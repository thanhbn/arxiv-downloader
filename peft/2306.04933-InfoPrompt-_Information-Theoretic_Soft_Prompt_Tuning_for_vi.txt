# 2306.04933.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2306.04933.pdf
# Kích thước tệp: 890341 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
InfoPrompt: Điều chỉnh Prompt Mềm Dựa trên Lý thuyết Thông tin cho
Hiểu biết Ngôn ngữ Tự nhiên
Junda Wu∗Tong Yu†Rui Wang‡Zhao Song§Ruiyi Zhang¶
Handong Zhao‖Chaochao Lu∗∗Shuai Li††Ricardo Henao‡‡
Tóm tắt
Điều chỉnh prompt mềm đạt được hiệu suất vượt trội trên nhiều tác vụ few-shot khác nhau.
Tuy nhiên, hiệu suất của việc điều chỉnh prompt có thể rất nhạy cảm với việc khởi tạo các
prompt. Chúng tôi cũng quan sát thực nghiệm rằng các phương pháp điều chỉnh prompt truyền thống không thể mã hóa và học đủ thông tin liên quan đến tác vụ từ các token prompt. Trong nghiên cứu này, chúng tôi phát triển
một khung lý thuyết thông tin xây dựng việc điều chỉnh prompt mềm như việc tối đa hóa thông tin lẫn nhau giữa các prompt và các tham số mô hình khác (hoặc các biểu diễn đã mã hóa). Quan điểm mới này giúp chúng tôi phát triển một phương pháp điều chỉnh prompt mềm hiệu quả, chính xác và mạnh mẽ hơn
InfoPrompt. Với khung này, chúng tôi phát triển hai hàm mất mát mới dựa trên thông tin lẫn nhau, để (i) khám phá việc khởi tạo prompt phù hợp cho các tác vụ downstream và học đủ thông tin liên quan đến tác vụ từ các token prompt và (ii) khuyến khích biểu diễn đầu ra từ
mô hình ngôn ngữ pretrained nhận thức rõ hơn về thông tin liên quan đến tác vụ được thu thập trong
prompt đã học. Các thí nghiệm mở rộng xác nhận rằng InfoPrompt có thể tăng tốc đáng kể việc hội tụ của việc điều chỉnh prompt và vượt trội hơn các phương pháp điều chỉnh prompt truyền thống. Cuối cùng,
chúng tôi cung cấp một kết quả lý thuyết chính thức để chỉ ra rằng thuật toán kiểu gradient descent có thể được sử dụng để huấn luyện hàm mất mát thông tin lẫn nhau của chúng tôi.
∗jw6466@nyu.edu . Đại học New York.
†tyu@adobe.com . Adobe Research.
‡rwr16@duke.edu . Đại học Duke.
§zsong@adobe.com . Adobe Research.
¶ruizhang@adobe.com . Adobe Research.
‖hazhao@adobe.com . Adobe Research.
∗∗luccnju@gmail.com . Đại học Cambridge.
††shuaili8@sjtu.edu.cn . Đại học Giao thông Thượng Hải.
‡‡ricardo.henao@duke.edu . Đại học Duke.arXiv:2306.04933v1  [cs.CL]  8 Jun 2023

--- TRANG 2 ---
1 Giới thiệu
Điều chỉnh prompt mềm đã cho thấy thành công lớn trong nhiều tác vụ xử lý ngôn ngữ tự nhiên,
đặc biệt trong các tình huống tài nguyên thấp [LARC21, GHLH22, LBL+22]. Với một phần tương đối nhỏ
của các tham số prompt có thể điều chỉnh được thêm vào đầu vào của ngữ cảnh, mô hình ngôn ngữ có thể được
huấn luyện trên các tác vụ downstream với các tham số pretrained quy mô lớn được đóng băng. So
với các phương pháp fine tuning truyền thống, điều chỉnh prompt yêu cầu ít bộ nhớ và tài nguyên tính toán
hơn để cập nhật những tham số prompt có kích thước nhỏ hơn đáng kể này. Ngoài ra, trong các tình huống học low-shot, điều chỉnh prompt có thể ngăn chặn mô hình ngôn ngữ overfitting trên dữ liệu huấn luyện,
và do đó duy trì khả năng tổng quát hóa của các mô hình ngôn ngữ pretrained.
Tuy nhiên, các nghiên cứu gần đây tiết lộ rằng việc tìm ra khởi tạo phù hợp của các token prompt là không đơn giản. Một số nghiên cứu đã điều tra ảnh hưởng của việc khởi tạo prompt đến hiệu suất điều chỉnh prompt [SWQ+22, WS22] và cho thấy rằng hiệu suất của việc điều chỉnh prompt rất nhạy cảm với việc khởi tạo prompt. Tuy nhiên, vì việc khởi tạo prompt có thể thay đổi với các tác vụ downstream và mô hình ngôn ngữ pretrained khác nhau, trong các tác vụ tài nguyên thấp, chúng ta khó có thể tìm thấy kiến thức rất chính xác để hướng dẫn chúng ta có được khởi tạo phù hợp [CZX+22].
Ngoài những hạn chế trên của điều chỉnh prompt mềm trong việc khởi tạo, chúng tôi cũng quan sát thực nghiệm rằng các phương pháp điều chỉnh prompt truyền thống không thể học hiệu quả đủ thông tin liên quan đến tác vụ từ các token prompt. Cụ thể, các phương pháp điều chỉnh prompt truyền thống không thể định vị các prompt với thông tin liên quan đến tác vụ được mã hóa bởi các mô hình ngôn ngữ đóng băng dựa trên ngữ cảnh đầu vào. Để hiểu mối liên quan giữa các token prompt và các tác vụ downstream, chúng tôi tính toán thông tin lẫn nhau có điều kiện (CMI) giữa các token prompt và biểu diễn tiềm ẩn từ mô hình ngôn ngữ dựa trên ngữ cảnh đầu vào. Chúng tôi tuân theo [HKM21] để xác định vị trí của các token prompt được chèn giữa câu đầu vào. Hình 1 cho thấy phân phối CMI của các prompt được học hoặc tạo thủ công từ các phương pháp khác nhau. Các prompt được lấy mẫu ngẫu nhiên có CMI thấp nhất. Các prompt được học bởi một phương pháp điều chỉnh prompt mềm, WARP [HKM21], có thể có CMI tương đối tốt hơn so với các prompt tạo thủ công. Bằng cách trực tiếp tối đa hóa CMI, InfoPrompt của chúng tôi (được chi tiết trong Phần 3) có thể mã hóa các prompt thông tin hơn.
Không có sự hướng dẫn của thông tin liên quan đến tác vụ, việc khám phá ngẫu nhiên các prompt thông qua không gian liên tục lớn của các token prompt có thể không hiệu quả, nơi một thách thức tương tự được thảo luận trong [QWS+21]. Một số kết quả liên quan [QWS+21, GHLH22, SRdV22] cho thấy rằng điều chỉnh prompt cần số lượng epoch lớn hơn nhiều để hội tụ so với các phương pháp fine tuning truyền thống.
Phương pháp của chúng tôi có thể hội tụ dễ dàng hơn so với phương pháp điều chỉnh prompt mềm truyền thống và chúng tôi cung cấp các đảm bảo lý thuyết về sự hội tụ của các hàm mất mát được đề xuất được huấn luyện bằng các thuật toán kiểu gradient descent truyền thống.
Trong bài báo này, để giải quyết những hạn chế trên, chúng tôi phát triển một khung lý thuyết thông tin
xây dựng việc điều chỉnh prompt mềm như việc tối đa hóa thông tin lẫn nhau giữa các prompt và các tham số mô hình khác (hoặc các biểu diễn đã mã hóa). Với khung này, chúng tôi phát triển InfoPrompt với hai hàm mất mát mới dựa trên thông tin lẫn nhau. (i) Để khám phá việc khởi tạo prompt phù hợp cho các tác vụ downstream và học đủ thông tin liên quan đến tác vụ từ các token prompt, chúng tôi tối ưu hóa head loss tối đa hóa thông tin lẫn nhau giữa prompt và language head. Bằng cách tối ưu hóa head loss này, prompt có thể học hiệu quả thông tin liên quan đến tác vụ từ các tác vụ downstream, vì language head thường chứa thông tin từ các tác vụ downstream. Bên cạnh đó, hàm mất mát thông tin lẫn nhau có thể giúp hướng dẫn việc học của các token prompt trong các bước đầu để giải quyết thách thức khởi tạo, vì các tham số language head có nhiều khả năng học thông tin tác vụ downstream nhanh hơn. (ii) Để khuyến khích thêm biểu diễn đầu ra từ mô hình ngôn ngữ pretrained (tức là biểu diễn đã mã hóa) nhận thức rõ hơn về thông tin liên quan đến tác vụ được thu thập trong prompt đã học, chúng tôi tối ưu hóa
1

--- TRANG 3 ---
InfoPrompt WARP Random Handcraft 1 Handcraft 2
Method024681012CMI(a) MRPC. Prompt handcraft 1 là 'it is equivalent to'
và prompt handcraft 2 là 'has the same meaning'.
InfoPrompt WARP Random Handcraft 1 Handcraft 2
Method01020304050CMI(b) SST-2. Prompt handcraft 1 là 'this is positive'
và prompt handcraft 2 là 'this is negative'.
Hình 1: Phân phối của các chỉ số CMI của các prompt được học hoặc tạo thủ công từ các
phương pháp khác nhau trên MRPC và SST-2 [WSM+18]. Bằng InfoPrompt của chúng tôi, mối liên quan giữa các token prompt và các tác vụ downstream là cao nhất trong tất cả các phương pháp.
representation loss tối đa hóa thông tin lẫn nhau có điều kiện giữa các token prompt và các biểu diễn đặc trưng dựa trên ngữ cảnh đầu vào.
Các đóng góp của chúng tôi được tóm tắt như sau:
•Chúng tôi xem xét lại những hạn chế của điều chỉnh prompt mềm trong việc khởi tạo và khám phá rằng các phương pháp điều chỉnh prompt hiện tại không thể học đủ thông tin liên quan đến tác vụ từ các token prompt.
Chúng tôi đề xuất giải quyết đồng thời những hạn chế này từ góc độ lý thuyết thông tin.
•Chúng tôi đề xuất một khung điều chỉnh prompt lý thuyết thông tin InfoPrompt. Chúng tôi phát triển
hai hàm mất mát mới để tìm việc khởi tạo prompt phù hợp và học đủ thông tin liên quan đến tác vụ từ các token prompt, mà không yêu cầu bất kỳ kiến thức trước nào.
•Các thí nghiệm mở rộng trên 6 tác vụ và 3 bộ dữ liệu xác nhận rằng, không có bất kỳ kiến thức trước nào, InfoPrompt có thể tăng tốc đáng kể sự hội tụ của việc điều chỉnh prompt và vượt trội hơn các phương pháp điều chỉnh prompt truyền thống.
•Chúng tôi cung cấp một kết quả lý thuyết chính thức để chỉ ra rằng thuật toán kiểu gradient descent có thể được sử dụng để huấn luyện hàm mất mát thông tin lẫn nhau của chúng tôi.
2 Sơ bộ
2.1 Điều chỉnh Prompt
Điều chỉnh prompt mềm đã cho thấy thành công lớn trong nhiều tác vụ NLP [LARC21, GHLH22,
LBL+22]. Gọi Φ là encoder của một mô hình ngôn ngữ pretrained, ví dụ, Roberta-Large [LOG+19].
Giả sử X={x1, x2,···, xn} là một chuỗi văn bản có độ dài n và Y là nhãn của nó. Bằng cách prompting, chúng ta
thêm thông tin bổ sung P để mô hình điều kiện hóa trong quá trình dự đoán Y. P={p1, . . . , p np}
là một chuỗi các embedding token. np là số lượng token prompt. pi∈RD,i= 1,···, np,
là một vector embedding có chiều D và D là chiều embedding của mô hình ngôn ngữ pretrained. Đầu tiên chúng ta nhúng mỗi token của X vào embedding token tương ứng từ
mô hình ngôn ngữ pretrained. P được chèn vào chuỗi embedding kết quả của X để tạo thành một
template, sau đó được mã hóa bởi encoder pretrained Φ vào không gian biểu diễn của mô hình ngôn ngữ pretrained. Template được chi tiết với các thí nghiệm. Chính thức, chúng ta ký hiệu
quá trình này là Z= Φ( P, X), với Z là biểu diễn đã mã hóa. Dự đoán của mô hình
cho X được thực hiện trên Z với một language modeling head có thể huấn luyện hθ (được tham số hóa bởi θ), sao cho,
2

--- TRANG 4 ---
đầu ra hθ(Z) là phân phối trên tất cả các nhãn có thể cho phân loại. Toàn bộ mô hình
thường được huấn luyện thông qua việc tối thiểu hóa hàm mất mát sau,
Lpred= cross entropy( hθ(Z), Y) (1)
Encoder pretrained Φ bị đóng băng trong quá trình huấn luyện. Khác với các nghiên cứu trước [LARC21] nơi
các prompt là tham số có thể học, trong cách tiếp cận của chúng tôi, các prompt được mã hóa từ đầu vào
X, để các prompt có thể mã hóa thông tin liên quan đến tác vụ từ văn bản huấn luyện X. Chúng tôi sẽ
mô tả chi tiết cách các prompt được mã hóa từ đầu vào X trong Phần 4.
2.2 Thông tin Lẫn nhau
Thông tin lẫn nhau (MI) là một chỉ số trong lý thuyết thông tin [Sha48, Cov99], đo lường
lượng thông tin chia sẻ giữa hai biến ngẫu nhiên. Thông tin lẫn nhau giữa
hai biến ngẫu nhiên A và B là
I(A;B) =Ep(a,b)[DKL[p(a|b)∥p(b)]]. (2)
Lấy cảm hứng từ [SRR+22], chúng tôi sử dụng MI làm tiêu chí để so sánh các prompt và các tham số mô hình khác. MI cũng đã được áp dụng để đo lường sự tương tự giữa token bị che và ngữ cảnh tương ứng trong việc pretrain của Multilingual Masked Language Modeling [CDW+21],
mối liên quan giữa tài liệu và một câu trong tóm tắt tài liệu [PH21] và
câu nguồn và câu dịch đích trong Neural Machine Translation (NMT) [ZLM+22].
3 Phương pháp của chúng tôi: InfoPrompt
Như đã đề cập ở trên, chúng tôi muốn các prompt đã học có liên quan đến tác vụ. Để đạt được điều này, chúng tôi chú ý
rằng language model head được huấn luyện với cả biểu diễn dữ liệu và các nhãn phân loại, do đó có liên quan đến tác vụ được huấn luyện. Trong việc khuyến khích tính liên quan tác vụ của
các prompt đã học, chúng tôi xem xét việc tối đa hóa thông tin lẫn nhau giữa prompt và các tham số của language model head, được ký hiệu là θ. Bằng cách tối đa hóa thông tin lẫn nhau như vậy, prompt đã học sẽ tương ứng hơn với dữ liệu huấn luyện mà language model head được huấn luyện, do đó thu thập thêm thông tin liên quan đến tác vụ từ việc huấn luyện. Hơn nữa, để
mô hình ngôn ngữ pretrained mã hóa đúng cách thông tin liên quan đến tác vụ trong prompt, chúng tôi
tối đa hóa thêm thông tin lẫn nhau giữa prompt và biểu diễn từ mô hình ngôn ngữ pretrained, để biểu diễn đã mã hóa có thể nhận thức được thông tin liên quan đến tác vụ được thu thập bởi prompt. Ngoài ra, chúng tôi cũng cung cấp đảm bảo lý thuyết về sự hội tụ của những hàm mất mát được huấn luyện bởi các thuật toán kiểu gradient descent truyền thống, điều này giúp phương pháp của chúng tôi hội tụ dễ dàng hơn so với các phương pháp điều chỉnh prompt mềm truyền thống và tránh vấn đề của số epoch huấn luyện lớn. Dưới đây, chúng tôi ký hiệu thông tin lẫn nhau âm giữa prompt và các tham số của language model head là head loss. Thông tin lẫn nhau âm giữa prompt và biểu diễn từ mô hình ngôn ngữ pretrained được ký hiệu là representation loss.
3.1 Head Loss
head loss là thông tin lẫn nhau âm giữa prompt P và tham số θ, tức là,
−I(P;θ|X). Trong việc tối đa hóa I(P;θ|X), chúng tôi tuân theo [MC18] để xấp xỉ nó với cận dưới sau,
3

--- TRANG 5 ---
I(P;θ|X)≥C+LNCE(P, θ, X ), (3)
C là một hằng số và LNCE là một Noise Contrastive Estimation (NCE) của thông tin lẫn nhau,
LNCE =E"
logexp(l(P, θ, X ))PK
k=1exp(l(Pk, θ|X))#
, (4)
{Pk}K
k=1 là các mẫu prompt âm cho học tương phản. Trong thực tế, chúng tôi lấy mẫu ngẫu nhiên
K−1 token từ ngữ cảnh làm các mẫu âm, tức là,{Pk}K
k=2 và P1=P.
Chúng tôi mô hình hóa hàm điểm l(θ, p) như một hàm song tuyến tính tiêu chuẩn với ma trận có thể học được
W1
l(P, θ|X) =P⊤W1θ. (5)
trong đó θ và P được mã hóa từ X. W1 là một ma trận có thể huấn luyện. Vì language model head
được học trên đầu ra từ lớp cuối cùng của mô hình ngôn ngữ pretrained, việc học các tham số θ của nó dễ dàng hơn so với việc học prompt P (lớp đầu vào của mô hình ngôn ngữ pretrained). Do đó, θ có thể thu thập thêm thông tin liên quan đến tác vụ hơn P trong giai đoạn đầu của việc huấn luyện. Bằng cách tối đa hóa thông tin lẫn nhau giữa θ và P, thông tin liên quan đến tác vụ có thể được chuyển đến P trong các bước huấn luyện ban đầu. Bằng cách này, P có thể liên quan đến tác vụ hơn đặc biệt trong giai đoạn huấn luyện đầu. Các thí nghiệm trong Phần 6 cũng cho thấy rằng head loss của chúng tôi, I(P;θ|X), có thể tạo thuận lợi cho việc huấn luyện trong các bước huấn luyện ban đầu.
3.2 Representation Loss
Representation loss, được ký hiệu là −I(P;Z|X), được định nghĩa là âm của thông tin lẫn nhau
giữa prompt P và biểu diễn đã mã hóa từ mô hình ngôn ngữ pretrained, tức là,
Z= Φ( P, X). Tương tự như head loss, chúng tôi xấp xỉ representation loss với cận dưới của nó,
I(P;Z|X)≥log(N) +LNCE(P, Z|X), (6)
và,
LNCE=E"
logexp(l(P, Z|X))PK
k=1exp(l(P, Z k|X))#
, (7)
{Zk}K
k=1 là các mẫu âm. Ở đây, chúng tôi sử dụng chồng ký hiệu của InfoNCE loss LNCE và
hàm điểm l để ngắn gọn. Gọi W2 là một ma trận có thể huấn luyện, hàm l cho representation loss được định nghĩa bởi,
l(P, Z|X) =P⊤W2Z. (8)
Chúng tôi sử dụng các phương pháp suy luận biến thiên [HCD+16] để phục hồi phân phối tiềm ẩn của Z. Cụ thể,
chúng tôi giả sử rằng phân phối tiềm ẩn là N(µ, σ), trong đó N(µ, σ) là phân phối chuẩn với
trung bình µ và ma trận hiệp phương sai chéo σ. Chúng tôi mô hình hóa µ và σ thông qua,
µ=fµ(Z), σ=fσ(Z). (9)
fµ và fµ là các lớp được kết nối đầy đủ có thể huấn luyện. Vì các mẫu âm của Z, tức là,{Zk}K
k=1,
không nên được ghép với P, chúng tôi giả sử {Zk}K
k=1 được rút ra từ N(µ′, σ′), sao cho,
µ′=fµ(Z′), σ′=fσ(Z′). (10)
Trái ngược với Z= Φ( P, X), chúng ta có Z′= Φ( X) để {Zk}K
k=1 không được ghép với P. Bằng cách tối đa hóa representation loss I(P;Z|X), chúng tôi khuyến khích biểu diễn đã mã hóa Z
nhận thức rõ hơn về prompt P, để thông tin liên quan đến tác vụ trong P có thể được mã hóa đúng cách bởi mô hình ngôn ngữ pretrained trong việc tạo ra Z.
4

--- TRANG 6 ---
3.3 Mục tiêu Tổng thể
Chúng tôi tối thiểu hóa mục tiêu sau trong điều chỉnh prompt:
L=Lpred−β· I(P;Z|X)−γ· I(P;θ|X). (11)
Chúng tôi ký hiệu Lpred là task loss. β và γ là các tham số cân bằng cho representation loss và head loss được đề xuất, tương ứng. Chúng tôi ký hiệu cách tiếp cận của chúng tôi là InfoPrompt.
3.4 Đảm bảo Lý thuyết
Chúng tôi trình bày kết quả lý thuyết chính của chúng tôi như sau. Do giới hạn không gian, chúng tôi hoãn chứng minh vào Phụ lục.
Định lý 3.1. Cho hàm Loss L(Eq. (11)) và các điều kiện được chỉ định trong Phụ lục C.1 và
D, sử dụng thuật toán tham lam kiểu gradient descent, chúng ta có thể tìm ra nghiệm tối ưu của hàm mất mát đó.
Chúng tôi cung cấp đảm bảo lý thuyết về sự hội tụ của những hàm mất mát được huấn luyện bởi các thuật toán kiểu gradient descent truyền thống, điều này giúp phương pháp của chúng tôi hội tụ dễ dàng hơn so với các phương pháp điều chỉnh prompt mềm truyền thống và tránh vấn đề của số epoch huấn luyện lớn.
4 Thí nghiệm
4.1 Bộ dữ liệu
Chúng tôi tiến hành thí nghiệm với các bộ dữ liệu phân loại chuỗi từ benchmark GLUE [WSM+18],
cùng với những bộ dữ liệu của các tác vụ trích xuất quan hệ và tác vụ NER. Chúng tôi chọn bốn tác vụ phân loại chuỗi từ benchmark GLUE: RTE (Recognizing Textual Entailment, [BCDG09]),
MRPC (Microsoft Research Paraphrase Corpus, [DB05]), CoLA (Corpus of Linguistic Acceptability, [WSB19]) và SST-2 (Sentence Sentiment Treebank, [SPW+13]). Chúng tôi chọn những tác vụ này vì các bộ dữ liệu của chúng có kích thước nhỏ hơn và điều chỉnh prompt tương đối hiệu quả hơn trong môi trường tài nguyên thấp [HKM21, LL21]. Đối với tác vụ trích xuất quan hệ, chúng tôi đánh giá phương pháp của chúng tôi trên
corpus ACE2005 và bộ dữ liệu Semeval-2010 [HKK+19]. Chúng tôi cũng sử dụng corpus ACE2005 cho tác vụ NER. Lưu ý rằng các khoảng thực thể cho NER đã được cung cấp trong ACE2005. Khác với mô hình NER tiêu chuẩn học dự đoán khoảng thực thể và loại thực thể đồng thời từ chuỗi văn bản thô, mô hình của chúng tôi chỉ dự đoán loại thực thể dựa trên khoảng thực thể đã cho. Chúng tôi tuân theo cùng chiến lược chia dữ liệu cho corpus ACE2005 như nghiên cứu trước [YM16, NCG16]. Đối với các tác vụ Semeval-2010, chúng tôi tuân theo phân vùng dữ liệu chính thức [HKK+19].
4.2 Cài đặt Thí nghiệm
Chúng tôi tuân theo tình huống hạn chế tài nguyên trong [HKM21] huấn luyện mỗi tác vụ chỉ với 64 hoặc 256
mẫu. Chúng tôi thí nghiệm với np= 1 và np= 4 token prompt cho mỗi tác vụ. Các token prompt
được chèn vào template cho mỗi tác vụ. Tương tự như [HKM21], chúng tôi áp dụng mô hình RoBERTa-large
làm encoder pretrained của chúng tôi. Chúng tôi đóng băng các tham số pretrained và chỉ huấn luyện với các tham số
của prompt head và token prompt. Trong quá trình huấn luyện, chúng tôi thiết lập thực nghiệm β= 0.1 và γ= 0.05.
Số lượng mẫu âm K= 32. Tỷ lệ học là 1 e−3 và kích thước batch là 8. Đối với mỗi tác vụ, chúng tôi báo cáo kết quả sau 30 epoch, trung bình trên 5 hạt giống ngẫu nhiên. Để mã hóa prompt P= [p1,···, pnp] từ X, đầu tiên chúng tôi mã hóa X thành P′∈RD thông qua P′= Φ(X). Đối với mỗi pi∈RD, chúng ta có pi=Wup
iWdown
iP′,Wup
i∈RD×64,Wdown
i∈R64×D.
5

--- TRANG 7 ---
Đối với các tác vụ phân loại chuỗi và trích xuất quan hệ, chúng tôi tuân theo template của
[HKM21] chứa một token [ mask ]. Biểu diễn Z là token [ mask ] từ lớp cuối cùng của encoder Roberta-Large. Đối với các tác vụ nhận dạng thực thể có tên, chúng tôi có token [ mask ] trước khoảng thực thể đã cho, với phần còn lại giống như đối với phân loại chuỗi.
Bảng 1: Kết quả trên Phân loại Chuỗi.
CoLa ( np= 1) CoLa ( np= 4) RTE ( np= 1) RTE ( np= 4) MRPC ( np= 1) MRPC ( np= 4) SST2 ( np= 1) SST2( np= 4) Trung bình
Finetuning 0.6131 0.7798 0.8873 0.9427 0.8057
Adapter 0.5552 0.5776 0.6814 0.9472 0.6904
WARP [HKM21] 0.5282 0.5911 0.6282 0.6426 0.8039 0.8186 0.9507 0.9587 0.7403
IDPG [WWG+22] 0.5556 0.5646 0.6282 0.6534 0.7941 0.8039 0.9587 0.9587 0.7396
InfoPrompt 0.5631 0.6018 0.6751 0.6968 0.8039 0.8137 0.9576 0.9599 0.7590
γ= 0 0.5699 0.5853 0.6751 0.6787 0.7941 0.8137 0.9495 0.9587 0.7531
β= 0 0.5546 0.5579 0.6065 0.6318 0.7892 0.7966 0.9472 0.9610 0.7306
γ= 0, β= 0 0.5032 0.5732 0.6173 0.6029 0.7917 0.7672 0.9495 0.9564 0.7202
Bảng 2: Kết quả trên Trích xuất Quan hệ và NER.
RE (np= 1) RE ( np= 4) NER( np= 1) NER( np= 4) SemEval ( np= 1) SemEval ( np= 4) Trung bình
Finetuning 0.8119 0.9054 0.8506 0.8560
Adapter 0.5073 0.8329 0.6570 0.6657
WARP [HKM21] 0.6384 0.6596 0.8174 0.8607 0.6702 0.7284 0.7291
IDPG [WWG+22] 0.6079 0.6132 0.8360 0.8931 0.6408 0.6776 0.7114
InfoPrompt 0.6914 0.7616 0.8526 0.8962 0.7563 0.7917 0.7916
γ= 0 0.6914 0.7285 0.8452 0.8635 0.7471 0.7865 0.7770
β= 0 0.6967 0.7470 0.8351 0.8698 0.7449 0.7538 0.7746
γ= 0, β= 0 0.5364 0.7285 0.8512 0.8661 0.7490 0.7799 0.7519
4.3 Baseline và Ablation
Như đã đề cập ở trên, phương pháp của chúng tôi với (11) được ký hiệu là InfoPrompt. Trong các thí nghiệm, chúng tôi
so sánh phương pháp của chúng tôi với các baseline sau:
•Fine Tuning: Chúng tôi fine tune tất cả các tham số từ encoder pretrained trên mỗi tác vụ.
Fine Tuning được bao gồm như cận trên cho hiệu suất mô hình, vì nó tốn kém về mặt tính toán hơn so với chỉ huấn luyện các tham số prompt.
•Adapter: Tương tự như điều chỉnh prompt, đây cũng là một cách huấn luyện tiết kiệm tham số cho
các mô hình ngôn ngữ pretrained. Cụ thể, thay vì thêm các token prompt trong đầu vào,
chúng tôi thêm các adapter sau lớp tuyến tính cuối cùng trong mỗi lớp transformer.
•WARP [HKM21]: Khác với cách tiếp cận của chúng tôi, các token prompt của WARP không được tạo ra
từ chuỗi đầu vào. các token prompt được chèn vào chuỗi đầu vào. Trong quá trình huấn luyện,
encoder pretrained bị đóng băng và chỉ các token prompt có thể huấn luyện.
•IDPG [WWG+22]: Tương tự như cách tiếp cận của chúng tôi, các token prompt được tạo ra từ chuỗi đầu vào. Encoder pretrained bị đóng băng và prompt generator có thể huấn luyện.
Trong việc đánh giá hiệu quả của các hàm mất mát được đề xuất của chúng tôi, chúng tôi xem xét hai ablation sau:
•γ= 0: Chúng tôi vô hiệu hóa head loss trong quá trình huấn luyện thông qua γ= 0, trong khi giữ β= 0.05.
•β= 0: Chúng tôi vô hiệu hóa head loss trong quá trình huấn luyện thông qua γ= 0, trong khi giữ γ= 0.1.
•β=γ= 0: Chúng tôi vô hiệu hóa cả hai hàm mất mát. Các tham số prompt được huấn luyện với Lpred.
6

--- TRANG 8 ---
5 Kết quả Thí nghiệm
5.1 Huấn luyện với bộ dữ liệu Đầy đủ
Bảng 1 và 2 cho thấy kết quả huấn luyện với bộ dữ liệu đầy đủ cho mỗi tác vụ. Chúng ta có thể quan sát rằng
kết quả với InfoPrompt của chúng tôi nói chung cao hơn so với các baseline tiết kiệm tham số khác
đóng băng các tham số Roberta-Large pretrained (ví dụ, WARP và Adapter). Fine Tuning
nói chung có hiệu suất tốt hơn so với các cách tiếp cận khác. Điều này là do nó cho phép huấn luyện
với tất cả các tham số mô hình, với chi phí tính toán cao hơn trong quá trình huấn luyện.
Như đã đề cập ở trên, Fine Tuning được dự định bao gồm như cận trên cho hiệu suất.
Hơn nữa, chúng ta có thể thấy hiệu suất với γ= 0 và β= 0 thấp hơn so với InfoPrompt,
cho thấy rằng việc học các token prompt liên quan đến tác vụ với head loss và representation loss được đề xuất là có lợi. Hơn nữa, khoảng cách hiệu suất giữa γ= 0/β= 0 và β=γ= 0
cho thấy rằng các hàm được đề xuất có hiệu quả khi được thêm vào điều chỉnh prompt thông thường, tức là chỉ với
Lpred.
5.2 Huấn luyện với bộ dữ liệu Few-Shot
Bảng 3: Kết quả few-shot trên Phân loại Chuỗi. Chúng tôi thí nghiệm với 64 và 256 mẫu cho
mỗi tác vụ. Số lượng prompt được cố định là np= 4 cho tất cả các phương pháp điều chỉnh prompt mềm.
CoLa (64) CoLa (256) RTE (64) RTE (256) MRPC (64) MRPC(256) SST2 (64) SST2(256) Trung bình
Finetuning 0.1746 0.4086 0.4801 0.6787 0.7107 0.7819 0.8027 0.8853 0.6153
Adapter 0.0627 0.2486 0.5487 0.5668 0.5931 0.625 0.4908 0.664 0.4750
WARP [HKM21] 0.0749 0.0785 0.5596 0.5812 0.7083 0.7083 0.5872 0.7638 0.5077
InfoPrompt 0.1567 0.1750 0.6137 0.6580 0.7059 0.7377 0.6697 0.7305 0.5559
γ= 0 0.1479 0.1447 0.5776 0.6318 0.6936 0.7328 0.664 0.7294 0.5402
β= 0 0.1372 0.1433 0.5812 0.5957 0.6838 0.7132 0.5631 0.656 0.5092
γ= 0, β= 0 0.0919 0.1397 0.5668 0.5523 0.6985 0.7108 0.5505 0.6296 0.4925
Bảng 4: Kết quả few-shot trên Trích xuất Quan hệ và NER. Chúng tôi thí nghiệm với 64 và 256 mẫu
cho mỗi tác vụ. Số lượng prompt được cố định là np= 4 cho tất cả các phương pháp điều chỉnh prompt mềm.
RE (64) RE (256) NER (64) NER (256) SemEval(64) SemEval(256) Trung bình
Finetuning 0.1285 0.4013 0.3033 0.4358 0.2223 0.4829 0.3290
Adapter 0.1086 0.1815 0.2345 0.2437 0.1211 0.177 0.1777
WARP [HKM21] 0.1404 0.2556 0.3082 0.4369 0.1708 0.3684 0.2801
InfoPrompt 0.2119 0.2993 0.3331 0.4739 0.2113 0.4034 0.3222
γ= 0 0.2026 0.2834 0.3225 0.4776 0.2153 0.3739 0.3126
β= 0 0.2013 0.2874 0.3208 0.4615 0.2072 0.3629 0.3069
γ= 0, β= 0 0.1974 0.2728 0.3142 0.4662 0.2278 0.3276 0.3010
Kết quả cho huấn luyện với bộ dữ liệu few-shot được liệt kê trong Bảng 3 và 4. So với
huấn luyện với bộ dữ liệu đầy đủ (Bảng 1 và 2), chúng ta có thể thấy rằng khoảng cách hiệu suất giữa InfoPrompt được đề xuất của chúng tôi và các baseline nói chung lớn hơn trong môi trường few-shot. Khác với các bộ dữ liệu đầy đủ, các bộ dữ liệu few-shot chứa ít thông tin hơn nhiều liên quan đến tác vụ cần học. Kết quả là, các prompt được học chỉ với task loss (ví dụ, với WARP hoặc β=γ= 0) có thể dễ dàng overfit với thông tin không liên quan đến tác vụ cho các bộ dữ liệu few-shot. Trong tình huống như vậy, sẽ quan trọng để khuyến khích rõ ràng prompt đã học có liên quan đến tác vụ, tức là thông qua các hàm mất mát được đề xuất của chúng tôi dựa trên tối đa hóa thông tin lẫn nhau. Điều này giải thích tại sao InfoPrompt mang lại lợi ích hiệu suất lớn hơn khi được huấn luyện với bộ dữ liệu few-shot. Tương tự như huấn luyện với bộ dữ liệu đầy đủ, lợi ích hiệu suất của InfoPrompt so với InfoPrompt (γ= 0) và InfoPrompt (β= 0)
cho thấy hiệu quả của các hàm mất mát được đề xuất của chúng tôi trong tình huống few-shot.
7

--- TRANG 9 ---
6 Phân tích
1.5
 1.0
 0.5
 0.0 0.5 1.0 1.5
Thành phần Chính 11.5
1.0
0.5
0.00.51.01.5Thành phần Chính 2
T ask Loss
InfoPrompt = 0.05
InfoPrompt = 0
0.450.500.550.600.650.700.75
(a) Cảnh quan của task loss. β= 0.1
1.5
 1.0
 0.5
 0.0 0.5 1.0 1.5
Thành phần Chính 11.5
1.0
0.5
0.00.51.01.5Thành phần Chính 2
CMI Loss
InfoPrompt = 0.05
InfoPrompt = 0
2.452.502.552.602.652.702.75 (b) Cảnh quan của representation loss. β= 0.1
Hình 2: Cảnh quan của các hàm mất mát trong không gian tham số của các token prompt. Cảnh quan
minh họa cách các giá trị của hàm mất mát thay đổi với các token prompt đầu vào. Quỹ đạo cho thấy 500 bước đầu tiên trong quá trình huấn luyện cho InfoPrompt với γ= 0.05 hoặc γ= 0.
6.1 Cảnh quan Mất mát
Để cung cấp hiểu biết toàn diện hơn về hiệu quả của các hàm mất mát được đề xuất của chúng tôi,
chúng tôi vẽ cảnh quan của các hàm mất mát trong không gian tham số của các token prompt. Cảnh quan minh họa cách các giá trị của hàm mất mát thay đổi với các token prompt đầu vào. Vì các token prompt là các vector có chiều cao, tức là mỗi token có chiều 1024 cho
RoBerta-Large, chúng tôi hiển thị các giá trị mất mát liên quan của chúng thông qua việc chiếu các token prompt vào một không gian con 2D. Cụ thể, chúng tôi tuân theo nghiên cứu trước về phân tích embedding token [CHBC20]
chiếu các token prompt vào top-2 thành phần chính được tính từ các embedding token pretrained của Roberta-Large. Chúng tôi chỉ chèn một token prompt vào chuỗi đầu vào
trong quá trình hiển thị.
Lấy tác vụ MRPC làm ví dụ, chúng tôi vẽ cảnh quan 2D của task loss và
representation loss trong Hình 2a và 2b, tương ứng. Tất cả hai hình đều được vẽ với cùng
tỷ lệ, tức là với cùng giá trị của token prompt. Các giá trị trục là độ lệch từ
trung bình của các embedding token Roberta-Large pretrained. Các giá trị mất mát được hiển thị trong các hình
là trung bình của 20 mẫu ngẫu nhiên từ MRPC. Trong Hình 2a, chúng ta có thể thấy rằng có
rất nhiều minimum cục bộ trong cảnh quan của task loss. Điều này phù hợp với các quan sát
của các nghiên cứu trước [GHLH22, SWQ+22] rằng điều chỉnh prompt khó được tối ưu hóa và nhạy cảm với việc khởi tạo, ví dụ, tối ưu hóa có thể dễ dàng overfit với một minimum cục bộ
mà không có khởi tạo phù hợp. Từ Hình 2b, chúng ta có thể quan sát rằng các giá trị của info loss được đề xuất của chúng tôi mượt mà hơn nhiều so với task loss trong Hình 2a. Với cảnh quan mượt mà hơn, tối ưu hóa với các hàm mất mát được đề xuất của chúng tôi có thể ổn định hơn (cũng được hiển thị trong Phần 6.2), tức là ít có khả năng bị mắc kẹt trong một minimum cục bộ và cũng được đảm bảo hội tụ bởi các kết quả lý thuyết của chúng tôi (xem Định lý 3.1). Ngoài ra, chúng tôi vẽ quỹ đạo của 500 bước đầu tiên trong quá trình huấn luyện cho InfoPrompt (γ= 0.05) (xanh lá) và γ= 0 (tím) trong Hình 2a và 2b. Các ngôi sao trong biểu đồ chỉ ra giá trị ban đầu của prompt trước khi huấn luyện. Chúng tôi thấy rằng huấn luyện với γ= 0.05
có thể tạo ra một descent lớn hơn cho cả task loss và representation loss, so với γ= 0.
8

--- TRANG 10 ---
Như phân tích trong Phần 3.1, language head dễ học hơn so với prompt. Kết quả là, các tham số của language head có thể chứa thêm thông tin liên quan đến tác vụ trong giai đoạn đầu của việc huấn luyện. Bằng cách tối đa hóa thông tin lẫn nhau giữa tham số head và prompt thông qua head loss được đề xuất (được cân bằng bởi γ), chúng tôi khuyến khích prompt đã học thu thập thêm thông tin liên quan đến tác vụ trong các bước huấn luyện ban đầu, do đó dẫn đến γ= 0.05 có descent lớn hơn so với γ= 0 trong các quỹ đạo được hiển thị trong Hình 2a và 2b. Lưu ý rằng hai hàm mất mát được đề xuất của chúng tôi là không giám sát và không yêu cầu thêm nhãn.
6.2 Đường cong Học tập
Chúng tôi vẽ đường cong huấn luyện cho tác vụ NER và SST-2 trong Hình 3a và 3b, tương ứng. Khác với WARP [HKM21] và Fine Tuning huấn luyện chỉ với task loss Lpred, InfoPrompt của chúng tôi cũng huấn luyện với representation loss và head loss. Chúng ta có thể quan sát rằng việc huấn luyện InfoPrompt của chúng tôi ổn định hơn và hội tụ nhanh hơn, so với WARP. Điều này có thể được giải thích từ các biểu đồ cảnh quan trong Phần 6.1. Vì cảnh quan của task loss không mượt mà (Hình 2a),
đường cong huấn luyện của WARP có thể thể hiện sự dao động đáng kể khi tối ưu hóa overfit với một minimum cục bộ, ví dụ, bước thứ 10000 trong Hình 3a. Tương đối, InfoPrompt được đề xuất của chúng tôi có thể làm mượt cảnh quan tối ưu hóa, do đó ổn định việc huấn luyện và dẫn đến hội tụ nhanh hơn, được đảm bảo bởi các kết quả lý thuyết của chúng tôi. Chúng tôi quan sát rằng Fine Tuning nói chung hội tụ nhanh hơn và kết thúc với độ chính xác cao hơn InfoPrompt. Điều này là do Fine Tuning, huấn luyện với tất cả các tham số mô hình, có khả năng mô hình lớn hơn nhiều trong quá trình huấn luyện so với điều chỉnh prompt (InfoPrompt và WARP). Kết quả như vậy cho Fine Tuning với chi phí tính toán lớn hơn, tức là chúng ta cần tính gradient cho tất cả các tham số mô hình (354M) thay vì chỉ các tham số prompt P(1.3M).
0 2500 5000 7500 10000 12500 15000 17500
bước0.00.20.40.60.8độ chính xác
InfoPrompt
WARP
Finetuning
(a) Đường cong học tập NER ACE.
0 2000 4000 6000 8000 10000 12000 14000
bước0.50.60.70.80.9độ chính xác
InfoPrompt
WARP
Finetuning (b) Đường cong học tập SST-2.
Hình 3: Các đường cong học tập cho tác vụ NER và SST-2. Việc huấn luyện InfoPrompt của chúng tôi
ổn định hơn và hội tụ nhanh hơn, so với WARP.
9

--- TRANG 11 ---
7 Nghiên cứu Liên quan
7.1 Điều chỉnh Prompt Mềm
Điều chỉnh prompt mềm trở thành một paradigm mới trong NLP. Dựa trên một số mô hình pretrained lớn (ví dụ,
BERT [DCLT19], RoBERTa [LOG+19]), một số lượng tương đối nhỏ các tham số có thể huấn luyện có thể được
thêm vào đầu vào, trong khi các tham số của backbone được cố định. Nhiều nghiên cứu đã chứng minh
hiệu quả của điều chỉnh prompt mềm trong nhiều tác vụ NLP downstream [LARC21, HKM21,
QE21], đặc biệt trong các vùng tài nguyên thấp [SRdV22, LBL+22, GHLH22]. Một số nghiên cứu gần đây cũng
tìm thấy sức mạnh chuyển giao của các prompt mềm qua các domain [WS22, SWQ+22, VLC+22], qua các mô hình ngôn ngữ [SWQ+22] và cho khái quát hóa zero-shot [YJK+22]. Để nâng cao thêm hiệu quả của các tham số prompt mềm và cho phép khả năng khái quát hóa tốt hơn, nhiều nghiên cứu xem xét học đa tác vụ [ASPH22, DWL+22, VLC+22, HZT+22], hoặc đa ngôn ngữ [CHH22, HMZ+22].
Một số nghiên cứu cũng cố gắng khám phá prompt với kiến thức trước được mã hóa [HDW+21, HWSW22,
CZX+22]. Trong khi hầu hết các nỗ lực ban đầu của điều chỉnh prompt mềm không nhận thức ngữ cảnh, một số nghiên cứu gần đây gợi ý rằng các token prompt mềm nên được điều kiện hóa trên ngữ cảnh đầu vào.
Hyperprompt [HZT+22] đề xuất một cấu trúc hyper-network để tạo ra các token prompt dựa trên chỉ số tác vụ. [WWG+22] và [BSH22] gợi ý một số phương pháp tạo prompt mềm nhận thức ngữ cảnh.
[LLY22] đề xuất một phương pháp điều chỉnh prompt mềm có cấu trúc.
7.2 Phương pháp Lý thuyết Thông tin trong NLP
Các phương pháp lý thuyết thông tin được sử dụng rộng rãi trong nhiều tác vụ NLP [JLK+21, WHBC19, SDJS22,
JZZ+22, MCC+19]. [WHBC19] và [JLK+21] đề xuất các phương pháp lý thuyết thông tin cho việc ghi nhớ văn bản. [MCC+19] gợi ý một phương pháp lý thuyết thông tin cho đối thoại. [JZZ+22] xem
vấn đề NMT đa phương thức trong quan điểm lý thuyết thông tin. Đối với việc pretrain mô hình, [WWC+20] đề xuất Infobert để cải thiện độ mạnh mẽ của mô hình BERT. INFOXLM
[CDW+21] đề xuất một mô hình ngôn ngữ đa ngôn ngữ dựa trên khung lý thuyết thông tin.
Đối với fine-tuning mô hình, [MBH21] đề xuất một phương pháp mô hình information bottleneck cho fine-tuning tài nguyên thấp. [SRR+22] đề xuất một phương pháp lý thuyết thông tin để thiết kế các prompt rời rạc.
7.3 Tính toán Attention Lý thuyết
Softmax là một trong những đơn vị chính trong sơ đồ attention của hầu hết các mô hình ngôn ngữ lớn NLP gần đây.
Tính toán ma trận attention nhanh hơn là một câu hỏi thú vị về mặt thực tiễn [CKLM19, WLK+20,
KKL20]. Gần đây, một số nghiên cứu lý thuyết đã cố gắng nghiên cứu đơn vị softmax/attention
từ góc độ lý thuyết. Tính toán attention softmax có thể được định nghĩa chính thức như sau:
giả sử chúng ta được cho ba ma trận Q∈Rn×k (query), K∈Rn×k (key), và V∈Rn×k
(value), mục tiêu là tính toán Att(Q, K, V ) =D−1exp(QK⊤)V nơi ma trận chéo
D là diag(exp( QK⊤)1n). Ở đây K⊤ ký hiệu chuyển vị của ma trận K. Nghiên cứu của [ZHDK23,
AS23] xem xét setting tĩnh, và nghiên cứu của [BSZ23] xem xét setting động. [AS23]
đề xuất một thuật toán chặt chẽ để tính toán Att và cung cấp một kết quả cận dưới dựa trên
giả thuyết thời gian mũ mạnh. Nghiên cứu [BSZ23] cho thấy một kết quả tích cực chặt chẽ và một kết quả tiêu cực. Trong [BSZ23], họ cung cấp một cận trên thông qua các kỹ thuật cập nhật lười [CLS19]. Trong [BSZ23],
họ cũng trình bày một kết quả cận dưới dựa trên giả thuyết Hinted MV [BNS19].
Nghiên cứu của [DMS23] đề xuất hai thuật toán sparsification để tính toán ma trận attention khi
chiều đặc trưng ≫ độ dài câu. [GSY23a] cho thấy cách cung cấp một thuật toán bảo mật khác biệt cho việc tính toán ma trận attention dưới khung bảo mật khác biệt [DMNS06,
DKM+06].
10

--- TRANG 12 ---
8 Kết luận
Chúng tôi xem xét lại những hạn chế của điều chỉnh prompt mềm trong việc khởi tạo. Chúng tôi cũng khám phá thực nghiệm
rằng các phương pháp điều chỉnh prompt truyền thống không thể học đủ thông tin liên quan đến tác vụ từ các token prompt. Chúng tôi giải quyết những hạn chế này từ góc độ lý thuyết thông tin và đề xuất một phương pháp điều chỉnh prompt lý thuyết thông tin InfoPrompt. Hai hàm mất mát mới được thiết kế
để (i) khám phá việc khởi tạo prompt phù hợp cho các tác vụ downstream và học đủ thông tin liên quan đến tác vụ từ các token prompt và (ii) khuyến khích biểu diễn đầu ra từ mô hình ngôn ngữ pretrained nhận thức rõ hơn về thông tin liên quan đến tác vụ được thu thập trong prompt đã học. Với các thí nghiệm mở rộng, không có bất kỳ kiến thức chuyên gia trước nào, InfoPrompt có thể tăng tốc đáng kể sự hội tụ của việc điều chỉnh prompt và đạt được hiệu suất chính xác và mạnh mẽ hơn so với các phương pháp điều chỉnh prompt truyền thống.
9 Hạn chế
InfoPrompt được đề xuất của chúng tôi là một cách tiếp cận nhắm vào huấn luyện tiết kiệm tham số, tức là giảm các tham số có thể huấn luyện thông qua việc đóng băng các tham số pretrained và chỉ huấn luyện prompt. Mặc dù chi phí tính toán được giảm đáng kể so với fine tuning, tính toán cho
suy luận mô hình vẫn giữ nguyên. Các nghiên cứu tương lai có thể xem xét thêm sự phối hợp giữa tác vụ huấn luyện tiết kiệm tham số và nén mô hình (ví dụ distillation hoặc pruning), để
mô hình kết quả cũng có thể hưởng lợi từ chi phí tính toán giảm trong quá trình suy luận.
Phụ lục
Lộ trình. Trong Phần A, chúng tôi cung cấp một số ký hiệu cơ bản. Trong Phần B, chúng tôi cung cấp
một số định nghĩa cơ bản và thảo luận một số nghiên cứu liên quan về các kết quả hồi quy softmax lý thuyết trước. Trong Phần C, chúng tôi cung cấp một chứng minh hoàn chỉnh cho kết quả lý thuyết chính của chúng tôi trong bài báo này.
Chúng tôi trình bày kết quả cuối cùng của chúng tôi trong Phần D.
A Sơ bộ
Đối với bất kỳ số nguyên dương n nào, chúng tôi sử dụng [ n] để ký hiệu tập hợp {1,2,···, n}. Đối với bất kỳ hàm f nào, chúng tôi sử dụng eO(g)
để ký hiệu g·poly(log g).
Vector Đối với một vector có độ dài n z, chúng tôi sử dụng exp( z) để ký hiệu một vector có độ dài n mà phần tử thứ i của nó là
exp(zi).
Đối với một vector có độ dài n z, chúng tôi sử dụng ∥z∥2 để biểu diễn chuẩn ℓ2 của nó, tức là, ∥z∥2:= (Pn
i=1x2
i)1/2. Đối với một vector có độ dài n z, chúng tôi sử dụng ∥z∥∞ để ký hiệu max i∈[n]|zi|.
Đối với một vector có độ dài n z∈Rn, chúng tôi sử dụng diag( z) để tạo ra một ma trận chéo nơi mỗi phần tử
trên đường chéo ( i, i) là zi cho mọi i∈[n].
Chúng tôi sử dụng 1n để biểu diễn một vector có độ dài n nơi tất cả các tọa độ đều là một. Tương tự, chúng tôi sử dụng
0n để biểu diễn một vector có độ dài n nơi tất cả các giá trị đều là không.
PSD Chúng tôi nói W⪰Z (positive semi-definite) nếu x⊤Wx≥x⊤Zx cho tất cả vector x.
11

--- TRANG 13 ---
Liên quan đến Ma trận Đối với một ma trận n×d C, chúng tôi sử dụng nnz( C) để ký hiệu số lượng phần tử khác không
của C, tức là, nnz( C) :=|{(i, j)∈[n]×[d]|Ci,j̸= 0}|
Đối với một ma trận chéo D∈Rn×n, chúng tôi nói D là một ma trận chéo k-sparse, tức là, k=|{i∈
[n]|Di,i̸= 0}|.
Đối với bất kỳ ma trận Z∈Rn×k nào, chúng tôi ký hiệu chuẩn phổ của Z bởi ∥Z∥, tức là,
∥Z∥:= sup
x∈Rk∥Zx∥2
∥x∥2.
Đối với một ma trận Q, chúng tôi sử dụng σmax(Q) để ký hiệu giá trị đơn lớn nhất của Q. Chúng tôi sử dụng σmin(Q) để
ký hiệu giá trị đơn nhỏ nhất của Q.
Tính toán Ma trận Chúng tôi sử dụng ω để ký hiệu số mũ của phép nhân ma trận, tức là, nω ký hiệu
thời gian nhân một ma trận n×n với một ma trận n×n khác. Hiện tại ω≈2.373 [Wil12,
LG14, AW21].
Liên quan đến Tính toán Chúng tôi sử dụng ký hiệu ◦ bằng cách tuân theo tài liệu [LSZ23, DLS23, GSY23b,
LSX+23, SSZ23]. Giả sử rằng chúng ta được cho hai vector cột x, y∈Rn, chúng tôi sử dụng x◦y để ký hiệu một vector cột mà ( x◦y)i là xiyi.
B Nghiên cứu Liên quan về Kết quả Hồi quy Attention Lý thuyết
Trong bài báo này, chúng tôi tập trung vào hướng của các tác vụ hồi quy [GMS23, LSZ23, DLS23, LSX+23, SSZ23].
Mục tiêu của phần này sẽ xem xét hồi quy tuyến tính (Định nghĩa B.1), hồi quy mũ
(Định nghĩa B.2), hồi quy softmax tái tỷ lệ (Định nghĩa B.3), hồi quy softmax (Định nghĩa B.2).
Định nghĩa B.1 (Hồi quy tuyến tính) . Cho một ma trận A∈Rn×d và b∈Rn, mục tiêu là giải quyết
min
x∈Rd∥Ax−b∥2.
Để thuận tiện, gọi u(x) để ký hiệu exp(Ax).
Định nghĩa B.2 (Hồi quy Mũ, xem [GMS23, LSZ23]) . Giả sử chúng ta được cho một vector có độ dài n
b, và một ma trận có kích thước n×d A, mục tiêu của chúng ta là tối ưu hóa
min
x∈Rd∥u(x)−b∥2.
Định nghĩa B.3 (Hồi quy Softmax Tái tỷ lệ, xem [GSY23b]) . Giả sử chúng ta được cho một vector có độ dài n
b, và một ma trận có kích thước n×d A, mục tiêu của chúng ta là tối ưu hóa
min
x∈Rd∥u(x)− ⟨u(x),1n⟩ ·b∥2
Định nghĩa B.4 (Hồi quy Softmax, xem [DLS23, LSX+23, SSZ23]) . Giả sử chúng ta được cho một vector có độ dài n b, và một ma trận có kích thước n×d A, mục tiêu của chúng ta là tối ưu hóa
min
x∈Rd∥⟨u(x),1n⟩−1·u(x)−b∥2.
12

--- TRANG 14 ---
C Đảm bảo Lý thuyết
Trong Phần C.1, chúng tôi cung cấp một số định nghĩa cơ bản. Trong Phần C.2, chúng tôi giải thích cách tính toán
gradient của hàm f. Trong Phần C.3, chúng tôi cho thấy cách tính toán gradient của hàm log f(x).
Trong Phần C.4, chúng tôi giải thích cách tính toán Hessian của hàm log f(x). Trong Phần C.5, chúng tôi
tính toán hessian của tích vô hướng giữa log f(x) và b. Trong Phần C.6, chúng tôi tính toán
Hessian của hàm mất mát cross entropy. Trong Phần C.7, chúng tôi cho thấy Hessian là positive definite. Trong Phần C.8, chúng tôi chứng minh rằng Hessian là Lipschitz.
C.1 Định nghĩa Hàm
Chúng tôi định nghĩa
Định nghĩa C.1. Chúng tôi định nghĩa u(x) như sau
•u(x) = exp( Ax)
Định nghĩa C.2. Chúng tôi định nghĩa v(x) như sau
•v(x) = exp( Ax)
Nghiên cứu trước [LSZ23] nghiên cứu ba loại hàm hyperbolic exp( ·), cosh( ·) và sinh( ·). Chúng tôi
chủ yếu tập trung vào hàm exp( ·).
Định nghĩa C.3 (Hệ số chuẩn hóa, Định nghĩa 5.4 trong [DLS23]) . Chúng tôi định nghĩa α:Rd→R như
sau
α(x) :=⟨u(x),1n⟩.
Chúng tôi định nghĩa hàm softmax f như sau
Định nghĩa C.4 (Hàm f, Định nghĩa 5.1 trong [DLS23]) . Giả sử rằng chúng ta được cho một ma trận n×d
A. Gọi 1n ký hiệu một vector có độ dài n mà tất cả các tọa độ đều là một. Chúng tôi định nghĩa hàm dự đoán
f:Rd→Rn như sau
f(x) :=⟨u(x),1n⟩−1·u(x).
Sự kiện C.5. Gọi f(x) được định nghĩa như Định nghĩa C.4. Khi đó chúng ta có
•Phần 1. ⟨f(x),1n⟩= 1
•Phần 2. ∥f(x)∥1= 1
•Phần 3. ∥f(x)∥2≤1
Chứng minh. Chứng minh là đơn giản. Để biết thêm chi tiết, chúng tôi tham khảo độc giả đến [DLS23].
Chúng tôi định nghĩa mất mát ℓ2
Định nghĩa C.6. Chúng tôi định nghĩa
Lexp:= 0.5∥f(x)−b∥2
2.
Nghiên cứu trước [SSZ23] chỉ xem xét entropy, ở đây chúng tôi xem xét cross entropy thay thế.
Định nghĩa C.7 (Cross Entropy) . Chúng tôi định nghĩa Lcent:Rd→R,
Lcent(x) :=−⟨b,logf(x)⟩
Định nghĩa C.8. Giả sử chúng ta được cho một ma trận n×d A và W= diag( w)∈Rn×n nơi w∈Rn
là một vector, chúng tôi định nghĩa Lreg:Rd→R
Lreg(x) := 0 .5∥WAx∥2
2
13

--- TRANG 15 ---
C.2 Tính toán Gradient cho Hàm f
Chúng tôi trình bày một công cụ tính toán từ nghiên cứu trước [DLS23] (ví dụ, chúng tôi tham khảo độc giả đến Lemma
5.6 trong [DLS23]).
Lemma C.9. Nếu các điều kiện sau đúng
•Cho ma trận A∈Rn×d và một vector b∈Rn.
•Giả sử rằng hàm α:Rd→R được định nghĩa trong Định nghĩa C.3.
•Giả sử rằng hàm f:Rd→Rn được định nghĩa trong Định nghĩa C.4.
Đối với mỗi i∈[d], chúng ta có
•Phần 1.
df(x)
dxi=− ⟨f(x), A∗,i⟩ ·f(x) +f(x)◦A∗,i
•Phần 2.
⟨df(x)
dxi, A∗,i⟩=−⟨f(x), A∗,i⟩2+⟨f(x), A∗,i◦A∗,i⟩
•Phần 3.
⟨df(x)
dxi, A∗,j⟩=−⟨f(x), A∗,i⟩ · ⟨f(x), A∗,j⟩+⟨f(x), A∗,i◦A∗,j⟩
C.3 Tính toán Gradient cho Hàm logf(x)
Trong phần này, chúng tôi giải thích cách tính toán gradient của log f(x).
Lemma C.10. Nếu điều kiện sau đúng
•Giả sử rằng hàm f được định nghĩa trong Định nghĩa C.4.
Chúng ta có
•Phần 1.
d logf(x)
dxi=−⟨f(x), A∗,i⟩ ·1n+A∗,i
•Phần 2.
⟨d logf(x)
dxi, b⟩=⟨A∗,i, b⟩ − ⟨f(x), A∗,i⟩ · ⟨b,1n⟩
•Phần 3.
d
dxiLcent(x) =⟨f(x), A∗,i⟩ · ⟨b,1n⟩ − ⟨A∗,i, b⟩
14

--- TRANG 16 ---
Chứng minh. Chứng minh của Phần 1.
Đối với tất cả chỉ số j∈[n], chúng ta có thể tính toán gradient đối với xi
d logf(x)j
dxi=f(x)−1
jdf(x)j
dxi
Sau đó chúng ta nhóm n tọa độ, chúng ta có
d logf(x)
dxi=f(x)−1◦df(x)
dxi
=f(x)−1◦(−⟨f(x), A∗,i⟩f(x) +f(x)◦A∗,i)
=− ⟨f(x), A∗,i⟩f(x)−1◦f(x) +f(x)−1◦f(x)◦A∗,i
=− ⟨f(x), A∗,i⟩ ·1n+A∗,i
Chứng minh của Phần 2. Chúng ta có
⟨d logf(x)
dxi, b⟩=⟨−⟨f(x), A∗,i⟩ ·1n+A∗,i, b⟩
=⟨A∗,i, b⟩ − ⟨f(x), A∗,i⟩ · ⟨b,1n⟩,
trong đó bước đầu tiên tuân theo Phần 1 và bước thứ hai tuân theo đại số đơn giản.
Chứng minh của Phần 3. Chứng minh trực tiếp tuân theo Phần 2 và Định nghĩa của Lcent(x) (Xem
Định nghĩa C.7).
C.4 Tính toán Hessian cho Hàm logf(x)
Trong phần này, chúng tôi sẽ cho thấy cách tính toán Hessian cho hàm log f(x).
Lemma C.11. Nếu các điều kiện sau đúng
•Gọi f được định nghĩa như Định nghĩa C.4.
Khi đó chúng ta có
•Phần 1.
d2logf(x)
dx2
i= (⟨f(x), A∗,i⟩2− ⟨f(x), A∗,i◦A∗,i⟩)·1n
•Phần 2.
d2logf(x)
dxidxj= (⟨f(x), A∗,i⟩⟨f(x), A∗,j⟩ − ⟨f(x), A∗,i◦A∗,j⟩)·1n
Chứng minh. Chứng minh của Phần 1.
Chúng ta có
d2logf(x)
dx2
i=d
dxi(d logf(x)
dxi)
=d
dxi(−⟨f(x), A∗,i⟩ ·1n+A∗,i)
=−d
dxi(⟨f(x), A∗,i⟩)·1n
= (⟨f(x), A∗,i⟩2− ⟨f(x), A∗,i◦A∗,i⟩)·1n
15

--- TRANG 17 ---
trong đó bước thứ 2 đến từ Phần 1 của Lemma C.10, bước thứ 3 tuân theo A∗,i độc lập
với x, và bước thứ tư tuân theo Phần 2 của Lemma C.9.
Chứng minh của Phần 2.
Tương tự, chúng ta có thể cung cấp một chứng minh cho Phần 2.
C.5 Tính toán Hessian cho Hàm ⟨logf(x), b⟩
Mục tiêu của phần này là chứng minh Lemma C.12.
Lemma C.12. Nếu các điều kiện sau đúng
•Gọi f được định nghĩa như Định nghĩa C.4.
Khi đó chúng ta có
•Phần 1.
⟨d2logf(x)
dx2
i, b⟩= (⟨f(x), A∗,i⟩2− ⟨f(x), A∗,i◦A∗,i⟩)· ⟨1n, b⟩
•Phần 2.
⟨d2logf(x)
dxidxj, b⟩= (⟨f(x), A∗,i⟩⟨f(x), A∗,j⟩ − ⟨f(x), A∗,i◦A∗,j⟩)· ⟨1n, b⟩
Chứng minh. Chứng minh trực tiếp tuân theo Lemma C.11.
C.6 Tính toán Hessian cho Hàm Lcent(x)
Để thuận tiện phân tích ma trận Hessian d×d, chúng tôi sẽ bắt đầu với việc định nghĩa ma trận B n×n.
Định nghĩa C.13. Chúng tôi định nghĩa B(x)∈Rn×n như sau
B(x) :=⟨1n, b⟩ ·(diag( f(x))−f(x)f(x)⊤)
Lemma C.14. Nếu các điều kiện sau đúng
•Gọi f được định nghĩa như Định nghĩa C.4.
•Gọi Lcent được định nghĩa như Định nghĩa C.7
•Gọi B được định nghĩa như Định nghĩa C.13
Khi đó chúng ta có
•Phần 1.
d2
dx2
iLcent= (−⟨f(x), A∗,i⟩2+⟨f(x), A∗,i◦A∗,i⟩)· ⟨1n, b⟩
•Phần 2.
d2
dxidxjLcent= (−⟨f(x), A∗,i⟩⟨f(x), A∗,j⟩+⟨f(x), A∗,i◦A∗,j⟩)· ⟨1n, b⟩
•Phần 3.
d2
dx2Lcent=A⊤B(x)A
Chứng minh. Chứng minh tự nhiên tuân theo Lemma C.12 và Định nghĩa C.13.
16

--- TRANG 18 ---
C.7 Hessian là Positive Definite
Nghiên cứu trước [DLS23] không xem xét cross entropy trong hàm mất mát cuối cùng. Ở đây chúng tôi tổng quát hóa
lemma trước để cross entropy cũng được xem xét.
Lemma C.15 (Một tổng quát hóa cross entropy của Lemma 6.3 trong [DLS23]) . Giả sử các điều kiện sau
đúng
•Gọi A∈Rn×d,R≥4,l >0, giả sử rằng R0= exp( O(R2+ log n))
•
L(x) = Lreg(x)|{z}
Định nghĩa C .8+Lcent(x)|{z}
Định nghĩa C .7+Lexp(x)|{z}
Định nghĩa C .6.
•Gọi eB(x) =B(x) +W2
Khi đó chúng ta có
•Phần 1. mini∈[n]w2
i≥10R0+l/σmin(A)2, khi đó chúng ta có
d2L
dx2⪰l·Id
•Phần 2. mini∈[n]w2
i≥104·R0+l/σmin(A)2, khi đó chúng ta có
(1−0.01)·eB(x)⪯W2⪯(1−0.01)·eB(x).
Chứng minh. Sử dụng định nghĩa của B cho Lcent (xem Định nghĩa C.13), định nghĩa/cận của B cho Lexp (xem
[DLS23]), và các công cụ được phát triển trong Phần 6 trong [DLS23], chúng ta có thể hoàn thành chứng minh.
C.8 Hessian là Lipschitz
Nghiên cứu trước [DLS23] không xem xét cross entropy trong hàm mất mát cuối cùng. Ở đây chúng tôi tổng quát hóa
lemma trước để cross entropy cũng được xem xét.
Lemma C.16 (Một phiên bản cross entropy của Lemma 7.1 trong [DLS23]) . Giả sử điều kiện sau
đúng
•Gọi H(x) =d2L
dx2 và R >4
•Giả sử rằng max{∥x∥2,∥y∥2} ≤R, và max{∥A∥,∥b∥2} ≤R
•∥A(x−y)∥∞<0.01
Khi đó chúng ta có
∥H(x)−H(y)∥ ≤n4exp(O(R2+ log n))· ∥x−y∥2
Chứng minh. Sử dụng định nghĩa của B cho Lcent (xem Định nghĩa C.13), định nghĩa/cận của B cho Lexp (xem
[DLS23]), và các công cụ được phát triển trong Phần 7 trong [DLS23], chúng ta có thể hoàn thành chứng minh.
17

--- TRANG 19 ---
Thuật toán 1 Thuật toán của chúng tôi.
1:procedure ThuậtToánCủaChúngTôi (A∈Rn×d, b∈Rn, w∈Rn, ϵ, δ) ▷Định lý D.1
2: Chúng tôi chọn x0
3: T←log(∥x0−x∗∥2/ϵ) ▷ T ký hiệu số lần lặp
4: for t= 0→T do
5: Xây dựng Hessian chính xác một cách ngầm định và sử dụng điều đó để xây dựng một Hessian xấp xỉ eH
(tương tự như Phần 8 trong [DLS23])
6: Tính toán gradient
7: eH←A⊤eDA
8: xt+1←xt+eH−1g
9: end for
10:ex←xT+1
11: return ex
12:end procedure
D Đảm bảo Lý thuyết Chính
Nghiên cứu trước [DLS23] đã chứng minh kết quả tương tự mà không xem xét cross entropy. Chúng tôi
tổng quát hóa các kỹ thuật trong bài báo trước [DLS23] từ chỉ xem xét task loss ℓ2 đến xem xét cả task loss ℓ2 và cross entropy loss (Lcent xem định nghĩa chính thức trong Định nghĩa C.7). Thuật toán của chúng tôi là một phiên bản của phương pháp Newton xấp xỉ, các phương pháp như vậy đã được sử dụng rộng rãi trong nhiều tác vụ tối ưu hóa [CLS19, LSZ19, Bra20, JKL+20, SY21, JSWZ21, DLY21, GS22, SYYZ22,
HJS+22, QSZZ23, DLS23]. Trong nghiên cứu này, chúng tôi tập trung vào phương pháp Newton xấp xỉ theo hướng của [SYYZ22, DLS23].
Định lý D.1 (Phiên bản chính thức của Định lý 3.1) . Gọi x∗ ký hiệu một vector có độ dài d thỏa mãn,
arg min
x∈RdLexp|{z}
Định nghĩa C .6+ Lcent|{z}
Định nghĩa C .7+ Lreg|{z}
Định nghĩa C .8
Giả sử các điều kiện sau đang giữ:
•R≥4,g(x∗) =0d.
•∥x∗∥2≤R,∥A∥ ≤R,∥b∥2≤R.
•M= exp( O(R2+ log n)).
•mini∈[n]w2
i≥100M+l/σmin(A)2
•Giả sử rằng ϵ∈(0,0.1) là cuối cùng và δ∈(0,0.1) là xác suất thất bại.
•Giả sử x0 thỏa mãn điều kiện M∥x0−x∗∥2≤0.1l.
•Giả sử rằng T= log( ∥x0−x∗∥2/ϵ)
Khi đó có một thuật toán ngẫu nhiên (Thuật toán 1) sao cho
•nó chạy T lần lặp
18

--- TRANG 20 ---
•trong mỗi lần lặp, nó dành thời gian1
O((nnz( A) +dω)·poly(log( n/δ)).
•tạo ra một vector ex∈Rd thỏa mãn
∥ex−x∗∥2≤ϵ
•xác suất thành công là 1−δ
Chứng minh. Khung cấp cao của định lý chúng tôi tương tự như nghiên cứu trước về hồi quy mũ [LSZ23], hồi quy softmax [DLS23] và hồi quy softmax tái tỷ lệ [GSY23b]. Tương tự như nghiên cứu trước [LSZ23, DLS23, GSY23b, SSZ23], chúng tôi sử dụng thuật toán newton xấp xỉ (ví dụ xem Phần 8 trong [DLS23]). Vì vậy trong chứng minh, chúng tôi chỉ tập trung vào sự khác biệt về cận dưới positive definite của Hessian và tính chất Lispchitz của Hessian.
Sử dụng Lemma C.15 và Lemma C.16 và phân tích thuật toán Newton xấp xỉ trong [DLS23],
sau đó chúng tôi hoàn thành chứng minh.
Tài liệu tham khảo
[AS23] Josh Alman và Zhao Song. Fast attention requires bounded entries. arXiv preprint
arXiv:2302.13214 , 2023.
[ASPH22] Akari Asai, Mohammadreza Salehi, Matthew E. Peters, và Hannaneh Hajishirzi. At-
tempt: Parameter-efficient multi-task tuning via attentional mixtures of soft prompts,
2022.
[AW21] Josh Alman và Virginia Vassilevska Williams. A refined laser method and faster
matrix multiplication. In Proceedings of the 2021 ACM-SIAM Symposium on Discrete
Algorithms (SODA) , pages 522–539. SIAM, 2021.
[BCDG09] Luisa Bentivogli, Peter Clark, Ido Dagan, và Danilo Giampiccolo. The fifth pascal
recognizing textual entailment challenge. In TAC, 2009.
[BNS19] Jan van den Brand, Danupon Nanongkai, và Thatchaphol Saranurak. Dynamic ma-
trix inverse: Improved algorithms and matching conditional lower bounds. In 2019
IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS) , pages
456–480. IEEE, 2019.
[Bra20] Jan van den Brand. A deterministic linear program solver in current matrix multi-
plication time. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on
Discrete Algorithms (SODA) , pages 259–278. SIAM, 2020.
[BSH22] Rishabh Bhardwaj, Amrita Saha, và Steven CH Hoi. Vector-quantized input-
contextualized soft prompts for natural language understanding. arXiv preprint
arXiv:2205.11024 , 2022.
[BSZ23] Jan van den Brand, Zhao Song, và Tianyi Zhou. Algorithm and hardness for dynamic
attention maintenance in large language models. arXiv preprint arXiv:2304.02207 ,
2023.
1Ở đây ω ký hiệu số mũ của phép nhân ma trận. Hiện tại ω≈2.373.
19

--- TRANG 21 ---
[CDW+21] Zewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham Singhal, Wenhui Wang, Xia
Song, Xian-Ling Mao, He-Yan Huang, và Ming Zhou. Infoxlm: An information-
theoretic framework for cross-lingual language model pre-training. In Proceedings of the
2021 Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies , pages 3576–3588, 2021.
[CHBC20] Xingyu Cai, Jiaji Huang, Yuchen Bian, và Kenneth Church. Isotropy in the con-
textual embedding space: Clusters and manifolds. In International Conference on
Learning Representations , 2020.
[CHH22] Yuxuan Chen, David Harbecke, và Leonhard Hennig. Multilingual relation classifi-
cation via efficient and effective prompting. arXiv preprint arXiv:2210.13838 , 2022.
[CKLM19] Kevin Clark, Urvashi Khandelwal, Omer Levy, và Christopher D Manning. What
does bert look at? an analysis of bert's attention. In Proceedings of the 2019 ACL
Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP , pages
276–286, 2019.
[CLS19] Michael B Cohen, Yin Tat Lee, và Zhao Song. Solving linear programs in the current
matrix multiplication time. In STOC , 2019.
[Cov99] Thomas M Cover. Elements of information theory . John Wiley & Sons, 1999.
[CZX+22] Xiang Chen, Ningyu Zhang, Xin Xie, Shumin Deng, Yunzhi Yao, Chuanqi Tan, Fei
Huang, Luo Si, và Huajun Chen. Knowprompt: Knowledge-aware prompt-tuning
with synergistic optimization for relation extraction. In Proceedings of the ACM Web
Conference 2022 , pages 2778–2788, 2022.
[DB05] Bill Dolan và Chris Brockett. Automatically constructing a corpus of sentential
paraphrases. In Third International Workshop on Paraphrasing (IWP2005) , 2005.
[DCLT19] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: Pre-
training of deep bidirectional transformers for language understanding. In Proceedings
of the 2019 Conference of the North American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) ,
pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational
Linguistics.
[DKM+06] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, và Moni
Naor. Our data, ourselves: Privacy via distributed noise generation. In Annual In-
ternational Conference on the Theory and Applications of Cryptographic Techniques ,
pages 486–503. Springer, 2006.
[DLS23] Yichuan Deng, Zhihang Li, và Zhao Song. Attention scheme inspired softmax regres-
sion. arXiv preprint arXiv:2304.10411 , 2023.
[DLY21] Sally Dong, Yin Tat Lee, và Guanghao Ye. A nearly-linear time algorithm for linear
programs with small treewidth: A multiscale representation of robust central path. In
Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing ,
pages 1784–1797, 2021.
20

--- TRANG 22 ---
[DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, và Adam Smith. Calibrating noise to
sensitivity in private data analysis. In Theory of Cryptography: Third Theory of Cryp-
tography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings
3, pages 265–284. Springer, 2006.
[DMS23] Yichuan Deng, Sridhar Mahadevan, và Zhao Song. Randomized and deterministic
attention sparsification algorithms for over-parameterized feature dimension. arxiv
preprint: arxiv 2304.03426 , 2023.
[DWL+22] Kun Ding, Ying Wang, Pengzhang Liu, Qiang Yu, Haojian Zhang, Shiming Xiang, và
Chunhong Pan. Prompt tuning with soft context sharing for vision-language models.
arXiv preprint arXiv:2208.13474 , 2022.
[GHLH22] Yuxian Gu, Xu Han, Zhiyuan Liu, và Minlie Huang. Ppt: Pre-trained prompt tuning
for few-shot learning. In Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers) , pages 8410–8423, 2022.
[GMS23] Yeqi Gao, Sridhar Mahadevan, và Zhao Song. An over-parameterized exponential
regression. arXiv preprint arXiv:2303.16504 , 2023.
[GS22] Yuzhou Gu và Zhao Song. A faster small treewidth sdp solver. arXiv preprint
arXiv:2211.06033 , 2022.
[GSY23a] Yeqi Gao, Zhao Song, và Xin Yang. Differentially private attention computation.
arXiv preprint arXiv:2305.04701 , 2023.
[GSY23b] Yeqi Gao, Zhao Song, và Junze Yin. An iterative algorithm for rescaled hyperbolic
functions regression. arXiv preprint arXiv:2305.00660 , 2023.
[HCD+16] Rein Houthooft, Xi Chen, Yan Duan, John Schulman, Filip De Turck, và Pieter
Abbeel. Vime: Variational information maximizing exploration. Advances in neural
information processing systems , 29, 2016.
[HDW+21] Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Juanzi Li, và Maosong
Sun. Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer
for text classification. arXiv preprint arXiv:2108.02035 , 2021.
[HJS+22] Baihe Huang, Shunhua Jiang, Zhao Song, Runzhou Tao, và Ruizhe Zhang. Solving
sdp faster: A robust ipm framework and efficient implementation. In 2022 IEEE
63rd Annual Symposium on Foundations of Computer Science (FOCS) , pages 233–
244. IEEE, 2022.
[HKK+19] Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid O
S´ eaghdha, Sebastian Pad´ o, Marco Pennacchiotti, Lorenza Romano, và Stan Szpakow-
icz. Semeval-2010 task 8: Multi-way classification of semantic relations between pairs
of nominals. arXiv preprint arXiv:1911.10422 , 2019.
[HKM21] Karen Hambardzumyan, Hrant Khachatrian, và Jonathan May. Warp: Word-level
adversarial reprogramming. In Proceedings of the 59th Annual Meeting of the Asso-
ciation for Computational Linguistics and the 11th International Joint Conference on
Natural Language Processing (Volume 1: Long Papers) , pages 4921–4933, 2021.
21

--- TRANG 23 ---
[HMZ+22] Lianzhe Huang, Shuming Ma, Dongdong Zhang, Furu Wei, và Houfeng Wang. Zero-
shot cross-lingual transfer of prompt-based tuning with a unified multilingual prompt.
arXiv preprint arXiv:2202.11451 , 2022.
[HWSW22] Keqing He, Jingang Wang, Chaobo Sun, và Wei Wu. Unified knowledge prompt pre-
training for customer service dialogues. In Proceedings of the 31st ACM International
Conference on Information & Knowledge Management , pages 4009–4013, 2022.
[HZT+22] Yun He, Steven Zheng, Yi Tay, Jai Gupta, Yu Du, Vamsi Aribandi, Zhe Zhao, YaGuang
Li, Zhao Chen, Donald Metzler, et al. Hyperprompt: Prompt-based task-conditioning
of transformers. In International Conference on Machine Learning , pages 8678–8690.
PMLR, 2022.
[JKL+20] Haotian Jiang, Tarun Kathuria, Yin Tat Lee, Swati Padmanabhan, và Zhao Song. A
faster interior point method for semidefinite programming. In 2020 IEEE 61st annual
symposium on foundations of computer science (FOCS) , pages 910–918. IEEE, 2020.
[JLK+21] Jiaxin Ju, Ming Liu, Huan Yee Koh, Yuan Jin, Lan Du, và Shirui Pan. Leverag-
ing information bottleneck for scientific document summarization. In Findings of the
Association for Computational Linguistics: EMNLP 2021 , pages 4091–4098, 2021.
[JSWZ21] Shunhua Jiang, Zhao Song, Omri Weinstein, và Hengjie Zhang. Faster dynamic
matrix inverse for faster lps. In STOC . arXiv preprint arXiv:2004.07470, 2021.
[JZZ+22] Baijun Ji, Tong Zhang, Yicheng Zou, Bojie Hu, và Si Shen. Increasing visual aware-
ness in multimodal neural machine translation from an information theoretic perspec-
tive. arXiv preprint arXiv:2210.08478 , 2022.
[KKL20] Nikita Kitaev,  Lukasz Kaiser, và Anselm Levskaya. Reformer: The efficient trans-
former. arXiv preprint arXiv:2001.04451 , 2020.
[LARC21] Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-
efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods
in Natural Language Processing , pages 3045–3059, 2021.
[LBL+22] Xiaochen Liu, Yu Bai, Jiawei Li, Yinan Hu, và Yang Gao. Psp: Pre-trained soft
prompts for few-shot abstractive summarization. arXiv preprint arXiv:2204.04413 ,
2022.
[LG14] Fran¸ cois Le Gall. Powers of tensors and fast matrix multiplication. In Proceedings
of the 39th international symposium on symbolic and algebraic computation , pages
296–303, 2014.
[LL21] Xiang Lisa Li và Percy Liang. Prefix-tuning: Optimizing continuous prompts for
generation. arXiv preprint arXiv:2101.00190 , 2021.
[LLY22] Chi-Liang Liu, Hung-yi Lee, và Wen-tau Yih. Structured prompt tuning. arXiv
preprint arXiv:2205.12309 , 2022.
[LOG+19] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. Roberta: A robustly
optimized bert pretraining approach. ArXiv , abs/1907.11692, 2019.
22

--- TRANG 24 ---
[LSX+23] Shuai Li, Zhao Song, Yu Xia, Tong Yu, và Tianyi Zhou. The closeness of in-context
learning and weight shifting for softmax regression. arXiv preprint arXiv:2304.13276 ,
2023.
[LSZ19] Yin Tat Lee, Zhao Song, và Qiuyi Zhang. Solving empirical risk minimization in the
current matrix multiplication time. In COLT , 2019.
[LSZ23] Zhihang Li, Zhao Song, và Tianyi Zhou. Solving regularized exp, cosh and sinh
regression problems. arXiv preprint arXiv:2303.15725 , 2023.
[MBH21] Rabeeh Karimi Mahabadi, Yonatan Belinkov, và James Henderson. Varia-
tional information bottleneck for effective low-resource fine-tuning. arXiv preprint
arXiv:2106.05469 , 2021.
[MC18] Zhuang Ma và Michael Collins. Noise contrastive estimation and negative sam-
pling for conditional models: Consistency and statistical efficiency. arXiv preprint
arXiv:1809.01812 , 2018.
[MCC+19] Kory W Mathewson, Pablo Samuel Castro, Colin Cherry, George Foster, và Marc G
Bellemare. Shaping the narrative arc: An information-theoretic approach to collabo-
rative dialogue. arXiv preprint arXiv:1901.11528 , 2019.
[NCG16] Thien Huu Nguyen, Kyunghyun Cho, và Ralph Grishman. Joint event extraction
via recurrent neural networks. In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language
Technologies , pages 300–309, 2016.
[PH21] Vishakh Padmakumar và He He. Unsupervised extractive summarization using point-
wise mutual information. In Proceedings of the 16th Conference of the European Chap-
ter of the Association for Computational Linguistics: Main Volume , pages 2505–2512,
2021.
[QE21] Guanghui Qin và Jason Eisner. Learning how to ask: Querying lms with mixtures of
soft prompts. In Proceedings of the 2021 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies , pages
5203–5212, 2021.
[QSZZ23] Lianke Qin, Zhao Song, Lichen Zhang, và Danyang Zhuo. An online and unified
algorithm for projection matrix vector multiplication with application to empirical
risk minimization. In AISTATS , 2023.
[QWS+21] Yujia Qin, Xiaozhi Wang, YuSheng Su, Yankai Lin, Ning Ding, Zhiyuan Liu, Juanzi
Li, Lei Hou, Peng Li, Maosong Sun, và Jie Zhou. Exploring low-dimensional intrinsic
task subspace via prompt tuning. CoRR , abs/2110.07867, 2021.
[SDJS22] Victor Steinborn, Philipp Dufter, Haris Jabbar, và Hinrich Sch¨ utze. An information-
theoretic approach and dataset for probing gender stereotypes in multilingual masked
language models. In Findings of the Association for Computational Linguistics:
NAACL 2022 , pages 921–932, 2022.
[Sha48] Claude Elwood Shannon. A mathematical theory of communication. The Bell system
technical journal , 27(3):379–423, 1948.
23

--- TRANG 25 ---
[SPW+13] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning,
Andrew Y Ng, và Christopher Potts. Recursive deep models for semantic composi-
tionality over a sentiment treebank. In Proceedings of the 2013 conference on empirical
methods in natural language processing , pages 1631–1642, 2013.
[SRdV22] Nathan Schucher, Siva Reddy, và Harm de Vries. The power of prompt tuning
for low-resource semantic parsing. In Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume 2: Short Papers) , pages 148–156,
2022.
[SRR+22] Taylor Sorensen, Joshua Robinson, Christopher Rytting, Alexander Shaw, Kyle
Rogers, Alexia Delorey, Mahmoud Khalil, Nancy Fulda, và David Wingate. An
information-theoretic approach to prompt engineering without ground truth labels. In
Proceedings of the 60th Annual Meeting of the Association for Computational Linguis-
tics (Volume 1: Long Papers) , pages 819–862, 2022.
[SSZ23] Ritwik Sinha, Zhao Song, và Tianyi Zhou. A mathematical abstraction for balancing
the trade-off between creativity and reality in large language models. arXiv preprint ,
2023.
[SWQ+22] Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang,
Kaiyue Wen, Zhiyuan Liu, Peng Li, Juanzi Li, et al. On transferability of prompt
tuning for natural language processing. In Proceedings of the 2022 Conference of the
North American Chapter of the Association for Computational Linguistics: Human
Language Technologies , pages 3949–3969, 2022.
[SY21] Zhao Song và Zheng Yu. Oblivious sketching-based central path method for solving
linear programming problems. In 38th International Conference on Machine Learning
(ICML) , 2021.
[SYYZ22] Zhao Song, Xin Yang, Yuanyuan Yang, và Tianyi Zhou. Faster algorithm for struc-
tured john ellipsoid computation. arXiv preprint arXiv:2211.14407 , 2022.
[VLC+22] Tu Vu, Brian Lester, Noah Constant, Rami Al-Rfou, và Daniel Cer. Spot: Better
frozen model adaptation through soft prompt transfer. In Proceedings of the 60th
Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers) , pages 5039–5059, 2022.
[WHBC19] Peter West, Ari Holtzman, Jan Buys, và Yejin Choi. Bottlesum: Unsupervised
and self-supervised sentence summarization using the information bottleneck principle,
2019.
[Wil12] Virginia Vassilevska Williams. Multiplying matrices faster than coppersmith-winograd.
In Proceedings of the forty-fourth annual ACM symposium on Theory of computing ,
pages 887–898, 2012.
[WLK+20] Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, và Hao Ma. Linformer:
Self-attention with linear complexity. arXiv preprint arXiv:2006.04768 , 2020.
[WS22] Hui Wu và Xiaodong Shi. Adversarial soft prompt tuning for cross-domain sentiment
analysis. In Proceedings of the 60th Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers) , pages 2438–2447, 2022.
24

--- TRANG 26 ---
[WSB19] Alex Warstadt, Amanpreet Singh, và Samuel R Bowman. Neural network accept-
ability judgments. Transactions of the Association for Computational Linguistics ,
7:625–641, 2019.
[WSM+18] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel R
Bowman. Glue: A multi-task benchmark and analysis platform for natural language
understanding. arXiv preprint arXiv:1804.07461 , 2018.
[WWC+20] Boxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan, Ruoxi Jia, Bo Li, và Jingjing
Liu. Infobert: Improving robustness of language models from an information theoretic
perspective. arXiv preprint arXiv:2010.02329 , 2020.
[WWG+22] Zhuofeng Wu, Sinong Wang, Jiatao Gu, Rui Hou, Yuxiao Dong, VG Vydiswaran, và
Hao Ma. Idpg: An instance-dependent prompt generation method. arXiv preprint
arXiv:2204.04497 , 2022.
[YJK+22] Seonghyeon Ye, Joel Jang, Doyoung Kim, Yongrae Jo, và Minjoon Seo. Retrieval of
soft prompt enhances zero-shot task generalization. arXiv preprint arXiv:2210.03029 ,
2022.
[YM16] Bishan Yang và Tom Mitchell. Joint extraction of events and entities within a doc-
ument context. arXiv preprint arXiv:1609.03632 , 2016.
[ZHDK23] Amir Zandieh, Insu Han, Majid Daliri, và Amin Karbasi. Kdeformer: Accelerating
transformers via kernel density estimation. arXiv preprint arXiv:2302.02451 , 2023.
[ZLM+22] Songming Zhang, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jian Liu, và
Jie Zhou. Conditional bilingual mutual information based adaptive training for neural
machine translation. In Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) , pages 2377–2389, 2022.
25

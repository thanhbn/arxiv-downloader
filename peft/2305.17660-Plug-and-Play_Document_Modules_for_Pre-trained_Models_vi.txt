# 2305.17660.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2305.17660.pdf
# Kích thước tệp: 1054306 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Các Module Tài liệu Cắm-và-Chạy cho Mô hình Tiền huấn luyện
Chaojun Xiao1,2,3, Zhengyan Zhang1,2,3, Xu Han1,2,3∗, Chi-Min Chan1,2,3, Yankai Lin4,5
Zhiyuan Liu1,2,3∗, Xiangyang Li6, Zhonghua Li6, Zhao Cao6, Maosong Sun1,2,3∗
1Nhóm NLP, DCST, IAI, BNRIST, Đại học Thanh Hoa, Bắc Kinh
2Trung tâm Đổi mới Quốc tế Đại học Thanh Hoa, Thượng Hải3Phòng thí nghiệm Quan Cheng
4Trường Trí tuệ Nhân tạo Gaoling, Đại học Nhân dân Trung Quốc, Bắc Kinh
5Phòng thí nghiệm Chính của Bắc Kinh về Phương pháp Quản lý và Phân tích Dữ liệu Lớn
6Công ty TNHH Công nghệ Huawei
xiaocj20@mails.tsinghua.edu.cn ,{hanxu2022,liuzy,sms}@tsinghua.edu.cn

Tóm tắt
Các mô hình tiền huấn luyện quy mô lớn (PTM) đã được sử dụng rộng rãi trong các tác vụ NLP hướng tài liệu, như trả lời câu hỏi. Tuy nhiên, yêu cầu ghép nối mã hóa-tác vụ dẫn đến việc mã hóa lặp lại cùng một tài liệu cho các tác vụ và truy vấn khác nhau, điều này rất kém hiệu quả về mặt tính toán. Để giải quyết vấn đề này, chúng tôi nhắm mục tiêu tách rời việc mã hóa tài liệu khỏi các tác vụ downstream, và đề xuất biểu diễn mỗi tài liệu như một module tài liệu cắm-và-chạy, tức là một plugin tài liệu, cho PTM (PlugD). Bằng cách chèn các plugin tài liệu vào PTM backbone cho các tác vụ downstream, chúng ta có thể mã hóa một tài liệu một lần để xử lý nhiều tác vụ, điều này hiệu quả hơn so với các phương pháp ghép nối mã hóa-tác vụ thông thường mà đồng thời mã hóa tài liệu và truy vấn đầu vào bằng các bộ mã hóa đặc thù tác vụ. Các thí nghiệm rộng rãi trên 8 bộ dữ liệu của 4 tác vụ NLP điển hình cho thấy PlugD cho phép các mô hình mã hóa tài liệu một lần và cho tất cả các tình huống khác nhau. Đặc biệt, PlugD có thể tiết kiệm 69% chi phí tính toán trong khi đạt được hiệu suất tương đương với các phương pháp ghép nối mã hóa-tác vụ hiện đại. Ngoài ra, chúng tôi cho thấy PlugD có thể phục vụ như một cách hậu xử lý hiệu quả để tiêm kiến thức vào các mô hình đặc thù tác vụ, cải thiện hiệu suất mô hình mà không cần huấn luyện mô hình bổ sung. Mã và checkpoint của chúng tôi có thể được tìm thấy tại https://github.com/thunlp/Document-Plugin.

1 Giới thiệu
Trong những năm gần đây, các mô hình tiền huấn luyện quy mô lớn (PTM) (Devlin et al., 2019; Raffel et al., 2020) đã được áp dụng rộng rãi và đạt được hiệu suất đột phá cho các tác vụ NLP hướng tài liệu, như trả lời câu hỏi. Tuy nhiên, do việc ghép nối chặt chẽ giữa mã hóa tài liệu và các tác vụ cụ thể, PTM phải tạo ra các biểu diễn tài liệu một cách động theo các tác vụ và truy vấn cụ thể, dẫn đến việc mã hóa lặp lại cùng một tài liệu trong các ứng dụng khác nhau.

Ví dụ, các tài liệu Wikipedia thường được sử dụng trong nhiều tác vụ thâm dụng kiến thức khác nhau như trả lời câu hỏi (Chen et al., 2017), xác minh sự thật (Thorne et al., 2018), và tạo ra đối thoại (Dinan et al., 2019). Trong trường hợp này, các phương pháp hiện tại mã hóa riêng biệt một tài liệu cho mỗi tác vụ hoặc thậm chí cho mỗi truy vấn đầu vào (ví dụ, một câu hỏi cho trả lời câu hỏi, một tuyên bố cho xác minh sự thật), khiến chúng rất kém hiệu quả về mặt tính toán.

Để giải quyết vấn đề này, nó đặt ra một câu hỏi tự nhiên: liệu chúng ta có thể tách rời việc mã hóa tài liệu khỏi các tác vụ cụ thể, mã hóa tài liệu chỉ một lần và với khả năng chuyển giao được đảm bảo qua nhiều tác vụ?

Đối với câu hỏi này, chúng tôi đề xuất một framework mới dựa trên PTM để tách rời việc mã hóa tài liệu khỏi các tác vụ, có tên là PlugD. Cụ thể, PlugD kết hợp các module cắm-và-chạy để lưu trữ thông tin tài liệu và sử dụng một backbone PTM để nắm bắt thông tin từ các plugin cho lý luận tác vụ. Như được hiển thị trong Hình 1, các tài liệu được mã hóa thành các plugin có thể cắm một lần và cho tất cả trước khi thích ứng tác vụ. Ngữ nghĩa và kiến thức của tài liệu có thể được tiêm vào các mô hình đặc thù tác vụ bằng cách cắm các plugin tài liệu. Trong quá trình lý luận tác vụ, các mô hình đặc thù tác vụ có thể kích hoạt thông tin được mã hóa trong các plugin tài liệu để xử lý các truy vấn đầu vào. Theo cách này, PlugD có thể tách rời việc mã hóa tài liệu khỏi lý luận tác vụ downstream và giảm chi phí tính toán.

Để biểu diễn các tài liệu như các module có thể cắm, có hai thách thức chính: (1) Học plugin: Các plugin tài liệu phải hiệu quả cho nhiều tác vụ downstream khác nhau, yêu cầu chúng chứa đủ ngữ nghĩa và kiến thức. (2) Sử dụng plugin: Khi các plugin tài liệu đã sẵn sàng, điều quan trọng là các mô hình đặc thù tác vụ nắm bắt thông tin liên quan từ chúng một cách hiệu quả cho lý luận tác vụ.

Đối với việc học plugin, chúng tôi áp dụng một phương pháp tự giám sát, yêu cầu các plugin tài liệu cung cấp đủ kiến thức cho PTM để đưa ra dự đoán. Cụ thể, đối với mỗi tài liệu, chúng tôi đầu tiên chọn ngẫu nhiên các phần của câu làm truy vấn và sử dụng các câu còn lại làm ngữ cảnh để học các plugin. Sau đó, sau khi mã hóa ngữ cảnh thành các plugin, mô hình được yêu cầu khôi phục các span lặp lại bị che hoặc tạo ra các câu tiếp theo cho truy vấn dựa trên kiến thức plugin.

Đối với việc sử dụng plugin, chúng tôi đề xuất hai chiến lược để sử dụng các plugin tài liệu cho các tác vụ downstream: cắm trong quá trình điều chỉnh và cắm sau điều chỉnh. Đối với cắm trong quá trình điều chỉnh, các plugin tài liệu được sử dụng trong cả giai đoạn điều chỉnh và suy luận. Dữ liệu tác vụ và các plugin tài liệu được kết hợp cùng nhau để huấn luyện các mô hình đặc thù tác vụ. Đối với cắm sau điều chỉnh, các plugin tài liệu chỉ được sử dụng trong giai đoạn suy luận để cung cấp kiến thức bên ngoài. Các plugin tài liệu được áp dụng như một cách hậu xử lý để tiêm kiến thức vào các mô hình đặc thù tác vụ mà không cần huấn luyện bổ sung.

Để xác minh hiệu quả của framework cắm-và-chạy của chúng tôi, chúng tôi áp dụng Wikipedia làm bộ sưu tập tài liệu và tiến hành thí nghiệm trên 8 bộ dữ liệu của 4 tác vụ NLP thâm dụng kiến thức điển hình. Kết quả cho thấy chúng ta có thể tạo ra các plugin tài liệu một lần và thành công thích ứng các plugin với nhiều tác vụ downstream khác nhau. So với các baseline cạnh tranh mà mã hóa đồng thời tài liệu và đầu vào đặc thù tác vụ, phương pháp dựa trên plugin của chúng tôi có thể tiết kiệm 69% chi phí tính toán với hiệu suất tương đương. Bên cạnh đó, việc sử dụng các plugin tài liệu hoạt động như một phương pháp hậu xử lý hiệu quả để đưa kiến thức của tài liệu vào các mô hình đặc thù tác vụ và đạt được cải thiện hiệu suất mà không cần huấn luyện mô hình. Chúng tôi lập luận rằng với xu hướng hiện tại là tăng kích thước mô hình của PTM, việc tách rời mã hóa tài liệu khỏi các tác vụ cụ thể như PlugD có thể là một hướng đi đầy hứa hẹn cho phép các PTM lớn phục vụ hiệu quả và hiệu suất cho các tác vụ downstream đa dạng.

--- TRANG 2 ---
ngữ nghĩa và kiến thức của tài liệu có thể được tiêm vào các mô hình đặc thù tác vụ bằng cách cắm các plugin tài liệu. Trong quá trình lý luận tác vụ, các mô hình đặc thù tác vụ có thể kích hoạt thông tin được mã hóa trong các plugin tài liệu để xử lý các truy vấn đầu vào. Theo cách này, PlugD có thể tách rời việc mã hóa tài liệu khỏi lý luận tác vụ downstream và giảm chi phí tính toán.

Để biểu diễn các tài liệu như các module có thể cắm, có hai thách thức chính: (1) Học plugin: Các plugin tài liệu phải hiệu quả cho nhiều tác vụ downstream khác nhau, yêu cầu chúng chứa đủ ngữ nghĩa và kiến thức. (2) Sử dụng plugin: Khi các plugin tài liệu đã sẵn sàng, điều quan trọng là các mô hình đặc thù tác vụ nắm bắt thông tin liên quan từ chúng một cách hiệu quả cho lý luận tác vụ.

Đối với việc học plugin, chúng tôi áp dụng một phương pháp tự giám sát, yêu cầu các plugin tài liệu cung cấp đủ kiến thức cho PTM để đưa ra dự đoán. Cụ thể, đối với mỗi tài liệu, chúng tôi đầu tiên chọn ngẫu nhiên các phần của câu làm truy vấn và sử dụng các câu còn lại làm ngữ cảnh để học các plugin. Sau đó, sau khi mã hóa ngữ cảnh thành các plugin, mô hình được yêu cầu khôi phục các span lặp lại bị che hoặc tạo ra các câu tiếp theo cho truy vấn dựa trên kiến thức plugin.

Đối với việc sử dụng plugin, chúng tôi đề xuất hai chiến lược để sử dụng các plugin tài liệu cho các tác vụ downstream: cắm trong quá trình điều chỉnh và cắm sau điều chỉnh. Đối với cắm trong quá trình điều chỉnh, các plugin tài liệu được sử dụng trong cả giai đoạn điều chỉnh và suy luận. Dữ liệu tác vụ và các plugin tài liệu được kết hợp cùng nhau để huấn luyện các mô hình đặc thù tác vụ. Đối với cắm sau điều chỉnh, các plugin tài liệu chỉ được sử dụng trong giai đoạn suy luận để cung cấp kiến thức bên ngoài. Các plugin tài liệu được áp dụng như một cách hậu xử lý để tiêm kiến thức vào các mô hình đặc thù tác vụ mà không cần huấn luyện bổ sung.

Để xác minh hiệu quả của framework cắm-và-chạy của chúng tôi, chúng tôi áp dụng Wikipedia làm bộ sưu tập tài liệu và tiến hành thí nghiệm trên 8 bộ dữ liệu của 4 tác vụ NLP thâm dụng kiến thức điển hình. Kết quả cho thấy chúng ta có thể tạo ra các plugin tài liệu một lần và thành công thích ứng các plugin với nhiều tác vụ downstream khác nhau. So với các baseline cạnh tranh mà mã hóa đồng thời tài liệu và đầu vào đặc thù tác vụ, phương pháp dựa trên plugin của chúng tôi có thể tiết kiệm 69% chi phí tính toán với hiệu suất tương đương. Bên cạnh đó, việc sử dụng các plugin tài liệu hoạt động như một phương pháp hậu xử lý hiệu quả để đưa kiến thức của tài liệu vào các mô hình đặc thù tác vụ và đạt được cải thiện hiệu suất mà không cần huấn luyện mô hình. Chúng tôi lập luận rằng với xu hướng hiện tại là tăng kích thước mô hình của PTM, việc tách rời mã hóa tài liệu khỏi các tác vụ cụ thể như PlugD có thể là một hướng đi đầy hứa hẹn cho phép các PTM lớn phục vụ hiệu quả và hiệu suất cho các tác vụ downstream đa dạng.

2 Công trình liên quan

2.1 Các Module Cắm-và-Chạy cho PTM

Các PTM gần đây đã cho thấy hiệu quả trong nhiều tác vụ downstream khác nhau (Devlin et al., 2019; Liu et al., 2019; Raffel et al., 2020; Radford et al., 2018; Brown et al., 2020; Han et al., 2021; Chowdhery et al., 2022). Tuy nhiên, việc huấn luyện và điều chỉnh các PTM quy mô lớn cho các tác vụ ngày càng tăng là tốn kém về tính toán và lưu trữ. Để giải quyết vấn đề này, việc xây dựng các module cắm-và-chạy với nhiều khả năng khác nhau cho PTM đã nhận được sự chú ý ngày càng tăng gần đây. Ví dụ, điều chỉnh hiệu quả tham số, còn được gọi là điều chỉnh delta, được đề xuất để thực hiện thích ứng tác vụ bằng cách tinh chỉnh chỉ một lượng nhỏ tham số và giữ các tham số khác cố định (Zaken et al., 2022; Houlsby et al., 2019; Lester et al., 2021; Liu et al., 2021; Hu et al., 2021; Ding et al., 2022). Các module đặc thù tác vụ sở hữu đặc tính cắm-và-chạy và có thể tiêm khả năng tác vụ vào PTM một cách hiệu quả. Bên cạnh đó, một số nhà nghiên cứu khám phá việc kết hợp các module có thể cắm với các PTM quy mô lớn để tạo văn bản có thể kiểm soát hiệu quả (Dathathri et al., 2020; Madotto et al., 2020; Pascual et al., 2021), thích ứng miền (Chronopoulou et al., 2022; Pfeiffer et al., 2020), truy xuất thông tin (Shi et al., 2023; Yu et al., 2023), tiêm kiến thức (Zhang et al., 2023), khử thiên vị mô hình (Lauscher et al., 2021), và tích hợp mô hình (Xu et al., 2023; Alayrac et al., 2022). Nhờ khả năng mạnh mẽ của các PTM quy mô lớn, các module này có thể kích hoạt hiệu quả khả năng của mô hình với số lượng tham số hạn chế. Khác với các module chức năng trước đây, chúng tôi cố gắng xây dựng các plugin tài liệu để cung cấp kiến thức và thông tin ngữ cảnh cho PTM.

2.2 Học Biểu diễn Ngôn ngữ

Học biểu diễn ngôn ngữ là một tác vụ NLP cơ bản (Bengio et al., 2013; Devlin et al., 2019; Radford et al., 2018) nhằm mục đích biểu diễn hiệu quả ngữ nghĩa phong phú được phân bố trong văn bản và mang lại lợi ích cho nhiều tác vụ downstream khác nhau. Các nỗ lực trước đây cố gắng ánh xạ các đầu vào ngôn ngữ thành các đặc trưng phân tán trung gian, như embedding từ (Mikolov et al., 2013; Kiros et al., 2015; Pennington et al., 2014; Peters et al., 2018), embedding câu (Conneau et al., 2017; Reimers và Gurevych, 2019; Gao et al., 2021), và embedding tài liệu (Dai et al., 2015; Wu et al., 2018), được sử dụng tiếp như đầu vào của các mô hình đặc thù tác vụ downstream để tạo ra các biểu diễn tài liệu đặc thù tác vụ cuối cùng. Hơn nữa, một số nhà nghiên cứu đã có những khám phá sơ bộ để tách rời việc mã hóa tài liệu khỏi các tác vụ bằng cách đóng băng một phần các lớp của bộ mã hóa tài liệu (Du et al., 2020; Saad-Falcon et al., 2022). Nhưng các công trình này chỉ đạt được việc tách rời bán phần mã hóa tài liệu khỏi các tác vụ, và chỉ có thể được sử dụng cho cài đặt cắm trong quá trình điều chỉnh.

Đáng chú ý, nhiều nỗ lực đã được dành để khám phá các kiến trúc hiệu quả, như attention thưa thớt, của PTM để mã hóa các tài liệu dài (Beltagy et al., 2020; Zaheer et al., 2020; Zhang et al., 2021; Mehta et al., 2022; Tay et al., 2022). Các công trình này song song với công trình của chúng tôi, và chúng tôi có thể áp dụng các lớp attention thưa thớt để cải thiện hiệu quả hơn nữa.

3 Phương pháp luận

Trong phần này, chúng tôi sẽ đầu tiên trình bày mô tả paradigm và framework tổng thể của PlugD. Sau đó chúng tôi giới thiệu phương pháp học plugin tự giám sát để làm cho các plugin tài liệu chứa đủ ngữ nghĩa và hai chiến lược về cách sử dụng các module tài liệu.

3.1 Các Module Tài liệu Cắm-và-Chạy

Trong bài báo này, chúng tôi tập trung vào việc tách rời mã hóa tài liệu với các tác vụ cụ thể. Khác với các phương pháp ghép nối mã hóa-tác vụ mà đồng thời mã hóa tài liệu và truy vấn đặc thù tác vụ, PlugD nhằm mục đích mã hóa tài liệu một lần và cho tất cả trước khi thích ứng tác vụ. Cụ thể, cho một backbone PTM M và một tài liệu d, chúng tôi đầu tiên sử dụng PTM để mã hóa tài liệu thành một module có thể cắm bất khả tri tác vụ, D, tức là một plugin tài liệu. Được trang bị plugin tài liệu, PTM được tiêm kiến thức tài liệu tương ứng. Sau đó chúng tôi áp dụng dữ liệu tác vụ để điều chỉnh PTM để thu được các mô hình đặc thù tác vụ. Trong quá trình suy luận, chúng ta có thể nhanh chóng thu được dự đoán cho một truy vấn đầu vào bằng cách chèn plugin tài liệu liên quan vào các mô hình đặc thù tác vụ, tránh việc mã hóa lại tài liệu.

3.2 Framework Tổng thể

Như được hiển thị trong Hình 1, chúng tôi thiết kế PlugD, bao gồm ba thành phần: một backbone PTM, các plugin tài liệu cung cấp kiến thức tài liệu, và các mô hình đặc thù tác vụ được xuất phát từ PTM để xử lý các tác vụ cụ thể. Chúng tôi sẽ trình bày các thành phần này dưới đây.

Backbone PTM. PTM đã được chứng minh hiệu quả trong một loạt rộng các tác vụ downstream, và đưa ra một sự thay đổi paradigm để giải quyết nhiều tác vụ với một mô hình thống nhất (Bommasani et al., 2021; Brown et al., 2020; Chowdhery et al., 2022). Xét đến điều này, chúng tôi tiếp tục khám phá việc tách rời mã hóa tài liệu và các tác vụ, thống nhất các biểu diễn tài liệu qua các tác vụ. PlugD dựa vào một PTM quy mô lớn, có thể phục vụ như một cơ sở hạ tầng cơ bản để học các plugin từ tài liệu và như một khởi tạo cho các mô hình đặc thù tác vụ. Lưu ý rằng, đối với framework của chúng tôi, bất kỳ PTM nào với tham số quy mô lớn đều có thể được sử dụng làm backbone. Cụ thể, chúng tôi áp dụng một PTM chuỗi-đến-chuỗi được sử dụng rộng rãi, T5 (Raffel et al., 2020), trong bài báo này. Vì các mục tiêu tiền huấn luyện của PTM không liên quan đến các plugin tài liệu, chúng tôi tiếp tục tiến hành học plugin cho PTM để nó có thể tạo ra và sử dụng các plugin tài liệu. Các tác vụ huấn luyện được giới thiệu trong các phần sau.

Plugin Tài liệu. Các plugin tài liệu lưu trữ kiến thức tài liệu và được thu thập trước khi sử dụng những tài liệu này cho các tác vụ cụ thể. Được truyền cảm hứng từ tiến bộ gần đây trong giải thích mô hình (Petroni et al., 2019; Jiang et al., 2020; Roberts et al., 2020; Dai et al., 2022; Mitchell et al., 2022), tuyên bố rằng các tham số của PTM lưu trữ lượng kiến thức khổng lồ, chúng tôi đề xuất mã hóa ngữ nghĩa và kiến thức của tài liệu thành các tham số có thể cắm. Theo cách này, khi plugin tài liệu được chèn vào PTM, PTM được trao quyền với kiến thức tài liệu tương ứng.

Được truyền cảm hứng từ prefix-tuning (Li và Liang, 2021), chúng tôi biểu diễn tài liệu như các token tiền tố cho các lớp attention. Khi plugin tài liệu được chèn vào backbone, chúng tôi nối các token tiền tố tương ứng với các vector ẩn của truy vấn đặc thù tác vụ trong các lớp attention để cung cấp kiến thức tài liệu. Cụ thể, cho một tài liệu d với Ld token, chúng tôi đầu tiên mã hóa tài liệu với PTM để có được các biểu diễn tài liệu thô Hd={h1, ...,hLd}. Sau đó, chúng tôi áp dụng một mạng ánh xạ để chiếu các vector biểu diễn thành các token tiền tố: Pd={p1, ...,pLd}, trong đó pi=hi+MLP(hi). Các token tiền tố được chèn tiếp vào các lớp attention. Để Hq={hq1, ...,hqLq} biểu thị các vector ẩn của truy vấn trong lớp attention. Chúng tôi tính toán đầu ra attention như sau:

Hoq=Attn(HqWq,cat(Pd,Hq)Wk,cat(Pd,Hq)Wv), (1)

trong đó Wq, Wk, và Wv là các tham số có thể huấn luyện cho lớp self-attention. Sau đó Hoq được đưa vào lớp feed-forward như lớp Transformer gốc (Vaswani et al., 2017).

Khác với việc mã hóa tài liệu trong quá trình thích ứng tác vụ hoặc suy luận, các token tiền tố không liên quan đến tính toán của các lớp feed-forward. Hơn nữa, để tích hợp tốt hơn ngữ nghĩa của tài liệu và truy vấn để xử lý các tác vụ, các plugin tài liệu chỉ được chèn trong các lớp gần đỉnh của backbone PTM. Do đó, những plugin tài liệu này dưới dạng token tiền tố chỉ tăng yêu cầu tính toán hạn chế, trong khi PlugD có thể đạt được tăng tốc tính toán đáng kể như một kết quả. Do yêu cầu lưu trữ cao của việc thêm các token tiền tố khác nhau vào các lớp attention khác nhau, chúng tôi chia sẻ Pd cho tất cả các lớp attention. Lưu ý rằng, chúng tôi cũng có thể sử dụng các cấu trúc mô hình khác, như tham số bias (Zaken et al., 2022) và LoRA (Hu et al., 2021), để biểu diễn tài liệu trong PlugD, mà chúng tôi để dành cho công trình tương lai.

Các Mô hình Đặc thù Tác vụ. Các mô hình đặc thù tác vụ được xuất phát từ backbone PTM và được điều chỉnh trên dữ liệu tác vụ có giám sát để thu được khả năng lý luận tác vụ. Trong quá trình điều chỉnh downstream, chúng tôi đóng băng các plugin tài liệu, và chỉ các mô hình đặc thù tác vụ và mạng ánh xạ của các plugin tài liệu là có thể huấn luyện để các plugin tài liệu có thể được tái sử dụng qua các tác vụ khác nhau. Chúng tôi áp dụng hai phương pháp huấn luyện cho các mô hình đặc thù tác vụ, bao gồm tinh chỉnh đầy đủ tham số thông thường và điều chỉnh hiệu quả tham số (PET). Lưu ý rằng, việc triển khai các PTM quy mô lớn với tinh chỉnh đầy đủ tham số sẽ dẫn đến gánh nặng tính toán và lưu trữ trầm trọng hơn cho các tình huống đa tác vụ. Do đó, việc khám phá PlugD với PET cho thích ứng tác vụ hiệu quả trong các ứng dụng thực tế là đáng giá.

Cả hai phương pháp huấn luyện đều áp dụng các mục tiêu đặc thù tác vụ để tối ưu hóa các tham số. Tinh chỉnh tối ưu hóa tất cả các tham số của backbone PTM, trong khi điều chỉnh hiệu quả tham số chỉ tối ưu hóa các phần của tham số và giữ các tham số khác đóng băng. Cụ thể, chúng tôi áp dụng adapter cho điều chỉnh hiệu quả tham số (Pfeiffer et al., 2021). Cho vector ẩn h∈Rd, trong đó d là kích thước ẩn, đầu ra của lớp adapter được tính như:

hout=h+ϕ(hWdown)Wup, (2)

trong đó Wdown∈Rd×r, Wup∈Rr×d, và r≪d tham chiếu đến chiều bottleneck.

Độ phức tạp Tính toán. PlugD mã hóa các tài liệu trước khi thích ứng tác vụ và do đó có thể giảm chi phí tính toán. Trong đoạn này, chúng tôi thảo luận chi tiết về độ phức tạp tính toán của PlugD. Giả sử độ dài của truy vấn và tài liệu là Lq và Ld, tương ứng. Đối với các mô hình ghép nối mã hóa-tác vụ truyền thống, mà đồng thời mã hóa tài liệu và truy vấn, độ phức tạp tính toán của lớp attention là O((Lq+Ld)2), và độ phức tạp tính toán của lớp feed-forward là O(Lq+Ld). Đối với PlugD, các plugin tài liệu được chèn vào lớp attention, có độ phức tạp tính toán là O(Lq(Lq+Ld)). Và các plugin tài liệu không liên quan đến tính toán của lớp feed-forward, và do đó độ phức tạp tính toán của nó là O(Lq). Trong các ứng dụng thực tế, các tài liệu thường dài hơn nhiều so với các truy vấn. Do đó, PlugD có thể đạt được tăng tốc tính toán đáng kể so với các mô hình ghép nối mã hóa-tác vụ thông thường.

--- TRANG 5 ---
3.3 Học Plugin

Để cho phép các plugin tài liệu chứa đủ kiến thức tài liệu, chúng tôi tiếp tục khám phá học plugin tự giám sát trong phần này. Như được hiển thị trong Hình 2, chúng tôi áp dụng hai tác vụ tự giám sát, dự đoán span lặp lại, và tạo câu tiếp theo để tăng cường khả năng hiểu và tạo ra của PlugD. Cả hai tác vụ đều yêu cầu các plugin tài liệu cung cấp thông tin ngữ cảnh cho mô hình để đưa ra dự đoán. Để d={s1, ..., sn} biểu thị tài liệu đầu vào với n câu. Chúng tôi thực hiện học plugin như:

Dự đoán span lặp lại (RSP). Được truyền cảm hứng từ Ram et al. (2021), chúng tôi sử dụng các span lặp lại để xây dựng tín hiệu tự giám sát. Các span lặp lại xuất hiện nhiều lần trong tài liệu, và thường chứa ngữ nghĩa quan trọng cho việc hiểu tài liệu. Việc che các span lặp lại và yêu cầu PTM khôi phục chúng có thể giúp PTM nắm bắt ngữ nghĩa tài liệu. Cụ thể, chúng tôi nối các câu được lấy mẫu ngẫu nhiên từ tài liệu d làm truy vấn q, và coi các câu còn lại làm ngữ cảnh c. Sau đó chúng tôi tạo ra plugin tài liệu Pc dựa trên c, và thay thế các span lặp lại trong q thành các token mặt nạ đặc biệt. PTM được yêu cầu dự đoán các span bị che trong q dựa trên Pc. Khác với tác vụ mô hình ngôn ngữ bị che truyền thống (Devlin et al., 2019; Raffel et al., 2020), chủ yếu tập trung vào thông tin cục bộ xung quanh các span bị che, RSP thường yêu cầu PTM tích hợp thông tin toàn cục từ các plugin tài liệu.

Tạo câu tiếp theo (NSG). Để cho phép các plugin tài liệu mang lại lợi ích cho các tác vụ tạo ra, chúng tôi áp dụng NSG như một tác vụ huấn luyện. Chúng tôi đầu tiên lấy mẫu ngẫu nhiên ba câu liên tiếp {si, si+1, si+2} từ tài liệu d. Các câu còn lại được coi là ngữ cảnh c = {s1, ..., si−1, si+3, ..., sn} để tạo ra plugin tài liệu Pc. Sau đó chúng tôi coi si là truy vấn, và yêu cầu PTM tạo ra hai câu tiếp theo {si+1, si+2} dựa trên Pc.

Hai tác vụ này yêu cầu PTM nắm bắt cả thông tin cục bộ từ các truy vấn và thông tin toàn cục từ các plugin tài liệu. Do đó, sau khi học plugin, PTM được cho là có thể xây dựng các plugin tài liệu có thông tin và phục vụ như một khởi tạo tốt cho các mô hình đặc thù tác vụ để nắm bắt kiến thức từ các plugin tài liệu. Cả hai tác vụ đều là các tác vụ chuỗi-đến-chuỗi, và chúng tôi áp dụng likelihood âm làm mục tiêu huấn luyện cho hai tác vụ. Mô hình được huấn luyện theo cách đa tác vụ, và loss huấn luyện cuối cùng là tổng của loss của hai tác vụ. Trong quá trình học plugin, các plugin tài liệu được tính toán thời gian thực cho các tài liệu khác nhau. Tất cả các tham số của PTM được điều chỉnh cho việc học plugin. Sau đó, các plugin tài liệu có thể được tính toán và lưu trữ cho việc điều chỉnh và suy luận tác vụ downstream tiếp theo.

3.4 Các Chiến lược Cắm

Để sử dụng linh hoạt các plugin tài liệu, chúng tôi đề xuất hai chiến lược cắm:

Cắm trong quá trình điều chỉnh. Trong cài đặt này, các plugin tài liệu được áp dụng trong cả việc huấn luyện và suy luận của các mô hình đặc thù tác vụ. Cho một instance với truy vấn và tài liệu làm đầu vào, chúng tôi đầu tiên chèn plugin tài liệu tương ứng, được tính toán trước khi tinh chỉnh, vào các mô hình. Sau đó các mô hình đặc thù tác vụ được huấn luyện với các mục tiêu đặc thù tác vụ để nắm bắt thông tin liên quan từ các plugin tài liệu.

Cắm sau điều chỉnh. Trong cài đặt này, các plugin tài liệu được áp dụng chỉ trong suy luận của các mô hình đặc thù tác vụ. Các plugin tài liệu có thể cung cấp kiến thức bên ngoài, và phục vụ như một phương pháp hậu xử lý để tiêm kiến thức vào các mô hình đặc thù tác vụ. Trong quá trình suy luận, cho một instance, chúng tôi trực tiếp chèn các plugin tài liệu liên quan vào các mô hình đặc thù tác vụ để đạt được tiêm kiến thức. Cài đặt này không yêu cầu huấn luyện bổ sung cho các mô hình đặc thù tác vụ hiện có và có thể được sử dụng để tiêm kiến thức văn bản một cách linh hoạt.

4 Thí nghiệm

4.1 Cài đặt Đánh giá

Bộ dữ liệu. Chúng tôi áp dụng các bài viết Wikipedia được sử dụng rộng rãi làm bộ sưu tập tài liệu của chúng tôi và chọn các tác vụ thâm dụng kiến thức điển hình để đánh giá. Chúng tôi áp dụng một benchmark đa tác vụ điển hình, KILT (Petroni et al., 2021), để đánh giá các mô hình của chúng tôi. Các tác vụ trong KILT được dựa trên cùng một snapshot của các trang Wikipedia. Cụ thể, chúng tôi đánh giá PlugD trên một bộ dữ liệu xác minh sự thật, FEVER (Thorne et al., 2018), bốn bộ dữ liệu trả lời câu hỏi, bao gồm Natural Questions (NQ) (Kwiatkowski et al., 2019), HotpotQA (Yang et al., 2018), TriviaQA (Joshi et al., 2017), ELI5 (Fan et al., 2019), một bộ dữ liệu tạo đối thoại, Wizard of Wikipedia (WoW) (Dinan et al., 2019), và hai bộ dữ liệu điền slot, Zero Shot RE (zsRE) (Levy et al., 2017), T-REx (ElSahar et al., 2018). Những tác vụ này đa dạng và yêu cầu mô hình khai thác đầy đủ kiến thức tài liệu. Như được hiển thị trong bài báo của KILT, kiến thức tài liệu bên ngoài không thể mang lại lợi ích cho tác vụ liên kết thực thể. Do đó, chúng tôi không sử dụng chúng để đánh giá trong bài báo này. Theo Petroni et al. (2021), chúng tôi sử dụng truy xuất đoạn văn dày đặc (Karpukhin et al., 2020) để truy xuất các tài liệu liên quan từ các bài viết Wikipedia cho mỗi truy vấn. Vui lòng tham khảo Phụ lục để biết kết quả đánh giá của truy xuất tài liệu.

Metric. Theo công trình trước đây, chúng tôi áp dụng độ chính xác cho tác vụ xác minh sự thật (FEVER) và các tác vụ điền slot (zsRE, T-REx); khớp chính xác (EM) và điểm F1 cho các tác vụ trả lời câu hỏi trích xuất (NQ, HotpotQA, TriviaQA); ROUGE-L (RL) cho các tác vụ trả lời câu hỏi trừu tượng dài (ELI5); điểm F1 cho tác vụ tạo đối thoại (WoW). Bên cạnh đó, để đánh giá hiệu suất tổng thể, chúng tôi tính toán điểm trung bình cho những tác vụ này như một metric đánh giá, trong đó điểm EM được sử dụng cho các tác vụ trả lời câu hỏi trích xuất.

4.2 Chi tiết Huấn luyện

Chúng tôi sử dụng T5-large được sử dụng rộng rãi (Raffel et al., 2020), làm backbone PTM của chúng tôi. Đối với phương pháp huấn luyện PET, chúng tôi đặt chiều bottleneck của adapter là 16. Chúng tôi chèn các plugin tài liệu trong 12 lớp cuối cùng. Chúng tôi tiến hành học plugin trên một corpus không giám sát quy mô lớn, C4 (Raffel et al., 2020) trong 36k bước. Chúng tôi sử dụng Adam để tối ưu hóa các mô hình của chúng tôi. Do chi phí tính toán cao của tinh chỉnh đầy đủ tham số, trong các thí nghiệm sau, chúng tôi áp dụng phương pháp PET để huấn luyện các mô hình trừ khi có quy định khác. Chúng tôi huấn luyện các mô hình với floating point nửa độ chính xác trên 8 GPU NVIDIA A100, và quá trình học plugin mất 18 giờ. Vui lòng tham khảo Phụ lục để biết thêm chi tiết.

4.3 Baseline

Cắm trong quá trình điều chỉnh. Ở đây chúng tôi so sánh PlugD với một số baseline đại diện, mà mã hóa tài liệu và truy vấn với hai bộ mã hóa khác nhau. Theo cách này, những mô hình này có thể tái sử dụng các biểu diễn tài liệu qua các truy vấn khác nhau, nhưng chúng vẫn cần tạo ra các biểu diễn tài liệu khác nhau cho các tác vụ khác nhau. (1) ED2LM (Hui et al., 2022) sử dụng kiến trúc encoder-decoder để mã hóa các truy vấn và tài liệu riêng biệt, và sau đó tài liệu có thể được mã hóa trước trước khi suy luận. Cụ thể, các tài liệu được đưa vào encoder, và các truy vấn được đưa vào decoder. (2) EmbRecy (Saad-Falcon et al., 2022) đề xuất tái sử dụng các activation trung gian của tài liệu để đạt được tăng tốc cho tinh chỉnh và suy luận. EmbRecy cache đầu ra của một lớp trung gian làm biểu diễn tài liệu và các lớp gần đỉnh còn lại được điều chỉnh để hợp nhất thông tin của tài liệu và truy vấn. (3) Bên cạnh đó, để đáp ứng cài đặt tách rời mã hóa tài liệu khỏi các tác vụ, chúng tôi đóng băng các bộ mã hóa tài liệu của ED2LM và EmbRecy để làm cho các biểu diễn tài liệu thống nhất qua các tác vụ khác nhau. Chúng tôi ký hiệu hai phương pháp bất khả tri tác vụ là ED2LM f và EmbRecy f. (4) Vì PlugD tiến hành huấn luyện tự giám sát thêm cho việc học biểu diễn cắm-và-chạy, chúng tôi cũng trình bày kết quả của PlugD mà không có học plugin (w/o PT) để hiển thị hiệu quả của kiến trúc của PlugD. (5) UpperBound theo cài đặt truyền thống, trong đó các truy vấn và tài liệu được nối cùng nhau và đưa vào mô hình. Các biểu diễn tài liệu được tạo ra bởi baseline này là đặc thù truy vấn. Mô hình cần mã hóa một tài liệu đơn nhiều lần cho các tác vụ khác nhau và các truy vấn khác nhau, đó là giới hạn trên của các phương pháp bất khả tri tác vụ.

Cắm sau điều chỉnh. Chúng tôi cố gắng tiêm kiến thức văn bản không có cấu trúc vào PTM sau khi điều chỉnh downstream. Các phương pháp hiện tại chủ yếu tập trung vào tăng cường PTM với kiến thức có cấu trúc trong quá trình tiền huấn luyện hoặc tinh chỉnh (Zhang et al., 2019; Wang et al., 2021; Bosselut et al., 2019). Những phương pháp này yêu cầu huấn luyện lại các mô hình đặc thù tác vụ để đạt được tiêm kiến thức, do đó không thể được áp dụng trong cài đặt này. Do đó, chúng tôi trình bày kết quả của các mô hình sau: (1) Chúng tôi áp dụng T5 (Raffel et al., 2020) và PlugD làm backbone, được huấn luyện chỉ với các truy vấn làm đầu vào và không sử dụng kiến thức tài liệu bên ngoài trong đánh giá. (2) Dựa trên T5 và PlugD đã được huấn luyện, chúng tôi áp dụng các phương pháp hậu xử lý khác nhau để kết hợp kiến thức tài liệu. Đối với T5, chúng tôi trực tiếp nối tài liệu và truy vấn làm đầu vào cho đánh giá (+Concat). Đối với PlugD, chúng tôi chèn kiến thức tài liệu với các plugin tài liệu (+DPlug). Cài đặt này thách thức vì có một khoảng cách giữa huấn luyện và đánh giá.

4.4 Cắm trong quá trình Điều chỉnh

Chúng tôi trình bày kết quả so sánh giữa các mô hình baseline và PlugD trong Bảng 1. Từ bảng này, chúng ta có thể quan sát thấy: (1) Các mô hình baseline mà tạo ra các biểu diễn tài liệu bất khả tri tác vụ hoạt động kém hơn so với các mô hình tương ứng mà tạo ra các biểu diễn đặc thù tác vụ. Điều này chỉ ra rằng việc tách rời biểu diễn tài liệu khỏi các tác vụ cụ thể là thách thức và các phương pháp hiện tại không thể đạt được hiệu suất thỏa đáng. (2) So với các mô hình baseline bất khả tri tác vụ (ED2LM f và EmbRecy f), PlugD có thể đạt được cải thiện hiệu suất đáng kể qua các tác vụ khác nhau. Bên cạnh đó, so với ED2LM và EmbRecy, PlugD cũng có thể đạt được kết quả vượt trội trên nhiều bộ dữ liệu, đặc biệt là cho điều chỉnh hiệu quả tham số. Ngoài ra, ED2LM và EmbRecy cần tạo ra các biểu diễn tài liệu cho các tác vụ khác nhau riêng biệt. Do đó chúng yêu cầu lưu trữ nhiều hơn PlugD. Ngược lại, PlugD có thể tạo ra các biểu diễn thống nhất có thông tin với yêu cầu lưu trữ ít hơn và đạt được kết quả vượt trội qua các tác vụ khác nhau. (3) So với mô hình ghép nối mã hóa-tác vụ truyền thống (UpperBound), việc chia sẻ biểu diễn tài liệu qua các tác vụ khác nhau trong PlugD chỉ dẫn đến một sự sụt giảm hiệu suất hạn chế (39.68 vs. 41.22, và 40.61 vs. 41.79 trung bình). Và vì PlugD không cần mã hóa tài liệu trong quá trình điều chỉnh và suy luận downstream, PlugD cho phép tăng tốc tính toán đáng kể. Kết quả cho thấy PlugD có thể nắm bắt hiệu quả ngữ nghĩa tài liệu và tiêm chúng vào PTM để cung cấp kiến thức. (4) Thậm chí PlugD mà không có học plugin thêm có thể vượt trội hơn các baseline trên một số bộ dữ liệu. Điều này chứng minh rằng PlugD được hưởng lợi từ cả các tác vụ tự giám sát và kiến trúc mô hình. Bên cạnh đó, nó cũng chỉ ra rằng các biểu diễn tài liệu theo ngữ cảnh được tạo ra bởi PTM gốc (PlugD w/o PT) là mạnh mẽ nếu chúng ta sử dụng chúng một cách chính xác.

Chi phí Tính toán. Chúng tôi so sánh chi phí tính toán của PlugD và các mô hình baseline. Ở đây, chúng tôi trình bày các phép toán điểm nổi (FLOP) và thời gian tính toán cần thiết để xử lý một dữ liệu trong suy luận cho mỗi phương pháp. Chúng tôi giả sử rằng tài liệu, truy vấn, và câu trả lời chứa 512, 48, và 32 token, tương ứng. Kết quả được hiển thị trong Bảng 2. Từ kết quả, chúng ta có thể quan sát thấy: (1) Các phương pháp cho biểu diễn bất khả tri tác vụ yêu cầu chi phí tính toán ít hơn nhiều so với các phương pháp ghép nối mã hóa-tác vụ. Đặc biệt, phương pháp PlugD của chúng tôi có thể đạt được tăng tốc 3.25× (139.3 GFLOP vs. 453.1 GFLOP). (2) Các phương pháp cho biểu diễn bất khả tri tác vụ nói chung kém hơn các phương pháp ghép nối mã hóa-tác vụ. PlugD có thể đạt được điểm trung bình tốt hơn so với các baseline khác và duy trì chi phí tính toán thấp. (3) Cả các mô hình bất khả tri tác vụ và bất khả tri truy vấn đều cần mã hóa trước và lưu trữ các biểu diễn tài liệu trước khi điều chỉnh downstream để tăng tốc suy luận. Tuy nhiên, các mô hình tạo ra các biểu diễn bất khả tri truy vấn và đặc thù tác vụ yêu cầu các biểu diễn tài liệu riêng biệt cho mỗi tác vụ. Ngược lại, PlugD của chúng tôi tạo ra các biểu diễn bất khả tri tác vụ cho tất cả các tác vụ, dẫn đến kết quả tốt hơn và yêu cầu lưu trữ thấp hơn.

4.5 Cắm sau Điều chỉnh

Kết quả so sánh được hiển thị trong Bảng 3. Từ kết quả, chúng ta có thể quan sát thấy: (1) Cả T5 và PlugD đều không thể đạt được cải thiện nhất quán từ tiêm kiến thức hậu xử lý trên những tác vụ này. Điều này chứng minh rằng cắm sau điều chỉnh là một cài đặt thách thức vì có một khoảng cách giữa huấn luyện và đánh giá. (2) PlugD có thể đạt được cải thiện đáng kể trên FEVER, NQ, và zsRE, điều này tiếp tục chỉ ra hiệu quả của PlugD. Tuy nhiên, PlugD không thể đạt được cải thiện trên WoW. Vì khả năng thu nhận kiến thức từ các plugin tài liệu được có được từ học plugin, việc điều chỉnh tác vụ downstream thêm có thể dẫn các mô hình quên khả năng đó. Do đó, thậm chí PlugD cũng không thể đạt được cải thiện nhất quán. (3) Mà không có kiến thức tài liệu, PlugD và T5 đạt được kết quả tương đương. Điều này chỉ ra rằng quá trình học plugin không cải thiện khả năng cơ bản của PTM. Cải thiện đạt được bởi PlugD trong cả cài đặt cắm trong/sau điều chỉnh đến từ framework cắm-và-chạy hiệu quả.

4.6 Nghiên cứu Loại bỏ

Trong phần này, chúng tôi tiến hành một nghiên cứu loại bỏ để xác minh hiệu quả của các tác vụ học plugin được đề xuất của chúng tôi. Chúng tôi hiển thị kết quả của các mô hình, được huấn luyện chỉ với tác vụ dự đoán span lặp lại (w/ RSP), chỉ với tác vụ tạo câu tiếp theo (w/ NSG), hoặc mà không có học plugin (w/o PT). Chúng tôi đánh giá các mô hình trên bốn bộ dữ liệu cho cài đặt cắm trong quá trình điều chỉnh.

Kết quả được hiển thị trong Bảng 4. Chúng ta có thể thấy rằng (1) PlugD mà không có học plugin dẫn đến sự sụt giảm hiệu suất đáng kể, điều này tiếp tục chỉ ra rằng các tác vụ huấn luyện được đề xuất có thể giúp PTM mã hóa hiệu quả kiến thức tài liệu vào các plugin. (2) Hai tác vụ có thể hợp tác với nhau để cải thiện hiệu suất mô hình. Mặc dù huấn luyện PlugD chỉ với một tác vụ sẽ dẫn đến suy giảm hiệu suất trên một số tác vụ, huấn luyện với hai tác vụ có thể đạt được cải thiện nhất quán so với mô hình mà không có học plugin. (3) Khi PlugD được huấn luyện chỉ với NSG, mô hình có thể đạt được kết quả vượt trội cho WoW. Nhưng tác vụ này gây hại cho hiệu suất của FEVER và zsRE. Điều này là do NSG yêu cầu mô hình tạo ra các câu dài, tương tự như WoW, trong khi FEVER và zsRE chỉ yêu cầu đầu ra ngắn. Ngược lại, huấn luyện chỉ với RSP cũng sẽ dẫn đến sự sụt giảm hiệu suất cho WoW. Điều này chỉ ra rằng các tác vụ học plugin đa dạng là quan trọng cho các plugin tài liệu biểu cảm.

4.7 Phân tích Khả năng Chuyển giao

Trong phần này, chúng tôi muốn khám phá hiệu quả của các tác vụ có giám sát trên khả năng chuyển giao biểu diễn tài liệu. Ở đây chúng tôi trình bày kết quả của ED2LM, có thể vượt trội hơn các baseline khác. Cụ thể, chúng tôi huấn luyện bộ mã hóa tài liệu đặc thù tác vụ trên một tác vụ nguồn, và sau đó tái sử dụng bộ mã hóa trên các tác vụ đích khác để tiếp tục huấn luyện phần còn lại của mô hình. Kết quả được hiển thị trong Hình 3.

Từ kết quả, chúng ta có thể quan sát thấy 1) Các giá trị không chéo của ma trận nhất quán nhỏ hơn các giá trị chéo. Điều này cho thấy rằng việc huấn luyện bộ mã hóa tài liệu với các tác vụ có giám sát hiện tại khó có thể mang lại lợi ích cho các tác vụ đích khác. PlugD được huấn luyện với hai mục tiêu tự giám sát có thể cung cấp biểu diễn tài liệu có thể chuyển giao và đạt được kết quả vượt trội. 2) Các bộ mã hóa được huấn luyện trên bộ dữ liệu NQ có thể vượt trội hơn các bộ mã hóa được huấn luyện trên các tác vụ khác. Điều này chỉ ra rằng huấn luyện với các tác vụ thách thức có thể dẫn đến hiệu suất tốt hơn.

5 Kết luận

Trong bài báo này, chúng tôi khám phá một paradigm mới, nhằm mục đích biểu diễn tài liệu như các module có thể cắm cho PTM. Trong cài đặt này, chúng ta có thể thoát khỏi việc mã hóa cùng một tài liệu nhiều lần cho các tác vụ khác nhau. Các thí nghiệm rộng rãi chứng minh rằng PlugD được đề xuất của chúng tôi có thể giảm đáng kể chi phí tính toán và tiêm hiệu quả kiến thức tài liệu vào PTM để cải thiện hiệu suất. Trong tương lai, chúng tôi sẽ khám phá các tác vụ học plugin hiệu quả hơn và tiếp tục cố gắng biểu diễn đồ thị kiến thức, và hình ảnh như các plugin để cung cấp kiến thức cho PTM.

Hạn chế

Chúng tôi thảo luận về các hạn chế của PlugD trong phần này: (1) Chúng tôi khám phá việc tách rời mã hóa tài liệu khỏi các tác vụ cụ thể trong bài báo này, và đề xuất biểu diễn tài liệu như các module có thể cắm trước khi thích ứng tác vụ. Do đó, PlugD có yêu cầu lưu trữ cao hơn so với các phương pháp ghép nối mã hóa thông thường. (2) Trong các thí nghiệm, chúng tôi áp dụng T5 làm backbone PTM của chúng tôi. Thực tế, framework được đề xuất cũng có thể được áp dụng cho nhiều mô hình tiền huấn luyện với nhiều kiến trúc mô hình khác nhau. Bên cạnh đó, xu hướng gần đây cho thấy rằng các mô hình lớn hơn có xu hướng xây dựng các biểu diễn văn bản biểu cảm hơn. Việc khám phá PlugD với các PTM lớn hơn với hàng tỷ tham số để học các plugin tài liệu có thông tin là đáng giá. (3) Trong bài báo này, chúng tôi áp dụng một retriever bên ngoài để truy xuất các tài liệu liên quan cho mỗi truy vấn đầu vào. Tiến bộ gần đây trong các mô hình ngôn ngữ tăng cường truy xuất cho thấy rằng việc huấn luyện PTM với một retriever kiến thức văn bản end-to-end có thể thúc đẩy hiệu suất downstream. Chúng tôi tin rằng các plugin tài liệu cũng có thể phục vụ như cơ sở kiến thức bên ngoài và tăng cường PlugD với truy xuất end-to-end là một hướng đi đầy hứa hẹn.

Lời cảm ơn

Công trình này được hỗ trợ bởi Chương trình R&D Chính quốc gia (Số 2020AAA0106502), Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62236004).

Đóng góp của Tác giả Chaojun Xiao và Chi-Min Chan đã viết mã và tiến hành các thí nghiệm. Chaojun Xiao, Zhengyan Zhang, và Xu Han đã viết bản thảo ban đầu. Yankai Lin, Zhiyuan Liu, và Xiangyang Li đã chỉnh sửa và cải thiện đáng kể bài báo. Zhonghua Li, Zhao Cao, và Maosong Sun đã cung cấp lời khuyên có giá trị cho nghiên cứu.

Tài liệu tham khảo

[Các tài liệu tham khảo tiếp tục với định dạng tương tự...]

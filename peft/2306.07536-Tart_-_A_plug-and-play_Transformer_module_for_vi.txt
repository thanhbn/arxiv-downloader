# 2306.07536.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2306.07536.pdf
# Kích thước tệp: 10575764 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tart : Một mô-đun Transformer có thể cắm và sử dụng để
suy luận bất khả tri về tác vụ
Kush Bhatia†∗Avanika Narayan†∗Christopher De Sa‡Christopher Ré†
†Khoa Khoa học Máy tính, Đại học Stanford
‡Khoa Khoa học Máy tính, Đại học Cornell
{kushb, avanika, chrismre}@cs.stanford.edu, cdesa@cs.cornell.edu
Tóm tắt
Các mô hình ngôn ngữ lớn (LLMs) thể hiện khả năng học trong ngữ cảnh cho phép cùng một
mô hình thực hiện nhiều tác vụ mà không cần bất kỳ huấn luyện cụ thể nào cho tác vụ. Ngược lại, các
phương pháp thích ứng truyền thống, như tinh chỉnh, sửa đổi các mô hình cơ bản cho từng tác vụ cụ thể.
Tuy nhiên, học trong ngữ cảnh luôn kém hiệu suất hơn các phương pháp điều chỉnh cụ thể cho tác vụ
ngay cả khi được cung cấp cùng những ví dụ. Trong khi hầu hết các phương pháp hiện có (ví dụ: kỹ thuật
prompt) tập trung vào các biểu diễn đã học của LLM để vá lỗ hổng hiệu suất này, phân tích của chúng tôi
thực sự tiết lộ rằng các biểu diễn LLM chứa đủ thông tin để đưa ra dự đoán tốt. Do đó, chúng tôi tập trung
vào khả năng suy luận của LLM và chứng minh rằng khoảng cách hiệu suất này tồn tại do niềm bất lực của
chúng trong việc thực hiện các tác vụ suy luận xác suất đơn giản. Điều này đặt ra một câu hỏi hấp dẫn: Liệu
LLMs có thực sự có khả năng học cách suy luận theo cách bất khả tri về tác vụ? Chúng tôi trả lời khẳng định
điều này và đề xuất Tart cái mà cải thiện khả năng suy luận của một LLM một cách chung chung bằng cách
sử dụng một mô-đun suy luận dựa trên Transformer được huấn luyện tổng hợp. Tart huấn luyện mô-đun
suy luận này theo cách bất khả tri về tác vụ chỉ sử dụng các tác vụ hồi quy logistic tổng hợp và kết hợp nó
với một mô hình được huấn luyện trước tùy ý trong thế giới thực mà không cần bất kỳ huấn luyện bổ sung
nào. Với một mô-đun suy luận duy nhất, Tart cải thiện hiệu suất trên các họ mô hình khác nhau (GPT-Neo,
Pythia, Bloom), kích thước mô hình (100M - 6B), tác vụ (14 tác vụ phân loại nhị phân NLP), và thậm chí
trên các phương thức khác nhau (âm thanh và thị giác). Ngoài ra, trên RAFT Benchmark, Tart cải thiện
hiệu suất của GPT-Neo (125M) sao cho nó vượt trội hơn Bloom (176B), và trong vòng 4% của GPT-3 (175B).¹

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLMs) thể hiện khả năng học trong ngữ cảnh cho phép chúng thực hiện
một tác vụ chỉ với một vài ví dụ, mà không cập nhật các tham số mô hình [Bro+20; Bom+21]. Khả năng
bất khả tri về tác vụ này cho phép một mô hình duy nhất được áp dụng cho một loạt rộng các tác vụ [Agr+22;
Wei+22a; Nar+22]. Ngược lại, các phương pháp thích ứng tác vụ truyền thống, như tinh chỉnh, cập nhật
các tham số mô hình cho từng tác vụ cụ thể.

Mặc dù là bất khả tri về tác vụ, học trong ngữ cảnh hiếm khi là phương pháp được người thực hành
lựa chọn vì nó luôn kém hiệu suất hơn các phương pháp thích ứng cụ thể cho tác vụ [LAC21; Bro+20]. Hầu hết
các công trình hiện có đều quy khoảng cách hiệu suất này cho cửa sổ ngữ cảnh hạn chế của LLMs chỉ có thể
chứa một vài ví dụ tác vụ [Koc+23; Huy23; Liu+22a]. Tuy nhiên, chúng tôi chỉ ra rằng khoảng cách này
giữa học trong ngữ cảnh và các phương pháp tinh chỉnh tồn tại ngay cả khi được cung cấp cùng những
ví dụ tác vụ.

∗Đóng góp ngang bằng
¹Mã và mô hình của chúng tôi có sẵn tại https://github.com/HazyResearch/TART

--- TRANG 2 ---
Hình 1: Phân loại các chiến lược thích ứng tác vụ. (Trái) So sánh các chiến lược thích ứng khác nhau
trên ba tiêu chí mong muốn: bất khả tri về tác vụ, chất lượng, khả năng mở rộng. (Phải) Cập nhật tham số
trên các chiến lược thích ứng, vùng màu đại diện cho thay đổi tham số do chiến lược thích ứng.

Quan sát này đặt ra câu hỏi liệu khoảng cách hiệu suất này có phải là một hạn chế chung của
các phương pháp bất khả tri về tác vụ để thích ứng hay nó cụ thể cho học trong ngữ cảnh? Cụ thể, liệu chúng ta
có thể thiết kế các phương pháp thích ứng thỏa mãn các tiêu chí mong muốn sau:
• Bất khả tri về tác vụ: Cùng một mô hình khái quát hóa trên nhiều tác vụ khác nhau.
• Chất lượng: Đạt được độ chính xác cạnh tranh với các phương pháp cụ thể cho tác vụ trên những tác vụ khác nhau này.
• Khả năng mở rộng dữ liệu: Khả năng học cải thiện với số lượng ví dụ tác vụ tăng lên.

Chúng tôi đầu tiên điều tra tại sao khoảng cách chất lượng này tồn tại. Chúng tôi phân tách khả năng học trong ngữ cảnh
của một LLM thành hai khả năng: học các biểu diễn tốt cho tác vụ và thực hiện suy luận xác suất, hay suy luận,
trên những biểu diễn này [03]. Liệu khoảng cách này có phải vì các biểu diễn không chứa đủ thông tin hay vì
LLMs không thể suy luận trên chúng? Chúng tôi khám phá giả thuyết này một cách thực nghiệm trong Phần 3
bằng cách đo cả khoảng cách suy luận và khoảng cách biểu diễn trên nhiều họ LLM khác nhau (GPT-Neo [Bla+21],
Pythia [Bid+23], Bloom[Sca+22]) trên một bộ các tác vụ phân loại nhị phân. Chúng tôi kết luận rằng LLMs
sở hữu các biểu diễn tốt, và đa số khoảng cách chất lượng (lên đến 79%) có thể quy cho khả năng suy luận
không đủ của chúng. Chúng tôi tiếp tục thấy rằng tinh chỉnh cải thiện mô hình cơ bản trên cả hai trục này,
nhưng chủ yếu cải thiện khả năng suy luận cụ thể cho tác vụ chiếm 72% hiệu suất đạt được.

Khá đáng ngạc nhiên, hầu hết các kỹ thuật hiện có để cải thiện khoảng cách hiệu suất, như kỹ thuật prompt
hoặc lựa chọn ví dụ tích cực, tập trung hoàn toàn vào các biểu diễn đã học của LLM. Ngược lại, công trình của chúng tôi
khám phá hướng trực giao của việc cải thiện khả năng suy luận của LLM. Như một bước đầu tiên, chúng tôi tinh chỉnh
LLMs sử dụng các tác vụ suy luận xác suất được tạo tổng hợp để cải thiện khả năng suy luận của chúng. Trong khi
phương pháp này cung cấp một cải thiện so với hiệu suất học trong ngữ cảnh cơ bản của mô hình (lên đến 19%, xem Hình 8
trong Phụ lục A), phương pháp này yêu cầu phải tinh chỉnh từng LLM riêng lẻ. Tiến xa hơn một bước, chúng tôi
xem xét khả năng liệu có thể cải thiện khả năng suy luận theo cách bất khả tri đối với cả tác vụ và mô hình.

Chúng tôi chỉ ra rằng thực sự có thể cải thiện khả năng suy luận theo cách hoàn toàn bất khả tri.
Chúng tôi đề xuất Tart cái mà cải thiện khả năng suy luận của một LLM bằng cách sử dụng một mô-đun suy luận
được huấn luyện tổng hợp (xem Hình 2). Tart huấn luyện một mô-đun suy luận dựa trên Transformer chỉ sử dụng
các tác vụ hồi quy logistic được tạo tổng hợp độc lập với tác vụ hạ nguồn hoặc LLM cơ bản. Mô-đun suy luận này
có thể được kết hợp, mà không cần bất kỳ huấn luyện bổ sung nào, với các embedding của một LLM để cải thiện
khả năng suy luận của nó. Đáng chú ý, Tart thỏa mãn các mục tiêu mong muốn:

--- TRANG 3 ---
Hình 2: Tart. (Trái) Quy trình huấn luyện mô-đun suy luận: Mô-đun suy luận được huấn luyện trên các chuỗi
của các tác vụ hồi quy logistic được tạo tổng hợp. (Phải) Khung từ đầu đến cuối: Tart kết hợp một
LLM được huấn luyện trước với mô-đun suy luận. Tart sử dụng LLM để nhúng văn bản đầu vào. Những embedding này,
cùng với nhãn huấn luyện, được truyền như một chuỗi cho mô-đun suy luận cái mà tạo ra dự đoán cuối cùng.

• Bất khả tri về tác vụ: Mô-đun suy luận của Tart chỉ được huấn luyện một lần sử dụng dữ liệu tổng hợp.
• Chất lượng: Vượt trội hơn LLM cơ bản trên tất cả các tác vụ và thu hẹp khoảng cách với các phương pháp tinh chỉnh cụ thể cho tác vụ.
• Khả năng mở rộng dữ liệu: Có thể chứa gấp 10 lần ví dụ hơn học trong ngữ cảnh.

Tart là bất khả tri về tác vụ, mô hình và miền. Sử dụng một mô-đun suy luận duy nhất được huấn luyện trên dữ liệu tổng hợp,
chúng tôi thể hiện rằng Tart không chỉ khái quát hóa trên ba họ mô hình (GPT-Neo, Pythia, Bloom)
trên 14 tác vụ phân loại NLP, mà còn trên các miền khác nhau (thị giác và lời nói; xem Hình 7).
Về chất lượng, chúng tôi chỉ ra rằng hiệu suất của Tart tốt hơn 18,4% so với học trong ngữ cảnh,
tốt hơn 3,4% so với adapter cụ thể cho tác vụ, và trong vòng 3,1% của tinh chỉnh cụ thể cho tác vụ đầy đủ
trên một bộ các tác vụ NLP. Trên RAFT Benchmark [Ale+21], Tart cải thiện hiệu suất của GPT-Neo (125M)
sao cho nó vượt trội hơn Bloom (176B), và trong vòng 4% của GPT-3 (175B). Tart
có khả năng mở rộng dữ liệu và vượt qua nút cổ chai độ dài ngữ cảnh hạn chế của học trong ngữ cảnh. Trong khi mỗi
ví dụ trải dài nhiều token trong một LLM, thường trải dài hàng trăm token, mô-đun suy luận của Tart
mã hóa mỗi ví dụ chỉ sử dụng hai token – một cho ngữ cảnh và một cho nhãn. Khả năng mở rộng dữ liệu này
có thể dẫn đến cải thiện lên đến 6,8% (xem Hình 6c).

Từ góc độ lý thuyết, chúng tôi chỉ ra rằng khả năng khái quát hóa của Tart phụ thuộc chủ yếu
vào sự dịch chuyển phân phối giữa phân phối embedding văn bản tự nhiên được tạo bởi LLM và
phân phối dữ liệu tổng hợp, được đo bằng metric Wasserstein-1 (Định lý 1).

Tóm lại, các đóng góp chính của chúng tôi như sau:
• Nghiên cứu tại sao học trong ngữ cảnh không hoạt động tốt như tinh chỉnh cụ thể cho tác vụ mặc dù có
quyền truy cập vào cùng thông tin, thông qua phân tách biểu diễn-suy luận.
• Đề xuất một phương pháp bất khả tri về tác vụ mới, Tart, cái mà thu hẹp khoảng cách hiệu suất với các phương pháp
cụ thể cho tác vụ và được huấn luyện chỉ sử dụng dữ liệu tổng hợp.
• Chứng minh rằng Tart hoạt động trên các tác vụ NLP khác nhau cho một loạt các họ mô hình. Cùng
mô-đun suy luận cũng khái quát hóa cho các miền thị giác và lời nói.

2 Công trình liên quan
Kỹ thuật prompt tập trung vào cải thiện khả năng thích ứng tác vụ trong ngữ cảnh của LLMs bằng cách
sửa đổi các prompt. Một dòng công trình cải thiện hiệu suất bằng cách thiết kế cẩn thận các đặc tả tác vụ
ngôn ngữ tự nhiên [Aro+23; Wei+22b] trong khi những dòng khác cải thiện hiệu suất bằng cách tối ưu hóa các ví dụ
được chọn cho prompt [Dia+23; Liu+22b], khuyến khích các mô hình suy luận tuần tự [Koj+22;
Wei+22b; Zel+22] và tổng hợp các prompt [Wan+22b; Wan+22a]. Không may, thích ứng tác vụ dựa trên prompt
có nhiều nhiễu [Lu+22]. Một cách khác, điều chỉnh prompt cải thiện khả năng trong ngữ cảnh của
các mô hình bằng cách huấn luyện một lượng nhỏ các vector có thể học [LL21; LAC21; Liu+22c] cho các tác vụ cụ thể.
Trong khi những phương pháp này đã được chỉ ra là cải thiện hiệu suất học trong ngữ cảnh, chúng yêu cầu
tinh chỉnh cụ thể cho tác vụ và không bất khả tri về tác vụ.

Các công trình gần đây tìm cách hiểu tính chất học trong ngữ cảnh của LLMs bằng cách trình bày các diễn giải
cơ học của học trong ngữ cảnh [Osw+22], thực hiện phân tích khám phá về hành vi học trong ngữ cảnh [Wei+23],
và giải thích nó như suy luận Bayes ẩn [Xie+21]. Tài liệu hiện có chứng minh rằng LLMs có thể học các lớp
hàm đơn giản trong ngữ cảnh [Gar+22] và đề xuất rằng LLMs đang thực hiện gradient descent khi học các tác vụ
trong ngữ cảnh [Osw+22]. Bổ sung cho những điều này, công trình của chúng tôi cung cấp thông tin về cơ chế
của học trong ngữ cảnh và những thiếu sót của nó.

Hơn nữa, các chiến lược chuyển giao tác vụ thích ứng LLMs cho một tác vụ mục tiêu được chỉ định trước. Các chiến lược
từ tinh chỉnh hiệu quả tham số (PEFT) [Hou+19; Zha+23] đến thích ứng Hạng thấp (LoRA) [Hu+22]
cái mà giới thiệu các ma trận phân tách hạng có thể huấn luyện vào mỗi lớp để kết hợp linear probing
và tinh chỉnh [Kum+22]. Trong khi chúng có hiệu suất tốt, những phương pháp này yêu cầu huấn luyện
các mô hình trên cơ sở từng tác vụ một trái ngược với Tart.

3 Chiến lược thích ứng tác vụ: Phân loại và đánh giá
Chúng tôi bắt đầu bằng cách mô tả vấn đề thích ứng các mô hình ngôn ngữ được huấn luyện trước cho một tập hợp
các tác vụ hạ nguồn trong khi bất khả tri về tác vụ, có năng lực về hiệu suất, và có khả năng mở rộng dữ liệu. Với
những tiêu chí này, chúng tôi đánh giá các phương pháp thích ứng tác vụ hiện có và đề xuất phân tách biểu diễn-suy luận
để hiểu hiệu suất tương đối của chúng.

3.1 Phát biểu vấn đề và tiêu chí đánh giá
Trọng tâm của chúng tôi là các phương pháp thích ứng các mô hình ngôn ngữ lớn được huấn luyện trước (LLMs) cho các tác vụ
hạ nguồn. Cụ thể, cho một LLM và dữ liệu được gán nhãn hạn chế cho một tác vụ, làm thế nào để thích ứng mô hình
cho tác vụ? Khi đánh giá một chiến lược thích ứng tác vụ, chúng tôi quan tâm đến các thuộc tính sau:

Bất khả tri về tác vụ. Với khả năng chung của LLMs được huấn luyện trước, chúng tôi phấn đấu sử dụng cùng
mô hình trên các tác vụ khác nhau mà không yêu cầu bất kỳ huấn luyện cụ thể nào cho tác vụ. Với sự gia tăng kích thước mô hình,
chi phí triển khai các mô hình cụ thể cho tác vụ tăng cả trong quá trình huấn luyện (tìm kiếm siêu tham số đắt đỏ)
cũng như trong quá trình suy luận (triển khai nhiều mô hình). Nói chung, các phương pháp bất khả tri về tác vụ
sẽ mở rộng tốt hơn với kích thước mô hình tăng lên bằng cách tránh cả hai chi phí này.

Chất lượng hiệu suất. Chúng tôi muốn các phương pháp thích ứng có khả năng cạnh tranh về hiệu suất
khi so sánh với các phương pháp cụ thể cho tác vụ trên một loạt rộng các tác vụ. Đối với các tác vụ phân loại nhị phân,
phương pháp nên có độ chính xác có thể so sánh với các phương pháp cụ thể cho tác vụ.

Khả năng mở rộng dữ liệu. Phương pháp thích ứng tác vụ nên có khả năng mở rộng với số lượng ví dụ tác vụ được gán nhãn.
Cụ thể, phương pháp nên có khả năng học từ các bộ dữ liệu lớn, và liên tục cải thiện chất lượng hiệu suất của nó.

3.2 Phân loại các chiến lược thích ứng tác vụ
Chúng ta có thể phân loại rộng rãi các chiến lược thích ứng tác vụ hiện có cho LLMs thành học trong ngữ cảnh,
tinh chỉnh mô hình, và huấn luyện adapter cụ thể cho tác vụ (xem Hình 1).

--- TRANG 4 ---
Học trong ngữ cảnh. Học trong ngữ cảnh cho phép thích ứng mô hình mà không cập nhật bất kỳ
tham số mô hình nào, bằng cách đơn giản cung cấp một vài minh chứng của tác vụ trong prompt LLM.
Học trong ngữ cảnh hoàn toàn bất khả tri về tác vụ vì cùng một mô hình có thể được sử dụng trên các tác vụ
vì không có trọng số nào được cập nhật tại thời điểm suy luận. Tuy nhiên, hiệu suất của nó thường không ngang bằng
khi so sánh với các phương pháp cụ thể cho tác vụ và nó không mở rộng tốt với dữ liệu vì số lượng
ví dụ có thể được sử dụng bị nút cổ chai bởi độ dài ngữ cảnh của mô hình.

Tinh chỉnh. Lớp phương pháp truyền thống này cập nhật trọng số mô hình để thích ứng nó cụ thể
cho tác vụ, thường bằng cách thực hiện gradient descent trên bộ dữ liệu được gán nhãn. Các phương pháp tinh chỉnh
không bất khả tri về tác vụ vì chúng thay đổi mô hình cơ bản đáng kể nhưng thường đạt được
hiệu suất tiên tiến cho bất kỳ tác vụ nào và có khả năng mở rộng dữ liệu.

Adapter. Adapter thích ứng LLM cơ bản cho một tác vụ cụ thể bằng cách kết hợp mô hình cơ bản LLM
với một tập hợp tham số bổ sung được tối ưu hóa cho tác vụ. Trái ngược với tinh chỉnh
cái mà thực hiện cập nhật cho mô hình cơ bản, adapter giữ mô hình cơ bản đóng băng và chỉ cập nhật
các tham số bổ sung. Hiệu suất của adapter thường cạnh tranh với tinh chỉnh đầy đủ.

3.3 Hiểu hiệu suất thông qua phân tách Biểu diễn-Suy luận
Từ phân loại các phương pháp thích ứng tác vụ, chỉ học trong ngữ cảnh thỏa mãn thuộc tính bất khả tri về tác vụ
nhưng nó luôn kém hiệu suất hơn các phương pháp điều chỉnh cụ thể cho tác vụ. Phần này
điều tra tại sao khoảng cách hiệu suất này tồn tại. Chúng tôi giả thuyết rằng đó có thể là vì (a) các
biểu diễn được học bởi LLM không đủ để học một bộ dự đoán tốt cho tác vụ cụ thể, hoặc
(b) LLM thiếu khả năng suy luận trên những biểu diễn này để đưa ra dự đoán tốt cho tác vụ.

Để hiểu liệu các biểu diễn có đủ thông tin, chúng tôi huấn luyện một bộ phân loại tuyến tính cụ thể cho tác vụ
sử dụng những biểu diễn này, còn được gọi là linear probing, và đánh giá độ chính xác của nó.
Gọi Acc_FT, Acc_ICL, và Acc_LR lần lượt biểu thị độ chính xác đạt được bởi tinh chỉnh, học trong ngữ cảnh, và
bởi linear probing. Sử dụng điều này như một trung gian, chúng tôi phân tách khoảng cách hiệu suất
∆perf := Acc_FT - Acc_ICL = Acc_FT - Acc_LR + Acc_LR - Acc_ICL
                              |_______|      |____________|
                                ∆rep           ∆reas        (1)

trong đó ∆rep đại diện cho khoảng cách trong hiệu suất có thể quy cho khả năng biểu diễn
không đủ và ∆reas là khoảng cách hiệu suất do khả năng suy luận không đủ. Sử dụng phân tách này,
chúng tôi xem xét các giả thuyết sau:

H1. Các biểu diễn LLM có đủ thông tin để thực hiện tác vụ trong ngữ cảnh, nhưng chúng thiếu
khả năng suy luận để thực hiện tác vụ tốt.

H2. Tinh chỉnh ảnh hưởng đến cả biểu diễn và suy luận nhưng cải thiện trong khả năng suy luận
chủ yếu dẫn đến hiệu suất tốt hơn.

H3. Tinh chỉnh và adapter không bất khả tri về tác vụ vì huấn luyện cụ thể cho tác vụ làm tổn hại
khả năng chuyển giao suy luận của chúng.

Bây giờ chúng tôi phân tích từng phương pháp thích ứng tác vụ thông qua lăng kính của các giả thuyết trên.
Chúng tôi thực hiện tất cả các thí nghiệm với ba lớp mô hình ngôn ngữ khác nhau (GPT-Neo, Pythia,
Bloom) trên một tập hợp 6 tác vụ phân loại nhị phân. Xem Phụ lục B để biết thêm chi tiết.

--- TRANG 5 ---
(a)                  (b)                  (c)
Hình 3: Tất cả kết quả cho GPT-Neo (125M). (a) Độ chính xác của học trong ngữ cảnh so với linear probing trên
embedding mô hình: các biểu diễn có đủ thông tin. (b) Biểu đồ phân tán cho thấy mức tăng biểu diễn và
suy luận (xem eq. (1)) trên các bộ dữ liệu NLP khác nhau cho một mô hình được tinh chỉnh khi so sánh với học trong ngữ cảnh cơ bản.
Tinh chỉnh chủ yếu cải thiện suy luận cụ thể cho tác vụ trên các bộ dữ liệu. (c) Độ chính xác (trung bình trên 6 bộ dữ liệu)
của mô hình được tinh chỉnh trên AGNews và kiểm tra trên tác vụ riêng biệt X so với mô hình được tinh chỉnh trên tác vụ X
và kiểm tra trên cùng tác vụ X. Trung bình, tinh chỉnh làm tổn hại tính bất khả tri về tác vụ và có thể giảm 25% so với
tinh chỉnh cho tác vụ cụ thể.

Học trong ngữ cảnh: LLMs thiếu khả năng suy luận. Chúng tôi bắt đầu bằng cách nghiên cứu khoảng cách biểu diễn
và suy luận, như được định nghĩa trong eq. (1), cho học trong ngữ cảnh. Trong Hình 3a, chúng tôi vẽ biểu đồ độ chính xác trung bình
trên các bộ dữ liệu cho học trong ngữ cảnh, tinh chỉnh cụ thể cho tác vụ, và linear probing. Chúng ta thấy
rằng trên các mô hình và số lượng ví dụ trong ngữ cảnh khác nhau, khoảng cách suy luận ∆reas chiếm
lên đến 79,11% khoảng cách hiệu suất giữa học trong ngữ cảnh và tinh chỉnh. Điều này chỉ ra rằng
các biểu diễn LLM có đủ thông tin nhưng thiếu khả năng suy luận trên chúng.

Tinh chỉnh: Cải thiện suy luận cụ thể cho tác vụ. Tiếp theo chúng tôi điều tra cách tinh chỉnh cho
một tác vụ cụ thể ảnh hưởng đến hiệu suất của mô hình cơ bản. Trong Hình 3b, chúng tôi cho thấy một biểu đồ phân tán
của các mức tăng có thể quy cho cải thiện biểu diễn so với mức tăng suy luận. Chúng ta
thấy rằng, trên các mô hình, cải thiện suy luận chiếm 73,06% các cải thiện. Điều này
chỉ ra rằng trong khi tinh chỉnh cải thiện cả suy luận và biểu diễn của LLM, các mức tăng
chủ yếu do cải thiện trong suy luận cụ thể cho tác vụ. Hơn nữa, tinh chỉnh cụ thể cho tác vụ này
của LLM làm tổn hại hiệu suất của nó trên các tác vụ khác. Trong Hình 3c, chúng tôi cho thấy rằng độ chính xác
của một mô hình được tinh chỉnh trên bộ dữ liệu AGNews [ZZL15], dẫn đến mức giảm trung bình 25,77%
trên các tác vụ khác. Hơn nữa, mức giảm độ chính xác này có thể quy cho việc giảm khả năng suy luận cụ thể cho tác vụ
—những điều này chiếm 72,58% mức giảm (xem Phụ lục B để biết thêm chi tiết).

Adapter: Làm suy yếu tính bất khả tri về tác vụ thông qua suy luận. Adapter cụ thể cho tác vụ không thay đổi
khả năng biểu diễn cơ bản của mô hình. Để nghiên cứu khả năng khái quát hóa của chúng trên các tác vụ, chúng tôi
huấn luyện một adapter cho bộ dữ liệu AGNews và đánh giá nó trên các tác vụ khác. Trong Phụ lục B, chúng tôi cho thấy
rằng hiệu suất giảm trên các tác vụ trung bình 19,8%, chỉ ra rằng adapter chỉ học
khả năng suy luận cụ thể cho tác vụ.

4 Tart: Task-Agnostic Reasoning Transformers
Phân tích trên cho thấy cách khả năng suy luận hiệu quả của LLMs hạn chế
hiệu suất của nó khi so sánh với các phương pháp thích ứng cụ thể cho tác vụ. Dựa trên thông tin này,
chúng tôi đề xuất Tart, cái mà học một mô-đun suy luận mục đích chung hoàn toàn bất khả tri đối với
LLM cơ bản và khi được kết hợp với bất kỳ LLM nào thông qua embedding của nó, cải thiện chung chung
khả năng suy luận của nó. Tart là một phương pháp hoàn toàn bất khả tri về tác vụ hoạt động trên một bộ
các tác vụ mà không cần bất kỳ huấn luyện cụ thể nào cho tác vụ.

--- TRANG 6 ---
Tart bao gồm hai thành phần: một mô-đun suy luận bất khả tri về tác vụ chung chung, và embedding
từ LLM cơ bản. Mô-đun suy luận được huấn luyện chỉ sử dụng dữ liệu tổng hợp (các bài toán hồi quy logistic Gaussian),
bất khả tri về mô hình ngôn ngữ được huấn luyện tự hồi quy, với mục tiêu học thực hiện suy luận xác suất (Phần 4.1).
Mô-đun transformer đã học này sau đó được kết hợp với LLM cơ bản, mà không cần huấn luyện, bằng cách
đơn giản tổng hợp embedding đầu ra và sử dụng chúng như đầu vào cùng với nhãn lớp (Phần 4.2). Cùng nhau,
những thành phần này làm cho Tart bất khả tri về tác vụ, tăng chất lượng hiệu suất bằng cách cải thiện suy luận,
và làm cho phương pháp có khả năng mở rộng dữ liệu bằng cách tổng hợp embedding đầu vào thành một vector duy nhất.

Một cách trực quan, tác vụ hồi quy logistic Gaussian là một tác vụ suy luận xác suất đơn giản trong đó
mục tiêu là hồi quy một vector đặc trưng cho trước thành một nhãn nhị phân rời rạc. Dạy một mô-đun độc lập
thực hiện một họ những tác vụ này và kết hợp chúng với các mô hình ngôn ngữ được huấn luyện trước
có thể được coi là một cách để cải thiện chung chung khả năng suy luận của LLM bằng cách làm cho chúng
thực hiện hồi quy như vậy tốt hơn.

4.1 Mô-đun suy luận: Liệu Transformer có thể học suy luận xác suất?
Mô-đun suy luận của Tart là một mô hình dựa trên Transformer được huấn luyện để thực hiện suy luận xác suất
trong ngữ cảnh chỉ sử dụng dữ liệu được tạo tổng hợp.

4.1.1 Huấn luyện mô-đun suy luận
Mô-đun suy luận là một mô hình Transformer được huấn luyện tự hồi quy trên một họ
các tác vụ hồi quy logistic, với mỗi chuỗi đầu vào tương ứng với một bài toán hồi quy logistic khác nhau.
Chúng tôi tiếp theo mô tả kiến trúc mô hình và quy trình huấn luyện.

Kiến trúc mô hình. Mô-đun suy luận dựa trên kiến trúc Transformer decoder-only tiêu chuẩn
từ họ GPT-2 (xem Phụ lục C.1 để biết chi tiết). Kiến trúc nhận đầu vào là
một chuỗi các vector và được huấn luyện để dự đoán vector tiếp theo trong chuỗi. Chuỗi đầu vào
bao gồm k cặp ví dụ được gán nhãn (x1, y1), (x2, y2), . . . , (xk, yk), với mỗi ví dụ zi = (xi, yi)
chỉ sử dụng hai vị trí đầu vào của transformer – một cho các biến đồng biến x và một cho
nhãn y. Điều này trái ngược với LLMs tiêu chuẩn nơi mỗi ví dụ được trải rộng trên nhiều token
cái mà hạn chế số lượng ví dụ có thể được đặt trong ngữ cảnh. Ví dụ, với cửa sổ ngữ cảnh
2048, mô-đun của chúng tôi có thể hỗ trợ 1024 ví dụ trong khi mô hình cơ bản chỉ có thể hỗ trợ 10 ví dụ,
giả sử mỗi minh chứng bao gồm 200 token ngôn ngữ tự nhiên.

Quy trình huấn luyện. Mô-đun này được huấn luyện sử dụng gradient descent để tối thiểu hóa tổn thất tổng thể
ℓ(Tθ) := Ex,y[1/k ∑(i=1 to k) ℓCE(Tθ(z1:i-1, xi), yi)]                                                (2)

trong đó z1:i-1 tương ứng với i-1 ví dụ đầu tiên và ℓCE là tổn thất cross-entropy được đánh giá trên
dự đoán transformer và yi thật. Mỗi chuỗi huấn luyện st được sử dụng để cập nhật các tham số
w bao gồm một bài toán hồi quy logistic d-chiều khác nhau, được lấy mẫu như
Chuỗi st: wt ∼ N(0, Id), xi,t ∼ N(0, Id), yi,t ∼ σ(α⟨xi,t, wt⟩) cho i ∈ [k],                            (3)

trong đó σ đại diện cho hàm sigmoid và hệ số nhân α xác định mức độ nhiễu của
bài toán. Chúng tôi huấn luyện mô hình với d = 16 và k = 256. Quan sát rằng tổn thất chỉ được tính trên
đầu ra dự đoán của các đặc trưng x trong chuỗi. Chúng tôi mô tả các siêu tham số mô hình và
quy trình huấn luyện chi tiết hơn trong Phụ lục C.1.

--- TRANG 7 ---
Chúng tôi đã huấn luyện mô-đun suy luận với chiều đầu vào được đặt thành 16 với các nhãn y được mã hóa trong
không gian này bằng cách sử dụng mã hóa one-hot bằng cách nối nhãn thật với các số không. Trong khi hầu hết các mô hình cơ bản
tạo ra các biểu diễn có chiều cao hơn nhiều (từ 784 đến 2048). Để giảm
chiều của những biểu diễn này, chúng tôi thực hiện PCA trên embedding đầu ra của
mô hình cơ bản, học các thành phần chỉ sử dụng các điểm huấn luyện có sẵn cho tác vụ cụ thể đó.
Các ví dụ kiểm tra sau đó được chiếu lên những thành phần chính này để tạo ra biểu diễn đầu vào 16 chiều.

4.1.2 Thuộc tính của mô-đun suy luận
Mô-đun suy luận bất khả tri về tác vụ được mô tả ở trên được huấn luyện để hoạt động tốt trên một họ các tác vụ hồi quy logistic.
Chúng tôi nghiên cứu một số thuộc tính của mô-đun suy luận, cụ thể là nó học thực hiện tác vụ tốt như thế nào
ở cấp độ trường hợp và nó mạnh mẽ như thế nào đối với các biến thể trong mức độ nhiễu α.

Độ chính xác của suy luận xác suất. Để hiểu hiệu suất cấp độ trường hợp của
mô-đun suy luận, chúng tôi đánh giá nó trên một mẫu 64 bài toán hồi quy logistic khác nhau, được lấy mẫu
theo eq. (3). Đối với mỗi bài toán, chúng tôi huấn luyện các bộ phân loại tuyến tính cụ thể cho tác vụ sử dụng hồi quy logistic
và so sánh chúng với mô-đun suy luận bất khả tri về tác vụ của chúng tôi. Trong Hình 4a chúng tôi vẽ biểu đồ độ lệch
của các xác suất dự đoán (trung bình trên 64 bài toán) so với xác suất thật cho
mô-đun suy luận và các bộ giải logistic cụ thể cho tác vụ như một hàm của số lượng ví dụ được sử dụng
cho dự đoán. Chúng ta quan sát rằng lỗi cho mô-đun suy luận giảm như một hàm của
số lượng ví dụ trong ngữ cảnh và trong vòng 2% của hàm logistic cụ thể cho tác vụ.

Tính mạnh mẽ đối với mức độ nhiễu. Chúng tôi nghiên cứu tính mạnh mẽ của mô-đun đã học đối với các mức độ nhiễu,
α, của bài toán hồi quy logistic. Nhớ lại rằng chúng tôi đã huấn luyện mô-đun suy luận bằng cách cố định
mức độ nhiễu α = 10. Tại thời điểm suy luận, chúng tôi thay đổi mức độ nhiễu thành [0.5, 1, 10, 20], trong đó các giá trị thấp hơn
tương ứng với bài toán nhiễu hơn. Mô-đun suy luận khái quát hóa cho bài toán dễ hơn mà không có
bất kỳ sự giảm độ chính xác nào nhưng khi chúng ta làm cho bài toán khó hơn (α = [0.5, 1]), lỗi tăng lên
dần dần (xem Hình 4b).

4.2 Vai trò của biểu diễn: Nên lấy embedding nào?
Mô-đun suy luận kết hợp với LLM cơ bản thông qua embedding lớp cuối của nó. Một cách tự nhiên
để tạo ra những embedding này là đặt tất cả các ví dụ huấn luyện trong ngữ cảnh và sau đó lấy trung bình
các vector embedding tương ứng với ví dụ cụ thể (xem Hình 5a). Tại thời điểm suy luận,
chúng ta nối ví dụ kiểm tra vào tập huấn luyện, và lấy trung bình embedding tương ứng với
ví dụ này. Chúng tôi gọi những embedding này là embedding vanilla. Thí nghiệm của chúng tôi tiết lộ rằng những embedding này
dường như bão hòa (hoặc thậm chí làm tổn hại hiệu suất) vượt quá một số lượng ví dụ trong ngữ cảnh nhất định (xem Hình 4c).
Một lý do có thể là bản chất nhân quả của mô hình khiến những embedding này có thông tin bất đối xứng
—embedding của mỗi ví dụ bị ảnh hưởng bởi các ví dụ đi trước nó.

Để chống lại sự bất đối xứng này, chúng tôi đề xuất embedding leave-one-out (LOO) trong đó embedding
cho mỗi điểm huấn luyện được hình thành bằng cách đặt tất cả các ví dụ huấn luyện khác trước nó trong prompt sao cho
tất cả embedding được hình thành với cùng nội dung thông tin (xem Hình 5b). Trong Hình 4c,
thay đổi kiểu embedding từ vanilla thành LOO liên tục cải thiện hiệu suất trên các mô hình
và tác vụ. Embedding LOO giúp Tart có khả năng mở rộng dữ liệu bằng cách cho phép nó nhúng một số lượng lớn hơn nhiều
điểm so với cửa sổ ngữ cảnh có thể hỗ trợ. Để làm điều này, chúng tôi chỉ sử dụng một tập con của các ví dụ huấn luyện
như prompt trong ngữ cảnh. Mô-đun suy luận, bằng thiết kế kiến trúc của nó, đã có thể
chứa nhiều ví dụ hơn so với những gì được hỗ trợ bởi cửa sổ ngữ cảnh của LLM cơ bản.

4.3 Phân tích lý thuyết: Khái quát hóa của Tart cho các tác vụ ngôn ngữ
Chúng tôi nghiên cứu các thuộc tính khái quát hóa của phương pháp bất khả tri về tác vụ được đề xuất Tart. Lưu ý rằng
mô-đun suy luận được huấn luyện hoàn toàn trên dữ liệu tổng hợp trong khi tại thời điểm đánh giá, đầu vào của chúng ta là
embedding từ một tác vụ ngôn ngữ tự nhiên. Trong Định lý 1 chúng tôi chỉ ra rằng hiệu suất của nó trên
tác vụ ngôn ngữ tự nhiên phụ thuộc vào sự dịch chuyển phân phối từ tổng hợp đến phân phối thật
(xem Phụ lục C.3 để biết phát biểu chính thức và chứng minh).

Định lý 1 (Không chính thức). Gọi T đại diện cho lớp các mô hình transformer và TS ∈ T biểu thị
mô-đun suy luận được huấn luyện trên tập S của hồi quy tổng hợp với nsyn chuỗi được lấy mẫu từ
phân phối Psyn trong eq.(3). Lỗi của transformer TS khi được đánh giá trên một phân phối PNL
trên các chuỗi ngôn ngữ tự nhiên là
errPNL ≲ W1(PNL, Psyn) + √(Comp(T)/nsyn) + êrrPsyn(TS),                                           (4)

trong đó W1 biểu thị metric Wasserstein-1, Comp(T) đại diện cho độ phức tạp của lớp T, và êrr
đại diện cho lỗi trên phân phối thực nghiệm.

Một vài nhận xét theo thứ tự: Hạng tử đầu tiên đại diện cho lỗi dịch chuyển phân phối giữa
tác vụ ngôn ngữ tự nhiên thật và tác vụ tổng hợp. Hạng tử thứ hai tương ứng với lỗi khái quát hóa
trên tác vụ hồi quy logistic, có thể được làm cho nhỏ tùy ý vì nó mở rộng với nsyn,

--- TRANG 8 ---
(a)                  (b)                  (c)
Hình 4: Thuộc tính của mô-đun suy luận Tart. (a) So sánh với hàm logistic đã học:
mô-đun suy luận khôi phục các xác suất cơ bản. (b) Biến thiên trong lỗi với các mức độ nhiễu khác nhau cho
mô hình được huấn luyện trên α = 10. (c) So sánh hiệu suất Tart khi sử dụng embedding LOO và embedding vanilla.

số lượng điểm dữ liệu tổng hợp có thể được tạo ra mà không có bất kỳ chi phí nào. Hạng tử thứ ba là
lỗi tối ưu hóa chỉ ra mô-đun suy luận TS đã khớp với tập huấn luyện tổng hợp tốt như thế nào.

5 Đánh giá thực nghiệm
Chúng tôi đánh giá Tart trên một loạt rộng các tác vụ phân loại nhị phân trên ba miền: ngôn ngữ,
thị giác và âm thanh. Chúng tôi chứng minh rằng Tart cải thiện hiệu suất trong ngữ cảnh cơ bản và thu hẹp
khoảng cách với các chiến lược cụ thể cho tác vụ tiêu chuẩn. Chúng tôi cũng tiến hành các ablation để chứng minh rằng Tart
mở rộng với kích thước mô hình và có thể hỗ trợ gấp 10 lần mẫu hơn học trong ngữ cảnh.

5.1 Thiết lập thí nghiệm
Bộ dữ liệu. Chúng tôi mô tả ngắn gọn các bộ dữ liệu được sử dụng, với chi tiết có sẵn trong Phụ lục D.1. Chúng tôi xem xét
14 tác vụ phân loại nhị phân khác nhau từ phân loại cảm tình, phân loại bài báo tin tức
đến phát hiện thư rác. Các bộ dữ liệu đánh giá bao gồm: SST [Soc+13], Rotten Tomatoes [PLV02], SMS
Spam [AHY11], IMDB [Maa+11], Civil Comments [Bor+19], AGNews [ZZL15], DBPedia [ZZL15],
và bộ dữ liệu Youtube [Zha+21]. Vì AGNews và DBPedia14 là các bộ dữ liệu đa lớp, chúng tôi
xây dựng 4 tác vụ phân loại nhị phân từ mỗi bộ dữ liệu tương ứng. Đối với mỗi bộ dữ liệu, chúng tôi cắt ngắn
văn bản đầu vào có nhiều nhất 100 ký tự để cho phép chúng tôi khớp đủ số lượng mẫu trong ngữ cảnh.

Họ mô hình. Chúng tôi đánh giá phương pháp của chúng tôi trên ba họ mô hình khác nhau: GPT-
Neo[Bla+21], Pythia [Bid+23], và Bloom[Sca+22]. Đối với các đánh giá của chúng tôi trên 14 bộ dữ liệu, chúng tôi
sử dụng GPT-Neo (125M), Pythia (160M) và Bloom (560M). Đối với các ablation trên các mô hình lớn hơn,
chúng tôi đánh giá các mô hình với 1B tham số trên mỗi họ mô hình (tức là, GPT-Neo (1.3B),
Pythia (1.4B) và Bloom (1.7B)) và các mô hình với 3B tham số (tức là, GPT-Neo (2.7B),
Pythia (2.8B) và Bloom (3B)). Chúng tôi bổ sung đánh giá trên GPT-J (6B) [WK21].

Baseline. Chúng tôi đánh giá các mô hình của chúng tôi so với tất cả các loại chiến lược thích ứng tác vụ được mô tả trong
Phần 3.2: 1) học trong ngữ cảnh, 2) tinh chỉnh đầy đủ, 3) tinh chỉnh lớp cuối, 4) tinh chỉnh đầu LM,
và 5) adapter. Đối với mỗi baseline, chúng tôi thực hiện tìm kiếm siêu tham số rộng rãi trên số
epoch và learning rate cho mỗi bộ dữ liệu để tối ưu hóa hiệu suất (xem Phụ lục D.1 cho
chi tiết siêu tham số). Đối với Tart, chúng tôi chọn một tập hợp tham số cơ bản mặc định và sử dụng cùng
mô-đun suy luận với chính xác cùng trọng số cho tất cả các thí nghiệm trong phần này.

5.2 Đánh giá benchmark ngôn ngữ tự nhiên
Đối với phần này, tất cả độ chính xác được báo cáo được lấy trung bình trên 5 seed ngẫu nhiên độc lập. Một bộ
kết quả đầy đủ với độ lệch chuẩn có thể được tìm thấy trong Phụ lục D.2.

Hiệu suất so với baseline. Như được hiển thị trong Phụ lục D.2, trung bình trên tất cả các tác vụ
và họ mô hình, Tart cải thiện hiệu suất học trong ngữ cảnh cơ bản trung bình
18,4 điểm, cải thiện adapter head 3,4 điểm, và trong vòng 3,1 điểm của tinh chỉnh đầy đủ. Chúng tôi
cũng quan sát rằng Tart luôn vượt trội hơn các chiến lược cụ thể cho tác vụ của tinh chỉnh đầu LM
và tinh chỉnh lớp cuối.

--- TRANG 9 ---
(a) Embedding Vanilla        (b) Embedding LOO
Hình 5: Giao thức Embedding Tart. (a) Đối với embedding vanilla, ví dụ kiểm tra được nối vào
tập huấn luyện và chuỗi được truyền cho mô hình cơ bản. Biểu diễn cho mỗi ví dụ huấn luyện
trong chuỗi này được lấy như embedding trung bình trên tất cả các token của nó. (b) Đối với embedding LOO, chúng ta
tạo ra embedding cho mỗi ví dụ huấn luyện riêng biệt bằng cách đặt tất cả các ví dụ huấn luyện khác trước nó trong
prompt và lấy trung bình embedding trên các token của ví dụ cuối cùng. Hình cho thấy cách tính toán
embedding cho ví dụ huấn luyện thứ i.

Hiệu suất trên RAFT Benchmark Chúng tôi đánh giá Tart trên tất cả các tác vụ phân loại nhị phân trong
RAFT Benchmark, theo giao thức được sử dụng trong HELM [Lia+22]. Khi được áp dụng với GPT-Neo
(125M), Tart vượt trội hơn Bloom (176B), và trong vòng 4% điểm của GPT-3 (175B), cả hai
đều lớn hơn 1000 lần về kích thước. Xem Bảng 1 để biết độ chính xác chính xác.

Hiệu suất với số lượng ví dụ trong ngữ cảnh. Kết quả của chúng tôi chứng minh rằng hiệu suất
của Tart mở rộng với số lượng ví dụ trong ngữ cảnh (xem Hình 6a). Trên 14 tác vụ và 3 họ
mô hình, khi mở rộng từ 18 đến 64 ví dụ, Tart cải thiện hiệu suất trung bình 4,8%.
Tương ứng, tinh chỉnh đầy đủ cải thiện hiệu suất 9,0%.

Mở rộng với kích thước mô hình cơ bản. Chúng tôi phân tích cách các chiến lược thích ứng tác vụ khác nhau mở rộng
so với kích thước mô hình sử dụng họ GPT-Neo: GPT-Neo (125M), GPT-Neo (1.3B) và
GPT-J (6B). Hình 6b cho thấy rằng khi mở rộng từ tham số 100M đến 6B, hiệu suất của
các phương pháp cụ thể cho tác vụ và Tart tăng như một hàm của quy mô. Đối với Tart, hiệu suất tăng
9,8% trong khi sử dụng cùng mô-đun suy luận trên các kích thước mô hình. Hơn nữa, sự khác biệt trong
hiệu suất giữa Tart và baseline tinh chỉnh giảm từ 7,5% đến 2,2% từ quy mô 100M
đến quy mô 6B.

Vượt quá độ dài ngữ cảnh. Chúng tôi đánh giá các thuộc tính mở rộng dữ liệu cho cả học trong ngữ cảnh
và Tart (Hình 6c). Để chứng minh thuộc tính mở rộng, chúng tôi không cắt ngắn văn bản đầu vào thành
100 ký tự và sử dụng toàn bộ chuỗi văn bản. Đối với Tart, chúng tôi quan sát rằng độ chính xác tiếp tục
cải thiện khi mở rộng từ 18 đến 256 ví dụ trong ngữ cảnh với mức tăng hiệu suất 6,8%. Trong
so sánh, ICL, bị nút cổ chai bởi độ dài ngữ cảnh, hỗ trợ ít mẫu hơn 10 lần, với
cửa sổ ngữ cảnh bão hòa chỉ ở 24 ví dụ và tụt hậu Tart trung bình 19,1%.

5.3 Mở rộng cho các phương thức khác
Chúng tôi chứng minh rằng Tart không chỉ bất khả tri về mô hình và tác vụ, mà còn về phương thức. Chúng tôi
mở rộng Tart cho các tác vụ phân loại trên các phương thức ngoài ngôn ngữ: thị giác và âm thanh. Đối với các tác vụ thị giác,
chúng tôi sử dụng biểu diễn từ mô hình Vision Transformer (ViT) được huấn luyện trước 307M tham số của Google
[Wu+20]: ViT-large-patch16-224-in21k. Đối với các tác vụ âm thanh, chúng tôi sử dụng biểu diễn từ
mô hình Whisper được huấn luyện trước 1.5B tham số của OpenAI [Rad+22]: Whisper-large. Trong việc áp dụng Tart
cho các biểu diễn từ những mô hình này, chúng tôi cung cấp một cách để thực hiện học trong ngữ cảnh trong
các phương thức ngoài văn bản. Chúng tôi giới thiệu người đọc đến Phụ lục D.3 để biết thêm chi tiết về thiết lập thí nghiệm.

Ứng dụng thị giác. Chúng tôi đánh giá hiệu suất của Tart trên các phiên bản phân loại nhị phân của
CIFAR-10 [Kri09] (lớp máy bay và chim) và MNIST [LCB10] (lớp 0 và 8). Như được hiển thị trong
Hình 7a và 7b, hiệu suất của Tart có khả năng cạnh tranh với các phương pháp thích ứng cụ thể cho tác vụ.

--- TRANG 10 ---
Mô hình Tart GPT-J (6B) OPT (175B) Bloom (176B) GPT-3 (175B)
Độ chính xác 0.634 0.608 0.637 0.595 0.673

Bảng 1: Hiệu suất Phân loại Nhị phân RAFT (HELM) (Độ chính xác Trung bình). Tart được sử dụng
với mô hình GPT-Neo (125M) nhỏ hơn 1000 lần so với các mô hình tham số 175B tương ứng.
Tart vượt trội hơn Bloom (176B) và có khả năng cạnh tranh với OPT (175B) và GPT-3 (175B).

--- TRANG 11 ---
(a)                  (b)                  (c)
Hình 6: Hiệu ứng của quy mô. (a) Hiệu ứng của số lượng ví dụ trong ngữ cảnh đến hiệu suất cho các chiến lược
thích ứng tác vụ khác nhau. (b) Hiệu ứng của kích thước mô hình đến hiệu suất của các chiến lược thích ứng tác vụ khác nhau. (c)
Vượt quá giới hạn độ dài ngữ cảnh, so sánh hiệu suất so với số lượng ví dụ trong ngữ cảnh.

Ứng dụng âm thanh. Chúng tôi đánh giá Tart trên một phiên bản phân loại nhị phân của bộ dữ liệu Speech Commands
[War18], trong đó tác vụ là phân loại các phát ngôn "stop" và "go". Như được hiển thị trong Hình 7c,
hiệu suất của Tart có khả năng cạnh tranh với các phương pháp thích ứng tác vụ.

6 Thảo luận
Chúng tôi nhìn vào vấn đề học bất khả tri về tác vụ với LLMs. Chúng tôi chỉ ra rằng LLMs thiếu khả năng
thực hiện suy luận đơn giản trên các biểu diễn đã học của chúng và giới thiệu Tart, một phương pháp bất khả tri về tác vụ, mô hình và
miền để cải thiện khả năng suy luận của chúng. Trong công trình này, chúng tôi tập trung vào các tác vụ phân loại nhị phân,
chỉ ra rằng dữ liệu tác vụ hồi quy logistic tổng hợp có thể được sử dụng để huấn luyện một mô-đun suy luận chung chung
có khả năng hoàn thành lớp tác vụ này. Các mở rộng cho các tác vụ phân loại đa lớp có thể
bằng cách sử dụng phương pháp one-vs-all hoặc bằng cách huấn luyện mô-đun suy luận của Tart sử dụng
dữ liệu tổng hợp đa lớp. Trong công trình tương lai, chúng tôi tìm cách hiểu liệu các tác vụ tổng hợp tồn tại cho
huấn luyện các mô-đun suy luận chung chung khác, có khả năng cải thiện hiệu suất LLM cơ bản trên các tác vụ như
tạo sinh hoặc tóm tắt.

Lời cảm ơn
Chúng tôi biết ơn Simran Arora, Rishi Bommasani, Niladri Chatterji, Arjun Desai, Sabri Eyuboglu,
Neha Gupta, Karan Goel, Erik Jones, Ananya Kumar, Cassidy Laidlaw, Megan Leszczynski, Piero
Molino, Laurel Orr, Michael Poli, Dimitris Tsipras, Michael Wornow, Ce Zhang, và Michael Zhang
vì những nhận xét và phản hồi hữu ích của họ, và các cuộc thảo luận đã giúp định hình dự án này.

Chúng tôi biết ơn sự hỗ trợ của NIH dưới số U54EB020405 (Mobilize), NSF dưới
số CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), và 1937301 (RTML); US
DEVCOM ARL dưới số W911NF-21-2-0251 (Interactive Human-AI Teaming); ONR dưới số
N000141712266 (Unifying Weak Supervision); ONR N00014-20-1-2480: Understanding and Applying
Non-Euclidean Geometry in Machine Learning; N000142012275 (NEPTUNE); NXP, Xilinx, LETI-
CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson,
Qualcomm, Analog Devices, Google Cloud, Salesforce, Total, chương trình HAI-GCP Cloud Credits for
Research, Stanford Data Science Initiative (SDSI), và các thành viên của dự án Stanford DAWN:
Facebook, Google, và VMWare. CDS được hỗ trợ bởi NSF CAREER (giải thưởng 2046760).

Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối bản in lại cho các mục đích Chính phủ
bất chấp bất kỳ ghi chú bản quyền nào trên đó. Bất kỳ ý kiến, phát hiện, và kết luận
hoặc khuyến nghị được thể hiện trong tài liệu này là của các tác giả và không nhất thiết
phản ánh quan điểm, chính sách, hoặc sự tán thành, được thể hiện rõ ràng hoặc ngụ ý, của NIH, ONR, hoặc Chính phủ
Hoa Kỳ.

--- TRANG 12 ---
(a) MNIST            (b) CIFAR-10         (c) Speech Commands
Hình 7: Tart có thể khái quát hóa trên các miền sử dụng cùng mô-đun suy luận đã được sử dụng cho các benchmark ngôn ngữ:
Hiệu suất trên các tác vụ thị giác (MNIST, CIFAR-10) và một tác vụ âm thanh (Speech Commands).

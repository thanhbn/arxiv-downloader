# 2305.11186.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2305.11186.pdf
# Kích thước tệp: 1168509 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Nén, Sau Đó Gợi Ý: Cải Thiện Sự Đánh Đổi Độ Chính Xác-Hiệu Quả
của Suy Luận LLM với Prompt Có Thể Chuyển Giao
Zhaozhuo Xu∗1, Zirui Liu∗1, Beidi Chen2, Yuxin Tang1, Jue Wang3, Kaixiong Zhou1, Xia
Hu1, và Anshumali Shrivastava1
1Khoa Khoa Học Máy Tính, Đại Học Rice
2Khoa Kỹ Thuật Điện và Máy Tính, Đại Học Carnegie Mellon
3ETH Zürich, Thụy Sĩ
{Zhaozhuo.Xu, Zirui.Liu, Yuxin.Tang, Kaixiong.Zhou, Xia.Hu,
Anshumali.Shrivastva}@rice.edu ,beidic@andrew.cmu.edu ,juewang@inf.ethz.ch
Tóm Tắt
Mặc dù số lượng tham số khổng lồ trong các Mô Hình Ngôn Ngữ Lớn (LLM) góp phần vào
hiệu suất vượt trội của chúng, quy mô khổng lồ này khiến chúng không hiệu quả và tốn nhiều
bộ nhớ. Do đó, chúng khó triển khai trên phần cứng thông thường, chẳng hạn như một GPU
đơn lẻ. Với các ràng buộc về bộ nhớ và năng lượng của các thiết bị như vậy, các phương pháp
nén mô hình được sử dụng rộng rãi để giảm cả kích thước mô hình và độ trễ suy luận, điều này
về cơ bản đánh đổi chất lượng mô hình để đổi lấy hiệu quả được cải thiện. Do đó, tối ưu hóa
sự đánh đổi độ chính xác-hiệu quả này là rất quan trọng cho việc triển khai LLM trên phần
cứng thông thường. Trong bài báo này, chúng tôi giới thiệu một góc nhìn mới để tối ưu hóa
sự đánh đổi này bằng cách gợi ý các mô hình được nén. Cụ thể, chúng tôi đầu tiên quan sát
thấy rằng đối với một số câu hỏi nhất định, chất lượng sinh ra của một LLM được nén có thể
được cải thiện đáng kể bằng cách thêm các hard prompt được thiết kế cẩn thận, mặc dù điều
này không phải là trường hợp đối với tất cả các câu hỏi. Dựa trên quan sát này, chúng tôi đề
xuất một phương pháp học soft prompt trong đó chúng tôi cho mô hình được nén tiếp xúc với
quá trình học prompt, nhằm nâng cao hiệu suất của các prompt. Phân tích thực nghiệm của
chúng tôi cho thấy chiến lược soft prompt của chúng tôi cải thiện đáng kể hiệu suất của mô
hình LLaMA-7B được nén 8× (với nén kết hợp lượng tử hóa 4-bit và cắt bỏ trọng số 50%),
cho phép chúng đạt được hiệu suất tương đương với các đối tác chưa nén trên các benchmark
phổ biến. Ngoài ra, chúng tôi chứng minh rằng các prompt đã học này có thể được chuyển
giao qua các tập dữ liệu, tác vụ và mức độ nén khác nhau. Do đó, với khả năng chuyển giao
này, chúng ta có thể gắn soft prompt vào một mô hình mới được nén để cải thiện độ chính xác
thời gian kiểm tra theo cách "tại chỗ".
∗Đóng góp bằng nhau. Thứ tự tác giả được xác định bằng cách tung đồng xu.
1arXiv:2305.11186v2  [cs.CL]  10 Oct 2023

--- TRANG 2 ---
1 Giới Thiệu
Các Mô Hình Ngôn Ngữ Lớn (LLM) [27, 28, 2, 40, 33] đã cách mạng hóa lĩnh vực Xử Lý Ngôn
Ngữ Tự Nhiên (NLP). Đáng chú ý, các LLM được biết đến với khả năng học trong ngữ cảnh,
cho phép chúng tổng quát hóa cho các tác vụ chưa thấy mà không cần tinh chỉnh thêm [2]. Cụ
thể, các LLM được điều khiển thông qua các đặc tả ngôn ngữ tự nhiên của tác vụ do người dùng
cung cấp, hoặc prompt, minh họa cách hoàn thành một tác vụ. Được trang bị khả năng học trong
ngữ cảnh, chúng ta chỉ cần phục vụ một mô hình lớn duy nhất để xử lý hiệu quả các tác vụ khác
nhau. Mặc dù có khả năng thích ứng đáng chú ý, các LLM rất tốn kém để triển khai [3, 35]. Quá
trình suy luận của các LLM, chẳng hạn như LLaMA 2 [34], có thể yêu cầu nhiều GPU mạnh mẽ,
điều này cực kỳ tốn kém đối với cộng đồng nói chung. Do đó, việc tạo điều kiện cho suy luận LLM
trên phần cứng dễ tiếp cận hơn, chẳng hạn như một GPU đơn lẻ, vốn có tài nguyên tính toán và
bộ nhớ hạn chế, là rất quan trọng.

Để giải quyết vấn đề này, các phương pháp nén mô hình được sử dụng rộng rãi để giảm kích
thước mô hình và độ trễ suy luận, chẳng hạn như lượng tử hóa [26, 4, 36, 7] và cắt tỉa [6]. Các
phương pháp này về cơ bản đánh đổi chất lượng mô hình để đổi lấy độ trễ giảm và kích thước mô
hình nhỏ hơn. Do đó, có một sự đánh đổi không thể tránh khỏi giữa độ chính xác và hiệu quả,
dẫn đến sự giảm sút đáng chú ý trong độ chính xác của mô hình và do đó, lợi ích hiệu suất tổng
thể của các LLM. Để có cảm nhận, như được hiển thị trong Hình 1, mô hình đầy đủ (LLaMA-7B)
có thể cung cấp câu trả lời chính xác cho cả ba câu hỏi. Tuy nhiên, mô hình được cắt tỉa tạo ra
các câu trả lời không liên quan và ngoài chủ đề cho cùng những câu hỏi đó.

Cả nén mô hình và prompt đều có thể ảnh hưởng đến chất lượng sinh ra của các LLM. Do đó,
theo trực giác, chúng ta cũng có thể sử dụng prompt để giúp mô hình được nén tạo ra những câu
trả lời phù hợp hơn. Theo hiểu biết tốt nhất của chúng tôi, góc nhìn này chưa được khám phá
đầy đủ đối với các LLM. Do đó, một câu hỏi tự nhiên là, đối với một mô hình được nén, chúng ta
có thể thiết kế một prompt giúp nó sửa chữa các dự đoán của mình tương ứng không?

Trong bài báo này, chúng tôi cung cấp câu trả lời khẳng định đầu tiên cho câu hỏi trên. Như
được hiển thị trong Hình 1, chúng tôi gắn thêm một cách thủ công prompt " Hãy kiểm tra cẩn
thận ma trận trọng số trong mô hình, vì nó có thể chứa lỗi. Điều quan trọng là phải xác minh độ
chính xác của nó và thực hiện bất kỳ điều chỉnh cần thiết nào để đảm bảo hiệu suất tối ưu " vào
câu hỏi gốc. Mô hình được cắt tỉa có prompt, tức là "LLaMA-7B (62.5% sparsity) w./ Hard
Prompt" trong Hình 1, cho thấy sự cải thiện đáng kể trong các phản hồi của nó, mặc dù không
phải tất cả chúng đều chính xác hoặc hoàn chỉnh. Prompt được tạo thủ công này chỉ truyền đạt
rằng trọng số mô hình có thể không chính xác, mà không xem xét tập dữ liệu, phương pháp nén
hoặc tác vụ. Phát hiện này làm nổi bật tiềm năng đáng kể cho khả năng chuyển giao của "hard
prompt" này qua các tập dữ liệu, mức độ nén và tác vụ. Mặc dù có tiềm năng, prompt được thiết
kế thủ công này không có hiệu quả nhất quán. Lấy cảm hứng từ các nghiên cứu prompt có thể
học trước đây [19, 18], chúng tôi đưa ra giả thuyết rằng bằng cách liên quan trọng số nén vào
quá trình học prompt, một prompt có thể học có khả năng vượt qua hiệu suất của prompt được
thiết kế thủ công, đồng thời duy trì khả năng chuyển giao. Dựa trên hiểu biết này, chúng tôi giới
thiệu một mô hình học prompt nhằm huấn luyện các token prompt cộng thêm trên một LLM được
nén để nâng cao độ chính xác của nó. Chúng tôi nhấn mạnh rằng sự khác biệt chính giữa phương
pháp học prompt của chúng tôi và các khung tinh chỉnh prompt trước đây [19, 18, 32] là các
phương pháp trước đó chủ yếu sử dụng prompt để thích ứng mô hình cho các tác vụ downstream
cụ thể. Ngược lại, prompt đã học trong bài báo này giống với hard prompt trong Hình 1, vì nó
có thể được chuyển giao giữa các tập dữ liệu, phương pháp nén và tác vụ khác nhau.

Phân tích thực nghiệm của chúng tôi cho thấy phương pháp của chúng tôi cải thiện đáng kể
hiệu suất của mô hình LLaMA-7B được nén 8× (với nén kết hợp lượng tử hóa 4-bit và cắt tỉa
trọng số 50%), cho phép chúng đạt được hiệu suất tương đương với các đối tác chưa nén trên một
số benchmark tiêu chuẩn. Chúng tôi cũng quan sát một mức độ nhất định về khả năng chuyển
giao của các prompt đã học này qua các tập dữ liệu, tác vụ và mức độ nén khác nhau. Do đó,
với khả năng chuyển giao này, chúng ta có thể gắn soft prompt vào một mô hình mới được nén
để cải thiện độ chính xác thời gian kiểm tra theo cách "tại chỗ".
2

--- TRANG 3 ---
Q: Vui lòng đưa ra câu trả lời cho
câu hỏi này: Long Beach ở đâu?Tôi là một sinh viên và tôi đang
tìm việc làm.Long Beach là một thành phố ở
Quận Los Angeles,
California, Hoa Kỳ.Câu trả lời là: Long
Beach nằm ở Hoa Kỳ.Long Beach là một thành phố ở
Quận Los Angeles,
California.LLAMA-7B
(Đầy đủ)LLAMA-7B
(62.5% sparsity)LLAMA-7B
(62.5% sparsity)
w./ Hard PromptLLAMA-7B
(62.5% sparsity)
w./ Learned Prompt

Q: Vui lòng đưa ra câu trả lời cho
câu hỏi này: Tulsa, Oklahoma ở đâu?Tôi là sinh viên của
Đại học Tulsa.Tulsa ở bang
Oklahoma. Nó nằm ở
phần đông bắc của
bang.Ma trận trọng số là một
tập hợp các trọng số được
sử dụng để tính toán
trọng số của mô hình...Tulsa là một thành phố ở
Oklahoma.

Q: Vui lòng đưa ra câu trả lời cho
câu hỏi này: Măng tây là gì?Tôi không chắc măng tây
là gì.Măng tây là một loại
rau được trồng vào
mùa xuân. Nó thuộc họ
hoa loa kèn.Măng tây là một loại cây
được sử dụng để nấu ăn.Măng tây là một loại cây
mọc trong vườn

Hình 1: Hard prompt cho phép các LLM được nén lấy lại thường thức. Hard prompt được thiết kế
là " Hãy kiểm tra cẩn thận ma trận trọng số trong mô hình, vì nó có thể chứa lỗi. Điều quan trọng
là phải xác minh độ chính xác của nó và thực hiện bất kỳ điều chỉnh cần thiết nào để đảm bảo hiệu
suất tối ưu " (cột thứ tư từ trái). Chúng tôi làm nổi bật các câu trả lời được cải thiện bằng màu xanh.

2 Phát Biểu Vấn Đề và Nghiên Cứu Liên Quan

Trong phần này, chúng tôi sẽ bắt đầu bằng việc giới thiệu nút thắt cổ chai hiệu quả của suy luận
LLM. Sau đó, chúng tôi sẽ giới thiệu các phương pháp xấp xỉ hiện tại được thiết kế để giảm chi
phí tính toán và bộ nhớ và cải thiện độ trễ suy luận LLM. Cuối cùng, chúng tôi sẽ cung cấp một
đánh giá về tiến bộ gần đây đã được thực hiện trong việc phát triển prompt cho các LLM.

2.1 Nút Thắt Cổ Chai Hiệu Quả của Suy Luận LLM

Các LLM áp dụng phương pháp chỉ decoder, tự hồi quy trong đó việc sinh token được thực hiện
từng bước, với việc sinh ra mỗi token phụ thuộc vào các kết quả được sinh trước đó. Ví dụ, các
mô hình như GPT [27, 28, 2] tuân theo mô hình này. Một nghiên cứu gần đây của [20] điều tra
quá trình suy luận của các mô hình OPT-175B và phát hiện rằng (1) việc sinh token là yếu tố
chiếm ưu thế góp phần vào độ trễ suy luận, và (2) Multilayer Perceptron (MLP) phát sinh chi
phí I/O và độ trễ tính toán cao hơn so với các khối attention trong quá trình sinh token. Mặc dù
các tối ưu hóa cấp hệ thống [30, 9, 10] có thể nâng cao thời gian suy luận của các LLM, chúng
không trực tiếp giảm thiểu tính toán và I/O bộ nhớ liên quan đến quá trình suy luận LLM.

2.2 Xấp Xỉ trong Suy Luận LLM

Ngoài việc tối ưu hóa ở cấp hệ thống, có hai phương pháp chính để giảm cả tính toán và I/O bộ
nhớ để giảm thiểu độ trễ trong suy luận. (1) Mô hình hóa thưa thớt: ý tưởng chung là chọn một
tập hợp cụ thể các trọng số trong các lớp nhất định để giảm thiểu cả tính toán và I/O bộ nhớ [6,
20]. Các kỹ thuật này cũng có liên quan chặt chẽ đến cắt tỉa [12, 15, 17, 14] trong tài liệu. Với
số lượng tham số khổng lồ trong các LLM, việc thưa thớt hóa thường được thực hiện từng lớp
một. Tuy nhiên, LLM thưa thớt kết quả có thể thể hiện sự sai lệch đáng kể trong dự đoán cuối
cùng tại thời điểm suy luận, dẫn đến sự suy giảm độ chính xác không thể tránh khỏi khi so sánh
với LLM gốc. (2) Lượng tử hóa: nó đề cập đến quá trình nén các giá trị trọng số đã huấn luyện
trong
3

--- TRANG 4 ---
các LLM thành các bit thấp hơn [26, 4, 36, 7]. Các đánh giá thực nghiệm đã cho thấy rằng lượng
tử hóa int8 có thể cung cấp một xấp xỉ tuyệt vời về hiệu suất dự đoán của các LLM gốc [4]. Tuy
nhiên, có sự suy giảm đáng kể về độ chính xác khi cố gắng giảm số bit hơn nữa.

2.3 Prompt cho LLM

Các LLM được biết đến với khả năng học trong ngữ cảnh, cho phép chúng tổng quát hóa cho các
tác vụ chưa thấy mà không cần tinh chỉnh thêm [2]. Cụ thể, các LLM được điều khiển thông qua
các đặc tả ngôn ngữ tự nhiên của tác vụ do người dùng cung cấp, hoặc prompt, minh họa cách
hoàn thành một tác vụ. Trong mô hình này, chúng ta không ép buộc các sửa đổi trên chính các
LLM. Thay vào đó, chúng ta tập trung vào việc thích ứng các đầu vào cho các LLM để có hiệu
suất dự đoán tốt hơn trong các tác vụ downstream. Một chiến lược điển hình là chèn các token
trước chuỗi đầu vào để ảnh hưởng đến cơ chế attention. Đã được chỉ ra trong [2] rằng kỹ thuật
prompt engineering cho phép các LLM đạt được hiệu suất của các mô hình ngôn ngữ được tinh
chỉnh trên nhiều tác vụ hiểu ngôn ngữ. Hơn nữa, [18] chỉ ra thực nghiệm rằng có sự tương đương
giữa việc sửa đổi đầu vào và tinh chỉnh mô hình. Ngoài ra, [31] nghiên cứu khả năng chuyển giao
của prompt qua các tập dữ liệu tương tự hoặc thậm chí các tác vụ. Kể từ đó, chúng ta đã chứng
kiến sự phát triển của cơ sở hạ tầng tinh chỉnh prompt [5]. Tuy nhiên, chúng tôi muốn nhấn
mạnh rằng hầu hết các minh chứng hiện tại về tinh chỉnh prompt đều dành riêng cho tác vụ [19,
18]. Khi xem xét hiệu quả, mong muốn là một prompt thể hiện khả năng chuyển giao qua các
cài đặt khác nhau.

3 Động Lực

Các phương pháp nén giảm độ phức tạp tính toán với chi phí là đưa ra các đầu ra ít chính xác
hơn. Do đó, tự nhiên tồn tại một sự đánh đổi giữa độ chính xác và hiệu quả. Trong phần này,
chúng tôi đầu tiên đánh giá thực nghiệm sự đánh đổi của các LLM được nén. Sau đó, chúng tôi
phát hiện rằng đối với một mô hình được nén, chúng ta có thể thiết kế thủ công một hard prompt
thông báo cho mô hình về trạng thái nén của nó và giúp nó sửa chữa các dự đoán tương ứng.

3.1 Hiệu Suất của Các Phương Pháp Hiện Có

[Biểu đồ hiển thị kết quả thực nghiệm]

Thiết Lập Thực Nghiệm. Chúng tôi đánh giá sự đánh
đổi bằng cách sử dụng LLaMA [33] trên tập dữ liệu
C4 [29]. Ở đây chúng tôi áp dụng hai phương pháp
nén sau huấn luyện đại diện, tức là GPTQ [7] và
SparseGPT [6], để phân tích sự đánh đổi qua các
mức độ nén khác nhau. Chúng tôi lưu ý rằng chúng
tôi chọn các phương pháp nén sau huấn luyện chủ
yếu vì tính dễ triển khai của chúng. Đối với phương
pháp lượng tử hóa, chúng tôi áp dụng GPTQ để nén
các trọng số mô hình thành các số nguyên 2, 3 và 4
bit. Còn đối với phương pháp cắt tỉa, chúng tôi sử
dụng SparseGPT để loại bỏ 50%, 62.5% và 75% tham số mô hình. Chúng tôi muốn lưu ý rằng
việc nén sau huấn luyện được thực hiện bằng cách sử dụng tập huấn luyện của C4, và sau đó,
chúng tôi đánh giá hiệu suất của việc nén với tập validation của C4.

Kết Quả Định Lượng. Như được hiển thị trong Hình 2, chúng tôi trực quan hóa perplexity đánh
giá (PPL) [16] so với mức độ nén. Khi chúng ta cắt tỉa 50% tham số hoặc lượng tử hóa các tham
số xuống 4 bit, PPL vẫn gần với PPL của mô hình LLaMA đầy đủ. PPL liên tục tăng khi chúng
ta giảm tài nguyên được phân bổ (ví dụ: bit-width/sparsity). Đáng chú ý, PPL sẽ bùng nổ khi
tài nguyên dưới một ngưỡng nhất định. Ví dụ, PPL chuyển từ 14 lên 53 khi sparsity tăng từ
62.5% lên 75%. Hơn nữa, PPL tăng đáng kể từ khoảng 11 lên khoảng 691 khi chúng ta hạ mức
lượng tử hóa từ 3-bit xuống 2-bit.

Kết Quả Định Tính. Như được hiển thị ở phần bên trái của Hình 1, ngoài PPL, chúng tôi cũng
thực hiện một nghiên cứu tình huống để hiểu cách nén ảnh hưởng đến kết quả sinh ra của mô
hình. Trong ví dụ này, mô hình đầy đủ có thể cung cấp các câu trả lời chính xác và phù hợp cho
cả ba câu hỏi đơn giản. Cụ thể, nó xác định chính xác Long Beach là một thành phố ở Quận Los
Angeles, California, chỉ rõ Tulsa ở đông bắc Oklahoma, và mô tả măng tây là một loại rau mùa
xuân thuộc họ hoa loa kèn. Tuy nhiên, mô hình được cắt tỉa với 62.5% sparsity trọng số gặp khó
khăn trong việc tạo ra các phản hồi có ý nghĩa. Thay vì cung cấp thông tin được yêu cầu, các
câu trả lời của nó có vẻ không liên quan và tiếp tuyến. Ví dụ, mô hình được cắt tỉa phản hồi
bằng một tuyên bố về việc tìm kiếm việc làm khi được hỏi về Long Beach, đề cập đến việc là
sinh viên tại Đại học Tulsa khi được hỏi về vị trí của Tulsa, và thừa nhận không chắc chắn về
Măng tây. Nghiên cứu tình huống này chứng minh rằng việc nén mô hình mạnh mẽ, chẳng hạn
như 62.5% sparsity trọng số được áp dụng cho mô hình được cắt tỉa, có thể dẫn đến sự suy
thoái đáng kể trong chất lượng của các phản hồi được tạo ra.

3.2 Prompt Các Mô Hình Được Nén

Học trong ngữ cảnh đề cập đến khả năng thích ứng với ngữ cảnh được cung cấp trong dữ liệu
đầu vào thông qua các đặc tả ngôn ngữ tự nhiên do người dùng cung cấp [37, 25], thường được
gọi là prompt. Prompt phục vụ để hướng dẫn các LLM tạo ra các dự đoán mong muốn bằng cách
cung cấp thông tin ngữ cảnh hữu ích. Như được hiển thị trong Hình 1, mô hình được nén tạo ra
các câu trả lời không liên quan và ngoài chủ đề khi phản hồi những câu hỏi đơn giản này. Do đó,
một câu hỏi tự nhiên là, đối với một mô hình được nén, chúng ta có thể thiết kế một prompt cụ
thể giúp nó sửa chữa các dự đoán tương ứng không?

Theo câu hỏi, chúng tôi thiết kế thủ công hard prompt là " Hãy kiểm tra cẩn thận ma trận trọng
số trong mô hình, vì nó có thể chứa lỗi. Điều quan trọng là phải xác minh độ chính xác của nó và
thực hiện bất kỳ điều chỉnh cần thiết nào để đảm bảo hiệu suất tối ưu ". Kết quả được hiển thị
ở cột thứ tư của Hình 1. Các quan sát được tóm tắt như sau:

Mô hình được cắt tỉa có prompt, tức là "LLaMA-7B (62.5% sparsity) w./ Hard Prompt"
trong Hình 1, cho thấy sự cải thiện đáng kể trong các phản hồi của nó, mặc dù không
phải tất cả chúng đều chính xác hoặc hoàn chỉnh. Cụ thể, (1) khi được thông báo rõ ràng
về trạng thái nén của nó, mô hình được cắt tỉa có prompt xác định chính xác rằng Long Beach
nằm ở Hoa Kỳ. Tuy nhiên, nó không cung cấp thêm thông tin về thành phố, chẳng hạn như sự
hiện diện của nó ở Quận Los Angeles, California. (2) Liên quan đến câu hỏi thứ hai về Tulsa,
Oklahoma, mô hình được cắt tỉa có prompt không cung cấp câu trả lời phù hợp, thay vào đó lặp
lại prompt của chúng tôi về trạng thái nén, điều này không liên quan đến câu hỏi. (3) Khi được
hỏi về măng tây, mô hình được cắt tỉa có prompt xác định chính xác nó là một loại cây được sử
dụng để nấu ăn.

Hiểu Biết Sâu Sắc. Bằng cách thông báo rõ ràng cho mô hình về trạng thái nén của nó, các LLM
có thể tạo ra các phản hồi phù hợp hơn cho một số câu hỏi nhất định. Thành công của prompt
được thiết kế ngụ ý ba tiềm năng lớn:

1. Khả Năng Chuyển Giao Qua Tập Dữ Liệu. Prompt được thiết kế bởi con người này chỉ cung
cấp thông tin rằng trọng số mô hình không chính xác. Vì vậy, theo trực giác, bất kể tập dữ liệu
cụ thể nào được sử dụng, chúng tôi đưa ra giả thuyết rằng các LLM có thể tạo ra các phản hồi
phù hợp hơn với cùng một prompt.

2. Khả Năng Chuyển Giao Qua Nén. Tương tự, prompt được thiết kế bởi con người chỉ đề cập
rằng trọng số không chính xác, mà không chỉ định mức độ nén hoặc phương pháp chính xác.
Chúng tôi đưa ra giả thuyết rằng các LLM có thể tạo ra các phản hồi phù hợp hơn với cùng một
prompt qua các mức độ nén và phương pháp khác nhau.
5

--- TRANG 6 ---
3. Khả Năng Chuyển Giao Qua Tác Vụ. Nếu các LLM có thể hiểu trạng thái nén của chúng và
điều chỉnh tương ứng, khả năng thích ứng này không giới hạn ở các tác vụ hoặc miền vấn đề
cụ thể. Thay vào đó, nó có thể được mở rộng cho một phạm vi rộng các tác vụ.

Tuy nhiên, mặc dù có tiềm năng, như chúng tôi đã phân tích ở đầu phần này, prompt được thiết
kế thủ công không có hiệu quả nhất quán. Nói cách khác, nó chỉ hoạt động cho một số vấn đề,
và không phải tất cả các câu trả lời được tạo ra đều chính xác hoặc hoàn chỉnh. Lấy cảm hứng từ
các nghiên cứu prompt có thể học trước đây [19, 18], chúng tôi đưa ra giả thuyết rằng bằng cách
liên quan trọng số nén vào quá trình học prompt, một prompt có thể học có khả năng vượt qua
hiệu suất của hard prompt đồng thời vẫn giữ lại các khía cạnh khả năng chuyển giao của hard
prompt.

4 Học Prompt cho Suy Luận LLM Hiệu Quả

Trong phần này, chúng tôi sẽ bắt đầu bằng việc giới thiệu việc công thức hóa mô hình học prompt.
Sau đó, chúng tôi sẽ chuyển trọng tâm của mình sang mục tiêu likelihood tối đa của việc học
prompt. Cuối cùng, chúng tôi sẽ đi sâu vào khả năng chuyển giao của các prompt đã học.

4.1 Công Thức Hóa

Phần 3.2 đã cho thấy rằng việc kết hợp prompt có thể nâng cao hiệu suất dự đoán của các LLM
được nén. Tuy nhiên, việc khám phá các prompt dựa trên ngôn ngữ hiệu quả thông qua thử và
sai là một quá trình cồng kềnh và không hiệu quả đòi hỏi khám phá một không gian từ vựng rộng
lớn. Do đó, bài báo này nhằm phát triển một phương pháp dựa trên dữ liệu để học một soft
prompt.

Thông thường một LLM sẽ có một tokenizer ánh xạ mỗi câu đầu vào thành một chuỗi các số
nguyên [x0, x1,···, xn]. Sau đó, mỗi token xi∈[v] đại diện cho một vector hàng d-chiều trong
ma trận embedding W∈Rv×d. Trong giai đoạn suy luận của LLM, chúng ta được cung cấp một
chuỗi đầu vào [x0, x1,···, xm] với m token. Chúng ta muốn tạo ra các token sau xm từng bước
một bằng cách sử dụng một LLM. Chúng ta ký hiệu prompt là một chuỗi các số nguyên [e1, e2,···,
ek] với độ dài k. Mỗi token ej∈[k] đại diện cho một vector hàng d-chiều trong ma trận embedding
prompt E∈Rk×d.

4.2 Mục Tiêu Học

Trong nghiên cứu này, chúng tôi trình bày một chiến lược học prompt có thể được sử dụng như
một quá trình sau huấn luyện cho các LLM được nén. Với một mô hình LLM có tham số được
ký hiệu là θ, chúng ta bắt đầu với phương pháp thưa thớt hóa [6, 20] hoặc lượng tử hóa [7] để
nén các tham số mô hình. Chúng ta ký hiệu các tham số sau khi nén là θ̃. Chúng tôi lưu ý rằng
việc học prompt phụ thuộc vào dữ liệu, và do đó, chúng ta cần sử dụng một tập dữ liệu văn bản
X cho quy trình này. Tiếp theo, cho mỗi chuỗi [x0, x1,···, xn]∈X, chúng ta chèn k token prompt
[e1, e2,···, ek] trước nó. Tiếp theo, chúng ta tối ưu hóa mục tiêu sau.

min
E L θ̃ = min
E Σ_{n}_{t=1} −log Pr θ̃[xt|e1,···, ek, x0,···xt−1]. (1)

Chúng tôi lưu ý rằng tham số mô hình θ̃ được cố định và không được cập nhật. Và các tham số
có thể huấn luyện là embedding của các token prompt [e1, e2,···, ek], được ký hiệu bởi ma trận
E∈Rk×d. Theo [18], chúng tôi khởi tạo E sao cho mỗi hàng trong E tương ứng với một vector
được chọn ngẫu nhiên từ ma trận embedding token W của LLM. Chuỗi token prompt vẫn giữ
nguyên cho tất cả các chuỗi trong X. Điều này có nghĩa là chúng ta sử dụng biểu diễn của các
token prompt để ảnh hưởng đến cơ chế attention của LLM giữa các token trong chuỗi [x0, x1,···,
xn]. Cụ thể,
6

--- TRANG 7 ---
Phương trình (1) nhằm tối đa hóa likelihood dự đoán chính xác token tiếp theo trong chuỗi, với
các token đi trước. Bằng cách này, prompt đã học nhận thức được các trọng số nén, khi gradient
chảy qua các trọng số nén này trong quá trình tối ưu hóa. Điều này cho phép mô hình thích ứng
hành vi của nó để tính đến các hiệu ứng nén trong khi tạo ra các phản hồi, có khả năng dẫn đến
hiệu suất được cải thiện.

4.3 Khả Năng Chuyển Giao của Prompt Đã Học

Các phát hiện rút ra từ Phần 3.2 đã cung cấp cho chúng tôi động lực hấp dẫn để đi sâu vào việc
khám phá khả năng chuyển giao của các token prompt thu được thông qua Phương trình (1). Biểu
diễn của các token prompt này, cũng như việc thu thập chúng thông qua một tập dữ liệu, có thể
có tác động đáng kể đến các ứng dụng NLP khác. Cụ thể, chúng tôi đã chọn tập trung vào các
tình huống dưới đây.

Khả Năng Chuyển Giao Qua Tập Dữ Liệu. Chúng tôi nhằm điều tra liệu các token prompt được
huấn luyện từ một tập dữ liệu có thể áp dụng cho các tập dữ liệu khác không. Học prompt, mặc
dù hiệu quả hơn so với tinh chỉnh, cần đến sức mạnh tính toán và bộ nhớ đáng kể. Với một Nvidia-
A100 đơn lẻ sở hữu 40GB bộ nhớ, chỉ có thể hỗ trợ việc học prompt của mô hình LLaMA-7B
sử dụng batch size bằng 1, độ dài chuỗi 1024 và 100 token prompt. Nếu chúng ta thực hiện một
vòng học prompt duy nhất cho một LLM được nén và đạt được kết quả thuận lợi qua các tập dữ
liệu khác nhau, chúng ta có thể nâng cao đáng kể sự đánh đổi độ chính xác-hiệu quả của LLM
trong quá trình suy luận.

Khả Năng Chuyển Giao Qua Nén. Chúng tôi nhằm điều tra tính khả thi của việc sử dụng các
prompt đã học được huấn luyện từ một LLM được nén cho một LLM được nén khác với các mức
độ nén khác nhau. Ví dụ, chúng tôi đánh giá liệu một prompt được huấn luyện trên một LLM
thưa thớt với 75% sparsity có thể nâng cao hiệu quả hiệu suất của một LLM với 50% sparsity
trọng số không. Ngoài ra, chúng tôi cũng kiểm tra khả năng áp dụng của các prompt được huấn
luyện trên một LLM thưa thớt khi được sử dụng với một LLM được lượng tử hóa.

Khả Năng Chuyển Giao Qua Tác Vụ. Chúng tôi nhằm điều tra liệu prompt đã học được huấn
luyện từ Phương trình (1) trên các tác vụ sinh token có thể được áp dụng cho các tác vụ NLP
khác không. Việc khám phá này sẽ chứng minh tính hiệu quả của prompt trong việc cải thiện sự
đánh đổi độ chính xác-hiệu quả trong tổng quát hóa zero-shot của các LLM trong các tác vụ
downstream như trả lời câu hỏi.

5 Thí Nghiệm

Trong phần này, chúng tôi đánh giá tính hiệu quả của chiến lược prompt của chúng tôi trong việc
nâng cao sự đánh đổi giữa độ chính xác và hiệu quả trong quá trình suy luận LLM. Chúng tôi bắt
đầu bằng việc nêu rõ thiết lập thực nghiệm, sau đó trình bày kết quả của việc sinh token. Hơn
nữa, chúng tôi điều tra khả năng chuyển giao của prompt qua các tập dữ liệu và mức độ nén khác
nhau. Đối với các thí nghiệm bổ sung liên quan đến khả năng chuyển giao và hiệu quả, vui lòng
tham khảo Phụ lục A, nơi chúng tôi đã bao gồm thêm chi tiết.

5.1 Thiết Lập Thí Nghiệm

Trong khung thực nghiệm của chúng tôi, chúng tôi kết hợp việc sử dụng GPU Nvidia V100 để
thực hiện suy luận và học prompt trong các LLM. Các tập dữ liệu mà chúng tôi sử dụng để sinh
token rất toàn diện, bao gồm Common Crawl's web corpus (C4) [29], Wikitext-2 [23], và cơ sở
dữ liệu Penn Treebank (PTB) [22]. Chúng tôi đặt độ dài chuỗi cho các tập dữ liệu này là 1024.
Đối với tác vụ sinh token, chúng tôi sử dụng perplexity (PPL) [16] làm thước đo đánh giá. Chúng
tôi cũng giới thiệu một số tác vụ downstream để đánh giá khả năng chuyển giao qua tác vụ của
prompt đã học. Chúng tôi sẽ giới thiệu thông tin tác vụ trong phần cụ thể. Ở cốt lõi của phương
pháp mô hình hóa của chúng tôi, chúng tôi áp dụng Open Pre-trained Transformer (OPT) Language
Models [40] và Large Language Model Architecture (LLaMA) [33]. Để nén các mô hình OPT và
LLaMA, chúng tôi sử dụng các kỹ thuật từ cả phương pháp SparseGPT [6] và GPTQ [7]. Chúng
tôi giới thiệu độc giả đến Phụ lục A.1 để biết thêm chi tiết thực nghiệm.

5.2 Kết Quả Sinh Token

Trên tập huấn luyện C4, chúng tôi nén OPT-1.3B, OPT-2.7B, OPT-6.7B và LLaMA-7B bằng
SparseGPT [6]. Chúng tôi sử dụng mức độ sparsity 50%, 62.5% và 75% để nén. Ngoài ra, chúng
tôi sử dụng GPTQ [7] cho lượng tử hóa 2-bit, 3-bit và 4-bit. Hơn nữa, việc học prompt được áp
dụng cho mỗi mô hình được nén bằng phương pháp được giới thiệu trong Phương trình (1). Chúng
tôi đặt k trong Phương trình 1 bằng 100, tức là kết hợp 100 token prompt có thể học. Trong Bảng
1, chúng tôi cũng thực hiện nghiên cứu ablation về tác động của số lượng soft token sử dụng
LLaMA-7B được lượng tử hóa 3-bit trên tập dữ liệu PTB. Chúng tôi quan sát thấy vẫn có sự cải
thiện đáng kể với 25 token prompt, và chúng ta có thể cải thiện hiệu suất bằng cách tăng kích
thước prompt.

[Bảng 1 hiển thị kết quả nghiên cứu ablation]

Hình 3 chứng minh tác động của phương pháp của chúng tôi trên tập validation của C4. Chúng
tôi quan sát sự cải thiện đáng kể về PPL qua tất cả các mức độ nén. Đầu tiên, bằng cách sử dụng
các soft prompt token, các LLM được nén sử dụng SparseGPT với 50% sparsity thậm chí vượt
trội so với các đối tác mô hình đầy đủ, thể hiện PPL thấp hơn. Xu hướng này cũng được quan sát
thấy trong lượng tử hóa 4-bit của các LLM sử dụng GPTQ. Thứ hai, ngay cả với việc nén nâng
cao hơn nữa, các LLM được nén với các soft prompt token đã học từ Phương trình (1) vẫn duy
trì PPL có thể so sánh với các đối tác gốc của chúng. Đáng chú ý, các prompt được học từ mỗi
mô hình được lượng tử hóa 3-bit trong bốn mô hình giúp vượt qua hiệu suất của các đối tác mô
hình đầy đủ tương ứng. Chúng tôi cũng quan sát hiệu ứng tương tự trong các mô hình thưa thớt
với 62.5% sparsity cho OPT-1.3B và OPT-2.7B. Ngược lại, các prompt được học từ cả OPT-6.7B
và LLaMA-7B hỗ trợ đạt được PPL giống như các đối tác mô hình đầy đủ của chúng. Cuối cùng,
phương pháp của chúng tôi nâng cao đáng kể hiệu suất dự đoán của nén quy mô cực đoan. Trong
cả SparseGPT với 75% sparsity và GPTQ với lượng tử hóa 2-bit, chúng tôi phát hiện rằng chiến
lược học prompt cải thiện đáng kể PPL qua tất cả bốn mô hình. Ví dụ, các prompt được học qua
nén GPTQ 2-bit của OPT-1.3B giảm PPL từ 2337.8 xuống 59.

5.3 Khả Năng Chuyển Giao Qua Tập Dữ Liệu

Theo trực giác, một mô hình được nén bằng một tập dữ liệu nên đạt được hiệu suất dự đoán khá
tốt khi được chuyển sang các tập dữ liệu khác [7, 6]. Ở đây chúng tôi đánh giá liệu các token
prompt được học từ một tập dữ liệu có thể chuyển giao tương tự qua các tập dữ liệu khác nhau
không. Cụ thể, chúng tôi đầu tiên nén một mô hình với SparseGPT hoặc GPTQ sử dụng tập huấn
luyện C4. Sau đó chúng tôi học prompt với mô hình được nén trên tập huấn luyện C4. Cuối cùng,
chúng tôi đánh giá hiệu suất của mô hình được nén này có và không có các prompt đã học trên
các tập dữ liệu khác, ví dụ: tập dữ liệu Wikitext-2 và PTB. Chúng tôi nhấn mạnh toàn bộ quá
trình không liên quan đến bất kỳ dữ liệu cụ thể cho tác vụ nào, và kết quả của chúng tôi
do đó vẫn là "zero-shot".

Hình 4 trình bày hiệu suất của OPT-1.3B, OPT-2.7B, OPT-6.7B và LLaMA-7B trên tập kiểm
tra của Wikitext-2 và tập dữ liệu PTB. Đối với mỗi mô hình LLM, chúng tôi cũng bao gồm hiệu
suất
8

--- TRANG 9 ---
[Hình 3: Biểu đồ hiển thị kết quả trên các mô hình OPT và LLaMA với các mức độ nén khác nhau]

của các phiên bản được nén của nó với 50%, 62.5% và 75% sparsity sử dụng SparseGPT. Ngoài
ra, chúng tôi bao gồm hiệu suất của phiên bản được nén của mỗi mô hình với lượng tử hóa 2-bit,
3-bit và 4-bit sử dụng GPTQ. Các hình minh họa những lợi thế nhất quán của các token prompt
qua hai tập dữ liệu. Đối với mọi mô hình với 50% sparsity hoặc lượng tử hóa 4-bit, việc học prompt
từ tập dữ liệu C4 dẫn đến PPL thấp hơn so với đối tác mô hình đầy đủ. Hơn nữa, chúng tôi quan
sát sự cải thiện đáng kể về PPL khi sử dụng các token prompt đã học khi mô hình trở nên được
nén nhiều hơn. Hiện tượng này xác nhận rằng các prompt được học trên các mô hình được nén
có thể được chuyển giao hiệu quả qua các tập dữ liệu.

Do giới hạn trang, chúng tôi cũng thực hiện các thí nghiệm ablation về khả năng chuyển
giao trong Phụ lục A.2. Cụ thể, chúng tôi so sánh các soft prompt được chuyển giao với các
soft prompt được huấn luyện trên tập dữ liệu downstream, đóng vai trò là đối tác top-line. Chúng
tôi cũng quan sát thấy với soft prompt đã học, khoảng cách giữa mô hình đầy đủ và mô hình được
lượng tử hóa được giảm đáng kể.

5.4 Khả Năng Chuyển Giao Qua Nén

Trong phần này, chúng tôi đánh giá khả năng chuyển giao của các prompt đã học qua các mức
độ nén khác nhau. Cụ thể, chúng tôi nhằm giải quyết các câu hỏi sau: (1) Prompt được học từ
một LLM được nén thông qua thưa thớt hóa ở một mức độ sparsity cụ thể có thể được áp dụng
cho các LLM thưa thớt khác với các sparsity khác nhau không? (2) Prompt được học từ một LLM
được lượng tử hóa đến một mức bit cụ thể có thể được áp dụng cho các LLM được lượng tử hóa
khác với các bit khác nhau không? (3) Có thể chuyển giao các prompt được học từ các LLM thưa
thớt sang các LLM được lượng tử hóa, hoặc ngược lại, để nâng cao độ chính xác dự đoán không?

Trong Hình 5, chúng tôi đánh giá hiệu suất của việc sử dụng các prompt có nguồn gốc từ một
LLM được nén trên các LLM được nén khác, sử dụng các phương pháp và mức độ nén khác nhau.
Ví dụ, chúng tôi sử dụng LLaMA-7B và trình bày kết quả PPL trên tập validation của C4, cũng
như các tập kiểm tra của Wikitext-2 và PTB. Trong ngữ cảnh này, "target" đề cập đến loại và
mức độ nén cho mô hình được nén, trong khi "source" đại diện cho loại và mức độ của mô hình
được nén mà từ đó prompt được học. Ví dụ, "source 4-bit" chỉ ra rằng prompt được học từ một
mô hình được nén với lượng tử hóa 4-bit. Dựa trên các hình, chúng tôi giải quyết các câu hỏi đã
đặt ra từ ba góc độ: (1) Liên quan đến các LLM thưa thớt, các prompt được học từ sparsity cao
hơn có thể được chuyển giao hiệu quả sang các mô hình với sparsity thấp hơn. Ví dụ, các prompt
được học từ 62.5% và
9

--- TRANG 10 ---
[Hình 4: Biểu đồ hiển thị kết quả trên Wikitext-2 và PTB với các mô hình OPT và LLaMA]

10

--- TRANG 11 ---
[Hình 5: Ma trận hiển thị khả năng chuyển giao của LLaMA-7B giữa các mức độ sparsity và bit-width khác nhau]

75% sparsity có thể được áp dụng cho một mô hình LLaMA-7B thưa thớt với 50% sparsity, dẫn
đến PPL tốt hơn so với mô hình LLaMA-7B gốc. (2) Đối với các LLM được lượng tử hóa, các
prompt được học từ các mức độ lượng tử hóa bit thấp hơn có thể được áp dụng thành công cho
các mô hình với lượng tử hóa bit cao hơn, đồng thời đạt được hiệu suất có thể so sánh. (3) Có
một mức độ nhất định về khả năng chuyển giao của các prompt được học giữa các loại nén khác
nhau, đặc biệt khi mức độ nén ít hơn. Ví dụ, một prompt được học từ một mô hình LLaMA-7B
với lượng tử hóa 4-bit có thể được chuyển giao sang một mô hình LLaMA-7B với 50% sparsity.

5.5 Kết Hợp Thưa Thớt Hóa và Lượng Tử Hóa

[Bảng 2: Kết quả PPL của việc kết hợp 50% sparsity + lượng tử hóa 4-bit với các prompt đã học]

Trong phần này, chúng tôi khám phá tính hiệu quả của chiến lược prompt trong việc kết hợp thưa
thớt hóa và lượng tử hóa để nén LLM. Vì thưa thớt hóa và lượng tử hóa nhắm đến các khía cạnh
khác nhau của nén, việc kết hợp chúng để đạt được hiệu quả tốt hơn là điều tự nhiên. Bảng 2
trình bày PPL trước và sau, có và không có prompt đã học trên tập validation của C4, cũng như
các tập kiểm tra của Wikitext-2 và PTB. Chúng tôi chọn mô hình LLaMA-7B được nén sử dụng
50% sparsity và lượng tử hóa 4-bit từ tập huấn luyện của C4. Chúng tôi nên lưu ý rằng quá trình
học prompt cũng diễn ra trên tập huấn luyện của C4. Kết quả của chúng tôi chứng minh rằng
chiến lược học prompt vẫn hiệu quả khi kết hợp thưa thớt hóa và lượng tử hóa. Ngoài ra, với
prompt, mô hình được nén 50% sparse và 4-bit vẫn hoạt động tương đương với LLaMA-7B gốc.

6 Kết Luận

Nghiên cứu này giới thiệu một phương pháp sáng tạo để tối ưu hóa sự đánh đổi giữa hiệu quả
tính toán và độ chính xác trong các Mô Hình Ngôn Ngữ Lớn (LLM). Nghiên cứu chứng minh
rằng việc sử dụng một định dạng đầu vào riêng biệt và các prompt được chọn chiến lược có thể
cải thiện đáng kể hiệu suất của các LLM được nén. Việc giới thiệu một mô hình học prompt, nhấn
mạnh việc thêm các prompt chính xác trên một LLM được nén, đã cho thấy nâng cao độ chính xác
của chúng, thường đạt được và thậm chí vượt qua các mô hình gốc. Nghiên cứu cũng làm nổi bật
khả năng chuyển giao của các prompt đã học này qua các tập dữ liệu, tác vụ và mức độ nén khác
nhau, tiết lộ những hướng đi đầy hứa hẹn cho những tiến bộ xa hơn trong việc mở rộng quy mô
các LLM trên phần cứng thông thường. Kết quả nhấn mạnh tầm quan trọng của việc chỉnh sửa
đầu vào thận trọng cho một mô hình lớn được nén, có khả năng cách mạng hóa cách chúng ta tiếp
cận suy luận LLM trên các nền tảng phần cứng tiêu chuẩn.

Tài Liệu Tham Khảo

[1-40: Danh sách tài liệu tham khảo từ trang 12-15]

Phụ Lục

A Thêm Thí Nghiệm

A.1 Chi Tiết Thí Nghiệm

[Chi tiết về cấu hình thí nghiệm và các thông số sử dụng]

A.2 Ablation về Khả Năng Chuyển Giao

[Bảng 4 và các phân tích chi tiết về khả năng chuyển giao]

A.3 Khả Năng Chuyển Giao Qua Tác Vụ

[Bảng 5 và các kết quả về khả năng chuyển giao qua các tác vụ khác nhau]

A.4 Phân Tích Hiệu Quả

[Hình 6 và phân tích về tác động của prompt token đến độ trễ]

B Thêm Trực Quan Hóa

[Hình 7 và 8: Các nghiên cứu tình huống bổ sung cho hiệu ứng của prompt]

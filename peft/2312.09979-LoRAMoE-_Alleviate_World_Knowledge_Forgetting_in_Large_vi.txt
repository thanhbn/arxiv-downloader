# 2312.09979.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2312.09979.pdf
# Kích thước tệp: 1153794 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
LoRAMoE: Giảm thiểu việc quên kiến thức thế giới trong các mô hình ngôn ngữ lớn thông qua Plugin phong cách MoE

Shihan Dou1*, Enyu Zhou1∗, Yan Liu1, Songyang Gao1, Jun Zhao1, Wei Shen1,
Yuhao Zhou1, Zhiheng Xi1, Xiao Wang1, Xiaoran Fan1, Shiliang Pu2, Jiang Zhu2,
Rui Zheng1, Tao Gui1†, Qi Zhang1†, Xuanjing Huang1
1Nhóm NLP, Đại học Fudan
2Hikvision Inc
shdou21@m.fudan.edu.cn, eyzhou23@m.fudan.edu.cn
{rzheng20, tgui, qz}@fudan.edu.cn

Tóm tắt
Tinh chỉnh có giám sát (SFT) là một bước quan trọng
đối với các mô hình ngôn ngữ lớn (LLM), cho phép
chúng phù hợp với các hướng dẫn của con người và
tăng cường khả năng của chúng trong các nhiệm vụ
hạ nguồn. Việc tăng đáng kể dữ liệu hướng dẫn là một
giải pháp trực tiếp để căn chỉnh mô hình với phạm vi
rộng hơn của các nhiệm vụ hạ nguồn hoặc cải thiện
đáng kể hiệu suất của nó trên một nhiệm vụ cụ thể.
Tuy nhiên, chúng tôi thấy rằng việc tăng quy mô lớn
dữ liệu hướng dẫn có thể làm hại kiến thức thế giới
đã được lưu trữ trước đó trong LLM. Để giải quyết
thách thức này, chúng tôi đề xuất LoRAMoE, một
khung mới giới thiệu một số bộ chuyển đổi thứ hạng
thấp (LoRA) và tích hợp chúng bằng cách sử dụng
một mạng định tuyến, như một phiên bản plugin của
Mixture of Experts (MoE). Nó đóng băng mô hình
backbone và buộc một phần các LoRA tập trung vào
việc tận dụng kiến thức thế giới để giải quyết các
nhiệm vụ hạ nguồn, nhằm giảm thiểu việc quên kiến
thức thế giới. Kết quả thực nghiệm cho thấy rằng,
khi dữ liệu hướng dẫn tăng lên, LoRAMoE có thể
cải thiện đáng kể khả năng xử lý các nhiệm vụ hạ
nguồn, trong khi vẫn duy trì kiến thức thế giới được
lưu trữ trong LLM1.

1 Giới thiệu
Tinh chỉnh có giám sát (SFT) cung cấp một kỹ thuật
quan trọng để làm cho các mô hình ngôn ngữ lớn (LLM)
tuân theo các hướng dẫn của con người và cải thiện
hiệu suất của chúng đối với các nhiệm vụ hạ nguồn
(Chung et al., 2022; Ouyang et al., 2022). Mặc dù
một số nghiên cứu (Zhou et al., 2023; Cao et al., 2023)
chỉ ra rằng các LLM được huấn luyện trên ít dữ liệu
có thể tuân theo hướng dẫn tốt, việc tăng lượng dữ
liệu là một cách đơn giản để nâng cao khả năng của
chúng đối với nhiều nhiệm vụ hạ nguồn hoặc cải thiện
hiệu suất của chúng trên một nhiệm vụ cụ thể, như
được thể hiện ở bên trái của Hình 1.

*Đóng góp ngang nhau.
†Tác giả liên lạc.
1https://github.com/Ablustrund/LoRAMoE

[Hình 1: (Trái) Với số lượng mẫu tinh chỉnh tăng từ 10K lên 3M, hiệu suất của nhiều nhiệm vụ hạ nguồn được cải thiện đáng kể. (Phải) Với lượng dữ liệu hướng dẫn tăng lên, việc tinh chỉnh các mô hình ngôn ngữ dẫn đến sự suy giảm hiệu suất trên các benchmark đo lường kiến thức thế giới của chúng, như TriviaQA (Han et al., 2019), Natural Questions (Kwiatkowski et al., 2019). Chi tiết về việc thực hiện huấn luyện có thể xem ở Phần 2.1.]

Tuy nhiên, việc tăng quy mô lớn dữ liệu hướng dẫn có thể phá hủy kiến thức thế giới được lưu trữ trong LLM, như được minh họa ở bên phải của Hình 1. Cụ thể, khi lượng dữ liệu hướng dẫn tăng lên, chúng tôi quan sát thấy sự suy giảm đáng kể về hiệu suất trên các tập dữ liệu Trả lời câu hỏi sách đóng (CBQA), được sử dụng để đo lường kiến thức thế giới trong LLM (Touvron et al., 2023; Neeman et al., 2022). Trong mô hình tinh chỉnh có giám sát, xung đột giữa việc duy trì kiến thức thế giới bên trong LLM và cải thiện hiệu suất của chúng trên các nhiệm vụ hạ nguồn bằng cách mở rộng dữ liệu hướng dẫn chưa được kiểm tra kỹ lưỡng.

Trong bài báo này, chúng tôi đề xuất LoRAMoE, một khung mới cho SFT, để nâng cao khả năng của các mô hình trong việc giải quyết các nhiệm vụ hạ nguồn, đồng thời giảm thiểu việc quên kiến thức thế giới trong giai đoạn huấn luyện. LoRAMoE là một plugin theo phong cách Mixture-of-Experts (MoE), giới thiệu một số bộ chuyển đổi thứ hạng thấp (LoRA (Hu et al., 2021)) làm các chuyên gia và tích hợp chúng bằng cách sử dụng một mạng định tuyến. Mạng định tuyến tự động gán trọng số cho các chuyên gia, có thể cải thiện hiệu suất của LLM trên nhiều nhiệm vụ hạ nguồn.

--- TRANG 2 ---
[Hình 2: Hiệu suất trên các nhiệm vụ khác nhau sau khi mở rộng lượng dữ liệu tinh chỉnh. Đối với hầu hết các nhiệm vụ hạ nguồn (ví dụ: NLI và tóm tắt), với việc mở rộng dữ liệu huấn luyện, hiệu suất trên những nhiệm vụ này vẫn ổn định sau khi cải thiện. Trong khi đó, đối với benchmark kiến thức thế giới, có thể chứng kiến sự suy giảm đáng kể sau một lượng lớn dữ liệu hướng dẫn.]

Để chứng minh hiệu quả của phương pháp đề xuất, chúng tôi tiến hành các thử nghiệm rộng rãi trên nhiều nhiệm vụ hạ nguồn. Kết quả thực nghiệm cho thấy LoRAMoE có thể cải thiện đáng kể khả năng của LLM trong việc giải quyết các nhiệm vụ hạ nguồn khác nhau bằng cách tinh chỉnh mô hình trên một lượng lớn dữ liệu hướng dẫn, đồng thời duy trì kiến thức thế giới được lưu trữ trong mô hình. Ngoài ra, chúng tôi tiếp tục đánh giá phương pháp của mình bằng cách trực quan hóa trọng số chuyên gia cho các nhiệm vụ. Kết quả chỉ ra rằng LoRAMoE giảm thiểu đầy đủ việc quên kiến thức thế giới và đạt được sự cải thiện của các mô hình bằng cách thúc đẩy sự hợp tác giữa các chuyên gia.

Những đóng góp chính của bài báo chúng tôi như sau:
1. Chúng tôi thấy rằng việc tăng đáng kể lượng dữ liệu hướng dẫn trong giai đoạn SFT có thể làm hại kiến thức thế giới bên trong LLM. Nhu cầu cải thiện trong các nhiệm vụ hạ nguồn bằng cách mở rộng dữ liệu hướng dẫn xung đột với việc duy trì kiến thức thế giới bên trong mô hình.

2. Chúng tôi giới thiệu LoRAMoE, một khung mới cho SFT, giới thiệu các LoRA như các chuyên gia và tích hợp chúng bằng bộ định tuyến. LoRAMoE có thể nâng cao khả năng của mô hình trong việc giải quyết các nhiệm vụ hạ nguồn, đồng thời giảm thiểu việc quên kiến thức thế giới.

3. Các thử nghiệm rộng rãi chứng minh hiệu quả của phương pháp đề xuất trong đa nhiệm vụ và giảm thiểu việc quên kiến thức thế giới bên trong mô hình. Thử nghiệm trực quan hóa cho thấy LoRAMoE có thể đạt được sự cải thiện bằng cách thúc đẩy sự hợp tác giữa các chuyên gia.

2 Động lực
Trong phần này, chúng tôi xác minh rằng một SFT quy mô lớn có thể gây ra thiệt hại không thể đảo ngược cho kiến thức thế giới trong LLM đồng thời cải thiện hiệu suất của LLM trong các nhiệm vụ hạ nguồn khác nhau.

2.1 Một xu hướng phân kỳ
Chúng tôi đã xây dựng một tập dữ liệu chứa bảy loại nhiệm vụ với tổng cộng năm triệu mẫu huấn luyện, và sử dụng nó để tiến hành SFT trên mô hình Llama-2-7B. Chi tiết thực hiện được mô tả trong Phụ lục A. Trong quá trình mở rộng dữ liệu tinh chỉnh, chúng tôi quan sát thấy một xu hướng phân kỳ trong hiệu suất trên hai loại nhiệm vụ, như được thể hiện trong Hình 2:

Trên các nhiệm vụ hạ nguồn như tóm tắt, Suy luận ngôn ngữ tự nhiên (NLI), dịch máy và các nhiệm vụ khác, hiệu suất của mô hình đã tinh chỉnh ban đầu cho thấy sự tăng trưởng tuyệt vời và cuối cùng ổn định ở mức độ hứa hẹn. Tuy nhiên, khi nói đến các nhiệm vụ QA sách đóng (CBQA) được sử dụng làm benchmark kiến thức thế giới (Touvron et al., 2023; Neeman et al., 2022), hiệu suất của mô hình giảm sút thảm khốc dưới baseline. Đáng chú ý, với việc mở rộng dữ liệu huấn luyện, có thể chứng kiến sự suy giảm liên tục. Hơn nữa, sự suy giảm này sẽ xảy ra sớm hơn nếu tập kiểm tra được lọc. Phụ lục B trường hợp với một tập dữ liệu lớn hơn bao gồm nhiều nhiệm vụ hơn cho thấy sự sụt giảm thậm chí còn dốc hơn trên các benchmark kiến thức thế giới, mặc dù hiệu suất vẫn cạnh tranh trên các nhiệm vụ khác.

--- TRANG 3 ---
[Hình 3: Hiệu suất trên các benchmark kiến thức thế giới sau khi huấn luyện chỉ trên CBQA. Hiệu suất tăng mạnh sau khi huấn luyện với rất ít mẫu và tương đối ổn định sau đó.]

2.2 Việc quên kiến thức không thể đảo ngược
Trong phần này, chúng tôi phân tích lý do đằng sau sự suy giảm trên các benchmark kiến thức thế giới này trong quá trình mở rộng dữ liệu tinh chỉnh. Chúng tôi thấy điều này xuất phát từ sự xuất hiện của việc quên kiến thức không thể đảo ngược bên trong LLM.

Hiệu suất trên các benchmark kiến thức thế giới phụ thuộc rất nhiều vào kiến thức và kỹ năng học được trong giai đoạn tiền huấn luyện. Để điều tra mối quan hệ giữa hiệu suất trên các benchmark kiến thức thế giới và kiến thức được nhúng trong các mô hình tiền huấn luyện (Petroni et al., 2019; Roberts et al., 2020; AlKhamissi et al., 2022), chúng tôi tiến hành tinh chỉnh chỉ trên tập dữ liệu CBQA với 250k mẫu và chạy đánh giá trên các tập kiểm tra mà không có sự chồng chéo train-test. Kết quả trong Hình 3 cho thấy việc huấn luyện ban đầu làm tăng hiệu suất đáng kể, đặc biệt là 1% đầu tiên (khoảng 1k mẫu), với mức tăng hạn chế sau đó. Điều này là do việc tinh chỉnh sớm làm căn chỉnh kiến thức hiện có với các hướng dẫn mới, cải thiện kết quả CBQA. Tuy nhiên, do sự chồng chéo dữ liệu huấn luyện-kiểm tra tối thiểu, việc thêm nhiều mẫu hơn không nâng cao hiệu suất thêm nữa. Do đó, thành công benchmark của một mô hình dựa vào kiến thức thế giới thu được từ quá trình tiền huấn luyện.

Với điều này, tự nhiên giả định rằng hiệu suất giảm sút trên benchmark kiến thức xuất phát từ thiệt hại của kiến thức được lưu trữ trong LLM do việc điều chỉnh hướng dẫn quy mô lớn. Để xác minh giả thuyết, chúng tôi tiến hành tinh chỉnh tuần tự một mô hình sử dụng hai tập dữ liệu, đầu tiên loại trừ dữ liệu CBQA, sau đó với dữ liệu CBQA. Kết quả được trình bày trong Bảng 1 cho thấy sự suy giảm lớn trong khả năng kiến thức so với LLM gốc. Điều này chỉ ra rằng kiến thức thế giới trong mô hình đã bị tổn hại trong giai đoạn đầu của việc tinh chỉnh quy mô lớn, dẫn đến việc mô hình không thể tạo ra sự căn chỉnh giữa hướng dẫn của con người và kiến thức đã bị phá hủy trong giai đoạn tiếp theo của việc tinh chỉnh chỉ với CBQA.

[Bảng 1: Hiệu suất từ trái sang phải: LlaMA-2-7B, mô hình được điều chỉnh trên CBQA, và mô hình được điều chỉnh trên 3M hướng dẫn sau đó trên CBQA. Mặc dù điều chỉnh thêm trên CBQA, khả năng trả lời kiến thức của mô hình SFT quy mô lớn không cải thiện, vẫn dưới baseline.]

Tóm lại, việc theo đuổi nâng cao hiệu suất trên các nhiệm vụ hạ nguồn thông qua việc mở rộng dữ liệu huấn luyện xung đột với việc bảo tồn kiến thức thế giới trong mô hình trong SFT vanilla.

3 LoRAMoE
Trong phần này, chúng tôi trình bày chi tiết phương pháp của LoRAMoE, đó là một plugin phong cách MoE và giới thiệu Ràng buộc cân bằng địa phương trong giai đoạn huấn luyện để giảm thiểu kiến thức thế giới, như được thể hiện trong Hình 4.

3.1 Kiến trúc
Bên trái của Hình 4 minh họa quá trình chuyển tiếp của kiến trúc MoE tiêu chuẩn (Shazeer et al., 2016; Fedus et al., 2021; Lepikhin et al., 2020). Trong MoE, bộ định tuyến gán trọng số của các chuyên gia theo dữ liệu, cho phép chúng phân chia lao động để hoàn thành quá trình chuyển tiếp (Jacobs et al., 1991). Ý tưởng chính của LoRAMoE là chúng tôi đóng băng mô hình backbone để duy trì kiến thức thế giới và giới thiệu các chuyên gia để tận dụng kiến thức này nhằm giải quyết các nhiệm vụ, đồng thời cải thiện hiệu suất trên nhiều nhiệm vụ hạ nguồn. Ngoài ra, chúng tôi sử dụng LoRA (Hu et al., 2021) làm kiến trúc của chuyên gia để cải thiện hiệu quả huấn luyện và suy luận.

[Hình 4: Kiến trúc của LoRAMoE, so sánh với MoE cổ điển. LoRAMoE sử dụng nhiều LoRA làm các chuyên gia thích ứng và một bộ định tuyến để kiểm soát chúng trong lớp FFN của mỗi khối transformer. Trong quá trình huấn luyện, chỉ các chuyên gia và bộ định tuyến được tối ưu hóa.]

Chính thức, đối với kiến trúc transformers truyền thống, quá trình lan truyền thuận của khối mạng nơ-ron feed-forward (FFN) có thể được đơn giản hóa như sau:
f(x) = x + f_FNN(x). (1)

Hoạt động ma trận của lớp tuyến tính trong quá trình lan truyền thuận này có thể được biểu diễn là:
o = Wx = W₀x + ΔWx (2)

trong đó W₀ ∈ R^(d_in×d_out) biểu diễn ma trận tham số của mô hình backbone và ΔW ∈ R^(d_in×d_out) biểu thị tham số được cập nhật trong giai đoạn huấn luyện. Đối với LoRAMoE, chúng tôi thay thế lớp tuyến tính trong khối FFN bằng plugin phong cách MoE, làm cho các chuyên gia hợp tác để giải quyết các nhiệm vụ. Trong giai đoạn huấn luyện, chúng tôi đóng băng backbone để duy trì kiến thức thế giới và chỉ cập nhật ΔW. Xét lớp LoRAMoE chứa N chuyên gia, được ký hiệu là {E_i}^N_i=1, quá trình chuyển tiếp của lớp có thể được biểu diễn toán học như sau:

o = W₀x + ΔWx = W₀x + Σ(i=1 to N) G(x)_i E_i(x) (3)

trong đó E_i(·) và G(·) = Softmax(xW_g) biểu thị chuyên gia thứ i và bộ định tuyến trong lớp LoRAMoE, tương ứng. W_g là ma trận tham số có thể huấn luyện của mạng định tuyến. Bằng cách này, các chuyên gia và công việc bên ngoài hoạt động cùng nhau, cho phép các chuyên gia phát triển các khả năng đa dạng và xử lý hiệu quả các loại nhiệm vụ khác nhau.

Ngoài ra, LoRA đã được chứng minh là vừa hiệu quả vừa hiệu quả đối với giai đoạn SFT của LLM (Wang et al., 2023a; Liu et al., 2022; Pan et al., 2022). Để nâng cao hiệu quả và tiết kiệm tài nguyên của quá trình tinh chỉnh, chúng tôi thay thế ma trận tham số của các chuyên gia bằng định dạng thứ hạng thấp. Cụ thể, ma trận ΔW_E ∈ R^(d_in×d_out) của chuyên gia E(·) trong lớp LoRAMoE có thể được viết như sau:

ΔW_E = BA (4)

trong đó A ∈ R^(d_in×r), B ∈ R^(r×d_out), và thứ hạng r ≪ min(d_in, d_out). LoRA đóng góp vào việc giảm đáng kể các tham số có thể huấn luyện, từ đó tăng cường hiệu quả và tiết kiệm chi phí trong quá trình tinh chỉnh.

--- TRANG 4 ---
[Hình 5: Hệ số biến thiên đối với các chuyên gia của LoRAMoE không bị ràng buộc tăng dần và duy trì ở giá trị cao, tức là khoảng ba, tương tự như hiện tượng quan sát được tại Shazeer et al. (2016). Điều này cho thấy rằng bộ định tuyến gán trọng số lớn cho cùng một vài chuyên gia.]

Nhìn chung, quá trình chuyển tiếp của lớp LoRAMoE thay thế lớp FFN truyền thống có thể được biểu diễn là:

o = W₀x + (α/r)Σ(i=1 to N) ωᵢ · BᵢAᵢx (5)

trong đó ωᵢ biểu thị trọng số của chuyên gia thứ i và α là siêu tham số hằng số, gần tương đương với tốc độ học.

3.2 Ràng buộc cân bằng địa phương
Sự mất cân bằng của việc sử dụng các chuyên gia là một vấn đề điển hình trong MoE (Shazeer et al., 2016; Fedus et al., 2021), cũng được quan sát thấy trong phương pháp đề xuất của chúng tôi, như được thể hiện trong Hình 5. Giải pháp thông thường là cân bằng việc sử dụng chuyên gia (Shazeer et al., 2016), bao gồm việc làm cho hệ số biến thiên của tầm quan trọng của các chuyên gia làm hàm mất mát. Tuy nhiên, phương pháp này giả định tất cả các mẫu huấn luyện đều thuộc cùng một phân phối, bỏ qua thực tế rằng các mẫu có thể đến từ các phân phối khác nhau như nhiệm vụ trả lời câu hỏi và các nhiệm vụ hạ nguồn khác, phân tích chi tiết hơn và chứng minh khái niệm trong Phụ lục C.

Xét các đặc điểm hỗn hợp của phân phối dữ liệu là quan trọng, trong giai đoạn huấn luyện, chúng tôi giới thiệu ràng buộc cân bằng địa phương, một phương pháp cân bằng sử dụng chuyên gia mới để làm cho một phần chuyên gia tập trung hơn vào việc tận dụng kiến thức thế giới để giải quyết các nhiệm vụ. Như được thể hiện trong Hình 6, trong giai đoạn tinh chỉnh, chúng tôi ràng buộc một cách mềm mại các chuyên gia tập trung vào hai khía cạnh, một trong số đó tập trung vào việc tận dụng kiến thức thế giới bằng cách học trên các tập dữ liệu liên quan của nó, trong khi khía cạnh khác tập trung vào các nhiệm vụ hạ nguồn khác. Ngoài ra, tất cả các chuyên gia trong cùng một khía cạnh đều được cân bằng như cân bằng việc sử dụng chuyên gia.

[Hình 6: Ràng buộc cân bằng địa phương. Chúng tôi ràng buộc một cách mềm mại các chuyên gia tập trung vào hai loại, một cho việc tận dụng kiến thức thế giới bằng cách học trên các nhiệm vụ liên quan của nó, và một khác cho việc tập trung vào các nhiệm vụ hạ nguồn khác. Trong khi đó, các chuyên gia trong việc giải quyết cùng một khía cạnh đang được cân bằng.]

Chính thức, chúng tôi định nghĩa ma trận quan trọng Q của lớp LoRAMoE và Q_n,m biểu thị tổng các giá trị định tuyến của chuyên gia thứ n cho mẫu huấn luyện thứ m trong một lô, có thể được biểu diễn như sau:

Q_n,m = Σ(j=1 to T_m) G(x_j)_i = exp(ω_j_i/τ) / Σ(k=1 to N) exp(ω_j_i/τ) (6)

trong đó N và T_m biểu thị số lượng chuyên gia và số lượng token của mẫu huấn luyện thứ m, tương ứng. x_j là đầu vào ẩn của token thứ j.

Sau đó chúng tôi định nghĩa ma trận hệ số I với cùng kích thước của Q, tương ứng với ma trận quan trọng Q. I_n,m biểu thị hệ số quan trọng của Q_n,m, có thể được viết như sau:

I_n,m = {
  1 + δ, Type_e(n) = Type_s(m)
  1 - δ, Type_e(n) ≠ Type_s(m)
} (7)

trong đó δ ∈ [0,1] kiểm soát mức độ mất cân bằng giữa các loại chuyên gia. Type_e(n) và Type_s(m) là loại mục tiêu được định nghĩa trước của chuyên gia thứ n và loại nhiệm vụ của mẫu huấn luyện thứ m trong một lô, tương ứng.

Chúng tôi phân loại dữ liệu hướng dẫn thành hai loại riêng biệt: các nhiệm vụ liên quan đến kiến thức thế giới như TriviaQA, và các nhiệm vụ hạ nguồn khác như Flores. Sau đó, chúng tôi cho phép một phần chuyên gia học trên các nhiệm vụ liên quan đến kiến thức thế giới để căn chỉnh hướng dẫn của con người với kiến thức thế giới, trong khi làm cho các chuyên gia khác tập trung hơn vào việc nâng cao hiệu suất của các nhiệm vụ hạ nguồn.

--- TRANG 5 ---
Chính thức, giả sử I_i,k và I_j,k biểu thị hệ số quan trọng của chuyên gia thứ i và thứ j cho mẫu thứ k, tương ứng. Nếu các chuyên gia thuộc cùng một nhóm, các giá trị của chúng tại các vị trí tương ứng trong ma trận hệ số là giống nhau, tức là I_i,k = I_j,k. Điều này cho thấy rằng những chuyên gia này có cùng tầm quan trọng vì chúng được gán để tập trung vào việc học cùng một loại nhiệm vụ. Ngược lại, các giá trị của các chuyên gia từ các nhóm khác biệt tại ma trận hệ số của chúng là khác nhau, tức là I_i,k ≠ I_j,k.

Mất mát ràng buộc cân bằng địa phương L_lbc được định nghĩa để đo lường sự phân tán của ma trận quan trọng có trọng số Z = I ⊙ Q, có thể được biểu diễn toán học là:

L_lbc = σ²(Z) / μ(Z) (8)

trong đó σ²(Z) và μ(Z) biểu thị phương sai và trung bình của Z, tương ứng. Cụ thể, nếu một mẫu cụ thể đến từ tập dữ liệu liên quan đến kiến thức thế giới, các chuyên gia tập trung vào giải quyết loại này sẽ có các giá trị lớn hơn trong ma trận hệ số I. Tối ưu hóa việc giảm mất mát L_lbc có thể làm cho các chuyên gia tương ứng học nhiều hơn từ mẫu này và được gán một trọng số lớn hơn bởi bộ định tuyến. Trong khi đó, các chuyên gia giải quyết cùng loại nhiệm vụ được cân bằng như Shazeer et al. (2016). Ngoài ra, ràng buộc là mềm để khuyến khích sự hợp tác giữa các chuyên gia để bảo tồn khả năng tổng quát hóa.

Nhìn chung, ràng buộc cân bằng địa phương L_lbc đạt được sự cân bằng địa phương giữa hai loại chuyên gia: một chuyên về việc tận dụng kiến thức thế giới bằng cách huấn luyện nhiều hơn trên các tập dữ liệu liên quan đến kiến thức thế giới, trong khi loại khác tập trung vào các nhiệm vụ hạ nguồn khác nhau. Mất mát của LoRAMoE có thể được biểu diễn như sau:

L_total = L + βL_lbc (9)

trong đó L là mất mát dự đoán token tiếp theo của LLM và β kiểm soát cường độ của ràng buộc cân bằng địa phương. Trong giai đoạn huấn luyện, chúng tôi đóng băng mô hình backbone và các tham số có thể huấn luyện chỉ là những tham số của các chuyên gia và bộ định tuyến trong các lớp LoRAMoE. Trong quá trình suy luận, bộ định tuyến tự động gán trọng số cho tất cả các chuyên gia, tránh được nhu cầu chỉ định trước các loại dữ liệu.

4 Thực nghiệm
4.1 Thiết lập thực nghiệm
Trong phần này, chúng tôi giới thiệu việc thực hiện huấn luyện cho LoRAMoE. Chúng tôi chỉ thay thế lớp tuyến tính trong mạng nơ-ron feed-forward của LLM bằng lớp LoRAMoE, khởi tạo mỗi lớp với sáu chuyên gia, trong đó ba chuyên gia được dành riêng để giải quyết các nhiệm vụ hạ nguồn, và ba chuyên gia khác chịu trách nhiệm tận dụng kiến thức thế giới trong mô hình cơ sở bằng cách học trên các nhiệm vụ liên quan của nó. Các siêu tham số để kiểm soát cường độ ràng buộc β và mức độ mất cân bằng δ đều được đặt là 0.1. Đối với các thiết lập LoRA, α và r được đặt là 32 và bốn cho kết quả chính, tương ứng. Dropout là 0.05, và tốc độ học là 2e-4.

Tập dữ liệu huấn luyện là bộ 3 triệu giống như bộ được mô tả trong Phụ lục A, cũng như các thiết lập đánh giá. Chúng tôi đóng băng các tham số của mô hình cơ sở, chỉ làm cho các chuyên gia và bộ định tuyến trong LoRAMoE có thể huấn luyện. Kích thước lô mỗi nút được đặt là 16.

4.2 Kết quả chính
Bảng 2 hiển thị hiệu suất của LoRAMoE và so sánh kết quả này với kết quả của việc áp dụng trực tiếp SFT cho mô hình hoặc sử dụng điều chỉnh LoRA. Kết quả cho thấy rằng mô hình ngôn ngữ với LoRAMoE có được hiệu suất tốt trên cả các benchmark kiến thức thế giới và các benchmark khác, cho thấy hiệu quả của nó trong việc tránh quên kiến thức đồng thời cải thiện khả năng đa nhiệm vụ.

[Bảng 2: Kết quả của LoRAMoE. Trái ngược với việc tinh chỉnh đầy đủ trực tiếp và việc sử dụng điều chỉnh LoRA thể hiện hiệu suất giảm trên các benchmark kiến thức thế giới sau khi huấn luyện, phương pháp của chúng tôi đảm bảo sự tăng trưởng đồng thời của cả các benchmark kiến thức thế giới và các nhiệm vụ hạ nguồn khác.]

Đối với các benchmark kiến thức thế giới, trái ngược với sự sụp đổ thảm khốc được thấy trong Phần 2, LoRAMoE không chỉ tránh được vấn đề này mà còn vượt trội hơn mô hình được tinh chỉnh chỉ với tập dữ liệu CBQA. LoRAMoE cho thấy sự tăng trưởng hiệu suất đáng kể trên các benchmark kiến thức thế giới so với SFT vanilla, với mức cải thiện lên đến 63.9% và mức tăng trung bình 35.3%.

Đối với các nhiệm vụ hạ nguồn khác, LoRAMoE có khả năng đạt được hiệu suất gần bằng hoặc thậm chí vượt trội so với SFT trực tiếp. Ví dụ, trong tất cả các nhiệm vụ đọc hiểu (tức là Race, ReCoRD, multiRC), LoRAMoE đạt được hiệu suất vượt trội.

Chúng tôi cũng so sánh phương pháp của chúng tôi với PEFT bằng một LoRA duy nhất. Việc quên kiến thức cũng xảy ra trong quá trình điều chỉnh LoRA đơn lẻ, vì nó về cơ bản giống như SFT vanilla (Hu et al., 2021). So với một LoRA duy nhất, nhiều LoRA cộng tác trong LoRAMoE nâng cao cả khả năng giữ lại kiến thức thế giới và hiệu suất đa nhiệm vụ. Chúng mang lại mức tăng trung bình 30.9% trong các benchmark kiến thức thế giới và 8.4% trong các nhiệm vụ hạ nguồn khác.

Bên cạnh đó, L_lbc cải thiện kết quả cho LoRAMoE trong phần lớn các nhiệm vụ, cả benchmark kiến thức thế giới và những nhiệm vụ khác. Đáng chú ý, đối với đọc hiểu, NLI và tập dữ liệu CBQA gốc, lợi ích của phương pháp này là khá đáng kể, lên đến 17.6%. Điều này cho thấy việc phân chia khả năng trong nhóm chuyên gia có lợi cho hiệu suất trong học tập đa nhiệm vụ.

[Bảng 3: Hiệu suất của LoRAMoE thay đổi với số lượng chuyên gia và thứ hạng LoRA trên tất cả các tập kiểm tra. Điều này bao gồm kết quả trung bình trên cả benchmark kiến thức thế giới và tất cả các nhiệm vụ hạ nguồn khác. LoRAMoE cho thấy sự ổn định đối với các thay đổi tham số.]

4.3 Phân tích độ nhạy
Trong phần này, chúng tôi phân tích độ nhạy tham số của LoRAMoE. Giữ các thiết lập khác không đổi, chúng tôi thay đổi số lượng chuyên gia và thứ hạng của LoRA. Hiệu suất trung bình với các thiết lập tham số khác nhau trên tất cả các tập kiểm tra bao gồm benchmark kiến thức thế giới và tất cả các nhiệm vụ hạ nguồn khác được thể hiện trong Bảng 3. Trong Phụ lục D có các kết quả chi tiết.

Khi số lượng tham số có thể huấn luyện tăng lên, hiệu suất nói chung ổn định. Số lượng 6 chuyên gia là lựa chọn có lợi nhất, vì nhiều chuyên gia hơn không dẫn đến hiệu suất cao hơn. Trong khi việc tăng thứ hạng LoRA cải thiện khả năng của mô hình phần nào, nó mang lại sự gia tăng theo cấp số nhân trong các tham số có thể huấn luyện.

4.4 Trực quan hóa việc sử dụng chuyên gia
Để xác nhận hiệu quả của LoRAMoE trong việc chuyên môn hóa các chuyên gia với hai loại, chúng tôi trực quan hóa trọng số của chúng được gán bởi bộ định tuyến khi gặp phải dữ liệu từ các nhiệm vụ hạ nguồn và các benchmark kiến thức tương ứng, như được minh họa trong Hình 7.

[Hình 7: Trực quan hóa trọng số của bộ định tuyến trên các loại dữ liệu khác nhau, trong đó loại 1 đề cập đến các chuyên gia dành riêng để căn chỉnh kiến thức thế giới trong mô hình cơ sở với hướng dẫn của con người và loại 2 đề cập đến các chuyên gia tập trung vào các nhiệm vụ hạ nguồn. Tỷ lệ sử dụng của loại chuyên gia phân kỳ đáng kể giữa các nhiệm vụ.]

Có một sự tương phản rõ rệt trong việc sử dụng hai loại chuyên gia khi xử lý các benchmark kiến thức thế giới và các nhiệm vụ hạ nguồn khác. Điều này cho thấy rằng các bộ định tuyến có thể tự động phân bổ các nhiệm vụ cụ thể cho các chuyên gia có khả năng tương ứng trong giai đoạn suy luận. Cụ thể, các chuyên gia được yêu cầu tận dụng kiến thức thế giới được sử dụng rất nhiều trong các benchmark kiến thức thế giới (ví dụ: TriviaQA, Natural Questions và HotpotQA), nhấn mạnh vai trò quan trọng của chúng trong việc ngăn chặn quên kiến thức thế giới. Điều này tương ứng với thực tế chúng tôi nêu trong Phần 2 rằng việc tinh chỉnh có giám sát tăng cường khả năng của mô hình trong những nhiệm vụ này bằng cách liên kết kiến thức thế giới được lưu trữ trước trong mô hình với hướng dẫn của con người.

Mặt khác, các chuyên gia được gán tập trung vào việc nâng cao hiệu suất trong các nhiệm vụ hạ nguồn được đặt tầm quan trọng tăng lên khi gặp phải những nhiệm vụ này. Thông qua kết quả trực quan hóa này, chúng tôi thấy rằng một số nhiệm vụ hạ nguồn vẫn cần các chuyên gia của loại khác. Điều này là hợp lý. Ví dụ, trong các nhiệm vụ đọc hiểu, kiến thức mà mô hình học được trong quá trình tiền huấn luyện có thể hỗ trợ tốt hơn trong việc đưa ra các phán đoán thực tế. Hiện tượng này thậm chí còn rõ ràng hơn trong các nhiệm vụ dựa trên ngôn ngữ. Trong nhiệm vụ WSC (Levesque et al., 2012), bộ định tuyến phân bổ trung bình khoảng 45% sự chú ý của nó cho các chuyên gia chịu trách nhiệm về kiến thức thế giới.

--- TRANG 6 ---
5 Công trình liên quan
Tinh chỉnh hiệu quả tham số. Với kích thước của các mô hình ngôn ngữ ngày càng lớn, việc tinh chỉnh hiệu quả tham số (PEFT (He et al., 2021)) đã trở nên quan trọng để tiết kiệm tài nguyên. Các nhà nghiên cứu đã đề xuất một số phương pháp như LoRA (Hu et al., 2021), adapters (Houlsby et al., 2019) và prompt learning (Lester et al., 2021), để nâng cao hiệu quả tinh chỉnh. PEFT dựa trên các bộ chuyển đổi thứ hạng thấp (Hu et al., 2021) được ưa chuộng và sử dụng rộng rãi, giới thiệu hai ma trận thứ hạng thấp có thể huấn luyện trong mỗi lớp kết nối đầy đủ, để đạt được tiết kiệm đáng kể trong tài nguyên huấn luyện mà không thêm chi phí tính toán suy luận bổ sung. Chúng tôi áp dụng các kỹ thuật thứ hạng thấp vào cấu trúc của các chuyên gia để tiết kiệm tiêu thụ tài nguyên.

Hỗn hợp các chuyên gia. Hỗn hợp các chuyên gia (MoE) thay thế lớp mạng nơ-ron feed-forward bằng các chuyên gia được kích hoạt thưa thớt, làm tăng đáng kể mô hình mà không tăng đáng kể chi phí tính toán (Jacobs et al., 1991). Hiện tại, các kiến trúc MoE cấp token được sử dụng rộng rãi trong các mô hình ngôn ngữ tiền huấn luyện và mô hình thị giác (Shazeer et al., 2016; Lepikhin et al., 2020; Du et al., 2022; Riquelme et al., 2021). Ngoài ra, các nhà nghiên cứu (Zhou et al., 2022; Chi et al., 2022) nhằm điều tra vấn đề lựa chọn bộ định tuyến trong MoE. Khác với những nỗ lực này để mở rộng kích thước mô hình và giải quyết vấn đề lựa chọn, chúng tôi đề xuất một khung phong cách MoE cho việc học đa nhiệm vụ và duy trì kiến thức thế giới được lưu trữ trong LLM.

Kiến trúc đa LoRA. Các nhà nghiên cứu cũng đã sử dụng nhiều LoRA để nâng cao hiệu suất mô hình. Huang et al. (2023) đề xuất LoraHub để chọn các kết hợp LoRA khác nhau cho tổng quát hóa nhiệm vụ. MOELoRA (Liu et al., 2023) tận dụng LoRA và MoE cho điều chỉnh cụ thể nhiệm vụ và đa nhiệm vụ, đặc biệt trong chăm sóc sức khỏe. Tuy nhiên, những phương pháp này cần loại dữ liệu làm đầu vào trong giai đoạn suy luận, hạn chế ứng dụng của mô hình cho các nhiệm vụ khác. Chen et al. (2023a) lần đầu tiên giới thiệu nhiều hệ thống phục vụ LoRA và Sheng et al. (2023) đề xuất S-LoRA, một hệ thống có thể phục vụ hàng nghìn bộ chuyển đổi LoRA từ một máy duy nhất. Chen et al. (2023b) giới thiệu một số chuyên gia để nâng cao khả năng của mô hình cho học tập đa phương thức. Khác với những phương pháp này, LoRAMoE giới thiệu một plugin phong cách MoE và Ràng buộc cân bằng địa phương để giải quyết việc quên kiến thức thế giới trong LLM, đồng thời nâng cao khả năng của mô hình trong học tập đa nhiệm vụ.

6 Kết luận
Trong bài báo này, chúng tôi trước tiên tìm hiểu sâu về xung đột giữa việc cải thiện hiệu suất của LLM trên các nhiệm vụ hạ nguồn bằng cách mở rộng dữ liệu trong giai đoạn SFT và việc ngăn chặn quên kiến thức thế giới. Để giải quyết xung đột này, chúng tôi sau đó giới thiệu LoRAMoE, một khung mới cho SFT, giới thiệu các LoRA làm chuyên gia và tích hợp chúng bằng bộ định tuyến. Kết quả thực nghiệm rộng rãi chứng minh rằng LoRAMoE có thể thúc đẩy sự hợp tác giữa các chuyên gia để nâng cao hiệu suất của mô hình đối với các nhiệm vụ hạ nguồn, đồng thời bảo tồn kiến thức thế giới bên trong nó.

--- TRANG 7 ---
7 Hạn chế
Trong phần này, chúng tôi thảo luận về những hạn chế tiềm ẩn của phương pháp đề xuất LoRAMoE. Thứ nhất, mặc dù chúng tôi đã chứng minh hiệu quả của LoRAMoE trong việc giảm thiểu quên kiến thức thế giới đồng thời nâng cao khả năng hạ nguồn của LLM với SFT, chúng tôi giới hạn kích thước mô hình ở 7B do hạn chế về tài nguyên và thời gian. Công việc tiếp theo sẽ được tiến hành trên các LLM lớn hơn, để hiểu ảnh hưởng của SFT quy mô lớn đối với những LLM này và để tăng cường khả năng đa nhiệm vụ của chúng. Thứ hai, ràng buộc cân bằng địa phương có thể ràng buộc một cách mềm mại loại chuyên gia và cân bằng việc sử dụng chuyên gia. Tuy nhiên, chúng tôi chưa nghiên cứu trường hợp có nhiều loại chuyên gia hơn cho việc phân loại nhiệm vụ chi tiết hơn. Công việc trong tương lai sẽ được tiến hành về sự hiểu biết chi tiết hơn về ảnh hưởng của SFT và việc sử dụng LoRAMoE.

Tài liệu tham khảo
[Các tài liệu tham khảo được liệt kê từ trang 8-10]

--- TRANG 8 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 9 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 10 ---
[Tiếp tục danh sách tài liệu tham khảo]

A Chi tiết về thực hiện thực nghiệm
Tập dữ liệu. Bảy nhiệm vụ là trả lời câu hỏi sách đóng (CBQA), phân giải đồng tham chiếu, suy luận ngôn ngữ tự nhiên (NLI), tóm tắt trừu tượng, dịch đa ngôn ngữ, đọc hiểu và phân loại văn bản. Bảng 4 cho thấy thành phần của tập dữ liệu 3 triệu mẫu. Dữ liệu tinh chỉnh năm triệu mà chúng tôi sử dụng bao gồm phiên bản ba triệu và các biến thể của chúng từ các chiến lược tăng cường dữ liệu. Phiên bản 1 triệu mẫu là tập con của tập dữ liệu 3 triệu mẫu gốc.

Đánh giá. Chúng tôi sử dụng khung opencompass để chạy quá trình đánh giá trên các nhiệm vụ đã nêu. Đáng chú ý, xem xét công việc trước đây đã ghi nhận sự chồng chéo train-test trong các tập dữ liệu CBQA (Lewis et al., 2020), chúng tôi cẩn thận lựa chọn các phần của tập dữ liệu CBQA mà không có sự chồng chéo train-test cho tập kiểm tra của chúng tôi, cụ thể là Filtered NQ và Filtered TriviaQA, để phân tích kiến thức thế giới của các mô hình tốt hơn.

B Kiến thức thế giới của LLM giảm thêm sau khi được huấn luyện với nhiều dữ liệu hơn
Với các loại nhiệm vụ tăng lên, có xu hướng không thể tránh khỏi là tăng lượng dữ liệu huấn luyện SFT. Để xác minh thêm rằng quá trình huấn luyện SFT quy mô lớn có thể dẫn đến việc quên kiến thức của LLM như đã nêu trong Phần 2, chúng tôi xây dựng một tập dữ liệu lớn hơn nhiều chứa mười triệu mẫu huấn luyện. Ngoài tập dữ liệu từ phần trước, chúng tôi cũng thêm các nhiệm vụ sau:

• Nhận dạng thực thể có tên: được lấy mẫu từ Wang et al. (2023b). Chứa 17 nhiệm vụ NER khác nhau.
• Thực thi chương trình: được lấy mẫu từ Wang et al. (2022). Chứa 90 nhiệm vụ khác nhau yêu cầu LLM hiểu hướng dẫn về một chương trình và thực thi nó.
• Tạo câu hỏi: được lấy mẫu từ tập dữ liệu huggingface hiện có. Với một ngữ cảnh, LLM cần tạo một câu hỏi phù hợp dựa trên câu trả lời.
• Text2sql: được lấy mẫu từ hai tập dữ liệu huggingface hiện có. Với một mô tả bằng ngôn ngữ tự nhiên, LLM cần tạo một chuỗi SQL phù hợp.
• Phân loại độc hại: được lấy mẫu từ tập dữ liệu huggingface hiện có.

Sau khi huấn luyện LLaMa-2-7b trên tập dữ liệu 10 triệu mẫu này với cùng thiết lập thực nghiệm với Phụ lục A, chúng tôi thấy LLM thể hiện việc quên kiến thức lớn hơn nhưng hiệu suất hứa hẹn trong các nhiệm vụ khác ngoài các benchmark kiến thức.

C Tình huống khó khăn phân phối hỗn hợp cho cân bằng chuyên gia
Khi tinh chỉnh MoE mà không có bất kỳ ràng buộc nào, cơ chế bộ định tuyến thường hội tụ về trạng thái mà một số ít chuyên gia nhận được tỷ lệ ưu tiên không cân xứng bởi bộ định tuyến, như được mô tả trong Hình 5. Sự mất cân bằng này giữa các chuyên gia đưa ra một thách thức cần khắc phục, vì các chuyên gia nhận được trọng số định tuyến lớn hơn trong các giai đoạn đầu của việc huấn luyện trải qua tối ưu hóa nhanh hơn, do đó thu được sự ưu tiên tăng lên từ bộ định tuyến. Một hiện tượng tương tự đã được ghi nhận trong công trình được trình bày trong Shazeer et al. (2016) và Fedus et al. (2021).

Một giải pháp thông thường để cân bằng việc sử dụng chuyên gia bao gồm việc sử dụng hệ số biến thiên của tầm quan trọng của các chuyên gia làm hàm mất mát, nhằm cân bằng tầm quan trọng của mỗi chuyên gia (Shazeer et al., 2016). Giải pháp này giả định rằng phân phối của các mẫu huấn luyện để tối ưu hóa MoE là một phân phối duy nhất, điều này vốn dĩ loại bỏ sự cần thiết phải xem xét các nguồn gốc đa dạng của phân phối dữ liệu. Cụ thể, phương pháp truyền thống này đơn giản hóa quá trình mô hình hóa bằng cách giả định tính đồng nhất trong các nguồn dữ liệu mà thường không phù hợp với dữ liệu tinh chỉnh chứa cả QA kiến thức thực tế và các nhiệm vụ hạ nguồn khác. Do đó, sự đơn giản hóa như vậy có thể dẫn đến sai lệch đáng kể, đặc biệt khi gặp phải các tập dữ liệu có đặc điểm phân phối khác nhau.

Các ràng buộc cân bằng truyền thống, nhằm phân bổ một phân phối đồng nhất của các mẫu huấn luyện trên tất cả các chuyên gia, có thể dẫn đến ước lượng tham số không chính xác. Điều này là vì những ràng buộc như vậy không tính đến sự khác biệt nội tại trong biểu diễn dữ liệu và tầm quan trọng trên các danh mục khác nhau. Nhận ra bản chất khác biệt của phân phối dữ liệu, LoRAMoE chiến lược gán dữ liệu cho các chuyên gia, không phải một cách đồng nhất, mà dựa trên các mất cân bằng quan sát được. Việc phân bổ này được điều chỉnh bởi một tập hợp trọng số được hiệu chỉnh để phản ánh tầm quan trọng và biểu diễn khác nhau của các danh mục dữ liệu khác nhau trong tập dữ liệu tổng thể.

Phương pháp phân bổ chuyên biệt như vậy là then chốt trong việc giải quyết các thách thức do phân phối dữ liệu không đồng đều gây ra. Bằng cách điều chỉnh phân phối của các mẫu huấn luyện cho mỗi chuyên gia dựa trên sự khác biệt vốn có trong dữ liệu, LoRAMoE tạo điều kiện cho việc ước lượng tham số chính xác và đại diện hơn. Phương pháp tinh tế này đối với phân phối dữ liệu cho phép khớp hiệu quả hơn của mô hình với các tập con dữ liệu đa dạng, cải thiện đáng kể độ chính xác dự đoán và khả năng tổng quát hóa của mô hình. Chiến lược này đặc biệt hiệu quả trong các tình huống mà sự mất cân bằng dữ liệu có thể dẫn đến việc học lệch và lỗi tổng quát hóa, đảm bảo rằng mỗi danh mục dữ liệu được đại diện và mô hình hóa một cách phù hợp trong hệ thống tổng thể.

Để minh họa khái niệm với một mô hình đơn giản, hãy giả sử dữ liệu huấn luyện của chúng tôi được lấy mẫu từ hỗn hợp hai phân phối Gaussian. Các giá trị trung bình (μ₁, μ₂) và phương sai (σ₁², σ₂²) của những phân phối này là ngầm định. Tỷ lệ dữ liệu huấn luyện từ mỗi phân phối được ký hiệu là p₁ và p₂ trong đó p₁ + p₂ = 1, không mất tính tổng quát, chúng tôi giả định rằng p₁ ≤ p₂. Khi một mô hình MoE khớp với phân phối đề xuất với trọng số cân bằng m, khả năng của mô hình với dữ liệu có thể được biểu diễn là:

L(X) = ∏(x∈X₁) [mN(x;μ'₁,σ'₁²) + (1-m)N(x;μ'₂,σ'₂²)] × ∏(x∈X₂) [mN(x;μ'₁,σ'₁²) + (1-m)N(x;μ'₂,σ'₂²)] (10)

trong đó Card(X₁) : Card(X₂) = p₁ : p₂.

Sử dụng N₁(x) và N₂(x) cho N(x;μ'₁,σ'₁²) và N(x;μ'₂,σ'₂²),

Giá trị trung bình tối ưu cho μ'₁ thỏa mãn các điều kiện sau, có giá trị là 0 khi phân phối khớp thuộc cùng họ phân phối hỗn hợp N(θ,p₁) như phân phối lấy mẫu:

∂logL(X)/∂μ'₁ = Σ(x∈X₁∪X₂) ∂/∂μ'₁ log(mN₁(x) + (1-m)N₂(x))
= Σ(x∈X₁∪X₂) (x-μ'₁)/σ'₁² × mN₁(x)/(mN₁(x) + (1-m)N₂(x)) (11)

Trong phương trình 10, chúng tôi có thể thay thế một phần của phép tổng bằng ước lượng thực nghiệm của giá trị trung bình của đầu vào x. Đối với một mạng định tuyến lý tưởng, phải tồn tại một phân phối Nᵢ sao cho dữ liệu được phân bổ cho phân phối này là độc lập và phân phối đồng nhất với một trong các đỉnh trong phân phối lấy mẫu. Hãy giả sử phân phối này là N₂. Trong trường hợp này, nếu m ≥ p₁, thì kết quả khớp cho phân phối μ₁' sẽ là μ'₁ = (p₁μ₁ + (m-p₁)μ₂)/m.

Dựa trên quy tắc chuỗi của phép tính vi phân, chúng tôi kết thúc với:

dlogL/dm = ∂logL/∂μ'₁ × dμ'₁/dm
= Σ(x∈X₁∪X₂) (x-μ'₁)/σ'₁² × mN₁(x)/(mN₁(x) + (1-m)N₂(x)) × p₁(μ₂-μ₁)/m² ≤ 0 (12)

Kết quả nghịch đảo có thể được suy ra tương tự.

Do đó, lỗi huấn luyện tốt nhất chỉ đạt được khi hệ số hỗn hợp m của phân phối trước phù hợp với trọng số phân phối lấy mẫu thực tế p₁.

D Kết quả chi tiết của nghiên cứu độ nhạy
Bảng 6 cho thấy các kết quả chi tiết được trình bày trong Phần 4.3.

[Bảng 4-6: Các bảng chi tiết về thành phần tập dữ liệu và kết quả thực nghiệm]

# 2311.17601.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2311.17601.pdf
# Kích thước file: 185574 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
arXiv:2311.17601v1 [cs.LG] 29 Nov 2023Học liên tục với Thích ứng Hạng thấp
Martin Wistuba
Amazon Web ServicesPrabhu Teja S
Amazon Web Services
Lukas Balles
Amazon Web ServicesGiovanni Zappella
Amazon Web Services
Tóm tắt
Các nghiên cứu gần đây sử dụng transformer đã được huấn luyện trước đã cho thấy hiệu suất ấn tượng khi được tinh chỉnh với dữ liệu từ bài toán downstream quan tâm. Tuy nhiên, chúng gặp khó khăn trong việc duy trì hiệu suất đó khi đặc tính dữ liệu thay đổi. Trong bài báo này, chúng tôi tập trung vào học liên tục, nơi một transformer đã được huấn luyện trước được cập nhật để hoạt động tốt trên dữ liệu mới, đồng thời duy trì hiệu suất của nó trên dữ liệu mà nó đã được huấn luyện trước đó. Các công trình trước đây đã giải quyết vấn đề này chủ yếu thông qua các phương pháp lấy cảm hứng từ điều chỉnh prompt. Chúng tôi đặt câu hỏi về lựa chọn này và nghiên cứu khả năng áp dụng của Thích ứng Hạng thấp (LoRA) cho học liên tục. Trên một loạt các benchmark học tăng dần theo miền, giải pháp dựa trên LoRA của chúng tôi, CoLoR, mang lại hiệu suất tốt nhất hiện tại, trong khi vẫn hiệu quả về tham số như các phương pháp dựa trên điều chỉnh prompt.

1 Giới thiệu
Một tính năng chính của khả năng nhận thức của con người là cập nhật kiến thức về một vấn đề một cách gia tăng và liên tục; một đứa trẻ có thể học cách nhận biết các giống chó mới một cách liền mạch mà không quên những gì đã học trước đó. Tuy nhiên, các hệ thống học máy hiện đại lại thất bại ở điều này. Khi các phương pháp tinh chỉnh ngây thơ được sử dụng để cập nhật trọng số, chúng hoạt động tốt trên tập dữ liệu cụ thể mà nó đã được tinh chỉnh, nhưng mất hiệu suất trên những tập dữ liệu trước đó, một hiện tượng được gọi là quên thảm khốc [9,20]. Vấn đề này, mặc dù không nghiêm trọng bằng đối với các transformer được huấn luyện trước hiện đại [25], vẫn là một trở ngại lớn trong việc triển khai các hệ thống đáng tin cậy. Học liên tục [4,21] giải quyết vấn đề cập nhật định kỳ một mô hình với dữ liệu mới, đồng thời tránh quên thông tin trước đó.

Trong thực tế, dữ liệu đến dưới dạng một chuỗi các tập dữ liệu và chúng ta nhằm mục đích hoạt động tốt trên tập dữ liệu mới nhất trong khi duy trì hiệu suất trên các tập dữ liệu trước đó. Một số mô hình học liên tục được định nghĩa dựa trên sự khác biệt giữa mỗi tập dữ liệu. Trong học tăng dần theo miền (DIL), tập nhãn được cố định, trong khi phân phối dữ liệu có thể thay đổi một cách tùy ý. Trong học tăng dần theo lớp (CIL), tập nhãn tăng dần với các tập dữ liệu mới, điều này đặt ra thách thức nhận biết các lớp mới được giới thiệu. Trong học tăng dần theo tác vụ (TIL), chúng ta học giải quyết các tác vụ khác nhau và số lượng tác vụ tăng dần. Trong thời gian huấn luyện và dự đoán, chúng ta biết danh tính tác vụ, điều này không xảy ra trong các cài đặt khác.

Với các mô hình dựa trên transformer trở nên phổ biến, một số phương pháp học liên tục đã được đề xuất sử dụng các thành phần kiến trúc cụ thể của những mô hình đó. Các phương pháp này được lấy cảm hứng mạnh mẽ từ các phương pháp tinh chỉnh hiệu quả tham số trong NLP [28], chủ yếu là điều chỉnh prompt [15]. Điều chỉnh prompt thêm một tập hợp các tham số có thể học được vào đầu ra của lớp nhúng đầu vào và chỉ huấn luyện những tham số đó, trong khi giữ phần còn lại của mô hình đóng băng. Learning to Prompt

Workshop on Distribution Shifts, 37th Conference on Neural Information Processing Systems (NeurIPS 2023).

--- TRANG 2 ---
(L2P) [38] huấn luyện một tập hợp các prompt phụ thuộc vào đầu vào được chia sẻ qua các tập dữ liệu, điều này khuyến khích chuyển giao. S-Prompts [31] thay vào đó học một prompt duy nhất cho mỗi tập dữ liệu, và đề xuất một phương pháp để xác định prompt nào sử dụng khi suy luận. Chúng tôi thảo luận về một số công trình khác trong Phụ lục A. Tuy nhiên, việc lựa chọn sử dụng điều chỉnh prompt không được biện minh đầy đủ trong các phương pháp này ngoài hiệu quả tham số, mặc dù các công trình trước đây [12,30] đã chứng minh điều chỉnh prompt chậm hơn trong huấn luyện và đạt hiệu suất thời gian kiểm tra thấp hơn so với tinh chỉnh đầy đủ tương ứng.

Trong công trình này, chúng tôi xem xét lại lựa chọn này, dựa trên bằng chứng từ cộng đồng NLP cho thấy các phương pháp cập nhật hạng thấp [12] hoạt động tốt hơn so với những phương pháp dựa trên prompt. Chúng tôi đề xuất một sự thích ứng của S-Prompts, phương pháp tốt nhất hiện tại cho học tăng dần theo miền, được gọi là CoLoR để huấn luyện liên tục hiệu quả các vision transformer cho thấy cải thiện đáng kể trong hiệu suất dự đoán. Với đánh giá thực nghiệm trên ba benchmark tăng dần theo miền, chúng tôi cho thấy rằng CoLoR vượt trội hơn các phương pháp dựa trên prompt như L2P và S-Prompts về độ chính xác trung bình và việc quên. Hơn nữa, chúng tôi cho thấy rằng những cải thiện này đạt được với xấp xỉ cùng số lượng tham số mô hình. Chúng tôi đề xuất một mở rộng đơn giản cho phương pháp của mình gọi là CoLoR++ mang lại kết quả tốt nhất hiện tại trên Split CIFAR-100.

2 Thích ứng Hạng thấp Liên tục
Chúng tôi thảo luận về Thích ứng Hạng thấp (LoRA), và sau đó trình bày phương pháp của chúng tôi Thích ứng Hạng thấp Liên tục (CoLoR).

2.1 Thích ứng Hạng thấp
Chúng tôi tập trung vào vision transformer trong công trình này, nhưng cách tiếp cận này đủ tổng quát để được sử dụng với các transformer được huấn luyện trước khác. Mô tả chi tiết về vision transformer được cung cấp trong Phụ lục B. Tinh chỉnh truyền thống cập nhật tất cả trọng số của transformer được huấn luyện trước với dữ liệu của tác vụ downstream. Thích ứng Hạng thấp [12] ràng buộc việc cập nhật thành một cập nhật hạng thấp.

Một cập nhật cho ma trận tham số W∈Rd×k có dạng W←W+ ∆W được ràng buộc bằng cách tham số hóa ∆W=BA trong đó A∈Rr×k và B∈Rd×r. Điều này hạn chế ∆W thành hạng r, và cũng hiệu quả về tham số; khi r≪k, tổng số tham số được cập nhật là r(d+k) thay vì kd như trong trường hợp tinh chỉnh đầy đủ. Ngoài ra, LoRA chỉ được áp dụng cho các ma trận nhúng query và value (WQ và WV) trong tất cả các lớp của mạng, do đó giảm thêm số lượng tham số có thể huấn luyện so với tinh chỉnh đầy đủ. Khi suy luận, các tham số được thêm vào có thể được hợp nhất với các tham số cũ, giữ cho thời gian suy luận không bị ảnh hưởng.

2.2 CoLoR – Huấn luyện và Suy luận
Huấn luyện CoLoR tận dụng một mô hình được huấn luyện trước h và mở rộng nó bằng LoRA để huấn luyện một mô hình chuyên gia cho mỗi tập dữ liệu D. Hãy ký hiệu mô hình chuyên gia cho tập dữ liệu D với fD(x) = gD◦h(x;ΘD) trong đó các tham số của h được đóng băng nhưng nó được mở rộng bởi các mô-đun LoRA cụ thể cho tập dữ liệu được tham số hóa bởi ΘD. gD đề cập đến lớp phân loại cụ thể cho tập dữ liệu gD(x) = softmax(w⊺D h(x;ΘD)+ bD) sử dụng token [CLS] của vision transformer. Các tham số có thể huấn luyện của mạng là ΘD,l={At,lQ,BD,lQ,AD,lV,BD,lV} tương ứng với tất cả các thành phần LoRA được thêm vào mỗi lớp l, và các tham số của bộ phân loại wD,bD. Mạng tổng thể được huấn luyện với một hàm mất mát phù hợp cho bài toán downstream.

Suy luận Vì định danh tập dữ liệu D không có sẵn tại thời điểm suy luận, chúng tôi sử dụng một phương pháp không giám sát đơn giản [31] để suy luận nó. Chúng tôi ước tính k vector nguyên mẫu tập dữ liệu cho mỗi tập dữ liệu D tại thời điểm huấn luyện như sau. Đầu tiên, chúng tôi nhúng mỗi instance huấn luyện sử dụng h (không có mô-đun LoRA), và chạy k-means trên những nhúng đặc trưng đó. Chúng tôi lưu trữ k tâm cụm phục vụ như đại diện cho tập dữ liệu D. Tại thời điểm suy luận cho một instance x, chúng tôi ước tính tâm cụm gần nhất với h(x). Sau đó, chúng tôi sử dụng fˆD để đưa ra dự đoán cho x, trong đó ˆD là tập dữ liệu tương ứng với tâm cụm gần nhất.

--- TRANG 3 ---
3 Thực nghiệm
Thiết lập thực nghiệm Các thực nghiệm của chúng tôi phản ánh chặt chẽ những thực nghiệm của [31]. Đối với các thực nghiệm học tăng dần theo miền, chúng tôi trình bày kết quả trên CORe50 [18] và DomainNet [23]. CORe50 là một benchmark cho nhận dạng đối tượng liên tục với 50 lớp từ 11 tập dữ liệu với 8 trong số chúng hoạt động như tập huấn luyện, và phần còn lại như tập kiểm tra. DomainNet là một benchmark cho phân loại ảnh với 345 lớp và 6 tập dữ liệu. Đối với các thực nghiệm tăng dần theo lớp, chúng tôi sử dụng Split CIFAR-100 [37] chia CIFAR-100 thành 10 tập dữ liệu gồm 10 lớp liên tiếp mỗi tập.

Để tạo điều kiện so sánh công bằng các baseline, chúng tôi sử dụng mô hình ViT-B-16 [6] được huấn luyện trước trên ImageNet21k từ thư viện timm [34], và báo cáo độ chính xác trung bình, tức là phần trăm các instance kiểm tra được phân loại chính xác cho đến tập dữ liệu hiện tại. Cơ sở mã của chúng tôi được xây dựng dựa trên S-Prompts [31].

Chúng tôi cung cấp một tóm tắt kết quả ở đây, và trình bày các bảng chi tiết trong Phụ lục D (Bảng 2 đến 4). Chúng tôi, chủ yếu, tập trung vào các phương pháp không có bộ nhớ ở đây và đẩy so sánh rộng hơn với các phương pháp dựa trên replay vào Phụ lục.

406080Độ chính xác trung bình74.8 75.578.383.185.5CORe50
40506070
47.649.2
40.150.669.7DomainNet
EWC [14] LwF [17] L2P [33] S-Prompts [31] CoLoR

Hình 1: Kết quả trên hai tập dữ liệu khác nhau cho học tăng dần theo miền. CoLoR cải thiện 2%-19% so với phương pháp không có bộ nhớ tốt nhất tiếp theo.

CoLoR thể hiện kết quả tốt nhất hiện tại mới trong học tăng dần theo miền. Trong Hình 1, CoLoR thể hiện hiệu suất vượt trội so với tất cả các phương pháp khác. Nó vượt trội hơn đối thủ cạnh tranh gần nhất 2% trên CORe50, và 19% trên DomainNet. Hơn nữa, CoLoR hoạt động ngang bằng hoặc tốt hơn các phương pháp dựa trên replay (Phụ lục, Bảng 3).

6080100Độ chính xác trung bình 47.060.783.8
67.372.786.5Split CIFAR-100
EWC [14]
LwF [17]L2P [33]
S-Prompts [31]CoLoR
CoLoR++

Hình 2: CoLoR cải thiện hơn 5% trên CIFAR-100 trong kịch bản tăng dần theo lớp so với S-Prompts.

LoRA có lợi trong học tăng dần theo lớp. Kết quả trên Split CIFAR-100 hỗ trợ lập luận của chúng tôi rằng LoRA là lựa chọn tốt hơn so với điều chỉnh prompt, vì CoLoR mang lại kết quả tốt hơn S-Prompts (Hình 2). Tuy nhiên, CoLoR thua kém L2P do chất lượng biểu diễn được trích xuất bởi ViT (h(·)) cho phương pháp nhận dạng tập dữ liệu. Để giải quyết điểm yếu này, chúng tôi đề xuất CoLoR++, sử dụng biểu diễn được trích xuất bởi mạng sau khi cập nhật tập dữ liệu đầu tiên, tức là h(x,Θ1). Chúng tôi tin rằng bộ trích xuất đặc trưng này biểu diễn dữ liệu hiệu quả vì nó đã được huấn luyện trên một phần của nó, dẫn đến kết quả cải thiện. Một cải thiện tương đương cũng được nhận thấy trong học tăng dần theo miền, mặc dù ở mức độ ít hơn (Phụ lục, Bảng 3).

CoLoR giữ hiệu quả tham số của S-Prompts Bảng 2 tóm tắt các tham số bổ sung cần thiết cho CoLoR và các đối thủ cạnh tranh điều chỉnh prompt của nó trên một bài toán hai lớp giả định. Vì hiệu quả này chỉ đúng đối với hạng thấp r, chúng tôi báo cáo kết quả độ chính xác bổ sung trong Hình 3 và Bảng 3 và 4 trong Phụ lục.

--- TRANG 4 ---
Bảng 1: Số lượng tham số có thể huấn luyện cho mỗi phương pháp. Chúng tôi báo cáo các tham số được huấn luyện cho DyTox, L2P, S-Prompts, và CoLoR (r= 1) cho một bài toán hai lớp giả định. †số liệu được tái tạo từ [31].

DyTox† L2P† S-Prompts†CoLoR
Tham số bổ sung mỗi tập dữ liệu (trung bình)1.42M 18.43K 52.22K 38.40K
1.65%↑0.02%↑ 0.06%↑ 0.04%↑

100101102
Hạng LoRA r83858789Độ chính xác trung bình CORe50
100101102
Hạng LoRA r4954596469DomainNet
100101102
Hạng LoRA r677073Split CIFAR-100

Hình 3: Tăng hạng bằng cách giữ tất cả các cài đặt khác cố định. Tăng hạng vượt quá con số 2 chữ số chỉ mang lại cải thiện nhỏ trong hầu hết các trường hợp. CoLoR vượt trội hơn đối thủ cạnh tranh tốt nhất của nó ngay cả với hạng nhỏ nhất.

Rõ ràng, đối với cùng số lượng tham số, CoLoR vẫn cung cấp kết quả tốt hơn so với các đối thủ cạnh tranh. Hơn nữa, việc tăng hạng cho phép đánh đổi hiệu quả tham số để có hiệu suất dự đoán.

CoLoR thu hẹp khoảng cách giữa DIL và TIL. Trong các thực nghiệm trước đây, chúng tôi giả định không có quyền truy cập vào định danh tập dữ liệu khi suy luận, và sử dụng phương pháp nhận dạng tập dữ liệu của chúng tôi để xác định mô-đun LoRA nào sử dụng. Trong Bảng 2, chúng tôi cho thấy kết quả cho việc sử dụng phương pháp nhận dạng tập dữ liệu oracle. Một sự gia tăng đáng kể về độ chính xác được mong đợi vì việc nhận dạng tập dữ liệu không tầm thường; đặc biệt, trong CIL một dự đoán tập dữ liệu sai dẫn đến phân loại sai. Tuy nhiên, đối với DIL điều này xảy ra ở mức độ ít hơn và CoLoR thu hẹp khoảng cách giữa TIL và DIL. Cuối cùng, hiệu suất TIL có thể được hiểu như cận trên của việc sử dụng các mô-đun dựa trên LoRA cho học liên tục. Quan trọng là, cận trên này cao hơn đáng kể so với cận thường đạt được bằng cách huấn luyện một mô hình duy nhất sử dụng tất cả dữ liệu (xem Phụ lục, Bảng 4).

Bảng 2: So sánh id tập dữ liệu được suy luận với id tập dữ liệu đã biết với CoLoR. Chúng tôi báo cáo hiệu suất trong trường hợp id tập dữ liệu được suy luận như giải thích ở trên và trong trường hợp id tập dữ liệu chính xác được cung cấp bởi oracle. Mặc dù cài đặt dựa trên oracle không thực tế, việc so sánh này vẫn hữu ích để khảo sát hiệu suất của thuật toán. Thực nghiệm này không áp dụng cho CORe50.

DomainNet Split CIFAR-100
CoLoR (id tập dữ liệu được suy luận) 69.67 71.42
CoLoR (id tập dữ liệu chính xác) 73.68 98.67

4 Kết luận
Trong công trình này, chúng tôi đã xem xét kỹ lưỡng sự hiện diện khắp nơi của điều chỉnh prompt trong các phương pháp học liên tục gần đây để ủng hộ các phương pháp tinh chỉnh hiệu quả tham số (PEFT) khác. Chúng tôi đã làm điều này bằng cách giới thiệu CoLoR, một phương pháp học liên tục dựa trên LoRA. Chúng tôi đã chứng minh thực nghiệm rằng nó vượt trội hơn phương pháp điều chỉnh prompt tương ứng trong học tăng dần theo miền và theo lớp với biên độ lớn và vẫn hiệu quả về tham số. Hơn nữa, chúng tôi đã cải thiện chiến lược nhận dạng tập dữ liệu không giám sát bằng cách sử dụng biểu diễn của mô hình được tinh chỉnh. Thay đổi này đã mang lại kết quả tốt nhất hiện tại mới trên Split CIFAR-100.

--- TRANG 5 ---
Tài liệu tham khảo
[1] Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, và Simone Calderara. Dark experience for general continual learning: a strong, simple baseline. Trong NeurIPS, 2020. 8,9, 10
[2] Hyuntak Cha, Jaeho Lee, và Jinwoo Shin. Co2l: Contrastive continual learning. Trong ICCV, 2021. 9,10
[3] Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K Dokania, Philip HS Torr, và Marc'Aurelio Ranzato. On tiny episodic memories in continual learning. arXiv preprint arXiv:1902.10486, 2019. 8,9,10
[4] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, và Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366–3385, 2021. 1
[5] Prithviraj Dhar, Rajat Vikram Singh, Kuan-Chuan Peng, Ziyan Wu, và Rama Chellappa. Learning without memorizing. Trong CVPR, trang 5138–5146. Computer Vision Foundation / IEEE, 2019. 8
[6] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, và Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. Trong ICLR, 2021. 3,8
[7] Arthur Douillard, Alexandre Ramé, Guillaume Couairon, và Matthieu Cord. Dytox: Transformers for continual learning with dynamic token expansion. Trong CVPR, 2022. 8,9
[8] Beyza Ermis, Giovanni Zappella, Martin Wistuba, Aditya Rawal, và Cédric Archambeau. Memory efficient continual learning with transformers. Trong NeurIPS, 2022. 8
[9] Robert M French. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences, 3(4):128–135, 1999. 1
[10] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, và Dahua Lin. Learning a unified classifier incrementally via rebalancing. Trong CVPR, 2019. 8
[11] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, và Sylvain Gelly. Parameter-efficient transfer learning for NLP. Trong ICML, tập 97 của Proceedings of Machine Learning Research, trang 2790–2799. PMLR, 2019. 8
[12] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. LoRA: Low-rank adaptation of large language models. Trong International Conference on Learning Representations, 2022. 2
[13] Ronald Kemker và Christopher Kanan. Fearnet: Brain-inspired model for incremental learning. Trong ICLR, 2018. 8
[14] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, và cộng sự. Overcoming catastrophic forgetting in neural networks. Trong Proceedings of the national academy of sciences, 2017. 3,8,9,10
[15] Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-efficient prompt tuning. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 3045–3059, Online và Punta Cana, Dominican Republic, tháng 11 năm 2021. Association for Computational Linguistics. 1,8

--- TRANG 6 ---
[16] Xiang Lisa Li và Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 4582–4597, Online, tháng 8 năm 2021. Association for Computational Linguistics. 8
[17] Zhizhong Li và Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935–2947, 2017. 3,8,9,10
[18] Vincenzo Lomonaco và Davide Maltoni. CORe50: a new dataset and benchmark for continuous object recognition. Trong Sergey Levine, Vincent Vanhoucke, và Ken Goldberg, biên tập, Proceedings of the 1st Annual Conference on Robot Learning, tập 78 của Proceedings of Machine Learning Research, trang 17–26. PMLR, 13–15 tháng 11 năm 2017. 3
[19] Francesco Marra, Cristiano Saltori, Giulia Boato, và Luisa Verdoliva. Incremental learning for the detection and classification of gan-generated images. Trong WIFS, 2019. 8
[20] Michael McCloskey và Neal J Cohen. Catastrophic interference in connectionist networks: The sequential learning problem. Trong Psychology of learning and motivation, tập 24, trang 109–165. Elsevier, 1989. 1
[21] German I Parisi, Ronald Kemker, Jose L Part, Christopher Kanan, và Stefan Wermter. Continual lifelong learning with neural networks: A review. Neural networks, 113:54–71, 2019. 1
[22] Lorenzo Pellegrini, Gabriele Graffeti, Vincenzo Lomonaco, và Davide Maltoni. Latent replay for real-time continual learning. Trong IROS, 2020.
[23] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, và Bo Wang. Moment matching for multi-source domain adaptation. Trong ICCV, 2019. 3
[24] Ameya Prabhu, Philip HS Torr, và Puneet K Dokania. GDumb: A simple approach that questions our progress in continual learning. Trong ECCV, 2020. 8,9,10
[25] Vinay Venkatesh Ramasesh, Aitor Lewkowycz, và Ethan Dyer. Effect of scale on catastrophic forgetting in neural networks. Trong International Conference on Learning Representations, 2022. 1
[26] Anastasia Razdaibiedina, Yuning Mao, Rui Hou, Madian Khabsa, Mike Lewis, và Amjad Almahairi. Progressive prompts: Continual learning for language models. Trong ICLR. OpenReview.net, 2023. 8
[27] Hippolyt Ritter, Aleksandar Botev, và David Barber. Online structured laplace approximations for overcoming catastrophic forgetting. Trong NeurIPS, trang 3742–3752, 2018. 8
[28] Sebastian Ruder, Jonas Pfeiffer, và Ivan Vulić. Modular and parameter-efficient fine-tuning for NLP models. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts, trang 23–29, Abu Dubai, UAE, tháng 12 năm 2022. Association for Computational Linguistics. 1
[29] James Seale Smith, Leonid Karlinsky, Vyshnavi Gutta, Paola Cascante-Bonilla, Donghyun Kim, Assaf Arbelle, Rameswar Panda, Rogério Feris, và Zsolt Kira. Coda-prompt: Continual decomposed attention-based prompting for rehearsal-free continual learning. Trong CVPR, trang 11909–11919. IEEE, 2023. 8
[30] Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan Liu, Peng Li, Juanzi Li, Lei Hou, Maosong Sun, và Jie Zhou. On transferability of prompt tuning for natural language processing. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 3949–3969, Seattle, United States, tháng 7 năm 2022. Association for Computational Linguistics. 2

--- TRANG 7 ---
[31] Yabin Wang, Zhiwu Huang, và Xiaopeng Hong. S-prompts learning with pre-trained transformers: An occam's razor for domain incremental learning. Trong NeurIPS, 2022. 2,3,4,8,9, 10
[32] Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, và cộng sự. Dualprompt: Complementary prompting for rehearsal-free continual learning. trang 631–648, 2022. 8
[33] Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, và Tomas Pfister. Learning to prompt for continual learning. Trong CVPR, 2022. 3,9,10
[34] Ross Wightman. Pytorch image models. https://github.com/rwightman/pytorch-image-models, 2019. 3
[35] Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, và Yun Fu. Large scale incremental learning. Trong CVPR, 2019. 8,9,10
[36] Fei Ye và Adrian G. Bors. Learning latent representations across multiple data domains using lifelong VAEGAN. Trong ECCV (20), tập 12365 của Lecture Notes in Computer Science, trang 777–795. Springer, 2020. 8
[37] Friedemann Zenke, Ben Poole, và Surya Ganguli. Continual learning through synaptic intelligence. Trong ICML, 2017. 3
[38] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, và Ziwei Liu. Learning to prompt for vision-language models. arXiv preprint arXiv:2109.01134, 2021. 2,8

--- TRANG 8 ---
Phụ lục A Các công trình liên quan
Các phương pháp học liên tục có thể được phân loại rộng rãi dựa trên cách chúng giữ lại thông tin đã học trong các tập dữ liệu trước đó. Các phương pháp dựa trên replay giải quyết quên thảm khốc bằng cách sử dụng một số dữ liệu bổ sung được sử dụng khi huấn luyện trên dữ liệu mới [1–3,10,19,24,35]. Các phương pháp này lưu trữ một số điểm dữ liệu từ các tập dữ liệu trước đó trong một bộ nhớ có kích thước hạn chế và phát lại những điểm dữ liệu đó trong quá trình huấn luyện. Các cách tiếp cận không có bộ nhớ thay thế các điểm dữ liệu thực bằng dữ liệu được tạo ra hoặc phụ trợ, được phát lại [13,36].

Các phương pháp dựa trên regularization thường không yêu cầu bộ nhớ và tránh quên bằng cách thêm các điều kiện regularization vào hàm mất mát. Các điều kiện này có thể regularize trọng số trực tiếp để tránh thay đổi các trọng số quan trọng [14,27] hoặc regularize đầu ra kích hoạt [5,17].

Với sự xuất hiện của các transformer được huấn luyện trước quy mô lớn, học liên tục không có bộ nhớ dựa trên điều chỉnh prompt [15] cho học tăng dần theo miền hoặc theo lớp, hoặc adapter [11] cho học tăng dần theo tác vụ [8] đã được đề xuất gần đây. Learning To Prompt (L2P) [38], dựa trên điều chỉnh prompt, học một tập hợp các prompt phụ thuộc vào đầu vào được chia sẻ qua các tập dữ liệu. Dual-Prompts [32] mở rộng điều này bằng cách học thêm các prompt phụ thuộc vào tập dữ liệu và độc lập với tập dữ liệu tại các điểm khác nhau trong mạng. Ngoài ý tưởng này, các công trình tiếp theo đề xuất học các thành phần được kết hợp thành prompt tại thời điểm suy luận [29]. Các công trình đơn giản hóa vấn đề bằng cách học một prompt cho mỗi tập dữ liệu được kết hợp để chuyển giao hiệu quả tồn tại. Tuy nhiên, điều này yêu cầu giả định một cài đặt tăng dần theo tác vụ nơi các prompt cũ không được cập nhật thêm [26] hoặc quyền truy cập vào dữ liệu cũ [7]. S-Prompts vượt qua vấn đề này bằng cách huấn luyện giả định cài đặt tăng dần theo tác vụ và sau đó giải quyết vấn đề nhận dạng tác vụ tại thời điểm suy luận bằng cách sử dụng clustering [31]. Công trình được thảo luận ở đây cho học liên tục đối với transformer dựa trên các biến thể của điều chỉnh prompt hoặc prefix-tuning [16]. Ngoài ra, S-Prompts chủ yếu được chứng minh hoạt động cho các kịch bản tăng dần theo miền.

Phương pháp của chúng tôi, CoLoR, mở rộng dòng công trình này bằng cách sử dụng các mô-đun LoRA, giữ lại tính đơn giản của S-Prompts, và hiệu quả trong cả kịch bản học tăng dần theo miền và theo tác vụ.

Phụ lục B Vision Transformer
Trong phần này, chúng tôi mô tả Vision Transformer [6] (ViT) mà chúng tôi sử dụng trong bài báo này. ViT nhận một ảnh I∈RW×H×3, và đầu tiên trích xuất các patch có kích thước P×P, tổng cộng W×H/P2 patch cho mỗi ảnh. Mỗi patch này được làm phẳng và nhúng vào không gian D chiều. Với điều này, một mã hóa vị trí đã học (Epos) được thêm vào, và một token đặc biệt gọi là token phân loại ([CLS]) được nối vào. Chúng tôi gọi điều này là X0∈RN×D trong đó N=W×H/P2+ 1. Phép toán này có thể được biểu diễn như

X0= [[CLS];I1pE;···I(N−1)pE]+Epos. (1)

Biểu diễn đặc trưng này được xử lý qua L lớp các lớp attention tự đa đầu.

Xal=MHSA(Xl−1)+Xl−1
Xl=FFN(Xal)+Xal} ∀l= 1...L

Hàm MHSA bao gồm nhiều mô-đun SA hoạt động song song. Mỗi mô-đun SA có thể được viết như

SA(Xl) = softmax(XlWlQWlKTXTl/√d)XlWV (2)

và FFN như

FFN(Xl) =GeLU(Wl2GeLU(Wl1Xl+bl1)+bl2). (3)

Token [CLS] tại XL được đưa vào một lớp tuyến tính RD→RC xuất ra logit cho phân loại. Tập hợp các tham số có thể huấn luyện cho tinh chỉnh là {Wl*,bl*}Ll=1.

--- TRANG 9 ---
Phụ lục C Siêu tham số huấn luyện
Chúng tôi tuân theo chặt chẽ giao thức của công trình trước đây để cho phép so sánh công bằng [31]. Chúng tôi áp dụng tăng cường dữ liệu của họ bao gồm lật ngang đơn giản và cắt ngẫu nhiên. Chúng tôi sử dụng kích thước batch là 128 và weight decay là 0.0002. Chúng tôi đặt learning rate và epoch để giảm thiểu ngân sách huấn luyện. Trong hầu hết các trường hợp, chúng tôi sử dụng 50 epoch ngoại trừ CORe50 nơi chúng tôi sử dụng 20. Mặc định, chúng tôi sử dụng learning rate là 10−3. Đối với CIFAR-100, chúng tôi sử dụng 0.01, đối với CORe50, 0.02. Cosine annealing được sử dụng để giảm learning rate theo thời gian. Trừ khi được nêu khác, chúng tôi sử dụng hạng LoRA là 64. Chúng tôi đặt số lượng cụm thành k= 5 như khuyến nghị cho S-Prompts [31] trong DIL. Đối với CIL, chúng tôi đặt số lượng cụm thành hai lần số lượng lớp mới, tức là 20 cho Split CIFAR-100. Việc lựa chọn số lượng cụm và hạng được nghiên cứu trong § 3 và Phụ lục E.

Phụ lục D Kết quả
Trong phần này, chúng tôi mở rộng kết quả trong Hình 1 và 2 bằng cách so sánh CoLoR với các phương pháp dựa trên replay trong Bảng 3 và 4.

Đối với kịch bản tăng dần theo miền được trình bày trong Bảng 3, chúng tôi quan sát thấy rằng CoLoR vượt trội hơn phương pháp replay với kích thước buffer hạn chế trên hầu hết các tập dữ liệu. Trên DomainNet, hiệu suất của CoLoR chỉ được so sánh bởi DyTox sử dụng buffer replay.

Trong Bảng 4, chúng tôi trình bày kết quả chi tiết cho Split CIFAR-100. Đối với tinh chỉnh, chúng tôi tinh chỉnh toàn bộ mô hình ViT và che các đầu ra cho các lớp không có trong một bản cập nhật bằng cách đặt những logit đó thành −∞. Chúng tôi thấy rằng điều này quan trọng đối với L2P, mà không có điều này hiệu suất của nó sẽ giảm mạnh. Sử dụng "class-masking", kết quả tinh chỉnh trong Bảng 4 cao hơn đáng kể so với những kết quả được báo cáo trong tài liệu như FT-seq và FT-seq-frozen. Hơn nữa, chúng tôi báo cáo kết quả thu được khi huấn luyện ViT trên tất cả dữ liệu sử dụng LoRA, và tinh chỉnh toàn bộ mô hình như cận trên.

Bảng 3: Kết quả độ chính xác trung bình trên ba benchmark tăng dần theo miền. CoLoR liên tục vượt trội hơn các cách tiếp cận thay thế ngay cả khi chúng có quyền truy cập vào dữ liệu trước đó. Điều này bao gồm cận trên tự báo cáo cho S-Prompts có quyền truy cập vào tất cả dữ liệu. Kết quả được đánh dấu † từ [33], và với ‡ từ [31].

Phương pháp Kích thước Buffer CORe50 DomainNet
S-Prompts (cận trên)∞84.01‡63.22‡
LoRA (r= 64) 96.15 ±0.07 73.62±0.02
DyTox [7]
50/lớp79.21‡±0.10 62.94‡
ER [3] 80.10†±0.56 -
GDumb [24] 74.92†±0.25 -
BiC [35] 79.28†±0.30 -
DER++ [1] 79.70†±0.44 -
Co2L [2] 79.75†±0.84 -
L2P [33] 81.07†±0.13 -
EWC [14]
074.82†±0.60 47.62‡
LwF [17] 75.45†±0.40 49.19‡
L2P [33] 78.33†±0.06 40.15‡
S-Prompts [31] (k= 5) 83.13‡±0.51 50.62‡
CoLoR (r= 1, k= 5) 84.88 ±0.10 67.71±0.08
CoLoR (r= 8, k= 5) 85.72 ±0.48 68.87±0.04
CoLoR (r= 64, k= 5) 85.52 ±0.42 69.67±0.04
CoLoR++ (r= 64, k= 5) 86.75±0.40 70.06±0.05

--- TRANG 10 ---
Bảng 4: Học tăng dần theo lớp trên CIFAR-100. CoLoR vượt trội hơn S-Prompts và CoLoR++ vượt trội hơn tất cả các phương pháp học liên tục khác. Điều này bao gồm cận trên tự báo cáo cho L2P. Kết quả được đánh dấu * được lấy từ [33]. Chúng tôi báo cáo kết quả mới cho huấn luyện trên tất cả dữ liệu sử dụng LoRA và tinh chỉnh đầy đủ.

Phương pháp Kích thước Buffer Split CIFAR-100
Độ chính xác trung bình (↑) Quên (↓)
L2P (cận trên)
∞90.85*±0.12 N/A
LoRA (r= 64) 92.49 ±0.07 N/A
Fine-Tuning 92.11 ±0.10 N/A
ER [3]
50/lớp82.53*±0.17 16.46*±0.25
GDumb [24] 81.67* ±0.02 N/A
BiC [35] 81.42* ±0.85 17.31*±1.02
DER++ [1] 83.94* ±0.34 14.55*±0.73
Co2L [2] 82.49* ±0.89 17.48*±1.80
L2P-R [33] 86.31* ±0.59 5.83*±0.61
ER [3]
10/lớp67.87*±0.57 33.33*±1.28
GDumb [24] 67.14* ±0.37 N/A
BiC [35] 66.11* ±1.76 35.24*±1.64
DER++ [1] 61.06* ±0.87 39.87*±0.99
Co2L [2] 72.15* ±1.32 28.55*±1.56
L2P-R [33] 84.21* ±0.53 7.72*±0.77
FT-seq-frozen
017.72*±0.34 59.09*±0.25
FT-seq 33.61* ±0.85 86.87*±0.20
FT+class masking 67.02 ±4.20 24.37±3.76
EWC [14] 47.01* ±0.29 33.27*±1.17
LwF [17] 60.69* ±0.63 27.77*±2.17
L2P [33] 83.83* ±0.04 7.63*±0.30
S-Prompts [31] (k= 5) 57.17 ±1.57 19.56±0.86
S-Prompts [31] (k= 10) 65.71 ±1.50 14.76±0.75
S-Prompts [31] (k= 20) 67.31 ±1.34 12.47±1.49
CoLoR (r= 64, k= 5) 59.98 ±0.04 18.69±0.41
CoLoR (r= 64, k= 10) 68.51 ±0.23 10.65±0.04
CoLoR (r= 1, k= 20) 70.87 ±0.23 10.16±0.19
CoLoR (r= 8, k= 20) 71.22 ±0.11 10.22±0.18
CoLoR (r= 64, k= 20) 71.42 ±0.24 10.27±0.39
CoLoR++ (r= 1, k= 20) 85.27 ±0.24 6.55±0.46
CoLoR++ (r= 64, k= 20) 86.47±0.07 6.25±0.34

Phụ lục E Nghiên cứu tách biệt
Trong phần này, chúng tôi nghiên cứu ảnh hưởng của số lượng cụm k đến độ chính xác trung bình. Chúng tôi thay đổi k bằng cách cố định tất cả các siêu tham số khác theo mặc định được mô tả trong Phụ lục C.

Trong Hình 4, chúng tôi quan sát thấy một hành vi tương tự như việc tăng hạng trong Hình 3 đối với số lượng cụm: nhiều hơn mang lại kết quả tốt hơn cho CIL, nơi việc chọn một số lượng cụm đủ lớn dẫn đến sự gia tăng đáng kể trong hiệu suất. Lợi ích của việc tăng k tiếp tục giảm rất nhanh. Điều này không đáng ngạc nhiên vì trong kịch bản này, các cụm đại diện cho các lớp riêng lẻ. Do đó, nếu k nhỏ hơn số lượng lớp trong một bản cập nhật (trong trường hợp này là 10), các centroid không thể biểu diễn tập dữ liệu đầy đủ gây ra lỗi phát hiện tập dữ liệu. Điều này được thể hiện rõ ràng bằng sự bão hòa mà chúng tôi đạt được khi k đạt đến số lượng lớp mới. Chúng tôi thấy rằng việc lựa chọn k không quá nhạy cảm; trên một ngưỡng nhỏ nhất định, việc lựa chọn của nó có ảnh hưởng tương đối ít đến kết quả. Việc tối ưu hóa nó tương đối rẻ vì không yêu cầu huấn luyện lại mô hình.

--- TRANG 11 ---
100101102
Số lượng cụm k506070Độ chính xác trung bình S-Prompts (k= 20)Split CIFAR-100

Hình 4: Tăng số lượng cụm mà không thay đổi bất kỳ cài đặt nào khác. Điều này cải thiện đáng kể hiệu suất trong CIL (Split CIFAR-100) cho đến khi k bằng số lượng lớp mới.

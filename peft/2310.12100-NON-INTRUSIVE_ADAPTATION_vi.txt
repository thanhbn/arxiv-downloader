# NON-INTRUSIVE ADAPTATION:
INPUT-CENTRIC PARAMETER-EFFICIENT FINE-TUNING
FOR VERSATILE MULTIMODAL MODELING

THÍCH ỨNG KHÔNG XÂM NHẬP:
TINH CHỈNH HIỆU QUẢ THAM SỐ HƯỚNG VÀO ĐẦU VÀO
CHO MÔ HÌNH ĐA PHƯƠNG THỨC LINH HOẠT

Yaqing Wang∗, Jialin Wu∗, Tanmaya Dabral, Jiageng Zhang, Geoff Brown,
Chun-Ta Lu, Frederick Liu, Yi Liang, Bo Pang, Michael Bendersky, Radu Soricut
Google
{yaqingwang, jialinwu, tanmayad, jiageng, geoffbrown, chunta,
frederickliu, yiliang, bopang, bemike, rsoricut }@google.com

TÓM TẮT
Các mô hình ngôn ngữ lớn (LLM) và mô hình ngôn ngữ thị giác (VLM) thể hiện hiệu suất xuất sắc trên nhiều loại tác vụ bằng cách mở rộng số lượng tham số từ mức O(109) đến O(1012) và hơn thế nữa. Những quy mô lớn này khiến việc thích ứng và triển khai các mô hình chuyên biệt hoàn toàn cho một tác vụ quan tâm trở nên bất khả thi. Tinh chỉnh hiệu quả tham số (PEFT) nổi lên như một hướng đi hứa hẹn để giải quyết các thách thức thích ứng và phục vụ cho những mô hình lớn như vậy. Chúng tôi phân loại các kỹ thuật PEFT thành hai loại: xâm nhập và không xâm nhập. Các kỹ thuật PEFT xâm nhập thay đổi trực tiếp kiến trúc bên trong của mô hình. Mặc dù linh hoạt hơn, chúng tạo ra những phức tạp đáng kể cho việc huấn luyện và phục vụ. Các kỹ thuật PEFT không xâm nhập để nguyên kiến trúc bên trong và chỉ thích ứng các tham số bên ngoài mô hình, chẳng hạn như embeddings cho đầu vào. Trong công trình này, chúng tôi mô tả AdaLink như một kỹ thuật PEFT không xâm nhập đạt được hiệu suất cạnh tranh so với PEFT xâm nhập tiên tiến (LoRA) và tinh chỉnh toàn bộ mô hình (FT) trên các tác vụ khác nhau. Chúng tôi đánh giá bằng cách sử dụng cả tác vụ chỉ văn bản và đa phương thức, với các thí nghiệm tính đến cả việc mở rộng số lượng tham số và chế độ huấn luyện (có và không có tinh chỉnh hướng dẫn).

1 GIỚI THIỆU
Trong khi các mô hình ngôn ngữ lớn (LLM) (Vaswani et al., 2017; Raffel et al., 2020; Brown et al., 2020; Chowdhery et al., 2022; OpenAI, 2023; Anil et al., 2023) và mô hình ngôn ngữ-thị giác (VLM) (Alayrac et al., 2022; Li et al., 2023; Wang et al., 2022a; Chen et al., 2023b) gần đây đã chứng minh khả năng đáng chú ý trên nhiều tác vụ khác nhau, vẫn tồn tại một số thách thức. Do chi phí kỹ thuật đắt đỏ và sự kém hiệu quả liên quan đến việc duy trì các mô hình riêng biệt cho các tác vụ khác nhau, vẫn còn là một câu hỏi mở về cách thích ứng những mô hình này cho các trường hợp sử dụng chuyên biệt khác nhau để kết hợp thông tin mới nhất. Do đó, có một xu hướng hướng tới tinh chỉnh hiệu quả tham số (PEFT) như một giải pháp đầy hứa hẹn cho những thách thức này, cung cấp sự cân bằng giữa khả năng thích ứng và hiệu quả. Các kỹ thuật PEFT, như adapters (Houlsby et al., 2019; Pfeiffer et al., 2020, 2021), LoRA (Hu et al., 2021), và prompt tuning (Lester et al., 2021b; Liu et al., 2021), chỉ giới thiệu một tỷ lệ nhỏ các tham số bổ sung để tinh chỉnh trong khi để nguyên phần lớn tham số của LLM. Trong khuôn khổ này, chúng tôi phân biệt giữa các phương pháp PEFT xâm nhập và không xâm nhập dựa trên mức độ mà chúng tương tác với hoặc thay đổi kiến trúc cốt lõi của LLM, như các khối transformer.

Các phương pháp thích ứng xâm nhập, bao gồm LoRA (Hu et al., 2021), Adapter (Pfeiffer et al., 2021; Beck et al., 2021), prefix-tuning (Li & Liang, 2021) và các phương pháp kết hợp của chúng (Chen et al., 2023a; Mao et al., 2021), tạo ra những thay đổi trực tiếp đối với kiến trúc mô hình hoặc các tham số bên trong một cách linh hoạt, sửa đổi các lớp hiện có và thêm các lớp mới. Trong khi cung cấp sức mạnh biểu đạt mạnh mẽ thông qua tính linh hoạt và có khả năng giảm khoảng cách hiệu suất tương tự như tinh chỉnh toàn bộ mô hình, chúng tạo ra những phức tạp đáng kể trong không gian thiết kế kiến trúc và cơ sở hạ tầng phục vụ. Hơn nữa, những thay đổi kiến trúc cốt lõi này thường dẫn đến các vấn đề tương thích và làm phức tạp việc kỹ thuật cần thiết để triển khai một LLM duy nhất được trang bị nhiều thành phần thích ứng. Những phức tạp như vậy cũng làm tăng khả năng xảy ra các hành vi không mong muốn, ví dụ, có khả năng tải trọng số thích ứng không chính xác cho các tác vụ hoặc lớp khác nhau, do đó làm cho việc xác thực và kiểm tra mở rộng càng trở nên bắt buộc để đảm bảo độ tin cậy của mô hình.

Ngược lại, các chiến lược thích ứng không xâm nhập như prompt-tuning (Lester et al., 2021b) nhằm điều chỉnh hành vi của mô hình với những thay đổi tối thiểu đối với kiến trúc bên trong hoặc các tham số thường đạt được bằng cách sửa đổi đầu vào cho kiến trúc cốt lõi. Chúng thường cho phép người dùng thực hiện những thay đổi chi tiết ở mức đầu vào cho mỗi ví dụ trong cùng một batch. Kết quả là, mô hình vẫn linh hoạt và có thể thích ứng với các nhu cầu tùy chỉnh khác nhau. Tuy nhiên, các phương pháp Tinh chỉnh Hiệu quả Tham số (PEFT) không xâm nhập như prompt-tuning đã gặp phải những thách thức tối ưu hóa Razdaibiedina et al. (2023). Chúng thường kém hiệu quả hơn trong việc thích ứng mô hình cho các tác vụ phức tạp, như đa tác vụ (Wang et al., 2022c), và vẫn đang trong giai đoạn khám phá cho các môi trường đa phương thức, đặc biệt là trong việc bảo toàn vị trí của các token thị giác khi xử lý đầu vào hình ảnh. Hướng tới những thách thức này, chúng tôi giới thiệu một phương pháp mới gọi là AdaLink mà giới thiệu một mô-đun thích ứng được đặt giữa embedding và các khối transformer chính của LLM dưới dạng một liên kết, giữ lại các lợi ích không xâm nhập và giảm bớt những khó khăn tối ưu hóa.

Công trình gần đây (Wei et al., 2021; Sanh et al., 2021; Mishra et al., 2022; Touvron et al., 2023) đã chứng minh khả năng của các mô hình ngôn ngữ lớn (LLM) để có được nhiều kỹ năng khác nhau và khái quát hóa tốt cho các tác vụ chưa thấy thông qua tinh chỉnh hướng dẫn. Trong bài báo này, chúng tôi khám phá việc thích ứng cả LLM thô và được tinh chỉnh hướng dẫn sử dụng tinh chỉnh hiệu quả tham số (PEFT). Chúng tôi thấy rằng việc bắt đầu từ một checkpoint được tinh chỉnh hướng dẫn giảm lượng tham số thích ứng cần thiết, tạo điều kiện thuận lợi cho quá trình huấn luyện thích ứng và cải thiện kết quả hơn nữa. Sự kết hợp của tinh chỉnh hướng dẫn và PEFT mở ra tiềm năng đáng kể, đạt được hiệu suất ngang bằng với tinh chỉnh toàn bộ mô hình trên các tác vụ văn bản và đa phương thức đa dạng. Khi các LLM được tinh chỉnh hướng dẫn tiếp tục trở nên phổ biến, các phương pháp PEFT không xâm nhập như AdaLink được đề xuất ở đây đủ để có được hiệu suất tối ưu và nổi lên như một phương pháp tinh chỉnh thực tế và hiệu quả. Theo kinh nghiệm, chúng tôi đã tiến hành các thí nghiệm toàn diện về các tác vụ đa phương thức (chú thích và VQA) và tác vụ hiểu ngôn ngữ tự nhiên. Bằng cách chỉ tinh chỉnh ít hơn 0,02% tham số của mô hình ngôn ngữ được huấn luyện trước, AdaLink đạt được kết quả cạnh tranh hoặc thậm chí tốt hơn so với các phương pháp tinh chỉnh toàn bộ mô hình.

Tính chất của AdaLink. AdaLink cho phép thích ứng hiệu quả và có thể mở rộng thông qua thiết kế mô-đun nhẹ nhưng biểu cảm của nó. Độ phức tạp tính toán được thêm vào chỉ tăng tuyến tính với chiều embedding của mô hình, bất biến với các tham số mô hình khác. Điều này tránh được việc mở rộng bậc hai gây ra bởi các phương pháp như prompt tuning làm tăng độ dài chuỗi. Hơn nữa, AdaLink cung cấp khả năng thích ứng đầu vào từng phần linh hoạt, chuyển đổi chỉ các embeddings được chọn để giảm thiểu sự can thiệp giữa các phương thức hoặc tác vụ. Bản chất mô-đun cũng cho phép phục vụ có thể cấu hình, cho phép AdaLink hoạt động như một đơn vị xử lý trung gian hoặc chuyển đổi trực tiếp embeddings từ vựng. Nhìn chung, AdaLink cung cấp khả năng thích ứng tác vụ có thể tùy chỉnh và mở rộng trong khi hạn chế chi phí phức tạp và bảo toàn kiến trúc mô hình, khiến nó rất hứa hẹn cho việc triển khai quy mô lớn.

2 BỐI CẢNH
Prompt tuning. Cho một mô hình ngôn ngữ được huấn luyện trước với tham số Θ và một tác vụ mục tiêu, tinh chỉnh toàn bộ mô hình có thể kém hiệu quả tham số cho nhiều tác vụ. Prompt tuning (PT) cung cấp một phương án thay thế hiệu quả hơn và không xâm nhập bằng cách khởi tạo một số vector prompt có thể học được và nối chúng vào embeddings đầu vào mà không chạm vào Θ (Lester et al., 2021a) và kiến trúc transformer. Phương pháp này tối ưu hóa một hàm mất mát đối với các vector prompt và đã được chứng minh là hiệu quả. Mặc dù prompt tuning không xâm nhập và dễ triển khai, nó vẫn gặp phải khoảng cách hiệu suất lớn trong các cài đặt đa tác vụ (Wang et al., 2022c) và sự nhạy cảm với việc khởi tạo (Lester et al., 2021a; Su et al., 2022; Zhong et al., 2022).

Adapter và LoRA. Thay vào đó, adapters (Houlsby et al., 2019) và LoRA (Hu et al., 2021) có thể được sử dụng để thích ứng LLM cho các tác vụ hạ nguồn với một số lượng nhỏ tham số bổ sung. Những chiến lược tinh chỉnh này giới thiệu các tham số mới vào LLM theo cách xâm nhập. Trong quá trình tinh chỉnh, các tham số mới được cập nhật với các tham số LLM gốc được giữ đóng băng. Adapters và LoRA thường bao gồm hai lớp được kết nối đầy đủ. Ví dụ, xem hình minh họa của adapter như được hiển thị bên phải.

Lớp adapter sử dụng một phép chiếu xuống Wdown∈ Rd×r để chiếu biểu diễn đầu vào x từ chiều mô hình d đến một không gian chiều thấp r (được gọi là chiều cổ chai), theo sau bởi một hàm kích hoạt phi tuyến f(·), và một phép chiếu lên với Wup∈ Rr×d để chiếu các đặc trưng chiều thấp trở lại chiều ban đầu.

3 PHƯƠNG PHÁP LUẬN
3.1 BIỂU DIỄN ĐẦU VÀO
Biểu diễn Văn bản. Đối với biểu diễn văn bản, chúng tôi theo T5 (Raffel et al., 2020) để sử dụng SentencePiece cho việc token hóa, điều này phân chia văn bản đầu vào thành các đơn vị từ phụ. Gọi T = {t1, t2, ..., tn} đại diện cho văn bản đầu vào, trong đó ti là token thứ i và n là độ dài của văn bản. Đầu vào được token hóa được truyền qua một lớp embedding để chuyển đổi thành các vector liên tục. Chính thức, điều này có thể được biểu diễn như Etext = {e1, e2, ..., en}, trong đó ei biểu thị embedding của token ti.

Biểu diễn Hình ảnh. Đối với biểu diễn hình ảnh, chúng tôi theo PaLI (Chen et al., 2023b) để sử dụng mô-đun ViT để tạo ra embeddings thị giác. Mỗi hình ảnh được thay đổi kích thước đến một kích thước cố định và sau đó được phân vùng thành các patches không chồng chéo với kích thước patch 14×14. Chúng tôi làm phẳng các patch-embeddings đầu ra từ mô-đun ViT làm biểu diễn hình ảnh Eimage.

Biểu diễn Hình ảnh-Văn bản. Embeddings thị giác và embeddings văn bản được nối để tạo thành chuỗi đầu vào đa phương thức: E = {Eimage, Etext}.

3.2 MÔ-ĐUN ADALINK
Về bản chất, AdaLink được thiết kế xung quanh khái niệm kết hợp một hàm biến đổi như liên kết giữa lớp embedding và các khối transformer chính. Lớp được thêm này phục vụ như một cơ chế cho việc thích ứng tinh tế. Quá trình bắt đầu với việc dữ liệu được chuyển đổi thành embeddings thông qua lớp embedding hoặc các mô-đun thị giác. Những embeddings này sau đó được truyền qua các Mô-đun AdaLink, dẫn đến việc biến đổi các đầu vào được chọn. Những đầu vào được biến đổi này sau đó được đưa vào các khối transformer chính đã đóng băng để xử lý thêm. Đáng ngạc nhiên, chúng tôi thấy rằng một cấu trúc adapter với hai lớp được kết nối đầy đủ khá hiệu quả theo kinh nghiệm. Phương pháp này cho phép chúng tôi đạt được kết quả cạnh tranh mà không thêm độ phức tạp đáng kể, và nó duy trì một số tính chất có lợi như độ phức tạp có thể mở rộng và các chiến lược triển khai linh hoạt mà chúng tôi sẽ thảo luận chi tiết hơn trong các phần tiếp theo.

Một cách chính thức hơn, chúng tôi theo ký hiệu từ Phần 2 để mô tả AdaLink, bao gồm hai lớp được kết nối đầy đủ. Phép chiếu xuống Wdown∈ Rdemb×r chiếu biểu diễn đầu vào từ chiều mô hình gốc demb đến một không gian chiều thấp r (được gọi là chiều cổ chai); phép chiếu lên với Wup∈ Rr×demb chiếu các đặc trưng chiều thấp trở lại chiều embedding ban đầu. AdaLink có tính linh hoạt để được sử dụng như một mô-đun thích ứng độc lập trên cơ sở mỗi tác vụ hoặc trên cơ sở mỗi phương thức. Chúng tôi giới thiệu hai kịch bản này như sau và để các cài đặt tiềm năng khác cho nghiên cứu tương lai.

AdaLink Đa tác vụ. Các phương pháp tinh chỉnh hiệu quả tham số thông thường được đề xuất để thích ứng LLM cho các tác vụ khác nhau mà không tạo ra các bản sao đắt tiền của mô hình gốc và hiệu quả lưu trữ. AdaLink cũng cho phép tính linh hoạt trong mức độ chi tiết của việc thích ứng tác vụ. Ví dụ, trong các kịch bản học đa tác vụ, người ta có thể liên kết một mô-đun AdaLink riêng biệt với mỗi tác vụ. Trong quá trình huấn luyện, các embeddings đầu vào được chuyển đổi một cách có chọn lọc bởi AdaLink cụ thể cho tác vụ trước khi đi qua backbone transformer được chia sẻ. Điều này nhắm mục tiêu thích ứng với các sắc thái của mỗi tác vụ trong khi cho phép chuyển giao kiến thức tích cực thông qua các tham số được chia sẻ. Tại thời điểm suy luận, mô hình định tuyến các đầu vào qua mô-đun AdaLink của tác vụ tương ứng để gợi ra hành vi thích ứng cho tác vụ đó. Phần còn lại của mô hình vẫn không thay đổi, tránh sự can thiệp tiêu cực. So với LoRA và Adapter, AdaLink không yêu cầu sửa đổi kiến trúc và giảm thêm tải trọng kỹ thuật mở rộng các chức năng của LLM khi triển khai. So với prompt tuning, AdaLink không tạo ra chi phí bổ sung cho các khối transformer với các token mới.

AdaLink Đa phương thức. Ngoài việc thích ứng theo tác vụ, AdaLink cũng cho phép thích ứng linh hoạt theo phương thức trong các cài đặt đa phương thức. Đối với các mô hình nhận các loại đầu vào không đồng nhất như văn bản, hình ảnh, âm thanh, v.v., người ta có thể liên kết một mô-đun AdaLink riêng biệt với mỗi phương thức. Trong quá trình huấn luyện và suy luận, các embeddings cho mỗi phương thức được chuyển đổi một cách có chọn lọc bởi AdaLink tương ứng của chúng trước khi hợp nhất. Một lợi ích chính là việc thích ứng cụ thể cho phương thức này cô lập sự can thiệp giữa các phương thức. Nó cũng cho phép các biểu diễn phương thức được xử lý một cách độc lập để có tính linh hoạt lớn hơn; ví dụ, lưu trữ chúng riêng biệt hoặc hợp nhất chúng ở các mức khác nhau. Một cách chính thức hơn, cho một đầu vào bao gồm một hình ảnh ximage và văn bản xtext, chúng tôi trước tiên thu được các biểu diễn cụ thể cho phương thức Eimage và Etext. Những biểu diễn này sau đó được đưa vào các mô-đun AdaLink riêng biệt để có được embeddings thích ứng

Ẽimage = Eimage + f(Eimage · Wdownimage) · Wupimage, (1)
Ẽtext = Etext + f(Etext · Wdowntext) · Wuptext, (2)

trong đó f chỉ hàm kích hoạt phi tuyến. Chúng tôi thấy rằng việc loại bỏ kích hoạt phi tuyến chỉ dẫn đến giảm hiệu suất không đáng kể, do đó chúng tôi loại bỏ nó để đơn giản. Các biểu diễn phương thức thích ứng Ẽimage và Ẽtext được nối để tạo thành biểu diễn kết hợp Ẽ = {Ẽimage, Ẽtext}. Ẽ này sau đó được truyền vào mô hình Transformer chính để xử lý thêm. Bằng cách biến đổi mỗi phương thức riêng biệt, AdaLink cung cấp khả năng thích ứng có mục tiêu trong khi cô lập sự can thiệp giữa các phương thức.

3.3 THẢO LUẬN VỀ CÁC TÍNH CHẤT CỦA ADALINK
Chi phí Tính toán Có thể Mở rộng. Xem xét rằng chúng ta có một đầu vào với độ dài chuỗi N, chiều embedding của LLM là demb và AdaLink với rank r, độ phức tạp được thêm vào là O(Ndembr). Độ phức tạp tính toán của AdaLink vẫn bất biến đối với việc mở rộng các lớp mô hình và tỷ lệ thuận tuyến tính với chiều embedding của LLM. Ngược lại, prompt tuning nối thêm embeddings bổ sung, do đó làm tăng độ dài chuỗi, dẫn đến sự gia tăng bậc hai trong độ phức tạp tính toán. Sự gia tăng độ phức tạp này có thể được làm trầm trọng thêm với việc mở rộng các mô hình ngôn ngữ lớn (LLM).

Can thiệp Tối thiểu. Một lợi ích chính của AdaLink là tính linh hoạt trong việc thích ứng với các đầu vào từng phần, chẳng hạn như một tập con các phương thức, mà không yêu cầu bất kỳ thay đổi nào đối với kiến trúc transformer chính. Việc thích ứng được đóng gói trong các mô-đun AdaLink nhẹ chuyển đổi các embeddings được chọn trước khi đưa vào các khối transformer tiêu chuẩn. Không giống như các phương pháp tiêm thêm các token mềm, AdaLink không sửa đổi các biểu diễn đầu vào ban đầu. Điều này bảo toàn thông tin vị trí của các đầu vào như hình ảnh, nơi mà mối quan hệ không gian giữa các đối tượng là quan trọng. Bằng cách giới hạn việc thích ứng cho các mô-đun AdaLink, AdaLink cho phép dễ dàng thích ứng các LLM mạnh mẽ với các kịch bản mới.

Phục vụ Có thể Cấu hình. AdaLink có thể được triển khai như một đơn vị xử lý trung gian như được hiển thị trong Hình 1, mang theo độ phức tạp được thêm vào. Ngoài ra, nó có thể được sử dụng để chuyển đổi embeddings từ vựng. Theo cách này, trong khi độ phức tạp vẫn không đổi, có sự gia tăng liên quan trong yêu cầu lưu trữ do việc thêm lớp embedding.

4 THÍ NGHIỆM
4.1 THÍ NGHIỆM ĐA PHƯƠNG THỨC
Chúng tôi tiến hành thí nghiệm trên bốn tác vụ VQA và hai tác vụ chú thích hình ảnh sử dụng PaLI-X (Chen et al., 2023b), một mô hình nền tảng đa phương thức 55B đã đạt được kết quả SoTA trên một loạt các benchmark thị giác và ngôn ngữ. Chúng tôi chứng minh rằng PEFT không xâm nhập đạt được kết quả rất cạnh tranh so với tinh chỉnh toàn bộ mô hình cho một VLM quy mô lớn như PaLI-X, đặc biệt là trên một biến thể được tinh chỉnh hướng dẫn đa phương thức.

4.1.1 MÔ HÌNH CƠ SỞ
Checkpoint thô: Chúng tôi tham chiếu checkpoint PaLI-X được huấn luyện trước theo (Chen et al., 2023b) với độ phân giải 756×756 như checkpoint thô.

Biến thể MMIT: Chúng tôi cũng thí nghiệm với một biến thể tinh chỉnh hướng dẫn đa phương thức (MMIT), nơi chúng tôi tinh chỉnh checkpoint PaLI-X thô trên các tác vụ MMIT. Các tác vụ MMIT được tạo theo tinh thần của "Self-Instruct" (Wang et al., 2022b), tận dụng các mô hình ngôn ngữ lớn mạnh mẽ. Chúng tôi xem xét ba loại tác vụ: (i) Chú thích dài trong đó nhiều chú thích được tạo cho mỗi hình ảnh và LLM (Anil et al., 2023) được sử dụng để kết hợp và tóm tắt chúng thành một chú thích dài hơn và chi tiết hơn; (ii) Viết sáng tạo trong đó LLM trước tiên được sử dụng để tạo ra các lời nhắc viết sáng tạo mới và sau đó được sử dụng để tạo ra các tác phẩm viết thực tế dựa trên các lời nhắc dựa trên chú thích hình ảnh. (iii) Trả lời câu hỏi dài trong đó LLM được sử dụng để tạo ra câu hỏi và câu trả lời với lý do dựa trên chú thích hình ảnh. Lưu ý rằng những tác vụ này cùng nhau bao gồm một loạt các trường hợp sử dụng đa dạng có gốc rễ trong cuộc sống hàng ngày. Nhưng chúng cũng có tính chất chung theo nghĩa rằng chúng tôi không kỳ vọng chúng sẽ trực tiếp trong miền cho các tác vụ hạ nguồn được xem xét trong công việc này. Đặc biệt, chúng tôi thí nghiệm trên các tác vụ hạ nguồn yêu cầu các kỹ năng cụ thể như hiểu văn bản cảnh và tài liệu, hoặc trả lời các câu hỏi chuyên sâu về kiến thức.

4.1.2 CHI TIẾT THỰC HIỆN
Chúng tôi so sánh tinh chỉnh toàn bộ mô hình (FT) với ba loại PEFT: prompt tuning (PT) (Lester et al., 2021b), LoRA (Hu et al., 2021) và AdaLink. Chúng tôi sử dụng adafactor (Shazeer & Stern, 2018) làm optimizer. Tốc độ học được đặt thành 0,03 cho PEFT và 0,0001 cho tinh chỉnh với warmup tuyến tính và phân rã căn bậc hai nghịch đảo trừ khi được chỉ định khác. Theo mặc định, chúng tôi đặt tỷ lệ dropout là 0,1 để ngăn overfitting.

Tinh chỉnh. Nhớ lại rằng PaLI-X tuân theo kiến trúc encoder-decoder trong đó embeddings hình ảnh được tạo ra bởi mô-đun ViT, cùng với embeddings văn bản, được đưa vào encoder đa phương thức như một chuỗi. Trong các thí nghiệm tinh chỉnh toàn bộ mô hình (FT), chúng tôi giữ mô-đun ViT đóng băng và chỉ tinh chỉnh backbone encoder-decoder.

LoRA. Chúng tôi thêm trọng số LoRA trên mỗi lớp tuyến tính trong khối attention đa đầu và khối MLP trong các khối transformer encoder cho cả mô hình cơ sở. Tương tự như (Yang et al., 2022), chúng tôi thấy rằng việc thêm trọng số LoRA trong decoder không giúp nhiều cho hiệu suất thích ứng với chi phí gấp đôi số lượng tham số. Chúng tôi sử dụng rank LoRA là 16 trong các thí nghiệm trên checkpoint thô và rank LoRA là 4 trong các thí nghiệm trên biến thể MMIT.

Prompt Tuning. Prompt Tuning (PT) được thực hiện bằng cách nối 64 token mềm có thể điều chỉnh với chuỗi đầu vào ban đầu, và đưa chuỗi được nối đó vào encoder đa phương thức của PaLI-X. Chúng tôi áp dụng hai lớp tái tham số hóa dư (Razdaibiedina et al., 2023) để có kết quả ổn định hơn. Chúng tôi sử dụng tỷ lệ dropout là 0,05 cho tất cả các thí nghiệm prompt tuning vì chúng tôi thấy nó vượt trội hơn tỷ lệ mặc định là 0,1.

AdaLink. Chúng tôi chèn các mô-đun AdaLink cụ thể cho phương thức vào embeddings của các token văn bản và token thị giác như một kỹ thuật PEFT không xâm nhập cho mô hình cơ sở. Chúng tôi sử dụng rank là 64 trong tất cả các thí nghiệm.

4.1.3 KẾT QUẢ CHÚ THÍCH HÌNH ẢNH
Bảng 1 báo cáo điểm CIDEr tinh chỉnh PEFT chú thích hình ảnh (Vedantam et al., 2015) trên COCO (Lin et al., 2014) và TextCaps (Sidorov et al., 2020). Trong họ PEFT không xâm nhập, AdaLink vượt trội hơn prompt tuning khoảng 2 điểm cider trung bình, cho thấy hiệu quả của việc trực tiếp thích ứng embeddings đầu vào.

Quan trọng hơn, chúng tôi quan sát thấy khoảng cách nhỏ hơn giữa AdaLink và FT trên biến thể MMIT so với checkpoint thô. Điều này phù hợp với giả thuyết của chúng tôi rằng AdaLink có thể hưởng lợi nhiều hơn từ các mô hình cơ sở được tinh chỉnh hướng dẫn, cho phép kết quả cạnh tranh với FT (trung bình chênh lệch 0,65). Thật ấn tượng khi AdaLink (1,05M tham số để tinh chỉnh) có thể đạt được trong vòng một điểm so với tinh chỉnh toàn bộ (32B tham số để tinh chỉnh). Thật vậy, với số lượng tham số có thể điều chỉnh nhỏ hơn nhiều, PEFT không xâm nhập có thể gặp phải sức mạnh biểu đạt kém hơn. Điều này có lẽ ít trở thành vấn đề hơn với sức mạnh biểu đạt trong chính các mô hình cơ sở quy mô lớn (như PaLI-X), và một phần được giảm thiểu thêm khi các mô hình cơ sở được huấn luyện trước trên nhiều tác vụ đa dạng hơn (ví dụ, biến thể MMIT trong các thí nghiệm của chúng tôi). Cũng lưu ý: trong khi PaLI-X cung cấp một mô hình cơ sở rất mạnh, với kết quả tinh chỉnh SoTA trên một loạt benchmark rộng, nó không mạnh đến mức hiệu suất này có thể dễ dàng đạt được với việc tinh chỉnh bằng không. Như một điểm tham chiếu, trên cùng tác vụ COCO Captions, Chen et al. (2023b) đã báo cáo điểm CIDEr là 107,6 cho 4-shots và 114,5 cho 32-shots learning, chênh lệch hơn 30 điểm so với FT. Do đó, việc đạt được hiệu suất FT SoTA với kỹ thuật tinh chỉnh nhẹ như AdaLink là không tầm thường.

Trong khi LoRA cũng có được hiệu suất tốt hơn trên biến thể MMIT, khoảng cách hiệu suất giữa AdaLink và LoRA cũng nhỏ hơn trên biến thể này. Với sự phổ biến ngày càng tăng của các LLM được tinh chỉnh hướng dẫn, PEFT không xâm nhập, đặc biệt là AdaLink, trở thành một ứng cử viên mạnh mẽ với độ phức tạp thấp hơn đáng kể trong kiến trúc và cơ sở hạ tầng phục vụ với chi phí suy giảm hiệu suất rất nhỏ. Khi các tác vụ tinh chỉnh hướng dẫn đa phương thức trở nên toàn diện và đa dạng hơn, chúng tôi giả định có thể có khoảng cách hiệu suất thậm chí nhỏ hơn giữa phương pháp PEFT không xâm nhập đơn giản như AdaLink và PEFT xâm nhập hoặc tinh chỉnh toàn bộ mô hình. Trong trường hợp tăng kích thước mô hình cơ sở, độ phức tạp của các phương pháp PEFT không xâm nhập như AdaLink không tăng theo độ sâu của các mô hình đang phát triển, thể hiện một lợi thế rõ ràng khác về mặt thực tế.

Tiếp theo, chúng tôi trình bày các nghiên cứu ablation bổ sung trên COCO Captions, một lần nữa báo cáo kết quả trên phần test Karpathy.

Hiệu ứng của rank. Bảng 2 báo cáo các hiệu ứng của việc thay đổi rank trong AdaLink sử dụng biến thể MMIT. Chúng tôi quan sát thấy rằng hiệu suất không quá nhạy cảm với rank, cho thấy sự ổn định của AdaLink. Ngay cả rank 4 cũng có thể giúp mô hình thích ứng đến hiệu suất hợp lý, và hiệu suất bão hòa ở rank 64.

Hiệu ứng của việc sử dụng adapter riêng biệt cho hình ảnh và phương thức văn bản. Tiếp theo, chúng tôi so sánh AdaLink dựa trên phương thức mặc định với adapter riêng biệt cho hình ảnh và phương thức văn bản với baseline sử dụng một AdaLink thống nhất với rank 128 (gấp đôi so với AdaLink mặc định) để thích ứng cả token thị giác và văn bản. Bảng 3 trình bày hiệu suất của chúng trên chú thích COCO. Bất kể biến thể mô hình cơ sở nào được sử dụng, AdaLink dựa trên phương thức vượt trội hơn AdaLink thống nhất đơn lẻ khoảng 1 điểm CIDEr trong khi sử dụng cùng số lượng tham số bổ sung, định lượng lợi ích của mô hình hóa cụ thể cho phương thức, điều mà prompt tuning gặp khó khăn để đạt được.

4.1.4 KẾT QUẢ VQA
Trong Bảng 4, chúng tôi trình bày hiệu suất VQA sử dụng PEFT trên bốn tác vụ VQA: OK-VQA (Marino et al., 2019) yêu cầu sử dụng kiến thức bên ngoài, DocVQA (Mathew et al., 2021) xem xét khả năng hiểu tài liệu, và hai bộ dữ liệu hiểu văn bản cảnh — TextVQA (Singh et al., 2019) và ST-VQA (Biten et al., 2019). Chúng tôi tuân theo các metric đánh giá tiêu chuẩn, sử dụng độ chính xác mềm (Antol et al., 2015) cho OKVQA và TextVQA và điểm ANLS cho DocVQA và ST-VQA.

Như được hiển thị trong Bảng 4, việc tinh chỉnh biến thể MMIT nói chung dẫn đến hiệu suất tốt hơn so với việc tinh chỉnh checkpoint thô. Trên thực tế, khi sử dụng biến thể MMIT, sự khác biệt hiệu suất trung bình giữa các kỹ thuật tinh chỉnh khác nhau là không đáng kể, và AdaLink một lần nữa nổi lên như một lựa chọn xuất sắc do sự dễ dàng phục vụ và số lượng tham số thấp hơn, chỉ kém FT 0,05, lặp lại những gì chúng tôi đã thấy từ các thí nghiệm chú thích.

Đáng chú ý là cả ba phương pháp PEFT, cả xâm nhập và không xâm nhập, đều đạt được hiệu suất tốt hơn trên biến thể MMIT, khiến chúng cạnh tranh với FT. Điều này một lần nữa chỉ ra một xu hướng thú vị đang nổi lên: sức mạnh ngày càng tăng của LLM và VLM cho phép thích ứng PEFT nhẹ đạt được hiệu suất cạnh tranh cho các trường hợp sử dụng chuyên biệt cao; hơn nữa, điều này cũng cho phép các phương pháp PEFT không xâm nhập như AdaLink thực hiện cạnh tranh với các phương pháp xâm nhập.

4.2 THÍ NGHIỆM NGÔN NGỮ TỰ NHIÊN
Cài đặt thí nghiệm. Chúng tôi thực hiện thí nghiệm trên một loạt tác vụ bao gồm tám tác vụ hiểu ngôn ngữ tự nhiên (NLU) trong benchmark General Language Understanding Evaluation (GLUE) (Wang et al., 2019). Chúng tôi so sánh AdaLink với tinh chỉnh toàn bộ mô hình với các checkpoint khác nhau bao gồm checkpoint được tinh chỉnh hướng dẫn FLAN (Wei et al., 2021) và checkpoint T5 với các bước thích ứng bổ sung theo (Lester et al., 2021b). Trừ khi được chỉ định khác, tất cả các thí nghiệm trong công việc này sử dụng checkpoint T5 hoặc FLAN 11 tỷ tham số làm mô hình cơ sở.

Chi tiết thực hiện AdaLink. Chúng tôi thực hiện AdaLink trong Jax cho các thí nghiệm. AdaLink sử dụng chiều r là 4 và 256 với checkpoint FLAN và T5 trong cài đặt tác vụ đơn lẻ. Trong cài đặt đa tác vụ, chúng tôi tăng chiều lên 256 và 1024 cho checkpoint FLAN và T5 tương ứng. Chúng tôi thấy rằng hầu hết các tác vụ không nhạy cảm với rank của AdaLink và hiệu suất của AdaLink ổn định sau khi các mô-đun đạt được một kích thước nhất định. Việc tăng dung lượng vượt quá điểm này mang lại lợi ích giảm dần, với ít hoặc không có cải thiện nào được quan sát trong các metric tác vụ cuối. Tốc độ học được đặt thành 0,001 cho AdaLink. Theo mặc định, chúng tôi đặt tỷ lệ dropout là 0,1 để ngăn overfitting.

Tác vụ đơn lẻ. Bảng so sánh tinh chỉnh toàn bộ với việc sử dụng AdaLink để thích ứng checkpoint T5 và FLAN 11B cho các tác vụ GLUE riêng lẻ. Đối với tinh chỉnh toàn bộ, tất cả 11 tỷ tham số được tinh chỉnh trên mỗi tác vụ. Với AdaLink, chỉ các mô-đun adapter nhỏ với 0,5-0,008 triệu tham số được tinh chỉnh cho mỗi tác vụ. Chúng tôi quan sát thấy rằng AdaLink đạt được hiệu suất tương đương hoặc tốt hơn tinh chỉnh toàn bộ trên hầu hết các tác vụ, mặc dù tinh chỉnh ít tham số hơn nhiều. Ví dụ, với checkpoint FLAN, AdaLink đạt được độ chính xác cao hơn trên các benchmark SST-2, QQP, RTE và STS-B. Nhìn chung, AdaLink đạt được điểm GLUE trung bình tương tự như tinh chỉnh toàn bộ là 90,7 sử dụng FLAN, trong khi chỉ tinh chỉnh 0,008M tham số thích ứng cho mỗi tác vụ. Điều này chứng minh hiệu quả của AdaLink trong thích ứng tác vụ có mục tiêu cho các mô hình ngôn ngữ lớn. Kết quả xác nhận AdaLink như một phương pháp hiệu quả và hiệu suất để thích ứng các mô hình được huấn luyện trước cho các tác vụ riêng lẻ, mà không ảnh hưởng đến khả năng mô hình. Kiến trúc mô-đun cho phép mở rộng các tác vụ hoặc kiến thức mới mà không cần phải phát triển lại các mô hình chính, tương tự như việc thêm patches vào phần mềm trong quá trình thay đổi phiên bản.

Đa tác vụ. Công việc trước đây đã chỉ ra rằng các phương pháp prompt tuning có khó khăn tối ưu hóa khi được áp dụng cho nhiều tác vụ đồng thời (Wang et al., 2022c). Là một phương pháp hướng vào đầu vào tương tự như prompt tuning, việc khám phá khả năng và giới hạn của AdaLink trong cài đặt đa tác vụ có tính thông tin và có thể giúp tiết lộ tiềm năng của phương pháp mới này. AdaLink thể hiện khoảng cách nhỏ chỉ 1-2% so với tinh chỉnh toàn bộ và nó đạt được độ chính xác tương đương hoặc cao hơn so với tinh chỉnh toàn bộ trên 6 trong 8 tác vụ GLUE sử dụng checkpoint FLAN. Khoảng cách rõ ràng nhất là trên tác vụ CoLA thách thức yêu cầu thích ứng ngôn ngữ phức tạp. Tuy nhiên, hiệu suất mạnh mẽ của AdaLink trên hầu hết các benchmark cho thấy rằng tinh chỉnh cấp đầu vào có thể mô phỏng hiệu quả các hành vi cụ thể cho tác vụ.

Phân tích về rank. Các thí nghiệm của chúng tôi chứng minh rằng AdaLink không quá nhạy cảm với siêu tham số rank. Với checkpoint FLAN được tinh chỉnh hướng dẫn, rank nhỏ là 4 đạt được hiệu suất GLUE tối đa, cho thấy AdaLink compact đủ cho việc biến đổi không gian embedding. Việc tăng rank thêm cho thấy lợi ích không đáng kể, nhấn mạnh sự ổn định của kiến trúc AdaLink. Một rank lớn hơn cần thiết cho checkpoint T5 không chuyên biệt, nhưng hiệu suất ổn định nhanh chóng. Nhìn chung, AdaLink đạt được khả năng thích ứng mạnh mẽ với tham số hóa tối thiểu trên các khởi tạo đa dạng.

5 CÔNG TRÌNH LIÊN QUAN
Phạm vi rộng của khả năng đạt được bởi LLM (Raffel et al., 2020; Brown et al., 2020; Chowdhery et al., 2022; Anil et al., 2023) và VLM (Alayrac et al., 2022; Li et al., 2023; Wang et al., 2022a; Chen et al., 2023b) đi cùng với việc mở rộng số lượng tham số lên mức tỷ. Điều này ngăn cản các pipeline triển khai mô hình thông thường nơi các tác vụ khác nhau sở hữu các bản sao khác nhau của toàn bộ mô hình được phục vụ riêng biệt. Chúng tôi giới thiệu ngắn gọn hai phương tiện trong các phần sau để giải quyết vấn đề này.

5.1 TINH CHỈNH HƯỚNG DẪN
Tinh chỉnh hướng dẫn (Wei et al., 2021; Chung et al., 2022; Sanh et al., 2021; Wang et al., 2022b; Ouyang et al., 2022; Longpre et al., 2023) nhằm giải quyết một loạt các tác vụ sử dụng một mô hình nền tảng. Toàn bộ mô hình được tinh chỉnh trên một hỗn hợp lớn các hướng dẫn được xây dựng từ các tác vụ quan tâm. (Wei et al., 2021) khám phá việc kết hợp 62 bộ dữ liệu NLP với 10 hướng dẫn cho mỗi bộ làm dữ liệu huấn luyện. Chung et al. (2022) mở rộng phạm vi lên đến 1800 tác vụ. Các LLM chứng minh khả năng mạnh mẽ trong việc học nội suy các tác vụ được sử dụng và khái quát hóa tốt cho các tác vụ chưa thấy. Khi kích thước dữ liệu tinh chỉnh hướng dẫn thường bị hạn chế, nghiên cứu gần đây đề xuất "Self-Instruct" (Wang et al., 2022b) thu thập dữ liệu bằng cách tự bootstrapping từ các thế hệ của chính họ, giảm gánh nặng chú thích.

Tinh chỉnh Hướng dẫn Đa phương thức. Tương tự như tinh chỉnh hướng dẫn chỉ văn bản, Tinh chỉnh Hướng dẫn Đa phương thức (MMIT) nhằm học chung một bộ sưu tập lớn các tác vụ ngôn ngữ thị giác. Tuy nhiên, vì hầu hết các tác vụ ngôn ngữ-thị giác có sẵn là chú thích ngắn, hỏi-đáp và grounding cho các benchmark học thuật bị hạn chế về cả phạm vi thị giác (tức là các miền thị giác được bao phủ) và phạm vi tác vụ. Nhiều tác vụ đi chệch khỏi các trường hợp sử dụng tự nhiên như kể chuyện, tạo chú thích mô tả, trả lời câu hỏi với giải thích, v.v. Do đó, hầu hết MMIT (Liu et al., 2023; Zhang et al., 2023; Dai et al., 2023; Gao et al., 2023) dựa vào các giao thức "Self-Instruct" (Wang et al., 2022b) tạo ra các tác vụ huấn luyện tự động.

5.2 TINH CHỈNH HIỆU QUẢ THAM SỐ
Thay vì triển khai các mô hình đầy đủ chuyên biệt, nghiên cứu gần đây điều tra nhiều hơn về tinh chỉnh hiệu quả tham số (PEFT) chỉ thích ứng một phần nhỏ tham số, giữ hầu hết các tham số đóng băng. Chúng tôi phân loại các phương pháp PEFT thành các phương pháp xâm nhập và không xâm nhập.

PEFT xâm nhập tạo ra những thay đổi trực tiếp đối với kiến trúc mô hình, thường là đối với các khối transformer. Prompt tuning theo lớp (Liu et al., 2021) và LLaMA (Zhang et al., 2023) đặt trước các token có thể điều chỉnh vào đầu vào của các khối transformer. Adapters (Houlsby et al., 2019; Pfeiffer et al., 2020, 2021) chèn các MLP rank thấp trong mỗi khối. LoRA (Hu et al., 2021) đi xa hơn và thêm trọng số rank thấp trong mỗi lớp tuyến tính trong self-attention và MLP. Mặc dù các phương pháp PEFT xâm nhập cung cấp tính linh hoạt hơn trong thiết kế, chúng tạo ra những thách thức đáng kể trong triển khai mô hình nơi trọng số thích ứng cần được chuyển đến kiến trúc bên trong. Bên cạnh đó, kích thước của các tham số có thể điều chỉnh vẫn tăng tỷ lệ với kích thước mô hình.

PEFT không xâm nhập hướng vào đầu vào giữ các khối transformer cốt lõi đóng băng, bao gồm cả tham số được huấn luyện trước và đồ thị tính toán. Prompt tuning là ví dụ điển hình trong đó các token có thể điều chỉnh được đặt trước embeddings từ trước khi được đưa vào các khối transformer. Tuy nhiên, các thí nghiệm cho thấy rằng prompt tuning gặp khó khăn với các khó khăn tối ưu hóa Razdaibiedina et al. (2023), yêu cầu một số lượng lớn ví dụ huấn luyện. Chúng tôi đề xuất AdaLink thích ứng embeddings đầu vào sử dụng các MLP rank thấp, tận dụng lợi ích của "zero init" tránh sự rối loạn ở đầu quá trình huấn luyện. Chúng tôi chỉ ra rằng AdaLink đạt được kết quả cạnh tranh như tinh chỉnh toàn bộ mô hình với việc mở rộng kích thước mô hình.

6 KẾT LUẬN
Trong bài báo này, chúng tôi xem xét ảnh hưởng của việc mở rộng cả số lượng tham số mô hình và các tác vụ huấn luyện trước đến tinh chỉnh hiệu quả tham số (PEFT) trên cả tác vụ chỉ văn bản và tác vụ đa phương thức hạ nguồn. Chúng tôi chỉ ra rằng khoảng cách hiệu suất giữa tinh chỉnh toàn bộ mô hình và PEFT được thu hẹp đáng kể với sự giúp đỡ của cả hai. Điều này cho thấy các LLM và VLM ngày càng mạnh mẽ chỉ yêu cầu một chút thích ứng, và PEFT không xâm nhập hướng vào đầu vào thường đủ để có được hiệu suất tối ưu và tận hưởng sự dễ dàng triển khai và kích thước không đổi đối với độ sâu mô hình. Chúng tôi cũng giới thiệu AdaLink đạt được hiệu suất thích ứng tốt hơn so với prompt tuning trong họ PEFT không xâm nhập.

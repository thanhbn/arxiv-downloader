# LLAMA FACTORY: Tinh chỉnh hiệu quả thống nhất cho hơn 100 mô hình ngôn ngữ

Yaowei Zheng1, Richong Zhang1*, Junhao Zhang1, Yanhan Ye1,
Zheyan Luo1, Zhangchi Feng1, Yongqiang Ma2
1Khoa Khoa học Máy tính và Kỹ thuật, Đại học Beihang, Trung Quốc
2Khoa Phần mềm và Vi điện tử, Đại học Bắc Kinh, Trung Quốc
{hiyouga,zhang.jh,yeyanhan,akamya,zcmuller}@buaa.edu.cn ,zhangrc@act.buaa.edu.cn ,codingma@pku.edu.cn
Video demo: https://youtu.be/W29FgeZEpus

## Tóm tắt

Tinh chỉnh hiệu quả có vai trò quan trọng trong việc thích ứng các mô hình ngôn ngữ lớn (LLMs) với các tác vụ cụ thể. Tuy nhiên, việc triển khai các phương pháp này trên các mô hình khác nhau đòi hỏi nỗ lực đáng kể. Chúng tôi giới thiệu LLAMA FACTORY, một framework thống nhất tích hợp bộ công cụ các phương pháp huấn luyện hiệu quả tiên tiến. Nó cung cấp giải pháp để tùy chỉnh linh hoạt việc tinh chỉnh hơn 100 LLMs mà không cần lập trình thông qua giao diện web tích hợp LLAMA BOARD. Chúng tôi kiểm chứng thực nghiệm về hiệu quả và tính hiệu quả của framework trên các tác vụ mô hình hóa ngôn ngữ và sinh văn bản. Nó đã được phát hành tại https://github.com/hiyouga/LLaMA-Factory và nhận được hơn 25.000 sao và 3.000 fork.

## 1 Giới thiệu

Các mô hình ngôn ngữ lớn (LLMs) (Zhao et al., 2023) thể hiện khả năng lý luận đáng chú ý và hỗ trợ nhiều ứng dụng khác nhau như trả lời câu hỏi (Jiang et al., 2023b), dịch máy (Wang et al., 2023c; Jiao et al., 2023a), và trích xuất thông tin (Jiao et al., 2023b). Tiếp theo, một số lượng lớn LLMs được phát triển và có thể truy cập thông qua các cộng đồng mã nguồn mở. Ví dụ, bảng xếp hạng LLM mở của Hugging Face (Beeching et al., 2023) có hơn 5.000 mô hình, mang lại sự thuận tiện cho những cá nhân muốn tận dụng sức mạnh của LLMs.

Tinh chỉnh số lượng tham số cực lớn với tài nguyên hạn chế trở thành thách thức chính khi thích ứng LLM với các tác vụ cụ thể. Một giải pháp phổ biến là tinh chỉnh hiệu quả (Houlsby et al., 2019; Hu et al., 2022; Dettmers et al., 2023), giúp giảm chi phí huấn luyện LLMs khi thích ứng với các tác vụ khác nhau. Tuy nhiên, cộng đồng đóng góp nhiều phương pháp tinh chỉnh hiệu quả khác nhau, thiếu một framework hệ thống để thích ứng và thống nhất các phương pháp này cho các LLMs khác nhau và cung cấp giao diện thân thiện cho việc tùy chỉnh của người dùng.

Để giải quyết các vấn đề trên, chúng tôi phát triển LLAMA FACTORY, một framework dân chủ hóa việc tinh chỉnh LLMs. Nó thống nhất nhiều phương pháp tinh chỉnh hiệu quả thông qua các module có thể mở rộng, cho phép tinh chỉnh hàng trăm LLMs với tài nguyên tối thiểu và thông lượng cao. Ngoài ra, nó hợp lý hóa các phương pháp huấn luyện thường được sử dụng, bao gồm tiền huấn luyện sinh (Radford et al., 2018), tinh chỉnh có giám sát (SFT) (Wei et al., 2022), học tăng cường từ phản hồi con người (RLHF) (Ouyang et al., 2022), và tối ưu hóa sở thích trực tiếp (DPO) (Rafailov et al., 2023). Người dùng có thể tận dụng giao diện dòng lệnh hoặc web để tùy chỉnh và tinh chỉnh LLMs của họ với nỗ lực lập trình tối thiểu hoặc không cần lập trình.

LLAMA FACTORY bao gồm ba module chính: Model Loader, Data Worker và Trainer. Chúng tôi tối thiểu hóa sự phụ thuộc của các module này vào các mô hình và tập dữ liệu cụ thể, cho phép framework mở rộng linh hoạt đến hàng trăm mô hình và tập dữ liệu. Cụ thể, chúng tôi đầu tiên thiết lập một registry mô hình nơi Model Loader có thể đính kèm adapters chính xác vào các mô hình được tiền huấn luyện bằng cách xác định các lớp chính xác. Sau đó, chúng tôi phát triển một thông số mô tả dữ liệu cho phép Data Worker thu thập các tập dữ liệu bằng cách căn chỉnh các cột tương ứng. Hơn nữa, chúng tôi cung cấp các triển khai plug-and-play của các phương pháp tinh chỉnh hiệu quả tiên tiến cho phép Trainer kích hoạt bằng cách thay thế những phương pháp mặc định. Thiết kế của chúng tôi cho phép các module này được tái sử dụng qua các phương pháp huấn luyện khác nhau, giảm đáng kể chi phí tích hợp.

LLAMA FACTORY được triển khai với PyTorch (Paszke et al., 2019) và hưởng lợi đáng kể từ các thư viện mã nguồn mở như Transformers (Wolf et al., 2020), PEFT (Mangrulkar et al., 2022), và TRL (von Werra et al., 2020). Trên cơ sở đó, chúng tôi cung cấp một framework sẵn sàng sử dụng với mức độ trừu tượng cao hơn. Ngoài ra, chúng tôi xây dựng LLAMA BOARD với Gradio (Abid et al., 2019), cho phép tinh chỉnh LLMs mà không cần nỗ lực lập trình.

LLAMA FACTORY được phát hành mã nguồn mở dưới giấy phép Apache-2.0. Nó đã thu hút hơn 25.000 sao và 3.000 fork trên GitHub, và hàng trăm mô hình mã nguồn mở đã được xây dựng dựa trên LLAMA FACTORY trên Hugging Face Hub. Ví dụ, Truong et al. (2024) xây dựng GemSUra-7B dựa trên LLAMA FACTORY, tiết lộ khả năng đa ngôn ngữ của Gemma (Mesnard et al., 2024). Hơn nữa, hàng chục nghiên cứu đã sử dụng framework của chúng tôi để khám phá LLMs (Wang et al., 2023a; Yu et al., 2023; Bhardwaj et al., 2024).

## 2 Các nghiên cứu liên quan

Với sự gia tăng nhanh chóng trong nhu cầu tinh chỉnh LLMs, nhiều framework để thích ứng LLMs cho các mục đích cụ thể đã được phát triển. LLaMA-Adapter (Zhang et al., 2024) tinh chỉnh hiệu quả mô hình Llama (Touvron et al., 2023a) sử dụng attention được khởi tạo zero. FastChat (Zheng et al., 2023) là một framework tập trung vào huấn luyện và đánh giá LLMs cho mục đích hoàn thiện cuộc trò chuyện. LitGPT (AI, 2023) cung cấp triển khai của các mô hình sinh và hỗ trợ nhiều phương pháp huấn luyện. Open-Instruct (Wang et al., 2023d) cung cấp các công thức để huấn luyện mô hình instruct. Colossal AI (Li et al., 2023b) áp dụng các chiến lược song song tiên tiến cho huấn luyện phân tán. LMFlow (Diao et al., 2024) hỗ trợ huấn luyện LLMs cho các lĩnh vực hoặc tác vụ chuyên biệt. GPT4All (Anand et al., 2023) cho phép LLMs chạy trên các thiết bị tiêu dùng, đồng thời cung cấp khả năng tinh chỉnh. So với các framework cạnh tranh hiện có, LLAMA FACTORY hỗ trợ phạm vi rộng hơn các kỹ thuật tinh chỉnh hiệu quả và phương pháp huấn luyện. Chúng tôi liệt kê các tính năng giữa các framework đại diện trong Bảng 1.

## 3 Kỹ thuật tinh chỉnh hiệu quả

Các kỹ thuật tinh chỉnh LLM hiệu quả có thể được chia thành hai loại chính: những kỹ thuật tập trung vào tối ưu hóa và những kỹ thuật nhằm vào tính toán. Mục tiêu chính của các kỹ thuật tối ưu hóa hiệu quả là tinh chỉnh các tham số của LLMs trong khi giữ chi phí ở mức tối thiểu. Mặt khác, các phương pháp tính toán hiệu quả tìm cách giảm thời gian hoặc không gian cho tính toán cần thiết trong LLMs. Các phương pháp được bao gồm trong LLAMA FACTORY được liệt kê trong Bảng 2. Chúng tôi sẽ trình bày các kỹ thuật tinh chỉnh hiệu quả này và cho thấy cải thiện hiệu quả đáng kể đạt được bằng cách kết hợp chúng vào framework của chúng tôi trong các phần tiếp theo.

### 3.1 Tối ưu hóa hiệu quả

Đầu tiên, chúng tôi cung cấp tổng quan về các kỹ thuật tối ưu hóa hiệu quả được sử dụng trong LLAMA FACTORY. Phương pháp freeze-tuning (Houlsby et al., 2019) bao gồm việc đóng băng phần lớn tham số trong khi tinh chỉnh các tham số còn lại trong một tập hợp nhỏ các lớp decoder. Một phương pháp khác được gọi là chiếu gradient thấp-rank (GaLore) (Zhao et al., 2024) chiếu gradient vào không gian chiều thấp hơn, tạo điều kiện học tham số đầy đủ theo cách tiết kiệm bộ nhớ. Tương tự, BAdam (Luo et al., 2024) tận dụng block coordinate descent (BCD) để tối ưu hóa hiệu quả các tham số rộng lớn.

Ngược lại, phương pháp thích ứng thấp-rank (LoRA) (Hu et al., 2022) đóng băng tất cả trọng số được tiền huấn luyện và giới thiệu một cặp ma trận thấp-rank có thể huấn luyện vào lớp được chỉ định. Khi kết hợp với lượng tử hóa, phương pháp này được gọi là QLoRA (Dettmers et al., 2023), giúp giảm thêm việc sử dụng bộ nhớ. DoRA (Liu et al., 2024) chia trọng số được tiền huấn luyện thành các thành phần độ lớn và hướng và cập nhật các thành phần hướng để tăng hiệu suất. LoRA+ (Hayou et al., 2024) được đề xuất để khắc phục tính tối ưu dưới mức của LoRA. PiSSA (Meng et al., 2024) khởi tạo adapters với các thành phần chính của trọng số được tiền huấn luyện để hội tụ nhanh hơn.

### 3.2 Tính toán hiệu quả

Trong LLAMA FACTORY, chúng tôi tích hợp một loạt các kỹ thuật cho tính toán hiệu quả. Các kỹ thuật thường được sử dụng bao gồm huấn luyện độ chính xác hỗn hợp (Micikevicius et al., 2018) và activation checkpointing (Chen et al., 2016). Rút ra hiểu biết từ việc kiểm tra chi phí đầu vào-đầu ra (IO) của lớp attention, flash attention (Dao et al., 2022) giới thiệu phương pháp thân thiện với phần cứng để tăng cường tính toán attention. S2attention (Chen et al., 2024b) giải quyết thách thức của ngữ cảnh mở rộng với shifted sparse attention, từ đó giảm việc sử dụng bộ nhớ trong tinh chỉnh LLMs ngữ cảnh dài. Các chiến lược lượng tử hóa khác nhau (Dettmers et al., 2022a; Frantar et al., 2023; Lin et al., 2023; Egiazarian et al., 2024) giảm yêu cầu bộ nhớ trong các mô hình ngôn ngữ lớn (LLMs) bằng cách sử dụng biểu diễn độ chính xác thấp hơn cho trọng số. Tuy nhiên, việc tinh chỉnh các mô hình được lượng tử hóa bị hạn chế đối với các kỹ thuật dựa trên adapter như LoRA (Hu et al., 2022). Unsloth (Han và Han, 2023) kết hợp Triton (Tillet et al., 2019) để triển khai lan truyền ngược của LoRA, giúp giảm các phép toán floating-point (FLOPs) trong quá trình gradient descent và dẫn đến huấn luyện LoRA nhanh hơn.

LLAMA FACTORY kết hợp liền mạch các kỹ thuật này thành một cấu trúc gắn kết để tăng hiệu quả tinh chỉnh LLM. Điều này dẫn đến việc giảm dấu chân bộ nhớ từ 18 byte trên mỗi tham số trong huấn luyện độ chính xác hỗn hợp (Micikevicius et al., 2018) hoặc 8 byte trên mỗi tham số trong huấn luyện độ chính xác một nửa (Le Scao et al., 2022) xuống chỉ 0.6 byte trên mỗi tham số. Thông tin chi tiết hơn về các thành phần trong LLAMA FACTORY sẽ được cung cấp trong phần tiếp theo.

## 4 Framework LLAMA FACTORY

LLAMA FACTORY bao gồm ba module chính: Model Loader, Data Worker và Trainer. Model Loader thao tác với nhiều kiến trúc mô hình khác nhau để tinh chỉnh, hỗ trợ cả mô hình ngôn ngữ lớn (LLMs) và mô hình ngôn ngữ thị giác (VLMs). Data Worker xử lý dữ liệu từ các tác vụ khác nhau thông qua pipeline được thiết kế tốt, hỗ trợ cả cuộc hội thoại một lượt và nhiều lượt. Trainer áp dụng các kỹ thuật tinh chỉnh hiệu quả cho các phương pháp huấn luyện khác nhau, hỗ trợ tiền huấn luyện, instruction tuning và tối ưu hóa sở thích. Ngoài ra, LLAMA BOARD cung cấp giao diện trực quan thân thiện để truy cập các module này, cho phép người dùng cấu hình và khởi chạy các instance tinh chỉnh LLM riêng lẻ mà không cần code và giám sát trạng thái huấn luyện đồng bộ. Chúng tôi minh họa mối quan hệ giữa các module này và kiến trúc tổng thể của LLAMA FACTORY trong Hình 1.

### 4.1 Model Loader

Phần này đầu tiên trình bày bốn thành phần trong Model Loader: khởi tạo mô hình, patching mô hình, lượng tử hóa mô hình và đính kèm adapter, tiếp theo là mô tả phương pháp của chúng tôi trong việc thích ứng với nhiều thiết bị khác nhau bằng cách xử lý độ chính xác floating-point của tham số trong quá trình tinh chỉnh.

**Khởi tạo mô hình** Chúng tôi sử dụng Auto Classes của Transformers (Wolf et al., 2020) để tải các mô hình được tiền huấn luyện và khởi tạo tham số. Cụ thể, chúng tôi tải các mô hình ngôn ngữ thị giác sử dụng lớp AutoModelForVision2Seq trong khi phần còn lại được tải sử dụng lớp AutoModelForCausalLM. Tokenizer được tải sử dụng lớp AutoTokenizer cùng với mô hình. Trong trường hợp kích thước từ vựng của tokenizer vượt quá khả năng của lớp embedding, chúng tôi thay đổi kích thước lớp và khởi tạo các tham số mới với khởi tạo mean nhiễu. Để xác định hệ số tỷ lệ cho RoPE scaling (Chen et al., 2023), chúng tôi tính toán nó như tỷ lệ của độ dài chuỗi đầu vào tối đa với độ dài ngữ cảnh của mô hình.

**Model Patching** Để kích hoạt S2attention, chúng tôi sử dụng monkey patch để thay thế tính toán forward của các mô hình. Tuy nhiên, chúng tôi sử dụng lớp native để kích hoạt flash attention vì nó đã được hỗ trợ rộng rãi kể từ Transformers 4.34.0. Để ngăn chặn phân vùng quá mức của các lớp động, chúng tôi đặt các khối mixture-of-experts (MoE) làm module lá khi chúng tôi tối ưu hóa các mô hình MoE dưới DeepSpeed ZeRO stage-3 (Rasley et al., 2020).

**Lượng tử hóa mô hình** Lượng tử hóa động các mô hình xuống 8 bit hoặc 4 bit với LLM.int8 (Dettmers et al., 2022a) có thể được thực hiện thông qua thư viện bitsandbytes (Dettmers, 2021). Đối với lượng tử hóa 4-bit, chúng tôi sử dụng double quantization và 4-bit normal float như QLoRA (Dettmers et al., 2023). Chúng tôi cũng hỗ trợ tinh chỉnh các mô hình được lượng tử hóa bằng các phương pháp lượng tử hóa sau huấn luyện (PTQ), bao gồm GPTQ (Frantar et al., 2023), AWQ (Lin et al., 2023), và AQLM (Egiazarian et al., 2024). Lưu ý rằng chúng tôi không thể tinh chỉnh trực tiếp các trọng số được lượng tử hóa; do đó, các mô hình được lượng tử hóa chỉ tương thích với các phương pháp dựa trên adapter.

**Đính kèm Adapter** Chúng tôi tự động xác định các lớp thích hợp để đính kèm adapters thông qua việc duyệt qua các lớp mô hình. Các adapters thấp-rank được đính kèm vào tất cả các lớp tuyến tính để hội tụ tốt hơn như được gợi ý bởi (Dettmers et al., 2023). Thư viện PEFT (Mangrulkar et al., 2022) cung cấp cách cực kỳ thuận tiện để triển khai các phương pháp dựa trên adapter như LoRA (Hu et al., 2022), rsLoRA (Kalajdzievski, 2023), DoRA (Liu et al., 2024) và PiSSA (Meng et al., 2024). Chúng tôi thay thế tính toán backward bằng tính toán của Unsloth (Han và Han, 2023) để tăng tốc huấn luyện. Để thực hiện học tăng cường từ phản hồi con người (RLHF), một lớp value head được thêm vào trên đầu mô hình transformer, ánh xạ biểu diễn của mỗi token thành một scalar.

**Thích ứng độ chính xác** Chúng tôi xử lý độ chính xác floating-point của các mô hình được tiền huấn luyện dựa trên khả năng của các thiết bị tính toán. Đối với GPU NVIDIA, chúng tôi áp dụng độ chính xác bfloat16 nếu khả năng tính toán là 8.0 hoặc cao hơn. Nếu không, float16 được áp dụng. Bên cạnh đó, chúng tôi áp dụng float16 cho NPU Ascend và GPU AMD và float32 cho các thiết bị không phải CUDA. Trong huấn luyện độ chính xác hỗn hợp, chúng tôi đặt tất cả các tham số có thể huấn luyện thành float32 để ổn định huấn luyện. Tuy nhiên, chúng tôi giữ các tham số có thể huấn luyện là bfloat16 trong huấn luyện độ chính xác một nửa.

### 4.2 Data Worker

Chúng tôi phát triển một pipeline xử lý dữ liệu, bao gồm tải dataset, căn chỉnh dataset, hợp nhất dataset và tiền xử lý dataset. Nó chuẩn hóa các dataset từ các tác vụ khác nhau thành một định dạng thống nhất, cho phép chúng tôi tinh chỉnh các mô hình trên các dataset với nhiều định dạng khác nhau.

**Tải dataset** Chúng tôi sử dụng thư viện Datasets (Lhoest et al., 2021) để tải dữ liệu, cho phép người dùng tải dataset từ xa từ Hugging Face Hub hoặc đọc dataset cục bộ thông qua script hoặc qua file. Thư viện Datasets giảm đáng kể overhead bộ nhớ trong quá trình xử lý dữ liệu và tăng tốc truy vấn mẫu sử dụng Arrow (Apache, 2016). Theo mặc định, toàn bộ dataset được tải xuống đĩa cục bộ. Tuy nhiên, nếu dataset quá lớn để lưu trữ, framework của chúng tôi cung cấp dataset streaming để lặp qua mà không cần tải xuống.

**Căn chỉnh dataset** Để thống nhất định dạng dataset, chúng tôi thiết kế một đặc tả mô tả dữ liệu để đặc trưng cho cấu trúc của dataset. Ví dụ, dataset alpaca có ba cột: instruction, input và output (Taori et al., 2023). Chúng tôi chuyển đổi dataset thành cấu trúc chuẩn tương thích với nhiều tác vụ khác nhau theo đặc tả mô tả dữ liệu. Một số ví dụ về cấu trúc dataset được hiển thị trong Bảng 3.

**Hợp nhất dataset** Cấu trúc dataset thống nhất cung cấp phương pháp hiệu quả để hợp nhất nhiều dataset. Đối với các dataset ở chế độ non-streaming, chúng tôi đơn giản nối chúng trước khi các dataset được xáo trộn trong quá trình huấn luyện. Tuy nhiên, trong chế độ streaming, việc nối đơn giản các dataset cản trở việc xáo trộn dữ liệu. Do đó, chúng tôi cung cấp các phương pháp để đọc xen kẽ dữ liệu từ các dataset khác nhau.

**Tiền xử lý dataset** LLAMA FACTORY được thiết kế để tinh chỉnh các mô hình sinh văn bản, chủ yếu được sử dụng trong hoàn thiện chat. Chat template là một thành phần quan trọng trong các mô hình này, vì nó có liên quan chặt chẽ đến khả năng tuân theo instruction của các mô hình này. Do đó, chúng tôi cung cấp hàng chục chat template có thể được tự động chọn theo loại mô hình. Chúng tôi mã hóa câu sau khi áp dụng chat template sử dụng tokenizer. Theo mặc định, chúng tôi chỉ tính toán loss trên các completion, trong khi các prompt bị bỏ qua (Taori et al., 2023). Tùy chọn, chúng tôi có thể sử dụng sequence packing (Krell et al., 2021) để giảm thời gian huấn luyện, được tự động kích hoạt khi thực hiện tiền huấn luyện sinh.

### 4.3 Trainer

**Huấn luyện hiệu quả** Chúng tôi tích hợp các phương pháp tinh chỉnh hiệu quả tiên tiến, bao gồm LoRA+ (Hayou et al., 2024), GaLore (Zhao et al., 2024) và BAdam (Luo et al., 2024) vào Trainer bằng cách thay thế các thành phần mặc định. Các phương pháp tinh chỉnh này độc lập với Trainer, làm cho chúng dễ dàng áp dụng cho các tác vụ khác nhau. Chúng tôi sử dụng các trainer của Transformers (Wolf et al., 2020) cho tiền huấn luyện và SFT, trong khi áp dụng các trainer của TRL (von Werra et al., 2020) cho RLHF và DPO. Chúng tôi cũng bao gồm các trainer của các phương pháp tối ưu hóa sở thích tiên tiến như KTO (Ethayarajh et al., 2024) và ORPO (Hong et al., 2024) từ thư viện TRL. Các data collator tùy chỉnh được tận dụng để phân biệt các trainer của các phương pháp huấn luyện khác nhau. Để phù hợp với định dạng đầu vào của các trainer cho dữ liệu sở thích, chúng tôi xây dựng 2n mẫu trong một batch trong đó n mẫu đầu là các ví dụ được chọn và n mẫu cuối là các ví dụ bị từ chối.

**RLHF chia sẻ mô hình** Cho phép huấn luyện RLHF trên các thiết bị tiêu dùng là quan trọng để dân chủ hóa tinh chỉnh LLM. Tuy nhiên, điều này khó khăn vì huấn luyện RLHF yêu cầu bốn mô hình khác nhau. Để giải quyết vấn đề này, chúng tôi đề xuất RLHF chia sẻ mô hình, cho phép toàn bộ huấn luyện RLHF với không quá một mô hình được tiền huấn luyện. Cụ thể, chúng tôi đầu tiên huấn luyện một adapter và một value head với hàm mục tiêu cho reward modeling, cho phép mô hình tính toán điểm reward. Sau đó, chúng tôi khởi tạo một adapter khác và value head và huấn luyện chúng với thuật toán PPO (Ouyang et al., 2022). Các adapter và value head được chuyển đổi động thông qua các phương thức set_adapter và disable_adapter của PEFT (Mangrulkar et al., 2022) trong quá trình huấn luyện, cho phép một mô hình được tiền huấn luyện duy nhất phục vụ như policy model, value model, reference model, và reward model đồng thời. Theo hiểu biết của chúng tôi, đây là phương pháp đầu tiên hỗ trợ huấn luyện RLHF trên các thiết bị tiêu dùng.

**Huấn luyện phân tán** Chúng tôi có thể kết hợp các trainer trên với DeepSpeed (Rasley et al., 2020; Ren et al., 2021) cho huấn luyện phân tán. Chúng tôi áp dụng song song dữ liệu để khai thác hoàn toàn khả năng của các thiết bị tính toán. Tận dụng bộ tối ưu hóa DeepSpeed ZeRO, việc tiêu thụ bộ nhớ có thể được giảm thêm thông qua phân vùng hoặc offloading.

### 4.4 Tiện ích

**Suy luận mô hình** Trong thời gian suy luận, chúng tôi tái sử dụng chat template từ Data Worker để xây dựng đầu vào mô hình. Chúng tôi cung cấp hỗ trợ cho việc lấy mẫu đầu ra mô hình sử dụng Transformers (Wolf et al., 2020) và vLLM (Kwon et al., 2023), cả hai đều hỗ trợ giải mã luồng. Ngoài ra, chúng tôi triển khai API kiểu OpenAI sử dụng công cụ LLM không đồng bộ và paged attention của vLLM, để cung cấp dịch vụ suy luận đồng thời thông lượng cao, tạo điều kiện cho việc triển khai các LLM được tinh chỉnh vào nhiều ứng dụng khác nhau.

**Đánh giá mô hình** Chúng tôi bao gồm một số metric để đánh giá LLMs, bao gồm các tác vụ multiple-choice như MMLU (Hendrycks et al., 2021), CMMLU (Li et al., 2023a), và C-Eval (Huang et al., 2023), cũng như tính toán điểm tương tự văn bản như BLEU-4 (Papineni et al., 2002) và ROUGE (Lin, 2004). Tính năng này tạo điều kiện cho người dùng đo lường khả năng của các mô hình được tinh chỉnh.

### 4.5 LLAMA BOARD: Giao diện thống nhất cho LLAMA FACTORY

LLAMA BOARD là giao diện người dùng thống nhất dựa trên Gradio (Abid et al., 2019) cho phép người dùng tùy chỉnh tinh chỉnh LLMs mà không cần viết bất kỳ mã nào. Nó cung cấp dịch vụ tinh chỉnh và suy luận mô hình được đơn giản hóa, cho phép người dùng dễ dàng khám phá tiềm năng của LLMs trong môi trường của họ.

LLAMA BOARD có các tính năng đáng chú ý sau:

**Cấu hình dễ dàng** LLAMA BOARD cho phép chúng tôi tùy chỉnh các tham số tinh chỉnh thông qua tương tác với giao diện web. Chúng tôi cung cấp giá trị mặc định cho phần lớn các tham số được khuyến nghị cho hầu hết người dùng, đơn giản hóa quá trình cấu hình. Hơn nữa, người dùng có thể xem trước các dataset trên giao diện web để xác thực chúng.

**Huấn luyện có thể giám sát** Trong quá trình huấn luyện, các log huấn luyện và đường cong loss được trực quan hóa và cập nhật theo thời gian thực, cho phép người dùng giám sát tiến trình huấn luyện. Tính năng này cung cấp hiểu biết có giá trị để phân tích quá trình tinh chỉnh.

**Đánh giá linh hoạt** LLAMA BOARD hỗ trợ tính toán điểm tương tự văn bản trên các dataset để tự động đánh giá mô hình hoặc thực hiện đánh giá con người bằng cách trò chuyện với chúng.

**Hỗ trợ đa ngôn ngữ** LLAMA BOARD cung cấp các file bản địa hóa, tạo điều kiện cho việc tích hợp các ngôn ngữ mới để render giao diện. Hiện tại chúng tôi hỗ trợ ba ngôn ngữ: Tiếng Anh, Tiếng Nga và Tiếng Trung, cho phép phạm vi người dùng rộng hơn sử dụng LLAMA BOARD để tinh chỉnh LLMs.

## 5 Nghiên cứu thực nghiệm

Chúng tôi đánh giá hệ thống LLAMA FACTORY từ hai góc độ: 1) hiệu quả huấn luyện về mức sử dụng bộ nhớ, thông lượng và perplexity. 2) hiệu quả của việc thích ứng với các tác vụ downstream.

### 5.1 Hiệu quả huấn luyện

**Thiết lập thí nghiệm** Chúng tôi sử dụng dataset PubMed (Canese và Weis, 2013), bao gồm hơn 36 triệu bản ghi về tài liệu y sinh học. Chúng tôi trích xuất khoảng 400K token từ phần tóm tắt của tài liệu để xây dựng corpus huấn luyện. Sau đó, chúng tôi tinh chỉnh các mô hình Gemma-2B (Mesnard et al., 2024), Llama2-7B và Llama2-13B (Touvron et al., 2023b) sử dụng mục tiêu tiền huấn luyện sinh với nhiều phương pháp tinh chỉnh hiệu quả khác nhau. Chúng tôi so sánh kết quả của full-tuning, freeze-tuning, GaLore, LoRA và 4-bit QLoRA. Sau khi tinh chỉnh, chúng tôi tính toán perplexity trên corpus huấn luyện để đánh giá hiệu quả của các phương pháp khác nhau. Chúng tôi cũng kết hợp các perplexity của các mô hình được tiền huấn luyện làm baseline.

Trong thí nghiệm này, chúng tôi áp dụng learning rate 10^-5, token batch size 512. Chúng tôi tinh chỉnh các mô hình này sử dụng bộ tối ưu hóa 8-bit AdamW (Dettmers et al., 2022b) với độ chính xác bfloat16 với activation checkpointing để giảm dấu chân bộ nhớ. Trong freeze-tuning, chúng tôi chỉ tinh chỉnh 3 lớp decoder cuối cùng của mô hình. Đối với GaLore, chúng tôi đặt rank và scale lần lượt là 128 và 2.0. Đối với LoRA và QLoRA, chúng tôi đính kèm adapters vào tất cả các lớp tuyến tính và đặt rank và alpha lần lượt là 128 và 256. Tất cả các thí nghiệm được thực hiện trên một GPU NVIDIA A100 40GB duy nhất. Chúng tôi kích hoạt flash attention trong tất cả các thí nghiệm và Unsloth cho các thí nghiệm LoRA và QLoRA.

**Kết quả** Kết quả về hiệu quả huấn luyện được trình bày trong Bảng 4, trong đó memory đề cập đến bộ nhớ peak tiêu thụ trong quá trình huấn luyện, throughput được tính như số token được huấn luyện trên giây, và PPL đại diện cho perplexity của mô hình trên corpus huấn luyện. Vì full-tuning Llama2-13B dẫn đến tràn bộ nhớ, các kết quả không được ghi lại. Chúng tôi quan sát thấy QLoRA luôn có dấu chân bộ nhớ thấp nhất vì các trọng số được tiền huấn luyện được biểu diễn với độ chính xác thấp hơn. LoRA thể hiện thông lượng cao hơn tận dụng tối ưu hóa trong các lớp LoRA bằng Unsloth. GaLore đạt PPL thấp hơn trên các mô hình lớn trong khi LoRA có lợi thế trên các mô hình nhỏ hơn.

### 5.2 Tinh chỉnh trên các tác vụ downstream

**Thiết lập thí nghiệm** Để đánh giá hiệu quả của các phương pháp tinh chỉnh hiệu quả khác nhau, chúng tôi so sánh hiệu suất của các mô hình khác nhau sau khi tinh chỉnh trên các tác vụ downstream. Chúng tôi xây dựng tập huấn luyện và tập test không chồng chéo sử dụng 2.000 ví dụ và 1.000 ví dụ từ ba tác vụ sinh văn bản đại diện, bao gồm CNN/DM (Nallapati et al., 2016), XSum (Narayan et al., 2018) và AdGen (Shao et al., 2019), tương ứng. Chúng tôi chọn một số mô hình được instruction-tuned và tinh chỉnh chúng theo tác vụ sequence-to-sequence sử dụng các phương pháp tinh chỉnh khác nhau. Sau đó, chúng tôi so sánh kết quả của full-tuning (FT), GaLore, LoRA và 4-bit QLoRA. Sau khi tinh chỉnh, chúng tôi tính toán điểm ROUGE (Lin, 2004) trên tập test của mỗi tác vụ. Chúng tôi cũng kết hợp các điểm của các mô hình được instruction-tuned gốc làm baseline.

Trong thí nghiệm này, chúng tôi đặt learning rate thành 10^-5, batch size thành 4 và độ dài đầu vào tối đa thành 2048. Chúng tôi tinh chỉnh các mô hình này sử dụng bộ tối ưu hóa 8-bit AdamW (Dettmers et al., 2022b) với độ chính xác bfloat16 với activation checkpointing. Đối với GaLore, chúng tôi đặt rank và scale lần lượt là 128 và 2.0. Đối với LoRA và QLoRA, chúng tôi đính kèm adapters vào tất cả các lớp tuyến tính và đặt rank và alpha lần lượt là 128 và 256. Tất cả các thí nghiệm được thực hiện trên GPU NVIDIA A100 40GB.

**Kết quả** Kết quả đánh giá trên các tác vụ downstream được hiển thị trong Bảng 5. Chúng tôi báo cáo điểm trung bình qua ROUGE-1, ROUGE-2 và ROUGE-L. Một số kết quả của các mô hình Gemma-7B và Qwen2-7B (Bai et al., 2023) không được bao gồm trong bảng vì phương pháp GaLore có thể không áp dụng được cho chúng. Một phát hiện thú vị từ kết quả là LoRA và QLoRA đạt hiệu suất tốt nhất trong hầu hết các trường hợp, ngoại trừ các mô hình ChatGLM3-6B (Zeng et al., 2024) và Llama2-7B trên các dataset CNN/DM và AdGen. Hiện tượng này nhấn mạnh hiệu quả của các phương pháp tinh chỉnh hiệu quả này trong việc thích ứng LLMs với các tác vụ cụ thể. Ngoài ra, chúng tôi quan sát thấy Llama3-8B đạt hiệu suất tốt nhất giữa các mô hình này, trong khi Yi-6B (Young et al., 2024) và Mistral-7B (Jiang et al., 2023a) thể hiện hiệu suất cạnh tranh giữa các mô hình cùng kích thước.

## 6 Kết luận và công việc tương lai

Trong bài báo này, chúng tôi trình bày LLAMA FACTORY, một framework thống nhất cho việc tinh chỉnh hiệu quả LLMs. Thông qua thiết kế modular, chúng tôi tối thiểu hóa sự phụ thuộc giữa các mô hình, dataset và phương pháp huấn luyện và cung cấp phương pháp tích hợp để tinh chỉnh hơn 100 LLMs với một loạt các kỹ thuật tinh chỉnh hiệu quả đa dạng. Ngoài ra, chúng tôi cung cấp giao diện web linh hoạt LLAMA BOARD, cho phép tinh chỉnh và đánh giá tùy chỉnh LLMs mà không cần nỗ lực coding. Chúng tôi kiểm chứng thực nghiệm về hiệu quả và tính hiệu quả của framework trên các tác vụ mô hình hóa ngôn ngữ và sinh văn bản.

Chúng tôi sẽ liên tục giữ LLAMA FACTORY đồng bộ với các mô hình tiên tiến và kỹ thuật tinh chỉnh hiệu quả. Chúng tôi cũng hoan nghênh các đóng góp từ cộng đồng mã nguồn mở. Lộ trình của LLAMA FACTORY bao gồm:

(1) Cho phép tinh chỉnh cho các mô hình hỗ trợ phạm vi rộng hơn các phương thức, ví dụ như các phương thức âm thanh và video (Zhu et al., 2024a).

(2) Tích hợp thêm các chiến lược huấn luyện song song, ví dụ như sequence parallelism (Jacobs et al., 2023) và tensor parallelism (Shoeybi et al., 2019).

(3) Khám phá các phương pháp tinh chỉnh mạnh hơn cho các mô hình hội thoại, ví dụ như self-play (Chen et al., 2024c; Yuan et al., 2024).

## 7 Tác động rộng và sử dụng có trách nhiệm

LLAMA FACTORY đã thu hút một số lượng lớn các cá nhân quan tâm đến LLMs để khám phá khả năng tùy chỉnh các mô hình. Điều này đóng góp đáng kể vào sự phát triển của các cộng đồng mã nguồn mở. Nó đang nhận được sự chú ý ngày càng tăng và được giới thiệu trong Awesome Transformers như một đại diện của các framework tinh chỉnh hiệu quả cho LLMs. Chúng tôi dự đoán rằng các nhà thực hành xây dựng LLMs của họ dựa trên framework của chúng tôi sẽ mang lại lợi ích cho xã hội. Việc tuân thủ giấy phép mô hình là bắt buộc khi sử dụng LLAMA FACTORY để tinh chỉnh LLMs, từ đó ngăn chặn bất kỳ việc sử dụng sai mục đích tiềm ẩn nào.

## Lời cảm ơn

Công việc này được hỗ trợ một phần bởi Dự án Khoa học và Công nghệ Quốc gia dưới Grant 2022ZD0120202, bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số U23B2056), bởi Quỹ Nghiên cứu Cơ bản cho các Đại học Trung ương, và bởi Phòng thí nghiệm Trọng điểm Nhà nước về Môi trường Phần mềm Phức tạp & Quan trọng.

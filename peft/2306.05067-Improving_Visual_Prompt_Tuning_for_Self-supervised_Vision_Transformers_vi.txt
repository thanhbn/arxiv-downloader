# 2306.05067.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2306.05067.pdf
# Kích thước tệp: 6964629 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Cải thiện Visual Prompt Tuning cho Vision Transformers Tự giám sát
Seungryong Yoo1Eunji Kim1Dahuin Jung1Jungbeom Lee1Sungroh Yoon1 2
Tóm tắt
Visual Prompt Tuning (VPT) là một phương pháp tuning hiệu quả để điều chỉnh các Vision Transformers (ViTs) đã được huấn luyện trước cho các nhiệm vụ downstream. Nó sử dụng các token có thể học được bổ sung, được gọi là prompts, để điều hướng các ViTs đã được huấn luyện trước và được đóng băng. Mặc dù VPT đã chứng minh khả năng ứng dụng với các vision transformers được giám sát, nó thường hoạt động kém với các mô hình tự giám sát. Thông qua các quan sát thực nghiệm, chúng tôi suy ra rằng hiệu quả của VPT phụ thuộc chủ yếu vào các khối ViT mà các token prompt tương tác. Cụ thể, VPT cho thấy hiệu suất cải thiện trên các nhiệm vụ phân loại hình ảnh cho MAE và MoCo v3 khi các token prompt được chèn vào các khối sau thay vì khối đầu tiên. Những quan sát này cho thấy tồn tại một vị trí tối ưu của các khối để chèn các token prompt. Thật không may, việc xác định các khối tối ưu cho prompts trong mỗi ViT tự giám sát cho các tình huống tương lai đa dạng là một quá trình tốn kém. Để giảm thiểu vấn đề này, chúng tôi đề xuất một phương pháp đơn giản nhưng hiệu quả để học một cổng cho mỗi khối ViT nhằm điều chỉnh sự can thiệp của nó vào các token prompt. Với phương pháp của chúng tôi, các token prompt được ảnh hưởng có chọn lọc bởi các khối cần điều hướng để thích ứng nhiệm vụ. Phương pháp của chúng tôi vượt trội hơn các biến thể VPT trong phân loại hình ảnh FGVC và VTAB và phân đoạn ngữ nghĩa ADE20K. Mã nguồn có sẵn tại https://github.com/ryongithub/GatedPromptTuning.

1. Giới thiệu
Hiện tại, học tự giám sát (SSL) với Vision Transformers (ViTs) (Bao et al., 2021; He et al., 2022; Chen et al., 2021; Caron et al., 2021) đã thể hiện kết quả đáng chú ý trên các nhiệm vụ nhận dạng thị giác đa dạng như phân loại và phân đoạn ngữ nghĩa. Các phương pháp SSL nỗ lực để

1Electrical and Computer Engineering,2Interdisciplinary Program in Artificial Intelligence, Seoul National University, Seoul, Korea. Correspondence to: Sungroh Yoon <sryoon@snu.ac.kr >.

Proceedings of the 40thInternational Conference on Machine Learning , Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s).

Hình 1. Độ chính xác phân loại trên bộ dữ liệu CUB và KITTI với vị trí thay đổi nơi các token prompt được chèn vào ViT-B/16 đã được huấn luyện trước. MAE và MoCo v3 cải thiện hiệu suất đáng kể khi các token prompt bị ảnh hưởng bởi các khối sau khối thứ 11 và 8, tương ứng. Chỉ số khối biểu thị điểm chèn ban đầu của các token prompt.

huấn luyện các mạng nơ-ron mà không thiên vị chúng về các nhãn chứa thông tin rất cụ thể về các nhiệm vụ tương ứng (Zhao et al., 2020). Kết quả là, các mô hình tự giám sát thể hiện khả năng mở rộng vượt trội trên các nhiệm vụ thị giác khác nhau so với các mô hình được giám sát (Chen et al., 2020; He et al., 2020; Grill et al., 2020; He et al., 2022; Caron et al., 2021; Bao et al., 2021). Tuy nhiên, hiệu quả của các mô hình tự giám sát phụ thuộc vào chiến lược transfer learning được chọn. Ví dụ, tồn tại khoảng cách hiệu suất lớn giữa fine-tuning đầy đủ và linear probing khi được sử dụng như một phương pháp chuyển giao cho Masked Autoencoder (MAE) (He et al., 2022). Hiệu suất của SSL ViTs có thể khác nhau đáng kể dựa trên phương pháp chuyển giao, nhấn mạnh tầm quan trọng của nghiên cứu về các chiến lược chuyển giao cho SSL ViTs.

Visual Prompt Tuning (VPT) (Jia et al., 2022) là một kỹ thuật transfer learning dựa trên prompt hiệu quả, rút ra khái niệm từ các công trình trước đó trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) (Li & Liang, 2021; Lester et al., 2021). Cụ thể, VPT thêm các token prompt có thể học được vào đầu chuỗi đầu vào, sau đó hoạt động như các hướng dẫn cụ thể cho nhiệm vụ bằng cách điều hướng thông tin từ bộ mã hóa đã được huấn luyện trước cố định. VPT, khi được sử dụng với các backbone ViT được giám sát, đã cho thấy hiệu suất xuất sắc trên nhiều nhiệm vụ downstream.

1arXiv:2306.05067v1  [cs.LG]  8 Jun 2023

--- TRANG 2 ---
Cải thiện Visual Prompt Tuning cho Vision Transformers Tự giám sát

Tuy nhiên, bất chấp thành công của prompt tuning (Lester et al., 2021; Hambardzumyan et al., 2021; Qin & Eisner, 2021; Huang et al., 2023) với các mô hình SSL trong NLP (Devlin et al., 2018; Liu et al., 2019), VPT đã thể hiện hiệu suất tương đối kém với SSL ViTs (Jia et al., 2022). Để giải quyết điều này, chúng tôi đề xuất một phương pháp chuyển giao đơn giản nhưng hiệu quả dựa trên prompt tuning để nâng cao hiệu suất của SSL ViTs.

Điều được biết rõ là các Mạng Nơ-ron Sâu (DNNs) dần dần trừu tượng hóa thông tin chứa trong các mẫu dữ liệu qua các lớp của chúng (LeCun et al., 2015; Schmidhuber, 2015; Kriegeskorte, 2015). Xem xét điều này trong bối cảnh VPT, thông tin từ tất cả các mức trừu tượng ảnh hưởng đến các token prompt. Tuy nhiên, các token prompt này nên có thể mã hóa các hướng dẫn bằng cách tập trung chỉ vào thông tin liên quan đến nhiệm vụ để thích ứng nhiệm vụ mục tiêu. Điều này có thể đặt ra thách thức cho các token prompt từ hai góc độ. Thứ nhất, bộ mã hóa sở hữu các phân cấp thông tin khác nhau qua các khối tùy thuộc vào cách nó được huấn luyện trước. Thứ hai, thông tin liên quan đến nhiệm vụ cần thiết có thể khác nhau tùy thuộc vào nhiệm vụ downstream.

Chúng tôi phỏng đoán rằng những gì các token prompt học được phụ thuộc nhiều vào khối nào ảnh hưởng đến chúng trong quá trình huấn luyện. Để chứng minh phỏng đoán của chúng tôi, chúng tôi đã tiến hành một thí nghiệm để quan sát hiệu suất thay đổi như thế nào tùy thuộc vào khối nào can thiệp với các token prompt. Thú vị là, trong Hình 1, trên benchmark phân loại CUB (Wah et al., 2011), MAE (He et al., 2022) và MoCo v3 (Chen et al., 2021) tăng độ chính xác của chúng khi các token prompt bắt đầu tương tác với khối thứ 11 và 8 trong ViT-B, tương ứng. Đặc biệt đối với MAE, khoảng cách hiệu suất lớn tới 36.4%. Dựa trên những phát hiện này, trực giác chính của nghiên cứu này là tồn tại các khối mong muốn mà các token prompt nên tập trung vào để điều hướng.

Tùy thuộc vào chiến lược huấn luyện trước, các mạng nơ-ron đã được huấn luyện trước mã hóa thông tin khác nhau về lượng và nội dung (Zhao et al., 2020; Bordes et al., 2021). Ngoài ra, thông tin liên quan cần thiết để giải quyết nhiệm vụ downstream thay đổi theo nhiệm vụ đó. Vì những lý do này, các khối liên quan đến nhiệm vụ sẽ khác nhau tùy thuộc vào việc sử dụng chúng trong nhiệm vụ downstream và phương pháp huấn luyện trước. Thật không may, việc điều tra tất cả các trường hợp có thể để tìm các tập hợp mong muốn của các khối ViT phát sinh chi phí đáng kể. Để giải quyết điều này, chúng tôi đề xuất một phương pháp đơn giản nhưng hiệu quả để học hướng dẫn prompt tương tác có chọn lọc với các khối mong muốn mã hóa thông tin liên quan đến nhiệm vụ. Chúng tôi đạt được điều này bằng cách giới thiệu các cổng có thể học được cho các khối ViT để điều chỉnh sự can thiệp vào các token prompt từ các khối ViT. Với phương pháp đề xuất của chúng tôi, các token prompt tập trung vào các khối cần được điều hướng để thích ứng nhiệm vụ mục tiêu.

Kết quả thực nghiệm xác nhận rằng phương pháp đề xuất của chúng tôi mở khóa tiềm năng của prompt tuning như một chiến lược tuning phổ quát cho các ViTs tự giám sát. Trên benchmark FGVC, bao gồm năm nhiệm vụ phân loại tinh vi (Wah et al., 2011; Van Horn et al., 2015; Khosla et al., 2011; Gebru et al., 2017; Nilsback & Zisserman, 2008), chúng tôi đạt được độ chính xác trung bình 73.4% cho MAE và 83.0% cho MoCo v3. Những kết quả này vượt trội đáng kể so với VPT-shallow và vượt trội hoặc tương đương với VPT-deep. Hơn nữa, trên benchmark VTAB-1K (Zhai et al., 2019), bao gồm 19 nhiệm vụ phân loại thị giác đa dạng, phương pháp đề xuất của chúng tôi đạt được độ chính xác trung bình 49.2% và 65.8% cho MAE và MoCo v3, tương ứng, vượt trội đáng kể so với cả VPT-deep và VPT-shallow. Phương pháp của chúng tôi thể hiện sức mạnh không chỉ trong các nhiệm vụ phân loại mà còn trong các nhiệm vụ dự đoán dày đặc như phân đoạn ngữ nghĩa. Nó thể hiện hiệu suất vượt trội so với các đối tác VPT trên benchmark phân đoạn ngữ nghĩa ADE 20K (Zhou et al., 2017), đạt được 38.4 mIoU cho MAE và 36.8 mIoU cho MoCo v3.

2. Kiến thức cơ bản

Vision Transformer. Thông thường, ViT bao gồm một lớp patch embedding, một stack gồm L khối transformer, và một đầu phân loại. Để xử lý một hình ảnh có chiều cao H, chiều rộng W và kênh C thành một ViT, chúng ta chia hình ảnh thành một lưới các patch xi∈RP×P×C, trong đó P là kích thước patch và i= 1, . . . ,HW/P2. Mỗi xi được nhúng như một đặc trưng D chiều và embedding vị trí D chiều được thêm vào mỗi token patch để cung cấp thông tin vị trí cho ViTs như sau:

z0i=PatchEmbed (xi) +ei, (1)

trong đó z0i biểu thị token đầu vào nhúng cho khối ViT đầu tiên và ei biểu thị embedding vị trí. Gọi các token patch đầu vào cho khối thứ l là Zl−1= {zl−11, . . . , zl−1N}, trong đó N=HW/P2,l= 1, . . . , L , và L là số khối. Các token patch và một token có thể học được bổ sung để phân loại, zlCLS, được đưa vào các khối như sau:

{zlCLS,Zl} =Blockl{zl−1CLS,Zl−1} ∈R(N+1)×D,(2)

trong đó mỗi khối bao gồm một multi-head self-attention theo sau bởi một lớp feed-forward với layer normalization (Ba et al., 2016) và residual connection (He et al., 2016). Trong số nhiều đầu self-attention trong khối thứ l, một đầu self-attention đơn (Vaswani et al., 2017) được công thức hóa như sau:

Attention (Ql, Kl, Vl) =alVl
s.t.al=Softmax(QlKlT/√d), (3)

trong đó Ql, Kl, Vl trình bày các token query, key và value đầu vào được xây dựng bởi phép chiếu tuyến tính của {zl−1CLS,Zl−1}, tương ứng, và al trình bày điểm self-attention được tính toán trong khối thứ l. Cuối cùng, đầu phân loại có một lớp feed-forward đơn để dự đoán lớp.

Visual Prompt Tuning. VPT (Jia et al., 2022) huấn luyện các prompt liên tục trong không gian nhúng. Các token prompt có thể học được P= [p1, . . . , p Np]∈RNP×D được thêm vào đầu chuỗi đầu vào, trong đó Np là số token prompt và D là chiều của token prompt. Trong quá trình transfer learning, chỉ các token prompt và đầu phân loại có thể huấn luyện được và bộ mã hóa ViT đã được huấn luyện trước được cố định. Các token prompt học mã hóa các hướng dẫn cụ thể cho nhiệm vụ bằng cách tương tác với các biểu diễn patch qua tất cả các khối ViT. VPT giới thiệu hai biến thể: VPT-shallow và VPT-deep. VPT-shallow chèn các token prompt có thể học được như đầu vào trong khối đầu tiên. Các phương trình sau công thức hóa VPT-shallow:

{z1CLS,Z1P,Z1} =Block1{z0CLS,P,Z0}
{zlCLS,ZlP,Zl} =Blockl{zl−1CLS,Zl−1P,Zl−1}, (4)

trong đó ZlP biểu thị biểu diễn prompt đầu ra của khối thứ l. Khác biệt, VPT-deep tiêm các token prompt có thể học được theo khối Pl−1 vào mỗi khối, không phải đầu ra Zl−1P của khối trước:

{zlCLS,,Zl} =Blockl{zl−1CLS,Pl−1,Zl−1}. (5)

3. Động lực

Kiến thức được huấn luyện trước và nhiệm vụ downstream là hai yếu tố quan trọng trong các tình huống transfer learning. Trong phần này, chúng tôi thảo luận về nền tảng động lực của nghiên cứu từ hai góc độ này.

Kiến thức được huấn luyện trước. Chúng tôi thấy rằng khối nơi các token prompt được chèn đầu tiên dẫn đến hiệu suất khác nhau trong Hình 1. Chúng tôi xác minh những phát hiện này từ góc độ thông tin chứa trong mỗi khối của ViTs. Chúng tôi sử dụng Deep Image Prior (DIP) (Ulyanov et al., 2018) để điều tra sự thay đổi thông tin qua các khối của ViTs đã được huấn luyện trước. DIP tái tạo một hình ảnh bằng cách cập nhật nhiễu ngẫu nhiên sao cho biểu diễn của hình ảnh gốc và biểu diễn của nhiễu đã được cập nhật gần nhau trong không gian biểu diễn. Sử dụng hình ảnh được tái tạo, chúng ta có thể suy ra thông tin mà không gian biểu diễn của mỗi đơn vị mạng nơ-ron mã hóa. Như được hiển thị trong Hình 2, trong các khối sau, ViT được giám sát có xu hướng loại bỏ nhiều thông tin hơn ViT tự giám sát. Trái ngược với mô hình được giám sát, các ViTs tự giám sát, MoCo v3 (Chen et al., 2021) và MAE (He et al., 2022) giữ lại thông tin phong phú qua các khối. Xu hướng này cũng rõ ràng trong điểm chất lượng hình ảnh được tái tạo, như PSNR và SSIM, như được chỉ ra trong Hình 9 ở Phụ lục C.1. Hơn nữa, có thể quan sát thấy rằng ngay cả các Vision Transformers tự giám sát cũng thể hiện sự khác biệt trong nội dung thông tin được mã hóa bởi mỗi khối. Khi so sánh MoCo v3 với MAE, có thể nhận thấy rằng MoCo v3 thể hiện sự giảm thông tin màu sắc sau khối giữa. Nhiều kết quả DIP có sẵn trong Phụ lục C.2.

Ví dụ này cho thấy các phương pháp huấn luyện trước khác nhau dẫn đến các khối ViT khác nhau về lượng và nội dung thông tin chúng mã hóa. Từ đó suy ra rằng vị trí của các khối chứa thông tin liên quan đến nhiệm vụ khác nhau tùy thuộc vào ViTs đã được huấn luyện trước. Nếu prompt được chèn vào khối đầu tiên mà không xem xét những khác biệt này, sự can thiệp tích lũy của các khối không liên quan đến nhiệm vụ có thể làm xáo trộn các token prompt để tập trung vào các khối liên quan đến nhiệm vụ.

Đa dạng nhiệm vụ. Thông tin liên quan đến nhiệm vụ khác nhau tùy thuộc vào nhiệm vụ downstream. Ví dụ, trong trường hợp phân loại trên bộ dữ liệu CUB, việc phân biệt thông tin màu sắc và hình dạng tinh vi là rất quan trọng để phân loại các loài chim đa dạng. Không giống như nhiệm vụ phân loại chim với CUB, nhiệm vụ khoảng cách KITTI (Geiger et al., 2013) yêu cầu nắm bắt thông tin vị trí và quy mô để ước tính chính xác khoảng cách đến các đối tượng trong cảnh. Do đó, ngay cả với cùng một Vision Transformer đã được huấn luyện trước, vị trí của các khối mã hóa thông tin liên quan đến nhiệm vụ có thể khác nhau tùy thuộc vào nhiệm vụ. Hình 1 minh họa rằng sự thay đổi hiệu suất theo vị trí chèn prompt khác nhau giữa CUB và KITTI. Điều này chỉ ra rằng các khối mong muốn để chèn prompt để thực hiện thích ứng nhiệm vụ phụ thuộc vào nhiệm vụ.

--- TRANG 3 ---
Cải thiện Visual Prompt Tuning cho Vision Transformers Tự giám sát

[Hình ảnh minh họa không được dịch]

Hình 2. Hình ảnh được tái tạo sử dụng Deep Image Prior (DIP) với biểu diễn khối ViT đã được huấn luyện trước làm mục tiêu huấn luyện. Hình ảnh được tái tạo duy trì sự tương tự với hình ảnh gốc khi khối bảo tồn thông tin đến khối cuối cùng. Hàng 1: hình ảnh gốc. Hàng 2-4: kết quả tái tạo cho mỗi ViTs đã được huấn luyện trước. Kết quả kém trong các khối muộn (7 và 10) của mô hình được giám sát cho thấy nó loại bỏ nhiều thông tin hơn qua các khối so với các ViTs tự giám sát.

--- TRANG 4 ---
Cải thiện Visual Prompt Tuning cho Vision Transformers Tự giám sát

[Hình ảnh minh họa Gated Prompt Tuning]

Hình 3. Minh họa phương pháp đề xuất của chúng tôi, Gated Prompt Tuning. Zl−1P và Z̃lP là biểu diễn prompt đầu vào và đầu ra của khối thứ l. Cổng có thể học được gl kết hợp lồi Zl−1P và Z̃lP sao cho khối thứ (l+1) nhận biểu diễn prompt ZlP trong đó sự can thiệp của khối thứ l vào biểu diễn prompt được điều chỉnh bởi gl.

4. Phương pháp đề xuất

Trong phần trước, chúng tôi thảo luận rằng vị trí của các khối nơi prompt có thể đạt được hiệu suất cải thiện phụ thuộc vào phương pháp SSL. Hơn nữa, vì hướng dẫn cụ thể cho nhiệm vụ cần thiết có thể khác nhau tùy thuộc vào nhiệm vụ, các khối mong muốn cho prompt có thể khác nhau trong cùng một mô hình đã được huấn luyện trước. Hiệu suất nhiệm vụ đầy đủ có thể không được đảm bảo khi prompts được chèn từ khối đầu tiên mà không xem xét cẩn thận sự khác biệt này. Trong khía cạnh này, chúng tôi xem xét một phương pháp prompt tuning phổ quát có thể học chọn các khối nơi điều hướng để thích ứng nhiệm vụ được yêu cầu mạnh mẽ. Để đạt được mục tiêu này, chúng tôi giới thiệu Gated Prompt Tuning, sử dụng các cổng có thể học được để điều chỉnh sự can thiệp của mỗi khối vào các token prompt. Các cổng có thể học được cho phép prompts dễ dàng tập trung vào các khối cần điều hướng để thích ứng nhiệm vụ. Tương tự như VPT-shallow, phương pháp của chúng tôi chỉ thêm các token prompt một lần vào chuỗi patch đầu vào. Khung làm việc của chúng tôi được minh họa trong Hình 3.

4.1. Gated Prompt Tuning

Đầu tiên, chúng tôi định nghĩa gate priors Γ = [ γ1, . . . , γL−1], một tập hợp các giá trị vô hướng cho tất cả các khối ngoại trừ khối cuối cùng. Sau khi được chia tỷ lệ với hàm sigmoid, gate prior được sử dụng như giá trị cổng của khối thứ l:

gl=1/(1 +e^(−γl))∈R. (6)

Thao tác gating cho biểu diễn prompt đầu vào tại khối thứ (l+ 1) (tức là ZlP) được công thức hóa như sau:

{zlCLS,Z̃lP,Zl} =Blockl{zl−1CLS,Zl−1P,Zl−1},
ZlP=gl·Z̃lP+ (1−gl)·Zl−1P, (7)

trong đó Z̃lP biểu thị biểu diễn prompt đầu ra của khối thứ l. Trong Eq. 7, khối thứ (l+ 1) nhận tổng có trọng số của Zl−1P và Z̃lP, là biểu diễn prompt đầu vào và đầu ra của khối thứ l, tương ứng. Ở đây, giá trị cổng gl kiểm soát đóng góp trong việc tạo ra biểu diễn prompt đầu vào của khối thứ (l+ 1) giữa Zl−1P và Z̃lP. Do đó, cổng gl quyết định mức độ ảnh hưởng của khối trước đó trên prompt được chuyển sang khối tiếp theo. Trong quá trình huấn luyện, các cổng học điều chỉnh sự can thiệp của mỗi khối trong các token prompt, cho phép prompts tập trung vào các khối mong muốn cần điều hướng cụ thể cho nhiệm vụ.

Ngay trước đầu nhiệm vụ, khối cuối cùng tinh chỉnh các biểu diễn để có tính phân biệt cho nhiệm vụ. Biểu diễn prompt đầu vào (tức là ZL−1P) cho khối cuối cùng có vai trò quan trọng trong khía cạnh này. Sử dụng Eq. 7, chúng ta có thể biểu thị biểu diễn prompt đầu vào của khối cuối cùng như sau:

ZL−1P=∏(l=1 to L−1)(1−gl)P + ∑(l=1 to L−2)∏(m=l+1 to L−1)(1−gm)gl Z̃lP+gL−1Z̃L−1P. (8)

Vì Z̃lP là biểu diễn prompt đầu ra của khối thứ l, Eq. 8 có thể được hiểu như một tập hợp có chọn lọc của tất cả biểu diễn prompt đầu ra từ các khối ViT bởi các cổng đã học. Tập hợp có chọn lọc dẫn đến các hướng dẫn thích ứng cho các nhiệm vụ mục tiêu.

4.2. Adaptive Attention Shaping

Prompt tuning có thể được hiểu như việc học điều hướng hành vi của ViTs bằng cách thao tác điểm attention đã được huấn luyện trước của các token patch bằng cách mở rộng chuỗi đầu vào với các token prompt bổ sung. Dựa trên trực giác này, như một kỹ thuật bổ sung để tăng khả năng thích ứng nhiệm vụ của prompt tuning, chúng tôi giới thiệu Adaptive Attention Shaping. Chúng tôi định nghĩa nhiệt độ có thể học được T= [τ1, . . . , τL], một tập hợp các giá trị vô hướng điều chỉnh giá trị attention trong thao tác self-attention của khối tương ứng. Với nhiệt độ có thể học được, chúng tôi viết lại điểm self-attention trong Eq. 3 như sau:

al=Softmax(QlKlT/τl). (9)

T trực tiếp định hình lại self-attentions của các khối bằng cách làm cho chúng sắc nét hơn hoặc mượt mà hơn sao cho T hỗ trợ prompts mã hóa hướng dẫn có lợi để giải quyết nhiệm vụ hiện tại.

4.3. So sánh với VPT

Phương pháp của chúng tôi kết hợp các cổng có thể học được để điều hòa các token prompt tương tác với các khối liên quan đến nhiệm vụ và cho phép học prompt hiệu quả bằng cách sử dụng khả năng bổ sung thu được thông qua nhiệt độ có thể học được. Tuy nhiên, trong VPT, không có sự xem xét như vậy cho việc học hiệu quả của các token prompt.

Một sự khác biệt khác giữa phương pháp của chúng tôi và VPT nằm ở việc liệu prompt có thể cung cấp hướng dẫn cụ thể cho mẫu nhưng liên quan đến nhiệm vụ hay không. Trong VPT-shallow, biểu diễn prompt được chuyển đến mỗi khối được điều kiện hóa trên biểu diễn patch từ khối trước, cho phép hướng dẫn cụ thể cho mẫu tại mỗi khối. VPT-shallow có thể được coi là một trường hợp đặc biệt của phương pháp chúng tôi, vì tất cả các cổng đã học được đặt thành 1, và nó thiếu nhiệt độ có thể học được. Tuy nhiên, khi được áp dụng cho các ViTs tự giám sát, các token prompt tương tác với tất cả các khối trong VPT-shallow, và do đó, VPT-shallow có hạn chế trong việc nhắm mục tiêu hiệu quả thông tin liên quan đến nhiệm vụ.

VPT-deep giải quyết sự khác biệt trong mức độ liên quan đến nhiệm vụ qua các khối bằng cách cung cấp các tập hợp token prompt có thể học được độc lập cho mỗi khối. Các prompts trong mỗi khối của VPT-deep được huấn luyện để cung cấp hướng dẫn liên quan đến nhiệm vụ trung bình trên toàn bộ dữ liệu huấn luyện. Tuy nhiên, vì tất cả các mẫu nhận cùng một hướng dẫn từ các token prompt được chia sẻ tại mỗi khối, VPT-deep không thể cung cấp hướng dẫn cụ thể cho mẫu.

Trong phương pháp của chúng tôi, thao tác gating cho phép token prompt tương tác có chọn lọc với các khối, và biểu diễn prompt đầu vào cho mỗi khối phụ thuộc vào biểu diễn patch từ khối trước đó. Do đó, phương pháp của chúng tôi cho phép cung cấp hướng dẫn cụ thể cho mẫu nhưng liên quan đến nhiệm vụ tại mỗi khối.

5. Thí nghiệm

5.1. Thiết lập thí nghiệm

Nhiệm vụ và bộ dữ liệu downstream. Chúng tôi đánh giá phương pháp của mình với hai loại nhiệm vụ downstream: phân loại hình ảnh và phân đoạn ngữ nghĩa. Đối với phân loại hình ảnh, chúng tôi tiến hành thí nghiệm trên benchmark FGVC và VTAB-1K (Zhai et al., 2019). FGVC bao gồm năm nhiệm vụ phân loại tinh vi: CUB (Wah et al., 2011), Oxford Flowers (Nilsback & Zisserman, 2008), Stanford Cars (Gebru et al., 2017), Stanford Dogs (Khosla et al., 2011) và NABirds (Van Horn et al., 2015). VTAB-1K được chia thành ba nhóm phụ: Natural với hình ảnh tự nhiên, Specialized với hình ảnh thu được từ thiết bị chuyên dụng, và Structured yêu cầu hiểu biết cấu trúc như dự đoán độ sâu 3D.

Đối với phân đoạn ngữ nghĩa, chúng tôi đánh giá hiệu suất trên benchmark ADE20K (Zhou et al., 2017) chứa 20K hình ảnh với 150 danh mục đối tượng. Đối với mô hình phân đoạn, chúng tôi sử dụng SETR-PUP (Zheng et al., 2021) sử dụng ViT (Dosovitskiy et al., 2020) như một backbone encoder. Lưu ý rằng triển khai gốc của SETR-PUP áp dụng bốn đầu phụ trợ tại các khối 10, 15, 20 và 24 của ViT-L. Vì chúng tôi sử dụng ViT-B/16 trong tất cả các thí nghiệm, hai đầu phụ trợ được sử dụng tại các khối 5 và 9. Chi tiết thí nghiệm thêm được mô tả trong Sec. A.2 trong Phụ lục.

Vision Transformers tự giám sát. Nghiên cứu của chúng tôi sử dụng hai Vision Transformers tự giám sát hiệu suất tốt, MAE (He et al., 2022) và MoCo v3 (Chen et al., 2021), được huấn luyện trước trên ImageNet-1K (Deng et al., 2009). Các tham số mô hình đã được huấn luyện trước được lấy từ kho lưu trữ chính thức của Visual Prompt Tuning (Jia et al., 2022). Chúng tôi sử dụng ViT-B/16 như kiến trúc backbone trong tất cả các thí nghiệm của nghiên cứu này.

5.2. Kết quả chính

5.2.1. PHÂN LOẠI TRÊN FGVC

Chúng tôi đánh giá hiệu suất phân loại tinh vi trong benchmark FGVC. Đối với VPT-shallow và phương pháp của chúng tôi, chúng tôi đặt 100 token, và đối với VPT-deep, chúng tôi đặt 10 token cho mỗi khối, có nghĩa là tổng cộng 120 token được sử dụng cho VPT-deep. Bảng 1 cho thấy phương pháp của chúng tôi luôn vượt trội hơn đối tác VPT-shallow với biên độ lớn cho cả MAE và MoCo v3 trong tất cả các bộ dữ liệu. Điều này cho thấy phương pháp của chúng tôi dẫn dắt prompt mã hóa hướng dẫn nâng cao trong SSL ViTs để thích ứng nhiệm vụ. Lưu ý rằng so với VPT-deep, MAE với phương pháp của chúng tôi có độ chính xác trung bình cao hơn trong khi vượt trội trong hầu hết tất cả các bộ dữ liệu. Khi được áp dụng cho MoCo v3, mặc dù VPT-deep sử dụng thêm 20% tham số, phương pháp của chúng tôi cho thấy hiệu suất tương đương với VPT-deep trung bình. Theo đó, khi số lượng token prompt được thêm tương tự, phương pháp của chúng tôi hiệu quả hơn trong việc sử dụng các token prompt cho phân loại tinh vi so với cả hai biến thể VPT này. Hơn nữa, phương pháp của chúng tôi cho thấy kết quả hiệu quả hơn với ít token prompt hơn so với VPT-deep. Kết quả thí nghiệm bổ sung cho FGVC với ít token hơn có thể được tìm thấy trong Bảng 7 ở Phụ lục B.1.

--- TRANG 5 ---
Cải thiện Visual Prompt Tuning cho Vision Transformers Tự giám sát

Bảng 1. Kết quả phân loại trên FGVC. TOTAL PARAMS biểu thị tổng số tham số cho tất cả nhiệm vụ bao gồm backbone encoder ViT-B, token prompt và đầu nhiệm vụ. Phông chữ đậm biểu thị hiệu suất tốt nhất trong mỗi benchmark.

[Bảng hiển thị kết quả so sánh MAE và MoCo v3 với các phương pháp VPT-SHALLOW, VPT-DEEP và OURS trên các bộ dữ liệu CUB, FLOWERS, CARS, DOGS, NABIRDS]

Bảng 2. Kết quả phân loại trên VTAB-1K. TOTAL PARAMS biểu thị tổng tham số cho tất cả nhiệm vụ, bao gồm backbone encoder ViT-B, token prompt và đầu nhiệm vụ. (†) biểu thị hiệu suất được báo cáo trong bài báo gốc của VPT (Jia et al., 2022). Phông chữ đậm biểu thị hiệu suất tốt nhất trong mỗi benchmark.

[Bảng hiển thị kết quả so sánh trên VTAB-1K với các nhóm Natural, Specialized, Structured]

5.2.2. PHÂN LOẠI TRÊN VTAB-1K

Với benchmark VTAB-1K, chúng tôi kiểm tra khả năng của phương pháp để điều khiển backbone encoder nắm bắt các khái niệm thị giác chung trên ba nhóm bộ dữ liệu riêng biệt. Bảng 2 cho thấy kết quả phân loại trên VTAB-1K. MAE với phương pháp của chúng tôi vượt trội lớn so với VPT-deep và VPT-shallow trong tất cả ba nhóm. Ngoài ra, phương pháp của chúng tôi cung cấp lợi ích đáng kể cho MoCo v3 trong nhóm Natural và Structured so với các đối tác VPT. Đặc biệt đối với cả MAE và MoCo v3, chúng tôi quan sát được mức tăng hiệu suất lớn nhất trong nhóm Structured, 10.23% và 6.72% từ VPT-deep, tương ứng. Điều này chỉ ra rằng phương pháp của chúng tôi học các token prompt cho phép SSL ViTs chuyển giao hiệu quả hơn. Nó hiệu quả không chỉ với hình ảnh tự nhiên mà còn trong các tình huống có miền hình ảnh khác nhau hoặc khi cần hiểu biết cấu trúc.

5.2.3. PHÂN ĐOẠN NGỮ NGHĨA TRÊN ADE20K

Để xác thực rằng khả năng ứng dụng của phương pháp không giới hạn ở phân loại hình ảnh, chúng tôi đánh giá nhiệm vụ phân đoạn ngữ nghĩa trên ADE20K. Theo cài đặt trong VPT (Jia et al., 2022), chúng tôi sử dụng SETR-PUP (Zheng et al., 2021) cho mô hình phân đoạn. Như được hiển thị trong Bảng 3, phương pháp của chúng tôi mang lại lợi ích hiệu suất lớn từ VPT-shallow cho cả MAE và MoCo v3. Khi so sánh với VPT-deep, MAE và MoCo v3 với phương pháp của chúng tôi cũng cho thấy kết quả tiên tiến.

Bảng 3. Kết quả phân đoạn ngữ nghĩa trên ADE20K với SETR-PUP (Zheng et al., 2021) như mô hình phân đoạn. Đối với VPT-deep, (×12) biểu thị cùng số token prompt được sử dụng cho mỗi khối của ViT-B/16. PT biểu thị token prompt. Phông chữ đậm biểu thị hiệu suất tốt nhất trong mỗi chỉ số.

[Bảng hiển thị kết quả phân đoạn trên ADE20K]

Lưu ý rằng trong thí nghiệm này, phương pháp của chúng tôi đánh bại tất cả các đối tác VPT trong khi VPT-deep sử dụng nhiều hơn 20% token prompt. Điều này ngụ ý rằng phương pháp của chúng tôi sử dụng token prompt hiệu quả hơn trong các nhiệm vụ phân đoạn ngữ nghĩa. Trong Phụ lục B.1, chúng tôi trình bày kết quả cho ADE20K khi sử dụng ít token prompt hơn trong Bảng 6. Tóm lại, như được hiển thị trong kết quả benchmark FGVC, VTAB-1K và ADE20K, phương pháp đề xuất của chúng tôi là chiến lược chuyển giao dựa trên prompt khai thác tốt hơn SSL ViTs cho các nhiệm vụ thị giác đa dạng.

--- TRANG 6 ---
Cải thiện Visual Prompt Tuning cho Vision Transformers Tự giám sát

5.3. Phân tích bổ sung

Phân tích về các cổng đã học. Như chúng tôi đã giải thích trong Eq. 8, phương pháp của chúng tôi được hiểu như một tập hợp có chọn lọc của biểu diễn prompt từ mỗi khối. Sử dụng các giá trị cổng đã học, gl, chúng ta có thể xác định đóng góp của mỗi khối vào prompt được chuyển đến khối cuối cùng. Trong Eq. 8, trọng số được áp dụng cho biểu diễn prompt đầu ra của mỗi khối được biểu thị như sau:

g̃l=∏(m=l+1 to L−1)(1−gm)gl, l= 1, . . . , L −2
g̃L−1=gL−1 (10)

Dựa trên trọng số g̃l, chúng tôi định nghĩa tỷ lệ lựa chọn, đại diện cho ảnh hưởng của mỗi khối trên biểu diễn prompt của khối cuối cùng:

rl=g̃l/∑(m=1 to L−1)g̃m. (11)

Hình 4 cho thấy tỷ lệ lựa chọn được tính từ các mô hình được huấn luyện cho các tình huống chuyển giao khác nhau. Như được hiển thị trong hình, tỷ lệ lựa chọn thay đổi theo nhiệm vụ downstream và phương pháp SSL. Ví dụ, các prompts được học cho MAE tập trung chủ yếu vào khối thứ 11 cho bộ dữ liệu NABirds trong khi tập trung gần như đều nhau vào khối thứ 4 và 11 cho bộ dữ liệu Stanford Cars. Ngoài ra, chúng tôi quan sát rằng các prompts đã học tập trung vào các khối khác nhau tùy thuộc vào SSL ViT. Trên NABirds và Stanford Cars, các prompts đã học với MAE có xu hướng tập trung vào khối thứ 11, trong khi với MoCo v3, chúng có xu hướng tập trung vào khối thứ 10. Nói cách khác, các cổng hướng dẫn prompts xem xét sự thay đổi thông tin qua các khối khác nhau tùy thuộc vào phương pháp tự giám sát. Trong phân đoạn ADE20K, các prompts đã học dường như có tỷ lệ đồng đều qua các khối. Điều này chỉ ra rằng các cổng học làm cho prompts điều hướng tất cả các khối vì thông tin đa cấp có lợi cho các nhiệm vụ phân đoạn (Lin et al., 2017). Những khác biệt trong tỷ lệ lựa chọn này hỗ trợ động lực của chúng tôi rằng prompts nên tập trung vào các khối khác nhau để chúng có thể bị ảnh hưởng có chọn lọc bởi các khối ViT để thích ứng nhiệm vụ hiệu quả.

Self-attention được điều chỉnh. Như chúng tôi đã thảo luận trong Phần 4.2, prompt tuning thao tác self-attention để điều hướng hành vi của ViTs đã được huấn luyện trước. Chúng tôi trực quan hóa bản đồ self-attention tại các khối thứ 3 (sớm), 7 (giữa) và 12 (muộn) của SSL ViT có và không có phương pháp của chúng tôi trong Hình 5. MAE với prompt tuning chú ý đến một vùng khác trong hình ảnh. Đặc biệt tại khối muộn, MAE với Gated Prompt Tuning chú ý đến đầu đối tượng trong khi MAE chú ý đến ranh giới đối tượng. Ngoài ra, khi chúng tôi thêm nhiệt độ có thể học được, self-attention kết quả khác với khi chỉ sử dụng Gated Prompt Tuning. Điều này cho thấy nhiệt độ có thể học được cũng đóng vai trò trong việc điều chỉnh self-attention.

Hình 4. Tỷ lệ lựa chọn r trên phân loại tinh vi NABirds, Stanford Cars và phân đoạn ngữ nghĩa ADE20K. Tỷ lệ lựa chọn đại diện cho ảnh hưởng của mỗi khối trên biểu diễn prompt của khối cuối cùng.

[Hình ảnh visualization self-attention]

Hình 5. Trực quan hóa bản đồ self-attention của các khối ViT-B/16. Cả prompt tuning và temperature scaling đều điều chỉnh bản đồ self-attention từ MAE. GATE biểu thị Gated Prompt Tuning và LT biểu thị Adaptive Attention Shaping với nhiệt độ có thể học được.

5.4. Nghiên cứu loại bỏ

Trong phần này, chúng tôi tiến hành nghiên cứu loại bỏ về hiệu quả của Gated Prompt Tuning và Adaptive Attention Shaping của chúng tôi. Trong Hình 6, chúng tôi báo cáo những thay đổi hiệu suất khi các thành phần đề xuất của chúng tôi được thêm vào VPT-shallow. Trên tất cả các benchmark và SSL ViTs, Gated Prompt Tuning của chúng tôi liên tục cải thiện hiệu suất từ VPT-shallow. Điều này xác minh rằng tương tác với các khối ViT có chọn lọc thay vì tất cả các khối tăng cường sức mạnh của các token prompt để thích ứng nhiệm vụ. Hơn nữa, Adaptive Attention Shaping với nhiệt độ có thể học được cải thiện hiệu suất trong hầu hết tất cả các trường hợp. Những kết quả này hỗ trợ rằng việc điều chỉnh điểm self-attention với adaptive temperature scaling hỗ trợ prompts mã hóa hướng dẫn cải thiện. Kết quả trên mỗi bộ dữ liệu riêng lẻ được hiển thị trong Phụ lục B.3.

Để đánh giá hiệu quả của thao tác gating, chúng tôi áp dụng các cổng cứng có thể học được được triển khai với Gumbel-Sigmoid (Geng et al., 2020; Jang et al., 2016) cho phương pháp đề xuất của chúng tôi để phân loại CUB và OxfordFlowers. Như được hiển thị trong Bảng 4, việc sử dụng cổng cứng được triển khai với Gumbel-Sigmoid vượt trội hơn VPT-shallow. Điều này chỉ ra rằng tương tác có chọn lọc với các khối ViT hiệu quả trong thích ứng nhiệm vụ sử dụng các token prompt. Phương pháp của chúng tôi với cổng mềm cho thấy hiệu suất cải thiện so với việc sử dụng cổng cứng. Điều này là do cổng mềm cho phép các token prompt tương tác một phần với các khối nếu có bất kỳ yếu tố mong muốn nào cho nhiệm vụ. Mặt khác, cổng cứng sẽ dẫn đến kết quả dưới tối ưu vì chúng loại trừ toàn bộ khối ngay cả khi nó liên quan một phần đến nhiệm vụ.

Hình 6. Nghiên cứu loại bỏ trên các benchmark. Đối với VTAB-1K và FGVC, chúng tôi báo cáo hiệu suất phân loại trung bình, và đối với ADE20K, chúng tôi báo cáo hiệu suất phân đoạn ngữ nghĩa. GATE biểu thị Gated Prompt Tuning và LT biểu thị Adaptive Attention Shaping với nhiệt độ có thể học được.

Ngoài ra, chúng tôi điều tra hiệu quả tham số của phương pháp sử dụng MAE trên bộ dữ liệu Stanford Cars so với VPT-deep bằng cách thay đổi số lượng token prompt đầu vào.

Bảng 4. Nghiên cứu loại bỏ về cổng. Chúng tôi sử dụng MAE như Self-supervised ViT. PT biểu thị token prompt và GH biểu thị cổng cứng được triển khai với hàm Gumbel-Sigmoid.

[Bảng so sánh các phương pháp với cổng cứng và mềm]

Trong Hình 7, phương pháp của chúng tôi vượt trội hơn VPT-deep chỉ với một nửa số token prompt trong tất cả các trường hợp. Ví dụ, bằng cách chỉ sử dụng 24 token prompt, phương pháp của chúng tôi vượt trội hơn VPT-deep với 48 token prompt (66.1% so với 60.9%). Đối với VPT-deep, không thể sử dụng ít hơn 12 token prompt vì nó yêu cầu ít nhất một token prompt cho mỗi khối ViT, nhưng phương pháp của chúng tôi có thể xử lý số lượng token prompt ít hơn 12 và vẫn vượt trội với ít token prompt hơn. Trong Phụ lục B.1, chúng tôi cung cấp kết quả thí nghiệm bổ sung trên các benchmark FGVC và ADE20K, chứng minh rằng Gated Prompt Tuning của chúng tôi sử dụng các token prompt hiệu quả để thích ứng nhiệm vụ.

Hình 7. So sánh hiệu suất giữa VPT-deep và phương pháp của chúng tôi dưới cùng số token prompt. Chúng tôi sử dụng MAE như backbone SSL ViT và đánh giá nó trên bộ dữ liệu Stanford Cars. Đối với VPT-deep, việc sử dụng 12, 24, 48 và 96 token prompt biểu thị rằng 1, 2, 4 và 8 token prompt được chèn vào mỗi khối của ViT-B/16.

6. Công trình liên quan

6.1. Vision Transformers tự giám sát

Vision Transformers tự giám sát đã chứng minh là một backbone đã được huấn luyện trước xuất sắc cho các nhiệm vụ thị giác máy tính (Bao et al., 2021; He et al., 2022; Chen et al., 2021; Xie et al., 2022; Zhou et al., 2021; Caron et al., 2021). MoCo v3 (Chen et al., 2021) và DINO (Caron et al., 2021) đại diện cho phương pháp dựa trên instance, trong đó chúng học các biểu diễn bất biến qua các phép biến đổi ngẫu nhiên. Mô hình hóa hình ảnh có mặt nạ (He et al., 2022; Bao et al., 2021; Zhou et al., 2021; Xie et al., 2022), học các biểu diễn bằng cách khôi phục các patch được che ngẫu nhiên, là một nhánh đầy hứa hẹn khác của học tự giám sát. Việc sử dụng các mô hình này cho các nhiệm vụ thị giác máy tính đa dạng là một chiến lược đầy hứa hẹn, vì chúng đã chứng minh khả năng chuyển giao xuất sắc và hiệu suất cao (He et al., 2022; Chen et al., 2021; Caron et al., 2021; Bao et al., 2021; Zhou et al., 2021). Tuy nhiên, các phương pháp tuning cho Vision Transformers tự giám sát trong quá trình chuyển giao chúng sang các nhiệm vụ thị giác downstream, đặc biệt là tuning dựa trên prompt, đã được khám phá ít hơn.

6.2. Transfer Learning

Transfer learning nhằm sử dụng hiệu quả các mạng nơ-ron đã được huấn luyện trước cho một loạt các nhiệm vụ downstream. Phương pháp cơ bản nhất, fine-tuning đầy đủ, bao gồm việc huấn luyện cả backbone đã được huấn luyện trước và mạng cụ thể cho nhiệm vụ. Gần đây, nghiên cứu đáng kể đã được tiến hành về việc tuning các mô hình lớn đã được huấn luyện trước theo cách hiệu quả về tham số (Jia et al., 2022; Houlsby et al., 2019; Cai et al., 2020; Chen et al., 2022; Bahng et al., 2022; Li & Liang, 2021; Lester et al., 2021; Huang et al., 2023). Cai et al. (2020) đề xuất đóng băng các trọng số và chỉ cập nhật bias của các mô hình đã được huấn luyện trước. Chen et al. (2022) giới thiệu một mô-đun nhẹ bổ sung, được gọi là AdaptMLP, trong mô-đun MLP của các khối ViT và fine-tune nó. Trong số này, prompt tuning sử dụng các nhiễu loạn có thể học được trong không gian embedding hoặc không gian pixel (Jia et al., 2022; Bahng et al., 2022). Tuy nhiên, vì những điều này chủ yếu xử lý các mô hình đã được huấn luyện trước được giám sát, có ít nghiên cứu về tuning hiệu quả tham số cho các ViTs tự giám sát. Trong công trình này, chúng tôi phát triển một phương pháp transfer learning dựa trên prompt cho các ViTs tự giám sát.

6.3. Thảo luận

Phương pháp đề xuất của chúng tôi có thể được hiểu như thực hiện thao tác chia tỷ lệ trên các token prompt sử dụng một cổng. Có các công trình trước đó sử dụng thao tác chia tỷ lệ, như AdaptFormer (Chen et al., 2022), để đạt được fine-tuning hiệu quả của Vision Transformers. Tuy nhiên, công trình của chúng tôi và AdaptFormer khác nhau ở hai khía cạnh. Thứ nhất, vị trí của thao tác chia tỷ lệ trong AdaptFormer khác với thao tác gating của chúng tôi. Trong AdaptFormer, thao tác chia tỷ lệ được áp dụng cho biểu diễn patch, phát sinh từ một nhánh bổ sung trong mô-đun MLP. Ngược lại, trong phương pháp đề xuất của chúng tôi, thao tác gating được tiến hành độc quyền cho token prompt và được đặt giữa các khối Transformer. Thứ hai, mục đích của việc chia tỷ lệ khác nhau. Trong khi thao tác chia tỷ lệ trong AdaptFormer tìm cách cân bằng các đặc trưng không phụ thuộc nhiệm vụ và cụ thể cho nhiệm vụ từ hai nhánh riêng biệt trong mỗi khối, thao tác gating của chúng tôi được thiết kế để điều chỉnh tương tác giữa các token prompt và mỗi khối. Theo hiểu biết tốt nhất của chúng tôi, phương pháp chúng tôi đề xuất đại diện cho một trong những triển khai đầu tiên của thao tác gating trong prompting cho các nhiệm vụ thị giác máy tính.

Trong NLP, một nghiên cứu đồng thời, được gọi là Prompt Gating (Huang et al., 2023), gần đây đã được báo cáo sử dụng các cổng có thể huấn luyện. Phương pháp này nhằm kết hợp các prefix được huấn luyện độc lập, mỗi cái được học riêng biệt cho việc tạo văn bản một khía cạnh, để cho phép tạo văn bản đa khía cạnh có thể kiểm soát trong quá trình suy luận. Một vấn đề phát sinh trong bối cảnh này là các prefix được huấn luyện độc lập cho mỗi khía cạnh tương tác trong một sublayer attention, gây ra nhiễu loạn lẫn nhau và do đó giảm khả năng kiểm soát. Prompt Gating giải quyết vấn đề này bằng cách giới thiệu các cổng chia tỷ lệ lại các prefix cho mỗi khía cạnh, điều chỉnh độ lớn của các prefix cho mỗi khía cạnh trong sublayer attention để giảm thiểu nhiễu loạn lẫn nhau. Phương pháp của chúng tôi khác với Prompt Gating về động lực, mục tiêu và triển khai thao tác gating. Thứ nhất, công trình của chúng tôi được thúc đẩy bởi quan sát rằng các ViTs tự giám sát mã hóa nhiều thông tin hơn trong các khối so với các ViTs được giám sát, do đó khiến việc prompts tập trung vào các khối liên quan đến nhiệm vụ trở nên thách thức. Thứ hai, công trình của chúng tôi nhằm tạo điều kiện cho các tương tác tập trung giữa prompt và các khối liên quan đến nhiệm vụ, trái ngược với việc điều chỉnh tương tác giữa nhiều prompt nhiệm vụ. Để hoàn thành điều này, thao tác gating của chúng tôi hoạt động bằng cách tạo ra một kết hợp lồi của các biểu diễn prompt đầu ra từ khối trước và khối hiện tại. Ngược lại, Prompt Gating chỉ chia tỷ lệ trạng thái ẩn attention của prompt trong khối hiện tại.

7. Kết luận

Trong công trình này, chúng tôi đề xuất một phương pháp chuyển giao dựa trên prompt nâng cao cho các ViTs tự giám sát. Các khối liên quan đến nhiệm vụ trong các ViTs đã được huấn luyện trước phụ thuộc vào các phương pháp huấn luyện trước và nhiệm vụ downstream. Để giải quyết điều này, chúng tôi giới thiệu Gated Prompt Tuning, áp dụng các cổng có thể học được và hướng dẫn prompt tập trung có chọn lọc vào các khối liên quan đến nhiệm vụ để thích ứng nhiệm vụ hiệu quả. Hơn nữa, chúng tôi giới thiệu Adaptive Attention Shaping, điều chỉnh điểm attention và nâng cao thêm hướng dẫn cụ thể cho nhiệm vụ với prompts. Kết quả thí nghiệm rộng rãi trên các benchmark đa dạng xác nhận rằng phương pháp đề xuất của chúng tôi sử dụng các token prompt hiệu quả hơn để thích ứng nhiệm vụ.

Lời cảm ơn

Công trình này được hỗ trợ bởi các khoản tài trợ của Quỹ Nghiên cứu Quốc gia Hàn Quốc (NRF) được tài trợ bởi chính phủ Hàn Quốc (Bộ Khoa học và ICT, MSIT) (2022R1A3B1077720 và 2022R1A5A708390811), Trung tâm AI Hyperscale SNU-Naver, các khoản tài trợ của Viện Lập kế hoạch và Đánh giá Công nghệ Thông tin & Truyền thông (IITP) được tài trợ bởi chính phủ Hàn Quốc (MSIT) (2022-0-00959 và 2021-0-01343: Chương trình Trường Sau đại học AI, SNU), và chương trình BK21 FOUR của Chương trình Giáo dục và Nghiên cứu cho Các Nhà tiên phong ICT Tương lai, Đại học Quốc gia Seoul năm 2023.

--- TRANG 9 và các trang sau ---
[Phần còn lại chứa tài liệu tham khảo và phụ lục với các chi tiết kỹ thuật, bảng kết quả bổ sung và hình ảnh minh họa - được dịch tương tự theo cấu trúc gốc]

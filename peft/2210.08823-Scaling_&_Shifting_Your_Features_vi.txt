# 2210.08823.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2210.08823.pdf
# Kích thước tệp: 3323529 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Chia tỷ lệ & Dịch chuyển Các Đặc trưng của Bạn:
Một Đường chuẩn Mới cho Điều chỉnh Mô hình Hiệu quả
Dongze Lian1Daquan Zhou1;2Jiashi Feng2Xinchao Wang1
1Đại học Quốc gia Singapore2ByteDance
{dongze,xinchao}@nus.edu.sg {zhoudaquan21,jshfeng}@gmail.com
Tóm tắt
Các phương pháp tinh chỉnh hiện tại hoặc điều chỉnh tất cả các tham số của mô hình đã được tiền huấn luyện
(tinh chỉnh đầy đủ), điều này không hiệu quả, hoặc chỉ điều chỉnh lớp tuyến tính cuối cùng (thăm dò tuyến tính), 
điều này gặp phải sự sụt giảm độ chính xác đáng kể so với tinh chỉnh đầy đủ.
Trong bài báo này, chúng tôi đề xuất một phương pháp tinh chỉnh hiệu quả tham số mới được gọi là
SSF, thể hiện rằng các nhà nghiên cứu chỉ cần Chia tỷ lệ và Dịch chuyển các Đặc trưng sâu
được trích xuất bởi một mô hình đã tiền huấn luyện để bắt kịp với hiệu suất của tinh chỉnh đầy đủ. 
Bằng cách này, SSF cũng đáng ngạc nhiên vượt trội hơn các phương pháp tinh chỉnh hiệu quả tham số khác 
ngay cả với số lượng tham số có thể điều chỉnh nhỏ hơn. Hơn nữa, khác với một số phương pháp tinh chỉnh 
hiệu quả tham số hiện tại (ví dụ: Adapter hoặc VPT) mà giới thiệu các tham số bổ sung và chi phí tính toán 
trong các giai đoạn huấn luyện và suy luận, SSF chỉ thêm các tham số có thể học được trong giai đoạn huấn luyện, 
và các tham số bổ sung này có thể được hợp nhất vào trọng số mô hình đã tiền huấn luyện gốc 
thông qua tái tham số hóa trong giai đoạn suy luận. Với SSF được đề xuất, mô hình của chúng tôi 
đạt được cải thiện hiệu suất 2,46% (90,72% so với 88,54%) và 11,48% (73,10% so với 65,57%) 
trên FGVC và VTAB-1k về độ chính xác Top-1 so với tinh chỉnh đầy đủ nhưng chỉ tinh chỉnh khoảng 0,3M tham số. 
Chúng tôi cũng tiến hành nhiều thí nghiệm trên các họ mô hình khác nhau (CNN, Transformer, và MLP) 
và các tập dữ liệu. Kết quả trên tổng cộng 26 tập dữ liệu phân loại hình ảnh và 3 tập dữ liệu mạnh mẽ 
& ngoài phân phối cho thấy hiệu quả của SSF. Mã có sẵn tại https://github.com/dongzelian/SSF .

1 Giới thiệu
Với sự phổ biến của các phương pháp dựa trên dữ liệu trong cộng đồng học sâu, quy mô tập dữ liệu
và kích thước mô hình đều có sự bùng nổ lớn. Có xu hướng khám phá các mô hình lớn và
sau đó áp dụng các mô hình đã tiền huấn luyện này trong các tác vụ hạ nguồn để đạt được hiệu suất tốt hơn 
và hội tụ nhanh hơn, điều này dần trở thành một cách thức phổ biến.

Tuy nhiên, quy trình hiện tại phụ thuộc rất nhiều vào tinh chỉnh đầy đủ, nơi tất cả các tham số của
mô hình được cập nhật. Điều này không thể tránh khỏi khiến mô hình bị quá khớp với tập dữ liệu đích nhỏ 
và do đó không thể được sử dụng cho các tác vụ khác sau khi tinh chỉnh. Kết quả là, thiết bị sẽ cần 
lưu một bộ tham số mô hình chuyên dụng cho mỗi tác vụ, điều này gây ra một lượng lớn không gian lưu trữ, 
đặc biệt là đối với các mô hình lớn ngày nay (ví dụ: ViT-G/14 [16] 1.8G, CoAtNet [10] 2.4G).

Một giải pháp đơn giản cho vấn đề trên là thăm dó tuyến tính [26], nơi chỉ lớp đầu cuối cùng được
tinh chỉnh. Tuy nhiên, thực hành này thường mang lại hiệu suất kém hơn so với đại diện tinh chỉnh đầy đủ. 
Được thúc đẩy bởi sự thành công của chiến lược tinh chỉnh hiệu quả tham số với prompt trong
lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) [36,49,38,30], công việc gần đây thực hiện một đại diện tương tự
trên các tác vụ thị giác [44], được gọi là Điều chỉnh Prompt Trực quan (VPT). Cụ thể, VPT [44] đề xuất
chèn các prompt có thể học được làm đầu vào và nối chúng với các token hình ảnh gốc. Những prompt này

Đóng góp ngang nhau.
Hội nghị lần thứ 36 về Hệ thống Xử lý Thông tin Thần kinh (NeurIPS 2022).arXiv:2210.08823v3  [cs.CV]  15 Jan 2023

--- TRANG 2 ---
Phương pháp Acc.Params.
(M)Không gian tham số
thống nhấtKhông có tham số
suy luận bổ sung
Tinh chỉnh đầy đủ 93.82 85.88 X X
Thăm dò tuyến tính 88.70 0.08 X X
Adapter [36] 93.34 0.31 X 
VPT [44] 93.17 0.54 
SSF (của chúng tôi) 93.99 0.28 X X
Bảng 1: Đặc điểm của các phương pháp tinh chỉnh
khác nhau. Acc. có nghĩa là độ chính xác Top-1
(%) trên CIFAR-100 với một ViT-B/16 đã tiền huấn luyện
để điều chỉnh. Params. có nghĩa là các tham số có thể
học được khi tinh chỉnh. SSF của chúng tôi có
không gian tham số có thể học được thống nhất và
không yêu cầu tham số suy luận bổ sung trong khi
đạt được hiệu suất vượt trội.

Hình 1: So sánh hiệu suất của bảy phương pháp tinh chỉnh 
với mô hình ViT-B/16 đã tiền huấn luyện
trên tập dữ liệu FGVC và benchmark VTAB-1k.
SSF của chúng tôi (các chấm đỏ) đạt được hiệu suất tối tân
chỉ với khoảng 0,3M tham số có thể học được trung bình.

sẽ tương tác với các token hình ảnh bằng cách thực hiện tự chú ý và được cập nhật trong quá trình tinh chỉnh.
Bằng cách này, một cải thiện hiệu suất đáng kể có thể đạt được trong các tác vụ hạ nguồn so với đại diện
thăm dò tuyến tính. Tuy nhiên, so với tinh chỉnh đầy đủ và thăm dò tuyến tính, nó bổ sung gây ra hai vấn đề:
i) VPT điều chỉnh số lượng prompt cho các tác vụ khác nhau, điều này giới thiệu một không gian tham số
có thể học được phụ thuộc vào tác vụ. Hiệu suất tinh chỉnh nhạy cảm với số lượng prompt cho mỗi tác vụ
và cần được thiết kế cẩn thận. Quá ít hoặc quá nhiều prompt có thể làm giảm độ chính xác của tinh chỉnh
hoặc tăng sự dư thừa của tính toán (ví dụ: 200 prompt trên Clevr/count so với 1 prompt trên Flowers102);
ii) VPT [44], cũng như các phương pháp dựa trên Adapter khác [36,60], giới thiệu các tham số bổ sung
và chi phí tính toán trong giai đoạn suy luận so với mô hình đã tiền huấn luyện gốc. Ví dụ, VPT giới thiệu
các đầu vào bổ sung cho tự chú ý với các token hình ảnh. Các phương pháp dựa trên Adapter chèn các
mô-đun bổ sung vào mô hình đã tiền huấn luyện. Những phương pháp này thay đổi kiến trúc backbone
cụ thể hoặc đầu vào của mạng, có thể dẫn đến sự thay đổi cấu trúc thường xuyên và khối lượng công việc
nặng nề, đặc biệt là cho những mô hình đã được triển khai trên các thiết bị biên (ví dụ: điện thoại di động).

Để đối phó với các vấn đề trên, chúng tôi cố gắng tìm một đại diện tổng quát cho tinh chỉnh hiệu quả tham số,
nơi không gian tham số có thể học được được thống nhất (độc lập với tác vụ) và không có tham số suy luận
bổ sung nào được giới thiệu. Được truyền cảm hứng bởi một số phương pháp điều chế đặc trưng [80,40,66],
chúng tôi đề xuất một phương pháp tinh chỉnh hiệu quả tham số mới có tên là SSF, nơi bạn chỉ cần Chia tỷ lệ
và Dịch chuyển các Đặc trưng sâu được trích xuất bởi một mô hình đã tiền huấn luyện để tinh chỉnh.
Trực giác đằng sau phương pháp của chúng tôi đến từ thực tế là các tập dữ liệu thượng nguồn và tập dữ liệu
hạ nguồn có các phân phối dữ liệu khác nhau [71]. Do đó, khó khăn để áp dụng các trọng số mô hình được
huấn luyện trong tập dữ liệu thượng nguồn cho tập dữ liệu hạ nguồn. Ví dụ, một chiến lược thăm dò tuyến
tính ngây thơ với việc giữ đóng băng trọng số của backbone sẽ gây ra sự suy giảm hiệu suất. Để giảm thiểu
vấn đề trên, SSF giới thiệu các tham số tỷ lệ và tham số dịch chuyển, có thể được coi là phương sai và
trung bình để điều chế các đặc trưng của tập dữ liệu hạ nguồn được trích xuất với mô hình đã tiền huấn luyện
trên tập dữ liệu thượng nguồn, sao cho đặc trưng được điều chế rơi vào một không gian phân biệt.
Những tham số tỷ lệ và tham số dịch chuyển này không phụ thuộc vào bất kỳ đầu vào nào và có một
không gian tham số có thể học được thống nhất cho các tác vụ khác nhau. Một ưu điểm khác của SSF
là nó chỉ giới thiệu các phép biến đổi tuyến tính vì chúng tôi chia tỷ lệ và dịch chuyển các đặc trưng
được trích xuất. Những phép biến đổi tuyến tính này có thể được hợp nhất thêm vào trọng số đã tiền huấn
luyện gốc thông qua tái tham số hóa mô hình [15] trong giai đoạn suy luận, do đó tránh được các tham số
và FLOP bổ sung cho các tác vụ hạ nguồn. Đối với một mô hình được triển khai trên các thiết bị biên,
chỉ cần tải lên các trọng số được cập nhật sau tinh chỉnh thay vì thay đổi kiến trúc backbone. Bảng 1 cho thấy
các so sánh đặc điểm cụ thể giữa SSF và các phương pháp tinh chỉnh khác. SSF đơn giản, hiệu quả và
tiết kiệm, điều này cũng phù hợp với nguyên tắc Occam's Razor. Do đó, chúng tôi khám phá đường chuẩn
mới này và thấy rằng nó đáng ngạc nhiên vượt trội hơn tất cả các phương pháp tinh chỉnh hiệu quả tham số khác.

Chúng tôi đánh giá phương pháp của mình trên tổng cộng 26 tập dữ liệu phân loại và 3 tập dữ liệu mạnh mẽ
& ngoài phân phối. SSF đạt được hiệu suất tối tân so với các phương pháp tinh chỉnh hiệu quả tham số khác
với sự đánh đổi giữa tham số có thể huấn luyện và độ chính xác (Bảng 1 và Hình 1). So với tinh chỉnh
đầy đủ, phương pháp của chúng tôi đạt được cải thiện hiệu suất 2,46% (90,72% so với 88,54%) và 11,48%
(73,10% so với 65,57%) trên FGVC và VTAB-1k về độ chính xác Top-1 nhưng chỉ với khoảng 0,3M tham số
có thể huấn luyện. Hơn nữa, SSF của chúng tôi không yêu cầu tham số bổ sung trong giai đoạn suy luận.
Nó có thể cắm và chạy và rất dễ mở rộng cho các họ mô hình khác nhau (CNN, Transformer, và MLP).
SSF của chúng tôi thiết lập một đường chuẩn mới và chúng tôi hy vọng nó mang lại nhiều hiểu biết hơn
vào lĩnh vực điều chỉnh mô hình hiệu quả.

2

--- TRANG 3 ---
2 Công trình Liên quan
2.1 Các Họ Mô hình
Phép tích chập đã được sử dụng trong một thời gian dài như mô-đun chính để trích xuất các đặc trưng hình ảnh
trong các tác vụ thị giác máy tính, và các kiến trúc dựa trên CNN đã được nghiên cứu [70,29,83,57,84,55,87]
với mở rộng trên dữ liệu dựa trên đồ thị [86,85,54]. Gần đây, một họ kiến trúc khác, Transformer,
đã thu hút sự chú ý rộng rãi nhờ vào thành công lớn của nó trong NLP [77,13,38]. Theo hướng này,
Dosovitskiy et al. [16] đầu tiên sử dụng transformer trong lĩnh vực thị giác máy tính và giới thiệu
một mô hình kiến trúc mới, ViT, đạt được kết quả hứa hẹn [88,69]. Tiếp theo, các mô hình dựa trên
transformer khác nhau, chẳng hạn như DeiT [74] và Swin Transformer [56], được giới thiệu và
được chứng minh là hiệu quả trên nhiều tác vụ như phát hiện đối tượng, phân đoạn ngữ nghĩa,
nhận dạng hành động [58], v.v. Trong một hướng khác, Tolstikhin et al. [73] đề xuất một kiến trúc
dựa trên MLP thuần túy, và các bài báo tiếp theo [35,50] đã thú vị chứng minh rằng các kiến trúc
dựa trên MLP có thể bắt kịp với transformer. Tuy nhiên, ngoài các mô-đun được thiết kế tốt,
hiệu suất xuất sắc của chúng cũng được quy cho việc triển khai các mô hình quy mô lớn.
Cho một mô hình quy mô lớn được tiền huấn luyện trên một tập dữ liệu lớn, cách thực hiện
tinh chỉnh hiệu quả tham số trong các tác vụ hạ nguồn là cần thiết nhưng hiện tại ít được khám phá.
Trong bài báo này, chúng tôi đề xuất SSF như một đường chuẩn mới và cho thấy hiệu suất hứa hẹn
của nó với việc xác thực toàn diện trong một loạt các tác vụ đa dạng.

2.2 Tiền huấn luyện và Tinh chỉnh
Các mô hình sớm [29,39,37,83,72] thường được tiền huấn luyện trên tập dữ liệu ImageNet-1K,
và sau đó được tinh chỉnh trên các tác vụ hạ nguồn để đạt được hội tụ nhanh hơn [27] hoặc hiệu suất tốt hơn.
Quy trình như vậy được gọi là tiền huấn luyện và tinh chỉnh, hoặc học chuyển giao. Các công trình gần đây
có xu hướng sử dụng các mô hình lớn hơn (ví dụ: ViT [16] và Swin Transformer V2 [56]) và huấn luyện
chúng trên các tập dữ liệu lớn hơn (ví dụ: ImageNet-21K và JFT-300M) để theo đuổi hiệu suất tốt hơn.
Cả trong lĩnh vực NLP và thị giác máy tính, những mô hình lớn này [13,56,68,25,94,95] đạt được
cải thiện hiệu suất to lớn so với các mô hình quy mô nhỏ và cung cấp trọng số đã tiền huấn luyện
cho các tác vụ hạ nguồn. Một số công trình khác cố gắng khám phá cách tinh chỉnh hiệu quả
các mô hình đã tiền huấn luyện [23,96] trên các tác vụ đích. Ví dụ, cho một tác vụ đích, SpotTune [23]
điều tra lớp nào cần được tinh chỉnh. Touvron et al. [75] thấy rằng tinh chỉnh trọng số của các lớp
chú ý và đóng băng trọng số của các phần khác là đủ để thích nghi các vision transformer với
các tác vụ hạ nguồn khác. Một số công trình cũng đề xuất chèn các adapter vào mạng để tinh chỉnh
theo cách hiệu quả tham số. Những adapter này có thể là một mạng phi tuyến nhỏ [36],
một siêu mạng tạo ra trọng số mô hình [61], hoặc một compactor [60] thực hiện phân tách
hạng thấp để giảm các tham số. Một số công trình cũng đã thử chỉ cập nhật số hạng bias [3,90].
Gần đây hơn, VPT [44] đề xuất chèn một số lượng nhỏ các tham số có thể học được (prompt)
và tối ưu hóa chúng trong khi đóng băng backbone, đạt được cải thiện hiệu suất đáng kể
so với tinh chỉnh đầy đủ. Trong quá trình nộp công trình này, một số phương pháp [5,92]
cũng được đề xuất cho tinh chỉnh hiệu quả tham số, ví dụ: chèn mô-đun adapter hoặc tìm kiếm
prompt thần kinh. Khác với tất cả các công trình trên, chúng tôi đề xuất chia tỷ lệ và dịch chuyển
các đặc trưng sâu được trích xuất bởi một mô hình đã tiền huấn luyện, điều này đơn giản
nhưng hiệu quả và vượt trội hơn các phương pháp tinh chỉnh hiệu quả tham số khác.

2.3 Điều chế Đặc trưng
Nhiều công trình đã cố gắng điều chế các đặc trưng để đạt được hiệu suất tốt hơn. Những công trình
liên quan nhất đến công trình của chúng tôi là các phương pháp chuẩn hóa khác nhau [41,1,80].
BN, LN, và GN thường chuẩn hóa các đặc trưng và sau đó biến đổi chúng tuyến tính với các yếu tố
chia tỷ lệ và dịch chuyển để điều chế phân phối đặc trưng, điều này đã được xác minh là hiệu quả
trong nhiều tác vụ. STN [43] giới thiệu một mô-đun có thể học được để biến đổi không gian
các bản đồ đặc trưng. Trong lĩnh vực tạo hình ảnh, AdaIN [40] tạo ra các yếu tố chia tỷ lệ
và dịch chuyển để đặc trưng hóa các phong cách hình ảnh cụ thể. Tự điều chế [6] cho thấy
các GAN được hưởng lợi từ các lớp tự điều chế trong generator. Trong các tác vụ thị giác-ngôn ngữ,
Conditional BN [11] và FiLM [66] thường được sử dụng để điều chế các đặc trưng của hai phương thức.
Không giống như một số thuật toán như BN, SSF của chúng tôi không bị giới hạn trong việc
điều chế lớp chuẩn hóa, và nó có động lực khác là giảm thiểu sự không khớp phân phối
giữa các tác vụ thượng nguồn và hạ nguồn cho tinh chỉnh hiệu quả tham số. Để so sánh,
chúng tôi cũng tiến hành thí nghiệm trong Phần 4.3 và cho thấy rằng SSF của chúng tôi
hiệu quả hơn so với chỉ điều chỉnh lớp chuẩn hóa. So với STN, AdaIN, FiLM và các phương pháp khác,
phương pháp của chúng tôi độc lập với đầu vào và các tham số chia tỷ lệ và dịch chuyển này
mô hình hóa phân phối của toàn bộ tập dữ liệu để chúng có thể được hấp thụ vào trọng số
mô hình đã tiền huấn luyện gốc trong giai đoạn suy luận.

3

--- TRANG 4 ---
2.4 Tái tham số hóa Mô hình
Tái tham số hóa mô hình đã là một thực hành phổ biến để cải thiện hiệu quả suy luận. Một trong những
kỹ thuật đại diện là gấp chuẩn hóa batch được sử dụng trong các thuật toán nén mô hình [42].
Các tham số được giới thiệu bởi các lớp chuẩn hóa batch [41] được hợp nhất vào các lớp tích chập
thường được xếp chồng trước chúng. Kỹ thuật này được sử dụng thêm để hợp nhất các nhánh
khác nhau của mạng thành một nhánh mới [89,15,14]. Tương tự, SSF của chúng tôi hoàn toàn
áp dụng các phép biến đổi tuyến tính, cho phép các tham số chia tỷ lệ và dịch chuyển trong
giai đoạn huấn luyện được hợp nhất vào trọng số mô hình đã tiền huấn luyện gốc, do đó tránh
được việc giới thiệu các tham số bổ sung và chi phí tính toán trong giai đoạn suy luận.

3 Phương pháp
3.1 Kiến thức Cơ bản
Transformer. Trong một vision transformer (ViT) [16], một hình ảnh RGB I∈R³ᴴˣᵂ được chia thành
N² patch không chồng lấp, và sau đó các patch hình ảnh này được nối thêm một class token
được đưa vào một lớp nhúng theo sau là các khối vision transformer L-lớp với tự chú ý
là hoạt động cốt lõi. Đầu vào x∈R⁽ᴺ²⁺¹⁾ˣᵈ, trong đó d là chiều nhúng, đầu tiên được biến đổi thành
khóa K∈R⁽ᴺ²⁺¹⁾ˣᵈ, giá trị V∈R⁽ᴺ²⁺¹⁾ˣᵈ, và truy vấn Q∈R⁽ᴺ²⁺¹⁾ˣᵈ. Sau đó, chúng ta có thể
tính toán một tự chú ý toàn cục bởi
Attention(Q;K;V) = Softmax(QK^T/√d)V. (1)
Đầu ra của lớp chú ý sẽ được đưa vào một MLP hai lớp để trích xuất thông tin trong chiều kênh.

Adapter. Adapter [36] được chèn vào lớp transformer để tinh chỉnh hiệu quả. Nó là một mô-đun
thắt cổ chai với một vài tham số có thể huấn luyện, chứa một phép chiếu xuống để giảm chiều
đặc trưng, một hàm kích hoạt phi tuyến, và một phép chiếu lên để chiếu trở lại chiều gốc.
Do đó, cho đầu vào x∈R⁽ᴺ²⁺¹⁾ˣᵈ, đầu ra được tính bởi
out = [W_up(σ(W_down x^T))]^T; (2)
trong đó W_down∈R^(d'×d) (với d'≪d), σ, và W_up∈R^(d×d') đại diện cho ma trận chiếu xuống,
hàm phi tuyến, và ma trận chiếu lên tương ứng.

VPT. VPT [44] chèn một số tham số có thể học được (tức là prompt) vào không gian đầu vào
sau lớp nhúng. Những prompt này tương tác với các token hình ảnh gốc bằng cách thực hiện
tự chú ý. Trong quá trình tinh chỉnh, trọng số của mạng backbone được giữ đóng băng và
chỉ có các tham số của prompt được cập nhật. VPT-Shallow chèn prompt trong lớp đầu tiên
trong khi VPT-Deep chèn prompt trong tất cả các lớp của transformer. Giả sử rằng đầu vào
là x∈R⁽ᴺ²⁺¹⁾ˣᵈ, ký hiệu các prompt được chèn là p∈R^(n×d), trong đó n là số lượng prompt,
các token kết hợp x' là
x' = [x;p]; (3)
trong đó x'∈R⁽ᴺ²⁺ⁿ⁺¹⁾ˣᵈ sẽ được đưa vào khối transformer để tự chú ý (Phương trình (1)).

3.2 Chia tỷ lệ và Dịch chuyển Các Đặc trưng của Bạn để Tinh chỉnh
Khác với các phương pháp trên, chúng tôi giới thiệu cả các yếu tố chia tỷ lệ và dịch chuyển
để điều chế các đặc trưng sâu được trích xuất bởi một mô hình đã tiền huấn luyện với
phép biến đổi tuyến tính để khớp với phân phối của một tập dữ liệu đích, như đã đề cập trong Phần 1.
Năm thuộc tính chính được bao gồm trong phương pháp của chúng tôi: i) SSF đạt được hiệu suất
ngang bằng với chiến lược tinh chỉnh đầy đủ; ii) tất cả các tác vụ hạ nguồn có thể được đưa vào
mô hình một cách độc lập mà không dựa vào bất kỳ tác vụ nào khác; iii) mô hình chỉ cần
tinh chỉnh rất ít tham số; iv) không giống như VPT [44], điều chỉnh số lượng prompt cho
mỗi tác vụ, tập hợp các tham số để tinh chỉnh trong SSF không thay đổi khi tác vụ thay đổi,
làm cho nó khả thi để tinh chỉnh thêm các tham số sau này bằng cách thêm nhiều tác vụ hơn
cho học đa tác vụ hoặc học liên tục²; v) nhờ vào phép biến đổi tuyến tính, SSF tránh được
việc giới thiệu các tham số bổ sung và chi phí tính toán trong giai đoạn suy luận, làm cho
phương pháp của chúng tôi không có chi phí thêm.

²Nó cung cấp nhiều tính linh hoạt hơn, điều này không mâu thuẫn với ii).

4

--- TRANG 5 ---
…
γβ(c)SSF-ADA…OP1SSF-ADAOPiSSF-ADAOPKSSF-ADAHeadLayer……OP1OPiOPKHeadLayerscaleshiftInputOutput(a)Training
(b)Pre-trainedmodel&InferenceFrozenTrainableFeature

Hình 2: Quy trình tổng thể của SSF. (a) Quy trình
huấn luyện qua SSF, trong đó một OP có nghĩa là
một thao tác, ví dụ: MSA, MLP hoặc LN. (b) Một
mô hình đã tiền huấn luyện hoặc quy trình suy luận.
(c) SSF-ADA của chúng tôi.

Thiết kế của SSF. SSF thực hiện phép biến đổi tuyến tính để điều chế các đặc trưng cho tinh chỉnh
hiệu quả tham số như được thể hiện trong Hình 2. Trong Hình 2 (a), cho một mô hình được
tiền huấn luyện trong tác vụ thượng nguồn, chúng tôi chèn SSF-ADA³ sau mỗi thao tác (OP)
của mạng để điều chế đặc trưng. Có tổng cộng K OP và những thao tác này có thể chứa
tự chú ý đa đầu (MSA), MLP và chuẩn hóa lớp (LN), v.v. Trong quá trình tinh chỉnh, trọng số
đã tiền huấn luyện trong những thao tác này được giữ đóng băng và các tham số SSF-ADA
được cập nhật. Cấu trúc SSF-ADA cụ thể được thể hiện trong Hình 2 (c), trong đó các đặc trưng
đầu ra từ thao tác trước được thực hiện tích vô hướng với một yếu tố chia tỷ lệ và sau đó
được cộng với một yếu tố dịch chuyển, độc lập với đầu vào. Chính thức, cho đầu vào
x∈R⁽ᴺ²⁺¹⁾ˣᵈ, đầu ra y∈R⁽ᴺ²⁺¹⁾ˣᵈ (cũng là đầu vào của thao tác tiếp theo) được tính bởi
y = γ⊙x + β; (4)
trong đó γ∈Rᵈ và β∈Rᵈ là các yếu tố chia tỷ lệ và dịch chuyển tương ứng. ⊙ là tích vô hướng.

Tái tham số hóa. Vì SSF-ADA là một phép biến đổi hoàn toàn tuyến tính, chúng ta có thể
tái tham số hóa nó bằng cách hấp thụ các số hạng chia tỷ lệ và dịch chuyển vào lớp tuyến tính
trước đó như sau
y = γ⊙x + β = γ⊙(w⊛t + b) + β = (γ⊙w)⊛t + γ⊙b + β; (5)
trong đó w và b là các số hạng trọng số và bias tương ứng. ⊛ đại diện cho thao tác 'tích chập'
trong lớp tích chập hoặc thao tác 'nhân' trong lớp MLP. t là đầu vào của lớp tuyến tính trước đó.
Vì w và b bị đóng băng và γ và β được cập nhật trong tinh chỉnh, γ và β có thể được hợp nhất
vào không gian tham số gốc (w và b) trong giai đoạn suy luận thông qua công thức trên.
Từ góc độ này, SSF-ADA của chúng tôi làm cho việc thực hiện các tác vụ hạ nguồn trở nên
khả thi mà không thêm bất kỳ tham số bổ sung và chi phí tính toán nào, như được thể hiện
trong Hình 2 (b).

Thảo luận. Câu hỏi đầu tiên là tại sao chúng tôi muốn γ và β đầu vào độc lập với đầu vào.
Như FiLM [66] và AdaIN [40] cho thấy, chúng ta có thể đạt được γ và β bằng cách điều kiện
một mẫu hình ảnh, tuy nhiên, điều này có thể gây ra hai khuyết điểm. Một là chúng tôi muốn
γ và β độc lập với đầu vào để đại diện cho phân phối của toàn bộ tập dữ liệu hạ nguồn để
chúng ta có thể sửa đổi phân phối trọng số trước đó để phù hợp với tập dữ liệu hạ nguồn
bằng cách điều chế đặc trưng. Thứ hai, đầu vào có điều kiện yêu cầu giới thiệu một số mạng
bổ sung (ví dụ: MLP) để tạo ra γ và β, điều này giới thiệu nhiều tham số có thể huấn luyện hơn.
Quan trọng hơn, để tạo ra γ và β tốt hơn, một hàm kích hoạt phi tuyến có thể được yêu cầu,
điều này sẽ dẫn đến sự không thể xử lý của tái tham số hóa. Do đó, chúng tôi trực tiếp thực hiện
một phép biến đổi hoàn toàn tuyến tính để hợp nhất các yếu tố γ và β vào trọng số đã tiền huấn luyện
gốc, để trọng số có thể được tải lên dễ dàng các thiết bị biên mà không cần sửa đổi kiến trúc backbone.

Câu hỏi thứ hai là những thao tác nào nên được theo sau bởi SSF-ADA. Kinh nghiệm của chúng tôi
là bạn có thể chèn SSF-ADA sau mỗi thao tác với một hệ số tuyến tính trong ViT. Mặc dù chúng ta
có thể tìm kiếm một số lớp hoặc thao tác tối ưu với Tìm kiếm Kiến trúc Thần kinh (NAS) [67,53,24,51],
để giảm số lượng tham số có thể huấn luyện, chúng tôi tin rằng phương pháp của chúng tôi sẽ
tạo ra kết quả tốt hơn (hoặc không tệ hơn NAS) mà không giới thiệu quá nhiều tham số có thể
huấn luyện có thể được hợp nhất để suy luận, như sẽ được thể hiện trong Phần 4.3.

3.3 Phân tích Độ phức tạp
Chúng tôi cũng so sánh độ phức tạp của Adapter, VPT và SSF của chúng tôi. Lấy một ViT làm ví dụ,
chiều và số lượng token là d và N². Giả sử rằng Adapter chiếu các đặc trưng từ d-dim thành d'-dim
(với d'≪d) để các tham số có thể huấn luyện bổ sung là 2dd' trong mỗi lớp,

³Ở đây, chúng tôi gọi phương pháp được đề xuất của chúng tôi là SSF và mô-đun cụ thể là SSF-ADA.

5

--- TRANG 6 ---
Phương pháp Adapter VPT-Shallow VPT-Deep SSF (của chúng tôi)
# Tham số Bổ sung 2Ldd'(1) nd(1) nLd (1) mLd (0)
# FLOP Bổ sung 2N²Ldd'(1) 2n(2N²+n)d(1) 2n(2N²+n)Ld(1) mN²Ld(0)

Bảng 2: So sánh độ phức tạp của Adapter [36], VPT [44] và SSF của chúng tôi. '(1)': cùng tham số và FLOP cho huấn luyện và suy luận; '(0)': không cần tham số và FLOP bổ sung cho suy luận.

VPT chèn n prompt để đạt được nd tham số bổ sung trong mỗi lớp, và SSF chèn SSF-ADA sau mỗi thao tác với hệ số tuyến tính để đạt được md tham số bổ sung trong mỗi lớp, khi tổng số lớp là L, độ phức tạp của Adapter, VPT và SSF được thể hiện trong Bảng 2. Số lượng cụ thể của các tham số bổ sung được sử dụng bởi Adapter, VPT và SSF phụ thuộc vào các giá trị của d', n và m. Tuy nhiên, trong thực tế, SSF vượt trội hơn Adapter và VPT-Deep ngay cả với số tham số ít hơn một chút trong giai đoạn huấn luyện như chúng ta sẽ thấy trong Phần 4. Hơn nữa, trong giai đoạn suy luận, vay mượn chiến lược tái tham số hóa mô hình, các tham số và FLOP bổ sung của SSF bằng không. Tuy nhiên, độ phức tạp của Adapter và VPT vẫn giống nhau so với huấn luyện, điều này thiết lập những điểm mạnh của phương pháp của chúng tôi.

4 Thí nghiệm
4.1 Cài đặt Thí nghiệm
Tập dữ liệu. Chúng tôi chủ yếu tiến hành thí nghiệm trên một loạt tập dữ liệu có thể được phân loại thành ba loại như chi tiết dưới đây:

FGVC. Theo VPT [44], chúng tôi sử dụng năm tập dữ liệu Phân loại Thị giác Hạt mịn (FGVC) để đánh giá hiệu quả của SSF được đề xuất của chúng tôi, bao gồm CUB-200-2011 [79], NABirds [76], Oxford Flowers [64], Stanford Dogs [46] và Stanford Cars [18].

VTAB-1k. Benchmark VTAB-1k được giới thiệu trong [91], chứa 19 tác vụ từ các lĩnh vực đa dạng: i) Hình ảnh tự nhiên được chụp bởi camera tiêu chuẩn; ii) Hình ảnh chuyên biệt được chụp bởi camera không tiêu chuẩn, ví dụ: camera viễn thám và y tế; iii) Hình ảnh có cấu trúc được tổng hợp từ các môi trường mô phỏng. Benchmark này chứa nhiều tác vụ đa dạng (ví dụ: đếm đối tượng, ước lượng độ sâu) từ các lĩnh vực hình ảnh khác nhau và mỗi tác vụ chỉ chứa 1.000 mẫu huấn luyện, do đó cực kỳ thách thức.

Tập dữ liệu Phân loại Hình ảnh Tổng quát. Chúng tôi cũng xác thực hiệu quả của SSF trên các tác vụ phân loại hình ảnh tổng quát. Chúng tôi chọn các tập dữ liệu CIFAR-100 [47] và ImageNet-1K [12] làm tập dữ liệu đánh giá, trong đó CIFAR-100 chứa 60.000 hình ảnh với 100 danh mục. ImageNet-1K chứa 1,28M hình ảnh huấn luyện và 50K hình ảnh xác thực với 1.000 danh mục, là các tập dữ liệu rất lớn cho nhận dạng đối tượng.

Mô hình. Để so sánh công bằng, chúng tôi theo VPT [44] và chủ yếu chọn mô hình ViT-B/16 [16] được tiền huấn luyện trên ImageNet-21K làm khởi tạo để tinh chỉnh. Ngoài ra, chúng tôi cũng tổng quát hóa phương pháp của mình cho các backbone của các họ mô hình khác nhau, bao gồm Swin Transformer [56] gần đây (Swin-B), ConvNeXt-B [57] và AS-MLP-B [50]. Cái trước xây dựng một kiến trúc transformer dựa trên phân cấp, và hai cái sau thuộc về kiến trúc dựa trên CNN và kiến trúc dựa trên MLP tương ứng.

Đường chuẩn. Chúng tôi đầu tiên so sánh phương pháp của mình với hai phương pháp tinh chỉnh cơ bản: i) tinh chỉnh đầy đủ, trong đó tất cả các tham số của mô hình được cập nhật khi tinh chỉnh; ii) thăm dò tuyến tính, trong đó chỉ các tham số của đầu phân loại (một lớp MLP) được cập nhật. Chúng tôi cũng so sánh phương pháp của mình với các phương pháp tinh chỉnh hiệu quả tham số gần đây: iii) Adapter [36], trong đó một cấu trúc adapter mới với phép chiếu lên, hàm phi tuyến, và phép chiếu xuống được chèn vào transformer và chỉ các tham số của mô-đun mới này được cập nhật; iv) Bias [90], trong đó tất cả các số hạng bias của tham số được cập nhật; v) VPT [44], trong đó các prompt được chèn vào transformer như các token đầu vào và chúng được cập nhật khi tinh chỉnh.

Chi tiết Triển khai. Đối với các tập dữ liệu FGVC, chúng tôi xử lý hình ảnh với cắt thay đổi kích thước ngẫu nhiên thành 224×224 và lật ngang ngẫu nhiên để tăng cường dữ liệu. Đối với VTAB-1k, chúng tôi trực tiếp thay đổi kích thước hình ảnh thành 224×224, theo cài đặt mặc định trong VTAB [91]. Đối với CIFAR-100 và ImageNet-1K, chúng tôi theo cài đặt tinh chỉnh của ViT-B/16 trong [16], nơi các chiến lược tăng cường dữ liệu mạnh hơn được áp dụng. Chúng tôi sử dụng bộ tối ưu hóa AdamW [59] để tinh chỉnh các mô hình trong 100 epoch cho CIFAR-100, và 30 epoch cho ImageNet-1K. Chiến lược phân rã cosine được áp dụng cho lịch trình tỷ lệ học, và khởi động tuyến tính được sử dụng trong 10 epoch đầu tiên cho CIFAR-100 và 5 epoch cho ImageNet-1K.

6

--- TRANG 7 ---
Phương pháp Tập dữ liệu CUB-200-2011 NABirds Oxford Flowers Stanford Dogs Stanford Cars Trung bình Params. (M)
Tinh chỉnh đầy đủ 87.3 82.7 98.8 89.4 84.5 88.54 85.98
Thăm dò tuyến tính 85.3 75.9 97.9 86.2 51.3 79.32 0.18
Adapter [36] 87.1 84.3 98.5 89.8 68.6 85.67 0.41
Bias [90] 88.4 84.2 98.8 91.2 79.4 88.41 0.28
VPT-Shallow [44] 86.7 78.8 98.4 90.7 68.7 84.62 0.25
VPT-Deep [44] 88.5 84.2 99.0 90.2 83.6 89.11 0.85
SSF (của chúng tôi) 89.5 85.7 99.6 89.6 89.2 90.72 0.39

Bảng 3: So sánh hiệu suất trên năm tập dữ liệu FGVC với các mô hình ViT-B/16 được tiền huấn luyện trên ImageNet-21K.

Tự nhiên Chuyên biệt Có cấu trúc
Phương pháp Tập dữ liệu CIFAR-100 Caltech101 DTD Flowers102 Pets SVHN Sun397 Patch Camelyon EuroSAT Resisc45 Retinopathy Clevr/count Clevr/distance DMLab KITTI/distance dSprites/loc dSprites/ori SmallNORB/azi SmallNORB/ele Trung bình Params. (M)
Tinh chỉnh đầy đủ [44] 68.9 87.7 64.3 97.2 86.9 87.4 38.8 79.7 95.7 84.2 73.9 56.3 58.6 41.7 65.5 57.5 46.7 25.7 29.1 65.57 85.84
Thăm dò tuyến tính [44] 63.4 85.0 63.2 97.0 86.3 36.6 51.0 78.5 87.5 68.6 74.0 34.3 30.6 33.2 55.4 12.5 20.0 9.6 19.2 52.94 0.04
Adapter [36] 74.1 86.1 63.2 97.7 87.0 34.6 50.8 76.3 88.0 73.1 70.5 45.7 37.4 31.2 53.2 30.3 25.4 13.8 22.1 55.82 0.27
Bias [90] 72.8 87.0 59.2 97.5 85.3 59.9 51.4 78.7 91.6 72.9 69.8 61.5 55.6 32.4 55.9 66.6 40.0 15.7 25.1 62.05 0.14
VPT-Shallow [44] 77.7 86.9 62.6 97.5 87.3 74.5 51.2 78.2 92.0 75.6 72.9 50.5 58.6 40.5 67.1 68.7 36.1 20.2 34.1 64.85 0.11
VPT-Deep [44] 78.8 90.8 65.8 98.0 88.3 78.1 49.6 81.8 96.1 83.4 68.4 68.5 60.0 46.5 72.8 73.6 47.9 32.9 37.8 69.43 0.60
SSF (của chúng tôi) 69.0 92.6 75.1 99.4 91.8 90.2 52.9 87.4 95.9 87.4 75.5 75.9 62.3 53.3 80.6 77.3 54.9 29.5 37.9 73.10 0.24

Bảng 4: So sánh hiệu suất trên benchmark VTAB-1k với các mô hình ViT-B/16 được tiền huấn luyện trên ImageNet-21K.

4.2 So sánh Hiệu suất trên Phân loại Hình ảnh
Chúng tôi so sánh hiệu suất của SSF và các phương pháp đường chuẩn khác trong 26 tác vụ phân loại hình ảnh và kết quả trên FGVC và VTAB-1k được thể hiện trong Bảng 3 và Bảng 4 (cũng xem Hình 1) tương ứng, và kết quả trên CIFAR-100 và ImageNet-1K được thể hiện trong Bảng 5, được đánh giá bằng độ chính xác Top-1 (%). Trong ba bảng này, phông chữ đậm hiển thị độ chính xác tốt nhất của tất cả các phương pháp và phông chữ gạch dưới hiển thị độ chính xác tốt thứ hai.

Chúng tôi có những phát hiện sau bằng cách quan sát chúng: i) Trong Bảng 3 và Bảng 4, trong đó cột cuối cùng là trung bình của các tham số tinh chỉnh cho mỗi phương pháp trên các tập dữ liệu tương ứng, SSF của chúng tôi vượt trội hơn VPT [44] và các phương pháp tinh chỉnh hiệu quả tham số khác, và thậm chí đạt được hiệu suất tốt hơn tinh chỉnh đầy đủ, chủ yếu là do phép biến đổi tuyến tính được áp dụng trên các đặc trưng. Cụ thể, SSF đạt được cải thiện độ chính xác 1,81% (90,72% so với 89,11%) và 2,46% (90,72% so với 88,54%) trên năm tập dữ liệu FGVC, và cải thiện 5,29% (73,10% so với 69,43%) và 11,48% (73,10% so với 65,57%) trên benchmark VTAB-1k so với VPT và tinh chỉnh đầy đủ. Trong khi đó, SSF cũng sử dụng ít tham số có thể huấn luyện hơn so với VPT-Deep trong cả hai tập dữ liệu (0,39M so với 0,85M, 0,24M so với 0,60M). SSF duy trì một không gian tham số có thể học được thống nhất cho các tác vụ khác nhau với một vài tham số trong khi VPT [44] cần thiết kế số lượng prompt khác nhau cho mỗi tác vụ, điều này cũng cho thấy sự ngắn gọn của phương pháp của chúng tôi; ii) Trong Bảng 5, tức là trong CIFAR-100 và ImageNet-1K, SSF và các phương pháp tinh chỉnh hiệu quả tham số khác gặp khó khăn trong việc đạt được hiệu suất tương tự như tinh chỉnh đầy đủ, có thể là do các tập dữ liệu này có đủ dữ liệu để ngăn chặn quá khớp của mô hình, đặc biệt là trong ImageNet-1K. Ngược lại, trong benchmark VTAB-1k, lượng dữ liệu không quá lớn (ví dụ: chỉ 1.000 hình ảnh huấn luyện), có thể gây ra quá khớp của mô hình cho tinh chỉnh đầy đủ. Tuy nhiên, trong CIFAR-100 và ImageNet-1K, SSF của chúng tôi vẫn vượt trội hơn các phương pháp tinh chỉnh hiệu quả tham số trước đây (Adapter, Bias, và VPT), điều này cho thấy hiệu quả của phương pháp của chúng tôi; iii) Trong Bảng 5, kết quả của SSF của chúng tôi với các mô hình Swin Transformer, ConvNeXt, và AS-MLP liên tục vượt trội hơn các phương pháp tinh chỉnh hiệu quả tham số khác, điều này cũng xác minh hiệu quả của SSF trên một loạt các mô hình đa dạng.

Chi phí Tính toán. Để xác thực hiệu quả của phương pháp của chúng tôi, chúng tôi hiển thị chi phí tính toán của SSF trong Hình 3. Chúng tôi sử dụng kích thước batch là 16 cho giai đoạn huấn luyện và giai đoạn suy luận, và sử dụng huấn luyện độ chính xác hỗn hợp. Tất cả kết quả chạy trong Hình 3 được đo trên một GPU GeForce RTX 2080Ti duy nhất. Chúng ta có thể thấy rằng SSF có thời gian huấn luyện và bộ nhớ huấn luyện tương tự như VPT nhưng với

7

--- TRANG 8 ---
Mô hình ViT-B/16 [16] Swin-B [56] ConvNeXt-B [57] AS-MLP-B [50]
Phương pháp Tập dữ liệu CIFAR-100 Params. (M) ImageNet-1K Params. (M) CIFAR-100 Params. (M) ImageNet-1K Params. (M) CIFAR-100 Params. (M) ImageNet-1K Params. (M) CIFAR-100 Params. (M)
Tinh chỉnh đầy đủ 93.82 85.88 83.58 86.57 93.85 86.85 85.20 88.03 94.14 87.67 85.80 88.85 89.96 86.83
Thăm dò tuyến tính 88.70 0.08 82.04 0.77 89.27 0.10 83.25 1.03 89.20 0.10 84.05 1.03 79.04 0.10
Adapter [36] 93.34 0.31 82.72 1.00 92.49 0.33 83.82 1.26 92.86 0.45 84.49 1.37 88.01 0.33
Bias [90] 93.39 0.18 82.74 0.87 92.19 0.24 83.92 1.16 92.80 0.23 84.63 1.16 87.46 0.26
VPT-Shallow [44] 90.38 0.23 82.08 0.92 90.02 0.13 83.29 1.05 - - - - - -
VPT-Deep [44] 93.17 0.54 82.45 1.23 92.62 0.70 83.44 1.63 - - - - - -
SSF (của chúng tôi) 93.99 0.28 83.10 0.97 93.06 0.37 84.40 1.29 93.45 0.36 84.85 1.28 88.28 0.37

Bảng 5: So sánh hiệu suất trên CIFAR-100 và ImageNet-1K với các họ mô hình khác nhau, trong đó ViT-B/16, Swin-B, và ConvNeXt-B được tiền huấn luyện trên ImageNet-21K, và AS-MLP-B được tiền huấn luyện trên ImageNet-1K.

[Biểu đồ về thời gian huấn luyện, bộ nhớ huấn luyện, thời gian kiểm tra, và bộ nhớ kiểm tra]

Hình 3: Chi phí tính toán của các phương pháp điều chỉnh khác nhau. Từ trái sang phải: thời gian huấn luyện, bộ nhớ huấn luyện, thời gian kiểm tra, và bộ nhớ kiểm tra.

thời gian suy luận và bộ nhớ suy luận ít hơn. Ở đây, chúng tôi hiển thị chi phí tính toán của VPT với 200/50 prompt (cùng số lượng prompt để đạt được hiệu suất trong Bảng 5) cho VPT-Shallow và VPT-Deep tương ứng. Khi thêm số lượng prompt, chi phí thời gian và bộ nhớ sẽ lớn hơn nhưng SSF của chúng tôi đạt được suy luận không có chi phí thêm, điều này có lợi thế hơn.

4.3 Tác động của Các Thiết kế Khác nhau
Là hoạt động cốt lõi của SSF, chúng tôi đánh giá kỹ lưỡng cách SSF-ADA ảnh hưởng đến kết quả, ví dụ: các vị trí chèn, khởi tạo của SSF-ADA và các thành phần của nó. Chúng tôi tiến hành thí nghiệm để phân tích tác động của các thiết kế khác nhau để tinh chỉnh. Tất cả thí nghiệm được thực hiện với các mô hình ViT-B/16 đã tiền huấn luyện trên CIFAR-100 và kết quả được thể hiện trong Bảng 6.

Tác động của số lượng lớp. Chúng tôi trực tiếp chèn SSF-ADA vào các lớp khác nhau để đánh giá hiệu quả của việc chèn lớp, và kết quả được thể hiện trong bảng 6a. Các giá trị trong cột #layers chỉ ra số lượng lớp với SSF-ADA, trong đó #layers-0 đại diện cho thăm dò tuyến tính. Từ hàng thứ nhất và thứ hai, chúng tôi thấy rằng kết quả sẽ cải thiện từ 88,70% lên 92,69% và tăng với một số lượng nhỏ các tham số có thể huấn luyện (0,08M so với 0,11M) khi chỉ chèn SSF-ADA vào hai lớp đầu tiên. Tiếp tục thêm SSF-ADA trong các lớp tiếp theo sẽ làm cho kết quả tốt hơn. Sự tăng trưởng của kết quả gần như tuyến tính với số lượng lớp của SSF-ADA được chèn. Do đó, chúng tôi trực tiếp chọn chèn SSF-ADA vào tất cả (12) lớp của vision transformer để mang lại kết quả tốt nhất (93,99%) với 0,28M tham số có thể huấn luyện.

Tác động của các vị trí chèn khác nhau. Dựa trên các hoạt động khác nhau của ViT, chúng tôi đánh giá tác động của các vị trí chèn của SSF-ADA. Chúng tôi riêng biệt loại bỏ SSF-ADA sau các hoạt động này và kết quả được thể hiện trong Bảng 6b. Chúng tôi thấy rằng loại bỏ SSF-ADA trong hoạt động MLP đạt được kết quả kém hơn so với loại bỏ những cái trong hoạt động Attention (93,46% so với 93,69%) với các tham số có thể huấn luyện tương đương (0,19M so với 0,21M), điều này cho thấy rằng việc thực hiện điều chế đặc trưng cho hoạt động MLP có thể quan trọng hơn. Mặc dù có thể sử dụng NAS để tìm kiếm tầm quan trọng của các hoạt động khác nhau và do đó chèn SSF-ADA vào các vị trí cụ thể, kết quả có thể không tốt hơn so với chèn SSF-ADA vào tất cả các hoạt động. Do đó, để đạt được hiệu suất xuất sắc, chúng tôi không thực hiện NAS mà trực tiếp chèn SSF-ADA vào tất cả các hoạt động.

8

--- TRANG 9 ---
#layers Acc. Params.
0 88.70 0.08
2 92.69 0.11
4 93.30 0.15
8 93.60 0.22
12 (của chúng tôi) 93.99 0.28
(a)

location Acc. Params.
w/o. mlp 93.46 0.19
w/o. attn 93.69 0.21
w/o. embed 93.91 0.28
w/o. norm 93.80 0.25
ours 93.99 0.28
(b)

initialization Acc.
random 90.11
constant 93.91
uniform 93.87
trunc_normal 93.93
normal (của chúng tôi) 93.99
(c)

case Acc. Params.
w/o. scale 93.49 0.18
w/o. shift 93.74 0.18
only norm 93.26 0.11
scalar scale 93.59 0.18
ours 93.99 0.28
(d)

Bảng 6: Tác động của các thiết kế khác nhau. (a) Tác động của số lượng lớp với SSF-ADA. (b) Tác động của các vị trí chèn khác nhau của SSF-ADA. (c) Tác động của khởi tạo. (d) Tác động của các thành phần khác nhau. Acc.: Độ chính xác Top-1 (%); Params.: tham số (M).

Tác động của khởi tạo. Chúng tôi cũng điều tra cách các cách khởi tạo khác nhau của các yếu tố chia tỷ lệ và dịch chuyển ảnh hưởng đến hiệu suất trong Bảng 6c. Trong các thí nghiệm của chúng tôi, chúng tôi đầu tiên khởi tạo ngẫu nhiên cả tham số chia tỷ lệ và dịch chuyển với giá trị trung bình bằng không, nhưng thấy rằng hiệu suất kém (90,11%) và không thể hội tụ trong một số thí nghiệm. Sau đó, chúng tôi khởi tạo ngẫu nhiên yếu tố chia tỷ lệ với giá trị trung bình bằng một và thấy hiệu suất tốt hơn, điều này ngụ ý rằng trọng số của một mô hình đã tiền huấn luyện không nên bị phá vỡ hoàn toàn trong tinh chỉnh, thay vào đó, chúng ta nên bắt đầu từ mô hình đã tiền huấn luyện này để tối ưu hóa mô hình của chúng ta. Thí nghiệm cho thấy rằng sử dụng khởi tạo bình thường đạt được hiệu suất tốt nhất, trong đó các giá trị trung bình của yếu tố chia tỷ lệ và yếu tố dịch chuyển là một và không tương ứng.

Tác động của các thành phần khác nhau. Chúng tôi cũng đánh giá tác động của các thành phần khác nhau trong SSF-ADA và kết quả được thể hiện trong Bảng 6d. Chúng tôi thấy rằng loại bỏ số hạng chia tỷ lệ mang lại hiệu suất tệ hơn so với loại bỏ số hạng dịch chuyển với cùng tham số có thể huấn luyện, điều này cho thấy rằng số hạng chia tỷ lệ có thể quan trọng hơn số hạng dịch chuyển. Ngoài ra, lưu ý rằng sự khác biệt giữa 'w/o. scale' và phương pháp 'Bias' trong Bảng 5 là chúng tôi tinh chỉnh mô hình với một số hạng dịch chuyển bổ sung trong 'w/o. scale', trong khi 'Bias' tinh chỉnh mô hình dựa trên các bias gốc, cho thấy rằng tinh chỉnh mô hình theo cách giống res có thể đạt được hiệu suất tốt hơn một chút (93,49% so với 93,39%). Chúng tôi cũng thử chỉ tinh chỉnh tất cả các yếu tố chia tỷ lệ và dịch chuyển trong lớp chuẩn hóa (LN), hoặc tinh chỉnh mô hình với SSF nhưng đặt số hạng chia tỷ lệ như một vô hướng. Những thí nghiệm này mang lại hiệu suất kém hơn so với SSF (93,26% so với 93,99%, 93,59% so với 93,99%), nhưng có thể được coi là một sự thay thế do thực tế là chúng chỉ sử dụng khoảng một nửa số tham số có thể huấn luyện của SSF.

4.4 So sánh Hiệu suất trên Tập dữ liệu Mạnh mẽ và OOD

Phương pháp Tập dữ liệu IN-1K (↑) IN-A (↑) IN-R (↑) IN-C (↓)
Tinh chỉnh đầy đủ 83.58 34.49 51.29 46.47
Thăm dò tuyến tính 82.04 33.91 52.87 46.91
Adapter [36] 82.72 42.21 54.13 42.65
Bias [90] 82.74 42.12 55.94 41.90
VPT-Shallow [44] 82.08 30.93 53.72 46.88
VPT-Deep [44] 82.45 39.10 53.54 43.10
SSF (của chúng tôi) 83.10 45.88 56.77 41.47

Bảng 7: So sánh hiệu suất trên tập dữ liệu mạnh mẽ và ngoài phân phối. 'IN' có nghĩa là ImageNet. Hiệu suất trên IN-1K, IN-A và IN-R được đánh giá bằng độ chính xác Top-1 (%). Hiệu suất trên IN-C được đánh giá bằng mCE (lỗi tham nhũng trung bình). Càng thấp (↓), càng tốt.

Chúng tôi cũng tiến hành thí nghiệm để phân tích khả năng mạnh mẽ và Ngoài Phân phối (OOD) của phương pháp SSF của chúng tôi với các tập dữ liệu sau: ImageNet-A, ImageNet-R và ImageNet-C. Vui lòng tham khảo Phụ lục A.2 để biết chi tiết của chúng. Chúng tôi thực hiện đánh giá mạnh mẽ và OOD trên ba tập dữ liệu này với các mô hình được tinh chỉnh trên ImageNet-1K. Tất cả kết quả thí nghiệm được liệt kê trong Bảng 7.

Từ bảng này, chúng ta có thể thấy rằng SSF của chúng tôi đạt được hiệu suất tốt hơn so với VPT và các phương pháp tinh chỉnh hiệu quả tham số khác trên ba tập dữ liệu, điều này cho thấy phương pháp tinh chỉnh của chúng tôi có khả năng tổng quát hóa mạnh mẽ hơn và ngoài phân phối. Hơn nữa, mặc dù SSF có độ chính xác thấp hơn so với tinh chỉnh đầy đủ trên ImageNet-1K, hiệu suất trên ImageNet-A, ImageNet-R và ImageNet-C tốt hơn, điều này cũng cho thấy hiệu suất giữa ImageNet-1K và ImageNet-A/R/C không tương quan tích cực tuyệt đối. Những cải thiện như vậy trong tập dữ liệu mạnh mẽ và OOD có thể đến từ thực tế là SSF đóng băng hầu hết các tham số đã tiền huấn luyện, điều này bảo tồn tối đa kiến thức học được từ tập dữ liệu quy mô lớn và do đó duy trì khả năng tổng quát hóa tốt hơn.

4.5 Trực quan hóa và Phân tích
Mặc dù mục tiêu của chúng tôi là điều chế các đặc trưng được trích xuất bởi một mô hình đã tiền huấn luyện, các tham số chia tỷ lệ và dịch chuyển thực sự độc lập với đầu vào. Do đó, các tham số này cũng có thể được coi là mã hóa thông tin của toàn bộ tập dữ liệu hạ nguồn. Sau khi tái tham số hóa, những tham số chia tỷ lệ và

9

--- TRANG 10 ---
Layer1Layer1Layer4Layer8Layer11
Layer1Layer4Layer8Layer11
(a) Mô hình đã tiền huấn luyện so với Mô hình được tinh chỉnh thông qua SSF.
Layer1
Layer1Layer4Layer8Layer11
Layer1Layer4Layer8Layer11 (b) Mô hình đã tiền huấn luyện so với Mô hình được tinh chỉnh đầy đủ.

Hình 4: So sánh phân phối tham số giữa mô hình đã tiền huấn luyện gốc và các phương pháp tinh chỉnh khác nhau. Hàng đầu tiên hiển thị phân phối trọng số và hàng thứ hai là phân phối bias. Biểu đồ màu xanh cho thấy mô hình đã tiền huấn luyện gốc, và biểu đồ màu cam cho thấy mô hình được tinh chỉnh thông qua SSF trong (a) và mô hình được tinh chỉnh đầy đủ trong (b).

dịch chuyển này được hấp thụ vào trọng số mô hình gốc. Để hiểu rõ hơn thông tin học được bởi SSF, chúng tôi trực quan hóa các phân phối của trọng số và bias trước và sau khi tinh chỉnh thông qua SSF trong Hình 4a. Chúng ta có thể thấy rằng các tham số chia tỷ lệ và dịch chuyển điều chỉnh trọng số và bias gốc, và thay đổi phân phối của trọng số và bias để phù hợp với tác vụ hạ nguồn.

[Biểu đồ độ tương tự đặc trưng qua các lớp]

Hình 5: Trực quan hóa độ tương tự đặc trưng giữa tinh chỉnh đầy đủ và thăm dò tuyến tính, tinh chỉnh đầy đủ và VPT-Deep, tinh chỉnh đầy đủ và SSF, trong các lớp khác nhau của ViT-B/16.

Để so sánh, chúng tôi cũng trực quan hóa phân phối trọng số gốc và phân phối trọng số sau khi tinh chỉnh đầy đủ trong Hình 4b, từ đó chúng tôi có thể thấy một hiện tượng thú vị rằng tinh chỉnh đầy đủ không thay đổi phân phối của trọng số và bias nhiều, nhưng có thể chỉ một phần nhỏ các giá trị bị thay đổi. Đáng chú ý rằng mặc dù SSF không khớp với phân phối trọng số của tinh chỉnh đầy đủ, nó đạt được hiệu suất tốt hơn (93,99% so với 93,82% trong Bảng 5) trên CIFAR-100.

Để điều tra thêm tại sao SSF có thể đạt được hiệu suất vượt trội, ngoài phân phối trọng số, chúng tôi cũng trực quan hóa độ tương tự đặc trưng giữa tinh chỉnh đầy đủ và thăm dò tuyến tính, tinh chỉnh đầy đủ và VPT-Deep, tinh chỉnh đầy đủ và SSF, như được thể hiện trong Hình 5. Trong lớp cuối cùng, SSF có đặc trưng tương tự nhất với tinh chỉnh đầy đủ và độ chính xác cũng gần nhất. Điều này cho thấy rằng ngay cả khi phân phối trọng số học được bởi SSF khác với tinh chỉnh đầy đủ, SSF cũng có thể trích xuất các đặc trưng của hình ảnh trong tác vụ hạ nguồn rất tốt, điều này xác thực hiệu quả của phương pháp của chúng tôi.

5 Kết luận
Trong bài báo này, chúng tôi tập trung vào tinh chỉnh hiệu quả tham số và đề xuất một phương pháp SSF để chia tỷ lệ và dịch chuyển các đặc trưng được trích xuất bởi một mô hình đã tiền huấn luyện. Trực giác đằng sau phương pháp của chúng tôi đến từ việc giảm thiểu sự không khớp phân phối giữa các tác vụ thượng nguồn và hạ nguồn bằng cách điều chế các đặc trưng sâu. SSF đáng ngạc nhiên vượt trội hơn các phương pháp tinh chỉnh hiệu quả tham số khác với một số lượng nhỏ các tham số có thể học được. Bên cạnh đó, các tham số chia tỷ lệ và dịch chuyển được giới thiệu trong quá trình tinh chỉnh có thể được hợp nhất vào trọng số mô hình đã tiền huấn luyện gốc thông qua tái tham số hóa trong giai đoạn suy luận, do đó tránh được các tham số và FLOP bổ sung. Với phương pháp SSF được đề xuất, mô hình của chúng tôi đạt được cải thiện hiệu suất 2,46% (90,72% so với 88,54%) và 11,48% (73,10% so với 65,57%) trên FGVC và VTAB-1k về độ chính xác Top-1 so với tinh chỉnh đầy đủ nhưng chỉ tinh chỉnh khoảng 0,3M tham số. Thí nghiệm trên tổng cộng 26 tập dữ liệu phân loại hình ảnh và 3 tập dữ liệu mạnh mẽ & ngoài phân phối với các họ mô hình khác nhau (CNN, Transformer, và MLP) cho thấy hiệu quả của SSF, thiết lập một đường chuẩn mới.

Lời cảm ơn
Các tác giả ghi nhận sự hỗ trợ từ Quỹ Nghiên cứu Quốc gia Singapore ("CogniVision – Máy ảnh nhận thức và chú ý luôn bật tự trị năng lượng cho thị giác thời gian thực phân tán với mức tiêu thụ điện năng milliwatt" cấp NRF-CRP20-2017-0003) – www.green-ic.org/ CogniVision. Xinchao Wang là tác giả liên lạc.

10

[Tiếp tục với các trang còn lại...]

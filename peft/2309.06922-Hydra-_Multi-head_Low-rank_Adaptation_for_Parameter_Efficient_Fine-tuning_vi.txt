# Hydra: Thích ứng Đa đầu Thứ hạng Thấp cho Tinh chỉnh Hiệu quả Tham số

Sanghyeon Kim1* Hyunmo Yang2* Younghyun Kim2* Youngjoon Hong3†
Eunbyung Park1,2†

1Khoa Kỹ thuật Điện và Máy tính, Đại học Sungkyunkwan
2Khoa Trí tuệ Nhân tạo, Đại học Sungkyunkwan
3Khoa Khoa học Toán học, KAIST

## Tóm tắt

Sự gia tăng gần đây của các mô hình nền tảng quy mô lớn đã thúc đẩy sự phát triển của các phương pháp hiệu quả để thích ứng những mô hình này với các tác vụ hạ nguồn khác nhau. Các phương pháp thích ứng thứ hạng thấp, như LoRA, đã nhận được sự chú ý đáng kể do hiệu quả tham số xuất sắc và không có độ trễ suy luận bổ sung. Bài báo này điều tra một dạng tổng quát hơn của mô-đun adapter dựa trên phân tích rằng các nhánh thích ứng song song và tuần tự học các đặc trưng mới và tổng quát trong quá trình tinh chỉnh, tương ứng. Phương pháp được đề xuất, có tên là Hydra, do các nhánh tính toán đa đầu của nó, kết hợp nhánh song song và tuần tự để tích hợp khả năng, có tính biểu đạt cao hơn các phương pháp nhánh đơn hiện có và cho phép khám phá một phạm vi rộng hơn các điểm tối ưu trong quá trình tinh chỉnh. Ngoài ra, phương pháp thích ứng được đề xuất tận dụng rõ ràng các trọng số được tiền huấn luyện bằng cách thực hiện kết hợp tuyến tính của các đặc trưng được tiền huấn luyện. Điều này cho phép các đặc trưng học được có hiệu suất tổng quát hóa tốt hơn trên các tác vụ hạ nguồn đa dạng. Hơn nữa, chúng tôi thực hiện phân tích toàn diện về đặc điểm của từng nhánh thích ứng với bằng chứng thực nghiệm. Thông qua một loạt thí nghiệm rộng lớn, bao gồm các so sánh và nghiên cứu loại bỏ, chúng tôi chứng minh tính hiệu quả và khẳng định hiệu suất vượt trội của Hydra. Đánh giá toàn diện này nhấn mạnh tác động tiềm năng và hiệu quả của Hydra trong nhiều ứng dụng khác nhau. Mã của chúng tôi có sẵn tại https://github.com/extremebird/Hydra

## 1. Giới thiệu

Các mô hình nền tảng quy mô lớn đã thành công đáng kể trên nhiều lĩnh vực và tác vụ khác nhau [5, 12, 15, 40, 61]. Huấn luyện các mô hình quy mô lớn này từ đầu là một nhiệm vụ đáng gờm, chủ yếu bị giới hạn trong một số ít tổ chức được lựa chọn. Những rào cản chính cản trở khả năng tiếp cận rộng hơn là kích thước mô hình lớn, yêu cầu tính toán cực kỳ tốn kém và việc không có sẵn các bộ dữ liệu rộng lớn. Đặc biệt, kích thước mô hình lớn áp đặt gánh nặng tính toán đáng kể ngay cả trong quá trình tinh chỉnh cho các tác vụ hạ nguồn. Thích ứng hiệu quả các mô hình quy mô lớn này với các tác vụ hạ nguồn đã trở thành thực tiễn phổ biến trong nhiều ứng dụng.

Các phương pháp Tinh chỉnh Hiệu quả Tham số (PEFT) [7, 32-34, 47, 48, 80] tinh chỉnh hiệu quả một mạng được tiền huấn luyện. Mặc dù các phương pháp này tối ưu hóa một số lượng tham số nhỏ hơn đáng kể so với tổng số tham số, chúng đã vượt trội so với việc tinh chỉnh toàn bộ trong nhiều tác vụ hạ nguồn khác nhau. Trong số các phương pháp PEFT, các phương pháp dựa trên adapter [7, 32, 33, 48] đã thể hiện hiệu suất vượt trội và được sử dụng rộng rãi. Chúng gắn các mô-đun nhẹ, được gọi là adapter, vào một mô hình được tiền huấn luyện và chỉ tối ưu hóa các mô-đun adapter trong quá trình tinh chỉnh. Gần đây, được thúc đẩy bởi bằng chứng thực nghiệm về chiều thấp nội tại trong việc thích ứng mô hình, LoRA [33] tận dụng các mô-đun adapter tuyến tính để loại bỏ độ trễ suy luận bổ sung tồn tại trong các phương pháp dựa trên adapter trước đó [7, 32]. Hơn nữa, nhiều kỹ thuật phân tích ma trận khác nhau đã được áp dụng vào các mô-đun adapter để tăng cường hiệu quả [29, 82].

Trong khi các phương pháp dựa trên adapter đã trở nên hiệu quả và tiên tiến hơn, chúng đã bị giới hạn ở cách tiếp cận song song hoặc tuần tự. Các cách tiếp cận song song (Hình 1-(b)) và tuần tự (Hình 1-(c)) được biểu diễn tương ứng là f(x) + g(x) và f(x) + g(f(x)), trong đó f là một mô-đun được tiền huấn luyện và g là một mô-đun adapter. Trong khi hai cách này được biểu diễn theo cách tương tự, mô-đun adapter của mỗi cách tiếp cận được tối ưu hóa với các đặc trưng đầu vào khác nhau, x và f(x). Nói cách khác, các đặc trưng cụ thể cho tác vụ có thể được thu thập dựa trên cách mô-đun adapter được gắn trong quá trình tinh chỉnh. Tuy nhiên, các phương pháp dựa trên adapter hiện có đã không khám phá rộng rãi khía cạnh này.

Bài báo này điều tra các đặc điểm của từng cách tiếp cận gắn. Nhánh song song được tối ưu hóa trên cùng đầu vào x như lớp được tiền huấn luyện, dẫn đến việc học các đặc trưng cụ thể cho tác vụ chưa được tiền huấn luyện. Điều này phù hợp với các quan sát thực nghiệm, vì nghiên cứu trước đây [33] phát hiện rằng thích ứng thứ hạng thấp thường khuếch đại các đặc trưng quan trọng liên quan đến các tác vụ hạ nguồn cụ thể. Mặt khác, nhánh tuần tự học kết hợp các đặc trưng tổng quát từ mô hình quy mô lớn được tiền huấn luyện do công thức rõ ràng g(f(x)) của nó.

Dựa trên những đặc điểm này, chúng tôi đề xuất một dạng tổng quát hơn của mô-đun adapter, có tên là Hydra¹, kết hợp các mô-đun adapter song song và tuần tự. Dạng được đề xuất là f(x) + gₚ(x) + gₛ(f(x)), trong đó gₚ và gₛ lần lượt là adapter song song và tuần tự. Công thức này vốn có tính biểu đạt cao hơn các cách tiếp cận nhánh đơn, vì nó có thể được rút gọn thành một trong số chúng khi gₚ(·) = 0 hoặc gₛ(·) = 0. Giả thuyết của chúng tôi là việc giới thiệu một dạng tổng quát và có tính biểu đạt cao hơn cho phép khám phá một phạm vi rộng hơn các điểm tối ưu địa phương. Do đó, tính linh hoạt gia tăng này có thể dẫn đến hiệu suất tổng quát hóa vượt trội cho các tác vụ mới.

Ngoài ra, chúng tôi sử dụng mô-đun adapter tuyến tính của LoRA để xây dựng phương pháp được đề xuất trong khi bảo toàn các thuộc tính có lợi của nó. Do đó, hai nhánh tính toán bổ sung của phương pháp chúng tôi có thể được hợp nhất sau khi huấn luyện, do đó không có độ trễ bổ sung trong quá trình suy luận. Hơn nữa, nhờ cấu trúc adapter tuyến tính đơn giản và linh hoạt, mô-đun được đề xuất không chỉ có thể được triển khai dễ dàng mà còn có thể được cắm vào bất kỳ lớp tuyến tính nào cho mục đích tinh chỉnh hiệu quả tham số.

¹Được đặt tên theo quái vật thần thoại Hy Lạp đa đầu, vần với LoRA gốc

Trong bài báo này, chúng tôi đi sâu vào vai trò của cả nhánh song song và tuần tự. Chúng tôi quan sát thấy rằng mỗi nhánh học các đặc trưng khác biệt trong quá trình tinh chỉnh. Cụ thể, nhánh song song có xu hướng học các đặc trưng mới bằng cách khám phá các đặc trưng vắng mặt trong giai đoạn tiền huấn luyện, và nhánh tuần tự học các đặc trưng tương đối tổng quát bằng cách khai thác các đặc trưng được tiền huấn luyện. Phương pháp được đề xuất, Hydra, đã trải qua thử nghiệm rộng rãi trên các kiến trúc transformer phổ biến, và chúng tôi đã tiến hành các thí nghiệm tinh chỉnh trên các bộ dữ liệu đa dạng trải rộng trên các tác vụ thị giác và ngôn ngữ tự nhiên. Kết quả là, việc tận dụng cả nhánh song song và tuần tự càng tăng cường khả năng tinh chỉnh của mô hình, vượt trội so với các phương pháp tinh chỉnh phổ biến khác.

## 2. Các công trình liên quan

### 2.1. Transformer

Transformer là một kiến trúc mạng neural sử dụng các lớp tự chú ý đa đầu và ban đầu được đề xuất cho dịch máy [71]. Nhiều transformer được tiền huấn luyện quy mô lớn [5, 15, 45, 50, 60, 61] đã thể hiện hiệu suất xuất sắc trong nhiều tác vụ xử lý ngôn ngữ tự nhiên (NLP), cho thấy khả năng mở rộng của chúng. Những thành công này của transformer trong các lĩnh vực NLP đã truyền cảm hứng cho [18] giới thiệu Vision Transformer (ViT), một kiến trúc backbone hoàn toàn dựa trên transformer cho các tác vụ thị giác máy tính (CV) và cho thấy kết quả đầy hứa hẹn. Tiếp theo, nhiều mô hình thị giác dựa trên transformer [12, 17, 51, 69] đã được đề xuất và cho thấy sự cải thiện đáng kể trong các tác vụ thị giác, bao gồm phân loại hình ảnh [13, 42], dự đoán dày đặc [49, 84], và tạo sinh hình ảnh [31, 38]. Hơn nữa, huấn luyện đa phương thức [59] và học tự giám sát [28] cũng thúc đẩy việc sử dụng rộng rãi ViT. Trong bài báo này, chúng tôi áp dụng phương pháp của mình cho các kiến trúc transformer được sử dụng rộng rãi trong cả tác vụ ngôn ngữ và thị giác.

### 2.2. Các phương pháp dựa trên adapter

Phương pháp dựa trên adapter là một trong những phương pháp thích ứng hiệu quả tham số bao gồm chỉ huấn luyện các mô-đun adapter nhẹ mà không cập nhật các tham số gốc của mô hình được tiền huấn luyện. [63] là công trình tiên phong đã áp dụng các mô-đun adapter cho thích ứng đa lĩnh vực thị giác. Adapter [32] đã giới thiệu một mô-đun adapter tồn dư thứ hạng thấp bao gồm phép chiếu xuống và lên với hàm phi tuyến trung gian.

Các nghiên cứu tiếp theo [1, 58, 64] đã chứng minh hiệu suất tinh chỉnh hiệu quả và đầy hứa hẹn trong nhiều tác vụ NLP khác nhau. Hơn nữa, Compacter [37] tận dụng phân tích tích Kronecker và chia sẻ tham số cho các ma trận chiếu của mô-đun adapter để thích ứng hiệu quả hơn. VL-adapter [68] đã áp dụng thành công nhiều adapter khác nhau cho các tác vụ đa phương thức (thị giác và ngôn ngữ), chứng minh tính linh hoạt và hiệu quả của chúng. Adaptformer [7] đã giới thiệu một adapter song song cho các mạng feed-forward của ViT cho các tác vụ nhận dạng thị giác. Trong khi các phương pháp tinh chỉnh adapter này đã cho thấy kết quả hứa hẹn, các nhánh adapter bổ sung, có các hàm phi tuyến trung gian, làm chậm tốc độ suy luận.

LoRA [33] đã đề xuất một mô-đun thích ứng thứ hạng thấp chỉ bao gồm các lớp tuyến tính. Thiết kế này cho phép các tham số của các nhánh được giới thiệu có thể được hợp nhất theo cách cộng với các tham số được tiền huấn luyện ở giai đoạn suy luận, đảm bảo không có độ trễ. So với tinh chỉnh adapter hiện có, nó đã cho thấy khả năng thích ứng cạnh tranh hoặc thậm chí tốt hơn trong các lĩnh vực NLP. AdaLoRA [82] đã cải thiện thêm LoRA với phân tích giá trị kỳ dị (SVD) cho phân bổ ngân sách thích ứng. KAdaptation [29] tận dụng cách cập nhật trọng số thứ hạng thấp tương tự như LoRA, trong đó các trọng số cập nhật được thu thập bởi tích Kronecker của ma trận chia sẻ và ma trận thứ hạng thấp, để tinh chỉnh các mô hình thị giác. Ngoài ra, FacT [35] đã đề xuất khung tensorization-decomposition, tensorize toàn bộ ViT thành một tensor 3D duy nhất, sau đó áp dụng Factor-Tuning với nhiều phương pháp phân tích tensor khác nhau, như Tensor-Train(TT) hoặc Tucker(TK).

SSF [48] đề xuất việc giới thiệu các yếu tố tỷ lệ và dịch chuyển để thực hiện biến đổi tuyến tính trên các đặc trưng sau các mô-đun được tiền huấn luyện của ViT, nhằm phù hợp với phân phối mục tiêu. Gần đây, RepAdapter [52] đã đề xuất một sơ đồ tái tham số hóa cấu trúc tuần tự cho các mô-đun thích ứng thứ hạng thấp. Những nghiên cứu này đã thể hiện hiệu suất cạnh tranh và hiệu quả, không làm chậm tốc độ suy luận. Dựa trên những cách tiếp cận nhánh đơn này, chúng tôi tận dụng cả nhánh song song và tuần tự cùng nhau để chứng minh hiệu suất vượt trội.

### 2.3. Các cách tiếp cận PEFT khác

Bên cạnh thành công của các phương pháp dựa trên adapter, các cách tiếp cận không có adapter đã được khám phá. BitFit [80] chỉ huấn luyện các hệ số bias trong quá trình tinh chỉnh. Diff-pruning [26] đã giới thiệu một vector diff cụ thể cho tác vụ, được tỉa thích ứng trong quá trình huấn luyện. Các cách tiếp cận tinh chỉnh dựa trên token [34, 44, 47, 65] cũng là các phương pháp PEFT được sử dụng rộng rãi. Chúng bao gồm việc gắn các token bổ sung, còn được gọi là prompt, vào chuỗi đầu vào hoặc trung gian và tinh chỉnh chúng để hướng sự chú ý của mô hình về thông tin liên quan cho tác vụ mới. VPT [34] đã chứng minh hiệu suất đầy hứa hẹn trong lĩnh vực thị giác bằng cách áp dụng cách tiếp cận tinh chỉnh prompt đã thành công trong các tác vụ ngôn ngữ tự nhiên. Trong khi tinh chỉnh dựa trên token đã chứng minh khả năng tinh chỉnh đầy hứa hẹn, việc thêm các token mới gây ra một số nhược điểm. Nó làm giảm độ dài chuỗi đầu vào có sẵn, có thể hạn chế lượng ngữ cảnh mà mô hình có thể xử lý hiệu quả. Hơn nữa, nó tăng độ phức tạp tính toán. Ngoài ra, việc áp dụng những cách tiếp cận này cho các mô hình sử dụng tự chú ý địa phương có thể tạo ra những thách thức bổ sung.

## 3. Phương pháp

### 3.1. Kiến thức cơ bản

LoRA [33] áp dụng một mô-đun adapter tuyến tính trên các lớp tuyến tính (dày đặc) của mô hình được tiền huấn luyện để thích ứng mô hình hiệu quả. Nó giả định rằng thứ hạng nội tại của ma trận thích ứng A∈ℝᵈˣᵏ thấp, cho phép phân tích thứ hạng thấp trên A (rank(A) ≪ min(d, k)). Tức là, ma trận thích ứng A được phân tích thành A = AᵤₚAᵈₒwₙ, trong đó Aᵤₚ∈ℝᵈˣʳ và Aᵈₒwₙ∈ℝʳˣᵏ lần lượt là ma trận thích ứng chiếu lên và chiếu xuống. Do đó, mô-đun adapter tuyến tính được công thức hóa là g(x; Aᵤₚ, Aᵈₒwₙ) = AᵤₚAᵈₒwₙx. Để ngắn gọn, sau đây, chúng tôi sử dụng g(x; A) để biểu thị g(x; Aᵤₚ, Aᵈₒwₙ).

Đối với đặc trưng đầu vào x∈ℝᵏ cho trước, lượt truyền thuận của LoRA được triển khai như sau:

h = f(x; W₀, b₀) + g(x; A) (1)
  = W₀x + b₀ + AᵤₚAᵈₒwₙx, (2)

trong đó h∈ℝᵈ là vector đầu ra, W₀∈ℝᵈˣᵏ là ma trận trọng số được tiền huấn luyện, và b₀∈ℝᵈ là bias. Để tối ưu hóa hiệu quả lớp tuyến tính trong quá trình tinh chỉnh, chỉ có các ma trận thích ứng Aᵤₚ và Aᵈₒwₙ được huấn luyện, và ma trận được tiền huấn luyện W₀ và bias b₀ được đóng băng. Trong khi việc sử dụng nhánh song song bổ sung g(x; A) hiệu quả cho tinh chỉnh, nó dẫn đến độ trễ trong suy luận. Nhờ tính tuyến tính, lượt truyền thuận trong Eq. (2) có thể được triển khai lại như sau:

h = (W₀ + A)x + b₀ (3)
  = f(x; W₀ + A, b₀), (4)

Nói cách khác, trong quá trình suy luận, mô-đun adapter có thể được hợp nhất vào lớp tuyến tính được tiền huấn luyện, đảm bảo không có chi phí tính toán bổ sung.

Trong Eq. (1), rõ ràng LoRA là một trong những cách tiếp cận song song. Mô-đun adapter tuyến tính của LoRA có thể được tối ưu hóa mà không phụ thuộc trực tiếp vào ma trận được tiền huấn luyện W₀. Do đó, nó sẽ tạo điều kiện cho việc học dễ dàng các đặc trưng mới khác biệt với các đặc trưng được tiền huấn luyện. Tuy nhiên, có khả năng mất khả năng tổng quát hóa của ma trận trọng số được tiền huấn luyện.

### 3.2. SeqLoRA

Để so sánh các cách tiếp cận song song và tuần tự, chúng tôi giới thiệu SeqLoRA, một dạng tuần tự của LoRA, tận dụng ý tưởng thích ứng thứ hạng thấp trên vector đầu ra của lớp tuyến tính được tiền huấn luyện. Điều này dẫn đến lượt truyền thuận sau:

h = f(x; W₀, b₀) + g(f(x; W₀, b₀); B) (5)
  = W₀x + b₀ + BᵤₚBᵈₒwₙW₀x + BᵤₚBᵈₒwₙb₀, (6)

trong đó B∈ℝᵈˣᵈ là ma trận thích ứng, Bᵤₚ∈ℝᵈˣʳ là ma trận thích ứng chiếu lên, và Bᵈₒwₙ∈ℝʳˣᵈ là ma trận thích ứng chiếu xuống. Tương tự như LoRA, chỉ có mô-đun adapter được tối ưu hóa và lượt truyền thuận cho suy luận có thể được biểu diễn như một lớp tuyến tính đơn:

h = (W₀ + BW₀)x + b₀ + Bb₀ (7)
  = f(x; W₀ + BW₀, b₀ + Bb₀), (8)

Chúng tôi giả định rằng LoRA và SeqLoRA bổ sung cho nhau. SeqLoRA có thể học các đặc trưng mới cho các tác vụ hạ nguồn bằng cách kết hợp tuyến tính các đặc trưng từ lớp được tiền huấn luyện. Trong khi SeqLoRA có khả năng học các đặc trưng rất hữu ích dựa trên khả năng của các mô hình được tiền huấn luyện quy mô lớn, nó có thể gặp hạn chế trong việc học các khái niệm hoặc đặc trưng mới vắng mặt trong giai đoạn tiền huấn luyện.

SeqLoRA có điểm tương đồng với RepAdapter [52] được đề xuất gần đây về mặt mô-đun adapter tuyến tính tuần tự. Tuy nhiên, chúng tôi giới thiệu nó để so sánh với đối tác song song và sử dụng như một thành phần của phương pháp được đề xuất sau đây, Hydra.

### 3.3. Hydra

Để khai thác điểm mạnh của cả LoRA và SeqLoRA, chúng tôi giới thiệu Hydra, một dạng tổng quát hơn của mô-đun thích ứng tuyến tính tích hợp khả năng của cả hai phương pháp. Hydra cho phép kết hợp và sử dụng các khía cạnh có lợi của LoRA và SeqLoRA, cung cấp một khung làm việc toàn diện và linh hoạt để thích ứng mô hình hiệu quả và hiệu suất. Cụ thể hơn, nó không chỉ có thể nắm bắt các đặc trưng mới dễ dàng mà còn có cái nhìn rộng hơn dựa trên các đặc trưng được tiền huấn luyện tổng quát. Đối với Hydra, chúng tôi kết hợp các nhánh thích ứng song song và tuần tự, cho phép lượt truyền thuận sau:

h = f(x; W₀, b₀) + g(x; A) + g(f(x; W₀, b₀); B) (9)
  = W₀x + b₀ + AᵤₚAᵈₒwₙx + BᵤₚBᵈₒwₙW₀x + BᵤₚBᵈₒwₙb₀, (10)

trong đó A∈ℝᵈˣᵏ, Aᵤₚ∈ℝᵈˣʳᵃ, Aᵈₒwₙ∈ℝʳᵃˣᵏ là ma trận thích ứng cho nhánh song song và phân tích thứ hạng thấp của nó với thứ hạng rₐ, B∈ℝᵈˣᵈ, Bᵤₚ∈ℝᵈˣʳᵦ, Bᵈₒwₙ∈ℝʳᵦˣᵈ là ma trận thích ứng cho nhánh tuần tự và phân tích thứ hạng thấp của nó với thứ hạng rᵦ. Để đơn giản, chúng tôi đặt thứ hạng là rₐ = rᵦ trong suốt bài báo.

Theo LoRA, chúng tôi sử dụng khởi tạo Gaussian ngẫu nhiên cho các ma trận chiếu xuống, Aᵈₒwₙ và Bᵈₒwₙ, và khởi tạo zero cho các ma trận chiếu lên, Aᵤₚ và Bᵤₚ. Do đó, ở đầu quá trình huấn luyện, cả A và B đều được khởi tạo bằng zero. Để thích ứng mô hình, Aᵤₚ, Aᵈₒwₙ, Bᵤₚ, và Bᵈₒwₙ được huấn luyện dựa trên gradient descent, trong khi W₀ và b₀ không được cập nhật.

Như được mô tả trong Hình 1-(d), việc triển khai cho huấn luyện bao gồm ba nhánh: được tiền huấn luyện, song song, và tuần tự. Sau khi huấn luyện, các nhánh song song và tuần tự có thể được hợp nhất vào nhánh được tiền huấn luyện như sau:

h = (W₀ + A + BW₀)x + b₀ + Bb₀ (11)
  = f(x; W₀ + A + BW₀, b₀ + Bb₀), (12)

Do đó, phương pháp của chúng tôi không tăng độ phức tạp tính toán trong quá trình suy luận.

Ngoài ra, rõ ràng LoRA và SeqLoRA có thể được xác định là các trường hợp cụ thể của Hydra khi B = 0 và A = 0, tương ứng. Quan sát này thiết lập rằng phương pháp của chúng tôi bao gồm một khung làm việc tổng quát hóa hơn cho các thích ứng cụ thể cho tác vụ. Kết quả là, cách tiếp cận của chúng tôi cung cấp khả năng mô hình hóa nâng cao để nắm bắt toàn diện các tình huống thích ứng khác nhau trong quá trình tinh chỉnh.

### 3.4. Thiết kế kiến trúc

Trong khi cách tiếp cận của chúng tôi được thiết kế để tương thích với bất kỳ lớp tuyến tính nào, trong công trình này, chúng tôi tập trung vào việc áp dụng nó cho các khối MLP trong các kiến trúc transformer, đã được sử dụng rộng rãi trong các mô hình quy mô lớn gần đây. Như được minh họa trong Hình 2, một khối transformer điển hình bao gồm một khối tự chú ý đa đầu (MSA) và một khối MLP, xen kẽ bằng các hàm kích hoạt phi tuyến và chuẩn hóa lớp. Chúng tôi thay thế mô-đun thích ứng được đề xuất bằng lớp cuối cùng của khối MLP. Vì các hàm kích hoạt phi tuyến không được sử dụng trong lớp tuyến tính cuối cùng của MLP, chúng tôi có thể tránh 'độ trễ bổ sung' tiềm ẩn có thể phát sinh trong quá trình suy luận. Chúng tôi gọi khối MLP, mà phương pháp của chúng tôi được áp dụng, là Hydra-MLP.

Ngoài ra, lựa chọn thiết kế này cũng được thúc đẩy bởi các nghiên cứu gần đây, tiết lộ rằng các khối tự chú ý trong transformer có xu hướng giảm thông tin tần số cao, trong khi các khối MLP khuếch đại nó [56, 75]. Vì Hydra-MLP chứa SeqLoRA được thiết kế để khai thác các đặc trưng được tiền huấn luyện thông qua kết hợp tuyến tính, cách tiếp cận của chúng tôi hiệu quả khuyến khích mô hình thúc đẩy các đặc trưng tần số cao hữu ích cho các tác vụ hạ nguồn cụ thể. Trừ khi được chỉ định, trong bài báo này, Hydra chỉ Hydra-MLP.

## 4. Kết quả thực nghiệm

Chúng tôi chứng minh tính linh hoạt của phương pháp Hydra thông qua một loạt thí nghiệm rộng lớn bao gồm cả tác vụ thị giác và ngôn ngữ tự nhiên. Tiếp theo, chúng tôi phân tích các đặc điểm dựa trên cách tiếp cận sử dụng nhánh adapter và thảo luận về hiệu quả tính toán của phương pháp được đề xuất. Cuối cùng, chúng tôi xác minh hiệu quả của thiết kế kiến trúc bằng cách tiến hành các nghiên cứu loại bỏ.

### 4.1. Thí nghiệm few-shot

Đầu tiên, vì nhiều ứng dụng tinh chỉnh khác nhau lựa chọn rơi vào điều kiện khả năng truy cập dữ liệu hạn chế, chúng tôi đã xác thực Hydra được đề xuất trong kịch bản học few-shot sử dụng 20 bộ dữ liệu phân loại hình ảnh từ benchmark ELEVATOR [46]. Mỗi bộ dữ liệu bao gồm một số lượng nhãn riêng biệt cùng với các hình ảnh tương ứng. Theo công trình trước đó [29], chúng tôi sử dụng CLIP được tiền huấn luyện ViT-Base-224/32 làm mô hình backbone. Và, chúng tôi đặt thứ hạng bottleneck của Hydra là rₐ = rᵦ = 2. Cài đặt thí nghiệm chi tiết và thống kê của từng bộ dữ liệu được báo cáo trong Phụ lục B và C, tương ứng.

Như thể hiện trong Bảng 1, Hydra đạt điểm độ chính xác cao nhất trên 11 trong 20 bộ dữ liệu và vượt qua các phương pháp PEFT khác về độ chính xác trung bình. Hơn nữa, chúng tôi báo cáo điểm PE [46] để so sánh sự đánh đổi giữa độ chính xác và hiệu quả. Điểm PE được định nghĩa như sau:

PE = accuracy · exp(-log₁₀(p/M₀ + 1)), (13)

trong đó p là số lượng tham số có thể huấn luyện, và M₀ là cường độ của các tham số mô hình được tiền huấn luyện. Chúng tôi đặt M₀ = 10⁸. Chúng tôi quan sát thấy rằng phương pháp của chúng tôi cũng đạt điểm PE cao nhất trong Bảng 1. Kết quả là, phương pháp được đề xuất không chỉ hiệu quả mà còn hiệu suất cho học few-shot.

### 4.2. Thí nghiệm VTAB-1k

Tiếp theo, chúng tôi tiến hành thí nghiệm trên benchmark VTAB-1k [81] để so sánh Hydra với các phương pháp PEFT tiên tiến. Benchmark VTAB-1k bao gồm 19 bộ dữ liệu thị giác và mỗi bộ dữ liệu được phân loại thành ba nhóm với các khái niệm khác nhau, tức là Natural, Specialized và Structured. Chúng tôi sử dụng mô hình ViT-Base-224/16 được tiền huấn luyện trên ImageNet-21k theo cách giám sát. Theo các công trình trước đó [52], chúng tôi áp dụng mô-đun Hydra trên mỗi lớp của cả lớp chiếu trong khối attention và lớp tuyến tính cuối cùng của khối MLP với chiều thứ hạng thấp rₐ = rᵦ = 2 cho thí nghiệm này. Chi tiết hơn về các thí nghiệm trong Phụ lục B và C.

Chúng tôi lưu ý rằng Hydra vượt trội so với các phương pháp PEFT gần đây trong Bảng 2. So với các phương pháp adapter phi tuyến hiện có [7, 32], phương pháp của chúng tôi đã chứng minh hiệu suất nâng cao, tránh mọi độ trễ suy luận bổ sung thông qua kết hợp các phép toán tuyến tính. Do đó điều này thể hiện các mô-đun adapter tuyến tính cũng có thể hoạt động tốt trong cách tiếp cận đa nhánh.

Hơn nữa, đáng chú ý là phương pháp được đề xuất, kết hợp các nhánh thích ứng song song và tuần tự, vượt trội so với các cách tiếp cận nhánh đơn trước đó (song song hoặc tuần tự) [33, 35, 48, 52]. Để học hiệu quả các đặc trưng cụ thể cho tác vụ trong quá trình tinh chỉnh, nói cách khác, cả nhánh song song học các khái niệm mới và nhánh tuần tự biến đổi các đặc trưng được tiền huấn luyện cần được sử dụng kết hợp. Kết quả là, việc giới thiệu một cấu trúc toàn diện và có tính biểu đạt cao hơn hữu ích cho việc thích ứng tác vụ thành thạo.

### 4.3. Thí nghiệm hiểu ngôn ngữ tự nhiên

Trong lĩnh vực NLP, transformer đã đạt được thành công lớn, dẫn đến nhiều mô hình transformer được tiền huấn luyện quy mô lớn. Do đó, nhiều phương pháp PEFT ban đầu được đề xuất cho các tác vụ NLP. Vì vậy, trong phần này, chúng tôi xác nhận rằng phương pháp của chúng tôi có thể tinh chỉnh hiệu quả một mô hình NLP được tiền huấn luyện. Chúng tôi thực hiện các thí nghiệm hiểu ngôn ngữ tự nhiên trên benchmark GLUE [73]. Theo [33], chúng tôi sử dụng RoBERTa (base) được tiền huấn luyện [50], ban đầu có 125M tham số có thể huấn luyện từ thư viện HuggingFace Transformers [78]. Chi tiết thí nghiệm hơn trong Phụ lục B và C.

Như thể hiện trong Bảng 3, Hydra đã chứng minh khả năng thích ứng vượt trội so với tinh chỉnh toàn bộ trong khi yêu cầu ít tham số có thể huấn luyện hơn đáng kể. Tương tự, giống như kết quả từ các thí nghiệm tác vụ thị giác, phương pháp được đề xuất vượt trội so với các cách tiếp cận PEFT hiện có. Đáng chú ý, mặc dù cả LoRA và Hydra áp dụng cùng mô-đun adapter tuyến tính, Hydra đạt được lợi thế đáng kể so với LoRA, cho thấy lợi thế hiệu suất đáng kể (+0.7 trung bình). Điều này nhấn mạnh tiềm năng của phương pháp được đề xuất trong các tác vụ NLP. Về bản chất, mô-đun adapter đa nhánh của chúng tôi thể hiện hiệu suất mạnh mẽ trên các lĩnh vực, làm cho nó linh hoạt và có thể áp dụng trong nhiều tình huống tinh chỉnh khác nhau.

### 4.4. Phân tích

Các phương pháp dựa trên adapter có thể được phân loại thành các cách tiếp cận song song và tuần tự dựa trên cách gắn. Trong khi các công thức (Eqs. (1) và (5)) tương tự, chúng được huấn luyện theo cách riêng biệt vì các đặc trưng đầu vào khác nhau. Nhánh song song học các đặc trưng mới bằng cách khám phá các đặc trưng vắng mặt trong giai đoạn tiền huấn luyện. Mặt khác, nhánh tuần tự học các đặc trưng tương đối tổng quát bằng cách khai thác các đặc trưng được tiền huấn luyện. Trong phần này, chúng tôi đi sâu vào các thuộc tính của các nhánh song song và tuần tự với bằng chứng thực nghiệm. Theo đó, chúng tôi cũng phân tích Hydra từ góc độ hiệu quả, một yếu tố quan trọng của các phương pháp PEFT.

**Độ tương tự không gian con của ma trận trọng số** Chúng tôi phân tích từng nhánh về mặt ma trận trọng số. Để làm như vậy, chúng tôi đo độ tương tự giữa ma trận trọng số được tiền huấn luyện W₀ và các ma trận trọng số của từng nhánh. Trong Eq. (11), các ma trận trọng số của các nhánh song song và tuần tự được biểu diễn tương ứng là A và BW₀ cho đầu vào x. Theo [33], chúng tôi tận dụng độ tương tự không gian con được định nghĩa như sau:

φ(M, N, i, j) = ||UᵢᵀₘUⱼₙ||²F / min{i, j}, (14)

trong đó các ma trận UᵢₘꞱℝᵈˣⁱ và UⱼₙꞱℝᵈˣʲ được tạo thành bằng cách trích xuất từ cột thứ nhất đến thứ i và thứ j của ma trận kỳ dị trái của các ma trận M và N, tương ứng. Chúng tôi đánh giá độ tương tự giữa 10% hướng kỳ dị hàng đầu trong ma trận được tiền huấn luyện W₀ và 2 hướng kỳ dị hàng đầu trong ma trận trọng số thích ứng A hoặc BW₀.

Trong Hình 3, chúng tôi quan sát thấy các giá trị độ tương tự tổng thể cao hơn giữa BW₀ và W₀ so với A và W₀ do tận dụng rõ ràng W₀. Điều này cho thấy nhánh tuần tự có xu hướng học các đặc trưng tổng quát tương đối giống với các đặc trưng được tiền huấn luyện. Hơn nữa, phần lớn các giá trị độ tương tự không vượt quá 0.25 cho cả A và BW₀. Điều này ngụ ý rằng mô-đun Hydra tăng cường các đặc trưng cụ thể cho tác vụ thay vì các đặc trưng được khuếch đại trước đó bởi W₀. Do đó, mô-đun đa nhánh của chúng tôi hiệu quả thực hiện vai trò của mô-đun adapter, cần học các đặc trưng cụ thể cho tác vụ.

**Trực quan hóa không gian đặc trưng** Chúng tôi tiến hành trực quan hóa t-SNE [70] trên các đặc trưng nhúng của token [CLS] trong khối transformer cuối cùng sau khi tinh chỉnh. Trong trực quan hóa này, chúng tôi trực quan hóa đặc trưng nhúng, phân biệt nó thành đầu ra nhánh được tiền huấn luyện f(x; W₀, b₀), đầu ra nhánh song song g(x; A), và đầu ra nhánh tuần tự g(f(x; W₀, b₀); B). Dựa trên điều này, chúng tôi diễn giải những đặc trưng mà mỗi nhánh được huấn luyện để biểu diễn.

Như được minh họa trong Hình 4, chúng tôi có thể quan sát sự khác biệt đáng chú ý trong phân phối các đặc trưng đầu ra giữa nhánh song song và nhánh tuần tự. Điều này rõ ràng chứng minh rằng mỗi nhánh giữ các đặc điểm riêng biệt. Đặc biệt, phân phối các đặc trưng đầu ra trong nhánh tuần tự chủ yếu trong không gian đặc trưng của nhánh được tiền huấn luyện. Điều này cho thấy rằng nhánh tuần tự học các đặc trưng tương tự với các đặc trưng được tiền huấn luyện tổng quát tốt. Mặt khác, nhánh song song học các đặc trưng độc đáo không được thu thập trong quá trình tiền huấn luyện.

**Hiệu quả tính toán** Ở đây, chúng tôi giải quyết hiệu quả tham số của Hydra với độ phức tạp tính toán. Để đơn giản, chúng tôi giả định đầu vào và đầu ra của mô-đun adapter tuyến tính có cùng chiều d. Sau đó, mô-đun adapter tuyến tính có độ phức tạp tính toán O(2rd). Điều này là do nó được định nghĩa là g(x; A) = AᵤₚAᵈₒwₙx, trong đó Aᵤₚ∈ℝᵈˣʳ, và Aᵈₒwₙ∈ℝʳˣᵈ. Do đó, độ phức tạp tính toán của các phương pháp nhánh đơn, LoRA và SeqLoRA, là O(2rd). Với rₐ = rᵦ = r, Hydra về cơ bản có hai nhánh, dẫn đến tăng độ phức tạp tính toán. Tuy nhiên, trong tất cả các thí nghiệm, chúng tôi đặt rₐ = rᵦ = r/2, dẫn đến độ phức tạp thời gian và bộ nhớ O(2rd). Điều này ngụ ý rằng độ phức tạp tính toán của LoRA, SeqLoRA, và Hydra giống nhau về mặt lý thuyết.

Tuy nhiên, khi áp dụng vào các ứng dụng thực tế, thiết kế đa nhánh của Hydra có thể dẫn đến bottleneck trên GPU. Để tìm ra các bottleneck, chúng tôi so sánh thời gian huấn luyện của từng phương pháp trên bộ dữ liệu CIFAR10. Để so sánh công bằng, chúng tôi áp dụng tất cả các phương pháp, bao gồm Hydra, vào các khối MLP. Chúng tôi sử dụng mô hình ViT-Base-224/32 với kích thước batch là 128. Kết quả được hiển thị trong Bảng 4. Nó chứng minh rằng khi số lượng tham số, có nghĩa là tiêu thụ bộ nhớ, tương tự, có thể quan sát thấy rằng các phương pháp nhánh đơn thường nhanh hơn Hydra. Tuy nhiên, sự khác biệt không đáng kể, và như quan sát trong các thí nghiệm trước đó, Hydra đã chứng minh hiệu suất thích ứng đặc biệt so với các phương pháp khác. Ngoài ra, Hydra có lợi thế không có độ trễ suy luận bổ sung. Do đó, các nhánh thích ứng được sử dụng cho tinh chỉnh không có tác động đến độ phức tạp tính toán suy luận.

### 4.5. Nghiên cứu loại bỏ

Trong phần này, chúng tôi thực hiện các nghiên cứu loại bỏ để xác nhận lý do đằng sau thiết kế kiến trúc của chúng tôi. Đầu tiên, chúng tôi tiến hành so sánh trực tiếp để đánh giá công bằng hiệu quả của cách tiếp cận. Tiếp theo, chúng tôi xác minh vị trí hiệu quả của Hydra trong kiến trúc transformer. Ở đây, chúng tôi chỉ trình bày các bảng tóm tắt, Bảng 5 đến 7. Các bảng đầy đủ được báo cáo trong Phụ lục A.

**So sánh trực tiếp** Hydra là phương pháp kết hợp các nhánh song song và tuần tự, tức là LoRA và SeqLoRA. Chúng tôi thực hiện các thí nghiệm, loại bỏ một trong những nhánh này, để chứng minh lợi thế của phương pháp nhánh kết hợp. Để làm như vậy, chúng tôi tận dụng các thí nghiệm thị giác trong Phần 4.2 và các thí nghiệm ngôn ngữ tự nhiên trong Phần 4.3 với cùng cài đặt thí nghiệm. Để so sánh công bằng, chúng tôi áp dụng từng phương pháp vào các khối mà mô-đun adapter được gắn trong từng thí nghiệm. Chúng tôi cấu hình thứ hạng thấp r để đảm bảo số lượng tham số có thể huấn luyện tương tự.

Như thể hiện trong Bảng 5 và 6, Hydra thể hiện hiệu suất trung bình cao nhất trong cả hai thí nghiệm. Ngoài ra, trong khi không có sự khác biệt đáng kể về hiệu suất giữa LoRA và SeqLoRA, Hydra chứng minh sự khác biệt đáng chú ý. Quan sát này ngụ ý rằng kết hợp LoRA và SeqLoRA, Hydra, là cách hiệu quả hơn so với việc sử dụng từng cái. Xem xét phân tích của chúng tôi rằng các nhánh song song và tuần tự bổ sung về bản chất, phương pháp được đề xuất có thể được coi là tích hợp hiệu quả điểm mạnh của từng nhánh. Do đó, dạng tổng quát và có tính biểu đạt cao của phương pháp chúng tôi cho phép tinh chỉnh xuất sắc trên các lĩnh vực tác vụ đa dạng, bất kể lĩnh vực cụ thể.

**Vị trí của mô-đun Hydra** Về bản chất, mô-đun Hydra có thể được áp dụng cho bất kỳ lớp tuyến tính nào của transformer, chẳng hạn như các lớp chiếu của các khối MSA hoặc các lớp tuyến tính nằm trong các khối MLP. Chúng tôi chủ yếu áp dụng mô-đun Hydra vào các khối MLP, được hướng dẫn bởi thuộc tính đặc biệt của từng khối. Để làm rõ hơn, chúng tôi điều tra thực nghiệm khối tối ưu cho mô-đun Hydra. Nó được thực hiện trên các thí nghiệm benchmark ELEVATOR trong Phần 4.1.

Kết quả được hiển thị trong Bảng 7. Chúng tôi quan sát thấy rằng khi áp dụng mô-đun Hydra vào các khối MLP, nó thể hiện hiệu suất tốt hơn. Do đó, thiết kế kiến trúc của chúng tôi, Hydra-MLP được mô tả trong Hình 2, là hợp lý. Hơn nữa, điều này cho thấy rằng phương pháp của chúng tôi biến đổi tốt các đặc trưng được tiền huấn luyện với tần số cao được khuếch đại bởi khối MLP thành các đặc trưng cụ thể cho tác vụ.

## 5. Kết luận

Trong bài báo này, chúng tôi tiến hành phân tích sâu về vai trò của từng nhánh thích ứng, song song và tuần tự, chưa được khám phá. Chúng tôi chứng minh rằng nhánh song song nghiêng về việc thu thập các đặc trưng mới thông qua khám phá các đặc trưng vắng mặt trong giai đoạn tiền huấn luyện, trong khi nhánh tuần tự sử dụng các đặc trưng được tiền huấn luyện để nắm bắt các đặc trưng tương đối tổng quát.

Chúng tôi cũng đề xuất một công thức thích ứng tổng quát và có tính biểu đạt cao, Hydra, kết hợp nhánh thích ứng song song và tuần tự để tích hợp khả năng của cả hai nhánh. Bằng cách tận dụng mô-đun adapter tuyến tính, nó không có độ trễ suy luận bổ sung và có thể được áp dụng cho bất kỳ lớp tuyến tính nào. Hơn nữa, nhờ cấu trúc đơn giản, Hydra có thể được triển khai dễ dàng. Phương pháp được đề xuất chứng minh hiệu suất vượt trội trong các thí nghiệm toàn diện, bao gồm cả tác vụ thị giác và ngôn ngữ tự nhiên, mà không cần bells and whistles. Điều này cho thấy tính linh hoạt của Hydra trong các ứng dụng tinh chỉnh.

Vì trọng tâm của chúng tôi chủ yếu là phân tích các đặc điểm của từng nhánh và chứng minh hiệu quả của cách tiếp cận đa nhánh, chúng tôi sử dụng mô-đun adapter tuyến tính đơn giản. Tuy nhiên, dạng của Hydra không bị ảnh hưởng bởi mô-đun adapter. Do đó, các phương pháp dựa trên adapter hiện có có thể dễ dàng được mở rộng thành các biến thể đa nhánh. Chúng tôi dự đoán rằng dạng tổng quát và có tính biểu đạt cao của Hydra sẽ được áp dụng rộng rãi trong lĩnh vực tinh chỉnh hiệu quả tham số.

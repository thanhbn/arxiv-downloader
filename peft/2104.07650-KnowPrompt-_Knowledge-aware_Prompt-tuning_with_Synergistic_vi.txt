--- TRANG 9 ---

KnowPrompt WWW '22, ngày 25-29 tháng 4, 2022, Sự kiện ảo, Lyon, Pháp

bởi Trung tâm Công nghệ Thông tin và Phòng thí nghiệm trọng điểm quốc gia CAD&CG, Đại học Chiết Giang.

TÀI LIỆU THAM KHẢO

[1] Christoph Alt, Aleksandra Gabryszak, và Leonhard Hennig. 2020. TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task. Trong Proceedings of ACL 2020.

[2] Xuefeng Bai, Yulong Chen, Linfeng Song, và Yue Zhang. 2021. Semantic Representation for Dialogue Modeling. Trong Proceedings of ACL/IJCNLP 2021.

[3] Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, và Tom Kwiatkowski. 2019. Matching the Blanks: Distributional Similarity for Relation Learning. Trong Proceedings of ACL/IJCNLP 2019.

[4] Anson Bastos, Abhishek Nadgeri, Kuldeep Singh, Isaiah Onando Mulang, Saeedeh Shekarpour, Johannes Hoffart, và Manohar Kaul. 2021. RECON: Relation Extraction using Knowledge Graph Context in a Graph Neural Network. Trong Proceedings of the Web Conference 2021. 1673-1685.

[5] Matthias Baumgartner, Wen Zhang, Bibek Paudel, Daniele Dell'Aglio, Huajun Chen, và Abraham Bernstein. 2018. Aligning Knowledge Base and Document Embedding Models Using Regularized Multi-Task Learning. Trong International Semantic Web Conference (1) (Lecture Notes in Computer Science, Vol. 11136). Springer, 21-37.

[6] Eyal Ben-David, Nadav Oved, và Roi Reichart. 2021. PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains. arXiv preprint arXiv:2102.12206 (2021).

[7] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language Models are Few-Shot Learners. Trong Proceedings of NeurIPS 2020.

[8] Mary Elaine Califf và Raymond J. Mooney. 1999. Relational Learning of Pattern-Match Rules for Information Extraction. Trong Proceedings of AAAI. AAAI Press / The MIT Press, 328-334.

[9] Jiaoyan Chen, Yuxia Geng, Zhuo Chen, Jeff Z. Pan, Yuan He, Wen Zhang, Ian Horrocks, và Huajun Chen. 2021. Low-resource Learning with Knowledge Graphs: A Comprehensive Survey. CoRR abs/2112.10006 (2021). arXiv:2112.10006 https://arxiv.org/abs/2112.10006

[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Trong Proceedings of NAACL-HLT 2019.

[11] Ning Ding, Yulin Chen, Xu Han, Guangwei Xu, Pengjun Xie, Hai-Tao Zheng, Zhiyuan Liu, Juanzi Li, và Hong-Gee Kim. 2021. Prompt-Learning for Fine-Grained Entity Typing. CoRR abs/2108.10604 (2021). arXiv:2108.10604 https://arxiv.org/abs/2108.10604

[12] Ning Ding, Yulin Chen, Xu Han, Guangwei Xu, Pengjun Xie, Hai-Tao Zheng, Zhiyuan Liu, Juanzi Li, và Hong-Gee Kim. 2021. Prompt-Learning for Fine-Grained Entity Typing. arXiv preprint arXiv:2108.10604 (2021).

[13] Bayu Distiawan, Gerhard Weikum, Jianzhong Qi, và Rui Zhang. 2019. Neural relation extraction for knowledge base enrichment. Trong Proceedings of ACL. 229-240.

[14] Bowen Dong, Yuan Yao, Ruobing Xie, Tianyu Gao, Xu Han, Zhiyuan Liu, Fen Lin, Leyu Lin, và Maosong Sun. 2020. Meta-Information Guided Meta-Learning for Few-Shot Relation Classification. Trong Proceedings of COLING 2020.

[15] Tianyu Gao, Adam Fisch, và Danqi Chen. 2021. Making Pre-trained Language Models Better Few-shot Learners. Trong Proceedings of ACL.

[16] Tianyu Gao, Xu Han, Zhiyuan Liu, và Maosong Sun. 2019. Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification. Trong Proceedings of AAAI.

[17] Tianyu Gao, Xu Han, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin, và Maosong Sun. 2020. Neural Snowball for Few-Shot Relation Learning. Trong Proceedings of AAAI 2020.

[18] Yuxian Gu, Xu Han, Zhiyuan Liu, và Minlie Huang. 2021. PPT: Pre-trained Prompt Tuning for Few-shot Learning. CoRR abs/2109.04332 (2021). arXiv:2109.04332 https://arxiv.org/abs/2109.04332

[19] Zhijiang Guo, Guoshun Nan, Wei Lu, và Shay B Cohen. 2020. Learning Latent Forests for Medical Relation Extraction.. Trong IJCAI. 3651-3657.

[20] Zhijiang Guo, Yan Zhang, và Wei Lu. 2019. Attention Guided Graph Convolutional Networks for Relation Extraction. Trong Proceedings of ACL 2019.

[21] Karen Hambardzumyan, Hrant Khachatrian, và Jonathan May. 2021. WARP: Word-level Adversarial ReProgramming. Trong Proceedings of ACL/IJCNLP 2021.

[22] Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, và Maosong Sun. 2021. PTR: Prompt Tuning with Rules for Text Classification. CoRR abs/2105.11259 (2021). arXiv:2105.11259 https://arxiv.org/abs/2105.11259

[23] Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, và Maosong Sun. 2018. FewRel: A Large-Scale Supervised Few-shot Relation Classification Dataset with State-of-the-Art Evaluation. Trong Proceedings of EMNLP, 2018.

[24] Tom Harting, Sepideh Mesbah, và Christoph Lofi. 2020. LOREM: Language-consistent Open Relation Extraction from Unstructured Text. Trong WWW '20: The Web Conference 2020, Taipei, Taiwan, April 20-24, 2020, Yennun Huang, Irwin King, Tie-Yan Liu, và Maarten van Steen (Eds.). ACM / IW3C2, 1830-1838. https://doi.org/10.1145/3366423.3380252

[25] Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, và Graham Neubig. 2021. Towards a Unified View of Parameter-Efficient Transfer Learning. CoRR abs/2110.04366 (2021). arXiv:2110.04366 https://arxiv.org/abs/2110.04366

[26] Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid Ó Séaghdha, Sebastian Padó, Marco Pennacchiotti, Lorenza Romano, và Stan Szpakowicz. 2010. SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals. Trong Proceedings of SemEval. 33-38. https://www.aclweb.org/anthology/S10-1006/

[27] Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Juanzi Li, và Maosong Sun. 2021. Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification. CoRR abs/2108.02035 (2021). arXiv:2108.02035 https://arxiv.org/abs/2108.02035

[28] Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Juanzi Li, và Maosong Sun. 2021. Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification. arXiv preprint arXiv:2108.02035 (2021).

[29] Scott B. Huffman. 1995. Learning information extraction patterns from examples. Trong Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing.

[30] Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, và Omer Levy. 2020. SpanBERT: Improving Pre-training by Representing and Predicting Spans. Trans. Assoc. Comput. Linguistics 8 (2020), 64-77. https://transacl.org/ojs/index.php/tacl/article/view/1853

[31] Brian Lester, Rami Al-Rfou, và Noah Constant. 2021. The Power of Scale for Parameter-Efficient Prompt Tuning. arXiv preprint arXiv:2104.08691 (2021). https://arxiv.org/abs/2104.08691

[32] Juan Li, Ruoxu Wang, Ningyu Zhang, Wen Zhang, Fan Yang, và Huajun Chen. 2020. Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification. Trong Proceedings of COLING. 2967-2978.

[33] Pengfei Li, Kezhi Mao, Xuefeng Yang, và Qi Li. 2019. Improving Relation Extraction with Knowledge-attention. Trong Proceedings of EMNLP. 229-239.

[34] Xiang Lisa Li và Percy Liang. 2021. Prefix-Tuning: Optimizing Continuous Prompts for Generation. Trong Proceedings of ACL/IJCNLP 2021.

[35] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, và Graham Neubig. 2021. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv preprint arXiv:2107.13586 (2021).

[36] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, và Jie Tang. 2021. GPT Understands, Too. CoRR abs/2103.10385 (2021). arXiv:2103.10385 https://arxiv.org/abs/2103.10385

[37] Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, và Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. arXiv preprint arXiv:2104.08786 (2021).

[38] Matthew E Peters, Mark Neumann, Robert Logan, Roy Schwartz, Vidur Joshi, Sameer Singh, và Noah A Smith. 2019. Knowledge Enhanced Contextual Word Representations. Trong Proceedings of EMNLP-IJCNLP. 43-54. https://www.aclweb.org/anthology/D19-1005

[39] Meng Qu, Tianyu Gao, Louis-Pascal A. C. Xhonneux, và Jian Tang. 2020. Few-shot Relation Extraction via Bayesian Meta-learning on Relation Graphs. Trong Proceedings of ICML 2020.

[40] Laria Reynolds và Kyle McDonell. 2021. Prompt programming for large language models: Beyond the few-shot paradigm. Trong Proceeding of CHI. 1-7.

[41] Teven Le Scao và Alexander M. Rush. 2021. How Many Data Points is a Prompt Worth? CoRR abs/2103.08493 (2021). arXiv:2103.08493 https://arxiv.org/abs/2103.08493

[42] Timo Schick, Helmut Schmid, và Hinrich Schütze. 2020. Automatically Identifying Words That Can Serve as Labels for Few-Shot Text Classification. Trong Proceedings of COLING.

[43] Timo Schick và Hinrich Schütze. 2020. It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners. CoRR abs/2009.07118 (2020). arXiv:2009.07118 https://arxiv.org/abs/2009.07118

[44] Timo Schick và Hinrich Schütze. 2021. Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference. Trong Proceedings of EACL 2021.

[45] Yongliang Shen, Xinyin Ma, Yechun Tang, và Weiming Lu. 2021. A Trigger-Sense Memory Flow Framework for Joint Entity and Relation Extraction. Trong WWW '21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021, Jure Leskovec, Marko Grobelnik, Marc Najork, Jie Tang, và Leila Zia (Eds.). ACM / IW3C2, 1704-1715. https://doi.org/10.1145/3442381.3449895

[46] Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, và Sameer Singh. 2020. AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. Trong Proceedings of EMNLP 2020.

[47] George Stoica, Emmanouil Antonios Platanios, và Barnabás Póczos. 2021. Re-TACRED: Addressing Shortcomings of the TACRED Dataset. arXiv preprint

--- TRANG 10 ---

WWW '22, ngày 25-29 tháng 4, 2022, Sự kiện ảo, Lyon, Pháp Xiang Chen et al.

arXiv:2104.08398 (2021). https://arxiv.org/abs/2104.08398

[48] Zifeng Wang, Rui Wen, Xi Chen, Shao-Lun Huang, Ningyu Zhang, và Yefeng Zheng. 2020. Finding influential instances for distantly supervised relation extraction. arXiv preprint arXiv:2009.09841 (2020).

[49] Shanchan Wu và Yifan He. 2019. Enriching Pre-trained Language Model with Entity Information for Relation Classification. Trong Proceedings of the CIKM 2019.

[50] Tongtong Wu, Xuekai Li, Yuan-Fang Li, Reza Haffari, Guilin Qi, Yujin Zhu, và Guoqiang Xu. 2021. Curriculum-Meta Learning for Order-Robust Continual Relation Extraction. CoRR abs/2101.01926 (2021). arXiv:2101.01926 https://arxiv.org/abs/2101.01926

[51] Fuzhao Xue, Aixin Sun, Hao Zhang, và Eng Siong Chng. 2021. GDPNet: Refining Latent Multi-View Graph for Relation Extraction. Trong Proceedings of AAAI 2021.

[52] Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, và Yuji Matsumoto. 2020. LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention. Trong Proceedings of EMNLP 2020.

[53] Hongbin Ye, Ningyu Zhang, Shumin Deng, Mosha Chen, Chuanqi Tan, Fei Huang, và Huajun Chen. 2021. Contrastive Triple Extraction with Generative Transformer. Trong Proceedings of AAAI, 2021.

[54] Dian Yu, Kai Sun, Claire Cardie, và Dong Yu. 2020. Dialogue-Based Relation Extraction. Trong Proceedings of ACL 2020.

[55] Haiyang Yu, Ningyu Zhang, Shumin Deng, Hongbin Ye, Wei Zhang, và Huajun Chen. 2020. Bridging Text and Knowledge with Multi-Prototype Embedding for Few-Shot Relational Triple Extraction. Trong Proceedings of COLING. International Committee on Computational Linguistics, 6399-6410. https://doi.org/10.18653/v1/2020.coling-main.563

[56] Daojian Zeng, Kang Liu, Yubo Chen, và Jun Zhao. 2015. Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks. Trong Proceedings of EMNLP 2015.

[57] Ningyu Zhang, Xiang Chen, Xin Xie, Shumin Deng, Chuanqi Tan, Mosha Chen, Fei Huang, Luo Si, và Huajun Chen. 2021. Document-level Relation Extraction as Semantic Segmentation. Trong Proceedings of IJCAI, Zhi-Hua Zhou (Ed.). ijcai.org, 3999-4006. https://doi.org/10.24963/ijcai.2021/551

[58] Ningyu Zhang, Shumin Deng, Zhanling Sun, Xi Chen, Wei Zhang, và Huajun Chen. 2018. Attention-Based Capsule Network with Dynamic Routing for Relation Extraction. Trong Proceedings of EMNLP 2018.

[59] Ningyu Zhang, Shumin Deng, Zhanlin Sun, Guanying Wang, Xi Chen, Wei Zhang, và Huajun Chen. 2019. Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks. Trong Proceedings of NAACL-HLT.

[60] Ningyu Zhang, Qianghuai Jia, Shumin Deng, Xiang Chen, Hongbin Ye, Hui Chen, Huaixiao Tou, Gang Huang, Zhao Wang, Nengwei Hua, và Huajun Chen. 2021. AliCG: Fine-grained and Evolvable Conceptual Graph Construction for Semantic Search at Alibaba. Trong Proceedings of KDD. ACM, 3895-3905. https://doi.org/10.1145/3447548.3467057

[61] Yuhao Zhang, Peng Qi, và Christopher D. Manning. 2018. Graph Convolution over Pruned Dependency Trees Improves Relation Extraction. Trong Proceedings of EMNLP, 2018.

[62] Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, và Christopher D. Manning. 2017. Position-aware Attention and Supervised Data Improve Slot Filling. Trong Proceedings of EMNLP 2017.

[63] Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, và Christopher D Manning. 2017. Position-aware attention and supervised data improve slot filling. Trong Proceedings of EMNLP. 35-45. https://nlp.stanford.edu/pubs/zhang2017tacred.pdf

[64] Hengyi Zheng, Rui Wen, Xi Chen, Yifan Yang, Yunyan Zhang, Ziheng Zhang, Ningyu Zhang, Bin Qin, Xu Ming, và Yefeng Zheng. 2021. PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction. Trong Proceedings of ACL/IJCNLP 2021.

[65] Peng Zhou, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li, Hongwei Hao, và Bo Xu. 2016. Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification. Trong Proceedings of ACL 2016.

[66] Wenxuan Zhou và Muhao Chen. 2021. An Improved Baseline for Sentence-level Relation Extraction. CoRR abs/2102.01373 (2021). arXiv:2102.01373 https://arxiv.org/abs/2102.01373

[67] Wenxuan Zhou, Hongtao Lin, Bill Yuchen Lin, Ziqi Wang, Junyi Du, Leonardo Neves, và Xiang Ren. 2020. NERO: A Neural Rule Grounding Framework for Label-Efficient Relation Extraction. Trong WWW '20: The Web Conference 2020, Taipei, Taiwan, April 20-24, 2020, Yennun Huang, Irwin King, Tie-Yan Liu, và Maarten van Steen (Eds.). ACM / IW3C2, 2166-2176. https://doi.org/10.1145/3366423.3380282

A THỐNG KÊ CHI TIẾT CỦA BỘ DỮ LIỆU

Để có các thực nghiệm toàn diện, chúng tôi thực hiện các thực nghiệm trên năm bộ dữ liệu trích xuất quan hệ: TACRED [63], TACREV [1], Re-TACRED [47], SemEval 2010 Task 8 (SemEval) [26], và DialogRE [54]. Giới thiệu ngắn gọn về các dữ liệu này như sau:

TACRED: một bộ dữ liệu trích xuất quan hệ cấp câu quy mô lớn được rút ra từ thử thách TACKBP4 hàng năm, chứa hơn 106K câu. Nó bao gồm 42 quan hệ khác nhau (41 loại quan hệ thông thường và một loại "không có quan hệ" đặc biệt). Các đề cập chủ thể trong TACRED là người và tổ chức, trong khi các đề cập đối tượng có 16 loại chi tiết, bao gồm ngày tháng, số, v.v.

TACRED-Revisit: một bộ dữ liệu được xây dựng dựa trên bộ dữ liệu TACRED gốc. Họ tìm ra và sửa chữa các lỗi trong tập phát triển và tập kiểm tra gốc của TACRED, trong khi tập huấn luyện được giữ nguyên.

Re-TACRED: một phiên bản khác của bộ dữ liệu TACRED. Họ giải quyết một số thiếu sót của bộ dữ liệu TACRED gốc, tái cấu trúc tập huấn luyện, tập phát triển và tập kiểm tra của nó. Re-TACRED cũng sửa đổi một vài loại quan hệ, cuối cùng tạo ra một bộ dữ liệu với 40 loại quan hệ.

SemEval: một bộ dữ liệu truyền thống trong phân loại quan hệ chứa 10.717 ví dụ được chú thích bao phủ 9 quan hệ với hai hướng và một quan hệ đặc biệt "no_relation".

DialogRE: DialogRE là bộ dữ liệu RE cấp đối thoại được chú thích bởi con người đầu tiên. Nó chứa 1.788 đối thoại có nguồn gốc từ bản ghi đầy đủ của một bộ phim hài tình huống truyền hình nổi tiếng của Mỹ. Đây là phân loại đa nhãn, vì mỗi cặp thực thể có thể có nhiều hơn một quan hệ.

B CHI TIẾT TRIỂN KHAI CHO KNOWPROMPT

Phần này trình bày chi tiết các quy trình huấn luyện và siêu tham số cho mỗi bộ dữ liệu. Chúng tôi sử dụng Pytorch để thực hiện các thực nghiệm với 8 GPU Nvidia 3090. Tất cả các tối ưu được thực hiện với bộ tối ưu AdamW với khởi động tuyến tính của tỷ lệ học trong 10% đầu tiên của các cập nhật gradient lên giá trị tối đa, sau đó giảm tuyến tính trong phần còn lại của quá trình huấn luyện. Gradient được cắt nếu chuẩn của chúng vượt quá 1.0, biên γ, λ và trọng số suy giảm trên tất cả các tham số không phải bias được đặt thành 1, 0.001 và 0.01. Tìm kiếm lưới được sử dụng để tinh chỉnh siêu tham số (giá trị tối đa được in đậm bên dưới).

B.1 Cài đặt giám sát tiêu chuẩn

Không gian tìm kiếm siêu tham số được hiển thị như sau:
• tỷ lệ học lr1 của tối ưu hiệp đồng cho mẫu ảo và từ neo. [5e-5, 1e-4, 2e-4]
• tỷ lệ học lr2 của tối ưu cho các tham số tổng thể. [1e-5, 2e-5, 3e-5, 5e-5]
• số epoch 5 (đối với dialogre là 20)
• kích thước batch: 16 (đối với tacrev, retacred và dialogre là 8)
• độ dài seq tối đa: 256 (đối với tacrev, retacred và dialogre là 512)
• bước tích lũy gradient: 1 (đối với dialogre là 4)

B.2 Cài đặt tài nguyên thấp

Không gian tìm kiếm siêu tham số được hiển thị như sau:
• tỷ lệ học lr1 của tối ưu hiệp đồng cho mẫu ảo và từ neo: [5e-5, 1e-4, 2e-4]
• tỷ lệ học lr2 của tối ưu cho các tham số tổng thể: [1e-5, 2e-5, 3e-5, 5e-5]
• số epoch: 30
• kích thước batch: 16 (đối với tacrev, retacred và dialogre là 8)

--- TRANG 11 ---

KnowPrompt WWW '22, ngày 25-29 tháng 4, 2022, Sự kiện ảo, Lyon, Pháp

• độ dài seq tối đa: 256 (đối với tacrev, retacred và dialogre là 512)
• bước tích lũy gradient: 1 (đối với dialogre là 4)

C CHI TIẾT TRIỂN KHAI CHO TINH CHỈNH

Phương pháp tinh chỉnh được thực hiện như được hiển thị trong Hình 2, được trang bị cùng dấu hiệu thực thể trong văn bản thô để so sánh công bằng. Các siêu tham số như kích thước batch, epoch, và tỷ lệ học giống như KnowPrompt.

D CHI TIẾT TRIỂN KHAI CHO PTR

Vì PTR không thực hiện các thực nghiệm trên DialogRE trong cài đặt giám sát tiêu chuẩn và SemEval và DialogRE trong các cài đặt vài mẫu, chúng tôi chạy lại mã công khai của nó để bổ sung các thực nghiệm mà chúng tôi mô tả ở trên với các dữ liệu và tình huống này. Đối với SemEval, quá trình thực nghiệm hoàn toàn tuân theo cài đặt gốc trong mã của họ, trong khi đối với DialogRE, chúng tôi sửa đổi mã của họ để thích ứng hơn với cài đặt của bộ dữ liệu này. Các siêu tham số cụ thể như kích thước batch, epoch, và tỷ lệ học giống như KnowPrompt.

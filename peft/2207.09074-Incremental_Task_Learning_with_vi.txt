# 2207.09074.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2207.09074.pdf
# Kích thước tệp: 1308449 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Học Tác Vụ Tăng Dần với
Cập Nhật Hạng Tăng Dần
Rakib Hyder1, Ken Shao1, Boyu Hou1, Panos Markopoulos2,
Ashley Prater-Bennette3, và M. Salman Asif1
1Đại học California Riverside
2Viện Công nghệ Rochester
3Phòng thí nghiệm Nghiên cứu Không quân
Tóm tắt. Học Tác vụ Tăng dần (ITL) là một danh mục của học liên tục
nhằm huấn luyện một mạng đơn lẻ cho nhiều tác vụ (lần lượt từng tác vụ),
trong đó dữ liệu huấn luyện cho mỗi tác vụ chỉ có sẵn trong quá trình
huấn luyện tác vụ đó. Mạng nơ-ron có xu hướng quên các tác vụ cũ khi
chúng được huấn luyện cho các tác vụ mới; đặc tính này thường được gọi là
quên thảm khốc. Để giải quyết vấn đề này, các phương pháp ITL sử dụng
bộ nhớ cảnh, chính quy hóa tham số, che giấu và cắt tỉa, hoặc cấu trúc
mạng mở rộng. Trong bài báo này, chúng tôi đề xuất một khung học tác vụ
tăng dần mới dựa trên phân tích nhân tử hạng thấp. Cụ thể, chúng tôi
biểu diễn trọng số mạng cho mỗi lớp như một tổ hợp tuyến tính của
nhiều ma trận hạng-1. Để cập nhật mạng cho một tác vụ mới, chúng tôi
học một ma trận hạng-1 (hoặc hạng thấp) và thêm ma trận đó vào trọng số
của mỗi lớp. Chúng tôi cũng giới thiệu một vector chọn lọc bổ sung gán
các trọng số khác nhau cho các ma trận hạng thấp đã học cho các tác vụ
trước đó. Chúng tôi chứng minh rằng phương pháp của chúng tôi hoạt động
tốt hơn các phương pháp hiện đại nhất hiện tại về độ chính xác và khả năng
quên. Phương pháp của chúng tôi cũng cung cấp hiệu quả bộ nhớ tốt hơn
so với các phương pháp dựa trên bộ nhớ cảnh và mặt nạ. Mã của chúng tôi
sẽ có sẵn tại https://github.com/CSIPlab/task-increment-rank-update.git

1 Giới thiệu
Mạng nơ-ron sâu đã cực kỳ thành công cho nhiều loại tác vụ học và
biểu diễn (ví dụ: phân loại hình ảnh, phát hiện/phân đoạn đối tượng,
học tăng cường, mô hình sinh). Một mạng điển hình được huấn luyện để học
một hàm ánh xạ đầu vào đến đầu ra mong muốn. Mối quan hệ đầu vào-đầu ra
được giả định là cố định và các mẫu dữ liệu đầu vào-đầu ra được rút ra từ một
phân phối cố định [25]. Nếu mối quan hệ đầu vào-đầu ra hoặc phân phối dữ liệu
thay đổi, mạng có thể được huấn luyện lại sử dụng một tập hợp mới các mẫu
dữ liệu đầu vào-đầu ra. Vì khả năng lưu trữ, tính toán và mạng bị giới hạn,
chúng ta có thể cần thay thế các mẫu dữ liệu cũ bằng các mẫu mới. Hơn nữa,
các mối quan tâm về quyền riêng tư cũng có thể buộc các mẫu dữ liệu chỉ có
sẵn trong thời gian giới hạn [10,25]. Trong quá trình huấn luyện như vậy,
một mạng thường quên các tác vụ đã học trước đó; hiệu ứng này được gọi là
quên thảm khốc [21,26].arXiv:2207.09074v1 [cs.CV] 19 Jul 2022

--- TRANG 2 ---
2 R. Hyder et al.
Hình 1: Tổng quan về phương pháp đề xuất của chúng tôi cho học liên tục thông qua cập
nhật mạng hạng thấp. Trước tiên chúng tôi biểu diễn (và học) ma trận trọng số (hoặc tensor)
cho mỗi lớp như một tích của các ma trận hạng thấp. Để huấn luyện mạng cho các tác vụ mới
mà không quên các tác vụ trước đó, chúng tôi tái sử dụng các nhân tử từ các tác vụ trước đó
và thêm một tập hợp nhân tử mới cho tác vụ mới. Các thí nghiệm của chúng tôi gợi ý rằng
một cập nhật hạng-1 thường đủ cho việc học liên tục thành công.

Học tác vụ tăng dần là một danh mục con của các phương pháp học liên tục
hoặc học suốt đời nhằm giải quyết vấn đề quên thảm khốc bằng cách thích ứng
mạng hoặc quy trình huấn luyện để học các tác vụ mới mà không quên những
tác vụ đã học trước đó [23,16,3,2,4,6,28,29,12]. Trong bài báo này, chúng tôi
tập trung vào học liên tục tăng dần tác vụ trong đó dữ liệu cho mỗi tác vụ được
cung cấp theo cách tuần tự để huấn luyện/cập nhật mạng [8]. Đây là một thiết
lập học liên tục phổ biến ngay cả trong tài liệu gần đây [7,14,11,36,31,40].
ITL tìm thấy ứng dụng của mình trong các thiết lập nơi id tác vụ có sẵn trong
quá trình suy luận; ví dụ, các tác vụ được thực hiện dưới các điều kiện thời
tiết/ánh sáng/nền khác nhau và chúng ta biết các thay đổi, hoặc các tác vụ
được học trên các dữ liệu/lớp khác nhau nơi chúng ta biết id tác vụ.

Hãy ký hiệu hàm mạng ánh xạ đầu vào x đến đầu ra cho tác vụ t là
f(x;Wt), trong đó Wt biểu thị trọng số mạng cho tác vụ t. Chúng tôi tìm cách
cập nhật Wt cho tất cả t khi chúng ta tuần tự nhận tập dữ liệu cho một tác vụ
tại một thời điểm. Giả sử tập dữ liệu huấn luyện cho tác vụ t được cho là
(Xt,Yt) được rút ra từ một phân phối Pt, trong đó Xt biểu thị tập hợp các
mẫu đầu vào và Yt biểu thị các đầu ra thực tế tương ứng. Mục tiêu của chúng ta
là cập nhật trọng số mạng từ tác vụ trước đó (Wt−1) thành Wt sao cho

y≈f(x;Wt),cho tất cả (x,y)∼Pt. (1)

Thiết lập ITL ở trên giả định rằng danh tính tác vụ của các mẫu kiểm tra được
biết tại thời điểm kiểm tra và trọng số mạng tương ứng được sử dụng để suy luận.
Các phương pháp kiến trúc động có tiềm năng đạt được quên bằng không, sử dụng
Wt để kiểm tra dữ liệu cho tác vụ t; tuy nhiên, điều này cũng đòi hỏi lưu trữ
Wt cho tất cả các

--- TRANG 3 ---
Học Tác Vụ Tăng Dần với Cập Nhật Hạng Tăng Dần 3

tác vụ. Một trong những đóng góp chính của bài báo này là biểu diễn, học và
cập nhật Wt sử dụng các nhân tử hạng thấp sao cho chúng có thể được lưu trữ
và áp dụng với chi phí bộ nhớ và tính toán tối thiểu.

Chúng tôi đề xuất một phương pháp mới cho ITL cập nhật trọng số mạng sử dụng
các gia tăng hạng-1 (hoặc hạng thấp) cho mỗi tác vụ mới. Hình 1 cung cấp một
minh họa về phương pháp đề xuất của chúng tôi. Chúng tôi biểu diễn trọng số
mạng cho mỗi lớp như một tổ hợp tuyến tính của nhiều nhân tử hạng thấp (có
thể được biểu diễn như một tích của hai ma trận hạng thấp và một ma trận
chéo). Để cập nhật mạng cho tác vụ t mà không quên các tác vụ trước đó, chúng
tôi đóng băng các nhân tử hạng thấp đã học từ các tác vụ trước đó, thêm một
nhân tử hạng-1 (hoặc hạng thấp) có thể huấn luyện mới cho mỗi lớp, và kết
hợp nó với các nhân tử cũ hơn sử dụng các trọng số chọn lọc có thể học (hiển
thị như một ma trận chéo). Chúng tôi sử dụng một cấu hình đa đầu có một lớp
đầu ra độc lập cho mỗi tác vụ. Vì chúng tôi đang học các ma trận chéo riêng
biệt cho mỗi tác vụ, chúng tôi có thể đạt được quên bằng không trong quá
trình suy luận.

Chúng tôi trình bày một tập hợp thí nghiệm mở rộng để chứng minh hiệu suất
của phương pháp đề xuất cho các tập dữ liệu chuẩn khác nhau. Chúng tôi quan
sát thấy rằng phương pháp đề xuất của chúng tôi vượt trội hơn các phương pháp
hiện đại nhất hiện tại về độ chính xác với chi phí bộ nhớ nhỏ.

Các đóng góp chính của bài báo này như sau:

1. Biểu diễn các lớp như ma trận hạng thấp: Chúng tôi biểu diễn và học
trọng số mạng cho mỗi lớp như một cấu trúc hạng thấp. Chúng tôi chứng minh
rằng cấu trúc hạng thấp đủ để biểu diễn tất cả các tác vụ trong thiết lập
học liên tục.

2. Tái sử dụng các nhân tử cũ để có hiệu suất tốt hơn với chi phí bộ nhớ
nhỏ: Chúng tôi giới hạn số lượng tham số cần thiết để cập nhật mạng bằng
cách tái sử dụng các nhân tử đã học từ các tác vụ trước đó. Chúng tôi chứng
minh rằng một gia tăng hạng-1 đủ để vượt trội hơn các kỹ thuật hiện có.

3. Quên bằng không mà không cần bộ đệm phát lại: Phương pháp của chúng tôi
có quên bằng không được đạt được sử dụng cập nhật hạng tăng dần hoặc trọng
số mạng. Ngược lại, hầu hết các kỹ thuật học liên tục hiện có đòi hỏi bộ đệm
phát lại hoặc chi phí bộ nhớ lớn để đạt được quên bằng không.

Hạn chế. Phương pháp của chúng tôi chia sẻ cùng hạn chế cố hữu của ITL
(tức là yêu cầu task-id trong quá trình suy luận). Ngoài ra, vì chúng tôi sử
dụng tất cả các nhân tử đã học trước đó để suy luận, các tác vụ sau đó đòi
hỏi nhiều bộ nhớ và tính toán hơn để suy luận. Tuy nhiên, chúng tôi chứng minh
rằng sử dụng cấu trúc hạng thấp, tổng yêu cầu bộ nhớ của chúng tôi thấp hơn
đáng kể so với một mạng đơn lẻ. Hơn nữa, vì chúng tôi học các ma trận chéo
riêng biệt cho mỗi tác vụ, chúng tôi có thể duy trì hiệu suất cao ngay cả khi
mạng đạt đến hạng đầy đủ với số lượng lớn các tác vụ.

2 Bối cảnh và Công trình Liên quan

Học tác vụ tăng dần (ITL) [10,34] nhằm huấn luyện một mô hình duy nhất trên
một chuỗi các tác vụ khác nhau và hoạt động tốt trên tất cả các tác vụ đã
huấn luyện một khi quá trình huấn luyện hoàn tất. Trong khi huấn luyện trên
các tác vụ mới, dữ liệu cũ từ các tác vụ trước đó sẽ không được cung cấp cho
mô hình. Tình huống này bắt chước quá trình học của con người

--- TRANG 4 ---
4 R. Hyder et al.

nơi họ có khả năng thu thập kiến thức và kỹ năng mới trong suốt cuộc đời của
mình. Tuy nhiên, thiết lập này vẫn thách thức đối với các mô hình mạng nơ-ron
vì một hiện tượng phổ biến được gọi là "quên thảm khốc [21]" được quan sát
trong quá trình học này. Quên thảm khốc xảy ra khi dữ liệu từ các tác vụ mới
can thiệp vào dữ liệu đã thấy trong các tác vụ trước đó và do đó làm giảm
hiệu suất mô hình trên các tác vụ trước đó. Để vượt qua vấn đề này, các
phương pháp khác nhau đã được đề xuất cho đến nay có thể được chia thành ba
danh mục chính: các phương pháp dựa trên chính quy hóa, các phương pháp
dựa trên bộ nhớ và phát lại, và các phương pháp dựa trên kiến trúc mạng động.
Một số phương pháp này được thiết kế đặc biệt cho ITL trong khi các phương
pháp khác được thiết kế cho thiết lập học liên tục tổng quát hơn.

Các phương pháp dựa trên chính quy hóa [15,23,16] cập nhật toàn bộ mô hình
trong mỗi tác vụ nhưng một thuật ngữ chính quy hóa ℓreg được thêm vào tổng
mất mát L=ℓcurrent + λℓreg để phạt các thay đổi trong các tham số quan trọng
đối với các tác vụ trước đó do đó bảo tồn hiệu suất trên các tác vụ đã học
trước đó. Ví dụ, Consolidation Trọng số Đàn hồi (EWC) [15] ước tính tầm quan
trọng của các tham số sử dụng ma trận Fisher Information; Học Liên tục Biến
phân (VCL) [23] xấp xỉ phân phối hậu nghiệm của các tham số sử dụng suy luận
biến phân; Học mà không Quên (LwF) [16] chính quy hóa mất mát hiện tại với
các mục tiêu mềm được lấy từ các tác vụ trước đó sử dụng chưng cất kiến thức
[13]. GCL [5] trộn luyện tập với chưng cất kiến thức và chính quy hóa để giảm
thiểu quên thảm khốc. Một số phương pháp được đề xuất gần đây buộc các cập
nhật trọng số thuộc về không gian null của hiệp phương sai đặc trưng [37,35].

Các phương pháp dựa trên bộ nhớ [27,28,8,9,35] thường sử dụng bộ nhớ và
cơ chế phát lại/luyện tập để nhớ lại một bộ nhớ cảnh nhỏ của các tác vụ trước
đó trong khi huấn luyện các tác vụ mới do đó giảm mất mát trong các tác vụ
trước đó. Ví dụ, iCaRL [27] là phương pháp phát lại đầu tiên, học theo cách
tăng dần lớp bằng cách chọn và lưu trữ các mẫu gần nhất với trung bình đặc
trưng của mỗi lớp; Phát lại Trải nghiệm Meta (MER) [28] kết hợp phát lại
trải nghiệm với meta-learning dựa trên tối ưu hóa để tối ưu hóa sự đánh đổi
đối xứng giữa chuyển giao và can thiệp bằng cách thực thi liên kết gradient
qua các ví dụ; AGEM [8] chiếu gradient trên minibatch hiện tại bằng cách sử
dụng một bộ nhớ cảnh bên ngoài của các mẫu từ các trải nghiệm trước đó như
một ràng buộc tối ưu hóa; ER-Ring [9] cùng huấn luyện dữ liệu tác vụ mới
với dữ liệu của các tác vụ trước đó.

Các kiến trúc mạng động [30,19,39,38,33,7,41] cố gắng thêm các nơ-ron mới
vào mô hình tại các tác vụ mới bổ sung, do đó hiệu suất trên các tác vụ trước
đó được bảo tồn bằng cách đóng băng các tham số cũ và chỉ cập nhật các tham
số mới được thêm vào. Ví dụ, Mạng nơ-ron Tiến bộ (PNN) [30] tận dụng kiến
thức trước đó thông qua các kết nối bên để học các đặc trưng trước đó; PackNet
[19] lặp lại gán các tập con tham số cho các tác vụ liên tiếp bằng cách tạo thành
các mặt nạ nhị phân. SupSup [39] cũng tìm các mặt nạ để gán các tập con khác
nhau của trọng số cho các tác vụ khác nhau. BatchEnsemble [38] học trên các
ma trận tỷ lệ hạng-1 riêng biệt cho mỗi tác vụ sau đó được sử dụng để tỷ lệ
trọng số của mạng được chia sẻ. HAT [33] kết hợp các embedding cụ thể tác vụ
để che giấu attention. [24] cũng đề xuất hypernetwork có điều kiện tác vụ cho
học liên tục.

--- TRANG 5 ---
Học Tác Vụ Tăng Dần với Cập Nhật Hạng Tăng Dần 5

[20] đề xuất các tập hợp đơn vị không chồng chéo hoạt động cho mỗi tác vụ.
Piggyback [18] học các mặt nạ nhị phân trên một mạng hiện có để cung cấp
hiệu suất tốt trên các tác vụ mới. [1] đề xuất chọn lọc bộ lọc tích chập cụ
thể tác vụ cho học liên tục. Các phương pháp dựa trên mặt nạ được liệt kê
ở trên cung cấp kết quả xuất sắc cho học liên tục, nhưng chúng đòi hỏi một
số lượng lớn các tham số để biểu diễn các mặt nạ cho mỗi tác vụ. Một phương
pháp dựa trên phân tích nhân tử được đề xuất trong [22] thực hiện chọn lọc
hạng tự động cho mỗi tác vụ cho suy luận biến phân sử dụng quá trình Indian
Buffet. Phương pháp đòi hỏi các gia tăng hạng lớn đáng kể cho mỗi tác vụ để
đạt được độ chính xác cao; ngược lại, phương pháp của chúng tôi sử dụng một
phương pháp dựa trên học để tìm các gia tăng hạng-1 và tái sử dụng các nhân
tử cũ với các trọng số chọn lọc đã học. ORTHOG-SUBSPACE [7] học các tác vụ
trong các không gian con vector khác nhau (hạng thấp) được giữ trực giao với
nhau để giảm thiểu can thiệp.

Phương pháp đề xuất của chúng tôi thuộc danh mục các phương pháp kiến trúc
mạng động. Lưu ý rằng chúng ta có thể biểu diễn một ma trận trọng số hạng thấp
sử dụng hai lớp được kết nối đầy đủ nhỏ hơn và tăng hạng của ma trận trọng
số tương đương với việc thêm các node mới trong hai lớp được kết nối đầy đủ
nhỏ hơn.

3 Học Tác Vụ Tăng Dần thông qua Gia tăng Hạng

Chúng tôi tập trung vào thiết lập học tác vụ tăng dần trong đó chúng tôi tìm
cách huấn luyện một mạng cho T tác vụ. Sự khác biệt chính giữa học tác vụ
tăng dần và học thông thường là dữ liệu huấn luyện cho mỗi tác vụ chỉ có sẵn
trong khi huấn luyện mạng cho tác vụ đó. Thách thức chính trong học tác vụ
tăng dần là không quên các tác vụ trước đó khi chúng ta học các tác vụ mới.
Học mỗi tác vụ đòi hỏi huấn luyện trọng số cho mạng để học mối quan hệ
đầu vào-đầu ra cụ thể tác vụ sử dụng dữ liệu huấn luyện cụ thể tác vụ.

Chúng tôi tìm cách phát triển một khung ITL trong đó chúng tôi biểu diễn trọng
số của bất kỳ lớp nào sử dụng một số lượng nhỏ các nhân tử hạng thấp. Chúng
tôi khởi tạo mạng với một kiến trúc cơ sở trong đó trọng số cho mỗi lớp có
thể được biểu diễn sử dụng một ma trận hạng thấp. Sau đó chúng tôi thêm các
nhân tử hạng thấp mới cho mỗi lớp khi chúng ta học các tác vụ mới.

Hãy giả sử mạng có K lớp và trọng số cho lớp kth và tác vụ t có thể được
biểu diễn là Wk,t. Hãy giả sử thêm rằng trọng số cho lớp kth và tác vụ t = 1
có thể được biểu diễn như một ma trận hạng thấp

Wk,1=Uk,1Sk,1,1V⊤k,1, (2)

trong đó Uk,1, Vk,1 biểu diễn hai ma trận hạng thấp và Sk,1,1 biểu diễn một
ma trận chéo. Để học mạng cho tác vụ 1, chúng ta học Uk,1, Vk,1, Sk,1,1 cho
tất cả k. Cho tác vụ 2, chúng ta biểu diễn trọng số cho lớp kth là

Wk,2=Uk,1Sk,1,2V⊤k,1+Uk,2Sk,2,2V⊤k,2.

Uk,1, Vk,1 biểu diễn hai ma trận hạng thấp đã học cho tác vụ 1 và được đóng
băng sau đó. Uk,2, Vk,2 biểu diễn hai ma trận hạng thấp được thêm vào để cập
nhật

--- TRANG 6 ---
6 R. Hyder et al.

trọng số, và chúng sẽ được học cho tác vụ 2. Sk,1,2, Sk,2,2 biểu diễn các
ma trận chéo, sẽ được học cho tác vụ 2. Chúng ta học Sk,1,2, đây là một ma
trận chéo gán trọng số cho các nhân tử tương ứng với tác vụ 1, để bao gồm/
loại trừ hoặc ưu tiên/triệt tiêu các nhân tử đóng băng từ các tác vụ trước đó
cho các tác vụ mới. Chúng ta có thể biểu diễn trọng số cho lớp kth và tác vụ t
là

Wlayer,task =Wk,t=∑i≤tUk,iSk,i,tV⊤k,i
=∑i<tUk,i|{z}đóng băng Sk,i,tV⊤k,i|{z}đóng băng +Uk,tSk,t,tV⊤k,t, (3)

trong đó Uk,i, Vk,i được đóng băng cho tất cả i < t và Uk,t, Vk,t và tất cả
Sk,i,t được học cho tác vụ t. Toàn bộ mạng cho tác vụ t có thể được biểu diễn
là Wt = {Uk,i, Sk,i,t, Vk,i}i≤t. Để cập nhật các tham số mạng có thể huấn
luyện cho tác vụ t, chúng ta giải quyết bài toán tối ưu hóa sau:

min[Uk,t,Sk,i,t,Vk,t] ∑(x,y)∈(Xt,Yt) loss(f(x;Wt[Uk,t, Sk,i,t, Vk,t]), y)

cho tất cả k≤K và i≤t, (4)

trong đó chúng ta sử dụng loss(·,·) để biểu thị hàm mất mát và Wt[Uk,t, Sk,i,t, Vk,t]
để chỉ ra các tham số có thể huấn luyện trong Wt, trong khi phần còn lại được
đóng băng. Chúng ta đôi khi gọi Sk,i,t là ma trận/vector trọng số chọn lọc để
chỉ ra rằng các mục chéo của nó xác định đóng góp của mỗi nhân tử đối với
trọng số mỗi tác vụ/lớp.

Thuật toán ITL đề xuất của chúng tôi hoạt động như sau. Chúng tôi huấn luyện
các nhân tử hạng thấp cho tác vụ đã cho sử dụng các mẫu huấn luyện tương ứng.
Sau đó chúng tôi đóng băng các nhân tử tương ứng với các tác vụ cũ hơn và chỉ
cập nhật các nhân tử mới và các ma trận chéo. Theo cách này, tổng số tham số
chúng tôi thêm vào mô hình của mình tỷ lệ tuyến tính với hạng của các nhân tử
mới. Để giữ cho độ phức tạp mạng nhỏ, chúng tôi tìm cách đạt được độ chính
xác tốt sử dụng hạng nhỏ cho mỗi cập nhật tác vụ và lớp. Chúng tôi tóm tắt
phương pháp của mình trong Thuật toán 1 và 2.

Lưu ý rằng chúng ta không cần tạo ma trận trọng số Wk,t cho bất kỳ lớp nào
một cách rõ ràng vì chúng ta có thể tính toán tất cả các bước trong truyền
tiến và truyền ngược một cách hiệu quả sử dụng dạng phân tích nhân tử của
mỗi lớp. Kích thước của mỗi lớp được xác định bởi sự lựa chọn kiến trúc
mạng. Hạng của mỗi lớp cho mỗi tác vụ là một siêu tham số mà chúng ta có
thể chọn theo các tác vụ trong tay. Để giữ cho chi phí bộ nhớ nhỏ, chúng ta
cần sử dụng các giá trị nhỏ cho gia tăng hạng. Hãy ký hiệu hạng cho Uk,t
là rk,t, biểu diễn hạng gia tăng cho lớp kth và tác vụ t. Tại thời điểm kiểm
tra, chúng ta có thể sử dụng một số lượng nhân tử phù hợp tùy thuộc vào tác
vụ. Ví dụ, nếu chúng ta muốn dự đoán đầu ra cho tác vụ 1 thì chúng ta sử
dụng rk,1 nhân tử đầu tiên và cho tác vụ 2 chúng ta sử dụng rk,1+rk,2 nhân
tử. Chúng ta có thể thêm các nhân tử mới theo cách tăng dần khi chúng ta thêm
các tác vụ mới trong thiết lập ITL. Trong trường hợp cực đoan của các gia tăng
hạng-1, rk,t = 1. Trong các thí nghiệm của chúng tôi, chúng tôi quan sát thấy
rằng các cập nhật hạng-1 cạnh tranh hoặc vượt trội hơn hiệu suất của các
phương pháp ITL hiện có (xem Bảng 1) và hiệu suất của phương pháp chúng tôi
cải thiện thêm khi chúng ta tăng hạng (xem Bảng 5). Bất kỳ sự gia tăng nào
trong hạng đều đi kèm với chi phí tăng chi phí bộ nhớ.

--- TRANG 7 ---
Học Tác Vụ Tăng Dần với Cập Nhật Hạng Tăng Dần 7

Thuật toán 1 ITL với các gia tăng hạng-1 (Huấn luyện)
Đầu vào: Dữ liệu (X1 và Y1) cho tác vụ thứ 1.
Đặt hạng ban đầu, r1.
Khởi tạo các nhân tử trọng số Uk,1, Vk,1 ngẫu nhiên và Sk,1,1 như một ma trận đồng nhất.
Học Uk,1, Vk,1 và Sk,1,1. ▷ Tối ưu hóa trong (4)
for t = 2,3, ..., T do
    Đầu vào: Dữ liệu huấn luyện (Xt và Yt) cho tác vụ thứ t.
    Khởi tạo các nhân tử cập nhật hạng thấp Uk,t, Vk,t.
    Đóng băng các nhân tử trước đó {Uk,i, Vk,i}i<t.
    Khởi tạo các mục chéo của {Sk,i,t} là 1
    for i = t và 0 for i < t.
    Học Uk,t, Vk,t và Sk,i,t
    for i < t. ▷ Tối ưu hóa trong (4)
end for

Thuật toán 2 ITL với các gia tăng hạng-1 (Suy luận)
Đầu vào: Dữ liệu kiểm tra x với danh tính tác vụ t.
Lấy trọng số đã huấn luyện: Wt={Uk,i, Vk,i, Sk,i,t} cho tất cả k và i≤t.
Đầu ra: Tính toán đầu ra mạng là f(x,Wt).

4 Thí nghiệm và Kết quả

Chúng tôi sử dụng các tác vụ phân loại khác nhau trên các chuẩn mực học liên
tục nổi tiếng để chứng minh tầm quan trọng của phương pháp đề xuất của chúng tôi.

4.1 Tập dữ liệu và Mô tả Tác vụ

Thí nghiệm được thực hiện trên bốn tập dữ liệu: Split CIFAR100, Permuted MNIST,
Rotated MNIST, và Split MiniImageNet.

P-MNIST tạo các tác vụ mới bằng cách áp dụng một hoán vị ngẫu nhiên nhất định
trên các pixel của tất cả hình ảnh trong tập dữ liệu gốc. Trong thí nghiệm của
chúng tôi, chúng tôi tạo ra 20 tác vụ khác nhau, mỗi tác vụ tương ứng với một
hoán vị nhất định nhưng khác nhau.

R-MNIST tương tự như Permuted MNIST, nhưng thay vì áp dụng một hoán vị ngẫu
nhiên nhất định trên các pixel, nó áp dụng một xoay ngẫu nhiên nhất định cho
các hình ảnh trong cùng tác vụ. Chúng tôi tạo ra 20 tác vụ khác nhau, mỗi tác
vụ tương ứng với một phiên bản xoay nhất định nhưng khác nhau từ khoảng [0, 180] độ.

S-CIFAR100 chia tập dữ liệu CIFAR-100 gốc thành 20 tập không rời rạc, mỗi tập
chứa 5 lớp, được coi là một tác vụ riêng biệt. 5 lớp trong mỗi tác vụ được
chọn ngẫu nhiên không thay thế từ tổng số 100 lớp.

S-miniImageNet chia một tập con của tập dữ liệu Imagenet thành 20 tập không
rời rạc, mỗi tập chứa 5 lớp, được coi là một tác vụ riêng biệt. 5 lớp trong
mỗi tác vụ được chọn ngẫu nhiên không thay thế từ tổng số 100 lớp.

--- TRANG 8 ---
8 R. Hyder et al.

4.2 Chi tiết Huấn luyện

Mạng. Trong tập hợp thí nghiệm đầu tiên, chúng tôi sử dụng một perceptron
đa lớp (MLP) ba lớp (được kết nối đầy đủ) với các lớp ẩn 256-node, tương tự
như mạng trong [7]. Chúng tôi làm phẳng đầu vào hình ảnh đa chiều thành một
đầu vào vector 1D. Chúng tôi sử dụng kích hoạt ReLU cho tất cả các lớp trừ
lớp cuối cùng. Chúng tôi sử dụng Softmax cho các tác vụ phân loại đa lớp.
Chúng tôi sử dụng cùng một mạng cho tất cả các tác vụ với những sửa đổi cần
thiết cho kích thước đầu vào và đầu ra. Phương pháp của chúng tôi cũng có thể
được sử dụng trong các mạng tích chập. Chúng tôi báo cáo kết quả sử dụng
ResNet18 với phương pháp của chúng tôi trên tập dữ liệu S-CIFAR100 và
S-miniImageNet trong Bảng 6.

Phân tích nhân tử và lựa chọn hạng. Chúng tôi sử dụng phân tích nhân tử ma
trận được định nghĩa trong (3) trong tất cả các thí nghiệm của chúng tôi.
Chúng tôi chọn hạng một cách thực nghiệm cho tác vụ đầu tiên, rk,1 là 11 dựa
trên các thí nghiệm trên một tác vụ Rotated MNIST mẫu và giữ cùng giá trị
cho tất cả các thí nghiệm. Sau đó chúng tôi thực hiện gia tăng hạng-1 (rk,t)
cho mỗi tác vụ bổ sung. Chúng tôi muốn chỉ ra rằng AGEM và Orthog Subspace
sử dụng 3 tác vụ đầu tiên để điều chỉnh siêu tham số. Chúng tôi không điều
chỉnh các siêu tham số của mình trên dữ liệu kiểm tra, thay vào đó chúng tôi
chọn các tham số cung cấp sự hội tụ tốt hơn trong quá trình huấn luyện. Chúng
tôi tăng các ma trận trọng số theo hạng-1 cho mỗi tác vụ; do đó, tốc độ học
và số lượng epochs là các siêu tham số duy nhất trong các thí nghiệm của chúng tôi.

Tối ưu hóa. Chúng tôi sử dụng khởi tạo trực giao cho các nhân tử hạng thấp,
như được mô tả trong [32]. Chúng tôi sử dụng khởi tạo tất cả một cho các nhân
tử bổ sung của các ma trận chọn lọc Sk,t,t. Chúng tôi sử dụng tối ưu hóa Adam
để cập nhật các nhân tử. Chúng tôi sử dụng kích thước batch là 128 cho mỗi tác vụ.

Thước đo hiệu suất. Chúng tôi sử dụng độ chính xác và sự quên cho mỗi tác vụ,
đây là hai thước đo thường được sử dụng trong tài liệu học liên tục [6,7], để
đánh giá hiệu suất của các phương pháp được mô tả. Gọi at,j là độ chính xác
kiểm tra của tác vụ j < t sau khi mô hình đã hoàn thành việc học tác vụ t∈{1, ..., T}
theo cách tăng dần. Độ chính xác trung bình At sau khi mô hình đã học tác vụ t
được định nghĩa là At=1/t∑tj=1at,j. Mặt khác, quên là sự giảm trong độ chính
xác của một tác vụ sau khi huấn luyện của nó, và sau khi một hoặc nhiều tác
vụ được học tăng dần. Chúng tôi định nghĩa sự quên trung bình Ft là
Ft=1/(t-1)∑t-1j=1(aj,j-at,j).

Trong Hình 2, chúng tôi hiển thị sự tiến triển của độ chính xác trung bình At
khi t tăng. Chúng tôi cũng hiển thị sự tiến triển của độ chính xác theo tác vụ
at,j trong Hình 3, nơi cường độ pixel (t,j) phản ánh at,j. Chúng tôi báo cáo
độ chính xác trung bình AT, độ chính xác trung bình sau khi mô hình đã học
mọi tác vụ tăng dần, trong Bảng 1. Chúng tôi báo cáo sự quên FT sau khi mô
hình đã học tất cả các tác vụ tăng dần trong Bảng 2. Lưu ý rằng phương pháp
của chúng tôi thực hiện học tác vụ tăng dần mà không quên.

4.3 So sánh Các Kỹ thuật

Chúng tôi so sánh phương pháp của mình với các phương pháp ITL hiện đại khác
nhau. EWC [15] là một phương pháp dựa trên chính quy hóa sử dụng ma trận
Fisher Information để ước tính hậu nghiệm của các tác vụ trước đó để bảo tồn
các tham số quan trọng. ICARL [27] là một phương pháp dựa trên bộ nhớ sử
dụng các mẫu và chưng cất kiến thức [13] để giữ lại kiến thức trước đó. AGEM
[8] là một phương pháp dựa trên bộ nhớ

--- TRANG 9 ---
Học Tác Vụ Tăng Dần với Cập Nhật Hạng Tăng Dần 9

Bảng 1: Độ chính xác kiểm tra trung bình của ITL cho P-MNIST, R-MNIST, S-CIFAR100,
và S-miniImageNet với MLP ba lớp. Độ lệch chuẩn của độ chính xác kiểm tra trên năm lần
chạy được hiển thị trong ngoặc đơn cho một số thí nghiệm.
∗Không gian con Orthog không sử dụng bộ đệm phát lại cho các biến thể MNIST.

Phương pháp | Bộ đệm Phát lại | P-MNIST | R-MNIST | S-CIFAR100 | S-miniImageNet
EWC [15] | Không | 67.9 (±0.68) | 44.5 (±1.09) | 52.7 (±0.81) | 29.3 (±1.08)
ICARL [27] | Có | 85.4 (±0.01) | 51.2 (±2.41) | 56.9 (±0.31) | 39.9 (±0.27)
AGEM [8] | Có | 73.9 (±0.52) | 53.4 (±1.80) | 51.3 (±1.54) | 31.3 (±0.89)
HAT [33] | Không | 90.1 (±1.60) | 89.1 (±2.51) | 64.8 (±0.32) | 47.0 (±0.88)
PackNet [19] | Không | 90.0 (±0.24) | 88.4 (±0.37) | 63.7 (±0.41) | 45.1 (±1.05)
Orth sub [7] | Có∗ | 86.6 (±0.79) | 80.2 (±0.41) | 57.8 (±1.03) | 38.1 (±0.67)
Adam-NSCL[37] | Không | – | – | 64.26 | 47.32
IBP-WF [22] | Không | – | – | 53.22 | 40.52
Của chúng tôi | Không | 85.6 (±0.15) | 91.1 (±0.12) | 65.9 (±2.16) | 54.7 (±2.87)
Song song 2 (r=2) | - | 65.3 | 65.5 | 62.8 | 55.4
Song song 4 (r=4) | - | 86.3 | 87.4 | 65.6 | 58.6
Song song fullrank | - | 95.9 | 97.3 | 73.1 | 63.1
Đa tác vụ | - | 96.8 | 97.7 | 16.4 | 4.21

được xây dựng dựa trên [17] sử dụng bộ nhớ cảnh để giải quyết một bài toán
tối ưu hóa có ràng buộc. ER-Ring [9] là một phương pháp dựa trên bộ nhớ khác
cùng huấn luyện trên dữ liệu tác vụ mới với dữ liệu của các tác vụ trước đó.
Orth. sub. [7] học các tác vụ trong các không gian con vector khác nhau (hạng
thấp) được giữ trực giao với nhau để giảm thiểu can thiệp. Ngoài các phương
pháp được đề cập ở trên, chúng tôi so sánh với các phương pháp dựa trên mặt
nạ cũng thuộc danh mục kiến trúc động như phương pháp của chúng tôi. HAT
[33] kết hợp các embedding cụ thể tác vụ để che giấu attention. PackNet [19]
lặp lại gán các tập con của một mặt nạ nhị phân duy nhất cho mỗi tác vụ. Các
phương pháp dựa trên mặt nạ tận dụng sự dư thừa của các tham số mạng để
biểu diễn các tác vụ khác nhau với các phiên bản mặt nạ khác nhau của cùng
trọng số mạng. Chúng tôi cũng trình bày so sánh với một số phương pháp gần
đây: IBP-WF [22] và Adam-NSCL [37], về độ chính xác trung bình cho một
thí nghiệm trên hai tập dữ liệu.

Ngoài ra, chúng tôi báo cáo kết quả cho hai phương pháp cơ sở không liên tục:
Học Song song và Học Đa tác vụ. Học Song song huấn luyện các mạng hạng thấp
độc lập (nhỏ hơn) cùng kích thước cho mỗi tác vụ. Chúng tôi báo cáo kết quả
cho ba mạng như vậy. Song song 2 sử dụng các lớp hạng-2, Song song 4 sử dụng
các lớp hạng-4, và Song song full sử dụng một MLP hạng đầy đủ. Song song 2
đòi hỏi khoảng cùng số lượng tham số như mạng ITL hạng-1 mà chúng tôi sử
dụng trong các thí nghiệm của mình; Song song 4 cung cấp khả năng mạng cao
hơn, trong khi đòi hỏi ít tham số hơn so với mạng hạng đầy đủ. Chúng ta có
thể coi hiệu suất của phương pháp Song song full như giới hạn trên mà chúng
ta có thể đạt được sử dụng các phương pháp ITL. Cuối cùng, Học Đa tác vụ
đã được sử dụng như một cơ sở trong [7,8]. Trong học đa tác vụ, chúng ta có
quyền truy cập vào tất cả dữ liệu để tối ưu hóa một mạng duy nhất.

--- TRANG 10 ---
10 R. Hyder et al.

Bảng 2: Kết quả quên trung bình tương ứng với Bảng 1 cho các tập dữ liệu khác nhau
sử dụng các phương pháp khác nhau. Chúng tôi báo cáo sự quên theo đơn vị phần trăm (%).
Chúng tôi cũng báo cáo độ lệch chuẩn trên 5 thí nghiệm cho một số phương pháp.

EWC | AGEM | Không gian con Orthog | Adam-NSCL | Song song fullrank, HAT, PackNet | Của chúng tôi, IBP-WF
P-MNIST | 25.8 (±0.70) | 19.6 (±0.64) | 4.49 (±0.93) | - | 0
R-MNIST | 52.9 (±1.17) | 44.2 (±1.85) | 14.7 (±0.39) | - | 0
S-CIFAR100 | 6.96 (±0.80) | 21.5 (±2.89) | 6.30 (±0.38) | 8.5 | 0
S-miniImageNet | 17.3 (±1.81) | 18.8 (±1.40) | 9.98 (±0.31) | 11.23 | 0

4.4 Kết quả với MLP Ba lớp

Hiệu suất phân loại và so sánh. Chúng tôi báo cáo kết quả phân loại cho các
tác vụ P-MNIST, R-MNIST, S-CIFAR100, và S-miniImageNet trong Bảng 1.
Chúng tôi cũng hiển thị kết quả cho các kỹ thuật so sánh. Chúng tôi quan sát
thấy rằng phương pháp của chúng tôi với cập nhật hạng-1 hoạt động tốt hơn
tất cả các phương pháp so sánh (EWC, ICARL, AGEM, HAT, PackNet, Orthog
Subspace) trên các tác vụ R-MNIST, S-CIFAR100 và S-miniImageNet sử dụng
số lượng tham số ít hơn đáng kể. Phương pháp của chúng tôi hoạt động gần với
Orthog Subspace trên các tác vụ P-MNIST.

Hình 2: Độ chính xác kiểm tra trung bình cho các tập dữ liệu khác nhau (Permuted MNIST,
Rotated MNIST, Split CIFAR100, Split miniImageNet) cùng các tác vụ khác nhau sử dụng
các thuật toán khác nhau (AGEM, EWC, Orthog. Subspace, ICARL và phương pháp của chúng tôi).
Chúng tôi sử dụng MLP ba lớp ở đây. Kết quả Song song full-rank tương ứng với trường hợp
khi chúng tôi huấn luyện mỗi tác vụ trên các mạng hạng đầy đủ riêng biệt độc lập (phục vụ
như một giới hạn trên cho các phương pháp ITL). Chúng tôi hiển thị trung bình của 20 tác vụ.

Chúng tôi cũng quan sát thấy rằng cập nhật hạng-1 đề xuất vượt trội hơn cơ sở
Song song 2 không liên tục có số lượng tham số tương tự so với phương pháp

--- TRANG 11 ---
Học Tác Vụ Tăng Dần với Cập Nhật Hạng Tăng Dần 11

Hình 3: Tiến triển của độ chính xác kiểm tra theo tác vụ trên các tập dữ liệu P-MNIST
(hàng đầu) và R-MNIST (hàng thứ hai) cho EWC, Không gian con Trực giao, và Phương pháp
của chúng tôi. Chúng ta có thể quan sát từ sự giảm trong độ chính xác kiểm tra rằng EWC
và Không gian con Trực giao quên các tác vụ trước đó khi họ học các tác vụ mới. Phương
pháp của chúng tôi không hiển thị bất kỳ sự quên nào khi chúng ta học các tác vụ mới.

của chúng tôi. Chúng tôi hoạt động tương tự như cơ sở Song song 4 sử dụng gần
gấp đôi số lượng tham số so với phương pháp của chúng tôi. Song song full hoạt
động như một giới hạn trên với cấu trúc mạng mà chúng tôi lựa chọn vì nó
huấn luyện các mạng hạng đầy đủ độc lập cho mỗi tác vụ. Học Đa tác vụ là
một cơ sở không liên tục khác sử dụng tất cả dữ liệu từ tất cả các tác vụ
đồng thời. Bảng 1 gợi ý rằng phương pháp ITL của chúng tôi có thể học các
tác vụ phức tạp như phân loại CIFAR100 và miniImageNet với một MLP ba lớp,
trong khi học đa tác vụ (đang giải quyết bài toán phân loại 100 lớp) thất bại
với một mạng đơn giản như vậy. Chúng tôi cũng thử nghiệm mạng Resnet18,
có số lượng tham số nhiều hơn đáng kể so với mạng được sử dụng trong Bảng 1.
Kết quả cho Resnet18 được trình bày trong Bảng 6.

Chúng tôi trình bày hiệu suất kiểm tra theo tác vụ cho một số phương pháp so
sánh trên các tập dữ liệu P-MNIST, R-MNIST, S-CIFAR100 và S-miniImageNet
trong Hình 2. Chúng tôi quan sát thấy rằng khi chúng ta huấn luyện các tác vụ
mới, hiệu suất theo tác vụ giảm đối với các phương pháp so sánh, đặc biệt là
cho P-MNIST và R-MNIST.

ICARL và AGEM đòi hỏi bộ đệm phát lại (bộ nhớ cảnh) cho mỗi tác vụ. Mặc dù
Orthog Subspace không sử dụng bộ đệm phát lại cho các thí nghiệm MNIST,
nó đòi hỏi bộ đệm phát lại trong thuật toán của họ và đã sử dụng nó cho các
thí nghiệm S-CIFAR100 và S-miniImageNet. EWC không đòi hỏi bất kỳ bộ đệm
phát lại nào, nhưng nó chịu sự quên cao như được hiển thị trong Hình 3.
Phương pháp đề xuất của chúng tôi không đòi hỏi bộ đệm phát lại, và nó vượt
trội hơn các phương pháp khác trong Bảng 1.

Độ chính xác so với sự quên. Chúng tôi báo cáo sự quên trung bình của các
phương pháp so sánh khác nhau trong Bảng 2. Phương pháp của chúng tôi, các
phương pháp dựa trên mặt nạ (HAT và

--- TRANG 12 ---
12 R. Hyder et al.

Bảng 3: Số lượng tham số và kích thước bộ đệm trong các phương pháp ITL với MLP 3 lớp.

Của chúng tôi | IBP-WF | EWC | AGEM | Ortho Sub | Adam-NSCL | Song song fullrank
# tham số | 0.17M | 0.23M | 0.93M | 1.76M | 2.82M | 0.88M | 19.7M
kích thước bộ đệm | 0 | 0 | 1.71M | 7.90M | 9.01M | 0 | 0

Bảng 4: Số lượng tham số được sử dụng bởi các thuật toán quên bằng không khác nhau
(HAT, PackNet, và Của chúng tôi) sử dụng MLP 3 lớp.

Phương pháp | P/R-MNIST | S-CIFAR100 | S-miniImageNet
HAT | 0.33M | 0.89M | 5.51M
PackNet | 0.26M | 0.83M | 5.50M
Của chúng tôi | 0.11M | 0.17M | 0.72M

PackNet) và các cơ sở song song có quên bằng không, trong khi tất cả các
phương pháp so sánh khác thể hiện một mức độ quên nhất định. Để chứng minh
tốt hơn sự quên, trong Hình 3, chúng tôi hiển thị độ chính xác cho các tác vụ
trong toàn bộ quy trình huấn luyện. Hàng thứ i (từ trên xuống dưới) của sơ
đồ biểu thị hiệu suất của i tác vụ trên các tập kiểm tra khi chúng ta huấn
luyện tác vụ thứ i. Như mong đợi, chúng ta có thể quan sát thấy rằng hiệu suất
huấn luyện cho các tác vụ đã học trước đó thường giảm với việc huấn luyện
dần dần các tác vụ tiếp theo đặc biệt là đối với phương pháp dựa trên chính
quy hóa, EWC. Tuy nhiên, thuật toán của chúng tôi duy trì cùng hiệu suất cho
các tác vụ trong quá khứ vì chúng ta không thay đổi bất kỳ nhân tử nào đã
học trước đó. Ngay cả phương pháp không gian con trực giao cũng quan sát thấy
sự quên như vậy trên một số tác vụ.

Độ phức tạp bộ nhớ. Phương pháp của chúng tôi tăng hạng của mỗi lớp cho
mỗi tác vụ; do đó, chúng tôi so sánh tổng số tham số trong mạng được huấn
luyện tăng dần và các cơ sở Song song. Lưu ý rằng nếu số lượng tham số trong
hai phương pháp giống nhau, chúng ta có thể huấn luyện một mạng nhỏ cho mỗi
tác vụ độc lập. Chúng tôi báo cáo tổng số tham số và kích thước bộ đệm phát
lại cho các phương pháp khác nhau trong Bảng 3. Vì chúng tôi sử dụng cấu
trúc mạng được kết nối đầy đủ tương tự cho tất cả các tác vụ, chúng tôi báo
cáo kết quả cho các thí nghiệm Split CIFAR100. Mặc dù chúng tôi tăng hạng
cho mỗi tác vụ, sự gia tăng đủ nhỏ để ngay cả sau 20 tác vụ tổng số tham số
của chúng tôi vẫn nhỏ hơn tất cả các phương pháp khác.

Chúng tôi cũng báo cáo số lượng tham số được sử dụng bởi các thuật toán
quên bằng không dựa trên mặt nạ (HAT và PackNet) để học 20 tác vụ khác nhau
trên các tập dữ liệu khác nhau trong Bảng 4. Chúng ta có thể quan sát thấy
rằng phương pháp của chúng tôi vượt trội hơn HAT và PackNet cho R-MNIST,
S-CIFAR100 và S-miniImageNet với số lượng tham số nhỏ hơn đáng kể. Mặc dù
tất cả các phương pháp sử dụng cùng mạng, phương pháp của chúng tôi sử dụng
các nhân tử hạng-1 đòi hỏi số lượng tham số nhỏ hơn đáng kể cho việc học
tăng dần các tác vụ. Lưu ý rằng các thí nghiệm P-MNIST và R-MNIST đòi hỏi
cùng số lượng tham số.

Hiệu ứng của hạng. Trong Bảng 5, chúng tôi đánh giá hiệu ứng của việc lựa
chọn hạng khác nhau cho các tập dữ liệu MNIST khác nhau sử dụng phương pháp
ITL của chúng tôi. Chúng tôi thử nghiệm hạng ban đầu (hạng cho tác vụ đầu
tiên) là 1, 6, và 11, giữ gia tăng hạng là 1. Chúng tôi quan sát thấy rằng độ
chính xác tăng khi hạng ban đầu tăng, và chúng tôi

--- TRANG 13 ---
Học Tác Vụ Tăng Dần với Cập Nhật Hạng Tăng Dần 13

Bảng 5: Độ chính xác kiểm tra cho các lựa chọn hạng khác nhau của phương pháp ITL
đề xuất và mạng cơ sở đa tác vụ cho P-MNIST và R-MNIST. Hạng ban đầu là rk,1 và
gia tăng hạng/tác vụ là rk,t.

Thiết lập | 1 | 2 | 3 | 4 | 5
(rk,1, rk,t) | (1,1) | (6,1) | (11,1) | (11,2) | (11,4)
P-MNIST | 74.23 | 82.21 | 85.61 | 90.51 | 93.84
R-MNIST | 81.57 | 89.39 | 91.09 | 92.76 | 94.12
# tham số | 0.09M | 0.1M | 0.11M | 0.14M | 0.2M

đạt được gần 90% độ chính xác với hạng ban đầu là 11. Chúng tôi cũng thử
nghiệm các giá trị khác nhau của gia tăng hạng cho mỗi tác vụ và quan sát
thấy rằng độ chính xác tăng với gia tăng hạng lớn hơn. Tuy nhiên, gia tăng
hạng-1 cung cấp cho chúng tôi hiệu suất tương đương hoặc tốt hơn so với các
kỹ thuật so sánh như được hiển thị trong Bảng 1.

4.5 Kết quả với ResNet18

Phương pháp gia tăng hạng thấp đề xuất có thể được tổng quát hóa cho các
loại mạng và lớp khác. Ví dụ, các kernel tích chập có tensor trọng số bốn
chiều trái ngược với ma trận trọng số hai chiều của các lớp được kết nối đầy
đủ. Chúng thường được công thức hóa như một tensor của kênh đầu ra và đầu
vào (Cout, Cin), và hai chiều của các bộ lọc tích chập (H, W). Chúng tôi định
hình lại các tensor trọng số tích chập thành ma trận có kích thước Cout×CinHW
và thực hiện các cập nhật hạng thấp tương tự cho mỗi tác vụ như chúng tôi
đã mô tả cho MLP trong bài báo chính. Chúng tôi báo cáo kết quả cho các tập
dữ liệu S-CIFAR-100 và S-miniImageNet với kiến trúc Resnet18. Đối với mỗi
lớp tích chập, chúng tôi định hình lại và phân tích các tensor trọng số tích
chập thành các nhân tử hạng thấp giống như được mô tả trong (3) và thực hiện
các cập nhật hạng thấp cho mỗi tác vụ.

Chúng tôi báo cáo kết quả trong Bảng 6. Đối với hầu hết các kỹ thuật so sánh,
kết quả từ [7] được báo cáo vì chúng tôi sử dụng cùng kiến trúc và tập dữ
liệu. Đối với các so sánh bị thiếu, chúng tôi huấn luyện các mô hình sử dụng
cùng quy trình như được nêu trong [7].

Thay vì sử dụng một giá trị cố định cho hạng tại mỗi lớp như chúng tôi đã
làm trong thiết lập MLP, chúng tôi sử dụng kích thước hạng tỷ lệ với kích
thước của Cout,i tại lớp tích chập thứ i vì trọng số cho các lớp khác nhau
của ResNet18 khác nhau về kích thước. Chúng tôi chọn hạng ban đầu = 0.1Cout,i
cho tác vụ đầu tiên và hạng gia tăng = 0.02Cout,i cho các tác vụ gia tăng tiếp theo.

Kết quả trong Bảng 6 cho thấy rằng hiệu suất của mọi phương pháp cải thiện
với cấu trúc ResNet18 tích chập so với MLP 3 lớp. Tuy nhiên, phương pháp của
chúng tôi vượt trội hơn các phương pháp so sánh cho cả hai tập dữ liệu. Adam-NSCL
[37] có kết quả tốt hơn trên CIFAR100, nhưng nó đòi hỏi 11.21M tham số (so
với 1.33M tham số mà phương pháp của chúng tôi đòi hỏi).

Hiệu ứng của việc cập nhật vài lớp cuối. Chúng tôi thực hiện một thí nghiệm
trên S-CIFAR-100 nơi chúng tôi phân tích nhân tử L lớp cuối của kiến trúc
ResNet18 giữ phần còn lại của mạng cố định tại trọng số đã huấn luyện trên
Tác vụ 1. Cập nhật L lớp cuối =

--- TRANG 14 ---
14 R. Hyder et al.

Bảng 6: So sánh độ chính xác kiểm tra và sự quên cho các tập dữ liệu split CIFAR-100
và split miniImageNet sử dụng kiến trúc ResNet18.

Phương pháp | S-CIFAR-100 | S-miniImageNet
 | Độ chính xác | Sự quên | Độ chính xác | Sự quên
EWC [15] | 43.2 (±2.77) | 26 (±2) | 34.8 (±2.34) | 24 (±4)
ICARL [27] | 46.4 (±1.21) | 16 (±1) | 44.2 | 24.64
AGEM [8] | 60.34 (±2.05) | 11.0 (±2.88) | 42.3 (±1.42) | 17 (±1)
ER-Ring [9] | 59.6 (±11.9) | 0.14 (±1) | 49.8 (±2.92) | 12 (±1)
Ortho sub [7] | 63.42 (±1.82) | 8.37 (±0.71) | 51.4 (±1.44) | 10 (±1)
Adam-NSCL [37] | 74.31 | 9.47 | 57.92 | 13.42
IBP-WF [22] | 68.25 | 0 | 55.84 | 0
Của chúng tôi | 68.46 (±2.52) | 0 | 59.26 (±1.15) | 0
Song song full-rank | 92.7 | 0 | 94.5 | 0
Học đa tác vụ | 70.2 | 0 | 65.1 | 0

{1,2,3,4,5} lớp cung cấp độ chính xác trung bình là {34.38,34.99,53.41,57.08,65.03},
tương ứng. Kết quả này gợi ý rằng việc cập nhật vài lớp cuối có thể đủ vì
các lớp ban đầu chỉ đơn giản hoạt động như một bộ trích xuất đặc trưng.

5 Kết luận

Chúng tôi đã đề xuất một phương pháp học tác vụ tăng dần mới trong đó chúng
tôi cập nhật trọng số mạng sử dụng các gia tăng hạng thấp khi chúng ta học
các tác vụ mới. Các lớp mạng được biểu diễn như một tổ hợp tuyến tính của
các nhân tử hạng thấp. Để cập nhật mạng cho một tác vụ mới, chúng tôi đóng
băng các nhân tử đã học cho các tác vụ trước đó, thêm một nhân tử hạng thấp
(hoặc hạng-1) mới, và kết hợp nó với các nhân tử trước đó sử dụng một tổ
hợp đã học. Phương pháp đề xuất cung cấp cải thiện đáng kể về hiệu suất so
với các phương pháp hiện đại cho ITL trong các tác vụ phân loại hình ảnh.
Ngoài ra, ITL hạng thấp đề xuất tránh việc sử dụng bộ đệm bộ nhớ hoặc chi
phí bộ nhớ lớn trong khi đạt được quên bằng không.

Nhu cầu về kiến thức ID tác vụ là một hạn chế chung của phương pháp ITL
của chúng tôi và các phương pháp khác. Các phương pháp như vậy có thể hữu
ích cho việc học đa tác vụ tăng dần nơi ID tác vụ có sẵn trong quá trình suy
luận nhưng dữ liệu huấn luyện chỉ có sẵn trong một cửa sổ ngắn. Mở rộng
phương pháp này cho việc học tăng dần lớp (không đòi hỏi ID tác vụ) là một
vấn đề quan trọng cho công việc tương lai.

Lời cảm ơn. Tài liệu này dựa trên công việc được hỗ trợ một phần bởi Văn
phòng Nghiên cứu Khoa học Không quân (AFOSR) các giải thưởng FA9550-21-1-0330,
FA9550-20-1-0039, Văn phòng Nghiên cứu Hải quân (ONR) giải thưởng N00014-19-1-2264,
và Quỹ Khoa học Quốc gia (NSF) giải thưởng CCF-2046293. Được phê duyệt cho
Phát hành Công khai bởi AFRL; Phân phối Không giới hạn: Số trường hợp AFRL-2021-4063
Tác giả liên lạc: M. Salman Asif (sasif@ucr.edu)

--- TRANG 15 ---
Học Tác Vụ Tăng Dần với Cập Nhật Hạng Tăng Dần 15

Tài liệu tham khảo

1. Abati, D., Tomczak, J., Blankevoort, T., Calderara, S., Cucchiara, R., Bejnordi,
B.E.: Conditional channel gated networks for task-aware continual learning. In:
Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition. pp. 3930–3939 (2020)

2. Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M., Tuytelaars, T.: Memory
aware synapses: Learning what (not) to forget. In: Proceedings of the European
Conference on Computer Vision (ECCV). pp. 139–154 (2018)

3. Aljundi, R., Chakravarty, P., Tuytelaars, T.: Expert gate: Lifelong learning with a
network of experts. In: Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. pp. 3366–3375 (2017)

4. Aljundi, R., Lin, M., Goujaud, B., Bengio, Y.: Gradient based sample selection for
online continual learning. Advances in Neural Information Processing Systems 32,
11816–11825 (2019)

5. Buzzega, P., Boschini, M., Porrello, A., Abati, D., Calderara, S.: Dark experience
for general continual learning: a strong, simple baseline. Advances in neural information processing systems 33, 15920–15930 (2020)

6. Chaudhry, A., Dokania, P.K., Ajanthan, T., Torr, P.H.: Riemannian walk for incremental learning: Understanding forgetting and intransigence. In: Proceedings of
the European Conference on Computer Vision (ECCV). pp. 532–547 (2018)

7. Chaudhry, A., Khan, N., Dokania, P., Torr, P.: Continual learning in low-rank orthogonal subspaces. Advances in Neural Information Processing Systems 33(2020)

8. Chaudhry, A., Marc'Aurelio, R., Rohrbach, M., Elhoseiny, M.: Efficient lifelong
learning with a-gem. In: International Conference on Learning Representations,
ICLR (2019)

9. Chaudhry, A., Rohrbach, M., Elhoseiny, M., Ajanthan, T., Dokania, P.K., Torr,
P.H., Ranzato, M.: On tiny episodic memories in continual learning. arXiv preprint
arXiv:1902.10486 (2019)

10. Delange, M., Aljundi, R., Masana, M., Parisot, S., Jia, X., Leonardis, A., Slabaugh,
G., Tuytelaars, T.: A continual learning survey: Defying forgetting in classification
tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence (2021)

11. Deng, D., Chen, G., Hao, J., Wang, Q., Heng, P.A.: Flattening sharpness for dynamic gradient projection memory benefits continual learning. Advances in Neural
Information Processing Systems 34(2021)

12. Farajtabar, M., Azizan, N., Mott, A., Li, A.: Orthogonal gradient descent for continual learning. In: International Conference on Artificial Intelligence and Statistics. pp. 3762–3773. PMLR (2020)

13. Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural network.
NeurIPS (2014)

14. Hurtado, J., Raymond-Saez, A., Soto, A.: Optimizing reusable knowledge for continual learning via metalearning. Advances in Neural Information Processing Systems34(2021)

15. Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu,
A.A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et al.: Overcoming
catastrophic forgetting in neural networks. Proceedings of the national academy of
sciences 114(13), 3521–3526 (2017)

16. Li, Z., Hoiem, D.: Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence 40(12), 2935–2947 (2017)

--- TRANG 16 ---
16 R. Hyder et al.

17. Lopez-Paz, D., Ranzato, M.: Gradient episodic memory for continual learning.
Advances in neural information processing systems 30, 6467–6476 (2017)

18. Mallya, A., Davis, D., Lazebnik, S.: Piggyback: Adapting a single network to multiple tasks by learning to mask weights. In: Proceedings of the European Conference
on Computer Vision (ECCV). pp. 72–88 (2018)

19. Mallya, A., Lazebnik, S.: Packnet: Adding multiple tasks to a single network by
iterative pruning. In: Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. pp. 7765–7773 (2018)

20. Masse, N.Y., Grant, G.D., Freedman, D.J.: Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization. Proceedings of the National Academy of Sciences 115(44), E10467–E10475 (2018)

21. McCloskey, M., Cohen, N.J.: Catastrophic interference in connectionist networks:
The sequential learning problem. In: Psychology of learning and motivation, vol. 24,
pp. 109–165. Elsevier (1989)

22. Mehta, N., Liang, K., Verma, V.K., Carin, L.: Continual learning using a bayesian
nonparametric dictionary of weight factors. In: International Conference on Artificial Intelligence and Statistics. pp. 100–108. PMLR (2021)

23. Nguyen, C.V., Li, Y., Bui, T.D., Turner, R.E.: Variational continual learning. In:
International Conference on Learning Representations (2018)

24. von Oswald, J., Henning, C., Sacramento, J., Grewe, B.F.: Continual learning with
hypernetworks. In: International Conference on Learning Representations (2019)

25. Parisi, G.I., Kemker, R., Part, J.L., Kanan, C., Wermter, S.: Continual lifelong
learning with neural networks: A review. Neural Networks 113, 54–71 (2019)

26. Ratcliff, R.: Connectionist models of recognition memory: constraints imposed by
learning and forgetting functions. Psychological review 97(2), 285 (1990)

27. Rebuffi, S.A., Kolesnikov, A., Sperl, G., Lampert, C.H.: icarl: Incremental classifier and representation learning. In: Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. pp. 2001–2010 (2017)

28. Riemer, M., Cases, I., Ajemian, R., Liu, M., Rish, I., Tu, Y., Tesauro, G.: Learning
to learn without forgetting by maximizing transfer and minimizing interference.
In: International Conference on Learning Representations (2019)

29. Rolnick, D., Ahuja, A., Schwarz, J., Lillicrap, T., Wayne, G.: Experience replay
for continual learning. Advances in Neural Information Processing Systems 32,
350–360 (2019)

30. Rusu, A.A., Rabinowitz, N.C., Desjardins, G., Soyer, H., Kirkpatrick, J.,
Kavukcuoglu, K., Pascanu, R., Hadsell, R.: Progressive neural networks. arXiv
preprint arXiv:1606.04671 (2016)

31. Saha, G., Garg, I., Roy, K.: Gradient projection memory for continual learning. In:
International Conference on Learning Representations (2021)

32. Saxe, A.M., McClelland, J.L., Ganguli, S.: Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. arXiv preprint arXiv:1312.6120
(2013)

33. Serra, J., Suris, D., Miron, M., Karatzoglou, A.: Overcoming catastrophic forgetting with hard attention to the task. In: International Conference on Machine
Learning. pp. 4548–4557. PMLR (2018)

34. Silver, D.L., Mercer, R.E.: The task rehearsal method of life-long learning: Overcoming impoverished data. In: Conference of the Canadian Society for Computational Studies of Intelligence. pp. 90–101. Springer (2002)

35. Tang, S., Chen, D., Zhu, J., Yu, S., Ouyang, W.: Layerwise optimization by gradient decomposition for continual learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 9634–9643 (2021)

--- TRANG 17 ---
Học Tác Vụ Tăng Dần với Cập Nhật Hạng Tăng Dần 17

36. Veniat, T., Denoyer, L., Ranzato, M.: Efficient continual learning with modular
networks and task-driven priors. In: International Conference on Learning Representations (2021)

37. Wang, S., Li, X., Sun, J., Xu, Z.: Training networks in null space of feature covariance for continual learning. In: Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition. pp. 184–193 (2021)

38. Wen, Y., Tran, D., Ba, J.: Batchensemble: an alternative approach to efficient
ensemble and lifelong learning. In: International Conference on Learning Representations (2020)

39. Wortsman, M., Ramanujan, V., Liu, R., Kembhavi, A., Rastegari, M., Yosinski, J.,
Farhadi, A.: Supermasks in superposition. Advances in Neural Information Processing Systems 33(2020)

40. Yin, H., Li, P., et al.: Mitigating forgetting in online continual learning with neuron calibration. Advances in Neural Information Processing Systems 34(2021)

41. Yoon, J., Yang, E., Lee, J., Hwang, S.J.: Lifelong learning with dynamically
expandable networks. In: International Conference on Learning Representations
(2018)

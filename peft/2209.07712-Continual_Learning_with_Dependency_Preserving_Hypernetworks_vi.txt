# 2209.07712.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2209.07712.pdf
# Kích thước tệp: 446819 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Học Liên Tục với Mạng Siêu Bảo Tồn Phụ Thuộc
Dupati Srikar Chandra1Sakshi Varshney1P.K. Srijith1Sunil Gupta2
1Viện Công Nghệ Ấn Độ, Ấn Độ2Đại học Deakin, Úc
{ai20resch11004,cs16resch01002 }@iith.ac.in srijith@cse.iith.ac.in sunil.gupta@deakin.edu.au
Tóm tắt
Con người học liên tục suốt đời bằng cách tích lũy kiến thức đa dạng và tinh chỉnh nó cho các nhiệm vụ tương lai. Khi được trình bày một mục tiêu tương tự, các mạng nơ-ron gặp phải hiện tượng quên thảm khốc nếu phân phối dữ liệu qua các nhiệm vụ tuần tự không ổn định trong quá trình học. Một phương pháp hiệu quả để giải quyết các vấn đề học liên tục (CL) như vậy là sử dụng mạng siêu để tạo ra các trọng số phụ thuộc nhiệm vụ cho mạng đích. Tuy nhiên, hiệu suất học liên tục của các phương pháp dựa trên mạng siêu hiện có bị ảnh hưởng bởi giả định độc lập của các trọng số qua các lớp để duy trì hiệu quả tham số. Để giải quyết hạn chế này, chúng tôi đề xuất một phương pháp mới sử dụng mạng siêu bảo tồn phụ thuộc để tạo ra trọng số cho mạng đích đồng thời duy trì hiệu quả tham số. Chúng tôi đề xuất sử dụng mạng siêu dựa trên mạng nơ-ron hồi quy (RNN) có thể tạo ra các trọng số lớp một cách hiệu quả đồng thời cho phép phụ thuộc qua chúng. Ngoài ra, chúng tôi đề xuất các kỹ thuật điều chuẩn mới và tăng trưởng mạng cho mạng siêu dựa trên RNN để cải thiện thêm hiệu suất học liên tục. Để chứng minh hiệu quả của các phương pháp đề xuất, chúng tôi đã tiến hành thí nghiệm trên một số nhiệm vụ phân loại hình ảnh học liên tục và các cài đặt. Chúng tôi thấy rằng các phương pháp đề xuất dựa trên mạng siêu RNN vượt trội hơn các đường cơ sở trong tất cả các cài đặt và nhiệm vụ CL này.

1. Giới thiệu
Có nhiều ứng dụng nơi hệ thống tính toán phải học từ một luồng dữ liệu liên tục và thích nghi với môi trường bằng cách sử dụng kiến thức thu được từ kinh nghiệm quá khứ. Ví dụ, các tác nhân tự động trong thế giới thực phải học qua các luồng dữ liệu liên tục và cần ghi nhớ thông tin từ các phân phối không ổn định khác nhau mà không quên [20]. Các mạng nơ-ron sâu đã đạt được hiệu suất cao trên nhiều điểm chuẩn phân loại hình ảnh, có thể so sánh hoặc thậm chí tốt hơn con người. Tuy nhiên, trong khi học một nhiệm vụ mới, các mạng này quên đi kiến thức thu được từ các nhiệm vụ trước đó. Quá trình quên kiến thức hoặc thông tin thu được từ các nhiệm vụ trước đó do thay đổi trọng số đột ngột trong khi học các nhiệm vụ mới được gọi là quên thảm khốc [18]. Nếu phân phối dữ liệu qua các nhiệm vụ tuần tự không ổn định, các trọng số của mô hình thay đổi đột ngột để phân loại nhiệm vụ mới, dẫn đến quên kiến thức thu được từ các nhiệm vụ trước đó. Lý tưởng là, hiệu suất của một nhiệm vụ mới học được không nên có tác động đến nhiệm vụ trước đó (hoặc ngược lại).

Để khắc phục việc quên, các hệ thống tính toán hoặc tác nhân, một mặt, phải có tính dẻo để thu nhận thông tin mới và tinh chỉnh thông tin cũ dựa trên đầu vào liên tục và, mặt khác, phải ổn định để ngăn đầu vào mới can thiệp vào thông tin cũ. Điều này được gọi là tình trạng tiến thoái lưỡng nan tính dẻo-ổn định [7, 19]. Học liên tục nhằm phát triển các mô hình học máy và học sâu đủ ổn định để giữ lại thông tin học được từ các nhiệm vụ cũ nhưng cũng có tính dẻo cần thiết để học các nhiệm vụ mới [20].

Các kỹ thuật học liên tục cho mạng nơ-ron đã nhận được sự chú ý đáng kể gần đây [20]. Một số phương pháp học liên tục đã được đề xuất để tránh quên trong mạng nơ-ron. Chúng có thể được phân loại rộng rãi thành ba phương pháp: Kỹ thuật điều chuẩn [9, 12], phương pháp kiến trúc động [2, 24] và phương pháp dựa trên phát lại [5, 21]. Gần đây, Học liên tục với mạng siêu đã cho thấy kết quả rất hứa hẹn trong việc xử lý việc quên ở mức meta bằng cách tạo ra các trọng số cụ thể cho nhiệm vụ [4, 8, 28]. Mạng siêu là một mạng nơ-ron meta tạo ra các tham số cho mạng chính liên quan đến nhiệm vụ (chẳng hạn, mạng phân loại hoặc hồi quy) bằng cách xem xét một số thông tin liên quan đến nhiệm vụ. Trong quá trình đào tạo, thay vì cố gắng cập nhật trực tiếp các tham số của mạng chính, các tham số mạng siêu tạo ra chúng được cập nhật. Nhưng việc tạo ra toàn bộ tham số mạng chính sẽ yêu cầu một mạng siêu lớn hơn vì nó cần tạo ra một đầu ra có chiều rất cao. Thay vào đó, các mạng siêu phân khối [8, 28] tạo ra chúng trong các khối nhỏ hơn (khối được gọi là tập con của trọng số mạng chính) nhiều lần một cách lặp lại bằng cách sử dụng mạng siêu nhỏ hơn có thể tái sử dụng và cũng giúp nén mô hình đáng kể.

--- TRANG 2 ---
Một hạn chế chính của mạng siêu phân khối là nó giả định các ma trận trọng số liên quan đến các khối là độc lập, điều này ảnh hưởng đáng kể đến hiệu suất học liên tục. Mạng siêu phân khối [28] sử dụng mạng nơ-ron truyền thẳng để tạo ra trọng số mà không xem xét phụ thuộc qua các khối. Chúng tôi đề xuất sử dụng mạng nơ-ron hồi quy (RNN), để nắm bắt phụ thuộc trong việc tạo ra ma trận trọng số qua các khối. Nhưng RNN tiêu chuẩn gặp vấn đề gradient biến mất và có thể không thể nhớ phụ thuộc trong thời gian dài. Vậy nên, một biến thể của RNN, LSTM [9] đã được sử dụng để nhớ phụ thuộc ma trận trọng số trong thời gian dài hơn. Do đó, chúng tôi đề xuất mạng siêu dựa trên LSTM có thể tạo ra trọng số của mạng chính một cách hiệu quả đồng thời duy trì phụ thuộc qua các khối.

Trong khi học nhiều nhiệm vụ theo cách tuần tự, mạng siêu nên nhớ kiến thức thu được từ các nhiệm vụ trước đó và cũng có thể chuyển kiến thức đó cho các nhiệm vụ sắp tới. Để đạt được điều này, chúng tôi đề xuất một kỹ thuật điều chuẩn mạng siêu mới, Điều chuẩn Trọng số Quan trọng (IWR) có thể cải thiện thêm hiệu suất của học liên tục dựa trên mạng siêu bằng cách cho phép chuyển tiếp đồng thời giữ lại thông tin trước đó. IWR xem xét tầm quan trọng của các tham số mạng chính và cho phép mạng siêu linh hoạt hơn để thích nghi với nhiệm vụ mới bằng cách xem xét tầm quan trọng này. Chúng tôi cũng đề xuất một kỹ thuật tăng trưởng mạng cho mạng siêu dựa trên LSTM để học liên tục. Phương pháp này dựa trên ý tưởng rằng sự phụ thuộc giữa các tham số mạng chính qua các nhiệm vụ vẫn giữ nguyên trong khi các giá trị chính xác của chúng có thể khác nhau. Điều này được thực hiện bằng cách chia sẻ các trọng số liên quan đến các trạng thái ẩn trong LSTM qua các nhiệm vụ. Chúng tôi vẫn học các trọng số cụ thể đầu vào cho mỗi nhiệm vụ riêng biệt. Phương pháp này cải thiện hiệu suất học liên tục mà không cần điều chuẩn thêm và tăng tốc đào tạo mô hình. Kết quả thí nghiệm của chúng tôi trên dữ liệu thế giới thực cho thấy rằng các phương pháp đề xuất cùng với mạng siêu dựa trên LSTM có thể giảm thiểu hiệu quả việc quên thảm khốc và cải thiện đáng kể hiệu suất học liên tục.

Những đóng góp chính của chúng tôi có thể được tóm tắt như sau:
• Chúng tôi đề xuất một mạng siêu LSTM bảo tồn phụ thuộc mới để học liên tục.
• Chúng tôi đề xuất một kỹ thuật điều chuẩn mới cho học liên tục dựa trên mạng siêu và một kỹ thuật tăng trưởng mạng dành riêng cho mạng siêu dựa trên LSTM không yêu cầu điều chuẩn.
• Chúng tôi chứng minh sự cải thiện trong hiệu suất học liên tục của các phương pháp đề xuất thông qua thí nghiệm trên một số bộ dữ liệu phân loại hình ảnh và cho các cài đặt CL khác nhau.

2. Công việc liên quan
Một số phương pháp đã được đề xuất gần đây cho học liên tục và để xử lý việc quên thảm khốc. Về mặt khái niệm, các phương pháp này được phân loại dựa trên việc phát lại các ví dụ đã lưu trữ, các phương pháp mở rộng mô hình khi thấy nhiệm vụ mới và các phương pháp điều chuẩn sự thay đổi tham số bằng cách giữ lại mạng [20, 13]. Các phương pháp dựa trên điều chuẩn [1, 11, 16, 30] tránh việc quên bằng cách áp đặt ràng buộc lên việc cập nhật tham số. Với lợi thế không yêu cầu bộ nhớ thêm, các phương pháp điều chuẩn được sử dụng cho nhiều ứng dụng rộng rãi hơn có ràng buộc về bộ nhớ, tài nguyên tính toán và quyền riêng tư dữ liệu. Consolidation trọng số đàn hồi (EWC) [11] và Trí tuệ Synaptic (SI) [30] là các phương pháp nổi tiếng nhất, được đề xuất để giảm thiểu việc quên bằng cách ràng buộc việc cập nhật các tham số quan trọng của nhiệm vụ. Nó áp đặt một hình phạt bậc hai lên sự khác biệt giữa các tham số cũ và mới giúp làm chậm việc học các nhiệm vụ mới bằng cách cập nhật các tham số cũ. Nhưng các thí nghiệm trong [10] cho thấy rằng EWC không hiệu quả trong việc học các lớp mới một cách tăng dần.

Các phương pháp dựa trên phát lại [2, 17, 21] giảm thiểu việc quên thảm khốc bằng cách phát lại các ví dụ cũ trong khi học các nhiệm vụ mới. Các phương pháp này hoặc lưu trữ các ví dụ từ các nhiệm vụ trước đó hoặc tạo ra các ví dụ tổng hợp từ các mô hình sinh được đào tạo từ không gian đặc trưng đã học. Variational autoencoders (VAE) và Generative adversarial networks (GAN) được sử dụng để tạo ra các mẫu từ không gian đặc trưng. iCaRL [21], lưu trữ một tập con mẫu trên mỗi lớp trong bộ nhớ cố định và các ví dụ được chọn nên xấp xỉ tốt nhất các trung bình lớp trong không gian đặc trưng. Nhưng khi số lượng nhiệm vụ tăng lên, số mẫu trên mỗi lớp được lưu trữ sẽ trở nên quá ít để đảm bảo hiệu suất cần thiết. Nhiều phương pháp khác [6, 22, 3] đã được đề xuất để tạo ra các mẫu cho các nhiệm vụ cũ thay vì lưu trữ chúng và chúng được phát lại trong khi học một nhiệm vụ mới.

Các phương pháp dựa trên kiến trúc động cung cấp một giải pháp hướng tới học liên tục bằng cách phát triển hoặc cập nhật cấu trúc mô hình của nó cho mỗi nhiệm vụ [15, 29]. Mạng nơ-ron tiến bộ (PNN) [23] phát triển kiến trúc của chúng bằng cách mở rộng mạng tĩnh với các mô-đun mới. Việc quên có thể được khắc phục bằng cách thêm các kết nối bên từ các mô-đun trước đó. Thay vì phát triển cấu trúc mạng tĩnh, Mạng có thể mở rộng động (DEN) phát triển kiến trúc mạng cho mỗi nhiệm vụ chỉ với số lượng đơn vị hạn chế và xác định các nơ-ron quan trọng cho nhiệm vụ mới và đào tạo chúng một cách có chọn lọc [29].

Gần đây, các phương pháp dựa trên mạng siêu đã được đề xuất [8, 10, 26, 28] có lợi thế là có không gian tìm kiếm bị ràng buộc so với mạng chính. Các kỹ thuật dựa trên mạng siêu sử dụng một mạng nơ-ron thứ cấp để tạo ra các tham số của mạng chính và xử lý việc quên ở mức mạng siêu. Để giữ kích thước của mạng siêu nhỏ so với mạng chính

--- TRANG 3 ---
mạng, chúng tạo ra các trọng số của mạng chính trong các khối có kích thước cố định nhỏ [8]. Tuy nhiên, chúng tôi nhận thấy rằng quá trình tạo ra trọng số khối độc lập bỏ qua sự phụ thuộc giữa các tham số mạng chính và do đó ảnh hưởng đến hiệu suất học liên tục. Để khắc phục điều này, chúng tôi đề xuất một mạng siêu dựa trên LSTM có thể tạo ra trọng số trong các khối nhỏ hơn đồng thời duy trì phụ thuộc qua chúng. Do khả năng nắm bắt phụ thuộc, LSTM được sử dụng để học từ dữ liệu tuần tự. Gần đây, các phương pháp học liên tục cho mạng nơ-ron hồi quy dựa trên kỹ thuật điều chuẩn hiện có và mạng siêu đã được đề xuất trong [4]. Trái ngược với công việc trong [4], nơi mục tiêu là mô hình hóa học liên tục cho các nhiệm vụ liên quan đến dữ liệu tuần tự sử dụng RNN với các kỹ thuật CL hiện có, mục tiêu của bài báo này là phát triển phương pháp học liên tục mới dựa trên RNN (cụ thể là LSTM) bằng cách coi chúng như một mạng siêu. Ngoài ra, chúng tôi cũng giới thiệu các kỹ thuật học liên tục mới cho mạng siêu dựa trên LSTM như vậy như điều chuẩn trọng số quan trọng và tăng trưởng mạng.

3. Mạng siêu LSTM và Kỹ thuật Điều chuẩn cho Học Liên tục
Trong nhiều tình huống học tập thực tế trong thế giới thực, các nhiệm vụ đến theo cách tuần tự. Học liên tục nhằm học từ một chuỗi nhiệm vụ trong đó dữ liệu của tất cả các nhiệm vụ không có sẵn cùng một lúc và chúng ta có kích thước bộ nhớ cố định. Chúng ta giả định rằng chúng ta được đưa ra một chuỗi K nhiệm vụ, trong đó mỗi nhiệm vụ t∈ T={1, . . . , K} chứa đầu vào Xt={xt j}nt j=1 và nhãn mục tiêu Yt={yt j}nt j=1 trong đó nt là số lượng mẫu trong nhiệm vụ t. Mục tiêu của mạng chính m là học một hàm ft m(·,Θt m) :Xt→Yt với các tham số Θt m liên quan đến nhiệm vụ t. Trong khi học một nhiệm vụ t chúng ta chỉ có quyền truy cập vào các quan sát của nhiệm vụ hiện tại t nhưng không có quyền truy cập vào dữ liệu của các nhiệm vụ trước đó.

Chúng ta có thể học Θt m riêng biệt cho mỗi nhiệm vụ, nhưng nó dẫn đến tăng trưởng tuyến tính về số lượng tham số và bộ nhớ cố định sẽ không đủ để lưu trữ chúng. Nếu chúng ta duy trì tham số mạng chính giống nhau qua tất cả các nhiệm vụ, các giá trị tham số sẽ bị ghi đè bởi dữ liệu nhiệm vụ mới dẫn đến quên thảm khốc. Để học liên tục qua các nhiệm vụ mà không yêu cầu tăng trưởng tuyến tính về tham số, mạng siêu được đề xuất để tạo ra các tham số mạng chính cho mỗi nhiệm vụ. Mạng siêu h học một hàm fh(·,Θh) :et→Θt m để tạo ra tham số cụ thể nhiệm vụ Θt m cho một nhúng nhiệm vụ et sử dụng các tham số có thể đào tạo Θh.

Tạo ra các tham số mạng chính có chiều cao cùng một lúc yêu cầu một mạng siêu rất lớn với một số lượng lớn đầu ra và tính toán tốn kém để đào tạo chúng. Với động cơ giảm số lượng tham số có thể đào tạo trong mạng siêu, mạng siêu phân khối [8, 28] được đề xuất để tạo ra trọng số trong các khối nhỏ hơn (tập con của ma trận trọng số của mạng chính) bằng cách tái sử dụng cùng một mạng siêu fh nhiều lần với các nhúng khối khác nhau.

Do đó, mạng siêu fh với tham số Θh lấy nhúng nhiệm vụ et và nhúng khối c={c1, . . . ,cnc} làm đầu vào để tạo ra tập hợp trọng số mạng chính, Θt m =fh(et,c,Θh)= {fh(et,c1,Θh), fh(et,c2,Θh), . . . , fh(et,cnc,Θh)}, trong đó nc là số lượng khối. mạng siêu vẫn có thể bị quên thảm khốc khi các tham số mạng siêu được cập nhật để tạo ra các tham số mạng chính cho nhiệm vụ mới. Để khắc phục việc quên này, một thuật ngữ điều chuẩn bổ sung được sử dụng trong khi học các tham số của mạng siêu cho một nhiệm vụ mới cùng với mất mát cụ thể nhiệm vụ [28].

Mạng siêu phân khối tạo ra trọng số của mạng chính trong các khối nhỏ hơn sử dụng một mạng siêu xem xét nhúng nhiệm vụ và nhúng khối. Chúng tôi quan sát thấy rằng chúng không xem xét tính chất tuần tự và sự phụ thuộc lẫn nhau của trọng số giữa các khối. Chúng tôi lưu ý rằng mạng siêu phân khối đưa ra các giả định độc lập có điều kiện về trọng số của mạng chính. Do đó, nếu chúng ta xem xét một phân phối xác suất trên trọng số, nó được phân tách qua các khối như P(Θt,1 m,Θt,2 m, . . .,Θt,nc m|et,c) =P(Θt,1 m|et,c1)× P(Θt,2 m|et,c2). . . P(Θt,nc m|et,cnc). Giả định độc lập qua các khối thường không đúng và có thể ảnh hưởng đến việc tạo ra tham số mạng chính và hiệu suất của học liên tục.

3.1. Mạng siêu LSTM
Để nắm bắt sự phụ thuộc lẫn nhau trong trọng số khối và đồng thời hiệu quả về tham số, chúng tôi đề xuất một mạng nơ-ron hồi quy (RNN) và cụ thể là bộ nhớ ngắn hạn dài (LSTM) [9] dựa trên mạng siêu được gọi là LSTM NET. LSTM NET có khả năng tạo ra trọng số cho mạng chính trong các khối nhỏ hơn đồng thời duy trì phụ thuộc qua các khối. LSTM là các mô hình tuần tự có khả năng nắm bắt các phụ thuộc tầm xa và sẽ có thể tạo ra trọng số khối tùy thuộc vào trọng số liên quan đến các khối trước đó. Do đó, nó mô hình hóa xác suất chung trên các tham số mạng chính như

P(Θt,1 m,Θt,2 m, . . .,Θt,nc m|et,c) =P(Θt,1 m|et,c1)× P(Θt,2 m|Θt,1 m,et,c2). . . P(Θt,nc m|Θt,1 m. . .Θt,nc−1 m ,et,cnc)(1)

Mạng siêu LSTM đề xuất sử dụng trạng thái ẩn ht j−1 và trạng thái tế bào st j−1 của khối trước đó cùng với nhúng khối hiện tại để tạo ra trọng số khối. Các phép toán LSTM sau được sử dụng để tạo ra

--- TRANG 4 ---
trọng số khối giả định một mạng lớp đơn nơi nó lấy nhúng nhiệm vụ et và nhúng khối cj làm đầu vào.

it j=σ(wi× ⟨et,cj⟩+ui×ht j−1)
ft j=σ(wf× ⟨et,cj⟩+uf×ht j−1)
ot j=σ(wo× ⟨et,cj⟩+uo×ht j−1)
gt j=Tanh (wg× ⟨et,cj⟩+ug×ht j−1)
st j=ft j⊙st j−1+it j⊙gt j
ht j=ot j⊙tanh(st j)
Θ(t,j) m=ht jW

trong đó f,i,o,g lần lượt là cổng quên, cổng đầu vào, cổng đầu ra, và cổng tế bào. σ là hàm sigmoid, và ⊙ là tích Hadamard. w, u là các trọng số liên quan đến trạng thái đầu vào và ẩn tương ứng với chỉ số phụ biểu thị cổng tương ứng. Θ(t,j) m là khối thứ j của trọng số mạng chính được tạo ra bởi mạng siêu LSTM. Ở đây, W∈Rd1×d2 là trọng số của lớp truyền thẳng tạo ra trọng số khối.

[Hình 1: Mạng siêu dựa trên LSTM có thể tạo ra trọng số mạng chính Θt m cho nhiệm vụ t trong các khối nhỏ hơn bằng cách sử dụng cùng một mạng siêu lặp lại nhưng cũng bằng cách duy trì phụ thuộc qua chúng sử dụng LSTM.]

Chúng tôi học các tham số LSTM Θh khi được trình bày dữ liệu từ nhiệm vụ T bằng cách tối thiểu hóa mất mát sau bao gồm mất mát cụ thể nhiệm vụ và mất mát điều chuẩn [28].

arg min Θh Ltotal=Ltask(Θh,eT,c, XT, YT) +β T−1 T−1 X t=1||fh(et,c,Θ∗ h)−fh(et,c,Θh+ ∆Θ h)||2(2)

trong đó fh(et,c,Θh) = Θt m biểu thị tất cả các tham số của mạng chính cho nhiệm vụ t, Θ∗ h là các tham số của mạng siêu trước khi học nhiệm vụ T, β là một hằng số điều chuẩn cân bằng mất mát cụ thể nhiệm vụ và mất mát điều chuẩn, và ∆Θh là thay đổi theo hướng của các trọng số của mạng siêu được đánh giá trên mất mát cụ thể nhiệm vụ. Mất mát cụ thể nhiệm vụ Ltask là mất mát liên quan đến nhiệm vụ (ví dụ, mất mát cross-entropy cho phân loại). Mất mát điều chuẩn ràng buộc mạng siêu học được trên nhiệm vụ mới để tạo ra các tham số mạng chính tương tự như những tham số được tạo ra bởi mạng siêu đã học trước đó. Các tham số mạng siêu Θh và nhúng khối được học bằng cách tối thiểu hóa tổng mất mát Ltotal, và nhúng nhiệm vụ được học chỉ sử dụng Ltask bằng lan truyền ngược.

3.2. Điều chuẩn Trọng số Quan trọng
Chúng tôi đề xuất một kỹ thuật điều chuẩn mới cho học liên tục trong mạng siêu cung cấp sự linh hoạt hơn cho mạng siêu để thích nghi với nhiệm vụ mới so với điều chuẩn trong (2). Điều chuẩn trọng số quan trọng (IWR) đề xuất cập nhật các tham số mạng siêu dựa trên tầm quan trọng của các tham số liên quan đến mạng chính cho mỗi nhiệm vụ. IWR yêu cầu mạng siêu chỉ tạo ra các tham số mạng chính quan trọng liên quan đến các nhiệm vụ cũ chứ không phải tất cả các tham số mạng chính. Chúng tôi đạt được điều này bằng cách xem xét điểm thông tin fisher của các tham số mạng chính trong thuật ngữ điều chuẩn trong (2). Điều này sẽ buộc mạng siêu phải chú ý đến các tham số mạng chính quan trọng trong quá trình tạo ra trọng số mạng chính. Trong khi đó, nó cung cấp sự linh hoạt cho mạng siêu để thích nghi các tham số của nó tự do hơn với nhiệm vụ mới vì nó không bị ràng buộc để tạo ra tất cả các tham số mạng chính với tầm quan trọng như nhau. Hàm mục tiêu xem xét điều chuẩn IWR được định nghĩa như

arg min Θh Ltotal=Ltask(Θh,eT,c, XT, YT) +β T−1 T−1 X t=1 X i FIt i(fhi(et,c,Θ∗ h)−fhi(et,c,Θh+ ∆Θ h))2 (3)

trong đó thuật ngữ đầu tiên Ltask là mất mát cụ thể nhiệm vụ và thuật ngữ thứ hai là thuật ngữ IWR điều chuẩn các tham số mạng siêu để tránh quên. Thuật ngữ IWR sử dụng FIt i là ma trận thông tin fisher (được định nghĩa dưới đây) trên các tham số mạng chính liên quan đến nhiệm vụ t. FIt i cung cấp tầm quan trọng của các tham số mạng chính cho nhiệm vụ t, và chỉ số i lặp qua tất cả các tham số mạng chính. fhi(et,c,Θh) biểu thị tham số mạng chính thứ i được tạo ra bởi mạng siêu. Chúng ta có thể quan sát rằng nếu thông tin Fisher liên quan đến tham số mạng chính thứ i cao (ngụ ý rằng tham số này quan trọng), thì mạng siêu được yêu cầu tạo ra nó chính xác trong khi nó không cần phải làm như vậy cho các tham số không quan trọng. Do đó, IWR cung cấp sự linh hoạt hơn cho mạng siêu để học và thích nghi với các nhiệm vụ mới.

--- TRANG 5 ---
Ma trận thông tin Fisher (FI) cung cấp thông tin về tầm quan trọng của mỗi trọng số trong mạng. Đối với IWR trong (3), ma trận FI được định nghĩa như

FIt=1 Nt Nt X i=1 ∇ΘtmLtask(Θh,et, yi,xi)× ∇ΘtmLtask(Θh,et, yi,xi)T (4)

Chúng tôi lưu ý rằng các đạo hàm được tính toán liên quan đến các tham số mạng chính để đánh giá tầm quan trọng của những tham số đó chứ không phải liên quan đến các tham số mạng siêu mà chúng ta đang học không giống như các kỹ thuật điều chuẩn tiêu chuẩn. Do đó, sử dụng ma trận thông tin Fisher chúng ta có thể tìm ra các tham số mạng chính quan trọng trong việc học nhiệm vụ. Điều chuẩn hiện có cho mạng siêu trong (2) đối xử bình đẳng với tất cả các tham số mạng chính. Trong thực tế, không phải tất cả các tham số mạng chính đều đóng góp bình đẳng cho việc giải quyết một nhiệm vụ cụ thể. Do đó, không cần thiết phải tạo ra chính xác tất cả các tham số mạng chính bởi mạng siêu mà chỉ những tham số quan trọng và có thể đạt được bằng cách sử dụng điều chuẩn IWR. Điều chuẩn IWR là một kỹ thuật chung có thể được sử dụng với bất kỳ mạng siêu nào chứ không chỉ mạng siêu LSTM để cải thiện hiệu suất học liên tục.

3.3. Kỹ thuật Tăng trưởng Mạng
Một vấn đề tiềm ẩn với các phương pháp điều chuẩn là thời gian đào tạo tăng lên với số lượng nhiệm vụ như có thể thấy từ Eq (2) và Eq (3). Hơn nữa, các tham số mạng siêu giống nhau được sử dụng để tạo ra tất cả các tham số chính cụ thể nhiệm vụ. Điều này có thể trở thành một nút thắt cổ chai và ảnh hưởng đến hiệu suất học liên tục trong các tình huống có số lượng lớn nhiệm vụ. Chúng tôi đề xuất mạng siêu LSTM (LSTM NET GROW) dựa trên tăng trưởng mạng cho học liên tục. Nó cung cấp sự linh hoạt hơn trong việc thích nghi với nhiệm vụ mới bằng cách duy trì các tham số cụ thể nhiệm vụ và tăng tốc đào tạo mô hình bằng cách không yêu cầu điều chuẩn. Để chuyển giao kiến thức qua các nhiệm vụ, LSTM NET GROW cũng duy trì một tập hợp các tham số mạng siêu được chia sẻ.

Chúng tôi giả thuyết rằng, mặc dù các tham số mạng chính thực tế khác nhau qua các nhiệm vụ, các phụ thuộc tồn tại giữa các tham số mạng chính vẫn giữ nguyên qua các nhiệm vụ. Dựa trên trực giác này, chúng tôi định nghĩa các tham số được chia sẻ và cụ thể nhiệm vụ trong mạng siêu LSTM. Trong LSTM, các phụ thuộc được nắm bắt bởi các trọng số liên quan đến trạng thái ẩn. Do đó, chúng tôi giả định chúng giống nhau qua các nhiệm vụ trong mô hình LSTM NET GROW đề xuất. Tính biến thiên trong việc tạo ra tham số qua các nhiệm vụ được nắm bắt bằng cách có các trọng số cụ thể nhiệm vụ liên quan đến đầu vào. Cụ thể hơn, các trọng số (uf,ui,uo,ug) của LSTM được chia sẻ qua các nhiệm vụ và chúng tôi duy trì các trọng số đầu vào (wt f,wt i,wt o,wt g) cụ thể nhiệm vụ. LSTM NET GROW sử dụng các phép toán LSTM sau để tạo ra trọng số khối của các tham số mạng chính liên quan đến nhiệm vụ t.

it j=σ(wt i× ⟨et,cj⟩+ui×ht j−1)
ft j=σ(wt f× ⟨et,cj⟩+uf×ht j−1)
ot j=σ(wt o× ⟨et,cj⟩+uo×ht j−1)
gt j=Tanh (wt g× ⟨et,cj⟩+ug×ht j−1)
st j=ft j⊙st j−1+it j⊙gt j
ht j=ot j⊙tanh(st j)
Θ(t,j) m=ht jWt

Mô hình LSTM NET GROW đóng băng các trọng số ẩn (uf,ui,uo,ug) của LSTM sau khi học nhiệm vụ đầu tiên và được chia sẻ qua tất cả các nhiệm vụ. Nó tiếp tục học các trọng số đầu vào cụ thể nhiệm vụ mới (wt f,wt i,wt o,wt g) khi đào tạo trên nhiệm vụ mới và những trọng số đó được lưu trữ để suy luận ở giai đoạn sau. Phương pháp này không yêu cầu thuật ngữ điều chuẩn bổ sung và có thể được học chỉ dựa trên mất mát cụ thể nhiệm vụ (Ltask). Ngoài ra, các trọng số cụ thể nhiệm vụ cung cấp sự linh hoạt thêm cho mạng siêu LSTM trong việc tạo ra trọng số mạng chính cụ thể nhiệm vụ.

4. Thí nghiệm
Chúng tôi thực hiện các thí nghiệm mở rộng trên các thiết lập học liên tục khác nhau và các bộ dữ liệu điểm chuẩn thế giới thực để thể hiện hiệu quả của phương pháp chúng tôi. Chúng tôi trình bày kết quả của chúng tôi trên các bộ dữ liệu Split MNIST, permuted MNIST, CIFAR-10, và CIFAR-100. Thông qua các thí nghiệm, chúng tôi nhằm chứng minh:

• tác động của việc duy trì phụ thuộc qua các khối sử dụng mạng siêu dựa trên LSTM (LSTM NET),
• tác động của điều chuẩn IWR đề xuất trên LSTM NET (LSTM NET IWR) và trên HNET (HNET IWR) trong việc giảm thiểu quên thảm khốc,
• cải thiện hiệu suất sử dụng mạng siêu dựa trên LSTM tăng trưởng động đề xuất LSTM NET GROW,
• chuyển giao kiến thức và giảm thiểu việc quên qua các nhiệm vụ sử dụng các bộ dữ liệu Cifar thách thức.

4.1. Thiết lập Thí nghiệm
Các mô hình học liên tục được kiểm tra trên ba tình huống học liên tục khác nhau [27].

CL1 (Học tăng dần nhiệm vụ) : Nó cung cấp thông tin nhận dạng nhiệm vụ cho mô hình cả trong quá trình đào tạo và kiểm tra

--- TRANG 6 ---
thời gian. Vì nhận dạng nhiệm vụ có sẵn, các thành phần chuyên dụng có thể được gán cho các nhiệm vụ trong chuỗi. Mô hình đa đầu là một loại kiến trúc mô hình như vậy được sử dụng trong học liên tục.

CL2 (Học tăng dần miền) : Nó không cung cấp thông tin nhận dạng nhiệm vụ tại thời điểm kiểm tra, cũng không cần phải suy luận nhận dạng nhiệm vụ. Ở đây, mỗi nhiệm vụ coi dữ liệu là từ các miền khác nhau nhưng với cùng các lớp. Nó xem xét cùng số lượng lớp qua tất cả các nhiệm vụ trong chuỗi và sử dụng cùng các đầu ra cho tất cả các nhiệm vụ.

CL3 (Học tăng dần lớp) : Trong tình huống học liên tục này, mô hình không được cung cấp nhận dạng nhiệm vụ. Nó không chỉ yêu cầu học các nhiệm vụ tăng dần mà còn yêu cầu suy luận nhận dạng nhiệm vụ. Ở đây, nhận dạng nhiệm vụ được suy luận thông qua entropy phân phối dự đoán. Tình huống này giống nhất với thiết lập thời gian thực với các đối tượng lớp mới xuất hiện tăng dần.

Hiệu quả của các kỹ thuật CL dựa trên mạng siêu cho việc tạo ra tham số cũng được kiểm tra trên hai thiết lập học liên tục, thiết lập dựa trên phát lại và không dựa trên phát lại. Trong thiết lập không dựa trên phát lại, mạng siêu được đào tạo để tạo ra các tham số của bộ phân loại được sử dụng để giải quyết các vấn đề phân loại hình ảnh. Trong thiết lập không dựa trên phát lại, chúng tôi so sánh phương pháp đề xuất với các đường cơ sở điều chuẩn Elastic Weight Consolidation (EWC) [11], Synaptic Intelligence (SI) [30] và mạng siêu đường cơ sở HNET [28]. Trong thiết lập dựa trên phát lại, chúng tôi tăng cường hệ thống của mình với một mô hình sinh, ví dụ như variational auto-encoder (VAE) để tạo ra các ví dụ tổng hợp từ các nhiệm vụ trước đó có thể được phát lại để hỗ trợ bộ phân loại nhớ các nhiệm vụ trước đó. Trong trường hợp này, mạng siêu sẽ tạo ra trọng số cho mạng phát lại tức là VAE nhưng không phải bộ phân loại đích. Trong thiết lập dựa trên phát lại, chúng tôi so sánh phương pháp đề xuất với các đường cơ sở phát lại sinh sâu có chưng cất (DGR) [25], học mà không quên (LWF) [14] và mạng siêu đường cơ sở HNET [28].

Chúng tôi tiến hành thí nghiệm trên nhiệm vụ học liên tục tiêu chuẩn của phân loại hình ảnh trên các bộ dữ liệu thế giới thực có sẵn công khai như split MNIST, permuted MNIST, CIFAR-10 và CIFAR-100. Trong các thí nghiệm này, chúng tôi sử dụng LSTM lớp đơn lấy nhúng nhiệm vụ và khối mỗi loại có kích thước 96. Đối với MNIST, chúng tôi xem xét LSTM với kích thước trạng thái ẩn 64 và kích thước lô 128. Đối với CIFAR, kích thước ẩn và kích thước lô lần lượt là 128 và 32. Đối với Split MNIST, bộ phân loại là một mạng kết nối đầy đủ (FCN) với 2 lớp mỗi lớp có kích thước 400 [28]. Đối với Permuted

[Bảng 1: So sánh độ chính xác kiểm tra trung bình (%) của Split MNIST và Permuted MNIST cho tất cả ba tình huống học liên tục mà không có phát lại sinh]

[Bảng 2: So sánh độ chính xác kiểm tra trung bình (%) của Split MNIST và Permuted MNIST cho tất cả ba tình huống học liên tục với phát lại sinh]

--- TRANG 7 ---
MNIST, kích thước lớp được lấy là 1000 như thực hiện trong [28]. Đối với bộ dữ liệu CIFAR, Resnet-32 được sử dụng làm bộ phân loại. Trong thiết lập dựa trên phát lại, chúng tôi sử dụng VAE sử dụng FCN với hai lớp mỗi lớp có kích thước 400 cả làm bộ mã hóa và bộ giải mã và sử dụng không gian tiềm ẩn với chiều 100.

4.2. Kết quả
Chúng tôi chứng minh kết quả của các thí nghiệm trên các bộ dữ liệu phân loại hình ảnh khác nhau được sử dụng cho thiết lập học liên tục và một số đường cơ sở. Để so sánh công bằng, chúng tôi duy trì số lượng tham số có thể đào tạo trong mạng siêu bằng hoặc nhỏ hơn các phương pháp đường cơ sở.

4.2.1 Split MNIST:
Split MNIST là một điểm chuẩn học liên tục phổ biến cho phân loại hình ảnh. Bộ dữ liệu bao gồm hình ảnh của mười chữ số (0-9) và tạo thành năm nhiệm vụ phân loại nhị phân bằng cách ghép đôi chúng tuần tự tức là {(0,1),(2,3),(4,5), (6,7),(8,9)}. Kết quả được trình bày trong Bảng 1 cho thiết lập không dựa trên phát lại, và trong Bảng 2 cho thiết lập dựa trên phát lại. Kết quả cho thấy hiệu quả của phương pháp chúng tôi trong việc đạt được hiệu suất học liên tục tốt hơn trong tất cả ba tình huống CL và cho mỗi thiết lập.

Mạng siêu đề xuất LSTM NET vượt trội hơn các đường cơ sở EWC, SI và HNET trong thiết lập không dựa trên phát lại, và vượt trội hơn các đường cơ sở LWF, DGR và HNET trong thiết lập dựa trên phát lại. Hiệu suất của HNET IWR và LSTM NET IWR chứng minh rằng kỹ thuật điều chuẩn IWR đề xuất cải thiện thêm hiệu suất của HNET và LSTM NET trong tất cả các thiết lập học liên tục. Trong khi các phương pháp cung cấp kết quả tương đương cho thiết lập CL1 dễ hơn, sự cải thiện hiệu suất sử dụng các kỹ thuật đề xuất rõ ràng hơn trong các thiết lập CL2 và CL3 phức tạp và thực tế hơn. Điều này còn rõ ràng hơn trong thiết lập không phát lại nơi các kỹ thuật tiêu chuẩn gặp khó khăn. Chúng ta có thể quan sát rằng phương pháp đề xuất LSTM NET GROW đã cải thiện đáng kể hiệu suất học liên tục so với các mô hình khác cho các tình huống và thiết lập CL này. Một trong những lý do chính cho sự cải thiện lớn về độ chính xác của CL2 và CL3 với LSTM NET GROW là do mạng mở rộng động với các nhiệm vụ mới, điều này giúp mỗi nhiệm vụ có các tham số cụ thể nhiệm vụ sẽ không bị cập nhật trong khi học các nhiệm vụ mới và đóng góp đáng kể cho sự cải thiện hiệu suất.

4.2.2 Permuted MNIST
Điểm chuẩn CL này là một biến thể của MNIST, nó bao gồm các nhiệm vụ được tạo ra bằng cách thực hiện hoán vị ngẫu nhiên trên các hình ảnh MNIST. Chuỗi T= 10 nhiệm vụ được thu được bằng cách lặp lại thủ tục này. Chúng tôi xem xét một bộ dữ liệu với chuỗi nhiệm vụ đủ dài (T= 10) để điều tra khả năng nhớ của mô hình học liên tục của chúng tôi. Kết quả được trình bày trong Bảng 1 và Bảng 2 cho thiết lập không phát lại và dựa trên phát lại tương ứng chứng minh hiệu quả của các phương pháp đề xuất cho học liên tục trên Permuted MNIST. Kết quả theo xu hướng tương tự như trong split MNIST, với LSTM NET GROW cho kết quả tốt nhất, tiếp theo là LSTM NET IWR và LSTM NET, đánh bại các phương pháp đường cơ sở.

4.2.3 Bộ dữ liệu CIFAR-10/100
Chúng tôi tiếp tục đánh giá hiệu quả của các phương pháp đề xuất trên dữ liệu phân loại hình ảnh thách thức hơn CIFAR-10 và CIFAR-100. Mô hình trước tiên được đào tạo trên 10 lớp của CIFAR-10, và sau đó trên năm tập hợp mười lớp từ cifar-100 theo thiết lập thí nghiệm trong [28]. Do đó, mô hình cần học T= 6 nhiệm vụ. Chúng tôi sử dụng ResNet-32 để phân loại bộ dữ liệu CIFAR-10/100 và các mạng siêu được đào tạo để tạo ra các tham số của kiến trúc ResNet-32. Các thí nghiệm được tiến hành trên tình huống CL1 và thiết lập không dựa trên phát lại theo [28]. Ngoài mạng siêu đường cơ sở HNET, chúng tôi

[Bảng 3: So sánh độ chính xác kiểm tra của các phương pháp khác nhau trên CIFAR-10 (C-10) và năm phần tiếp theo (S1...5) mỗi phần với mười lớp của CIFAR-100 (C-100).]

--- TRANG 8 ---
cũng xem xét các đường cơ sở cho phép chúng tôi chứng minh việc chuyển giao kiến thức qua các nhiệm vụ. Đường cơ sở Training-from-scratch học độc lập và riêng biệt các tham số mạng chính cho mỗi nhiệm vụ và kiểm tra hiệu suất trên nhiệm vụ tương ứng. Đường cơ sở Finetuning thích nghi mạng chính với các nhiệm vụ mới mà không tính đến việc quên thảm khốc. Mô hình được thích nghi với nhiệm vụ cuối cùng sau đó được sử dụng để dự đoán hiệu suất trên tất cả các nhiệm vụ. Để chứng minh hiệu quả của LSTM NET trong việc xử lý việc quên thảm khốc, chúng tôi cũng xem xét một đường cơ sở LSTM NET during, nơi chúng tôi kiểm tra LSTM NET trên mỗi nhiệm vụ ngay sau khi đào tạo trên nhiệm vụ đó thay vì kiểm tra sau khi đào tạo trên tất cả các nhiệm vụ như trong LSTM NET.

Chúng tôi cung cấp kết quả so sánh tất cả các phương pháp trong Bảng 3. Chúng ta có thể quan sát rõ ràng từ kết quả rằng phương pháp LSTM NET của chúng tôi vượt trội hơn HNET một cách đáng kể trên bộ dữ liệu thách thức như CIFAR-10/100. Trong Bảng 3, so sánh kết quả của LSTM NET, LSTM NET IWR và LSTM NET GROW với Training-from-scratch, chúng ta có thể thấy rằng việc chuyển giao kiến thức qua các nhiệm vụ giúp các phương pháp đề xuất đạt được hiệu suất tốt hơn. Chúng ta cũng có thể quan sát rằng LSTM NET during khớp với LSTM NET cho thấy rằng mạng siêu dựa trên LSTM rất hiệu quả trong việc xử lý việc quên thảm khốc. Chúng tôi cũng thực hiện thí nghiệm sử dụng các kỹ thuật điều chuẩn khác nhau. Điều chuẩn IWR đề xuất đạt được kết quả tốt hơn so với điều chuẩn đường cơ sở được đề xuất trong [28]. Thực tế, nó cũng cải thiện hiệu suất HNET, một sự cải thiện trong tổng độ chính xác kiểm tra gần 2%. Do đó, IWR là một kỹ thuật điều chuẩn hiệu quả cho bất kỳ phương pháp học liên tục dựa trên mạng siêu nào. Hiệu suất cải thiện thêm bằng cách sử dụng phương pháp LSTM NET GROW cho học liên tục trong dữ liệu này tương tự như MNIST.

4.2.4 Nghiên cứu Loại bỏ
Chúng tôi tiến hành nghiên cứu loại bỏ thêm trên CIFAR-10/CIFAR-100 để hiểu tác động của tỷ lệ nén (Hình 2a) và hằng số điều chuẩn (Hình 2b) trên các mô hình đề xuất. Từ Hình 2a, chúng ta có thể thấy rằng khi số lượng tham số có thể đào tạo tăng lên trong mạng siêu so với mạng chính, hiệu suất LSTM NET cải thiện thêm so với HNET. Trong Hình 2b, chúng tôi nghiên cứu hiệu ứng của việc thay đổi hằng số điều chuẩn (β) trong thuật ngữ điều chuẩn IWR trong LSTM NET IWR trên bộ dữ liệu Cifar. Hiệu suất kém khi thuật ngữ điều chuẩn bị bỏ qua (giá trị β thấp) như mong đợi và cao và ổn định cho các giá trị β cao hơn.

Từ các thí nghiệm trên các nhiệm vụ CIFAR-10/CIFAR-100, chúng tôi quan sát rằng thời gian đào tạo sử dụng LSTM NET với điều chuẩn trong Eq.2 và Eq.3 khoảng 28 giờ nhưng với LSTM NET GROW khoảng 20 giờ. Các

[Hình 2: Trong Hình 2a, vẽ kết quả độ chính xác của LSTM NET so với HNET với sự gia tăng tỷ lệ nén (tỷ lệ tham số có thể đào tạo trong mạng siêu so với mạng chính) trên bộ dữ liệu Cifar. Trong Hình 2b, vẽ đồ thị với các giá trị độ chính xác sử dụng LSTM NET IWR với hằng số điều chuẩn thay đổi (β) trong IWR trên bộ dữ liệu Cifar.]

kết quả trên được tính toán với kích thước lô 32 và 200 epoch cho mỗi lô. Khi số lượng nhiệm vụ tăng lên, thời gian đào tạo của các phương pháp điều chuẩn tăng tuyến tính nhưng của LSTM NET GROW vẫn không đổi. Mặt khác, yêu cầu bộ nhớ của các phương pháp điều chuẩn vẫn không đổi nhưng LSTM NET GROW tăng tuyến tính với các nhiệm vụ do một số tham số cụ thể nhiệm vụ nhưng thấp hơn nhiều so với việc duy trì các tham số riêng biệt cho mỗi nhiệm vụ.

5. Kết luận
Chúng tôi đề xuất một mạng siêu dựa trên LSTM mới cho học liên tục có thể nắm bắt phụ thuộc qua các tham số mạng chính đồng thời duy trì hiệu quả tham số. Để cải thiện hiệu suất học liên tục sử dụng mạng siêu, chúng tôi đề xuất một điều chuẩn mới Điều chuẩn Trọng số Quan trọng (IWR) rất phù hợp cho các phương pháp CL dựa trên mạng siêu. Để cải thiện thêm hiệu suất học liên tục của mạng siêu LSTM đề xuất, chúng tôi đề xuất một kỹ thuật tăng trưởng mạng cho LSTM. Thông qua các thí nghiệm trên một số nhiệm vụ và bộ dữ liệu phân loại hình ảnh, chúng tôi chứng minh hiệu quả của các phương pháp đề xuất, mạng siêu dựa trên LSTM, điều chuẩn IWR cho mạng siêu, và tăng trưởng mạng trên LSTM. Các phương pháp đề xuất đã cải thiện hiệu suất học liên tục trên tất cả các nhiệm vụ, thiết lập và bộ dữ liệu CL. Là công việc tương lai, chúng tôi muốn cải thiện sự tăng trưởng tham số trong LSTM NET GROW, và phát triển các mô hình lai kết hợp tăng trưởng mạng và điều chuẩn để cải thiện thêm hiệu suất CL.

--- TRANG 9 ---
Tài liệu tham khảo
[1] Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, và Tinne Tuytelaars. Memory aware synapses: Learning what (not) to forget. Trong Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, và Yair Weiss, biên tập, Computer Vision - ECCV 2018 - 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part III, tập 11207 của Lecture Notes in Computer Science, trang 144–161. Springer, 2018.

[2] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. Efficient lifelong learning with A-GEM. Trong 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019.

[3] Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K Dokania, Philip HS Torr, và Marc'Aurelio Ranzato. On tiny episodic memories in continual learning. arXiv preprint arXiv:1902.10486, 2019.

[4] Benjamin Ehret, Christian Henning, Maria R. Cervera, Alexander Meulemans, Johannes von Oswald, và Benjamin F. Grewe. Continual learning in recurrent neural networks with hypernetworks. CoRR, abs/2006.12109, 2020.

[5] Sibo Gai, Zhengyu Chen, và Donglin Wang. Multi-modal meta continual learning. Trong International Joint Conference on Neural Networks, IJCNN 2021, Shenzhen, China, July 18-22, 2021, trang 1–8. IEEE, 2021.

[6] Chandan Gautam, Sethupathy Parameswaran, Ashish Mishra, và Suresh Sundaram. Generalized continual zero-shot learning. CoRR, abs/2011.08508, 2020.

[7] Stephen Grossberg. Consciousness CLEARS the mind. Neural Networks, 20(9):1040–1053, 2007.

[8] David Ha, Andrew M. Dai, và Quoc V. Le. Hypernetworks. Trong 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017.

[9] Sepp Hochreiter và Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.

[10] Ronald Kemker, Marc McClure, Angelina Abitino, Tyler L. Hayes, và Christopher Kanan. Measuring catastrophic forgetting in neural networks. Trong Sheila A. McIlraith và Kilian Q. Weinberger, biên tập, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, trang 3390–3398. AAAI Press, 2018.

[11] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521–3526, 2017.

[12] Jan Koutník, Faustino J. Gomez, và Jürgen Schmidhuber. Evolving neural networks in compressed weight space. Trong Martin Pelikan và Jürgen Branke, biên tập, Genetic and Evolutionary Computation Conference, GECCO 2010, Proceedings, Portland, Oregon, USA, July 7-11, 2010, trang 619–626. ACM, 2010.

[13] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory G. Slabaugh, và Tinne Tuytelaars. Continual learning: A comparative study on how to defy forgetting in classification tasks. CoRR, abs/1909.08383, 2019.

[14] Zhizhong Li và Derek Hoiem. Learning without forgetting. Trong Bastian Leibe, Jiri Matas, Nicu Sebe, và Max Welling, biên tập, Computer Vision - ECCV 2016 - 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part IV, tập 9908 của Lecture Notes in Computer Science, trang 614–629. Springer, 2016.

[15] Xialei Liu, Marc Masana, Luis Herranz, Joost van de Weijer, Antonio M. López, và Andrew D. Bagdanov. Rotate your networks: Better weight consolidation and less catastrophic forgetting. Trong 24th International Conference on Pattern Recognition, ICPR 2018, Beijing, China, August 20-24, 2018, trang 2262–2268. IEEE Computer Society, 2018.

[16] Noel Loo, Siddharth Swaroop, và Richard E. Turner. Generalized variational continual learning. Trong 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021.

[17] David Lopez-Paz và Marc'Aurelio Ranzato. Gradient episodic memory for continual learning. Trong Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, và Roman Garnett, biên tập, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, trang 6467–6476, 2017.

[18] Michael McCloskey và Neal J Cohen. Catastrophic interference in connectionist networks: The sequential learning problem. Trong Psychology of learning and motivation, tập 24, trang 109–165. Elsevier, 1989.

[19] Martial Mermillod, Aurélia Bugaiska, và Patrick Bonin. The stability-plasticity dilemma: Investigating the continuum from catastrophic forgetting to age-limited learning effects, 2013.

[20] German Ignacio Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, và Stefan Wermter. Continual lifelong learning with neural networks: A review. Neural Networks, 113:54–71, 2019.

[21] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H. Lampert. icarl: Incremental classifier and representation learning. Trong 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017, trang 5533–5542. IEEE Computer Society, 2017.

[22] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, và Gerald Tesauro. Learning to learn without forgetting by maximizing transfer and minimizing interference. Trong 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019.

--- TRANG 10 ---
[23] Andrei A. Rusu, Neil C. Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, và Raia Hadsell. Progressive neural networks. CoRR, abs/1606.04671, 2016.

[24] Jürgen Schmidhuber. Learning to control fast-weight memories: An alternative to dynamic recurrent networks. Neural Comput., 4(1):131–139, 1992.

[25] Hanul Shin, Jung Kwon Lee, Jaehong Kim, và Jiwon Kim. Continual learning with deep generative replay. Trong Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, và Roman Garnett, biên tập, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, trang 2990–2999, 2017.

[26] Kenneth O. Stanley, David B. D'Ambrosio, và Jason Gauci. A hypercube-based encoding for evolving large-scale neural networks. Artif. Life, 15(2):185–212, 2009.

[27] Gido M. van de Ven và Andreas S. Tolias. Three scenarios for continual learning. CoRR, abs/1904.07734, 2019.

[28] Johannes von Oswald, Christian Henning, João Sacramento, và Benjamin F. Grewe. Continual learning with hypernetworks. Trong 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020.

[29] Jaehong Yoon, Eunho Yang, Jeongtae Lee, và Sung Ju Hwang. Lifelong learning with dynamically expandable networks. Trong 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018.

[30] Friedemann Zenke, Ben Poole, và Surya Ganguli. Continual learning through synaptic intelligence. Trong Doina Precup và Yee Whye Teh, biên tập, Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, tập 70 của Proceedings of Machine Learning Research, trang 3987–3995. PMLR, 2017.

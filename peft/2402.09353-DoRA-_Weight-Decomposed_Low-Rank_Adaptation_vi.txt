# DoRA: Thích Ứng Thứ Hạng Thấp Phân Tách Trọng Số
Shih-Yang Liu1 2Chien-Yi Wang1Hongxu Yin1Pavlo Molchanov1Yu-Chiang Frank Wang1
Kwang-Ting Cheng2Min-Hung Chen1
Tóm tắt
Trong số các phương pháp tinh chỉnh hiệu quả tham số (PEFT) được sử dụng rộng rãi, LoRA và các biến thể của nó đã trở nên rất phổ biến vì tránh được chi phí suy luận bổ sung. Tuy nhiên, vẫn thường tồn tại khoảng cách độ chính xác giữa các phương pháp này và tinh chỉnh đầy đủ (FT). Trong công trình này, chúng tôi đầu tiên giới thiệu một phân tích phân tách trọng số mới để khảo sát các khác biệt bản chất giữa FT và LoRA. Nhằm mục đích mô phỏng khả năng học tập của FT từ các phát hiện, chúng tôi đề xuất Thích Ứng Thứ Hạng Thấp Phân Tách Trọng Số (DoRA). DoRA phân tách trọng số tiền huấn luyện thành hai thành phần, độ lớn và hướng, để tinh chỉnh, cụ thể là sử dụng LoRA cho các cập nhật hướng để giảm hiệu quả số lượng tham số có thể huấn luyện. Bằng cách sử dụng DoRA, chúng tôi tăng cường cả khả năng học tập và tính ổn định huấn luyện của LoRA trong khi tránh bất kỳ chi phí suy luận bổ sung nào. DoRA luôn vượt trội so với LoRA trong việc tinh chỉnh LLaMA, LLaVA, và VL-BART trên các tác vụ downstream khác nhau, như lý luận thông thường, điều chỉnh hướng dẫn hình ảnh, và hiểu biết văn bản hình ảnh/video. Mã nguồn có sẵn tại https://github.com/NVlabs/DoRA.

1. Giới thiệu
Các mô hình được tiền huấn luyện với các tập dữ liệu miền tổng quát rộng lớn đã chứng minh khả năng tổng quát hóa đáng kể, mang lại lợi ích to lớn cho một loạt các ứng dụng, từ các tác vụ xử lý ngôn ngữ tự nhiên (NLP) (Qin et al., 2023; Taori et al., 2023) đến các tác vụ đa phương thức (Li et al., 2022; Liu et al., 2023a). Để điều chỉnh các mô hình tổng quát này cho các tác vụ downstream cụ thể, tinh chỉnh đầy đủ (FT) thường được sử dụng, bao gồm việc huấn luyện lại tất cả các tham số mô hình.

Tuy nhiên, khi kích thước của các mô hình và tập dữ liệu mở rộng về quy mô, chi phí liên quan đến việc tinh chỉnh toàn bộ mô hình trở nên cực kỳ lớn.

Để giải quyết vấn đề này, các phương pháp tinh chỉnh hiệu quả tham số (PEFT) (Houlsby et al., 2019) đã được giới thiệu để tinh chỉnh các mô hình tiền huấn luyện chỉ với số lượng tham số tối thiểu. Trong số này, LoRA (Hu et al., 2022), không thay đổi kiến trúc mô hình, đã trở nên đặc biệt phổ biến vì tính đơn giản và hiệu quả. Tuy nhiên, vẫn còn khoảng cách khả năng giữa LoRA và FT, thường được quy cho số lượng tham số có thể huấn luyện hạn chế mà không có khám phá thêm về các nguyên nhân cơ bản khác (Hu et al., 2022; Kopiczko et al., 2024).

Dựa trên Chuẩn hóa Trọng số (Salimans & Kingma, 2016), đạt được sự hội tụ nhanh hơn thông qua cải thiện điều kiện của gradient bằng tái tham số hóa trọng số, chúng tôi giới thiệu một phân tích phân tách trọng số mới mà ban đầu tái tham số hóa trọng số mô hình thành các thành phần độ lớn và hướng, sau đó khảo sát các thay đổi

1NVIDIA2HKUST. Liên hệ: Shih-Yang Liu <shihyangl@nvidia.com, sliuau@connect.ust.hk>, Min-Hung Chen <minhungc@nvidia.com>.

Kỷ yếu Hội nghị Quốc tế lần thứ 41 về Học Máy, Vienna, Austria. PMLR 235, 2024. Bản quyền 2024 thuộc về (các) tác giả.

trong độ lớn và hướng được giới thiệu bởi LoRA và FT. Phân tích của chúng tôi tiết lộ rằng LoRA và FT thể hiện các mẫu cập nhật khác biệt rõ rệt, dẫn chúng tôi đến giả định rằng những biến thể này phản ánh khả năng học tập của mỗi phương pháp.

Lấy cảm hứng từ các phát hiện của chúng tôi, chúng tôi đề xuất Thích Ứng Thứ Hạng Thấp Phân Tách Trọng Số (DoRA), bắt đầu bằng cách phân tách trọng số tiền huấn luyện thành các thành phần độ lớn và hướng của nó, sau đó tinh chỉnh cả hai. Do kích thước đáng kể của thành phần hướng về mặt tham số, chúng tôi khai thác LoRA cho việc thích ứng hướng để cho phép tinh chỉnh hiệu quả, như được minh họa trong Hình 1. Hơn nữa, bằng cách cho thấy hành vi học tập tương tự FT cả về mặt thực nghiệm và toán học, gợi ý khả năng học tập gần giống với FT, chúng tôi đã xác thực DoRA trên nhiều tác vụ đa dạng, từ NLP đến Vision-Language, và trên các backbone khác nhau, bao gồm LLM và LVLM. Kết quả thực nghiệm cho thấy DoRA luôn vượt trội so với LoRA mà không hy sinh hiệu quả suy luận, như lý luận thông thường (+3.7/+1.0 trên LLaMA-7B/13B, +2.9 trên LLaMA2-7B, và +4.4 trên LLaMA3-8B), điều chỉnh hướng dẫn hình ảnh (+0.6 trên LLaVA-7B), và hiểu biết văn bản hình ảnh/video (+0.9/+1.9 trên VL-BART).

Tóm tắt các đóng góp của chúng tôi như sau:
• Chúng tôi giới thiệu DoRA, một phương pháp PEFT mới kết hợp phân tách trọng số, đạt được khả năng học tập gần giống FT mà không có bất kỳ độ trễ suy luận bổ sung nào so với LoRA.
• Chúng tôi giới thiệu một phân tích phân tách trọng số mới để khám phá các khác biệt cơ bản trong các mẫu học tập của FT và các phương pháp PEFT khác nhau.
• DoRA luôn vượt trội so với LoRA trên các tác vụ khác nhau, từ NLP đến các benchmark Vision-Language và trên các backbone khác nhau, bao gồm LLM và LVLM.

2. Các Công Trình Liên Quan
Các phương pháp Tinh chỉnh Hiệu quả Tham số (PEFT) được thiết kế để giảm chi phí cao của việc tinh chỉnh các mô hình quy mô lớn. Chúng đạt được điều này bằng cách huấn luyện một tập con tương đối nhỏ các tham số, so với tổng số tham số, để thích ứng với các tác vụ downstream. Các phương pháp PEFT hiện có có thể được chia thành ba loại. Loại thứ nhất được gọi là các phương pháp dựa trên Adapter, bao gồm việc đưa các mô-đun có thể huấn luyện bổ sung vào backbone gốc bị đóng băng, như (Houlsby et al., 2019; He et al., 2021; Karimi Mahabadi et al., 2021; mahabadi et al., 2021). Ví dụ, (Houlsby et al., 2019) đề xuất thêm các mô-đun tuyến tính theo chuỗi vào lớp hiện có, trong khi (He et al., 2021) ủng hộ việc tích hợp các mô-đun này song song với lớp gốc để tăng cường hiệu suất. Loại thứ hai là các phương pháp dựa trên Prompt. Các phương pháp này thêm các token mềm bổ sung (prompts) vào đầu vào ban đầu và chỉ tập trung vào việc tinh chỉnh các vector có thể huấn luyện này, như được thấy trong các công trình như (Lester et al., 2021; Razdaibiedina et al., 2023; Wang et al., 2023). Tuy nhiên, các phương pháp này thường gặp khó khăn do độ nhạy cảm với khởi tạo, ảnh hưởng đến hiệu quả tổng thể của chúng. Hai loại đầu tiên này, dù thay đổi đầu vào hay kiến trúc của mô hình, đều dẫn đến độ trễ suy luận tăng so với mô hình cơ sở.

LoRA (Hu et al., 2022) và các biến thể của nó thuộc loại thứ ba của PEFT, đáng chú ý vì không thêm bất kỳ gánh nặng suy luận bổ sung nào. Các phương pháp này áp dụng ma trận thứ hạng thấp để xấp xỉ các thay đổi trọng số trong quá trình tinh chỉnh và có thể kết hợp với trọng số tiền huấn luyện trước khi suy luận. Ví dụ, (Zhang et al., 2023) sử dụng phân tách SVD và cắt bỏ các giá trị đơn ít quan trọng hơn để cập nhật hiệu quả hơn. (Hyeon-Woo et al., 2022) tập trung vào tích Hadamard thứ hạng thấp cho học liên kết. (Qiu et al., 2023; Liu et al., 2023b) khai thác phân tách trực giao trong tinh chỉnh các mô hình khuếch tán. (Renduchintala et al., 2023) sử dụng ràng buộc trọng số để giảm thêm các tham số có thể huấn luyện. (Yeh et al., 2023) giới thiệu một khung họ LoRA thống nhất cho Stable diffusion. (Ponti et al., 2022) chọn các kết hợp khác nhau của LoRA từ kho với một hàm định tuyến cho các tác vụ khác nhau. (Kopiczko et al., 2024) thực hiện các vector tỷ lệ có thể học để điều chỉnh một cặp ma trận ngẫu nhiên đóng băng được chia sẻ giữa các lớp. Nghiên cứu của chúng tôi cũng thuộc loại thứ ba này, và chúng tôi xác thực hiệu quả của phương pháp đề xuất cùng với LoRA và các biến thể của nó thông qua thí nghiệm toàn diện.

3. Phân Tích Mẫu của LoRA và FT
3.1. Thích Ứng Thứ Hạng Thấp (LoRA)
Dựa trên giả thuyết rằng các cập nhật được thực hiện trong quá trình tinh chỉnh thể hiện "thứ hạng nội tại" thấp, LoRA (Hu et al., 2022) đề xuất sử dụng tích của hai ma trận thứ hạng thấp để cập nhật trọng số tiền huấn luyện một cách tăng dần. Đối với ma trận trọng số tiền huấn luyện W0∈Rd×k, LoRA mô hình hóa cập nhật trọng số ∆W∈Rd×k bằng cách sử dụng phân tách thứ hạng thấp, được biểu diễn là BA, trong đó B∈Rd×r và A∈Rr×k đại diện cho hai ma trận thứ hạng thấp, với r≪min(d, k). Do đó, trọng số tinh chỉnh W′ có thể được biểu diễn là:
W′=W0+ ∆W=W0+BA (1)
trong đó W0 giữ nguyên trong quá trình tinh chỉnh, và các tham số được gạch chân đang được huấn luyện. Ma trận A được khởi tạo với phân phối Kaiming đồng nhất (He et al., 2015), trong khi B ban đầu được đặt bằng không, dẫn đến ∆W=BA bằng không khi bắt đầu huấn luyện. Đáng chú ý, phân tách ∆W này có thể được thay thế bằng các biến thể LoRA khác, như VeRA (Kopiczko et al., 2024). Ngoài ra, dựa trên Eq. (1), chúng ta có thể kết hợp ∆W đã học với trọng số tiền huấn luyện W0 và có được W′ trước khi triển khai, và cho rằng cả W′ và W0 đều thuộc về chiều Rd×k, LoRA và các biến thể liên quan không đưa ra bất kỳ độ trễ bổ sung nào trong quá trình suy luận so với mô hình gốc.

3.2. Phân Tích Phân Tách Trọng Số
Nghiên cứu được trình bày trong LoRA (Hu et al., 2022) gợi ý rằng LoRA có thể được coi là một xấp xỉ tổng quát của tinh chỉnh đầy đủ. Bằng cách tăng dần thứ hạng r của LoRA để phù hợp với thứ hạng của trọng số tiền huấn luyện, LoRA có thể đạt được mức độ biểu đạt tương tự như FT. Do đó, nhiều nghiên cứu trước đây đã quy sự khác biệt về độ chính xác giữa LoRA và FT chủ yếu cho số lượng tham số có thể huấn luyện hạn chế, thường không có phân tích thêm (Hu et al., 2022; Kopiczko et al., 2024).

Lấy cảm hứng từ Chuẩn hóa Trọng số (Salimans & Kingma, 2016), tái tham số hóa ma trận trọng số thành độ lớn và hướng để tăng tốc tối ưu hóa, chúng tôi giới thiệu một phân tích phân tách trọng số sáng tạo. Phân tích của chúng tôi tái cấu trúc ma trận trọng số thành hai thành phần riêng biệt, độ lớn và hướng, để tiết lộ các khác biệt bản chất trong các mẫu học tập LoRA và FT.

Phương pháp Phân tích: Phân tích này khảo sát các cập nhật trong cả độ lớn và hướng của trọng số LoRA và FT so với trọng số tiền huấn luyện để tiết lộ các khác biệt cơ bản trong hành vi học tập của cả hai. Phân tách trọng số của W∈Rd×k có thể được công thức hóa là:
W=mV/||V||c=||W||cW/||W||c (2)
trong đó m∈R1×k là vector độ lớn, V∈Rd×k là ma trận hướng, với ||·||c là chuẩn vector-wise của ma trận qua mỗi cột. Phân tách này đảm bảo rằng mỗi cột của V/||V||c vẫn là một vector đơn vị, và scalar tương ứng trong m xác định độ lớn của mỗi vector.

Đối với phân tích phân tách trọng số của chúng tôi, chúng tôi chọn mô hình VL-BART được tinh chỉnh trên bốn tác vụ văn bản hình ảnh như được nêu trong (Sung et al., 2022) để nghiên cứu trường hợp. Theo (Sung et al., 2022), áp dụng LoRA chỉ cho ma trận trọng số query/value trong mô-đun self-attention. Chúng tôi phân tách trọng số tiền huấn luyện W0, trọng số tinh chỉnh đầy đủ WFT, và trọng số LoRA đã kết hợp WLoRA của ma trận trọng số query/value bằng Eq. (2). Các biến thể độ lớn và hướng giữa W0 và WFT có thể được định nghĩa như sau:
∆MtFT=∑k n=1|mn,tFT−mn0|/k (3)
∆DtFT=∑k n=1(1−cos(Vn,tFT, Wn0))/k (4)

Ở đây, ∆MtFT và ∆DtFT đại diện cho sự khác biệt độ lớn và sự khác biệt hướng giữa W0 và WFT tại bước huấn luyện t tương ứng, với cos(·,·) là hàm độ tương tự cosine. Mn,tFT và Mn0 là scalar thứ n trong các vector độ lớn tương ứng, trong khi Vn,tFT và Wn0 là cột thứ n trong VtFT và W0. Sự khác biệt độ lớn và hướng giữa WLoRA và W0 được tính tương tự, theo Eq. (3) và Eq. (4). Chúng tôi chọn các checkpoint từ bốn bước huấn luyện khác nhau để phân tích, bao gồm ba bước trung gian và checkpoint cuối cùng từ cả FT và LoRA, và chúng tôi thực hiện phân tích phân tách trọng số trên mỗi checkpoint này để xác định ∆M và ∆D qua các lớp khác nhau.

Kết quả Phân tích: Hình 2 (a) và (b) minh họa các thay đổi trong ma trận trọng số query của FT và LoRA, với mỗi điểm đại diện cho một cặp (∆Dt,∆Mt) từ ma trận trọng số query qua các lớp và bước huấn luyện khác nhau. Tương tự, Hình 7 trong phụ lục hiển thị các sửa đổi ma trận trọng số value. Có thể nhận thấy rằng LoRA thể hiện xu hướng độ dốc dương nhất quán qua tất cả các bước trung gian, biểu thị mối quan hệ tỷ lệ giữa các thay đổi trong hướng và độ lớn. Ngược lại, FT hiển thị mẫu học tập đa dạng hơn với độ dốc tương đối âm. Sự khác biệt này giữa FT và LoRA có thể phản ánh khả năng học tập tương ứng của chúng. Trong khi LoRA có xu hướng tăng hoặc giảm độ lớn và cập nhật hướng một cách tỷ lệ, nó thiếu khả năng tinh tế cho các điều chỉnh tinh vi hơn. Cụ thể, LoRA không cho thấy thành thạo trong việc thực hiện các thay đổi hướng nhẹ cùng với các thay đổi độ lớn đáng kể hơn, hoặc ngược lại, một đặc điểm đặc trưng hơn của phương pháp FT. Chúng tôi nghi ngờ rằng giới hạn như vậy của LoRA có thể xuất phát từ thách thức học tập đồng thời cả thích ứng độ lớn và hướng, điều này có thể quá phức tạp đối với LoRA. Do đó, trong công trình này, chúng tôi nhằm mục đích đề xuất một biến thể của LoRA thể hiện mẫu học tập gần giống với FT hơn, và có thể cải thiện khả năng học tập so với LoRA.

4. Phương pháp
4.1. Thích Ứng Thứ Hạng Thấp Phân Tách Trọng Số
Dựa trên những hiểu biết từ phân tích phân tách trọng số của chúng tôi, chúng tôi giới thiệu Thích Ứng Thứ Hạng Thấp Phân Tách Trọng Số (DoRA). DoRA ban đầu phân tách trọng số tiền huấn luyện thành các thành phần độ lớn và hướng của nó và tinh chỉnh cả hai. Bởi vì thành phần hướng lớn về mặt số lượng tham số, chúng tôi tiếp tục phân tách nó bằng LoRA để tinh chỉnh hiệu quả.

Trực giác của chúng tôi là hai mặt. Thứ nhất, chúng tôi tin rằng việc giới hạn LoRA tập trung độc quyền vào thích ứng hướng trong khi cũng cho phép thành phần độ lớn có thể điều chỉnh đơn giản hóa tác vụ so với phương pháp gốc, nơi LoRA được yêu cầu học các điều chỉnh trong cả độ lớn và hướng. Thứ hai, quá trình tối ưu hóa cập nhật hướng được thực hiện ổn định hơn thông qua phân tách trọng số, mà chúng tôi đi sâu hơn trong Phần 4.2. Điều quan trọng cần nhấn mạnh là sự khác biệt chính giữa DoRA và chuẩn hóa trọng số (Salimans & Kingma, 2016) nằm ở phương pháp huấn luyện của chúng. Chuẩn hóa trọng số huấn luyện cả hai thành phần từ đầu, làm cho phương pháp nhạy cảm với các khởi tạo khác nhau. Ngược lại, DoRA tránh các mối quan tâm khởi tạo như vậy vì cả hai thành phần đều bắt đầu với trọng số tiền huấn luyện. Chúng tôi khởi tạo DoRA với trọng số tiền huấn luyện W0 như được nêu trong Eq. (2), trong đó m=||W0||c và V=W0 sau khởi tạo. Sau đó chúng tôi giữ V đóng băng và m là một vector có thể huấn luyện. Thành phần hướng sau đó được cập nhật thông qua LoRA. DoRA có thể được công thức hóa tương tự Eq. (1) là:
W′=mV+ ∆V/||V+ ∆V||c=mW0+BA/||W0+BA||c (5)
trong đó ∆V là cập nhật hướng tăng dần được học bằng cách nhân hai ma trận thứ hạng thấp B và A, và các tham số được gạch chân biểu thị các tham số có thể huấn luyện. Các ma trận B∈Rd×r và A∈Rr×k được khởi tạo theo chiến lược của LoRA để đảm bảo rằng W′ bằng W0 trước khi tinh chỉnh. Hơn nữa, DoRA có thể được kết hợp với trọng số tiền huấn luyện trước khi suy luận, do đó không đưa ra bất kỳ độ trễ bổ sung nào.

Chúng tôi hình dung các khác biệt độ lớn và hướng của ma trận trọng số query giữa trọng số DoRA đã kết hợp và W0 trong cùng cài đặt như cho FT và LoRA trong Hình 2 (c) và để lại việc hình dung ma trận trọng số value trong phụ lục. Từ đường hồi quy cho (∆D,∆M) của cả DoRA và FT, chúng tôi tiết lộ rằng trái ngược với mẫu của LoRA, DoRA và FT được đặc trưng bởi một độ dốc âm riêng biệt. Chúng tôi lý luận rằng FT có xu hướng về độ dốc âm vì trọng số tiền huấn luyện đã sở hữu kiến thức đáng kể phù hợp cho các tác vụ downstream khác nhau. Do đó, khi được cung cấp khả năng học tập đầy đủ, việc có thay đổi độ lớn hoặc hướng lớn hơn một mình là đủ cho thích ứng downstream. Chúng tôi cũng tính toán tương quan giữa ∆D và ∆M cho FT, LoRA, và DoRA, và chúng tôi thấy rằng cả FT và DoRA đều thể hiện các giá trị tương quan âm là -0.62 và -0.31, tương ứng. Ngược lại, LoRA cho thấy tương quan dương với giá trị 0.83. Kết luận, việc DoRA chứng minh khả năng chỉ thực hiện các điều chỉnh hướng đáng kể với các thay đổi tương đối tối thiểu về độ lớn hoặc ngược lại trong khi cho thấy các mẫu học tập gần với FT hơn biểu thị khả năng học tập vượt trội so với LoRA.

4.2. Phân Tích Gradient của DoRA
Trong phần này, chúng tôi đầu tiên tính toán gradient của DoRA và minh họa cách phân tách đề xuất của chúng tôi có lợi cho việc tối ưu hóa ∆V. Sau đó, chúng tôi phân tích từ góc độ gradient để giải thích mẫu học tập của DoRA, có xu hướng có độ dốc âm.

Từ Eq. (5), chúng ta có thể có được gradient của Loss L đối với m và V′=V+ ∆V là:
∇V′L=m/||V′||c[I−V′V′T/||V′||2c]∇W′L (6)
∇mL=∇W′L · V′/||V′||c (7)

Eq. (6) tiết lộ rằng gradient trọng số ∇W′L được tỷ lệ bởi m/||V′||c và được chiếu ra khỏi ma trận trọng số hiện tại. Hai hiệu ứng này góp phần làm cho ma trận hiệp phương sai của gradient phù hợp gần hơn với ma trận đơn vị, điều này có lợi cho việc tối ưu hóa (Salimans & Kingma, 2016). Ngoài ra, cho rằng V′=V+ ∆V, gradient ∇V′L tương đương với ∇∆VL. Do đó, các lợi ích tối ưu hóa thu được từ phân tách này được chuyển đầy đủ sang ∆V, tăng cường tính ổn định học tập của LoRA.

Chúng ta có thể có thêm hiểu biết về mẫu học tập của DoRA bằng cách tham khảo Eq. (7). Trong cuộc thảo luận tiếp theo, chúng tôi biểu diễn các vector bằng các chữ cái thường thay vì ký hiệu dạng ma trận trước đây. Xem xét w′′=w′+ ∆w là cập nhật tham số cho một vector trọng số, trong đó ∆w∝ ∇w′L. Trong hai kịch bản cập nhật giả định, S1 và S2, S1 bao gồm cập nhật hướng nhỏ hơn (∆DS1), trong khi S2 bao gồm cập nhật lớn hơn (∆DS2). Giả sử ||∆wS1||=||∆wS2||, và tại thời điểm 0, chúng ta có ∆v= 0 và v′=v. Từ ∆DS1<∆DS2, suy ra |cos(∆wS1, w′)|>|cos(∆wS2, w′)|. Vì ∆w∝∇w′L, nó ngụ ý |cos(∇S1w′L, w′)|>|cos(∇S2w′L, w′)|. Từ Phần 4.1, với v được khởi tạo là v0 và w′=w0 tại thời điểm 0, chúng ta có |cos(∇w′L, w′)|=|cos(∇w′L, v′)|=|cos(∇w′L, v)|. Sử dụng phương trình độ tương tự cosine với ∆v= 0:
cos(∇w′L, v′) =cos(∇w′L, v) =∇w′L · v/(||∇w′L||||v||) (8)

ký hiệu m∗ là scalar độ lớn của vector w′ thì Eq. (7) đối với m∗ có thể được viết lại thành:
∇m∗L=∇w′L · v′/||v′||=||∇w′L|| · cos(∇w′L, v) (9)

Cho rằng ||∆wS1||=||∆wS2|| cho S1 và S2, và ||∇S1w′L||=||∇S2w′L||. Do đó, với:
||∇S1w′L|| · |cos(∇S1w′L, v)|>||∇S2w′L|| · |cos(∇S2w′L, v)| (10)

có thể suy ra rằng |∇S1m∗L|>|∇S2m∗L| điều này chỉ ra rằng S1 có cập nhật độ lớn lớn hơn S2 trong khi có thay đổi hướng nhỏ hơn so với S2. Kết luận của chúng tôi thường đúng trong thực tế, như được chứng minh bởi Hình 2 (c). Do đó, chúng tôi đã hiệu quả chỉ ra cách DoRA có thể được sử dụng để điều chỉnh mẫu học tập, khác biệt với LoRA và phù hợp gần hơn với mẫu của FT.

4.3. Giảm Chi Phí Huấn Luyện
Trong Eq. (1), gradient của W′ và ∆W giống nhau. Tuy nhiên, với DoRA, chuyển hướng thích ứng thứ hạng thấp về phía thành phần hướng, gradient của các cập nhật thứ hạng thấp khác với gradient của W′, như được minh họa trong Eq. (6). Sự khác biệt này đòi hỏi bộ nhớ bổ sung trong quá trình lan truyền ngược. Để giải quyết điều này, chúng tôi đề xuất xử lý ||V+∆V||c trong Eq. (5) như một hằng số, do đó tách nó khỏi đồ thị gradient. Điều này có nghĩa là trong khi ||V+ ∆V||c phản ánh động các cập nhật của ∆V, nó sẽ không nhận được bất kỳ gradient nào trong quá trình lan truyền ngược. Với sửa đổi này, gradient đối với m vẫn không thay đổi, và ∇V′L được định nghĩa lại là:
∇V′L=m/C∇W′L trong đó C=||V′||c (11)

Phương pháp này giảm đáng kể mức tiêu thụ bộ nhớ đồ thị gradient mà không có sự khác biệt đáng kể về độ chính xác. Chúng tôi tiến hành nghiên cứu loại bỏ để đánh giá tác động của sửa đổi đề xuất đối với việc tinh chỉnh LLaMA-7B và VL-BART. Kết quả cho thấy sửa đổi dẫn đến giảm bộ nhớ huấn luyện khoảng 24.4% trong tinh chỉnh LLaMA và 12.4% trong VL-BART. Hơn nữa, độ chính xác của DoRA với sửa đổi vẫn không thay đổi đối với VL-BART và cho thấy sự khác biệt nhỏ chỉ 0.2 so với DoRA không có sửa đổi trên LLaMA. Để so sánh toàn diện về việc sử dụng bộ nhớ huấn luyện và các khác biệt độ chính xác, vui lòng xem Bảng 7 trong phụ lục. Do đó, tất cả các thí nghiệm tiếp theo với DoRA đều kết hợp điều chỉnh này.

5. Thí nghiệm
Chúng tôi tiến hành một loạt thí nghiệm để thể hiện hiệu quả của DoRA trên các tác vụ khác nhau bao gồm các miền ngôn ngữ, hình ảnh và video. Đầu tiên, chúng tôi đánh giá DoRA so với một số phương pháp Tinh chỉnh Hiệu quả Tham số (PEFT) bằng cách tinh chỉnh LLaMA-7B/13B, LLaMA2-7B, và LLaMA3-8B trên các tác vụ lý luận thông thường. Sau đó, chúng tôi mở rộng từ đơn phương thức đến đa phương thức. Chúng tôi so sánh DoRA với LoRA qua các tác vụ hiểu biết văn bản hình ảnh/video đa tác vụ bằng VL-BART và điều chỉnh hướng dẫn thị giác với LLaVA-1.5-7B. Tiếp theo, chúng tôi khám phá khả năng tương thích của DoRA với LoRA và VeRA (Kopiczko et al., 2024) cho điều chỉnh hướng dẫn trên LLaMA-7B và LLaMA2-7B. Hơn nữa, chúng tôi thực hiện một loạt nghiên cứu loại bỏ để minh họa rằng DoRA vượt trội so với LoRA về hiệu suất, bất kể số lượng mẫu huấn luyện tinh chỉnh và biến thể thứ hạng. Cuối cùng, chúng tôi phân tích độ chi tiết điều chỉnh của DoRA, và cho thấy DoRA có thể đạt được độ chính xác tốt hơn LoRA với ít tham số có thể huấn luyện hơn bằng cách chọn lọc cập nhật chỉ các thành phần hướng của một số mô-đun nhất định.

5.1. Lý Luận Thông Thường
Chúng tôi đánh giá DoRA so với LoRA và một số phương pháp cơ sở bao gồm Prompt learning (Prefix) (Li & Liang, 2021), Series adapter (Series) (Houlsby et al., 2019), và Parallel adapter (Parallel) (He et al., 2021) trên LLaMA-7B/13B (Touvron et al., 2023) cho các tác vụ lý luận thông thường. Chúng tôi cũng bao gồm độ chính xác của ChatGPT thu được bằng API gpt-3.5-turbo sử dụng Chain of Thought zero-shot (OpenAI, 2023; Wei et al., 2022).

Các tác vụ lý luận thông thường bao gồm 8 tác vụ con, mỗi tác vụ có tập huấn luyện và kiểm tra được định nghĩa trước. Chúng tôi theo cài đặt của (Hu et al., 2023) và kết hợp các tập dữ liệu huấn luyện từ tất cả 8 tác vụ để tạo tập dữ liệu huấn luyện cuối cùng và tiến hành đánh giá trên tập dữ liệu kiểm tra riêng lẻ cho mỗi tác vụ. Để đảm bảo so sánh công bằng, chúng tôi ban đầu tinh chỉnh các mô hình với DoRA theo cấu hình LoRA, duy trì cùng thứ hạng trong khi chỉ điều chỉnh tốc độ học. Sự tăng nhỏ 0.01% trong số lượng tham số có thể huấn luyện cho DoRA so với LoRA, như được chi tiết trong Bảng 1, phát sinh từ việc bao gồm các thành phần độ lớn có thể học (tham số có kích thước 1×k). Sau đó, chúng tôi tiếp tục giảm một nửa thứ hạng được sử dụng trong DoRA so với LoRA và ký hiệu cấu hình điều chỉnh này là DoRA†. Xem Bảng 8 để biết chi tiết về các siêu tham số được sử dụng.

Bảng 1 chứng minh rằng DoRA luôn vượt trội so với tất cả các phương pháp cơ sở trên cả LLaMA-7B/13B, LLaMA2-7B và LLaMA3-8B. Đáng chú ý, trong mô hình LLaMA-7B, nơi LoRA vượt trội so với hiệu suất của các cơ sở khác, DoRA tiếp tục tăng cường độ chính xác 3.7%, vượt qua mức độ chính xác của ChatGPT. Ngược lại, đối với LLaMA-13B, nơi hiệu quả của LoRA kém hơn Parallel adapter, DoRA đạt được độ chính xác vượt trội so với LoRA 1% và độ chính xác tương đương với Parallel adapter, với chỉ một phần tư tham số có thể huấn luyện được yêu cầu bởi Parallel adapter và không thêm bất kỳ chi phí suy luận bổ sung nào như Parallel adapter. Ngoài ra, DoRA luôn vượt trội so với LoRA trên cả LLaMA2-7B và LLaMA3-8B lần lượt 2.1% và 4.4%. Hơn nữa, DoRA† vượt trội so với hiệu suất của LoRA trên LLaMA-7B 2.8%, trên LLaMA-13B 1%, trên LLaMA2-7B 2.9%, và trên LLaMA3-8B 4.2%, mặc dù chỉ có một nửa số tham số có thể huấn luyện so với LoRA. Kết quả này gợi ý rằng việc tích hợp DoRA tăng cường khả năng học tập của LoRA, do đó giảm nhu cầu thứ hạng cao hơn để vượt trội so với LoRA về độ chính xác.

Ngoài ra, trong các phần trước, chúng tôi giả thuyết rằng tương quan âm giữa cập nhật độ lớn và cập nhật hướng là tối ưu hơn tương quan dương. Điều này là do trọng số tiền huấn luyện đã chứa kiến thức đáng kể phù hợp cho các tác vụ downstream, và thay đổi độ lớn hoặc hướng lớn hơn một mình là đủ cho thích ứng downstream. Để xác thực thêm giả thuyết của chúng tôi, chúng tôi đã sử dụng LLaMA2-7B được tinh chỉnh với DoRA/LoRA trên các tập dữ liệu lý luận thông thường như một nghiên cứu trường hợp. Chúng tôi hình dung sự khác biệt độ lớn (∆M) và hướng (∆D) giữa trọng số DoRA/LoRA và trọng số mô hình tiền huấn luyện qua các mô-đun và lớp khác nhau. Trong Hình 3 (a) và (b), chúng tôi quan sát thấy trọng số tinh chỉnh DoRA cho thấy ít sai lệch hơn so với trọng số tiền huấn luyện trong cả độ lớn và hướng, trong khi các khác biệt đối với trọng số tinh chỉnh LoRA lớn hơn đáng kể. Kết hợp với kết quả thí nghiệm rằng DoRA vượt trội đáng kể so với LoRA, chúng ta có thể kết luận rằng giả thuyết trước đây của chúng tôi là hợp lệ: một mô hình nền tảng mạnh mẽ không yêu cầu thay đổi đáng kể cho thích ứng downstream hiệu quả và có khả năng thực hiện cập nhật độ lớn và hướng tinh tế hơn giải thích sự vượt trội của DoRA so với LoRA. Chúng tôi để lại hình dung của các ma trận trọng số value và key trong phụ lục.

5.2. Hiểu Biết Văn Bản Hình Ảnh/Video
Sau khi chỉ ra rằng DoRA có thể luôn đạt được độ chính xác tốt hơn trong tinh chỉnh LLM, chúng tôi muốn xem liệu DoRA có thể duy trì tính cạnh tranh trong các tác vụ tinh chỉnh đa phương thức. Chúng tôi so sánh DoRA với LoRA và tinh chỉnh đầy đủ trên VL-BART bao gồm bộ mã hóa thị giác (CLIP-ResNet101 (Radford et al., 2021)) và mô hình ngôn ngữ mã hóa-giải mã (BART Base(Lewis et al., 2020)) qua bốn tác vụ văn bản hình ảnh khác nhau: VQAv2(Goyal et al., 2017) và GQA (Hudson & Manning, 2019) cho hỏi đáp thị giác, NLVR2(Suhr et al., 2019) cho lý luận thị giác, và MSCOCO (Chen et al., 2015) cho chú thích hình ảnh, và bốn tác vụ văn bản video khác nhau từ Benchmark VALUE (Li et al., 2021): TVQA (Lei et al., 2018) và How2QA (Li et al., 2020) cho hỏi đáp video, TVC (Lei et al., 2020) và YC2C (Zhou et al., 2018) cho chú thích video.

Chúng tôi theo cùng khung như (Sung et al., 2022) và tinh chỉnh VL-BART trong khung đa tác vụ cho cả tác vụ văn bản hình ảnh/video. Chúng tôi áp dụng cùng thiết lập như LoRA được nêu trong (Sung et al., 2022) khi áp dụng DoRA. Xem Bảng 9 cho các siêu tham số hoàn chỉnh. Kết quả của LoRA và FT cho cả tác vụ văn bản hình ảnh/video được trích dẫn trực tiếp từ (Sung et al., 2022). Chúng ta có thể thấy rằng DoRA vượt trội đồng nhất so với LoRA về độ chính xác trong khi duy trì số lượng tham số có thể huấn luyện tương tự trong cả Bảng 2 và Bảng 3. Cụ thể, DoRA vượt trội so với hiệu suất của LoRA gần 1% trong các tác vụ hiểu biết văn bản hình ảnh, đạt mức độ chính xác của FT. Hơn nữa, DoRA đạt được độ chính xác cao hơn khoảng 2% so với LoRA trong các tác vụ hiểu biết văn bản video.

5.3. Điều Chỉnh Hướng Dẫn Thị Giác
Chúng tôi tiếp tục mở rộng kích thước mô hình và so sánh DoRA với LoRA và FT trên các tác vụ điều chỉnh hướng dẫn thị giác với LLaVA-1.5-7B (Liu et al., 2023a) bao gồm một mô hình ngôn ngữ, Vicuna-1.5-7B (Peng et al., 2023), và một bộ mã hóa thị giác, CLIP ViT-L/336px (Radford et al., 2021). Các tập dữ liệu huấn luyện chứa một số tập dữ liệu từ VQA (Goyal et al., 2017; Hudson & Manning, 2019; Marino et al., 2019; Schwenk et al., 2022), OCR (Mishra et al., 2019; Sidorov et al., 2020), VQA cấp vùng (Kazemzadeh et al., 2014; Krishna et al., 2017; Mao et al., 2016), cuộc trò chuyện thị giác (Liu et al., 2023a), và dữ liệu cuộc trò chuyện ngôn ngữ. Chúng tôi theo cài đặt của (Liu et al., 2023a) để lọc dữ liệu huấn luyện và xây dựng định dạng prompt điều chỉnh. Để so sánh công bằng, DoRA theo cùng cấu hình như cấu hình LoRA được cung cấp bởi (Liu et al., 2023a). Các mô hình tinh chỉnh sau đó được đánh giá trên bảy benchmark vision-language: VQAv2(Goyal et al., 2017), GQA (Hudson & Manning, 2019), VisWiz (Gurari et al., 2018) SQA (Lu et al., 2022), VQAT(Singh et al., 2019), POPE (Li et al., 2023), và MMBench (Liu et al., 2023c).

Từ Bảng 4, chúng ta có thể quan sát thấy độ chính xác trung bình của LoRA đã vượt trội so với FT, điều này có thể ngụ ý rằng FT có thể gặp phải vấn đề về overfitting. Cho rằng DoRA được thiết kế để tăng cường hiệu suất của LoRA để gần giống với FT hơn, trong các tình huống mà FT kém hơn LoRA, cải thiện của DoRA so với LoRA có thể không rõ ràng như quan sát trong các thí nghiệm khác nơi FT thường vượt trội so với LoRA. Tuy nhiên, DoRA vẫn chứng minh hiệu suất vượt trội so với cả LoRA và FT, với cải thiện trung bình 0.7% so với LoRA và 1.1% so với FT. Xem Bảng 10 cho cài đặt siêu tham số và Bảng 12 cho điểm số của mỗi benchmark đánh giá.

5.4. Khả Năng Tương Thích của DoRA với các biến thể LoRA khác
Nhớ lại từ Phương trình (1) rằng ∆W có thể được thích ứng bởi các biến thể LoRA khác nhau. Với DoRA, khái niệm cập nhật hướng tăng dần ∆V được giới thiệu trong Phương trình (5) cũng có thể được thay thế bằng các biến thể LoRA khác. Trong phần này, chúng tôi chọn VeRA (Kopiczko et al., 2024) như một nghiên cứu trường hợp để khám phá khả năng tương thích của DoRA với các biến thể LoRA khác. VeRA đề xuất đóng băng một cặp ma trận ngẫu nhiên thứ hạng thấp duy nhất để được chia sẻ qua tất cả các lớp, chỉ sử dụng các vector tỷ lệ có thể huấn luyện tối thiểu cụ thể cho từng lớp để nắm bắt các cập nhật tăng dần của mỗi lớp. Phương pháp này cho phép VeRA giảm đáng kể các tham số có thể huấn luyện 10 lần so với LoRA, chỉ với tác động tối thiểu đến độ chính xác. Chúng tôi áp dụng VeRA cho cập nhật hướng trong DoRA và đặt tên cho sự kết hợp như vậy là DVoRA. Chúng tôi đánh giá hiệu quả của cả DVoRA và DoRA so với VeRA và LoRA qua LLaMA-7B và LLaMA2-7B, tập trung vào điều chỉnh hướng dẫn với tập con 10K của tập dữ liệu Alpaca đã được làm sạch (Taori et al., 2023). Chúng tôi sử dụng cài đặt chính thức của VeRA để có được kết quả của VeRA và LoRA và tinh chỉnh mô hình với DVoRA và DoRA sử dụng cài đặt huấn luyện giống hệt như VeRA và LoRA (xem Bảng 11 trong phụ lục để biết thêm chi tiết). Hiệu suất của các mô hình tinh chỉnh sau đó được đánh giá trên benchmark MT-Bench (Zheng et al., 2023) bằng cách tạo ra các phản hồi mô hình cho một tập hợp được định nghĩa trước gồm 80 câu hỏi đa lượt. Các phản hồi này sau đó được đánh giá bởi GPT-4, xem xét mỗi câu trả lời và gán một điểm số từ 10.

Bảng 5 trình bày điểm số trung bình cho DVoRA, DoRA, VeRA, và LoRA, chứng minh rằng phương pháp đề xuất của chúng tôi thể hiện cải thiện nhất quán so với VeRA và LoRA cho cả LLaMA-7B và LLaMA2-7B. Điều này hiệu quả thể hiện khả năng tương thích của DoRA với VeRA. Cụ thể, DVoRA kết hợp các phẩm chất có lợi của DoRA và VeRA, đạt được điểm số ngang bằng hoặc thậm chí vượt qua LoRA, nhưng với ít tham số hơn đáng kể. Ví dụ, DVoRA vượt trội so với VeRA 0.7/0.5 điểm và đạt được cùng mức độ chính xác như LoRA trên LLaMA-7B và DoRA trên LLaMA2-7B, tương ứng. Ngoài ra, chúng tôi trình bày một lựa chọn câu hỏi được chọn từ MT-Bench, kèm theo các phản hồi từ LLaMA2-7B được tinh chỉnh bằng DVoRA và VeRA trong phụ lục (Bảng 13 và 14) nơi chúng ta có thể quan sát thấy rằng các câu trả lời được đưa ra bởi DVoRA có xu hướng chính xác và có cấu trúc hơn.

Tiếp theo, để đánh giá thêm khả năng của DoRA duy trì tính cạnh tranh dưới các lượng dữ liệu huấn luyện khác nhau, xem xét rằng trong các tình huống thực tế, việc tiếp cận các tập dữ liệu tinh chỉnh rộng lớn thường bị hạn chế. Chúng tôi so sánh DoRA với LoRA và DVoRA với VeRA để tinh chỉnh LLaMA2-7B/LLaMA-7B với một loạt kích thước mẫu điều chỉnh hướng dẫn, cụ thể là 1000, 4000, 7000, 10000, với 10000 là cài đặt của (Kopiczko et al., 2024). Chúng tôi hình dung hiệu suất trung bình của mỗi phương pháp trên LLaMA2-7B trong Hình 4, và trên LLaMA-7B trong Hình 9 trong phụ lục. Kết quả cho thấy DoRA và DVoRA luôn vượt trội so với LoRA và VeRA qua tất cả các kích thước mẫu huấn luyện. Ví dụ, với 7000 mẫu huấn luyện, DoRA và DVoRA vượt trội so với LoRA và VeRA với biên độ 0.3 và 0.33, tương ứng. Ngay cả khi kích thước mẫu được giảm xuống 1000, DoRA và DVoRA vẫn duy trì lợi thế với ưu thế 0.29 và 0.22 so với LoRA và VeRA, tương ứng. Điều này chứng minh rằng các phương pháp của chúng tôi liên tục tăng cường hiệu suất so với LoRA và VeRA, bất kể khối lượng mẫu huấn luyện.

5.5. Độ Bền Vững của DoRA đối với các cài đặt thứ hạng khác nhau
Phần này khám phá tác động của các cấu hình thứ hạng khác nhau đối với DoRA và LoRA bằng cách điều chỉnh r trong tập {4, 8, 16, 32, 64} và đánh giá hiệu suất của LLaMA-7B tinh chỉnh trên các tác vụ lý luận thông thường như được nêu trong Phần 5.1. Độ chính xác trung bình của LoRA và DoRA qua các thứ hạng khác nhau được mô tả trong Hình 5, với các số chi tiết được trình bày trong Bảng 15. Từ Hình 5, chúng ta có thể quan sát thấy DoRA luôn vượt trội so với LoRA qua tất cả các cấu hình thứ hạng. Đáng chú ý, khoảng cách hiệu suất mở rộng cho các thứ hạng dưới 8, nơi độ chính xác trung bình của LoRA giảm xuống 40.74% cho r=8 và 39.49% cho r=4. Ngược lại, DoRA duy trì độ chính xác đáng kể là 77.96% cho r=8 và 61.89% cho r=4, chứng minh khả năng phục hồi và hiệu suất vượt trội nhất quán so với LoRA bất kể cài đặt thứ hạng.

5.6. Phân Tích Độ Chi Tiết Điều Chỉnh
Hình dung trong Hình 2 cho thấy rằng các thay đổi đáng kể về độ lớn thường dẫn đến các thay đổi hướng tương đối nhỏ hơn. Cho quan sát này và thực tế rằng các cập nhật hướng chiếm phần lớn các tham số có thể huấn luyện, nó thúc đẩy một cuộc điều tra về việc liệu có thể giảm số lượng tham số có thể huấn luyện bằng cách chỉ cập nhật các thành phần độ lớn của các mô-đun cụ thể trong khi tiếp tục cập nhật cả thành phần độ lớn và hướng cho các mô-đun tuyến tính còn lại.

Các phát hiện của chúng tôi cho thấy rằng, trái ngược với cấu hình gốc được đề xuất cho LoRA trong (Hu et al., 2023), yêu cầu cập nhật cả lớp Multi-head Attention và MLP để có hiệu suất tối ưu, DoRA đã có thể đạt được độ chính xác vượt trội bằng cách chỉ cập nhật các thành phần hướng và độ lớn của các lớp multi-head và độ lớn của các lớp MLP. Cụ thể, như được hiển thị trong Bảng 6, bằng cách cập nhật các thành phần hướng và độ lớn của các mô-đun QKV và chỉ độ lớn của các lớp còn lại, DoRA vượt trội so với LoRA 2.8% trên LLaMA-7B và 0.8% trên LLaMA-13B, trong khi sử dụng chỉ ít hơn một nửa số tham số có thể huấn luyện so với LoRA.

6. Tác Động Rộng Lớn Hơn
6.1. QDoRA: Cải Tiến cho QLoRA
Trong khi tinh chỉnh LLM với PEFT giảm đáng kể chi phí bộ nhớ huấn luyện, một lượng đáng kể bộ nhớ GPU vẫn được yêu cầu để ban đầu tải trọng số mô hình lên GPU. Để giảm thêm nhu cầu bộ nhớ của tinh chỉnh, QLoRA (Dettmers et al., 2023) đề xuất lượng tử hóa mô hình tiền huấn luyện xuống 4-bit và tinh chỉnh LoRA trên backbone bit thấp đóng băng. Với DoRA đề xuất của chúng tôi, thu hẹp khoảng cách giữa LoRA và FT, tự nhiên là cũng khám phá liệu DoRA có thể tăng cường độ chính xác của LoRA trong khung QLoRA. Gần đây, (Kerem Turgutlu, 2024) khởi chạy một dự án thay thế thành phần LoRA trong QLoRA bằng DoRA, gọi là QDoRA, và kết hợp đường ống huấn luyện với Fully Sharded Data Parallel (FSDP) (Zhao et al., 2023) để cho phép phân chia mô hình và huấn luyện song song qua nhiều GPU. Họ đã tiến hành thí nghiệm tinh chỉnh LLaMA2-7B/LLaMA3-8B sử dụng tập dữ liệu Orca-Math(Mitra et al., 2024) với QDoRA, QLoRA, và FT. Tập huấn luyện bao gồm 100k mẫu, với 500 được dành riêng cho đánh giá sử dụng điểm số exact match làm thước đo. Ngoài các mô hình tinh chỉnh, họ cũng báo cáo kết quả từ zero-shot, few-shot, và FT với quantization sau huấn luyện (PTQ), nơi mô hình FT được lượng tử hóa sang định dạng BnB NF4 sau huấn luyện. Theo Hình 6, QDoRA không chỉ vượt trội đáng kể so với QLoRA 0.19/0.23 trên LLaMA2-7B và LLaMA3-8B, mà còn nhẹ vượt trội so với FT trên cả hai mô hình, trong khi sử dụng ít bộ nhớ hơn đáng kể. Điều này cho thấy QDoRA có thể hiệu quả kết hợp hiệu quả tham số của QLoRA với tối ưu hóa chi tiết hơn của tinh chỉnh đầy đủ. Những phát hiện ban đầu này gợi ý rằng QDoRA có tiềm năng đáng kể và có thể mang lại lợi ích to lớn cho cộng đồng mã nguồn mở bằng cách giảm đáng kể các yêu cầu bộ nhớ GPU cho tinh chỉnh các mô hình ngôn ngữ lớn.

6.2. Tạo Sinh Văn Bản thành Hình Ảnh
Gần đây, khi các mô hình khuếch tán đã mở rộng kích thước, LoRA đã trở thành một phương pháp phổ biến để tinh chỉnh hiệu quả các mô hình stable diffusion lớn. Trong phần này, chúng tôi nhằm mục đích khám phá liệu các ưu thế của DoRA so với LoRA có mở rộng đến tác vụ tạo sinh văn bản thành hình ảnh. Chúng tôi theo đường ống huấn luyện của DreamBooth (Ruiz et al., 2023) để tinh chỉnh SDXL (Podell et al., 2023), sử dụng các script huấn luyện tiên tiến được phát triển bởi HuggingFace. Cài đặt siêu tham số cho LoRA và DoRA được giữ giống nhau, và chúng tôi tinh chỉnh mô hình sử dụng hai tập dữ liệu thách thức: biểu tượng 3D và bộ Lego. Hạt giống mẫu để tạo hình ảnh được giữ giống nhau cho LoRA và DoRA để so sánh công bằng. Các hình ảnh được tạo ra được hiển thị trong Hình 10 và 11 trong phụ lục. Kết quả cho thấy DoRA đạt được cá nhân hóa tốt hơn đáng kể so với LoRA khi sử dụng cùng cài đặt huấn luyện, và phản ánh chính xác hơn các mục tiêu huấn luyện. Ví dụ, trong Hình 10, hình phụ đầu tiên của đầu ra DoRA có một hình vuông tròn duy nhất xung quanh hình ảnh, đây là một đặc điểm chung cho tất cả các mục tiêu huấn luyện. Ngược lại, đặc điểm này không có mặt trong tất cả các đầu ra LoRA. Một quan sát tương tự có thể được tìm thấy với các mục tiêu huấn luyện Lego, nơi chỉ các đầu ra DoRA nhất quán kết hợp logo Lego trong các hình ảnh được tạo ra.

7. Kết Luận
Trong công trình này, chúng tôi đầu tiên tiến hành một phân tích phân tách trọng số mới để tiết lộ các mẫu học tập riêng biệt giữa LoRA và FT. Dựa trên những hiểu biết này, chúng tôi giới thiệu DoRA, một phương pháp tinh chỉnh tương thích với LoRA và các biến thể của nó và thể hiện sự giống nhau gần hơn với hành vi học tập của FT. DoRA luôn vượt trội so với LoRA qua các tác vụ tinh chỉnh và kiến trúc mô hình khác nhau. Cụ thể, DoRA cải thiện so với LoRA trong các tác vụ lý luận thông thường và điều chỉnh hướng dẫn thị giác. Hơn nữa, DoRA cũng cho thấy khả năng tương thích với VeRA trên tác vụ điều chỉnh hướng dẫn Alpaca. Hơn nữa, DoRA có thể được coi là một thay thế không tốn kém cho LoRA, vì các thành phần độ lớn và hướng phân tách của nó có thể được kết hợp trở lại vào trọng số tiền huấn luyện sau khi huấn luyện, đảm bảo rằng không có chi phí suy luận bổ sung. Đối với công việc tương lai, chúng tôi muốn khám phá khả năng tổng quát hóa của DoRA trong các miền ngoài ngôn ngữ và thị giác, đặc biệt là trong lĩnh vực âm thanh.

Lời Cảm Ơn
Chúng tôi bày tỏ lòng biết ơn đến Benjamin Bossan, Younes Belkada, và Sourab Mangrulkar từ Hugging Face vì sự hỗ trợ của họ trong việc tích hợp DoRA vào gói PEFT, do đó làm cho công trình của chúng tôi dễ tiếp cận hơn với công chúng rộng lớn. Chúng tôi cảm ơn Kerem Turgutlu, Jonathan Whitaker, và Jeremy Howard từ Answer.AI vì công việc của họ về việc thực hiện và thí nghiệm QDoRA/FSDP, điều này làm cho việc tinh chỉnh các mô hình ngôn ngữ lớn với DoRA trên GPU người tiêu dùng trở nên khả thi hơn nhiều. Chúng tôi cũng cảm ơn Sebastian Raschka vì hướng dẫn được viết tốt của ông về DoRA, cung cấp một cái nhìn tổng quan toàn diện về kiến thức nền cần thiết để hiểu DoRA.

Tuyên Bố Tác Động
Bài báo này trình bày công trình có mục tiêu thúc đẩy lĩnh vực Học Máy. Có nhiều hậu quả xã hội tiềm tàng của công trình chúng tôi, không có gì chúng tôi cảm thấy phải đặc biệt nhấn mạnh ở đây.

# 2211.03044.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/peft/2211.03044.pdf
# File size: 1590775 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Tuning Language Models as Training Data Generators for
Augmentation-Enhanced Few-Shot Learning
Yu Meng1Martin Michalski1Jiaxin Huang1Yu Zhang1Tarek Abdelzaher1Jiawei Han1
Abstract
Recent studies have revealed the intriguing few-
shot learning ability of pretrained language mod-
els (PLMs): They can quickly adapt to a new task
when Ô¨Åne-tuned on a small amount of labeled
data formulated as prompts, without requiring
abundant task-speciÔ¨Åc annotations. Despite their
promising performance, most existing few-shot
approaches that only learn from the small training
set still underperform fully supervised training
by nontrivial margins. In this work, we study
few-shot learning with PLMs from a different per-
spective: We Ô¨Årst tune an autoregressive PLM on
the few-shot samples and then use it as a gener-
ator to synthesize a large amount of novel train-
ing samples which augment the original training
set. To encourage the generator to produce label-
discriminative samples, we train it via weighted
maximum likelihood where the weight of each
token is automatically adjusted based on a dis-
criminative meta-learning objective. A classiÔ¨Å-
cation PLM can then be Ô¨Åne-tuned on both the
few-shot and the synthetic samples with regular-
ization for better generalization and stability. Our
approach FewGen achieves an overall better re-
sult across seven classiÔ¨Åcation tasks of the GLUE
benchmark than existing few-shot learning meth-
ods, improving no-augmentation methods by 5+
average points, and outperforming augmentation
methods by 3+average points.
1. Introduction
Recent research has demonstrated the appealing few-
shot learning potential of pretrained language models
(PLMs) (Brown et al., 2020; Clark et al., 2020; Devlin
et al., 2019; He et al., 2021; Liu et al., 2019; Meng et al.,
1University of Illinois Urbana-Champaign. Correspondence to:
Yu Meng<yumeng5@illinois.edu >.
Proceedings of the 40thInternational Conference on Machine
Learning , Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright
2023 by the author(s).2021a; 2022b) on natural language understanding (NLU)
tasks (Wang et al., 2019; 2018): Instead of relying on abun-
dant task-speciÔ¨Åc annotations, PLMs can effectively lever-
age a small set of training samples to quickly learn a new
task. Such training data efÔ¨Åciency is usually achieved by for-
mulating downstream tasks as prompts (Brown et al., 2020;
Gao et al., 2021; Scao & Rush, 2021; Schick & Sch ¬®utze,
2021a;d), allowing the PLM to adapt its language modeling
ability acquired through pretraining to downstream tasks.
The success of prompt-based methods has stimulated nu-
merous explorations along the line of effective few-shot
learning with PLMs: The training samples converted to
natural language prompts can be used to directly Ô¨Åne-tune
PLMs (Gao et al., 2021; Schick & Sch ¬®utze, 2021a) or as
in-context demonstrations to facilitate better inference (Liu
et al., 2022b; Min et al., 2022b). Recent approaches aim to
automate the design of prompts by gradient-based search-
ing (Shin et al., 2020) or parameterizing prompts as con-
tinuous learnable embeddings (Lester et al., 2021; Zhang
et al., 2022; Zhong et al., 2021). Other studies investigate
and address speciÔ¨Åc issues in prompt-based few-shot learn-
ing (Liu et al., 2022a; Tam et al., 2021; Zhao et al., 2021).
While remarkable, the model performance still has a non-
trivial gap from fully supervised models trained on massive
labeled data. Indeed, training deep models is inherently data
demanding‚Äîmodel generalization usually beneÔ¨Åts from
more training samples (Baum & Haussler, 1988).
In this work, we study few-shot learning with PLMs from
a different perspective: Instead of proposing new methods
for Ô¨Åne-tuning on few-shot samples, we focus on the gen-
eration of quality training data based on few-shot samples
and using these synthesized training samples to Ô¨Åne-tune
the classiÔ¨Åcation models. Motivated by the strong text gen-
eration power of autoregressive PLMs (Brown et al., 2020;
Keskar et al., 2019; Raffel et al., 2019), a few previous
studies enlarge the training set by generating new texts as
training samples. They either Ô¨Åne-tune the generator on the
initial training set with the standard maximum likelihood
objective (Anaby-Tavor et al., 2020; Kumar et al., 2020)
or use the training samples as demonstrations (Yoo et al.,
2021). However, these methods do not explicitly model
the distinction across different labels and may struggle to
1arXiv:2211.03044v2  [cs.CL]  12 May 2023

--- PAGE 2 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
generate accurate training samples pertaining to the desired
labels for challenging NLU tasks.
In this paper, we explore how to effectively use few-shot
samples to tune PLMs for generating high quality label-
discriminative training samples. Our contributions are as
follows: (1) We analyze the issues of using standard max-
imum likelihood for tuning the generator and propose a
meta-weighted maximum likelihood objective by automati-
cally learning token weights that emphasize label discrimi-
nativeness. (2) We propose a simple and effective training
procedure for Ô¨Åne-tuning classiÔ¨Åcation PLMs on generated
data by mitigating label noise. (3) Under the same few-shot
learning setting, our method FewGen outperforms existing
methods by 3+average points on seven classiÔ¨Åcation tasks
of the GLUE benchmark (Wang et al., 2018). Ablation stud-
ies validate the effectiveness of our proposed meta-weighted
training objective and classiÔ¨Åer Ô¨Åne-tuning method.1
2. Related Work
Few-Shot Learning with PLMs. Few-shot learning has
gained much attention recently due to its minimal resource
assumption‚ÄîWithout requiring massive annotated data but
only leveraging a few training samples ( e.g.,16per label),
few-shot methods can be widely adopted in many prac-
tical scenarios where obtaining large-scale annotations is
unaffordable. Standard Ô¨Åne-tuning of PLMs for few-shot
learning usually performs poorly because the limited train-
ing samples may not be sufÔ¨Åcient for optimizing the pa-
rameters in the newly introduced classiÔ¨Åcation head. To
reuse the language modeling ability of PLMs without in-
troducing randomly initialized parameters, prompt-based
approaches (Brown et al., 2020; Gao et al., 2021; Hu et al.,
2022; Logan IV et al., 2021; Min et al., 2022a; Schick &
Sch¬®utze, 2021a;b;d; Tam et al., 2021) formulate training
samples as natural language prompt templates so that var-
ious downsteam tasks can be solved as a token prediction
problem. They enjoy improved training data efÔ¨Åciency over
standard Ô¨Åne-tuning in low-data regimes (Scao & Rush,
2021) and achieve remarkable few-shot learning perfor-
mance. Later developments in prompt-based methods re-
place the manual design of prompt templates with automatic
search or learning (Cui et al., 2022; Hambardzumyan et al.,
2021; Lester et al., 2021; Liu et al., 2021b; Zhang et al.,
2022; Zhong et al., 2021). There are also studies focusing
on speciÔ¨Åc issues (Liu et al., 2022a; Tam et al., 2021; Zhao
et al., 2021) in prompt-based methods. Instead of proposing
Ô¨Åne-tuning methods for few-shot learning, we study how
to generate quality training samples as augmentations by
learning from the few-shot samples.
1Code can be found at https://github.com/
yumeng5/FewGen .Data Augmentation. Data augmentation methods (Chen
et al., 2020; Huang et al., 2022; Lee et al., 2021; Meng
et al., 2021b; Miyato et al., 2017; Xie et al., 2020) aim to
create similar samples to the existing ones so that the en-
larged training set can beneÔ¨Åt model generalization. Early
approaches simply use manually designed rules ( e.g., swap-
ping or inserting tokens) for word-level alterations over the
given samples to create new ones (Wei & Zou, 2019). Later
methods leverage the strong generation power of PLMs to
synthesize novel samples from scratch. Given a training set,
the PLMs can be either Ô¨Åne-tuned on the labeled samples to
learn label-conditioned generation probability (Kumar et al.,
2020; Lee et al., 2021; Yang et al., 2020) or take the labeled
data as demonstrations (Wang et al., 2021; Yoo et al., 2021)
to generate similar samples pertaining to the same label. In
this work, we study how to effectively tune generators on
few-shot training data for creating new data‚Äîstandard Ô¨Åne-
tuning of PLMs on a small set of training data is prone to
overÔ¨Åtting, and the resulting model may struggle to generate
accurate, diverse and novel training data. We address this
challenge by leveraging preÔ¨Åx-tuning and proposing a new
meta-weighted generator tuning objective that emphasizes
label-distinctive tokens.
Controlled Text Generation. Generating training sam-
ples for different labels can be viewed as a form of con-
trolled text generation (Hu et al., 2017), whose goal is to
generate textual contents of desired semantics, styles or
attributes. Such control can be realized through different
stages of PLM training and deployment: During pretraining,
control codes (Keskar et al., 2019) can be used as explicit
guidance for training the model to generate domain/attribute-
speciÔ¨Åc texts; Ô¨Åne-tuning PLMs with attribute-speciÔ¨Åc data
can also grant high-level control ( e.g., certain topics or sen-
timents (Ziegler et al., 2019)), Ô¨Åne-grained control ( e.g.,
speciÔ¨Åc words or phrases (Chan et al., 2021)) or both (Khal-
ifa et al., 2021); at inference time, control over desired
attributes can also be enforced without updating the PLM
parameters (Dathathri et al., 2020; Krause et al., 2021; Ku-
mar et al., 2021; Liu et al., 2021a; Pascual et al., 2021; Yang
& Klein, 2021). More speciÔ¨Åcally related to the idea of
generating training data with language models, early meth-
ods in text classiÔ¨Åcation use bag-of-words or LSTM-based
language models (Meng et al., 2018; 2019) to generate class-
conditioned texts as training data. Recently, a few studies
explore Ô¨Åne-tuning autoregressive PLMs (Anaby-Tavor
et al., 2020; Yang et al., 2020) with the standard language
modeling objective on the training set or using label-speciÔ¨Åc
prompts (Gao et al., 2023; Meng et al., 2022a; Schick &
Sch¬®utze, 2021c; Wang et al., 2021; Ye et al., 2022) to steer
text generation towards the desired label. In this work, we
analyze issues with directly tuning PLMs on few-shot sam-
ples with the standard maximum likelihood objective and
propose a weighted variant of the objective that encourages
2

--- PAGE 3 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
the PLM to focus on label-discriminative tokens.
Meta-Learning for Sample Weighting. The idea of
weighting training samples in the loss calculation originates
from the class imbalance (Wang et al., 2017) and noisy
label (Hendrycks et al., 2018) learning scenarios‚ÄîBy as-
signing higher weights to the samples from minority classes
or lower weights to the noisy samples, the learning pro-
cess is less impacted by the imbalance/label noise issues.
Meta-learning (Andrychowicz et al., 2016; Finn et al., 2017;
Franceschi et al., 2018; Wu et al., 2018) is one way to auto-
matically learn the weight for each sample. SpeciÔ¨Åcally, a
meta objective, usually deÔ¨Åned as the loss on a clean unbi-
ased validation set (Ren et al., 2018; Shu et al., 2019), can
be used to learn the sample weights which become hyperpa-
rameters that control the optimization of model parameters.
Our work has a different motivation and formulation of the
meta objective for token-wise weighted training: Not all
tokens in a training sample are equally label-discriminative.
We thus design a meta objective to emphasize distinction
across different labels (instead of using the validation loss
as the meta objective) for learning the token weights.
3. Method
3.1. Preliminaries
Overview. We consider the strict few-shot learning set-
ting (Perez et al., 2021): The training set Dtrain=f(x;y)ig
consists of Ktraining samples per label where x=
[x1;x2;:::;xn]is a text sequence with ntokens. The de-
velopment setDdevis of the same size as Dtrain. There is
no access to additional task-speciÔ¨Åc unlabeled data. The
number of training samples Kis assumed to be very small
(e.g.,K= 16 ), making it challenging to train a classiÔ¨Å-
cation model Cthat generalizes well to unseen data. To
mitigate the training data scarcity issue, we Ô¨Årst train an
autoregressive PLM on Dtrain, and then use it as a generator
Gto synthesize more novel samples Dgen=f(~x;~y)igthat
augment the original training set. Finally, a classiÔ¨Åcation
PLMCis Ô¨Åne-tuned on both DtrainandDgento perform
the task. An overview of FewGen is shown in Fig. 1.
Text Generation with Autoregressive PLMs. In stan-
dard Ô¨Åne-tuning for text generation, an autoregressive PLM
Gis trained via the maximum likelihood generation loss of
each token in a sequence xconditioned on previous tokens:
min
 1
nnX
j=1logp(xjjx<j);
p(xjjx<j) =exp(e>
jhj)
PjVj
j0=1exp(e>
j0hj):where the token generation probability p()is usually pa-
rameterized using token embeddings eand hidden states h
of a Transformer (Vaswani et al., 2017) model. After train-
ing,Gcan be used to generate novel texts by iteratively
sampling tokens from its generation probability distribution.
PreÔ¨Åx-Tuning. Unlike Ô¨Åne-tuning which updates all
model parameters of a PLM, preÔ¨Åx-tuning (Li & Liang,
2021) freezes all pretrained Transformer parameters and
only optimizes preÔ¨Åx vectors pthat are prepended to each
Transformer layer. We use preÔ¨Åx-tuning for training Gp
onDtrainbecause (1) it offers better effectiveness than Ô¨Åne-
tuning for small datasets (Li & Liang, 2021) and (2) the
generation models for different labels can share the same
backbone Transformer parameters with only the preÔ¨Åx vec-
tors being different, signiÔ¨Åcantly reducing the memory re-
quirement for multi-class classiÔ¨Åcation tasks.
3.2. Label-Discriminative Text Generator Tuning
Motivation. To model the conditional text generation
probabilityp(xjyl)on different labels, a straightforward
way is to parameterize a generation model Gplfor each
labelylvia a set of preÔ¨Åx vectors p=fplgjL
l=1so that
p(xjyl) =ppl(x), and then tune plon the training sam-
plesxwith labelyl:
min
plLgen;Lgen(pl) = 1
nnX
j=1logppl(xjjx<j):(1)
However, such an approach only optimizes the generative
likelihoodp(xjyl)without accounting for label discrimina-
tivenessp(yljx)which is essential for generating unambigu-
ous training samples to beneÔ¨Åt the Ô¨Ånal classiÔ¨Åcation task.
Challenging NLU tasks can have largely similar distribu-
tions across different labels, with very nuanced differences
reÔ¨Çected by a few key tokens. For example, a negative re-
view text ‚Äú a movie where the ending feels like a cop-out ‚Äù
may immediately become a positive one by just changing
the last word ‚Äúcop-out‚Äù to ‚Äúrevelation‚Äù. Indeed, we Ô¨Ånd
that such subtle distinctions over different labels may not
be effectively captured using the standard generation objec-
tive in Eq. (1)where each token contributes equally to the
overall loss. As shown in Fig. 2, a discriminative loss Ldisc
(deÔ¨Åned in Eq. (2)) can even increase during training‚ÄîIt is
possible that the dominating patterns in the training samples
are label- indiscriminate (e.g., a movie review dataset may
frequently mention ‚Äúthe movie‚Äù), making the generators of
different labels eventually converge to similar distributions,
especially when there are limited training samples per label.
To promote the generation of label-discriminative texts, we
encourage each token xjto be more likely generated under
the corresponding label ylinstead of other labels ( i.e., maxi-
mizeppl(xjjx<j)and minimize ppl0(xjjx<j)forl06=l)
3

--- PAGE 4 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Autoregressive PLM(frozen)
<latexit sha1_base64="YBz04+z+ETsAgwq4V58SIMoauRc=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx0/9T3+uWKW3XnIKvEy0kFcjT65a/eIGZphNIwQbXuem5i/Iwqw5nAaamXakwoG9Mhdi2VNELtZ/NTp+TMKgMSxsqWNGSu/p7IaKT1JApsZ0TNSC97M/E/r5ua8NrPuExSg5ItFoWpICYms7/JgCtkRkwsoUxxeythI6ooMzadkg3BW355lbQuqt5ltXZXq9RreRxFOIFTOAcPrqAOt9CAJjAYwjO8wpsjnBfn3flYtBacfOYY/sD5/AEKaI2b</latexit>x1
<latexit sha1_base64="YBz04+z+ETsAgwq4V58SIMoauRc=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx0/9T3+uWKW3XnIKvEy0kFcjT65a/eIGZphNIwQbXuem5i/Iwqw5nAaamXakwoG9Mhdi2VNELtZ/NTp+TMKgMSxsqWNGSu/p7IaKT1JApsZ0TNSC97M/E/r5ua8NrPuExSg5ItFoWpICYms7/JgCtkRkwsoUxxeythI6ooMzadkg3BW355lbQuqt5ltXZXq9RreRxFOIFTOAcPrqAOt9CAJjAYwjO8wpsjnBfn3flYtBacfOYY/sD5/AEKaI2b</latexit>x1
PreÔ¨Åx<latexit sha1_base64="L/GsFSN8q9178ZEb98acQLzwm4Q=">AAAB8XicbVBNS8NAEJ34WetX1aOXYBE8lUSKeix48VjBfmAbymY7bZduNmF3IpTQf+HFgyJe/Tfe/Ddu2xy09cHA470ZZuaFiRSGPO/bWVvf2NzaLuwUd/f2Dw5LR8dNE6eaY4PHMtbtkBmUQmGDBElsJxpZFEpshePbmd96Qm1ErB5okmAQsaESA8EZWemxSyMk1suSaa9U9ireHO4q8XNShhz1Xumr2495GqEiLpkxHd9LKMiYJsElTovd1GDC+JgNsWOpYhGaIJtfPHXPrdJ3B7G2pcidq78nMhYZM4lC2xkxGpllbyb+53VSGtwEmVBJSqj4YtEglS7F7ux9ty80cpITSxjXwt7q8hHTjJMNqWhD8JdfXiXNy4p/VaneV8u1ah5HAU7hDC7Ah2uowR3UoQEcFDzDK7w5xnlx3p2PReuak8+cwB84nz/0h5ES</latexit>‚úìp
<latexit sha1_base64="L/GsFSN8q9178ZEb98acQLzwm4Q=">AAAB8XicbVBNS8NAEJ34WetX1aOXYBE8lUSKeix48VjBfmAbymY7bZduNmF3IpTQf+HFgyJe/Tfe/Ddu2xy09cHA470ZZuaFiRSGPO/bWVvf2NzaLuwUd/f2Dw5LR8dNE6eaY4PHMtbtkBmUQmGDBElsJxpZFEpshePbmd96Qm1ErB5okmAQsaESA8EZWemxSyMk1suSaa9U9ireHO4q8XNShhz1Xumr2495GqEiLpkxHd9LKMiYJsElTovd1GDC+JgNsWOpYhGaIJtfPHXPrdJ3B7G2pcidq78nMhYZM4lC2xkxGpllbyb+53VSGtwEmVBJSqj4YtEglS7F7ux9ty80cpITSxjXwt7q8hHTjJMNqWhD8JdfXiXNy4p/VaneV8u1ah5HAU7hDC7Ah2uowR3UoQEcFDzDK7w5xnlx3p2PReuak8+cwB84nz/0h5ES</latexit>‚úìp¬∑¬∑¬∑<latexit sha1_base64="AcPHc2/GmseUvYw39tetylSl3A8=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cK9gPaUDabTbt2kw27E6GE/gcvHhTx6v/x5r9x2+agrQ8GHu/NMDMvSKUw6LrfTmltfWNzq7xd2dnd2z+oHh61jco04y2mpNLdgBouRcJbKFDybqo5jQPJO8H4duZ3nrg2QiUPOEm5H9NhIiLBKFqp3WehQjOo1ty6OwdZJV5BalCgOah+9UPFspgnyCQ1pue5Kfo51SiY5NNKPzM8pWxMh7xnaUJjbvx8fu2UnFklJJHSthIkc/X3RE5jYyZxYDtjiiOz7M3E/7xehtG1n4skzZAnbLEoyiRBRWavk1BozlBOLKFMC3srYSOqKUMbUMWG4C2/vEraF3XPJnN/WWvcFHGU4QRO4Rw8uIIG3EETWsDgEZ7hFd4c5bw4787HorXkFDPH8AfO5w+uBY8u</latexit><latexit sha1_base64="AcPHc2/GmseUvYw39tetylSl3A8=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cK9gPaUDabTbt2kw27E6GE/gcvHhTx6v/x5r9x2+agrQ8GHu/NMDMvSKUw6LrfTmltfWNzq7xd2dnd2z+oHh61jco04y2mpNLdgBouRcJbKFDybqo5jQPJO8H4duZ3nrg2QiUPOEm5H9NhIiLBKFqp3WehQjOo1ty6OwdZJV5BalCgOah+9UPFspgnyCQ1pue5Kfo51SiY5NNKPzM8pWxMh7xnaUJjbvx8fu2UnFklJJHSthIkc/X3RE5jYyZxYDtjiiOz7M3E/7xehtG1n4skzZAnbLEoyiRBRWavk1BozlBOLKFMC3srYSOqKUMbUMWG4C2/vEraF3XPJnN/WWvcFHGU4QRO4Rw8uIIG3EETWsDgEZ7hFd4c5bw4787HorXkFDPH8AfO5w+uBY8u</latexit><latexit sha1_base64="AcPHc2/GmseUvYw39tetylSl3A8=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cK9gPaUDabTbt2kw27E6GE/gcvHhTx6v/x5r9x2+agrQ8GHu/NMDMvSKUw6LrfTmltfWNzq7xd2dnd2z+oHh61jco04y2mpNLdgBouRcJbKFDybqo5jQPJO8H4duZ3nrg2QiUPOEm5H9NhIiLBKFqp3WehQjOo1ty6OwdZJV5BalCgOah+9UPFspgnyCQ1pue5Kfo51SiY5NNKPzM8pWxMh7xnaUJjbvx8fu2UnFklJJHSthIkc/X3RE5jYyZxYDtjiiOz7M3E/7xehtG1n4skzZAnbLEoyiRBRWavk1BozlBOLKFMC3srYSOqKUMbUMWG4C2/vEraF3XPJnN/WWvcFHGU4QRO4Rw8uIIG3EETWsDgEZ7hFd4c5bw4787HorXkFDPH8AfO5w+uBY8u</latexit><latexit sha1_base64="AcPHc2/GmseUvYw39tetylSl3A8=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cK9gPaUDabTbt2kw27E6GE/gcvHhTx6v/x5r9x2+agrQ8GHu/NMDMvSKUw6LrfTmltfWNzq7xd2dnd2z+oHh61jco04y2mpNLdgBouRcJbKFDybqo5jQPJO8H4duZ3nrg2QiUPOEm5H9NhIiLBKFqp3WehQjOo1ty6OwdZJV5BalCgOah+9UPFspgnyCQ1pue5Kfo51SiY5NNKPzM8pWxMh7xnaUJjbvx8fu2UnFklJJHSthIkc/X3RE5jYyZxYDtjiiOz7M3E/7xehtG1n4skzZAnbLEoyiRBRWavk1BozlBOLKFMC3srYSOqKUMbUMWG4C2/vEraF3XPJnN/WWvcFHGU4QRO4Rw8uIIG3EETWsDgEZ7hFd4c5bw4787HorXkFDPH8AfO5w+uBY8u</latexit>
<latexit sha1_base64="+FXiSQiYwlN0oEEEdSOOedg1wVA=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKUY8FLx4r2lZoQ9lsN+3SzSbsTsQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4W19Y3NreJ2aWd3b/+gfHjUNnGqGW+xWMb6IaCGS6F4CwVK/pBoTqNA8k4wvp75nUeujYjVPU4S7kd0qEQoGEUr3T31a/1yxa26c5BV4uWkAjma/fJXbxCzNOIKmaTGdD03QT+jGgWTfFrqpYYnlI3pkHctVTTixs/mp07JmVUGJIy1LYVkrv6eyGhkzCQKbGdEcWSWvZn4n9dNMbzyM6GSFLlii0VhKgnGZPY3GQjNGcqJJZRpYW8lbEQ1ZWjTKdkQvOWXV0m7VvUuqvXbeqVRz+Mowgmcwjl4cAkNuIEmtIDBEJ7hFd4c6bw4787HorXg5DPH8AfO5w8L7I2c</latexit>x2
<latexit sha1_base64="+FXiSQiYwlN0oEEEdSOOedg1wVA=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKUY8FLx4r2lZoQ9lsN+3SzSbsTsQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8IJHCoOt+O4W19Y3NreJ2aWd3b/+gfHjUNnGqGW+xWMb6IaCGS6F4CwVK/pBoTqNA8k4wvp75nUeujYjVPU4S7kd0qEQoGEUr3T31a/1yxa26c5BV4uWkAjma/fJXbxCzNOIKmaTGdD03QT+jGgWTfFrqpYYnlI3pkHctVTTixs/mp07JmVUGJIy1LYVkrv6eyGhkzCQKbGdEcWSWvZn4n9dNMbzyM6GSFLlii0VhKgnGZPY3GQjNGcqJJZRpYW8lbEQ1ZWjTKdkQvOWXV0m7VvUuqvXbeqVRz+Mowgmcwjl4cAkNuIEmtIDBEJ7hFd4c6bw4787HorXg5DPH8AfO5w8L7I2c</latexit>x2<latexit sha1_base64="zLeqvMqEy8Jwfmd5JBGmIDxZ/iQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2m3bpZhN2J2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekEhh0HW/ncLa+sbmVnG7tLO7t39QPjxqmTjVjDdZLGPdCajhUijeRIGSdxLNaRRI3g7GNzO//ci1EbF6wEnC/YgOlQgFo2il+6e+6pcrbtWdg6wSLycVyNHol796g5ilEVfIJDWm67kJ+hnVKJjk01IvNTyhbEyHvGupohE3fjY/dUrOrDIgYaxtKSRz9fdERiNjJlFgOyOKI7PszcT/vG6K4bWfCZWkyBVbLApTSTAms7/JQGjOUE4soUwLeythI6opQ5tOyYbgLb+8SloXVe+yWrurVeq1PI4inMApnIMHV1CHW2hAExgM4Rle4c2Rzovz7nwsWgtOPnMMf+B8/gBm3I3Y</latexit>xn
<latexit sha1_base64="zLeqvMqEy8Jwfmd5JBGmIDxZ/iQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2m3bpZhN2J2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekEhh0HW/ncLa+sbmVnG7tLO7t39QPjxqmTjVjDdZLGPdCajhUijeRIGSdxLNaRRI3g7GNzO//ci1EbF6wEnC/YgOlQgFo2il+6e+6pcrbtWdg6wSLycVyNHol796g5ilEVfIJDWm67kJ+hnVKJjk01IvNTyhbEyHvGupohE3fjY/dUrOrDIgYaxtKSRz9fdERiNjJlFgOyOKI7PszcT/vG6K4bWfCZWkyBVbLApTSTAms7/JQGjOUE4soUwLeythI6opQ5tOyYbgLb+8SloXVe+yWrurVeq1PI4inMApnIMHV1CHW2hAExgM4Rle4c2Rzovz7nwsWgtOPnMMf+B8/gBm3I3Y</latexit>xn¬∑¬∑¬∑<latexit sha1_base64="AcPHc2/GmseUvYw39tetylSl3A8=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cK9gPaUDabTbt2kw27E6GE/gcvHhTx6v/x5r9x2+agrQ8GHu/NMDMvSKUw6LrfTmltfWNzq7xd2dnd2z+oHh61jco04y2mpNLdgBouRcJbKFDybqo5jQPJO8H4duZ3nrg2QiUPOEm5H9NhIiLBKFqp3WehQjOo1ty6OwdZJV5BalCgOah+9UPFspgnyCQ1pue5Kfo51SiY5NNKPzM8pWxMh7xnaUJjbvx8fu2UnFklJJHSthIkc/X3RE5jYyZxYDtjiiOz7M3E/7xehtG1n4skzZAnbLEoyiRBRWavk1BozlBOLKFMC3srYSOqKUMbUMWG4C2/vEraF3XPJnN/WWvcFHGU4QRO4Rw8uIIG3EETWsDgEZ7hFd4c5bw4787HorXkFDPH8AfO5w+uBY8u</latexit><latexit sha1_base64="AcPHc2/GmseUvYw39tetylSl3A8=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cK9gPaUDabTbt2kw27E6GE/gcvHhTx6v/x5r9x2+agrQ8GHu/NMDMvSKUw6LrfTmltfWNzq7xd2dnd2z+oHh61jco04y2mpNLdgBouRcJbKFDybqo5jQPJO8H4duZ3nrg2QiUPOEm5H9NhIiLBKFqp3WehQjOo1ty6OwdZJV5BalCgOah+9UPFspgnyCQ1pue5Kfo51SiY5NNKPzM8pWxMh7xnaUJjbvx8fu2UnFklJJHSthIkc/X3RE5jYyZxYDtjiiOz7M3E/7xehtG1n4skzZAnbLEoyiRBRWavk1BozlBOLKFMC3srYSOqKUMbUMWG4C2/vEraF3XPJnN/WWvcFHGU4QRO4Rw8uIIG3EETWsDgEZ7hFd4c5bw4787HorXkFDPH8AfO5w+uBY8u</latexit><latexit sha1_base64="AcPHc2/GmseUvYw39tetylSl3A8=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cK9gPaUDabTbt2kw27E6GE/gcvHhTx6v/x5r9x2+agrQ8GHu/NMDMvSKUw6LrfTmltfWNzq7xd2dnd2z+oHh61jco04y2mpNLdgBouRcJbKFDybqo5jQPJO8H4duZ3nrg2QiUPOEm5H9NhIiLBKFqp3WehQjOo1ty6OwdZJV5BalCgOah+9UPFspgnyCQ1pue5Kfo51SiY5NNKPzM8pWxMh7xnaUJjbvx8fu2UnFklJJHSthIkc/X3RE5jYyZxYDtjiiOz7M3E/7xehtG1n4skzZAnbLEoyiRBRWavk1BozlBOLKFMC3srYSOqKUMbUMWG4C2/vEraF3XPJnN/WWvcFHGU4QRO4Rw8uIIG3EETWsDgEZ7hFd4c5bw4787HorXkFDPH8AfO5w+uBY8u</latexit><latexit sha1_base64="AcPHc2/GmseUvYw39tetylSl3A8=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cK9gPaUDabTbt2kw27E6GE/gcvHhTx6v/x5r9x2+agrQ8GHu/NMDMvSKUw6LrfTmltfWNzq7xd2dnd2z+oHh61jco04y2mpNLdgBouRcJbKFDybqo5jQPJO8H4duZ3nrg2QiUPOEm5H9NhIiLBKFqp3WehQjOo1ty6OwdZJV5BalCgOah+9UPFspgnyCQ1pue5Kfo51SiY5NNKPzM8pWxMh7xnaUJjbvx8fu2UnFklJJHSthIkc/X3RE5jYyZxYDtjiiOz7M3E/7xehtG1n4skzZAnbLEoyiRBRWavk1BozlBOLKFMC3srYSOqKUMbUMWG4C2/vEraF3XPJnN/WWvcFHGU4QRO4Rw8uIIG3EETWsDgEZ7hFd4c5bw4787HorXkFDPH8AfO5w+uBY8u</latexit>
ClassiÔ¨Åcation PLM
<latexit sha1_base64="lw/CyxS9BFwGblz0kbCSyjdq/E4=">AAACAXicbVBNS8NAEN34WetX1YvgJVgETyWRoh4LevBYwX5AG8JmO22XbjZhdyKWEC/+FS8eFPHqv/Dmv3Hb5qCtDwYe780wMy+IBdfoON/W0vLK6tp6YaO4ubW9s1va22/qKFEMGiwSkWoHVIPgEhrIUUA7VkDDQEArGF1N/NY9KM0jeYfjGLyQDiTvc0bRSH7psBtSHDIq0uvMT7sID5gOQGaZXyo7FWcKe5G4OSmTHHW/9NXtRSwJQSITVOuO68TopVQhZwKyYjfREFM2ogPoGCppCNpLpx9k9olRenY/UqYk2lP190RKQ63HYWA6J/fqeW8i/ud1EuxfeimXcYIg2WxRPxE2RvYkDrvHFTAUY0MoU9zcarMhVZShCa1oQnDnX14kzbOKe16p3lbLtWoeR4EckWNySlxyQWrkhtRJgzDySJ7JK3mznqwX6936mLUuWfnMAfkD6/MHvsiXsg==</latexit>Dgen______________________________________________________________________________________________________________________________________________________Generator TrainingClassiÔ¨Åer Training__________________________________________________<latexit sha1_base64="fFHmQiaNPG9ZdcSBIOu1Eg7yAtE=">AAACA3icbVBNS8NAEN34WetX1JtegkXwVBIp6rGgB48V7Ac0IWy2m3bpZhN2J2IJAS/+FS8eFPHqn/Dmv3HT5qCtDwYe780wMy9IOFNg29/G0vLK6tp6ZaO6ubW9s2vu7XdUnEpC2yTmsewFWFHOBG0DA057iaQ4CjjtBuOrwu/eU6lYLO5gklAvwkPBQkYwaMk3D90Iw4hgnl3nfuYCfYAMJGYiz32zZtftKaxF4pSkhkq0fPPLHcQkjagAwrFSfcdOwMuwBEY4zatuqmiCyRgPaV9TgSOqvGz6Q26daGVghbHUJcCaqr8nMhwpNYkC3VlcrOa9QvzP66cQXnoZE0kKVJDZojDlFsRWEYg1YJIS4BNNMJFM32qREZaYgI6tqkNw5l9eJJ2zunNeb9w2as1GGUcFHaFjdIocdIGa6Aa1UBsR9Iie0St6M56MF+Pd+Ji1LhnlzAH6A+PzB3eQmKo=</latexit>DtrainStep 1: Supervised Training on <latexit sha1_base64="fFHmQiaNPG9ZdcSBIOu1Eg7yAtE=">AAACA3icbVBNS8NAEN34WetX1JtegkXwVBIp6rGgB48V7Ac0IWy2m3bpZhN2J2IJAS/+FS8eFPHqn/Dmv3HT5qCtDwYe780wMy9IOFNg29/G0vLK6tp6ZaO6ubW9s2vu7XdUnEpC2yTmsewFWFHOBG0DA057iaQ4CjjtBuOrwu/eU6lYLO5gklAvwkPBQkYwaMk3D90Iw4hgnl3nfuYCfYAMJGYiz32zZtftKaxF4pSkhkq0fPPLHcQkjagAwrFSfcdOwMuwBEY4zatuqmiCyRgPaV9TgSOqvGz6Q26daGVghbHUJcCaqr8nMhwpNYkC3VlcrOa9QvzP66cQXnoZE0kKVJDZojDlFsRWEYg1YJIS4BNNMJFM32qREZaYgI6tqkNw5l9eJJ2zunNeb9w2as1GGUcFHaFjdIocdIGa6Aa1UBsR9Iie0St6M56MF+Pd+Ji1LhnlzAH6A+PzB3eQmKo=</latexit>Dtrain
Step 2: Training with Regularization and Sample Filtering on         t 
<latexit sha1_base64="lw/CyxS9BFwGblz0kbCSyjdq/E4=">AAACAXicbVBNS8NAEN34WetX1YvgJVgETyWRoh4LevBYwX5AG8JmO22XbjZhdyKWEC/+FS8eFPHqv/Dmv3Hb5qCtDwYe780wMy+IBdfoON/W0vLK6tp6YaO4ubW9s1va22/qKFEMGiwSkWoHVIPgEhrIUUA7VkDDQEArGF1N/NY9KM0jeYfjGLyQDiTvc0bRSH7psBtSHDIq0uvMT7sID5gOQGaZXyo7FWcKe5G4OSmTHHW/9NXtRSwJQSITVOuO68TopVQhZwKyYjfREFM2ogPoGCppCNpLpx9k9olRenY/UqYk2lP190RKQ63HYWA6J/fqeW8i/ud1EuxfeimXcYIg2WxRPxE2RvYkDrvHFTAUY0MoU9zcarMhVZShCa1oQnDnX14kzbOKe16p3lbLtWoeR4EckWNySlxyQWrkhtRJgzDySJ7JK3mznqwX6936mLUuWfnMAfkD6/MHvsiXsg==</latexit>DgenGenerate__________________________________________________<latexit sha1_base64="fFHmQiaNPG9ZdcSBIOu1Eg7yAtE=">AAACA3icbVBNS8NAEN34WetX1JtegkXwVBIp6rGgB48V7Ac0IWy2m3bpZhN2J2IJAS/+FS8eFPHqn/Dmv3HT5qCtDwYe780wMy9IOFNg29/G0vLK6tp6ZaO6ubW9s2vu7XdUnEpC2yTmsewFWFHOBG0DA057iaQ4CjjtBuOrwu/eU6lYLO5gklAvwkPBQkYwaMk3D90Iw4hgnl3nfuYCfYAMJGYiz32zZtftKaxF4pSkhkq0fPPLHcQkjagAwrFSfcdOwMuwBEY4zatuqmiCyRgPaV9TgSOqvGz6Q26daGVghbHUJcCaqr8nMhwpNYkC3VlcrOa9QvzP66cQXnoZE0kKVJDZojDlFsRWEYg1YJIS4BNNMJFM32qREZaYgI6tqkNw5l9eJJ2zunNeb9w2as1GGUcFHaFjdIocdIGa6Aa1UBsR9Iie0St6M56MF+Pd+Ji1LhnlzAH6A+PzB3eQmKo=</latexit>Dtrain
<latexit sha1_base64="6vsCgg+5BhbNIvIlDnWSW0kO11o=">AAACCnicdVA9TxtBEN2D8BGHDwNlmg0WEg3WnTnZ0CGloaAgUgxIPsuaW4/Nir290+4cYJ2upuGv0KQAobT5Benyb7IHjgSIPGmkp/dmNDMvzpS05Pt/vJnZD3PzC4sfa5+WlldW62vrJzbNjcCuSFVqzmKwqKTGLklSeJYZhCRWeBpffK3800s0Vqb6O00y7Ccw1nIkBZCTBvUvO5GGWEGUAJ0LUMVROSgiwmsqrnbGqMtyUG/4zf29ditsc7/p+52gFVSk1Ql3Qx44pUKDTXE8qP+OhqnIE9QkFFjbC/yM+gUYkkJhWYtyixmICxhjz1ENCdp+8fRKybecMuSj1LjSxJ/UlxMFJNZOkth1Vhfbt14lvuf1chrt9Qups5xQi+dFo1xxSnmVCx9Kg4LUxBEQRrpbuTgHA4JcejUXwr9P+f/JSasZtJvht7BxEE7jWGSf2SbbZgHrsAN2yI5Zlwl2w+7YPXvwbr0f3qP387l1xpvObLBX8H79BaQjm4E=</latexit> rLw-gen<latexit sha1_base64="xAcT66ehS1iWGf3ApJexvY98U9o=">AAAB6nicdVDLSsNAFL2pr1pfVZduBovgKiQ2temu4MZlRfuANpTJdNIOTiZhZqKU0k9w40IRt36RO//G6UNQ0QMXDufcy733hClnSjvOh5VbWV1b38hvFra2d3b3ivsHLZVkktAmSXgiOyFWlDNBm5ppTjuppDgOOW2Htxczv31HpWKJuNHjlAYxHgoWMYK1ka7v+26/WHJsz3cqvoMcu1L2y9WyIbWaX/GryLWdOUqwRKNffO8NEpLFVGjCsVJd10l1MMFSM8LptNDLFE0xucVD2jVU4JiqYDI/dYpOjDJAUSJNCY3m6veJCY6VGseh6YyxHqnf3kz8y+tmOvKDCRNppqkgi0VRxpFO0OxvNGCSEs3HhmAimbkVkRGWmGiTTsGE8PUp+p+0zmz33PauvFLdW8aRhyM4hlNwoQp1uIQGNIHAEB7gCZ4tbj1aL9brojVnLWcO4Qest0+Y8I3+</latexit>w1<latexit sha1_base64="TJS9ta5i+J89d9OZD3t2Q9ZNcEQ=">AAAB6nicdVDLSsNAFJ3UV62vqks3g0VwFSZpsOmu4MZlRfuANpTJdNIOnUzCzEQpoZ/gxoUibv0id/6N04egogcuHM65l3vvCVPOlEbowyqsrW9sbhW3Szu7e/sH5cOjtkoySWiLJDyR3RArypmgLc00p91UUhyHnHbCyeXc79xRqVgibvU0pUGMR4JFjGBtpJv7gTsoV5DtVmsIORDZVcep+b4h9brvVj3o2GiBClihOSi/94cJyWIqNOFYqZ6DUh3kWGpGOJ2V+pmiKSYTPKI9QwWOqQryxakzeGaUIYwSaUpouFC/T+Q4Vmoah6Yzxnqsfntz8S+vl+nID3Im0kxTQZaLooxDncD533DIJCWaTw3BRDJzKyRjLDHRJp2SCeHrU/g/abu2c2F7116l4a3iKIITcArOgQNqoAGuQBO0AAEj8ACewLPFrUfrxXpdthas1cwx+AHr7RN3p43n</latexit>w2<latexit sha1_base64="29Yme9NaoosYr+vZHd59F+ioX0I=">AAAB6nicdVDLSgNBEOz1GeMr6tHLYBA8hZ0Q8rgFvHiMaB6QLGF2MpsMmZ1dZmaVsOQTvHhQxKtf5M2/cTaJoKIFDUVVN91dfiy4Nq774aytb2xubed28rt7+weHhaPjjo4SRVmbRiJSPZ9oJrhkbcONYL1YMRL6gnX96WXmd++Y0jySt2YWMy8kY8kDTomx0s39UA4LRbfkui7GGGUE16quJY1GvYzrCGeWRRFWaA0L74NRRJOQSUMF0bqP3dh4KVGGU8Hm+UGiWUzolIxZ31JJQqa9dHHqHJ1bZYSCSNmSBi3U7xMpCbWehb7tDImZ6N9eJv7l9RMT1L2UyzgxTNLloiARyEQo+xuNuGLUiJklhCpub0V0QhShxqaTtyF8fYr+J51yCVdLletKsVlZxZGDUziDC8BQgyZcQQvaQGEMD/AEz45wHp0X53XZuuasZk7gB5y3T7JMjg0=</latexit>wn
<latexit sha1_base64="9Lu70nkETqyQ5kPT6AAtpTCsjno=">AAACCXicdVA9SwNBEN3zM8avqKXNYhBsDHchxKQL2FhYKJgYyIUwt9no4t7esTsnhuNaG/+KjYUitv4DO/+NezGCij4YeLw3w8y8IJbCoOu+OzOzc/MLi4Wl4vLK6tp6aWOzY6JEM95mkYx0NwDDpVC8jQIl78aaQxhIfh5cHeb++TXXRkTqDMcx74dwocRIMEArDUp031cQSPBDwEsGMj3OBqmP/AbToTAsywalsltxLep1mhOv4XqWNJuNarVJvYnlumUyxcmg9OYPI5aEXCGTYEzPc2Psp6BRMMmzop8YHgO7ggves1RByE0/nXyS0V2rDOko0rYU0on6fSKF0JhxGNjO/GDz28vFv7xegqNGPxUqTpAr9rlolEiKEc1joUOhOUM5tgSYFvZWyi5BA0MbXtGG8PUp/Z90qhWvXqmd1sqt2jSOAtkmO2SPeOSAtMgROSFtwsgtuSeP5Mm5cx6cZ+fls3XGmc5skR9wXj8AEJqbNw==</latexit> rLdisc
<latexit sha1_base64="lNodwlgG4b3p0Rn+x4xzF5/zycA=">AAACA3icbVA9SwNBEN3zM8avqJ02h0GwMdxJUMuAjYVFBPMBSTj2NnPJkr29Y3dODceBjX/FxkIRW/+Enf/GzUehiQ8GHu/NMDPPjwXX6Djf1sLi0vLKam4tv76xubVd2Nmt6yhRDGosEpFq+lSD4BJqyFFAM1ZAQ19Awx9cjvzGHSjNI3mLwxg6Ie1JHnBG0UheYb8dUuwzKtLrzEvbCA+Y3p/0QGaZVyg6JWcMe564U1IkU1S9wle7G7EkBIlMUK1brhNjJ6UKOROQ5duJhpiyAe1By1BJQ9CddPxDZh8ZpWsHkTIl0R6rvydSGmo9DH3TObpYz3oj8T+vlWBw0Um5jBMEySaLgkTYGNmjQOwuV8BQDA2hTHFzq836VFGGJra8CcGdfXme1E9L7lmpfFMuVsrTOHLkgBySY+KSc1IhV6RKaoSRR/JMXsmb9WS9WO/Wx6R1wZrO7JE/sD5/ACH1mHI=</latexit>Lw-gen
<latexit sha1_base64="Q9Q34t+mXrwPmz/Q6rrZaQMNuNg=">AAACA3icbVA9SwNBEN3zM8avUzttDoNgFe5CUMuAjYVFBPMByRn2NpNkyd7esTsnhuPAxr9iY6GIrX/Czn/j5qPQxAcDj/dmmJkXxIJrdN1va2l5ZXVtPbeR39za3tm19/brOkoUgxqLRKSaAdUguIQachTQjBXQMBDQCIaXY79xD0rzSN7iKAY/pH3Je5xRNFLHPmyHFAeMivQ666RthAdM+yCz7K7UsQtu0Z3AWSTejBTIDNWO/dXuRiwJQSITVOuW58bop1QhZwKyfDvREFM2pH1oGSppCNpPJz9kzolRuk4vUqYkOhP190RKQ61HYWA6xxfreW8s/ue1Euxd+CmXcYIg2XRRLxEORs44EKfLFTAUI0MoU9zc6rABVZShiS1vQvDmX14k9VLROyuWb8qFSnkWR44ckWNySjxyTirkilRJjTDySJ7JK3mznqwX6936mLYuWbOZA/IH1ucPBMCYXg==</latexit>L2gen
<latexit sha1_base64="aX5kfSe/0FXQyp7YHY3P9HErwZk=">AAACA3icbVA9SwNBEN2LXzF+Re20OQyCVbiToJYBGwuLCOYDkvPY20ySJXt7x+6cGI4DG/+KjYUitv4JO/+Nm49CEx8MPN6bYWZeEAuu0XG+rdzS8srqWn69sLG5tb1T3N1r6ChRDOosEpFqBVSD4BLqyFFAK1ZAw0BAMxhejv3mPSjNI3mLoxi8kPYl73FG0Uh+8aATUhwwKtLrzE87CA+Y9kFm2Z3rF0tO2ZnAXiTujJTIDDW/+NXpRiwJQSITVOu268TopVQhZwKyQifREFM2pH1oGyppCNpLJz9k9rFRunYvUqYk2hP190RKQ61HYWA6xxfreW8s/ue1E+xdeCmXcYIg2XRRLxE2RvY4ELvLFTAUI0MoU9zcarMBVZShia1gQnDnX14kjdOye1au3FRK1cosjjw5JEfkhLjknFTJFamROmHkkTyTV/JmPVkv1rv1MW3NWbOZffIH1ucPAzyYXQ==</latexit>L1gen<latexit sha1_base64="lshZGe8eF77w4ToFVeJDMDi7jvI=">AAACA3icbVA9SwNBEN2LXzF+Re20OQyCVbiToJYBGwuLCOYDkjPsbSbJkr29Y3dODMeBjX/FxkIRW/+Enf/GvSSFJj4YeLw3w8w8PxJco+N8W7ml5ZXVtfx6YWNza3unuLvX0GGsGNRZKELV8qkGwSXUkaOAVqSABr6Apj+6zPzmPSjNQ3mL4wi8gA4k73NG0Ujd4kEnoDhkVCTXaTfpIDxgMgCZpnfGLDllZwJ7kbgzUiIz1LrFr04vZHEAEpmgWrddJ0IvoQo5E5AWOrGGiLIRHUDbUEkD0F4y+SG1j43Ss/uhMiXRnqi/JxIaaD0OfNOZXaznvUz8z2vH2L/wEi6jGEGy6aJ+LGwM7SwQu8cVMBRjQyhT3NxqsyFVlKGJrWBCcOdfXiSN07J7Vq7cVErVyiyOPDkkR+SEuOScVMkVqZE6YeSRPJNX8mY9WS/Wu/Uxbc1Zs5l98gfW5w9fsJia</latexit>Lngen
Figure 1: Overview of FewGen. A generator PLM is Ô¨Årst tuned on the few-shot samples with our proposed meta-weighted
training objective and then used to synthesize new training samples. A classiÔ¨Åcation PLM is Ô¨Ånally trained on both the
few-shot and the generated samples.
0 100 200 300 400
Training Steps23Lgen
(a)Lgenduring training
0 100 200 300 400
Training Steps012Ldisc (b)Ldiscduring training
Figure 2: (On MNLI) Training the generator via Lgendoes
not automatically decrease Ldisc.
via a discriminative loss Ldisc:
Ldisc(p) = 1
nnX
j=1Lj
disc(p);
Lj
disc(p) =ppl(xjjx<j)
PL
l0=1ppl0(xjjx<j):(2)
Although one can directly combine LdiscwithLgento train
Gpto enforce distinction across different labels, doing so
will result in two undesirable consequences: (1) A hyper-
parameter needs to be introduced to balance the weights
of the two losses, whose optimal value is likely to vary by
task; and (2) directly updating generator parameters with the
discriminative loss Ldiscwill worsen the language modeling
quality of the generator, making it prone to generating less
Ô¨Çuent and coherent texts after training.
Weighted Maximum Likelihood Generator Tuning.
To preserve the generative learning of Gpwhile emphasiz-
ing label-discriminative tokens, we assume each token is
associated with a weight in the maximum likelihood loss. In-
tuitively, when our goal is to generate distinctive texts across
different labels as training samples, not all tokens should
contribute equally to generator training. For example, for
sentiment classiÔ¨Åcation tasks, one would expect ‚Äúgood/bad‚Äùto be more label-discriminative than ‚Äúthe movie‚Äù, and the
former should be paid more attention to during training. It is
thus natural to generalize Lgenin Eq. (1)toLw-gen as follows
by assuming a weight wjis given for each token.
min
plLw-gen;Lw-gen(pl;w) = nX
j=1wjLj
gen(pl);(3)
Lj
gen(pl) = logppl(xjjx<j):
Note that inLw-gen,wis assumed to be the hyperparameter
under whichplis optimized. When wjis the same for
every token, Eq. (3)will be equivalent to Eq. (1). While it
is possible to manually design weighting rules for setting
wto promote label-discriminative learning, they will likely
necessitate task-speciÔ¨Åc knowledge and nontrivial tuning.
To facilitate the automatic learning of these weights w, we
propose to parameterize them as learnable hyperparameters
using the idea of meta-learning.
Meta Weight Learning Setup. To automatically learn
token weights as hyperparameters, we formulate a bi-level
optimization problem using the idea of meta-learning. The
inner objectiveLw-gen optimizes the generator parameters
pgiven the token weights wj:
Lw-gen(p;!) = nX
j=1wj(!)Lj
gen(p);

p(!) = argmin
pLw-gen;
where the token weights wj(!)are parameterized and
learned via a weighting network g!(details about its im-
plementation are in Appendix A). The weighting network
4

--- PAGE 5 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Algorithm 1 Meta-Weighted Generator Tuning.
Input:Dtrain: Few-shot training set.
Parameter: T: Number of training steps.
Output:p: PreÔ¨Åx parameters for all labels.
Initialize(0)
p(with task-descriptive prompts) and !(0)
fort2[0;1;:::;T 1]do
B Sample a minibatch from Dtrain
^(t)
p 
!(t)
 Take one gradient step to descend
Lw-gen
(t)
p;!(t)
onB
!(t+1) Take one gradient step to descend
Ldisc
^(t)
p 
!(t)
onB
(t+1)
p Take one gradient step to descend
Lw-gen
(t)
p;!(t+1)
onB
end
returnp=(T)
p
parameters!are trained with an outer objective Ldisc:
Ldisc(
p(!)) = 1
nnX
j=1Lj
disc(
p(!));
!= argmin
!Ldisc:(4)
Under the above bi-level optimization formulation, the dis-
criminative lossLdiscis not used to directly update generator
parameters, but to automatically learn token weights that
are used as hyperparameters by the inner objective Lw-gen.
As the token weights are trained to minimize Ldisc, the gen-
erator focuses more on label-discriminative tokens.
We use an online optimization strategy (Shu et al., 2019)
instead of nested optimization loops to optimize !and
p
for training efÔ¨Åciency. It also guarantees convergence to the
critical points of both Lw-gen andLdiscunder mild conditions.
We initialize the preÔ¨Åx parameters pusing natural language
prompts, and the details can be found in Appendix B. The
overall training procedure is shown in Algorithm 1.
Analysis of Meta Weight Learning. To study how the
token weights are learned during training, we analyze the
gradients of the weighting network parameters !which are
optimized via Eq. (4) (detailed derivation in Appendix C):
 @Ldisc
^(t)
p(!)
@!
!=!(t)/nX
j=1dj@wj(!)
@!
!=!(t);
dj=@Ldisc
^p
@^p^p=^(t)
p@Lj
gen(p)
@p>
p=(t)
p:Algorithm 2 ClassiÔ¨Åer Ô¨Åne-tuning on DtrainandDgen.
Input:Dtrain: Few-shot training set; Dgen: Synthesized
training set.
Parameter: T: Number of training steps.
Output:: Trained classiÔ¨Åcation model parameters.
(0) Train onDtrainwith standard supervised learning
z 0// Initialize ensembled prediction
fort2[0;1;:::;T 1]do
B Sample a minibatch from Dgen
(t+1) Take one gradient step to descend Lclassin
Eq. (5) onB
z Accumulate the current model prediction
UpdateDgento exclude noisy samples based on z
end
return=(T)
It can be seen that the gradient descent direction of !is de-
termined by a sum of token weight gradient ascent directions
(i.e.,@wj(!)
@!) weighted by a scalar dj, wheredjcharacter-
izes the similarity between the gradient of the discriminative
objective and the gradient of the generative objective on the
jth token. Therefore, the meta weights will be higher on
those tokens where optimizing their generative objective is
more beneÔ¨Åcial for minimizing the discriminative objective,
so that label-distinctive information is better emphasized.
3.3. ClassiÔ¨Åer Fine-Tuning
With the trained generator Gp, we can synthesize novel
training samplesDgenthat augmentDtrainfor Ô¨Åne-tuning a
classiÔ¨Åcation PLM C. The major challenge to effectively
leverageDgenis that the label noise ( i.e., some generated
samples may not accurately pertain to the corresponding
label) may deteriorate model performance if standard su-
pervised learning is directly used. We propose a simple
noise-robust training procedure to improve the generaliza-
tion and stability of training: First Ô¨Åne-tune ConDtrain
with standard supervised training, and then continue Ô¨Åne-
tuning it onDgenby applying label smoothing (Szegedy
et al., 2016) and temporal ensembling (Laine & Aila, 2017)
as regularization, following (Meng et al., 2022a). SpeciÔ¨Å-
cally, given a training sample (~x;~y)2D gen, we minimize
the following classiÔ¨Åcation loss:
Lclass() = LX
l=1qllog(p(~x)l) LX
l=1zllogp(~x)l
zl;
(5)
whereql= 1(l= ~y)(1 )+=Landis the label smooth-
ing weight; p(~x)is the model prediction on ~x;is a
regularization weight for temporal ensembling; and zis the
accumulated moving-average model predictions. We also
use the ensembled prediction zto Ô¨Ålter out noisy synthe-
sized samples: We only include those samples for training
5

--- PAGE 6 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
where zstrongly agrees with the label ~y(i.e.,z~y>where
>0is a threshold parameter). In Eq. (5), the Ô¨Årst classiÔ¨Å-
cation term is the cross-entropy loss with smoothed labels;
the second regularization term corresponds to temporal en-
sembling, which requires the current model prediction to
be close to its past accumulated predictions. This not only
neutralizes the Ô¨Çuctuation in model predictions for better
training stability when label noise is present (Nguyen et al.,
2020) but also helps prevent catastrophic forgetting (Kirk-
patrick et al., 2017) of the information learned previously
from the few-shot training set Dtrain. Please refer to Ap-
pendix B for details about the temporal ensembling imple-
mentation. The overall procedure of classiÔ¨Åer Ô¨Åne-tuning is
summarized in Algorithm 2.
4. Experimental Setup
Downstream Tasks and Metrics. We conduct evaluation
on all tasks of the GLUE benchmark (Wang et al., 2018)
(more details in Appendix D) except STS-B which is a re-
gression task. We follow the same data split and evaluation
protocol as (Gao et al., 2021): Both DtrainandDdevcon-
tain16samples per label and are sampled from the original
training set with 5different random seeds. The original de-
velopment sets are used for testing. For all reported results,
we include the average and standard deviation over the 5
differentDtrain/Ddevsplits. F1 score is used as the metric
for QQP and MRPC, Matthews correlation for CoLA, and
accuracy for the remaining tasks.
Models and Training Settings. FewGen is a training data
generation method and can be used with any Ô¨Åne-tuning
method on any classiÔ¨Åcation model. We use moderate-sized
PLMs to ensure our results are reproducible on typical re-
search hardware: CTRL ( 1:6B parameters) (Keskar et al.,
2019) as the generator Gand RoBERTa Large (356M pa-
rameters) (Liu et al., 2019) as the classiÔ¨Åer C. We use
preÔ¨Åx-tuning for training Gand prompt-based Ô¨Åne-tuning
for trainingC. For simplicity, we use the most basic man-
ual prompt version of LM-BFF (Gao et al., 2021). The
only exception is CoLA for which we use the standard Ô¨Åne-
tuning since the input data might be out of the distribution
ofC(Gao et al., 2021). The hyperparameter tuning is
performed onDdev. More details are in Appendix B.
Compared Methods. No-augmentation baselines include
zero-shot prompting, standard Ô¨Åne-tuning, in-context learn-
ing, and the following strong few-shot learning methods:
Four versions of LM-BFF (Gao et al., 2021), P-Tuning (Liu
et al., 2021b) and DART (Zhang et al., 2022). We also com-
pare with data augmentation methods for few-shot learn-
ing: MixText (Chen et al., 2020), using back translation
systems to generate paraphrases (UDA-style (Xie et al.,
2020) augmentation), a few-shot demonstration methodGPT3Mix (Yoo et al., 2021), and standard Ô¨Åne-tuning of
generator on the few-shot samples with prompts. For fair
comparisons, all augmentation methods use LM-BFF (Man.)
to Ô¨Åne-tune a RoBERTa Large classiÔ¨Åer. We also include the
results of fully-supervised Ô¨Åne-tuning. More details about
augmentation baselines are in Appendix E.
5. Evaluation
5.1. Main Results
We present the results of FewGen and baselines in Table 1.
FewGen achieves overall better performance across the
GLUE tasks, on average 5+points higher than the pre-
vious best few-shot method without augmentation, and 3+
points better than GPT3Mix2(Yoo et al., 2021) which uses
a100times larger generator model ( 175B) than FewGen.
Comparison with Back Translation. Using back trans-
lation to paraphrase the few-shot samples does not improve
the results‚Äîthis is probably because it does not produce
samples that are sufÔ¨Åciently different from the few-shot
training set. The success of UDA (Xie et al., 2020) is
grounded in the augmentations from abundant unlabeled
data that improve the classiÔ¨Åer generalization. However,
under the strict few-shot learning setup, there is no access
to additional task-speciÔ¨Åc unlabeled data (Gao et al., 2021),
making it challenging for paraphrase-based methods to cre-
ate sufÔ¨Åciently diverse training samples only based on the
small few-shot set. The new training samples produced by
our FewGen method are not limited to the paraphrases of
the few-shot samples, as the generator is trained via preÔ¨Åx-
tuning to preserve the PLM‚Äôs pretraining knowledge, based
on which novel training samples can be synthesized.
Comparison with GPT3Mix. The gigantic size of GPT3
makes it challenging for tuning on few-shot samples. There-
fore, GPT3Mix (Yoo et al., 2021) uses few-shot samples
as demonstrations for creating the augmentations. Such
an approach suffers from two limitations: (1) Without any
parameter update to the PLM, its learning ability is not fully
leveraged to adapt to the few-shot training set. (2) The
PLM can only use a small subset of the few-shot samples
at a time for creating each augmentation, as the number
of demonstrations received by the model is bounded by its
maximum input sequence length. This makes the quality of
the created augmentations more sensitive to the randomly
drawn training samples. Our FewGen method, on the other
hand, can use the entire few-shot set for tuning the PLM
and achieves overall even better classiÔ¨Åcation results with
a much smaller PLM ( <1%the size of the GPT3 model)
2The original GPT3Mix paper uses accuracy as the metric
instead of Matthews correlation for CoLA; our reimplemented
GPT3Mix achieves 79:40:6on CoLA if measured by accuracy.
6

--- PAGE 7 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Table 1: Results on seven classiÔ¨Åcation tasks of the GLUE benchmark. We report average and standard deviation (as
subscripts) performance over 5differentDtrain/Ddevsplits deÔ¨Åned in (Gao et al., 2021).y: Results from (Gao et al., 2021).z:
Results from (Zhang et al., 2022). Methods that use additional models apart from the Ô¨Ånal classiÔ¨Åcation model are marked.
MethodMNLI-(m/mm) QQP QNLI SST-2 CoLA RTE MRPC A VG
(Acc.) (F1) (Acc.) (Acc.) (Matt.) (Acc.) (F1)
Methods without Augmentation : Few-shot samples are directly used for classiÔ¨Åer tuning or as demonstrations for inference
Promptingy50:8/51:7 49:7 50:8 83:6 2:0 51:3 61:9 50:1
Fine-Tuningy45:86:4/47:86:860:74:360:26:581:43:833:914:354:43:976:62:559:1
In-Contexty52:00:7/53:40:636:15:253:80:484:81:3 1:52:460:41:445:76:047:4
LM-BFF (Man.)y68:32:3/70:51:965:55:364:54:292:70:99:37:3 69:13:674:55:363:6
+ demonstrationy70:71:3/72:01:269:81:869:21:992:60:518:78:868:72:377:82:066:9
LM-BFF (Auto)y(w.2:9B T5) 68:32:5/70:12:667:03:068:37:492:31:014:014:1 73.92:276:22:365:8
+ demonstrationy(w.2:9B T5) 70:03:6/72:03:167:75:868:55:493:00:621:815:971:15:378:13:467:3
P-Tuningz61:52:1/  65:63:064:32:892:20:4    74:57:6 
DARTz67:52:6/  67:83:266:73:793:50:5    78:34:5 
Methods with Augmentation : Few-shot samples are used for creating synthesized samples and for classiÔ¨Åer tuning
MixText 65:12:6/66:22:860:63:968:45:189:12:312:89:266:54:164:67:661:1
Back Translation (w. trained Marian) 66:94:6/68:33:859:84:667:84:991:11:97:53:7 62:45:368:011:260:6
GPT3Mix (w. 175B GPT3) 61:53:2/62:62:270:41:969:20:393.60:6 48.91:970:410:069:912:469:2
Generator Fine-Tuning (w. 1:6B CTRL) 68:95:1/70:85:360:48:770:94:191:21:218:810:066:14:460:815:4 62.6
FewGen (w. 1:6B CTRL) 75.71:6/77.11:0 71.51:776.34:493:10:840:07:571:22:4 81.12:5 72.8
Fully Supervised Fine-Tuningy89.8/89.5 81.7 93.3 95.0 62.6 80.9 91.4 84.9
Table 2: Ablation studies by removing (  ) or switching (w.) one component of FewGen.
Method MNLI-(m/mm) QQP QNLI SST-2 CoLA RTE MRPC
FewGen 75:71:6/77:11:071:51:776:34:493:10:840:07:571:22:481:12:5
w.Lgen 74:91:0/76:21:070:71:975:04:892:50:737:88:269:52:280:83:0
w.Lgen+Ldisc 74:61:6/76:01:568:82:176:14:392:40:841:29:070:12:279:62:4
 label smooth 75:01:3/76:21:071:11:876:53:592:70:739:38:669:41:981:32:8
 temporal ensemble 72:22:5/74:02:265:82:175:12:792:11:733:94:466:62:480:43:2
w. Ô¨Åne-tune onDtrain[D gen 68:91:8/70:61:964:31:571:14:191:81:334:03:259:61:080:43:5
which can be deployed much more easily in practice.
5.2. Ablation Studies
The overall performance gain brought by FewGen over a
no-augmentation counterpart can be seen by comparing Few-
Gen with LM-BFF (Man.) which uses the same classiÔ¨Åer
and Ô¨Åne-tuning method on Dtrainonly. We further analyze
the effectiveness of each important component in FewGen
via the following ablations: (1) Using the standard Lgenin
Eq.(1)instead of our proposed Lw-gen in Eq. (3)for genera-
tor tuning (w.Lgen); (2) using the directly combined Lgen
andLdiscfor generator tuning (w. Lgen+Ldisc); (3) without
applying label smoothing in Eq. (5)( label smooth); (4)
without applying temporal ensembling in Eq. (5)( tem-
poral ensemble); (5) directly Ô¨Åne-tuning the classiÔ¨Åcation
model on the combination of DgenandDtrain(w. Ô¨Åne-tune
onDtrain[D gen)3. As shown in Table 2, (1) & (2) using the
standard maximum likelihood loss or the combination of
3For this ablation, we upsample Dtrainby100so that its size
is comparable with Dgen; otherwise, the result is much worse.
0 100 200 300 400
Training Steps012LdiscLgen
Lgen+Ldisc
Lw-gen(a)Ldiscduring training
0 100 200 300 400
Training Steps2.22.42.62.83.0Dev Set LossLgen
Lgen+Ldisc
Lw-gen (b) Dev set loss during training
Figure 3: With different generator tuning objectives, (a)
Ldiscand (b) language modeling loss on the dev set.
generative and discriminative losses to tune the generator
both yield lower-quality training data and lead to degraded
classiÔ¨Åcation performance; (3) & (4) not applying regular-
ization techniques for Ô¨Åne-tuning the classiÔ¨Åer is more prone
to label noise in the generated samples; (5) Ô¨Åne-tuning the
classiÔ¨Åer on the combination of DgenandDtrainsigniÔ¨Åcantly
underperforms our two-step Ô¨Åne-tuning method.
5.3. Analyses of Loss Functions for Generator Tuning
As shown in Table 2, the choice of generator loss has a
signiÔ¨Åcant impact on the synthesized data quality and thus
7

--- PAGE 8 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Table 3: Quantitative evaluation of generator training objectives. We use two metrics: Generated data accuracy (Acc; higher
is better) and generator‚Äôs perplexity on the test set (PPL; lower is better). The results are averaged over 5Dtrain/Ddevsplits.
ObjectiveMNLI QQP QNLI SST-2 CoLA RTE MRPC
Acc. (") PPL (#) Acc. (") PPL (#) Acc. (") PPL (#) Acc. (") PPL (#) Acc. (") PPL (#) Acc. (") PPL (#) Acc. (") PPL (#)
Lgen 69:4 13:1 87:5 10:9 57:0 23:4 91:5 43:8 59:1 85:6 82:9 9:3 87:6 5:0
Lgen+Ldisc 70:2 13:5 87:3 11:2 57:2 24:8 92:0 49:5 59:2 87:0 82:8 9:6 86:3 5:3
Lw-gen 72.3 11.9 89.5 10.7 60.1 23.2 93.2 43.5 60.7 83.8 83.4 8.9 90.5 4.9
Table 4: (For MNLI) Examples of generated second sequence (hypothesis) by generators tuned with three different objectives
conditioned on a given Ô¨Årst sequence (premise) ‚Äú In 2009, hair samples from 1,137 Taiji residents were tested for mercury by
the National Institute for Minamata Disease (NIMD) ‚Äù. The true label of the generated sequence is marked at the end of the
sequence (if the generated sequence correctly pertains to the target label, it is marked in blue; otherwise, it is in red).
Objective Label Generated Second Sequence
Lgenentailment The NIMD found that hair samples from 1,137 Taiji residents had mercury in their hair. (neutral)
neutralThe NIMD found that there was no evidence of a link between exposure to high levels
of mercury and thyroid cancer. (neutral)
contradiction There was no evidence of mercury in hair samples from Taiji. (neutral)
Lgen+Ldiscentailment The number of hairs in a sample is equal to the number of people who lived in Taiji. (neutral)
neutral The results showed that there was no signiÔ¨Åcant difference in levels of mercury. (neutral)
contradiction Hair samples from 1,137 Taiji residents were not tested. (contradiction)
Lw-genentailment The NIMD tested hair samples from 1,137 residents of Taiji. (entailment)
neutralThere was no signiÔ¨Åcant difference in levels between people who lived near a nickel mine
and those living far away. (neutral)
contradiction The NIMD did not test any of the hair samples. (contradiction)
the Ô¨Ånal model performance. We conduct further analyses
to compare the training processes of the generator under the
following three loss functions and the resulting generated
samples: (1)Lgenwhich is the standard language modeling
loss; (2)Lgen+Ldiscwhich directly adds the discriminative
loss to generator training; and (3) Lw-gen which is our meta-
weighted objective. Fig. 3 shows the discriminative loss
Ldiscand the standard language modeling loss on the held-
out development set throughout training. Although using
Lgen+Ldischelps reduce the discriminative loss, it comes at
the cost of hindering language modeling‚Äîthe generator loss
on the development set is high. Using our meta-weighted
objectiveLw-gen not only encourages discriminativeness but
also mitigates overÔ¨Åtting, yielding the lowest validation set
loss. This is likely because the model receives contrastive in-
formation from other labels which facilitates more accurate
modeling of the texts with the target label.
Quantitative Analyses. Apart from the Ô¨Ånal classiÔ¨Åcation
model performance which indirectly reÔ¨Çects the synthetic
data quality, we additionally conduct more direct quantita-
tive analyses of different generator training objectives. We
use two metrics: (1) The accuracy of generated texts, which
is judged by fully-supervised RoBERTa Large models Ô¨Åne-
tuned on the original training sets of each task. We choose
to adopt such an automatic evaluation instead of human eval-
uation because it is efÔ¨Åcient and reliable‚Äîfully-supervised
RoBERTa Large models have comparable or better accuracythan human baselines according to the GLUE benchmark4.
(2) The generator‚Äôs perplexity on the test sets, which re-
Ô¨Çects how well the generator models the task distribution.
As shown in Table 3, using Lw-gen for generator training
consistently outperforms using LgenorLgen+Ldisc, both in
generated text accuracy and in language modeling ability.
ComparingLw-gen withLgen, the meta weights automati-
cally learned emphasize discriminative tokens in generator
training and help the generator capture subtle semantic dif-
ferences across different labels, resulting in better language
modeling quality and more distinctive synthetic data.
ComparingLw-gen withLgen+Ldisc, the generator train-
ing objective is not directly impacted by the discriminative
objective, thus avoiding the gradient interference issue in
multi-task learning (Standley et al., 2019)‚Äîthe gradient for
optimizing the generative probability p(xjyl)will be inter-
fered by the gradient optimizing the discriminative probabil-
ityp(yljx)ifLgen+Ldiscis used. Therefore, using Lw-gen
results in better language modeling quality and more Ô¨Çuent
and coherent generation results.
Qualitative Analyses . We showcase concrete generation
results for the three labels of MNLI by models trained with
the three different loss functions in Table 4. The model
trained withLgenproduces Ô¨Çuent and coherent sentences,
but the generated sentences do not accurately pertain to
4https://gluebenchmark.com/leaderboard
8

--- PAGE 9 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Sentence 2: Prophecies based on coincidences are widely known to be weak and unreliable.Sentence 1: But prophecy is always strongest when based on coincidence--that is a prime rule.Label: ContradictionSentence 1: But Rodgers did tell Lewis that he despises Amelio because Amelio supported ddddddClinton, so it is Rodgers' mistake, not our author's, that we are correcting. <latexit sha1_base64="G62TDpOndLoAQU4hgeklWgMhqKo=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRsVB9Wa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJalY3A</latexit>0.03<latexit sha1_base64="RWP8vMvAS+rXKlomA2BKUaCFkpQ=">AAAB7HicdVDLSsNAFJ3UV62vqks3g0VwIWHShprsCm5cVjC20IYymU7aoZNJmJkIJfQb3LhQxK0f5M6/cfoQVPTAhcM593LvPVHGmdIIfViltfWNza3ydmVnd2//oHp4dKfSXBIakJSnshthRTkTNNBMc9rNJMVJxGknmlzN/c49lYql4lZPMxomeCRYzAjWRgqQjepwUK0h2/c8H3kQ2S5Crucb0vB9v9mAjo0WqIEV2oPqe3+YkjyhQhOOleo5KNNhgaVmhNNZpZ8rmmEywSPaM1TghKqwWBw7g2dGGcI4laaEhgv1+0SBE6WmSWQ6E6zH6rc3F//yermOvbBgIss1FWS5KM451Cmcfw6HTFKi+dQQTCQzt0IyxhITbfKpmBC+PoX/k7u67TRt98attS5WcZTBCTgF58ABl6AFrkEbBIAABh7AE3i2hPVovVivy9aStZo5Bj9gvX0CrzuN6Q==</latexit>0.02<latexit sha1_base64="mPcf2Yiysw9OpwTvtDT9gwywIFs=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRsxxlWa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJZEo2/</latexit>0.11<latexit sha1_base64="u5zgvj4rR8dhza7sssVGo33QeSU=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRs1BhWa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJfIY3D</latexit>0.06<latexit sha1_base64="32WnJop1if5+32S1KsD3eCW2EQc=">AAAB63icdVDLSsNAFJ34rPVVdelmsAguJExsrMmu4MZlBfuANpTJdNIOnUnCzEQoob/gxoUibv0hd/6Nk7aCih64cDjnXu69J0w5UxqhD2tldW19Y7O0Vd7e2d3brxwctlWSSUJbJOGJ7IZYUc5i2tJMc9pNJcUi5LQTTq4Lv3NPpWJJfKenKQ0EHsUsYgTrQkI2uhxUqsj2Pc9HHkS2i5Dr+YbUfN+v16BjozmqYInmoPLeHyYkEzTWhGOleg5KdZBjqRnhdFbuZ4qmmEzwiPYMjbGgKsjnt87gqVGGMEqkqVjDufp9IsdCqakITafAeqx+e4X4l9fLdOQFOYvTTNOYLBZFGYc6gcXjcMgkJZpPDcFEMnMrJGMsMdEmnrIJ4etT+D9pX9hO3XZv3WrjfBlHCRyDE3AGHHAFGuAGNEELEDAGD+AJPFvCerRerNdF64q1nDkCP2C9fQJdnY3C</latexit>0.05<latexit sha1_base64="tgS9OE1qy8Vw+gSzF77nWIDLrn8=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFqQk12BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRsxxlWa8j2Pc9HHkS2i5Dr+YY4vu83HFi30QI1sEJrWH0fjBKSxVRowrFS/TpKdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNr1hu3eurXmxSqOMjgBp+Ac1MEVaIIb0AJtQMAEPIAn8GzF1qP1Yr0uW0vWauYY/ID19glfJI3D</latexit>0.33
<latexit sha1_base64="u5zgvj4rR8dhza7sssVGo33QeSU=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRs1BhWa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJfIY3D</latexit>0.06<latexit sha1_base64="hBWF+7CQNMZmavlqrkVOVPf/imw=">AAAB63icdVBNS8NAEN3Ur1q/qh69LBbBg4RNG2pyK3jxWMHaQhvKZrtpl+4mYXcjlNC/4MWDIl79Q978N27aCir6YODx3gwz88KUM6UR+rBKa+sbm1vl7crO7t7+QfXw6E4lmSS0QxKeyF6IFeUsph3NNKe9VFIsQk674fSq8Lv3VCqWxLd6ltJA4HHMIkawLiRk151htYZs3/N85EFkuwi5nm9Iw/f9ZgM6NlqgBlZoD6vvg1FCMkFjTThWqu+gVAc5lpoRTueVQaZoiskUj2nf0BgLqoJ8cescnhllBKNEmoo1XKjfJ3IslJqJ0HQKrCfqt1eIf3n9TEdekLM4zTSNyXJRlHGoE1g8DkdMUqL5zBBMJDO3QjLBEhNt4qmYEL4+hf+Tu7rtNG33xq21LlZxlMEJOAXnwAGXoAWuQRt0AAET8ACewLMlrEfrxXpdtpas1cwx+AHr7RNal43A</latexit>0.21
<latexit sha1_base64="G62TDpOndLoAQU4hgeklWgMhqKo=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRsVB9Wa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJalY3A</latexit>0.03<latexit sha1_base64="G62TDpOndLoAQU4hgeklWgMhqKo=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRsVB9Wa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJalY3A</latexit>0.03<latexit sha1_base64="G62TDpOndLoAQU4hgeklWgMhqKo=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRsVB9Wa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJalY3A</latexit>0.03<latexit sha1_base64="u5zgvj4rR8dhza7sssVGo33QeSU=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRs1BhWa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJfIY3D</latexit>0.06weightsLabel: EntailmentSentence 2: Rodgers told Lewis he hates Amelio.weights<latexit sha1_base64="sLacaWPlx3Erefd1maoLYTUOQAA=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRsxx1Wa8j2Pc9HHkS2i5Dr+YbUfd9v1KFjowVqYIXWsPo+GCUki6nQhGOl+g5KdZBjqRnhdF4ZZIqmmEzxmPYNFTimKsgXt87hmVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnooJ4etT+D/pXNpOw3Zv3VrzYhVHGZyAU3AOHHAFmuAGtEAbEDABD+AJPFux9Wi9WK/L1pK1mjkGP2C9fQJdno3C</latexit>0.14<latexit sha1_base64="h0z2Sf/6HCemiIwwJx9U8UX8d/M=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRs5A2rNWT7nucjDyLbRcj1fEPqvu836tCx0QI1sEJrWH0fjBKSxVRowrFSfQelOsix1IxwOq8MMkVTTKZ4TPuGChxTFeSLW+fwzCgjGCXSlNBwoX6fyHGs1CwOTWeM9UT99grxL6+f6cgLcibSTFNBlouijEOdwOJxOGKSEs1nhmAimbkVkgmWmGgTT8WE8PUp/J90Lm2nYbu3bq15sYqjDE7AKTgHDrgCTXADWqANCJiAB/AEnq3YerRerNdla8lazRyDH7DePgFiKY3F</latexit>0.08<latexit sha1_base64="mQyKreprppdwoX/badKZ/nRbMto=">AAAB63icdVDLSsNAFJ34rPVVdelmsAguJExsaJNdwY3LCvYBbSiT6aQdOpmEmYlQQn/BjQtF3PpD7vwbJ20FFT1w4XDOvdx7T5hypjRCH9ba+sbm1nZpp7y7t39wWDk67qgkk4S2ScIT2QuxopwJ2tZMc9pLJcVxyGk3nF4XfveeSsUScadnKQ1iPBYsYgTrQkI2agwrVWT7nucjDyLbRcj1fENqvu/Xa9Cx0QJVsEJrWHkfjBKSxVRowrFSfQelOsix1IxwOi8PMkVTTKZ4TPuGChxTFeSLW+fw3CgjGCXSlNBwoX6fyHGs1CwOTWeM9UT99grxL6+f6cgLcibSTFNBlouijEOdwOJxOGKSEs1nhmAimbkVkgmWmGgTT9mE8PUp/J90rmynbru3brV5uYqjBE7BGbgADmiAJrgBLdAGBEzAA3gCz1ZsPVov1uuydc1azZyAH7DePgFgpY3E</latexit>0.07<latexit sha1_base64="pCMALU1e8hchGbW2Ch4fLPeBXK4=">AAAB63icdVDLSgMxFM34rPVVdekmWAQXMmTs0M7sCm5cVrAPaIeSSTNtaCYzJBmhDP0FNy4UcesPufNvzLQVVPRA4OSce7n3njDlTGmEPqy19Y3Nre3STnl3b//gsHJ03FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRstzGsVJHte56PPGj+CLmeb0jN9/16DTo2WqAKVmgNK++DUUKymApNOFaq76BUBzmWmhFO5+VBpmiKyRSPad9QgWOqgnyx6xyeG2UEo0SaJzRcqN87chwrNYtDUxljPVG/vUL8y+tnOvKCnIk001SQ5aAo41AnsDgcjpikRPOZIZhIZnaFZIIlJtrEUzYhfF0K/yedK9up2+6tW21eruIogVNwBi6AAxqgCW5AC7QBARPwAJ7AsxVbj9aL9bosXbNWPSfgB6y3T2a5jcg=</latexit>0.47<latexit sha1_base64="zVmz4cBstknVGNdMeFeyYWSyP18=">AAAB63icdVDLSsNAFJ34rPVVdelmsAguJExsaJNdwY3LCvYBbSiT6aQdOpmEmYlQQn/BjQtF3PpD7vwbJ20FFT1w4XDOvdx7T5hypjRCH9ba+sbm1nZpp7y7t39wWDk67qgkk4S2ScIT2QuxopwJ2tZMc9pLJcVxyGk3nF4XfveeSsUScadnKQ1iPBYsYgTrQkK20xhWqsj2Pc9HHkS2i5Dr+YbUfN+v16BjowWqYIXWsPI+GCUki6nQhGOl+g5KdZBjqRnhdF4eZIqmmEzxmPYNFTimKsgXt87huVFGMEqkKaHhQv0+keNYqVkcms4Y64n67RXiX14/05EX5EykmaaCLBdFGYc6gcXjcMQkJZrPDMFEMnMrJBMsMdEmnrIJ4etT+D/pXNlO3XZv3WrzchVHCZyCM3ABHNAATXADWqANCJiAB/AEnq3YerRerNdl65q1mjkBP2C9fQJiKo3F</latexit>0.17
<latexit sha1_base64="h0z2Sf/6HCemiIwwJx9U8UX8d/M=">AAAB63icdVDLSsNAFJ3UV62vqks3g0VwIWFiQ012BTcuK9gHtKFMppN26GQSZiZCCf0FNy4UcesPufNvnLQVVPTAhcM593LvPWHKmdIIfViltfWNza3ydmVnd2//oHp41FFJJgltk4QnshdiRTkTtK2Z5rSXSorjkNNuOL0u/O49lYol4k7PUhrEeCxYxAjWhYRs5A2rNWT7nucjDyLbRcj1fEPqvu836tCx0QI1sEJrWH0fjBKSxVRowrFSfQelOsix1IxwOq8MMkVTTKZ4TPuGChxTFeSLW+fwzCgjGCXSlNBwoX6fyHGs1CwOTWeM9UT99grxL6+f6cgLcibSTFNBlouijEOdwOJxOGKSEs1nhmAimbkVkgmWmGgTT8WE8PUp/J90Lm2nYbu3bq15sYqjDE7AKTgHDrgCTXADWqANCJiAB/AEnq3YerRerNdla8lazRyDH7DePgFiKY3F</latexit>0.08
Figure 4: Visualization of learned token weights on two samples from MNLI‚Äôs few-shot training set. The generator is trained
given the Ô¨Årst sentence to generate the second. The tokens associated with higher weights are more label indicative.
the desired label ( i.e., the ‚Äúentailment‚Äù and ‚Äúcontradiction‚Äù
generation results are in fact neutral with respect to the
given sentence), lacking label discriminativeness. When
Lgen+Ldiscis used, the generated samples of different
labels are more distinctive, but also become less natural and
coherent due to the model‚Äôs language modeling ability being
hampered. The generator tuned with Lw-gen produces both
coherent and label-discriminative samples. More concrete
generation results for each task can be found in Appendix F.
5.4. Visualization of Learned Token Weights
To understand how token weights are automatically learned
during generator tuning, we visualize the learned weights in
Fig. 4. The tokens with higher weights ( e.g., ‚Äúweak‚Äù in the
Ô¨Årst example and ‚Äúhates‚Äù in the second example) are learned
to be important tokens that decide the relation of the second
sentence to the Ô¨Årst sentence ( i.e., the label of the training
sample). With such tokens emphasized during training,
the generator is encouraged to capture label-discriminative
information that facilitates the generation of unambiguous
training samples.
6. Discussions and Conclusions
Ethical Considerations. Despite the impressive text gen-
eration and representation power of PLMs, they can
also come with the risk (Bender et al., 2021; Bender &
Koller, 2020; Brown et al., 2020) of generating disinfor-
mation (Pagnoni et al., 2021) or exacerbating biases (Prab-
humoye et al., 2018). Instead of improving upon PLM
architectures or generation techniques, our work focuses on
using existing PLMs to create training data for NLU tasks.
In practice, our method can be combined with any bias re-
duction and correction strategies (Gehman et al., 2020; Ma
et al., 2020) to reduce the adverse effects of PLMs.
Limitations. Compared to few-shot learning methods that
directly train classiÔ¨Åcation models on the small training
set, FewGen requires tuning a generator PLM and using
it to synthesize novel training samples, resulting in higher
computation costs and longer running time. Still, we believe
that our method may bring more good than harm‚Äîwhen the
small training data size becomes the performance bottleneckfor NLU tasks, a simple yet costly solution is to obtain more
human annotations. Our method may replace or reduce the
human efforts in such training data creation processes.
Conclusions. In this work, we propose FewGen, which
leverages few-shot training samples to tune a generator PLM
for synthesizing novel training data. The generated data can
be then used in combination with few-shot samples to Ô¨Åne-
tune a classiÔ¨Åcation model for better generalization. To
emphasize label-discriminative information during gener-
ator tuning, we propose a weighted maximum likelihood
objective where the token weights are automatically learned
via a discriminative meta objective. Since the generated
samples may contain label noise, we propose a simple train-
ing procedure that Ô¨Årst trains classiÔ¨Åers on the few-shot
training set and then on the generated set by applying regu-
larization for noise-robustness. Across seven classiÔ¨Åcation
tasks from the GLUE benchmark, FewGen signiÔ¨Åcantly
outperforms existing approaches under the same few-shot
learning setting. The effectiveness of each important com-
ponent in FewGen is validated via ablation studies. Future
directions may include: Using larger PLMs as the generator
and the classiÔ¨Åer, jointly training both models with each
other‚Äôs high-conÔ¨Ådent predictions, improving the robustness
of models trained on synthetic data, and developing sys-
tematic metrics to evaluate the quality of generated training
samples.
Acknowledgments
Research was supported in part by US DARPA KAIROS
Program No. FA8750-19-2-1004 and INCAS Program No.
HR001121C0165, National Science Foundation IIS-19-
56151, IIS-17-41317, and IIS 17-04532, and the Molecule
Maker Lab Institute: An AI Research Institutes program
supported by NSF under Award No. 2019897, and the In-
stitute for Geospatial Understanding through an Integrative
Discovery Environment (I-GUIDE) by NSF under Award
No. 2118329. Any opinions, Ô¨Åndings, and conclusions or
recommendations expressed herein are those of the authors
and do not necessarily represent the views, either expressed
or implied, of DARPA or the U.S. Government. Yu Meng
was supported by the Google PhD Fellowship. We thank
anonymous reviewers for valuable and insightful feedback.
9

--- PAGE 10 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
References
Anaby-Tavor, A., Carmeli, B., Goldbraich, E., Kantor, A.,
Kour, G., Shlomov, S., Tepper, N., and Zwerdling, N. Do
not have enough data? deep learning to the rescue! In
AAAI , 2020.
Andrychowicz, M., Denil, M., Colmenarejo, S. G., Hoffman,
M. W., Pfau, D., Schaul, T., and de Freitas, N. Learning
to learn by gradient descent by gradient descent. In NIPS ,
2016.
Baum, E. and Haussler, D. What size net gives valid gener-
alization? In NIPS , 1988.
Bender, E. M. and Koller, A. Climbing towards NLU: On
meaning, form, and understanding in the age of data. In
ACL, 2020.
Bender, E. M., Gebru, T., McMillan-Major, A., and
Shmitchell, S. On the dangers of stochastic parrots: Can
language models be too big? In ACM Conference on
Fairness, Accountability, and Transparency , 2021.
Bentivogli, L., Clark, P., Dagan, I., and Giampiccolo, D.
The Ô¨Åfth pascal recognizing textual entailment challenge.
InTAC, 2009.
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,
J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,
Askell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,
Henighan, T. J., Child, R., Ramesh, A., Ziegler, D. M.,
Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin,
M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish,
S., Radford, A., Sutskever, I., and Amodei, D. Language
models are few-shot learners. In NeurIPS , 2020.
Chan, A., Ong, Y ., Pung, B. T. W., Zhang, A., and Fu, J.
CoCon: A self-supervised approach for controlled text
generation. In ICLR , 2021.
Chen, J., Yang, Z., and Yang, D. MixText: Linguistically-
informed interpolation of hidden space for semi-
supervised text classiÔ¨Åcation. In ACL, 2020.
Clark, K., Luong, M.-T., Le, Q. V ., and Manning, C. D.
ELECTRA: Pre-training text encoders as discriminators
rather than generators. In ICLR , 2020.
Cui, G., Hu, S., Ding, N., Huang, L., and Liu, Z. Prototypi-
cal verbalizer for prompt-based few-shot tuning. In ACL,
2022.
Dagan, I., Glickman, O., and Magnini, B. The pascal recog-
nising textual entailment challenge. In Machine Learning
Challenges Workshop , 2005.
Dathathri, S., Madotto, A., Lan, J., Hung, J., Frank, E.,
Molino, P., Yosinski, J., and Liu, R. Plug and play lan-
guage models: A simple approach to controlled text gen-
eration. In ICLR , 2020.Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. BERT:
Pre-training of deep bidirectional transformers for lan-
guage understanding. In NAACL-HLT , 2019.
Dolan, W. B. and Brockett, C. Automatically construct-
ing a corpus of sentential paraphrases. In International
Workshop on Paraphrasing (IWP) , 2005.
Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-
learning for fast adaptation of deep networks. In ICML ,
2017.
Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., and Pontil,
M. Bilevel programming for hyperparameter optimization
and meta-learning. In ICML , 2018.
Gao, J., Pi, R., Lin, Y ., Xu, H., Ye, J., Wu, Z., Zhang, W.,
Liang, X., Li, Z., and Kong, L. Self-guided noise-free
data generation for efÔ¨Åcient zero-shot learning. In ICLR ,
2023.
Gao, T., Fisch, A., and Chen, D. Making pre-trained lan-
guage models better few-shot learners. In ACL, 2021.
Gehman, S., Gururangan, S., Sap, M., Choi, Y ., and Smith,
N. A. RealToxicityPrompts: Evaluating neural toxic
degeneration in language models. In EMNLP Findings ,
2020.
Giampiccolo, D., Magnini, B., Dagan, I., and Dolan, B.
The third pascal recognizing textual entailment challenge.
InACL-PASCAL workshop on textual entailment and
paraphrasing , 2007.
Haim, R. B., Dagan, I., Dolan, B., Ferro, L., Giampiccolo,
D., Magnini, B., and Szpektor, I. The second pascal
recognising textual entailment challenge. In PASCAL
Challenges Workshop on Recognising Textual Entailment ,
2006.
Hambardzumyan, K., Khachatrian, H., and May, J. WARP:
Word-level adversarial reprogramming. In ACL, 2021.
He, P., Liu, X., Gao, J., and Chen, W. DeBERTa: Decoding-
enhanced BERT with disentangled attention. In ICLR ,
2021.
Hendrycks, D., Mazeika, M., Wilson, D., and Gimpel, K.
Using trusted data to train deep networks on labels cor-
rupted by severe noise. In NeurIPS , 2018.
Hu, S., Ding, N., Wang, H., Liu, Z., Li, J.-Z., and Sun, M.
Knowledgeable prompt-tuning: Incorporating knowledge
into prompt verbalizer for text classiÔ¨Åcation. In ACL,
2022.
10

--- PAGE 11 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Hu, Z., Yang, Z., Liang, X., Salakhutdinov, R., and Xing,
E. P. Toward controlled generation of text. In ICML ,
2017.
Huang, J., Gu, S. S., Hou, L., Wu, Y ., Wang, X., Yu, H., and
Han, J. Large language models can self-improve. ArXiv ,
abs/2210.11610, 2022.
Junczys-Dowmunt, M., Grundkiewicz, R., Dwojak, T.,
Hoang, H. T., HeaÔ¨Åeld, K., Neckermann, T., Seide, F.,
Germann, U., Aji, A. F., Bogoychev, N., Martins, A. F. T.,
and Birch, A. Marian: Fast neural machine translation in
C++. In ACL System Demo , 2018.
Keskar, N. S., McCann, B., Varshney, L. R., Xiong,
C., and Socher, R. CTRL: A conditional transformer
language model for controllable generation. ArXiv ,
abs/1909.05858, 2019.
Khalifa, M., ElSahar, H., and Dymetman, M. A distribu-
tional approach to controlled text generation. In ICLR ,
2021.
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Des-
jardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T.,
Grabska-Barwinska, A., et al. Overcoming catastrophic
forgetting in neural networks. Proceedings of the national
academy of sciences , 2017.
Krause, B., Gotmare, A. D., McCann, B., Keskar, N. S.,
Joty, S. R., Socher, R., and Rajani, N. GeDi: Generative
discriminator guided sequence generation. In EMNLP ,
2021.
Kumar, S., Malmi, E., Severyn, A., and Tsvetkov, Y . Con-
trolled text generation as continuous optimization with
multiple constraints. In NeurIPS , 2021.
Kumar, V ., Choudhary, A., and Cho, E. Data augmentation
using pre-trained transformer models. In Workshop on
Life-long Learning for Spoken Language Systems , 2020.
Laine, S. and Aila, T. Temporal ensembling for semi-
supervised learning. In ICLR , 2017.
Lee, K., Guu, K., He, L., Dozat, T., and Chung, H. W. Neu-
ral data augmentation via example extrapolation. arXiv
preprint arXiv:2102.01335 , 2021.
Lester, B., Al-Rfou, R., and Constant, N. The power of
scale for parameter-efÔ¨Åcient prompt tuning. In EMNLP ,
2021.
Li, X. L. and Liang, P. PreÔ¨Åx-tuning: Optimizing continuous
prompts for generation. In ACL, 2021.
Liu, A., Sap, M., Lu, X., Swayamdipta, S., Bhagavatula,
C., Smith, N. A., and Choi, Y . DExperts: Decoding-time
controlled text generation with experts and anti-experts.
InACL, 2021a.Liu, H., Tam, D., Muqeeth, M., Mohta, J., Huang, T., Bansal,
M., and Raffel, C. Few-shot parameter-efÔ¨Åcient Ô¨Åne-
tuning is better and cheaper than in-context learning. In
NeurIPS , 2022a.
Liu, J., Shen, D., Zhang, Y ., Dolan, B., Carin, L., and Chen,
W. What makes good in-context examples for GPT-3? In
Proceedings of Deep Learning Inside Out , 2022b.
Liu, X., Zheng, Y ., Du, Z., Ding, M., Qian, Y ., Yang, Z., and
Tang, J. GPT understands, too. ArXiv , abs/2103.10385,
2021b.
Liu, Y ., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D.,
Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V .
RoBERTa: A robustly optimized BERT pretraining ap-
proach. arXiv preprint arXiv:1907.11692 , 2019.
Logan IV , R. L., Bala Àázevi¬¥c, I., Wallace, E., Petroni, F., Singh,
S., and Riedel, S. Cutting down on prompts and param-
eters: Simple few-shot learning with language models.
arXiv preprint arXiv:2106.13353 , 2021.
Ma, X., Sap, M., Rashkin, H., and Choi, Y . PowerTrans-
former: Unsupervised controllable revision for biased
language correction. In EMNLP , 2020.
Meng, Y ., Shen, J., Zhang, C., and Han, J. Weakly-
supervised neural text classiÔ¨Åcation. In CIKM , 2018.
Meng, Y ., Shen, J., Zhang, C., and Han, J. Weakly-
supervised hierarchical text classiÔ¨Åcation. In AAAI , 2019.
Meng, Y ., Xiong, C., Bajaj, P., Tiwary, S., Bennett, P., Han,
J., and Song, X. COCO-LM: Correcting and contrast-
ing text sequences for language model pretraining. In
NeurIPS , 2021a.
Meng, Y ., Zhang, Y ., Huang, J., Wang, X., Zhang, Y ., Ji,
H., and Han, J. Distantly-supervised named entity recog-
nition with noise-robust learning and language model
augmented self-training. In EMNLP , 2021b.
Meng, Y ., Huang, J., Zhang, Y ., and Han, J. Generating
training data with language models: Towards zero-shot
language understanding. In NeurIPS , 2022a.
Meng, Y ., Xiong, C., Bajaj, P., Tiwary, S., Bennett, P., Han,
J., and Song, X. Pretraining text encoders with adversarial
mixture of training signal generators. In ICLR , 2022b.
Min, S., Lewis, M., Hajishirzi, H., and Zettlemoyer, L.
Noisy channel language model prompting for few-shot
text classiÔ¨Åcation. In ACL, 2022a.
11

--- PAGE 12 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M.,
Hajishirzi, H., and Zettlemoyer, L. Rethinking the role of
demonstrations: What makes in-context learning work?
InEMNLP , 2022b.
Miyato, T., Dai, A. M., and Goodfellow, I. J. Adversarial
training methods for semi-supervised text classiÔ¨Åcation.
InICLR , 2017.
Nguyen, D. T., Mummadi, C. K., Ngo, T.-P.-N., Nguyen, T.
H. P., Beggel, L., and Brox, T. SELF: Learning to Ô¨Ålter
noisy labels with self-ensembling. In ICLR , 2020.
Pagnoni, A., Balachandran, V ., and Tsvetkov, Y . Understand-
ing factuality in abstractive summarization with FRANK:
A benchmark for factuality metrics. In NAACL , 2021.
Pascual, D., Egressy, B., Meister, C., Cotterell, R., and
Wattenhofer, R. A plug-and-play method for controlled
text generation. In EMNLP Findings , 2021.
Perez, E., Kiela, D., and Cho, K. True few-shot learning
with language models. In NeurIPS , 2021.
Prabhumoye, S., Tsvetkov, Y ., Salakhutdinov, R., and Black,
A. W. Style transfer through back-translation. In ACL,
2018.
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S.,
Matena, M., Zhou, Y ., Li, W., and Liu, P. J. Exploring
the limits of transfer learning with a uniÔ¨Åed text-to-text
transformer. Journal of Machine Learning Research ,
2019.
Ren, M., Zeng, W., Yang, B., and Urtasun, R. Learning to
reweight examples for robust deep learning. In ICML ,
2018.
Scao, T. L. and Rush, A. M. How many data points is a
prompt worth? In NAACL , 2021.
Schick, T. and Sch ¬®utze, H. Exploiting cloze-questions for
few-shot text classiÔ¨Åcation and natural language infer-
ence. In EACL , 2021a.
Schick, T. and Sch ¬®utze, H. Few-shot text generation with
natural language instructions. In EMNLP , 2021b.
Schick, T. and Sch ¬®utze, H. Generating datasets with pre-
trained language models. In EMNLP , 2021c.
Schick, T. and Sch ¬®utze, H. It‚Äôs not just size that matters:
Small language models are also few-shot learners. In
NAACL , 2021d.
Shankar, I., Nikhil, D., and Korn ¬¥el, C. First Quora
dataset release: Question pairs, 2017. URL
https://www.quora.com/q/quoradata/
First-Quora-Dataset-Release-Question-Pairs .Shin, T., Razeghi, Y ., IV , R. L. L., Wallace, E., and Singh,
S. Eliciting knowledge from language models using auto-
matically generated prompts. In EMNLP , 2020.
Shu, J., Xie, Q., Yi, L., Zhao, Q., Zhou, S., Xu, Z., and
Meng, D. Meta-weight-net: Learning an explicit mapping
for sample weighting. In NeurIPS , 2019.
Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning,
C. D., Ng, A. Y ., and Potts, C. Recursive deep models for
semantic compositionality over a sentiment treebank. In
EMNLP , 2013.
Standley, T. S., Zamir, A. R., Chen, D., Guibas, L. J., Ma-
lik, J., and Savarese, S. Which tasks should be learned
together in multi-task learning? In ICML , 2019.
Szegedy, C., Vanhoucke, V ., Ioffe, S., Shlens, J., and Wojna,
Z. Rethinking the inception architecture for computer
vision. In CVPR , 2016.
Tam, D., Menon, R. R., Bansal, M., Srivastava, S., and
Raffel, C. Improving and simplifying pattern exploiting
training. In EMNLP , 2021.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
L., Gomez, A. N., Kaiser, ≈Å., and Polosukhin, I. Attention
is all you need. In NeurIPS , 2017.
Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and
Bowman, S. R. GLUE: A multi-task benchmark and
analysis platform for natural language understanding. In
EMNLP Workshop BlackboxNLP , 2018.
Wang, A., Pruksachatkun, Y ., Nangia, N., Singh, A.,
Michael, J., Hill, F., Levy, O., and Bowman, S. R. Su-
perGLUE: A stickier benchmark for general-purpose lan-
guage understanding systems. In NeurIPS , 2019.
Wang, Y .-X., Ramanan, D., and Hebert, M. Learning to
model the tail. In NIPS , 2017.
Wang, Z., Yu, A. W., Firat, O., and Cao, Y . Towards zero-
label language learning. ArXiv , abs/2109.09193, 2021.
Warstadt, A., Singh, A., and Bowman, S. R. Neural network
acceptability judgments. In TACL , 2019.
Wei, J. and Zou, K. EDA: Easy data augmentation tech-
niques for boosting performance on text classiÔ¨Åcation
tasks. In EMNLP , 2019.
Williams, A., Nangia, N., and Bowman, S. A broad-
coverage challenge corpus for sentence understanding
through inference. In NAACL-HLT , 2018.
Wu, L., Tian, F., Xia, Y ., Fan, Y ., Qin, T., Lai, J., and Liu,
T.-Y . Learning to teach with dynamic loss functions. In
NeurIPS , 2018.
12

--- PAGE 13 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Xie, Q., Dai, Z., Hovy, E. H., Luong, M.-T., and Le, Q. V .
Unsupervised data augmentation for consistency training.
InNeurIPS , 2020.
Yang, K. and Klein, D. FUDGE: Controlled text generation
with future discriminators. In NAACL , 2021.
Yang, Y ., Malaviya, C., Fernandez, J., Swayamdipta, S.,
Bras, R. L., ping Wang, J., Bhagavatula, C., Choi, Y ., and
Downey, D. G-daug: Generative data augmentation for
commonsense reasoning. In EMNLP Findings , 2020.
Ye, J., Gao, J., Li, Q., Xu, H., Feng, J., Wu, Z., Yu, T.,
and Kong, L. ZeroGen: EfÔ¨Åcient zero-shot learning via
dataset generation. In EMNLP , 2022.
Yoo, K. M., Park, D.-H., Kang, J., Lee, S.-W., and Park, W.GPT3Mix: Leveraging large-scale language models for
text augmentation. In EMNLP Findings , 2021.
Zhang, N., Li, L., Chen, X., Deng, S., Bi, Z., Tan, C., Huang,
F., and Chen, H. Differentiable prompt makes pre-trained
language models better few-shot learners. In ICLR , 2022.
Zhao, T., Wallace, E., Feng, S., Klein, D., and Singh, S.
Calibrate before use: Improving few-shot performance of
language models. In ICML , 2021.
Zhong, Z., Friedman, D., and Chen, D. Factual probing is
[mask]: Learning vs. learning to recall. In NAACL , 2021.
Ziegler, D. M., Stiennon, N., Wu, J., Brown, T. B., Radford,
A., Amodei, D., Christiano, P., and Irving, G. Fine-
tuning language models from human preferences. ArXiv ,
abs/1909.08593, 2019.
13

--- PAGE 14 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
A. Details of Weighting Network Implementation
Since the token weights wused in Eq. (4)need to characterize the discriminativeness of each token, we use the value of
discriminative objective at each token Lj
discas the input to the weighting network, and we use softmax to normalize the
weights:
wj(!) =exp
g!(Lj
disc)
Pn
j0=1exp
g!(Lj0
disc):
Following (Shu et al., 2019), we instantiate g!to be a feedforward network (FFN) with only one 100-dimension hidden
layer by default.
B. Implementation Details
Table 5: Prompts used for initializing the preÔ¨Åx vectors and control codes (required by CTRL (Keskar et al., 2019)) used in
generator training. The control codes are selected to approximiate the task domain. For single-sequence tasks, xdenotes the
training sample; for sequence-pair tasks, x1andx2denote the Ô¨Årst and second sequence in the training sample, respectively.
Task Task Type Control Code Label Initialization Prompt
SST-2 single-sequence Reviewspositive Rating: 5.0 positive movie review: x
negative Rating: 1.0 negative movie review: x
CoLA single-sequence Linksgrammatical Linguistically correct sentence: x
not grammatical Linguistically incorrect sentence: x
MNLI sequence-pair Wikipediaentailment Sentence 1 implies Sentence 2. Sentence 1: x1Sentence 2:x2
neutral Sentence 2 supplements Sentence 1. Sentence 1: x1Sentence 2:x2
contradiction Sentence 2 contradicts Sentence 1. Sentence 1: x1Sentence 2:x2
QNLI sequence-pair Linksentailment Paragraph is relevant to Question. Question: x1Paragraph:x2
not entailment Paragraph is irrelevant to Question. Question: x1Paragraph:x2
RTE sequence-pair Wikipediaentailment Sentence 1 implies Sentence 2. Sentence 1: x1Sentence 2:x2
not entailment Sentence 2 supplements Sentence 1. Sentence 1: x1Sentence 2:x2
MRPC sequence-pair Wikipediaequivalent Sentence 1 is equivalent to Sentence 2. Sentence 1: x1Sentence 2:x2
not equivalent Sentence 1 is different from Sentence 2. Sentence 1: x1Sentence 2:x2
QQP sequence-pair Linksequivalent Question 1 is equivalent to Question 2. Question 1: x1Question 2:x2
not equivalent Question 1 is different from Question 2. Question 1: x1Question 2:x2
Details of Initialization Prompts Used for Generator Tuning on Different Tasks. For generator tuning, we Ô¨Ånd it
beneÔ¨Åcial to initialize the preÔ¨Åx vectors with task-descriptive prompts, similar to the observations in (Li & Liang, 2021).
The preÔ¨Åx lengths ( i.e., number of trained preÔ¨Åx token positions) are equal to the number of tokens in the prompts. We
present details about the prompts used for initializing the preÔ¨Åx vectors for different tasks in Table 5. For sequence-pair
tasks, an additional inÔ¨Åx prompt is used between the two sequences, and we also tune the embeddings of the inÔ¨Åx ( i.e.,
prompt-tuning (Lester et al., 2021)) for generator training.
Details of Generator Tuning. The meta-weighted generator tuning procedure (Algorithm 1) involves three forward and
backward passes, and thus its time complexity is approximately 3times of standard generator training without meta learning.
However, since the few-shot training sets have a small amount of training data, the extra time cost is usually affordable.
In practice, our generator tuning with meta weight learning takes 10minutes to train on each task (the standard generator
training time without meta-learning is 3:5minutes). We use a Ô¨Åxed set of hyperparamters for all tasks without task-speciÔ¨Åc
hyperparamter tuning: In Algorithm 1, we set the batch size to be 2, the learning rate for optimizing ^pto be 2e 2, the
learning rate for optimizing !to be 1e 2, the learning rate for optimizing pto be 5e 3, and training epoch to be 20.
We also experiment with larger batch sizes ( e.g.,16/32) and/or training for more epochs, but they result in worse language
modeling quality than the default hyperparamters.
Details of Generating Training Data. Following (Meng et al., 2022a), for sequence-pair tasks (MNLI, QQP, QNLI, RTE
and MRPC), we randomly sample the Ô¨Årst sequence from the pretraining corpus ( e.g., Wikipedia) and use greedy sampling
14

--- PAGE 15 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
for generating the second sequence. For single-sequence tasks (SST-2 and CoLA), we use top- ksampling with temperature
to generate training data from scratch where k= 10 . For all tasks, we generate 5;000samples per label.
For SST-2, we use one of the following tokens to start generation: ‚Äúa‚Äù, ‚Äúone‚Äù, ‚Äúthe‚Äù, ‚Äúthis‚Äù, ‚Äúthat‚Äù, ‚Äúi‚Äù, ‚Äúyou‚Äù, ‚Äúit‚Äù, ‚Äúwhat‚Äù.
For CoLA, we use a random stop word to start generation.
Table 6: Hyperparameters for generating
training data for different tasks. : Temper-
ature during sampling ( = 0means greedy
sampling);: Repetition penalty.
Task Label  
SST-2positive0.51.1
negative 1.1
CoLAgrammatical 0.3 1.1
not grammatical 10 1.1
MNLIentailment
01.1
neutral 1.5
contradiction 1.1
QNLIentailment01.0
not entailment 1.5
RTEentailment01.0
not entailment 1.5
MRPCequivalent01.0
not equivalent 1.5
QQPequivalent01.0
not equivalent 1.5We apply repetition penalty (Keskar et al., 2019) to the logits of tokens
that have already appeared in the sequence. Overall, the token probability
distribution is post-processed as follows before conducting sampling:
p(xijx<i) =exp(e>
ihi=!)
PjVj
j=1exp(e>
jhi=!);
!=(
 xi2x<i
 else;
whereis the temperature hyperparameter, and is the repetition penalty
hyperparameter. For labels that favor token repetitions between the Ô¨Årst
and the second sequences ( e.g., paraphrase or entailment), we set to be
a smaller value ( e.g.,1:0), and vice versa.
The hyperparameter values for training data generation on all tasks can be
found in Table 6.
Hyperparameters for Fine-Tuning ClassiÔ¨Åer PLMs. For Ô¨Åne-tuning on
the few-shot training samples Dtrain, we search among the following hyper-
parameter ranges based on development set ( Ddev) model performance and
pick the best performing model for futher Ô¨Åne-tuning on synthesized data:
Learning rate in [1e 5;2e 5]and batch size in [4;8]. The number of
training steps is Ô¨Åxed to be 1000 . We also Ô¨Ånd it beneÔ¨Åcial to apply label
smoothing (smoothing weight set to 0:15) for Ô¨Åne-tuning on the few-shot
training set.
For Ô¨Åne-tuning on the synthesized training samples Dgen, we use the following hyperparameters: 5e 6as the learning rate;
16as the batch size; label smoothing weight = 0:15; temporal ensemble momentum = 0:9; temporal ensemble loss
weight= 20 ; training steps T= 6;000.
Details of Temporal Ensembling for Fine-Tuning ClassiÔ¨Åer PLMs on Synthetic Data. We update ensembled predic-
tions zas follows where pis the current model prediction, is the momentum parameter, ^zis the accumulated model
prediction before bias correction, zis the accumulated model prediction after bias correction, and tis the number of updates
zhas received:
^z ^z+ (1 )p;z ^z=(1 t):
The accumulated model prediction ^zhas a zero initialization; the division (1 t)is for bias correction (Laine & Aila,
2017). After each update of ^z, it will be compared to a threshold value ; each synthesized sample (~x;~y)will be included in
training only if z~y>.
We update the ensembled predictions zon all samples inDgenevery 200steps, and set the threshold value for sample
Ô¨Åltering= 0:8.
Computation Environment. The experiments are conducted on NVIDIA A100 GPUs.
15

--- PAGE 16 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
C. Derivation of Meta Weight Gradient Update
We Ô¨Årst write out the gradient update of ^(t)
p 
!(t)
and!(t+1)according to Algorithm 1 as follows:
^(t)
p
!(t)
=(t)
p @Lw-gen
p;!(t)
@p
p=(t)
p=(t)
p nX
j=1wj
!(t)@Lj
gen(p)
@p
p=(t)
p(6)
!(t+1)=!(t) @Ldisc
^(t)
p(!)
@!
!=!(t): (7)
whereandare step sizes.
The gradient in Equation (7) is calculated as:
@Ldisc
^(t)
p(!)
@!
!=!(t)
=@Ldisc
^p
@^p^p=^(t)
p@^p(!)
@!
!=!(t)
=@Ldisc
^p
@^p^p=^(t)
p0
@ nX
j=1@Lj
gen(p)
@p>
p=(t)
p@wj(!)
@!
!=!(t)1
A Plugging in Eq. (6)
= nX
j=10
BBBBBBB@@Ldisc
^p
@^p^p=^(t)
p@Lj
gen(p)
@p>
p=(t)
p
| {z }
,dj@wj(!)
@!
!=!(t)1
CCCCCCCA
Therefore,
 @Ldisc
^(t)
p(!)
@!
!=!(t)/nX
j=1dj@wj(!)
@!
!=!(t); dj=@Ldisc
^p
@^p^p=^(t)
p@Lj
gen(p)
@p>
p=(t)
p:
D. GLUE Tasks
We provide the details of the seven classiÔ¨Åcation tasks included in the GLUE benchmark.
MNLI: Multi-genre Natural Language Inference (Williams et al., 2018) requires predicting whether a given premise
sentence entails, contradicts or neutral with respect to a given hypothesis sentence.
QQP: Quora Question Pairs (Shankar et al., 2017) requires judging whether a pair of questions asked are semantically
equivalent.
QNLI: Question Natural Language Inference requires predicting whether a given sentence contains the answer to a given
question sentence.
SST-2: Stanford Sentiment Treebank (Socher et al., 2013) requires determining if a movie review has positive or negative
sentiment.
CoLA: Corpus of Linguistic Acceptability (Warstadt et al., 2019) requires determining whether a given sentence is
linguistically acceptable or not.
16

--- PAGE 17 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Table 7: Prompts used for GPT3Mix augmentation. For sequence-pair tasks, x1andx2denote the Ô¨Årst and second input
sequence, respectively. For single-sequence tasks, xdenotes the input sequence. ydenotes the label name. Only one
example is shown in the template for clarity; in practice, we concatenate k= 4samples according to the optimal setting in
GPT3Mix (Yoo et al., 2021).
Task Template Label name
SST-2Each item in the following list contains a movie review and the respective sentiment. positive: positive
The sentiment is one of ‚Äòpositive‚Äô or ‚Äònegative‚Äô. negative: negative
Movie review: x(Sentiment:y):::
CoLAEach item in the following list contains a text and the respective grammar. grammatical: correct
The grammar is one of ‚Äòcorrect‚Äô or ‚Äòincorrect‚Äô. not grammatical: incorrect
Text:x(Grammar:y):::
MNLIEach item in the following list contains a premise, a hypothesis and their logical relation. entailment: entailment
The logical relation is one of ‚Äòentailment‚Äô, ‚Äòneutral‚Äô or ‚Äòcontradiction‚Äô. neutral: neutral
Premise:x1Hypothesis:x2(Logical relation: y)::: contradiction: contradiction
QNLIEach item in the following list contains a question, an answer and their logical relation. entailment: entailment
The logical relation is one of ‚Äòentailment‚Äô or ‚Äòneutral‚Äô. not entailment: neutral
Question:x1Answer:x2(Logical relation: y):::
RTEEach item in the following list contains a premise, a hypothesis and their logical relation. entailment: entailment
The logical relation is one of ‚Äòentailment‚Äô or ‚Äòneutral‚Äô. not entailment: neutral
Premise:x1Hypothesis:x2(Logical relation: y):::
MRPCEach item in the following list contains two sentences and their semantic relation. equivalent: equivalent
The semantic relation is one of ‚Äòequivalent‚Äô or ‚Äòdifferent‚Äô. not equivalent: different
Sentence 1:x1Sentence 2:x2(Semantic relation: y):::
QQPEach item in the following list contains two questions and their semantic relation. equivalent: equivalent
The semantic relation is one of ‚Äòequivalent‚Äô or ‚Äòdifferent‚Äô. not equivalent: different
Question 1:x1Question 2:x2(Semantic relation: y):::
RTE: Recognizing Textual Entailment (Bentivogli et al., 2009; Dagan et al., 2005; Giampiccolo et al., 2007; Haim et al.,
2006) requires predicting whether a given premise sentence entails a given hypothesis sentence or not.
MRPC: Microsoft Research Paraphrase Corpus (Dolan & Brockett, 2005) requires predicting whether two sentences are
semantically equivalent or not.
E. Data Augmentation Baseline Details
Details About MixText (Chen et al., 2020). We use the TMix version of MixText to perform data interpolation on
the few-shot labeled dataset (since there is no access to unlabeled task-speciÔ¨Åc data under the strict few-shot learning
setting (Gao et al., 2021)). We adapt the label mix-up operation to Ô¨Åt prompt-based Ô¨Åne-tuning by interpolating the label
words instead of categorical labels; we observe that this results in better few-shot performance than the original TMix,
probably analogous to why prompt-based Ô¨Åne-tuning outperforms standard Ô¨Åne-tuning for few-shot learning. We train the
classiÔ¨Åer with supervised loss combined with consistency loss over the interpolated samples as in the original paper. We
follow the default hyperparameters in MixText.
Details About Back Translation. We use two trained Marian (Junczys-Dowmunt et al., 2018) models to perform data
augmentation via back translation. We translate our labeled examples from English to French, and then back to English. As
in UDA (Xie et al., 2020), we employ random sampling with a tunable temperature to generate a diverse set of derivative
examples. We generate 32examples from each few-shot training example and let the synthesized samples share the same
label with the original few-shot training sample. After combining with the original examples, we Ô¨Åne-tune the classiÔ¨Åer and
observe performance.
Details About GPT3Mix (Yoo et al., 2021). We use the 175B GPT3 model for generating the augmentations. For
creating each augmentation, we randomly sample k= 4(the optimal setting according to GPT3Mix) examples from the
few-shot training set as demonstrations. The prompts follow the suggested format proposed in the original paper (Yoo et al.,
17

--- PAGE 18 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
2021) and are shown in Table 7. We create 5;000augmented samples per label to make the resulting training set size equal
to that of FewGen. After obtaining the augmented examples and their pseudo labels (the probability predictions over all
labels by GPT3), we use them along with the real few-shot samples for Ô¨Åne-tuning the classiÔ¨Åer, following the setting in
GPT3Mix (Yoo et al., 2021).
Details About Standard Generator Fine-Tuning. We Ô¨Åne-tune the same 1:6B CTRL (Keskar et al., 2019) model as
used in FewGen with the standard maximum likelihood objective. Different from previous studies (Anaby-Tavor et al.,
2020; Kumar et al., 2020) that prepend categorical labels to the training samples, we enhance the generator Ô¨Åne-tuning with
label-descriptive prompts (shown in Table 5) used in FewGen. We create 5;000augmented samples per label to make the
resulting training set size equal to that of FewGen.
F. Concrete Generation Results
We present some concrete generation results (from Dgen) for all tasks in Tables 8, 9, 10, 11, 12, 13, and 14. To compare Dgen
withDtrain, we also show the few-shot training samples ( Dtrain) of SST-2 in Table 15,
Comparing Tables 8 with 15, it can be seen that the synthetic samples are accurate and quite different from the given training
samples to serve as effective augmentations. For sequence-pair tasks, because we randomly sample the Ô¨Årst sequence from
the pretraining corpus and let the generator create the second sequence given certain labels, the resulting generated samples
will be certainly different from the given training samples.
Table 8: Examples of concrete generations for SST-2.
Example Label Generated Text
#1positive i was a bit skeptical when i Ô¨Årst saw the trailer for this movie, but after watching it, it was quite enjoyable.
negative i was expecting a fun and entertaining movie with some nice special effects, but instead it was just plain boring.
#2positivethat is, a Ô¨Ålm that has the potential to move an audience to tears, or at least to a state of mind where
you feel something.
negativea Ô¨Ålm that has the potential to be one of the most moving and powerful experiences ever made
is instead marred by an unfocused script, bad acting and a lack of emotional depth.
#3positive this is a good movie ‚Äì it‚Äôs not just for people who like to see things blow up or have explosions or shoot guns.
negative i am a big fan of the Ô¨Årst two movies but this one is just plain bad.
Table 9: Examples of concrete generations for CoLA.
Example Label Generated Text
#1grammatical Between the two of us, I think you have a good chance to make it to the Ô¨Ånals.
not grammaticalA few weeks later we saw them on television. We thought there were a hundred more.
It wasn‚Äôt that they came out one at time.
#2grammatical Doing the dishes is a task that I have to do because I am not allowed to go out and play with my friends.
not grammatical Only those whose lives depend on it, but only when you are at its mercy do it harm.
#3grammatical To be able to speak the language of the other person is a prerequisite for communication.
not grammatical The only good way to avoid getting into trouble for being too friendly would to let me go on a trip.
18

--- PAGE 19 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Table 10: Examples of concrete generations for QQP. The Ô¨Årst question ( italicized ) is randomly sampled from the pretraining
corpus; the second question (underlined ) is generated by Gp.
Example Label Generated Text
#1equivalentQuestion 1: How long does it take for a project to be completed?
Question 2: How long does it take to complete a project?
not equivalentQuestion 1: How long does it take for a project to be completed?
Question 2: What is the total cost of completing this project?
#2equivalentQuestion 1: What mascots or characters would you like to see included as
Super Mario Maker DLC in the future?
Question 2: What would you like to see in Super Mario Maker DLC that
you did not see in the game?
not equivalentQuestion 1: What mascots or characters would you like to see included as
Super Mario Maker DLC in the future?
Question 2: How do I get a copy of this game?
Table 11: Examples of concrete generations for MNLI. The Ô¨Årst sentence ( italicized ) is randomly sampled from the
pretraining corpus; the second sentence (underlined ) is generated by Gp.
Example Label Generated Text
#1entailmentSentence 1: Air is provided for the combustion by an electric blower.
Sentence 2: The blower provides air to a combustion chamber.
neutralSentence 1: Air is provided for the combustion by an electric blower.
Sentence 2: Electric blowers are available in most gas stations.
contradictionSentence 1: Air is provided for the combustion by an electric blower.
Sentence 2: The blower does not work.
#2entailmentSentence 1: Since its base is almost at sea level, it is only the 15th highest light
in the United States, the Ô¨Årst 14 being built on higher ground.
Sentence 2: It is the 15th highest light in the United States.
neutralSentence 1: Since its base is almost at sea level, it is only the 15th highest light
in the United States, the Ô¨Årst 14 being built on higher ground.
Sentence 2: The lighthouse was originally constructed to be a beacon for ships
passing by and as such has been used since before World War II.
contradictionSentence 1: Since its base is almost at sea level, it is only the 15th highest light
in the United States, the Ô¨Årst 14 being built on higher ground.
Sentence 2: It is located on a mountain top.
Table 12: Examples of concrete generations for QNLI. The question ( italicized ) is randomly sampled from the pretraining
corpus; the answer (underlined ) is generated by Gp.
Example Label Generated Text
#1entailmentQuestion: What makes you want to step up to the next level?
Answer: I want to be the best player I can be.
not entailmentQuestion: What makes you want to step up to the next level?
Answer: The new program will be called ‚ÄùProject 10‚Äù and it is expected that a total
of $450 million in federal funding would go toward it.
#2entailmentQuestion: How do all those shops know what you would like to buy?
Answer: The stores are able to track your preferences and provide you with a list
of products that are best for you.
not entailmentQuestion: How do all those shops know what you would like to buy?
Answer: The stores are not required by law or regulation in the United States and Canada
but they have been known for years as a source of illegal sales on eBay.
19

--- PAGE 20 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Table 13: Examples of concrete generations for RTE. The Ô¨Årst sentence ( italicized ) is randomly sampled from the pretraining
corpus; the second sentence (underlined ) is generated by Gp.
Example Label Generated Text
#1entailmentSentence 1: In 1970, the Science Council of Canada recommended that the government
of Canada immediately invest in industrial development of the aviation industry,
including construction of aircraft, navigation aids, and regulation of air trafÔ¨Åc.
Sentence 2: The government of Canada has invested in the aviation industry.
not entailmentSentence 1: In 1970, the Science Council of Canada recommended that the government
of Canada immediately invest in industrial development of the aviation industry,
including construction of aircraft, navigation aids, and regulation of air trafÔ¨Åc.
Sentence 2: The Aviation Industry was established by a Royal Decree on June 1, 1970.
#2entailmentSentence 1: All of the Centre‚Äôs staff are Ô¨Çuently bilingual in both English and Chinese
and are familiar with the traditions of the Chinese culture.
Sentence 2: The Centre is a bilingual institution.
not entailmentSentence 1: All of the Centre‚Äôs staff are Ô¨Çuently bilingual in both English and Chinese
and are familiar with the traditions of the Chinese culture.
Sentence 2: The Centre is a cultural centre for learning about China.
Table 14: Examples of concrete generations for MRPC. The Ô¨Årst sentence ( italicized ) is randomly sampled from the
pretraining corpus; the second sentence (underlined ) is generated by Gp.
Example Label Generated Text
#1entailmentSentence 1: It embodies the aesthetic ideals of the Queen Anne style through its design
and detailing and shows the type of house that attracted prosperous Napans
at the end of the Victorian era.
Sentence 2: It is a Ô¨Åne example of the Queen Anne style of architecture through its design
and detailing and shows the type of house that attracted prosperous Napans
at the end of the Victorian era.
not entailmentSentence 1: It embodies the aesthetic ideals of the Queen Anne style through its design
and detailing and shows the type of house that attracted prosperous Napans
at the end of the Victorian era.
Sentence 2: The building is a Ô¨Åne example in this style, with an elegant facade reminiscent
to those found on many grand mansions built by wealthy merchants during
America‚Äôs Gilded Age.
#2entailmentSentence 1: Crosbie ran unsuccessfully for the leadership of the Liberal Party of Newfoundland
and Labrador in 1969, losing to Smallwood, and was also a candidate in the
Progressive Conservative Party of Canada‚Äôs 1983 leadership election, placing third.
Sentence 2: Crosbie was a candidate in the Progressive Conservative Party of Canada‚Äôs 1983
leadership election, placing third.
not entailmentSentence 1: Crosbie ran unsuccessfully for the leadership of the Liberal Party of Newfoundland
and Labrador in 1969, losing to Smallwood, and was also a candidate in the
Progressive Conservative Party of Canada‚Äôs 1983 leadership election, placing third.
Sentence 2: He lost his bid as leader after he failed twice at running against John Diefenbaker.
20

--- PAGE 21 ---
Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning
Table 15: 16-shot training samples of SST-2.
Label Example Review Text
positive#1(ramsay) visually transforms the dreary expanse of dead-end distaste the characters inhabit into a poem of art ,
music and metaphor .
#2 the Ô¨Ålm jolts the laughs from the audience ‚Äì as if by cattle prod .
#3the Ô¨Ålm presents visceral and dangerously honest revelations about the men and machines behind the curtains
of our planet .
#4 a Ô¨Ålm that will enthrall the whole family .
#5serious movie-goers embarking upon this journey will Ô¨Ånd that the road to perdition leads to a satisfying
destination .
#6 sweet and memorable Ô¨Ålm .
#7shyamalan takes a potentially trite and overused concept (aliens come to earth) and infuses it into a
rustic , realistic , and altogether creepy tale of hidden invasion .
#8a crisp psychological drama (and) a fascinating little thriller that would have been perfect for an old
‚Äú twilight zone ‚Äù episode .
#9my big fat greek wedding is not only the best date movie of the year , it ‚Äôs also a ‚Äì dare i say it twice
‚Äì delightfully charming ‚Äì and totally american , i might add ‚Äì slice of comedic bliss .
#10a comedy-drama of nearly epic proportions rooted in a sincere performance by the title character undergoing
midlife crisis .
#11 diggs and lathan are among the chief reasons brown sugar is such a sweet and sexy Ô¨Ålm .
#12 you ‚Äôre not merely watching history , you ‚Äôre engulfed by it .
#13 the concept is a hoot .
#14the Ô¨Ålmmakers ‚Äô eye for detail and the high standards of performance convey a strong sense of the
girls ‚Äô environment .
#15 a haunting tale of murder and mayhem .
#16neil burger here succeeded in ... making the mystery of four decades back the springboard for a more
immediate mystery in the present .
negative#1 nothing happens , and it happens to Ô¨Çat characters .
#2 as lively an account as seinfeld is deadpan .
#3so we got ten little indians meets friday the 13th by way of clean and sober , Ô¨Ålmed on the set of carpenter ‚Äôs
the thing and loaded with actors you ‚Äôre most likely to Ô¨Ånd on the next inevitable incarnation of the love boat .
#4the plot is nothing but boilerplate cliches from start to Ô¨Ånish , and the script assumes that not only would
subtlety be lost on the target audience , but that it ‚Äôs also too stupid to realize that they ‚Äôve already seen this
exact same movie a hundred times
#5ultimately , sarah ‚Äôs dedication to Ô¨Ånding her husband seems more psychotic than romantic , and nothing in
the movie makes a convincing case that one woman ‚Äôs broken heart outweighs all the loss we witness .
#6the big Ô¨Ånish is a bit like getting all excited about a chocolate eclair and then biting into it and Ô¨Ånding
the Ô¨Ålling missing .
#7this picture is mostly a lump of run-of-the-mill profanity sprinkled with a few remarks so geared toward
engendering audience sympathy that you might think he was running for ofÔ¨Åce ‚Äì or trying to win over a
probation ofÔ¨Åcer .
#8just because a walk to remember is shrewd enough to activate girlish tear ducts does n‚Äôt mean it ‚Äôs good enough
for our girls .
#9 often lingers just as long on the irrelevant as on the engaging , which gradually turns what time is it there ?
#10 this movie , a certain scene in particular , brought me uncomfortably close to losing my lunch .
#11 but it would be better to wait for the video .
#12a rude black comedy about the catalytic effect a holy fool has upon those around him in the cutthroat world
of children ‚Äôs television .
#13 just a collection of this and that ‚Äì whatever Ô¨Ålls time ‚Äì with no uniÔ¨Åed whole .
#14although god is great addresses interesting matters of identity and heritage , it ‚Äôs hard to shake the feeling
that it was intended to be a different kind of Ô¨Ålm .
#15 the chocolate factory without charlie .
#16 in that setting , their struggle is simply too ludicrous and borderline insulting .
21

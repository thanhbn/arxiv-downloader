# Điều chỉnh Tham số Hiệu quả Thị giác Có Nhận thức Độ Nhạy

## Tóm tắt

Điều chỉnh Tham số Hiệu quả Thị giác (PEFT) đã trở thành một giải pháp mạnh mẽ thay thế cho việc điều chỉnh toàn bộ để thích ứng các mô hình thị giác được đào tạo trước với các tác vụ downstream, chỉ điều chỉnh một số lượng nhỏ tham số trong khi đóng băng phần lớn để giảm gánh nặng lưu trữ và khó khăn tối ưu hóa. Tuy nhiên, các phương pháp PEFT hiện tại giới thiệu tham số có thể huấn luyện vào cùng các vị trí trên các tác vụ khác nhau chỉ dựa vào kinh nghiệm của con người và bỏ qua khoảng cách miền. Để giải quyết điều này, chúng tôi nghiên cứu vị trí giới thiệu và cách phân bổ tham số có thể huấn luyện bằng cách đề xuất một sơ đồ Điều chỉnh Tham số Hiệu quả Thị giác Có Nhận thức Độ Nhạy (SPT) mới, phân bổ thích ứng tham số có thể huấn luyện vào các vị trí quan trọng cụ thể cho tác vụ với ngân sách tham số điều chỉnh được mong muốn. Cụ thể, SPT của chúng tôi đầu tiên nhanh chóng xác định các tham số nhạy cảm cần điều chỉnh cho một tác vụ nhất định theo cách phụ thuộc dữ liệu. Tiếp theo, SPT của chúng tôi tiếp tục tăng cường khả năng biểu diễn cho các ma trận trọng số có số lượng tham số nhạy cảm vượt quá ngưỡng xác định trước bằng cách sử dụng các phương pháp điều chỉnh có cấu trúc hiện có, ví dụ như LoRA hoặc Adapter, để thay thế việc điều chỉnh trực tiếp các tham số nhạy cảm được chọn (điều chỉnh không có cấu trúc) trong ngân sách. Các thí nghiệm rộng rãi trên nhiều tác vụ nhận dạng downstream cho thấy SPT của chúng tôi bổ sung cho các phương pháp PEFT hiện có và cải thiện đáng kể hiệu suất của chúng, ví dụ như SPT cải thiện Adapter với backbone ViT-B/16 được đào tạo trước có giám sát lần lượt 4.2% và 1.4% độ chính xác Top-1 trung bình, đạt hiệu suất SOTA trên các benchmark FGVC và VTAB-1k. Mã nguồn tại https://github.com/ziplab/SPT.

## 1. Giới thiệu

Để thích ứng hiệu quả các biểu diễn được đào tạo trước với các tác vụ downstream, lựa chọn thực tế là điều chỉnh toàn bộ, khởi tạo mô hình với trọng số được đào tạo trước và điều chỉnh tất cả tham số. Tuy nhiên, việc điều chỉnh toàn bộ thông thường cần lưu trữ một phiên bản tham số riêng biệt cho mỗi tác vụ và mỗi tình huống triển khai. Điều này có thể cực kỳ tốn kém về mặt lưu trữ vì chi phí lưu trữ tăng tuyến tính theo số lượng trường hợp có thể, xem xét có nhiều loại tác vụ downstream và môi trường triển khai động, đặc biệt khi triển khai các mô hình thị giác lớn lên hệ thống di động. Ví dụ, chỉ lưu trữ một mô hình ViT-H được đào tạo trước lớn trên đĩa cục bộ cần ít nhất 2.3GB, trong khi Top-10 ứng dụng Mỹ chỉ cần tổng cộng 2.2GB vào tháng 5/2021.

Một giải pháp mới nổi đáng chú ý là thay thế việc điều chỉnh thông thường bằng Điều chỉnh Tham số Hiệu quả Thị giác (PEFT), chỉ điều chỉnh một số lượng nhỏ tham số có thể huấn luyện trong khi đóng băng phần lớn được chia sẻ bởi nhiều tác vụ. Vì các phương pháp PEFT có ít hơn 1% tham số có thể huấn luyện, gánh nặng lưu trữ được giảm đáng kể. Một tính chất hấp dẫn khác của PEFT là điều chỉnh ít tham số hơn làm giảm khó khăn tối ưu hóa và giảm thiểu vấn đề overfitting khi thích ứng các mô hình được đào tạo trước lớn trên tập dữ liệu mục tiêu, từ đó đạt được hiệu suất tương đương hoặc thậm chí tốt hơn so với điều chỉnh thông thường. Mặc dù triển vọng, các phương pháp PEFT hiện tại giới thiệu tham số có thể huấn luyện vào cùng các vị trí cho tất cả tác vụ downstream, dựa vào kinh nghiệm của con người và bỏ qua khoảng cách miền và đặc điểm cụ thể của tác vụ, điều này hạn chế hiệu suất của chúng.

Để giải quyết thách thức cơ bản này, chúng tôi khám phá vị trí giới thiệu và cách phân bổ tham số có thể huấn luyện dưới ngân sách tham số mong muốn bằng cách trình bày sơ đồ Điều chỉnh Tham số Hiệu quả Thị giác Có Nhận thức Độ Nhạy (SPT) mới xác định các vị trí quan trọng cụ thể của tác vụ để phân bổ thích ứng tham số có thể huấn luyện. Vì trọng số được đào tạo trước tại các vị trí khác nhau có đóng góp khác nhau cho các tác vụ downstream khác nhau, chúng tôi đầu tiên đề xuất một tiêu chí mới để nhanh chóng xác định các tham số nhạy cảm cụ thể của tác vụ cần điều chỉnh theo cách phụ thuộc dữ liệu. Lấy cảm hứng từ các phép đo cắt tỉa mô hình, chúng tôi đề xuất đo độ nhạy tham số bằng việc giảm mất mát khi được điều chỉnh, có thể được xấp xỉ bằng khai triển Taylor bậc nhất có được trong một lần forward và backward duy nhất trước khi điều chỉnh. Tiêu chí độ nhạy của chúng tôi đơn giản và hiệu quả, có thể xác định các vị trí quan trọng cụ thể của tác vụ để giới thiệu tham số có thể huấn luyện cho bất kỳ backbone nào một cách nhanh chóng.

Với tiêu chí của chúng tôi, chúng tôi quan sát thực nghiệm rằng tỷ lệ các tham số độ nhạy cho mỗi block thực sự thay đổi đáng kể giữa các tác vụ khác nhau. Để phân bổ tham số có thể huấn luyện dưới ngân sách tham số có thể huấn luyện mong muốn, một giải pháp trực quan là điều chỉnh trực tiếp các kết nối trọng số nhạy cảm nhất, mà chúng tôi gọi là điều chỉnh không có cấu trúc. Mặc dù đơn giản và linh hoạt, điều chỉnh không có cấu trúc chỉ điều chỉnh một số ít tham số vẫn thiếu khả năng biểu diễn và khó khăn trong việc thu hẹp khoảng cách miền. Để giải quyết điều này, chúng tôi đề xuất tiếp tục kết hợp điều chỉnh có cấu trúc để thay thế điều chỉnh không có cấu trúc tại các ma trận trọng số nhạy cảm có số lượng tham số nhạy cảm vượt quá ngưỡng xác định trước để cải thiện khả năng biểu diễn dưới ngân sách tham số tương tự.

Điều chỉnh có cấu trúc có thể được thực hiện bằng bất kỳ phương pháp điều chỉnh có cấu trúc hiệu quả tham số nào hiện có điều chỉnh trực tiếp các biểu diễn ẩn, ví dụ như chèn một module adapter tuần tự sau các ma trận trọng số nhạy cảm. Do đó, SPT của chúng tôi thích ứng kết hợp cả độ chi tiết điều chỉnh không có cấu trúc và có cấu trúc và phân bổ tham số có thể huấn luyện với tính linh hoạt cao và khả năng biểu diễn cho mỗi tác vụ downstream riêng biệt.

Bài báo này có những đóng góp chính sau đây: 1) Chúng tôi thực hiện khám phá tiên phong để xác định các vị trí quan trọng cụ thể của tác vụ dưới cài đặt PEFT, nhanh chóng, hiệu quả, đa năng để áp dụng cho các backbone khác nhau với các chiến lược đào tạo trước khác nhau, và trực giao với các phương pháp PEFT hiện có. 2) Dựa trên tiêu chí độ nhạy, chúng tôi đề xuất chiến lược phân bổ tham số có thể huấn luyện thích ứng kết hợp cả điều chỉnh không có cấu trúc và có cấu trúc dưới ngân sách tham số mong muốn để đạt được tính linh hoạt cao, dung lượng lớn và sự đánh đổi thuận lợi giữa hiệu quả tham số và độ chính xác. 3) Các thí nghiệm rộng rãi trên tổng cộng 24 tác vụ nhận dạng downstream với cả backbone vision Transformer phẳng và phân cấp dưới đào tạo trước có giám sát và tự giám sát cho thấy SPT của chúng tôi bổ sung cho các phương pháp PEFT hiện có và tăng hiệu suất của chúng với biên độ lớn.

## 2. Công trình liên quan

**Điều chỉnh hiệu quả tham số.** Điều chỉnh toàn bộ là phương pháp phổ biến nhất khi thích ứng mô hình được đào tạo trước quy mô lớn với các tác vụ downstream, nơi mô hình được khởi tạo từ trọng số được đào tạo trước với tất cả tham số có thể huấn luyện. Tuy nhiên, khi mô hình trở nên lớn hơn, điều chỉnh hiệu quả tham số rất được mong muốn, chỉ điều chỉnh một phần nhỏ tham số để giảm bớt gánh nặng lưu trữ. Các phương pháp PEFT chung có thể được phân loại thành các phương pháp PEFT dựa trên phép cộng và các phương pháp PEFT dựa trên tham số hóa lại.

PEFT dựa trên phép cộng gắn các tham số có thể huấn luyện bổ sung vào backbone và chỉ điều chỉnh các tham số này. Ngoài Prompt tuning và Adapter, các phương pháp dựa trên phép cộng gần đây nghiên cứu kết nối hoặc kết hợp các phương pháp PEFT hiện có. Vì các tham số bổ sung cần tính toán thêm so với điều chỉnh toàn bộ, một số công trình gần đây thiết kế kiến trúc cụ thể để tránh lưu trữ các kích hoạt trung gian, từ đó giảm bớt chi phí bộ nhớ điều chỉnh.

PEFT dựa trên tham số hóa lại nhằm tránh chi phí tính toán thêm bằng cách điều chỉnh các tham số vốn có hoặc có thể được tham số hóa lại vào backbone trong quá trình suy luận. Các công trình trước chọn các tham số vốn có trong backbone, bao gồm các thuật ngữ bias, vài lớp cuối cùng, và các kết nối trọng số. Để tham số hóa lại các tham số mới vào backbone, công trình đại diện LoRA tối ưu hóa hai ma trận low-rank có thể được hợp nhất thêm vào các ma trận trọng số. Trái ngược với các công trình đã nêu, chúng tôi lập luận tầm quan trọng của việc điều chỉnh tham số tại các vị trí quan trọng cụ thể của tác vụ và nhanh chóng xác định chúng với tiêu chí độ nhạy tham số được đề xuất trước khi điều chỉnh, bổ sung và cung cấp hướng dẫn có giá trị cho các phương pháp PEFT hiện có.

**Học chuyển giao cụ thể tác vụ.** Hiệu quả của việc chuyển giao các mô hình được đào tạo trước sang các tác vụ downstream phụ thuộc mạnh vào mối quan hệ giữa các tác vụ nguồn và đích. Điều này đã thúc đẩy cộng đồng khám phá dữ liệu đào tạo trước tối ưu, mô hình và trọng số cho tác vụ đích. Để tìm kiếm dữ liệu đào tạo trước cụ thể tác vụ phù hợp, một số nghiên cứu chọn dữ liệu miền nguồn từ các lớp tương tự nhất được đo bằng khoảng cách Earth Mover, đánh trọng số mỗi lớp trong miền nguồn bằng học tăng cường, và đầu tiên huấn luyện một tập hợp đa dạng các chuyên gia rồi chọn chuyên gia phù hợp nhất cho mỗi tác vụ đích.

## 3. Phương pháp

Điều chỉnh hiệu quả tham số thị giác có nhận thức độ nhạy của chúng tôi bao gồm hai giai đoạn. Trong giai đoạn đầu tiên, SPT đo độ nhạy cụ thể tác vụ cho các tham số được đào tạo trước. Dựa trên độ nhạy tham số và ngân sách tham số nhất định, SPT sau đó phân bổ thích ứng tham số có thể huấn luyện vào các vị trí quan trọng cụ thể tác vụ.

### 3.1. Độ nhạy tham số cụ thể tác vụ

Nghiên cứu gần đây đã quan sát thấy rằng các tham số backbone được đào tạo trước thể hiện các mẫu đặc trưng khác nhau và tính quan trọng tại các vị trí riêng biệt. Hơn nữa, khi được chuyển giao sang các tác vụ downstream, hiệu quả của chúng thay đổi tùy thuộc vào mức độ tái sử dụng các đặc trưng được đào tạo trước và mức độ thích ứng tốt với khoảng cách miền cụ thể. Được thúc đẩy bởi những quan sát này, chúng tôi lập luận rằng không phải tất cả tham số đều đóng góp như nhau cho hiệu suất trên các tác vụ khác nhau trong PEFT và đề xuất một tiêu chí mới để đo độ nhạy của các tham số trong backbone được đào tạo trước cho một tác vụ nhất định.

Cụ thể, với tập dữ liệu huấn luyện cho tác vụ thứ t và trọng số mô hình được đào tạo trước, mục tiêu cho tác vụ là tối thiểu hóa rủi ro thực nghiệm. Chúng tôi ký hiệu tập độ nhạy tham số và độ nhạy cho tham số được đo bằng sự khác biệt rủi ro thực nghiệm khi điều chỉnh nó.

Tuy nhiên, việc tính toán này vẫn tốn kém về mặt tính toán vì hai lý do. Thứ nhất, việc có được rủi ro thực nghiệm cho N tham số cần forward toàn bộ mạng N lần, rất tốn thời gian. Thứ hai, khó có được cập nhật vì phải điều chỉnh từng tham số riêng lẻ cho đến khi hội tụ.

Để vượt qua rào cản đầu tiên, chúng tôi đơn giản hóa mất mát thực nghiệm bằng cách xấp xỉ trong lân cận bằng khai triển Taylor bậc nhất. Để giải quyết rào cản thứ hai, chúng tôi lấy trọng số một bước như là đại diện cho trọng số tối ưu và xấp xỉ với một bước gradient descent duy nhất. Do đó, độ nhạy của một tham số có thể được đo hiệu quả bằng tiềm năng giảm mất mát trên miền đích.

Trong thực tế, chúng tôi tích lũy độ nhạy từ tổng số C mẫu huấn luyện trước khi điều chỉnh để tạo ra độ nhạy chính xác, trong đó C là một siêu tham số xác định trước.

### 3.2. Phân bổ tham số có thể huấn luyện thích ứng

Bước tiếp theo của chúng tôi là phân bổ tham số có thể huấn luyện dựa trên tập độ nhạy tham số thu được và ngân sách tham số mong muốn. Một giải pháp đơn giản là điều chỉnh trực tiếp các kết nối không có cấu trúc nhạy cảm nhất (tham số) trong khi giữ phần còn lại đóng băng, mà chúng tôi gọi là điều chỉnh không có cấu trúc.

Tuy nhiên, xem xét các phương pháp PEFT thường giới hạn tỷ lệ tham số có thể huấn luyện dưới 1%, việc chỉ điều chỉnh một số lượng nhỏ kết nối trọng số không có cấu trúc có thể không có đủ khả năng biểu diễn để xử lý các tập dữ liệu downstream có khoảng cách miền lớn từ dữ liệu đào tạo trước nguồn. Do đó, để cải thiện khả năng biểu diễn, chúng tôi đề xuất thay thế điều chỉnh không có cấu trúc bằng điều chỉnh có cấu trúc tại các ma trận trọng số nhạy cảm có số lượng tham số nhạy cảm cao.

Theo cách này, SPT của chúng tôi thích ứng kết hợp cả độ chi tiết điều chỉnh có cấu trúc và không có cấu trúc để cho phép tính linh hoạt cao hơn và sức mạnh biểu diễn mạnh hơn, đồng thời.

## 4. Thí nghiệm

### 4.1. Thiết lập thí nghiệm

**Tập dữ liệu và phép đo.** Chúng tôi đánh giá SPT của mình trên tổng cộng 24 tác vụ downstream trong hai nhóm. 1) FGVC là benchmark cho phân loại thị giác chi tiết, bao gồm các tập dữ liệu CUB-200-2011, NABirds, Oxford Flowers, Stanford Cars và Stanford Dogs. 2) VTAB-1k là benchmark học chuyển giao quy mô lớn bao gồm tập hợp 19 tác vụ phân loại thị giác.

**Backbone được đào tạo trước.** Chúng tôi tiến hành thí nghiệm trên backbone vision Transformer phẳng ViT-B/16 được đào tạo trước trên ImageNet với các chiến lược đào tạo trước khác nhau, bao gồm đào tạo trước có giám sát và đào tạo trước tự giám sát với MAE và MoCo v3. Chúng tôi cũng tiến hành thí nghiệm trên backbone vision Transformer phân cấp đại diện Swin-B dưới đào tạo trước có giám sát.

**Đối thủ cạnh tranh.** Chúng tôi phân loại các phương pháp baseline thành các phương pháp PEFT dựa trên phép cộng và dựa trên tham số hóa lại. Các phương pháp dựa trên phép cộng cần tính toán thêm trong quá trình suy luận, bao gồm MLP-k, PROMPT-SHALLOW, PROMPT-DEEP, ADAPTER-k, ADAPTFORMER và NOAH. Các phương pháp dựa trên tham số hóa lại không có chi phí tính toán bổ sung trong quá trình suy luận, bao gồm LINEAR, PARTIAL-k, BIAS và LORA-k.

### 4.2. Kết quả chính

**Nhận dạng thị giác với backbone ViT.** Đầu tiên, SPT-ADAPTER và SPT-LORA được đề xuất của chúng tôi đạt được hiệu suất tốt nhất dưới các ngân sách tham số có thể huấn luyện khác nhau với backbone ViT-B/16 được đào tạo trước có giám sát. Chúng tôi suy đoán rằng các biến thể SPT của chúng tôi phân bổ tham số có thể huấn luyện tại các vị trí cụ thể tác vụ so với các vị trí được chọn theo kinh nghiệm trong các phương pháp baseline, điều này góp phần vào hiệu suất vượt trội của chúng tôi.

Thứ hai, các biến thể SPT vượt trội hơn các phương pháp baseline và điều chỉnh toàn bộ với biên độ đáng kể với các backbone ViT-B/16 được đào tạo trước tự giám sát. Đáng chú ý là các phương pháp PEFT trước đây cho kết quả không nhất quán với các backbone có chiến lược đào tạo trước khác nhau. Ngược lại, các biến thể SPT luôn vượt trội hơn điều chỉnh toàn bộ.

**Nhận dạng thị giác với backbone Swin và ConvNeXt.** Chúng tôi quan sát thấy SPT-LORA và SPT-ADAPTER của chúng tôi cũng đạt được hiệu suất SOTA với backbone Swin-B trên tất cả các nhóm tập dữ liệu. Chúng tôi cũng áp dụng các biến thể SPT cho kiến trúc giống ResNet ConvNeXt-Base. Chúng tôi quan sát thấy các biến thể SPT đạt được sự đánh đổi tốt hơn giữa độ chính xác và hiệu quả tham số so với các phương pháp baseline.

**Phân đoạn ngữ nghĩa.** Chúng tôi tiến hành phân đoạn ngữ nghĩa trên tập dữ liệu ADE20k. Đáng chú ý, SPT-LORA và SPT-ADAPTER vượt trội hơn các phương pháp baseline với biên độ lớn, cho thấy SPT của chúng tôi có thể được tổng quát hóa cho tác vụ phân đoạn ngữ nghĩa.

### 4.3. Nghiên cứu loại bỏ

**Hiệu quả của tiêu chí độ nhạy.** Chúng tôi điều tra hiệu quả của tiêu chí độ nhạy của mình trên VTAB-1k bằng cách áp dụng các phương pháp điều chỉnh có cấu trúc vào các ma trận trọng số nhạy cảm cụ thể tác vụ. Tiêu chí của chúng tôi mang lại cải thiện hiệu suất nhất quán, chứng minh tính hiệu quả và tính đa năng của tiêu chí độ nhạy để xác định các vị trí quan trọng cụ thể tác vụ chính xác.

**Hiệu quả của điều chỉnh có cấu trúc và không có cấu trúc.** Chúng tôi điều tra hiệu quả của điều chỉnh không có cấu trúc và có cấu trúc riêng lẻ trên VTAB-1k. Chúng tôi quan sát thấy rằng điều chỉnh có cấu trúc đặc biệt quan trọng để đạt được hiệu suất tốt trên các tập dữ liệu Structured. Chúng tôi suy đoán rằng các tập dữ liệu Structured có khoảng cách miền lớn hơn từ miền đào tạo trước nguồn so với các tập dữ liệu Natural và Specialized. Cuối cùng, chúng tôi quan sát thấy rằng việc kết hợp cả điều chỉnh có cấu trúc và không có cấu trúc tại các vị trí quan trọng cụ thể tác vụ đạt được hiệu suất cao nhất trên tất cả các nhóm tập dữ liệu.

### 4.4. Quan sát về các mẫu độ nhạy

Tiêu chí độ nhạy của chúng tôi xác định các vị trí quan trọng cụ thể tác vụ, có thể tiết lộ đóng góp của trọng số được đào tạo trước cho các tác vụ downstream khác nhau trong quá trình học chuyển giao. Chúng tôi trực quan hóa tỷ lệ các tham số nhạy cảm cho backbone ViT-B/16 được đào tạo trước có giám sát dưới ngân sách tham số có thể huấn luyện 0.4M.

Đầu tiên, chúng tôi điều tra các block nhạy cảm nhất, có số lượng tham số nhạy cảm được tổng hợp và chuẩn hóa qua 12 block ViT-B/16. Chúng tôi quan sát thấy rằng các mẫu tỷ lệ tham số nhạy cảm thay đổi đáng kể giữa các tác vụ khác nhau. Điều này gợi ý rằng chúng ta không nên giới thiệu tham số có thể huấn luyện vào cùng các vị trí cho mỗi tác vụ riêng lẻ mà phân bổ tham số có thể huấn luyện tại các vị trí cụ thể tác vụ như chúng tôi đề xuất.

Tiếp theo, chúng tôi điều tra các ma trận trọng số ít nhạy cảm nhất trong một block. Một block ViT bao gồm các ma trận trọng số query, key, value và output trong lớp multi-head self-attention và hai ma trận trọng số trong mạng feed-forward. Chúng tôi quan sát thấy rằng các ma trận trọng số query và key có tỷ lệ tham số nhạy cảm thấp nhất cho tất cả ba tác vụ mẫu. Vì query và key chịu trách nhiệm học các điểm attention cho biết sự tương tự theo cặp giữa các patch, chúng tôi suy đoán rằng mặc dù miền thay đổi, các mối quan hệ patch được học trong quá trình đào tạo trước có thể được tái sử dụng hiệu quả khi chuyển giao sang các tác vụ phân loại downstream.

## 5. Kết luận

Trong bài báo này, chúng tôi đã khám phá việc xác định và phân bổ tham số có thể huấn luyện vào các vị trí quan trọng cụ thể tác vụ cho điều chỉnh hiệu quả tham số thị giác. Cụ thể, chúng tôi đã đề xuất một tiêu chí mới để nhanh chóng đo độ nhạy của các tham số được đào tạo trước cho mỗi tác vụ cụ thể trước khi điều chỉnh. Dựa trên độ nhạy tham số, chúng tôi đã đề xuất chiến lược phân bổ tham số có thể huấn luyện thích ứng kết hợp cả điều chỉnh không có cấu trúc và có cấu trúc dưới ngân sách tham số có thể huấn luyện mong muốn, cho phép khả năng biểu diễn cao và tính linh hoạt. Cuối cùng, chúng tôi đã tiến hành các thí nghiệm rộng rãi trên tổng cộng 24 tác vụ nhận dạng downstream với cả backbone vision Transformer phẳng và phân cấp dưới các chiến lược đào tạo trước khác nhau để chứng minh tính đa năng và hiệu quả của SPT được đề xuất. Đáng chú ý, chúng tôi đã chỉ ra rằng phương pháp của chúng tôi bổ sung cho các phương pháp PEFT hiện có và cải thiện hiệu suất của chúng một cách đáng kể.

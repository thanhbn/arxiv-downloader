# LiST: Việc Tự Huấn Luyện Nhẹ Nhàng Với Gợi Ý Tạo Ra Các Học Viên Few-shot Hiệu Quả Tham Số

Chúng tôi trình bày một phương pháp mới LiST cho việc tinh chỉnh hiệu quả tham số của các mô hình ngôn ngữ lớn đã được tiền huấn luyện (PLM) cho việc học few-shot. LiST cải thiện so với các phương pháp gần đây áp dụng tinh chỉnh dựa trên gợi ý (FN) bằng cách sử dụng hai kỹ thuật chính. Đầu tiên là việc sử dụng tự huấn luyện để tận dụng lượng lớn dữ liệu không nhãn cho FN dựa trên gợi ý trong các thiết lập few-shot. Chúng tôi sử dụng tự huấn luyện kết hợp với meta-learning để tái cân bằng các nhãn giả gợi ý nhiễu. Tự huấn luyện tốn kém vì nó đòi hỏi việc cập nhật tất cả các tham số mô hình một cách lặp lại. Do đó, chúng tôi sử dụng kỹ thuật thứ hai cho việc tinh chỉnh nhẹ nhàng nơi chúng tôi giới thiệu một số lượng nhỏ các tham số cụ thể cho tác vụ được tinh chỉnh trong quá trình tự huấn luyện trong khi giữ bộ mã hóa PLM cố định. Các thí nghiệm của chúng tôi cho thấy LiST có thể hiệu quả tận dụng dữ liệu không nhãn để cải thiện hiệu suất mô hình cho việc học few-shot. Ngoài ra, việc tinh chỉnh là hiệu quả vì nó chỉ cập nhật một tỷ lệ nhỏ các tham số và tổng dung lượng mô hình được giảm vì nhiều tác vụ có thể chia sẻ một bộ mã hóa PLM chung làm xương sống. Một nghiên cứu toàn diện trên sáu tác vụ NLU chứng minh LiST cải thiện 35% so với tinh chỉnh cổ điển và 6% so với FN dựa trên gợi ý với 96% giảm số lượng tham số có thể huấn luyện khi tinh chỉnh với không quá 30 ví dụ có nhãn từ mỗi tác vụ. Với chỉ 14M tham số có thể điều chỉnh, LiST vượt trội hơn GPT-3 in-context learning 33% trên các tác vụ NLU few-shot.

Các mô hình ngôn ngữ lớn đã được tiền huấn luyện (PLM) đã đạt được hiệu suất tốt nhất trong một số tác vụ hiểu ngôn ngữ tự nhiên. Mặc dù thành công đáng kể của chúng trong các thiết lập giám sát đầy đủ, hiệu suất của chúng vẫn chưa thỏa mãn khi tinh chỉnh chỉ với một số ít ví dụ có nhãn. Trong khi các mô hình như GPT-3 đã đạt được hiệu suất few-shot ấn tượng với việc thích ứng tác vụ trong ngữ cảnh, chúng có khoảng cách hiệu suất đáng kể so với các mô hình SoTA giám sát đầy đủ. Ví dụ, hiệu suất few-shot của GPT-3 tệ hơn 20 điểm so với DeBERTa được tinh chỉnh đầy đủ trên SuperGLUE. Điều này đặt ra những thách thức đáng kể cho nhiều tác vụ thực tế nơi dữ liệu có nhãn lớn khó có được.

Trong công việc này, chúng tôi trình bày một phương pháp tinh chỉnh mới LiST nhằm cải thiện khả năng học few-shot so với các chiến lược tinh chỉnh hiện có bằng cách sử dụng hai kỹ thuật như sau.

Kỹ thuật đầu tiên là tận dụng tự huấn luyện với lượng lớn dữ liệu không nhãn từ miền đích để cải thiện việc thích ứng mô hình trong các thiết lập few-shot. Tinh chỉnh dựa trên gợi ý gần đây đã cho thấy những cải thiện đáng kể so với tinh chỉnh cổ điển trong thiết lập học few-shot. Trong bài báo này, chúng tôi chứng minh rằng tự huấn luyện với dữ liệu không nhãn có thể cải thiện đáng kể tinh chỉnh dựa trên gợi ý nơi chúng tôi cập nhật lặp lại một cặp mô hình thầy và học sinh với các gợi ý ngôn ngữ tự nhiên và rất ít ví dụ có nhãn cho tác vụ. Vì thầy không chắc chắn trong thiết lập few-shot tạo ra các nhãn giả nhiễu, chúng tôi tiếp tục sử dụng meta-learning để tái cân bằng các nhãn gợi ý giả.

Tự huấn luyện truyền thống có thể tốn kém nếu chúng ta phải cập nhật tất cả các tham số mô hình một cách lặp lại. Để cải thiện hiệu quả của tự huấn luyện, kỹ thuật chính thứ hai giới thiệu một số lượng nhỏ các tham số bộ điều hợp cụ thể cho tác vụ trong PLM được cập nhật với kỹ thuật trên, trong khi giữ bộ mã hóa PLM lớn cố định. Chúng tôi chứng minh việc điều chỉnh nhẹ nhàng như vậy với tự huấn luyện phù hợp với hiệu suất mô hình nơi tất cả các tham số được điều chỉnh. Điều này cho phép sử dụng hiệu quả tham số của tự huấn luyện và giảm chi phí lưu trữ của mô hình đã tinh chỉnh vì nhiều mô hình đã tinh chỉnh giờ đây có thể chia sẻ cùng một PLM làm xương sống trong quá trình suy luận.

Chúng tôi thực hiện các thí nghiệm rộng rãi trong sáu tác vụ hiểu ngôn ngữ tự nhiên để chứng minh hiệu quả của LiST. Chúng tôi thiết kế một khung đánh giá toàn diện xem xét phương sai trong hiệu suất few-shot của PLM với các shots, seeds ngẫu nhiên và splits khác nhau. Kết quả cho thấy LiST cải thiện so với các phương pháp FN truyền thống và dựa trên gợi ý gần đây hơn lần lượt 35% và 6%, với 96% giảm số lượng tham số có thể huấn luyện chỉ với 30 ví dụ có nhãn cho mỗi tác vụ downstream. Hình 1 cho thấy kết quả trên MNLI như một ví dụ. Chúng tôi so sánh LiST với GPT-3 in-context learning vượt trội 33% cũng như một số phương pháp học bán giám sát few-shot SoTA với LiST vượt trội baseline mạnh nhất 6% chỉ với 30 ví dụ có nhãn cho mỗi tác vụ.

Phát biểu bài toán. Mỗi tác vụ downstream trong khung của chúng tôi bao gồm rất ít ví dụ huấn luyện có nhãn DTrain K cho các shots khác nhau K ∈ {10, 20, 30} nơi |DTrain K| = K, dữ liệu không nhãn DU nơi DU ∩ DTrain K = ∅, và một tập kiểm tra DTest. Cho dataset DK = DTrain K ∪ DU cho một tác vụ với shots K, một PLM với tham số θPLM và hàm mất mát L, chúng tôi muốn thích ứng mô hình cho tác vụ học few-shot bằng cách giới thiệu một số lượng nhỏ tham số mô hình có thể điều chỉnh α ≪ θPLM.

Cho một chuỗi văn bản x hoặc một cặp chuỗi {x1, x2} được phân tách bằng các toán tử đặc biệt (ví dụ: [CLS] và [SEP]) và một bộ mã hóa mô hình ngôn ngữ enc(·) được tham số hóa bởi θ - tinh chỉnh cổ điển được phổ biến bởi Devlin et al. tận dụng biểu diễn trạng thái ẩn h[CLS] của (các) chuỗi thu được từ enc([CLS]x1[SEP]x2[SEP]) làm đầu vào cho một đầu cụ thể tác vụ softmax(W^T h[CLS]) để phân loại, nơi W ∈ R^{d×L} với d và L đại diện cho chiều trạng thái ẩn và số lượng lớp, là các tham số có thể điều chỉnh được khởi tạo ngẫu nhiên. Trong quá trình này, nó cập nhật cả đầu cụ thể tác vụ W và tham số bộ mã hóa cùng nhau.

Tuy nhiên, điều này tạo ra một khoảng cách giữa mục tiêu tiền huấn luyện và tinh chỉnh với các không gian nhãn khác nhau và các tham số được khởi tạo ngẫu nhiên bổ sung W được giới thiệu cho tinh chỉnh cụ thể tác vụ. Điều này đặc biệt thách thức cho tinh chỉnh cổ điển few-shot, nơi dữ liệu có nhãn hạn chế không đủ để thích ứng đầu cụ thể tác vụ và trọng số PLM hiệu quả. FN dựa trên gợi ý giải quyết khoảng cách này bằng cách tái công thức hóa mục tiêu như một tác vụ tự động hoàn thành kiểu cloze. Điều này được thực hiện bằng cách thêm một cụm từ (cũng được gọi là gợi ý) vào một câu như x1 = "chứa không có trí tuệ, chỉ có những trò đùa gượng ép" dưới dạng x̃ = x1 ⊕ "Nó [MASK]", nơi ⊕ biểu thị nối hai chuỗi; và ánh xạ đầu ra (cũng được gọi là verbalizers) từ từ vựng V đến không gian nhãn Y như "{tuyệt vời, khủng khiếp}" tương ứng với các lớp tích cực và tiêu cực. Xác suất dự đoán lớp y ∈ Y bằng với tính toán xác suất của từ nhãn tương ứng v ∈ V:

p([MASK] = v|x̃) = exp(W^T_v h[MASK]) / Σ_{v'∈V} exp(W^T_{v'} h[MASK])

nơi W_v chỉ ra các tham số có thể điều chỉnh. Vì nó giống hệt với mô hình hóa ngôn ngữ có mặt nạ (MLM), W_v được khởi tạo bằng trọng số tiền huấn luyện của PLM.

Trong công việc này, chúng tôi chứng minh tự huấn luyện nhẹ với dữ liệu không nhãn để cải thiện đáng kể tinh chỉnh gợi ý của PLM trong các thiết lập few-shot.

Các công việc liên quan gần đây đã khám phá các phương pháp bán giám sát cho việc học few-shot với dữ liệu không nhãn cụ thể tác vụ, bao gồm tăng cường dữ liệu, tự huấn luyện và học tương phản. GPT-3 tận dụng quy mô lớn với 175 tỷ tham số để đạt được hiệu suất few-shot đáng kể trên một số tác vụ NLU với các gợi ý ngôn ngữ tự nhiên và một vài minh chứng cho tác vụ. Các công việc gần đây mở rộng ý tưởng gợi ý này cho các mô hình ngôn ngữ như BERT và RoBERTa. Công việc liên quan nhất với chúng tôi là iPET, kết hợp FN dựa trên gợi ý với học bán giám sát. Trong khi iPET tập hợp nhiều mô hình được tinh chỉnh đầy đủ, chúng tôi phát triển một khung tự huấn luyện gợi ý nhẹ nhàng để đạt được cả hiệu quả dữ liệu và tham số.

Các công việc thích ứng few-shot huấn luyện mô hình trên dữ liệu có nhãn lớn trên các tác vụ nguồn và phát triển các kỹ thuật để thích ứng chúng với tác vụ đích với nhãn few-shot. Ngược lại, chúng tôi tập trung vào học few-shot thực sự một tác vụ chỉ với 10 đến 30 ví dụ có nhãn có sẵn tổng thể và không có nhãn giám sát phụ trợ.

Các phương pháp tinh chỉnh tiêu chuẩn điều chỉnh tất cả các tham số mô hình có thể huấn luyện cho mọi tác vụ. Những nỗ lực gần đây đã tập trung vào việc điều chỉnh nhẹ nhàng các PLM lớn bằng cách cập nhật một tập nhỏ tham số trong khi giữ hầu hết các tham số trong PLM cố định, bao gồm điều chỉnh tiền tố, điều chỉnh token gợi ý và điều chỉnh Adapter. Tất cả các công việc trên tập trung vào các thiết lập giám sát đầy đủ với hàng nghìn ví dụ có nhãn sử dụng tinh chỉnh cổ điển. Ngược lại, chúng tôi tập trung vào các thiết lập học few-shot tận dụng gợi ý để điều chỉnh mô hình.

Chúng tôi áp dụng một PLM (ví dụ: RoBERTa) làm bộ mã hóa chung cho cả học sinh và thầy cho tự huấn luyện. Bộ mã hóa PLM chung được cố định và không được cập nhật trong quá trình huấn luyện. Chúng tôi giới thiệu các tham số adapter có thể điều chỉnh trong cả thầy và học sinh được điều chỉnh lặp lại trong quá trình tự huấn luyện.

Đầu tiên chúng tôi sử dụng tinh chỉnh dựa trên gợi ý để cập nhật adapter thầy (Bước 1) với các ví dụ có nhãn few-shot và tận dụng mô hình thầy để gán các nhãn gợi ý giả (Bước 2) trên dữ liệu không nhãn Du. Thầy thường không chắc chắn trong học few-shot và tạo ra các nhãn giả nhiễu. Do đó, chúng tôi áp dụng meta-learning để tái cân bằng các mẫu nhãn giả nhiễu (Bước 3). Dữ liệu được tái cân bằng được sử dụng để huấn luyện adapter học sinh (Bước 4). Vì huấn luyện adapter với nhãn giả nhiễu khá không ổn định, chúng tôi giới thiệu khởi động chưng cất kiến thức. Cuối cùng, chúng tôi gán adapter học sinh đã huấn luyện thành adapter thầy mới (Bước 5). Theo các thiết lập học few-shot thực sự, chúng tôi không sử dụng bất kỳ tập phát triển hoặc xác thực riêng biệt nào. Do đó, chúng tôi lặp lại các bước trên một số lần được định trước (M = 6).

Phương pháp chủ yếu để thích ứng tác vụ là điều chỉnh tất cả các tham số có thể huấn luyện của PLM cho mọi tác vụ. Điều này đặt ra những thách thức tài nguyên đáng kể cả trong quá trình huấn luyện và triển khai. Một nghiên cứu gần đây cho thấy PLM có một chiều nội tại thấp có thể phù hợp với hiệu suất của không gian tham số đầy đủ. Để thích ứng PLM cho các tác vụ downstream với một số lượng nhỏ tham số, adapters gần đây đã được giới thiệu như một phương pháp thay thế cho điều chỉnh nhẹ nhàng.

Xem xét kịch bản sau để minh họa, nơi chúng tôi muốn sử dụng RoBERTa-large với M = 355M tham số làm PLM cho T = 100 tác vụ. Tinh chỉnh đầy đủ cho kịch bản này đòi hỏi cập nhật và lưu trữ M × T = 35.5B tham số. Bây giờ, xem xét tinh chỉnh với LiST đòi hỏi A = 14M tham số adapter (có thể điều chỉnh) cho mọi tác vụ trong khi giữ PLM cố định. Điều này dẫn đến tổng thể M + A × T = 1.8B tham số, do đó giảm chi phí lưu trữ tổng thể 20 lần.

Adapter được sử dụng trong LiST bao gồm hai lớp được kết nối đầy đủ, nơi một lớp feedforward chiếu xuống biểu diễn đầu vào xuống một không gian chiều thấp d (được gọi là chiều cổ chai), và một lớp feedforward khác chiếu lên các đặc trưng chiều thấp trở lại chiều ban đầu. Tuy nhiên, các tham số mới chèn vào này có thể gây ra phân kỳ dẫn đến suy giảm hiệu suất lên đến 20% trong các thiết lập few-shot. Để xử lý vấn đề này, chúng tôi áp dụng thiết kế kết nối bỏ qua nơi các tham số adapter được khởi tạo với nhiễu Gaussian trung bình không nhỏ.

Các công việc trước đó về thích ứng nhẹ nhàng điều chỉnh bias hoặc embeddings của Transformers trong các thiết lập giám sát đầy đủ để cải thiện hiệu quả tham số với mất mát hiệu suất tối thiểu. Tuy nhiên, cho các thiết lập few-shot, chúng tôi lưu ý rằng vị trí adapter là quan trọng để thu hẹp khoảng cách hiệu suất với mô hình có thể điều chỉnh đầy đủ và các lựa chọn điều chỉnh bias hoặc embedding có thể dẫn đến suy giảm hiệu suất lên đến 10%.

Để giải quyết vấn đề này, chúng tôi khám phá một số lựa chọn vị trí adapter tương ứng với các mô-đun transformer quan trọng nhất, cụ thể là embedding, feedforward trung gian, feedforward đầu ra và mô-đun attention trong mỗi lớp của Transformer. Dựa trên các thí nghiệm thực nghiệm trên sáu tác vụ NLU đa dạng, chúng tôi quan sát các mô-đun feedforward đầu ra và attention là những thành phần quan trọng nhất cho thích ứng hiệu quả tham số trong các thiết lập few-shot.

Chính thức, xem xét D̃Train K = {x̃l, ỹl} là dữ liệu có nhãn few-shot và D̃U = {x̃u} là dữ liệu không nhãn, nơi chúng tôi biến đổi các chuỗi đầu vào x thành đầu vào kiểu cloze x̃ chứa một mặt nạ duy nhất theo chiến lược gợi ý được nêu trong Phần 2. Chúng tôi sử dụng các mẫu template và verbalizers giống nhau từ các công việc FN dựa trên gợi ý truyền thống. Cho thiết kế adapter trên và lựa chọn vị trí với tham số α, một dataset D̃Train K với shots K, một bộ mã hóa PLM enc với tham số θPLM, nơi α ≪ θPLM, chúng tôi muốn thực hiện tối ưu hóa sau đây cho thích ứng mô hình hiệu quả:

α* = arg min_α L(D̃Train K; θPLM, α)

Xem xét {ŷ(t)n}^N_{n=1} là các nhãn gợi ý giả (cho các token được che trong x̃u_n ∈ X̃) từ thầy (θPLM, α̂tea) trong vòng lặp thứ t nơi N là số lượng instance không nhãn và α̂tea đại diện cho các tham số adapter thầy. Trong tự huấn luyện, mô hình học sinh được huấn luyện để bắt chước các dự đoán của thầy trên tập chuyển giao.

Xem xét L(ŷ(t)n, enc(x̃u_n; θPLM, α(t)stu)) là mất mát của mô hình học sinh với tham số (θPLM, α(t)stu) trên dữ liệu nhãn giả trong vòng lặp thứ t, nơi θPLM và αstu đại diện cho PLM và các tham số adapter học sinh tương ứng. Để giảm lan truyền lỗi từ các nhãn giả nhiễu, chúng tôi tận dụng meta-learning để tái cân bằng chúng dựa trên mất mát mô hình học sinh trên tập xác thực như mục tiêu meta của chúng tôi.

Trực giác của tái cân bằng meta là đo lường tác động hoặc trọng số của một ví dụ nhãn giả được đưa ra bởi hiệu suất của nó trên tập xác thực. Vì chúng tôi không có quyền truy cập vào một tập xác thực riêng biệt theo tinh thần của học few-shot thực sự, chúng tôi tận dụng tập huấn luyện có nhãn D̃Train K một cách thận trọng để tái cân bằng.

Để có được một ước tính rẻ của meta-weight tại bước t, chúng tôi thực hiện một bước gradient descent duy nhất trên một mini-batch D̃(t) ∈ D̃Train K như sau:

u(t)i = ∂/∂αi [Σ^{|D̃(t)|}_{i=1} L(yi, enc(x̃i; θPLM, α̂(t)stu(α))) / |D̃(t)|]

Trọng số w(t)i của (x̃u_i, ŷ(t)i) tại vòng lặp t được đặt tỷ lệ với gradient âm u(t)i để phản ánh tầm quan trọng của các mẫu nhãn giả. Các mẫu có trọng số âm được lọc ra vì chúng có thể làm giảm hiệu suất học sinh. Cuối cùng, chúng tôi cập nhật các tham số adapter học sinh αstu trong khi tính đến tái cân bằng như:

L(t) = (1/N) Σ^N_{i=1} [w(t)i L(ŷ(t)i, enc(x̃u_i; θPLM, α̂(t-1)stu))]

Tái cân bằng meta tận dụng gradient như một proxy để ước tính trọng số của các nhãn giả nhiễu. Tuy nhiên, các gradient của tham số adapter α không ổn định trong các giai đoạn đầu của huấn luyện do khởi tạo ngẫu nhiên và nhiễu trong các nhãn giả. Vấn đề không ổn định này được làm trầm trọng thêm với điều chỉnh adapter thường đòi hỏi tốc độ học lớn hơn.

Do đó, để ổn định điều chỉnh adapter, chúng tôi đề xuất một giai đoạn khởi động huấn luyện qua chưng cất kiến thức để đầu tiên điều chỉnh tham số adapter qua mất mát chưng cất kiến thức cho Twarm bước và sau đó chúng tôi tiếp tục tự huấn luyện với cập nhật tái cân bằng. Vì thủ tục tái cân bằng có quyền truy cập vào nhãn huấn luyện của chúng tôi, chúng tôi không sử dụng dữ liệu có nhãn trong chưng cất kiến thức trong khi chỉ sử dụng mất mát nhất quán không giám sát giữa mô hình thầy (θPLM, α̂tea) và mô hình học sinh (θPLM, α̂stu) trên dữ liệu không nhãn.

Một thách thức điển hình trong các thiết lập few-shot là thiếu một tập xác thực riêng biệt. Theo tinh thần học few-shot thực sự, chúng tôi chỉ sử dụng các ví dụ có nhãn few-shot có sẵn D̃Train K làm tập xác thực cho meta-learning của mô hình học sinh. Điều này đặt ra một thách thức thú vị là ngăn chặn rò rỉ nhãn. Để giải quyết vấn đề này, chúng tôi tái khởi tạo các tham số adapter học sinh mỗi lần tại đầu mỗi vòng lặp tự huấn luyện để giảm thiểu can thiệp với dữ liệu có nhãn.

Chúng tôi thực hiện các thí nghiệm quy mô lớn với sáu tác vụ hiểu ngôn ngữ tự nhiên. Chúng tôi sử dụng bốn tác vụ từ GLUE, bao gồm MNLI cho suy luận ngôn ngữ tự nhiên, RTE cho entailment văn bản, QQP cho tương đương ngữ nghĩa và SST-2 cho phân loại cảm xúc. MPQA và Subj được sử dụng cho phát hiện cực tính và chủ quan.

Đối với mỗi dataset, chúng tôi lấy mẫu ngẫu nhiên |K| ∈ {10, 20, 30} mẫu có nhãn thủ công từ dữ liệu huấn luyện, và thêm phần còn lại vào tập không nhãn trong khi bỏ qua nhãn của chúng. Chúng tôi lặp lại lấy mẫu K instance có nhãn năm lần, chạy mỗi mô hình với 5 seeds khác nhau và báo cáo hiệu suất trung bình với độ lệch chuẩn qua các lần chạy.

Theo thiết lập học few-shot thực sự, chúng tôi không sử dụng tập phát triển bổ sung ngoài |K| mẫu có nhãn cho bất kỳ điều chỉnh siêu tham số hoặc dừng sớm nào. Hiệu suất của mỗi mô hình được báo cáo sau các epoch huấn luyện cố định.

Ngoài tinh chỉnh cổ điển (Classic FN), chúng tôi áp dụng tinh chỉnh dựa trên gợi ý (Prompt FN) làm baseline chỉ có nhãn. Chúng tôi cũng áp dụng một số baseline bán giám sát tiên tiến bao gồm UST, MetaST và iPET. UST và MetaST là hai phương pháp tự huấn luyện dựa trên các chiến lược tinh chỉnh cổ điển. iPET là một phương pháp bán giám sát tận dụng tinh chỉnh dựa trên gợi ý và tập hợp gợi ý để đạt được hiệu suất tiên tiến. Trong khi iPET tập hợp nhiều mô hình được tinh chỉnh đầy đủ, chúng tôi phát triển một khung tự huấn luyện lite để đạt được cả hiệu quả dữ liệu và tham số.

Bảng 1 cho thấy so sánh hiệu suất giữa các mô hình khác nhau với |K| = 30 ví dụ có nhãn với việc cố định RoBERTa-large làm bộ mã hóa. RoBERTa-large được giám sát đầy đủ huấn luyện trên hàng nghìn ví dụ có nhãn cung cấp hiệu suất trần cho thiết lập few-shot. Chúng tôi quan sát LiST vượt trội đáng kể so với các baseline tiên tiến khác cùng với 96% giảm tham số có thể điều chỉnh, đạt được cả hiệu quả dữ liệu có nhãn và tham số.

Cụ thể hơn, LiST cải thiện so với Classic FN, Prompt FN, iPET và PromptST lần lượt 34.6%, 5.7%, 8.6% và 6.2% về hiệu suất trung bình trên sáu tác vụ. Điều này chứng minh tác động của tự huấn luyện với dữ liệu không nhãn và FN dựa trên gợi ý. Ngoài ra, iPET và LiST đều tận dụng FN dựa trên gợi ý để cải thiện đáng kể so với UST và MetaST sử dụng các chiến lược tinh chỉnh cổ điển, xác nhận hiệu quả của FN dựa trên gợi ý trong chế độ dữ liệu thấp.

Hình 5 so sánh hiệu suất của các phương pháp điều chỉnh với số lượng nhãn huấn luyện khác nhau và bộ mã hóa có kích thước khác nhau. Chúng tôi quan sát rằng các mô hình lớn hiệu quả dữ liệu hơn so với các mô hình nhỏ hơn. Tuy nhiên, các mô hình lớn có thể điều chỉnh đầy đủ đắt đỏ để sử dụng trong thực tế. Chúng tôi quan sát rằng LiST với số lượng nhỏ tham số có thể điều chỉnh liên tục vượt trội hơn các chiến lược FN cổ điển và dựa trên gợi ý có thể điều chỉnh đầy đủ trong tất cả các thiết lập dữ liệu có nhãn, chứng minh cả hiệu quả dữ liệu và tham số.

Chúng tôi thực hiện so sánh giữa GPT-3 in-context learning, RoBERTa-large Prompt-based fine-tuning và các phương pháp LiST với số lượng nhãn huấn luyện khác nhau trong Bảng 2. Để so sánh công bằng, gợi ý và từ nhãn giống nhau cho ba phương pháp. Chúng tôi quan sát rằng LiST vượt trội hơn GPT-3 In-context learning và Prompt-based FN một cách nhất quán với số lượng nhãn khác nhau.

Trong phần này, chúng tôi khám phá các lựa chọn thiết kế adapter cho FN dựa trên gợi ý với RoBERTa-large làm bộ mã hóa chỉ sử dụng dữ liệu có nhãn few-shot.

Để trả lời câu hỏi này, chúng tôi tiến hành một thí nghiệm để nghiên cứu vai trò của các mô-đun Transformer khác nhau trong FN dựa trên gợi ý few-shot. Để làm điều này, chúng tôi điều chỉnh một mô-đun nhất định cùng với đầu mô hình ngôn ngữ trong khi giữ tất cả các tham số khác cố định. Bảng 3 cho thấy so sánh hiệu suất của việc điều chỉnh các mô-đun cụ thể trên sáu tác vụ với số lượng ví dụ có nhãn khác nhau. Các mô-đun chính của RoBERTa bao gồm Embedding, Attention, Feedforward Output và các lớp Feedforward Intermediate. Chúng tôi quan sát rằng việc điều chỉnh chỉ Feedforward Output hoặc mô-đun Attention mang lại hiệu suất tốt nhất trên hầu hết các tác vụ với nhãn few-shot. Tương ứng, điều này thúc đẩy chúng tôi chèn các tham số adapter của chúng tôi vào hai mô-đun này.

Để xác thực hiệu quả của các adapter LiST, chúng tôi so sánh nó với một số baseline trong Bảng 4. Để so sánh công bằng, chúng tôi trình bày hai biến thể của adapter LiST với các chiều cổ chai d = {2, 128} tương ứng với 1M và 14M tham số để phù hợp với các dung lượng adapter khác; tất cả các phương pháp trong Bảng 4 được huấn luyện chỉ với 30 nhãn mà không có dữ liệu không nhãn để so sánh công bằng.

(1) Bias-only là một phương pháp nhẹ nhàng đơn giản nhưng hiệu quả, điều chỉnh các thuật ngữ bias của PLM trong khi giữ các tham số khác cố định. (2) Điều chỉnh các lớp đầu được sử dụng rộng rãi như một baseline mạnh cho các nghiên cứu nhẹ nhàng, nơi chúng tôi điều chỉnh hai lớp cuối bao gồm đầu mô hình ngôn ngữ trong khi đóng băng các tham số khác. (3) prompt-tuning là một phương pháp nhẹ nhàng chỉ cập nhật embedding gợi ý tác vụ trong khi giữ toàn bộ mô hình cố định. (4) Houlsby Adapter điều chỉnh các tham số adapter được chèn vào giữ bộ mã hóa cố định bằng cách áp dụng chiến lược điều chỉnh cổ điển.

Bảng 4 cho thấy LiST có thể phù hợp với hiệu suất của FN dựa trên gợi ý mô hình đầy đủ với chiều cổ chai d = 128 và vượt trội hơn tất cả các baseline khác với dung lượng tương tự. Trong khi các lựa chọn điều chỉnh mô hình nhẹ nhàng như điều chỉnh bias hoặc chèn adapter vào các mô hình điều chỉnh cổ điển được chứng minh là hiệu quả trong các thiết lập giám sát đầy đủ, chúng tôi quan sát chúng hoạt động kém hơn cho việc học few-shot. Chúng tôi quan sát rằng các lựa chọn điều chỉnh đơn giản hơn như Head-only và Bias-only dẫn đến suy giảm hiệu suất lên đến 10%. Houlsby adapter và Prompt-only dẫn đến suy giảm hiệu suất lên đến 20%. Ngược lại, adapter LiST có thể phù hợp với hiệu suất của điều chỉnh đầy đủ trong thiết lập few-shot, chứng minh tầm quan trọng của các lựa chọn vị trí adapter và khởi tạo tham số.

Bảng 5 chứng minh tác động của các thành phần và lựa chọn thiết kế khác nhau của LiST.

Huấn luyện với rất ít nhãn và dữ liệu nhãn giả nhiễu dẫn đến không ổn định cho việc điều chỉnh adapter. Để chứng minh sự ổn định huấn luyện, chúng tôi bao gồm độ chính xác trung bình và độ lệch chuẩn qua một số lần chạy và phân chia như các chỉ số. Chúng tôi quan sát rằng các nhãn giả cứng làm tổn hại hiệu suất mô hình so với các nhãn giả mềm và làm trầm trọng thêm vấn đề không ổn định. Điều này trái ngược với các quan sát từ tinh chỉnh cổ điển. Một lý do tiềm năng có thể là đầu mô hình ngôn ngữ được tiền huấn luyện tốt cho FN dựa trên gợi ý có thể nắm bắt các mối liên kết tốt hơn giữa các nhãn gợi ý khác nhau.

Trong nghiên cứu loại bỏ này, chúng tôi loại bỏ giai đoạn khởi động với chưng cất kiến thức từ LiST (được ký hiệu là "LiST w/o KD Warmup"). Loại bỏ thành phần này dẫn đến sụt giảm hiệu suất 4% về độ chính xác trung bình và độ lệch chuẩn lớn hơn 300% - chứng minh tầm quan trọng của KD Warmup trong việc ổn định huấn luyện LiST.

Trong LiST, chúng tôi chỉ tinh chỉnh adapter và đầu mô hình ngôn ngữ trong khi giữ các tham số bộ mã hóa khác cố định để đạt được hiệu quả tham số. Bảng 5 cho thấy LiST chỉ sử dụng 4% tham số có thể điều chỉnh có thể phù hợp với hiệu suất của LiST có thể điều chỉnh đầy đủ (nghĩa là không sử dụng bất kỳ adapter nào và điều chỉnh tất cả các tham số bộ mã hóa) trên MNLI và RTE - chứng minh hiệu quả của thiết kế nhẹ nhàng của chúng tôi.

Chúng tôi phát triển một phương pháp mới LiST để điều chỉnh nhẹ nhàng các mô hình ngôn ngữ lớn trong các thiết lập few-shot. LiST sử dụng tự huấn luyện có gợi ý để học từ lượng lớn dữ liệu không nhãn từ các miền đích. Để giảm chi phí lưu trữ và huấn luyện, LiST chỉ điều chỉnh một số lượng nhỏ tham số adapter với nhãn few-shot trong khi giữ bộ mã hóa lớn cố định. Chỉ với 30 nhãn cho mỗi tác vụ, LiST cải thiện lên đến 35% so với tinh chỉnh cổ điển và 6% so với điều chỉnh gợi ý trong khi giảm 96% tham số có thể điều chỉnh. Với việc giảm đáng kể chi phí chú thích (dữ liệu) và tổng dung lượng mô hình, LiST cung cấp một khung hiệu quả hướng tới việc học suốt đời của các tác nhân AI. Trong khi adapter giảm chi phí lưu trữ, LiST không giảm độ trễ suy luận do xương sống PLM. Một công việc tương lai là xem xét kết hợp các kỹ thuật nén mô hình với adapter để giảm FLOPS và độ trễ.

Trong công việc này, chúng tôi giới thiệu một khung nhẹ nhàng cho tự huấn luyện các mô hình ngôn ngữ chỉ với một vài ví dụ có nhãn. Chúng tôi mong đợi rằng tiến bộ và những phát hiện được trình bày trong bài báo này có thể mang lại lợi ích thêm cho các ứng dụng NLP với dữ liệu có nhãn hạn chế. Trong thiết lập thế giới thực, thường không chỉ tốn kém để có được dữ liệu có nhãn quy mô lớn cho mỗi tác vụ mà còn mang lại những lo ngại về quyền riêng tư và tuân thủ khi cần gắn nhãn dữ liệu quy mô lớn. Các lo ngại về quyền riêng tư có thể được làm trầm trọng thêm khi xử lý dữ liệu người dùng nhạy cảm cho các tác vụ cá nhân hóa. Khung của chúng tôi chỉ cần dữ liệu có nhãn few-shot có thể giúp trong việc này để có được hiệu suất tiên tiến trong khi giảm thiểu những lo ngại về quyền riêng tư.

Khung được đề xuất được thử nghiệm trên các tác vụ khác nhau và có thể được sử dụng cho các ứng dụng trong nhiều lĩnh vực khác nhau bao gồm tài chính, pháp lý, chăm sóc sức khỏe, bán lẻ và các miền khác nơi việc áp dụng mạng nơ-ron sâu có thể bị cản trở do thiếu chú thích thủ công quy mô lớn trên dữ liệu người dùng nhạy cảm.

Trong khi khung của chúng tôi thúc đẩy tiến bộ của NLP, nó cũng gặp phải các tác động xã hội liên quan của tự động hóa từ mất việc làm cho các công nhân cung cấp chú thích như một dịch vụ cũng như cho các ngành công nghiệp khác dựa vào lao động con người. Hơn nữa, nó có thể mang lại những lo ngại bổ sung khi các mô hình NLP được sử dụng bởi các tác nhân độc hại để truyền bá thiên vị, thông tin sai lệch và tham gia vào các hoạt động có hại khác. Tuy nhiên, nhiều lo ngại này cũng có thể được giảm thiểu với khung của chúng tôi để phát triển các mô hình phát hiện và chiến lược giảm thiểu tốt hơn chỉ với một vài ví dụ đại diện của những ý định như vậy.

Phương pháp đề xuất hơi tốn kém về tính toán vì nó liên quan đến mô hình ngôn ngữ quy mô lớn. Điều này có thể gây ra tác động tiêu cực đến dấu chân carbon từ việc huấn luyện các mô hình được mô tả. Để giảm chi phí lưu trữ và huấn luyện, thiết kế được đề xuất chỉ điều chỉnh một số lượng nhỏ tham số adapter với nhãn few-shot trong khi giữ bộ mã hóa lớn cố định.

# Các Adapter Mixture-of-Linguistic-Experts để Cải thiện và Diễn giải Các Mô hình Ngôn ngữ Tiền huấn luyện

Raymond Li†, Gabriel Murray‡, Giuseppe Carenini†
†Đại học British Columbia, Vancouver, BC, Canada
‡Đại học Fraser Valley, Abbotsford, BC, Canada
{raymondl, carenini}@cs.ubc.ca
gabriel.murray@ufv.ca

## Tóm tắt

Trong công trình này, chúng tôi đề xuất một phương pháp kết hợp hai lĩnh vực nghiên cứu phổ biến bằng cách tiêm các cấu trúc ngôn ngữ vào các mô hình ngôn ngữ tiền huấn luyện trong bối cảnh tinh chỉnh hiệu quả tham số (PEFT). Trong cách tiếp cận của chúng tôi, các mô-đun adapter song song mã hóa các cấu trúc ngôn ngữ khác nhau được kết hợp bằng cách sử dụng kiến trúc Mixture-of-Linguistic-Experts mới, nơi các cổng Gumbel-Softmax được sử dụng để xác định tầm quan trọng của những mô-đun này tại mỗi lớp của mô hình. Để giảm số lượng tham số, chúng tôi đầu tiên huấn luyện mô hình trong một số bước nhỏ cố định trước khi cắt tỉa các chuyên gia dựa trên điểm quan trọng của chúng. Kết quả thí nghiệm của chúng tôi với ba mô hình tiền huấn luyện khác nhau cho thấy cách tiếp cận của chúng tôi có thể vượt trội hơn các phương pháp PEFT tiên tiến với số lượng tham số tương đương. Ngoài ra, chúng tôi cung cấp phân tích bổ sung để kiểm tra các chuyên gia được mỗi mô hình lựa chọn tại mỗi lớp để cung cấp thông tin chi tiết cho các nghiên cứu tương lai.

## 1 Giới thiệu

Trong những năm gần đây, các mô hình ngôn ngữ tiền huấn luyện đã trở thành công cụ không thể thiếu cho lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) (Devlin et al., 2019; Liu et al., 2019; Clark et al., 2020; He et al., 2021, 2023). Sự thay đổi này chủ yếu do sự xuất hiện và thành công của các mô hình dựa trên transformer (Vaswani et al., 2017) nơi tiền huấn luyện quy mô lớn giúp mô hình học được cấu trúc cú pháp và ngữ nghĩa của một ngôn ngữ mà không cần giám sát rõ ràng. Đồng thời, có những lý do chính đáng để đặt câu hỏi liệu những mô hình này có thể được cho là hiểu một ngôn ngữ theo cách có ý nghĩa và có thể diễn giải được hay không (Trott et al., 2020; Merrill et al., 2021). Để giải quyết vấn đề này, các nghiên cứu thăm dò đã chứng minh, ở một mức độ nhất định, rằng có thể suy ra các cấu trúc ngôn ngữ từ các biểu diễn trong những mô hình này (Hewitt and Manning, 2019; Tenney et al., 2019b; Maudslay et al., 2020). Tuy nhiên, mối liên hệ chính xác giữa sự tồn tại của các cấu trúc và lợi ích của chúng đối với hiệu suất nhiệm vụ vẫn chưa được thiết lập vững chắc. Mặt khác, trong khi cách tinh chỉnh thông thường đã tìm thấy thành công trong một loạt các nhiệm vụ NLP, khả năng áp dụng của nó đã ngày càng giảm do chi phí tính toán liên quan với xu hướng gần đây chuyển sang các mô hình lớn hơn và phức tạp hơn (Zhao et al., 2023).

Trong khi một số người lập luận rằng tiền huấn luyện chỉ trên văn bản không có cấu trúc đã trang bị cho mô hình đủ khả năng để hiểu ý nghĩa của ngôn ngữ, những người khác (Bender and Koller, 2020; Prange et al., 2022) đã khẳng định rằng việc ánh xạ hành vi của mô hình lên các cấu trúc có thể hiểu được bởi con người cung cấp bằng chứng đáng tin cậy hơn về khả năng của nó để giải quyết các nhiệm vụ ngoài việc chỉ khai thác các gợi ý bề mặt. Cụ thể, các nghiên cứu trong lĩnh vực này đã mang lại những nỗ lực thành công trong việc tiêm các cấu trúc cú pháp và ngữ nghĩa vào các mô hình ngôn ngữ tiền huấn luyện (Bai et al., 2021; Wu et al., 2021; Yu et al., 2022), với kết quả tích cực được báo cáo trên các nhiệm vụ hạ nguồn. Tuy nhiên, mặc dù có những nỗ lực gần đây, không có công trình nào đã giải quyết vấn đề về nơi và cách thức hiệu quả để tiêm nhiều cấu trúc khác nhau một cách hiệu quả.

Cách tiếp cận thông thường của việc tinh chỉnh các mô hình NLP tiền huấn luyện bao gồm việc tối ưu hóa toàn bộ tập hợp các tham số mô hình cho mỗi nhiệm vụ. Tuy nhiên, điều này dẫn đến một bản sao riêng biệt của các tham số mô hình đã tinh chỉnh cho mỗi nhiệm vụ và đã trở nên ngày càng không khả thi do xu hướng gần đây của việc tiền huấn luyện các mô hình ngày càng lớn hơn. Để giải quyết những mối quan ngại này, một làn sóng công trình gần đây đã được dành cho việc nghiên cứu các phương pháp tinh chỉnh hiệu quả tham số (PEFT) (Ding et al., 2023), nơi chỉ một phần nhỏ các tham số có thể huấn luyện cụ thể cho nhiệm vụ được điều chỉnh trong khi giữ phần còn lại của mô hình bị đóng băng. Trong khi những nghiên cứu này đã đạt được hiệu suất ấn tượng thậm chí có thể so sánh với việc tinh chỉnh đầy đủ, chúng chủ yếu tập trung vào việc xác định tập con các tham số mô hình để điều chỉnh (Lee et al., 2019; Ben Zaken et al., 2022) hoặc tìm vị trí để chèn các tham số có thể huấn luyện bổ sung (Houlsby et al., 2019a; Li and Liang, 2021; Hu et al., 2022). Không có công trình nào đã giải quyết vấn đề liệu các tiền đề cấu trúc ngôn ngữ có thể được kết hợp vào những tham số có thể huấn luyện này dưới bối cảnh PEFT hay không.

Trong công trình này, chúng tôi kết hợp hai lĩnh vực nghiên cứu về tiêm các cấu trúc ngôn ngữ và PEFT bằng cách đề xuất một chiến lược kết hợp hiệu quả nhiều cấu trúc ngôn ngữ vào các mô hình NLP tiền huấn luyện theo cách hiệu quả tham số. Để kết hợp nhiều cấu trúc ngôn ngữ, chúng tôi đề xuất một kiến trúc mới lấy cảm hứng từ các mô hình Mixture-of-Experts (Shazeer et al., 2017), nơi các mô-đun Relational Graph Convolutional Networks (RGCN) (Schlichtkrull et al., 2018) được mã hóa với các cây ngôn ngữ khác nhau được tổng hợp bằng cách sử dụng các cổng Gumbel-Softmax có thể học được (Jang et al., 2017), và được chèn giữa mỗi lớp của mô hình tiền huấn luyện. Để giảm số lượng tham số, chúng tôi đề xuất một chiến lược cắt tỉa nơi chúng tôi đầu tiên điều chỉnh toàn bộ tập hợp các mô-đun RGCN trước khi cắt tỉa tất cả trừ các "chuyên gia" hàng đầu dựa trên điểm quan trọng học được từ các cổng. Để chứng minh lợi ích của cách tiếp cận của chúng tôi, chúng tôi thực hiện thí nghiệm trên benchmark GLUE với ba mô hình NLP tiền huấn luyện khác nhau và so sánh kết quả với các phương pháp PEFT tiên tiến (Mao et al., 2022). Hơn nữa, chúng tôi thực hiện phân tích bổ sung để hiểu loại cấu trúc ngôn ngữ nào được giữ lại tại mỗi lớp của mô hình và cung cấp thông tin chi tiết cho công việc tương lai về việc tiêm kiến thức thông qua các phương pháp PEFT. Tóm lại, đóng góp của chúng tôi có thể được tóm tắt như sau:

1. Chúng tôi đề xuất một kiến trúc mới để kết hợp và diễn giải hiệu quả nhiều cấu trúc ngôn ngữ tại các lớp khác nhau của mô hình tiền huấn luyện.

2. Để cải thiện hiệu quả, chúng tôi áp dụng một chiến lược cắt tỉa bằng cách chỉ giữ lại các chuyên gia hàng đầu theo điểm quan trọng của chúng.

3. Kết quả thí nghiệm của chúng tôi với ba mô hình khác nhau chứng minh lợi ích của cách tiếp cận của chúng tôi bằng cách đạt được hiệu suất tổng thể tốt nhất trên benchmark GLUE.

4. Chúng tôi thực hiện phân tích về các chuyên gia được mô hình lựa chọn để cung cấp thông tin chi tiết có giá trị cho công việc tương lai.

## 2 Các Công trình Liên quan

Chúng tôi tổ chức phần này dựa trên hai lĩnh vực nghiên cứu mà công trình của chúng tôi tìm cách kết hợp. Trong §2.1, chúng tôi cung cấp tổng quan về các kỹ thuật tiêm cấu trúc ngôn ngữ, trong khi §2.2 tóm tắt các xu hướng gần đây trong tinh chỉnh hiệu quả tham số.

### 2.1 Tiêm Các Cấu trúc Ngôn ngữ

Các công trình trước đây về tiêm các cấu trúc ngôn ngữ vào mạng nơ-ron thường dựa trên kiến trúc mạng nơ-ron đệ quy (Goller and Kuchler, 1996; Socher et al., 2011, 2012, 2013), nơi một hàm tổng hợp đệ quy kết hợp các biểu diễn của các nút con theo một cấu trúc cây được định nghĩa trước. Theo cùng trực giác, các nghiên cứu tiếp theo đã mở rộng cách tiếp cận của họ để tổng hợp các trạng thái ẩn thành nhiều kiến trúc nơ-ron bao gồm mạng nơ-ron hồi quy (RNN) (Tai et al., 2015; Miwa and Bansal, 2016; Roth and Lapata, 2016; Kuncoro et al., 2017; Shen et al., 2019), mạng nơ-ron đồ thị (GNN) (Marcheggiani and Titov, 2017; Bastings et al., 2017; Zhang et al., 2018; Huang and Carley, 2019; Wang et al., 2020), và sau đó, Transformers (Wu et al., 2018; Hao et al., 2019; Strubell et al., 2018; Wang et al., 2019b,c). Ví dụ, Strubell et al. (2018) đã sử dụng toán tử bi-affine (Dozat and Manning, 2017) để dự đoán điểm ái lực giữa các biểu diễn token (vector key và query) dựa trên cây phụ thuộc, trong khi (Wang et al., 2019c) khuyến khích các đầu attention tuân theo các cấu trúc cây bằng cách áp dụng một tiền đề thành phần trên các trọng số attention.

Gần đây hơn, nghiên cứu trong lĩnh vực này đã chuyển sang các mô hình ngôn ngữ tiền huấn luyện (Devlin et al., 2019; Liu et al., 2019; Clark et al., 2020; He et al., 2021, 2023). Trong khi các nghiên cứu trước về thăm dò (Hewitt and Manning, 2019; Tenney et al., 2019b; Maudslay et al., 2020; Newman et al., 2021; Arps et al., 2022) đã chỉ ra rằng các cấu trúc phân cấp có ý nghĩa (ví dụ, cây cú pháp) có thể được trích xuất từ các mô hình tiền huấn luyện mà không cần giám sát rõ ràng, người ta cũng đã phát hiện ra rằng việc kết hợp các cấu trúc ngôn ngữ vẫn có thể có lợi cho hiệu suất hạ nguồn (Zhang et al., 2020; Kuncoro et al., 2020; Sachan et al., 2021; Qian et al., 2021), ngay cả khi các cấu trúc đã tồn tại trong mô hình (Li et al., 2022). Ví dụ, Bai et al. (2021) đã rõ ràng che giấu các trọng số attention tiền huấn luyện hiện có dựa trên các ma trận liền kề được định nghĩa bởi các cây cú pháp. Mặt khác, Wu et al. (2021) đã sử dụng các lớp GNN bổ sung để kết hợp các phụ thuộc ngữ nghĩa bằng cách thêm chúng vào đầu encoder tiền huấn luyện. Gần giống nhất với công trình của chúng tôi, Yu et al. (2022) đã mở rộng cách tiếp cận của Wu et al. (2021) và thực hiện một nghiên cứu thực nghiệm về cú pháp và đồ thị tầm thường. Tuy nhiên, phương pháp của họ yêu cầu huấn luyện một mô hình mới cho mỗi đồ thị, điều này không hiệu quả để nghiên cứu lợi ích của chúng tại các lớp khác nhau của mô hình. Theo hiểu biết của chúng tôi, không có công trình nào đã cố gắng kết hợp nhiều cấu trúc ngôn ngữ khác nhau trong cùng một mô hình, như chúng tôi làm trong bài báo này.

### 2.2 Tinh chỉnh Hiệu quả Tham số

Trong khi mô hình tiêu chuẩn của việc tinh chỉnh các mô hình ngôn ngữ tiền huấn luyện đã trở thành thực tiễn phổ biến cho các nhiệm vụ NLP (Min et al., 2021), nó đã trở nên ít áp dụng hơn do chi phí tính toán liên quan với các mô hình ngày càng lớn (Brown et al., 2020a; OpenAI, 2023). Các phương pháp tinh chỉnh hiệu quả tham số (PEFT) (Ding et al., 2023), mặt khác, trình bày một giải pháp cho vấn đề này bằng cách đóng băng hầu hết hoặc tất cả các trọng số tiền huấn luyện và chỉ tinh chỉnh một tập hợp nhỏ các tham số tỷ lệ với kích thước mô hình. Các phương pháp PEFT có thể được tổ chức thô thành hai danh mục. Danh mục đầu tiên điều chỉnh một tập con các tham số hiện có với các ví dụ đáng chú ý bao gồm đóng băng toàn bộ các lớp (Lee et al., 2019) hoặc chỉ điều chỉnh các thuật ngữ bias (Ben Zaken et al., 2022). Tuy nhiên, những cách tiếp cận này thường dẫn đến hiệu suất tệ hơn và chỉ được chỉ ra là đạt được hiệu suất tương đương với việc tinh chỉnh đầy đủ trên các nhiệm vụ tài nguyên thấp. Thay vào đó, danh mục thứ hai thêm các tham số có thể huấn luyện mới trong khi giữ các trọng số tiền huấn luyện bị đóng băng (Han et al., 2021; Karimi Mahabadi et al., 2021; Lester et al., 2021). Ví dụ, Houlsby et al. (2019a) đã sử dụng một lớp bottleneck có thể huấn luyện sau mạng feed-forward trong mỗi lớp của mô hình, Li and Liang (2021) đã đặt trước các vector có thể huấn luyện vào đầu vào của multi-head attention, trong khi Hu et al. (2022) đã kết hợp các trọng số attention tiền huấn luyện với các ma trận rank thấp có thể huấn luyện. Cuối cùng, các nghiên cứu gần đây hơn (He et al., 2022; Mao et al., 2022) đã đề xuất một framework thống nhất bằng cách kết hợp các phương pháp PEFT khác nhau như các mô-đun con. Trong khi chúng tôi sử dụng cách tiếp cận của họ làm baseline, không có công trình PEFT nào đã cố gắng kết hợp các cấu trúc có thể diễn giải làm tiền đề cho các mô-đun có thể huấn luyện, như chúng tôi làm trong bài báo này.

## 3 Kiến trúc Mô hình

Trong phần này, chúng tôi mô tả các kiến trúc của các adapter Mixture-of-Linguistic của chúng tôi (Hình 1). Chúng tôi bắt đầu bằng cách giới thiệu các mô-đun Relational Graph Convolutional Network (RGCN) để kết hợp các cấu trúc ngôn ngữ (§3.1) trước khi mô tả phương pháp được sử dụng để kết hợp nhiều RGCN (§3.2). Cuối cùng, chúng tôi thảo luận về cách các adapter được chèn vào mô hình tiền huấn luyện (§3.3).

### 3.1 Mô hình hóa Các Cấu trúc Phụ thuộc

Để mô hình hóa các cấu trúc phụ thuộc, chúng tôi áp dụng phương pháp được đề xuất bởi Wu et al. (2021), nơi các lớp RGCN (Schlichtkrull et al., 2018) được sử dụng để truyền các biểu diễn nút theo cấu trúc được định nghĩa bởi cây phụ thuộc.

h(ℓ)_i = ReLU(∑_{r∈R} ∑_{j∈N_i} W_r h(ℓ-1)_j / |N_i| + W_0 h(ℓ-1)_i)     (1)

Phương trình 1 mô tả quá trình truyền cho một lớp RGCN duy nhất, nơi biểu diễn nút h_i được cập nhật với một hàm tổng hợp đã học dựa trên các nút lân cận h_j∈N_i (và chính nó) trong đồ thị phụ thuộc. Cụ thể, chúng tôi sử dụng các trạng thái ẩn trung gian của mô hình tiền huấn luyện làm đầu vào, nơi các vector token con được tính trung bình để tạo ra biểu diễn nút cho từ liên quan. Vì số lượng tham số trong RGCN tăng tuyến tính với số lượng loại quan hệ, thay vì liên kết mỗi quan hệ phụ thuộc với một tập trọng số W_r riêng biệt, chúng tôi chỉ mô hình hóa các quan hệ con và cha (|R| = 2) để giảm số lượng tham số.

Phép toán graph convolution có độ phức tạp tính toán O(|E| · d_1 · d_2), nơi d_1 và d_2 lần lượt là số chiều đầu vào và đầu ra của lớp, và |E| là tổng số cạnh được định nghĩa bởi đồ thị phụ thuộc. Ngoài ra, phép toán self-loop trong lớp RGCN thêm một độ phức tạp O(|N| · d_1 · d_2), nơi |N| = |E| + 1 là tổng số nút hoặc token từ trong đồ thị phụ thuộc. Phép toán self-loop có cùng độ phức tạp với lớp tuyến tính tiêu chuẩn.

### 3.2 Kết hợp Các Mô-đun Khác nhau

Lấy cảm hứng từ kiến trúc Mixture-of-Experts (Shazeer et al., 2017), chúng tôi đề xuất một chiến lược để xác định tầm quan trọng của các mô-đun adapter khác nhau bằng cách lấy mẫu các giá trị cổng từ phân phối Gumbel-Softmax (Maddison et al., 2017; Jang et al., 2017). Cụ thể, chúng tôi định nghĩa một logit cổng z_i cho mỗi mô-đun "chuyên gia" E_i, nơi giá trị cổng g_i được lấy mẫu từ phân phối Gumbel-Softmax trong quá trình huấn luyện. Phương pháp lấy mẫu được định nghĩa là:

g_i = softmax((z_i + ε)/τ)     (2)

nơi tính ngẫu nhiên đến từ nhiễu gumbel ε = -log(-log(u)) sao cho u ~ Uniform(0,1), và τ là nhiệt độ để kiểm soát tính ngẫu nhiên của phân phối. Giá trị của logit cổng z_i có thể được diễn giải là đóng góp của mô-đun chuyên gia tương ứng khi tính toán biểu diễn tổng hợp từ tất cả các chuyên gia.

Trái ngược với các cổng softmax được sử dụng trong kiến trúc MoE gốc (Shazeer et al., 2017), việc lấy mẫu cổng từ phân phối Gumbel-Softmax cung cấp khả năng diễn giải tốt hơn về tầm quan trọng của nó vì tính ngẫu nhiên vốn có giới thiệu một đặc tính khám phá và cho phép mô hình xem xét một tập hợp đa dạng các đầu ra tiềm năng. Trong khi đó, phép toán softmax tiêu chuẩn giả định một câu trả lời đúng duy nhất tại mỗi lớp, có nghĩa là mô hình có thể bỏ qua các kết hợp tốt của các mô-đun bằng cách khai thác cục bộ mô-đun với xác suất cao nhất duy nhất.

### 3.3 Adapters

Dựa trên các công trình trước về tinh chỉnh hiệu quả tham số (Houlsby et al., 2019b; Mao et al., 2022), chúng tôi tiêm lớp Mixture-Linguistic-Experts của chúng tôi giữa các lớp của mô hình transformer tiền huấn luyện (§3.2) và chỉ cập nhật các adapter trong khi giữ các tham số tiền huấn luyện bị đóng băng. Chúng tôi chọn chèn các mô-đun theo gợi ý của He et al. (2022), nơi họ phát hiện ra rằng việc chèn adapter song song với các mạng feed-forward (FFN) đạt được hiệu suất tổng thể tốt nhất.

h(ℓ)_attn = MultiHeadAttn(h(ℓ-1))
h(ℓ) = FFN(h(ℓ)_attn) + Adapter(h(ℓ)_attn)     (3)

Từ Phương trình 3, mô-đun adapter của chúng tôi lấy đầu ra ẩn h_attn từ lớp con multi-head attention (MultiHeadAttn) và sử dụng một thành phần cộng với FFN gốc để tạo ra đầu ra lớp cuối cùng h(l).

## 4 Chiến lược Huấn luyện

Trong khi kiến trúc được đề xuất trong phần 3 cho phép chúng tôi tổng hợp nhiều mô-đun adapter tại mỗi lớp tiền huấn luyện, nó giảm đáng kể hiệu quả do số lượng tham số cụ thể cho nhiệm vụ được sử dụng trong quá trình huấn luyện và suy luận. Để giải quyết vấn đề này, chúng tôi đề xuất một chiến lược cắt tỉa để giảm số lượng chuyên gia.

Để quyết định chuyên gia nào sẽ giữ lại tại mỗi lớp, chúng tôi đầu tiên tinh chỉnh toàn bộ tập hợp các mô-đun chuyên gia bằng cách sử dụng kiến trúc Mixture-of-Linguistic-Experts của chúng tôi (Hình 1) trong một số bước nhỏ cố định. Sau khi các cổng đã hội tụ, điểm quan trọng từ các cổng có thể được sử dụng để xác định chuyên gia nào sẽ giữ lại. Trong khi một chiến lược cắt tỉa lặp (Michel et al., 2019; Behnke and Heafield, 2020; Tan and Motani, 2020) cũng có thể được sử dụng, nó ít hiệu quả hơn do yêu cầu nhiều bước huấn luyện hơn. Cuối cùng, sau quá trình cắt tỉa, chúng tôi khởi động lại quá trình huấn luyện và tinh chỉnh mô hình kết quả với một mô-đun chuyên gia trên mỗi lớp.

## 5 Thí nghiệm

Chúng tôi mô tả chi tiết các thiết lập thí nghiệm và kết quả trong phần này. Chúng tôi bắt đầu bằng cách cung cấp một tóm tắt ngắn gọn về các đồ thị ngôn ngữ (§5.1) trước khi mô tả các tập dữ liệu (§5.2) mô hình (§5.3), và các thiết lập siêu tham số (§5.4). Cuối cùng, chúng tôi trình bày kết quả trong §5.5.

### 5.1 Đồ thị Ngôn ngữ

Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng ba đồ thị ngôn ngữ khác nhau để mã hóa các cấu trúc cấp câu. Theo các nghiên cứu trước (Wu et al., 2021; Yu et al., 2022), chúng tôi truyền các cây phụ thuộc ngữ nghĩa và cú pháp cũng như một đồ thị hai chiều tuần tự vào ba mô-đun adapter RGCN riêng biệt cho mỗi lớp của mô hình tiền huấn luyện. Ngoài ra, để tính đến các kịch bản nơi các cấu trúc không cần thiết hoặc có hại, chúng tôi cũng sử dụng một mô-đun perceptron đa lớp (MLP) để đại diện cho một đồ thị không có cạnh, nơi không có thành phần nào được thực hiện.

**Cây Cú pháp** Trong các phân tích cú pháp, mỗi từ trong câu được gán một đầu cú pháp dựa trên hình thức Universal Dependencies (UD) (de Marneffe et al., 2021). Chúng tôi sử dụng parser phụ thuộc nơ-ron biaffine sâu dựa trên Bi-LSTM (Dozat and Manning, 2017) được huấn luyện trên treebank UD tiếng Anh từ thư viện Stanza (Qi et al., 2020).

**Cây Ngữ nghĩa** Dựa trên hình thức phụ thuộc DELPH-IN (Ivanova et al., 2012), các phân tích ngữ nghĩa gán các phụ thuộc từ dựa trên các quan hệ predicate-argument. Trái ngược với các đồ thị cú pháp, các từ không đóng góp vào biểu diễn ý nghĩa của câu không xuất hiện trong đồ thị ngữ nghĩa. Các đồ thị được trích xuất với một parser dựa trên chuyển đổi nơ-ron (Wang et al., 2018; Che et al., 2019) được huấn luyện trên nhiệm vụ chia sẻ CoNLL 2019 (Oepen et al., 2019).

**Đồ thị Hai chiều Tuần tự** Chúng tôi cũng sử dụng một đồ thị hai chiều tuần tự đơn giản kết nối các token từ theo thứ tự tuần tự. Điều này cho phép các lớp RGCN tổng hợp thông tin cục bộ thay vì các phụ thuộc có thể dài, nơi nó đã chỉ ra khả năng cải thiện hiệu suất nhiệm vụ khi được tiêm vào các lớp transformer tiền huấn luyện thông qua attention cố định (Li et al., 2022).

**Đồ thị Không có Cạnh** Ngoài ba đồ thị ngôn ngữ, chúng tôi cũng áp dụng một phép biến đổi phi tuyến đơn giản bằng cách sử dụng các lớp MLP. Trực giác là tại một số lớp, việc tiêm cấu trúc có thể không hữu ích (hoặc thậm chí có hại) đối với hiệu suất nhiệm vụ khi tiền đề ngôn ngữ không thể được sử dụng dựa trên biểu diễn được học bởi lớp đó.

### 5.2 Tập dữ liệu

| Tập dữ liệu | Nhiệm vụ | Huấn luyện | Dev |
|-------------|----------|------------|-----|
| CoLA | Acceptability | 1K | 1.74 |
| RTE | Entailment | 2.5K | 278 |
| MRPC | Paraphrase | 2.7K | 409 |
| STS-B | Similarity | 5.8K | 1.5k |
| SST-2 | Sentiment | 67K | 873 |
| QNLI | Entailment | 105k | 5.5K |
| QQP | Entailment | 363K | 40K |
| MNLI | Entailment | 392k | 9.8K |

Bảng 1: Thống kê của các tập dữ liệu trong benchmark GLUE, được sắp xếp theo kích thước của tập huấn luyện.

Chúng tôi thực hiện tất cả các thí nghiệm của chúng tôi trên benchmark GLUE (Wang et al., 2019a), bao gồm một bộ công cụ toàn diện các nhiệm vụ hiểu ngôn ngữ tự nhiên. Benchmark chứa tám tập dữ liệu cho phân loại văn bản, bao gồm khả năng chấp nhận ngôn ngữ (CoLA), phân tích cảm xúc (SST-2), các nhiệm vụ tương tự và paraphrase (MRPC, STS-B, QQP), và suy luận ngôn ngữ tự nhiên (MNLI, QNLI, RTE). Đối với phương pháp đánh giá, chúng tôi sử dụng Matthew's Correlation cho CoLA, F1 cho MRPC và QQP, Spearman's Rank-Order Correlation cho STS-B, và Accuracy cho SST-2, RTE, QNLI, và MNLI. Theo các nghiên cứu trước (Houlsby et al., 2019b; He et al., 2022), chúng tôi loại trừ tập dữ liệu WNLI khỏi các thí nghiệm của chúng tôi do phạm vi bao phủ hạn chế của nó. Thống kê của các tập dữ liệu được trình bày trong Bảng 1.

### 5.3 Mô hình

Trong các thí nghiệm của chúng tôi, chúng tôi áp dụng các phương pháp của chúng tôi cho ba mô hình ngôn ngữ tiền huấn luyện khác nhau: BERT, RoBERTa, DeBERTaV3. RoBERTa (Liu et al., 2019) cải tiến BERT (Devlin et al., 2019) bằng cách kết hợp nhiều dữ liệu huấn luyện hơn và loại bỏ mục tiêu dự đoán chuỗi tiếp theo, DeBERTa (He et al., 2021) giới thiệu một cơ chế attention tách biệt để mã hóa các vị trí tương đối tại mỗi lớp, trong khi DeBERTaV3 (He et al., 2021) cải thiện các phiên bản trước bằng cách điều chỉnh mục tiêu phát hiện token được thay thế (Clark et al., 2020). Đối với tất cả các mô hình, chúng tôi sử dụng biến thể tiêu chuẩn với 12 lớp và 12 đầu. Đối với baseline, chúng tôi sử dụng framework thống nhất cho việc điều chỉnh mô hình ngôn ngữ hiệu quả tham số (UniPELT) được đề xuất bởi (Mao et al., 2022). Vì kết quả từ bài báo gốc đã chứng minh hiệu suất vượt trội so với các phương pháp PEFT khác (Houlsby et al., 2019a; Li and Liang, 2021; Hu et al., 2022), chúng tôi chỉ báo cáo kết quả cho những phương pháp này cho BERT. Đối với tất cả các nhiệm vụ, chúng tôi áp dụng một bộ phân loại trên biểu diễn token [CLS] từ lớp ẩn cuối cùng.

### 5.4 Siêu tham số

Cả các mô-đun adapter MLP và RGCN đều bao gồm hai lớp ẩn với chiều bottleneck là 48. Vì các mô-đun RGCN yêu cầu 3× số lượng tham số của các mô-đun MLP, chúng tôi chỉ chọn top-2 mô-đun RGCN dựa trên giá trị cổng của chúng. Theo thiết lập của Mao et al. (2022), chúng tôi đặt độ dài đầu vào là 128, và huấn luyện tổng cộng 50 epoch với tốc độ học 5e-4 và kích thước batch là 16. Trong các bước đầu tiên của việc huấn luyện mô hình Mixture-of-Linguistic-Experts của chúng tôi, chúng tôi tuân theo gợi ý từ công trình trước (Huijben et al., 2022) và áp dụng temperature annealing (Jang et al., 2017) để giảm dần nhiệt độ từ 5 xuống 0.1 trong 1000 bước. Trực giác đằng sau temperature annealing là cho phép mô hình bắt đầu với hành vi khám phá nhiều hơn trước khi dần dần trở nên khai thác hơn. Cuối cùng, chúng tôi cũng chia đầu ra adapter theo một hệ số không đổi là 4 như được đề xuất trong công trình của He et al. (2022).

### 5.5 Kết quả

Từ kết quả trong Bảng 2, chúng ta thấy rằng cách tiếp cận của chúng tôi đạt được hiệu suất tổng thể tốt nhất trên benchmark GLUE. Đối với các nhiệm vụ riêng lẻ, mặc dù phương pháp của chúng tôi thua kém UniPELT trong các nhiệm vụ tài nguyên thấp RTE và STS-B, phương pháp của chúng tôi đạt được cải thiện nhất quán trong bốn nhiệm vụ có số lượng ví dụ huấn luyện cao nhất (Bảng 1): SST-2, QNLI, QQP và MNLI, nơi các cải thiện cho SST-2 và QNLI có ý nghĩa thống kê cho hai trong ba mô hình, và QQP và MNLI cho tất cả ba mô hình. Điều này phù hợp với các phát hiện của công trình trước (Mao et al., 2022; Chen et al., 2022), nơi họ phát hiện rằng trong khi các phương pháp PEFT hiện tại xuất sắc trong các nhiệm vụ tài nguyên thấp, chúng vẫn gặp khó khăn để mang lại hiệu suất cạnh tranh nhất quán trong các thiết lập tài nguyên trung bình và cao. Tuy nhiên, chúng tôi tin rằng việc học cách sử dụng các cấu trúc ngôn ngữ liên quan đến các cây phụ thuộc yêu cầu nhiều điều chỉnh hơn và có thể vượt trội hơn các phương pháp PEFT tiêu chuẩn khi có nhiều dữ liệu huấn luyện hơn. Cuối cùng, đáng chú ý rằng việc áp dụng cách tiếp cận của chúng tôi vào mô hình RoBERTa đã dẫn đến một sự gia tăng đáng kể trong hiệu suất (+0.19) so với baseline, vượt qua các mức tăng được quan sát với BERT (+0.09) và DeBERTa (+0.13). Vì RoBERTa được tiền huấn luyện trên một corpus lớn hơn BERT, chúng tôi giả thuyết rằng sự khác biệt này có thể do thực tế là RoBERTa đã học được biểu diễn có ý nghĩa hơn để hiểu các cấu trúc ngôn ngữ. Ngược lại, lợi thế của các cấu trúc ngôn ngữ được tiêm có thể bị bù trừ phần nào bởi phương pháp tiền huấn luyện tinh vi hơn được sử dụng bởi DeBERTa. Cuối cùng, chúng tôi lưu ý rằng trong khi Mao et al. (2022) báo cáo rằng phương pháp của họ (UniPELT) đạt được hiệu suất tốt hơn đáng kể so với tinh chỉnh tiêu chuẩn, các thí nghiệm của chúng tôi với RoBERTa cho kết quả ngược lại. Điều này phù hợp với các phát hiện của Chen et al. (2022), nơi họ phát hiện rằng các phương pháp PELT rất không ổn định và không thể đạt được hiệu suất cạnh tranh nhất quán so với tinh chỉnh (đặc biệt là trong các thiết lập tài nguyên trung bình đến cao). Do đó, chúng tôi giả thuyết sự khác biệt giữa kết quả của chúng tôi và của họ là do việc tìm kiếm siêu tham số rộng rãi có thể được thực hiện bởi (Mao et al., 2022), trong khi chúng tôi sử dụng các thiết lập siêu tham số giống hệt nhau trong tất cả các thí nghiệm như được báo cáo trong phần 5.4.

Trong Bảng 3, chúng tôi báo cáo số lượng tham số có thể huấn luyện cho mỗi phương pháp trong Bảng 2. Trong khi việc tăng số lượng mô-đun RGCN hoặc các chiều lớp ẩn có thể cải thiện hiệu suất của mô hình của chúng tôi, các thiết lập siêu tham số của chúng tôi (phần 5.4) được chọn đặc biệt để phù hợp với số lượng tham số được sử dụng trong UniPELT (Mao et al., 2022). Ngoài ra, đáng chú ý rằng chúng tôi đã chọn không kết hợp các quan hệ phụ thuộc vì số lượng tham số trong các lớp RGCN tăng tuyến tính với số lượng loại quan hệ.

| Phương pháp | Tham số |
|-------------|---------|
| Fine-tuning | 110M (100%) |
| Adapter | 895K (0.81%) |
| Prefix-tuning | 184K (0.17%) |
| LoRA | 295K (0.27%) |
| UniPELT (AP) | 1.1M (0.99%) |
| UniPELT (APL) | 1.4M (1.26%) |
| Của chúng tôi | 1.2M (1.14%) |

Bảng 3: Số lượng tham số có thể huấn luyện cần thiết cho mỗi phương pháp tinh chỉnh hiệu quả tham số.

## 6 Phân tích

Trong phần này, chúng tôi cung cấp một phân tích về hành vi của mô hình bằng cách đầu tiên kiểm tra chuyên gia ngôn ngữ được sử dụng cho mỗi mô hình (§6.1) trước khi kiểm tra tốc độ hội tụ của các cổng Gumbel-Softmax tại các lớp khác nhau của mô hình (§6.2).

### 6.1 Giá trị Cổng

Hình 2 minh họa các chuyên gia được sử dụng tại mỗi lớp của các mô hình. Nhìn thoáng qua, chúng ta có thể thấy rõ rằng tất cả các mô hình đều có xu hướng ưa chuộng các mô-đun RGCN ở các lớp trên, trong khi adapter MLP tiêu chuẩn được sử dụng cho các lớp dưới. Điều này có thể do thực tế là các mô hình ngôn ngữ tiền huấn luyện được thiết kế để học các biểu diễn phân cấp của đầu vào, nơi các lớp cấp thấp hơn thường nắm bắt kiến thức bề mặt cần thiết để hiểu các thành phần bậc cao (Tenney et al., 2019a; Niu et al., 2022). Vì kiến thức như vậy thường áp dụng cho tất cả các nhiệm vụ hạ nguồn với sự sửa đổi tối thiểu ngay cả trong quá trình tinh chỉnh đầy đủ (Zhou and Srikumar, 2022), việc tăng cường các biểu diễn của chúng với các cấu trúc tổng hợp có thể có hại cho hiệu suất. Các phát hiện tương tự cũng được báo cáo bởi Rücklé et al. (2021), nơi việc bỏ qua các adapter trong các lớp thấp hơn có tác động ít nhất đến hiệu suất mô hình.

Để hiểu rõ hơn về cách các cấu trúc ngôn ngữ khác nhau được sử dụng, chúng tôi cung cấp một so sánh định tính về các chuyên gia ngôn ngữ được sử dụng giữa các mô hình. Từ Hình 2, chúng ta có thể thấy rằng các chuyên gia được sử dụng giữa BERT và RoBERTa rất tương tự, với 5 trong 8 nhiệm vụ hoàn toàn giống nhau. Trái ngược, DeBERTa có xu hướng sử dụng nhiều chuyên gia ngữ nghĩa và cú pháp hơn, không có chuyên gia tuần tự nào được chọn ở lớp trên cùng. Chúng tôi tin rằng điều này là do cơ chế attention tách biệt được sử dụng bởi mô hình DeBERTa (He et al., 2021), nơi các vị trí token đã được mã hóa bởi một vector bổ sung tại mỗi lớp của mô hình. Ngoài ra, chúng ta thấy rằng các đồ thị ngữ nghĩa được chọn ít nhất. Điều này có thể do thực tế là chúng tôi không mô hình hóa các loại quan hệ, điều này cần thiết để xác định các vai trò ngữ nghĩa tinh vi giữa các khái niệm và ý tưởng. Ngược lại, các loại quan hệ trong cây cú pháp (ví dụ, chủ ngữ-động từ) không cung cấp ý nghĩa đầy đủ của câu ngoài cấu trúc ngữ pháp, nơi các nghiên cứu trước đã chỉ ra rằng cây cú pháp không có quan hệ vẫn có thể có lợi cho hiệu suất hạ nguồn (Bai et al., 2021).

### 6.2 Hội tụ Cổng

Tiếp theo, chúng tôi kiểm tra tốc độ hội tụ cho các logit cổng bằng cách đo lường các thay đổi trong giá trị cổng giữa các bước. Với mục đích phân tích, chúng tôi huấn luyện toàn bộ tập hợp các chuyên gia trong 2000 bước trong khi giữ tất cả các siêu tham số giống nhau. Hình 3 vẽ JS-Divergence giữa phân phối softmax của giá trị cổng theo khoảng thời gian 10 bước. Từ đồ thị, chúng ta có thể thấy rằng các giá trị cổng trong các lớp thấp hơn thay đổi nhanh chóng trong các lần lặp đầu tiên trước khi hội tụ. Điều này ngụ ý rằng mô hình có thể nhanh chóng học cách chọn mô-đun MLP (§6.1), cung cấp thêm bằng chứng chống lại việc tiêm kiến thức cấu trúc tại các lớp thấp hơn của các mô hình tiền huấn luyện. Trong các lớp trên, trong khi nó tuân theo xu hướng tương tự nơi các cổng thay đổi nhanh chóng trước khi đường cong thay đổi trở nên phẳng, chúng ta vẫn thấy một lượng dao động vừa phải ngay cả sau 1000 bước. Điều này có thể được diễn giải là chuyên gia tốt nhất không có đủ lợi thế tương đối so với những người khác để mô hình gán một điểm quan trọng cao. Vì mục đích chính của công trình của chúng tôi là đề xuất một kiến trúc để chọn các chuyên gia, chúng tôi để lại việc điều tra sâu về sự đánh đổi giữa các chuyên gia ngôn ngữ khác nhau như một hướng thú vị cho công việc tương lai. Cuối cùng, chúng ta thấy rằng hầu như tất cả các cổng đã hội tụ tại mốc 250 bước. Để tham khảo, đây là khoảng 2% số bước cho một epoch duy nhất trên tập huấn luyện MNLI. Phát hiện này chứng minh rằng chỉ cần một số bước nhỏ để học tầm quan trọng của các mô-đun adapter khác nhau.

### 6.3 Nghiên cứu Ablation

Chúng tôi thực hiện các thí nghiệm ablation để nghiên cứu hiệu quả của phương pháp lựa chọn chuyên gia của chúng tôi dựa trên các điểm quan trọng (phần 4). Để đảm bảo so sánh công bằng với kết quả trong Bảng 2, chúng tôi chỉ sử dụng một chuyên gia trên mỗi lớp trong khi sử dụng cùng kiến trúc. Chúng tôi thiết kế thủ công thứ tự của các chuyên gia dựa trên trực giác của pipeline NLP truyền thống (Tenney et al., 2019a), với các đặc trưng bề mặt ở dưới cùng, các đặc trưng cú pháp ở giữa, và các đặc trưng ngữ nghĩa ở trên cùng (Jawahar et al., 2019). Cụ thể, chúng tôi sử dụng mã hóa đồ thị tuần tự thông tin vị trí tại bốn lớp thấp hơn, cây cú pháp tại bốn lớp giữa, và đồ thị ngữ nghĩa tại bốn lớp trên. Chúng tôi cũng thực hiện thí nghiệm chỉ sử dụng một chuyên gia cho toàn bộ mô hình làm baseline.

| Phương pháp | SST-2 | QNLI |
|-------------|-------|------|
| Chỉ cú pháp | 92.04 | 86.40 |
| Chỉ ngữ nghĩa | 85.36 | 85.36 |
| Chỉ vị trí | 88.97 | 88.97 |
| Thiết kế thủ công | 91.84 | 89.12 |
| Của chúng tôi | 94.27 | 92.53 |

Bảng 4: Kết quả ablation với RoBERTa với các chuyên gia được chọn thủ công, trung bình trên 3 seeds.

Bảng 4 cho thấy kết quả cho RoBERTa trên hai tập dữ liệu tài nguyên trung bình (SST-2 và QNLI). Từ kết quả, chúng ta thấy rằng trong khi cách tiếp cận thiết kế thủ công của chúng tôi đạt được hiệu suất tốt hơn các mô hình chuyên gia đơn, chúng vẫn thua kém đáng kể so với cách tiếp cận lựa chọn tự động của chúng tôi. Phát hiện này xác minh giả thuyết của chúng tôi rằng việc tăng cường các biểu diễn của các lớp thấp hơn với các cấu trúc tổng hợp có thể có tác động không thể phục hồi đối với các biểu diễn lớp trên được sử dụng cho dự đoán nhiệm vụ (phần 6.1), cuối cùng dẫn đến sự suy giảm đáng kể trong hiệu suất.

## 7 Kết luận và Công việc Tương lai

Trong công trình này, chúng tôi giới thiệu một cách tiếp cận kết hợp hai lĩnh vực nghiên cứu phổ biến của việc tiêm các cấu trúc ngôn ngữ và tinh chỉnh hiệu quả tham số (PEFT). Để bắt đầu, chúng tôi giới thiệu một framework mới kết hợp nhiều cấu trúc ngôn ngữ trong một kiến trúc lấy cảm hứng từ mô hình Mixture-of-Experts, nơi các cổng Gumbel-Softmax được sử dụng để học tầm quan trọng của những chuyên gia này tại các lớp khác nhau của mô hình trong một số bước huấn luyện cố định nhỏ. Cuối cùng, chúng tôi giảm số lượng tham số bằng cách cắt tỉa tất cả trừ một chuyên gia tại mỗi lớp sao cho số lượng tham số có thể huấn luyện kết quả có thể so sánh với các phương pháp PEFT tiên tiến. Sau khi chạy thí nghiệm với ba mô hình tiền huấn luyện khác nhau trên benchmark GLUE, kết quả cho thấy rằng phương pháp của chúng tôi có thể đạt được hiệu suất tổng thể tốt nhất trong khi vượt trội đáng kể so với các baseline trên các nhiệm vụ tài nguyên cao. Cuối cùng, chúng tôi kiểm tra các chuyên gia được mỗi mô hình lựa chọn và tốc độ hội tụ của các cổng Gumbel-Softmax để hiểu rõ hơn về hành vi của các mô hình và cung cấp thông tin chi tiết có giá trị cho các nghiên cứu tương lai về tiêm kiến thức.

Đối với công việc tương lai, chúng tôi dự định thực hiện thêm các thí nghiệm để xác định lợi thế tương đối của kiến thức ngôn ngữ khác nhau và nghiên cứu cách chất lượng của các đồ thị ảnh hưởng đến hiệu suất mô hình trên các nhiệm vụ hạ nguồn. Một thách thức đáng kể là kết hợp hiệu quả các loại quan hệ của cây phụ thuộc, điều mà chúng tôi sẽ khám phá trong công việc tương lai. Ngoài ra, chúng tôi dự định cải thiện thêm hiệu quả của cách tiếp cận của chúng tôi bằng cách kết hợp các phát hiện từ các công trình gần đây khác, chẳng hạn như việc bỏ qua các adapter trong các lớp thấp hơn (Rücklé et al., 2021). Cuối cùng, chúng tôi dự định mở rộng cách tiếp cận của chúng tôi để tiêm các cấu trúc ngôn ngữ (bao gồm các đồ thị discourse) vào các kiến trúc chỉ decoder (Radford et al., 2019; Brown et al., 2020b) và thực hiện các nghiên cứu trên các biến thể mô hình lớn hơn (Touvron et al., 2023).

## Hạn chế

Một hạn chế của nghiên cứu của chúng tôi là cách tiếp cận của chúng tôi (loại trừ các đồ thị tuần tự) yêu cầu các parser chất lượng cao để xây dựng các cây cú pháp và ngữ nghĩa tiêu chuẩn vàng. Trong khi cách tiếp cận của chúng tôi thường áp dụng cho tất cả các cấu trúc, các thí nghiệm của chúng tôi tập trung vào các đồ thị ngôn ngữ cấp câu trên benchmark GLUE. Các cấu trúc khác như cây discourse trên các nhiệm vụ đa câu vẫn chưa được khám phá trong các nghiên cứu tương lai. Ngoài ra, tất cả các thí nghiệm của chúng tôi được thực hiện trên các biến thể tiêu chuẩn của các mô hình encoder tiền huấn luyện, hành vi khác nhau có thể được quan sát trên các mô hình lớn hơn hoặc có cấu trúc khác nhau, chẳng hạn như kiến trúc chỉ decoder.

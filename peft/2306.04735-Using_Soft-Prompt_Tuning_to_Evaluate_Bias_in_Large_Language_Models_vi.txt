Sử Dụng Soft-Prompt Tuning để Đánh Giá Thiên Lệch trong Mô Hình Ngôn Ngữ Lớn

Jacob-Junqi Tian1,2David Emerson1Sevil Zanjani Miyandoab3
Deval Pandya1Laleh Seyed-Kalantari1,4Faiza Khan Khattak1
1Vector Institute for AI2McGill University3Amirkabir University4York University
jacob.tian@mail.mcgill.ca, sev.zanjani@gmail.com, lsk@yorku.ca,
{david.emerson,deval.pandya,faiza.khankhattak }@vectorinstitute.ai

Tóm tắt
Việc prompting các mô hình ngôn ngữ lớn (LLMs) đã trở nên cực kỳ phổ biến vì các LLM được tiền huấn luyện có khả năng thực hiện các tác vụ downstream mà không cần lượng lớn dữ liệu được gán nhãn (Liu et al. 2023). Do đó, việc sử dụng prompting để đánh giá thiên lệch được thể hiện bởi các mô hình này cũng là điều tự nhiên. Tuy nhiên, để đạt được hiệu suất tốt cho từng tác vụ cụ thể thường đòi hỏi tối ưu hóa prompt thủ công. Trong bài báo này, chúng tôi khám phá việc sử dụng soft-prompt tuning để định lượng thiên lệch của các LLM như OPT (Zhang et al. 2022) và LLaMA (Touvron et al. 2023). Các mô hình này được huấn luyện trên dữ liệu thế giới thực với khả năng có thiên lệch ngầm đối với các nhóm nhất định. Vì LLM ngày càng được sử dụng trong nhiều ngành công nghiệp và ứng dụng, việc xác định chính xác và hiệu quả những thiên lệch này và tác động thực tế của chúng là điều quan trọng.

Trong bài báo này, chúng tôi sử dụng soft-prompt tuning để đánh giá thiên lệch mô hình qua nhiều thuộc tính nhạy cảm thông qua góc nhìn công bằng nhóm (thiên lệch). Ngoài việc cải thiện hiệu suất tác vụ, việc sử dụng soft-prompt tuning mang lại lợi thế tránh việc tiêm thiên lệch con người tiềm ẩn thông qua các prompt được thiết kế thủ công. Việc khảo sát bằng prompt-tuning tiết lộ các mẫu thiên lệch quan trọng, bao gồm sự chênh lệch qua độ tuổi và tình dục.

1 Giới thiệu
Mặc dù được sử dụng rộng rãi và thành công, các mô hình ngôn ngữ (LM) được fine-tuned có một số nhược điểm. Chúng bao gồm việc yêu cầu tài nguyên tính toán đáng kể để huấn luyện, lượng lớn dữ liệu được gán nhãn, và việc huấn luyện và lưu trữ riêng biệt cho mỗi tác vụ downstream (Han et al. 2021; Wang et al. 2022). Language model prompting giải quyết một số nhược điểm này, nhưng nhiệm vụ thiết kế prompt để tạo ra hiệu suất tối ưu cho một ứng dụng downstream cụ thể là thách thức (Liu et al. 2021; Petroni et al. 2019). Tiến bộ đáng kể đã được thực hiện trong các phương pháp kỹ thuật prompt tự động. Một phương pháp như vậy để tối ưu hóa prompt tự động là soft-prompt tuning, một phương pháp fine-tuning hiệu quả tham số (PEFT) huấn luyện một tập nhỏ các embedding token prompt để được cung cấp cùng với đầu vào ngôn ngữ tự nhiên tiêu chuẩn. Đối với các LLM khác nhau, soft-prompt tuning đã được chứng minh là có thể bằng hoặc gần bằng hiệu suất fine-tuning cho các tác vụ khác nhau như phân loại, tóm tắt và hỏi-đáp (Lester, Al-Rfou, and Constant 2021; Liu et al. 2022).

Mặt khác, sự tồn tại của các thiên lệch có thể có hại được thể hiện bởi các LM phổ biến đã được ghi chép đầy đủ (Dixon et al. 2018; Suresh and Guttag 2021; Bender et al. 2021; Marjanovic, Stánczak, and Augenstein 2022) và khá phổ biến. Định lượng thiên lệch đã thu hút sự chú ý đáng kể từ cộng đồng nghiên cứu gần đây (Mehrabi et al. 2021; Seyyed-Kalantari et al. 2021). Khi các ứng dụng LLM tiếp tục mở rộng nhanh chóng, việc phát triển các khung phân tích toàn diện để đo lường các thiên lệch xã hội được học hoặc thừa hưởng của các mô hình như vậy là bắt buộc.

Trong bài báo này, chúng tôi đánh giá tính hữu ích của soft-prompt tuning để đánh giá thiên lệch của LLM, bao gồm các mô hình ngôn ngữ OPT (Zhang et al. 2022) và LLaMA (Touvron et al. 2023). Cụ thể hơn, phương pháp được trình bày ở đây tận dụng các soft-prompt được tối ưu hóa để điều kiện hóa các mô hình hướng tới việc hoàn thành các tác vụ phân tích cảm xúc mà trên đó các thước đo công bằng (thiên lệch) được đo lường sau đó. Ngoài hiệu quả của phương pháp về số lượng tham số được điều chỉnh, một lợi thế khác của soft-prompt tuning là nó loại bỏ bất kỳ sự tiêm thiên lệch con người nào thông qua thiết kế prompt thủ công. Các thí nghiệm chứng minh rằng prompt-tuning cho phép phân tích chi tiết và hiểu biết tổng thể về thiên lệch của LLM đối với các thuộc tính nhạy cảm và qua các nhóm được bảo vệ. Các đóng góp của bài báo này như sau:

• Theo hiểu biết của chúng tôi, đây là ứng dụng đầu tiên của soft-prompt tuning cho đánh giá công bằng. Do đó, chúng tôi chứng minh rằng phương pháp này tạo thành một cách tiếp cận hiệu quả và hiệu quả cho việc đánh giá như vậy.

• Chúng tôi cho thấy rằng các LLM như OPT và LLaMA thể hiện thiên lệch có thể đo lường qua các nhóm được bảo vệ trong các thuộc tính nhạy cảm về tuổi tác, tình dục và khuyết tật. Hơn nữa, những thiên lệch như vậy thường nhất quán qua kích thước mô hình, loại và tập dữ liệu prompt-tuning.

• Các thước đo thiên lệch về khoảng cách tỷ lệ dương tính giả và âm tính giả được khám phá ở đây. Tuy nhiên, phương pháp này tương thích với các thước đo công bằng khác, bao gồm bộ công bằng toàn diện được đề xuất trong (Czarnowska, Vyas, and Shah 2021).

2 Công trình liên quan
Nghiên cứu về soft-prompt tuning và các phương pháp PEFT cho LLM đã mở rộng nhanh chóng (Lester, Al-Rfou, and Constant 2021; Li and Liang 2021; Liu et al. 2022). Các phương pháp như vậy tập trung vào việc giảm chi phí liên quan đến việc thích ứng các LLM được tiền huấn luyện cho các tác vụ downstream. Các phương pháp này được nghiên cứu kỹ lưỡng về hiệu suất cạnh tranh và đôi khi được cải thiện so với fine-tuning toàn mô hình. Tuy nhiên, công trình hiện tại không xem xét các tác động thiên lệch hoặc tính hữu ích của các phương pháp như vậy trong đánh giá thiên lệch.

Mặt khác, nhiều nhà nghiên cứu đã tập trung vào việc xác định, định lượng và giảm thiểu thiên lệch trong xử lý ngôn ngữ tự nhiên (NLP) (Delobelle et al. 2022; Felkner et al. 2022). Đối với LLM, một số baseline đánh giá thiên lệch hẹp liên quan đến các mô hình như GPT đã được thiết lập (Brown et al. 2020; Zhang et al. 2022). Ngoài ra, một số lượng hạn chế các nghiên cứu nhằm thiết kế các công cụ để đánh giá thiên lệch trong LLM. Ví dụ, tác vụ đánh giá Bias Benchmark for QA (Parrish et al. 2022), nhằm tạo ra một khung để đánh giá thiên lệch xã hội trong LM có kích thước bất kỳ theo một loạt lớn các thuộc tính nhạy cảm. Tuy nhiên, tác vụ này bị giới hạn trong các thiết lập câu hỏi-đáp nhiều lựa chọn. Big-Bench (Srivastava et al. 2022) giới thiệu các khung khác nhau để đánh giá LLM, nhưng số lượng hạn chế các phương pháp, thước đo và khía cạnh đánh giá thiên lệch được bao phủ. Quan trọng là, mỗi trường hợp trên cho đến nay đã bị giới hạn ở các prompt được thiết kế thủ công như cơ chế khảo sát cho LLM. Công trình của chúng tôi giải quyết khoảng trống này và cung cấp một công cụ quan trọng cho việc đánh giá thiên lệch có thể tái tạo trong LLM.

3 Phương pháp luận
Trong bài báo này, chúng tôi tận dụng tối ưu hóa prompt liên tục như một phương tiện hiệu quả để định lượng thiên lệch có trong LLM. Prompting là quá trình bổ sung văn bản đầu vào với các cụm từ hoặc mẫu được chế tác cẩn thận để giúp LM được tiền huấn luyện hoàn thành tác vụ downstream. Khi kết hợp với các prompt được hình thành tốt, LLM thực hiện chính xác nhiều tác vụ mà không cần fine-tuning (Brown et al. 2020). Tuy nhiên, thành phần của prompt thường có tác động vật chất đến hiệu suất của LLM (Liu et al. 2021). Gần đây, nghiên cứu đáng kể đã tạo ra các phương pháp hiệu quả cho tối ưu hóa prompt tự động, đặc biệt ở dạng prompting tuning, điều chỉnh không gian liên tục của embedding token. Một số công trình đã chỉ ra rằng prompt tuning, trong các dạng khác nhau của nó, vượt qua tối ưu hóa thủ công và rời rạc về hiệu suất, và trong một số trường hợp, thậm chí vượt trội hơn fine-tuning toàn mô hình. Hơn nữa, phương pháp này cũng hiệu quả hơn hàng trăm hoặc hàng nghìn lần về tham số so với fine-tuning toàn mô hình, đồng thời thể hiện hiệu quả dữ liệu tốt hơn (Lester, Al-Rfou, and Constant 2021; Liu et al. 2022; Li and Liang 2021).

Thiên lệch trong NLP thường được định lượng bằng cách sử dụng các thuộc tính nhạy cảm (Czarnowska, Vyas, and Shah 2021) như giới tính, tuổi tác hoặc tình dục. Mỗi thuộc tính nhạy cảm này bao gồm các nhóm được bảo vệ khác nhau. Ví dụ, thuộc tính nhạy cảm tuổi tác có thể bao gồm các nhóm được bảo vệ {người lớn, trẻ, già}. Xem Phụ lục A để biết thêm chi tiết. Ở đây, chúng tôi tập trung vào công bằng nhóm, đánh giá liệu hiệu suất của mô hình có thay đổi đáng kể và nhất quán qua các nhóm được bảo vệ khác nhau hay không và liệu thiên lệch đó có có hại cho các nhóm cụ thể. Trong khi chúng tôi tập trung vào công bằng nhóm, phương pháp luận tổng quát hóa cho các khái niệm công bằng khác, như công bằng phản thực tế. Từ góc độ thiên lệch, tối ưu hóa prompt liên tục cung cấp một công cụ đánh giá tiềm năng tuyệt vời, nhưng nó chưa được nghiên cứu trong tài liệu trước đây. Trong bài báo này, phương pháp prompt-tuning trong (Lester, Al-Rfou, and Constant 2021) được áp dụng để huấn luyện hiệu quả LLM thực hiện hai tác vụ phân tích cảm xúc ba chiều như một phương tiện đo lường thiên lệch ngoại tại.

Thiết lập thí nghiệm
Như đã thảo luận ở trên, chúng tôi sử dụng soft-prompt tuning để đánh giá thiên lệch thông qua góc nhìn công bằng nhóm. Đối với một thước đo, M, và một tập hợp các ví dụ thuộc về nhóm được bảo vệ, X, công bằng nhóm được định nghĩa là

dM(X) = M(X) - M̄.

Hàm dM(X) đo lường M-gap cho một nhóm cụ thể bằng cách so sánh giá trị thước đo bị hạn chế đối với các mẫu từ nhóm đó, M(X), với giá trị thước đo trung bình được quan sát cho mỗi nhóm được bảo vệ trong một thuộc tính nhạy cảm, M̄. Trong phân tích dưới đây, M là tỷ lệ dương tính giả (FPR). Do đó, chúng tôi đo lường FPR Gaps trong hiệu suất mô hình.

Dưới đây, chúng tôi cụ thể xem xét Positive và Negative FPR Gaps trong bối cảnh phân loại cảm xúc ba chiều. Positive FPR, chẳng hạn, được định nghĩa là tỷ lệ mà các điểm dữ liệu được gán nhãn là cảm xúc tiêu cực hoặc trung tính bị phân loại sai thành tích cực bởi mô hình được prompt-tuned. Do đó, một Positive FPR Gap lớn lớn hơn không cho thấy rằng bộ phân loại ưu tiên một nhóm bằng cách phân loại các ví dụ tiêu cực hoặc trung tính thuộc về nhóm đó thành tích cực với tỷ lệ cao hơn so với các nhóm khác. Mặt khác, một Negative FPR Gap lớn và tích cực gợi ý việc đối xử bất lợi bởi mô hình, vì nó phân loại các ví dụ tích cực và trung tính thuộc về một nhóm cụ thể thành tiêu cực với tỷ lệ cao hơn, so với những nhóm khác. Các thuộc tính nhạy cảm được phân tích dưới đây, và các nhóm được bảo vệ tương ứng của chúng, là

• Tuổi tác: {người lớn, già, trẻ}
• Tình dục: {vô tính, lưỡng tính, dị tính, đồng tính, khác}

Mô hình và Tập dữ liệu
Để định lượng thiên lệch sau khi soft-prompt tuning một mô hình, các mẫu toàn diện và tập dữ liệu kiểm tra kết quả được thiết kế bởi (Czarnowska, Vyas, and Shah 2021) được sử dụng. Bảng 1, cung cấp một ví dụ minh họa về các mẫu như vậy cho các thuộc tính nhạy cảm về giới tính và tuổi tác. Việc sử dụng các tập dữ liệu tổng hợp như vậy để đánh giá thiên lệch là thực hành phổ biến (Dixon et al. 2018). Cảm xúc liên quan đến mỗi điểm dữ liệu là rõ ràng đối với người đánh giá con người. Như vậy, ngay cả những chênh lệch nhỏ trong hiệu suất mô hình qua các nhóm được bảo vệ cũng có thể là nguyên nhân quan tâm. Hơn nữa, mặc dù cấu trúc tương đối đơn giản của các mẫu, chúng tôi vẫn quan sát những khoảng cách nhất quán và có ý nghĩa thống kê trong hiệu suất mô hình.

Trong các thí nghiệm dưới đây, chúng tôi xem xét ảnh hưởng mà các tập dữ liệu prompt-tuning khác nhau, loại mô hình và kích thước mô hình có trên các thiên lệch được đo lường. Chúng tôi điều chỉnh prompt trên hai tập dữ liệu cảm xúc riêng biệt, SemEval-2018 Task 1-Valence Ordinal Classification (Saif et al. 2018) (SemEval) và Stanford Sentiment Treebank Five-way (Socher et al. 2013) (SST-5), ánh xạ cả hai thành tác vụ phân loại 3 chiều như được mô tả trong Phụ lục C. Đối với các mô hình, chúng tôi đánh giá thiên lệch của họ mô hình OPT và LLaMA. Các mô hình có kích thước tham số 125M, 350M, 1.3B, 2.7B, 6.7B và 13B cho OPT và 6.7B và 13B cho LLaMA được khám phá. Các mô hình này được chọn vì chúng là mã nguồn mở, có nhiều kích thước khác nhau và chia sẻ sự tương đồng kiến trúc với nhiều mô hình khác, bao gồm các mô hình đóng như GPT-4.

Chi tiết Soft-prompt Tuning
Phương pháp soft-prompting thêm một chuỗi token với embedding có thể huấn luyện, T={t1, t2, ..., tn}, vào văn bản đầu vào mô hình X. Cho một token mục tiêu hoặc tập hợp token Y, mục tiêu là tối đa hóa log-likelihood của xác suất sinh ra Y được điều kiện hóa trên các token, T, và văn bản đầu vào, X, được biểu thị là P(Y|T;X). Đối với các tác vụ cảm xúc được xem xét ở đây, các token mục tiêu là positive, negative và neutral. Một minh họa về quy trình prompt-tuning được hiển thị trong Hình 1. Các trọng số của LM cơ bản được đóng băng trong suốt quá trình huấn luyện. Do đó, việc tạo ra các biểu diễn cụ thể cho tác vụ không sửa đổi rõ ràng các thiên lệch được thừa hưởng từ dữ liệu tiền huấn luyện LM. Chúng tôi giả thuyết rằng khi so sánh với fine-tuning toàn mô hình, phương pháp này đảm bảo đánh giá chính xác hơn về thiên lệch bẩm sinh của LM. Mặt khác, các embedding prompt được tối ưu hóa giúp đảm bảo rằng mô hình thực hiện tác vụ downstream cũng tốt như mô hình được fine-tuned hoàn toàn, điều này tự nhiên phản ánh các thiết lập triển khai thực tế. Để huấn luyện, một optimizer AdamW tiêu chuẩn được sử dụng (Loshchilov and Hutter 2017). Chúng tôi tận dụng khung ML JAX (Bradbury et al. 2018) để đạt được song song mô hình hiệu quả trên các thiết bị TPUv3-8 và lên đến bốn GPU A40 48GB.

Như được hiển thị trong Hình 1, các token beginning-of-sequence được sử dụng để cung cấp embedding ban đầu cho các prompt liên tục. Mỗi embedding sau đó được nhiễu loạn bổ sung bởi lớp embedding prompt có thể huấn luyện trước khi chảy qua LM như thường lệ, cùng với các token văn bản đầu vào không được sửa đổi còn lại. Một ví dụ về đầu vào được prompted cho tác vụ cảm xúc cũng được mô tả trong hình. Lưu ý rằng không có bổ sung prompt nào khác được thực hiện và hướng dẫn tác vụ đến hoàn toàn ở dạng các token prompt. Dựa trên kết quả tìm kiếm siêu tham số, số lượng token prompt được cố định ở 8 cho tất cả các thí nghiệm. Mỗi token prompt là một vector dày đặc với cùng số chiều như không gian embedding của LM tương ứng, dao động từ 1024 đến 5120, tùy thuộc vào kích thước mô hình. Nhìn chung, các tham số được học có quy mô khoảng 0.003% so với trọng số mô hình LM đầy đủ.

Để điều chỉnh cụ thể cho tác vụ của các mô hình, các phần huấn luyện và xác thực tiêu chuẩn được sử dụng cho cả hai tập dữ liệu được gán nhãn. Tỷ lệ học được tối ưu hóa bằng cách sử dụng độ chính xác xác thực. Mô tả cụ thể về việc quét siêu tham số, cùng với các tham số cuối cùng được chọn xuất hiện trong Phụ lục B. Do tính bất ổn vốn có của prompt tuning, sau khi lựa chọn siêu tham số, chúng tôi đã điều chỉnh 15 prompt khác nhau, mỗi cái với một random seed khác nhau, được chi tiết trong phụ lục. Đối với mỗi cặp kích thước mô hình và tập dữ liệu cụ thể cho tác vụ, chúng tôi chọn năm prompt hàng đầu về độ chính xác xác thực để thiết lập ước tính trung bình và khoảng tin cậy cho các thước đo công bằng (thiên lệch) kết quả. Early stopping được áp dụng trong quá trình prompt tuning khi, cho một bước nhất định, loss đánh giá vượt quá tối đa của năm loss đánh giá được quan sát trước đó sau một giai đoạn huấn luyện ban đầu 2,500 bước. Tất cả các prompt được huấn luyện cho đến khi tiêu chí early stopping được đáp ứng.

4 Kết quả
Trong phần này, kết quả được trình bày cho các thuộc tính nhạy cảm khác nhau bằng cách hiển thị FPR gap cho các nhóm được bảo vệ khác nhau khi sử dụng các tập dữ liệu SemEval và SST-5 để prompt tuning. Chúng tôi cũng xem xét tác động của việc điều chỉnh các kích thước mô hình khác nhau của OPT và LLaMA trên các thước đo.

Sexuality FPR Gaps
Trong Hình 2, FPR gap cho cảm xúc tích cực được hiển thị cho tình dục. Trong mỗi nhóm, gap trung bình được đo lường và khoảng tin cậy tương ứng của nó được hiển thị cho mỗi mô hình. Như đã thảo luận ở trên, Positive FPR Gap đo lường tỷ lệ mà mô hình phân loại sai các câu tiêu cực hoặc trung tính liên quan đến nhóm được bảo vệ theo ánh sáng thuận lợi. Do đó, các gap tiêu cực nhất quán và đáng kể cho một tình dục cụ thể qua các mô hình ngụ ý rằng các nhóm như vậy hưởng lợi từ lỗi mô hình với tỷ lệ thấp hơn có thể đo lường so với những nhóm khác. Mặt khác, các gap tích cực lớn gợi ý rằng một nhóm hưởng lợi từ lỗi mô hình với tỷ lệ cao hơn không cân xứng.

Hình 2 cho thấy rằng tỷ lệ mà các ví dụ thuộc về nhóm asexual hưởng lợi từ lỗi mô hình là nhất quán thấp hơn cho các mô hình được huấn luyện trên cả hai tập dữ liệu SemEval và SST-5 và qua tất cả các kích thước mô hình. Hơi bất ngờ, trong thước đo này, có bằng chứng gợi ý rằng các ví dụ heterosexual tạo thành một nhóm không được ưu tiên và không hưởng lợi từ lỗi mô hình. Tuy nhiên, mẫu này khá yếu. Cũng thú vị khi lưu ý rằng các ví dụ từ nhóm bisexual hưởng lợi không cân xứng từ lỗi mô hình trong cả hai tập dữ liệu. Điều này đặc biệt đúng cho các mô hình được huấn luyện trên SST5 nơi các gap có ý nghĩa thống kê cho nhiều mô hình.

Kết quả trong Hình 3 hiển thị Negative FPR Gap. Chúng đại diện cho sự khác biệt trong tỷ lệ lỗi nơi mô hình đã dự đoán rằng các điểm dữ liệu trung tính hoặc tích cực từ mỗi nhóm được bảo vệ là các ví dụ tiêu cực. Do đó, các gap tích cực trong các biểu đồ này gợi ý thiên lệch bất lợi chống lại các nhóm này so với toàn thể. Đối với các mô hình nhỏ hơn, rõ ràng là, như trong Hình 2, nhóm asexual chịu từ tỷ lệ lỗi có hại tăng cao. Hơn nữa, các ví dụ từ nhóm homosexual trải nghiệm sự gia tăng lớn và có ý nghĩa thống kê trong Negative FPR cho cả hai tập dữ liệu được xem xét và gần như tất cả các mô hình. Hai nhóm được bảo vệ, bisexual và other, trải nghiệm sự giảm có ý nghĩa thống kê trong thước đo FPR cho gần như tất cả các mô hình qua cả hai tập dữ liệu, tách biệt rõ rệt khỏi các nhóm khác.

Được báo cáo trong các hình, cùng với các FPR gap được đo lường cho mỗi kích thước mô hình, là khoảng tin cậy liên quan đến gap đó. Đối với mỗi nhóm, Bảng 2 hiển thị số lần thuần mà gap dưới hoặc trên không, ở độ tin cậy 95%. Có nghĩa là, đối với mỗi gap đáng kể dưới không, chúng tôi trừ một, trong khi một được cộng cho các gap đáng kể trên không. Các giá trị được tô màu đỏ chỉ ra hướng của các gap đáng kể có thể có hại, trong khi những cái màu xanh lá cây biểu thị việc đối xử có thể thuận lợi bởi các mô hình, mặc dù điều này phụ thuộc vào cách kết quả mô hình được sử dụng trong thực tế.

Đối với các nhóm được bảo vệ asexual và homosexual, kết quả thí nghiệm mạnh mẽ chỉ ra thiên lệch có hại tiềm ẩn trong Positive FPR và Negative FPR Gaps, tương ứng. Điều này nhất quán qua các tập dữ liệu, kích thước mô hình và loại mô hình. Mặt khác, các nhóm được bảo vệ bisexual và other nhất quán hưởng lợi từ lỗi mô hình với tỷ lệ tăng cao có ý nghĩa thống kê trong cả hai thước đo gap cho tất cả các cấu hình thí nghiệm.

Nhìn chung, trong các thí nghiệm trên, các gap được quan sát trong FPR cho cả lớp tích cực và tiêu cực đều nhất quán qua loại mô hình, kích thước mô hình và tập dữ liệu cho thấy rằng prompt-tuning, như một probe công bằng, hiệu quả trong việc tiết lộ thiên lệch được thừa hưởng nhất quán. Hơn nữa, một số nhóm được bảo vệ trải nghiệm FPR gap có ý nghĩa thống kê qua tất cả hoặc gần như tất cả các thiết lập thí nghiệm khác nhau.

Age FPR Gaps
Các FPR Gap cho các nhóm được bảo vệ thuộc về thuộc tính tuổi tác được phân tích trong phần này. Trong khi các kết luận ít rõ ràng hơn so với thuộc tính nhạy cảm về tình dục, một số xu hướng quan trọng vẫn còn. Hình 4 cho thấy FPR Gap được đo lường cho lớp tích cực. Khi xem xét kết quả từ tập dữ liệu SemEval, một sự giảm rõ rệt trong FPR có mặt cho nhóm old của các ví dụ. Xu hướng này cũng có mặt cho tập dữ liệu SST-5, mặc dù nó yếu hơn. Mặt khác, khi xem xét các đo lường trong Hình 5, nhóm adult bị ảnh hưởng bởi các lỗi đúc họ trong ánh sáng tiêu cực với tỷ lệ thấp hơn đáng kể so với các nhóm khác cho tập dữ liệu SemEval. Ngoài ra, các nhóm old và young thường chịu từ xác suất tăng cao của các lỗi như vậy, mặc dù các gap không phải lúc nào cũng có ý nghĩa thống kê khi các khoảng tin cậy được xem xét. Các Negative FPR gap được quan sát cho tập dữ liệu SST-5 ít nhất quán hơn. Tuy nhiên, có sự đồng ý chung về nhóm nào chịu hoặc hưởng lợi từ thiên lệch mô hình. Có nghĩa là, các ví dụ từ nhóm adult được ưu tiên và những cái từ nhóm young nhận được lỗi bất lợi, mặc dù cách mà thiên lệch được biểu hiện hơi khác nhau tùy thuộc vào tập dữ liệu prompt-tuning cơ bản. Bảng 2 củng cố kết luận này. Ở đó, chúng tôi quan sát sự đồng ý chung qua các mô hình về nhóm nào hưởng lợi hoặc không từ thiên lệch, nhưng gap xác định các nhóm này khác nhau tùy thuộc vào tập dữ liệu prompt-tuning.

Trong Phụ lục D, kết quả FPR gap bổ sung được trình bày cho thuộc tính nhạy cảm về khuyết tật. Kết quả hỗ trợ thêm tính hữu ích và nhất quán của việc sử dụng prompt-tuning như một probe thiên lệch cho LLM. Các gap được đo lường phần lớn nhất quán trong các nhóm qua loại và kích thước mô hình. Hơn nữa, nhiều gap được đo lường có ý nghĩa.

5 Kết luận và Thảo luận
Trong bài báo này, chúng tôi đã chứng minh lợi ích của việc tận dụng soft-prompt tuning như một cơ chế để định lượng thiên lệch trong LLM. Phương pháp này cung cấp một số lợi thế so với tối ưu hóa prompt thủ công bao gồm loại bỏ nhu cầu thiết kế prompt, hiệu suất tác vụ tốt hơn và việc tiêm thiên lệch bên ngoài hạn chế. Hơn nữa, nó nhanh hơn và hiệu quả hơn so với fine-tuning toàn mô hình, với hiệu suất tương đương hoặc tốt hơn. Do đó, các thiên lệch được phát hiện phản ánh chính xác hơn triển khai thế giới thực.

Kết quả cho thấy rằng, ví dụ, trong các thuộc tính nhạy cảm về tình dục và tuổi tác, các nhóm được bảo vệ dưới các thuật ngữ asexual, homosexual và old nhận được đối xử bất lợi, so với các nhóm khác, nhất quán qua các tập dữ liệu, kích thước mô hình và loại mô hình. Tuy nhiên, các điểm sau đây nên được xem xét cho một phân tích hoàn chỉnh.

Khía cạnh Đa chiều của Thí nghiệm
Trong khi trong bài báo này, chúng tôi đã khám phá tính hữu ích của một kỹ thuật soft-prompt tuning tiên tiến, tác vụ downstream được chọn, về bản thân nó, là thách thức nhưng có tác động. Sự kết hợp này làm cho việc khám phá thú vị nhưng phân tích kết quả là đa chiều qua các tập dữ liệu, mẫu, lựa chọn prompt-tuning, thuộc tính nhạy cảm, các nhóm được bảo vệ của chúng, mô hình, thước đo công bằng (thiên lệch), và biểu diễn đồ họa của chúng. Chúng tôi đã cố gắng hết sức để trình bày kết quả theo cách toàn diện nhất.

Thiết kế Mẫu
Chúng tôi sử dụng các mẫu probe công bằng của (Czarnowska, Vyas, and Shah 2021). Chúng cung cấp một baseline quan trọng cho các thí nghiệm, nhưng bao gồm các câu đơn giản, thường dễ hiểu bởi các LLM. Mặc dù vậy, sự chênh lệch nhất quán và đáng kể được quan sát cho các nhóm nhất định. Tuy nhiên, điều này có thể là nguyên nhân của kết quả ít kết luận cho một số nhóm. Trong công việc tương lai, chúng tôi nhằm thực hiện các thí nghiệm sử dụng các mẫu phức tạp hơn.

Loại Thiên lệch
Nhiều bài báo (Czarnowska, Vyas, and Shah 2021) dựa vào các giá trị tuyệt đối của sự chênh lệch thước đo để đơn giản tiết lộ sự hiện diện và độ lớn tiềm ẩn của thiên lệch. Chúng tôi sử dụng một thước đo thiên lệch định hướng để xác định các nhóm được ưu tiên và không được ưu tiên, cung cấp phân tích thiên lệch chính xác hơn của các LLM. Tuy nhiên, một nhóm được gắn cờ là nhóm thuận lợi có thể được gắn cờ là bất lợi bằng cách sử dụng một thước đo định lượng thiên lệch khác hoặc xem xét một tác vụ downstream khác nhau. Do đó, các công thức định lượng thiên lệch khác nhau (Seyyed-Kalantari et al. 2021) có thể không thể đạt được đồng thời.

Tác động của Soft-prompt Tuning lên Thiên lệch
Đánh giá công bằng thông qua prompting, và prompt tuning nói riêng, cung cấp một số lợi thế so với các phương pháp fine-tuning truyền thống. Quan trọng nhất trong số đó là nó hiệu quả hơn đáng kể về tài nguyên trong khi tạo ra hiệu suất tác vụ downstream có thể so sánh (Lester, Al-Rfou, and Constant 2021) trong các mô hình lớn. Ngoài ra, continuous prompt tuning giảm thiểu ảnh hưởng tiềm ẩn của các thiên lệch tồn tại trong các tác vụ huấn luyện có giám sát bằng cách hạn chế số lượng tham số được học. Cuối cùng, nó loại bỏ yếu tố con người của thiết kế prompt, loại bỏ một con đường khác cho việc giới thiệu thiên lệch bên ngoài LLM chính nó. Cần lưu ý rằng chúng tôi đã thực hiện soft-prompt tuning trên các tập dữ liệu tiêu chuẩn được tạo ra từ tweet (SemEval) và đánh giá phim (SST-5). Chất lượng của các tập dữ liệu này có tác động mạnh mẽ đến các soft-prompt được tạo ra. Khám phá cách một tập dữ liệu chất lượng tốt hơn (nếu có sẵn) ảnh hưởng đến hiệu suất của tác vụ downstream và các thiên lệch là quan tâm.

Ngoài các hướng được đề cập ở trên, chúng tôi dự định mở rộng công việc của mình bằng cách bao gồm một phạm vi rộng hơn các LM, mở rộng đến nhiều thuộc tính nhạy cảm hơn, xem xét nhiều thước đo thiên lệch hơn và kết hợp các tác vụ downstream khác. Đây là một nỗ lực để làm cho việc sử dụng LLM an toàn hơn và đạo đức hơn trong triển khai thế giới thực.

Phụ lục
A Từ vựng Công bằng
Thuộc tính nhạy cảm: Một thuộc tính trong đó thiên lệch xã hội có thể được thể hiện. Ví dụ bao gồm tuổi tác, khuyết tật, giới tính, quốc tịch, chủng tộc, tôn giáo và tình dục.
Nhóm được bảo vệ: Mỗi thuộc tính nhạy cảm bao gồm các nhóm được bảo vệ khác nhau mà hành vi mô hình nên duy trì nhất quán.

B Chi tiết Siêu tham số
Chúng tôi đã tiến hành tìm kiếm siêu tham số trên phần xác thực của SemEval và SST5 cho các giá trị tỷ lệ học có thể sau: 0.01, 0.001, 0.0001. Tỷ lệ học tốt nhất cho tất cả các mô hình OPT là 0.001, ngoại trừ OPT-13B, sử dụng 0.0001. Tỷ lệ 0.0001 được áp dụng cho cả hai kích thước mô hình LLaMA. Số lượng token prompt cho tất cả các mô hình được cố định ở 8. Giá trị này cũng được chọn bằng tìm kiếm siêu tham số trên độ dài prompt là 16. Cuối cùng, các random seed được sử dụng cho 15 lần chạy điều chỉnh cho mỗi thí nghiệm dao động từ 1001 đến 1015.

C Tập dữ liệu
Đối với mỗi mô hình, chúng tôi điều chỉnh các prompt liên tục trên các tập dữ liệu SemEval và SST5. Tập dữ liệu SemEval là một bộ sưu tập các tweet tiếng Anh với nhãn số nguyên trong [-3,3]. Theo (Czarnowska, Vyas, and Shah 2021), các nhãn này được nén bằng ánh xạ {Negative 0: [-3, -2], Neutral 1: [-1, 0, 1], Positive 2: [2, 3]}. Các nhãn của SST-5 (very positive, positive, neutral, negative, very negative) dựa trên các đánh giá phim tiếng Anh ngắn gọn và, do đó, tạo thành một corpus cơ bản rất khác. Như với các nhãn valence SemEval, các annotation năm chiều của SST-5 được thu gọn thành phân loại ba chiều bằng cách giữ lại nhãn neutral và ánh xạ polarity tích cực và tiêu cực của bất kỳ loại nào đơn giản thành các lớp positive hoặc negative, tương ứng.

D Kết quả Gap cho Khuyết tật
Trong phần này, các nhóm được bảo vệ thuộc về thuộc tính nhạy cảm về khuyết tật được xem xét. Hình 6 và 7 và hiển thị các Positive và Negative FPR gap được đo lường, tương ứng, cho các mô hình OPT và LLaMA được prompt-tuned trên tập dữ liệu SST-5. Về Positive FPR, có nhiều gap tiêu cực có ý nghĩa thống kê cho các ví dụ liên quan đến khiếm thính, khuyết tật di chuyển và khiếm thị. Ngoài ra, các gap tích cực được thấy cho các nhóm được ký hiệu bởi khuyết tật nhận thức và thể chất.

Đối với Negative FPR, một gap tích cực lớn được thấy cho các ví dụ thuộc về nhóm bệnh tật mãn tính. Các gap nhỏ, nhưng có ý nghĩa thống kê tiêu cực, cho khiếm thính và khuyết tật thể chất có mặt qua các cấu hình thí nghiệm khác nhau.

Tài liệu tham khảo
[Danh sách đầy đủ các tài liệu tham khảo như trong bản gốc]

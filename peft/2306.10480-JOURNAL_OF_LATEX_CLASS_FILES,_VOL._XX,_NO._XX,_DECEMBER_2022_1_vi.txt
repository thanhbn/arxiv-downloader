# 2306.10480.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2306.10480.pdf
# Kích thước tệp: 4112926 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
JOURNAL OF LATEX CLASS FILES, VOL. XX, NO. XX, DECEMBER 2022 1
IF2Net: Mạng học liên tục không quên tự nhiên
Depeng Li, Tianqi Wang, Bingrong Xu, Kenji Kawaguchi, Zhigang Zeng, Fellow, IEEE ,
và Ponnuthurai Nagaratnam Suganthan, Fellow, IEEE

Tóm tắt—Học liên tục có thể hấp thụ từng bước các khái niệm mới mà không can thiệp vào kiến thức đã học trước đó. Được thúc đẩy bởi các đặc điểm của mạng nơ-ron, trong đó thông tin được lưu trữ trong các trọng số trên các kết nối, chúng tôi đã nghiên cứu cách thiết kế một Mạng Không Quên Tự Nhiên (IF2Net) cho ngữ cảnh học liên tục. Nghiên cứu này đề xuất một mô hình học đơn giản nhưng hiệu quả bằng cách khéo léo giữ nguyên các trọng số liên quan đến mỗi nhiệm vụ đã thấy trước và sau khi học một nhiệm vụ mới. Chúng tôi đầu tiên trình bày kỹ thuật học ở cấp độ biểu diễn mới trên chuỗi nhiệm vụ với trọng số ngẫu nhiên. Kỹ thuật này đề cập đến việc điều chỉnh các biểu diễn bị lệch do ngẫu nhiên hóa trở lại trạng thái hoạt động tối ưu cho từng nhiệm vụ riêng biệt, nhưng các trọng số liên quan được đóng băng và tái sử dụng (ngược với việc cập nhật trọng số theo từng lớp nổi tiếng). Sau đó, việc ra quyết định tuần tự mà không quên có thể đạt được bằng cách chiếu các cập nhật trọng số đầu ra vào không gian trực giao tiết kiệm, làm cho các thích ứng không làm xáo trộn kiến thức cũ trong khi duy trì tính dẻo của mô hình. IF2Net cho phép một mạng duy nhất vốn có thể học các quy tắc ánh xạ không giới hạn mà không cần biết danh tính nhiệm vụ tại thời điểm kiểm tra bằng cách tích hợp các điểm mạnh tương ứng của ngẫu nhiên hóa và trực giao hóa. Chúng tôi đã xác thực hiệu quả của phương pháp trong phân tích lý thuyết và nghiên cứu thực nghiệm mở rộng.

Thuật ngữ chỉ mục—Học liên tục, quên nghiêm trọng, học biểu diễn ngẫu nhiên, không gian trực giao tiết kiệm

✦

1 GIỚI THIỆU

HỌC liên tục (CL) là khả năng học và ghi nhớ một chuỗi các nhiệm vụ, từng cái một, với tất cả dữ liệu của nhiệm vụ hiện tại có sẵn nhưng không có các nhiệm vụ trước đó hoặc tương lai [1]. Tuy nhiên, ngay cả các mạng nơ-ron sâu (DNN) tiên tiến hiện nay cũng sẽ gặp phải sự suy giảm nghiêm trọng về hiệu suất nhận dạng, được gọi là hiện tượng quên nghiêm trọng, khi các nhiệm vụ được huấn luyện tuần tự [2], [3]. Các nguyên nhân chính có thể là hai mặt. (i) DNN về cơ bản là các mô hình kết nối được xây dựng bởi một nhiệm vụ mục tiêu, trong đó thông tin thu được được lưu trữ trong các trọng số kết nối giữa các lớp liền kề. Một ánh xạ đã học trước đó của một nhiệm vụ cũ sẽ bị xóa nếu người ta trực tiếp sử dụng gradient descent tiêu chuẩn để học các ánh xạ mới. Do đó, mô hình bị ghi đè tham số sẽ chỉ nhớ tốt nhiệm vụ được học gần đây nhất. (ii) Một trong những mô hình cơ bản nhất trong machine learning là dữ liệu kiểm tra được phân phối tương tự như dữ liệu huấn luyện, được gọi là độc lập và phân phối đồng nhất (IID). Tuy nhiên, Non-IID xảy ra khi mỗi nhiệm vụ xuất hiện theo chuỗi, ví dụ, phân phối đầu vào đang thay đổi hoặc/và các danh mục mới chưa biết xuất hiện trong các nhiệm vụ tương lai. Điều này dẫn đến sự xuyên âm giữa các nhãn ở lớp đầu ra khi ra quyết định.

Gần đây, CL đã nhận được sự quan tâm ngày càng tăng từ cộng đồng machine learning [4], [5], [6], [7], [8]. Công trình trước đây được biết đến rộng rãi về chủ đề này thuộc ba họ. Đầu tiên, các phương pháp dựa trên replay, ví dụ, exemplar replay, đề cập đến việc duy trì một cách đơn giản một số lượng hạn chế các mẫu từ mỗi nhiệm vụ đã thấy và sau đó pha trộn chúng với nhiệm vụ mới để truy xuất kiến thức đã học [9], [10]. Mặc dù được hỗ trợ bởi bộ đệm exemplar, ngân sách bộ nhớ bị giới hạn thường mang theo kiến thức cụ thể của nhiệm vụ không đầy đủ, và việc học vẫn sẽ bị thiên hướng về ánh xạ hiện tại. Hơn nữa, những phương pháp này không khả thi khi dữ liệu từ các nhiệm vụ trước đó không thể truy cập được do hạn chế bộ nhớ hoặc vấn đề riêng tư [11], [12]. Các đối tác replay tạo sinh của chúng, thay vào đó, nhằm mục đích tạo ra các quan sát trong quá khứ trong các mẫu giả bằng cách sử dụng bộ tạo dữ liệu [13], [14]. Tuy nhiên, điều này chuyển áp lực từ một mô hình được đánh giá sang mạng tạo sinh, khiến việc yêu cầu mô-đun bên ngoài khôi phục chính xác những ánh xạ cũ này trở nên đòi hỏi [15]. Thứ hai, các phương pháp dựa trên regularization cố gắng hạn chế trọng số mà không có những thay đổi lớn bằng cách áp đặt các hình phạt theo từng lớp [16], [17]. Để đạt được điều này, các thuật ngữ regularization tích lũy được sử dụng cho các trọng số kết nối sao cho các cập nhật chỉ xảy ra theo các hướng bị ràng buộc trong quá trình huấn luyện tuần tự [12], [18]. Mặc dù những phương pháp này tránh lưu trữ dữ liệu, các mục tiêu của các nhiệm vụ trong quá khứ làm cho một mô hình khá không linh hoạt để tìm các tham số tối ưu khi số lượng nhiệm vụ lớn [19]. Thứ ba, các phương pháp dựa trên kiến trúc động mở rộng dần dần một mạng trong đó các trọng số mới được gán độc quyền phụ trách các nhiệm vụ mới [20], [21], [22]. Điều này tương đương với việc phân bổ dung lượng bổ sung cho mỗi nhiệm vụ, và độ phức tạp bộ nhớ tăng theo số lượng nhiệm vụ [23]. Thú vị là, quên nghiêm trọng không thể được cố ý quy cho dung lượng mạng không đủ vì các mạng cùng kích thước có thể phù hợp tốt với nhiều nhiệm vụ khi được huấn luyện theo cách xen kẽ hoặc bằng cách sử dụng dữ liệu của tất cả các nhiệm vụ đã thấy cho đến nay [24], [25].

Nhiều công trình tiếp theo tập trung vào những thiếu sót được quan sát ở trên và tiếp tục nâng cao hiệu suất CL theo nhiều cách khác nhau, chẳng hạn như đa dạng hóa các exemplar hạn chế [26], [27], ràng buộc độ lớn của các thay đổi trọng số [28], [29], và nén kích thước mạng mở rộng bổ sung [30], [31], như được tóm tắt sau trong phần công trình liên quan. Tuy nhiên, chúng tôi thấy rằng, trong hầu hết các phương pháp CL, các cập nhật theo từng lớp của trọng số được tối ưu hóa bằng cách sử dụng stochastic gradient descent không tránh khỏi hoặc can thiệp vào kiến thức cũ hoặc cản trở việc học cho các nhiệm vụ sắp tới. Điều này thúc đẩy nghiên cứu của chúng tôi về việc khai thác các trọng số có tính dẻo cao và khám phá tính bất biến của trọng số trong quá trình huấn luyện tuần tự, và quan trọng nhất, thiết kế một mạng đơn giản vốn có khả năng chống chọi với việc quên. Do đó tên gọi, mạng không quên tự nhiên (IF2Net). Ý tưởng cốt lõi là giữ nguyên các trọng số liên quan đến mỗi nhiệm vụ đã thấy suốt thời gian, điều này không được nghiên cứu kỹ theo hiểu biết tốt nhất của chúng tôi.

Trong mỗi phiên huấn luyện, IF2Net, với ngẫu nhiên hóa và trực giao hóa, cung cấp một giải pháp có hệ thống cho các thách thức CL, sao cho nó có khả năng học các ánh xạ đầu vào-đầu ra song song không giới hạn dưới cài đặt task-agnostic.

Nghiên cứu được trình bày có thể được coi là một nghiên cứu mở rộng của các họ CL hiện có, cung cấp một ý tưởng và hướng đi sáng tạo cho nghiên cứu tương lai về CL. Những đóng góp và điểm mạnh chính của công trình này bao gồm:

•Một kỹ thuật học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa được phát triển đầu tiên để tái tạo hoàn hảo các biểu diễn từ chuỗi nhiệm vụ. Chúng tôi thực hiện nó thông qua các lượt truyền tiến không giám sát, làm giảm các yêu cầu tính toán và bộ nhớ so với thuật toán back-propagation. Điều này cho phép, lần đầu tiên, các trọng số ngẫu nhiên (và bias) được tái chế để tạo ra các biểu diễn phân biệt.

•Chúng tôi giới thiệu việc ra quyết định dựa trên trực giao hóa vào lớp đầu ra cuối cùng để vượt qua nghịch lý ổn định-dẻo. Do đó, các trọng số đầu ra được cập nhật theo hướng trực giao với không gian con được mở rộng bởi các đặc trưng vừa thu được từ lớp gần cuối, loại bỏ sự không linh hoạt trong thực hành theo từng lớp ban đầu một cách triệt để nhất. Không gian trực giao tiết kiệm đảm bảo các trọng số đầu ra không bị ảnh hưởng liên quan đến tất cả các nhiệm vụ đã thấy. Đặc biệt, chúng tôi đã suy ra toán học ma trận chiếu trực giao để điều chỉnh gradient và cung cấp bằng chứng cho việc học mà không quên.

•IF2Net tiết kiệm bộ nhớ so với các phương pháp dựa trên replay và kiến trúc động vì nó không yêu cầu exemplar/tham số bổ sung khi các nhiệm vụ mới đến. Bên cạnh đó, phương pháp được đề xuất tương thích với hầu hết, nếu không muốn nói là tất cả, các phương pháp CL do tính tổng quát của nó và do đó, thúc đẩy những kỹ thuật tương ứng đó trong việc đạt được kết quả tiên tiến mới, ví dụ, cùng với elastic weight consolidation (EWC) điển hình để tăng cường biên.

•Chúng tôi đã chứng minh hiệu quả của phương pháp trong kịch bản học tăng dần theo lớp, được đánh giá bằng ba chỉ số, và các thí nghiệm mở rộng cho thấy IF2Net liên tục vượt trội hơn các phương pháp tiên tiến trước đó trên các benchmark MNIST, FashionMNIST, CIFAR-100, Stanford Dogs, CUB-200, và ImageNet-Subset.

Phần còn lại của bài báo này được tổ chức như sau. Phần 2 giới thiệu các công trình liên quan. Trong Phần 3, chúng tôi trình bày các thiết lập CL và sau đó chi tiết IF2Net được đề xuất trong Phần 4. Phần 5 tiến hành các thí nghiệm mở rộng trên sáu bộ dữ liệu benchmark để đánh giá tính ưu việt của phương pháp của chúng tôi. Cuối cùng, chúng tôi kết luận bài báo và đề xuất nghiên cứu tương lai trong Phần 6.

2 CÔNG TRÌNH LIÊN QUAN

Học liên tục. Một mô hình học, còn được gọi là học suốt đời/tăng dần, đã được đề xuất để tạo ra sự cân bằng giữa ổn định và tính dẻo [32], [33]. Nó đặt một mô hình duy nhất trong một môi trường động nơi nó phải thích ứng một luồng các nhiệm vụ để đưa ra các dự đoán mới mà không quên [25], [34]. Có ba danh mục chính của các thuật toán CL gần đây [4], [5], [32], [35].

Các phương pháp dựa trên replay xây dựng một bộ đệm exemplar để lưu các mẫu từ các nhiệm vụ trước đó và huấn luyện với dữ liệu nhiệm vụ hiện tại. Như một đại diện, gradient episodic memory (GEM) thu được một sự chuyển giao tích cực của kiến thức đến các nhiệm vụ trước đó bằng cách ràng buộc độc lập tổn thất của mỗi bộ nhớ episodic không tăng [10]. Incremental learning with dual memory (IL2M) sử dụng cả hình ảnh exemplar bị giới hạn và thống kê lớp trong quá khứ để chỉnh sửa dự đoán mạng [36]. Rainbow memory (RM) tập trung vào sự không chắc chắn phân loại để chọn các mẫu khó [37]. Hơn nữa, [26] khai thác thông tin không liên quan ngữ nghĩa phong phú từ dữ liệu không được gắn nhãn để đa dạng hóa các exemplar hạn chế. Tuy nhiên, các phương pháp dựa trên replay hoặc thường làm giảm hiệu suất với kích thước bộ đệm nhỏ hơn hoặc cuối cùng không áp dụng được cho các trường hợp mà quyền riêng tư dữ liệu cần được xem xét [11], [12]. Phương pháp của chúng tôi không dựa vào bộ đệm exemplar để giải quyết việc quên vì nó có thể vốn có phù hợp với các ánh xạ đã học trước đó, do đó thỏa mãn tiêu chí quyền riêng tư dữ liệu.

Các phương pháp dựa trên regularization hạn chế tính dẻo mô hình trong việc học các tham số quan trọng của các nhiệm vụ trước đó bằng cách thêm các thuật ngữ regularization bổ sung. Elastic weight consolidation (EWC) là một người tiên phong của họ này, sử dụng ước lượng Bayesian tuần tự và ma trận thông tin Fisher để regularize các cập nhật trọng số [16]. Các phương pháp đại diện theo sau nó bao gồm synaptic intelligence (SI) [17], memory aware synapses (MAS) [12], và mỗi tham số mạng được kết hợp với tầm quan trọng trọng số được tính toán bằng các chiến lược khác nhau. Dưới khung Bayesian, một tập hợp phương pháp khác lấy phân phối posterior của các tham số mạng làm hình phạt ngầm [38], [39], [40]. Mặc dù những phương pháp này giải quyết việc quên ở một mức độ nào đó mà không lưu trữ các ví dụ trong quá khứ, chúng không thể hoạt động thỏa đáng trong các cài đặt thách thức hoặc với các bộ dữ liệu phức tạp. Ngược lại, phương pháp của chúng tôi có thể làm giảm yêu cầu đòi hỏi của chúng về tối ưu hóa tham số và mang theo chúng để thiết lập một trạng thái nghệ thuật mới.

--- TRANG 3 ---
Các phương pháp dựa trên kiến trúc động thích ứng động các kiến trúc mạng bằng cách mở rộng hoặc thao tác mặt nạ để phù hợp với kiến thức cần thiết cho các nhiệm vụ mới. Một mạng nơ-ron tiến bộ (PNN) được đề xuất để dần dần thêm các nhánh mới cho tất cả các lớp theo chiều ngang [41]. Một mạng lựa chọn đường dẫn ngẫu nhiên (RPS-Net) tận dụng các mô-đun song song tại mỗi lớp trong đó một không gian tìm kiếm có thể được hình thành để chứa kiến thức cụ thể của nhiệm vụ trước đó [32] để giảm thiểu sự mở rộng không thể kiểm soát của kích thước mạng. Các tham số mô hình trong additive parameter decomposition (APD) được phân tách thành các phần được chia sẻ và cụ thể cho nhiệm vụ bằng cách sử dụng mặt nạ [42]. Efficient feature transformation (EFT) đề xuất một khung cụ thể cho nhiệm vụ nhỏ gọn để vượt qua việc quên nghiêm trọng [20]. Per-class learning (PCL) sử dụng thiết lập đa đầu kích thước nhỏ nơi nó tạo nhánh một lớp đầu ra độc quyền cho các lớp đã học cho đến nay thông qua học một lớp [23], [43]. Với học dựa trên prompt, [44] thiết kế một cơ chế truy vấn để động tìm kiếm một tập con các prompt liên quan đến nhiệm vụ bằng cách giới thiệu nhẹ các tham số prompt bổ sung. Ngược lại, phương pháp của chúng tôi được đặc trưng bởi một mạng không tăng trưởng, có nghĩa là IF2Net có thể không đổi về số lượng tham số.

Mạng nơ-ron với trọng số ngẫu nhiên. Trong học một nhiệm vụ thông thường, huấn luyện một mạng nơ-ron feed-forward một lớp ẩn duy nhất với trọng số ngẫu nhiên (NN-RW) đã chứng minh tiềm năng lớn trong việc phát triển các mô hình dễ thực hiện, trong đó chỉ cần điều chỉnh các trọng số đầu ra [45], [46], [47]. Qua nhiều thập kỷ nghiên cứu, NN-RW đang nhận được ngày càng nhiều sự chú ý [48], [49], [50], [51], [52]. Độc giả có thể tham khảo [53], [54], [55], [56] để có cái nhìn tổng quan toàn diện về các kỹ thuật học ngẫu nhiên hóa. Ở đây, một vấn đề kỹ thuật quan trọng nằm ở việc gán ngẫu nhiên các trọng số đầu vào (và bias) sao cho mô hình học ngẫu nhiên hóa chia sẻ khả năng xấp xỉ vạn năng theo cách xác định hoặc không xác định. Việc gán ngẫu nhiên các trọng số đầu vào (và bias) từ một phân phối xác suất cố định nghe có vẻ đơn giản và nhanh chóng và đã được random vector functional-link network (RVFLN) [45], extreme learning machine (ELM) [57], stochastic configuration network (SCN) [49], và broad learning system (BLS) [50] áp dụng phổ biến. Các mạng nơ-ron kết quả với các tham số ẩn ngẫu nhiên cố định có thể có khả năng xấp xỉ vạn năng theo nghĩa xác suất, với điều kiện là một phân phối thích hợp (ví dụ, một phạm vi đồng nhất [r,−r], r > 0) được thiết lập đúng cách trước [58], [59], [60]. Điều này có nghĩa là một "phạm vi hỗ trợ" nhất định dẫn đến một bộ xấp xỉ vạn năng ngẫu nhiên hóa tồn tại và phụ thuộc vào dữ liệu cho một nhiệm vụ đã cho. Được truyền cảm hứng bởi điểm kỹ thuật này, chúng tôi nhằm mục đích mở rộng các tham số ẩn ngẫu nhiên cố định để vượt qua việc quên nghiêm trọng. Tuy nhiên, không có công trình nào được trình bày cho đến nay về CL với sự giúp đỡ của kỹ thuật học ngẫu nhiên hóa do bản chất ngẫu nhiên của nó (biến động hiệu suất), kiến trúc nông (biểu diễn kém), và điều kiện IID (giống như DNN). Điều này thúc đẩy nghiên cứu của chúng tôi về việc xây dựng học ở cấp độ biểu diễn ổn định với nhiều lớp ẩn ngẫu nhiên hóa trên chuỗi nhiệm vụ để lấp đầy khoảng trống. Để đạt được điều này, chúng tôi sẽ cải thiện đáng kể NN-RW, như được giải thích trong Phần 4.2 và 4.5.1.

Gradient descent trực giao. Gần đây, một số tài liệu đã bắt đầu xem xét chiến lược gradient descent trực giao, một biến thể back-propagation [61], bằng cách giữ cố định các ánh xạ đầu vào-đầu ra [28], [62], [63]. Để đạt được điều này, các trọng số mạng được tối ưu hóa tuần tự trong không gian trực giao của các đầu vào/đặc trưng đã học trước đó của mỗi lớp tuyến tính. Các công trình tiên phong bao gồm conceptor-aided backpropagation (CAB) [28] và orthogonal weights modification (OWM) [62], chúng dựa vào các lý thuyết toán học khác nhau để tính toán không gian con trực giao một cách xấp xỉ. Cụ thể, một ma trận chiếu trực giao trong mỗi lớp của mạng được xây dựng để bảo tồn kiến thức đã học. Hơn nữa, các gradient trong mạng nơ-ron được chiếu vào hướng trực giao của tất cả các đặc trưng đã học trước đó bằng ma trận chiếu trực giao trong quá trình học một nhiệm vụ mới. Không giống như CAB và OWM, chúng tôi chỉ áp dụng nó vào lớp đầu ra cuối cùng để ra quyết định trong khi đơn giản hóa dạng của bộ chiếu trực giao. Các khác biệt và điểm mạnh chi tiết sẽ được thảo luận trong Phần 4.3, 4.5.2, và 4.5.3.

3 THIẾT LẬP HỌC LIÊN TỤC

Định nghĩa. Chúng tôi tập trung phạm vi công việc của mình vào kịch bản học tăng dần theo lớp phổ biến nhất nhưng thách thức nhất, cụ thể là CIL [64], [65]. Một mô hình trong kịch bản này giải quyết mỗi nhiệm vụ đã thấy cho đến nay và suy luận nhiệm vụ nào nó sẽ gặp phải, bao gồm vấn đề thực tế phổ biến của việc học tăng dần các lớp đối tượng mới.

Về mặt toán học, chúng ta hãy bắt đầu bằng cách định nghĩa CIL. Cho các bộ dữ liệu học có giám sát Dt={(Xt,Yt)|Xt∈ RNt×Mt,Yt∈RNt×Ct} của nhiệm vụ t(t= 1,2, . . .), trong đó Xt là đầu vào, Yt là nhãn, Nt là số lượng mẫu, Mt và Ct lần lượt là các chiều của dữ liệu đầu vào và các lớp đầu ra. Giả sử một mô hình f(Xt−1;θt−1) (t≥2) được huấn luyện trên (các) nhiệm vụ trước đó, được tham số hóa bởi các trọng số kết nối θt−1, mục tiêu là huấn luyện một mô hình cập nhật f(Xt;θt) có thể phù hợp với Ct lớp mới xuất hiện [66], tức là, f(XT;θT) cần nhớ cách thực hiện tốt trên tổng cộng C=∑T t=1 Ct lớp. Trong khi đó, dữ liệu của các nhiệm vụ trước đó Dt(t= 1,2, . . . , T − 1) cho f(XT;θT) không có sẵn ngoại trừ các phương pháp/baseline dựa trên replay, ví dụ, một số ít mẫu trong bộ đệm exemplar có thể được xem lại. Tại thời điểm kiểm tra, mô hình kết quả sẽ được đưa các mẫu từ bất kỳ nhiệm vụ nào từ 1 đến T mà không cho biết định danh nhiệm vụ/oracle và được đánh giá bằng các chỉ số CL tiêu chuẩn được công thức hóa như sau.

Chỉ số. Chúng tôi theo dõi ba thống kê để phản ánh chất lượng của các phương pháp CL (tất cả đều càng cao càng tốt). Đầu tiên, độ chính xác kiểm tra trung bình cuối cùng (ACC) được báo cáo trong phần lớn tài liệu được định nghĩa là:

ACC =1/T ∑T t=1 RT,t (1)

trong đó RT,t có nghĩa là độ chính xác phân loại kiểm tra của một mô hình trên nhiệm vụ t sau khi huấn luyện trên nhiệm vụ T. ACC đo lường mức độ hiệu suất trung bình của mô hình suy giảm khi nó học các nhiệm vụ mới và trực tiếp hiển thị hiệu suất kiểm tra của một mô hình trên tất cả các nhiệm vụ đã thấy cho đến nay. Thứ hai, chuyển giao ngược (BWT) [10] được định nghĩa là sự khác biệt về độ chính xác giữa khi một nhiệm vụ được huấn luyện đầu tiên và sau khi huấn luyện trên nhiệm vụ cuối cùng, trung bình trên tất cả các nhiệm vụ:

--- TRANG 4 ---
BWT =1/(T−1) ∑T−1 t=1 RT,t−Rt,t (2)

Nó chỉ ra khả năng của một mô hình trong việc giữ gìn kiến thức. Kết quả là, giá trị BWT thấp hơn tương ứng với việc quên nghiêm trọng, trong khi BWT = zero được coi là không quên. Thứ ba, chuyển giao tiến (FWT) [67] định nghĩa sự cải thiện trung bình về độ chính xác trên một nhiệm vụ mới so với một mô hình được huấn luyện độc lập trên nhiệm vụ đó, được thể hiện là:

FWT =1/(T−1) ∑T t=2 Rt,t−Rind t (3)

trong đó Rind t là độ chính xác phân loại kiểm tra của một mô hình độc lập được huấn luyện chỉ trên nhiệm vụ t. FWT ước tính mức độ tốt của một mô hình sử dụng kiến thức đã học trước đó để cải thiện độ chính xác phân loại trên các nhiệm vụ mới được thấy. Thật vậy, BWT và FWT bổ sung cho ACC, ví dụ, nếu hai mô hình có ACC tương tự, mô hình ưa thích hơn chia sẻ BWT và FWT lớn hơn.

4 MẠNG KHÔNG QUÊN TỰ NHIÊN

4.1 Tổng quan

Phần này giải thích cách chúng tôi thách thức sự can thiệp giữa các nhiệm vụ tuần tự bằng cách thiết kế một mạng không quên tự nhiên gọi là IF2Net. Để đạt được điều này, chúng tôi đã kết hợp các phép chiếu kép (ngẫu nhiên hóa và trực giao hóa) vào IF2Net sao cho nó có thể giữ các trọng số liên quan đến mỗi nhiệm vụ đã thấy không bị động trước và sau khi học một nhiệm vụ mới. Đặc biệt, quá trình CL chủ yếu được trung gian bởi học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa trong một số lớp ẩn và việc ra quyết định dựa trên trực giao hóa trong lớp đầu ra cuối cùng. Một cái nhìn tổng quan được hiển thị trong Hình 1. Để có được một sự nắm bắt tốt về mô hình học được tạo ra bởi IF2Net, xác minh lý thuyết của hai tính chất chính, chẳng hạn như phân tích hội tụ của xấp xỉ biểu diễn và bằng chứng của quyết định học-mà-không-quên, được cung cấp với các suy diễn toán học nghiêm ngặt, cho thấy tính khả thi của phương pháp được đề xuất dưới những điều kiện nhất định. Sau đó, chúng tôi sẽ làm nổi bật các đóng góp chính và nguyên bản với cuộc thảo luận sâu sắc.

4.2 Học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa

Động lực để giới thiệu học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa là ba mặt. Đầu tiên, việc huấn luyện lại trực tiếp một mạng sửa đổi các trọng số kết nối của nó khỏi các giải pháp tối ưu cho các nhiệm vụ cũ với việc học mới ghi đè các biểu diễn hiện có. Thứ hai, ngay cả khi các "bộ nhớ" bổ sung (như bộ đệm exemplar, trọng số mô hình, và ma trận regularization) của các nhiệm vụ trong quá khứ được sử dụng để truy xuất kiến thức đã học trước đó, các cập nhật theo từng lớp của trọng số được tối ưu hóa bởi stochastic gradient descent hoặc can thiệp vào kiến thức cũ hoặc cản trở việc học cho các nhiệm vụ sắp tới. Thứ ba, NN-RW với các tham số ẩn ngẫu nhiên cố định có thể chia sẻ một tính chất xấp xỉ vạn năng cho một nhiệm vụ [68], tức là, người ta có thể bớt nhấn mạnh tầm quan trọng của trọng số bằng cách gán ngẫu nhiên các trọng số đầu vào (và bias). Do đó, thay vì tối ưu hóa trọng số lớp ẩn của một mạng cố định, chúng tôi thay vào đó nhấn mạnh các kích hoạt cần thiết (biểu diễn) hoạt động tốt trên một chuỗi các nhiệm vụ. Kỹ thuật này thách thức thực hành phổ biến để đẩy các biểu diễn bị lệch do ngẫu nhiên hóa trở lại trạng thái hoạt động tối ưu cho từng nhiệm vụ riêng biệt của chúng, trong đó các trọng số ngẫu nhiên (và bias) liên quan được tái sử dụng. Chi tiết như sau.

4.2.1 Quá trình học ở cấp độ biểu diễn

Trước khi quá trình học ở cấp độ biểu diễn bắt đầu, IF2Net tận dụng các đặc trưng đại diện từ một CNN được huấn luyện trước (mặc dù nó không bắt buộc); tuy nhiên, thay vì điều chỉnh các tham số trong quá trình CL, IF2Net giữ mô hình được huấn luyện trước cố định vì các lớp đầu của CNN có thể có tính chuyển giao cao [69], [70], và học tăng dần một tập hợp các biểu diễn phong phú từ các nhiệm vụ sắp tới khi được sử dụng, giống với những gì [23], [44], [62], [70], [71] đã thực hiện. Do đó, đầu vào của IF2Net có thể là các mẫu gốc X từ các nhiệm vụ đồ chơi (MNIST và FashionMNIST) hoặc các đặc trưng được trích xuất XF từ các nhiệm vụ chiều cao (Stanford Dogs, CUB-200, CIFAR-100, và ImageNet-Subset). Chúng tôi sử dụng X để biểu thị cả hai biến để đơn giản hóa ký hiệu.

Cấu trúc liên kết được sử dụng trong học ở cấp độ biểu diễn bao gồm một số lớp kết nối đầy đủ (FC) thường được sử dụng, nhưng quá trình huấn luyện hoàn toàn khác với công việc trước đó. Với sự giúp đỡ của các trọng số được khởi tạo ngẫu nhiên (và bias) trong các lớp ẩn, các đầu vào/đặc trưng được biến đổi thành một không gian biểu diễn ngẫu nhiên, có thể giúp khai thác thông tin ẩn giữa các mẫu huấn luyện. Đặc biệt, mỗi lớp l(l= 0,1, . . . , L −1) trong phần con này phân bổ ngẫu nhiên Sl nút được cấu thành

--- TRANG 5 ---
Hình 2. Quá trình học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa. Lấy FC1 làm ví dụ. Khi Xt(t= 1,2, . . .) có mặt, chúng tôi đầu tiên sử dụng các trọng số được gán ngẫu nhiên (mũi tên chấm màu đen, trái) để có khả năng tạo ra các phản hồi kém gọi là biểu diễn bị lệch (mũi tên đặc màu đen, phải). Sau đó, chúng được điều chỉnh bởi tinh chỉnh không giám sát trở lại trạng thái hoạt động tối ưu cho từng nhiệm vụ riêng biệt của chúng (mũi tên đặc màu đỏ, phải). Học ở cấp độ biểu diễn tiến có thể hoạt động tốt trên chuỗi nhiệm vụ mà không cần sửa đổi trọng số. Xem tốt nhất với màu.

của nl nhóm khối nút, với mỗi nhóm sl nút để đa dạng hóa các đối tác của chúng về biểu diễn đầu ra. Trong phần tiếp theo, chúng tôi sử dụng một triển khai kết nối đầy đủ ba lớp đơn giản (xem Các lớp ẩn nằm ở bảng dưới của Hình 1) để mô tả quá trình học ở cấp độ biểu diễn. Đầu tiên, chúng tôi định nghĩa hàm tiến của khối nút thứ j (j= 1,2, . . . , n l+1) tại lớp l+ 1 như sau:

Vl+1 j=σ(˜VlWl j+ 1Ntbl j) (4)

trong đó ˜Vl∈RNt×Sl là các kích hoạt được điều chỉnh (biểu diễn) từ lớp trước l, ma trận Wl j∈RSl×sl+1 và vector hàng bl j∈R1×sl+1 lần lượt là các trọng số được gán ngẫu nhiên trong phạm vi thiết lập thích hợp (ví dụ, [−1,1]) [59], 1Nt∈RNt là vector cột với mọi mục là một, và σ(·) là hàm kích hoạt tại mỗi lớp. Lưu ý rằng ˜V0=Xt và θ= (Wl j,bl j). Tuy nhiên, các lượt truyền tiến đơn lẻ ở trên có khả năng dẫn đến các biểu diễn bị lệch Vl+1 j (j= 1,2, . . . , n l+1) do ngẫu nhiên hóa [49], [59], như được mô tả trong Hình 2.

Để giải quyết vấn đề này, chúng tôi đã công thức hóa nó như một bài toán tối ưu hóa, và hàm mục tiêu được định nghĩa là:

˜θ∈argmin (˜Wl j,˜bl j)∥Vl+1 j˜Wl j+1Nt˜bl j−˜Vl∥2 2+∥˜Wl j∥1+∥˜bl j∥1(5)

trong đó ˜θ= (˜Wl j,˜bl j) là giải pháp trung gian, ∥ · ∥ 1 và ∥ · ∥ 2 lần lượt là chuẩn L1 và L2. Về mặt khái niệm, (5) có thể phục vụ như một bộ xử lý đặc trưng trong mạng nơ-ron phân cấp, trong đó phản hồi ngẫu nhiên hóa Vl+1 j được sử dụng để xấp xỉ đầu vào ˜Vl bằng cách giảm thiểu các lỗi tái tạo [50], [72]. Sau đó, biểu diễn bị lệch Vl+1 j có thể được điều chỉnh bằng cách thay thế θ thô bằng ˜θ được tinh chỉnh, tức là, ˜Vl+1 j=σ(˜Vl˜Wl j+ 1Nt˜bl j). Do đó, lượt truyền tiến này có thể quản lý để tinh chỉnh nhẹ mỗi nhóm phản hồi ngẫu nhiên hóa Vl+1 j (j= 1,2, . . . , n l+1) theo cách không giám sát nhưng đóng băng trọng số liên quan θ= (Wl j,bl j), sao cho các biểu diễn bị lệch của mỗi nhiệm vụ luôn có thể được kéo trở lại trạng thái hoạt động tối ưu riêng biệt/ban đầu của chúng ˜Vl+1 j (xem Hình 2) và do đó tái tạo hoàn hảo các biểu diễn của mỗi nhiệm vụ đã thấy cho đến nay, như được giải thích sau trong Phần 4.2.2. Trong khi đó, chúng ta có thể thu được đệ quy các kích hoạt được điều chỉnh ˜Vl+1= [˜Vl+1 1,˜Vl+1 2, . . . , ˜Vl+1 nl+1]

(a) (b) (c) (d) (e) (f)

Hình 3. Trực quan hóa t-SNE dựa trên benchmark Split FashionMNIST. Mỗi màu đại diện cho một lớp, và hai lớp được đưa vào các lớp ẩn từng bước như một nhiệm vụ độc lập. Trong chuỗi nhiệm vụ này, dữ liệu huấn luyện của tất cả các lớp cùng nhau được trực quan hóa đầu tiên như một tham chiếu, tiếp theo là các biểu diễn được điều chỉnh sau khi học từng bước hai lớp mỗi phiên. (a) Không gian mẫu thô hỗn hợp. (b)-(f) Không gian biểu diễn được gom cụm tốt tương ứng với các đầu ra được chiếu của FC3. IF2Net có thể tạo ra các biểu diễn có thể phân biệt từ một chuỗi các nhiệm vụ cho việc ra quyết định cuối cùng. Xem tốt nhất với màu.

trong lớp l+ 1 bằng cách nối tất cả nl+1 nhóm khối nút. Chúng tôi sẽ xác thực hiệu quả của nhiều khối nút trong Phần 5.3.2. Học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa ở trên chứng minh rằng các trọng số ngẫu nhiên được tái sử dụng (và bias) là khả thi để thu được các biểu diễn tối ưu từ chuỗi nhiệm vụ.

Trực giác đằng sau học ở cấp độ biểu diễn là hầu hết các phương pháp CL được thúc đẩy bởi tối ưu hóa ở cấp độ trọng số, điều này không nhất thiết là cách cơ bản mà các mô hình kết nối phân biệt và ghi nhớ kiến thức. Các trọng số liên quan trong các lớp ẩn có thể là tạm thời hoặc có thể vứt bỏ. Theo nghĩa này, thay vì đánh giá hiệu suất CL với các trọng số được tối ưu hóa toàn cầu, chúng ta có thể đo lường nó với các biểu diễn hiện tại. Do đó, cái sau có thể so sánh với một số phương pháp cho học một nhiệm vụ. Hãy xem xét FashionMNIST làm ví dụ. Hình 3 mô tả trực quan hóa t-SNE [73] của không gian mẫu thô và các biểu diễn được chiếu cuối cùng tương ứng với các đầu ra của FC3, điều này chỉ ra tiềm năng tốt của học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa. Các biểu diễn có thể phân biệt thu được từ một chuỗi các nhiệm vụ sau đó được sử dụng để ra quyết định trong lớp đầu ra cuối cùng.

4.2.2 Phân tích hội tụ

Ở đây, chúng tôi cung cấp một thuật toán lặp dựa trên mạng nơ-ron chiếu thời gian rời rạc [74] để giải quyết bài toán tối ưu hóa trong (5) và sau đó cung cấp một phân tích lý thuyết để giải thích liệu học ở cấp độ biểu diễn được đề xuất có hội tụ dưới những điều kiện nhất định hay không.

Cho g(u):Rn→Rn là một toán tử chiếu được định nghĩa trên một tập lồi đóng Ω={u⊆Rn:li≤ui≤hi, i= 1,2, . . . , n } khi đó,

g(ui) = {hi ui> hi ui li≤ui≤hi li ui< li (6)

--- TRANG 6 ---
đó là một hàm tuyến tính từng đoạn. Tính chất cho việc giải quyết vấn đề được trình bày trong bổ đề sau:

Bổ đề 1. [75] Giả sử có một ma trận đầy đủ hạng A. Đối với bất kỳ x∈Rn, Ax=b nếu và chỉ nếu Zx=q, trong đó Z=AT(AAT)−1A và q=AT(AAT)−1b.

Với những điều kiện tiên quyết này, chúng ta có thể viết lại tổng quát hàm mục tiêu trong (5) là:

arg min x∗:1/2∥Zx∗−qt∥2 2+λ∥x∗∥1 (7)

trong đó t∈N+ là chỉ số nhiệm vụ, qt là vector đầu vào mong muốn, Z là các biểu diễn bị lệch, λ là một vô hướng trọng số dương, và x∗ là đại diện liên kết với ˜θ. Tính chất hội tụ của học ở cấp độ biểu diễn được đề xuất có thể được phát biểu trong định lý sau:

Định lý 1. Đối với t∈N+, x∗∈Rn là một giải pháp tối ưu cho bài toán (7) nếu và chỉ nếu tồn tại y∗∈Rn sao cho x∗ và y∗ thỏa mãn:

{Zx∗−qt+λy∗= 0 y∗=g(y∗+x∗). (8)

Chứng minh 1. x∗∈Rn là một giải pháp tối ưu cho bài toán (7) nếu và chỉ nếu tồn tại y∗∈Rn sao cho x∗ và y∗ thỏa mãn điều kiện sau:

Zx∗−qt+λy∗= 0, t= 1,2, . . . (9)

trong đó y∗= [y∗ 1, y∗ 2, . . . , y∗ n]T là một subgradient của ∥x∗∥1 với mỗi thành phần y∗ j(j= 1,2, . . . , n ) được định nghĩa là:

y∗ j {= 1 x∗ j>0 ∈[−1,1] x∗ j= 0 =−1 x∗ j<0 (10)

Sau đó, y∗ thỏa mãn:

y∗=g(y∗+x∗) (11)

trong đó g(·) là một toán tử chiếu từ Rn→[−1,1]n như được định nghĩa trong (6) với li=−1 và hi= 1. □

Không mất tính tổng quát, giải pháp cho (7) có thể được mô tả lặp như sau [74]:

{x(k+ 1) = x(k)−γ(Zx(k))−qt+λg(y(k) +x(k)) y(k+ 1) = g(y(k) +x(k+ 1)) (12)

trong đó γ > 0 là độ lợi của mạng, x(k) là vector trạng thái, và y(k) lần lượt là vector đầu ra.

Phương trình được đề cập ở trên đã phân tích lý thuyết về cách kỹ thuật học ở cấp độ biểu diễn được đề xuất có thể hội tụ các phản hồi ngẫu nhiên hóa của các nhiệm vụ khác nhau về các giá trị tối ưu của chúng. Chúng tôi trình bày mã giả của quá trình học ở cấp độ biểu diễn trong Thuật toán 1 để làm rõ việc thực hiện thuật toán. Ngoài ra, chúng tôi lưu ý rằng nó đạt được hiệu suất tương tự nếu (7) được giải quyết theo cách khác, chẳng hạn như bằng cách mở rộng thuật toán co ngắn-ngưỡng lặp nhanh (FISTA) [76] cho học ở cấp độ biểu diễn.

Thuật toán 1 Học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa
Đầu vào: Các bộ dữ liệu Dt={(Xt,Yt)} của nhiệm vụ t; Một mạng cơ sở với L lớp ẩn; Số lượng khối nút nl và các nút trong mỗi khối sl; Các vô hướng dương λ và γ.
Đầu ra: Các biểu diễn kết quả của lớp thứ L VL.
1: # khởi tạo tham số từ một phạm vi đồng nhất
2: for l= 0,1, . . . , L −1 do
3: for j= 1,2, . . . , n l+1 do
4: Gán ngẫu nhiên trọng số Wl j và bias bl j;
5: end for
6: end for
7: # học ở cấp độ biểu diễn trên các nhiệm vụ tuần tự
8: for t= 1,2, . . . , T do
9: for l= 0,1, . . . , L −1 do
10: Thu được các biểu diễn bị lệch Vl+1 dựa trên (4);
11: Điều chỉnh các biểu diễn bị lệch dựa trên (5);
12: end for
13: end for

4.3 Ra quyết định dựa trên trực giao hóa

Trong ngữ cảnh CL, lớp đầu ra cuối cùng, được gọi là bộ phân loại, phải phù hợp với các phân phối đầu vào thay đổi hoặc/và các danh mục mới chưa biết xuất hiện trong các nhiệm vụ tương lai, điều này rất quan trọng đối với cả các nhiệm vụ đã học trước đó và sắp tới. Chúng tôi đã thực hiện một thuật toán trực giao hóa mà về mặt lý thuyết đạt được các quyết định không quên hoàn toàn bằng cách làm cho các trọng số được cập nhật không làm xáo trộn kiến thức cũ trong khi duy trì tính dẻo của mô hình. Trong phần tiếp theo, chúng tôi giải thích tại sao chúng tôi mong muốn hình thành một không gian trực giao tiết kiệm để ra quyết định, cách chúng tôi tận dụng trực giao hóa và thực hiện các cập nhật trọng số đầu ra một cách hiệu quả.

4.3.1 Không gian trực giao tiết kiệm

Sử dụng phương pháp gradient descent trực giao, các trọng số mạng có thể được tối ưu hóa tuần tự trong không gian trực giao của tất cả các đầu vào/đặc trưng đã học trước đó cho mỗi lớp FC [28], [62], [63]. Tuy nhiên, vì các trọng số được huấn luyện bị ràng buộc vào không gian tương ứng được hình thành bởi các nhiệm vụ trước đó, việc giảm thiểu lỗi bình phương trung bình hoặc tổn thất cross-entropy sẽ dẫn đến hai vấn đề chính:

Đầu tiên, trực giao hóa theo từng lớp đòi hỏi các yêu cầu tính toán và bộ nhớ lớn tỷ lệ thuận với số lượng lớp mạng. Nó cần lưu trữ và cập nhật ma trận chiếu cho mỗi lớp, giải thích tại sao thuật toán gradient descent trực giao đôi khi yêu cầu bộ nhớ đầy đủ để duy trì không gian, đặc biệt trong các mô hình với nhiều lớp mạng và nút. Quan trọng hơn, nó dễ bị tổn thương hơn trong việc tăng lỗi ràng buộc tổng quát hóa trong quá trình huấn luyện tuần tự, điều này ảnh hưởng xấu đến việc giữ gìn kiến thức của các nhiệm vụ trước đó.

Thứ hai, trực giao hóa theo từng lớp khiến việc tìm các tham số tối ưu trở nên khó khăn khi các nhiệm vụ CL thách thức. Một gradient descent tiêu chuẩn thường gặp phải hội tụ chậm và bẫy tại cực tiểu địa phương, chứ đừng nói đến việc thực hiện trực giao của nó, bằng cách cập nhật các trọng số mạng dọc theo hướng bị ràng buộc. Đặc biệt, với việc lan truyền ngược của toàn bộ mạng theo từng lớp, ràng buộc có khả năng được khuếch đại rất nhiều, làm suy giảm khả năng giữ gìn kiến thức của mô hình mới.

--- TRANG 7 ---
Không giống như những phương pháp này, chúng tôi chỉ áp dụng nó vào các trọng số đầu ra để ra quyết định và tinh chỉnh dạng của ma trận chiếu trực giao, như được trình bày trong phần tiếp theo. Do đó, bản chất của sự tiết kiệm chủ yếu đề cập đến hai khía cạnh. (i) Đối với một nhiệm vụ cá nhân, nó chỉ hoạt động trên lớp đầu ra cuối cùng, trái ngược với các thao tác theo từng lớp thường được sử dụng. Sự đơn giản hóa này được thực hiện tốt bởi học ở cấp độ biểu diễn. Theo cách này, phương pháp của chúng tôi làm giảm các yêu cầu tính toán và bộ nhớ, vì chúng tôi không trực giao hóa các trọng số của các nơ-ron được tái sử dụng trong các lớp ẩn và loại bỏ sự không linh hoạt một cách triệt để nhất. (ii) Đối với các nhiệm vụ tuần tự, nó chỉ quan tâm đến một bộ chiếu trực giao dựa trên các biểu diễn của lớp gần cuối. Ngược lại, trực giao hóa theo từng lớp yêu cầu bộ chiếu tại mỗi lớp được chuyển giao và cập nhật trong quá trình học một nhiệm vụ mới. Kết quả là, không gian trực giao tiết kiệm sẽ tốt hơn để đảm bảo rằng các trọng số đầu ra không bị thấm nước liên quan đến tất cả các nhiệm vụ đã thấy.

4.3.2 Ma trận chiếu trực giao

Chúng tôi đầu tiên trình bày quá trình ra quyết định với bằng chứng về tính chất học mà không quên của nó, tiếp theo là suy ra toán học ma trận chiếu trực giao để điều chỉnh gradient. Chi tiết như sau.

Khi hoàn thành học ở cấp độ biểu diễn trên nhiệm vụ t (t= 1,2, . . .), IF2Net có thể tuần tự thu được các biểu diễn có thể phân biệt tại FC3 gọi là ˜V3. Sau đây, chúng tôi ký hiệu ˜V3 bằng Vt∈RNt×S3 để đơn giản, trong đó chỉ số dưới t biểu thị chỉ số nhiệm vụ và S3 là tổng số nút tại FC3. Trái ngược với lớp softmax, chúng tôi đánh giá các trọng số đầu ra bằng cách giải quyết một hệ phương trình tuyến tính. Do đó, mục tiêu học cho IF2Net là bài toán giảm thiểu bình phương nhỏ nhất được regularize sau:

arg min βt:∥Vtβt−Yt∥2 F+µ∥βt∥2 F (13)

trong đó ∥ · ∥F là chuẩn Frobenius, βt là ma trận trọng số đầu ra, Yt là nhãn mẫu huấn luyện, và µ là hệ số cân bằng. Do đó, dự đoán mạng tương ứng ˆYt=Vtβt có thể được thực hiện tại lớp đầu ra cuối cùng bằng cách chiếu các cập nhật trọng số đầu ra ∆βt vào không gian trực giao tiết kiệm, trong đó hướng cập nhật được hướng dẫn bởi một ma trận chiếu trực giao Pt (xem Hình 4). Khi học một nhiệm vụ mới, các trọng số đầu ra cũ được cập nhật theo hướng trực giao của các biểu diễn đã học để tránh xâm phạm thông tin đã thu được trước đó, ngay cả sau khi trải qua một chuỗi các nhiệm vụ. Đặc biệt,

βt=βt−1−ηPt∆βt (14)

trong đó η là tốc độ học. Do đó, trong quá trình ra quyết định, cho ma trận khác không Pt thỏa mãn AtPt=O (t= 1,2, . . .), trong đó At= [VT 1,VT 2, . . .,VT t−1]T bao gồm tất cả các biểu diễn được điều chỉnh trước đó. Bằng chứng toán học như sau:

Giả sử đã có t(t= 1,2, . . . , T −1) nhiệm vụ được thấy cho đến nay, và khi IF2Net được huấn luyện trên nhiệm vụ T, dự đoán hiện tại của nó là ˆYT=VTβT trong đó βT được cập nhật với (14) để duy trì tính dẻo mô hình trên cái gì đó mới, và mỗi Pt có thể được xây dựng theo dạng sau:

Pt=I−AT t(AtAT t+αI)−1At =α(AT tAt+αI)−1 (15)

trong đó α là một hằng số tương đối nhỏ [62], [63]. Tại thời điểm kiểm tra, mô hình cuối cùng có thể dự đoán ˆYt từ bất kỳ nhiệm vụ nào từ 1 đến T−1 mà không cần biết định danh nhiệm vụ, tức là,

ˆYt=VtβT =Vt(βT−1−ηPT∆βT) =Vt(βt−η∑T k=t+1Pk∆βk) =Vtβt−η∑T k=t+1VtPk∆βk =Vtβt (16)

Lưu ý rằng AkPk=O(k=t+ 1, . . . , T ) và Vt thuộc về Ak. Điều này hoàn thành bằng chứng về các quyết định học-mà-không-quên của IF2Net. □

Tuy nhiên, từ quan điểm thuật toán, khó có thể tìm một ma trận chiếu trực giao Pt luôn có thể thỏa mãn AtPt=O(t= 1,2, . . .). Để làm cho việc tính toán bộ chiếu hiệu quả hơn, chúng tôi đã sử dụng một phương pháp lặp để xấp xỉ không gian trực giao tiết kiệm được mở rộng bởi Vt, rất giống với bình phương nhỏ nhất đệ quy (RLS) [77], [78], có thể được sử dụng để huấn luyện mạng nơ-ron feed-forward để đạt được hội tụ nhanh. Do đó, chúng tôi

--- TRANG 8 ---
coi k hàng đầu tiên của Vt như một mini-batch; tức là, Vt(k) = [v1,v2, . . . ,vk]T. Tương tự, Vt(k+ 1)TVt(k+ 1) = Vt(k)TVt(k) +vT k+1vk+1. Chúng tôi ký hiệu Pt(k) là dạng lặp liên kết với Vt(k). Do đó, (15) có thể được biểu thị là:

Pt(k+ 1) = α(Vt(k+ 1)TVt(k+ 1) + αI)−1 =α(Vt(k)TVt(k) +vT k+1vk+1+αI)−1 (17)

Sau đó, chúng tôi áp dụng định danh ma trận Woodbury [79] như một giải pháp cho (17), như được trình bày dưới đây. Cho A và B là hai ma trận xác định dương M×M liên quan đến

A=B−1+CD−1CT (18)

trong đó D là một ma trận xác định dương N×N và C là một ma trận M×M. Sử dụng bổ đề nghịch đảo ma trận, chúng ta thu được

A−1=B−BC(D+CTBC)−1CTB (19)

Bằng cách chỉ định B−1=Vt(k)TVt(k) +αI trong (17), chúng ta có B−1=αPt(k)−1. Hơn nữa, cho C=vT k+1 và D=I. Theo (18)-(19), chúng ta có

Pt(k+ 1) = Pt(k)−Pt(k)vT k+1vk+1Pt(k) αI+vk+1Pt(k)vT k+1 (20)

Tính toán bộ chiếu trực giao bằng cách sử dụng (20) có hai điểm mạnh chính. (i) Triển khai lặp theo cách trực tuyến hiệu quả tránh thao tác nghịch đảo ma trận được định nghĩa trong (15), điều này tạo điều kiện đáng kể cho quá trình cập nhật. (ii) Mỗi batch được coi như một nhiệm vụ khác nhau và phá vỡ giới hạn lưu trữ các biểu diễn từ tất cả các nhiệm vụ trước đó, ví dụ, V1,V2, . . ., vì chỉ cần Vt hiện tại đã học và Pt(k) được cập nhật gần đây nhất; do đó, tăng tốc hơn nữa quá trình xử lý. Thuật toán 2 minh họa quá trình ra quyết định của IF2Net.

Nhận xét 1. Chúng tôi lưu ý rằng việc đưa "ghi nhớ" vào xem xét, việc ra quyết định dựa trên trực giao hóa ở trên có thể hấp thụ một ánh xạ đầu vào-đầu ra mới mà không can thiệp vào những cái đã học trước đó. Tuy nhiên, quá trình này có thể kém hiệu quả hơn cho "học". Điều này là do regularization trực giao cập nhật các trọng số đầu ra dọc theo hướng bị ràng buộc, và nó có khả năng bất lợi trong việc tìm các giá trị tối ưu trong quá trình huấn luyện tuần tự, đặc biệt đối với nhiệm vụ 1, hoạt động như thao tác tiền huấn luyện hoặc khởi tạo. Để giảm thiểu điều này, chúng tôi nhìn lại bài toán tối ưu hóa trong (13), và một giải pháp dạng đóng cho khởi tạo tham số được đưa ra bởi:

β∗ 1= (VT 1V1+µI)−1VT 1Y1, N1≥S3 (21)

Hoặc,

β∗ 1=VT 1(V1VT 1+µI)−1Y1, N1< S 3 (22)

Độ phức tạp tính toán được giới thiệu bởi thao tác nghịch đảo ma trận có thể được tránh bằng cách sử dụng (21) hoặc (22), tùy thuộc vào kích thước mẫu N1 hoặc tổng chiều biểu diễn S3. Về mặt thực nghiệm, chúng ta có thể bắt đầu thêm với một mini-batch được chọn để tính toán giải pháp dạng đóng, tiếp theo cùng cách với các cập nhật tiếp theo của trọng số đầu ra βt(t≥2). Trong Phần 5.3.1, chúng tôi chứng minh hiệu quả của khởi tạo phân tích này cho trọng số đầu ra. Do đó, với hướng cập nhật bị ràng buộc kết quả từ trực giao hóa theo từng lớp, chúng tôi đã đơn giản hóa nó thành một lớp cho việc ra quyết định cuối cùng và giới thiệu một thao tác khởi tạo hiệu quả, loại bỏ sự không linh hoạt ở mức độ tối đa.

Thuật toán 2 Ra quyết định dựa trên trực giao hóa
Đầu vào: Các bộ dữ liệu Dt={(Xt,Yt)} của nhiệm vụ t; Một bộ phân loại với lớp đầu ra một đầu duy nhất; Các vô hướng dương µ,η, và α; Các biểu diễn của lớp gần cuối Vt.
Đầu ra: Dự đoán mạng trên các nhiệm vụ đã thấy cho đến nay ˆYt.
1: # ra quyết định trên các nhiệm vụ tuần tự
2: for t= 1,2, . . . , T do
3: if t= 1 then
4: Khởi tạo β∗ 1 dựa trên (21) hoặc (22);
5: Xấp xỉ lặp Pt dựa trên (20);
6: else
7: # cập nhật trong không gian trực giao tiết kiệm
8: Trực giao hóa gradient bằng Pt∆βt;
9: Cập nhật βt dựa trên (14);
10: Xấp xỉ lặp Pt dựa trên (20);
11: end if
12: end for

4.4 Tích hợp điểm mạnh của các điều kiện bên ngoài

Để làm nổi bật tính tổng quát của phương pháp chúng tôi, chúng tôi tiếp tục khám phá khả năng tương thích của IF2Net với công việc trước đó và tận dụng chúng như các điều kiện bên ngoài, chẳng hạn như các chiến lược dựa trên replay-, regularization-, và kiến trúc động, đạt được sự tăng cường biên trong hiệu suất học. Với hạn chế không gian, chúng tôi xem xét thuật toán EWC điển hình làm ví dụ và đổi tên nó thành IF2Net-EWC. Cả IF2Net và IF2Net-EWC đều áp dụng cùng một học ở cấp độ biểu diễn trong các lớp ẩn nhưng các chính sách hơi khác nhau để cập nhật các trọng số đầu ra trong quá trình huấn luyện tuần tự.

Đặc biệt, giả sử đã có T−1 (T≥2) nhiệm vụ cho đến nay. Khi nhiệm vụ T được trình bày, mục tiêu học cải tiến cho IF2Net-EWC có thể được biểu thị là:

arg min βT:1/2NT∥VTβT−YT∥2 F+µ/2∑T−1 t=1∥Qt⊙(βT−βT−1)∥2 F s.t.:βT=βT−1−ηPT∆βT (23)

trong đó NT là số lượng mẫu huấn luyện hiện tại, ⊙ là tích theo từng phần tử, βT−1 là trọng số đầu ra được học gần đây nhất, và Ft=Qt⊙Qt là ma trận thông tin Fisher chỉ ra tầm quan trọng tham số, như được công thức hóa dưới đây.

Ft=1/Nt∑Nt p=1∇βTlogp(βT|Dt)∇βTlogp(βT|Dt)T (24)

Do đó, IF2Net-EWC giữ gìn kiến thức của các nhiệm vụ cũ bằng cách ràng buộc các trọng số đầu ra ở lại trong vùng lỗi thấp

--- TRANG 9 ---
trong khi học một nhiệm vụ mới, chỉ cho phép nhiệm vụ mới thay đổi các trọng số đầu ra của nó mà không quan trọng đối với các nhiệm vụ cũ trong không gian trực giao tiết kiệm. Nói cách khác, mỗi trọng số đầu ra với tầm quan trọng nhỏ không ảnh hưởng đáng kể đến hiệu suất và do đó, có thể được thay đổi dọc theo hướng trực giao để giảm thiểu hàm mục tiêu, trong khi, lý tưởng, nó nên được giữ nguyên với tầm quan trọng lớn. Hơn nữa, Dt không còn cần được xem lại hoặc lưu trữ một khi Ft được thu được. Tóm lại, IF2Net-EWC tiếp tục kết hợp hạn mức cập nhật theo tầm quan trọng tham số để thực hiện consolidation trọng số có chọn lọc so với IF2Net.

Nhận xét 2. Trực giác, chỉ nên duy trì và cố định một thuật ngữ duy nhất tại các trọng số đầu ra liên kết với nhiệm vụ T−1 mới nhất vì các trọng số được học gần đây nhất βT−1 kế thừa các trọng số trước đó βt (t= 1,2, . . . , T −2). Thay vào đó, nhiều thuật ngữ phạt có thể được kết hợp vào (23) bằng cách thay thế βT−1 bằng βt. Cái sau buộc một mô hình nhớ các nhiệm vụ cũ hơn rõ ràng hơn bằng cách đếm kép dữ liệu từ các nhiệm vụ trước đó, điều này có thể bù đắp cho thực tế là các nhiệm vụ cũ hơn khó nhớ hơn [80]. Như một cái giá, thuật toán thể hiện sự tăng trưởng tuyến tính trong yêu cầu bộ nhớ khi số lượng nhiệm vụ tăng lên. Do đó, chúng tôi chỉ kết hợp IF2Net với một thuật ngữ duy nhất, như được công thức hóa trong (23).

4.5 Thảo luận

4.5.1 Chúng ta có thể trực tiếp sử dụng NN-RW cho CL không?

Như được mô tả trong phần công việc liên quan, NN-RW gán ngẫu nhiên các trọng số đầu vào (và bias), và chỉ cần điều chỉnh các trọng số đầu ra trong quá trình học một nhiệm vụ. Mặc dù một số chiến lược hữu ích, chẳng hạn như cơ chế giám sát trong SCN [49], và thuật toán lasso trong BLS [50], đã được giới thiệu để tận dụng tốt hơn bản chất ngẫu nhiên hóa, NN-RW và các biến thể của nó phụ thuộc vào dữ liệu và chủ yếu hoạt động tốt trong điều kiện IID, khiến nó không khả thi trong ngữ cảnh CL. Cụ thể, kỹ thuật học ngẫu nhiên hóa có thể được sử dụng để trích xuất các đặc trưng phân biệt cho một nhiệm vụ đã cho, nhưng nó thất bại trong việc hoạt động trong một chuỗi các nhiệm vụ. Điều này là do thông tin phân biệt được học cho một nhiệm vụ mới có thể không đủ phân biệt giữa các nhiệm vụ cũ và giữa các lớp cũ và mới [23]. Quan trọng hơn, NN-RW với các trọng số đầu ra cụ thể cho nhiệm vụ hạn chế ứng dụng của nó trong quá trình học một nhiệm vụ, và không có công việc nào được trình bày để hướng dẫn các cập nhật của trọng số đầu ra để giải quyết việc quên. Do đó, cần có những cải tiến hơn nữa để mở rộng NN-RW cho ngữ cảnh CL, và công việc của chúng tôi lấp đầy khoảng trống này ở một mức độ nhất định.

4.5.2 Mối quan hệ giữa IF2Net và các phương pháp gradient descent trực giao

Bây giờ chúng tôi thảo luận mối quan hệ giữa phương pháp được đề xuất, IF2Net, và phương pháp gradient descent trực giao đại diện, OWM [62]. Cả hai đều phục vụ cùng một mục đích thách thức việc quên nghiêm trọng trong mạng nơ-ron. Tuy nhiên, có ba sự khác biệt chính giữa IF2Net và OWM, tạo ra sự khác biệt hiệu suất đáng kể. (i) Thay vì các cập nhật regularization trực giao của tất cả các trọng số mạng theo từng lớp, chúng tôi đề xuất tận dụng học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa trong một số lớp ẩn, như đã thảo luận trong Phần 4.2. Nó được phân tích lý thuyết rằng kỹ thuật được đề xuất có thể làm cho các phản hồi ngẫu nhiên hóa của các nhiệm vụ khác nhau hội tụ về các tối ưu riêng biệt của chúng. (ii) Sau đó chúng tôi áp dụng trực giao hóa cho lớp đầu ra cuối cùng để ra quyết định vì bản đồ đặc trưng được trích xuất từ các lớp sâu hơn có nhiều khả năng chứa thông tin cụ thể cho nhiệm vụ, và lớp sâu hơn có thể dễ dàng quên kiến thức trước đó [26]. Đặc biệt, chúng tôi chiếu các cập nhật trọng số đầu ra vào không gian trực giao tiết kiệm được mở rộng bởi phản hồi thu được từ lớp trước, tức là, phương pháp của chúng tôi chỉ cần duy trì một ma trận chiếu trực giao, trong khi số lượng bộ chiếu trong OWM bằng với số lượng lớp mạng. Phương pháp của chúng tôi, cùng với một giải pháp dạng đóng cho khởi tạo tham số, có thể tạo điều kiện cho quá trình hội tụ và loại bỏ sự không linh hoạt trong thực hành theo từng lớp ban đầu. (iii) Phương pháp của chúng tôi tương thích với hầu hết, nếu không muốn nói là tất cả, các phương pháp CL vì tính tổng quát của nó, có nghĩa là người ta có thể dễ dàng kết hợp IF2Net với các kỹ thuật tương ứng trong các phương pháp CL hiện có để đạt được kết quả tiên tiến mới.

4.5.3 So sánh qua góc độ ràng buộc tổng quát hóa

Chúng tôi cũng thảo luận hiệu suất tổng quát hóa để hiểu tại sao phương pháp của chúng tôi tốt hơn OWM. Dựa trên độ phức tạp Rademacher [81], hai bổ đề hỗ trợ được trình bày để giải thích lập luận trực giác của chúng tôi, tức là, việc ra quyết định dựa trên trực giao hóa trong lớp đầu ra cuối cùng có xu hướng dẫn đến lỗi ràng buộc tổng quát hóa thấp hơn trong quá trình huấn luyện tuần tự.

Phần này tập trung vào độ phức tạp Rademacher, là một công cụ tiêu chuẩn để ràng buộc lỗi tổng quát hóa (và do đó độ phức tạp mẫu) của các lớp dự đoán đã cho [82], [83]. Chính thức, cho một lớp hàm có giá trị thực H và tập hợp các điểm dữ liệu x1, . . . , x m∈X, chúng tôi định nghĩa độ phức tạp Rademacher (thực nghiệm) ˆRm(H) là:

ˆRm(H) =Eϵ sup h∈H1/m∑m i=1h(xi)ϵi (25)

trong đó ϵ= (ϵ1, . . . , ϵ m) là một vector được phân phối đồng nhất trong {-1,+1} và m là kích thước mẫu. Bartlett và Mendelson [82] đã cung cấp ràng buộc tổng quát hóa sau cho các hàm tổn thất Lipschitz:

Bổ đề 2. [82] Giả sử tổn thất ℓ là Lipschitz (đối với đối số đầu tiên của nó) với hằng số Lipschitz Lℓ và ℓ bị ràng buộc bởi c. Đối với bất kỳ δ > 0 và với xác suất ít nhất 1−δ đồng thời cho tất cả h∈ H , chúng ta có

L(h)≤ˆL(h) + 2LℓˆRm(H) +c√(log(1/δ)/2m)

trong đó L(h) =E[ℓ(h(x), y)] là tổn thất kỳ vọng của h và ˆL(h) =1/m∑m i=1ℓ(h(xi), yi) là tổn thất thực nghiệm.

Chúng ta có thể giới thiệu một ràng buộc cho thuật ngữ độ phức tạp Rademacher bằng cách sử dụng Bổ đề 2 .

Bổ đề 3. [84] Cho Hd là lớp mạng có giá trị thực có độ sâu d trên miền X={x:∥x∥ ≤ B} trong không gian Euclidean, trong đó mỗi ma trận tham số Wj có chuẩn Frobenius nhiều nhất MF(j), và với các hàm kích hoạt thỏa mãn Bổ đề 1 trong [84]. Khi đó,

ˆRm(Hd)≤1/m∏d j=1MF(j)·√(2 log(2) d+ 1)√(∑m i=1∥xi∥2) ≤B√(2 log(2) d+ 1)∏d j=1MF(j)/√m.

trong đó W1, . . . ,Wd trong mỗi lớp d có chuẩn Frobenius ∥ · ∥ F bị ràng buộc trên bởi MF(1), . . . , M F(d), tương ứng.

Hãy xem xét những bổ đề này trong ngữ cảnh học liên tục. Giả sử rằng t(t= 1,2, . . . , T −1) nhiệm vụ đã được huấn luyện. Trong quá trình huấn luyện tuần tự, người ta có thể đảm bảo rằng tổn thất thực nghiệm ˆL(h) ở phía bên phải của Bổ đề 2 không thay đổi bằng phương pháp gradient descent trực giao. Tuy nhiên, thuật ngữ độ phức tạp Rademacher ˆRm(Hd) vẫn có thể tăng cho nhiệm vụ t khi chúng ta cập nhật trọng số mạng tại nhiệm vụ T. Do đó, trong khi mạng không quên những gì đã học, lỗi tổng quát hóa cho các nhiệm vụ trước đó có thể tăng lên khi trọng số được cập nhật cho các nhiệm vụ sau này. Hơn nữa, chúng ta có thể sử dụng ràng buộc của thuật ngữ độ phức tạp Rademacher trong Bổ đề 3 . Đối với phương pháp của chúng tôi, d= 1 và miền X đề cập đến lớp ẩn cuối cùng, trong khi đối với OWM, d >1 và miền X đề cập đến lớp đầu vào. Kết quả là, điều này dẫn đến sự khác biệt lớn trong mức độ chúng tăng thuật ngữ độ phức tạp Rademacher cho nhiệm vụ t < T −1 trong quá trình huấn luyện cho nhiệm vụ T. Từ Bổ đề 3 , có thể dự kiến rằng IF2Net được đề xuất không tăng đáng kể thuật ngữ độ phức tạp Rademacher so với OWM. Chúng tôi đã xác thực giả thuyết này bằng cách vẽ giá trị của thuật ngữ độ phức tạp Rademacher cho phương pháp của chúng tôi và OWM trong Phần 5.3.4.

5 THÍ NGHIỆM

Trong phần này, chúng tôi trình bày các thí nghiệm mở rộng để xác thực tính ưu việt của phương pháp được đề xuất bằng cách sử dụng ba chỉ số đánh giá, sáu bộ dữ liệu benchmark tiêu chuẩn, và 17 phương pháp baseline trong kịch bản CIL. Đầu tiên, chúng tôi giới thiệu cài đặt thí nghiệm. Sau đó chúng tôi cung cấp kết quả thí nghiệm và thảo luận, theo sau đó chúng tôi phân tích thực nghiệm hiệu quả của các thiết kế cốt lõi trong thuật toán của chúng tôi.

5.1 Cài đặt thí nghiệm

Giao thức. Để so sánh công bằng, chúng tôi đã cẩn thận chọn các phương pháp so sánh trong cùng một môi trường. (i) Chỉ có các mẫu của nhiệm vụ hiện tại t có sẵn, ngoại trừ các phương pháp dựa trên replay, trong khi các mẫu kiểm tra có thể đến từ bất kỳ nhiệm vụ nào từ 1 đến t tại thời điểm kiểm tra, trong đó danh tính nhiệm vụ không biết. (ii) Không sử dụng chuỗi nhiệm vụ cố định, chúng tôi chạy mỗi benchmark nhiều lần với thứ tự nhiệm vụ được xáo trộn ngẫu nhiên và sau đó báo cáo giá trị trung bình và/hoặc độ lệch chuẩn của những kết quả này. Do đó, các lần chạy lặp lại sẽ vào các nhiệm vụ với thứ tự agnostic trước khi huấn luyện, điều này thực tế hơn trong một môi trường mở. (iii) Chúng tôi ưu tiên các phương pháp baseline được công nhận tốt nhất và hoạt động tốt nhất trong cài đặt "single-head" và tham chiếu đến các codebase gốc để thực hiện và lựa chọn siêu tham số để đảm bảo hiệu suất tốt nhất có thể.

Bộ dữ liệu. Chúng tôi tuân theo thực hành phổ biến trong kịch bản CIL để mô phỏng các phân phối đầu vào thay đổi và các lớp mới xuất hiện bằng cách chia các bộ dữ liệu benchmark [20], [23], [26], [44], [64], [66], [85], bao gồm MNIST, FashionMNIST, Stanford Dogs, CUB-200, CIFAR-100, và ImageNet-Subset. Để thuận tiện, chúng tôi sử dụng danh pháp [DATASET]- C/T để biểu thị một chuỗi nhiệm vụ với C lớp được chia đều thành T nhiệm vụ trong kịch bản CIL; ví dụ, hậu tố chỉ ra rằng một mô hình cần nhận dạng C/T lớp mới trong mỗi nhiệm vụ.

Các phương pháp so sánh . Chúng tôi so sánh phương pháp của chúng tôi với cả các baseline CL cổ điển và mới nhất, bao gồm GEM [10], LOGD [86], IL2M [36], FS-DGPM [87], ARI [88] từ các phương pháp dựa trên replay, EWC [16], SI [17], MAS [12], OL-EWC [89], BiC [90], OWM [62] từ các phương pháp dựa trên regularization, và RPS-Net [32], EFT [20], PCL [23] từ các phương pháp dựa trên kiến trúc động. Ngoài ra, chúng tôi so sánh nó với một NN-RW đại diện [50], một phương pháp naivety đơn giản tinh chỉnh mỗi nhiệm vụ mới ( None ; có thể được coi là ràng buộc dưới), và một mạng luôn được huấn luyện bằng cách sử dụng dữ liệu của tất cả các nhiệm vụ cho đến nay ( Joint ; có thể được coi là ràng buộc trên).

Kiến trúc. Trong các thí nghiệm của chúng tôi, tất cả các phương pháp đều sử dụng các kiến trúc mạng nơ-ron có kích thước tương tự. Đối với MNIST và FashionMNIST, một mạng kết nối đầy đủ với ba lớp ẩn được sử dụng. Không có CNN được huấn luyện trước nào được sử dụng cho các nhiệm vụ đồ chơi, vì một mô hình đơn giản đã tạo ra kết quả rất tốt. Đối với Stanford Dogs, CUB-200, CIFAR-100, và ImageNet-Subset, một ResNet tiêu chuẩn (ví dụ, ResNet-18, ResNet-56) được sử dụng để cung cấp các đặc trưng được trích xuất tốt, tương tự như [23], [44], [62], [70], [71] trong đó một bộ trích xuất đặc trưng được huấn luyện trước bởi các danh mục con đã chọn. Sau đó, các lớp còn lại mà bộ trích xuất đặc trưng không được huấn luyện được đưa tuần tự vào một mô hình đơn giản để học các ánh xạ khác nhau. Ví dụ, nó lấy 100 lớp từ CUB-200 để huấn luyện trước với ResNet-56 và sau đó bắt đầu học liên tiếp 100 lớp khác mà mô hình được huấn luyện trước chưa gặp phải. Điều này phù hợp với đặc điểm của việc học của con người chuẩn bị đầy đủ cho các nhiệm vụ thách thức, thay vì không có bất kỳ kiến thức tiên nghiệm nào. Một CNN được huấn luyện trước được sử dụng đồng đều trong phương pháp của chúng tôi và tất cả các baseline.

Siêu tham số. Đối với tất cả các baseline, chúng tôi sử dụng mã nguồn mở được phát hành bởi các tác giả của họ hoặc mã của bên thứ ba phổ biến. Đặc biệt, chúng tôi sử dụng bộ tối ưu hóa SGD với tốc độ học ban đầu ( η) là 0.01 và kích thước batch là 64 trong các thí nghiệm của chúng tôi. Đối với các phương pháp dựa trên replay, chúng tôi giữ một tập exemplar ngẫu nhiên là 4.4k cho MNIST, FashionMNIST, CUB-200, và ImageNet-Subset, và hạn chế ngân sách bộ nhớ exemplar đến 2k mẫu cho Stanford Dogs và CIFAR-100 bằng cách tuân theo cài đặt trong [10], [86]. Các phương pháp dựa trên cấu trúc động sẽ có cùng độ lớn với một mạng cơ sở sau khi học tất cả các nhiệm vụ hoặc không có giới hạn về kích thước mở rộng của chúng. Đối với các phương pháp dựa trên regularization, sự cân bằng từ tập {100, 1000, 10000, 100000 }. Lưu ý rằng các siêu tham số khác được tham chiếu đến các cài đặt gốc theo mặc định. Trong phương pháp của chúng tôi, các cài đặt siêu tham số bao gồm λ= 0.01 và γ= 0.4 trong (12), µ= 2−30 trong (13), và α= 0.1 trong (20).

--- TRANG 11 ---
BẢNG 1
So sánh hiệu suất trên MNIST -10/5 và FashionMNIST -10/5 cả hai đều được đo bằng ba chỉ số đánh giá. Tất cả kết quả đều được (tái) tạo dưới 5 lần chạy, với giá trị trung bình và độ lệch chuẩn được báo cáo. Chúng tôi cũng đánh dấu kết quả tốt nhất bằng Chữ đậm và kết quả tốt thứ hai bằng Chữ nghiêng .

[Bảng với dữ liệu hiệu suất các phương pháp khác nhau trên MNIST-10/5 và FashionMNIST-10/5]

5.2 Kết quả thí nghiệm

5.2.1 Thí nghiệm trên các ví dụ đồ chơi

MNIST-10/5 và FashionMNIST-10/5. Bảng 1 liệt kê kết quả so sánh của MNIST-10/5 và FashionMNIST-10/5. Cả None và NN-RW, được cung cấp cho học một nhiệm vụ, chỉ nhớ nhiệm vụ được học gần đây nhất, và những cái được huấn luyện trước đó đã bị quên hoàn toàn. Ngược lại, phương pháp được đề xuất đạt được ACC cao nhất (96.16%, 95.09%), tiếp cận Joint , và BWT (-0.0044, -0.0189), tiếp cận zero, chứng minh rằng IF2Net là một phương pháp không quên. Các giá trị FWT bổ sung của GEM và PCL tốt hơn so với IF2Net. Tuy nhiên, các giá trị ACC của chúng thấp hơn của chúng tôi. Chúng tôi quan sát thấy rằng hiệu suất của EWC, MAS, OL-EWC, và SI kém hơn đáng kể so với những cái khác, vì kịch bản CIL đặc biệt khó khăn đối với các phương pháp dựa trên regularization. Hầu hết các phương pháp dựa trên replay đạt được ACC thấp hơn một chút so với IF2Net, đặc biệt đối với IL2M và LOGD trên chuỗi nhiệm vụ MNIST-10/5. Ngoài ra, việc sử dụng thứ tự nhiệm vụ được xáo trộn ngẫu nhiên mong muốn hơn trong một môi trường mở, có thể đóng vai trò trong tính công bằng của mô hình. Theo cách này, các độ lệch chuẩn được báo cáo rằng phương pháp của chúng tôi cũng có độ nhạy cảm thứ tự thấp, với độ chính xác tương tự cho mỗi chuỗi nhiệm vụ bất kể thứ tự nhiệm vụ ngẫu nhiên. Cuối cùng, kết quả của IF2Net-EWC cho thấy sự tăng cường biên trong hiệu suất học, chỉ ra tính tổng quát và khả năng tương thích của nó.

5.2.2 Thí nghiệm trên các nhiệm vụ thách thức

CUB-{100/5, 100/10, 100/20 }.Ba chuỗi nhiệm vụ thách thức hơn được chia bởi CUB được sử dụng, và kết quả so sánh được vẽ trong biểu đồ thanh xếp chồng (xem Hình 5), nơi một mô hình phải nhận dạng tăng dần các nhiệm vụ phân loại thị giác tinh tế. Phương pháp của chúng tôi vượt trội hơn các phương pháp tiên tiến được chọn trên ACC trong khi được trang bị độ lệch chuẩn cạnh tranh. Đặc biệt, IF2Net được đề xuất cải thiện ACC với phương pháp tốt thứ hai IL2M bằng một biên tuyệt đối 5.48%, và độ lệch chuẩn của GEM, OWM, và BiC vượt trội một chút so với của chúng tôi, nhưng ACC của chúng kém hơn nhiều so với IF2Net. Do đó, kết quả trên các chuỗi nhiệm vụ CUB- {100/5, 100/10, 100/20 } làm nổi bật phương pháp của chúng tôi như một công cụ đầy hứa hẹn để giảm thiểu việc quên. Độ lệch chuẩn của PCL cao vì nó sử dụng một thiết lập đa đầu nơi nó tạo nhánh thành một lớp đầu ra độc quyền cho các lớp đã học cho đến nay. Do đó, việc yêu cầu PCL khớp chính xác các đầu tương ứng để ra quyết định là đòi hỏi, cho một chuỗi các nhiệm vụ thị giác tinh tế.

Stanford Dogs- {60/5, 60/10 }.Tương tự, kết quả của các chuỗi nhiệm vụ được chia bởi Stanford Dogs phù hợp với những của CUB, như được mô tả trong Hình 6. Lưu ý rằng phần dưới của mỗi hình phụ sử dụng trục tọa độ dọc trái để báo cáo ACC, trong khi phần trên sử dụng trục tọa độ dọc phải để báo cáo kết quả BWT và FWT của các phương pháp tương ứng. Lấy Hình 6a làm ví dụ,

--- TRANG 12 ---
[Mô tả các biểu đồ và bảng hiệu suất trên các bộ dữ liệu khác nhau]

và phương pháp được đề xuất vượt trội hơn các baseline khác trên ACC, trong đó IL2M vẫn là baseline mạnh nhất với 2.29% thấp hơn của chúng tôi. Trong khi đó, IF2Net đạt được giá trị BWT tốt nhất và giá trị FWT tốt thứ hai, điều này ngụ ý khả năng mạnh mẽ của nó trong việc giữ gìn và chuyển giao kiến thức qua các nhiệm vụ phân loại thị giác tinh tế. Điều này cũng được phản ánh trong so sánh trong Hình 6b.

CIFAR- {60/10, 60/20 }.Hiệu suất của các phương pháp CL khác nhau trên các chuỗi nhiệm vụ được chia bởi CIFAR-100 được báo cáo trong Bảng 2, tập trung vào xu hướng thay đổi của ACC với số lượng nhiệm vụ tăng lên. Kết quả chỉ ra hiệu suất vượt trội của phương pháp được đề xuất trong kịch bản CIL. Mặc dù nó bắt đầu với một sự khác biệt nhỏ trong nhiệm vụ đầu tiên, phương pháp của chúng tôi cho thấy sự suy giảm ACC tương đối nhẹ nhàng trong quá trình huấn luyện tuần tự. Hơn nữa, so với ACC tốt thứ hai từ IL2M, phương pháp của chúng tôi đạt được mức tăng tương đối 4.95% sau khi kết thúc học. Ngoài Bảng 2, Hình 7 mô tả sinh động kết quả nhất quán bằng cách học tăng dần ba lớp mới mỗi nhiệm vụ.

ImageNet- {100/10, 100/25, 100/50 }.Bảng 3 so sánh các phương pháp khác nhau trên các chuỗi nhiệm vụ được chia bởi ImageNet-Subset, nơi vấn đề quên nghiêm trọng trở nên thách thức hơn trong một nhiệm vụ cá nhân khó khăn hoặc một chuỗi nhiệm vụ khá dài. Kết quả cho thấy IF2Net vượt trội hơn các phương pháp tiên tiến được chọn với biên 2.86%, 2.08%, và 1.53% lần lượt cho ImageNet- {100/10, 100/25, 100/50 }. Nhìn chung, các thí nghiệm mở rộng đã xác thực hiệu suất cạnh tranh của IF2Net so với các phương pháp tiên tiến, vốn có miễn dịch với việc quên nghiêm trọng bằng cách duy trì chức năng các trọng số liên quan đến mỗi nhiệm vụ đã thấy không bị động suốt thời gian.

--- TRANG 13 ---
BẢNG 3
Thí nghiệm quy mô lớn trên ImageNet trong kịch bản CIL được đo bằng độ chính xác kiểm tra trung bình (%). Các phương pháp được chạy dưới 5 thứ tự nhiệm vụ ngẫu nhiên, với giá trị trung bình và độ lệch chuẩn được báo cáo.

[Dữ liệu bảng với kết quả hiệu suất]

5.3 Nghiên cứu loại bỏ

Trước khi kết luận công việc của chúng tôi, chúng tôi đã tiến hành các nghiên cứu loại bỏ để cung cấp hiểu biết sâu hơn về phương pháp của chúng tôi. Để đạt được điều này, nghiên cứu thực nghiệm về hiệu quả của các thiết kế cốt lõi trong IF2Net được chi tiết như sau.

5.3.1 Lợi thế của khởi tạo trọng số đầu ra bằng giải pháp dạng đóng

Như đã nói trước đó, chúng tôi sử dụng khởi tạo phân tích thay vì khởi tạo ngẫu nhiên cho nhiệm vụ 1; tức là, chúng tôi bắt đầu với một mini-batch được chọn để tính toán giải pháp dạng đóng β∗ 1, tiếp theo cùng cách với các cập nhật tiếp theo của trọng số đầu ra βt(t≥2). Để điều tra lợi ích của chiến lược này, chúng tôi so sánh hai loại khởi tạo trọng số đầu ra. Cụ thể, các η và epoch khác nhau được xem xét trong nghiên cứu loại bỏ, bao gồm (i) trọng số đầu ra được khởi tạo ngẫu nhiên và (ii) bắt đầu với một mini-batch được chọn để tính toán phân tích các trọng số đầu ra. Bảng 4 trình bày kết quả so sánh dựa trên chuỗi nhiệm vụ Fashion-MNIST. Chúng tôi quan sát thấy rằng với một η thích hợp, khởi tạo phân tích có thể hội tụ nhanh hơn so với đối tác ngẫu nhiên của nó, như được đo bằng giá trị tổn thất, độ chính xác kiểm tra cho nhiệm vụ 1, và giá trị ACC cho tất cả. Điều này có nghĩa là nó có thể giảm thiểu hiệu quả hạn chế của gradient descent trực giao theo hướng cập nhật tham số. Trong khi đó, khởi tạo phân tích tận dụng 2.5k (khoảng 20% của tất cả có sẵn) mẫu từ Nhiệm vụ 1 có thể tạo ra kết quả cạnh tranh. Ngược lại, IF2Net với khởi tạo ngẫu nhiên khiến việc tìm tối ưu trở nên khó khăn ngay cả sau mười epoch.

5.3.2 Hiệu quả của các khối nút trong các lớp ẩn

Chúng tôi đề xuất học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa, trong đó một số khối nút được phân bổ ngẫu nhiên để khai thác tốt hơn thông tin ẩn giữa các mẫu huấn luyện. Lấy FC1 làm ví dụ, Bảng 5 minh họa mức độ mà các kết hợp khác nhau đóng góp vào hiệu suất học. Chúng tôi quan sát thấy rằng với 100 nút ẩn cố định trong FC1, IF2Net được trang bị với các khối nút quá nhỏ hoặc quá lớn sẽ làm suy giảm đáng kể các giá trị của ACC, BWT, và FWT. Ngược lại, một số cặp (10, 10) và (25, 4) được sử dụng trong các thí nghiệm của chúng tôi hoạt động tốt, ngụ ý rằng các khối nút thích hợp là không thể thiếu cho quá trình học ở cấp độ biểu diễn được đề xuất. Phân tích hiệu quả cung cấp một số kiến thức tiên nghiệm về lựa chọn khối nút, và nó không có nghĩa là các cài đặt được liệt kê là lựa chọn tối ưu. Nói cách khác, tinh chỉnh do người dùng chỉ định dựa trên các ví dụ được khuyến nghị có thể tạo ra kết quả hiệu suất đơn lẻ và tổng thể tốt hơn.

5.3.3 Tác động của việc tăng các lớp trực giao hóa

Một trong những sự khác biệt rõ ràng nhất giữa IF2Net và OWM là cái sau chỉ gây ra trực giao hóa cho lớp đầu ra cuối cùng thay vì các thao tác theo từng lớp. Để khám phá hiệu ứng của việc dần dần thêm các lớp trực giao hóa, chúng tôi ký hiệu các trường hợp tương ứng: (a) Bốn lớp/OWM; (b) FC1-Ba lớp; (c) FC1-FC2-Hai lớp; (d) FC1-FC2-FC3-Một lớp/IF2Net với khởi tạo ngẫu nhiên; (e) FC1-FC2-FC3-Một lớp/IF2Net với khởi tạo phân tích. Bảng 6 so sánh các trường hợp khác nhau trên FashionMNIST trong đó việc sử dụng bộ nhớ GPU tỷ lệ thuận với số lượng lớp trực giao hóa. Hơn nữa, với chỉ một hoặc hai lớp trực giao hóa, IF2Net hoạt động tốt trên bốn chỉ số. Thú vị là, ACC được tạo ra từ Trường hợp (d) thấp hơn so với Trường hợp (c) và Trường hợp (e), và thay thế khởi tạo ngẫu nhiên bằng triển khai phân tích của nó đạt được kết quả phản công. Do đó, chúng tôi áp dụng trực giao hóa lớp đầu ra cho quá trình ra quyết định cuối cùng.

5.3.4 Tính ưu việt trong lỗi ràng buộc tổng quát hóa

Chúng tôi tuân theo cùng cài đặt trong phần trước sao cho người ta có thể tương ứng với độ phức tạp Rademacher cho các trường hợp khác nhau. Cụ thể, chúng tôi ngẫu nhiên lấy giá trị trong {-1,+1} với xác suất bằng nhau như nhãn huấn luyện của mỗi nhiệm vụ và tính toán độ phức tạp Rademacher dựa trên (25). Sau đó, chúng tôi tích lũy kết quả của tất cả các nhiệm vụ trước đó trong mỗi phiên huấn luyện, đo lường cách lớp hàm (mô hình hiện tại) phù hợp tăng dần với các nhãn được lấy mẫu ngẫu nhiên. Hình 8 vẽ giá trị của thuật ngữ độ phức tạp Rademacher cho phương pháp của chúng tôi và OWM trong toàn bộ các phiên huấn luyện. Chúng tôi quan sát thấy rằng lỗi ràng buộc tổng quát hóa tăng lên với số lượng nhiệm vụ mới, như được nêu trong Bổ đề 2 . Đặc biệt, IF2Net với khởi tạo phân tích tương ứng với Trường hợp (e) sử dụng một lớp trực giao hóa trong lớp đầu ra cuối cùng và thu được lỗi ràng buộc tổng quát hóa tốt nhất. Ngược lại, ví dụ, càng trực giao hóa nhiều lớp, lỗi tăng càng nhanh, như được nêu trong Bổ đề 3 . Do đó, nghiên cứu loại bỏ này phân biệt tại sao phương pháp của chúng tôi tốt hơn OWM và chứng minh tính ưu việt của nó trong lỗi ràng buộc tổng quát hóa.

6 KẾT LUẬN

Hầu hết các phương pháp học liên tục nhấn mạnh việc sử dụng các điều kiện bên ngoài (không vốn có), chẳng hạn như bộ đệm exemplar/bộ tạo dữ liệu, các mục tiêu bổ sung, và các nhánh độc quyền để giảm thiểu việc quên, thay vì tập trung vào việc thực hiện vốn có tránh các trọng số bị ghi đè trong các mô hình kết nối. Để đạt được điều này, nghiên cứu này giới thiệu hai phép chiếu đơn giản, học ở cấp độ biểu diễn dựa trên ngẫu nhiên hóa và ra quyết định dựa trên trực giao hóa, để vốn có vượt qua việc quên trong một mạng xương sống. Xác minh lý thuyết cho phân tích hội tụ của xấp xỉ biểu diễn và bằng chứng của

--- TRANG 14 ---
BẢNG 4
Phân tích thực nghiệm về khởi tạo trọng số đầu ra bằng giải pháp dạng đóng trên FashionMNIST -10/5. Dưới các tốc độ học khác nhau ( η) và epoch, kết quả được đo bằng tổn thất của việc học nhiệm vụ 1, độ chính xác của việc học nhiệm vụ 1, và tất cả. Chúng tôi đánh dấu kết quả tốt nhất bằng chữ đậm . Lưu ý rằng số 1k, 2.5k, và 5k là mini-batch được chọn cho khởi tạo phân tích.

[Dữ liệu bảng chi tiết]

BẢNG 5
Phân tích thực nghiệm về các khối nút trên FashionMNIST -10/5. Với các kết hợp khác nhau, kết quả được đo bằng ba chỉ số đánh giá. Các nút được phân bổ ngẫu nhiên trong FC1 được cấu thành từ n1 nhóm khối nút, với mỗi nhóm s1 nút.

[Dữ liệu bảng chi tiết]

BẢNG 6
Phân tích thực nghiệm về việc tăng một số lớp trực giao hóa trên FashionMNIST -10/5. Trong các trường hợp khác nhau, kết quả được đo bằng bốn chỉ số đánh giá. Lưu ý rằng chỉ số GPU (MB) đề cập đến việc sử dụng bộ nhớ trong quá trình học nhiệm vụ cuối cùng.

[Dữ liệu bảng chi tiết]

quyết định học-mà-không-quên được cung cấp với các suy diễn toán học nghiêm ngặt. Phương pháp kết quả tránh các lượt truyền tiến và ngược của backpropagation, và người ta có thể giữ trọng số của các lớp ẩn không thay đổi và chỉ thích ứng với lớp đầu ra trong quá trình huấn luyện tuần tự. Do đó, phương pháp được đề xuất tái tạo hoàn hảo những gì đã học trước đó và làm giảm các yêu cầu tính toán và bộ nhớ.

Các nghiên cứu gần đây đã làm nổi bật tầm quan trọng tiềm năng của việc tận dụng một mô hình được huấn luyện trước trong ngữ cảnh học liên tục. Dựa trên điều này, chúng tôi sử dụng một kiến trúc đơn giản để phân tích tốt hơn hành vi của một mạng trong suốt nghiên cứu này, vì học tăng dần theo lớp thách thức có thể được thực hiện với các thích ứng nhỏ. Tự nhiên khi xem xét liệu IF2Net có thể được mở rộng để triển khai end-to-end cho các nhiệm vụ thách thức. Mục đích của nghiên cứu này là cung cấp một giải pháp có hệ thống với các phép chiếu kép (ngẫu nhiên hóa và trực giao hóa) cho các thách thức học liên tục, và chúng tôi để lại cho nghiên cứu tương lai.

LỜI CẢM ƠN

Công việc này được hỗ trợ bởi Chương trình R&D Chính quốc gia của Trung Quốc dưới Grant 2021ZD0201300, Quỹ Nghiên cứu Cơ bản cho các Trường Đại học Trung ương dưới Grant YCJJ202203012, Quỹ Học bổng Nhà nước của Hội đồng Học bổng Trung Quốc dưới Grant 202206160045, và Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc dưới các Grant U1913602, 61936004, và 62206204.

TÀI LIỆU THAM KHẢO

[1] S. Thrun and T. M. Mitchell, "Lifelong robot learning," Robotics and Autonomous Systems , vol. 15, no. 1-2, pp. 25–46, 1995.

[Tiếp tục với danh sách tài liệu tham khảo đầy đủ...]

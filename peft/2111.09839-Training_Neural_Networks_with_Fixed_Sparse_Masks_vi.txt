# Huấn luyện mạng nơ-ron với mặt nạ thưa thớt cố định

Yi-Lin Sung
UNC Chapel Hill
ylsung@cs.unc.edu

Varun Nair
Duke University
vn40@duke.edu

Colin Raffel
UNC Chapel Hill
craffel@gmail.com

## Tóm tắt

Trong quá trình huấn luyện điển hình dựa trên gradient của mạng nơ-ron sâu, tất cả các tham số của mô hình đều được cập nhật tại mỗi vòng lặp. Các nghiên cứu gần đây đã chỉ ra rằng có thể chỉ cập nhật một tập con nhỏ các tham số của mô hình trong quá trình huấn luyện, điều này có thể giảm thiểu yêu cầu lưu trữ và truyền thông. Trong bài báo này, chúng tôi chỉ ra rằng có thể tạo ra một mặt nạ thưa thớt cố định trên các tham số của mô hình để chọn một tập con cập nhật qua nhiều vòng lặp. Phương pháp của chúng tôi xây dựng mặt nạ từ k tham số có thông tin Fisher lớn nhất như một phép xấp xỉ đơn giản về việc tham số nào quan trọng nhất cho tác vụ hiện tại. Trong các thí nghiệm về học chuyển giao hiệu quả tham số và huấn luyện phân tán, chúng tôi chỉ ra rằng phương pháp của chúng tôi đạt hiệu suất tương đương hoặc vượt trội so với các phương pháp khác để huấn luyện với cập nhật thưa thớt trong khi hiệu quả hơn về sử dụng bộ nhớ và chi phí truyền thông. Chúng tôi công khai mã nguồn để thúc đẩy việc ứng dụng thêm phương pháp của chúng tôi.

## 1 Giới thiệu

Gradient descent ngẫu nhiên (SGD) là một thành phần quan trọng trong quy trình hiện đại để huấn luyện mạng nơ-ron sâu. Cùng với thuật toán lan truyền ngược, gradient descent cho phép tối ưu hóa hiệu quả hàm mất mát bằng cách cập nhật dần dần các tham số của mô hình. SGD tối ưu hóa mất mát trên một tập con ngẫu nhiên nhỏ của tập dữ liệu tại mỗi vòng lặp huấn luyện, cho phép huấn luyện trên các tập dữ liệu lớn. Trong thực tế, việc tối ưu hóa mất mát huấn luyện của mạng nơ-ron lớn bằng SGD thường tạo ra các mô hình có khả năng tổng quát hóa tốt cho dữ liệu mới [3, 17, 27], khiến SGD trở thành một công cụ vô giá.

Mặc dù hiệu quả, SGD tiêu chuẩn yêu cầu tất cả các tham số mô hình được cập nhật tại mỗi vòng lặp huấn luyện. Do đó, việc truyền thông các thay đổi đối với mô hình cần truyền thông giá trị cập nhật của mọi tham số. Vì các mạng nơ-ron hiện đại thường có hàng triệu hoặc hàng tỷ tham số [9,7,40], việc truyền thông này có thể trở nên quá đắt đỏ. Một ví dụ cụ thể về tác động tiêu cực của các chi phí này xuất hiện trong bối cảnh học chuyển giao. Trong học chuyển giao, các tham số của mô hình được khởi tạo từ một mô hình đã được huấn luyện trước hiện có trước khi được tinh chỉnh (tức là huấn luyện) trên tác vụ quan tâm. Các mô hình đã được huấn luyện trước có thể được tinh chỉnh một số lượng lớn lần – ví dụ, kho mô hình Hugging Face có hàng nghìn biến thể tinh chỉnh của mô hình BERT [12]. Mỗi biến thể tinh chỉnh này yêu cầu một bản sao riêng của các tham số mô hình, mỗi bản chiếm khoảng 500MB dung lượng đĩa. Liên quan đến điều này, trong huấn luyện phân tán [11] và học liên kết [35], các worker tính toán cập nhật cho mô hình tập trung song song trên các tập con khác nhau của dữ liệu. Sau một số lượng cập nhật nhất định, các worker mỗi cái truyền thông các giá trị tham số mới tính toán trở lại mô hình tập trung. Bước truyền thông có thể gây ra một lượng overhead đáng kể (đặc biệt khi mô hình lớn) vì các worker phải truyền thông giá trị cập nhật của tất cả tham số khi sử dụng SGD tiêu chuẩn.

Những vấn đề này có thể được giảm thiểu nếu có thể chỉ cập nhật một số ít tham số trong quá trình huấn luyện trong khi vẫn duy trì hiệu suất gần với việc huấn luyện tất cả tham số. Điều này đã dẫn đến các nghiên cứu khác nhau về huấn luyện hiệu quả tham số của mạng nơ-ron. Ví dụ, Adapters [19,41,5] giới thiệu các tham số bổ sung vào mô hình đã được huấn luyện trước dưới dạng các module nhỏ cụ thể cho tác vụ được tinh chỉnh trong khi phần còn lại của các tham số mô hình được giữ cố định. Diff Pruning [16] và BitFit [6] chứng minh rằng có thể tinh chỉnh mô hình trong khi chỉ cập nhật một tập con nhỏ của các tham số hiện có. Trong các thiết lập huấn luyện phân tán và liên kết, Aji và Heafield [2] và Kone ˇcn`y và cộng sự [23] đã chỉ ra rằng có thể để mỗi worker chỉ cập nhật một tập con thưa thớt của các tham số mô hình, từ đó giảm chi phí truyền thông.

Các phương pháp hiện có để huấn luyện với cập nhật thưa thớt thường hoạt động theo một trong ba cách: chúng hoặc thêm tham số vào mô hình (Adapters), chọn một tập con được định nghĩa bằng tay và có động lực heuristic của các tham số (BitFit), hoặc cho phép tập con tham số thay đổi trong quá trình huấn luyện (Diff Pruning và các phương pháp trong huấn luyện phân tán và liên kết). Trong bài báo này, chúng tôi lập luận cho việc tính toán trước một tập con thưa thớt của các tham số hiện có để cập nhật và giữ tập con cố định qua nhiều vòng lặp huấn luyện. Phương pháp này mang lại các lợi ích khác nhau: Đầu tiên, bằng cách cập nhật một tập con của các tham số hiện có thay vì thêm tham số (như được thực hiện trong Adapters), chúng tôi tránh bất kỳ sự gia tăng nào trong tổng kích thước của mô hình. Thứ hai, bằng cách tránh định nghĩa mặt nạ bằng tay, chúng tôi có thể đảm bảo rằng quy trình của chúng tôi không phụ thuộc vào mô hình. Thứ ba, bằng cách tính toán trước mặt nạ, chúng tôi tránh được overhead tính toán và bộ nhớ rõ ràng khi cập nhật mặt nạ trong quá trình huấn luyện. Nó cũng cho phép các worker trong thiết lập huấn luyện phân tán hoạt động trên các tập con tham số hoàn toàn bổ sung. Cuối cùng, việc giữ mặt nạ cố định qua nhiều vòng lặp, chúng tôi có thể đảm bảo rằng chỉ một số cố định cụ thể của tham số được cập nhật. Chúng tôi không biết về bất kỳ kỹ thuật hiện có nào thỏa mãn các yêu cầu này.

Được thúc đẩy bởi những lợi ích này, chúng tôi giới thiệu một phương pháp mới để tính toán trước các mặt nạ thưa thớt cố định. Phương pháp của chúng tôi đầu tiên ước tính tầm quan trọng của mỗi tham số bằng cách sử dụng một phép xấp xỉ thực nghiệm của thông tin Fisher của nó. Sau đó, chúng tôi xây dựng mặt nạ bằng cách chọn k tham số có thông tin Fisher lớn nhất. Mặt nạ kết quả, mà chúng tôi gọi là "FISH Mask (Fisher-Induced Sparse uncHanging)", có thể được sử dụng lại cho nhiều vòng lặp huấn luyện tiếp theo. Chúng tôi chứng minh hiệu quả của việc sử dụng FISH Mask trong nhiều thiết lập khác nhau, bao gồm học chuyển giao hiệu quả tham số, huấn luyện phân tán với độ trễ dài giữa các worker, và giảm kích thước checkpoint. Nói rộng ra, huấn luyện FISH Mask có thể giảm đáng kể yêu cầu lưu trữ và truyền thông, trong khi hy sinh hiệu suất tối thiểu so với gradient descent tiêu chuẩn và vượt trội so với các phương pháp trước đó có liên quan để huấn luyện với cập nhật thưa thớt.

## 2 Mặt nạ FISH (Fisher-Induced Sparse uncHanging)

Đóng góp chính của bài báo này là một phương pháp để tính toán trước một tập con thưa thớt của các tham số mô hình để cập nhật qua nhiều vòng lặp huấn luyện tiếp theo. Để xây dựng tập con như vậy, chúng tôi sử dụng một phép xấp xỉ thông tin Fisher của mỗi tham số như một tín hiệu về mức độ quan trọng của tham số đối với tác vụ đã cho. Chúng tôi gọi mặt nạ kết quả (tức là mảng nhị phân chỉ ra tham số nào được bao gồm trong tập con) là FISH Mask (Fisher-Induced Sparse uncHanging). Trong phần này, chúng tôi cung cấp nền tảng cần thiết và chi tiết các bước cần thiết để tính toán FISH Mask. Quá trình này được minh họa trong hình 1.

### 2.1 Thông tin Fisher

Mục tiêu của chúng tôi là chọn tập con các tham số (theo một nghĩa nào đó) quan trọng nhất để cập nhật. Một cách để đo lường tầm quan trọng của tham số là xem xét việc thay đổi tham số sẽ thay đổi đầu ra của mô hình như thế nào. Chúng tôi ký hiệu p(y|x) là phân phối đầu ra trên y được tạo ra bởi mô hình với vector tham số θ ∈ R|θ| cho đầu vào x. Một cách để đo lường việc thay đổi tham số sẽ thay đổi dự đoán của mô hình như thế nào là tính toán D_KL(p(y|x)||p_θ+ε(y|x)), trong đó ε ∈ R|θ| là một nhiễu động nhỏ. Có thể chỉ ra [34, 37] rằng khi ε → 0, đến bậc hai:

E_x[D_KL(p(y|x)||p_θ+ε(y|x))] = ε^T F ε + O(ε^3)  (1)

trong đó F ∈ R|θ|×|θ| là ma trận thông tin Fisher [14, 4], được định nghĩa là:

F = E_x~p(x)[E_y~p(y|x)[∇_θ log p(y|x) ∇_θ log p(y|x)^T]]  (2)

Cho quan hệ này, có thể thấy rằng ma trận thông tin Fisher được kết nối chặt chẽ với mức độ mỗi tham số ảnh hưởng đến dự đoán của mô hình. Thật vậy, điều này đã dẫn đến việc ma trận thông tin Fisher được sử dụng rộng rãi trong học máy hiện đại, ví dụ như một thước đo tầm quan trọng tham số [21], như một preconditioner trong gradient descent [4,37,34], như một cách để đo lường lượng "thông tin" trong mỗi tham số của mạng nơ-ron [1], hoặc như một cách để quyết định tham số nào cần cắt tỉa khi thực hiện nén mô hình [43, 10, 47].

Khi áp dụng cho các mạng nơ-ron lớn, kích thước |θ| × |θ| của ma trận thông tin Fisher làm cho nó không thể tính toán được. Do đó, các nghiên cứu trước thường xấp xỉ F như một ma trận đường chéo, hoặc tương đương, như một vector trong R|θ|. Riêng biệt, khi huấn luyện các mô hình học máy, chúng ta hiếm khi có khả năng rút mẫu x ~ p(x); thay vào đó, chúng ta được cung cấp một tập huấn luyện hữu hạn của các mẫu như vậy. Hơn nữa, thường không cần thiết phải tính toán kỳ vọng trên x trong phương trình (2) trên toàn bộ tập huấn luyện; thay vào đó, nó thường có thể được xấp xỉ tốt trên N mẫu x_1, ..., x_N. Những ràng buộc này dẫn đến phép xấp xỉ phổ biến sau:

F̂ = (1/N) Σ_{i=1}^N E_y~p(y|x_i)[(∇_θ log p(y|x_i))^2]  (3)

trong đó F̂ ∈ R|θ|. Phép xấp xỉ này cũng có một diễn giải trực quan: Một mục nhập cho trước trong F̂ liên quan đến trung bình của bình phương gradient của đầu ra mô hình đối với một tham số cho trước. Nếu một tham số cho trước ảnh hưởng mạnh đến đầu ra của mô hình, thì mục nhập tương ứng trong F̂ sẽ lớn, vì vậy chúng ta có thể hợp lý coi F̂ là một phép xấp xỉ của tầm quan trọng của mỗi tham số.

Lưu ý rằng cả phương trình (2) và phương trình (3) đều bao gồm kỳ vọng trên y ~ p(y|x). Khi số lượng lớp nhỏ, kỳ vọng này có thể được tính toán chính xác. Đối với các tác vụ có nhiều lớp có thể, việc xấp xỉ kỳ vọng bằng một vài mẫu từ p(y|x) là phổ biến. Trong các thiết lập học có giám sát, chúng ta có quyền truy cập vào nhãn thực tế y_i cho mỗi mẫu x_i trong tập huấn luyện của chúng ta. Điều này dẫn đến khả năng thay thế E_y~p(y|x_i)[(∇_θ log p(y|x_i))^2] trong phương trình (3) bằng (∇_θ log p(y_i|x_i))^2. Thực hiện phép xấp xỉ này được gọi là "Fisher thực nghiệm". Đã được chỉ ra rằng việc sử dụng Fisher thực nghiệm có thể dẫn đến hành vi thoái hóa khi được sử dụng làm preconditioner trong optimizer [34,26]. Vì việc sử dụng thông tin Fisher của chúng tôi chủ yếu dựa trên khái niệm tầm quan trọng tham số có động lực heuristic, chúng tôi đã thử nghiệm với cả phép xấp xỉ Fisher thực nghiệm và tiêu chuẩn (phương trình (3)) và thấy rằng chúng tạo ra hiệu suất tương tự. Hơn nữa, Fisher thực nghiệm nhanh hơn để tính toán so với Fisher tiêu chuẩn miễn là nhiều hơn một mẫu được sử dụng để xấp xỉ kỳ vọng E_y~p(y|x_i). Chúng tôi thảo luận thêm về điều này trong phần 4.4.1.

### 2.2 Tính toán mặt nạ thưa thớt cố định

Nhớ lại rằng mục tiêu của chúng tôi là chọn một tập con tham số (hoặc, tương đương, một mặt nạ thưa thớt trên các tham số) để cập nhật qua nhiều vòng lặp huấn luyện trong khi giữ phần còn lại của các tham số cố định. Sau khi thiết lập thông tin Fisher là một công cụ hữu ích để ước tính tầm quan trọng của một tham số cho trước, do đó chúng tôi đầu tiên tính toán thông tin Fisher xấp xỉ (như được mô tả trong phần trước) cho tất cả các tham số của mô hình. Sau đó, để xây dựng FISH Mask, chúng tôi chỉ đơn giản chọn k tham số có thông tin Fisher lớn nhất, trong đó k được đặt theo mức độ thưa thớt mặt nạ mong muốn.

Cụ thể, FISH Mask bao gồm các tham số {θ_i | F̂_i ∈ sort(F̂)[:k]}. Việc tính toán FISH Mask là rẻ vì F̂ có thể được tính toán hiệu quả bằng cách sử dụng backpropagation, và (như chúng tôi sẽ chỉ ra trong phần 4.4.2) chúng ta có thể có được một mặt nạ đáng tin cậy cho các giá trị N tương đối nhỏ. Hơn nữa, thực tế là chúng tôi tái sử dụng mặt nạ cho nhiều vòng lặp ngăn chúng tôi phải tính toán F̂ thường xuyên. Như chúng tôi sẽ chỉ ra trong phần 4, chúng tôi thấy rằng quy trình đơn giản này đủ để tạo ra một mặt nạ có thể được sử dụng lại cho nhiều vòng lặp (hơn 100,000 vòng lặp trong một số trường hợp) trong nhiều thiết lập khác nhau mà không hy sinh hiệu suất đáng kể so với huấn luyện dựa trên gradient tiêu chuẩn.

Lưu ý rằng trong một số ứng dụng học chuyển giao, một lớp phân loại tuyến tính mới phải được thêm vào mô hình để làm cho nó áp dụng được cho tác vụ hạ nguồn. Vì FISH Mask phụ thuộc vào p(y|x) và được tính toán trước khi huấn luyện bắt đầu, điều này có nghĩa là chúng ta phải tính toán FISH Mask bằng cách sử dụng bộ phân loại được khởi tạo ngẫu nhiên trước khi bất kỳ huấn luyện nào bắt đầu. Chúng tôi thấy rằng việc tính toán thông tin Fisher thông qua lớp phân loại được khởi tạo ngẫu nhiên vẫn cung cấp tín hiệu tốt về tầm quan trọng tham số. Khi áp dụng FISH Mask trong các thiết lập học chuyển giao nơi một lớp phân loại mới được thêm vào, chúng tôi luôn bao gồm các tham số của bộ phân loại trong mặt nạ.

## 3 Công trình liên quan

Phương pháp của chúng tôi có điểm tương đồng và lấy cảm hứng từ các phương pháp hiện có cho học chuyển giao hiệu quả tham số và huấn luyện phân tán của các mô hình học máy. Trong phần này, chúng tôi phác thảo các phương pháp liên quan, một số trong đó chúng tôi sẽ so sánh trực tiếp trong phần 4. Chúng tôi cũng mô tả ngắn gọn cách công trình của chúng tôi liên quan và khác biệt với công trình trong cắt tỉa mạng.

### 3.1 Học chuyển giao hiệu quả tham số

Học chuyển giao [36], nơi một mô hình được khởi tạo từ một checkpoint đã được huấn luyện trước trước khi được tinh chỉnh trên tác vụ hạ nguồn có liên quan, có thể cải thiện đáng kể hiệu suất và tăng tốc độ hội tụ trên tác vụ hạ nguồn [12,8,40]. Thực hành tiêu chuẩn là cập nhật tất cả các tham số của mô hình trong quá trình tinh chỉnh, mặc dù trong một số trường hợp hiệu suất hợp lý có thể đạt được bằng cách chỉ tinh chỉnh lớp đầu ra của mô hình [20,8,38]. Việc chỉ huấn luyện lớp đầu ra có lợi ích là việc thích ứng một mô hình đã được huấn luyện trước cho trước với tác vụ hạ nguồn chỉ yêu cầu thêm một số lượng tương đối nhỏ tham số mới, nhưng thường dẫn đến hiệu suất kém hơn so với huấn luyện toàn bộ mô hình [38, 24].

Các phương pháp khác nhau đã được đề xuất nhằm cố gắng đạt hiệu suất của việc tinh chỉnh toàn bộ mô hình trong khi chỉ cập nhật hoặc thêm một lượng nhỏ tham số. Adapters [19,41,5] là các mạng con nhỏ được thêm vào giữa các lớp mạng nơ-ron đã được huấn luyện trước. Các nghiên cứu khác nhau [19,33,32] đã chỉ ra rằng, khi được thiết kế phù hợp, việc chỉ cập nhật các tham số trong adapters và lớp đầu ra có thể tiếp cận hiệu suất của việc tinh chỉnh tất cả tham số. Ví dụ, Houlsby và cộng sự [19] thêm trung bình 3.6% tham số hơn để thích ứng mô hình BERT đã được huấn luyện trước [12] với các tác vụ trong benchmark GLUE [48]. Công trình đồng thời của Mahabadi và cộng sự [33] cải thiện hiệu quả của Adapters bằng cách tạo ra trọng số của adapters cụ thể cho tác vụ qua một hypernetwork. Phương pháp đồng thời thứ hai của Mahabadi và cộng sự [32] giới thiệu COMPACTER, sử dụng phân tách ma trận và tham số hóa low-rank cho trọng số của adapters. COMPACTER được chỉ ra đạt hiệu suất tương tự như tinh chỉnh tiêu chuẩn của các mô hình T5 [40] trong khi chỉ thêm 0.047% tham số so với mô hình gốc. Cuối cùng, công trình rất gần đây đã chỉ ra rằng có thể huấn luyện các mô hình ngôn ngữ để thực hiện một tác vụ bằng cách chỉ tối ưu hóa các tham số của một "prompt" được tiêm vào đầu vào của các lớp mô hình [29,28]. Điều này có thể mang lại kết quả cực kỳ hiệu quả tham số (thấp đến 0.01% tham số cụ thể cho tác vụ [28]) nhưng loại phương pháp này chỉ áp dụng được cho các mô hình ngôn ngữ dự đoán bước tiếp theo. Nhược điểm chính của tất cả các phương pháp kiểu Adapter là chúng tăng số lượng tham số và chi phí tính toán của mô hình. Điều này làm cho chúng không thể áp dụng cho các thiết lập huấn luyện phân tán và checkpointing hiệu quả được xem xét trong bài báo này. Do đó, chúng tôi chỉ so sánh trực tiếp với các phương pháp khác không thêm bất kỳ tham số nào.

Có liên quan chặt chẽ hơn đến phương pháp của chúng tôi là các phương pháp để chọn một tập con nhỏ các tham số hiện có của mô hình để cập nhật. Trong trường hợp cực đoan, Zhao và cộng sự [50] tìm một mặt nạ thưa thớt để nhân với các tham số đã được huấn luyện trước (không được cập nhật khác). Tức là, thay vì tinh chỉnh các mô hình, một mặt nạ nhị phân được học để đánh dấu tham số nào nên được đặt về không. Hiệu suất kết quả giảm mạnh khi mặt nạ được làm rất thưa thớt, cho thấy rằng việc cập nhật tham số có thể có lợi. Gần đây hơn, Guo và cộng sự [16] đề xuất "Diff Pruning", nơi một mặt nạ nhị phân thưa thớt được tìm thấy trong quá trình huấn luyện để biểu thị tham số nào nên được cập nhật hoặc cố định ở giá trị từ mô hình đã được huấn luyện trước. Độ thưa thớt mặt nạ trong mặt nạ nhị phân được thực thi thông qua một phép xấp xỉ mịn của norm L_0 được giới thiệu bởi Louizos và cộng sự [31]. Guo và cộng sự [16] cũng chỉ ra hiệu suất được cải thiện bằng cách áp đặt một cấu trúc trên mặt nạ theo tham số nào tương ứng với một ma trận trọng số cụ thể hoặc vector bias. Cuối cùng, Diff Pruning được chỉ ra vừa hiệu quả hơn về tham số và vượt trội so với Adapters khi áp dụng để tinh chỉnh BERT trên benchmark GLUE. Tuy nhiên, việc sử dụng Diff Pruning yêu cầu đáng kể nhiều bộ nhớ hơn trong quá trình huấn luyện để lưu trữ và cập nhật mặt nạ. Một kết quả gần đây khác của Ben-Zaken và cộng sự [6] chứng minh rằng việc chỉ cập nhật các tham số bias trong BERT có thể đạt hiệu suất cạnh tranh với Diff Pruning. Mặc dù điều này cung cấp một baseline đơn giản và mạnh mẽ, nó không áp dụng được phổ quát – ví dụ, mô hình T5 đã được huấn luyện trước [40] không có bất kỳ vector bias nào. Trong phần 4, chúng tôi chỉ ra rằng việc sử dụng FISH Mask vượt trội so với tất cả các phương pháp này trong tinh chỉnh hiệu quả tham số của BERT trên GLUE.

### 3.2 Huấn luyện phân tán

Khi các mô hình và tập dữ liệu phát triển, việc huấn luyện mô hình trên một máy đơn lẻ trở nên không hiệu quả hoặc không thể. Điều này đã thúc đẩy nhu cầu về các chiến lược huấn luyện phân tán nơi tính toán để huấn luyện mô hình được chia sẻ giữa nhiều máy (được gọi là workers) [11]. Một cân nhắc chính trong huấn luyện phân tán là chi phí truyền thông, vì các worker cần thường xuyên truyền thông cập nhật tham số với nhau. Để giảm thiểu chi phí truyền thông, các worker có thể tính toán nhiều cập nhật trên bản sao mô hình của họ trước khi truyền thông các thay đổi của họ, nhưng điều này gây ra vấn đề "gradient cũ" nơi các worker đang hoạt động trên bản sao mô hình đã lỗi thời. Phương pháp tiêu chuẩn và đơn giản để đối phó với gradient cũ là chỉ đơn giản áp dụng cập nhật theo thứ tự "sai", có thể hiệu quả trong thực tế [11,42]. Một phương pháp trực giao để giảm chi phí truyền thông là để các worker chỉ cập nhật một tập con nhỏ các tham số của mô hình [2,13,44,45]. Ví dụ, Aji và Heafield [2] chỉ đơn giản để các worker truyền thông chỉ những cập nhật tương ứng với các gradient có độ lớn top-k lớn nhất tại mỗi bước. Điều này mang động lực tương tự như FISH Mask, nhưng dẫn đến một "mặt nạ" thay đổi tại mỗi vòng lặp và do đó yêu cầu các worker truyền thông sau mỗi cập nhật. Ngược lại, việc tính toán trước FISH Mask cho phép các worker thực hiện nhiều vòng lặp trước khi truyền thông cập nhật của họ, từ đó giảm thêm chi phí truyền thông.

Một biến thể cực đoan của huấn luyện phân tán là học liên kết [22,35]. Trong học liên kết, các worker bất đồng bộ thực hiện nhiều cập nhật trên dữ liệu riêng tư trước khi truyền thông các thay đổi trở lại mô hình tập trung. Việc huấn luyện liên quan đến một máy chủ và nhiều máy khách, và gradient của mô hình máy chủ là sự kết hợp của gradient của các worker. Như với bất kỳ dạng huấn luyện bất đồng bộ nào, chi phí truyền thông và gradient cũ là những vấn đề đáng kể. McMahan và cộng sự [35] chứng minh rằng việc lấy trung bình các cập nhật được tính toán bởi các worker riêng lẻ là một phương pháp hiệu quả để đối phó với gradient cũ và Kone ˇcn`y và cộng sự [23] đã nghiên cứu các kỹ thuật để giảm đáng kể chi phí truyền thông. Phương pháp của chúng tôi bổ sung cho các kỹ thuật giảm truyền thông được đề xuất bởi Kone ˇcn`y và cộng sự [23].

### 3.3 Cắt tỉa mạng

Công trình trước đây trong cắt tỉa mạng cũng đã khám phá các kỹ thuật để làm thưa thớt mạng nơ-ron (tức là đặt về không nhiều tham số cho mục đích nén) trong khi hy sinh hiệu suất tối thiểu. Có liên quan nhất đến công trình của chúng tôi, Theis và cộng sự [46] đề xuất sử dụng Fisher để cắt tỉa và giảm tổng số tham số cho dự đoán ánh mắt, và Liu và cộng sự [30] cũng sử dụng Fisher để khám phá các nhóm tham số để cắt tỉa từ các kiến trúc backbone phổ biến. Quan trọng, những công trình này khác với công trình của chúng tôi ở chỗ chúng tôi không huấn luyện mạng nơ-ron với trọng số thưa thớt. Thay vào đó, chúng tôi tập trung vào việc sử dụng Fisher để thông báo việc lựa chọn một tập con thưa thớt cố định của trọng số trong mạng không thưa thớt để cập nhật trong quá trình huấn luyện.

## 4 Thí nghiệm

Chúng tôi đánh giá hiệu quả của FISH Mask trong ba thiết lập: học chuyển giao hiệu quả tham số, huấn luyện phân tán, và huấn luyện với checkpointing hiệu quả. Đối với học chuyển giao hiệu quả tham số, chúng tôi chứng minh rằng phương pháp của chúng tôi đạt hiệu suất của huấn luyện dựa trên gradient tiêu chuẩn trên benchmark GLUE [48] trong khi chỉ cập nhật 0.5% tham số của mô hình mỗi tác vụ. Đối với huấn luyện phân tán, chúng tôi đánh giá huấn luyện FISH Mask cho cả học chuyển giao trên GLUE và huấn luyện từ đầu trên CIFAR-10 [25]. Trong cả hai thiết lập, chúng tôi thấy rằng chúng ta có thể giảm đáng kể truyền thông mà không hy sinh hiệu suất đáng kể, mặc dù huấn luyện từ đầu trên CIFAR-10 yêu cầu mức độ thưa thớt mặt nạ cao hơn so với tinh chỉnh trên GLUE. Cuối cùng, chúng tôi chứng minh một ứng dụng mới của huấn luyện với cập nhật thưa thớt: Giảm thiểu kích thước checkpoint trong quá trình huấn luyện. Chúng tôi chỉ ra rằng việc sử dụng FISH Mask trong khi huấn luyện trên CIFAR-10 với mức độ thưa thớt mặt nạ 10% có thể thu nhỏ kích thước checkpoint trên đĩa với hệ số 5 trong khi chỉ hy sinh một lượng nhỏ độ chính xác.

Trong suốt các thí nghiệm của chúng tôi, chúng tôi báo cáo kết quả với các mức độ thưa thớt mặt nạ khác nhau để có cảm giác về tiết kiệm được tạo ra bởi FISH Mask. Để dễ so sánh, chúng tôi báo cáo độ thưa thớt mặt nạ theo tỷ lệ phần trăm tổng số tham số được cập nhật. Tỷ lệ phần trăm này có thể được chuyển đổi thành giá trị k được sử dụng cho phép toán top-k khi xây dựng mặt nạ chỉ đơn giản bằng cách nhân nó với tổng số tham số trong mô hình.

Chúng tôi cũng bao gồm các nghiên cứu ablation để đo lường tác động của số lượng mẫu được sử dụng để ước tính thông tin Fisher cũng như lựa chọn Fisher thực hoặc thực nghiệm. Tất cả thí nghiệm cho GLUE được chạy với biến thể BERT LARGE của BERT, chứa 16 attention heads, 24 lớp và tổng cộng 330 triệu tham số [12], và hầu hết các thí nghiệm được chạy trên GPU RTX 3090. Đối với các thí nghiệm trên CIFAR-10, chúng tôi sử dụng ResNet-34 [18] với các tối ưu hóa khác nhau để hội tụ nhanh. Chúng tôi báo cáo hiệu suất trung bình trên 5 seeds cho tất cả thí nghiệm.

### 4.1 Học chuyển giao hiệu quả tham số

Trong học chuyển giao hiệu quả tham số, mục tiêu là tinh chỉnh mô hình đã được huấn luyện trước trong khi cập nhật ít tham số nhất có thể. Chúng tôi tập trung vào việc tinh chỉnh BERT LARGE trên benchmark GLUE [48], đây là thiết lập chính được sử dụng để đánh giá trong các công trình trước. Đối với tất cả thí nghiệm, chúng tôi tinh chỉnh trong 7 epochs và thực hiện tìm kiếm siêu tham số trên learning rate ∈ {1×10^-4, 5×10^-5, 1×10^-5} và batch size ∈ {8, 16} cho mỗi tác vụ GLUE. Chúng tôi thấy learning rate 5×10^-5 và batch size 16 hiệu quả cho hầu hết các tác vụ, ngoại trừ batch size = 8 được sử dụng cho RTE. Các siêu tham số bổ sung, chẳng hạn như lựa chọn optimizer, độ dài chuỗi, và các tham số khác, tuân theo cấu hình mặc định cho BERT LARGE được trình bày trong thư viện Hugging Face [49]. Kết quả tập test được báo cáo bằng cách gửi đến benchmark GLUE sử dụng checkpoint mô hình cuối cùng sau tìm kiếm siêu tham số trên kết quả validation, trừ khi có ghi chú khác.

**Baselines** Chúng tôi so sánh hiệu suất tác vụ GLUE của FISH Mask với một số baselines khác và các phương pháp tập trung vào học chuyển giao hiệu quả tham số. Trong **Dense Fine-tuning**, chúng tôi tinh chỉnh tất cả tham số của mô hình đã được huấn luyện trước, như điển hình trong học chuyển giao tiêu chuẩn. Trong baseline **Random Mask**, chúng tôi chọn và cố định ngẫu nhiên k tham số để cập nhật tại đầu huấn luyện. Để so sánh với công trình trước, chúng tôi tái tạo **Bit-Fit** [6], trong đó chỉ các tham số bias của mô hình BERT được cập nhật trong suốt quá trình huấn luyện. Việc tái tạo của chúng tôi tuân theo bài báo gốc và thực hiện tìm kiếm siêu tham số với learning rates trong phạm vi [1×10^-3, 1×10^-4]. Chúng tôi cũng tái tạo kết quả từ **Diff Pruning** [16], cập nhật mặt nạ thưa thớt trong quá trình huấn luyện. Việc tái tạo Diff Pruning của chúng tôi ở mức độ thưa thớt mặt nạ 0.5% tuân theo code-base của bài báo và các thiết lập huấn luyện, và báo cáo kết quả tập test GLUE sử dụng checkpoint validation tốt nhất. Do hạn chế về số lượng gửi được phép đến máy chủ test GLUE, chúng tôi chỉ có thể báo cáo kết quả với mức độ thưa thớt mặt nạ 0.5% cho những phương pháp mà chúng tôi có thể kiểm soát mức độ thưa thớt mặt nạ. Do đó, chúng tôi bao gồm thêm kết quả tập validation cho các mức độ thưa thớt mặt nạ khác nhau khi sử dụng FISH Mask.

**Kết quả** Kết quả của chúng tôi về học chuyển giao hiệu quả tham số với FISH Mask có thể thấy trong bảng 1. Huấn luyện FISH Mask dẫn đến hiệu suất thực tế giống như tinh chỉnh "dense" tiêu chuẩn (82.5%), mặc dù chỉ cập nhật 0.5% tham số BERT LARGE. Baseline Random Mask đạt điểm GLUE trung bình thấp hơn đáng kể, điều này chứng minh giá trị của việc sử dụng thông tin Fisher trong việc lựa chọn tham số để cập nhật. Cuối cùng, huấn luyện FISH Mask có tính cạnh tranh với tất cả các phương pháp học chuyển giao hiệu quả tham số khác; điểm tốt nhất tiếp theo là 81.5% được đạt bởi Diff Pruning [16]. Như đã đề cập trong phần 3, chúng tôi không bao gồm so sánh trực tiếp với các phương pháp dựa trên Adapter vì chúng thêm tham số vào mô hình, mặc dù chúng tôi lưu ý rằng phương pháp của chúng tôi có thể đạt hiệu suất của BERT LARGE sử dụng mức độ thưa thớt mặt nạ thấp hơn đáng kể (0.5% so với 3.6%) so với phương pháp được đề xuất bởi Houlsby và cộng sự [19].

Hình 2 chỉ ra sự thay đổi trong hiệu suất trên tập validation GLUE khi chúng tôi thay đổi mức độ thưa thớt mặt nạ cho cả mặt nạ ngẫu nhiên và FISH Mask. Chúng tôi thấy rằng FISH Mask liên tục vượt trội so với baseline mặt nạ ngẫu nhiên và vẫn mạnh ngay cả ở mức độ thưa thớt mặt nạ thấp hơn là 0.1%. Những kết quả này chứng minh rằng FISH Mask có thể là một công cụ hữu ích trong việc giảm thiểu chi phí lưu trữ của việc lưu nhiều mô hình tinh chỉnh vì nó chỉ yêu cầu rằng các tham số cập nhật và các chỉ số tương ứng của chúng được lưu.

### 4.2 Huấn luyện phân tán

Bây giờ, chúng tôi chuyển sang sử dụng FISH Mask để giảm chi phí truyền thông trong các thiết lập huấn luyện phân tán. Chúng tôi xem xét thiết lập nơi các worker phân tán tính toán nhiều cập nhật liên tiếp cho một bản sao cục bộ của mô hình trước khi truyền các thay đổi của họ trở lại máy chủ trung tâm. Trong các thí nghiệm của chúng tôi, chúng tôi giả định tất cả worker lấy mẫu dữ liệu i.i.d. từ cùng một tập dữ liệu và tất cả worker tính toán cùng số lượng cập nhật giữa mỗi bước truyền thông, mặc dù kết quả của chúng tôi có thể chuyển sang các thiết lập nơi worker sử dụng các tập dữ liệu khác nhau và lượng cập nhật khác nhau (ví dụ trong Federated Learning [35]).

Gọi θ biểu thị vector tham số được lưu trữ trên máy chủ trung tâm và Δ_i đại diện cho cập nhật được tính toán bởi worker i. Sau mỗi bước cập nhật/truyền thông, máy chủ phải truyền θ cập nhật trở lại tất cả worker. Khi huấn luyện dựa trên gradient tiêu chuẩn được sử dụng, tất cả tham số được cập nhật, vậy |Δ_i| = |θ|. Nếu có M worker, chi phí truyền thông cho huấn luyện bình thường là M|Δ_i| = M|θ| cho truyền thông worker-to-server và M|θ| cho truyền thông server-to-worker, tổng chi phí truyền thông là 2M|θ|.

Việc sử dụng mặt nạ thưa thớt sẽ hiệu quả giảm kích thước của mỗi Δ_i xuống k. Không mất tính tổng quát, chúng tôi giả định rằng |Δ_i| giống nhau trên tất cả worker. Hơn nữa, giả định cập nhật được tập hợp trên máy chủ trung tâm bằng cách cộng chúng lại với nhau, máy chủ có thể hoặc truyền thông vector tham số cập nhật đầy đủ trở lại tất cả worker, hoặc máy chủ có thể truyền thông tất cả cập nhật của worker khác đến một worker cho trước. Hai tùy chọn này tương đương với chi phí truyền thông server-to-worker hoặc M|θ| hoặc M(M-1)|Δ_i| ≈ M^2|Δ_i|. Nói chung, chúng tôi mong đợi M nhỏ và |θ| lớn, vì vậy chúng tôi thường có M^2|Δ_i| < M|θ|. Do đó, chúng ta có thể đạt được tiết kiệm truyền thông đáng kể bằng cách sử dụng cập nhật thưa thớt. Để đơn giản, chúng tôi đặt M = 2 trong tất cả thí nghiệm của chúng tôi; điều này làm cho tiết kiệm trong truyền thông bằng mức độ thưa thớt mặt nạ. Để áp dụng FISH trong huấn luyện phân tán, máy chủ trung tâm tính toán F̂ và một FISH Mask duy nhất được chia sẻ trên tất cả worker.

**Baselines** Đối với các thí nghiệm huấn luyện phân tán, chúng tôi so sánh huấn luyện FISH Mask với ba baselines: Đầu tiên, trong **huấn luyện tiêu chuẩn**, chúng tôi điều chỉnh tất cả tham số trong một máy đơn lẻ (tức là huấn luyện tiêu chuẩn, không phân tán). Điều này cung cấp giới hạn trên về hiệu suất cho các kỹ thuật huấn luyện phân tán. Thứ hai, trong **huấn luyện phân tán cập nhật dense**, worker sử dụng gradient descent tiêu chuẩn để tính toán cập nhật trên tất cả tham số, và tất cả cập nhật của worker được cộng lại với nhau trên máy chủ tập trung. Thứ ba, trong **huấn luyện phân tán mặt nạ ngẫu nhiên**, chúng tôi chọn ngẫu nhiên một tập con tham số để cập nhật cho worker. Để so sánh công bằng, chúng tôi giữ tổng batch huấn luyện giống nhau cho tất cả phương pháp, vì vậy các vòng lặp huấn luyện của một worker là một nửa so với baseline máy đơn lẻ.

**Thiết lập thí nghiệm** Trong các thí nghiệm sơ bộ trên benchmark GLUE (được mô tả trong phụ lục A), chúng tôi thấy rằng huấn luyện phân tán cập nhật dense không thấy sự suy giảm hiệu suất thực sự ngay cả đối với độ trễ truyền thông dài. Điều này cho thấy gradient cũ có thể ít là vấn đề hơn trong các thiết lập học chuyển giao. Do đó, chúng tôi tập trung vào huấn luyện từ đầu của ResNet-34 trên CIFAR-10. Chúng tôi huấn luyện mô hình trong tổng cộng 100 epochs, với 50 epochs được thực hiện bởi mỗi trong hai worker. Đáng chú ý, chúng tôi thấy rằng hiệu suất của các phương pháp cập nhật thưa thớt kém trừ khi chúng tôi thực hiện 5 epochs huấn luyện tiêu chuẩn như "warmup" trước khi bắt đầu huấn luyện phân tán. Ngoài thay đổi này, tất cả các mô hình và siêu tham số tuân theo những gì đã đề cập trong phần 4.1. Chúng tôi tìm kiếm learning rate ban đầu tốt nhất trong {0.4, 0.2, 0.08, 0.04, 0.02}. Chúng tôi đo hiệu suất sử dụng số lượng cập nhật tham số khác nhau giữa mỗi bước truyền thông worker-server. Chúng tôi báo cáo hiệu suất theo độ chính xác đạt được dưới một ngân sách truyền thông nhất định, nơi chi phí truyền thông được đo bằng số lượng cập nhật tham số mô hình đầy đủ tương đương. Ví dụ, một phương pháp cập nhật 10% tham số mô hình và thực hiện 5 bước truyền thông trong quá trình huấn luyện có cùng chi phí như một phương pháp truyền thông tất cả tham số mô hình một lần (vì chúng ta phải truyền cả tham số cập nhật và vị trí của chúng; chi tiết hơn trong phần 4.3).

**Kết quả** Kết quả từ huấn luyện ResNet-34 trên CIFAR-10 được chỉ ra trong hình 3. Như trong phần 4.1, việc sử dụng FISH Mask hoạt động tốt hơn so với việc sử dụng mặt nạ ngẫu nhiên cho tất cả chi phí truyền thông. Hơn nữa, chúng tôi thường thấy rằng việc sử dụng FISH Mask với mức độ thưa thớt 10% đạt được sự đánh đổi truyền thông/hiệu suất tốt hơn so với huấn luyện phân tán cập nhật dense. Ví dụ, huấn luyện FISH Mask đạt hiệu suất tương đương với huấn luyện tiêu chuẩn khi chỉ truyền thông hai bản sao của mô hình, trong khi huấn luyện cập nhật dense thực hiện tệ hơn đáng kể ở lượng truyền thông này. Đáng chú ý, hiệu suất tương đối kém khi chỉ cập nhật 2% tham số mô hình với FISH Mask, cho thấy có một giới hạn dưới mà dưới đó việc đạt được kết quả hợp lý là khó khăn. Nhìn chung, kết quả của chúng tôi chỉ ra triển vọng đáng kể để giảm đáng kể chi phí tính toán trong các thiết lập huấn luyện phân tán.

### 4.3 Checkpointing hiệu quả

Trong quá trình huấn luyện mô hình học máy, việc lưu các tệp checkpoint trung gian lưu trữ giá trị tham số mô hình là phổ biến. Những checkpoint này có thể hữu ích để khởi động lại huấn luyện từ một vòng lặp cho trước thay vì bắt đầu từ đầu trong trường hợp công việc huấn luyện gặp sự cố hoặc bị dừng. Chúng cũng thường được sử dụng để phân tích hậu hoc, ví dụ để đánh giá hiệu suất của mô hình trên các tập dữ liệu hoặc metrics mới trong quá trình huấn luyện. Vì checkpoint lưu trữ một bản sao đầy đủ của các tham số mô hình, chúng có thể chiếm một lượng đáng kể không gian trên đĩa. Hơn nữa, tùy thuộc vào tần suất checkpointing, hàng trăm checkpoint thường được ghi vào đĩa trong suốt quá trình huấn luyện. Chu kỳ phát triển của mô hình học máy có thể dẫn đến hàng trăm biến thể mô hình khác nhau được huấn luyện. Kết hợp những yếu tố này với không gian trên đĩa cần thiết để lưu trữ các tham số của các mô hình hiện đại (khoảng 1 GB cho BERT LARGE) dẫn đến chi phí lưu trữ có thể lớn.

Huấn luyện với cập nhật thưa thớt có thể giảm đáng kể những chi phí lưu trữ này. Cụ thể, nếu chỉ một tập con nhỏ tham số được cập nhật giữa các lần lưu checkpoint, thì checkpoint chỉ cần lưu trữ các giá trị tham số cập nhật và chỉ số biểu thị vị trí của các giá trị tham số cập nhật. Giả định rằng chi phí lưu trữ cho một giá trị tham số và chỉ số là như nhau (ví dụ sử dụng float 32-bit cho giá trị tham số và integer 32-bit cho chỉ số), việc sử dụng mặt nạ thưa thớt sẽ giảm chi phí lưu trữ khi mức độ thưa thớt mặt nạ nhỏ hơn 50%. Lưu ý rằng thiết lập này cho phép "mặt nạ" thay đổi trong quá trình huấn luyện, và do đó là một sự nới lỏng của thiết lập trong phần 4.1, nơi yêu cầu là cùng một tập con tham số được cập nhật trong toàn bộ quá trình tinh chỉnh. Theo kết quả của chúng tôi trong phần 4.1, huấn luyện FISH Mask có thể được áp dụng dễ dàng để giảm kích thước checkpoint trong học chuyển giao hiệu quả tham số. Tuy nhiên, chúng tôi thấy rằng yêu cầu nghiêm ngặt về việc cố định mặt nạ trong toàn bộ quá trình huấn luyện từ đầu trên CIFAR-10 dẫn đến sự suy giảm đáng kể trong hiệu suất. Điều này phù hợp với công trình trước đây chứng minh khó khăn của việc xác định các mạng con thưa thớt cố định để huấn luyện trước khi huấn luyện bắt đầu [15]. Do đó, chúng tôi tập trung vào huấn luyện từ đầu trên CIFAR-10 và cho phép mặt nạ thay đổi mỗi lần checkpoint được ghi, điều này không tăng yêu cầu lưu trữ so với việc sử dụng cùng mặt nạ cố định từ đầu huấn luyện.

Nhìn chung, chúng tôi sử dụng cùng thiết lập thí nghiệm như trong phần 4.2. Chúng tôi đo hiệu suất khi cập nhật mặt nạ mỗi epoch (là lựa chọn phổ biến trong thực tế), mỗi 2 epochs, mỗi 4 epochs, và để mặt nạ cố định trong quá trình huấn luyện. Chúng tôi thực hiện tìm kiếm mới về learning rates trong {0.4, 0.2, 0.08, 0.04, 0.02}. Chúng tôi so sánh với baselines của huấn luyện tiêu chuẩn (để phục vụ như giới hạn trên về hiệu suất của việc sử dụng FISH Mask) và sử dụng mặt nạ ngẫu nhiên.

**Kết quả** Trong bảng 2, chúng tôi chỉ ra kết quả của huấn luyện FISH Mask khi giữ mặt nạ cố định trong quá trình huấn luyện hoặc cập nhật nó tại mỗi epoch. Chúng tôi thấy rằng việc cập nhật FISH Mask mỗi epoch có thể đạt hiệu suất của huấn luyện bình thường (93.9% độ chính xác) ở mức độ thưa thớt mặt nạ 10%, điều này sẽ giảm yêu cầu lưu trữ với hệ số 5. Ở mức độ thưa thớt mặt nạ thấp hơn, chúng ta thấy một số suy giảm trong hiệu suất. Chúng tôi thấy rằng độ chính xác có xu hướng giảm khi chúng tôi giảm tần suất cập nhật mặt nạ, nhưng hiệu ứng này tương đối nhỏ. Như đã đề cập trước đó, chúng tôi cũng thấy rằng việc sử dụng mặt nạ cố định làm giảm đáng kể hiệu suất, mặc dù chỉ vài phần trăm ở mức độ thưa thớt mặt nạ 10%. Điều này cho thấy rằng FISH Mask cũng có thể hữu ích để xác định các mạng con thưa thớt để huấn luyện trước khi huấn luyện bắt đầu, như được đoán bởi Giả thuyết Vé số [15]. Chúng tôi để lại việc khám phá khả năng này cho công trình tương lai. Cuối cùng, hiệu suất của FISH Mask đồng nhất tốt hơn so với Random Mask trên ba mức độ thưa thớt mặt nạ.

### 4.4 Ablations

Sau khi thiết lập hiệu quả của huấn luyện với FISH mask, bây giờ chúng tôi ablate một số lựa chọn thiết kế để giúp chứng minh tính mạnh mẽ của phương pháp chúng tôi. Chúng tôi thực hiện tất cả thí nghiệm ablation trong thiết lập học chuyển giao hiệu quả tham số được mô tả trong phần 4.1.

#### 4.4.1 True Fisher so với Empirical Fisher

Trong phần 2, chúng tôi lưu ý rằng công trình trước đây đã xấp xỉ ma trận thông tin Fisher (phương trình (3)) sử dụng hoặc kỳ vọng trên y ~ p(y|x) ("true Fisher") hoặc nhãn thực tế ("empirical Fisher"). Trong khi công trình trước đây đã chỉ ra rằng việc sử dụng empirical Fisher có thể có hại trong các thiết lập tối ưu hóa [34,26], chúng tôi chủ yếu sử dụng thông tin Fisher như một tín hiệu của tầm quan trọng tham số. Empirical Fisher cũng có lợi ích là tránh việc marginalize trên hoặc lấy mẫu từ p(y|x) và chỉ yêu cầu tính toán gradient cho một giá trị duy nhất của y. Khi so sánh hiệu suất của việc sử dụng true hoặc empirical Fisher để tính toán FISH Mask thưa thớt 0.5% cho học chuyển giao hiệu quả tham số, chúng tôi quan sát rằng cả hai phương pháp đều đạt hiệu suất gần như giống hệt nhau với điểm GLUE trung bình trên tập validation là 82.5 trong cả hai trường hợp. Vì tính toán empirical Fisher có thể hiệu quả hơn về mặt tính toán, chúng tôi đã sử dụng empirical Fisher cho tất cả thí nghiệm.

#### 4.4.2 Ablation mẫu

Chúng tôi cũng ablate số lượng mẫu, N, được sử dụng để tính toán FISH Mask để nghiên cứu xem có nhiều mẫu hơn có lợi không. Kết quả cho học chuyển giao hiệu quả tham số trên GLUE được chỉ ra trong hình 2, bên phải. Ở số lượng mẫu 0, FISH Mask tương đương với baseline Random Mask được trình bày trong phần 4.1, trong đó tham số để cập nhật được chọn ngẫu nhiên thay vì được thông báo bởi thông tin Fisher. Chúng tôi quan sát rằng hiệu suất FISH Mask trên tập validation GLUE ổn định đáng ngạc nhiên trên nhiều giá trị mẫu, với chỉ 32 mẫu cần thiết để đạt hiệu suất cao nhất có thể. Những kết quả này cho thấy rằng việc sử dụng thông tin Fisher xấp xỉ là một phương pháp hiệu quả dữ liệu để tính toán tầm quan trọng tham số, và do đó chúng tôi chạy tất cả thí nghiệm với số lượng mẫu N = 1024, ngoại trừ trong huấn luyện phân tán chúng tôi sử dụng N = 256 để hiệu quả.

## 5 Kết luận

Trong công trình này, chúng tôi đề xuất huấn luyện FISH Mask như một phương pháp mới để tính toán trước các mặt nạ thưa thớt cố định của các tham số mô hình để cập nhật qua nhiều vòng lặp tiếp theo. FISH Mask ước tính tầm quan trọng của mỗi tham số mô hình bằng cách đầu tiên xấp xỉ thông tin Fisher của mỗi tham số và sau đó chọn k tham số có thông tin Fisher lớn nhất để bao gồm trong mặt nạ. Chúng tôi chứng minh tính hữu ích của huấn luyện FISH Mask trong một số thiết lập, bao gồm học chuyển giao hiệu quả tham số, huấn luyện phân tán và giảm yêu cầu lưu trữ của checkpoint mô hình. Trong công trình tương lai, chúng tôi hy vọng khám phá các phương pháp cải thiện hiệu suất của huấn luyện FISH Mask ở mức độ thưa thớt mặt nạ thấp hơn, có thể bằng cách xem xét các thước đo khác về tầm quan trọng tham số. Chúng tôi cũng hy vọng chứng minh thêm hiệu quả của FISH Mask trong các thiết lập thực tế nơi lợi ích của việc cập nhật tham số thưa thớt thậm chí còn rõ ràng hơn, chẳng hạn như trong Federated Learning. Việc tích hợp FISH Masks trên các tác vụ và chia sẻ giữa các practitioners cũng có thể là một hướng nghiên cứu hữu ích, như các framework gần đây như AdapterHub [39] đã kích hoạt cho các module Adapter [19].

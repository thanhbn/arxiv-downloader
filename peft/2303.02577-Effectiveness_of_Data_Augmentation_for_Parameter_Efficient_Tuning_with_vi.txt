# Hiệu quả của Tăng cường Dữ liệu cho Điều chỉnh Hiệu quả Tham số với Dữ liệu Hạn chế

Stephen Obadinmaa, Hongyu Guob,c, Xiaodan Zhua
aKhoa Kỹ thuật Điện và Máy tính, Đại học Queen's,
bTrung tâm Nghiên cứu Công nghệ Số, Hội đồng Nghiên cứu Quốc gia Canada,
cTrường Kỹ thuật Điện và Khoa học Máy tính, Đại học Ottawa
a{16sco, xiaodan.zhu}@queensu.ca
b,c{Hongyu.Guo}@nrc-cnrc.gc.ca

Tóm tắt

Công trình gần đây đã chứng minh rằng việc sử dụng các kỹ thuật điều chỉnh hiệu quả tham số như điều chỉnh tiền tố (hoặc P-tuning) trên các mô hình ngôn ngữ được huấn luyện trước có thể mang lại hiệu suất tương đương hoặc vượt trội so với tinh chỉnh trong khi giảm đáng kể các tham số có thể huấn luyện. Tuy nhiên, hiệu quả của các phương pháp này trong bối cảnh tăng cường dữ liệu, một chiến lược phổ biến để cải thiện việc học trong chế độ dữ liệu ít, chưa được khám phá đầy đủ. Trong bài báo này, chúng tôi xem xét hiệu quả của một số kỹ thuật tăng cường dữ liệu phổ biến không phụ thuộc vào tác vụ, tức là EDA, Dịch Ngược và Mixup, khi sử dụng hai phương pháp điều chỉnh hiệu quả tham số tổng quát, P-tuning v2 và LoRA, trong điều kiện khan hiếm dữ liệu. Chúng tôi chỉ ra rằng tăng cường dữ liệu có thể được sử dụng để nâng cao hiệu suất của các mô hình P-tuning và LoRA, nhưng hiệu quả của mỗi kỹ thuật thay đổi và một số phương pháp có thể dẫn đến sự suy giảm đáng kể về hiệu suất, đặc biệt khi sử dụng các mô hình lớn hơn và trên các tác vụ khó hơn. Chúng tôi tiến hành phân tích thêm về biểu diễn câu của P-tuning so với tinh chỉnh để giúp hiểu hành vi trên, và tiết lộ cách P-tuning thường thể hiện khả năng hạn chế hơn trong việc tách biệt các embedding câu từ các lớp khác nhau của dữ liệu được tăng cường. Ngoài ra, nó hiển thị hiệu suất kém hơn trên dữ liệu được thay đổi mạnh. Tuy nhiên, chúng tôi chứng minh rằng bằng cách thêm một hàm mất mát tương phản đơn giản, nó có thể giúp giảm thiểu những vấn đề như vậy cho điều chỉnh tiền tố, dẫn đến những cải thiện đáng kể đối với hiệu suất dữ liệu được tăng cường.

1 Giới thiệu

Trong khi các mô hình ngôn ngữ được huấn luyện trước lớn đã đạt được hiệu suất vượt trội và được áp dụng rộng rãi trên nhiều tác vụ NLP (Zaheer et al., 2020; Bengio et al., 2021), chúng thường chứa hàng trăm triệu hoặc thậm chí hàng trăm tỷ tham số, điều này hạn chế đáng kể việc ứng dụng của chúng vào các tác vụ mà tài nguyên tính toán và lưu trữ bị hạn chế. Để giải quyết vấn đề này, toàn bộ một họ các kỹ thuật được gọi là phương pháp điều chỉnh hiệu quả tham số (PET) đã được phát triển. Đáng chú ý nhất, điều chỉnh prompt sâu (tức là điều chỉnh tiền tố hoặc P-tuning) (Li và Liang, 2021; Qin và Eisner, 2021; Liu et al., 2021) đã thu hút sự chú ý rộng rãi, so với tinh chỉnh, chỉ điều chỉnh các embedding liên tục có thể huấn luyện, dẫn đến một tỷ lệ nhỏ các tham số được điều chỉnh cho mỗi tác vụ. Do đó, một mô hình ngôn ngữ duy nhất có thể được sử dụng cho nhiều tác vụ bằng cách trao đổi các prompt được huấn luyện theo từng tác vụ (Li và Liang, 2021). Thành công như vậy cũng đã được thể hiện bởi mô hình P-tuning v2 hiện đại (Liu et al., 2021), mang lại hiệu suất tương đương với tinh chỉnh trên các tác vụ hiểu ngôn ngữ tự nhiên khác nhau. Ngoài ra, Thích ứng Hạng Thấp (LoRA) (Hu et al., 2021) cũng đã xuất hiện như một cách tiếp cận thay thế, trong đó trọng số của các ma trận phân rã hạng được tiêm vào mỗi lớp được tối ưu hóa thay cho trọng số mạng đầy đủ, giảm tham số có thể huấn luyện trong khi cũng đạt được cải thiện độ chính xác so với tinh chỉnh và các phương pháp PET khác.

Khi dữ liệu huấn luyện khan hiếm trong một tác vụ, tăng cường dữ liệu (DA) là một chiến lược được sử dụng rộng rãi có thể nâng cao hiệu suất của các mô hình học sâu (xem (Feng et al., 2021) cho một khảo sát về tăng cường dữ liệu trong NLP). Khi đó một câu hỏi cơ bản cần được trả lời là nó hiệu quả như thế nào khi các khung PET trên được áp dụng kết hợp với tăng cường dữ liệu. Để giải quyết vấn đề này, chúng tôi nghiên cứu ba phương pháp DA phổ biến không phụ thuộc vào tác vụ, EDA (Wei và Zou, 2019), Dịch Ngược (Sennrich et al., 2016), và Mixup (Guo et al., 2019a) với hai mô hình ngôn ngữ phổ biến BERT (Devlin et al., 2019) và RoBERTa (Liu et al., 2019), được huấn luyện bằng P-tuning v2 (Liu et al., 2021) và LoRA (Hu et al., 2021). Chúng tôi thiết lập nghiên cứu của mình trên năm tác vụ, bao gồm 4 tác vụ từ SuperGLUE (Wang et al., 2019), trong đó kích thước dữ liệu huấn luyện là nhỏ.

Chúng tôi chỉ ra rằng tăng cường dữ liệu có thể tăng độ chính xác của các mô hình điều chỉnh tiền tố. Tuy nhiên, hiệu suất của mỗi kỹ thuật thay đổi tùy thuộc vào tập dữ liệu và mô hình được huấn luyện trước cơ bản, và các kỹ thuật hiệu quả khác với tinh chỉnh. Một số phương pháp thậm chí có thể dẫn đến sự suy giảm đáng kể về hiệu suất, đặc biệt khi sử dụng các mô hình lớn hơn. Để hiểu rõ hơn về các hiện tượng trên, chúng tôi trực quan hóa biểu diễn câu của dữ liệu dưới điều chỉnh tiền tố, một kỹ thuật mà nhiều phương pháp tăng cường thất bại trong việc có được kết quả tốt, để quan sát xem có bất kỳ hạn chế nào hiện diện với cách dữ liệu được biểu diễn dẫn đến hiệu suất kém trong một số trường hợp nhất định. Thông qua điều này, chúng tôi thấy rằng các mô hình này gặp khó khăn hơn trong việc tách biệt các embedding được tăng cường từ các lớp khác nhau. Quan sát này được hỗ trợ thêm bởi các thí nghiệm bổ sung của chúng tôi cho thấy độ bền thấp hơn đối với dữ liệu được tăng cường thay đổi mạnh so với tinh chỉnh, và phân tích độ tương tự cosine giữa các embedding câu của các câu được tăng cường và các đối tác gốc của chúng, nơi chúng tôi thấy rằng điều chỉnh tiền tố tạo ra các embedding có độ tương tự cao bất kể những thay đổi. Chúng tôi tìm cách cải thiện hiệu suất khi huấn luyện trên dữ liệu được tăng cường bằng cách thêm một số hạng mất mát tương phản (Oord et al., 2018) để giảm thiểu khoảng cách giữa các embedding trong lớp trong P-tuning v2, giúp giảm thiểu những vấn đề trên với biểu diễn câu, và dẫn đến một số cải thiện về độ chính xác. Chúng tôi hy vọng nghiên cứu thực nghiệm này giúp tạo điều kiện cho công việc tương lai về việc tận dụng tăng cường dữ liệu khi huấn luyện các mô hình dựa trên transformer sử dụng phương pháp điều chỉnh hiệu quả tham số.

2 Công trình Liên quan

Một loạt các kỹ thuật tăng cường dữ liệu được sử dụng trong NLP. Một số loại phương pháp tổng quát bao gồm các kỹ thuật dựa trên quy tắc sử dụng các biến đổi dựa trên quy tắc được xác định trước như thay thế từ đồng nghĩa không phụ thuộc vào bất kỳ kiến trúc mô hình nào (Feng et al., 2021). Các phương pháp ví dụ bao gồm EDA. Các kỹ thuật dựa trên mô hình sử dụng mô hình hóa ngôn ngữ để tạo dữ liệu mới thông qua các phương tiện như mô hình dịch seq2seq như trong dịch ngược (Sennrich et al., 2016), mô hình hóa ngôn ngữ có mặt nạ sử dụng transformer trên các đầu vào được mặt nạ ngẫu nhiên (Garg và Ramakrishnan, 2020), hoặc sử dụng các mô hình sinh như GPT-2 như trong Anaby-Tavor et al. (2020) nơi một mô hình sinh có điều kiện nhãn được thu được bằng cách tinh chỉnh GPT-2 (Radford et al., 2019).

Mặc dù được sử dụng rộng rãi trong thị giác máy tính, DA không được sử dụng phổ biến trong huấn luyện các mô hình NLP, phần lớn do bản chất rời rạc của ngôn ngữ khiến việc áp dụng nhiễu loạn mà không làm tổn hại đến ý nghĩa trở nên khó khăn, và sự không nhất quán về hiệu suất của các kỹ thuật khác nhau (Feng et al., 2021). Hiệu quả của DA trên các mô hình được tinh chỉnh đã được nghiên cứu trước đây. (Longpre et al., 2020) mô tả cách BT và EDA không thể tạo ra lợi ích nhất quán cho các tác vụ phân loại với các mô hình dựa trên transformer. Tương tự, (Okimura et al., 2022) mở rộng nghiên cứu trước đây này và kiểm tra tác động của 12 phương pháp DA khác nhau và thấy ít lợi ích khi huấn luyện trên các tập dữ liệu với hàng nghìn ví dụ, nhưng có một số cải thiện về hiệu suất với dữ liệu rất hạn chế (chỉ vài trăm trường hợp huấn luyện). Nghiên cứu của chúng tôi tiến hành một kiểm tra tương tự về hiệu quả của tăng cường dữ liệu với các mô hình được huấn luyện trước, tuy nhiên chúng tôi tập trung vào điều chỉnh tiền tố và LoRA, và chúng tôi kiểm tra cách các thuộc tính của điều chỉnh tiền tố dưới DA khác với tinh chỉnh và tác động thực tế của điều này, đặc biệt về mặt biểu diễn câu.

3 Tăng cường Dữ liệu với Điều chỉnh Hiệu quả Tham số

Cách tiếp cận Điều chỉnh Tiền tố. Chúng tôi đầu tiên thí nghiệm với điều chỉnh tiền tố, và dựa cách tiếp cận của chúng tôi trên việc triển khai P-tuning v2 (Liu et al., 2021). Bằng cách tối ưu hóa độ dài tiền tố, áp dụng tham số hóa lại một cách có chọn lọc, và điều chỉnh một đầu phân loại được khởi tạo ngẫu nhiên trên đầu các biểu diễn câu transformer, P-tuning v2 có thể được áp dụng cho các mô hình ngôn ngữ nhỏ hơn và trên nhiều tác vụ, bao gồm phân loại, mà không giảm hiệu suất so với tinh chỉnh. P-tuning v2 hoạt động bằng cách thêm các prompt có độ dài p token vào tất cả các lớp của mô hình ngôn ngữ dưới dạng các chuỗi token tiền tố liên tục. Các embedding liên tục này, được biểu diễn bởi vector Hm = [h0, ..., hp] nơi mỗi hi ∈ Rd có chiều của các token embedding d cho mỗi lớp m trong mô hình dựa trên transformer, được đặt trước các embedding của mỗi lớp transformer Em = [ECLS, E1, ..., En] nơi n là độ dài chuỗi tối đa. Do đó, mỗi lớp của mô hình ngôn ngữ có thể chú ý đến các prompt một cách độc lập. Các tham số mô hình ngôn ngữ tổng thể vẫn bị đông cứng trong quá trình huấn luyện, chỉ có các tham số của các tiền tố và đầu tuyến tính cho lớp phân loại được tối ưu hóa. Các tiền tố có thể tùy chọn được truyền vào một bộ mã hóa tham số hóa lại như MLP (Li và Liang, 2021), nhưng điều này không phải lúc nào cũng hiệu quả và do đó chúng tôi chỉ áp dụng có chọn lọc trong một số trường hợp nhất định mà chúng tôi thấy nó cải thiện hiệu suất như trong Liu et al. (2021).

LoRA. Chúng tôi kiểm tra LoRA (Hu et al., 2021), một kỹ thuật tương tự đông cứng các trọng số transformer gốc, nhưng chỉ điều chỉnh các cặp ma trận phân rã hạng có thể huấn luyện được chèn vào mỗi lớp transformer để xấp xỉ các cập nhật trọng số, giảm đáng kể số lượng tham số cần thiết bằng cách tránh cập nhật trọng số lớp đầy đủ trong khi không tăng chi phí suy luận. Thay vì cập nhật ma trận trọng số được huấn luyện trước của transformer W0 ∈ Rd×k với cập nhật trọng số dựa trên gradient ΔW cho bước thời gian t để có ma trận trọng số mới như trong Wt = W0 + ΔWt, LoRA thực hiện phân rã hạng thấp của việc cập nhật thành hai ma trận WB ∈ Rd×r và WA ∈ Rr×k hoạt động như các tham số có thể học để biểu diễn cập nhật mới là Wt = WBWA + W0, với W0 bị đông cứng và nơi r biểu diễn hạng của việc phân rã. Các tác giả thấy rằng việc áp dụng LoRA cho các ma trận chiếu truy vấn và giá trị trong cơ chế chú ý dẫn đến hiệu suất tối ưu nhất. LoRA thường vượt trội hơn các phương pháp PET khác, khiến nó xứng đáng được nghiên cứu trong bối cảnh này (He et al., 2022).

Phương pháp Tăng cường Dữ liệu. Trong nghiên cứu này, chúng tôi tập trung vào tăng cường dữ liệu không phụ thuộc vào tác vụ, là các phương pháp có thể áp dụng rộng rãi cho nhiều tác vụ NLP khác nhau. Nhiều phương pháp DA phổ biến tồn tại và trong số này, chúng tôi sử dụng: (1) Tăng cường Dữ liệu Dễ dàng (EDA) (Wei và Zou, 2019), một kỹ thuật nơi các câu được tăng cường được tạo ra bằng cách áp dụng một số thao tác chỉnh sửa văn bản dựa trên quy tắc; (2) Dịch Ngược (BT) (Sennrich et al., 2016) nơi dữ liệu được tăng cường được tạo ra bằng cách dịch văn bản sang ngôn ngữ đích rồi dịch ngược lại ngôn ngữ gốc; (3) Mixup cho Phân loại Câu (Guo et al., 2019a), nơi chúng tôi sử dụng cách tiếp cận senMixup bằng cách tạo dữ liệu tổng hợp thông qua nội suy trên các token phân loại của các cặp câu ngẫu nhiên. Tất cả những điều này đã thể hiện khả năng cải thiện độ chính xác mô hình cho dữ liệu hạn chế (Wei và Zou, 2019; Guo, 2020; Feng et al., 2021; Fabbri et al., 2020) trong khi có chi phí triển khai thấp.

4 Thiết lập Thí nghiệm

Chúng tôi chủ yếu tập trung vào các tập dữ liệu nhỏ với ít hơn vài nghìn điểm dữ liệu có chú thích, vì dữ liệu hạn chế tạo ra thách thức trong việc học các mô hình có thể tổng quát hóa và do đó là trường hợp sử dụng phổ biến cho DA. Các công trình trước đây đã chỉ ra DA với các mô hình ngôn ngữ được huấn luyện trước có xu hướng phần lớn không hiệu quả đối với các tập dữ liệu lớn hơn (Okimura et al., 2022).

Chúng tôi kiểm tra trên năm tập dữ liệu phân loại văn bản. Bốn tập từ benchmark SuperGLUE (Wang et al., 2019), bao gồm RTE (Dagan et al., 2006; Bar Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009), CB (De Marneffe et al., 2019), COPA (Roemmele et al., 2011), và WSC (Levesque et al., 2011). Đây là các tập dữ liệu nhỏ nhất trong benchmark với chỉ 2500, 250, 400, 554 mẫu huấn luyện tương ứng. Chúng nắm bắt một phạm vi độ khó, và bao gồm các vấn đề đa dạng như quan hệ văn bản, giải quyết đồng tham chiếu dựa trên lý luận thường thức, xác định nguyên nhân hoặc hậu quả, và cam kết mệnh đề. Để nắm bắt hiệu suất trên tác vụ phân tích cảm xúc câu đơn đơn giản hơn, chúng tôi cũng sử dụng một tập con được lấy mẫu giảm của SST-2 (Socher et al., 2013), bao gồm 400 mẫu huấn luyện và 100 câu xác thực. Chúng tôi thí nghiệm với BERT-base (Devlin et al., 2019) và RoBERTa-large (Liu et al., 2019), có 110 triệu và 355 triệu tham số tương ứng. So với các mô hình lớn hơn, kích thước của chúng làm cho chúng phù hợp khi có lo ngại về lưu trữ.

Mỗi mô hình được huấn luyện đến khi hội tụ và chúng tôi báo cáo kết quả tại epoch mà độ chính xác xác thực cao nhất được đạt. Chúng tôi cung cấp các cài đặt huấn luyện chi tiết cho các mô hình của chúng tôi trong Phụ lục A. Dưới đây chúng tôi mô tả các cài đặt cho mỗi phương pháp tăng cường dữ liệu:

EDA: Chúng tôi áp dụng sự kết hợp của các thao tác thay thế từ đồng nghĩa, hoán đổi ngẫu nhiên, chèn ngẫu nhiên và xóa ngẫu nhiên cho một tỷ lệ nhất định các từ trong một câu để tạo ra nhiều câu được tăng cường cho mỗi câu gốc. Đối với số lượng câu được tăng cường được tạo ra, và tỷ lệ từ bị ảnh hưởng, chúng tôi tuân theo các hướng dẫn sử dụng được khuyến nghị bởi Wei và Zou (2019) phụ thuộc vào kích thước của tập huấn luyện. 16 câu được tăng cường cho mỗi câu gốc được tạo ra cho các tập dữ liệu nhỏ nhất; CB, COPA, WSC, và SST-2 vì chúng chỉ chứa vài trăm mẫu huấn luyện. Tỷ lệ từ trong văn bản gốc bị ảnh hưởng cho mỗi trong 4 thao tác là 5% (α = 0.05). 8 câu được tạo ra cho mỗi câu gốc cho tập huấn luyện RTE, với cùng tỷ lệ từ bị ảnh hưởng như các tập dữ liệu đã nói trên.

BT: Đối với việc triển khai của chúng tôi, chúng tôi dịch ngược các câu sử dụng một loạt các mô hình dịch từ tiếng Anh sang ngôn ngữ đích và ngôn ngữ đích sang tiếng Anh cho 4 ngôn ngữ phổ biến: Pháp, Tây Ban Nha, Đức và Trung Quốc. Các mô hình cụ thể chúng tôi sử dụng là các mô-đun dịch Helsinki NLP Opus (Tiedemann, 2020). Những ngôn ngữ này được chọn do lượng lớn dữ liệu song song có sẵn để huấn luyện các mô hình ngôn ngữ tương ứng, mang lại các bản dịch chất lượng cao hơn có thể bảo tồn ngữ nghĩa của câu gốc tốt hơn trong khi vẫn giới thiệu một số đa dạng.

Mixup: Được truyền cảm hứng bởi Mixup trong phân loại hình ảnh (Zhang et al., 2018; Guo et al., 2019b), nơi các cặp hình ảnh đầu vào ngẫu nhiên và nhãn của chúng được nội suy tuyến tính để giúp tạo ra hình ảnh tổng hợp, Mixup có thể được áp dụng tương tự trên các embedding cho văn bản. Như trong Guo et al. (2019a), chúng tôi điều chỉnh Mixup cho phân loại văn bản bằng cách nội suy trên các embedding câu (senMixup). Trong một mini batch có kích thước N, chúng tôi lấy cùng số cặp văn bản đầu vào ngẫu nhiên, và nội suy trên các token phân loại ([CLS]) d chiều (768 trong trường hợp của BERT-base và 1024 cho RoBERTa-large) của lớp ẩn cuối cùng của bộ mã hóa transformer được tạo ra sau khi mỗi đầu vào được đưa vào transformer. Token được nội suy sau đó được truyền vào một lớp được kết nối đầy đủ để tạo ra vector dự đoán softmax cuối cùng. Việc nội suy cho một cặp token [CLS] cho trước (xi, xj) với các vector nhãn one hot tương ứng (yi, yj), cho các đầu vào i và j được thực hiện như sau:

x̃ij = λxi + (1-λ)xj, (1)
ỹij = λyi + (1-λ)yj, (2)

dẫn đến các vector được nội suy x̃ij và ỹij. Mixup được tham số hóa bởi tỷ lệ pha trộn λ, khác nhau cho mỗi cặp, và được thu được bằng cách lấy mẫu từ phân phối Beta(α, α) với siêu tham số α = 1.0, tương ứng với phân phối đồng đều. Đây là cài đặt được khuyến nghị trong Guo et al. (2019a) và do đó chúng tôi cũng sử dụng giá trị này. Mixup được thực hiện theo cách tương tự cho điều chỉnh tiền tố, ngoại trừ chúng tôi sử dụng phiên bản được gộp của token phân loại (tức là một phiên bản đã đi qua lớp tuyến tính và kích hoạt tanh).

Thủ tục cho Tăng cường: Để đơn giản, vì hầu hết các tập dữ liệu sử dụng nhiều câu/từ đầu vào cho mỗi mẫu huấn luyện (ví dụ: tiền đề và giả thuyết), chúng tôi áp dụng các phương pháp DA tĩnh trên đầu vào chính (đầu tiên), là tiền đề cho RTE, CB, và COPA, mặc dù chúng tôi sử dụng câu đầy đủ cho WSC và SST2.

5 Kết quả Thí nghiệm và Phân tích

5.1 Tăng cường Dữ liệu với PET

Bảng 1 hiển thị kết quả chính của chúng tôi. Các phương pháp DA đạt được hiệu suất tốt nhất trên mỗi tập dữ liệu và loại mô hình thay đổi rất nhiều. Một số cải thiện hiệu suất mạnh có thể được thấy khi sử dụng DA với P-tuning v2, rõ ràng nhất được thấy khi sử dụng BT với BERT trên RTE, CB, và COPA. Các trường hợp tương tự tồn tại với LoRA sử dụng Mixup trên RTE với RoBERTa, và BT trên BERT với CB. Tuy nhiên, mặc dù có những trường hợp hiệu suất tích cực, sự suy giảm thường xuyên về độ chính xác có thể được thấy trong hầu hết các trường hợp từ việc sử dụng DA, đặc biệt với các mô hình RoBERTa lớn hơn, và trên một số tập dữ liệu nhất định như RTE với P-tuning v2 và COPA với LoRA. EDA đặc biệt có xu hướng hoạt động kém khi kết hợp với các phương pháp PET. WSC thấy cải thiện với EDA, nhưng những mô hình này phần lớn không có khả năng học dữ liệu một cách thích hợp, vì vậy bất kỳ lợi ích nào cũng có thể là giả tạo.

Quan trọng là phải chú ý đến cách phương pháp hoạt động tốt nhất thường khác nhau giữa tinh chỉnh, điều chỉnh tiền tố và LoRA, và hiệu suất của mỗi phương pháp DA có thể thay đổi đáng kể giữa chúng như được thấy với BT trên COPA giữa các phiên bản tinh chỉnh và điều chỉnh tiền tố của BERT, do đó những gì hoạt động cho tinh chỉnh không thể được giả định sẽ hoạt động cho các phương pháp PET khác nhau. Với những kết quả này, chúng tôi không thể khuyến nghị phổ quát khi sử dụng DA với điều chỉnh tiền tố hoặc LoRA với dữ liệu hạn chế, mặc dù với việc lựa chọn cẩn thận, lợi ích vẫn có thể được thu được.

5.2 Phân tích Embedding

Hiệu suất kém của EDA và BT trên nhiều tình huống, đặc biệt với P-tuning v2 thúc đẩy nghiên cứu thêm về cách điều chỉnh tiền tố học biểu diễn câu của và dưới dữ liệu được tăng cường để xác định bất kỳ vấn đề tiềm ẩn nào dẫn đến hiệu suất kém. Để làm điều này, chúng tôi áp dụng t-SNE (van der Maaten và Hinton, 2008) để trực quan hóa và hiểu các embedding câu không gian tiềm ẩn giữa các phiên bản tinh chỉnh và P-tuning v2 của BERT và RoBERTa trên cả hai tập dữ liệu RTE và CB nơi chúng tôi ban đầu quan sát sự khác biệt rõ rệt về hiệu suất của DA, đặc biệt trên RTE vì có sự phân chia lớn giữa nơi DA hoạt động tốt (BERT được tinh chỉnh) so với không tốt (RoBERTa điều chỉnh tiền tố). Chúng tôi vẽ biểu diễn 2-D của token [CLS] trong lớp ẩn cuối cùng. Hình 1 hiển thị các hình ảnh nơi chúng tôi cho thấy các biểu diễn được học khi huấn luyện trên dữ liệu sạch và kiểm tra trên dữ liệu xác thực được tăng cường được tăng cường theo cách tương tự như dữ liệu huấn luyện. Chúng tôi sử dụng EDA, BT, và phương pháp tham nhũng nặng được mô tả dưới đây trong Phần 5.3, cùng với đường cơ sở không sử dụng DA. Thông qua điều này, chúng tôi có thể kiểm tra mỗi phương pháp xử lý dữ liệu được tăng cường không quen thuộc tốt như thế nào, và liệu dữ liệu được tăng cường có được biểu diễn tương tự như dữ liệu gốc hay không. Hình 2 hiển thị một phong cách khác của các biểu diễn được tạo ra từ việc huấn luyện trên dữ liệu được tăng cường và kiểm tra trên dữ liệu xác thực sạch. Điều này có thể cho thấy việc huấn luyện với DA ảnh hưởng đến việc mô hình học biểu diễn giữa các loại dữ liệu khác nhau như thế nào. Trong cả hai hình, chúng tôi quan sát cùng xu hướng tổng quát giữa tinh chỉnh và điều chỉnh tiền tố, bất kể loại mô hình và tập dữ liệu. Mặc dù một số mô hình như P-tuning v2 RoBERTa có hiệu suất dự đoán mạnh hơn so với các đối tác được tinh chỉnh của chúng với BERT, có sự thiếu phân cụm riêng biệt đáng chú ý giữa các mẫu lớp của các lớp khác nhau. Các biểu diễn câu từ các lớp khác nhau của dữ liệu được tăng cường ít tách biệt hơn. Khi được huấn luyện trên dữ liệu sạch, các biểu diễn của dữ liệu xác thực được tăng cường cũng lộn xộn hơn và ít tách biệt hơn trong không gian biểu diễn. Ngoài ra, khi được huấn luyện bằng DA, việc phân cụm trong các mô hình BERT được tinh chỉnh rõ ràng hơn, đặc biệt đối với EDA và BT nơi P-tuning gặp khó khăn. Ngay cả khi không có tăng cường và khi sử dụng Mixup, sự khác biệt về phân cụm vẫn tồn tại. Những hình ảnh này chứng minh rằng có thể có khó khăn với cách điều chỉnh tiền tố có thể xử lý dữ liệu được tăng cường. Điều chỉnh tiền tố dường như ít bền vững hơn đối với các phương pháp tăng cường như EDA có thể thay đổi ý nghĩa của dữ liệu gốc, có thể tạo ra thách thức huấn luyện.

5.3 Ảnh hưởng của Dữ liệu Bị Nhiễu loạn Nặng

Xem xét hiệu suất kém tổng thể của điều chỉnh tiền tố với EDA, và cách nó có vấn đề với việc tách biệt các biểu diễn câu, chúng tôi chạy thí nghiệm để xác nhận rằng điều chỉnh tiền tố gặp khó khăn hơn với dữ liệu được tăng cường bị nhiễu loạn cao so với dữ liệu gốc. Để mô phỏng tình huống dữ liệu bị thay đổi nặng này, chúng tôi sử dụng tất cả bốn thao tác EDA để sửa đổi đến 50% câu với mỗi thao tác, và tạo ra tám câu cho mỗi câu gốc trên RTE, CB, COPA, và SST2, và chúng tôi so sánh hiệu suất xác thực tốt nhất của mỗi phương pháp huấn luyện. Sự suy giảm hiệu suất có thể được mong đợi vì mô hình nên gặp khó khăn hơn trong việc tổng quát hóa khi học từ dữ liệu phần lớn không mạch lạc, nhiễu như được ghi chú trong (Wei và Zou, 2019). Như Bảng 2 cho thấy, điều chỉnh tiền tố thường không thể đối phó cũng như tinh chỉnh khi được huấn luyện trên dữ liệu này nhưng thường tự tin hơn. Một lời giải thích có thể cho hiện tượng này là vì các tham số của các mô hình ngôn ngữ bị đông cứng, số lượng tham số có thể huấn luyện thấp hơn có thể dễ dàng hơn trong việc overfitting với nhiễu trong dữ liệu được tăng cường, điều này giải thích entropy softmax thấp/độ tin cậy dự đoán cao. Trên thực tế, những kết quả này báo hiệu tầm quan trọng của việc lựa chọn các phương pháp tăng cường dữ liệu có thể bảo tồn ý nghĩa và cấu trúc của dữ liệu huấn luyện gốc nhưng vẫn cung cấp đa dạng từ vựng.

5.4 Phân tích Tương đồng

Để chính thức hóa phân tích định tính được cung cấp trong Phần 5.2 với kết quả định lượng và mang lại hiểu biết thêm về kết quả của chúng tôi trong Phần 5.3, chúng tôi chạy thí nghiệm bổ sung so sánh độ tương đồng cosine trung bình giữa các embedding câu được tạo ra bởi điều chỉnh tiền tố và tinh chỉnh. Đặc biệt, chúng tôi so sánh các phiên bản gốc và bị tham nhũng nặng của các câu. Đối với điều này, chúng tôi huấn luyện các phiên bản tinh chỉnh và P-tuning v2 của BERT và RoBERTa trên dữ liệu sạch của các tập dữ liệu RTE và CB, và đánh giá trên xác thực bị tham nhũng nặng được xây dựng theo cách tương tự như được mô tả trong Phần 5.3. Chúng tôi tính toán độ tương đồng cosine giữa các embedding câu của các câu gốc và bị thay đổi và tính trung bình trên toàn bộ tập dữ liệu. Chúng tôi sử dụng cả các embedding câu [CLS] như trước đây, và biểu diễn câu trung bình thu được bằng cách tính trung bình tất cả các token trong trạng thái ẩn cuối cùng. Để có ý tưởng về độ tương đồng cosine lý tưởng, chúng tôi cũng bao gồm độ tương đồng trung bình thu được bằng cách sử dụng một mô hình được điều chỉnh cụ thể để đo lường độ tương đồng câu; Sentence Transformer all-MiniLM-L6-v2 (Reimers và Gurevych, 2019). Chúng tôi vẽ biểu đồ kết quả của mình, có thể được thấy trong Hình 3. Chúng tôi tính trung bình kết quả của mình trên 3 lần chạy và tính độ lệch chuẩn. Chúng tôi phát hiện ra rằng điều chỉnh tiền tố xuất ra độ tương đồng cực kỳ cao mặc dù dữ liệu bị tham nhũng nặng khi so sánh với tinh chỉnh, trên cả hai loại biểu diễn. Trong hầu hết các trường hợp, tinh chỉnh gần với Sentence Transformer hơn nhiều, và do đó cho thấy khả năng phân biệt lớn giữa các khác biệt về ngữ nghĩa giữa hai đầu vào. Điều này báo hiệu rằng điều chỉnh tiền tố cần khả năng lớn hơn để có thể phân biệt giữa dữ liệu khác nhau, có thể là chìa khóa để cải thiện hiệu suất của nó trên dữ liệu được tăng cường.

5.5 Lợi ích của Mất mát Tương phản

Với kết quả trong Phần 5.4, tự nhiên phải tự hỏi liệu có thể cải thiện hiệu suất của DA với điều chỉnh tiền tố bằng cách sử dụng một phương pháp có thể thúc đẩy các cụm được xác định rõ hơn và sự khác biệt lớn hơn giữa các đầu vào khác nhau về ngữ nghĩa hay không. Chúng tôi nghiên cứu điều này bằng cách thêm một số hạng mất mát tương phản trong khi huấn luyện P-tuning v2. Chúng tôi thường áp dụng một phiên bản của mất mát NT-Xent được đề xuất trong (Oord et al., 2018). Chúng tôi điều chỉnh phương pháp của họ cho tác vụ này bằng cách tạo các mẫu tích cực trong một batch thông qua việc lấy mẫu các cặp đầu vào với cùng lớp, và tạo các mẫu tiêu cực bằng cách lấy mẫu các cặp của các lớp khác nhau. Cụ thể hơn, với một mini batch có kích thước N, chúng tôi tạo ra cặp tích cực thứ i Ai = (ai, âi) trong số N với lớp k, bằng cách lấy mẫu ngẫu nhiên hai đầu vào với cùng nhãn lớp và sử dụng biểu diễn [CLS] của chúng. Chúng tôi tạo ra hai cặp tiêu cực Bi = (ai, b̂i) và Ci = (bi, âi) theo cách tương tự nơi hai đầu vào được lấy mẫu ngẫu nhiên b và b̂ không có cùng nhãn lớp với cặp tích cực. Ba cặp này được sử dụng trong phương trình sau cho mất mát tương phản:

L = -1/N ∑(i=1 to N) log(e^(sim(ai,âi)/τ) / (e^(sim(ai,âi)/τ) + e^(sim(ai,b̂i)/τ) + e^(sim(âi,bi)/τ)))

nơi sim() là một thước đo tương đồng cho các biểu diễn, mà chúng tôi sử dụng độ tương đồng cosine. Chúng tôi thấy rằng việc sử dụng tham số nhiệt độ cao τ = 0.9 cho kết quả tốt nhất. Chúng tôi cũng chia tỷ lệ mất mát bổ sung này bằng một tham số λcon để tránh quá nhiều thiên vị đối với mất mát này, mà chúng tôi thay đổi cho mỗi mô hình. Ngoài ra, chúng tôi sử dụng độ tương đồng cosine được tạo ra bởi Sentence Transformer all-MiniLM-L6-v2 giữa các mẫu huấn luyện gốc và được tăng cường để cân bằng các giá trị mất mát entropy chéo để ưu tiên học các đầu vào tương tự về ngữ nghĩa hơn.

Bảng 3 hiển thị kết quả khi chúng tôi áp dụng những số hạng mất mát bổ sung này cho việc huấn luyện các mô hình P-tuning v2 BERT và RoBERTa trên RTE, CB, COPA, và SST2 sử dụng cả EDA và BT. Chúng tôi thường quan sát sự gia tăng độ chính xác khi thêm số hạng tương phản vào việc huấn luyện với DA, đặc biệt với EDA, và trong các trường hợp không có cải thiện hiệu suất, kết quả vẫn tương tự. Điều này báo hiệu cách các phương pháp tương phản có thể là chìa khóa để có được hiệu suất tốt khi sử dụng DA với điều chỉnh tiền tố. Chúng tôi thấy rằng trong một số trường hợp, sự gia tăng quan sát được không đủ để tăng độ chính xác vượt quá mô hình được huấn luyện mà không có DA, vì vậy trong những trường hợp này, những kỹ thuật DA này phần lớn vốn dĩ quá không hiệu quả cho tác vụ cụ thể đó.

5.6 Biểu diễn Mất mát Tương phản

Như trong Phần 5.2, chúng tôi phân tích định tính các biểu diễn của các mô hình được huấn luyện sử dụng mất mát tương phản khi chúng được huấn luyện trên dữ liệu được tăng cường. Hình 4 cho thấy cách việc thêm số hạng mất mát tương phản không chỉ giúp độ chính xác của việc tăng cường P-tuning v2 RoBERTa trên CB với EDA, mà còn học các biểu diễn cho dữ liệu xác thực được tăng cường có phân cụm rõ ràng hơn, đặc biệt với BT và dữ liệu xác thực không được tăng cường so với chỉ sử dụng mất mát entropy chéo thông thường, cho thấy cách phương pháp có thể giúp tạo ra điều chỉnh tiền tố để học các biểu diễn hữu ích hơn cho dữ liệu được tăng cường. Phương pháp tương phản của chúng tôi khá đơn giản, và không đặc biệt phù hợp cho việc học có giám sát. Chúng tôi tin rằng việc khám phá các hàm mất mát phù hợp hơn như Center Loss (Wen et al., 2016) có thể cho thấy kết quả hứa hẹn hơn nữa, mà công việc tương lai có thể khám phá.

6 Kết luận

Chúng tôi tiết lộ cách khi dữ liệu huấn luyện hạn chế có sẵn, tăng cường dữ liệu có thể cung cấp những cải thiện quan trọng về độ chính xác khi huấn luyện các mô hình phân loại sử dụng phương pháp PET, mặc dù lợi ích không phải là phổ quát, và hạn chế tồn tại khi sử dụng một số phương pháp nhất định. Chúng tôi cũng chứng minh cách điều chỉnh tiền tố có thể gặp khó khăn hơn trong việc học biểu diễn câu của dữ liệu được tăng cường. Chúng tôi tiếp tục cho thấy rằng học tương phản có thể là một giải pháp cho những vấn đề này, và đề xuất rằng cần thực hiện thêm công việc để tìm các phương pháp tương tự có thể tổng quát hóa hơn.

Hạn chế

Mặc dù chúng tôi trình bày kết quả của mình trên nhiều tập dữ liệu và mô hình, chúng tôi phần lớn tuân thủ các tác vụ hiểu ngôn ngữ tự nhiên. Mức độ hiệu quả của các phương pháp tăng cường trên các tác vụ liên quan đến sinh cần nghiên cứu thêm.

Ngoài ra, một hạn chế khác là chúng tôi không nghiên cứu mức độ nhiễu loạn cần thiết để có tác động tiêu cực đến điều chỉnh tiền tố. Biết điều này có thể làm sáng tỏ những loại biến đổi cụ thể nào là vấn đề đối với điều chỉnh tiền tố để chúng có thể được tránh. Giả thuyết của chúng tôi ở đây là các mức nhiễu loạn như vậy nhạy cảm với nhiều yếu tố trong quá trình huấn luyện, chẳng hạn như độ khó của tác vụ và đặc điểm của các cách tiếp cận tăng cường dữ liệu được áp dụng, có thể khó được định lượng.

Tuyên bố Đạo đức

Bất kỳ loại kỹ thuật nào mà dữ liệu văn bản tổng hợp được tạo ra theo cách tự động, đặc biệt với các kỹ thuật tăng cường như BT và EDA có thể thêm hoặc loại bỏ từ ngẫu nhiên hoặc diễn đạt lại câu hoàn toàn, có thể thay đổi ý nghĩa hoặc cách giải thích ban đầu của một câu. Điều này có một số tiềm năng để đưa thêm những thiên vị bất ngờ vào dữ liệu huấn luyện, đặc biệt khi các mô hình thiên vị được sử dụng để tạo ra dữ liệu tổng hợp (ví dụ: một mô hình dịch thiên vị chủng tộc). Ngay cả với hiệu suất được cải thiện, những thiên vị này có thể khiến các mô hình đưa ra những phán đoán không công bằng, có thể trở thành mối quan tâm lớn trong các lĩnh vực quan trọng về an toàn như trong lĩnh vực pháp lý hoặc y tế. Hậu quả là, trước khi bất kỳ kỹ thuật tăng cường dữ liệu nào được áp dụng cho các kỹ thuật PET, phải có sự xem xét về những thiên vị cơ bản có thể được đưa vào thông qua các phương pháp tạo ra dữ liệu tổng hợp.

Lời cảm ơn

Chúng tôi muốn cảm ơn các nhà đánh giá ẩn danh đã cung cấp phản hồi có giá trị để hoàn thiện bài báo. Công việc này được hỗ trợ bởi Học bổng Động lực Kỹ thuật và Công nghệ Bản địa và Da đen (IBET) và Tài trợ Khám phá NSERC [RGPIN-2018-06415].

Tài liệu tham khảo

[Danh sách tài liệu tham khảo được giữ nguyên vì chúng là tên riêng và trích dẫn học thuật]

A Cài đặt Huấn luyện và Siêu tham số

Trong phần này, chúng tôi cung cấp chi tiết về các cài đặt huấn luyện chung chúng tôi sử dụng cùng với các siêu tham số. Các siêu tham số lý tưởng cho mỗi loại mô hình đã được điều chỉnh rất cẩn thận bằng cách sử dụng tìm kiếm ngẫu nhiên với điều chỉnh thủ công bổ sung, và phần lớn tuân theo các khuyến nghị trong Mosbach et al. (2021) để đạt được hiệu suất ổn định, cao với tinh chỉnh và LoRA. Tương tự, chúng tôi thường sử dụng các cài đặt siêu tham số tương tự như trong Liu et al. (2021) để huấn luyện P-tuning v2 trên các tập dữ liệu SuperGLUE, vì các tác giả quản lý để đạt được kết quả vững chắc với các cài đặt của họ, mặc dù các mô hình của chúng tôi vẫn yêu cầu điều chỉnh bổ sung trong hầu hết các trường hợp vì các phương pháp của chúng tôi khác với phạm vi ban đầu của họ khi chúng tôi kết hợp DA.

Các cài đặt chung trên tất cả các mô hình và tập dữ liệu bao gồm độ dài chuỗi tối đa của tokenizer được đặt là 128 token, ngoại trừ WSC và SST-2 được giới hạn ở 64. Chúng tôi sử dụng bộ tối ưu hóa AdamW (Loshchilov và Hutter, 2019) cho tất cả các thí nghiệm, với bộ lập lịch tuyến tính có khởi động. Đối với các mô hình BERT, chúng tôi sử dụng giá trị cắt gradient 1.0. Chúng tôi thường chọn kích thước batch giữa 16 hoặc 32. Chúng tôi huấn luyện mỗi mô hình sử dụng GPU NVIDIA RTX-3090 (24GB) với việc triển khai của chúng tôi cho các mô hình cơ sở dựa trên HuggingFace Transformers (Wolf et al., 2019). Chúng tôi sử dụng thư viện Sentence-Transformers (Reimers và Gurevych, 2019).

Cài đặt Tinh chỉnh: Các cài đặt cụ thể cho các mô hình được tinh chỉnh như sau: trên tất cả các mô hình được tinh chỉnh, chúng tôi sử dụng tỷ lệ khởi động 10%. Đối với BERT, chúng tôi thay đổi tỷ lệ học từ 1e-5 và 5e-5 tùy thuộc vào tập dữ liệu. CB sử dụng 5e-5 ví dụ, mặc dù tỷ lệ lý tưởng cho các tập dữ liệu khác có thể thay đổi với 2e-5 cho SST-2. Kích thước batch tốt nhất thay đổi giữa 16 và 32, mặc dù thường giá trị 16 hoạt động tốt hơn. Đối với RoBERTa, chúng tôi sử dụng tỷ lệ học 1e-5 hoặc 2e-5 và kích thước batch 16 để đạt được hiệu suất ổn định trên tất cả các tập dữ liệu và phương pháp tăng cường. Số epoch huấn luyện chúng tôi chọn phụ thuộc vào khi mô hình bắt đầu hội tụ. Đối với EDA, điều này thường rơi vào khoảng 2-4 epoch cho tất cả các tập dữ liệu, trong khi đối với BT là 4-8. Đối với Mixup và huấn luyện thông thường, các epoch huấn luyện trong khoảng 8-12, mặc dù RTE thường chỉ cần 5-7 epoch.

Cài đặt P-tuning v2: Các siêu tham số lý tưởng cho P-tuning v2 thay đổi mạnh giữa tập dữ liệu được chọn, phương pháp tăng cường và loại mô hình, vì vậy để tiết kiệm không gian, chúng tôi chỉ bao gồm các phạm vi mà chúng tôi điều chỉnh các siêu tham số. Chúng tôi thường giữ tỷ lệ học giữa 5e-3 đến 5e-2, với các mô hình được huấn luyện với phương pháp tăng cường thường yêu cầu tỷ lệ thấp hơn từ 7e-3 đến 1e-2. Các mô hình không được tăng cường hoạt động tốt nhất giữa 1e-2 đến 5e-2. Kích thước batch lý tưởng chủ yếu là 16 mặc dù 32 hiệu quả hơn trên các tập dữ liệu như RTE. Độ dài chuỗi tiền tố được giữ ngắn, thường giữa 4 đến 32 token. Tham số hóa lại tiền tố được sử dụng trên hầu hết các tập dữ liệu, và hoạt động đặc biệt tốt trên CB và SST-2. Xác suất dropout ẩn được đặt nhất quán ở 0.1. Tương tự, kích thước ẩn tiền tố được giữ nhất quán ở 512. Chúng tôi không sử dụng khởi động cho các mô hình tiền tố. Số epoch huấn luyện để đặt thường rơi vào khoảng 10-25 cho EDA, 20-40 cho BT, và cho Mixup và huấn luyện thông thường 50-120, với số chính xác phụ thuộc vào khi mô hình hội tụ đến 100% độ chính xác huấn luyện. Tham số λcon chúng tôi sử dụng khi huấn luyện với mất mát tương phản được đặt giữa 0.1 và 0.3, với hầu hết các mô hình sử dụng giá trị 0.2.

Cài đặt LoRA: Trong nhiều trường hợp, các cài đặt của chúng tôi để huấn luyện các biến thể LoRA của các mô hình tương tự như những cài đặt được mô tả cho tinh chỉnh, mặc dù thường LoRA yêu cầu thời gian huấn luyện ngắn hơn. Về các tham số cụ thể của LoRA, hạng r và tham số chia tỷ lệ tham số hóa lại LoRA α, chúng tôi phản ánh các cài đặt cho BERT-base và RoBERTa-large trong bài báo gốc của Hu et al. (2021) với r = 8, α = 8 và r = 8, α = 16 cho mỗi loại mô hình tương ứng. Chúng tôi sử dụng thư viện adapter-transformers (Pfeiffer et al., 2020) để triển khai LoRA.

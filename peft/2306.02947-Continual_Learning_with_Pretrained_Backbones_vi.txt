# 2306.02947.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2306.02947.pdf
# Kích thước tệp: 1392744 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Học Liên Tục với Backbone Được Tiền Huấn Luyện
bằng Tinh Chỉnh trong Không Gian Đầu Vào
Simone Marullo∗†
∗DINFO
Đại học Florence
Florence, Italy
simone.marullo@unifi.itMatteo Tiezzi†
†DIISM
Đại học Siena
Siena, Italy
matteo.tiezzi@unisi.itMarco Gori†‡
‡MAASAI
Đại học Côte d'Azur
Nice, France
marco.gori@unisi.it
Stefano Melacci†
†DIISM
Đại học Siena
Siena, Italy
mela@diism.unisi.itTinne Tuytelaars§
§ESAT
KU Leuven
Leuven, Belgium
tinne.tuytelaars@esat.kuleuven.be

Tóm tắt —Khó khăn nội tại trong việc thích ứng các mô hình học sâu với môi trường không ổn định giới hạn khả năng ứng dụng của mạng nơ-ron vào các tác vụ thực tế. Vấn đề này rất quan trọng trong các thiết lập học có giám sát thực tế, chẳng hạn như những trường hợp mà một mô hình được tiền huấn luyện tính toán các phép chiếu hướng tới không gian tiềm ẩn nơi các dự đoán tác vụ khác nhau được học tuần tự theo thời gian. Thực tế, việc tinh chỉnh gia tăng toàn bộ mô hình để thích ứng tốt hơn với các tác vụ mới thường dẫn đến quên thảm khốc, với hiệu suất giảm sút trên các kinh nghiệm trong quá khứ và mất kiến thức có giá trị từ giai đoạn tiền huấn luyện. Trong bài báo này, chúng tôi đề xuất một chiến lược mới để làm cho quy trình tinh chỉnh hiệu quả hơn, bằng cách tránh cập nhật phần được tiền huấn luyện của mạng và học không chỉ đầu phân loại thông thường, mà còn một tập hợp các tham số học được mới được giới thiệu có trách nhiệm biến đổi dữ liệu đầu vào. Quá trình này cho phép mạng tận dụng hiệu quả kiến thức tiền huấn luyện và tìm ra sự cân bằng tốt giữa tính dẻo và ổn định với nỗ lực tính toán khiêm tốn, do đó đặc biệt phù hợp cho các thiết lập trên edge. Các thí nghiệm của chúng tôi trên bốn bài toán phân loại hình ảnh trong thiết lập học liên tục xác nhận chất lượng của phương pháp được đề xuất khi so sánh với một số quy trình tinh chỉnh và các phương pháp học liên tục phổ biến.

Từ khóa chỉ mục —Học liên tục, mạng nơ-ron, mô hình prompt, tinh chỉnh, tinh chỉnh đầu vào, huấn luyện thân thiện.

I. GIỚI THIỆU

Hiệu suất xuất sắc đạt được bởi các giải pháp Học Máy trong nhiều lĩnh vực [1] và các tác vụ được định nghĩa rõ ràng [2] thường bị hạn chế trong một thiết lập rất cụ thể, nơi

Công trình này được hỗ trợ một phần bởi dự án PRIN 2017 RexLearn, được tài trợ bởi Bộ Giáo dục, Đại học và Nghiên cứu Italia (số cấp 2017TWNMH2). Công trình này cũng được hỗ trợ một phần bởi TAILOR và HumanE-AI-Net, các dự án được tài trợ bởi chương trình nghiên cứu và đổi mới EU Horizon 2020 theo GA số 952215 và số 952026, tương ứng.

Được chấp nhận xuất bản tại Hội nghị Quốc tế IEEE về Mạng Nơ-ron Kết hợp (IJCNN) 2023 (DOI: TBA). ©2023 IEEE. Sử dụng cá nhân tài liệu này được cho phép. Sự cho phép từ IEEE phải được lấy cho tất cả các mục đích sử dụng khác, trong bất kỳ phương tiện hiện tại hoặc tương lai nào, bao gồm in lại/xuất bản lại tài liệu này cho mục đích quảng cáo hoặc khuyến mại, tạo ra các tác phẩm tập thể mới, để bán lại hoặc phân phối lại đến các máy chủ hoặc danh sách, hoặc sử dụng lại bất kỳ thành phần có bản quyền nào của công trình này trong các công trình khác.

giả định rằng tất cả dữ liệu huấn luyện có sẵn từ đầu và được lấy mẫu từ một phân phối tĩnh theo cách độc lập (i.i.d.). Kịch bản này không xem xét trường hợp mà các mô hình nơ-ron được thích ứng dần dần với dữ liệu mới được lấy mẫu theo thời gian từ các phân phối không ổn định. Gần đây, những hạn chế bao hàm bởi giả định i.i.d. đã thu hút sự chú ý rộng rãi hơn và các mô hình mới được thiết kế để học theo thời gian bắt đầu xuất hiện [3]. Những mô hình như vậy được lấy cảm hứng lỏng lẻo từ nhận thức con người, thường hoạt động theo cách gia tăng với các khái niệm mới được học trong mối quan hệ có ích với kiến thức đã có trước đó, để cả kỹ năng cũ và mới thường được tinh chỉnh thông qua sự tương tác của chúng [4]. Điều này trái ngược hoàn toàn với hành vi mặc định của mạng nơ-ron, nơi thường nhận thấy sự sụt giảm hiệu suất lớn trên dữ liệu cũ khi thích ứng trọng số trên các tập dữ liệu mới và chưa bao giờ thấy trước được trình bày theo thời gian. Vấn đề này, thường được gọi là quên thảm khốc [5], đã được biết đến từ phong trào kết nối sớm [4] và vẫn còn xa mới được giải quyết một cách tổng quát và thỏa đáng. Để giải quyết những vấn đề này, Học Liên Tục (CL) phát triển các phương pháp phù hợp cho các bài toán trong đó dữ liệu huấn luyện được trình bày theo thời gian và có khả năng theo cách suốt đời.

Các thiết bị edge thông minh, bao gồm cảm biến, thiết bị truyền động, nền tảng robot, v.v., với tài nguyên tính toán khiêm tốn, đang trở nên phổ biến và có nhu cầu ngày càng tăng về khả năng xử lý được điều khiển bởi Học Máy cho nhận thức, hiểu biết và cá nhân hóa trong Internet of Things. Thực vậy, những thiết bị như vậy có khả năng thu thập các luồng dữ liệu liên tục [6], có thể được xử lý bằng các giải pháp dựa trên CL chạy trên chính các thiết bị edge. Một số thách thức phải được đối mặt khi triển khai các phương pháp CL đến các thiết bị edge. Trước hết, các kiến trúc nơ-ron hiện đại tiêu chuẩn (ví dụ: Transformers [7]) với nhiều lớp mã hóa có thể có khả năng ứng dụng hạn chế do thiếu hụt bộ nhớ và khả năng tính toán. Trong khi việc chuyển tải lên đám mây có thể là một giải pháp đơn giản, nó gây ra lo ngại về quyền riêng tư và các vấn đề phức tạp.

arXiv:2306.02947v2  [cs.LG]  8 Jun 2023

--- TRANG 2 ---
Hơn nữa, hầu hết các phương pháp CL hiện đại bao gồm các quy trình rehearsal [3], tức là, xem lại một số mẫu của các khái niệm trong quá khứ để "làm mới" kiến thức của mô hình. Điều này mở ra những vấn đề mới liên quan đến khả năng lưu trữ và, một lần nữa, quyền riêng tư [8], vì nó đưa ra nhu cầu lưu trữ dài hạn dữ liệu huấn luyện. Các phương pháp dựa trên latent replay (thay vì input replay) đạt được nén tốt hơn và che khuất dữ liệu có khả năng riêng tư, nhưng các vấn đề lưu trữ không được giải quyết và bảo vệ quyền riêng tư có thể hoàn toàn không đáng tin cậy [9]. Một vấn đề khác với nghiên cứu CL hiện tại liên quan đến quy mô hạn chế của các tác vụ được giải quyết, với chỉ những nỗ lực hạn chế được dành để đánh giá hiệu suất của các phương pháp CL trong các ứng dụng thực tế.

Trong bối cảnh các thiết bị edge với khả năng tính toán hạn chế, việc bắt đầu từ các mạng được tiền huấn luyện trên các bộ sưu tập dữ liệu lớn có vẻ hợp lý, vì chúng là những công cụ mạnh mẽ để tính toán các biểu diễn tiềm ẩn có thông tin và chúng cho phép giảm nỗ lực huấn luyện. Tuy nhiên, kiến thức nhúng của chúng có thể bị mất đáng kể khi tinh chỉnh dần dần mạng để thích ứng với các miền mới theo cách CL (đặc biệt khi rehearsal không được thực hiện [10]). Một thay thế cho tinh chỉnh gần đây đã trở nên phổ biến trong cộng đồng Học Máy, tức là, học các tham số ảnh hưởng đến đầu vào mô hình với mục tiêu điều kiện hóa mạng thay vì thay đổi trọng số nội bộ của nó. Những mô hình Prompt Tuning này [11]–[13] được hình thành để thúc đẩy việc khai thác các mạng quy mô rất lớn, để tận dụng hiệu quả khả năng của chúng trong các tác vụ downstream cụ thể. Tuy nhiên, hầu hết công việc trong dòng này tập trung vào các mô hình Transformer lớn và kết nối với CL không được nghiên cứu sâu [14].

Được thúc đẩy bởi những cân nhắc này, trong bài báo này chúng tôi đề xuất và điều tra tính phù hợp của các tùy chọn tinh chỉnh khác nhau khi đối mặt với bài toán CL dựa trên mạng được tiền huấn luyện, thường được gọi là backbone, tập trung vào các phương pháp đòi hỏi nỗ lực tính toán thấp hơn và không rehearsal, phù hợp tốt cho các thiết bị edge. Cụ thể, chúng tôi đề xuất Input Tuning (IT), một hình thức thay thế của Prompt Tuning, để thích ứng hiệu quả mô hình với dữ liệu mới và đạt được sự cân bằng tốt giữa tính dẻo và ổn định. Chúng tôi cung cấp phân tích thực nghiệm được thực hiện trên các tập dữ liệu khác nhau có sẵn trong tài liệu liên quan, so sánh một số quy trình tinh chỉnh và các phương pháp học liên tục nổi tiếng. Những đóng góp của bài báo này như sau: (1) chúng tôi đề xuất việc áp dụng các quy trình Input Tuning để tận dụng tốt hơn các backbone được tiền huấn luyện trong CL; (2) chúng tôi đánh giá thực nghiệm tác động của tinh chỉnh trên các benchmark CL phổ biến, cung cấp kết quả tham khảo; (3) chúng tôi điều tra và cho thấy lợi ích của Input Tuning trong thiết lập liên tục, với các kiến trúc nơ-ron thân thiện với edge, cho cả sự dịch chuyển miền nhỏ và lớn.

Bài báo này được tổ chức như sau. Công việc liên quan được trình bày trong Phần II, trong khi Input Tuning được mô tả trong Phần III. Thí nghiệm ở Phần IV và Phần V, trong khi kết luận và gợi ý cho công việc tương lai được rút ra trong Phần VI.

II. CÔNG VIỆC LIÊN QUAN

Sự có sẵn rộng rãi của các mô hình được tiền huấn luyện mang lại một số cơ hội để chuyển giao kiến thức của chúng đến các tác vụ downstream cụ thể. Phương pháp đơn giản nhất bao gồm việc tinh chỉnh các mô hình trên dữ liệu tác vụ mới. Điều này thường đòi hỏi nhiều tài nguyên, đặc biệt trong trường hợp các mô hình quy mô lớn, do việc chiếm dụng bộ nhớ (gradient cũng như activations) và các hoạt động trong quy trình cập nhật trọng số. Khái niệm chung về tiền huấn luyện đã được chứng minh là ngầm làm cho một số bài toán CL dễ dàng hơn [15], theo trực giác rằng nó có nhiều khả năng kết thúc trong các giải pháp có thông tin hơn so với các mô hình được khởi tạo ngẫu nhiên, do các kỹ năng học được trong giai đoạn tiền huấn luyện. Tất nhiên, một quy trình tinh chỉnh không phù hợp có thể tạo ra một mô hình tập trung quá mạnh vào tác vụ mới, mất lợi thế từ kiến thức đã học trước đó. Tuy nhiên, trong khi các giới hạn của việc chuyển giao các mô hình được tiền huấn luyện đến các tác vụ downstream gần đây đã được nghiên cứu [16], khi nói đến việc nghiên cứu hoặc đánh giá cụ thể tác động cụ thể của việc thích ứng các mô hình được tiền huấn luyện vào bối cảnh CL, tài liệu khoa học tương đối khan hiếm [10]. Ramasesh et al. [17] đã chỉ ra rằng khả năng chống quên luôn tỷ lệ thuận với kích thước mạng khi sử dụng các mô hình được tiền huấn luyện. Tuy nhiên, một số câu hỏi vẫn chưa được trả lời, đặc biệt liên quan đến các mô hình quy mô nhỏ hơn trong môi trường bị hạn chế tính toán, như những mô hình chúng tôi nghiên cứu trong bài báo này. Một dòng công việc khác [18], [19] thay thế bước tiền huấn luyện bằng một quy trình liên tục, đặc biệt trong thiết lập tự giám sát. Trong khi phương pháp này mở đường cho việc khai thác dữ liệu phi tập trung và streaming trong nhiều bối cảnh khác nhau, nó không tập trung vào kịch bản thực tế trong đó các tác vụ downstream được học theo cách gia tăng.

Một chủ đề nghiên cứu khác liên quan đến bài báo này bao gồm các mô hình Prompt Tuning [11], [12], [20], ban đầu được hình thành trong Xử lý Ngôn ngữ Tự nhiên (NLP), và mở ra một góc nhìn mới về cách thích ứng một mô hình được tiền huấn luyện với một môi trường mới, liên quan đến giai đoạn tiền huấn luyện. Các mô hình Prompt Tuning học các tham số thực sự là một phần của giai đoạn đầu vào, để khám phá cách thích hợp để điều kiện hóa mô hình, thay vì thay đổi giá trị của các trọng số nội bộ hoặc học các tham số nội bộ bổ sung (như trong trường hợp Adapters [21]). Kỹ thuật như vậy chủ yếu được áp dụng cho các mô hình Transformer, cả cho các tác vụ ngôn ngữ và tác vụ thị giác. Trong bài báo này, chúng tôi tập trung vào một loại tinh chỉnh cụ thể không bị hạn chế đối với các mô hình Transformer, và chúng tôi nghiên cứu trong bối cảnh CL.

Việc điều chỉnh không gian đầu vào để thay đổi hành vi của mạng nơ-ron đã được điều tra cho nhiều mục đích khác nhau. Với chiến lược này, các nhà nghiên cứu đã thành công trong việc tái lập trình một mô hình được huấn luyện để thực hiện trên một tác vụ rất khác biệt [22], trong khi những người khác [23], [24] đã phát triển một phương pháp học theo chương trình lấy cảm hứng để học hiệu quả từ một tập hợp liên tục các bài toán học với độ phức tạp tăng dần. Gần đây, ý tưởng này đã được nghiên cứu trong bối cảnh transfer learning cho phân loại hình ảnh [13], và đã được chứng minh rằng việc học các tham số để biến đổi dữ liệu đầu vào là một

--- TRANG 3 ---
phương pháp cạnh tranh để đối phó với các mô hình được tiền huấn luyện lớn, đặc biệt là những mô hình dựa trên Transformer. Các nhà nghiên cứu đang bắt đầu áp dụng trực giác này vào góc độ CL [14], nhưng họ chủ yếu tập trung vào các mô hình ViT [25] khá lớn. Hơn nữa, họ phụ thuộc nhiều vào khả năng của mô hình được xem xét để trích xuất các biểu diễn phong phú về mặt ngữ nghĩa toàn cầu để hướng dẫn việc biến đổi đầu vào, trong khi họ thiếu so sánh rõ ràng với trường hợp không phải Transformer. Trong bài báo này, chúng tôi nghiên cứu cụ thể cách thay đổi dữ liệu đầu vào bằng các tham số học được mới được giới thiệu có thể mang lại CL hiệu quả và có thể chi trả về mặt tính toán, bắt đầu từ một backbone được tiền huấn luyện.

Hình Ảnh Đầu Vào
IT-PAD IT-ADD
Đầu Vào Được Biến Đổi Biến Đổi
Bộ Phân Loại Bộ Phân Loại

Hình 1: Phác thảo quy trình Input Tuning được đề xuất. Hai biến thể (IT-PAD, IT-ADD) của hàm biến đổi g(·,·), hiển thị các ví dụ về các tham số học được mới được giới thiệu θg và của các đầu vào được biến đổi kết quả ˜x.

III. TINH CHỈNH LIÊN TỤC MỘT MÔ HÌNH ĐƯỢC TIỀN HUẤN LUYỆN

Chúng tôi xem xét một thiết lập cụ thể trong đó việc học được thực hiện bởi một thiết bị edge với tài nguyên tính toán hạn chế, được trang bị một mạng nơ-ron đã được tiền huấn luyện trên một tác vụ ban đầu (thường là dữ liệu quy mô lớn). Không mất tính tổng quát, chúng tôi tập trung vào các bài toán phân loại hình ảnh, để đầu vào của mạng là một hình ảnh RGB w×h. Như thường lệ, mạng có thể được coi là bao gồm một bộ trích xuất đặc trưng m trích xuất các đặc trưng cấp cao hơn, và một đầu phân loại c trả về độ tin cậy dự đoán y trên một tập hợp các lớp,

y=c(m(x, θm), θc),

trong đó θm và θc là các tham số (trọng số và bias) của bộ trích xuất đặc trưng và đầu phân loại, tương ứng, và y là một vector với số thành phần bằng số lớp. Để đơn giản, chúng tôi coi đầu phân loại chỉ bao gồm phép chiếu tuyến tính cuối cùng và tính phi tuyến. Kiến thức mạng có thể được chuyển giao đến các tác vụ liên quan khác bằng cách loại bỏ c và thay thế nó bằng một đầu cụ thể cho tác vụ ĉ, với θĉ mới của riêng nó. M ban đầu hoạt động như một backbone, và θm có thể được tinh chỉnh trên tác vụ mới, cùng với việc học từ đầu θĉ mới. Chúng tôi ký hiệu FT cho phương pháp tinh chỉnh như vậy, có thể bị hạn chế đối với θĉ và một tập con của θm. Chúng tôi gọi thiết lập đó là FT-Partial. Chúng tôi tiếp tục phân biệt những trường hợp này với một tùy chọn nhẹ hơn được gọi là Bias Tuning (BT), được biết đến để nhắm mục tiêu vào một tập con đặc biệt nhỏ và biểu cảm của các tham số mô hình [26], tức là, các bias của các nơ-ron của toàn bộ mạng, cùng với θĉ thông thường. Chúng tôi giả định rằng mạng đủ đơn giản để thực hiện suy luận nhanh với phần cứng được xem xét, tức là, trong khoảng thời gian có thể chấp nhận được cho kịch bản mục tiêu.

Chúng tôi tập trung vào thiết lập CL phổ biến trong đó việc học bao gồm một số (T≥1) phiên huấn luyện riêng biệt, Sj, j = 1, . . . , T, trong đó T có thể là vô hạn (học suốt đời). Mỗi phiên đi kèm với dữ liệu Dj, và không có sự chồng chéo giữa các lô dữ liệu của các phiên khác nhau, Dj∩Dh=∅,∀(j, h). Trong mỗi Sj, người học được chọn được trình bày với một tác vụ và sau khi kết thúc phiên, dữ liệu tác vụ không còn có sẵn để huấn luyện thêm. Trước khi bắt đầu quá trình CL, chúng tôi cắm một đầu phân loại mới ĉ lên trên m được tiền huấn luyện, sử dụng một số lượng lớn nơ-ron đầu ra (ít nhất bằng tổng số lớp dự kiến ​​vào cuối toàn bộ quá trình học), và khởi tạo ngẫu nhiên các tham số của nó. Tất nhiên, chúng tôi giả định rằng tập dữ liệu tiền huấn luyện đủ chung để hữu ích cho việc giải quyết nhiều bài toán học downstream. Mục tiêu cuối cùng là tinh chỉnh hiệu quả mô hình theo cách tiến bộ, sử dụng dữ liệu đến từ luồng tác vụ, mà không lưu trữ thông tin trong quá khứ. Chúng tôi ký hiệu θ(j)* các giá trị của các tham số sau phiên Sj, trong đó * là một trình giữ chỗ cho tất cả các tham số khác nhau được đề cập trong bài báo này. Chúng tôi mong đợi mô hình tổng thể vào cuối chuỗi tác vụ,

y = ĉ(m(x, θ(T)m), θ(T)ĉ),

có độ chính xác trung bình cao trên tất cả các tác vụ, giữ cho việc quên trung bình kiến thức ở mức tối thiểu.

Chúng tôi sẽ chủ yếu tập trung vào thiết lập class-incremental với một số cái nhìn sâu sắc về thiết lập domain-incremental, trong cả hai trường hợp trong kịch bản được giám sát đầy đủ. Trong thiết lập class-incremental, chúng ta được cung cấp dữ liệu được phân chia thành một số lượng lớn các lớp và chúng ta mô phỏng CL bằng cách giới hạn mỗi phiên Sj với một tập con cụ thể của chúng (các tập con rời rạc). Đối với mỗi Sj, bộ phân loại xuất ra điểm tin cậy y giới hạn cho các lớp liên quan đến phiên, do đó khai thác một phần của đầu ĉ, được gọi là ĉj.1 Gradient chỉ được tính toán cho các tham số bao gồm các nơ-ron đầu ra trong ĉj, có giá trị được ký hiệu bằng θĉj. Đây là một thể hiện của cái gọi là "label trick" [27], một kỹ thuật khá đơn giản có vai trò rất hiệu quả trong việc ngăn chặn nhiễu và, như vậy, nó được coi là một phần ổn định của tất cả các mô hình. Trong trường hợp domain-incremental, người học được trình bày với dữ liệu mới được gắn nhãn trên cùng một tập hợp các lớp thông qua các phiên, nhưng có nguồn gốc từ một tổng thể dữ liệu khác, do đó label trick không áp dụng. Thực tế, đối với mỗi Sj, bộ phân loại xuất ra tập hợp đầy đủ các điểm tin cậy sử dụng toàn bộ ĉ, và gradient luôn được tính toán đối với tất cả θĉ. Trong tất cả các thí nghiệm CL của bài báo này, chúng tôi luôn

1Trong trường hợp kích hoạt softmax trên các đơn vị đầu ra, ký hiệu y của chúng tôi đề cập đến các logit không chuẩn hóa (và không phải đầu ra softmax).

--- TRANG 4 ---
giả định rằng danh tính tác vụ không được biết tại thời điểm kiểm tra, vì nó thách thức hơn và thực tế hơn. Điều quan trọng là phải nhấn mạnh sự khác biệt của những gì chúng tôi đã mô tả cho đến nay với quá trình transfer learning phổ biến hơn trong đó tất cả dữ liệu (∪T j=1Dj) đồng thời có sẵn để tinh chỉnh mô hình, mà chúng tôi gọi là thiết lập Joint Learning (JL), vì tất cả các tác vụ mới được xử lý cùng nhau. Thực tế, việc học trong thiết lập CL thách thức hơn đáng kể so với trong JL, vì chúng ta mong đợi mô hình giữ hiệu suất hợp lý trên các tác vụ trong quá khứ trong khi học các tác vụ mới theo cách tuần tự, mà không lưu trữ dữ liệu trong quá khứ.

A. Phương Pháp Được Đề Xuất

Trong bài báo này, chúng tôi đề xuất xem xét một Input Tuning (IT) chung trong đó hình ảnh đầu vào ban đầu x được biến đổi thành ˜x bởi một hàm g nào đó trước khi đưa nó vào mạng (Hình 1),

˜x=g(x, θg)
y= ĉ(m(˜x, θm), θĉ),

trong đó θg là các tham số học được mới được giới thiệu chỉ liên quan đến hàm biến đổi. Mục đích của việc tối ưu hóa được thực hiện trong quá trình CL là đào tạo chung các tham số θĉ của bộ phân loại ĉ cùng với các tham số input tuning θg mới. Phương pháp Input Tuning đầu tiên mà chúng tôi xem xét, mà chúng tôi gọi là IT-PAD, bao gồm việc đóng khung hình ảnh đầu vào với một đường viền (được gọi là Frame) của các "pixel" học được, được mô tả bởi θg. Một thay thế đơn giản khác, từ đây được ký hiệu là IT-ADD, bao gồm việc biến đổi đầu vào bằng cách thêm vào x một tensor học được θg (được gọi là Perturbation) có cùng hình dạng với hình ảnh đầu vào, được chia sẻ bởi tất cả các đầu vào có thể. Hình 1 hiển thị một phác thảo trực quan của những biến đổi này, bao gồm một ví dụ được lấy từ các thí nghiệm sẽ được thảo luận kỹ lưỡng trong Phần IV.

Để cung cấp một cái nhìn thoáng qua về kết quả của IT, chúng tôi báo cáo trong Bảng I sự thay đổi độ chính xác mà chúng ta nhận được khi so sánh một mô hình baseline không được tinh chỉnh (tức là, một mô hình trong đó chỉ θĉ được huấn luyện trong khi toàn bộ backbone được giữ cố định) với các quy trình tinh chỉnh hoặc Input Tuning đã giới thiệu trước đó, cả khi thực hiện transfer learning sử dụng tất cả dữ liệu (JL, cột thứ ba), và khi thực hiện CL tuần tự (cột thứ tư), đây là trọng tâm của công việc này và sẽ được chi tiết trong phần sau. Rõ ràng là những gì hoạt động rất tốt trong thiết lập JL không nhất thiết phù hợp cho trường hợp CL, xác nhận tầm quan trọng của việc điều tra các cách thay thế để khai thác các backbone được tiền huấn luyện trong CL. Thú vị là, các thể hiện IT (IT-PAD và IT-ADD) là những cái hoạt động tốt hơn trong CL, ngay cả khi chúng học một tập hợp tham số tương đối nhỏ.

Tinh Chỉnh Tham Số Đã Học Joint Continual
None θĉ 66.12 44.49
BT θĉ và Biases của m(∼1k) +4.44 -2.77
FT-Partial1 θĉ và θ′m(4.7M) +1.69 -30.47
FT-Partial2 θĉ và θ′′m(8.4M) -2.16 -32.20
IT-PAD θĉ và Frame (0.1M) +1.86 +7.09
IT-ADD θĉ và Perturbation (0.15M) -0.56 +0.32

BẢNG I: Xem trước tác động của các phương pháp tinh chỉnh khác nhau trên CIFAR100 trong thiết lập Joint (độ chính xác) và Continual (độ chính xác tác vụ trung bình được đo ở cuối chuỗi học) Learning. Hàng đầu tiên báo cáo kết quả tuyệt đối của baseline. Sự khác biệt so với chúng được báo cáo trong các hàng khác. Trong khi Bias Tuning (BT) rất hiệu quả khi tất cả các ví dụ đồng thời có sẵn để huấn luyện, Input Tuning là một phương pháp cạnh tranh trong thiết lập CL - nơi tinh chỉnh một phần (FT-Partial) thất bại nặng nề. θ′m và θ′′m là hai tập con khác nhau của các tham số backbone – xem Phần IV để biết thêm chi tiết.

Bất cứ khi nào một bài toán học liên tục bao trùm các phân phối rõ ràng không đồng nhất (ví dụ trong trường hợp dữ liệu được thu thập từ nhiều nguồn), việc chia sẻ chính xác cùng một biến đổi g(·, θg) cho tất cả các tác vụ (được gọi là phương pháp tiêu chuẩn, được mô tả trong Hình 2a) có thể không tối ưu. Vì lý do này, chúng tôi đề xuất học một biến đổi đầu vào khác nhau trong các phiên huấn luyện khác nhau, bằng cách học các θg độc lập, một cho mỗi tác vụ của phiên. Chúng tôi sẽ ký hiệu θgj các tham số biến đổi được học trong phiên Sj, về tác vụ thứ j. Trong thiết lập thách thức mà chúng tôi xem xét, danh tính tác vụ không được biết tại thời điểm kiểm tra, để sau phiên huấn luyện St, chúng tôi biến đổi một mẫu kiểm tra x thành n ˜xj=g(x, θ(j)gj), j= 1, . . . , t. Trong trường hợp class-incremental, sau phiên huấn luyện St, chúng tôi sau đó tính toán n yj= ĉj(m(˜xj, θ(t)m), θ(j)ĉj), j= 1, . . . , t, và chúng tôi nối các yj để nhận được một vector điểm tin cậy bao gồm tất cả các lớp đã khám phá cho đến nay, được sử dụng để đưa ra dự đoán cuối cùng trên x (nhớ rằng mỗi yj chỉ về một tập con của các lớp). Khác biệt, trong trường hợp domain-incremental, sau phiên huấn luyện St chúng tôi tính toán n yj= ĉ(m(˜xj, θ(t)m), θ(t)ĉ), j= 1, . . . , t, và đối với mỗi lớp chúng tôi lấy điểm tin cậy tối đa để có được vector quyết định cuối cùng (nhớ rằng ở đây mỗi yj là về tất cả các lớp, vì tập hợp các lớp được chia sẻ bởi tất cả các tác vụ). Vì tất cả các hoạt động này có thể được chạy song song trên các biến đổi khác nhau (lên đến các yj cuối cùng), chúng tôi gọi quy trình phân loại như vậy với thuật ngữ bộ phân loại song song (xem Hình 2b).

IV. THÍ NGHIỆM

Chúng tôi mô tả điều tra thực nghiệm của chúng tôi bằng cách giới thiệu các tập dữ liệu được xem xét trong Phần IV-A, các đối thủ cạnh tranh trong Phần IV-B, kiến trúc nơ-ron và thiết lập thực nghiệm trong Phần IV-C, và bằng cách báo cáo và thảo luận kết quả trong Phần IV-D, tiếp theo là phân tích sâu về phương pháp được đề xuất.

A. Tập Dữ Liệu

Để đánh giá hiệu suất của thuật toán học được đề xuất, chúng tôi khai thác nhiều tập dữ liệu có sẵn trong tài liệu. CIFAR100 [28] là một tập dữ liệu Phân loại Hình ảnh phổ biến, bao gồm 60k hình ảnh màu 32×32 từ 100 lớp khác nhau (500 hình ảnh huấn luyện mỗi lớp). Tập dữ liệu RESISC45 [29]

--- TRANG 5 ---
Gia Tăng Lớp
(Kiểm tra tại thời điểm t) Gia Tăng Miền
(Kiểm tra tại thời điểm t) CAT(a)
Gia Tăng Lớp
(Kiểm tra tại thời điểm t) Gia Tăng Miền
(Kiểm tra tại thời điểm t) CAT MAX MAX (b)

Hình 2: Phác thảo đường ống tính toán Input Tuning cho các trường hợp class-incremental và domain-incremental, đi từ đầu vào x đến điểm tin cậy lớp y (logits trong trường hợp softmax) tại thời điểm suy luận: (a) phương pháp tiêu chuẩn, (b) biến thể bộ phân loại song song.

là một benchmark cho Phân loại Cảnh Hình ảnh Viễn thám (RESISC). Tập dữ liệu này chứa 32k hình ảnh màu, bao phủ 45 lớp cảnh (560 hình ảnh huấn luyện cho mỗi lớp). FIVEDS [30] là sự nối của năm tập dữ liệu phân loại hình ảnh nổi tiếng: CIFAR-10 [28], MNIST [31], Fashion-MNIST [32], SVHN [33], và notMNIST [34]. Mặc dù mỗi benchmark đơn lẻ là tương đối dễ dàng khi sử dụng các mô hình được tiền huấn luyện, FIVEDS là thách thức vì việc quên phát sinh từ các phân phối rất khác nhau trong không gian đầu vào. DomainNet [35] là một bộ sưu tập hình ảnh được gắn nhãn trên 345 lớp với nhiều sự dịch chuyển miền drastic. Trong bài báo này, chúng tôi khai thác 4 tập con (sketch, real, painting, clipart), tổng cộng 250k mẫu huấn luyện và 110k mẫu kiểm tra.

Chúng tôi định nghĩa bốn bài toán CL khác nhau sử dụng bốn tập dữ liệu vừa mô tả: (i.) CIFAR100/T10, trong đó CIFAR100 được chia ngẫu nhiên thành 10 tác vụ (mỗi tác vụ chứa 10 lớp) (ii.) RESISC45/T9 với 9 tác vụ (mỗi tác vụ chứa 5 lớp); (iii.) FIVEDS/T5, trong đó mỗi tác vụ bao gồm 10 lớp có sẵn trong mỗi tập dữ liệu con điền vào FIVEDS, và (iv.) DOMAINNET/T4, trong đó mỗi tác vụ chứa các ví dụ mới của cùng một tập hợp các lớp nhưng từ một miền khác nhau. Trong khi (i.,ii.,iii.) là class-incremental, (iv.) là domain-incremental. Hơn nữa, (i.,ii.) là Single Source Data, trong khi (iii.,iv.) là Multiple Source Data.

B. Đối Thủ Cạnh Tranh

Chúng tôi so sánh IT-PAD và IT-ADD được đề xuất với một mô hình baseline chỉ huấn luyện đầu phân loại (tham số θĉ), BT, và FT-Partial (hai trường hợp, được mô tả bên dưới). Trong IT-PAD, IT-ADD và mô hình baseline, quá trình học được điều khiển bởi một loss bao gồm dữ liệu được giám sát có sẵn trong mỗi phiên, tức là, Dj. Khác biệt, trong trường hợp FT-Partial, loss được tăng cường với các regularizer CL từ các phương pháp hiện đại.2 Mục tiêu của chúng tôi là điều tra xem IT có phải là một chiến lược cạnh tranh mà không thay đổi hàm loss và không đưa ra các tính toán bổ sung. Thực tế, một loạt các kỹ thuật CL cụ thể khác nhau đã được phát triển trong thập kỷ qua [3]. Cụ thể, các phương pháp regularization dữ liệu chủ yếu được lấy cảm hứng từ knowledge distillation [36]. Learning without Forgetting (LwF) [37] là thể hiện đơn giản nhất và về cơ bản nó thực hiện distillation trên output logits được tính toán trên dữ liệu hiện có sẵn, từ mô hình thu được vào cuối phiên St−1 đến mô hình hiện tại trong St. Rõ ràng, distillation bị hạn chế đối với các đơn vị của các lớp đã học cho đến thời điểm St. Thay thế, Learning without Memorizing (LwM) [38] được hướng đến attention. Cụ thể, nó bao gồm một loss bổ sung được sử dụng để bảo tồn attention maps qua các phiên khác nhau (xem [39] để biết chi tiết). Cuối cùng, chúng tôi cũng xem xét các phương pháp regularization trực tiếp nhắm mục tiêu vào các trọng số, chẳng hạn như Elastic Weight Consolidation (EWC) [40]. Tầm quan trọng của các trọng số được ước tính thông qua một xấp xỉ của Fisher Information Matrix, và EWC thực thi regularity trên các tham số học được giữa θ(t−1)* và θ(t)* theo tầm quan trọng được ước tính như vậy. Các tác giả của [41] đã đề xuất một thể hiện thậm chí đơn giản hơn của EWC, vì họ chỉ ra rằng tầm quan trọng của mỗi tham số đối với việc hoàn thành một tác vụ học có thể được ước tính bằng cách tích lũy các thay đổi trọng số riêng lẻ; phương pháp như vậy được gọi là Path Integral trong phần sau (còn được biết đến như Synaptic Intelligence).

C. Thiết Lập Thực Nghiệm

Chúng tôi tập trung vào một lớp cụ thể của mạng tích chập cho phân loại hình ảnh, các ResNet rất phổ biến [42], theo kịch bản hướng edge của chúng tôi trong đó ngân sách tính toán thực sự bị hạn chế. Cụ thể, chúng tôi sẽ xem xét ResNet-18 khá nhỏ (11M tham số), được tiền huấn luyện trên ImageNet [43] (đầu vào ở độ phân giải 224×224). Khác với kiến trúc dựa trên Transformer, nó đòi hỏi bộ nhớ nhỏ hơn và ít đòi hỏi tính toán hơn (so với những thể hiện của các mô hình Transformer với số lượng tham số tương đối nhỏ hơn - chẳng hạn như ViT-B/16, 84M tham số). Trong phần sau, chúng tôi xem xét hai thiết lập tinh chỉnh một phần khác nhau, FT-Partial1 và FT-Partial2, tập trung vào module cuối cùng của kiến trúc được xem xét,

2Như chúng tôi sẽ chỉ ra trong Phần V, tinh chỉnh mà không có bất kỳ regularizer CL nào là không thực tế do việc quên mạnh mẽ.

--- TRANG 6 ---
được tạo thành từ hai BasicBlock cuối cùng3 và đại diện cho một phần đáng kể (70% tổng số tham số) của toàn bộ kiến trúc. Trong FT-Partial1, chúng tôi hạn chế các hoạt động tinh chỉnh đối với các tham số có trong BasicBlock cuối cùng (4.7M), và chúng tôi gọi các tham số này với θ′m. Trong FT-Partial2, chúng tôi cũng bao gồm những tham số trong BasicBlock thứ hai cuối cùng (+3.7M), ký hiệu với θ′′m sự hợp nhất của các tham số này.

Nói chung, chúng tôi sử dụng cross-entropy làm hàm loss phân loại, và bộ tối ưu hóa Adam được khai thác cho tất cả các tham số học được trừ khi có quy định khác; một kích thước batch B nhỏ hơn được sử dụng cho các tập dữ liệu nhỏ hơn (B= 16 cho CIFAR100, RESISC45; B= 64 cho FIVEDS, DOMAINNET). Trong tất cả các thí nghiệm, các mạng được khởi tạo ngẫu nhiên, sử dụng cùng một seed cho các phương pháp khác nhau, và chúng tôi báo cáo kết quả trung bình trên 3 lần chạy với các khởi tạo khác nhau. Theo [44], huấn luyện cho nhiều epoch tách rời các hiệu ứng của việc quên và underfitting. Như vậy, trừ khi có quy định khác, chúng tôi chọn một số epoch đủ để có được cấu hình ổn định của các tham số vào cuối mỗi tác vụ. Vì chúng tôi giả định có ngân sách tính toán hạn chế, các siêu tham số được chia sẻ qua các bài toán học khác nhau (tức là, không được tinh chỉnh cụ thể cho tập dữ liệu hiện có). Trong tất cả các thí nghiệm IT-PAD, chúng tôi học một đường viền dày 32 pixel. Về các chiến lược CL4, chúng tôi áp dụng các tham số được đề xuất bởi các tác giả tương ứng và được đề xuất thêm bởi [39]: đối với LwF chúng tôi đặt nhiệt độ thành 2; đối với EWC sự hợp nhất của các trọng số quan trọng cũ và mới được thực hiện với α= 0.5; đối với LwM chúng tôi đặt β=γ= 1.0; đối với Path Integral chúng tôi cố định tham số damping thành 0.1 như được đề xuất trong công việc ban đầu. Về các lớp batch normalization, chúng tôi sử dụng running averages tại thời điểm kiểm tra cho Single Source Data và thống kê tiền huấn luyện cố định cho Multiple Source Data. Trong khi tác động đến các metric cuối cùng là khiêm tốn, có thể dễ dàng hiểu được rằng, trong trường hợp dữ liệu rất không đồng nhất qua các tác vụ khác nhau, việc học tinh chỉnh mô hình với thống kê cố định dẫn đến ít thích ứng cụ thể cho tác vụ, do đó ít quên hơn. Mặt khác, nếu tất cả dữ liệu tương đối đồng nhất về mặt thống kê toàn cầu (ví dụ: CIFAR100), việc thích ứng mô hình trong chế độ running có thể được hưởng lợi từ thống kê đại diện hơn một chút so với miền tiền huấn luyện.

Chúng tôi đo độ chính xác trung bình và việc quên trung bình vào cuối chuỗi học (tức là t=T). Độ chính xác trung bình āT vào cuối chuỗi tác vụ được xem xét được chọn làm metric chính, như trong hầu hết tài liệu học liên tục. Gọi τ là chỉ số tác vụ/phiên, at,τ là độ chính xác được tính toán trên tập kiểm tra của tác vụ τ, với mô hình thu được sau khi huấn luyện trên tác vụ t (tức là, với các tham số θ(t)*). Việc quên trung bình f̄T cũng hữu ích để đánh giá độ lớn trung bình của sự sụt giảm độ chính xác qua chuỗi. Chính thức,

āt=1/t ∑(τ=1 to t) at,τ, f̄t=1/(t-1) ∑(τ=1 to t-1) max(τ'∈{1,···,t-1})(aτ',τ−at,τ).

Trong tất cả các kết quả sau, các thuật ngữ accuracy và forgetting đề cập đến các giá trị trung bình đã đề cập.

D. Kết Quả và Thảo Luận

Kết quả của các hoạt động thực nghiệm của chúng tôi được báo cáo trong Bảng II và được thảo luận trong phần sau.

Trong trường hợp CIFAR100/T10 (Single Source Data), sự dịch chuyển miền từ tác vụ này sang tác vụ khác trong chuỗi tương đối nhỏ và về mặt chất lượng tất cả dữ liệu chia sẻ các đặc trưng thị giác tương tự [45]. Nhận xét đáng chú ý đầu tiên là baseline, chỉ học bộ phân loại ĉ với label trick, hoạt động tốt một cách đáng ngạc nhiên so với tinh chỉnh được ghép nối với các regularizer CL nổi tiếng. Thú vị thay, bias tuning (BT) không cho thấy cải thiện thực tế nào so với baseline, do việc quên do tính chất gia tăng của bài toán học. Cùng xu hướng có thể được quan sát cho các tùy chọn tinh chỉnh một phần (FT-Partial1, FT-Partial2). Ngược lại, cả hai phương pháp IT có ít nhất cùng độ chính xác với baseline, cho thấy rằng chúng là một cách thích hợp để phấn đấu cho hiệu suất tốt hơn, với độ phức tạp bổ sung nhẹ trên đỉnh của baseline label trick. Trong khi cải thiện được cung cấp bởi IT-ADD là nhỏ, IT-PAD cải thiện đáng kể độ chính xác kiểm tra mà không đặc biệt tiếp xúc với việc quên so với các tùy chọn khác. Như mong đợi (Phần III), phương pháp bộ phân loại song song không giúp ích do tính đồng nhất tương đối của dữ liệu của các tác vụ khác nhau (Single Source Data).

Trong RESISC45/T9 (Single Source Data), người ta có thể tự hỏi liệu mối quan hệ ngữ nghĩa tương đối cao giữa miền tiền huấn luyện (ImageNet) và các tác vụ mục tiêu có quan trọng để có được cải thiện so với baseline hay không. Thực tế, RESISC45 là một tập dữ liệu có sẵn công khai của hình ảnh vệ tinh, có sự dịch chuyển ngữ nghĩa và nhận thức khá lớn so với miền tiền huấn luyện. Tương tự như trường hợp trước, các chiến lược CL dựa trên regularization đang gặp khó khăn trong việc đạt được và duy trì hiệu suất tốt trong suốt chuỗi tác vụ, giảm xuống mức độ chính xác thấp hơn baseline. Mặt khác, IT-PAD lại là tùy chọn hoạt động tốt nhất và cung cấp sự gia tăng độ chính xác đáng đánh giá, trong khi bị ảnh hưởng ít hơn bởi việc quên so với các tùy chọn tinh chỉnh khác (ngoại trừ FT-Partial1-LwF, được đặc trưng bởi một độ chính xác thấp hơn đáng kể tuy nhiên).

Trong FIVEDS/T5 (Multiple Source Data), chúng tôi thử nghiệm với dữ liệu đến từ nhiều nguồn, có thể xa trong không gian ngữ nghĩa và nhận thức. Thú vị thay, trong trường hợp này LwF cung cấp hiệu suất cao nhất. Cho rằng nó ban đầu được đề xuất như một chiến lược task-incremental, không có gì đáng ngạc nhiên khi nó hoạt động tốt trên một chuỗi các tác vụ rất khác biệt (cả trong không gian ngữ nghĩa và trong không gian nhận thức). Đồng thời, chúng ta có thể thấy rằng IT-PAD và IT-ADD cung cấp cải thiện có giá trị khi được triển khai trong bộ phân loại song song. Hơn nữa, so với LwF và Path Integral, lượng tham số đã học (và gánh nặng tính toán) nhỏ hơn, không cần lưu trữ tensor có cùng kích thước với trọng số (trọng số quan trọng cho PathInt, snapshot mô hình cho LwF) và việc quên thấp hơn.

--- TRANG 7 ---
Tinh Chỉnh Tham Số Đã Học CIFAR100/T10 RESISC45/T9 FIVEDS/T5 DOMAINNET/T4
Độ Chính Xác ↑ Quên ↓ Độ Chính Xác ↑ Quên ↓ Độ Chính Xác ↑ Quên ↓ Độ Chính Xác ↑ Quên ↓
None θĉ 44.49±0.22 13.92±1.49 57.14±0.50 22.51±1.15 44.20±2.79 17.78±1.30 35.93±0.13 18.98±0.32
BT θĉ và Biases của m(∼1k) 41.72±0.30 29.91±0.81 46.79±2.06 35.24±1.19 20.36±2.86 56.92±2.11 38.85±1.93 23.28±2.31
FT-Partial1-LwF θĉ và θ′m(4.7M) 39.18±0.83 24.62±0.65 54.46±1.15 12.07±1.41 52.72±1.15 28.85±1.70 – –
FT-Partial1-LwM θĉ và θ′m(4.7M) 38.26±0.72 22.19±0.81 52.51±1.06 25.92±1.49 29.34±0.85 67.02±4.05 – –
FT-Partial1-EWC θĉ và θ′m(4.7M) 39.62±0.48 22.85±0.73 54.17±0.45 25.75±1.46 38.45±2.02 55.18±0.76 19.05±1.77 9.72±0.71
FT-Partial1-PathInt θĉ và θ′m(4.7M) 37.46±1.22 23.49±0.97 52.95±1.64 24.47±1.35 51.38±1.34 25.12±0.52 38.55±1.48 5.7±1.86
FT-Partial2-LwF θĉ và θ′′m(8.4M) 43.03±0.49 28.61±0.22 53.78±0.45 29.27±2.05 61.45±3.02 28.68±0.23 – –
FT-Partial2-LwM θĉ và θ′′m(8.4M) 42.06±0.63 28.57±1.04 53.94±0.88 28.94±2.60 40.98±0.87 35.71±2.45 – –
FT-Partial2-EWC θĉ và θ′′m(8.4M) 41.91±0.81 26.76±0.64 56.03±1.39 27.17±0.41 46.25±0.88 53.11±1.05 29.59±1.31 11.21±1.42
FT-Partial2-PathInt θĉ và θ′′m(8.4M) 42.11±1.08 27.27±1.01 54.98±1.86 26.02±0.80 60.24±2.05 29.09±2.62 39.41±1.65 16.17±3.68
IT-PAD(Standard) θĉ và Frame (0.1M) 51.58±1.78 19.31±1.46 61.06±0.99 16.99±0.94 44.65±1.23 31.86±0.89 38.74±0.44 18.85±1.39
IT-ADD(Standard) θĉ và Perturbation (0.15M) 44.81±0.83 21.01±0.85 57.18±1.63 19.43±0.64 36.09±1.85 44.29±0.97 33.67±0.30 22.45±0.34
IT-PAD(Parallel) θĉ và Frame (0.1M/task) 46.54±0.82 12.88±2.27 55.84±1.59 19.68±1.81 53.36±0.55 19.97±1.40 43.93±1.22 16.12±0.91
IT-ADD(Parallel) θĉ và Perturb. (0.15M/task) 41.82±1.23 13.05±1.14 52.47±2.83 18.29±2.51 56.32±0.43 17.75±0.37 41.18±0.83 17.34±1.61

BẢNG II: Độ chính xác trung bình (↑, cao hơn là tốt hơn) và quên (↓, thấp hơn là tốt hơn) được đo ở cuối chuỗi học. Lưu ý rằng một số chiến lược CL không phù hợp cho thiết lập domain-incremental (xem văn bản của bài báo; các cấu hình không hợp lệ sau đó được đánh dấu bằng "–"). Trong cột thứ hai, chúng tôi báo cáo tập hợp các tham số chịu tối ưu hóa: chúng tôi luôn học đầu phân loại; chúng tôi tinh chỉnh trọng số mạng trong các phương pháp BT, FT-Partial và chúng tôi học các tham số biến đổi (Perturbation hoặc Frame) trong các phương pháp IT. Chúng tôi báo cáo số lượng của các tham số đã học như vậy trong ngoặc.

Trường hợp DOMAINNET/T4 (Multiple Source Data) khác biệt với những trường hợp trước, là thiết lập domain-incremental. Không gian ngữ nghĩa được chia sẻ bởi tất cả các tác vụ, có các phong cách thị giác và đặc trưng nhận thức khá khác nhau (màu sắc, kết cấu, v.v.). Mặc dù độ chính xác thu được có thể có vẻ hơi thấp, điều quan trọng là phải nhấn mạnh rằng đây là một bài toán học rất thách thức, với nhiều ví dụ khó ngay cả đối với con người và đặc biệt đối với mạng tích chập, được biết đến là phụ thuộc nhiều vào kết cấu [46]. Chúng tôi không áp dụng LwF và LwM, không phù hợp với thiết lập domain-incremental. Thực tế, thuật ngữ knowledge distillation sẽ yêu cầu đầu ra mạng với dữ liệu mới để (a) phù hợp với loss phân loại và (b) tương tự với đầu ra của mô hình được học ở tác vụ trước, không được mong đợi giúp ích trong việc học hiệu quả với việc quên thấp. Ngoài ra, cần lưu ý rằng trong trường hợp này bản thân baseline không thể khai thác label trick, vì mỗi tác vụ chứa dữ liệu cho toàn bộ tập hợp lớp. Như vậy, một số phương pháp cung cấp cải thiện so với baseline, bao gồm bias tuning khá đơn giản (BT). Hơn nữa, Path Integral cũng cung cấp cải thiện tương tự, mặc dù ngụ ý tính toán và lưu trữ trọng số quan trọng cụ thể cho tham số. Mặt khác, có thể đánh giá rõ ràng rằng IT-PAD được đề xuất được triển khai với bộ phân loại song song có độ chính xác cao nhất, xác nhận tầm quan trọng của việc học các biến đổi độc lập trong Multiple Source Data.

V. PHÂN TÍCH SÂU

Chúng tôi thực hiện các thí nghiệm bổ sung nhằm có được nhiều cái nhìn sâu sắc hơn về các kết quả đã mô tả trước đó, tập trung vào bài toán học CIFAR100/T10.

Trong Hình 3, chúng tôi báo cáo độ chính xác thu được trong một thí nghiệm so sánh với 5 biến thể khác nhau của lược đồ IT-PAD. (i.) IT-PAD-Online là thiết lập trong đó việc huấn luyện được thực hiện với một lần đi qua dữ liệu huấn luyện. Điều này tăng tốc việc học nhưng nó giảm đáng kể mức độ cải thiện vào cuối việc huấn luyện (so với Bảng II). (ii.) IT-PAD-Fix đề cập đến thiết lập trong đó chúng tôi giữ cố định Frame (padding học được) sau tác vụ đầu tiên. Kết quả cho thấy rằng việc học các pixel bổ sung thực sự có lợi chỉ khi chúng được phép thích ứng với các biến thể nhỏ của các tác vụ khác nhau. (iii.) IT-PAD-Small được tạo ra bằng cách giảm đi một hệ số 4 độ dày của đường viền khung, giảm tổng lượng tham số bổ sung đi một hệ số 5; thú vị khi nhận thấy rằng độ chính xác cao hơn 4% so với Baseline (hàng đầu tiên của Bảng II) cũng trong thiết lập đó. (iv.) IT-PAD-Latent là về việc áp dụng hoạt động padding trong không gian tiềm ẩn (ngay sau hai lớp tích chập đầu tiên) và được hưởng lợi từ cải thiện tương đương với một lượng tham số học được bổ sung tương tự (<0.1M). Mặt khác, (v.) kết hợp phương pháp IT hứa hẹn nhất với BT (IT-PAD+Bias), hoàn toàn làm mất đi bất kỳ cải thiện nào, phù hợp với những gì được đề xuất trong [13]. Phân tích này xác nhận giá trị của lược đồ IT-PAD đơn giản nhưng hiệu quả.

40.0 42.5 45.0 47.5 50.0 52.5
Độ Chính Xác (%) Baseline
IT-Pad-Online
IT-Pad-Fix
IT-Pad-Small
IT-Pad-Latent
IT-Pad
IT-Pad+Bias

Hình 3: Độ chính xác kiểm tra trung bình được đo ở cuối chuỗi học, cho các biến thể của IT-PAD trong CIFAR100/T10. Thực hiện biến đổi trong một không gian tiềm ẩn nào đó (thay vì đầu vào) có hiệu suất kém và việc thêm bias tuning có vẻ phản tác dụng.

--- TRANG 8 ---
Trong Bảng III, chúng tôi điều tra thêm thiết lập online, hiển thị độ chính xác kiểm tra cho các phương pháp khác nhau. Nói chung, khoảng cách giữa phương pháp IT-PAD và tất cả các đối thủ cạnh tranh thậm chí còn rộng hơn so với thiết lập multi-epoch, vì việc tinh chỉnh một phần lớn hơn của mạng sẽ đòi hỏi một lượng lớn hơn các bước cập nhật để có được cấu hình ổn định của các trọng số, xung đột với ràng buộc single-epoch.

Tinh Chỉnh Tham Số Đã Học Độ Chính Xác ↑ Quên ↓
None θĉ 41.38±0.56 14.11±1.88
BT θĉ và Biases (∼1k) 43.94±2.31 24.87±3.18
FT-Partial1 (LwF) θĉ và θ′m(4.7M) 26.07±0.41 20.19±0.92
FT-Partial1 (LwM) θĉ và θ′m(4.7M) 26.09±0.64 20.08±0.68
FT-Partial1 (EWC) θĉ và θ′m(4.7M) 25.88±0.83 23.11±0.77
FT-Partial1 (PathInt) θĉ và θ′m(4.7M) 26.06±1.98 20.84±1.41
FT-Partial2 (LwF) θĉ và θ′′m(8.4M) 29.13±0.71 22.48±0.86
FT-Partial2 (LwM) θĉ và θ′′m(8.4M) 22.84±0.55 31.83±1.29
FT-Partial2 (EWC) θĉ và θ′′m(8.4M) 23.14±0.32 21.32±0.58
FT-Partial2 (PathInt) θĉ và θ′′m(8.4M) 26.69±1.72 24.85±1.95
IT-PAD(Standard) θĉ và Frame (0.1M) 45.65±1.20 17.89±1.92
IT-ADD(Standard) θĉ và Perturb. (0.15M) 42.48±1.34 14.87±0.82

BẢNG III: Kết quả trên CIFAR100/T10 trong thiết lập online: độ chính xác trung bình và quên được đo ở cuối chuỗi học.

Trong Hình 4, chúng tôi cung cấp một số cái nhìn sâu sắc về độ chính xác kiểm tra, được đo trong chuỗi học và ở cuối nó, tương ứng. Trong Hình 4 (trái), chúng tôi cho thấy rằng phương pháp IT-PAD thường có độ chính xác trung bình cao nhất trong suốt chuỗi học, trong khi sử dụng FT-Partial mà không có bất kỳ regularizer CL nào khác không phải là một tùy chọn khả thi. Trong Hình 4 (phải), chúng ta có thể thấy rằng độ chính xác tác vụ của IT-PAD khá đồng đều trên toàn bộ tập hợp (không quên drastic trên các tác vụ cũ) và nói chung là cao nhất trong số các phương pháp được xem xét.

VI. KẾT LUẬN

Chúng tôi đã trình bày Input Tuning, một quy trình tinh chỉnh mới để khai thác các mô hình được tiền huấn luyện trong bối cảnh học liên tục bằng cách điều chỉnh dữ liệu đầu vào (đặc biệt khi chèn một khung các pixel học được, được gọi là IT-PAD). Chúng tôi đã chứng minh thực nghiệm rằng phương pháp được đề xuất đơn giản nhưng hiệu quả trong việc cải thiện đáng kể chất lượng kết quả trên nhiều bài toán học, và có thể được mở rộng nhanh chóng cho trường hợp Multiple Source Data. Trong khi những cải thiện có thể nhìn thấy có thể được kết nối trực quan với những phát hiện về sự phổ biến của việc quên trong các lớp cuối cùng của mạng [47], [48], chúng tôi dự định có được cái nhìn sâu sắc hơn về động lực học tập của phương pháp được đề xuất.

TÀI LIỆU THAM KHẢO
[1] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., "Language models are few-shot learners," in Advances in Neural Information Processing Systems, 2020.
[2] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei, "ImageNet Large Scale Visual Recognition Challenge," Intl. Journal of Computer Vision (IJCV), vol. 115, no. 3, pp. 211–252, 2015.

0123456789
Phiên huấn luyện102030405060708090Độ chính xác trung bình
IT-PAD
FT-Partial2
Baseline
LwF (FT-Partial2)
LwM (FT-Partial2)
EWC (FT-Partial2)
PathInt (FT-Partial2)

0123456789
ID Tác vụ01020304050607080Độ chính xác cuối cùng của tác vụ
IT-PAD
FT-Partial2
Baseline
FT-Partial2 (LwF)
BT

Hình 4: CIFAR100/T10, các mô hình từ Bảng II. Trái: Độ chính xác trung bình trong suốt chuỗi học. Đường cong màu xanh (FT-Partial2, không có regularizer CL) làm nổi bật thực tế rằng việc tinh chỉnh một cách ngây thơ không phải là một tùy chọn thực tế. IT-PAD (xanh lá) cho thấy hành vi tốt nhất trong suốt tất cả chuỗi học. Phải: Độ chính xác cụ thể cho tác vụ, ở cuối chuỗi học. Tinh chỉnh mà không có regularizer CL (FT-Partial2, xanh) có độ chính xác cực thấp, loại trừ tác vụ cuối cùng. BT (xám) và FT-Partial2 (LwF, cam) các tác vụ hoạt động tốt nhất tập trung ở phần cuối của chuỗi (task id ≥6). IT-PAD đánh bại baseline một cách nhất quán và là tốt nhất cho hầu hết các tác vụ.

[3] M. Delange, R. Aljundi, M. Masana, S. Parisot, X. Jia, A. Leonardis, G. Slabaugh, and T. Tuytelaars, "A continual learning survey: Defying forgetting in classification tasks," IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 1–1, 2021.
[4] R. M. French, "Catastrophic forgetting in connectionist networks," Trends in Cognitive Sciences, vol. 3, no. 4, pp. 128–135, 1999.
[5] I. J. Goodfellow, M. Mirza, X. Da, A. C. Courville, and Y. Bengio, "An empirical investigation of catastrophic forgeting in gradient-based neural networks," in Proc. of the Intl. Conf. on Learning Representations, ICLR, 2014.
[6] M. G. S. Murshed, C. Murphy, D. Hou, N. Khan, G. Ananthanarayanan, and F. Hussain, "Machine learning at the network edge: A survey," ACM Comput. Surv., 2021.
[7] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin, "Attention is all you need," in Advances in Neural Information Processing Systems, 2017.
[8] L. Pellegrini, G. Graffieti, V. Lomonaco, and D. Maltoni, "Latent replay for real-time continual learning," in Proc. of the IEEE Intl. Conf. on Intelligent Robots and Systems (IROS), 2020.
[9] A. Mahendran and A. Vedaldi, "Understanding deep image representations by inverting them," in Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2015.
[10] O. Ostapenko, T. Lesort, P. Rodriguez, M. R. Arefin, A. Douillard, I. Rish, and L. Charlin, "Continual Learning with Foundation Models: An Empirical Study of Latent Replay," in Proc. of the 1st Conf. on Lifelong Learning Agents (CoLLAs). PMLR, 2022.
[11] X. L. Li and P. Liang, "Prefix-tuning: Optimizing continuous prompts for generation," Proc. of the 59th Annual Meeting of the Assoc. for Computational Linguistics and the 11th Intl. Joint Conf. on Natural Language Processing, vol. abs/2101.00190, 2021.
[12] B. Lester, R. Al-Rfou, and N. Constant, "The power of scale for parameter-efficient prompt tuning," in Proc. of the 2021 Conf. on Empirical Methods in Natural Language Processing. Assoc. for Computational Linguistics, 2021.
[13] M. Jia, L. Tang, B.-C. Chen, C. Cardie, S. Belongie, B. Hariharan, and S.-N. Lim, "Visual prompt tuning," in Proc. of the European Conf. on Computer Vision (ECCV), 2022.

--- TRANG 9 ---
[14] Z. Wang, Z. Zhang, C.-Y. Lee, H. Zhang, R. Sun, X. Ren, G. Su, V. Perot, J. Dy, and T. Pfister, "Learning to prompt for continual learning," in Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022.
[15] S. V. Mehta, D. Patil, S. Chandar, and E. Strubell, "An empirical investigation of the role of pre-training in lifelong learning," arXiv preprint arXiv:2112.09153, 2021.
[16] S. Abnar, M. Dehghani, B. Neyshabur, and H. Sedghi, "Exploring the limits of large scale pre-training," in Proc. of the Intl. Conf. on Learning Representations (ICLR), 2022.
[17] V. V. Ramasesh, A. Lewkowycz, and E. Dyer, "Effect of scale on catastrophic forgetting in neural networks," in Proc. of the Intl. Conf. on Learning Representations (ICLR), 2022.
[18] D. Hu, S. Yan, Q. Lu, L. Hong, H. Hu, Y. Zhang, Z. Li, X. Wang, and J. Feng, "How well does self-supervised pre-training perform with streaming data?" in Intl. Conf. on Learning Representations (ICLR), 2022.
[19] A. Cossu, T. Tuytelaars, A. Carta, L. Passaro, V. Lomonaco, and D. Bacciu, "Continual Pre-Training Mitigates Forgetting in Language and Vision," arXiv preprint arXiv:2205.09357, 2022.
[20] S. An, Y. Li, Z. Lin, Q. Liu, B. Chen, Q. Fu, W. Chen, N. Zheng, and J.-G. Lou, "Input-tuning: Adapting unfamiliar inputs to frozen pretrained models," arXiv preprint arXiv:2203.03131, 2022.
[21] J. Pfeiffer, A. Rückl´e, C. Poth, A. Kamath, I. Vuli´c, S. Ruder, K. Cho, and I. Gurevych, "Adapterhub: A framework for adapting transformers," in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, 2020, pp. 46–54.
[22] G. F. Elsayed, I. Goodfellow, and J. Sohl-Dickstein, "Adversarial reprogramming of neural networks," in Proc. of the Intl. Conf. on Learning Representations (ICLR), 2019.
[23] S. Marullo, M. Tiezzi, M. Gori, and S. Melacci, "Friendly training: Neural networks can adapt data to make learning easier," in Proc. of the Intl. Joint Conf. on Neural Networks (IJCNN), 2021.
[24] ——, "Being friends instead of adversaries: Deep networks learn from data simplified by other networks," in Proc. of the AAAI Conf. on Artificial Intelligence, 2022.
[25] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby, "An image is worth 16x16 words: Transformers for image recognition at scale," in Proc. of the Intl. Conf. on Learning Representations (ICLR), 2021.
[26] H. Cai, C. Gan, L. Zhu, and S. Han, "Tinytl: Reduce memory, not parameters for efficient on-device learning," in Advances in Neural Information Processing Systems, 2020.
[27] C. Zeno, I. Golan, E. Hoffer, and D. Soudry, "Task-Agnostic Continual Learning Using Online Variational Bayes With Fixed-Point Updates," Neural Computation, 2021.
[28] A. Krizhevsky, "Learning Multiple Layers of Features from Tiny Images," University of Toronto, Tech. Rep., 2009, https://www.cs.toronto.edu/˜kriz/learning-features-2009-TR.pdf.
[29] G. Cheng, J. Han, and X. Lu, "Remote sensing image scene classification: Benchmark and state of the art," Proceedings of the IEEE, 2017.
[30] S. Ebrahimi, F. Meier, R. Calandra, T. Darrell, and M. Rohrbach, "Adversarial continual learning," Proc. of European Conference on Computer Vision (ECCV), 2020.
[31] Y. LeCun, "The mnist database of handwritten digits," http://yann. lecun. com/exdb/mnist/, 1998.
[32] H. Xiao, K. Rasul, and R. Vollgraf, "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms," arXiv preprint arXiv:1708.07747, 2017.
[33] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng, "Reading digits in natural images with unsupervised feature learning," in Advances in Neural Information Processing Systems, 2011.
[34] Y. Bulatov. (2011) notmnist dataset. [Online]. Available: http: //yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html
[35] X. Peng, Q. Bai, X. Xia, Z. Huang, K. Saenko, and B. Wang, "Moment matching for multi-source domain adaptation," in Proc. of the IEEE Intl. Conf. on Computer Vision (ICCV), 2019.
[36] G. Hinton, O. Vinyals, and J. Dean, "Distilling the knowledge in a neural network," in Advances in Neural Information Processing Systems - Workshop on Deep Learning, 2014.
[37] Z. Li and D. Hoiem, "Learning without forgetting," IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017.
[38] P. Dhar, R. V. Singh, K.-C. Peng, Z. Wu, and R. Chellappa, "Learning without memorizing," in Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2019.
[39] M. Masana, X. Liu, B. Twardowski, M. Menta, A. D. Bagdanov, and J. van de Weijer, "Class-incremental learning: survey and performance evaluation," IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.
[40] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska et al., "Overcoming catastrophic forgetting in neural networks," Proc. of the National Academy of Sciences, 2017.
[41] F. Zenke, B. Poole, and S. Ganguli, "Continual learning through synaptic intelligence," in Proc. of the Intl. Conf. on Machine Learning (ICML), 2017.
[42] K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for image recognition," in Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2016.
[43] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei, "ImageNet Large Scale Visual Recognition Challenge," Intl. Journal of Computer Vision (IJCV), 2015.
[44] P. Buzzega, M. Boschini, A. Porrello, D. Abati, and S. Calderara, "Dark experience for general continual learning: a strong, simple baseline," in Advances in Neural Information Processing Systems, 2020.
[45] G. I. Parisi, R. Kemker, J. L. Part, C. Kanan, and S. Wermter, "Continual lifelong learning with neural networks: A review," Neural Networks, 2019.
[46] R. Geirhos, P. Rubisch, C. Michaelis, M. Bethge, F. A. Wichmann, and W. Brendel, "Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness." in Proc. of the Intl. Conf. on Learning Representations (ICLR), 2019.
[47] T. Lesort, T. George, and I. Rish, "Continual learning in deep networks: an analysis of the last layer," arXiv preprint arXiv:2106.01834, 2021.
[48] V. V. Ramasesh, E. Dyer, and M. Raghu, "Anatomy of catastrophic forgetting: Hidden representations and task semantics," in Proc. of the Intl. Conf. on Learning Representations (ICLR), 2021.

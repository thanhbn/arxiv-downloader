# 2308.02084.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2308.02084.pdf
# Kích thước tệp: 1217876 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
1
Thích Ứng Mô Hình Hiệu Quả cho Học Liên Tục
tại Edge
Zachary A. Daniels, Jun Hu, Michael Lomnitz, Phil Miller, Aswin Raghavan, Joe Zhang, Michael Piacentino, và
David Zhang

Tóm tắt —Hầu hết các hệ thống học máy (ML) đều giả định phân phối dữ liệu tĩnh và khớp nhau trong quá trình huấn luyện và triển khai. Đây thường là một giả định sai. Khi các mô hình ML được triển khai trên các thiết bị thực, phân phối dữ liệu thường thay đổi theo thời gian do những thay đổi trong các yếu tố môi trường, đặc tính cảm biến và nhiệm vụ quan tâm. Mặc dù có thể có con người tham gia vào vòng lặp để giám sát các thay đổi phân phối và thiết kế các kiến trúc mới để đáp ứng những thay đổi này, nhưng thiết lập như vậy không hiệu quả về chi phí. Thay vào đó, cần có các mô hình AutoML (Machine Learning Tự động) không dừng. Bài báo này trình bày khung Encoder-Adaptor-Reconfigurator (EAR) để học liên tục hiệu quả dưới những thay đổi miền. Khung EAR sử dụng một bộ mã hóa đặc trưng mạng nơ-ron sâu (DNN) cố định và huấn luyện các mạng nông trên bộ mã hóa để xử lý dữ liệu mới. Khung EAR có khả năng 1) phát hiện khi dữ liệu mới là ngoài phân phối (OOD) bằng cách kết hợp DNN với tính toán siêu chiều (HDC), 2) xác định các adaptor nơ-ron tham số thấp để thích ứng mô hình với dữ liệu OOD bằng cách sử dụng tìm kiếm kiến trúc nơ-ron zero-shot (ZS-NAS), và 3) giảm thiểu việc quên thảm khốc các nhiệm vụ trước đó bằng cách phát triển kiến trúc nơ-ron dần dần khi cần thiết và định tuyến dữ liệu động qua các adaptor và reconfigurator phù hợp để xử lý học liên tục tăng dần miền và lớp. Chúng tôi đánh giá có hệ thống phương pháp của mình trên nhiều bộ dữ liệu chuẩn cho thích ứng miền và chứng minh hiệu suất mạnh so với các thuật toán tiên tiến cho phát hiện OOD và NAS few-/zero-shot.

Tuyên bố Tác động —Nói chung, các hệ thống ML giả định phân phối dữ liệu tĩnh và khớp nhau trong quá trình huấn luyện và triển khai. Trên thực tế, các hệ thống ML được triển khai gặp phải những thay đổi trong phân phối đầu vào theo thời gian, ví dụ, do các yếu tố môi trường. Giám sát con người trong vòng lặp cho những thay đổi phân phối và thiết kế thủ công các kiến trúc ML mới là tốn kém. Khung của chúng tôi tự động xác định khi nào xảy ra thay đổi miền và thích ứng kiến trúc nơ-ron để tính đến những thay đổi này. Trong các ứng dụng tính toán edge và Internet-of-Things (IoT), phần cứng được triển khai có tài nguyên tính toán hạn chế. So với nhiều phương pháp hiện có cho AutoML, chúng tôi tập trung vào các phương pháp nhanh, ít tốn kém tính toán cho phát hiện OOD và NAS để học các mô hình adaptor tham số thấp.

Từ khóa chỉ mục —AutoML, Học Liên tục, Tính toán Edge, Phát hiện Mẫu Ngoài Phân phối, Mạng Nơ-ron Tiến bộ, Tìm kiếm Kiến trúc Nơ-ron Zero-Shot

Được gửi: 31 tháng 5, 2023

Nghiên cứu này dựa trên công việc được hỗ trợ một phần bởi Văn phòng Giám đốc Tình báo Quốc gia (ODNI), Hoạt động Nghiên cứu Tiên tiến Tình báo (IARPA), qua Hợp đồng số: 2022-21100600001. Các quan điểm và kết luận được chứa trong tài liệu này là của các tác giả và không nên được hiểu là nhất thiết đại diện cho các chính sách chính thức, được thể hiện rõ ràng hoặc ngụ ý, của ODNI, IARPA, hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối bản sao cho mục đích chính phủ bất chấp bất kỳ chú thích bản quyền nào trong đó.

Tất cả các tác giả đều là nhà nghiên cứu tại Trung tâm Công nghệ Thị giác, SRI International, Princeton, New Jersey 08540 USA (email tác giả liên hệ: zachary.daniels@sri.com)

I. GIỚI THIỆU

TRONG ML truyền thống, người ta giả định rằng phân phối của các đặc trưng đầu vào và nhãn đầu ra không thay đổi một khi mô hình được huấn luyện; tức là, mô hình được khớp với một phân phối tĩnh của các đặc trưng trên một nhiệm vụ cụ thể, và trong quá trình suy luận/triển khai, mô hình được áp dụng cho cùng một nhiệm vụ với phân phối khớp của các đặc trưng đầu vào. Ngược lại, các mô hình ML được triển khai trên các thiết bị thế giới thực cho các ứng dụng liên quan đến IoT, tính toán edge và phân tích mạng cảm biến thường phải đối phó với sự thay đổi phân phối theo thời gian do những thay đổi trong 1) cảm biến (ví dụ, một mô hình được huấn luyện trên hình ảnh độ phân giải cao được áp dụng cho hình ảnh độ phân giải thấp), 2) không gian nhiệm vụ (ví dụ, một mô hình được huấn luyện để phát hiện một tập hợp phương tiện được tái sử dụng để phát hiện một tập hợp phương tiện khác), hoặc 3) môi trường (ví dụ, một mô hình được huấn luyện vào những ngày nắng được chạy trong cơn bão).

Mặc dù có thể có con người tham gia vào vòng lặp để giám sát các thay đổi phân phối và thiết kế các kiến trúc mới để tính đến những thay đổi này, nhưng thiết lập như vậy thường không hiệu quả về chi phí. Một thay thế thực tế hơn là phát triển một hệ thống ML có thể tự động xác định 1) khi nào phân phối của đầu vào và đầu ra đã thay đổi, và 2) xác định cách thích ứng kiến trúc của nó để xử lý phân phối dữ liệu mới trong khi duy trì hiệu suất trên các phân phối trước đó. Hơn nữa, đối với nhiều ứng dụng liên quan đến ML dưới sự thay đổi phân phối, việc thích ứng phải được thực hiện nhanh chóng trên phần cứng hạn chế tài nguyên. Công việc này đề xuất một phương pháp cho AutoML không dừng hiệu quả.

Cụ thể, chúng tôi tập trung vào vấn đề học liên tục tăng dần miền và lớp [1], [2] nơi các thay đổi phân phối trong không gian đầu vào và đầu ra xảy ra theo thời gian. Học liên tục tăng dần miền liên quan đến việc học cùng một loại vấn đề dưới các bối cảnh khác nhau (ví dụ, phương thức). Học liên tục tăng dần lớp liên quan đến việc học tăng dần để gán nhãn cho một tập hợp lớp ngày càng tăng, có thể dưới các bối cảnh khác nhau.

Trong các thí nghiệm của chúng tôi, chúng tôi xem xét bốn trường hợp thay đổi miền: 1) trong trường hợp cực đoan nhất, cả phương thức đầu vào và tập hợp nhãn đầu ra đều thay đổi, 2) phương thức đầu vào thay đổi, nhưng nhãn lớp vẫn giữ nguyên, 3) phương thức đầu vào vẫn giữ nguyên, nhưng tập hợp nhãn thay đổi, và 4) trong trường hợp tinh tế nhất, phương thức đầu vào và nhãn lớp vẫn giữ nguyên, nhưng các yếu tố môi trường thay đổi.

Mục tiêu của công việc này là học cách xác định khi nào phân phối dữ liệu đã thay đổi và nhanh chóng thích ứng các mô hình ML với các miền mới (AutoML không dừng) với tài nguyên tính toán hạn chế. Chúng tôi giới thiệu khung Encoder-Adaptor-Reconfigurator

--- TRANG 2 ---
2
(EAR), bao gồm ba thành phần:
• Encoder: Backbone trích xuất đặc trưng được huấn luyện trước cố định
• Adaptors: Các NN nông tạo điều kiện chuyển giao đặc trưng cho các phân phối dữ liệu mới
• Reconfigurator: Mô hình nhẹ cho phép thích ứng nhanh chóng với không gian nhiệm vụ mới với ít huấn luyện lại

Chúng tôi tập trung vào các vấn đề nghiên cứu về 1) cách xác định khi nào phân phối dữ liệu thay đổi, 2) cách phát triển mô hình ML khi cần thiết, cân bằng hiệu suất trên miền mới và hiệu quả mô hình, và 3) cách thực hiện học liên tục thông qua định tuyến dữ liệu động thông minh qua các adaptor/reconfigurator để giảm thiểu việc quên thảm khốc các miền trước đó. Bài báo này trình bày những đóng góp sau:

• Giới thiệu khung Encoder-Adaptor-Reconfigurator cho thích ứng mô hình hiệu quả với những thay đổi phân phối trên phần cứng hạn chế tài nguyên
• Công thức hóa và quy trình huấn luyện để học các adaptor-reconfigurator siêu chiều (HD) sâu [3] cho phát hiện OOD và phân loại mạnh mẽ kết hợp
• Công thức hóa phương pháp dựa trên phân tích phổ cho tìm kiếm kiến trúc nơ-ron zero-shot [4]
• Trình diễn khung EAR trong thiết lập học liên tục thông qua mạng nơ-ron tiến bộ [5], [6] với định tuyến dữ liệu động
• Hiệu suất cao so với các thuật toán tiên tiến cho phát hiện OOD và NAS few/zero-shot trên các bộ dữ liệu thích ứng miền chuẩn

II. NỀN TẢNG

A. Mạng Nơ-ron Tiến bộ cho Học Liên tục

Chúng tôi khám phá vấn đề học liên tục [1], [2] nơi một tác tử được huấn luyện trên một chuỗi các nhiệm vụ, và tác tử phải cân bằng tính dẻo dai so với tính ổn định: nó phải học giải quyết nhiệm vụ mới trong khi giảm thiểu việc quên (thảm khốc) các nhiệm vụ trước đó. Van de Ven et al. [2] đã phân loại học liên tục thành ba loại: tăng dần nhiệm vụ, miền và lớp. Học tăng dần nhiệm vụ liên quan đến việc giải quyết các chuỗi nhiệm vụ nơi tác tử được báo rõ ràng về nhiệm vụ quan tâm hiện tại. Trong thiết lập tăng dần miền, tác tử không biết nhiệm vụ quan tâm hiện tại là gì, nhưng cấu trúc của vấn đề không thay đổi giữa các nhiệm vụ (chỉ phân phối đầu vào thể hiện sự thay đổi), và tác tử có thể giải quyết nhiệm vụ hiện tại mà không cần xác định rõ ràng nhiệm vụ. Trong thiết lập tăng dần lớp, cấu trúc của vấn đề thay đổi theo thời gian (tức là, các tập hợp lớp mới được thêm vào). Trong trường hợp này, tác tử phải vừa xác định vừa sau đó giải quyết nhiệm vụ quan tâm hiện tại.

Khung EAR được thiết kế cho thiết lập tăng dần lớp đầy thử thách nhất, nhưng có thể được áp dụng một cách tầm thường cho các thiết lập tăng dần nhiệm vụ và miền.

Có ba phương pháp rộng để huấn luyện các tác tử học liên tục [7]. Các phương pháp dựa trên phát lại lưu các ví dụ của các nhiệm vụ đã gặp trước đó (một cách rõ ràng, thông qua các mẫu/nguyên mẫu, thông qua bộ nhớ sinh, hoặc trong các biểu diễn nén), và định kỳ phát lại những ví dụ này để giảm thiểu việc quên thảm khốc. Các phương pháp dựa trên chính quy hóa áp đặt các ràng buộc lên hành vi học của mạng (ví dụ, thông qua sửa đổi hàm mất mát) để ngăn mô hình quá khớp với nhiệm vụ mới và ghi đè kiến thức về các nhiệm vụ cũ. Các phương pháp dựa trên kiến trúc phát triển và cắt tỉa kiến trúc mô hình một cách thông minh. Khung EAR của chúng tôi là một phương pháp dựa trên kiến trúc cho học liên tục. Các phương pháp dựa trên kiến trúc khác bao gồm Mạng Nơ-ron Tiến bộ [5], [6], Mạng Mở rộng Động [8], "Nén, Chọn và Phát triển" [9], "Học để Phát triển" [10], và NN Bayesian Tiến bộ Toàn diện [11].

Kiến trúc EAR có thể được coi là một trường hợp đặc biệt của NN tiến bộ. NN tiến bộ phát triển các kết nối bên, do đó, tránh việc quên với chi phí tăng sử dụng tài nguyên. Khung EAR phát triển dần dần các adaptor và reconfigurator từ backbone encoder đặc trưng đóng băng. Để mở rộng NN tiến bộ, chúng tôi đề xuất một phương pháp mới để định tuyến dữ liệu động qua các adaptor/reconfigurator phù hợp, và chúng tôi sử dụng ZS-NAS để xác định nơi nên thêm các adaptor và cấu trúc của các adaptor.

B. Phát hiện Ngoài Phân phối với Mạng Nơ-ron Sâu

Phương pháp của chúng tôi nhằm tự động xác định khi nào phân phối đầu vào đã thay đổi (phát hiện OOD) [12]. Cụ thể, chúng tôi tập trung vào thiết lập phát hiện tính mới [13] nơi bộ phát hiện OOD chỉ thấy các mẫu trong phân phối (ID) trong quá trình huấn luyện. Mô hình của chúng tôi học các adaptor chiếu dữ liệu vào các biểu diễn đã học có thể được sử dụng cho phát hiện OOD và phân loại kết hợp. Có nhiều phương pháp phát hiện OOD với mạng sâu. Trong phương pháp cơ bản nhất, một mạng sâu được huấn luyện với cross-entropy tiêu chuẩn và vector đặc trưng ngay trước lớp phân loại được sử dụng để huấn luyện mô hình phát hiện OOD (ví dụ, sử dụng các thuật toán phát hiện OOD và tính mới cổ điển có sẵn như one-class SVM [14], ước lượng hiệp phương sai thực nghiệm và mạnh mẽ [15], yếu tố ngoại lai cục bộ [16], rừng cô lập [17], [18]). Thay vào đó, thống kê về phân phối xác suất softmax được xuất ra bởi mô hình mạng nơ-ron được huấn luyện trước có thể được phân tích để tách các mẫu OOD khỏi ID (ví dụ, [19]). Mở rộng vượt ra ngoài các phương pháp một lớp, các phương pháp tiên tiến kết hợp thông tin từ nhiều lớp của mạng được huấn luyện trước để phát hiện các mẫu OOD (ví dụ, ma trận gram [20] và kết hợp đặc trưng siêu chiều [21]). Cuối cùng, cấu trúc và huấn luyện của NN có thể được sửa đổi để học các biểu diễn được thiết kế cho phát hiện OOD và phân loại kết hợp, ví dụ, sử dụng học contrastive có giám sát kết hợp với bộ phân loại láng giềng gần nhất sâu [22]. Phương pháp của chúng tôi kết hợp phân tích đặc trưng đa lớp với các biểu diễn đã học, mở rộng phương pháp kết hợp đặc trưng HD bằng cách sử dụng các adaptor để tự động học các phép chiếu từ đặc trưng sang vector HD thay vì sử dụng các ma trận chiếu cố định ngẫu nhiên.

C. Tính toán Siêu chiều

Phương pháp của chúng tôi cho phát hiện OOD và phân loại được xây dựng xung quanh tính toán siêu chiều (HDC) [3], [23], [24]. HDC là một mô hình tính toán neuro-symbolic lấy cảm hứng từ nơ-ron biểu diễn các phần thông tin rời rạc dưới dạng các vector phân tán chiều cao, độ chính xác thấp. Trái ngược với DNN, HDC sử dụng năng lượng thấp, yêu cầu độ chính xác thấp, và đã được chứng minh là mạnh mẽ đối với các hỏng hóc trong dữ liệu đầu vào.

--- TRANG 3 ---
3
HDC được xây dựng dựa trên toán học thao tác các vector giả trực giao ngẫu nhiên trong không gian chiều cao. HDC được xây dựng xung quanh hai phép toán chính: 1) ràng buộc lấy hai vector đầu vào và tạo ra một vector mới không giống với mỗi đầu vào và 2) gộp (còn gọi là superposition) lấy hai hoặc nhiều vector đầu vào và tạo ra một vector mới tương tự với các đầu vào. Chúng tôi học các adaptor biểu diễn các đặc trưng theo lớp dưới dạng các vector nhị phân giả trực giao, và sau đó, các reconfigurator sử dụng bỏ phiếu đa số để gộp tất cả các mẫu từ một lớp thành một vector nguyên mẫu lớp nhị phân.

Các mẫu mới có thể được phân loại vào các lớp hiện có nếu vector HD của nó gần với một trong các vector nguyên mẫu lớp dựa trên khoảng cách hamming, hoặc có thể được phân loại là OOD nếu nó xa tất cả các nguyên mẫu lớp.

D. Tìm kiếm Kiến trúc Nơ-ron Zero-Shot

DNN đã được chứng minh tự nhiên tạo điều kiện cho học chuyển giao [25], thậm chí chỉ bằng cách tinh chỉnh (các) lớp cuối của mô hình. Tuy nhiên, khi có những thay đổi mạnh mẽ trong phân phối đầu vào hoặc không gian nhiệm vụ, việc tinh chỉnh chỉ các lớp cuối có thể không đủ, và việc tinh chỉnh toàn bộ mạng có thể tốn kém và dẫn đến việc quên thảm khốc các miền trước đó. Hơn nữa, một kiến trúc mạng được tối ưu cho một miền có thể không hoạt động tối ưu trên miền khác. Khung EAR đóng băng mạng encoder đặc trưng được huấn luyện trên một miền và học các tập hợp adaptor/reconfigurator khai thác encoder tại các vị trí khác nhau. Để tối ưu hiệu suất trên nhiệm vụ mới trong khi hạn chế sự phát triển của mô hình, cần thiết phải thiết kế cẩn thận các lớp adaptor và xác định các điểm khai thác nào sẽ tạo điều kiện tốt nhất cho học chuyển giao sang miền mới. Để xác định vị trí và cấu trúc của các adaptor và reconfigurator, chúng tôi sử dụng NAS [26].

NAS bao gồm ba thành phần:
• Không gian tìm kiếm là không gian các kiến trúc có thể được biểu diễn trong quá trình tìm kiếm
• Chiến lược tìm kiếm là thuật toán được sử dụng để tìm và kiểm tra các kiến trúc, cân bằng khám phá và khai thác. Các ví dụ bao gồm học tăng cường, tối ưu Bayesian và thuật toán tiến hóa.
• Chiến lược ước lượng hiệu suất: định lượng mức độ tốt của một kiến trúc, thước đo hiệu suất là gì, và các ràng buộc là gì.

Trong công việc này, không gian tìm kiếm xác định các adaptor trông như thế nào và nơi đặt chúng, chiến lược tìm kiếm tương thích với khung EAR của chúng tôi là bất kỳ chiến lược tối ưu toàn cục nào (chúng tôi sử dụng tối ưu Bayesian), và đóng góp mới chính của chúng tôi là xác định chiến lược ước lượng hiệu suất.

Khung EAR được dự định triển khai trên phần cứng ít tài nguyên và lý tưởng là thích ứng một cách nhanh chóng và hiệu quả. Vì những lý do này, chúng tôi tập trung vào tìm kiếm kiến trúc nơ-ron zero-shot [4], [27], [28]. ZS-NAS đánh giá các kiến trúc ứng viên mà không huấn luyện kiến trúc thông qua các heuristic proxy, dự đoán các thuộc tính tương quan với mức độ hoạt động tốt dự kiến của mô hình ứng viên sau khi được huấn luyện. Chúng tôi đề xuất một phương pháp dựa trên phân tích phổ của không gian đặc trưng của các adaptor, nhưng một số phương pháp ZS-NAS khác tồn tại, bao gồm snip [29], grasp [30],

Hình 1: Sơ đồ cấp cao của kiến trúc EAR

điểm số fisher [31], điểm số Jacobian-covariance [4], Synflow [32], grad-norm, Φ-Score [33], và Zen-NAS [33]. Hầu hết công việc đều công thức hóa heuristic proxy theo gradient của kiến trúc ứng viên trên một lô dữ liệu ngẫu nhiên. Ngược lại, phương pháp của chúng tôi sử dụng proxy không gradient, làm cho nó hiệu quả hơn về mặt tính toán.

III. PHƯƠNG PHÁP LUẬN

A. Khung Encoder-Adaptor-Reconfigurator cho Học Liên tục

Chúng tôi đề xuất khung EAR để xử lý thay đổi miền theo thời gian trong các thiết lập hạn chế tính toán (Hình 1). Khung bao gồm ba thành phần: một backbone encoder trích xuất đặc trưng được huấn luyện trước cố định, một tập hợp các adaptor NN nông tạo điều kiện chuyển giao đặc trưng cho các phân phối dữ liệu mới, và một reconfigurator nhẹ cho phép thích ứng nhanh chóng với không gian nhiệm vụ mới với ít huấn luyện lại.

Trong các thí nghiệm của chúng tôi, encoder là một DNN được huấn luyện trước trên bộ dữ liệu quy mô lớn và tinh chỉnh trên miền đầu tiên gặp; sau đó, nó được đóng băng. Khi mô hình gặp các miền mới, các adaptor nông, được kết nối bên vào các điểm khai thác của encoder, được học. Những adaptor này hiệu quả biến đổi các đặc trưng được điều chỉnh cho miền đầu tiên để hữu ích cho các miền tiếp theo. Các adaptor của chúng tôi bao gồm một vài lớp tích chập và dày đặc biến đổi các vector đặc trưng không hạn chế thành các vector đặc trưng HD nhị phân (Phần III-B). Các vector HD mỗi adaptor đầu ra cung cấp vào một reconfigurator là mô hình dự đoán cho miền mới (một bộ phát hiện và phân loại OOD kết hợp). Reconfigurator gộp tất cả các vector HD mỗi adaptor thành một vector HD tổng hợp duy nhất cho mỗi thể hiện đầu vào. Trong quá trình huấn luyện, các vector HD tổng hợp của tất cả dữ liệu trong tập huấn luyện từ một lớp duy nhất được gộp thành một nguyên mẫu duy nhất cho mỗi lớp. Trong quá trình suy luận, phân loại được thực hiện bằng cách so sánh vector HD tổng hợp của một thể hiện với tất cả các vector nguyên mẫu lớp được lưu trữ bởi reconfigurator. Thể hiện được gán lớp của nguyên mẫu gần nhất, hoặc nếu nó không gần với bất kỳ nguyên mẫu nào, nó được gán là OOD cho miền được liên kết với reconfigurator (chi tiết trong Phần III-B).

Trong Hình 2, chúng tôi cho thấy luồng điều khiển cấp cao của kiến trúc EAR trong kịch bản học liên tục. Chúng tôi giả định rằng mô hình chỉ thấy dữ liệu truyền từ một miền/nhiệm vụ duy nhất

--- TRANG 4 ---
4
Hình 2: Luồng điều khiển cho học liên tục sử dụng khung EAR

tại một thời điểm nhất định, nhưng miền/nhiệm vụ có thể thay đổi bất kỳ lúc nào. Do đó, mô hình cần hoạt động trên các chuỗi nhiệm vụ nơi ranh giới nhiệm vụ không được biết. Khi dữ liệu mới đến, nó được truyền qua encoder một lần và sau đó được truyền qua mỗi tập hợp adaptor/reconfigurator. Nếu dữ liệu là ID theo bất kỳ reconfigurator nào, thì nó được phân loại theo reconfigurator có khớp gần nhất (điểm số OOD nhỏ nhất). Khi một nhiệm vụ mới được gặp, các mẫu mới sẽ xuất hiện là OOD đối với tất cả reconfigurator. Một khi mô hình đủ tự tin rằng đã có sự thay đổi miền, nó sẽ xác minh với một nhà tiên tri (ví dụ, con người trong vòng lặp) rằng sự thay đổi đã xảy ra, và nó sẽ bắt đầu thu thập dữ liệu cho miền mới. Lưu ý rằng chúng tôi không thảo luận về cách tự động chú thích các mẫu mới trong bài báo này vì đó không phải là trọng tâm của chúng tôi, và do đó giả định tồn tại một nhà tiên tri cho mục đích này. Một khi bộ đệm đạt đến giới hạn dung lượng, nhà tiên tri ghi nhãn dữ liệu, và hệ thống sử dụng ZS-NAS (Phần III-C) để xác định cấu trúc và vị trí của một tập hợp adaptor và reconfigurator mới, được huấn luyện trên dữ liệu đã thu thập. Để xác định khi nào một miền/nhiệm vụ mới xuất hiện, mô hình giám sát liệu tỷ lệ của N mẫu dữ liệu cuối cùng được gán là OOD có lớn hơn một ngưỡng được chỉ định; sau đó, quá trình cập nhật được kích hoạt.

B. Tính toán Siêu chiều Sâu cho Phát hiện Mẫu Ngoài Phân phối và Phân loại Kết hợp

Wilson et al. đã chỉ ra rằng HDC [21] có thể được kết hợp với DNN được huấn luyện trước để phát hiện tính mới (tức là, khi bộ phát hiện OOD chỉ thấy dữ liệu ID trong quá trình huấn luyện). Phương pháp của họ chiếu các đầu ra của mọi lớp của NN được huấn luyện trước lên một vector ngẫu nhiên chiều cao thông qua phép toán ràng buộc. Các vector HD theo lớp được tổng hợp thành một vector duy nhất, và các vector nguyên mẫu HD được học cho mỗi lớp. Nếu vector HD của một thể hiện mới có khoảng cách lớn hơn một ngưỡng cố định đến tất cả các nguyên mẫu lớp, nó được gắn cờ là OOD.

Công việc này mở rộng phương pháp của Wilson et al. Tính mới của phương pháp chúng tôi là: 1) thay vì sử dụng các phép chiếu tuyến tính cố định ngẫu nhiên để ánh xạ các đầu ra theo lớp sang vector HD, chúng tôi sử dụng các adaptor để học các phép chiếu phi tuyến sang một tập hợp vector HD được xác định trước cố định; 2) chúng tôi thực hiện kết hợp từ một tập con nhỏ các lớp được xác định qua ZS-NAS thay vì mọi lớp; 3) chúng tôi chiếu sang các vector HD nhị phân thay vì các vector HD có giá trị thực, tiết kiệm bộ nhớ và cho phép tính toán nhẹ hơn; và 4) phương pháp của chúng tôi cho phép mô hình học thực hiện phát hiện-phân loại OOD kết hợp theo cách end-to-end, dẫn đến việc học biểu diễn phân biệt hơn.

1) Mô hình Cơ bản cho Phân loại: Để bắt đầu, chúng tôi giải thích cách các adaptor có thể học một mô hình phân loại bằng cách ánh xạ các mẫu đầu vào sang vector HD sử dụng kết hợp các NN và các phép toán HDC. Đối với một miền cụ thể, cho một mẫu đầu vào x, một adaptor f^tap_ada(.) ánh xạ các đặc trưng từ một điểm khai thác tap của mô hình encoder f_enc(.) sang một vector HD nhị phân h^tap_ada(.):

π^tap_ada(x) = f^tap_ada(f_enc(x)),
h^tap_ada(x) = lấy mẫu phần tử i
                 là 1 với xác suất π^tap,(i)_ada(x),
                 là 0 với xác suất 1−π^tap,(i)_ada(x)
∀i∈[0, len(h^tap_ada(x))]                    (1)

Các adaptor dự đoán một điểm số từ 0 đến 1 cho mỗi phần tử của vector HD (ví dụ, thông qua kích hoạt sigmoid). Để đưa vector đầu ra giả nhị phân này thành vector HD nhị phân, chúng tôi lấy mẫu mỗi phần tử theo điểm số theo phần tử.

Reconfigurator phục vụ hai mục đích:
1) Nó tổng hợp các vector HD trên tập hợp tất cả adaptor A cho miền thành một vector HD h_agg(.) bằng cách gộp:
   h_agg(x) = round(1/|A| ∑_(tap,ada)∈A h^tap_ada(x))    (2)

2) Nó học các nguyên mẫu cho mỗi lớp h^class_proto cho miền bằng cách gộp tất cả các thể hiện huấn luyện từ một lớp X_C:
   h^class_proto = round(1/|X_C| ∑_x_c∈X_C h_agg(x_c))    (3)

Để gán nhãn lớp cho một thể hiện đầu vào x, chúng tôi tính toán h_agg(x) và chọn lớp có khoảng cách hamming nhỏ nhất:
ŷ(x) = argmin_class d_hamming(h_agg(x), h^class_proto)    (4)

2) Huấn luyện các Adaptor: Để huấn luyện các adaptor, đầu tiên chúng tôi tạo ra một vector HD duy nhất cho mỗi lớp cho mỗi adaptor (tức là, cho mười lớp và năm adaptor, năm mười vector giả trực giao được tạo ra) thông qua Thuật toán 1 (⊗ là tích Kronecker).

Thuật toán 1 đầu tiên tạo ra một ma trận trực giao đối xứng thỏa mãn {−1,1}^n×n. Hàng và cột đầu tiên của ma trận được loại bỏ để cải thiện tính ổn định của việc huấn luyện các adaptor.

--- TRANG 5 ---
5
Thuật toán 1 Thuật toán tạo vector HD nhị phân
Yêu cầu: n > k
Yêu cầu: n là lũy thừa của hai
k ← số lớp × số adaptor
n ← chiều của vector HD + 1
C ← [1 1]
     [1 -1]
C₀ ← clone(C)
i = 0
while i < log₂(n/2) do
    C ← C₀ ⊗ C
    i ← i + 1
end while
C ← C[1:n, 1:n]
Trộn các hàng của C
C ← C[0:k, 0:n-1]
C[C = -1] ← 0

Mặc dù điều này phá vỡ tính trực giao, ma trận vẫn giữ tính giả trực giao. Các hàng của ma trận được trộn (giúp ổn định việc huấn luyện các adaptor), và các vector HD cho mỗi kết hợp adaptor và nhãn lớp được chọn. Cuối cùng, tất cả các phần tử của vector HD là -1 được đặt thành 0.

Chúng tôi chọn chiều của vector HD là 2^⌈log₂(#adaptor * #lớp + 1)⌉ - 1. Điều này đảm bảo rằng cho mỗi cặp adaptor-lớp, sẽ có một vector (giả-)trực giao lẫn nhau duy nhất. Vector này phục vụ như đầu ra mục tiêu cho bất kỳ mẫu dữ liệu nào của lớp cụ thể đi qua adaptor tương ứng. Bằng cách ép buộc tính trực giao giữa các vector HD qua các adaptor bằng cách xây dựng các vector HD mục tiêu, các phép toán ràng buộc không cần thiết trong quá trình tổng hợp.

Để ánh xạ từ đầu vào x sang các vector HD mục tiêu cho một adaptor, chúng tôi coi ánh xạ như một vấn đề phân loại đa nhãn nhị phân chiều cao. Chúng tôi sử dụng mất mát cross-entropy tiêu điểm nhị phân có trọng số [34] được tính trung bình trên mọi phần tử i của vector HD được dự đoán, buộc các adaptor tập trung vào các mẫu khó phân loại hơn trong quá trình huấn luyện:

ℓ_foc = 1/#dims ∑ᵢ₌₀^#dims -αᵢ * (1 - p_target^(i))^γ * log(p_target^(i))  (5)

p_target^(i) là xác suất phần tử i được xuất ra bởi adaptor được gán cho giá trị mục tiêu đúng của nó, α là một thuật ngữ trọng số điều chỉnh cho sự mất cân bằng (được tính từ dữ liệu huấn luyện) trong các "nhãn" theo phần tử nhị phân, và γ là một hằng số kiểm soát mức độ tập trung được đặt lên các mẫu khó phân loại hơn (gamma = 2 trong các thí nghiệm của chúng tôi).

Ngoài việc cho phép kết hợp đặc trưng dễ dàng giữa các adaptor, có những lý do thực tế khác để chiếu sang các vector HD lớp mục tiêu nhị phân tại mỗi adaptor. Mọi lớp cho mọi adaptor được gán một vector HD duy nhất. Mục tiêu là ánh xạ tất cả các thể hiện đầu vào sang vector HD tương ứng với nhãn lớp của chúng cho adaptor đã cho. Để học ánh xạ này, nếu mỗi vector HD có chiều D, thì một bộ phân loại nhị phân được học cho mỗi trong số D chiều. Bởi vì mỗi phần tử được gán 0 hoặc 1 ngẫu nhiên và tất cả các thể hiện từ cùng một lớp chia sẻ một vector lớp mục tiêu, điều này có nghĩa hiệu quả rằng mô hình đang học dự đoán một phân vùng ngẫu nhiên của các lớp thành hai meta-nhãn cho mỗi phần tử của vector HD. Bởi vì các vector HD mục tiêu trực giao lẫn nhau cho mỗi lớp, những bộ phân loại D này có tính dư thừa thấp. Ánh xạ sang vector HD có thể được coi như một phương pháp ensemble nơi mỗi adaptor tạo thành một bộ phân loại đa lớp mạnh bằng cách ensemble nhiều bộ phân loại nhị phân yếu có tính dư thừa thấp. Hơn nữa, việc gộp giữa các adaptor là một hình thức ensemble khác có nguyên tắc toán học. Kết hợp tất cả những đặc tính này, ánh xạ từ đầu vào sang embedding vector HD cuối cùng cuối cùng dẫn đến các mô hình phân biệt cao với khả năng chịu nhiễu cao.

3) Phát hiện Ngoài Phân phối: Để xác định liệu một mẫu có phải OOD cho một reconfigurator nhất định, vector HD tổng hợp được tính toán và so sánh với các vector nguyên mẫu HD lớp trong reconfigurator. Nếu khoảng cách hamming tối thiểu đến bất kỳ nguyên mẫu nào lớn hơn một ngưỡng cố định τ, thì mẫu được dự đoán là OOD:

ood(x) = min_class d_hamming(h_agg(x), h^class_proto) > τ  (6)

Điều này hoạt động tốt nếu chúng ta chỉ quan tâm đến việc xác định liệu một mẫu có OOD cho một miền duy nhất. Thường trường hợp chúng ta cần xác định liệu một mẫu có OOD trên tất cả các miền, hoặc chúng ta cần xác định tập hợp adaptor/reconfigurator nào mà dữ liệu nên được định tuyến qua khi kiến thức về miền thực không được biết. Những trường hợp như vậy có thể yêu cầu các ngưỡng khác nhau cho reconfigurator, và điểm số OOD của mỗi reconfigurator có thể không so sánh được một-một (ví dụ, nếu tự nhiên dễ dàng hơn để (quá)khớp một tập hợp adaptor với một miền so với miền khác, đặc tính nhiễu có thể làm cho khoảng cách đến nguyên mẫu gần nhất không thể so sánh trực tiếp). Do đó, chúng ta cần một điểm số OOD được hiệu chỉnh có thể so sánh được giữa các tập hợp adaptor.

Để có được điểm số OOD được hiệu chỉnh này, chúng tôi khớp một phân phối xác suất trên khoảng cách đến nguyên mẫu gần nhất cho tập huấn luyện. Dựa trên công việc trong lý thuyết giá trị cực trị và phân loại tập hợp mở [35], chúng tôi khớp một phân phối Weibull 3-Tham số [36] với các mẫu ID:

PDF_weib(x) = {
    (b/a)(x-c/a)^(b-1) exp(-(x-c/a)^b), nếu x > c
    0, nếu x ≤ c
}  (7)

Trong Phương trình 7, a là tham số tỷ lệ, b là tham số hình dạng, và c là tham số vị trí. Những tham số này được khớp thông qua ước lượng likelihood tối đa, và nói chung, tham số vị trí trở thành không, đơn giản hóa thành phân phối Weibull 2-Tham số. Trong Hình 3, chúng tôi cho thấy một phân phối Weibull được khớp với dữ liệu ID. Dữ liệu có xu hướng có đuôi phải mạnh, và do đó, chúng ta cần một phân phối biểu cảm hơn Gaussian.

Một khi phân phối được khớp, chúng ta có thể chấm điểm các mẫu dựa trên khả năng dữ liệu là ID. Chúng tôi sử dụng CDF của phân phối Weibull được khớp để tính toán xác suất rằng khoảng cách giữa một mẫu trong phân phối ngẫu nhiên và nguyên mẫu lớp gần nhất của nó nhỏ hơn khoảng cách giữa mẫu quan sát và nguyên mẫu gần nhất của nó. Chúng tôi chọn một ngưỡng cứng về xác suất τ_π để đưa ra dự đoán cuối cùng về

--- TRANG 6 ---
6
Hình 3: Ước lượng phân phối của các mẫu ID sử dụng phân phối Weibull; so sánh mật độ của dữ liệu ID và OOD được xác định bởi khoảng cách đến nguyên mẫu lớp gần nhất

liệu mẫu có OOD cho mỗi reconfigurator:

ood(x) = CDF_weib(min_class d_hamming(h_agg(x), h^class_proto)) > τ_π  (8)

C. Phương pháp Dựa trên Phân tích Phổ cho Tìm kiếm Kiến trúc Nơ-ron Zero-Shot để Thích ứng

Cuối cùng, chúng ta cần xác định cách phát triển tập hợp adaptor/reconfigurator khi các miền mới được gặp bằng cách sử dụng NAS. NAS truyền thống có thể cực kỳ tốn kém, mất nhiều GPU-ngày để thực hiện. Mục tiêu của chúng tôi là để NAS được thực hiện trên phần cứng tính toán nhẹ; do đó, chúng ta không có ngân sách tính toán để chạy NAS đầy đủ. Chúng tôi cải thiện hiệu quả của NAS theo hai cách: 1) chúng tôi đóng băng backbone trích xuất đặc trưng và chỉ tìm kiếm kiến trúc của các lớp adaptor nông, giảm đáng kể không gian tìm kiếm kiến trúc ứng viên và cải thiện tốc độ huấn luyện mô hình, và 2) chúng tôi sử dụng ZS-NAS nơi chúng tôi tránh huấn luyện các kiến trúc ứng viên, thay vào đó đánh giá chất lượng mô hình ứng viên thông qua heuristic proxy. Chúng tôi định nghĩa NAS của mình như sau:

• Không gian Tìm kiếm: Định nghĩa adaptor/reconfigurator trong các ràng buộc tham số hợp lý được chỉ định bởi con người
• Chiến lược Tìm kiếm: Lựa chọn ứng viên thông qua bộ tối ưu toàn cục; chúng tôi sử dụng tối ưu Bayesian sử dụng Ranh giới Tin cậy Trên Quá trình Gaussian [37], [38] với giảm miền tuần tự [39] như hàm thu thập
• Chiến lược Ước lượng Hiệu suất: Heuristic proxy zero-shot thông qua phân tích phổ của đồ thị láng giềng gần nhất của một lô ngẫu nhiên các mẫu đầu vào

Proxy cho ZS-NAS thường nhằm tối đa hóa một trong các thuộc tính sau: biểu cảm, khả năng huấn luyện, hoặc tổng quát hóa [40]. Những phương pháp này thường yêu cầu tính toán hoặc xấp xỉ gradient trên một hoặc nhiều lô dữ liệu ngẫu nhiên. Tính toán và lưu trữ gradient có thể tốn kém về mặt tính toán và bộ nhớ. Chúng tôi đề xuất một heuristic proxy không gradient. Hơn nữa, các phương pháp ZS-NAS hiện có không giả định việc sử dụng mạng backbone đóng băng và có thể không hoạt động như mong đợi khi được sử dụng với khung EAR. Phương pháp của chúng tôi xem xét các thuộc tính độc đáo của kiến trúc EAR cho trường hợp sử dụng hạn chế tài nguyên:

• Tối đa hóa tính biểu cảm của các biểu diễn của mỗi adaptor giả định một encoder được huấn luyện trước cố định
• Giảm thiểu tính dư thừa của các biểu diễn được học qua tất cả adaptor
• Giảm thiểu số lượng tham số có thể huấn luyện

Mục tiêu đầu tiên của ZS-NAS của chúng tôi là tối đa hóa tính biểu cảm của mỗi adaptor. Một lô ngẫu nhiên dữ liệu được truyền qua mỗi adaptor được khởi tạo ngẫu nhiên, chưa được huấn luyện và các đặc trưng được trích xuất từ lớp đứng trước phép chiếu cuối cùng sang không gian HD. Laplacian của đồ thị láng giềng gần nhất 2 L được tính toán cho lô mẫu này trong không gian đặc trưng "ngẫu nhiên". Encoder đã trích xuất các biểu diễn hữu ích, vì vậy chúng ta không muốn học các adaptor làm suy thoái đặc trưng thành một điểm đơn lẻ hoặc xáo trộn các đặc trưng thành một không gian đồng nhất. Chúng tôi giả thuyết rằng một adaptor biểu cảm sẽ dẫn đến một cảnh quan đặc trưng gồ ghề được đặc trưng bởi các cụm nhỏ điểm dữ liệu. Điều này có thể đạt được bằng cách tối đa hóa số lượng thành phần liên kết trong đồ thị láng giềng gần nhất. Laplacian được phân tách thành Eigenvalue λ và Eigenvector v⃗. Số lượng thành phần liên kết của đồ thị láng giềng gần nhất được tính bằng cách đếm số lượng Eigenvalue có giá trị 0 [41]. Chúng tôi nới lỏng ràng buộc rằng điểm số tỷ lệ thuận trực tiếp với số lượng thành phần liên kết, và thay vào đó, xây dựng một điểm số sử dụng số lượng thành phần liên kết lỏng lẻo (γ kiểm soát tính nghiêm ngặt của việc đếm thành phần liên kết; chúng tôi đặt γ = 3):

s_exp^ada = ∑_i max(1 - λ_i^ada, 0)^γ  (9)

Mục tiêu thứ hai của phương pháp của chúng tôi là giảm thiểu tính dư thừa của các biểu diễn được học qua tất cả adaptor. Chúng tôi tái sử dụng Eigenvalue và Eigenvector từ tính toán trước đó và thực hiện phân cụm phổ [42] cho mỗi adaptor sử dụng phương pháp của Damle et al. [43]. Số lượng cụm được đặt dựa trên số lượng Eigenvalue nhỏ hơn 0.1. Điểm số dư thừa s_red đo sự trùng lặp cụm sử dụng metric thông tin tương hỗ điều chỉnh [44] giữa tất cả các cặp adaptor.

Mục tiêu cuối cùng là giảm thiểu số lượng tham số adaptor/reconfigurator có thể huấn luyện. s_par đơn giản đếm số lượng tham số có thể huấn luyện qua tất cả các lớp adaptor.

Heuristic proxy cuối cùng cho điểm số ZS-NAS được đề xuất của chúng tôi là một tổng có trọng số của ba điểm số thành phần:

s = ∑_tất cả adaptor s_exp^ada + β₀ * ∑_tất cả adaptor s_par^ada + β₁ * ∑_tất cả cặp adaptor s_red^ada_i,ada_j  (10)

Trong các thí nghiệm của chúng tôi, β₀ được đặt thành 3*10⁻⁶ và β₁ được đặt thành 5.

IV. KẾT QUẢ

Chúng tôi xác thực phương pháp của mình trên bốn bộ dữ liệu chuẩn so với các thuật toán chuẩn tiên tiến cho phát hiện OOD với DNN và ZS-NAS.

--- TRANG 7 ---
7
A. Thiết lập Thí nghiệm

Các thí nghiệm của chúng tôi được tiến hành trên một máy có hai CPU Intel Xeon Gold 6240R với 24 lõi/48 luồng mỗi cái, một NVidia A5000 với 24 GB VRAM, và 500 GB RAM. Chúng tôi triển khai các mô hình của mình bằng Python sử dụng TensorFlow 2 ở chế độ biên dịch. Mạng encoder của chúng tôi là một mô hình EfficientNetV2B3 [45]. Chúng tôi sử dụng bộ tối ưu Adam [46] với tốc độ học 0.001 không có weight decay để học các biểu diễn HD, tốc độ học 0.005 với tham số weight decay 10⁻⁵ để huấn luyện NN cơ bản dựa trên cross-entropy, và tốc độ học 0.001 và weight decay 10⁻⁷ cho mô hình láng giềng gần nhất sâu được huấn luyện với mất mát contrastive có giám sát [47]. Để huấn luyện NN, chúng tôi sử dụng kích thước lô 128 và huấn luyện trong 40 epoch. Đối với các thí nghiệm OOD và ZS-NAS, chúng tôi chạy 15 lần thử với các seed ngẫu nhiên khác nhau cho mỗi thiết lập thí nghiệm và các phân chia tập dữ liệu huấn luyện/kiểm tra khác nhau.

B. Bộ dữ liệu

Chúng tôi đánh giá trên các biến thể của bốn bộ dữ liệu chuẩn: PACS [48], Office 31 [49], Office Home [50], và DomainNet [51]. Chúng tôi tập trung vào trường hợp sử dụng nơi dữ liệu bị hạn chế (thường <100 mẫu huấn luyện cho mỗi lớp). Chúng tôi đánh giá phát hiện OOD từ bốn góc độ, đòi hỏi xây dựng các biến thể của các bộ dữ liệu nói trên: 1) cả phương thức đầu vào và tập hợp nhãn lớp đầu ra đều thay đổi (Office Home - Miền/Lớp Rời rạc), 2) phương thức đầu vào thay đổi, nhưng nhãn lớp vẫn giữ nguyên (PACS), 3) phương thức đầu vào vẫn giữ nguyên, nhưng nhãn lớp thay đổi (Office 31 - Lớp Phân tách), và 4) phương thức đầu vào và nhãn lớp vẫn giữ nguyên, nhưng các yếu tố môi trường thay đổi (Office 31). Đối với thí nghiệm học liên tục của chúng tôi, chúng tôi sửa đổi bộ dữ liệu DomainNet bằng cách chọn hai mười lớp từ ba phương thức khác nhau, mỗi lớp có 4000 mẫu, chia thành sáu nhiệm vụ rời rạc. Thống kê của các bộ dữ liệu xuất hiện trong Bảng I.

[Bảng I - chi tiết thống kê các bộ dữ liệu]

C. Phát hiện Tính mới và Phân loại sử dụng HDC Sâu

Trong tập hợp thí nghiệm đầu tiên, chúng tôi lấy một mạng với encoder EfficientNetV2B3 được huấn luyện trước trên Imagenet, và chúng tôi tinh chỉnh toàn bộ mạng trên miền đầu tiên quan tâm cho phân loại hình ảnh và phát hiện OOD. Sau đó chúng tôi áp dụng mạng cho các mẫu hỗn hợp từ tập kiểm tra của miền ID và miền OOD chưa thấy. Để giảm thiểu ảnh hưởng của việc huấn luyện trước Imagenet, miền đầu tiên luôn bao gồm một phương thức được căn chỉnh chặt chẽ với hình ảnh tự nhiên. Chúng tôi xem xét năm kiểu huấn luyện: 1) huấn luyện encoder cộng với perceptron 2 lớp sử dụng cross-entropy tiêu chuẩn, 2) huấn luyện encoder cộng với lớp embedding cho láng giềng gần nhất sâu sử dụng mất mát contrastive có giám sát [22], 3) huấn luyện encoder cộng với adaptor/reconfigurator HD lớp cuối duy nhất, 4) huấn luyện encoder cộng với adaptor HD perceptron 2 lớp cho bảy điểm khai thác (khối 1, 4, 7, 12, 19, 31, và "head" từ mô hình EfficientNetV2B3) và một reconfigurator cuối cùng, và 5) huấn luyện encoder, adaptor HD có điểm khai thác (tập con của các điểm khai thác trước đó) và kiến trúc được xác định bằng ZS-NAS, và reconfigurator.

Để so sánh với các mạng không được thiết kế rõ ràng cho phát hiện OOD, chúng tôi huấn luyện các thuật toán phát hiện OOD hậu kỳ trên một trong i) các đặc trưng ngay trước lớp phân loại, ii) các xác suất đầu ra softmax, hoặc iii) sử dụng các đầu ra đặc trưng của tất cả 32 lớp trong mạng encoder. Đối với thiết lập (i), chúng tôi xem xét các thuật toán phát hiện OOD và tính mới cổ điển có sẵn: one-class SVM [14], ước lượng hiệp phương sai thực nghiệm và mạnh mẽ [15], yếu tố ngoại lai cục bộ [16], và rừng cô lập [17], [18] như được triển khai trong scikit-learn. Đối với thiết lập (ii), chúng tôi sử dụng baseline sâu cho phát hiện OOD được đề xuất bởi Hendrycks và Gimpel [19]. Đối với thiết lập (iii), chúng tôi xem xét hai phương pháp tiên tiến: sử dụng ma trận gram theo lớp [20] và kết hợp đặc trưng siêu chiều [21]. Chúng tôi cũng so sánh với láng giềng gần nhất sâu, được thiết kế cho phát hiện OOD và phân loại kết hợp.

Chúng tôi xem xét các metric sau để đánh giá:
• Độ chính xác phân loại của các mẫu kiểm tra ID để đo khả năng phân biệt
• Khi các mẫu ID và OOD chia sẻ nhãn lớp, chúng tôi cũng kiểm tra độ chính xác phân loại của các mẫu kiểm tra OOD để đo chuyển giao kiến thức/mạnh mẽ bẩm sinh đối với nhiễu từ các thay đổi phân phối
• Để đo hiệu suất trên phát hiện OOD, chúng tôi tính toán:
  - Diện tích dưới đường cong receiver-operator (AUROC) khi các mẫu ID được coi là lớp dương
  - Macro-F1-measure của việc dự đoán ID so với OOD
  - Tỷ lệ Âm Thực tế True Negative Rate tại Tỷ lệ Dương Thực tế True Positive Rate 95% (TNR@TPR95) và 90% (TNR@TPR90) nơi dữ liệu ID được coi là lớp dương
• Số lượng tham số, adaptor và chiều embedding để có cảm giác về hiệu quả và dung lượng mô hình

Trong các trường hợp cần một quyết định nhị phân, chúng tôi đánh giá so với ngưỡng tối ưu trên các hàm chấm điểm. Lưu ý rằng những bộ dữ liệu này tương đối thách thức cho vấn đề phát hiện OOD; do đó, một số metric, thậm chí sử dụng các thuật toán tiên tiến cho OOD, thấp so với việc chạy những thuật toán này trên các bộ dữ liệu chuẩn phát hiện OOD khác. Chúng tôi

--- TRANG 8 ---
8
cũng áp dụng kiểm định Kruskal-Wallis (ANOVA phi tham số) so sánh hiệu suất của các thuật toán OOD khác nhau trong một thiết lập thí nghiệm cụ thể tiếp theo bởi kiểm định Dunn hậu kỳ với hiệu chỉnh Bonferroni để xác định thuật toán OOD nào khác biệt với mô hình HD sâu dựa trên ZS-NAS theo cách có ý nghĩa thống kê (p-value của 0.05). Trong các bảng kết quả thí nghiệm ⊙ đại diện cho không thể xác định được phát hiện có ý nghĩa thống kê, ⊕ đại diện cho mô hình HD ZS-NAS tốt hơn đáng kể so với bộ so sánh, và ⊖ đại diện cho mô hình HD ZS-NAS tệ hơn đáng kể so với bộ so sánh.

Trong Bảng II, IV, VI, và VIII, chúng tôi xem xét cách hiệu suất phân loại của phương pháp được đề xuất bị ảnh hưởng bởi các loại thay đổi miền khác nhau. Chúng tôi nhận thấy các xu hướng sau:
• Các phương pháp dựa trên HD đã học vượt trội hơn các phương pháp tiêu chuẩn và dựa trên láng giềng gần nhất sâu về độ chính xác ID khoảng ~2-7% trên tất cả các bộ dữ liệu
• Việc thêm adaptor perceptron đa lớp một cách ngây thơ vào tất cả các điểm khai thác ứng viên có thể dẫn đến hiệu suất phân loại được cải thiện nhẹ, nhưng với chi phí tăng đáng kể số lượng tham số mô hình.
• Các adaptor được xác định bởi ZS-NAS thường sử dụng các kiến trúc nhỏ hơn đáng kể trong khi chỉ thể hiện giảm hiệu suất nhỏ so với thiết lập "tất cả lớp" và vượt trội các mô hình không dựa trên HD.
• Việc chỉ học một adaptor lớp cuối duy nhất là một baseline mạnh, khớp hiệu suất với mô hình ZS-NAS về độ chính xác phân loại trong hầu hết các trường hợp.
• Thú vị, khi áp dụng mô hình được huấn luyện trên một miền cho một miền khác với cùng tập hợp lớp, các mô hình dựa trên HD đã học vượt trội đáng kể các mô hình không dựa trên HD về độ chính xác, gợi ý rằng biểu diễn HD mạnh mẽ hơn đối với nhiễu gây ra bởi thay đổi phân phối. Điều này đặc biệt rõ ràng đối với các miền tương tự về mặt tri giác, ví dụ, chuyển từ hình ảnh tự nhiên sang tranh vẽ photorealistic. Mô hình "tất cả lớp" tổng quát hóa tệ hơn mô hình ZS-NAS.

Trong Bảng III, V, VII, và IX, chúng tôi xem xét cách hiệu suất phát hiện OOD bị ảnh hưởng bởi các loại thay đổi miền khác nhau. Chúng tôi nhận thấy các xu hướng sau:
• Bất kể thiết lập, các mô hình dựa trên HD đã học khớp hoặc vượt hiệu suất của các mô hình khác.
• Mô hình HD "tất cả lớp" thỉnh thoảng hoạt động kém hơn về nhiệm vụ phát hiện mẫu OOD so với các mô hình HD "lớp cuối" và ZS-NAS (ví dụ, trong nhiệm vụ chuyển PACS photo-to-sketch). Điều này đặc biệt rõ ràng khi nhìn vào các metric TNR@TPR.

D. So sánh các Phương pháp NAS Khác nhau

Trong tập hợp thí nghiệm thứ hai, chúng tôi so sánh phương pháp ZS-NAS được đề xuất ("phổ") với các phương pháp NAS hiện có. Chúng tôi tinh chỉnh encoder và học một tập hợp adaptor trên miền đầu tiên, và sau đó đóng băng encoder và học một tập hợp adaptor trên miền thứ hai. Chúng tôi so sánh với việc thêm adaptor lớp cuối và tinh chỉnh toàn bộ mạng trên nhiệm vụ thứ hai, thêm adaptor lớp cuối mà không tinh chỉnh encoder, chọn ngẫu nhiên vị trí và kiến trúc

[Nhiều bảng so sánh hiệu suất được liệt kê - Bảng II đến IX]

--- TRANG 9 ---
9
[Tiếp tục từ trang trước với các bảng so sánh và phương pháp NAS khác nhau]

của tập hợp adaptor, sử dụng NAS few-shot (với một epoch huấn luyện duy nhất cho mỗi đánh giá ứng viên), và so sánh với các heuristic proxy zero-shot khác: tính toán chuẩn ℓ2 của gradient (grad norm) của các kiến trúc ứng viên, synflow (được thiết kế để tối đa hóa độ thưa của các kiến trúc ứng viên) [32], và điểm số ϕ [33] và Jacobian-covariance (jacob cov) [4], cố gắng tối đa hóa tính biểu cảm mạng. Trong tất cả các trường hợp, chúng tôi thêm spar (được chia tỷ lệ bằng thử nghiệm và sai lầm) vào heuristic cơ bản

[Bảng X về so sánh các phương pháp tìm kiếm kiến trúc nơ-ron]

để hạn chế dấu chân bộ nhớ của tập hợp adaptor. Chúng tôi đánh giá các phương pháp dựa trên độ chính xác của tập hợp adaptor trên dữ liệu kiểm tra miền mới và về hiệu quả tính toán và bộ nhớ được xác định bởi số lượng tham số có thể huấn luyện, thời gian thực hiện NAS, số lượng adaptor và kích thước embedding. Một lần nữa chúng tôi sử dụng

--- TRANG 10 ---
10
kiểm định ANOVA Kruskal-Wallis với kiểm định Dunn hậu kỳ với hiệu chỉnh Bonferroni (p-value của 0.05). Kết quả xuất hiện trong Bảng X. Chúng tôi quan sát:

• Phương pháp phổ đạt được độ chính xác bằng hoặc cao hơn phương pháp ZS-NAS tốt nhất tiếp theo trong tất cả các thiết lập.
• Trong hầu hết các trường hợp, phương pháp phổ tốt như hoặc tốt hơn việc tinh chỉnh toàn bộ mạng về độ chính xác.
• Một lần nữa, việc học một adaptor lớp cuối là một baseline mạnh một cách ngạc nhiên.
• Phương pháp phổ nhanh hơn 2-7x để đánh giá heuristic so với các phương pháp ZS-NAS khác (lưu ý rằng những phương pháp này được tái triển khai bởi các tác giả và có thể không nhất thiết được tối ưu hoàn toàn).
• Kích thước của các tập hợp adaptor được xác định bởi phương pháp được đề xuất thường trong cùng bậc độ lớn với các phương pháp khác, nhưng phương pháp phổ có vẻ linh hoạt hơn để phát triển và thu nhỏ khi cần thiết. Ví dụ, trên bộ dữ liệu Office 31, phương pháp phổ tìm thấy một mô hình khoảng 2-3 lần kích thước của các phương pháp khác nhưng đạt được tăng 13% độ chính xác so với phương pháp ZS-NAS tốt nhất tiếp theo.

E. Phát hiện OOD và Định tuyến Dữ liệu Động với Nhiều Tập hợp Adaptor/Reconfigurator

Trong phần này, chúng tôi xem xét cách mô hình hoạt động khi có hai tập hợp adaptor/reconfigurator cho hai miền riêng biệt, và dữ liệu phải được định tuyến phù hợp đến tập hợp adaptor đúng. Chúng tôi xem xét năm metric: 1) độ chính xác của việc áp dụng các adaptor từ miền thứ hai cho dữ liệu kiểm tra từ miền thứ hai để xác minh rằng mô hình học các mô hình mạnh trên miền mới mặc dù sử dụng mô hình encoder đóng băng, 2) áp dụng các adaptor từ miền thứ hai cho dữ liệu kiểm tra OOD từ miền đầu tiên để xem liệu có sự mạnh mẽ bẩm sinh nào đó đối với nhiễu từ thay đổi phân phối trong mô hình, 3) macro-F1-measure, đo mức độ tốt của việc định tuyến dữ liệu đến tập hợp adaptor phù hợp, 4) "điểm số định tuyến độ chính xác kết hợp", là độ chính xác của việc định tuyến kết hợp đến tập hợp adaptor đúng và sau đó đưa ra dự đoán đúng, và 5) "điểm số lớp chia sẻ độ chính xác kết hợp", là độ chính xác của việc dự đoán lớp đúng ngay cả khi được định tuyến đến adaptor sai (nếu các miền chia sẻ một tập hợp lớp). Kết quả được hiển thị trong Bảng XI. Chúng tôi quan sát:

• Mặc dù sử dụng encoder đóng băng và một tập hợp adaptor nông, mô hình hoạt động tốt trên dữ liệu miền mới.
• Đáng ngạc nhiên, các adaptor của miền mới xử lý các mẫu OOD từ miền gốc cực kỳ tốt (>50% độ chính xác) khi các lớp được chia sẻ mặc dù không được huấn luyện trên chúng. Chúng tôi mong đợi điều này là do adaptor ban đầu được huấn luyện trên miền đầu tiên, HDC được biết là mạnh mẽ đối với nhiễu, và các bộ phân loại HD đã học có thể được coi như một sơ đồ học được điều hòa nặng (ensemble của nhiều bộ phân loại yếu).
• Cơ chế định tuyến có vẻ hiệu quả nói chung.
• Sự không hoàn hảo trong định tuyến gây ra giảm độ chính xác đáng chú ý, nhưng độ chính xác vẫn ở mức chấp nhận được xem xét độ khó của vấn đề.
• Do sự mạnh mẽ mạnh mẽ đối với nhiễu do thay đổi phân phối, ngay cả khi các mẫu dữ liệu được định tuyến không chính xác, khi các lớp được chia sẻ, mô hình thường vẫn có thể thành công trong việc gán các lớp đúng.

[Bảng XI về hiểu biết về sự mạnh mẽ của các adaptor đã học]

F. Học Liên tục Tăng dần Lớp

Trong tập hợp thí nghiệm cuối cùng, chúng tôi tạo ra một chương trình giảng dạy bao gồm sáu nhiệm vụ, mỗi nhiệm vụ bao gồm phân loại dữ liệu từ bộ dữ liệu DomainNet. Mô hình được cung cấp một mẫu tại một thời điểm, xác định tập hợp adaptor nào để gửi dữ liệu đến, và đưa ra dự đoán về nhãn lớp và khả năng mẫu là OOD. Adaptor được chọn và điểm số OOD được lưu trữ trong một cửa sổ 50 bước thời gian. Khi ít nhất 60% của 50 mẫu cuối cùng có điểm số OOD 0.7 hoặc lớn hơn, mô hình kích hoạt giai đoạn học nơi 1000 mẫu được thu thập và ghi nhãn bởi một nhà tiên tri. Mô hình chạy ZS-NAS để xác định vị trí và cấu trúc của các adaptor, và tập hợp adaptor được huấn luyện trên dữ liệu đã thu thập. Mỗi 2000 mẫu, nhiệm vụ thay đổi (mô hình không có kiến thức trước về khi nào nhiệm vụ thay đổi). Mỗi nhiệm vụ xuất hiện hai lần, và thứ tự của chương trình giảng dạy là ngẫu nhiên. Chúng tôi đo trung bình di động trong 50 mẫu cuối cùng như metric hiệu suất. Chúng tôi so sánh ba công thức vấn đề: 1) ranh giới trên về hiệu suất nơi mô hình được cung cấp kiến thức về

--- TRANG 11 ---
11
[Bảng XI tiếp tục và Hình 4]

nhiệm vụ hiện tại, 2) thuật toán định tuyến động "chậm" nơi mô hình xác định tập hợp adaptor nào để gửi mẫu hiện tại dựa trên bỏ phiếu đa số sử dụng điểm số ID từ 50 mẫu cuối cùng, và 3) thuật toán định tuyến động tức thời nơi mỗi mẫu dữ liệu được xử lý độc lập, và adaptor tốt nhất được chọn một cách tham lam cho mỗi mẫu.

Các đường cong đánh giá và độ chính xác tổng thể của các cơ chế định tuyến khác nhau xuất hiện trong Hình 4 nơi chúng tôi quan sát:

• Mô hình thể hiện học liên tục thành công.
• Thuật toán định tuyến chậm hoạt động rất tương tự như thuật toán định tuyến tối ưu, nhưng luôn có hình phạt độ trễ thời gian sau khi thay đổi nhiệm vụ do cần thu thập đủ bằng chứng để chuyển tập hợp adaptor hiện tại của nó.
• Thuật toán định tuyến tức thời có thể ngay lập tức điều chỉnh cho sự thay đổi nhiệm vụ, nhưng nó mắc nhiều lỗi hơn về danh tính nhiệm vụ, dẫn đến hiệu suất tổng thể thấp hơn so với thuật toán định tuyến "chậm".
• Mô hình học đúng các adaptor cho sáu nhiệm vụ (với một số lần kích hoạt sai sớm). Các cập nhật thường được kích hoạt sớm sau các thay đổi nhiệm vụ.
• Một khi sáu adaptor được học, điểm số OOD vẫn thấp và các giai đoạn cập nhật không còn kích hoạt.

Hình 4: Hiển thị học liên tục trên chương trình giảng dạy của sáu nhiệm vụ được lặp lại hai lần. Các đường tím biểu thị thay đổi nhiệm vụ. Các thanh vàng biểu thị các giai đoạn thu thập và huấn luyện dữ liệu. Các đường cam biểu thị kích hoạt sai của việc phát hiện thay đổi trong phân phối. Tất cả kết quả là trung bình di động trong 50 mẫu cuối cùng, được đặt lại sau mỗi giai đoạn huấn luyện.

V. KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Chúng tôi đã trình bày một khung mới cho thích ứng mô hình hiệu quả và nhanh chóng trên các thiết bị hạn chế tài nguyên sử dụng kiến trúc EAR. Chúng tôi đã trình bày các đóng góp kỹ thuật mới liên quan đến NN tiến bộ cho học liên tục, phát hiện OOD dựa trên HDC sâu, và ZS-NAS dựa trên phân tích phổ. Chúng tôi thấy rằng các phương pháp dựa trên HD đã học vượt trội hơn các phương pháp được huấn luyện cross-entropy tiêu chuẩn và dựa trên láng giềng gần nhất sâu về độ chính xác ID khoảng ~2-7% trên tất cả các bộ dữ liệu, chứng minh sức mạnh phân biệt của bộ phân loại HD sâu. Tương tự, trên nhiệm vụ phát hiện OOD, mô hình HD đã học thường khớp hoặc vượt hiệu suất của tất cả các phương pháp baseline. Phương pháp phổ của chúng tôi cho ZS-NAS được chỉ ra là nhanh hơn 2-7x để đánh giá heuristic so với các phương pháp ZS-NAS khác trong khi khám phá các kiến trúc tham số thấp đạt được hiệu suất bằng hoặc tốt hơn trên các nhiệm vụ phân loại và OOD downstream. Thú vị, trong thiết lập tăng dần miền (các phương thức khác nhau, cùng lớp), kiến trúc EAR được chỉ ra là cực kỳ mạnh mẽ đối với các thay đổi về phương thức, đạt được độ chính xác phân loại cao ngay cả khi được định tuyến đến tập hợp adaptor không chính xác. Cuối cùng, trong thiết lập học liên tục tăng dần lớp, phương pháp được đề xuất hiệu quả xác định các thay đổi nhiệm vụ và cơ chế định tuyến động "chậm" đạt được hiệu suất gần với cơ chế định tuyến tối ưu (78.3% độ chính xác tổng thể so với 80.6%).

Tuy nhiên, vẫn có một số thành phần của phương pháp chúng tôi ngăn cản hệ thống hoàn toàn tự trị. Chủ yếu, phương pháp hiện tại yêu cầu một nhà tiên tri i) để xác minh rằng miền thực sự đã thay đổi và ii) để sau đó ghi nhãn dữ liệu cho miền mới. Việc bổ sung cơ chế pseudo-labeling sẽ giảm nhu cầu về nhà tiên tri. Phương pháp được đề xuất của chúng tôi cũng giả định thiết bị chạy mô hình không có ràng buộc về bộ nhớ; tức là, mô hình của chúng tôi liên tục phát triển các tập hợp adaptor mới. Chúng ta cần một cơ chế không chỉ để phát triển adaptor, mà còn cập nhật và cắt tỉa các adaptor hiện có khi phân phối dữ liệu thay đổi để xử lý các thiết bị có bộ nhớ hạn chế.

TÀI LIỆU THAM KHẢO

[1] M. De Lange, R. Aljundi, M. Masana, S. Parisot, X. Jia, A. Leonardis, G. Slabaugh, và T. Tuytelaars, "A continual learning survey: Defying forgetting in classification tasks," IEEE TPAMI, 2021.

[2] G. M. van de Ven, T. Tuytelaars, và A. S. Tolias, "Three types of incremental learning," Nature Machine Intelligence, 2022.

[3] P. Kanerva, "Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors," Cognitive computation, 2009.

[4] J. Mellor, J. Turner, A. Storkey, và E. J. Crowley, "Neural architecture search without training," in ICML. PMLR, 2021.

[5] A. A. Rusu, N. C. Rabinowitz, G. Desjardins, H. Soyer, J. Kirkpatrick, K. Kavukcuoglu, R. Pascanu, và R. Hadsell, "Progressive neural networks," arXiv:1606.04671, 2016.

[6] H. M. Fayek, L. Cavedon, và H. R. Wu, "Progressive learning: A deep learning framework for continual learning," Neural Networks, vol. 128, 2020.

[Tiếp tục với danh sách tài liệu tham khảo từ [7] đến [51]...]

--- TRANG 12 ---
12
[Tiếp tục danh sách tài liệu tham khảo và thông tin tác giả]

Dr. Zachary A. Daniels là một nhà khoa học máy tính nghiên cứu với Phòng thí nghiệm Hệ thống Thị giác của Trung tâm Công nghệ Thị giác SRI International tại Princeton, NJ. Ông nhận bằng cử nhân khoa học máy tính với chuyên ngành phụ khoa học nhận thức từ Đại học Lehigh năm 2014. Ông nhận bằng tiến sĩ khoa học máy tính với trọng tâm về học máy, thị giác máy tính và trí tuệ nhân tạo năm 2020 từ Đại học Rutgers.

Dr. David Zhang là Quản lý Kỹ thuật Cấp cao trong Phòng thí nghiệm Hệ thống Thị giác của Trung tâm Công nghệ Thị giác tại SRI International với kinh nghiệm trong phát triển thuật toán và phần mềm nhúng. Ông có chuyên môn về thuật toán thị giác máy tính và học máy, với trọng tâm về tính toán edge và giám sát video, theo dõi và tăng cường trong môi trường thị giác suy giảm. Ông nhận bằng Tiến sĩ Vật lý từ Đại học Bang Pennsylvania năm 2001.

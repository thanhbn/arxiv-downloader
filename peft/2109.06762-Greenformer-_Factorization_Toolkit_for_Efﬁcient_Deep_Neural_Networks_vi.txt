# 2109.06762.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2109.06762.pdf
# Kích thước tệp: 538654 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Greenformer: Bộ công cụ phân tích ma trận cho các mạng nơ-ron sâu hiệu quả
Samuel Cahyawijaya*, Genta Indra Winata, Holy Lovenia, Bryan Wilie,
Wenliang Dai, Etsuko Ishii, Elham J. Barezi, Pascale Fung
Trung tâm Nghiên cứu Trí tuệ Nhân tạo (CAiRE)
Đại học Khoa học và Công nghệ Hồng Kông
scahyawijaya@connect.ust.hk
Tóm tắt
Trong khi những tiến bộ gần đây trong mạng nơ-ron sâu (DNN) mang lại thành công đáng kể, chi phí tính toán cũng tăng lên đáng kể. Trong bài báo này, chúng tôi giới thiệu Greenformer, một bộ công cụ để tăng tốc tính toán của các mạng nơ-ron thông qua phân tích ma trận trong khi duy trì hiệu suất. Greenformer có thể dễ dàng được áp dụng chỉ với một dòng mã cho bất kỳ mô hình DNN nào. Kết quả thực nghiệm của chúng tôi cho thấy Greenformer hiệu quả cho nhiều tình huống khác nhau. Chúng tôi cung cấp bản demo của Greenformer tại https://samuelcahyawijaya.github.io/greenformer-demo/.

Giới thiệu
Với sự tăng trưởng đáng kể về tính toán của các mô hình DNN (Hernandez và Brown 2020), các nhà nghiên cứu AI trên toàn thế giới đã bắt đầu thúc đẩy và áp dụng khái niệm 'Green AI' (Schwartz et al. 2020). Nhiều nghiên cứu gần đây (Strubell, Ganesh, và McCallum 2019; Lacoste et al. 2019; Patterson et al. 2021; Dai et al. 2021; Menghani 2021) đề cập đến các thách thức môi trường như việc sử dụng năng lượng và mức phát thải carbon của các mô hình DNN và phát triển các giải pháp học sâu hiệu quả hơn. Để đáp ứng vấn đề này, chúng tôi giới thiệu một bộ công cụ phân tích ma trận thứ hạng thấp mạnh mẽ và dễ sử dụng, giúp giảm không chỉ chi phí tính toán mà còn cả kích thước mô hình, với tổn thất hiệu suất tối thiểu.

Phân tích ma trận thứ hạng thấp được thực hiện bằng cách phân tách một ma trận lớn thành hai hoặc nhiều ma trận nhỏ hơn, giảm chi phí tính toán và bộ nhớ. Các phương pháp phân tích sau huấn luyện với phân tích giá trị kỳ dị (SVD) (Golub và Reinsch 1970) và phân tích ma trận không âm (NMF) (Lee và Seung 2001) đã được áp dụng để xấp xỉ ma trận trọng số của một mô hình đã huấn luyện (Winata et al. 2019; Ben Noach và Goldberg 2020). Trong hướng nghiên cứu khác, phân tích theo thiết kế áp dụng phân tích ma trận trực tiếp vào cấu trúc mô hình trước khi huấn luyện. Phương pháp này tạo ra kết quả ấn tượng với mô hình nén không chỉ nhỏ hơn và nhanh hơn mà còn có thể vượt trội hơn mô hình không nén (Winata et al. 2020; Cahyawijaya 2021; Kuchaiev và Ginsburg 2017).

Mặc dù thực tế là nhiều nghiên cứu đã được công bố về phân tích ma trận thứ hạng thấp, tất cả các giải pháp đều phụ thuộc vào mô hình, làm cho việc áp dụng cho các kiến trúc mô hình khác nhau trở nên khó khăn và rườm rà. Để cải thiện tính tổng quát và khả năng áp dụng của phương pháp phân tích ma trận thứ hạng thấp, chúng tôi giới thiệu Greenformer, một bộ công cụ phân tích ma trận thứ hạng thấp tinh tế hỗ trợ nhiều trường hợp sử dụng khác nhau của phân tích ma trận và hiện được triển khai cho framework PyTorch (Paszke et al. 2019). Như được hiển thị trong Hình 1, với Greenformer, chúng ta có thể dễ dàng phân tích bất kỳ mạng nơ-ron sâu nào để thực hiện cả phân tích theo thiết kế và phân tích sau huấn luyện. Chúng tôi tiếp tục chứng minh hiệu quả của bộ công cụ Greenformer cho ba trường hợp sử dụng khác nhau: 1) phân tích theo thiết kế, 2) phân tích sau huấn luyện, và 3) phân tích học few-shot thông qua học trong ngữ cảnh.

Thiết kế và Cân nhắc
Greenformer thực hiện phân tách các ma trận trọng số của các lớp tuyến tính và tích chập. Cụ thể, một ma trận trọng số W∈R^(m×n) được phân tách thành hai ma trận thứ hạng thấp A∈R^(m×r) và B∈R^(r×n), trong đó r ≤ min{m,n}.

Greenformer phân tách một ma trận bằng cách sử dụng một bộ giải phân tích. Có ba bộ giải phân tích khác nhau được triển khai trong Greenformer: Random, SVD (Golub và Reinsch 1970), và Semi-Nonnegative Matrix Factorization (SNMF) (Lee và Seung 2001). Bộ giải Random thay thế ma trận gốc bằng hai ma trận ngẫu nhiên bằng cách tham khảo kích thước gốc và thứ hạng mục tiêu được chỉ định. Lưu ý rằng bộ giải random không phù hợp cho phân tích sau huấn luyện, vì nó có thể phá vỡ những gì mô hình đã học trong quá trình huấn luyện chính vì nó không xấp xỉ ma trận gốc. Bộ giải SVD tính toán W = AΣV^T = AB trong đó Σ là ma trận chéo và có các giá trị kỳ dị. SNMF là một phần mở rộng của NMF giúp giảm bớt ràng buộc không âm trên W. Bộ giải SNMF thực hiện phân tách W = AB, trong đó B là nghiêm ngặt không âm nhưng A không có hạn chế về dấu.

Vì ba bộ giải được đề cập ở trên không thể xử lý tensor, Greenformer sắp xếp lại các tensor trọng số thành ma trận để phân tách các lớp tích chập. Ví dụ, một lớp tích chập 1D bao gồm một trọng số W∈R^(C_in×C_out×S), trong đó C_in và C_out biểu thị số kênh đầu vào và đầu ra, và S biểu thị kích thước của kernel tích chập. Greenformer sắp xếp lại trọng số thành một ma trận 2 chiều W'∈R^(C_in×S×C_out). Ma trận sau đó được phân tách và chuyển đổi trở lại chiều gốc tạo ra các tensor A∈R^(C_in×r×S) và B∈R^(r×C_out×1). Cùng một thủ thuật cũng được áp dụng cho các lớp tích chập 2D và 3D.

--- TRANG 2 ---
Các ma trận và/hoặc tensor đã phân tách sau đó được bao bọc vào một module thứ hạng thấp tương thích, sau đó được sử dụng để thay thế các lớp tuyến tính và/hoặc tích chập gốc của mô hình. Cụ thể, chúng tôi thay thế một lớp tuyến tính thành một lớp Linear Encoder-Decoder (LED) và thay thế một lớp tích chập thành một lớp Convolution Encoder-Decoder (CED). Sự mô tả cách hoạt động của các lớp LED và/hoặc CED được hiển thị trong Hình 3. Cả LED và CED đều có cùng đầu vào và đầu ra với các lớp tuyến tính và tích chập; do đó, chúng có thể duy trì tính tương thích với mô hình.

Để tối đa hóa kết quả của phân tích tự động, Greenformer chỉ thực hiện phân tích khi thứ hạng thấp r nhỏ hơn thứ hạng thấp tối đa r_max để đảm bảo giảm chi phí tính toán lý thuyết. Đối với một ma trận trọng số W∈R^(m×n), thứ hạng thấp tối đa được định nghĩa là:

r_max = (mn)/(m+n)  (1)

Để cải thiện tính linh hoạt, Greenformer hỗ trợ phân tích với thứ hạng động qua tất cả các lớp bằng cách tính toán thứ hạng dựa trên tỷ lệ với thứ hạng tối đa r_max của lớp tương ứng. Ngoài ra, chúng tôi cũng quan sát thấy rằng việc áp dụng phân tích cho tất cả các lớp của các mô hình được huấn luyện trước lớn dẫn đến tổn thất hiệu suất đáng kể. Để giải quyết vấn đề này, Greenformer được trang bị tính năng lọc cho phép phân tích chỉ trên một tập hợp cụ thể các module.

Chúng tôi kiểm tra bộ công cụ của mình trên ba trường hợp sử dụng: 1) Phân tích theo thiết kế, nơi chúng tôi huấn luyện mô hình trước khi huấn luyện; 2) phân tích sau huấn luyện, nơi chúng tôi phân tích mô hình trước giai đoạn đánh giá; và phân tích học trong ngữ cảnh, nơi chúng tôi áp dụng phân tích cho các mô hình ngôn ngữ được huấn luyện trước lớn và thực hiện học trong ngữ cảnh theo Brown et al. (2020). Chúng tôi kiểm tra bộ công cụ của mình trên 3 tác vụ phân loại văn bản và 2 tác vụ phân loại hình ảnh. Chúng tôi cho thấy hiệu quả của bộ công cụ Greenformer trong tất cả các trường hợp sử dụng trong Hình 2.

Kết luận
Chúng tôi trình bày Greenformer, một bộ công cụ phân tích tự động cung cấp cải thiện hiệu quả đáng kể trong khi duy trì hiệu suất mô hình. Ngoài ra, Greenformer linh hoạt, dễ sử dụng và có thể áp dụng cho nhiều tình huống. Đối với công việc trong tương lai, thật thú vị khi mở rộng Greenformer cho các trường hợp sử dụng tốn nhiều năng lượng hơn, chẳng hạn như huấn luyện trước các mô hình lớn và tìm kiếm kiến trúc mạng.

--- TRANG 3 ---
Tài liệu tham khảo
Ben Noach, M.; và Goldberg, Y. 2020. Compressing Pre-trained Language Models by Matrix Decomposition. Trong Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, 884–889. Suzhou, China: Association for Computational Linguistics.

Brown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal, S.; Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.; Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever, I.; và Amodei, D. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165.

Cahyawijaya, S. 2021. Greenformers: Improving Computation and Memory Efficiency in Transformer Models via Low-Rank Approximation. arXiv:2108.10808.

Dai, W.; Cahyawijaya, S.; Liu, Z.; và Fung, P. 2021. Multimodal End-to-End Sparse Model for Emotion Recognition. Trong NAACL.

Golub, G. H.; và Reinsch, C. 1970. Singular Value Decomposition and Least Squares Solutions. Numer. Math., 14(5): 403–420.

Hernandez, D.; và Brown, T. B. 2020. Measuring the Algorithmic Efficiency of Neural Networks. arXiv:2005.04305.

Kuchaiev, O.; và Ginsburg, B. 2017. Factorization tricks for LSTM networks. ICLR Workshop.

Lacoste, A.; Luccioni, A.; Schmidt, V.; và Dandres, T. 2019. Quantifying the Carbon Emissions of Machine Learning. Workshop on Tackling Climate Change with Machine Learning at NeurIPS 2019.

Lee, D.; và Seung, H. S. 2001. Algorithms for Non-negative Matrix Factorization. Trong Leen, T.; Dietterich, T.; và Tresp, V., eds., Advances in Neural Information Processing Systems, volume 13. MIT Press.

Menghani, G. 2021. Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better. arXiv:2106.08962.

Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.; Chanan, G.; Killeen, T.; Lin, Z.; Gimelshein, N.; Antiga, L.; Desmaison, A.; Kopf, A.; Yang, E.; DeVito, Z.; Raison, M.; Tejani, A.; Chilamkurthy, S.; Steiner, B.; Fang, L.; Bai, J.; và Chintala, S. 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library. Trong Wallach, H.; Larochelle, H.; Beygelzimer, A.; d'Alché-Buc, F.; Fox, E.; và Garnett, R., eds., Advances in Neural Information Processing Systems 32, 8024–8035. Curran Associates, Inc.

Patterson, D.; Gonzalez, J.; Le, Q.; Liang, C.; Munguia, L.-M.; Rothchild, D.; So, D.; Texier, M.; và Dean, J. 2021. Carbon Emissions and Large Neural Network Training. arXiv:2104.10350.

Schwartz, R.; Dodge, J.; Smith, N. A.; và Etzioni, O. 2020. Green AI. Commun. ACM, 63(12): 54–63.

Strubell, E.; Ganesh, A.; và McCallum, A. 2019. Energy and Policy Considerations for Deep Learning in NLP. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 3645–3650. Florence, Italy: Association for Computational Linguistics.

Winata, G. I.; Cahyawijaya, S.; Lin, Z.; Liu, Z.; và Fung, P. 2020. Lightweight and Efficient End-To-End Speech Recognition Using Low-Rank Transformer. Trong 2020 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2020, Barcelona, Spain, May 4-8, 2020, 6144–6148. IEEE.

Winata, G. I.; Madotto, A.; Shin, J.; Barezi, E. J.; và Fung, P. 2019. On the Effectiveness of Low-Rank Matrix Factorization for LSTM Model Compression. Trong Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, 253–262. Waseda Institute for the Study of Language and Information.

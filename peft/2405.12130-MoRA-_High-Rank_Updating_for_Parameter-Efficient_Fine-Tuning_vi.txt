# MoRA: Cập nhật Thứ hạng Cao cho Tinh chỉnh Hiệu quả Tham số

Ting Jiang1, Shaohan Huang2, Shengyue Luo2, Zihan Zhang2, Haizhen Huang2
Furu Wei2, Weiwei Deng2, Feng Sun2, Qi Zhang2, Deqing Wang1†, Fuzhen Zhuang1
1Đại học Beihang 2Tập đoàn Microsoft
royokong@buaa.edu.cn

## Tóm tắt

Thích ứng thứ hạng thấp (LoRA) là một phương pháp tinh chỉnh hiệu quả tham số (PEFT) phổ biến cho các mô hình ngôn ngữ lớn (LLM). Trong bài báo này, chúng tôi phân tích tác động của cập nhật thứ hạng thấp, như được triển khai trong LoRA. Các phát hiện của chúng tôi cho thấy cơ chế cập nhật thứ hạng thấp có thể hạn chế khả năng của LLM trong việc học và ghi nhớ kiến thức mới một cách hiệu quả. Được truyền cảm hứng từ quan sát này, chúng tôi đề xuất một phương pháp mới gọi là MoRA, sử dụng ma trận vuông để đạt được cập nhật thứ hạng cao trong khi duy trì cùng số lượng tham số có thể huấn luyện. Để đạt được điều này, chúng tôi giới thiệu các toán tử không tham số tương ứng để giảm chiều đầu vào và tăng chiều đầu ra cho ma trận vuông. Hơn nữa, các toán tử này đảm bảo rằng trọng số có thể được hợp nhất trở lại vào LLM, làm cho phương pháp của chúng tôi có thể được triển khai như LoRA. Chúng tôi thực hiện đánh giá toàn diện phương pháp của mình trên năm nhiệm vụ: tinh chỉnh hướng dẫn, lý luận toán học, tiền huấn luyện liên tục, bộ nhớ và tiền huấn luyện. Phương pháp của chúng tôi vượt trội so với LoRA trong các nhiệm vụ tốn nhiều bộ nhớ và đạt được hiệu suất tương đương trong các nhiệm vụ khác. Mã nguồn của chúng tôi sẽ có sẵn tại https://github.com/kongds/MoRA.

## 1 Giới thiệu

Khi kích thước của các mô hình ngôn ngữ tăng lên, tinh chỉnh hiệu quả tham số (PEFT) (Houlsby et al., 2019) đã xuất hiện như một kỹ thuật phổ biến để thích ứng các mô hình này với các nhiệm vụ hạ nguồn cụ thể. So với Tinh chỉnh Toàn phần (FFT), cập nhật tất cả tham số mô hình, PEFT chỉ sửa đổi một phần nhỏ các tham số. Ví dụ, nó có thể đạt được hiệu suất tương tự với FFT bằng cách cập nhật ít hơn 1% tham số trong một số nhiệm vụ (Hu et al., 2021), điều này giảm đáng kể yêu cầu bộ nhớ cho bộ tối ưu hóa và tạo điều kiện thuận lợi cho việc lưu trữ và triển khai các mô hình đã tinh chỉnh.

Trong số các phương pháp PEFT hiện có, Thích ứng Thứ hạng Thấp (LoRA) (Hu et al., 2021) đặc biệt phổ biến cho LLM. LoRA nâng cao hiệu suất so với các phương pháp PEFT khác như tinh chỉnh gợi ý (Lester et al., 2021) hoặc bộ điều hợp (Houlsby et al., 2019) bằng cách cập nhật tham số thông qua các ma trận thứ hạng thấp. Các ma trận này có thể được hợp nhất vào các tham số mô hình gốc, do đó tránh chi phí tính toán bổ sung trong quá trình suy luận. Có nhiều phương pháp nhằm cải thiện LoRA cho LLM. Tuy nhiên, hầu hết các phương pháp chủ yếu xác thực hiệu quả của chúng dựa trên GLUE (Wang et al., 2018), bằng cách đạt được hiệu suất tốt hơn hoặc bằng cách yêu cầu ít tham số có thể huấn luyện hơn. Các phương pháp gần đây (Liu et al., 2024; Meng et al., 2024; Zhu et al., 2024) tận dụng nhiệm vụ tinh chỉnh hướng dẫn như Alpaca (Wang et al., 2024) hoặc các nhiệm vụ lý luận như GSM8K (Cobbe et al., 2021) để đánh giá tốt hơn hiệu suất của chúng trên LLM. Tuy nhiên, các cài đặt và bộ dữ liệu đa dạng được sử dụng trong đánh giá làm phức tạp việc hiểu tiến bộ của chúng.

Trong bài báo này, chúng tôi thực hiện đánh giá toàn diện LoRA trên các nhiệm vụ khác nhau dưới cùng các cài đặt, bao gồm tinh chỉnh hướng dẫn, lý luận toán học và tiền huấn luyện liên tục. Chúng tôi phát hiện rằng các phương pháp giống LoRA thể hiện hiệu suất tương tự trên các nhiệm vụ này và chúng thực hiện tương đương với FFT trong tinh chỉnh hướng dẫn nhưng kém hơn trong lý luận toán học và tiền huấn luyện liên tục. Trong số các nhiệm vụ này, tinh chỉnh hướng dẫn chủ yếu tập trung vào tương tác với định dạng, thay vì thu được kiến thức và khả năng, được học hầu như hoàn toàn trong quá trình tiền huấn luyện (Zhou et al., 2024). Chúng tôi quan sát thấy LoRA dễ dàng thích ứng để tuân theo các định dạng phản hồi trong tinh chỉnh hướng dẫn nhưng gặp khó khăn với các nhiệm vụ khác đòi hỏi tăng cường kiến thức và khả năng thông qua tinh chỉnh.

Một lời giải thích khả dĩ cho hạn chế này quan sát được với LoRA có thể là sự phụ thuộc vào cập nhật thứ hạng thấp (Lialin et al., 2023). Ma trận cập nhật thứ hạng thấp, ∆W, gặp khó khăn trong việc ước tính các cập nhật thứ hạng đầy đủ trong FFT, đặc biệt trong các nhiệm vụ tốn nhiều bộ nhớ như tiền huấn luyện liên tục đòi hỏi ghi nhớ kiến thức cụ thể theo lĩnh vực. Vì thứ hạng của ∆W nhỏ hơn đáng kể so với thứ hạng đầy đủ, hạn chế này giới hạn khả năng lưu trữ thông tin mới thông qua tinh chỉnh. Hơn nữa, các biến thể hiện tại của LoRA không thể thay đổi đặc tính cố hữu của cập nhật thứ hạng thấp. Để xác thực điều này, chúng tôi đã thực hiện một nhiệm vụ ghi nhớ sử dụng dữ liệu giả để đánh giá hiệu suất của LoRA trong việc ghi nhớ kiến thức mới. Chúng tôi phát hiện rằng LoRA thực hiện kém hơn đáng kể so với FFT, ngay cả với thứ hạng lớn như 256.

Dựa trên những quan sát này, chúng tôi giới thiệu một phương pháp gọi là MoRA, sử dụng ma trận vuông trái ngược với ma trận thứ hạng thấp, nhằm tối đa hóa thứ hạng trong ∆W trong khi duy trì cùng số lượng tham số có thể huấn luyện. Ví dụ, khi sử dụng thứ hạng 8 với kích thước ẩn 4096, LoRA sử dụng hai ma trận thứ hạng thấp A∈R^(4096×8) và B∈R^(8×4096), với rank(∆W)≤8. Dưới cùng số lượng tham số, phương pháp của chúng tôi sử dụng ma trận vuông M∈R^(256×256), với rank(∆W)≤256, như mô tả trong Hình 1. Đáng chú ý, phương pháp của chúng tôi thể hiện khả năng lớn hơn LoRA với thứ hạng lớn. Để giảm chiều đầu vào và tăng chiều đầu ra cho M, chúng tôi phát triển các toán tử không tham số tương ứng. Hơn nữa, các toán tử này và M có thể được thay thế bằng ∆W, đảm bảo phương pháp của chúng tôi có thể được hợp nhất trở lại vào LLM như LoRA.

Các đóng góp của chúng tôi như sau:

1. Chúng tôi giới thiệu MoRA, một phương pháp mới sử dụng ma trận vuông thay vì ma trận thứ hạng thấp trong LoRA để đạt được cập nhật thứ hạng cao, trong khi duy trì cùng số lượng tham số có thể huấn luyện.

2. Chúng tôi thảo luận bốn loại toán tử không tham số của MoRA để giảm chiều đầu vào và tăng chiều đầu ra cho ma trận vuông, đồng thời đảm bảo rằng trọng số có thể được hợp nhất trở lại vào LLM.

3. Chúng tôi đánh giá MoRA trên năm nhiệm vụ: bộ nhớ, tinh chỉnh hướng dẫn, lý luận toán học, tiền huấn luyện liên tục và tiền huấn luyện. Phương pháp của chúng tôi vượt trội so với LoRA trong các nhiệm vụ tốn nhiều bộ nhớ và đạt được hiệu suất tương đương trong các nhiệm vụ khác, điều này chứng minh tính hiệu quả của cập nhật thứ hạng cao.

## 2 Công trình Liên quan

### 2.1 LoRA

LoRA là một trong những phương pháp PEFT phổ biến nhất để tinh chỉnh LLM, nhờ vào khả năng áp dụng rộng rãi và hiệu suất mạnh mẽ so với các phương pháp khác. Để xấp xỉ trọng số cập nhật ∆W trong FFT, LoRA sử dụng hai ma trận thứ hạng thấp để phân tách. Bằng cách điều chỉnh thứ hạng của hai ma trận này, LoRA có thể sửa đổi tương ứng các tham số có thể huấn luyện. Nhờ vào điều này, LoRA có thể hợp nhất các ma trận này sau tinh chỉnh mà không có độ trễ suy luận so với FFT. Có nhiều phương pháp để cải thiện thêm LoRA, đặc biệt cho ứng dụng trong LLM. DoRA (Liu et al., 2024) phân tách thêm trọng số gốc thành các thành phần độ lớn và hướng và sử dụng LoRA để cập nhật thành phần hướng. LoRA+ (Hayou et al., 2024) sử dụng tốc độ học khác nhau cho hai ma trận thứ hạng thấp để cải thiện hiệu quả học. ReLoRA (Lialin et al., 2023) tích hợp LoRA vào LLM trong quá trình huấn luyện để tăng thứ hạng của ∆W cuối cùng.

### 2.2 Tinh chỉnh với LLM

Mặc dù hiệu suất ấn tượng của LLM với học trong ngữ cảnh, một số tình huống vẫn cần thiết phải tinh chỉnh, có thể được phân loại rộng rãi thành ba loại. Loại đầu tiên, tinh chỉnh hướng dẫn, nhằm căn chỉnh tốt hơn LLM với các nhiệm vụ cuối và sở thích của người dùng, mà không tăng cường đáng kể kiến thức và khả năng của LLM (Zhou et al., 2024). Cách tiếp cận này đơn giản hóa quá trình xử lý các nhiệm vụ đa dạng và hiểu các hướng dẫn phức tạp. Loại thứ hai liên quan đến các nhiệm vụ lý luận phức tạp như giải quyết vấn đề toán học (Collins et al., 2023; Imani et al., 2023; Yu et al., 2023), trong đó tinh chỉnh hướng dẫn chung thường không đủ để xử lý các nhiệm vụ lý luận phức tạp, tượng trưng, nhiều bước. Để cải thiện khả năng lý luận của LLM, phần lớn nghiên cứu tập trung vào việc tạo ra các bộ dữ liệu huấn luyện tương ứng, bằng cách tận dụng các mô hình giáo viên lớn hơn như GPT-4 (Fu et al., 2023), hoặc bằng cách diễn đạt lại các câu hỏi theo con đường lý luận (Yu et al., 2023). Loại thứ ba, tiền huấn luyện liên tục (Cheng et al., 2023; Chen et al., 2023; Han et al., 2023; Liu et al., 2023), nhằm tăng cường khả năng cụ thể theo lĩnh vực của LLM. Không giống như tinh chỉnh hướng dẫn, nó cần thiết phải tinh chỉnh để tăng cường kiến thức và khả năng cụ thể theo lĩnh vực tương ứng.

Tuy nhiên, hầu hết các biến thể của LoRA (Kopiczko et al., 2023; Lialin et al., 2023; Dettmers et al., 2024; Zhu et al., 2024) chủ yếu sử dụng nhiệm vụ tinh chỉnh hướng dẫn hoặc các nhiệm vụ phân loại văn bản từ GLUE (Wang et al., 2018) để xác thực hiệu quả của chúng trên LLM. Vì tinh chỉnh hướng dẫn đòi hỏi ít khả năng nhất để tinh chỉnh so với các loại khác, nó có thể không phản ánh chính xác tính hiệu quả của các biến thể LoRA. Để đánh giá tốt hơn các phương pháp của họ, các công trình gần đây (Meng et al., 2024; Liu et al., 2024; Shi et al., 2024; Renduchintala et al., 2023) đã sử dụng các nhiệm vụ lý luận để kiểm tra phương pháp của họ. Nhưng các bộ huấn luyện được sử dụng thường quá nhỏ để LLM học lý luận hiệu quả. Ví dụ, một số phương pháp (Meng et al., 2024; Renduchintala et al., 2023) sử dụng GSM8K (Cobbe et al., 2021) chỉ với 7.5K mẫu huấn luyện. So với phương pháp SOTA với 395K mẫu huấn luyện (Yu et al., 2023), bộ huấn luyện nhỏ này đạt được hiệu suất kém hơn trong lý luận và làm cho việc đánh giá tính hiệu quả của các phương pháp này trở nên khó khăn.

## 3 Phân tích Ảnh hưởng của Cập nhật Thứ hạng Thấp

Ý tưởng chính của LoRA (Hu et al., 2021) liên quan đến việc sử dụng cập nhật thứ hạng thấp để ước tính cập nhật thứ hạng đầy đủ trong FFT. Một cách chính thức, cho một ma trận tham số đã tiền huấn luyện W₀∈R^(d×k), LoRA sử dụng hai ma trận thứ hạng thấp để tính toán cập nhật trọng số ∆W:

h = W₀x + ∆Wx = W₀x + BAx                    (1)

trong đó A∈R^(r×k) và B∈R^(d×r) đại diện cho các ma trận thứ hạng thấp trong LoRA. Để đảm bảo rằng ∆W = 0 ở đầu huấn luyện, LoRA khởi tạo A với phân phối Gaussian và B với số không. Do phân tách thứ hạng thấp của ∆W thành BA, rank(∆W) ≤ r. Cập nhật trọng số trong LoRA thể hiện thứ hạng rõ ràng thấp, r ≪ min(d, k), so với cập nhật thứ hạng đầy đủ trong FFT. Cập nhật thứ hạng thấp bởi LoRA cho thấy hiệu suất ngang bằng với cập nhật thứ hạng đầy đủ trong một số nhiệm vụ như phân loại văn bản hoặc tinh chỉnh hướng dẫn (Liu et al., 2024; Meng et al., 2024). Tuy nhiên, đối với các nhiệm vụ như lý luận phức tạp hoặc tiền huấn luyện liên tục, LoRA có xu hướng cho thấy hiệu suất kém hơn (Liu et al., 2023).

Dựa trên những quan sát này, chúng tôi đề xuất giả thuyết rằng cập nhật thứ hạng thấp dễ dàng tận dụng kiến thức và khả năng ban đầu của LLM để giải quyết nhiệm vụ, nhưng nó gặp khó khăn để xử lý các nhiệm vụ đòi hỏi tăng cường kiến thức và khả năng của LLM.

Để chứng thực giả thuyết này, chúng tôi kiểm tra sự khác biệt giữa LoRA và FFT về mặt ghi nhớ kiến thức mới thông qua tinh chỉnh. Để tránh tận dụng kiến thức ban đầu của LLM, chúng tôi tạo ngẫu nhiên 10K cặp Định danh Duy nhất Toàn cầu (UUID), mỗi cặp bao gồm hai UUID với 32 giá trị thập lục phân. Nhiệm vụ yêu cầu LLM tạo ra UUID tương ứng dựa trên UUID đầu vào. Ví dụ, cho một UUID như "205f3777-52b6-4270-9f67-c5125867d358", mô hình nên tạo ra UUID tương ứng dựa trên 10K cặp huấn luyện. Nhiệm vụ này cũng có thể được xem như một nhiệm vụ hỏi-đáp, trong khi kiến thức không thể thiếu để hoàn thành nó chỉ từ các bộ dữ liệu huấn luyện chứ không phải từ chính LLM.

Đối với các cài đặt huấn luyện, chúng tôi sử dụng LLaMA-2 7B làm mô hình cơ sở, sử dụng 1.000 cặp mỗi lô và thực hiện 100 epochs. Đối với LoRA, chúng tôi áp dụng ma trận thứ hạng thấp cho tất cả các lớp tuyến tính và tìm kiếm tốc độ học từ {1e-4, 2e-4, 3e-4} để tăng hiệu suất. Chúng tôi thực hiện thí nghiệm trên LoRA sử dụng các thứ hạng khác nhau r ∈ {8, 16, 32, 64, 128, 256}. Đối với FFT, chúng tôi trực tiếp sử dụng tốc độ học 3e-5.

Dựa trên Hình 2, chúng tôi quan sát cập nhật thứ hạng thấp khó ghi nhớ kiến thức mới so với FFT. Mặc dù liên tục tăng thứ hạng của LoRA có thể làm giảm vấn đề này, khoảng cách vẫn tồn tại.

Trái ngược với nhiệm vụ bộ nhớ, chúng tôi cũng đánh giá khoảng cách hiệu suất giữa LoRA và FFT trong tinh chỉnh hướng dẫn, chỉ giới thiệu kiến thức mới. Tương tự như các kết quả trước đây (Meng et al., 2024; Zhu et al., 2024), chúng tôi cũng thấy rằng LoRA khớp với hiệu suất của FFT với thứ hạng nhỏ r = 8 trong Bảng 1. Điều này chỉ ra rằng LoRA có thể dễ dàng tận dụng kiến thức ban đầu của LLM bằng tinh chỉnh như FFT.

## 4 Phương pháp

Dựa trên phân tích trên, chúng tôi đề xuất một phương pháp mới để giảm thiểu tác động tiêu cực của cập nhật thứ hạng thấp. Ý tưởng chính của phương pháp chúng tôi là sử dụng các tham số có thể huấn luyện giống nhau càng nhiều càng tốt để đạt được thứ hạng cao hơn trong ∆W. Xét đến trọng số đã tiền huấn luyện W₀∈R^(d×k), LoRA sử dụng hai ma trận thứ hạng thấp A và B với tổng số (d+k)r tham số có thể huấn luyện cho thứ hạng r. Dưới cùng tham số có thể huấn luyện, ma trận vuông M∈R^(r̂×r̂) trong đó r̂ = ⌊√((d+k)r)⌋ có thể đạt được thứ hạng cao nhất do r ≪ min(d, k).

Để hoàn thành điều này, chúng tôi cần giảm chiều đầu vào và tăng chiều đầu ra cho M. Một cách chính thức,

h = W₀x + f_decomp(Mf_comp(x))                    (2)

trong đó f_comp: R^k → R^r̂ biểu thị hàm giảm chiều đầu vào của x từ k xuống r̂, và f_decomp: R^r̂ → R^d đại diện cho hàm tăng cường chiều đầu ra từ r̂ lên d. Hơn nữa, hai hàm này phải là các toán tử không tham số hóa và dự kiến thực thi trong thời gian tuyến tính tương ứng với chiều. Chúng cũng nên có hàm tương ứng, f'_comp: R^(r̂×r̂) → R^(r̂×k) và f'_decomp: R^(r̂×k) → R^(d×k), để biến đổi M thành ∆W. Đối với bất kỳ x nào, điều sau đây phải đúng:

f_decomp(Mf_comp(x)) = ∆Wx, ∀x ∈ R^k                    (3)

trong đó ∆W = f'_decomp(f'_comp(M)). Nếu Phương trình 3 đúng, M có thể được mở rộng một cách không mất mát thành ∆W dựa trên f_comp và f_decomp. Điều này cho phép phương pháp của chúng tôi hợp nhất trở lại vào LLM như LoRA.

Đối với thiết kế của f_comp và f'_comp, chúng tôi khám phá một số phương pháp để triển khai các hàm này. Một phương pháp đơn giản là cắt bớt chiều và sau đó thêm nó vào chiều tương ứng. Một cách chính thức, điều này có thể được biểu diễn như:

f_comp(x) = x_{1:r̂}
f_decomp(x) = [x; 0]                    (4)

và ∆W tương ứng là:

∆W = [M 0; 0 0]                    (5)

Tuy nhiên, phương pháp này dẫn đến mất mát đáng kể thông tin trong quá trình nén và chỉ sửa đổi một đoạn của đầu ra bằng cách thêm vectơ không trong quá trình giải nén. Để cải thiện nó, chúng tôi có thể chia sẻ các hàng và cột của M để đạt được nén và giải nén hiệu quả hơn. Một cách chính thức, điều này có thể được biểu diễn như:

f_comp(x) = [∑_{j∈g_i} x_j]_{i=1}^r̂
f_decomp(x) = [x_{g'_i}]_{i=1}^d                    (6)

Ở đây, g và g' đại diện cho các nhóm được định nghĩa trước chia sẻ cùng hàng và cột trong M, tương ứng. Thuật ngữ j ∈ g_i chỉ ra rằng chiều thứ j thuộc về nhóm thứ i trong g. Thuật ngữ g'_i là nghịch đảo của g'_i, đề cập đến chiều thứ i được liên kết với nhóm thứ g'_i trong g'. ∆W tương ứng như sau:

∆W_{i,j} = M_{g'_i, g_j}                    (7)

Chia sẻ hàng và cột có thể hiệu quả cho các thứ hạng lớn hơn như r = 128 hoặc r = 256, vì chỉ có một vài hàng hoặc cột trong ∆W chia sẻ một hàng hoặc cột chung. Ví dụ, xét đến ∆W∈R^(4096×4096) cho r = 128, có r̂ = 1024 và M∈R^(1024×1024). Trong tình huống này, chỉ có 4 hàng hoặc cột chia sẻ cùng hàng hoặc cột. Ngược lại, đối với các thứ hạng nhỏ hơn như r = 8, trong đó r̂ = 256, nó yêu cầu trung bình 16 hàng hoặc cột trong một nhóm để chia sẻ cùng hàng hoặc cột trong M. Nó có thể dẫn đến không hiệu quả do mất mát thông tin đáng kể trong quá trình nén trong Phương trình 6.

Để tăng cường hiệu suất cho các thứ hạng nhỏ hơn, chúng tôi định hình lại x thay vì nén trực tiếp nó, để bảo tồn thông tin đầu vào. Trong bối cảnh này, f_comp(x): R^k → R^(n×r̂) và f_decomp: R^(n×r̂) → R^d. f'_comp, f'_decomp và ∆W tương ứng như sau:

f_comp(x) = [x_{1:r̂} x_{r̂:2r̂} ⋯ x_{(n-1)r̂:nr̂}]
f_decomp(x) = concat(x)
∆W = [M 0 ⋯ 0; 0 M ⋯ 0; ⋮ ⋮ ⋱ ⋮; 0 0 ⋯ M]                    (8)

trong đó concat(x) đề cập đến nối các hàng của x thành một vectơ. Để đơn giản, chúng tôi bỏ qua các toán tử đệm và cắt bớt trong các hàm trên và tập trung vào trường hợp d = k. So với chia sẻ cột và hàng, phương pháp này phát sinh chi phí tính toán bổ sung bằng cách định hình lại x thành R^(n×r̂) thay vì R^r̂. Tuy nhiên, vì kích thước của M nhỏ hơn đáng kể so với W₀, tính toán bổ sung này rất nhỏ cho thứ hạng như 8. Ví dụ, khi tinh chỉnh mô hình 7B với thứ hạng 8 (r̂ = 256), phương pháp này chỉ chậm hơn 1.03 lần so với các phương pháp trước đây.

Được truyền cảm hứng từ RoPE (Su et al., 2024), chúng tôi có thể tinh chỉnh thêm phương pháp này bằng cách kết hợp các toán tử quay vào f_comp để tăng cường tính biểu đạt của M bằng cách cho phép nó phân biệt giữa các x_{ir̂:(i+1)r̂} khác nhau bằng cách quay chúng. Chúng tôi có thể sửa đổi Phương trình 8 như sau:

f_comp(x) = [a₁ a₂ ⋯ a_{n-1}]
∆W = [P₁ 0 ⋯ 0; 0 P₂ ⋯ 0; ⋮ ⋮ ⋱ ⋮; 0 0 ⋯ P_{n-1}]                    (9)

trong đó a_i và P_i đại diện cho các giá trị tương ứng của x_{ir̂:(i+1)r̂} và M sau khi quay, tương ứng. Theo RoPE, chúng tôi sử dụng ma trận chéo khối r̂×r̂ để thực hiện phép quay. Tuy nhiên, phương pháp của chúng tôi sử dụng thông tin quay để cho phép M phân biệt x_{ir̂:(i+1)r̂} thay vì vị trí token trong RoPE. Chúng tôi có thể định nghĩa a_i và P_i như sau:

a_i = [R_{θ₁,i} 0 ⋯ 0; 0 R_{θ₂,i} ⋯ 0; ⋮ ⋮ ⋱ ⋮; 0 0 ⋯ R_{θ_{r̂/2},i}] x_{ir̂:(i+1)r̂}

P_i = M [R_{θ₁,i} 0 ⋯ 0; 0 R_{θ₂,i} ⋯ 0; ⋮ ⋮ ⋱ ⋮; 0 0 ⋯ R_{θ_{r̂/2},i}]                    (10)

trong đó θ_j = 10000^{-2(j-1)/r̂} và R_{θ_j,i} ∈ R^{2×2} là ma trận quay:

R_{θ_j,i} = [cos(iθ_j) -sin(iθ_j); sin(iθ_j) cos(iθ_j)]                    (11)

## 5 Thí nghiệm

Chúng tôi đánh giá phương pháp của mình trên các nhiệm vụ khác nhau để hiểu ảnh hưởng của cập nhật thứ hạng cao. Trong Mục 5.1, chúng tôi đánh giá phương pháp của mình với LoRA và phương pháp của chúng tôi trong việc ghi nhớ các cặp UUID để cho thấy lợi ích của cập nhật thứ hạng cao trong ghi nhớ. Trong Mục 5.2, chúng tôi tái tạo LoRA, các biến thể LoRA và FFT trên ba nhiệm vụ tinh chỉnh: tinh chỉnh hướng dẫn, lý luận toán học và tiền huấn luyện liên tục. Trong Mục 5.3, chúng tôi so sánh phương pháp của mình với LoRA và ReLoRA trong tiền huấn luyện bằng cách huấn luyện transformer từ đầu.

### 5.1 Ghi nhớ Cặp UUID

Đầu tiên chúng tôi so sánh phương pháp của mình với LoRA và FFT trong việc ghi nhớ cặp UUID để chứng minh cải thiện thông qua cập nhật thứ hạng cao. Theo các cài đặt huấn luyện trong Mục 3, chúng tôi tìm kiếm tốc độ học từ {5e-5, 1e-4, 2e-4} và sử dụng các hàm giải nén và nén trong Phương trình 8, chia sẻ hàng và cột trong M. Do sử dụng một ma trận M thay vì hai ma trận A và B, chúng tôi có thể trực tiếp khởi tạo M với số không. Đối với các nhóm được định nghĩa trước g và g', chúng tôi nhóm mỗi r̂ hàng hoặc cột liền kề lại với nhau. Mất mát huấn luyện được trình bày trong Hình 3.

Phương pháp của chúng tôi cho thấy cải thiện đáng kể so với LoRA với cùng số lượng tham số có thể huấn luyện, nhờ vào cập nhật thứ hạng cao. Chúng tôi cũng báo cáo độ chính xác ở cấp độ ký tự tại các bước huấn luyện khác nhau trong Bảng 2. MoRA yêu cầu ít bước huấn luyện hơn để ghi nhớ các cặp UUID này so với LoRA. So với FFT, MoRA với thứ hạng 256 có thể đạt được hiệu suất tương tự và cả hai phương pháp đều có thể ghi nhớ tất cả các cặp UUID trong 500 bước.

### 5.2 Nhiệm vụ Tinh chỉnh

#### 5.2.1 Thiết lập

Chúng tôi đánh giá phương pháp của mình trên ba nhiệm vụ tinh chỉnh cho các mô hình ngôn ngữ lớn (LLM): tinh chỉnh hướng dẫn, lý luận toán học và tiền huấn luyện liên tục. Đối với các nhiệm vụ này, chúng tôi chọn các bộ dữ liệu tương ứng chất lượng cao để kiểm tra cả LoRA và phương pháp của chúng tôi. Trong tinh chỉnh hướng dẫn, chúng tôi sử dụng Tülu v2 (Ivison et al., 2023), một hỗn hợp của một số bộ dữ liệu hướng dẫn chất lượng cao, chứa 326k mẫu đã lọc. Chúng tôi đánh giá hiệu suất hướng dẫn sử dụng MMLU (Hendrycks et al., 2020) trong cả cài đặt zero-shot và five-shot. Đối với lý luận toán học, chúng tôi sử dụng MetaMath (Yu et al., 2023) với 395k mẫu để tăng cường khả năng lý luận toán học và cũng sử dụng GSM8K (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021) để đánh giá thêm. Trong tiền huấn luyện liên tục, chúng tôi thích ứng LLM với y sinh học và tài chính sử dụng tóm tắt PubMed từ Pile (Gao et al., 2020) và tin tức tài chính, được bổ sung bằng các phương pháp tiền xử lý dữ liệu từ AdaptLLM (Cheng et al., 2023) để tăng hiệu suất. Chúng tôi báo cáo hiệu suất trung bình của các nhiệm vụ tương ứng cho tiền huấn luyện liên tục. Chi tiết thêm có thể được tìm thấy trong Phụ lục C.

#### 5.2.2 Đường cơ sở và Triển khai

Đối với các phương pháp giống LoRA và MoRA, chúng tôi thực hiện thí nghiệm tại r = 8 và r = 256, và tái tạo các phương pháp sau trên ba nhiệm vụ: FFT, LoRA, LoRA+ (Hayou et al., 2024), AsyLoRA (Zhu et al., 2024), ReLoRA (Lialin et al., 2023) và DoRA (Liu et al., 2024). LoRA+ tăng cường tốc độ học của ma trận B trong LoRA để tạo điều kiện học tính năng hiệu quả dựa trên phân tích lý thuyết. Chúng tôi tìm kiếm siêu tham số λ tương ứng từ {2, 4}. AsyLoRA cũng phân tích tính bất đối xứng trong các ma trận A và B, và chúng tôi áp dụng chiến lược khởi tạo của họ. ReLoRA đề xuất một phương pháp để hợp nhất các ma trận thứ hạng thấp vào mô hình trong quá trình huấn luyện để tăng thứ hạng của ∆W. chúng tôi tìm kiếm các bước hợp nhất từ {1k, 2k} và sử dụng khởi động lại 50 bước. DoRA tận dụng phân tách trọng số để tăng cường hiệu suất như một đường cơ sở mạnh mẽ. Đối với FFT, chúng tôi tuân theo các cài đặt được đề xuất bởi các bộ dữ liệu tương ứng. Đối với MoRA, chúng tôi sử dụng các toán tử quay như được nêu trong Phương trình 9 để triển khai nén và giải nén cho r = 8, và cho r = 256, chúng tôi sử dụng chia sẻ hàng và cột như được chỉ định trong Phương trình 6 và nhóm mỗi r̂ hàng hoặc cột liền kề lại với nhau. Chi tiết siêu tham số về tinh chỉnh có thể được tìm thấy trong Phụ lục A.

#### 5.2.3 Kết quả và Phân tích

Chúng tôi trình bày kết quả của các nhiệm vụ tinh chỉnh trong Bảng 1. Chúng tôi báo cáo kết quả của MMLU với cài đặt zero-shot và 5-shot cho tinh chỉnh hướng dẫn, GSM8K và MATH cho lý luận toán học, và hiệu suất trung bình trên các nhiệm vụ y sinh học và nhiệm vụ tài chính cho tiền huấn luyện liên tục.

MoRA cho thấy hiệu suất ngang bằng với LoRA trong tinh chỉnh hướng dẫn và lý luận toán học. Nhờ vào cập nhật thứ hạng cao để ghi nhớ kiến thức mới, MoRA vượt trội so với LoRA trong cả lĩnh vực y sinh học và tài chính cho tiền huấn luyện liên tục.

Chúng tôi cũng thấy rằng các biến thể LoRA thể hiện hiệu suất tương tự trên các nhiệm vụ tinh chỉnh này so với LoRA. Mặc dù AsyLoRA đạt được hiệu suất tốt nhất trong tinh chỉnh hướng dẫn, nó thể hiện hiệu suất kém trong lý luận toán học. Đối với ReLoRA, việc hợp nhất các ma trận thứ hạng thấp trong quá trình huấn luyện có thể làm tổn hại hiệu suất, đặc biệt ở thứ hạng cao như 256.

Xét sự khác biệt giữa ba nhiệm vụ, chúng cho thấy các yêu cầu khác nhau cho khả năng tinh chỉnh. Đối với tinh chỉnh hướng dẫn, không học kiến thức mới từ tinh chỉnh, thứ hạng 8 là đủ để đạt được hiệu suất tương tự với FFT. Đối với lý luận toán học, thứ hạng 8 không thể khớp với hiệu suất FFT. Tuy nhiên, tăng thứ hạng từ 8 lên 256 có thể loại bỏ khoảng cách hiệu suất. Đối với tiền huấn luyện liên tục, LoRA với thứ hạng 256 vẫn kém hiệu suất so với FFT.

### 5.3 Tiền huấn luyện

Để hiểu ảnh hưởng của cập nhật thứ hạng cao, chúng tôi huấn luyện transformer từ đầu trên các bộ dữ liệu C4 (Raffel et al., 2020). Đối với kiến trúc mô hình, chúng tôi huấn luyện mô hình dựa trên LLaMA với RMSNorm (Zhang và Sennrich, 2019), SwiGLU (Shazeer, 2020) và RoPE (Su et al., 2024) ở kích thước 250M và 1.3B. Đối với các siêu tham số, chúng tôi sử dụng 10k bước, 1024 kích thước lô, 512 độ dài chuỗi và theo Lialin et al., sử dụng thứ hạng r = 128 cho LoRA và các phương pháp của chúng tôi và cũng giữ các mô-đun không áp dụng các lớp LoRA như layernorm hoặc embeddings không bị đóng băng. Chúng tôi so sánh phương pháp của mình với LoRA và ReLoRA. Để thể hiện tốt hơn sự khác biệt giữa cập nhật thứ hạng cao và thứ hạng thấp, chúng tôi tái tạo ReLoRA và các phương pháp khác mà không có khởi động huấn luyện thứ hạng đầy đủ. Đối với MoRA, chúng tôi sử dụng các hàm nén và giải nén trong Phương trình 6 bằng cách chia sẻ cột và hàng.

Chúng tôi cũng kết hợp merge-and-reint trong ReLoRA với phương pháp của chúng tôi gọi là ReMoRA bằng cách hợp nhất M trở lại vào các tham số ban đầu trong quá trình huấn luyện để tăng thứ hạng của ∆W. Tuy nhiên, nếu chúng tôi trực tiếp hợp nhất M với g và g' trong Phương trình 6, thứ hạng cuối cùng của ∆W không thay đổi do cùng mẫu mở rộng. Để giải quyết vấn đề này, chúng tôi có thể thay đổi g và g' sau khi hợp nhất để đảm bảo thứ hạng của ∆W tăng. Chi tiết thêm về ReMoRA có thể được tìm thấy trong Phụ lục B. Đối với các siêu tham số tương ứng với ReLoRA và ReMoRA, chúng tôi hợp nhất mỗi 2k bước và sử dụng khởi động lại 50 bước với việc đặt lại bộ tối ưu hóa và lịch trình răng cưa.

Chúng tôi cho thấy mất mát tiền huấn luyện trong Hình 4 và perplexity tương ứng trên bộ dữ liệu xác thực C4 trong Bảng 3. Phương pháp của chúng tôi cho thấy hiệu suất tốt hơn trong tiền huấn luyện so với LoRA và ReLoRA với cùng lượng tham số có thể huấn luyện. Nhờ vào cập nhật thứ hạng cao, ReMoRA cũng đạt được nhiều cải thiện hơn trên MoRA so với ReLoRA, điều này chứng minh tính hiệu quả của chiến lược merge-and-reint trong ReMoRA.

## 6 Phân tích

### 6.1 Cập nhật Thứ hạng Cao

Để chứng minh tác động của cập nhật thứ hạng cao lên thứ hạng của ∆W, chúng tôi phân tích phổ của các giá trị đơn lẻ cho ∆W đã học trên mô hình tiền huấn luyện 250M. Chúng tôi trình bày số lượng trung bình của các giá trị đơn lẻ vượt quá 0.1 trên tất cả các lớp cho ∆W_q, ∆W_k, ∆W_v, ∆W_o, ∆W_up, ∆W_down và ∆W_gate trong Hình 5 theo (Lialin et al., 2023).

MoRA và ReMoRA thể hiện số lượng các giá trị đơn lẻ đáng kể cao hơn đáng kể so với LoRA và ReLoRA, làm nổi bật tính hiệu quả của các phương pháp của chúng tôi trong việc tăng thứ hạng của ∆W. Chúng tôi thấy rằng số lượng các giá trị đơn lẻ được hiển thị trong Hình 5 có thể được tương quan với các chỉ số perplexity được liệt kê trong Bảng 3. Hơn nữa, MoRA, không có chiến lược merge-and-reint trong ReLoRA và ReMoRA, có thể đạt được perplexity thấp hơn ReLoRA cùng với các giá trị đơn lẻ đáng kể cao hơn.

### 6.2 Ảnh hưởng của Giải nén và Nén

Để khám phá tác động của các hàm giải nén và nén trong MoRA, chúng tôi báo cáo hiệu suất trên GSM8K sử dụng các phương pháp khác nhau: cắt bớt, chia sẻ, tách rời và quay trong Bảng 4. Trong số các phương pháp này, cắt bớt cho thấy hiệu suất tệ nhất do mất mát thông tin đáng kể trong quá trình nén. Chia sẻ có thể đạt được hiệu suất tốt hơn cắt bớt bằng cách tận dụng các hàng hoặc cột chia sẻ để bảo tồn thông tin đầu vào. Nhưng trong trường hợp r = 8, chia sẻ cho thấy hiệu suất kém hơn tách rời và quay do số lượng lớn các hàng hoặc cột chia sẻ, như chúng tôi đã thảo luận trong Mục 4. Quay hiệu quả hơn tách rời, do thông tin quay có thể giúp ma trận vuông phân biệt thông tin đầu vào.

## 7 Kết luận

Trong bài báo này, chúng tôi phân tích tác động của cập nhật thứ hạng thấp thông qua LoRA và quan sát rằng cập nhật như vậy gặp khó khăn cho các nhiệm vụ tốn nhiều bộ nhớ, điều này cũng hạn chế các biến thể LoRA hiện tại. Để vượt qua hạn chế này, chúng tôi giới thiệu MoRA, một phương pháp sử dụng các toán tử không tham số hóa cho cập nhật thứ hạng cao. Trong khuôn khổ MoRA, chúng tôi khám phá các phương pháp khác nhau để triển khai các hàm giải nén và nén. So sánh hiệu suất chỉ ra rằng MoRA khớp với LoRA trong tinh chỉnh hướng dẫn và lý luận toán học, và thể hiện hiệu suất vượt trội trong tiền huấn luyện liên tục và các nhiệm vụ bộ nhớ. Ngoài ra, chúng tôi thực hiện các thí nghiệm tiền huấn luyện để chứng minh thêm tính hiệu quả của cập nhật thứ hạng cao và cho thấy kết quả vượt trội so với ReLoRA.

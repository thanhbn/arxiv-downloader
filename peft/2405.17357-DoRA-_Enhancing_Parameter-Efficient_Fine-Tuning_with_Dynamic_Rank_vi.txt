DoRA: Nâng cao Tinh chỉnh Hiệu quả Tham số với Phân phối Cấp bậc Động

Yulong Mao*1,2, Kaiyu Huang*1,2, Changhao Guan1,2,
Ganglin Bao1,2, Fengran Mo3, và Jinan Xu†1,2

1Phòng thí nghiệm Chính Bắc Kinh về Phân tích và Khai thác Dữ liệu Giao thông, Bắc Kinh, Trung Quốc
2Đại học Giao thông Bắc Kinh, Bắc Kinh, Trung Quốc
3Đại học Montréal, Montréal, Canada

Tóm tắt

Tinh chỉnh các mô hình được huấn luyện trước quy mô lớn vốn là một nhiệm vụ tốn nhiều tài nguyên. Mặc dù nó có thể nâng cao khả năng của mô hình, nhưng cũng phát sinh chi phí tính toán đáng kể, đặt ra thách thức cho việc ứng dụng thực tế của các nhiệm vụ hạ nguồn. Các phương pháp tinh chỉnh hiệu quả tham số (PEFT) hiện tại như Thích ứng Cấp bậc Thấp (LoRA) dựa trên khung bypass bỏ qua các yêu cầu ngân sách tham số khác biệt giữa các ma trận trọng số, có thể dẫn đến kết quả tinh chỉnh không tối ưu. Để giải quyết vấn đề này, chúng tôi giới thiệu phương pháp Thích ứng Cấp bậc Thấp Động (DoRA). DoRA phân tách các lớp LoRA cấp bậc cao thành các thành phần cấp bậc đơn có cấu trúc, cho phép cắt tỉa động ngân sách tham số dựa trên tầm quan trọng của chúng đối với các nhiệm vụ cụ thể trong quá trình huấn luyện, tận dụng tối đa ngân sách tham số hạn chế. Kết quả thí nghiệm cho thấy DoRA có thể đạt được hiệu suất cạnh tranh so với LoRA và tinh chỉnh mô hình đầy đủ, và vượt trội hơn các baseline mạnh với cùng ngân sách tham số lưu trữ. Mã nguồn của chúng tôi có sẵn tại https://github.com/MIkumikumi0116/DoRA

1 Giới thiệu

Các Mô hình Ngôn ngữ Được huấn luyện trước (PLM) (Kenton và Toutanova, 2019; Brown et al., 2020; Liu et al., 2019; He et al., 2020, 2021b) đóng vai trò quan trọng trong Xử lý Ngôn ngữ Tự nhiên (NLP), mang lại những cải tiến đáng kể trong các nhiệm vụ hạ nguồn khác nhau (Lee et al., 2020; Mars, 2022; Raffel et al., 2020). Việc tùy chỉnh các mô hình này cho các nhiệm vụ cụ thể thường liên quan đến việc tinh chỉnh chúng để thích ứng kiến thức được huấn luyện trước với các yêu cầu cụ thể (Alabi et al., 2022; Uppaal et al., 2023). Tuy nhiên, với quy mô ngày càng tăng của PLM, chi phí tinh chỉnh mô hình đầy đủ trở nên cấm đoán (Qiu et al., 2020). Điều này đã làm nổi bật nhu cầu và tăng sự quan tâm đến các phương pháp tinh chỉnh hiệu quả tham số (PEFT) hơn (Zeng et al., 2023; Ding et al., 2023b).

Các phương pháp PEFT phổ biến giới thiệu tham số bổ sung để thích ứng với các nhiệm vụ hạ nguồn và đóng băng tất cả các tham số gốc (Li và Liang, 2021a; Liu et al., 2022; Lester et al., 2021a). Ví dụ, Thích ứng Cấp bậc Thấp (LoRA) (Hu et al., 2022a) đã trở nên phổ biến với cách tiếp cận gọn gàng bằng cách tích hợp các ma trận có thể huấn luyện cấp bậc thấp vào các ma trận trọng số cố định hiện có trong PLM. Tuy nhiên, LoRA gán các tham số có thể huấn luyện một cách đồng nhất trên tất cả các ma trận, và có các nghiên cứu (Zhang et al., 2023) chỉ ra rằng không phải tất cả các trọng số đều đóng góp như nhau cho hiệu suất tinh chỉnh. Điều này có thể dẫn đến việc sử dụng tham số không hiệu quả. Do đó, để tinh chỉnh tối ưu, có thể đánh giá nhu cầu ngân sách tham số của từng ma trận và phân bổ chiến lược các tham số hạn chế hay không?

May mắn thay, có những phương pháp như AdaLoRA (Zhang et al., 2023) có thể giảm thiểu các hạn chế của các phương pháp PEFT trước đây bằng cách giới thiệu một chiến lược phân phối tham số tinh tế hơn. Huấn luyện với AdaLoRA bắt đầu với ngân sách tham số cao hơn và mô phỏng một quá trình phân tách SVD (Singular value decomposition), dần dần cắt tỉa các giá trị kỳ dị nhỏ hơn và các vectơ kỳ dị tương ứng. Nó mở ra cánh cửa để thực hiện phân bổ thích ứng ngân sách tham số. Tuy nhiên, sự phụ thuộc vào quy hóa trực giao cho quá trình phân tách SVD mô phỏng có thể hạn chế các cải tiến tiếp theo trong hiệu quả tinh chỉnh. Ngoài ra, chiến lược cắt tỉa của AdaLoRA chỉ tập trung vào các giá trị kỳ dị và không khai thác đầy đủ tất cả thông tin có sẵn trong các ma trận chiếu, có thể dẫn đến các quyết định kém tối ưu.

Để giải quyết các thách thức hiện tại, công trình này giới thiệu phương pháp Thích ứng Cấp bậc Thấp Động (DoRA), như được mô tả trong Hình 1. Khác với các phương pháp LoRA, DoRA phân tách các lớp LoRA cấp bậc cao thành tổng của các thành phần cấp bậc đơn, đánh giá đóng góp của từng thành phần vào hiệu suất tổng thể, và cắt tỉa các thành phần có ít đóng góp hơn. Điều này cho phép phân bổ ngân sách tham số theo nhu cầu cho các module của PLM, tối đa hóa việc sử dụng ngân sách tham số hạn chế. So với các phương pháp phân bổ tham số động hiện tại (ví dụ, AdaLoRA), DoRA có thể phân bổ ngân sách tham số phù hợp hơn dựa trên một tập thông tin phong phú hơn từ các ma trận chiếu.

Tóm lại, các đóng góp của chúng tôi như sau:

• Chúng tôi giới thiệu một phương pháp PEFT mới, DoRA, vượt trội hơn hiệu suất tinh chỉnh mô hình đầy đủ với ít hơn 0,3% tham số có thể huấn luyện.

• DoRA có thể xác định hiệu quả các module trong PLM đóng vai trò quan trọng trong nhiệm vụ tinh chỉnh, từ đó phân bổ ngân sách tham số lớn hơn cho các module chính này.

• DoRA tối đa hóa việc sử dụng ngân sách tham số hạn chế. Các thí nghiệm chứng minh rằng DoRA vượt trội hơn các phương pháp baseline qua nhiều nhiệm vụ hạ nguồn dưới cùng ràng buộc ngân sách tham số.

2 Nền tảng

Sự xuất hiện của các PLM như BERT (Kenton và Toutanova, 2019), GPT (Radford et al., 2019), và Llama (Touvron et al., 2023) đã thúc đẩy có ý nghĩa lĩnh vực NLP. Được huấn luyện trên các tập dữ liệu văn bản rộng lớn, các PLM nắm bắt được các mẫu ngôn ngữ phức tạp, cho phép hiệu suất vượt trội trong các nhiệm vụ NLP khác nhau như phân loại văn bản, nhận dạng thực thể có tên, và dịch máy (Zhao et al., 2023). Tính linh hoạt của chúng trong việc thích ứng với các tập dữ liệu cụ thể thông qua tinh chỉnh khiến chúng trở nên cực kỳ đa năng để giải quyết các thách thức ngôn ngữ khác nhau.

Các PLM chủ yếu tận dụng kiến trúc Transformer (Vaswani et al., 2017) có các khối Transformer xếp chồng. Mỗi khối bao gồm hai thành phần chính: cơ chế Chú ý Đa đầu (MHA) và mạng Neural Truyền thẳng (FFN). Cụ thể, MHA nắm bắt hiệu quả các mối quan hệ ngữ cảnh trong văn bản và được cho bởi:

MHA(x) = Concatenate(head₁(x), head₂(x), ..., headₕ(x))W^o

headᵢ(x) = Softmax(xW^qᵢ)(xW^kᵢ)ᵀ/√dₕ xW^vᵢ

trong đó x∈Rⁿˣᵈ là đặc trưng đầu vào, n là độ dài chuỗi và d là chiều ẩn. Cơ chế bao gồm h đầu tự chú ý, mỗi đầu nhằm nắm bắt các khía cạnh thông tin khác nhau. Đối với mỗi đầu headᵢ, có ba ma trận chiếu: truy vấn W^qᵢ, khóa W^kᵢ, và giá trị W^vᵢ, mỗi ma trận có kích thước Rᵈˣᵈʰ, trong đó dₕ là chiều của mỗi đầu, thường được đặt là d/h. Ma trận chiếu đầu ra W^o∈Rᵈˣᵈ được sử dụng để tạo ra đầu ra cuối cùng.

Điểm chú ý được tính bằng cách chuẩn hóa tích vô hướng của các truy vấn và khóa thông qua hàm softmax và được cho bởi:

Softmax(xᵢ) = e^xᵢ/∑ⱼ₌₁ⁿ e^xⱼ

Các điểm này xác định mức độ chú ý mà mỗi vị trí chuỗi dành cho các vị trí khác. Tiếp theo, các điểm này được nhân với kết quả chiếu giá trị để tạo ra đầu ra của mỗi đầu. Cuối cùng, các đầu ra của tất cả các đầu được nối lại và nhân với ma trận chiếu đầu ra W^o, tạo thành đầu ra MHA cuối cùng.

Sau MHA, FFN tiếp tục xử lý thông tin:

FFN(x) = ReLU(xW^f₁ + b₁)W^f₂ + b₂

Điều này cho phép các tương tác phức tạp hơn giữa các đặc trưng được trích xuất bởi cơ chế tự chú ý. Mỗi khối Transformer kết hợp một kết nối dư thêm đầu vào của khối trực tiếp vào đầu ra của nó. Cách tiếp cận này giúp giảm thiểu vấn đề gradient biến mất và đảm bảo luồng thông tin nhất quán qua các lớp của mô hình.

3 Thích ứng Cấp bậc Thấp Động

Trong bài báo này, chúng tôi nhằm tối ưu hóa việc sử dụng ngân sách tham số hạn chế trong việc tinh chỉnh PLM với LoRA. Chúng tôi cải tiến dựa trên LoRA (Hu et al., 2022a) và AdaLoRA (Zhang et al., 2023), như được hiển thị trong Bảng 1. Chúng tôi đề xuất DoRA nổi bật nhờ cách tiếp cận sáng tạo, bao gồm ba chiến lược chính: một chiến lược phân tách xem lớp LoRA cấp bậc cao như một kết hợp của nhiều thành phần LoRA cấp bậc đơn, một cơ chế phân bổ cấp bậc động điều chỉnh các thành phần này dựa trên đóng góp của chúng vào hiệu suất tổng thể của mô hình và một hình phạt quy hóa để đảm bảo cắt tỉa ổn định trong suốt quá trình. Thuật toán tổng thể được hiển thị trong Thuật toán 1.

3.1 Tham số hóa

DoRA giới thiệu một góc nhìn mới về PEFT cho PLM, xây dựng và nâng cao kỹ thuật LoRA nền tảng. Một lớp LoRA tiêu chuẩn được định nghĩa là:

W = W₀ + ΔW = W₀ + AB

trong đó W là ma trận trọng số sau tinh chỉnh, W₀ biểu thị ma trận trọng số gốc, và A, B là các ma trận cấp bậc thấp được giới thiệu bởi LoRA. Ngược lại, DoRA diễn giải lại cấu hình này và được cho bởi:

W = W₀ + ∑ᵢ₌₁ʳ' ΔWᵢ = W₀ + ∑ᵢ₌₁ʳ' AᵢBᵢcᵢ

ở đây, r' đại diện cho số lượng thành phần LoRA, sẽ được giải thích chi tiết trong Phần 3.3. Một thành phần LoRA là một bộ ba Aᵢ, Bᵢ, và cᵢ, trong đó Aᵢ và Bᵢ là các ma trận cấp bậc đơn, có hình dạng d×1 và 1×d tương ứng. cᵢ là một vô hướng được sử dụng để cắt tỉa thành phần, nó được đặt là 0 nếu thành phần được cắt tỉa.

3.2 Tính điểm Quan trọng

Để đánh giá tầm quan trọng của từng thành phần LoRA, chúng tôi sử dụng cơ chế tính điểm quan trọng định lượng đóng góp của từng ΔWᵢ và được cho bởi:

sᵢ = ||ΔWᵢ||F / ||∑ⱼ₌₁ʳ' ΔWⱼ||F = ||AᵢBᵢcᵢ||F / ||∑ⱼ₌₁ʳ' AⱼBⱼcⱼ||F

ở đây, ||x||F biểu thị chuẩn Frobenius, một phép đo tính căn bậc hai của tổng bình phương của tất cả các phần tử trong ma trận.

Việc sử dụng chuẩn Frobenius cho phép chúng tôi đo tỷ lệ đóng góp của từng thành phần LoRA vào tổng độ lớn cập nhật của lớp LoRA tương ứng. Chỉ số này tạo điều kiện ước tính tác động tiềm năng lên tổng cập nhật của lớp LoRA nếu một thành phần cụ thể bị cắt tỉa. Các thành phần có tác động nhỏ hơn lên tổng độ lớn cập nhật được ưu tiên cắt tỉa. Điều này đảm bảo rằng quá trình cắt tỉa ảnh hưởng tối thiểu đến hiệu suất, tập trung vào việc loại bỏ các thành phần đóng góp ít nhất cho hiệu quả của lớp LoRA.

So với các phương pháp trước đây (Zhang et al., 2023), chúng tôi sử dụng ||ΔWᵢ||F thay vì cᵢ để đánh giá tầm quan trọng của các thành phần, từ đó kết hợp thông tin từ Aᵢ và Bᵢ để đánh giá tầm quan trọng của thành phần một cách toàn diện hơn.

Hơn nữa, để tăng cường độ chính xác của điểm quan trọng, chúng tôi sử dụng phương pháp làm mịn bằng cách áp dụng trung bình động theo mũ vào các điểm quan trọng. Điểm quan trọng được làm mịn cho thành phần LoRA thứ i tại thời điểm t, ký hiệu là ẽsᵢ(t), kết hợp điểm quan trọng hiện tại sᵢ với điểm trước đó, được điều chỉnh bởi hệ số β:

ẽsᵢ(t) = β·ẽsᵢ(t-1) + (1-β)·sᵢ

3.3 Lập lịch Tham số và Chiến lược Cắt tỉa

Ngân sách tham số đề cập đến số lượng thành phần LoRA trung bình trong mỗi lớp LoRA. Nó bắt đầu với ngân sách tham số ban đầu, b(0) = r', được đặt có chủ ý cao hơn ngân sách mục tiêu cuối cùng, b(T) = r, trong đó r' và r là các siêu tham số. Việc đặt r' lớn hơn r cho phép DoRA khám phá một phạm vi rộng hơn của các phân bổ tham số tiềm năng, tạo thuận lợi cho việc tìm kiếm phân phối tối ưu.

DoRA áp dụng chiến lược cắt tỉa nhẹ nhàng. Đối với các bộ ba được cắt tỉa Aᵢ, Bᵢ, và cᵢ, việc cắt tỉa được thực hiện chỉ bằng cách đặt cᵢ thành 0 trong khi giữ nguyên Aᵢ và Bᵢ. Trong quá trình huấn luyện tiếp theo, các bộ ba đã cắt tỉa có thể được phục hồi miễn là cᵢ được cập nhật thành giá trị khác không bằng lan truyền ngược và không bị cắt tỉa lại.

DoRA khởi động huấn luyện không cắt tỉa trong tᵢ bước đầu tiên, i biểu thị các bước ban đầu và sau đó theo một mẫu giảm dần hình khối để cắt tỉa các thành phần có điểm quan trọng thấp hơn cho đến khi các thành phần còn lại đạt ngân sách b(T). Tiếp theo, nó cố định phân phối thành phần trong tf bước cuối cùng, f biểu thị các bước cuối cùng. Bộ lập lịch ngân sách tổng thể được cho bởi:

b(t) = {
  b(0) nếu 0 ≤ t < tᵢ,
  b(0) - (b(0) - b(T)) * ((t - tᵢ)/(tf - tᵢ))³ nếu tᵢ ≤ t ≤ T - tf,
  b(T) nếu t > T - tf.
}

3.4 Bộ Điều chỉnh Cân bằng Chiều

DoRA sử dụng chuẩn Frobenius của các thành phần để cắt tỉa, với sự ưu tiên cho việc cắt những thành phần có chuẩn nhỏ hơn. Tuy nhiên, một vấn đề tiềm tàng xuất hiện khi một thành phần có hầu hết các phần tử gần bằng không và một vài phần tử có giá trị cao đáng kể, dẫn đến chuẩn Frobenius tương đối thấp và do đó được chọn để cắt tỉa. Tình huống này có thể dẫn đến những thay đổi đáng kể trong một số chiều hạn chế của tổng cập nhật, ΔW, giống như hiệu ứng bùng nổ gradient và ảnh hưởng bất lợi đến tính ổn định của mô hình và hiệu suất tinh chỉnh.

Để tránh điều này, chúng tôi giới thiệu tổn thất Bộ Điều chỉnh Cân bằng Chiều (DEM), phạt phương sai của các thành phần như:

R = (1/n) ∑ᵢ₌₁ⁿ (Var(Aᵢ) + Var(Bᵢ))

trong đó Var(Aᵢ) và Var(Bᵢ) đại diện cho phương sai của các thành phần Aᵢ và Bᵢ, với n chỉ số lượng thành phần. DEM khuyến khích phân phối đồng nhất của các phần tử trong các thành phần, tránh tác động không cân xứng từ các chiều biệt lập hoặc ít, hiệu quả giảm nhiễu từ việc cắt tỉa mô hình, và tăng cường tính ổn định của mô hình.

4 Thí nghiệm

4.1 Thiết lập Thí nghiệm

Chúng tôi so sánh DoRA với các phương pháp baseline hiện có để đánh giá hiệu suất của nó trong các nhiệm vụ hiểu ngôn ngữ tự nhiên (NLU), hỏi đáp (QA), và sinh văn bản (tóm tắt). Chúng tôi đã chọn RoBERTa (Liu et al., 2019) và Bart (Lewis et al., 2019) làm các mô hình nền tảng, được sử dụng tương ứng cho các nhiệm vụ NLU và QA, và cho các nhiệm vụ tóm tắt.

RoBERTa là phiên bản tối ưu hóa của kiến trúc BERT (Kenton và Toutanova, 2019), cải thiện đáng kể hiệu suất trên nhiều nhiệm vụ hiểu ngôn ngữ thông qua huấn luyện kéo dài, tập dữ liệu lớn hơn, và tinh chỉnh tham số tốt hơn. Bart là một mô hình được huấn luyện trước sequence-to-sequence dựa trên Transformer (Vaswani et al., 2017) được thiết kế đặc biệt cho các nhiệm vụ sinh văn bản, như tóm tắt. Nó xử lý hiệu quả các nhiệm vụ sinh khác nhau bằng cách kết hợp kiến trúc Transformer hai chiều và tự hồi quy.

Chúng tôi đã kiểm tra hiệu suất trên một số tập dữ liệu tiêu chuẩn: sử dụng tập dữ liệu GLUE (General Language Understanding Evaluation) (Wang et al., 2018) để đánh giá các nhiệm vụ NLU, SQuAD (Rajpurkar et al., 2016) (Stanford Question Answering Dataset) cho QA, và Xsum (Narayan et al., 2018) cho tóm tắt văn bản. GLUE là một tập dữ liệu để huấn luyện và kiểm tra các hệ thống NLU, bao gồm các nhiệm vụ khác nhau như phân tích cảm tình và suy luận văn bản. SQuAD là một tập dữ liệu hỏi đáp bao gồm các câu hỏi được tạo từ các bài báo Wikipedia và các câu trả lời tương ứng. Xsum cung cấp một môi trường kiểm tra cho các nhiệm vụ tóm tắt cực đoan nhằm sinh ra tóm tắt một câu, thách thức các mô hình dưới điều kiện nén thông tin cực đoan.

Chúng tôi đã chọn một số phương pháp tinh chỉnh chính thống làm baseline, bao gồm LoRA, AdaLoRA, Adapter Tuning, BitFit, và tinh chỉnh mô hình đầy đủ. LoRA tinh chỉnh trọng số mô hình bằng cách thêm ma trận cấp bậc thấp vào các ma trận được huấn luyện trước; AdaLoRA là cải tiến của LoRA, thêm cơ chế điều chỉnh thích ứng. Adapter Tuning tinh chỉnh bằng cách chèn các module mạng nhẹ vào PLM. BitFit chỉ điều chỉnh các tham số bias trong PLM. Tinh chỉnh mô hình đầy đủ là phương pháp truyền thống liên quan đến việc điều chỉnh toàn diện tất cả trọng số mô hình.

Chúng tôi báo cáo kết quả trung bình dựa trên 5 hạt giống ngẫu nhiên, như được hiển thị trong Bảng 2, Bảng 3, và Bảng 4. Các cài đặt siêu tham số cho thí nghiệm có thể được tìm thấy trong Phụ lục E.

4.2 Kết quả

Chúng tôi điều tra hiệu suất của DoRA và các phương pháp baseline qua các nhiệm vụ con của benchmark GLUE, tiến hành thí nghiệm dưới hai tình huống ngân sách tham số khác nhau.

Như được hiển thị trong Bảng 2, DoRA và AdaLoRA, sử dụng các chiến lược phân bổ tham số thích ứng, vượt trội hơn tất cả các phương pháp baseline sử dụng phân phối tham số đồng nhất, chứng minh hiệu quả đáng kể của phân bổ tham số thích ứng. Qua benchmark GLUE, DoRA vượt trội hơn LoRA 0,84% và 0,88%, và AdaLoRA 0,59% và 0,45% dưới hai ngân sách tham số, tiếp tục chứng minh tính ứng dụng rộng rãi và hiệu quả của chiến lược phân bổ tham số thích ứng của DoRA trong nhiều nhiệm vụ.

Đặc biệt đáng chú ý là hiệu suất của DoRA trên tập dữ liệu CoLA, nơi nó cho thấy cải tiến cao nhất, vượt trội hơn phương pháp baseline có hiệu suất cao nhất 1,48% và 1,73% dưới hai ngân sách tham số. Điều này làm nổi bật lợi thế của DoRA trong việc xử lý nhiệm vụ chấp nhận ngôn ngữ, thể hiện hiệu quả của nó trong việc xử lý các nhiệm vụ NLP thách thức. Tuy nhiên, hiệu suất của DoRA trên nhiệm vụ MNLI hơi tụt hậu so với AdaLoRA, có thể do MNLI là tập dữ liệu lớn nhất trong GLUE với độ phức tạp nhiệm vụ cao, chỉ ra nhu cầu tối ưu hóa thêm chiến lược phân bổ tham số thích ứng khi xử lý các nhiệm vụ quy mô lớn phức tạp.

Đáng chú ý là DoRA thể hiện hiệu quả tham số ngoại lệ, vượt trội hơn hiệu suất tinh chỉnh mô hình đầy đủ với chỉ 0,34M tham số, ít hơn 0,3% so với tinh chỉnh mô hình đầy đủ, làm nổi bật khả năng của DoRA trong việc sử dụng hiệu quả ngân sách tham số hạn chế.

Kết quả tương tự cũng được quan sát thấy trong các thí nghiệm trên SQuAD và Xsum, nơi DoRA vượt trội hơn tất cả các phương pháp PEFT baseline dưới cả hai cài đặt tham số.

5 Phân tích và Thảo luận

5.1 Hiệu quả của DEM

Để xác minh hiệu quả của DEM, chúng tôi đã kiểm tra tinh chỉnh trên các tập dữ liệu bao gồm STS-B, CoLA, và SST-2, có và không có DEM, không có DEM có nghĩa là đặt hệ số quy hóa siêu tham số η thành 0, như được hiển thị trong Bảng 5.

Việc bật DEM áp đặt hình phạt lên phương sai của các thành phần LoRA, khuyến khích phân phối trọng số đồng nhất, và tránh các biến động cực đoan trong tổng cập nhật ΔW qua một vài chiều do cắt tỉa. Tinh chỉnh với DEM được bật đạt được kết quả cao hơn, chứng minh hiệu quả của DEM.

5.2 Sở thích Phân bổ Tham số

Để xác thực xem DoRA có thể xác định các module chính trong PLM hay không, chúng tôi đặt các ngân sách cuối cùng b(T) thành 2, 4, 8, và 16, với 1,5 lần ngân sách cuối cùng làm ngân sách ban đầu b(0), và tiến hành các thí nghiệm tinh chỉnh trên tập dữ liệu SST-2 tương ứng.

Kết quả được trình bày trực quan trong Hình 2, cho thấy rằng, trong các lớp trung gian, các ma trận truy vấn và khóa được phân bổ với nhiều ngân sách tham số hơn, trong khi các ma trận giá trị được phân bổ với ít ngân sách hơn. Các ma trận đầu ra ban đầu nhận được nhiều ngân sách hơn. Trong mạng neural truyền thẳng, các ma trận chiếu thấp hơn, được biểu diễn là Wf2 trong hình, ở phía sau, đặc biệt là trong vài lớp cuối cùng, được phân bổ với rất ít ngân sách.

DoRA thể hiện cùng xu hướng phân bổ tham số qua tất cả bốn cấu hình, chứng minh khả năng của nó trong việc xác định nhất quán các module chính trong PLM và phân bổ ngân sách tham số nhiều hơn cho chúng tương ứng.

5.3 Tác động của Ngân sách Ban đầu

Chúng tôi điều tra tác động của ngân sách ban đầu b(0) qua các tập dữ liệu MRPC, STS-B, và SST-2. Chúng tôi đã tinh chỉnh các mô hình bắt đầu từ các ngân sách ban đầu khác nhau và cắt tỉa chúng đến ngân sách cuối cùng nhất quán b(T) là 2. Kết quả được trình bày trong Bảng 6. Hàng đầu tiên chỉ ra rằng khi ngân sách ban đầu là 2, nó khớp với ngân sách cuối cùng, có nghĩa là không có cắt tỉa mô hình nào được thực hiện.

Thú vị là, các phát hiện của chúng tôi cho thấy rằng việc duy trì ngân sách tham số cuối cùng không đổi trong khi bắt đầu với ngân sách tham số ban đầu cao hơn cải thiện hiệu suất mô hình. Chúng tôi gán việc cải thiện này cho ngân sách tham số ban đầu hào phóng hơn cung cấp không gian khám phá rộng hơn cho DoRA, do đó tăng cơ hội bảo tồn các tham số thiết yếu trong quá trình cắt tỉa và tối ưu hóa hiệu suất cuối cùng của mô hình.

6 Công trình Liên quan

PEFT là quan trọng cho việc tinh chỉnh PLM trong các ứng dụng thực tế. Các kỹ thuật này chủ yếu tập trung vào việc cập nhật một tập con lựa chọn các tham số của mô hình hoặc giới thiệu tham số mới ở quy mô nhỏ, cho phép sử dụng tài nguyên hiệu quả hơn. Các phương pháp này đặc biệt có giá trị trong các tình huống bị hạn chế bởi tài nguyên tính toán. Các phương pháp PEFT hiện tại có thể được chia thành ba loại: phương pháp dựa trên phép cộng, phương pháp dựa trên đặc tả, và phương pháp dựa trên tham số hóa lại (Ding et al., 2022).

Các phương pháp dựa trên phép cộng đạt được điều chỉnh bằng cách thêm các module bổ sung hoặc tham số có thể huấn luyện vào PLM, như adapter có thể huấn luyện hoặc prompt mềm. Các phương pháp này có thể mở rộng và áp dụng cho các mô hình có kích thước khác nhau, với khoảng cách hiệu suất giữa chúng và tinh chỉnh mô hình đầy đủ thu hẹp khi kích thước mô hình tăng. Ví dụ bao gồm adapter (Houlsby et al., 2019; Pfeiffer et al., 2021; He et al., 2021a; Zhu et al., 2021), chèn các module neural nhỏ vào các lớp transformer để điều chỉnh, và tinh chỉnh dựa trên prompt (Li và Liang, 2021b; Gao et al., 2021; Hu et al., 2022b; Tan et al., 2022; Lester et al., 2021b; Vu et al., 2021), kích thích PLM bằng cách thêm ngữ cảnh bổ sung xung quanh đầu vào gốc.

Các phương pháp dựa trên đặc tả tập trung vào việc tinh chỉnh một số tham số vốn có trong mô hình mà không thay đổi cấu trúc nội tại của nó (Vucetic et al., 2022; Holmes et al., 2021). Bằng cách trực tiếp đặc tả phần nào của tham số cần tối ưu hóa, các phương pháp này đạt được thích ứng mô hình hiệu quả, duy trì hiệu suất gần với tinh chỉnh tham số đầy đủ trong khi giảm số lượng tham số được điều chỉnh. Ví dụ bao gồm BitFit (Ben Zaken et al., 2022), chỉ tối ưu hóa các hạng bias trong mô hình, và Diff Pruning (Guo et al., 2021), giới thiệu tính thưa thớt bằng cách tối ưu hóa một vectơ khác biệt.

Các phương pháp dựa trên tham số hóa lại tối ưu hóa mô hình bằng cách biến đổi tham số thích ứng thành các dạng hiệu quả hơn, thường dựa trên giả thuyết cấp bậc thấp. Các phương pháp này (Holmes et al., 2021; Karimi Mahabadi et al., 2021; Edalati et al., 2022; Zhang et al., 2023; Lialin et al., 2023; Ding et al., 2023a; Valipour et al., 2023; Su et al., 2024; Liu et al., 2024) nhằm giảm chi phí tính toán và bộ nhớ bằng cách tối ưu hóa tham số proxy chiều thấp trong khi duy trì hoặc vượt trội hiệu suất của tinh chỉnh tham số đầy đủ. Chúng dựa trên lý thuyết rằng các thích ứng PLM với các nhiệm vụ hạ nguồn vốn có cấp bậc thấp. Ví dụ bao gồm LoRA (Hu et al., 2022a), tối ưu hóa dựa trên giả thuyết về cấp bậc nội tại thấp của các thay đổi trọng số.

7 Kết luận

Trong bài báo này, chúng tôi giới thiệu Thích ứng Cấp bậc Thấp Động (DoRA), một phương pháp mới nhằm nâng cao hiệu quả tinh chỉnh PLM bằng cách điều chỉnh động phân phối tham số. DoRA sáng tạo phân bổ ngân sách tham số dựa trên tầm quan trọng của chúng đối với các nhiệm vụ cụ thể, chứng minh những cải tiến đáng kể trong các ứng dụng NLP. Kết quả thí nghiệm cho thấy DoRA vượt trội hơn các phương pháp baseline, làm nổi bật tiềm năng của nó cho việc áp dụng rộng rãi hơn trong các nỗ lực tối ưu hóa mô hình.

Sự đổi mới của DoRA nằm ở việc áp dụng chiến lược phân bổ tham số thích ứng, không giống như phân phối đồng nhất truyền thống, điều chỉnh động phân phối ngân sách tham số dựa trên đóng góp của chúng. Ngoài ra, DoRA sử dụng phương pháp phân tách theo thành phần để xử lý các lớp LoRA, xem các lớp LoRA cấp bậc cao như một kết hợp của các thành phần LoRA cấp bậc đơn. Các thành phần này được điều chỉnh thông qua cơ chế phân bổ cấp bậc động, được cắt tỉa theo đóng góp của chúng vào hiệu suất mô hình tổng thể. Để đảm bảo cắt tỉa ổn định trong suốt quá trình, DoRA kết hợp một hạng phạt quy hóa tập trung vào việc giảm phương sai thành phần.

Hạn chế

Nghiên cứu của chúng tôi xác nhận hiệu quả của DoRA trong một số nhiệm vụ NLP. Tuy nhiên, đánh giá của nó đã bị hạn chế trong các nhiệm vụ này, và hiệu quả của nó trong việc xử lý các thách thức NLP phức tạp hơn, như dịch máy hoặc các nhiệm vụ đa phương thức, vẫn chưa được thiết lập. Hơn nữa, các mô hình được sử dụng trong thí nghiệm của chúng tôi hơi hạn chế về quy mô, vì chúng tôi chưa tiến hành thí nghiệm với các mô hình ngôn ngữ lớn (LLM). Giải quyết hạn chế này, công việc tương lai có thể khám phá tiềm năng của DoRA trong các lĩnh vực tinh vi này của NLP.

Lời cảm ơn

Công trình này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62376019, 61976015, 61976016, 61876198 và 61370130) và Quỹ Nhân tài của Đại học Giao thông Bắc Kinh (2024JBRC005). Chúng tôi chân thành cảm ơn các nhà bình duyệt vì những nhận xét sâu sắc và đề xuất cải thiện chất lượng bài báo.

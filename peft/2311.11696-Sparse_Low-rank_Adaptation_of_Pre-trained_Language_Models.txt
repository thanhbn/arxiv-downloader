# 2311.11696.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/peft/2311.11696.pdf
# File size: 2175155 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Sparse Low-rank Adaptation of Pre-trained Language Models
Ning Ding1∗, Xingtai Lv1∗, Qiaosen Wang4, Yulin Chen2
Bowen Zhou1†,Zhiyuan Liu2,3†,Maosong Sun2,3†
1Department of Electronic Engineering, Tsinghua University
2Department of Computer Science and Technology, Tsinghua University
3BNRIST, IAI, Tsinghua University,4Department of Statistics, The University of Chicago
dn97@mail.tsinghua.edu.cn ,lvxt20@mails.tsinghua.edu.cn
Abstract
Fine-tuning pre-trained large language mod-
els in a parameter-efficient manner is widely
studied for its effectiveness and efficiency.
The popular method of low-rank adaptation
(LoRA) offers a notable approach, hypothe-
sizing that the adaptation process is intrinsi-
cally low-dimensional. Although LoRA has
demonstrated commendable performance, it is
implemented with a fixed and unalterable in-
trinsic rank that might not always be the ideal
choice. Recognizing the need for more flexi-
ble adaptation, we extend the methodology of
LoRA to an innovative approach we call sparse
low-rank adaptation (SoRA) that enables dy-
namic adjustments to the intrinsic rank during
the adaptation process. We achieve this through
the incorporation of a gate unit optimized with
proximal gradient method in the training stage,
controlling the cardinality of rank under the
sparsity of the gate. In the subsequent inference
stage, we eliminate the parameter blocks cor-
responding to the zeroed-out ranks, to reduce
each SoRA module back to a concise yet rank-
optimal LoRA. Our approach strengthens the
representation power of LoRA by initializing
it with a higher rank, while efficiently taming
a temporarily increased number of parameters
via updating in a sparse way. We further intro-
duce a sparsifying scheduler for SoRA, aiming
to examine the impact of the number of non-
zero parameters on the model’s memorization
and generalization. Our experimental results
demonstrate that SoRA can outperform other
baselines even with 70% retained parameters
and 70% training time.
1 Introduction
Adapting large-scale pre-trained language mod-
els (Devlin et al., 2019; Brown et al., 2020; He et al.,
2020; Bommasani et al., 2021; Han et al., 2021;
Touvron et al., 2023) in a parameter-efficient (He
∗equal contributions
†corresponding authorset al., 2022; Ding et al., 2023; Hu et al., 2023) man-
ner is increasingly gaining traction within the re-
search community. The methods of this paradigm
typically keep most of the parameters of the un-
derlying model unchanged, either insert additional
trainable parameters into the model (Houlsby et al.,
2019; Li and Liang, 2021), or specify a small num-
ber of parameters (Zaken et al., 2021; Liu et al.,
2021; Su et al., 2023) to be trainable or reparame-
terize the adaptation process into a more efficient
form (Hu et al., 2021; Qin et al., 2021). They have
been validated to be effective across various mod-
els and tasks, often yielding comparable or even
better results than full-parameter fine-tuning.
The development potential of parameter-efficient
fine-tuning became evident after extensive vali-
dation of its performance. These methods offer
the opportunity to adapt the base model to fit any
data, allowing for enhancements and customiza-
tion of language models tailored to specific tasks
and personalized user characteristics. Due to the
lightweight nature of the optimized parameters,
they can be seamlessly plugged into the model, al-
lowing targeted enhancements to be made. Among
these methods, low-rank adaptation ( LORA(Hu
et al., 2021)) is considered one of the most efficient
methods at present. It assumes that the change of
the model’s parameters after adaptation is "intrin-
sically low-dimensional" and performs adaptation
by optimizing the matrix obtained from low-rank
decomposition. LoRA avoids forward propaga-
tion latency caused by inserting additional neural
modules while demonstrating stable performance.
Although effective, the setup of the intrinsic rank
(normally as a hyperparameter) is still unclear. In-
tuitively, a larger rank brings larger optimization
space and creates the capacity to handle more chal-
lenging tasks. However, in practice, the optimal
intrinsic rank would vary according to multiple
factors such as the backbone model and the task.
Given the enormous computational cost ofarXiv:2311.11696v1  [cs.CL]  20 Nov 2023

--- PAGE 2 ---
searching hyperparameters on large-scale models
(such as GPT-3 (Brown et al., 2020) with 175 bil-
lion parameters and LLaMA (Touvron et al., 2023)
with 700 million to 65 billion parameters), develop-
ing a method based on adaptive ranks is a natural
approach. Some existing work has attempted to
explore this direction (Valipour et al., 2022; Zhang
et al., 2023), but they are largely heuristic or intro-
duce additional costs. In this paper, we propose
SoRA, a simple, effective, and automated method
for adaptive parameter-efficient fine-tuning. We
introduce a gating module with a proximal gradient
decent update under L1 regularization to control
the sparsity of the updated matrices. After train-
ing, the zero entry of the gating vector records
the columns of the down-projection matrix and the
rows of the up-projection matrix, which can be
simply dropped and stored in a more parameter-
efficient manner. Compared to other adaptive ap-
proaches, the proximal gradient method has a clear
mathematical meaning and does not have to involve
other computations and heuristics. For example,
AdaLoRA (Zhang et al., 2023) introduces an addi-
tional regularizer to ensure that the lower and upper
projection matrices strictly adhere to the definition
of singular value decomposition (SVD), with each
matrix being orthogonal. However, this regular-
ization term incurs substantial computational over-
head due to the gradient calculations. In contrast,
we eliminate this requirement and instead selec-
tively filter low-rank components by controlling
the intermediate diagonal matrix. We detailedly
compare SoRA and related methods in Section 3.
The mechanism of SoRA also allows us to con-
trol the sparsity temporarily and investigate the
relationship between the number of non-zero train-
able parameters and memorization and generaliza-
tion capabilities. We propose a sparsifying sched-
uler and find that the process of model adapta-
tion exhibits a strong “compression capability”,
and even a tiny portion of parameters (lower than
LoRA rank being 1) could retain considerable per-
formance. Extensive experiments are conducted to
demonstrate the effectiveness of our method. Par-
ticularly, our model could consistently outperform
parameter-efficient baselines with fewer parame-
ters and 30% shorter training time on a wide range
of downstream tasks. The code of this work will be
publicly available at https://github.com/
TsinghuaC3I/SoRA .2 A Closer Look to Adaptive Rank
Related Work. Before introducing our approach,
we first briefly recap parameter-efficient tuning
and our backbone low-rank adaptation (LoRA).
Parameter-efficient tuning is a set of methods that
only optimize a small portion of parameters and
keep the main model untouched for adaptation.
Some parameter-efficient methods would insert ad-
ditional neural modules or parameters to the back-
bone model, such as Adapter (Houlsby et al., 2019),
Prefix and Prompt Tuning (Li and Liang, 2021;
Lester et al., 2021). And another line of such meth-
ods attempts to specify particular parameters to be
trainable or prunable (Guo et al., 2021; Zhao et al.,
2020; Zaken et al., 2021). Researchers derive a
series of variants of parameter-efficient methods to
improve the effectiveness or efficiency (Karimi Ma-
habadi et al., 2021; Hu et al., 2022; Sung et al.,
2022; He et al., 2022). Recently, the applications
of parameter-efficient fine-tuning are expanded to
multi-modal and instruction-tuning scenarios (Gao
et al., 2023; Dettmers et al., 2023). In this paper,
we focus more on LoRA (Hu et al., 2021), which
uses low-rank matrices to approximate the change
of weights.
In LoRA, pre-trained weights (denoted as W0∈
Rp×q) are frozen, and the trainable LoRA modules
are low-rank decomposition matrices Wd∈Rr×q
andWu∈Rp×rof the change of each weight ma-
trix∆=WuWd∈Rp×q. In this way, the output
of the current layer hcould be represented as
y← −W0x+WuWdx, (1)
where r≪min{p, q}is a hyper-parameter of
“intrinsic dimension” that controls the size of
low-rank matrices and the number of trainable
parameters. In this section, we primarily focus on
the last term, denoting z← −WuWdx.
Adaptive Rank on LoRA. Despite a great step
forward in tractability and efficiency, LoRA is still
restricted by its inflexibility in selecting the opti-
mal rank r. Unlike continuous hyperparameters
such as learning rate and weight decay that can be
tuned adaptively online during the training process,
LoRA rank rtakes discrete values – the change of
which will directly alter the model structures. The
optimal choice of rank can vary across different
backbone models and downstream tasks. A conser-
vative choice of huge rank rcan waste training time
and computation resources, while progressively set-
tingrtiny may degrade model performance and

--- PAGE 3 ---
···<latexit sha1_base64="cAiOZblwH8iALsf/vkdYLcRxSgQ=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> ·[[·
<latexit sha1_base64="cAiOZblwH8iALsf/vkdYLcRxSgQ=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> ·[[<latexit sha1_base64="UjUn3B7ufgCOmxVTlETrJ0C/vJY=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>x
<latexit sha1_base64="7LjW4inxM3IqVcFm0MkAOftM7UI=">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>Wd
<latexit sha1_base64="pIWFDq2Tt0ud+NvmF88Xp+emVao=">AAAB6nicbVBNS8NAEJ34WetX1aOXxSKIh5BIUY8FLx4r2g9oY9lsN+3SzW7Y3Qgh9Cd48aCIV3+RN/+N2zYHbX0w8Hhvhpl5YcKZNp737aysrq1vbJa2yts7u3v7lYPDlpapIrRJJJeqE2JNORO0aZjhtJMoiuOQ03Y4vpn67SeqNJPiwWQJDWI8FCxiBBsr3WeP5/1K1XO9GdAy8QtShQKNfuWrN5AkjakwhGOtu76XmCDHyjDC6aTcSzVNMBnjIe1aKnBMdZDPTp2gU6sMUCSVLWHQTP09keNY6ywObWeMzUgvelPxP6+bmug6yJlIUkMFmS+KUo6MRNO/0YApSgzPLMFEMXsrIiOsMDE2nbINwV98eZm0Llz/0q3d1ap1t4ijBMdwAmfgwxXU4RYa0AQCQ3iGV3hzuPPivDsf89YVp5g5gj9wPn8A/fCNjg==</latexit>y⇤
<latexit sha1_base64="z65MLNYS9m9NIMg0IO7wQhtVhZc=">AAAB8XicbVDLSsNAFL2pr1pfVZduBovgqiQi6rLgxmUF+8A2lMn0ph06mYSZiVBC/8KNC0Xc+jfu/BsnbRbaemDgcM69zLknSATXxnW/ndLa+sbmVnm7srO7t39QPTxq6zhVDFssFrHqBlSj4BJbhhuB3UQhjQKBnWBym/udJ1Sax/LBTBP0IzqSPOSMGis99iNqxkGYjWaDas2tu3OQVeIVpAYFmoPqV38YszRCaZigWvc8NzF+RpXhTOCs0k81JpRN6Ah7lkoaofazeeIZObPKkISxsk8aMld/b2Q00noaBXYyT6iXvVz8z+ulJrzxMy6T1KBki4/CVBATk/x8MuQKmRFTSyhT3GYlbEwVZcaWVLEleMsnr5L2Rd27ql/eX9Ya9aKOMpzAKZyDB9fQgDtoQgsYSHiGV3hztPPivDsfi9GSU+wcwx84nz/gTpEA</latexit>g
<latexit sha1_base64="pcjqgRbl/D1PXi1iZ64D301adTY=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit>Wu
<latexit sha1_base64="ot/yvaZQPa9zErjmSLBW76zU60o=">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit>gt ⌘trgL0( )
<latexit sha1_base64="8/UihlMxlt0wyylqbLxBDRogGzg=">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T(·)
<latexit sha1_base64="F+Pa0tnka1i85dgk3KuWQdNTg88=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>z
·
<latexit sha1_base64="cAiOZblwH8iALsf/vkdYLcRxSgQ=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> ·[[<latexit sha1_base64="UjUn3B7ufgCOmxVTlETrJ0C/vJY=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>x
<latexit sha1_base64="7LjW4inxM3IqVcFm0MkAOftM7UI=">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>Wd
<latexit sha1_base64="pIWFDq2Tt0ud+NvmF88Xp+emVao=">AAAB6nicbVBNS8NAEJ34WetX1aOXxSKIh5BIUY8FLx4r2g9oY9lsN+3SzW7Y3Qgh9Cd48aCIV3+RN/+N2zYHbX0w8Hhvhpl5YcKZNp737aysrq1vbJa2yts7u3v7lYPDlpapIrRJJJeqE2JNORO0aZjhtJMoiuOQ03Y4vpn67SeqNJPiwWQJDWI8FCxiBBsr3WeP5/1K1XO9GdAy8QtShQKNfuWrN5AkjakwhGOtu76XmCDHyjDC6aTcSzVNMBnjIe1aKnBMdZDPTp2gU6sMUCSVLWHQTP09keNY6ywObWeMzUgvelPxP6+bmug6yJlIUkMFmS+KUo6MRNO/0YApSgzPLMFEMXsrIiOsMDE2nbINwV98eZm0Llz/0q3d1ap1t4ijBMdwAmfgwxXU4RYa0AQCQ3iGV3hzuPPivDsf89YVp5g5gj9wPn8A/fCNjg==</latexit>y⇤
<latexit sha1_base64="z65MLNYS9m9NIMg0IO7wQhtVhZc=">AAAB8XicbVDLSsNAFL2pr1pfVZduBovgqiQi6rLgxmUF+8A2lMn0ph06mYSZiVBC/8KNC0Xc+jfu/BsnbRbaemDgcM69zLknSATXxnW/ndLa+sbmVnm7srO7t39QPTxq6zhVDFssFrHqBlSj4BJbhhuB3UQhjQKBnWBym/udJ1Sax/LBTBP0IzqSPOSMGis99iNqxkGYjWaDas2tu3OQVeIVpAYFmoPqV38YszRCaZigWvc8NzF+RpXhTOCs0k81JpRN6Ah7lkoaofazeeIZObPKkISxsk8aMld/b2Q00noaBXYyT6iXvVz8z+ulJrzxMy6T1KBki4/CVBATk/x8MuQKmRFTSyhT3GYlbEwVZcaWVLEleMsnr5L2Rd27ql/eX9Ya9aKOMpzAKZyDB9fQgDtoQgsYSHiGV3hztPPivDsfi9GSU+wcwx84nz/gTpEA</latexit>g
<latexit sha1_base64="pcjqgRbl/D1PXi1iZ64D301adTY=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit>Wu<latexit sha1_base64="ot/yvaZQPa9zErjmSLBW76zU60o=">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit>gt ⌘trgL0( )
<latexit sha1_base64="8/UihlMxlt0wyylqbLxBDRogGzg=">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T(·)
<latexit sha1_base64="F+Pa0tnka1i85dgk3KuWQdNTg88=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>z4x33x14x14x13x43x1
<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )<latexit sha1_base64="NfIpreFiwZKqcEZ9f+kK1kWNKNc=">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit> KXk=1kg(k)k1
<latexit sha1_base64="fQbJT0bmzDSzA+yL/oTkkH6TgLg=">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvgapgRUZcFNy5cVLAPmA4lk2ba0EwyJBmhDP0MNy4UcevXuPNvzLSz0NYDgcM595JzT5Rypo3nfTuVtfWNza3qdm1nd2//oH541NEyU4S2ieRS9SKsKWeCtg0znPZSRXEScdqNJreF332iSjMpHs00pWGCR4LFjGBjpaCfYDMmmOf3s0G94bneHGiV+CVpQInWoP7VH0qSJVQYwrHWge+lJsyxMoxwOqv1M01TTCZ4RANLBU6oDvN55Bk6s8oQxVLZJwyaq783cpxoPU0iO1lE1MteIf7nBZmJb8KciTQzVJDFR3HGkZGouB8NmaLE8KklmChmsyIyxgoTY1uq2RL85ZNXSefC9a/cy4fLRtMt66jCCZzCOfhwDU24gxa0gYCEZ3iFN8c4L86787EYrTjlzjH8gfP5A33vkVc=</latexit>L<latexit sha1_base64="8uB+wur6y1P5uh20XI3SQtWrgok=">AAACMHicbVDLSgMxFM34rPVVdekmWJQWYZiRom4KBRcKuqhgH9Bph0yaaUMzmSHJCGWYT3Ljp+hGQRG3foXpY1FbDwTOPffeJOd4EaNSWda7sbS8srq2ntnIbm5t7+zm9vbrMowFJjUcslA0PSQJo5zUFFWMNCNBUOAx0vAGV6N+45EISUP+oIYRaQeox6lPMVJacnPXToBUHyOW3KUn5ZnCtQqN4qnD9FVd5Mg4cJNB+TbtJDx16kQo2OskhUFxUri2m8tbpjUGXCT2lOTBFFU39+J0QxwHhCvMkJQt24pUO0FCUcxImnViSSKEB6hHWppyFBDZTsaGU3islS70Q6EPV3Cszm4kKJByGHh6cuRIzvdG4n+9Vqz8y3ZCeRQrwvHkIT9mUIVwlB7sUkGwYkNNEBZU/xXiPhIIK51xVodgz1teJPUz0z43S/elfMWcxpEBh+AIFIANLkAF3IAqqAEMnsAr+ACfxrPxZnwZ35PRJWO6cwD+wPj5BWUFqb4=</latexit>L=L0(W)+ nXk=Kkg(k)k1Non-zero
<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )
<latexit sha1_base64="oMVNr0TY+RuNTPo/mXm4PRr/4ks=">AAAB/XicbVDLSsNAFJ3UV62v+Ni5GSyCq5JIUZdFNy4r2Ac0IUwmk3boJBNmboRair/ixoUibv0Pd/6N0zYLbT0wcDjnXO6dE2aCa3Ccb6u0srq2vlHerGxt7+zu2fsHbS1zRVmLSiFVNySaCZ6yFnAQrJspRpJQsE44vJn6nQemNJfpPYwy5iekn/KYUwJGCuwjT5hwRLBHIwnYY0ACCOyqU3NmwMvELUgVFWgG9pcXSZonLAUqiNY918nAHxMFnAo2qXi5ZhmhQ9JnPUNTkjDtj2fXT/CpUSIcS2VeCnim/p4Yk0TrURKaZEJgoBe9qfif18shvvLHPM1yYCmdL4pzgUHiaRU44opRECNDCFXc3IrpgChCwRRWMSW4i19eJu3zmntRq9/Vq43roo4yOkYn6Ay56BI10C1qohai6BE9o1f0Zj1ZL9a79TGPlqxi5hD9gfX5A/BClOg=</latexit> ·⌘t
<latexit sha1_base64="KMS8K7k8Fpgib6SgzOKf+ZCOSwY=">AAAB/XicbVDLSsNAFJ34rPUVHzs3g0VwFRIp6rLgxmUF+4AmhMlk0g6dTMLMjVBL8VfcuFDErf/hzr9x2mahrQcGDuecy71zolxwDa77ba2srq1vbFa2qts7u3v79sFhW2eFoqxFM5GpbkQ0E1yyFnAQrJsrRtJIsE40vJn6nQemNM/kPYxyFqSkL3nCKQEjhfaxL0w4JtincQbYZ0BCCO2a67gz4GXilaSGSjRD+8uPM1qkTAIVROue5+YQjIkCTgWbVP1Cs5zQIemznqGSpEwH49n1E3xmlBgnmTJPAp6pvyfGJNV6lEYmmRIY6EVvKv7n9QpIroMxl3kBTNL5oqQQGDI8rQLHXDEKYmQIoYqbWzEdEEUomMKqpgRv8cvLpH3heJdO/a5eazhlHRV0gk7ROfLQFWqgW9RELUTRI3pGr+jNerJerHfrYx5dscqZI/QH1ucP6j6U1A==</latexit> ·⌘t
<latexit sha1_base64="mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>⇠
<latexit sha1_base64="2ib/1NcO2EZySJ8nP9FjmEGX2Ic=">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRaheCi7UtRjwYvHivYD2rVk02wbmk2WJCssS3+CFw+KePUXefPfmLZ70NYHA4/3ZpiZF8ScaeO6305hbX1jc6u4XdrZ3ds/KB8etbVMFKEtIrlU3QBrypmgLcMMp91YURwFnHaCyc3M7zxRpZkUDyaNqR/hkWAhI9hY6T59PB+UK27NnQOtEi8nFcjRHJS/+kNJkogKQzjWuue5sfEzrAwjnE5L/UTTGJMJHtGepQJHVPvZ/NQpOrPKEIVS2RIGzdXfExmOtE6jwHZG2Iz1sjcT//N6iQmv/YyJODFUkMWiMOHISDT7Gw2ZosTw1BJMFLO3IjLGChNj0ynZELzll1dJ+6LmXdbqd/VKo5rHUYQTOIUqeHAFDbiFJrSAwAie4RXeHO68OO/Ox6K14OQzx/AHzucP/CKNiA==</latexit>y⇤
Input & Output
··<latexit sha1_base64="UjUn3B7ufgCOmxVTlETrJ0C/vJY=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>x
<latexit sha1_base64="7LjW4inxM3IqVcFm0MkAOftM7UI=">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>Wd
<latexit sha1_base64="pcjqgRbl/D1PXi1iZ64D301adTY=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit>Wu
<latexit sha1_base64="ot/yvaZQPa9zErjmSLBW76zU60o=">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit>gt ⌘trgL0( )
<latexit sha1_base64="8/UihlMxlt0wyylqbLxBDRogGzg=">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T(·)<latexit sha1_base64="F+Pa0tnka1i85dgk3KuWQdNTg88=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>zDrop after trainingZeroNon-zero<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )
<latexit sha1_base64="mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>⇠
<latexit sha1_base64="2ib/1NcO2EZySJ8nP9FjmEGX2Ic=">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRaheCi7UtRjwYvHivYD2rVk02wbmk2WJCssS3+CFw+KePUXefPfmLZ70NYHA4/3ZpiZF8ScaeO6305hbX1jc6u4XdrZ3ds/KB8etbVMFKEtIrlU3QBrypmgLcMMp91YURwFnHaCyc3M7zxRpZkUDyaNqR/hkWAhI9hY6T59PB+UK27NnQOtEi8nFcjRHJS/+kNJkogKQzjWuue5sfEzrAwjnE5L/UTTGJMJHtGepQJHVPvZ/NQpOrPKEIVS2RIGzdXfExmOtE6jwHZG2Iz1sjcT//N6iQmv/YyJODFUkMWiMOHISDT7Gw2ZosTw1BJMFLO3IjLGChNj0ynZELzll1dJ+6LmXdbqd/VKo5rHUYQTOIUqeHAFDbiFJrSAwAie4RXeHO68OO/Ox6K14OQzx/AHzucP/CKNiA==</latexit>y⇤Input & OutputDrop after trainingZeroNon-zeroInput & Output
LoRASoRA
Multi-head AttentionAdd & LayerNormAdd & LayerNormFeed Forward Net
QKVWWWHidden StatesPreﬁxLoRALoRAPreﬁxTransformer Layer× L
+·
<latexit sha1_base64="cAiOZblwH8iALsf/vkdYLcRxSgQ=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> ·[[<latexit sha1_base64="UjUn3B7ufgCOmxVTlETrJ0C/vJY=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>x
<latexit sha1_base64="8/UihlMxlt0wyylqbLxBDRogGzg=">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T(·)
<latexit sha1_base64="F+Pa0tnka1i85dgk3KuWQdNTg88=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>z<latexit sha1_base64="NfIpreFiwZKqcEZ9f+kK1kWNKNc=">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit> KXk=1kg(k)k1
<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )
<latexit sha1_base64="mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>⇠
Drop after trainingZeroNon-zeroInput & OutputProximal Gradient DescentGatingDown-projectionUp-projection<latexit sha1_base64="SQNLzP+oVKTBulPSpmKN+TfSpd4=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJM21oJjMkd4Qy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1gNOE+xEdKREKRtFKj/2I4jgIs/FsUK64NXcBsk68nFQgR3NQ/uoPY5ZGXCGT1Jie5yboZ1SjYJLPSv3U8ISyCR3xnqWKRtz42SLxjFxYZUjCWNunkCzU3xsZjYyZRoGdnCc0q95c/M/rpRje+JlQSYpcseVHYSoJxmR+PhkKzRnKqSWUaWGzEjammjK0JZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMEzvMKbY5wX5935WI4WnHznFP7A+fwB4AWQ+w==</latexit>h
<latexit sha1_base64="HBl2VMqsA9H1oNFDXe3UKmJfeFw=">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvYVZmRoi4LblxWsA+YDiWTZtrQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3knNPmHCmjet+O6WNza3tnfJuZW//4PCoenzS1TJVhHaI5FL1Q6wpZ4J2DDOc9hNFcRxy2gund7nfe6JKMykezSyhQYzHgkWMYGMlfxBjMwmjbDK/HFZrbsNdAK0TryA1KNAeVr8GI0nSmApDONba99zEBBlWhhFO55VBqmmCyRSPqW+pwDHVQbaIPEcXVhmhSCr7hEEL9fdGhmOtZ3FoJ/OIetXLxf88PzXRbZAxkaSGCrL8KEo5MhLl96MRU5QYPrMEE8VsVkQmWGFibEsVW4K3evI66V41vOtG86FZa9WLOspwBudQBw9uoAX30IYOEJDwDK/w5hjnxXl3PpajJafYOYU/cD5/AERUkSw=</latexit>h0<latexit sha1_base64="nbqJXXGN5BTEUvsIFXww4ZYe/LA=">AAAB83icbVDLSgMxFL3xWeur6tJNsAgupMxIUZcFNy4r2Ad0hpLJZNrQTGZIMkIZ+htuXCji1p9x59+YaWehrQcCh3Pu5Z6cIBVcG8f5RmvrG5tb25Wd6u7e/sFh7ei4q5NMUdahiUhUPyCaCS5Zx3AjWD9VjMSBYL1gclf4vSemNE/ko5mmzI/JSPKIU2Ks5HkxMeMgynuzYTis1Z2GMwdeJW5J6lCiPax9eWFCs5hJQwXReuA6qfFzogyngs2qXqZZSuiEjNjAUklipv18nnmGz60S4ihR9kmD5+rvjZzEWk/jwE4WGfWyV4j/eYPMRLd+zmWaGSbp4lCUCWwSXBSAQ64YNWJqCaGK26yYjoki1NiaqrYEd/nLq6R71XCvG82HZr11WdZRgVM4gwtw4QZacA9t6ACFFJ7hFd5Qhl7QO/pYjK6hcucE/gB9/gBBlZHF</latexit>Wd
<latexit sha1_base64="/zBQzt27borSCLHZJETVK/L3JjQ=">AAAB83icbVDLSsNAFL2pr1pfVZduBovgQkoipbosuHFZwT6gCWUynbRDJ5MwD6GE/oYbF4q49Wfc+TdO2iy09cDA4Zx7uWdOmHKmtOt+O6WNza3tnfJuZW//4PCoenzSVYmRhHZIwhPZD7GinAna0Uxz2k8lxXHIaS+c3uV+74lKxRLxqGcpDWI8FixiBGsr+X6M9SSMst58aIbVmlt3F0DrxCtIDQq0h9Uvf5QQE1OhCcdKDTw31UGGpWaE03nFN4qmmEzxmA4sFTimKsgWmefowiojFCXSPqHRQv29keFYqVkc2sk8o1r1cvE/b2B0dBtkTKRGU0GWhyLDkU5QXgAaMUmJ5jNLMJHMZkVkgiUm2tZUsSV4q19eJ93rutesNx4atdZVUUcZzuAcLsGDG2jBPbShAwRSeIZXeHOM8+K8Ox/L0ZJT7JzCHzifP1tZkdY=</latexit>Wu<latexit sha1_base64="QxHJIYnglv0qz/Wz78YlSTh0Gbg=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>g<latexit sha1_base64="dNEdt8VzjdxuWRV2qtIdvhVZt+I=">AAACMnicbZBNS+RAEIY7fq2Oro569NI4LOhhh0REPQp6WMGDgqPCZAiVnsrY2OmE7srCEPKbvPhLBA/rQRGv/gh7xhG/tqDh4X2r6Ko3zpW05Pv/vLHxicmpH9Mztdm5n/ML9cWlU5sVRmBLZCoz5zFYVFJjiyQpPM8NQhorPIsv9wb+2V80Vmb6hPo5dlLoaZlIAeSkqH4QpkAXcVL2qqikiv8OkSAiHmqIFUTlu13xIQtQ5WEV+WtvTriPiqBaj+oNv+kPi3+HYAQNNqqjqH4TdjNRpKhJKLC2Hfg5dUowJIXCqhYWFnMQl9DDtkMNKdpOOTy54r+c0uVJZtzTxIfqx4kSUmv7aew6B3var95A/J/XLijZ6ZRS5wWhFq8fJYXilPFBfrwrDQpSfQcgjHS7cnEBBgS5lGsuhODryd/hdKMZbDU3jzcbu81RHNNsha2yNRawbbbL/rAj1mKCXbFbds8evGvvznv0nl5bx7zRzDL7VN7zC+Blq6w=</latexit>gt ⌘trgL0( )Update <latexit sha1_base64="QxHJIYnglv0qz/Wz78YlSTh0Gbg=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>g·
<latexit sha1_base64="cAiOZblwH8iALsf/vkdYLcRxSgQ=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> ·[[<latexit sha1_base64="UjUn3B7ufgCOmxVTlETrJ0C/vJY=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>x
<latexit sha1_base64="8/UihlMxlt0wyylqbLxBDRogGzg=">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T(·)
<latexit sha1_base64="F+Pa0tnka1i85dgk3KuWQdNTg88=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>z<latexit sha1_base64="NfIpreFiwZKqcEZ9f+kK1kWNKNc=">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit> KXk=1kg(k)k1
<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )
<latexit sha1_base64="mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>⇠
Drop after trainingZeroNon-zeroInput & OutputProximal Gradient DescentGatingDown-projectionUp-projection<latexit sha1_base64="SQNLzP+oVKTBulPSpmKN+TfSpd4=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJM21oJjMkd4Qy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1gNOE+xEdKREKRtFKj/2I4jgIs/FsUK64NXcBsk68nFQgR3NQ/uoPY5ZGXCGT1Jie5yboZ1SjYJLPSv3U8ISyCR3xnqWKRtz42SLxjFxYZUjCWNunkCzU3xsZjYyZRoGdnCc0q95c/M/rpRje+JlQSYpcseVHYSoJxmR+PhkKzRnKqSWUaWGzEjammjK0JZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMEzvMKbY5wX5935WI4WnHznFP7A+fwB4AWQ+w==</latexit>h
<latexit sha1_base64="HBl2VMqsA9H1oNFDXe3UKmJfeFw=">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvYVZmRoi4LblxWsA+YDiWTZtrQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3knNPmHCmjet+O6WNza3tnfJuZW//4PCoenzS1TJVhHaI5FL1Q6wpZ4J2DDOc9hNFcRxy2gund7nfe6JKMykezSyhQYzHgkWMYGMlfxBjMwmjbDK/HFZrbsNdAK0TryA1KNAeVr8GI0nSmApDONba99zEBBlWhhFO55VBqmmCyRSPqW+pwDHVQbaIPEcXVhmhSCr7hEEL9fdGhmOtZ3FoJ/OIetXLxf88PzXRbZAxkaSGCrL8KEo5MhLl96MRU5QYPrMEE8VsVkQmWGFibEsVW4K3evI66V41vOtG86FZa9WLOspwBudQBw9uoAX30IYOEJDwDK/w5hjnxXl3PpajJafYOYU/cD5/AERUkSw=</latexit>h0<latexit sha1_base64="nbqJXXGN5BTEUvsIFXww4ZYe/LA=">AAAB83icbVDLSgMxFL3xWeur6tJNsAgupMxIUZcFNy4r2Ad0hpLJZNrQTGZIMkIZ+htuXCji1p9x59+YaWehrQcCh3Pu5Z6cIBVcG8f5RmvrG5tb25Wd6u7e/sFh7ei4q5NMUdahiUhUPyCaCS5Zx3AjWD9VjMSBYL1gclf4vSemNE/ko5mmzI/JSPKIU2Ks5HkxMeMgynuzYTis1Z2GMwdeJW5J6lCiPax9eWFCs5hJQwXReuA6qfFzogyngs2qXqZZSuiEjNjAUklipv18nnmGz60S4ihR9kmD5+rvjZzEWk/jwE4WGfWyV4j/eYPMRLd+zmWaGSbp4lCUCWwSXBSAQ64YNWJqCaGK26yYjoki1NiaqrYEd/nLq6R71XCvG82HZr11WdZRgVM4gwtw4QZacA9t6ACFFJ7hFd5Qhl7QO/pYjK6hcucE/gB9/gBBlZHF</latexit>Wd
<latexit sha1_base64="/zBQzt27borSCLHZJETVK/L3JjQ=">AAAB83icbVDLSsNAFL2pr1pfVZduBovgQkoipbosuHFZwT6gCWUynbRDJ5MwD6GE/oYbF4q49Wfc+TdO2iy09cDA4Zx7uWdOmHKmtOt+O6WNza3tnfJuZW//4PCoenzSVYmRhHZIwhPZD7GinAna0Uxz2k8lxXHIaS+c3uV+74lKxRLxqGcpDWI8FixiBGsr+X6M9SSMst58aIbVmlt3F0DrxCtIDQq0h9Uvf5QQE1OhCcdKDTw31UGGpWaE03nFN4qmmEzxmA4sFTimKsgWmefowiojFCXSPqHRQv29keFYqVkc2sk8o1r1cvE/b2B0dBtkTKRGU0GWhyLDkU5QXgAaMUmJ5jNLMJHMZkVkgiUm2tZUsSV4q19eJ93rutesNx4atdZVUUcZzuAcLsGDG2jBPbShAwRSeIZXeHOM8+K8Ox/L0ZJT7JzCHzifP1tZkdY=</latexit>Wu<latexit sha1_base64="QxHJIYnglv0qz/Wz78YlSTh0Gbg=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>g<latexit sha1_base64="dNEdt8VzjdxuWRV2qtIdvhVZt+I=">AAACMnicbZBNS+RAEIY7fq2Oro569NI4LOhhh0REPQp6WMGDgqPCZAiVnsrY2OmE7srCEPKbvPhLBA/rQRGv/gh7xhG/tqDh4X2r6Ko3zpW05Pv/vLHxicmpH9Mztdm5n/ML9cWlU5sVRmBLZCoz5zFYVFJjiyQpPM8NQhorPIsv9wb+2V80Vmb6hPo5dlLoaZlIAeSkqH4QpkAXcVL2qqikiv8OkSAiHmqIFUTlu13xIQtQ5WEV+WtvTriPiqBaj+oNv+kPi3+HYAQNNqqjqH4TdjNRpKhJKLC2Hfg5dUowJIXCqhYWFnMQl9DDtkMNKdpOOTy54r+c0uVJZtzTxIfqx4kSUmv7aew6B3var95A/J/XLijZ6ZRS5wWhFq8fJYXilPFBfrwrDQpSfQcgjHS7cnEBBgS5lGsuhODryd/hdKMZbDU3jzcbu81RHNNsha2yNRawbbbL/rAj1mKCXbFbds8evGvvznv0nl5bx7zRzDL7VN7zC+Blq6w=</latexit>gt ⌘trgL0( )Update <latexit sha1_base64="QxHJIYnglv0qz/Wz78YlSTh0Gbg=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>g·
<latexit sha1_base64="cAiOZblwH8iALsf/vkdYLcRxSgQ=">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> ·[[<latexit sha1_base64="UjUn3B7ufgCOmxVTlETrJ0C/vJY=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>x
<latexit sha1_base64="8/UihlMxlt0wyylqbLxBDRogGzg=">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T(·)
<latexit sha1_base64="F+Pa0tnka1i85dgk3KuWQdNTg88=">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>z<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )<latexit sha1_base64="sdBR52GDjKcMlZo0a/JnSibCcuw=">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )
<latexit sha1_base64="mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>⇠
Drop after trainingZero valuesNon-zero valuesInput & OutputProximal Gradient DescentGatingDown-projectionUp-projection<latexit sha1_base64="SQNLzP+oVKTBulPSpmKN+TfSpd4=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJM21oJjMkd4Qy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1gNOE+xEdKREKRtFKj/2I4jgIs/FsUK64NXcBsk68nFQgR3NQ/uoPY5ZGXCGT1Jie5yboZ1SjYJLPSv3U8ISyCR3xnqWKRtz42SLxjFxYZUjCWNunkCzU3xsZjYyZRoGdnCc0q95c/M/rpRje+JlQSYpcseVHYSoJxmR+PhkKzRnKqSWUaWGzEjammjK0JZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMEzvMKbY5wX5935WI4WnHznFP7A+fwB4AWQ+w==</latexit>h
<latexit sha1_base64="HBl2VMqsA9H1oNFDXe3UKmJfeFw=">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvYVZmRoi4LblxWsA+YDiWTZtrQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3knNPmHCmjet+O6WNza3tnfJuZW//4PCoenzS1TJVhHaI5FL1Q6wpZ4J2DDOc9hNFcRxy2gund7nfe6JKMykezSyhQYzHgkWMYGMlfxBjMwmjbDK/HFZrbsNdAK0TryA1KNAeVr8GI0nSmApDONba99zEBBlWhhFO55VBqmmCyRSPqW+pwDHVQbaIPEcXVhmhSCr7hEEL9fdGhmOtZ3FoJ/OIetXLxf88PzXRbZAxkaSGCrL8KEo5MhLl96MRU5QYPrMEE8VsVkQmWGFibEsVW4K3evI66V41vOtG86FZa9WLOspwBudQBw9uoAX30IYOEJDwDK/w5hjnxXl3PpajJafYOYU/cD5/AERUkSw=</latexit>h0<latexit sha1_base64="nbqJXXGN5BTEUvsIFXww4ZYe/LA=">AAAB83icbVDLSgMxFL3xWeur6tJNsAgupMxIUZcFNy4r2Ad0hpLJZNrQTGZIMkIZ+htuXCji1p9x59+YaWehrQcCh3Pu5Z6cIBVcG8f5RmvrG5tb25Wd6u7e/sFh7ei4q5NMUdahiUhUPyCaCS5Zx3AjWD9VjMSBYL1gclf4vSemNE/ko5mmzI/JSPKIU2Ks5HkxMeMgynuzYTis1Z2GMwdeJW5J6lCiPax9eWFCs5hJQwXReuA6qfFzogyngs2qXqZZSuiEjNjAUklipv18nnmGz60S4ihR9kmD5+rvjZzEWk/jwE4WGfWyV4j/eYPMRLd+zmWaGSbp4lCUCWwSXBSAQ64YNWJqCaGK26yYjoki1NiaqrYEd/nLq6R71XCvG82HZr11WdZRgVM4gwtw4QZacA9t6ACFFJ7hFd5Qhl7QO/pYjK6hcucE/gB9/gBBlZHF</latexit>Wd
<latexit sha1_base64="/zBQzt27borSCLHZJETVK/L3JjQ=">AAAB83icbVDLSsNAFL2pr1pfVZduBovgQkoipbosuHFZwT6gCWUynbRDJ5MwD6GE/oYbF4q49Wfc+TdO2iy09cDA4Zx7uWdOmHKmtOt+O6WNza3tnfJuZW//4PCoenzSVYmRhHZIwhPZD7GinAna0Uxz2k8lxXHIaS+c3uV+74lKxRLxqGcpDWI8FixiBGsr+X6M9SSMst58aIbVmlt3F0DrxCtIDQq0h9Uvf5QQE1OhCcdKDTw31UGGpWaE03nFN4qmmEzxmA4sFTimKsgWmefowiojFCXSPqHRQv29keFYqVkc2sk8o1r1cvE/b2B0dBtkTKRGU0GWhyLDkU5QXgAaMUmJ5jNLMJHMZkVkgiUm2tZUsSV4q19eJ93rutesNx4atdZVUUcZzuAcLsGDG2jBPbShAwRSeIZXeHOM8+K8Ox/L0ZJT7JzCHzifP1tZkdY=</latexit>Wu<latexit sha1_base64="QxHJIYnglv0qz/Wz78YlSTh0Gbg=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>gUpdate <latexit sha1_base64="QxHJIYnglv0qz/Wz78YlSTh0Gbg=">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>g
<latexit sha1_base64="GfJz1eI/r4ne/tVxPM2b6z4LLBs=">AAACRHicbVBJSwMxGM241rpVPXoJFkFFhowWl4NQ8CJ4UbBVmBmHTJppQzMLSUYoYX6cF3+AN3+BFw+KeBXTdg5uDwKP920vL8w4kwqhJ2ticmp6ZrYyV51fWFxarq2stmWaC0JbJOWpuAmxpJwltKWY4vQmExTHIafXYf90WL++o0KyNLlSg4z6Me4mLGIEKyMFNVd7oyWu6Ia+Rvb+scHRLrIbCCEHlQTtFx43SzvYk3kc6P6JU9zq88JrU6GgF2PVCyPdNdpWf3usBk4R1OrIRiPAv8QpSR2UuAhqj14nJXlME0U4ltJ1UKZ8jYVihNOi6uWSZpj0cZe6hiY4ptLXI/8F3DRKB0apMC9RcKR+n9A4lnIQh6Zz6Ff+rg3F/2purqIjX7MkyxVNyPhQlHOoUjhMFHaYoETxgSGYCGa8QtLDAhNlcq+aEJzfX/5L2nu2c2A3Lhv15k4ZRwWsgw2wBRxwCJrgDFyAFiDgHjyDV/BmPVgv1rv1MW6dsMqZNfAD1ucXMyyuvQ==</latexit> KXk=1kg(k)k1<latexit sha1_base64="sXEWZE7Ef6gwsVRn6Y2lkbFH6Dw=">AAACMnicbZBNixNBEIZ7ou7G6K5ZPXppDEIEN8wswd1jQA8KHiKYbCAThppOTdKkp2forlkIw/ymvfhLFvagB2XZqz/CzofofhQ0PLxvFV31xrmSlnz/u1d78PDRzm79cePJ0739Z82D50ObFUbgQGQqM6MYLCqpcUCSFI5yg5DGCk/jxfuVf3qGxspMf6VljpMUZlomUgA5KWp+ClOgeZyUsyoqqeKHIRJExEMNsYKo/GdXfM0CVPm5ivz2Xyf8gIqgehM1W37HXxe/C8EWWmxb/ah5EU4zUaSoSSiwdhz4OU1KMCSFwqoRFhZzEAuY4dihhhTtpFyfXPHXTpnyJDPuaeJr9f+JElJrl2nsOld72tveSrzPGxeUnExKqfOCUIvNR0mhOGV8lR+fSoOC1NIBCCPdrlzMwYAgl3LDhRDcPvkuDI86wbtO90u31Xu7jaPOXrJXrM0Cdsx67CPrswET7Jxdsp/sl/fN++Fdedeb1pq3nXnBbpT3+w/fy6uq</latexit>gt ⌘trgL0( )Figure 1: An illustration of sparse low-rank adaptation (SoRA). At the training stage, the gate gwill control the
sparsity of WdandWu. At the inference stage, zero vectors in WdandWu, indexed by the zero entries of g,
would be eliminated.
lead to from-scratch re-training. These limitations
highlight the importance of upgrading LoRA with
an adaptive-rank-selection plug-in.
Several remedies have been proposed in re-
cent years to enable the flexible tuning of LoRA
rank. For example, rather than setting a fixed rank,
Valipour et al. (Valipour et al., 2022) introduce Dy-
LoRA in which a pre-defined discrete distribution
pB(·)is cast over a range of rank choices. This
approach is related to but different from nested
dropout (Rippel et al., 2014), and can be regarded
as optimizing a mixture model with LoRA modules
of different ranks.
Nevertheless, tuning LoRA rank straightfor-
wardly and deterministically appears to be a more
attractive approach. To devise such an approach,
we first gain a crucial hint from the connection be-
tween a matrix’s rank and its singular value decom-
position (SVD). Let us denote the tunable incre-
mental weight matrix in LoRA by ∆:=WuWd.
We can then formulate its SVD as
∆p×q=Up×pΣp×qV⊤
q×q, (2)
in which UandVare orthogonal respectively, and
Σis a (rectangular) diagonal matrix with diagonal
elements being the singular values of ∆:σ(∆) =
{σ1≥σ2≥ ··· ≥ σmin{p,q}≥0}. For notation
convenience, we reshape the diagonal of Σinto a
column vector
g:= (σ1, σ2,···, σmin{p,q})⊤. (3)Then, letting d= min {p, q}, we can reformulate
the LoRA forward propagation as
z← −∆x=U·,1:d(g⊙V⊤
·,1:dx), (4)
where ⊙denotes element-wise dot product
(Hadamard product). Note that rank(∆) =∥g∥0
which is the ℓ0norm of g. Therefore, tuning
the LoRA rank suffices to control the sparsity of
the vector g. Zhang et al. precede along this
SVD-based track with their methodology named
AdaLoRA (Zhang et al., 2023). In AdaLoRA,
the elements in vector gare calibrated such that
the number of nonzero entries is smaller than a
pre-defined budget b. To be specific, they pre-
serve only the entries with top- bimportance score –
which is their newly proposed metric of "sensitiv-
ity" heuristically constructed from weight-gradient
product. The nonnegativity of gentries is reason-
ably dropped since a negative gican be simply
reduced to the positive case by flipping the sign
of either uiorvi. Besides, they transform the
constrained optimization problem into its uncon-
strained version by replacing the orthogonality con-
ditions U⊤U=IpandV⊤V=Iqwith a regular-
ization term
R(U,V) =∥U⊤U−Ip∥2
F+∥V⊤V−Iq∥2
F.
(5)
In spite of the effectiveness demonstrated
through experiments, there are still two problems
in AdaLoRA that demand rethinking of the method-
ology and wait for further improvements. First, the

--- PAGE 4 ---
sparsity selection criterion in AdaLoRA is based
on their newly proposed importance score relied
on the moving average of weight-gradient prod-
uct. Despite its effectiveness in empirical study,
this criterion is largely heuristic, lacking theoreti-
cal motivation. Second, both the moving average
operation of importance scores and the gradients
of orthogonality regularization (5)add up to addi-
tional computation cost. Compared to AdaLoRA
with the aforementioned limitations, our approach,
SoRA, serves as an amelioration with highly simpli-
fied updating rules and is backed up by the theory
of sparsity regularization and proximal gradient
methods. Detailed methodology of SoRA will be
elaborated in the next section.
3 Our Approach
The key idea of our approach, sparse low-rank adap-
tation (SoRA), is to dynamically adjust the intrinsic
rank in the training process with a sparse gating
unit trained by proximal gradient method. SoRA
adopts the previously introduced framework of low-
rank decomposition because of its widely validated
effectiveness and parameter efficiency.
3.1 Sparse Low-rank Adaptation
Module Structure. At the start of building a
SoRA module, we pre-define a maximum accept-
able rank rmaxaccording to practical or research
concerns. Then, each SoRA module will inherit
two matrices Wd∈Rrmax×qandWu∈Rp×rmax
from LoRA for down projection and up projection.
The maximum rank rmaxis set to be relatively large,
but we will show in the subsequent paragraph how
to tame it efficiently in a sparse sense. In fact, this
is realized by injecting a gating unit g∈Rrmaxbe-
tween the projection matrices, which imitates the
formulation of SVD. The forward propagation of
the SoRA module proceeds as follows:
hdown projection← − − − − − − − − Wdx; (6)
h′gating← − − − g⊙h; (7)
zup projection← − − − − − − − Wuh′; (8)
or, more compactly,
z←Wu(g⊙(Wdx)). (9)
Optimization. We optimize down-projection and
up-projection matrices with stochastic gradientmethods as in LoRA, while each gate gis updated
in a different sparsity-promoting way:
gt+1← T ηt·λ(gt−ηt∇gL0(∆t)), (10)
in which L0(·)is the original loss function of the
language model, ∆denotes the complete tunable
parameter (including the gates), ηt>0stands for
the step-size at the t-th iteration, and λ >0works
as the regularization strength hyperparameter that
promotes sparsity. Besides, Tηt·λ(·)in the above
expression stands for the element-wise broadcast
of the following soft-thresholding function:
Tξ(x) :=

x−ξ, x > ξ
0,−ξ < x ≤ξ
x+ξ, x ≤ −ξ(11)
withξ=ηt·λbeing the threshold. In practice, the
true gradient ∇gL0in(10) is approximated by its
mini-batch stochastic counterpart.
Post-pruning. When training is completed, we
further prune the SoRA weights to drop the zeroed-
out ranks and reduce the module back to the LoRA
form. To be specific, for the k-th SoRA module, let
I(k)=n
i∈[1 :rmax]|g(k)
i= 0o
(12)
be the index of zero entry in the k-th gating vector
g(k). We drop the I(k)-th rows of down-projection
W(k)
dto obtain fW(k)
d, theI(k)-th columns of up-
projection W(k)
uto obtain fW(k)
u, as well as the
I(k)-th entry of gate g(k)to obtain eg(k). In this way,
during inference time the k-th SoRA module will
proceed as a usual LoRA module of rank rmax−
|I(k)|with down-projection matrix fW(k)
dand up-
projection matrix fW(k)
u·diag(eg(k)).
3.2 Interpretation and Comparison
Theoretical interpretation. The update rule (10)
is in fact an application of the proximal gradient
method for ℓ1loss (Chambolle et al., 1998; Beck
and Teboulle, 2009). This follows immediately
once we reformulate (10) equivalently as
gt+1←arg min
gηt·λ∥g∥1
+1
2∥g−(gt−ηt∇L0(gt))∥2
2. (13)
The above equation (13) is exactly the proximal
gradient update of the ℓ1regularized loss function
L(∆) :=L0(∆) +λKX
k=1∥g(k)∥1, (14)

--- PAGE 5 ---
where g(k)denotes the gate of the k-th SoRA mod-
ule. This sparsity-promoting strategy dates back
to LASSO estimator (Tibshirani, 1996) and com-
pressed sensing (Candes et al., 2006), and is also
adopted by many works within the realm of deep
learning (Wen et al., 2016; Scardapane et al., 2017).
Comparision with AdaLoRA. Inspired alike by
SVD decomposition, our approach SoRA differs
from the preceding work AdaLoRA (Zhang et al.,
2023) in the following sense. First, we do not
apply the orthogonality regularization (5)used in
AdaLoRA. The reason is that for rank selection
purposes, sparsifying the gate gwill be sufficient.
Sticking to the original requirements of SVD can
result in additional computation expenditure. Sec-
ond, the moving averaged importance score in
AdaLoRA works as an approximation to the change
in loss when the corresponding entry is zeroed out,
which is regarded as a heuristic measurement of
parameter "sensitivity". However, a model’s tempo-
ral sensitivity to a certain parameter cannot imply
that the parameter should be retained, since there
is no rigorous theory for doing so. By contrast,
our rank selection based on soft-thresholding oper-
ation (10) proceeds in a much cleaner form and is
soundly justified by the theory of proximal gradient
iteration. As is explained earlier this section, the
updating rule of SoRA module exactly follows the
first principle of interpolation-complexity trade-off
by minimizing a regularized loss objective (14).
Beyond the formal simplicity and theoretical
clearness is SoRA’s superior experimental perfor-
mance achieved with fewer parameters in less wall-
clock time, which will be presented in Section 4.
3.3 Scheduling ξto Explore Memorization
and Generalization
We dub the threshold ξas a sparsity indicator. As
the name implies, this parameter could directly de-
termine the sparsity of SoRA in the training process.
It can be set as a constant to heuristically control
the sparsity according to the budget of parame-
ters and expected performance. When dynamically
changing ξin the adaptation process, SoRA serves
as an effective tool to assess the memorization and
generalization under a model Mand a dataset D.
In other words, we can visually observe how many
additional parameters are required to achieve a par-
ticular point of performance given the model M
and data D. We elaborate the fundamental idea
as follows. The process starts by assigning a rel-atively small value to ξ. Consequently, the SoRA
model is initially "dense" and is trained until con-
vergence. Once this stage is achieved, we introduce
a scheduler to incrementally increase the value of
ξ, thereby enhancing the model’s sparsity. During
this transition from a dense to a sparse model, it
becomes possible to evaluate the model’s memo-
rization and generalization abilities by examining
performance on the training and testing data respec-
tively. The procedure is reported in Algorithm 1.
The process can be regarded as exploring
the “compression loss” in the scenario of model
adaptation. Here, “compression loss” refers to
the reduction in model performance due to the
increased sparsity, providing a measure of how
well the model can retain its predictive power
under constraints. Investigating this “compres-
sion loss” is meaningful to understanding the
behavior of model adaptation and can facilitate
developing efficient, compact models that maintain
high-performance levels.
Algorithm 1: Scheduling Algorithm of ξ
Input : M, ξ0, ξmax, δξ,D
Output : M′={M 0,M1, ...}
ξ←ξ0;
M′← ∅;
M=TrainUntilConvergence (M,D, ξ);
M′.add(M);
ξ←ξ+ξλ;
while ξ≤ξmaxdo
forepoch←1to5do
M=Update (M,D, ξ);
end
M′.add(M);
ξ←ξ+δξ;
end
4 Experiments
Extensive experiments are carried out to assess
the effectiveness of our approach comprehensively.
Generally speaking, we explore two aspects in this
section: (1) the performance and corresponding
analysis as a normal parameter-efficient method;
and (2) the investigation of memorization and gen-
eralization in virtue of the sparsity nature of SoRA.
4.1 Experimental Settings.
Baselines. Our baselines comprise full-parameter
fine-tuning and other well-recognized parameter-
efficient methods, including Adapter (Houlsby

--- PAGE 6 ---
Method #Params CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg.
Fine-Tune 184M 69.21 95.64 89.22 92.05/89.31 91.59 89.98/89.95 93.78 82.49 87.82
Adapter 1.41M 69.00 95.16 89.90 91.45/88.88 92.21 90.11/90.11 93.79 82.44 87.85
Bitfit 0.1M 68.70 94.38 87.16 87.86/84.20 89.71 87.45/87.45 91.90 76.12 85.18
LoRA (r=8) 1.33M 69.73 95.57 89.71 91.95/89.26 91.86 90.47/90.46 93.76 85.32 88.38
AdaLoRA 1.27M 70.86 95.95 90.22 92.13/88.41 91.39 90.27/90.30 94.28 87.36 88.83
SoRA 0.91M 71.48 95.64 91.98 92.39/89.87 92.22 90.35/90.38 94.28 87.77 89.36
Table 1: Test results of SoRA and other baselines on the GLUE benchmark. We denote the best result in bold and
underline the second best result. The standard deviations of results from different methods are similar and we show
them in Table 8 in Appendix A.4.
et al., 2019), BitFit (Zaken et al., 2021), LoRA (Hu
et al., 2021) and AdaLoRA (Zhang et al., 2023).
We omit the variants of the Adapter since we find
that the performance between them is very close.
We also do not include Prompt Tuning since we
find that it takes considerably longer time for con-
vergence and cannot yield non-trivial performance
on our backbone models.
Datasets For evaluation, we adaopt the
GLUE benchmark (Wang et al.), including
CoLA (Warstadt et al., 2019), SST-2 (Socher
et al., 2013), MRPC (Dolan and Brockett,
2005), QQP (Wang et al.), STS-B (Wang et al.),
MNLI (Williams et al., 2017), QNLI (Rajpurkar
et al., 2016) and RTE (Dagan et al., 2005; Haim
et al., 2006; Giampiccolo et al., 2007; Bentivogli
et al., 2009). We mainly use DeBERTaV3-base (He
et al., 2021) as the backbone model. Additionally,
we also use RoBERTa-large (Liu et al., 2019) for
analysis. Other experimental details are described
in Appendix A.
4.2 Results
We first conduct an evaluation on GLUE bench-
mark, a widely recognized benchmark for natural
language understanding. The experimental perfor-
mance of SoRA, as well as other baseline method-
ologies, is recorded in Table 1. We reproduce these
methods in our infrastructure and present the av-
erage results drawn from 5 random seeds. Our
findings indicate that both AdaLoRA and SoRA
consistently outperform the initial LoRA baseline.
This underlines the validity of adaptive rank as a po-
tent solution for enhanced model adaptation. Most
notably, SoRA outshines all other baselines, partic-
ularly LoRA and AdaLoRA, despite utilizing fewer
parameters. This lends credence to the argument
that our proximal gradient method may constitute a
more efficacious and essential approach to achiev-
ing adaptive rank. For instance, on the MRPC,SoRA achieved an accuracy of 91.98%, surpassing
AdaLoRA by 1.76%. On average, SoRA surpassed
LoRA and AdaLoRA on the GLUE benchmark by
0.98% and 0.52%, respectively, using 31.5% and
28.3% fewer parameters. To take a closer look
at the effectiveness of adaptive rank, we conduct
an experiment to compare LoRA and SoRA with
different ranks in Table 2. The results affirm that
SoRA’s superiority is consistent across different
budgets of parameters, that is, SoRA could out-
perform the LoRA baseline in all settings while
utilizing over 30% fewer parameters.
4.3 Sparsifying Scheduler
We apply the sparsifying scheduler introduced in
Section 3.3 by enlarging the sparse indicator ξ
(starting from 1e-4) of SoRA progressively in the
adaptation process. As illustrated in Figure 2, we
plot the memorization and generalization curve of
RoBERTa-large (Liu et al., 2019) on MRPC, RTE,
STS-B, CoLA, QNLI, and SST-2, where the mem-
orization is gauged by the performance on the train-
ing set and the generalization is measured by the
performance on the validation set. Intriguingly,
we observe a robust “compression performance"
across almost all the datasets. Among these, SST-2
emerges as the most "compressible" task, where the
model sustains over 99% performance even when
restricted to 47,104 non-zero parameters. Remark-
ably, a mere 4,096 parameters can still conserve
above 90% memorization and generalization capa-
bilities. As the sparsifying process proceeds, the
model encounters an “inflection point” on differ-
ent data, after which the performance significantly
plummets. This consistent phenomenon suggests
that there exist some critical parameters that un-
derpin the performance and are worth further in-
vestigation. Insight gleaned from the graph also
indicates varying degrees of adaptation difficulty
for the model across different datasets. For exam-
ple, certain datasets, like CoLA, prompt an earlier

--- PAGE 7 ---
Method #Params CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg.
LoRA r=1 0.17M 68.60 94.95 88.24 91.20/88.37 91.41 90.09/90.28 93.35 81.29 87.23
SoRA r=1 0.12M -29.41% 70.24 +1.64 95.14 +0.19 89.22 +0.98 91.52/88.73 +0.34 91.41 +0.00 90.08/90.41 +0.06 93.43 +0.08 83.02 +1.73 87.85 +0.62
LoRA r=2 0.33M 68.93 95.04 88.43 91.59/88.87 91.53 90.35/90.30 93.63 84.17 87.79
SoRA r=2 0.25M -24.24% 70.22 +1.29 95.64 +0.60 89.71 +1.28 91.88/89.12 +0.27 91.63 +0.10 90.37/90.51 +0.12 93.78 +0.15 85.18 +1.01 88.39 +0.60
LoRA r=4 0.66M 69.27 95.55 89.22 91.40/88.41 91.69 90.36/90.49 93.83 82.01 87.74
SoRA r=4 0.47M -28.79% 71.05 +1.78 95.57 +0.02 90.20 +0.98 92.06/89.44 +0.85 91.76 +0.07 90.38/90.43 -0.02 93.92 +0.09 86.04 +4.03 88.71 +0.97
LoRA r=8 1.33M 69.73 95.57 89.71 91.95/89.26 91.86 90.47/90.46 93.76 85.32 88.38
SoRA r=8 0.91M -31.58% 71.48 +1.75 95.64 +0.07 91.98 +2.27 92.39/89.87 +0.53 92.22 +0.36 90.35/90.38 -0.10 94.28 +0.52 87.77 +2.45 89.36 +0.98
LoRA r=16 2.65M 69.87 95.53 89.91 92.22/89.63 91.79 90.55/90.31 93.46 87.05 88.62
SoRA r=16 1.78M -32.83% 71.93 +2.06 95.61 +0.08 92.00 +2.09 92.37/89.84 +0.18 92.05 +0.26 90.34/90.47 -0.03 94.11 +0.65 87.41 +0.36 89.33 +0.71
Table 2: Test results and number of parameters of SoRA initialized with different rmaxon the GLUE benchmark,
compared with LoRA of the same rank. The standard deviations of results from different methods are similar and
we show them in Table 9 in Appendix A.4.
Figure 2: The memorization and generalization curve on six datasets. The "Param" axis indicates the number of
non-zero parameters. The sparsity indicator ξincreases every 5 epochs.
and more pronounced decline in performance com-
pared to others. Another finding is that the trend
of memorization and generalization is consistent
in the sparsifying procedure, which is aligned with
intuition. Our observations also indicate a tendency
for the parameters of intermediate and deep layers
to maintain their density, while those of the shallow
layers show a higher propensity towards sparsity.
4.4 Rank Analysis
An intuitive statement is that a single model suf-
fers from varying extents of difficulty when being
adapted to different downstream datasets. Concur-
rently, it is evident that not all parameters within the
model carry equal importance—some are more crit-
ical to performance than others. In this section, we
visualize the final ranks after the training processconverges with SoRA on four datasets in Figure
3. Quite obviously, the trained parameter matrices
on QQP are exceedingly dense and others do not
exhibit such density, which echos the existence of
different levels of difficulties. This phenomenon
also suggests that leveraging the performance and
the parameter budget does not have an invariable
constant law, but needs specific considerations in
different situations.
4.5 Applying SoRA to Different Weights
In our experiments in Table 1, we utilize LoRA,
AdaLoRA, and SoRA on all weight matrices to
enhance performance. It should be noted that
the performance may fluctuate when parameter-
efficient fine-tuning is applied to various positions
within the model, as evidenced by previous

--- PAGE 8 ---
Figure 3: The final ranks after training with SoRA on four datasets (l.e., QQP, MNLI, QNLI, and MRPC). The
X-axis is the index of DeBERTaV3-base layers, and the Y-axis indicates different layers SoRA applies to.
research (Zaken et al., 2021; Hu et al., 2022;
Zhang et al., 2023). We carry out such ablation
experiments with SoRA on three datasets to
investigate the impact. Although SoRA is not a
budget-oriented method, we adjust λto approxi-
mately equate the retained non-zero parameters.
As reported in Table 3, in most cases, the applica-
tion of SoRA to all weight matrices resulted in a
considerable improvement in performance com-
pared to the application of merely one or several
types of weights, which suggest that uniformly
applying SoRA to all weight matrices can serve
as a beneficial strategy. And merely applying
SoRA to WQ,K will experience considerable
performance drop, which is aligned with LoRA.
#Params CoLA MRPC STS-B
WQ,K 0.80M 65.56 ±2.24 86.43 ±0.83 72.30 ±2.61
WQ,K,V 0.69M 69.07 ±2.17 88.24 ±1.84 90.82 ±0.70
WQ,K,V,A.O 0.87M 71.99 ±1.30 90.20 ±1.83 91.71 ±0.34
All 0.77M 71.48 ±1.17 91.98 ±1.16 92.22 ±0.24
Table 3: Test results that applying SoRA to different
weights. Q, K, V , and A.O represent query, key, value
and attention output layers respectively. #Params
means the number of parameters that would remain
after training.
4.6 Efficiency Analysis
We elaborate that SoRA is a theoretically clear and
computation-efficient method in Section 3.2. To
evaluate this, we measure the efficiency of SoRA
and AdaLora in this section. We compute the clock
time of average epoch of AdaLoRA and SoRA on
six datasets with identical compute infrastructureand batch size. As shown in Table 4, SoRA takes
about 30% less training time than AdaLoRA. In
certain instances, such as the CoLA, QNLI, and
RTE datasets, SoRA exhibits a significant edge in
efficiency over its counterpart. Conversely, while
SoRA consistently outpaces AdaLoRA on other
datasets, the margin is not as wide. This discrep-
ancy could be attributable to the different rank dis-
tributions of AdaLoRA and SoRA under varying
tasks. Such distributions exert influence on the
calculation of regularization in AdaLoRA.
Datasets AdaLoRA (s) SoRA (s)
CoLA 160.2 57.2 -64.29%
SST-2 491.0 433.0 -11.81%
MRPC 27.3 24.8 -9.16%
STS-B 48.2 38.4 -20.33%
QNLI 1001.0 676.3 -32.44%
RTE 79.8 45.1 -43.48%
Avg. 301.3 212.5 -29.47%
Table 4: The average training time per epoch on six
datasets. For each task, the experiments with AdaLoRA
and SoRA have the same batch size 32.
5 Conclusion
Our work presents Sparse Low-Rank Adapta-
tion (SoRA), an innovative method for parameter-
efficient fine-tuning large pre-trained language
models. Upon the hypothesis that the adaptation
process could be intrinsically sparse, we offer a
dynamic alternative rank by introducing an opti-
mizable gate with a proximal gradient method to

--- PAGE 9 ---
regulate sparsity, thereby expanding the optimiza-
tion space while enhancing parameter efficiency.
The method is simple and theoretically supported
with promising performance across various tasks.
Utilizing SoRA as a tool, we propose a sparsify-
ing scheduler to analyze the correlation between
parameters and memorization and generalization.
Limitations
Despite the encouraging results demonstrated by
SoRA, there are certain limitations in our current
study that are worth acknowledging. This paper
only evaluates the effectiveness of SoRA on tra-
ditional natural language processing tasks. How-
ever, recent studies demonstrate that parameter-
efficient methods could be applied to cross-modal
or instruction-tuning scenarios. In those cases, how
the sparsity of SoRA is displayed is still unknown
and worth investigating. Our sparsifying scheduler
could provide insights on the adaptation process of
language models, but it is still challenging to rigor-
ously explain the procedure and more efficiently to
assess the difficulty of an adaptation process.
Acknowledgements
This work is supported by the National Key R&D
Program of China (No. 2022ZD0119101), Na-
tional Natural Science Foundation of China (No.
62236004), the Young Elite Scientists Sponsorship
Program by CAST, and Institute Guo Qiang at Ts-
inghua University.
References
Amir Beck and Marc Teboulle. 2009. A fast itera-
tive shrinkage-thresholding algorithm for linear in-
verse problems. SIAM journal on imaging sciences ,
2(1):183–202.
Luisa Bentivogli, Peter Clark, Ido Dagan, and Danilo
Giampiccolo. 2009. The fifth pascal recognizing
textual entailment challenge. In Proceedings of Text
Analysis Conference .
Rishi Bommasani, Drew A Hudson, Ehsan Adeli,
Russ Altman, Simran Arora, Sydney von Arx,
Michael S Bernstein, Jeannette Bohg, Antoine Bosse-
lut, Emma Brunskill, et al. 2021. On the opportuni-
ties and risks of foundation models. arXiv preprint
arXiv:2108.07258 .
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-V oss,Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Language models are few-shot learners. In Ad-
vances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Process-
ing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual .
Emmanuel J Candes, Justin K Romberg, and Terence
Tao. 2006. Stable signal recovery from incomplete
and inaccurate measurements. Communications on
Pure and Applied Mathematics: A Journal Issued
by the Courant Institute of Mathematical Sciences ,
59(8):1207–1223.
Antonin Chambolle, Ronald A De V ore, Nam-Yong Lee,
and Bradley J Lucier. 1998. Nonlinear wavelet im-
age processing: variational problems, compression,
and noise removal through wavelet shrinkage. IEEE
Transactions on Image Processing , 7(3):319–335.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005. The pascal recognising textual entailment chal-
lenge. In Machine Learning Challenges Workshop ,
pages 177–190. Springer.
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and
Luke Zettlemoyer. 2023. Qlora: Efficient finetuning
of quantized llms. arXiv preprint arXiv:2305.14314 .
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers) , pages
4171–4186, Minneapolis, Minnesota. Association for
Computational Linguistics.
Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei,
Zonghan Yang, Yusheng Su, Shengding Hu, Yulin
Chen, Chi-Min Chan, Weize Chen, et al. 2023.
Parameter-efficient fine-tuning of large-scale pre-
trained language models. Nature Machine Intelli-
gence , 5(3):220–235.
Bill Dolan and Chris Brockett. 2005. Automati-
cally constructing a corpus of sentential paraphrases.
InThird International Workshop on Paraphrasing
(IWP2005) .
Dan Friedman, Ben Dodge, and Danqi Chen. 2021.
Single-dataset experts for multi-dataset question an-
swering. ArXiv preprint , abs/2109.13880.
Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie
Geng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui
He, Xiangyu Yue, et al. 2023. Llama-adapter v2:
Parameter-efficient visual instruction model. arXiv
preprint arXiv:2304.15010 .

--- PAGE 10 ---
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and
Bill Dolan. 2007. The third PASCAL recognizing
textual entailment challenge. In Proceedings of the
ACL-PASCAL Workshop on Textual Entailment and
Paraphrasing , pages 1–9, Prague. Association for
Computational Linguistics.
Demi Guo, Alexander Rush, and Yoon Kim. 2021.
Parameter-efficient transfer learning with diff prun-
ing. In Proceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the
11th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers) , pages
4884–4896, Online. Association for Computational
Linguistics.
R Bar Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo
Giampiccolo, Bernardo Magnini, and Idan Szpektor.
2006. The second pascal recognising textual entail-
ment challenge. In Proceedings of the Second PAS-
CAL Challenges Workshop on Recognising Textual
Entailment , volume 7.
Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao
Liu, Yuqi Huo, Jiezhong Qiu, Liang Zhang, Wentao
Han, Minlie Huang, Qin Jin, Yanyan Lan, Yang Liu,
Zhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song,
Jie Tang, Ji-Rong Wen, Jinhui Yuan, Wayne Xin
Zhao, and Jun Zhu. 2021. Pre-trained models: Past,
present and future. AI Open .
Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-
Kirkpatrick, and Graham Neubig. 2022. Towards a
unified view of parameter-efficient transfer learning.
InInternational Conference on Learning Representa-
tions .
Pengcheng He, Jianfeng Gao, and Weizhu Chen. 2021.
Debertav3: Improving deberta using electra-style pre-
training with gradient-disentangled embedding shar-
ing.arXiv preprint arXiv:2111.09543 .
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and
Weizhu Chen. 2020. Deberta: Decoding-enhanced
bert with disentangled attention. arXiv preprint
arXiv:2006.03654 .
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,
Bruna Morrone, Quentin de Laroussilhe, Andrea Ges-
mundo, Mona Attariyan, and Sylvain Gelly. 2019.
Parameter-efficient transfer learning for NLP. In Pro-
ceedings of the 36th International Conference on Ma-
chine Learning, ICML 2019, 9-15 June 2019, Long
Beach, California, USA , volume 97 of Proceedings
of Machine Learning Research , pages 2790–2799.
PMLR.
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
and Weizhu Chen. 2021. Lora: Low-rank adap-
tation of large language models. ArXiv preprint ,
abs/2106.09685.
Shengding Hu, Ning Ding, Weilin Zhao, Xingtai Lv,
Zhen Zhang, Zhiyuan Liu, and Maosong Sun. 2023.Opendelta: A plug-and-play library for parameter-
efficient adaptation of pre-trained models. arXiv
preprint arXiv:2307.03084 .
Shengding Hu, Zhen Zhang, Ning Ding, Yadao Wang,
Yasheng Wang, Zhiyuan Liu, and Maosong Sun.
2022. Sparse structure search for parameter-efficient
tuning. arXiv preprint arXiv:2206.07382 .
Rabeeh Karimi Mahabadi, James Henderson, and Se-
bastian Ruder. 2021. Compacter: Efficient low-rank
hypercomplex adapter layers. Advances in Neural
Information Processing Systems , 34:1022–1035.
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.
The power of scale for parameter-efficient prompt
tuning. ArXiv preprint , abs/2104.08691.
Quentin Lhoest, Albert Villanova del Moral, Yacine
Jernite, Abhishek Thakur, Patrick von Platen, Suraj
Patil, Julien Chaumond, Mariama Drame, Julien Plu,
Lewis Tunstall, Joe Davison, Mario Šaško, Gun-
jan Chhablani, Bhavitvya Malik, Simon Brandeis,
Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas
Patry, Angelina McMillan-Major, Philipp Schmid,
Sylvain Gugger, Clément Delangue, Théo Matus-
sière, Lysandre Debut, Stas Bekman, Pierric Cis-
tac, Thibault Goehringer, Victor Mustar, François
Lagunas, Alexander Rush, and Thomas Wolf. 2021.
Datasets: A community library for natural language
processing. In Proceedings of the 2021 Conference
on Empirical Methods in Natural Language Process-
ing: System Demonstrations , pages 175–184, Online
and Punta Cana, Dominican Republic. Association
for Computational Linguistics.
Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning:
Optimizing continuous prompts for generation. In
Proceedings of the 59th Annual Meeting of the Asso-
ciation for Computational Linguistics and the 11th
International Joint Conference on Natural Language
Processing (Volume 1: Long Papers) , pages 4582–
4597, Online. Association for Computational Lin-
guistics.
Peiyu Liu, Ze-Feng Gao, Wayne Xin Zhao, Zhong-Yi
Lu, and Ji-Rong Wen. 2021. Enabling lightweight
fine-tuning for pre-trained language model compres-
sion based on matrix product operators. arXiv
preprint arXiv:2106.02205 .
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. ArXiv preprint , abs/1907.11692.
Adam Paszke, Sam Gross, Francisco Massa, Adam
Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca
Antiga, et al. 2019. Pytorch: An imperative style,
high-performance deep learning library. Advances in
neural information processing systems , 32.

--- PAGE 11 ---
Yujia Qin, Xiaozhi Wang, Yusheng Su, Yankai Lin,
Ning Ding, Zhiyuan Liu, Juan-Zi Li, Lei Hou, Peng
Li, Maosong Sun, and Jie Zhou. 2021. Exploring
low-dimensional intrinsic task subspace via prompt
tuning. ArXiv , abs/2110.07867.
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
Percy Liang. 2016. Squad: 100,000+ questions
for machine comprehension of text. arXiv preprint
arXiv:1606.05250 .
Oren Rippel, Michael Gelbart, and Ryan Adams. 2014.
Learning ordered representations with nested dropout.
InInternational Conference on Machine Learning ,
pages 1746–1754. PMLR.
Simone Scardapane, Danilo Comminiello, Amir Hus-
sain, and Aurelio Uncini. 2017. Group sparse regular-
ization for deep neural networks. Neurocomputing ,
241:81–89.
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng, and
Christopher Potts. 2013. Recursive deep models for
semantic compositionality over a sentiment treebank.
InProceedings of the 2013 conference on empiri-
cal methods in natural language processing , pages
1631–1642.
Yusheng Su, Chi-Min Chan, Jiali Cheng, Yujia Qin,
Yankai Lin, Shengding Hu, Zonghan Yang, Ning
Ding, Zhiyuan Liu, and Maosong Sun. 2023. Ar-
bitrary few parameters are good enough for adapt-
ing large-scale pre-trained language models. arXiv
preprint arXiv:2306.02320 .
Yi-Lin Sung, Jaemin Cho, and Mohit Bansal. 2022.
Lst: Ladder side-tuning for parameter and mem-
ory efficient transfer learning. arXiv preprint
arXiv:2206.06522 .
Robert Tibshirani. 1996. Regression shrinkage and se-
lection via the lasso. Journal of the Royal Statistical
Society: Series B (Methodological) , 58(1):267–288.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, et al. 2023. Llama: Open and effi-
cient foundation language models. arXiv preprint
arXiv:2302.13971 .
Mojtaba Valipour, Mehdi Rezagholizadeh, Ivan
Kobyzev, and Ali Ghodsi. 2022. Dylora: Parameter
efficient tuning of pre-trained models using dynamic
search-free low-rank adaptation. arXiv preprint
arXiv:2210.07558 .
Alex Wang, Amanpreet Singh, Julian Michael, Felix
Hill, Omer Levy, and Samuel R Bowman. Glue:
A multi-task benchmark and analysis platform for
natural language understanding.
Alex Warstadt, Amanpreet Singh, and Samuel R Bow-
man. 2019. Neural network acceptability judgments.
Transactions of the Association for Computational
Linguistics , 7:625–641.Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen,
and Hai Li. 2016. Learning structured sparsity in
deep neural networks. Advances in neural informa-
tion processing systems , 29.
Adina Williams, Nikita Nangia, and Samuel R Bow-
man. 2017. A broad-coverage challenge corpus for
sentence understanding through inference. arXiv
preprint arXiv:1704.05426 .
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
et al. 2020. Transformers: State-of-the-art natural
language processing. In Proceedings of the 2020 con-
ference on empirical methods in natural language
processing: system demonstrations , pages 38–45.
Elad Ben Zaken, Shauli Ravfogel, and Yoav Gold-
berg. 2021. Bitfit: Simple parameter-efficient
fine-tuning for transformer-based masked language-
models. ArXiv preprint , abs/2106.10199.
Qingru Zhang, Minshuo Chen, Alexander Bukharin,
Pengcheng He, Yu Cheng, Weizhu Chen, and
Tuo Zhao. 2023. Adaptive budget allocation for
parameter-efficient fine-tuning. arXiv preprint
arXiv:2303.10512 .
Mengjie Zhao, Tao Lin, Fei Mi, Martin Jaggi, and Hin-
rich Schütze. 2020. Masking as an efficient alterna-
tive to finetuning for pretrained language models. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP) ,
pages 2226–2241, Online. Association for Computa-
tional Linguistics.

--- PAGE 12 ---
A Experimental Details
A.1 Datasets
The GLUE benchmark, consisting of
CoLA (Warstadt et al., 2019), SST-2 (Socher
et al., 2013), MRPC (Dolan and Brockett,
2005), QQP (Wang et al.), STS-B (Wang et al.),
MNLI (Williams et al., 2017), QNLI (Rajpurkar
et al., 2016) and RTE (Dagan et al., 2005; Haim
et al., 2006; Giampiccolo et al., 2007; Bentivogli
et al., 2009), is used for natural language under-
standing. The details and the evaluation metric
are reported in Table 5. We source each dataset
from Huggingface Datasets (Lhoest et al., 2021)
and utilize the full dataset for our experiments.
For almost all experiments, we run 5 times using
different random seeds and report the average
results in order to ensure statistical significance.
Dataset #Train #Valid #Test Metric
CoLA 8.5k 1,043 1,063 Mcc
SST-2 67k 872 1.8k Acc
MRPC 3.7k 408 1.7k Acc
QQP 364k 40.4k 391k Acc/F1
STS-B 5.7k 1.5k 1.4k Corr
MNLI 393k 9.8k/9.8k 9.8k/9.8k Acc(m/mm)
QNLI 105k 5.5k 5.5k Acc
RTE 2.5k 277 3k Acc
Table 5: The size and evaluation metric of the datasets
in GLUE benchmark. "Mcc", "Acc", "F1" and "Corr"
represent matthews correlation coefficient, accuracy, the
F1 score and pearson correlation coefficient respectively.
And "Acc(m/mm)" represents the results corresponding
to matched and mismatched datasets of MNLI while the
metric is accuracy.
A.2 Implementation Details
Regarding hyper-parameters, we set the learning
rate to 8e-4. Based on the size and training conver-
gence speed of the datasets, we set the number of
epochs for CoLA, MRPC, and STS-B to 20, and
the number of epochs for the remaining tasks to 10.
As for RTE, we reference the settings of Friedman
et al. 2021, which entail a learning rate of 1.2e-3
and an epoch count of 50. We set λto 0.1 in all
our experiments, and select ξwith a grid search
in {1e-5, 5e-5, 1e-4}. When dealing with MRPC,
RTE, and STS-B datasets, a common trick in cer-
tain studies is that using the best model checkpoint
on the MNLI dataset could boost the performance.
In our experiments, we do not use this strategy and
instead opt for standard initializations across all
models.The Huggingface Transformers (Wolf et al.,
2020) and PyTorch (Paszke et al., 2019) are utilized
for all the experiments. We use NVIDIA GeForce
RTX 3090 (maximum GPU memory=24268MB)
and the application of SoRA with a batch size of 8
occupies 6110MB GPU memory on average.
A.3 Optimization of Hyperparameters
In this section, we delve into the optimization of
hyperparameters. The results of different rmaxare
proved in Table 2 and we supplement the results of
two other important hyperparameters, ξandηin
the Table 6 and Table 7. The performance of SoRA
is highly stable with respect to different choices of
ξandη. And for each fixed ξandη, the variance of
performance is rather low. In general, we suggest
setting ξto 1e-4 level and ηaround 1e-1 ∼1e-3.
ξ COLA STS-B
1e-3 63.25 ±0.71 90.85 ±0.53
8e-4 64.98 ±1.25 91.12 ±0.38
5e-4 66.94 ±0.98 91.61 ±0.24
3e-4 68.61 ±1.23 92.22 ±0.24
1e-4 70.18 ±1.05 92.01 ±0.14
8e-5 68.78 ±1.43 92.00 ±0.15
5e-5 71.48 ±1.17 92.02 ±0.18
3e-5 69.68 ±1.94 92.18 ±0.15
1e-5 69.65 ±1.93 92.08 ±0.15
Table 6: Test results of the optimization experiments on
different ξ.
ηt COLA STS-B
10 69.06 ±2.18 91.75 ±0.41
1 70.54 ±1.15 92.02 ±0.20
0.1 71.48 ±1.17 92.22 ±0.24
0.01 68.78 ±2.29 92.06 ±0.17
0.001 69.86 ±1.54 91.83 ±0.22
0.0001 69.70 ±1.70 92.13 ±0.40
Table 7: Test results of the optimization experiments on
different ηt.
A.4 Results with Standard Deviations
The test results in Table 1 are shown in Table 8,
and results in Table 2 are shown in Table 9.

--- PAGE 13 ---
Method #Params CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg.
Fine-Tune 184M69.21
(2.24)95.64
(0.52)89.22
(0.69)92.05/89.31
(0.09)/(0.07)91.59
(0.47)89.98/89.95
(0.06)/(0.33)93.78
(0.02)82.49
(1.48)87.82
Adapter 1.41M69.00
(0.91)95.16
(0.46)89.90
(2.10)91.45/88.88
(0.18)/(0.40)92.21
(0.33)90.11/90.11
(0.57)/(0.57)93.79
(0.07)82.44
(1.74)87.85
Bitfit 0.1M68.70
(1.85)94.38
(0.28)87.16
(0.58)87.86/84.20
(0.52)/(0.74)89.71
(0.58)87.45/87.45
(0.76)/(0.76)91.90
(0.14)76.12
(1.54)85.18
LoRA (r=8) 1.33M69.73
(1.42)95.57
(0.21)89.71
(1.32)91.95/89.26
(0.12)/(0.18)91.86
(0.29)90.47/90.46
(0.23)/(0.12)93.76
(0.36)85.32
(0.86)88.38
AdaLoRA 1.27M70.86
(1.43)95.95
(0.37)90.22
(0.40)92.13/88.41
(0.06)/(0.05)91.39
(0.25)90.27/90.30
(0.11)/(0.18)94.28
(0.11)87.36
(0.30)88.83
SoRA 0.91M71.48
(1.17)95.64
(0.23)91.98
(1.16)92.39/89.87
(0.17)/(0.27)92.22
(0.24)90.35/90.38
(0.09)/(0.12)94.28
(0.06)87.77
(1.56)89.36
Table 8: Test results of SoRA and other baselines on the GLUE benchmark. We denote the best result in bold and
underline the second best result. The standard deviation is provided in parentheses.
Method #Params CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg.
LoRA r=1 0.17M68.60
(1.58)94.95
(0.20)88.24
(1.42)91.20/88.37
(0.20/0.33)91.41
(0.29)90.09/90.28
(0.16/0.14)93.35
(0.34)81.29
(2.83)87.23
SoRA r=1 0.12M70.24
(1.10)95.14
(0.25)89.22
(2.12)91.52/88.73
(0.14/0.22)91.41
(0.29)90.08/90.41
(0.18/0.12)93.43
(0.33)83.02
(2.47)87.85
LoRA r=2 0.33M68.93
(1.50)95.04
(0.37)88.43
(1.06)91.59/88.87
(0.06/0.12)91.53
(0.32)90.35/90.30
(0.13/0.17)93.63
(0.37)84.17
(1.20)87.79
SoRA r=2 0.25M70.22
(1.03)95.64
(0.09)89.71
(0.81)91.88/89.12
(0.13/0.17)91.63
(0.30)90.37/90.51
(0.06/0.08)93.78
(0.23)85.18
(0.73)88.39
LoRA r=4 0.66M69.27
(2.22)95.55
(0.56)89.22
(1.64)91.40/88.41
(0.17/0.27)91.69
(0.24)90.36/90.49
(0.12/0.32)93.83
(0.35)82.01
(1.76)87.74
SoRA r=4 0.47M71.05
(0.74)95.57
(0.05)90.20
(1.60)92.06/89.44
(0.17/0.14)91.76
(0.17)90.38/90.43
(0.04/0.25)93.92
(0.09)86.04
(1.96)88.71
LoRA r=8 1.33M69.73
(1.42)95.57
(0.21)89.71
(1.32)91.95/89.26
(0.12/0.18)91.86
(0.29)90.47/90.46
(0.23/0.12)93.76
(0.36)85.32
(0.86)88.38
SoRA r=8 0.91M71.48
(1.17)95.64
(0.23)91.98
(1.16)92.39/89.87
(0.17/0.27)92.22
(0.24)90.35/90.38
(0.09/0.12)94.28
(0.06)87.77
(1.56)89.36
LoRA r=16 2.65M69.87
(0.86)95.53
(0.15)89.91
(1.69)92.22/89.63
(0.05/0.04)91.79
(0.16)90.55/90.31
(0.10/0.03)93.46
(0.12)87.05
(3.11)88.62
SoRA r=16 1.78M71.93
(0.97)95.61
(0.11)92.00
(0.23)92.37/89.84
(0.15/0.19)92.05
(0.16)90.34/90.47
(0.13/0.04)94.11
(0.07)87.41
(1.08)89.33
Table 9: Test results and number of parameters of SoRA initialized with different rmaxon the GLUE benchmark,
compared with LoRA of the same rank. The standard deviation is provided in parentheses.

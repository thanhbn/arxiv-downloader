# 2309.06526.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2309.06526.pdf
# Kích thước tệp: 327471 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
KHÁM PHÁ LỢI ÍCH CỦA TIỀN HUẤN LUYỆN VỚI QUYỀN RIÊNG TƯ SAI PHÂN VÀ
TINH CHỈNH HIỆU QUẢ THAM SỐ CHO TABLE TRANSFORMER
Xilong Wang⋆, Chia-Mu Yu†, và Pin-Yu Chen‡
⋆Trường Đại học Khoa học và Công nghệ Trung Quốc, Hợp Phì, Trung Quốc
†Trường Đại học Quốc gia Yang Ming Chiao Tung, Tân Trúc, Đài Loan
‡IBM Research, New York, Mỹ
TÓM TẮT
Đối với học máy với dữ liệu dạng bảng, Table Transformer
(TabTransformer) là một mô hình mạng nơ-ron tiên tiến, 
trong khi Quyền riêng tư Sai phân (DP) là một thành phần 
thiết yếu để đảm bảo quyền riêng tư dữ liệu. Trong bài báo này, 
chúng tôi khám phá lợi ích của việc kết hợp hai khía cạnh này 
trong kịch bản học chuyển giao – tiền huấn luyện với quyền riêng tư 
sai phân và tinh chỉnh TabTransformer với nhiều phương pháp 
tinh chỉnh hiệu quả tham số (PEFT), bao gồm Adapter,
LoRA, và Prompt Tuning. Các thí nghiệm mở rộng của chúng tôi 
trên tập dữ liệu ACSIncome cho thấy những phương pháp PEFT này 
vượt trội so với các phương pháp truyền thống về độ chính xác 
của tác vụ hạ lưu và số lượng tham số có thể huấn luyện, do đó 
đạt được sự cân bằng cải thiện giữa hiệu quả tham số, quyền riêng tư, 
và độ chính xác. Mã nguồn của chúng tôi có sẵn tại
https://github.com/IBM/DP-TabTransformer .
Thuật ngữ chỉ mục —Table Transformer, Quyền riêng tư Sai phân,
Học chuyển giao

1. GIỚI THIỆU
Table transformer (TabTransformer) [1] là một mô hình sâu mới 
cho dữ liệu dạng bảng trong các kịch bản khác nhau, chẳng hạn như 
học có giám sát và bán giám sát. Đóng góp chính của nó là 
chuyển đổi các embedding phân loại thông thường thành các embedding 
theo ngữ cảnh, do đó đạt được độ chính xác cao hơn so với 
các phương pháp tiên tiến trước đó. Mặt khác, Quyền riêng tư 
Sai phân (DP) [5] là một kỹ thuật thường được sử dụng để đảm bảo 
quyền riêng tư cho các điểm dữ liệu cá nhân trong tập dữ liệu huấn luyện. 
DP-SGD [6], kết hợp DP với thuật toán gradient descent ngẫu nhiên (SGD), 
là một trong những kỹ thuật tối ưu hóa thường được sử dụng nhất 
trong học máy (ML) để huấn luyện mô hình trên dữ liệu nhạy cảm 
trong khi bảo vệ quyền riêng tư cá nhân.

Trong tài liệu, các kỹ thuật DP-SGD hoặc tinh chỉnh một 
mô hình đã được tiền huấn luyện hoặc huấn luyện mô hình từ đầu. 
Tuy nhiên, hầu như không có nghiên cứu nào tập trung vào TabTransformer. 
Trong bài báo này, chúng tôi triển khai các kỹ thuật tinh chỉnh 
hiệu quả tham số gần đây, chẳng hạn như LoRA [2], Adapter [3], 
và Prompt Tuning [4] (cả Shallow Tuning và Deep Tuning), 
nhằm khám phá lợi ích của tiền huấn luyện và tinh chỉnh với 
quyền riêng tư sai phân cho TabTransformer. Tóm lại, các đóng góp 
chính của chúng tôi như sau: 1) Chúng tôi nghiên cứu một kịch bản 
chưa được khám phá cho học chuyển giao trong TabTransformer với DP, 
tức là triển khai các loại kỹ thuật hiệu quả tham số khác nhau 
trong giai đoạn tinh chỉnh thay vì tinh chỉnh toàn bộ. 2) Khác 
với các phương pháp học dạng bảng trước đây chủ yếu khai thác 
DP ở giai đoạn tinh chỉnh, chúng tôi nghiên cứu việc sử dụng 
DP-SGD cho cả tiền huấn luyện và tinh chỉnh, do đó đảm bảo 
quyền riêng tư từ đầu đến cuối. 3) Các thí nghiệm của chúng tôi 
trên tập dữ liệu ACSIncome cho thấy độ chính xác vượt trội so với 
các phương pháp cơ sở trong hầu hết các trường hợp, trong khi 
hiệu quả tham số cải thiện hơn 97,86%. Ngoài ra, chúng tôi báo cáo 
cài đặt PEFT có lợi nhất để thông báo và truyền cảm hứng cho 
thiết kế tương lai của tiền huấn luyện và tinh chỉnh nhận biết DP 
cho TabTransformer.

2. BỐI CẢNH VÀ NGHIÊN CỨU LIÊN QUAN

2.1. Quyền riêng tư Sai phân (DP) và DP-SGD
ML được biết đến rộng rãi với khả năng phân tích các tập dữ liệu lớn,
nhận dạng các mẫu, và đưa ra dự đoán hoặc quyết định dựa trên
dữ liệu đó. Tuy nhiên, điều này cũng mang đến rủi ro tiết lộ
thông tin nhạy cảm từ tập dữ liệu huấn luyện. DP [5] và
DP-SGD [6] được giới thiệu để giải quyết vấn đề này. Một thuật toán
ngẫu nhiên A thỏa mãn (ϵ, δ)−DP nếu nó thỏa mãn:
P[A(D)∈S]≤exp(ϵ)P[A(D′)∈S] +δ, (1)
trong đó P[A(D)∈S] là xác suất đầu ra của A
trên tập dữ liệu D rơi vào tập S, và P[A(D′)∈S] là
xác suất đầu ra của A trên tập dữ liệu lân cận
D′(khác với D một điểm dữ liệu) rơi vào S.
Càng nhỏ ϵ, A có đảm bảo quyền riêng tư càng mạnh.

Được truyền cảm hứng bởi DP, Thuật toán Gradient Descent
Ngẫu nhiên với Quyền riêng tư Sai phân (DP-SGD) [6] là một
trong những kỹ thuật tối ưu hóa bảo vệ quyền riêng tư được sử dụng
rộng rãi nhất trong ML [12–15]. Đây là một quy trình hai giai đoạn.
Chính thức, cho ước lượng gradient SGD g được đánh giá trên tập dữ liệu
huấn luyện, và định nghĩa độ nhạy Sg là giá trị lớn nhất của ∥g(D)−g(D′)∥2.
Trong giai đoạn đầu tiên, DP-SGD thêm nhiễu Gaussian với trung bình bằng không
có ma trận hiệp phương sai cho trước, tức là N(0, S²gσ²I) vào ước lượng
gradient đã tính toán như sau:
g(D) +N(0, S²gσ²I).
Trong giai đoạn thứ hai, DP-SGD truyền ước lượng gradient
qua toán tử Clip:
Clip(x) =x/max{1,∥x∥2/C},
để cố định độ nhạy của ước lượng gradient tại một siêu
tham số C. Tuy nhiên, đáng tiếc là hầu như không có kỹ thuật
DP-SGD nào được áp dụng cho nghiên cứu TabTransformer.

2.2. Tinh chỉnh Hiệu quả Tham số (PEFT)
PEFT [2–4, 9–11] là một kỹ thuật mới nổi trong lĩnh vực
học chuyển giao nhằm thích ứng các mô hình lớn đã được tiền huấn luyện
với các tác vụ cụ thể với số lượng tham số đặc thù tác vụ nhỏ hơn.
Nó tinh chỉnh mô hình đã tiền huấn luyện trên tác vụ mục tiêu
trong khi giữ đông đa số tham số gốc của mô hình. So với
tinh chỉnh toàn bộ mà tinh chỉnh toàn bộ mô hình, phương pháp này
giảm tài nguyên tính toán và yêu cầu bộ nhớ cần thiết cho
thích ứng đặc thù tác vụ. PEFT đặc biệt có giá trị trong các
kịch bản với tài nguyên tính toán hạn chế hoặc khi triển khai
mô hình đến các môi trường hạn chế tài nguyên, mà không hy sinh
hiệu suất tác vụ. Các kỹ thuật PEFT phổ biến nhất bao gồm
LoRA [2], Adapter [3], và (Deep/Shallow) Prompt Tuning
[4]. Tuy nhiên, tương tự như ML tiêu chuẩn, PEFT cũng đối mặt
với rủi ro tiết lộ dữ liệu nhạy cảm trong suốt quy trình tinh chỉnh
và do đó cần đảm bảo quyền riêng tư [7].

3. PHƯƠNG PHÁP LUẬN

3.1. TabTransformer
TabTransformer [1] là một kiến trúc học sâu cho
mô hình hóa dữ liệu dạng bảng. Nó sử dụng các embedding theo ngữ cảnh
để đạt được độ chính xác dự đoán cao hơn và khả năng diễn giải tốt hơn.
Nó vượt trội so với các phương pháp học sâu tiên tiến cho dữ liệu
dạng bảng và rất bền vững trước các đặc trưng dữ liệu bị thiếu
hoặc nhiễu. Cấu trúc tóm tắt của TabTransformer được hiển thị
trong Hình 1 (a). Kiến trúc TabTransformer bao gồm một lớp
embedding cột, một chồng N khối Transformer, và một
perceptron đa lớp (MLP). Mỗi lớp Transformer bao gồm
một lớp multi-head self-attention theo sau bởi một lớp
feed-forward theo vị trí. Như thể hiện trong Hình 1 (a), các
vùng được tô đỏ là nơi chúng ta có thể thực hiện PEFT.
Cụ thể, chúng tôi đã triển khai LoRA [2] và Adapter [3]
trong các khối Transformer, trong khi Deep Tuning và Shallow Tuning [4]
được khai thác trong MLP.

3.2. Deep Tuning và Shallow Tuning
Visual Prompt Tuning (VPT) [4] là một phương án hiệu quả
so với tinh chỉnh toàn bộ cho các mô hình Transformer
quy mô lớn. Nó cung cấp hai chiến lược tinh chỉnh: VPT-Deep và
VPT-Shallow. VPT-Deep thêm trước một tập các tham số có thể học
vào đầu vào của mỗi lớp encoder Transformer, trong khi
VPT-Shallow chỉ chèn các tham số prompt vào đầu vào của
lớp đầu tiên. Được truyền cảm hứng bởi VPT, chúng tôi đề xuất
Deep Tuning và Shallow Tuning, nhằm tinh chỉnh MLP của
TabTransformer.

3.3. Adapter
Adapter [3], như thể hiện trong Hình 2 (b), là một phương pháp
học chuyển giao cho phép chia sẻ tham số hiệu quả và khả năng
mở rộng trong các mô hình lớn đã được tiền huấn luyện. Nó sử dụng
các mô-đun nhỏ và đặc thù tác vụ được chèn giữa các lớp
đã được tiền huấn luyện của mô hình cơ sở. Các mô-đun này có
khởi tạo gần đồng nhất và số lượng tham số nhỏ, cho phép
huấn luyện ổn định và tăng trưởng chậm của tổng kích thước mô hình
khi thêm nhiều tác vụ hơn.

3.4. LoRA
LoRA [2], như thể hiện trong Hình 2 (c), là một kỹ thuật
thích ứng low-rank giảm số lượng tham số có thể huấn luyện
cho các tác vụ hạ lưu trong khi duy trì chất lượng mô hình cao.
Nó hoạt động bằng cách tiêm một ma trận thích ứng low-rank
vào mô hình đã được tiền huấn luyện, có thể được chia sẻ
và sử dụng để xây dựng nhiều mô-đun LoRA nhỏ cho các tác vụ
khác nhau. LoRA làm cho huấn luyện hiệu quả hơn và cho phép
chuyển đổi tác vụ nhanh chóng.

3.5. PEFT Kết hợp với DP-SGD
Chúng tôi tích hợp DP-SGD vào PEFT bằng cách ban đầu tiền huấn luyện
một mô hình TabTransformer với DP trên tập dữ liệu tiền huấn luyện.
Sau đó, chúng tôi đông đá backbone của mô hình đã được tiền huấn luyện
và áp dụng các kỹ thuật PEFT nói trên để tinh chỉnh mô hình
kết hợp với DP-SGD trên tập dữ liệu hạ lưu. Phương pháp này
phục vụ để bảo vệ quyền riêng tư của cả tập dữ liệu tiền huấn luyện
và tập dữ liệu hạ lưu, do đó đảm bảo quyền riêng tư từ đầu đến cuối.
Cụ thể hơn, như thể hiện trong Hình 2 (a) và Hình 2 (c), chúng tôi
kết hợp LoRA với lớp Feed Forward trong mỗi khối Transformer
của TabTransformer. Hơn nữa, chúng tôi tiêm một Adapter giữa
lớp Feed Forward và lớp Add & Norm trong mỗi khối Transformer
của TabTransformer. Đối với Deep Tuning và Shallow Tuning,
như thể hiện trong Hình 1 (b), Deep Tuning tinh chỉnh một số
nơ-ron nhất định trong mỗi lớp của MLP, tức là phần được đánh dấu
đỏ trong Hình 1 (b). Trong khi đó, Shallow Tuning chỉ tinh chỉnh
một vài nơ-ron trong lớp đầu vào của MLP, tức là phần được đánh dấu
xanh trong hình.

4. ĐÁNH GIÁ HIỆU SUẤT
Trong phần này, chúng tôi kiểm tra hiệu suất của tất cả các
phương pháp PEFT đã đề cập và xác định phương pháp hiệu quả
nhất để có lợi cho nghiên cứu tương lai. Để so sánh, chúng tôi
khai thác hai phương pháp cơ sở, tức là tinh chỉnh toàn bộ
và huấn luyện từ đầu. Hơn nữa, để minh họa tác động của PEFT,
chúng tôi cũng đánh giá mô hình đã được tiền huấn luyện trực tiếp
trên dữ liệu hạ lưu mà không có PEFT (tức là Suy luận Zero-shot).
Kết quả thí nghiệm cho thấy rõ ràng rằng các phương pháp PEFT
đảm bảo hiệu quả tham số cao mà không mất độ chính xác, do đó
vượt trội so với các phương pháp cơ bản về độ chính xác, hiệu quả
tham số, và quyền riêng tư.

4.1. Thiết lập Thí nghiệm
Tập dữ liệu ACSIncome. Tập dữ liệu ACSIncome [8] được lấy
từ dữ liệu American Community Survey (ACS) Public Use
Microdata Sample (PUMS). Nó nhằm dự đoán liệu thu nhập
hàng năm của người trưởng thành làm việc ở Mỹ có trên 50.000 đô la
hay không. Nó bao phủ tất cả các bang của Hoa Kỳ và bao gồm
nhiều năm. Được truyền cảm hứng bởi đặc điểm này, chúng ta có thể
thực hiện tiền huấn luyện và tinh chỉnh qua các bang khác nhau.
Cụ thể hơn, chúng tôi đã chọn hai bang, California (CA) và
Indiana (IN), cách xa nhau về địa lý và có sự khác biệt
đáng kể về quy mô dân số và chênh lệch kinh tế. CA và IN
thể hiện sự thay đổi phân phối tập huấn luyện rõ ràng, và do đó
chúng tôi đã sử dụng chúng cho nghiên cứu về tiền huấn luyện
và tinh chỉnh với TabTransformer.

Phương pháp cơ sở. (1) Tinh chỉnh Toàn bộ: Trong kịch bản này,
sau tiền huấn luyện, Tinh chỉnh Toàn bộ tinh chỉnh tất cả
tham số của mô hình đã được tiền huấn luyện. (2) Huấn luyện
từ đầu: Phương pháp cơ sở này chỉ đơn giản huấn luyện toàn bộ
mô hình trên tập dữ liệu hạ lưu từ đầu mà không có tiền huấn luyện.
(3) Suy luận Zero-shot: Để nhấn mạnh hiệu quả của PEFT,
sau khi có được mô hình đã được tiền huấn luyện, phương pháp cơ sở
này trực tiếp đánh giá hiệu suất của cùng mô hình trên tập dữ liệu
hạ lưu.

Tham số. (1) Cho ep chỉ ϵ được sử dụng cho tiền huấn luyện
và ef biểu thị ϵ được sử dụng cho tinh chỉnh. Các giá trị cho
ep và ef được chọn từ {0.5,1,2,4,8,16,32}. (2) Norm cắt
C= 2. (3) δ= 10⁻⁵. (4) Đối với TabTransformer, chúng tôi
đặt chiều ẩn (embedding), số lượng khối Transformer, và
số lượng attention head lần lượt là 32, 4, và 8. Kích thước
MLP là 5 lớp với 72 đơn vị cho mỗi lớp. (4) Kích thước
batch B= 64 cho cả tiền huấn luyện và tinh chỉnh. (5) Tinh chỉnh
toàn bộ tinh chỉnh 8 đơn vị (token) trong mỗi lớp MLP,
và Shallow Tuning tinh chỉnh 8 đơn vị chỉ trong lớp đầu tiên
của MLP.

4.2. Kết quả Thí nghiệm
Số lượng Tham số Có thể Huấn luyện. Mức độ hiệu quả
tham số trong một kỹ thuật PEFT phụ thuộc vào số lượng
tham số vẫn có thể huấn luyện được trong quá trình tinh chỉnh.
Cho N đại diện cho số lượng tham số có thể huấn luyện, và
khi đó N của tất cả các kỹ thuật được thể hiện trong Bảng 1.

Bảng 1. Số lượng Tham số Có thể Huấn luyện của Các Phương pháp Khác nhau
Phương pháp     Deep Tuning  Full Tuning  Shallow Tuning
N               4,408        206,193      2,072
Phương pháp     Adapter      LoRA         Train from Scratch
N               1,424        1,424        206,193

Dựa trên số lượng tham số trong Bảng 1, chúng ta có thể đi đến
kết luận sau. Khi chúng ta so sánh giữa các phương pháp PEFT
được liệt kê trong bảng và các phương pháp cơ sở (Full Tuning
và Train from Scratch), rõ ràng rằng tất cả các phương pháp
PEFT đều giảm đáng kể giá trị N ít nhất (206,193−4,408)/206,193=
97.86%. Để đi vào chi tiết, đáng chú ý rằng LoRA và Adapter
nổi lên như những phương án hiệu quả tham số nhất, thể hiện
sự giảm đáng kể trong N bởi (206,193−1,424)/206,193=99.3%.

Độ chính xác Kiểm tra. Trong nỗ lực đánh giá hiệu suất
của tất cả các phương pháp PEFT so với phương pháp cơ sở,
mô hình TabTransformer đã trải qua một quy trình hai bước.
Ban đầu, nó được tiền huấn luyện trên tập dữ liệu ACSIncome
từ California (tổng cộng 195,665 mẫu), sau đó tinh chỉnh
trên tập dữ liệu ACSIncome từ Indiana (tổng cộng 35,022 mẫu).
Toàn bộ quá trình tiền huấn luyện và tinh chỉnh được thực hiện
sử dụng DP-SGD. Để đánh giá, chúng tôi ngẫu nhiên chia 20%
ACSIncome-Indiana làm tập kiểm tra. Hơn nữa, chúng tôi lựa chọn
sử dụng thước đo độ chính xác, ký hiệu là Accuracy (Acc),
làm tiêu chí đánh giá chính để đánh giá khả năng của TabTransformer
trong việc dự đoán liệu thu nhập hàng năm của một cá nhân
có vượt quá 50.000 đô la hay không. Kết quả chi tiết được thể hiện
trong Bảng 2.

Dựa trên các phát hiện được trình bày trong Bảng 2 và Bảng 1,
chúng ta có thể suy ra những kết luận sau. Thứ nhất, tất cả
các phương pháp PEFT đều thể hiện Acc tương đương khi so sánh
với các phương pháp cơ sở. Ví dụ, khi ϵp, ϵf đều được đặt
là 32, Acc của Deep Tuning, Adapter, LoRA, và Shallow Tuning
lần lượt là 0.75, 0.7475, 0.7472, và 0.7452. Trong khi đó,
khi ϵ= 32, Acc của Train from Scratch và Zero-shot Inference
lần lượt là 0.7099 và 0.7098. Các giá trị này cho thấy rằng
khi so sánh với Train from Scratch và Zero-shot Inference,
các kỹ thuật PEFT tăng Acc ít nhất 4.7%. Hơn nữa, Acc của
PEFT không tụt hậu đáng kể so với Full Tuning. Do đó, tóm lại,
các kỹ thuật PEFT đạt được mức độ chính xác (Acc) xuất sắc
trong khi thể hiện mức độ hiệu quả tham số cao đáng kể.
Thứ hai, các phương pháp PEFT thể hiện khả năng chịu đựng
mạnh mẽ với các giá trị ϵ thấp so với Full Tuning, điều này
cho thấy rằng PEFT có thể đảm bảo mức độ quyền riêng tư cao hơn
Full Tuning. Ví dụ, khi (ϵp, ϵf) = (32, 0.5), Acc của
Deep Tuning, Adapter, LoRA, và Shallow Tuning lần lượt là
0.7239, 0.7368, 0.7272, 0.736, trong khi Acc của Full Tuning
là 0.6889. Do đó, khi (ϵp, ϵf) = (32, 0.5), Acc của PEFT
ít nhất cao hơn Full Tuning 3.5%. Thứ ba, chúng tôi thấy rằng
Deep Tuning và Adapter vượt trội hơn các phương pháp khác
trong hầu hết các trường hợp. Xét rằng Adapter hiệu quả tham số
hơn Deep Tuning như thể hiện trong Bảng 1, chúng ta có thể
kết luận rằng Adapter đạt được sự cân bằng tốt nhất giữa
quyền riêng tư, độ chính xác, và hiệu quả tham số.

5. KẾT LUẬN
Trong bài báo này, chúng tôi đã trình bày một nghiên cứu thử nghiệm
khám phá lợi ích của việc kết hợp tiền huấn luyện với quyền riêng tư
sai phân và tinh chỉnh hiệu quả tham số (PEFT) cho TabTransformer
với nhiều phương pháp tinh chỉnh khác nhau, bao gồm Adapter [3],
LoRA [2], Deep/Shallow Tuning [4]. Chúng tôi đã tiến hành các
thí nghiệm mở rộng trên tập dữ liệu ACSIncome với các cấu hình
khác nhau. Kết quả trong Bảng 1 cho thấy số lượng tham số có thể
huấn luyện của các kỹ thuật PEFT giảm ít nhất 97.86% so với
các phương pháp cơ sở. Kết quả trong Bảng 2 cho thấy độ chính xác
của các phương pháp PEFT vượt trội so với các phương pháp cơ sở
trong hầu hết các trường hợp. Do đó, so với ba phương pháp cơ sở
hoặc tốn tham số hoặc không hiệu quả, các kỹ thuật PEFT đạt được
sự cân bằng cải thiện đáng kể giữa quyền riêng tư, độ chính xác,
và hiệu quả tham số. Chúng tôi cũng thấy rằng Adapter là cài đặt
tối ưu nhất cho PEFT trong bối cảnh này. Nghiên cứu của chúng tôi
khám phá các lợi ích chưa được khám phá và cung cấp những hiểu biết
mới về việc áp dụng PEFT trên TabTransformer đã được tiền huấn luyện
với quyền riêng tư sai phân cho học chuyển giao với quyền riêng tư
sai phân.

--- TRANG 5 ---
6. TÀI LIỆU THAM KHẢO
[1] Xin Huang, Ashish Khetan, Milan Cvitkovic, và
Zohar Karnin. Tabtransformer: Tabular data mod-
eling using contextual embeddings. arXiv preprint
arXiv:2012.06678, 2020.
[2] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và
Weizhu Chen. Lora: Low-rank adaptation of large lan-
guage models. arXiv preprint arXiv:2106.09685, 2021.
[3] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,
Bruna Morrone, Quentin De Laroussilhe, Andrea Ges-
mundo, Mona Attariyan, và Sylvain Gelly. Parameter-
efficient transfer learning for nlp. In International
Conference on Machine Learning, pages 2790–2799.
PMLR, 2019.
[4] Menglin Jia, Luming Tang, Bor-Chun Chen, Claire
Cardie, Serge Belongie, Bharath Hariharan, và Ser-
Nam Lim. Visual prompt tuning. In European Con-
ference on Computer Vision, pages 709–727. Springer,
2022.
[5] Cynthia Dwork, Frank McSherry, Kobbi Nissim, và
Adam Smith. Calibrating noise to sensitivity in private
data analysis. In Theory of Cryptography: Third Theory
of Cryptography Conference, TCC 2006, New York, NY,
USA, March 4-7, 2006. Proceedings 3, pages 265–284.
Springer, 2006.
[6] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan
McMahan, Ilya Mironov, Kunal Talwar, và Li Zhang.
Deep learning with differential privacy. In Proceedings
of the 2016 ACM SIGSAC conference on computer and
communications security, pages 308–318, 2016.
[7] Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi,
Huseyin A Inan, Gautam Kamath, Janardhan Kulkarni,
Yin Tat Lee, Andre Manoel, Lukas Wutschitz, et al. Dif-
ferentially private fine-tuning of language models. arXiv
preprint arXiv:2110.06500, 2021.
[8] Frances Ding, Moritz Hardt, John Miller, và Ludwig
Schmidt. Retiring adult: New datasets for fair machine
learning. Advances in neural information processing
systems, 34:6478–6490, 2021.
[9] Jonas Pfeiffer, Ivan Vulić, Iryna Gurevych, và Sebas-
tian Ruder. Mad-x: An adapter-based framework for
multi-task cross-lingual transfer. In Proceedings of the
2020 Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 7654–7673, 2020.
[10] Yuning Mao, Lambert Mathias, Rui Hou, Amjad Alma-
hairi, Hao Ma, Jiawei Han, Scott Yih, và Madian
Khabsa. Unipelt: A unified framework for parameter-
efficient language model tuning. In Proceedings of
the 60th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers), pages
6253–6264, 2022.
[11] Xiang Lisa Li và Percy Liang. Prefix-tuning: Optimiz-
ing continuous prompts for generation. In Proceedings
of the 59th Annual Meeting of the Association for Com-
putational Linguistics and the 11th International Joint
Conference on Natural Language Processing (Volume
1: Long Papers), pages 4582–4597, 2021.
[12] Muah Kim, Onur Günlü, và Rafael F Schaefer. Feder-
ated learning with local differential privacy: Trade-offs
between privacy, utility, and communication. In ICASSP
2021-2021 IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP), pages
2650–2654. IEEE, 2021.
[13] Christophe Dupuy, Radhika Arava, Rahul Gupta, và
Anna Rumshisky. An efficient dp-sgd mechanism for
large scale nlu models. In ICASSP 2022-2022 IEEE In-
ternational Conference on Acoustics, Speech and Signal
Processing (ICASSP), pages 4118–4122. IEEE, 2022.
[14] Huzaifa Arif, Alex Gittens, và Pin-Yu Chen.
Reprogrammable-fl: Improving utility-privacy tradeoff
in federated learning via model reprogramming. In 2023
IEEE Conference on Secure and Trustworthy Machine
Learning (SaTML), pages 197–209. IEEE, 2023.
[15] Yizhe Li, Yu-Lin Tsai, Xuebin Ren, Chia-Mu Yu,
và Pin-Yu Chen. Exploring the benefits of vi-
sual prompting in differential privacy. arXiv preprint
arXiv:2303.12247, 2023.

# Khảo sát Khả năng Chống chịu Phân phối Ngoài miền của Mô hình Ngôn ngữ với Học chuyển giao Hiệu quả Tham số

Hyunsoo Cho†, Choonghyun Park†, Junyeop Kim†, Hyuhng Joon Kim†,
Kang Min Yoo†‡∗, Sang-goo Lee†§∗
†Đại học Quốc gia Seoul, ‡NAVER, §IntelliSys
{johyunsoo,pch330,juny116,heyjoonkim,sglee}@europa.snu.ac.kr
{kangmin.yoo}@navercorp.com

Tóm tắt
Khi kích thước của mô hình ngôn ngữ được tiền huấn luyện (PLM) tiếp tục tăng, nhiều phương pháp học chuyển giao hiệu quả tham số đã được đề xuất gần đây để bù đắp cho chi phí khổng lồ của việc tinh chỉnh. Mặc dù đạt được kết quả ấn tượng từ các mô hình ngôn ngữ được tiền huấn luyện lớn (PLMs) và các phương pháp học chuyển giao hiệu quả tham số (PETL) khác nhau trên nhiều bộ tiêu chuẩn, vẫn chưa rõ liệu chúng có thể xử lý các đầu vào đã bị dịch chuyển phân phối một cách hiệu quả. Trong nghiên cứu này, chúng tôi khám phá một cách có hệ thống khả năng phát hiện ngoài phân phối (OOD) thay đổi như thế nào khi kích thước PLM tăng lên hoặc các phương pháp chuyển giao được thay đổi. Cụ thể, chúng tôi đánh giá các kỹ thuật PETL khác nhau, bao gồm tinh chỉnh, Adapter, LoRA, và prefix-tuning, trên ba tác vụ phân loại ý định khác nhau, mỗi tác vụ sử dụng các mô hình ngôn ngữ khác nhau với các quy mô khác nhau.

1 Giới thiệu

Các mô hình ngôn ngữ được tiền huấn luyện (PLM), được tiền huấn luyện trên các kho dữ liệu quy mô lớn sử dụng kiến trúc dựa trên transformer (Vaswani et al., 2017), đã đạt được thành công đột phá trên nhiều bộ tiêu chuẩn (Wang et al., 2019b; Rajpurkar et al., 2016; Wang et al., 2019a), khẳng định vị thế của chúng như mô hình neural chuẩn trong vô số ứng dụng.

Hơn nữa, các mô hình ngôn ngữ được tiền huấn luyện với số lượng tham số lớn hơn trên khối lượng dữ liệu phong phú có xu hướng thể hiện nhiều tiềm năng hấp dẫn hơn, chẳng hạn như khả năng nắm bắt kiến thức thế giới (Petroni et al., 2019), tạo mã lệnh (Poesia et al., 2022), và thậm chí giải quyết các bài toán số học (Henighan et al., 2020), ngoài việc hiểu kiến thức ngôn ngữ học (ví dụ: ngữ nghĩa hoặc cú pháp). Để khám phá đỉnh cao của các mô hình ngôn ngữ được tiền huấn luyện (PLMs), kích thước của PLMs đang tăng theo cấp số nhân và đã đạt tới hàng tỷ đến hàng nghìn tỷ tham số (Brown et al., 2020; Chowdhery et al., 2022; Fedus et al., 2022; Hoffmann et al., 2022).

Trong những hoàn cảnh này, phương pháp truyền thống để chuyển giao PLMs sang tác vụ đích (tức là tinh chỉnh) hiện không khả thi vì nó đòi hỏi chi phí cấm đoán để huấn luyện và lưu trữ toàn bộ tham số của PLMs lớn cho mỗi tác vụ mong muốn. Để giảm thiểu vấn đề này, một số phương pháp học chuyển giao hiệu quả tham số (PETL) gần đây đã được đề xuất để cải thiện khả năng mở rộng tác vụ. Ví dụ, các phương pháp dựa trên adapter (Houlsby et al., 2019; Hu et al., 2022) chèn các mô-đun neural nhỏ vào mỗi lớp của PLM và cập nhật các mô-đun nhẹ đó trong giai đoạn huấn luyện. Được truyền cảm hứng từ thành công gần đây của các prompt văn bản (Brown et al., 2020), các phương pháp dựa trên prompt (Li and Liang, 2021; Lester et al., 2021; Shin et al., 2020) nối các token có thể điều chỉnh bổ sung vào phía trước của đầu vào hoặc các lớp ẩn và cập nhật các soft prompt được thêm vào trước trong giai đoạn huấn luyện.

Mặc dù có những đột phá này trong NLP, ngay cả các nghiên cứu phát hiện bất thường rất gần đây (Cho et al., 2022; Shen et al., 2021) vẫn bị giới hạn ở các PLMs hai chiều tương đối nhỏ (ví dụ: BERT, RoBERTa). Do đó, cách thức các PLMs quy mô lớn hoặc PLMs tự hồi quy đối phó với các ngoại lệ vẫn là vùng đất chưa được khám phá, tự nhiên đặt ra những câu hỏi sau:

•Q1: Việc tăng kích thước mô hình có cải thiện hiệu suất phát hiện OOD mà không có tham số mô hình không?

•Q2: Nếu có, việc mở rộng quy mô PLM có làm cho mô hình đủ mạnh để sử dụng chúng mà không cần bất kỳ quy trình bổ sung nào không?

•Q3: Tinh chỉnh và các phương pháp PETL khác nhau có hiển thị sự khác biệt về hiệu suất phát hiện OOD theo kích thước của PLMs không?

•Q4: Các phương pháp phát hiện OOD từ các nghiên cứu trước đây (thường dành cho PLMs hai chiều) có thể được chuyển giao sang PLMs tự hồi quy (GPT) không?

Để giải quyết những câu hỏi này, bài báo này điều tra khả năng của PLMs lớn như các bộ phát hiện ngoại lệ từ nhiều góc độ khác nhau. Cụ thể, chúng tôi so sánh khả năng chống chịu với các ngoại lệ với các kỹ thuật học chuyển giao khác nhau trên một số bộ tiêu chuẩn OOD: Tinh chỉnh đầy đủ, LoRA (Hu et al., 2022), Adapter (Houlsby et al., 2019), và prefix-tuning (Li and Liang, 2021) trên các PLMs tự hồi quy khác nhau với kích thước khác nhau, tức là GPT2-S, M, L, XL (Radford et al., 2019), GPT-Neo (Black et al., 2021) và GPT-J (Wang and Komatsuzaki, 2021). Từ các điều tra sâu sắc, chúng tôi chia sẻ một số quan sát hấp dẫn: (1) Khi kích thước PLM tăng lên, hiệu suất cải thiện mà không cần cập nhật bất kỳ tham số mô hình nào. Tuy nhiên, việc sử dụng nó mà không có sự giám sát vẫn là thách thức vì hiệu suất của chúng vẫn còn tụt hậu so với PLM nhỏ được tinh chỉnh (tức là BERT-base). (2) PETLs vượt trội hơn tinh chỉnh với PLMs đủ lớn trong cả các chỉ số IND và OOD. (3) Cuối cùng, việc tận dụng thông tin của biểu diễn ẩn cuối cùng, phương pháp phổ biến nhất cho PLM hai chiều trong phát hiện OOD gần đây, không chuyển giao tốt trong PLM tự hồi quy, đòi hỏi một kỹ thuật trích xuất biểu diễn mới. Chúng tôi tin rằng những phát hiện này sẽ giúp ích cho các nghiên cứu phát hiện bất thường trong tương lai.

2 Khảo sát Khả năng Chống chịu OOD

2.1 Các mô hình gốc và mô hình

Để điều tra xu hướng hiệu suất OOD dưới các quy mô PLM khác nhau, chúng tôi xem xét ba yếu tố trong quá trình lựa chọn mô hình gốc. Chúng phải (1) có sẵn công khai, (2) có kích thước hợp lý lớn, và (3) chia sẻ cấu trúc giống hệt nhau để loại bỏ các yếu tố khác ngoài kích thước. Vì các PLMs lớn gần đây sử dụng các mục tiêu tự hồi quy do độ phức tạp tính toán của chúng, chúng tôi áp dụng sáu PLMs tự hồi quy làm xương sống của các thí nghiệm của chúng tôi tương ứng: GPT2 (S,M,L,XL), GPT-Neo, và GPT-J.

Đối với các phương pháp chuyển giao hiệu quả tham số, chúng tôi đã chọn hai phương pháp: hai phương pháp dựa trên adapter và một phương pháp dựa trên kỹ thuật prompt. Cụ thể, Adapter (Houlsby et al., 2019), LoRA (Hu et al., 2022), và Prefix-tuning (Li and Liang, 2021) được chọn cho phương pháp adapter, tương thích với các tác vụ phân loại, cho phương pháp prompt. Chúng tôi cũng báo cáo hiệu suất của đánh giá tuyến tính, tức là perceptron một lớp (SLP) trên PLMs, và tinh chỉnh, lần lượt hoạt động như giới hạn dưới và giới hạn trên.

2.2 Bộ dữ liệu và Chỉ số

Bộ dữ liệu. Chúng tôi đánh giá mô hình trên hai bộ dữ liệu, CLINC150 và Banking77, được sử dụng rộng rãi trong phát hiện OOD. Bộ dữ liệu CLINC150 (Larson et al., 2019) chứa 150 nhãn lớp (15 ý định cho 10 miền), trong khi bộ dữ liệu Banking77 (Casanueva et al., 2020) bao gồm 77 ý định liên quan đến ngân hàng chi tiết. Theo các cài đặt thí nghiệm từ các nghiên cứu trước đây (Cho et al., 2022; Zhang et al., 2022; Shu et al., 2017; Fei and Liu, 2016; Lin and Xu, 2019), chúng tôi xác thực mô hình trong hai tình huống khác nhau: cài đặt far-OOD và cài đặt close-OOD.

Đối với bộ dữ liệu CLINC, chúng tôi huấn luyện mô hình với toàn bộ bộ dữ liệu huấn luyện và kiểm tra với một phần kiểm tra OOD độc lập từ bộ dữ liệu CLINC, không trùng lặp với 150 lớp trong bộ dữ liệu huấn luyện. Các ngoại lệ trong phần OOD CLINC có phân phối xa với phân phối huấn luyện (Zhang et al., 2022), vì vậy tương đối dễ phân biệt. Đối với Banking77, chúng tôi phân chia bộ dữ liệu thành 2 bộ dữ liệu rời rạc (tức là bộ dữ liệu IND / OOD) dựa trên nhãn lớp. Vì cả bộ dữ liệu IND và OOD đều bắt nguồn từ bộ dữ liệu tương đương, chúng chia sẻ các phân phối và thuộc tính tương tự, làm cho tác vụ khó khăn hơn. Do đó, chúng tôi gọi cài đặt CLINC OOD là far-OOD và cài đặt phân chia trong Banking là cài đặt close-OOD, tương ứng.

Chỉ số. Để đánh giá hiệu suất IND, chúng tôi đo độ chính xác phân loại. Và đối với hiệu suất OOD, chúng tôi áp dụng hai chỉ số thường được sử dụng trong tài liệu phát hiện OOD gần đây:

•FPR@95. Tỷ lệ dương tính giả tại tỷ lệ dương tính thật 95% (FPR@95) đo xác suất phân loại đầu vào OOD như đầu vào IND khi tỷ lệ dương tính thật là 95%.

•AUROC. Diện tích dưới đường cong đặc tính hoạt động của máy thu (AUROC) là một chỉ số không có ngưỡng chỉ ra khả năng của mô hình trong việc phân biệt các ngoại lệ khỏi các mẫu IND.

2.3 Phương pháp Đánh giá OOD

Đánh giá trong phát hiện OOD được thực hiện thông qua một hàm tính điểm, xuất ra sự thích hợp của đầu vào thành một giá trị vô hướng duy nhất (p). Sau đó chúng tôi so sánh p với ngưỡng đặt trước δ để xác định xem đầu vào có phải là ngoại lệ hay không:

Iδ(x) = {IND nếu p(x) ≥ δ; OOD nếu p(x) < δ}     (1)

Trong bài báo này, chúng tôi đánh giá hiệu suất phương pháp của chúng tôi bằng 4 phương pháp đánh giá khác nhau, có thể được phân loại thành 2 nhánh cao hơn: dựa trên biểu diễn và dựa trên logit.

Các phương pháp dựa trên Logit khai thác kết quả dự đoán của PLM được trích xuất từ lớp phân loại làm thông tin chính để phân biệt các ngoại lệ. Các phương pháp dựa trên Logit đơn giản và có ưu thế riêng về chi phí tính toán vì chúng theo đuổi phát hiện OOD và phân loại tổng quát gần như đồng thời.

•MSP là phương pháp cơ bản trong nhánh này sử dụng xác suất softmax tối đa để tính điểm sự thích hợp của đầu vào đã cho, dựa trên ý tưởng rằng mô hình sẽ xuất ra kết quả chắc chắn hơn (xác suất cao hơn) cho một mẫu bình thường (Hendrycks and Gimpel, 2017):

p(x) = e^(fi(x)) / ΣN j=1 e^(fj(x))     (2)

trong đó fi(x) đề cập đến giá trị tối đa từ lớp phân loại (giá trị logit tối đa).

•Energy là một biến thể của MSP, hiệu chỉnh giá trị logit dựa trên hàm năng lượng (Liu et al., 2020):

p(x) = -E(x;f) = T·log ΣN i e^(f(x)/T)     (3)

Mặt khác, các phương pháp dựa trên Biểu diễn sử dụng biểu diễn ẩn từ PLM làm nguồn chính. Vì kích thước của biểu diễn ẩn lớn hơn và chứa thông tin phong phú hơn, chúng thường cho kết quả quyết định chính xác hơn so với các phương pháp dựa trên logit. Tuy nhiên, chúng đòi hỏi thời gian suy luận nhiều hơn để tạo ra điểm số cuối cùng. Chúng tôi sử dụng các phương pháp dựa trên khoảng cách Mahalanobis và dựa trên độ tương tự cosine trong nhánh này.

•Khoảng cách Mahalanobis đề cập đến khoảng cách giữa phân phối cụ thể và đầu vào. Trong phát hiện OOD, chúng tôi ước tính phân phối gaussian của bộ dữ liệu huấn luyện và sử dụng khoảng cách Mahalanobis tối thiểu để tính điểm sự thích hợp của đầu vào (Lee et al., 2018):

p(x) = (h-µk)^T Σ^(-1)(h-µk)     (4)

trong đó phân phối huấn luyện là (N(µi,Σ) cho i ∈ i={1,2,···,|C|}), và k đề cập đến chỉ số của khoảng cách mahalanobis tối thiểu.

•Phương pháp Độ tương tự Cosine sử dụng khoảng cách cosine giữa biểu diễn của đầu vào đã cho (z(x)) và láng giềng gần nhất z(xnn) (Tack et al., 2020):

p(x) = sim(z(x),z(xnn))     (5)

3 Phân tích

Trong phần này, chúng tôi chia sẻ một số phát hiện và hiểu biết hấp dẫn từ các cài đặt khác nhau.

3.1 Khả năng Chống chịu OOD của PLMs mà không có Giám sát

Trong thí nghiệm này, chúng tôi điều tra khả năng phát hiện OOD của PLMs mà không có điều chỉnh tham số. Chính xác, chúng tôi trích xuất biểu diễn lớp cuối cùng từ mỗi PLM đông lạnh và đánh giá hiệu suất của chúng thông qua các phương pháp đánh giá dựa trên biểu diễn. (Các phương pháp đánh giá dựa trên Logit không được sử dụng vì chúng đòi hỏi huấn luyện bổ sung của lớp phân loại.) Hình 1 tóm tắt kết quả trong hai tình huống (tức là far-OOD và close-OOD). Chúng tôi xác nhận mối tương quan giữa kích thước PLMs và khả năng phát hiện OOD của chúng, nhưng việc sử dụng chúng mà không có giám sát tham số gần như không thể vì chúng vẫn tụt hậu xa so với các phương pháp có giám sát nhỏ (tức là BERT-base với đánh giá Mahalanobis) trong cài đặt cơ bản. Hơn nữa, cải thiện hiệu suất từ việc mở rộng quy mô bão hòa trong cài đặt khắc nghiệt hơn (tức là close-OOD), hiển thị một khoảng cách không thể vượt qua với mô hình được tinh chỉnh.

3.2 Phương pháp đánh giá cho PLMs tự hồi quy

Nhiều nghiên cứu OOD gần đây (Zhou et al., 2021; Shen et al., 2021) tận dụng đánh giá dựa trên biểu diễn ẩn, vì chúng thường vượt trội hơn các đánh giá dựa trên logit (Podolskiy et al., 2021). Suy đoán hợp lý đằng sau thành công của chúng là biểu diễn ẩn có thông tin phong phú hơn so với giá trị logit. Tuy nhiên, trong PLMs tự hồi quy, các đánh giá dựa trên logit (tức là MSP và Energy) vượt trội hơn các phương pháp dựa trên biểu diễn (tức là khoảng cách Mahalanobis và độ tương tự cosine), như được thể hiện trong Bảng 1. Suy đoán hợp lý cho hiện tượng này là do đặc tính của mô hình ngôn ngữ. Không giống như các mô hình hai chiều (ví dụ: BERT, RoBERTa, DeBERTa), các mô hình giải mã (ví dụ: GPT và các biến thể của nó) không có embedding [CLS], tập hợp các embedding token để nắm bắt thông tin toàn diện (Devlin et al., 2019; Kim et al., 2021). Do đó, PLMs tự hồi quy thường sử dụng embedding token cuối cùng làm embedding đặc trưng cuối cùng thay thế cho embedding [CLS] của các mô hình dựa trên encoder. Trong khi token cuối cùng của GPT phù hợp để dự đoán token tiếp theo, tuy nhiên, nó không thể trích xuất ngữ nghĩa tổng thể của câu một cách thích hợp, không giống như embedding [CLS]. Chúng tôi tin rằng việc trích xuất biểu diễn tốt hơn thông qua các phương pháp pooling khác nhau (Wang and Kuo, 2020) có thể là một hướng đi khả thi cho các mô hình tự hồi quy để cải thiện hơn nữa khả năng chống chịu OOD.

3.3 PETLs VS. Tinh chỉnh

Trong thí nghiệm này, chúng tôi điều tra khoảng cách hiệu suất giữa các phương pháp PETL khác nhau (tức là Adapter, LoRA, prefix-tuning) và tinh chỉnh mô hình. Để so sánh hiệu suất của mỗi phương pháp trong các hoàn cảnh tương tự, chúng tôi đặt mọi phương pháp PETL sử dụng số lượng tham số tương tự đủ để đạt độ chính xác tối đa. Hơn nữa, chúng tôi sử dụng hàm năng lượng để đánh giá mỗi phương pháp vì chúng hiển thị hiệu suất tốt nhất trong số các phương pháp đánh giá khác, tức là cosine, Mahalanobis, và MSP, trong các thí nghiệm trước đây. Bảng 2 tóm tắt kết quả.

Từ thí nghiệm này, chúng tôi quan sát thấy rằng các phương pháp PETL mạnh hơn tinh chỉnh với PLMs có kích thước hợp lý lớn (tức là GPT-J). Cụ thể, hầu hết các phương pháp PELT trên GPT-J vượt trội hơn tinh chỉnh với các tham số có thể điều chỉnh thích hợp. Tuy nhiên, kích thước không phải là câu trả lời cuối cùng. Mặc dù rõ ràng rằng quy mô của mô hình là một yếu tố thiết yếu trong khả năng chống chịu OOD, các mô hình lớn hơn vẫn dễ bị tổn thương với các đầu vào close-OOD. Khả năng phát hiện các đầu vào far-OOD (xa khỏi phân phối huấn luyện) cải thiện tỷ lệ thuận khi kích thước tăng, trong khi khả năng xác định đầu vào close-OOD cải thiện khá tầm thường. Tính dễ bị tổn thương của PLM đối với close-OOD đã được báo cáo trong các nghiên cứu khác (Zhang et al., 2022), và điều này có thể liên quan đến học tắt (Geirhos et al., 2020) dự đoán với xác suất cao bằng cách nhìn vào các từ cụ thể. Việc tạo dữ liệu OOD với các từ khóa cụ thể hoặc sử dụng một tác vụ pretext khác, chẳng hạn như (Moon et al., 2021), có thể là những phương pháp xứng đáng để giảm thiểu hiện tượng như vậy. Một phương pháp OOD phù hợp là cần thiết để giảm thiểu vấn đề nói trên, vì nó có thể tăng cường hơn nữa khả năng chống chịu. Chúng tôi tiến hành các thí nghiệm bổ sung với PETLs trên ba số lượng tham số có thể điều chỉnh khác nhau: 0.1%, 0.5%, và 1% của các tham số PLM. Hình 2 tóm tắt kết quả. Với đủ tham số để đạt hiệu suất tối đa, không có sự khác biệt hoặc cải thiện có ý nghĩa trong mỗi phương pháp. Ngoài ra, theo kinh nghiệm, chúng tôi xác nhận rằng LoRA ổn định nhất trong quá trình học và prefix-tuning dao động mạnh theo việc học.

4 Kết luận và Nghiên cứu Tương lai

Trong nghiên cứu này, chúng tôi đã chỉ ra rằng quy mô của mô hình ngôn ngữ là một yếu tố quan trọng trong khả năng chống chịu OOD. Hơn nữa, chúng tôi cũng cho thấy rằng các phương pháp khác nhau vượt trội hơn tinh chỉnh khi áp dụng cho PLM đủ lớn. Nghiên cứu tiếp theo của chúng tôi tìm cách tạo ra một phương pháp cho phép PLMs lớn mạnh hơn đối với đầu vào OOD. Cải thiện hiệu suất có thể đạt được bằng kích thước PLM và kỹ thuật OOD là trực giao. Phù hợp với kích thước PLM ngày càng tăng, kỹ thuật OOD cần được phát triển theo cách hiệu quả tham số hơn. Như vậy, việc phát triển một kỹ thuật OOD thích hợp tương thích với các phương pháp chuyển giao hiệu quả tham số là mục tiêu thích hợp của chúng tôi.

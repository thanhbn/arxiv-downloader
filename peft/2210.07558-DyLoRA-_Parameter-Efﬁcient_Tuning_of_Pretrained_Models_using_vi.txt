# 2210.07558.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2210.07558.pdf
# Kích thước tệp: 644523 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
DyLoRA: Điều chỉnh hiệu quả tham số của các mô hình được huấn luyện trước bằng cách sử dụng
Thích ứng thứ hạng thấp động không cần tìm kiếm
Mojtaba Valipour1;2Mehdi Rezagholizadeh2Ivan Kobyzev2Ali Ghodsi1
{mojtaba.valipour, ali.ghodsi}@uwaterloo.ca, {mehdi.rezagholizadeh, ivan.kobyzev}@huawei.com
1: Đại học Waterloo, 2: Phòng thí nghiệm Huawei Noah's Ark

Tóm tắt
Với kích thước ngày càng tăng của các mô hình được huấn luyện trước (PM), việc tinh chỉnh chúng đã trở nên đắt đỏ và tốn nhiều tài nguyên hơn. Như một giải pháp, các bộ chuyển đổi thứ hạng thấp (LoRA) giữ các trọng số huấn luyện trước chính của mô hình được cố định và chỉ giới thiệu một số mô-đun SVD cắt ngắn có thể học được (được gọi là các khối LoRA) vào mô hình. Mặc dù các khối LoRA có hiệu quả về tham số, chúng gặp phải hai vấn đề chính: thứ nhất, kích thước của các khối này được cố định và không thể thay đổi sau khi huấn luyện (ví dụ, nếu chúng ta cần thay đổi thứ hạng của các khối LoRA, thì chúng ta cần huấn luyện lại chúng từ đầu); thứ hai, việc tối ưu hóa thứ hạng của chúng đòi hỏi một tìm kiếm và nỗ lực toàn diện. Trong công trình này, chúng tôi giới thiệu một kỹ thuật thích ứng thứ hạng thấp động (DyLoRA) để giải quyết hai vấn đề này cùng lúc. Phương pháp DyLoRA của chúng tôi huấn luyện các khối LoRA cho một phạm vi thứ hạng thay vì một thứ hạng duy nhất bằng cách sắp xếp biểu diễn được học bởi mô-đun bộ chuyển đổi tại các thứ hạng khác nhau trong quá trình huấn luyện. Chúng tôi đánh giá giải pháp của mình trên các nhiệm vụ hiểu ngôn ngữ tự nhiên khác nhau (benchmark GLUE) và các nhiệm vụ tạo ngôn ngữ (E2E, DART và WebNLG) sử dụng các mô hình được huấn luyện trước khác nhau như RoBERTa và GPT với các kích thước khác nhau. Kết quả của chúng tôi cho thấy chúng tôi có thể huấn luyện các mô hình động không cần tìm kiếm với DyLoRA ít nhất nhanh hơn 4 đến 7 lần (tùy thuộc vào nhiệm vụ) so với LoRA mà không làm giảm đáng kể hiệu suất. Hơn nữa, các mô hình của chúng tôi có thể hoạt động ổn định trên phạm vi thứ hạng lớn hơn nhiều so với LoRA.

1 Giới thiệu
Tiền huấn luyện/tinh chỉnh đã trở thành một mô hình phổ biến để giải quyết nhiều nhiệm vụ trong xử lý ngôn ngữ tự nhiên (NLP) (Devlin et al., 2018; Liu et al., 2019; Brown et al., 2020) và Thị giác máy tính (Simonyan and Zisserman, 2014; He et al., 2016; Howard et al., 2019; Bochkovskiy et al., 2020; Chen et al., 2020; Dosovitskiy et al., 2020). Các mô hình được huấn luyện trước (PM) như các mô hình ngôn ngữ được huấn luyện trước (PLM) (Devlin et al., 2018; Brown et al., 2020), và các mô hình thị giác-ngôn ngữ được huấn luyện trước (Lu et al., 2019; Li et al., 2019; Su et al., 2019; Xia et al., 2021) đã tiến bộ rất nhiều trong những năm gần đây. Với kích thước ngày càng tăng của các mô hình được huấn luyện trước này, việc tinh chỉnh chúng trên các nhiệm vụ hạ nguồn trở nên đắt đỏ hơn. Hơn nữa, khi tỷ lệ số lượng tham số của các mô hình so với dữ liệu được gán nhãn tăng lên, quá trình tinh chỉnh sẽ dễ bị overfitting hơn (Karimi Mahabadi et al., 2021). Có hai loại giải pháp: thứ nhất, nén mô hình (Jafari et al., 2021; Chen et al., 2021); thứ hai, điều chỉnh hiệu quả tham số (PET) (Houlsby et al., 2019a; Karimi Mahabadi et al., 2021; Mao et al., 2021).

Có nhiều kỹ thuật nén mô hình khác nhau trong tài liệu cho các mô hình dựa trên Transformer như phân tích ma trận (Noach and Goldberg, 2020; Tahaei et al., 2021), cắt tỉa (Wang et al., 2019), lượng tử hóa (Tao et al., 2022; Prato et al., 2020), và chưng cất tri thức (Hinton et al., 2015; Li et al., 2021; Jafari et al., 2021; Passban et al., 2021; Rashid et al., 2021). Cũng có các loại kỹ thuật PET khác nhau trong tài liệu như các bộ chuyển đổi thứ hạng thấp (Wang et al., 2020; Karimi Mahabadi et al., 2021; Houlsby et al., 2019b; Hu et al., 2021b), và các kỹ thuật dựa trên prompt (Lester et al., 2021).

Mặc dù các giải pháp nén mô hình được thiết lập tốt trong những năm gần đây trong tài liệu, việc áp dụng chúng cho các mô hình ngôn ngữ lớn có thể rất tốn kém, vì các kỹ thuật nén thường cần huấn luyện (hoặc tinh chỉnh) mô hình lớn ban đầu. Một trường hợp điển hình là chưng cất tri thức dựa trên việc tinh chỉnh một mô hình giáo viên lớn hoặc thậm chí tiền huấn luyện mô hình học sinh như được đề xuất trong (Jiao et al., 2019). Hơn nữa, việc sử dụng các kỹ thuật nén thường dẫn đến giảm hiệu suất mô hình. PET có thể là giải pháp thay thế cho các phương pháp nén, đặc biệt là khi chúng ta muốn sử dụng toàn bộ khả năng của các mô hình được huấn luyện trước lớn với nỗ lực huấn luyện nhẹ (như kịch bản mô hình ngôn ngữ như dịch vụ (Sun et al., 2022)).

--- TRANG 2 ---
Trọng số được 
huấn luyện trước 
cố định
DyLoRA Cập nhật tham số Truyền tiếpHình 1: DyLoRA: Sơ đồ tổng thể của phương pháp được đề xuất. Trong mỗi lần lặp, chúng tôi lấy mẫu từ một phân phối ngẫu nhiên được xác định trước sẽ giúp chúng tôi cắt ngắn các ma trận chiếu lên và chiếu xuống trong mục tiêu LoRA (Hu et al., 2021a).

Trong số các kỹ thuật PET, các bộ chuyển đổi thứ hạng thấp đã nhận được nhiều sự chú ý vì, trái ngược với các kỹ thuật điều chỉnh prompt, các bộ chuyển đổi thứ hạng thấp không thêm vào độ dài chuỗi, được huấn luyện nhanh hơn và hoạt động tốt hơn (Karimi Mahabadi et al., 2021). Mặc dù có nhiều kỹ thuật thích ứng thứ hạng thấp trong tài liệu, như Adapter (Houlsby et al., 2019b), Compacter (Karimi Mahabadi et al., 2021), và LoRA (Hu et al., 2021b); tất cả chúng đều gặp phải hai vấn đề chung lớn: thứ nhất, không rõ cách chọn kích thước thứ hạng của chúng (trong khi hiệu suất của chúng rất nhạy cảm với việc lựa chọn thứ hạng này); thứ hai, việc huấn luyện của chúng là tĩnh có nghĩa là nếu một mô hình thứ hạng thấp được huấn luyện dựa trên một kích thước thứ hạng cụ thể, nó sẽ không hoạt động tốt ở các giá trị thứ hạng khác (tức là cho bất kỳ giá trị thứ hạng nào khác, chúng ta cần huấn luyện một mô hình riêng biệt).

Bài báo này đề xuất một kỹ thuật bộ chuyển đổi thứ hạng thấp động (DyLoRA) để giải quyết hai vấn đề này. Không mất tính tổng quát, chúng tôi tập trung vào LoRA (Hu et al., 2021a) và huấn luyện các khối LoRA cho một phạm vi thứ hạng thay vì một thứ hạng duy nhất bằng cách sắp xếp biểu diễn được học tại các thứ hạng khác nhau trong quá trình huấn luyện. Trong khi mô hình của chúng tôi linh hoạt hơn, nó có thể vượt trội hơn LoRA trong phạm vi thứ hạng rộng hơn nhiều mà không thêm vào thời gian huấn luyện. Hơn nữa, kỹ thuật của chúng tôi không cần huấn luyện thêm để tìm kiếm qua các thứ hạng. Chúng tôi tóm tắt những đóng góp của mình như sau:

• LoRA động: Trên cơ sở LoRA, chúng tôi đã phát triển một thuật toán mới (DyLoRA) làm cho nó động tại thời gian suy luận mà không phát sinh chi phí thêm.

• LoRA không cần tìm kiếm: Chúng tôi chứng minh rằng bằng cách thỏa hiệp không đáng kể về hiệu suất, có thể tránh được quá trình tìm kiếm tốn kém để chọn thứ hạng tối ưu cho LoRA.

2 Công trình liên quan
Phần này xem xét các kỹ thuật thích ứng thứ hạng thấp cho điều chỉnh hiệu quả tham số và các giải pháp tiềm năng hiện có để làm cho các kỹ thuật này trở nên động và không cần tìm kiếm.

Đã được chứng minh trong (Aghajanyan et al., 2020) rằng đối với các nhiệm vụ phân loại như hiểu ngôn ngữ tự nhiên (NLU), PLM có chiều hướng nội tại thấp. Quan sát này thúc đẩy việc sử dụng các bộ chuyển đổi thứ hạng thấp cho điều chỉnh hiệu quả tham số. Có nhiều bộ chuyển đổi thứ hạng thấp trong tài liệu như LoRA (Hu et al., 2021b), Adapter (Houlsby et al., 2019b), Compacter (Karimi Mahabadi et al., 2021), và Parallel Adapter (PA) (He et al., 2021).

LoRA là một phép biến đổi chiếu lên/chiếu xuống thứ hạng thấp không có tính phi tuyến nào được áp dụng song song với các ma trận attention key và value. Lợi ích chính của LoRA là mô-đun bộ chuyển đổi, sau khi huấn luyện, có thể được tích hợp vào các ma trận trọng số ban đầu của mô hình, điều này có thể dẫn đến thời gian suy luận rất hiệu quả. Adapter cũng có một phép biến đổi chiếu lên/chiếu xuống thứ hạng thấp với tính phi tuyến trung gian.

--- TRANG 3 ---
Mô-đun Adapter được áp dụng nối tiếp với mạng feed-forward (FFN). Việc có mô-đun bộ chuyển đổi nằm cùng hàng với các khối khác trong mô hình có thể tăng thời gian suy luận của mô hình. PA là một phiên bản nhanh hơn của Adapter, có thể được áp dụng song song với khối FFN. Compactor là một phiên bản hiệu quả bộ nhớ hơn của Adapter, sử dụng tổng các tích Kronecker để tái tạo mỗi ma trận chiếu lên và chiếu xuống. Tất cả các bộ chuyển đổi thứ hạng thấp này đều gặp phải hai vấn đề chính: thứ nhất, tìm thứ hạng tốt nhất đòi hỏi huấn luyện và tìm kiếm toàn diện nặng nề; thứ hai, mô-đun bộ chuyển đổi được điều chỉnh chỉ hoạt động tốt với một thứ hạng cụ thể.

Mặc dù đã có một số nỗ lực trong tài liệu hướng tới các mạng động như DynaBERT (Hou et al., 2020) và GradMax (Evci et al., 2022), theo hiểu biết tốt nhất của chúng tôi, vấn đề này đối với các mạng phân tách và các bộ chuyển đổi thứ hạng thấp vẫn chưa được giải quyết. DRONE (Chen et al., 2021) đề xuất một kỹ thuật cho nén mô hình thứ hạng thấp nhận biết dữ liệu tuy nhiên cách tiếp cận của họ không phải không cần tìm kiếm, và cũng không động. DynaBERT giới thiệu một phương pháp hai giai đoạn để huấn luyện các mạng động theo chiều rộng và chiều sâu. Tuy nhiên, DynaBERT yêu cầu một mô hình giáo viên được tinh chỉnh trên nhiệm vụ để huấn luyện các mạng con của nó, điều này làm cho nó không phù hợp cho các kỹ thuật PET. GradMax là một kỹ thuật dần dần thêm vào các neuron của mạng mà không chạm vào các neuron đã được huấn luyện. Nhưng không rõ cách GradMax có thể được triển khai để giảm bớt vấn đề tìm kiếm thứ hạng trong các bộ chuyển đổi thứ hạng thấp. Wang et al. (2019) đề xuất một kỹ thuật cắt tỉa có cấu trúc được gọi là cắt tỉa thứ hạng thấp phân tách (FLOP). FLOP phân tách các ma trận trọng số của mạng thành tổng các thành phần thứ hạng-1, được điều chỉnh trong quá trình huấn luyện để có được tính thưa thớt. Đáng chú ý là FLOP nhằm mục đích nén mô hình chính, và thậm chí nếu nó có thể được sử dụng để tìm một thứ hạng tốt trong biểu diễn thứ hạng thấp hơn của các ma trận trọng số đầy đủ, mô hình thứ hạng thấp cuối cùng sẽ không động (tức là nó chỉ được huấn luyện tốt cho một thứ hạng chứ không phải một phạm vi thứ hạng, giống như LoRA.). Trong bài báo này, chúng tôi đề xuất một phương pháp mới để huấn luyện các mô-đun thứ hạng thấp cho nhiều thứ hạng đồng thời thay vì huấn luyện một bộ chuyển đổi thứ hạng đơn lẻ tại một thời điểm (mà không thay đổi ngân sách huấn luyện). Lấy cảm hứng từ ý tưởng của nested dropout (Rippel et al., 2014), chúng tôi theo đuổi việc sắp xếp các biểu diễn của nút thắt cổ chai tại các mô-đun bộ chuyển đổi thứ hạng thấp với một công thức mới. Theo hiểu biết tốt nhất của chúng tôi, đây là lần đầu tiên khái niệm sắp xếp biểu diễn được triển khai trong huấn luyện PLM.

3 Nền tảng
3.1 Nested Dropout
Lấy cảm hứng từ dropout (Hinton et al., 2012), nested dropout (Rippel et al., 2014) là một kỹ thuật điều chỉnh ngẫu nhiên nhằm mục đích thực thi các biểu diễn có thứ tự trong huấn luyện auto-encoder. Nested dropout thêm một bias ngầm (không tồn tại trong dropout) để ưu tiên thứ tự trong huấn luyện. Ví dụ, trong dropout, chúng ta có thể ngẫu nhiên loại bỏ bất kỳ nút hoặc đơn vị nào trong mạng, nhưng trong nested dropout, nếu chúng ta ngẫu nhiên chọn đơn vị thứ k, thì chúng ta giữ tất cả các đơn vị được lập chỉ mục từ 1 đến k và loại bỏ các đơn vị có chỉ số lớn hơn k. Do đó, nested dropout có xu hướng chứa thông tin quan trọng hơn trong các chỉ số thấp hơn trong khi học biểu diễn.

Theo các ký hiệu của (Rippel et al., 2014), nested dropout giả định một ánh xạ auto-encoder của N mẫu huấn luyện {yi}N i=1 ∈ Y, Y ∈ RD thành các biểu diễn tương ứng {xi}N i=1 ∈ X, X ∈ RK sử dụng hàm f: Y → X với tham số θ; và sau đó giải mã các biểu diễn này bằng một hàm khác g: X → Y với tham số φ để tái tạo đầu vào. Mất mát tái tạo có thể được định nghĩa như sau:

C(θ, φ) = ∑N i=1 ||yi - g(f(yi))||². (1)

Giả sử chúng ta muốn ngẫu nhiên loại bỏ một số đơn vị trong vector biểu diễn x của chúng ta. Trong vấn đề này, chúng ta lấy mẫu một biến ngẫu nhiên b ~ pB(·); b ∈ {1, 2, ..., K} từ một phân phối phân loại được xác định trước pB(·) và cắt ngắn các hàm f và g để giữ các đơn vị tương ứng được lập chỉ mục từ 1 đến b và loại bỏ các chỉ số b+1 đến K. Hãy định nghĩa phiên bản cắt ngắn b của vector x là x#b và phiên bản cắt ngắn b của các hàm f và g là f#b và g#b tương ứng. Trong trường hợp này, mất mát tái tạo được định nghĩa lại cho mô hình cắt ngắn b như sau:

C(θ, φ) = EpB[C#b(θ, φ)] = ∑K b=1 pB(b)C#b(θ, φ)

trong đó
C#b(θ, φ) = ∑N i=1 ||yi - g#b(f#b(yi))||².
(2)

--- TRANG 4 ---
Trong giai đoạn cuối, các tham số của mô hình này có thể được thu được bằng cách giải quyết vấn đề tối ưu hóa sau:

(θ*, φ*) = argmin θ,φ C(θ, φ). (3)

Mặc dù công việc của chúng tôi trong bài báo này được lấy cảm hứng từ tính năng sắp xếp thông tin được đề xuất trong nested dropout, chúng tôi có thể phân biệt công việc của mình với nested dropout trong một số khía cạnh:

1. Kỹ thuật nested dropout được sử dụng để thêm thông tin thứ tự vào một biểu diễn vector; tuy nhiên, chúng tôi đang thêm thông tin thứ tự vào phân tách ma trận thứ hạng thấp để làm cho nó hoạt động trên một phạm vi thứ hạng thay vì một thứ hạng duy nhất.

2. Thuật toán huấn luyện của chúng tôi khác với nested dropout trong việc lựa chọn hàm phân phối pB(·), và chúng tôi đề xuất một mất mát cá nhân hiệu quả hơn cho mỗi ma trận cắt ngắn so với mất mát tổng tuyến tính (kiểm tra các phương trình 2 và 11 trong bài báo gốc (Rippel et al., 2014)) trong nested dropout. Đề xuất ban đầu cho nested dropout là sử dụng một batch với các ví dụ cắt ngắn hỗn hợp. Để tăng hiệu quả và giải quyết tính không tối ưu, chúng tôi đề xuất cố định việc cắt ngắn trong toàn bộ batch như một phần của cách tiếp cận của chúng tôi.

3.2 LoRA: Bộ chuyển đổi thứ hạng thấp
Trong LoRA (Hu et al., 2021a), một số trọng số được huấn luyện trước của các lớp dày đặc của PLM được cộng với các mô-đun bộ chuyển đổi tuyến tính thứ hạng thấp song song. Trong quá trình tinh chỉnh, các trọng số được huấn luyện trước ban đầu được giữ cố định; thay vào đó, các mô-đun LoRA có thể được cập nhật. Ví dụ, giả sử W0 ∈ Rm×d là một ma trận trọng số được huấn luyện trước trong mạng được đi kèm với một mô-đun LoRA ΔW = WupWdw trong đó Wup ∈ Rm×r, Wdw ∈ Rr×d, và r ≪ min(m, d). Khi đó, đầu ra của lớp này có thể được tính như sau:

h = W0x + ΔWx = W0x + αWupWdwx. (4)

Lưu ý rằng ma trận Wup được khởi tạo là ma trận zero, và ma trận Wdw được khởi tạo là phân phối Gaussian có trung bình zero trong đó α là một hằng số tỷ lệ siêu tham số.

Trong LoRA, thứ hạng r là một siêu tham số cần được điều chỉnh cho từng nhiệm vụ. Hơn nữa, LoRA là một bộ chuyển đổi thứ hạng thấp tĩnh chỉ hoạt động với một kích thước cụ thể của r, đã được huấn luyện trên nó.

4 Phương pháp của chúng tôi: DyLoRA
Trong phần này, chúng tôi giới thiệu giải pháp của mình để có được các bộ chuyển đổi thứ hạng thấp động có thể được huấn luyện và triển khai tốt trên một phạm vi thứ hạng thay vì một thứ hạng cụ thể (với ngân sách huấn luyện cố định). Tính linh hoạt này có thể giải phóng chúng ta khỏi việc tìm kiếm thứ hạng tốt nhất bằng cách huấn luyện mô hình nhiều lần.

Không mất tính tổng quát, chúng tôi giải thích giải pháp của mình trên cơ sở LoRA như một trong những kỹ thuật bộ chuyển đổi thứ hạng thấp nổi bật trong tài liệu. Trong mỗi mô-đun LoRA, chúng ta có một ma trận chiếu lên (Wup ∈ Rm×r) và một ma trận chiếu xuống (Wdw ∈ Rr×d). Giả sử rằng chúng ta muốn huấn luyện mô-đun LoRA để hoạt động trong phạm vi r ∈ Range [rmin, rmax] trong đó rmin và rmax có thể được coi là các siêu tham số mới. Để làm cho mô-đun LoRA hoạt động trong một phạm vi thứ hạng thay vì một thứ hạng duy nhất, chúng ta cần đảm bảo rằng việc tăng hoặc giảm thứ hạng sẽ không làm giảm đáng kể hiệu suất của mô hình. Một cách để thực hiện hành vi như vậy sẽ là bằng cách sắp xếp nội dung thông tin của các thứ hạng khác nhau trong quá trình huấn luyện các mô-đun LoRA. Trong vấn đề này, tại mỗi bước huấn luyện, chúng ta lấy mẫu b ~ pB(·); b ∈ {rmin, rmin + 1, ..., rmax} từ một phân phối phân loại được xác định trước (có hỗ trợ trong Range [rmin, rmax]) và cắt ngắn ma trận Wdw và Wup tương ứng.

Wdw#b = Wdw[1 : b, :]
Wup#b = Wup[:, 1 : b] (5)

Wdw#b và Wup#b là các phiên bản cắt ngắn b của Wdw và Wup tương ứng (xem Hình 1 để trực quan hóa). Hơn nữa, hãy định nghĩa Wbdw là hàng thứ b của Wdw; Wbup tương ứng với cột thứ b của Wup.

Wbdw = Wdw[b, :]
Wbup = Wup[:, b] (6)

Khi đó, lượt truyền tiến của mô-đun LoRA cắt ngắn này trong quá trình huấn luyện sẽ được tính như sau:

h = W0x + αWup#bWdw#bx (7)

Để đơn giản, giả sử chúng ta chỉ có một mô-đun LoRA trong mạng (cái được mô tả trong Phương trình 7). Trước tiên, hãy xem xét hàm mất mát tĩnh thông thường (LS) của mạng f(x; Wdw, Wup) với Wdw và Wup là các tham số có thể điều chỉnh cho N cặp đầu vào-đầu ra đã cho (x, y) = (xi, yi)N i=1:

min Wdw,Wup LS(x, y; Wdw, Wup) ≜ ∑N i=1 l(f(xi; Wdw, Wup), yi). (8)

trong đó l(f, y) là một hàm mất mát đo lường sự phân kỳ của các dự đoán mạng so với các nhãn mục tiêu. Sau đó, hãy mở rộng mất mát huấn luyện để làm cho mạng trở nên động xem xét quá trình cắt ngắn b. Chúng ta có thể định nghĩa hàm mất mát động LDY của chúng ta như sau:

LDY #b = ∑N i=1 l(f(xi; Wdw#b, Wup#b), yi). (9)

Lưu ý rằng, hàm mất mát của chúng ta có sự khác biệt lớn so với mất mát nested dropout, điều này làm cho nó hiệu quả hơn. Mất mát nested dropout có dạng ∑rmax b=rmin pB(b)LDY #b(x, y; Wdw#b, Wup#b) đòi hỏi tổng mất mát trên toàn bộ phạm vi thứ hạng có thể và nó tốn kém về mặt tính toán. Để vượt qua hạn chế tính toán này, chúng tôi thay thế nó bằng việc tối ưu hóa các tham số mô hình cho từng thứ hạng mục tiêu riêng lẻ tại mỗi bước thời gian. Chúng tôi cho thấy rằng sơ đồ này hoạt động khá tốt.

Sự khác biệt khác với nested dropout là trong giai đoạn cập nhật tham số, chúng tôi thêm một chế độ mới (được gọi là frozen) như một siêu tham số vào quá trình huấn luyện của chúng tôi. Chế độ mới này đề xuất chỉ cập nhật hàng và cột thứ b tương ứng được lấy mẫu trong giai đoạn cắt ngắn (tức là một hàng hoặc cột duy nhất sẽ được cập nhật tại một thời điểm để ngăn các tham số học không bị quên ở các bước thời gian trước.). Với chi phí hiệu suất nhỏ, cách tiếp cận này có thể cải thiện hiệu quả của thuật toán của chúng tôi hơn nữa.

Wbdw ← Wbdw - η∇WbdwLDY #b
Wbup ← Wbup - η∇WbupLDY #b (10)

Bảng 4 cho thấy tác động của việc chỉ cập nhật "b" so với việc cập nhật các cột và hàng từ 1 đến b. Tóm tắt kỹ thuật của chúng tôi được mô tả trong Thuật toán 1.

5 Thí nghiệm
Trong phần này, chúng tôi mô tả các thí nghiệm được sử dụng để đánh giá mô hình DyLoRA của chúng tôi trên cả nhiệm vụ hiểu ngôn ngữ tự nhiên (NLU) và nhiệm vụ tạo ngôn ngữ tự nhiên (NLG).

Thuật toán 1 DyLoRA - Huấn luyện
Yêu cầu:
r ∈ Range[rmin, rmax]; i: số lần lặp huấn luyện; α: hệ số tỷ lệ; pB: hàm phân phối xác suất cho việc lựa chọn thứ hạng; X ∈ Rd×n: tất cả các đặc trưng đầu vào cho LORA; W0 ∈ Rm×d ma trận trọng số được huấn luyện trước ban đầu đã cố định

Yêu cầu: Wdw ∈ Rr×d; Wup ∈ Rm×r, FROZEN: có giữ các thứ hạng thấp hơn cố định khi cập nhật các thứ hạng cao hơn hay không

while t < i do:
    Truyền tiến:
    // lấy mẫu một thứ hạng cụ thể, trong quá trình kiểm tra được đưa ra
    b ~ pB(·)
    // cắt ngắn ma trận chiếu xuống
    Wdw#b = Wdw[:b, :]
    Wbdw = Wdw[b, :]
    // cắt ngắn ma trận chiếu lên
    Wup#b = Wup[:, :b]
    Wbup = Wup[:, b]
    // tính đầu ra LoRA
    h = W0X + αWup#bWdw#bX
    
    Truyền ngược:
    if FROZEN then
        // chỉ cập nhật các tham số duy nhất
        // của thứ hạng đã chọn
        Wbdw ← Wbdw - η∇WbdwLDY #b
        Wbup ← Wbup - η∇WbupLDY #b
    else
        Wdw#b ← Wdw#b - η∇Wdw#bLDY #b
        Wup#b ← Wup#b - η∇Wup#bLDY #b
    end if
end while

Để công bằng với phương pháp LoRA ban đầu, chúng tôi cố gắng giữ cài đặt thí nghiệm của mình tương tự như bài báo LoRA (Hu et al., 2021a). Do đó, tương tự, chúng tôi đã chọn mô hình RoBERTa (Liu et al., 2019) base được huấn luyện trước làm xương sống của các thí nghiệm LoRA và DyLoRA cho benchmark GLUE (Development Set), và GPT-Medium cho các nhiệm vụ NLG. Đối với các thí nghiệm của chúng tôi, chúng tôi không sử dụng bất kỳ điều chỉnh siêu tham số nào, cũng không tìm kiếm các epoch xác thực, cũng không sử dụng thủ thuật MLNI (sử dụng checkpoint MLNI thay vì trọng số được huấn luyện trước) để tăng hiệu suất của mô hình. Thông tin chi tiết hơn về các siêu tham số có sẵn trong Bảng 8 ở Phụ lục B. Tổng cộng, chúng tôi đã tiến hành hơn 200 thí nghiệm và đánh giá hơn 1600 mô hình, chi tiết

--- TRANG 5 ---
Mô hình: RoBERTa-Base
Nhiệm vụ Thứ hạng=1 Thứ hạng=2 Thứ hạng=4 Thứ hạng=8 Thứ hạng=16 Thứ hạng=32
QQP (Độ chính xác) 89.14 89.96 90.33 90.69 90.95 91.02
SST-2 (Độ chính xác) 93.58 94.15 94.38 94.84 94.27 94.5
MRPC (Độ chính xác) 87.25 87.75 88.24 87.25 86.76 89.22
CoLA (Mathews) 61.84 57.78 61.57 63.81 63.07 62.82

Bảng 1: Tác động của thứ hạng của ma trận thích ứng thứ hạng thấp đối với hiệu suất của mô hình. Trong thí nghiệm này, tất cả các siêu tham số khác được cố định, và chúng tôi chỉ thay đổi thứ hạng của mô hình LoRA. Trong không gian tìm kiếm này, gạch chân cho thấy thứ hạng hiệu suất tối thiểu, và số in đậm cho thấy thứ hạng hiệu suất tối đa.

[Tiếp theo là bảng 2 với dữ liệu so sánh chi tiết giữa LoRA và DyLoRA ở các thứ hạng khác nhau]

Bảng 2: Trong bảng này, nhiệm vụ là tìm một ma trận thích ứng thứ hạng thấp hoạt động với các thứ hạng khác nhau tại thời gian suy luận với ngân sách cố định (thời gian huấn luyện).

có thể được tìm thấy trong các tệp đính kèm.

5.1 Baseline
• Tinh chỉnh: Để cho thấy một giới hạn trên tương đối cho hiệu suất của phương pháp được đề xuất, chúng tôi đã tinh chỉnh tất cả các tham số trong mô hình. Mặc dù chúng tôi có một số lượng lớn tham số có thể huấn luyện, điều này có thể giúp chúng tôi hiểu rõ hơn về cách các mô hình thứ hạng cao hoạt động.

• LoRA: Làm baseline cho DyLoRA, chúng tôi sử dụng mô hình LoRA ban đầu với các siêu tham số đã được điều chỉnh của họ (Hu et al., 2021a). Kết quả là, hầu hết các thí nghiệm đã được tiến hành theo cách có lợi cho LoRA.

--- TRANG 6 ---
Độ chính xác Độ chính xác F1 Mathews Độ chính xác Độ chính xác Độ chính xác Pearson
Mô hình MNLI SST-2 MRPC CoLA QNLI QQP RTE STS-B Trung bình

[Bảng dữ liệu chi tiết về hiệu suất của các mô hình LoRA và DyLoRA với các thứ hạng khác nhau]

Bảng 3: Bảng này so sánh DyLoRA với các thuật toán dựa trên nén. Như được chỉ ra bởi *, chúng tôi báo cáo "Tinh chỉnh" và FLOP từ các bài báo gốc của họ, (Liu et al., 2019) và (Wang et al., 2019). Theo hiểu biết tốt nhất của chúng tôi, các thí nghiệm được tiến hành trong cùng một cài đặt thí nghiệm. Chúng tôi đếm tất cả các tham số có thể huấn luyện bao gồm bộ phân loại, không giống như bài báo LoRA (Hu et al., 2021a) mà họ chỉ đếm các tham số cụ thể của LoRA.

• FLOP: Do tính linh hoạt của nó, Factorized Low Rank Pruning (FLOP) (Wang et al., 2019) có thể được áp dụng cho bất kỳ phép nhân ma trận nào và do đó có thể được sử dụng để tránh tìm kiếm trong vấn đề của chúng tôi. Tuy nhiên, baseline này thiếu các thuộc tính động của DyLoRA. Chúng tôi sử dụng nó để cho thấy hiệu suất và ưu nhược điểm của các kỹ thuật dựa trên điều chỉnh.

5.2 Vấn đề lựa chọn thứ hạng LoRA
Không có hướng dẫn rõ ràng về cách xác định thứ hạng cho thuật toán LoRA. Rõ ràng trong bài báo LoRA (Hu et al., 2021a) rằng hiệu suất của các mô hình thay đổi rất nhiều với các thứ hạng khác nhau (ví dụ kiểm tra Bảng 15 và 18 trong bài báo LoRA), và không chỉ ra bất kỳ xu hướng rõ ràng nào. Chúng tôi cũng quan sát thấy vấn đề tương tự trong benchmark GLUE. Chúng ta có thể lập luận rằng về mặt lý thuyết, thứ hạng với hiệu suất tốt nhất luôn là cao nhất. Tuy nhiên, các thứ hạng cao giới thiệu thêm tham số vào quá trình thích ứng và điều này có thể không mong muốn. Trên thực tế, như được chứng minh trong Bảng 1, thứ hạng hiệu quả nhất khác nhau tùy thuộc vào nhiệm vụ. Ví dụ, dựa trên kết quả MRPC, thứ hạng với hiệu suất thấp nhất là 16 trong khi thứ hạng với hiệu suất cao nhất là 32. Điều này khác với SST-2, trong đó thứ hạng 1 là thứ hạng hoạt động kém nhất và thứ hạng 8 là thứ hạng hiệu quả nhất. Nhiều yếu tố có thể đóng góp vào sự khác biệt này, bao gồm nhưng không giới hạn ở kích thước của tập dữ liệu, lựa chọn siêu tham số, cấu hình phần cứng và tối ưu hóa.

5.3 Thích ứng thứ hạng thấp động
Ví dụ, giả sử chúng ta có một mạng thần kinh mà chúng ta muốn triển khai trên các thiết bị khác nhau với các cấu hình khác nhau. Việc sử dụng các thứ hạng cao hơn có thể gây ra vấn đề cho các thiết bị rất nhạy cảm vì chúng có số lượng tham số lớn hơn. Do đó, chúng ta phải huấn luyện nhiều mô hình với các cấu hình khác nhau hoặc tìm thứ hạng tối ưu nhất. Chi phí liên quan đến điều này là đáng kể, vì ngay cả trong cài đặt của LoRA, chúng ta cần tìm thứ hạng tốt nhất cho từng nhiệm vụ và từng thiết bị. Tuy nhiên, sử dụng DyLoRA, người ta chỉ cần huấn luyện một mô hình cho mỗi nhiệm vụ và, vì phương pháp của chúng tôi thích ứng tại thời gian suy luận, chúng ta có thể triển khai nó theo nhu cầu của mình. Trong Bảng 2, chúng tôi chứng minh các thuộc tính động của DyLoRA. Để đảm bảo so sánh công bằng, tất cả các mô hình LoRA và DyLoRA trong bảng này có cùng kích thước mô hình, chúng tôi đã sử dụng cùng mã và quá trình đánh giá, và tất cả các mô hình đều được huấn luyện ở mức độ tương tự. Trong LoRA, chúng ta mất hiệu suất khi thực hiện suy luận cho các thứ hạng thấp hơn. Điều này xảy ra vì mô hình chỉ được huấn luyện cho thứ hạng 8 trong quá trình huấn luyện. Trong DyLoRA, chúng ta duy trì mức hiệu suất cao cho các thứ hạng thấp hơn trong khi cạnh tranh tốt với LoRA ở thứ hạng 8.

[Tiếp theo là các bảng và phân tích chi tiết khác]

--- TRANG 7 ---
[Bảng 4 về nghiên cứu loại bỏ và Bảng 5 về thời gian tìm kiếm]

5.4 Thích ứng thứ hạng thấp không cần tìm kiếm
Quá trình lựa chọn một thứ hạng cụ thể có thể tốn kém như đã đề cập trước đó. Trong Bảng 5, chúng tôi trình bày một thí nghiệm minh họa chi phí liên quan đến việc tìm kiếm như vậy cho LoRA và DyLoRA. Ví dụ, nếu ai đó muốn tìm kiếm toàn bộ phạm vi thứ hạng một cách ngây thơ (ví dụ, 64 trong thí nghiệm), thì họ sẽ phải huấn luyện và đánh giá 64 mô hình riêng biệt để xác định thứ hạng phù hợp. Nó trở nên tốn kém hơn nếu người ta tìm kiếm toàn bộ không gian thứ hạng. Trong trường hợp tìm kiếm đồng nhất, chi phí này ít hơn, nhưng vẫn đắt hơn (7 lần trong thí nghiệm) so với phương pháp được đề xuất của chúng tôi. Do đó, đối với LoRA (Search), chúng tôi đã chạy thí nghiệm cho các thứ hạng=1,2,4,8,16,32,64 và chúng tôi báo cáo kết quả tốt nhất. Kết quả cho thấy phương pháp được đề xuất của chúng tôi hoạt động cạnh tranh với chi phí thấp hơn nhiều.

5.5 Tính bền vững của DyLoRA
Như được minh họa trong Bảng 2, DyLoRA khá bền vững đối với tính ngẫu nhiên và có thể tạo ra kết quả tốt nhất quán do sự hội tụ ổn định.

5.6 Điều chỉnh và Cắt tỉa
Một phương pháp thay thế để tránh vấn đề tìm kiếm là sử dụng các kỹ thuật điều chỉnh/cắt tỉa để xác định thứ hạng nội tại của ma trận trọng số. Bằng cách này, chúng ta có thể giảm số lượng tham số của các ma trận ban đầu; tuy nhiên, chúng ta sẽ không có mô hình động trong quá trình suy luận. Để minh họa sự khác biệt giữa các phương pháp như vậy và DyLoRA, chúng tôi báo cáo hiệu suất của một trong những mô hình này, FLOP (Wang et al., 2019), trong Bảng 3. FLOP sử dụng phân tích thứ hạng thấp để tạo ra các ma trận mới đại diện cho ma trận trọng số ban đầu. Do đó, chúng sẽ có ít tham số tổng hơn nhưng yêu cầu nhiều tham số có thể huấn luyện hơn để đạt được hiệu suất tương đương với DyLoRA.

5.7 Nhiệm vụ tạo sinh
Trong thí nghiệm này, chúng tôi đánh giá hiệu suất của mô hình trên các nhiệm vụ tạo ngôn ngữ tự nhiên (NLG) khác nhau như E2E NLG Challenge (Novikova et al., 2017), DART (Nan et al., 2020) và WebNLG (Gardent et al., 2017). Kết quả của nhiệm vụ E2E được hiển thị trong Bảng 6 và do hạn chế về không gian, kết quả của hai nhiệm vụ khác được trình bày trong Phụ lục C. Các nhiệm vụ tạo sinh cho thấy một mô hình tương tự như nhiệm vụ NLU, cho thấy mô hình của chúng tôi có thể hoạt động tốt trong phạm vi thứ hạng rộng hơn so với LoRA.

5.8 Nghiên cứu loại bỏ
Trong phần phụ này, chúng tôi điều tra tác động của hai lựa chọn thiết kế trong DyLoRA: thứ nhất, siêu tham số phân phối PB mới trong kỹ thuật của chúng tôi; thứ hai, tác động của việc cập nhật các tham số Wbdw và Wbup thay vì toàn bộ Wdw#b và Wup#b. Phân phối PB thay đổi tầm quan trọng tương đối của các thứ hạng khác nhau trong quá trình huấn luyện. Để kiểm tra tác động của phân phối được chọn đối với hiệu suất của DyLoRA, chúng tôi đã sử dụng hai phân phối, hình học và đồng nhất. Như được hiển thị trong Bảng 4, phân phối hình học cung cấp một phương pháp tốt hơn nhiều để tối ưu hóa các thứ hạng thấp hơn, vì nó chú ý nhiều hơn đến các thứ hạng thấp hơn trong quá trình huấn luyện, và phân phối đồng nhất sẽ cho hiệu suất tốt hơn trên tất cả các thứ hạng. Chúng tôi chọn sử dụng phân phối đồng nhất trong hầu hết các thí nghiệm của mình để tránh thêm một siêu tham số khác là yêu cầu của phân phối hình học. Hơn nữa, chúng tôi chứng minh rằng có thể đảm bảo việc tối ưu hóa thứ hạng b sẽ không ảnh hưởng tiêu cực đến hiệu suất của các thứ hạng thấp hơn (1 đến b-1), trong khi hoạt động một cách hợp lý. Như đã đề cập, điều này có thể được thực hiện bằng cách chỉ cập nhật các tham số duy nhất liên quan đến thứ hạng r không trùng lặp với các thứ hạng thấp hơn.

Ngoài ra, trong Bảng 7, chúng tôi chứng minh kết quả của việc sử dụng mất mát cá nhân của chúng tôi (Phương trình 9) so với hàm mục tiêu ban đầu của nested dropout trong một cài đặt bình đẳng. Như được hiển thị, hàm mục tiêu được đề xuất của chúng tôi vừa hiệu quả vừa hữu ích. Hơn nữa, điều quan trọng cần lưu ý là mất mát tổng không thể mở rộng khi có nhiều thứ hạng tham gia. Chúng tôi cũng thảo luận về độ phức tạp thời gian của LoRA và DyLoRA trong Phụ lục A.

[Bảng 6 về kết quả E2E NLG Challenge]

--- TRANG 8 ---
[Bảng 7 về so sánh hàm mất mát]

6 Kết luận
Trong bài báo này, chúng tôi đã trình bày giải pháp DyLoRA của mình để giải quyết hai vấn đề trong các bộ chuyển đổi thứ hạng thấp liên quan đến lựa chọn thứ hạng và làm cho chúng trở nên động. Chúng tôi đã chỉ ra rằng DyLoRA có thể chọn thứ hạng mà không cần huấn luyện lại nhiều lần và có thể làm cho LoRA trở nên động tại thời gian suy luận. Kết quả là, chúng ta có thể tránh được quá trình tìm kiếm thứ hạng tối ưu cho nhiều kịch bản thực tế. Đã được chứng minh rằng hiệu suất DyLoRA tương đương với LoRA, nhưng chúng ta có thể hỗ trợ phạm vi thứ hạng rộng hơn mà không thêm thời gian và nỗ lực bổ sung.

Hạn chế
Theo LoRA (Hu et al., 2021a), một lựa chọn phù hợp của vô hướng α có thể cải thiện kết quả. Để xác định lựa chọn tốt nhất là gì, cần có thêm nghiên cứu. Mặc dù chúng tôi đã chứng minh rằng phân phối đồng nhất có thể hiệu quả như phân phối hình học cụ thể, cần có thêm nghiên cứu để đánh giá tác động của các phân phối khác nhau đối với các nhiệm vụ hạ nguồn khác nhau. Như được hiển thị trong bài báo này, thuật toán của chúng tôi hoạt động trên phạm vi thứ hạng rộng, nhưng cần có thêm nghiên cứu để hiểu tác động của việc chọn một phạm vi cụ thể.

7 Lời cảm ơn
Chúng tôi muốn sử dụng DyLoRA với Mindspore2, một framework mới cho tính toán học sâu.

--- TRANG 9 ---
Tài liệu tham khảo
[Danh sách các tài liệu tham khảo được dịch sang tiếng Việt]

--- TRANG 10 ---
[Tiếp tục danh sách tài liệu tham khảo]

A Độ phức tạp thời gian
Thời gian huấn luyện cho DyLoRA tương đương với LoRA được huấn luyện một lần trên một thứ hạng cụ thể. Do đó, khi tìm kiếm không gian thứ hạng cho LoRA, chúng ta cần huấn luyện nó nhiều lần, trong khi phương pháp của chúng tôi không yêu cầu tìm kiếm các thứ hạng. Theo đó, độ phức tạp thời gian tương đối của DyLoRA tỷ lệ nghịch với số lượng thứ hạng có thể mà mô hình LoRA phải được tìm kiếm. Trong MRPC, DyLoRA (cho tất cả các thứ hạng) và LoRA (chỉ trên một thứ hạng 8) yêu cầu tổng thời gian huấn luyện là 408.39 giây và 399.95 giây tương ứng. Do đó, khi chúng ta cần huấn luyện tám mô hình LoRA (Thứ hạng=1,2,...,8), nó sẽ dẫn đến chi phí 399.95*8=3199.6s, so với thời gian huấn luyện của mô hình chúng tôi, chỉ là 408.39 giây. Việc triển khai hiệu quả hơn thuật toán của chúng tôi có thể dẫn đến độ phức tạp thời gian tốt hơn.

B Siêu tham số
Chúng tôi không sử dụng bất kỳ điều chỉnh tham số nào hoặc thủ thuật MNLI (khởi tạo một số nhiệm vụ hạ nguồn từ checkpoint MNLI thay vì trọng số được huấn luyện trước). Do đó, chúng tôi đã tinh chỉnh tất cả các tập dữ liệu từ trọng số được huấn luyện trước ban đầu. Chúng tôi chỉ đơn giản tuân theo các siêu tham số thống nhất cho tất cả các thí nghiệm khác nhau. Không giống như LoRA (Hu et al., 2021a) báo cáo trung vị trên 5 seed ngẫu nhiên, chúng tôi báo cáo trung bình và độ lệch chuẩn trên 5 seed ngẫu nhiên. Xem chi tiết trong Bảng 8.

C Thí nghiệm GPT
Một tóm tắt về các thí nghiệm bổ sung đã được tiến hành để chứng minh hiệu quả của phương pháp được đề xuất cho nhiệm vụ tạo ngôn ngữ được cung cấp trong Bảng 9.

--- TRANG 11-14 ---
[Các bảng siêu tham số và kết quả thí nghiệm chi tiết]

MoELoRA: Học Tương Phản Hướng Dẫn Hỗn Hợp Chuyên Gia trên Tinh Chỉnh Hiệu Quả Tham Số cho Mô Hình Ngôn Ngữ Lớn

Tongxu Luo¹* Jiahe Lei¹* Fangyu Lei¹,² Weihao Liu¹
Shizhu He¹,² Jun Zhao¹,² Kang Liu¹,²
¹Viện Tự Động Hóa, CAS ²Đại học Viện Hàn lâm Khoa học Trung Quốc

Tóm tắt

Tinh chỉnh thường cần thiết để tăng cường khả năng thích ứng của Mô hình Ngôn ngữ Lớn (LLM) với các tác vụ hạ nguồn. Tuy nhiên, quá trình cập nhật hàng tỷ tham số đòi hỏi tài nguyên tính toán và thời gian huấn luyện đáng kể, điều này tạo ra một rào cản lớn đối với việc ứng dụng rộng rãi các mô hình quy mô lớn trong nhiều tình huống khác nhau. Để giải quyết vấn đề này, Tinh Chỉnh Hiệu Quả Tham Số (PEFT) đã nổi lên như một mô hình nổi bật trong nghiên cứu gần đây. Tuy nhiên, các phương pháp PEFT hiện tại sử dụng một tập hợp hạn chế các tham số toàn cục (như LoRA, thêm ma trận xấp xỉ thấp hạng vào tất cả trọng số) gặp thử thách trong việc kết hợp linh hoạt các mô-đun tính toán khác nhau trong các tác vụ hạ nguồn. Trong công trình này, chúng tôi giới thiệu một phương pháp PEFT mới: MoELoRA. Chúng tôi xem xét LoRA như Hỗn Hợp Chuyên Gia (MoE), và để giảm thiểu hiện tượng định tuyến ngẫu nhiên quan sát được trong MoE, chúng tôi đề xuất việc sử dụng học tương phản để khuyến khích các chuyên gia học các đặc trưng khác biệt. Chúng tôi đã tiến hành thí nghiệm trên 11 tác vụ trong các benchmark lý luận toán học và lý luận thông thường. Với cùng số lượng tham số, phương pháp của chúng tôi vượt trội hơn LoRA đáng kể. Trong lý luận toán học, MoELoRA đạt được hiệu suất trung bình cao hơn LoRA 4,2%, và thể hiện hiệu suất cạnh tranh so với GPT-3.5 175B trên một số benchmark.

Từ khóa: Mô hình Ngôn ngữ Lớn, Hỗn hợp Chuyên gia, Tinh chỉnh Hiệu quả Tham số, Học Tương phản

1. Giới thiệu

Với sự phát triển nhanh chóng của các Mô hình Ngôn ngữ Lớn (LLM) như GPT3 (Brown et al., 2020), BLOOM (Scao et al., 2022) và LLaMA (Touvron et al., 2023), việc ứng dụng thành công của tiền huấn luyện tự giám sát trên dữ liệu văn bản không nhãn đã mang lại những cơ hội chưa từng có để tăng cường các tác vụ hạ nguồn. Tuy nhiên, để khai thác đầy đủ tiềm năng của các LLM này trong các ứng dụng thực tế, cũng cần phải tiếp tục tinh chỉnh (Wei et al., 2021; Chung et al., 2022) các LLM dựa trên dữ liệu huấn luyện của các tác vụ cụ thể để đáp ứng các yêu cầu hiệu suất của tác vụ hạ nguồn. Số lượng tham số đáng kể, thường vượt quá một tỷ, làm cho việc tinh chỉnh các LLM này trở thành một nỗ lực tốn kém, đòi hỏi một khoản đầu tư lớn về tài nguyên tính toán (Hình 1a). Do đó, trong những năm gần đây, các kỹ thuật Tinh Chỉnh Hiệu Quả Tham Số (PEFT) (Mangrulkar et al., 2022; Zhang et al., 2023) đã xuất hiện với mục tiêu giảm chi phí tinh chỉnh bằng cách đóng băng một số trọng số mô hình hoặc giới thiệu các mô-đun có thể huấn luyện nhỏ hơn.

Trong việc khám phá liên tục trong lĩnh vực này, một loạt các phương pháp như LoRA (Hu et al., 2021), AdaLoRA (Zhang et al., 2023), Adamix (Wang et al., 2022), QLoRA (Dettmers et al., 2023) và LoRAHub (Huang et al., 2023) đã xuất hiện, mỗi phương pháp đều đưa ra các quan điểm độc đáo về việc tinh chỉnh hiệu quả các Mô hình Ngôn ngữ Lớn để có khả năng ứng dụng tốt hơn trong các tác vụ hạ nguồn. LoRA (Hình 1b) giới thiệu khái niệm về hạng LoRA để giảm số lượng tham số có thể huấn luyện. AdaLoRA xây dựng trên nền tảng của LoRA, đạt được một phương pháp không cần tìm kiếm giúp đơn giản hóa đáng kể quá trình tinh chỉnh. Adamix kết hợp MoE với Adapter để vượt qua hiệu suất của LoRA. LoRAHub sử dụng một phương pháp không có gradient (Liu et al., 2020) để thực hiện kết hợp có trọng số của nhiều trọng số LoRA, từ đó thích ứng tốt hơn với các tác vụ hạ nguồn mới.

Tuy nhiên, các phương pháp PEFT hiện tại sử dụng một tập hợp hạn chế các tham số toàn cục gặp thử thách trong việc kết hợp linh hoạt các mô-đun tính toán khác nhau trong các tác vụ hạ nguồn. Được truyền cảm hứng từ các phương pháp như Hỗn hợp Chuyên gia (MoE), Adamix, và LoRAHub, chúng tôi đề xuất một phương pháp PEFT mới có tên MoELoRA. Phương pháp này xem xét LoRA như một Hỗn hợp Chuyên gia, tận dụng khả năng mô hình hóa của nhiều chuyên gia cho các miền dữ liệu phức tạp, cũng như sử dụng các đặc trưng hiệu quả tham số của LoRA. Như trong Hình 1c, trong cả quá trình huấn luyện và suy luận, chỉ có LoRA được lựa chọn bởi mạng cổng sẽ được kích hoạt và chỉ những "chuyên gia" này liên quan đến các tác vụ cụ thể sẽ tham gia vào cập nhật gradient hoặc suy luận tiến.

Tuy nhiên, việc áp dụng MoE cho LoRA đặt ra những thách thức. Thứ nhất, dưới kiến trúc MoE, mạng cổng không thể hiện sở thích cho một chuyên gia cụ thể nào, dẫn đến một mức độ ngẫu nhiên định tuyến nhất định (Zuo et al., 2021). Thứ hai, việc hướng dẫn các chuyên gia học các đặc trưng khác biệt là một nhiệm vụ đầy thách thức.

Để giải quyết những vấn đề này, chúng tôi giới thiệu học tương phản giữa các chuyên gia. Thông qua phương pháp học tương phản này, chúng tôi coi các đầu ra của cùng một chuyên gia như các mẫu dương và các đầu ra của các chuyên gia khác nhau như các mẫu âm, khuyến khích các chuyên gia học các đặc trưng khác biệt. Cuối cùng, chúng tôi đạt được hiệu suất vượt trội hơn LoRA dưới cùng số lượng tham số. Trong lý luận toán học, MoELoRA có hiệu suất trung bình cao hơn LoRA 4,2%, và trong lý luận thông thường, nó cao hơn LoRA trung bình 1,0%. Hơn nữa, MoELoRA thể hiện hiệu suất cạnh tranh so với GPT-3.5 175B trên một số benchmark.

Tóm lại, công trình của chúng tôi đóng góp những điểm sau:

(1) Chúng tôi xem xét LoRA như Hỗn hợp Chuyên gia và đề xuất một phương pháp PEFT mới có tên MoELoRA, tận dụng kiến trúc MoE để đạt được kết hợp động của nhiều mô-đun LoRA, phục vụ tốt hơn cho các yêu cầu của tác vụ hạ nguồn.

(2) Để đáp ứng với vấn đề định tuyến ngẫu nhiên trong việc sử dụng Hỗn hợp Chuyên gia (MoE) cho việc hợp nhất LoRA, chúng tôi đề xuất sử dụng học tương phản để khuyến khích các chuyên gia học các đặc trưng khác biệt.

(3) Chúng tôi tiến hành thí nghiệm trên 11 tập dữ liệu cho các tác vụ lý luận toán học và lý luận thông thường, chứng minh rằng phương pháp của chúng tôi vượt trội hơn LoRA trong tất cả các tác vụ. Kết quả của các thí nghiệm loại bỏ cũng cho thấy sự cải thiện trong các tác vụ hạ nguồn với học tương phản. Hơn nữa, chúng tôi thực hiện phân tích theo dõi định tuyến MoE để hiểu tác động của phương pháp chúng tôi đối với quá trình ra quyết định của mô hình.

2. Công trình Liên quan

2.1. Tinh Chỉnh Hiệu Quả Tham Số

Trong khi tinh chỉnh với các tập dữ liệu cụ thể cho tác vụ, tinh chỉnh toàn mô hình không chỉ đòi hỏi tài nguyên tính toán và lưu trữ đáng kể mà còn có thể dẫn đến hiện tượng quên thảm khốc. Ngược lại, Tinh Chỉnh Hiệu Quả Tham Số (PEFT) (Mangrulkar et al., 2022) điều chỉnh có chọn lọc một số lượng hạn chế tham số hoặc giới thiệu các tham số có thể huấn luyện bổ sung thay vì toàn bộ mô hình xương sống, nhưng vẫn đạt được hiệu suất có thể so sánh hoặc thậm chí vượt trội so với tinh chỉnh đầy đủ (Ding et al., 2023). Prefix-tuning (Li and Liang, 2021) và Prompt-tuning (Lester et al., 2021) điều kiện các mô hình ngôn ngữ đóng băng thông qua các nhúng token ảo có thể huấn luyện. Adapter (Houlsby et al., 2019; He et al., 2021; Wang et al., 2022) chèn các lớp adapter có thể huấn luyện giữa các lớp hiện có trong mạng nơ-ron và chỉ tinh chỉnh chúng. Hu et al. (2021) giới thiệu LoRA, sử dụng hai ma trận thấp hạng và độc quyền tinh chỉnh LLM. Tuy nhiên, LoRA đơn lẻ không thể kết hợp linh hoạt các mô-đun tính toán khác nhau trong các tác vụ hạ nguồn. Chúng tôi thiết lập nhiều LoRA như các chuyên gia khác biệt và kết hợp chúng một cách động để đạt được PEFT tốt hơn.

2.2. Hỗn hợp Chuyên gia

Hỗn hợp Chuyên gia (MoE) tích hợp các đầu ra của các mô hình con chuyên biệt, được gọi là chuyên gia, thông qua một cơ chế bộ định tuyến phụ thuộc token. Giả định sự tồn tại của các tập con tự nhiên trong tập dữ liệu, chẳng hạn như có nguồn gốc từ các miền hoặc chủ đề khác nhau, một mạng cổng được sử dụng để xác định chuyên gia nào nên được huấn luyện. Điều này cho phép mỗi mạng xử lý một tập con của toàn bộ tập dữ liệu huấn luyện, giải quyết thách thức về tổng quát hóa cho một mô hình đơn lẻ trên các tập dữ liệu phức tạp.

Shazeer et al. (2017) giới thiệu các mô hình Hỗn hợp Chuyên gia Cổng Thưa thớt (MoE), sử dụng một chiến lược định tuyến top-k để duy trì sự thưa thớt trong khi mở rộng quy mô các tham số mô hình. Phương pháp này đạt được quy mô tham số 137 tỷ trong các mạng dựa trên RNN, trong khi đảm bảo chi phí tính toán thấp cho cả huấn luyện và suy luận (ví dụ, FLOP, tham số). Bằng cách thiết kế các hàm mất mát để thực thi cân bằng tải chuyên gia, phương pháp này đã tạo ra hiệu suất tiên tiến trong các benchmark mô hình hóa ngôn ngữ và dịch máy. Ngoài ra, các nghiên cứu gần đây của GShard (Lepikhin et al., 2020), Switch-Transformer (Fedus et al., 2022), BASELayer (Lewis et al., 2021), và Hash Layer (Roller et al., 2021) đã tập trung vào việc phát triển các mô hình dựa trên Transformer quy mô lớn kết hợp MoE, cùng với việc khám phá các chiến lược huấn luyện tối ưu để khai thác đầy đủ khả năng của mô hình. Trái ngược với công trình của họ, chúng tôi tích hợp MoE vào PEFT và xác nhận hiệu quả của nó.

2.3. Học Tương Phản

Học Tương Phản (Hadsell et al., 2006) đã nổi lên như một mô hình mạnh mẽ trong lĩnh vực học biểu diễn không giám sát. Nó nhằm mục đích học các biểu diễn có ý nghĩa bằng cách tối đa hóa sự đồng thuận giữa các quan điểm được tăng cường khác nhau của cùng một dữ liệu. Một số nghiên cứu (Zhuang et al., 2019; Misra and Maaten, 2020; Chen et al., 2020) đã giới thiệu các phương pháp để căn chỉnh các biểu diễn của các tăng cường khác nhau áp dụng cho một hình ảnh, dẫn đến những thành công đáng chú ý trong thị giác máy tính.

Học tương phản cũng đã chứng minh là một phương pháp thành công trong các tác vụ NLP. Ví dụ, Conneau et al. (2019) giới thiệu một khung học tương phản được thiết kế riêng để thu được các biểu diễn đa ngôn ngữ, thể hiện hiệu quả trong các tác vụ xuyên ngôn ngữ. CERT (Fang et al., 2020) sử dụng phương pháp dịch ngược để tạo ra các phiên bản tăng cường của các câu gốc, trong khi DeCLUTR (Giorgi et al., 2020) cho rằng các phân đoạn khác nhau trong một tài liệu tương tự nhau. CLEAR (Wu et al., 2020), áp dụng một cấu trúc chỉ có bộ mã hóa, và thu được một biểu diễn câu bất biến với nhiễu.

Hơn nữa, nhiều biến thể và phần mở rộng của học tương phản đã được giới thiệu để tăng cường hiệu quả của nó. Ví dụ, Chen et al. (2020) giới thiệu SimCLR, sử dụng một tập hợp các tăng cường dữ liệu và kích thước lô lớn để đạt được kết quả ấn tượng trên nhiều tác vụ thị giác máy tính. MoCo (He et al., 2020) giới thiệu một cơ chế ngân hàng bộ nhớ để cho phép học tương phản hiệu quả hơn. Trong bài báo này, chúng tôi giới thiệu khung học tương phản vào mô hình MoE, nhằm tối đa hóa sự khác biệt trong phân phối đầu ra giữa các chuyên gia khác nhau để nắm bắt các đặc trưng đa dạng trong các tác vụ hạ nguồn, giảm thiểu hiện tượng định tuyến ngẫu nhiên được thể hiện trong Zuo et al. (2021).

3. Phương Pháp Đề Xuất

3.1. Khung MoELoRA

MoELoRA kết hợp khái niệm MoE với LoRA, tăng hiệu quả các tham số mô hình trong khi duy trì cùng chi phí tính toán để đạt được hiệu suất vượt trội. Cụ thể, phương pháp của chúng tôi được chi tiết như sau:

Đầu tiên, chúng tôi xem xét kiến trúc MoE truyền thống. Đối với một token đầu vào x∈Rd, chúng tôi thu được trọng số cho từng chuyên gia thông qua một mạng cổng G:Rd→Rn, dẫn đến G(x) = [G(x)1, G(x)2, ..., G(x)n], trong đó n đại diện cho số lượng chuyên gia, và G(x)∈Rn. Sau đó, chúng tôi sử dụng những trọng số này để kết hợp tuyến tính các đầu ra của các chuyên gia khác nhau, tạo ra đầu ra y của lớp MoE:

y = Σ(i=1 to n) G(x)i ⊙ Ei(x)  (1)

Bản chất của MoE nằm ở việc tăng khả năng của mô hình trong khi giữ số lượng tham số cho dự đoán và huấn luyện không đổi. Mạng cổng áp dụng một chiến lược định tuyến Top k, trong đó chỉ k≪n trọng số trong G(x) là khác không. Điều này có nghĩa là mặc dù thêm nhiều chuyên gia, điều này tăng tổng số tham số mô hình, chỉ một số lượng nhỏ chuyên gia tham gia vào các tính toán trong cả quá trình truyền tiến và truyền ngược, đạt được sự thưa thớt.

Tiếp theo, chúng tôi xem xét cấu trúc LoRA. Ban đầu, đầu vào x trải qua một hoạt động LoRA Dropout để tăng cường khả năng tổng quát hóa của nó. Sau đó, nó được chiếu xuống dưới thành r (r≪d) chiều thông qua A(x), trong đó r đại diện cho Hạng LoRA. Tiếp theo, nó được chiếu trở lại lên d chiều thông qua B(x), và quá trình này có thể được biểu diễn như:

A(x) = xA  (2)
B(x) = xB  (3)
LoRA(x) = B(A(x)) = xAB  (4)

Trong đó A∈Rd×r và B∈Rr×d là các ma trận trọng số.

Chúng tôi xem xét các mô-đun LoRA khác nhau như các chuyên gia, tạo thành kiến trúc MoELoRA. Đối với một mẫu đầu vào x, trước tiên chúng tôi sử dụng mạng cổng để tạo ra một vector trọng số G(x). Sau đó, chúng tôi áp dụng những trọng số này cho các nhánh khác nhau trong mỗi cấu trúc LoRA, tạo ra nhiều nhánh được tinh chỉnh, được ký hiệu là LoRAi(x). Cuối cùng, chúng tôi thu được đầu ra dự đoán MoELoRA cuối cùng bằng cách kết hợp tuyến tính các nhánh này như sau:

MoELoRA(x) = Σ(i=1 to n) G(x)i ⊙ LoRAi(x)  (5)

3.2. Thách Thức của MoELoRA

3.2.1. Mất Cân Bằng Tải

Không có can thiệp, Top k MoE thường gán một số lượng lớn token cho một vài chuyên gia, trong khi các chuyên gia còn lại nhận được ít hoặc không có token nào được gán (Zuo et al., 2021). Điều này có thể dẫn đến hiệu suất kém. Do đó, các công trình trước đây (Shazeer et al., 2017; Fedus et al., 2022) đã sử dụng Loss Cân Bằng Tải để khuyến khích định tuyến cân bằng.

3.2.2. Định Tuyến Ngẫu Nhiên

Mô hình MoE thể hiện một hiện tượng, trong đó mạng cổng không thể hiện sở thích cho bất kỳ chuyên gia cụ thể nào, dẫn đến một quá trình định tuyến có vẻ ngẫu nhiên. Trong những trường hợp như vậy, do thực tế là mỗi chuyên gia nhận được token được tạo ra bởi định tuyến ngẫu nhiên (Zuo et al., 2021), nội dung được học bởi tất cả các chuyên gia thực tế không khác biệt đáng kể. Điều này trái ngược với ý định ban đầu của việc sử dụng MoE, đó là phân chia một vấn đề lớn thành các vấn đề con nhỏ hơn, huấn luyện các chuyên gia khác nhau để giải quyết hiệu quả các vấn đề con này, và sau đó kết hợp các đầu ra của những chuyên gia này. Do đó, việc giải quyết định tuyến ngẫu nhiên đặt ra một thách thức lớn phải được khắc phục trong kiến trúc MoE.

3.3. Mất Mát Phụ

3.3.1. Mất Mát Cân Bằng Tải

Trong quá trình huấn luyện, mạng cổng có xu hướng hội tụ về một trạng thái trong đó nó liên tục phân bổ trọng số đáng kể cho một tập con hạn chế của các chuyên gia (Zuo et al., 2021), có thể dẫn đến phân phối khối lượng công việc không cân bằng giữa chúng. Để giải quyết mối quan ngại này, Shazeer et al. (2017) và Fedus et al. (2022) đã đề xuất mất mát cân bằng tải và trong bài báo này, chúng tôi áp dụng phương pháp sau.

Xem xét một lô huấn luyện B với T token. Để fi đại diện cho tỷ lệ token được gán cho chuyên gia thứ i, tức là:

fi = (1/T) Σ(x∈B) 1{arg max p(x) = i}  (6)

Để Pi là trung bình của tất cả T xác suất được tạo ra bởi mạng cổng cho chuyên gia thứ i. Pi có thể được biểu diễn như:

Pi = (1/T) Σ(x∈B) pi(x)  (7)

Dựa trên các phương trình trên, f là không khả vi trong khi P là khả vi. Mất Mát Cân Bằng Tải Ll được định nghĩa là tích vô hướng giữa f và P, làm cho nó khả vi, và nó có thể được biểu diễn như:

Ll = n Σ(i=1 to n) fi(x)·Pi  (8)

Mất mát này tối ưu hóa "cân bằng tải" từ hai góc độ: f đặc trưng cho phân phối số lượng token được gán cho mỗi chuyên gia, trong khi P mô tả phân phối của đầu ra từ mạng cổng. Khi mạng cổng xuất ra một phân phối xác suất trung bình [1/n···1/n] cho các token trong một lô, Ll đạt được giá trị tối thiểu của nó, là n Σ(i=1 to n) 1/n·1/n = 1.

3.3.2. Mất Mát Tương Phản Chuyên Gia

Chúng tôi giới thiệu học tương phản để khuyến khích các chuyên gia học các đặc trưng khác nhau và giảm thiểu định tuyến ngẫu nhiên. Đối với mỗi token đầu vào, chúng tôi chọn k chuyên gia hàng đầu bằng cách sử dụng một mạng cổng, đảm bảo rằng mỗi token được gán cho một số chuyên gia. Để thúc đẩy các chuyên gia khác nhau trong việc học nội dung khác biệt từ đầu vào x∈RT×d (trong đó T đại diện cho tổng số lô token), một phương pháp trực quan như sau: Đối với Ti token được gán cho chuyên gia Ei, chúng nên chia sẻ một thuộc tính chung, ví dụ, nếu Ei chuyên về xử lý token loại "động từ", thì thuộc tính chung giữa các token được gán cho chuyên gia này là "động từ". Đối với những token loại "động từ" này, sau khi được xử lý bởi Ei, chúng nên đủ gần nhau trong không gian ngữ nghĩa. Ngược lại, đối với hai chuyên gia Ei và Ej, vì chúng tôi mong đợi họ học các đặc trưng khác nhau, các token họ xử lý nên xa nhau trong không gian ngữ nghĩa. Điều này có thể được biểu diễn đơn giản như:

d(Ei(xk), Ei(xm)) ≪ d(Ei(xk), Ej(xn))  (9)

Do đó, chúng tôi có thể sử dụng một phương pháp học tương phản được đề xuất trong He et al. (2020), trong đó các đầu ra của cùng một chuyên gia được coi như các mẫu dương, trong khi các đầu ra của các chuyên gia khác nhau được xem xét như các mẫu âm. Cho đầu vào x∈RT×d, đầu ra mô hình chuyên gia E(x) = [E1(x), E2(x), ···, En(x)], trong đó Ei(x)∈Rti×h, và ti đại diện cho số lượng token được kích hoạt bởi chuyên gia thứ i, thỏa mãn mối quan hệ T·top k = Σti. Theo định nghĩa của chúng tôi về các mẫu dương và âm trong học tương phản chuyên gia, để q∈Ei(x) và k+∈Ei(x).

Cuối cùng, đối với chuyên gia thứ i, Mất Mát Tương Phản Chuyên Gia có thể được định nghĩa như:

LEi = -Σ(q≠k+) log(exp(q·k+/τ) / Σ(k∈E(x)) exp(q·k/τ))  (10)

Ở đây, τ đại diện cho hệ số nhiệt độ, kiểm soát hình dạng phân phối của q·k. Khi τ tăng, nó làm mềm phân phối của q·k, giảm sức mạnh phân biệt của LE đối với tất cả các mẫu âm. Ngược lại, một giá trị τ thấp hơn làm cho mô hình tập trung nhiều hơn vào các mẫu âm trong quá trình huấn luyện. Trong Hình 2, chúng tôi minh họa quá trình tính toán chi tiết của Mất Mát Tương Phản Chuyên Gia.

Cuối cùng, Mất Mát Phụ mà chúng tôi áp dụng được định nghĩa như:

L = α·Ll + β·LE  (11)

trong đó α và β là các siêu tham số.

4. Thí Nghiệm

4.1. Thiết Lập Thí Nghiệm

4.1.1. Tập Dữ Liệu

Chúng tôi đánh giá LoRA và MoELoRA cùng các adapter khác trên các tác vụ lý luận toán học và lý luận thông thường. Tập dữ liệu lý luận toán học của chúng tôi, cũng như tất cả các lý luận cho các mẫu, được lấy từ Hu et al. (2023). Tất cả các lý luận cho các mẫu được tạo ra thông qua zero-shot-CoT (Kojima et al., 2022) trên GPT-3.5, nhưng không trải qua bất kỳ việc lọc lỗi nào. Các tác vụ lý luận toán học bao gồm tổng cộng 6 benchmark: AddSub (Hosseini et al., 2014), AQuA (Ling et al., 2017), gsm8k (Cobbe et al., 2021), MultiArith (Roy and Roth, 2016), SingleEQ (Koncel-Kedziorski et al., 2015), và SVAMP (Patel et al., 2021).

Các tác vụ thông thường mà chúng tôi chọn bao gồm 5 benchmark: cụ thể là ARC-C, ARC-E (Chollet, 2019), BoolQ (Clark et al., 2019), OBQA (Mihaylov et al., 2018), và PIQA (Bisk et al., 2020).

4.1.2. Chi Tiết Thực Hiện

Chúng tôi sử dụng LLaMA-7b (Touvron et al., 2023) như Mô hình Ngôn ngữ Lớn. Chúng tôi tiến hành so sánh giữa Series-Adapter, Parallel-Adapter, LoRA và MoELoRA. Chúng tôi giới thiệu LoRA hoặc MoELoRA vào 'q_proj' và 'p_proj' của LLaMA. Chúng tôi thiết lập LoRA và MoELoRA với cùng số lượng tham số có thể huấn luyện, chứng minh rằng MoELoRA vượt trội hơn LoRA đáng kể dưới cùng các thiết lập. Sau đó, chúng tôi tiến hành các thí nghiệm loại bỏ để phân tích các thành phần thiết kế khác nhau của MoELoRA.

Trong các thí nghiệm, vì AdapterH (Houlsby et al., 2019) và AdapterP (Pfeiffer et al., 2020) là các adapter Chuỗi, và AdapterP vượt trội hơn AdapterH, chúng tôi sử dụng AdapterP với kích thước thắt cổ chai 768 như Series Adapter. Đối với Parallel-Adapter (Pfeiffer et al., 2020), các lớp adapter đã được đặt trong các mô-đun attention đa đầu với kích thước thắt cổ chai 256. Đối với LoRA, chúng tôi thiết lập Hạng LoRA thành R=36, trong khi đối với MoELoRA, chúng tôi thiết lập Hạng LoRA thành R=32, với tổng cộng n=8 chuyên gia, mỗi chuyên gia có Hạng LoRA r=4. Cấu hình này đảm bảo rằng LoRA và MoELoRA có số lượng tham số có thể huấn luyện bằng nhau. Đối với mất mát, τ được thiết lập thành 0.07. α và β được thiết lập thành 0.01. Tất cả các thí nghiệm của chúng tôi được tiến hành trên một RTX3090 duy nhất.

4.2. Kết Quả Chính

Bảng 1 trình bày hiệu suất trên sáu benchmark tác vụ lý luận toán học. Trong AddSub, MoELoRA đạt được độ chính xác cao hơn so với LoRA 3,8, và nó cũng vượt trội hơn GPT-3.5 3,3 điểm. Trong trường hợp AQuA, MoELoRA cho thấy sự cải thiện độ chính xác 7,9 so với LoRA. Đối với gsm8k, độ chính xác của MoELoRA vượt quá LoRA 1,5. Trong MultiArith, MoELoRA thể hiện sự tăng độ chính xác 6,7 so với LoRA, và nó cũng vượt trội hơn GPT-3.5 11,2. Trong SingleEQ, độ chính xác của MoELoRA cao hơn LoRA 3,9, và nó vượt qua GPT-3.5 6,0. Cuối cùng, trong SVAMP, MoELoRA đạt được sự cải thiện độ chính xác 1,0 so với LoRA. Các thí nghiệm của chúng tôi đã chứng minh rằng, với cùng số lượng tham số, MoELoRA liên tục vượt trội hơn LoRA trong tất cả các khía cạnh. Về độ chính xác trung bình, MoELoRA thể hiện sự cải thiện 4,2 so với LoRA, vượt qua baseline LoRA một cách toàn diện. Hơn nữa, MoELoRA vẫn rất cạnh tranh ngay cả khi so sánh với GPT-3.5, có gần 10^4 lần nhiều tham số hơn.

Bảng 2 thể hiện hiệu suất của LoRA, MoELoRA, và GPT-3.5 trên năm benchmark lý luận thông thường. Trong ARC-C, MoELoRA đạt được độ chính xác cao hơn LoRA 1,7. Trong ARC-E, độ chính xác của MoELoRA cao hơn LoRA 0,3. Đối với BoolQ, MoELoRA vượt qua LoRA 1,1 và cũng vượt trội hơn GPT-3.5 0,6. Trên OBQA, độ chính xác của MoELoRA vượt quá LoRA 1,4 và GPT-3.5 8,8. Trong trường hợp PIQA, độ chính xác của MoELoRA cao hơn LoRA 0,9 và cao hơn GPT-3.5 0,2. Các thí nghiệm của chúng tôi đã chứng minh rằng, với cùng số lượng tham số, MoELoRA thể hiện sự cải thiện 1,0% so với LoRA trên các tác vụ lý luận thông thường, và nó vẫn cạnh tranh so với GPT-3.5 trên một số benchmark.

4.3. Nghiên Cứu Loại Bỏ

4.3.1. Loại Bỏ trên Mất Mát Phụ

Để xác nhận hiệu quả của Mất Mát Tương Phản Chuyên Gia của chúng tôi, chúng tôi tiến hành các thí nghiệm loại bỏ. Bảng 3 hiển thị kết quả của các thí nghiệm loại bỏ trên các tác vụ lý luận toán học, và Bảng 4 trình bày kết quả cho các tác vụ lý luận thông thường. Trong những thí nghiệm này, chúng tôi giữ Hạng LoRA ở R=32, với tổng cộng n=8 chuyên gia, và sử dụng thiết lập trong đó mỗi token được gán cho 2 chuyên gia được kích hoạt hàng đầu. Kết quả thí nghiệm cho thấy rằng việc loại bỏ mất mát tương phản chuyên gia dẫn đến sự giảm trung bình 3,0 trong các tác vụ lý luận toán học và sự giảm trung bình 0,9 trong các tác vụ lý luận thông thường. Những thí nghiệm này cung cấp bằng chứng về sự cải thiện đáng kể trong hiệu suất được quy cho Mất Mát Tương Phản Chuyên Gia trong MoELoRA.

4.3.2. Loại Bỏ trên Lựa Chọn Top-k mỗi Token

Đồng thời, chúng tôi tiến hành các thí nghiệm liên quan đến việc lựa chọn k chuyên gia hàng đầu cho mỗi token. Chúng tôi cố định Hạng LoRA ở R=32 và sử dụng tổng cộng n=8 chuyên gia. Đáng ngạc nhiên, chúng tôi thấy rằng hiệu suất thể hiện sự cải thiện đáng kể khi sử dụng 2 chuyên gia hàng đầu, so với 1 và 4 chuyên gia hàng đầu. Bảng 5 hiển thị kết quả cho các tác vụ lý luận toán học, và Bảng 6 trình bày kết quả cho các tác vụ lý luận thông thường.

5. Phân Tích

5.1. Tại Sao Sự Cải Thiện Trong Các Tác Vụ Thông Thường Lại Không Rõ Rệt?

Trong Phụ lục A, chúng tôi hiển thị bốn định dạng khác nhau của các benchmark cho các tác vụ thông thường, cụ thể là ARC, BoolQ, OBQA, và PIQA. Mỗi benchmark này đòi hỏi LLM phải sở hữu kiến thức tương ứng, điều này đặt ra những yêu cầu đáng kể đối với hiệu quả tiền huấn luyện của LLM. Hơn nữa, trong quá trình tinh chỉnh, nếu kiến thức không thể được tiêm hiệu quả, thì việc tinh chỉnh trên các tác vụ thông thường trở nên vô ích. Do đó, hiệu suất trên các tác vụ thông thường dựa nhiều hơn vào kho kiến thức mà LLM đã tích lũy trong giai đoạn tiền huấn luyện. Trong khi PEFT có tác động đến các tác vụ thông thường, cuối cùng nó không thể giải quyết vấn đề là LLM có thể thiếu kiến thức liên quan.

Geva et al. (2020); Dai et al. (2021) đã chứng minh rằng Mạng Nơ-ron Feedforward (FFN) có thể được diễn giải như các mạng bộ nhớ có khả năng lưu trữ lượng kiến thức đáng kể. Trong moefication, Zhang et al. (2022) phân tích các mẫu kích hoạt của FFN trong các mô hình Transformer và phát hiện ra một hiện tượng trong đó chỉ một phần nhỏ các nơ-ron được kích hoạt cho một đầu vào duy nhất. Những phát hiện của họ khẳng định rằng một mô hình Transformer có thể được biến đổi thành một mô hình Hỗn hợp Chuyên gia (MoE) tương đương.

5.2. Theo Dõi Token Qua Chuyên Gia

Trong tác vụ lý luận toán học của chúng tôi, chúng tôi đã theo dõi định tuyến token trong MoE để phân tích liệu hiện tượng định tuyến ngẫu nhiên có được giảm thiểu hay không. Đầu tiên, chúng tôi theo dõi định tuyến của tất cả các token số trong một số lớp, như được thể hiện trong Hình 3. Chúng tôi quan sát thấy rằng luôn có một số chuyên gia cụ thể giỏi trong việc xử lý các token số.

Chúng tôi cũng quan sát thấy rằng đối với các token số cụ thể, chẳng hạn như '2' hoặc '4' trong hình 4 và 5, chúng được định tuyến đến các chuyên gia cụ thể để xử lý trong các lớp đầu. Tuy nhiên, do ảnh hưởng của cơ chế attention, khi các lớp tiến triển và các token tiếp thu một lượng lớn thông tin, định tuyến của chúng trở nên đồng đều hơn.

Hơn nữa, theo sự ngạc nhiên của chúng tôi, chúng tôi thấy rằng tải không đặc biệt cân bằng. Tuy nhiên, khi xem xét kỹ hơn, điều này được mong đợi vì tập dữ liệu vốn chứa các biến thể trong tần suất token. Một số token xuất hiện thường xuyên hơn trong tập dữ liệu, trong khi những token khác xảy ra ít hơn. Xem bảng 7. Tần suất xuất hiện khác nhau của các token trong tập dữ liệu làm cho việc đạt được cân bằng tải trở thành một nhiệm vụ đầy thách thức. Nhưng Mất mát cân bằng tải vẫn cần thiết, nếu không một số chuyên gia sẽ không được gán token từ đầu đến cuối.

6. Kết Luận và Công Trình Tương Lai

Chúng tôi đã giới thiệu một phương pháp Tinh Chỉnh Hiệu Quả Tham Số mới gọi là MoELoRA và giảm thiểu hiện tượng định tuyến ngẫu nhiên quan sát được trong MoE thông qua học tương phản. Ngoài ra, chúng tôi tiến hành các thí nghiệm rộng rãi trên 11 tập dữ liệu lý luận toán học và lý luận thông thường. Trong lý luận toán học, MoELoRA có hiệu suất trung bình cao hơn LoRA 4,2%, và trong lý luận thông thường, nó cao hơn LoRA trung bình 1,0%. Kết quả cho thấy rằng MoELoRA liên tục vượt trội hơn LoRA trong tất cả các tác vụ. Hơn nữa, khi so sánh với mô hình GPT-3.5, MoELoRA thể hiện hiệu suất cạnh tranh của nó.

Công Trình Tương Lai: Trong Phần 5.1, chúng tôi đề cập đến những cải thiện hạn chế trên các tác vụ thông thường. Do đó, có thể đáng để khám phá MoELoRA bằng cách tái khung hóa các tác vụ thông thường như các tác vụ chỉnh sửa kiến thức. Ngoài ra, chúng tôi có thể áp dụng các mô-đun LoRA được huấn luyện trên các tác vụ khác nhau cho mỗi chuyên gia, đóng băng chúng, và chỉ huấn luyện mạng cổng.

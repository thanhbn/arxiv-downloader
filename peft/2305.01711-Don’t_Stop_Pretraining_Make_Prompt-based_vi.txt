# 2305.01711.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2305.01711.pdf
# Kích thước tệp: 857352 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Đừng Ngừng Tiền Huấn Luyện? Làm Cho Tinh Chỉnh Dựa Trên Gợi Ý
Trở Thành Người Học Mạnh Mẽ
Zhengxiang Shi
University College London
London, United Kingdom
zhengxiang.shi.19@ucl.ac.uk

Aldo Lipani
University College London
London, United Kingdom
aldo.lipani@ucl.ac.uk

Tóm tắt
Các mô hình ngôn ngữ (LMs) được huấn luyện trên lượng lớn dữ liệu không nhãn đã thúc đẩy mạnh mẽ lĩnh vực xử lý ngôn ngữ tự nhiên (NLP). Trong nghiên cứu này, chúng tôi xem xét lại quan niệm được chấp nhận rộng rãi trong NLP rằng việc tiếp tục tiền huấn luyện LMs trên các văn bản liên quan đến nhiệm vụ sẽ cải thiện hiệu suất của tinh chỉnh (FT) trong các nhiệm vụ hạ nguồn. Thông qua các thí nghiệm trên tám nhiệm vụ câu đơn và tám nhiệm vụ cặp câu trong cả môi trường bán giám sát và giám sát đầy đủ, chúng tôi thấy rằng tiền huấn luyện tiếp tục thông thường không luôn mang lại lợi ích và thậm chí có thể có hại cho các nhiệm vụ cặp câu hoặc khi sử dụng FT dựa trên gợi ý. Để giải quyết những vấn đề này, chúng tôi đề xuất Tiền Huấn Luyện Tiếp Tục Dựa Trên Gợi Ý (PCP), kết hợp ý tưởng của điều chỉnh hướng dẫn với tiền huấn luyện tiếp tục thông thường. Phương pháp của chúng tôi nhằm cải thiện hiệu suất của FT dựa trên gợi ý bằng cách trình bày cả văn bản liên quan đến nhiệm vụ và mẫu gợi ý cho LMs thông qua các mục tiêu tiền huấn luyện không giám sát trước khi tinh chỉnh cho nhiệm vụ đích. Các đánh giá thực nghiệm của chúng tôi trên 21 điểm chuẩn cho thấy PCP liên tục cải thiện hiệu suất của các phương pháp FT dựa trên gợi ý tiên tiến (lên đến 20,1% tuyệt đối) trong cả môi trường bán giám sát và giám sát đầy đủ, ngay cả với chỉ hàng trăm ví dụ không nhãn. Ngoài ra, FT dựa trên gợi ý với PCP vượt trội hơn các phương pháp bán giám sát tiên tiến với sự đơn giản hơn, loại bỏ nhu cầu về quá trình lặp và tăng cường dữ liệu bổ sung. Phân tích sâu hơn của chúng tôi khám phá giới hạn hiệu suất dưới của PCP và tiết lộ rằng những lợi thế của PCP tồn tại qua các kích thước khác nhau của mô hình và tập dữ liệu. Mã nguồn có sẵn tại https://github.com/ZhengxiangShi/PowerfulPromptFT.

1 Giới thiệu
Hình 1: Hiệu suất trung bình của FT dựa trên CLS và gợi ý qua 16 nhiệm vụ NLP khi được huấn luyện riêng lẻ hoặc kết hợp với TAPT hoặc PCP đề xuất của chúng tôi trong môi trường bán giám sát. Vui lòng tham khảo Bảng 1 để biết chi tiết.

Tiền huấn luyện các mô hình ngôn ngữ (LMs) [25,53,69] trên dữ liệu không nhãn khổng lồ và sau đó tinh chỉnh trên dữ liệu có nhãn cụ thể cho nhiệm vụ cho nhiệm vụ hạ nguồn cụ thể mang lại những cải thiện hiệu suất lớn qua các nhiệm vụ NLP. Trong nghiên cứu này, chúng tôi xem xét lại niềm tin được giữ rộng rãi trong NLP [39,82,35] rằng tiếp tục tiền huấn luyện LMs trên dữ liệu cụ thể cho nhiệm vụ [1,56] hoặc dữ liệu trong miền [54,97] nói chung có lợi cho việc cải thiện hiệu suất của tinh chỉnh (FT) trên các nhiệm vụ hạ nguồn. Như được hiển thị trong Hình 1, các thí nghiệm của chúng tôi trên tám nhiệm vụ câu đơn và tám nhiệm vụ cặp câu trong cả môi trường bán và đầy đủ giám sát tiết lộ rằng tiền huấn luyện tiếp tục thông thường trên dữ liệu cụ thể cho nhiệm vụ [35], được biết đến như tiền huấn luyện thích ứng nhiệm vụ (TAPT) (xem

Hội nghị lần thứ 37 về Hệ thống Xử lý Thông tin Thần kinh (NeurIPS 2023).arXiv:2305.01711v4 [cs.CL] 6 Oct 2023

--- TRANG 2 ---
Tôi <mask> thích cái này <mask>. Nó tích cực Tôi thực sự thích bộ phim này. Nó <mask>
Tôi <mask> thích cái này <mask>. (c) Mô hình Ngôn ngữ Che giấu Tôi thực sự thích bộ phim này. Bộ mã hóa (a) Tinh chỉnh dựa trên CLS Đầu CLS Lớp: 0 Bộ mã hóa (b) Tinh chỉnh dựa trên Gợi ý Đầu LM Verbalizer: Positive 0

thực sự, phim (d) Mô hình Ngôn ngữ Che giấu Được Gợi ý thực sự, phim Bộ mã hóa Đầu LM Bộ mã hóa Đầu LM

Các Lớp Mô hình Token Gợi ý Nhãn Vàng/Giả (e) Tiền Huấn Luyện Tiếp Tục Thông thường (ví dụ, TAPT) LMs Huấn luyện LMs trên văn bản liên quan đến Nhiệm vụ A sử dụng mục tiêu tiền huấn luyện Tinh chỉnh dựa trên CLS trên Nhiệm vụ A (f) Điều chỉnh Hướng dẫn (ví dụ, FLAN hoặc T0) LMs Huấn luyện LMs với hướng dẫn/mẫu trên Nhiệm vụ B, C, D, … Suy luận trên Nhiệm vụ A (g) Tiền Huấn Luyện Tiếp Tục Dựa trên Gợi ý (Của chúng tôi) LMs Huấn luyện LMs trên văn bản liên quan đến Nhiệm vụ A với mẫu sử dụng mục tiêu tiền huấn luyện Tinh chỉnh dựa trên gợi ý trên Nhiệm vụ A

❄ Huấn luyện Mô hình ❄ Đóng băng Mẫu Văn bản liên quan đến Nhiệm vụ

Hình 2: Tổng quan về Tiền Huấn Luyện Tiếp Tục Dựa trên Gợi ý (g), so sánh với tiền huấn luyện tiếp tục thông thường (e) và điều chỉnh hướng dẫn (f), cùng với các phương pháp tinh chỉnh (a,b) và kỹ thuật tiền huấn luyện tiếp tục (c,d). Verbalizer hoạt động như một ánh xạ từ không gian nhãn nhiệm vụ sang các từ riêng lẻ. Chúng tôi sử dụng mô hình ngôn ngữ che giấu cho mục đích minh họa, trong đó <mask> đại diện cho một token bị che giấu trong từ vựng LM.

Hình 2e): (1) có thể dẫn đến sự giảm hiệu suất đáng kể của FT dựa trên CLS (xem Hình 2a) trên các nhiệm vụ cặp câu; và (2) có thể hoạt động không ổn định qua các nhiệm vụ khác nhau cho FT dựa trên gợi ý (xem Hình 2b), thường được coi là một lựa chọn tốt hơn so với FT dựa trên CLS bởi các nghiên cứu trước đây [73,45] (§4.2). Những phát hiện này cho thấy rằng việc chỉ trình bày các văn bản liên quan đến nhiệm vụ cho LMs thông qua tiền huấn luyện tiếp tục có thể không phải là phương pháp hiệu quả nhất để cải thiện hiệu suất của FT trong các tình huống nêu trên.

Nghiên cứu gần đây [42,3,65,91,61,72,89,59] về khái quát hóa nhiệm vụ chéo đã chứng minh sự cải thiện ấn tượng về khả năng học zero-shot hoặc few-shot của LMs (xem Hình 2f). Những nghiên cứu này cho thấy rằng việc trình bày các hướng dẫn/mẫu gợi ý phù hợp cho LMs thông qua huấn luyện trên một loạt nhiệm vụ NLP cải thiện hiệu suất hạ nguồn của chúng trên các nhiệm vụ được giữ lại. Mặc dù những công trình này huấn luyện LMs với các mục tiêu khác nhau từ các giai đoạn tiền huấn luyện, chúng tôi hiểu "tinh chỉnh LMs trên một loạt nhiệm vụ NLP" như một loại tiền huấn luyện tiếp tục đặc biệt. Do đó, chúng tôi giả thuyết rằng việc trình bày cả văn bản liên quan đến nhiệm vụ và hướng dẫn/mẫu gợi ý cho LMs có thể giảm bớt các vấn đề nêu trên đối với tiền huấn luyện tiếp tục thông thường và có lợi cho hiệu suất nhiệm vụ đích. Thay vì cải thiện khả năng tổng quát hóa của LMs với các mục tiêu giám sát, công việc của chúng tôi đặt trọng tâm lớn hơn vào việc nâng cao hiệu suất nhiệm vụ đích cụ thể với các mục tiêu tiền huấn luyện không giám sát.

Trong công trình này, chúng tôi đề xuất Tiền Huấn Luyện Tiếp Tục Dựa trên Gợi ý (PCP) (§3), tích hợp các hướng dẫn/mẫu gợi ý vào văn bản liên quan đến nhiệm vụ với nhãn vàng hoặc giả (xem Hình 2g). Các thí nghiệm của chúng tôi chứng minh rằng PCP liên tục cải thiện hiệu suất của các phương pháp FT dựa trên gợi ý tiên tiến [28,100] trong cả môi trường bán và đầy đủ giám sát, bao gồm cả nhiệm vụ câu đơn và nhiệm vụ cặp câu, và rằng những cải thiện hiệu suất từ PCP vượt quá những cải thiện từ tiền huấn luyện tiếp tục thông thường (TAPT) với một biên độ đáng kể (§4.2). Trong trường hợp thuận lợi nhất, PCP tăng hiệu suất của FT dựa trên gợi ý hơn 20% tuyệt đối trong khi TAPT dẫn đến sự giảm hiệu suất 9,2%. Hơn nữa, kết quả của chúng tôi cho thấy PCP vượt trội hơn các phương pháp bán giám sát tiên tiến [80,94,96,99,12] với sự đơn giản hơn, loại bỏ nhu cầu về quá trình lặp và tăng cường dữ liệu bổ sung (§4.3). Ngoài ra, phân tích của chúng tôi cho thấy PCP có thể cải thiện hiệu quả hiệu suất của FT dựa trên gợi ý chỉ với hàng trăm ví dụ không nhãn. Trong khi đó, phân tích của chúng tôi khám phá giới hạn hiệu suất dưới của PCP và tiết lộ rằng những lợi thế của PCP tồn tại qua các kích thước khác nhau của mô hình và tập dữ liệu (§4.4). Cuối cùng, chúng tôi phác thảo những hạn chế của nghiên cứu và đề xuất các hướng cho nghiên cứu tương lai (§6).

Tóm lại, những đóng góp chính của bài báo này như sau:
• Nghiên cứu của chúng tôi chứng minh thực nghiệm rằng tiền huấn luyện tiếp tục thông thường có thể không hiệu quả như ban đầu nghĩ và thậm chí có thể tác động tiêu cực đến hiệu suất tinh chỉnh, đặc biệt trong các nhiệm vụ cặp câu hoặc khi sử dụng FT dựa trên gợi ý;
• Đánh giá của chúng tôi trên 21 nhiệm vụ phân loại và hồi quy NLP cho thấy phương pháp PCP đề xuất của chúng tôi cung cấp một lựa chọn vượt trội so với tiền huấn luyện tiếp tục thông thường cho FT dựa trên gợi ý. Phương pháp này liên tục mang lại cải thiện hiệu suất trong các thiết lập mô hình và tập dữ liệu đa dạng, ngay cả với chỉ vài trăm ví dụ không nhãn. Hơn nữa, nó có thể vượt trội hơn các phương pháp bán giám sát tiên tiến với sự đơn giản hóa lớn hơn;
• Kết quả của chúng tôi cho thấy hiệu quả của việc trình bày cả văn bản liên quan đến nhiệm vụ và mẫu/hướng dẫn cho LMs thông qua các mục tiêu tiền huấn luyện không giám sát về việc cải thiện hiệu suất của FT dựa trên gợi ý trên các nhiệm vụ hạ nguồn. Theo hiểu biết của chúng tôi, đây là công trình đầu tiên thực hiện điều chỉnh hướng dẫn thông qua các mục tiêu không giám sát.

2 Nền tảng
Giả sử chúng ta tập trung vào các LMs được huấn luyện với mục tiêu mô hình ngôn ngữ che giấu (MLM) [25,53]. Cho X={x1, x2, ..., xN} là một chuỗi các token, trong đó N đại diện cho tổng số token. LMs được thiết kế để mã hóa văn bản đầu vào X thành một chuỗi tương ứng của các vector ẩn {hi∈Rd}. Như được hiển thị trong Hình 2a, FT dựa trên CLS thông thường [25,35,76] huấn luyện vector đầu ra h tương ứng với token [CLS] với một lớp đầu bổ sung (ví dụ, một lớp MLP). Tuy nhiên, có sự khác biệt giữa mục tiêu tiền huấn luyện (xem Hình 2c) và mục tiêu FT dựa trên CLS, điều này đã dẫn đến nghiên cứu về các kỹ thuật dựa trên gợi ý để có hiệu suất LM tốt hơn.

FT dựa trên gợi ý được hình thức hóa như một bài toán MLM trong đó mục tiêu là dự đoán các token bị che giấu [73,74]. Cụ thể, văn bản đầu vào X được điều kiện hóa với một mẫu gợi ý cụ thể ˜X=T(X), bao gồm một token đặc biệt [MASK]. FT dựa trên gợi ý sau đó ánh xạ vector đầu ra liên kết với token [MASK] đến một từ nhãn. Xác suất dự đoán lớp y∈Y được tính như:

p(y|X) = p([MASK] = M(y)|˜X), (1)

trong đó verbalizer M:Y → V là một ánh xạ từ không gian nhãn nhiệm vụ đến các từ riêng lẻ trong từ vựng V.

FT dựa trên gợi ý có thể sử dụng mẫu gợi ý cứng hoặc mềm T, với các từ nhãn có thể là một phần của mẫu gợi ý [36,100]. Mẫu gợi ý cứng [73,28,78] yêu cầu thiết kế cẩn thận các gợi ý và từ nhãn cho mỗi nhiệm vụ. Việc sử dụng gợi ý cứng, tuy nhiên, được phát hiện là không tối ưu và nhạy cảm với việc lựa chọn gợi ý [102,52]. Gợi ý mềm [52,100] sau đó được đề xuất để sử dụng các token không sử dụng từ từ vựng V hoặc các token bổ sung như các embedding có thể điều chỉnh cho mẫu gợi ý và có thể được huấn luyện trực tiếp với sự giám sát cụ thể cho nhiệm vụ. Thiết kế này cho phép các embedding token trong mẫu gợi ý được cập nhật độc lập với các embedding từ cụ thể sau khi khởi tạo, do đó giảm nỗ lực tìm kiếm các mẫu gợi ý và từ nhãn.

3 Phương pháp của chúng tôi: Tiền Huấn Luyện Tiếp Tục Dựa trên Gợi ý (PCP)
Trong phần này, chúng tôi giới thiệu phương pháp đề xuất, Tiền Huấn Luyện Tiếp Tục Dựa trên Gợi ý (PCP), nhằm cải thiện hiệu suất của LMs trên các nhiệm vụ hạ nguồn thông qua tiền huấn luyện tiếp tục với mẫu gợi ý, như được hiển thị trong Hình 2g. Cho L≜{(X1, y1), . . . , (Xn, yn)} biểu thị n ví dụ có nhãn và U≜{X′1, . . . , X′m} biểu thị m ví dụ không nhãn. Phương pháp của chúng tôi bao gồm hai bước chính, được mô tả dưới đây.

Bước 1: Xây dựng Corpus Tiền Huấn Luyện Tiếp Tục. Ban đầu, chúng tôi chọn một mô hình F, được tiền huấn luyện với mục tiêu MLM và được tham số hóa bởi Θ. Sau đó chúng tôi huấn luyện mô hình này bằng FT dựa trên gợi ý, tối thiểu hóa hàm mất mát đích ℓ trên các ví dụ có nhãn L, như được minh họa trong Hình 2b:

L(L) = ΣXi,yi∈L ℓ(yi, F(T(Xi),Θ)), (2)

Tiếp theo, chúng tôi sử dụng mô hình đã huấn luyện F với các tham số đã học Θ′ để tạo ra các dự đoán (được gọi là "nhãn giả") trên các mẫu không nhãn U:

y′i = F(T(X′i),Θ′), (3)

Đối với mỗi ví dụ văn bản X và nhãn liên kết (vàng hoặc giả) y của nó, chúng tôi tạo một ví dụ cho PCP đề xuất của chúng tôi là Xpcp=T(X,M(y)), trong đó vị trí [MASK] ban đầu được thay thế bằng M(y). Điều này dẫn đến một corpus mới, C={Xpcpi}n+mi=1. Trong thiết lập giám sát đầy đủ, m=0 và tất cả ví dụ sử dụng nhãn vàng.

--- TRANG 4 ---
Bước 2: Thực hiện tiền huấn luyện tiếp tục và FT dựa trên gợi ý. Sau đó chúng tôi tiếp tục tiền huấn luyện thêm một mô hình khác G, được tham số hóa bởi Θ, sử dụng mục tiêu MLM trên corpus mới được tạo C, để có được checkpoint PCP Φ (xem Hình 2d). Cuối cùng, chúng tôi huấn luyện mô hình G, được khởi tạo bởi Φ, sử dụng Phương trình 2 với FT dựa trên gợi ý cho các nhiệm vụ hạ nguồn.

So với tiền huấn luyện tiếp tục thông thường, PCP không yêu cầu bất kỳ sửa đổi nào đối với kiến trúc mô hình hoặc quá trình huấn luyện. Sự khác biệt duy nhất là việc thêm một vài token bổ sung vào văn bản đầu vào trong quá trình tiền huấn luyện tiếp tục. Sửa đổi này không cản trở hiệu quả của phương pháp, tức là cả tiền huấn luyện tiếp tục thông thường và PCP đều duy trì mức độ hiệu quả bằng nhau.

Trong nghiên cứu này, chúng tôi chủ yếu tập trung vào các LMs được tiền huấn luyện với mục tiêu MLM [53]. Đáng chú ý là việc khám phá toàn diện các kiến trúc khác [25,70,14,65] vẫn là một hướng cho nghiên cứu tương lai. Tuy nhiên, xem xét các phương pháp tinh chỉnh dựa trên gợi ý [52,47,51] đã được thích ứng cho các kiến trúc mô hình và mục tiêu tiền huấn luyện khác nhau [25,70,14,65]. Điều này ngụ ý rằng việc mở rộng phương pháp của chúng tôi sang các kiến trúc thay thế sẽ là một công việc khả thi.

4 Thí nghiệm và Kết quả
Trong phần này, chúng tôi đánh giá phương pháp PCP đề xuất bằng cách so sánh nó với tiền huấn luyện tiếp tục thông thường và bốn phương pháp bán giám sát tiên tiến. Chúng tôi đánh giá hiệu suất tương đối của chúng qua 21 nhiệm vụ phân loại và hồi quy NLP khác nhau, bao gồm các nhiệm vụ câu đơn và cặp câu. Chúng tôi tiến hành phân tích bổ sung liên quan đến giới hạn hiệu suất dưới của PCP và hiệu quả của PCP qua các tập dữ liệu và kích thước mô hình khác nhau.

4.1 Thiết lập Thí nghiệm
Tập dữ liệu. Nghiên cứu của chúng tôi tiến hành phân tích toàn diện 21 tập dữ liệu NLP, bao gồm các nhiệm vụ phân loại và hồi quy. Theo các nghiên cứu trước đây [28,36,100] về FT dựa trên gợi ý, chúng tôi rút ra 8 nhiệm vụ câu đơn và 8 nhiệm vụ cặp câu tiếng Anh từ điểm chuẩn GLUE [87], SNLI [13], và 6 nhiệm vụ phân loại câu được sử dụng rộng rãi khác (tức là SST-5, MR, CR, MPQA, Subj, TREC). Ngoài ra, chúng tôi sử dụng 5 điểm chuẩn phổ biến cho học bán giám sát từ nghiên cứu trước đây [34,21,94,48,29,77], bao gồm IMDB [55], AG NEWS [101], YELP REVIEW1, YAHOO! ANSWER [18], và AMAZON REVIEW [57]. Xem chi tiết tập dữ liệu trong Phụ lục §A. Chúng tôi huấn luyện mô hình với hai thiết lập khác nhau: (1) thiết lập giám sát đầy đủ, trong đó chúng tôi huấn luyện mô hình với toàn bộ tập huấn luyện; và (2) thiết lập bán giám sát, trong đó chúng tôi lấy mẫu cùng một lượng dữ liệu có nhãn mỗi lớp từ toàn bộ tập huấn luyện. Chúng tôi lấy mẫu lại dữ liệu có nhãn sử dụng cùng năm seed cho tất cả các phương pháp so sánh và báo cáo hiệu suất trung bình với thanh lỗi.

Tất cả Phương pháp So sánh. Trong nghiên cứu của chúng tôi, chúng tôi chủ yếu thí nghiệm sử dụng các mô hình ROBERTA-BASE (125M) và ROBERTA-LARGE (355M). Chúng tôi sử dụng FT dựa trên CLS thông thường và hai phương pháp FT dựa trên gợi ý tiên tiến: (1) "FT dựa trên CLS": tinh chỉnh với biểu diễn token [CLS] với một lớp MLP bổ sung; (2) "FT dựa trên gợi ý (cứng)": tinh chỉnh với các gợi ý và từ nhãn thủ công chất lượng cao hoặc được tạo tự động [73,28]; và (3) "FT dựa trên gợi ý (mềm)": tinh chỉnh với gợi ý mềm sử dụng các token bổ sung cho cả mẫu và từ nhãn [100]. Vì mục tiêu của FT gợi ý mềm là tối thiểu hóa sự phụ thuộc vào các mẫu được thiết kế bởi con người, chúng tôi thống nhất mẫu cho tất cả các nhiệm vụ ở đây. Xem chi tiết mẫu cụ thể được sử dụng cho mỗi tập dữ liệu trong Phụ lục §B. Chúng tôi huấn luyện ba loại phương pháp FT này từ ba loại checkpoint khác nhau để đánh giá hiệu quả tương đối của chúng: (i) checkpoint ROBERTA-LARGE sẵn có; (ii) checkpoint tiền huấn luyện thích ứng nhiệm vụ (TAPT) [35] (đại diện cho tiền huấn luyện tiếp tục thông thường). Đối với các nhiệm vụ cặp câu, chúng tôi nối hai câu làm một ví dụ đầu vào; và (iii) checkpoint PCP đề xuất, thu được trong §3. Đối với cả (ii) và (iii), chúng tôi thực hiện MLM trên tất cả các tập huấn luyện đầy đủ trừ MNLI, MNLI-mm, SNLI, QNLI, và QQP, trong đó chúng tôi chọn tối đa 10k ví dụ không nhãn từ các tập huấn luyện đầy đủ (xem thí nghiệm bổ sung trên các tập huấn luyện đầy đủ trong Phụ lục §D). Ngoài ra, chúng tôi so sánh PCP đề xuất với bốn phương pháp bán giám sát tiên tiến, bao gồm FixMatch [80], Dash [96], FlexMatch [99], và AdaMatch [12] (xem mô tả của các phương pháp này trong Phụ lục §C), trong đó back-translation [64] được sử dụng để tăng cường dữ liệu như các công trình trước đây [94,77] và FT dựa trên gợi ý (cứng) được sử dụng làm xương sống. Xem chi tiết siêu tham số và triển khai trong Phụ lục §E.

1https://www.yelp.com/dataset

--- TRANG 5 ---
Nhiệm vụ Câu Đơn
SST-2 SST-5 MR CR MPQA Subj TREC CoLA
(acc) (acc) (acc) (acc) (acc) (acc) (acc) (Matt.)
Đa số (đầy đủ) 50.9 23.1 50.0 50.0 50.0 50.0 18.8 0.0
FT dựa trên gợi ý zero-shot† 83.6 35.0 80.8 79.5 67.6 51.4 32.0 2.0
học trong ngữ cảnh 84.81.3 30.60.9 80.51.7 87.40.8 63.82.1 53.61.0 26.22.4 −1.52.4

Học Giám sát Đầy đủ
FT dựa trên CLS 95.1 59.4 90.8 90.8 89.1 96.9 96.8 54.3
+ TAPT 96.0↑0.9 60.6↑1.2 91.4↑0.6 91.0↑0.2 89.9↑0.8 96.9↑0.0 97.6↑0.8 43.6↓10.7
FT dựa trên gợi ý (cứng) 95.2 60.0 90.8 92.4 89.4 95.9 97.8 54.7
+ TAPT 93.5↓1.7 60.4↑0.4 90.3↓0.5 90.8↓1.6 89.5↑0.1 95.9↑0.0 97.6↓0.2 44.0↓10.7
+ PCP (của chúng tôi) 95.5↑0.3 60.5↑0.5 91.7↑0.9 92.8↑0.4 89.6↑0.2 96.8↑0.9 97.8↑0.0 56.0↑1.3
FT dựa trên gợi ý (mềm) 94.2 59.8 90.4 92.7 87.8 96.4 97.4 61.3
+ TAPT 92.7↓1.5 59.5↓0.3 91.8↑1.4 92.5↓0.2 89.5↑1.7 96.8↑0.4 97.8↑0.4 52.6↓8.7
+ PCP (của chúng tôi) 94.3↑0.1 60.7↑0.9 91.8↑1.4 92.8↑0.1 90.4↑2.6 97.1↑0.7 98.0↑0.6 62.0↑0.7

Học Bán Giám sát
FT dựa trên CLS 81.22.7 41.71.3 76.33.2 79.53.8 65.112.6 91.70.4 80.35.8 26.77.8
+ TAPT 88.21.5↑7.0 43.42.6↑1.7 86.10.7↑9.8 86.22.4↑6.7 73.74.4↑8.6 94.21.5↑2.5 80.46.4↑0.1 1.92.4↓24.8
FT dựa trên gợi ý (cứng) 92.71.3 46.71.5 86.21.2 90.70.8 80.86.9 91.01.1 84.74.4 7.25.5
+ TAPT 92.91.0↑0.2 48.91.1↑2.2 88.40.5↑2.2 89.82.3↓0.9 84.64.9↑3.8 93.51.1↑2.5 85.22.9↑0.5 1.43.5↓5.8
+ PCP (của chúng tôi) 93.60.3↑0.9 50.91.3↑4.2 89.00.6↑2.8 92.30.4↑1.6 87.90.5↑7.1 95.70.4↑4.7 90.63.5↑5.9 25.02.9↑17.8
FT dựa trên gợi ý (mềm) 92.51.2 48.00.7 86.81.4 90.81.3 81.26.8 90.32.1 83.03.0 4.93.7
+ TAPT 93.40.5↑0.9 47.01.2↓1.0 88.50.8↑1.7 89.63.4↓1.2 83.45.1↑2.2 93.30.7↑3.0 84.52.4↑1.5 2.11.8↓2.8
+ PCP (của chúng tôi) 93.90.3↑1.4 50.71.3↑2.7 89.80.6↑3.0 92.00.5↑1.2 88.30.5↑7.1 94.90.9↑4.6 88.65.4↑5.6 21.52.5↑16.6

Nhiệm vụ Cặp Câu
MNLI MNLI-mm SNLI QNLI RTE MRPC QQP STS-B
(acc) (acc) (acc) (acc) (acc) (F1) (F1) (Pear.)
Đa số (đầy đủ) 32.7 33.0 33.8 49.5 52.7 81.2 0.0 -
FT dựa trên gợi ý zero-shot† 50.8 51.7 49.5 50.8 51.3 61.9 49.7 -3.2
học trong ngữ cảnh 52.00.7 53.40.6 47.10.6 53.80.4 60.41.4 45.76.0 36.15.2 14.32.8

Học Giám sát Đầy đủ
FT dựa trên CLS 82.1 82.7 88.1 90.2 83.4 91.9 79.7 91.2
+ TAPT 81.0↓1.1 82.0↓0.7 86.7↓1.4 85.6↓4.6 83.4↑0.0 91.6↓0.3 80.2↑0.5 90.4↓0.8
FT dựa trên gợi ý (cứng) 85.4 85.8 89.0 89.6 88.1 93.1 73.8 91.5
+ TAPT 82.8↓2.6 83.2↓2.6 88.3↓0.7 90.9↑1.3 83.8↓4.3 92.7↓0.4 78.2↑4.4 91.2↓0.3
+ PCP (của chúng tôi) 86.5↑1.1 86.2↑0.4 89.5↑0.5 91.5↑1.9 88.5↑0.4 93.3↑0.2 79.6↑5.8 91.9↑0.4
FT dựa trên gợi ý (mềm) 84.6 85.4 89.0 89.5 84.5 92.4 73.9 91.6
+ TAPT 83.5↓1.1 84.1↓1.3 88.3↓0.7 90.9↑1.4 82.7↓1.8 92.6↑0.2 79.9↑6.0 90.9↓0.7
+ PCP (của chúng tôi) 85.7↑1.1 86.0↑0.6 89.5↑0.5 91.0↑1.5 85.5↑1.0 92.6↑0.2 79.6↑5.7 91.7↑0.1

Học Bán Giám sát
FT dựa trên CLS 46.20.6 48.51.0 45.65.4 61.48.2 54.24.3 73.28.7 58.53.8 46.016.3
+ TAPT 36.01.0↓10.2 36.31.1↓12.2 45.73.6↑0.1 55.62.7↓5.8 53.41.0↓0.8 67.78.5↓5.5 55.04.1↓3.5 48.119.6↑2.1
FT dựa trên gợi ý (cứng) 67.31.3 68.91.2 76.71.6 66.54.3 68.33.1 75.91.6 66.81.9 67.78.1
+ TAPT 50.73.9↓16.6 52.24.6↓16.7 74.53.1↓2.2 55.31.1↓11.2 59.92.7↓8.4 63.26.3↓12.7 58.22.6↓8.6 63.18.0↓4.6
+ PCP (của chúng tôi) 75.61.4↑8.3 76.80.9↑7.9 82.41.3↑5.7 85.10.8↑18.6 70.22.7↑1.9 80.73.3↑4.8 71.81.3↑5.0 71.58.4↑3.8
FT dựa trên gợi ý (mềm) 62.72.2 65.91.2 75.40.8 64.24.7 68.23.7 73.010.6 66.51.8 63.76.8
+ TAPT 46.63.9↓16.1 49.56.8↓16.4 72.12.0↓3.3 55.02.3↓9.2 58.42.4↓9.8 63.35.8↓9.7 58.31.9↓8.2 65.36.3↑1.6
+ PCP (của chúng tôi) 75.40.7↑12.7 76.80.3↑10.9 82.61.2↑7.2 84.32.0↑20.1 70.43.2↑2.2 80.02.4↑7.0 72.31.2↑5.8 71.47.8↑7.7

Tóm tắt kết quả: xác suất cải thiện hiệu suất cho TAPT và PCP
Nhiệm vụ Câu Đơn Nhiệm vụ Cặp Câu
Checkpoint TAPT (đầy đủ) PCP (đầy đủ) TAPT (bán) PCP (bán) TAPT (đầy đủ) PCP (đầy đủ) TAPT (bán) PCP (bán)
FT dựa trên CLS 87.5 (7/8) - 87.5 (7/8) - 25.0 (2/8) - 25.0 (2/8) -
FT dựa trên gợi ý (cứng) 37.5 (3/8) 100 (8/8) 75.0 (6/8) 100 (8/8) 25.0 (2/8) 100 (8/8) 0.0 (0/8) 100 (8/8)
FT dựa trên gợi ý (mềm) 50.0 (4/8) 100 (8/8) 62.5 (5/8) 100 (8/8) 37.5 (3/8) 100 (8/8) 12.5 (1/8) 100 (8/8)

Bảng 1: So sánh giữa PCP và tiền huấn luyện tiếp tục thông thường (TAPT) sử dụng ROBERTA-LARGE. Tóm tắt làm nổi bật tỷ lệ phần trăm tác động tích cực mang lại bởi PCP và TAPT. Trung bình và độ lệch chuẩn trên các tập kiểm tra được báo cáo qua 5 seed khác nhau. Trong học bán giám sát, 16 ví dụ mỗi lớp được sử dụng để huấn luyện, phù hợp với các nghiên cứu trước đây [28,52,100]. Mũi tên xanh và đỏ chỉ ra các thay đổi so với các baseline FT không sử dụng TAPT hoặc PCP. †đại diện cho việc không sử dụng ví dụ huấn luyện. Ba baseline bổ sung có nguồn từ [28] được bao gồm, trong đó "Đa số" đề cập đến lớp đa số, và "học trong ngữ cảnh" chỉ ra việc sử dụng học trong ngữ cảnh [14] với ROBERTA-LARGE, mà không cập nhật bất kỳ tham số nào.

4.2 So sánh PCP và tiền huấn luyện tiếp tục thông thường
Bảng 1 trình bày và tóm tắt kết quả thí nghiệm của chúng tôi trên 8 nhiệm vụ câu đơn và 8 nhiệm vụ cặp câu. Dưới đây chúng tôi đi sâu vào hai phát hiện chính của chúng tôi.

#1. TAPT không luôn có lợi cho các nhiệm vụ cặp câu, cũng như khi sử dụng FT dựa trên gợi ý. Ban đầu, chúng tôi xem xét lại tác động của TAPT (đại diện cho tiền huấn luyện tiếp tục thông thường) đối với FT dựa trên CLS, như được hiển thị trong Bảng 1. Kết quả thí nghiệm của chúng tôi phù hợp với các nghiên cứu trước đây

--- TRANG 6 ---
Phương pháp IMDB AG NEWS YELP REVIEW YAHOO! ANSWER AMAZON REVIEW Trung bình
20 100 40 200 40 200 40 200 40 200
DASH [96] 93.340.7 93.300.6 85.002.9 87.900.3 47.442.2 58.851.0 60.074.7 66.460.9 44.092.6 53.951.0 69.04
FIXMATCH [80] 95.260.4 94.280.5 85.441.1 88.210.4 47.261.2 58.510.3 61.566.9 68.370.7 44.262.0 52.331.7 69.55
FLEXMATCH [99] 95.220.3 94.840.4 85.331.4 88.570.6 50.602.5 58.341.9 58.093.7 66.431.3 45.483.1 54.191.1 69.71
ADAMATCH [12] 95.200.5 94.940.1 85.792.1 88.720.8 50.422.7 58.951.9 63.680.7 68.090.8 44.663.4 53.050.6 70.35
FT dựa trên gợi ý (cứng) 86.782.1 89.521.6 84.871.1 86.990.3 46.694.2 58.270.7 60.631.5 66.941.1 44.341.5 57.010.4 68.20
+ PCP (của chúng tôi) 92.491.2 94.240.9 87.061.0 88.940.4 52.924.5 63.151.3 65.581.8 70.220.9 53.443.0 59.641.6 72.77
FT dựa trên gợi ý (mềm) 88.142.9 90.801.5 85.651.3 87.660.3 45.433.4 57.121.0 61.181.5 67.850.8 44.523.6 55.031.5 68.34
+ PCP (của chúng tôi) 93.531.5 94.360.7 87.260.8 88.960.6 50.663.3 62.921.0 65.261.5 70.030.9 52.783.2 59.160.8 72.49
FT dựa trên gợi ý (cứng) † 95.60 91.06 68.71 74.30 63.85 78.70
FT dựa trên gợi ý (mềm) † 95.50 91.10 69.63 75.66 63.32 79.04

Bảng 2: So sánh giữa PCP và bốn phương pháp bán giám sát sử dụng ROBERTA-LARGE. Mỗi tập dữ liệu được đánh giá với hai kích thước dữ liệu có nhãn khác nhau và toàn bộ tập huấn luyện được sử dụng làm dữ liệu không nhãn. †chỉ ra rằng toàn bộ tập huấn luyện được sử dụng làm dữ liệu có nhãn. Chúng tôi báo cáo điểm Macro-F1 trung bình trên tập kiểm tra qua năm seed, với độ lệch chuẩn là chỉ số dưới. Đối với mỗi cột, màu xanh đại diện cho hiệu suất tốt nhất và màu cam đại diện cho hiệu suất tốt thứ hai.

[39,35,77], cho thấy TAPT nói chung cải thiện hiệu suất của FT dựa trên CLS trên 7 trong 8 nhiệm vụ câu đơn trong cả thiết lập bán giám sát và giám sát đầy đủ. Tuy nhiên, thú vị là chúng tôi quan sát thấy TAPT ảnh hưởng tiêu cực đến hiệu suất của FT dựa trên CLS trên 6 trong 8 nhiệm vụ cặp câu, như được tóm tắt trong Hình 1 và ở cuối Bảng 1. Phát hiện này ngụ ý rằng tiền huấn luyện tiếp tục thông thường (TAPT) có thể không có lợi cho các nhiệm vụ cặp câu.

Hơn nữa, điều tra của chúng tôi tiết lộ rằng TAPT có thể ảnh hưởng tiêu cực đến FT dựa trên gợi ý. Cụ thể, trong thiết lập giám sát đầy đủ, TAPT dẫn đến giảm hiệu suất trên 11 trong 16 nhiệm vụ cho FT dựa trên gợi ý (cứng) và trên 9 trong 16 nhiệm vụ cho FT dựa trên gợi ý (mềm). Trong tình huống thuận lợi nhất, TAPT nâng cao hiệu suất của FT dựa trên gợi ý (mềm) từ 73,9% lên 79,9% trên tập dữ liệu QQP. Ngược lại, trong tình huống ít thuận lợi nhất, TAPT giảm hiệu suất của FT dựa trên gợi ý (cứng) từ 54,7% xuống 44,0% trên tập dữ liệu CoLA. Trong thiết lập bán giám sát, TAPT dẫn đến sự giảm hiệu suất trên 12 trong 16 nhiệm vụ cho cả FT dựa trên gợi ý (cứng) và FT dựa trên gợi ý (mềm) (xem tóm tắt kết quả trong Hình 1 và ở cuối Bảng 1). Đặc biệt, đối với các nhiệm vụ cặp câu, TAPT dẫn đến sự giảm tuyệt đối trung bình 9,5% trong hiệu suất cho FT dựa trên gợi ý. Những kết quả này cho thấy hiệu quả của TAPT thay đổi qua các nhiệm vụ khác nhau và không thể được áp dụng một cách phổ quát. Chúng tôi tiến hành thí nghiệm bổ sung để xác nhận những hạn chế của TAPT tồn tại qua các kích thước khác nhau của corpus tiền huấn luyện trong Phụ lục D.

#2. PCP mang lại cải thiện nhất quán và đáng kể trong cả thiết lập bán và đầy đủ giám sát. Như được mô tả trong Bảng 1, các thí nghiệm của chúng tôi bao gồm 16 tập dữ liệu trong cả thiết lập bán và đầy đủ giám sát, bao gồm các nhiệm vụ câu đơn và nhiệm vụ cặp câu, tiết lộ rằng (1) PCP liên tục tăng cường hiệu suất của FT dựa trên gợi ý; và rằng (2) những cải thiện hiệu suất đạt được bởi PCP liên tục vượt quá những cải thiện thu được bởi TAPT với một biên độ đáng kể. Cụ thể, so với FT dựa trên gợi ý, PCP dẫn đến hơn 1,0% cải thiện tuyệt đối trung bình trong thiết lập giám sát đầy đủ và đóng góp vào một sự tăng cường hiệu suất tuyệt đối trung bình 6,8% trong thiết lập bán giám sát qua 16 nhiệm vụ. So với TAPT, PCP mang lại hơn 1,8% cải thiện tuyệt đối trung bình trong thiết lập giám sát đầy đủ và đóng góp vào một sự tăng hiệu suất tuyệt đối trung bình 11,2% trong thiết lập bán giám sát qua 16 nhiệm vụ. Đáng chú ý, PCP có thể tạo ra những cải thiện đáng kể trong một số tập dữ liệu nhất định. Ví dụ, nó nâng hiệu suất của FT dựa trên gợi ý (cứng) từ 7,2% (Hệ số Tương quan Matthews) lên 25,0%, trong khi TAPT thậm chí giảm hiệu suất của FT dựa trên gợi ý. Ngoài ra, PCP cải thiện hiệu suất của FT dựa trên gợi ý (mềm) trên tập dữ liệu QNLI từ 64,2% lên 84,3% với cải thiện 31%, trong khi TAPT dẫn đến sự giảm hiệu suất tuyệt đối 9,2%. Chúng tôi quy những cải thiện này cho việc trình bày mẫu gợi ý cho LMs thông qua giai đoạn tiền huấn luyện thêm, điều này ngụ ý rằng việc chỉ hiển thị các văn bản liên quan đến nhiệm vụ cho LMs có thể không phải là phương pháp tối ưu cho FT dựa trên gợi ý.

4.3 So sánh PCP và các phương pháp bán giám sát tiên tiến
Bảng 2 trình bày kết quả thí nghiệm của chúng tôi trên năm tập dữ liệu, so sánh PCP đề xuất với các phương pháp bán giám sát tiên tiến. Dưới đây chúng tôi đi sâu vào phát hiện chính của chúng tôi với một cuộc thảo luận.

PCP đề xuất vượt trội hơn các phương pháp bán giám sát tiên tiến trên 4 trong 5 nhiệm vụ. Như được hiển thị trong Bảng 2, phương pháp PCP đề xuất của chúng tôi với biến thể cứng hoặc mềm của FT dựa trên gợi ý vượt trội hơn các phương pháp bán giám sát hoạt động tốt nhất trên 4 trong 5 tập dữ liệu. Đáng chú ý, FT dựa trên gợi ý (cứng) với PCP vượt trội hơn các phương pháp bán giám sát hoạt động tốt nhất (FLEXMATCH) với điểm Macro-F1 tuyệt đối 5,5% trên tập dữ liệu AMAZON REVIEW khi sử dụng 200 ví dụ huấn luyện có nhãn. Trong khi phương pháp bán giám sát hoạt động tốt nhất, FIXMATCH, vượt trội hơn PCP 1,7% trong giá trị tuyệt đối trên tập dữ liệu IMDB sử dụng 20 ví dụ có nhãn, sự khác biệt hiệu suất thu hẹp khi số lượng ví dụ huấn luyện có nhãn tăng. Nhìn chung, FT dựa trên gợi ý (cứng) và (mềm) với PCP vượt trội hơn tất cả các phương pháp bán giám sát này với cải thiện hiệu suất tuyệt đối trung bình hơn 2% qua các tập dữ liệu và kích thước tập dữ liệu có nhãn khác nhau, chứng minh hiệu quả của phương pháp đề xuất của chúng tôi.

Thảo luận. Các phương pháp bán giám sát tiên tiến thường dựa vào việc tạo nhãn giả cho các ví dụ không nhãn để huấn luyện các mô hình học sinh và giáo viên một cách lặp đi lặp lại [4,15,95,27,94,29]. Tuy nhiên, quá trình lặp này dễ bị thiên kiến xác nhận [83,2,31], có thể dẫn đến tích lũy lỗi nếu nhãn giả không chính xác ở bất kỳ bước lặp nào [49,88,31,20]. Nhiều nỗ lực đã được thực hiện để giảm thiểu thiên kiến xác nhận, chẳng hạn như chỉ sử dụng nhãn giả độ tin cậy cao [80,99,12] hoặc dựa nhiều vào tăng cường dữ liệu [94,21,11]. Trong khi những nỗ lực này làm cho quá trình huấn luyện phức tạp hơn, vấn đề vẫn khó giải quyết hoàn toàn [20,77]. Phương pháp đề xuất của chúng tôi cung cấp một cách thay thế để sử dụng nhãn giả khác với các phương pháp bán giám sát trước đây [98,58]. Thay vì dựa vào một quá trình lặp với tín hiệu giám sát trực tiếp từ nhãn giả, chúng tôi kết hợp nhãn giả thông qua tiền huấn luyện tiếp tục với một mục tiêu không giám sát (tức là MLM). Trong khi phương pháp đề xuất của chúng tôi có thể không luôn vượt trội hơn các phương pháp bán giám sát qua tất cả các điểm chuẩn, nó mang lại hiệu suất rất cạnh tranh trong khi đơn giản hóa đáng kể quá trình bằng cách loại bỏ sự cần thiết cho việc lặp và tăng cường dữ liệu bổ sung. Chúng tôi sẽ thảo luận về hiệu quả của PCP đề xuất sau này (§4.4). Ngoài ra, PCP trực giao với các phương pháp bán giám sát này và có thể được kết hợp dễ dàng bằng cách khởi tạo xương sống của chúng từ checkpoint PCP. Trong công việc tương lai, chúng tôi dự định điều tra các trường hợp sử dụng cụ thể hơn nơi PCP đề xuất của chúng tôi có thể được ưa thích hơn các phương pháp bán giám sát này.

4.4 Phân tích Sâu hơn
#1. Giới hạn dưới của hiệu suất mô hình sử dụng PCP là gì? Để hiểu giới hạn dưới của hiệu suất PCP, chúng tôi tiến hành phân tích bổ sung với hai cấu hình khác nhau của nhãn giả trong PCP: (1) tất cả nhãn giả đều không chính xác; và (2) tất cả nhãn được chọn ngẫu nhiên. Hình 3 mô tả hiệu suất sử dụng các loại nhãn giả khác nhau. Chúng tôi sử dụng FT dựa trên gợi ý mà không có PCP (được hiển thị bằng màu vàng) và với PCP (được hiển thị bằng màu đỏ) làm baseline. Kết quả thí nghiệm chỉ ra rằng việc sử dụng nhãn giả không chính xác (được hiển thị bằng màu xanh) thường dẫn đến hiệu suất kém hơn. Trong các thí nghiệm sử dụng hai FT dựa trên gợi ý trên 16 tập dữ liệu, chúng tôi thấy rằng việc sử dụng nhãn ngẫu nhiên dẫn đến kết quả cải thiện trong 19 trong 32 tình huống. Điều này cho thấy PCP với nhãn ngẫu nhiên có hơn 50% cơ hội cải thiện hiệu suất của FT dựa trên gợi ý, chỉ ra rằng giới hạn hiệu suất dưới

--- TRANG 7 ---
SST-2 (acc) SST-5 (acc) MR (acc) CR (acc) MPQA (acc) Subj (acc) TREC (acc) CoLA (Matt.) 25 0 25 50 75 100 Hiệu suất (%) (a) Nhiệm vụ Câu Đơn sử dụng FT dựa trên gợi ý (cứng)

SST-2 (acc) SST-5 (acc) MR (acc) CR (acc) MPQA (acc) Subj (acc) TREC (acc) CoLA (Matt.) 0 25 50 75 100 (b) Nhiệm vụ Câu Đơn sử dụng FT dựa trên gợi ý (mềm)

MNLI (acc) MNLI-mm (acc) SNLI (acc) QNLI (acc) RTE (acc) MRPC (F1) QQP (F1) STS-B (Pear.) 0 20 40 60 80 Hiệu suất (%) (c) Nhiệm vụ Cặp Câu sử dụng FT dựa trên gợi ý (cứng)

Nhãn Sai+FT Chỉ FT Nhãn Ngẫu nhiên+FT Nhãn Giả+FT (PCP) MNLI (acc) MNLI-mm (acc) SNLI (acc) QNLI (acc) RTE (acc) MRPC (F1) QQP (F1) STS-B (Pear.) 0 20 40 60 80 (d) Nhiệm vụ Cặp Câu sử dụng FT dựa trên gợi ý (mềm)

Hình 3: Giới hạn hiệu suất dưới của PCP, trong đó "nhãn sai" chỉ ra rằng tất cả nhãn trong PCP đều không chính xác và "nhãn ngẫu nhiên" chỉ ra rằng tất cả nhãn trong PCP được chọn ngẫu nhiên. Đối với mỗi tập dữ liệu, 16 ví dụ mỗi lớp được sử dụng làm dữ liệu có nhãn và toàn bộ tập huấn luyện được sử dụng làm dữ liệu không nhãn. Hiệu suất trung bình trên các tập kiểm tra được báo cáo qua 5 seed khác nhau.

là thỏa đáng. Ngoài ra, PCP với nhãn ngẫu nhiên cải thiện hiệu suất trên các nhiệm vụ cặp câu trong 8 trong 16 trường hợp, trong khi TAPT dẫn đến kết quả kém hơn trong 15 trong 16 trường hợp (tham khảo Bảng 1). Điều này cho thấy PCP có thể có lợi ngay cả khi sử dụng nhãn ngẫu nhiên, mang lại lợi ích trong các tình huống mà TAPT không thành công. Thú vị là, khác với nghiên cứu trước đây [60] về học trong ngữ cảnh [14], nơi LMs sử dụng nhãn ngẫu nhiên trong các cuộc thị phạm hoạt động gần như những LMs sử dụng nhãn thật, kết quả của chúng tôi cho thấy việc sử dụng nhãn giả được gán bởi một mô hình đã huấn luyện (được hiển thị bằng màu đỏ) liên tục dẫn đến hiệu suất tốt hơn, làm nổi bật tầm quan trọng của nhãn giả chính xác.

Kích thước Tập dữ liệu FT +TAPT +PCP
IMDB 23K 87.31.2 88.91.3 91.40.5
AG NEWS 100K 86.40.9 87.61.1 88.00.4
YELP REVIEW 250K 52.42.5 60.31.9 61.442.0
AMAZON REVIEW 250K 51.21.8 56.81.2 57.01.5
YAHOO! ANSWER 500K 64.90.8 64.91.1 69.01.4

Bảng 3: Kết quả Kiểm tra cho FT dựa trên gợi ý (mềm) sử dụng ROBERTA-BASE với các kích thước corpus tiền huấn luyện tiếp tục khác nhau. Macro-F1 trung bình với độ lệch chuẩn được báo cáo qua năm seed. Mô hình được huấn luyện trên tập dữ liệu IMDB sử dụng 100 ví dụ có nhãn và sử dụng 200 ví dụ có nhãn cho các tập dữ liệu khác. Hiệu suất tốt nhất cho mỗi tập dữ liệu được làm nổi bật bằng màu xanh.

#2. Yêu cầu về kích thước dữ liệu và tài nguyên tính toán cho PCP là gì? Để hiểu sâu hơn về hiệu quả của phương pháp PCP đề xuất của chúng tôi, chúng tôi tiến hành phân tích bổ sung để xác định số điểm dữ liệu cần thiết cho PCP. Hình 4 (trái) trình bày hiệu suất của các phương pháp FT dựa trên gợi ý, bao gồm cả biến thể cứng và mềm, qua bốn tập dữ liệu. Hiệu suất FT dựa trên gợi ý nói chung cải thiện khi PCP được triển khai với hơn 1000 ví dụ không nhãn, và một số cải thiện có thể được quan sát ngay cả với chỉ 100 ví dụ không nhãn. Điều này chỉ ra rằng tiền huấn luyện tiếp tục (cả TAPT và PCP) không nhất thiết đòi hỏi tính toán cao và có thể được sử dụng hiệu quả ngay cả với chỉ hàng trăm ví dụ huấn luyện. Trong các thí nghiệm của chúng tôi, việc thực hiện PCP trên 1k ví dụ không nhãn mất ít hơn 10 phút sử dụng hai GPU NVIDIA 3090 24GB, và tất cả hiệu suất PCP đạt được trong §4.2 sử dụng ít hơn 10k ví dụ không nhãn. Điều này tương phản rõ rệt với công việc trước đây [33] theo đuổi các mục tiêu tương tự (cho tinh chỉnh hiệu quả tham số) với chúng tôi nhưng sử dụng 10GB dữ liệu văn bản tiếng Anh.

#3. Sức mạnh của quy mô. Phân tích thực nghiệm của chúng tôi điều tra tác động của việc tăng kích thước LM xương sống đối với hiệu suất mô hình sử dụng PCP. Hình 4 (phải) hiển thị kết quả của các phương pháp FT dựa trên gợi ý, bao gồm biến thể cứng và mềm, được huấn luyện sử dụng TAPT hoặc PCP, trên bốn tập dữ liệu. Hiệu suất của phương pháp PCP cải thiện đáng kể khi kích thước LM xương sống mở rộng, phù hợp với quy luật mở rộng được quan sát trong LMs [41,37]. Hơn nữa, phương pháp PCP liên tục vượt trội hơn các phương pháp baseline khác, làm nổi bật những lợi thế của PCP qua các kích thước mô hình khác nhau.

--- TRANG 8 ---
0 100 1000 6920 92.0 92.5 93.0 93.5 94.0 Độ chính xác Kiểm tra (%) (a) SST-2

0 100 1000 8662 86.0 87.0 88.0 89.0 90.0 (b) MR

ROBERTA-Base ROBERTA-Large 88 89 90 91 92 93 94 Độ chính xác Kiểm tra (%) (e) SST-2

ROBERTA-Base ROBERTA-Large 82 84 86 88 90 (f) MR

0 100 1000 8606 Kích thước Dữ liệu Không nhãn 80.0 82.0 84.0 86.0 88.0 90.0 Độ chính xác Kiểm tra (%) (c) MPQA

0 100 1000 5452 Kích thước Dữ liệu Không nhãn 82.0 84.0 86.0 88.0 90.0 92.0 (d) TREC

ROBERTA-Base ROBERTA-Large Loại Mô hình 76 78 80 82 84 86 88 90 Độ chính xác Kiểm tra (%) (g) MPQA

FT dựa trên gợi ý (Cứng) FT dựa trên gợi ý (Mềm) FT dựa trên gợi ý (Cứng) + TAPT FT dựa trên gợi ý (Mềm) + TAPT FT dựa trên gợi ý (Cứng) + PCP FT dựa trên gợi ý (Mềm) + PCP ROBERTA-Base ROBERTA-Large Loại Mô hình 76 78 80 82 84 86 88 90 92 (h) TREC

Hình 4: (Trái) Ảnh hưởng của các kích thước dữ liệu không nhãn khác nhau sử dụng ROBERTA-LARGE. (Phải) Ảnh hưởng của Quy luật Mở rộng, trong đó ROBERTA-BASE(123M) và ROBERTA-LARGE (354M). Tất cả các phương pháp so sánh được huấn luyện với 16 ví dụ mỗi lớp cho mỗi tập dữ liệu.

bound là thỏa đáng. Ngoài ra, PCP với nhãn ngẫu nhiên cải thiện hiệu suất trên các nhiệm vụ cặp câu trong 8 trong 16 trường hợp, trong khi TAPT dẫn đến kết quả kém hơn trong 15 trong 16 trường hợp (tham khảo Bảng 1). Điều này cho thấy PCP có thể có lợi ngay cả khi sử dụng nhãn ngẫu nhiên, mang lại lợi ích trong các tình huống mà TAPT thất bại. Thú vị là, khác với nghiên cứu trước đây [60] về học trong ngữ cảnh [14], nơi LMs sử dụng nhãn ngẫu nhiên trong các cuộc thị phạm hoạt động gần như những LMs sử dụng nhãn thực tế, kết quả của chúng tôi cho thấy việc sử dụng nhãn giả được gán bởi một mô hình đã huấn luyện (được hiển thị bằng màu đỏ) liên tục dẫn đến hiệu suất tốt hơn, làm nổi bật tầm quan trọng của nhãn giả chính xác.

#4. Tác động của corpus tiền huấn luyện tiếp tục lớn hơn đối với hiệu suất mô hình sử dụng PCP và TAPT. Ở đây chúng tôi mở rộng điều tra của chúng tôi để xem liệu lợi thế của phương pháp PCP đề xuất có tồn tại khi kích thước của corpus tiền huấn luyện tiếp tục tăng. Bảng 3 trình bày hiệu suất của FT dựa trên gợi ý (mềm), được huấn luyện sử dụng TAPT hoặc PCP, qua năm tập dữ liệu với các kích thước khác nhau của ví dụ huấn luyện không nhãn. Những kết quả thí nghiệm này phù hợp với các phát hiện của chúng tôi trong §4.2 và §4.3, cho thấy phương pháp PCP đề xuất liên tục vượt trội hơn hiệu suất mô hình sử dụng TAPT ngay cả khi corpus lớn hơn cho tiền huấn luyện tiếp tục được sử dụng.

#5. Nghiên cứu loại bỏ về việc bao gồm nhãn và mẫu trong PCP. Để hiểu sâu hơn về những đóng góp riêng lẻ của nhãn giả và mẫu trong phương pháp PCP đề xuất của chúng tôi, chúng tôi tiến hành một nghiên cứu loại bỏ bổ sung, trong đó chúng tôi chỉ sử dụng nhãn giả hoặc mẫu. Nghiên cứu loại bỏ này được thực hiện sử dụng tinh chỉnh dựa trên gợi ý mềm. Như được hiển thị trong Bảng 4, kết quả thí nghiệm tiết lộ rằng việc sử dụng nhãn hoặc mẫu độc quyền sẽ làm tổn hại hiệu suất của mô hình so với phương pháp PCP đề xuất của chúng tôi, làm nổi bật tầm quan trọng sống còn của việc tích hợp cả mẫu và nhãn giả.

#6. Tác động của tinh chỉnh kéo dài đối với hiệu suất mô hình. Để chắc chắn rằng hiệu quả của phương pháp đề xuất của chúng tôi không chỉ đơn giản là do thời gian tinh chỉnh kéo dài, chúng tôi tiến hành thí nghiệm bổ sung. Chúng tôi huấn luyện FT dựa trên CLS 5 lần nhiều bước hơn (tổng cộng 5k bước) từ checkpoint TAPT. Như được hiển thị trong Bảng 5, kết quả của chúng tôi tiết lộ rằng tinh chỉnh kéo dài chỉ mang lại cải thiện biên của chỉ 0,1% qua tám nhiệm vụ. Đáng chú ý, điều này vẫn thấp hơn đáng kể so với phương pháp đề xuất của chúng tôi (8,1% tuyệt đối).

--- TRANG 9 ---
SST-2 SST-5 MR CR MPQA Subj TREC CoLA Trung bình
FT Gợi ý 92.5 48.0 86.8 90.8 81.2 90.3 83.0 4.9 72.2
FT Gợi ý +PCP 93.9 50.7 89.8 92.0 88.3 94.9 88.6 21.5 77.5
FT Gợi ý +PCP (Chỉ Nhãn) 93.7 50.8 87.7 91.3 85.1 94.3 85.7 -0.7 73.5
FT Gợi ý +PCP (Chỉ Mẫu) 90.7 43.5 88.6 92.6 82.0 95.1 84.1 0.7 72.2

Bảng 4: Nghiên cứu loại bỏ về việc bao gồm mẫu và nhãn trong PCP đề xuất của chúng tôi. Kết quả kiểm tra sử dụng FT gợi ý mềm và ROBERTA-LARGE được báo cáo. Hiệu suất tốt nhất cho mỗi tập dữ liệu được làm nổi bật bằng màu xanh.

SST-2 SST-5 MR CR MPQA Subj TREC CoLA Trung bình
FT dựa trên CLS (1k bước) + TAPT 88.2 43.4 86.1 86.2 73.7 94.2 80.4 1.9 69.3
FT dựa trên CLS (5k bước) + TAPT 89.6 43.4 86.7 87.0 72.9 94.6 79.0 1.7 69.4
FT Gợi ý (1k bước) + PCP 93.9 50.7 89.8 92.0 88.3 94.9 88.6 21.5 77.5

Bảng 5: Nghiên cứu loại bỏ về tinh chỉnh kéo dài, trong đó ROBERTA-LARGE được sử dụng làm mô hình xương sống. Kết quả kiểm tra sử dụng FT dựa trên CLS và FT gợi ý mềm được báo cáo. Hiệu suất tốt nhất cho mỗi tập dữ liệu được làm nổi bật bằng màu xanh.

5 Công trình Liên quan
Các Phương pháp dựa trên Gợi ý. Trong những năm gần đây, các nhà nghiên cứu đã khám phá các phương pháp dựa trên gợi ý để cải thiện hiệu suất của tinh chỉnh. Những phương pháp này có thể được chia rộng rãi thành hai hướng nghiên cứu. Hướng đầu tiên, được biết đến như FT dựa trên gợi ý, tối ưu hóa tất cả các tham số trong LMs để có hiệu suất tốt hơn [73,28,52,100], như đã thảo luận trong §2. Adaprompt [22] cải thiện hiệu suất của FT dựa trên gợi ý cứng [73,28] trên các nhiệm vụ câu đơn thông qua tiền huấn luyện tiếp tục thông thường, điều này nói chung phù hợp với kết quả thí nghiệm của chúng tôi. Hướng thứ hai là tinh chỉnh hiệu quả tham số (PEFT) [51,68,47,81,86], nhằm đạt được kết quả cạnh tranh trong khi duy trì chi phí tính toán thấp. PPT [33] cố gắng cải thiện hiệu suất của PEFT [47] bằng cách tiền huấn luyện thêm mô hình T5 [70], theo đuổi ý tưởng tương tự như chúng tôi. Tuy nhiên, phương pháp này dựa vào một loạt thiết kế thủ công và phụ thuộc vào nhiệm vụ cho tiền huấn luyện thêm, làm cho nó ít thích ứng với các nhiệm vụ hạ nguồn mới [86]. Hơn nữa, nó đòi hỏi một corpus huấn luyện lớn hơn nhiều, như đã thảo luận trong §4.4. Ngược lại, công việc của chúng tôi cung cấp một thiết kế thống nhất qua tất cả các nhiệm vụ và tập trung vào FT dựa trên gợi ý. Trong công việc tương lai, chúng tôi dự định khám phá tính tương thích của tiền huấn luyện tiếp tục (bao gồm cả TAPT và PCP đề xuất của chúng tôi) và các phương pháp PEFT.

Huấn luyện LMs với Hướng dẫn/Mẫu. Công việc của chúng tôi liên quan đến việc huấn luyện LMs với mẫu. Các nghiên cứu gần đây [42,3,65,91,61,72,89,59] đã khám phá ý tưởng về việc huấn luyện LMs trên nhiều nhiệm vụ NLP với hướng dẫn/mẫu ngôn ngữ tự nhiên, với mục tiêu tổng quát hóa cho các nhiệm vụ chưa thấy. Các ý tưởng tương tự, chuyển giao gợi ý, cũng đã được khám phá trong bối cảnh PEFT [33,81,86,75], tìm cách học một biểu diễn hiệu quả của gợi ý mềm cho nhiệm vụ đích bằng cách huấn luyện trên các nhiệm vụ khác. Trong phương pháp của chúng tôi, chúng tôi chuyển giao kiến thức từ các văn bản liên quan đến nhiệm vụ với mẫu gợi ý được thiết kế riêng cho một nhiệm vụ đích duy nhất đến LMs.

Học Bán Giám sát. Công việc của chúng tôi liên quan đến học bán giám sát [32,19,43], với mục tiêu sử dụng dữ liệu không nhãn một cách hiệu quả. Tiền huấn luyện tiếp tục theo sau bởi tinh chỉnh [39,82,35] là một loại phương pháp bán giám sát. Trong khi lợi ích của tiền huấn luyện tiếp tục được thừa nhận rộng rãi [6,1,56], thường được giả định rằng lượng lớn dữ liệu là cần thiết cho tiền huấn luyện tiếp tục [ví dụ, 50,38,33]. Ngược lại, nghiên cứu của chúng tôi chứng minh rằng tiền huấn luyện tiếp tục có thể cải thiện hiệu suất chỉ sử dụng vài trăm mẫu không nhãn. Tự huấn luyện [98,58] là một phương pháp bán giám sát mạnh mẽ khác, thường sử dụng các mô hình học sinh-giáo viên để gán nhãn giả cho dữ liệu không nhãn [46,44,83,62,4,15,27,94,80,29]. Công việc của chúng tôi cung cấp một cách thay thế để sử dụng nhãn giả mà không cần đến một quá trình lặp, như đã thảo luận trong §4.3.

6 Kết luận
Kết luận. Nghiên cứu này thách thức quan niệm được chấp nhận rộng rãi trong NLP, cho thấy rằng tiền huấn luyện tiếp tục thông thường có thể có hại cho hiệu suất mô hình, đặc biệt cho các nhiệm vụ cặp câu và FT dựa trên gợi ý. Như một lựa chọn thay thế, chúng tôi đề xuất Tiền Huấn Luyện Tiếp Tục Dựa trên Gợi ý (PCP), liên tục cải thiện hiệu suất của các phương pháp FT dựa trên gợi ý tiên tiến so với tiền huấn luyện tiếp tục thông thường. Ngoài ra, PCP đề xuất của chúng tôi vượt trội hơn các phương pháp bán giám sát tiên tiến với một quá trình hợp lý hơn. Phân tích sâu hơn tiết lộ rằng những lợi thế của PCP vẫn nhất quán qua các kích thước khác nhau của mô hình và tập dữ liệu. Nghiên cứu này nhấn mạnh tầm quan trọng của việc trình bày cả văn bản liên quan đến nhiệm vụ và mẫu/hướng dẫn cho LMs trong quá trình tiền huấn luyện để có hiệu suất tinh chỉnh tốt hơn trên các nhiệm vụ hạ nguồn, đóng góp vào khối lượng nghiên cứu ngày càng tăng về tối ưu hóa các chiến lược tiền huấn luyện và tinh chỉnh trong NLP.

Hạn chế và Tác động Rộng hơn. Chúng tôi phác thảo một số hạn chế vốn có trong nghiên cứu của chúng tôi:
• Quy mô của các mô hình ngôn ngữ. Các thí nghiệm của chúng tôi sử dụng các mô hình ngôn ngữ có kích thước khá khiêm tốn [53]. Những tác động của việc mở rộng lên các mô hình ngôn ngữ tiên tiến hơn, chẳng hạn như Llama-2 [84] hoặc phương pháp mixture-of-experts như GPT-4 [63], vẫn là một câu hỏi mở. Trong bối cảnh các mô hình ngôn ngữ lớn, việc áp dụng PCP với một bộ cập nhật tham số đầy đủ cho một nhiệm vụ cụ thể có thể không được biện minh về mặt chi phí tính toán. Nghiên cứu tương lai có thể khám phá các chiến lược học đa nhiệm vụ hoặc tiền huấn luyện tiếp tục hiệu quả tham số.
• Kiến trúc của các mô hình ngôn ngữ. Công việc của chúng tôi được giới hạn ở các mô hình chỉ mã hóa [25,53]. Để tổng quát hóa các phát hiện của chúng tôi, nghiên cứu tương lai nên điều tra ảnh hưởng của phương pháp PCP của chúng tôi trên các kiến trúc mã hóa-giải mã [70] và chỉ giải mã [14].
• Sự đa dạng của các nhiệm vụ. Đánh giá của chúng tôi được giới hạn ở các nhiệm vụ phân loại và hồi quy văn bản. Nghiên cứu tương lai nên điều tra các nhiệm vụ tạo sinh hoặc đa phương thức, có thể cung cấp cái nhìn toàn diện hơn về khả năng ứng dụng của phương pháp PCP của chúng tôi.

Ngoài ra, công việc của chúng tôi dựa trên các phương pháp tiền huấn luyện và gợi ý cho LMs. Các công trình trước đây [8,14,7] đã thảo luận rộng rãi về các rủi ro và tác hại tiềm ẩn liên quan đến LMs, bao gồm việc khuếch đại các thiên kiến không mong muốn được học từ dữ liệu huấn luyện không nhãn [8,5,16]. Chi phí năng lượng và dấu chân carbon cho công việc của chúng tôi khoảng 125 kWh và 70 kg CO2e, tương đối nhỏ hơn so với tiền huấn luyện LM [25, 53, 14, 23].

Lời cảm ơn và Tiết lộ Nguồn tài trợ
Các tác giả bày tỏ lòng biết ơn đối với các nhà đánh giá NeurIPS và chủ tịch khu vực cho những cuộc thảo luận sâu sắc của họ. Các tác giả biết ơn Xin Zhao về những đóng góp của cô ấy trong việc hiệu đính. Zhengxiang Shi được tài trợ bởi Học bổng Nghiên cứu từ University College London (UCL).

--- TRANG 11 ---
Tài liệu tham khảo
[1] Emily Alsentzer, John Murphy, William Boag, Wei-Hung Weng, Di Jindi, Tristan Naumann, và Matthew McDermott. Publicly available clinical BERT embeddings. Trong Proceedings of the 2nd Clinical Natural Language Processing Workshop, trang 72–78, Minneapolis, Minnesota, USA, tháng 6 năm 2019. Association for Computational Linguistics.

[2] Eric Arazo, Diego Ortego, Paul Albert, Noel E O'Connor, và Kevin McGuinness. Pseudo-labeling and confirmation bias in deep semi-supervised learning. Trong 2020 International Joint Conference on Neural Networks (IJCNN), trang 1–8. IEEE, 2020.

[3] Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q. Tran, Dara Bahri, Jianmo Ni, Jai Gupta, Kai Hui, Sebastian Ruder, và Donald Metzler. Ext5: Towards extreme multi-task scaling for transfer learning. Trong International Conference on Learning Representations, 2022.

[4] Mikel Artetxe, Gorka Labaka, và Eneko Agirre. A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 789–798, Melbourne, Australia, tháng 7 năm 2018. Association for Computational Linguistics.

[5] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021.

[6] Iz Beltagy, Kyle Lo, và Arman Cohan. SciBERT: A pretrained language model for scientific text. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 3615–3620, Hong Kong, China, tháng 11 năm 2019. Association for Computational Linguistics.

[7] Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, và Shmargaret Shmitchell. On the dangers of stochastic parrots: Can language models be too big? Trong Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21, trang 610–623, New York, NY, USA, 2021. Association for Computing Machinery.

[8] Emily M. Bender và Alexander Koller. Climbing towards NLU: On meaning, form, and understanding in the age of data. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 5185–5198, Online, tháng 7 năm 2020. Association for Computational Linguistics.

[9] Yoshua Bengio, Jérôme Louradour, Ronan Collobert, và Jason Weston. Curriculum learning. Trong Proceedings of the 26th Annual International Conference on Machine Learning, ICML '09, trang 41–48, New York, NY, USA, 2009. Association for Computing Machinery.

[10] Luisa Bentivogli, Peter Clark, Ido Dagan, và Danilo Giampiccolo. The fifth PASCAL recognizing textual entailment challenge. Trong TAC, 2009.

[11] David Berthelot, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, và Colin Raffel. Remixmatch: Semi-supervised learning with distribution matching and augmentation anchoring. Trong International Conference on Learning Representations, 2020.

[12] David Berthelot, Rebecca Roelofs, Kihyuk Sohn, Nicholas Carlini, và Alexey Kurakin. Adamatch: A unified approach to semi-supervised learning and domain adaptation. Trong International Conference on Learning Representations, 2022.

[13] Samuel R. Bowman, Gabor Angeli, Christopher Potts, và Christopher D. Manning. A large annotated corpus for learning natural language inference. Trong Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, trang 632–642, Lisbon, Portugal, tháng 9 năm 2015. Association for Computational Linguistics.

--- TRANG 12 ---
[14] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. Trong Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS'20, Red Hook, NY, USA, 2020. Curran Associates Inc.

[15] Rui Cai và Mirella Lapata. Semi-supervised semantic role labeling with cross-view training. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 1018–1027, Hong Kong, China, tháng 11 năm 2019. Association for Computational Linguistics.

[16] Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom B Brown, Dawn Song, Ulfar Erlingsson, et al. Extracting training data from large language models. Trong USENIX Security Symposium, tập 6, 2021.

[17] Daniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-Gazpio, và Lucia Specia. SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation. Trong the 11th International Workshop on Semantic Evaluation (SemEval-2017), 2017.

[18] Ming-Wei Chang, Lev Ratinov, Dan Roth, và Vivek Srikumar. Importance of semantic representation: dataless classification. Trong Proceedings of the 23rd national conference on Artificial intelligence-Volume 2, trang 830–835, 2008.

[19] Olivier Chapelle, Bernhard Scholkopf, và Alexander Zien. Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book reviews]. IEEE Transactions on Neural Networks, 20(3):542–542, 2009.

[20] Baixu Chen, Junguang Jiang, Ximei Wang, Pengfei Wan, Jianmin Wang, và Mingsheng Long. Debiased self-training for semi-supervised learning. Trong Advances in Neural Information Processing Systems, NIPS'22, 2022.

[21] Jiaao Chen, Zichao Yang, và Diyi Yang. MixText: Linguistically-informed interpolation of hidden space for semi-supervised text classification. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 2147–2157, Online, tháng 7 năm 2020. Association for Computational Linguistics.

[22] Yulong Chen, Yang Liu, Li Dong, Shuohang Wang, Chenguang Zhu, Michael Zeng, và Yue Zhang. AdaPrompt: Adaptive model training for prompt-based NLP. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, trang 6057–6068, Abu Dhabi, United Arab Emirates, tháng 12 năm 2022. Association for Computational Linguistics.

[23] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.

[24] Ido Dagan, Oren Glickman, và Bernardo Magnini. The PASCAL recognising textual entailment challenge. Trong the First International Conference on Machine Learning Challenges: Evaluating Predictive Uncertainty Visual Object Classification, and Recognizing Textual Entailment, 2005.

[25] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Minneapolis, Minnesota, 2019. Association for Computational Linguistics.

[26] William B. Dolan và Chris Brockett. Automatically constructing a corpus of sentential paraphrases. Trong the Third International Workshop on Paraphrasing (IWP2005), 2005.

--- TRANG 13 ---
[27] Xin Dong và Gerard de Melo. A robust self-learning framework for cross-lingual text classification. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 6306–6310, Hong Kong, China, tháng 11 năm 2019. Association for Computational Linguistics.

[28] Tianyu Gao, Adam Fisch, và Danqi Chen. Making pre-trained language models better few-shot learners. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 3816–3830, Online, tháng 8 năm 2021. Association for Computational Linguistics.

[29] Ariel Gera, Alon Halfon, Eyal Shnarch, Yotam Perlitz, Liat Ein-Dor, và Noam Slonim. Zero-shot text classification with self-training. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2022.

[30] Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, và Bill Dolan. The third PASCAL recognizing textual entailment challenge. Trong the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, 2007.

[31] Arushi Goel, Yunlong Jiao, và Jordan Massiah. Pars: Pseudo-label aware robust sample selection for learning with noisy labels. arXiv preprint arXiv:2201.10836, 2022.

[32] Yves Grandvalet và Yoshua Bengio. Semi-supervised learning by entropy minimization. Advances in neural information processing systems, 17, 2004.

[33] Yuxian Gu, Xu Han, Zhiyuan Liu, và Minlie Huang. PPT: Pre-trained prompt tuning for few-shot learning. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 8410–8423, Dublin, Ireland, tháng 5 năm 2022. Association for Computational Linguistics.

[34] Suchin Gururangan, Tam Dang, Dallas Card, và Noah A. Smith. Variational pretraining for semi-supervised text classification. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 5880–5894, Florence, Italy, tháng 7 năm 2019. Association for Computational Linguistics.

[35] Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, và Noah A. Smith. Don't stop pretraining: Adapt language models to domains and tasks. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 8342–8360, Online, tháng 7 năm 2020. Association for Computational Linguistics.

[36] Karen Hambardzumyan, Hrant Khachatrian, và Jonathan May. WARP: Word-level Adversarial ReProgramming. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 4921–4933, Online, tháng 8 năm 2021. Association for Computational Linguistics.

[37] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022.

[38] Zejiang Hou, Julian Salazar, và George Polovets. Meta-Learning the Difference: Preparing Large Language Models for Efficient Adaptation. Transactions of the Association for Computational Linguistics, 10:1249–1265, 11 2022.

[39] Jeremy Howard và Sebastian Ruder. Universal language model fine-tuning for text classification. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 328–339, Melbourne, Australia, tháng 7 năm 2018. Association for Computational Linguistics.

[40] Minqing Hu và Bing Liu. Mining and summarizing customer reviews. Trong ACM SIGKDD international conference on Knowledge discovery and data mining, 2004.

--- TRANG 14 ---
[41] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020.

[42] Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, và Hannaneh Hajishirzi. UNIFIEDQA: Crossing format boundaries with a single QA system. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 1896–1907, Online, tháng 11 năm 2020. Association for Computational Linguistics.

[43] Thomas N. Kipf và Max Welling. Semi-supervised classification with graph convolutional networks. Trong International Conference on Learning Representations (ICLR), 2017.

[44] Samuli Laine và Timo Aila. Temporal ensembling for semi-supervised learning. Trong 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017.

[45] Teven Le Scao và Alexander Rush. How many data points is a prompt worth? Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 2627–2636, Online, tháng 6 năm 2021. Association for Computational Linguistics.

[46] Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. Trong Workshop on challenges in representation learning, ICML, trang 896, 2013.

[47] Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-efficient prompt tuning. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 3045–3059, Online và Punta Cana, Dominican Republic, tháng 11 năm 2021. Association for Computational Linguistics.

[48] Changchun Li, Ximing Li, và Jihong Ouyang. Semi-supervised text classification with balanced deep representation distributions. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 5044–5053, Online, tháng 8 năm 2021. Association for Computational Linguistics.

[49] Junnan Li, Richard Socher, và Steven C H Hoi. DIVIDEMIX: LEARNING WITH NOISY LABELS AS SEMI-SUPERVISED LEARNING. Trong ICLR 2020, trang 14. ICLR, 2020.

[50] Shiyang Li, Semih Yavuz, Wenhu Chen, và Xifeng Yan. Task-adaptive pre-training and self-training are complementary for natural language understanding. Trong Findings of the Association for Computational Linguistics: EMNLP 2021, trang 1006–1015, Punta Cana, Dominican Republic, tháng 11 năm 2021. Association for Computational Linguistics.

[51] Xiang Lisa Li và Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 4582–4597, Online, tháng 8 năm 2021. Association for Computational Linguistics.

[52] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, và Jie Tang. Gpt understands, too. arXiv:2103.10385, 2021.

[53] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.

[54] Lajanugen Logeswaran, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob Devlin, và Honglak Lee. Zero-shot entity linking by reading entity descriptions. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 3449–3460, Florence, Italy, tháng 7 năm 2019. Association for Computational Linguistics.

--- TRANG 15 ---
[55] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, và Christopher Potts. Learning word vectors for sentiment analysis. Trong Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, trang 142–150, Portland, USA, tháng 6 năm 2011. Association for Computational Linguistics.

[56] Katerina Margatina, Loic Barrault, và Nikolaos Aletras. On the importance of effectively adapting pretrained language models for active learning. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), trang 825–836, Dublin, Ireland, tháng 5 năm 2022. Association for Computational Linguistics.

[57] Julian McAuley và Jure Leskovec. Hidden factors and hidden topics: Understanding rating dimensions with review text. Trong Proceedings of the 7th ACM Conference on Recommender Systems, RecSys '13, trang 165–172, New York, NY, USA, 2013. Association for Computing Machinery.

[58] David McClosky, Eugene Charniak, và Mark Johnson. Effective self-training for parsing. Trong Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, trang 152–159, New York City, USA, tháng 6 năm 2006. Association for Computational Linguistics.

[59] Sewon Min, Mike Lewis, Luke Zettlemoyer, và Hannaneh Hajishirzi. MetaICL: Learning to learn in context. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 2791–2809, Seattle, United States, tháng 7 năm 2022. Association for Computational Linguistics.

[60] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, và Luke Zettlemoyer. Rethinking the role of demonstrations: What makes in-context learning work? Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 11048–11064, Abu Dhabi, United Arab Emirates, tháng 12 năm 2022. Association for Computational Linguistics.

[61] Swaroop Mishra, Daniel Khashabi, Chitta Baral, và Hannaneh Hajishirzi. Cross-task generalization via natural language crowdsourcing instructions. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 3470–3487, Dublin, Ireland, tháng 5 năm 2022. Association for Computational Linguistics.

[62] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, và Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE transactions on pattern analysis and machine intelligence, 41:1979–1993, 2018.

[63] OpenAI. Gpt-4 technical report. arXiv, 2023.

[64] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, và Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. Trong Proceedings of NAACL-HLT 2019: Demonstrations, 2019.

[65] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, và Ryan Lowe. Training language models to follow instructions with human feedback. Trong Alice H. Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.

[66] Bo Pang và Lillian Lee. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. Trong Association for Computational Linguistics (ACL), 2004.

[67] Bo Pang và Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. Trong Association for Computational Linguistics (ACL), 2005.

[68] Guanghui Qin và Jason Eisner. Learning how to ask: Querying LMs with mixtures of soft prompts. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 5203–5212, Online, tháng 6 năm 2021. Association for Computational Linguistics.

--- TRANG 16 ---
[69] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8), 2019.

[70] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(1), jan 2020.

[71] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. SQuAD: 100,000+ questions for machine comprehension of text. Trong Empirical Methods in Natural Language Processing (EMNLP), 2016.

[72] Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, et al. Multitask prompted training enables zero-shot task generalization. Trong International Conference on Learning Representations, 2022.

[73] Timo Schick và Hinrich Schütze. Exploiting cloze-questions for few-shot text classification and natural language inference. Trong Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, trang 255–269, Online, tháng 4 năm 2021. Association for Computational Linguistics.

[74] Timo Schick và Hinrich Schütze. It's not just size that matters: Small language models are also few-shot learners. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 2339–2352, Online, tháng 6 năm 2021. Association for Computational Linguistics.

[75] Zhengxaing Shi và Aldo Lipani. Dept: Decomposed prompt tuning for parameter-efficient fine-tuning. arXiv preprint, 2023.

[76] Zhengxiang Shi, Yue Feng, và Aldo Lipani. Learning to execute actions or ask clarification questions. Trong Findings of the Association for Computational Linguistics: NAACL 2022, trang 2060–2070, Seattle, United States, tháng 7 năm 2022. Association for Computational Linguistics.

[77] Zhengxiang Shi, Francesco Tonolini, Nikolaos Aletras, Emine Yilmaz, Gabriella Kazai, và Yunlong Jiao. Rethinking semi-supervised learning with language models. Trong Findings of ACL 2023, Toronto, Canada, 2023. Association for Computational Linguistics.

[78] Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, và Sameer Singh. AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 4222–4235, Online, tháng 11 năm 2020. Association for Computational Linguistics.

[79] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, và Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. Trong Empirical Methods in Natural Language Processing (EMNLP), 2013.

[80] Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, và Colin Raffel. Fixmatch: Simplifying semi-supervised learning with consistency and confidence. Trong Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS'20, Red Hook, NY, USA, 2020. Curran Associates Inc.

[81] Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan Liu, Peng Li, Juanzi Li, Lei Hou, Maosong Sun, và Jie Zhou. On transferability of prompt tuning for natural language processing. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, tháng 7 năm 2022.

[82] Chi Sun, Xipeng Qiu, Yige Xu, và Xuanjing Huang. How to fine-tune bert for text classification? Trong China national conference on Chinese computational linguistics, trang 194–206. Springer, 2019.

--- TRANG 17 ---
[83] Antti Tarvainen và Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. Trong Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS'17, trang 1195–1204, Red Hook, NY, USA, 2017. Curran Associates Inc.

[84] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.

[85] Ellen M Voorhees và Dawn M Tice. Building a question answering test collection. Trong the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, 2000.

[86] Tu Vu, Brian Lester, Noah Constant, Rami Al-Rfou', và Daniel Cer. SPoT: Better frozen model adaptation through soft prompt transfer. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 5039–5059, Dublin, Ireland, tháng 5 năm 2022. Association for Computational Linguistics.

[87] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel Bowman. GLUE: A multi-task benchmark and analysis platform for natural language understanding. Trong Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, trang 353–355, Brussels, Belgium, tháng 11 năm 2018. Association for Computational Linguistics.

[88] Ximei Wang, Jinghan Gao, Mingsheng Long, và Jianmin Wang. Self-tuning for data-efficient deep learning. Trong International Conference on Machine Learning (ICML), 2021.

[89] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Kuntal Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Savan Doshi, Shailaja Keyur Sampat, Siddhartha Mishra, Sujan Reddy A, Sumanta Patro, Tanay Dixit, và Xudong Shen. Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 5085–5109, Abu Dhabi, United Arab Emirates, tháng 12 năm 2022. Association for Computational Linguistics.

[90] Alex Warstadt, Amanpreet Singh, và Samuel R. Bowman. Neural network acceptability judgments. Transactions of the Association of Computational Linguistics (TACL), 7, 2019.

[91] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, và Quoc V Le. Finetuned language models are zero-shot learners. Trong International Conference on Learning Representations, 2022.

[92] Janyce Wiebe, Theresa Wilson, và Claire Cardie. Annotating expressions of opinions and emotions in language. Language resources and evaluation, 39(2-3), 2005.

[93] Adina Williams, Nikita Nangia, và Samuel Bowman. A broad-coverage challenge corpus for sentence understanding through inference. Trong North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), 2018.

[94] Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, và Quoc V. Le. Unsupervised data augmentation for consistency training. Trong Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS'20, Red Hook, NY, USA, 2020. Curran Associates Inc.

[95] Qizhe Xie, Minh-Thang Luong, Eduard Hovy, và Quoc V Le. Self-training with noisy student improves imagenet classification. Trong Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, trang 10687–10698, 2020.

[96] Yi Xu, Lei Shang, Jinxing Ye, Qi Qian, Yu-Feng Li, Baigui Sun, Hao Li, và Rong Jin. Dash: Semi-supervised learning with dynamic thresholding. Trong International Conference on Machine Learning, trang 11525–11536. PMLR, 2021.

--- TRANG 18 ---
[97] Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, và Colin Raffel. mT5: A massively multilingual pre-trained text-to-text transformer. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 483–498, Online, tháng 6 năm 2021. Association for Computational Linguistics.

[98] David Yarowsky. Unsupervised word sense disambiguation rivaling supervised methods. Trong 33rd Annual Meeting of the Association for Computational Linguistics, trang 189–196, Cambridge, Massachusetts, USA, tháng 6 năm 1995. Association for Computational Linguistics.

[99] Bowen Zhang, Yidong Wang, Wenxin Hou, Hao Wu, Jindong Wang, Manabu Okumura, và Takahiro Shinozaki. Flexmatch: Boosting semi-supervised learning with curriculum pseudo labeling. Trong Proceedings of the 35th International Conference on Neural Information Processing Systems, tập 34, 2021.

[100] Ningyu Zhang, Luoqiu Li, Xiang Chen, Shumin Deng, Zhen Bi, Chuanqi Tan, Fei Huang, và Huajun Chen. Differentiable prompt makes pre-trained language models better few-shot learners. Trong International Conference on Learning Representations, 2022.

[101] Xiang Zhang, Junbo Zhao, và Yann LeCun. Character-level convolutional networks for text classification. Trong Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1, NIPS'15, trang 649–657, Cambridge, MA, USA, 2015. MIT Press.

[102] Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, và Sameer Singh. Calibrate before use: Improving few-shot performance of language models. Trong Marina Meila và Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, tập 139 của Proceedings of Machine Learning Research, trang 12697–12706. PMLR, 18–24 Jul 2021.

--- TRANG 19 ---
Tổng quan Phụ lục
Phụ lục được cấu trúc như sau:
Phụ lục §A cung cấp mô tả ngắn gọn cho mỗi tập dữ liệu.
Phụ lục §B cung cấp chi tiết về mẫu và từ nhãn được sử dụng cho mỗi tập dữ liệu.
Phụ lục §C trình bày mô tả ngắn gọn về bốn phương pháp bán giám sát (tự huấn luyện) tiên tiến.
Phụ lục §D cung cấp kết quả thí nghiệm bổ sung để điều tra các lý do tiềm ẩn cho việc không hiệu quả của tinh chỉnh dựa trên CLS trên các nhiệm vụ cặp câu.
Phụ lục §E cung cấp chi tiết triển khai và siêu tham số cho tất cả các phương pháp so sánh được sử dụng trong các thí nghiệm của chúng tôi.

A Tập dữ liệu
Trong công trình này, chúng tôi sử dụng 21 tập dữ liệu phổ biến từ nghiên cứu học few-shot và bán giám sát trước đây.

Đối với các thí nghiệm trong §4.2, chúng tôi tuân theo phương pháp trong [28] và sử dụng 16 tập dữ liệu khác nhau2, bao gồm SST-2 [79], SST-5 [79], MR [67], CR [40], MPQA [92], Subj [66], TREC [85], CoLA [90], MNLI [93], SNLI [13], QNLI [71], RTE [24,30,10], MRPC [26], QQP3, và STS-B [17]. Phù hợp với nghiên cứu trước đây [28], tập xác thực của chúng tôi bao gồm 16 ví dụ mỗi lớp từ các tập dữ liệu nêu trên. Ngoài ra, chúng tôi sử dụng 16 ví dụ mỗi lớp cho tập huấn luyện và toàn bộ tập huấn luyện làm tập không nhãn trong thiết lập bán giám sát. Chúng tôi cũng sử dụng toàn bộ tập huấn luyện cho mục đích huấn luyện trong thiết lập giám sát đầy đủ. Đối với các nhiệm vụ cặp câu, chúng tôi chọn tối đa 10k ví dụ cho tiền huấn luyện tiếp tục để giảm chi phí tính toán.

Đối với các thí nghiệm trong §4.3, chúng tôi tuân theo thiết lập trong [77] và sử dụng 5 tập dữ liệu khác nhau, bao gồm IMDB [55], AG NEWS [101], YELP REVIEW4, YAHOO! ANSWER [18], và AMAZON REVIEW [57]. Tham khảo thống kê tập dữ liệu trong Bảng 6. Tập xác thực của chúng tôi bao gồm 1.000 ví dụ cho mỗi tập dữ liệu.

B Mẫu cho FT dựa trên Gợi ý
Ở đây chúng tôi giới thiệu các mẫu được sử dụng trong hai phương pháp FT dựa trên gợi ý tiên tiến cho mỗi tập dữ liệu. Đối với "FT dựa trên gợi ý (cứng)", chúng tôi sử dụng gợi ý và từ nhãn thủ công chất lượng cao hoặc được tạo tự động cho mỗi nhiệm vụ từ các công trình trước đây [73,28]. Đối với "FT dựa trên gợi ý (mềm)", chúng tôi sử dụng mẫu STS-2 cho tất cả các nhiệm vụ câu đơn và mẫu STS-B cho tất cả các nhiệm vụ cặp câu, trong khi các từ nhãn cho mỗi nhiệm vụ tuân theo mô tả trong Bảng 7.

C Khung S T
FIXMATCH. FIXMATCH [80] tạo ra nhãn nhân tạo sử dụng cả regularization nhất quán và pseudo-labelling, trong đó các nhãn nhân tạo được tạo ra dựa trên dữ liệu không nhãn được tăng cường yếu. Những nhãn nhân tạo này sau đó được sử dụng làm mục tiêu để huấn luyện mô hình trên dữ liệu không nhãn được tăng cường mạnh. FIXMATCH chỉ giữ lại một nhãn nhân tạo nếu mô hình gán xác suất cao cho một trong các lớp có thể.

DASH. DASH [96] mở rộng FIXMATCH bằng cách giới thiệu một cơ chế với ngưỡng mất mát được điều chỉnh động để chọn một tập con các ví dụ huấn luyện từ dữ liệu không nhãn để thực hiện SSL.

2https://github.com/princeton-nlp/LM-BFF/blob/main/data/download_dataset.sh
3https://www.quora.com/q/quoradata/
4https://www.yelp.com/dataset

--- TRANG 20 ---
Nhiệm vụ Câu Đơn
Tập dữ liệu |Y| L #Train #Test Loại Nhãn (nhiệm vụ phân loại)
SST-2 2 19 6,920 872 Cảm xúc positive, negative
SST-5 5 18 8,544 2,210 Cảm xúc v. pos., positive, neutral, negative, v. neg.
MR 2 20 8,662 2,000 Cảm xúc positive, negative
CR 2 19 1,775 2,000 Cảm xúc positive, negative
MPQA 2 3 8,606 2,000 Cực tính Ý kiến positive, negative
Subj 2 23 8,000 2,000 Chủ quan subjective, objective
TREC 6 10 5,452 500 Phân loại Câu hỏi abbr., entity, description, human, loc., num.
CoLA 2 8 8,551 1,042 Tính chấp nhận grammatical, not_grammatical
IMDB 2 149 8,000 1,000 Đánh giá Phim positive, negative
AG NEWS 2 37 8,000 1,000 Chủ đề Tin tức world, sports, business, sci/tech
YELP REVIEW 2 134 8,000 1,000 Cảm xúc Đánh giá 1, 2, 3, 4, 5
AMAZON REVIEW 2 79 8,000 1,000 Cảm xúc Đánh giá 1, 2, 3, 4, 5
YAHOO! ANSWER 2 32 8,000 1,000 Phân loại Chủ đề culture, science, health, education, computer, sports, business, music, family, politics

Nhiệm vụ Cặp Câu
Tập dữ liệu |Y| L #Train #Test Loại Nhãn (nhiệm vụ phân loại)
MNLI 3 22/11 392,702 9,815 NLI entailment, neutral, contradiction
SNLI 3 14/8 549,367 9,842 NLI entailment, neutral, contradiction
QNLI 2 11/30 104,743 5,463 NLI entailment, not_entailment
RTE 2 49/10 2,490 277 NLI entailment, not_entailment
MRPC 2 22/21 3,668 408 Paraphrase equivalent, not_equivalent
QQP 2 12/12 363,846 40,431 Paraphrase equivalent, not_equivalent
STS-B R 11/11 5,749 1,500 Độ tương tự Câu -

Bảng 6: Các tập dữ liệu được đánh giá trong công trình này. |Y|: # lớp cho các nhiệm vụ phân loại (với một ngoại lệ: STS-B là một nhiệm vụ hồi quy giá trị thực trên khoảng [0,5]). L: trung bình # từ trong (các) câu đầu vào. Lưu ý rằng chúng tôi chỉ lấy mẫu các ví dụ từ tập huấn luyện ban đầu trong các thí nghiệm few-shot của chúng tôi.

Nhiệm vụ Câu Đơn
Nhiệm vụ Mẫu Từ nhãn
SST-2 <S1>It was [MASK] . positive: great, negative: terrible
SST-5 <S1>It was [MASK] . v.positive: great, positive: good, neutral: okay, negative: bad, v.negative: terrible
MR <S1>It was [MASK] . positive: great, negative: terrible
CR <S1>It was [MASK] . positive: great, negative: terrible
MPQA <S1>is[MASK] . positive: positive, negative: negative
Subj <S1>This is [MASK] . subjective: subjective, objective: objective
TREC [MASK] :<S1> abbreviation: Expression, entity: Entity, description: Description human: Human, location: Location, numeric: Number
COLA <S1>This is [MASK] . grammatical: correct, not_grammatical: incorrect
IMDB <S1>It was [MASK] . positive: great, negative: terrible
AG NEWS <S1>It was [MASK] . World: world, Sports:sports, Business: business, Sci/Tech: tech
YELP REVIEW <S1>It was [MASK] . 0: 0, 1: 1, 2: 2, 3: 3, 4: 4
AMAZON REVIEW <S1>It was [MASK] . 0: 0, 1: 1, 2: 2, 3: 3, 4: 4
YAHOO! ANSWER <S1>It was [MASK] . culture: culture, science: science, health: health, education: education computer: computer, sports: sports, business: business music: music, family: family, politics: politics

Nhiệm vụ Cặp Câu
Nhiệm vụ Mẫu Từ nhãn
MNLI <S1>?[MASK] ,<S2> entailment: Yes, neutral: Maybe, contradiction: No
SNLI <S1>?[MASK] , in this case <S2> entailment: Yes, neutral: Maybe, contradiction: No
QNLI <S1>?[MASK] ,<S2> entailment: Yes, not_entailment: No
RTE <S1>?[MASK] , I think that <S2> entailment: Clearly, not_entailment: Yet
MRPC <S1> [MASK] ,<S2> equivalent: Yes, not_equivalent: No
QQP <S1> [MASK] ,<S2> equivalent: Yes, not_equivalent: No
STS-B <S1> [MASK] ,<S2> yu: Yes, yl: No

Bảng 7: Mẫu và từ nhãn được sử dụng cho "FT dựa trên gợi ý (cứng)". Chúng tôi sử dụng mẫu STS-2 và STS-B cho tất cả các nhiệm vụ câu đơn và nhiệm vụ cặp câu sử dụng "FT dựa trên gợi ý (mềm)", tương ứng.

FLEXMATCH. FLEXMATCH [99] cũng mở rộng FIXMATCH bằng cách giới thiệu khái niệm học theo chương trình [9] để điều chỉnh linh hoạt ngưỡng cho các lớp khác nhau tại mỗi bước thời gian và chọn dữ liệu không nhãn và nhãn giả của chúng có nhiều khả năng mang tính thông tin.

--- TRANG 21 ---
ADAMATCH. ADAMATCH [12] nhằm giải quyết các vấn đề thích ứng miền trong SSL và xây dựng một mô hình độ chính xác cao huấn luyện trên và kiểm tra trên các phân phối dữ liệu khác nhau. ADAMATCH xây dựng trên FIXMATCH và giới thiệu một ngưỡng tin cậy tương đối và một alignment phân phối được sửa đổi từ [11].

D Thí nghiệm Bổ sung
Trong phần này, chúng tôi điều tra tại sao TAPT không hiệu quả trên các nhiệm vụ cặp câu. Chúng tôi đã đánh giá ba giải thích có thể cho việc không hiệu quả của TAPT trên các nhiệm vụ cặp câu: (1) kích thước tập dữ liệu cho tiền huấn luyện tiếp tục, (2) các cặp câu với độ tương tự cao hơn so với những gì đã quan sát trong dữ liệu tiền huấn luyện, và (3) thiếu sự tách biệt trong các cặp câu. Kết quả thí nghiệm của chúng tôi cho thấy việc không hiệu quả của TAPT trên các nhiệm vụ cặp câu không phải là một sự cố riêng lẻ mà là một vấn đề tái diễn. Dưới đây chúng tôi thảo luận chi tiết về từng thiết lập.

#1. Tác động của tiền huấn luyện tiếp tục (TAPT) với corpus tiền huấn luyện lớn hơn đối với hiệu suất của FT dựa trên gợi ý trên các nhiệm vụ cặp câu. Trong Phần 4.2, chúng tôi chọn ngẫu nhiên tối đa 10k ví dụ không nhãn từ các tập huấn luyện đầy đủ của MNLI, MNLI-mm, SNLI, QNLI, và QQP, làm corpus cho tiền huấn luyện tiếp tục do tài nguyên tính toán học thuật hạn chế của chúng tôi. Đối với tất cả các nhiệm vụ khác, chúng tôi sử dụng toàn bộ tập huấn luyện cho tiền huấn luyện tiếp tục vì có ít hơn 10k ví dụ trong các tập huấn luyện của chúng. Để xác minh các phát hiện của chúng tôi rằng "TAPT không luôn có lợi cho các nhiệm vụ cặp câu, cũng như khi sử dụng FT dựa trên gợi ý" đúng khi sử dụng corpus tiền huấn luyện tiếp tục lớn hơn, chúng tôi thực hiện tiền huấn luyện tiếp tục thông thường (TAPT) trên toàn bộ tập huấn luyện trên MNLI, MNLI-mm, SNLI, QNLI, và QQP.

Tập dữ liệu MNLI MNLI-mm SNLI QNLI QQP
Kích thước Corpus 393k 393k 549k 104k 364k
FT dựa trên CLS 46.20.6 48.51.0 45.65.4 61.48.2 58.53.8
+ TAPT 34.70.4↓ 35.10.6↓ 41.82.7↓ 54.82.0↓ 62.62.9↑
FT dựa trên gợi ý (cứng) 67.31.3 68.91.2 76.71.6 66.54.3 66.81.9
+ TAPT 47.85.6↓ 47.95.2↓ 47.59.4↓ 53.50.8↓ 53.50.8↓
FT dựa trên gợi ý (mềm) 62.72.2 65.91.2 75.40.8 64.24.7 66.51.8
+ TAPT 45.43.7↓ 45.84.1↓ 50.23.9↓ 53.80.9↓ 53.80.9↓

Bảng 8: Kết quả Kiểm tra sử dụng ROBERTA-LARGE, với kích thước corpus tiền huấn luyện tiếp tục tương ứng cho mỗi nhiệm vụ. Hiệu suất trung bình với độ lệch chuẩn được báo cáo qua năm seed.

Bảng 8 trình bày hiệu suất của FT dựa trên CLS, FT dựa trên gợi ý (cứng), và FT dựa trên gợi ý (mềm) sử dụng TAPT. Kết quả thí nghiệm tiết lộ rằng TAPT nói chung dẫn đến hiệu suất kém hơn, ngay cả khi corpus tiền huấn luyện tiếp tục lớn hơn được sử dụng. Đáng chú ý, hiệu suất của các phương pháp tinh chỉnh này có thể thậm chí tệ hơn so với những phương pháp đạt được bằng cách sử dụng corpus tiền huấn luyện tiếp tục nhỏ hơn (tham khảo kết quả trong Bảng 1), cho thấy rằng huấn luyện với corpus lớn hơn không phải là một giải pháp hiệu quả cho các vấn đề của tiền huấn luyện tiếp tục thông thường (TAPT).

MNLI MNLI-mm SNLI QNLI RTE MRPC QQP STS-B Trung bình
FT dựa trên CLS 46.2 48.5 45.6 61.4 54.2 73.2 58.5 46.0 54.2
+TAPT 36.0 36.3 45.7 55.6 53.4 67.7 55.0 48.1 49.7
+TAPT (Tokenizer Sep) 36.4 37.5 50.5 58.8 50.8 63.5 59.2 48.8 50.7
+TAPT (PCP Sep) 36.3 36.7 64.6 58.3 51.2 65.3 57.4 44.5 51.8
+TAPT (random sent pair) 34.8 35.4 37.7 52.2 51.2 64.8 56.9 23.8 44.6
+TAPT (first sent only) 35.6 35.9 42.7 52.2 52.6 62.5 53.6 16.7 44.0

Bảng 9: Nghiên cứu loại bỏ về hiệu suất của tinh chỉnh dựa trên CLS với các thiết lập khác nhau của tiền huấn luyện tiếp tục thông thường, trong đó ROBERTA-LARGE được sử dụng làm mô hình xương sống.

#2. Độ tương tự cao trong các cặp câu. Chúng tôi xem xét rằng độ tương tự cao giữa các cặp câu có thể xung đột với phân phối từ mà mô hình đã quan sát trong quá trình tiền huấn luyện mô hình. Ví dụ, trong nhiệm vụ MNLI, hai câu là Salt kept the town fed và Salt kept the town thriving. Để khám phá điều này, chúng tôi thực hiện TAPT trên hai thiết lập khác nhau, một trong đó chúng tôi tiếp tục tiền huấn luyện TAPT trên các câu được ghép cặp ngẫu nhiên trong tập dữ liệu và một thiết lập khác trong đó chúng tôi tiếp tục tiền huấn luyện TAPT chỉ sử dụng câu đầu tiên của mỗi cặp. Như được hiển thị trong Bảng 9, kết quả thí nghiệm cho thấy huấn luyện TAPT với một trong hai trường hợp dẫn đến hiệu suất thậm chí tệ hơn.

#3. Tách biệt dựa trên token của các cặp câu. Trong một nỗ lực để giảm thiểu hiệu ứng ở trên, chúng tôi cũng xem xét rằng việc phân biệt hai câu bằng cách sử dụng các token riêng biệt có thể tạo ra sự khác biệt. Để kiểm tra điều này, chúng tôi thực hiện TAPT với hai loại token tách biệt, token đặc biệt từ tokenizer và mẫu được sử dụng trong PCP (không có nhãn). Như được hiển thị trong Bảng 9, huấn luyện TAPT với các token tách biệt giữa hai câu có thể phần nào giảm thiểu sự giảm hiệu suất cho tinh chỉnh dựa trên CLS trên các nhiệm vụ cặp câu. Tuy nhiên, kết quả vẫn kém hơn so với tinh chỉnh dựa trên CLS mà không sử dụng TAPT.

Tóm lại, các điều tra của chúng tôi làm nổi bật những khó khăn mà TAPT gặp phải trên các nhiệm vụ cặp câu, trong khi phương pháp PCP đề xuất của chúng tôi cung cấp một giải pháp đơn giản nhưng hiệu quả. Chúng tôi đưa ra giả thuyết rằng việc không hiệu quả của TAPT đối với tinh chỉnh dựa trên CLS trên các nhiệm vụ cặp câu có thể do nhiều yếu tố khác nhau, mà chúng tôi để lại cho một điều tra toàn diện hơn trong công việc tương lai.

E Chi tiết Triển khai
Mã của chúng tôi được triển khai sử dụng Pytorch5 và Huggingface6. Các phương pháp bán giám sát được triển khai dựa trên repository7. Dưới đây, chúng tôi cung cấp danh sách toàn diện các siêu tham số được sử dụng trong mã của chúng tôi. Đối với tinh chỉnh, như được hiển thị trong Bảng 10, chúng tôi tiến hành tìm kiếm lưới cho tỷ lệ học trong tập hợp {1e-5, 2e-5, 5e-5}, và chọn kích thước batch là 8. Trong mỗi thử nghiệm, chúng tôi huấn luyện mô hình trong 1.000 bước, đánh giá hiệu suất mỗi 100 bước, và chọn checkpoint tốt nhất dựa trên hiệu suất tối ưu trên tập đánh giá. Hiệu suất tốt nhất được xác định bởi metric đánh giá liên quan. Đối với tiền huấn luyện tiếp tục, chúng tôi sử dụng cùng một tập hợp siêu tham số cho cả TAPT và PCP, như được hiển thị trong Bảng 11. Tỷ lệ học và kích thước dữ liệu không nhãn có liên quan chặt chẽ và cần được điều chỉnh đồng thời. Như một hướng dẫn chung, chúng tôi đề xuất giảm tỷ lệ học khi kích thước dữ liệu không nhãn giảm. Khác với tiền nhiệm của nó, BERT [25], sử dụng mục tiêu dự đoán câu tiếp theo, ROBERTA [53] được huấn luyện chỉ với mục tiêu mô hình ngôn ngữ che giấu (MLM), cụ thể là mất mát entropy chéo trên việc dự đoán các token bị che giấu ngẫu nhiên. RoBERTa thay đổi động mẫu che giấu được áp dụng cho các ví dụ huấn luyện, thường sử dụng xác suất che giấu 0,15. Ngoài ra, Bảng 12 liệt kê các siêu tham số cho các phương pháp tự huấn luyện, trong đó tìm kiếm lưới cho tỷ lệ học trong tập hợp {1e5, 2e-5, 5e-5} được tiến hành.

5https://pytorch.org/
6https://huggingface.co/
7https://github.com/amzn/pretraining-or-self-training

--- TRANG 22 ---
Siêu tham số Gán
số bước 1000 bước (đánh giá mỗi 100 bước)
kích thước batch 8
tỷ lệ học tối đa 1e-05, 2e-5, 5e-5
độ dài chuỗi tối đa 128, 256
bộ tối ưu tỷ lệ học AdamW
Adam epsilon 1e-6
trọng số beta Adam 0.9, 0.98
lịch trình tỷ lệ học Warmup linear
Weight decay 0.01
tỷ lệ Warmup 0.06

Bảng 10: Siêu tham số cho tinh chỉnh dựa trên gợi ý cứng và mềm.

Siêu tham số Gán
số bước 100 epochs
kích thước batch 256
tỷ lệ học tối đa 1e-05, 1e-4
bộ tối ưu tỷ lệ học AdamW
Adam epsilon 1e-6
trọng số beta Adam 0.9, 0.98
lịch trình tỷ lệ học Warmup linear
Weight decay 0.01
tỷ lệ Warmup 0.06
Xác suất Che giấu 0.15

Bảng 11: Siêu tham số cho cả tiền huấn luyện tiếp tục thông thường (TAPT) và tinh chỉnh thông thường dựa trên gợi ý (PCP).

Siêu tham số Gán
số bước 12 800 hoặc 25 600 bước
kích thước batch 16
tỷ lệ học 1e-05, 2e-05, 5e-05
bộ tối ưu tỷ lệ học AdamW
độ dài chuỗi tối đa 256
lịch trình tỷ lệ học Warmup linear
tỷ lệ Warmup 0.05
giảm tỷ lệ học linear

Bảng 12: Siêu tham số cho tự huấn luyện. Các siêu tham số cụ thể cho thuật toán sẽ được phát hành trong các tệp cấu hình cùng với mã nguồn.

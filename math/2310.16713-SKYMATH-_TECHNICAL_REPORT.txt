# 2310.16713.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/math/2310.16713.pdf
# File size: 872574 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
SKYMATH: TECHNICAL REPORT
Liu Yang, Haihua Yang, Wenjun Cheng, Lei Lin, Chenxia Li, Yifu Chen, Lunan Liu,
Jianfei Pan, Tianwen Wei, Biye Li, Liang Zhao, Lijie Wang, Bo Zhu, Guoliang Li,
Xuejie Wu, Xilin Luo, Rui Hu†
Kunlun Inc.
rui.hu@kunlun-inc.com
ABSTRACT
Large language models (LLMs) have shown great potential to solve varieties of
natural language processing (NLP) tasks, including mathematical reasoning. In
this work, we present SkyMath, a large language model for mathematics with
13 billion parameters. By applying self-compare fine-tuning, we have enhanced
mathematical reasoning abilities of Skywork-13B-Base remarkably. On GSM8K,
SkyMath outperforms all known open-source models of similar size and has es-
tablished a new SOTA performance. On dataset MATH and out-of-domain dataset
CMath, SkyMath also achieves a high accuracy rate, showing remarkable gener-
alizability to varieties of math problems.
1 I NTRODUCTION
Nowadays, Large language models (LLMS) are increasingly being applied to all kinds of complex
tasks, including content creation (Gardner et al., 2023; Zhang et al., 2023a; Zhu et al., 2023; Dai
et al., 2023; Liu et al., 2023a), code generation (Nijkamp et al., 2023; Wang et al., 2023d; Fried et al.,
2023; Chen et al., 2021; Li et al., 2023; Zheng et al., 2023b), multi-turn conversations (Thoppilan
et al., 2022; Touvron et al., 2023b; Bai et al., 2023; Yang et al., 2023a; Zeng et al., 2023; Shu
et al., 2023), mathematical reasoning (Azerbayev et al., 2023; Yue et al., 2023; Yu et al., 2023;
Luo et al., 2023a; Qiao et al., 2023; Chern et al., 2023; Fu et al., 2023a), and knowledge-based
question answering (Cui et al., 2023; Wu et al., 2023; Yang et al., 2023b; Wang et al., 2023a; Zhu &
Wang, 2023), and they have the potential to revolutionize the fields of natural language processing
and natural language understanding (OpenAI, 2022, 2023). Moreover, compared to traditional AI
methods, LLMs gain unparalleled advantages in these landscapes. Generative Artificial Intelligence
(GenAI) fueled by LLMs is just around the corner.
Despite their impressive capabilities, LLMs come with a series of challenges and issues. Math-
ematical reasoning is one of subfields worth exploring. In the context of evaluating the reason-
ing capabilities of LLMs, complex mathematical reasoning serves as a crucial benchmark. More-
over, mathematical reasoning tasks are considered to be one of the major gaps between closed-
source models like ChatGPT (OpenAI, 2022) or GPT4 (OpenAI, 2023) and open-source models
like LLaMA (Touvron et al., 2023a,b). To achieve advanced mathematical reasoning capabilities,
numerous open-source models have made attempts: Kuaishou introduces the KwaiYiiMath by ap-
plying Supervised Fine-Tuning (SFT) and Reinforced Learning from Human Feedback (RLHF) and
constructed a small-scale Chinese primary school mathematics test set (named KMath) (Fu et al.,
2023a); Microsoft presentes wizardMath by applying their proposed Reinforcement Learning from
Evol-Instruct Feedback (RLEIF) method to the domain of math (Luo et al., 2023a); Xiang et al. in-
troduce MAmmoTH by training the model on their self-developed dataset MathInstruct (Yue et al.,
2023); Zhangir et al. presente LLEMMA by continue pretraining Code Llama on Proof-Pile-2, a
mixture of scientific papers, web data containing mathematics, and mathematical code (Azerbayev
et al., 2023); Yu et al. (Yu et al., 2023) proposes MetaMath trained on a new dataset called Meta-
MathQA which is build by bootstrapping mathematical questions by rewriting the question from
multiple perspectives. Despite the great success, most existing open-source LLMs are still far away
from satisfactory for solving mathematical problems due to the complex reasoning procedures, and
preform poorly on GSM8K and MATH when compared to open-sourced models.
1arXiv:2310.16713v2  [cs.CL]  26 Oct 2023

--- PAGE 2 ---
To bridge this gap, we propose SkyMath, a finetuned language model that specializes in mathe-
matical reasoning, by applying our improved data augmentation techniques and SFT process to the
finetuning of Skywork-13B-Base. The main process consists of three parts, as follows: 1. Fine-
tuning the Skywork-13B-Base model on open-source datasets; 2. Constructing a new dataset for
math by improved data augmentation techniques; 3. Reconstructing math dataset by applying our
proposed self-check techniques. Experimental results show that SkyMath outperforms many open-
source models in similar sizes on two mathematical benchmarks, namly GSM8k (Cobbe et al., 2021)
and MATH (Hendrycks et al., 2021).
The paper is structured as follows. Section 2 provides an overview of related work including LLMs
and LLMs for mathematics. Section 3 introduces the methodology of Skywork-13B-Math including
sample construction methods and process of supervised fine-tuning . Then, the experimental vali-
dations and comparisons are made in Section 4 and Section 5. The conclusion is drawn in Section
6.
2 R ELATED WORK
Large Language Models Recently, LLMs have achieved substantial progress in natural language
processing tasks, benefiting from high-quality, diverse textual data, and enormous model parame-
ter counts. Researchers have found that LLMs perform better on downstream tasks (Kaplan et al.,
2020). LLMs, which pretrained on extensive textual data and fine-tuned for specific tasks, demon-
strate remarkable capabilities in numerous natural language processing tasks compared to smaller
models (Devlin et al., 2019; Wei et al., 2022b). The significant capabilities of large models mainly
lie in three aspects: 1. In-context learning. 2. Instruction following. 3. Step-by-step reasoning
(Zhao et al., 2023). The GPT-3 (Brown et al., 2020), a language model that has tens of billions
parameter counts, exhibits significant performance improvements in few-shot, one-shot, and zero-
shot learning tasks through in-context learning. However, the effectiveness of in-context learning
capability depends on different downstream tasks. The open-source model Llama2 (Touvron et al.,
2023b), with a pre-trained context length of up to 4k, demonstrates robust contextual understanding
in tasks such as summarization, multi-turn dialogues, and reading comprehension. LLMs handle
different downstream tasks efficiently, but sometimes these pre-trained models still struggle to com-
prehend human instructions (Ouyang et al., 2022). It is highly challenging for LLMs to understand
and follow specific instructions in the complex natural language tasks. To overcome the challenge,
Instruction Tuning (IT) (Zhang et al., 2023b) and Chain of Thought (CoT) (Wei et al., 2022c) have
been proposed. Specifically, IT aims to utilize the constructed pairs whose formats are [instruction,
output] to fine-tune the pre-trained language model. Moreover, the adoption of multitask instruction
blending in fine-tuning has demonstrated the effectiveness of IT techniques in unseen tasks (Sanh
et al., 2022; Ouyang et al., 2022; Wei et al., 2022a). Numerous studies show that high-quality, di-
verse instructions can effectively improve the performance of LLMs in natural language tasks (Wang
et al., 2023c; Zhou et al., 2023; Wei et al., 2022a; Cao et al., 2023). CoT is a method that aims to
improve the performance of LLMs by providing detailed reasoning processes as training inputs. By
enabling the model to follow a step-by-step process, CoT helps LLMs to break down complex prob-
lems into smaller ones and accumulate small victories to achieve greater success (Wei et al., 2022c).
This approach has led to significant improvements in the reasoning capabilities of LLMs, especially
in mathematical reasoning and decision-making tasks. The success of CoT and IT technologies in
Self-Supervised Fine-Tuning (SFT) has opened up new possibilities for enhancing the performance
of LLMs. Numerous models, including InstructonGPT (Ouyang et al., 2022), BLOOMZ (Muen-
nighoff et al., 2023), WizardLM (Xu et al., 2023), ChatGLM2 (Du et al., 2022), and Vicuna (Chiang
et al., 2023), have acquired powerful reasoning abilities, allowing them to perform complex tasks
with remarkable accuracy. In addition, by training LLMs on data specific to a particular domain,
such as medical or legal, it is possible to obtain models that excel in that domain. Models obtained
in this way include InstructDial (Gupta et al., 2022), Radiology-GPT (Liu et al., 2023b), Goat (Liu
& Low, 2023), WizardCoder (Luo et al., 2023b).
Large Language Models for Mathematical reasoning Mathematical reasoning is one of the es-
sential abilities required for LLMs. To enhance mathematical reasoning capabilities of base LLMs,
a group of researchers conducted a comprehensive study. Based on CoT, a series of works are car-
ried out to optimize the reasoning paths (Wang et al., 2023b; Fu et al., 2023b; Huang et al., 2022).
2

--- PAGE 3 ---
Wang et al. introduces Self-Consistency, employing the results of multiple reasoning paths to en-
hance the accuracy of inference through consistent answers (Wang et al., 2023b). Fu et al. proposes
Complexity-based CoT, achieving improved performance in mathematical reasoning tasks through
a CoT involving multiple complex reasoning steps (Fu et al., 2023b). In terms of prompting engi-
neering, Zheng et al. combines CoT to generate answers, utilizing the answer from the previous step
as a prompt for the next step, gradually guiding LLMs to generate correct answers (Zheng et al.,
2023a). Luo et al. proposes reinforced evol-instruct, a method that combines evol-instruct with
reinforcement learning to enhance the reasoning performance of LLMs (Luo et al., 2023a). Madaan
et al. introduces Self-Refine, which a single LLM serves simultaneously as a generator, refiner, and
feedback provider, iteratively refining itself to enhance its capabilities in mathematical reasoning
(Madaan et al., 2023). Yu et al. constructs a new dataset, MetaMathQA, through data augmen-
tation of rewriting of mathematical problems from multiple perspectives (Yu et al., 2023). Fu et
al. enhances the mathematical reasoning capabilities of LLMs through a combination of supervised
fine-tuning and reinforcement learning with human feedback (RLHF) (Fu et al., 2023a). Based on
Cot and Program of Thoughts (PoT) (Chen et al., 2022), Yue et al. constructs a new dataset namly
MathInstruct and uses it in SFT. PoT utilizes an external interpreter (e.g., Python interpreter) to
compute answers for complex mathematical problems (Yue et al., 2023). Azerbayev et al. continues
pretraining on Proof-Pile-2, a dataset containing mathematical web data and mathematical code, and
uses PoT to obtain an accurate answer (Azerbayev et al., 2023).
3 M ETHOD
In this section, we introduce SkyMath in detail. As shown in Figure 1, our method mainly contains
two steps:
1. Instruction boosting.
2. Self-compare fine-tuning.
Figure 1: The Overview Architecture of SkyMath
3.1 I NSTRUCTION BOOSTING
Previous work has shown math instructions with various complexities could make remarkable effect
on math LLMs training (Luo et al., 2023a). Therefore, the first step we do is constructing a dataset
of both high quality and diversity.
1. We first collect a math dataset from different sources, including different levels, in both Chinese
3

--- PAGE 4 ---
and English.
2. Then inspired by WizardLM (Xu et al., 2023) and MetaMath (Yu et al., 2023), we adapt instruc-
tion boosting, namely 1) concretizing, 2) adding constraints, 3) deepening and 4) rephrasing, to the
question augmentation process.
3. We use LLMs to generate responses for augmented questions.
4. Correctness check.
By now, we have got a dataset of high complexity.
3.2 S ELF-COMPARE FINE-TUNING
Progressive-Hint Prompting (PHP) (Zheng et al., 2023a) enables multiple interactions between users
and LLMs by using previously generated answers as hints to progressively guide LLMs toward the
correct answers. Inspired by this, we believe introducing previous answers to the training process
also has an effect. We hope the model can compare its previous answers with ground truth and
correct its specific errors through training.
Figure 2: Self-compare Fine-tuning
As shown in Figure 2, self-compare fine-tuning contains four steps:
1. For each question, ask the LLM to give an answer.
2. 2. Construct self-compare prompts, as shown in Figure 3.
3. Combine the data with the origin dataset.
4. Fine-tuning.
Like human beings, we believe LLMs tend to make different mistakes as their abilities improve.
Therefore, in practice we divide the origin dataset into several sub-datasets thus we can repeat self-
compare fine-tuning more than once.
4 E XPERIMENTS
4.1 E VALUATION BENCHMARKS
We mainly evaluate SkyMath on two popular mathematical reasoning benchmarks: GSM8k (Cobbe
et al., 2021) and MATH (Hendrycks et al., 2021). In order to see the performance of SkyMath on
the out-of-domain dataset and in chinese, we also evaluate our model on CMath (Wei et al., 2023),
for completeness.
4

--- PAGE 5 ---
Figure 3: Self-compare Prompts
GSM8k contains 7,473 training data and 1,319 test data, mainly on grade school level English math
problems. Each problem takes between 2 and 8 steps to solve, and solutions primarily involve
performing a sequence of elementary calculations using basic arithmetic operations.
MATH is much more challenging. It contains 7,500 training data and 5,000 test data, spans seven
subjects including Prealgebra, Algebra, Number Theory, Counting and Probability, Geometry, In-
termediate Algebra, and Precalculus.
CMath is a Chinese Elementary School Math Word Problems (CMATH) dataset, which contains
1.7k elementary school-level math word problems with detailed annotations, sourced from actual
Chinese workbooks and exams. We use it as an out-of-domain dataset.
4.2 M ODEL AND BASELINES
We use SkyWork-13B as base model and correspondingly choose models of the same size and has
already been open source for comparison. Therefore we choose LLaMA1 (Touvron et al., 2023a),
LLaMA2 (Touvron et al., 2023a), BaiChuan1 (Yang et al., 2023a), BaiChuan2 (Yang et al., 2023a),
WizardMath (Luo et al., 2023a), GAIRMath-Abel (Chern et al., 2023), and MetaMath (Yu et al.,
2023) as baselines.
5 M AINRESULTS
Table 1: Results of pass@1 (%) on GSM8k, MATH and CMath
Model #Params GSM8K Math CMath
LLaMA1 (Touvron et al., 2023a) 13B 17.8 3.9 -
LLaMA2 (Touvron et al., 2023a) 13B 28.7 3.9 -
BaiChuan1 (Yang et al., 2023a) 13B 26.76 4.84 51.33
BaiChuan2 (Yang et al., 2023a) 13B 52.77 10.08 -
WizardMath (Luo et al., 2023a) 13B 63.9 14.0 50.83
GAIRMath-Abel (Chern et al., 2023) 13B 66.41 17.34 -
MetaMath (Yu et al., 2023) 13B 72.3 22.4 -
SkyMath 13B 72.33 16.98 77.27
5

--- PAGE 6 ---
Evaluating results are shown in Table 1. SkyMath outperforms all baselines on GSM8K, thus we
have established a new SOTA performance across open-source LLMs of similar size. On the MATH
dataset, which is highly challenging, SkyMath also achieves a high accuracy rate. Meanwhile, on
the out-of-domain dataset CMath, SkyMath’s performance shows remarkable generalizability to
both unseen math problems and Chinese math problems.
6 C ONCLUSION AND FUTURE WORK
This paper introduces SkyMath, a mathematics model fine-tuned with self-compare. Evaluating re-
sults show SkyMath achieves SOTA performance across all existing open-source LLMs of similar
size on GSM8K and shows remarkable generalizability to out-of-domain math problems. Consider-
ing we didn’t use tools or reward models, the result is even more difficult.
Future Work. Although our model achieves impressive performance on GSM8K, we still fall far
behind models like GPT-4. In the future, we will explore more methods to improve the abilities of
our model.
REFERENCES
Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, Al-
bert Q. Jiang, Jia Deng, Stella Biderman, and Sean Welleck. Llemma: An open language model
for mathematics. arXiv preprint arXiv:2310.06786 , 2023.
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge,
Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu,
Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi
Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng
Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan,
Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou,
Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. Qwen technical report, 2023.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-
wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,
Ariel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.
Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,
Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In Hugo Larochelle,
Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Proceed-
ings of the 33th Annual Conference on Neural Information Processing Systems 2020 , 2020.
Yihan Cao, Yanbin Kang, and Lichao Sun. Instruction mining: High-quality instruction data selec-
tion for large language models. arXiv preprint arXiv:2307.06290 , 2023.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pond ´e de Oliveira Pinto, Jared
Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,
Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,
Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,
Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fo-
tios Chantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex
Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,
Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,
Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob
McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating
large language models trained on code. arXiv preprint arXiv:2107.03374 , 2021.
Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen. Program of thoughts prompt-
ing: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint
arXiv:2211.12588 , 2022.
Ethan Chern, Haoyang Zou, Xuefeng Li, Jiewen Hu, Kehua Feng, Junlong Li, and Pengfei Liu.
Generative ai for math: Abel. https://github.com/GAIR-NLP/abel , 2023.
6

--- PAGE 7 ---
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,
Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:
An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https:
//lmsys.org/blog/2023-03-30-vicuna/ .
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John
Schulman. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 ,
2021.
Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li Yuan. Chatlaw: Open-source legal large
language model with integrated external knowledge bases. arXiv preprint arXiv:2306.16092 ,
2023.
Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang,
Boyang Li, Pascale Fung, and Steven C. H. Hoi. Instructblip: Towards general-purpose vision-
language models with instruction tuning. arXiv preprint arXiv:2305.06500 , 2023.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep
bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies , pp. 4171–4186, 2019.
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. GLM:
general language model pretraining with autoregressive blank infilling. In Smaranda Muresan,
Preslav Nakov, and Aline Villavicencio (eds.), Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics , pp. 320–335. Association for Computational Linguis-
tics, 2022.
Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,
Scott Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling
and synthesis. In Proceedings of the 11th International Conference on Learning Representations .
OpenReview.net, 2023.
Jiayi Fu, Lei Lin, Xiaoyang Gao, Pengli Liu, Zhengzong Chen, Zhirui Yang, Shengnan Zhang, Xue
Zheng, Yan Li, Yuliang Liu, Xucheng Ye, Yiqiao Liao, Chao Liao, Bin Chen, Chengru Song,
Junchen Wan, Zijia Lin, Fuzheng Zhang, Zhongyuan Wang, Di Zhang, and Kun Gai. Kwaiyi-
imath: Technical report, 2023a.
Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. Complexity-based prompt-
ing for multi-step reasoning. In Proceedings of the 11th International Conference on Learning
Representations . OpenReview.net, 2023b.
Josh Gardner, Simon Durand, Daniel Stoller, and Rachel M. Bittner. Llark: A multimodal foundation
model for music, 2023.
Prakhar Gupta, Cathy Jiao, Yi-Ting Yeh, Shikib Mehri, Maxine Esk ´enazi, and Jeffrey P. Bigham.
Instructdial: Improving zero and few-shot generalization in dialogue through instruction tuning.
In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.), Proceedings of the 2022 Conference
on Empirical Methods in Natural Language Processing , pp. 505–525. Association for Computa-
tional Linguistics, 2022.
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,
and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset. In
Joaquin Vanschoren and Sai-Kit Yeung (eds.), Proceedings of the Neural Information Processing
Systems Track on Datasets and Benchmarks 1 , 2021.
Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei
Han. Large language models can self-improve. arXiv preprint arXiv:2210.11610 , 2022.
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child,
Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language
models. arXiv preprint arXiv:2001.08361 , 2020.
7

--- PAGE 8 ---
Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao
Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozh-
skii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier,
Jo˜ao Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee,
Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang,
Rudra Murthy V , Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan
Dey, Zhihan Zhang, Nour Moustafa-Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh,
Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee,
Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank
Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish
Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Mu ˜noz Ferran-
dis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. Starcoder:
may the source be with you! arXiv preprint arXiv:2305.06161 , 2023.
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. arXiv
preprint arXiv:2304.08485 , 2023a.
Tiedong Liu and Bryan Kian Hsiang Low. Goat: Fine-tuned llama outperforms GPT-4 on arithmetic
tasks. arXiv preprint arXiv:2305.14201 , 2023.
Zhengliang Liu, Aoxiao Zhong, Yiwei Li, Longtao Yang, Chao Ju, Zihao Wu, Chong Ma, Peng Shu,
Cheng Chen, Sekeun Kim, Haixing Dai, Lin Zhao, Dajiang Zhu, Jun Liu, Wei Liu, Dinggang
Shen, Xiang Li, Quanzheng Li, and Tianming Liu. Radiology-gpt: A large language model for
radiology. arXiv preprint arXiv:2306.08666 , 2023b.
Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qing-
wei Lin, Shifeng Chen, and Dongmei Zhang. Wizardmath: Empowering mathematical reasoning
for large language models via reinforced evol-instruct. arXiv preprint arXiv:2308.09583 , 2023a.
Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing
Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with
evol-instruct. arXiv preprint arXiv:2306.08568 , 2023b.
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri
Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bodhisattwa Prasad Ma-
jumder, Shashank Gupta, Amir Yazdanbakhsh, and Peter Clark. Self-refine: Iterative refinement
with self-feedback. arXiv preprint arXiv:2303.17651 , 2023.
Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le
Scao, M. Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir
Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson,
Edward Raff, and Colin Raffel. Crosslingual generalization through multitask finetuning. In
Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023,
Toronto, Canada, July 9-14, 2023 , pp. 15991–16111. Association for Computational Linguistics,
2023.
Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese,
and Caiming Xiong. Codegen: An open large language model for code with multi-turn program
synthesis. In Proceedings of the 11th International Conference on Learning Representations .
OpenReview.net, 2023.
OpenAI. Openai: Introducing chatgpt. 2022.
OpenAI. Gpt-4 technical report. 2023.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin,
Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser
Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan
Leike, and Ryan Lowe. Training language models to follow instructions with human feedback.
InProceedings of the Conference on Neural Information Processing Systems , 2022.
8

--- PAGE 9 ---
Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei
Huang, and Huajun Chen. Reasoning with language model prompting: A survey. In Anna Rogers,
Jordan L. Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics , pp. 5368–5393. Association for Computational
Linguistics, 2023.
Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai,
Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish
Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal V .
Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica,
Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj,
Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault F ´evry, Jason Alan Fries, Ryan Teehan,
Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M. Rush. Multitask
prompted training enables zero-shot task generalization. In Proceedings of the 10th International
Conference on Learning Representations . OpenReview.net, 2022.
Yu Shu, Siwei Dong, Guangyao Chen, Wenhao Huang, Ruihua Zhang, Daochen Shi, Qiqi Xiang,
and Yemin Shi. Llasm: Large language and speech model. arXiv preprint arXiv:2308.15930 ,
2023.
Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze
Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven
Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin,
James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi
Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-
Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny So-
raker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson,
Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna,
Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil,
Blaise Ag ¨uera y Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. Lamda: Language
models for dialog applications. arXiv preprint arXiv:2201.08239 , 2022.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth ´ee
Lacroix, Baptiste Rozi `ere, Naman Goyal, Eric Hambro, Faisal Azhar, Aur ´elien Rodriguez, Ar-
mand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation
language models. arXiv preprint arXiv:2302.13971 , 2023a.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-
lay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher,
Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy
Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn,
Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel
Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee,
Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi,
Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh
Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen
Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aur ´elien Rodriguez, Robert Stojnic,
Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models.
arXiv preprint arXiv:2307.09288 , 2023b.
Haochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, and Ting Liu. Huatuo:
Tuning llama model with chinese medical knowledge. arXiv preprint arXiv:2304.06975 , 2023a.
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V . Le, Ed H. Chi, Sharan Narang, Aakanksha
Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language
models. In Proceedings of the 11th International Conference on Learning Representations . Open-
Review.net, 2023b.
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and
Hannaneh Hajishirzi. Self-instruct: Aligning language models with self-generated instructions.
9

--- PAGE 10 ---
In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st
Annual Meeting of the Association for Computational Linguistics , pp. 13484–13508. Association
for Computational Linguistics, 2023c.
Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D. Q. Bui, Junnan Li, and Steven C. H.
Hoi. Codet5+: Open code large language models for code understanding and generation. arXiv
preprint arXiv:2305.07922 , 2023d.
Jason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,
Andrew M. Dai, and Quoc V . Le. Finetuned language models are zero-shot learners. In Proceed-
ings of the 10th International Conference on Learning Representations . OpenReview.net, 2022a.
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yo-
gatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol
Vinyals, Percy Liang, Jeff Dean, and William Fedus. Emergent abilities of large language models.
Transactions on Machine Learning Research , 2022, 2022b.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi,
Quoc V . Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language
models. In Proceedings of the Conference on Neural Information Processing Systems , 2022c.
Tianwen Wei, Jian Luan, Wei Liu, Shuang Dong, and Bin Wang. CMATH: can your language model
pass chinese elementary school math test? arXiv preprint arXiv:2306.16636 , 2023.
Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prab-
hanjan Kambadur, David S. Rosenberg, and Gideon Mann. Bloomberggpt: A large language
model for finance. arXiv preprint arXiv:2303.17564 , 2023.
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and
Daxin Jiang. Wizardlm: Empowering large language models to follow complex instructions.
arXiv preprint arXiv:2304.12244 , 2023.
Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan,
Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng
Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, Juntao
Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel
Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li,
Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu,
Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang,
Zenan Zhou, and Zhiying Wu. Baichuan 2: Open large-scale language models. arXiv preprint
arXiv:2309.10305 , abs/2309.10305, 2023a.
Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. Fingpt: Open-source financial large
language models. arXiv preprint arXiv:2306.06031 , 2023b.
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok,
Zhenguo Li, Adrian Weller, and Weiyang Liu. Metamath: Bootstrap your own mathematical
questions for large language models. arXiv preprint arXiv:2309.12284 , 2023.
Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen.
Mammoth: Building math generalist models through hybrid instruction tuning. arXiv preprint
arXiv:2309.05653 , 2023.
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan
Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang
Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, and Jie Tang. GLM-130b: An open bilingual pre-
trained model. In Proceedings of the 11th International Conference on Learning Representations ,
2023.
Pan Zhang, Xiaoyi Dong, Bin Wang, Yuhang Cao, Chao Xu, Linke Ouyang, Zhiyuan Zhao, Shuan-
grui Ding, Songyang Zhang, Haodong Duan, Wenwei Zhang, Hang Yan, Xinyue Zhang, Wei
Li, Jingwen Li, Kai Chen, Conghui He, Xingcheng Zhang, Yu Qiao, Dahua Lin, and Jiaqi Wang.
Internlm-xcomposer: A vision-language large model for advanced text-image comprehension and
composition. arXiv preprint arXiv:2309.15112 , 2023a.
10

--- PAGE 11 ---
Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi
Hu, Tianwei Zhang, Fei Wu, and Guoyin Wang. Instruction tuning for large language models: A
survey. arXiv preprint arXiv:2308.10792 , 2023b.
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min,
Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen,
Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and
Ji-Rong Wen. A survey of large language models. arXiv preprint arXiv:2303.18223 , 2023.
Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and Yu Li. Progressive-hint prompting
improves reasoning in large language models. arXiv preprint arXiv:2304.09797 , 2023a.
Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen,
Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. Codegeex: A pre-trained model for
code generation with multilingual evaluations on humaneval-x, 2023b.
Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and
Jimmy Ba. Large language models are human-level prompt engineers. In Proceedings of the 11th
International Conference on Learning Representations . OpenReview.net, 2023.
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: En-
hancing vision-language understanding with advanced large language models. arXiv preprint
arXiv:2304.10592 , 2023.
Wei Zhu and Xiaoling Wang. Chatmed: A chinese medical large language model. https:
//github.com/michael-wzhu/ChatMed , 2023.
11

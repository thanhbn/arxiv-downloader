# 2401.08190.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2401.08190.pdf
# Kích thước tệp: 1060445 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
MARIO: Lý luận Toán học với đầu ra Trình thông dịch mã
– Một Pipeline Có thể Tái tạo
Minpeng Liao∗, Wei Luo∗, Chengxi Li∗, Jing Wu∗, Kai Fan†
Alibaba Group
{minpeng.lmp,muzhuo.lw,xiji.lcx,wj334275,k.fan}@alibaba-inc.com
Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) đã có những tiến bộ đáng kể trong các tác vụ hiểu ngôn ngữ tự nhiên, tuy nhiên vẫn còn khoảng cách cần khắc phục trước khi đạt được trí tuệ nhân tạo tổng quát thực sự, đặc biệt là những thiếu sót trong khả năng lý luận toán học. Chúng tôi đề xuất rằng bản chất vốn có của việc huấn luyện LLM, tập trung vào việc dự đoán xác suất của token tiếp theo, đặt ra những thách thức trong việc mô hình hóa hiệu quả lý luận toán học đòi hỏi tính toán chính xác, cả từ quan điểm dữ liệu và lý thuyết. Trong bài báo này, chúng tôi giải quyết thách thức này bằng cách làm phong phú cảnh quan dữ liệu và giới thiệu một bộ dữ liệu toán học mới, được tăng cường với khả năng sử dụng trình thông dịch mã Python. Bộ dữ liệu này được phát triển từ GSM8K[7] và MATH[15] và đã được tinh chỉnh thêm thông qua sự kết hợp của chú thích GPT-4, đánh giá con người và quy trình tự huấn luyện, trong đó các lỗi trong bộ huấn luyện GSM8K gốc đã được sửa. Ngoài ra, chúng tôi đề xuất một giao thức thử nghiệm, dễ tái tạo cho việc tinh chỉnh các LLM chuyên về toán học, điều này đã dẫn đến cải thiện đáng kể trong hiệu suất của LLM 7B tham số trên các bộ dữ liệu GSM8K và MATH. Chúng tôi cam kết thúc đẩy lĩnh vực lý luận toán học trong LLM và vì mục đích đó, chúng tôi đã công khai mã nguồn cho việc tạo dữ liệu/huấn luyện/suy luận và các checkpoint mô hình tại https://github.com/MARIO-Math-Reasoning/MARIO. Chúng tôi hy vọng điều này sẽ tạo điều kiện thuận lợi cho nghiên cứu và phát triển thêm trong cộng đồng.

1 Giới thiệu
Kỹ thuật nhắc nhở Chuỗi Tư duy (CoT)[34] đã được chứng minh thực nghiệm là tăng cường khả năng lý luận phức tạp của các mô hình ngôn ngữ lớn (LLM) bằng cách tạo ra một chuỗi các bước lý luận trung gian. Các LLM thương mại hoặc độc quyền, bao gồm GPT-4[25] và Claude-2[3], được thiết kế để tạo ra các phản hồi CoT theo mặc định, dẫn đến cải thiện hiệu suất lý luận toán học, như được chứng minh bởi tỷ lệ chính xác 50.36% trên bộ dữ liệu MATH với GPT-4[44].
Hơn nữa, khi các LLM này được tăng cường với plugin có khả năng thực thi các đoạn mã, độ chính xác của chúng trong tính toán số học—thường là thách thức đối với LLM—được cải thiện thêm. Ví dụ, GPT-4-Code đạt tỷ lệ chính xác 69.69% trên bộ dữ liệu MATH[44]. Điều này nhấn mạnh hiệu quả của việc tích hợp phân tích văn bản với thực thi mã trong các bộ dữ liệu được thiết kế cho các tác vụ lý luận toán học.

Gần đây, Yang et al.[38] đã chứng minh rằng, mặc dù có việc tinh chỉnh rộng rãi về các phép toán số học, các mô hình ngôn ngữ lớn (LLM) vẫn không thể đạt được độ chính xác hoàn hảo. Do đó, việc tích hợp mã để tính toán số chính xác đã trở thành một xu hướng không thể tránh khỏi. Khung Chương trình Tư duy (PoT)[6] và các mô hình Ngôn ngữ Hỗ trợ Chương trình (PAL)[12] đại diện cho những nỗ lực tiên phong trong việc tạo ra các bộ dữ liệu tập trung vào mã cho nghiên cứu học thuật. Dựa trên xu hướng này, ToRA[14] thúc đẩy lĩnh vực này bằng cách sử dụng phương pháp chú thích độc quyền cùng với GPT-4, thiết lập một điểm chuẩn mới cho hiệu suất tiên tiến trong việc giải quyết các bài toán toán học thông qua thông dịch mã.

Tuy nhiên, cần lưu ý rằng các giải pháp chứa trong các bộ dữ liệu này chủ yếu bao gồm các đoạn mã, với phân tích văn bản đi kèm tối thiểu. Một thiếu sót rõ ràng của giải pháp tập trung vào mã là nó có thể bỏ qua lẽ thường trong các bài toán từ toán học. Ví dụ, như được minh họa trong Hình 1b, các giải pháp PoT bỏ qua thực tế rằng số lượng thức ăn lấy đi không thể âm. MathCoder[32] đại diện cho một sáng kiến mô phỏng các mẫu phản hồi của GPT-4, tích hợp một plugin thành thạo cả trong việc tạo mã và lý luận ngôn ngữ tự nhiên. Cách tiếp cận này khai thác khả năng của GPT-4, được trang bị trình thông dịch mã, để tự động hóa quá trình chú thích, tạo ra sự pha trộn giữa phân tích văn bản và đoạn mã, được hướng dẫn bởi các hướng dẫn phù hợp.

Cách tiếp cận tạo dữ liệu của chúng tôi nhìn chung phản ánh của MathCoder, nhưng với việc tăng cường thêm một lớp xác minh con người đặc biệt cho việc sửa chữa các lỗi dễ khắc phục. Do đó, tất cả các giải pháp sai trong bộ huấn luyện GSM8K gốc đã được sửa chữa thủ công. Ngược lại, bộ dữ liệu MATH bao gồm các vấn đề khó khăn hơn và đòi hỏi chuyên môn của các chú thích viên chuyên nghiệp. Để giải quyết vấn đề này, chúng tôi sử dụng các kỹ thuật tự huấn luyện và chưng cất kiến thức để chọn lọc xác định các giải pháp đúng, cùng với nhiều mẫu hơn.

Hơn nữa, chúng tôi giới thiệu một giao thức thử nghiệm và dễ tái tạo cho việc tinh chỉnh các Mô hình Ngôn ngữ Lớn (LLM) chuyên về toán học. Để đảm bảo khả năng tái tạo của các thí nghiệm, chúng tôi bắt đầu với LLM được nghiên cứu rộng rãi, Llama-2[31], và sử dụng biến thể tiền huấn luyện liên tục hướng toán học của nó, Llemma[4]. Sau đó, chúng tôi áp dụng tinh chỉnh có giám sát cho bộ dữ liệu chú thích của chúng tôi để thiết lập một mô hình cơ sở.

Không giống như các tác vụ tạo văn bản như tóm tắt hoặc dịch thuật, lý luận toán học thường cho ra một câu trả lời duy nhất, điều này đơn giản hóa việc xác minh tính đúng đắn của nó. Tuy nhiên, việc đánh giá quá trình lý luận dẫn đến câu trả lời cuối cùng vẫn là thách thức. Để giải quyết vấn đề này, Lightman et al.[22] đã giới thiệu một mô hình được giám sát bởi quy trình và một bộ dữ liệu tương ứng với các thủ tục giải pháp được ghi nhãn thủ công. Tuy nhiên, từ quan điểm tái tạo, việc tạo ra những chú thích này vừa tốn nhiều lao động vừa tốn kém. Như một sự thỏa hiệp, chúng tôi khuyến nghị huấn luyện một mô hình giám sát kết quả đơn giản với cả các giải pháp đúng và sai như được mô tả bởi[8,40], để phục vụ như một công cụ phụ trợ cho việc so sánh và lựa chọn tốt nhất trong số các giải pháp khác nhau. Mô hình giá trị kết quả (OVM) của chúng tôi được tinh chỉnh bằng cách sử dụng huấn luyện LoRA hiệu quả[18] trong thiết lập đa tác vụ, cho phép mô hình bảo tồn tài nguyên tính toán trong khi duy trì khả năng tạo sinh của nó.

Tóm lại, những đóng góp chính của chúng tôi bao gồm ba khía cạnh.
1. Chúng tôi tạo ra một định dạng lý luận toán học tích hợp cả phân tích văn bản và đoạn mã, tận dụng lý luận logic và tính toán chính xác.
2. Chúng tôi giới thiệu một pipeline có thể tái tạo cho việc tinh chỉnh một mô hình ngôn ngữ lớn trong lĩnh vực toán học, bao gồm Tiền huấn luyện Liên tục (CPT), Tinh chỉnh Có giám sát (SFT), và Tinh chỉnh OVM Đa tác vụ.
3. Cả LLM SFT và Value của chúng tôi đều có thể tạo ra giải pháp, và LLM giá trị có thể đóng vai trò của mô hình giá trị kết quả. Các thí nghiệm của chúng tôi cho thấy rằng cách tiếp cận của chúng tôi có thể tăng cường đáng kể hiệu suất trên các tác vụ lý luận toán học, như được nêu bật trong Hình 1a.

2 Bộ dữ liệu
Trong phần này, chúng tôi sẽ cung cấp mô tả chi tiết về phương pháp và các bước liên quan đến việc xây dựng corpus hoàn chỉnh. Như đã đề cập trước đó, giải pháp mà chúng tôi muốn phát triển phải tích hợp phân tích văn bản và đoạn mã một cách liền mạch. Nội dung văn bản nên diễn đạt quá trình giải quyết vấn đề, trong khi các đoạn mã nên thực hiện các tính toán chính xác, có thể bao gồm đơn giản hóa ký hiệu, phân tích vi phân, phân tích số, giải phương trình, và xử lý bất đẳng thức, trong số các tác vụ khác. Điểm khởi đầu của chúng tôi sẽ là các bài toán toán học cấp tiểu học, cụ thể là bộ dữ liệu GSM8K.

GSM8K Để tạo ra một giải pháp ở định dạng mong muốn, chúng tôi sử dụng hướng dẫn lấy cảm hứng từ REACT[39] để đảm bảo GPT nhận ra khi nào cần sử dụng một công cụ bên ngoài, chẳng hạn như trình thông dịch mã Python ngoại tuyến, khi cần thiết. Ngoài hướng dẫn REACT trong prompt, chúng tôi cung cấp hai ví dụ minh họa được tạo thủ công trong prompt để mô hình ngôn ngữ mô phỏng. Để biết thêm chi tiết về thiết lập prompt, vui lòng xem Phụ lục 7.1.1.

Cho rằng các bài toán trong GSM8K tương đối đơn giản, chúng tôi ban đầu nhắc nhở cả GPT-3.5 và GPT-4 giải quyết mỗi câu hỏi với tối đa 5 đoạn mã trong tập huấn luyện sử dụng temperature 0, nhằm mô phỏng giải mã tham lam. Đối với các câu hỏi vẫn chưa được giải quyết sau hai lần thử ban đầu, chúng tôi giải quyết yêu cầu tiềm năng cho các giải pháp sáng tạo hơn bằng cách nhắc nhở lại GPT-4 với temperature 0.6 cho hai lần thử khác. Cách tiếp cận này nhằm tăng cường tính đa dạng của các phản hồi được tạo ra. Theo phương pháp này, chúng tôi thành công thu được ít nhất một giải pháp đúng cho 98.3% các câu hỏi trong tập huấn luyện GSM8K.

Khoảng 100 câu hỏi còn lại mà các câu trả lời được tạo bởi GPT không phù hợp với các câu trả lời từ tập huấn luyện gốc. Với số lượng có thể quản lý, chúng tôi đã tiến hành đánh giá thủ công về các khác biệt và sửa chữa bất kỳ sai sót nào được tìm thấy trong các câu trả lời do LLM tạo ra hoặc câu trả lời gốc. Điều này đảm bảo rằng mỗi câu hỏi trong tập huấn luyện GSM8K được liên kết với ít nhất một giải pháp đúng ở định dạng yêu cầu.

MATH Cách tiếp cận cơ bản để xây dựng các giải pháp cho bộ dữ liệu MATH tiếp tục dựa vào hướng dẫn REACT, với các chi tiết cụ thể của thiết lập prompt có sẵn để tham khảo trong Phụ lục 7.1.1. Tuy nhiên, có hai khác biệt chính. Đầu tiên, trong bốn lần thử ban đầu sử dụng GPT, chúng tôi độc quyền sử dụng GPT-4 với tối đa 8 đoạn mã được phép do độ khó đáng kể cao hơn của các câu hỏi MATH. Sau quá trình này, chỉ 71.8% các câu hỏi trong tập huấn luyện MATH được cung cấp ít nhất một giải pháp đúng.

Thứ hai, chúng tôi từ bỏ các giải pháp thủ công cho tất cả 1.208 câu hỏi còn lại do gánh nặng đáng kể mà nó đặt ra, đòi hỏi cả kiến thức chuyên môn và ngân sách quá mức. Thay vào đó, xác minh con người được áp dụng để sửa chữa các lỗi dễ khắc phục. Do đó, 83.9% các câu hỏi MATH được giải quyết chính xác, sau đó được kết hợp với bộ dữ liệu GSM8K đã tạo trước đó thành một bộ dữ liệu thống nhất với kích thước 26.9K. Điều này đã được tinh chỉnh trên một LLM MATH được tiền huấn luyện tốt, Llemma-34B[4]. Sử dụng mô hình giáo viên thu được, chúng tôi tạo ra tối đa 100 mẫu với temperature 0.6 cho mỗi câu hỏi chưa giải quyết, tiếp tục cho đến khi tối đa 4 giải pháp đúng được xác định. Thông qua cách tiếp cận này, chúng tôi đạt được phạm vi phủ sóng 93.8% các câu hỏi trong tập huấn luyện MATH với các giải pháp đúng.

Tăng cường Để tăng cường thêm quy mô và tính đa dạng của các câu hỏi trong bộ dữ liệu của chúng tôi, chúng tôi kết hợp khoảng 240K câu hỏi mới được lấy từ MetaMath[41]. Những câu hỏi này, là các biến đổi của những câu hỏi được tìm thấy trong các bộ dữ liệu GSM8K và MATH gốc, cho phép chúng tôi thu thập một tập hợp phong phú hơn các giải pháp mẫu bao gồm cả các ví dụ tích cực và tiêu cực. Chúng tôi dự đoán rằng chiến lược tăng cường dữ liệu này sẽ tăng cường đáng kể hiệu suất của mô hình và phục vụ các tín hiệu huấn luyện cho mô hình giá trị kết quả.

Định dạng lại Pipeline tạo dữ liệu cho REACT được mô tả trong Hình 2, dẫn đến một bộ dữ liệu hợp nhất bao gồm khoảng 28.8K giải pháp. Tuy nhiên, dữ liệu chúng tôi thu được bằng cách sử dụng từ khóa template REACT không được sử dụng trực tiếp. Thay vào đó, chúng tôi chuyển đổi dữ liệu REACT thành định dạng giống HTML, sử dụng <p></p> để bao gồm phân tích văn bản và <code></code> để bao gồm đoạn mã, như được minh họa trong Hình 5 trong Phụ lục 7.3. Chúng tôi quan sát thấy rằng sử dụng hướng dẫn REACT thường tạo ra đầu ra chất lượng cao hơn từ các mô hình GPT. Tuy nhiên, khi nói đến việc tinh chỉnh một Mô hình Ngôn ngữ Lớn (LLM) được tiền huấn luyện, việc sử dụng định dạng giống HTML cho lần lặp đầu tiên dẫn đến mất mát huấn luyện trung bình thấp hơn khoảng 20%. Một so sánh kỹ lưỡng có sẵn trong Phần 4. Giả thuyết của chúng tôi là định dạng giống HTML có thể thu hẹp khoảng cách giữa corpus tiền huấn luyện và corpus tinh chỉnh, dẫn đến hiệu suất khởi tạo được cải thiện.

3 Tinh chỉnh
Để tăng cường khả năng lý luận toán học của mô hình ngôn ngữ lớn, chúng tôi đề xuất sử dụng mô hình nền tảng Llemma[4]. Có hai lý do chính để chọn Llemma. Đầu tiên, Llemma đại diện cho việc tiếp tục quá trình tiền huấn luyện được khởi xướng bởi Llama-2[31], mở rộng thành thạo của nó vào cả lĩnh vực toán học và lập trình, điều này phù hợp hoàn hảo với yêu cầu của chúng tôi. Thứ hai, đã được chứng minh rằng cả Llama-2 và Llemma đều không thể hiện sự quá khớp quá mức trên bộ dữ liệu GSM8K hoặc MATH, như được xác nhận bởi[35].

3.1 Tinh chỉnh Có giám sát với Tham số Đầy đủ
Tinh chỉnh có giám sát phản ánh chặt chẽ bước tạo dữ liệu phục vụ để mở rộng phạm vi phủ sóng của bộ dữ liệu MATH. Trong giai đoạn SFT, chúng tôi điều chỉnh toàn bộ tập hợp các tham số của LLM sử dụng bộ dữ liệu được tuyển chọn đặc biệt của chúng tôi. Đối với mỗi câu hỏi q và giải pháp đúng tương ứng s+, chúng tôi tối ưu hóa mô hình bằng cách tối thiểu hóa mất mát entropy chéo bằng cách che các token của câu hỏi.
min−logp(s+|q) (1)

3.2 Tinh chỉnh Đa tác vụ với LoRA
Trong quá trình tạo giải pháp, Mô hình Ngôn ngữ (LLM) có khả năng tạo ra dễ dàng cả mẫu đúng (tích cực) và sai (tiêu cực) s−. Tính chất kép này cho phép chúng tôi huấn luyện LLM để phân biệt tính hợp lệ của một giải pháp bằng cách dự đoán xem câu trả lời cuối cùng có chính xác hay không. Để đạt được điều này, chúng tôi thêm một bộ phân loại nhị phân nhẹ (tức là một lớp tuyến tính được tham số hóa bởi W∈Rd×1 và b∈R với kích hoạt sigmoid), cùng với lớp softmax hiện có chịu trách nhiệm dự đoán token. Chúng tôi duy trì tỷ lệ gần như bằng nhau giữa các ví dụ tích cực và tiêu cực để huấn luyện cân bằng. Mất mát tổng thể tuân theo thiết lập đa tác vụ trong[8], trong khi khác biệt chính là LLM của chúng tôi được tinh chỉnh bằng phương pháp huấn luyện hiệu quả được gọi là LoRA[18].

min−logp(s+|q)−logp(y+|(q,s+))−logp(y−|(q,s−)) (2)

trong đó thuật ngữ đầu tiên đại diện cho mất mát tạo sinh truyền thống của việc huấn luyện LLM trên các giải pháp đúng, trong khi hai thuật ngữ sau tương ứng với mất mát phân loại được tính toán cho mỗi token của giải pháp đúng hoặc sai. Do đó, y là một vector nhị phân có độ dài bằng số token trong giải pháp s. Tương tự như[8], nhãn của mỗi token được xác định hoàn toàn bởi tính đúng đắn của giải pháp, tức là, y+=1; và y−=0.

Với kích thước dữ liệu lớn hơn đáng kể cần thiết cho việc huấn luyện Value LLM, chúng tôi sử dụng LoRA trong quá trình tinh chỉnh để hiệu quả hơn về mặt tính toán. Ngoài ra, huấn luyện LoRA cũng giữ lại khả năng tạo sinh của mô hình, tức là đóng vai trò kép trong việc tạo ra giải pháp và đánh giá chúng. Lợi ích chính của tính năng này là tính thực tế, vì nó chỉ đòi hỏi việc triển khai một LLM duy nhất cho toàn bộ quá trình suy luận. Khả năng này, được duy trì cùng với việc dự đoán các giá trị cấp độ token, cho phép các sửa đổi đơn giản cho thuật toán giải mã được sử dụng trong việc triển khai bộ giải mã transformer. Ví dụ, cơ chế tìm kiếm chùm có thể kết hợp log-likelihood gốc với giá trị dự đoán. Hướng tiềm năng này là những gì chúng tôi dự định khám phá trong công việc tương lai.

3.3 Suy luận
Cả SFT LLM và Value LLM đều có khả năng tạo ra giải pháp trực tiếp. LLM tạo giải pháp có thể được kết hợp với Value LLM, đóng vai trò như một mô hình giá trị kết quả (OVM). Value LLM chủ yếu phục vụ để đánh giá kết quả, tức là ước tính khả năng câu trả lời cuối cùng là chính xác. Để cải thiện chất lượng của các giải pháp được tạo ra bởi SFT LLM, người ta có thể xem xét việc xếp hạng lại nhiều giải pháp được lấy mẫu từ SFT LLM. Tuy nhiên, chúng tôi đề xuất sử dụng thuật toán lựa chọn OVM không có ngoại lệ để xác định câu trả lời tốt nhất. Cụ thể, với K giải pháp được lấy mẫu {si}K i=1 dẫn đến k câu trả lời cuối cùng khác biệt {aj}k j=1, tần suất của mỗi câu trả lời được biểu diễn như n1,···, nk, sao cho Σk j=1nj=K. Câu trả lời tối ưu được chọn theo tiêu chí κ= arg max {j|nj>δK}max si∈ajOVM (si). Trong các thí nghiệm của chúng tôi, với K= 20, chúng tôi đặt δK= 1. Điều này là do một số lượng nhỏ các mẫu, chẳng hạn như 20 trong ví dụ của chúng tôi, có thể dẫn đến tình huống mà một mẫu ngẫu nhiên tạo ra dự đoán kết quả bất thường cao, khiến việc loại trừ các giải pháp ngoại lệ trở nên quan trọng. Trong trường hợp hiếm hoi mà tất cả K giải pháp được lấy mẫu đều độc nhất, chúng tôi đơn giản chọn giải pháp có giá trị kết quả dự đoán cao nhất.

4 Thí nghiệm
4.1 Tóm tắt Bộ dữ liệu
Chúng tôi trình bày thống kê cho các ví dụ tích cực được sử dụng trong tinh chỉnh có giám sát trong Bảng 1. Dữ liệu hạt giống, bắt nguồn từ các bộ dữ liệu GSM8K và MATH, culminates trong một bộ sưu tập 26.9K giải pháp bằng chú thích GPT và con người, chủ yếu được sử dụng để huấn luyện mô hình giáo viên từ Llemma-34B. Đối với dữ liệu tăng cường thu được từ MetaMath, bao gồm 240K câu hỏi mới, chúng tôi sử dụng mô hình giáo viên để lấy mẫu một giải pháp cho mỗi câu hỏi và chọn ngẫu nhiên khoảng 55K cặp câu hỏi-giải pháp đúng. Khi áp dụng tự tạo sinh để tạo ra các ví dụ tích cực, một số lượng đáng kể các giải pháp không chính xác được tạo ra không thể tránh khỏi. Chúng có thể phục vụ như dữ liệu huấn luyện cho mô hình giá trị kết quả. Tổng cộng, chúng tôi đã thu thập 300K ví dụ, cả tích cực và tiêu cực, duy trì tỷ lệ nhãn cân bằng gần đúng.

Các tập kiểm tra trong miền đến từ các bộ dữ liệu GSM8K và MATH gốc. Chúng tôi cũng tiến hành đánh giá trên hai tập kiểm tra ngoài miền (OOD): bộ dữ liệu OCWCourses nguồn mở[21] và bộ dữ liệu GaoKao2023-Math-En độc quyền của chúng tôi. OCWCourses bao gồm một bộ sưu tập 272 bài toán STEM nhắm vào cấp độ đại học, đòi hỏi lý luận nhiều bước cho hầu hết các câu hỏi. Bộ dữ liệu GaoKao2023-Math-En bao gồm 385 bài toán toán học từ kỳ thi tuyển sinh đại học Trung Quốc năm 2023, được dịch chuyên nghiệp sang tiếng Anh. Hai bộ dữ liệu OOD thậm chí còn thách thức hơn so với bộ dữ liệu MATH.

4.2 Chi tiết Triển khai
Chúng tôi huấn luyện chuỗi Llemma[4] thông qua tinh chỉnh với corpus được tuyển chọn của chúng tôi, dẫn đến việc phát triển chuỗi SFT LLM của chúng tôi, bởi vì, trên GSM8K và MATH, Llama-2 đã được xác minh[35] không có vấn đề rò rỉ dữ liệu, và mô hình CPT của nó Llemma đã trải qua kiểm tra chồng chéo dữ liệu[4]. Trong giai đoạn tối ưu hóa này, chúng tôi thường sử dụng tốc độ học 5e-5, ngoại trừ các mô hình 7B và 34B, cho chúng tôi giảm tỷ lệ xuống 4e-5. Chúng tôi đặt kích thước batch toàn cục là 512 và sử dụng bộ lập lịch tốc độ học tuyến tính bao gồm giai đoạn khởi động chiếm 3% tổng thời gian huấn luyện, trải rộng trong 3 epoch. Huấn luyện cho tất cả các mô hình được khởi chạy với accelerate trong DeepSpeed ZeRO Stage2[26] và cơ chế Flash-Attention 2[9].

Khi tinh chỉnh value LLM với LoRA, chúng tôi cấu hình các siêu tham số với rank 4096 và alpha 2048 cho các tham số attention Wq và Wv. Trong bối cảnh kiến trúc Llama-2-7B, 2B tham số mô hình có thể huấn luyện. Chúng tôi sử dụng tốc độ học 5e-5, được điều chỉnh dần dần bằng bộ lập lịch cosine decay.

Trong quá trình suy luận, số lượng tối đa các đoạn mã được phép vẫn nhất quán với dữ liệu huấn luyện đã chuẩn bị, với giới hạn 5 cho GSM8K và 8 cho MATH. Đối với các bộ dữ liệu ngoài miền thách thức hơn, số lượng cũng được đặt ở 8 đoạn mã.

Baseline Chúng tôi tiến hành so sánh với các LLM tiền huấn luyện độc quyền và nguồn mở nổi tiếng như GPT[25], Claude[3], PaLM[1], Minerva[21], Gemini[30], Llama-2[31], CodeLlama[27], Qwen[5], và DeepSeek[10]. Ngoài ra, chúng tôi đã báo cáo kết quả từ nhiều mô hình nguồn mở khác nhau, đặc biệt là Llama-2, cùng với một số mô hình SFT bắt nguồn từ Llama-2, bao gồm RFT[42], WizardMath[23], MathCoder[32], MAmmoTH[43] và ToRA[14].

4.3 Kết quả Chính
Mô hình SFT Bảng 2 minh họa hiệu suất của mô hình chúng tôi trên bốn bộ dữ liệu bao gồm cả các vấn đề trong miền và ngoài miền. Mô hình giáo viên 34B của chúng tôi, MARIO-34B, được tinh chỉnh độc quyền trên bộ dữ liệu 26.9K, không phù hợp với hiệu suất của MathCoder hoặc ToRA ở cấp độ toán học tiểu học. Ngược lại, đối với các vấn đề phức tạp hơn trong bộ dữ liệu MATH, hoặc thậm chí đối với các vấn đề ngoài miền thách thức, mô hình 34B của chúng tôi liên tục vượt trội hơn những mô hình khác. Ít dữ liệu huấn luyện hơn có thể là một lý do, nhưng lý do chính nên là khả năng thực hiện phân tích văn bản của nó, phân tích các vấn đề thành các đoạn mã có thể quản lý, do đó tăng cường hiệu quả giải quyết vấn đề của nó. Điều này được xác minh bởi mô hình tương tự được quan sát với mô hình 7B của chúng tôi được huấn luyện trên bộ dữ liệu 82K, phù hợp với các phương pháp tiên tiến (SOTA) trong quá khứ. Vì vậy, chúng tôi kết luận rằng mô hình như vậy đạt được kết quả vượt trội trên các vấn đề phức tạp hơn, có thể vì những vấn đề này đòi hỏi nhiều hơn logic đơn giản và một vài bước số học — các tình huống mà các mô hình với cách tiếp cận tập trung vào mã thường có lợi thế.

Mô hình OVM Các phát hiện thực nghiệm của thuật toán lựa chọn OVM không có ngoại lệ được hiển thị trong Bảng 3, nơi chúng tôi tương phản cách tiếp cận của chúng tôi với thuật toán bỏ phiếu đa số. Các phát hiện của chúng tôi cho thấy rằng thuật toán OVM không có ngoại lệ có thể tăng cường đáng kể kết quả so với bỏ phiếu đa số, và lợi ích của bỏ phiếu đa số từ cách tiếp cận của chúng tôi có ý nghĩa hơn so với ToRA. Như đã đề cập trước đó, mô hình OVM được thiết kế cho học tập đa tác vụ, cho phép nó không chỉ đánh giá kết quả mà còn tạo ra giải pháp. Trong Bảng 3, chúng tôi trình bày kết quả toàn diện thể hiện hiệu suất của OVM khi nó đảm nhận cả vai trò tạo giải pháp và đánh giá kết quả. OVM thể hiện thành thạo tương đương trong việc tạo ra giải pháp; tuy nhiên, nó thể hiện hiệu quả hơi giảm trên các bộ dữ liệu ngoài miền. Kết quả này là điều mong đợi, cho rằng OVM của chúng tôi đã được tinh chỉnh liên tục trên các câu hỏi MetaMath, bắt nguồn từ các bộ dữ liệu GSM8K và MATH.

4.4 Nghiên cứu Loại bỏ
Chúng tôi thực hiện nghiên cứu loại bỏ đầu tiên để kiểm tra tác động của mỗi nguồn dữ liệu bằng cách thêm dần dần nhiều ví dụ huấn luyện hơn, với các phát hiện chính được chi tiết trong Bảng 4. Nhìn chung, những tiến bộ trong MATH nổi bật hơn. Chúng tôi quy cho xu hướng này ba yếu tố chính. Đầu tiên, bộ dữ liệu GSM8K, được tổng hợp bởi GPT, bao gồm 98.3% các câu hỏi, trái ngược với phạm vi phủ sóng 71.8% của bộ dữ liệu MATH. Thứ hai, tiêu chí lựa chọn cho bộ dữ liệu MATH dựa trên sự khớp chính xác giữa câu trả lời cuối cùng do GPT tạo ra và câu trả lời được cung cấp của bộ dữ liệu, có thể dẫn đến mô hình được tinh chỉnh quá khớp các câu hỏi cụ thể có câu trả lời đơn giản. Can thiệp của con người có tiềm năng tăng cường tính biến đổi của các câu trả lời. Cuối cùng, các giải pháp được tạo ra bởi mô hình giáo viên tập trung nhiều hơn vào bộ dữ liệu MATH. Điều này là do thực tế là chúng tôi đã trích xuất một số lượng lớn hơn các giải pháp lý luận nhiều bước theo các câu hỏi MetaMath, có khả năng phù hợp hơn với độ khó của bộ dữ liệu MATH.

Nghiên cứu loại bỏ thứ hai nhằm điều tra tác động của LLM toán học cơ bản và định dạng dữ liệu cho SFT. DeepSeek-MATH-7B[29], là một LLM chuyên về toán học được phát triển thông qua tiền huấn luyện liên tục trên mô hình Deep-Seek-Code-7B, hưởng lợi từ corpus tiền huấn luyện toán học rộng lớn hơn so với Llemma-7B và có chủ đích bỏ qua bất kỳ nội dung nào có thể liên quan đến các bộ dữ liệu GSM8K và MATH. Do đó, DeepSeek-MATH-7B được cho là vượt trội hơn Llemma-7B. Khi áp dụng SFT trên bộ dữ liệu SFT tập trung vào mã quy mô lớn, DeepSeek-MATH-7B có thể đạt được hiệu suất SOTA như LLM 7B. Kết quả được trình bày trong hàng thứ hai của Bảng 5 cho thấy kết quả tinh chỉnh DeepSeek-MATH-7B với bộ dữ liệu của chúng tôi. Mặc dù chỉ bằng 1/30 kích thước của bộ dữ liệu họ sử dụng, định dạng lai của chúng tôi thể hiện hiệu quả dữ liệu cao hơn. Kết quả được trình bày trong hàng cuối của Bảng 5 cho thấy rằng SFT từ một mô hình CPT vượt trội tăng cường khả năng lý luận toán học.

4.5 Tại sao GSM-Hard không phải là bộ kiểm tra tốt cho MATH LLM?
Bộ dữ liệu GSM-Hard, được giới thiệu bởi Gao et al.[12], tương tự như bộ kiểm tra GSM8K gốc, với sự khác biệt duy nhất là việc thay đổi các số trong các tuyên bố vấn đề gốc. Tuy nhiên, như được minh họa trong phần giới thiệu, những sửa đổi này đối với các số không phải lúc nào cũng phù hợp với lẽ thường của thế giới vật lý thực tế; ví dụ, tuổi không thể âm, và số lượng người không thể là phân số. Các phương pháp tuân theo paradigm PAL hoặc PoT có xu hướng tạo ra mã mà không xác minh tính hợp lý của đầu ra của chúng. Ngược lại, cách tiếp cận của chúng tôi kết hợp phân tích văn bản đảm bảo rằng các kết quả thu được từ thực thi mã phù hợp với các ràng buộc của thế giới vật lý. Kết quả là, LLM của chúng tôi sẽ chọn không tạo ra câu trả lời cuối cùng phi logic hoặc làm tròn phân số một cách tùy ý, ngay cả khi câu trả lời được gọi là chính xác đã được tính toán trong quá trình giải quyết vấn đề. Điều này giải thích cho độ chính xác thấp hơn được quan sát với phương pháp của chúng tôi trên bộ dữ liệu này, như được hiển thị trong Bảng 6.

Ngoài ra, chúng tôi phát hiện ra rằng các giải pháp trong GSM-Hard vẫn giống như GSM8K gốc, ngay cả khi các số đã thay đổi. Để có các ví dụ phức tạp hơn, vui lòng tham khảo nghiên cứu trường hợp được cung cấp trong Phụ lục 7.4. Tóm lại, chúng tôi khuyến nghị không sử dụng bộ dữ liệu GSM-Hard trong cộng đồng này trừ khi các lỗi đã đề cập được sửa.

4.6 Tại sao định dạng lại thành HTML?
Template tiêu chuẩn cho REACT được minh họa trong Phụ lục 7.1.5 sử dụng định dạng cặp khóa-giá trị được biểu diễn như chuỗi, với mỗi bước bao gồm các yếu tố như "Thought:text analysis", "Action: tool name", "Action Input: code snippet", và "Observation: execution output".

Phân tích của chúng tôi về log-likelihood cho các ví dụ REACT cho thấy rằng các định dạng dữ liệu như vậy hiếm trong các corpus được sử dụng để tiền huấn luyện LLM. Ngược lại, khi chuyển đổi dữ liệu REACT thành định dạng HTML, sử dụng các thẻ như "<p>text analysis</p>" và "<code>code snippet</code>", chúng tôi ghi nhận sự giảm đáng kể trong log-likelihood. Trong pipeline dữ liệu của chúng tôi trong Hình 2, khi huấn luyện Llemma-34B trên bộ dữ liệu 26.9K với các định dạng khác nhau, sự giảm này rõ ràng từ mất mát ban đầu được quan sát trong lần lặp đầu tiên.

Như Hình 4 minh họa, mất mát cho tinh chỉnh với dữ liệu định dạng HTML thấp hơn 20% so với khi sử dụng định dạng REACT gốc. Tuy nhiên, khi đánh giá hiệu suất trên các tập kiểm tra sau 3 epoch SFT, chúng tôi quan sát chỉ cải thiện nhẹ (1%) trên tập kiểm tra MATH. Với mất mát ban đầu giảm đáng kể, chúng tôi đưa ra giả thuyết rằng việc điều chỉnh siêu tham số cẩn thận có thể có khả năng tăng cường hiệu suất của dữ liệu được định dạng trong HTML. Chúng tôi dự định khám phá khả năng này trong công việc tương lai.

5 Công việc Liên quan
Lý luận toán học thu hút nhiều sự chú ý hơn do sự xuất hiện của LLM. Các công trình gần đây[34,20,33,10] về lý luận toán học đã đạt được tiến bộ ấn tượng được hỗ trợ bởi LLM. Tuy nhiên, tính toán chính xác và thao tác ký hiệu trong quá trình lý luận vẫn là thách thức. Một số công trình đã khám phá các công cụ bao gồm máy tính[8,28] và trình thông dịch mã[12] để giải quyết những hạn chế. Nghiên cứu thêm[32,43,14] cố gắng kết hợp sử dụng công cụ và quá trình lý luận văn bản để tận dụng điểm mạnh của cả hai.

Chưng cất kiến thức[16,13] là một cách tiếp cận thường được sử dụng để thúc đẩy các mô hình học sinh bằng cách chuyển giao kiến thức từ các mô hình giáo viên cho chúng. Việc sử dụng LLM giáo viên để xây dựng các mẫu lý luận cho mô hình học sinh để tinh chỉnh đã được chứng minh là thực hành hiệu quả của chưng cất kiến thức[11,17]. Việc xây dựng corpus của chúng tôi bao gồm chưng cất kiến thức loại này trên MATH với nhiều mẫu hơn từ SFT LLM 34B.

Xác minh trong lý luận toán học đóng vai trò quan trọng trong việc đảm bảo hiệu suất suy luận bằng cách cho phép các mô hình tự hồi quy sửa chữa các lỗi đã mắc phải. Đã được chứng minh rằng LLM có thể tự xác minh[2,36,37] và tự tinh chỉnh[24] bằng cách thiết kế nhắc nhở. Một trình xác minh được huấn luyện đặc biệt cũng có thể đóng vai trò tương tự bằng cách can thiệp vào quá trình giải mã[8,19,40]. Trong bài báo này, chúng tôi sử dụng tinh chỉnh đa tác vụ tương tự như việc huấn luyện một mô hình giám sát kết quả đơn giản.

6 Kết luận
Bài báo này giới thiệu một pipeline có thể tái tạo bao gồm cả việc xây dựng bộ dữ liệu chuyên về toán học và tinh chỉnh một mô hình ngôn ngữ lớn (LLM) với sự nhấn mạnh vào việc tận dụng trình thông dịch mã Python. Để hỗ trợ nghiên cứu và phát triển thêm trong lĩnh vực này, trước tiên chúng tôi đã công khai các checkpoint mô hình như một tài nguyên nguồn mở và cung cấp mô tả chi tiết về quy trình tinh chỉnh ba giai đoạn của chúng tôi. Kết quả của chúng tôi chứng minh rằng việc tích hợp phân tích văn bản với đoạn mã tăng cường khả năng của mô hình cho lý luận lẽ thường và tính toán chính xác trong các tác vụ lý luận toán học. Hơn nữa, phương pháp tinh chỉnh của chúng tôi tăng cường hiệu suất mô hình bằng cách kết hợp một mô hình xác minh chỉ đòi hỏi một số lượng tham số bổ sung không đáng kể. Theo hiểu biết tốt nhất của chúng tôi, cách tiếp cận của chúng tôi thiết lập một điểm chuẩn tiên tiến mới cho LLM với kích thước khoảng 7 tỷ tham số trên các bộ dữ liệu MATH, và nó thể hiện khả năng tổng quát hóa đáng chú ý trên các bộ dữ liệu toán học ngoài miền thách thức.

[Phần còn lại của tài liệu tiếp tục với Tài liệu tham khảo và Phụ lục, nhưng tôi sẽ dừng ở đây do giới hạn độ dài. Nếu bạn cần phần còn lại được dịch, vui lòng cho tôi biết.]

# 2306.01707.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2306.01707.pdf
# Kích thước file: 434257 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Học Tập Lý Luận Đa Bước Bằng Cách Giải Các Bài Toán Số Học
Tianduo Wang và Wei Lu
Nhóm Nghiên cứu StatNLP
Đại học Công nghệ và Thiết kế Singapore
{tianduo_wang,luwei}@sutd.edu.sg
Tóm tắt
Lý luận toán học được coi là một khả năng cần thiết cho các Mô hình Ngôn ngữ (LMs). Các nghiên cứu gần đây chứng minh hiệu suất ấn tượng của các LMs lớn trong việc giải quyết các bài toán toán học. Thành công này được cho là nhờ vào khả năng lý luận Chuỗi-Suy-nghĩ (CoT) của chúng, tức là khả năng phân tách các câu hỏi phức tạp thành các chuỗi lý luận từng bước, nhưng khả năng này dường như chỉ xuất hiện từ các mô hình có số lượng tham số dồi dào. Nghiên cứu này điều tra cách kết hợp các LMs tương đối nhỏ với khả năng lý luận đa bước. Chúng tôi đề xuất tiêm những khả năng như vậy bằng cách tiền huấn luyện liên tục các LMs trên một bộ dữ liệu tổng hợp MSAT được cấu thành từ các Bài toán Số học Đa bước. Các thí nghiệm của chúng tôi trên bốn bộ dữ liệu bài toán từ toán học cho thấy tính hiệu quả của phương pháp đề xuất trong việc nâng cao khả năng lý luận toán học của các LMs.

1 Giới thiệu
Làm cho các Mô hình Ngôn ngữ (LMs) thực hiện lý luận toán học là một mục tiêu nghiên cứu có giá trị, nhưng đầy thách thức (Hendrycks et al., 2021; Cobbe et al., 2021). Gần đây, chúng ta đã chứng kiến hiệu suất ấn tượng của các LMs quy mô lớn trong một loạt các nhiệm vụ lý luận thông qua việc nhắc nhở chuỗi-suy-nghĩ (Wei et al., 2022). Phương pháp này khai thác khả năng của LMs lớn để phân tách một vấn đề phức tạp thành nhiều bước trung gian. Tuy nhiên, người ta tin rằng khả năng như vậy chỉ xuất hiện từ các mô hình đủ lớn (theo kinh nghiệm là hơn 100B tham số) (Wei et al., 2022). Trong bài báo này, chúng tôi khám phá cách kết hợp các LMs cỡ vừa, ví dụ như RoBERTa (Liu et al., 2019), với khả năng lý luận đa bước như vậy thông qua tiền huấn luyện liên tục để cải thiện hiệu suất trên các bài toán toán học.

Hiểu chính xác các con số là điều kiện tiên quyết của khả năng lý luận toán học. Nhưng Wallace et al. (2019) chỉ ra rằng các LMs cỡ vừa có khuyết tật trong việc hiểu số học. Để khắc phục vấn đề này, các nghiên cứu trước đây tiêm các kỹ năng lý luận số học vào LMs theo hai cách tiếp cận. Cách thứ nhất là che giấu các con số bằng các token đặc biệt và tạo ra các biểu thức ký hiệu với một bộ giải mã thần kinh có cấu trúc (Xie và Sun, 2019; Jie et al., 2022). Một ví dụ về biểu thức như vậy được cung cấp trong Hình 1. Chiến lược thứ hai tiền huấn luyện liên tục các LMs trên các nhiệm vụ số học tổng hợp, yêu cầu các mô hình học cách thực hiện tính toán liên quan đến các con số (Geva et al., 2020; Pi et al., 2022).

Tuy nhiên, cả hai cách tiếp cận đều gặp phải những hạn chế quan trọng. Đối với các phương pháp ký hiệu, chúng bỏ qua thông tin được mang bởi các con số, có thể cung cấp những gợi ý quan trọng để giải quyết các bài toán toán học (Wu et al., 2021; Liang et al., 2022). Còn đối với các phương pháp tiền huấn luyện liên tục, các kỹ năng số học của LMs không đáng tin cậy. Các nghiên cứu trước đây chỉ ra rằng những kỹ năng như vậy bị ảnh hưởng mạnh bởi dữ liệu huấn luyện (Razeghi et al., 2022) và khó để ngoại suy (Wallace et al., 2019).

Được thúc đẩy bởi những thiếu sót này, chúng tôi đề xuất tiền huấn luyện các LMs cỡ vừa trên một bộ dữ liệu tổng hợp được gọi là MSAT (Các Bài toán Số học Đa bước)

--- TRANG 2 ---
Y=8.Z=2. X-Y=Z. X=?N0=2.N1=8. Ans=N0+N1Bộ Giải mã Tự hồi quyAdapterBộ Mã hóa LM Tiền huấn luyệnHình 2: Minh họa quá trình tiền huấn luyện liên tục trên mô hình Seq2Seq của chúng tôi. Chúng tôi gắn các mô-đun adapter vào mỗi lớp của bộ mã hóa LM và cố định các tham số của LM (vùng tô đậm) trong quá trình tiền huấn luyện. Các token N0, N1, và Ans trong đầu ra chỉ là tên biến được sử dụng bởi bộ giải mã. Mô hình cấu trúc DAG của chúng tôi được tiền huấn luyện tương tự với sự khác biệt duy nhất ở phần bộ giải mã.

trước khi tinh chỉnh nhiệm vụ cuối. Để đảm bảo LMs nắm bắt được thông tin được mang bởi các con số, chúng tôi giữ lại các con số trong câu hỏi thay vì che giấu chúng trong cả quá trình tiền huấn luyện và tinh chỉnh. Thay vì làm cho LMs thực hiện tính toán nội bộ, MSAT khuyến khích LMs tạo ra một loạt các bước trung gian dẫn đến câu trả lời. Các thí nghiệm trên bốn bộ dữ liệu bài toán từ toán học với hai mô hình nền tảng chứng minh tính hiệu quả của phương pháp của chúng tôi trong việc nâng cao hiệu suất lý luận toán học của LMs.

2 Phương pháp
Phương pháp của chúng tôi về cơ bản thêm một giai đoạn tiền huấn luyện liên tục trước khi tinh chỉnh LMs trên các nhiệm vụ cuối. Việc tiền huấn luyện liên tục phục vụ hai mục đích: thứ nhất, chúng tôi token hóa các con số từng chữ số để cải thiện khả năng hiểu số học của LMs; thứ hai, chúng tôi làm cho LMs học các kỹ năng lý luận đa bước từ nhiệm vụ tổng hợp được đề xuất.

2.1 Token hóa chữ số cho các con số
Các phương pháp token hóa từ phụ, ví dụ như mã hóa cặp byte (BPE) (Sennrich et al., 2016), là một trong những lý do tại sao các LMs cỡ vừa hiểu kém các con số (Wallace et al., 2019). Các tokenizer dựa trên BPE chia văn bản dựa trên tần suất token trong kho văn bản huấn luyện, có thể phản trực quan khi xử lý các con số. Ví dụ, các con số "520" và "521" sẽ được token hóa thành [" 520"] và ["5", "21"] tương ứng bởi RoBERTaTokenizer của thư viện Transformers (Wolf et al., 2020).

Chiến lược token hóa không nhất quán như vậy cho các con số làm suy yếu khả năng hiểu số học của LM. Do đó, chúng tôi token hóa các con số từng chữ số cho cả tiền huấn luyện và tinh chỉnh.

2.2 Các Bài toán Số học Đa bước (MSAT)
Cốt lõi của phương pháp của chúng tôi là nhiệm vụ tổng hợp MSAT nơi LMs có thể học các kỹ năng lý luận đa bước. Giống như các nhiệm vụ MWP, MSAT có thể được công thức hóa như một nhiệm vụ Seq2Seq: đầu vào của một ví dụ MSAT mô tả một câu hỏi số học, trong khi đầu ra là một chuỗi lý luận dẫn đến câu trả lời. Cụ thể, mỗi chuỗi đầu vào được cấu thành từ ba thành phần: bối cảnh câu hỏi, phương trình, và biến câu hỏi. Phương trình là một chuỗi các ký hiệu và toán tử (+, −, ×, ÷, =) tạo mối quan hệ đẳng thức giữa các ký hiệu. Cho một phương trình, chỉ một trong các ký hiệu được đặt làm biến câu hỏi, trong khi các ký hiệu khác sẽ được liệt kê trong bối cảnh câu hỏi với các giá trị số của chúng.

Chuỗi đầu ra của MSAT được xây dựng theo định dạng lý luận đa bước kiểu mã. Mỗi bước bao gồm hai bước phụ: gán biến và tính toán. Trong gán biến, các con số xuất hiện trong chuỗi đầu vào được gán cho tên biến độc quyền cho bộ giải mã. Trong tính toán, một biến mới được tạo ra từ tính toán của các biến hiện có. Điều này làm cho đầu ra của chúng tôi trở thành mã Python có thể thực thi để câu trả lời số có thể được tính toán bởi một trình thông dịch Python bên ngoài. Cả đầu vào và đầu ra của MSAT đều được tạo ra hoàn toàn tự động. Chi tiết về việc xây dựng MSAT được cung cấp trong Phụ lục A.1.

2.3 Tiền huấn luyện thông qua adapter-tuning
Huấn luyện trực tiếp trên dữ liệu tổng hợp khác biệt lớn so với kho văn bản ngôn ngữ tự nhiên sẽ làm hại khả năng ngôn ngữ của LMs (Geva et al., 2020). Do đó, chúng tôi áp dụng chiến lược tinh chỉnh hai giai đoạn (Wang và Lu, 2022) để tiêm các kỹ năng lý luận vào LMs. Cụ thể, chúng tôi thực hiện adapter-tuning (Houlsby et al., 2019) trên MSAT và sau đó cùng tinh chỉnh adapter và backbone LM trên các nhiệm vụ cuối. Nó giảm thiểu quên lãng thảm khốc vì các tham số gốc của LM được bảo tồn phần lớn trong quá trình adapter-tuning (Houlsby et al., 2019).

Chúng tôi xem xét hai mô hình backbone để xác minh tính hiệu quả của phương pháp của chúng tôi. Cụ thể, chúng tôi chọn một mô hình chuỗi-đến-chuỗi (Seq2Seq) (Lan et al., 2021) và một mô hình cấu trúc đồ thị có hướng không chu trình (DAG) (Jie et al., 2022) mà cả hai đều sử dụng RoBERTa base để mã hóa các câu hỏi đầu vào. Thêm chi tiết về các mô hình này được cung cấp trong §3.1. Hình 2 cho thấy tổng quan về phương pháp tiền huấn luyện được đề xuất.

--- TRANG 3 ---
Mô hình MAWPS ASDiv-A SVAMP SVAMP (khó)
Acc. Δ Acc. Δ Acc. Δ Acc. Δ

Các mô hình ngôn ngữ lớn (PaLM 540B) (code-davici-002) (PaLM 540B)
w/ nhắc nhở Chuỗi-Suy-nghĩ 93.3 80.4 79.0 -

Mô hình Seq2Seq
ROBERTAGEN (Lan et al., 2021)
w/ mặt nạ ký hiệu 88.4 72.1 30.3 30.3♡
w/ token hóa chữ số 84.1 (-4.3) 71.9 (-0.2) 27.6 (-2.7) 19.6 (-10.7)
MSAT-ROBERTAGEN (CỦA CHÚNG TÔI) 91.6 (+3.2) 81.8 (+9.7) 39.8 (+9.5) 36.2 (+5.9)

Mô hình cấu trúc DAG
DEDUCTREASONER (Jie et al., 2022)
w/ mặt nạ ký hiệu 92.0 85.0 45.0 45.0♡
w/ token hóa chữ số 91.6 (-0.4) 84.1 (-0.9) 44.4 (-0.6) 42.8 (-2.2)
MSAT-DEDUCTREASONER (CỦA CHÚNG TÔI) 94.3 (+2.3) 87.5 (+2.5) 48.9 (+3.9) 48.2 (+3.2)

Bảng 1: So sánh độ chính xác (%) giữa các mô hình ngôn ngữ lớn (LLMs), các baseline mô hình nền tảng, và phương pháp của chúng tôi. Δ: khoảng cách hiệu suất so với các baseline mặt nạ ký hiệu. ♡: Đối với các baseline với mặt nạ ký hiệu, hiệu suất trên SVAMP (khó) giống như SVAMP vì các con số thực tế được thay thế bằng token ký hiệu. Kết quả của LLMs với nhắc nhở chuỗi-suy-nghĩ từ Wei et al. (2022).

3 Thí nghiệm
Bây giờ chúng tôi điều tra liệu phương pháp tiền huấn luyện của chúng tôi có tạo thuận lợi cho các mô hình trong các nhiệm vụ giải Bài toán Từ Toán học (MWP) hay không. Tất cả kết quả được trung bình hóa trên ba lần chạy khác nhau.

3.1 Thiết lập thí nghiệm
Các bộ dữ liệu hiện có Chúng tôi xem xét ba bộ dữ liệu MWP thường được sử dụng: MAWPS (Koncel-Kedziorski et al., 2016), ASDiv-A (Miao et al., 2020), và SVAMP (Patel et al., 2021). Thống kê của các bộ dữ liệu này được cung cấp trong Bảng 2. Thêm chi tiết có thể tìm thấy trong Phụ lục A.2. Chúng tôi báo cáo kết quả xác nhận chéo năm lần cho cả MAWPS và ASDiv-A và độ chính xác tập kiểm tra cho SVAMP theo thực hành trước đây (Lan et al., 2021; Jie et al., 2022).

SVAMP (khó) Chúng tôi thấy hơn 85% số trong các bộ dữ liệu trên nhỏ hơn 102. Để điều tra hiệu suất ngoại suy của các mô hình được huấn luyện với MSAT, chúng tôi tạo SVAMP (khó) từ bộ dữ liệu SVAMP gốc bằng cách thay thế các con số bằng những con số lớn hơn nhiều được lấy cảm hứng từ Gao et al. (2022). Thêm chi tiết về SVAMP (khó) và phân bố số của các bộ dữ liệu hiện có được cung cấp trong Phụ lục A.3.

Bộ dữ liệu # Dữ liệu Độ dài đầu vào trung bình Số bước lý luận trung bình
MAWPS 1,987 30.3 1.4
ASDiv-A 1,217 32.3 1.2
SVAMP 1,000 34.7 1.2

Bảng 2: Thống kê bộ dữ liệu hiện có.

Các mô hình Chúng tôi xem xét cả mô hình chuỗi-đến-chuỗi (Seq2Seq) và mô hình cấu trúc đồ thị có hướng không chu trình (DAG) làm mô hình nền tảng của chúng tôi. Đối với mô hình Seq2Seq, chúng tôi chọn ROBERTAGEN (Lan et al., 2021), một mô hình encoder-decoder với RoBERTa base làm encoder kết hợp với decoder Transformer. Đối với mô hình cấu trúc DAG, chúng tôi chọn DEDUCTREASONER (Jie et al., 2022) kết hợp RoBERTa base với decoder DAG. Trong triển khai gốc của chúng, cả hai mô hình đều thay thế các con số bằng token mặt nạ ký hiệu. Do đó, chúng tôi bổ sung xem xét một baseline cho mỗi mô hình backbone sử dụng các con số thực tế với token hóa chữ số. Chúng tôi đặt tên các mô hình dựa trên hai mô hình backbone này và được tiền huấn luyện với phương pháp của chúng tôi là MSAT-ROBERTAGEN và MSAT-DEDUCTREASONER tương ứng. Chúng tôi cũng so sánh các mô hình của chúng tôi với các LMs lớn, ví dụ như PaLM (Chowdhery et al., 2022) và Codex (Chen et al., 2021), với nhắc nhở chuỗi-suy-nghĩ (Wei et al., 2022). Tất cả các mô hình được đánh giá qua giải mã tham lam. Thêm chi tiết triển khai, ví dụ như các siêu tham số huấn luyện, được cung cấp trong Phụ lục B.

3.2 Kết quả chính
Bảng 1 so sánh các mô hình của chúng tôi với các baseline mô hình nền tảng và LMs lớn. Trên tất cả các bộ dữ liệu, các baseline token hóa chữ số liên tục hoạt động tệ hơn so với các đối tác mặt nạ ký hiệu của chúng, cho thấy sự thiếu hụt trong khả năng hiểu số học của mô hình RoBERTa gốc. Tuy nhiên, các mô hình được huấn luyện với MSAT vượt trội hơn cả hai baseline với biên độ lớn, điều này chứng minh tính hiệu quả của phương pháp tiền huấn luyện của chúng tôi.

--- TRANG 4 ---
2 4 6 8 10 12
Số bước tiền huấn luyện (nghìn)020406080100Độ chính xác MsAT
Độ chính xác MsAT
Độ chính xác SVAMP
36404448
Độ chính xác SVAMP
Hình 3: Hiệu suất trên MSAT và SVAMP theo số bước tiền huấn luyện. Kết quả được thu thập từ 3 lần chạy khác nhau.

SVAMP (khó) Chúng ta có thể quan sát thấy rằng, trên SVAMP (khó), độ chính xác của các baseline token hóa chữ số giảm mạnh (giảm 10.7 điểm cho ROBERTAGEN và giảm 2.2 điểm cho DEDUCTREASONER) so với các baseline với mặt nạ ký hiệu, trong khi các mô hình được huấn luyện với MSAT vẫn vượt trội hơn các baseline mặt nạ ký hiệu lần lượt 5.9 và 3.2 điểm. Điều này cho thấy rằng không chỉ các mô hình của chúng tôi có được kết quả tốt hơn so với các baseline trên các nhiệm vụ hiện có, mà nó cũng mạnh mẽ hơn trong việc xử lý các con số ngoài phân phối.

So sánh với các mô hình ngôn ngữ lớn Chúng tôi cũng quan sát thấy rằng, trên các nhiệm vụ tương đối đơn giản, tức là MAWPS và ASDiv-A, các mô hình dựa trên RoBERTa có thể vượt trội hơn các LMs lớn. Nhưng đối với nhiệm vụ thách thức hơn SVAMP, vẫn còn một khoảng cách hiệu suất lớn. Chúng tôi tin rằng điều này là do SVAMP yêu cầu các mô hình phải hiểu ngôn ngữ tự nhiên tốt hơn. Jie et al. (2022) cũng báo cáo rằng việc thay đổi bộ mã hóa LM dẫn đến sự chênh lệch hiệu suất đáng kể trên SVAMP, cho thấy hiệu suất SVAMP gắn liền chặt chẽ với khả năng ngôn ngữ tự nhiên của mô hình.

4 Phân tích tiền huấn luyện
Trong phần này, chúng tôi cung cấp một phân tích cẩn thận về phương pháp tiền huấn luyện của chúng tôi từ nhiều góc độ khác nhau để hiểu tại sao nó hoạt động.

4.1 Hiệu suất nhiệm vụ tiền huấn luyện
Chúng tôi trực quan hóa cách hiệu suất của nhiệm vụ tiền huấn luyện MSAT và một trong các nhiệm vụ MWP SVAMP thay đổi theo số bước tiền huấn luyện trong Hình 3. Có thể quan sát thấy rằng hiệu suất trên cả nhiệm vụ tổng hợp và ngôn ngữ tự nhiên có xu hướng cải thiện dần dần khi số bước tiền huấn luyện tăng lên.

Hình 3 chứng minh rằng LMs có khả năng học lý luận đa bước dần dần từ nhiệm vụ tổng hợp MSAT. Khả năng lý luận đa bước được thu thập có thể được chuyển giao tiếp theo đến các nhiệm vụ giải MWP cuối, nâng cao hiệu suất trong giai đoạn tinh chỉnh.

4.2 Định dạng lý luận của MSAT
Định dạng lý luận của MSAT quyết định các kỹ năng lý luận cụ thể mà LMs sẽ thu thập trong quá trình tiền huấn luyện. Chúng tôi chứng minh sự ưu việt của định dạng lý luận đa bước kiểu mã của chúng tôi bằng cách so sánh nó với hai biểu thức lý luận khác nhau.

Tác động của việc tạo ra các bước trung gian Trong khi việc huấn luyện LMs hướng tới việc trực tiếp tạo ra các câu trả lời số của các câu hỏi số học là một thực hành phổ biến (Geva et al., 2020; Pi et al., 2022), một nghiên cứu gần đây cho thấy rằng các kỹ năng số học của LMs không đáng tin cậy (Razeghi et al., 2022). Để khám phá liệu LMs có thể học các kỹ năng lý luận từ MSAT mà không có các bước trung gian hay không, chúng tôi tiền huấn luyện LMs trên một biến thể của MSAT bằng cách thay thế các chuỗi đầu ra từng bước bằng chỉ các câu trả lời số. Hình 4 so sánh mô hình này (chỉ câu trả lời) với mô hình của chúng tôi (kiểu mã). Hiệu suất kém của nó trên cả MSAT và SVAMP xác nhận sự cần thiết của việc tạo ra các bước lý luận trung gian trong quá trình tiền huấn luyện.

Biểu thức kiểu mã có cấu trúc Tiếp theo chúng tôi điều tra tầm quan trọng của việc áp dụng các biểu thức lý luận kiểu mã có cấu trúc bằng cách so sánh nó với các biểu thức toán học ít được định dạng hơn. Chúng tôi lập luận rằng, so với các biểu thức toán học chỉ chứa các con số và toán tử, các biểu thức kiểu mã của chúng tôi phù hợp hơn cho lý luận đa bước do thông tin cấu trúc trong các chuỗi đầu ra.

Các thí nghiệm của chúng tôi trong Hình 4 chứng minh sự ưu việt của các biểu thức đầu ra kiểu mã. Chúng ta có thể thấy rằng các mô hình với biểu thức toán học hoạt động liên tục tệ hơn so với các mô hình với định dạng lý luận đa bước kiểu mã trên cả nhiệm vụ tiền huấn luyện MSAT và nhiệm vụ giải MWP SVAMP.

020406080100Độ chính xác (%)
9.163.396.5MsAT
10152025303540
10.128.639.8SVAMP
Chỉ câu trả lời Biểu thức toán học Biểu thức kiểu mã
Hình 4: So sánh giữa các định dạng biểu thức đầu ra khác nhau. Kết quả được thu thập từ mô hình Seq2Seq của chúng tôi (với biểu thức kiểu mã) và các biến thể của nó.

--- TRANG 5 ---
1.5 2.0 2.5
Độ khó tiền huấn luyện90.090.490.891.291.6Độ chính xác MAWPS
Độ chính xác MAWPS
Độ khó MAWPS
1.5 2.0 2.5
Độ khó tiền huấn luyện80.080.480.881.281.682.0Độ chính xác ASDiv-A
Độ chính xác ASDiv-A
Độ khó ASDiv-A
Hình 5: Hiệu suất trên MAWPS và ASDiv-A theo độ khó tiền huấn luyện. Mức độ khó của hai nhiệm vụ MWP cũng được thêm vào để tham khảo.

4.3 Mức độ khó của MSAT
Tận dụng dữ liệu tổng hợp cho tiền huấn luyện cung cấp lợi thế cho phép tùy chỉnh cao mức độ khó cho dữ liệu huấn luyện. Ở đây chúng tôi định nghĩa mức độ khó của một nhiệm vụ lý luận là số bước lý luận trung bình cần thiết để giải quyết các vấn đề. Từ Hình 5, chúng ta thấy rằng tiền huấn luyện LMs trên các MSAT khó hơn các nhiệm vụ cuối thường dẫn đến kết quả tốt hơn. Quan trọng cần lưu ý rằng, nói chung, mức độ khó của một nhiệm vụ lý luận, đặc biệt là những nhiệm vụ liên quan đến ngôn ngữ tự nhiên, không chỉ được xác định bởi số bước lý luận. Một ví dụ là, mặc dù cả ASDiv-A và SVAMP đều có số bước lý luận trung bình là 1.2 (xem Bảng 2), SVAMP được coi là khó hơn vì nó yêu cầu hiểu ngôn ngữ tự nhiên ở mức độ cao (Patel et al., 2021).

4.4 Thực hiện adapter-tuning trên MSAT
Tinh chỉnh tất cả các tham số của bộ mã hóa LM trên dữ liệu tổng hợp khác biệt lớn so với kho tiền huấn luyện có thể dẫn đến quên lãng thảm khốc (Geva et al., 2020). Để khám phá tầm quan trọng của việc thực hiện adapter-tuning trên MSAT, chúng tôi tạo một biến thể của phương pháp của chúng tôi trong đó chúng tôi thực hiện tinh chỉnh đầy đủ trên MSAT. Chúng tôi so sánh biến thể này với các mô hình của chúng tôi trong Hình 6. Có thể quan sát thấy rằng cả tinh chỉnh đầy đủ và adapter-tuning đều có thể đạt được hiệu suất tốt trên MSAT, nhưng adapter-tuning vượt trội hơn tinh chỉnh trên tất cả các bộ dữ liệu MWP cuối, điều này chứng minh lợi ích của việc thực hiện adapter-tuning trên MSAT.

5 Công trình liên quan
Trong công trình này, chúng tôi tập trung vào việc cải thiện hiệu suất MWP của LM cỡ vừa bằng cách tiêm khả năng lý luận đa bước. Do đó, công trình của chúng tôi liên quan chặt chẽ đến cả việc tiêm khả năng lý luận (Geva et al., 2020; Pi et al., 2022) và giải MWP (Xie và Sun, 2019; Patel et al., 2021; Jie et al., 2022).

92949698Độ chính xác (%)9696.5MsAT
86889092
86.791.6MAWPS
7476788082
75.581.8ASDiv-A
3234363840
34.539.8SVAMP
Tinh chỉnh đầy đủ Adapter-tuning
Hình 6: So sánh hiệu suất MSAT và nhiệm vụ cuối giữa tinh chỉnh đầy đủ và adapter-tuning trong quá trình tiền huấn luyện.

Tiêm kỹ năng lý luận Kỹ thuật này đề cập đến việc tiền huấn luyện liên tục LMs trên các nhiệm vụ được tạo ra có chủ đích để nâng cao khả năng lý luận của chúng. GenBERT (Geva et al., 2020) tiền huấn luyện LMs trên dữ liệu tổng hợp dựa trên mẫu để tiêm các kỹ năng số học vào LMs. PoET (Pi et al., 2022) cải thiện khả năng lý luận của LMs bằng cách tiền huấn luyện chúng trên dữ liệu bảng hướng tới bắt chước các bộ thực thi chương trình. Cả hai phương pháp đều liên quan đến việc huấn luyện LMs để tạo ra các câu trả lời số trực tiếp, có thể không đáng tin cậy (Razeghi et al., 2022). Công trình của chúng tôi tập trung vào việc tiêm vào LMs khả năng giải quyết các vấn đề số học phức tạp từng bước.

Giải MWP với các kiến trúc chuyên biệt Một trong các hướng nghiên cứu của việc giải MWP tập trung vào việc thiết kế các kiến trúc chuyên biệt cho lý luận toán học (Xie và Sun, 2019; Lan et al., 2021; Jie et al., 2022). Ví dụ, Lan et al. (2021) kết hợp RoBERTa (Liu et al., 2019) với decoder Transformer (Vaswani et al., 2017), và Jie et al. (2022) tăng cường LMs chỉ encoder bằng decoder đồ thị có hướng không chu trình. Một trong những thiếu sót của những mô hình như vậy là mất thông tin do che giấu các con số thực tế trong câu hỏi bằng token ký hiệu (Wu et al., 2021). Trong công trình này, chúng tôi đề xuất biểu diễn các con số thực tế bằng token hóa chữ số và cải thiện khả năng lý luận đa bước của các mô hình bằng cách tiền huấn luyện chúng trên nhiệm vụ tổng hợp MSAT.

6 Kết luận
Chúng tôi đề xuất một nhiệm vụ tiền huấn luyện tổng hợp mới, MSAT, để kết hợp LMs với các kỹ năng lý luận đa bước cải thiện hiệu suất trên các nhiệm vụ MWP. Nhiệm vụ tiền huấn luyện này khuyến khích LMs tạo ra các bước lý luận trung gian thay vì dự đoán trực tiếp các câu trả lời số cuối cùng. Các thí nghiệm của chúng tôi cho thấy rằng phương pháp được đề xuất có hiệu quả trong việc cải thiện hiệu suất của LM cỡ vừa trên các nhiệm vụ giải MWP.

--- TRANG 6 ---
Hạn chế
Số lượng toán tử được xem xét hạn chế Theo các phương pháp trước đây (Lan et al., 2021), chúng tôi chỉ xem xét các toán tử nhị phân (+, −, ×, và ÷). Vì chúng tôi áp dụng định dạng đầu ra kiểu mã, có thể giới thiệu các toán tử phi nhị phân khác được hỗ trợ bởi trình thông dịch Python, ví dụ như sum() và max(). Tuy nhiên, việc thu thập dữ liệu có nhãn với các toán tử như vậy có thể đòi hỏi nỗ lực cần cù. Chúng tôi tin rằng đây là một câu hỏi nghiên cứu thú vị về việc khám phá cách dạy các mô hình giải quyết các câu hỏi thực tế, ví dụ như bài toán từ toán học, bằng cách viết mã trong bối cảnh ít tài nguyên (Jie và Lu, 2023).

Hiệu suất hạn chế do giải mã tham lam Tất cả các kết quả chúng tôi báo cáo trong công trình này được tạo ra thông qua giải mã tham lam. Một nghiên cứu gần đây (Wang et al., 2023) báo cáo rằng làm cho các LMs lớn tạo ra nhiều câu trả lời và chọn câu trả lời có nhiều phiếu bầu nhất có thể thúc đẩy hiệu suất với biên độ lớn. Tuy nhiên, thực hiện tìm kiếm chùm tia cho các bộ lý luận thần kinh ký hiệu, ví dụ như DeductReasoner, có thể thách thức ở chỗ không gian tìm kiếm tăng theo cấp số nhân với số biến trong câu hỏi (Jie et al., 2022). Thiết kế các chiến lược tìm kiếm chùm tia hiệu quả cho các bộ lý luận thần kinh ký hiệu là một hướng đầy hứa hẹn.

Lời cảm ơn
Chúng tôi muốn cảm ơn các nhà đánh giá ẩn danh, meta-reviewer, và các chủ tịch khu vực cấp cao của chúng tôi vì những bình luận sâu sắc và hỗ trợ cho công trình này. Chúng tôi cũng muốn cảm ơn các thành viên của nhóm nghiên cứu StatNLP của chúng tôi vì những thảo luận hữu ích. Nghiên cứu/dự án này được hỗ trợ bởi Quỹ Nghiên cứu Quốc gia Singapore và Phòng thí nghiệm Quốc gia DSO trong khuôn khổ Chương trình AI Singapore (Giải thưởng AISG số: AISG2-RP-2020-016), và Bộ Giáo dục, Singapore, trong khuôn khổ Chương trình Quỹ Nghiên cứu Học thuật (AcRF) Tier 2 (Giải thưởng MOE AcRF Tier 2 số: MOE-T2EP20122-0011)

Tài liệu tham khảo
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Đánh giá các mô hình ngôn ngữ lớn được huấn luyện trên mã. arXiv preprint arXiv:2107.03374.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Mở rộng mô hình ngôn ngữ với các đường dẫn. arXiv preprint arXiv:2204.02311.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Huấn luyện các bộ xác minh để giải các bài toán từ toán học. arXiv preprint arXiv:2110.14168.

Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, và Graham Neubig. 2022. Pal: Các mô hình ngôn ngữ hỗ trợ chương trình. arXiv preprint arXiv:2211.10435.

Mor Geva, Ankit Gupta, và Jonathan Berant. 2020. Tiêm các kỹ năng lý luận số học vào các mô hình ngôn ngữ. Trong Proceedings of ACL.

Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, và Jacob Steinhardt. 2021. Đo lường việc giải quyết vấn đề toán học với bộ dữ liệu toán. Trong Proceedings of NeurIPS.

Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, và Sylvain Gelly. 2019. Học chuyển giao hiệu quả tham số cho NLP. Trong Proceedings of ICML.

Zhanming Jie, Jierui Li, và Wei Lu. 2022. Học lý luận suy diễn: Giải quyết bài toán từ toán học như trích xuất quan hệ phức tạp. Trong Proceedings of ACL.

Zhanming Jie và Wei Lu. 2023. Tận dụng dữ liệu huấn luyện trong việc nhắc nhở few-shot cho lý luận số học. Trong Findings of ACL.

Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, và Hannaneh Hajishirzi. 2016. Mawps: Kho lưu trữ bài toán từ toán học. Trong Proceedings of NAACL.

Yihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang, và Ee-Peng Lim. 2021. Mwptoolkit: Một framework mã nguồn mở cho các bộ giải bài toán từ toán học dựa trên học sâu. arXiv preprint arXiv:2109.00799.

Zhenwen Liang, Jipeng Zhang, Lei Wang, Wei Qin, Yunshi Lan, Jie Shao, và Xiangliang Zhang. 2022. MWP-BERT: Tiền huấn luyện tăng cường số học cho việc giải quyết bài toán từ toán học. Trong Findings of NAACL.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: Một cách tiếp cận tiền huấn luyện bert được tối ưu hóa mạnh mẽ. arXiv preprint arXiv:1907.11692.

Ilya Loshchilov và Frank Hutter. 2019. Chính quy hóa phân rã trọng số tách rời. Trong Proceedings of ICLR.

--- TRANG 7 ---
Shen-yun Miao, Chao-Chun Liang, và Keh-Yih Su. 2020. Một kho văn bản đa dạng để đánh giá và phát triển các bộ giải bài toán từ toán học tiếng Anh. Trong Proceedings of ACL.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. Pytorch: Một thư viện học sâu hiệu suất cao, phong cách mệnh lệnh. Trong Proceedings of NeurIPS.

Arkil Patel, Satwik Bhattamishra, và Navin Goyal. 2021. Các mô hình NLP có thực sự có thể giải quyết các bài toán từ toán học đơn giản không? Trong Proceedings of NAACL.

Xinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, và Weizhu Chen. 2022. Lý luận như các bộ thực thi chương trình. Trong Proceedings of EMNLP.

Yasaman Razeghi, Robert L Logan IV, Matt Gardner, và Sameer Singh. 2022. Tác động của tần suất thuật ngữ tiền huấn luyện đối với lý luận few-shot. Trong Proceedings of ICML.

Rico Sennrich, Barry Haddow, và Alexandra Birch. 2016. Dịch máy thần kinh của các từ hiếm với các đơn vị từ phụ. Trong Proceedings of ACL.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, và Illia Polosukhin. 2017. Chú ý là tất cả những gì bạn cần. Trong Proceedings of NeurIPS.

Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, và Matt Gardner. 2019. Các mô hình NLP có biết số không? thăm dò khả năng số học trong các embedding. Trong Proceedings of EMNLP-IJCNLP.

Tianduo Wang và Wei Lu. 2022. Tăng cường dữ liệu khả vi cho học biểu diễn câu đối chiếu. Trong Proceedings of EMNLP.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, và Denny Zhou. 2023. Sự nhất quán bản thân cải thiện lý luận chuỗi suy nghĩ trong các mô hình ngôn ngữ. Trong Proceedings of ICLR.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. 2022. Nhắc nhở chuỗi suy nghĩ gợi ra lý luận trong các mô hình ngôn ngữ lớn. Trong Proceedings of NeurIPS.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, et al. 2020. Transformers: Xử lý ngôn ngữ tự nhiên hiện đại. Trong Proceedings of EMNLP.

Qinzhuo Wu, Qi Zhang, Zhongyu Wei, và Xuanjing Huang. 2021. Giải quyết bài toán từ toán học với các giá trị số rõ ràng. Trong Proceedings of ACL-IJCNLP.

Zhipeng Xie và Shichao Sun. 2019. Một mô hình thần kinh có cấu trúc cây hướng mục tiêu cho các bài toán từ toán học. Trong Proceedings of IJCAI.

A Thông tin bổ sung về các bộ dữ liệu
Trong phần này, chúng tôi cung cấp chi tiết bổ sung về các bộ dữ liệu mà chúng tôi đã sử dụng trong các thí nghiệm.

A.1 Xây dựng MSAT
MSAT được đề xuất là một nhiệm vụ Seq2Seq tổng hợp trong đó các đầu vào mô tả các câu hỏi số học và đầu ra là các giải pháp được biểu diễn bởi định dạng lý luận đa bước kiểu mã. Cả đầu vào và đầu ra của MSAT đều có thể được tạo ra tự động.

Để xây dựng một ví dụ của MSAT, chúng tôi đầu tiên tạo ra chuỗi đầu vào và sau đó tạo ra giải pháp đầu ra tương ứng. Tổng cộng, chúng tôi tạo ra 85,000 ví dụ và chia chúng thành 80,000 và 5,000 để huấn luyện và đánh giá tương ứng.

Xây dựng chuỗi đầu vào Chúng tôi bắt đầu bằng cách chuẩn bị một tập hợp các mẫu phương trình và mỗi mẫu phương trình chứa không quá 3 toán tử nhị phân (+, −, ×, và ÷). Bằng cách liệt kê các kết hợp có thể có của các toán tử, chúng tôi thu được 4+4²+4³ = 84 mẫu phương trình tổng cộng. Bước đầu tiên để xây dựng một câu hỏi số học đầu vào là khởi tạo một phương trình từ một mẫu phương trình. Ví dụ, với mẫu phương trình "<Num0> + <Num1> = <Num2>", chúng tôi gán mỗi biến một giá trị làm cho đẳng thức đúng và một tên biến được chọn từ các chữ cái viết hoa. Các con số trong câu hỏi được lấy mẫu từ 0 đến 10,000. Bước cuối cùng là chọn ngẫu nhiên một biến làm biến câu hỏi. Do đó, câu hỏi số học đầu vào có thể trông như: "A=1. C=3. A+B=C. B?"

Xây dựng chuỗi đầu ra Cho một phương trình và một biến câu hỏi, đầu ra đầu tiên được xây dựng như một biểu thức toán học dẫn đến giá trị của biến câu hỏi. Lưu ý rằng một phương trình có thể được biểu diễn như một cây nhị phân trong đó các biến là các nút lá và các toán tử là các nút không lá. Do đó, đầu ra có thể được tạo ra bởi thuật toán "đảo ngược cây" (xem Hình 7) từ một phương trình và một biến câu hỏi.

=+Num0Num1Num2=Num1-Num2Num0
Hình 7: Minh họa thuật toán "đảo ngược cây" tạo ra biểu thức đầu ra từ câu hỏi số học. Biến câu hỏi được làm nổi bật.

--- TRANG 8 ---
020406080
65
27
8MAWPS
020406053
35
12ASDiv-A
020406053
32
15SVAMP
0204060
162658SVAMP (khó)Tỷ lệ (%)
<20 20~100 >100
Hình 8: Phân bố số cho các bộ dữ liệu khác nhau.

A.2 Các bộ dữ liệu hiện có
MAWPS (Koncel-Kedziorski et al., 2016) Đây là một bộ dữ liệu điểm chuẩn phổ biến cho các bài toán từ toán học. Chúng tôi sử dụng phân chia năm lần được cung cấp bởi Lan et al. (2021) để đánh giá.

ASDiv-A (Miao et al., 2020) Đây là một nhiệm vụ bài toán từ toán học tiếng Anh chứa các mẫu ngôn ngữ và danh mục vấn đề khác nhau. Chúng tôi thu thập dữ liệu và phân chia năm lần từ Patel et al. (2021).

SVAMP (Patel et al., 2021) Đây là một tập thách thức được tạo ra để đánh giá tính mạnh mẽ của mô hình MWP. Các ví dụ trong SVAMP từ ASDiv-A với các biến thể được thiết kế có chủ đích. Những biến thể như vậy bao gồm: thay đổi câu hỏi, thêm thông tin không liên quan, v.v. Theo giao thức đánh giá được đề xuất bởi Patel et al. (2021), chúng tôi huấn luyện các mô hình của chúng tôi trên 3,138 ví dụ huấn luyện từ sự kết hợp của MAWPS và ASDiv-A.

A.3 SVAMP (khó)
SVAMP (khó) được sử dụng để đánh giá khả năng ngoại suy của các mô hình trên các con số ngoài phân phối. Chúng tôi lấy mẫu các con số từ 10 đến 10,000, một phạm vi khác biệt đáng kể so với phạm vi gốc, để thay thế các con số gốc trong SVAMP. Mỗi câu hỏi trong SVAMP (khó) tương ứng với một câu hỏi trong SVAMP. Mặc dù việc lấy mẫu một con số lớn và sử dụng nó để thay thế các con số là đơn giản, chúng tôi mong đợi các câu hỏi được tạo ra có ý nghĩa. Chúng tôi đạt được điều này bằng cách đảm bảo các kết quả số mới có cùng loại với những kết quả gốc. Ví dụ, nếu câu trả lời số gốc là một số nguyên dương, thì chúng tôi đảm bảo câu trả lời số mới cũng là một số nguyên dương. Chúng tôi so sánh phân bố số của các bộ dữ liệu MWP hiện có và SVAMP (khó) trong Hình 8.

B Chi tiết triển khai
Phương pháp của chúng tôi được triển khai bằng Python 3.8 với các thư viện Transformers của HuggingFace (Wolf et al., 2020) và PyTorch (Paszke et al., 2019). Tất cả các thí nghiệm có thể được thực hiện trên một GPU NVIDIA RTX 6000 với bộ nhớ 22 GB.

B.1 Triển khai mô hình backbone
Đối với MSAT-ROBERTAGEN và MSAT-DEDUCTREASONER của chúng tôi, chúng tôi xây dựng các mô hình backbone theo triển khai được cung cấp bởi Lan et al. (2021) và Jie et al. (2022) tương ứng. Các encoder cho cả hai mô hình được khởi tạo với các trọng số tiền huấn luyện của RoBERTa base. Các mô-đun adapter (Houlsby et al., 2019) được thêm vào mỗi lớp của các encoder với chiều cổ chai là 64. Thêm chi tiết về các kiến trúc mô hình được cung cấp trong Bảng 3.

ROBERTAGEN DEDUCTREASONER
# Tham số 139.71 M 142.40 M
# Đầu chú ý 8 -
Chiều ẩn 768 768
Chiều feedforward 1024 768
# Lớp 2 -
Kích hoạt ReLU ReLU
Dropout 0.1 0.1
Làm mượt nhãn 0.05 -
# Hằng số 17 17

Bảng 3: Siêu tham số của các kiến trúc mô hình.

B.2 Cấu hình huấn luyện
TIỀN HUẤN LUYỆN TINH CHỈNH
Kích thước batch 32 16
Số bước tối đa 10,000 50,000
Bộ tối ưu hóa AdamW (Loshchilov và Hutter, 2019)
Phân rã trọng số 0.01 0.01
Chuẩn gradient tối đa 0.1 1.0
Tốc độ học 3e-5 1e-5
Bộ lập lịch LR Tuyến tính Tuyến tính

Bảng 4: Siêu tham số tiền huấn luyện và tinh chỉnh.

# 2310.03731.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2310.03731.pdf
# Kích thước tệp: 827971 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
MATHCODER : TÍCH HỢP MÃ LIỀN MẠCH TRONG
LLM ĐỂ TĂNG CƯỜNG KHẢ NĂNG LẬP LUẬN TOÁN HỌC
Ke Wang1∗Houxing Ren1∗Aojun Zhou1∗Zimu Lu1∗Sichun Luo3∗
Weikang Shi1∗Renrui Zhang1Linqi Song3Mingjie Zhan1†Hongsheng Li1,2‡
1Phòng thí nghiệm Đa phương tiện (MMLab), Đại học Trung văn Hồng Kông
2Phòng thí nghiệm Trí tuệ nhân tạo Thượng Hải3Đại học Thành phố Hồng Kông
{wangk.gm, renhouxing, aojunzhou, zmjdll}@gmail.com
hsli@ee.cuhk.edu.hk

TÓM TẮT
GPT-4 Code Interpreter được phát hành gần đây đã chứng minh khả năng xuất sắc
trong việc giải quyết các bài toán khó, chủ yếu được quy cho khả năng lập luận
liền mạch bằng ngôn ngữ tự nhiên, tạo mã, thực thi mã và tiếp tục lập luận dựa
trên kết quả thực thi. Trong bài báo này, chúng tôi trình bày một phương pháp để
tinh chỉnh các mô hình ngôn ngữ mã nguồn mở, cho phép chúng sử dụng mã để
mô hình hóa và suy dẫn các phương trình toán học và do đó tăng cường khả năng
lập luận toán học của chúng. Chúng tôi đề xuất một phương pháp tạo bộ dữ liệu
mới và chất lượng cao với các bài toán và lời giải dựa trên mã, được gọi là
MathCodeInstruct. Mỗi lời giải xen kẽ ngôn ngữ tự nhiên, mã và kết quả thực
thi. Chúng tôi cũng giới thiệu một phương pháp tinh chỉnh có giám sát và suy
luận tùy chỉnh. Phương pháp này tạo ra các mô hình MathCoder, một họ mô hình
có khả năng tạo ra các lời giải dựa trên mã để giải quyết các bài toán khó. Đáng
ấn tượng là các mô hình MathCoder đạt điểm số tiên tiến nhất trong số các LLM
mã nguồn mở trên bộ dữ liệu MATH (45,2%) và GSM8K (83,9%), vượt trội đáng
kể so với các lựa chọn thay thế mã nguồn mở khác. Đáng chú ý, mô hình
MathCoder không chỉ vượt ChatGPT-3.5 và PaLM-2 trên GSM8K và MATH mà
còn vượt GPT-4 trên bộ dữ liệu MATH cấp độ thi đấu. Bộ dữ liệu và các mô
hình sẽ được phát hành tại https://github.com/mathllm/MathCoder .

1 GIỚI THIỆU
Gần đây, các mô hình ngôn ngữ lớn mã nguồn đóng (LLM) như GPT-4 (OpenAI, 2023) và PaLM-
2 (Anil et al., 2023), kết hợp với các phương pháp như Chain-of-Thought (CoT) (Wei et al., 2022) và
Program-Aided Language models (PAL) (Gao et al., 2023), đã cho thấy hiệu suất đáng kể trong
các tác vụ lập luận toán học. Ngược lại, các LLM mã nguồn mở hiện tại (Touvron et al., 2023;
Penedo et al., 2023; Zhang et al., 2022) vẫn tụt hậu đáng kể trong lĩnh vực này. Ngay cả Llama-2-
70B (Touvron et al., 2023), một trong những mô hình mã nguồn mở mạnh nhất, chỉ đạt 56,8% và
13,5% tương ứng trên bộ dữ liệu GSM8K (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021),
thấp hơn đáng kể so với GPT-4 Code Interpreter1, đạt 97% và 69,7% (Zhou et al., 2023a).
Để thu hẹp khoảng cách giữa các mô hình mã nguồn mở và mã nguồn đóng trong việc giải toán,
các nghiên cứu gần đây như WizardMath (Luo et al., 2023) và RFT (Yuan et al., 2023) đã cố gắng
tinh chỉnh các mô hình mã nguồn mở với các bài toán và lời giải CoT, đạt được cải thiện đáng kể
về hiệu suất so với mô hình cơ sở Llama-2. Mặt khác, các phương pháp như PAL (Gao
et al., 2023), PoT (Chen et al., 2022), và CSV (Zhou et al., 2023a) khuyến khích sử dụng mã trong việc giải
∗Đóng góp ngang nhau.
†Người dẫn dắt dự án.
‡Tác giả liên hệ.
1https://openai.com/blog/chatgpt-plugins#code-interpreter
1arXiv:2310.03731v1  [cs.CL]  5 Oct 2023

--- TRANG 2 ---
Bảng 1: So sánh với các bộ dữ liệu tuân thủ hướng dẫn khác nhau.
Các bộ dữ liệu cơ sở bao gồm RFT-u13b (Yuan et al., 2023) và
WizardMath (Luo et al., 2023) gần đây.
Bộ dữ liệu Hạt giống Chú thích
RFT-100k GSM8K Llama
WizardMath-96k GSM8K+MATH GPT-4
Của chúng tôi-49k GSM8K+MATH GPT-4
Của chúng tôi-80k GSM8K+MATHGPT-4 +
Tự chưng cất
7B 70B1020304050607080Độ chính xác
17.824.846.250.773.1MathCoder
WizardMath (SoTA)
Llama-1 RFTHình 1: So sánh hiệu suất
giữa MathCoder, WizardMath, và
các mô hình Llama-1 RFT với các
kích thước mô hình khác nhau.

bài toán toán học, cho thấy những cải thiện đầy hứa hẹn khi kết hợp với các mô hình mã nguồn đóng như GPT-
3.5, GPT-4 và GPT-4 Code Interpreter. Đặc biệt, GPT-4 Code Interpreter vượt trội hơn SOTA
trước đó một cách rõ ràng. Nghiên cứu gần đây (Zhou et al., 2023a) cho thấy hiệu suất xuất sắc
này có thể được quy cho khả năng tạo ra và đánh giá kết quả thực thi của một chuỗi mã xen kẽ
với các bước lập luận bằng ngôn ngữ tự nhiên.

Tuy nhiên, các mô hình mã nguồn mở hiện tại không thể hưởng lợi từ cơ chế phức tạp này vì
chúng tụt hậu so với các mô hình mã nguồn đóng trong cả việc tạo mã và lập luận bằng ngôn
ngữ tự nhiên. Do đó, chúng ta vẫn thiếu một công thức hiệu quả để cung cấp các mô hình mã
nguồn mở để giải toán theo cách tương tự như GPT-4 Code Interpreter.

Trong bài báo này, tận dụng thế mạnh của GPT-4 Code Interpreter (Zhou et al., 2023a), chúng
tôi giới thiệu một khung công việc đơn giản nhưng hiệu quả, MathCoder, được thiết kế để
tăng cường khả năng lập luận toán học của các mô hình mã nguồn mở. Khung này có thể được
phân loại thành hai phần: (1) xây dựng bộ dữ liệu tuân thủ hướng dẫn toán học và (2) tinh chỉnh
có giám sát tùy chỉnh.

Cụ thể, bộ dữ liệu tuân thủ hướng dẫn, được gọi là MathCodeInstruct, bao gồm độc quyền
80k bài toán toán học và các lời giải tương ứng. Mỗi lời giải được xen kẽ với ngôn ngữ tự
nhiên để lập luận, mã để thực thi và kết quả thực thi. Sự so sánh giữa MathCodeInstruct và
các bộ dữ liệu tinh chỉnh hướng dẫn toán học khác được thể hiện trong Bảng 1.

MathCodeInstruct được tạo ra trong hai bước. Bước đầu tiên là thu thập các lời giải theo phong
cách GPT-4 Code Interpreter cho bộ huấn luyện GSM8K và MATH. GSM8K và MATH là hai bộ
dữ liệu quan trọng của các bài toán toán học để cải thiện và đánh giá khả năng toán học của
các mô hình, bao gồm các bài toán từ cấp tiểu học và các bài toán thi đấu thách thức tương ứng.
Sử dụng dữ liệu này, chúng tôi đã huấn luyện các mô hình ban đầu, được gọi là MathCoder-Initial.
Bước thứ hai là bổ sung thêm các bài toán toán học bằng cách sử dụng một lời nhắc sáng tạo
có tên gọi nội suy bài toán, yêu cầu LLM tạo ra các câu hỏi có mức độ khó nằm giữa các
bài toán MATH và GSM8K được cung cấp. Mô hình này tạo ra các bài toán kết nối khoảng cách
giữa các bài toán cấp tiểu học trong GSM8K và các bài toán cấp trung học khó trong MATH,
từ đó tăng cường khả năng tổng quát hóa của bộ dữ liệu. Chúng tôi sử dụng MathCoder-Initial
để tạo ra các lời giải cho các bài toán mới này. Kết hợp dữ liệu mới này với dữ liệu từ bước
đầu tiên, chúng tôi tinh chỉnh các mô hình Llama-2 cơ sở, đạt được điểm số vượt trội hơn
SOTA một cách rõ ràng trên GSM8K và MATH. Đồng thời với công trình của chúng tôi,
MAmmoTH (Yue et al., 2023) cũng tạo ra một bộ dữ liệu bao gồm các bài toán toán học và
lời giải do mô hình tạo ra. Tuy nhiên, lời giải của họ bao gồm chỉ mã hoặc chỉ các bước lập
luận bằng ngôn ngữ tự nhiên, khác biệt đáng kể so với bộ dữ liệu lời giải theo phong cách
GPT-4 Code Interpreter của chúng tôi.

Về giai đoạn tinh chỉnh có giám sát, chúng tôi đề xuất một quy trình huấn luyện và suy luận
hiệu quả để đảm bảo rằng mô hình được tinh chỉnh của chúng tôi có thể hoạt động theo cách
tương tự như GPT-4 Code Interpreter. Chúng tôi sử dụng các token đặc biệt (<|text|>, <|code|>,
<|execution|>) để xác định một phần của dữ liệu huấn luyện là ngôn ngữ tự nhiên, mã, hay
kết quả thực thi. Với kho dữ liệu huấn luyện được tạo ra cẩn thận này, mô hình học cách tạo
ra ngôn ngữ tự nhiên và mã xen kẽ được phân cách bằng các token đặc biệt. Trong quá trình
suy luận, chúng tôi có thể sử dụng các token đặc biệt để phát hiện các khối mã và sử dụng
Jupyter Notebooks để thực thi mã. Chúng tôi nối kết quả thực thi tức thời vào các dự đoán
trước đó của mô hình. Sau đó, mô hình tiếp tục dự đoán token tiếp theo một cách tự hồi quy
dựa trên phiên bản mới của đầu vào, bao gồm kết quả thực thi ở cuối. Bằng cách này, mô hình
có thể "nhìn thấy" kết quả thực thi và tiếp tục lập luận tương ứng.

2

--- TRANG 3 ---
Huấn luyện GSM8K 
& MATH 
(bài toán)
GPT-4 
(Suy luận) GSM8K 
& MATH 
(bài toán+lời giải, 49k)
MathCoder-Initial 
34B
MathCoder-Initial
34B
(Suy luận) MathCode 
Instruct 
(bài toán+lời giải, 80k)
CodeLlama 
34B
(SFT) 
Nội suy 
Bài toán 
(bài toán)
Nội suy 
Bài toán 
(bài toán+lời giải, 31k)
MathCoder-CL
7B, 13B, 34B MathCoder-L 
7B, 13B, 70B 
MathCode 
Instruct 
(bài toán+lời giải, 80k)
CodeLlama 
7B, 13B, 34B 
(SFT) 
Llama-2 
7B, 13B, 70B 
(SFT) 
(b) Tinh chỉnh Có giám sát (SFT) (a) Tạo Bộ dữ liệu 
bài toán: bài toán 
lời giải: lời giải Hình 2: Quá trình tạo bộ dữ liệu và tinh chỉnh mô hình. (a) Đầu tiên, các lời giải cho các bài toán trong
bộ dữ liệu GSM8K và MATH được thu thập từ GPT-4. Sau đó, chúng tôi tinh chỉnh mô hình CodeLlama-34B
trên dữ liệu này, tạo ra MathCoder-Initial. Các bài toán mới được tạo ra bằng cách sử dụng lời nhắc mới của chúng tôi (ví dụ chi tiết trong Phụ lục A), và lời giải của chúng được tạo ra bằng MathCoder-Initial. (b) Cuối cùng, các bài toán và lời giải mới được kết hợp với dữ liệu huấn luyện hiện có để tạo ra bộ dữ liệu cuối cùng, mà chúng tôi sử dụng để tinh chỉnh mô hình Llama-2 cơ sở, tạo ra mô hình MathCoder cuối cùng của chúng tôi.

Chúng tôi sử dụng MathCodeInstruct để tinh chỉnh các mô hình Llama-2 và CodeLlama (Rozière
et al., 2023) mã nguồn mở phổ biến, tạo ra một họ mô hình tên là MathCoder. Kết quả thực
nghiệm cho thấy các mô hình với bộ dữ liệu được đề xuất và khung huấn luyện của chúng tôi
đạt được cải thiện đáng kể trên các tiêu chuẩn lập luận toán học khác nhau, như được mô tả
trong Hình 1.

Những đóng góp chính của bài báo này có thể được tóm tắt trong ba khía cạnh chính:
• Theo hiểu biết của chúng tôi, đây là nghiên cứu hệ thống đầu tiên tích hợp một cách
rõ ràng lập luận bằng ngôn ngữ tự nhiên, tạo mã và phản hồi từ kết quả thực thi vào
các mô hình ngôn ngữ lớn được pre-train mã nguồn mở, nhằm tăng cường khả năng
lập luận toán học của chúng.
• Chúng tôi đã xây dựng một bộ dữ liệu tinh chỉnh hướng dẫn toán học chất lượng cao,
MathCodeInstruct. Bộ dữ liệu này bao gồm các bài toán toán học hiện có từ GSM8K
và MATH, với các lời giải theo phong cách GPT-4 Code Interpreter, và những bài
toán mới được xây dựng thông qua chiến lược lời nhắc nội suy bài toán mới của chúng tôi.
• Chúng tôi đã tạo ra một họ mô hình, MathCoder. Chúng tôi tinh chỉnh các mô hình
Llama-2 và CodeLlama trên bộ dữ liệu của chúng tôi, tạo ra một họ mô hình không
chỉ có độ chính xác cao trên GSM8K và MATH, mà còn có hiệu suất tốt trên các bộ
dữ liệu ngoài miền khác như Mathematics và SimulEq.

2 MATHCODER: CHUYÊN MÔN HÓA LLAMA CHO LẬP LUẬN TOÁN HỌC

Trong phần này, chúng tôi đầu tiên giới thiệu phương pháp tạo MathCodeInstruct trong Mục 2.1.
Tiếp theo, chúng tôi trình bày chi tiết các phương pháp tinh chỉnh có giám sát (SFT) và suy luận
trong Mục 2.2.

2.1 BỘ DỮ LIỆU MATHCODEINSTRUCT

Bộ dữ liệu MathCodeInstruct của chúng tôi có thể được biểu diễn như D={D0, D1}, trong đó D0
biểu thị dữ liệu hạt giống và D1 là dữ liệu được tạo ra bằng phương pháp nhắc nhở được đề xuất,
có tên gọi là lời nhắc nội suy bài toán. Hình 2 (a) phác thảo quá trình tạo Bộ dữ liệu MathCodeInstruct.

Dữ liệu hạt giống D0. Đầu tiên, chúng tôi thu thập lời giải cho bộ huấn luyện GSM8K và MATH
từ GPT-4. Dữ liệu có thể được biểu diễn dưới dạng các cặp (lời giải, câu hỏi) như {(yi, xi)}N
i=1. Mỗi lời giải yi chứa

3

--- TRANG 4 ---
Đầu vào cho MathCoder
<|system|><|text|>Dưới đây là một bài toán toán học. Hãy giải từng bước.<|endofblock|><|endofmessage|>
<|user|><|text|>Một nhóm bạn đi du lịch qua hai thành phố. Ở thành phố đầu tiên, họ đã tiêu hết một nửa số tiền họ có cộng thêm 50 đô la.
Ở thành phố thứ hai, họ tiêu hết một nửa số tiền còn lại cộng thêm 20 đô la, để lại cho họ 40 đô la. Họ bắt đầu với bao nhiêu tiền trước
chuyến đi?<|endofblock|><|endofmessage|>

(a) Ví dụ CoT
Hãy gọi số tiền họ bắt đầu với x.
1. Ở thành phố đầu tiên, họ đã tiêu một nửa (x/2) cộng 50 đô la. Số tiền còn lại là
x - (x/2 + 50).
2. Rút gọn điều này cho x - x/2 - 50 = x/2 - 50.
3. Ở thành phố thứ hai, họ tiêu một nửa số tiền còn lại ((x/2 - 50)/2) cộng
20 đô la. Số tiền còn lại là x/2 - 50 - (x/2 - 50)/2 + 20.
4. Rút gọn điều này cho x/2 - 50 - x/4 + 25 - 20 = x/4 - 45.
5. Họ còn lại 40 đô la, vậy x/4 - 45 = 40.
6. Giải x cho x/4 = 85 và x = 340.

(b) Ví dụ PoT
# Định nghĩa một biến để biểu diễn số tiền ban đầu
starting_amount = 0
# Vòng lặp để tìm số tiền ban đầu
while True:
    amount = starting_amount
    # Tiêu ở thành phố đầu tiên: một nửa số tiền họ có cộng 50 đô la
    amount -= (amount / 2 + 50)
    # Tiêu ở thành phố thứ hai: một nửa số tiền còn lại cộng 20 đô la
    amount -= (amount / 2 + 20)
    # Kiểm tra xem họ có còn lại 40 đô la không
    if amount == 40:
        break
    starting_amount += 1
starting_amount >>> 340

(c) Lời giải LCE từ MathCoder
<|assistant|> <|text|> Để giải bài toán này, hãy đặt x là
số tiền nhóm bạn bắt đầu với.
1. Ở thành phố đầu tiên, họ tiêu một nửa số tiền họ có (x/2) cộng thêm 50 đô la.
2. Sau đó, họ còn lại x - (x/2 + 50).
3. Ở thành phố thứ hai, họ tiêu một nửa số tiền còn lại cộng thêm 20 đô la.
4. Cuối cùng, họ còn lại 40 đô la.

Phương trình có thể được thiết lập như sau:
x - (x/2 + 50) - ((x - (x/2 + 50))/2 + 20) = 40

Hãy tiến hành giải phương trình này bằng mã.<|endofblock|>
<|code|> from sympy import symbols, Eq, solve
# Định nghĩa biến và phương trình
x = symbols('x')
# Phương trình dựa trên mô tả bài toán
equation = Eq(x - (x/2 + 50) - ((x - (x/2 + 50)) / 2 + 20), 40)
# Giải phương trình
initial_amount = solve(equation, x)
initial_amount[0]<|endofblock|>
<|execution|> 340<|endofblock|>
<|text|> Vậy, nhóm bạn đã bắt đầu với 340 đô la trước chuyến đi.<|endofblock|><|endofmessage|>

Hình 3: Ví dụ về CoT (Wei et al., 2022), PoT (Gao et al., 2023; Chen et al., 2022) và lời giải LCE với token đặc biệt. Trái ngược với CoT, chỉ bao gồm ngôn ngữ tự nhiên, và PoT, chỉ bao gồm mã, lời giải LCE của chúng tôi xen kẽ ngôn ngữ tự nhiên, mã và kết quả thực thi. <|text|>, <|code|>, và <|execution|> là các token đặc biệt biểu thị ngôn ngữ tự nhiên, mã và kết quả thực thi tương ứng.

ba loại thành phần: ngôn ngữ tự nhiên (văn bản) để lập luận L, mã để thực thi C, và kết quả thực thi E, trong đó L là bước lập luận bằng ngôn ngữ tự nhiên, C là mã Python mà mô hình tạo ra khi lập luận của nó dẫn đến một số tính toán phức tạp mà nó cần mã để giải quyết, và E là đầu ra của mã. E được mô hình đánh giá để có thể tạo ra một L mới. Cả ba loại thành phần được liên kết chặt chẽ với nhau trong các lời giải, với mỗi thành phần ảnh hưởng đến thành phần đến sau nó. Một lời giải tích hợp yi có thể được biểu diễn như (L,C,E,L,C,E, ...). Một ví dụ được thể hiện trong Hình 3 (c). Chúng tôi gọi các lời giải ở định dạng này là lời giải Ngôn ngữ tự nhiên, Mã và Thực thi (LCE). Chúng tôi đưa một số nghiên cứu trường hợp vào Phụ lục E để chứng minh lợi thế của LCE.

Chúng tôi lọc dữ liệu hạt giống D0 = ({(yi, xi)}), đảm bảo rằng mỗi lời giải yi cung cấp cùng một câu trả lời như câu trả lời đúng để chất lượng của bộ dữ liệu được đảm bảo thêm. Sau đó, chúng tôi tinh chỉnh CodeLlama-34B bằng dữ liệu hạt giống D0, tạo ra mô hình MathCoder ban đầu, có tên MathCoder-Initial.

Lời nhắc nội suy bài toán D1. Sử dụng mô hình MathCoder ban đầu, chúng tôi có thể tạo ra lời giải LCE cho các bài toán mới. Chúng tôi đã quan sát thấy một khoảng cách lớn về độ khó giữa các bài toán GSM8K cấp tiểu học và các bài toán MATH thi đấu khó khăn. Để kết nối khoảng cách này, chúng tôi trình bày một phương pháp nhắc nhở mới (xem chi tiết trong Phụ lục A), cung cấp cho một LLM mạnh mẽ như GPT-4 một bài toán tương đối đơn giản được rút ra từ bộ huấn luyện GSM8K, kết hợp với một bài toán khó được rút ra từ MATH, và yêu cầu mô hình tạo ra một bài toán mới có độ khó giữa hai bài toán. Sau đó chúng tôi sử dụng GPT-4 để đánh giá các bài toán mới, và kết quả được thể hiện trong Hình 4. Chúng tôi

4

--- TRANG 5 ---
15.3 83.295.6 3.3
GSM8K vs.
NộisuyMATH vs.
NộisuyMATH/GSM8K khó hơn Hòa Nội suy khó hơnHình 4: So sánh độ khó của các bài toán nội suy so với MATH và GSM8K bằng GPT-4. Lời nhắc đánh giá và ví dụ được thể hiện trong Phụ lục B.

có thể thấy rằng 83,2% các bài toán mới khó hơn GSM8K, và 95,6% dễ hơn MATH, cho thấy rằng các bài toán được tạo ra theo cách này có độ khó phù hợp.

Chúng tôi cũng đã nghiên cứu việc chỉ sử dụng GSM8K để tạo ra các bài toán khó, nhưng chúng tôi phát hiện rằng các bài toán mới quá giống với các bài toán ban đầu, và khoảng cách lớn với MATH vẫn tồn tại (thêm thông tin có thể được tìm thấy trong Phụ lục C).

Tự chưng cất. Do chúng tôi không có câu trả lời đúng cho các bài toán mới, chúng tôi sau đó tạo ra n lời giải LCE khác nhau như được mô tả trong (Wang et al., 2023a) cho mỗi bài toán mới với các mô hình MathCoder ban đầu của chúng tôi, chỉ giữ lại những lời giải mà tất cả n câu trả lời đều khớp (n được đặt là 3 trong bài báo này), do đó đảm bảo chất lượng bộ dữ liệu của chúng tôi. Chúng tôi sử dụng MathCoder-Initial ở đây vì nó thể hiện tiềm năng cho việc chưng cất mô hình hiệu quả bằng cách sử dụng một mô hình yếu hơn nhiều so với các mô hình mã nguồn đóng mạnh mẽ. Vì MathCoder-Initial đã có độ chính xác 77,3% trên GSM8K và 44,0% trên MATH, việc chưng cất nó có thể tạo ra kết quả tốt. Nó cũng giảm chi phí so với việc sử dụng GPT-4. Một số ví dụ có thể được tìm thấy trong Phụ lục A.

Kết hợp dữ liệu mới D1 với dữ liệu hạt giống D0 tạo ra bộ dữ liệu MathCodeInstruct D = {D0, D1}. Chúng tôi tinh chỉnh các mô hình Llama-2 (Touvron et al., 2023) và CodeLlama (Rozière et al., 2023) cơ sở bằng MathCodeInstruct để tạo ra các mô hình MathCoder cuối cùng. Để rõ ràng, chúng tôi gọi việc tinh chỉnh có giám sát của Llama-2 cơ sở là "MathCoder-L" và của CodeLlama là "MathCoder-CL", như được thể hiện trong Hình 2 (b).

2.2 TINH CHỈNH CÓ GIÁM SÁT VÀ SUY LUẬN

Tinh chỉnh có giám sát. Để xác định ba loại thành phần trong các lời giải LCE, như được minh họa trong Hình 3 (c), chúng tôi đặt chúng trong các token đặc biệt. Ngôn ngữ lập luận bắt đầu với <|text|>, trong khi mã toán học và kết quả thực thi bắt đầu với <|code|> và <|execution|> tương ứng. Tất cả các thành phần kết thúc bằng <|endofblock|>. Những token này giúp mô hình hiểu sự khác biệt giữa từng thành phần và tạo ra lời giải LCE trong quá trình suy luận. Sau khi các token đặc biệt được thêm vào, tất cả các thành phần được nối với nhau để tạo thành lời giải, được đặt trước bởi câu hỏi toán học ban đầu để tạo thành một thể hiện của dữ liệu huấn luyện. Để làm cho việc huấn luyện hiệu quả hơn, một số thể hiện được nối với nhau để tạo thành một đầu vào duy nhất, trong khi việc che giấu cross-question được sử dụng để đảm bảo chỉ các token trong cùng một thể hiện mới có thể nhìn thấy.

Trong quá trình tinh chỉnh có giám sát, chúng tôi áp dụng một hàm mất mát cross-entropy tiêu chuẩn theo Alpaca (Taori et al., 2023). Hàm mất mát chỉ được tính toán trên ngôn ngữ lập luận và mã toán học vì chúng là các thành phần của dữ liệu huấn luyện được tạo ra bởi LLM. Đặc biệt, chúng tôi loại bỏ hàm mất mát trên các token từ kết quả thực thi, vì mô hình sẽ không cần dự đoán những token này.

Suy luận. Sau khi tinh chỉnh có giám sát, mô hình đã học cách xuất ra ngôn ngữ tự nhiên và mã được bao quanh bởi các token đặc biệt. Chúng tôi có thể xác định kết thúc của mỗi thành phần bằng cách tìm <|endofblock|>, và xác định thành phần nào bằng cách kiểm tra token đầu tiên của thành phần. Khi một việc tạo mã được gặp phải, chúng tôi sử dụng Jupyter Notebook để thực thi mã thời gian thực, cho phép các biến được định nghĩa trong các khối mã trước đó được sử dụng trong các khối tiếp theo. Sau khi thực thi, kết quả thực thi được nối tiếp theo khối mã toán học trước đó. Mô hình sau đó tiếp tục tạo ra khối ngôn ngữ lập luận tiếp theo một cách tự hồi quy, tạo thành chuỗi suy nghĩ trong định dạng LCE, cho đến khi nó đạt đến câu trả lời cuối cùng. Quá trình này đảm bảo rằng mô hình hoạt động tương tự như GPT-4 Code Interpreter.

5

--- TRANG 6 ---
3 THÍ NGHIỆM
3.1 BỘ DỮ LIỆU VÀ CHI TIẾT TRIỂN KHAI

Bộ dữ liệu. Chúng tôi đánh giá MathCoder trên năm bộ dữ liệu, bao gồm hai bộ dữ liệu trong miền:
GSM8K (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021); và ba bộ dữ liệu ngoài miền:
SVAMP (Patel et al., 2021), Mathematics (Saxton et al., 2019), và SimulEq (Kushman et al., 2014).
Chúng tôi coi GSM8K và MATH là trong miền vì bộ huấn luyện của chúng được sử dụng cho việc tinh chỉnh có giám sát của chúng tôi, trong khi SVAMP, Mathematics, và SimulEq là ngoài miền vì bộ huấn luyện của chúng không được sử dụng trong việc tinh chỉnh của chúng tôi. Sự đa dạng rộng rãi của các bộ dữ liệu đánh giá bao gồm các thách thức toán học từ cấp tiểu học, trung học và đại học, bao gồm các môn khác nhau như hình học, logic hình thức, và thậm chí lập luận thường thức. Việc lựa chọn những bộ dữ liệu này nhằm cung cấp một đánh giá toàn diện về khả năng tổng quát hóa của các mô hình đến những hoàn cảnh không biết và các lĩnh vực toán học đa dạng.

Chi tiết triển khai. Các LLM cơ sở khác nhau với các kích thước khác nhau được thử nghiệm, bao gồm Llama-2 (7B, 13B, và 70B) và CodeLlama (7B, 13B, và 34B). Trong quá trình huấn luyện, chúng tôi sử dụng tỷ lệ học thống nhất 2×10−5 và độ dài ngữ cảnh 2048, và chúng tôi đặt kích thước batch là 128 với các tỷ lệ khác nhau của bước tích lũy gradient và kích thước batch huấn luyện trên mỗi thiết bị, xem xét kích thước mô hình. Ngoài ra, chúng tôi sử dụng một bộ lập lịch cosine trong tổng cộng ba epoch với khoảng thời gian khởi động 50 bước. Để huấn luyện hiệu quả các mô hình tính toán chuyên sâu, chúng tôi đồng thời sử dụng huấn luyện DeepSpeed với giai đoạn ZeRO-3 (Rajbhandari et al., 2020) và flash attention (Dao et al., 2022). Các mô hình 7B, 13B, và 34B/70B được huấn luyện trên 8, 16, và 32 GPU NVIDIA A800 80GB, tương ứng. Khung text-generation-inference của Hugging Face được sử dụng để suy luận với greedy decoding và token mới tối đa của mỗi khối được đặt là 512, và từ một đến bốn GPU được sử dụng khi cần thiết. Chúng tôi cho phép tối đa 32 khối LCE trong mỗi lời giải.

Mô hình cơ sở. Chúng tôi so sánh các MathCoder được đề xuất với các mô hình cơ sở cạnh tranh sau đây.
Mô hình mã nguồn đóng: chúng tôi xem xét ba mô hình mã nguồn đóng, bao gồm ChatGPT-3.5 Brown et al. (2020), GPT-4 (OpenAI, 2023), GPT-4 Code Interpreter (Zhou et al., 2023a), và PaLM-2 (Anil et al., 2023). Mô hình mã nguồn mở: chúng tôi so sánh với Llama-2 (Touvron et al., 2023), WizardMath (Luo et al., 2023), Llama-1 RFT (Yuan et al., 2023), và Galactica (Taylor et al., 2022).
Đối với các mô hình cơ sở, lời nhắc CoT (Wei et al., 2022) và học ngữ cảnh vài shot (Dong et al., 2023) được sử dụng để tối đa hóa hiệu suất của chúng trong khi các MathCoder của chúng tôi luôn được đánh giá mà không có lời nhắc thêm và dưới cài đặt zero-shot (Kojima et al., 2023).

3.2 KẾT QUẢ CHÍNH

So sánh giữa MathCoder và các mô hình mã nguồn mở SOTA. Kết quả thí nghiệm trong Bảng 2 cho thấy phương pháp của chúng tôi vượt trội hơn các mô hình giải toán cạnh tranh mã nguồn mở khác với một lợi thế rõ ràng, đạt được kết quả tiên tiến nhất trên tất cả các bộ dữ liệu. Tuy nhiên, vẫn tồn tại một khoảng cách hiệu suất đáng kể so với phương pháp mã nguồn đóng tiên tiến nhất GPT-4 Code Interpreter. Những quan sát của chúng tôi như sau: (1) MathCoder-L-7B vượt trội hơn WizardMath-70B. Ngay cả phiên bản nhỏ nhất của MathCoder, MathCoder-L-7B, cũng vượt trội hơn mô hình WizardMath lớn nhất, WizardMath-70B, trên ba trong số năm bộ dữ liệu, đạt được một cải thiện đáng kể (+4,5%) trong điểm trung bình, như được thể hiện trong Bảng 2. Điều này có thể được quy cho thực tế là WizardMath chỉ được huấn luyện trên dữ liệu CoT, trong khi MathCoder được huấn luyện trên các lời giải LCE được đề xuất của chúng tôi. Điều này chứng minh lợi thế của việc sử dụng các lời giải xen kẽ ngôn ngữ tự nhiên, mã và thực thi (các khối LCE), tăng cường đáng kể khả năng thực hiện các tính toán phức tạp của mô hình. (2) Ngoài ra, đáng chú ý là trong khi khả năng mã của CodeLlama-34B vượt trội đáng kể so với Llama-2-70B, trong trường hợp các mô hình MathCoder, chúng tôi quan sát thấy rằng các mô hình dựa trên Llama-2-70B (73,1%) có thể vượt trội hơn CodeLlama-34B (70,2%). Điều này trái ngược với những phát hiện trong công trình đồng thời, MAmmoTH (Yue et al., 2023). Lý do chính cho sự khác biệt này có thể là Llama-2-70B thể hiện khả năng lập luận bằng ngôn ngữ tự nhiên tốt hơn, và bộ dữ liệu MathCodeInstruct có thể tăng cường khả năng tạo mã của các mô hình ngôn ngữ để giải quyết bài toán toán học.

So sánh giữa Llama-2 và CodeLlama. Bảng 3 cho thấy MathCoder-CL với CodeLlama làm mô hình cơ sở mang lại cải thiện đáng kể so với MathCoder-L với Llama-2 làm mô hình cơ sở. MathCode-CL-7B và MathCoder-CL-13B thể hiện cải thiện độ chính xác 4,1% và 3,0% tương ứng, so với các mô hình MathCoder-L tương ứng

6

--- TRANG 7 ---
Bảng 2: Đánh giá mô hình trên các bộ dữ liệu trong miền (GSM8K & MATH) và ngoài miền (SVAMP, Mathematics & SimulEq). + biểu thị cải thiện so với mô hình mã nguồn mở tốt nhất. SVA. viết tắt cho SVAMP, Mat. viết tắt cho Mathematics, và Sim. viết tắt cho SimulEq.

Mô hình Cơ sở Kích thước Trong miền Ngoài miền Trung bình GSM8K MATH SVA. Mat. Sim.
Mô hình mã nguồn đóng
ChatGPT-3.5 (Zhao et al., 2023) - - 80.8 34.1 - - - -
GPT-4 (OpenAI, 2023) - - 92.0 42.5 97.0 - - -
GPT-4 Code (Zhou et al., 2023a) - - 97.0 69.7 - - - -
PaLM-2 (Anil et al., 2023) - - 80.7 34.3 - - - -
Mô hình mã nguồn mở
Galactica (Taylor et al., 2022) -6.7B 10.2 2.2 25.6 4.6 4.2 9.4
30B 41.7 12.7 41.6 11.8 13.2 24.2
Llama-1 RFT (Yuan et al., 2023) Llama-17B 46.5 5.2 21.1 5.1 11.0 17.8
13B 52.1 5.1 46.5 6.7 10.1 24.1
34B 56.5 7.4 55.4 7.6 12.8 27.9
WizardMath (Luo et al., 2023) Llama-27B 54.9 10.7 36.1 9.3 12.8 24.8
13B 63.9 14.0 51.9 14.1 14.9 31.8
70B 81.6 22.7 71.8 17.1 37.9 46.2
MathCoder-L Llama-27B64.2 23.3 71.5 46.9 47.5 50.7
+9.3 +12.6 +35.4 +37.6 +34.7 +25.9
13B72.6 29.9 76.9 54.7 62.3 59.2
+8.7 +15.9 +25.0 +40.6 +47.4 +27.4
70B83.9 45.1 84.9 74.4 77.0 73.1
+2.3 +22.4 +13.1 +57.3 +39.1 +26.9
MathCoder-CL CodeLlama7B67.8 30.2 70.7 55.8 49.6 54.8
+12.9 +19.5 +34.6 +46.5 +36.8 +30.0
13B74.1 35.9 78.0 62.5 60.7 62.2
+10.2 +21.9 +26.1 +48.4 +45.8 +30.4
34B81.7 45.2 82.5 75.9 65.8 70.2
+0.1 +22.5 +10.7 +58.8 +27.9 +24.0

Bảng 3: So sánh hiệu suất mô hình cho MathCoder với CodeLlama và Llama-2 làm cơ sở.
Kích thước GSM8K MATH SVAMP Mathematics SimulEq Trung bình
MathCoder-CL-7B vs. MathCoder-L-7B +3.6 +6.9 -0.8 +8.9 +2.1 +4.1
MathCoder-CL-13B vs. MathCoder-L-13B +1.5 +6.0 +1.1 +7.8 -1.6 +3.0

có cùng kích thước. Khả năng mã hóa và lập luận có thể vượt trội của CodeLlama có thể được quy cho việc huấn luyện bổ sung trên dữ liệu mã (Rozière et al., 2023). Việc huấn luyện mở rộng này cung cấp cho CodeLlama hiểu biết sâu hơn về các khái niệm và mô hình lập trình, cho phép nó xuất sắc trong các tác vụ liên quan đến mã và thể hiện khả năng lập luận toán học tiên tiến hơn.

So sánh giữa các môn khác nhau trên nhiều cấp độ. Các bài toán trong bộ dữ liệu MATH được phân loại với các mức độ khó từ 1 đến 5, bao gồm bảy môn toán khác nhau, bao gồm đại số, tiền đại số, lý thuyết số, đếm và xác suất, tiền giải tích, đại số trung cấp, và hình học. Trong Hình 5, chúng tôi trình bày so sánh hiệu suất của MathCoder-L (7B, 13B) và MathCoder-CL (7B, 13B), được nhóm theo các cấp độ và môn này. Kết quả khác được thể hiện trong Phụ lục D. Chúng tôi thấy rằng MathCoder đạt điểm số cao hơn trong các bài toán đại số và tiền đại số. Tuy nhiên, khi nói đến các bài toán hình học, MathCoder gặp khó khăn để đạt điểm số cao, đặc biệt là đối với các bài toán có mức độ khó cao hơn. Điều này gợi ý rằng mã đóng vai trò quan trọng hơn trong các câu hỏi tính toán chuyên sâu.

3.3 NGHIÊN CỨU LOẠI BỎ

Phân tích ảnh hưởng của nội suy bài toán. Chúng tôi thực hiện một thí nghiệm để nghiên cứu ảnh hưởng của phần câu hỏi MathCodeInstruct được tạo ra bằng cách sử dụng nội suy bài toán được đề xuất

7

--- TRANG 8 ---
L1 L2 L3 L4 L5algebra
prealgebra
number
theory
counting and
probability
precalculus
intermediate
algebra
geometry 0.72 0.51 0.4 0.27 0.13
0.52 0.53 0.41 0.3 0.14
0.57 0.28 0.26 0.15 0.05
0.51 0.46 0.17 0.08 0.07
0.32 0.15 0.09 0.04 0
0.29 0.21 0.17 0.08 0.04
0.29 0.3 0.16 0.13 0.01MathCoder-L-7B
(Tổng thể: 0.233)
L1 L2 L3 L4 L5 0.76 0.61 0.49 0.37 0.21
0.69 0.64 0.49 0.38 0.22
0.67 0.43 0.32 0.29 0.17
0.59 0.5 0.19 0.15 0.05
0.4 0.21 0.12 0.1 0.03
0.35 0.3 0.18 0.13 0.09
0.29 0.35 0.27 0.1 0.01MathCoder-CL-7B
(Tổng thể: 0.3024)
L1 L2 L3 L4 L5 0.77 0.63 0.5 0.4 0.21
0.59 0.56 0.5 0.42 0.19
0.77 0.41 0.34 0.2 0.16
0.67 0.48 0.24 0.14 0.06
0.42 0.21 0.13 0.09 0
0.4 0.25 0.18 0.14 0.06
0.37 0.39 0.2 0.17 0.02MathCoder-L-13B
(Tổng thể: 0.2992)
L1 L2 L3 L4 L5 0.83 0.67 0.57 0.45 0.29
0.73 0.69 0.52 0.45 0.24
0.77 0.49 0.42 0.32 0.21
0.74 0.58 0.22 0.16 0.18
0.44 0.34 0.23 0.15 0.04
0.44 0.38 0.24 0.17 0.1
0.24 0.48 0.25 0.18 0.05MathCoder-CL-13B
(Tổng thể: 0.3588)
0.00.10.20.30.40.50.60.70.8Hình 5: So sánh hiệu suất của MathCoder-L (7B, 13B) và MathCoder-CL (7B, 13B) trên bộ dữ liệu MATH theo cấp độ và môn học. Chúng ta có thể thấy rằng việc cải thiện độ chính xác từ MathCoder-L sang MathCoder-CL chủ yếu đến từ các môn học yêu cầu tính toán chính xác như đại số và lý thuyết số.

Bảng 4: Ảnh hưởng của các bài toán nội suy trong MathCodeInstruct (như được thể hiện trong Bảng 1) dựa trên CodeLlama-34B.
Bộ huấn luyện Mẫu GSM8K MATH SVAMP Mathematics SimulEq Trung bình
GSM8K+MATH 49k 77.3 44.0 78.6 71.6 59.3 66.2
GSM8K+MATH+Nội suy 80k81.7 45.2 82.5 75.9 65.8 70.2
+4.4 +1.2 +3.9 +4.3 +6.4 +4.0

phương pháp nội suy. Thí nghiệm sử dụng CodeLlama-34B làm mô hình cơ sở. Kết quả thí nghiệm trong Bảng 4 xác nhận rằng nội suy bài toán mang lại cải thiện đáng kể trên tất cả năm bộ dữ liệu. Kết quả cho thấy rằng bằng cách sử dụng nội suy bài toán, chúng ta có thể tạo ra các bài toán với mức độ khó trung gian, từ đó tăng sự đa dạng của tập hợp bài toán. Điều này mở rộng sự đa dạng của các bài toán và cuối cùng tăng cường hiệu suất của mô hình.

Phân tích thực thi mã thực tế trong giai đoạn suy luận. Chúng tôi nghiên cứu tác động của việc thực thi mã trong giai đoạn suy luận và báo cáo kết quả trong Bảng 5. Chúng tôi thực hiện nghiên cứu này bằng cách sử dụng CodeLlama-34B làm mô hình cơ sở và huấn luyện các mô hình trên bộ dữ liệu MathCodeInstruct 80k của chúng tôi. Bảng 5 (#1) và Bảng 5 (#2) sử dụng cùng một mô hình, được huấn luyện với hàm mất mát cross-entropy được tính toán không chỉ trên ngôn ngữ tự nhiên và mã, mà còn cả kết quả thực thi. Bằng cách này, mô hình này học cách dự đoán kết quả thực thi. Trong Bảng 5 (#1), kết quả thực thi mã được dự đoán bởi chính mô hình, trong khi ở Bảng 5 (#2), kết quả thực thi được trả về từ một trình thông dịch mã Python. Từ so sánh giữa Bảng 5 (#1) và Bảng 5 (#2), chúng ta có thể thấy rằng Bảng 5 (#1) vượt trội hơn Bảng 5 (#2) trên tất cả năm bộ dữ liệu, thể hiện cải thiện 34,0% trong điểm độ chính xác trung bình. Điều này cho thấy rằng việc thực thi mã thực tế trong giai đoạn suy luận có tác động đáng kể đến hiệu suất của mô hình. Nghiên cứu này cho thấy rằng mô hình không thể dự đoán kết quả thực thi đúng cho nhiều chương trình và việc thực sự thực thi mã bằng một công cụ bên ngoài có thể cải thiện đáng kể độ chính xác khi thực hiện các tính toán phức tạp. Phát hiện này xác nhận tầm quan trọng của việc tích hợp thực thi mã khi giải quyết bài toán toán học với LLM, phù hợp với GPT-4 Code interpreter mã nguồn đóng trước đó (Zhou et al., 2023a).

Phân tích kết quả thực thi trong giai đoạn huấn luyện. Dựa trên quan sát rằng việc thực thi mã thực tế đóng góp rất nhiều vào hiệu suất của mô hình, chúng tôi nghiên cứu việc không buộc mô hình phải dự đoán kết quả thực thi đúng. Bảng 5 (#3) là hiệu suất của MathCoder-CL-34B, loại bỏ kết quả thực thi khi tính toán hàm mất mát, để mô hình không học cách ước lượng kết quả thực thi và nhiệm vụ học tập ở giai đoạn tinh chỉnh có giám sát trở nên đơn giản hơn. So với Bảng 5 (#2), Bảng 5 (#3) cải thiện độ chính xác trên bốn trong số năm bộ dữ liệu, dẫn đến sự tăng độ chính xác trung bình từ 69,1% lên 70,2%, phù hợp với giả thuyết rằng bằng cách chỉ tính toán hàm mất mát trên ngôn ngữ tự nhiên và mã, mô hình có thể tập trung hơn vào kỹ năng giải quyết bài toán toán học, do đó làm cho việc tinh chỉnh có giám sát hiệu quả hơn.

8

--- TRANG 9 ---
Bảng 5: Nghiên cứu loại bỏ về có/không có thực thi mã trong quá trình suy luận và về hàm mất mát có/không có kết quả thực thi trong giai đoạn huấn luyện.
Thí nghiệm Bao gồm Thực tế GSM8K MATH SVAMP Mathematics Simuleq Trung bình kết quả thực thi cho huấn luyện thực thi mã trong suy luận
#1 Có Không 54.1 16.9 69.6 20.6 14.2 35.1
#2 Có Có 79.9 45.9 81.9 74.2 63.6 69.1
+25.8 +29.0 +12.3 +53.6 +49.4 +34.0
#3 Không Có 81.7 45.2 82.5 75.9 65.8 70.2
+1.8 -0.7 +0.6 +1.7 +2.1 +1.1

4 CÔNG TRÌNH LIÊN QUAN

Tinh chỉnh hướng dẫn. Tinh chỉnh hướng dẫn là một phương pháp tăng cường khả năng tuân thủ hướng dẫn của LLM, do đó điều chỉnh các mô hình ngôn ngữ với các mục tiêu hữu ích hơn và sở thích của con người. Một dòng nghiên cứu dài trước đây (Ye et al., 2021; Longpre et al., 2023; Sanh et al., 2021; Wang et al., 2022b; Wei et al., 2021; Chung et al., 2022; Longpre et al., 2023) tập trung vào việc tăng cường khả năng tuân thủ hướng dẫn của LLM nói chung. Với sự xuất hiện của các mô hình như GPT-3 và GPT-4, các nghiên cứu gần đây (Wang et al., 2022a; 2023b; Zhou et al., 2023b; Peng et al., 2023; Xu et al., 2023) đã bắt đầu sử dụng các hướng dẫn tổng hợp được tạo ra bởi những mô hình mạnh mẽ này để tinh chỉnh các mô hình nhỏ hơn. So với các công trình này, tinh chỉnh hướng dẫn của chúng tôi tập trung vào việc sử dụng các lời giải chất lượng cao cho các bài toán toán học được tạo ra bởi các mô hình để cải thiện khả năng giải toán của LLM. Một công trình liên quan khác được trình bày trong (Luo et al., 2023), nhưng phương pháp của họ không sử dụng mã để giải quyết bài toán toán học, phân biệt công trình của chúng tôi với họ.

Lập luận toán học. Có nhiều bộ dữ liệu tiêu chuẩn (Hendrycks et al., 2020; Ling et al., 2017; Hendrycks et al., 2021) để đo lường khả năng lập luận toán học của mô hình. Gần đây, nhiều công trình đã tập trung vào việc tăng cường khả năng giải quyết bài toán toán học của LLM, đạt điểm cao trên những tiêu chuẩn này. Nhiều trong số chúng áp dụng Chain-of-Thought (Wei et al., 2022; Kojima et al., 2023; Wang et al., 2023a; Fu et al., 2022) để cải thiện khả năng lập luận đa bước của LLM. Một dòng công trình khác (Gao et al., 2023; Chen et al., 2022; Zhou et al., 2023a) sử dụng mã để bù đắp cho những hạn chế của LLM trong việc thực hiện các tính toán toán học phức tạp. Công trình của chúng tôi lấy cảm hứng từ hai dòng công trình này, vì chúng tôi tin rằng cả Chain-of-Thought và tạo mã (Li et al., 2023a; Rozière et al., 2023) đều cần thiết để giải quyết bài toán toán học. Cũng có các công trình tập trung vào việc pre-train liên quan đến toán học (Lewkowycz et al., 2022; Taylor et al., 2022) để cải thiện khả năng lập luận tổng quát của mô hình. Chúng tôi kết hợp ngôn ngữ tự nhiên và mã một cách liền mạch trong bộ dữ liệu của chúng tôi, do đó cung cấp một phương pháp để huấn luyện các mô hình hiệu quả hơn trong việc giải quyết bài toán toán học.

Chưng cất. Chưng cất (Hinton et al., 2015) thường liên quan đến việc chuyển giao kiến thức từ một mô hình lớn hơn, mạnh mẽ hơn sang một mô hình nhỏ hơn, yếu hơn (Taori et al., 2023; Zheng et al., 2023; Cobbe et al., 2021). Nghiên cứu gần đây (Li et al., 2023b; Wang et al., 2022a; Allen-Zhu & Li, 2020) đã chứng minh tính khả thi của tự chưng cất, đạt được cải thiện hiệu suất bằng cách chưng cất chính mô hình đó. Cách tiếp cận của chúng tôi cũng có thể được xem như một hình thức tự chưng cất, vì các lời giải được tạo ra bởi MathCoder-Initial, được xây dựng trên CodeLlama-34B, được sử dụng để tinh chỉnh CodeLlama-34B, dẫn đến MathCoder-CL-34B.

5 KẾT LUẬN VÀ HẠN CHẾ

Trong bài báo này, chúng tôi trình bày MathCoder, một mô hình ngôn ngữ lớn mã nguồn mở được thiết kế cho lập luận toán học, kết nối khoảng cách giữa hiểu biết ngôn ngữ tự nhiên và giải quyết bài toán tính toán. MathCoder tích hợp việc xây dựng bộ dữ liệu tuân thủ hướng dẫn toán học. Bằng cách sử dụng các bộ dữ liệu GSM8K và MATH làm dữ liệu hạt giống, chúng tôi tận dụng GPT-4 để tạo ra các bài toán bao gồm lập luận, tạo mã và thực thi chương trình. Ngoài ra, chúng tôi đề xuất một phương pháp diễn giải bài toán để tạo ra các bài toán cấp độ trung gian. Hơn nữa, chúng tôi giới thiệu một phương pháp tinh chỉnh có giám sát tùy chỉnh, trong đó hàm mất mát huấn luyện chỉ được áp dụng cho ngôn ngữ tự nhiên và mã. Nghiên cứu thực nghiệm của chúng tôi chứng minh rằng MathCoder đạt hiệu suất tiên tiến nhất trong năm bộ dữ liệu toán học trong số các LLM mã nguồn mở, với điểm số 83,9% trên bộ dữ liệu GSM8K và 45,2% trên bộ dữ liệu MATH. Đáng chú ý rằng MathCoder vượt trội hơn các mô hình mã nguồn đóng như ChatGPT-3.5 và PaLM-2 trên các bộ dữ liệu GSM8K và MATH và thậm chí vượt trội hơn GPT-4 trên bộ dữ liệu MATH.

9

--- TRANG 10 ---
Tuy nhiên, công trình của chúng tôi có một số hạn chế nhất định cần khám phá thêm trong nghiên cứu tương lai.
Đầu tiên, vì chúng tôi dựa vào GPT-4 để tạo dữ liệu, khả năng của MathCoder về bản chất bị hạn chế
bởi khả năng của mô hình này và không thể giải quyết các bài toán chứng minh định lý.
Ngoài ra, như một loạt mô hình đơn phương thức, MathCoder vẫn gặp thách thức trong việc giải quyết
các bài toán hình học phức tạp, điều mà chúng tôi thừa nhận và dự định giải quyết trong các nghiên cứu
tương lai của chúng tôi.

TÀI LIỆU THAM KHẢO

Zeyuan Allen-Zhu and Yuanzhi Li. Towards understanding ensemble, knowledge distillation and
self-distillation in deep learning. arXiv preprint arXiv:2012.09816, 2020.

Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos,
Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report.
arXiv preprint arXiv:2305.10403, 2023.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are
few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompting:
Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint
arXiv:2211.12588, 2022.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language
models. arXiv preprint arXiv:2210.11416, 2022.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to
solve math word problems. arXiv preprint arXiv:2110.14168, 2021.

Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. Flashattention: Fast and
memory-efficient exact attention with io-awareness, 2022.

Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu,
Lei Li, and Zhifang Sui. A survey on in-context learning, 2023.

Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. Complexity-based prompting
for multi-step reasoning. arXiv preprint arXiv:2210.00720, 2022.

Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and
Graham Neubig. Pal: Program-aided language models. In International Conference on Machine
Learning, pp. 10764–10799. PMLR, 2023.

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Xiaodong
Song, and Jacob Steinhardt. Measuring massive multitask language understanding. ArXiv,
abs/2009.03300, 2020. URL https://api.semanticscholar.org/CorpusID:
221516475.

Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,
and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. arXiv
preprint arXiv:2103.03874, 2021.

Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the knowledge in a neural
network. ArXiv, abs/1503.02531, 2015. URL https://api.semanticscholar.org/
CorpusID:7200347.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large
language models are zero-shot reasoners, 2023.

10

--- TRANG 11 ---
Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and Regina Barzilay. Learning to automatically
solve algebra word problems. In Proceedings of the 52nd Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), pp. 271–281, 2014.

Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay
Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. Solving
quantitative reasoning problems with language models. Advances in Neural Information
Processing Systems, 35:3843–3857, 2022.

Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao
Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii,
Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João
Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee,
Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang,
Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan
Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha
Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav
Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra,
Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor,
Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean
Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. Starcoder: may the
source be with you!, 2023a.

Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy, Jason Weston, and
Mike Lewis. Self-alignment with instruction backtranslation. ArXiv, abs/2308.06259, 2023b.
URL https://api.semanticscholar.org/CorpusID:260866107.

Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale
generation: Learning to solve and explain algebraic word problems. In Proceedings of the 55th
Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),
pp. 158–167, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi:
10.18653/v1/P17-1015. URL https://aclanthology.org/P17-1015.

Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V
Le, Barret Zoph, Jason Wei, et al. The flan collection: Designing data and methods for effective
instruction tuning. arXiv preprint arXiv:2301.13688, 2023.

Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo
Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. Wizardmath: Empowering
mathematical reasoning for large language models via reinforced evol-instruct. arXiv preprint
arXiv:2308.09583, 2023.

OpenAI. Gpt-4 technical report, 2023.

Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are nlp models really able to solve simple math
word problems? arXiv preprint arXiv:2103.07191, 2021.

Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli,
Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. The refinedweb
dataset for falcon llm: outperforming curated corpora with web data, and web data only. arXiv
preprint arXiv:2306.01116, 2023.

Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. Instruction tuning
with gpt-4. arXiv preprint arXiv:2304.03277, 2023.

Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: Memory optimizations
toward training trillion parameter models, 2020.

Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi
Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton,
Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez,
Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and
Gabriel Synnaeve. Code llama: Open foundation models for code, 2023.

11

--- TRANG 12 ---
Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai,
Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training
enables zero-shot task generalization. arXiv preprint arXiv:2110.08207, 2021.

David Saxton, Edward Grefenstette, Felix Hill, and Pushmeet Kohli. Analysing mathematical
reasoning abilities of neural models. arXiv preprint arXiv:1904.01557, 2019.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy
Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.
https://github.com/tatsu-lab/stanford_alpaca, 2023.

Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia,
Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica: A large language model for
science. arXiv preprint arXiv:2211.09085, 2022.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei,
Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open
foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha
Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language
models. In The Eleventh International Conference on Learning Representations, 2023a. URL
https://openreview.net/forum?id=1PL1NIMMrw.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and
Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions.
arXiv preprint arXiv:2212.10560, 2022a.

Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,
Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al.
Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. arXiv
preprint arXiv:2204.07705, 2022b.

Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavi
Chandu, David Wadden, Kelsey MacMillan, Noah A Smith, Iz Beltagy, et al. How far can camels
go? exploring the state of instruction tuning on open resources. arXiv preprint arXiv:2306.04751,
2023b.

Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,
Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint
arXiv:2109.01652, 2021.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi,
Quoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language
models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.),
Advances in Neural Information Processing Systems, 2022. URL https://openreview.
net/forum?id=_VjQlMeSB_J.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and
Daxin Jiang. Wizardlm: Empowering large language models to follow complex instructions.
arXiv preprint arXiv:2304.12244, 2023.

Qinyuan Ye, Bill Yuchen Lin, and Xiang Ren. Crossfit: A few-shot learning challenge for cross-task
generalization in nlp. arXiv preprint arXiv:2104.08835, 2021.

Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Chuanqi Tan, and Chang Zhou. Scaling
relationship on learning mathematical reasoning with large language models. arXiv preprint
arXiv:2308.01825, 2023.

Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen.
Mammoth: Building math generalist models through hybrid instruction tuning, 2023.

12

--- TRANG 13 ---
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen,
Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open pre-trained
transformer language models. arXiv preprint arXiv:2205.01068, 2022.

Xu Zhao, Yuxi Xie, Kenji Kawaguchi, Junxian He, and Qizhe Xie. Automatic model selection with
large language models for reasoning, 2023.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,
Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.
Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.

Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia,
Linqi Song, Mingjie Zhan, et al. Solving challenging math word problems using gpt-4 code
interpreter with code-based self-verification. arXiv preprint arXiv:2308.07921, 2023a.

Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat,
Ping Yu, Lili Yu, et al. Lima: Less is more for alignment. arXiv preprint arXiv:2305.11206,
2023b.

13

--- TRANG 14 ---
PHỤ LỤC

A VÍ DỤ VỀ BỘ DỮ LIỆU

Trong phần này, chúng tôi bao gồm hai ví dụ cho thấy quá trình tạo ra MathCodeInstruct.
Hình 6 cho thấy một ví dụ chỉ có một khối LCE, trong khi Hình 7 cho thấy một ví dụ có ba khối LCE.

B VÍ DỤ VỀ SO SÁNH ĐỘ KHÓ

Chúng tôi thể hiện năm ví dụ về việc sử dụng GPT-4 để đánh giá độ phức tạp của các bài toán trong
MathCodeInstruct. Hình 8 và Hình 9 là hai ví dụ về các bài toán nội suy được tạo ra mới khó hơn
các bài toán GSM8K gốc, và Hình 10 là một ví dụ về bài toán MATH gốc khó hơn bài toán nội suy
được tạo ra mới. Hai tình huống này là phổ biến nhất (83,2% và 95,6%).

Hình 11 thể hiện một ví dụ về bài toán nội suy được tạo ra mới hòa với bài toán GSM8K gốc, tình
huống này chiếm 15,3% của tất cả các bài toán.

Hình 12 thể hiện một ví dụ không phổ biến về bài toán GSM8K gốc hơi khó hơn bài toán nội suy
được tạo ra mới theo GPT-4, tình huống này chiếm dưới 3% của tất cả các bài toán.

C TẠO BÀI TOÁN CHỈ SỬ DỤNG GSM8K

Hình 13, Hình 14, Hình 15, Hình 16 và Hình 17 là năm ví dụ sử dụng các bài toán từ tập huấn luyện
của GSM8K để tạo ra các bài toán mới khó hơn các bài toán gốc. So với các bài toán được tạo ra bằng
phương pháp nội suy của chúng tôi, chúng ta có thể thấy rằng các bài toán mới được tạo ra theo cách này
rất giống với các bài toán GSM8K thô, đôi khi chỉ thay đổi tên của một số biến hoặc thay đổi giá trị.
Những bài toán này chỉ phức tạp hơn một chút so với các bài toán thô, nếu không phải là khó như nhau,
và vẫn đơn giản hơn nhiều so với những bài toán từ bộ dữ liệu MATH.

Trái ngược với việc chỉ sử dụng GSM8K, việc giới thiệu các bài toán từ bộ dữ liệu MATH trong phương
pháp nội suy cho thấy mô hình (GPT-4 ở đây) một tuyến đường để tạo ra các bài toán thách thức hơn.
Do đó, các bài toán nội suy được tạo ra mới tương tự như các bài toán trong GSM8K và các bài toán
trong MATH. Kết quả là, những bài toán nội suy này có thể thu hẹp khoảng cách độ khó giữa hai bộ dữ liệu.

D KẾT QUẢ THÍ NGHIỆM KHÁC

Chúng tôi thể hiện so sánh hiệu suất của tất cả các MathCoder, MathCoder-L (7B, 13B, 70B) và
MathCoder-CL (7B, 13B, 34B), trên bộ dữ liệu MATH theo cấp độ và môn học trong Hình 18.
Chúng ta có thể thấy rằng việc cải thiện độ chính xác từ MathCoder-L sang MathCoder-CL chủ yếu
đến từ các môn học yêu cầu tính toán chính xác như đại số, lý thuyết số, và đếm và xác suất.

E NGHIÊN CỨU TRƯỜNG HỢP VỚI COT, POT VÀ LCE

Chúng tôi so sánh các lời giải LCE của chúng tôi với các lời giải CoT và lời giải PoT. Hình 19 là một
ví dụ về một bài toán trong lý thuyết số, và Hình 20 là một ví dụ về một bài toán trong đại số.
CoT và PoT đều không giải quyết được bài toán trong cả hai trường hợp, nhưng LCE thành công.

Hình 21, Hình 22, và Hình 23 là ba lời giải cho một bài toán trong hình học. Các lời giải CoT đã
tính toán thành công tọa độ của D, C, và E nhưng không thể tính toán diện tích, trong khi PoT
không thể diễn giải các điều kiện trong bài toán. So với chúng, chúng ta có thể thấy rằng các lời
giải LCE của chúng tôi không chỉ có thể sử dụng đúng các điều kiện trong bài toán mà còn không
mắc lỗi trong tính toán.

14

--- TRANG 15 ---
(a) Lời nhắc nội suy:
Hãy tạo ra một bài toán mới, theo ví dụ đã cho, "Ví dụ 1" là một bài toán dễ và
"Ví dụ 2" khó hơn nhiều so với "Ví dụ 1", bài toán mới nên khó hơn
"Ví dụ 1" và đơn giản hơn "Ví dụ 2".
Ví dụ 1: Marissa đang đi bộ trên một con đường mòn dài 12 dặm. Cô ấy đã mất 1 giờ để đi 4 dặm đầu tiên, sau đó mất thêm
một giờ để đi 2 dặm tiếp theo. Nếu cô ấy muốn tốc độ trung bình của mình là 4 dặm mỗi giờ, cô ấy cần đi với tốc độ bao nhiêu (tính bằng
dặm mỗi giờ) cho khoảng cách còn lại?
Ví dụ 2: Hai nghiệm của phương trình x2+bx+ 48 = 0 có tỷ lệ 3 với 1 cho một số giá trị
của b. Giá trị lớn nhất có thể có của b là bao nhiêu?
(b) Bài toán mới được tạo ra bởi GPT-4:
Một nhóm bạn đi du lịch qua ba thành phố. Ở thành phố đầu tiên, họ tiêu hết một nửa số tiền họ có cộng thêm 50 đô la. Ở thành phố thứ hai, họ tiêu hết một nửa số tiền còn lại cộng thêm 30 đô la. Ở thành phố thứ ba, họ tiêu hết một nửa số tiền còn lại cộng thêm 20 đô la, để lại cho họ 40 đô la. Họ bắt đầu với bao nhiêu tiền trước chuyến đi?
(c) Lời giải được tạo ra bởi MathCoder-Initial mà không có lời nhắc thêm:
Hãy chia nhỏ bài toán này từng bước:
1. Gọi x là số tiền họ bắt đầu với.
2. Sau khi đến thành phố đầu tiên, họ đã tiêu x/2+ 50. Vậy, số tiền còn lại là x−x/2+ 50.
3. Ở thành phố thứ hai, họ tiêu một nửa số tiền còn lại cộng 30 đô la. Điều này có nghĩa là họ đã tiêu
x−(x/2+50)/2+ 30. Sau khi chi tiêu này, họ sẽ có x−x/2+ 50−
x−(x/2+50)/2+ 30 còn lại.
4. Ở thành phố thứ ba, họ tiêu một nửa số tiền còn lại từ số tiền trên cộng 20 đô la. Sau đó, họ còn lại 40 đô la.
Sử dụng thông tin trên, chúng ta có thể thiết lập một phương trình để giải x:
x−x/2+ 50− 
x−x/2+ 50/2+ 30!
−
x−x/2+ 50−
x−(x/2+50)/2+ 30/2+ 20
= 40
Hãy giải phương trình này để tìm giá trị của x.
from sympy import symbols, Eq, solve
# Định nghĩa biến
x = symbols('x')
# Định nghĩa phương trình dựa trên mô tả bài toán
equation = Eq(x - (x/2 + 50) - (x - (x/2 + 50))/2 - 30 - (x - (x/2 + 50) - (x - (x/2 + 50))/2
- 30)/2 - 20, 40)
# Giải phương trình
initial_money = solve(equation)[0]
>>> 700
Nhóm bạn đã bắt đầu với 700 đô la trước chuyến đi.

Hình 6: Một ví dụ về quá trình tạo ra MathCodeInstruct. Đầu tiên, "Ví dụ 1" và "Ví dụ
2" được chọn ngẫu nhiên từ tập huấn luyện của GSM8K và MATH tương ứng. Sau đó một bài toán mới được tạo ra
bởi GPT-4 bằng lời nhắc nội suy. Cuối cùng, chúng tôi sử dụng MathCoder ban đầu để tạo ra lời giải theo phong cách LCE
cho bài toán mới.

15

--- TRANG 16 ---
(a) Lời nhắc nội suy:
Hãy tạo ra một bài toán mới, theo ví dụ đã cho, "Ví dụ 1" là một bài toán dễ và
"Ví dụ 2" khó hơn nhiều so với "Ví dụ 1", bài toán mới nên khó hơn
"Ví dụ 1" và đơn giản hơn "Ví dụ 2".
Ví dụ 1: Xe buýt đến bến xe buýt của Jerry mỗi 20 phút bắt đầu từ đúng 5:13 sáng. Nếu Jerry xuất hiện vào đúng 8:35 sáng, anh ấy sẽ phải đợi bao nhiêu phút cho chuyến xe buýt tiếp theo?
Ví dụ 2: Ông của Bella bị hạn chế với xe lăn. Ông sẽ đến thăm cô. Bella muốn xây một đường dốc xe lăn. Nghiên cứu của cô cho thấy rằng phải có 3,5 mét đường dốc cho mỗi 30 centimét độ cao. Khoảng cách từ mặt đất đến bậc cửa trước nhà Bella là 9 cm. Độ dài của đường dốc phải là bao nhiêu?
(b) Bài toán mới được tạo ra bởi GPT-4:
Liam là một người quan sát chim và ghi lại mô hình di cư của một loài chim cụ thể. Mỗi 15 ngày, những con chim bay về phía nam 250 dặm và sau đó bay trở lại phía bắc 100 dặm. Nếu mô hình này tiếp tục, những con chim sẽ ở về phía nam bao xa so với vị trí ban đầu của chúng sau 75 ngày?
(c) Lời giải được tạo ra bởi MathCoder-Initial mà không có lời nhắc thêm:
Hãy giải bài toán từng bước:
1. Tính toán khoảng cách ròng mà những con chim đã di chuyển từ vị trí ban đầu của chúng trong 15 ngày.
2. Sử dụng khoảng cách ròng để xác định những con chim sẽ di chuyển bao xa sau 75 ngày.
Hãy bắt đầu bằng cách tính toán khoảng cách ròng mà những con chim bay về phía nam trong 15 ngày. Khoảng cách ròng có thể được tìm thấy bằng cách trừ khoảng cách bay về phía bắc khỏi khoảng cách bay về phía nam.
south_distance_15_days, north_distance_15_days = 250, 100
net_distance_15_days = south_distance_15_days - north_distance_15_days
>>> 150
Những con chim đã di chuyển một khoảng cách ròng 150 dặm về phía nam từ vị trí ban đầu của chúng trong 15 ngày.
Bây giờ, để xác định những con chim sẽ di chuyển bao xa sau 75 ngày, chúng ta cần:
Tính toán có bao nhiêu chu kỳ 15 ngày trong 75 ngày. Nhân số chu kỳ 15 ngày với khoảng cách ròng di chuyển trong 15 ngày để có tổng khoảng cách di chuyển trong 75 ngày. Hãy tìm hiểu có bao nhiêu chu kỳ 15 ngày trong 75 ngày.
total_days = 75
number_of_cycles = total_days // 15
>>> 5
Có 5 chu kỳ 15 ngày trong khoảng thời gian 75 ngày.
Bây giờ, hãy tính toán tổng khoảng cách mà những con chim sẽ di chuyển sau 75 ngày bằng cách nhân số chu kỳ 15 ngày với khoảng cách ròng di chuyển trong một chu kỳ 15 ngày.
total_distance_75_days = number_of_cycles *net_distance_15_days
>>> 750
Sau 75 ngày, những con chim sẽ ở 750 dặm về phía nam từ vị trí ban đầu của chúng.

Hình 7: Một ví dụ về quá trình tạo ra MathCodeInstruct. Đầu tiên, "Ví dụ 1" và "Ví dụ
2" được chọn ngẫu nhiên từ tập huấn luyện của GSM8K và MATH tương ứng. Sau đó một bài toán mới được tạo ra
bởi GPT-4 bằng lời nhắc nội suy. Cuối cùng, chúng tôi sử dụng MathCoder ban đầu để tạo ra lời giải theo phong cách LCE
cho bài toán mới.

16

--- TRANG 17 ---
(a) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Zain có thêm 10 đồng xu mỗi loại so với Emerie. Nếu Emerie có sáu đồng xu 25 xu, bảy đồng xu 10 xu, và
năm đồng xu 5 xu, Zain có bao nhiêu đồng xu?"
Bài toán 2: "Trong một cuộc chạy marathon, mỗi vận động viên phải chạy qua một số điểm kiểm tra. Trong đoạn đầu tiên,
Angela chạy nhiều hơn Miguel 15 mét. Trong mỗi đoạn tiếp theo, Angela chạy ít hơn 5 mét so với đoạn trước đó, trong khi Miguel chạy ổn định. Nếu Miguel chạy 50 mét trong đoạn đầu tiên, Angela chạy bao nhiêu mét tổng cộng khi cô ấy hoàn thành 5 đoạn?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(b) Phán đoán từ GPT-4:
Hãy phân tích cả hai bài toán từng bước để đánh giá độ phức tạp của chúng.
Bài toán 1:
Emerie có:
• Đồng xu 25 xu: 6
• Đồng xu 10 xu: 7
• Đồng xu 5 xu: 5
Zain có thêm 10 đồng xu mỗi loại so với Emerie:
• Đồng xu 25 xu: 6 + 10 = 16
• Đồng xu 10 xu: 7 + 10 = 17
• Đồng xu 5 xu: 5 + 10 = 15
Để tìm hiểu Zain có bao nhiêu đồng xu, chúng ta chỉ cần cộng những con số này lại:
16 + 17 + 15 = 48 đồng xu
Bài toán 2:
Cho:
- Miguel chạy ổn định ở 50 mét mỗi đoạn.
- Angela chạy 50 + 15 = 65 mét trong đoạn đầu tiên.
- Angela chạy ít hơn 5 mét trong mỗi đoạn tiếp theo.
Sử dụng khái niệm về cấp số cộng:
Sn=n/2(2a1+ (n−1)d)
Với Angela, số hạng đầu tiên, a1, là 65 mét (nhiều hơn Miguel 15 mét so với 50 mét của Miguel), và công sai, d, là -5 mét, vì cô ấy chạy ít hơn 5 mét trong mỗi đoạn tiếp theo. Cô ấy hoàn thành 5 đoạn, vậy n= 5.
Hãy thay vào các giá trị để tìm hiểu Angela chạy bao nhiêu mét tổng cộng trong 5 đoạn:
S5=5/2(2·65 + (5 −1)· −5) =5/2(130−20) =5/2(110) =550/2= 275 mét
Kết luận:
Bài toán 1 bao gồm phép tính đơn giản và yêu cầu người giải cộng một số đồng xu không đổi vào số đồng xu đã biết mà Emerie có. Không có chuỗi hoặc giảm/tăng tuần tự nào liên quan.
Bài toán 2, tuy nhiên, bao gồm việc hiểu một cấp số cộng. Nó cần hiểu về dãy số và chuỗi, và có thể yêu cầu nhiều bước để giải hơn, chẳng hạn như xác định số hạng đầu tiên, công sai, và sau đó áp dụng công thức để tìm tổng của chuỗi. Do đó, dựa trên những cân nhắc này, có thể lập luận rằng "Bài toán 2" khó hơn.

Hình 8: Một ví dụ về việc sử dụng GPT-4 để đánh giá độ phức tạp của các bài toán trong MathCodeInstruct.
"Bài toán 2" có trong MathCodeInstruct và "Bài toán 1" là bài toán từ GSM8K được sử dụng để
tạo ra "Bài toán 2".

17

--- TRANG 18 ---
(a) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Peter có 15 con chim. 1/3 là vịt. Phần còn lại là gà và cần thức ăn đặc biệt có giá 2 đô la mỗi con. Chi phí cho việc cho gà ăn là bao nhiêu?"
Bài toán 2: "Trong một khu vườn hình chữ nhật, chiều dài gấp 4 lần chiều rộng. Nếu tổng diện tích của khu vườn được tăng 120 feet vuông bằng cách tăng chiều rộng thêm 5 feet trong khi giữ chiều dài không đổi, diện tích ban đầu của khu vườn là bao nhiêu?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2", và "Hòa".
(b) Phán đoán từ GPT-4:
Hãy phân tích hai bài toán để hiểu độ phức tạp của từng bài.
Bài toán 1:
Peter có 15 con chim, và 1/3 là vịt. Vậy số gà là 2/3×15 = 10 con gà.
Chi phí cho việc cho gà ăn là 2 đô la mỗi con gà, vậy:
Chi phí = 10 con gà ×2 đô la/con gà = 20 đô la
Bài toán 2:
Gọi chiều rộng ban đầu của khu vườn là w và chiều dài là 4w.
Diện tích ban đầu của khu vườn là 4w2.
Nếu chiều rộng được tăng thêm 5 feet, chiều rộng mới là w+ 5.
Diện tích mới sau đó là 4w(w+ 5) = 4w2+ 20w.
Cho rằng tổng diện tích của khu vườn được tăng 120 feet vuông:
4w2+ 20w−(4w2) = 120
20w= 120
w= 6 feet
Vậy, diện tích ban đầu là:
4w2= 4(6)2= 144 feet vuông
So sánh:
Bài toán 1 bao gồm phép tính cơ bản và một phân số đơn giản, làm cho nó tương đối dễ dàng.
Bài toán 2 bao gồm việc giải một phương trình bậc hai và yêu cầu hiểu biết tốt hơn về các khái niệm đại số và diện tích hình chữ nhật.
Vậy, Bài toán 2 khó hơn Bài toán 1.

Hình 9: Một ví dụ về việc sử dụng GPT-4 để đánh giá độ phức tạp của các bài toán trong MathCodeInstruct.
"Bài toán 2" có trong MathCodeInstruct và "Bài toán 1" là bài toán từ GSM8K được sử dụng để
tạo ra "Bài toán 2".

18

--- TRANG 19 ---
(a) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Hai nghiệm của phương trình x2+bx+ 48 = 0 có tỷ lệ 3 với 1 cho một số
giá trị của b. Giá trị lớn nhất có thể có của b là bao nhiêu?"
Bài toán 2: "Trong một khu vườn hình chữ nhật, chiều dài gấp 4 lần chiều rộng. Nếu tổng diện tích của khu vườn được
tăng 120 feet vuông bằng cách tăng chiều rộng thêm 5 feet trong khi giữ chiều dài không đổi, diện tích ban đầu của khu vườn là bao nhiêu?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(b) Phán đoán từ GPT-4:
Hai bài toán được cung cấp, về cơ bản, đều liên quan đến thao tác đại số, nhưng Bài toán 1 liên quan đến phương trình bậc hai và hiểu biết khái niệm hơn về nghiệm bậc hai, trong khi Bài toán 2 đơn giản hơn và liên quan đến phương trình tuyến tính. Dựa trên điều này, có thể nói rằng "Bài toán 1" khó hơn so với "Bài toán 2". Đây là một giải thích và lời giải ngắn gọn cho cả hai bài toán để minh họa điểm này:
Bài toán 1:
Cho rằng các nghiệm của x2+bx+ 48 = 0 có tỷ lệ 3 : 1, gọi các nghiệm là 3k và k. Tổng các nghiệm là 4k, và tích các nghiệm là 48.
Sử dụng công thức Vieta:
-3k+k= 4k=−b
-3k∗k= 3k2= 48
Giải k trong phương trình thứ hai:
k2= 16 = ⇒k=±4
Vậy, các nghiệm là 12 và 4 hoặc −12 và −4. Vậy, các giá trị có thể có của b là −16 hoặc 16.
Vậy giá trị lớn nhất có thể có của b là 16.
Bài toán 2:
Gọi chiều rộng của khu vườn hình chữ nhật là w, thì chiều dài sẽ là 4w.
Diện tích ban đầu là:
Aoriginal =l∗w= 4w∗w= 4w2
Nếu chiều rộng được tăng thêm 5 feet, chiều rộng mới là w+ 5, và diện tích mới là:
Anew=l∗(w+ 5) = 4w∗(w+ 5) = 4w2+ 20w
Cho rằng tổng diện tích của khu vườn được tăng 120 feet vuông:
Anew=Aoriginal + 120
4w2+ 20w= 4w2+ 120
Giải w:
20w= 120 = ⇒w= 6
Vậy, diện tích ban đầu của khu vườn là:
Aoriginal = 4w2= 4∗36 = 144 feet vuông
Bài toán 1 yêu cầu hiểu biết về phương trình bậc hai, công thức Vieta, và xem xét nhiều khả năng, làm cho nó thách thức hơn so với Bài toán 2, liên quan đến thao tác đại số đơn giản hơn với phương trình tuyến tính.

Hình 10: Một ví dụ về việc sử dụng GPT-4 để đánh giá độ phức tạp của các bài toán trong MathCodeInstruct.
"Bài toán 2" có trong MathCodeInstruct và "Bài toán 1" là bài toán từ MATH được sử dụng để
tạo ra "Bài toán 2".

19

--- TRANG 20 ---
(a) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Kara trộn cốc đường và nước theo tỷ lệ 1:2 để làm một lít nước chanh.
Tính tổng số cốc đường sử dụng nếu cô ấy đã sử dụng 84 cốc để làm nước chanh."
Bài toán 2: "Một bể nước hình trụ có hai ngăn. Ngăn đầu tiên có chiều cao bằng một nửa chiều cao của ngăn thứ hai. Khi được đổ đầy, ngăn đầu tiên chứa 60 lít nước. Nếu một ống bơm nước vào bể với tốc độ 10 lít mỗi phút và bắt đầu đổ đầy ngăn thứ hai, sẽ mất bao nhiêu phút để đổ đầy toàn bộ bể?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(b) Phán đoán từ GPT-4:
Hãy giải từng bài toán một và sau đó xác định bài toán nào khó hơn.
Bài toán 1:
Kara trộn cốc đường và nước theo tỷ lệ 1 : 2.
Vậy, với mỗi 1 cốc đường, có 2 cốc nước.
Tỷ lệ đường với tổng hỗn hợp là:
Đường : Tổng = 1 : (1 + 2) = 1 : 3
Cô ấy đã sử dụng 84 cốc để làm nước chanh, vậy:
Số cốc đường sử dụng =1/3×84 = 28 cốc
Bài toán 2:
Ngăn đầu tiên có chiều cao bằng một nửa chiều cao của ngăn thứ hai nhưng chứa 60 lít nước.
Vậy, ngăn thứ hai sẽ chứa 2×60 lít nước, tức là 120 lít nước.
Tổng thể tích của bể, bao gồm cả hai ngăn, là:
60 lít + 120 lít = 180 lít
Ống bơm nước với tốc độ 10 lít mỗi phút, vậy để đổ đầy toàn bộ bể, sẽ mất:
Thời gian =180 lít/(10 lít/phút)= 18 phút
Kết luận:
Cả hai bài toán đều có thể được giải bằng phép tính cơ bản và hiểu biết về tỷ lệ, và không bài toán nào yêu cầu khái niệm toán học nâng cao. Do đó, có thể được coi là "Hòa" về độ khó.

Hình 11: Một ví dụ về việc sử dụng GPT-4 để đánh giá độ phức tạp của các bài toán trong MathCodeInstruct.
"Bài toán 2" có trong MathCodeInstruct, và "Bài toán 1" là bài toán từ GSM8K được sử dụng để
tạo ra "Bài toán 2". Đây là một ví dụ về trường hợp hòa.

20

--- TRANG 21 ---
(a) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Khi Jeffrey đi bộ, cứ mỗi ba bước tiến, anh ấy lại lùi hai bước.
Do đó, nếu khoảng cách giữa nhà và hộp thư là 66 bước, tổng số bước Jeffrey thực hiện khi đi từ nhà đến hộp thư là bao nhiêu?"
Bài toán 2: "Cứ mỗi bốn quả táo Jake ăn, anh ấy trồng ba hạt táo. Nếu cuối tháng anh ấy đã tiêu thụ 24 quả táo, anh ấy đã trồng bao nhiêu hạt?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(b) Phán đoán từ GPT-4:
Hãy phân tích từng bài toán từng bước:
Bài toán 1:
Mỗi 3 bước tiến và 2 bước lùi có nghĩa là Jeffrey di chuyển hiệu quả 1 bước cho mỗi 5 bước anh ấy thực hiện (3 bước tiến - 2 bước lùi = 1 bước di chuyển ròng).
Để bao phủ 66 bước:
Số bước cần thiết = (Tổng khoảng cách / Di chuyển ròng mỗi chu kỳ) × Số bước mỗi chu kỳ
Số bước cần thiết = (66 bước / 1 bước) × 5 = 330 bước
Bài toán 2:
Cứ mỗi 4 quả táo Jake ăn, anh ấy trồng 3 hạt.
Vậy, với 24 quả táo:
Số hạt trồng = (24 quả táo / 4) × 3 hạt = 6 × 3 = 18 hạt
Để xác định bài toán nào khó hơn, có vẻ như cả hai bài toán đều liên quan đến các phép toán cơ bản tương tự (chia và nhân).
Tuy nhiên, bài toán đầu tiên giới thiệu thêm một lớp phức tạp với hai loại chuyển động khác nhau (tiến và lùi) so với tỷ lệ trực tiếp trong bài toán thứ hai.
Với phân tích này, Bài toán 1 có vẻ hơi khó hơn Bài toán 2 do lớp hiểu biết bổ sung cần thiết để giải quyết nó.

Hình 12: Một ví dụ về việc sử dụng GPT-4 để đánh giá độ phức tạp của các bài toán trong MathCodeInstruct và
đây là một ví dụ không phổ biến về bài toán từ GSM8K hơi khó hơn bài toán nội suy.
"Bài toán 2" có trong MathCodeInstruct và "Bài toán 1" là bài toán từ GSM8K được sử dụng để
tạo ra "Bài toán 2".

21

--- TRANG 22 ---
(a) Lời nhắc:
Hãy tạo ra một bài toán mới, theo "Ví dụ" đã cho và bài toán mới nên khó hơn "Ví dụ".
Ví dụ: "Mẹ Josh cho anh ấy 20 đô la để đi mua sắm ở trung tâm thương mại. Anh ấy mua một chiếc mũ với giá 10 đô la và một cây bút chì với giá 2 đô la. Sau đó anh ấy mua bốn cái bánh quy. Nếu mỗi cái bánh quy có giá 1,25 đô la, Josh còn lại bao nhiêu tiền?"
(b) Bài toán mới được tạo ra bởi GPT-4:
Bố Rebecca cho cô ấy 50 đô la để tiêu trong công viên giải trí. Cô ấy mua một vé với giá 25 đô la và một món quà lưu niệm với giá 6 đô la. Sau khi đi một vài trò chơi, cô ấy quyết định mua sáu quả bóng bay cho bạn bè. Nếu mỗi quả bóng bay có giá 2,50 đô la, Rebecca còn lại bao nhiêu tiền?
(c) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Mẹ Josh cho anh ấy 20 đô la để đi mua sắm ở trung tâm thương mại. Anh ấy mua một chiếc mũ với giá 10 đô la và một cây bút chì với giá 2 đô la. Sau đó anh ấy mua bốn cái bánh quy. Nếu mỗi cái bánh quy có giá 1,25 đô la, Josh còn lại bao nhiêu tiền?"
Bài toán 2: "Bố Rebecca cho cô ấy 50 đô la để tiêu trong công viên giải trí. Cô ấy mua một vé với giá 25 đô la và một món quà lưu niệm với giá 6 đô la. Sau khi đi một vài trò chơi, cô ấy quyết định mua sáu quả bóng bay cho bạn bè. Nếu mỗi quả bóng bay có giá 2,50 đô la, Rebecca còn lại bao nhiêu tiền?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(d) Phán đoán từ GPT-4:
Hãy giải cả hai bài toán từng bước:
Bài toán 1: Số tiền ban đầu của Josh: 20 đô la
Anh ấy mua một chiếc mũ: 20 đô la - 10 đô la = 10 đô la còn lại
Anh ấy mua một cây bút chì: 10 đô la - 2 đô la = 8 đô la còn lại
Giá của bốn cái bánh quy = 4 x 1,25 đô la = 5 đô la
Số tiền sau khi mua bánh quy: 8 đô la - 5 đô la = 3 đô la
Vậy, Josh còn lại 3 đô la.
Bài toán 2: Số tiền ban đầu của Rebecca: 50 đô la
Cô ấy mua một vé: 50 đô la - 25 đô la = 25 đô la còn lại
Cô ấy mua một món quà lưu niệm: 25 đô la - 6 đô la = 19 đô la còn lại
Giá của sáu quả bóng bay = 6 x 2,50 đô la = 15 đô la
Số tiền sau khi mua bóng bay: 19 đô la - 15 đô la = 4 đô la
Vậy, Rebecca còn lại 4 đô la.
Về độ khó, cả hai bài toán đều liên quan đến phép trừ và nhân. Tuy nhiên, Bài toán 2 có số lớn hơn một chút và một phép nhân nhiều hơn Bài toán 1. Do đó, bạn có thể lập luận rằng:
Trả lời: Bài toán 2 khó hơn Bài toán 1.

Hình 13: Một ví dụ về việc sử dụng GPT-4 để tạo ra bài toán chỉ dựa trên các bài toán từ GSM8K và sau đó
đánh giá độ phức tạp của các bài toán mới được tạo ra. "Bài toán 2" là bài toán mới, và "Bài toán 1" là
bài toán từ GSM8K được sử dụng để tạo ra "Bài toán 2".

22

--- TRANG 23 ---
(a) Lời nhắc:
Hãy tạo ra một bài toán mới, theo "Ví dụ" đã cho và bài toán mới nên khó hơn "Ví dụ".
Ví dụ: "Kara trộn cốc đường và nước theo tỷ lệ 1:2 để làm một lít nước chanh.
Tính tổng số cốc đường sử dụng nếu cô ấy đã sử dụng 84 cốc để làm nước chanh."
(b) Bài toán mới được tạo ra bởi GPT-4:
Liam trộn cốc mật ong, nước, và nước chanh theo tỷ lệ 2:5:3 để làm một gallon nước chanh mật ong. Tính tổng số cốc mật ong sử dụng nếu anh ấy đã sử dụng 120 cốc để làm nước chanh mật ong.
(c) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Kara trộn cốc đường và nước theo tỷ lệ 1:2 để làm một lít nước chanh.
Tính tổng số cốc đường sử dụng nếu cô ấy đã sử dụng 84 cốc để làm nước chanh."
Bài toán 2: "Liam trộn cốc mật ong, nước, và nước chanh theo tỷ lệ 2:5:3 để làm một gallon nước chanh mật ong. Tính tổng số cốc mật ong sử dụng nếu anh ấy đã sử dụng 120 cốc để làm nước chanh mật ong."
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(d) Phán đoán từ GPT-4:
Hãy giải từng bài toán để xác định bài toán nào khó hơn:
Bài toán 1:
Nếu tỷ lệ đường với nước là 1:2, thì cứ mỗi 3 cốc (1 cốc đường + 2 cốc nước), 1 lít nước chanh được làm.
Vậy, nếu cô ấy đã sử dụng 84 cốc để làm nước chanh, thì:
Số lít nước chanh được làm = 84 cốc / 3 = 28 lít
Do đó, tổng số cốc đường sử dụng là:
28 lít * 1 cốc đường = 28 cốc đường
Bài toán 2:
Nếu tỷ lệ mật ong với nước với nước chanh là 2:5:3, thì cứ mỗi 10 cốc (2 cốc mật ong + 5 cốc nước + 3 cốc nước chanh), 1 gallon nước chanh mật ong được làm.
Vậy, nếu anh ấy đã sử dụng 120 cốc để làm nước chanh mật ong, thì:
Số gallon nước chanh mật ong được làm = 120 cốc / 10 = 12 gallon
Do đó, tổng số cốc mật ong sử dụng là:
12 gallon * 2 cốc mật ong = 24 cốc mật ong
So sánh:
Cả hai bài toán đều liên quan đến cách tiếp cận tương tự để giải. Cả hai đều yêu cầu hiểu biết về tỷ lệ và chia tỷ lệ tổng số cốc đã cho theo tổng các thành phần của tỷ lệ.
Kết luận: Hòa. Cả hai bài toán có độ khó tương tự.

Hình 14: Một ví dụ về việc sử dụng GPT-4 để tạo ra bài toán chỉ dựa trên các bài toán từ GSM8K và sau đó
đánh giá độ phức tạp của các bài toán mới được tạo ra. "Bài toán 2" là bài toán mới, và "Bài toán 1" là
bài toán từ GSM8K được sử dụng để tạo ra "Bài toán 2".

23

--- TRANG 24 ---
(a) Lời nhắc:
Hãy tạo ra một bài toán mới, theo "Ví dụ" đã cho và bài toán mới nên khó hơn "Ví dụ".
Ví dụ: "Hillary luôn mua các ấn bản thứ Tư, thứ Năm và thứ Sáu của tờ báo địa phương với giá 0,50 đô la mỗi tờ. Vào Chủ nhật, cô ấy tiêu 2,00 đô la để mua bản sao đó. Cô ấy tiêu bao nhiêu tiền cho báo trong 8 tuần?"
(b) Bài toán mới được tạo ra bởi GPT-4:
Joseph mua các tạp chí yêu thích của mình vào thứ Hai, thứ Ba, và thứ Bảy hàng tuần. Ấn bản thứ Hai có giá 1,25 đô la, ấn bản thứ Ba có giá 1,50 đô la, và ấn bản thứ Bảy có giá 2,75 đô la. Ngoài ra, anh ấy mua một ấn bản đặc biệt hàng tuần vào Chủ nhật với giá 3,50 đô la. Joseph tiêu bao nhiêu tiền để mua các tạp chí yêu thích của mình trong 12 tuần?
(c) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Hillary luôn mua các ấn bản thứ Tư, thứ Năm và thứ Sáu của tờ báo địa phương với giá 0,50 đô la mỗi tờ. Vào Chủ nhật, cô ấy tiêu 2,00 đô la để mua bản sao đó. Cô ấy tiêu bao nhiêu tiền cho báo trong 8 tuần?"
Bài toán 2: "Joseph mua các tạp chí yêu thích của mình vào thứ Hai, thứ Ba, và thứ Bảy hàng tuần. Ấn bản thứ Hai có giá 1,25 đô la, ấn bản thứ Ba có giá 1,50 đô la, và ấn bản thứ Bảy có giá 2,75 đô la. Ngoài ra, anh ấy mua một ấn bản đặc biệt hàng tuần vào Chủ nhật với giá 3,50 đô la. Joseph tiêu bao nhiêu tiền để mua các tạp chí yêu thích của mình trong 12 tuần?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(d) Phán đoán từ GPT-4:
Hãy phân tích từng bài toán:
Bài toán 1:
1. Hillary mua báo vào thứ Tư, thứ Năm, và thứ Sáu với giá 0,50 đô la mỗi tờ. Vậy, chi phí cho 3 ngày này = 3 * 0,50 đô la = 1,50 đô la
2. Vào Chủ nhật, cô ấy tiêu 2,00 đô la.
3. Tổng cô ấy tiêu trong một tuần = 1,50 đô la + 2,00 đô la = 3,50 đô la
4. Trong 8 tuần, cô ấy tiêu = 8 * 3,50 đô la = 28,00 đô la
Bài toán 2:
1. Joseph mua tạp chí vào thứ Hai với giá 1,25 đô la, thứ Ba với giá 1,50 đô la, và thứ Bảy với giá 2,75 đô la. Vậy, chi phí cho 3 ngày này = 1,25 đô la + 1,50 đô la + 2,75 đô la = 5,50 đô la
2. Ngoài ra, anh ấy mua một ấn bản đặc biệt vào Chủ nhật với giá 3,50 đô la.
3. Tổng anh ấy tiêu trong một tuần = 5,50 đô la + 3,50 đô la = 9,00 đô la
4. Trong 12 tuần, anh ấy tiêu = 12 * 9,00 đô la = 108,00 đô la
Về độ phức tạp toán học, cả hai bài toán đều liên quan đến cùng những phép toán: nhân và cộng. Tuy nhiên, bài toán thứ hai có nhiều mua hàng hơn và giá trị cao hơn liên quan, điều này có thể làm cho nó hơi thách thức hơn đối với một số người để giải quyết. Ngoài ra, thực tế là việc mua của Joseph kéo dài trong 12 tuần, trái ngược với 8 tuần của Hillary, thêm một lớp phức tạp.
Vậy, dựa trên thông tin đã cho, câu trả lời sẽ là: Bài toán 2.

Hình 15: Một ví dụ về việc sử dụng GPT-4 để tạo ra bài toán chỉ dựa trên các bài toán từ GSM8K và sau đó
đánh giá độ phức tạp của các bài toán mới được tạo ra. "Bài toán 2" là bài toán mới, và "Bài toán 1" là
bài toán từ GSM8K được sử dụng để tạo ra "Bài toán 2".

24

--- TRANG 25 ---
(a) Lời nhắc:
Hãy tạo ra một bài toán mới, theo "Ví dụ" đã cho và bài toán mới nên khó hơn "Ví dụ".
Ví dụ: "Peter có 15 con chim. 1/3 là vịt. Phần còn lại là gà và cần thức ăn đặc biệt có giá 2 đô la mỗi con. Chi phí cho việc cho gà ăn là bao nhiêu?"
(b) Bài toán mới được tạo ra bởi GPT-4:
Maria có 36 con vật. 1/4 trong số chúng là thỏ. Phần còn lại là mèo, và mỗi con mèo cần thức ăn đặc biệt có giá 3 đô la mỗi con mỗi ngày. Nếu Maria cho mèo ăn trong 5 ngày, cô ấy sẽ tiêu bao nhiêu tiền cho thức ăn mèo?
(c) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Peter có 15 con chim. 1/3 là vịt. Phần còn lại là gà và cần thức ăn đặc biệt có giá 2 đô la mỗi con. Chi phí cho việc cho gà ăn là bao nhiêu?"
Bài toán 2: "Maria có 36 con vật. 1/4 trong số chúng là thỏ. Phần còn lại là mèo, và mỗi con mèo cần thức ăn đặc biệt có giá 3 đô la mỗi con mỗi ngày. Nếu Maria cho mèo ăn trong 5 ngày, cô ấy sẽ tiêu bao nhiêu tiền cho thức ăn mèo?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(d) Phán đoán từ GPT-4:
Hãy phân tích các bước cần thiết để giải từng bài toán:
Bài toán 1:
1. Tính số vịt: 15×1/3= 5.
2. Trừ số vịt khỏi tổng để tìm số gà: 15−5 = 10.
3. Tính chi phí cho việc cho gà ăn: 10×2 đô la = 20 đô la.
Bài toán 2:
1. Tính số thỏ: 36×1/4= 9.
2. Trừ số thỏ khỏi tổng để tìm số mèo: 36−9 = 27.
3. Tính chi phí hàng ngày cho việc cho mèo ăn: 27×3 đô la = 81 đô la.
4. Nhân chi phí hàng ngày với 5 ngày: 5×81 đô la = 405 đô la.
Trong khi cả hai bài toán đều yêu cầu cách tiếp cận ban đầu tương tự là tìm số con vật không được nêu rõ ràng, Bài toán 2 có thêm bước nhân với số ngày để có chi phí cuối cùng.
Dựa trên số bước và tính toán cần thiết, Bài toán 2 hơi khó hơn Bài toán 1.

Hình 16: Một ví dụ về việc sử dụng GPT-4 để tạo ra bài toán chỉ dựa trên các bài toán từ GSM8K và sau đó
đánh giá độ phức tạp của các bài toán mới được tạo ra. "Bài toán 2" là bài toán mới, và "Bài toán 1" là
bài toán từ GSM8K được sử dụng để tạo ra "Bài toán 2".

25

--- TRANG 26 ---
(a) Lời nhắc:
Hãy tạo ra một bài toán mới, theo "Ví dụ" đã cho và bài toán mới nên khó hơn "Ví dụ".
Ví dụ: "Zain có thêm 10 đồng xu mỗi loại so với Emerie. Nếu Emerie có sáu đồng xu 25 xu, bảy đồng xu 10 xu, và
năm đồng xu 5 xu, Zain có bao nhiêu đồng xu?"
(b) Bài toán mới được tạo ra bởi GPT-4:
Xavier có thêm 15 đồng xu mỗi loại so với Elara. Nếu Elara có chín đồng xu 25 xu, mười một đồng xu 10 xu, tám đồng xu 5 xu, và ba đồng xu 1 xu, Xavier có bao nhiêu đồng xu?
(c) Lời nhắc đánh giá:
Bài toán nào khó hơn?
Bài toán 1: "Zain có thêm 10 đồng xu mỗi loại so với Emerie. Nếu Emerie có sáu đồng xu 25 xu, bảy đồng xu 10 xu, và
năm đồng xu 5 xu, Zain có bao nhiêu đồng xu?"
Bài toán 2: "Xavier có thêm 15 đồng xu mỗi loại so với Elara. Nếu Elara có chín đồng xu 25 xu, mười một đồng xu 10 xu, tám đồng xu 5 xu, và ba đồng xu 1 xu, Xavier có bao nhiêu đồng xu?"
Câu trả lời của bạn nên là một trong "Bài toán 1", "Bài toán 2" và "Hòa".
(d) Phán đoán từ GPT-4:
Hãy phân tích từng bài toán từng bước:
Bài toán 1:
Emerie có: 6 đồng xu 25 xu, 7 đồng xu 10 xu, 5 đồng xu 5 xu
Với mỗi loại đồng xu, Zain có thêm 10 đồng xu so với Emerie.
Vậy:
- Zain có 6 + 10 = 16 đồng xu 25 xu
- Zain có 7 + 10 = 17 đồng xu 10 xu
- Zain có 5 + 10 = 15 đồng xu 5 xu
Tổng số đồng xu Zain có = 16 + 17 + 15 = 48 đồng xu.
Bài toán 2:
Elara có: 9 đồng xu 25 xu, 11 đồng xu 10 xu, 8 đồng xu 5 xu, 3 đồng xu 1 xu
Với mỗi loại đồng xu, Xavier có thêm 15 đồng xu so với Elara.
Vậy:
- Xavier có 9 + 15 = 24 đồng xu 25 xu
- Xavier có 11 + 15 = 26 đồng xu 10 xu
- Xavier có 8 + 15 = 23 đồng xu 5 xu
- Xavier có 3 + 15 = 18 đồng xu 1 xu
Tổng số đồng xu Xavier có = 24 + 26 + 23 + 18 = 91 đồng xu.
Bây giờ, hãy đánh giá độ phức tạp:
Bài toán 1 có 3 loại đồng xu và chênh lệch 10 cho mỗi đồng xu.
Bài toán 2 có 4 loại đồng xu và chênh lệch 15 cho mỗi đồng xu.
Xem xét rằng "khó hơn" có thể có nghĩa là nhiều bước hơn hoặc phép toán hơn để giải, Bài toán 2 có nhiều loại đồng xu hơn và chênh lệch lớn hơn, vậy nó yêu cầu tính toán hơi nhiều hơn.
Trả lời: Bài toán 2 khó hơn.

Hình 17: Một ví dụ về việc sử dụng GPT-4 để tạo ra bài toán chỉ dựa trên các bài toán từ GSM8K và sau đó
đánh giá độ phức tạp của các bài toán mới được tạo ra. "Bài toán 2" là bài toán mới, và "Bài toán 1" là
bài toán từ GSM8K được sử dụng để tạo ra "Bài toán 2".

26

--- TRANG 27 ---
algebra
prealgebra
number
theory
counting and
probability
precalculus
intermediate
algebra
geometry 0.72 0.51 0.4 0.27 0.13
0.52 0.53 0.41 0.3 0.14
0.57 0.28 0.26 0.15 0.05
0.51 0.46 0.17 0.08 0.07
0.32 0.15 0.09 0.04 0
0.29 0.21 0.17 0.08 0.04
0.29 0.3 0.16 0.13 0.01MathCoder-L-7B
(Tổng thể: 0.233)
 0.76 0.61 0.49 0.37 0.21
0.69 0.64 0.49 0.38 0.22
0.67 0.43 0.32 0.29 0.17
0.59 0.5 0.19 0.15 0.05
0.4 0.21 0.12 0.1 0.03
0.35 0.3 0.18 0.13 0.09
0.29 0.35 0.27 0.1 0.01MathCoder-CL-7B
(Tổng thể: 0.3024)
algebra
prealgebra
number
theory
counting and
probability
precalculus
intermediate
algebra
geometry 0.77 0.63 0.5 0.4 0.21
0.59 0.56 0.5 0.42 0.19
0.77 0.41 0.34 0.2 0.16
0.67 0.48 0.24 0.14 0.06
0.42 0.21 0.13 0.09 0
0.4 0.25 0.18 0.14 0.06
0.37 0.39 0.2 0.17 0.02MathCoder-L-13B
(Tổng thể: 0.2992)
 0.83 0.67 0.57 0.45 0.29
0.73 0.69 0.52 0.45 0.24
0.77 0.49 0.42 0.32 0.21
0.74 0.58 0.22 0.16 0.18
0.44 0.34 0.23 0.15 0.04
0.44 0.38 0.24 0.17 0.1
0.24 0.48 0.25 0.18 0.05MathCoder-CL-13B
(Tổng thể: 0.3588)
algebra
prealgebra
number
theory
counting and
probability
precalculus
intermediate
algebra
geometry 0.9 0.77 0.75 0.6 0.41
0.77 0.81 0.68 0.53 0.34
0.87 0.49 0.64 0.46 0.26
0.77 0.58 0.43 0.38 0.2
0.46 0.46 0.35 0.18 0.01
0.62 0.38 0.31 0.2 0.13
0.39 0.49 0.42 0.23 0.08MathCoder-L-70B
(Tổng thể: 0.442)
 0.93 0.78 0.7 0.62 0.39
0.83 0.8 0.66 0.55 0.33
0.83 0.58 0.57 0.49 0.36
0.77 0.66 0.51 0.27 0.26
0.61 0.42 0.36 0.2 0.1
0.48 0.35 0.28 0.19 0.1
0.39 0.44 0.36 0.22 0.05MathCoder-CL-34B
(Tổng thể: 0.452)
L1 L2 L3 L4 L5algebra
prealgebra
number
theory
counting and
probability
precalculus
intermediate
algebra
geometry 0.92 0.76 0.73 0.62 0.37
0.81 0.79 0.68 0.57 0.38
0.8 0.64 0.61 0.46 0.31
0.74 0.62 0.49 0.31 0.22
0.6 0.48 0.28 0.17 0.07
0.58 0.45 0.32 0.22 0.11
0.5 0.5 0.44 0.2 0.07MathCode-CL-34B với hàm mất mát trên kết quả thực thi
(Tổng thể: 0.459)
L1 L2 L3 L4 L5 0.44 0.32 0.27 0.17 0.07
0.53 0.45 0.34 0.21 0.11
0.3 0.22 0.13 0.09 0.04
0.49 0.37 0.25 0.1 0.03
0.33 0.12 0.02 0.03 0.01
0.25 0.15 0.07 0.02 0.02
0.45 0.26 0.14 0.06 0.01MathCode-CL-34B không có thực thi mã
(Tổng thể: 0.169)
0.00.20.40.60.81.0Hình 18: So sánh hiệu suất của MathCoder-L (7B, 13B, 70B) và MathCoder-CL (7B, 13B, 34B)
trên bộ dữ liệu MATH theo cấp độ và môn học. Việc cải thiện độ chính xác từ MathCoder-L sang MathCoder-CL
chủ yếu đến từ các môn học yêu cầu tính toán chính xác như đại số, lý thuyết số, và đếm và xác suất.

27

--- TRANG 28 ---
Bài toán: MATH/test/number-theory/1191
<|user|><|text|> Nếu n là một số nguyên, 1≤n≤2010, có bao nhiêu phân số n2/2010 cho thập phân lặp lại? <|endofblock|><|endofmessage|>

(a) Lời giải CoT cho MATH/test/number-theory/1191
Để xác định xem một phân số a/b có tạo ra thập phân lặp lại hay không,
bạn cần nhìn vào mẫu số, b. Một phân số sẽ tạo ra thập phân lặp lại
nếu và chỉ nếu, sau khi rút gọn về dạng đơn giản nhất, mẫu số có
nhân tử nguyên tố khác 2 hoặc 5.

Hãy giải bài toán từng bước:
Bước 1: Phân tích nhân tử nguyên tố của 2010
2010 = 2 ×3×5×67

Bước 2: Tiêu chí thập phân lặp lại. Để n2/2010 là thập phân lặp lại,
mẫu số, sau khi rút gọn phân số về dạng đơn giản nhất, phải có
nhân tử nguyên tố khác 2 hoặc 5.

Bước 3: Đếm các giá trị có thể có của n. Để có mẫu số với nhân tử
nguyên tố khác 2 hoặc 5 trong dạng rút gọn, n không nên chia hết
cho 3, 67, hoặc bất kỳ bội số nào của chúng. Vậy, chúng ta có thể
tìm các giá trị có thể có của n như sau:
a) Có 2010/3 = 670 số là bội số của 3 giữa 1 và 2010.
b) Có 2010/67 = 30 số là bội số của 67 giữa 1 và 2010.
c) Có các số chồng lặp là bội số của 3×67 = 201. Có 2010/201 = 10 số như vậy.

Bước 4: Áp dụng nguyên lý bao hàm-loại trừ. Để tránh đếm các số
chồng lặp hai lần, chúng ta áp dụng nguyên lý bao hàm-loại trừ:
Số lượng = 670 + 30 −10 = 700 −10 = 690

Bước 5: Trừ khỏi tổng các giá trị có thể có của n. Có 2010 giá trị
có thể có cho n tổng cộng. Để tìm số lượng n cho thập phân lặp lại:
2010−690 = 1320

Vậy, có 1320✗ phân số n2/2010 cho thập phân lặp lại.

(b) Lời giải PoT cho MATH/test/number-theory/1191
from sympy.ntheory import factorint
# Phạm vi cho trước
n_range = range(1, 2011)
# Mẫu số cho trước
denominator = 2010
# Khởi tạo bộ đếm cho các phân số có thập phân lặp lại
repeating_decimal_count = 0
# Phân tích nhân tử mẫu số để tìm phân tích nhân tử nguyên tố
denominator_factors = factorint(denominator)
# Lặp qua phạm vi để tìm các phân số có thập phân lặp lại
for n in n_range:
    # Phân tích nhân tử tử số
    numerator_factors = factorint(n **2)
    # Kiểm tra xem mỗi nhân tử của mẫu số có mặt trong tử số
    # với ít nhất cùng lũy thừa không
    repeating_decimal = any(
        denominator_factors[p] >
        numerator_factors.get(p, 0) for p in
        denominator_factors)
    # Nếu phân số có thập phân lặp lại, tăng bộ đếm
    if repeating_decimal:
        repeating_decimal_count += 1
repeating_decimal_count
>>> 2009 ✗

(c) Lời giải LCE cho MATH/test/number-theory/1191
<|assistant|> <|text|> Được rồi, để một phân số cho thập phân lặp lại, mẫu số của nó (sau khi đơn giản hóa) nên chứa các nhân tử nguyên tố khác 2 và 5.

Vậy, để giải bài toán này, chúng ta cần làm theo các bước sau:
1. Phân tích nhân tử 2010 để có các nhân tử nguyên tố của nó.
2. Với mỗi số nguyên n từ 1 đến 2010, tính n2.
3. Chia n2 cho 2010 và đơn giản hóa phân số.
4. Kiểm tra xem mẫu số đã đơn giản hóa có nhân tử nguyên tố khác 2 và 5 không.

Nếu mẫu số sau khi đơn giản hóa chỉ có 2 và 5 làm nhân tử nguyên tố, thì nó sẽ cho thập phân hữu hạn. Ngược lại, nó sẽ cho thập phân lặp lại.

Hãy tiến hành với các bước này. <|endofblock|>
<|code|>
from math import gcd
# Bước 1: Phân tích nhân tử 2010 để có các nhân tử nguyên tố của nó.
def prime_factors(n):
    i = 2
    factors = {}
    while i * i <= n:
        if n % i:
            i += 1
        else:
            n //= i
            factors[i] = factors.get(i, 0) + 1
    if n > 1:
        factors[n] = factors.get(n, 0) + 1
    return factors

factors_2010 = prime_factors(2010)
# Bước 2, 3 và 4
count_repeating = 0
for n in range(1, 2011):
    n_square = n **2
    common_factor = gcd(n_square, 2010)
    denominator = 2010 // common_factor
    # Kiểm tra xem mẫu số đã đơn giản hóa có nhân tử nguyên tố khác 2 và 5 không
    factors_denominator = prime_factors(denominator)
    if 2 in factors_denominator:
        del factors_denominator[2]
    if 5 in factors_denominator:
        del factors_denominator[5]
    if factors_denominator: # nếu còn lại các nhân tử nguyên tố khác
        count_repeating += 1
count_repeating
<|endofblock|>
<|execution|> 2000 <|endofblock|>
<|text|> Có 2000✓ phân số dạng n2/2010 cho thập phân lặp lại khi 1≤n≤2010.
<|endofblock|><|endofmessage|>

Hình 19: Ví dụ về lời giải CoT, PoT và LCE với token đặc biệt. Bài toán từ tập kiểm tra của MATH trong lý thuyết số với id 1191. Trái ngược với CoT, chỉ bao gồm ngôn ngữ tự nhiên, và PoT, chỉ bao gồm mã, lời giải LCE của chúng tôi xen kẽ ngôn ngữ tự nhiên, mã và kết quả thực thi.

28

--- TRANG 29 ---
Bài toán: MATH/test/algebra/2477
<|user|><|text|> Xét dãy số học vô hạn A với số hạng đầu 5 và công sai −2. Bây giờ định nghĩa dãy vô hạn B sao cho
số hạng thứ k của B là 2 lũy thừa số hạng thứ k của A. Tìm tổng của tất cả các số hạng của B. <|endofblock|><|endofmessage|>

(a) Lời giải CoT cho MATH/test/algebra/2477
Được rồi. Hãy bắt đầu bằng cách hiểu cả hai dãy từng bước.
Dãy A
Đây là một dãy số học vô hạn. Số hạng đầu tiên, a1, là 5, và công sai, d, là -2.
Vậy, chúng ta có thể mô tả số hạng thứ k của A như:
ak= 5−2(k−1)
ak= 5−2k+ 2
ak= 7−2k
Dãy B
Dãy B được định nghĩa sao cho số hạng thứ k của B là 2 lũy thừa số hạng thứ k của A:
bk= 2ak= 27−2k
Tổng của dãy B
Vì B là một dãy vô hạn, chúng ta phải tìm tổng của tất cả các số hạng của B:
SB= 27+ 25+ 23+ 21+···
Để tìm SB, chú ý rằng đây là một chuỗi hình học với số hạng đầu 27
và tỷ số công bội 2−2=1/4.
Tổng của một chuỗi hình học vô hạn có thể được tìm bằng công thức:
S=a/(1−r)
trong đó a là số hạng đầu và r là tỷ số công bội.
Thay số hạng đầu 27 và tỷ số công bội 1/4 vào công thức:
SB=27/(1−1/4)=27/(3/4)=27·4/3
1=29/3
Vậy, tổng của tất cả các số hạng của dãy B là 29/3.✗

(b) Lời giải PoT cho MATH/test/algebra/2477
# Số hạng đầu và công sai cho trước của dãy A
first_term_A = 5
common_diff_A = -2
# Khởi tạo tổng của dãy B
sum_B = 0
# Lặp qua các số hạng của dãy A và tính toán các số hạng tương ứng của dãy B,
# cho đến khi số hạng của dãy A không dương.
kth_term_A = first_term_A
while kth_term_A > 0:
    kth_term_B = 2 **kth_term_A
    sum_B += kth_term_B
    kth_term_A += common_diff_A
sum_B
>>> 42 ✗

(c) Lời giải LCE cho MATH/test/algebra/2477
<|assistant|> <|text|> Chắc chắn. Hãy giải bài toán từng bước.
Bước 1: Định nghĩa dãy A. Cho rằng số hạng đầu của dãy A là 5 và công sai là -2, số hạng thứ k của A, ký hiệu là Ak, có thể được tìm bằng công thức:
Ak= 5−2(k−1)
Ak= 7−2k
Bước 2: Định nghĩa dãy B. Số hạng thứ k của dãy B, ký hiệu là Bk, được định nghĩa là 2 lũy thừa số hạng thứ k của A:
Bk= 2Ak
Thay giá trị của Ak vào phương trình cho Bk:
Bk= 27−2k
Bước 3: Tìm tổng của dãy B. Để tìm tổng của tất cả các số hạng của dãy B, chúng ta cần tìm tổng đến vô cực của dãy này.
Vì các số hạng của dãy B ngày càng nhỏ (bởi vì 27−2k giảm khi k tăng), đây là một chuỗi hình học.
Tổng của một chuỗi hình học vô hạn có thể được tìm bằng công thức:
S=a/(1−r)
Trong đó:
-S là tổng của chuỗi,
-a là số hạng đầu của chuỗi,
-r là tỷ số công bội của chuỗi.
Hãy tìm số hạng đầu và tỷ số công bội của dãy B và sau đó sử dụng chúng để tìm tổng của dãy B.
<|endofblock|>
<|code|>
# Các giá trị cho trước
first_term_A = 5
common_difference_A = -2
base_B = 2
# Tính toán số hạng đầu của dãy B
first_term_B = base_B **first_term_A
# Tính toán tỷ số công bội của dãy B
# Với k=1, A_k = 5, B_1 = 2^5
# Với k=2, A_k = 3, B_2 = 2^3 => B_2 = B_1 / 2^2
common_ratio_B = base_B **(-2 *1) # k=1, nên 2*1=2
# Tính toán tổng của dãy B
sum_B = first_term_B / (1 - common_ratio_B)
first_term_B, common_ratio_B, sum_B
<|endofblock|>
<|execution|> (32, 0.25, 42.666666666666667) <|endofblock|>
<|text|>
Bước 3: Kết quả Vậy, tổng của tất cả các số hạng của dãy B là khoảng 42.67.✓<|endofblock|><|endofmessage|>

Hình 20: Ví dụ về lời giải CoT, PoT và LCE với token đặc biệt. Bài toán từ tập kiểm tra của MATH trong đại số với id 2477. Trái ngược với CoT, chỉ bao gồm ngôn ngữ tự nhiên, và PoT, chỉ bao gồm mã, lời giải LCE của chúng tôi xen kẽ ngôn ngữ tự nhiên, mã và kết quả thực thi.

29

--- TRANG 30 ---
Bài toán: MATH/test/geometry/500
<|user|><|text|> Các điểm A(0,0), B(9,6) và C(6,12) là các đỉnh của tam giác ABC. Điểm D nằm trên đoạn AB sao cho 2(AD) = DB,
điểm E nằm trên đoạn BC sao cho 2(BE) = EC và điểm F nằm trên đoạn CA sao cho 2(CF) = FA. Tỷ số diện tích của
tam giác DEF với diện tích của tam giác ABC là bao nhiêu? Biểu diễn câu trả lời của bạn dưới dạng phân số tối giản. <|endofblock|><|endofmessage|>

Lời giải CoT cho MATH/test/geometry/500
Để tìm tọa độ của các điểm D, E, và F, chúng ta có thể sử dụng công thức chia đoạn. Công thức chia đoạn phát biểu rằng nếu một đường thẳng chia hai điểm P(x1, y1) và Q(x2, y2) theo tỷ lệ m:n, thì tọa độ (x, y) của điểm chia đoạn thẳng được cho bởi:
x = (mx2 + nx1)/(m + n)
y = (my2 + ny1)/(m + n)

Tìm tọa độ của D
D chia AB theo tỷ lệ 2 : 1. Ở đây, A(0,0) và B(9,6). Vậy,
xD = (2·9 + 1·0)/(2 + 1) = 6
yD = (2·6 + 1·0)/(2 + 1) = 4
Vậy, D(6,4).

Tìm tọa độ của E
E chia BC theo tỷ lệ 2 : 1. Ở đây, B(9,6) và C(6,12). Vậy,
xE = (2·6 + 1·9)/(2 + 1) = 7
yE = (2·12 + 1·6)/(2 + 1) = 10
Vậy, E(7,10).

Tìm tọa độ của F
F chia CA theo tỷ lệ 2 : 1. Ở đây, C(6,12) và A(0,0). Vậy,
xF = (2·0 + 1·6)/(2 + 1) = 2
yF = (2·0 + 1·12)/(2 + 1) = 4
Vậy, F(2,4).

Tìm tỷ số diện tích của △DEF với △ABC. Diện tích của tam giác được tạo bởi ba đỉnh P(x1, y1), Q(x2, y2), và R(x3, y3) được cho bởi:
Diện tích = (1/2)|x1(y2 − y3) + x2(y3 − y1) + x3(y1 − y2)|

1. Diện tích của △ABC:
Diện tích ABC = (1/2)|0·(6 − 12) + 9·(12 − 0) + 6·(0 − 6)|
Diện tích ABC = (1/2)|0 + 108 + 36|
Diện tích ABC = 72 đơn vị vuông

2. Diện tích của △DEF:
Diện tích DEF = (1/2)|6·(10 − 4) + 7·(4 − 4) + 2·(4 − 10)|
Diện tích DEF = (1/2)|36 + 0 − 12|
Diện tích DEF = 12 đơn vị vuông

Tìm tỷ số
Tỷ số = Diện tích DEF / Diện tích ABC
Tỷ số = 12/72 = 1/6

Vậy, tỷ số diện tích của tam giác DEF với diện tích của tam giác ABC là 1/6.✗

Hình 21: Ví dụ về lời giải CoT. Bài toán từ tập kiểm tra của MATH trong hình học với id 500.

30

--- TRANG 31 ---
Bài toán: MATH/test/geometry/500
<|user|><|text|> Các điểm A(0,0), B(9,6) và C(6,12) là các đỉnh của tam giác ABC. Điểm D nằm trên đoạn AB sao cho 2(AD) = DB,
điểm E nằm trên đoạn BC sao cho 2(BE) = EC và điểm F nằm trên đoạn CA sao cho 2(CF) = FA. Tỷ số diện tích của
tam giác DEF với diện tích của tam giác ABC là bao nhiêu? Biểu diễn câu trả lời của bạn dưới dạng phân số tối giản. <|endofblock|><|endofmessage|>

Lời giải PoT cho MATH/test/geometry/500
from sympy import symbols, solve, Point, Polygon, Rational
# Các điểm cho trước của tam giác ABC
A = Point(0, 0)
B = Point(9, 6)
C = Point(6, 12)
# Cho rằng D nằm trên đoạn AB sao cho 2(AD) = DB
# Do đó, AD:DB = 1:2
# Sử dụng công thức chia đoạn để tìm tọa độ của D
m1, m2 = 2, 1
D = Point((m1 *B.x + m2 *A.x)/(m1+m2), (m1 *B.y + m2 *A.y)/(m1+m2))
# Cho rằng E nằm trên đoạn BC sao cho 2(BE) = EC
# Do đó, BE:EC = 1:2
# Sử dụng công thức chia đoạn để tìm tọa độ của E
m1, m2 = 1, 2
E = Point((m1 *C.x + m2 *B.x)/(m1+m2), (m1 *C.y + m2 *B.y)/(m1+m2))
# Cho rằng F nằm trên đoạn CA sao cho 2(CF) = FA
# Do đó, CF:FA = 1:2
# Sử dụng công thức chia đoạn để tìm tọa độ của F
m1, m2 = 1, 2
F = Point((m1 *A.x + m2 *C.x)/(m1+m2), (m1 *A.y + m2 *C.y)/(m1+m2))
# Tính diện tích của các tam giác ABC và DEF
triangle_ABC = Polygon(A, B, C)
triangle_DEF = Polygon(D, E, F)
area_ABC = abs(triangle_ABC.area)
area_DEF = abs(triangle_DEF.area)
# Tìm tỷ số diện tích của tam giác DEF với tam giác ABC
ratio = Rational(area_DEF, area_ABC)
ratio
>>> 2/9 ✗

Hình 22: Ví dụ về lời giải PoT. Bài toán từ tập kiểm tra của MATH trong hình học với id 500.

31

--- TRANG 32 ---
Bài toán: MATH/test/geometry/500
<|user|><|text|> Các điểm A(0,0), B(9,6) và C(6,12) là các đỉnh của tam giác ABC. Điểm D nằm trên đoạn AB sao cho 2(AD) = DB,
điểm E nằm trên đoạn BC sao cho 2(BE) = EC và điểm F nằm trên đoạn CA sao cho 2(CF) = FA. Tỷ số diện tích của
tam giác DEF với diện tích của tam giác ABC là bao nhiêu? Biểu diễn câu trả lời của bạn dưới dạng phân số tối giản. <|endofblock|><|endofmessage|>

Lời giải LCE cho MATH/test/geometry/500
<|assistant|> <|text|> Hãy giải bài toán từng bước:
1. Tìm các điểm D, E, F:
- Sử dụng công thức chia đoạn để tìm tọa độ của các điểm D, E, và F.
- Công thức chia đoạn là:
(x, y) = (m·x2 + n·x1)/(m + n), (m·y2 + n·y1)/(m + n)
- Với điểm D, m = 2, n = 1, x1 = 0, y1 = 0, x2 = 9, và y2 = 6.
- Với điểm E, m = 2, n = 1, x1 = 9, y1 = 6, x2 = 6, và y2 = 12.
- Với điểm F, m = 2, n = 1, x1 = 6, y1 = 12, x2 = 0, và y2 = 0.
2. Tìm diện tích của các tam giác ABC và DEF:
- Diện tích của tam giác có các đỉnh (x1, y1), (x2, y2), và (x3, y3) được cho bởi:
Diện tích = |x1(y2 − y3) + x2(y3 − y1) + x3(y1 − y2)|/2
3. Tìm tỷ số diện tích:
- Tỷ số diện tích của tam giác DEF và ABC được cho bởi:
Tỷ số = Diện tích DEF / Diện tích ABC
Hãy bắt đầu bằng cách tìm tọa độ của các điểm D, E, và F bằng công thức chia đoạn. <|endofblock|>
<|code|>
# Các điểm và tỷ lệ cho trước
A = (0, 0)
B = (9, 6)
C = (6, 12)
m1, n1 = 2, 1 # tỷ lệ cho điểm D
m2, n2 = 2, 1 # tỷ lệ cho điểm E
m3, n3 = 2, 1 # tỷ lệ cho điểm F
# Sử dụng công thức chia đoạn để tìm tọa độ của D, E, F
D = ((m1 *B[0] + n1 *A[0]) / (m1 + n1), (m1 *B[1] + n1 *A[1]) / (m1 + n1))
E = ((m2 *C[0] + n2 *B[0]) / (m2 + n2), (m2 *C[1] + n2 *B[1]) / (m2 + n2))
F = ((m3 *A[0] + n3 *C[0]) / (m3 + n3), (m3 *A[1] + n3 *C[1]) / (m3 + n3))
D, E, F
<|endofblock|>
<|execution|> ((6.0, 4.0), (7.0, 10.0), (2.0, 4.0)) <|endofblock|>
<|text|> Tọa độ của các điểm như sau:
- Điểm D nằm tại (6,4)
- Điểm E nằm tại (7,10)
- Điểm F nằm tại (2,4)
Bây giờ, hãy tiếp tục tìm diện tích của tam giác ABC và DEF bằng công thức diện tích tam giác, và sau đó tìm tỷ số của các diện tích này.
<|endofblock|>
<|code|>
# Hàm để tìm diện tích tam giác cho các đỉnh của nó
def triangle_area(v1, v2, v3):
    return 0.5 *abs(v1[0] *(v2[1] - v3[1]) + v2[0] *(v3[1] - v1[1]) + v3[0] *(v1[1] - v2[1]))
# Diện tích của tam giác ABC và DEF
area_ABC = triangle_area(A, B, C)
area_DEF = triangle_area(D, E, F)
# Tỷ số diện tích
ratio_areas = area_DEF / area_ABC
area_ABC, area_DEF, ratio_areas
<|endofblock|>
<|execution|> (36.0, 12.0, 0.3333333333333333) <|endofblock|>
<|text|> Vậy, tỷ số diện tích của tam giác DEF với diện tích của tam giác ABC là 1/3✓ hay 0.3333. <|endofblock|><|endofmessage|>

Hình 23: Ví dụ về lời giải LCE với token đặc biệt. Bài toán từ tập kiểm tra của MATH trong hình học với id 500. Trái ngược với CoT, chỉ bao gồm ngôn ngữ tự nhiên, và PoT, chỉ bao gồm mã, lời giải LCE của chúng tôi xen kẽ ngôn ngữ tự nhiên, mã và kết quả thực thi.

32

# 2309.12284.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2309.12284.pdf
# Kích thước tệp: 738674 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
METAMATH: TỰ TẠO CÁC CÂU HỎI TOÁN HỌC
CHO CÁC MÔ HÌNH NGÔN NGỮ LỚN
Longhui Yu1,⋆Weisen Jiang2,3,⋆Han Shi4,†Jincheng Yu3,4Zhengying Liu4
Yu Zhang2James T. Kwok3Zhenguo Li4Adrian Weller1,5Weiyang Liu1,6,†
1Đại học Cambridge2Đại học Khoa học và Công nghệ Miền Nam
3Đại học Khoa học và Công nghệ Hồng Kông4Phòng thí nghiệm Noah's Ark Huawei
5Viện Alan Turing6Viện Max Planck về Hệ thống Thông minh - Tübingen
yulonghui@stu.pku.edu.cn ,wjiangar@cse.ust.hk ,shi.han@huawei.com ,wl396@cam.ac.uk
Trang dự án: meta-math.github.io
TÓM TẮT
Các mô hình ngôn ngữ lớn (LLMs) đã đẩy giới hạn của hiểu biết ngôn ngữ tự nhiên và thể hiện khả năng giải quyết vấn đề xuất sắc. Mặc dù có thành công lớn, hầu hết các LLMs mã nguồn mở hiện tại (ví dụ: LLaMA-2) vẫn còn xa mới đạt được kết quả thỏa mãn trong việc giải quyết các bài toán do các quy trình lý luận phức tạp. Để thu hẹp khoảng cách này, chúng tôi đề xuất MetaMath, một mô hình ngôn ngữ được tinh chỉnh chuyên về lý luận toán học. Cụ thể, chúng tôi bắt đầu bằng việc tự tạo các câu hỏi toán học bằng cách viết lại câu hỏi từ nhiều góc độ khác nhau, tạo ra một bộ dữ liệu mới có tên MetaMathQA. Sau đó chúng tôi tinh chỉnh các mô hình LLaMA-2 trên MetaMathQA. Kết quả thực nghiệm trên hai điểm chuẩn phổ biến (tức là GSM8K và MATH) cho lý luận toán học cho thấy MetaMath vượt trội hơn một loạt các LLMs mã nguồn mở với một khoảng cách đáng kể. Mô hình MetaMath-7B của chúng tôi đạt 66.5% trên GSM8K và 19.8% trên MATH, vượt qua các mô hình tiên tiến nhất cùng kích thước lần lượt 11.5% và 8.7%. Đặc biệt, MetaMath-70B đạt độ chính xác 82.3% trên GSM8K, tốt hơn một chút so với GPT-3.5-Turbo. Chúng tôi công bố bộ dữ liệu MetaMathQA, các mô hình MetaMath với kích thước mô hình khác nhau và mã huấn luyện để sử dụng công cộng.

Câu hỏi Meta: James mua 5 gói thịt bò, mỗi gói 4 pounds. Giá thịt bò là $5.50 mỗi pound. Anh ấy đã trả bao nhiều tiền?

Câu trả lời MetaMathQA: Anh ấy đã mua 5*4=20 pounds thịt bò. Vì vậy anh ấy đã trả 20*5.5=$110. Đáp án là: 110

Câu hỏi Tự kiểm tra: James mua x gói thịt bò, mỗi gói 4 pounds. Giá thịt bò là $5.50 mỗi pound. Anh ấy đã trả 110. Giá trị của biến chưa biết x là bao nhiều? Câu trả lời: ……

Câu hỏi Diễn đạt lại: Tổng số tiền mà James đã trả là bao nhiều khi anh ấy mua 5 gói thịt bò, mỗi gói nặng 4 pounds, với giá $5.50 mỗi pound? Câu trả lời: ……

Câu hỏi FOBAR: James mua x gói thịt bò, mỗi gói 4 pounds. Giá thịt bò là $5.50 mỗi pound. Anh ấy đã trả bao nhiều tiền? Nếu chúng ta biết câu trả lời cho câu hỏi trên là 110, giá trị của biến chưa biết x là bao nhiều? Câu trả lời: ……

Tăng cường Câu trả lời: James mua 5 gói thịt bò, mỗi gói 4 pounds, vì vậy anh ấy mua tổng cộng 5*4=20 pounds thịt bò. Giá thịt bò là $5.50 mỗi pound, vì vậy anh ấy trả 20*$5.50=$110. Đáp án là: 110

Tự tạo Câu hỏi → Tinh chỉnh MetaMath → LLaMA-2 → Dữ liệu Gốc

Hình 1: Tổng quan về bộ dữ liệu MetaMathQA và LLM giải quyết bài toán toán học – MetaMath. Chúng tôi lưu ý rằng MetaMath-70B của chúng tôi được tinh chỉnh bằng QLoRA do hạn chế về tài nguyên tính toán.

⋆Đóng góp ngang bằng †Tác giả liên hệ

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

1 GIỚI THIỆU
Những năm gần đây đã chứng kiến sự phát triển nhanh chóng của các mô hình ngôn ngữ lớn (LLMs) xuất hiện như phương pháp được ưa chuộng cho các ứng dụng khác nhau và thể hiện khả năng đa chiều, bao gồm tuân theo chỉ dẫn, hỗ trợ lập trình, và giải quyết bài toán toán học. Trong số các nhiệm vụ khác nhau, giải quyết bài toán toán học thách thức hơn vì chúng thường yêu cầu khả năng lý luận đa bước phức tạp và có tính biểu tượng cao. Mặc dù một số mô hình mã nguồn đóng, ví dụ: GPT-3.5-Turbo, GPT-4 và PaLM-2, đã thể hiện hiệu suất đầy hứa hẹn trên một số điểm chuẩn giải quyết bài toán toán học, vẫn là một bí ẩn về cách các mô hình này được huấn luyện và dữ liệu nào các mô hình này sử dụng. Do đó, làm thế nào để trang bị cho các LLMs mã nguồn mở (ví dụ: LLaMA) với kỹ năng giải quyết bài toán toán học tốt vẫn là một thách thức mở.

Để giải quyết thách thức này, hai hướng nghiên cứu phổ biến để cải thiện khả năng giải quyết bài toán toán học của LLMs là: phương pháp dựa trên prompt và phương pháp dựa trên tinh chỉnh. Phương pháp dựa trên prompt nhằm kích hoạt khả năng tiềm năng của LLMs bằng cách chọn đầu vào prompting phù hợp mà không thay đổi các tham số mô hình. Phương pháp dựa trên tinh chỉnh cập nhật các LLMs mã nguồn mở (ví dụ: LLaMA) dưới sự hướng dẫn của một số LLMs mã nguồn đóng mạnh mẽ khác (ví dụ: GPT-3.5, GPT-4). Trong khi các phương pháp dựa trên prompt phụ thuộc vào mô hình và nhạy cảm với nhiều yếu tố, các phương pháp dựa trên tinh chỉnh, mặc dù đơn giản và không phụ thuộc vào mô hình, phụ thuộc rất nhiều vào dữ liệu huấn luyện hiệu quả trên các câu hỏi toán học downstream. Công việc của chúng tôi nhằm cải thiện các phương pháp dựa trên tinh chỉnh với một phương pháp mới để tự tạo các câu hỏi toán học có sẵn trong tập huấn luyện. Cụ thể, chúng tôi đề xuất tự tạo các câu hỏi theo cả hai hướng lý luận tiến và lùi. Đối với hướng tiến, chúng tôi có các câu hỏi gốc và được LLM diễn đạt lại. Đối với hướng lùi, chúng tôi có câu hỏi tự kiểm tra và câu hỏi FOBAR.

Để xây dựng các câu hỏi lý luận ngược, chúng tôi che một token trong câu hỏi bằng cách sử dụng một định danh "x" và yêu cầu mô hình dự đoán token bị che nếu câu trả lời được cung cấp. Khác với việc áp dụng lý luận ngược để kiểm tra suy luận, chúng tôi sử dụng nó như một dạng câu hỏi cho việc tinh chỉnh mô hình ngôn ngữ. Đối với câu trả lời, chúng tôi áp dụng một phương pháp tăng cường câu trả lời dựa trên lấy mẫu từ chối, nơi các đường dẫn lý luận đa dạng được tạo ra và chỉ những đường dẫn có câu trả lời đúng mới được sử dụng. Sau khi kết hợp cả câu hỏi toán học tiến và lùi với câu trả lời được tăng cường, chúng tôi xây dựng một bộ dữ liệu mới để tinh chỉnh, gọi là MetaMathQA. Bằng cách tinh chỉnh LLaMA-2 trên MetaMathQA, chúng tôi có được mô hình MetaMath của mình. Phương pháp của chúng tôi được hướng dẫn bởi nhận thức rằng một câu hỏi toán học chỉ đại diện cho một góc nhìn duy nhất của kiến thức meta cơ bản. Do đó, tự tạo câu hỏi có thể được xem như một dạng tăng cường đa góc nhìn để cho phép chuyển giao kiến thức meta. Tận dụng bộ dữ liệu MetaMathQA, MetaMath thể hiện hiệu suất đặc biệt trong lý luận toán học, định vị nó trong số những người thể hiện hàng đầu trên các điểm chuẩn đánh giá được công nhận rộng rãi.

Một động lực khác đằng sau việc tự tạo câu hỏi là để mở rộng sự đa dạng của câu hỏi sao cho phân phối câu hỏi có thể đủ phong phú để bao phủ nhiều tình huống chưa thấy hơn. Chúng tôi định lượng sự đa dạng câu hỏi của các câu hỏi gốc và bộ dữ liệu MetaMathQA của chúng tôi trong Hình 2. Mức tăng đa dạng cho biết câu hỏi đa dạng như thế nào so với bộ dữ liệu hiện có, và mức tăng đa dạng lớn hơn có nghĩa là câu hỏi mới khác biệt hơn so với bộ dữ liệu hiện có. Với việc tự tạo câu hỏi, bộ dữ liệu MetaMathQA của chúng tôi đa dạng hơn nhiều so với bộ dữ liệu gốc. Chúng tôi cũng quan sát thấy rằng độ chính xác kiểm tra mà không có các câu hỏi được tự tạo nhanh chóng đạt trạng thái bão hòa. Ngược lại, độ chính xác kiểm tra khi sử dụng các câu hỏi được tự tạo tiếp tục thể hiện sự tăng ổn định.

Tự tạo câu hỏi cũng có mối liên hệ nội tại với chưng cất bộ dữ liệu và machine teaching, nơi mục tiêu chung là xây dựng một bộ dữ liệu huấn luyện tốt nhất hỗ trợ khái quát hóa. Khác với cả hai phương pháp tập trung vào tối ưu hóa rủi ro thực nghiệm huấn luyện, việc tự tạo câu hỏi sử dụng sự đa dạng lý luận của câu hỏi như một proxy heuristic và tối đa hóa sự đa dạng này bằng cách xây dựng các câu hỏi tiến, lùi và diễn đạt lại. MetaMath nhằm chuyển giao kiến thức meta cơ bản để cho phép khái quát hóa mạnh mẽ. Các đóng góp của chúng tôi được liệt kê bên dưới:

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

• Chúng tôi đề xuất một phương pháp tự tạo câu hỏi mới để tăng cường bộ dữ liệu huấn luyện, tạo ra MetaMathQA. Tự tạo câu hỏi viết lại câu hỏi với cả đường dẫn lý luận tiến và lùi và cũng tận dụng LLMs để diễn đạt lại văn bản câu hỏi.

• Dựa trên bộ dữ liệu MetaMathQA, MetaMath được tinh chỉnh từ các LLMs mã nguồn mở tiên tiến (ví dụ: LLaMA-2), thể hiện khả năng giải quyết bài toán toán học cơ bản xuất sắc.

• Chúng tôi xác định một yếu tố quan trọng khi tạo bộ dữ liệu MetaMathQA – sự đa dạng câu hỏi. Sự đa dạng đặc biệt quan trọng trong các hướng lý luận, và các câu hỏi lý luận ngược rất hữu ích cho LLMs để hiểu kiến thức toán học mà không cần ghi nhớ.

• Chúng tôi thực hiện thí nghiệm trên hai điểm chuẩn lý luận toán học tiêu chuẩn: GSM8K và MATH. MetaMath vượt trội hơn các LLMs mã nguồn mở hiện có với một khoảng cách lớn. MetaMath-7B đã đạt 66.5% trên GSM8K (+11.5% so với LLM mã nguồn mở tốt nhất trước đó) trên GSM8K và 19.8% trên MATH (+8.7% so với LLM mã nguồn mở tốt nhất trước đó).

• Công việc của chúng tôi nghiên cứu tăng cường dữ liệu để cải thiện khả năng giải quyết bài toán toán học của LLMs. Mặc dù đơn giản, phương pháp của chúng tôi vượt trội đáng kể so với nhiều phương pháp phức tạp. Kết quả của chúng tôi nhấn mạnh tầm quan trọng của tăng cường dữ liệu và cũng làm sáng tỏ các nhiệm vụ lý luận khác.

2 CÔNG TRÌNH LIÊN QUAN
Các Mô hình Ngôn ngữ Lớn (LLMs) đã đạt được thành công lớn trong các nhiệm vụ xử lý ngôn ngữ tự nhiên khác nhau, ví dụ: phân loại chủ đề, phân loại cảm xúc, dịch thuật, bằng few-shot prompting (hoặc in-context learning). Gần đây, Wang et al., Wei et al. cho thấy rằng LLMs với hơn 100B tham số (ví dụ: GPT-3 với 175B, PaLM với 540B) có thể giải quyết các nhiệm vụ phức tạp bằng cách tạo ra nhiều bước lý luận hướng tới câu trả lời khi được đưa một vài ví dụ lý luận làm minh họa. Trong khi cả GPT-3.5 và GPT-4 đều đã thể hiện khả năng lý luận đầy hứa hẹn cho các nhiệm vụ toán học phức tạp như MATH, hiệu suất của các mô hình mã nguồn mở (ví dụ: LLaMA-1, LLaMA-2) vẫn còn xa mới thỏa mãn.

Học Lý luận Toán học cho các nhiệm vụ toán phức tạp như GSM8K và MATH là một trong những vấn đề thách thức nhất trong các LLMs mã nguồn mở. Wei et al. tăng cường khả năng lý luận của LLMs bằng cách tăng cường đầu ra với một chuỗi các bước trung gian hướng tới câu trả lời. Một số phương pháp được đề xuất để cải thiện chất lượng của các đường dẫn lý luận. Ví dụ, Complexity-based CoT chọn các ví dụ với nhiều bước hơn làm minh họa in-context và cho thấy rằng prompting với nhiều bước lý luận hơn dẫn đến hiệu suất tốt hơn. Self-Consistency lấy mẫu nhiều đường dẫn lý luận và chọn câu trả lời cuối cùng bằng bỏ phiếu đa số. Một danh mục công trình khác là các phương pháp dựa trên tinh chỉnh, tinh chỉnh các mô hình mã nguồn mở (ví dụ: LLaMA) với kiến thức từ một số LLMs mã nguồn đóng tiên tiến. Magister et al. điều tra việc chuyển giao khả năng lý luận qua chưng cất kiến thức. Yuan et al. đề xuất áp dụng tinh chỉnh lấy mẫu từ chối (RFT) để cải thiện hiệu suất lý luận toán học. WizardMath đề xuất một phương pháp reinforced evol-instruct để tăng cường khả năng lý luận bằng tinh chỉnh có giám sát và huấn luyện PPO. MAmmoTH kết hợp các lý do CoT và Program-of-Thought để dạy LLMs sử dụng các công cụ bên ngoài (ví dụ: Python interpreter) để giải quyết bài toán toán học. Wang et al. đề xuất một hàm mất mát constraint alignment để tinh chỉnh LLMs cho hiệu chuẩn.

Chưng cất Kiến thức chuyển giao kiến thức từ một mô hình giáo viên lớn hơn sang một mô hình học sinh nhỏ hơn, đạt được hiệu suất đầy hứa hẹn trong nhiều ứng dụng. Gần đây, đề xuất chuyển giao khả năng lý luận từ LLMs (ví dụ: GPT-3.5, PaLM) sang các mô hình ngôn ngữ nhỏ (ví dụ: T5, GPT-2). Ví dụ, Finetune-CoT lấy mẫu nhiều đường dẫn lý luận từ LLMs và tinh chỉnh mô hình học sinh với những đường dẫn đúng, trong khi Self-Improve chọn đường dẫn có độ tin cậy cao nhất. Li et al. tiến xa hơn bằng cách đưa câu hỏi và nhãn thực tế vào LLMs để prompting đường dẫn lý luận của nó. Shridhar et al. đề xuất tạo ra các cặp câu hỏi con và giải pháp để huấn luyện. Các mô hình nhỏ được tinh chỉnh bằng chưng cất kiến thức có thể đạt hiệu suất tương tự như LLMs trên cả lý luận thông thường (ví dụ: CommonSenseQA) và lý luận ký hiệu (ví dụ: Coin Flip). Tuy nhiên, để giải quyết các bài toán toán học thách thức (ví dụ: GSM8K), vẫn có một khoảng cách hiệu suất lớn.

3 PHƯƠNG PHÁP
Tổng quan về phương pháp của chúng tôi được minh họa trong Hình 1. Cho một câu hỏi meta (một mẫu trong tập huấn luyện toán học gốc), chúng tôi có thể tạo ra một loạt các biến thể. Cụ thể, chúng tôi thực hiện ba loại tự tạo câu hỏi. Kết hợp với tăng cường câu trả lời, chúng tôi trình bày MetaMathQA, một bộ dữ liệu toán học đa dạng và chất lượng cao dựa trên GSM8K và MATH. Sau đó chúng tôi trình bày MetaMath, một họ LLMs được tinh chỉnh trên MetaMathQA tập trung vào giải quyết bài toán toán học cơ bản.

3.1 TĂNG CƯỜNG CÂU TRẢ LỜI (ANSAUG)
Tạo ra nhiều đường dẫn lý luận hơn là một cách đơn giản nhưng hiệu quả để tăng cường tập huấn luyện. Đối với một câu hỏi qi, chúng tôi sử dụng few-shot chain-of-thought prompting với temperature sampling để tạo ra KAnsAug đường dẫn lý luận khác nhau {(r(j)i, a(j)i) : j = 1, ..., KAnsAug}: câu hỏi được nối thêm vào một vài ví dụ lý luận in-context, sau đó đưa vào LLM để tạo ra đường dẫn lý luận r(j)i và câu trả lời a(j)i. Chúng tôi lọc ra các đường dẫn lý luận có câu trả lời đúng như sau:
DAnsAug = {(qi, r(j)i, a(j)i) : a(j)i = a⋆i; i = 1, ..., Nq; j = 1, ..., KAnsAug}. (1)

3.2 TỰ TẠO CÂU HỎI BẰNG DIỄN ĐẠT LẠI LLM
Tạo thêm câu trả lời cho các câu hỏi toán học với LLMs là đơn giản, nhưng tạo câu hỏi thì thách thức hơn. Các câu hỏi Toán được viết bởi các giáo viên có trình độ tốt. Do đó, mở rộng tập câu hỏi thông qua tạo tay công tốn thời gian và nhân công. Để giải quyết vấn đề này, chúng tôi đề xuất rephrasing prompting để tạo ra nhiều câu hỏi hơn thông qua LLM.

Ví dụ 3.1: Câu hỏi Diễn đạt lại
Câu hỏi: Tổng số tiền mà James đã trả là bao nhiều khi anh ấy mua 5 gói thịt bò, mỗi gói nặng 4 pounds, với giá $5.50 mỗi pound?
Câu trả lời: Mỗi gói thịt bò nặng 4 pounds, vì vậy 5 gói nặng 4 * 5 = 20 pounds tổng cộng. Giá mỗi pound thịt bò là $5.50, vì vậy tổng chi phí cho 20 pounds là 20 * $5.50 = $110. ... Đáp án là: 110.

Cụ thể, đối với một câu hỏi qi, chúng tôi nối nó vào prompt, sau đó đưa vào LLM để tạo ra câu hỏi được diễn đạt lại. Ví dụ 3.1 cho thấy một câu hỏi được diễn đạt lại được tạo ra và prompt hoàn chỉnh được hiển thị trong Phụ lục A.1. Chúng tôi áp dụng temperature sampling để lấy mẫu Krephrase câu hỏi được diễn đạt lại cho mỗi câu hỏi meta. Đối với các câu hỏi được diễn đạt lại, việc kiểm tra thủ công tính nhất quán so với các câu hỏi gốc tốn thời gian. Chúng tôi đề xuất một phương pháp có giám sát để đánh giá tính đúng đắn giữa các câu hỏi được diễn đạt lại và các câu hỏi meta. Đối với mỗi câu hỏi được diễn đạt lại ˆq(j)i, chúng tôi sử dụng few-shot Chain-of-Thought prompting để tạo ra đường dẫn lý luận ˆr(j)i và câu trả lời ˆa(j)i, được so sánh với câu trả lời thực tế a⋆i. Độ chính xác của Complexity-based CoT để trả lời câu hỏi được diễn đạt lại bằng GPT-3.5-Turbo là 76.30%, tương đương với việc trả lời các câu hỏi huấn luyện gốc (80.74%). Điều này cho thấy rằng chất lượng của các câu hỏi được diễn đạt lại được giữ cao trong khi sự đa dạng câu hỏi được cải thiện. Chúng tôi thu thập các câu hỏi được diễn đạt lại với câu trả lời đúng (tức là ˆa(j)i = a⋆i) làm dữ liệu tăng cường:
Drephrase = {(ˆqi, ˆr(j)i, ˆa(j)i) : ˆa(j)i = a⋆i; i = 1, ..., Nq; j = 1, ..., Krephrase}. (2)

3.3 TỰ TẠO CÂU HỎI BẰNG LÝ LUẬN NGƯỢC
Lý luận ngược đóng vai trò quan trọng trong việc trả lời nhiều câu hỏi toán học, tức là bắt đầu với một điều kiện cho trước và suy nghĩ ngược lại để xác định một biến chưa biết trong câu hỏi. Một ví dụ cụ thể giữa một câu hỏi và một câu hỏi ngược được minh họa trong Ví dụ 3.2. Tuy nhiên, các phương pháp hiện tại (SFT, RFT, WizardMath) có độ chính xác thấp hơn đáng kể trên các câu hỏi ngược, như được thể hiện trong Hình 6, thúc đẩy chúng tôi tự tạo các câu hỏi ngược để cải thiện khả năng lý luận.

Ví dụ 3.2: Câu hỏi và Câu hỏi Ngược
Câu hỏi: James mua 5 gói thịt bò, mỗi gói 4 pounds. Giá thịt bò là $5.50 mỗi pound. Anh ấy đã trả bao nhiều tiền? Câu trả lời: Anh ấy đã mua 5*4=20 pounds thịt bò. Anh ấy đã trả 20*5.5=$110. Đáp án là: 110 ✓

Câu hỏi Ngược: James mua x gói thịt bò, mỗi gói 4 pounds. Giá thịt bò là $5.50 mỗi pound. Anh ấy đã trả bao nhiều tiền? Nếu chúng ta biết câu trả lời cho câu hỏi trên là 110, giá trị của biến chưa biết x là bao nhiều? Câu trả lời: Tổng trọng lượng thịt bò là 4*x vì 4*5.5 = 22. ... Đáp án là: 27 ✗

Để cải thiện khả năng lý luận ngược của các mô hình được tinh chỉnh, chúng tôi tạo ra nhiều câu hỏi hơn có thể được giải quyết theo cách ngược: một số trong câu hỏi qi được che bằng "x", trong khi LLM được yêu cầu dự đoán giá trị của "x" khi câu trả lời a⋆i được cung cấp. Khác với lý luận tiến, tạo ra các bước trung gian rõ ràng hướng tới câu trả lời cuối cùng, lý luận ngược bắt đầu với câu trả lời và tạo ra nhiều bước lý luận để dự đoán số bị che. Các phương pháp lý luận ngược tiêu biểu bao gồm Self-Verification và FOBAR.

Trong Self-Verification (SV), câu hỏi với câu trả lời trước tiên được viết lại thành một câu kể, ví dụ: "Anh ấy đã trả bao nhiều tiền?" (với câu trả lời 110) được viết lại thành "Anh ấy đã trả $110". Sau đó, một câu hỏi để hỏi giá trị của x được nối thêm, ví dụ: "Giá trị của biến chưa biết x là bao nhiều?". Ví dụ 3.3 đưa ra một ví dụ tăng cường. Chúng tôi thu thập các câu hỏi mới và các đường dẫn lý luận được tạo ra của chúng với câu trả lời đúng làm dữ liệu tăng cường:
DSV = {(˜q(j)i, ˜r(j)i, ˜a(j)i) : ˜a(j)i = a⋆i; i = 1, ..., Nq; j = 1, ..., KSV}. (3)

Ví dụ 3.3: Câu hỏi Self-Verification
Câu hỏi: James mua x gói thịt bò, mỗi gói 4 pounds. Giá thịt bò là $5.50 mỗi pound. Anh ấy đã trả 110. Giá trị của biến chưa biết x là bao nhiều?
Câu trả lời: Để giải quyết bài toán này, chúng ta cần xác định giá trị của x, đại diện cho số gói thịt bò mà James đã mua. Mỗi gói thịt bò nặng 4 pounds và ... Giá trị của x là 5.

Ví dụ 3.4: Câu hỏi FOBAR
Câu hỏi: James mua x gói thịt bò, mỗi gói 4 pounds. Giá thịt bò là $5.50 mỗi pound. Anh ấy đã trả bao nhiều tiền? Nếu chúng ta biết câu trả lời cho câu hỏi trên là 110, giá trị của biến chưa biết x là bao nhiều?
Câu trả lời: James mua x gói thịt bò, mỗi gói 4 pounds, vì vậy anh ấy mua tổng cộng 4x pounds thịt bò. Giá thịt bò là $5.50 mỗi pound, vì vậy tổng chi phí thịt bò là 5.50 * 4x = 22x. ... Giá trị của x là 5.

Self-Verification cần viết lại câu hỏi với câu trả lời thành một câu kể, điều này thách thức đối với các câu hỏi phức tạp. Để giải quyết vấn đề này, FOBAR đề xuất nối trực tiếp câu trả lời vào câu hỏi, tức là "Nếu chúng ta biết câu trả lời cho câu hỏi trên là {a⋆i}, giá trị của biến chưa biết x là bao nhiều?" Ví dụ 3.4 cho thấy một ví dụ. Chúng tôi thu thập các câu hỏi mới cùng với câu trả lời đúng của chúng làm dữ liệu tăng cường:
DFOBAR = {(¯q(j)i, ¯r(j)i, ¯a(j)i) : ¯a(j)i = a⋆i; i = 1, ..., Nq; j = 1, ..., KFOBAR}. (4)

3.4 HÀM MỤC TIÊU TINH CHỈNH
Chúng tôi gộp tất cả dữ liệu tăng cường, bao gồm dữ liệu tăng cường câu trả lời và các câu hỏi được tự tạo (Diễn đạt lại, Self-Verification, FOBAR) như DMetaMathQA = DAnsAug ∪ Drephrase ∪ DSV ∪ DFOBAR. Chúng tôi tinh chỉnh một mô hình LLM (được tham số hóa bởi θ) trên DMetaMathQA để có được mô hình MetaMath bằng cách tối đa hóa log likelihood của đường dẫn lý luận có điều kiện trên câu hỏi, tức là L(θ) = Σ(q,r,a)∈DMetaMathQA log P(r|q;θ). Mặc dù chúng tôi chỉ xem xét LLaMA-2 ở đây, MetaMathQA cũng có thể được sử dụng để tinh chỉnh các LLMs khác.

4 THÍ NGHIỆM VÀ KẾT QUẢ

4.1 THIẾT LẬP THÍ NGHIỆM

Bộ dữ liệu. Chúng tôi sử dụng hai điểm chuẩn lý luận toán học phổ biến: (i) GSM8K là một bộ dữ liệu gồm các bài toán toán cấp tiểu học chất lượng cao, chứa 7,473 mẫu huấn luyện và 1,319 mẫu kiểm tra; và (ii) bộ dữ liệu MATH gồm các bài toán thi đấu toán trung học bao gồm bảy môn học bao gồm Prealgebra, Algebra, Number Theory, Counting and Probability, Geometry, Intermediate Algebra, và Precalculus. Nó chứa 7,500 và 5,000 mẫu để huấn luyện và kiểm tra tương ứng. Các câu hỏi trong GSM8K cần từ 2 đến 8 bước để đến câu trả lời, trong khi MATH thách thức hơn nhiều.

Bảng 1: Số lượng mẫu trong MetaMathQA được đề xuất.

[Bảng hiển thị số lượng mẫu cho các loại dữ liệu khác nhau:
- MetaMathQA-GSM8K: AnsAug 80K, Rephrasing 80K, SV 40K, FOBAR 40K, Tổng 240K
- MetaMathQA-MATH: AnsAug 75K, Rephrasing 50K, SV 15K, FOBAR 15K, Tổng 155K
- MetaMathQA tổng: AnsAug 155K, Rephrasing 130K, SV 55K, FOBAR 55K, Tổng 395K]

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

[Bảng 2: So sánh độ chính xác kiểm tra với các LLMs hiện có trên GSM8K và MATH]

Mô hình. Chúng tôi sử dụng mô hình mã nguồn mở tiên tiến hiện tại LLaMA-2, bao gồm ba kích thước tham số khác nhau: 7B, 13B, và 70B, làm mô hình cơ sở để tinh chỉnh. GPT-3.5-Turbo được sử dụng để diễn đạt lại câu hỏi cũng như tạo câu trả lời trong tất cả bốn phương pháp tăng cường, nơi temperature được đặt thành 0.7. LLaMA-2-7B và LLaMA-2-13B được huấn luyện bằng tinh chỉnh đầy đủ. LLaMA-2-70B được tinh chỉnh bằng QLoRA để hiệu quả tính toán. Các chi tiết thí nghiệm khác có thể xem trong Phụ lục B.

Baseline. Các phương pháp được đề xuất được so sánh với (i) các mô hình mã nguồn đóng như GPT-3.5-Turbo, PaLM; (ii) các mô hình mã nguồn mở như LLaMA-1, LLaMA-2; (iii) Supervised Fine-Tuning (SFT), sử dụng tập huấn luyện của các bộ dữ liệu GSM8K hoặc MATH gốc; (iv) Rejection sampling Fine-Tuning (RFT) tạo ra và thu thập các đường dẫn lý luận đúng làm dữ liệu tăng cường để tinh chỉnh; (v) WizardMath tạo ra mẫu và huấn luyện hai mô hình phần thưởng sử dụng ChatGPT để chọn mẫu cho tinh chỉnh.

Mức tăng Đa dạng. Chúng tôi sử dụng mức tăng đa dạng để đo lường mức độ một bộ dữ liệu mới được thêm vào bộ dữ liệu cơ bản có thể cải thiện sự đa dạng dữ liệu tổng thể. Đối với một bộ dữ liệu cơ bản Dbase = {xi = (qi, ri, ai)}Ni=1 với N mẫu, và một bộ dữ liệu mới Dnew = {xi = (qi, ri, ai)}Mi=1 với M mẫu, mức tăng đa dạng được định nghĩa là: Dnew so với Dbase như: dgain = 1/M Σxi∈Dnew minxj∈Dbase(||f(xi) - f(xj)||22), trong đó f là bộ trích xuất đặc trưng và chúng tôi sử dụng OpenAI Embedding API text-embedding-ada-002 để trích xuất đặc trưng. Đối với Hình 2, chúng tôi thay đổi kích thước dữ liệu của dữ liệu cơ bản và chọn một tập cố định 20K điểm dữ liệu mới mà mô hình chưa gặp để tạo thành Dnew.

4.2 KẾT QUẢ TRÊN GSM8K VÀ MATH

Bảng 1 minh họa mô tả chi tiết về bộ sưu tập MetaMathQA của chúng tôi và Bảng 2 cho thấy độ chính xác kiểm tra trên GSM8K và MATH. Như có thể thấy, đối với các mô hình mã nguồn mở có tham số 1-10B, MetaMath đạt được hiệu suất tiên tiến. So với LLM tốt nhất trước đó, MetaMath đạt được một cải thiện lớn 11.6% trên GSM8K và 9.1% trên MATH về độ chính xác kiểm tra, cho thấy rằng tinh chỉnh trên dữ liệu MetaMathQA của chúng tôi là hiệu quả.

Đối với các LLMs có tham số 11-50B, MetaMath được đề xuất thể hiện tốt nhất. Đặc biệt, trên cả GSM8K và MATH, MetaMath đạt được độ chính xác cao hơn SFT, RFT, và WizardMath với một khoảng cách lớn (+7%), chứng minh hiệu quả của dữ liệu MetaMath trong việc cải thiện khả năng lý luận toán học. Hơn nữa, đối với các LLMs có tham số 51-70B, một lần nữa, MetaMath đạt được độ chính xác kiểm tra cao nhất. Đặc biệt, MetaMath tốt hơn GPT-3.5-Turbo trên GSM8K, được sử dụng để tạo ra dữ liệu tăng cường cho tinh chỉnh.

4.3 HIỆU QUẢ CỦA CÁC PHƯƠNG PHÁP TĂNG CƯỜNG

Trong phần này, chúng tôi thực hiện thí nghiệm để nghiên cứu hiệu quả của các phương pháp tăng cường trong MetaMath. Chúng tôi trước tiên tinh chỉnh mô hình LLaMA-2-7B trên dữ liệu GSM8K được tăng cường (MetaMath-GSM8K), và kiểm tra mô hình được tinh chỉnh trên GSM8K và MATH. Bảng 3 cho thấy độ chính xác kiểm tra của các kết hợp tăng cường khác nhau, nơi chúng tôi trộn tất cả dữ liệu tăng cường với nhau cho mỗi mô hình. Như có thể thấy, trên GSM8K, các mô hình được huấn luyện trên tăng cường câu trả lời (AnsAug) hoặc tăng cường diễn đạt lại đạt được độ chính xác cao hơn nhiều so với SFT, chỉ được huấn luyện trên tập huấn luyện. Kết hợp dữ liệu tăng cường câu trả lời và dữ liệu tăng cường diễn đạt lại để tinh chỉnh dẫn đến độ chính xác cao hơn một chút, được cải thiện thêm khoảng 4% thông qua việc gộp dữ liệu tăng cường FOBAR và SV.

Đối với MATH, MetaMath được huấn luyện chỉ trên dữ liệu MetaMathQA-GSM8K thể hiện tốt hơn SFT, cho thấy hiệu quả trong việc khái quát hóa cho các nhiệm vụ toán học chưa thấy.

Chúng tôi cũng thực hiện thí nghiệm bằng cách tinh chỉnh LLaMA-2-7B trên dữ liệu MATH được tăng cường (MetaMathQA-MATH) sau đó đánh giá mô hình trên GSM8K và MATH. Bảng 3 cho thấy độ chính xác kiểm tra. Một lần nữa, MetaMath được huấn luyện trên dữ liệu tăng cường AnsAug hoặc diễn đạt lại thể hiện tốt hơn nhiều so với SFT. Hơn nữa, gộp tất cả dữ liệu tăng cường với nhau để tinh chỉnh tốt hơn so với việc gộp dữ liệu tăng cường AnsAug và diễn đạt lại, chứng minh hiệu quả của dữ liệu tăng cường SV và FOBAR trong việc cải thiện khả năng lý luận toán học. Hơn nữa, đối với nhiệm vụ GSM8K chưa thấy, MetaMath được huấn luyện trên dữ liệu MetaMathQA-MATH tốt hơn đáng kể so với SFT (+20%).

[Bảng 3: Hiệu quả của các phương pháp tăng cường câu hỏi khác nhau với LLaMA-2-7B được tinh chỉnh trên GSM8K hoặc MATH]

4.4 THẢO LUẬN TỪ GÓ独 ĐỘ PERPLEXITY

Theo Giả thuyết Alignment Bề ngoài được đề xuất bởi Zhou et al., khả năng của một mô hình bắt nguồn từ pretraining, và dữ liệu từ các nhiệm vụ downstream hoạt động để kích hoạt khả năng vốn có của LLMs đã được học trong quá trình pretraining. Có hai câu hỏi quan trọng phát sinh từ giả thuyết này: (i) loại dữ liệu nào hiệu quả nhất trong việc kích hoạt kiến thức tiềm ẩn có thể có, và (ii) tại sao một bộ dữ liệu tốt hơn bộ dữ liệu khác trong việc kích hoạt như vậy? Kết quả thực nghiệm của chúng tôi cho thấy rằng, trong các nhiệm vụ toán học chúng tôi xem xét, bộ dữ liệu MetaMathQA của chúng tôi có thể phục vụ như một bộ kích hoạt kiến thức toán học vượt trội. Tuy nhiên, tại sao MetaMath mang lại hiệu suất vượt trội so với việc huấn luyện trên dữ liệu chỉ có câu trả lời đúng hoặc GSM8K CoT vẫn chưa rõ ràng. Chúng tôi suy đoán rằng có lẽ đó là sự đơn giản của dữ liệu quan trọng. Như được thể hiện trong Hình 3, chúng tôi tính toán perplexity cho mô hình LLaMA-2-7B được tinh chỉnh dưới mức, về dữ liệu chỉ có câu trả lời, GSM8K CoT, và các phần con của dữ liệu MetaMathQA. Perplexity của MetaMathQA thấp hơn đáng kể so với hai bộ dữ liệu khác. Điều này làm nổi bật bản chất dễ học vốn có của nó, có thể thuận lợi hơn cho việc kích thích khả năng giải quyết vấn đề được tăng cường từ một LLM. Điều này cũng phù hợp với các phát hiện với TinyStories, nơi dữ liệu câu chuyện ngắn và dễ có thể giúp LLMs tạo ra nội dung một cách trôi chảy.

[Hình 3: Perplexity thấp hơn của MetaMathQA]

4.5 THẢO LUẬN TỪ GÓƯỚC ĐỘ ĐA DẠNG

Như được thể hiện trong Hình 2, việc prompting GPT-3.5-Turbo một cách ngây thơ để tăng cường câu trả lời dẫn đến sự bão hòa độ chính xác rõ ràng. Sau khi bão hòa độ chính xác, việc tăng dữ liệu AnsAug chỉ mang lại lợi ích hiệu suất hạn chế. Ví dụ, sử dụng 80K dữ liệu tăng cường câu trả lời để huấn luyện mô hình LLaMA-2 7B dẫn đến độ chính xác 59.6%, thêm 20K dữ liệu AnsAug mới chỉ mang lại lợi ích hiệu suất 0.1%. Điều này là do tính đồng nhất của các mẫu bổ sung, đóng góp vào mức tăng đa dạng chỉ 0.05 (được thể hiện trong Hình 4). Ngược lại, thêm cùng một lượng dữ liệu được tạo ra bởi tự tạo câu hỏi dẫn đến sự cải thiện hiệu suất đáng kể, do mức tăng đa dạng đáng chú ý được mang lại bởi tự tạo câu hỏi. Như được thể hiện trong Hình 4, thêm 20K dữ liệu từ Rephrasing, FOBAR, hoặc SV mang lại mức tăng đa dạng tăng dần, do đó gây ra lợi ích độ chính xác tương ứng là 0.4%, 2.3%, và 2.6%. Thí nghiệm này chứng minh mối tương quan tích cực (hệ số Pearson là 0.972) giữa sự đa dạng được mang lại bởi các phương pháp tự tạo và độ chính xác. Điều này cũng phù hợp với thành công của MetaMath, được huấn luyện với bộ dữ liệu MetaMathQA đa dạng bao gồm 4 loại dữ liệu phản ánh cả đường dẫn lý luận tiến và lùi.

[Hình 4: Độ chính xác tương quan tích cực với sự đa dạng]

4.6 ĐÁNH GIÁ KHAO NĂNG LÝ LUẬN TOÁN HỌC NGƯỢC

Lời nguyền Đảo ngược, nơi LLMs được huấn luyện từ một câu "A là B" không thể khái quát hóa để trả lời "B là A", cũng phù hợp với quan sát trong bài báo này rằng LLMs thiếu khả năng lý luận toán học ngược. Để đánh giá khả năng toán học ngược, chúng tôi đề xuất một tập kiểm tra GSM8K-Backward, bao gồm 1270 câu hỏi ngược bằng cách sử dụng SV và FOBAR để tăng cường tập kiểm tra GSM8K gốc (như được thể hiện trong Ví dụ 3.3 và Ví dụ 3.4). Hình 6 cho thấy so sánh độ chính xác của các LLMs toán học 7B khác nhau giữa các bộ dữ liệu GSM8K và GSM8K-Backward. Như có thể thấy, các LLMs hiện tại gặp khó khăn trong việc giải quyết các bài toán toán học theo lý luận ngược và MetaMath của chúng tôi có sự cải thiện đáng kể trên cả hai bộ dữ liệu. Cụ thể, các cách mà các LLMs khác nhau giải quyết bài toán toán học ngược được minh họa thông qua các ví dụ trong Phụ lục C.

[Hình 6: Khoảng cách độ chính xác giữa GSM8K và GSM8K-Backward]

4.7 ĐƯỜNG DẪN LÝ LUẬN VỚI CÂU TRẢ LỜI SAI CŨNG CÓ THỂ HỮU ÍCH

Chúng tôi thực hiện thí nghiệm trên GSM8K sử dụng LLaMA-2-7B để nghiên cứu liệu các mẫu tăng cường câu trả lời với câu trả lời sai có hữu ích cho việc tinh chỉnh LLM hay không. Chúng tôi chọn ngẫu nhiên 7,473 đường dẫn lý luận với câu trả lời sai từ các câu trả lời được tạo ra, và chúng tôi đảm bảo rằng kích thước giống như tập huấn luyện gốc. Từ Bảng 4, chúng tôi quan sát thấy rằng mô hình được tinh chỉnh trên dữ liệu tăng cường với câu trả lời sai vẫn tốt hơn SFT, điều này phản trực giác. Chúng tôi giả thuyết rằng mặc dù câu trả lời cuối cùng sai, một số bước lý luận trung gian là đúng (xem Ví dụ 4.1). Các bước lý luận này vẫn có thể là tín hiệu giám sát hữu ích. Kết quả của chúng tôi cũng phù hợp với, nơi họ khám phá tầm quan trọng của giám sát quá trình trung gian cho lý luận.

[Bảng 4: Độ chính xác kiểm tra trên GSM8K của LLaMA-2-7B được huấn luyện trên các dữ liệu khác nhau]

[Hình 5: Kết hợp bộ dữ liệu RFT với MetaMathQA của chúng tôi dẫn đến giảm hiệu suất]

4.8 NHIỀU DỮ LIỆU KHÔNG PHẢI LÚC NÀO CŨNG TỐT HƠN

Cũng có các công trình trước đó tăng cường dữ liệu lý luận toán học để tinh chỉnh. Một câu hỏi thú vị là liệu việc kết hợp các bộ dữ liệu tăng cường hiện có với MetaMathQA của chúng tôi có thể cải thiện hiệu suất giải quyết bài toán toán học tổng thể hay không. Chúng tôi chọn bộ dữ liệu RFT làm bộ dữ liệu bên ngoài. Hình 5 cho thấy rằng việc gộp dữ liệu RFT vào MetaMathQA thực sự làm tổn hại hiệu suất, cho thấy rằng dữ liệu RFT có thể không có lợi cho MetaMath. Hiện tượng này được quan sát thấy nhất quán trong bộ dữ liệu MetaMathQA dưới các kích thước khác nhau (từ 20K đến 100K), và bộ dữ liệu RFT được thêm vào khoảng 47K. Sự giảm hiệu suất ngụ ý rằng dữ liệu tăng cường nhiều hơn không phải lúc nào cũng giúp ích cho khái quát hóa.

Ví dụ 4.2: Nghiên cứu Trường hợp trong Tập Kiểm tra GSM8K
Câu hỏi: Tuổi của Darrell và Allen theo tỉ lệ 7:11, Nếu tổng tuổi của họ hiện tại là 162, tính tuổi của Allen sau 10 năm nữa. (Câu trả lời thực tế là 109)

[Tiếp theo là các câu trả lời từ các mô hình khác nhau: SFT, RFT, WizardMath, và câu trả lời của chúng tôi]

4.9 PHÂN TÍCH LỖI

Chúng tôi đã chứng minh rằng – qua nhiều quy mô – các mô hình MetaMath của chúng tôi có thể đạt được hiệu suất giải quyết vấn đề xuất sắc. Tuy nhiên, điều quan trọng là phải xem xét các đặc điểm của các vấn đề gây ra lỗi trong MetaMath và các mô hình toán học mã nguồn mở hiện có. Đặc biệt, chúng tôi xem xét mối quan hệ giữa độ dài câu hỏi và hiệu suất mô hình. Để điều tra, chúng tôi chia tập kiểm tra GSM8K thành ba tập con có kích thước bằng nhau dựa trên độ dài khác nhau của câu hỏi và tính toán độ chính xác của các mô hình trên mỗi tập con. Chúng tôi thấy trong Hình 7 rằng MetaMath và các phương pháp liên quan gặp khó khăn với các câu hỏi dài hơn. Tuy nhiên, đáng phấn khích là MetaMath luôn có được hiệu suất vượt trội. Chúng tôi thấy việc nghiên cứu cải thiện hiệu suất mô hình với độ dài câu hỏi dài hơn – ví dụ bằng cách tăng cường thêm bộ dữ liệu MetaMathQA – là nền tảng chín muồi cho công việc tương lai.

[Hình 7: Độ chính xác kiểm tra trên các câu hỏi có độ dài ngắn, trung bình và dài]

5 KẾT LUẬN
Trong bài báo này, chúng tôi tập trung vào việc cải thiện khả năng giải quyết bài toán toán học của các LLMs mã nguồn mở. Bằng cách tự tạo các câu hỏi toán học trên GSM8K và MATH, chúng tôi trình bày một bộ dữ liệu chất lượng cao và đa dạng MetaMathQA, bao gồm các mẫu lý luận tiến và lùi. Họ LLMs của chúng tôi được tinh chỉnh trên MetaMathQA, có tên MetaMath, đã đạt được tiên tiến trên các điểm chuẩn toán học trong số tất cả các LLMs mã nguồn mở. Đáng chú ý, MetaMath-7B đạt 66.5% trên GSM8K và 19.8% trên MATH, vượt qua các LLMs mã nguồn mở trước đó với một khoảng cách đáng kể. Công việc của chúng tôi nhấn mạnh thêm tầm quan trọng của các đặc điểm của dữ liệu huấn luyện trong việc tăng cường khả năng giải quyết vấn đề của LLM.

LỜI CẢM ƠN
Các tác giả muốn chân thành cảm ơn Katherine M. Collins từ Đại học Cambridge vì những hiểu biết sâu sắc và đề xuất quý giá của bà.

Công việc này được hỗ trợ bởi khoản tài trợ chính NSFC 62136005, khoản tài trợ chung NSFC 62076118, và chương trình nghiên cứu cơ bản Thâm Quyến JCYJ20210324105000003. Nghiên cứu này được hỗ trợ một phần bởi Hội đồng Tài trợ Nghiên cứu của Đặc khu Hành chính Hồng Kông (Khoản tài trợ 16200021 và 16202523). AW thừa nhận sự hỗ trợ từ Học bổng Turing AI Fellowship theo khoản tài trợ EP/V025279/1, và Leverhulme Trust qua CFI.

TÀI LIỆU THAM KHẢO

[Danh sách tài liệu tham khảo từ [1] đến [85] với các chi tiết đầy đủ về các công trình nghiên cứu được trích dẫn]

PHỤ LỤC
Mục lục
A Prompts 17
A.1 Prompts Diễn đạt lại . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
A.2 Viết lại Câu hỏi với Câu trả lời thành Câu Kể . . . . . . . . . . . . 18
B Chi tiết Thí nghiệm 18
C Các LLMs khác nhau giải quyết bài toán toán học đảo ngược như thế nào? 19
D Khái quát hóa cho Game of 24 19
E Kết quả Thí nghiệm Khác 21
E.1 MetaMathQA Hữu ích cho Các Mô hình Cơ sở Khác nhau . . . . . . . . . . . . 21
E.2 Độ chính xác Kiểm tra dưới Kích thước Dữ liệu Tăng cường Khác nhau . . . . . . . . . 21
E.3 Nghiên cứu Ablation trên Mô hình Lớn hơn LLaMA-2-13B . . . . . . . . . . . 22
E.4 Khả năng Ngoài Phân phối . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

[Các phần phụ lục tiếp theo chứa các chi tiết kỹ thuật, prompt cụ thể, và kết quả thí nghiệm bổ sung]

# 2308.07758.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2308.07758.pdf
# Kích thước tệp: 1533101 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Lập luận Thuận-Nghịch trong Mô hình Ngôn ngữ Lớn
cho Xác minh Toán học
Weisen Jiang1, 2, Han Shi3, Longhui Yu4, Zhengying Liu3
Yu Zhang1,*, Zhenguo Li3, James T. Kwok2
1Khoa Khoa học Máy tính và Kỹ thuật, Đại học Khoa học và Công nghệ Miền Nam
2Khoa Khoa học Máy tính và Kỹ thuật, Đại học Khoa học và Công nghệ Hồng Kông
3Phòng thí nghiệm Noah's Ark của Huawei4Đại học Bắc Kinh
{waysonkong, yu.zhang.ust }@gmail.com, jamesk@cse.ust.hk
Trang dự án: https://llm-fobar.github.io
Tóm tắt
Tự-Nhất quán lấy mẫu các chuỗi lập luận đa dạng với câu trả lời và chọn câu trả lời cuối cùng bằng bỏ phiếu đa số. Nó dựa trên lập luận thuận và không thể cải thiện hiệu suất thêm bằng cách lấy mẫu nhiều chuỗi lập luận hơn khi đã bão hòa. Để tăng cường hiệu suất hơn nữa, chúng tôi giới thiệu lập luận nghịch để xác minh các câu trả lời ứng viên. Cụ thể, đối với các nhiệm vụ toán học, chúng tôi che một số trong câu hỏi và yêu cầu LLM trả lời một câu hỏi nghịch được tạo bởi một mẫu đơn giản, tức là dự đoán số bị che khi một câu trả lời ứng viên được cung cấp. Thay vì chỉ sử dụng lập luận thuận hoặc nghịch, chúng tôi đề xuất FOBAR để kết hợp Lập luận Thuận và Nghịch cho việc xác minh. Các thí nghiệm rộng rãi trên sáu bộ dữ liệu toán học tiêu chuẩn và ba LLM cho thấy FOBAR đạt hiệu suất tối tân. Đặc biệt, FOBAR vượt trội so với Tự-Nhất quán, phương pháp chỉ sử dụng lập luận thuận, chứng minh rằng kết hợp lập luận thuận và nghịch chính xác hơn trong xác minh. Ngoài ra, FOBAR đạt độ chính xác cao hơn so với các phương pháp xác minh hiện có, cho thấy hiệu quả của mẫu đơn giản được sử dụng trong lập luận nghịch và sự kết hợp được đề xuất.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLM) được huấn luyện trước (Chowdhery et al., 2022; OpenAI, 2023; Wu et al., 2023; Jiang et al., 2023) khái quát hóa tốt trên các nhiệm vụ chưa từng thấy bằng cách gợi ý few-shot (hoặc học ngữ cảnh (ICL) (Brown et al., 2020; Min et al., 2022; Chen et al., 2022; Li et al., 2023; Xiong et al., 2024). Điều này được thực hiện bằng cách nối một vài ví dụ (ví dụ: các cặp câu hỏi-câu trả lời) làm gợi ý, sau đó thêm câu hỏi kiểm tra. Tuy nhiên, vẫn còn thách thức đối với LLM để trả lời các câu hỏi toán học bằng cách chỉ gợi ý các cặp câu hỏi-câu trả lời, vì toán học phức tạp hơn và thường cần nhiều bước để suy ra câu trả lời.

Gần đây, Wei et al. (2022) đề xuất gợi ý chuỗi suy nghĩ (CoT), tạo ra các bước trung gian rõ ràng được sử dụng để đạt đến câu trả lời, cho LLM. Cụ thể, mỗi ví dụ trong ngữ cảnh được bổ sung với một số bước suy nghĩ được mô tả bằng ngôn ngữ tự nhiên. Một vài ví dụ được nối lại thành một gợi ý CoT. Trong suy luận, câu hỏi kiểm tra được thêm vào gợi ý và sau đó đưa cho LLM. LLM được kỳ vọng sẽ bắt chước các ví dụ trong ngữ cảnh, tức là tạo ra một số bước lập luận trước khi đưa ra câu trả lời. Gợi ý CoT đã đạt hiệu suất hứa hẹn trong các nhiệm vụ lập luận toán học (Wei et al., 2022; Wang et al., 2023; Zheng et al., 2023; Zhang et al., 2023b), và nhiều công trình đã được đề xuất để cải thiện hiệu quả (Fu et al., 2023; Zheng et al., 2023; Zhou et al., 2023; Yao et al., 2023; Pitis et al., 2023) và hiệu suất (Zhang et al., 2023b; Kojima et al., 2022; Diao et al., 2023; Lu et al., 2022) của nó.

Tự-Nhất quán (Wang et al., 2023) là một phương pháp đơn giản nhưng hiệu quả để cải thiện gợi ý CoT. Sử dụng lấy mẫu nhiệt độ (Ackley et al., 1985; Ficler và Goldberg, 2017), nó lấy mẫu một tập hợp đa dạng các chuỗi lập luận có thể dẫn đến nhiều câu trả lời ứng viên. Câu trả lời nhận được nhiều phiếu bầu nhất sau đó được chọn là câu trả lời cuối cùng. Tuy nhiên, kết quả thí nghiệm của chúng tôi1 cho thấy việc chỉ lấy mẫu nhiều đường dẫn lập luận hơn có thể không dẫn đến cải thiện độ chính xác kiểm tra, đặc biệt khi số lượng đường dẫn lấy mẫu đã lớn. Hơn nữa, trong số các câu hỏi thất bại của Tự-Nhất quán, khoảng 60% có ít nhất một chuỗi lập luận đạt đến câu trả lời chính xác (Bảng 4 trong Phần 4.8). Do đó, việc bỏ phiếu đa số của Tự-Nhất quán có thể được cải thiện bằng cách sử dụng một trình xác minh đáng tin cậy hơn.

Chúng tôi giới thiệu lập luận nghịch (hoặc chuỗi nghịch) (Pettit và Sugden, 1989; Russell và Norvig, 1995; Khot et al., 2021; Liang et al., 2021; Yu et al., 2023) để xác minh các câu trả lời ứng viên. Hình 1 đưa ra một nghiên cứu trường hợp. Đối với mỗi câu trả lời ứng viên ˆAc, chúng tôi che một số trong câu hỏi bằng "x", và thiết kế một mẫu "Nếu chúng ta biết câu trả lời của câu hỏi trên là ˆAc, giá trị của biến không xác định x là gì?" để tạo thành một câu hỏi nghịch. Câu hỏi này sau đó được đưa cho LLM để lấy mẫu nhiều chuỗi lập luận nghịch để dự đoán số bị che. Vì giá trị thực của x đã biết, chúng ta có thể kiểm tra xem số bị che có được dự đoán chính xác hay không. Trực quan, một câu trả lời ứng viên đúng có nhiều khả năng giúp dự đoán số bị che hơn so với câu trả lời sai (như được xác minh trong Hình 5). Sau đó, bằng cách định nghĩa số phiếu của ˆAc là số chuỗi dự đoán chính xác số bị che, chúng tôi ước tính xác suất nghịch PB(ˆAc) là tỷ lệ phiếu bầu mà ˆAc nhận được trong hướng nghịch. Khi chỉ sử dụng lập luận nghịch, dự đoán là arg max ˆAcPB(ˆAc).

Vì lập luận thuận và nghịch bổ sung cho nhau, chúng tôi đề xuất phương pháp Lập luận Thuận-Nghịch (FOBAR) để kết hợp chúng. Bằng cách ước tính xác suất thuận PF(ˆAc) là tỷ lệ phiếu bầu mà ˆAc nhận được trong hướng thuận, chúng tôi đề xuất ước tính xác suất mà ˆAc đúng (ký hiệu là P(ˆAc)) là trung bình hình học của xác suất thuận và nghịch, tức là P(ˆAc)∝ PF(ˆAc)α PB(ˆAc)1−α.

Các thí nghiệm rộng rãi trên sáu bộ dữ liệu và ba LLM của OpenAI (bao gồm text-davinci-003 (OpenAI, 2022a), GPT-3.5-Turbo (OpenAI, 2022b), và GPT-4 (OpenAI, 2023)) cho thấy FOBAR đạt hiệu suất tối tân (SOTA).

Đóng góp của chúng tôi được tóm tắt như sau:
(i) Chúng tôi giới thiệu lập luận nghịch vào xác minh toán học bằng cách che một số trong câu hỏi gốc và yêu cầu LLM dự đoán số bị che khi một câu trả lời ứng viên được cung cấp. (ii) Chúng tôi đề xuất FOBAR để kết hợp lập luận thuận và nghịch cho việc xác minh. (iii) Kết quả thí nghiệm trên sáu điểm chuẩn toán học tiêu chuẩn và ba LLM cho thấy FOBAR đạt hiệu suất SOTA. Đặc biệt, FOBAR vượt trội so với Tự-Nhất quán chỉ sử dụng lập luận thuận, chứng minh rằng kết hợp lập luận thuận và nghịch tốt hơn. Ngoài ra, FOBAR vượt trội so với Tự-Xác minh, xác nhận rằng việc sử dụng mẫu đơn giản và sự kết hợp được đề xuất hiệu quả hơn.

2 Công trình liên quan
Gợi ý Chuỗi Suy nghĩ (CoT). Wei et al. (2022) đề xuất bổ sung các cặp câu hỏi-câu trả lời với các bước trung gian sao cho LLM có thể giải quyết câu hỏi từng bước. Cụ thể, mỗi ví dụ trong ngữ cảnh là một bộ ba (Q(i), R(i), A⋆(i)), trong đó R(i) là một chuỗi lập luận với mô tả ngôn ngữ tự nhiên về các bước dẫn từ câu hỏi Q(i) đến câu trả lời thực tế A⋆(i). Trong suy luận, một câu hỏi mới Q được thêm vào gợi ý: PCoT="Câu hỏi: Q(1)\nTrả lời: R(1), A⋆(1) ...Câu hỏi: Q(K)\nTrả lời: R(K), A⋆(K)" và "PCoT\nCâu hỏi: Q \nTrả lời:" được đưa cho LLM để tạo ra cả chuỗi lập luận R và câu trả lời A. Gợi ý CoT đã đạt hiệu suất SOTA trên một loạt các nhiệm vụ rộng rãi (Wei et al., 2022; Kojima et al., 2022; Fu et al., 2023; Zhang et al., 2023b; Wang et al., 2023; Zheng et al., 2023; Zhou et al., 2023; Zhang et al., 2023c; Wei et al., 2024).

--- TRANG 2 ---
Câu hỏi nghịch (với câu trả lời 21): Tổng của ba số lẻ liên tiếp là x. Số nhỏ nhất trong ba số là gì? Nếu chúng ta biết câu trả lời của câu hỏi trên là 21, giá trị của biến không xác định x là gì? (chúng tôi lấy mẫu 10 chuỗi nghịch và tất cả dự đoán x = 69, do đó, 10 chuỗi nghịch chính xác)

Câu hỏi nghịch (với câu trả lời 23): Tổng của ba số lẻ liên tiếp là x. Số nhỏ nhất trong ba số là gì? Nếu chúng ta biết câu trả lời của câu hỏi trên là 23, giá trị của biến không xác định x là gì? (chúng tôi lấy mẫu 10 chuỗi nghịch và tất cả dự đoán x = 75, do đó, không có chuỗi nghịch chính xác)

Xác suất nghịch:
Các câu trả lời ứng viên được tạo bởi Tự-Nhất quán: 21 (16 lần), 23 (24 lần)
Xác suất thuận: PF(21) = 16/40, PF(23) = 24/40
PB(21) = 10/(10 +ε), PB(23) = ε/(10 +ε)

Câu hỏi (thực tế: 21): Tổng của ba số lẻ liên tiếp là 69. Số nhỏ nhất trong ba số là gì?

Xác suất kết hợp: P(21) ∝ PF(21)PB(21) ≈ 0.63
P(23) ∝ PF(23)PB(23) ≈ 2.45 × 10^-5 (ε = 10^-8)

Hình 1: Nghiên cứu trường hợp cho phương pháp FOBAR được đề xuất.

Gần đây, nhiều công trình (Fu et al., 2023; Zheng et al., 2023; Madaan et al., 2023; Paul et al., 2023; Shinn et al., 2023; Welleck et al., 2023; Zhou et al., 2023; Chen et al., 2023; Zhang et al., 2023a) đã được đề xuất để cải thiện chất lượng các chuỗi lập luận trong gợi ý CoT. ComplexCoT (Fu et al., 2023) chọn các ví dụ có nhiều bước hơn làm ví dụ trong ngữ cảnh, trong khi PHP (Zheng et al., 2023) lặp lại sử dụng các câu trả lời trước đó làm gợi ý trong việc tạo gợi ý. Các công trình nêu trên có thể được xem là lập luận thuận (Shao et al., 2023; Weng et al., 2023), bắt đầu từ câu hỏi và tạo ra một chuỗi lập luận để đạt đến câu trả lời. Thay vì lấy một chuỗi lập luận duy nhất bằng giải mã tham lam, Tự-Nhất quán (Wang et al., 2023) lấy mẫu một tập hợp đa dạng các chuỗi và thu được một tập hợp các câu trả lời ứng viên. Câu trả lời cuối cùng sau đó được chọn bằng bỏ phiếu đa số.

Lập luận Nghịch. Lập luận nghịch (còn gọi là chuỗi nghịch) (Pettit và Sugden, 1989; Russell và Norvig, 1995; Khot et al., 2021; Liang et al., 2021; Yu et al., 2023) bắt đầu với một câu trả lời và làm việc ngược lại để xác minh chuỗi các bước hoặc điều kiện cần thiết để đạt đến câu trả lời này. Lập luận nghịch đặc biệt hữu ích trong các lĩnh vực khi câu trả lời đã biết, ví dụ trong các trình chứng minh định lý tự động (Russell và Norvig, 1995; Rocktäschel và Riedel, 2016; Wang và Deng, 2020; Kazemi et al., 2023; Poesia và Goodman, 2023). Gần đây, Tự-Xác minh (Weng et al., 2023) viết lại câu hỏi với một câu trả lời thành một câu tuyên bố và sau đó yêu cầu LLM dự đoán số bị che. RCoT (Xue et al., 2023) tái tạo một câu (một chuỗi token) trong câu hỏi dựa trên câu trả lời và phát hiện xem có sự không nhất quán về mặt thực tế trong câu hỏi được xây dựng thông qua ba bước phức tạp. Quy trình kiểm tra phức tạp có thể dẫn đến xác minh không chính xác. Ngược lại, để tạo các câu hỏi nghịch, chúng tôi chỉ đơn giản thêm một mẫu vào câu hỏi gốc mà không cần viết lại và tái tạo thêm; để xác minh, FOBAR được đề xuất chỉ cần kiểm tra xem số có được dự đoán chính xác bằng so sánh chuỗi, đơn giản và chính xác hơn nhiều. Hơn nữa, FOBAR được đề xuất kết hợp lập luận thuận và nghịch cùng nhau để xác minh, trong khi Tự-Xác minh và RCoT chỉ sử dụng lập luận nghịch. Khác với MetaMath (Yu et al., 2024) sử dụng lập luận nghịch để bổ sung câu hỏi cho việc tinh chỉnh, chúng tôi tập trung vào việc sử dụng lập luận nghịch để xác minh.

3 Lập luận Thuận-Nghịch cho Xác minh
Trong phần này, chúng tôi đề xuất phương pháp FOBAR để xác minh. Tổng quan được thể hiện trong Hình 2. Chúng tôi đầu tiên xem xét các nhiệm vụ lập luận toán học. Một tập hợp các câu trả lời ứng viên được tạo ra theo hướng thuận, và chúng tôi ước tính xác suất của mỗi câu trả lời dựa trên số phiếu bầu nó nhận được (Phần 3.1). Tiếp theo, chúng tôi che một số trong câu hỏi và đề xuất một mẫu đơn giản để tạo các câu hỏi nghịch để xác minh các câu trả lời ứng viên (Phần 3.2). Chúng tôi tiếp tục đề xuất FOBAR (Phần 3.3) để kết hợp lập luận thuận và nghịch. Phần mở rộng cho các nhiệm vụ phi toán học được thảo luận trong Phần 3.4.

3.1 Lập luận Thuận
Lập luận thuận bắt đầu với một câu hỏi và tạo ra nhiều bước trung gian hướng tới câu trả lời. Cụ thể, đối với một câu hỏi Q, chúng tôi đặt trước nó một gợi ý cơ sở PF (ví dụ: gợi ý CoT (Wei et al., 2022) hoặc gợi ý ComplexCoT (Fu et al., 2023)) và đưa bộ (PF, Q) cho LLM để tạo ra một chuỗi lập luận và câu trả lời ứng viên. Sử dụng lấy mẫu nhiệt độ (Ackley et al., 1985; Ficler và Goldberg, 2017), chúng tôi lấy mẫu MF chuỗi lập luận ứng viên {Ri}MF i=1 và trích xuất các câu trả lời ứng viên tương ứng {Ai}MF i=1 (xem Hình 2, trên). Gọi A = {ˆAc}|A| c=1 là tập hợp các câu trả lời được loại bỏ trùng lặp từ {Ai}MF i=1. Không như giải mã tham lam (Wei et al., 2022), chúng ta có thể có nhiều câu trả lời ứng viên khác nhau (tức là |A| > 1). Chúng tôi đề xuất ước tính xác suất mà câu trả lời ứng viên ˆAc ∈ A đúng là tỷ lệ phiếu bầu nó nhận được từ các đường dẫn lập luận:

PF(ˆAc) = 1/MF ∑(i=1 to MF) I(Ai = ˆAc), (1)

trong đó I(·) là hàm chỉ báo. Chọn ˆAc với PF(ˆAc) lớn nhất tương ứng với phương pháp tối tân Tự-Nhất quán (Wang et al., 2023). Tuy nhiên, như thể hiện trong Hình 7, hiệu suất của Tự-Nhất quán bão hòa khi MF đủ lớn. Do đó, việc chỉ lấy mẫu nhiều đường dẫn lập luận hơn mang lại cải thiện hiệu suất không đáng kể.

3.2 Lập luận Nghịch
Trong lập luận nghịch, chúng tôi che một số có trong câu hỏi và yêu cầu LLM dự đoán số bị che bằng cách sử dụng một câu trả lời ứng viên được cung cấp. Cụ thể, giả sử câu hỏi Q liên quan đến NQ số {num(n)}NQ n=1. Chúng tôi thay thế từng số một bằng x. Câu hỏi bị che kết quả ˆQ(n) sau đó được nối với mẫu sau đây, có chứa một câu trả lời ứng viên ˆAc ∈ A.

Mẫu để Tạo Câu hỏi Nghịch
T(ˆAc) = Nếu chúng ta biết câu trả lời của câu hỏi trên là {ˆAc}, giá trị của biến không xác định x là gì?

Mỗi cặp (ˆQ(n), T(ˆAc)) được gọi là một câu hỏi nghịch. Tổng cộng, chúng tôi thu được NQ câu hỏi nghịch. Một số ví dụ về câu hỏi nghịch được hiển thị trong Ví dụ A.1 của Phụ lục A. Lưu ý rằng Tự-Xác minh (Weng et al., 2023) cần sự hỗ trợ của một LLM để viết lại một cặp (câu hỏi, câu trả lời) thành một câu tuyên bố.2 Ngược lại, mẫu được đề xuất đơn giản hơn và tránh các lỗi có thể xảy ra (một ví dụ minh họa lỗi viết lại của Tự-Xác minh được hiển thị trong Phụ lục B).

Để dự đoán số bị che, chúng tôi đặt trước câu hỏi nghịch với một gợi ý PB, bao gồm một số demo câu hỏi-câu trả lời (nghịch) với các chuỗi lập luận. Một ví dụ demo câu hỏi-câu trả lời được hiển thị trong Ví dụ A.2 của Phụ lục A. Chúng tôi đưa mỗi (PB, ˆQ(n), T(ˆAc)) (trong đó n = 1, ..., NQ) cho LLM, sau đó bắt chước các ví dụ trong ngữ cảnh trong PB và tạo ra một chuỗi lập luận để dự đoán số bị che. Chúng tôi lấy mẫu MB chuỗi lập luận như vậy với các dự đoán {dnum(n) c,b}MB b=1 (xem Hình 2, giữa).

Đối với mỗi câu trả lời ứng viên ˆAc, chúng tôi đếm số lần mà số bị che được dự đoán chính xác:

Zc = ∑(n=1 to NQ) ∑(b=1 to MB) I(dnum(n) c,b = num(n)). (2)

Xác suất mà câu trả lời ứng viên ˆAc đúng được ước tính là

PB(ˆAc) = (Zc + ε) / (∑(c'=1 to |A|) Zc' + ε|A|), (3)

trong đó ε = 10^-8 là một hằng số dương nhỏ để tránh chia cho không. Người ta có thể đơn giản chọn ˆAc với PB(ˆAc) lớn nhất làm dự đoán. Một phương pháp hiệu quả hơn, như sẽ được thể hiện trong Phần 3.3, là kết hợp các xác suất thu được từ lập luận thuận và nghịch.

3.3 FOBAR (Lập luận Thuận và Nghịch)
Vì lập luận thuận và nghịch bổ sung cho nhau (tức là lập luận nghịch có thể thành công trong những trường hợp mà lập luận thuận thất bại, và ngược lại, như thể hiện trong Ví dụ C.1 và C.2 trong Phụ lục C), chúng tôi đề xuất kết hợp chúng để xác minh. Trực quan, một câu trả lời ứng viên có khả năng đúng khi nó nhận được nhiều phiếu bầu trong lập luận thuận và cũng giúp LLM dự đoán các số bị che trong lập luận nghịch. Chúng tôi ước tính xác suất mà ˆAc đúng là

P(ˆAc) ∝ PF(ˆAc)^α PB(ˆAc)^(1-α), (4)

với trọng số α ∈ [0,1] (xem Hình 2, dưới). Khi α = 1, nó rút gọn thành Tự-Nhất quán (Wang et al., 2023); Khi α bằng 0, nó rút gọn thành lập luận nghịch để xác minh. Trong các thí nghiệm, chúng tôi kết hợp các xác suất thuận và nghịch bằng trung bình hình học (tức là α = 0.5) vì chúng tôi kỳ vọng câu trả lời ứng viên cuối cùng có xác suất không đáng kể trong cả hai hướng thuận và nghịch. Cuối cùng, chúng tôi chọn câu trả lời là arg max ˆAc∈A P(ˆAc). Toàn bộ quy trình được thể hiện trong Thuật toán 1. Vì tất cả các tính toán xác suất đều đơn giản, chi phí tính toán bổ sung của Thuật toán 1 là không đáng kể.

So với việc huấn luyện một LLM làm trình xác minh (Cobbe et al., 2021), điều này tốn kém về mặt tính toán và tốn nhiều công sức trong việc thu thập dữ liệu chú thích bổ sung, FOBAR không cần huấn luyện (do đó, không cần thu thập dữ liệu bổ sung) và hiệu quả hơn trong xác minh (Bảng 6 trong Phụ lục D.1). Lập luận nghịch được đề xuất có thể được kết hợp với các phương pháp lập luận thuận khác như xác minh từng bước được đề xuất bởi Ling et al. (2023) (Bảng 7 trong Phụ lục D.2).

3.4 Mở rộng cho Các Nhiệm vụ Phi Toán học
Trong các câu hỏi toán học, số là những từ chứa thông tin nhất. Đối với các nhiệm vụ phi toán học, chúng ta có thể tương tự che một từ chứa thông tin và yêu cầu LLM đoán từ bị che khi được cung cấp một câu trả lời ứng viên. Ví dụ, xem xét cặp câu hỏi-câu trả lời sau đây từ nhiệm vụ Nối Chữ cái Cuối (Wei et al., 2022; Zhou et al., 2023): "Lấy chữ cái cuối của mỗi từ trong 'Whitney Erika Tj Benito' và nối chúng lại" với câu trả lời thực tế "yajo". Chúng ta có thể che một trong bốn từ (ví dụ: "Erika"). Với một câu trả lời ứng viên ˆAc, chúng ta tạo một câu hỏi nghịch như "Lấy chữ cái cuối của mỗi từ trong 'Whitney Tj Benito' và nối chúng lại. Nếu chúng ta biết câu trả lời của câu hỏi trên là ˆAc, từ ở chỗ trống là Erika hay Dqhjz", trong đó "Dqhjz" được thu được bằng cách dịch chuyển mỗi chữ cái của "Erika". LLM có nhiều khả năng chọn "Erika" nếu chữ cái thứ hai trong ˆAc là "a".

--- TRANG 3 ---
Trả lời: Jim dành 2 giờ xem TV ... dành 4*9=36 giờ cho TV và đọc sách. Câu trả lời là 36. Trả lời: Jim dành 2 giờ xem TV và đọc sách trong nửa thời gian ... Câu trả lời là 12. ...

Câu hỏi: Jim dành 2 giờ xem TV và sau đó quyết định đi ngủ và đọc sách trong nửa thời gian đó. Anh ấy làm điều này 3 lần một tuần. Anh ấy dành bao nhiêu giờ cho TV và đọc sách trong 4 tuần? (câu trả lời: 36)

Lập luận Thuận

FOBAR: Lập luận Thuận-Nghịch

Trả lời: Jim dành 2 giờ ... Giá trị của x là 3. Trả lời: Jim xem TV 2 giờ, sau đó ... Giá trị của x là 3. ...

Câu hỏi: Jim dành 2 giờ xem TV và sau đó quyết định đi ngủ và đọc sách trong nửa thời gian đó. Anh ấy làm điều này x lần một tuần. Anh ấy dành bao nhiêu giờ cho TV và đọc sách trong 4 tuần? Nếu chúng ta biết câu trả lời của câu hỏi trên là 36, giá trị của biến không xác định x là gì?

Trả lời: Jim dành 2 giờ ... Giá trị của x là 4. Trả lời: Jim xem TV 2 giờ ... Giá trị của x là 3.

Câu hỏi: Jim dành 2 giờ xem TV và sau đó quyết định đi ngủ và đọc sách trong nửa thời gian đó. Anh ấy làm điều này x lần một tuần. Anh ấy dành bao nhiêu giờ cho TV và đọc sách trong 4 tuần? Nếu chúng ta biết câu trả lời của câu hỏi trên là 12, giá trị của biến không xác định x là gì? ...

Lập luận Nghịch

A = {ˆAc}|A| c=1 các câu trả lời ứng viên (MF đường dẫn lập luận)
Zc ≡ #{các chuỗi nghịch chính xác|ˆAc}
ε = 10^-8
PF(ˆAc) = 1/MF ∑(i=1 to MF) I(Ai = ˆAc)
PB(ˆAc) = (Zc + ε) / (∑(c'=1 to |A|) Zc' + ε|A|)
P(ˆAc) ∝ (PF(ˆAc))^α (PB(ˆAc))^(1-α)

Hình 2: Tổng quan về lập luận thuận/nghịch và FOBAR được đề xuất. Quy trình chi tiết được thể hiện trong Thuật toán 1.

Thuật toán 1 FOBAR.
Yêu cầu: số chuỗi lập luận MF và MB, các gợi ý PF và PB; ε = 10^-8; α = 0.5;
1: Đầu vào: một câu hỏi Q với NQ số;
2: đưa (PF, Q) cho LLM, lấy mẫu MF chuỗi lập luận với các câu trả lời ứng viên {Ai}MF i=1;
3: loại bỏ trùng lặp {Ai}MF i=1 thành A = {ˆAc}|A| c=1;
4: tính PF(ˆAc) bằng Phương trình (1) cho ˆAc ∈ A;
5: for ˆAc ∈ A do
6: for n = 1, ..., NQ do
7: tạo ˆQ(n) bằng cách che số thứ n num(n) trong Q;
8: đưa (PB, ˆQ(n), T(ˆAc)) cho LLM;
9: lấy mẫu MB dự đoán {dnum(n) c,b}MB b=1;
10: end for
11: tính Zc bằng Phương trình (2);
12: end for
13: tính PB(ˆAc) bằng Phương trình (3) cho ˆAc ∈ A;
14: tính P(ˆAc) bằng Phương trình (4) cho ˆAc ∈ A;
15: return arg max ˆAc∈A P(ˆAc).

4 Thí nghiệm
4.1 Thiết lập
Bộ dữ liệu. Các thí nghiệm được tiến hành trên sáu bộ dữ liệu toán học chuẩn được sử dụng phổ biến trong việc đánh giá khả năng lập luận CoT (Zheng et al., 2023; Wang et al., 2023): (i) AddSub (Hosseini et al., 2014), (ii) MultiArith (Roy và Roth, 2015), (iii) SingleEQ (Koncel-Kedziorski et al., 2015), (iv) SVAMP (Patel et al., 2021), (v) GSM8K (Cobbe et al., 2021), (vi) AQuA (Ling et al., 2017). Một số thống kê và các cặp câu hỏi-câu trả lời ví dụ được hiển thị trong Bảng 8 trong Phụ lục E. Câu hỏi trong AddSub và SingleEQ dễ hơn và không cần tính toán nhiều bước. Câu hỏi trong các bộ dữ liệu khác thách thức hơn vì cần nhiều bước.

Đường cơ sở. Chúng tôi so sánh FOBAR được đề xuất với (i) Học Trong Ngữ cảnh (ICL) sử dụng các cặp câu hỏi-câu trả lời làm minh chứng (Brown et al., 2020), và các phương pháp gợi ý CoT gần đây, bao gồm: (ii) gợi ý CoT (Wei et al., 2022); (iii) gợi ý ComplexCoT (Fu et al., 2023) chọn các minh chứng với các bước lập luận phức tạp; (iv) RE2 (Xu et al., 2023) đọc lại câu hỏi trong gợi ý; (v) PHP (Zheng et al., 2023) lặp lại sử dụng các câu trả lời trước đó làm gợi ý trong việc thiết kế gợi ý; (vi) RCoT (Xue et al., 2023) tái tạo câu hỏi dựa trên câu trả lời ứng viên và kiểm tra sự không nhất quán về mặt thực tế để xác minh; (vii) RCI (Kim et al., 2023) đệ quy phê bình và cải thiện đầu ra trước đó của nó; (viii) Tự-Nhất quán (Wang et al., 2023), lấy mẫu nhiều chuỗi lập luận và chọn câu trả lời bằng bỏ phiếu đa số; (ix) Tự-Xác minh (Weng et al., 2023), chọn 2 câu trả lời ứng viên hàng đầu thu được từ Tự-Nhất quán và sắp xếp lại chúng dựa trên điểm số xác minh được tính trong quy trình nghịch.

Theo Zheng et al. (2023), chúng tôi thí nghiệm với ba LLM: (i) text-davinci-003 (OpenAI, 2022a), (ii) GPT-3.5-Turbo (OpenAI, 2022b), và (iii) GPT-4 (OpenAI, 2023). GPT-3.5-Turbo và GPT-4 mạnh hơn text-davinci-003. FOBAR được đề xuất là tổng quát và có thể được tích hợp vào bất kỳ phương pháp gợi ý nào. Ở đây, chúng tôi chọn gợi ý CoT và gợi ý ComplexCoT làm gợi ý cơ sở như trong Zheng et al. (2023).

Chi tiết Triển khai. Theo (Wang et al., 2023; Zhou et al., 2023; Zheng et al., 2023), nhiệt độ lấy mẫu là 0.7 cho cả lập luận thuận và nghịch. α trong Phương trình (4) được đặt thành 0.5. Đối với text-davinci-003, MF là 40 như trong (Wang et al., 2023; Zheng et al., 2023); trong khi các LLM mạnh hơn (GPT-3.5-Turbo và GPT-4) sử dụng MF nhỏ hơn (tức là 10). MB được đặt thành 8 cho cả ba LLM. Chúng tôi không lặp lại các thí nghiệm sử dụng các seed khác nhau vì truy vấn LLM của OpenAI tốn kém, điều này là một giao thức tiêu chuẩn trong nghiên cứu dựa trên CoT (Fu et al., 2023; Wang et al., 2023; Zhou et al., 2023). Số chuỗi thuận giống nhau cho Tự-Nhất quán, Tự-Xác minh, và FOBAR, trong khi số chuỗi nghịch giống nhau cho Tự-Xác minh và FOBAR.

4.2 Kết quả Chính
Bảng 1 hiển thị độ chính xác kiểm tra. Như có thể thấy, đối với cả ba LLM, FOBAR với gợi ý ComplexCoT đạt độ chính xác trung bình cao nhất, cho thấy FOBAR hiệu quả trong việc xác minh các câu trả lời ứng viên. Phát hiện mới này cho thấy xác minh là một hướng đầy hứa hẹn để cải thiện hiệu suất của các phương pháp dựa trên CoT. Khi sử dụng CoT làm gợi ý cơ sở, FOBAR vượt trội so với Tự-Nhất quán hầu hết thời gian, chứng minh rằng kết hợp lập luận thuận và nghịch tốt hơn việc chỉ sử dụng lập luận thuận. Hơn nữa, FOBAR hoạt động tốt hơn Tự-Xác minh trên hầu hết các bộ dữ liệu, chứng minh rằng việc sử dụng mẫu đơn giản được đề xuất trong lập luận nghịch và sự kết hợp được đề xuất hiệu quả hơn trong xác minh. FOBAR (với CoT hoặc ComplexCoT) trên GPT-4 đạt độ chính xác trung bình cao nhất, vì GPT-4 hiện tại là LLM SOTA. Hơn nữa, đối với cả ba LLM, FOBAR sử dụng ComplexCoT làm gợi ý cơ sở đạt độ chính xác cao hơn so với việc sử dụng CoT trung bình, điều này phù hợp với quan sát trong (Fu et al., 2023; Zheng et al., 2023) rằng ComplexCoT tốt hơn CoT.

4.3 Kết hợp Xác suất Thuận và Nghịch
Trong thí nghiệm này, chúng tôi nghiên cứu cách trọng số kết hợp α trong Phương trình (4) ảnh hưởng đến hiệu suất. Hình 3 hiển thị độ chính xác kiểm tra (trung bình trên sáu bộ dữ liệu) với α ∈ [0,1] sử dụng ba LLM. Như có thể thấy, FOBAR không nhạy cảm với α trong một phạm vi lớn đối với cả ba LLM. Trong phần tiếp theo, chúng tôi sử dụng α = 0.5, tương ứng với trung bình hình học của xác suất thuận và nghịch.

Ngoài ra, người ta có thể kết hợp các xác suất thuận và nghịch bằng trung bình số học, tức là P(ˆAc) = 1/2 [PF(ˆAc) + PB(ˆAc)]. Hình 4 hiển thị độ chính xác kiểm tra cho ba LLM. Như thể hiện, trung bình số học có hiệu suất tương đương với trung bình hình học. Do đó, Hình 3 và 4 cùng nhau cho thấy FOBAR mạnh mẽ đối với việc kết hợp xác suất thuận và nghịch.

--- TRANG 4 ---
Bảng 1: Độ chính xác kiểm tra (%) trên sáu bộ dữ liệu sử dụng ba LLM. Đối với mỗi LLM, các phương pháp được nhóm theo gợi ý cơ sở mà chúng sử dụng. Tốt nhất trong mỗi nhóm được in đậm. Kết quả với † là từ các bài báo gốc. "–" có nghĩa là kết quả không được báo cáo trong bài báo gốc.

AddSub MultiArith SingleEQ SVAMP GSM8K AQuA Trung bình

text-davinci-003
ICL (Brown et al., 2020) 90.4 37.6 84.3 69.1 16.9 29.1 54.5

CoT
CoT (Wei et al., 2022) 91.4 93.6 92.7 79.5 55.8 46.5 76.6
PHP†(Zheng et al., 2023) 91.1 94.0 93.5 81.3 57.5 44.4 77.0
RE2†(Xu et al., 2023) 91.7 93.3 93.3 81.0 61.6 44.5 77.6
Tự-Nhất quán (Wang et al., 2023) 91.7 95.9 94.5 83.1 67.9 55.1 81.4
Tự-Xác minh (Weng et al., 2023) 87.4 95.3 92.9 82.2 59.8 37.4 75.8
FOBAR 91.9 100.0 96.1 86.8 70.8 55.1 83.5

ComplexCoT
ComplexCoT (Fu et al., 2023) 88.9 95.3 93.7 78.0 67.7 48.8 78.7
PHP†(Zheng et al., 2023) 91.6 96.6 95.0 83.7 68.4 53.1 81.4
Tự-Nhất quán (Wang et al., 2023) 89.4 98.5 91.1 82.7 79.1 58.7 83.2
Tự-Xác minh (Weng et al., 2023) 89.9 95.5 94.1 80.1 72.0 38.2 78.3
FOBAR 90.6 100.0 95.3 87.0 78.7 58.7 85.0

GPT-3.5-Turbo
ICL (Brown et al., 2020) 88.6 87.6 88.8 80.6 32.2 31.1 68.2

CoT
CoT (Wei et al., 2022) 89.4 97.9 92.9 84.2 77.2 54.3 82.7
RE2†(Xu et al., 2023) 89.9 96.5 95.3 80.0 80.6 58.3 83.4
Tự-Nhất quán (Wang et al., 2023) 90.6 98.6 93.1 86.4 81.9 62.6 85.5
Tự-Xác minh (Weng et al., 2023) 90.4 97.4 92.9 83.1 74.9 60.6 83.2
FOBAR 89.4 99.3 94.5 88.9 85.1 62.6 86.6

ComplexCoT
ComplexCoT (Fu et al., 2023) 87.9 98.3 94.5 81.1 80.7 59.1 83.6
RCoT†(Xue et al., 2023) 88.2 – 93.0 84.9 84.6 53.3 –
PHP†(Zheng et al., 2023) 85.3 98.0 92.9 83.1 85.1 60.6 84.2
RCI†(Kim et al., 2023) 90.6 99.21 93.7 87.4 84.3 – –
Tự-Nhất quán (Wang et al., 2023) 88.1 98.8 94.5 85.0 86.4 63.0 86.0
Tự-Xác minh (Weng et al., 2023) 87.9 96.6 93.3 81.0 78.2 61.4 83.1
FOBAR 88.4 99.8 94.3 88.5 87.4 63.4 87.0

GPT-4
ICL (Brown et al., 2020) 92.1 98.6 94.3 90.9 48.5 48.0 78.7

CoT
CoT (Wei et al., 2022) 92.7 99.0 95.7 92.9 93.4 69.7 90.6
Tự-Nhất quán (Wang et al., 2023) 92.2 99.0 95.9 93.3 94.8 71.3 91.1
Tự-Xác minh (Weng et al., 2023) 92.7 99.0 95.7 93.1 93.7 70.1 90.7
FOBAR 92.4 99.0 96.1 94.1 95.4 71.3 91.4

ComplexCoT
ComplexCoT (Fu et al., 2023) 91.9 98.3 94.5 92.4 95.1 72.4 90.8
PHP†(Zheng et al., 2023) 89.6 98.1 93.1 91.9 95.5 79.9 91.3
Tự-Nhất quán (Wang et al., 2023) 91.4 98.5 94.7 93.4 96.2 75.2 91.6
Tự-Xác minh (Weng et al., 2023) 91.6 98.5 94.7 93.0 95.7 75.6 91.5
FOBAR 91.9 98.6 94.7 94.4 96.4 75.2 91.9

[Các hình 3-8 và bảng 2-5 tiếp theo được dịch tương tự...]

4.4 Tính hữu ích của Lập luận Thuận và Nghịch
Chúng tôi thực hiện một nghiên cứu phân tích trên lập luận thuận (FO) và nghịch (BA). Chúng tôi xem xét bốn kết hợp: (i) không sử dụng lập luận thuận hay nghịch (rút gọn thành giải mã tham lam (Wei et al., 2022)); (ii) chỉ sử dụng lập luận thuận (tức là Tự-Nhất quán); (iii) chỉ sử dụng lập luận nghịch trong việc chọn câu trả lời (tức là α = 0 trong Thuật toán 1); (iv) sử dụng cả lập luận thuận và nghịch (tức là FOBAR được đề xuất).

Bảng 2 hiển thị độ chính xác kiểm tra (trung bình trên sáu bộ dữ liệu) cho ba LLM. Như có thể thấy, trong tất cả các thiết lập, việc sử dụng lập luận thuận hoặc nghịch luôn tốt hơn việc không sử dụng chúng. Hơn nữa, kết hợp lập luận thuận và nghịch luôn là tốt nhất. Ví dụ C.1 và C.2 trong Phụ lục C cho thấy FOBAR có thể sửa chữa một số trường hợp thất bại của lập luận thuận và nghịch tương ứng.

4.5 Câu trả lời Ứng viên Đúng Giúp Lập luận Nghịch
Trong thí nghiệm này, chúng tôi xác minh trực quan rằng câu trả lời ứng viên đúng giúp LLM dự đoán các số bị che. Hình 5 so sánh độ chính xác dự đoán các số bị che trong câu hỏi nghịch với các ứng viên đúng/sai. Như có thể thấy, việc sử dụng ứng viên đúng có độ chính xác cao gấp 2 lần (trung bình trên sáu bộ dữ liệu) so với những ứng viên sai trong việc dự đoán số bị che, chứng minh rằng việc sử dụng lập luận nghịch để xác minh câu trả lời ứng viên là hợp lý.

4.6 Số Chuỗi Lập luận Thuận và Nghịch
4.6.1 Thay đổi MF
Trong phần này, chúng tôi nghiên cứu cách hiệu suất của FOBAR thay đổi theo số chuỗi lập luận thuận MF. Hình 6 hiển thị độ chính xác kiểm tra (trung bình trên sáu bộ dữ liệu) cho ba LLM. Như có thể thấy, việc sử dụng MF rất nhỏ (ví dụ ≤ 5) rõ ràng là không mong muốn, nhưng độ chính xác bão hòa nhanh chóng khi MF tăng. Điều này cho thấy người ta có thể sử dụng MF nhỏ để giảm chi phí tính toán. Hơn nữa, các đường cong độ chính xác của FOBAR cao hơn so với Tự-Nhất quán trong Hình 7, một lần nữa chứng minh rằng việc tích hợp lập luận nghịch vào xác minh là hiệu quả.

4.6.2 Thay đổi MB
Tiếp theo, chúng tôi nghiên cứu cách hiệu suất của FOBAR thay đổi theo số chuỗi lập luận nghịch MB. Hình 8 hiển thị độ chính xác kiểm tra (trung bình trên sáu bộ dữ liệu) cho ba LLM. Lưu ý rằng MB = 0 tương ứng với việc chỉ sử dụng lập luận thuận. Như thể hiện, việc sử dụng MB rất nhỏ (ví dụ ≤ 4) rõ ràng là không mong muốn, nhưng độ chính xác bão hòa nhanh chóng khi MB tăng. Do đó, việc sử dụng MB nhỏ có thể đạt được sự cân bằng tốt giữa hiệu suất và hiệu quả.

4.7 Mở rộng cho Các Nhiệm vụ Phi Toán học
Trong phần này, chúng tôi thực hiện thí nghiệm trên hai nhiệm vụ phi toán học thường được sử dụng: Hiểu Ngày tháng (Wei et al., 2022; Fu et al., 2023) và Nối Chữ cái Cuối (Wei et al., 2022; Zhou et al., 2023). Các ví dụ được hiển thị trong Bảng 8 (Phụ lục E). Chúng tôi so sánh FOBAR với các phương pháp dựa trên CoT khác và ICL sử dụng GPT-3.5-Turbo. PHP không báo cáo kết quả trên các nhiệm vụ phi toán học.

Bảng 3 hiển thị độ chính xác kiểm tra. Như thể hiện, FOBAR hoạt động tốt hơn tất cả các đường cơ sở với CoT hoặc ComplexCoT làm gợi ý cơ sở. Hơn nữa, tất cả các phương pháp dựa trên CoT đều vượt trội đáng kể so với ICL.

4.8 Trường hợp Thất bại của Tự-Nhất quán và FOBAR
Chúng tôi tiến hành phân tích về các trường hợp thất bại của Tự-Nhất quán và FOBAR trên sáu bộ dữ liệu, sử dụng GPT-3.5-Turbo với gợi ý ComplexCoT.

Bảng 4 hiển thị số trường hợp thất bại của Tự-Nhất quán, với việc phân tích thành số trường hợp không có chuỗi nào đạt đến câu trả lời đúng và ít nhất một chuỗi đạt đến câu trả lời đúng. Như có thể thấy, khoảng 60% tổng số trường hợp thất bại có ít nhất một chuỗi đúng (40% còn lại không có chuỗi đúng và do đó không thể được giải quyết bằng lập luận nghịch). Những trường hợp 60% này có thể được sửa chữa bằng một trình xác minh tốt hơn (như FOBAR được đề xuất).

Bảng 5 hiển thị thống kê về các trường hợp thất bại của FOBAR. Như có thể thấy, FOBAR sửa chữa 54 (tức là 294−240) trong số 294 trường hợp thất bại có ít nhất một câu trả lời đúng trong Tự-Nhất quán.

5 Kết luận
Trong bài báo này, chúng tôi nghiên cứu vấn đề xác minh các câu trả lời ứng viên cho các bài toán toán học sử dụng gợi ý chuỗi suy nghĩ. Để bổ sung cho việc chỉ sử dụng lập luận thuận để xác minh, chúng tôi giới thiệu lập luận nghịch: Một mẫu đơn giản được giới thiệu để tạo câu hỏi và một gợi ý được thiết kế để yêu cầu LLM dự đoán một từ bị che khi một câu trả lời ứng viên được cung cấp. Hơn nữa, chúng tôi đề xuất FOBAR để kết hợp lập luận thuận và nghịch cho việc xác minh. Các thí nghiệm rộng rãi trên sáu bộ dữ liệu toán học tiêu chuẩn và ba LLM cho thấy FOBAR được đề xuất đạt hiệu suất tối tân trên các nhiệm vụ lập luận toán học. FOBAR cũng có thể được sử dụng trên các nhiệm vụ phi toán học và đạt hiệu suất vượt trội.

Hạn chế và Rủi ro Tiềm ẩn
Hạn chế Trong bài báo này, chúng tôi tập trung vào các nhiệm vụ lập luận toán học, với phần mở rộng cho hai nhiệm vụ lập luận phi toán học. Tuy nhiên, việc mở rộng cho các nhiệm vụ lập luận phi toán học phức tạp hơn như Trả lời Câu hỏi Thường thức (CSQA) (Wei et al., 2022) và StrategyQA (Wei et al., 2022; Fu et al., 2023) vẫn cần được khám phá, vì việc xác định các từ chứa thông tin để che là thách thức hơn.

Khi một số trong câu hỏi thừa (không cần thiết trong việc giải quyết câu hỏi), số đó có thể không thể dự đoán được khi một câu trả lời ứng viên được cung cấp. Do đó, các số thừa có thể không ảnh hưởng đến số chuỗi nghịch đúng Zc, chủ yếu phụ thuộc vào các số quan trọng. Vì vậy, FOBAR vẫn có thể áp dụng. Mặc dù việc tránh che các số dư thừa sẽ chính xác hơn, việc kiểm tra xem một số có dư thừa hay không là thách thức và sẽ được nghiên cứu trong công trình tương lai của chúng tôi.

Rủi ro Tiềm ẩn Tất cả các bộ dữ liệu được sử dụng trong công trình này không chứa bất kỳ thông tin nào đặt tên hoặc xác định duy nhất các cá nhân hoặc nội dung công kích. Do đó, không có mối lo ngại về các cân nhắc đạo đức và quyền riêng tư dữ liệu.

[Phần Acknowledgement và References tiếp theo...]

Lời cảm ơn
Công trình này được hỗ trợ bởi NSFC key grant 62136005, NSFC general grant 62076118, và chương trình nghiên cứu cơ bản Thâm Quyến JCYJ20210324105000003. Nghiên cứu này được hỗ trợ một phần bởi Hội đồng Nghiên cứu Cấp phí của Đặc khu Hành chính Hồng Kông (Grants 16200021 và 16202523).

[Phần References dài được dịch tương tự...]

--- TRANG 10 ---
[Tiếp tục dịch các trang còn lại với cấu trúc tương tự, bao gồm các bảng thống kê, ví dụ, và phụ lục...]

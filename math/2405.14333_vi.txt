I'll translate this PDF content to Vietnamese while maintaining the exact structure and formatting.

# 2405.14333.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2405.14333.pdf
# Kích thước tệp: 601408 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
DeepSeek-Prover: Thúc đẩy Chứng minh Định lý trong
LLMs thông qua Dữ liệu Tổng hợp Quy mô Lớn
Huajian Xin1,2Daya Guo1Zhihong Shao1Z.Z. Ren1Qihao Zhu1Bo Liu1
Chong Ruan1Wenda Li3Xiaodan Liang2,4∗
1DeepSeek2Sun Yat-sen University3University of Edinburgh4MBZUAI
{xinhj, guoday, zhihongshao, rzz, zhuqh, chong.ruan}@deepseek.com,
benjaminliu.eecs@gmail.com, wli8@ed.ac.uk, xdliang328@gmail.com
Tóm tắt
Các trợ lý chứng minh như Lean đã cách mạng hóa việc xác minh chứng minh toán học,
đảm bảo độ chính xác và độ tin cậy cao. Mặc dù các mô hình ngôn ngữ lớn (LLMs)
cho thấy tiềm năng trong lý luận toán học, sự tiến bộ của chúng trong chứng minh định lý
chính thức bị cản trở bởi việc thiếu dữ liệu huấn luyện. Để giải quyết vấn đề này, chúng tôi giới
thiệu một phương pháp để tạo ra dữ liệu chứng minh Lean 4 mở rộng có nguồn gốc từ các
bài toán thi đấu toán học cấp trung học và đại học. Phương pháp này bao
gồm việc dịch các bài toán ngôn ngữ tự nhiên thành các phát biểu chính thức, lọc ra
các phát biểu chất lượng thấp, và tạo ra các chứng minh để tạo dữ liệu tổng hợp. Sau khi tinh
chỉnh mô hình DeepSeekMath 7B trên tập dữ liệu tổng hợp này, bao gồm
8 triệu phát biểu chính thức với chứng minh, mô hình của chúng tôi đạt được độ chính xác tạo
chứng minh toàn bộ là 46.3% với 64 mẫu và 52% tích lũy trên bài kiểm tra Lean
4 miniF2F, vượt qua đường cơ sở GPT-4 ở 23.0% với 64 mẫu và một
phương pháp học tăng cường tìm kiếm cây ở 41.0%. Ngoài ra, mô hình của chúng tôi
đã chứng minh thành công 5 trong số 148 bài toán trong chuẩn mực Lean 4 Formalized International
Mathematical Olympiad (FIMO), trong khi GPT-4 thất bại trong việc chứng minh bất kỳ bài nào.
Những kết quả này chứng minh tiềm năng của việc tận dụng dữ liệu tổng hợp quy mô lớn để
tăng cường khả năng chứng minh định lý trong LLMs. Cả tập dữ liệu tổng hợp và
mô hình sẽ được cung cấp để hỗ trợ nghiên cứu thêm trong lĩnh vực đầy hứa hẹn này.

1 Giới thiệu
Trong toán học hiện đại, sự phức tạp ngày càng tăng của các chứng minh đưa ra những thách thức đáng kể cho
việc đánh giá đồng nghiệp. Sự phức tạp này đã dẫn đến việc chấp nhận các chứng minh sai lầm, với những lỗ hổng nghiêm trọng
thường chỉ được phát hiện sau một thời gian đáng kể. Để giải quyết những vấn đề này, các ngôn ngữ toán học chính thức
như Lean [De Moura et al., 2015, Moura and Ullrich, 2021], Isabelle [Paulson, 1994], và
Coq [The Coq Development Team] đã được phát triển. Những ngôn ngữ này cho phép tạo ra
các chứng minh có thể xác minh bằng máy tính [Avigad, 2023]. Tuy nhiên, việc tạo ra các chứng minh chính thức đòi hỏi nỗ lực đáng kể,
chuyên môn chuyên biệt, và đặt ra thách thức ngay cả đối với các nhà toán học dày dạn kinh nghiệm. Do đó,
tầm quan trọng của chứng minh định lý tự động đang gia tăng [Shulman, 2024].

Để giảm bớt nỗ lực liên quan đến việc viết các chứng minh toán học chính thức, một số phương pháp [Polu and
Sutskever, 2020, Jiang et al., 2021, Han et al., 2021, Polu et al., 2022, Lample et al., 2022, Jiang et al.,
2022a, Yang et al., 2024] đã được phát triển, chủ yếu tập trung vào các thuật toán tìm kiếm khám phá
các giải pháp tiềm năng cho các định lý được đề xuất. Tuy nhiên, những phương pháp này thường gặp khó khăn với không gian tìm kiếm rộng lớn
cần thiết cho các định lý phức tạp, khiến chúng không hiệu quả đối với các chứng minh phức tạp hơn [Loos
et al., 2017]. Gần đây, những tiến bộ trong các mô hình ngôn ngữ lớn (LLMs) đã giới thiệu một chiến lược mới,
∗Tác giả liên hệ.
Preprint. Đang được xem xét.arXiv:2405.14333v1  [cs.AI]  23 May 2024

--- TRANG 2 ---
sử dụng các mô hình được huấn luyện trước để hướng dẫn quá trình tìm kiếm. Mặc dù những phương pháp mới này [Jiang et al.,
2022b, Zhao et al., 2023, Xin et al., 2023] đại diện cho những cải tiến đáng kể, chúng vẫn chưa đạt đến
khả năng ứng dụng thực tế do thiếu corpus song song. Không giống như các ngôn ngữ lập trình thông thường
như Python hoặc Java, các ngôn ngữ chứng minh chính thức được sử dụng bởi tương đối ít nhà toán học, dẫn đến
các tập dữ liệu hạn chế. Những tiến bộ gần đây trong tự động hóa chính thức [Wu et al., 2022] cho phép tổng hợp thêm dữ liệu phù hợp
để huấn luyện các trình chứng minh định lý tự động dựa trên LLM. Tuy nhiên, tập dữ liệu kết quả
vẫn quá nhỏ để hoàn toàn khai thác khả năng của LLMs.

Để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp để tạo ra dữ liệu chứng minh Lean 4 mở rộng từ các
bài toán toán học không chính thức. Phương pháp của chúng tôi dịch các bài toán thi đấu toán học cấp trung học và đại học thành các phát biểu chính thức. Sau đó chúng tôi tự động hóa việc tạo chứng minh sử dụng một
mô hình ngôn ngữ lớn (LLM) và xác minh tính đúng đắn của những chứng minh này trong môi trường Lean 4.
Thách thức chính của phương pháp này là đảm bảo cả quy mô và chất lượng của dữ liệu tổng hợp.

Đảm bảo Chất lượng: Chúng tôi nâng cao chất lượng của các chứng minh được tạo ra thông qua một quy trình nhiều bước.
Đầu tiên, chúng tôi lọc ra các phát biểu đơn giản sử dụng một mô hình chấm điểm chất lượng và loại trừ các phát biểu không hợp lệ
thông qua một chiến lược bác bỏ giả thuyết. Khung làm việc lặp mới của chúng tôi sau đó cải thiện chất lượng chứng minh bằng cách
ban đầu tạo ra các phát biểu tổng hợp từ các bài toán toán không chính thức sử dụng một LLM chưa được huấn luyện đầy đủ
được tinh chỉnh trên dữ liệu hạn chế. Những phát biểu này được sử dụng để tạo ra các chứng minh tương ứng, được
xác thực tính đúng đắn sử dụng một trình xác minh Lean 4. Các cặp định lý-chứng minh đúng sau đó được
sử dụng để huấn luyện thêm mô hình ban đầu. Thông qua nhiều lần lặp, mô hình được huấn luyện trên dữ liệu
tổng hợp quy mô lớn trở nên mạnh mẽ hơn đáng kể so với các LLM chưa được huấn luyện đầy đủ ban đầu, dẫn đến
các cặp định lý-chứng minh chất lượng cao hơn.

Đảm bảo Quy mô: Để tăng tốc quá trình tạo chứng minh, phương pháp của chúng tôi giải quyết thách thức
của không gian tìm kiếm lớn cho các chứng minh. Một nguyên nhân đáng kể gây chậm trễ là việc tạo ra các phát biểu không thể chứng minh
mà tiếp tục được xử lý cho đến khi chúng đạt đến giới hạn thời gian. Để giảm thiểu điều này, chúng tôi đề xuất
chứng minh các phát biểu phủ định song song. Một khi phát biểu gốc hoặc phủ định của nó được chứng minh,
toàn bộ quá trình chứng minh được chấm dứt.

Chúng tôi đánh giá hiệu quả của phương pháp này trên chứng minh định lý Lean 4 sử dụng 488 bài toán từ
miniF2F [Zheng et al., 2021] và 148 bài toán từ các chuẩn mực FIMO [Liu et al., 2023]. Chúng tôi
sử dụng DeepSeekMath 7B [Shao et al., 2024], một mô hình toán học tiên tiến, làm cơ sở. Các
kết quả cho thấy mô hình được huấn luyện lặp của chúng tôi hoạt động mạnh mẽ, đạt được 46.3% độ chính xác trong tạo
chứng minh toàn bộ trên chuẩn mức miniF2F-test với 64 mẫu, vượt qua GPT-4 [Achiam et al.,
2023] ở 23.0% và một phương pháp học tăng cường ở 41.0%. Ngoài ra, phương pháp của chúng tôi giải quyết 4
trong số 148 bài toán trong chuẩn mức FIMO với 100 mẫu, trong khi GPT-4 không giải quyết được bài nào, và phương pháp của chúng tôi giải quyết 5 bài với 4096 mẫu. Các thí nghiệm loại bỏ chỉ ra rằng mô hình dần dần
giải quyết được nhiều bài toán hơn trong miniF2F với mỗi lần lặp. Tóm lại, bài báo của chúng tôi đóng góp những điều sau:

•Chúng tôi giới thiệu một phương pháp lặp để tổng hợp 8 triệu phát biểu chính thức, mỗi phát biểu đi kèm
với một chứng minh chính thức, từ các bài toán toán không chính thức. Kết quả thí nghiệm chứng minh
rằng phương pháp này nâng cao đáng kể cả tính mở rộng và chất lượng của dữ liệu tổng hợp.

•Mô hình của chúng tôi, được huấn luyện trên tập dữ liệu tổng hợp này, đạt được hiệu suất tiên tiến trên
các chuẩn mực, với độ chính xác tạo chứng minh toàn bộ là 46.3% sử dụng 64 mẫu và 52%
tích lũy trên bài kiểm tra Lean 4 miniF2F. Điều này vượt qua đường cơ sở GPT-4 ở 23.0% với
64 mẫu và một phương pháp học tăng cường tìm kiếm cây ở 41.0%. Ngoài ra, mô hình của chúng tôi
đã chứng minh thành công 5 trong số 148 bài toán trong chuẩn mực Lean 4 Formalized International
Mathematical Olympiad (FIMO), trong khi GPT-4 thất bại trong việc chứng minh bất kỳ bài nào.

•Chúng tôi đóng góp cho cộng đồng toán học và AI bằng cách tạo ra và mở nguồn một
tập dữ liệu lớn các chứng minh toán học chính thức chất lượng cao, do đó thúc đẩy nghiên cứu thêm
và phát triển trong chứng minh định lý tự động.

2 Bối cảnh và Các Công trình Liên quan
Chứng minh định lý tự động đã là một lĩnh vực quan tâm đáng kể trong nghiên cứu trí tuệ nhân tạo
kể từ khi bắt đầu [Bibel, 2013]. Những nỗ lực ban đầu được hướng đến các khung logic đơn giản hơn, điều này
đã dẫn đến việc phát triển các trình chứng minh định lý bậc một hiệu quả cao như E [Schulz, 2002] và
Vampire [Kovács and Voronkov, 2013]. Tuy nhiên, những công cụ này thường không đủ khả năng xử lý các định lý phức tạp
thường thấy trong các trợ lý chứng minh hiện đại như Lean [De Moura et al., 2015], Isabelle
[Paulson, 1994], và Coq [The Coq Development Team]. Sự ra đời của các mô hình học sâu gần đây
và các kỹ thuật tìm kiếm được hướng dẫn bởi mô hình đã làm sống lại lĩnh vực này [Bansal et al., 2019]. Phương pháp hiện đại
này không chỉ nâng cao khả năng của các hệ thống ATP mà còn mở rộng khả năng ứng dụng của chúng
trong việc giải quyết các bài toán toán học phức tạp hơn.

ATP với Các Mô hình Neural. Với sự phát triển của học sâu, một số phương pháp đã được
đề xuất để kết hợp các mô hình neural với ATP [Loos et al., 2017]. Một loạt các phương pháp ATP áp dụng
các thuật toán tìm kiếm cây được hướng dẫn bởi các mô hình neural [Polu and Sutskever, 2020, Han et al., 2021, Polu
et al., 2022, Jiang et al., 2022a, Yang et al., 2024]. Những phương pháp này chủ yếu sử dụng các kỹ thuật học tăng cường
để nâng cao độ chính xác của mô hình [Kaliszyk et al., 2018, Crouse et al., 2021,
Wu et al., 2021, Lample et al., 2022]. Vì không gian tìm kiếm rất lớn, quá trình tìm kiếm
tiêu tốn thời gian và tài nguyên tính toán đáng kể.

Một loạt phương pháp ATP khác khai thác sức mạnh của các mô hình ngôn ngữ lớn. Những phương pháp này
thường liên quan đến các mô hình ngôn ngữ được tinh chỉnh với dữ liệu chứng minh mã nguồn mở và tương tác với
các trình xác minh thông qua một chương trình chuyển đổi trạng thái-hành động [Polu and Sutskever, 2020, Jiang et al., 2021, Han et al.,
2021, Polu et al., 2022, Lample et al., 2022, Jiang et al., 2022a, Yang et al., 2024]. Quá trình này
lặp đi lặp lại tạo ra các bước chứng minh và xác minh tính đúng đắn của chúng với các trình xác minh chính thức. Sau đó nó tạo ra
các bước chứng minh tiếp theo dựa trên các trạng thái chứng minh được trả về bởi các trình xác minh chính thức. Mặc dù những
phương pháp này đạt được hiệu suất cao, chúng tốn nhiều tính toán. Để nâng cao hiệu quả,
các nghiên cứu gần đây tận dụng các mô hình ngôn ngữ để tạo ra các chứng minh chính thức hoàn chỉnh trực tiếp [First et al.,
2023, Jiang et al., 2022b, Zhao et al., 2023, Xin et al., 2023], do đó bỏ qua tương tác lặp
trong quá trình tạo chứng minh.

Tự động hóa Chính thức cho Toán học Chính thức. Do sự sẵn có hạn chế của các corpus chính thức
để huấn luyện, hiệu suất của các mô hình ngôn ngữ lớn (LLMs) hiện tại cũng bị hạn chế. Do đó,
một số phương pháp đề xuất tự động hóa chính thức [Wu et al., 2022, Jiang et al., 2022b], bao gồm
việc chuyển đổi các mô tả ngôn ngữ tự nhiên thành các phát biểu chính thức có thể được xác minh bởi các trợ lý chứng minh.
Một số nghiên cứu đã tạo ra các tập dữ liệu tổng hợp của các chứng minh chính thức sử dụng các phép biến đổi dựa trên quy tắc
của các định lý hiện có [Wu et al., 2020, Wang and Deng, 2020, Xiong et al., 2023]. Mặc dù hiệu quả,
những phương pháp này bị hạn chế bởi sự phụ thuộc vào các quy tắc được định nghĩa trước và thiếu tính linh hoạt cho các ứng dụng rộng hơn. Các phương pháp gần đây áp dụng các mô hình ngôn ngữ lớn để dịch các bài toán ngôn ngữ tự nhiên
thành các phát biểu chính thức [Huang et al., 2024]. Tuy nhiên, những tập dữ liệu này vẫn nhỏ hơn
mức cần thiết và bị giới hạn trong các chuẩn mức toán học nhỏ, dẫn đến chỉ những cải thiện nhỏ
trong kết quả huấn luyện cho các mô hình ngôn ngữ. Trong bài báo này, chúng tôi hướng đến việc tổng hợp các chứng minh chính thức thông qua
tự động hóa chính thức ở quy mô lớn hơn nhiều để thúc đẩy hiệu suất của một trình chứng minh neural.

3 Phương pháp
Trong phần này, chúng tôi giới thiệu phương pháp của chúng tôi, bao gồm bốn quy trình chính như được mô tả trong
Hình 1. Giai đoạn ban đầu tập trung vào việc tạo ra các phát biểu toán học chính thức từ một bộ sưu tập rộng lớn
của các bài toán toán không chính thức, cần thiết để chứng minh thêm. Tiếp theo, các phát biểu được tự động hóa chính thức
được lọc thông qua các phương pháp chấm điểm mô hình và bác bỏ giả thuyết để chọn các phát biểu chất lượng cao.
Những phát biểu này sau đó được chứng minh bởi một mô hình gọi là DeepSeek-Prover, với tính đúng đắn của chúng được xác minh
bởi trình xác minh chính thức gọi là Lean 42, tạo ra các phát biểu và chứng minh chính thức đã được xác thực. Những dữ liệu này
phục vụ như dữ liệu tổng hợp để tinh chỉnh DeepSeek-Prover. Sau khi nâng cao DeepSeek-Prover,
chúng tôi lặp lại toàn bộ quy trình đã mô tả trước đó. Chu kỳ này tiếp tục cho đến khi những cải thiện trong
DeepSeek-Prover trở nên tối thiểu. Đáng chú ý, để nâng cao hiệu quả chứng minh, chúng tôi chứng minh đồng thời
cả các phát biểu gốc và phủ định của chúng. Phương pháp này có lợi thế là nhanh chóng loại bỏ
phát biểu gốc khi nó không hợp lệ bằng cách chứng minh phủ định của nó. Chi tiết của từng giai đoạn sẽ được
mô tả trong các phần tiếp theo.

3.1 Tự động hóa Chính thức
Việc tạo ra dữ liệu chứng minh chính thức về cơ bản dựa vào sự sẵn có của một corpus đáng kể
của các phát biểu chính thức. Tuy nhiên, trong thực tế, việc tích lũy một bộ sưu tập lớn các phát biểu chính thức
được tạo thủ công là thách thức. May mắn thay, internet đầy những bài toán liên quan đến toán học được biểu đạt bằng
2leanprover /lean4 :v4.7.0−rc2

--- TRANG 3 ---
ngôn ngữ tự nhiên. Bằng cách tự động hóa chính thức những bài toán toán học không chính thức này, chúng ta có thể tạo ra một
kho lưu trữ rộng lớn các phát biểu chính thức.

Chúng tôi đã quan sát thấy rằng các bài toán có điều kiện rõ ràng và mục tiêu được định nghĩa rõ thường dễ dàng
chính thức hóa hơn so với các chủ đề toán học nâng cao đòi hỏi các định nghĩa và cấu trúc phức tạp. Do đó, bài báo này chủ yếu xem xét các bài toán thi đấu cấp trung học và đại học, với trọng tâm đặc biệt vào đại số và lý thuyết số, và ở mức độ thấp hơn, tổ hợp, hình học, và thống kê. Mặc dù có vẻ đơn giản, những bài toán này thường
liên quan đến các kỹ thuật giải quyết phức tạp, khiến chúng trở thành những ứng cử viên xuất sắc để xây dựng dữ liệu chứng minh
nhằm cải thiện khả năng chứng minh định lý trong Các Mô hình Ngôn ngữ Lớn (LLMs). Để biên soạn tập dữ liệu của chúng tôi,
chúng tôi đã sử dụng các kỹ thuật web scraping và làm sạch dữ liệu cẩn thận để trích xuất các bài toán từ các nguồn trực tuyến
có các bài tập, kỳ thi, và cuộc thi cấp trung học và đại học, tạo ra một
tập dữ liệu gồm 869,659 bài toán toán ngôn ngữ tự nhiên chất lượng cao.

Cụ thể, chúng tôi khởi tạo DeepSeek-Prover sử dụng mô hình DeepSeekMath-Base 7B [Shao
et al., 2024]. Ban đầu, mô hình gặp khó khăn trong việc chuyển đổi các bài toán toán không chính thức thành các phát biểu chính thức.
Để giải quyết điều này, chúng tôi tinh chỉnh mô hình DeepSeek-Prover sử dụng tập dữ liệu MMA [Jiang et al.,
2023], bao gồm các phát biểu chính thức từ mathlib3 của Lean 4 được dịch ngược thành
các mô tả bài toán ngôn ngữ tự nhiên bởi GPT-4. Sau đó chúng tôi hướng dẫn mô hình dịch những
bài toán ngôn ngữ tự nhiên này thành các phát biểu chính thức trong Lean 4 sử dụng một phương pháp có cấu trúc.

Gợi ý :
Bài toán Toán học bằng Ngôn ngữ Tự nhiên:
{$informal_statement_with_answers}
Dịch bài toán sang Lean 4 (chỉ khai báo cốt lõi):
"'lean4
Phản hồi :
{$formal_statement}
"'

3.2 Lọc Chất lượng
Chất lượng của các phát biểu được tự động hóa chính thức được phát hiện là không tối ưu do hai vấn đề chính.
Thứ nhất, nhiều phát biểu chính thức quá đơn giản. Để giải quyết điều này, chúng tôi phát triển các tiêu chí chấm điểm
và cung cấp các ví dụ từ miniF2F-valid làm ví dụ few-shot để hướng dẫn mô hình DeepSeek-Prover
3Commit mathlib cụ thể được sử dụng là 64528268b3c2cf578639bc479828882a9ecd3a82 .

--- TRANG 4 ---
trong việc đánh giá nội dung và chất lượng của những phát biểu này sử dụng phương pháp chuỗi suy nghĩ.
Việc xem xét thủ công các điểm số này xác nhận rằng đánh giá của mô hình phù hợp chặt chẽ với trực giác và kỳ vọng của con người. Cụ thể, mô hình được hướng dẫn (xem Phụ lục A.1 để biết gợi ý chi tiết)
để phân loại chất lượng của mỗi phát biểu chính thức thành các danh mục: "xuất sắc," "tốt," "trên trung bình,"
"khá," hoặc "kém." Các phát biểu được đánh giá là "khá" hoặc "kém" sau đó được loại trừ.

Vấn đề thứ hai liên quan đến các phát biểu chính thức mà, mặc dù có thể chứng minh, nhưng dựa trên các giả thuyết không nhất quán dẫn đến các kết luận trống rỗng, khiến các kết luận trở nên vô nghĩa trong toán học.
Ví dụ, xem xét phát biểu do mô hình tạo ra sau đây:
example ( θ:R) (h 0:∀z :C, z ^ 2 = -1 ∧z ^ 3 = -1 ∧z ^ 6 = 1) (h 1:
Real.tan θ= 2 * Real.sqrt 3) : θ= 5 * Real.pi / 3

Ở đây, giả thuyết z2=−1∧z3=−1∧z6= 1 cho tất cả các số phức rõ ràng là sai, khiến
bất kỳ kết luận nào được rút ra đều vô nghĩa. Để loại bỏ những trường hợp như vậy khỏi tập dữ liệu của chúng tôi, chúng tôi triển khai một
phương pháp bác bỏ giả thuyết. Điều này bao gồm việc sử dụng mô hình DeepSeek-Prover để cố gắng chứng minh
phát biểu chính thức với 'False' làm kết luận. Một chứng minh thành công chỉ ra một giả thuyết không hợp lệ,
thúc đẩy việc loại trừ phát biểu. Một ví dụ được hiển thị dưới đây:
example ( θ:R) (h 0:∀z :C, z ^ 2 = -1 ∧z ^ 3 = -1 ∧z ^ 6 = 1) (h 1:
Real.tan θ= 2 * Real.sqrt 3) : False := by
simpa using h 01

Bằng cách áp dụng chiến lược kép này của chấm điểm mô hình và bác bỏ giả thuyết, chúng tôi đã tuyển chọn một tập hợp
tinh lọc gồm 712,073 phát biểu chính thức chất lượng cao, cung cấp một nền tảng vững chắc cho tổng hợp chứng minh tiếp theo.

3.3 Chứng minh Phát biểu
Sau khi tạo ra một corpus đáng kể các phát biểu chính thức chất lượng cao, chúng tôi sử dụng mô hình để
tìm kiếm các chứng minh cho những phát biểu này. Theo truyền thống, các mô hình ngôn ngữ đã được sử dụng chủ yếu
theo cách brute-force để chứng minh các định lý—liên tục cố gắng cho đến khi tìm thấy một chứng minh hợp lệ hoặc
tài nguyên tính toán bị cạn kiệt. Phương pháp này không hiệu quả cho mục đích của chúng tôi. Thông thường,
các mô hình ngôn ngữ được áp dụng cho các phát biểu chính thức được con người tuyển chọn cẩn thận và
nói chung là đúng và có thể chứng minh; tuy nhiên, trong nhiệm vụ chứng minh các phát biểu được tự động hóa chính thức của chúng tôi, nhiều
phát biểu được tạo ra bởi mô hình có thể không chính xác. Thật vậy, việc mong đợi
mô hình xác thực một mệnh đề sai trong bất kỳ hệ thống chứng minh đáng tin cậy nào là không hợp lý. Vấn đề này trở nên rõ ràng hơn
trong quá trình tự động hóa chính thức quy mô lớn, nơi chúng tôi quan sát thấy rằng ít nhất 20% các phát biểu chính thức
được tạo ra bởi mô hình của chúng tôi, ngay cả sau khi lọc chất lượng, đều không chính xác, dẫn đến lãng phí tính toán đáng kể nếu được giải quyết bằng brute force.

Để giảm thiểu lãng phí tài nguyên trên các phát biểu không thể chứng minh và cải thiện hiệu quả của quá trình
tìm kiếm chứng minh, chúng tôi khai thác tính đối xứng logic giữa một phát biểu và phủ định của nó để tăng tốc
tổng hợp chứng minh. Chúng tôi triển khai tìm kiếm chứng minh song song kép cho mỗi phát biểu tổng hợp—một
cho phát biểu Γ⊢P và một khác cho phủ định của nó Γ⊢ ¬P. Việc tìm kiếm chấm dứt ngay khi một
chứng minh hợp lệ được tìm thấy cho một trong hai, một cách quyết định chứng minh tính không thể chứng minh của cái kia. Mỗi luồng tìm kiếm chứng minh cố gắng lên đến k chứng minh trừ khi một chứng minh hợp lệ xuất hiện sớm hơn.

Tất cả các chứng minh đã được xác thực, cho dù chúng biện minh cho các định lý gốc hay phủ định của chúng, sau đó được tổng hợp
để huấn luyện thêm DeepSeek-Prover. Do đó, phương pháp kép này phục vụ như một hình thức tăng cường dữ liệu,
làm phong phú tập dữ liệu với cả các mệnh đề và phủ định của chúng—ngay cả khi các mệnh đề gốc
không được chính thức hóa đúng bởi mô hình.

3.4 Cải tiến Lặp
Vì toàn bộ pipeline phụ thuộc nhiều vào DeepSeek-Prover, việc nâng cao hiệu suất của mô hình
sau mỗi lần lặp là rất quan trọng. Để đạt được điều này, chúng tôi liên tục tinh chỉnh mô hình với dữ liệu
mới được tạo ra. Mô hình đã cập nhật sau đó được sử dụng cho các lần lặp tự động hóa chính thức tiếp theo. Thông tin quan trọng từ quá trình lặp này là mô hình dần dần cải thiện về sức mạnh và
hiệu quả sau mỗi chu kỳ tinh chỉnh và ứng dụng. Quá trình lặp này tiếp tục cho đến khi không
quan sát thêm được lợi ích nào. Do đó, các cặp định lý-chứng minh được tạo ra bởi mô hình trở nên
ngày càng chất lượng cao hơn với mỗi lần lặp. Phương pháp này đảm bảo rằng DeepSeek-Prover
liên tục nâng cao hiệu suất của nó, cuối cùng tạo ra các cặp định lý-chứng minh vượt trội thông qua
sự tinh chỉnh liên tục.

4 Thí nghiệm

4.1 Thiết lập Thí nghiệm
DeepSeek-Prover được xây dựng dựa trên mô hình DeepSeekMath-Base 7B [Shao et al., 2024], một
transformer chỉ giải mã [Vaswani et al., 2017] được huấn luyện trước trên một corpus bao gồm 120 tỷ token liên quan đến toán học.
Chúng tôi tinh chỉnh mô hình này sử dụng kích thước batch toàn cục là 512 và tỷ lệ học không đổi là 1×10−4,
kết hợp 6,000 bước khởi động với dữ liệu tổng hợp. Hiệu suất của DeepSeek-Prover được đánh giá
so với một số đường cơ sở:

•GPT-3.5 và GPT-4 [Achiam et al., 2023], được phát triển bởi OpenAI, là các mô hình AI tạo sinh tiên tiến
được biết đến với hiệu quả trong các nhiệm vụ đa dạng, bao gồm tạo mã. Mặc dù không được thiết kế rõ ràng cho chứng minh định lý, quy mô rộng lớn và số lượng tham số
của chúng mang lại khả năng đáng kể. Ngược lại, DeepSeekMath là một mô hình chuyên biệt, được
huấn luyện trước rõ ràng cho nội dung toán học. Chúng tôi sử dụng cả GPT-4 (cụ thể là phiên bản GPT-4-turbo
0409) và DeepSeekMath để tạo ra các chứng minh hoàn chỉnh cho các định lý đã cho sử dụng một
phương pháp tương tự như của chúng tôi.

•GPT-f [Polu and Sutskever, 2020], sử dụng kiến trúc lấy cảm hứng từ GPT-2 [Radford et al.,
2019], triển khai một phương pháp tìm kiếm best-first lặp để dần dần tạo ra và xác thực
các bước chứng minh trong một môi trường chứng minh chính thức cho đến khi một chứng minh được hoàn thành hoặc tài nguyên
bị cạn kiệt. Phương pháp này đã được tiến bộ thêm bởi Proof Artifact Co-Training
[Han et al., 2021], ReProver [Yang et al., 2024], Llemma [Azerbayev et al., 2023], và
COPRA [Thakur et al., 2023], sử dụng hoặc các mô hình tinh chỉnh chuyên biệt hoặc
các mô hình đa năng như GPT-3.5 và GPT-4 để tạo ra các bước chứng minh.

4.2 Kết quả Chính
Nghiên cứu này giải quyết các bài toán toán học phức tạp trong đại số và lý thuyết số. Chúng tôi đánh giá
hiệu quả chứng minh định lý của mô hình chúng tôi sử dụng các chuẩn mực miniF2F [Zheng et al., 2021] và FIMO [Liu et al.,
2023]. Thước đo pass@k được sử dụng để biểu thị tình huống mà ít nhất một chứng minh hợp lệ
được phát hiện trong số k lần cố gắng đầu tiên được tạo ra bởi mô hình.

Kết quả trên MiniF2F. Chuẩn mực miniF2F bao gồm 244 bài toán xác thực và 244 bài toán kiểm tra,
từ số học cơ bản đến các bài toán cấp độ thi đấu, ví dụ, các bài toán từ American
Invitational Mathematics Examination (AIME), American Mathematics Competitions (AMC),
và International Mathematical Olympiad (IMO). Chúng tôi sử dụng phiên bản miniF2F trong Lean 4, được
phát hành bởi dự án LeanDojo ( https://github.com/yangky11/miniF2F-lean4 ).

Bảng 1 so sánh các phương pháp tiên tiến khác nhau trên tập dữ liệu miniF2F. DeepSeek-Prover vượt trội
tất cả với điểm số tích lũy 60.2% trên miniF2F-valid và 52.0% trên miniF2F-test, cao hơn đáng kể
so với các phương pháp khác, bao gồm GPT-4 đạt 25.41% và 22.95%, tương ứng. Ngay cả
phương pháp tìm kiếm cây tốt nhất, Hypertree Proof Search với mô hình 600M, chỉ đạt được lên đến 58.6%
trên miniF2F-valid và 41.0% trên miniF2F-test. Tính mở rộng của DeepSeek-Prover rõ ràng khi hiệu suất của nó cải thiện với tài nguyên tính toán tăng lên, tăng từ 30.03% sử dụng phương pháp tham lam
đến 50.0% ở 65536 lần tạo, chứng minh hiệu quả của nó trong xử lý các tình huống chứng minh phức tạp. Các ví dụ về các định lý đã chứng minh của MiniF2F có thể được tìm thấy trong Phụ lục A.3.1.

Kết quả trên FIMO. Chuẩn mực FIMO bao gồm 149 bài toán chính thức có nguồn gốc từ
danh sách ngắn IMO được dịch sang Lean 4. Phương pháp của chúng tôi đã chứng minh thành công 4 định lý với 100
lần cố gắng cho mỗi định lý, trong khi GPT-4 thất bại trong việc chứng minh bất kỳ định lý nào. Bằng cách tăng số lần cố gắng cho mỗi
định lý lên 4,096, chúng tôi đã chứng minh thành công thêm một định lý. Các ví dụ về các định lý đã chứng minh của
FIMO có thể được tìm thấy trong Phụ lục A.3.2.

--- TRANG 5 ---
Bảng 1: So sánh với các phương pháp tiên tiến trên tập dữ liệu miniF2F.

[Bảng hiển thị các phương pháp khác nhau, kích thước mô hình, số lần tạo, và kết quả trên miniF2F-valid và miniF2F-test]

4.3 Nghiên cứu Loại bỏ

4.3.1 Hiệu quả của Tự động hóa Chính thức Quy mô Lớn
Để chứng minh hiệu quả của tự động hóa chính thức quy mô lớn, chúng tôi đã tiến hành một phân tích so sánh
như được hiển thị trong Bảng 2 giữa tập dữ liệu được tự động hóa chính thức của chúng tôi và các tập dữ liệu thông thường sử dụng
lặp chuyên gia [Polu and Sutskever, 2020]. Phương pháp lặp này bao gồm việc tạo ra các chứng minh chính thức,
tinh chỉnh mô hình dựa trên kết quả thành công, và lặp lại quá trình này cho đến khi không có thêm
cải thiện nào được quan sát. Kết quả chỉ ra rằng các mô hình được huấn luyện với dữ liệu được tự động hóa chính thức của chúng tôi
vượt trội đáng kể so với những mô hình chỉ được huấn luyện với dữ liệu mathlib.

Bảng 2: Cải thiện tỷ lệ đạt trong miniF2F ở pass@128 trong các mô hình được huấn luyện trên các chứng minh chính thức,
bao gồm những chứng minh có nguồn gốc từ các định lý do con người viết trong mathlib của Lean 4 và các định lý
được tự động hóa chính thức.

4.3.2 Hiệu quả của Chấm điểm Phát biểu Chính thức
Để chứng minh hiệu quả của mô hình trong việc lọc ra các phát biểu chất lượng thấp, chúng tôi tinh chỉnh
mô hình DeepSeekMath-Base sử dụng một lượng bằng nhau dữ liệu chứng minh điểm cao và dữ liệu chứng minh điểm thấp để xác minh chất lượng của dữ liệu, như được hiển thị trong Bảng 3. Bảng cho thấy mô hình được huấn luyện
trên dữ liệu chứng minh điểm cao vượt trội hơn mô hình được huấn luyện trên dữ liệu chứng minh điểm thấp 4.5%. Sự
cải thiện này nhấn mạnh tính hữu ích của mô hình trong việc chấm điểm chính xác và lọc hiệu quả
các phát biểu chất lượng thấp hơn.

--- TRANG 6 ---
Bảng 3: Cải thiện tỷ lệ đạt cho miniF2F ở pass@128 trong các mô hình được huấn luyện trên dữ liệu chứng minh
được chấm điểm khác nhau.

4.3.3 Hiệu quả của Cải tiến Lặp
Bảng 4 chứng minh một mối tương quan rõ ràng giữa số lần lặp trong tổng hợp dữ liệu và
hiệu suất cải tiến trong chứng minh định lý. Bằng chứng này nhấn mạnh sự thành công của chiến lược cải tiến lặp của chúng tôi trong việc tăng cường khả năng chứng minh định lý. Các lần lặp liên tiếp không chỉ
tinh chỉnh khả năng của mô hình để xử lý các chứng minh phức tạp mà còn tăng đáng kể chất lượng và
số lượng dữ liệu tổng hợp được tạo ra.

Bảng 4: Cải thiện tỷ lệ đạt cho miniF2F ở pass@128 trong các mô hình qua các lần lặp huấn luyện liên tiếp,
được hỗ trợ bởi sự tích hợp tăng dần của dữ liệu được tổng hợp thông qua tự động hóa chính thức.

4.3.4 Hiệu quả của Mở rộng Dữ liệu Chứng minh Định lý Tổng hợp
Nghiên cứu của chúng tôi về dữ liệu chứng minh định lý tổng hợp tiết lộ một mối tương quan rõ ràng giữa kích thước tập dữ liệu
và hiệu quả mô hình, như được minh họa trong Bảng 5. Bằng cách xem xét các tập con của tám triệu điểm dữ liệu chứng minh
được tạo ra, chúng tôi quan sát thấy rằng hiệu suất trên chuẩn mực miniF2F cải thiện tỷ lệ thuận
với sự tăng theo cấp số nhân trong kích thước tập dữ liệu. Mô hình này làm nổi bật tầm quan trọng then chốt của các tập dữ liệu quy mô lớn cho việc thúc đẩy thành thạo mô hình trong tự động hóa chính thức các câu hỏi ngôn ngữ tự nhiên.
Những phát hiện này nhấn mạnh tiềm năng đáng kể và sự cần thiết của xây dựng dữ liệu có hệ thống để
tiến bộ trong lĩnh vực chứng minh định lý tự động.

Bảng 5: Cải thiện tỷ lệ đạt cho miniF2F ở pass@128 trong các mô hình được huấn luyện với một phần lớn hơn
của dữ liệu được tổng hợp thông qua tự động hóa chính thức.

5 Nghiên cứu Trường hợp
Phần này trình bày hai nghiên cứu trường hợp để chứng minh việc áp dụng các phương pháp của chúng tôi trong tự động hóa chính thức
các định lý. Nó thể hiện cả các chứng minh thành công và việc xác định các sự không nhất quán trong
giai đoạn Bác bỏ Giả thuyết.

--- TRANG 7 ---
5.1 Định lý Được Tự động hóa Chính thức với Chứng minh Hoàn chỉnh
Ví dụ a. Bài toán : Chứng minh rằng định thức của ma trận sau bằng không.
"1 cos( a−b) cos( a)
cos(a−b) 1 cos( b)
cos(a) cos( b) 1#

Định lý Được Tự động hóa Chính thức trong Lean :
example (a b : R) :
Matrix.det ![![1, Real.cos (a - b), Real.cos a], ![Real.cos (a - b), 1, Real.cos
b], ![Real.cos a, Real.cos b, 1]] = 0

Phương pháp này hiệu quả dịch biểu thức đại số của ma trận và định thức của nó thành một
ngôn ngữ chính thức sử dụng Lean. Việc tự động hóa chính thức nắm bắt được bản chất của phát biểu toán học gốc bằng cách định nghĩa một ma trận 3×3 cụ thể phụ thuộc vào các số thực a và b, và khẳng định rằng định thức của nó
bằng không. Việc chính thức hóa sử dụng hàm Matrix.det để tính định thức,
sử dụng ký hiệu ![...] cho danh sách các danh sách trong Lean để biểu diễn các hàng ma trận.

5.2 Tự động hóa Chính thức của Định lý với Giả thuyết Không Nhất quán
Ví dụ b. Bài toán : Cho một số thực D và điều kiện rằng đối với các số thực khác không a, b, c ,
định thức của ma trận"a b c
1 4 9
3 1 2#
bằng D, chứng minh rằng D2= 154 .

Định lý Được Tự động hóa Chính thức trong Lean :
example (D : R) (h 0:∀a b c : R, a̸=0∧b̸=0∧c̸=0→
Matrix.det ![![a, b, c], ![1, 4, 9], ![3, 1, 2]] = D) : D ^ 2 = 154

Việc tự động hóa chính thức ban đầu không chính xác giả định rằng điều kiện D2= 154 áp dụng phổ quát cho
tất cả các số thực khác không a,b, và c. Giả định này không được hỗ trợ bởi phát biểu bài toán,
không khẳng định tính áp dụng phổ quát. Thay vào đó, việc chính thức hóa nên hướng đến việc xác định
các giá trị cụ thể của a,b, và c thỏa mãn D2= 154 hoặc chứng minh rằng không có giá trị nào như vậy tồn tại.

Mô hình thành công xác định sự không nhất quán này và cung cấp một phản ví để chứng minh
tính vô lý của giả thuyết:
example (D : R) (h 0:∀a b c : R, a̸=0∧b̸=0∧c̸=0→
Matrix.det ![![a, b, c], ![1, 4, 9], ![3, 1, 2]] = D) : False := by
have h 1:= h 01 2 3
have h 2:= h 01 4 9
simp [Matrix.det_fin_three] at h 1h2
linarith

Một phiên bản được chỉnh sửa của định lý được tự động hóa chính thức có thể được đề xuất như sau:
example (a b c : R) (h 0: a̸=0∧b̸=0∧c̸=0) :
let D := Matrix.det ![![a, b, c], ![1, 4, 9], ![3, 1, 2]];
D ^ 2 = 154

Những ví dụ này minh họa khả năng của mô hình để xác minh các chứng minh và xác định các sự không nhất quán giả thuyết
một cách hiệu quả. Chi tiết thêm có thể được tìm thấy trong Phụ lục A.2.

6 Kết luận
Trong bài báo này, chúng tôi đã trình bày một phương pháp để tạo ra dữ liệu chứng minh tổng hợp mở rộng từ các bài toán thi đấu toán học cấp trung học và đại học. Bằng cách dịch các bài toán ngôn ngữ tự nhiên
thành các phát biểu chính thức, lọc ra những phát biểu chất lượng thấp, và sử dụng tạo chứng minh lặp, chúng tôi tạo ra
8 triệu điểm dữ liệu chứng minh và cải thiện đáng kể hiệu suất của mô hình DeepSeekMath 7B
trong ATP khi được huấn luyện trên dữ liệu tổng hợp này. Mô hình của chúng tôi vượt trội hơn GPT-4 và các phương pháp khác trên các
chuẩn mực như miniF2F và FIMO. Bằng cách mở nguồn tập dữ liệu và mô hình của chúng tôi, chúng tôi hướng đến việc thúc đẩy nghiên cứu trong chứng minh định lý tự động và nâng cao khả năng của các mô hình ngôn ngữ lớn trong
lý luận toán học chính thức. Hiện tại, công việc của chúng tôi chủ yếu tập trung vào đại số và lý thuyết số ở
cấp độ trung học và đại học. Trong công việc tương lai, chúng tôi sẽ hướng đến việc mở rộng sự đa dạng của
các bài toán toán học được giải quyết, nâng cao khả năng ứng dụng chung của các phương pháp của chúng tôi trong ATP.

Tác động Rộng hơn
Nghiên cứu được trình bày trong bài báo này có tiềm năng thúc đẩy đáng kể chứng minh định lý tự động bằng cách tận dụng dữ liệu chứng minh tổng hợp quy mô lớn được tạo ra từ các bài toán toán học không chính thức. Sự tiến bộ đáng chú ý này có thể nâng cao khả năng của các mô hình ngôn ngữ lớn trong
chứng minh định lý chính thức, đóng góp vào việc xác minh chứng minh toán học đáng tin cậy hơn và cung cấp các tài nguyên giáo dục có giá trị cho sinh viên và nhà nghiên cứu. Bằng cách trực tiếp phát hành mã, mô hình, và dữ liệu,
chúng tôi hướng đến việc đảm bảo việc sử dụng có trách nhiệm công việc của chúng tôi, thúc đẩy đổi mới thêm và duy trì các tiêu chuẩn cao về quyền riêng tư dữ liệu và tuân thủ sở hữu trí tuệ.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo đầy đủ được duy trì nguyên văn]

--- TRANG 8 ---
[Tiếp tục bảng và phần tài liệu tham khảo...]

--- TRANG 9 ---
[Tiếp tục phần tài liệu tham khảo...]

--- TRANG 10 ---
[Tiếp tục phần tài liệu tham khảo...]

--- TRANG 11 ---
[Tiếp tục phần tài liệu tham khảo...]

--- TRANG 12 ---
[Tiếp tục phần tài liệu tham khảo...]

--- TRANG 13 ---
A Phụ lục / tài liệu bổ sung

A.1 Gợi ý
Cụ thể, chúng tôi sử dụng định dạng sau để chấm điểm cho chất lượng của các phát biểu được chính thức hóa:

Gợi ý :
Để đánh giá liệu một phát biểu Lean4 chính thức có được cộng đồng quan tâm hay không, hãy xem xét các tiêu chí sau:
1. Liên quan đến Nghiên cứu Hiện tại: Phát biểu có giải quyết một bài toán
hoặc khái niệm đang được nghiên cứu tích cực trong toán học hoặc các lĩnh vực
liên quan không? Điểm liên quan cao hơn chỉ ra tiềm năng quan tâm lớn hơn.
2. Độ phức tạp và Chiều sâu: Phát biểu có đủ phức tạp để thách thức
các lý thuyết và phương pháp hiện có, nhưng đủ sâu để cung cấp
những hiểu biết hoặc tiến bộ đáng kể không? Độ phức tạp và chiều sâu thể hiện
khả năng của Lean4 và thu hút sự quan tâm.
3. Tiềm năng Liên ngành: Phát biểu có cung cấp cơ hội
cho nghiên cứu liên ngành, kết nối toán học với các lĩnh vực khác
như khoa học máy tính, vật lý, hoặc sinh học không? Các dự án liên ngành
thường thu hút sự quan tâm rộng rãi.
4. Nhu cầu và Khoảng trống Cộng đồng: Phát biểu có lấp đầy một nhu cầu được xác định
hoặc khoảng trống trong cộng đồng Lean4 hoặc cộng đồng toán học rộng hơn không?
Giải quyết những nhu cầu này liên quan trực tiếp đến sự quan tâm.
5. Tính Đổi mới: Phát biểu đổi mới đến mức nào? Nó có đề xuất
các phương pháp, khái niệm, hoặc ứng dụng mới không? Đổi mới thúc đẩy sự quan tâm và
tham gia.

Tùy chỉnh đánh giá của bạn cho từng bài toán tương ứng, đánh giá nó là
'xuất sắc', 'tốt', 'trên trung bình', 'khá' hoặc 'kém'.

Bạn nên trả lời theo định dạng sau cho mỗi phát biểu:
"'
Dịch mã sang ngôn ngữ tự nhiên: (Giải thích chi tiết về
phát biểu không chính thức, bao gồm bất kỳ thông tin nền liên quan,
giả định, và định nghĩa.)
Phân tích: (Cung cấp lý do ngắn gọn cho mỗi điểm số, làm nổi bật tại sao
phát biểu được chấm điểm như vậy qua các tiêu chí.)
Đánh giá: (Dựa trên các tiêu chí, đánh giá phát biểu là 'xuất sắc',
'tốt', 'trên trung bình', 'khá' hoặc 'kém'.)
"'

A.2 Nghiên cứu Trường hợp về Tự động hóa Chính thức
[Các ví dụ chi tiết về việc tự động hóa chính thức được duy trì nguyên văn...]

A.3 Ví dụ Chứng minh Lean được Tạo bởi Mô hình của Chúng tôi

A.3.1 Kết quả trên Tập dữ liệu MiniF2F-Test
[Các ví dụ chứng minh được duy trì nguyên văn...]

A.3.2 Kết quả trên Tập dữ liệu FIMO
[Các ví dụ chứng minh được duy trì nguyên văn...]

A.4 Chi tiết Xác minh Chính thức
Chúng tôi xác minh mã Lean 4 được tạo ra với mã sau làm tiền tố:
[Danh sách import và thiết lập được duy trì nguyên văn...]

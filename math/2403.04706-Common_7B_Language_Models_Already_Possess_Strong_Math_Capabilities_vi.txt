# 2403.04706.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2403.04706.pdf
# Kích thước file: 3100882 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Các Mô hình Ngôn ngữ 7B Thông thường Đã Sở hữu Khả năng Toán học Mạnh
Chen Li1,4, Weiqi Wang2,4, Jingcheng Hu3,4, Yixuan Wei3,4,
Nanning Zheng1, Han Hu4, Zheng Zhang4*, Houwen Peng4*
1IAIR, Đại học Giao thông Tây An2Đại học Khoa học và Công nghệ Trung Quốc
3Đại học Thanh Hoa4Microsoft Research Asia
edward82@stu.xjtu.edu.cn {v-weiqiwang, t-jingchu, t-yixuanwei, zhez, houwen.peng}@microsoft.com
nnzheng@xjtu.edu.cn ancientmooner@gmail.com
Tóm tắt
Các khả năng toán học trước đây được cho rằng
chỉ xuất hiện trong các mô hình ngôn ngữ thông
thường ở quy mô rất lớn hoặc yêu cầu tiền huấn
luyện rộng rãi liên quan đến toán học. Bài báo
này chỉ ra rằng mô hình LLaMA-2 7B với tiền
huấn luyện thông thường đã thể hiện khả năng
toán học mạnh, được chứng minh bởi độ chính
xác ấn tượng 97.7% và 72.0% trên các điểm chuẩn
GSM8K và MATH, tương ứng, khi chọn phản
hồi tốt nhất từ 256 lần tạo ngẫu nhiên. Vấn đề
chính với mô hình cơ sở hiện tại là khó khăn trong
việc khơi gợi một cách nhất quán các khả năng
toán học vốn có của nó. Đáng chú ý, độ chính
xác cho câu trả lời đầu tiên giảm xuống 49.5%
và 7.9% trên các điểm chuẩn GSM8K và MATH,
tương ứng. Chúng tôi nhận thấy rằng việc đơn
giản mở rộng dữ liệu SFT có thể nâng cao đáng
kể độ tin cậy trong việc tạo ra câu trả lời đúng.
Tuy nhiên, tiềm năng mở rộng rộng rãi bị hạn
chế bởi sự khan hiếm của các câu hỏi toán học
có sẵn công khai. Để vượt qua hạn chế này,
chúng tôi sử dụng dữ liệu tổng hợp, điều này
tỏ ra gần như hiệu quả bằng dữ liệu thực và
không cho thấy dấu hiệu bão hòa rõ ràng khi
mở rộng lên khoảng một triệu mẫu. Phương pháp
đơn giản này đạt được độ chính xác 82.6% trên
GSM8K và 40.6% trên MATH sử dụng các mô
hình LLaMA-2 7B, vượt trội so với các mô hình
trước đó lần lượt 14.2% và 20.8%. Chúng tôi
cũng cung cấp những hiểu biết về hành vi mở
rộng qua các độ phức tạp lý luận và loại lỗi
khác nhau.

1 Giới thiệu
Các khả năng toán học từ lâu được coi là thách
thức đến mức chúng được cho là chỉ xuất hiện
trong các mô hình ngôn ngữ thông thường ở quy
mô rất lớn. Ví dụ, các nghiên cứu của (Wei et al., 2022a,b)
cho rằng chỉ các mô hình có kích thước vượt quá 50
*Trưởng dự án. Chen, Weiqi, Jingcheng và Yixuan là
thực tập sinh tại MSRA. GitHub: Xwin-Math Repository này sẽ được
cập nhật liên tục.

Hình 1: Các dấu sao màu cam đại diện cho độ
chính xác đạt được bằng cách chọn phản hồi tốt nhất
từ 256 lần tạo ngẫu nhiên của mô hình LLaMA-2 7B.
Độ chính xác cao trên các điểm chuẩn MATH (trái) và
GSM8K (phải) (72.0% và 97.7%, tương ứng) cho thấy
rằng LLaMA-2 7B đã sở hữu khả năng toán học mạnh,
mặc dù tính ổn định trong việc tạo ra câu trả lời đúng
có thể được cải thiện. Bài báo này chứng minh rằng
bằng cách mở rộng dữ liệu SFT tổng hợp, tính ổn định
có thể được cải thiện đáng kể như được minh chứng bởi
các đường cong. Thông qua việc mở rộng dữ liệu SFT
đơn giản này, mô hình hiệu suất cao nhất đã vượt qua
mô hình GPT-4 ban đầu 10.3% trên điểm chuẩn MATH.

tỷ tham số mới có thể đạt được độ chính xác có
ý nghĩa hoặc hưởng lợi từ xử lý chuỗi suy nghĩ
trên các bài toán toán học. Một chiến lược để trang
bị cho các mô hình ngôn ngữ nhỏ hơn khả năng
toán học bao gồm việc tạo ra các mô hình cơ sở
chuyên về toán học được huấn luyện trên hàng
trăm tỷ dữ liệu tiền huấn luyện liên quan đến toán
học (Lewkowycz et al., 2022; Azerbayev et al.,
2023). Tuy nhiên, độ chính xác của các mô hình
như vậy vẫn khiêm tốn; ví dụ, Llemma-7B (Azer-
bayev et al., 2023) chỉ đạt 36.4% trên tập dữ liệu
GSM8K (Cobbe et al., 2021) và 18.0% trên tập
dữ liệu MATH (Hendrycks et al., 2021).

Trong bài báo này, chúng tôi chứng minh rằng các
mô hình ngôn ngữ thông thường có kích thước nhỏ,
chẳng hạn như mô hình LLaMA-2 7B (Touvron et al., 2023b),
đã sở hữu khả năng toán học mạnh mà không cần
tiền huấn luyện cụ thể trên dữ liệu liên quan đến
toán học. Đáng ngạc nhiên, chúng tôi thấy rằng với
việc tinh chỉnh có giám sát chỉ trên hàng nghìn câu
hỏi toán học (lưu ý rằng giai đoạn SFT không nâng
cao khả năng như đã nêu trong arXiv:2403.04706v1 [cs.CL] 7 Mar 2024

--- TRANG 2 ---
Bảng 1: So sánh mở rộng dữ liệu SFT với câu hỏi
toán học thực và tổng hợp. Nó cho thấy rằng các câu
hỏi toán học tổng hợp gần như hiệu quả bằng những
câu hỏi thực.

Kích thước dữ liệu GSM8K-thực GSM8K-tổng hợp MATH-thực MATH-tổng hợp
0.94K 26.7 25.9 4.2 3.9
1.88K 32.8 31.9 5.6 4.9
3.75K 43.3 42.2 6.6 6.0
7.50K 50.2 49.5 8.4 7.9

(Bai et al., 2022; Ouyang et al., 2022)), mô hình
có thể giải đúng 97.7% câu hỏi GSM8K và 72.0%
câu hỏi MATH, khi chọn câu trả lời tốt nhất từ
256 lần tạo ngẫu nhiên, như được chỉ ra bởi các
dấu sao màu cam trong Hình 1. Đáng chú ý rằng
độ chính xác thậm chí đã vượt qua những gì được
báo cáo cho mô hình GPT-4, mô hình này đạt 92.0%
trên GSM8K và 42.5% trên MATH 1. Do đó, chúng
tôi kết luận rằng mô hình LLaMA-2 7B thực sự đã
phát triển khả năng toán học mạnh. Vấn đề chính
là thiếu đảm bảo rằng câu trả lời đúng sẽ được
khai thác, vì hầu hết các lần tạo đều không chính
xác. Thực tế, độ chính xác giảm xuống 49.5% trên
GSM8K và 7.9% trên MATH nếu chúng ta chỉ xem
xét một lần tạo ngẫu nhiên cho mỗi câu hỏi. Chúng
tôi gọi đây là vấn đề mất ổn định.

Để giải quyết vấn đề mất ổn định, đầu tiên chúng
tôi quan sát thấy rằng độ chính xác cải thiện gần
như tuyến tính hoặc thậm chí siêu tuyến tính với
dữ liệu tinh chỉnh có giám sát (SFT) tăng theo cấp
số nhân. Hơn nữa, chúng tôi lưu ý rằng độ chính
xác còn xa mới đạt đến ngưỡng khi sử dụng tất cả
dữ liệu huấn luyện GSM8K và MATH có sẵn (như
được thể hiện trong Bảng 1). Quan sát này khuyến
khích chúng tôi tiếp tục mở rộng dữ liệu SFT. Tuy
nhiên, chúng tôi đối mặt với thách thức vì thiếu
dữ liệu thực có thể truy cập công khai để hỗ trợ
việc mở rộng liên tục này.

Để vượt qua hạn chế này, chúng tôi chuyển sang
dữ liệu tổng hợp, sử dụng một mô hình ngôn ngữ
uy tín, cụ thể là GPT-4 Turbo, để tạo ra các câu
hỏi toán học tổng hợp. Chúng tôi thấy rằng chiến
lược tạo "hoàn toàn mới" đơn giản, thúc đẩy GPT-4
Turbo tạo ra một câu hỏi hoàn toàn mới dựa trên
những câu ưa thích và sau đó áp dụng một bộ xác
minh đơn giản (cũng dựa trên GPT-4 Turbo), đã
rất hiệu quả. Cụ thể, như được chỉ ra trong Bảng 1,
việc sử dụng các câu hỏi toán học được tạo tổng
hợp có thể

1Các số độ chính xác được báo cáo trong báo cáo kỹ thuật
GPT-4 (OpenAI, 2023b). Các mô hình GPT-4 liên tục được
cải thiện. API GPT-4 Turbo (1106) mới nhất đã tăng độ chính
xác lên 94.8% trên GSM8K và 64.5% trên MATH. Tuy nhiên,
mô hình LLaMA-2 7B sử dụng tốt nhất trong 256 lần tạo vẫn
vượt trội so với các mô hình GPT-4 mới nhất.

đạt độ chính xác gần như ngang bằng với các câu
hỏi thực, làm nổi bật tiềm năng của các câu hỏi
toán học SFT tổng hợp cho mục đích mở rộng.

Việc tận dụng dữ liệu tổng hợp đã cho phép chúng
tôi mở rộng dữ liệu SFT một cách đáng kể, ví dụ,
từ 7.5K lên 960K trên GSM8K và từ 7.5K lên 480K
trên MATH. Việc mở rộng dữ liệu này cho thấy hành
vi mở rộng gần như hoàn hảo, như được vẽ trong
Hình 1. Cụ thể, bằng cách đơn giản mở rộng dữ liệu
SFT, mô hình của chúng tôi đã trở thành mô hình
đầu tiên vượt qua 80% và 40% độ chính xác trên
GSM8K và MATH, tương ứng, sử dụng mô hình cơ
sở LLaMA-2 7B tiêu chuẩn (đạt 82.6% và 40.6%
tương ứng)2.

Dữ liệu SFT tổng hợp đơn giản cũng tỏ ra hiệu
quả từ các mô hình cơ sở mạnh hơn, chẳng hạn như
LLaMA-2 70B, đạt 90.6% trên GSM8K và 52.8%
trên MATH. Theo hiểu biết của chúng tôi, đây là
mô hình mã nguồn mở đầu tiên vượt qua 90% độ
chính xác trên GSM8K. Đây cũng là mô hình mã
nguồn mở đầu tiên vượt trội so với GPT-4 (tức là,
GPT-4-0314) trên điểm chuẩn MATH, chứng minh
hiệu quả của phương pháp mở rộng tổng hợp đơn
giản của chúng tôi.

Ngoài các kết quả mạnh mẽ, chúng tôi cũng đã
thu thập được những hiểu biết về hiệu quả của
phương pháp của chúng tôi: 1) Khi quy mô dữ liệu
SFT tăng, độ chính xác của mô hình có xu hướng
đạt ngưỡng khi sử dụng 256 lần thử; tuy nhiên,
có sự gia tăng rõ rệt khi sử dụng 1 phản hồi. Điều
này cho thấy rằng trong khi giới hạn khả năng
tối đa của mô hình vẫn khá ổn định, lợi ích hiệu
suất chủ yếu do tính ổn định được cải thiện trong
việc tạo ra câu trả lời đúng. 2) Độ chính xác giải
bài toán tuân theo luật lũy thừa liên quan đến số
bước chuỗi suy nghĩ (CoT) với các lượng dữ liệu
SFT khác nhau. Một tập dữ liệu SFT mở rộng cải
thiện độ tin cậy của mỗi bước lý luận. Việc tăng
thêm tỷ lệ mẫu huấn luyện với các bước CoT dài
hơn thông qua lấy mẫu lại có thể cải thiện đáng
kể độ chính xác của mô hình đối với các câu hỏi
khó. 3) Phân tích các loại lỗi trong quá trình mở
rộng cho thấy rằng lỗi tính toán dễ được giảm
thiểu hơn so với lỗi lý luận.

2 Khảo sát Khả năng Toán học của Mô hình
Ngôn ngữ

Chỉ số Chúng tôi sử dụng hai chỉ số để khảo sát
khả năng toán học của các mô hình ngôn ngữ.

2Đồng thời, DeepSeek-MATH-7B (Shao et al., 2024)
cũng vượt qua 80% độ chính xác. Tuy nhiên, phương pháp
của họ dựa vào một mô hình cơ sở mạnh hơn nhiều được
tiền huấn luyện rộng rãi trên kho dữ liệu liên quan đến
toán học và một thuật toán RL tinh vi. Kết quả của chúng
tôi bổ sung cho kết quả của họ.

--- TRANG 3 ---
Đầu tiên là chỉ số Pass@N

Pass@N = E
Bài toán[min( c,1)], (1)

trong đó c đại diện cho số câu trả lời đúng trong
N phản hồi. Chỉ số này coi một câu hỏi được giải
nếu ít nhất một câu trả lời đúng được tạo ra từ N
lần tạo ngẫu nhiên. Chúng tôi sử dụng chỉ số này
để phản ánh tiềm năng hoặc khả năng của một mô
hình trong việc giải một câu hỏi toán học. Để tăng
cường tính đa dạng của N lần tạo, chúng tôi đặt
nhiệt độ của quá trình tạo thành 0.73.

Thứ hai là chỉ số PassRatio@N

PassRatio@N = E
Bài toán⟨c/N⟩, (2)

đo lường tỷ lệ phần trăm câu trả lời đúng trong N
câu trả lời được tạo. Chỉ số này có phần tương
đương với Pass@1, nhưng với phương sai giảm.

Quan sát Dựa trên hai chỉ số này, chúng tôi khảo
sát hiệu suất của các mô hình LLaMA-2 trên các
điểm chuẩn GSM8K và MATH4 như được thể hiện
trong Hình 1. Để điều chỉnh các mô hình cho hai
điểm chuẩn này trong thiết lập tuân theo hướng
dẫn, chúng tôi sử dụng các phiên bản SFT của
chúng, được huấn luyện với một lượng dữ liệu
SFT hạn chế (tức là, 7.5K). Như được chứng minh
trong (Bai et al., 2022; Ouyang et al., 2022), giai
đoạn SFT không nâng cao khả năng (và thậm chí
có thể dẫn đến giảm, như đã đề cập trong bối cảnh
"thuế căn chỉnh"). Do đó, việc sử dụng phiên bản
SFT cung cấp đánh giá công bằng về khả năng
toán học của các mô hình.

Đầu tiên chúng tôi quan sát thấy rằng các chỉ số
Pass@256 cho mô hình LLaMA-2 7B trên cả hai
điểm chuẩn đều cao một cách đáng kể: 97.7% trên
GSM8K và 72.0% trên MATH. Điều này cho thấy
rằng mô hình LLaMA-2 7B sở hữu khả năng mạnh
trong việc giải các bài toán toán học.

Sau đó chúng tôi nhận thấy rằng PassRatio@256
thấp hơn đáng kể so với Pass@256, là 48.2% trên
GSM8K và 7.9% trên MATH. Điều này cho thấy
rằng trong khi các câu trả lời đúng cho hầu hết
các câu hỏi toán học có mặt trong 256 lần tạo ngẫu
nhiên, không có đảm bảo rằng các câu trả lời đúng
sẽ được trích xuất một cách nhất quán, một hiện
tượng chúng tôi gọi là "vấn đề mất ổn định".

3Đáng chú ý rằng hầu hết các mô hình toán học sử dụng
chiến lược tạo tham lam với nhiệt độ đặt thành 0. Tuy nhiên,
tác động của sự khác biệt này là tối thiểu.

4Theo (Lightman et al., 2023), chúng tôi sử dụng một tập
con 500 mẫu thử nghiệm từ điểm chuẩn MATH để hiệu quả
thí nghiệm.

Trong phần tiếp theo, chúng tôi sẽ trình bày một
phương pháp đơn giản để giảm đáng kể vấn đề
mất ổn định.

3 Mở rộng Dữ liệu SFT sử dụng Câu hỏi Toán
học Tổng hợp

Trong phần này, đầu tiên chúng tôi chứng minh
rằng việc mở rộng dữ liệu SFT thực hạn chế có
thể giảm thiểu đáng kể vấn đề mất ổn định. Chúng
tôi cũng quan sát thấy rằng độ chính xác chưa đạt
ngưỡng khi sử dụng toàn bộ dữ liệu huấn luyện
GSM8K và MATH có sẵn. Chúng tôi xem xét việc
tiếp tục mở rộng dữ liệu SFT sử dụng các câu hỏi
toán học tổng hợp. Để đạt mục tiêu này, chúng tôi
giới thiệu một phương pháp đơn giản để tạo dữ
liệu tổng hợp sử dụng API GPT-4 Turbo. Dữ liệu
tổng hợp tỏ ra hiệu quả như các câu hỏi toán học
thực. Do đó, chúng tôi mạnh dạn mở rộng dữ liệu
SFT tổng hợp lên 960K trên GSM8K và 480K trên
MATH, tương ứng, dẫn đến hành vi mở rộng gần
như hoàn hảo, và đạt độ chính xác tiên tiến.

Mở rộng sử dụng Câu hỏi Toán học Thực Chúng
tôi bắt đầu bằng cách khảo sát hành vi mở rộng
của các câu hỏi toán học thực trên toàn bộ tập
huấn luyện GSM8K và MATH. Như được chỉ ra
trong Bảng 1, chúng tôi quan sát thấy cải thiện
độ chính xác nhất quán, tăng từ 26.7% lên 50.2%
trên GSM8K, và từ 4.2% lên 8.4% trên MATH,
không có dấu hiệu bão hòa.

Tạo Dữ liệu SFT Tổng hợp Vì dữ liệu thực đã
cạn kiệt, chúng tôi cân nhắc việc tiếp tục mở rộng
dữ liệu SFT sử dụng các câu hỏi toán học được
tạo tổng hợp.

Chúng tôi giới thiệu một phương pháp ba bước
đơn giản với sự hỗ trợ của API GPT-4 Turbo:

• Bước 1. Tạo một câu hỏi toán học mới. Chúng
tôi yêu cầu API GPT-4 Turbo tạo một câu hỏi
hoàn toàn mới sử dụng một câu hỏi toán học
tham khảo làm điểm khởi đầu. Để cải thiện
tính hợp lệ của các câu hỏi mới, chúng tôi
kết hợp ba quy tắc vào lời nhắc: Thứ nhất,
câu hỏi mới phải tuân theo kiến thức thông
thường; thứ hai, nó phải có thể giải được độc
lập với câu hỏi gốc; và thứ ba, nó không được
bao gồm bất kỳ phản hồi câu trả lời nào. Bên
cạnh đó, chúng tôi đã đặt các yêu cầu định
dạng cụ thể cho các câu hỏi và câu trả lời
phù hợp với các tập dữ liệu mục tiêu khác
nhau.

• Bước 2. Xác minh câu hỏi. Chúng tôi tiếp
tục nâng cao chất lượng của các câu hỏi được
tạo bằng cách xác thực và tinh chỉnh chúng
thông qua các giải pháp thử nghiệm. Bằng
cách tích hợp các bước giải quyết và

--- TRANG 4 ---
xác minh vào một lời nhắc duy nhất, chúng
tôi đã thấy rằng phương pháp này liên tục
nâng cao tính hợp lệ của các câu hỏi trên
các điểm chuẩn khác nhau.

• Bước 3. Tạo câu trả lời chuỗi suy nghĩ (CoT).
Chúng tôi yêu cầu GPT-4 Turbo tạo ra một
phản hồi câu trả lời chuỗi suy nghĩ (CoT)
cho mỗi câu hỏi mới được tạo.

Các thiết kế lời nhắc chi tiết được thể hiện trong
Phụ lục A.

So sánh Dữ liệu SFT Tổng hợp với Dữ liệu Thực
Để đánh giá chất lượng của các câu hỏi toán học
được tạo tổng hợp, chúng tôi đánh giá hiệu quả
của chúng so với các câu hỏi thực từ các tập huấn
luyện GSM8K và MATH, sử dụng mô hình LLaMA-2
7B, như được chi tiết trong Bảng 1. Kết quả cho
thấy rằng các câu hỏi toán học tổng hợp gần như
hiệu quả bằng những câu hỏi thực.

Chúng tôi cũng khám phá nhiều phương pháp tổng
hợp khác như được đề xuất trong các công trình
trước đây (Xu et al., 2023; Yu et al., 2023; An et al., 2023).
Các phương pháp này cũng tỏ ra hiệu quả, mặc
dù ít hơn một chút so với phương pháp của chúng
tôi, như được minh họa trong Hình 6.

Mở rộng lên khoảng Một triệu Dữ liệu Toán SFT
Xem xét hiệu quả của phương pháp tổng hợp,
chúng tôi tăng đáng kể quy mô dữ liệu SFT cho
cả bài toán GSM8K và MATH, lên 960K và 480K,
tương ứng. Hình 1 trình bày các kết quả chính
sử dụng các kích thước khác nhau của dòng LLaMA-2.
Chiến lược mở rộng đơn giản mang lại độ chính
xác tiên tiến.

Cũng đáng chú ý rằng độ chính xác chưa đạt đỉnh.
Việc khám phá hiệu ứng của việc mở rộng bổ sung
sẽ là nghiên cứu tương lai của chúng tôi.

4 Thí nghiệm

4.1 Tập dữ liệu và Đánh giá

Chúng tôi tiến hành thí nghiệm trên 5 điểm chuẩn
để đánh giá hiệu quả của phương pháp được đề xuất.

GSM8K (Cobbe et al., 2021). Đây là một tập dữ
liệu toán học chất lượng cao, đa dạng về ngôn ngữ,
mà kiến thức toán học chủ yếu bao gồm cấp độ
tiểu học. Nó bao gồm 7,473 ví dụ huấn luyện và
1,319 trường hợp thử nghiệm. Trong công việc
này, chúng tôi sử dụng tập huấn luyện của nó
làm các câu hỏi cho trước để tạo dữ liệu tổng hợp
mới.

MATH (Hendrycks et al., 2021). Tập dữ liệu này
tập trung vào các bài toán toán học cấp độ thi đấu
yêu cầu mức độ cao khả năng lý luận và kiến thức
toán học. Nó bao gồm 7,500 ví dụ huấn luyện và
5,000 trường hợp thử nghiệm. Chúng tôi sử dụng
các ví dụ huấn luyện để tạo dữ liệu tổng hợp.

SVAMP (Patel et al., 2021). Tập dữ liệu này bao
gồm các bài toán toán học cấp độ tiểu học. Chúng
tôi sử dụng tất cả 1,000 trường hợp thử nghiệm
của nó để đánh giá hiệu suất liên tập dữ liệu của
các mô hình của chúng tôi.

ASDiv (Miao et al., 2021). Tập dữ liệu này chứa
một tập hợp các bài toán toán học với các mẫu
ngôn ngữ và loại câu hỏi đa dạng. Chúng tôi áp
dụng tập thử nghiệm gồm 2,305 bài toán làm điểm
chuẩn đánh giá.

Kỳ thi Trung học Quốc gia Hungary Điểm chuẩn
đánh giá này lần đầu được giới thiệu bởi Grok-1
(xAI, 2023), được thiết kế để đánh giá khả năng
ngoài lĩnh vực của các mô hình toán học. Nó bao
gồm 33 bài toán thách thức.

Đáng chú ý rằng các câu trả lời cuối cùng của
tập dữ liệu Kỳ thi Trung học Quốc gia Hungary
được chú thích bởi con người, trong khi các điểm
chuẩn khác được gắn nhãn bằng script tự động,
tương tự như các công trình trước đây (Luo et al., 2023;
Gou et al., 2023).

4.2 Chi tiết Triển khai

Trong tổng hợp dữ liệu, chúng tôi sử dụng API
GPT-4 Turbo, đặt nhiệt độ thành 1.0 cho cả việc
tạo câu hỏi và câu trả lời.

Đối với tinh chỉnh có giám sát, chúng tôi sử dụng
bộ tối ưu hóa Adam với lịch trình tỷ lệ học tập
cosin trải dài tổng cộng 3 epoch huấn luyện. Tỷ
lệ học tập tối đa được đặt 2e-5 (ngoại trừ 2e-6
cho mô hình Mistral-7b) và có 4% khởi động tuyến
tính. Độ dài token tối đa được đặt 2048, và lời
nhắc hệ thống Vicuna-v1.1 (Zheng et al., 2023)
được sử dụng. Tất cả thí nghiệm được tiến hành
trên 8 × GPU Nvidia H100. Thí nghiệm tốn tài
nguyên nhất của chúng tôi, liên quan đến mô hình
70B và 960K điểm dữ liệu, mất 1900 giờ GPU H100.

Đối với đánh giá, chúng tôi sử dụng cùng lời nhắc
như được sử dụng trong SFT và đặt độ dài chuỗi
tối đa thành 2048. vLLM (Kwon et al., 2023) được
sử dụng trong việc tạo câu trả lời.

4.3 Kết quả Chính và So sánh với Các Mô hình
Tiên tiến

Trong so sánh này, chúng tôi khảo sát cả các điểm
chuẩn trong lĩnh vực, GSM8K/MATH, và các điểm
chuẩn ngoài lĩnh vực, chẳng hạn như Kỳ thi Trung
học Quốc gia Hungary. Đối với đánh giá trong
lĩnh vực của mỗi điểm chuẩn, chúng tôi sử dụng
dữ liệu được tổng hợp từ các mẫu huấn luyện
tương ứng của nó. Đối với GSM8K, 960K dữ liệu
tổng hợp được sử dụng, trong khi đối với MATH,
480K dữ liệu tổng hợp được sử dụng. Đối với đánh
giá ngoài lĩnh vực,

--- TRANG 5 ---
Bảng 2: Hiệu suất lý luận toán học của các LLM khác nhau.

Mô hình GSM8K MATH
Các mô hình nguồn đóng
GPT-4 Turbo (1106) 94.8 64.5
GPT-4-0314 94.7 52.6
GPT-4 (Achiam et al., 2023) 92.0 42.5
Claude-2 (Anthropic, 2023) 88.0 -
GPT-3.5-Turbo (OpenAI, 2023a) 80.8 34.1
Các mô hình nguồn mở LLaMA-2-7B
WizardMath-7B (Luo et al., 2023) 54.9 10.7
MuggleMath-7B (Li et al., 2023) 68.4 -
MetaMath-7B (Yu et al., 2023) 66.5 19.8
LEMA-LLaMA-2-7B (An et al., 2023) 54.1 9.4
Xwin-Math-7B (của chúng tôi) 82.6 40.6
Các mô hình nguồn mở Mistral-7B
WizardMath-7B-v1.1 (Luo et al., 2023) 83.2 33.0
MetaMath-Mistral-7B (Yu et al., 2023) 77.4 28.2
Xwin-Math-Mistral-7B (của chúng tôi) 89.2 43.7
Các mô hình nguồn mở Llemma-7B
MetaMath-Llemma-7B (Yu et al., 2023) 69.2 30.0
Xwin-Math-Llemma-7B (của chúng tôi) 84.2 47.2
Các mô hình nguồn mở LLaMA-2-13B
WizardMath-13B (Luo et al., 2023) 63.9 14.0
MuggleMath-13B (Li et al., 2023) 74.0 -
MetaMath-13B (Yu et al., 2023) 72.3 22.4
LEMA-LLaMA-2-13B (An et al., 2023) 65.7 12.6
Xwin-Math-13B (của chúng tôi) 88.1 44.9
Các mô hình nguồn mở LLaMA-2-70B
WizardMath-70B (Luo et al., 2023) 81.6 22.7
MuggleMath-70B (Li et al., 2023) 82.3 -
MetaMath-70B (Yu et al., 2023) 82.3 26.6
LEMA-LLaMA-2-70B (An et al., 2023) 83.5 25.0
Xwin-Math-70B (của chúng tôi) 90.6 52.8

chúng tôi thử nghiệm các mô hình được huấn luyện
sử dụng GSM8K, MATH, hoặc hỗn hợp của hai
tập tổng hợp.

Đối với các mô hình cơ sở, chúng tôi xem xét cả
các mô hình ngôn ngữ thông thường, tức là, LLaMA-2
7B/13B/70B/Mistral-7B, và các mô hình chuyên
về toán học, chẳng hạn như Llemma-7B, để đánh
giá tính tổng quát của phương pháp được đề xuất.

Kết quả Trong Lĩnh vực Bảng 2 trình bày so
sánh phương pháp được đề xuất với các mô hình
nguồn mở và nguồn đóng tiên tiến. Trên tất cả
các mô hình cơ sở, phương pháp của chúng tôi
vượt trội đáng kể so với các phương pháp tốt nhất
trước đây sử dụng cùng mô hình cơ sở được tiền
huấn luyện.

Trên LLaMA-2-7B, phương pháp của chúng tôi
vượt qua tốt nhất trước đây tuyệt đối +14.2 trên
GSM8K (so với MuggleMath-7B (Li et al., 2023)),
và +20.8 trên MATH (so với MetaMath-7B (Yu
et al., 2023)), tương ứng. Nó thậm chí vượt qua
một số mô hình 70B mới nhất dành riêng cho khả
năng toán học, chẳng hạn như WizardMath-70B
(Luo et al., 2023) (82.6 so với 81.6 trên GSM8K).
Trên LLaMA-2-13B, những

Bảng 3: Kết quả thử nghiệm kỳ thi trung học quốc gia
Hungary của các LLM khác nhau.

Mô hình Điểm Thử nghiệm (%)
GPT-4 (Achiam et al., 2023) 68
Grok-1 (xAI, 2023) 59
Claude-2 (Anthropic, 2023) 55
GPT-3.5 Turbo (OpenAI, 2023a) 41
DeepSeek-LLM-67B-Chat (Bi et al., 2024) 58
Xwin-Math-70B (480K GSM8K) 22
Xwin-Math-70B (120K MATH) 51
Xwin-Math-70B (480K MATH) 59
Xwin-Math-70B (480K Mix) 65

cải thiện là +14.1 trên GSM8K (so với MuggleMath-13B
(Li et al., 2023)) và +22.5 trên MATH (so với
MetaMath-13B (Yu et al., 2023)), tương ứng. Trên
LLaMA-2-70B, lợi ích là +7.1 trên GSM8K (so với
LEMA-LLaMA-2-70B (An et al., 2023)) và +26.2
trên MATH (so với MetaMath-70B (Yu et al., 2023)),
tương ứng.

Trên một mô hình ngôn ngữ thông thường mạnh
hơn, tức là, Mistral-7B, những cải thiện là +6.0
trên GSM8K và +10.7 trên MATH (so với WizardMath-7B-v1.1
(Luo et al., 2023)), tương ứng.

Trên một mô hình cơ sở chuyên về toán học, chẳng
hạn như Llemma-7B, lợi ích là +15.0 trên GSM8K
và +17.2 trên MATH (so với MetaMath-Llemma-7B
(Luo et al., 2023)), tương ứng.

Cũng đáng chú ý rằng mô hình LLaMA-2-70B của
chúng tôi đạt độ chính xác cạnh tranh với các
phiên bản đầu của GPT-4 trên GSM8K và MATH.
Theo hiểu biết của chúng tôi, đây là mô hình dựa
trên LLaMA đầu tiên vượt trội so với GPT-4-0314
trên MATH.

Những kết quả này chứng minh hiệu quả đáng
kể và khả năng ứng dụng rộng rãi của việc mở
rộng dữ liệu SFT toán học tổng hợp.

Kết quả Ngoài Lĩnh vực Chúng tôi thử nghiệm
các mô hình được huấn luyện sử dụng GSM8K,
MATH, hoặc hỗn hợp của hai tập tổng hợp trên
một điểm chuẩn ngoài lĩnh vực, Bài Thử nghiệm
Trung học Quốc gia Hungary, theo thực hành
trong (xAI, 2023).

Bảng 3 cho thấy kết quả. Mô hình của chúng tôi
được huấn luyện trên dữ liệu hỗn hợp (240K dữ
liệu tổng hợp MATH + 240K dữ liệu tổng hợp
GSM8K) xếp hạng thứ hai, chỉ sau GPT-4 và tốt
hơn nhiều so với các mô hình khác. Ngoài ra,
chúng tôi vẽ mối tương quan giữa điểm GSM8K
và điểm kỳ thi trung học quốc gia Hungary trong
Phụ lục B. Kết quả cho thấy rằng không có hiện
tượng quá khớp điểm chuẩn đáng kể trong mô
hình của chúng tôi.

Hình 2 (Trái) trình bày kết quả của mô hình

--- TRANG 6 ---
Hình 2: So sánh sự gia tăng quy mô dữ liệu SFT sử dụng một tập dữ liệu đơn lẻ hoặc tập dữ liệu hỗn hợp.

Hình 3: Đường cong Pass@256 và PassRatio@256 với kích thước dữ liệu tăng trên điểm chuẩn GSM8K và MATH.

được huấn luyện trên dữ liệu tổng hợp GSM8K,
trong khi Hình 2 (Giữa) trình bày kết quả của
mô hình được huấn luyện trên MATH. Chúng tôi
thấy rằng độ chính xác của các điểm chuẩn khác
cũng cải thiện khi lượng dữ liệu tăng đối với các
mô hình được huấn luyện với dữ liệu tổng hợp
GSM8K hoặc MATH. Chúng tôi cũng lưu ý rằng
hành vi tổng quát hóa khác nhau đối với các mô
hình GSM8K và MATH: 1) SVAMP và ASDiv hưởng
lợi nhiều hơn từ các mô hình GSM8K so với các
mô hình MATH. 2) Trong khi các mô hình MATH
hoạt động tương đối tốt trên điểm chuẩn GSM8K,
các mô hình GSM8K hoạt động kém hơn đáng kể
trên các điểm chuẩn MATH.

Hình 2 (Phải) cho thấy kết quả của các mô hình
sử dụng hỗn hợp GSM8K và MATH theo tỷ lệ 1:1.
Những mô hình này thể hiện hành vi mở rộng cân
bằng trong cả các điểm chuẩn trong lĩnh vực và
ngoài lĩnh vực.

4.4 Điều gì Xảy ra đằng sau Cải thiện Hiệu suất?

Pass@256 so với PassRatio@256 Để hiểu sâu hơn
về cải thiện hiệu suất, chúng tôi theo dõi chỉ số
Pass@N và chỉ số PassRatio@N dưới kích thước
dữ liệu khác nhau. Kết quả được thể hiện trong
Hình 3. Với dữ liệu tổng hợp rất hạn chế (ví dụ
7.5K mẫu), mô hình Xwin-Math-70B đã có Pass@256
rất cao, cho thấy khả năng mạnh trong việc tạo
ra câu trả lời đúng thông qua nhiều lần thử. Trong
khi đó, chỉ số Pass@256 chỉ thay đổi nhẹ với việc
tăng lượng dữ liệu được sử dụng. Ngược lại,
PassRatio@256, phản ánh tính ổn định trong việc
tạo ra câu trả lời đúng, tăng đáng kể với lượng
dữ liệu tổng hợp, và xu hướng tăng trưởng của
nó tương tự như của Pass@1. Kết quả này xác nhận
giả thuyết của chúng tôi rằng cải thiện hiệu suất
chủ yếu do tính ổn định tốt hơn trong việc tạo
ra câu trả lời thay vì khả năng mạnh hơn để trả
lời câu hỏi.

Độ Chính xác Lý luận Một bước Ước tính Vì
Chuỗi Suy nghĩ (CoT) được áp dụng trong suy
luận, quá trình trả lời các bài toán được hoàn
thành bởi một quá trình lý luận nhiều bước. Do
đó, chúng tôi giả thuyết rằng sự gia tăng độ chính
xác câu trả lời cuối cùng có thể được giải thích
bởi sự cải thiện trong độ chính xác lý luận một
bước. Dựa trên giả định này, nếu một câu hỏi có
thể được trả lời về mặt lý thuyết bằng s bước lý
luận trong CoT, độ chính xác câu trả lời cuối cùng
có thể được xấp xỉ bởi hàm lũy thừa của độ chính
xác lý luận một bước:

Acc final = Acc^s_step (3)

Với phương trình này, độ chính xác bước có thể
được ước tính từ độ chính xác câu trả lời cuối
cùng. Chúng tôi thí nghiệm trên GSM8K. Đối với
mỗi câu hỏi trong tập thử nghiệm

--- TRANG 7 ---
Hình 4: Trái: Mối quan hệ giữa độ chính xác trung
bình trên GSM8K và số bước CoT được chú thích với
dữ liệu tăng. Đường liền nét được khớp sử dụng tất
cả bảy điểm, trong khi đường đứt nét được khớp sử
dụng bốn điểm đầu tiên. Phải: Thay đổi độ chính xác
trung bình khi lấy mẫu lại được sử dụng để tăng độ
dài CoT của dữ liệu huấn luyện.

tập, chúng tôi tạo ra 256 phản hồi và sử dụng số
bước trong chú thích CoT của tập thử nghiệm
GSM8k làm các bước CoT lý thuyết. Chúng tôi
vẽ đường cong để hiển thị mối quan hệ giữa số
bước lý luận CoT và độ chính xác câu trả lời cuối
cùng trung bình và hiển thị đường cong được khớp
dựa trên Phương trình 3. Chúng tôi thử nghiệm
các mô hình Xwin-Math-7B với dữ liệu tổng hợp
khác nhau, và kết quả được thể hiện trong Hình 4.
Đường liền nét được khớp sử dụng tất cả bảy
điểm và Bảng 4 cho thấy độ chính xác một bước
ước tính khi sử dụng lượng dữ liệu khác nhau
sử dụng tất cả các điểm dữ liệu, và có thể thấy
rằng độ chính xác một bước cải thiện đáng kể với
nhiều dữ liệu hơn.

Tuy nhiên, khi chúng tôi khớp dựa trên Phương
trình 3 với bốn điểm đầu tiên, như được hiển thị
trong các đường đứt nét, chúng tôi thấy rằng ba
điểm sau đó thấp hơn đáng kể so với đường cong.
Chúng tôi tin rằng hiện tượng này có thể liên quan
đến tỷ lệ nhỏ hơn của các bài toán phức tạp hơn
trong dữ liệu huấn luyện. Do đó, chúng tôi lấy
mẫu lại dữ liệu tổng hợp 960K theo số câu trong
giải pháp CoT. Như có thể thấy từ Hình 4 (phải),
khi tỷ lệ của các bài toán phức tạp được tăng lên,
độ chính xác cho các bài toán đơn giản hầu như
không thay đổi, nhưng độ chính xác cho các bài
toán phức tạp hơn có thể được cải thiện đáng kể.
Hơn nữa, việc sử dụng lấy mẫu lại dữ liệu có thể
tăng PassRatio@256 của mô hình từ 71.1 lên 72.8.
Kết quả thí nghiệm này cung cấp những hiểu biết
mới về việc lựa chọn dữ liệu cho các nhiệm vụ
lý luận toán học.

Ngoài ra, chúng tôi tiếp tục sử dụng GPT-4 Turbo
để tìm vị trí mà bước đầu tiên trong câu trả lời
của chúng tôi sai và chuẩn hóa vị trí đó bằng
tổng số bước trong mỗi câu trả lời. Khi độ chính
xác một bước ước tính ngày càng cao, vị trí

Bảng 4: Độ chính xác lý luận một bước ước tính và
vị trí lỗi đầu tiên chuẩn hóa trung bình bằng GPT-4
Turbo trong Xwin-Math-7B trên điểm chuẩn GSM8K.

Kích thước dữ liệu Ước tính Acc step Vị trí lỗi đầu tiên chuẩn hóa
7.5K 78.9 67.1
120K 89.7 83.9
960K 94.2 90.9

Hình 5: Thay đổi tỷ lệ lỗi tính toán và lỗi lý luận
trong quá trình tăng dữ liệu.

lỗi đầu tiên của việc chuẩn hóa được hoãn lại.

Sự Cải thiện Độ Chính xác Tính toán Số học
Đáng kể hơn so với Lý luận Logic Hiệu suất
của mô hình dần cải thiện khi dữ liệu tổng hợp
tăng. Để hiểu sâu hơn, chúng tôi phân tích tỷ lệ
lỗi cho các loại lỗi khác nhau trên GSM8K. Chúng
tôi phân loại lỗi thành hai loại: lỗi lý luận và lỗi
tính toán. Lỗi lý luận chủ yếu bao gồm các vấn
đề như mất điều kiện và nhầm lẫn khái niệm, trong
khi lỗi tính toán bao gồm phân tích sai mối quan
hệ định lượng và lỗi tính toán số học. Dựa trên
kết quả thí nghiệm được minh họa trong Hình 5,
chúng tôi quan sát thấy sự giảm dần tỷ lệ lỗi tính
toán, cho thấy rằng GSM8K đang sửa lỗi tính toán
với tốc độ nhanh hơn so với lỗi lý luận.

4.5 Nghiên cứu Loại bỏ về Lược đồ Tổng hợp
Dữ liệu

So sánh với Các Phương pháp Tổng hợp Dữ liệu
Khác Chúng tôi so sánh phương pháp của chúng
tôi với các phương pháp tổng hợp dữ liệu thường
được sử dụng sau đây:

Thêm Ràng buộc. Thêm một ràng buộc nữa vào
câu hỏi gốc trong khi giữ nguyên những ràng buộc
khác, được sử dụng trong WizardMath và MuggleMath.

Thay đổi Số. Thay đổi các số xuất hiện trong bài
toán trong khi giữ nguyên bối cảnh, được sử dụng
trong MuggleMath.

Thay đổi Bối cảnh. Thay đổi bối cảnh trong

--- TRANG 8 ---
Hình 6: Hiệu suất GSM8K và MATH của các phương
pháp tổng hợp khác nhau.

Bảng 5: Nghiên cứu loại bỏ xác minh câu hỏi trên MATH.

Mô hình Pass@1 (%)
Xwin-Math-70B (7.5K dữ liệu) 28.9
Xwin-Math-70B (7.5K dữ liệu) không có xác minh 28.1 (-0.8)
Xwin-Math-70B (30K dữ liệu) 37.6
Xwin-Math-70B (30K dữ liệu) không có xác minh 36.6 (-1.0)

câu hỏi trong khi giữ nguyên những thứ khác.

Kết hợp Thay đổi Số và Bối cảnh. Một phương
pháp kết hợp kết hợp việc thay đổi cả số và bối
cảnh.

Phương pháp MetaMath. Các phương pháp tổng
hợp được đề xuất trong MetaMath, bao gồm tăng
cường câu trả lời, diễn đạt lại câu hỏi, câu hỏi
tự xác minh và câu hỏi FOBAR. Trong thí nghiệm,
chúng tôi tuân theo việc triển khai MetaMath nhưng
sử dụng GPT-4 Turbo thay vì GPT-3.5 Turbo để
tạo dữ liệu phản hồi sử dụng các câu hỏi đã phát
hành của họ.

Kết quả thí nghiệm trong Hình 6 cho thấy rằng
khi kích thước dữ liệu tương đối nhỏ, ví dụ, 7.5k
và 30k mẫu, khoảng cách hiệu suất giữa các phương
pháp khác nhau là không đáng kể. Tuy nhiên, khi
kích thước dữ liệu tăng lên, phương pháp của
chúng tôi và phương pháp với các ràng buộc được
thêm vào cho thấy hiệu suất mạnh hơn. Điều này
cho thấy rằng việc lựa chọn chiến lược tổng hợp
dữ liệu trở nên quan trọng hơn khi kích thước dữ
liệu tăng, và một số phương pháp có thể mở rộng
dữ liệu hiệu quả hơn, do đó cải thiện hiệu suất.

Hiệu ứng của Xác minh Câu hỏi. Xác minh câu
hỏi được sử dụng để tiếp tục cải thiện chất lượng
tạo. Trong thí nghiệm của chúng tôi, chúng tôi
thấy nó có thể cải thiện hiệu suất trên điểm chuẩn
MATH, kết quả được thể hiện trong Bảng 5, trong
khi chúng tôi không thấy tác động đáng kể trên
tập dữ liệu GSM8K.

5 Công trình Liên quan

Mô hình Ngôn ngữ Lớn Các mô hình ngôn ngữ
lớn (Brown et al., 2020; Achiam et al., 2023; Tou-
vron et al., 2023a,b) đã đạt được những thành tựu
đáng kể, với hiệu suất ấn tượng trên một loạt
rộng các nhiệm vụ. Hiện tại, các mô hình ngôn
ngữ lớn nguồn đóng, được đại diện bởi GPT (Brown
et al., 2020; Achiam et al., 2023), Gemini (Team
et al., 2023), Grok (xAI, 2023), và Claude-2 (Anthropic,
2023), là những mô hình tiên tiến nhất về hiệu
suất. Tuy nhiên, các mô hình nguồn mở, được
đại diện bởi LLaMA (Touvron et al., 2023a), LLaMA-2
(Touvron et al., 2023b) và Mixtral (Jiang et al.,
2024), cũng đã tiến bộ nhanh chóng, và thậm chí
đã thể hiện hiệu suất cạnh tranh với các mô hình
nguồn đóng trên một số nhiệm vụ. Công việc của
chúng tôi, nhằm cải thiện hiệu suất của các LLM
nguồn mở trên các nhiệm vụ toán học bằng cách
tinh chỉnh chúng trên dữ liệu tổng hợp.

Khung Lý luận để Cải thiện Khả năng Toán học
Chuỗi suy nghĩ (Wei et al., 2022b) khuyến khích
các LLM thực hiện lý luận nhiều bước bằng các
lời nhắc được thiết kế cụ thể và có thể cải thiện
hiệu suất lý luận. Dựa trên công việc này, nhiều
công việc tiếp theo đề xuất những cải thiện thêm
(Fu et al., 2022; Zhang et al., 2022; Kojima et al., 2022).
Các công việc trên tập trung chủ yếu vào cách
cải thiện hiệu suất thông qua thiết kế lời nhắc
hoặc chiến lược suy luận tốt hơn mà không tinh
chỉnh mô hình, trong khi công việc của chúng tôi
tập trung vào cách cải thiện bản thân mô hình,
và do đó những phương pháp này bổ sung cho
phương pháp của chúng tôi.

LLM được Tinh chỉnh cho Toán học Một loại
công việc khác (Lightman et al., 2023; Luo et al., 2023;
Azerbayev et al., 2023; Yue et al., 2023; Yu et al., 2023;
An et al., 2023; Li et al., 2023; Gou et al., 2023)
cố gắng cải thiện hiệu suất trực tiếp bằng cách
huấn luyện mô hình trên dữ liệu toán học. Một
cách trực tiếp là sử dụng tinh chỉnh để cải thiện
các mô hình. Một phương pháp được sử dụng rộng
rãi là sử dụng dữ liệu tổng hợp, rất gần với phương
pháp của chúng tôi: MetaMath (Yu et al., 2023)
trình bày việc bootstrap câu hỏi để tăng cường
dữ liệu. LeMA (An et al., 2023) thu thập các cặp
dữ liệu sửa lỗi-sai lầm bằng cách sử dụng GPT-4
làm bộ sửa lỗi. Và MuggleMath (Li et al., 2023)
tăng cường tập dữ liệu GSM8K bằng cách kết hợp
GPT-4 với một loạt các hoạt động được định nghĩa
trước. So với những nỗ lực dựa trên dữ liệu tổng
hợp này, phương pháp tổng hợp dữ liệu của chúng
tôi đơn giản hơn nhiều và có thể mở rộng hơn do
giới thiệu ít tiên nghiệm và ràng buộc hơn.

Mở rộng Dữ liệu SFT Gần đây, một số nỗ lực
nghiên cứu đã tập trung vào quy mô dữ liệu cho
tinh chỉnh có giám sát. Ví dụ, LIMA (Zhou et al., 2023)
đề cập rằng tinh chỉnh với 1,000 hướng dẫn chất
lượng cao

--- TRANG 9 ---
có thể mang lại kết quả ấn tượng trong các nhiệm
vụ tổng quát khác nhau. Các nghiên cứu khác đã
chỉ ra rằng hiệu suất mở rộng theo kích thước dữ
liệu trong các nhiệm vụ toán học và lập trình
(Dong et al., 2023). Công việc gần đây (Bi et al., 2024)
thậm chí sử dụng 1.5 triệu dữ liệu cho tinh chỉnh
hướng dẫn để đạt được hiệu suất hàng đầu. Tuy
nhiên, những lý do nội tại đằng sau hiệu ứng mở
rộng này chưa được điều tra kỹ lưỡng.

6 Kết luận

Nghiên cứu này tiết lộ rằng các mô hình ngôn
ngữ 7B thông thường, chẳng hạn như LLaMA-2
7B, đã thể hiện khả năng toán học mạnh, thách
thức niềm tin trước đây rằng lý luận toán học
tiên tiến chỉ dành riêng cho các mô hình lớn hơn,
được tiền huấn luyện rộng rãi hơn. Bằng cách
mở rộng đáng kể dữ liệu SFT, chúng tôi đã cải
thiện rõ rệt tính ổn định của kỹ năng giải quyết
vấn đề toán học của mô hình. Phương pháp luận
của chúng tôi đã cho phép các mô hình Xwin-Math
đạt được mức hiệu suất có thể so sánh, và trong
một số trường hợp vượt trội, so với các đối tác
lớn hơn của chúng. Phân tích của chúng tôi cũng
cho thấy rằng những cải thiện chủ yếu do độ chính
xác gia tăng trong lý luận một bước và việc lấy
mẫu lại thêm dữ liệu huấn luyện có thể cải thiện
độ chính xác của các câu hỏi khó hơn. Ngoài ra,
chúng tôi thấy sự giảm đáng kể hơn của lỗi tính
toán so với lỗi lý luận logic. Nghiên cứu của chúng
tôi đóng góp những hiểu biết có giá trị về khả
năng toán học của các mô hình ngôn ngữ lớn.

Lời cảm ơn

Chen Li và Nanning Zheng được hỗ trợ một phần
bởi NSFC dưới cấp phép số 62088102. Cảm ơn
Shengnan An tại IAIR, Đại học Giao thông Tây
An vì lời khuyên có giá trị của anh ấy về công
việc này.

Tài liệu tham khảo

Josh Achiam, Steven Adler, Sandhini Agar-
wal, Lama Ahmad, Ilge Akkaya, Floren-
cia Leoni Aleman, Diogo Almeida, Janko Al-
tenschmidt, Sam Altman, Shyamal Anadkat,
et al. 2023. Gpt-4 technical report. arXiv
preprint arXiv:2303.08774.

Shengnan An, Zexiong Ma, Zeqi Lin, Nanning
Zheng, Jian-Guang Lou, and Weizhu Chen. 2023.
Learning from mistakes makes llm better rea-
soner. arXiv preprint arXiv:2310.20689.

Anthropic. 2023. Model card and evaluations for
claude models.

Zhangir Azerbayev, Hailey Schoelkopf, Keiran
Paster, Marco Dos Santos, Stephen McAleer,
Albert Q Jiang, Jia Deng, Stella Biderman, and
Sean Welleck. 2023. Llemma: An open lan-
guage model for mathematics. arXiv preprint
arXiv:2310.10631.

Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda
Askell, Anna Chen, Nova DasSarma, Dawn
Drain, Stanislav Fort, Deep Ganguli, Tom
Henighan, Nicholas Joseph, Saurav Kadavath,
Jackson Kernion, Tom Conerly, Sheer El-Showk,
Nelson Elhage, Zac Hatfield-Dodds, Danny Her-
nandez, Tristan Hume, Scott Johnston, Shauna
Kravec, Liane Lovitt, Neel Nanda, Catherine
Olsson, Dario Amodei, Tom Brown, Jack Clark,
Sam McCandlish, Chris Olah, Ben Mann, and
Jared Kaplan. 2022. Training a helpful and harm-
less assistant with reinforcement learning from
human feedback.

Xiao Bi, Deli Chen, Guanting Chen, Shanhuang
Chen, Damai Dai, Chengqi Deng, Honghui
Ding, Kai Dong, Qiushi Du, Zhe Fu, et al.
2024. Deepseek llm: Scaling open-source lan-
guage models with longtermism. arXiv preprint
arXiv:2401.02954.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sas-
try, Amanda Askell, et al. 2020. Language mod-
els are few-shot learners. Advances in neural
information processing systems, 33:1877–1901.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavar-
ian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek, Jacob Hilton,
Reiichiro Nakano, et al. 2021. Training verifiers
to solve math word problems. arXiv preprint
arXiv:2110.14168.

Guanting Dong, Hongyi Yuan, Keming Lu, Cheng-
peng Li, Mingfeng Xue, Dayiheng Liu, Wei
Wang, Zheng Yuan, Chang Zhou, and Jin-
gren Zhou. 2023. How abilities in large
language models are affected by supervised
fine-tuning data composition. arXiv preprint
arXiv:2310.05492.

Yao Fu, Hao Peng, Ashish Sabharwal, Peter
Clark, and Tushar Khot. 2022. Complexity-
based prompting for multi-step reasoning. arXiv
preprint arXiv:2210.00720.

--- TRANG 10 ---
Zhibin Gou, Zhihong Shao, Yeyun Gong, Yujiu
Yang, Minlie Huang, Nan Duan, Weizhu Chen,
et al. 2023. Tora: A tool-integrated reasoning
agent for mathematical problem solving. arXiv
preprint arXiv:2309.17452.

Dan Hendrycks, Collin Burns, Saurav Kadavath,
Akul Arora, Steven Basart, Eric Tang, Dawn
Song, and Jacob Steinhardt. 2021. Measuring
mathematical problem solving with the math
dataset. arXiv preprint arXiv:2103.03874.

Albert Q Jiang, Alexandre Sablayrolles, Antoine
Roux, Arthur Mensch, Blanche Savary, Chris
Bamford, Devendra Singh Chaplot, Diego de las
Casas, Emma Bou Hanna, Florian Bressand,
et al. 2024. Mixtral of experts. arXiv preprint
arXiv:2401.04088.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid,
Yutaka Matsuo, and Yusuke Iwasawa. 2022.
Large language models are zero-shot reason-
ers. Advances in neural information processing
systems, 35:22199–22213.

Woosuk Kwon, Zhuohan Li, Siyuan Zhuang,
Ying Sheng, Lianmin Zheng, Cody Hao Yu,
Joseph E. Gonzalez, Hao Zhang, and Ion Sto-
ica. 2023. Efficient memory management for
large language model serving with pagedatten-
tion. In Proceedings of the ACM SIGOPS 29th
Symposium on Operating Systems Principles.

Aitor Lewkowycz, Anders Andreassen, David
Dohan, Ethan Dyer, Henryk Michalewski,
Vinay Ramasesh, Ambrose Slone, Cem Anil,
Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu,
Behnam Neyshabur, Guy Gur-Ari, and Vedant
Misra. 2022. Solving quantitative reasoning
problems with language models.

Chengpeng Li, Zheng Yuan, Guanting Dong,
Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang
Wang, and Chang Zhou. 2023. Query and re-
sponse augmentation cannot help out-of-domain
math reasoning generalization. arXiv preprint
arXiv:2310.05506.

Hunter Lightman, Vineet Kosaraju, Yura Burda,
Harri Edwards, Bowen Baker, Teddy Lee, Jan
Leike, John Schulman, Ilya Sutskever, and Karl
Cobbe. 2023. Let's verify step by step. arXiv
preprint arXiv:2305.20050.

Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao,
Jianguang Lou, Chongyang Tao, Xiubo Geng,
Qingwei Lin, Shifeng Chen, and Dongmei
Zhang. 2023. Wizardmath: Empowering math-
ematical reasoning for large language models
via reinforced evol-instruct. arXiv preprint
arXiv:2308.09583.

Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih
Su. 2021. A diverse corpus for evaluating and
developing english math word problem solvers.
arXiv preprint arXiv:2106.15772.

OpenAI. 2023a. Gpt-3.5 turbo fine-tuning and api
updates.

OpenAI. 2023b. GPT-4 technical report. CoRR,
abs/2303.08774.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida,
Carroll L. Wainwright, Pamela Mishkin, Chong
Zhang, Sandhini Agarwal, Katarina Slama, Alex
Ray, John Schulman, Jacob Hilton, Fraser Kel-
ton, Luke Miller, Maddie Simens, Amanda
Askell, Peter Welinder, Paul Christiano, Jan
Leike, and Ryan Lowe. 2022. Training language
models to follow instructions with human feed-
back.

Arkil Patel, Satwik Bhattamishra, and Navin Goyal.
2021. Are nlp models really able to solve
simple math word problems? arXiv preprint
arXiv:2103.07191.

Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin
Xu, Junxiao Song, Mingchuan Zhang, Y. K. Li,
Y. Wu, and Daya Guo. 2024. Deepseekmath:
Pushing the limits of mathematical reasoning in
open language models.

Gemini Team, Rohan Anil, Sebastian Borgeaud,
Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,
Radu Soricut, Johan Schalkwyk, Andrew M Dai,
Anja Hauth, et al. 2023. Gemini: a family
of highly capable multimodal models. arXiv
preprint arXiv:2312.11805.

Hugo Touvron, Thibaut Lavril, Gautier Izacard,
Xavier Martinet, Marie-Anne Lachaux, Timo-
thée Lacroix, Baptiste Rozière, Naman Goyal,
Eric Hambro, Faisal Azhar, et al. 2023a. Llama:
Open and efficient foundation language models.
arXiv preprint arXiv:2302.13971.

--- TRANG 11 ---
Hugo Touvron, Louis Martin, Kevin Stone, Pe-
ter Albert, Amjad Almahairi, Yasmine Babaei,
Nikolay Bashlykov, Soumya Batra, Prajjwal
Bhargava, Shruti Bhosale, et al. 2023b. Llama
2: Open foundation and fine-tuned chat models.
arXiv preprint arXiv:2307.09288.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raf-
fel, Barret Zoph, Sebastian Borgeaud, Dani Yo-
gatama, Maarten Bosma, Denny Zhou, Donald
Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol
Vinyals, Percy Liang, Jeff Dean, and William Fe-
dus. 2022a. Emergent abilities of large language
models.

Jason Wei, Xuezhi Wang, Dale Schuurmans,
Maarten Bosma, Fei Xia, Ed Chi, Quoc V
Le, Denny Zhou, et al. 2022b. Chain-of-
thought prompting elicits reasoning in large lan-
guage models. Advances in Neural Information
Processing Systems, 35:24824–24837.

xAI. 2023. Grok-1.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,
Pu Zhao, Jiazhan Feng, Chongyang Tao, and
Daxin Jiang. 2023. Wizardlm: Empowering
large language models to follow complex instruc-
tions. arXiv preprint arXiv:2304.12244.

Longhui Yu, Weisen Jiang, Han Shi, Jincheng
Yu, Zhengying Liu, Yu Zhang, James T Kwok,
Zhenguo Li, Adrian Weller, and Weiyang Liu.
2023. Metamath: Bootstrap your own mathemat-
ical questions for large language models. arXiv
preprint arXiv:2309.12284.

Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wen-
hao Huang, Huan Sun, Yu Su, and Wenhu Chen.
2023. Mammoth: Building math generalist mod-
els through hybrid instruction tuning. arXiv
preprint arXiv:2309.05653.

Zhuosheng Zhang, Aston Zhang, Mu Li, and
Alex Smola. 2022. Automatic chain of thought
prompting in large language models. arXiv
preprint arXiv:2210.03493.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng,
Siyuan Zhuang, Zhanghao Wu, Yonghao
Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P
Xing, Hao Zhang, Joseph E. Gonzalez, and Ion
Stoica. 2023. Judging llm-as-a-judge with mt-
bench and chatbot arena.

Chunting Zhou, Pengfei Liu, Puxin Xu, Srini
Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia
Efrat, Ping Yu, Lili Yu, et al. 2023. Lima:
Less is more for alignment. arXiv preprint
arXiv:2305.11206.

--- TRANG 12 ---
A Lời nhắc Tổng hợp trên GSM8K

Lời nhắc 1: Tạo Câu hỏi
Vui lòng đóng vai như một giáo viên toán chuyên nghiệp.
Mục tiêu của bạn là tạo ra các bài toán từ toán học chất lượng cao để giúp học sinh học toán.
Bạn sẽ được đưa một câu hỏi toán học. Vui lòng tạo một câu hỏi mới dựa trên Câu hỏi Cho trước và các hướng dẫn sau.
Để đạt được mục tiêu, bạn có ba công việc.
# Vui lòng tạo một câu hỏi tương tự nhưng mới theo Câu hỏi Cho trước.
# Kiểm tra câu hỏi bằng cách giải từng bước để tìm ra xem nó có tuân thủ tất cả các nguyên tắc không.
# Sửa đổi câu hỏi đã tạo theo nhận xét kiểm tra của bạn để đảm bảo nó có chất lượng cao.
Bạn có năm nguyên tắc để làm điều này.
# Đảm bảo câu hỏi mới chỉ hỏi về một điều, hợp lý, dựa trên Câu hỏi Cho trước, và có thể được trả lời chỉ bằng một số (float hoặc integer). Ví dụ, KHÔNG hỏi, 'số lượng của A, B và C là bao nhiêu?'.
# Đảm bảo câu hỏi mới phù hợp với thông thường của cuộc sống. Ví dụ, số tiền mà ai đó có hoặc trả phải là số dương, và số người phải là số nguyên.
# Đảm bảo học sinh của bạn có thể trả lời câu hỏi mới mà không cần câu hỏi cho trước. Nếu bạn muốn sử dụng một số số, điều kiện hoặc bối cảnh trong câu hỏi cho trước, vui lòng phát biểu lại chúng để đảm bảo không có thông tin nào bị bỏ sót trong câu hỏi mới của bạn.
# Vui lòng KHÔNG bao gồm giải pháp trong câu hỏi của bạn.
# Nếu câu hỏi được tạo đã tuân theo những nguyên tắc này khi xác minh của bạn. Chỉ cần giữ nguyên mà không sửa đổi gì.
Câu hỏi Cho trước: câu hỏi cho trước
Đầu ra của bạn nên theo định dạng sau:
CÂU HỎI ĐÃ TẠO: <câu hỏi đã tạo của bạn>
XÁC MINH VÀ SỬA ĐỔI: <giải câu hỏi từng bước và sửa đổi nó để tuân theo tất cả các nguyên tắc>
CÂU HỎI ĐÃ TẠO CUỐI CÙNG: <câu hỏi đã tạo cuối cùng của bạn>

Lời nhắc 2: Tạo Câu trả lời
Vui lòng đóng vai như một giáo viên toán chuyên nghiệp.
Mục tiêu của bạn là giải chính xác một bài toán từ toán học.
Để đạt được mục tiêu, bạn có hai công việc.
# Viết giải pháp chi tiết cho Câu hỏi Cho trước.
# Viết câu trả lời cuối cùng cho câu hỏi này.
Bạn có hai nguyên tắc để làm điều này.
# Đảm bảo giải pháp theo từng bước.
# Đảm bảo câu trả lời cuối cùng chỉ là một số (float hoặc integer).
Câu hỏi Cho trước: câu hỏi cho trước
Đầu ra của bạn nên theo định dạng sau:
GIẢI PHÁP: <giải pháp chi tiết của bạn cho câu hỏi cho trước>
CÂU TRẢ LỜI CUỐI CÙNG: <câu trả lời cuối cùng của bạn cho câu hỏi chỉ với một số nguyên hoặc float>

Lời nhắc 3: Tạo Câu hỏi không có xác minh
Vui lòng đóng vai như một giáo viên toán chuyên nghiệp.
Mục tiêu của bạn là tạo ra các bài toán từ toán học chất lượng cao để giúp học sinh học toán.
Bạn sẽ được đưa một câu hỏi toán học. Vui lòng tạo một câu hỏi mới dựa trên Câu hỏi Cho trước và các hướng dẫn sau.
Để đạt được mục tiêu, bạn có một công việc.
# Vui lòng tạo một câu hỏi tương tự nhưng mới theo Câu hỏi Cho trước.
Bạn có bốn nguyên tắc để làm điều này.
# Đảm bảo câu hỏi mới chỉ hỏi về một điều, hợp lý, dựa trên Câu hỏi Cho trước, và có thể được trả lời chỉ bằng một số (float hoặc integer). Ví dụ, KHÔNG hỏi, 'số lượng của A, B và C là bao nhiêu?'.
# Đảm bảo câu hỏi mới phù hợp với thông thường của cuộc sống. Ví dụ, số tiền mà ai đó có hoặc trả phải là số dương, và số người phải là số nguyên.
# Đảm bảo học sinh của bạn có thể trả lời câu hỏi mới mà không cần câu hỏi cho trước. Nếu bạn muốn sử dụng một số số, điều kiện hoặc bối cảnh trong câu hỏi cho trước, vui lòng phát biểu lại chúng để đảm bảo không có thông tin nào bị bỏ sót trong câu hỏi mới của bạn.
# Bạn chỉ cần tạo câu hỏi mới. Vui lòng KHÔNG giải nó.
Câu hỏi Cho trước: câu hỏi cho trước
Đầu ra của bạn nên theo định dạng sau:
CÂU HỎI ĐÃ TẠO: <câu hỏi đã tạo của bạn>

--- TRANG 13 ---
B Kết quả Bổ sung

Hình 7: Hiệu suất tổng hợp của Xwin-Math trên hai điểm chuẩn này chỉ đứng sau GPT-4, chứng minh khả năng tổng quát hóa mạnh mẽ của mô hình chúng tôi.

[Biểu đồ scatter plot với trục x "Điểm Kỳ thi Hungary (%)" và trục y "Điểm GSM8K (%)", hiển thị các điểm dữ liệu cho GPT-4, Grok-1, Claude-2, GPT-3.5 Turbo, DeepSeek-LLM-67B-Chat, và các biến thể Xwin-Math-70B khác nhau]

Bảng 6: Để xác thực rò rỉ dữ liệu điểm chuẩn trong quá trình tạo dữ liệu, chúng tôi so sánh mất mát LM trên: 1) một tập con huấn luyện, là một tập con nhỏ với 256 mẫu từ tất cả dữ liệu tổng hợp; 2) một tập con huấn luyện được tạo lại, nơi chúng tôi duy trì các câu hỏi gốc từ tập con huấn luyện và sử dụng GPT-4 Turbo để viết lại câu trả lời; 3) một tập thử nghiệm được tạo lại, nơi chúng tôi giữ nguyên các câu hỏi từ các chỉ số đánh giá và sử dụng GPT-4 Turbo để viết lại câu trả lời; 4) một tập thử nghiệm tham chiếu, nơi chúng tôi sử dụng tập thử nghiệm làm hạt giống để tạo ra các câu hỏi và câu trả lời mới thông qua GPT-4 Turbo. Tham khảo Skywork, chúng tôi cũng báo cáo hai chỉ số chính: ∆1=Ltest-regen −Ltest-ref,∆2=Ltest-regen −Ltrain-regen, Vì ∆1 gần bằng 0 và ∆2 lớn hơn 0 một cách đáng kể trong hai điểm chuẩn, chúng tôi tin rằng không có rò rỉ trong quá trình tổng hợp dữ liệu.

Tập dữ liệu Ltest-regen Ltest-ref Ltrain Ltrain-regen ∆1 ∆2
GSM8K 0.52 0.50 0.11 0.33 0.02 0.19
MATH 0.59 0.58 0.23 0.39 0.01 0.20

--- TRANG 14 ---
C Nghiên cứu Trường hợp về Dữ liệu Tổng hợp

C.1 GSM8K

Câu hỏi Gốc
Randy có 60 cây xoài trong trang trại của mình. Anh ấy cũng có ít hơn một nửa số cây dừa so với cây xoài 5 cây. Randy có tổng cộng bao nhiêu cây trong trang trại của mình?

Câu hỏi Tổng hợp không có Xác minh
Maria có 80 cây táo trong vườn của cô ấy. Cô ấy cũng có ít hơn một phần ba số cây anh đào so với cây táo 4 cây. Maria có tổng cộng bao nhiêu cây trong vườn của cô ấy?

Nhận xét Xác minh
Hãy kiểm tra câu hỏi đã tạo:
- Maria có 80 cây táo.
- Cô ấy có ít hơn một phần ba số cây anh đào so với cây táo 4 cây. Một phần ba số cây táo là 80/3, tương đương khoảng 26.67.
- Ít hơn bốn cây sẽ là khoảng 22.67, nhưng vì chúng ta không thể có phân số cây, chúng ta làm tròn đến số nguyên gần nhất, là 27.
- Câu hỏi đã sửa đổi nên hỏi về số cây anh đào mà không có số thập phân. Vậy chúng ta điều chỉnh câu hỏi để có kết quả là số nguyên.
- Vì 80 không chia hết cho 3, để có số cây anh đào là số nguyên, chúng ta có thể thay đổi số để nó chia hết cho 3. Hãy sử dụng 81 cây táo thay vì 80.

Câu hỏi Tổng hợp có Xác minh
Maria có 81 cây táo trong vườn của cô ấy. Cô ấy cũng có ít hơn một phần ba số cây anh đào so với cây táo 4 cây. Maria có tổng cộng bao nhiêu cây trong vườn của cô ấy?

Giải pháp và Câu trả lời Cuối cùng Tổng hợp
Đầu tiên, hãy xác định số cây anh đào mà Maria có. Chúng ta được biết cô ấy có ít hơn một phần ba số cây anh đào so với cây táo 4 cây.

Vì Maria có 81 cây táo, hãy tìm một phần ba của số đó:
1/3 của 81 cây táo = 81 cây táo / 3 = 27 cây táo.

Bây giờ, vì cô ấy có ít hơn số lượng này 4 cây anh đào, chúng ta trừ 4 từ 27 để tìm số cây anh đào:
27 cây anh đào - 4 = 23 cây anh đào.

Để tìm tổng số cây mà Maria có trong vườn của mình, chúng ta cộng số cây táo với số cây anh đào:
81 cây táo + 23 cây anh đào = 104 cây.

Đáp án là 104.

--- TRANG 15 ---
C.2 MATH

Câu hỏi Gốc
Giá trị của log10 28471 nằm giữa các số nguyên liên tiếp a và b. Tìm a+b.

Câu hỏi Tổng hợp không có Xác minh
Giá trị của log2 16384 nằm giữa các số nguyên liên tiếp x và y. Tìm x+y.

Nhận xét Xác minh
Để đảm bảo câu hỏi có thể được giải, chúng ta cần kiểm tra xem logarit đã cho có thể được đánh giá và nằm giữa hai số nguyên liên tiếp không.
1. Xác định giá trị của 2n bằng 16384.
2. Nếu 16384 là lũy thừa của 2, thì log2 16384 sẽ là số nguyên.
3. Kiểm tra để đảm bảo kết quả là số nguyên và tìm các số nguyên liên tiếp xung quanh nó.

Hãy thực hiện kiểm tra:
20= 1, 21= 2, 22= 4, 23= 8, 24= 16
...
214= 16384

Vậy, log2 16384 = 14.

Các số nguyên liên tiếp xung quanh 14 là (13 và 14) hoặc (14 và 15).

Vì logarit cho kết quả số nguyên chính xác, để làm cho câu hỏi hợp lệ, chúng ta sẽ sửa đổi nó để sử dụng một số không phải là lũy thừa chính xác của 2.

CÂU HỎI ĐÃ TẠO ĐÃ SỬA ĐỔI:
Giá trị của log2 10000 nằm giữa các số nguyên liên tiếp m và n. Tìm m+n.

Bây giờ, hãy kiểm tra câu hỏi đã sửa đổi:
1. Vì 10000 không phải là lũy thừa của 2, log2 10000 sẽ không phải là số nguyên.
2. Mục tiêu là tìm hai số nguyên liên tiếp mà giá trị logarit này nằm giữa.
3. Biết rằng 213= 8192 và 214= 16384, log2 10000 nằm giữa 13 và 14.

Các số nguyên liên tiếp xung quanh log2 10000 là 13 và 14.

Câu hỏi Tổng hợp có Xác minh
Giá trị của log2 10000 nằm giữa các số nguyên liên tiếp m và n. Tìm m+n.

Giải pháp và Câu trả lời Cuối cùng Tổng hợp
Để tìm các số nguyên liên tiếp mà log2 10000 nằm giữa, chúng ta cần tìm các lũy thừa của 2 ngay lập tức nhỏ hơn và lớn hơn 10000.

Đầu tiên, hãy tìm lũy thừa lớn nhất của 2 nhỏ hơn 10000. Bắt đầu với 21, 22, ... và tiếp tục, chúng ta tìm thấy:
210= 1024, 211= 2048, 212= 4096, 213= 8192, 214= 16384

Ở đây, chúng ta thấy rằng 213< 10000 < 214, có nghĩa là log2 10000 lớn hơn 13 nhưng nhỏ hơn 14.

Do đó, các số nguyên liên tiếp m và n mà log2 10000 nằm giữa là m= 13 và n= 14.

Bây giờ chúng ta sẽ cộng hai số nguyên này để tìm tổng yêu cầu:
m+n= 13 + 14 = 27.

Đáp án là 27.

--- TRANG 16 ---
D Nghiên cứu Trường hợp về Phản hồi Mô hình

D.1 GSM8K

Câu hỏi và Giải pháp Chuẩn
Câu hỏi: Một thợ săn kho báu tìm thấy một rương kho báu chôn đầy đá quý. Có 175 viên kim cương, ít hơn kim cương 35 viên ruby, và gấp đôi số emerald so với ruby. Tổng cộng có bao nhiêu viên đá quý trong rương?

Giải pháp: Có 175 - 35 = 140 viên ruby trong rương kho báu. Có 140 x 2 = 280 viên emerald trong rương kho báu. Vậy, tổng số đá quý trong rương kho báu là 175 + 140 + 280 = 595.

Phản hồi – Xwin-Math-7B (7.5k dữ liệu) Giải mã Tham lam
Đầu tiên, hãy tìm số ruby. Chúng ta được biết có ít hơn kim cương 35 viên ruby. Vì có 175 viên kim cương, chúng ta có thể tính số ruby như sau:
Số ruby = Số kim cương - 35 = 175 - 35 = 140

Tiếp theo, chúng ta cần tìm số emerald. Chúng ta được biết có gấp đôi số emerald so với ruby. Vậy chúng ta có thể tính số emerald như sau:
Số emerald = 2 × Số ruby = 2 × 140 = 280

Bây giờ, chúng ta có thể tìm tổng số đá quý bằng cách cộng số kim cương, ruby và emerald lại với nhau:
Tổng số đá quý = Số kim cương + Số ruby + Số emerald = 175 + 140 + 280 = 605

Đáp án là: 605. Sai Tính toán Sai

Phản hồi – Xwin-Math-7B (7.5k dữ liệu) Một Mẫu từ Temperature=0.7
Hãy tìm số lượng từng loại đá quý trong rương từng bước.

Đầu tiên, chúng ta được cho số kim cương:
Số kim cương = 175

Tiếp theo, chúng ta được biết có ít hơn kim cương 35 viên ruby. Để tìm số ruby, chúng ta trừ 35 từ số kim cương:
Số ruby = Số kim cương - 35 = 175 - 35 = 140

Sau đó, chúng ta được biết có gấp đôi số emerald so với ruby. Để tìm số emerald, chúng ta nhân số ruby với 2:
Số emerald = 2 * Số ruby = 2 * 140 = 280

Bây giờ, chúng ta cộng số kim cương, ruby và emerald lại với nhau để tìm tổng số đá quý trong rương:
Tổng số đá quý = Số kim cương + Số ruby + Số emerald = 175 + 140 + 280 = 595

Đáp án là: 595. Đúng

Phản hồi – Xwin-Math-7B (960k dữ liệu) Giải mã Tham lam
Hãy phân tích thông tin được đưa ra trong bài toán từng bước.

1. Chúng ta biết có 175 viên kim cương.
2. Có ít hơn kim cương 35 viên ruby. Vì có 175 viên kim cương, chúng ta có thể tính số ruby bằng cách trừ 35 từ 175.
Số ruby = Số kim cương - 35 = 175 - 35 = 140

3. Có gấp đôi số emerald so với ruby. Chúng ta có thể tìm số emerald bằng cách nhân số ruby với 2.
Số emerald = 2 × Số ruby = 2 × 140 = 280

Bây giờ, để tìm tổng số đá quý trong rương, chúng ta cộng số kim cương, ruby và emerald lại với nhau.
Tổng số đá quý = Số kim cương + Số ruby + Số emerald = 175 + 140 + 280 = 595

Đáp án là: 595. Đúng

--- TRANG 17 ---
D.2 MATH

Câu hỏi và Giải pháp Chuẩn
Câu hỏi: Nếu f(x) = (3x-2)/(x-2), giá trị của f(-2) + f(-1) + f(0) là bao nhiêu? Biểu thị câu trả lời của bạn dưới dạng phân số thông thường.

Giải pháp: f(-2)+f(-1)+f(0) = (3(-2)-2)/(-2-2) + (3(-1)-2)/(-1-2) + (3(0)-2)/(0-2) = (-8)/(-4) + (-5)/(-3) + (-2)/(-2) = 2 + 5/3 + 1 = 14/3

Phản hồi – Xwin-Math-7B (7.5k dữ liệu) Giải mã Tham lam
Để tìm giá trị của f(-2) + f(-1) + f(0), chúng ta cần đánh giá hàm f(x) tại ba giá trị x này.

Đầu tiên, hãy tìm f(-2): f(x) = (3x-2)/(x-2) Thay x=-2: f(-2) = (3(-2)-2)/(-2-2) = (-6-2)/(-4) = (-8)/(-4)

Bây giờ, hãy tìm f(-1): Thay x=-1: f(-1) = (3(-1)-2)/(-1-2) = (-3-2)/(-3) = (-5)/(-3)

Cuối cùng, hãy tìm f(0): Thay x=0: f(0) = (3(0)-2)/(0-2) = (-2)/(-2) = 1

Bây giờ, chúng ta có thể tìm tổng: f(-2) + f(-1) + f(0) = (-8)/(-4) + (-5)/(-3) + 1

Để cộng các phân số này, chúng ta cần tìm mẫu số chung, đó là bội số chung nhỏ nhất (LCM) của ba mẫu số (-4, -2, và -3). LCM của các mẫu số này là -12.

Bây giờ, chúng ta có thể viết lại mỗi phân số với mẫu số chung:
(-8)/(-4) = 4/3, (-5)/(-3) = 5/3, 1 = 12/12

Bây giờ, chúng ta có thể cộng các phân số: 4/3 + 5/3 + 12/12 = (4+5+12)/3 = 19/3

Đáp án là: 19/3. Sai Tính toán Sai Không hợp lý

Phản hồi – Xwin-Math-7B (7.5k dữ liệu) Một Mẫu từ Temperature=0.7
Để tìm giá trị của f(-2) + f(-1) + f(0), đầu tiên chúng ta cần đánh giá mỗi hàm tại các giá trị cụ thể của x này.

Đối với f(-2): f(x) = (3x-2)/(x-2) Thay x=-2 vào phương trình: f(-2) = (3(-2)-2)/(-2-2) = (-6-2)/(-4) = (-8)/(-4) = 2

Đối với f(-1): f(x) = (3x-2)/(x-2) Thay x=-1 vào phương trình: f(-1) = (3(-1)-2)/(-1-2) = (-3-2)/(-3) = (-5)/(-3) = 5/3

Đối với f(0): f(x) = (3x-2)/(x-2) Thay x=0 vào phương trình: f(0) = (3(0)-2)/(0-2) = (-2)/(-2) = 1

Bây giờ chúng ta có thể cộng các giá trị của f(-2), f(-1), và f(0): f(-2) + f(-1) + f(0) = 2 + 5/3 + 1 = 14/3

Đáp án là: 14/3. Đúng

Phản hồi – Xwin-Math-7B (480k dữ liệu) Giải mã Tham lam
Để tìm giá trị của f(-2) + f(-1) + f(0), chúng ta cần đánh giá hàm f(x) tại mỗi điểm đã cho và sau đó tính tổng các kết quả.

Đầu tiên, hãy tìm f(-2): f(-2) = (3(-2)-2)/((-2)-2) = (-6-2)/(-2-2) = (-8)/(-4) = 2

Tiếp theo, hãy tìm f(-1): f(-1) = (3(-1)-2)/((-1)-2) = (-3-2)/(-1-2) = (-5)/(-3) = 5/3

Cuối cùng, hãy tìm f(0): f(0) = (3(0)-2)/(0-2) = (0-2)/(-2) = (-2)/(-2) = 1

Bây giờ, chúng ta có thể tính tổng các giá trị này: f(-2) + f(-1) + f(0) = 2 + 5/3 + 1 Để cộng những số này, chúng ta cần mẫu số chung, đó là 3: 2 + 5/3 + 1 = (2·3)/3 + 5/3 + (1·3)/3 = 6/3 + 5/3 + 3/3

Bây giờ, chúng ta cộng các tử số: 6/3 + 5/3 + 3/3 = (6+5+3)/3 = 14/3

Đáp án là: 14/3. Đúng

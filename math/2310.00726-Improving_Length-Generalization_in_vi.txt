# Cải thiện khả năng tổng quát hóa độ dài trong Transformer thông qua Gợi ý Tác vụ

**Tóm tắt**

Người ta đã quan sát thấy trong những năm gần đây rằng các transformer gặp vấn đề với việc tổng quát hóa độ dài cho một số loại tác vụ suy luận và tính toán cụ thể. Cụ thể, hiệu suất của mô hình transformer được huấn luyện trên các tác vụ (chẳng hạn như phép cộng) cho đến một độ dài nhất định (ví dụ: số có 5 chữ số) sẽ giảm mạnh khi áp dụng cho các trường hợp dài hơn của cùng một vấn đề. Nghiên cứu này đề xuất một phương pháp dựa trên gợi ý tác vụ để giải quyết vấn đề tổng quát hóa độ dài. Ý tưởng chính của chúng tôi là trong khi huấn luyện mô hình trên dữ liệu cụ thể của tác vụ, việc đồng thời huấn luyện mô hình để giải quyết một tác vụ phụ trợ đơn giản hơn nhưng có liên quan cũng sẽ có ích.

Chúng tôi nghiên cứu vấn đề sắp xếp cổ điển như một ví dụ điển hình để đánh giá phương pháp của mình. Chúng tôi thiết kế một khung huấn luyện đa tác vụ và cho thấy rằng các mô hình được huấn luyện thông qua gợi ý tác vụ cải thiện đáng kể khả năng tổng quát hóa độ dài. Cụ thể, đối với việc sắp xếp, chúng tôi cho thấy rằng có thể huấn luyện các mô hình trên dữ liệu bao gồm các chuỗi có độ dài tối đa là 20, và cải thiện độ chính xác kiểm tra trên các chuỗi có độ dài 100 từ dưới 1% (đối với huấn luyện tiêu chuẩn) lên hơn 92% (thông qua gợi ý tác vụ).

Nghiên cứu của chúng tôi khám phá ra một số khía cạnh thú vị của việc tổng quát hóa độ dài. Chúng tôi quan sát thấy rằng mặc dù một số tác vụ phụ trợ có thể có vẻ tự nhiên từ đầu, nhưng hiệu quả của chúng trong việc cải thiện tổng quát hóa độ dài lại khác biệt đáng kể. Chúng tôi tiếp tục sử dụng các kỹ thuật thăm dò và trực quan hóa để hiểu các cơ chế nội tại mà mô hình thực hiện tác vụ, và đề xuất một cấu trúc lý thuyết phù hợp với các hành vi học tập được quan sát của mô hình. Dựa trên cấu trúc của chúng tôi, chúng tôi cho thấy rằng việc đưa một số lượng nhỏ các tham số phụ thuộc vào độ dài vào quy trình huấn luyện có thể tăng thêm hiệu suất trên các độ dài chưa thấy. Cuối cùng, chúng tôi cũng cho thấy hiệu quả của phương pháp dựa trên gợi ý tác vụ của chúng tôi ngoài việc sắp xếp, mang lại hy vọng rằng những kỹ thuật này sẽ có thể áp dụng trong các bối cảnh rộng hơn.

## 1. Giới thiệu

Các mô hình transformer lớn được huấn luyện trên các tập dữ liệu khổng lồ tiếp tục thể hiện khả năng ấn tượng trên nhiều tác vụ trong hiểu ngôn ngữ, mô hình hóa hình ảnh và các lĩnh vực khác. Đồng thời, có một số lượng nghiên cứu ngày càng tăng về các hạn chế và lỗ hổng của những mô hình như vậy. Nghiên cứu này liên quan đến vấn đề tổng quát hóa độ dài. Đối với nhiều tác vụ tự nhiên—đặc biệt là những tác vụ liên quan đến suy luận nhiều bước như phép cộng, phép nhân, thực thi chương trình v.v.—có một khái niệm tự nhiên về độ dài của đầu vào, ví dụ: số chữ số khi thực hiện tác vụ cộng. Người ta đã quan sát thấy rằng hiệu suất của các transformer trên những tác vụ như vậy giảm mạnh khi được kiểm tra trên các trường hợp có độ dài không được thấy trong quá trình huấn luyện. Như được chính thức hóa trong nghiên cứu này, hiện tượng này cũng có thể được nghiên cứu như một dạng cực đoan của tính bền vững ngoài phân phối (OOD) trong đó hỗ trợ của phân phối tập kiểm tra không giao nhau với phân phối huấn luyện.

Các phương pháp hiện tại để giải quyết vấn đề tổng quát hóa độ dài có thể được chia thành hai loại chính. Một nhóm nghiên cứu gần đây bắt đầu với một mô hình ngôn ngữ lớn được huấn luyện trước (LLM) và điều tra việc tinh chỉnh/học tập trong ngữ cảnh để ngoại suy lên các độ dài lớn hơn. Đặc biệt, các nghiên cứu quan sát thấy rằng các chiến lược học tập trong ngữ cảnh như gợi ý chuỗi suy nghĩ và gợi ý bảng nháp có thể giúp cải thiện hiệu suất ngoài phân phối của các LLM. Một nhóm nghiên cứu khác xem xét các nghiên cứu tình huống trên các tác vụ đơn giản hơn, và thực hiện huấn luyện cụ thể cho tác vụ để cải thiện tổng quát hóa độ dài.

Nghiên cứu của chúng tôi thuộc loại thứ hai: mục tiêu của chúng tôi là phát triển các kỹ thuật huấn luyện có mục đích chung để cải thiện tổng quát hóa độ dài. Để đặt các thách thức cơ bản của tổng quát hóa độ dài vào bối cảnh, hãy liệt kê một số phương pháp tự nhiên có vẻ như không hữu ích. Ví dụ, người ta đã quan sát thấy rằng việc chỉ mở rộng quy mô mô hình và kích thước tập dữ liệu một mình không đủ cho tổng quát hóa độ dài. Các tác giả cũng quan sát thấy rằng mặc dù gợi ý bảng nháp giúp ích trong việc học tập trong ngữ cảnh, việc tinh chỉnh một LLM được huấn luyện trước trên các bảng nháp dường như không hiệu quả, điều này thật ngạc nhiên. Tương tự, các tác giả quan sát thấy rằng mặc dù việc sử dụng mô hình BERT được huấn luyện trước giúp cải thiện hiệu suất trên tác vụ LEGO mà các tác giả đã giới thiệu trong nghiên cứu, những cải thiện này là có hạn và không đủ để giải quyết vấn đề vượt qua một điểm nhất định. Do đó, các kỹ thuật thời gian huấn luyện để giải quyết vấn đề tổng quát hóa độ dài hoặc giới thiệu các kiến trúc cụ thể cho tác vụ hoặc thực hiện chuẩn bị dữ liệu/học tập theo chương trình, trong đó dữ liệu từ các trường hợp có độ dài cao hơn được đưa vào quy trình huấn luyện. Thú vị là, các tác giả quan sát thấy rằng mặc dù việc đưa một lượng nhỏ dữ liệu huấn luyện từ các trường hợp có độ dài n có thể giúp tổng quát hóa đến các trường hợp kiểm tra cũng có độ dài n, mô hình có thể thất bại hoàn toàn trên các trường hợp kiểm tra có độ dài n+1!

Được thúc đẩy bởi các nghiên cứu trên, chúng tôi nghiên cứu xem liệu có những kỹ thuật huấn luyện có mục đích chung để cải thiện tổng quát hóa độ dài hay không. Như trong các nghiên cứu trước, chúng tôi tập trung vào một số tác vụ đơn giản làm trường hợp sử dụng của mình, và xem xét việc huấn luyện các mô hình transformer từ đầu. Đối với phần lớn bài báo, chúng tôi xem xét vấn đề sắp xếp cổ điển như một ví dụ điển hình. Cho một chuỗi các số tự nhiên chưa được sắp xếp có độ dài n, chúng tôi xem xét việc huấn luyện các mô hình transformer chỉ giải mã để học cách xuất ra chuỗi đã sắp xếp. Chúng tôi làm việc với các kiến trúc transformer tiêu chuẩn và rõ ràng tránh sử dụng thậm chí một lượng nhỏ dữ liệu từ các chuỗi có độ dài cao hơn, dù trong quá trình huấn luyện hay để lựa chọn mô hình. Đóng góp chính của chúng tôi là khung gợi ý tác vụ để giải quyết tổng quát hóa độ dài. Phương pháp của chúng tôi dựa trên ý tưởng cốt lõi rằng như con người, việc học giải quyết một tác vụ cụ thể cũng bao gồm việc học giải quyết các tác vụ phụ đơn giản hữu ích. Ví dụ, một học sinh tuyên bố sắp xếp các số tốt cũng được kỳ vọng biết cách so sánh hai số, xác định phần tử kế tiếp/trước đó của một số trong chuỗi, đếm số lần xuất hiện của một số trong chuỗi và các kỹ năng khác.

Do đó, chúng tôi đề xuất một khung học tập đa tác vụ trong đó mạng transformer được huấn luyện đồng thời để giải quyết một tác vụ chính (như sắp xếp) và một tác vụ phụ trợ (như xác định phần tử kế tiếp). Chúng tôi cho thấy rằng phương pháp này dẫn đến một khung mạnh mẽ để cải thiện tổng quát hóa độ dài. Cụ thể, chúng tôi chứng minh rằng bằng cách huấn luyện mô hình chỉ trên dữ liệu có độ dài lên đến n=20 chuỗi, có thể cải thiện độ chính xác kiểm tra trên chuỗi có độ dài n=100 từ dưới 1% (đối với huấn luyện tiêu chuẩn) lên hơn 92% (thông qua gợi ý tác vụ). Trong phần thứ hai của bài báo, chúng tôi thực hiện một cuộc điều tra sâu hơn về khi nào và cách thức gợi ý tác vụ có ích. Chúng tôi quan sát thấy rằng mặc dù nhiều tác vụ phụ trợ có thể có vẻ tự nhiên từ đầu, nhưng tác động của chúng lên tổng quát hóa độ dài lại khác nhau rất nhiều. Đối với tác vụ sắp xếp chuỗi, chúng tôi quan sát thấy rằng tác vụ xác định phần tử kế tiếp giúp ích nhất, trong khi tác vụ đếm giúp ích ít nhất.

Chúng tôi tiếp tục sử dụng các kỹ thuật trực quan hóa để kết luận rằng đối với mỗi tác vụ, mạng transformer có xu hướng thiên về một cơ chế cụ thể để giải quyết tác vụ. Có lẽ tự nhiên, các tác vụ phụ trợ phù hợp tốt với thiên hướng này có xu hướng giúp ích nhất. Chúng tôi xác định một số nguyên tắc tính toán mà mạng có xu hướng nắm bắt ngầm ở các lớp khác nhau và đề xuất một cấu trúc lý thuyết của một transformer sắp xếp phù hợp với các phát hiện thực nghiệm. Dựa trên lý thuyết của chúng tôi, chúng tôi xác định một số lượng nhỏ các tham số phụ thuộc vào độ dài mà việc đưa vào mô hình sẽ tăng đáng kể khả năng tổng quát hóa độ dài của các transformer (ngay cả đối với các mô hình được huấn luyện mà không có gợi ý tác vụ). Cuối cùng, chúng tôi chứng minh tính hiệu quả của khung đề xuất cho một tác vụ đơn giản khác, đó là tăng một số.

## 2. Nghiên cứu liên quan

Tổng quát hóa độ dài trong các transformer là một vấn đề đầy thách thức, với nhiều yếu tố gây nhiễu, như vai trò của các embedding vị trí, lựa chọn kiến trúc, và các chiến lược định dạng tập dữ liệu và/hoặc gợi ý. Các nghiên cứu đề xuất các sửa đổi đối với cơ chế attention tiêu chuẩn để cho phép ngoại suy độ dài. Nghiên cứu quan sát một vai trò đáng ngạc nhiên được thực hiện bởi sự hiện diện/vắng mặt của token EOS. Cụ thể, họ quan sát thấy các mô hình không có token EOS ngoại suy tốt hơn đáng kể đến các độ dài cao hơn.

Nghiên cứu khám phá các chiến lược học tập trong ngữ cảnh để cải thiện tổng quát hóa độ dài. Các tác giả cho thấy rằng tổng quát hóa độ dài có thể được cải thiện đáng kể cho các tác vụ như tính chẵn lẻ và gán biến bằng cách gợi ý thông qua bảng nháp. Họ cũng quan sát một số hành vi trái ngược trực giác, như việc thiếu cải thiện trong tổng quát hóa độ dài khi tinh chỉnh mô hình thông qua gợi ý bảng nháp. Mặc dù có thể hình dung rằng tổng quát hóa độ dài có thể được cải thiện thông qua các bảng nháp/chuỗi suy nghĩ phức tạp hơn, việc tăng cường tập dữ liệu huấn luyện với những gợi ý như vậy có thể không luôn khả thi, và có thể dẫn đến sự gia tăng đáng kể của độ dài ngữ cảnh đầu vào. Như một ví dụ khác, nghiên cứu gần đây tinh chỉnh mô hình LLaMA mã nguồn mở cho phép nhân nhiều chữ số thông qua huấn luyện bảng nháp/chuỗi suy nghĩ. Nó quan sát thấy rằng mặc dù độ chính xác trong phân phối cải thiện đáng kể, các mô hình kết quả vẫn tiếp tục gặp khó khăn với tổng quát hóa độ dài.

Nghiên cứu đề xuất một tác vụ LEGO có hương vị tương tự như tác vụ sắp xếp. Các tác giả quan sát thấy rằng khi huấn luyện mô hình BERT từ đầu cho độ dài n=6, độ chính xác trong phân phối là 100%, nhưng độ chính xác cho n=8...12 không tốt hơn ngẫu nhiên. Hơn nữa, họ cho thấy rằng việc huấn luyện một kiến trúc cụ thể, đó là mô hình ALBERT, cải thiện tổng quát hóa độ dài ở một mức độ nào đó. Các tác giả đề xuất ý tưởng chuẩn bị dữ liệu cho tổng quát hóa độ dài. Điều này bao gồm việc đưa một lượng nhỏ (dưới 1%) dữ liệu từ các độ dài cao hơn (tức là phân phối kiểm tra) vào quá trình huấn luyện để cải thiện hiệu suất ngoài phân phối. Tuy nhiên, các tác giả quan sát thấy rằng việc chuẩn bị tập dữ liệu cho một độ dài chưa thấy n có thể không có lợi ích nào cho hiệu suất ở độ dài n+1. Theo hướng tương tự, các tác giả đề xuất một quy trình học tập theo chương trình, trong đó dữ liệu từ các độ dài ngày càng cao hơn được dần dần cải thiện vào quy trình huấn luyện.

Nghiên cứu của chúng tôi cũng liên quan đến việc hiểu các cơ chế học tập nội tại của các mô hình đã được huấn luyện thông qua các kỹ thuật dựa trên phép chiếu đơn giản. Theo hướng tương tự, nghiên cứu gần đây nghiên cứu một mạng độ sâu một được huấn luyện để cộng modulo 113, sử dụng biểu diễn d=128 chiều. Sử dụng bản chất có cấu trúc (và kích thước hạn chế) của tác vụ, họ cho thấy cách phóng to các nơ-ron và phân tích trọng số mạng có thể giúp hiểu các cơ chế cơ bản. Một nhóm nghiên cứu gần đây khác sử dụng thăm dò để tìm ánh xạ từ các biểu diễn nội tại của mạng đến trạng thái bên ngoài thực tế của vấn đề (Othello) được giải quyết. Trọng tâm của nghiên cứu chúng tôi là cho thấy rằng các kỹ thuật phổ rộng—dựa trên các phép chiếu đơn giản lên các cơ sở embedding và unembedding—có thể mang lại những hiểu biết có giá trị một cách đáng ngạc nhiên.

Cuối cùng, nghiên cứu của chúng tôi sử dụng khung học tập đa tác vụ có một tài liệu phong phú. Truyền thống, học tập đa tác vụ được sử dụng để có được các biểu diễn tốt có thể thích ứng với các tác vụ phụ trợ mới bằng cách sử dụng một lượng nhỏ dữ liệu bổ sung. Ngược lại, trong nghiên cứu này chúng tôi sử dụng học tập đa tác vụ chủ yếu để cải thiện tính bền vững ngoài phân phối của chính tác vụ chính.

## 3. Sắp xếp

Đối với phần lớn bài báo, chúng tôi tập trung vào sắp xếp như ví dụ điển hình của chúng tôi. Chúng tôi xem xét việc giải quyết tác vụ này thông qua các mô hình transformer chỉ giải mã được huấn luyện từ đầu. Chúng tôi làm việc với từ vựng Σ của các số nguyên từ 1 đến 100 và giới thiệu hai token bổ sung, ⊥ như dấu phân cách kết thúc đầu vào, và PAD như token đệm để đảm bảo rằng tất cả các chuỗi đầu vào trong quá trình huấn luyện có cùng độ dài. Cho một chuỗi đầu vào, chúng tôi huấn luyện mô hình transformer nhân quả chỉ giải mã để học dự đoán chuỗi đã sắp xếp từng token một. Việc huấn luyện được thực hiện thông qua khung dự đoán token tiếp theo tiêu chuẩn với hàm mất mát cross-entropy. Xem Hình 3.1 cho một ví dụ về chuỗi đầu vào, và mặt nạ chúng tôi sử dụng để phạt mô hình chỉ ở các vị trí đầu ra.

Tập dữ liệu huấn luyện của chúng tôi bao gồm các chuỗi có độ dài lên đến 20, trong đó mỗi chuỗi được tạo thành bằng cách rút các số từ Σ = {1, 2, ..., 100} một cách đồng nhất ngẫu nhiên có thay thế. Hơn nữa, để mô phỏng môi trường thực tế trong đó dữ liệu có sẵn miễn phí trên internet bị thiên về các độ dài chuỗi ngắn hơn, chúng tôi đảm bảo rằng 80% tập huấn luyện bao gồm các độ dài chuỗi từ {2, 3, 4, 5}, và 20% còn lại bao gồm các độ dài chuỗi {6, 7, ..., 20}. Chúng tôi đầu tiên điều tra xem việc mở rộng dữ liệu và mô hình có thể giúp (và bao nhiều) với tổng quát hóa độ dài hay không. Để làm điều này, chúng tôi huấn luyện mô hình độ sâu 2 với các kích thước tập dữ liệu {1M, 10M, 40M, 160M}, và chúng tôi cũng huấn luyện các mô hình có độ sâu {2, 4, 8, 12} trên tập huấn luyện 1M. Tất cả các mô hình được huấn luyện sử dụng bộ tối ưu Adam trong 100k bước gradient với kích thước batch 1024, và tốc độ học one-cycle cosine bắt đầu với tốc độ học cơ bản 1e-5. (Chúng tôi sử dụng 10 epoch đầu tiên để khởi động tuyến tính đến tốc độ học cơ bản.) Khi đánh giá các mô hình, chúng tôi sử dụng giải mã tham lam.

Kết quả của việc mở rộng dữ liệu được hiển thị trong Hình 3.2. Mặc dù dữ liệu nhiều hơn giúp ích ở một mức độ nào đó—độ chính xác kiểm tra trên các chuỗi độ dài 50 cải thiện từ 64% lên gần 90%—việc mở rộng thêm không giúp được gì và tất cả các mô hình đạt được dưới 1% độ chính xác trên các chuỗi độ dài 100. Ở đây độ chính xác kiểm tra đề cập đến tỷ lệ các chuỗi trong tập kiểm tra (100k ví dụ cho mỗi độ dài chuỗi) mà mô hình xuất ra chuỗi đã sắp xếp chính xác. Tương tự, việc mở rộng độ sâu từ 2 lên 4 giúp cải thiện độ chính xác trên các chuỗi độ dài 50, nhưng chúng tôi không quan sát thấy lợi ích nào thêm (Hình 3.3) sau đó. Một lần nữa, độ chính xác cho các chuỗi độ dài 100 là dưới 1% cho tất cả các kích thước mô hình và dữ liệu. Điều này phù hợp với hành vi được quan sát: việc mở rộng mô hình và dữ liệu một mình dường như không đủ để giải quyết tổng quát hóa độ dài.

### 3.1 Gợi ý Tác vụ

Chúng tôi hiện giới thiệu khung gợi ý tác vụ. Chúng tôi xem xét một thiết lập đa tác vụ trong đó chúng tôi huấn luyện mô hình để đồng thời hoạt động tốt trên tác vụ sắp xếp chính (Hình 3.1), và cũng là một tác vụ phụ trợ. Tác vụ phụ trợ này tương ứng với một tác vụ phụ đơn giản hơn liên quan đến việc "thực sự học" một giải pháp cho tác vụ chính. Trong phần này, hãy tập trung vào tác vụ kế tiếp: cho một chuỗi đầu vào và một phần tử cụ thể a từ chuỗi, mô hình phải học dự đoán phần tử kế tiếp của nó, tức là phần tử theo sau a trong chuỗi đã sắp xếp (xem Hình 3.4 cho một ví dụ).

Để học đồng thời hai tác vụ, chúng tôi sử dụng mô hình chia sẻ tham số cứng cho học tập đa tác vụ, trong đó toàn bộ backbone mô hình được chia sẻ giữa hai tác vụ, và một đầu phân loại cụ thể cho tác vụ được sử dụng ở lớp cuối để đưa ra dự đoán cho các tác vụ tương ứng. Chúng tôi huấn luyện các mô hình như trước đây trong 100k bước, mỗi lần xen kẽ giữa việc thực hiện cập nhật gradient trên tác vụ chính và tác vụ phụ trợ. Kích thước tập dữ liệu huấn luyện được chia đều giữa hai tác vụ.

Hình 3.5 cho thấy tác động của việc mở rộng kích thước tập huấn luyện trên mô hình độ sâu 2 với gợi ý tác vụ. Trái ngược với thiết lập đơn tác vụ, chúng tôi thấy những lợi ích nhất quán khi kích thước tập huấn luyện tăng. Cụ thể, đối với kích thước tập dữ liệu 160M, độ chính xác kiểm tra cho độ dài 100 đạt đến 52.4%. Hơn nữa, bằng cách sửa đổi tập huấn luyện một chút để 10% các chuỗi liên quan đến các lần lặp không tầm thường (xem Phụ lục B cho chi tiết), mô hình độ sâu 2 được huấn luyện thông qua gợi ý tác vụ đạt được 92.6% độ chính xác kiểm tra trên các chuỗi độ dài 100! Ngược lại, mô hình thu được mà không có gợi ý tác vụ tiếp tục có độ chính xác kiểm tra gần 0 trên các chuỗi độ dài 100, ngay cả trên tập huấn luyện được sửa đổi này.

Trong Hình 3.6 và 3.7, chúng tôi so sánh hiệu suất kiểm tra của mô hình độ sâu 2 được huấn luyện trên tập dữ liệu 160M thông qua gợi ý tác vụ và mô hình thu được thông qua huấn luyện tiêu chuẩn, khi chúng tôi tăng độ dài chuỗi kiểm tra. Cả hai mô hình đều được huấn luyện trên tập dữ liệu được sửa đổi chứa 10% chuỗi với các lần lặp không tầm thường. Chúng tôi xem xét hai chỉ số: (a) độ chính xác chuỗi đầy đủ, tức là liệu mô hình có xuất ra toàn bộ chuỗi đã sắp xếp một cách chính xác hay không, và (b) khoảng cách chỉnh sửa giữa chuỗi đã sắp xếp thực và chuỗi được dự đoán. Chúng tôi thấy hiệu suất của mô hình không có gợi ý giảm mạnh theo độ dài chuỗi; ngược lại, hiệu suất của mô hình có gợi ý vẫn ổn định hơn nhiều.

Để điều tra thêm về tính bền vững của các mô hình được huấn luyện, chúng tôi kiểm tra chúng trên các phân phối ngoài việc lấy mẫu ngẫu nhiên đồng nhất. Chúng tôi xây dựng các phân phối kiểm tra dạng rep(i, r), trong đó một chuỗi có độ dài i được tạo bằng cách lấy mẫu ⌊i/r⌋ phần tử một cách đồng nhất ngẫu nhiên không có thay thế, và lặp lại mỗi phần tử r lần. (Các phần tử còn lại i − ⌊i/r⌋r được rút một cách đồng nhất ngẫu nhiên có thay thế.) Hình 3.8 và 3.9 so sánh hiệu suất của các mô hình dựa trên gợi ý và không có gợi ý cho các giá trị lặp lại (r) trong {2, 3, 4, 5}. Một lần nữa, chúng tôi quan sát thấy rằng các mô hình dựa trên gợi ý ổn định trong hiệu suất của chúng, cả về độ chính xác chuỗi đầy đủ và khoảng cách chỉnh sửa của chúng.

**Gợi ý Thay thế.** Nhiều tác vụ phụ trợ tự nhiên khác có thể đóng vai trò như gợi ý cho tác vụ chính của việc sắp xếp. Trong Hình 3.10, chúng tôi trình bày hai tác vụ như vậy. Tác vụ đầu tiên là tác vụ "đếm" trong đó, cho một chuỗi chỉ có hai số được lặp lại một số lần nhất định, mô hình phải xác định số ít xuất hiện nhất. Ý tưởng cơ bản là việc sắp xếp đòi hỏi tạo ra một đầu ra với số lần xuất hiện chính xác của bất kỳ số cụ thể nào, và do đó hiểu liệu đầu ra có chứa ít hơn hay bằng số lần xuất hiện của một số. Một trực giác rất tương tự làm nền tảng cho tác vụ thứ hai, đó là tác vụ "điền": cho một chuỗi chứa một số duy nhất được lặp lại một số lần, theo sau bởi một tiền tố của chuỗi đó, mô hình phải điền vào các mục còn lại.

Chúng tôi hiện so sánh hiệu suất của các mô hình được huấn luyện thông qua ba loại gợi ý khác nhau—gợi ý kế tiếp từ phần trước, và các gợi ý đếm và điền này—trong Hình 3.11. Quan sát thấy rằng tổng quát hóa độ dài khác nhau rất nhiều tùy thuộc vào loại gợi ý được sử dụng. Cụ thể, mặc dù các gợi ý điền dẫn đến một cải thiện biên so với mô hình tiêu chuẩn không có gợi ý, việc sử dụng gợi ý đếm dẫn đến hiệu suất tồi tệ hơn so với việc không có gợi ý nào cả!

## 4. Diễn giải Gợi ý

Với những khác biệt lớn trong hiệu suất của các mô hình được huấn luyện với các loại gợi ý khác nhau, chúng tôi hiện chuyển sang các kỹ thuật trực quan hóa và thăm dò để cố gắng hiểu cơ chế mà mạng học tác vụ sắp xếp. Để bắt đầu, một số ký hiệu:

1. Đối với một mô hình được huấn luyện, hãy để E ∈ Rq×d là embedding đầu vào đã học (thường được gọi là bảng embedding); ở đây q là kích thước từ vựng, và d là chiều embedding. (Trong các thí nghiệm của chúng tôi, q = 103 và d = 1024.) Chúng tôi gọi các hàng của E là cơ sở mã hóa; việc sử dụng thuật ngữ "cơ sở" không phải là không hợp lý ở đây, vì thực nghiệm chúng tôi thấy rằng các hàng gần như trực giao và có độ dài rất tương tự.

2. Hãy để (W, b) biểu thị bộ phân loại được sử dụng ở lớp cuối để đưa ra dự đoán token tiếp theo. Ở đây W là ma trận d×q (thường được gọi là lớp softmax), và b là vector bias có kích thước d. Chúng tôi cũng quan sát thấy rằng các cột của W gần như trực giao, và chúng tôi gọi những vector này là cơ sở giải mã. Hai cơ sở này gần như trực giao với nhau, và do đó bao trùm 2q = 206 trong số d = 1024 chiều.

Khi mạng thực hiện suy luận trên một đầu vào σσσ = ⟨σ0, ..., σT−1⟩, chúng tôi có thể tính toán các embedding trung gian cho mỗi token σi trong chuỗi và trực quan hóa chúng trong các cơ sở mã hóa và giải mã. Chính thức, một mô hình transformer chỉ giải mã tiêu chuẩn bao gồm các lớp của các khối attention, trong đó mỗi khối attention bao gồm một lớp self-attention theo sau bởi một lớp MLP. Do đó, đối với một đầu vào σσσ và chỉ số vị trí i cho trước, hãy để X^pre_{i,j} biểu thị embedding của token σi thu được ở độ sâu j trước khi áp dụng MLP ở độ sâu đó, và hãy để X^post_{i,j} là embedding sau khi áp dụng MLP. Sau đó chúng tôi trực quan hóa một số vị trí i cho các đầu vào khác nhau bằng cách chiếu các embedding trước MLP và sau MLP lên các cơ sở mã hóa và giải mã. Những phép chiếu này thường mang tính sâu sắc, vì các vector cơ sở tự nhiên tương ứng với các ký hiệu từ vựng.

Như một ví dụ, hãy xem xét chuỗi đầu vào: σσσ = ⟨5, 17, 43, 78, 92, ⊥⟩ gồm năm số cần được sắp xếp. Chúng tôi xem xét một mô hình độ sâu hai được huấn luyện (thông qua huấn luyện tiêu chuẩn) và vẽ các embedding được chiếu cho token σ2 = 43 trong Hình 4.12. Các embedding sau lớp attention đầu tiên (độ sâu 0 trước MLP) được tập trung cao trên token 43 trong cơ sở mã hóa, gợi ý một thao tác sao chép (có nhiễu) được thực hiện bởi lớp. Xu hướng các token chỉ đơn giản sao chép chính chúng trong cơ sở mã hóa này được quan sát thấy đối với các token xuất hiện trước token ⊥ tại tất cả các điểm trong suy luận.

Tiếp theo, trong Hình 4.13 chúng tôi vẽ token 43 một lần nữa, nhưng bây giờ khi nó xuất hiện ở vị trí 8, tức là khi nó là một phần của chuỗi đầu ra. Chúng tôi một lần nữa quan sát thấy thao tác sao chép có nhiễu trong cơ sở mã hóa, nhưng hành vi trong cơ sở giải mã khá khác biệt. Cụ thể, embedding sau lớp attention thứ hai (độ sâu 1 trước MLP) được tập trung cao trên cả token 43 và trên phần tử kế tiếp của nó trong chuỗi đã sắp xếp, tức là trên token 78. Thực tế, chúng tôi nhất quán quan sát thấy hiện tượng hai đỉnh này trong embedding độ sâu 1 trước MLP cho các token trong chuỗi đầu ra—chúng dường như thực hiện một thao tác Identity+Successor. Lớp MLP cuối cùng sau đó hoạt động như một bộ khử nhiễu, giảm/loại bỏ đỉnh trên phần identity để đảm bảo rằng các embedding cuối cùng được tập trung chính xác trên phần tử kế tiếp—do đó việc phân loại dựa trên (W, b) xuất ra chính xác phần tử kế tiếp.

Cuối cùng, hãy xem xét các embedding cho token kết thúc đầu vào ⊥ trong Hình 4.14. Ở đây chúng tôi nhất quán quan sát thấy rằng một thao tác minimum có nhiễu được thực hiện ngay sau lớp attention đầu tiên (độ sâu 0): embedding có tích vô hướng lớn nhất với vector trong cơ sở giải mã tương ứng với phần tử nhỏ nhất trong đầu vào!

Để tóm tắt, hãy xem xét đầu vào σ0, ..., σn−1, với token ⊥ ở vị trí n. Chúng tôi nhất quán quan sát thấy rằng các embedding gợi ý cơ chế học tập sau:

(i) Bất kỳ token σi nào ở vị trí i < n có một đỉnh sắc nét trên vector cơ sở mã hóa tương ứng với ký hiệu σi trong suốt suy luận.

(ii) Embedding cho dấu phân cách kết thúc đầu vào ⊥ thường thực hiện một thao tác minimum có nhiễu trong cơ sở giải mã sau lớp self-attention độ sâu 0.

(iii) Bất kỳ token nào ở vị trí i > n (tức là một phần của đầu ra) thường thực hiện thao tác Identity+Successor sau lớp self-attention độ sâu 1. MLP độ sâu 1 hoạt động như một bộ khử nhiễu, loại bỏ đỉnh trên chính ký hiệu đó, sau đó chỉ làm nổi bật chính xác phần tử kế tiếp.

Bằng chứng thực nghiệm gợi ý rằng mạng nhằm mục đích giải quyết tác vụ sắp xếp bằng cách sử dụng một thuật toán tự nhiên: (a) đầu tiên tìm phần tử nhỏ nhất để theo sau ký hiệu ⊥, và sau đó (b) tính toán phần tử kế tiếp cho mỗi phần tử. Hơn nữa, điều này gợi ý tại sao các gợi ý kế tiếp có lợi ích cao: những gợi ý này phù hợp tốt với các khái niệm giải pháp mà mạng đang cố gắng học. Để xác nhận thêm giả thuyết này, chúng tôi so sánh mức độ hiệu quả của các biểu diễn nội tại của những mô hình độ sâu 2 này (được huấn luyện có/không có gợi ý) trong việc thực hiện các cơ chế được đề cập ở trên. Cụ thể, chúng tôi đo lường tần suất:

(i) embedding cho token ⊥ sau lớp self-attention độ sâu 0 tính toán phần tử nhỏ nhất đầu vào (điều này được đo bằng cách tính tích vô hướng của embedding với cơ sở giải mã), và

(ii) embedding cho các token trong chuỗi đầu ra (những token sau ⊥) thực hiện chính xác cơ chế Identity+Successor sau thao tác attention lớp 2.

Hình 4.15 và 4.16 cho thấy rằng việc sử dụng gợi ý kế tiếp cải thiện đáng kể độ chính xác của hai cơ chế này trong các biểu diễn nội tại, đặc biệt là ở các độ dài không được thấy trong quá trình huấn luyện. Chúng tôi phỏng đoán rằng nói chung, các tác vụ phụ trợ phù hợp tốt với thiên hướng ngầm của mạng có xu hướng giúp ích nhất để có được tính bền vững ngoài phân phối.

Phân tích của chúng tôi ở trên cho thấy rằng các kỹ thuật dựa trên phép chiếu trực tiếp có thể giúp làm sáng tỏ một số cơ chế thuật toán cơ bản của các mạng transformer, và cung cấp những hiểu biết thú vị. Hơn nữa, tính tổng quát của các kỹ thuật này mang lại hy vọng rằng chúng có thể được sử dụng cho các vấn đề quy mô lớn khác.

## 5. Phân tích Lý thuyết

Các phần trước dựa vào bộ công cụ trực quan hóa và thăm dò sử dụng các cơ sở mã hóa/giải mã để thu thập bằng chứng thực nghiệm về cơ chế đã học và hiệu quả của tác vụ tìm phần tử kế tiếp. Trong phần này, chúng tôi đặt ra các câu hỏi: liệu chúng tôi có thể đưa ra một cấu trúc lý thuyết phù hợp với các phát hiện thực nghiệm, và có thể được thực hiện thông qua một mô hình transformer nông hay không? Cấu trúc này cho chúng tôi biết gì về tổng quát hóa độ dài? Các nghiên cứu lý thuyết gần đây đã ám chỉ đến khả năng rằng các transformer log-precision có thể nắm bắt lớp độ phức tạp của các mạch TC0. Vì đã chỉ ra rằng sắp xếp thực sự nằm trong TC0, có thể hình dung rằng người ta có thể thiết kế các mô hình transformer độ sâu hằng số cho việc sắp xếp.

Mặc dù có thể có nhiều cấu trúc như vậy của các mô hình transformer nông, chúng tôi áp đặt một số ràng buộc bổ sung: (a) chúng tôi yêu cầu một mô hình độ sâu hai, và (b) kích thước của mạng nên độc lập với độ dài đầu vào n, mặc dù các tham số có thể phụ thuộc logarit vào n. Cuối cùng, chúng tôi muốn một cấu trúc hiển thị các thuộc tính thực nghiệm chúng tôi quan sát thấy trong Phần 4. Chúng tôi hy vọng rằng bằng cách có được một cấu trúc lý thuyết gần với hành vi được quan sát thực nghiệm, chúng tôi có thể tạo ra những hiểu biết hữu ích hơn về mặt thực tế từ lý thuyết.

Chính thức, chúng tôi cố định một bảng chữ cái Σ có kích thước q. Chúng tôi có một ký hiệu đặc biệt ⊥, là dấu phân cách kết thúc chuỗi. Hãy để Σ′ biểu thị bảng chữ cái mở rộng Σ ∪ {⊥}. Chúng tôi liên kết Σ với các số tự nhiên {1, 2, ..., q}, với thứ tự toàn phần thông thường trên chúng. Vì chúng tôi tìm cách sắp xếp các chuỗi bằng cách sử dụng dự đoán token tiếp theo, đầu vào là một chuỗi có độ dài T bao gồm ba phần khái niệm:

1. trước dấu phân cách: một chuỗi σ0, σ1, ..., σn−1 trong đó mỗi σi ∈ Σ. Những cái này đại diện cho đầu vào chưa được sắp xếp.

2. dấu phân cách kết thúc chuỗi: σn = ⊥.

3. sau dấu phân cách: một chuỗi i = T − n − 1 ký hiệu σn+1, σT+2, ..., σT−1 từ Σ, lý tưởng nhất là đại diện cho i ký hiệu nhỏ nhất trong đầu vào σσσ[0:n−1] (theo thứ tự không giảm).

Cho chuỗi σσσ này, chúng tôi muốn dự đoán ký hiệu tiếp theo theo thứ tự đã sắp xếp của đầu vào σσσ[0:n−1]. Cuối cùng, chúng tôi xem xét các transformer với thao tác softmax được điều chỉnh nhiệt độ, tức là cho x ∈ Rd, softmax_τ(x)_i = e^{τx_i} / Σ_j e^{τx_j}. Trong cấu trúc của chúng tôi, chúng tôi xem xét các mô hình transformer trong đó τ = β ln n và β là một tham số có thể điều chỉnh/học được, và n là độ dài chuỗi. Đây là một sự khác biệt so với thực hành tiêu chuẩn luôn đặt τ = 1, độc lập với độ dài đầu vào. Chúng tôi chứng minh định lý sau:

**Định lý 5.1.** Đối với bất kỳ bảng chữ cái nào có kích thước q và độ phức tạp độ chính xác bit b, tồn tại một mô hình transformer chỉ giải mã độ sâu 2 với hai đầu attention, chiều embedding và chiều lớp ẩn là O(q), và trọng số mạng được mã hóa bằng b bit độ chính xác, giải quyết chính xác tác vụ sắp xếp trên chuỗi có độ dài lên đến 2^{Ω(b)}. Hơn nữa, mạng hiển thị các đặc tính sau:

1. Đối với bất kỳ vị trí i < n nào, embedding thu được sau lớp attention đầu tiên được tập trung cao trên σi trong cơ sở mã hóa, do đó thực hiện thao tác sao chép.

2. Đối với token ⊥, embedding sau lớp attention đầu tiên có tích vô hướng cao nhất (trong cơ sở giải mã) với phần tử nhỏ nhất trong chuỗi, do đó thực hiện thao tác min.

3. Đối với bất kỳ vị trí i > n nào, embedding thu được sau lớp attention thứ hai được tập trung (trong cơ sở giải mã) trên token ở vị trí i và phần tử lớn nhất tiếp theo trong chuỗi đã sắp xếp, do đó thực hiện thao tác Identity&Successor.

**Hàm ý Thuật toán.** Lưu ý rằng cấu trúc lý thuyết của chúng tôi dựa vào khả năng áp dụng các thao tác softmax được điều chỉnh nhiệt độ phụ thuộc vào độ dài. Điều này quan trọng để chúng tôi đảm bảo rằng hiệu suất của mạng không giảm với độ dài chuỗi tăng. Cho cấu trúc lý thuyết này, chúng tôi hỏi liệu việc kết hợp các thao tác softmax được điều chỉnh nhiệt độ phụ thuộc vào độ dài được đề xuất bởi lý thuyết có thể giúp với tổng quát hóa độ dài trong thực tế hay không. Để thực hiện điều này, chúng tôi sửa đổi codebase Flaxformer để giới thiệu softmax được điều chỉnh nhiệt độ ở mỗi lớp attention (với mỗi tham số β có thể học riêng của nó). Chúng tôi huấn luyện các mô hình transformer độ sâu hai trên cùng một tập huấn luyện có kích thước 160M, cả có và không có gợi ý, và so sánh hiệu suất với và không có các thao tác softmax được điều chỉnh nhiệt độ.

Như chúng tôi quan sát thấy trong Bảng 1 và 2, việc giới thiệu softmax được điều chỉnh nhiệt độ cải thiện đáng kể tổng quát hóa độ dài của các mô hình được huấn luyện thông qua huấn luyện tiêu chuẩn, cũng như những mô hình được huấn luyện thông qua gợi ý tác vụ. Hơn nữa, softmax được điều chỉnh nhiệt độ giúp ích trên tất cả các phạm vi quy mô dữ liệu. Cụ thể, ngay cả đối với mô hình được huấn luyện không có gợi ý trên tập huấn luyện có kích thước 1M, độ chính xác kiểm tra trên các chuỗi có độ dài 100 tăng từ 0% lên 42% do việc giới thiệu softmax được điều chỉnh nhiệt độ!

## 6. Gợi ý Tác vụ cho Các Vấn đề Khác

Trong phần này, chúng tôi thảo luận về tính hiệu quả của phương pháp đề xuất của chúng tôi cho một vấn đề khác: tăng một số nguyên dương, tức là cộng 1 vào nó. Như chúng tôi sẽ thấy, việc các transformer có thể tổng quát hóa trên các độ dài chưa thấy ngay cả đối với thiết lập đơn giản này là khá khó khăn. Chúng tôi một lần nữa huấn luyện các mô hình chỉ giải mã tạo ra từng token một. Tương tự như trường hợp sắp xếp, chúng tôi sử dụng token ⊥ để biểu thị kết thúc chuỗi đầu vào. Mỗi ví dụ trong tập huấn luyện là một chuỗi có dạng: [1,2,3,⊥,4,2,1], trong đó đầu ra được tạo ra theo thứ tự ngược, vì đó là cách con người có xu hướng giải quyết tác vụ này.

Tập huấn luyện chứa 1M trường hợp có độ dài lên đến 10. Tương tự như trường hợp sắp xếp, chúng tôi làm xiêng phân phối về phía các chuỗi ngắn hơn bằng cách lấy mẫu 80% các trường hợp từ độ dài lên đến 4. Cuối cùng, chúng tôi đảm bảo rằng 10% các mẫu kết thúc bằng một chuỗi ngẫu nhiên gồm các số 9, vì những trường hợp này quan trọng để mô hình học khái niệm nhớ.

Việc giải quyết tác vụ tăng thông qua mạng chỉ giải mã nhân quả mang lại một tập hợp thách thức khác với sắp xếp—trường hợp không còn bất biến theo hoán vị, và khi số lượng token đầu ra tăng, mô hình phải chú ý đến một vị trí cụ thể xa hơn về phía trái trong chuỗi đầu vào. Chúng tôi so sánh các thuộc tính tổng quát hóa độ dài của các mô hình thu được thông qua huấn luyện tiêu chuẩn với những mô hình thu được thông qua gợi ý tác vụ hoặc thông qua việc giới thiệu thao tác softmax được điều chỉnh nhiệt độ. Đối với gợi ý tác vụ, chúng tôi xem xét gợi ý tự nhiên là làm cho mô hình xuất ra chuỗi nhớ cùng với chuỗi đầu ra. Do đó, một trường hợp từ tác vụ phụ trợ sẽ được cấu trúc như

[1,2,3,⊥,4,↑,0,2,↑,0,1,↑,0],

trong đó token ↑ biểu thị rằng mô hình nên xuất ra giá trị nhớ chính xác ở bước tiếp theo.

Chúng tôi huấn luyện các mô hình transformer độ sâu bốn cho tác vụ này và đánh giá độ chính xác kiểm tra của chúng trong việc giải quyết bài toán tăng một cách chính xác.

Bảng 3 so sánh hiệu suất của mô hình được huấn luyện thông qua huấn luyện tiêu chuẩn với (a) mô hình được huấn luyện thông qua gợi ý tác vụ, và (b) mô hình được huấn luyện sử dụng softmax được điều chỉnh nhiệt độ. Chúng tôi quan sát thấy rằng mặc dù gợi ý tác vụ giúp cải thiện tổng quát hóa độ dài, những cải thiện này nhỏ hơn so với những cải thiện cho việc sắp xếp. Tuy nhiên, chúng tôi quan sát thấy rằng mô hình dựa trên softmax được điều chỉnh nhiệt độ giúp cải thiện tổng quát hóa độ dài ở mức độ lớn hơn nhiều.

## 7. Thảo luận và Hạn chế

Trong nghiên cứu này, chúng tôi đã đề xuất gợi ý tác vụ như một phương pháp hiệu quả cho vấn đề tổng quát hóa độ dài. Chúng tôi quan sát thấy rằng việc sử dụng các gợi ý có sự phù hợp mạnh mẽ với các thiên hướng nội tại của cơ chế học tập có thể dẫn đến những lợi ích đáng kể trong tính bền vững ngoài phân phối cho vấn đề sắp xếp các số nguyên. Đối với thiết lập này, chúng tôi sử dụng các kỹ thuật thăm dò và dựa trên trực quan hóa để điều tra các cơ chế học tập nội tại; những kỹ thuật này cho phép chúng tôi giải thích thành công của các gợi ý dựa trên phần tử kế tiếp mà chúng tôi sử dụng trong các thí nghiệm. Nói chung, ngay cả những phương pháp thăm dò/trực quan hóa này cũng có thể không luôn khả thi cho các thiết lập quy mô lớn, vì vậy việc thiết kế các tác vụ gợi ý thích hợp có thể là một vấn đề riêng: sẽ tốt nếu phát triển một phương pháp có nguyên tắc để quyết định các tác vụ gợi ý.

Mặc dù chúng tôi quan sát thấy rằng các tác vụ gợi ý tự nhiên khác, như tác vụ đếm và tác vụ điền không giúp ích (và đôi khi thậm chí còn làm tổn hại hiệu suất), chúng tôi cảm thấy rằng đây là những khả năng phụ trợ hữu ích cho một mạng sắp xếp, và sẽ tốt nếu hiểu được sự thiếu thành công của chúng ở mức độ sâu hơn. Hơn nữa, cũng sẽ thú vị khi kết hợp nhiều gợi ý, và làm cho mạng hưởng lợi từ việc học nhiều hơn hai tác vụ đồng thời. Chúng tôi đã thử phương pháp này cho vấn đề sắp xếp, trong đó chúng tôi huấn luyện mô hình để hoạt động tốt trên cả ba loại tác vụ gợi ý đồng thời, nhưng quan sát thấy kết quả hỗn hợp hoặc thậm chí tiêu cực.

Nghiên cứu của chúng tôi cũng đề xuất việc giới thiệu các tham số phụ thuộc vào độ dài vào cơ chế attention, và quan sát thấy rằng chúng tăng đáng kể tính bền vững của các mô hình cho cả vấn đề sắp xếp và vấn đề tăng. Sẽ thú vị khi áp dụng điều này cho các thiết lập quy mô lớn hơn của việc huấn luyện các mô hình ngôn ngữ, và đánh giá xem liệu có thể có được bất kỳ lợi ích nào về tính bền vững trên các tác vụ suy luận tổng quát hơn hay không. Cuối cùng, khi sử dụng khung học tập đa tác vụ để làm cho mạng học cả hai tác vụ đồng thời, chúng tôi không nỗ lực tối ưu hóa các tham số khác nhau của thiết lập, và đã tuân theo một công thức đơn giản là xen kẽ các cập nhật gradient trên mỗi tác vụ. Các tối ưu hóa thêm trong giai đoạn này có thể dẫn đến hiệu suất tốt hơn.

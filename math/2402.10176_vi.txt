# 2402.10176.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2402.10176.pdf
# Kích thước file: 1281041 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
OpenMathInstruct-1: Bộ Dữ Liệu Điều Chỉnh Hướng Dẫn Toán Học 1.8 Triệu

Shubham Toshniwal, Ivan Moshkov, Sean Narenthiran, Daria Gitman,
Fei Jia, Igor Gitman
NVIDIA

Tóm tắt
Nghiên cứu gần đây đã cho thấy tiềm năng to lớn của các bộ dữ liệu được tạo ra một cách tổng hợp
để huấn luyện các mô hình ngôn ngữ lớn (LLMs), đặc biệt là để thu được các kỹ năng được nhắm mục tiêu.
Các bộ dữ liệu điều chỉnh hướng dẫn toán học quy mô lớn hiện tại như MetaMathQA [1] và
MAmmoTH [2] được xây dựng bằng cách sử dụng các đầu ra từ các LLMs nguồn đóng với các
giấy phép có hạn chế thương mại. Một lý do chính hạn chế việc sử dụng các LLMs nguồn mở
trong các đường ống tạo dữ liệu này là khoảng cách lớn giữa các kỹ năng toán học
của các LLMs nguồn đóng tốt nhất, như GPT-4, và các LLMs nguồn mở tốt nhất. Dựa trên
sự mới lạ trong prompting mà chúng tôi đề xuất, tiến bộ gần đây trong các LLMs nguồn mở, và
một số scaling brute-force, chúng tôi xây dựng OpenMathInstruct-1, một
bộ dữ liệu điều chỉnh hướng dẫn toán học chất lượng cao với 1.8M cặp bài toán-giải pháp. Bộ
dữ liệu được xây dựng bằng cách tổng hợp các giải pháp code-interpreter cho GSM8K và
MATH, hai benchmark lý luận toán học phổ biến, sử dụng mô hình Mixtral được phát hành gần đây và
có giấy phép cho phép. Mô hình tốt nhất của chúng tôi, OpenMath-CodeLlama-70B,
được huấn luyện trên một tập con của OpenMathInstruct-1, đạt điểm 84.6% trên GSM8K
và 50.7% trên MATH, có tính cạnh tranh với các mô hình gpt-distilled tốt nhất.
Để hỗ trợ các nỗ lực nguồn mở, chúng tôi đã phát hành code, mô hình, và
bộ dữ liệu OpenMathInstruct-1 dưới giấy phép cho phép thương mại.¹

1 Giới thiệu
Chi phí phát triển và suy luận khổng lồ liên quan đến các mô hình ngôn ngữ lớn (LLMs) đa năng
đã dẫn đến sự gia tăng của các LLMs nhỏ hơn, chuyên biệt cho tác vụ. Nghiên cứu gần đây đã đề xuất tạo ra các
LLMs chuyên biệt cho miền/tác vụ này bằng cách tạo ra dữ liệu tổng hợp chất lượng cao sử dụng các
mô hình nguồn đóng mạnh mẽ như GPT-3.5/4 [3] và huấn luyện các mô hình nhỏ hơn trên dữ liệu chưng cất được tạo ra [4,5,6].
Đối với lý luận toán học, tác vụ mà chúng tôi quan tâm, tất cả các mô hình nguồn mở hiện tại tiên tiến nhất
đều là gpt-distilled [7,2,8,9]. Tuy nhiên, các công thức phát triển mô hình dựa vào các mô hình độc quyền
như GPT-4 có thể có những hạn chế nghiêm trọng: (a) các ràng buộc pháp lý về cách các mô hình được tinh chỉnh có thể
được sử dụng,² (b) tạo dữ liệu với các mô hình nguồn đóng thường tốn kém hơn so với các
mô hình nguồn mở tiên tiến nhất, và (c) các công thức này thiếu khả năng tái tạo vì hành vi của mô hình nguồn đóng có thể thay đổi
đáng kể theo thời gian [10].

Để phát triển các mô hình lý luận toán học, tại sao các mô hình nguồn mở không được sử dụng thay thế
cho các mô hình nguồn đóng? Để trả lời điều này, chúng tôi so sánh GPT-4 với mô hình Mixtral 8x7B [11],
một trong những LLMs nguồn mở tốt nhất về lý luận toán học vào đầu năm 2024, bằng cách tạo ra các giải pháp
kiểu code-interpreter cho hai benchmark lý luận toán học phổ biến, cụ thể là GSM8K [12]

¹Dữ liệu và mô hình có sẵn tại https://huggingface.co/collections/nvidia/
openmath-65c5619de2ba059be0775014
Code có sẵn tại https://github.com/Kipok/NeMo-Skills
²https://openai.com/policies/terms-of-use

38th Conference on Neural Information Processing Systems (NeurIPS 2024).arXiv:2402.10176v2 [cs.CL] 3 Nov 2024

--- TRANG 2 ---
Hình 1: Phạm vi bao phủ tập huấn luyện của các giải pháp do mô hình Mixtral tạo ra như là hàm của số
giải pháp được lấy mẫu cho mỗi bài toán (sử dụng temperature 1.0 và top_p = 0.95). Thống kê cho
phạm vi bao phủ tập huấn luyện của GPT-4 là từ [8].

và MATH [13]. Chúng tôi sử dụng metric phạm vi bao phủ tập huấn luyện (TSC) để so sánh các mô hình, trong đó
TSC đo số lượng bài toán huấn luyện mà bất kỳ giải pháp nào được tạo ra dẫn đến
câu trả lời chính xác (pass@k). Hình 1 cho thấy phạm vi bao phủ tập huấn luyện (TSC) của mô hình Mixtral
như là hàm của số lượng giải pháp được lấy mẫu. Đối với benchmark GSM8K tương đối dễ hơn, phạm vi bao phủ
của mô hình Mixtral đuổi kịp GPT-4 với gần 8x số lượng mẫu giải pháp. Đối
với benchmark MATH thách thức, thậm chí với 12x số lượng giải pháp, mô hình Mixtral vẫn
có TSC thấp hơn GPT-4. Khoảng cách trong phạm vi bao phủ tập huấn luyện này phản ánh chất lượng dữ liệu chưng cất
và do đó, chất lượng của mô hình được tinh chỉnh cuối cùng. Điều này giải thích sự ưa thích GPT-4 trong
các đường ống chưng cất hiện tại cho lý luận toán học.

Bắc cầu khoảng cách bao phủ giữa GPT-4 và LLMs Nguồn mở: Chúng tôi giới hạn cuộc điều tra của mình về các
LLMs nguồn mở để tổng hợp giải pháp đối với mô hình Mixtral-base do (a) hiệu suất mạnh mẽ của nó trên
các tác vụ lý luận toán học so với các LLMs nguồn mở khác, và (b) giấy phép cho phép của nó.³
Như một nỗ lực đầu tiên, chúng tôi sử dụng phương pháp brute-force của việc lấy mẫu nhiều giải pháp cho mỗi bài toán. Tuy nhiên,
phương pháp này chỉ mở rộng theo logarit, hạn chế hiệu quả của nó (Hình 1). Tiếp theo, chúng tôi khám phá
phương pháp tạo giải pháp được nhắm mục tiêu, trong đó chúng tôi viết các prompts few-shot tập trung vào các
phần cụ thể của dữ liệu huấn luyện. Cụ thể, chúng tôi viết các prompts few-shot cho mỗi môn toán học trong
bộ dữ liệu MATH và hợp nhất các giải pháp được tổng hợp. Động lực là các prompts few-shot chuyên biệt theo môn học
này có thể nhắm mục tiêu tốt hơn các khả năng toán học tiềm ẩn của các LLMs đa năng này. Thật không may, chúng tôi chỉ tìm thấy
một mức tăng cận biên trong TSC với phương pháp này (Phần 2.2.2). Cuối cùng,
chúng tôi tận dụng thực tế là các giải pháp văn bản tham khảo đi kèm với các benchmark toán học như MATH
và GSM8K. Các giải pháp tham khảo này có thể hỗ trợ việc tổng hợp các giải pháp kiểu code-interpreter.
Chúng tôi cho thấy rằng việc sử dụng các giải pháp tham khảo này trong prompt few-shot của chúng tôi với một sửa đổi nhỏ
tăng đáng kể phạm vi bao phủ và do đó, hiệu suất của mô hình được tinh chỉnh
(Phần 2.2.3 và 4.1.2).

Các thí nghiệm tổng hợp giải pháp của chúng tôi dẫn đến OpenMathInstruct-1, một bộ sưu tập 1.8M cặp bài toán-
giải pháp. OpenMathInstruct-1 có phạm vi bao phủ tập huấn luyện 93% cho MATH và 99.9% cho
GSM8K. Bảng 1 cho thấy rằng so với các bộ dữ liệu tinh chỉnh lý luận toán học trước đó,
OpenMathInstruct-1 lớn hơn ít nhất bốn lần, và quan trọng hơn nữa, nó có
giấy phép cho phép, cho phép sử dụng không hạn chế bởi các nghiên cứu tương lai. Để minh họa chất lượng của OpenMathInstruct-1,
chúng tôi huấn luyện và phát hành một loạt mô hình dựa trên Mistral-7B [14], Llama 2 [15], và CodeLlama [16].
Đặc biệt, mô hình CodeLlama-70B được tinh chỉnh trên một tập con của OpenMathInstruct-1, được
gọi là OpenMath-CodeLlama-70B, đạt điểm 84.6% trên GSM8K và 50.7% trên MATH.
Các điểm số này có tính cạnh tranh với các mô hình GPT-distilled tốt nhất hiện tại. Cuối cùng, để hỗ trợ các
nỗ lực nguồn mở theo hướng này, chúng tôi đã công khai phát hành tất cả các mô hình được tinh chỉnh, code,
và bộ dữ liệu OpenMathInstruct-1, cùng với thêm 6.6M giải pháp được lấy mẫu không chính xác dưới
giấy phép cho phép thương mại.⁴

³https://mistral.ai/news/mixtral-of-experts/
⁴Các quỹ đạo giải pháp không chính xác có thể được sử dụng để huấn luyện các mô hình xác minh [12, 17, 18].

--- TRANG 3 ---
Bảng 1: So sánh OpenMathInstruct-1 với các bộ dữ liệu tinh chỉnh lý luận toán học được sử dụng
bởi các mô hình nguồn mở tiên tiến nhất hiện tại. OpenMathInstruct-1 lớn hơn 4x so với
bộ dữ liệu lớn nhất hiện tại, MetaMathQA, và là bộ duy nhất, ngoại trừ Lila, có giấy phép cho phép. Các bộ dữ liệu
được đánh dấu * chưa được công bố công khai.

Bộ dữ liệu | Kích thước | LM Tạo ra (Giấy phép Cho phép)
Lila [19] | 272K | - (✓)
MathInstruct [2] | 262K | GPT-4 (✗)
MetaMathQA [1] | 395K | GPT-3.5 (✗)
MathCodeInstruct [7] | 80K | GPT-4 + Self (✗)
WizardMath* [20] | 96K | GPT-3.5 (✗)
ToRA* [8] | 16K | GPT-4 (✗)
OpenMathInstruct-1 (Của chúng tôi) | 1.8M | Mixtral (✓)

2 Tổng hợp Dữ liệu Huấn luyện

2.1 Tổng quan

Thiết lập. Cho X={(q1, a1),···,(qN, aN)} là một bộ dữ liệu huấn luyện lý luận toán học điển hình,
trong đó qi và ai biểu thị câu hỏi và câu trả lời thứ i tương ứng. Tùy chọn, bộ dữ liệu huấn luyện có thể
bao gồm giải pháp văn bản tham khảo ti, minh họa một quỹ đạo từ qi đến ai sử dụng các
nguyên lý toán học.⁵ Bên cạnh dữ liệu, chúng tôi giả định có quyền truy cập vào một LLM nền tảng như Mixtral-base. 
Mục tiêu là tạo ra các giải pháp đa dạng, chất lượng cao cho các bài toán tập huấn luyện sử dụng LLM: một
công thức phổ biến cho các tác vụ lý luận [21,22]. Nghiên cứu gần đây cũng đã cố gắng tăng cường các
bài toán tập huấn luyện [1,2], nhưng chúng tôi giới hạn khám phá của mình vào việc tổng hợp giải pháp cho các bài toán hiện có trong
benchmark.

Định dạng Giải pháp. Chúng tôi sử dụng định dạng code-interpreter cho các giải pháp được tổng hợp (xem Hình 5
trong Phụ lục để biết mẫu giải pháp). Định dạng code-interpreter xen kẽ lý luận ngôn ngữ tự nhiên
với các khối code Python. Do đó nó kết hợp độ chính xác tính toán của môi trường coding
với tính biểu đạt của lý luận ngôn ngữ tự nhiên, điều này đặc biệt phù hợp cho các
tác vụ lý luận toán học [8,23]. Để phân định bắt đầu và kết thúc của một khối code, chúng tôi sử dụng các chuỗi
⟨llm-code⟩ và ⟨/llm-code⟩. Một khối code được theo sau bởi khối thực thi của nó, được phân
định bởi ⟨llm-code-output⟩ và ⟨/llm-code-output⟩. Trong quá trình suy luận, mô hình gọi
trình thông dịch Python để chạy khối code trước đó sau khi tạo ra ⟨/llm-code⟩, thêm kết quả thực thi
vào giữa các separator ⟨llm-code-output⟩, và tiếp tục suy luận mô hình tự hồi quy.⁶

Phương pháp. Chúng tôi sử dụng prompting few-shot để tổng hợp giải pháp cho các tập huấn luyện của GSM8K và
MATH. Chính thức, prompt có dạng:

I(q1, c1),···,(qK, cK)q′

trong đó I đại diện cho một hướng dẫn dựa trên văn bản cho tác vụ, {q1,···, qK} đại diện cho K bài toán đại
diện cho bộ dữ liệu, {c1,···, cK} đại diện cho các giải pháp tương ứng của chúng trong định dạng code-interpreter,
và q′ đại diện cho một câu hỏi từ tập huấn luyện. Với prompt này, LLM cơ sở tạo ra
một giải pháp ứng viên c′ cho câu hỏi q′. Nếu c′ dẫn đến câu trả lời chính xác cho câu hỏi q′, chúng tôi
thêm cặp (q′, c′) vào tập tinh chỉnh của chúng tôi. Đối với tất cả các thí nghiệm của chúng tôi, chúng tôi chọn K= 5, và các
bài toán đại diện được chọn từ tập huấn luyện của benchmark tương ứng. Trong hướng dẫn I, chúng tôi hướng dẫn mô hình xuất ra câu trả lời bên trong khối \boxed{}. Hướng dẫn đầy đủ
có trong Bảng 13 trong Phụ lục B.4.

Chi tiết Lấy mẫu. Chúng tôi lấy mẫu các giải pháp với temperature=1.0 và top_p=0.95. Chúng tôi sử dụng các
ràng buộc sau trong đường ống tạo của chúng tôi: (a) tổng số token đầu vào-đầu ra được giới hạn ở
4096, (b) tối đa 512 token mới sau mỗi khối code, (c) tối đa 3 khối code, và
(d) việc tạo ra dừng lại sau bất kỳ lỗi thực thi code nào. Chúng tôi sử dụng bộ công cụ TensorRT-LLM.⁷

⁵Cả GSM8K và MATH đều có các giải pháp văn bản này.
⁶Trong quá trình huấn luyện, chúng tôi không che giấu đầu ra thực thi code được bao quanh bởi các separator ⟨llm-code-output⟩.
⁷https://github.com/NVIDIA/TensorRT-LLM

--- TRANG 4 ---
Bảng 2: Thống kê các giải pháp duy nhất được tạo ra bởi các prompt được mô tả trong Phần 2.2. Prompt mặc định
đề cập đến prompt đơn được sử dụng cho hai benchmark, Mask-Text đề cập đến việc prompting
mô hình với giải pháp văn bản được che giấu, và Subj đề cập đến prompting với các prompt chuyên biệt theo môn học
(chỉ áp dụng cho MATH). Coverage % đề cập đến tỷ lệ phần trăm các bài toán trong tập huấn luyện
mà có ít nhất một giải pháp trong số các giải pháp được tạo ra.

Prompt | MATH | GSM8K
# Mẫu | # Giải pháp Duy nhất | Coverage (%) | # Mẫu | # Giải pháp Duy nhất | Coverage (%)
Mặc định | 224 | 177K | 80.1 | 128 | 434K | 99.1
+ Subj | 224 | 191K | 80.1 | - | - | -
Mask-Text | 224 | 192K | 85.9 | 128 | 602K | 99.9
+ Subj | 224 | 227K | 87.5 | - | - | -
Tổng | 896 | 787K | 93.0 | 256 | 1036K | 99.9

2.2 Prompting

Trong phần trước, chúng tôi đã mô tả đường ống tạo giải pháp của chúng tôi. Một thành phần chính của đường ống này
là các ví dụ prompt few-shot. Chúng tôi tiếp theo mô tả các chiến lược prompting khác nhau được khám phá trong
công trình này.

2.2.1 Mặc định

Chúng tôi chọn năm ví dụ đại diện của GSM8K và MATH để tạo prompt few-shot cho
các bộ dữ liệu tương ứng. Đối với GSM8K, chúng tôi sử dụng hỗn hợp các bài toán yêu cầu code Python vanilla
và các bài toán được giải tốt nhất bằng thư viện sympy của Python. Đối với MATH, chúng tôi soạn một
prompt 5-shot với các ví dụ từ các môn học khác nhau. Để phản ánh sự đa dạng này của các đường lý luận cần thiết cho
MATH, chúng tôi chọn hỗn hợp các bài toán yêu cầu giải pháp dựa trên code, giải pháp dựa trên văn bản, và
kết hợp của cả hai. Các prompt được sử dụng cho hai bộ dữ liệu được trình bày trong Phụ lục B.6.

Đối với GSM8K, chúng tôi lấy mẫu 128 giải pháp cho mỗi bài toán huấn luyện, điều này có được phạm vi bao phủ tập huấn luyện
99.1%. Đối với MATH, chúng tôi lấy mẫu 224 giải pháp cho mỗi bài toán huấn luyện, điều này chỉ đạt được phạm vi bao phủ tập huấn luyện
80.1%. Sự khác biệt trong phạm vi bao phủ này phản ánh độ khó của benchmark MATH
so với GSM8K, điều này đã được lưu ý trong các nghiên cứu trước đó cũng như [8, 9].

2.2.2 Prompting Chuyên biệt theo Môn học (Subj)

Liệu sự đa dạng của các chủ đề toán học trong MATH có thể là lý do cho phạm vi bao phủ tập huấn luyện thấp
với một prompt 5-shot đơn? Để trả lời câu hỏi này, chúng tôi tạo các prompt chuyên biệt theo môn học cho
bảy môn học trong benchmark MATH, cụ thể là algebra, geometry, intermediate algebra,
number theory, prealgebra, precalculus, và probability (Xem Bảng 11 trong phụ lục
cho phân chia theo môn học của dữ liệu huấn luyện MATH). Benchmark MATH cũng gắn nhãn các bài toán theo
mức độ khó của chúng, với các mức từ 1 đến 5, trong đó mức 5 là khó nhất. Để tạo
các prompt 5-shot chuyên biệt theo môn học, chúng tôi chọn một ví dụ từ mỗi mức cho một môn học cụ thể. Đối với mỗi
trong bảy prompt, chúng tôi lấy mẫu 32 giải pháp cho mỗi bài toán và kết hợp dữ liệu được tạo ra với tất cả
các prompt, điều này tương đương với 32 x 7 = 224 giải pháp cho mỗi bài toán. Tuy nhiên, thậm chí với
prompting chi tiết này, chúng tôi chỉ đạt được một mức tăng không đáng kể trong phạm vi bao phủ tập huấn luyện, mặc dù
tổng số giải pháp chính xác tăng lên 14K (177K →191K, xem Bảng 2).

Kết hợp bộ dữ liệu tinh chỉnh này với bộ dữ liệu prompt mặc định đơn trước đó mang lại phạm vi bao phủ huấn luyện
85.1% cho MATH, tăng 5% tuyệt đối. Tuy nhiên, để đạt được phạm vi bao phủ này cần
lấy mẫu gần 450 giải pháp cho mỗi bài toán (224 + 224 = 448). Liệu chúng ta có thể làm cho đường ống tạo giải pháp
hiệu quả hơn không?

2.2.3 Prompting Giải pháp Văn bản Được Che giấu (Mask-Text)

Các benchmark GSM8K và MATH đi kèm với các giải pháp văn bản tham khảo. Việc sử dụng các giải pháp văn bản này có thể,
về mặt lý thuyết, giảm vấn đề tạo giải pháp code-interpreter thành một vấn đề dịch thuật từ
văn bản sang code. Ban đầu chúng tôi đã thí nghiệm bằng cách prompting LLM với:

I(q1, t1, c1),···,(qK, tK, cK)q′, t′

--- TRANG 5 ---
Giải pháp Văn bản Được Che giấu

Câu hỏi
Lynne mua 7 cuốn sách về mèo và 2 cuốn sách về hệ mặt trời. Cô ấy cũng mua 3 tạp chí. Mỗi
cuốn sách có giá $7 và mỗi tạp chí có giá $4. Lynne đã chi bao nhiều tiền tổng cộng?

Giải pháp Văn bản Chính xác
Lynne đã mua tổng cộng 7 + 2 = 9 cuốn sách. Các cuốn sách đã khiến Lynne tốn 9 x 7 = $63. Đối với 3 tạp chí, Lynne đã chi 3
x 4 = $12. Tổng cộng, Lynne đã chi 63 + 12 = $75

Giải pháp Văn bản Được Che giấu
Lynne đã mua tổng cộng 7 + 2 = M cuốn sách. Các cuốn sách đã khiến Lynne tốn M x 7 = N. Đối với 3 tạp chí, Lynne đã chi 3
x 4 = P. Tổng cộng, Lynne đã chi N + P = Q

Hình 2: Một mẫu giải pháp được che giấu từ tập huấn luyện GSM8K. Giải pháp văn bản được che giấu chỉ che giấu
các phép tính trung gian, như 9 →M và 63 →N, và không che giấu các số lượng được giới thiệu
trong câu hỏi, như 7, 2, và $4.

trong đó ti's đại diện cho giải pháp văn bản của bài toán đại diện qi's và t′ đại diện cho giải pháp văn bản
của bài toán q′. Việc sử dụng giải pháp văn bản trong prompt dẫn đến tăng đáng kể trong phạm vi bao phủ tập huấn luyện. Tuy nhiên, phân tích thủ công của chúng tôi tiết lộ rằng nhiều giải pháp là các đường tắt. Ví dụ, các
giải pháp tầm thường như print(ANSWER) hoặc Câu trả lời là ANSWER trong đó ANSWER được sao chép từ
giải pháp văn bản t′ trong prompt. Các nỗ lực của chúng tôi để lọc ra các giải pháp tầm thường này tỏ ra thách thức
vì có nhiều cách sáng tạo mà các giải pháp được tạo ra đang gian lận (xem Hình 11 trong
Phụ lục).

Để ngăn chặn khả năng các giải pháp đường tắt như vậy trong đó kết quả của các phép tính trung gian hoặc
câu trả lời cuối cùng từ giải pháp văn bản được sao chép, chúng tôi đề xuất prompting với giải pháp văn bản được che giấu.
Các giải pháp như vậy có tất cả các số trong các phép tính trung gian được thay thế bằng các ký hiệu. Một mẫu
giải pháp văn bản được che giấu được hiển thị trong Hình 2. Các giải pháp văn bản được che giấu này được tạo ra bằng cách sử dụng
prompting few-shot như sau:

Imask(q1, t1, tmask₁),···,(qK, tK, tmaskₖ)q′, t′

trong đó Imask đại diện cho hướng dẫn cho tác vụ che giấu giải pháp, và {tmask₁,···, tmaskₖ} đại diện cho
các giải pháp văn bản được che giấu tương ứng với {t1,···, tK}. Để có cái nhìn tổng quan chi tiết về đường ống tạo giải pháp văn bản được che giấu, chúng tôi tham khảo độc giả đến Phụ lục B.5. Việc sử dụng các giải pháp văn bản được che giấu này
trong các prompt làm tăng đáng kể phạm vi bao phủ tập huấn luyện cho MATH, tăng từ 80.1% →
85.9% cho prompt mặc định đơn, và 80.1% →87.5% cho các prompt chuyên biệt theo môn học. Đối với
GSM8K, nó dẫn đến phạm vi bao phủ tăng từ 99.1% lên 99.9%.

Bảng 2 tóm tắt thống kê của bộ dữ liệu giải pháp được tạo ra thông qua các prompt khác nhau. Bộ dữ liệu
OpenMathInstruct-1 được thu được bằng cách hợp nhất và loại bỏ trùng lặp các cặp bài toán-giải pháp
từ các chiến lược prompt được mô tả ở trên. OpenMathInstruct-1 bao gồm 787K giải pháp duy nhất
cho 6978 bài toán (trong số 7500) trong MATH và 1.04M giải pháp duy nhất cho 7469 bài toán
(trong số 7473) trong GSM8K. Để đến được bộ dữ liệu cuối cùng này, chúng tôi cũng thực hiện một số bước hậu xử lý,
được mô tả tiếp theo.

2.3 Hậu xử lý

Các giải pháp được tạo ra đôi khi có thể bị nhiễu về mặt cú pháp ngay cả khi chúng dẫn đến câu trả lời đúng.
Chúng tôi sửa hoặc loại bỏ các giải pháp sau:

• Loại bỏ các giải pháp có nhiều khối \boxed{}.
• Loại bỏ các giải pháp có chuỗi ⟨llm-code⟩ nhưng không có chuỗi ⟨/llm-code⟩.
• Loại bỏ văn bản vượt quá dòng giải pháp với câu trả lời, tức là khối \boxed{}. Xem
Hình 12 trong Phụ lục để biết ví dụ giải pháp mà chúng tôi thực hiện cắt tỉa.

Trong khi các bước hậu xử lý này có thể sửa một số lỗi cú pháp, việc lọc các giải pháp nhiễu về mặt ngữ nghĩa,
tức là các giải pháp đến được câu trả lời đúng với lý luận có lỗ hổng [12], là một vấn đề khó hơn nhiều và
nằm ngoài phạm vi của công trình này. Theo kinh nghiệm, chúng tôi thấy các giải pháp như vậy hiếm gặp trong corpus của chúng tôi. Xem
Hình 13 trong Phụ lục để biết mẫu giải pháp nhiễu về mặt ngữ nghĩa.

--- TRANG 6 ---
(a) Lấy mẫu Ngây thơ (b) Lấy mẫu Công bằng

Hình 3: Biểu đồ tần số của số lượng giải pháp cho các bài toán trong tập con 64K được giảm mẫu của các
thể hiện MATH trong OpenMathInstruct-1.

2.4 Lựa chọn Dữ liệu

OpenMathInstruct-1 trung bình có hàng trăm giải pháp cho mỗi bài toán. Các giải pháp này có thể có
các định dạng khác nhau (code vs văn bản), và các bài toán có thể có số lượng giải pháp rất khác nhau trong
bộ dữ liệu. Lựa chọn dữ liệu cẩn thận cho phép giảm thời gian huấn luyện và cũng có thể có lợi cho hiệu suất.
Chúng tôi chi tiết các chiến lược lựa chọn dữ liệu được khám phá trong công trình này.

2.4.1 Giảm mẫu Công bằng vs Ngây thơ

Đối với một bộ dữ liệu như MATH, trong đó các bài toán có mức độ khó khác nhau, chiến lược tạo giải pháp của chúng tôi dẫn đến một corpus trong đó các bài toán dễ hơn có nhiều giải pháp và các bài toán khó hơn có
rất ít giải pháp (xem Phụ lục A.2 để thảo luận chi tiết về số lượng giải pháp). Một chiến lược ngây thơ để
giảm mẫu coi mọi thể hiện, tức là cặp bài toán-giải pháp, là bằng nhau. Việc lấy mẫu bất khả tri bài toán này
duy trì sự mất cân bằng của corpus gốc, như thấy trong Hình 3(a). Chúng tôi đề xuất một
thay thế lấy mẫu công bằng trong đó chúng tôi lặp qua tất cả các bài toán theo vòng tròn và lấy mẫu mà không
thay thế từ các giải pháp còn lại cho mỗi bài toán. Việc lấy mẫu phụ thuộc vào bài toán này
đảm bảo đại diện cân bằng hơn của mỗi bài toán trong bộ dữ liệu được giảm mẫu (xem Hình 3(b)).
Kết quả thí nghiệm cho thấy rằng giảm mẫu công bằng vượt trội hơn giảm mẫu ngây thơ (Phần 4.1.1).

2.4.2 Giải pháp Ưu tiên Code

Định dạng code-interpreter cho phép trộn code và văn bản, và cũng các giải pháp dựa trên văn bản mà không có
bất kỳ khối code nào. Đối với GSM8K, tỷ lệ các giải pháp dựa trên văn bản là 2%, nhưng đối với MATH, đại diện của chúng
là 35.1%.⁸ Trong khi lý luận ngôn ngữ tự nhiên có tính biểu đạt hơn, nó thiếu độ chính xác
của các giải pháp dựa trên code [24]. Giả sử đối với một bài toán q có tổng cộng Ntotal giải pháp chính xác trong
corpus, trong đó Ncode đại diện cho số lượng giải pháp dựa trên code, và Ntext đại diện cho
các giải pháp dựa trên văn bản. Chúng tôi đề xuất hai chiến lược lựa chọn dữ liệu ưu tiên code sau:

• Majority-Code: Nếu Ncode > Ntext, loại bỏ tất cả các giải pháp dựa trên văn bản.
• Any-Code: Nếu Ncode > 0, loại bỏ tất cả các giải pháp dựa trên văn bản.

Các thí nghiệm ablation trên tập con MATH của OpenMathInstruct-1 cho thấy lợi ích của việc lựa chọn dữ liệu
ưu tiên code (Phần 4.1.4).

3 Thiết lập Thí nghiệm

3.1 Chi tiết Huấn luyện

Đối với tất cả các thí nghiệm của chúng tôi, bao gồm cả ablations, các mô hình có kích thước 34B hoặc nhỏ hơn được huấn luyện trong bốn epoch.
Kích thước batch toàn cục 128 được sử dụng cùng với optimizer AdamW với weight decay 1e-

⁸Chúng tôi phát hiện sự hiện diện của code bằng cách tìm kiếm ⟨llm-code⟩ trong chuỗi giải pháp.

--- TRANG 7 ---
Bảng 3: So sánh các mô hình OpenMath-finetuned của chúng tôi với các đối tác gpt-distilled của chúng. Chúng
tôi trình bày kết quả trên các tác vụ lý luận toán học phổ biến, cụ thể là GSM8K, MATH, GSM-Hard,
SVAMP, TabMWP, ASDiv, và MAWPS. Đối với ToRA và MAmmoTH, chúng tôi báo cáo kết quả của các phiên bản
"-Code(r)" của chúng khi có sẵn vì chúng luôn tốt hơn các đối tác không có code của chúng.
SC (k=50) biểu thị giải mã tự nhất quán với 50 mẫu. Chúng tôi nổi bật các kết quả sau đây cho
một dải tham số: tốt nhất với SC, tốt nhất và tốt thứ hai với giải mã greedy.

Kích thước | Mô hình Cơ sở | Mô hình | GSM8K | MATH | GSM-Hard | SVAMP | TabMWP | ASDiv | MAWPS
- | GPT-4 (Code Interpreter) | | 97.0 | 69.7 | 77.6 | 94.8 | 95.9 | 92.6 | 97.7
7B | Llama-2 | WizardMath | 54.9 | 10.7 | - | 36.1 | - | - | -
 | | MetaMath | 66.4 | 19.4 | - | | | | 
 | CodeLlama | MAmmoTH | 59.4 | 33.4 | - | 71.4 | - | - | -
 | | ToRA | 72.6 | 44.6 | 56.0 | 70.4 | 51.6 | 78.7 | 91.3
 | | + SC (k=50) | 76.8 | 52.5 | - | - | - | - | -
 | | OpenMath-CodeLlama | 75.9 | 43.6 | 60.1 | 79.6 | 56.0 | 77.7 | 93.5
 | | + SC (k=50) | 84.8 | 55.6 | - | - | - | - | -
 | Mistral | MetaMath-Mistral-7B | 77.7 | 28.2 | - | - | - | - | -
 | | MAmmoTH-7B-Mistral | 75.0 | 40.0 | - | - | - | - | -
 | | WizardMath | 83.2 | 33.0 | - | - | - | - | -
 | | OpenMath-Mistral-7B | 80.2 | 44.5 | 63.7 | 82.4 | 70.0 | 82.7 | 95.4
 | | + SC (k=50) | 86.9 | 57.2 | - | - | - | - | -
13B | Llama-2 | WizardMath | 63.9 | 14.0 | - | 51.9 | - | - | -
 | | MetaMath | 72.3 | 22.4 | - | - | - | - | -
 | CodeLlama | MAmmoTH | 64.7 | 36.3 | - | 73.7 | - | - | -
 | | ToRA | 75.8 | 48.1 | 60.5 | 75.7 | 65.4 | 81.4 | 92.5
 | | + SC (k=50) | 80.4 | 55.1 | - | - | - | - | -
 | | OpenMath-CodeLlama | 78.8 | 45.5 | 61.9 | 78.8 | 59.7 | 81.2 | 93.6
 | | + SC (k=50) | 86.8 | 57.6 | - | - | - | - | -
34B | CodeLlama | MAmmoTH | 72.7 | 43.6 | - | 84.3 | - | - | -
 | | ToRA | 80.7 | 51.0 | 63.7 | 80.5 | 70.5 | 84.2 | 93.3
 | | + SC (k=50) | 85.1 | 60.0 | - | - | - | - | -
 | | OpenMath-CodeLlama | 80.7 | 48.3 | 64.0 | 83.6 | 66.0 | 82.7 | 94.9
 | | + SC (k=50) | 88.0 | 60.2 | - | - | - | - | -
70B | Llama-2 | WizardMath | 81.6 | 22.7 | - | 71.8 | - | - | -
 | | MetaMath | 82.3 | 26.6 | - | - | - | - | -
 | | MAmmoTH | 76.9 | 41.8 | - | 82.4 | - | - | -
 | | ToRA | 84.3 | 49.7 | 67.2 | 82.7 | 74.0 | 86.8 | 93.8
 | | + SC (k=50) | 88.3 | 56.9 | - | - | - | - | -
 | | OpenMath-Llama2 | 84.7 | 46.3 | 65.7 | 85.0 | 70.8 | 84.3 | 95.6
 | | + SC (k=50) | 90.1 | 58.3 | - | - | - | - | -
 | CodeLlama | OpenMath-CodeLlama | 84.6 | 50.7 | 66.6 | 87.8 | 74.2 | 84.7 | 95.7
 | | + SC (k=50) | 90.8 | 60.4 | - | - | - | - | -

2 [25] và dropout [26] của 0.1. Chúng tôi lưu một checkpoint mỗi epoch cho các thí nghiệm ablation và hai
checkpoint mỗi epoch cho các lần chạy mô hình cuối cùng. Checkpoint cuối cùng được tạo bằng cách tính trung bình tất cả các
checkpoint đã lưu. Tất cả các thí nghiệm được thực hiện bằng bộ công cụ NeMo⁹ [27]. Để biết tập đầy đủ các
siêu tham số huấn luyện, xem Phụ lục B.1.

3.2 Thiết lập Đánh giá

Chúng tôi đánh giá các mô hình của chúng tôi trên các benchmark lý luận toán học phổ biến, cụ thể là GSM8K, MATH, GSM-
Hard [24], SVAMP [28], TabMWP [29], ASDiv [30], và MAWPS [31]. Đối với các thí nghiệm ablation
và lựa chọn siêu tham số, chúng tôi tạo một tập validation 1K ví dụ từ tập huấn luyện của
GSM8K và MATH vì cả hai bộ dữ liệu đều thiếu tập validation thực sự. Tất cả các mô hình được tinh chỉnh được
đánh giá trong thiết lập zero-shot. Chúng tôi sử dụng giải mã greedy và tự nhất quán/bỏ phiếu đa số [32]
để đánh giá. Đối với bỏ phiếu đa số, chúng tôi thấy rằng việc sử dụng temperature thấp hơn 0.7 có lợi
so với thiết lập tạo dữ liệu. Chúng tôi cũng khác biệt với thiết lập tạo dữ liệu bằng cách cho phép
mô hình tiếp tục tạo ra câu trả lời sau các lỗi thực thi code.

⁹https://github.com/NVIDIA/NeMo

--- TRANG 8 ---
4 Kết quả

Chúng tôi tinh chỉnh tất cả các mô hình trên hỗn hợp của (a) 512K thể hiện GSM8K được giảm mẫu công bằng, và (b)
512K thể hiện MATH với lọc any-code (Phần 2.4).¹⁰ Như vậy, tổng kích thước corpus tinh chỉnh
là khoảng 1.02M. Chúng tôi biện minh cho các lựa chọn lựa chọn dữ liệu sau này trong các thí nghiệm ablation.

Bảng 3 so sánh hiệu suất của các mô hình OpenMath-finetuned với các đối tác GPT-distilled của chúng.
Trong số các mô hình 7B, OpenMath-Mistral-7B của chúng tôi có tính cạnh tranh với tất cả các mô hình GPT-distilled.
Nó đứng thứ hai sau WizardMath trên GSM8K, và bị ToRA vượt qua 0.1% trên MATH.¹¹
Các mô hình của chúng tôi dễ dàng vượt trội hơn cả MetaMath [1] và MAmmoTH [2], ngay cả khi kiểm soát
mô hình cơ sở được tinh chỉnh. Vì các bộ dữ liệu tinh chỉnh WizardMath và ToRA chưa được công bố công khai,
OpenMathInstruct-1 trình bày một thay thế vượt trội cho các bộ dữ liệu MetaMathQA và
MathInstruct có sẵn công khai, được sử dụng để tinh chỉnh MetaMath và MAmmoTH tương ứng.

Với sự gia tăng tham số mô hình, các mô hình của chúng tôi tiếp tục vượt trội hơn MetaMath và MAmmoTH
đáng kể. So với ToRA, với giải mã greedy, chúng tôi thấy sự giảm hiệu suất có ý nghĩa trên
MATH, mặc dù các mô hình của chúng tôi bằng hoặc tốt hơn trên GSM8K. Với giải mã tự nhất quán (SC),
tuy nhiên, các mô hình của chúng tôi vượt trội hơn ToRA trên cả MATH và GSM8K. Những mức tăng đáng kể với SC
có thể được quy cho sự đa dạng của dữ liệu tinh chỉnh của chúng tôi.

4.1 Ablations

Chúng tôi thực hiện các thí nghiệm ablation với Mistral-7B làm mô hình cơ sở. Chúng tôi báo cáo kết quả trên
các tập con validation kích thước 1K cho MATH và GSM8K do chúng tôi tạo ra.

Bảng 4: So sánh hiệu suất của Lấy mẫu Công bằng
vs Ngây thơ trên tập con validation của chúng tôi
cho GSM8K và MATH.

Lấy mẫu | GSM8K | MATH
Ngây thơ | 74.3 | 35.0
Công bằng | 75.3 | 37.0

Bảng 5: So sánh Prompting Mặc định vs Được Che giấu trên tập con validation của chúng tôi
cho GSM8K và MATH.

Prompt | GSM8K | MATH
Mặc định | 73.8 | 36.9
Được Che giấu | 77.7 | 37.4

4.1.1 Lấy mẫu Công bằng vs Ngây thơ

Chúng tôi tinh chỉnh mô hình cơ sở trên bộ dữ liệu 128K thể hiện được tạo bằng cách kết hợp 64K thể hiện được giảm mẫu
ngây thơ hoặc công bằng từ phần GSM8K và MATH của dữ liệu. Bảng 4 cho thấy rằng
mô hình được tinh chỉnh trên dữ liệu được giảm mẫu với lấy mẫu công bằng vượt trội hơn mô hình được tạo ra bằng
giảm mẫu ngây thơ. Khoảng cách hiệu suất đặc biệt đáng kể đối với MATH, vốn gặp phải
sự mất cân bằng dữ liệu nghiêm trọng hơn GSM8K trong corpus của chúng tôi.

4.1.2 Prompting Mặc định vs Được Che giấu

Chúng tôi tinh chỉnh mô hình cơ sở trên bộ dữ liệu 128K thể hiện được tạo bằng cách kết hợp 64K thể hiện được lấy mẫu công bằng
từ phần GSM8K và MATH của dữ liệu được tạo ra bằng prompting mặc định và được che giấu.
Bảng 5 cho thấy rằng mô hình được tinh chỉnh trên dữ liệu được tạo ra bằng prompting được che giấu vượt trội hơn
mô hình được tạo ra bằng prompting mặc định trên cả GSM8K và MATH. Như vậy, những mức tăng trong
phạm vi bao phủ tập huấn luyện với prompting được che giấu (Phần 2.2.3) cũng chuyển thành hiệu suất tinh chỉnh.

4.1.3 Tác động của Kích thước Bộ dữ liệu Tinh chỉnh

Để xác định tác động của kích thước bộ dữ liệu tinh chỉnh, chúng tôi tạo các bộ dữ liệu có kích thước
128K/256K/512K bằng cách kết hợp 64K/128K/256K tập con được giảm mẫu công bằng có kích thước bằng nhau của GSM8K
và MATH. Bảng 6 cho thấy rằng hiệu suất tăng cho cả GSM8K và MATH với
sự gia tăng kích thước bộ dữ liệu tinh chỉnh. Chúng tôi không tìm thấy lợi ích nào từ việc huấn luyện các mô hình để có thêm
bước, vì vậy mức tăng hiệu suất có thể quy cho kích thước dữ liệu tăng lên.

¹⁰Số lượng thể hiện MATH thực tế là 511,677.
¹¹Script chấm điểm của chúng tôi chấm điểm các đầu ra ToRA được phát hành công khai thấp hơn khoảng 2-3% so với các số được báo cáo.
Chúng tôi tin rằng ToRA sử dụng một số heuristics để trích xuất câu trả lời khi mô hình không tạo ra câu trả lời trong
định dạng chính xác.

--- TRANG 9 ---
Bảng 6: Tác động của kích thước bộ dữ liệu tinh chỉnh đối với hiệu suất trên tập con validation của chúng tôi cho GSM8K và
MATH.

Kích thước Bộ dữ liệu | GSM8K | MATH
128K | 75.3 | 37.0
256K | 79.0 | 38.6
512K | 81.0 | 41.6

Bảng 7: So sánh hiệu suất prompt mặc định vs theo môn học trên tập con validation MATH của chúng tôi.

Prompt | Pass@1 | SC (k=4)
Mặc định | 39.1 | 41.7
Theo môn học | 38.3 | 44.5

Bảng 8: Tác động của lựa chọn dữ liệu ưu tiên code đối với hiệu suất tập con validation MATH của chúng tôi.

Prompt | Pass@1 | SC (k=4)
Mặc định | 37.4 | 45.2
Majority-Code | 39.8 | 42.6
Any-Code | 39.4 | 42.6

4.1.4 Ablations chỉ cho MATH

Phần này trình bày kết quả ablation chỉ cho phần MATH của OpenMathInstruct-1. Chúng tôi
tinh chỉnh mô hình cơ sở trên tập con 128K được giảm mẫu công bằng để kiểm soát kích thước dữ liệu.

Prompting Mặc định vs Chuyên biệt theo Môn học. Trong phần 2.2.2, chúng tôi đã thúc đẩy việc sử dụng các prompt chuyên biệt theo môn học, cuối cùng không dẫn đến nhiều sự khác biệt về phạm vi bao phủ tập huấn luyện. Nhưng các giải pháp được tạo ra bởi sự kết hợp của các prompt theo môn học khác như thế nào so với một prompt mặc định đơn?
Để trả lời điều này, chúng tôi tạo một tập con 128K thể hiện được tạo ra với prompt mặc định/prompt chuyên biệt theo môn học. Bảng 7 so sánh hiệu suất tinh chỉnh trên hai phần này trên tập con validation MATH của chúng tôi. Trong khi mô hình được huấn luyện trên tập con chuyên biệt theo môn học kém hiệu suất hơn mô hình được huấn luyện trên
tập con mặc định với giải mã greedy, xu hướng được đảo ngược một cách quyết định cho giải mã tự nhất quán
với bốn mẫu. Điều này cho thấy rằng tập con được thu thập với các prompt chuyên biệt theo môn học có sự đa dạng
giải pháp cao hơn so với những cái được thu thập bằng một prompt đơn.

Tập con Ưu tiên Code. Trong ablation này, chúng tôi xác định tác động của các chiến lược lựa chọn giải pháp
ưu tiên code được đề xuất trong Phần 2.4.2. Bảng 8 cho thấy rằng các chiến lược giải pháp ưu tiên code
hỗ trợ hiệu suất giải mã greedy. Tuy nhiên, việc giảm đa dạng giải pháp có thể dẫn đến
sự giảm hiệu suất với giải mã tự nhất quán (các giải pháp dựa trên văn bản chiếm khoảng một phần ba
corpus gốc). Dựa trên các kết quả này và bởi vì Any-Code dẫn đến bộ dữ liệu tinh chỉnh nhỏ hơn
(512K so với 664K với Majority-Code), chúng tôi đã chọn sử dụng tập con Any-Code.

5 Phân tích

Chúng tôi phân tích hiệu suất của mô hình ablation được huấn luyện trên 512K thể hiện từ Phần 4.1.3. Chúng tôi
giới hạn thảo luận đến benchmark MATH, nơi mô hình ghi điểm 41.6% trên tập con validation của chúng tôi.

Hiệu suất-phân chia theo Môn học và Mức độ. Hình 4 trình bày phân chia hiệu suất theo môn học và
mức độ trên tập con validation MATH. Trong số các môn học, chúng tôi thấy rằng hiệu suất tồi tệ nhất của mô hình là
trên hình học, có thể được quy cho thiếu đa phương thức trong các mô hình cơ sở của chúng tôi [23]. Chúng tôi thấy
sự giảm đơn điệu về hiệu suất với sự gia tăng mức độ khó như mong đợi [23].
Mô hình ghi điểm 72.4% trên các bài toán Mức 1 và chỉ 16.3% trên các bài toán khó nhất, tức là Mức 5.

Phân tích Lỗi. Bảng 9 cho thấy rằng mô hình thực hiện tốt hơn 13.3% tuyệt đối khi sử dụng code
để trả lời câu hỏi so với khi không sử dụng nó. Chúng tôi thấy rằng một số lỗi được tạo ra bởi
giải pháp dựa trên văn bản có thể đã được tránh bằng cách ưu tiên giải pháp dựa trên code; xem Hình 16 để biết
mẫu giải pháp mà mô hình mắc lỗi tính toán số học. Phân tích này cung cấp
sự hỗ trợ khác cho đề xuất và việc sử dụng các giải pháp ưu tiên code của chúng tôi từ Phần 2.4.2.

Bảng 10 trình bày số lượng các loại lỗi khác nhau. Đối với các giải pháp dựa trên code, chúng tôi thấy rằng gần
74% lỗi trong các giải pháp như vậy là do lỗi lý luận, và 26% còn lại có thể quy cho
các vấn đề liên quan đến thực thi. Chúng tôi trình bày các mẫu giải pháp từ các loại lỗi này trong Phụ lục B.3.

--- TRANG 10 ---
(a) Hiệu suất theo môn học (b) Hiệu suất theo mức độ

Hình 4: Phân chia hiệu suất theo môn học và mức độ trên tập con validation MATH của chúng tôi.

Bảng 9: Phân chia hiệu suất dựa trên định dạng giải pháp. Các giải pháp không có chuỗi ⟨llm-code-output⟩
được coi là dựa trên văn bản.

Loại Giải pháp | Độ chính xác (%) | Số lượng
Dựa trên văn bản | 32.0 | 278
Code + Văn bản | 45.3 | 722
Tổng | 41.6 | 1000

Bảng 10: Các loại lỗi và số lượng của chúng.

Loại Lỗi | Số lượng
Lỗi Lý luận Văn bản | 189
Lỗi Lý luận Code | 292
Lỗi Thực thi Code | 78
Timeout Code | 15
Đạt số lần thực thi code tối đa | 10
Tổng | 584

6 Nghiên cứu Liên quan

Lý luận Toán học và LLMs. Gần đây, rất nhiều công trình đã được thực hiện để tăng cường
khả năng lý luận toán học của LLMs. Các kỹ thuật suy luận như Chain-of-
Thought [33], đối tác lập trình của nó, Program of Thought [24,34], Self-Consistency [32], và
Self-Verification [23] đã được chứng minh là cải thiện đáng kể khả năng lý luận của LLMs.
Việc pretrain các mô hình ngôn ngữ trên nội dung giàu toán học đã dẫn đến các LLMs nền tảng như Min-
erva [35], Galactica [36], Llemma [37], và DeepSeekMath [38] với kỹ năng toán học mạnh mẽ hơn
ngay từ đầu. Một phương pháp trực tiếp hơn của huấn luyện chuyên biệt cho bộ dữ liệu là instruction fine-tuning trên
các cặp bài toán-giải pháp được lấy từ các bộ dữ liệu lý luận toán học. Công trình của chúng tôi thuộc loại sau này
và có sự tương đồng với các nghiên cứu gần đây như RFT [39], ToRA [8], MAmmoTH [2], MetaMath [1]
và MathCoder [7]. Chúng tôi khác biệt với công trình trước đó theo một yếu tố hoặc sự kết hợp của
các yếu tố sau: (a) sự phụ thuộc vào GPT-3.5/4, (b) định dạng giải pháp, và (c) sử dụng giải pháp văn bản chính xác trong việc tổng hợp các giải pháp dựa trên code.

Chưng cất Kiến thức thông qua Dữ liệu Tổng hợp. Nghiên cứu gần đây khám phá việc sử dụng dữ liệu tổng hợp được nhắm mục tiêu được tạo ra bởi các mô hình nền tảng lớn cho pre-training/instruction tuning các LLMs nhỏ hơn đã dẫn đến
tiến bộ to lớn trong kỹ năng của các LLMs nhỏ hơn này [5, 6, 4, 40, 41, 42].

7 Kết luận

Chúng tôi giới thiệu OpenMathInstruct-1, một bộ dữ liệu instruction tuning toán học với 1.8M cặp bài toán-giải pháp được phát hành với giấy phép cho phép thương mại. So với công trình trước đó, bộ dữ liệu
OpenMathInstruct-1 lớn hơn ít nhất bốn lần. Với sự mới lạ trong prompting mà chúng tôi đề xuất
về việc sử dụng các giải pháp văn bản được che giấu và một số scaling brute-force, chúng tôi đạt được phạm vi bao phủ tập huấn luyện
99.9% cho benchmark GSM8K và 93% cho benchmark MATH thách thức. Chất lượng của
các giải pháp được tổng hợp này được minh họa bằng các thí nghiệm tinh chỉnh, cho thấy các mô hình đạt được
hiệu suất có thể so sánh hoặc tốt hơn so với các đối tác gpt-distilled của chúng. Để hỗ trợ các
nỗ lực nguồn mở theo hướng này, chúng tôi công khai phát hành tất cả các mô hình được tinh chỉnh, code, và OpenMathInstruct-
1 cùng với thêm 6.6M giải pháp được lấy mẫu không chính xác.

--- TRANG 11 ---
Hạn chế và Rủi ro Tiềm ẩn

Công trình của chúng tôi nhằm cải thiện lý luận toán học của các mô hình nguồn mở bằng cách sử dụng các
mô hình nguồn mở. Trong việc theo đuổi mục tiêu này, chúng tôi tạo ra một bộ dữ liệu tổng hợp, OpenMathInstruct-1, mà các thí nghiệm của chúng tôi cho thấy hỗ trợ hiệu suất trên các benchmark toán học hiện có. Dưới đây, chúng tôi liệt kê các hạn chế chính của
công trình chúng tôi:

• Phân tích thủ công của chúng tôi tiết lộ các giải pháp có được câu trả lời đúng nhưng thông qua lý luận có lỗ hổng
(Hình 13 trong Phụ lục). Việc loại bỏ các giải pháp nhiễu về mặt ngữ nghĩa này nằm ngoài phạm vi của
công trình hiện tại. Điều này có nghĩa là thiếu đảm bảo về chất lượng của các giải pháp được tạo ra một cách tổng hợp
của chúng tôi.

• Cải thiện hiệu suất trên các benchmark toán học trong miền có thể không chuyển thành mức tăng hiệu suất
trên các tác vụ liên quan khác. Sự giảm hiệu suất trên GSM-Hard so với GSM
cho thấy rằng các mô hình của chúng tôi có thể không mạnh mẽ đối với các nhiễu loạn đầu vào, mặc dù chúng ngang bằng
với công trình trước đó.

Trong khi chúng tôi không thấy trước bất kỳ rủi ro trọng yếu nào do công trình của chúng tôi, việc sử dụng bộ dữ liệu và mô hình không hoàn hảo của chúng tôi để
thực hiện các tác vụ, như đánh giá bài tập của học sinh hoặc xây dựng một gia sư toán học, mang theo rủi ro.

Tài liệu tham khảo

[1] Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok,
Zhenguo Li, Adrian Weller, và Weiyang Liu. MetaMath: Bootstrap Your Own Mathematical
Questions for Large Language Models. Trong ICLR, 2024.

[2] Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, và Wenhu
Chen. MAmmoTH: Building math generalist models through hybrid instruction tuning. Trong
ICLR, 2024. URL https://openreview.net/forum?id=yLClGs770I.

[3] OpenAI, :, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-
cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red
Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mo Bavar-
ian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner,
Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim
Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany
Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek
Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey
Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux,
Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling,
Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko
Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Chris-
tian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gor-
don, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei
Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke,
Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu,
Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang,
Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan,
Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan
Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Hendrik Kirchner, Jamie Kiros,
Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis,
Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike,
Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz
Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Man-
ning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob
McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David
Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie
Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély,
Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo
Noh, Long Ouyang, Cullen O'Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pan-
tuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov,

--- TRANG 12 ---
Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde
de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr Pong, Tolly Powell, Alethea
Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh,
Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez,
Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt,
David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh,
Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Kata-
rina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski
Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine Thompson, Phil
Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan
Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright,
Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila
Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens
Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu,
Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers,
Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk,
và Barret Zoph. GPT-4 Technical Report, 2023.

[4] Ronen Eldan và Yuanzhi Li. TinyStories: How Small Can Language Models Be and Still
Speak Coherent English? arXiv, 2023.

[5] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno,
Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil
Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tau-
man Kalai, Yin Tat Lee, và Yuanzhi Li. Textbooks Are All You Need. arXiv, 2023.

[6] Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, và Yin Tat
Lee. Textbooks Are All You Need II: phi-1.5 technical report. arXiv, 2023.

[7] Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun Luo, Weikang Shi, Renrui Zhang, Linqi
Song, Mingjie Zhan, và Hongsheng Li. MathCoder: Seamless Code Integration in LLMs for
Enhanced Mathematical Reasoning. Trong ICLR, 2024.

[8] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan Duan,
và Weizhu Chen. ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem
Solving. Trong ICLR, 2024. URL https://openreview.net/forum?id=Ep0TtjVoap.

[9] Minpeng Liao, Wei Luo, Chengxi Li, Jing Wu, và Kai Fan. MARIO: MAth Reasoning with
code Interpreter Output – A Reproducible Pipeline, 2024.

[10] Lingjiao Chen, Matei Zaharia, và James Zou. How is ChatGPT's behavior changing over
time?, 2023.

[11] Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris
Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand,
Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier,
Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak,
Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, và
William El Sayed. Mixtral of Experts, 2024.

[12] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, và John
Schulman. Training Verifiers to Solve Math Word Problems, 2021.

[13] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn
Song, và Jacob Steinhardt. Measuring Mathematical Problem Solving With the MATH Dataset.
NeurIPS, 2021.

[14] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh
Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile
Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut
Lavril, Thomas Wang, Timothée Lacroix, và William El Sayed. Mistral 7B. arXiv, 2023.

--- TRANG 13 ---
[15] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei,
Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas
Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes,
Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony
Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian
Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut
Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov,
Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta,
Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiao-
qing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien
Rodriguez, Robert Stojnic, Sergey Edunov, và Thomas Scialom. Llama 2: Open Foundation
and Fine-Tuned Chat Models, 2023.

[16] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan,
Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna
Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre
Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas
Scialom, và Gabriel Synnaeve. Code Llama: Open Foundation Models for Code. arXiv, 2023.

[17] Fei Yu, Anningzhe Gao, và Benyou Wang. Outcome-supervised Verifiers for Planning in
Mathematical Reasoning. arXiv, 2023.

[18] Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan
Leike, John Schulman, Ilya Sutskever, và Karl Cobbe. Let's Verify Step by Step. arXiv, 2023.

[19] Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral,
Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, và Ashwin Kalyan. Lila:
A Unified Benchmark for Mathematical Reasoning. Trong EMNLP, 2022.

[20] Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng,
Qingwei Lin, Shifeng Chen, và Dongmei Zhang. WizardMath: Empowering Mathemat-
ical Reasoning for Large Language Models via Reinforced Evol-Instruct. arXiv preprint
arXiv:2308.09583, 2023.

[21] Eric Zelikman, Yuhuai Wu, Jesse Mu, và Noah Goodman. STaR: Bootstrapping Reasoning
With Reasoning. Trong Alice H. Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun Cho,
editors, NeurIPS, 2022.

[22] Jiaxin Huang, Shixiang Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, và Jiawei Han.
Large Language Models Can Self-Improve. Trong Houda Bouamor, Juan Pino, và Kalika Bali,
editors, EMNLP, 2023.

[23] Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya
Jia, Linqi Song, Mingjie Zhan, và Hongsheng Li. Solving Challenging Math Word Problems
Using GPT-4 Code Interpreter with Code-based Self-Verification. Trong ICLR, 2024.

[24] Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan,
và Graham Neubig. PAL: Program-aided Language Models. Trong ICML, pages 10764–10799.
PMLR, 2023.

[25] Ilya Loshchilov và Frank Hutter. Decoupled Weight Decay Regularization. arXiv, 2019.

[26] Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, và Ruslan R Salakhut-
dinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv
preprint arXiv:1207.0580, 2012.

[27] O. Kuchaiev, J. Li, H. Nguyen, O. Hrinchuk, R. Leary, B. Ginsburg, S. Kriman, S. Beliaev,
V. Lavrukhin, J. Cook, et al. NeMo: a toolkit for building AI applications using neural modules.
Trong Systems for ML Workshop, NeurIPS, 2019.

[28] Arkil Patel, Satwik Bhattamishra, và Navin Goyal. Are NLP Models really able to Solve
Simple Math Word Problems? Trong NAACL-HLT, June 2021.

--- TRANG 14 ---
[29] Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter
Clark, và Ashwin Kalyan. Dynamic Prompt Learning via Policy Gradient for Semi-structured
Mathematical Reasoning. Trong ICLR, 2023.

[30] Shen-yun Miao, Chao-Chun Liang, và Keh-Yih Su. A Diverse Corpus for Evaluating and
Developing English Math Word Problem Solvers. Trong Dan Jurafsky, Joyce Chai, Natalie Schluter,
và Joel Tetreault, editors, ACL, 2020.

[31] Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, và Hannaneh Hajishirzi.
MAWPS: A Math Word Problem Repository. Trong Kevin Knight, Ani Nenkova, và Owen
Rambow, editors, NAACL-HLT, 2016.

[32] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha
Chowdhery, và Denny Zhou. Self-consistency improves chain of thought reasoning in language
models. Trong ICLR, 2023.

[33] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le,
Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models.
NeurIPS, 2022.

[34] Wenhu Chen, Xueguang Ma, Xinyi Wang, và William W. Cohen. Program of Thoughts
Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks. TMLR,
2023.

[35] Aitor Lewkowycz, Anders Johan Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski,
Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo,
Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, và Vedant Misra. Solving Quantitative Reason-
ing Problems with Language Models. Trong NeurIPS, 2022.

[36] Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis
Saravia, Andrew Poulton, Viktor Kerkez, và Robert Stojnic. Galactica: A Large Language
Model for Science, 2022.

[37] Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer,
Albert Q. Jiang, Jia Deng, Stella Biderman, và Sean Welleck. Llemma: An Open Language
Model For Mathematics, 2023.

[38] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang,
Mingchuan Zhang, Y. K. Li, Y. Wu, và Daya Guo. DeepSeekMath: Pushing the Limits of
Mathematical Reasoning in Open Language Models, 2024.

[39] Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Keming Lu, Chuanqi Tan, Chang
Zhou, và Jingren Zhou. Scaling Relationship on Learning Mathematical Reasoning with Large
Language Models, 2023.

[40] Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, và
Ahmed Awadallah. Orca: Progressive Learning from Complex Explanation Traces of GPT-4,
2023.

[41] Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, và
Daxin Jiang. WizardLM: Empowering Large Language Models to Follow Complex Instructions.
arXiv, 2023.

[42] Bingbin Liu, Sebastien Bubeck, Ronen Eldan, Janardhan Kulkarni, Yuanzhi Li, Anh Nguyen,
Rachel Ward, và Yi Zhang. TinyGSM: achieving> 80% on GSM8k with small language
models. arXiv preprint arXiv:2312.09241, 2023.

--- TRANG 15 ---
Danh sách Kiểm tra Bài báo NeurIPS

1. Tuyên bố
Câu hỏi: Các tuyên bố chính được đưa ra trong phần tóm tắt và giới thiệu có phản ánh chính xác
các đóng góp và phạm vi của bài báo không?
Trả lời: [Có]
Biện minh: Các tuyên bố của chúng tôi phù hợp với kết quả thí nghiệm của chúng tôi.
Hướng dẫn:
• Câu trả lời NA có nghĩa là phần tóm tắt và giới thiệu không bao gồm các tuyên bố được đưa ra
trong bài báo.
• Phần tóm tắt và/hoặc giới thiệu nên nêu rõ các tuyên bố được đưa ra, bao gồm các
đóng góp được thực hiện trong bài báo và các giả định và hạn chế quan trọng. Câu trả lời Không hoặc
NA cho câu hỏi này sẽ không được các nhà đánh giá đánh giá tốt.
• Các tuyên bố được đưa ra nên phù hợp với kết quả lý thuyết và thí nghiệm, và phản ánh mức độ
kết quả có thể được mong đợi khái quát hóa cho các thiết lập khác.
• Có thể bao gồm các mục tiêu khát vọng như động lực miễn là rõ ràng rằng các mục tiêu này
không được đạt được bởi bài báo.

2. Hạn chế
Câu hỏi: Bài báo có thảo luận về các hạn chế của công trình được thực hiện bởi các tác giả không?
Trả lời: [Có]
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không có hạn chế trong khi câu trả lời Không có nghĩa là
bài báo có hạn chế, nhưng chúng không được thảo luận trong bài báo.
• Các tác giả được khuyến khích tạo một phần "Hạn chế" riêng biệt trong bài báo của họ.
• Bài báo nên chỉ ra bất kỳ giả định mạnh mẽ nào và mức độ mạnh mẽ của kết quả đối với
việc vi phạm các giả định này (ví dụ, giả định độc lập, thiết lập không nhiễu,
đặc tả mô hình tốt, các xấp xỉ tiệm cận chỉ giữ cục bộ). Các tác giả nên suy ngẫm về cách
các giả định này có thể bị vi phạm trong thực tế và các hàm ý sẽ là gì.
• Các tác giả nên suy ngẫm về phạm vi của các tuyên bố được đưa ra, ví dụ, nếu phương pháp chỉ
được thử nghiệm trên một vài bộ dữ liệu hoặc với một vài lần chạy. Nói chung, kết quả thực nghiệm thường
phụ thuộc vào các giả định ngầm, cần được diễn đạt.
• Các tác giả nên suy ngẫm về các yếu tố ảnh hưởng đến hiệu suất của phương pháp.
Ví dụ, một thuật toán nhận dạng khuôn mặt có thể hoạt động kém khi độ phân giải hình ảnh
thấp hoặc hình ảnh được chụp trong ánh sáng yếu. Hoặc một hệ thống chuyển đổi giọng nói thành văn bản có thể không
được sử dụng một cách đáng tin cậy để cung cấp phụ đề đóng cho các bài giảng trực tuyến vì nó không xử lý được
thuật ngữ chuyên môn.
• Các tác giả nên thảo luận về hiệu quả tính toán của các thuật toán được đề xuất
và cách chúng mở rộng theo kích thước bộ dữ liệu.
• Nếu có thể áp dụng, các tác giả nên thảo luận về các hạn chế có thể có của phương pháp họ để giải quyết
các vấn đề về quyền riêng tư và công bằng.
• Trong khi các tác giả có thể lo sợ rằng việc trung thực hoàn toàn về hạn chế có thể được các nhà đánh giá sử dụng
như căn cứ để từ chối, một kết quả tồi tệ hơn có thể là các nhà đánh giá phát hiện ra
các hạn chế không được thừa nhận trong bài báo. Các tác giả nên sử dụng phán đoán tốt nhất của họ
và nhận ra rằng các hành động cá nhân ủng hộ tính minh bạch đóng vai trò quan trọng
trong việc phát triển các quy chuẩn bảo tồn tính toàn vẹn của cộng đồng. Các nhà đánh giá
sẽ được hướng dẫn cụ thể để không phạt sự trung thực về hạn chế.

3. Giả định và Chứng minh Lý thuyết
Câu hỏi: Đối với mỗi kết quả lý thuyết, bài báo có cung cấp tập đầy đủ các giả định và
một chứng minh hoàn chỉnh (và chính xác) không?
Trả lời: [NA]
Biện minh: Bài báo thực nghiệm

--- TRANG 16 ---
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không bao gồm kết quả lý thuyết.
• Tất cả các định lý, công thức và chứng minh trong bài báo nên được đánh số và tham chiếu chéo.
• Tất cả giả định nên được nêu rõ ràng hoặc tham chiếu trong phát biểu của bất kỳ định lý nào.
• Các chứng minh có thể xuất hiện trong bài báo chính hoặc tài liệu bổ sung, nhưng nếu
chúng xuất hiện trong tài liệu bổ sung, các tác giả được khuyến khích cung cấp một phác thảo chứng minh ngắn
để cung cấp trực giác.
• Ngược lại, bất kỳ chứng minh không chính thức nào được cung cấp trong phần chính của bài báo nên được bổ sung
bằng các chứng minh chính thức được cung cấp trong phụ lục hoặc tài liệu bổ sung.
• Các Định lý và Bổ đề mà chứng minh dựa vào nên được tham chiếu đúng cách.

4. Khả năng Tái tạo Kết quả Thí nghiệm
Câu hỏi: Bài báo có tiết lộ đầy đủ tất cả thông tin cần thiết để tái tạo các kết quả thí nghiệm chính
của bài báo trong phạm vi ảnh hưởng đến các tuyên bố và/hoặc kết luận chính
của bài báo (bất kể code và dữ liệu có được cung cấp hay không)?
Trả lời: [Có]
Biện minh: Chúng tôi cung cấp tất cả các chi tiết trong khả năng tốt nhất của chúng tôi. Một số chi tiết đã
được chia sẻ trong tài liệu bổ sung.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không bao gồm thí nghiệm.
• Nếu bài báo bao gồm thí nghiệm, câu trả lời Không cho câu hỏi này sẽ không được
các nhà đánh giá đánh giá tốt: Làm cho bài báo có thể tái tạo là quan trọng, bất kể
code và dữ liệu có được cung cấp hay không.
• Nếu đóng góp là một bộ dữ liệu và/hoặc mô hình, các tác giả nên mô tả các bước được thực hiện
để làm cho kết quả của họ có thể tái tạo hoặc có thể xác minh.
• Tùy thuộc vào đóng góp, khả năng tái tạo có thể được thực hiện theo nhiều cách khác nhau.
Ví dụ, nếu đóng góp là một kiến trúc mới, việc mô tả kiến trúc đầy đủ
có thể đủ, hoặc nếu đóng góp là một mô hình cụ thể và đánh giá thực nghiệm, có thể
cần thiết để làm cho việc người khác có thể sao chép mô hình với cùng
bộ dữ liệu, hoặc cung cấp quyền truy cập vào mô hình. Nói chung, việc phát hành code và dữ liệu thường
là một cách tốt để thực hiện điều này, nhưng khả năng tái tạo cũng có thể được cung cấp thông qua hướng dẫn chi tiết
về cách sao chép kết quả, quyền truy cập vào mô hình được lưu trữ (ví dụ, trong trường hợp
của một mô hình ngôn ngữ lớn), phát hành checkpoint mô hình, hoặc các phương tiện khác phù hợp
với nghiên cứu được thực hiện.
• Trong khi NeurIPS không yêu cầu phát hành code, hội nghị yêu cầu tất cả
bài nộp cung cấp một số con đường hợp lý cho khả năng tái tạo, có thể phụ thuộc vào
bản chất của đóng góp. Ví dụ
(a) Nếu đóng góp chủ yếu là một thuật toán mới, bài báo nên làm rõ cách
tái tạo thuật toán đó.
(b) Nếu đóng góp chủ yếu là một kiến trúc mô hình mới, bài báo nên mô tả
kiến trúc một cách rõ ràng và đầy đủ.
(c) Nếu đóng góp là một mô hình mới (ví dụ, một mô hình ngôn ngữ lớn), thì nên
có cách để truy cập mô hình này để tái tạo kết quả hoặc cách để tái tạo
mô hình (ví dụ, với bộ dữ liệu nguồn mở hoặc hướng dẫn về cách xây dựng
bộ dữ liệu).
(d) Chúng tôi nhận ra rằng khả năng tái tạo có thể khó khăn trong một số trường hợp, trong trường hợp đó các tác giả
được hoan nghênh mô tả cách cụ thể họ cung cấp cho khả năng tái tạo. Trong
trường hợp các mô hình nguồn đóng, có thể quyền truy cập vào mô hình bị hạn chế theo
cách nào đó (ví dụ, cho người dùng đã đăng ký), nhưng nên có thể cho các nhà nghiên cứu khác
có một số con đường để tái tạo hoặc xác minh kết quả.

5. Quyền truy cập mở vào dữ liệu và code
Câu hỏi: Bài báo có cung cấp quyền truy cập mở vào dữ liệu và code, với hướng dẫn đầy đủ
để tái tạo một cách trung thực các kết quả thí nghiệm chính, như được mô tả trong tài liệu bổ sung
không?

--- TRANG 17 ---
Trả lời: [Không]
Biện minh: Chúng tôi hiện không chia sẻ dữ liệu và code. Nhưng chúng tôi sẽ phát hành
mọi thứ với quyền truy cập mở sau chu kỳ đánh giá.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không bao gồm thí nghiệm yêu cầu code.
• Vui lòng xem hướng dẫn nộp code và dữ liệu NeurIPS (https://nips.cc/
public/guides/CodeSubmissionPolicy) để biết thêm chi tiết.
• Trong khi chúng tôi khuyến khích việc phát hành code và dữ liệu, chúng tôi hiểu rằng điều này có thể
không khả thi, vì vậy "Không" là một câu trả lời có thể chấp nhận. Các bài báo không thể bị từ chối đơn giản vì không
bao gồm code, trừ khi điều này là trung tâm của đóng góp (ví dụ, cho một benchmark nguồn mở mới).
• Các hướng dẫn nên chứa lệnh chính xác và môi trường cần thiết để chạy để
tái tạo kết quả. Xem hướng dẫn nộp code và dữ liệu NeurIPS (https:
//nips.cc/public/guides/CodeSubmissionPolicy) để biết thêm chi tiết.
• Các tác giả nên cung cấp hướng dẫn về truy cập và chuẩn bị dữ liệu, bao gồm cách
truy cập dữ liệu thô, dữ liệu đã xử lý sẵn, dữ liệu trung gian và dữ liệu được tạo ra, v.v.
• Các tác giả nên cung cấp script để tái tạo tất cả kết quả thí nghiệm cho phương pháp mới
được đề xuất và baseline. Nếu chỉ một tập con thí nghiệm có thể tái tạo, họ
nên nêu những cái nào bị bỏ qua khỏi script và tại sao.
• Tại thời điểm nộp, để bảo tồn tính ẩn danh, các tác giả nên phát hành các phiên bản ẩn danh
(nếu có thể áp dụng).
• Cung cấp càng nhiều thông tin càng tốt trong tài liệu bổ sung (được đính kèm vào
bài báo) được khuyến nghị, nhưng bao gồm URL đến dữ liệu và code được cho phép.

6. Thiết lập/Chi tiết Thí nghiệm
Câu hỏi: Bài báo có chỉ định tất cả các chi tiết huấn luyện và kiểm tra (ví dụ, phân chia dữ liệu, siêu
tham số, cách chúng được chọn, loại optimizer, v.v.) cần thiết để hiểu
kết quả không?
Trả lời: [Có]
Biện minh: Tất cả các chi tiết đã được chia sẻ trong bài báo.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không bao gồm thí nghiệm.
• Thiết lập thí nghiệm nên được trình bày trong phần chính của bài báo ở mức độ chi tiết
cần thiết để đánh giá kết quả và hiểu chúng.
• Các chi tiết đầy đủ có thể được cung cấp cùng với code, trong phụ lục, hoặc như tài liệu bổ sung.

7. Ý nghĩa Thống kê Thí nghiệm
Câu hỏi: Bài báo có báo cáo thanh lỗi được định nghĩa phù hợp và chính xác hoặc thông tin phù hợp khác
về ý nghĩa thống kê của các thí nghiệm không?
Trả lời: [Không]
Biện minh: Tất cả các lần chạy tinh chỉnh của chúng tôi đều khá tốn kém, điều này hạn chế khả năng của chúng tôi để thực hiện
nhiều lần chạy để nắm bắt sự biến thiên này.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không bao gồm thí nghiệm.
• Các tác giả nên trả lời "Có" nếu kết quả được đi kèm với thanh lỗi, khoảng tin cậy,
hoặc các kiểm tra ý nghĩa thống kê, ít nhất cho các thí nghiệm hỗ trợ
các tuyên bố chính của bài báo.
• Các yếu tố biến thiên mà thanh lỗi đang nắm bắt nên được nêu rõ (ví
dụ, phân chia train/test, khởi tạo, vẽ ngẫu nhiên của một số tham số, hoặc
chạy tổng thể với các điều kiện thí nghiệm đã cho).
• Phương pháp tính toán thanh lỗi nên được giải thích (công thức dạng đóng,
gọi hàm thư viện, bootstrap, v.v.)
• Các giả định được đưa ra nên được đưa ra (ví dụ, lỗi phân phối chuẩn).

--- TRANG 18 ---
• Nên rõ ràng liệu thanh lỗi là độ lệch chuẩn hay sai số chuẩn
của trung bình.
• Có thể báo cáo thanh lỗi 1-sigma, nhưng nên nêu rõ. Các tác giả nên
ưu tiên báo cáo thanh lỗi 2-sigma hơn là nêu rằng họ có 96% CI, nếu giả thuyết
về tính chuẩn của lỗi không được xác minh.
• Đối với phân phối không đối xứng, các tác giả nên cẩn thận không hiển thị trong bảng hoặc
hình thanh lỗi đối xứng sẽ mang lại kết quả nằm ngoài phạm vi (ví dụ, tỷ lệ lỗi âm).
• Nếu thanh lỗi được báo cáo trong bảng hoặc biểu đồ, Các tác giả nên giải thích trong văn bản cách
chúng được tính toán và tham chiếu các hình hoặc bảng tương ứng trong văn bản.

8. Tài nguyên Tính toán Thí nghiệm
Câu hỏi: Đối với mỗi thí nghiệm, bài báo có cung cấp thông tin đầy đủ về
tài nguyên máy tính (loại worker tính toán, bộ nhớ, thời gian thực thi) cần thiết để tái tạo
các thí nghiệm không?
Trả lời: [Có]
Biện minh: Chi tiết trong Phụ lục.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không bao gồm thí nghiệm.
• Bài báo nên chỉ ra loại worker tính toán CPU hoặc GPU, cluster nội bộ,
hoặc nhà cung cấp đám mây, bao gồm bộ nhớ và lưu trữ liên quan.
• Bài báo nên cung cấp lượng tính toán cần thiết cho mỗi lần chạy thí nghiệm
cá nhân cũng như ước tính tổng tính toán.
• Bài báo nên tiết lộ liệu toàn bộ dự án nghiên cứu có yêu cầu nhiều tính toán hơn
các thí nghiệm được báo cáo trong bài báo (ví dụ, các thí nghiệm sơ bộ hoặc thất bại mà
không thành công vào bài báo).

9. Quy tắc Đạo đức
Câu hỏi: Nghiên cứu được thực hiện trong bài báo có tuân thủ, trong mọi khía cạnh, với
Quy tắc Đạo đức NeurIPS https://neurips.cc/public/EthicsGuidelines không?
Trả lời: [Có]
Hướng dẫn:
• Câu trả lời NA có nghĩa là các tác giả chưa xem xét Quy tắc Đạo đức NeurIPS.
• Nếu các tác giả trả lời Không, họ nên giải thích các hoàn cảnh đặc biệt yêu cầu
sự lệch khỏi Quy tắc Đạo đức.
• Các tác giả nên đảm bảo bảo tồn tính ẩn danh (ví dụ, nếu có một cân nhắc đặc biệt
do luật pháp hoặc quy định trong phạm vi quyền hạn của họ).

10. Tác động Rộng lớn hơn
Câu hỏi: Bài báo có thảo luận về cả tác động xã hội tích cực tiềm ẩn và tác động xã hội tiêu cực
tiềm ẩn của công trình được thực hiện không?
Trả lời: [Có]
Biện minh: Chúng tôi đề cập ngắn gọn trong phần Hạn chế ở Trang 10.
Hướng dẫn:
• Câu trả lời NA có nghĩa là không có tác động xã hội của công trình được thực hiện.
• Nếu các tác giả trả lời NA hoặc Không, họ nên giải thích tại sao công trình của họ không có tác động xã hội
hoặc tại sao bài báo không đề cập đến tác động xã hội.
• Ví dụ về tác động xã hội tiêu cực bao gồm các cách sử dụng độc hại hoặc không mong muốn tiềm ẩn
(ví dụ, thông tin sai lệch, tạo hồ sơ giả, giám sát), các cân nhắc về công bằng
(ví dụ, triển khai các công nghệ có thể đưa ra quyết định ảnh hưởng bất công đến các
nhóm cụ thể), các cân nhắc về quyền riêng tư, và các cân nhắc về bảo mật.
• Hội nghị mong đợi rằng nhiều bài báo sẽ là nghiên cứu nền tảng và không gắn liền với
các ứng dụng cụ thể, chứ đừng nói đến triển khai. Tuy nhiên, nếu có một con đường trực tiếp đến
bất kỳ ứng dụng tiêu cực nào, các tác giả nên chỉ ra. Ví dụ, việc chỉ ra rằng
một cải tiến trong chất lượng của các mô hình tạo sinh có thể được sử dụng để
tạo deepfakes cho thông tin sai lệch là hợp lý. Mặt khác, không cần thiết phải chỉ ra
rằng một thuật toán chung để tối ưu hóa mạng neural có thể cho phép mọi người huấn luyện
các mô hình tạo Deepfakes nhanh hơn.

--- TRANG 19 ---
• Các tác giả nên xem xét các tác hại có thể có thể phát sinh khi công nghệ được
sử dụng như dự định và hoạt động chính xác, các tác hại có thể phát sinh khi
công nghệ được sử dụng như dự định nhưng đưa ra kết quả không chính xác, và các tác hại theo sau từ
việc sử dụng sai (có chủ ý hoặc không chủ ý) công nghệ.
• Nếu có tác động xã hội tiêu cực, các tác giả cũng có thể thảo luận về các chiến lược giảm thiểu có thể
(ví dụ, phát hành có kiểm soát của các mô hình, cung cấp phòng thủ ngoài tấn công,
các cơ chế để giám sát việc sử dụng sai, các cơ chế để giám sát cách một hệ thống học từ
phản hồi theo thời gian, cải thiện hiệu quả và khả năng tiếp cận của ML).

11. Biện pháp Bảo vệ
Câu hỏi: Bài báo có mô tả các biện pháp bảo vệ đã được đưa ra cho việc phát hành có trách nhiệm
dữ liệu hoặc mô hình có rủi ro cao cho việc sử dụng sai (ví dụ, mô hình ngôn ngữ được pretrain,
trình tạo hình ảnh, hoặc bộ dữ liệu được cạo) không?
Trả lời: [Không]
Biện minh: Bộ dữ liệu của chúng tôi liên quan đến lý luận toán học.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không đặt ra những rủi ro như vậy.
• Các mô hình được phát hành có rủi ro cao cho việc sử dụng sai hoặc sử dụng kép nên được phát hành với
các biện pháp bảo vệ cần thiết để cho phép sử dụng có kiểm soát của mô hình, ví dụ bằng cách yêu cầu
người dùng tuân thủ các hướng dẫn sử dụng hoặc hạn chế để truy cập mô hình hoặc triển khai
các bộ lọc an toàn.
• Các bộ dữ liệu đã được cạo từ Internet có thể đặt ra rủi ro an toàn. Các tác giả
nên mô tả cách họ tránh phát hành hình ảnh không an toàn.
• Chúng tôi nhận ra rằng việc cung cấp các biện pháp bảo vệ hiệu quả là thách thức, và nhiều bài báo
không yêu cầu điều này, nhưng chúng tôi khuyến khích các tác giả xem xét điều này
và nỗ lực thiện chí nhất.

12. Giấy phép cho các tài sản hiện có
Câu hỏi: Các nhà sáng tạo hoặc chủ sở hữu ban đầu của các tài sản (ví dụ, code, dữ liệu, mô hình), được sử dụng trong
bài báo, có được ghi nhận đúng cách và giấy phép và điều khoản sử dụng có được đề cập rõ ràng và
được tôn trọng đúng cách không?
Trả lời: [Có]
Biện minh: Chúng tôi đề cập đến việc sử dụng các mô hình Mixtral và rằng các mô hình này được phát hành dưới
giấy phép cho phép.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không sử dụng các tài sản hiện có.
• Các tác giả nên trích dẫn bài báo gốc đã tạo ra gói code hoặc bộ dữ liệu.
• Các tác giả nên nêu phiên bản nào của tài sản được sử dụng và, nếu có thể, bao gồm một
URL.
• Tên của giấy phép (ví dụ, CC-BY 4.0) nên được bao gồm cho mỗi tài sản.
• Đối với dữ liệu được cạo từ một nguồn cụ thể (ví dụ, trang web), bản quyền và điều khoản
dịch vụ của nguồn đó nên được cung cấp.
• Nếu các tài sản được phát hành, giấy phép, thông tin bản quyền và điều khoản sử dụng trong gói
nên được cung cấp. Đối với các bộ dữ liệu phổ biến, paperswithcode.com/datasets đã
tuyển chọn giấy phép cho một số bộ dữ liệu. Hướng dẫn cấp phép của họ có thể giúp xác định giấy phép
của một bộ dữ liệu.
• Đối với các bộ dữ liệu hiện có được đóng gói lại, cả giấy phép gốc và giấy phép của
tài sản dẫn xuất (nếu nó đã thay đổi) nên được cung cấp.
• Nếu thông tin này không có sẵn trực tuyến, các tác giả được khuyến khích liên hệ với
các nhà sáng tạo tài sản.

13. Tài sản Mới

--- TRANG 20 ---
Câu hỏi: Các tài sản mới được giới thiệu trong bài báo có được tài liệu hóa tốt và tài liệu
có được cung cấp cùng với các tài sản không?
Trả lời: [Có]
Biện minh: Chúng tôi đã cố gắng chia sẻ chi tiết của quá trình tạo bộ dữ liệu và bộ dữ liệu
cuối cùng được tạo ra trong khả năng tốt nhất của chúng tôi. Chúng tôi cũng đã truyền đạt rõ ràng rằng tất cả
các tài nguyên sẽ được phát hành dưới giấy phép cho phép thương mại.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không phát hành tài sản mới.
• Các nhà nghiên cứu nên truyền đạt chi tiết của bộ dữ liệu/code/mô hình như một phần của
việc nộp của họ thông qua các mẫu có cấu trúc. Điều này bao gồm chi tiết về huấn luyện, giấy phép,
hạn chế, v.v.
• Bài báo nên thảo luận liệu và cách thức sự đồng ý đã được thu được từ những người mà
tài sản được sử dụng.
• Tại thời điểm nộp, hãy nhớ ẩn danh hóa tài sản của bạn (nếu có thể áp dụng). Bạn có thể
tạo URL ẩn danh hoặc bao gồm file zip ẩn danh.

14. Crowdsourcing và Nghiên cứu với Đối tượng Con người
Câu hỏi: Đối với các thí nghiệm crowdsourcing và nghiên cứu với đối tượng con người, bài báo có bao gồm
toàn bộ văn bản hướng dẫn được đưa cho người tham gia và ảnh chụp màn hình, nếu có thể áp dụng, cũng như
chi tiết về tiền thù lao (nếu có) không?
Trả lời: [NA]
Biện minh: Không phải là bài báo liên quan đến đối tượng con người.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không liên quan đến crowdsourcing hay nghiên cứu với
đối tượng con người.
• Bao gồm thông tin này trong tài liệu bổ sung là tốt, nhưng nếu đóng góp chính
của bài báo liên quan đến đối tượng con người, thì càng nhiều chi tiết càng tốt nên được
bao gồm trong bài báo chính.
• Theo Quy tắc Đạo đức NeurIPS, các worker tham gia vào thu thập dữ liệu, tuyển chọn,
hoặc lao động khác nên được trả ít nhất mức lương tối thiểu ở quốc gia của người thu thập dữ liệu.

15. Phê duyệt Hội đồng Đánh giá Thể chế (IRB) hoặc Tương đương cho Nghiên cứu với Đối tượng
Con người
Câu hỏi: Bài báo có mô tả các rủi ro tiềm ẩn mà người tham gia nghiên cứu gặp phải, liệu
những rủi ro như vậy có được tiết lộ cho đối tượng, và liệu phê duyệt Hội đồng Đánh giá Thể chế (IRB)
(hoặc phê duyệt/đánh giá tương đương dựa trên yêu cầu của quốc gia hoặc
thể chế của bạn) có được thu được không?
Trả lời: [NA]
Biện minh: Không yêu cầu cho bài báo của chúng tôi.
Hướng dẫn:
• Câu trả lời NA có nghĩa là bài báo không liên quan đến crowdsourcing hay nghiên cứu với
đối tượng con người.
• Tùy thuộc vào quốc gia nơi nghiên cứu được thực hiện, phê duyệt IRB (hoặc tương đương)
có thể được yêu cầu cho bất kỳ nghiên cứu đối tượng con người nào. Nếu bạn có được phê duyệt IRB, bạn
nên nêu rõ điều này trong bài báo.
• Chúng tôi nhận ra rằng các thủ tục cho điều này có thể khác nhau đáng kể giữa các thể chế
và địa điểm, và chúng tôi mong đợi các tác giả tuân thủ Quy tắc Đạo đức NeurIPS và
hướng dẫn cho thể chế của họ.
• Đối với các bài nộp ban đầu, không bao gồm bất kỳ thông tin nào sẽ phá vỡ tính ẩn danh (nếu
có thể áp dụng), như thể chế thực hiện đánh giá.

A Thống kê Dữ liệu

--- TRANG 21 ---
Mẫu Giải pháp Kiểu Code-Interpreter

Câu hỏi
Một cửa hàng bách hóa hiển thị giảm giá 20% trên tất cả đồ đạc. Giá mới của một chiếc đèn ngủ cao 25 cm
có giá trị $120 sẽ là bao nhiều?

Giải pháp Kiểu Code-Interpreter
Hãy giải bài toán này bằng code Python.

<llm-code>
discount_percent = 20
price_before_discount = 120
discount = discount_percent / 100
discount_amount = price_before_discount * discount
price = price_before_discount - discount_amount
price
</llm-code>
<llm-code-output>
96.0
</llm-code-output>

Vậy giá mới của chiếc đèn là 96 đô la.

Hình 5: Giải pháp kiểu Code-Interpreter cho một bài toán tập huấn luyện từ GSM8K.

Hình 6: Phân phối các giải pháp với số lượng khối code khác nhau trong OpenMathInstruct-1.

A.1 Tần số Số lượng Khối Code

Chúng tôi đang sử dụng định dạng giải pháp code-interpreter, cho phép lý luận linh hoạt bằng văn bản cùng với
độ chính xác trong lý luận dựa trên code (xem Hình 10). Code-interpreter cho phép giải quyết một bài toán
bằng cách chia nó thành nhiều khối code. Hầu hết các giải pháp trong OpenMathInstruct-1 có 0 hoặc 1
khối code, lần lượt là 16.4% và 81.7% các giải pháp (xem Hình 6). 2% các
giải pháp còn lại có hai hoặc nhiều khối code hơn. Hình 7 hiển thị một ví dụ về giải pháp sử dụng hai
khối code.

A.2 Tần số của các giải pháp cho mỗi bài toán trong OpenMathInstruct-1

Hình 8 hiển thị biểu đồ tần số của tần số số lượng giải pháp trong OpenMathInstruct-1
cho các bài toán trong GSM8K và MATH. Đối với GSM8K, 57.4% bài toán (4292 trong số 7473) có nhiều hơn
nửa số giải pháp được lấy mẫu, tức là >128 giải pháp trong số 256 giải pháp được lấy mẫu, là hợp lệ. Đối với
MATH, biểu đồ tần số giải pháp bắt chước đường cong lũy thừa, với hầu hết các bài toán có rất
ít giải pháp và rất ít bài toán với nhiều giải pháp. Cụ thể, 19% bài toán (1324 trong số

--- TRANG 22 ---
Giải pháp với Hai Khối Code

Câu hỏi
Cho d và e biểu thị các nghiệm của 2x² + 3x - 5 = 0. Giá trị của (d-1)(e-1) là bao nhiều?

Giải pháp Được tạo ra
Hãy giải phương trình bậc hai sử dụng Sympy:

<llm-code>
from sympy import Symbol, solve, Eq, simplify

# Định nghĩa biến x
x = Symbol('x')

# Định nghĩa phương trình
eq = 2*x**2 + 3*x - 5

# Giải phương trình
roots = solve(eq, x)

# In các nghiệm
print("Các nghiệm là:")
for root in roots:
    print("x = ", simplify(root))
</llm-code>
<llm-code-output>
Các nghiệm là:
x = -5/2
x = 1
</llm-code-output>

Vậy d = -5/2 và e = 1.

Hãy tính câu trả lời:

<llm-code>
d = -5/2
e = 1

d_minus_1 = d - 1
e_minus_1 = e - 1

result = d_minus_1 * e_minus_1
print("Giá trị của (d-1)(e-1) là:", result)
</llm-code>
<llm-code-output>
Giá trị của (d-1)(e-1) là: -0.0
</llm-code-output>

Vậy câu trả lời là -0.0.

Hình 7: Mẫu giải pháp với nhiều khối code. Khối code đầu tiên tính các nghiệm của
phương trình bậc hai đã cho và khối thứ hai tính biểu thức liên quan đến chúng.

6978) với bất kỳ giải pháp nào trong OpenMathInstruct-1 có ≤10 giải pháp hợp lệ trong số 896 giải pháp được lấy mẫu
cho mỗi bài toán. Để làm nổi bật thêm độ khó của benchmark MATH so với
GSM8K, chỉ 3.1% bài toán (233 trong số 7500) có nhiều hơn nửa số giải pháp được lấy mẫu (>448
trong số 896 giải pháp được lấy mẫu), là hợp lệ.

--- TRANG 23 ---
(a) GSM8K (b) MATH

Hình 8: Biểu đồ tần số của số lượng giải pháp cho các bài toán trong GSM8K và MATH.

Sự Đa dạng của Giải pháp

Câu hỏi
Cho t(x) = √(3x + 1) và f(x) = 5 - t(x). t(f(5)) là bao nhiều?

Giải pháp 1
Để tìm t(f(5)) chúng ta có thể thay
x = 5 vào các hàm
t(x) và f(x) và sau đó tìm
giá trị của t(f(5)). Để thực hiện
các phép tính chúng ta sẽ sử dụng thư viện sympy.

<llm-code>
from sympy import symbols,
sqrt, simplify

# Định nghĩa các ký hiệu
x, f = symbols('x f')

# Định nghĩa các hàm
t = sqrt(3*x + 1)
f = 5 - t

# Đánh giá t tại f(5)
t.subs(x, f.subs(x, 5))
</llm-code>
<llm-code-output>
2
</llm-code-output>

Vậy giá trị của t(f(5)) là 2.

Giải pháp 2
Đầu tiên hãy tính t(x) cho
x = 5:
t(5) = √(3*5 + 1) = √16 = 4.

Sau đó hãy tính f(x)
cho x = 5:
f(5) = 5 - t(5) = 5 - 4 = 1.

Cuối cùng hãy tính
t(f(5)):
t(f(5)) = t(1) = √(3*1 + 1) = √4 = 2.

Vậy câu trả lời là 2.

Giải pháp 3
<llm-code>
def t(x):
    return (3 * x + 1) ** 0.5

def f(x):
    return 5 - t(x)

t(f(5))
</llm-code>
<llm-code-output>
2.0
</llm-code-output>

Như vậy câu trả lời là 2.

Hình 9: Ba giải pháp đại diện cho một bài toán mẫu từ tập huấn luyện MATH trong
OpenMathInstruct-1. Giải pháp đầu tiên và thứ ba sử dụng code, với giải pháp đầu tiên sử dụng thư viện sympy.
Giải pháp thứ hai dựa trên văn bản.

--- TRANG 24 ---
A.3 Phân chia Dữ liệu Huấn luyện MATH theo Môn học

Bảng 11: Phân tích tập huấn luyện MATH theo môn học.

Môn học | # Thể hiện Huấn luyện
Algebra | 1744
Geometry | 870
Intermediate Algebra | 1295
Number Theory | 869
Prealgebra | 1205
Precalculus | 746
Probability | 771
Tổng | 7500

B Khác

B.1 Siêu tham số Huấn luyện

Bảng 12: Chi tiết về các siêu tham số huấn luyện để tinh chỉnh các mô hình cơ sở khác nhau. LR=Tỷ lệ học,
TP=Tensor Parallel, PP=Pipeline Parallel.

| | Epochs | LR | # GPUs | TP | PP |
|---|---|---|---|---|---|
| Mistral-7B | 4 | 1e-6 | 64 | 4 | 1 |
| CodeLlama-7B | 4 | 2e-5 | 64 | 4 | 1 |
| CodeLlama-13B | 4 | 2e-5 | 64 | 4 | 1 |
| CodeLlama-34B | 4 | 1e-5 | 128 | 8 | 1 |
| Llama 2-70B | 2 | 1e-5 | 256 | 8 | 2 |
| CodeLlama-70B | 3 | 1e-5 | 256 | 8 | 2 |

Bảng 12 chi tiết các siêu tham số được sử dụng để tinh chỉnh các mô hình cơ sở khác nhau. Do hạn chế tính toán, đối với các mô hình 70B, chúng tôi giới hạn huấn luyện đến 2 epoch cho Llama2 và 3 epoch cho CodeLlama.
Đối với các mô hình CodeLlama, chúng tôi sử dụng tỷ lệ học 2e-5 được sử dụng bởi các mô hình ToRA [8]. Đối với mô hình Mistral-7B, chúng tôi sử dụng tỷ lệ học thấp hơn 1e-6 dựa trên tìm kiếm siêu tham số của chúng tôi.

B.2 Mẫu Giải pháp

Trong phần này, chúng tôi minh họa các mẫu giải pháp đại diện cho các hiện tượng khác nhau gặp phải
trong quá trình tạo OpenMathInstruct-1.

• Hình 9 trình bày một bài toán mẫu từ tập huấn luyện MATH với các giải pháp đại diện của nó
từ bộ dữ liệu OpenMathInstruct-1.

• Hình 10 hiển thị một mẫu giải pháp sử dụng sức mạnh của định dạng giải pháp code-interpreter
với lý luận trong cả code và ngôn ngữ tự nhiên.

• Hình 11 thể hiện một mẫu giải pháp được tạo ra khi giải pháp tham khảo được sử dụng trong
prompt few-shot. Mô hình sao chép tuổi của trẻ em từ giải pháp tham khảo và
khởi tạo biến child_age. Các giải pháp như vậy là lý do tại sao chúng tôi đề xuất việc sử dụng
các giải pháp văn bản được che giấu trong prompt.

• Hình 12 minh họa một mẫu giải pháp trong đó giải pháp vượt quá việc trả lời câu
hỏi, với mô hình tạo ra văn bản mạch lạc nhưng không liên quan cho bài toán đầu vào.

• Hình 13 hiển thị một mẫu giải pháp trong đó giải pháp được tạo ra có được câu trả lời đúng nhưng
thông qua lý luận có lỗ hổng. Các giải pháp nhiễu về mặt ngữ nghĩa này khó phát hiện hơn nhiều
với các bộ lọc cú pháp đơn giản. Một giải pháp có thể là sử dụng các mô hình như GPT-4 để chấm điểm
các giải pháp được tạo ra như đã thực hiện trong nghiên cứu gần đây [5]. Chúng tôi để việc phát triển các
bộ lọc ngữ nghĩa như vậy cho công trình tương lai.

--- TRANG 25 ---
Lý luận Code + Văn bản

Câu hỏi
Cho p(x) = √(-x), và q(x) = 8x² + 10x - 3. Miền của p(q(x)) có thể được viết dưới dạng
a ≤ x ≤ b. Tìm b - a.

Giải pháp Được tạo ra
Hãy sử dụng sympy để giải miền của p(q(x)).

<llm-code>
import sympy as sp

# định nghĩa các ký hiệu
x = sp.symbols('x')

# định nghĩa các hàm
p = sp.sqrt(-x)
q = 8*x**2 + 10*x - 3

# giải miền của p(q(x))
domain = sp.solve(q >= 0, x)

# in miền
print(domain)
</llm-code>
<llm-code-output>
((1/4 <= x) & (x < oo)) | ((-oo < x) & (x <= -3/2))
</llm-code-output>

Vậy miền là x ∈ [1/4, ∞) ∪ (-∞, -3/2].

Sự khác biệt giữa giới hạn trên và dưới là b - a = 1/4 - (-3/2).

Hình 10: Mẫu giải pháp trong đó mô hình thực hiện lý luận ban đầu trong code và thực hiện
các bước lý luận cuối cùng để trả lời câu hỏi bằng ngôn ngữ tự nhiên. Điều này cho thấy sức mạnh của
định dạng giải pháp code-interpreter cho lý luận toán học.

B.3 Phân tích Lỗi của Giải pháp Được tạo ra bởi Mô hình Được Tinh chỉnh

Trong phần này, chúng tôi minh họa các trường hợp của các loại lỗi khác nhau được tạo ra bởi mô hình ablation
được phân tích trong Phần 5.

• Hình 14 thể hiện một mẫu trong đó mô hình thực hiện lý luận chính xác trong khi tạo
ra code. Tuy nhiên, mô hình sa sút khi sao chép đầu ra code và tạo ra một
câu trả lời mới.

• Hình 15 trình bày một ví dụ trong đó mô hình tạo ra code chính xác nhưng không hiệu quả mà
không hoàn thành trong thời gian thực thi quy định của chúng tôi và dẫn đến lỗi timeout.

• Hình 16 minh họa một mẫu trong đó mô hình thực hiện lý luận chính xác nhưng sa sút trong
tính toán số học (phép nhân). Thất bại trong tính toán số học đã là một
vấn đề đã biết với LLMs và biện minh cho sự ưa thích của chúng tôi đối với các giải pháp dựa trên code.

• Hình 17 hiển thị một ví dụ trong đó mô hình tạo ra một khối code sai để giải quyết
vấn đề và liên tục tạo ra cùng một khối code cho đến khi nó chạy vào ràng buộc thực thi
tối đa của chúng tôi. Ví dụ này cho thấy một hạn chế của bộ dữ liệu hiện tại của chúng tôi trong đó chúng tôi thiếu
các ví dụ mà mô hình phục hồi từ lỗi của nó, không giống như GPT-4 [23].

• Hình 18 hiển thị một mẫu giải pháp trong đó code được tạo ra trong giải pháp chạy vào
lỗi thực thi. Tuy nhiên, mô hình vẫn tạo ra một câu trả lời không chính xác cho câu hỏi.

--- TRANG 26 ---
Giải pháp Đường tắt

Câu hỏi
Jolene và Phil có bốn đứa con, mỗi đứa có cùng sinh nhật. Họ sinh đứa con đầu tiên
đúng 15 năm trước. Họ sinh đứa con thứ hai đúng một năm sau khi sinh
đứa con đầu tiên. Họ sinh đứa con thứ ba vào sinh nhật lần thứ tư của đứa con thứ hai.
Hai năm sau khi sinh đứa con thứ ba, họ sinh đứa con thứ tư. Đứa con thứ tư bao nhiêu tuổi?

Giải pháp Tham khảo
Đứa con đầu tiên của họ được sinh 15 năm trước, và do đó 15 tuổi.
Đứa con thứ hai của họ được sinh 1 năm sau đứa con 15 tuổi, và do đó 15-1=14 tuổi.
Đứa con thứ ba của họ được sinh 4 năm sau đứa con 14 tuổi, và do đó 14-4=10 tuổi.
Đứa con thứ tư của họ được sinh 2 năm sau đứa con 10 tuổi, và do đó 10-2=8 tuổi.

Giải pháp Được tạo ra
Hãy viết một script python để trả lời vấn đề này.

<llm-code>
children = ['first', 'second', 'third', 'fourth']
child_age = [15, 14, 10, 8]
number_of_children = len(children)
children = children[:-1] # hãy loại bỏ đứa nhỏ nhất vì chúng ta đã biết đứa đó
dictionary = dict(zip(children, child_age))
dictionary
</llm-code>
<llm-code-output>
{'first': 15, 'second': 14, 'third': 10}
</llm-code-output>

Câu trả lời là 8 tuổi.

Hình 11: Mẫu giải pháp đường tắt được tạo ra từ việc prompting LLM với giải pháp tham khảo
trong ngữ cảnh. Code khởi tạo biến child_age với tuổi của trẻ em được sao chép từ
giải pháp tham khảo. Code được tạo ra sau đó thực hiện các tính toán ad-hoc trước khi trả lời
câu hỏi trong văn bản.

B.4 Hướng dẫn cho Việc tạo ra Dữ liệu Few-shot

Bảng 13: Hướng dẫn để prompting mô hình.

Tác vụ | Hướng dẫn
Prompt few-shot (I) | Đây là một số ví dụ về câu hỏi và giải pháp theo sau bởi một câu hỏi mới mà bạn cần giải quyết. Hãy chắc chắn đặt câu trả lời (và chỉ câu trả lời) bên trong \boxed{}.
Prompt few-shot che giấu văn bản (Imask) | Đây là một số ví dụ về câu hỏi, giải pháp, và các giải pháp được che giấu của chúng theo sau bởi một câu hỏi và giải pháp mới mà bạn cần che giấu. Mục tiêu là đảm bảo rằng giải pháp được che giấu không có bất kỳ giá trị số nào không được đề cập trong câu hỏi. Vậy các giá trị trung gian được tính toán trong giải pháp sẽ được che giấu bằng các biến chữ cái viết hoa đơn lẻ, như M, N.
Prompt zero-shot cho các mô hình được tinh chỉnh | System: Bạn là một lập trình viên Python và nhà toán học chuyên nghiệp. Giúp người dùng giải quyết vấn đề này bằng code khi cần thiết. Hãy chắc chắn đặt câu trả lời (và chỉ câu trả lời) bên trong \boxed{}.

Bảng 13 chi tiết các hướng dẫn được sử dụng cho các tác vụ tạo ra khác nhau.

--- TRANG 27 ---
Giải pháp Yêu cầu Cắt tỉa

Câu hỏi
Caroline có thể làm mười một ly lassi từ hai quả xoài. Cô ấy có thể làm bao nhiêu ly lassi từ mười hai quả xoài?

Giải pháp Được tạo ra
Cho f(x) là số ly lassi cô ấy có thể làm từ x quả xoài. Từ câu hỏi, chúng ta có thể thấy
rằng f(2) = 11. Sử dụng đại số cơ bản, chúng ta có thể thấy rằng f(12) = 66.

Hãy xác minh điều này với sympy.

<llm-code>
import sympy as sp

# định nghĩa hàm ẩn
x, y = sp.symbols('x y')

# hãy định nghĩa parabola
parabola = sp.Eq(y, x**2 + b*x + c)

# thay thế các điểm vào phương trình parabola và giải cho b, c
point_1 = parabola.subs({x: -1, y: -11})
point_2 = parabola.subs({x: 3, y: 17})
solutions = sp.solve((point_1,point_2), (b, c))
solutions[b]
</llm-code>

Giải pháp Được cắt tỉa
Cho f(x) là số ly lassi cô ấy có thể làm từ x quả xoài. Từ câu hỏi, chúng ta có thể thấy
rằng f(2) = 11. Sử dụng đại số cơ bản, chúng ta có thể thấy rằng f(12) = 66.

Hình 12: Mẫu giải pháp trong đó mô hình tạo ra văn bản không liên quan sau khi trả lời câu hỏi.
Trong quá trình hậu xử lý, chúng tôi cắt tỉa giải pháp bằng cách loại bỏ văn bản vượt quá dòng giải pháp với
câu trả lời.

B.5 Việc tạo ra Giải pháp Văn bản Được Che giấu

Chúng tôi tạo ra các giải pháp văn bản được che giấu bằng một đường ống rất tương tự như đường ống tạo ra giải pháp.
Chúng tôi sử dụng quy trình sau:

• Tạo ra tám giải pháp được che giấu ứng viên.
• Lọc ra các giải pháp có độ dài rất khác nhau.
• Lọc ra các giải pháp có câu trả lời cuối cùng. Điều này đảm bảo rằng các giải pháp được che giấu của chúng tôi ít nhất
che giấu câu trả lời cuối cùng.
• Xếp hạng các giải pháp trong đó các giải pháp được xếp hạng cao hơn có ít số hơn. Đây về cơ bản là một
heuristic để đảm bảo chúng tôi chọn các giải pháp mà phép tính trung gian được che giấu nhiều nhất.

B.6 Các prompt Few-shot được sử dụng cho GSM8K và MATH

--- TRANG 28 ---
Lý luận Có lỗ hổng

Câu hỏi
Diện tích của hai hình vuông có tỷ lệ 25 : 36. Tỷ lệ chu vi của chúng là bao nhiều? Biểu thị
câu trả lời của bạn dưới dạng a:b.

Giải pháp Tham khảo
Nói chung, nếu tỷ lệ chu vi của hai hình tương tự là a/b, thì tỷ lệ diện tích của chúng là
(a/b)². Vậy trong trường hợp này, (a/b)² = 25/36, hoặc a/b = 5/6.

Vậy câu trả lời là 5 : 6.

Giải pháp Được tạo ra
Hãy sử dụng sympy để in ra sự khác biệt giữa tỷ lệ chu vi của chúng và từng lựa chọn.

<llm-code>
from sympy import Rational, Abs

# diện tích có tỷ lệ 25:36
area_ratio = Rational(25, 36)

# danh sách các lựa chọn
options = [Rational(5, 6), Rational(5, 4), Rational(5, 3), Rational(5, 2),
Rational(5, 1)]

# hãy in ra các sự khác biệt
[Abs(area_ratio - frac_option) for frac_option in options]
</llm-code>
<llm-code-output>
[5/36, 5/9, 35/36, 65/36, 155/36]
</llm-code-output>

Bây giờ hãy kiểm tra sự khác biệt nào là nhỏ nhất.

<llm-code>
import numpy as np

# Tính idx của lựa chọn gần nhất
min_idx = np.argmin([5/36, 5/9, 35/36, 65/36, 155/36])

# In lựa chọn gần nhất
print(options[min_idx])
</llm-code>
<llm-code-output>
5/6
</llm-code-output>

Vậy câu trả lời là 5 : 6.

Hình 13: Mẫu giải pháp trong đó mô hình sử dụng lý luận hoàn toàn có lỗ hổng để đi đến câu trả lời chính xác. Lý luận có lỗ hổng như vậy khó phát hiện, nhưng may mắn thay, các giải pháp này hiếm gặp.

--- TRANG 29 ---
Sự cố Bước cuối

Câu hỏi
Chữ số thứ 100 ở bên phải dấu thập phân trong biểu diễn thập phân của 13/90 là gì?

Giải pháp Được tạo ra
Chúng ta có thể sử dụng sympy để tính biểu diễn thập phân của 13/90 và sau đó trích xuất chữ số thứ 100.

<llm-code>
from sympy import Rational, N

# Tính biểu diễn thập phân của 13/90
decimal_rep = N(Rational(13, 90), 100)

# Trích xuất chữ số thứ 100
digit = int(str(decimal_rep)[-1])
print(digit)
</llm-code>
<llm-code-output>
4
</llm-code-output>

Vậy chữ số thứ 100 ở bên phải dấu thập phân trong biểu diễn thập phân của 13/90 là 7.

Hình 14: Mô hình thực hiện lý luận chính xác cho đến khi tạo ra code. Nhưng thay vì sao chép
đầu ra code (4) nó kết luận với một câu trả lời khác (7).

--- TRANG 30 ---
Timeout

Câu hỏi
Cho a₁, a₂, ... là một dãy mà a₁ = 2, a₂ = 3, và aₙ = aₙ₋₁/aₙ₋₂ với mỗi số nguyên dương
n ≥ 3. a₂₀₀₆ là bao nhiều?

Giải pháp Được tạo ra
Hãy viết một hàm tính aₙ cho một n đã cho.

<llm-code>
def a_n(n):
    if n == 1:
        return 2
    elif n == 2:
        return 3
    else:
        return a_n(n-1) / a_n(n-2)

print(a_n(2006))
</llm-code>
<llm-code-output>
None
</llm-code-output>

Vậy a₂₀₀₆ = 1/5.

Hình 15: Mô hình tạo ra code dựa trên đệ quy để giải quyết vấn đề. Trong khi code về mặt kỹ thuật là chính xác, việc thiếu memoization có nghĩa là code cuối cùng cực kỳ không hiệu quả và
chạy vào timeout.

Lỗi Tính toán

Câu hỏi
Đội bóng rổ của chúng tôi có 12 thành viên, mỗi người có thể chơi bất kỳ vị trí nào. Có bao nhiêu cách
chúng ta có thể chọn một đội hình xuất phát gồm một trung phong, một tiền đạo cánh, một hậu vệ cánh, một tiền vệ
và một hậu vệ ném?

Giải pháp Được tạo ra
Chúng ta có thể chọn một đội hình xuất phát theo 12 × 11 × 10 × 9 × 8 = 11880 cách.

Hình 16: Mẫu giải pháp trong đó mô hình thực hiện lý luận văn bản đúng nhưng mắc lỗi tính toán.

--- TRANG 31 ---
Đạt Số lần Thực thi Tối đa

Câu hỏi
Trong △ABC, AB = 425, BC = 450, và AC = 510. Một điểm nội P sau đó được vẽ, và
các đoạn thẳng được vẽ qua P song song với các cạnh của tam giác. Nếu ba đoạn thẳng này có
độ dài bằng nhau d, tìm d.

Giải pháp Được tạo ra
Hãy sử dụng sympy để giải quyết vấn đề này.

<llm-code>
from sympy import symbols, Eq, solve

# Định nghĩa các biến
AB, BC, AC, d = symbols('AB BC AC d')

# Định nghĩa các phương trình
eq1 = Eq(AB, 425)
eq2 = Eq(BC, 450)
eq3 = Eq(AC, 510)
eq4 = Eq(AB + BC, 2 * d)
eq5 = Eq(BC + AC, 2 * d)
eq6 = Eq(AC + AB, 2 * d)

# Giải các phương trình
solutions = solve((eq1, eq2, eq3, eq4, eq5, eq6), (AB, BC, AC, d))
solutions
</llm-code>
<llm-code-output>
[]
</llm-code-output>

Các giải pháp trống, vậy chúng ta không thể giải quyết vấn đề này bằng sympy.

Hãy thử giải quyết nó một cách thủ công.

Chúng ta có thể thấy rằng tổng của hai cạnh bất kỳ của một tam giác lớn hơn cạnh thứ ba.
Vậy chúng ta có thể viết các bất đẳng thức sau:

AB + BC > AC
BC + AC > AB
AC + AB > BC

Hãy viết lại chúng bằng các giá trị đã cho:

425 + 450 > 510
450 + 510 > 425
510 + 425 > 450

Chúng ta có thể giải các bất đẳng thức này bằng sympy:

···

Hình 17: Mô hình tạo ra khối code đầu tiên, về mặt logic không chính xác và dẫn đến
đầu ra trống. Khối văn bản tiếp theo xác định vấn đề với đầu ra nhưng thực hiện lý luận không chính xác
dẫn đến việc tạo ra khối code thứ hai. Mô hình không thể phục hồi từ
các lỗi này và cuối cùng tạo ra các khối code-văn bản là các bản sao nguyên văn của khối code-văn bản đầu tiên. Việc tạo ra dừng lại ở khối code thứ sáu, đây là giới hạn của chúng tôi về số lần thực thi khối code
trong quá trình suy luận.

--- TRANG 32 ---
Lỗi Thực thi Code

Câu hỏi
Diện tích của một tam giác là 600 feet vuông. Tìm chiều cao, tính bằng feet, của tam giác nếu độ dài
của đáy tương ứng là 30 feet.

Giải pháp Được tạo ra
Hãy sử dụng sympy để giải quyết vấn đề này.

<llm-code>
from sympy import symbols, Eq, solve

# định nghĩa các biến
base, altitude = symbols('base altitude')

# diện tích của tam giác
area_eq = Eq(base * altitude / 2, 600)

# độ dài của đáy tương ứng
base_eq = Eq(base, 30)

# giải các phương trình
solutions = solve((area_eq, base_eq), (base, altitude))

# in chiều cao
print(solutions[altitude])
</llm-code>
<llm-code-output>
[0;31m--------------------------[0m
[0;31mTypeError[0m Traceback (most recent call last)
File [0;32m<ipython-input-1-f95732badac7>:16[0m
[1;32m 13[0m solutions [38;5;241m=[39m solve((area_eq, base_eq), (base, altitude)
)
[1;32m 15[0m [38;5;66;03m# print the altitude[39;00m
[0;32m---> 16[0m [38;5;28mprint[39m([43msolutions[49m[43m[[49m[43maltitude[49m[43
m][49m)

[0;31mTypeError[0m: list indices must be integers or slices, not Symbol
</llm-code-output>

Vậy chiều cao là 20.

Hình 18: Mẫu giải pháp trong đó code do mô hình tạo ra chạy vào lỗi thực thi. Tuy nhiên,
mô hình vẫn tạo ra một câu trả lời không chính xác cho câu hỏi.

--- TRANG 33 ---
Listing 1: Prompt few-shot cho GSM8K.

Đây là một số ví dụ về câu hỏi và giải pháp theo sau bởi một câu hỏi mới
mà bạn cần giải quyết.
Hãy chắc chắn đặt câu trả lời (và chỉ câu trả lời) bên trong \boxed{}.

Câu hỏi:
Missy có một con heo đất khổng lồ trong phòng ngủ của cô ấy. Mỗi ngày cô ấy sẽ tìm kiếm
tiền lẻ trong nhà để bỏ vào ngân hàng của mình. Sau 4 năm, ngân hàng được mở và
nó chứa $450 tiền lẻ. Nếu năm thứ hai, thứ ba và thứ tư cô ấy
nhân đôi số tiền bỏ vào ngân hàng so với số tiền cô ấy đã bỏ
vào năm trước đó, cô ấy đã bỏ bao nhiêu tiền, tính bằng đô la, vào ngân hàng
năm đầu tiên?

Giải pháp của tôi:
Missy bắt đầu với một số tiền nào đó trong năm đầu tiên.
Cô ấy sau đó nhân đôi số tiền mỗi năm trong 4 năm và cuối cùng có $450.

Hãy viết một phương trình cho vấn đề này và giải nó bằng sympy.

<llm-code>
from sympy import solve, symbols

first_year_money = symbols('first_year_money')
second_year_money = 2 * first_year_money
third_year_money = 2 * second_year_money
fourth_year_money = 2 * third_year_money

# Giải cho tiền năm đầu tiên biết rằng tổng tiết kiệm là 450
result = solve(first_year_money + second_year_money + third_year_money +
fourth_year_money - 450, first_year_money)[0]
result
</llm-code>
<llm-code-output>
30
</llm-code-output>

Như vậy Missy đã bỏ \boxed{30} đô la vào ngân hàng năm đầu tiên.

Câu hỏi:
Pete phải đi bộ 10 phút xuống ga tàu và sau đó lên tàu
1 giờ 20 phút đến LA. Anh ấy nên rời đi khi nào nếu anh ấy không thể đến LA
muộn hơn 0900 giờ? (thời gian 24 giờ)

Giải pháp của tôi:
Vì Pete cần đi bộ 10 phút và sau đó đi tàu 1 giờ 20 phút, anh ấy sẽ
mất tổng cộng 1 giờ và 30 phút.

Điều này có nghĩa là anh ấy cần rời đi sớm hơn 1 giờ và 30 phút so với 09:00
giờ.

Trừ 1 giờ và 30 phút từ 09:00 giờ chúng ta được \boxed{07:30}
giờ.

Câu hỏi:
Mark gửi $88 vào ngân hàng. Bryan gửi ít hơn $40 so với năm lần số tiền của Mark.
Bryan đã gửi bao nhiêu vào ngân hàng?

Giải pháp của tôi:
Hãy giải quyết vấn đề này bằng code Python.

<llm-code>
mark_deposit = 88
five_times_mark_deposit = 5 * mark_deposit

--- TRANG 34 ---
bryan_deposit = five_times_mark_deposit - 40
bryan_deposit
</llm-code>
<llm-code-output>
400
</llm-code-output>

Vậy Bryan đã gửi \boxed{400} đô la vào ngân hàng.

Câu hỏi:
Một cửa hàng bách hóa hiển thị giảm giá 20% trên tất cả đồ đạc. Giá mới của
một chiếc đèn ngủ cao 25 cm có giá trị $120 sẽ là bao nhiều?

Giải pháp của tôi:
Hãy giải quyết vấn đề này bằng code Python.

<llm-code>
discount_percent = 20
price_before_discount = 120
discount_portion = discount_percent / 100
discount_amount = price_before_discount * discount_portion
price_after_discount = price_before_discount - discount_amount
price_after_discount
</llm-code>
<llm-code-output>
96.0
</llm-code-output>

Vậy giá mới của chiếc đèn là \boxed{96} đô la.

Câu hỏi:
James mở một cửa hàng hoa. Anh ấy cần trả tiền thuê $1200 một tuần với thêm
20% tiền thuê để trả cho tiện ích và anh ấy có 2 nhân viên mỗi ca
với cửa hàng mở 16 giờ một ngày trong 5 ngày một tuần. Nếu anh ấy trả cho mỗi
nhân viên $12.50 một giờ, chi phí hàng tuần của anh ấy để điều hành cửa hàng là bao nhiều?

Giải pháp của tôi:
Chi phí bao gồm tiền thuê, tiện ích và lương nhân viên. Hãy tính
từng cái riêng biệt và sau đó cộng chúng lại.

<llm-code>
# chi phí thuê
rent_per_week = 1200

# chi phí tiện ích
utility_per_week = rent_per_week * 20 / 100

# chi phí nhân viên
employee_work_hours = 16
work_days_per_week = 5
employee_work_hours_per_week = work_days_per_week * employee_work_hours
number_of_employees = 2
employee_cost_per_hour = 12.5
employees_cost_per_week = number_of_employees * employee_work_hours_per_week
* employee_cost_per_hour

# cộng ba cái để có tổng chi phí
cost_per_week = rent_per_week + utility_per_week + employees_cost_per_week
cost_per_week
</llm-code>
<llm-code-output>
3440.0
</llm-code-output>

Như vậy chi phí hàng tuần của James cộng lại là \boxed{3440} đô la.

--- TRANG 35 ---
Câu hỏi:
Tim có ít hơn Martha 30 quả táo, và Harry có một nửa số táo so với Tim.
Nếu Martha có 68 quả táo, Harry có bao nhiêu quả táo?

Giải pháp của tôi:

--- TRANG 36 ---
Listing 2: Prompt few-shot cho MATH.

Đây là một số ví dụ về câu hỏi và giải pháp theo sau bởi một câu hỏi mới
mà bạn cần giải quyết.
Hãy chắc chắn đặt câu trả lời (và chỉ câu trả lời) bên trong \boxed{}.

Câu hỏi:
Một parabola với phương trình $y=x^2+bx+c$ đi qua các điểm $(-1,-11)$
và $(3,17)$. $c$ là bao nhiều?

Giải pháp của tôi:
Hãy viết một phương trình cho parabola và giải cho $c$ bằng sympy.

<llm-code>
import sympy as sp

# định nghĩa các ký hiệu
x, y, b, c = sp.symbols('x y b c')

# định nghĩa phương trình parabola
parabola_eq = sp.Eq(y, x**2 + b*x + c)

# parabola đi qua các điểm (-1,-11) và (3,17)
# vậy chúng ta thay thế các điểm này vào phương trình parabola
point_1 = parabola_eq.subs({x: -1, y: -11})
point_2 = parabola_eq.subs({x: 3, y: 17})

# bây giờ chúng ta có hai phương trình và hai ẩn số (b và c)
# chúng ta sẽ giải cho b và c
solutions = sp.solve((point_1,point_2), (b, c))
solutions[c]
</llm-code>
<llm-code-output>
-7
</llm-code-output>

Vậy c là \boxed{-7}

Câu hỏi:
Cho $f(x)$ là một hàm lẻ. $f(f(x))$ là chẵn, lẻ, hay không phải cả hai?
Nhập "odd", "even", hoặc "neither".

Giải pháp của tôi:
Định nghĩa của một hàm lẻ là $f(-x) = -f(x)$.
Áp dụng điều này cho $f(f(-x))$ chúng ta có $f(f(-x)) = f(-f(x)) = -f(f(x))$.
Như vậy, $f(f(x))$ là một hàm \boxed{odd}.

Câu hỏi:
Tại Olympic Toán học 2007, Đội Canada đã thắng $17$ trong số $100$ huy chương có thể có.
Cái nào trong số sau đây gần nhất với phần của huy chương mà
họ đã thắng? $$
\frac{1}{4} \qquad \frac{1}{5} \qquad \frac{1}{6} \qquad \frac{1}{7} \qquad
\frac{1}{8}
$$

Giải pháp của tôi:
Hãy sử dụng sympy để in ra sự khác biệt giữa phần của huy chương mà
Canada đã thắng và từng lựa chọn.

--- TRANG 37 ---
<llm-code>
from sympy import Rational, Abs

# đội Canada thắng 17 trong số 100 huy chương
medal_frac = Rational(17, 100)

# danh sách các lựa chọn
options = [Rational(1, 4), Rational(1, 5), Rational(1, 6), Rational(1, 7),
Rational(1, 8)]

# hãy in ra các sự khác biệt
[Abs(medal_frac - frac_option) for frac_option in options]
</llm-code>
<llm-code-output>
[2/25, 3/100, 1/300, 19/700, 9/200]
</llm-code-output>

Bây giờ hãy kiểm tra sự khác biệt nào là nhỏ nhất.

<llm-code>
import numpy as np

# Tính idx của lựa chọn gần nhất
min_idx = np.argmin([2/25, 3/100, 1/300, 19/700, 9/200])

# In lựa chọn gần nhất
print(options[min_idx])
</llm-code>
<llm-code-output>
1/6
</llm-code-output>

Vậy câu trả lời là \boxed{1/6}.

Câu hỏi:
Một hộp chữ nhật $P$ được nội tiếp trong một hình cầu có bán kính $r$. Diện tích bề mặt
của $P$ là 384, và tổng độ dài của 12 cạnh của nó là 112. $r$ là bao nhiều?

Giải pháp của tôi:
Cho các kích thước của $P$ là $x$, $y$, và $z$.
Tổng các cạnh của hộp là $4(x + y + z)$ và diện tích bề mặt là $2xy +
2yz + 2xz$.
Đường kính của hình cầu là $2r$ và nó bằng đường chéo của hộp.
Bây giờ hãy viết các phương trình dựa trên thông tin trên và giải
chúng bằng sympy.

<llm-code>
from sympy import symbols, Eq, solve

# định nghĩa các biến
x, y, z, r = symbols('x y z r')

# phương trình dựa trên thông tin đã cho
eq1 = Eq(2 * (x*y + x*z + y*z), 384)
eq2 = Eq(4 * (x + y + z), 112)

# đường chéo của hộp là đường kính của hình cầu
diagonal_eq = Eq(x**2 + y**2 + z**2, (2*r)**2)

# giải các phương trình
solutions = solve((eq1, eq2, diagonal_eq), (x, y, z, r))

# hãy xem chúng ta có được những giá trị r nào

--- TRANG 38 ---
[solution[-1] for solution in solutions]
</llm-code>
<llm-code-output>
[-10, -10, 10, 10]
</llm-code-output>

Vì bán kính của hình cầu là dương, chúng ta có $r = \boxed{10}$.

Câu hỏi:
Một con ong bắt đầu bay từ điểm $P_0$. Cô ấy bay $1$ inch về phía đông đến điểm
$P_1$. Với $j \ge 1$, một khi con ong đến điểm $P_j$, cô ấy quay $30^{\circ
}$ ngược chiều kim đồng hồ và sau đó bay $j+1$ inch thẳng đến điểm $P_{j+1}$.
Khi con ong đến $P_{2015},$ cô ấy cách $P_0$ bao xa, tính bằng inch?

Giải pháp của tôi:
Chúng ta có thể biểu diễn hành động quay thông qua $\omega = e^{\pi i/6}$.
Hãy giả sử con ong bắt đầu tại gốc tọa độ, vậy $P_{2015}$ ở điểm \[z
= 1 + 2 \omega + 3 \omega^2 + 4 \omega^3 + \dots + 2015 \omega^{2014}.\]
Đây là một chuỗi số học-hình học mà chúng ta có thể giải bằng cách đơn giản hóa
biểu thức.

Một cách khác, chúng ta có thể giải cho |z| bằng sympy sử dụng code sau.

<llm-code>
from sympy import I, pi, exp, sqrt

# hành động quay 30 độ
omega = exp(I * pi/6)

position = 0
for i in range(2015):
    delta = (i + 1) * omega**(i)
    position += delta

real, img = (position.as_real_imag())

# Khoảng cách từ gốc tọa độ tức là điểm bắt đầu
dist = sqrt(real**2 + img**2)
print(dist)
</llm-code>
<llm-code-output>
sqrt(2)*(1008 + 1008*sqrt(3))
</llm-code-output>

Vậy con ong cách $\boxed{1008\sqrt{2} + 1008\sqrt{6}}$ từ điểm bắt đầu.

Câu hỏi:
Nếu $f (x) = x^2 - 1$, giá trị của $f (-1)$ là bao nhiều?

Giải pháp của tôi:

# 2402.16352.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2402.16352.pdf
# Kích thước tệp: 597650 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
MathGenie: Tạo Dữ liệu Tổng hợp với Dịch ngược Câu hỏi để
Tăng cường Khả năng Lý luận Toán học của LLMs
Zimu Lu∗1, Aojun Zhou∗1, Houxing Ren1, Ke Wang1, Weikang Shi1
Junting Pan1,3,Mingjie Zhan†1,Hongsheng Li†1,2,3
1Phòng thí nghiệm Đa phương tiện (MMLab), Đại học Trung văn Hồng Kông
2Phòng thí nghiệm Trí tuệ nhân tạo Thượng Hải3CPII thuộc InnoHK
luzimu@mail.ustc.edu.cn {aojunzhou, zmjdll}@gmail.com
hsli@ee.cuhk.edu.hk
Tóm tắt
Các mô hình ngôn ngữ lớn (LLMs) đã thể hiện
tiềm năng lớn trong lý luận toán học.
Tuy nhiên, vẫn tồn tại khoảng cách hiệu suất trong
lĩnh vực này giữa các mô hình mã nguồn mở hiện
có và các mô hình mã nguồn đóng như GPT-4. Trong
bài báo này, chúng tôi giới thiệu MathGenie, một
phương pháp mới để tạo ra các bài toán toán học
đa dạng và đáng tin cậy từ một tập dữ liệu
bài toán-lời giải quy mô nhỏ (được ký hiệu là dữ liệu
hạt giống). Chúng tôi tăng cường các lời giải chính
xác của dữ liệu hạt giống và huấn luyện một mô hình
dịch ngược để dịch các lời giải đã tăng cường trở lại
thành các câu hỏi mới.
Sau đó, chúng tôi tạo ra các lời giải tích hợp mã
cho các câu hỏi mới. Để đảm bảo tính chính xác của
các lời giải tích hợp mã,
chúng tôi sử dụng chiến lược dựa trên lý luận để
xác minh lời giải. Các mô hình được huấn luyện trước
khác nhau, từ 7B đến 70B, được huấn luyện trên
dữ liệu mới được tuyển chọn để kiểm tra hiệu quả của
kỹ thuật tăng cường được đề xuất, tạo ra
một họ mô hình được gọi là MathGenieLM.
Các mô hình này luôn vượt trội so với các
mô hình mã nguồn mở trước đây trên năm tập dữ liệu
lý luận toán học đại diện, đạt được
hiệu suất tiên tiến nhất. Đặc biệt,
MathGenieLM-InternLM2 đạt được độ chính xác
87.7% trên GSM8K và 55.7% trên
MATH, đảm bảo điểm số tổng thể tốt nhất trong số
các mô hình ngôn ngữ mã nguồn mở.
1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLMs), như GPT-
4 (OpenAI, 2023), và các mô hình khác (Touvron et al., 2023;
Yue et al., 2023; Gou et al., 2023; Wang et al.,
2023), đã thể hiện khả năng xuất sắc
trong lý luận toán học. Các phương pháp hiện có đã
khám phá ba loại định dạng lời giải chính để giải
quyết vấn đề giải toán: lời giải Chuỗi Suy nghĩ (CoT)
chỉ có văn bản (Wei et al., 2022), lời giải Chương trình
Suy nghĩ (PoT) chỉ có mã (Chen
∗Đóng góp bằng nhau†Tác giả liên hệet al., 2022), và lời giải tích hợp mã (Zhou
et al., 2023). Trong số này, lời giải tích hợp mã
thể hiện hiệu suất vượt trội so với cả lời giải
CoT và PoT (Gou et al., 2023; Wang
et al., 2023; Zhou et al., 2023), cho thấy hiệu quả
của chúng trong việc tăng cường khả năng giải quyết vấn đề.
Trong bài báo này, chúng tôi tập trung vào việc tạo ra các
câu hỏi tăng cường đa dạng và đáng tin cậy và đảm bảo tính tin cậy
của các lời giải tích hợp mã được tạo ra,
từ đó tinh chỉnh tốt hơn các mô hình cơ sở được huấn luyện trước.
Các nghiên cứu hiện có, như ToRA (Gou et al., 2023)
và MathCoder (Wang et al., 2023), xây dựng lời giải
tích hợp mã và tăng cường các câu hỏi toán bằng cách sử dụng
GPT-4 có sẵn. Tuy nhiên, việc mở rộng quy mô
dữ liệu huấn luyện với GPT-4 trở nên cực kỳ
đắt đỏ.
Do đó, việc phát triển một mô hình mã nguồn mở
miễn phí để tạo ra dữ liệu tổng hợp quy mô lớn
đưa ra một giải pháp thay thế đầy hứa hẹn, cung cấp
khả năng mở rộng và hiệu quả về chi phí (Yuan et al., 2023;
Singh et al., 2023). Để mở rộng quy mô hiệu quả dữ liệu
giải toán, chúng tôi tập trung vào việc xử lý hai
thách thức quan trọng: (1) làm thế nào để tạo ra các bài toán toán
chất lượng cao và đa dạng để hỗ trợ tổng quát hóa, và (2) làm thế nào để tạo ra các lời giải
chính xác và đáng tin cậy cho các bài toán tăng cường mà
không có sự thật cơ sở được chú thích bởi con người, tốt nhất là trong
định dạng tích hợp mã. Một khung thống nhất,
MathGenie, được đề xuất, bao gồm ba
thành phần như được hiển thị trong Hình 1 để giải quyết các
thách thức đã đề cập ở trên: Tăng cường Lời giải Lặp lại,
Dịch ngược Câu hỏi và Lọc Lời giải
Dựa trên Xác minh.
Tăng cường Lời giải Lặp lại và Dịch ngược
Câu hỏi nhằm tạo ra các bài toán toán đa dạng và tin cậy. Khác với việc tăng cường câu hỏi trực tiếp (Yu et al., 2023), việc dịch ngược bài toán toán được đề xuất
tận dụng các ràng buộc và mối quan hệ logic vốn có trong các lời giải toán học để tạo ra một tập hợp
các bài toán toán mới đa dạng và chất lượng cao. Cụ thể, chúng tôi lặp lạiarXiv:2402.16352v2  [cs.CL]  11 Sep 2024

--- TRANG 2 ---
Lọc Dựa trên Xác minh
…
Bước 3: Lọc Lời giải Dựa trên Xác minhBước 1: Tăng cường Lời giải Lặp lại
Mô hình Tăng cường Lời giải 
(𝑀𝑡𝑒𝑥𝑡)
Lời giải Hạt giống (𝑆0) Lời giải 1 (𝑆1) Lời giải 2 (𝑆2) Lời giải K (𝑆𝐾)
Mô hình Dịch ngược 
(𝑀𝑏𝑎𝑐𝑘𝑡𝑟𝑎𝑛𝑠)Lời giải Tăng cường (𝑆𝐴𝑢𝑔)Câu hỏi Tăng cường (𝑄𝐴𝑢𝑔)
Mô hình Tạo và 
Xác minh Lời giải (𝑀𝑐𝑜𝑑𝑒)Câu hỏi Tăng cường (𝑄𝐴𝑢𝑔)Câu hỏi Tăng cường và Lời giải 
Tích hợp Mã (𝑄𝐴𝑢𝑔,𝑆𝑐𝑜𝑑𝑒𝐴𝑢𝑔)Câu hỏi Tăng cường đã Lọc và 
Lời giải Tích hợp Mã (𝑄𝐴𝑢𝑔,𝑆𝑐𝑜𝑑𝑒𝐴𝑢𝑔)Xác minh
Tăng cường Lời giải Lặp lại
Dịch ngược Câu hỏiBước 2: Dịch ngược Câu hỏi
Tạo Lời giải Tích hợp Mã
Hình 1: Khung của MathGenie. Tăng cường Lời giải Lặp lại tăng cường các lời giải được chú thích bởi con người trong
GSM8K và MATH để tạo ra các lời giải mới, như được hiển thị trong Bước 1. Các lời giải này sau đó được dịch ngược thành các
câu hỏi mới bằng cách sử dụng Dịch ngược Câu hỏi, được thể hiện trong Bước 2. Sau đó các lời giải tích hợp mã đáng tin cậy được
tuyển chọn bằng cách sử dụng Lọc Lời giải Dựa trên Xác minh, bằng cách tạo ra các lời giải và lọc chúng bằng cách sử dụng các
lý luận xác minh, như được hiển thị trong Bước 3.

tăng cường các lời giải được chú thích bởi con người từ
các tập huấn luyện tương đối nhỏ của MATH (Hendrycks
et al., 2021) và GSM8K (Cobbe et al., 2021),
tạo ra một bộ sưu tập quy mô lớn các lời giải
tăng cường mới, như được hiển thị trong Bước 1 của Hình 1.
Các lời giải này sau đó được xử lý bởi một mô hình dịch ngược toán,
Mbacktrans, để dịch ngược các lời giải
tăng cường thành các câu hỏi toán tương ứng của chúng, như được thể hiện trong Bước 2 của Hình 1. Phương pháp này lấy cảm hứng từ Dịch ngược
Hướng dẫn (Li et al., 2023b), dịch ngược các
hướng dẫn từ các văn bản trong kho văn bản web. Tuy nhiên,
sự khác biệt chính là các lời giải nguồn của chúng tôi cho
dịch ngược được tăng cường từ những lời giải hiện có
để đảm bảo tính tin cậy và khả năng giải được của các
câu hỏi tăng cường.
Các bài toán toán mới được tạo ra này thiếu các
lời giải chính xác đáng tin cậy, điều này đòi hỏi
Lọc Lời giải Dựa trên Xác minh được đề xuất.
Chúng tôi đầu tiên xây dựng một mô hình, Mcode, có khả năng tạo ra các lời giải tích hợp mã và xác minh các lời giải này. Sau đó, các lời giải tích hợp mã của các
câu hỏi mới được tạo ra với mô hình này. Để tăng cường tính tin cậy của các lời giải tích hợp mã này, chúng tôi sử dụng Mcode để xác minh các lời giải được tạo ra bởi mô hình bằng cách tạo ra các lý luận xác minh cho
chúng, như được thể hiện trong Bước 3 của Hình 1. Các lý luận xác minh sử dụng ngôn ngữ tự nhiên và mã xen kẽ để xác minh tính chính xác của các lời giải, như được hiển thị trong Bảng 13 và Bảng 14 trong Phụ lục G.
Chỉ những lời giải được xác minh là chính xác mới được
giữ lại, do đó cải thiện độ chính xác và chất lượng của
dữ liệu được tạo ra.
Dựa trên khung MathGenie được đề xuất,
chúng tôi thu được một tập dữ liệu bài toán-lời giải toán được tạo ra bởi mô hình quy mô lớn, MathGenieData, có
các câu hỏi tăng cường đa dạng và các lời giải tích hợp mã đáng tin cậy.
Để đánh giá hiệu quả của khung tăng cường
câu hỏi-lời giải MathGenie, chúng tôi
tinh chỉnh các mô hình được huấn luyện trước tiên tiến khác nhau,
từ 7B đến 70B. Điều này dẫn đến Math-
GenieLM, một họ mô hình toán mới với
hiệu suất xuất sắc. Các mô hình của chúng tôi thể hiện
độ chính xác cao trên năm tập dữ liệu toán đa dạng và đại diện: MATH, GSM8K, SVAMP, Simuleq,
và Mathematics. Đặc biệt, MathGenieLM-
InternLM2 đạt được độ chính xác 87.7% trên
GSM8K và 55.7% trên MATH, đạt được điểm số
tổng thể tốt nhất. Khi được tăng cường bởi biểu quyết đa số,
MathGenieLM-Llama-2-70B đạt được tỷ lệ độ chính xác
10 đường dẫn là 91.7% trên GSM8K và 63.3% trên
MATH.
Các đóng góp chính của bài báo này được
tóm tắt như sau: (1) Chúng tôi đề xuất đường ống Math-
Genie, được thiết kế để tăng cường quy mô, tính đa dạng và chất lượng của các câu hỏi toán
tổng hợp, cũng như cải thiện độ chính xác của

--- TRANG 3 ---
Câu hỏi Hạt giống: Cửa hàng yêu thích của Ann đang có
một đợt giảm giá mùa hè. Với $75 cô ấy đã mua 5 chiếc
quần short với giá $7 mỗi chiếc và 2 đôi giày với giá $10
mỗi đôi. Cô ấy cũng mua 4 chiếc áo, tất cả cùng giá.
Mỗi chiếc áo có giá bao nhiêu?Lời giải Hạt giống: Cô ấy đã mua 5 chiếc quần short với giá $7 mỗi chiếc nên 5*7=$35. Cô ấy
đã mua 2 đôi giày với giá $10 mỗi đôi nên 2*10=$20. Quần short và
giày đã tiêu tốn của cô ấy 35+20 = $55. Chúng ta biết cô ấy đã chi tổng cộng 75 và
quần short và giày đã tiêu tốn $55 để lại một chênh lệch là 75 -55 = $20.
Cô ấy đã mua 4 chiếc áo với tổng cộng $20 nên 20/4 = $5.
#### 5
Giải thích: Ann đã mua 5 món chính với giá $15 mỗi món nên
5*15=75. Cô ấy đã mua 2 món tráng miệng với giá $20 mỗi món nên
2*20=40. Món chính và món tráng miệng đã tiêu tốn của cô ấy
75+40=115. Điều này là không thể, vì chúng ta biết cô ấy
đã chi tổng cộng $75, ít hơn 115.
Vậy bài toán mới không có đáp án.
√ⅹMột cặp câu hỏi và lời giải hạt giống
Tăng cường Câu hỏi
Trực tiếpTăng cường Lời giải
Lặp lại
Dịch ngược
Câu hỏiLời giải Tăng cường: Cô ấy đã mua 5 quả chuối với giá $1 mỗi quả nên
5*1=$5. Cô ấy đã mua 2 quả cam với giá $2 mỗi quả nên 2*2=$4. Chuối
và cam đã tiêu tốn của cô ấy 5+4 = $9. Chúng ta biết cô ấy đã chi tổng cộng 10
và chuối và cam đã tiêu tốn $9 để lại một chênh lệch là
10 -9 = $1. Cô ấy đã mua 4 quả táo với tổng cộng $1 nên 1/4 = $0.25.
#### 0.25Lời giải Tăng cường: Cô ấy đã mua 5 quả chuối với giá $1 mỗi quả nên
5*1=$5. Cô ấy đã mua 2 quả cam với giá $2 mỗi quả nên 2*2=$4. Chuối
và cam đã tiêu tốn của cô ấy 5+4 = $9. Chúng ta biết cô ấy đã chi tổng cộng 10
và chuối và cam đã tiêu tốn $9 để lại một chênh lệch là
10 -9 = $1. Cô ấy đã mua 4 quả táo với tổng cộng $1 nên 1/4 = $0.25.
#### 0.25Lời giải Tăng cường: Cô ấy đã mua 5 quả chuối với giá $1 mỗi quả nên
5*1=$5. Cô ấy đã mua 2 quả cam với giá $2 mỗi quả nên 2*2=$4. Chuối
và cam đã tiêu tốn của cô ấy 5+4 = $9. Chúng ta biết cô ấy đã chi tổng cộng 10
và chuối và cam đã tiêu tốn $9 để lại một chênh lệch là
10 -9 = $1. Cô ấy đã mua 4 quả táo với tổng cộng $1 nên 1/4 = $0.25.
#### 0.25×𝑲
Câu hỏi Tăng cường: Jillian đã mua 5 quả chuối, 2
quả cam, và 4 quả táo. Cô ấy đã chi tổng cộng $10. Nếu
chuối có giá $1 mỗi quả và cam có giá $2 mỗi quả, Jillian
chi bao nhiêu cho mỗi quả táo?Câu hỏi Tăng cường: Jillian đã mua 5 quả chuối, 2
quả cam, và 4 quả táo. Cô ấy đã chi tổng cộng $10. Nếu
chuối có giá $1 mỗi quả và cam có giá $2 mỗi quả, Jillian
chi bao nhiêu cho mỗi quả táo?Câu hỏi Tăng cường: Jillian đã mua 5 quả chuối, 2
quả cam, và 4 quả táo. Cô ấy đã chi tổng cộng $10. Nếu
chuối có giá $1 mỗi quả và cam có giá $2 mỗi quả, Jillian
chi bao nhiêu cho mỗi quả táo?Câu hỏi Tăng cường: Nhà hàng yêu thích của Ann
đang có một đợt giảm giá mùa đông. Với $75
cô ấy đã mua 5 món chính trị giá $15 mỗi món và 2
món tráng miệng trị giá $20 mỗi món. Cô ấy cũng mua 4
món khai vị, tất cả cùng giá. Mỗi món khai vị có giá
bao nhiêu?Hình 2: So sánh giữa Tăng cường Câu hỏi Trực tiếp (trái) và Tăng cường Lời giải Lặp lại và
Dịch ngược Câu hỏi (phải). Tăng cường Câu hỏi Trực tiếp làm hại các ràng buộc ẩn giữa các
điều kiện (chi phí của một phần những thứ được mua không được vượt quá tổng chi phí), do đó tạo ra một câu hỏi không có
đáp án. Dịch ngược Câu hỏi xem xét lời giải, và tăng cường câu hỏi một cách chính xác.

các lời giải tích hợp mã được tạo ra cho chúng. (2)
Chúng tôi tiến hành các thí nghiệm rộng rãi trên các mô hình ngôn ngữ được huấn luyện trước khác nhau, thể hiện hiệu suất
vượt trội một cách nhất quán trên nhiều tập dữ liệu toán.

2 MathGenie
Trong phần này, chúng tôi giới thiệu MathGenie, một đường ống
để tạo ra các bài toán toán đa dạng và đáng tin cậy
thông qua dịch ngược, và tuyển chọn các lời giải tích hợp mã chất lượng cao thông qua xác minh. Chúng tôi
bắt đầu bằng việc giới thiệu dữ liệu hạt giống và mô hình tạo lời giải. Tiếp theo, chúng tôi trình bày đường ống Math-
Genie được đề xuất, bao gồm ba bước chính, như
được hiển thị trong Hình 1: Tăng cường Lời giải Lặp lại,
Dịch ngược Câu hỏi, và Lọc Lời giải Dựa trên Xác minh.

Dữ liệu Hạt giống. Dữ liệu hạt giống bao gồm hai
phần: (1) Phần đầu tiên được sử dụng cho tăng cường dữ liệu, bao gồm 15K bài toán toán và
lời giải được chú thích bởi con người từ các tập huấn luyện
của GSM8K và MATH. Chúng tôi ký hiệu nó là Dtext =
{(qi, si)}n
i=1, trong đó qi là câu hỏi thứ i, si là
lời giải ngôn ngữ tự nhiên của nó, và n là tổng số
trường hợp. (2) Phần thứ hai được sử dụng để huấn luyện mô hình tạo lời giải ứng viên của chúng tôi, phục vụ để tạo ra các lời giải ứng viên cho các câu hỏi tăng cường. Chúng tôi ký hiệu phần này của dữ liệu hạt giống là Dcode ={(qi, si
code, vi
code)}N
i=1, trong đó qi
là câu hỏi, si
code là lời giải tích hợp mã của nó, và vi
code là các lý luận xác minh tích hợp mã cho cặp câu hỏi-lời giải. Nó chứa 80K mẫu lời giải tích hợp mã cho
các bài toán trong GSM8K và MATH, cũng như các lý luận xác minh tích hợp mã cho các lời giải này.
Nhiều lời giải khác nhau được thu thập cho mỗi
câu hỏi. Chúng tôi có được các lời giải và lý luận xác minh này bằng cách sử dụng GPT-4 Code Interpreter,
bao gồm ngôn ngữ tự nhiên và mã xen kẽ.

Bộ Tạo Lời giải Ứng viên. Bộ tạo lời giải ứng viên là một mô hình Llama-2 70B
được huấn luyện với Dcode và được ký hiệu là Mcode. Các lời giải tích hợp mã trong Dcode cho phép Mcode
xuất ra các lời giải tích hợp mã ứng viên cho
các bài toán toán đã cho, tương tự như (Wang et al., 2023).
Nó có độ chính xác 86.4% trên GSM8K và 49.5%
trên MATH. Các lý luận xác minh trong Dcode cho phép Mcode xác minh hiệu quả các lời giải với
các lý luận tích hợp mã. Phương pháp huấn luyện
dữ liệu trong định dạng tích hợp mã được mô tả như trong Wang et al. (2023).

Tăng cường Lời giải Lặp lại. Khác
với các nghiên cứu trước đây tăng cường trực tiếp các câu hỏi toán (Luo et al., 2023), chúng tôi đề xuất tăng cường các lời giải trước tiên rồi sau đó dịch ngược các lời giải tăng cường thành các câu hỏi tương ứng của chúng để ràng buộc tốt hơn quá trình tạo câu hỏi
và tăng cường tính tin cậy của các câu hỏi được tạo ra bởi máy. Chiến lược được đề xuất cũng khác
với phương pháp Dịch ngược Hướng dẫn trước đây (Li et al., 2023b), tận dụng lượng lớn văn bản trong kho văn bản web. Vì các lời giải hiện có
bị hạn chế về số lượng và đã có
các câu hỏi tương ứng, cần thiết phải tăng cường
chúng trước khi dịch ngược.

Để tăng cường các lời giải trong Dtext thành các
lời giải mới có liên quan, chúng tôi phát triển một mô hình tăng cường lời giải, Mtext, bằng cách tinh chỉnh mô hình LLaMA-2 70B
trên các tập dữ liệu hướng dẫn chất lượng cao, bao gồm OpenOrca1 và Alpaca-GPT42. Mtext
nhận vào một lời giải và một lời nhắc hướng dẫn
mô hình tăng cường nó, và xuất ra một lời giải
tăng cường. Các lời nhắc được hiển thị trong Bảng 1. Các
tăng cường được ràng buộc cẩn thận và đáng tin cậy. Chúng tôi tăng cường lặp lại mỗi lời giải trong Dtext.
Để thuận tiện, tập hợp các lời giải được chú thích bởi con người trong Dtext được ký hiệu là S0. Các lời giải trong
S0 được tăng cường bởi Mtext để tạo ra S1. Như được hiển thị
trong Bước 1 của Hình 1, quá trình này được lặp lại trên các
lời giải được tạo ra trước đó, với S2 được tạo ra từ S1, và cứ thế. Sau K vòng, tập hợp cuối cùng
của các lời giải tăng cường, được ký hiệu là SAug, được
tạo ra bằng cách lấy hợp của S1, S2, . . . , SK:
SAug=S1∪ S2∪ ··· ∪ SK. (1)
Thông qua tăng cường lời giải lặp lại, mỗi
vòng tạo ra một tập hợp các lời giải khác biệt với
những lời giải trước đó, làm cho các lời giải dần dần
lệch xa hơn so với các lời giải gốc. Do đó,
tính đa dạng của các lời giải tăng cường được đảm bảo,
dẫn đến các cặp câu hỏi-lời giải tăng cường đa dạng như đã đề cập trong các phần sau. Quá trình lặp lại có lợi cho hiệu suất cuối cùng, như được thể hiện trong Bảng 9 của Phụ lục B

Dịch ngược Câu hỏi. Chúng tôi giới thiệu
Dịch ngược Câu hỏi để dịch các lời giải trong SAug trở lại thành các bài toán toán tương ứng của chúng.
Để tăng cường độ chính xác của việc dịch, chúng tôi xây dựng
một Mô hình Dịch ngược Câu hỏi Mbacktrans bằng cách
tinh chỉnh Llama-2 70B trên các cặp đảo ngược
của câu hỏi và lời giải trong Dtext. Định dạng của mỗi
mẫu trong dữ liệu tinh chỉnh có thể được ký hiệu là
(s, q), trong đó s là một lời giải, phục vụ như đầu vào, và q
là câu hỏi tương ứng của nó. Sau đó, chúng tôi trình bày các
lời giải trong SAug cho Mbacktrans, từ đó dịch
chúng trở lại thành một tập hợp các câu hỏi mới, được ký hiệu là
QAug. Một ví dụ về Dịch ngược Câu hỏi được
trình bày trong Bảng 2.

1https://huggingface.co/datasets/Open-Orca/
OpenOrca
2https://huggingface.co/datasets/vicgalle/
alpaca-gpt4Lời nhắc
Thay thế các đối tượng và động từ trong Lời giải.
Lời giải:
{solution}
Bạn phải thay thế các đối tượng và động từ trong Lời giải bằng các đối tượng và
động từ rất khác với trước đây để tạo ra một lời giải mới.
Thêm một bước phụ vào lời giải để nó phức tạp hơn.
Lời giải:
{solution}
Bạn phải thêm một bước phụ vào Lời giải để tạo ra một lời giải mới.
Thay đổi các số trong Lời giải.
Lời giải:
{solution}
Bạn phải thay đổi các số trong Lời giải để tạo ra một lời giải mới.
Thay thế các số và biến trong Lời giải bằng các biến và số khác
mà bạn chọn ngẫu nhiên.
Lời giải:
{solution}
Bạn phải thay thế các số và biến trong Lời giải bằng các
số và biến khác mà bạn chọn ngẫu nhiên để tạo ra một lời giải mới.
Bảng 1: Các lời nhắc khác nhau cho tăng cường lời giải.
"{solution}" được thay thế bằng lời giải cần được tăng cường.

Đầu vào
Tạo một Bài toán Mới dựa trên Lời giải:
Cho buổi tập luyện bóng đá, Jack cần 3 ngày * 10 quả bóng đá/ngày = 30
quả bóng đá. Thêm các quả bóng đá cho lớp Thể dục, anh ấy cần phải đưa
tổng cộng 30 quả bóng đá + 10 quả bóng đá = 40 quả bóng đá.
Đầu ra
Bài toán Mới: Jack chịu trách nhiệm về phòng thiết bị tại trường của mình.
Anh ấy cần thu thập 10 quả bóng đá cho lớp thể dục và cũng cung cấp 3 ngày
giá trị quả bóng đá cho buổi tập luyện của đội bóng đá. Nếu mỗi buổi tập sử dụng
10 quả bóng đá, Jack cần phải đưa ra bao nhiêu quả bóng đá?
Bảng 2: Một ví dụ về Dịch ngược Câu hỏi được đề xuất. Lời giải được đưa vào mô hình dịch ngược câu hỏi, và mô hình xuất ra câu hỏi tương ứng của nó.

Dịch ngược Câu hỏi hoạt động trên SAug,
ít bất định hơn so với các văn bản từ
kho văn bản web được sử dụng trong Dịch ngược Hướng dẫn (Li
et al., 2023b). Bằng cách tận dụng các ràng buộc được hiển thị
trong các lời giải, có thể tạo ra các câu hỏi mới
đáng tin cậy hơn so với những gì tăng cường câu hỏi trực tiếp
có thể tạo ra, như được xác thực trong các thí nghiệm.

Lọc Lời giải Dựa trên Xác minh. Các
mô hình mã nguồn mở hiện có như MathCoder (Wang
et al., 2023) chỉ có khả năng giải các bài toán toán
nhưng không thể xác minh hiệu quả các lời giải của chúng. Chúng tôi tăng cường khả năng của Mcode để xác minh các
lời giải bằng cách thêm các lý luận xác minh tích hợp mã
vào dữ liệu tinh chỉnh. Các mẫu huấn luyện
của lý luận xác minh trong dữ liệu hạt giống có
định dạng (q, scode, vcode), trong đó q và scode
là một cặp câu hỏi và lời giải tích hợp mã,
và vcode là xác minh tích hợp mã. Các
cặp (q, scode) là đầu vào, trong khi mô hình được
huấn luyện để xuất ra vcode. Theo cách này, mô hình
giải toán cơ sở Mcode có được khả năng xác minh các lời giải của nó với các lý luận được tạo

--- TRANG 4 ---
từ ngôn ngữ tự nhiên và mã xen kẽ. Khả năng này
không chỉ tạo điều kiện cho Lọc Lời giải Dựa trên Xác minh, mà còn có thể đóng một vai trò trong việc tăng cường
độ chính xác suy luận.

Để thực hiện Lọc Lời giải Dựa trên Xác minh
được đề xuất, trước tiên chúng tôi tạo ra các lời giải tích hợp mã
cho mỗi câu hỏi trong QAug. Lọc ban đầu
được thực hiện bằng cách sử dụng tính nhất quán của đáp án (Wang et al.,
2022), loại bỏ một câu hỏi nếu các lời giải của nó đạt được
các đáp án khác nhau. Sau đó chúng tôi trình bày mỗi cặp câu hỏi-
lời giải cho Mcode, nhắc nó xuất ra một
lý luận xác minh tích hợp mã, từ đó
chúng tôi có thể xác định liệu lời giải có được xác minh
là chính xác hay sai. Các ví dụ về quá trình xác minh
được hiển thị trong Phụ lục G. Các lời giải ứng viên
được xác minh là sai sẽ bị loại bỏ.
Quá trình được thể hiện trong Bước 3 của Hình 1.

Đường ống được đề xuất ở trên dẫn đến 170K
mẫu các cặp câu hỏi và lời giải tích hợp mã,
được ký hiệu là AugData. AugData bao
gồm hai phần: 110K mẫu được tăng cường
từ tập dữ liệu GSM8K, được ký hiệu là AugGSM8K,
và 60K mẫu được tăng cường từ tập dữ liệu MATH
dataset, được ký hiệu là AugMATH. Chúng tôi ký hiệu
dữ liệu hạt giống đã đề cập ở trên để huấn luyện Mcode là
SeedData. Kết hợp SeedData và AugData, chúng tôi
trình bày tập dữ liệu cuối cùng, MathGenieData, có thể
được sử dụng để tinh chỉnh các mô hình được huấn luyện trước khác nhau, như Llama-2 (Touvron et al., 2023) và
CodeLlama (Roziere et al., 2023), tăng cường
khả năng giải quyết vấn đề và kỹ năng xác minh lời giải của chúng. Họ mô hình lý luận toán học
kết quả được đặt tên là MathGenieLM.

3 Thí nghiệm
3.1 Thiết lập Thí nghiệm
Tập dữ liệu. Chúng tôi đánh giá các mô hình của mình trên hai
tập dữ liệu trong miền: GSM8K (Cobbe et al., 2021)
và MATH (Hendrycks et al., 2021), có các tập
huấn luyện được sử dụng để tinh chỉnh. Ngoài ra,
chúng tôi đánh giá các mô hình cuối cùng trên ba tập dữ liệu
ngoài miền: SVAMP (Patel et al., 2021),
Simuleq (Koncel-Kedziorski et al., 2016), và
Mathematics (Davies et al., 2021), để đánh giá
khả năng tổng quát hóa của phương pháp được đề xuất.

Mô hình. Chúng tôi thực hiện tinh chỉnh toàn bộ tham số
trên các mô hình được huấn luyện trước khác nhau, bao gồm Llama-2
7B, 13B, và 70B (Touvron et al., 2023), CodeL-
lama 7B, 13B, và 34B (Roziere et al., 2023),
Llemma 7B và 34B (Azerbayev et al., 2023), Mis-
tral 7B (Jiang et al., 2023), Mixtral-8x7B (Jiang et al., 2024), và InternLM2 20B (Team, 2023).
Chi tiết tinh chỉnh được mô tả trong Phụ lục E.

Các phương pháp so sánh. Chúng tôi so sánh Math-
GenieLM với các mô hình mã nguồn đóng như
ChatGPT-3.5 (Brown et al., 2020), GPT-4 (OpenAI,
2023), và PaLM-2 (Anil et al., 2023), cũng như
các mô hình mã nguồn mở như Mammoth (Yue et al.,
2023), MathCoder (Wang et al., 2023), ToRA (Gou
et al., 2023), và WizardMath (Luo et al., 2023).

3.2 Kết quả Chính
Bảng 3 hiển thị độ chính xác của MathGenieLM trên
năm tập dữ liệu. Dựa trên kết quả, chúng tôi đưa ra các
quan sát sau: (1) Đối với các mô hình mã nguồn mở
có tham số từ 7B đến 70B, MathGe-
nieLM đạt được hiệu suất tiên tiến nhất. (2)
MathGenieLM thể hiện hiệu suất đặc biệt cao
trên ba tập dữ liệu ngoài miền so
với các mô hình mã nguồn mở trước đây, cho thấy
khả năng tổng quát hóa vượt trội của phương pháp của chúng tôi. (3) Độ chính xác của MathGenieLM vượt quá
ChatGPT-3.5 và PaLM-2. Tuy nhiên, vẫn còn
một khoảng cách đáng chú ý khi so sánh với hiệu suất của GPT-4. (4) MathGenieLM-Llemma-34B và
MathGenieLM-InternLM2-20B đạt được hơn 55% độ chính xác trên tập dữ liệu MATH đầy thách thức. Điều này
có thể được quy cho dữ liệu liên quan đến toán chất lượng cao mà chúng đã sử dụng trong huấn luyện trước. (5) Mixtral-8x7B
đạt được hiệu suất xuất sắc, thể hiện
tiềm năng của các mô hình Mixture of Experts (MoE). Các
kết quả trong Bảng 3 đều được thu được bằng cách sử dụng giải mã tham lam.

Ngoài các kết quả thu được với giải mã tham lam, chúng tôi cũng báo cáo kết quả của biểu quyết đa số
sử dụng nhiều đường dẫn được lấy mẫu (Wang et al.,
2022), được tiến hành trên MathGenieLM-Llama-2-70B,
so sánh với ToRA-Llama-2-70B. Kết quả
được hiển thị trong Bảng 4, trong đó "k" đại diện cho số
lời giải được tạo ra cho biểu quyết đa số. Chúng tôi quan sát thấy rằng, với k= 10, biểu quyết đa số
tăng đáng kể độ chính xác trên tất cả
năm tập dữ liệu, mang lại mức tăng trung bình 7.9%.
Cụ thể, tại k= 10, MathGenieLM-Llama-2-
70B đạt được độ chính xác 91.5% trên GSM8K
và 63.3% trên MATH, vượt trội đáng kể so với
ToRA-70B tại k= 50. Điều này thể hiện hiệu suất vượt trội của mô hình chúng tôi.

3.3 Nghiên cứu Loại bỏ
Sau đây là một số nghiên cứu loại bỏ. Tất cả việc tinh chỉnh trong các nghiên cứu loại bỏ đã được tiến hành
sử dụng Mistral-7B làm mô hình cơ sở.

--- TRANG 5 ---
Mô hình Cơ sở Kích thướcTrong Miền Ngoài Miền
GSM8K MATH SVAMP Simuleq Mathematics Trung bình
Mô hình Mã nguồn Đóng
ChatGPT-3.5 - - 80.8 35.5 83.0 - - -
GPT-4 - - 92.0 42.5 97.0 - - -
GPT-4 Code - - 97.0 69.7 - - - -
PaLM-2 - - 80.7 34.3 - - - -
Mô hình Mã nguồn Mở
Mammoth CodeLlama 7B 59.4 33.4 71.4 45.9 55.4 53.1
MathCoder CodeLlama 7B 67.8 30.2 70.7 49.6 55.8 54.8
ToRA CodeLlama 7B 72.6 44.6 70.4 36.0 68.1 58.3
MathGenieLM CodeLlama 7B 71.5 39.7 80.2 69.1 69.5 66.0
Mammoth Llama-2 7B 53.6 31.5 67.7 41.2 46.3 48.1
MathCoder Llama-2 7B 64.2 23.3 71.5 47.5 46.9 50.7
ToRA Llama-2 7B 68.8 40.1 68.2 29.2 58.3 52.9
MathGenieLM Llama-2 7B 71.7 33.0 78.5 61.4 65.0 61.9
MathGenieLM Llemma 7B 76.0 48.3 81.3 85.0 76.6 73.4
MathGenieLM Mistral 7B 80.5 45.1 83.3 79.4 71.8 72.0
Mammoth CodeLlama 13B 64.7 36.3 73.7 47.1 61.5 56.7
MathCoder CodeLlama 13B 74.1 35.9 78.0 60.7 62.5 62.2
ToRA CodeLlama 13B 75.8 48.1 75.7 37.9 70.3 61.6
MathGenieLM CodeLlama 13B 78.5 40.3 84.5 76.7 65.7 69.1
Mammoth Llama-2 13B 62.0 34.2 72.4 43.2 49.2 52.2
MathCoder Llama-2 13B 72.6 29.9 76.9 62.3 54.7 59.3
ToRA Llama-2 13B 72.7 43.0 72.9 45.7 62.6 59.4
MathGenieLM Llama-2 13B 80.4 43.8 83.5 78.4 72.7 71.8
Mammoth CodeLlama 34B 72.7 43.6 84.3 51.8 65.4 63.6
MathCoder CodeLlama 34B 81.7 45.2 82.5 65.8 75.9 70.2
ToRA CodeLlama 34B 80.7 50.8 80.5 50.2 77.9 68.0
MathGenieLM CodeLlama 34B 86.2 51.4 86.9 85.8 78.4 77.7
MathGenieLM Llemma 34B 84.1 55.1 87.4 89.3 82.9 79.8
WizardMath Llama-2 70B 81.6 22.7 - - - -
Mammoth Llama-2 70B 76.9 41.8 82.4 51.4 55.6 61.6
MathCoder Llama-2 70B 83.9 45.1 84.9 77.0 74.4 73.1
ToRA Llama-2 70B 84.3 49.7 82.7 73.3 72.6 72.5
MathGenieLM Llama-2 70B 88.4 51.2 87.7 89.1 76.0 78.5
MathGenieLM Mixtral 8x7B 87.0 53.7 88.9 89.9 81.7 80.2
MathGenieLM InternLM2 20B 87.7 55.7 87.3 88.5 85.1 80.9
Bảng 3: Kết quả của MathGenieLM, so sánh với các mô hình mã nguồn mở và mã nguồn đóng khác nhau trên 2 tập dữ liệu
trong miền (GSM8K, MATH), và 3 tập dữ liệu ngoài miền (SVAMP, Simuleq, Mathematics). Kết quả của các
mô hình mã nguồn đóng được lấy từ Yue et al. (2023) và Gou et al. (2023).

Mô hình Cơ sở Biểu quyết k-đường dẫnTrong Miền Ngoài Miền
GSM8K MATH SVAMP Simuleq Mathematics Trung bình
ToRA Llama-2 70B ✓ 50 88.3 56.9 - - - -
MathGenieLM Llama-2 70B ✗ - 88.4 51.2 87.7 89.1 76.0 78.5
MathGenieLM Llama-2 70B ✓ 10 91.7 (+3.3) 63.3 (+12.1) 94.0 (+6.3) 95.9 (+6.8) 87.2 (+11.2) 86.4 (+7.9)
Bảng 4: Kết quả của biểu quyết đa số đơn giản. k-đường dẫn đại diện cho số lượng lời giải được tạo ra cho biểu quyết đa số.

Phân tích các thành phần dữ liệu khác nhau. Chúng tôi
phân tích hiệu ứng của việc thêm và bớt các
phần khác nhau của dữ liệu huấn luyện để quan sát tác động
của mỗi thành phần. Như được hiển thị trong nửa trên
của Bảng 5, khi chỉ thêm AugGSM8K, hiệu suất trên GSM8K, SVAMP, và Simuleq
cải thiện, trong khi việc thêm AugMATH dẫn đến những cải thiện đáng chú ý hơn trong MATH và Mathematics.
Điều này phù hợp với các loại câu hỏi trong mỗi tập dữ liệu: GSM8K, SVAMP, và Simuleq chứa các bài toán từ khối tiểu học với
các phép tính tương đối dễ, trong khi MATH và
Mathematics có các phép tính toán phức tạp hơn. Khi cả AugGSM8K và AugMATH đều được
thêm vào, những cải thiện trong các tập dữ liệu cũng được
tích lũy, cho thấy hiệu quả của
dữ liệu tăng cường của chúng tôi.

Phân tích các lượng dữ liệu tăng cường khác nhau

--- TRANG 6 ---
Dữ liệu Trong Miền Ngoài Miền
Hạt giống Xác minh AugGSM8K AugMATH GSM8K MATH SVAMP Simuleq Mathematics Trung bình
✓ ✗ ✗ ✗ 73.5 41.8 73.1 68.5 66.6 64.7
✓ ✓ ✗ ✗ 74.2 42.2 76.5 71.0 65.5 65.9
✓ ✓ ✓ ✗ 78.2 42.2 84.3 78.8 69.1 70.5
✓ ✓ ✗ ✓ 74.9 43.5 81.6 73.3 73.2 69.3
✓ ✓ ✓ ✓ 80.5 45.1 83.3 79.4 71.8 72.0
Hạt giống + Xác minh 74.2 42.2 76.5 71.0 65.5 65.9
Hạt giống + Xác minh +1
8(AugGSM8K + AugMATH) 75.6 41.6 80.7 75.3 67.7 68.2
Hạt giống + Xác minh +1
4(AugGSM8K + AugMATH) 77.9 42.7 82.6 77.0 67.8 69.6
Hạt giống + Xác minh +1
2(AugGSM8K + AugMATH) 79.2 44.0 82.1 80.2 68.8 70.9
Hạt giống + Xác minh + (AugGSM8K + AugMATH) 80.5 45.1 83.3 79.4 71.8 72.0
Bảng 5: Hiệu ứng của các thành phần dữ liệu khác nhau và lượng dữ liệu tăng cường với Mistral-7B làm mô hình cơ sở.

Dữ liệu GSM8K MATH Trung bình
không có lọc xác minh 79.3 43.8 61.6
có lọc xác minh 80.5 (+1.2) 45.1 (+1.3) 62.8 (+1.2)
Bảng 6: Hiệu ứng của việc sử dụng hoặc không sử dụng các lý luận xác minh tích hợp mã để lọc dữ liệu huấn luyện.

data. Chúng tôi phân tích chất lượng mở rộng của dữ liệu tăng cường mà chúng tôi đã tạo ra bằng cách huấn luyện một mô hình với
{0,1
8,1
4,1
2,1} lần lượng dữ liệu tăng cường.
Kết quả, như được hiển thị trong nửa dưới của Bảng 5
và Hình 3, cho thấy rằng, với sự gia tăng lượng
dữ liệu tăng cường, hiệu suất trên
tất cả năm tập dữ liệu liên tục cải thiện, với rất
ít ngoại lệ. Điều này thể hiện chất lượng mở rộng cao
của dữ liệu của chúng tôi.

Phân tích Lọc Lời giải Dựa trên Xác minh. Chúng tôi phân tích hiệu quả của Lọc Lời giải Dựa trên Xác minh bằng cách sử dụng dữ liệu trước và
sau khi lọc với sự trợ giúp của xác minh để tinh chỉnh mô hình. Như được thể hiện trong Bảng 6, việc tinh chỉnh mô hình với các cặp câu hỏi-lời giải tăng cường
được lọc bởi xác minh dẫn đến những tăng độ chính xác đáng chú ý trong cả GSM8K và MATH, cho thấy chất lượng vượt trội của dữ liệu tăng cường
sau khi lọc và hiệu quả của Lọc Lời giải Dựa trên Xác minh. Phân tích thêm về
khả năng xác minh của Mcode được hiển thị trong Bảng 11 của
Phụ lục D.

So sánh với các phương pháp tăng cường câu hỏi khác. Chúng tôi so sánh phương pháp của mình với
ba phương pháp tăng cường câu hỏi khác: Meta-
Math (Yu et al., 2023), tăng cường câu hỏi trực tiếp
không có lời giải, và tăng cường câu hỏi trực tiếp
có lời giải. Hai phương pháp tăng cường câu hỏi trực tiếp đều sử dụng Mtext làm mô hình tăng cường câu hỏi. Phương pháp trước chỉ trình bày
câu hỏi hạt giống cho mô hình trong quá trình

01
81
41
21
Lượng AugData4050607080Độ chính xác (%)
Hiệu ứng của Các Lượng AugData Khác nhau
GSM8K
Math
SVAMP
SimulEq
Mathematics
Trung bìnhHình 3: Hiệu suất của mô hình Mistral 7B được tinh chỉnh với {0,1
8,1
4,1
2,1} lần lượng
dữ liệu tăng cường.

tăng cường câu hỏi, trong khi phương pháp sau trình bày cả câu hỏi và lời giải của nó. Kết quả, như được hiển thị
trong Bảng 7, cho thấy phương pháp dịch ngược từ lời giải tăng cường sang câu hỏi của chúng tôi mang lại hiệu suất tốt hơn so với các phương pháp tăng cường hiện có.

3.4 Độ chính xác của Suy luận Đã xác minh
Các mô hình của chúng tôi có khả năng xác minh các lời giải của chính chúng khi được trình bày với các lời nhắc như được hiển thị trong
Bảng 10. Điều này đại diện cho một khả năng lý luận toán học có thể được áp dụng trong quá trình suy luận.

Một cách đơn giản để làm điều này là xác minh các lời giải được tạo ra và giải lại bài toán nếu lời giải được xác minh là không chính xác. Chúng tôi giới hạn số lần xác minh thành hai lần. Như được hiển thị
trong Bảng 8, việc áp dụng xác minh hai lần liên tục
tăng cường độ chính xác trên tất cả năm tập dữ liệu, với những cải thiện đáng chú ý trong các tập dữ liệu MATH và Mathematics. Tạo ra trung bình (N ×) được trình bày
trong Bảng 8 đo lường chi phí của suy luận đã xác minh,
là 2.3 × trung bình. Khi so sánh với 3-

--- TRANG 7 ---
Phương pháp TăngcườngTrong Miền Ngoài Miền
GSM8K MATH SVAMP Simuleq Mathematics Trung bình
MetaMath 79.5 44.6 78.4 79.6 67.9 70.0
Tăng cường câu hỏi trực tiếp (không có lời giải) 78.8 43.0 84.0 77.0 70.2 70.6
Tăng cường câu hỏi trực tiếp (có lời giải) 79.2 44.2 83.6 72.0 68.6 69.5
MathGenie (của chúng tôi) 80.5 45.1 83.3 79.4 71.8 72.0
Bảng 7: So sánh các phương pháp tăng cường câu hỏi khác nhau. Tăng cường câu hỏi trực tiếp (không có lời giải)
trình bày Mtext với chỉ các câu hỏi hạt giống để tạo ra câu hỏi mới. Tăng cường câu hỏi trực tiếp (có lời giải)
trình bày Mtext với các cặp câu hỏi-lời giải để tạo ra câu hỏi mới.

Trong Miền Ngoài Miền
GSM8K MATH SVAMP Simuleq Mathematics Trung bình
Độ chính xác Cơ sở 88.4 51.2 87.7 89.1 76.0 78.5
N× 1× 1× 1× 1× 1× 1×
Độ chính xác Xác minh (hai lần) 88.6 55.8 88.7 91.2 81.1 81.1
N× 2.1× 2.8× 2.1× 2.1× 2.3× 2.3×
Độ chính xác Biểu quyết (3-đường dẫn) 88.6 53.8 92.0 90.9 81.5 81.4
N× 3× 3× 3× 3× 3× 3×
Bảng 8: Kết quả của MathGenieLM-Llama-2-70B sử dụng suy luận đã xác minh. Xác minh (hai lần) có nghĩa là, khi kiểm tra
mô hình, các lời giải được xác minh và những lời giải được xác minh là không chính xác sẽ được giải lại. Quá trình này được lặp lại hai lần.
Mỗi lần xác minh hoặc lời giải được tính là 1 lần tạo ra, và N × là số lần tạo ra trung bình của mỗi câu hỏi.

path majority voting, suy luận đã xác minh đạt được
độ chính xác gần như giống hệt nhưng với chi phí giảm đáng kể. Kết quả của nhiều vòng xác minh hơn được phân tích trong Bảng 12 của Phụ lục F.

4 Công trình Liên quan
Mô hình Ngôn ngữ Lớn cho Lý luận Toán học. LLMs đã thể hiện hiệu suất đáng kể
trong các nhiệm vụ lý luận toán học.
CoT (Wei et al., 2022) tăng cường khả năng của LLMs cho lý luận đa bước. Self-Consistency (Wang
et al., 2022) chọn đáp án cuối cùng thông qua biểu quyết đa số. CSV (Zhou et al., 2023) giới thiệu tự xác minh dựa trên mã. Các nỗ lực nghiên cứu khác tập trung vào huấn luyện trước hoặc tinh chỉnh LLMs, từ đó tạo ra các LLMs chuyên biệt về toán, như Llemma (Azer-
bayev et al., 2023), WizardMath (Luo et al., 2023),
Mammoth (Yue et al., 2023), ToRA (Gou et al.,
2023), và MathCoder (Wang et al., 2023). Cần lưu ý rằng các mô hình tích hợp mã (Wang et al.,
2023; Gou et al., 2023) đã thể hiện khả năng vượt trội so với các mô hình kiểu CoT. Bài báo này phát triển các bài toán và lời giải toán tổng hợp bằng cách sử dụng các mô hình miễn phí để tăng cường lý luận toán học.

Tập dữ liệu Tuân theo Hướng dẫn cho LLMs. Các nghiên cứu gần đây (Taori et al., 2023; Peng et al., 2023;
Mukherjee et al., 2023; Li et al., 2023b) đã bắt đầu sử dụng các hướng dẫn tổng hợp được tạo ra bởi LLMs, như GPT-4 hoặc GPT-3.5, để chưng cất vào các mô hình nhỏ hơn. WizardLM (Xu et al., 2023) đề xuất các hướng dẫn phức tạp để làm phong phú dữ liệu hạt giống cho các mô hình chat tổng quát. Tuy nhiên, bài báo này tập trung vào tăng cường bài toán toán, đặc biệt cho các mô hình chuyên biệt về toán tích hợp mã.

Tăng cường Dữ liệu cho Lý luận Toán học. Để mở rộng số lượng bài toán toán,
các nghiên cứu khác nhau (Yu et al., 2023; Liu and Yao, 2024;
Li et al., 2023a) tăng cường trực tiếp các bài toán hiện có. Khác với các phương pháp này, phương pháp của chúng tôi sử dụng thông tin trong các lời giải thông qua dịch ngược câu hỏi toán, từ đó tăng cường tính tin cậy của các câu hỏi tăng cường. Chúng tôi cũng tạo ra các lời giải tích hợp mã cho các câu hỏi và sử dụng lý luận xác minh để lọc các lời giải.

5 Kết luận
Trong bài báo này, chúng tôi đề xuất một đường ống phối hợp
bao gồm Tăng cường Lời giải Lặp lại và
Dịch ngược Câu hỏi để tạo ra các câu hỏi toán tổng hợp quy mô lớn, và Lọc Lời giải Dựa trên Xác minh để lọc các lời giải tích hợp mã được tạo ra. Kết hợp, ba thành phần này hiệu quả tạo ra các câu hỏi mới và đảm bảo tính tin cậy của các lời giải tích hợp mã tương ứng. Các thí nghiệm cho thấy MathGenieLM
đạt được hiệu suất vượt trội trên năm điểm chuẩn giải toán

--- TRANG 8 ---
toán và trên sáu mô hình cơ sở được huấn luyện trước khác nhau, cung cấp thông tin chi tiết về việc phát triển các mô hình giải toán và mang lại hy vọng cho việc mở rộng sang các nhiệm vụ lý luận khác.

Hạn chế
Phương pháp của chúng tôi đòi hỏi tài nguyên GPU đáng kể,
bao gồm việc tinh chỉnh toàn bộ tham số của các mô hình ngôn ngữ lớn với tối đa 70B tham số. Do đó, việc các nghiên cứu tương lai khám phá các cách để giảm tài nguyên yêu cầu là rất quan trọng. Một hạn chế khác là các mô hình của chúng tôi không thể xử lý hình ảnh làm đầu vào, và do đó thiếu khả năng giải quyết các bài toán liên quan đến hình ảnh, như đã thảo luận trong (Lu et al.,
2023). Ngoài ra, các mô hình của chúng tôi bị hạn chế bởi độ dài ngữ cảnh giới hạn, đã được tinh chỉnh với độ dài ngữ cảnh là 4096. Những hạn chế này là đáng kể và xứng đáng được điều tra thêm.

Tuyên bố Đạo đức
Công trình của chúng tôi, bằng cách tăng cường khả năng toán học của các mô hình ngôn ngữ, có thể đóng góp tích cực cho sự nghiệp giáo dục toán. Tuy nhiên, các mô hình của chúng tôi có thể xuất ra các ảo giác không đúng sự thật, giống như bất kỳ mô hình ngôn ngữ nào. Chúng tôi đã sử dụng các mô hình mã nguồn mở khác nhau như LLaMA-2, CodeLLaMA, Mistral, và Mixtral-8x7B, cũng như phần mềm mã nguồn mở như Hugging Face và PyTorch. Chúng tôi tuân thủ các chính sách và giấy phép của những tài nguyên này và thừa nhận vai trò mà chúng đã đóng trong công việc của chúng tôi.

Lời cám ơn
Dự án này được tài trợ một phần bởi Chương trình R&D Chính quốc gia Trung Quốc Dự án 2022ZD0161100, bởi Trung tâm Trí tuệ Cảm nhận và Tương tác (CPII) Ltd thuộc Ủy ban Đổi mới và Công nghệ (ITC) InnoHK, bởi Quỹ Nghiên cứu Tổng quát của Hồng Kông RGC Dự án 14204021. Hong-
sheng Li là PI của CPII thuộc InnoHK.

Tài liệu tham khảo
Rohan Anil, Andrew M Dai, Orhan Firat, Melvin John-
son, Dmitry Lepikhin, Alexandre Passos, Siamak
Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
Chen, et al. 2023. Palm 2 technical report. arXiv
preprint arXiv:2305.10403 .

Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster,
Marco Dos Santos, Stephen McAleer, Albert Q Jiang,
Jia Deng, Stella Biderman, and Sean Welleck. 2023. Llemma: An open language model for mathematics.
arXiv preprint arXiv:2310.10631 .

Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020. Language models are few-shot
learners. Advances in neural information processing
systems , 33:1877–1901.

Wenhu Chen, Xueguang Ma, Xinyi Wang, and
William W Cohen. 2022. Program of thoughts
prompting: Disentangling computation from reason-
ing for numerical reasoning tasks. arXiv preprint
arXiv:2211.12588 .

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, et al. 2021. Training verifiers to solve math
word problems. arXiv preprint arXiv:2110.14168 .

Alex Davies, Petar Velickovic, Lars Buesing, Sam
Blackwell, Daniel Zheng, Nenad Tomašev, Richard
Tanburn, Peter W. Battaglia, Charles Blundell, An-
drás Juhász, Marc Lackenby, Geordie Williamson,
Demis Hassabis, and Pushmeet Kohli. 2021. Advanc-
ing mathematics by guiding human intuition with ai.
Nature , 600:70 – 74.

Zhibin Gou, Zhihong Shao, Yeyun Gong, Yujiu Yang,
Minlie Huang, Nan Duan, Weizhu Chen, et al.
2023. Tora: A tool-integrated reasoning agent
for mathematical problem solving. arXiv preprint
arXiv:2309.17452 .

Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul
Arora, Steven Basart, Eric Tang, Dawn Song, and Ja-
cob Steinhardt. 2021. Measuring mathematical prob-
lem solving with the math dataset. arXiv preprint
arXiv:2103.03874 .

Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-
sch, Chris Bamford, Devendra Singh Chaplot, Diego
de las Casas, Florian Bressand, Gianna Lengyel, Guil-
laume Lample, Lucile Saulnier, et al. 2023. Mistral
7b.arXiv preprint arXiv:2310.06825 .

Albert Q Jiang, Alexandre Sablayrolles, Antoine
Roux, Arthur Mensch, Blanche Savary, Chris Bam-
ford, Devendra Singh Chaplot, Diego de las Casas,
Emma Bou Hanna, Florian Bressand, et al. 2024.
Mixtral of experts. arXiv preprint arXiv:2401.04088 .

Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate
Kushman, and Hannaneh Hajishirzi. 2016. Mawps:
A math word problem repository. In North Ameri-
can Chapter of the Association for Computational
Linguistics .

Chengpeng Li, Zheng Yuan, Guanting Dong, Keming
Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, and
Chang Zhou. 2023a. Query and response augmenta-
tion cannot help out-of-domain math reasoning gen-
eralization. arXiv preprint arXiv:2310.05506 .

--- TRANG 9 ---
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke
Zettlemoyer, Omer Levy, Jason Weston, and Mike
Lewis. 2023b. Self-alignment with instruction back-
translation. arXiv preprint arXiv:2308.06259 .

Haoxiong Liu and Andrew Chi-Chih Yao. 2024. Aug-
menting math word problems via iterative question
composing. arXiv preprint arXiv:2401.09003 .

Ilya Loshchilov and Frank Hutter. 2017. Decou-
pled weight decay regularization. arXiv preprint
arXiv:1711.05101 .

Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chun-
yuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-
Wei Chang, Michel Galley, and Jianfeng Gao. 2023.
Mathvista: Evaluating mathematical reasoning of
foundation models in visual contexts. arXiv preprint
arXiv:2310.02255 .

Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-
guang Lou, Chongyang Tao, Xiubo Geng, Qingwei
Lin, Shifeng Chen, and Dongmei Zhang. 2023. Wiz-
ardmath: Empowering mathematical reasoning for
large language models via reinforced evol-instruct.
arXiv preprint arXiv:2308.09583 .

Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawa-
har, Sahaj Agarwal, Hamid Palangi, and Ahmed
Awadallah. 2023. Orca: Progressive learning from
complex explanation traces of gpt-4. arXiv preprint
arXiv:2306.02707 .

OpenAI. 2023. Gpt-4 technical report. ArXiv ,
abs/2303.08774.

Arkil Patel, Satwik Bhattamishra, and Navin Goyal.
2021. Are nlp models really able to solve
simple math word problems? arXiv preprint
arXiv:2103.07191 .

Baolin Peng, Chunyuan Li, Pengcheng He, Michel Gal-
ley, and Jianfeng Gao. 2023. Instruction tuning with
gpt-4. arXiv preprint arXiv:2304.03277 .

Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten
Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,
Jingyu Liu, Tal Remez, Jérémy Rapin, et al. 2023.
Code llama: Open foundation models for code. arXiv
preprint arXiv:2308.12950 .

Avi Singh, John D Co-Reyes, Rishabh Agarwal, Ankesh
Anand, Piyush Patil, Peter J Liu, James Harri-
son, Jaehoon Lee, Kelvin Xu, Aaron Parisi, et al.
2023. Beyond human data: Scaling self-training
for problem-solving with language models. arXiv
preprint arXiv:2312.06585 .

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
Dubois, Xuechen Li, Carlos Guestrin, Percy Liang,
and Tatsunori B. Hashimoto. 2023. Stanford alpaca:
An instruction-following llama model. https://
github.com/tatsu-lab/stanford_alpaca .

InternLM Team. 2023. Internlm: A multilin-
gual language model with progressively enhanced
capabilities. https://github.com/InternLM/
InternLM-techreport .

Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, et al. 2023. Llama 2: Open founda-
tion and fine-tuned chat models. arXiv preprint
arXiv:2307.09288 .

Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun
Luo, Weikang Shi, Renrui Zhang, Linqi Song,
Mingjie Zhan, and Hongsheng Li. 2023. Mathcoder:
Seamless code integration in llms for enhanced math-
ematical reasoning. In International Conference on
Learning Representations .

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,
Ed Chi, Sharan Narang, Aakanksha Chowdhery, and
Denny Zhou. 2022. Self-consistency improves chain
of thought reasoning in language models. arXiv
preprint arXiv:2203.11171 .

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,
et al. 2022. Chain-of-thought prompting elicits rea-
soning in large language models. Advances in Neural
Information Processing Systems , 35:24824–24837.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,
Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin
Jiang. 2023. Wizardlm: Empowering large lan-
guage models to follow complex instructions. arXiv
preprint arXiv:2304.12244 .

Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu,
Zhengying Liu, Yu Zhang, James T Kwok, Zhen-
guo Li, Adrian Weller, and Weiyang Liu. 2023.
Metamath: Bootstrap your own mathematical ques-
tions for large language models. arXiv preprint
arXiv:2309.12284 .

Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting
Dong, Chuanqi Tan, and Chang Zhou. 2023. Scal-
ing relationship on learning mathematical reason-
ing with large language models. arXiv preprint
arXiv:2308.01825 .

Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wen-
hao Huang, Huan Sun, Yu Su, and Wenhu Chen.
2023. Mammoth: Building math generalist models
through hybrid instruction tuning. arXiv preprint
arXiv:2309.05653 .

Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun
Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song,
Mingjie Zhan, and Hongsheng Li. 2023. Solving
challenging math word problems using gpt-4 code
interpreter with code-based self-verification. In Inter-
national Conference on Learning Representations .

--- TRANG 10 ---
A Ví dụ về Tăng cường Lời giải Lặp lại
và Dịch ngược Câu hỏi
Hình 4 (b) cho thấy một ví dụ về ba vòng Tăng cường Lời giải Lặp lại và Dịch ngược Câu hỏi. Lời giải hạt giống được tăng cường lặp lại, và các lời giải tăng cường được dịch ngược thành các câu hỏi mới. So với Hình 4 (a), nơi tăng cường được tiến hành trực tiếp trên câu hỏi, Dịch ngược Lời giải Lặp lại thể hiện sự đa dạng lớn hơn trong cách diễn đạt câu hỏi, vì câu hỏi gốc không được cung cấp trực tiếp cho mô hình.

B Phân tích Tăng cường Lời giải Lặp lại
Để thể hiện hiệu quả tác động của lặp lại trong việc tăng cường chất lượng lời giải, chúng tôi đã tạo ra một số lượng bằng nhau các lời giải tăng cường mà không sử dụng lặp lại, bằng cách tăng cường trực tiếp các lời giải mới từ tập hợp gốc. Như được minh họa trong Bảng 9, kết quả của thí nghiệm được tiến hành mà không có lặp lại trong tăng cường lời giải kém hơn đáng kể so với những kết quả có lặp lại. Điều này nhấn mạnh vai trò có lợi của lặp lại trong tăng cường lời giải, chủ yếu được quy cho tiềm năng của nó trong việc tăng cường tính đa dạng của các lời giải.

C Lời nhắc Xác minh
Bảng 10 trình bày định dạng lời nhắc được sử dụng trong tinh chỉnh và tạo ra các lý luận xác minh tích hợp mã.

D Phân tích Xác minh Tích hợp Mã
Để hiểu lý do đằng sau chất lượng cải thiện của dữ liệu, chúng tôi định lượng khả năng của Mcode để tiến hành xác minh tích hợp mã bằng cách kiểm tra nó trên các lời giải được tạo ra bởi Mcode trên năm tập dữ liệu kiểm tra. Chúng tôi sử dụng các tập dữ liệu kiểm tra này vì chúng chứa sự thật cơ sở, cho phép chúng tôi đánh giá tính chính xác thực sự của các lời giải. Chúng tôi định nghĩa hai chỉ số dưới đây để thể hiện khả năng của Mcode để xác minh các lời giải của nó: Precision và Recall.

Precision =TP
TP+FP
Recall =TP
TP+TN

TP đại diện cho các trường hợp mà xác minh chứng minh lời giải đúng và đáp án của lời giải thực sự chính xác. FP đại diện cho các trường hợp mà xác minh chứng minh lời giải đúng, nhưng đáp án của lời giải thực sự sai. TN đại diện cho các trường hợp mà xác minh chứng minh lời giải sai, nhưng đáp án của lời giải thực sự đúng. Tóm lại, Precision trả lời câu hỏi, "Tỷ lệ các đáp án được xác minh ĐÚNG thực sự chính xác là bao nhiêu?", trong khi Recall trả lời câu hỏi, "Tỷ lệ các đáp án chính xác thực sự được xác minh ĐÚNG là bao nhiêu?". Dựa trên các định nghĩa này, Precision phản ánh độ tin cậy của các lời giải tích hợp mã được giữ lại, trong khi Recall phản ánh hiệu quả của bước lọc.

Bảng 11 cho thấy rằng Precision cao hơn đáng kể so với Accuracy trên tất cả các tập dữ liệu, nhấn mạnh hiệu quả và khả năng tổng quát hóa của xác minh tích hợp mã.

E Chi tiết Tinh chỉnh
Trong công việc này, chúng tôi tinh chỉnh tất cả các mô hình bằng thư viện HuggingFace. Chúng tôi sử dụng bộ lập lịch trọng số cosine với tốc độ học 2e−5, chỉ định 50 bước đầu tiên làm các bước khởi động. Tất cả các mô hình được tối ưu hóa bằng AdamW (Loshchilov and Hutter, 2017) với kích thước batch là 64. Các mô hình 70B và 34B được tinh chỉnh trên 32 GPU NVIDIA A800 80GB. Mistral-8x7B được tinh chỉnh trên 16 GPU NVIDIA A800 80GB, trong khi các mô hình 7B, 13B, và 20B đều được tinh chỉnh trên 8 GPU NVIDIA A800 80GB.

F Phân tích Các Vòng Xác minh trong Suy luận Đã xác minh
Trong suy luận đã xác minh, chúng tôi xác minh các lời giải của các câu hỏi kiểm tra và chỉ giải lại những câu hỏi có lời giải được xác minh là không chính xác. Do đó, số lượng câu hỏi cần giải giảm với mỗi vòng. Về mặt lý thuyết, quá trình này có thể tiếp tục cho đến khi tất cả các câu hỏi có lời giải được xác minh là chính xác. Tuy nhiên, trong thực tế, việc xác minh quá nhiều vòng có thể dẫn đến chi phí bổ sung mà không có bất kỳ cải thiện nào về độ chính xác, vì một số câu hỏi có thể vượt quá khả năng giải quyết vấn đề và xác minh của mô hình. Để xác định sự cân bằng giữa chi phí và độ chính xác, chúng tôi tăng số vòng xác minh lên 9. Kết quả được hiển thị trong Bảng 12. Như có thể thấy, sự gia tăng độ chính xác trung bình trở nên nhỏ sau 2 vòng xác minh.

--- TRANG 11 ---
Trong Miền Ngoài Miền
GSM8K MATH SVAMP Simuleq Mathematics Trung bình
có lặp lại 80.5 45.1 83.3 79.4 71.8 72.0
không có lặp lại 78.7 (-1.8) 45.0 (-0.1) 82.9 (-0.4) 76.1 (-3.3) 70.9 (-0.9) 70.7 (-1.3)
Bảng 9: So sánh giữa có lặp lại hoặc không có lặp lại khi tiến hành tăng cường lời giải. Các mô hình được tinh chỉnh trên Mistral 7B.

Lời nhắc
**Câu hỏi**:
{question}
**Lời giải**:
{solution}
Trên đây là một bài toán và lời giải của nó. Vui lòng sử dụng mã để xác minh lời giải ở trên.
Bảng 10: Lời nhắc được sử dụng cho dịch ngược. {question} được thay thế bằng một câu hỏi toán, trong khi {solution} được thay thế bằng lời giải tích hợp mã của nó.

G Ví dụ về Lý luận Xác minh Tích hợp Mã
Hai ví dụ về lý luận xác minh tích hợp mã được trình bày trong Bảng 13 và Bảng 14. Trong Bảng 13, lời giải được xác minh là chính xác bằng cách sử dụng đáp án để tính toán điều kiện và so sánh nó với điều kiện thực tế. Trong Bảng 14, lời giải được xác minh là không chính xác bằng cách giải câu hỏi thông qua một phương pháp thay thế và so sánh các đáp án.

--- TRANG 12 ---
Chỉ số GSM8K MATH SVAMP Simuleq Mathematics Trung bình
Độ chính xác 86.4 49.5 86.0 88.1 73.6 76.7
Precision 89.3 (+2.9) 64.5 (+15.0) 88.3 (+2.3) 90.8 (+2.7) 79.9 (+3.2) 82.6 (+5.9)
Recall 98.5 94.7 97.4 98.2 97.1 97.2
Bảng 11: Độ chính xác, Precision và Recall của Mcode có và không có xác minh. Độ chính xác là phần trăm lời giải chính xác. Precision là phần trăm lời giải thực sự chính xác trong số các lời giải được xác minh là chính xác. Recall là phần trăm lời giải được xác minh là chính xác trong số các lời giải thực sự chính xác.

GSM8K MATH SVAMP Simuleq Mathematics Trung bình
Độ chính xác Cơ sở 88.4 51.2 87.7 89.1 76.0 78.5
N× 1× 1× 1× 1× 1× 1×
Độ chính xác Xác minh (k=1) 88.4 54.2 88.4 90.9 79.2 80.2
N× 2.0× 2.3× 2.0× 2.0× 2.1× 2.1×
Độ chính xác Xác minh (k=2) 88.6 55.8 88.7 91.2 81.1 81.1
N× 2.1× 2.8× 2.1× 2.1× 2.3× 2.3×
Độ chính xác Xác minh (k=3) 88.6 56.3 88.8 91.2 81.3 81.2
N× 2.1× 3.1× 2.1× 2.1× 2.3× 2.3×
Độ chính xác Xác minh (k=4) 88.6 56.3 89.0 91.4 81.4 81.3
N× 2.1× 3.3× 2.1× 2.1× 2.4× 2.4×
Độ chính xác Xác minh (k=5) 88.6 56.5 88.9 91.4 81.4 81.4
N× 2.1× 3.4× 2.1× 2.1× 2.4× 2.4×
Độ chính xác Xác minh (k=6) 88.6 56.8 88.9 91.4 81.4 81.4
N× 2.1× 3.6× 2.1× 2.1× 2.4× 2.5×
Độ chính xác Xác minh (k=7) 88.6 56.8 88.9 91.4 81.4 81.4
N× 2.1× 3.7× 2.1× 2.1× 2.4× 2.5×
Độ chính xác Xác minh (k=8) 88.6 57.1 88.9 91.4 81.4 81.5
N× 2.1× 3.7× 2.1× 2.1× 2.4× 2.5×
Độ chính xác Xác minh (k=9) 88.6 57.1 88.9 91.4 81.4 81.5
N× 2.1× 3.8× 2.1× 2.1× 2.4× 2.5×
Bảng 12: Kết quả của MathGenieLM-Llama-2-70B với số vòng xác minh khác nhau trong quá trình suy luận. Ở đây, "k" đại diện cho số vòng xác minh tối đa.

--- TRANG 13 ---
Câu hỏi Hạt giống: Trong tháng Tư, người thợ bánh đã bán 453 bánh với giá $12 và 126 bánh nướng với giá $7.
Người thợ bánh đã kiếm được bao nhiêu?
Vòng 1 Câu hỏi: Trong tháng Sáu, họa sĩ đã vẽ 453 ngôi nhà với giá $12 mỗi ngôi và 126
bức tranh với giá $7 mỗi bức. Họa sĩ đã kiếm được bao nhiêu?
Vòng 2 Câu hỏi: Trong tháng Sáu, đầu bếp đã nấu 453 món ăn với giá $12 mỗi món và 126
món tráng miệng với giá $7 mỗi món. Đầu bếp đã kiếm được bao nhiêu?
Vòng 3 Câu hỏi: Trong tháng Sáu, nhà động vật học đã quan sát 453 loài với giá $12 mỗi loài và
126 loài với giá $7 mỗi loài. Nhà động vật học đã kiếm được bao nhiêu?
Lời giải Hạt giống: Người thợ bánh đã bán bánh với giá 453 * 12
= $5436. Và bánh nướng với giá 126 * 7 = $882. Tổng cộng người thợ bánh
đã kiếm được 5436 + 882 = $6318. #### 6318
Vòng 1 Lời giải: Người bán hoa đã bán bó hoa với giá 88
* 8 = $704. Và vòng hoa với giá 98 * 9 = $882. Tổng cộng
người bán hoa đã kiếm được 704 + 882 = $1586. #### 1586
Vòng 2 Lời giải: Đầu bếp đã chuẩn bị súp với giá 20
* 2 = $40. Và bánh quy với giá 40 * 4 = $160. Tổng cộng,
đầu bếp đã kiếm được $200. #### 200
Vòng 3 Lời giải: Nông dân đã thu hoạch trái cây với giá
10 * 3 = $30. Và rau với giá 5 * 5 = $25. Tổng cộng,
nông dân đã kiếm được $55.Câu hỏi Hạt giống: Trong tháng Tư, người thợ bánh đã bán 453
bánh với giá $12 và 126 bánh nướng với giá $7. Người thợ bánh
đã kiếm được bao nhiêu?
Vòng 1 Câu hỏi: Một người bán hoa đang bán bó hoa với giá
$8 và vòng hoa với giá $9. Nếu người bán hoa đã bán 88
bó hoa và 98 vòng hoa, anh ấy đã kiếm được bao nhiêu?
Vòng 2 Câu hỏi: Một đầu bếp đã làm 20 bát súp và 40
bánh quy. Mỗi bát súp có giá $2 và mỗi bánh quy
có giá $4. Đầu bếp đã kiếm được bao nhiêu?
Vòng 3 Câu hỏi: Một nông dân đã thu hoạch 10 rổ
trái cây và 5 rổ rau. Nếu một rổ
trái cây có giá $3 và một rổ rau
có giá $5, nông dân đã được trả bao nhiêu cho
việc thu hoạch của mình?Câu hỏi và Lời giải Hạt giống(a)
(b)Hình 4: Một ví dụ về ba lần lặp lại của (a) Tăng cường Câu hỏi Trực tiếp và (b) Tăng cường Lời giải Lặp lại và Dịch ngược Câu hỏi.

--- TRANG 14 ---
Đầu vào:
**Câu hỏi**:
Biểu diễn 0.54 dưới dạng phân số ở dạng tối giản.
**Lời giải**:
Để biểu diễn số thập phân tuần hoàn 0.54 dưới dạng phân số ở dạng tối giản, chúng ta có thể sử dụng phép biến đổi đại số.
Đặt x = 0.54.
Bước 1: Nhân x với 100 để dịch chuyển dấu thập phân.
......
Do đó, 0.54 có thể được biểu diễn dưới dạng 6/11 ở dạng tối giản.
Trên đây là một bài toán và lời giải của nó. Vui lòng sử dụng mã để xác minh lời giải ở trên.
Đầu ra:
Bây giờ, hãy xác minh đáp án bằng cách chuyển đổi 6/11 trở lại thành số thập phân.
# Chuyển đổi phân số 6/11 thành số thập phân
decimal_value = float(simplified_fraction)
decimal_value
Kết quả:
0.5454545454545454
Biểu diễn thập phân của 6/11 là khoảng 0.5454545454545454, khớp với số thập phân tuần hoàn 0.54
Do đó, đáp án của chúng ta được xác minh và chính xác.
Bảng 13: Một ví dụ về lý luận xác minh tích hợp mã trong đó lời giải được xác minh là chính xác.

--- TRANG 15 ---
Đầu vào:
**Câu hỏi**:
2121₃ - 212₃ bằng bao nhiêu? Biểu diễn đáp án của bạn ở cơ số 3.
**Lời giải**:
Được rồi, hãy giải từng bước.
Để trừ các số này, chúng ta sẽ bắt đầu từ chữ số ngoài cùng bên phải (ít có nghĩa nhất) và di chuyển sang trái, giống như chúng ta làm trong phép trừ cơ số 10.
......
Kết quả của 2121₃ - 212₃ là 2223.
Trên đây là một bài toán và lời giải của nó. Vui lòng sử dụng mã để xác minh lời giải ở trên.
Đầu ra:
Bây giờ, hãy xác minh đáp án của chúng ta bằng cách chuyển đổi cả hai số sang cơ số 10, thực hiện phép trừ, và sau đó chuyển đổi kết quả trở lại cơ số 3 để xem liệu nó có khớp với đáp án của chúng ta hay không.
# Chuyển đổi các số từ cơ số 3 sang cơ số 10
def base3_to_base10(num_str):
    num_str = num_str[::-1]  # đảo ngược chuỗi để xử lý dễ dàng
    base10_value = 0
    for i, digit in enumerate(num_str):
        base10_value += int(digit) * (3 ** i)
......
# Chuyển đổi 2121₃ và 212₃ sang cơ số 10
num1_base10 = base3_to_base10("2121")
num2_base10 = base3_to_base10("212")
# Thực hiện phép trừ ở cơ số 10
result_base10 = num1_base10 - num2_base10
# Chuyển đổi kết quả trở lại cơ số 3
result_base3 = base10_to_base3(result_base10)
result_base3
Kết quả:
1202
Có vẻ như có lỗi trong các phép tính của chúng ta. Kết quả chính xác cho 2121₃ - 212₃ là 1202₃, không phải 2223. Tôi xin lỗi vì sự thiếu sót.
Bảng 14: Một ví dụ về lý luận xác minh tích hợp mã trong đó lời giải được xác minh là sai.

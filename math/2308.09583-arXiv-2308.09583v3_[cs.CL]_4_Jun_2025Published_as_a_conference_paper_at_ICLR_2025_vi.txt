# 2308.09583.pdf
# ÄÆ°á»£c chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/math/2308.09583.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 746674 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
arXiv:2308.09583v3 [cs.CL] 4 Jun 2025ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025
WizardMath: TÄ‚NG CÆ¯á»œNG KHáº¢ NÄ‚NG Láº¬P LUáº¬N TOÃN Há»ŒC
CHO CÃC MÃ” HÃŒNH NGÃ”N NGá»® Lá»šN THÃ”NG QUA Reinforced
Evol-Instruct
Haipeng Luo1âˆ—Qingfeng Sun2âˆ—Can Xu2â€ Pu Zhao2Jianguang Lou2Chongyang Tao2
Xiubo Geng2Qingwei Lin2Shifeng Chen3â€ Yansong Tang1â€ Dongmei Zhang2
1TrÆ°á»ng Sau Ä‘áº¡i há»c Quá»‘c táº¿ ThÃ¢m Quyáº¿n, Äáº¡i há»c Thanh Hoa
2Microsoft Corporation
3Viá»‡n CÃ´ng nghá»‡ TiÃªn tiáº¿n ThÃ¢m Quyáº¿n, Viá»‡n HÃ n lÃ¢m Khoa há»c Trung Quá»‘c
{luohp24@mails., tang.yansong@sz.}tsinghua.edu.cn
{caxu,qins,puzhao,jlou,chotao,xigeng,qlin,dongmeiz}@microsoft.com
{shifeng.chen}@siat.ac.cn

TÃ“M Táº®T
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM), nhÆ° GPT-4, Ä‘Ã£ cho tháº¥y hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ trong cÃ¡c nhiá»‡m vá»¥ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP), bao gá»“m cáº£ láº­p luáº­n toÃ¡n há»c Ä‘áº§y thá»­ thÃ¡ch. Tuy nhiÃªn, háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ hiá»‡n cÃ³ chá»‰ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u internet quy mÃ´ lá»›n vÃ  khÃ´ng cÃ³ tá»‘i Æ°u hÃ³a liÃªn quan Ä‘áº¿n toÃ¡n há»c. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i giá»›i thiá»‡u WizardMath, nÃ¢ng cao kháº£ nÄƒng láº­p luáº­n CoT toÃ¡n há»c cá»§a LLM mÃ  khÃ´ng sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ python bÃªn ngoÃ i, báº±ng cÃ¡ch Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p Reinforcement Learning from Evol-Instruct Feedback (RLEIF) Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i vÃ o lÄ©nh vá»±c toÃ¡n há»c. ThÃ´ng qua cÃ¡c thÃ­ nghiá»‡m rá»™ng rÃ£i trÃªn hai benchmark láº­p luáº­n toÃ¡n há»c, cá»¥ thá»ƒ lÃ  GSM8k vÃ  MATH, chÃºng tÃ´i tiáº¿t lá»™ kháº£ nÄƒng phi thÆ°á»ng cá»§a mÃ´ hÃ¬nh chÃºng tÃ´i. ÄÃ¡ng chÃº Ã½, WizardMath-Mistral 7B vÆ°á»£t trá»™i hÆ¡n cÃ¡c LLM mÃ£ nguá»“n má»Ÿ hÃ ng Ä‘áº§u má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ vá»›i hiá»‡u quáº£ dá»¯ liá»‡u cao hÆ¡n. HÆ¡n ná»¯a, WizardMath 70B tháº­m chÃ­ cÃ²n vÆ°á»£t trá»™i hÆ¡n GPT-3.5-Turbo, Claude 2, Gemini Pro vÃ  GPT-4-early-version. NgoÃ i ra, khÃ¡m phÃ¡ sÆ¡ bá»™ cá»§a chÃºng tÃ´i nháº¥n máº¡nh vai trÃ² then chá»‘t cá»§a tiáº¿n hÃ³a hÆ°á»›ng dáº«n vÃ  giÃ¡m sÃ¡t quÃ¡ trÃ¬nh trong viá»‡c Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t toÃ¡n há»c xuáº¥t sáº¯c. Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng tham kháº£o https://github.com/nlpxucan/WizardLM.

1 GIá»šI THIá»†U
Gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ quy mÃ´ lá»›n (LLM) Ä‘Ã£ thu hÃºt Ä‘Æ°á»£c sá»± chÃº Ã½ Ä‘Ã¡ng ká»ƒ vÃ  trá»Ÿ thÃ nh phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n Ä‘Æ°á»£c Æ°a chuá»™ng cho nhiá»u nhiá»‡m vá»¥ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP), bao gá»“m cuá»™c trÃ² chuyá»‡n miá»n má»Ÿ (Ouyang et al., 2022; OpenAI, 2023; Touvron et al., 2023a), láº­p trÃ¬nh (Chen et al., 2021; Wang et al., 2021; Li et al., 2023b) vÃ  toÃ¡n há»c (Taylor et al., 2022; Lewkowycz et al., 2022; Shao et al., 2024; Yang et al., 2024). Má»™t vÃ­ dá»¥ ná»•i báº­t lÃ  ChatGPT1, Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi OpenAI. MÃ´ hÃ¬nh nÃ y sá»­ dá»¥ng tiá»n huáº¥n luyá»‡n rá»™ng rÃ£i trÃªn dá»¯ liá»‡u internet quy mÃ´ lá»›n vÃ  tinh chá»‰nh thÃªm vá»›i dá»¯ liá»‡u hÆ°á»›ng dáº«n vÃ  phÆ°Æ¡ng phÃ¡p cá»¥ thá»ƒ. Káº¿t quáº£ lÃ , nÃ³ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t zero-shot tiÃªn tiáº¿n trÃªn cÃ¡c benchmark khÃ¡c nhau. Sau Ä‘Ã³, Anthropic, Google, vÃ  Meta cÅ©ng ra máº¯t cÃ¡c sáº£n pháº©m cáº¡nh tranh liÃªn tiáº¿p. ÄÃ¡ng chÃº Ã½, loáº¡t Llama cá»§a Meta (Touvron et al., 2023a;b; Dubey et al., 2024) Ä‘Ã£ khÆ¡i dáº­y má»™t cuá»™c cÃ¡ch máº¡ng mÃ£ nguá»“n má»Ÿ vÃ  nhanh chÃ³ng thu háº¹p khoáº£ng cÃ¡ch vá»›i nhá»¯ng LLM nguá»“n Ä‘Ã³ng Ä‘Ã³. Xu hÆ°á»›ng nÃ y cÅ©ng dáº§n dáº§n kÃ­ch thÃ­ch viá»‡c phÃ¡t hÃ nh Mistral (Jiang et al., 2023), Alpaca (Taori et al., 2023), Vicuna (Chiang et al., 2023), vÃ  WizardLM (Xu et al., 2023), v.v. Tuy nhiÃªn, nhá»¯ng mÃ´ hÃ¬nh má»Ÿ nÃ y váº«n gáº·p khÃ³ khÄƒn vá»›i cÃ¡c tÃ¬nh huá»‘ng Ä‘Ã²i há»i láº­p luáº­n Ä‘á»‹nh lÆ°á»£ng phá»©c táº¡p Ä‘a bÆ°á»›c, cháº³ng háº¡n nhÆ° giáº£i quyáº¿t cÃ¡c thá»­ thÃ¡ch toÃ¡n há»c vÃ  khoa há»c (Ahn et al., 2024; Long et al., 2024).

Chain-of-thought (CoT) (Wei et al., 2022) Ä‘á» xuáº¥t thiáº¿t káº¿ cÃ¡c lá»i nháº¯c tá»‘t hÆ¡n Ä‘á»ƒ táº¡o ra cÃ¡c giáº£i phÃ¡p tá»«ng bÆ°á»›c, cÃ³ thá»ƒ dáº«n Ä‘áº¿n hiá»‡u suáº¥t Ä‘Æ°á»£c cáº£i thiá»‡n. Self-Consistency (Wang et al., 2022)

âˆ—ÄÃ³ng gÃ³p ngang nhau. CÃ´ng viá»‡c Ä‘Æ°á»£c thá»±c hiá»‡n trong thá»i gian thá»±c táº­p cá»§a Luo táº¡i Microsoft Research.
â€ TÃ¡c giáº£ liÃªn há»‡.
1https://openai.com/

--- TRANG 2 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025
SFTB C
D E
C > A = E > B = DXáº¿p háº¡ng hÆ°á»›ng dáº«n
 GÃ¡n nhÃ£n cáº¥p bÆ°á»›cPPO
IRM PRM
C > A = E > B = DIRM PRM
ğ‘Ÿğ‘ğ‘Ÿğ‘
ğ‘Ÿ=ğ‘Ÿğ‘âˆ™ğ‘Ÿğ‘BÆ°á»›c 1:
Math Evol-Instruct vÃ 
tinh chá»‰nh cÃ³ giÃ¡m sÃ¡t.BÆ°á»›c 2:
MÃ´ hÃ¬nh ThÆ°á»Ÿng HÆ°á»›ng dáº«n (IRM) vÃ  
MÃ´ hÃ¬nh ThÆ°á»Ÿng GiÃ¡m sÃ¡t QuÃ¡ trÃ¬nh (PRM).BÆ°á»›c 3:
Há»c tÄƒng cÆ°á»ng 
vá»›i IRM vÃ  PRM.
Math Evol-Instruct
A

HÃ¬nh 1: SÆ¡ Ä‘á»“ minh há»a ba bÆ°á»›c cá»§a Reinforcement Learning from Evol-Instruct Feedback (RLEIF) cá»§a chÃºng tÃ´i. Äá»ƒ cÃ³ giáº£i thÃ­ch chi tiáº¿t vá» pipeline Ä‘Ã o táº¡o, tham kháº£o Phá»¥ lá»¥c A.6

cÅ©ng Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ trÃªn nhiá»u benchmark láº­p luáº­n, táº¡o ra má»™t sá»‘ cÃ¢u tráº£ lá»i cÃ³ thá»ƒ tá»« mÃ´ hÃ¬nh vÃ  chá»n cÃ¢u tráº£ lá»i Ä‘Ãºng dá»±a trÃªn bá» phiáº¿u Ä‘a sá»‘ (Fu et al., 2022). Llemma (Azerbayev et al., 2023) vÃ  MathPile (Wang et al., 2023c) tiáº¿p tá»¥c tiá»n huáº¥n luyá»‡n LLM vá»›i corpus toÃ¡n há»c Ä‘á»ƒ cáº£i thiá»‡n nÄƒng lá»±c miá»n. MetaMath (Yu et al., 2023b) vÃ  Xwin-Math (Li et al., 2024a) bootstrap cÃ¡c cÃ¢u há»i toÃ¡n há»c báº±ng cÃ¡ch tÄƒng cÆ°á»ng cÃ¢u há»i tá»« nhiá»u gÃ³c Ä‘á»™. MAmmoTH (Yue et al., 2023) vÃ  TORA (Gou et al., 2023) trÃ¬nh bÃ y má»™t sá»± káº¿t há»£p Ä‘á»™c Ä‘Ã¡o cá»§a CoT vÃ  program-of-thought (PoT) Ä‘á»ƒ Ä‘áº£m báº£o phá»§ sÃ³ng rá»™ng rÃ£i cÃ¡c lÄ©nh vá»±c Ä‘a dáº¡ng trong toÃ¡n há»c. Gáº§n Ä‘Ã¢y, Evol-Instruct lÃ  má»™t phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ cho viá»‡c tá»•ng há»£p dá»¯ liá»‡u quy mÃ´ lá»›n sá»­ dá»¥ng LLM. NÃ³ Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c minh vÃ  chá»©ng minh rá»™ng rÃ£i lÃ  hiá»‡u quáº£ trong viá»‡c nÃ¢ng cao kháº£ nÄƒng tuÃ¢n theo hÆ°á»›ng dáº«n cá»§a mÃ´ hÃ¬nh. NÃ³ sá»­ dá»¥ng In-depth Evolving vÃ  In-breadth Evolving Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a viá»‡c táº¡o ra cÃ¡c hÆ°á»›ng dáº«n miá»n má»Ÿ Ä‘a dáº¡ng vÃ  phá»©c táº¡p sá»­ dá»¥ng LLM, thay vÃ¬ dá»±a vÃ o cÃ¡c bá»™ dá»¯ liá»‡u hÆ°á»›ng dáº«n Ä‘Æ°á»£c táº¡o thá»§ cÃ´ng. In-depth Evolving tÄƒng dáº§n Ä‘á»™ phá»©c táº¡p cá»§a hÆ°á»›ng dáº«n báº±ng cÃ¡ch giá»›i thiá»‡u cÃ¡c rÃ ng buá»™c bá»• sung, lÃ m sÃ¢u sáº¯c, cá»¥ thá»ƒ hÃ³a, tÄƒng cÃ¡c bÆ°á»›c láº­p luáº­n, vÃ  phá»©c táº¡p hÃ³a Ä‘áº§u vÃ o. In-breadth Evolving táº­p trung vÃ o cáº£i thiá»‡n sá»± Ä‘a dáº¡ng chá»§ Ä‘á» vÃ  sá»± phong phÃº cá»§a bá»™ dá»¯ liá»‡u báº±ng cÃ¡ch táº¡o ra cÃ¡c hÆ°á»›ng dáº«n hoÃ n toÃ n má»›i. Äá»ƒ nÃ¢ng cao tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a tá»«ng bÆ°á»›c trong quÃ¡ trÃ¬nh táº¡o ra cá»§a mÃ´ hÃ¬nh, (Wang et al., 2024a; Chen et al., 2024a; Lightman et al., 2023) phÃ¡t hiá»‡n ráº±ng giÃ¡m sÃ¡t quÃ¡ trÃ¬nh vá»›i há»c tÄƒng cÆ°á»ng vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i giÃ¡m sÃ¡t káº¿t quáº£ trong viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n MATH Ä‘áº§y thá»­ thÃ¡ch.

Láº¥y cáº£m há»©ng tá»« Evol-Instruct vÃ  Process-supervised Reinforcement Learning, cÃ´ng trÃ¬nh nÃ y nháº±m nÃ¢ng cao kháº£ nÄƒng láº­p luáº­n toÃ¡n há»c cá»§a cÃ¡c LLM. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p má»›i cÃ³ tÃªn Reinforcement Learning from Evol-Instruct Feedback (RLEIF), cÃ³ thá»ƒ Ä‘áº§u tiÃªn táº¡o ra dá»¯ liá»‡u hÆ°á»›ng dáº«n toÃ¡n há»c Ä‘a dáº¡ng báº±ng Math Evol-Instruct hoÃ n toÃ n má»›i, bao gá»“m hai tiáº¿n trÃ¬nh tiáº¿n hÃ³a hÆ°á»›ng xuá»‘ng vÃ  hÆ°á»›ng lÃªn Ä‘á»ƒ táº¡o ra toÃ¡n cáº¥p tiá»ƒu há»c vÃ  toÃ¡n trung há»c thá»­ thÃ¡ch tÆ°Æ¡ng á»©ng. Tuy nhiÃªn khÃ¡c vá»›i WizardLM (Xu et al., 2023) vÃ  WizardCoder (Luo et al., 2023), chá»§ yáº¿u táº­p trung vÃ o giai Ä‘oáº¡n SFT vÃ  dá»… bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi viá»‡c há»c thÃ´ng tin áº£o giÃ¡c tá»« mÃ´ hÃ¬nh giÃ¡o viÃªn, chÃºng tÃ´i Ä‘á»•i má»›i giá»›i thiá»‡u PRM Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» False-Positive trong quÃ¡ trÃ¬nh giáº£i quyáº¿t váº¥n Ä‘á». HÆ¡n ná»¯a, Ä‘á»ƒ ngÄƒn tiáº¿n hÃ³a hÆ°á»›ng dáº«n spiral ra ngoÃ i táº§m kiá»ƒm soÃ¡t, chÃºng tÃ´i káº¿t há»£p má»™t mÃ´ hÃ¬nh thÆ°á»Ÿng hÆ°á»›ng dáº«n (IRM) nhÆ° má»™t chiáº¿n lÆ°á»£c giáº£m nháº¹. Do Ä‘Ã³, chÃºng tÃ´i Ä‘Ã o táº¡o má»™t mÃ´ hÃ¬nh thÆ°á»Ÿng hÆ°á»›ng dáº«n (IRM) vÃ  má»™t mÃ´ hÃ¬nh thÆ°á»Ÿng giÃ¡m sÃ¡t quÃ¡ trÃ¬nh (PRM) (Lightman et al., 2023; Uesato et al., 2022; Wang et al., 2024a; Chen et al., 2024a), cÃ¡i trÆ°á»›c chá»‰ ra cháº¥t lÆ°á»£ng cá»§a hÆ°á»›ng dáº«n Ä‘Ã£ tiáº¿n hÃ³a vÃ  cÃ¡i sau cung cáº¥p pháº£n há»“i cho tá»«ng bÆ°á»›c láº­p luáº­n trong giáº£i phÃ¡p. Ban Ä‘áº§u, chÃºng tÃ´i tinh chá»‰nh LLM vá»›i dá»¯ liá»‡u toÃ¡n Ä‘Ã£ tiáº¿n hÃ³a. Ngay sau Ä‘Ã³, chÃºng tÃ´i táº­n dá»¥ng GPT-4 Ä‘á»ƒ táº¡o ra thá»© tá»± xáº¿p háº¡ng cá»§a cÃ¡c hÆ°á»›ng dáº«n, vÃ  tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a tá»«ng bÆ°á»›c láº­p luáº­n, sau Ä‘Ã³ tá»‘i Æ°u hÃ³a LLM Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c cÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng. Cuá»‘i cÃ¹ng, chÃºng tÃ´i thá»±c hiá»‡n PPO tá»«ng bÆ°á»›c Ä‘á»ƒ Ä‘Ã o táº¡o WizardMath cá»§a chÃºng tÃ´i.

--- TRANG 3 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025

ChÃºng tÃ´i thá»±c hiá»‡n thÃ­ nghiá»‡m trÃªn hai benchmark láº­p luáº­n toÃ¡n há»c Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i, cá»¥ thá»ƒ lÃ  GSM8k (Cobbe et al., 2021) vÃ  MATH (Hendrycks et al., 2021) bao gá»“m cÃ¡c bÃ i toÃ¡n toÃ¡n tá»« cáº¥p Ä‘á»™ tiá»ƒu há»c Ä‘áº¿n trung há»c, káº¿t quáº£ cho tháº¥y WizardMath cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n táº¥t cáº£ cÃ¡c LLM mÃ£ nguá»“n má»Ÿ khÃ¡c cÃ³ cÃ¹ng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh, Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tiÃªn tiáº¿n. VÃ­ dá»¥, WizardMath-70B vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i MetaMath-70B má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ trÃªn GSM8k (92.8 vs. 82.3) vÃ  trÃªn MATH (58.6 vs. 26.6). Cá»¥ thá»ƒ, WizardMath-Mistral-7B quan sÃ¡t Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trong pass@1 vá»›i má»©c tÄƒng +12.8 (90.7. vs. 77.9) trÃªn GSM8k, vÃ  +26.8 (55.4 vs. 28.6) trÃªn MATH so vá»›i MetaMath-Mistral-7B. ÄÃ¡ng chÃº Ã½, mÃ´ hÃ¬nh 70B cá»§a chÃºng tÃ´i tháº­m chÃ­ cÃ²n vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i nhá»¯ng LLM Ä‘á»™c quyá»n máº¡nh máº½, nhÆ° GPT-3.5-Turbo, Claude 2 (Bai et al., 2022), Mistral Medium (Jiang et al., 2024), Gemini-Pro (Team, 2023), PaLM-2 (Anil et al., 2023) vÃ  GPT-4-early-version.

Nhá»¯ng Ä‘Ã³ng gÃ³p chÃ­nh cá»§a cÃ´ng trÃ¬nh nÃ y nhÆ° sau:
â€¢ ChÃºng tÃ´i giá»›i thiá»‡u mÃ´ hÃ¬nh WizardMath, nÃ¢ng cao kháº£ nÄƒng láº­p luáº­n toÃ¡n há»c cá»§a LLM trÃªn má»™t pháº¡m vi khÃ³ khÄƒn bÃ i toÃ¡n, tá»« cáº¥p Ä‘á»™ tiá»ƒu há»c Ä‘áº¿n trung há»c.
â€¢ ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p há»c tÄƒng cÆ°á»ng tá»± Ä‘á»™ng hoÃ n toÃ n báº±ng AI má»›i, Reinforcement Learning from Evol-Instruct Feedback (RLEIF), cÃ¹ng vá»›i Math Evol-Instruct vÃ  Process Supervision, Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t láº­p luáº­n.
â€¢ WizardMath vÆ°á»£t trá»™i hÆ¡n cÃ¡c LLM mÃ£ nguá»“n má»Ÿ hÃ ng Ä‘áº§u má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ vá»›i hiá»‡u quáº£ dá»¯ liá»‡u cao hÆ¡n vÃ  cÅ©ng vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c LLM Ä‘á»™c quyá»n khÃ¡c nhau trÃªn cáº£ GSM8k vÃ  MATH, chá»©ng minh hiá»‡u quáº£ cá»§a RLEIF cá»§a chÃºng tÃ´i.

2 CÃ”NG TRÃŒNH LIÃŠN QUAN

CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n. LLM Ä‘Ã£ tiáº¿n bá»™ Ä‘Ã¡ng ká»ƒ trong Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn, vá»›i cÃ¡c mÃ´ hÃ¬nh nhÆ° OpenAI's GPT Series (Brown et al., 2020a; OpenAI, 2023), Anthropic's Claude (Bai et al., 2022), Google's PaLM (Chowdhery et al., 2022; Anil et al., 2023), Gemini (Team, 2023), vÃ  Gemma (Team et al., 2024) cÃ³ hÃ ng tá»· tham sá»‘ vÃ  Ä‘Æ°á»£c Ä‘Ã o táº¡o trÃªn cÃ¡c bá»™ dá»¯ liá»‡u vÄƒn báº£n khá»•ng lá»“. LÄ©nh vá»±c AI cÅ©ng Ä‘Ã£ chá»©ng kiáº¿n sá»± gia tÄƒng cá»§a cÃ¡c LLM mÃ£ nguá»“n má»Ÿ nhÆ° Mistral (Jiang et al., 2023), Llama Series (Touvron et al., 2023a;b; Dubey et al., 2024; Taylor et al., 2022), DeepSeek (Bi et al., 2024; Shao et al., 2024), Qwen (Bai et al., 2023; Yang et al., 2024) v.v. ÄÃ¡ng chÃº Ã½, Llama phá»¥c vá»¥ nhÆ° má»™t mÃ´ hÃ¬nh ná»n táº£ng cho tinh chá»‰nh cÃ³ giÃ¡m sÃ¡t, dáº«n Ä‘áº¿n sá»± phÃ¡t triá»ƒn cá»§a cÃ¡c mÃ´ hÃ¬nh nhÆ° Alpaca, Vicuna (Taori et al., 2023; Chiang et al., 2023).

CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n Cho láº­p luáº­n toÃ¡n há»c. CÃ¡c mÃ´ hÃ¬nh NLP Ä‘á»‘i máº·t vá»›i thá»­ thÃ¡ch vá» láº­p luáº­n phá»©c táº¡p, bao gá»“m toÃ¡n há»c (Long et al., 2024; Zhang et al., 2024b; Xia et al., 2024), thÆ°á»ng thá»©c (Talmor et al., 2019). NghiÃªn cá»©u Ä‘Ã¡ng ká»ƒ táº­p trung vÃ o Mathematical Word Problems (MWP), Ä‘Ã²i há»i hiá»ƒu biáº¿t vá» cÃ¡c khÃ¡i niá»‡m toÃ¡n há»c vÃ  láº­p luáº­n Ä‘a bÆ°á»›c (Zheng et al., 2023; Zhao et al., 2023; Yuan et al., 2023a). CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c kiá»ƒm tra trÃªn cÃ¡c benchmark MWP khÃ¡c nhau (Roy & Roth, 2015; Hendrycks et al., 2021). CÃ¡c ká»¹ thuáº­t nhÆ° Chain-of-Thought Prompting (Wei et al., 2022), Least-to-Most prompting (Zhou et al., 2022), vÃ  Complex CoT (Fu et al., 2022) nÃ¢ng cao láº­p luáº­n báº±ng cÃ¡ch giá»›i thiá»‡u nhiá»u bÆ°á»›c vÃ  chia nhá» bÃ i toÃ¡n thÃ nh cÃ¡c bÃ i toÃ¡n con. CÃ³ má»™t sá»‘ mÃ´ hÃ¬nh nháº±m cáº£i thiá»‡n ká»¹ nÄƒng láº­p luáº­n CoT toÃ¡n há»c nhÆ° MetaMath (Yu et al., 2023b), MathScale (Tang et al., 2024), Xwin-Math (Li et al., 2024a), DART-Math (Tong et al., 2024) v.v. Má»™t sá»‘ mÃ´ hÃ¬nh nÃ¢ng cao láº­p luáº­n toÃ¡n há»c báº±ng cÃ¡ch tÃ­ch há»£p cÃ¡c cÃ´ng cá»¥ python, nhÆ° TORA (Gou et al., 2023), MAmmoTH (Yue et al., 2023), Openmathinstruct (Toshniwal et al., 2024), NuminaMath (Li et al., 2024b) v.v. Trong cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i, chÃºng tÃ´i chá»§ yáº¿u cáº£i thiá»‡n kháº£ nÄƒng láº­p luáº­n CoT cá»§a toÃ¡n há»c mÃ  khÃ´ng sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ Python bÃªn ngoÃ i.

Há»c TÄƒng cÆ°á»ng cho CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n. CÃ¡c mÃ´ hÃ¬nh tiÃªn tiáº¿n thÆ°á»ng hiá»ƒn thá»‹ lá»—i logic vÃ  áº£o giÃ¡c, Ä‘áº·c biá»‡t trong cÃ¡c miá»n Ä‘Ã²i há»i láº­p luáº­n phá»©c táº¡p, Ä‘a bÆ°á»›c, dáº«n Ä‘áº¿n nhá»¯ng thá»­ thÃ¡ch Ä‘Ã¡ng ká»ƒ (Bubeck et al., 2023; Maynez et al., 2020). CÃ¡c chiáº¿n lÆ°á»£c nhÆ° Ä‘Ã o táº¡o mÃ´ hÃ¬nh thÆ°á»Ÿng giÃºp phÃ¢n biá»‡t giá»¯a cÃ¡c Ä‘áº§u ra mong muá»‘n vÃ  khÃ´ng mong muá»‘n (Lightman et al., 2023; Wu et al., 2023; Chen et al., 2024b). Trong lá»‹ch sá»­, cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn káº¿t quáº£ táº­p trung vÃ o cÃ¡c nhiá»‡m vá»¥ thuáº­t toÃ¡n (Li et al., 2016; Cai et al., 2017; Yu et al., 2023a), trong khi nghiÃªn cá»©u gáº§n Ä‘Ã¢y chá»©ng minh hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng hoáº·c validators trong viá»‡c nÃ¢ng cao hiá»‡u suáº¥t mÃ´ hÃ¬nh (Cobbe et al., 2021; Wang et al., 2023a;b; Li et al., 2022). CÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c káº¿t há»£p vÃ o cÃ¡c pipeline há»c tÄƒng cÆ°á»ng vÃ  Ä‘Æ°á»£c sá»­ dá»¥ng trong rejection sampling Ä‘á»ƒ cÄƒn chá»‰nh CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLM) vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i (Shen et al., 2021; Bai et al., 2022; Yuan et al., 2023b; Dong et al., 2023;

--- TRANG 4 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025

Song et al., 2023; Touvron et al., 2023b; Rafailov et al., 2024; Meng et al., 2024). Má»™t sá»± tÆ°Æ¡ng pháº£n Ä‘Æ°á»£c rÃºt ra giá»¯a cÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng giÃ¡m sÃ¡t káº¿t quáº£ vÃ  giÃ¡m sÃ¡t quÃ¡ trÃ¬nh, vá»›i cÃ¡i sau hiá»‡u quáº£ hÆ¡n trong viá»‡c giáº£i quyáº¿t sá»± khÃ¡c biá»‡t phÃ¡t sinh tá»« cÃ¡c con Ä‘Æ°á»ng láº­p luáº­n khÃ´ng chÃ­nh xÃ¡c dáº«n Ä‘áº¿n káº¿t quáº£ Ä‘Ãºng (Uesato et al., 2022; Zelikman et al., 2022; Creswell et al., 2022). Nhá»¯ng tiáº¿n bá»™ gáº§n Ä‘Ã¢y Ä‘Ã£ thÃºc Ä‘áº©y giÃ¡m sÃ¡t dá»±a trÃªn quÃ¡ trÃ¬nh thÃ´ng qua chÃº thÃ­ch thá»§ cÃ´ng, mang láº¡i lá»£i Ã­ch Ä‘Ã¡ng ká»ƒ cho LLM so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn káº¿t quáº£ (Lightman et al., 2023; Wang et al., 2024a; Sun et al., 2024; Chen et al., 2024a; Wang et al., 2024b; Zhang et al., 2024a). Trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i, chÃºng tÃ´i táº­n dá»¥ng cÃ¡c mÃ´ hÃ¬nh AI nhÆ° ChatGPT Ä‘á»ƒ tá»± Ä‘á»™ng cung cáº¥p chÃº thÃ­ch quÃ¡ trÃ¬nh nháº±m cáº£i thiá»‡n hiá»‡u quáº£ cá»§a dÃ²ng nghiÃªn cá»©u nÃ y.

3 PHÆ¯Æ NG PHÃP

Trong pháº§n nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y chi tiáº¿t vá» WizardMath cá»§a chÃºng tÃ´i. Theo WizardLM vÃ  PRMs (Lightman et al., 2023), chÃºng tÃ´i Ä‘á» xuáº¥t phÆ°Æ¡ng phÃ¡p Reinforcement Learning from Evol-Instruct Feedback (RLEIF), tÃ­ch há»£p math Evol-Instruct vÃ  giÃ¡m sÃ¡t hÆ°á»›ng dáº«n vÃ  quÃ¡ trÃ¬nh Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ä‘á»ƒ tiáº¿n hÃ³a GSM8k vÃ  MATH, vÃ  tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u Ä‘Ã£ tiáº¿n hÃ³a vÃ  cÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng.

3.1 MATH EVOL-INSTRUCT

ÄÆ°á»£c thÃºc Ä‘áº©y bá»Ÿi phÆ°Æ¡ng phÃ¡p Evol-Instruct (Xu et al., 2023) Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi WiazrdLM vÃ  á»©ng dá»¥ng hiá»‡u quáº£ cá»§a nÃ³ trÃªn WizardCoder (Luo et al., 2023), cÃ´ng trÃ¬nh nÃ y cá»‘ gáº¯ng táº¡o ra cÃ¡c hÆ°á»›ng dáº«n toÃ¡n vá»›i Ä‘á»™ phá»©c táº¡p vÃ  Ä‘a dáº¡ng khÃ¡c nhau Ä‘á»ƒ nÃ¢ng cao cÃ¡c LLM Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n. Cá»¥ thá»ƒ, chÃºng tÃ´i Ä‘iá»u chá»‰nh Evol-Instruct thÃ nh má»™t mÃ´ hÃ¬nh má»›i bao gá»“m hai dÃ²ng tiáº¿n hÃ³a:

1) Tiáº¿n hÃ³a hÆ°á»›ng xuá»‘ng: NÃ³ nÃ¢ng cao hÆ°á»›ng dáº«n báº±ng cÃ¡ch lÃ m cho cÃ¡c cÃ¢u há»i dá»… hÆ¡n. VÃ­ dá»¥ i): sá»­a Ä‘á»•i cÃ¡c cÃ¢u há»i khÃ³ thÃ nh khÃ³ tháº¥p hÆ¡n, hoáº·c ii) táº¡o ra má»™t cÃ¢u há»i má»›i vÃ  dá»… hÆ¡n vá»›i má»™t chá»§ Ä‘á» khÃ¡c.

2) Tiáº¿n hÃ³a hÆ°á»›ng lÃªn: CÃ³ nguá»“n gá»‘c tá»« phÆ°Æ¡ng phÃ¡p Evol-Instruct ban Ä‘áº§u, nÃ³ lÃ m sÃ¢u sáº¯c vÃ  táº¡o ra cÃ¡c cÃ¢u há»i má»›i vÃ  khÃ³ hÆ¡n báº±ng i) thÃªm nhiá»u rÃ ng buá»™c hÆ¡n, ii) cá»¥ thá»ƒ hÃ³a, iii) tÄƒng láº­p luáº­n.

CÃ¡c lá»i nháº¯c Ä‘áº§y Ä‘á»§ cá»§a tiáº¿n hÃ³a trÃªn Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Phá»¥ lá»¥c A.1. Äá»‘i vá»›i má»—i hÆ°á»›ng dáº«n, chÃºng tÃ´i sá»­ dá»¥ng GPT-4 Ä‘á»ƒ tiáº¿n hÃ³a 5 vÃ²ng (2 hÆ°á»›ng xuá»‘ng vÃ  3 hÆ°á»›ng lÃªn) cá»§a cÃ¡c hÆ°á»›ng dáº«n má»›i má»™t cÃ¡ch tiá»‡m tiáº¿n, má»—i cÃ¡i má»›i Ä‘Æ°á»£c táº¡o ra bá»Ÿi vÃ²ng tiáº¿n hÃ³a trÆ°á»›c Ä‘Ã³.

3.2 CÃC MÃ” HÃŒNH THÆ¯á»NG

Xem xÃ©t sá»± cáº§n thiáº¿t cá»§a kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng cho cÃ¡c hÆ°á»›ng dáº«n Ä‘Ã£ tiáº¿n hÃ³a vÃ  Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« PRMs (Lightman et al., 2023), chÃºng tÃ´i Ä‘Ã o táº¡o hai mÃ´ hÃ¬nh thÆ°á»Ÿng Ä‘á»ƒ dá»± Ä‘oÃ¡n cháº¥t lÆ°á»£ng cá»§a cÃ¡c hÆ°á»›ng dáº«n vÃ  tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a tá»«ng bÆ°á»›c trong cÃ¢u tráº£ lá»i tÆ°Æ¡ng á»©ng:

MÃ´ hÃ¬nh ThÆ°á»Ÿng HÆ°á»›ng dáº«n (IRM) MÃ´ hÃ¬nh nÃ y nháº±m Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cá»§a cÃ¡c hÆ°á»›ng dáº«n Ä‘Ã£ tiáº¿n hÃ³a trÃªn hai khÃ­a cáº¡nh: i) Äá»™ khÃ³, vÃ  ii) Äá»‹nh nghÄ©a. Äá»ƒ táº¡o ra dá»¯ liá»‡u Ä‘Ã o táº¡o danh sÃ¡ch xáº¿p háº¡ng cá»§a IRM, chÃºng tÃ´i táº­n dá»¥ng GPT-4 Ä‘á»ƒ xáº¿p háº¡ng cháº¥t lÆ°á»£ng giá»¯a nhá»¯ng hÆ°á»›ng dáº«n Ä‘Ã£ tiáº¿n hÃ³a vÃ  hÆ°á»›ng dáº«n ban Ä‘áº§u. CÃ¡i cÃ³ Ä‘á»™ khÃ³ cao vÃ  Ä‘á»‹nh nghÄ©a rÃµ rÃ ng sáº½ xá»©ng Ä‘Ã¡ng cÃ³ xáº¿p háº¡ng cao hÆ¡n. Lá»i nháº¯c chi tiáº¿t cá»§a quÃ¡ trÃ¬nh xáº¿p háº¡ng trÃªn Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Phá»¥ lá»¥c A.2.

Cá»¥ thá»ƒ, cho má»™t hÆ°á»›ng dáº«n toÃ¡n q, IRM (Qâ†’R) gÃ¡n má»™t Ä‘iá»ƒm sá»‘ cho q Ä‘á»ƒ chá»‰ ra cháº¥t lÆ°á»£ng cá»§a nÃ³. ChÃºng tÃ´i tá»‘i Æ°u hÃ³a ORM thÃ´ng qua hÃ m máº¥t mÃ¡t xáº¿p háº¡ng cáº·p Ä‘Ã´i sau:

LIRM = âˆ’logÏƒ(rq_j âˆ’ rq_k âˆ’ m) (1)

trong Ä‘Ã³ rq_j lÃ  thÆ°á»Ÿng cá»§a hÆ°á»›ng dáº«n Ä‘Æ°á»£c chá»n vÃ  rq_k lÃ  thÆ°á»Ÿng cá»§a hÆ°á»›ng dáº«n bá»‹ tá»« chá»‘i, m lÃ  biÃªn.

MÃ´ hÃ¬nh ThÆ°á»Ÿng GiÃ¡m sÃ¡t QuÃ¡ trÃ¬nh (PRM) VÃ¬ khÃ´ng cÃ³ cÃ¡ch Ä‘Æ¡n giáº£n nÃ o Ä‘á»ƒ há»— trá»£ giÃ¡m sÃ¡t quÃ¡ trÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao mÃ  khÃ´ng cÃ³ cÃ¡c chuyÃªn gia ghi nhÃ£n chuyÃªn nghiá»‡p vÃ  Ä‘áº¯t Ä‘á», chÃºng tÃ´i phá»¥ thuá»™c vÃ o GPT-4 Ä‘á»ƒ cung cáº¥p giÃ¡m sÃ¡t quÃ¡ trÃ¬nh, vÃ  yÃªu cáº§u nÃ³ Ä‘Ã¡nh giÃ¡ tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a tá»«ng bÆ°á»›c trong cÃ¡c giáº£i phÃ¡p Ä‘Æ°á»£c táº¡o ra bá»Ÿi mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i Ä‘á»ƒ táº¡o ra dá»¯ liá»‡u Ä‘Ã o táº¡o PRM. Lá»i nháº¯c chi tiáº¿t cá»§a quÃ¡ trÃ¬nh ghi nhÃ£n cáº¥p bÆ°á»›c trÃªn Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Phá»¥ lá»¥c A.3.

--- TRANG 5 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025

Äá»ƒ chÃ­nh xÃ¡c, cho má»™t hÆ°á»›ng dáº«n toÃ¡n q vÃ  cÃ¢u tráº£ lá»i a cá»§a nÃ³, PRM (QÃ—Aâ†’R+) gÃ¡n má»™t Ä‘iá»ƒm sá»‘ cho tá»«ng bÆ°á»›c cá»§a a, chÃºng tÃ´i Ä‘Ã o táº¡o PRM vá»›i hÃ m máº¥t mÃ¡t cross-entropy sau:

LPRM = âˆ‘(i=1 to L) yi log ra_i + (1âˆ’yi) log(1 âˆ’ ra_i) (2)

trong Ä‘Ã³ L lÃ  cÃ¡c bÆ°á»›c láº­p luáº­n cá»§a cÃ¢u tráº£ lá»i a. yi lÃ  nhÃ£n ground-truth cá»§a bÆ°á»›c thá»© i cá»§a cÃ¢u tráº£ lá»i a, yi = 1 náº¿u ai Ä‘Ãºng, ngÆ°á»£c láº¡i yi = 0. ra_i lÃ  Ä‘iá»ƒm thÆ°á»Ÿng (Ä‘Æ°á»£c gÃ¡n bá»Ÿi PRM) cá»§a bÆ°á»›c thá»© i cá»§a cÃ¢u tráº£ lá»i a.

3.3 Há»ŒC TÄ‚NG CÆ¯á»œNG Vá»šI IRM VÃ€ PRM

Ngay sau Ä‘Ã³, chÃºng tÃ´i khai thÃ¡c há»c tÄƒng cÆ°á»ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a LLM. Theo (Lightman et al., 2023), chÃºng tÃ´i sá»­ dá»¥ng Proximal Policy Optimization (PPO) tá»«ng bÆ°á»›c Ä‘á»ƒ thÆ°á»Ÿng cho cáº£ hÆ°á»›ng dáº«n vÃ  tá»«ng bÆ°á»›c láº­p luáº­n.

Äá»‘i vá»›i má»—i hÆ°á»›ng dáº«n toÃ¡n q vÃ  cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o a, chÃºng tÃ´i sá»­ dá»¥ng IRM Ä‘á»ƒ gÃ¡n thÆ°á»Ÿng hÆ°á»›ng dáº«n rq, vÃ  sá»­ dá»¥ng Ä‘iá»ƒm sá»‘ tá»‘i thiá»ƒu trÃªn táº¥t cáº£ cÃ¡c bÆ°á»›c láº­p luáº­n Ä‘á»ƒ Ä‘áº¡i diá»‡n cho Ä‘iá»ƒm thÆ°á»Ÿng cuá»‘i cÃ¹ng ra cá»§a cÃ¢u tráº£ lá»i a Ä‘Æ°á»£c gÃ¡n bá»Ÿi PRM. Sau Ä‘Ã³ chÃºng tÃ´i Ã¡p dá»¥ng má»™t tÃ­ch sá»‘ nhÆ° thÆ°á»Ÿng cuá»‘i cÃ¹ng cá»§a cáº·p hÆ°á»›ng dáº«n-cÃ¢u tráº£ lá»i nÃ y:

r = rq Â· ra (3)

3.4 PRM CHO XÃC MINH

Theo (Lightman et al., 2023) vÃ  (Li et al., 2023c), chÃºng tÃ´i táº­n dá»¥ng cáº£ bá» phiáº¿u Ä‘a sá»‘ vÃ  PRM verifier Ä‘á»ƒ tá»•ng há»£p cÃ¡c dá»± Ä‘oÃ¡n cá»§a cÃ¡c con Ä‘Æ°á»ng láº­p luáº­n khÃ¡c nhau.

Ã¢ = arg max_a âˆ‘(i=1 to N) I{ai=a} Â· PRM(q, ai) (4)

trong Ä‘Ã³ PRM(q, ai) lÃ  Ä‘iá»ƒm sá»‘ cá»§a con Ä‘Æ°á»ng láº­p luáº­n thá»© i Ä‘Æ°á»£c gÃ¡n bá»Ÿi PRM cho hÆ°á»›ng dáº«n q. I{ai=a} lÃ  má»™t hÃ m chá»‰ thá»‹ tráº£ vá» 1 (hoáº·c 0) náº¿u ai = a.

4 THÃ NGHIá»†M

Pháº§n nÃ y cung cáº¥p má»™t tá»•ng quan toÃ n diá»‡n vá» cÃ¡c mÃ´ hÃ¬nh tiÃªn tiáº¿n. Sau Ä‘Ã³, chÃºng tÃ´i chá»§ yáº¿u lÃ m rÃµ cÃ¡c metric hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i trÃªn hai benchmark toÃ¡n há»c phá»• biáº¿n tá»« cÃ¡c bÃ i toÃ¡n tiá»ƒu há»c Ä‘áº¿n trung há»c: GSM8k (Cobbe et al., 2021) vÃ  MATH (Hendrycks et al., 2021).

4.1 THIáº¾T Láº¬P THÃ NGHIá»†M

Dá»¯ liá»‡u ÄÃ o táº¡o SFT. Äáº§u tiÃªn, sá»­ dá»¥ng cÃ¡c bá»™ Ä‘Ã o táº¡o GSM8k vÃ  MATH lÃ m bá»™ sÆ°u táº­p háº¡t giá»‘ng ban Ä‘áº§u, sau Ä‘Ã³ sá»­ dá»¥ng cáº£ phÆ°Æ¡ng phÃ¡p math Evol-Instruct hÆ°á»›ng lÃªn vÃ  hÆ°á»›ng xuá»‘ng trong nÄƒm vÃ²ng. Má»—i vÃ²ng cáº§n tiáº¿n hÃ³a cÃ¡c hÆ°á»›ng dáº«n ban Ä‘áº§u 6 láº§n, vÃ  tham sá»‘ nhiá»‡t Ä‘á»™ Ä‘Æ°á»£c Ä‘áº·t lÃ  0.7. Tiáº¿p theo, chÃºng tÃ´i loáº¡i bá» cÃ¡c hÆ°á»›ng dáº«n trÃ¹ng láº·p 17k. Do Ä‘Ã³, tá»•ng cá»™ng 448k hÆ°á»›ng dáº«n duy nháº¥t Ä‘Æ°á»£c thu tháº­p. Sau Ä‘Ã³, 30k dá»¯ liá»‡u bá»‹ loáº¡i trá»« báº±ng phÆ°Æ¡ng phÃ¡p lá»c dá»¯ liá»‡u Ä‘á»ƒ trÃ¡nh Ã´ nhiá»…m, cuá»‘i cÃ¹ng cÃ²n láº¡i 418k dá»¯ liá»‡u. Cuá»‘i cÃ¹ng, chÃºng tÃ´i sá»­ dá»¥ng GPT-4-0613 Ä‘á»ƒ táº¡o ra cÃ¢u tráº£ lá»i vá»›i Ä‘á»‹nh dáº¡ng tá»«ng bÆ°á»›c, vÃ  táº­n dá»¥ng chÃºng cho tinh chá»‰nh cÃ³ giÃ¡m sÃ¡t.

Dá»¯ liá»‡u ÄÃ o táº¡o MÃ´ hÃ¬nh ThÆ°á»Ÿng. Äá»ƒ Ä‘Ã o táº¡o cÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng, chÃºng tÃ´i thá»±c hiá»‡n thÃªm 5 vÃ²ng tiáº¿n hÃ³a trÃªn bá»™ hÆ°á»›ng dáº«n ban Ä‘áº§u vÃ  thu Ä‘Æ°á»£c 90k hÆ°á»›ng dáº«n. chÃºng tÃ´i sá»­ dá»¥ng GPT-4-0613 Ä‘á»ƒ xáº¿p háº¡ng tá»«ng danh sÃ¡ch hÆ°á»›ng dáº«n vá»›i cháº¥t lÆ°á»£ng tá»« 1 Ä‘áº¿n 6 lÃ m dá»¯ liá»‡u Ä‘Ã o táº¡o cá»§a IRM. Äá»ƒ thu Ä‘Æ°á»£c dá»¯ liá»‡u Ä‘Ã o táº¡o cá»§a PRM, chÃºng tÃ´i sá»­ dá»¥ng mÃ´ hÃ¬nh SFT Llama-2 70B cá»§a chÃºng tÃ´i Ä‘á»ƒ táº¡o ra 5 cÃ¢u tráº£ lá»i cho má»—i hÆ°á»›ng dáº«n, vÃ  GPT-4-0613 Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ gÃ¡n Ä‘Ã¡nh giÃ¡ tÃ­nh Ä‘Ãºng Ä‘áº¯n cho tá»«ng bÆ°á»›c láº­p luáº­n.

Chi tiáº¿t Triá»ƒn khai. ChÃºng tÃ´i sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i trÃªn hai mÃ´ hÃ¬nh ná»n táº£ng mÃ£ nguá»“n má»Ÿ Llama 2 (Touvron et al., 2023b) vÃ  Mistral-7B (Jiang et al., 2023). Llama 2 bao gá»“m ba kÃ­ch thÆ°á»›c tham sá»‘ khÃ¡c biá»‡t: 7B, 13B, vÃ  70B. ChÃºng tÃ´i sá»­ dá»¥ng GPT-4-0613 cho tiáº¿n hÃ³a hÆ°á»›ng dáº«n vÃ  xÃ¢y dá»±ng dá»¯ liá»‡u Ä‘Ã o táº¡o cá»§a cÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng. Äá»‘i vá»›i SFT, chÃºng tÃ´i Ä‘Ã o táº¡o 3 epochs, vÃ  tá»· lá»‡ há»c lÃ  2e-5, 1e-5 vÃ  5e-6 cho Llama 2 7B/13B, 70B vÃ  Mistral-7B. KÃ­ch thÆ°á»›c batch lÃ  512, vÃ  Ä‘á»™ dÃ i sequence lÃ  2048. Äá»‘i vá»›i mÃ´ hÃ¬nh thÆ°á»Ÿng, chÃºng tÃ´i Ä‘Ã o táº¡o Llama 2 vÃ  Mistral-7B vá»›i tá»· lá»‡ há»c 4e-6 vÃ  1e-6 trong má»™t epoch. Äá»‘i vá»›i RL, lr lÃ  4e-7 vÃ  1e-7 cho Llama 2 vÃ  Mistral-7B vÃ  Ä‘Ã o táº¡o má»™t epoch.

--- TRANG 6 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025

4.2 Káº¾T QUáº¢ CHÃNH

Báº£ng 1: Káº¿t quáº£ CoT pass@1 cá»§a cÃ¡c mÃ´ hÃ¬nh trÃªn GSM8k vÃ  MATH mÃ  khÃ´ng sá»­ dá»¥ng báº¥t ká»³ cÃ´ng cá»¥ python bÃªn ngoÃ i nÃ o.

[Báº£ng káº¿t quáº£ dÃ i vá»›i nhiá»u mÃ´ hÃ¬nh vÃ  Ä‘iá»ƒm sá»‘ - tÃ´i sáº½ dá»‹ch pháº§n chÃº thÃ­ch chÃ­nh:]

Báº£ng 1 hiá»ƒn thá»‹ káº¿t quáº£ CoT (Wei et al., 2022) pass@1 cá»§a cÃ¡c mÃ´ hÃ¬nh tiÃªn tiáº¿n hiá»‡n táº¡i trÃªn GSM8k vÃ  MATH. Trong nghiÃªn cá»©u nÃ y, Ä‘á»ƒ Ä‘áº£m báº£o cÃ¡c Ä‘Ã¡nh giÃ¡ cÃ´ng báº±ng vÃ  gáº¯n káº¿t, chÃºng tÃ´i bÃ¡o cÃ¡o Ä‘iá»ƒm sá»‘ cá»§a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh trong cÃ¡c thiáº¿t láº­p giáº£i mÃ£ tham lam vÃ  CoT mÃ  khÃ´ng sá»­ dá»¥ng báº¥t ká»³ cÃ´ng cá»¥ python bÃªn ngoÃ i nÃ o.

So sÃ¡nh vá»›i cÃ¡c MÃ´ hÃ¬nh Äá»™c quyá»n.
NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 1, WizardMath cá»§a chÃºng tÃ´i thá»ƒ hiá»‡n sá»± vÆ°á»£t trá»™i Ä‘Ã¡ng chÃº Ã½ so vá»›i cÃ¡c LLM Ä‘á»™c quyá»n khÃ¡c nhau trÃªn cÃ¡c benchmark GSM8k vÃ  MATH vá» pass@1:

1) WizardMath-Llama 70B, mÃ´ hÃ¬nh lá»›n nháº¥t, thá»ƒ hiá»‡n hiá»‡u suáº¥t xuáº¥t sáº¯c trÃªn GSM8k vÃ  MATH, vÆ°á»£t trá»™i hÆ¡n cÃ¡c phiÃªn báº£n trÆ°á»›c cá»§a GPT-4, Claude-2, vÃ  Gemini Pro, vÃ  hoáº¡t Ä‘á»™ng ngang báº±ng vá»›i GPT-4-0314. NÃ³ vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i GPT-3.5-Turbo 11.2% trÃªn GSM8k vÃ  15.5% trÃªn MATH.

2) WizardMath-Mistral 7B, mÃ´ hÃ¬nh kÃ­ch thÆ°á»›c nhá» hÆ¡n, vÆ°á»£t trá»™i hÆ¡n Baichuan 3 trÃªn GSM8k (90.7 vs. 87.6) vÃ  vÆ°á»£t trá»™i hÆ¡n GPT-4-0314 trÃªn MATH (55.4 vs. 52.6), vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i hiá»‡u suáº¥t cá»§a GPT-3.5-Turbo vÃ  Gemini Pro. Trong khi Ä‘Ã³, WizardMath-Mathstral, Ä‘Æ°á»£c Ä‘Ã o táº¡o trÃªn Mathstral-7B-v0.1, thá»ƒ hiá»‡n hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i GPT-4-turbo-0125. NgoÃ i ra, WizardMath-Qwen, Ä‘Æ°á»£c Ä‘Ã o táº¡o trÃªn Qwen2.5-Math, vÆ°á»£t trá»™i hÆ¡n GPT-4-2024-0513 trÃªn MATH (77.8 vs. 76.6).

So sÃ¡nh vá»›i cÃ¡c MÃ´ hÃ¬nh MÃ£ nguá»“n Má»Ÿ.
Káº¿t quáº£ Ä‘Æ°á»£c trÃ¬nh bÃ y trong Báº£ng 1 chá»‰ ra má»™t cÃ¡ch rÃµ rÃ ng ráº±ng WizardMath-Llama 70B cá»§a chÃºng tÃ´i thá»ƒ hiá»‡n sá»± vÆ°á»£t trá»™i hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh máº¡nh trong cáº£ benchmark GSM8k vÃ  MATH vá»›i hiá»‡u quáº£ dá»¯ liá»‡u cao hÆ¡n trÃªn pháº¡m vi tá»« 0.1B Ä‘áº¿n 70B tham sá»‘. Káº¿t quáº£ chi tiáº¿t nhÆ° sau:

1) Vá»›i cÃ¹ng kÃ­ch thÆ°á»›c tham sá»‘ mÃ´ hÃ¬nh, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n mÃ´ hÃ¬nh tá»‘t nháº¥t trÆ°á»›c Ä‘Ã¢y nhÆ° MetaMath, MAmmoTH2-Plus, Xwin-Math. Äáº·c biá»‡t, WizardMath-Llama 70B Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ 10.5% trÃªn GSM8K vÃ  32.0% trÃªn MATH so vá»›i MetaMath-Llama 70B trong Ä‘á»™ chÃ­nh xÃ¡c kiá»ƒm tra. Trong Báº£ng 2, chÃºng tÃ´i hiá»ƒn thá»‹ káº¿t quáº£ chi tiáº¿t cá»§a cÃ¡c chá»§ Ä‘á» con MATH vá»›i mÃ´ hÃ¬nh WizardMath 70B cá»§a chÃºng tÃ´i. Cá»¥ thá»ƒ, WizardMath-Mistral 7B cÅ©ng vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ hÃ ng Ä‘áº§u, vÆ°á»£t trá»™i hÆ¡n MetaMath-Mistral 7B vá»›i má»™t biÃªn Ä‘Ã¡ng chÃº Ã½ (90.7 vs 77.9 trÃªn GSM8k) vÃ  (55.4 vs 28.6 trÃªn MATH). NÃ³ chá»©ng minh hiá»‡u quáº£

--- TRANG 7 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025

Báº£ng 2: Káº¿t quáº£ pass@1 (%) trÃªn cÃ¡c chá»§ Ä‘á» con MATH (tá»©c lÃ , Intermediate Algebra, Geometry) vá»›i mÃ´ hÃ¬nh WizardMath 70B.

[Báº£ng káº¿t quáº£ cho cÃ¡c chá»§ Ä‘á» con MATH]

Báº£ng 3: KhÃ¡m phÃ¡ tÃ¡c Ä‘á»™ng cá»§a PRM vÃ  IRM trong quÃ¡ trÃ¬nh Ä‘Ã o táº¡o PPO.

[Báº£ng so sÃ¡nh cÃ¡c biáº¿n thá»ƒ cá»§a mÃ´ hÃ¬nh]

cá»§a phÆ°Æ¡ng phÃ¡p RLEIF cá»§a chÃºng tÃ´i trong viá»‡c nÃ¢ng cao kháº£ nÄƒng láº­p luáº­n toÃ¡n há»c trÃªn má»™t pháº¡m vi khÃ³ khÄƒn bÃ i toÃ¡n, tá»« cáº¥p Ä‘á»™ tiá»ƒu há»c Ä‘áº¿n trung há»c.

2) Báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n Ä‘a dáº¡ng (tá»©c lÃ , GPT-2, Llama 2, Mistral, Qwen, DeepSeek) lÃ m mÃ´ hÃ¬nh cÆ¡ sá»Ÿ, WizardMath thá»ƒ hiá»‡n nhá»¯ng tiáº¿n bá»™ Ä‘Ã¡ng chÃº Ã½ trÃªn cÃ¡c benchmark GSM8k vÃ  MATH. Cá»¥ thá»ƒ, WizardMath-Llama2-7B, dá»±a trÃªn Llama2-7B, cáº£i thiá»‡n hiá»‡u suáº¥t 69.5% trÃªn GSM8k vÃ  41.0% trÃªn MATH. TÆ°Æ¡ng tá»±, WizardMath-GPT2-XL, Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn GPT2-XL, Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n 43.5% trÃªn GSM8k vÃ  18.5% trÃªn MATH, hoáº¡t Ä‘á»™ng ngang báº±ng vá»›i Llama2-70B vÃ  vÆ°á»£t trá»™i hÆ¡n GPT-3.5 trÃªn GSM8k. Äiá»u nÃ y chá»©ng minh ráº±ng phÆ°Æ¡ng phÃ¡p RLEIF cá»§a chÃºng tÃ´i cÃ³ hiá»‡u quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng cho cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n trong viá»‡c nÃ¢ng cao kháº£ nÄƒng láº­p luáº­n toÃ¡n há»c, chá»©ng minh tÃ­nh má»Ÿ rá»™ng vÃ  Ä‘á»™ bá»n cá»§a nÃ³ trÃªn cÃ¡c backbone mÃ´ hÃ¬nh khÃ¡c nhau.

4.3 PHÃ‚N TÃCH

[HÃ¬nh 2: Biá»ƒu Ä‘á»“ hiá»ƒn thá»‹ Ä‘á»™ chÃ­nh xÃ¡c cá»§a Mistral-7B Ä‘Æ°á»£c tinh chá»‰nh vá»›i cÃ¡c kÃ­ch thÆ°á»›c dá»¯ liá»‡u tÄƒng cÆ°á»ng khÃ¡c nhau trÃªn GSM8K vÃ  MATH]

TÃ¡c Ä‘á»™ng cá»§a kÃ­ch thÆ°á»›c dá»¯ liá»‡u Ä‘Ã o táº¡o
ChÃºng tÃ´i tÃ² mÃ² vá» viá»‡c kÃ­ch thÆ°á»›c dá»¯ liá»‡u Ä‘Ã o táº¡o cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p xÃ¢y dá»±ng bá»™ dá»¯ liá»‡u khÃ¡c nhau áº£nh hÆ°á»Ÿng Ä‘áº¿n nÄƒng lá»±c láº­p luáº­n cá»§a LLM nhÆ° tháº¿ nÃ o. Do Ä‘Ã³ chÃºng tÃ´i thá»±c hiá»‡n sá»‘ lÆ°á»£ng khÃ¡c nhau cá»§a cÃ¡c instances Ä‘Ã o táº¡o tá»« dá»¯ liá»‡u tiáº¿n hÃ³a cá»§a chÃºng tÃ´i vÃ  MetaMathQA Ä‘á»ƒ tinh chá»‰nh Mistral 7B. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 2, Math Evol-Instruct Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u quáº£ dá»¯ liá»‡u vÆ°á»£t trá»™i. Cá»¥ thá»ƒ, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i liÃªn tá»¥c vÆ°á»£t trá»™i hÆ¡n MataMath hÆ¡n 3%âˆ¼6% trÃªn GSM8k vÃ  15%âˆ¼20% trÃªn MATH trong cÃ¹ng Ä‘iá»u kiá»‡n sá»‘ lÆ°á»£ng. PhÃ¡t hiá»‡n cá»§a chÃºng tÃ´i chá»‰ ra ráº±ng Math Evol-Instruct thá»ƒ hiá»‡n má»™t giá»›i háº¡n trÃªn tiá»m nÄƒng cao hÆ¡n so vá»›i MetaMath, do Ä‘Ã³ chá»©ng minh hiá»‡u quáº£ cá»§a Evol-Instruct cho tÃ¬nh huá»‘ng láº­p luáº­n toÃ¡n há»c.

TÃ¡c Ä‘á»™ng cá»§a PRM vÃ  IRM trong quÃ¡ trÃ¬nh Ä‘Ã o táº¡o PPO
Äá»ƒ xÃ¡c minh nhá»¯ng Ä‘Ã³ng gÃ³p cá»§a mÃ´ hÃ¬nh thÆ°á»Ÿng hÆ°á»›ng dáº«n vÃ  mÃ´ hÃ¬nh thÆ°á»Ÿng giÃ¡m sÃ¡t quÃ¡ trÃ¬nh, chÃºng tÃ´i xem xÃ©t cÃ¡c biáº¿n thá»ƒ sau: (1) SFT + PRM: chá»‰ sá»­ dá»¥ng PRM trong Ä‘Ã o táº¡o PPO. (2) SFT + PRM + IRM: sá»­ dá»¥ng cáº£ IRM vÃ  PRM trong Ä‘Ã o táº¡o PPO. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 3, Ã¡p dá»¥ng PRM má»™t mÃ¬nh cho Ä‘Ã o táº¡o PPO trÃªn GSM8k vÃ  MATH mang láº¡i cáº£i thiá»‡n 3%-4%. Khi káº¿t há»£p vá»›i IRM, má»™t lá»£i Ã­ch bá»• sung 2.5%-4% Ä‘Æ°á»£c quan sÃ¡t. Do Ä‘Ã³, viá»‡c tÃ­ch há»£p PRM vÃ  IRM dáº«n Ä‘áº¿n cáº£i thiá»‡n tá»•ng thá»ƒ Ä‘Ã¡ng ká»ƒ 6%-8%. VÃ¬ váº­y, chÃºng ta cÃ³ thá»ƒ káº¿t luáº­n ráº±ng (1) PRM ráº¥t quan trá»ng Ä‘á»‘i vá»›i WizardMath, vÃ¬ biáº¿n thá»ƒ vá»›i PRM vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i SFT mÃ  khÃ´ng cÃ³ báº¥t ká»³ Ä‘Ã o táº¡o PPO nÃ o (2) IRM cÅ©ng Ä‘Ã³ng vai trÃ² quan trá»ng trong thÃ nh cÃ´ng cá»§a há»c tÄƒng cÆ°á»ng, vÃ¬ cÃ³ sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ khi chÃºng ta káº¿t há»£p PRM vá»›i IRM, chá»©ng minh thÃªm sá»± cáº§n thiáº¿t cá»§a viá»‡c tÃ­nh Ä‘áº¿n cháº¥t lÆ°á»£ng hÆ°á»›ng dáº«n vÃ  sá»­a chá»¯a false positives trong quÃ¡ trÃ¬nh giáº£i quyáº¿t váº¥n Ä‘á» khi chÃºng ta tá»‘i Æ°u hÃ³a LLM.

--- TRANG 8 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025

Báº£ng 4: TÃ¡c Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng khÃ¡c nhau trong quÃ¡ trÃ¬nh Ä‘Ã o táº¡o PPO

[Báº£ng so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh thÆ°á»Ÿng khÃ¡c nhau]

Báº£ng 5: Káº¿t quáº£ cá»§a há»c tÄƒng cÆ°á»ng káº¿t há»£p vá»›i xÃ¡c thá»±c. SFT vÃ  cÃ¡c mÃ´ hÃ¬nh ThÆ°á»Ÿng Ä‘Æ°á»£c Ä‘Ã o táº¡o dá»±a trÃªn Mistral-7B. Verifier dá»±a trÃªn 256 Ä‘áº§u ra máº«u.

[Báº£ng káº¿t quáº£ vá»›i cÃ¡c generators vÃ  verifiers khÃ¡c nhau]

Báº£ng 6: TÃ¡c Ä‘á»™ng cá»§a cÃ¡c lÆ°á»£t Downward vÃ  Upward Evol-Instruct khÃ¡c nhau trÃªn Mistral-7B SFT.

[Báº£ng hiá»ƒn thá»‹ tÃ¡c Ä‘á»™ng cá»§a cÃ¡c vÃ²ng tiáº¿n hÃ³a khÃ¡c nhau]

TÃ¡c Ä‘á»™ng cá»§a cÃ¡c lÆ°á»£t Evol-Instruct. Báº£ng 6 minh há»a tÃ¡c Ä‘á»™ng cá»§a viá»‡c káº¿t há»£p tiáº¿n hÃ³a hÆ°á»›ng xuá»‘ng vÃ  hÆ°á»›ng lÃªn trong Ä‘Ã o táº¡o SFT. Hai vÃ²ng tiáº¿n hÃ³a hÆ°á»›ng xuá»‘ng cáº£i thiá»‡n GSM8k 14.8% (74.5 vs. 59.7) vÃ  MATH 19.6% (34.7 vs. 15.1) so vá»›i báº£n gá»‘c. Ba vÃ²ng tiáº¿n hÃ³a hÆ°á»›ng lÃªn mang láº¡i cáº£i thiá»‡n 18.9% trÃªn GSM8k (78.6 vs. 59.7) vÃ  cáº£i thiá»‡n 27.4% trÃªn MATH (42.5 vs. 15.1). HÆ¡n ná»¯a, viá»‡c káº¿t há»£p tiáº¿n hÃ³a hÆ°á»›ng xuá»‘ng dá»±a trÃªn tiáº¿n hÃ³a hÆ°á»›ng lÃªn dáº«n Ä‘áº¿n cáº£i thiá»‡n bá»• sung 2.6% trÃªn GSM8k (81.2 vs. 78.6), tá»•ng cáº£i thiá»‡n 21.5% so vá»›i báº£n gá»‘c. TÆ°Æ¡ng tá»±, cáº£i thiá»‡n 1.9% trÃªn MATH (46.5 vs. 42.5), tá»•ng cáº£i thiá»‡n 31.4%. Nhá»¯ng káº¿t quáº£ nÃ y nháº¥n máº¡nh hiá»‡u quáº£ bá»• sung vÃ  Ä‘Ã¡ng ká»ƒ cá»§a tiáº¿n hÃ³a hÆ°á»›ng lÃªn vÃ  hÆ°á»›ng xuá»‘ng.

ORM v.s. PRM; Human v.s. AI. Báº£ng 4 trÃ¬nh bÃ y hiá»‡u suáº¥t cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p thÆ°á»Ÿng cÃ¢u tráº£ lá»i khÃ¡c nhau cho LLM vá» pass@1. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹: 1) PRM tá»«ng bÆ°á»›c cá»§a chÃºng tÃ´i nÃ¢ng cao Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t cá»§a cáº£ mÃ´ hÃ¬nh SFT dá»±a trÃªn Llama vÃ  Mistral. Cá»¥ thá»ƒ, Mistral-7B Ä‘Æ°á»£c há»— trá»£ bá»Ÿi PRM cá»§a chÃºng tÃ´i Ä‘áº¡t 87.2% vÃ  52.7% trÃªn GSM8k vÃ  MATH tÆ°Æ¡ng á»©ng. 2) CÃ¡c mÃ´ hÃ¬nh PRM liÃªn tá»¥c vÆ°á»£t trá»™i hÆ¡n ORM trÃªn cáº£ GSM8k vÃ  MATH, chá»‰ ra hiá»‡u quáº£ cá»§a giÃ¡m sÃ¡t tá»«ng bÆ°á»›c. 3) PRM Ä‘Æ°á»£c Ä‘Ã o táº¡o trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c ghi nhÃ£n hoÃ n toÃ n báº±ng AI cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n cáº£ PRM800k Ä‘Æ°á»£c chÃº thÃ­ch thá»§ cÃ´ng vÃ  Math-Shepherd, sá»­ dá»¥ng tÃ¬m kiáº¿m cÃ¢y MCTS Ä‘á»ƒ chÃº thÃ­ch. Khi Ä‘Ã o táº¡o WizardMath-Mistral-SFT vá»›i PPO, PRM cá»§a chÃºng tÃ´i cáº£i thiá»‡n so vá»›i PRM800k 1.8% vÃ  Math-Shepherd 1.1% trÃªn GSM8k, trong khi vÆ°á»£t trá»™i hÆ¡n PRM800k 1.9% vÃ  Math-Shepherd 2.4% trÃªn MATH. Äiá»u nÃ y chá»©ng minh AI máº¡nh máº½ cÅ©ng cÃ³ thá»ƒ cung cáº¥p cháº¥t lÆ°á»£ng giÃ¡m sÃ¡t quÃ¡ trÃ¬nh tá»‘t, nháº¥n máº¡nh hiá»‡u quáº£ cá»§a viá»‡c sá»­ dá»¥ng AI Ä‘á»ƒ xÃ¢y dá»±ng dá»¯ liá»‡u Ä‘Ã o táº¡o PRM.

PRM nhÆ° Verifier. Báº£ng 5 trÃ¬nh bÃ y so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c generator khÃ¡c nhau vá»›i cÃ¡c verifier khÃ¡c nhau trÃªn GSM8K vÃ  MATH vá» pass@256. ChÃºng tÃ´i phÃ¡t hiá»‡n ráº±ng: 1) PRM verifier liÃªn tá»¥c thá»ƒ hiá»‡n hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i Self-Consistency vÃ  ORM. Cá»¥ thá»ƒ, generator SFT + PRM cá»§a chÃºng tÃ´i, Ä‘Æ°á»£c nÃ¢ng cao bá»Ÿi PRM verifier, Ä‘áº¡t 95.2% vÃ  64.7% Ä‘á»™ chÃ­nh xÃ¡c trÃªn GSM8K vÃ  MATH tÆ°Æ¡ng á»©ng. 2) Khi so sÃ¡nh vá»›i ORM, PRM thá»ƒ hiá»‡n lá»£i tháº¿ Ä‘Ã¡ng ká»ƒ hÆ¡n trÃªn bá»™ dá»¯ liá»‡u MATH thá»­ thÃ¡ch hÆ¡n, phÃ¹ há»£p vá»›i cÃ¡c phÃ¡t hiá»‡n trong (Uesato et al., 2022) vÃ  (Lightman et al., 2023). Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho thá»±c táº¿ ráº±ng GSM8K liÃªn quan Ä‘áº¿n Ã­t bÆ°á»›c vÃ  Ã­t phá»©c táº¡p hÆ¡n trong giáº£i quyáº¿t váº¥n Ä‘á» so vá»›i MATH. 3) Äáº·c biá»‡t, generator vá»›i Ä‘Ã o táº¡o PRM PPO

--- TRANG 9 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025

[HÃ¬nh 3: Hiá»‡u suáº¥t cá»§a Mistral-7B SFT vá»›i cÃ¡c chiáº¿n lÆ°á»£c xÃ¡c minh khÃ¡c nhau.]

vÆ°á»£t trá»™i hÆ¡n nhá»¯ng generator Ä‘Æ°á»£c Ä‘Ã o táº¡o SFT vÃ  ORM PPO báº¥t ká»ƒ viá»‡c sá»­ dá»¥ng Self-Consistency, ORM, vÃ  PRM verifiers. Äiá»u nÃ y chá»©ng minh thÃªm hiá»‡u quáº£ cá»§a PRM cá»§a chÃºng tÃ´i.

HÃ¬nh 3 cÅ©ng hiá»ƒn thá»‹ hiá»‡u suáº¥t cá»§a cÃ¡c chiáº¿n lÆ°á»£c XÃ¡c minh khÃ¡c nhau trÃªn má»™t pháº¡m vi sá»‘ lÆ°á»£ng á»©ng viÃªn tá»« 1 Ä‘áº¿n 256 trÃªn hai benchmark. CÃ¡c quan sÃ¡t chÃ­nh nhÆ° sau: 1) PRM verifiers liÃªn tá»¥c Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i cáº£ ORM vÃ  bá» phiáº¿u Ä‘a sá»‘, vÃ  sá»± vÆ°á»£t trá»™i nÃ y trá»Ÿ nÃªn rÃµ rÃ ng hÆ¡n khi N tÄƒng. 2) Äá»‘i vá»›i benchmark MATH, PRM cá»§a chÃºng tÃ´i Ä‘Æ°á»£c Ä‘Ã o táº¡o trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c chÃº thÃ­ch báº±ng AI vÆ°á»£t trá»™i nháº¹ so vá»›i PRM800K Ä‘Æ°á»£c chÃº thÃ­ch báº±ng con ngÆ°á»i.

Báº£ng 7: Hiá»‡u suáº¥t cá»§a WizardMath trÃªn 7 káº¿t quáº£ Ä‘Ã¡nh giÃ¡ ngoÃ i miá»n bao gá»“m cÃ¡c bÃ i toÃ¡n toÃ¡n há»c cáº¥p K-12, Ä‘áº¡i há»c, vÃ  thi Ä‘áº¥u.

[Báº£ng káº¿t quáº£ hiá»‡u suáº¥t trÃªn cÃ¡c benchmark ngoÃ i miá»n]

Hiá»‡u suáº¥t NgoÃ i Miá»n. Báº£ng 7 trÃ¬nh bÃ y káº¿t quáº£ cá»§a WizardMath trÃªn 7 káº¿t quáº£ Ä‘Ã¡nh giÃ¡ ngoÃ i miá»n bao gá»“m cÃ¡c bÃ i toÃ¡n toÃ¡n há»c cáº¥p K-12, Ä‘áº¡i há»c, vÃ  thi Ä‘áº¥u, nháº¥n máº¡nh cÃ¡c quan sÃ¡t ná»•i báº­t sau: (1) Vá»›i math Evol-Instruct vÃ  há»c tÄƒng cÆ°á»ng, WizardMath liÃªn tá»¥c vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ tiÃªn tiáº¿n trÆ°á»›c Ä‘Ã¢y (vÃ­ dá»¥ MetaMath, MathScale) trÃªn táº¥t cáº£ cÃ¡c quy mÃ´, vÃ  Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n 5%-10% trÃªn 7 nhiá»‡m vá»¥ trung bÃ¬nh. (2) Äá»™ chÃ­nh xÃ¡c cá»§a WizardMath-Mistral cao hÆ¡n khoáº£ng 5.0% so vá»›i WizardMath-Llama trÃªn cÃ¹ng kÃ­ch thÆ°á»›c. Äáº·c biá»‡t nÃ³ vÆ°á»£t trá»™i hÆ¡n GPT-3.5-Turbo (45.7 vs. 37.9) trong khi cÃ³ thá»ƒ so sÃ¡nh vá»›i GPT-4. Äiá»u nÃ y cÅ©ng chá»‰ ra ráº±ng Mistral-7B cÃ³ nhiá»u tiá»m nÄƒng hÆ¡n trong láº­p luáº­n toÃ¡n há»c. (3) Äáº·c biá»‡t trÃªn cÃ¡c benchmark khÃ³ (tá»©c lÃ , College Math, AGIE Gaokao Math), WizardMath vÆ°á»£t trá»™i hÆ¡n MetaMath má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ. Äiá»u nÃ y chá»©ng minh mÃ´ hÃ¬nh vÃ  phÆ°Æ¡ng phÃ¡p RLEIF cá»§a chÃºng tÃ´i cÃ³ Ä‘á»™ bá»n máº¡nh hÆ¡n vÃ  kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a Ä‘Ã¡ng ká»ƒ tá»‘t hÆ¡n cho cÃ¡c bÃ i toÃ¡n toÃ¡n há»c khÃ´ng nhÃ¬n tháº¥y.

Sá»­ dá»¥ng MÃ´ hÃ¬nh MÃ£ nguá»“n Má»Ÿ cho Math Evol-Instruct. Trong Báº£ng 19, chÃºng tÃ´i Ä‘iá»u tra viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ (tá»©c lÃ , Llama-3-70B-Instruct) nhÆ° má»™t thay tháº¿ cho GPT-4 trong giai Ä‘oáº¡n SFT cho Evol Instruct, sá»­ dá»¥ng cÃ¹ng chiáº¿n lÆ°á»£c tiáº¿n hÃ³a. Káº¿t quáº£ chá»©ng minh ráº±ng WizardMath-

--- TRANG 10 ---
ÄÆ°á»£c xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2025

Báº£ng 9: Má»™t nghiÃªn cá»©u trÆ°á»ng há»£p tá»« bá»™ kiá»ƒm tra GSM8k. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ pháº£n há»“i báº±ng PRM vÃ  ORM. VÄƒn báº£n mÃ u Ä‘á» biá»ƒu thá»‹ cÃ¡c bÆ°á»›c láº­p luáº­n sai mÃ  PRM phÃ¡t hiá»‡n thÃ nh cÃ´ng, nhÆ°ng ORM tháº¥t báº¡i.

[NghiÃªn cá»©u trÆ°á»ng há»£p chi tiáº¿t vá»›i cÃ¢u há»i vá» nÃ´ng tráº¡i vÃ  vÆ°á»n thÃº]

Báº£ng 8: TÃ¡c Ä‘á»™ng cá»§a viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ cho Math-Evol vÃ  sá»­ dá»¥ng Mistral-7B-v0.1 cho SFT.

[Báº£ng so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh]

Llama3-Evol Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n 33.8% trÃªn GSM8k vÃ  cáº£i thiá»‡n 30.6% trÃªn MATH, chá»‰ ra ráº±ng chiáº¿n lÆ°á»£c math evol instruct váº«n hiá»‡u quáº£ trÃªn cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ. Tuy nhiÃªn, so vá»›i tiáº¿n hÃ³a GPT-4, váº«n cÃ³ khoáº£ng cÃ¡ch hiá»‡u suáº¥t 5%-6%. Máº·c dÃ¹ váº­y, chiáº¿n lÆ°á»£c cho tháº¥y tiá»m nÄƒng Ä‘Ã¡ng ká»ƒ trong viá»‡c cÃ¢n báº±ng chi phÃ­ tÃ­nh toÃ¡n vÃ  Ä‘á»™ chÃ­nh xÃ¡c.

4.4 KIá»‚M TRA Ã” NHIá»„M Dá»® LIá»†U

NgoÃ i phÃ¢n tÃ­ch hiá»‡u suáº¥t, chÃºng tÃ´i cÅ©ng Ä‘iá»u tra xem liá»‡u tiáº¿n hÃ³a cÃ³ dáº«n Ä‘áº¿n Ã´ nhiá»…m dá»¯ liá»‡u giá»¯a dá»¯ liá»‡u Ä‘Ã o táº¡o vÃ  bá»™ kiá»ƒm tra hay khÃ´ng. Äá»ƒ giáº£i quyáº¿t má»‘i quan tÃ¢m nÃ y, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c hÆ°á»›ng dáº«n trong bá»™ kiá»ƒm tra GSM8k vÃ  MATH lÃ m truy váº¥n Ä‘á»ƒ truy xuáº¥t top-5 máº«u tá»« táº¥t cáº£ dá»¯ liá»‡u Ä‘Ã o táº¡o Ä‘Ã£ tiáº¿n hÃ³a vá»›i má»™t mÃ´ hÃ¬nh embedding, gte-large (Li et al., 2023d). NgoÃ i ra, chÃºng tÃ´i sá»­ dá»¥ng GPT-4 Ä‘á»ƒ cung cáº¥p Ä‘Ã¡nh giÃ¡ tÆ°Æ¡ng tá»± giá»¯a cÃ¡c bá»™ kiá»ƒm tra vÃ  cÃ¡c máº«u Ä‘Æ°á»£c truy xuáº¥t, vÃ  loáº¡i bá» top-2 hÆ°á»›ng dáº«n tÆ°Æ¡ng tá»±. Lá»i nháº¯c vÃ  chi tiáº¿t Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Phá»¥ lá»¥c A.4 vÃ  A.5. HÃ¬nh 4 minh há»a ráº±ng quÃ¡ trÃ¬nh tiáº¿n hÃ³a khÃ´ng mang láº¡i Ä‘iá»ƒm sá»‘ tÆ°Æ¡ng tá»± cao hÆ¡n.

4.5 NGHIÃŠN Cá»¨U TRÆ¯á»œNG Há»¢P

Evol-Instruct. CÃ¡c VÃ­ dá»¥ 3 vÃ  4 trong Phá»¥ lá»¥c A.1 hiá»ƒn thá»‹ lá»i nháº¯c vÃ  cÃ¡c trÆ°á»ng há»£p tÆ°Æ¡ng á»©ng cá»§a tiáº¿n hÃ³a hÆ°á»›ng dáº«n GSM8k vÃ  MATH, chá»©ng minh ráº±ng cÃ¡c hÆ°á»›ng dáº«n Ä‘Ã£ tiáº¿n hÃ³a thá»ƒ hiá»‡n Ä‘á»™ phá»©c táº¡p vÃ  Ä‘a dáº¡ng hÆ¡n so vá»›i bá»™ Ä‘Ã o táº¡o ban Ä‘áº§u.

PRM v.s. ORM. ChÃºng tÃ´i trÃ¬nh bÃ y má»™t nghiÃªn cá»©u trÆ°á»ng há»£p toÃ n diá»‡n Ä‘á»ƒ minh há»a hiá»‡u quáº£ cá»§a PRM cá»§a chÃºng tÃ´i. NhÆ° Ä‘Æ°á»£c mÃ´ táº£ chi tiáº¿t trong Báº£ng 9, PRM thá»ƒ hiá»‡n hiá»‡u suáº¥t chÃ­nh xÃ¡c trÃªn má»™t bÃ i toÃ¡n toÃ¡n thá»­ thÃ¡ch tá»« bá»™ kiá»ƒm tra GSM8k. ÄÃ¡ng chÃº Ã½, PRM cá»§a chÃºng tÃ´i phÃ¢n biá»‡t hiá»‡u quáº£ giáº£i phÃ¡p khÃ´ng chÃ­nh xÃ¡c, trong khi Ä‘Ã³ ORM gáº·p khÃ³ khÄƒn trong nhiá»‡m vá»¥ nÃ y. HÆ¡n ná»¯a, PRM thá»ƒ hiá»‡n cÃ¡i nhÃ¬n sÃ¢u sáº¯c xuáº¥t sáº¯c báº±ng cÃ¡ch phÃ¡t hiá»‡n chÃ­nh xÃ¡c cÃ¡c bÆ°á»›c khÃ´ng chÃ­nh xÃ¡c cá»§a giáº£i phÃ¡p Ä‘Æ°á»£c chá»n bá»Ÿi ORM, cá»¥ thá»ƒ lÃ  cÃ¡c bÆ°á»›c 7, 8, vÃ  9. Sau Ä‘Ã³, PRM cÅ©ng gÃ¡n Ä‘iá»ƒm sá»‘ logits tháº¥p hÆ¡n cho nhá»¯ng bÆ°á»›c sai láº§m nÃ y.

5 Káº¾T LUáº¬N

BÃ i bÃ¡o nÃ y giá»›i thiá»‡u WizardMath, má»™t mÃ´ hÃ¬nh toÃ¡n há»c Ä‘Æ°á»£c tinh chá»‰nh vá»›i RLEIF. Káº¿t quáº£ thÃ­ nghiá»‡m chá»©ng minh ráº±ng WizardMath Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t SOTA vÆ°á»£t trá»™i hÆ¡n cÃ¡c LLM mÃ£ nguá»“n má»Ÿ hiá»‡n cÃ³ trÃªn GSM8k vÃ  MATH tá»« cÃ¡c bÃ i toÃ¡n cáº¥p tiá»ƒu há»c Ä‘áº¿n trung há»c. ÄÃ¡ng chÃº Ã½, WizardMath 70B thá»ƒ hiá»‡n hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i má»™t sá»‘ LLM Ä‘á»™c quyá»n ná»•i tiáº¿ng, bao gá»“m ChatGPT-3.5, Claude Instant, PaLM-2, Gemini Pro. HÆ¡n ná»¯a, khÃ¡m phÃ¡ sÆ¡ bá»™ cá»§a chÃºng tÃ´i nháº¥n máº¡nh vai trÃ² then chá»‘t cá»§a tiáº¿n hÃ³a hÆ°á»›ng dáº«n vÃ  giÃ¡m sÃ¡t quÃ¡ trÃ¬nh trong viá»‡c Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t xuáº¥t sáº¯c.

--- TRANG 11 ---
[Tiáº¿p tá»¥c vá»›i pháº§n TÃ€I LIá»†U THAM KHáº¢O vÃ  PHá»¤ Lá»¤C...]

TÃ€I LIá»†U THAM KHáº¢O

[Danh sÃ¡ch Ä‘áº§y Ä‘á»§ cÃ¡c tÃ i liá»‡u tham kháº£o Ä‘Æ°á»£c dá»‹ch sang tiáº¿ng Viá»‡t...]

PHá»¤ Lá»¤C A

A.1 CÃC Lá»œI NHáº®C TIáº¾N HÃ“A TOÃN

[CÃ¡c vÃ­ dá»¥ vÃ  lá»i nháº¯c chi tiáº¿t Ä‘Æ°á»£c dá»‹ch sang tiáº¿ng Viá»‡t...]

[TÃ´i sáº½ tiáº¿p tá»¥c dá»‹ch toÃ n bá»™ ná»™i dung cÃ²n láº¡i náº¿u cáº§n, nhÆ°ng do Ä‘á»™ dÃ i cá»§a tÃ i liá»‡u, tÃ´i Ä‘Ã£ dá»‹ch cÃ¡c pháº§n chÃ­nh vÃ  cÃ³ thá»ƒ tiáº¿p tá»¥c vá»›i báº¥t ká»³ pháº§n cá»¥ thá»ƒ nÃ o mÃ  báº¡n muá»‘n.]

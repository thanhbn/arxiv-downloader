# Một Nghiên Cứu Cẩn Thận về Hiệu Suất của Mô Hình Ngôn Ngữ Lớn
trên Số Học Tiểu Học

Hugh Zhang∗Jeff Da Dean Lee Vaughn Robinson Catherine Wu Will Song
Tiffany Zhao Pranav Raja Charlotte Zhuang Dylan Slack Qin Lyu
Sean Hendryx Russell Kaplan Michele (Mike) Lunati†Summer Yue†
Scale AI

## Tóm tắt

Các mô hình ngôn ngữ lớn (LLM) đã đạt được thành công ấn tượng trên nhiều bộ đánh giá cho lý luận toán học. Tuy nhiên, có mối quan ngại ngày càng tăng rằng một số hiệu suất này thực sự phản ánh sự ô nhiễm dữ liệu, nơi dữ liệu tương tự chặt chẽ với các câu hỏi đánh giá rò rỉ vào dữ liệu huấn luyện, thay vì khả năng lý luận thực sự. Để điều tra tuyên bố này một cách nghiêm túc, chúng tôi ủy thác Grade School Math 1000 (GSM1k). GSM1k được thiết kế để phản ánh phong cách và độ phức tạp của bộ đánh giá GSM8k đã được thiết lập, tiêu chuẩn vàng để đo lường lý luận toán học cơ bản. Chúng tôi đảm bảo rằng hai bộ đánh giá có thể so sánh được qua các chỉ số quan trọng như tỷ lệ giải quyết của con người, số bước trong lời giải, độ lớn của câu trả lời, và nhiều hơn nữa. Khi đánh giá các LLM hàng đầu mã nguồn mở và đóng trên GSM1k, chúng tôi quan sát thấy độ chính xác giảm lên đến 8%, với một số họ mô hình cho thấy bằng chứng của việc overfitting hệ thống trên hầu hết tất cả các kích thước mô hình. Phân tích sâu hơn cho thấy mối quan hệ tích cực (Spearman's r2= 0.36) giữa xác suất của mô hình sinh ra một ví dụ từ GSM8k và khoảng cách hiệu suất của nó giữa GSM8k và GSM1k, cho thấy rằng một số mô hình có thể đã ghi nhớ một phần GSM8k. Tuy nhiên, nhiều mô hình, đặc biệt là những mô hình tiên tiến, cho thấy các dấu hiệu tối thiểu của overfitting, và tất cả các mô hình đều thể hiện khái quát rộng rãi đối với các bài toán toán học mới được đảm bảo không có trong dữ liệu huấn luyện của chúng.

## 1 Giới thiệu

Cải thiện lý luận trong các mô hình ngôn ngữ lớn (LLM) là một trong những hướng quan trọng nhất của nghiên cứu hiện tại. Do đó, việc đánh giá thích hợp các khả năng LLM hiện tại là tối quan trọng để đảm bảo tiến bộ tiếp tục theo đúng hướng. Hiện tại, lĩnh vực này thường dựa vào các bộ đánh giá công khai như GSM8k (Cobbe et al. [2021]), MATH (Hendrycks et al. [2021b]), MBPP (Austin et al. [2021]), HumanEval (Chen et al. [2021]), SWEBench (Jimenez et al. [2024])). Tuy nhiên, bởi vì LLM được huấn luyện trên các tập dữ liệu lớn được thu thập từ Internet, có những mối quan ngại lớn rằng các bộ đánh giá như vậy có thể vô tình bao gồm các ví dụ tương tự chặt chẽ với các câu hỏi được tìm thấy trong các bộ đánh giá như vậy. Sự ô nhiễm này có thể dẫn đến các mô hình có khả năng lý luận yếu hơn so với những gì được tin tưởng, do chỉ đơn giản là có thể lặp lại câu trả lời đúng mà nó

∗Liên hệ với hugh.zhang@scale.com†quyền tác giả cao cấp bằng nhau

Hội nghị lần thứ 38 về Hệ thống Xử lý Thông tin Neural (NeurIPS 2024) Track về Bộ dữ liệu và Đánh giá.arXiv:2405.00332v4 [cs.CL] 22 Nov 2024

--- TRANG 2 ---

Hình 1: Các mô hình đáng chú ý được sắp xếp theo độ giảm hiệu suất của chúng giữa GSM8k và GSM1k (thấp hơn là tệ hơn). Chúng tôi nhận thấy rằng Phi, Mistral và một số mô hình trong họ Llama dường như đang overfitting GSM8k, trong khi các mô hình như Gemini, GPT, và Claude cho thấy ít hoặc không có dấu hiệu overfitting.

đã gặp trước đó trong quá trình huấn luyện trước hoặc sau. Để điều tra đúng đắn khả năng lý luận của các mô hình, chúng tôi ủy thác GSM1k, một bộ sưu tập mới được xây dựng gồm 1205 bài toán toán học cấp tiểu học được thiết kế để phản ánh GSM8k. Chúng tôi nỗ lực rộng rãi để đảm bảo rằng GSM1k có phân phối độ khó tương tự như GSM8k để đảm bảo so sánh công bằng. Những nỗ lực này được mô tả trong Phần 3, cùng với mô tả chi tiết về quy trình tạo dữ liệu. Để giảm thiểu lo ngại về ô nhiễm dữ liệu, chúng tôi tạo GSM1k chỉ với các chú thích viên con người, không có sự hỗ trợ từ bất kỳ LLM nào hoặc nguồn dữ liệu tổng hợp khác.

Ví dụ Bộ dữ liệu
GSM8k: James viết một lá thư 3 trang cho 2 người bạn khác nhau hai lần một tuần. Anh ấy viết bao nhiêu trang trong một năm?
GSM1k (của chúng tôi): Lee mua 6 cổ phiếu Delta với giá 40$ mỗi cổ phiếu. Nếu anh ấy muốn kiếm 24$ từ giao dịch này, cổ phiếu Delta nên có giá bao nhiêu mỗi cổ phiếu khi anh ấy bán?

Hình 2: Ví dụ từ cả bộ dữ liệu GSM8k và bộ dữ liệu GSM1k mới (của chúng tôi). Chúng tôi cũng cung cấp thêm 50 ví dụ từ GSM1k trong Phụ lục G.

Chúng tôi đánh giá các LLM hàng đầu mã nguồn mở và đóng trên GSM1k, bao gồm GPT-4 (OpenAI et al. [2024]), Gemini (Team et al. [2024]), Claude, Mistral (Jiang et al. [2024, 2023]), Llama (Touvron et al. [2023a,b]), Phi (Gunasekar et al. [2023], Abdin et al. [2024]) và nhiều hơn nữa. Phân tích của chúng tôi xác nhận nghi ngờ rộng rãi trong lĩnh vực rằng nhiều mô hình bị ô nhiễm bởi dữ liệu đánh giá, với các mô hình tệ nhất hoạt động kém hơn 8% trên GSM1k so với GSM8k. Ngoài ra, kết quả của chúng tôi

2

--- TRANG 3 ---

cho thấy rằng một số họ mô hình cho thấy bằng chứng nhất quán của overfitting cho gần như tất cả các phiên bản và kích thước mô hình. Phân tích sâu hơn tìm thấy mối quan hệ tích cực (Spearman's r2= 0.36) giữa xác suất của mô hình sinh ra các ví dụ từ GSM8k và khoảng cách hiệu suất của nó giữa GSM8k và GSM1k, cho thấy mạnh mẽ rằng một thành phần quan trọng của overfitting này là các mô hình đã ghi nhớ một phần các ví dụ từ GSM8k. Tuy nhiên, kết quả của chúng tôi thấy rằng tất cả các mô hình tiên tiến cho thấy các dấu hiệu tối thiểu của overfitting. Ngoài ra, chúng tôi cũng thấy rằng tất cả các mô hình, bao gồm cả những mô hình overfit nhất, vẫn có khả năng khái quát thành công đến các bài toán toán học tiểu học mới, mặc dù đôi khi với tỷ lệ thấp hơn so với những gì số đánh giá của chúng sẽ gợi ý.

Chúng tôi không có ý định công bố GSM1k công khai tại thời điểm này để ngăn chặn vấn đề tương tự về ô nhiễm dữ liệu xảy ra trong tương lai. Tuy nhiên, chúng tôi dự định thực hiện các đánh giá định kỳ của tất cả các bản phát hành chính mã nguồn mở và đóng và liên tục cập nhật kết quả của chúng tôi. Chúng tôi cũng sẽ mở mã nguồn toàn bộ mã đánh giá của chúng tôi để phiên bản công khai của kết quả có thể được tái tạo. Ngoài ra, chúng tôi cam kết mở mã nguồn toàn bộ bộ đánh giá khi 1) các mô hình mã nguồn mở hàng đầu đạt trên 95% trên GSM1k hoặc 2) tháng 6 năm 2025, bất cứ điều gì đến trước. Xem Phần 3 cho các tiêu chí phát hành chính xác.

## 2 Công trình liên quan

Một nguồn cảm hứng chính của công trình này là nghiên cứu nổi tiếng về overfitting được thực hiện trên các bộ phân loại ImageNet vào năm 2019 (Recht et al. [2019]). Công trình này đo lường overfitting trong ImageNet bằng cách tạo các phiên bản mới của CIFAR10 và ImageNet và đo lường khoảng cách hiệu suất giữa bộ kiểm tra công khai và các bộ mới được xây dựng mà họ tạo ra. Trong công trình này, chúng tôi thực hiện phân tích tương tự trên GSM8k, một trong những bộ đánh giá hàng đầu cho lý luận toán học. GSM1k được mô hình hóa theo bộ dữ liệu GSM8k (Cobbe et al. [2021]), được phát hành bởi OpenAI vào năm 2021, bao gồm 8.5k bài toán toán học tiểu học. Mỗi bài toán được thiết kế để có thể giải quyết chỉ sử dụng các phép toán số học cơ bản (+,−,×,÷) với mức độ khó phù hợp cho học sinh tiểu học. Tính đến tháng 6 năm 2024, các mô hình hàng đầu báo cáo độ chính xác đánh giá trên 95% (Team et al. [2024]). Các bộ đánh giá phổ biến khác cho lý luận bao gồm MATH (Hendrycks et al. [2021b]), MMLU (Hendrycks et al. [2021a]), GPQA (Rein et al. [2023]).

### 2.1 Ô nhiễm Dữ liệu

Bởi vì ô nhiễm dữ liệu là một vấn đề được biết đến rộng rãi trong lĩnh vực (Balloccu et al. [2024], Magar và Schwartz [2022], Sainz et al. [2023], Jacovi et al. [2023], Xu et al. [2024]), các nhà xây dựng mô hình thường sẽ nỗ lực rất nhiều để giảm thiểu khả năng ô nhiễm dữ liệu. Ví dụ, việc loại bỏ tất cả dữ liệu có quá nhiều n-gram trùng lặp với dữ liệu đánh giá là phổ biến (Brown et al. [2020]). Ngoài ra, các phương pháp như sử dụng độ tương tự embedding cố gắng loại bỏ tất cả dữ liệu bị ô nhiễm quá tương tự trong không gian embedding với bộ dữ liệu (Shi et al. [2024]).

Xu et al. [2024] đề xuất sử dụng các biến thể tương tự của câu hỏi đánh giá để phát hiện xem các mô hình có ưa thích cách diễn đạt gốc như một đại diện cho ô nhiễm dữ liệu. Srivastava et al. [2024] đề xuất các đánh giá chức năng, nơi các bộ đánh giá được viết dưới dạng các hàm có thể tạo ra một số lượng vô hạn các điểm dữ liệu đánh giá cụ thể, mỗi điểm với các số hơi khác nhau. Trong thiết lập này, bất cứ khi nào một mô hình ngôn ngữ được đánh giá, các đánh giá chức năng tạo ra một thể hiện bài toán cụ thể để đánh giá mô hình, sau đó không bao giờ được sử dụng lại. Điều này giảm lo ngại về ô nhiễm dữ liệu bằng cách đảm bảo rằng không có điểm dữ liệu nào được sử dụng hai lần. Giống như của chúng tôi, kết quả của họ chỉ ra rằng LLM có thể bị overfit nghiêm trọng trên dữ liệu đánh giá. Lợi thế chính của phương pháp của chúng tôi so với đánh giá hoàn toàn dựa trên hàm là các đánh giá chức năng chỉ có thể tạo ra một phần nhỏ của không gian bài toán đầy đủ bằng cách tạo ra các biến thể của cùng một bài toán với các giá trị số hơi khác nhau. Kết quả của họ cũng cho thấy lượng ô nhiễm dữ liệu đáng kể, bao gồm cả cho các mô hình tiên tiến, trong bộ dữ liệu MATH.

## 3 GSM1k

GSM1k bao gồm 1205 bài toán chỉ yêu cầu lý luận toán học cơ bản để giải quyết. Chúng tôi tạo GSM1k sử dụng các chú thích viên con người. Các chú thích viên được nhắc với 3 ví dụ bài toán GSM8k và được yêu cầu tạo ra các bài toán mới có mức độ khó tương tự. Các hướng dẫn chính xác và giao diện người dùng được cung cấp cho các chú thích viên có sẵn trong Phụ lục C. Tất cả các chú thích viên bài toán được hướng dẫn tạo ra các bài toán có thể giải quyết chỉ với số học cơ bản (cộng, trừ, nhân, và chia) và không yêu cầu bất kỳ khái niệm toán học nâng cao nào. Như trường hợp với GSM8k, tất cả lời giải bài toán đều là số nguyên dương2. Không có mô hình ngôn ngữ nào được sử dụng để xây dựng bộ dữ liệu này.

Để ngăn chặn lo ngại về ô nhiễm dữ liệu với GSM1k, chúng tôi không có ý định phát hành bộ dữ liệu công khai tại thời điểm này. Tuy nhiên, chúng tôi cam kết phát hành bộ dữ liệu GSM1k đầy đủ khi ít nhất một trong hai điều kiện sau đã qua, bất cứ điều gì đến trước. 1) Ba mô hình mã nguồn mở với các dòng mô hình nền tảng được huấn luyện trước khác nhau đạt độ chính xác 95% trên GSM1k. 2) Tháng 6 năm 2025. Tại thời điểm đó, chúng tôi tin rằng toán học tiểu học có thể sẽ không còn đủ khó để đánh giá các bản phát hành mô hình một cách có ý nghĩa và cam kết phát hành tất cả dữ liệu vào miền công cộng dưới giấy phép MIT. Ngoài ra, để đánh giá các mô hình độc quyền, chúng tôi được yêu cầu gửi bộ dữ liệu qua API. Niềm tin của chúng tôi là các nhà cung cấp mô hình thường không sử dụng các điểm dữ liệu như vậy cho việc huấn luyện mô hình. Tuy nhiên, trong trường hợp dữ liệu GSM1k bị rò rỉ thông qua các phương tiện như vậy, chúng tôi cũng giữ lại một số lượng nhỏ các điểm dữ liệu đã vượt qua tất cả các kiểm tra chất lượng nhưng không xuất hiện trong bộ dữ liệu GSM1k cuối cùng. Dữ liệu này cũng sẽ được phát hành cùng với GSM1k khi phát hành cuối cùng. Chúng tôi khuyến khích các bộ đánh giá tương lai tuân theo mô hình tương tự, nơi chúng không được phát hành công khai để tránh bị lợi dụng, nhưng được cam kết trước để phát hành vào một ngày tương lai hoặc khi một điều kiện tương lai. Như một phần của bản phát hành này, chúng tôi cũng sẽ mở mã nguồn khung đánh giá của chúng tôi, dựa trên một nhánh của LM Evaluation Harness bởi EleutherAI (Gao et al. [2023a]).

Cuối cùng, trong khi chúng tôi đã nỗ lực rộng rãi để đảm bảo sự tương tự tối đa giữa GSM8k và GSM1k, những kết quả này chỉ là một xấp xỉ của một thế giới lý tưởng trong đó bộ kiểm tra của GSM8k thay vào đó không được phát hành công khai và được sử dụng cho các đánh giá. Chúng tôi khuyến nghị đọc tất cả kết quả với sự hiểu biết rằng GSM8k và GSM1k chỉ rất tương tự, nhưng không phân phối giống hệt nhau bất chấp tất cả nỗ lực của chúng tôi dưới đây.

### 3.1 Kiểm tra Chất lượng

Tất cả câu hỏi đã qua tổng cộng 3 lớp đánh giá. Sau khi tạo ban đầu, mỗi nhiệm vụ được đánh giá thủ công bởi một tập hợp con các chú thích viên đáng tin cậy được chọn vì hiệu suất tốt trong quá khứ. Những người đánh giá này kiểm tra cả tính đúng đắn cũng như đảm bảo các bài toán chỉ chứa toán học cấp tiểu học và định dạng thích hợp. Để đảm bảo rằng các câu hỏi được trả lời đúng, chúng tôi cũng thực hiện lớp đánh giá thứ hai bằng cách có một tập hợp độc lập các chú thích viên dữ liệu giải quyết mỗi câu hỏi mà không nhìn thấy lời giải dự định. Nếu lời giải thứ hai này tạo ra câu trả lời khác với lời giải ban đầu, chúng tôi loại bỏ bài toán. Cuối cùng, tất cả các bài toán được đánh giá bởi một nhóm đặc biệt trong Scale chịu trách nhiệm thực hiện kiểm toán chất lượng chung cho việc sản xuất dữ liệu. Trong tổng số 2108 bài toán ban đầu, 1419 đã vượt qua giai đoạn giải quyết thứ hai và 1375 đã vượt qua kiểm toán chất lượng chung.

### 3.2 Khớp Phân phối Độ khó của GSM8k

Một trục quan trọng của việc tái tạo một bộ đánh giá là đảm bảo rằng các bài toán mới có độ khó có thể so sánh với bộ đánh giá gốc. Để xây dựng các bài toán có độ khó N, chúng tôi yêu cầu các chú thích viên xây dựng các bài toán với N bước giải quyết cần thiết và nhắc họ với 3 ví dụ từ GSM8k với độ khó ước tính N. Phân phối các bài toán được yêu cầu từ các chú thích viên khớp với phân phối ước tính trong GSM8k. Độ khó khó đo lường chính xác, vì vậy chúng tôi đã sử dụng một ước tính dựa trên số lượng phép toán cần thiết để giải quyết bài toán. Điều này được trích xuất một cách chương trình bằng cách đếm số lượng thẻ "calculator" trong lời giải bài toán. Tuy nhiên, vì không phải tất cả lời giải bài toán đều được định dạng nhất quán, ước tính này chỉ là một ước tính thô của độ khó thực tế. Ngoài ra, số lượng bước giải quyết trong một bài toán không nhất thiết tương quan trực tiếp với mức độ khó thực sự của bài toán.

Các công trình trước đây cũng đã phát hiện rằng LLM gặp khó khăn với các bài toán có số lớn hơn (Gao et al. [2023b]) ngay cả khi chúng có thể giải quyết các bài toán giống hệt nhau với số nhỏ hơn. Để loại bỏ điều này như một biến số gây nhiễu tiềm năng, bước xử lý cuối cùng của chúng tôi là loại bỏ các bài toán ứng viên từ GSM1k để phân phối độ lớn câu trả lời của GSM8k và GSM1k tương tự nhau nhất có thể. Quy trình lựa chọn này được mô tả trong Hình 3. GSM1k bao gồm 1205 bài toán sống sót qua việc sàng lọc cuối cùng này. Ngoài ra, chúng tôi chạy một số kiểm tra để đảm bảo rằng nỗ lực của chúng tôi để khớp độ khó đánh giá là thành công.

2GSM8k có một vài bài toán, có thể là lỗi, mà điều này không đúng.

4

--- TRANG 5 ---

Hình 3: Là bước cuối cùng, chúng tôi chọn 1205 bài toán để khớp phân phối độ lớn câu trả lời của GSM8k càng nhiều càng tốt. Các bài toán còn lại được loại bỏ và không được bao gồm trong bộ dữ liệu cuối cùng. Trước khi loại bỏ, chúng tôi thấy rằng các bài toán được tạo ra của chúng tôi có xu hướng có câu trả lời lớn hơn một chút.

#### 3.2.1 Tỷ lệ Phân biệt của Con người

Bài kiểm tra đầu tiên chúng tôi chạy là khả năng phân biệt của con người. Chúng tôi trình bày cho các chú thích viên con người một tập hợp năm câu hỏi, bốn câu được chọn ngẫu nhiên từ bộ dữ liệu GSM8k gốc và một câu được chọn từ bộ dữ liệu GSM1k mới được tạo, và thưởng cho các chú thích viên vì tìm ra câu khác biệt. Trong một cuộc kiểm toán được thực hiện bằng 19 chú thích viên không tham gia vào quy trình tạo bài toán, chúng tôi thấy rằng các chú thích viên có thể xác định đúng ví dụ GSM1k duy nhất 21.83% thời gian trong 1205 lần thử (20% là cơ hội thuần túy). Riêng biệt, chúng tôi cũng đã kiểm tra một số tác giả bài báo chưa nhìn thấy dữ liệu và họ cũng không thể làm tốt hơn nhiều so với ngẫu nhiên. Điều này cho thấy sự khác biệt tối thiểu giữa GSM8k và GSM1k, ít nhất là như được đo bằng mắt người.

#### 3.2.2 Tỷ lệ Giải quyết của Con người

Để đảm bảo tỷ lệ giải quyết tương tự, chúng tôi cũng yêu cầu các chú thích viên giải quyết các câu hỏi dưới áp lực thời gian. 14 chú thích viên không tham gia vào quy trình tạo bài toán đã cố gắng giải quyết càng nhiều bài toán GSM8k càng có thể trong 15 phút và được thưởng dựa trên số lượng bài toán họ giải quyết. Chúng tôi lặp lại thiết lập chính xác này cho GSM1k. Các chú thích viên có thể giải quyết trung bình 4.07±0.93 bài toán trên bộ dữ liệu GSM8k. Họ có thể giải quyết 4.36±1.11 bài toán trên bộ dữ liệu GSM1k, nơi tỷ lệ lỗi là độ lệch chuẩn của đánh giá. Điều này cho thấy rằng GSM1k có thể so sánh về độ khó (và có lẽ thậm chí dễ hơn một chút) so với GSM8k. Do đó, sự giảm đáng kể trong độ chính xác của mô hình trên GSM1k so với GSM8k có thể không được giải thích do sự khác biệt trong độ khó của bộ dữ liệu.

#### 3.2.3 Tỷ lệ Giải quyết của LLM

Cuối cùng, chúng tôi kiểm tra kết quả của chúng tôi bằng cách đo tỷ lệ giải quyết của một số mô hình được biết là không bị ô nhiễm bởi GSM8k do được phát hành trước khi xuất bản bộ dữ liệu GSM8k. Do sự khan hiếm tương đối của LLM được huấn luyện chỉ trên dữ liệu trước 2021, chúng tôi chỉ đánh giá GPT-NeoX-20B (Black et al. [2022]) và GPT-2 (Radford et al. [2019]). Đối với hai mô hình ngôn ngữ này, chúng tôi thấy sự khác biệt tối thiểu giữa tỷ lệ giải quyết của chúng trên GSM8k và GSM1k (Hình 12).

## 4 Kết quả

Để đánh giá các mô hình, chúng tôi sử dụng một nhánh của LM Evaluation Harness của EleutherAI với các sửa đổi nhỏ. Chúng tôi sử dụng các thiết lập mặc định cho đánh giá, ngoại trừ việc tăng số lượng tối đa các token được tạo ra được phép từ 256 lên 1000, vì chúng tôi nhận thấy rằng thiết lập mặc định không cho phép một số mô hình

5

--- TRANG 6 ---

Hình 4: Các mô hình có độ chính xác trên 70% trên GSM8k so với đường không overfit. Biểu đồ này được phóng to vào các phần liên quan (độ chính xác 70-100%). Lưu ý rằng một số mô hình, đặc biệt là họ Claude, hoạt động trên đường 45 độ, điều này phù hợp với phát hiện của chúng tôi trong Phần 3 rằng GSM1k dễ hơn một chút so với GSM8k. Ngược lại, nhiều mô hình khác nằm rất dưới đường này.

hoàn thành lý luận chuỗi suy nghĩ đầy đủ của chúng trước khi bị cắt ngắn. Cả câu hỏi GSM8k và GSM1k đều được chạy với cùng prompt sử dụng 5 ví dụ được rút ngẫu nhiên từ tập huấn luyện GSM8k, như là tiêu chuẩn trong lĩnh vực. Một ví dụ prompt được cung cấp trong Phụ lục D. Tất cả các mô hình mã nguồn mở được đánh giá ở nhiệt độ 0 để có thể tái tạo. Đối với các mô hình mã nguồn mở, chúng tôi sử dụng vLLM để tăng tốc suy luận mô hình nếu một mô hình tương thích với thư viện. Nếu không, chúng tôi mặc định suy luận sử dụng các thư viện HuggingFace tiêu chuẩn. Các mô hình mã nguồn đóng được truy vấn thông qua thư viện LiteLLM thống nhất định dạng gọi API cho tất cả các mô hình độc quyền được đánh giá. Tất cả kết quả mô hình API đều từ các truy vấn giữa ngày 16 tháng 4 - 10 tháng 7 năm 2024 và sử dụng các thiết lập mặc định.

LM Evaluation Harness sử dụng phương pháp đánh giá tự động trích xuất câu trả lời số cuối cùng trong phản hồi và so sánh với câu trả lời đúng. Tuy nhiên, trong một số trường hợp, các mô hình sẽ tạo ra câu trả lời "đúng" ở định dạng không khớp với các ví dụ đã cho, dẫn đến câu trả lời của chúng bị đánh dấu là không chính xác. Để khám phá tác động của điều này đối với kết quả, chúng tôi chạy một phép thử loại bỏ nơi chúng tôi chọn một tập hợp con các mô hình và sử dụng chú thích con người để trích xuất thủ công các câu trả lời không được định dạng đúng (Phụ lục J). Chúng tôi không tìm thấy thay đổi lớn trong các phát hiện của chúng tôi đối với các mô hình được kiểm tra.

Vì hiệu suất đánh giá mô hình rất phụ thuộc vào việc lựa chọn prompt và thiết lập đánh giá, các số GSM8k được báo cáo của chúng tôi đôi khi có thể thấp hơn các số đánh giá mô hình được báo cáo, vì chúng tôi sử dụng thiết lập tiêu chuẩn cho tất cả các mô hình thay vì prompt tối đa hóa hiệu suất của từng mô hình riêng lẻ. Ngoài ra, chúng tôi khám phá tác động của các công thức prompt khác nhau với một số phép thử loại bỏ. Trong Phụ lục E, chúng tôi báo cáo kết quả với một định dạng prompt thay thế sử dụng các ví dụ không phải GSM8k làm ví dụ n-shot và cách diễn đạt câu trả lời hơi khác. Ngoài ra, chúng tôi khám phá tác động của việc thay đổi số lượng và nguồn của các ví dụ n-shot được sử dụng trong Phụ lục K và

6

--- TRANG 7 ---

L. Trong khi độ chính xác đánh giá chính xác thay đổi tùy thuộc vào thiết lập, chúng tôi thấy rằng các xu hướng chung của overfitting giữ nhất quán qua các phép thử loại bỏ của chúng tôi. Chúng tôi sẽ phát hành mã đánh giá đầy đủ để minh bạch.

Ngoài việc đánh giá các mô hình được biết đến rộng rãi, chúng tôi cũng đánh giá một số mô hình ít được biết đến hơn nằm gần đỉnh của OpenLLMLeaderboard và phát hiện bằng chứng của định luật Goodhart: nhiều mô hình này hoạt động kém hơn đáng kể trên GSM1k, cho thấy rằng chúng chủ yếu đang chơi game đánh giá GSM8k thay vì cải thiện khả năng lý luận của mô hình. Tập hợp kết quả đầy đủ, bao gồm bảng hiệu suất cho tất cả các mô hình, có thể được tìm thấy trong Phụ lục F. Để so sánh công bằng, chúng tôi phân chia các mô hình theo hiệu suất trên GSM8k và so sánh chúng với các mô hình khác hoạt động tương tự (Hình 4, 11, 12).

## 5 Phân tích

Mixtral-8x22b Mixtral-8x22b-Instruct 
Math-Shepherd-Mistral-7B-RL → llemma_34b 
llemma_7b 

Hình 5: So sánh giữa overfit trên GSM8k (trục x) và log-likelihood trung bình cấp độ chuỗi trên tập kiểm tra GSM8k (trục y). Chúng tôi thấy rằng có mối tương quan giữa overfit trên GSM8k và log-likelihood cấp độ chuỗi, cho thấy rằng, nói chung, các mô hình có overfit cao thường có xác suất cao hơn để tạo ra tập kiểm tra. Điều này cho thấy rằng một số tập kiểm tra GSM8k có thể đã rò rỉ vào dữ liệu huấn luyện mô hình. Đường khớp tốt nhất có màu xanh lam. Ngoài ra, chúng tôi làm nổi bật 5 mô hình "ngoại lệ" mà chúng tôi thảo luận thêm với Bài học 4.

Việc giải thích kết quả đánh giá, giống như việc giải thích giấc mơ, thường là một nỗ lực rất chủ quan. Trong khi chúng tôi báo cáo kết quả khách quan của chúng tôi trong Phần 4 và Phụ lục F, ở đây chúng tôi mô tả bốn điểm chính từ việc giải thích kết quả theo cách chủ quan hơn.

### 5.1 Bài học 1: Một số Họ Mô hình bị Overfit Hệ thống

Mặc dù khó khăn để rút ra kết luận từ các điểm dữ liệu đơn lẻ hoặc bản phát hành mô hình, việc kiểm tra một họ mô hình và quan sát một mẫu overfitting cho phép chúng tôi đưa ra các tuyên bố quyết định hơn. Một số họ mô hình, bao gồm các họ mô hình Phi và Mistral, cho thấy xu hướng hệ thống hoạt động mạnh hơn trên GSM8k so với GSM1k cho hầu hết mọi bản phát hành và quy mô mô hình. Các họ mô hình khác, như Yi, Xwin, Gemma và CodeLlama cũng cho thấy mẫu này ở mức độ ít hơn.

7

--- TRANG 8 ---

### 5.2 Bài học 2: Các Mô hình Khác, Đặc biệt là Mô hình Tiên tiến, Không Cho thấy Dấu hiệu Overfitting

Tuy nhiên, chúng tôi thấy rằng nhiều mô hình, qua tất cả các vùng hiệu suất, cho thấy các dấu hiệu tối thiểu của việc bị overfit. Đặc biệt, chúng tôi thấy rằng tất cả các mô hình tiên tiến hoặc gần tiên tiến (bao gồm Mistral Large độc quyền) dường như hoạt động tương tự trên cả GSM8k và GSM1k. Chúng tôi đưa ra hai giả thuyết tiềm năng cho điều này: 1) các mô hình tiên tiến có khả năng lý luận đủ tiên tiến để chúng có thể khái quát đến các bài toán mới ngay cả khi chúng đã thấy các bài toán GSM8k trong tập huấn luyện của chúng, 2) các nhà xây dựng mô hình tiên tiến có thể cẩn thận hơn về ô nhiễm dữ liệu.

Mặc dù không thể biết chắc chắn mà không nhìn vào tập huấn luyện cho mỗi mô hình, một bằng chứng ủng hộ giả thuyết trước là Mistral Large là mô hình duy nhất trong họ Mistral không cho thấy dấu hiệu overfitting. Vì giả thuyết rằng Mistral đã chăm sóc đặc biệt để đảm bảo rằng chỉ mô hình lớn nhất của họ không bị ô nhiễm dữ liệu có vẻ không chắc, chúng tôi nghiêng về giả thuyết rằng LLM đủ mạnh cũng học khả năng lý luận cơ bản trong quá trình huấn luyện. Nếu một mô hình học khả năng lý luận đủ mạnh để giải quyết các bài toán có độ khó nhất định, nó sẽ có thể khái quát đến các bài toán mới ngay cả khi GSM8k đã xuất hiện trong tập huấn luyện của nó.

### 5.3 Bài học 3: Mô hình Overfit Vẫn Có khả năng Lý luận

Một lo ngại về overfitting mô hình là các mô hình không có khả năng lý luận và chỉ ghi nhớ câu trả lời thấy trong dữ liệu huấn luyện. Kết quả của chúng tôi không hỗ trợ giả đoán này. Thực tế rằng một mô hình bị overfit không có nghĩa là nó kém lý luận, chỉ có nghĩa là nó không tốt như các đánh giá có thể chỉ ra. Thực tế, chúng tôi thấy rằng nhiều mô hình overfit nhất vẫn có khả năng lý luận và giải quyết các bài toán mới. Ví dụ, trong khi Phi-2 có 6% giảm độ chính xác giữa GSM8k và GSM1k, chúng tôi thấy rằng nó vẫn có thể giải quyết đúng hơn một nửa các bài toán GSM1k – những bài toán chắc chắn không xuất hiện trong phân phối huấn luyện của nó. Hiệu suất này tương tự như của các mô hình lớn hơn nhiều như Llama2-70B, chứa hơn 25 lần nhiều tham số. Tương tự, các mô hình Mistral vẫn là một số mô hình mã nguồn mở mạnh nhất, ngay cả khi tính đến overfitting của chúng. Điều này cung cấp bằng chứng bổ sung cho bài học của chúng tôi rằng các mô hình đủ mạnh học lý luận cơ bản, ngay cả khi dữ liệu đánh giá vô tình rò rỉ vào phân phối huấn luyện, như có thể là trường hợp đối với các mô hình overfit nhất.

### 5.4 Bài học 4: Ô nhiễm Dữ liệu Có thể Không phải là Lời giải thích Đầy đủ cho Overfitting

A priori, một giả thuyết tự nhiên là nguyên nhân chính của overfitting là ô nhiễm dữ liệu, ví dụ rằng tập kiểm tra đã rò rỉ trong phần huấn luyện trước hoặc tinh chỉnh hướng dẫn của việc tạo mô hình. Công trình trước đây đã gợi ý rằng các mô hình đặt log-likelihood cao hơn trên dữ liệu mà chúng đã thấy trong quá trình huấn luyện (Carlini et al. [2023]). Chúng tôi kiểm tra giả thuyết rằng ô nhiễm dữ liệu là nguyên nhân của overfitting bằng cách đo xác suất của mô hình tạo ra một ví dụ từ tập kiểm tra GSM8k và so sánh với mức độ overfit của nó trên GSM8k vs GSM1k, sử dụng giả định rằng xác suất của mô hình tạo ra tập kiểm tra GSM8k là đại diện cho việc chuỗi có thể đã xuất hiện trong tập huấn luyện. Chúng tôi chuẩn hóa bằng c, số ký tự trong chuỗi, để làm cho các tính toán log-likelihood có thể so sánh được giữa các chuỗi và mô hình với các tokenizer khác nhau. Chính thức, chúng tôi có:

1/c Σi log p(xi|x<i) (1)

với c là số ký tự trong chuỗi. Hình 5 cho thấy kết quả của biểu đồ này so với khoảng cách giữa hiệu suất GSM8k và GSM1k. Chúng tôi thực sự thấy mối quan hệ tích cực giữa hai giá trị. Chúng tôi quan sát thấy mối tương quan thứ hạng Spearman là 0.36 giữa log-likelihood mỗi ký tự của việc tạo ra GSM8k và khoảng cách hiệu suất giữa GSM8k và GSM1k (p= 0.03), và mối quan hệ cho thấy rằng mỗi điểm phần trăm khác biệt trong hiệu suất GSM8k và GSM1k được liên kết với sự tăng 1.2×10−2 trong log-likelihood mỗi ký tự. Kết quả này cho thấy rằng một số lý do cho overfitting là do ghi nhớ một phần tập kiểm tra. Để hoàn thiện, chúng tôi cũng báo cáo Pearson r2= 0.26 tiêu chuẩn và Kendall's τ của 0.29, nhưng lưu ý rằng Pearson r2 không phải là chỉ số lý tưởng do đường khớp tốt nhất không xuất hiện tuyến tính.

Tuy nhiên, ô nhiễm dữ liệu có thể không phải là câu chuyện đầy đủ. Chúng tôi quan sát điều này qua sự hiện diện của một số ngoại lệ, khiến giá trị r2= 0.36 tương đối thấp. Kiểm tra cẩn thận các ngoại lệ này tiết lộ rằng mô hình có log-likelihood mỗi ký tự thấp nhất (Mixtral-8x22b) và mô hình có log-likelihood mỗi ký tự cao nhất (Mixtral-8x22b-Instruct) không chỉ là các biến thể của cùng một mô hình, mà còn có mức độ overfit tương tự (Jiang et al. [2024]). Có lẽ thú vị hơn, một trong những mô hình overfit nhất chúng tôi phát hiện (Math-Shepherd-Mistral-7B-RL (Yu et al. [2023])) có log-likelihood mỗi ký tự tương đối thấp. Math Shepherd huấn luyện một mô hình thưởng trên dữ liệu cấp độ quá trình sử dụng dữ liệu tổng hợp. Do đó, chúng tôi giả thuyết rằng quá trình mô hình hóa thưởng có thể đã rò rỉ thông tin về các chuỗi lý luận đúng cho GSM8k ngay cả khi các bài toán chính chúng không bao giờ xuất hiện trong bộ dữ liệu. Cuối cùng, chúng tôi quan sát thấy rằng các mô hình Llema (Azerbayev et al. [2024]) có cả log-likelihood cao và overfit tối thiểu. Các mô hình này được mã nguồn mở cùng với dữ liệu huấn luyện của chúng, và các tác giả báo cáo tìm thấy một số rất nhỏ ví dụ GSM8k trong tập huấn luyện. Tuy nhiên, họ cũng thấy (và nghiên cứu của chúng tôi hỗ trợ) rằng những trường hợp ít này không dẫn đến overfitting. Sự tồn tại của các ngoại lệ này cho thấy rằng overfitting trên GSM8k không hoàn toàn do ô nhiễm dữ liệu, mà có thể thông qua các phương tiện gián tiếp khác, như các nhà xây dựng mô hình thu thập dữ liệu tương tự về bản chất với các đánh giá làm dữ liệu huấn luyện hoặc chọn các checkpoint mô hình cuối cùng dựa trên hiệu suất trên các đánh giá, ngay cả khi bản thân mô hình có thể không nhìn thấy bộ dữ liệu GSM8k tại bất kỳ thời điểm nào qua huấn luyện. Ngược lại, điều ngược lại cũng đúng: lượng nhỏ ô nhiễm dữ liệu không nhất thiết dẫn đến overfitting.

## 6 Thảo luận

Chúng tôi tạo GSM1k, một bộ dữ liệu mới được thiết kế để đo lường overfitting LLM trên GSM8k. Khi đánh giá các mô hình hàng đầu mã nguồn mở và đóng, chúng tôi thấy bằng chứng đáng kể rằng nhiều mô hình đã bị ô nhiễm bởi dữ liệu đánh giá, với các mô hình cho thấy độ giảm hiệu suất lên đến 8% độ chính xác. Ngoài ra, chúng tôi thấy rằng một số họ mô hình cho thấy overfitting nhất quán trên hầu hết tất cả các kích thước và phiên bản mô hình. Một phân tích mở rộng tiết lộ mối quan hệ tích cực giữa khả năng của mô hình tạo ra các điểm dữ liệu trong GSM8k và sự khác biệt hiệu suất của nó giữa GSM8k và GSM1k, cho thấy bằng chứng của ô nhiễm dữ liệu như một trong các nguyên nhân cơ bản. Tuy nhiên, chúng tôi thấy rằng các mô hình tiên tiến thể hiện ít hoặc không có bằng chứng overfitting và nhiều mô hình, ngay cả các họ overfit nặng nhất, cho thấy dấu hiệu mạnh mẽ của lý luận toán học có thể khái quát.

## 7 Lời cảm ơn

Chúng tôi muốn cảm ơn Dan Hendrycks, Adi Ganesh, Akilesh Praveen, Andrea Jaba, Will Zhou, Celia Chen, Apaar Shanker và Kamil˙e Lukoši¯ut˙e vì những nhận xét và gợi ý hữu ích của họ.

## Tài liệu tham khảo

[Danh sách tài liệu tham khảo được giữ nguyên như bản gốc do chứa nhiều tên riêng và định dạng đặc biệt]

--- TRANG 18 ---

## A Danh sách kiểm tra

1. Đối với tất cả tác giả...
(a) Các tuyên bố chính được đưa ra trong tóm tắt và giới thiệu có phản ánh chính xác đóng góp và phạm vi của bài báo không? [Có]
(b) Bạn có mô tả các hạn chế của công trình không? [Có]
(c) Bạn có thảo luận về bất kỳ tác động xã hội tiêu cực tiềm năng nào của công trình không? [Không áp dụng]
(d) Bạn có đọc các hướng dẫn đánh giá đạo đức và đảm bảo rằng bài báo của bạn tuân thủ chúng không? [Có]

2. Nếu bạn bao gồm kết quả lý thuyết...
(a) Bạn có phát biểu tập hợp đầy đủ các giả định của tất cả kết quả lý thuyết không? [Không áp dụng]
(b) Bạn có bao gồm chứng minh hoàn chỉnh của tất cả kết quả lý thuyết không? [Không áp dụng]

3. Nếu bạn chạy thí nghiệm (ví dụ cho đánh giá)...
(a) Bạn có bao gồm mã, dữ liệu và hướng dẫn cần thiết để tái tạo kết quả thí nghiệm chính (trong tài liệu bổ sung hoặc như một URL) không? [Có] được bao gồm trong phụ lục, sẽ mở mã nguồn sớm
(b) Bạn có chỉ rõ tất cả chi tiết huấn luyện (ví dụ, phân chia dữ liệu, siêu tham số, cách chúng được chọn) không? [Không áp dụng]
(c) Bạn có báo cáo thanh lỗi (ví dụ, đối với seed ngẫu nhiên sau khi chạy thí nghiệm nhiều lần) không? [Có] Phụ lục F bao gồm lỗi chuẩn và ý nghĩa thống kê.
(d) Bạn có bao gồm tổng lượng tính toán và loại tài nguyên được sử dụng (ví dụ, loại GPU, cluster nội bộ, hoặc nhà cung cấp cloud) không? [Có] Chúng tôi chạy tất cả mô hình trên cluster với 8 x A100 node. Hầu hết mô hình hoàn thành đánh giá trong vài phút.

4. Nếu bạn sử dụng tài sản hiện có (ví dụ, mã, dữ liệu, mô hình) hoặc tuyển chọn/phát hành tài sản mới...
(a) Nếu công trình của bạn sử dụng tài sản hiện có, bạn có trích dẫn người tạo không? [Không áp dụng]
(b) Bạn có đề cập đến giấy phép của tài sản không? [Không áp dụng]
(c) Bạn có bao gồm bất kỳ tài sản mới nào trong tài liệu bổ sung hoặc như một URL không? [Có] GSM1k chưa được phát hành, với ngày phát hành tương lai. Chúng tôi cung cấp bộ dữ liệu đầy đủ ở đây. Chúng tôi yêu cầu người đánh giá không chia sẻ bộ dữ liệu này công khai.
(d) Bạn có thảo luận xem có và làm thế nào để có được sự đồng ý từ những người có dữ liệu bạn đang sử dụng/tuyển chọn không? [Có] Tất cả bài toán được tạo bởi chú thích viên được Scale AI thuê.
(e) Bạn có thảo luận xem dữ liệu bạn đang sử dụng/tuyển chọn có chứa thông tin nhận dạng cá nhân hoặc nội dung xúc phạm không? [Không áp dụng]

5. Nếu bạn sử dụng crowdsourcing hoặc thực hiện nghiên cứu với đối tượng con người...
(a) Bạn có bao gồm văn bản đầy đủ hướng dẫn được đưa cho người tham gia và ảnh chụp màn hình, nếu có không? [Có] Xem Phụ lục C
(b) Bạn có mô tả bất kỳ rủi ro tiềm năng nào cho người tham gia, với liên kết đến phê duyệt Hội đồng Đánh giá Thể chế (IRB), nếu có không? [Không áp dụng]
(c) Bạn có bao gồm mức lương theo giờ ước tính được trả cho người tham gia và tổng số tiền chi cho bồi thường người tham gia không? [Có] Chú thích viên được trả 20-25 / giờ, tùy thuộc vào hiệu suất, kinh nghiệm và khuyến khích thưởng. Tổng cộng, Scale đã trả khoảng 180K cho các chú thích viên con người để tạo bộ đánh giá này.

18

--- TRANG 19 ---

## B Tài liệu Bộ dữ liệu

1. **Xây dựng.** GSM1k là một bộ dữ liệu gồm 1205 câu hỏi yêu cầu lý luận toán học cơ bản để giải quyết. Tất cả bài toán đều được dự định có thể giải quyết chỉ sử dụng bốn phép toán số học cơ bản.

2. **Tạo ra.** GSM1k được tạo ra sử dụng chú thích con người từ đầu mà không sử dụng bất kỳ LLM nào. Các chú thích viên con người được Scale AI thuê và được trả từ 20 đến 25 đô la mỗi giờ. Tất cả chú thích viên đều có trụ sở tại Hoa Kỳ. Tổng cộng, bộ dữ liệu này đã trả khoảng 180.000 đô la cho các chú thích viên con người, bao gồm chi phí từ việc tạo và giải bài toán, kiểm tra đảm bảo chất lượng, cũng như các thí nghiệm được thực hiện để so sánh phân phối độ khó với GSM8k.

3. **Ý định.** Bộ dữ liệu này được dự định sử dụng như một phiên bản được giữ lại của GSM8k để đo lường ô nhiễm dữ liệu. Do đó, nó phần lớn bắt chước định dạng và phong cách của GSM8k. Tất cả câu trả lời đều là một số nguyên không âm.

4. **Phát hành.** Bộ dữ liệu của chúng tôi không được xuất bản tại thời điểm này, để ngăn ngừa rủi ro ô nhiễm dữ liệu trong các mô hình tương lai. Chúng tôi sẽ phát hành metadata Croissant khi bộ dữ liệu công khai, với các điều kiện được mô tả trong bài báo chính.

5. **Trách nhiệm.** Các tác giả chịu mọi trách nhiệm trong trường hợp vi phạm quyền. Do Scale AI ủy thác xây dựng bộ dữ liệu này từ đầu chủ yếu cho mục đích của bài báo này, chúng tôi không dự đoán bất kỳ vấn đề bản quyền hoặc vấn đề khác. Bộ dữ liệu (chưa được phát hành) sẽ được phát hành với giấy phép MIT.

6. **Bảo tồn.** Chúng tôi dự định phát hành bộ dữ liệu đầy đủ trên Github cũng như HuggingFace để nó vẫn có thể truy cập công khai cho bất kỳ ai muốn sử dụng. Định dạng sẽ là 1205 hàng với cột câu hỏi và câu trả lời.

19

--- TRANG 20 ---

## C Hướng dẫn Chú thích viên

Chúng tôi cung cấp hướng dẫn chú thích viên dưới đây.

Chào mừng đến với dự án Phát triển Câu hỏi Toán Tiểu học. Mục tiêu của dự án này là tạo ra các câu hỏi và câu trả lời tương tự như những gì được tìm thấy trong bài kiểm tra toán lớp 8. Mục tiêu của chúng tôi là phát triển các câu hỏi chất lượng cao gần như giống với những gì được tìm thấy trong bộ dữ liệu nhưng hoàn toàn độc đáo. Bạn sẽ thấy ba câu hỏi ví dụ và câu trả lời tương ứng của chúng trong mỗi nhiệm vụ. Những ví dụ này sẽ hướng dẫn bạn tạo ra các cặp câu hỏi và câu trả lời hoàn toàn mới. Quan trọng là lưu ý rằng bạn không thể sử dụng chatbot hoặc mô hình ngôn ngữ để giúp bạn phát triển những cặp Q&A này. Bạn có thể bị loại khỏi dự án nếu chúng tôi phát hiện bất kỳ việc sử dụng chatbot nào. Quan trọng nhất, các cặp Q&A của bạn phải là những sáng tạo gốc và không thể là phiên bản diễn đạt lại của các ví dụ.

Quy trình làm việc của bạn cho dự án này sẽ như sau:

Xem xét các ví dụ: Trong mỗi nhiệm vụ, bạn sẽ được hiển thị các ví dụ từ bộ dữ liệu câu hỏi-và-câu trả lời lớp 8. Xem xét các ví dụ để thông tin về cách bạn có thể tạo cặp câu hỏi và câu trả lời của mình.

Tạo Bài toán: Các bài toán nên tuân theo hướng dẫn bước trong nhiệm vụ. Đừng tái sử dụng một bối cảnh bài toán. Nếu bạn đã viết một bài toán về chuyến đi của Roger đến cửa hàng tạp hóa, đừng viết một bài toán khác sử dụng cùng tiền đề. Tất cả câu hỏi nên có độ phân giải từ 1 trở lên. Chúng tôi không muốn bất kỳ câu hỏi nào có số nguyên âm hoặc số không làm câu trả lời.

Xây dựng các bước giải quyết: Các phép tính nên đủ đơn giản để một học sinh lớp 8 có thể hoàn thành bằng bút và giấy. Chỉ sử dụng các phép toán số học cơ bản (cộng, trừ, nhân, chia)

Cung cấp Câu trả lời cuối cùng: Câu trả lời nên là một giá trị số nguyên duy nhất. Bất kỳ đơn vị nào nên được chỉ rõ như một phần của câu hỏi (ví dụ "Robert có bao nhiêu tiền, tính bằng đô la?"). Số thập phân đơn giản (ví dụ 3.25) có thể là một phần của các bước trung gian trong bài toán, nhưng câu trả lời cuối cùng nên luôn là số nguyên.

Kiểm tra công việc của bạn: Chúng tôi sẽ sử dụng quy trình kiểm soát chất lượng để đảm bảo độ chính xác nhưng việc kiểm tra công việc của bạn là rất quan trọng!

20

--- TRANG 21 ---

Hình 6: Những gì các chú thích viên nhìn thấy trước khi thấy ba prompt ví dụ được rút từ GSM8k.

21

--- TRANG 22 ---

## D Prompt N-shot (các ví dụ được chọn ngẫu nhiên từ tập huấn luyện GSM8k)

Dưới đây là một ví dụ prompt. Đối với mỗi câu hỏi, chúng tôi chọn năm ví dụ ngẫu nhiên từ GSM8k để sử dụng làm ví dụ n-shot, thay đổi cho mỗi câu hỏi mới từ tập kiểm tra GSM1k/GSM8k. Mặc dù phương pháp đánh giá khác nhau giữa các mô hình, đây là phương pháp phổ biến nhất để đánh giá GSM8k.

Câu hỏi: Jen và Tyler là vận động viên thể dục nghệ thuật luyện tập lộn nhào. Jen đang luyện tập lộn ba vòng trong khi Tyler đang luyện tập lộn hai vòng. Jen đã thực hiện mười sáu lần lộn ba vòng trong buổi luyện tập. Tyler đã lộn trên không một nửa số lần so với Jen. Tyler đã thực hiện bao nhiêu lần lộn hai vòng?

Câu trả lời: Jen đã thực hiện 16 lần lộn ba vòng, vì vậy cô ấy đã thực hiện 16 * 3 = <<16*3=48>>48 lần lộn. Tyler đã thực hiện một nửa số lần lộn, vì vậy anh ấy đã thực hiện 48 / 2 = <<48/2=24>>24 lần lộn. Một lần lộn hai vòng có hai lần lộn, vì vậy Tyler đã thực hiện 24 / 2 = <<24/2=12>>12 lần lộn hai vòng.
#### 12

Câu hỏi: Bốn người trong một công ty luật đang lên kế hoạch cho một bữa tiệc. Mary sẽ mua một đĩa mì ống với giá 20$ và một ổ bánh mì với giá 2$. Elle và Andrea sẽ chia chi phí mua 4 lon nước ngọt với giá 1.50$ mỗi lon, và cánh gà với giá 10$. Joe sẽ mua một chiếc bánh với giá 5$. Mary sẽ chi nhiều hơn bao nhiêu so với phần còn lại của công ty cộng lại?

Câu trả lời: Mary sẽ chi 20$ + 2$ = $<<20+2=22>>22. Elle và Andrea sẽ chi 1.5$ x 4 = $<<1.5*4=6>>6 cho nước ngọt. Elle và Andrea sẽ chi 6$ + 10$ = $<<6+10=16>>16 cho nước ngọt và cánh gà. Elle, Andrea, và Joe cùng nhau sẽ chi 16$ + 5$ = $<<16+5=21>>21. Vì vậy, Mary sẽ chi 22$ - 21$ = $<<22-21=1>>1 nhiều hơn so với tất cả họ cộng lại.
#### 1

Câu hỏi: Một vỉ nướng than đốt cháy mười lăm viên than thành tro mỗi hai mười phút nướng. Vỉ nướng đã chạy đủ lâu để đốt hết ba túi than. Mỗi túi than chứa 60 viên than. Vỉ nướng đã chạy bao lâu?

Câu trả lời: Vỉ nướng đã đốt 3 * 60 = <<3*60=180>>180 viên than. Phải mất 20 phút để đốt 15 viên than, vì vậy vỉ nướng đã chạy trong 180 / 15 * 20 = <<180/15*20=240>>240 phút.
#### 240

Câu hỏi: Một con gấu đang chuẩn bị ngủ đông cho mùa đông và cần tăng 1000 pound. Vào cuối mùa hè, con gấu ăn mòn trái cây và động vật nhỏ trong rừng. Trong mùa thu, nó ngấu nghiến hạt sồi và cá hồi. Nó đã tăng một phần năm trọng lượng cần thiết từ trái cây trong mùa hè, và trong mùa thu, nó đã tăng gấp đôi lượng đó từ hạt sồi. Cá hồi chiếm một nửa trọng lượng còn lại mà nó cần tăng. Nó đã tăng bao nhiêu pound từ việc ăn động vật nhỏ?

Câu trả lời: Con gấu đã tăng 1 / 5 * 1000 = <<1/5*1000=200>>200 pound từ trái cây. Nó đã tăng 2 * 200 = <<2*200=400>>400 pound từ hạt sồi. Nó vẫn cần 1000 - 200 - 400 = <<1000-200-400=400>>400 pound. Do đó, nó đã tăng 400 / 2 = <<400/2=200>>200 pound từ cá hồi. Vì vậy, con gấu đã tăng 400 - 200 = <<400-200=200>>200 pound từ động vật nhỏ.
#### 200

Câu hỏi: Brendan có thể cắt 8 yard cỏ mỗi ngày, anh ấy đã mua một máy cắt cỏ và nó giúp anh ấy cắt thêm năm mười phần trăm yard mỗi ngày. Brendan sẽ có thể cắt bao nhiêu yard sau một tuần?

Câu trả lời: Yard bổ sung Brendan có thể cắt sau khi mua máy cắt cỏ là 8 x 0.50 = <<8*0.50=4>>4 yard. Vì vậy, tổng số yard anh ấy có thể cắt với máy cắt cỏ là 8 + 4 = <<8+4=12>>12. Do đó, tổng số yard anh ấy có thể cắt trong một tuần là 12 x 7 = <<12*7=84>>84 yard.
#### 84

22

--- TRANG 23 ---

## E Kết quả với Prompt Thay thế

Như một phép thử loại bỏ, chúng tôi đánh giá tất cả mô hình với một lược đồ prompt thay thế và so sánh kết quả với các phát hiện chính của chúng tôi. Prompt này có sẵn dưới LM Evaluation Harness như một prompt "chuỗi suy nghĩ". Tuy nhiên, việc kiểm tra thủ công prompt (được cung cấp đầy đủ dưới đây) tiết lộ rằng sự khác biệt chính với prompt n-shot tiêu chuẩn không nằm trong lý luận chuỗi suy nghĩ mà là sử dụng một tập hợp các bài toán không phải GSM8k làm ví dụ hướng dẫn cũng như cung cấp định dạng câu trả lời thay thế. Chúng tôi chọn sử dụng prompt tiêu chuẩn để khớp với các phương pháp đánh giá điển hình rộng rãi trong lĩnh vực nhưng cũng báo cáo những kết quả này để hoàn thiện.

Q: Có 15 cây trong khu rừng. Các công nhân khu rừng sẽ trồng cây trong khu rừng hôm nay. Sau khi họ hoàn thành, sẽ có 21 cây. Các công nhân khu rừng đã trồng bao nhiêu cây hôm nay?
A: Có 15 cây ban đầu. Sau đó có 21 cây sau khi một số cây được trồng thêm. Vì vậy phải có 21 −15 = 6. Câu trả lời là 6.

Q: Nếu có 3 xe trong bãi đậu xe và 2 xe nữa đến, có bao nhiêu xe trong bãi đậu xe?
A: Ban đầu có 3 xe. 2 xe nữa đến. 3 + 2 = 5. Câu trả lời là 5.

Q: Leah có 32 viên sô cô la và em gái cô ấy có 42 viên. Nếu họ ăn 35 viên, họ còn lại tổng cộng bao nhiêu viên?
A: Ban đầu, Leah có 32 viên sô cô la. Em gái cô ấy có 42 viên. Vì vậy tổng cộng họ có 32 + 42 = 74 viên. Sau khi ăn 35 viên, họ còn 74 −35 = 39 viên. Câu trả lời là 39.

Q: Jason có 20 cây kẹo mút. Anh ấy đưa cho Denny một số cây kẹo mút. Bây giờ Jason có 12 cây kẹo mút. Jason đã đưa cho Denny bao nhiêu cây kẹo mút?
A: Jason bắt đầu với 20 cây kẹo mút. Sau đó anh ấy có 12 cây sau khi đưa một số cho Denny. Vì vậy anh ấy đã đưa cho Denny 20 −12 = 8 cây. Câu trả lời là 8.

Q: Shawn có năm đồ chơi. Vào Giáng sinh, anh ấy nhận được hai đồ chơi từ mỗi người mẹ và bố. Anh ấy có bao nhiêu đồ chơi bây giờ?
A: Shawn bắt đầu với 5 đồ chơi. Nếu anh ấy nhận được 2 đồ chơi từ mỗi người mẹ và bố, thì đó là 4 đồ chơi nữa. 5 + 4 = 9. Câu trả lời là 9.

Q: Có chín máy tính trong phòng máy chủ. Năm máy tính nữa được lắp đặt mỗi ngày, từ thứ hai đến thứ năm. Có bao nhiêu máy tính trong phòng máy chủ bây giờ?
A: Ban đầu có 9 máy tính. Trong mỗi 4 ngày, 5 máy tính nữa được thêm vào. Vì vậy 5 *4 = 20 máy tính được thêm vào. 9 + 20 là 29. Câu trả lời là 29.

Q: Michael có 58 quả bóng golf. Vào thứ ba, anh ấy mất 23 quả bóng golf. Vào thứ tư, anh ấy mất thêm 2 quả. Anh ấy có bao nhiêu quả bóng golf vào cuối thứ tư?
A: Michael bắt đầu với 58 quả bóng golf. Sau khi mất 23 quả vào thứ ba, anh ấy có 58−23 = 35 quả. Sau khi mất thêm 2 quả, anh ấy có 35 −2 = 33 quả bóng golf. Câu trả lời là 33.

Q: Olivia có 23$. Cô ấy mua năm chiếc bánh mì với giá 3$ mỗi chiếc. Cô ấy còn lại bao nhiêu tiền?
A: Olivia có 23 đô la. 5 chiếc bánh mì với giá 3 đô la mỗi chiếc sẽ là 5 x 3 = 15 đô la. Vì vậy cô ấy còn lại 23 −15 đô la. 23 −15 là 8. Câu trả lời là 8.

Chúng tôi báo cáo kết quả của chúng tôi trong Bảng F. Mặc dù có sự khác biệt đáng kể dựa trên prompt, xu hướng chung của họ mô hình nào bị overfit là tương tự.

23

--- TRANG 24 ---

Hình 7: Khoảng cách độ chính xác giữa GSM8k và GSM1k cho các mô hình đạt trên 70% trên GSM8k.

24

--- TRANG 25 ---

## F Bảng Kết quả

Chúng tôi báo cáo kết quả đầy đủ của chúng tôi trong Bảng F. Các mô hình được sắp xếp theo sự khác biệt hiệu suất giữa GSM8k và GSM1k. Bởi vì tất cả mô hình được đánh giá sử dụng prompt LM Evaluation Harness tiêu chuẩn và định dạng đánh giá, hiệu suất mô hình trên GSM8k có thể không khớp với số đánh giá được báo cáo. Đặc biệt, các câu trả lời không khớp với định dạng ví dụ 5-shot được đánh dấu không chính xác ngay cả khi chúng "đúng" theo cách khác. Trọng tâm chính của chúng tôi là sự khác biệt giữa hiệu suất GSM8k và GSM1k, giữ nguyên thiết lập đánh giá. Z-score và p-value được tính cho kiểm định Z tỷ lệ hai đuôi. Kết quả prompt thay thế cũng được bao gồm. Để biết chi tiết, xem Phụ lục E.

### Prompt Tiêu chuẩn

| Mô hình | Diff | GSM8k | GSM1k | Z-score | p-value |
|---------|------|-------|-------|---------|---------|
| Yi-6B-Chat | 0.080 | 0.437 | 0.357 | 4.135 | 0.000 |
| math-shepherd-mistral-7b-rl | 0.072 | 0.826 | 0.754 | 4.488 | 0.000 |
| command | 0.065 | 0.447 | 0.383 | 3.336 | 0.000 |
| Xwin-Math-13B-V1.0 | 0.064 | 0.660 | 0.596 | 3.334 | 0.000 |
| phi-2 | 0.063 | 0.566 | 0.504 | 3.167 | 0.001 |
| Meta-Llama-3-8B-Instruct | 0.062 | 0.752 | 0.690 | 3.532 | 0.000 |
| Xwin-Math-7B-V1.0 | 0.060 | 0.552 | 0.492 | 3.040 | 0.001 |
| Meta-Llama-3-8B | 0.054 | 0.502 | 0.448 | 2.734 | 0.003 |
| phi-1.5 | 0.051 | 0.324 | 0.274 | 2.814 | 0.002 |
| Phind-CodeLlama-34B-v2 | 0.049 | 0.419 | 0.370 | 2.531 | 0.006 |
| CodeLlama-34b-Instruct-hf | 0.045 | 0.426 | 0.381 | 2.338 | 0.010 |
| Phi-3-medium-128k-instruct | 0.044 | 0.869 | 0.825 | 3.103 | 0.001 |
| CodeLlama-13b-Python-hf | 0.044 | 0.223 | 0.179 | 2.759 | 0.003 |
| gemma-7b | 0.043 | 0.519 | 0.476 | 2.198 | 0.014 |
| Phi-3-mini-4k-instruct | 0.040 | 0.788 | 0.748 | 2.385 | 0.009 |
| Yi-34B-Chat | 0.035 | 0.685 | 0.650 | 1.883 | 0.030 |
| mistral-medium-latest | 0.035 | 0.790 | 0.755 | 2.104 | 0.018 |
| Mixtral-8x7B-v0.1 | 0.035 | 0.591 | 0.557 | 1.771 | 0.038 |
| Xwin-Math-70B-V1.0 | 0.034 | 0.806 | 0.772 | 2.107 | 0.018 |
| Mixtral-8x7B-Instruct-v0.1 | 0.030 | 0.660 | 0.630 | 1.588 | 0.056 |
| Mistral-7B-v0.1 | 0.027 | 0.391 | 0.364 | 1.421 | 0.078 |
| Mixtral-8x22B-Instruct-v0.1 | 0.026 | 0.872 | 0.846 | 1.913 | 0.028 |
| CodeLlama-70b-Instruct-hf | 0.026 | 0.513 | 0.486 | 1.323 | 0.093 |
| Llama-2-7b-hf | 0.025 | 0.141 | 0.116 | 1.892 | 0.029 |
| Mistral-7B-Instruct-v0.1 | 0.025 | 0.353 | 0.329 | 1.309 | 0.095 |
| CodeLlama-70b-hf | 0.024 | 0.478 | 0.454 | 1.221 | 0.111 |
| gemma-7b-it | 0.023 | 0.325 | 0.302 | 1.247 | 0.106 |
| mistral-small-latest | 0.022 | 0.790 | 0.768 | 1.343 | 0.090 |
| CodeLlama-13b-hf | 0.021 | 0.236 | 0.215 | 1.247 | 0.106 |
| Phi-3-medium-4k-instruct | 0.020 | 0.874 | 0.854 | 1.519 | 0.064 |

25

--- TRANG 26 ---

### Prompt Tiêu chuẩn (tiếp)

| Mô hình | Diff | GSM8k | GSM1k | Z-score | p-value |
|---------|------|-------|-------|---------|---------|
| Mixtral-8x22B-v0.1 | 0.020 | 0.767 | 0.748 | 1.138 | 0.127 |
| CodeLlama-34b-hf | 0.017 | 0.354 | 0.337 | 0.919 | 0.179 |
| gemma-2b | 0.015 | 0.185 | 0.170 | 0.966 | 0.167 |
| Meta-Llama-3-70B-Instruct | 0.014 | 0.914 | 0.900 | 1.251 | 0.105 |
| CodeLlama-7b-Python-hf | 0.013 | 0.131 | 0.118 | 1.040 | 0.149 |
| dbrx-base | 0.012 | 0.731 | 0.719 | 0.707 | 0.240 |
| pythia-12b | 0.011 | 0.036 | 0.025 | 1.701 | 0.044 |
| Phi-3-mini-128k-instruct | 0.011 | 0.757 | 0.746 | 0.645 | 0.260 |
| Meta-Llama-3-70B | 0.011 | 0.817 | 0.806 | 0.707 | 0.240 |
| CodeLlama-34b-Python-hf | 0.010 | 0.312 | 0.301 | 0.549 | 0.291 |
| gpt-3.5-turbo | 0.009 | 0.760 | 0.750 | 0.546 | 0.293 |
| Mistral-7B-Instruct-v0.2 | 0.009 | 0.428 | 0.419 | 0.469 | 0.319 |
| claude-3-haiku-20240307 | 0.009 | 0.785 | 0.776 | 0.532 | 0.298 |
| Llama-2-70b-hf | 0.008 | 0.552 | 0.544 | 0.445 | 0.328 |
| CodeLlama-7b-Instruct-hf | 0.007 | 0.177 | 0.169 | 0.472 | 0.319 |
| gemini-1.5-pro-preview-0514 | 0.006 | 0.895 | 0.890 | 0.472 | 0.318 |
| gemini-1.5-pro-preview-0409 | 0.005 | 0.897 | 0.892 | 0.403 | 0.343 |
| CodeLlama-13b-Instruct-hf | 0.005 | 0.267 | 0.262 | 0.257 | 0.399 |
| dbrx-instruct | 0.004 | 0.730 | 0.726 | 0.211 | 0.417 |
| gpt-4-turbo | 0.003 | 0.898 | 0.895 | 0.270 | 0.394 |
| gpt2-xl | 0.002 | 0.009 | 0.007 | 0.778 | 0.218 |
| gpt-4o | 0.002 | 0.931 | 0.929 | 0.219 | 0.413 |
| gemini-pro | -0.001 | 0.792 | 0.793 | -0.081 | 0.532 |
| mistral-large-latest | -0.001 | 0.853 | 0.854 | -0.049 | 0.519 |
| gemma-2b-it | -0.001 | 0.111 | 0.112 | -0.106 | 0.542 |
| claude-2.1 | -0.004 | 0.887 | 0.891 | -0.336 | 0.632 |
| CodeLlama-7b-hf | -0.007 | 0.126 | 0.133 | -0.525 | 0.700 |
| Llama-2-13b-hf | -0.011 | 0.236 | 0.246 | -0.629 | 0.735 |
| gpt-4 | -0.012 | 0.911 | 0.923 | -1.161 | 0.877 |
| claude-3-sonnet-20240229 | -0.016 | 0.719 | 0.735 | -0.894 | 0.814 |
| claude-3-opus-20240229 | -0.022 | 0.802 | 0.824 | -1.421 | 0.922 |
| deepseek-math-7b-rl | -0.031 | 0.187 | 0.217 | -1.963 | 0.975 |
| gemini-1.5-flash-preview-0514 | -0.038 | 0.797 | 0.835 | -2.507 | 0.994 |

26

--- TRANG 27 ---

### Prompt Thay thế

| Mô hình | Diff | GSM8k | GSM1k | Z-score | p-value |
|---------|------|-------|-------|---------|---------|
| math-shepherd-mistral-7b-rl | 0.074 | 0.820 | 0.746 | 4.504 | 0.000 |
| deepseek-math-7b-rl | 0.064 | 0.760 | 0.696 | 3.672 | 0.000 |
| Yi-6B-Chat | 0.058 | 0.426 | 0.368 | 2.964 | 0.002 |
| CodeLlama-34b-Python-hf | 0.056 | 0.337 | 0.280 | 3.059 | 0.001 |
| command | 0.051 | 0.457 | 0.407 | 2.596 | 0.005 |
| phi-1.5 | 0.050 | 0.321 | 0.271 | 2.786 | 0.003 |
| Xwin-Math-13B-V1.0 | 0.042 | 0.662 | 0.620 | 2.212 | 0.013 |
| CodeLlama-70b-Instruct-hf | 0.040 | 0.529 | 0.489 | 2.047 | 0.020 |
| CodeLlama-70b-hf | 0.037 | 0.517 | 0.480 | 1.878 | 0.030 |
| gemma-7b | 0.036 | 0.568 | 0.532 | 1.826 | 0.034 |
| gemini-1.5-pro-preview-0409 | 0.035 | 0.908 | 0.873 | 2.883 | 0.002 |
| Phi-3-mini-128k-instruct | 0.035 | 0.818 | 0.783 | 2.211 | 0.014 |
| phi-2 | 0.034 | 0.552 | 0.518 | 1.744 | 0.041 |
| Xwin-Math-7B-V1.0 | 0.033 | 0.530 | 0.497 | 1.680 | 0.046 |
| CodeLlama-7b-hf | 0.027 | 0.123 | 0.095 | 2.242 | 0.012 |
| Mistral-7B-Instruct-v0.2 | 0.027 | 0.437 | 0.410 | 1.389 | 0.082 |
| dbrx-base | 0.024 | 0.712 | 0.688 | 1.322 | 0.093 |
| gemma-7b-it | 0.023 | 0.254 | 0.231 | 1.394 | 0.082 |
| Meta-Llama-3-8B-Instruct | 0.023 | 0.774 | 0.751 | 1.362 | 0.087 |
| CodeLlama-7b-Instruct-hf | 0.022 | 0.187 | 0.165 | 1.493 | 0.068 |
| Yi-34B-Chat | 0.022 | 0.679 | 0.656 | 1.170 | 0.121 |
| mistral-small-latest | 0.021 | 0.782 | 0.761 | 1.305 | 0.096 |
| CodeLlama-13b-Python-hf | 0.021 | 0.218 | 0.197 | 1.299 | 0.097 |
| CodeLlama-34b-hf | 0.020 | 0.330 | 0.310 | 1.097 | 0.136 |
| pythia-12b | 0.019 | 0.049 | 0.030 | 2.553 | 0.005 |
| mistral-medium-latest | 0.019 | 0.789 | 0.770 | 1.152 | 0.125 |
| Phi-3-medium-4k-instruct | 0.018 | 0.901 | 0.883 | 1.428 | 0.077 |
| dbrx-instruct | 0.016 | 0.713 | 0.697 | 0.924 | 0.178 |
| Mixtral-8x7B-Instruct-v0.1 | 0.016 | 0.679 | 0.662 | 0.870 | 0.192 |
| gemma-2b | 0.016 | 0.194 | 0.178 | 1.020 | 0.154 |
| Llama-2-7b-hf | 0.014 | 0.142 | 0.128 | 1.021 | 0.154 |
| Phind-CodeLlama-34B-v2 | 0.014 | 0.398 | 0.384 | 0.728 | 0.233 |
| Mixtral-8x7B-v0.1 | 0.013 | 0.614 | 0.601 | 0.690 | 0.245 |
| Meta-Llama-3-8B | 0.013 | 0.547 | 0.534 | 0.660 | 0.255 |
| gemini-pro | 0.012 | 0.688 | 0.676 | 0.677 | 0.249 |
| Mistral-7B-v0.1 | 0.011 | 0.431 | 0.420 | 0.583 | 0.280 |
| Meta-Llama-3-70B-Instruct | 0.008 | 0.907 | 0.899 | 0.714 | 0.238 |
| Mixtral-8x22B-Instruct-v0.1 | 0.008 | 0.890 | 0.882 | 0.612 | 0.270 |

27

--- TRANG 28 ---

### Prompt Thay thế (tiếp)

| Mô hình | Diff | GSM8k | GSM1k | Z-score | p-value |
|---------|------|-------|-------|---------|---------|
| Phi-3-mini-4k-instruct | 0.007 | 0.807 | 0.800 | 0.474 | 0.318 |
| claude-3-haiku-20240307 | 0.006 | 0.792 | 0.785 | 0.416 | 0.339 |
| Llama-2-13b-hf | 0.005 | 0.281 | 0.276 | 0.298 | 0.383 |
| Xwin-Math-70B-V1.0 | 0.005 | 0.808 | 0.803 | 0.319 | 0.375 |
| gpt2-xl | 0.004 | 0.006 | 0.002 | 1.422 | 0.078 |
| Mixtral-8x22B-v0.1 | 0.002 | 0.808 | 0.807 | 0.115 | 0.454 |
| gemini-1.5-flash-preview-0514 | 0.001 | 0.810 | 0.808 | 0.110 | 0.456 |
| CodeLlama-7b-Python-hf | 0.001 | 0.119 | 0.118 | 0.112 | 0.455 |
| CodeLlama-13b-Instruct-hf | -0.000 | 0.284 | 0.285 | -0.028 | 0.511 |
| gemma-2b-it | -0.000 | 0.101 | 0.101 | -0.064 | 0.526 |
| CodeLlama-34b-Instruct-hf | -0.002 | 0.403 | 0.404 | -0.073 | 0.529 |
| CodeLlama-13b-hf | -0.004 | 0.213 | 0.217 | -0.232 | 0.592 |
| Phi-3-medium-128k-instruct | -0.005 | 0.870 | 0.876 | -0.368 | 0.644 |
| claude-3-opus-20240229 | -0.006 | 0.830 | 0.836 | -0.396 | 0.654 |
| claude-2.1 | -0.006 | 0.836 | 0.842 | -0.425 | 0.665 |
| gpt-4 | -0.008 | 0.919 | 0.927 | -0.790 | 0.785 |
| gpt-4-turbo | -0.011 | 0.847 | 0.858 | -0.825 | 0.795 |
| Mistral-7B-Instruct-v0.1 | -0.011 | 0.340 | 0.352 | -0.617 | 0.731 |
| gpt-4o | -0.012 | 0.913 | 0.925 | -1.188 | 0.882 |
| Llama-2-70b-hf | -0.013 | 0.572 | 0.585 | -0.636 | 0.738 |
| gemini-1.5-pro-preview-0514 | -0.014 | 0.802 | 0.816 | -0.894 | 0.814 |
| mistral-large-latest | -0.017 | 0.854 | 0.871 | -1.228 | 0.890 |
| gpt-3.5-turbo | -0.017 | 0.742 | 0.759 | -0.994 | 0.840 |
| claude-3-sonnet-20240229 | -0.024 | 0.713 | 0.737 | -1.326 | 0.908 |
| Meta-Llama-3-70B | -0.034 | 0.815 | 0.849 | -2.287 | 0.989 |

28

--- TRANG 29 ---

## G 50 Ví dụ từ GSM1k

Một phiên bản trước của bài báo này đã nhầm lẫn bao gồm một số câu hỏi từ một phiên bản không phải cuối cùng của GSM1k. Một bảng đã được sửa ở dưới đây.

| Số | Câu hỏi | Câu trả lời |
|----|---------|-------------|
| 1 | Gabriela có 65,00$ và đang mua sắm thực phẩm để bà của cô ấy có thể nấu món súp cải xoăn yêu thích. Cô ấy cần kem đặc, cải xoăn, súp lơ, và thịt (thịt xông khói và xúc xích). Gabriella chi 40% số tiền của mình vào thịt. Cô ấy chi ít hơn một phần ba số tiền còn lại 5,00$ cho kem đặc. Súp lơ có giá ba phần tư giá kem đặc và cải xoăn có giá ít hơn súp lơ 2,00$. Khi Gabriela rời khỏi cửa hàng, cô ấy chi một phần ba số tiền còn lại của mình cho Bánh quy Girl Scout yêu thích của bà. Gabriela chi bao nhiêu tiền, tính bằng đô la, cho bánh quy Girl Scout? | 7 |
| 2 | Bernie là một nghệ sĩ đường phố chơi guitar. Trung bình, anh ấy làm đứt ba dây guitar mỗi tuần, và mỗi dây guitar có giá 3$ để thay thế. Anh ấy chi bao nhiêu tiền cho dây guitar trong suốt cả năm? | 468 |
| 3 | John Henry đang thi đấu với một cỗ máy để xem ai có thể đào hầm nhanh hơn. John làm việc không nghỉ ngơi, và đào với tốc độ 6 feet khối đá mỗi giờ. Máy đào nhanh hơn nhưng cần được tiếp nhiên liệu và bảo trì bởi người vận hành trong 30 phút mỗi giờ. Khi không được bảo trì, máy đào với tốc độ 10 feet khối đá mỗi giờ. Với điều kiện cuộc thi kéo dài 8 giờ, John sẽ đào được nhiều hơn máy bao nhiêu đá? | 8 |
| 4 | Colin đang chơi xúc xắc với bạn Eoin và cần giúp đỡ theo dõi điểm số. Anh ấy bắt đầu với 5 điểm và thắng 6 điểm trong vòng đầu tiên. Trong vòng thứ hai, anh ấy thắng gấp đôi số điểm so với vòng đầu tiên. Trong vòng thứ ba, anh ấy có một lần tung tuyệt vời và có thể nhân ba tổng số điểm của mình! Colin kết thúc trò chơi với bao nhiêu điểm? | 69 |
| 5 | Marge có một công việc để có thể mua chiếc xe đầu tiên. Công việc của cô ấy trả 15$/giờ và cô ấy làm việc 30 giờ một tuần. Chiếc xe Marge muốn có giá 3600$. Marge cần làm việc bao nhiêu tuần để mua xe? | 8 |
| 6 | Đội bóng đá của Andy cần 80 điểm để về nhất. Đội của anh ấy chơi 38 trận, và anh ấy nhận được 3 điểm cho mỗi trận thắng, 1 điểm cho mỗi trận hòa, và 0 điểm cho mỗi trận thua. Sau 26 trận, đội có 15 trận thắng, 5 trận hòa, và 6 trận thua. Đội của Andy cần bao nhiêu điểm nữa để đạt 80 điểm? | 30 |
| 7 | Molly muốn thắng cuộc thi ở trường về việc đọc 25 cuốn sách trước cuối tháng 5. Cho đến nay, cô ấy đã đọc 5 cuốn sách vào cuối tháng 1. Cô ấy cần đọc thêm bao nhiêu cuốn sách trung bình mỗi tháng cho đến cuối tháng 5 để thắng cuộc thi? | 5 |
| 8 | Cô Crabapple có một túi kẹo jellybean mà cô ấy sẽ chia đều cho tất cả 32 học sinh hoàn thành bài tập về nhà mỗi ngày trong suốt một tuần. Túi có 384 viên jellybean. Thật không may, nhiều học sinh của cô Crabapple có đạo đức làm việc kém phát triển, và chỉ một nửa số họ hoàn thành tất cả bài tập được yêu cầu. Mỗi học sinh đủ điều kiện sẽ nhận được bao nhiêu viên jellybean? | 24 |
| 9 | Bob phải đọc 2 cuốn sách và 3 bài báo, trong khi Emily phải đọc 4 cuốn sách và 2 bài báo. Mỗi cuốn sách có 3 chương và mỗi chương có 4 đoạn văn. Mỗi bài báo có 4 phần và mỗi phần có 2 đoạn văn. Bob và Emily sẽ đọc tổng cộng bao nhiêu đoạn văn? | 112 |

[Tiếp tục với 40 ví dụ còn lại theo cùng định dạng bảng...]

33

[Các trang còn lại được dịch theo cùng cách, giữ nguyên cấu trúc, bảng biểu, công thức toán học và định dạng gốc]

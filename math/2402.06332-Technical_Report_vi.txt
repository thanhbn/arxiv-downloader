# 2402.06332.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2402.06332.pdf
# Kích thước tệp: 1614922 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Báo cáo Kỹ thuật
InternLM-Math: Mô hình Ngôn ngữ Lớn Toán học Mở hướng tới
Lý luận có thể Xác minh
Huaiyuan Ying1,2*, Shuo Zhang1,3∗, Linyang Li3, Zhejian Zhou1,4, Yunfan Shao1,3
Zhaoye Fei1,3, Yichuan Ma1, Jiawei Hong1,3, Kuikun Liu1, Ziyi Wang1, Yudong Wang1
Zijian Wu1,5, Shuaibin Li1, Fengzhe Zhou1, Hongwei Liu1, Songyang Zhang1
Wenwei Zhang1, Hang Yan1, Xipeng Qiu3, Jiayu Wang1, Kai Chen1, Dahua Lin1
1Phòng thí nghiệm AI Thượng Hải
2Đại học Thanh Hoa
3Đại học Phục Đán, Khoa Khoa học Máy tính
4Đại học Nam California
5Đại học Giao thông Thượng Hải
internlm@pjlab.org.cn
Tóm tắt
Khả năng toán học của các mô hình ngôn ngữ lớn có thể thể hiện khả năng lý luận trừu tượng của chúng. Trong bài báo này, chúng tôi giới thiệu và mở mã nguồn các LLM lý luận toán học InternLM-Math được tiếp tục tiền huấn luyện từ InternLM2. Chúng tôi thống nhất lý luận chuỗi-tư-duy, mô hình hóa phần thưởng, lý luận hình thức, tăng cường dữ liệu, và thông dịch viên mã trong một định dạng seq2seq thống nhất và giám sát mô hình của chúng tôi để trở thành một người lý luận, xác minh, chứng minh, và tăng cường toán học đa năng. Những khả năng này có thể được sử dụng để phát triển các LLM toán học tiếp theo hoặc tự lặp lại. InternLM-Math đạt được hiệu suất tiên tiến mã nguồn mở dưới các thiết lập học ngữ cảnh, tinh chỉnh có giám sát, và lý luận hỗ trợ mã trong các điểm chuẩn không chính thức và chính thức khác nhau bao gồm GSM8K, MATH, kỳ thi toán Hungary, MathBench-ZH, và MiniF2F. Mô hình tiền huấn luyện của chúng tôi đạt 30.3 trên tập kiểm tra MiniF2F mà không cần tinh chỉnh. Chúng tôi khám phá thêm cách sử dụng LEAN để giải quyết các bài toán và nghiên cứu hiệu suất của nó dưới thiết lập học đa nhiệm vụ cho thấy khả năng sử dụng LEAN như một nền tảng thống nhất để giải quyết và chứng minh trong toán học. Các mô hình, mã nguồn, và dữ liệu của chúng tôi được phát hành tại https://github.com/InternLM/InternLM-Math .
Demo: https://huggingface.co/spaces/internlm/internlm2-math-7b
1 Giới thiệu
Các mô hình ngôn ngữ lớn (Brown et al., 2020; Lewkowycz et al., 2022b; Taylor et al., 2023;
OpenAI, 2023; Anil et al., 2023; InternLM, 2023; Azerbayev et al., 2023b; Google, 2023; Shao
et al., 2024) đã cho thấy khả năng đáng kể trong các nhiệm vụ lý luận toán học từ cấp tiểu học
(Cobbe et al., 2021) đến cấp trung học (Hendrycks et al., 2021a) bằng cách sử dụng lý luận
chuỗi-tư-duy (Wei et al., 2022) hoặc lý luận chương-trình-tư-duy (Chen et al., 2023b;
Gao et al., 2023).
Xây dựng những mô hình như vậy đòi hỏi tiền huấn luyện trên các kho dữ liệu toán học và tinh chỉnh có giám sát
trên các bài toán. Chúng tôi giới thiệu InternLM-Math dựa trên các mô hình InternLM2-Base1. InternLM2 cho thấy hiệu suất mạnh mẽ trong nhiều khía cạnh khác nhau bao gồm toán học, mã nguồn, trải nghiệm trò chuyện,
tuân theo hướng dẫn, và viết sáng tạo. Chúng tôi thu thập và tập hợp dữ liệu liên quan đến toán học để tiếp tục tiền huấn luyện trên InternLM2-Base và đạt được hiệu suất tiên tiến trên các điểm chuẩn lý luận toán học không chính thức
∗Đóng góp ngang nhau.
1https://github.com/InternLM/InternLM
1arXiv:2402.06332v2  [cs.CL]  24 May 2024

--- TRANG 2 ---
Báo cáo Kỹ thuật
và chính thức vượt trội hơn Minerva (Lewkowycz et al., 2022b)
và Llemma (Azerbayev et al., 2023b).
Trong quá trình tinh chỉnh có giám sát, chúng tôi giám sát InternLM-Math không chỉ để giải quyết các bài toán
sử dụng chuỗi-tư-duy và thông dịch viên mã mà còn nhiều nhiệm vụ để phát triển
LLM toán học bao gồm mô hình hóa phần thưởng và trợ lý tăng cường. Chúng tôi cũng giới thiệu việc sử dụng
LEAN để dịch giữa ngôn ngữ tự nhiên và các tuyên bố LEAN (Han et al., 2021),
giải quyết các bài toán dễ, và chứng minh các tuyên bố toán học. Dòng mô hình InternLM-Math
đạt được hiệu suất tiên tiến mã nguồn mở trên nhiều điểm chuẩn2và đạt điểm
hơn 90% so với GPT-4 (OpenAI, 2023).
Các đóng góp của chúng tôi bao gồm:
•Chúng tôi mở mã nguồn các LLM cơ sở và SFT trong lý luận toán học. Nó đạt được
SOTA mã nguồn mở dưới thiết lập ICL, SFT, sắp xếp lại RM, và hỗ trợ Python trong
các điểm chuẩn khác nhau.
•Chúng tôi thống nhất lý luận chuỗi-tư-duy, mô hình hóa phần thưởng, tăng cường dữ liệu, và
lý luận hình thức dưới một định dạng seq2seq thống nhất. Chúng tôi giám sát mô hình của chúng tôi với
cả khả năng giải quyết vấn đề và xác minh.
•Chúng tôi đề xuất lý luận xen kẽ với mã hóa (RICO) và đạt được lý luận toán học tiên tiến
với sự hỗ trợ của Python.
•Chúng tôi khám phá việc sử dụng LEAN để giải quyết các bài toán từ toán học và chúng tôi điều tra
hiệu suất của nó liên quan đến kích thước dữ liệu trong quá trình học đa nhiệm vụ.

Hình 1: Hiệu suất MATH 4-shot với 256 lần bỏ phiếu đa số. So sánh dựa
trên mô hình cơ sở tiền huấn luyện của chúng tôi, Llemma (Azerbayev et al., 2023b), và Minerva (Lewkowycz
et al., 2022b). Hình được chỉnh sửa từ Azerbayev et al. (2023b).
2 Công trình liên quan
Tiền huấn luyện Toán học Tiền huấn luyện giúp LLM có được kiến thức tính toán và toán học
từ các nguồn khác nhau, chẳng hạn như kho dữ liệu toán học (Han et al., 2021; Lewkowycz et al.,
2022b; Paster et al., 2023; Wang et al., 2023d), tập bài toán (Lightman et al., 2023), và
dữ liệu tổng hợp (Hendrycks et al., 2021b; Liu & Low, 2023; Yang et al., 2023b). ArXiv với
2Công trình này cùng thời với Deepseek-Math.
2

--- TRANG 3 ---
Báo cáo Kỹ thuật
nội dung toán học phong phú thường được sử dụng trong tiền huấn luyện toán học (Lewkowycz et al., 2022a;
Taylor et al., 2023; Azerbayev et al., 2023a). Paster et al. (2023) trích xuất các trang web toán học
từ common crawl có thể bổ sung cho arXiv. Các bài toán bao gồm
GSM8K (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021a) được sử dụng trong
tiền huấn luyện (OpenAI, 2023). Các bài toán tổng hợp được tạo ra thông qua quy tắc hoặc các tập lệnh chương trình toán học
(Hendrycks et al., 2021b) cũng có thể được sử dụng cho tiền huấn luyện. InternLM-Math thu thập dữ liệu tiền huấn luyện
từ kho dữ liệu toán học và dữ liệu tổng hợp để thiết lập khả năng toán học của nó.
Tinh chỉnh Toán học Xây dựng một tập dữ liệu chuỗi-tư-duy tăng cường mạnh mẽ hơn (Yu et al.,
2023b; Yue et al., 2023; Li et al., 2023; Liu & Yao, 2024) cho SFT để cải thiện hiệu suất lý luận toán học
đã nhận được rất nhiều quan tâm. Tăng cường bài toán (Luo et al., 2023; Yu et al.,
2023b; Li et al., 2023; Liu & Yao, 2024) và tăng cường đường lý luận (Zelikman et al.,
2022; Huang et al., 2022; Zhu et al., 2023; Yuan et al., 2023) là hai cách phổ biến cho thấy
hiệu quả đáng kể. Học tăng cường (Uesato et al., 2022; Luo et al., 2023;
Wang et al., 2023b; Singh et al., 2023) cũng đã được khám phá để tinh chỉnh các mô hình ngôn ngữ để
nâng cao hiệu suất lý luận đòi hỏi một mô hình phần thưởng (tức là trình xác minh) có thể phân biệt
quá trình lý luận và câu trả lời đúng và sai. So với công trình trước đây, chúng tôi
không chỉ xây dựng tập dữ liệu SFT chuỗi-tư-duy mạnh mẽ hơn mà còn tích hợp nhiều khả năng
tất-cả-trong-một bao gồm xác minh, chứng minh, thông dịch viên mã, và trợ lý tăng cường dữ liệu.
Trình xác minh Toán học Các mô hình phần thưởng (trình xác minh) thường được sử dụng để sắp xếp lại nhiều
đường lý luận ứng viên. Các mô hình phần thưởng kết quả (ORM) (Cobbe et al., 2021) và các mô hình phần thưởng quá trình (PRM) (Uesato et al., 2022; Lightman et al., 2023) tận dụng LLM để xác minh tính đúng đắn
của câu trả lời và quá trình. ORM kém hiệu quả hơn PRM (Lightman et al., 2023;
Wang et al., 2023b) trong khi PRM yêu cầu nhiều chuyên gia con người để gắn nhãn. Để giảm công sức
con người trong việc gắn nhãn PRM, Yu et al. (2023a); Wang et al. (2023b) xác định tính đúng đắn của
quá trình dựa trên nhiều hoàn thành từ quá trình. So với công trình trước đây
đã huấn luyện hai mạng riêng biệt cho mạng chính sách và mô hình phần thưởng. Chúng tôi
kết hợp hai chức năng này thành một định dạng seq2seq thống nhất. Sau SFT, mô hình của chúng tôi có thể được
sử dụng để giải quyết bài toán hoặc xác minh đường lý luận. Hơn nữa, chúng tôi khám phá việc tận dụng
ngôn ngữ toán học hình thức LEAN để xác minh đường lý luận bằng cách dịch sang mã LEAN.
Thông dịch viên Mã Toán học Thông dịch viên mã có thể bổ sung cho LLM với khả năng tính toán phức tạp
thông qua các thư viện Python khác nhau. Các khám phá ban đầu sử dụng chương-trình-tư-duy (Chen
et al., 2023b; Gao et al., 2023) nhưng thiếu tương tác giữa LLM và công cụ, có thể
không thể xử lý các tình huống yêu cầu lý luận và tính toán nhiều bước. Các công trình gần đây
(Gou et al., 2023; Wang et al., 2023a) cố gắng tích hợp thông dịch viên mã một cách liền mạch hơn
với lý luận bằng cách cho phép mô hình tóm tắt kết quả dựa trên kết quả thực thi mã một lần.
InternLM-Math khám phá lý luận xen kẽ với mã hóa (RICO), tức là,
quá trình lý luận và mã hóa xen kẽ trong nhiều vòng cho đến khi bài toán được
giải quyết, điều này tự nhiên hơn và gần gũi với quá trình giải quyết vấn đề và khai thác đầy đủ
khả năng lý luận của LLM.
Người chứng minh Toán học Giải quyết một bài toán bằng một câu trả lời đúng bởi LLM vẫn không thể đảm bảo
tính đúng đắn của quá trình. Tuy nhiên, chứng minh một tuyên bố sử dụng ngôn ngữ hình thức như Isabelle
(Paulson, 2000), LEAN (Moura & Ullrich, 2021), và Coq (The Coq Development Team,
2023) có thể hứa hẹn điều đó. Huấn luyện một LLM để chứng minh định lý tự động trong ngôn ngữ hình thức
(Han et al., 2021; Polu et al., 2022; Azerbayev et al., 2023a; Yang et al., 2023a; Welleck & Saha,
2023; Zheng et al., 2023) là khó khăn do dữ liệu thưa thớt. InternLM-Math đạt được hiệu suất few-shot tiên tiến
trên MiniF2F (Zheng et al., 2021) cho thấy tiềm năng trong việc xây dựng một
người chứng minh toán học mạnh mẽ.
3 Tiền huấn luyện
Trong phần này, chúng tôi trước tiên mô tả thành phần dữ liệu tiền huấn luyện của chúng tôi. Sau đó, chúng tôi phác thảo
phương pháp hậu xử lý dữ liệu chúng tôi thực hiện trên dữ liệu huấn luyện. Cuối cùng, chúng tôi đi sâu vào
chi tiết của chiến lược huấn luyện của chúng tôi.
3

--- TRANG 4 ---
Báo cáo Kỹ thuật
Lĩnh vực Tập dữ liệu Token Duy nhất(B) Epoch Token(B)
Dữ liệu Thu thập CC knowledge pile 20 4 80
Dữ liệu Lĩnh vực Đặc biệt open-web-math 6 4 24
algebraic-stack 4 4 16
khác 1 4 4
Dữ liệu Tổng hợp num 0.2 5 1
Tổng - 31.2 - 125
Bảng 1: Sử dụng dữ liệu tiền huấn luyện cho InternLM-Math. Token Duy nhất đề cập đến số lượng
token trong tập dữ liệu gốc. Token đề cập đến tổng số token trong tập dữ liệu
được tiêu thụ trong quá trình tiền huấn luyện.
3.1 Thành phần dữ liệu tiền huấn luyện
Để đạt được hiệu suất cạnh tranh trong lĩnh vực toán học, chúng tôi đã thu thập một
bộ sưu tập đa dạng gồm dữ liệu chất lượng cao. Chúng tôi không tận dụng bất kỳ dữ liệu do LLM tạo ra nào trong
tiền huấn luyện. Dữ liệu này được phân loại một cách có hệ thống thành các danh mục sau:
Dữ liệu Thu thập CC Chúng tôi sử dụng Query of CC (Fei et al., 2024) để thu thập kho dữ liệu huấn luyện
cho InternLM2-Math-Base. Chúng tôi chọn kho dữ liệu liên quan đến toán học từ kho dữ liệu Query of CC
như phần đầu tiên của dữ liệu tiếp tục tiền huấn luyện. Phần này bao gồm 20B token.
Dữ liệu Đặc biệt Lĩnh vực Chúng tôi chọn từ tập dữ liệu mã nguồn mở (Azerbayev et al., 2023b)
và tập dữ liệu chất lượng cao nội bộ trong lĩnh vực toán học bao gồm trang web, mã nguồn,
arXiv, diễn đàn, và sách. Phần này bao gồm 11B token.
Dữ liệu Tổng hợp Chúng tôi tổng hợp dữ liệu hoạt động số để cải thiện khả năng hoạt động số
của mô hình. Chúng tôi bao gồm năm hoạt động phổ biến bao gồm số học,
lũy thừa, logarit, lượng giác, và tính toán đa thức. Đối với hoạt động số,
chúng tôi duyệt qua một tập hợp các giá trị thường được sử dụng và lấy mẫu ngẫu nhiên một phạm vi rộng hơn
các giá trị trong số 10 chữ số. Để ngăn mô hình khớp quá với các
mẫu cụ thể, chúng tôi xây dựng các mẫu đa dạng để đảm bảo khả năng tính toán số
của mô hình tổng quát ở một mức độ nhất định. Phần này bao gồm 0.2B token.
3.2 Hậu xử lý dữ liệu
Để nâng cao chất lượng dữ liệu huấn luyện, chúng tôi tuân theo cách tiếp cận của Query of CC(Fei et al.,
2024) và triển khai một loạt chiến lược hậu xử lý dữ liệu. Cụ thể, chúng tôi đã huấn luyện một
mô hình chấm điểm để xác định tập dữ liệu chất lượng cao. Sau đó, Chúng tôi sử dụng phương pháp Minhash-LSH
để loại bỏ trùng lặp dữ liệu huấn luyện. Trong thực hành của chúng tôi, chúng tôi lọc ra dữ liệu trùng lặp
với độ tương tự vượt quá 0.7.
Chúng tôi tiến hành thêm khử nhiễm công thức chính xác cho dữ liệu lĩnh vực đặc biệt trên
tập kiểm tra MATH. Chúng tôi trích xuất tất cả các công thức trong một đoạn văn nhất định. Nếu việc nối
các công thức trùng với bất kỳ công thức nào trong tập kiểm tra MATH, chúng tôi đơn giản loại bỏ chúng.
3.3 Chiến lược huấn luyện
Sau khi thu thập và hậu xử lý dữ liệu thu thập và đặc biệt lĩnh vực chất lượng cao, chúng tôi thiết lập
các epoch huấn luyện khác nhau. Để biết chi tiết về tỷ lệ dữ liệu, xem Bảng 1. Tổng cộng, chúng tôi đã thu thập
31.2 tỷ token chất lượng cao trên các tập dữ liệu, chúng tôi tuân theo Muennighoff et al. (2023) để
sử dụng 4 epoch cho hầu hết các tập dữ liệu. Để tiếp tục tiền huấn luyện trên InternLM2-Base, chúng tôi áp dụng
chiến lược huấn luyện tương tự trên các kích thước mô hình khác nhau, như được mô tả trong InternLM (InternLM,
2023), và chúng tôi sử dụng InternEvo3làm framework huấn luyện. Trong quá trình huấn luyện, chúng tôi sử dụng
3https://github.com/InternLM/InternEvo
4

--- TRANG 5 ---
Báo cáo Kỹ thuật
BàitoánCOTORMBàitoánCOTPRMBàitoánCOTLEANBàitoán
CILEANBàitoánBàitoánLEANLEAN StateLEANNLStatementCOTCode InterpreterLEAN Calculation CodeLEAN StateLEAN TacticLEAN Calculation CodeĐúng / SaiStep K: Đúng / SaiInternLM2-MathAUGBàitoánAUG BàitoánBàitoánAUGAUG BàitoánCOTĐúng/SaiBàitoánCOTNL StatementBàitoánRMCOTNL StatementLEAN StateLEANLEAN TacticLEAN
Hình 2: Phần bên trái hiển thị các định dạng truy vấn và phản hồi trong SFT. Các phần bên phải hiển thị
hai cách sử dụng có thể có của mô hình SFT của chúng tôi. Phần trên bên phải là một quy trình tổng hợp các
bài toán mới sử dụng khả năng trợ lý tăng cường, COT, và RM của chúng tôi. Phần dưới bên phải là một quy trình
giải quyết các bài toán không chính thức sử dụng ngôn ngữ hình thức với khả năng COT và lý luận hình thức.
độ dài ngữ cảnh là 4096. Đối với các tài liệu quá dài hoặc quá ngắn, chúng tôi cắt ngắn
hoặc nối chúng để đạt được độ dài ngữ cảnh mong muốn. Chúng tôi áp dụng huấn luyện độ chính xác hỗn hợp
với bfloat16 và FlashAttention2 (Dao, 2023) để đạt được việc sử dụng bộ nhớ và hiệu quả huấn luyện
tối ưu. Bộ tối ưu AdamW tiêu chuẩn (Loshchilov & Hutter, 2017) được
sử dụng với các siêu tham số β1=0.9,β2=0.95, và weight decay =0.1. Chúng tôi sử dụng một
bộ lập lịch tỷ lệ học tập cosin tiêu chuẩn. Cụ thể, tỷ lệ học tập của mô hình đạt
tối đa lrmax=3e−5 sau 2000 bước khởi động, và sau đó giảm dần xuống
tối thiểu lrmin=3e−6 trong suốt quá trình huấn luyện. Trong quá trình tiếp tục tiền huấn luyện,
tổng cộng 125 tỷ token đã được huấn luyện. Đối với mô hình 20B, chúng tôi dừng sớm ở
80 tỷ token dựa trên hiệu suất học ngữ cảnh.
4 Tinh chỉnh có Giám sát
Khác với các LLM chuyên về toán học khác tập trung vào giải quyết bài toán, các mô hình của chúng tôi
được nhắm mục tiêu là người giải toán và cũng sẵn sàng cho việc tự cải thiện đòi hỏi các khả năng
bao gồm tăng cường bài toán, mô hình hóa phần thưởng, tự xác minh, lý luận hình thức, và
thông dịch viên mã. Dữ liệu SFT của chúng tôi chứa dữ liệu viết bởi con người, tạo ra bởi quy tắc, và
do LLM tạo ra chất lượng cao cho các khả năng đã nêu ở trên, thành phần dữ liệu chi tiết có thể
được thấy trong Bảng 16 và các phản hồi được tạo ra bởi mô hình của chúng tôi có thể được thấy trong Phụ lục D. Chúng tôi hiển thị
định dạng truy vấn và phản hồi của SFT trong Hình 2.
Chuỗi-tư-duy Chúng tôi sử dụng MetaMath (Yu et al., 2023b) như nguồn dữ liệu chuỗi-tư-duy
tiếng Anh cơ bản mang lại cải thiện lý luận nhất quán cho các
LLM khác nhau. Chúng tôi tận dụng tập dữ liệu tiếng Trung nội bộ cho khả năng chuỗi-tư-duy tiếng Trung.
Để cải thiện khả năng lý luận toán học của các điểm yếu của mô hình, chúng tôi áp dụng tăng cường đường lý luận
(Zelikman et al., 2022) trên các tập dữ liệu cụ thể. Lấy cảm hứng từ Uesato et al. (2022),
chúng tôi sử dụng câu trả lời cuối cùng và PRM được huấn luyện để lọc các đường lý luận tăng cường.
Mặc dù chúng tôi thêm dữ liệu tính toán tổng hợp trong tiền huấn luyện, các mô hình vẫn hoạt động kém
trong các tính toán phức tạp. Theo tinh thần của scratchpad (Nye et al., 2021; Liu & Low, 2023),
chúng tôi phân tách các tính toán phức tạp bao gồm tính toán nhiều dấu ngoặc, tính toán thập phân, tính toán và rút gọn phân số, bài toán số dư, và tính toán lũy thừa
thành các bước có thể tính toán. Chúng tôi thấy rằng việc đơn giản thêm dữ liệu tính toán giống scratchpad
sẽ không ảnh hưởng đến hành vi tính toán của mô hình. Lý do đến từ định dạng của
dữ liệu SFT yêu cầu mô hình ngay lập tức tạo ra câu trả lời phương trình như
(12+17)3=24389 bên trong quá trình chuỗi-tư-duy, và chúng tôi ký hiệu nó là ảo giác tính toán
5

--- TRANG 6 ---
Báo cáo Kỹ thuật
ảo giác. Để giảm bớt ảo giác tính toán, chúng tôi khớp và viết lại các phương trình như vậy
((12+17)3=293=841∗29= (800+40+1)∗29=23200 +1160+29=24389) bên trong
quá trình chuỗi-tư-duy càng nhiều càng tốt. Điều này cải thiện khả năng tính toán trong
lý luận chuỗi-tư-duy.
Chúng tôi cũng giới thiệu một số khả năng toán học cơ bản bao gồm kiểm tra số nguyên tố, trò chơi
24, phân tích thừa số của một số nguyên, và tính toán diện tích tam giác. Nguyên tắc tổng hợp
dữ liệu này của chúng tôi là Mô hình tạo ra chuỗi-tư-duy dựa trên sơ đồ luồng thuật toán. Việc dự đoán token tiếp theo
phải được xác định bởi các token đã tạo và không phụ thuộc vào các token tương lai. Sử dụng
tính toán diện tích tam giác như một ví dụ, chúng tôi yêu cầu mô hình trước tiên kiểm tra xem ba cạnh có thể
tạo thành một tam giác và nếu đó là tam giác vuông. Mô hình không cần giả định nó tạo thành
tam giác vuông mà không có lý luận chuỗi-tư-duy. Bảng 4 đưa ra một ví dụ. Chúng tôi cũng
đưa ra một ví dụ phản hồi không tuân theo nguyên tắc của chúng tôi vì dự đoán tam giác vuông
yêu cầu mô hình biết các token tương lai 32+42=52.
Diện tích Tam giác
Truy vấn: Tính diện tích của một tam giác với độ dài: 3,4,5.
Phản hồi: Vì 3 +4>5, chúng có thể tạo thành một tam giác.
32=9, 42=16, 52=25, 9+16=25.
Vậy 32+42=52, đó là tam giác vuông.
Diện tích là 3 ∗4/2=12/2 =6.
Phản hồi Tệ: Vì tam giác này là tam giác vuông (32+42=52).
Diện tích là 3 ∗4/2=12/2 =6.
Mô hình hóa Phần thưởng Mô hình hóa phần thưởng giúp mô hình sắp xếp lại tốt hơn việc tạo ra của nó và
lọc dữ liệu tổng hợp cho việc tự cải thiện. Lấy cảm hứng từ Math Shepherd (Wang et al., 2023b), chúng tôi
thống nhất ORM và PRM thành cùng định dạng học seq2seq. Chúng tôi cũng thêm dữ liệu ORM tiếng Trung
sử dụng chuỗi-tư-duy tự lấy mẫu của mô hình với các câu trả lời cuối cùng tương ứng.
Lý luận Toán học Hình thức Thay vì giải quyết bài toán bằng ngôn ngữ tự nhiên không chính thức, dữ liệu của chúng tôi
cũng bao gồm các mẫu lý luận hình thức dựa trên LEAN 3. Mục tiêu của chúng tôi là sử dụng LEAN như một
người giải, xác minh, và chứng minh. Chúng tôi chưng cất gpt-4-1106 để giải quyết các bài toán tập huấn luyện GSM8K
sử dụng LEAN 3. Chúng tôi chọn tất cả các mã có thể tạo ra câu trả lời đúng. Phần này bao gồm
6705 mẫu. Chúng tôi chia một nửa thành định dạng tạo ra LEAN dựa trên bài toán được sử dụng
để huấn luyện một người giải và nửa còn lại thành định dạng dịch giữa LEAN và COT
được sử dụng để huấn luyện một trình xác minh. Trình xác minh dịch COT sang LEAN và có thể xác minh bằng cách kiểm tra
mọi tính toán của COT dựa trên tính toán LEAN. Như một người chứng minh, mô hình cần
dịch giữa các tuyên bố không chính thức và chính thức và tạo ra chiến thuật dựa trên trạng thái LEAN.
Chúng tôi sử dụng tập dữ liệu MathLib-train (mathlib Community, 2020) được trích xuất từ Han
et al. (2021) như dữ liệu huấn luyện người chứng minh.
Trợ lý Tăng cường Một khía cạnh quan trọng khác của dữ liệu của chúng tôi là giúp xây dựng dữ liệu tổng hợp
cho việc tự cải thiện. Bằng cách diễn đạt lại hoặc tăng cường một câu hỏi, người ta có thể dễ dàng có được
một sự đa dạng câu hỏi mở rộng (Luo et al., 2023; Yu et al., 2023b; Li et al., 2023). Dịch
các cặp câu hỏi-câu trả lời thành một tuyên bố ngôn ngữ tự nhiên là yêu cầu của việc sử dụng
ngôn ngữ toán học hình thức để chứng minh.
5 Thông dịch viên Mã
Các nỗ lực gần đây (Chen et al., 2023b; Wang et al., 2023a; Gou et al., 2023) đã khám phá
việc tăng cường khả năng tính toán phức tạp của LLM bằng công cụ, trong đó thông dịch viên mã đã
trở nên phổ biến do tính linh hoạt và chức năng được hỗ trợ bởi các thư viện Python khác nhau.
Các khám phá ban đầu sử dụng chương trình như một loại chiến lược tư duy (Chen et al., 2023b; Gao et al.,
2023) nhưng không phù hợp cho lý luận và tính toán nhiều bước vì LLM không thể thấy
6

--- TRANG 7 ---
Báo cáo Kỹ thuật
Hình 3: Ví dụ về lý luận xen kẽ với mã hóa (RICO) và chuỗi-tư-duy
thông thường.
kết quả thực thi mã. Các công trình gần đây (Wang et al., 2023a; Gou et al., 2023) cố gắng tích hợp
thông dịch viên mã một cách liền mạch hơn với lý luận nhưng không tương thích và yêu cầu
sửa đổi bổ sung cho các dịch vụ trò chuyện chung.
Chúng tôi giải quyết vấn đề đã đề cập ở trên bằng cách để LLM thực hiện lý luận xen kẽ với mã hóa
(RICO), trong đó LLM thực hiện lý luận theo cùng định dạng như phản hồi trò chuyện và áp dụng một
giao thức gọi công cụ chung để sử dụng thông dịch viên mã. Thiết kế như vậy không chỉ cho phép
khai thác đầy đủ khả năng lý luận hiện có của LLM khi sử dụng thông dịch viên mã
mà còn cho phép tích hợp đầy đủ trực tiếp khả năng gọi công cụ vào mô hình trò chuyện. Do đó,
các khả năng khác nhau (như gọi công cụ và trò chuyện) của một mô hình có thể cung cấp dịch vụ trong một
hệ thống tăng cường công cụ phổ quát, mà chúng tôi tin là tương tự hơn với GPT-4
(OpenAI, 2023).
Cụ thể, như được hiển thị trong Hình 3, khi trả lời một bài toán, chúng tôi khuyến khích mô hình
thực hiện lý luận tượng trưng và tạo chương trình và sau đó quan sát kết quả thực thi mã
trong mỗi vòng. Mô hình sẽ tiếp tục các vòng như vậy cho đến khi nó trả lời đầy đủ
bài toán sau khi tóm tắt kết quả, khác với các phương pháp trước đây(Wang et al., 2023a; Gou
et al., 2023) về cơ bản viết mã một lần. Quá trình lý luận sử dụng cùng định dạng như
phản hồi trò chuyện chung thay vì sử dụng các dấu hiệu khác nhau cho cả văn bản và mã (Wang et al.,
2023a). Thiết kế như vậy cho phép mô hình khai thác đầy đủ khả năng lý luận đã học trong
kho dữ liệu SFT thông thường khi sử dụng thông dịch viên mã. Việc tạo chương trình có thể được
coi là một lời gọi công cụ chung, khác với ToRA(Gou et al., 2023), nhúng mã
trong phản hồi văn bản bằng cú pháp markdown. Điều này giải quyết sự mơ hồ trong ký hiệu markdown
của khối mã khi triển khai LLM trong hệ thống trò chuyện tăng cường công cụ.
Việc xây dựng dữ liệu huấn luyện cho thông dịch viên mã toán học áp dụng một chiến lược
cập nhật dữ liệu lặp và khai thác ví dụ khó để giảm sự phụ thuộc vào GPT-4. Ở mỗi
7

--- TRANG 8 ---
Báo cáo Kỹ thuật
lặp lại, chúng tôi trước tiên sử dụng mô hình được huấn luyện trong lặp lại trước đó để tạo ra phản hồi trên
tập huấn luyện của GSM8K và MATH. Vì mô hình không thể khớp hoàn toàn với tập huấn luyện, chúng tôi sử dụng
GPT-4-turbo để tạo ra phản hồi trên tập huấn luyện còn lại một lần. Các phản hồi đúng
được tạo ra bởi mô hình gần đây nhất và GPT-4-turbo sẽ được sử dụng để huấn luyện một mô hình mới cho
lặp lại tiếp theo. Dữ liệu ban đầu được tạo ra bởi ToRA-70B (Gou et al., 2023), không
lý tưởng do sự khác biệt về định dạng nhưng có thể được chuyển đổi thành phản hồi đúng để huấn luyện mô hình ban đầu.
Các mô hình InternLM2-Chat và InternLM2-Math áp dụng cùng dữ liệu huấn luyện cho khả năng thông dịch viên mã
.
6 Thí nghiệm
6.1 Hiệu suất Tiền huấn luyện
Để xác thực hiệu suất của các mô hình cơ sở tiền huấn luyện của chúng tôi, chúng tôi sử dụng điểm chuẩn tiêu chuẩn
cho lý luận không chính thức toán học: GSM8K (Cobbe et al., 2021) và MATH (Hendrycks et al.,
2021a) và đánh giá chúng sử dụng học ngữ cảnh. Chúng tôi áp dụng các mẫu few-shot từ
OpenCompass (Contributors, 2023). Chúng tôi sử dụng độ chính xác bỏ phiếu đa số (Wang et al., 2023c) làm
thước đo. Kết quả được liệt kê trong Bảng 2. Các mô hình InternLM2-Math-Base vượt trội hơn
các điểm kiểm tra ban đầu InternLM2-Base trên cả hai điểm chuẩn cho thấy hiệu quả của
việc tiếp tục tiền huấn luyện. InternLM2-Math-Base-7B đạt 21.5 trên MATH vượt trội hơn
Llemma-7B với 18.0. InternLM2-Math-Base-20B đạt 27.3 trên MATH vượt trội hơn
Llemma-34B và hoạt động tương tự với Minerva-62B với kích thước nhỏ hơn.
Bảng 2: So sánh các mô hình tiền huấn luyện sử dụng ICL. Thước đo là độ chính xác bỏ phiếu đa số.
K=100 cho điểm chuẩn GSM8K và K=256 cho điểm chuẩn MATH. Chúng tôi sử dụng giải mã tham lam
khi K=1. Chúng tôi lấy mẫu mô hình của chúng tôi sử dụng nhiệt độ 0.7 khi K>1.
Điểm chuẩn GSM8K MATH
Mô hình MAJ@1 MAJ@K MAJ@1 MAJ@K
Llama2-7B (Touvron et al., 2023) 14.6 - 2.5 -
Llemma-7B (Azerbayev et al., 2023b) 36.4 54.0 18.0 33.5
InternLM2-Base-7B 36.5 - 8.6 -
InternLM2-Math-Base-7B 49.2 75.7 21.5 35.6
Minerva-8B (Lewkowycz et al., 2022b) 16.2 28.4 14.1 25.4
InternLM2-Base-20B 54.6 - 13.7 -
InternLM2-Math-Base-20B 63.7 84.8 27.3 46.2
Llemma-34B 51.5 69.3 25.0 43.1
Minerva-62B 52.4 68.5 27.6 43.4
Minerva-540B 58.8 78.5 33.6 50.3
Một mô hình cơ sở tiền huấn luyện có thể có hiệu suất ICL tốt trong khi hoạt động trung bình
sau SFT do chồng chéo dữ liệu giữa tiền huấn luyện và SFT. Chúng tôi thực hiện SFT trên các mô hình khác nhau
với cùng tập dữ liệu SFT MetaMath (Yu et al., 2023b) để kiểm tra các mô hình của chúng tôi không gặp phải
hiện tượng như vậy. Chúng tôi hiển thị kết quả trong Bảng 3. Sử dụng MetaMath cho SFT, InternLM2-Math-
Base-7B vẫn có ưu thế so với Mistral-7B và Llemma-7B trên điểm chuẩn MATH.
InternLM2-Math-Base-20B vượt trội hơn Llemma-34B trên cả hai điểm chuẩn.
Để hiển thị khả năng lý luận toán học hình thức của mô hình, chúng tôi thực hiện ICL4trên
điểm chuẩn MiniF2F (Zheng et al., 2021) bao gồm các bài toán toán học cấp độ khác nhau trong ngôn ngữ
LEAN. LEAN có thể kiểm tra xem bằng chứng hình thức được tạo ra có hoàn thành mục tiêu của tuyên bố hay không.
Chúng tôi so sánh InternLM2-Math-Base với các mô hình ngôn ngữ tiền huấn luyện khác trong Bảng 4.
InternLM2-Math-7B-Base giải quyết 74 trong số 244 bài toán và đạt 30.3 tạo ra hiệu suất
tiên tiến mới. InternLM2-Math-7B-Base và InternLM2-Math-20B-Base tìm thấy
25 và 24 bằng chứng mới tương ứng không xuất hiện trong kho MiniF2F chính thức5.
Giống như Gloeckle et al. (2023); Azerbayev et al. (2023b), chúng tôi không thấy hiệu suất lý luận hình thức
4Thiết lập đang tuân theo https://github.com/wellecks/llemma formal2formal
5https://github.com/openai/miniF2F/blob/main/LEAN/src/test.LEAN
8

--- TRANG 9 ---
Báo cáo Kỹ thuật
Bảng 3: So sánh các mô hình tiền huấn luyện bằng cách tinh chỉnh trên tập dữ liệu MetaMath (Yu et al., 2023b).
Thước đo là độ chính xác tham lam. †kết quả đến từ Yu et al. (2023b). * kết quả đến từ
Wang et al. (2023b).
Mô hình GSM8K MATH
MetaMath-Llama2-7B (Touvron et al., 2023) † 66.5 19.8
MetaMath-Mistral-7B (Jiang et al., 2023) † 77.7 28.2
MetaMath-Llemma-7B (Azerbayev et al., 2023b) † 69.2 30.0
MetaMath- InternLM2-Math-Base-7B 76.4 33.8
MetaMath- InternLM2-Math-Base-20B 80.7 36.1
MetaMath-Llemma-34B * 75.8 34.8
hiệu suất tăng theo kích thước tham số mô hình. Chúng tôi để lại cho công việc tương lai về cách dữ liệu
và kích thước tham số ảnh hưởng đến hiệu suất lý luận hình thức.
Bảng 4: Hiệu suất tập kiểm tra MiniF2F. Ngân sách tìm kiếm giống như Azerbayev et al.
(2023b) là 1 ×32. Chúng tôi sử dụng 3-shot và LEAN 4 cho các mô hình cơ sở.
Mô hình Loại Tìm kiếm MiniF2F-test
ReProver (Yang et al., 2023a) SFT - 26.5
LLMStep (Welleck & Saha, 2023) SFT 1 ×32 27.9
Code-Llama-7B (Rozière et al., 2023) ICL 1 ×32 20.5
Code-Llama-34B ICL 1 ×32 22.1
Mistral-7B-v0.1 (Jiang et al., 2023) ICL 1 ×32 22.1
Mixtral-8x7B-v0.1 (Jiang et al., 2024) ICL 1 ×32 23.4
Llemma-7B (Azerbayev et al., 2023b) ICL 1 ×32 26.2
Llemma-34B ICL 1 ×32 25.8
Deepseek-coder-7B-v1.5-Base (Guo et al., 2024) ICL 1 ×32 28.7
Deepseek-math-7B-Base (Shao et al., 2024) ICL 1 ×32 28.3
InternLM2-7B-Base ICL 1 ×32 22.1
InternLM2-20B-Base ICL 1 ×32 25.4
InternLM2-Math-7B-Base ICL 1 ×32 30.3
InternLM2-Math-20B-Base ICL 1 ×32 29.5
6.2 Hiệu suất SFT
Để hiển thị hiệu suất của các mô hình SFT của chúng tôi, chúng tôi thực hiện lý luận toán học sử dụng chuỗi-tư-duy,
mô hình hóa phần thưởng, lý luận hình thức, và thông dịch viên mã. Chúng tôi cũng sẽ kiểm tra một số
khả năng được giới thiệu trong quá trình SFT của chúng tôi bao gồm trò chơi-24 và kiểm tra số nguyên tố.
6.2.1 Lý luận COT
Chúng tôi đánh giá các mô hình SFT trên GSM8K (Cobbe et al., 2021), MATH (Hendrycks et al., 2021a),
kỳ thi toán Hungary, và MathBench-ZH6sử dụng lý luận chuỗi-tư-duy zero-shot. Chúng tôi
sử dụng kỳ thi toán Hungary để kiểm tra khả năng tổng quát của mô hình và sử dụng MathBench-ZH
để kiểm tra khả năng toán tiếng Trung. MathBench-ZH chứa 600 bài toán toán tiếng Trung từ
cấp tiểu học, trung học cơ sở, trung học phổ thông, hoặc cấp đại học. Đối với mỗi bài toán lựa chọn trong
MathBench-ZH, chúng tôi sẽ xáo trộn thứ tự lựa chọn 4 lần. Một mô hình đưa ra câu trả lời đúng 4
lần có thể được coi là đúng. Chúng tôi hiển thị kết quả trong Bảng 5. InternLM2-Math-7B đạt
78.1, 34.6, 55, và 40 trên GSM8K, MATH, kỳ thi toán Hungary, và MathBench-ZH
tương ứng cho thấy hiệu suất trong-lĩnh vực và ngoài-lĩnh vực mạnh mẽ hơn nhiều ở cùng
kích thước mô hình. InternLM2-Math-7B cũng cho thấy hiệu suất tốt hơn so với việc sử dụng
MetaMath cho SFT chứng minh dữ liệu SFT của chúng tôi có thể kích hoạt tốt hơn khả năng lý luận của mô hình.
InternLM2-Math-20B đạt 37.7 và 66 trên MATH và kỳ thi toán Hungary
6https://github.com/open-compass/MathBench
9

--- TRANG 10 ---
Báo cáo Kỹ thuật
chỉ sau GPT-4. Nó đạt hiệu suất tiên tiến với kích thước nhỏ hơn nhiều
so với Qwen-72B và DeepSeek-67B.
Bảng 5: So sánh các mô hình SFT sử dụng lý luận COT zero-shot. Thước đo là độ chính xác tham lam.
Mô hình GSM8K MATH Hungary MathBench-ZH
Qwen-7B-Chat (Alibaba, 2023) 51.7 11.6 19 25.0
DeepSeek-7B-Chat (Bi et al., 2024) 63.0 15.8 28.5 12.7
InternLM2-Chat-7B 70.7 23.0 - 29.2
ChatGLM3-6B (Du et al., 2022) 53.8 20.4 32 15.2
MetaMath-Mistral-7B (Jiang et al., 2023) 77.7 28.2 29 -
MetaMath-Llemma-7B (Azerbayev et al., 2023b) 69.2 30.0 - -
InternLM2-Math-7B 78.1 34.6 55 40.0
InternLM2-Chat-20B 79.6 31.9 - 37.8
MetaMath-Llemma-34B (Azerbayev et al., 2023b) 75.8 34.8 - -
InternLM2-Math-20B 82.6 37.7 66 45.3
Qwen-72B-Chat (Alibaba, 2023) 78.9 35.2 52 47.8
DeepSeek-67B-Chat (Bi et al., 2024) 84.1 32.6 58 33.2
ChatGPT 80.8 34.1 41 21.5
GPT-4 (phiên bản gốc) 92.0 42.5 68 47.2
6.2.2 Mô hình hóa Phần thưởng
Các mô hình phần thưởng có thể được sử dụng để sắp xếp lại câu trả lời để cải thiện hiệu suất mô hình (Cobbe
et al., 2021; Uesato et al., 2022; Lightman et al., 2023; Wang et al., 2023b). Chúng tôi sẽ kiểm tra
hiệu suất của mô hình hóa phần thưởng của chúng tôi bằng sắp xếp lại ORM và PRM. Chúng tôi sử dụng cùng
mô hình SFT để suy luận và sắp xếp lại mô hình phần thưởng. Chúng tôi kiểm tra thêm việc sử dụng LEAN như một
mô hình phần thưởng (LRM) bằng cách yêu cầu mô hình chuyển đổi COT sang mã LEAN và thực thi
mã LEAN. Chúng tôi sẽ đánh dấu COT này là đúng với mã LEAN và COT đạt được
cùng kết quả. Lưu ý rằng việc sử dụng LEAN như một mô hình phần thưởng cho các nhiệm vụ như GSM8K chỉ có thể
kiểm tra quá trình tính toán chứ không phải quá trình logic. Chúng tôi kiểm tra trên GSM8K và MATH
(500 bài toán kiểm tra), kết quả được vẽ trong Hình 4 và hiển thị trong Bảng 19. Chúng tôi thấy rằng
nói chung việc sử dụng PRM vượt trội hơn ORM, và ORM vượt trội hơn bỏ phiếu đa số phù hợp
với (Lightman et al., 2023; Wang et al., 2023b). Chúng tôi thấy rằng việc sử dụng LEAN như
RM có lợi thế đáng kể trong việc sắp xếp lại GSM8K với các mô hình 7B, nhưng lợi thế
giảm đi với các mô hình 20B. Có rất nhiều chỗ cải thiện giữa hiệu suất sắp xếp lại RM
và hiệu suất oracle.
Chúng tôi cũng so sánh hiệu suất của chúng tôi với các mô hình sắp xếp lại RM khác trong Bảng 6. So với
sắp xếp lại MetaMath-DeepSeek-67B (Wang et al., 2023b), mô hình 20B của chúng tôi sử dụng ít lần suy luận hơn,
kích thước mô hình nhỏ hơn, và đạt hiệu suất tốt hơn với độ chính xác 50.0
cho thấy rằng RM của chúng tôi hiệu quả. Tuy nhiên, so với GPT-4-MathMix (Lightman
et al., 2023), khoảng cách hiệu suất vẫn lớn.
Bảng 6: Hiệu suất sắp xếp lại trên MATH(500) so với các đường cơ sở khác.
Mô hình Tham lam Phương pháp Hiệu suất
InternLM-MATH-7B 34.6 PRM K=100 47.0
InternLM-MATH-20B 37.7 PRM K=100 50.0
MetaMath-Llemma-34B 34.8 PRM K=256 47.3
MetaMath-DeepSeek-67B 36.8 PRM K=256 48.1
GPT-4-MathMix - ORM K=100 71.0
GPT-4-MathMix - PRM K=100 74.5
GPT-4-MathMix - ORM K=1860 72.4
GPT-4-MathMix - PRM K=1860 78.2
10

--- TRANG 11 ---
Báo cáo Kỹ thuật
Hình 4: Hiệu suất sắp xếp lại sử dụng các mô hình phần thưởng của chúng tôi trên GSM8K và MATH. Oracle
hiển thị hiệu suất giới hạn trên được tính bằng Pass@K.
6.2.3 Khả năng Hình thức
Nhắm mục tiêu vào một mô hình ngôn ngữ lớn để thực hiện lý luận toán học có thể xác minh, nhiều khả năng
được yêu cầu bao gồm dịch các bài toán hoặc tuyên bố chứng minh không chính thức thành tuyên bố hình thức
và giải quyết hoặc chứng minh các tuyên bố hình thức sử dụng ngôn ngữ hình thức.
Dịch Hình thức Chúng tôi trước tiên đánh giá khả năng dịch giữa ngôn ngữ tự nhiên
và tuyên bố hình thức. Chúng tôi tuân theo Azerbayev et al. (2023a) để dịch các tuyên bố được trích xuất
từ sách giáo khoa toán học đại học. Kết quả được liệt kê trong Bảng 7. Trong khi
mô hình của chúng tôi vượt trội hơn ProofGPT và phiên bản SFT của chúng (Azerbayev et al., 2023a) trong dịch hai chiều,
chúng tôi vẫn thua CodeX (Chen et al., 2021) và GPT-4 (OpenAI, 2023). Tương tự
với lý luận hình thức, chúng tôi không thấy lợi ích đáng kể từ việc mở rộng tham số.
Bảng 7: Đánh giá dịch giữa LEAN và tuyên bố ngôn ngữ không chính thức. Kết quả
ngoại trừ mô hình của chúng tôi được sao chép từ https://github.com/zhangir-azerbayev/ProofNet . Thước đo là điểm BLEU-4.
Mô hình Hình thức hóa Không chính thức hóa
ProofGPT-1.3B (Azerbayev et al., 2023a) 8.1 5.1
ProofGPT-6.7B (Azerbayev et al., 2023a) 4.7 6.0
ProofGPT-1.3B back-translated (Azerbayev et al., 2023a) 10.7 -
CodeX (Chen et al., 2021) 25.1 13.2
GPT-4 (OpenAI, 2023) 27.1 -
InternLM2-Math-7B 15.0 9.4
InternLM2-Math-20B 15.7 10.2
Sử dụng LEAN để giải quyết GSM8K LEAN chủ yếu được sử dụng như một trợ lý chứng minh để chứng minh một
tuyên bố thay vì giải quyết một bài toán. Để thống nhất việc giải quyết và chứng minh bài toán,
chúng tôi khám phá việc sử dụng LEAN để giải quyết bài toán. Chúng tôi yêu cầu mô hình tạo ra nhận xét
trước mã LEAN và liệt kê một ví dụ trong Bảng 6.2.3. Chúng tôi sử dụng LEAN 3 để biên dịch và
xuất kết quả như câu trả lời. Hiệu suất được liệt kê trong Bảng 8. Mô hình 7B của chúng tôi có thể đạt
11

--- TRANG 12 ---
Báo cáo Kỹ thuật
70.4 sử dụng LEAN để giải quyết GSM8K, trong khi mô hình 20B của chúng tôi có thể đạt 73.9. Chúng tôi thấy rằng
mô hình của chúng tôi hoạt động kém hơn COT. Lý do việc sử dụng LEAN kém hơn COT là: (1)
a−b=0 (khi a:N<b:N) (2) phép chia: a/b= [a/b](khi a:N,b:N). Những điều này gây
bất tiện trong một số tính toán cơ bản. Tuy nhiên, chúng tôi cho thấy khả năng sử dụng LEAN
như một giao diện thống nhất để giải quyết và chứng minh bài toán.
Giải quyết GSM8K sử dụng LEAN 3
Truy vấn: Một chiếc áo choàng cần 2 cuộn sợi xanh và một nửa lượng sợi trắng. Tổng cộng cần bao nhiều
cuộn?
Phản hồi:
-- Định nghĩa lượng sợi xanh cần cho một chiếc áo choàng
def blue_fiber_per_robe : N:= 2
-- Định nghĩa lượng sợi trắng cần cho một chiếc áo choàng bằng một nửa sợi xanh
def white_fiber_per_robe : N:= blue_fiber_per_robe / 2
-- Tính tổng lượng sợi cần cho một chiếc áo choàng
def total_fiber_per_robe : N:= blue_fiber_per_robe + white_fiber_per_robe
-- Xuất kết quả
#eval total_fiber_per_robe -- Điều này sẽ đánh giá thành 3 cuộn tổng cộng
Đầu ra: 3
Bảng 8: Hiệu suất trên GSM8K sử dụng COT và LEAN.
Mô hình COT LEAN
InternLM2-Math-7B 78.1 70.4
InternLM2-Math-20B 82.6 73.9
6.2.4 Thông dịch viên Mã
Như được hiển thị trong Bảng 9. InternLM2-Math-7B đã có thể vượt qua tất cả các mô hình mã nguồn mở
trước đây trên điểm chuẩn MATH ngoại trừ InternLM2-Chat-20B. InternLM2-Math-20B vượt trội hơn
InternLM2-Chat-20B và đạt kết quả tốt nhất trong các mô hình mã nguồn mở. Vì
InternLM2-Math và InternLM2-Chat áp dụng cùng dữ liệu huấn luyện cho thông dịch viên mã, chúng tôi tin
rằng những cải thiện của InternLM2-Math so với các mô hình InternLM2-Chat là kết quả
cải thiện khả năng lý luận toán học.
6.2.5 Các khả năng khác
Trò chơi 24 Để kiểm tra khả năng Trò chơi 24, chúng tôi sử dụng tập kiểm tra từ Yao et al. (2023).
Khi chúng tôi lấy mẫu một lần cho mỗi câu hỏi, các mô hình của chúng tôi đạt độ chính xác 26 và 35
tương ứng cho kích thước mô hình 7B và 20B, vượt trội hơn nhiều so với Llamma2-
7B được tinh chỉnh và thậm chí GPT-4. Hiệu suất có thể sánh với một số phương pháp đa mẫu,
cho thấy khả năng của dữ liệu SFT quá trình tìm kiếm từng bước được tạo ra của chúng tôi.
Kiểm tra số nguyên tố Đối với xác minh số nguyên tố, chúng tôi lấy mẫu một tập dữ liệu kiểm tra chứa 20
số cho mỗi số chữ số từ 2 đến 10 chứa 10 số nguyên tố và 10 số hợp số.
Mô hình của chúng tôi có thể đánh giá đúng cho hầu như tất cả các số, bất kể số chữ số của chúng, điều này
tốt hơn GPT-4 hoạt động kém hơn khi số chữ số trở nên lớn hơn.
12

--- TRANG 13 ---
Báo cáo Kỹ thuật
Bảng 9: So sánh các mô hình SFT sử dụng Thông dịch viên Mã Python. Thước đo là độ chính xác tham lam.
* Điều này được kiểm tra trên phiên bản web GPT-4 vào tháng 8 năm 2023.
Mô hình GSM8K MATH
DeepSeek-Coder-Instruct-7B (Guo et al., 2024) 62.8 28.6
MathCODER-CL-7B (Wang et al., 2023a) 67.8 30.2
DeepSeek-Coder-Instruct-1.5-7B (Guo et al., 2024) 72.6 34.1
ToRA-7B (Gou et al., 2023) 72.6 44.6
InternLM2-Chat-7B 77.9 45.1
InternLM2-Math-7B 79.4 50.9
MathCODER-CL-13B (Wang et al., 2023a) 74.1 35.9
MathCODER-CL-34B (Wang et al., 2023a) 81.7 45.2
ToRA-13B (Gou et al., 2023) 75.8 48.1
ToRA-Code-34B (Wang et al., 2023a) 80.7 50.8
InternLM2-Chat-20B 84.5 51.2
InternLM2-Math-20B 80.7 54.3
ToRA-70B (Gou et al., 2023) 84.3 49.7
GPT-4 Code Interpreter * (Zhou et al., 2023) 97.0 69.7
Bảng 10: Hiệu suất của Trò chơi-24.
Mô hình Độ chính xác Số lần lấy mẫu
Fine-tuned Llama2-7B (Yu et al., 2023a) 11 1
GPT-4 COT (Yao et al., 2023) 4 1
InternLM2-Math-7B 26 1
InternLM2-Math-20B 35 1
TOT (Yao et al., 2023) 45 12( b=1)
OVM (Yu et al., 2023a) 79 20
7 Thảo luận
7.1 So sánh Hiệu suất Tiền huấn luyện với Lượng Token Tiền huấn luyện
Chúng tôi tiền huấn luyện trên InternLM-Base-7B trong 200B token để đánh giá bao nhiều epoch chúng tôi nên
tiền huấn luyện. Chúng tôi đánh giá hiệu suất mô hình của chúng tôi mỗi 40B token sử dụng ICL và SFT trên
MetaMath trong Bảng 12. Chúng tôi thấy rằng sau 80B token, hiệu suất không cải thiện
đáng kể. Khi huấn luyện lâu hơn đến 200B (khoảng 7 epoch) token, hiệu suất
bắt đầu suy giảm.
7.2 Hiệu suất LEAN trên GSM8K
Chúng tôi giới thiệu việc sử dụng LEAN để giải quyết bài toán GSM8K trước đây. LEAN thưa thớt trong
tiền huấn luyện và tinh chỉnh so với ngôn ngữ tự nhiên, LATEX, và Python. Chúng tôi muốn
hiểu khả năng LEAN liên quan đến kích thước dữ liệu như thế nào. Chúng tôi phân tích hiệu suất
LEAN giải quyết GSM8K sử dụng lượng dữ liệu SFT khác nhau trong Bảng 13. Chúng tôi thấy rằng nếu chúng tôi
chỉ sử dụng GSM8K-LEAN trong SFT, hiệu suất LEAN kém hơn việc sử dụng GSM8K-
LEAN và MetaMath cùng nhau. Chúng tôi cũng thấy rằng nếu chúng tôi SFT mà không có MetaMath, hiệu suất LEAN
nhạy cảm với lượng dữ liệu. Trong khi nếu chúng tôi huấn luyện SFT với MetaMath, hiệu suất LEAN
ít nhạy cảm hơn cho thấy rằng mô hình chủ yếu cần học ngữ pháp
từ dữ liệu GSM8K-LEAN và học khả năng lý luận từ MetaMath. Những phát hiện này
cho thấy khả năng lý luận của MetaMath giúp hiệu suất trên LEAN với dữ liệu thưa thớt và
gợi ý một chiến lược huấn luyện đa nhiệm vụ cho những khả năng này.
13

--- TRANG 14 ---
Báo cáo Kỹ thuật
Bảng 11: Kiểm tra xác minh số nguyên tố bằng cách kiểm tra 10 số nguyên tố và 10 số hợp số
cho các chữ số từ 2 đến 10, tất cả kết thúc bằng 1, 3, 7, hoặc 9 (Kết thúc bằng các số khác là
số hợp số.). Kết quả 'a/b' chỉ ra số lượng xác định đúng, với
'a' đại diện cho số nguyên tố và 'b' đại diện cho số hợp số.
Mô hình 2 3 4 5 6 7 8 9 10
InternLM2-Math-7B 10/10 10/10 10/8 10/8 10/6 10/7 10/10 10/10 10/10
InternLM2-Math-20B 10/10 10/10 10/6 10/9 10/10 10/6 10/10 10/9 10/9
gpt-4-0125-preview 10/10 10/10 3/8 2/9 0/10 0/10 0/10 1/10 0/10
Bảng 12: Hiệu suất tiền huấn luyện trên lượng token tiền huấn luyện khác nhau.
Điểm chuẩn GSM8K MATH
Token ICL SFT ICL SFT
40B 30.9 75.3 19.5 30.2
80B 38.7 77.4 21.4 30.7
120B 39.0 76.4 21.5 33.8
160B 38.4 75.8 21.4 31.9
200B 35.1 76.7 21.1 31.3
7.3 Nghiên cứu Phân tích Dữ liệu trong SFT
Để nghiên cứu tác động của thành phần dữ liệu hỗn hợp của chúng tôi, chúng tôi đã thực hiện các nghiên cứu phân tích
cho mỗi loại dữ liệu trong hỗn hợp cuối cùng. Chúng tôi bao gồm tập dữ liệu MetaMath cho mọi
nghiên cứu phân tích để giữ các khả năng cơ bản để giải quyết bài toán từng bước. Kết quả đánh giá
được thể hiện trong Bảng 14. So với việc sử dụng MetaMath cho SFT, mô hình InternLM-
Math-7B của chúng tôi và mô hình với dữ liệu COT đạt kết quả tốt hơn trên MATH và GSM8K.
Các thành phần khác, mặc dù chứa ít token hơn nhiều so với MetaMath, dẫn đến kết quả
kém hơn trên hầu hết các tập dữ liệu kiểm tra. Điều này có thể do chuyển đổi định dạng và phong cách
trong mã, định dạng mô hình phần thưởng, và các hướng dẫn khác. Tuy nhiên, dữ liệu SFT
hoạt động tốt hơn MetaMath + COT sau khi tích hợp, cho thấy sự hữu ích lẫn nhau tiềm ẩn
của dữ liệu toàn diện vượt ra ngoài việc sử dụng đặc biệt ban đầu của chúng.
7.4 Dương tính giả trong MATH BenchMark
Đối với một bài toán yêu cầu một câu trả lời, người ta luôn có thể thử một số trường hợp đặc biệt để đoán
câu trả lời đúng với quá trình sai. Nếu câu hỏi về đếm, câu trả lời được tạo ra có thể
được lấy mẫu sai, và có được câu trả lời đúng do may mắn. Điều này có thể dẫn
chúng ta đánh giá quá cao khả năng lý luận toán học của mô hình và các LLM khác. Chúng tôi lấy mẫu ngẫu nhiên
5 mẫu cho mỗi cấp độ khó mà InternLM2-Math-20B đưa ra câu trả lời đúng trong tập kiểm tra MATH và
gắn nhãn thủ công quá trình dự đoán của 25 bài toán này để báo cáo vấn đề này. Bảng 15 hiển thị kết quả.
Một trong những trường hợp dương tính giả viết:
Nghiên cứu Trường hợp Dương tính Giả
Truy vấn: Có bao nhiều cặp số nguyên dương có thứ tự (m,n)thỏa mãn gcd(m,n) = 2
và lcm [m,n] =108?
Phản hồi: Tôi biết rằng đối với bất kỳ số nguyên dương m và n nào,gcd(m,n)·lcm[m,n] =mn.
Vậy, nếu tôi áp dụng công thức này cho bài toán đã cho, tôi có 2 ·108=mn. Điều này có nghĩa là
m và n là các thừa số của 216. Tôi cũng biết rằng gcd(m,n) = 2, có nghĩa là m
và n đều chẵn, và không số nào chia hết cho 4. Vậy, tôi cần tìm số
cách chọn hai thừa số chẵn của 216 không chia hết cho 4. Tôi
có thể liệt kê các thừa số chẵn của 216 như sau: 2, 4, 6, 8, 9, 12, 18, 24, 27, 36, 54, 72, 108, 216.
Trong số này, những số không chia hết cho 4 là 2, 6, 9, 18, 27, 54, 108. Tôi có thể ghép
14

--- TRANG 15 ---
Báo cáo Kỹ thuật
Bảng 13: Hiệu suất trên GSM8K sử dụng COT và LEAN với các tập dữ liệu SFT khác nhau.
Thiết lập COT LEAN
InternLM-Math-Base-7B 49.2 -
+ MetaMath SFT 76.4 -
+ SFT của chúng tôi 78.1 70.4
GSM8K-LEAN1⁄1 - 58.0
GSM8K-LEAN1⁄2 - 53.1
GSM8K-LEAN1⁄4 - 35.1
GSM8K-LEAN1⁄8 - 38.4
GSM8K-LEAN1⁄1+ MetaMath 75.7 66.0
GSM8K-LEAN1⁄2+ MetaMath 75.6 65.0
GSM8K-LEAN1⁄4+ MetaMath 77.7 58.8
GSM8K-LEAN1⁄8+ MetaMath 77.4 53.4
Bảng 14: Kết quả phân tích thành phần dữ liệu SFT của chúng tôi.
Điểm chuẩn MATH GSM8K
InternLM-Math-7B 34.60 78.09
Chỉ MetaMath 33.78 76.35
MetaMath + COT 34.02 77.63
MetaMath + CI 33.56 77.63
MetaMath + Hình thức 32.12 76.12
MetaMath + RM 29.84 75.13
MetaMath + Tăng cường 32.08 75.89
các thừa số này như sau: (2, 108 ),(6, 54),(9, 27),(18, 18 ). Có bốn cặp,
và mỗi cặp tương ứng với một cặp có thứ tự khác nhau (m,n). Ví dụ, (2, 108 )
tương ứng với (m,n) = ( 108, 2 ). Vậy, có bốn cặp có thứ tự (m,n)thỏa mãn
điều kiện đã cho. Câu trả lời 4.
Trong trường hợp này, mô hình liệt kê 9 và 27 như một số chẵn, dẫn đến một cặp (m,n) sai
(9, 27). Hơn nữa, các cặp (6, 54),(18, 18 ), mặc dù thỏa mãn điều kiện do mô hình
dự đoán, không đáp ứng yêu cầu của tiêu đề. Dự đoán chỉ tình cờ liệt kê bốn
cặp như câu trả lời. Tuy nhiên, nếu đánh giá chỉ xem xét kết quả,
mẫu này sẽ "đúng". Các trường hợp tương tự xuất hiện thường xuyên hơn khi cấp độ khó
tăng. Trong số những trường hợp dương tính giả này, hầu hết các bài toán có một số nguyên làm câu trả lời,
đặc biệt là số một chữ số, và lời giải có thể được thực hiện mà không cần tính toán chi tiết
hoặc chứng minh các trường hợp. Những điều này làm cho mô hình dễ dàng suy đoán một câu trả lời đúng
loại trừ lý luận từng bước. Việc đơn giản đánh giá khả năng mô hình chỉ bằng độ chính xác kết quả
có thể thiên lệch. Do đó, một trong những công việc tương lai của chúng tôi là sử dụng mô hình phần thưởng hoặc LEAN để
cung cấp kiểm tra quá trình tốt hơn.
Bảng 15: Tính Đúng đắn của Quá trình trong MATH BenchMark sử dụng mô hình 20B của chúng tôi.
Cấp độ khó Kết quả đúng Quá trình đúng
Cấp 1 5 5
Cấp 2 5 4
Cấp 3 5 4
Cấp 4 5 4
Cấp 5 5 3
15

--- TRANG 16 ---
Báo cáo Kỹ thuật
8 Kết luận
Chúng tôi đề xuất InternLM-Math như bước đầu tiên hướng tới khả năng lý luận toán học có thể xác minh.
InternLM-Math-Base xuất sắc có tiềm năng cho các nhiệm vụ lý luận toán học đa năng. Mặc dù
hiệu suất mạnh mẽ trong lý luận không chính thức và chính thức của InternLM-Math,
mô hình của chúng tôi có thể được xem như một điểm khởi đầu cho việc tự cải thiện. InternLM-Math tích hợp
khả năng COT và trợ lý tăng cường có thể được sử dụng để tổng hợp bài toán mới và phản hồi mới.
InternLM-Math đạt được khả năng ORM, PRM, và LEAN có thể được sử dụng để
xác minh câu trả lời và quá trình của phản hồi được tạo ra. Chúng tôi tin rằng việc tăng cường dữ liệu có thể xác minh như vậy
sẽ cải thiện khả năng của mô hình với thông lượng cao.
Hạn chế
Lý luận chuỗi-tư-duy Chúng tôi khớp và viết lại công thức theo tinh thần của scratch-
pad trong COT trong khi nó giới thiệu các vấn đề sau. Vấn đề đầu tiên là chúng tôi
không thể dễ dàng khớp tất cả các phương trình và tính toán cần được viết lại (ví dụ: Chúng tôi giải
x3−3x2+3x−1=0, và có được x=1). Vấn đề thứ hai là nhiều '=' khuyến khích
mô hình lặp lại nhiều hơn. Vấn đề thứ ba là điều này đôi khi tạo ra tính toán từng bước ngây thơ
có thể làm phiền người dùng cuối và có thể được giảm bớt thông qua lý luận chuỗi-tư-duy ngầm
(Deng et al., 2023). Chúng tôi sẽ giải quyết những vấn đề như vậy trong công việc tương lai.
Không có khả năng tự phê bình Mặc dù mô hình của chúng tôi có thể thực hiện ORM hoặc PRM. Chúng tôi không chứa
bất kỳ dữ liệu SFT nào để cho mô hình áp dụng tự phê bình vì dữ liệu như vậy có thể khó tạo ra
và xác minh bằng bất kỳ phương tiện nào. Chúng tôi sẽ nghiên cứu cách tạo ra dữ liệu SFT tự phê bình với
xác minh.
Mô hình hóa phần thưởng quá trình Chúng tôi thấy rằng mô hình của chúng tôi không có hiệu suất PRM đáng kể
có thể do định dạng gây nhầm lẫn giữa PRM và SFT và phân phối
không cân bằng giữa quá trình tích cực và quá trình tiêu cực.
Chuyển đổi mã Do phân phối dữ liệu SFT của chúng tôi, dữ liệu tiếng Anh lớn hơn dữ liệu tiếng Trung
sẽ gây ra chuyển đổi mã trong một số hướng dẫn hoặc định dạng bài toán.
Dữ liệu SFT đang sử dụng LEAN 3 Chúng tôi sử dụng LEAN 3 như dữ liệu SFT của chúng tôi vì GPT-4 chỉ có thể tạo ra
mã LEAN 3 cho GSM8K (ngay cả khi bạn yêu cầu nó áp dụng LEAN 4). Hơn nữa, chúng tôi thấy
dữ liệu dịch giữa hình thức và không chính thức từ MathLib được tiền xử lý trong LEAN
3. Chúng tôi sẽ chuyển dữ liệu SFT của chúng tôi sang LEAN 4 trong phiên bản tương lai.
Nhiễm dữ liệu trên LEAN-repo Chúng tôi sử dụng mã LEAN được giới thiệu từ Algebraic-
Stack (Azerbayev et al., 2023b), và chúng tôi không kiểm tra nhiễm của AlgebraicStack
trên MiniF2F. AlgebraicStack có thể chứa hoặc không chứa lời giải MiniF2F. Tuy nhiên,
so sánh giữa Llemma và mô hình của chúng tôi là công bằng.
Nhạy cảm với Prompt Các mô hình nhạy cảm với định dạng và prompt hướng dẫn đã cho. Nếu
chúng tôi đưa ra các prompt khác nhau trước câu hỏi (ví dụ: Question:, Q:, Please solve this question
step by step), nó có thể đạt được hiệu suất khác nhau.
Tài liệu tham khảo
Alibaba. Báo cáo kỹ thuật Qwen, 2023.
Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre
Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Báo cáo kỹ thuật Palm 2
. arXiv preprint arXiv:2305.10403 , 2023.
Zhangir Azerbayev, Bartosz Piotrowski, Hailey Schoelkopf, Edward W. Ayers, Dragomir
Radev, and Jeremy Avigad. Proofnet: Tự động hình thức hóa và chứng minh chính thức
toán học cấp đại học, 2023a.
16

--- TRANG 17 ---
Báo cáo Kỹ thuật
Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer,
Albert Q. Jiang, Jia Deng, Stella Biderman, and Sean Welleck. Llemma: Một mô hình ngôn ngữ mở
cho toán học, 2023b.
Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui
Ding, Kai Dong, Qiushi Du, Zhe Fu, et al. Deepseek llm: Mở rộng các mô hình ngôn ngữ
mã nguồn mở với chủ nghĩa dài hạn. arXiv preprint arXiv:2401.02954 , 2024.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini
Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan, Rewon Child, Aditya
Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen,
Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner,
Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Các mô hình ngôn ngữ
là người học few-shot. ArXiv , abs/2005.14165, 2020. URL https://api.semanticscholar.
org/CorpusID:218971783 .
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto,
Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray,
Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin,
Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings,
Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen
Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji,
Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh
Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage,
Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish,
Ilya Sutskever, and Wojciech Zaremba. Đánh giá các mô hình ngôn ngữ lớn được huấn luyện trên mã.
2021.
Nuo Chen, Zinan Zheng, Ning Wu, Linjun Shou, Ming Gong, Yangqiu Song, Dongmei
Zhang, and Jia Li. Phá vỡ rào cản ngôn ngữ trong lý luận toán học đa ngôn ngữ:
Những hiểu biết và quan sát, 2023a.
Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen. Prompt chương-trình-tư-duy:
Tách biệt tính toán khỏi lý luận cho các nhiệm vụ lý luận số. Giao dịch về Nghiên cứu Học máy , 2023b.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Huấn luyện trình xác minh
để giải quyết bài toán từ toán học. arXiv preprint arXiv:2110.14168 , 2021.
Cộng tác viên OpenCompass. Opencompass: Một nền tảng đánh giá phổ quát cho các mô hình nền tảng
. https://github.com/open-compass/opencompass , 2023.
Tri Dao. FlashAttention-2: Attention nhanh hơn với song song hóa và phân chia công việc tốt hơn.
2023.
Yuntian Deng, Kiran Prasad, Roland Fernandez, Paul Smolensky, Vishrav Chaudhary, and
Stuart Shieber. Lý luận chuỗi-tư-duy ngầm thông qua chưng cất kiến thức. ArXiv ,
abs/2311.01460, 2023. URL https://api.semanticscholar.org/CorpusID:264935229 .
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang.
Glm: Tiền huấn luyện mô hình ngôn ngữ chung với điền khoảng trống tự động. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1:
Long Papers) , pp. 320–335, 2022.
Zhaoye Fei, Yunfan Shao, Linyang Li, Zhiyuan Zeng, Hang Yan, Xipeng Qiu, and Dahua Lin.
Query of CC: Khai thác Kiến thức Đặc biệt Lĩnh vực Quy mô Lớn từ Kho dữ liệu Công cộng.
arXiv e-prints , art. arXiv:2401.14624, January 2024. doi: 10.48550/arXiv.2401.14624.
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan,
and Graham Neubig. Pal: Các mô hình ngôn ngữ hỗ trợ chương trình, 2023.
17

--- TRANG 18 ---
Báo cáo Kỹ thuật
Fabian Gloeckle, Baptiste Roziere, Amaury Hayat, and Gabriel Synnaeve. Mô hình ngôn ngữ lớn
có nhiệt độ điều chỉnh cho dự đoán bước chứng minh lean. Trong The 3rd Workshop on
Mathematical Reasoning and AI at NeurIPS'23 , 2023.
Google. Gemini: Một họ mô hình đa phương thức có khả năng cao, 2023.
Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan Duan,
and Weizhu Chen. Tora: Một tác nhân lý luận tích hợp công cụ cho giải quyết bài toán toán học
, 2023.
Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen,
Xiao Bi, Y. Wu, Y. K. Li, Fuli Luo, Yingfei Xiong, and Wenfeng Liang. Deepseek-coder:
Khi mô hình ngôn ngữ lớn gặp lập trình – sự trỗi dậy của trí thông minh mã, 2024.
Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W Ayers, and Stanislas Polu.
Đồng huấn luyện artifact chứng minh cho chứng minh định lý với mô hình ngôn ngữ. arXiv preprint
arXiv:2102.06203 , 2021.
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,
Dawn Song, and Jacob Steinhardt. Đo lường giải quyết bài toán toán học với
tập dữ liệu MATH. 2021a.
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,
Dawn Song, and Jacob Steinhardt. Đo lường giải quyết bài toán toán học với
tập dữ liệu math. arXiv preprint arXiv:2103.03874 , 2021b.
Shengding Hu, Yuge Tu, Xu Han, Chaoqun He, Ganqu Cui, Xiang Long, Zhi Zheng, Yewei
Fang, Yuxiang Huang, Weilin Zhao, et al. Minicpm: Tiết lộ tiềm năng của các mô hình ngôn ngữ nhỏ
với chiến lược huấn luyện có thể mở rộng. arXiv preprint arXiv:2404.06395 , 2024.
Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and
Jiawei Han. Các mô hình ngôn ngữ lớn có thể tự cải thiện, 2022.
InternLM. Internlm: Một mô hình ngôn ngữ đa ngôn ngữ với khả năng được tăng cường dần dần
. https://github.com/InternLM/InternLM , 2023.
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh
Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile
Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825 , 2023.
Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary,
Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian
Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088 , 2024.
Khan. Khan-exercises. https://github.com/Khan/khan-exercises , 2021.
Guillaume Lample, Timothee Lacroix, Marie-Anne Lachaux, Aurelien Rodriguez, Amaury
Hayat, Thibaut Lavril, Gabriel Ebner, and Xavier Martinet. Tìm kiếm chứng minh hypertree cho
chứng minh định lý neural. Advances in neural information processing systems , 35:26337–26349,
2022.
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski,
Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai
Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. Giải quyết các bài toán lý luận định lượng
với mô hình ngôn ngữ, 2022a.
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski,
Vinay V . Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai
Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. Giải quyết các bài toán lý luận định lượng
với mô hình ngôn ngữ. Trong NeurIPS , 2022b.
Chengpeng Li, Zheng Yuan, Guanting Dong, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang
Wang, and Chang Zhou. Tăng cường truy vấn và phản hồi không thể giúp tổng quát hóa lý luận toán học
ngoài lĩnh vực. arXiv preprint arXiv:2310.05506 , 2023.
18

--- TRANG 19 ---
Báo cáo Kỹ thuật
Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee,
Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Hãy xác minh từng bước. arXiv
preprint arXiv:2305.20050 , 2023.
Haoxiong Liu and Andrew Chi-Chih Yao. Tăng cường bài toán từ toán học thông qua sáng tác câu hỏi lặp lại
, 2024.
Hongwei Liu, Zilong Zheng, Yuxuan Qiao, Haodong Duan, Zhiwei Fei, Fengzhe Zhou,
Wenwei Zhang, Songyang Zhang, Dahua Lin, and Kai Chen. Mathbench: Đánh giá năng lực lý thuyết và ứng dụng
của llms với điểm chuẩn toán học phân cấp, 2024.
Tiedong Liu and Bryan Kian Hsiang Low. Goat: Llama được tinh chỉnh vượt trội hơn gpt-4 trong các nhiệm vụ số học
. arXiv preprint arXiv:2305.14201 , 2023.
Ilya Loshchilov and Frank Hutter. Chính quy hóa Weight Decay Tách rời. arXiv e-prints ,
art. arXiv:1711.05101, November 2017. doi: 10.48550/arXiv.1711.05101.
Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo
Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. Wizardmath: Trao quyền cho
lý luận toán học cho các mô hình ngôn ngữ lớn thông qua evol-instruct được tăng cường, 2023.
Math-eval. TAL-SCQ5K. https://github.com/math-eval/TAL-SCQ5K , 2023.
Cộng đồng mathlib. Thư viện toán học lean. Trong Proceedings of the 9th ACM
SIGPLAN International Conference on Certified Programs and Proofs , POPL '20. ACM, January
2020. doi: 10.1145/3372885.3373824. URL http://dx.doi.org/10.1145/3372885.3373824 .
Leonardo de Moura and Sebastian Ullrich. Người chứng minh định lý và ngôn ngữ lập trình lean 4
. Trong André Platzer and Geoff Sutcliffe (eds.), Automated Deduction – CADE 28 , pp.
625–635, Cham, 2021. Springer International Publishing. ISBN 978-3-030-79876-5.
Niklas Muennighoff, Alexander M. Rush, Boaz Barak, Teven Le Scao, Aleksandra Piktus,
Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, and Colin Raffel. Mở rộng các mô hình ngôn ngữ
bị ràng buộc dữ liệu, 2023.
Maxwell Nye, Anders Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David
Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton,
and Augustus Odena. Hiển thị công việc của bạn: Scratchpads cho tính toán trung gian với
mô hình ngôn ngữ. ArXiv , abs/2112.00114, 2021. URL https://api.semanticscholar.org/
CorpusID:244773644 .
OpenAI. Báo cáo kỹ thuật Gpt-4, 2023.
Keiran Paster, Marco Dos Santos, Zhangir Azerbayev, and Jimmy Ba. Openwebmath: Một tập dữ liệu mở
về văn bản web toán học chất lượng cao. arXiv preprint arXiv:2310.06786 , 2023.
Lawrence C. Paulson. Isabelle: 700 người chứng minh định lý tiếp theo, 2000.
Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin, and
Ilya Sutskever. Học chương trình giảng dạy tuyên bố toán học hình thức, 2022.
Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan,
Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov,
Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong,
Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas
Usunier, Thomas Scialom, and Gabriel Synnaeve. Code llama: Mô hình nền tảng mở
cho mã, 2023.
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, Y. K.
Li, Y. Wu, and Daya Guo. Deepseekmath: Đẩy giới hạn của lý luận toán học
trong các mô hình ngôn ngữ mở, 2024.
19

--- TRANG 20 ---
Báo cáo Kỹ thuật
Avi Singh, John D. Co-Reyes, Rishabh Agarwal, Ankesh Anand, Piyush Patil, Peter J. Liu,
James Harrison, Jaehoon Lee, Kelvin Xu, Aaron Parisi, Abhishek Kumar, Alex Alemi,
Alex Rizkowsky, Azade Nova, Ben Adlam, Bernd Bohnet, Hanie Sedghi, Igor Mordatch,
Isabelle Simpson, Izzeddin Gur, Jasper Snoek, Jeffrey Pennington, Jiri Hron, Kathleen
Kenealy, Kevin Swersky, Kshiteej Mahajan, Laura Culp, Lechao Xiao, Maxwell L. Bileschi,
Noah Constant, Roman Novak, Rosanne Liu, Tris Brian Warkentin, Yundi Qian, Ethan
Dyer, Behnam Neyshabur, Jascha Narain Sohl-Dickstein, and Noah Fiedel. Vượt ra ngoài
dữ liệu con người: Mở rộng tự huấn luyện cho giải quyết vấn đề với mô hình ngôn ngữ. ArXiv ,
abs/2312.06585, 2023. URL https://api.semanticscholar.org/CorpusID:266163375 .
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis
Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica: Một mô hình ngôn ngữ lớn
cho khoa học. 2023.
Nhóm Phát triển Coq. Tài liệu tham khảo Coq – phát hành 8.18.0. https://coq.
inria.fr/doc/V8.18.0/refman , 2023.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei,
Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas
Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude
Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman
Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas,
Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura,
Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning
Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew
Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva,
Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor,
Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang,
Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic,
Sergey Edunov, and Thomas Scialom. Llama 2: Mô hình nền tảng mở và trò chuyện được tinh chỉnh
, 2023.
Jonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, Lisa Wang,
Antonia Creswell, Geoffrey Irving, and Irina Higgins. Giải quyết bài toán từ toán học với
phản hồi dựa trên quá trình và kết quả, 2022.
Ke Wang, Houxing Ren, Aojun Zhou, Zimu Lu, Sichun Luo, Weikang Shi, Renrui Zhang,
Linqi Song, Mingjie Zhan, and Hongsheng Li. Mathcoder: Tích hợp mã liền mạch trong
llms để tăng cường lý luận toán học, 2023a.
Peiyi Wang, Lei Li, Zhihong Shao, RX Xu, Damai Dai, Yifei Li, Deli Chen, Y Wu, and Zhifang
Sui. Math-shepherd: Xác minh và tăng cường llms từng bước mà không cần chú thích của con người.
CoRR, abs/2312.08935 , 2023b.
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang,
Aakanksha Chowdhery, and Denny Zhou. Tự nhất quán cải thiện lý luận chuỗi-tư-duy
trong mô hình ngôn ngữ. Trong The Eleventh International Conference on Learning Representations , 2023c. URL https://openreview.net/forum?id=1PL1NIMMrw .
Yan Wang, Xiaojiang Liu, and Shuming Shi. Bộ giải quyết neural sâu cho bài toán từ toán học. Trong
Martha Palmer, Rebecca Hwa, and Sebastian Riedel (eds.), Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Processing , pp. 845–854, Copenhagen, Denmark,
September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1088.
URL https://aclanthology.org/D17-1088 .
Zengzhi Wang, Rui Xia, and Liu Pengfei. AI tạo sinh cho toán: Phần i – mathpile: Một
kho dữ liệu tiền huấn luyện quy mô tỷ token cho toán. arXiv preprint arXiv:2312.17120 , 2023d.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V
Le, Denny Zhou, et al. Prompt chuỗi-tư-duy gợi ra lý luận trong các mô hình ngôn ngữ lớn
. Advances in Neural Information Processing Systems , 35:24824–24837, 2022.
20

--- TRANG 21 ---
Báo cáo Kỹ thuật
Sean Welleck and Rahul Saha. Llmstep: Gợi ý bước chứng minh llm trong lean. arXiv preprint
arXiv:2310.18457 , 2023.
Kaiyu Yang, Aidan M Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad
Godil, Ryan Prenger, and Anima Anandkumar. Leandojo: Chứng minh định lý với mô hình ngôn ngữ
tăng cường truy xuất. arXiv preprint arXiv:2306.15626 , 2023a.
Zhen Yang, Ming Ding, Qingsong Lv, Zhihuan Jiang, Zehai He, Yuyi Guo, Jinfeng Bai,
and Jie Tang. Gpt có thể giải quyết bài toán toán học mà không cần máy tính. arXiv preprint
arXiv:2309.03241 , 2023b.
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and
Karthik Narasimhan. Tree of Thoughts: Giải quyết vấn đề có chủ ý với mô hình ngôn ngữ lớn
, 2023.
Fei Yu, Anningzhe Gao, and Benyou Wang. Trình xác minh giám sát kết quả cho lập kế hoạch trong
lý luận toán học, 2023a.
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T.
Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. Metamath: Bootstrap câu hỏi toán học
của riêng bạn cho các mô hình ngôn ngữ lớn, 2023b.
Lifan Yuan, Ganqu Cui, Hanbin Wang, Ning Ding, Xingyao Wang, Jia Deng, Boji Shan,
Huimin Chen, Ruobing Xie, Yankai Lin, Zhenghao Liu, Bowen Zhou, Hao Peng, Zhiyuan
Liu, and Maosong Sun. Thúc đẩy những người tổng quát lý luận llm với cây ưu tiên, 2024.
Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Keming Lu, Chuanqi Tan,
Chang Zhou, and Jingren Zhou. Mối quan hệ mở rộng trong việc học lý luận toán học
với các mô hình ngôn ngữ lớn, 2023.
Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu
Chen. MAmmoTH: Xây dựng mô hình tổng quát toán học thông qua tinh chỉnh hướng dẫn hỗn hợp.
arXiv preprint arXiv:2309.05653 , 2023.
Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman. STar: Bootstrap lý luận với
lý luận. Trong Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho
(eds.), Advances in Neural Information Processing Systems , 2022. URL https://openreview.
net/forum?id= 3ELRdg2sgI .
Chuanyang Zheng, Haiming Wang, Enze Xie, Zhengying Liu, Jiankai Sun, Huajian Xin,
Jianhao Shen, Zhenguo Li, and Yu Li. Lyra: Sắp xếp sửa chữa kép trong chứng minh định lý tự động
, 2023.
Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. Minif2f: một điểm chuẩn đa hệ thống
cho toán học cấp olympic hình thức. arXiv preprint arXiv:2109.00110 , 2021.
Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu,
Anya Jia, Linqi Song, Mingjie Zhan, and Hongsheng Li. Giải quyết bài toán từ toán học thách thức
sử dụng thông dịch viên mã gpt-4 với tự xác minh dựa trên mã, 2023.
Xinyu Zhu, Junjie Wang, Lin Zhang, Yuxiang Zhang, Yongfeng Huang, Ruyi Gan, Jiax-
ing Zhang, and Yujiu Yang. Giải quyết bài toán từ toán học thông qua mô hình ngôn ngữ
lý luận hợp tác được cảm hứng. Trong Proceedings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) , pp. 4471–4485, Toronto, Canada, July
2023. Association for Computational Linguistics. URL https://aclanthology.org/2023.
acl-long.245 .
21

--- TRANG 22 ---
Báo cáo Kỹ thuật
A Thành phần Dữ liệu SFT
Chúng tôi liệt kê Thành phần Dữ liệu SFT của chúng tôi trong Bảng 16.
B Cấu hình Thí nghiệm SFT
Mô hình SFT của chúng tôi được khởi tạo từ các mô hình InternLM-Math-Base tiền huấn luyện, tương ứng.
Tỷ lệ học tập đỉnh được đặt thành lrmax=4e−5, và tỷ lệ học tập tối thiểu trong quá trình khởi động
là lrmax=6e−6. Những thiết lập này giống nhau cho cả mô hình 7B và 20B. Dữ liệu huấn luyện SFT
được tokenize thành 622.7 M token. Kích thước batch được đặt thành 1 mỗi GPU với một
tập dữ liệu đóng gói có độ dài chuỗi tối đa là 32768. Chúng tôi huấn luyện mô hình trên những dữ liệu này sử dụng
Bộ tối ưu Adam trong ba epoch với 32 GPU, và quy trình huấn luyện mất khoảng
7 giờ để hoàn thành cho các mô hình 7B. Đối với mô hình 20B, chúng tôi sẽ sử dụng 64 GPU và quy trình huấn luyện
mất khoảng 10 giờ.
C Hiệu suất chi tiết trên điểm chuẩn MATH
Chúng tôi liệt kê hiệu suất chi tiết trên điểm chuẩn MATH trong Bảng 17 và Bảng 18. Chúng tôi liệt kê
hiệu suất sắp xếp lại trên GSM8K và MATH trong Bảng 19.
D Nghiên cứu trường hợp
Chúng tôi liệt kê các trường hợp được tạo ra bởi InternLM-Math-7B.
Dịch Hình thức
Truy vấn: Dịch bất đẳng thức Schur sang LEAN 3: x,y,z≥0,x3+y3+z3+3xyz≥
xy(x+y) +yz(y+z) +xz(x+z)
Phản hồi: (a := α)
theorem schur_inequality {a : Type*} [linear_ordered_field a] {x y z : a}
(hnonneg : 0 ≤x) (hnonneg1 : 0 ≤y) (hnonneg2 : 0 ≤z)
x ˆ 3 + y ˆ 3 + z ˆ 3 + 3 * x * y * z ≥x * y * (x + y) + y * z * (y + z) +
x * z * (x + z)
Kiểm tra số nguyên tố
Truy vấn: Kiểm tra xem 5287 có phải là số nguyên tố hay không.
Phản hồi: [√
5287] =72
Chúng ta cần kiểm tra các số nguyên tố từ 3 đến 72.
Số nguyên tố: 3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71
5287 / 3 = 1762 ... 1
5287 / 7 = 756 ... 5
5287 / 11 = 480 ... 7
5287 / 13 = 407 ... 6
5287 / 17 = 311 ... 0
5287 có thể chia hết cho 17.
5287 là số hợp số.
22

--- TRANG 23 ---
Báo cáo Kỹ thuật
Chứng minh Hình thức được tìm thấy bởi InternLM-Math sử dụng LEAN 4: amc12a 2013 p4
theorem amc12a_2013_p4 : (2 ˆ 2014 + 2 ˆ 2012) / (2 ˆ 2014 - 2 ˆ 2012) = (5 : R
) / 3 := by
--⊢(2 ˆ 2014 + 2 ˆ 2012) / (2 ˆ 2014 - 2 ˆ 2012) = 5 / 3
field_simp
--⊢(2 ˆ 2014 + 2 ˆ 2012) * 3 / (2 ˆ 2014 - 2 ˆ 2012) = 5
simp only [div_eq_inv_mul]
--⊢(2 ˆ 2014 - 2 ˆ 2012)−1* ((2 ˆ 2014 + 2 ˆ 2012) * 3) = 5
norm_cast
--⊢(↑(Int.subNatNat (2 ˆ 2014) (2 ˆ 2012)))−1*↑((2 ˆ 2014 + 2 ˆ 2012) *
3) = 5
norm_num
-- không có mục tiêu
Mô hình Phần thưởng Kết quả
Truy vấn: Cho một câu hỏi và một câu trả lời, kiểm tra xem nó có đúng không?
Câu hỏi: Xác định số cách sắp xếp các chữ cái của từ THAT.
Câu trả lời: Từ THAT có 4 chữ cái. Chúng ta có thể sắp xếp 4 chữ cái này theo
4!=4∗3∗2∗1=24 cách.
Do đó, có 24 cách sắp xếp các chữ cái của từ THAT.
Câu trả lời là: 24.
Phản hồi: Câu trả lời này sai.
Mô hình Phần thưởng Quá trình
Truy vấn: Cho một câu hỏi và một câu trả lời, kiểm tra xem nó có đúng không?
Câu hỏi: Camy tạo ra một danh sách mọi số nguyên dương năm chữ số có thể khác biệt
có thể được tạo thành sử dụng mỗi chữ số 1, 3, 4, 5 và 9 chính xác một lần trong mỗi số nguyên.
Tổng các số nguyên trong danh sách của Camy là bao nhiều?
Câu trả lời: Có 5 !=120 số nguyên dương năm chữ số có thể được tạo thành
sử dụng mỗi chữ số 1, 3, 4, 5, và 9 chính xác một lần.
Tổng của những số nguyên này có thể được tìm thấy bằng cách xem xét tổng của mỗi giá trị vị trí.
Đối với vị trí đơn vị, tổng là 1 ·120=120.
Đối với vị trí chục, tổng là 3 ·120=360.
Đối với vị trí trăm, tổng là 4 ·120=480.
Đối với vị trí nghìn, tổng là 5 ·120=600.
Đối với vị trí chục nghìn, tổng là 9 ·120=1080.
Cộng tất cả những tổng này, chúng ta có 120 +360+480+600+1080 =2880 .
Câu trả lời là: 2880.
Phản hồi: Bước 1: Có 5 !=120 số nguyên dương năm chữ số có thể
được tạo thành sử dụng mỗi chữ số 1, 3, 4, 5, và 9 chính xác một lần. <PRM + >
Bước 2: Tổng của những số nguyên này có thể được tìm thấy bằng cách xem xét tổng của mỗi giá trị vị trí
. <PRM + >
Bước 3: Đối với vị trí đơn vị, tổng là 1 ·120=120.<PRM - >
Bước 4: Đối với vị trí chục, tổng là 3 ·120=360.<PRM - >
Bước 5: Đối với vị trí trăm, tổng là 4 ·120=480.<PRM - >
Bước 6: Đối với vị trí nghìn, tổng là 5 ·120=600.<PRM - >
Bước 7: Đối với vị trí chục nghìn, tổng là 9 ·120=1080.<PRM - >
Bước 8: Cộng tất cả những tổng này, chúng ta có 120 +360+480+600+1080 =2880 .
<PRM - >
Bước 9: Câu trả lời là: 2880. <PRM - >.
23

--- TRANG 24 ---
Báo cáo Kỹ thuật
Mô hình phần thưởng
Truy vấn: Cho một câu hỏi và hai câu trả lời, cái nào tốt hơn?
Câu hỏi: Điểm trung bình của tôi trong 8 bài kiểm tra toán là 90. Nếu điểm trung bình của tôi trong 5
bài kiểm tra đầu tiên là 87, điểm trung bình của tôi trong 3 bài kiểm tra cuối cùng là bao nhiều?
Câu trả lời 1: Tôi đạt tổng cộng 8 ∗90=720 trong tất cả 8 bài kiểm tra. Tổng 5 ∗87=435 trong
5 bài kiểm tra đầu tiên để lại tổng 720 −435=285 cho 3 bài kiểm tra cuối cùng, vậy trung bình là
285÷3=95.
Câu trả lời 2: Tôi đạt tổng cộng 720 trong tất cả 8 bài kiểm tra. Tổng 435 trong 5 bài kiểm tra đầu tiên
để lại tổng 285 cho 3 bài kiểm tra cuối cùng, vậy trung bình là 285 ÷3=95
Phản hồi: Câu trả lời 2 tốt hơn.
Thay đổi câu hỏi và câu trả lời thành tuyên bố chứng minh
Truy vấn: Chuyển đổi câu hỏi và câu trả lời này thành định dạng chứng minh.
Câu hỏi: Grant đạt điểm cao hơn John 10 điểm trong bài kiểm tra toán. John nhận được
gấp đôi số điểm so với Hunter người đạt x điểm trong bài kiểm tra toán. Điểm kiểm tra của Grant
là bao nhiều? Nếu chúng ta biết câu trả lời cho câu hỏi trên là 100, giá trị của
biến số chưa biết x là bao nhiều?
Câu trả lời: Chúng ta biết rằng John nhận được gấp đôi số điểm so với Hunter, người đạt
x điểm trong bài kiểm tra toán. Vậy, John đạt 2x điểm. Grant đạt cao hơn
John 10 điểm, vậy Grant đạt 2x + 10 điểm. Chúng ta được cho rằng điểm kiểm tra của Grant
là 100, vậy chúng ta có thể viết: 2x + 10 = 100. Giải x, chúng ta có: x = 45. Giá trị của x là 45.
Phản hồi: Chứng minh rằng nếu Grant đạt điểm cao hơn John 10 điểm trong bài kiểm tra toán,
và John nhận được gấp đôi số điểm so với Hunter người đạt x điểm trong bài
kiểm tra toán, thì điểm kiểm tra của Grant là 100 khi và chỉ khi x = 45.
Tăng cường bài toán khó hơn
Truy vấn: Vui lòng tăng cường một bài toán mới khó hơn dựa trên:
Câu hỏi: Tìm số dư của x2+10x+4 chia cho x−2
Phản hồi: Tìm số dư của (x2+10x+4)2chia cho (x−2)2.
E Kết quả trên InternLM-Math-Plus
Chúng tôi cải thiện InternLM-Math thành InternLM-Math-Plus với kho dữ liệu tiền huấn luyện mới và
tập dữ liệu tinh chỉnh. Chúng tôi có bốn kích thước của InternLM-Math-Plus bao gồm 1.8B, 7B, 20B,
và 8x22B. Chúng tôi khởi tạo các mô hình của chúng tôi (1.8B, 7B, và 20B) từ InternLM-2, và 8x22B từ
Mixtral-8x22B (Jiang et al., 2024). Chúng tôi đánh giá hiệu suất của InternLM2-Math-Plus trên
điểm chuẩn lý luận toán học hình thức MiniF2F-test thông qua LEAN 4 (trong Bảng 20) và các điểm chuẩn lý luận toán học không chính thức
MATH, GSM8K, và MathBench-A (Liu et al., 2024) (trong Bảng 22).
Chúng tôi kiểm tra thêm MATH sử dụng Python (trong Bảng 21).
24

--- TRANG 25 ---
Báo cáo Kỹ thuật
Tập dữ liệu Loại Ngôn ngữ Mô tả Kích thước
MetaMath (Yu et al., 2023b) COT, GPT EN Bootstrap câu hỏi trên GSM8K & MATH. 395K
Goat (Liu & Low, 2023) COT, Quy tắc EN Dữ liệu tổng hợp cho các nhiệm vụ số học. 100K
Arithmetic (gốc) COT, Quy tắc EN 40k tính toán nhiều dấu ngoặc, 40k tính toán thập phân
, 35k tính toán phân số, 5k rút gọn phân số, 15k bài toán số dư
, và 4k tính toán lũy thừa.140K
Prime (gốc) COT, Quy tắc EN & ZH Đánh giá một số có phải số nguyên tố từng bước. 15K
Game-of-24 (gốc) COT, Quy tắc ZH Giải trò chơi k(không giới hạn ở 24) từng bước
bằng cách tìm kiếm.10K
Factoring (gốc) COT, Quy tắc EN & ZH Phân tích thừa số một số từng bước. 11K
Triangle (gốc) COT, Quy tắc EN & ZH Tính diện tích tam giác từng bước. 1K
Commonsense (gốc) COT, Quy tắc EN & ZH Tập dữ liệu thường thức toán học. 14K
Mammoth (Yue et al., 2023) COT, CI EN Hỗn hợp nhiều tập dữ liệu COT và POT. 216K
PRM800K (Lightman et al.,
2023)COT, GPT EN Đường lý luận đúng được chọn. 7K
Khan (Khan, 2021) COT, Hỗn hợp EN Kho dữ liệu liên quan đến toán học. 83K
TAL-SCQ5K-ZH (Math-
eval, 2023)COT, Con người ZH Tập huấn luyện của tập dữ liệu trắc nghiệm tiếng Trung
.3K
TAL-SCQ5K-EN (Math-
eval, 2023)COT, Con người EN Tập huấn luyện của tập dữ liệu trắc nghiệm tiếng Anh
.3K
Inhouse-ZH (gốc) COT, Con người ZH Tập dữ liệu toán tiếng Trung nội bộ. 293K
MathOctopus (Chen et al.,
2023a)COT, GPT ZH Chỉ chọn bài toán tiếng Trung từ đó. 7K
Math23K-AUG (Wang et al.,
2017)COT, OSLLM ZH Tăng cường Math23K được lọc với câu trả lời cuối cùng
.195K
MATH-AUG (Hendrycks
et al., 2021b)COT, OSLLM EN Tăng cường MATH được lọc với PRM của chúng tôi. 28K
COT-few-shot (gốc) COT, Hỗn hợp EN & ZH Thêm 1% dữ liệu định dạng few-shot cho hầu hết
tập dữ liệu.15K
Code-Interpreter (gốc) CI, GPT,
OSLLMEN & ZH Tập dữ liệu được hợp nhất của tập huấn luyện MATH & GSM8K
, và bài toán cấp K12 tiếng Trung. Lời giải
được tạo ra bởi GPT4 hoặc InternLM-70B.
Mỗi cái xen kẽ ngôn ngữ tự nhiên, mã,
và kết quả thực thi.76K
Math-Shepherd (Wang
et al., 2023b)RM, OSLLM EN Hợp nhất Math Shepherd và dữ liệu giống Math Shepherd
tự lấy mẫu. Chuyển đổi chúng
thành định dạng ORM và PRM.445K
ORM-ZH (gốc) RM, OSLLM ZH Dữ liệu ORM tự lấy mẫu trên bài toán tiếng Trung
.104K
GSM8K-LEAN (gốc) Hình thức, GPT EN Mã LEAN 3 trên tập huấn luyện GSM8K. 4K
COT-LEAN (gốc) Hình thức, GPT EN Dịch giữa COT và mã LEAN. 3K
NL-LEAN (Han et al., 2021) Hình thức, Con người
EN Dịch giữa ngôn ngữ tự nhiên và
tuyên bố LEAN.91K
MathLib-Train (Han et al.,
2021)Hình thức, Con người
EN Trạng thái và chiến thuật LEAN được trích xuất dựa trên
MathLib.169K
QA-theorem (gốc) Tăng cường,
GPTEN Diễn đạt lại câu hỏi và câu trả lời thành
tuyên bố chứng minh ngôn ngữ tự nhiên.1K
Augment-helper (gốc) Tăng cường,
GPTEN Tăng cường câu hỏi được tạo ra bởi ChatGPT
(Luo et al., 2023; Li et al., 2023).7K
GSM8K-rephrased (gốc
)Tăng cường,
GPTEN Định dạng lại câu hỏi được diễn đạt lại từ Meta-
Math (Yu et al., 2023b) cho việc diễn đạt lại.2K
Tất cả - EN & ZH Kết hợp chúng với việc loại bỏ trùng lặp thêm
và khử nhiễm tập kiểm tra.2.26M
Bảng 16: Thông tin thành phần dữ liệu SFT chi tiết. Chúng tôi liệt kê các loại dữ liệu và loại nguồn
ở đây. OSLLM ký hiệu các LLM mã nguồn mở.
25

--- TRANG 26 ---
Báo cáo Kỹ thuật
Bảng 17: Hiệu suất của MATH được nhóm theo danh mục. * Những kết quả này đến từ
việc tái tạo của chúng tôi.
Mô hình Prob. Precal. Inter. Pre-Alg. Alg. Geo. Num. Tổng thể
MetaMath
Llemma-7B * 24.5 14.7 13.7 45.6 43.0 22.8 18.3 28.7
InternLM-Math-Base-7B 28.5 16.9 14.5 53.5 50.0 25.5 24.1 33.4
InternLM-Math-Base-20B 32.3 19.0 15.7 56.3 54.5 27.6 25.4 36.1
Dữ liệu SFT của chúng tôi
InternLM-Math-7B 28.9 17.0 17.2 53.5 51.4 27.3 25.6 34.6
InternLM-Math-20B 29.1 21.8 19.2 59.1 55.9 30.0 30.2 37.7
Bảng 18: Hiệu suất của MATH được nhóm theo độ khó. * Những kết quả này đến từ
việc tái tạo của chúng tôi.
Mô hình Cấp 1 Cấp 2 Cấp 3 Cấp 4 Cấp 5 Tổng thể
MetaMath
Llemma-7B * 66.1 44.5 34.5 20.5 8.2 28.7
InternLM-Math-Base-7B 74.1 50.4 37.9 25.9 11.3 33.4
InternLM-Math-Base-20B 75.6 55.3 41.8 28.3 12.2 36.1
Dữ liệu SFT của chúng tôi
InternLM-Math-7B 75.1 53.0 39.3 26.1 12.5 34.6
InternLM-Math-20B 75.5 55.6 45.4 31.7 13.7 37.7
Bảng 19: Sử dụng sắp xếp lại mô hình phần thưởng trên nhiều điểm chuẩn toán học. Vì chúng tôi sử dụng
nhiệt độ=0.7 khi lấy mẫu, việc lấy mẫu 1 lần hoạt động kém hơn giải mã tham lam
là tự nhiên.
Mô hình Thước đo 1 2 4 8 16 32 64 100
7B/GSM8KMAJ 79.0 79.0 81.8 82.9 83.3 83.2 83 83.5
ORM 79.0 80.0 82.3 83.5 83.6 83.8 83.9 84.2
PRM 79.0 79.8 82.5 83.3 83.9 83.6 83.7 84.0
LRM 79.0 80.4 82.1 83.6 85.2 85.3 85.5 85.8
Oracle 79.0 84.4 88.6 91.3 93.7 95.7 96.7 97.0
20B/GSM8KMAJ 82.1 82.1 85.5 86.4 87.6 88.0 88.5 88.2
ORM 82.1 84.3 86.7 87.4 88.6 88.7 89.2 89.0
PRM 82.1 85.0 87.0 87.5 88.9 88.9 89.5 89.3
LRM 82.1 84.7 87.5 88.3 88.9 89.1 89.4 89.0
Oracle 82.1 88.1 91.3 94.4 96.0 97.1 98.0 98.3
7B/MATHMAJ 34.2 34.8 36.8 40.6 43.6 45.4 44.4 44.8
ORM 34.2 35.8 37.6 40.6 43.6 45.8 45.2 46.0
PRM 34.2 37.0 39.4 42.0 44.0 46.2 46.0 47.0
Oracle 34.2 42.2 49.2 57.6 65.6 71.4 77.6 80.8
20B/MATHMAJ 32.6 34.2 40.6 46.0 47.2 48.4 47.4 47.4
ORM 32.6 37.8 43.6 46.8 48.6 49.6 49.4 48.8
PRM 32.6 37.0 41.8 45.8 48.2 49.2 49.6 50.0
Oracle 32.6 44.8 54.0 61.2 66.8 73.0 79.6 81.8
26

--- TRANG 27 ---
Báo cáo Kỹ thuật
Bảng 20: Hiệu suất của các mô hình khác nhau trên MiniF2F-test.
Mô hình MiniF2F-test
ReProver (Yang et al., 2023a) 26.5
LLMStep (Welleck & Saha, 2023) 27.9
GPT-F Expert Iteration (Polu et al., 2022) 36.6
HTPS (Lample et al., 2022) 41.0
Llemma-7B 26.2
Llemma-34B 25.8
InternLM2-Math-7B-Base 30.3
InternLM2-Math-20B-Base 29.5
InternLM2-Math-Plus-1.8B 38.9
InternLM2-Math-Plus-7B 43.4
InternLM2-Math-Plus-20B 42.6
InternLM2-Math-Plus-Mixtral8x22B 37.3
Bảng 21: Hiệu suất của các mô hình khác nhau trên MATH và GSM8K.
Mô hình MATH MATH-Python GSM8K
MiniCPM-2B (Hu et al., 2024) 10.2 - 53.8
InternLM2-Math-Plus-1.8B 37.0 41.5 58.8
InternLM2-Math-7B 34.6 50.9 78.1
Deepseek-Math-7B-RL (Shao et al., 2024) 51.7 58.8 88.2
InternLM2-Math-Plus-7B 53.0 59.7 85.8
InternLM2-Math-20B 37.7 54.3 82.6
InternLM2-Math-Plus-20B 53.8 61.8 87.7
Mixtral8x22B-Instruct-v0.1 (Jiang et al., 2024) 41.8 - 78.6
Eurux-8x22B-NCA (Yuan et al., 2024) 49.0 - -
InternLM2-Math-Plus-Mixtral8x22B 58.1 68.5 91.8
Bảng 22: Hiệu suất của các mô hình khác nhau trên MathBench-A.
InternLM2-Math-Plus Số học Tiểu học Trung học Trung phổ thông Đại học Trung bình
-1.8B 43.0 43.3 25.4 18.9 4.7 27.1
-7B 61.4 78.3 52.5 40.5 21.7 50.9
-20B 65.8 79.7 59.5 47.6 24.8 55.5
-Mixtral8x22B 77.5 82.0 63.6 50.3 36.8 62.0
27

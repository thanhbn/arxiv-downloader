# SKYMATH: BÁO CÁO CHUYÊN MÔN

Liu Yang, Haihua Yang, Wenjun Cheng, Lei Lin, Chenxia Li, Yifu Chen, Lunan Liu,
Jianfei Pan, Tianwen Wei, Biye Li, Liang Zhao, Lijie Wang, Bo Zhu, Guoliang Li,
Xuejie Wu, Xilin Luo, Rui Hu†
Kunlun Inc.
rui.hu@kunlun-inc.com

TÓM TẮT
Các mô hình ngôn ngữ lớn (LLM) đã cho thấy tiềm năng tuyệt vời để giải quyết nhiều loại nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP), bao gồm cả lý luận toán học. Trong công trình này, chúng tôi giới thiệu SkyMath, một mô hình ngôn ngữ lớn cho toán học với 13 tỷ tham số. Bằng cách áp dụng tinh chỉnh tự so sánh, chúng tôi đã nâng cao khả năng lý luận toán học của Skywork-13B-Base một cách đáng kể. Trên GSM8K, SkyMath vượt trội so với tất cả các mô hình mã nguồn mở đã biết có kích thước tương tự và đã thiết lập hiệu suất SOTA mới. Trên tập dữ liệu MATH và tập dữ liệu ngoài miền CMath, SkyMath cũng đạt được tỷ lệ chính xác cao, thể hiện khả năng tổng quát hóa đáng kể đối với nhiều loại bài toán.

1 GIỚI THIỆU

Ngày nay, các mô hình ngôn ngữ lớn (LLM) đang được áp dụng ngày càng nhiều cho tất cả các loại nhiệm vụ phức tạp, bao gồm tạo nội dung (Gardner et al., 2023; Zhang et al., 2023a; Zhu et al., 2023; Dai et al., 2023; Liu et al., 2023a), tạo mã (Nijkamp et al., 2023; Wang et al., 2023d; Fried et al., 2023; Chen et al., 2021; Li et al., 2023; Zheng et al., 2023b), trò chuyện nhiều lượt (Thoppilan et al., 2022; Touvron et al., 2023b; Bai et al., 2023; Yang et al., 2023a; Zeng et al., 2023; Shu et al., 2023), lý luận toán học (Azerbayev et al., 2023; Yue et al., 2023; Yu et al., 2023; Luo et al., 2023a; Qiao et al., 2023; Chern et al., 2023; Fu et al., 2023a), và trả lời câu hỏi dựa trên kiến thức (Cui et al., 2023; Wu et al., 2023; Yang et al., 2023b; Wang et al., 2023a; Zhu & Wang, 2023), và chúng có tiềm năng cách mạng hóa các lĩnh vực xử lý ngôn ngữ tự nhiên và hiểu ngôn ngữ tự nhiên (OpenAI, 2022, 2023). Hơn nữa, so với các phương pháp AI truyền thống, LLM có được lợi thế vô song trong những lĩnh vực này. Trí tuệ nhân tạo tạo sinh (GenAI) được thúc đẩy bởi LLM đang sắp xuất hiện.

Mặc dù có những khả năng ấn tượng, LLM đi kèm với một loạt thách thức và vấn đề. Lý luận toán học là một trong những lĩnh vực phụ đáng khám phá. Trong bối cảnh đánh giá khả năng lý luận của LLM, lý luận toán học phức tạp đóng vai trò như một tiêu chuẩn quan trọng. Hơn nữa, các nhiệm vụ lý luận toán học được coi là một trong những khoảng cách lớn giữa các mô hình nguồn đóng như ChatGPT (OpenAI, 2022) hoặc GPT4 (OpenAI, 2023) và các mô hình mã nguồn mở như LLaMA (Touvron et al., 2023a,b). Để đạt được khả năng lý luận toán học tiên tiến, nhiều mô hình mã nguồn mở đã thực hiện các nỗ lực: Kuaishou giới thiệu KwaiYiiMath bằng cách áp dụng Tinh chỉnh có giám sát (SFT) và Học tăng cường từ Phản hồi con người (RLHF) và xây dựng một bộ kiểm tra toán học tiểu học Trung Quốc quy mô nhỏ (có tên KMath) (Fu et al., 2023a); Microsoft trình bày wizardMath bằng cách áp dụng phương pháp Học tăng cường từ Phản hồi Evol-Instruct (RLEIF) được đề xuất của họ vào lĩnh vực toán học (Luo et al., 2023a); Xiang et al. giới thiệu MAmmoTH bằng cách đào tạo mô hình trên tập dữ liệu MathInstruct do họ tự phát triển (Yue et al., 2023); Zhangir et al. trình bày LLEMMA bằng cách tiếp tục tiền đào tạo Code Llama trên Proof-Pile-2, một hỗn hợp các bài báo khoa học, dữ liệu web chứa toán học, và mã toán học (Azerbayev et al., 2023); Yu et al. (Yu et al., 2023) đề xuất MetaMath được đào tạo trên một tập dữ liệu mới gọi là MetaMathQA được xây dựng bằng cách bootstrap các câu hỏi toán học bằng cách viết lại câu hỏi từ nhiều góc độ. Mặc dù có thành công tuyệt vời, hầu hết các LLM mã nguồn mở hiện có vẫn còn xa mới đạt được sự hài lòng trong việc giải quyết các bài toán do các quy trình lý luận phức tạp, và hoạt động kém trên GSM8K và MATH khi so sánh với các mô hình mã nguồn mở.

Để thu hẹp khoảng cách này, chúng tôi đề xuất SkyMath, một mô hình ngôn ngữ được tinh chỉnh chuyên về lý luận toán học, bằng cách áp dụng các kỹ thuật tăng cường dữ liệu cải tiến và quy trình SFT của chúng tôi vào việc tinh chỉnh Skywork-13B-Base. Quy trình chính bao gồm ba phần, như sau: 1. Tinh chỉnh mô hình Skywork-13B-Base trên các tập dữ liệu mã nguồn mở; 2. Xây dựng một tập dữ liệu mới cho toán học bằng các kỹ thuật tăng cường dữ liệu cải tiến; 3. Tái xây dựng tập dữ liệu toán học bằng cách áp dụng các kỹ thuật tự kiểm tra được đề xuất của chúng tôi. Kết quả thực nghiệm cho thấy SkyMath vượt trội so với nhiều mô hình mã nguồn mở có kích thước tương tự trên hai tiêu chuẩn toán học, cụ thể là GSM8k (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021).

Bài báo được cấu trúc như sau. Phần 2 cung cấp tổng quan về các công trình liên quan bao gồm LLM và LLM cho toán học. Phần 3 giới thiệu phương pháp luận của Skywork-13B-Math bao gồm các phương pháp xây dựng mẫu và quy trình tinh chỉnh có giám sát. Sau đó, các xác thực và so sánh thực nghiệm được thực hiện trong Phần 4 và Phần 5. Kết luận được đưa ra trong Phần 6.

2 CÔNG TRÌNH LIÊN QUAN

Các mô hình ngôn ngữ lớn Gần đây, LLM đã đạt được tiến bộ đáng kể trong các nhiệm vụ xử lý ngôn ngữ tự nhiên, được hưởng lợi từ dữ liệu văn bản chất lượng cao, đa dạng, và số lượng tham số mô hình khổng lồ. Các nhà nghiên cứu đã phát hiện ra rằng LLM hoạt động tốt hơn trên các nhiệm vụ downstream (Kaplan et al., 2020). LLM, được tiền đào tạo trên dữ liệu văn bản rộng lớn và được tinh chỉnh cho các nhiệm vụ cụ thể, thể hiện khả năng đáng kể trong nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên so với các mô hình nhỏ hơn (Devlin et al., 2019; Wei et al., 2022b). Các khả năng quan trọng của các mô hình lớn chủ yếu nằm ở ba khía cạnh: 1. Học trong bối cảnh. 2. Tuân theo chỉ dẫn. 3. Lý luận từng bước (Zhao et al., 2023). GPT-3 (Brown et al., 2020), một mô hình ngôn ngữ có hàng chục tỷ tham số, thể hiện cải thiện hiệu suất đáng kể trong các nhiệm vụ học few-shot, one-shot, và zero-shot thông qua học trong bối cảnh. Tuy nhiên, hiệu quả của khả năng học trong bối cảnh phụ thuộc vào các nhiệm vụ downstream khác nhau. Mô hình mã nguồn mở Llama2 (Touvron et al., 2023b), với độ dài bối cảnh được tiền đào tạo lên đến 4k, thể hiện khả năng hiểu bối cảnh mạnh mẽ trong các nhiệm vụ như tóm tắt, đối thoại nhiều lượt, và đọc hiểu. LLM xử lý các nhiệm vụ downstream khác nhau một cách hiệu quả, nhưng đôi khi các mô hình được tiền đào tạo này vẫn gặp khó khăn trong việc hiểu chỉ dẫn của con người (Ouyang et al., 2022). Việc hiểu và tuân theo các chỉ dẫn cụ thể trong các nhiệm vụ ngôn ngữ tự nhiên phức tạp là một thách thức rất lớn đối với LLM. Để vượt qua thách thức này, Tinh chỉnh chỉ dẫn (IT) (Zhang et al., 2023b) và Chuỗi suy nghĩ (CoT) (Wei et al., 2022c) đã được đề xuất. Cụ thể, IT nhằm mục đích sử dụng các cặp được xây dựng có định dạng [chỉ dẫn, đầu ra] để tinh chỉnh mô hình ngôn ngữ được tiền đào tạo. Hơn nữa, việc áp dụng kết hợp chỉ dẫn đa nhiệm vụ trong tinh chỉnh đã chứng minh hiệu quả của các kỹ thuật IT trong các nhiệm vụ chưa thấy (Sanh et al., 2022; Ouyang et al., 2022; Wei et al., 2022a). Nhiều nghiên cứu cho thấy các chỉ dẫn chất lượng cao, đa dạng có thể cải thiện hiệu suất của LLM trong các nhiệm vụ ngôn ngữ tự nhiên một cách hiệu quả (Wang et al., 2023c; Zhou et al., 2023; Wei et al., 2022a; Cao et al., 2023). CoT là một phương pháp nhằm mục đích cải thiện hiệu suất của LLM bằng cách cung cấp các quy trình lý luận chi tiết như đầu vào đào tạo. Bằng cách cho phép mô hình tuân theo một quy trình từng bước, CoT giúp LLM chia nhỏ các vấn đề phức tạp thành các vấn đề nhỏ hơn và tích lũy những chiến thắng nhỏ để đạt được thành công lớn hơn (Wei et al., 2022c). Cách tiếp cận này đã dẫn đến những cải thiện đáng kể trong khả năng lý luận của LLM, đặc biệt là trong lý luận toán học và các nhiệm vụ ra quyết định. Sự thành công của các công nghệ CoT và IT trong Tinh chỉnh tự giám sát (SFT) đã mở ra những khả năng mới để nâng cao hiệu suất của LLM. Nhiều mô hình, bao gồm InstructionGPT (Ouyang et al., 2022), BLOOMZ (Muennighoff et al., 2023), WizardLM (Xu et al., 2023), ChatGLM2 (Du et al., 2022), và Vicuna (Chiang et al., 2023), đã có được khả năng lý luận mạnh mẽ, cho phép chúng thực hiện các nhiệm vụ phức tạp với độ chính xác đáng kể. Ngoài ra, bằng cách đào tạo LLM trên dữ liệu cụ thể cho một lĩnh vực cụ thể, như y tế hoặc pháp lý, có thể thu được các mô hình xuất sắc trong lĩnh vực đó. Các mô hình thu được theo cách này bao gồm InstructDial (Gupta et al., 2022), Radiology-GPT (Liu et al., 2023b), Goat (Liu & Low, 2023), WizardCoder (Luo et al., 2023b).

Các mô hình ngôn ngữ lớn cho lý luận toán học Lý luận toán học là một trong những khả năng thiết yếu cần thiết cho LLM. Để tăng cường khả năng lý luận toán học của các LLM cơ bản, một nhóm các nhà nghiên cứu đã tiến hành một nghiên cứu toàn diện. Dựa trên CoT, một loạt các công trình được thực hiện để tối ưu hóa các đường dẫn lý luận (Wang et al., 2023b; Fu et al., 2023b; Huang et al., 2022). Wang et al. giới thiệu Tự nhất quán, sử dụng kết quả của nhiều đường dẫn lý luận để nâng cao độ chính xác của suy luận thông qua các câu trả lời nhất quán (Wang et al., 2023b). Fu et al. đề xuất CoT dựa trên độ phức tạp, đạt được hiệu suất cải thiện trong các nhiệm vụ lý luận toán học thông qua một CoT liên quan đến nhiều bước lý luận phức tạp (Fu et al., 2023b). Về mặt kỹ thuật tạo lời nhắc, Zheng et al. kết hợp CoT để tạo ra câu trả lời, sử dụng câu trả lời từ bước trước đó làm lời nhắc cho bước tiếp theo, dần dần hướng dẫn LLM tạo ra câu trả lời đúng (Zheng et al., 2023a). Luo et al. đề xuất evol-instruct được tăng cường, một phương pháp kết hợp evol-instruct với học tăng cường để nâng cao hiệu suất lý luận của LLM (Luo et al., 2023a). Madaan et al. giới thiệu Self-Refine, trong đó một LLM đơn lẻ đồng thời đóng vai trò là người tạo ra, người tinh chỉnh, và người cung cấp phản hồi, tự tinh chỉnh một cách lặp đi lặp lại để nâng cao khả năng lý luận toán học của nó (Madaan et al., 2023). Yu et al. xây dựng một tập dữ liệu mới, MetaMathQA, thông qua tăng cường dữ liệu bằng cách viết lại các bài toán từ nhiều góc độ (Yu et al., 2023). Fu et al. nâng cao khả năng lý luận toán học của LLM thông qua kết hợp tinh chỉnh có giám sát và học tăng cường với phản hồi con người (RLHF) (Fu et al., 2023a). Dựa trên Cot và Chương trình suy nghĩ (PoT) (Chen et al., 2022), Yue et al. xây dựng một tập dữ liệu mới gọi là MathInstruct và sử dụng nó trong SFT. PoT sử dụng một thông dịch viên bên ngoài (ví dụ, thông dịch viên Python) để tính toán câu trả lời cho các bài toán phức tạp (Yue et al., 2023). Azerbayev et al. tiếp tục tiền đào tạo trên Proof-Pile-2, một tập dữ liệu chứa dữ liệu web toán học và mã toán học, và sử dụng PoT để thu được câu trả lời chính xác (Azerbayev et al., 2023).

3 PHƯƠNG PHÁP

Trong phần này, chúng tôi giới thiệu SkyMath một cách chi tiết. Như được thể hiện trong Hình 1, phương pháp của chúng tôi chủ yếu bao gồm hai bước:

1. Tăng cường chỉ dẫn.
2. Tinh chỉnh tự so sánh.

Hình 1: Kiến trúc tổng quan của SkyMath

3.1 TĂNG CƯỜNG CHỈ DẪN

Công trình trước đây đã chỉ ra rằng các chỉ dẫn toán học với độ phức tạp khác nhau có thể tạo ra hiệu ứng đáng kể đối với việc đào tạo LLM toán học (Luo et al., 2023a). Do đó, bước đầu tiên chúng tôi thực hiện là xây dựng một tập dữ liệu có cả chất lượng cao và đa dạng.

1. Trước tiên, chúng tôi thu thập một tập dữ liệu toán học từ các nguồn khác nhau, bao gồm các cấp độ khác nhau, bằng cả tiếng Trung và tiếng Anh.

2. Sau đó, được truyền cảm hứng bởi WizardLM (Xu et al., 2023) và MetaMath (Yu et al., 2023), chúng tôi áp dụng tăng cường chỉ dẫn, cụ thể là 1) cụ thể hóa, 2) thêm ràng buộc, 3) làm sâu sắc và 4) diễn đạt lại, vào quy trình tăng cường câu hỏi.

3. Chúng tôi sử dụng LLM để tạo ra các phản hồi cho các câu hỏi được tăng cường.

4. Kiểm tra tính đúng đắn.

Đến giờ, chúng tôi đã có một tập dữ liệu có độ phức tạp cao.

3.2 TINH CHỈNH TỰ SO SÁNH

Nhắc nhở gợi ý tiến bộ (PHP) (Zheng et al., 2023a) cho phép nhiều tương tác giữa người dùng và LLM bằng cách sử dụng các câu trả lời được tạo ra trước đó làm gợi ý để dần dần hướng dẫn LLM hướng tới các câu trả lời đúng. Được truyền cảm hứng bởi điều này, chúng tôi tin rằng việc giới thiệu các câu trả lời trước đó vào quy trình đào tạo cũng có hiệu quả. Chúng tôi hy vọng mô hình có thể so sánh các câu trả lời trước đó của nó với sự thật cơ bản và sửa chữa các lỗi cụ thể thông qua đào tạo.

Hình 2: Tinh chỉnh tự so sánh

Như được thể hiện trong Hình 2, tinh chỉnh tự so sánh bao gồm bốn bước:

1. Đối với mỗi câu hỏi, yêu cầu LLM đưa ra một câu trả lời.
2. Xây dựng các lời nhắc tự so sánh, như được thể hiện trong Hình 3.
3. Kết hợp dữ liệu với tập dữ liệu gốc.
4. Tinh chỉnh.

Giống như con người, chúng tôi tin rằng LLM có xu hướng mắc các lỗi khác nhau khi khả năng của chúng được cải thiện. Do đó, trong thực tế, chúng tôi chia tập dữ liệu gốc thành một số tập dữ liệu con để chúng tôi có thể lặp lại tinh chỉnh tự so sánh nhiều lần.

4 THỰC NGHIỆM

4.1 CÁC TIÊU CHUẨN ĐÁNH GIÁ

Chúng tôi chủ yếu đánh giá SkyMath trên hai tiêu chuẩn lý luận toán học phổ biến: GSM8k (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021). Để xem hiệu suất của SkyMath trên tập dữ liệu ngoài miền và bằng tiếng Trung, chúng tôi cũng đánh giá mô hình của chúng tôi trên CMath (Wei et al., 2023), để hoàn thiện.

Hình 3: Lời nhắc tự so sánh

GSM8k chứa 7,473 dữ liệu đào tạo và 1,319 dữ liệu kiểm tra, chủ yếu về các bài toán tiếng Anh cấp tiểu học. Mỗi bài toán cần từ 2 đến 8 bước để giải quyết, và các giải pháp chủ yếu liên quan đến việc thực hiện một chuỗi các phép tính cơ bản sử dụng các phép toán số học cơ bản.

MATH thách thức hơn nhiều. Nó chứa 7,500 dữ liệu đào tạo và 5,000 dữ liệu kiểm tra, bao gồm bảy môn học bao gồm Đại số cơ bản, Đại số, Lý thuyết số, Đếm và Xác suất, Hình học, Đại số trung cấp, và Giải tích sơ cấp.

CMath là một tập dữ liệu Bài toán từ Toán học tiểu học Trung Quốc (CMATH), chứa 1.7k bài toán từ cấp tiểu học với chú thích chi tiết, được lấy từ sách bài tập và kỳ thi thực tế của Trung Quốc. Chúng tôi sử dụng nó như một tập dữ liệu ngoài miền.

4.2 MÔ HÌNH VÀ BASELINE

Chúng tôi sử dụng SkyWork-13B làm mô hình cơ sở và tương ứng chọn các mô hình có cùng kích thước và đã được mã nguồn mở để so sánh. Do đó, chúng tôi chọn LLaMA1 (Touvron et al., 2023a), LLaMA2 (Touvron et al., 2023a), BaiChuan1 (Yang et al., 2023a), BaiChuan2 (Yang et al., 2023a), WizardMath (Luo et al., 2023a), GAIRMath-Abel (Chern et al., 2023), và MetaMath (Yu et al., 2023) làm baseline.

5 KẾT QUẢ CHÍNH

Bảng 1: Kết quả của pass@1 (%) trên GSM8k, MATH và CMath

Mô hình #Tham số GSM8K Math CMath
LLaMA1 (Touvron et al., 2023a) 13B 17.8 3.9 -
LLaMA2 (Touvron et al., 2023a) 13B 28.7 3.9 -
BaiChuan1 (Yang et al., 2023a) 13B 26.76 4.84 51.33
BaiChuan2 (Yang et al., 2023a) 13B 52.77 10.08 -
WizardMath (Luo et al., 2023a) 13B 63.9 14.0 50.83
GAIRMath-Abel (Chern et al., 2023) 13B 66.41 17.34 -
MetaMath (Yu et al., 2023) 13B 72.3 22.4 -
SkyMath 13B 72.33 16.98 77.27

Kết quả đánh giá được thể hiện trong Bảng 1. SkyMath vượt trội so với tất cả các baseline trên GSM8K, do đó chúng tôi đã thiết lập hiệu suất SOTA mới trên các LLM mã nguồn mở có kích thước tương tự. Trên tập dữ liệu MATH, vốn rất thách thức, SkyMath cũng đạt được tỷ lệ chính xác cao. Trong khi đó, trên tập dữ liệu ngoài miền CMath, hiệu suất của SkyMath cho thấy khả năng tổng quát hóa đáng kể đối với cả bài toán chưa thấy và bài toán tiếng Trung.

6 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Bài báo này giới thiệu SkyMath, một mô hình toán học được tinh chỉnh với tự so sánh. Kết quả đánh giá cho thấy SkyMath đạt được hiệu suất SOTA trên tất cả các LLM mã nguồn mở hiện có có kích thước tương tự trên GSM8K và cho thấy khả năng tổng quát hóa đáng kể đối với các bài toán ngoài miền. Xét rằng chúng tôi không sử dụng công cụ hoặc mô hình phần thưởng, kết quả càng khó khăn hơn.

Công việc tương lai. Mặc dù mô hình của chúng tôi đạt được hiệu suất ấn tượng trên GSM8K, chúng tôi vẫn thua xa các mô hình như GPT-4. Trong tương lai, chúng tôi sẽ khám phá nhiều phương pháp hơn để cải thiện khả năng của mô hình.

TÀI LIỆU THAM KHẢO

Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, Albert Q. Jiang, Jia Deng, Stella Biderman, và Sean Welleck. Llemma: An open language model for mathematics. arXiv preprint arXiv:2310.06786, 2023.

Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, và Tianhang Zhu. Qwen technical report, 2023.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, và Hsuan-Tien Lin (eds.), Proceedings of the 33th Annual Conference on Neural Information Processing Systems 2020, 2020.

Yihan Cao, Yanbin Kang, và Lichao Sun. Instruction mining: High-quality instruction data selection for large language models. arXiv preprint arXiv:2307.06290, 2023.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.

Wenhu Chen, Xueguang Ma, Xinyi Wang, và William W. Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588, 2022.

Ethan Chern, Haoyang Zou, Xuefeng Li, Jiewen Hu, Kehua Feng, Junlong Li, và Pengfei Liu. Generative ai for math: Abel. https://github.com/GAIR-NLP/abel, 2023.

Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, và Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, và John Schulman. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.

Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, và Li Yuan. Chatlaw: Open-source legal large language model with integrated external knowledge bases. arXiv preprint arXiv:2306.16092, 2023.

Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, và Steven C. H. Hoi. Instructblip: Towards general-purpose vision-language models with instruction tuning. arXiv preprint arXiv:2305.06500, 2023.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171–4186, 2019.

Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, và Jie Tang. GLM: general language model pretraining with autoregressive blank infilling. In Smaranda Muresan, Preslav Nakov, và Aline Villavicencio (eds.), Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, pp. 320–335. Association for Computational Linguistics, 2022.

Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Scott Yih, Luke Zettlemoyer, và Mike Lewis. Incoder: A generative model for code infilling and synthesis. In Proceedings of the 11th International Conference on Learning Representations. OpenReview.net, 2023.

Jiayi Fu, Lei Lin, Xiaoyang Gao, Pengli Liu, Zhengzong Chen, Zhirui Yang, Shengnan Zhang, Xue Zheng, Yan Li, Yuliang Liu, Xucheng Ye, Yiqiao Liao, Chao Liao, Bin Chen, Chengru Song, Junchen Wan, Zijia Lin, Fuzheng Zhang, Zhongyuan Wang, Di Zhang, và Kun Gai. Kwaiyiimath: Technical report, 2023a.

Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, và Tushar Khot. Complexity-based prompting for multi-step reasoning. In Proceedings of the 11th International Conference on Learning Representations. OpenReview.net, 2023b.

Josh Gardner, Simon Durand, Daniel Stoller, và Rachel M. Bittner. Llark: A multimodal foundation model for music, 2023.

Prakhar Gupta, Cathy Jiao, Yi-Ting Yeh, Shikib Mehri, Maxine Eskénazi, và Jeffrey P. Bigham. Instructdial: Improving zero and few-shot generalization in dialogue through instruction tuning. In Yoav Goldberg, Zornitsa Kozareva, và Yue Zhang (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 505–525. Association for Computational Linguistics, 2022.

Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, và Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset. In Joaquin Vanschoren và Sai-Kit Yeung (eds.), Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, 2021.

Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, và Jiawei Han. Large language models can self-improve. arXiv preprint arXiv:2210.11610, 2022.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020.

Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy V, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Moustafa-Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, và Harm de Vries. Starcoder: may the source be with you! arXiv preprint arXiv:2305.06161, 2023.

Haotian Liu, Chunyuan Li, Qingyang Wu, và Yong Jae Lee. Visual instruction tuning. arXiv preprint arXiv:2304.08485, 2023a.

Tiedong Liu và Bryan Kian Hsiang Low. Goat: Fine-tuned llama outperforms GPT-4 on arithmetic tasks. arXiv preprint arXiv:2305.14201, 2023.

Zhengliang Liu, Aoxiao Zhong, Yiwei Li, Longtao Yang, Chao Ju, Zihao Wu, Chong Ma, Peng Shu, Cheng Chen, Sekeun Kim, Haixing Dai, Lin Zhao, Dajiang Zhu, Jun Liu, Wei Liu, Dinggang Shen, Xiang Li, Quanzheng Li, và Tianming Liu. Radiology-gpt: A large language model for radiology. arXiv preprint arXiv:2306.08666, 2023b.

Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, và Dongmei Zhang. Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct. arXiv preprint arXiv:2308.09583, 2023a.

Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, và Daxin Jiang. Wizardcoder: Empowering code large language models with evol-instruct. arXiv preprint arXiv:2306.08568, 2023b.

Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, và Peter Clark. Self-refine: Iterative refinement with self-feedback. arXiv preprint arXiv:2303.17651, 2023.

Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M. Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, và Colin Raffel. Crosslingual generalization through multitask finetuning. In Anna Rogers, Jordan L. Boyd-Graber, và Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pp. 15991–16111. Association for Computational Linguistics, 2023.

Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, và Caiming Xiong. Codegen: An open large language model for code with multi-turn program synthesis. In Proceedings of the 11th International Conference on Learning Representations. OpenReview.net, 2023.

OpenAI. Openai: Introducing chatgpt. 2022.

OpenAI. Gpt-4 technical report. 2023.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, và Ryan Lowe. Training language models to follow instructions with human feedback. In Proceedings of the Conference on Neural Information Processing Systems, 2022.

Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, và Huajun Chen. Reasoning with language model prompting: A survey. In Anna Rogers, Jordan L. Boyd-Graber, và Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, pp. 5368–5393. Association for Computational Linguistics, 2023.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal V. Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Févry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, và Alexander M. Rush. Multitask prompted training enables zero-shot task generalization. In Proceedings of the 10th International Conference on Learning Representations. OpenReview.net, 2022.

Yu Shu, Siwei Dong, Guangyao Chen, Wenhao Huang, Ruihua Zhang, Daochen Shi, Qiqi Xiang, và Yemin Shi. Llasm: Large language and speech model. arXiv preprint arXiv:2308.15930, 2023.

Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Agüera y Arcas, Claire Cui, Marian Croak, Ed H. Chi, và Quoc Le. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239, 2022.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023a.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurélien Rodriguez, Robert Stojnic, Sergey Edunov, và Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023b.

Haochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, và Ting Liu. Huatuo: Tuning llama model with chinese medical knowledge. arXiv preprint arXiv:2304.06975, 2023a.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, và Denny Zhou. Self-consistency improves chain of thought reasoning in language models. In Proceedings of the 11th International Conference on Learning Representations. OpenReview.net, 2023b.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, và Hannaneh Hajishirzi. Self-instruct: Aligning language models with self-generated instructions. In Anna Rogers, Jordan L. Boyd-Graber, và Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, pp. 13484–13508. Association for Computational Linguistics, 2023c.

Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D. Q. Bui, Junnan Li, và Steven C. H. Hoi. Codet5+: Open code large language models for code understanding and generation. arXiv preprint arXiv:2305.07922, 2023d.

Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, và Quoc V. Le. Finetuned language models are zero-shot learners. In Proceedings of the 10th International Conference on Learning Representations. OpenReview.net, 2022a.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, và William Fedus. Emergent abilities of large language models. Transactions on Machine Learning Research, 2022, 2022b.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, và Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. In Proceedings of the Conference on Neural Information Processing Systems, 2022c.

Tianwen Wei, Jian Luan, Wei Liu, Shuang Dong, và Bin Wang. CMATH: can your language model pass chinese elementary school math test? arXiv preprint arXiv:2306.16636, 2023.

Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David S. Rosenberg, và Gideon Mann. Bloomberggpt: A large language model for finance. arXiv preprint arXiv:2303.17564, 2023.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, và Daxin Jiang. Wizardlm: Empowering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244, 2023.

Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, và Zhiying Wu. Baichuan 2: Open large-scale language models. arXiv preprint arXiv:2309.10305, abs/2309.10305, 2023a.

Hongyang Yang, Xiao-Yang Liu, và Christina Dan Wang. Fingpt: Open-source financial large language models. arXiv preprint arXiv:2306.06031, 2023b.

Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, và Weiyang Liu. Metamath: Bootstrap your own mathematical questions for large language models. arXiv preprint arXiv:2309.12284, 2023.

Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, và Wenhu Chen. Mammoth: Building math generalist models through hybrid instruction tuning. arXiv preprint arXiv:2309.05653, 2023.

Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, và Jie Tang. GLM-130b: An open bilingual pre-trained model. In Proceedings of the 11th International Conference on Learning Representations, 2023.

Pan Zhang, Xiaoyi Dong, Bin Wang, Yuhang Cao, Chao Xu, Linke Ouyang, Zhiyuan Zhao, Shuangrui Ding, Songyang Zhang, Haodong Duan, Wenwei Zhang, Hang Yan, Xinyue Zhang, Wei Li, Jingwen Li, Kai Chen, Conghui He, Xingcheng Zhang, Yu Qiao, Dahua Lin, và Jiaqi Wang. Internlm-xcomposer: A vision-language large model for advanced text-image comprehension and composition. arXiv preprint arXiv:2309.15112, 2023a.

Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, và Guoyin Wang. Instruction tuning for large language models: A survey. arXiv preprint arXiv:2308.10792, 2023b.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, và Ji-Rong Wen. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023.

Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, và Yu Li. Progressive-hint prompting improves reasoning in large language models. arXiv preprint arXiv:2304.09797, 2023a.

Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, Teng Su, Zhilin Yang, và Jie Tang. Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x, 2023b.

Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, và Jimmy Ba. Large language models are human-level prompt engineers. In Proceedings of the 11th International Conference on Learning Representations. OpenReview.net, 2023.

Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, và Mohamed Elhoseiny. Minigpt-4: Enhancing vision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592, 2023.

Wei Zhu và Xiaoling Wang. Chatmed: A chinese medical large language model. https://github.com/michael-wzhu/ChatMed, 2023.

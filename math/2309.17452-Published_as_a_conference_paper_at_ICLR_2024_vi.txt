# 2309.17452.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2309.17452.pdf
# Kích thước tệp: 1127603 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
TORA: MỘT TÁC TỬ LẬP LUẬN TÍCH HỢP CÔNG CỤ
CHO VIỆC GIẢI QUYẾT BÀI TOÁN TOÁN HỌC
Zhibin Gou1,2∗, Zhihong Shao1,2∗, Yeyun Gong2†, Yelong Shen3
Yujiu Yang1†, Minlie Huang1†, Nan Duan2, Weizhu Chen3
1Đại học Thanh Hoa 2Microsoft Research 3Microsoft Azure AI
{gzb22,szh19}@mails.tsinghua.edu.cn
{yegong,yeshe,nanduan,wzchen}@microsoft.com
TÓM TẮT
Các mô hình ngôn ngữ lớn đã đạt được tiến bộ đáng kể trong nhiều tác vụ ngôn ngữ khác nhau,
nhưng chúng vẫn gặp khó khăn với toán học phức tạp. Trong bài báo này, chúng tôi đề xuất TORA,
một loạt các Tác tử Lập luận Tích hợp Công cụ được thiết kế để giải quyết các bài toán toán học
thách thức bằng cách tích hợp liền mạch lập luận ngôn ngữ tự nhiên với việc sử dụng các công cụ
bên ngoài (ví dụ: thư viện tính toán và bộ giải quyết ký hiệu), từ đó kết hợp khả năng phân tích
của ngôn ngữ và hiệu quả tính toán của công cụ. Để huấn luyện TORA, chúng tôi tuyển chọn các
quỹ đạo sử dụng công cụ tương tác trên các tập dữ liệu toán học, áp dụng học tập mô phỏng trên
các chú thích, và đề xuất định hình không gian đầu ra để tinh chỉnh thêm hành vi lập luận của mô
hình. Kết quả là, các mô hình TORA vượt trội đáng kể so với các mô hình nguồn mở trên 10 tập
dữ liệu lập luận toán học ở tất cả các quy mô với cải thiện tuyệt đối 13%-19% trung bình. Đáng
chú ý, TORA-7B đạt 44,6% trên tập dữ liệu cấp độ thi đấu MATH, vượt qua mô hình nguồn mở
tốt nhất WizardMath-70B 22% tuyệt đối. TORA-CODE-34B cũng là mô hình nguồn mở đầu tiên
đạt được độ chính xác vượt quá 50% trên MATH, vượt trội đáng kể so với kết quả CoT của GPT-4,
và cạnh tranh với GPT-4 giải quyết bài toán bằng chương trình. Ngoài ra, chúng tôi thực hiện phân
tích toàn diện về lợi ích và thách thức còn lại của tương tác công cụ cho lập luận toán học, cung cấp
những hiểu biết có giá trị cho nghiên cứu tương lai1.
7B 13B 70B0102030405060Độ chính xác (%)
4.16.314.4
7.29.214.9
10.714.022.744.648.149.7MATH
7B 13B 70B020406080100Độ chính xác (%)
13.324.357.8
41.351.155.2 54.963.981.6
72.675.884.3GSM8kGPT-4-Code
GPT-4ChatGPT-Code
ChatGPTBase
SFTWizardMath
ToRA
Hình 1: So sánh TORA với các baseline trên các mô hình cơ sở LLaMA-2 từ 7B đến 70B. Các mô hình TORA
thể hiện những cải thiện đáng kể so với các phương pháp tiên tiến nhất trước đó ở tất cả các quy mô.
Đặc biệt, TORA-70B vượt trội rõ rệt so với kết quả CoT của GPT-4 trên MATH và đạt được kết quả
tương đương với GPT-4 giải quyết bài toán bằng code.
∗Đóng góp bằng nhau. Xem phần Đóng góp để biết chi tiết. Công việc được thực hiện trong thời gian thực tập tại Microsoft.
†Tác giả liên hệ.
1Code và mô hình có sẵn tại https://github.com/microsoft/ToRA .
1arXiv:2309.17452v4 [cs.CL] 21 Feb 2024

--- TRANG 2 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Bài toán: Giả sử tổng bình phương của hai số phức 𝑥 và 𝑦 là 7 và tổng lập phương của chúng là 10. Liệt kê tất cả các giá trị có thể của 𝑥+𝑦, cách nhau bởi dấu phẩy. Hãy sử dụng `Sympy` để tính toán và in tất cả các giá trị có thể của 𝑥+𝑦,
Loại bỏ trùng lặp, các giá trị có thể của 𝑥+𝑦 là \boxed{-5,1,4}. Chúng ta có 𝑥!+𝑦!=7 và 𝑥"+𝑦"=10. Chúng ta có thể phân tích 𝑥"+𝑦" để được 𝑥+𝑦(𝑥!−𝑥𝑦+𝑦!). Do đó, chúng ta có thể viết 10=𝑥+𝑦7. Suy ra 𝑥+𝑦 phải chia hết cho 10. Các khả năng duy nhất là 𝑥+𝑦 là 1,2,5 hoặc 10. ✘✓𝑟!𝑎"𝑟"𝑜" (a) Dựa trên lập luận (b) Dựa trên chương trình (c) Lập luận Tích hợp Công cụ (Định dạng được sử dụng bởi ToRA) import math def solution(): x = symbols('x'), y = symbols('y') x**2 + y**2 = 7 x**3 + y**3 = 10 x = (-1 + math.sqrt(17)) / 2 y = (-1 -math.sqrt(17)) / 2 # Lấy tất cả các giá trị có thể của x+y result = [x + y, -x -y] from sympy import symbols, Eq, solve, simplify def possible_values(): x, y = symbols('x y') eq1 = Eq(x**2 + y**2, 7) eq2 = Eq(x**3 + y**3, 10) solutions = solve((eq1,eq2), (x, y)) sums = [simplify(sol[0] + sol[1]) for sol in solutions] return sums print(possible_values()) >>> [-5, -5, 1, 1, 4, 4] >>> SyntaxError: cannot assign to expression. ✘ Lập luận Đầu ra Lập luận Chương trình

Hình 2: Ví dụ về ba định dạng lập luận cho lập luận toán học: (a) Phương pháp dựa trên lập luận (ví dụ: gợi ý CoT) tạo ra các lập luận ngôn ngữ tự nhiên từng bước, (b) Phương pháp dựa trên chương trình (ví dụ: gợi ý PAL) giải quyết các tác vụ với tổng hợp chương trình, và (c) định dạng Lập luận Tích hợp Công cụ đề xuất của chúng tôi xen kẽ các lập luận với việc sử dụng công cụ dựa trên chương trình. Để ngắn gọn, chúng tôi trình bày một ví dụ đơn giản về tương tác công cụ một vòng, trong đó mô hình tạo ra lập luận r1 để phân tích, viết chương trình a1 để gọi một bộ giải bên ngoài, thu được đầu ra thực thi o1, và sau đó tạo ra lập luận r2 để hoàn thiện câu trả lời.

1 GIỚI THIỆU
Các mô hình ngôn ngữ lớn (LLMs), như GPT-4 (OpenAI, 2023) và PaLM-2 (Anil et al., 2023), đã chứng minh tiến bộ đáng kể trong một loạt các tác vụ ngôn ngữ, đặc biệt là trong thách thức lâu dài về lập luận toán học (Feigenbaum et al., 1963; Hosseini et al., 2014). Tuy nhiên, các mô hình nguồn mở, như LLaMA-2 (Touvron et al., 2023a;b) và Falcon (Penedo et al., 2023), vẫn gặp khó khăn với các tác vụ lập luận toán học nâng cao.

Các công trình hiện tại cải thiện hiệu suất toán học của các mô hình ngôn ngữ bằng cách sử dụng lập luận ngôn ngữ tự nhiên từng bước (Wei et al., 2022) như minh họa trong Hình 2 (a), hoặc bằng cách tổng hợp và thực thi các chương trình để thu được câu trả lời (Gao et al., 2022; Chen et al., 2022), như mô tả trong Hình 2 (b). Cả hai phương pháp đều thể hiện những ưu điểm bổ sung. Ngôn ngữ tự nhiên phù hợp cho phân tích ngữ nghĩa, lập kế hoạch, và lập luận trừu tượng (ví dụ: lập luận thông thường), nhưng gặp khó khăn với tính toán chính xác, thao tác ký hiệu, và xử lý thuật toán. Ngược lại, chương trình xuất sắc trong các thao tác nghiêm ngặt, và có thể ủy thác các tính toán phức tạp cho các công cụ chuyên biệt như bộ giải phương trình.

Để tận dụng lợi ích của cả lập luận ngôn ngữ tự nhiên và sử dụng công cụ dựa trên chương trình, chúng tôi huấn luyện các mô hình nguồn mở như LLaMA-2 để lập luận theo cách mà lập luận ngôn ngữ tự nhiên được xen kẽ với việc sử dụng công cụ dựa trên chương trình một cách hiệp đồng (như mô tả trong Hình 2 (c)), từ đó giảm đáng kể khoảng cách với các mô hình nguồn đóng như GPT-4 trong lập luận toán học. Cụ thể, chúng tôi trước tiên thiết kế định dạng xen kẽ của lập luận, tuyển chọn các quỹ đạo sử dụng công cụ tương tác tương ứng cho các bài toán toán học từ tập dữ liệu phổ biến GSM8k (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021), và sau đó áp dụng học tập mô phỏng trên các chú thích chất lượng cao, dẫn đến hiệu suất tốt hơn so với bất kỳ mô hình nguồn mở hiện tại nào. Hơn nữa, vì dữ liệu được tuyển chọn còn xa mới cạn kiệt tất cả các quỹ đạo hợp lệ cho một bài toán, việc chỉ dựa vào học tập mô phỏng hạn chế không gian đầu ra của mô hình, cản trở tính linh hoạt trong việc khám phá các quỹ đạo hợp lý trong quá trình kiểm tra. Để cải thiện tính đa dạng của các bước lập luận hợp lý và giảm thiểu hành vi sử dụng công cụ không phù hợp, chúng tôi áp dụng định hình không gian đầu ra, bổ sung huấn luyện các mô hình trên cả các quỹ đạo hợp lệ tự lấy mẫu và các quỹ đạo không hợp lệ đã được sửa chữa bởi một mô hình giáo viên (ví dụ: mô hình 34B có thể làm giáo viên

--- TRANG 3 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Lập luận Đầu ra
②Định hình Không gian Đầu ra
Lấy mẫu Đầu ra Sửa chữa Giáo viên
Quỹ đạo Hợp lệ
LLM ToRA-Corpus Lập luận Tích hợp Công cụ Quỹ đạo Hợp lệ M
Lập luận Đầu ra Tinh chỉnh M
Bài toán Bài toán
Lập luận Đầu ra M' Tinh chỉnh ToRA
✓✘✘✓✓✓
…①Học tập Mô phỏng

Hình 3: Huấn luyện TORA bao gồm hai bước. ①Học tập Mô phỏng: Gợi ý cho các LLM như GPT-4 để tạo ra các quỹ đạo Lập luận Tích hợp Công cụ (TORA-CORPUS) và sử dụng bộ dữ liệu này để tinh chỉnh một mô hình M; ②Định hình Không gian Đầu ra: Lấy mẫu các quỹ đạo sử dụng công cụ đa dạng với M, giữ lại những quỹ đạo hợp lệ, sửa chữa những quỹ đạo không hợp lệ bằng một mô hình giáo viên M′, và huấn luyện lại M trên tập hợp của các quỹ đạo hợp lệ được lấy mẫu, các quỹ đạo đã sửa chữa, và TORA-CORPUS ban đầu để thu được TORA.

cho một mô hình 7B). Định hình không gian đầu ra cải thiện đáng kể lập luận, cho phép các mô hình nguồn mở đạt được độ chính xác vượt quá 50% trên tập dữ liệu MATH cấp độ thi đấu lần đầu tiên.

Chúng tôi đánh giá bộ Tác tử Lập luận Tích hợp Công cụ (TORA) kết quả từ 7B đến 70B trên 10 tập dữ liệu lập luận toán học đa dạng. Như thể hiện trong Hình 1, loạt TORA vượt trội đáng kể so với các mô hình nguồn mở ở tất cả các quy mô. Đáng chú ý, trên tập dữ liệu MATH cấp độ thi đấu, TORA-7B vượt trội so với WizardMath-70B SoTA trước đó (Luo et al., 2023) 22% tuyệt đối. TORA-CODE-34B đánh bại kết quả CoT của GPT-4 (Bubeck et al., 2023) 8,3% tuyệt đối (50,8% so với 42,5%), và cạnh tranh với GPT-4 giải quyết bài toán bằng code (GPT-4-Code, 51,8%). Ngoài ra, chúng tôi phân tích những lợi ích và thách thức còn lại của tương tác công cụ cho lập luận toán học, cung cấp những hiểu biết có giá trị cho công việc tương lai.

2 TORA: TÁC TỬ TÍCH HỢP CÔNG CỤ CHO LẬP LUẬN TOÁN HỌC

2.1 TỔNG QUAN
Loạt TORA giải quyết các bài toán toán học thách thức bằng cách tận dụng cả lập luận ngôn ngữ tự nhiên và sử dụng công cụ dựa trên chương trình. Như thể hiện trong Hình 2 (c), với một bài toán toán học q, TORA lập luận bằng ngôn ngữ tự nhiên, tạo ra r1. Khi đạt đến một điểm mà việc sử dụng công cụ dựa trên chương trình phù hợp hơn cho tác vụ tiếp theo, ví dụ: giải phương trình, TORA tạo ra một chương trình a1 để sử dụng công cụ theo hướng dẫn ngôn ngữ tự nhiên r1. Đầu ra thực thi o1 sẽ được đưa vào TORA để xử lý tiếp theo bao gồm điều chỉnh sử dụng công cụ, giải quyết các tác vụ con, hoặc hoàn thiện câu trả lời. Chúng tôi lặp lại quá trình cho đến khi mô hình đặt câu trả lời của nó trong "\boxed{}". Quỹ đạo kết quả được ký hiệu là τ=r1a1o1...rn−1an−1on−1rn, trong đó rn chứa câu trả lời.

Hình 3 trình bày quy trình huấn luyện của TORA. Chúng tôi trước tiên thu thập các quỹ đạo sử dụng công cụ tương tác trên các tập dữ liệu toán học phổ biến. Sau đó chúng tôi áp dụng học tập mô phỏng trên các chú thích kết quả, cũng như định hình không gian đầu ra để tinh chỉnh thêm hành vi lập luận của mô hình.

2.2 THU THẬP CÁC QUỸ ĐẠO SỬ DỤNG CÔNG CỤ TƯƠNG TÁC
Các tập dữ liệu lập luận toán học hiện tại chủ yếu chứa các chú thích bằng ngôn ngữ tự nhiên hoặc code, đặt ra thách thức trong việc huấn luyện các tác tử tích hợp công cụ do thiếu các chú thích sử dụng công cụ tương tác. Để giải quyết vấn đề này, chúng tôi sử dụng GPT-4 để tổng hợp các quỹ đạo chất lượng cao trên tập huấn luyện GSM8k và MATH. Chúng tôi chọn GSM8k và MATH vì chúng thể hiện các mẫu lập luận đa dạng, bao trùm nhiều lĩnh vực và mức độ khó khác nhau.

--- TRANG 4 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Thuật toán 1 Suy luận của Lập luận Tích hợp Công cụ
Yêu cầu: bài toán q, mô hình G, gợi ý p, công cụ bên ngoài E, điều kiện dừng Stop(·), số vòng lặp tối đa n
1:τ0←"" ▷Khởi tạo Quỹ đạo
2:for i←1 to n do
3: ri∼PG(·|p⊕q⊕τi−1) ▷Tạo Lập luận (Eq. 1)
4: if Stop(ri) then ▷Tiêu chí Dừng
5: return τi−1⊕ri
6: end if
7: ai∼PG(·|p⊕q⊕τi−1⊕ri) ▷Tạo Chương trình (Eq. 2)
8: oi← E(ai) ▷Thực thi Công cụ
9: τi←τi−1⊕ri⊕ai⊕oi ▷Cập nhật Quỹ đạo (Eq. 3)
10:end for
11:return τn

Tuyển chọn Gợi ý Chúng tôi soạn thảo các hướng dẫn cùng với các ví dụ few-shot đa dạng, sử dụng định dạng xen kẽ như mô tả trong Hình 2 (c). Các ví dụ này thể hiện các quỹ đạo sử dụng công cụ tương tác, kết hợp tên biến mô tả và đầu ra chương trình kết hợp. Vui lòng tham khảo Phụ lục E cho các gợi ý được tập hợp.

Quy trình Suy luận Chúng tôi theo Thuật toán 1 và cung cấp GPT-4 (G) với gợi ý p được soạn thảo để tạo ra một quỹ đạo sử dụng công cụ τ cho mỗi câu hỏi q từ tập huấn luyện. Quỹ đạo được khởi tạo như một chuỗi rỗng τ0, đối với mỗi vòng tương tác i, chúng tôi trước tiên tạo ra một lập luận:
ri∼PG(·|p⊕q⊕τi−1) (1)
trong đó ⊕ có nghĩa là nối chuỗi. Nếu ri bao gồm một câu trả lời trong "\boxed{}" (tức là điều kiện dừng Stop(ri)), chúng tôi ngừng tạo ra, ngược lại mô hình tiếp tục viết một chương trình để sử dụng công cụ:
ai∼PG(·|p⊕q⊕τi−1⊕ri) (2)
Theo Gou et al. (2023), nếu mô hình kích hoạt các từ dừng thực thi code như " '''output ", chúng tôi cung cấp cho nó thông điệp thực thi tương ứng và đầu ra oi bằng cách gọi công cụ với oi← E(ai), tạo điều kiện thuận lợi cho việc tạo ra các bước tiếp theo. Sau đó, chúng tôi cập nhật quỹ đạo bằng cách nối nó với lập luận ri mới được tạo ra, chương trình ai, và đầu ra oi:
τi←τi−1⊕ri⊕ai⊕oi (3)
Chúng tôi lặp lại quá trình tương tác trên cho đến khi chúng tôi đạt đến số vòng tối đa n.

Lấy mẫu Quỹ đạo Chúng tôi đặt n= 3 và thực hiện suy luận bằng GPT-4 với giải mã tham lam, giữ lại các quỹ đạo mang lại câu trả lời đúng. Đối với những câu hỏi mà GPT-4 thất bại với giải mã tham lam, chúng tôi áp dụng lấy mẫu nucleus với kích thước mẫu 10 và giữ lại tối đa 4 quỹ đạo hợp lệ mỗi câu hỏi. Cuối cùng, chúng tôi thành công chú thích quỹ đạo cho 98,2% câu hỏi GSM8k và 83,1% câu hỏi MATH. Sau khi lọc bỏ các quỹ đạo không hợp lệ với lỗi sử dụng công cụ hoặc câu trả lời sai, chúng tôi thu được 16k chú thích tạo thành tập dữ liệu TORA-CORPUS. Bảng 1 so sánh TORA-CORPUS với các tập dữ liệu lập luận toán học được đề xuất gần đây, trong khi Bảng 6 trong Phụ lục hiển thị chi tiết độ chính xác chú thích MATH.

2.3 HUẤN LUYỆN
Học tập Mô phỏng Chúng tôi áp dụng học tập mô phỏng trên TORA-CORPUS bằng cách tối thiểu hóa mất mát log-likelihood âm trên quỹ đạo τ có điều kiện trên bài toán q:
M= arg min
MX
q,τn−1X
i=1−logPM(ri+1ai+1|q, r1...oi) (4)
trong đó M là mô hình kết quả. Sau học tập mô phỏng, chúng tôi có thể đơn giản áp dụng cùng quy trình trong Thuật toán 1 bằng cách đặt gợi ý thành rỗng p="" để suy luận. Học tập mô phỏng dẫn đến hiệu suất lập luận toán học tiên tiến nhất mặc dù quy mô nhỏ của TORA-CORPUS.

--- TRANG 5 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Bảng 1: So sánh với các tập dữ liệu lập luận toán học, TORA-CORPUS kết hợp duy nhất các lập luận ngôn ngữ tự nhiên với việc sử dụng công cụ dựa trên chương trình. Lưu ý rằng TORA-CORPUS chỉ sử dụng các câu hỏi từ tập huấn luyện gốc của MATH và GSM8k.
Phương pháp #Chú thích Công cụ Xen kẽ LLM Sử dụng Nguồn
RFT (Yuan et al., 2023) >100k ✗ ✗ LLaMA-2 GSM8k
Open-Platypus Lee et al. (2023) 25k ✗ ✗ GPT-4 11 tập dữ liệu với MATH
WizardMath (Luo et al., 2023) >96k ✗ ✗ ChatGPT MATH & GSM8k
Lila (Mishra et al., 2022) 134k ✓(PoT) ✗ - 20 tập dữ liệu với MATH & GSM8k
MathInstruct (Yue et al., 2023) 260k ✓(PoT) ✗ GPT-4 14 tập dữ liệu với MATH & GSM8k
TORA-CORPUS (của chúng tôi) 16k ✓ ✓ GPT-4 MATH & GSM8k

Định hình Không gian Đầu ra Đối với mỗi câu hỏi, TORA-CORPUS chủ yếu chỉ thể hiện một quỹ đạo sử dụng công cụ tương tác hợp lệ, điều này có thể hạn chế không gian đầu ra của mô hình, khiến nó không linh hoạt trong việc khám phá các quỹ đạo hợp lý trong quá trình kiểm tra. Do đó chúng tôi đề xuất định hình không gian đầu ra nhằm khuyến khích tính đa dạng của các bước lập luận hợp lý và giảm hành vi sử dụng công cụ không phù hợp.

Để khám phá các quỹ đạo hợp lệ đa dạng, chúng tôi áp dụng lấy mẫu nucleus cho các mô hình học tập mô phỏng M để lấy mẫu 64 quỹ đạo mỗi câu hỏi huấn luyện q, theo quy trình suy luận trong Phần 2.2. Chúng tôi giữ lại các quỹ đạo hợp lệ với câu trả lời đúng và không có lỗi sử dụng công cụ. Vì nhiều mẫu là trùng lặp, để cải thiện thêm tính đa dạng và trong nỗ lực sửa chữa hành vi không phù hợp của mô hình, chúng tôi tìm cách tận dụng cả các quỹ đạo không hợp lệ. Chúng tôi quan sát thấy rằng các quỹ đạo với câu trả lời sai chủ yếu không chính xác ở giữa chừng (Li et al., 2023), và phần lập luận trước đó vẫn hợp lý; nói cách khác, chúng tôi có thể thu được các quỹ đạo hợp lệ bằng cách sửa chữa các phần tiếp theo. Cụ thể, một quỹ đạo sai eτ, khi được viết dưới dạng văn bản, có thể được biểu diễn như một chuỗi các dòng được phân tách bằng dấu xuống dòng, tức là eτ=l1...lm, trong đó m là tổng số dòng trong eτ. Chúng tôi liệt kê các phần trước có thể của các quỹ đạo sai, tức là eτ[:j] =l1...lj, và tận dụng một mô hình giáo viên M′ để hoàn thành các bước tiếp theo với giải mã tham lam: τ←PM′(·|q⊕eτ[:j]) trong đó chúng tôi lạm dụng ký hiệu PM′(·) để biểu thị quá trình sử dụng công cụ tương tác theo Phần 2.2. Cuối cùng, các quỹ đạo đã sửa chữa cũng như các mẫu quỹ đạo hợp lệ sẽ được sử dụng để huấn luyện mô hình, từ đó định hình không gian đầu ra.

Trong các thí nghiệm của chúng tôi, chúng tôi luôn sử dụng CodeLLaMA-34B được huấn luyện trên TORA-CORPUS làm mô hình giáo viên, và áp dụng lấy mẫu với loạt CodeLLaMA (từ 7B đến 34B, với học tập mô phỏng). Chúng tôi thu được tổng cộng 233k mẫu quỹ đạo hợp lệ riêng biệt và 69k mẫu đã sửa chữa. Từ tập dữ liệu kết hợp này, chúng tôi chọn ngẫu nhiên tối đa 4 quỹ đạo mỗi bài toán GSM8k và MATH, hợp nhất chúng với TORA-CORPUS, và sau đó huấn luyện tất cả các mô hình TORA trên 69k chú thích kết quả.

3 THÍ NGHIỆM

3.1 CHI TIẾT TRIỂN KHAI
Chúng tôi tinh chỉnh loạt LLaMA-2 (Touvron et al., 2023b) và CodeLLaMA (Rozière et al., 2023) (từ 7B đến 70B) sử dụng TORA-CORPUS với định hình không gian đầu ra, tạo ra loạt TORA và TORA-CODE tương ứng. Chúng tôi sử dụng tỷ lệ học 2e-5 theo mặc định trừ việc chúng tôi sử dụng 1e-5 cho các mô hình 34B và 70B. Chúng tôi đặt kích thước batch toàn cục là 128 và sử dụng bộ lập lịch tuyến tính với giai đoạn khởi động 3% trong 3 epoch. Chúng tôi huấn luyện tất cả các mô hình với DeepSpeed ZeRO Stage3 (Rajbhandari et al., 2021) và Flash-Attention 2 (Dao, 2023). Chúng tôi sử dụng giải mã tham lam cho tất cả kết quả, với độ dài chuỗi tối đa được đặt thành 2,048 và số lần thực thi công cụ tối đa được đặt thành 3.

3.2 THIẾT LẬP ĐÁNH GIÁ
Tập dữ liệu Chúng tôi đánh giá các mô hình trên GSM8k (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021), cùng với 8 tập dữ liệu ngoài phân phối, cụ thể là GSM-Hard (Gao et al., 2022), SVAMP (Patel et al., 2021), ASDIV (Miao et al., 2020), TabMWP (Lu et al., 2023), SingleEQ, SingleOP, AddSub, và MultiArith (Koncel-Kedziorski et al., 2016), như minh họa trong Bảng 5 trong Phụ lục. 10 tập dữ liệu đa dạng tập hợp bao gồm các bài toán toán học từ số học cơ bản đến cấp độ thi đấu, bao trùm chương trình trung học và phổ thông và các lĩnh vực toán học khác nhau. Các định dạng bài toán bao gồm các câu hỏi dựa trên bảng, dạng tự do, và trắc nghiệm, đảm bảo đánh giá toàn diện khả năng lập luận toán học của mô hình.

--- TRANG 6 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Bảng 2: Kết quả trên 10 tác vụ lập luận toán học. Kết quả MAWPS được tính trung bình trên bốn tác vụ: Singleeq, Singleop, Addsub, và MultArith. Các mô hình Vanilla được kiểm tra với CoT. Kết quả tốt nhất trong mỗi phần được tô màu xanh, kết quả tốt thứ hai được gạch dưới, trong khi kết quả của mô hình tốt nhất của chúng tôi được in đậm.∗ZS: Suy luận không cần mẫu mà không có minh chứng.
Mô hình Kích thước Công cụ ZS∗GSM8k MATH GSM-Hard SVAMP TabMWP ASDiv MAWPS AVG
Được sử dụng cho huấn luyện? ✓ ✓ ✗ ✗ ✗ ✗ ✗
Các Mô hình Độc quyền
GPT-4 - ✗ ✗ 92.0 42.5 64.7 93.1 67.1 91.3 97.6 78.3
GPT-4 (PAL) - ✓ ✗ 94.2 51.8 77.6 94.8 95.9 92.6 97.7 86.4
ChatGPT - ✗ ✗ 80.8 35.5 55.9 83.0 69.1 87.3 94.6 72.3
ChatGPT (PAL) - ✓ ✗ 78.6 38.7 67.6 77.8 79.9 81.0 89.4 73.3
Claude-2 - ✗ ✗ 85.2 32.5 - - - - - -
PaLM-2 540B ✗ ✗ 80.7 34.3 - - - - - -
Các Mô hình Nguồn Mở
LLaMA-2 7B ✗ ✗ 13.3 4.1 7.8 38.0 31.1 50.7 60.9 29.4
LLaMA-2 SFT 7B ✗ ✓ 41.3 7.2 16.1 31.9 27.8 47.4 60.0 33.1
LLaMA-2 RFT 7B ✗ ✓ 51.2 - - - - - - -
Platypus-2 7B ✗ ✗ 14.4 5.4 8.6 36.7 26.5 47.9 58.4 28.3
WizardMath 7B ✗ ✓ 54.9 10.7 20.6 57.3 38.1 59.1 73.7 44.9
CodeLLaMA (PAL) 7B ✓ ✗ 34.0 16.6 33.6 59.0 47.3 61.4 79.6 47.4
Toolformer† 7B ✓ ✓ - - - 29.4 - 40.4 44.0 -
TORA 7B ✓ ✓ 68.8 40.1 54.6 68.2 42.4 73.9 88.8 62.4
TORA-CODE 7B ✓ ✓ 72.6 44.6 56.0 70.4 51.6 78.7 91.3 66.5 (+19)
LLaMA-2 13B ✗ ✗ 24.3 6.3 13.6 43.1 39.5 56.3 70.4 36.2
LLaMA-2 SFT 13B ✗ ✓ 51.1 9.2 22.3 46.3 35.8 58.6 75.0 42.6
LLaMA-2 RFT 13B ✗ ✓ 55.3 - - - - - - -
Platypus-2 13B ✗ ✗ 23.7 7.1 14.3 50.7 45.3 55.1 69.6 38.0
WizardMath 13B ✗ ✓ 63.9 14.0 28.4 64.3 46.7 65.8 79.7 51.8
CodeLLaMA (PAL) 13B ✓ ✗ 39.9 19.9 39.0 62.4 59.5 65.3 86.0 53.1
TORA 13B ✓ ✓ 72.7 43.0 57.3 72.9 47.2 77.2 91.3 65.9
TORA-CODE 13B ✓ ✓ 75.8 48.1 60.5 75.7 65.4 81.4 92.5 71.3 (+18)
LLaMA-1 RFT 34B ✗ ✓ 57.9 - - - - - - -
CodeLLaMA (PAL) 34B ✓ ✗ 53.3 23.9 49.4 71.0 63.1 72.4 91.5 60.7
TORA-CODE 34B ✓ ✓ 80.7 50.8 63.7 80.5 70.5 84.2 93.3 74.8 (+14)
LLaMA-2 70B ✗ ✗ 57.8 14.4 36.0 73.6 57.5 76.0 92.4 58.2
LLaMA-2 SFT 70B ✗ ✓ 69.3 14.9 39.0 64.0 53.0 71.3 84.8 56.6
LLaMA-2 RFT 70B ✗ ✓ 64.8 - - - - - - -
Platypus-2 70B ✗ ✗ 45.9 15.0 24.6 74.3 47.3 72.7 91.1 53.0
WizardMath 70B ✗ ✓ 81.6 22.7 50.3 80.0 49.8 76.2 86.2 63.8
LLaMA-2 (PAL) 70B ✓ ✗ 55.2 18.3 50.0 74.6 59.5 71.9 92.8 60.3
TORA 70B ✓ ✓ 84.3 49.7 67.2 82.7 74.0 86.8 93.8 76.9 (+13)

Các chỉ số Chúng tôi báo cáo độ chính xác của các câu trả lời dự đoán. Theo Lightman et al. (2023), chúng tôi làm tròn các giá trị số và sử dụng sympy² để phân tích biểu thức. Vì các tập dữ liệu SingleEQ, SingleOP, AddSub, và MultiArith tập trung vào các khía cạnh khác nhau của số học cơ bản, chúng tôi báo cáo kết quả trung bình của chúng dưới thuật ngữ tập thể MAWPS (Koncel-Kedziorski et al., 2016) cho tất cả các phương pháp.

3.3 BASELINE
Các Mô hình Độc quyền Chúng tôi trình bày kết quả từ một loạt các LLM SoTA, như GPT-4 của OpenAI, ChatGPT (gpt-3.5-turbo), PaLM-2 của Google, và Claude-2 của Anthropic. Theo mặc định, chúng tôi báo cáo kết quả gợi ý CoT, và bao gồm kết quả gợi ý PAL (Gao et al., 2022) cho các mô hình được chọn.

Các Mô hình Nguồn Mở Các mô hình cơ sở bao gồm LLaMA-2 và CodeLLaMA với gợi ý CoT và PAL. Tinh chỉnh Có giám sát (SFT) sử dụng các lập luận CoT từ tập dữ liệu GSM8k và MATH gốc (15k mẫu) để tinh chỉnh. Tinh chỉnh Lấy mẫu Từ chối (RFT) tận dụng nhiều mô hình để tạo ra các đường lối lập luận đa dạng để tinh chỉnh (Yuan et al., 2023). WizardMath tăng cường dữ liệu bằng ChatGPT, và thực hiện SFT và RLHF. Platypus-2, mô hình hàng đầu trên LLM Leaderboard³, được tinh chỉnh với các tập dữ liệu lập luận Open-Platypus (Lee et al., 2023). Chúng tôi cũng so sánh TORA với Toolformer (Schick et al., 2023) là một mô hình được huấn luyện để sử dụng máy tính.

²https://www.sympy.org
³https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard

--- TRANG 7 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Bảng 3: Kết quả trên các chủ đề con của MATH.
Mô hình Kích thước Công cụ Đại số Trung cấp Precalculus Hình học Lý thuyết Số Đếm & Xác suất Prealgebra Đại số Tổng thể
Các Mô hình Độc quyền
ChatGPT (PAL) - ✓ 18.5 19.2 23.2 48.5 43.0 62.7 45.4 38.7
GPT-4 (PAL) - ✓ 32.8 29.3 38.0 58.7 61.0 73.9 59.1 51.8
Các Mô hình Nguồn Mở
WizardMath 7B ✗ 6.2 6.0 6.5 7.6 9.5 18.1 16.3 11.2
TORA-CODE 7B ✓ 35.1 (+28.9) 31.0 (+25.0) 24.0 (+17.5) 50.7 (+43.1) 30.6 (+21.1) 55.0 (+36.9) 61.7 (+45.4) 44.6 (+33.4)
w/o Shaping 7B ✓ 29.7 (-5.4) 25.1 (-5.9) 17.7 (-6.3) 46.9 (-3.8) 32.3 (+1.7) 51.9 (-3.1) 55.7 (-6.0) 40.2 (-4.4)
w/o Rationale 7B ✓ 25.5 (-9.6) 14.7 (-16.3) 15.4 (-8.6) 45.9 (-4.8) 29.7 (-0.9) 51.0 (-4.0) 52.4 (-9.3) 36.8 (-7.8)
WizardMath 13B ✗ 6.4 6.6 11.5 9.6 11.0 28.5 21.1 15.0
TORA-CODE 13B ✓ 35.7 (+29.3) 31.1 (+24.5) 25.7 (+14.2) 55.6 (+46.0) 39.5 (+28.5) 58.7 (+30.2) 66.7 (+45.6) 48.1 (+33.1)
w/o Shaping 13B ✓ 32.8 (-2.9) 26.0 (-5.1) 24.0 (-1.7) 52.6 (-3.0) 38.4 (-1.1) 55.6 (-3.1) 61.2 (-5.5) 44.6 (-3.5)
w/o Rationale 13B ✓ 27.1 (-8.6) 15.8 (-15.3) 16.3 (-9.4) 50.4 (-5.2) 36.9 (-2.6) 55.3 (-3.4) 56.5 (-10.2) 40.2 (-7.9)
TORA-CODE 34B ✓ 38.9 34.6 27.3 57.8 41.4 63.7 67.7 50.8
w/o Shaping 34B ✓ 34.0 (-4.9) 29.9 (-4.7) 24.6 (-2.7) 55.6 (-2.2) 41.6 (+0.2) 63.8 (+0.1) 61.4 (-6.3) 47.4 (-3.4)
w/o Rationale 34B ✓ 28.3 (-10.6) 15.8 (-18.8) 18.0 (-9.3) 52.4 (-5.4) 40.7 (-0.7) 58.6 (-5.1) 57.5 (-10.2) 41.9 (-8.9)
WizardMath 70B ✗ 9.1 13.4 16.9 16.5 19.2 42.7 35.0 24.1
TORA 70B ✓ 37.1 (+28) 30.4 (+17) 30.1 (+13.2) 54.6 (+38.1) 40.3 (+21.1) 64.9 (+22.2) 66.6 (+31.6) 49.7 (+25.6)
w/o Shaping 70B ✓ 33.8 (-3.3) 28.9 (-1.5) 27.1 (-3) 53.0 (-1.6) 38.0 (-2.3) 62.2 (-2.7) 64.2 (-2.4) 47.3 (-2.4)
w/o Rationale 70B ✓ 26.7 (-10.4) 14.7 (-15.7) 20.3 (-9.8) 48.9 (-5.7) 39.2 (-1.1) 59.8 (-5.1) 57.6 (-9) 41.5 (-8.2)

3.4 KẾT QUẢ CHÍNH
Bảng 2 trình bày kết quả của TORA trên 10 tập dữ liệu toán học, nêu bật những quan sát nổi bật sau: (1) Sử dụng định dạng xen kẽ và định hình không gian đầu ra, TORA vượt trội một cách nhất quán so với các mô hình nguồn mở tiên tiến nhất trước đó ở tất cả các quy mô, đạt được cải thiện tuyệt đối 13% đến 19% trên 10 tác vụ. (2) TORA-70B vượt trội đáng kể so với ChatGPT với cả gợi ý CoT và PAL trên GSM8k (84,3% so với 80,4%) và MATH (49,7% so với 38,7%), trong khi TORA-CODE-34B cạnh tranh với GPT-4 giải quyết tập dữ liệu MATH cấp độ thi đấu bằng code (50,8% so với 51,8%). (3) Độ chính xác của TORA-CODE cao hơn khoảng 5% so với TORA có cùng kích thước, chứng minh rằng việc huấn luyện tiếp tục trên dữ liệu code có lợi đáng kể cho việc sử dụng công cụ dựa trên chương trình. (4) Trong khi tinh chỉnh dựa trên lập luận ảnh hưởng tiêu cực đến khả năng tổng quát hóa ngoài phân phối, TORA thể hiện khả năng tổng quát hóa vượt trội. Ví dụ, WizardMath-70B kém hiệu suất hơn mô hình cơ sở trên TabMWP (49,8% so với 57,5%), trong khi TORA-70B tổng quát hóa hiệu quả cho tác vụ lập luận bảng này (74,0%). (5) TORA đạt được tốc độ suy luận không cần mẫu nhanh, trung bình 1,02 vòng tương tác công cụ mỗi bài toán, trong khi giải quyết hiệu quả các bài toán yêu cầu sử dụng công cụ tương tác.

3.5 NGHIÊN CỨU LOẠI BỎ
LLaMA-2-7B LLaMA-2-13B LLaMA-2-70B GPT-40102030405060Độ chính xác (%)
7.29.214.942.5
27.831.339.251.8
33.637.547.361.6Chỉ lập luận Chỉ chương trình Lập luận Tích hợp Công cụ

Hình 4: So sánh ba định dạng: (1) Chỉ lập luận: lập luận ngôn ngữ tự nhiên từng bước như CoT; (2) Chỉ chương trình: giải quyết bài toán bằng chương trình như PAL; (3) Lập luận Tích hợp Công cụ được sử dụng bởi TORA: xen kẽ lập luận và thực thi chương trình để giải quyết bài toán. Chúng tôi đánh giá GPT-4 với gợi ý few-shot. Chúng tôi huấn luyện các mô hình LLaMA-2 để lập luận theo ba loại định dạng tương ứng. Để so sánh công bằng, chúng tôi không áp dụng định hình không gian đầu ra cho tất cả các mô hình LLaMA-2.

--- TRANG 8 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
3.5.1 SO SÁNH CÁC ĐỊNH DẠNG
Để đánh giá hiệu quả của định dạng lập luận được áp dụng bởi TORA xen kẽ lập luận với chương trình, chúng tôi so sánh nó với các định dạng Chỉ lập luận và Chỉ chương trình bằng GPT-4 và LLaMA-2 được huấn luyện với cùng kích thước dữ liệu từ MATH. Như thể hiện trong Hình 4, phương pháp TORA vượt trội một cách nhất quán so với các phương pháp Chỉ lập luận và Chỉ chương trình. Đáng chú ý, sử dụng LLaMA-2, phương pháp TORA đạt được cải thiện đáng kể 29,0% và 6,7% so với Chỉ lập luận và Chỉ chương trình tương ứng. Với GPT-4 nguồn đóng, các cải thiện là 19,1% và 9,8% tương ứng. Điều này nhấn mạnh tính hiệu quả của việc tích hợp lập luận ngôn ngữ tự nhiên với chương trình.

3.5.2 TÁC ĐỘNG CỦA ĐỊNH HÌNH KHÔNG GIAN ĐẦU RA
7B 13B65707580Độ chính xác (%)68.173.5
71.174.9
72.675.8GSM8k
7B 13B35404550Độ chính xác (%)40.244.6 44.646.7
44.648.1MATHToRASampling
Correction
ToRACorrection
ToRA

Hình 5: Loại bỏ các chiến lược định hình không gian đầu ra sử dụng CodeLLaMA: (1) TORA−Sampling−Correction được huấn luyện trên TORA-CORPUS mà không có định hình. (2) TORA−Correction chỉ sử dụng chiến lược lấy mẫu để định hình, được huấn luyện với tối đa 4 mẫu quỹ đạo hợp lệ bổ sung mỗi bài toán. (3) TORA sử dụng cả lấy mẫu và sửa chữa, cũng được huấn luyện với tối đa 4 quỹ đạo bổ sung mỗi bài toán.

Chúng tôi đánh giá tính hiệu quả của các chiến lược định hình không gian đầu ra được trình bày trong Phần 2.3, cụ thể là lấy mẫu và sửa chữa. Như thể hiện trong Hình 5 và Bảng 3: (1) Định hình không gian đầu ra mang lại cải thiện đáng kể trung bình 3,4% và 4,0% tuyệt đối cho GSM8k và MATH tương ứng, với lợi ích lớn hơn cho các mô hình nhỏ hơn; (2) Áp dụng chiến lược lấy mẫu dẫn đến cải thiện tuyệt đối 2,7% trung bình, trong khi việc kết hợp thêm sửa chữa mang lại sự thúc đẩy đáng kể hơn lên đến 4,5%, mà không sử dụng thêm dữ liệu huấn luyện; (3) Định hình không gian đầu ra có lợi ngay cả cho mô hình lớn nhất TORA-70B, với cải thiện đáng chú ý từ 47,3% lên 49,7% trên MATH. Những phát hiện này làm nổi bật tính hiệu quả của các chiến lược định hình của chúng tôi trên các kích thước mô hình và tập dữ liệu khác nhau.

3.6 PHÂN TÍCH
Chúng tôi điều tra những lợi ích, mẫu chi tiết, và thách thức còn lại của tương tác công cụ cho lập luận toán học trên tập dữ liệu MATH thách thức. Phân tích hiệu suất trên tất cả các chủ đề con của MATH được báo cáo trong Bảng 3.

Lợi ích từ Tích hợp Công cụ cho các Chủ đề Con của MATH Như thể hiện trong Bảng 3, TORA vượt trội so với WizardMath khoảng 45% trong Đại số và Lý thuyết Số, điều này được quy cho việc kích thích và định hình hành vi sử dụng công cụ. Các bài toán từ hai chủ đề con thường cần tính toán phức tạp và thao tác dữ liệu. Đại số chủ yếu tập trung vào việc giải phương trình và các bài toán ứng dụng, trong khi nhiều bài toán Lý thuyết Số có thể được giải quyết bằng các phương pháp brute-force thông qua code.

Mẫu Sử dụng Thư viện cho Giải quyết Bài toán Hình 6 trình bày các thư viện được sử dụng thường xuyên nhất cho các chủ đề con khác nhau và độ chính xác tương ứng của các giải pháp của chúng. Hành vi sử dụng công cụ trên các lĩnh vực toán học khác nhau thể hiện các mẫu riêng biệt. sympy và các bộ giải nội bộ của nó được sử dụng chủ yếu cho các chủ đề liên quan đến đại số. Precalculus thể hiện các thao tác ma trận rộng rãi thông qua matrices, dẫn đến độ chính xác cao. Lý thuyết Số phụ thuộc vào các thuật toán như gcd và lcm. Hình học chủ yếu sử dụng thư viện rational cho các tính toán dựa trên phân số, trong khi việc áp dụng các công cụ khác bị hạn chế, biểu hiện tiềm năng cải thiện.

Tác động Chi tiết của Lập luận trên Các Chủ đề Khác nhau Bảng 3 cho thấy rằng việc sử dụng định dạng xen kẽ, trái ngược với việc chỉ viết chương trình, dẫn đến cải thiện đáng kể trên tất cả các chủ đề con, đặc biệt là trong Precalculus, Đại số, và Hình học, nơi các tăng trưởng đáng chú ý dao động từ 8,6% đến 18,8%.

--- TRANG 9 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Int. Alg. PreCalc Geometry Num. Th. C&P PreAlg Algebra Overall 020406080100 Tần suất (%) Tần suất Sử dụng Thư viện cho Mỗi Chủ đề
sympy
solvers
rational
calculus
matrices
binomial
algorithm
Int. Alg. PreCalc Geometry Num. Th. C&P PreAlg Algebra Overall 020406080100 Độ chính xác (%) Độ chính xác Sử dụng Thư viện cho Mỗi Chủ đề
sympy
solvers
rational
calculus
matrices
binomial
algorithm

Hình 6: Tần suất sử dụng thư viện và độ chính xác trên mỗi chủ đề con của MATH.

Phụ lục F.1 cung cấp các ví dụ đại diện chứng minh cách lập luận hỗ trợ trong lập kế hoạch, tự sửa chữa nhiều vòng, và hoàn thiện câu trả lời.

Bảng 4: Các chế độ thất bại của TORA trên MATH, và tỷ lệ phần trăm tương ứng của chúng trong các mẫu ngẫu nhiên được phân tích bởi con người. Chúng tôi bao gồm các ví dụ cụ thể của mỗi chế độ thất bại trong Phụ lục F.
Loại Lỗi Định nghĩa % Ví dụ
Lỗi Lập luận Sai lầm do các bước lập luận không chính xác hoặc thiếu điều kiện. 38% Ví dụ 5
Ảo giác Bịa đặt số hoặc câu trả lời. 5% Ví dụ 6
Hiểu Sơ đồ Hiểu sai sơ đồ đầu vào. 21% Ví dụ 7
Sử dụng Công cụ Không phù hợp Sử dụng không chính xác các công cụ bên ngoài, đặc biệt khi bài toán không thể giải quyết trực tiếp bằng thư viện. 10% Ví dụ 8
Lỗi Cú pháp Lỗi cú pháp liên tục mặc dù nhiều lần thử sửa chữa. 9% Ví dụ 9
Lỗi Runtime Lỗi trong quá trình thực thi chương trình, không được giải quyết bằng cách thử lại. 9% Ví dụ 10
Lỗi Chỉ lập luận Không thể được chính thức hóa thành một chương trình và lập luận là không chính xác. 3% Ví dụ 11
Âm tính Giả Câu trả lời đúng không khớp hoàn toàn với sự thật cơ bản. 5% Ví dụ 12

Những Thách thức Còn lại trong Lập luận Toán học cho TORA Để hiểu rõ hơn các chế độ thất bại và thách thức còn lại, chúng tôi chú thích thủ công 100 quỹ đạo được chọn ngẫu nhiên từ tập kiểm tra MATH, xác định và phân loại các chế độ thất bại của chúng. Kết quả được thể hiện trong Bảng 4: Chủ yếu, các bước lập luận không chính xác tạo thành nguồn lỗi chính cho ToRA trên các tác vụ lập luận toán phức tạp (38%), với một số vấn đề ảo giác cũng rõ ràng trong quá trình diễn giải bài toán và hoàn thiện câu trả lời (5%). Thứ hai, việc hiểu sai các sơ đồ đầu vào đóng góp đáng kể vào tỷ lệ lỗi (21%). Điều này đặc biệt đáng chú ý trong Hình học, Precalculus, và Đại số Trung cấp. Các sơ đồ trong tập dữ liệu MATH thường được mô tả chi tiết bằng văn bản sử dụng ngôn ngữ Asymptote (Hendrycks et al., 2021), do đó khiến TORA khó hiểu các sơ đồ chỉ từ các mô tả văn bản. Thứ ba, các vấn đề với việc sử dụng công cụ bao gồm Sử dụng Công cụ Không phù hợp (10%), Lỗi Cú pháp (9%), và Lỗi Runtime (9%). Những vấn đề này thường xuyên phát sinh khi TORA không thể sử dụng công cụ chính xác sau vài lần sửa chữa hoặc thử nghiệm. Có những đầu vào nhất định không được chính thức hóa tốt như các chương trình (3%), yêu cầu lập luận trừu tượng hơn là tính toán. Cuối cùng, chúng tôi cũng phát hiện rằng có những âm tính giả khi sử dụng các chỉ báo tự động, tức là các dự đoán đúng bị đánh giá sai là sai, nhưng tỷ lệ tương đối nhỏ (5%).

4 KẾT LUẬN
Bài báo này trình bày TORA, một loạt các Tác tử Lập luận Tích hợp Công cụ mới kết hợp hiệp đồng lập luận ngôn ngữ tự nhiên với việc sử dụng công cụ dựa trên chương trình để giải quyết bài toán toán học. Phương pháp của chúng tôi chứng minh tiềm năng của việc tích hợp các công cụ bên ngoài trong quá trình lập luận, cho phép các mô hình ngôn ngữ giải quyết hiệu quả các tác vụ định lượng phức tạp. TORA đạt được hiệu suất tiên tiến trên 10 tác vụ lập luận toán học đa dạng, vượt trội đáng kể so với các phương pháp dựa trên lập luận và dựa trên chương trình hiện có. Hơn nữa, phân tích hệ thống của chúng tôi về lợi ích và thách thức còn lại của tương tác công cụ cung cấp những hiểu biết có giá trị cho nghiên cứu tương lai, đóng góp vào việc phát triển các tác tử lập luận nâng cao và đa năng hơn.

--- TRANG 10 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
ĐÓNG GÓP CỦA TÁC GIẢ
Zhibin Gou đề xuất định dạng sử dụng công cụ xen kẽ của TORA và tuyển chọn tập dữ liệu TORA-CORPUS, triển khai quy trình huấn luyện và đánh giá, thực hiện thí nghiệm và phân tích trên tất cả các tập dữ liệu, triển khai các baseline, và là người đóng góp chính cho việc viết bài báo. Zhihong Shao đề xuất dự án, thực hiện các thí nghiệm sơ bộ, đề xuất và triển khai các quy trình huấn luyện và đánh giá, đề xuất và huấn luyện tất cả các mô hình TORA với định hình không gian đầu ra cũng như các biến thể TORA trong nghiên cứu loại bỏ, thiết kế và giám sát phân tích thực nghiệm, và đóng góp vào nhiều phần của việc viết bài báo. Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang, Nan Duan, và Weizhu Chen cung cấp hướng dẫn nghiên cứu, giám sát phối hợp dự án, và tư vấn và đóng góp vào nhiều phần của việc viết.

LỜI CẢM ƠN
Zhibin Gou và Yujiu Yang được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số tài trợ U1903213) và Chương trình Khoa học và Công nghệ Thâm Quyến (JSGG20220831110203007). Zhihong Shao và Minlie Huang được hỗ trợ bởi các dự án NSFC (Dự án chủ chốt số 61936010), và cũng được hỗ trợ bởi Quỹ Khoa học Quốc gia dành cho Các Nhà khoa học trẻ Xuất sắc (số 62125604).

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
TÀI LIỆU THAM KHẢO
[Danh sách các tài liệu tham khảo được giữ nguyên vì chúng là tên riêng và thuật ngữ kỹ thuật]

--- TRANG 12 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 13 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 14 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
MỤC LỤC
A Công trình Liên quan 15
B Tập dữ liệu Đánh giá 15
C Thí nghiệm và Phân tích Bổ sung 17
C.1 Độ chính xác của Các Mô hình Nguồn Đóng trên MATH . . . . . . . . . . . . . . . . . . . . 17
C.2 Tác động của # Quỹ đạo Hợp lệ cho Định hình Không gian Đầu ra . . . . . . . . . . . . . . . 17
C.3 Tác động của Định hình Không gian Đầu ra liên quan đến Độ khó Câu hỏi . . . . . . . . . . . 17
D Thông tin Chi tiết của TORA-CORPUS 18
E Gợi ý 20
F Ví dụ 22
F.1 Trường hợp Thành công . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
F.2 Trường hợp Thất bại . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

A CÔNG TRÌNH LIÊN QUAN
Lập luận Toán học Nghiên cứu gần đây đã cải thiện đáng kể khả năng lập luận trong LLM với lập luận ngôn ngữ tự nhiên từng bước (Polu & Sutskever, 2020; Wei et al., 2022; Zhou et al., 2023b; Zhu et al., 2023; Huang et al., 2022; Liang et al., 2023). Tuy nhiên, lập luận ngôn ngữ tự nhiên gặp khó khăn với các tính toán phức tạp và thao tác ký hiệu. Để vượt qua những hạn chế này, nghiên cứu gần đây đã khai thác các công cụ như máy tính (Cobbe et al., 2021; Shao et al., 2022), trình thông dịch code (Mishra et al., 2022), và bộ giải ký hiệu (Zhang et al., 2023). Các phương pháp dựa trên chương trình (Gao et al., 2022; Chen et al., 2022; Shao et al., 2023a) biến đổi các tác vụ lập luận thành các tác vụ tổng hợp chương trình, do đó cung cấp những ưu điểm bổ sung so với lập luận ngôn ngữ tự nhiên, nhưng chúng gặp thách thức trong lập luận tinh tế, lập kế hoạch, và xử lý lỗi (Gou et al., 2023), nơi lập luận ngôn ngữ tự nhiên phù hợp hơn.

Các Mô hình Ngôn ngữ Tăng cường Công cụ Việc tăng cường LLM với các công cụ có thể giảm thiểu đáng kể những hạn chế của LLM và cải thiện hiệu suất lập luận và tạo sinh (Parisi et al., 2022; Mialon et al., 2023; Yao et al., 2023). Công trình gần đây chứng minh lợi ích của việc tích hợp các trình truy xuất (Borgeaud et al., 2022; Shao et al., 2023b), công cụ tìm kiếm (Nakano et al., 2021), và các phương pháp đa công cụ (Schick et al., 2023; Paranjape et al., 2023; Gou et al., 2023) để cải thiện việc tạo sinh.

Chưng cất Kiến thức Chưng cất kiến thức (KD) chuyển giao kiến thức từ các mô hình giáo viên sang các mô hình học sinh (Bucilu ˇa et al., 2006; Hinton et al., 2015). Việc sử dụng các quỹ đạo được tạo ra bởi LLM để tinh chỉnh là một hình thức của KD (Fu et al., 2023; Taori et al., 2023; Peng et al., 2023; Ho et al., 2023). TORA đề xuất của chúng tôi cho thấy rằng việc học các quỹ đạo sử dụng công cụ tương tác là một hướng đầy hứa hẹn để điều chỉnh các mô hình ngôn ngữ cho các tác vụ lập luận.

B TẬP DỮ LIỆU ĐÁNH GIÁ
Chúng tôi trình bày thống kê và ví dụ của mười tập dữ liệu đánh giá trong Bảng 5.

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Bảng 5: Thống kê và ví dụ của 10 tập dữ liệu đánh giá. Trong bảng kết quả chính, chúng tôi trình bày độ chính xác trung bình của SingleEq, SingleOp, AddSub, và MultiArith dưới tên gọi tập thể MAWPS.
[Bảng chứa các tập dữ liệu với thông tin chi tiết và ví dụ được giữ nguyên vì chúng là tên riêng và dữ liệu kỹ thuật]

--- TRANG 17 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
[Tiếp tục nội dung về tập dữ liệu và phân tích bổ sung]

--- TRANG 18 ---
[Tiếp tục nội dung về thông tin chi tiết TORA-CORPUS]

--- TRANG 19 ---
[Tiếp tục nội dung về thông tin chi tiết TORA-CORPUS]

--- TRANG 20 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
E GỢI Ý
Chúng tôi trình bày các hướng dẫn và gợi ý few-shot ví dụ của Lập luận Tích hợp Công cụ để truy vấn GPT-4.

[Nội dung gợi ý được giữ nguyên vì đây là code và hướng dẫn kỹ thuật]

--- TRANG 21 ---
[Tiếp tục nội dung gợi ý]

--- TRANG 22 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
F VÍ DỤ
F.1 TRƯỜNG HỢP THÀNH CÔNG
[Các ví dụ code và toán học được giữ nguyên vì chúng là nội dung kỹ thuật]

--- TRANG 23 ---
[Tiếp tục các ví dụ thành công]

--- TRANG 24 ---
[Tiếp tục các ví dụ thành công]

F.2 TRƯỜNG HỢP THẤT BẠI
[Các ví dụ thất bại được giữ nguyên vì chúng là nội dung kỹ thuật]

--- TRANG 25 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 26 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 27 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 28 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 29 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 30 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 31 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 32 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 33 ---
[Tiếp tục các ví dụ thất bại]

--- TRANG 34 ---
[Kết thúc các ví dụ thất bại]

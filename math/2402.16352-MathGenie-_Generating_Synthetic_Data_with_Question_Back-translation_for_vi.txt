# MathGenie: Tạo dữ liệu tổng hợp bằng phương pháp dịch ngược câu hỏi để tăng cường khả năng lý luận toán học của các LLM

Zimu Lu∗1, Aojun Zhou∗1, Houxing Ren1, Ke Wang1, Weikang Shi1
Junting Pan1,3,Mingjie Zhan†1,Hongsheng Li†1,2,3
1Phòng thí nghiệm Đa phương tiện (MMLab), Đại học Trung văn Hồng Kông
2Phòng thí nghiệm Trí tuệ nhân tạo Thượng Hải3CPII thuộc InnoHK
luzimu@mail.ustc.edu.cn {aojunzhou, zmjdll}@gmail.com
hsli@ee.cuhk.edu.hk

## Tóm tắt

Các mô hình ngôn ngữ lớn (LLM) đã thể hiện tiềm năng lớn trong lý luận toán học. Tuy nhiên, vẫn còn khoảng cách hiệu suất trong lĩnh vực này giữa các mô hình mã nguồn mở hiện có và các mô hình mã nguồn đóng như GPT-4. Trong bài báo này, chúng tôi giới thiệu MathGenie, một phương pháp mới để tạo ra các bài toán toán học đa dạng và đáng tin cậy từ một tập dữ liệu bài toán-lời giải quy mô nhỏ (được ký hiệu là dữ liệu hạt giống). Chúng tôi mở rộng các lời giải đúng của dữ liệu hạt giống và huấn luyện một mô hình dịch ngược để dịch các lời giải được mở rộng trở lại thành các câu hỏi mới. Sau đó, chúng tôi tạo ra các lời giải tích hợp mã cho các câu hỏi mới. Để đảm bảo tính đúng đắn của các lời giải tích hợp mã, chúng tôi sử dụng chiến lược dựa trên lý luận để xác minh lời giải. Các mô hình được huấn luyện trước khác nhau, từ 7B đến 70B, được huấn luyện trên dữ liệu mới được tuyển chọn để kiểm tra hiệu quả của kỹ thuật mở rộng được đề xuất, tạo ra một họ mô hình được gọi là MathGenieLM. Các mô hình này luôn vượt trội hơn các mô hình mã nguồn mở trước đó trên năm tập dữ liệu lý luận toán học đại diện, đạt được hiệu suất tối ưu. Đặc biệt, MathGenieLM-InternLM2 đạt độ chính xác 87.7% trên GSM8K và 55.7% trên MATH, đảm bảo điểm tổng thể tốt nhất trong số các mô hình ngôn ngữ mã nguồn mở.

## 1 Giới thiệu

Các mô hình ngôn ngữ lớn (LLM), như GPT-4 (OpenAI, 2023), và các mô hình khác (Touvron et al., 2023; Yue et al., 2023; Gou et al., 2023; Wang et al., 2023), đã thể hiện khả năng xuất sắc trong lý luận toán học. Các phương pháp hiện có đã khám phá ba loại định dạng lời giải chính để giải quyết vấn đề giải toán: lời giải Chuỗi tư duy (CoT) chỉ có văn bản (Wei et al., 2022), lời giải Chương trình tư duy (PoT) chỉ có mã (Chen et al., 2022), và lời giải tích hợp mã (Zhou et al., 2023). Trong số này, lời giải tích hợp mã thể hiện hiệu suất vượt trội so với cả lời giải CoT và PoT (Gou et al., 2023; Wang et al., 2023; Zhou et al., 2023), cho thấy hiệu quả của chúng trong việc nâng cao khả năng giải quyết vấn đề.

Trong bài báo này, chúng tôi tập trung vào việc tạo ra các câu hỏi mở rộng đa dạng và đáng tin cậy và đảm bảo độ tin cậy của các lời giải tích hợp mã được tạo, từ đó tinh chỉnh tốt hơn các mô hình cơ sở được huấn luyện trước.

Các nghiên cứu hiện có, như ToRA (Gou et al., 2023) và MathCoder (Wang et al., 2023), xây dựng các lời giải tích hợp mã và mở rộng các câu hỏi toán học bằng cách sử dụng GPT-4 có sẵn. Tuy nhiên, việc mở rộng quy mô dữ liệu huấn luyện với GPT-4 trở nên cực kỳ tốn kém.

Do đó, phát triển một mô hình mã nguồn mở miễn phí để tạo ra dữ liệu tổng hợp quy mô lớn đưa ra một giải pháp thay thế đầy hứa hẹn, cung cấp khả năng mở rộng và hiệu quả chi phí (Yuan et al., 2023; Singh et al., 2023). Để mở rộng hiệu quả dữ liệu giải quyết bài toán toán học, chúng tôi tập trung vào việc xử lý hai thách thức quan trọng: (1) làm thế nào để tạo ra các bài toán toán học chất lượng cao và đa dạng để hỗ trợ khái quát hóa, và (2) làm thế nào để tạo ra các lời giải chính xác và đáng tin cậy cho các bài toán được mở rộng mà không có sự thật cơ bản được chú thích bởi con người, tốt nhất là ở định dạng tích hợp mã. Một khung thống nhất, MathGenie, được đề xuất, bao gồm ba thành phần như được hiển thị trong Hình 1 để giải quyết các thách thức nêu trên: Mở rộng lời giải lặp lại, Dịch ngược câu hỏi và Lọc lời giải dựa trên xác minh.

Mở rộng lời giải lặp lại và Dịch ngược câu hỏi nhằm tạo ra các bài toán toán học đa dạng và đáng tin cậy. Khác với việc mở rộng câu hỏi trực tiếp (Yu et al., 2023), phương pháp dịch ngược bài toán toán học được đề xuất tận dụng các ràng buộc và mối quan hệ logic vốn có trong các lời giải toán học để tạo ra một tập hợp các bài toán toán học mới đa dạng và chất lượng cao. Cụ thể, chúng tôi lặp lại việc mở rộng các lời giải được chú thích bởi con người từ các tập huấn luyện tương đối nhỏ của MATH (Hendrycks et al., 2021) và GSM8K (Cobbe et al., 2021), tạo ra một bộ sưu tập quy mô lớn các lời giải mới được mở rộng, như được hiển thị trong Bước 1 của Hình 1.

Những lời giải này sau đó được xử lý bởi một mô hình dịch ngược toán học, Mbacktrans, để dịch ngược các lời giải được mở rộng thành các câu hỏi toán học tương ứng của chúng, như được thể hiện trong Bước 2 của Hình 1. Phương pháp này lấy cảm hứng từ Dịch ngược hướng dẫn (Li et al., 2023b), dịch ngược các hướng dẫn từ các văn bản trong kho văn bản web. Tuy nhiên, sự khác biệt chính là các lời giải nguồn của chúng tôi để dịch ngược được mở rộng từ những lời giải hiện có để đảm bảo độ tin cậy và khả năng giải được của các câu hỏi được mở rộng.

Những bài toán toán học mới được tạo ra này thiếu các lời giải sự thật cơ bản đáng tin cậy, điều này đòi hỏi phải có Lọc lời giải dựa trên xác minh được đề xuất. Chúng tôi đầu tiên xây dựng một mô hình, Mcode, có khả năng tạo ra các lời giải tích hợp mã và xác minh những lời giải này. Sau đó, các lời giải tích hợp mã của các câu hỏi mới được tạo ra với mô hình này. Để nâng cao độ tin cậy của các lời giải tích hợp mã này, chúng tôi sử dụng Mcode để xác minh các lời giải do mô hình tạo ra bằng cách tạo ra các lý luận xác minh cho chúng, như được thể hiện trong Bước 3 của Hình 1. Các lý luận xác minh sử dụng ngôn ngữ tự nhiên và mã xen kẽ để xác minh tính đúng đắn của các lời giải, như được hiển thị trong Bảng 13 và Bảng 14 trong Phụ lục G. Chỉ những lời giải được xác minh là đúng mới được giữ lại, do đó cải thiện độ chính xác và chất lượng của dữ liệu được tạo.

Dựa trên khung MathGenie được đề xuất, chúng tôi thu được một tập dữ liệu bài toán-lời giải toán học quy mô lớn do mô hình tạo ra, MathGenieData, có các câu hỏi được mở rộng đa dạng và các lời giải tích hợp mã đáng tin cậy.

Để đánh giá hiệu quả của khung mở rộng câu hỏi-lời giải MathGenie, chúng tôi tinh chỉnh các mô hình được huấn luyện trước tối ưu khác nhau, từ 7B đến 70B. Điều này dẫn đến MathGenieLM, một họ mô hình toán học mới với hiệu suất xuất sắc. Các mô hình của chúng tôi thể hiện độ chính xác cao trên năm tập dữ liệu toán học đa dạng và đại diện: MATH, GSM8K, SVAMP, Simuleq, và Mathematics. Đặc biệt, MathGenieLM-InternLM2 đạt độ chính xác 87.7% trên GSM8K và 55.7% trên MATH, đạt điểm tổng thể tốt nhất. Khi được tăng cường bằng bỏ phiếu đa số, MathGenieLM-Llama-2-70B đạt tỷ lệ chính xác 10 đường dẫn là 91.7% trên GSM8K và 63.3% trên MATH.

Các đóng góp chính của bài báo này được tóm tắt như sau: (1) Chúng tôi đề xuất quy trình MathGenie, được thiết kế để nâng cao quy mô, sự đa dạng và chất lượng của các câu hỏi toán học tổng hợp, cũng như cải thiện độ chính xác của các lời giải tích hợp mã được tạo cho chúng. (2) Chúng tôi tiến hành các thí nghiệm rộng rãi trên các mô hình ngôn ngữ được huấn luyện trước khác nhau, thể hiện hiệu suất vượt trội nhất quán trên nhiều tập dữ liệu toán học.

## 2 MathGenie

Trong phần này, chúng tôi giới thiệu MathGenie, một quy trình để tạo ra các bài toán toán học đa dạng và đáng tin cậy thông qua dịch ngược, và tuyển chọn các lời giải tích hợp mã chất lượng cao thông qua xác minh. Chúng tôi bắt đầu bằng việc giới thiệu dữ liệu hạt giống và mô hình tạo lời giải. Tiếp theo, chúng tôi trình bày quy trình MathGenie được đề xuất, bao gồm ba bước chính, như được hiển thị trong Hình 1: Mở rộng lời giải lặp lại, Dịch ngược câu hỏi, và Lọc lời giải dựa trên xác minh.

**Dữ liệu hạt giống.** Dữ liệu hạt giống bao gồm hai phần: (1) Phần đầu tiên được sử dụng để mở rộng dữ liệu, bao gồm 15K bài toán toán học và các lời giải được chú thích bởi con người từ các tập huấn luyện của GSM8K và MATH. Chúng tôi ký hiệu nó là Dtext = {(qi, si)}n i=1, trong đó qi là câu hỏi thứ i, si là lời giải ngôn ngữ tự nhiên của nó, và n là tổng số trường hợp. (2) Phần thứ hai được sử dụng để huấn luyện mô hình tạo lời giải ứng viên của chúng tôi, phục vụ để tạo ra các lời giải ứng viên cho các câu hỏi được mở rộng. Chúng tôi ký hiệu phần này của dữ liệu hạt giống là Dcode = {(qi, si code, vi code)}N i=1, trong đó qi là câu hỏi, si code là lời giải tích hợp mã của nó, và vi code là các lý luận xác minh tích hợp mã cho cặp câu hỏi-lời giải. Nó chứa 80K mẫu lời giải tích hợp mã cho các bài toán trong GSM8K và MATH, cũng như các lý luận xác minh tích hợp mã cho những lời giải này. Nhiều lời giải khác nhau được thu thập cho mỗi câu hỏi. Chúng tôi thu được những lời giải và lý luận xác minh này bằng cách sử dụng Trình thông dịch mã GPT-4, bao gồm ngôn ngữ tự nhiên và mã xen kẽ.

**Bộ tạo lời giải ứng viên.** Bộ tạo lời giải ứng viên là một mô hình Llama-2 70B được huấn luyện với Dcode và được ký hiệu là Mcode. Các lời giải tích hợp mã trong Dcode cho phép Mcode xuất ra các lời giải tích hợp mã ứng viên cho các bài toán toán học được cho, tương tự như (Wang et al., 2023). Nó có độ chính xác 86.4% trên GSM8K và 49.5% trên MATH. Các lý luận xác minh trong Dcode cho phép Mcode xác minh hiệu quả các lời giải với các lý luận tích hợp mã. Phương pháp huấn luyện dữ liệu ở định dạng tích hợp mã được mô tả như trong Wang et al. (2023).

**Mở rộng lời giải lặp lại.** Khác với các nghiên cứu trước đây trực tiếp mở rộng các câu hỏi toán học (Luo et al., 2023), chúng tôi đề xuất mở rộng các lời giải trước rồi sau đó dịch ngược các lời giải được mở rộng thành các câu hỏi tương ứng của chúng để ràng buộc tốt hơn quá trình tạo câu hỏi và nâng cao độ tin cậy của các câu hỏi do máy tạo ra. Chiến lược được đề xuất cũng khác với phương pháp Dịch ngược hướng dẫn trước đây (Li et al., 2023b), tận dụng một lượng lớn văn bản trong kho văn bản web. Vì các lời giải hiện có có số lượng hạn chế và đã có các câu hỏi tương ứng, cần thiết phải mở rộng chúng trước khi dịch ngược.

Để mở rộng các lời giải trong Dtext thành những lời giải mới liên quan, chúng tôi phát triển một mô hình mở rộng lời giải, Mtext, bằng cách tinh chỉnh mô hình LLaMA-2 70B trên các tập dữ liệu hướng dẫn chất lượng cao, bao gồm OpenOrca1 và Alpaca-GPT42. Mtext nhận vào một lời giải và một lời nhắc hướng dẫn mô hình mở rộng nó, và xuất ra một lời giải được mở rộng. Các lời nhắc được hiển thị trong Bảng 1. Các mở rộng được ràng buộc cẩn thận và đáng tin cậy. Chúng tôi lặp lại việc mở rộng mỗi lời giải trong Dtext. Để thuận tiện, tập hợp các lời giải được chú thích bởi con người trong Dtext được ký hiệu là S0. Các lời giải trong S0 được mở rộng bởi Mtext để tạo ra S1. Như được hiển thị trong Bước 1 của Hình 1, quá trình này được lặp lại trên các lời giải được tạo trước đó, với S2 được tạo ra từ S1, và cứ thế. Sau K vòng, tập hợp cuối cùng các lời giải được mở rộng, được ký hiệu là SAug, được tạo ra bằng cách lấy hợp của S1, S2, . . . , SK:

SAug = S1 ∪ S2 ∪ ··· ∪ SK. (1)

Thông qua mở rộng lời giải lặp lại, mỗi vòng tạo ra một tập hợp các lời giải khác với vòng trước, làm cho các lời giải dần dần lệch xa hơn khỏi các lời giải ban đầu. Do đó, sự đa dạng của các lời giải được mở rộng được đảm bảo, dẫn đến các cặp câu hỏi-lời giải được mở rộng đa dạng như đã đề cập trong các phần sau. Quá trình lặp lại có lợi cho hiệu suất cuối cùng, như được chứng minh trong Bảng 9 của Phụ lục B.

**Dịch ngược câu hỏi.** Chúng tôi giới thiệu Dịch ngược câu hỏi để dịch các lời giải trong SAug trở lại thành các bài toán toán học tương ứng của chúng. Để nâng cao độ chính xác của việc dịch, chúng tôi xây dựng một Mô hình dịch ngược câu hỏi Mbacktrans bằng cách tinh chỉnh Llama-2 70B trên các cặp câu hỏi và lời giải đảo ngược trong Dtext. Định dạng của mỗi mẫu trong dữ liệu tinh chỉnh có thể được ký hiệu là (s, q), trong đó s là một lời giải, phục vụ như đầu vào, và q là câu hỏi tương ứng của nó. Sau đó, chúng tôi trình bày các lời giải trong SAug cho Mbacktrans, từ đó dịch chúng trở lại thành một tập hợp các câu hỏi mới, được ký hiệu là QAug. Một ví dụ về Dịch ngược câu hỏi được trình bày trong Bảng 2.

Dịch ngược câu hỏi hoạt động trên SAug, ít không thể đoán trước hơn các văn bản từ kho văn bản web được sử dụng trong Dịch ngược hướng dẫn (Li et al., 2023b). Bằng cách tận dụng các ràng buộc được hiển thị trong các lời giải, có thể tạo ra các câu hỏi mới đáng tin cậy hơn những gì mở rộng câu hỏi trực tiếp có thể tạo ra, như được xác nhận trong các thí nghiệm.

**Lọc lời giải dựa trên xác minh.** Các mô hình mã nguồn mở hiện có như MathCoder (Wang et al., 2023) chỉ có khả năng giải các bài toán toán học nhưng không thể xác minh hiệu quả các lời giải của chúng. Chúng tôi nâng cao khả năng xác minh lời giải của Mcode bằng cách thêm các lý luận xác minh tích hợp mã vào dữ liệu tinh chỉnh. Các mẫu huấn luyện lý luận xác minh trong dữ liệu hạt giống có định dạng (q, scode, vcode), trong đó q và scode là một cặp câu hỏi và lời giải tích hợp mã, và vcode là xác minh tích hợp mã. Các cặp (q, scode) là đầu vào, trong khi mô hình được huấn luyện để xuất ra vcode. Theo cách này, mô hình giải quyết bài toán toán học cơ sở Mcode có được khả năng xác minh các lời giải của nó với các lý luận được tạo từ ngôn ngữ tự nhiên và mã xen kẽ. Khả năng này không chỉ tạo điều kiện thuận lợi cho Lọc lời giải dựa trên xác minh, mà còn có thể đóng vai trò trong việc nâng cao độ chính xác suy luận.

Để thực hiện Lọc lời giải dựa trên xác minh được đề xuất, chúng tôi đầu tiên tạo ra các lời giải tích hợp mã cho mỗi câu hỏi trong QAug. Lọc ban đầu được thực hiện bằng cách sử dụng tính nhất quán của câu trả lời (Wang et al., 2022), loại bỏ một câu hỏi nếu các lời giải của nó đạt được các câu trả lời khác nhau. Sau đó chúng tôi trình bày mỗi cặp câu hỏi-lời giải cho Mcode, nhắc nó xuất ra một lý luận xác minh tích hợp mã, từ đó chúng tôi có thể xác định xem lời giải có được xác minh là đúng hay sai. Các ví dụ về quá trình xác minh được hiển thị trong Phụ lục G. Các lời giải ứng viên được xác minh là sai sẽ bị loại bỏ. Quá trình này được thể hiện trong Bước 3 của Hình 1.

Quy trình được đề xuất ở trên tạo ra 170K mẫu cặp câu hỏi và lời giải tích hợp mã, được ký hiệu là AugData. AugData bao gồm hai phần: 110K mẫu được mở rộng từ tập dữ liệu GSM8K, được ký hiệu là AugGSM8K, và 60K mẫu được mở rộng từ tập dữ liệu MATH, được ký hiệu là AugMATH. Chúng tôi ký hiệu dữ liệu hạt giống nêu trên để huấn luyện Mcode là SeedData. Kết hợp SeedData và AugData, chúng tôi trình bày tập dữ liệu cuối cùng, MathGenieData, có thể được sử dụng để tinh chỉnh các mô hình được huấn luyện trước khác nhau, như Llama-2 (Touvron et al., 2023) và CodeLlama (Roziere et al., 2023), nâng cao khả năng giải quyết vấn đề và kỹ năng xác minh lời giải của chúng. Họ mô hình lý luận toán học kết quả được đặt tên là MathGenieLM.

## 3 Thí nghiệm

### 3.1 Thiết lập thí nghiệm

**Tập dữ liệu.** Chúng tôi đánh giá các mô hình của mình trên hai tập dữ liệu trong miền: GSM8K (Cobbe et al., 2021) và MATH (Hendrycks et al., 2021), có các tập huấn luyện được sử dụng để tinh chỉnh. Ngoài ra, chúng tôi đánh giá các mô hình cuối cùng trên ba tập dữ liệu ngoài miền: SVAMP (Patel et al., 2021), Simuleq (Koncel-Kedziorski et al., 2016), và Mathematics (Davies et al., 2021), để đánh giá khả năng khái quát hóa của phương pháp được đề xuất.

**Mô hình.** Chúng tôi thực hiện tinh chỉnh tham số đầy đủ trên các mô hình được huấn luyện trước khác nhau, bao gồm Llama-2 7B, 13B, và 70B (Touvron et al., 2023), CodeLlama 7B, 13B, và 34B (Roziere et al., 2023), Llemma 7B và 34B (Azerbayev et al., 2023), Mistral 7B (Jiang et al., 2023), Mixtral-8x7B (Jiang et al., 2024), và InternLM2 20B (Team, 2023). Chi tiết tinh chỉnh được mô tả trong Phụ lục E.

**Phương pháp so sánh.** Chúng tôi so sánh MathGenieLM với các mô hình mã nguồn đóng như ChatGPT-3.5 (Brown et al., 2020), GPT-4 (OpenAI, 2023), và PaLM-2 (Anil et al., 2023), cũng như các mô hình mã nguồn mở như Mammoth (Yue et al., 2023), MathCoder (Wang et al., 2023), ToRA (Gou et al., 2023), và WizardMath (Luo et al., 2023).

### 3.2 Kết quả chính

Bảng 3 hiển thị độ chính xác của MathGenieLM trên năm tập dữ liệu. Dựa trên kết quả, chúng tôi đưa ra các quan sát sau: (1) Đối với các mô hình mã nguồn mở có tham số từ 7B đến 70B, MathGenieLM đạt được hiệu suất tối ưu. (2) MathGenieLM thể hiện hiệu suất đặc biệt cao trên ba tập dữ liệu ngoài miền so với các mô hình mã nguồn mở trước đây, thể hiện khả năng khái quát hóa vượt trội của phương pháp chúng tôi. (3) Độ chính xác của MathGenieLM vượt qua ChatGPT-3.5 và PaLM-2. Tuy nhiên, vẫn còn một khoảng cách đáng chú ý khi so sánh với hiệu suất của GPT-4. (4) MathGenieLM-Llemma-34B và MathGenieLM-InternLM2-20B đạt trên 55% độ chính xác trên tập dữ liệu MATH thách thức. Điều này có thể được quy cho dữ liệu liên quan đến toán học chất lượng cao mà chúng đã sử dụng trong quá trình huấn luyện trước. (5) Mixtral-8x7B đạt được hiệu suất xuất sắc, thể hiện tiềm năng của các mô hình Hỗn hợp chuyên gia (MoE). Kết quả trong Bảng 3 đều được thu được bằng cách sử dụng giải mã tham lam.

Ngoài kết quả thu được với giải mã tham lam, chúng tôi cũng báo cáo kết quả bỏ phiếu đa số sử dụng nhiều đường dẫn được lấy mẫu (Wang et al., 2022), được tiến hành trên MathGenieLM-Llama-2-70B, so sánh với ToRA-Llama-2-70B. Kết quả được hiển thị trong Bảng 4, trong đó "k" đại diện cho số lượng lời giải được tạo ra để bỏ phiếu đa số. Chúng tôi quan sát thấy rằng, với k = 10, bỏ phiếu đa số tăng đáng kể độ chính xác trên tất cả năm tập dữ liệu, mang lại mức tăng trung bình 7.9%. Cụ thể, tại k = 10, MathGenieLM-Llama-2-70B đạt độ chính xác 91.5% trên GSM8K và 63.3% trên MATH, vượt trội đáng kể so với ToRA-70B tại k = 50. Điều này thể hiện hiệu suất vượt trội của mô hình chúng tôi.

### 3.3 Nghiên cứu loại bỏ

Sau đây là một số nghiên cứu loại bỏ. Tất cả tinh chỉnh trong các nghiên cứu loại bỏ đã được tiến hành sử dụng Mistral-7B làm mô hình cơ sở.

**Phân tích thành phần dữ liệu khác nhau.** Chúng tôi phân tích hiệu ứng của việc thêm và trừ các phần khác nhau của dữ liệu huấn luyện để quan sát tác động của mỗi thành phần. Như được hiển thị trong nửa trên của Bảng 5, khi chỉ thêm AugGSM8K, hiệu suất trên GSM8K, SVAMP, và Simuleq được cải thiện, trong khi việc thêm AugMATH dẫn đến những cải thiện đáng chú ý hơn trong MATH và Mathematics. Điều này phù hợp với các loại câu hỏi trong mỗi tập dữ liệu: GSM8K, SVAMP, và Simuleq chứa các bài toán từ ở cấp độ tiểu học với các phép tính tương đối dễ, trong khi MATH và Mathematics có các phép tính toán học phức tạp hơn. Khi cả AugGSM8K và AugMATH đều được thêm vào, những cải thiện trong các tập dữ liệu cũng được kết hợp, điều này cho thấy hiệu quả của dữ liệu được mở rộng của chúng tôi.

**Phân tích các lượng dữ liệu được mở rộng khác nhau.** Chúng tôi phân tích chất lượng mở rộng của dữ liệu được mở rộng mà chúng tôi đã tạo ra bằng cách huấn luyện một mô hình với {0, 1/8, 1/4, 1/2, 1} lần lượng dữ liệu được mở rộng. Kết quả, như được hiển thị trong nửa dưới của Bảng 5 và Hình 3, cho thấy rằng, với sự gia tăng lượng dữ liệu được mở rộng, hiệu suất trên tất cả năm tập dữ liệu đều cải thiện một cách nhất quán, với rất ít ngoại lệ. Điều này thể hiện chất lượng mở rộng cao của dữ liệu chúng tôi.

**Phân tích Lọc lời giải dựa trên xác minh.** Chúng tôi phân tích hiệu quả của Lọc lời giải dựa trên xác minh bằng cách sử dụng dữ liệu trước và sau khi lọc với sự giúp đỡ của xác minh để tinh chỉnh mô hình. Như được thể hiện trong Bảng 6, việc tinh chỉnh mô hình với các cặp câu hỏi-lời giải được mở rộng được lọc bằng xác minh dẫn đến những tăng độ chính xác đáng chú ý trong cả GSM8K và MATH, cho thấy chất lượng vượt trội của dữ liệu được mở rộng sau khi lọc và hiệu quả của Lọc lời giải dựa trên xác minh. Phân tích thêm về khả năng xác minh của Mcode được hiển thị trong Bảng 11 của Phụ lục D.

**So sánh với các phương pháp mở rộng câu hỏi khác.** Chúng tôi so sánh phương pháp của mình với ba phương pháp mở rộng câu hỏi khác: MetaMath (Yu et al., 2023), mở rộng câu hỏi trực tiếp không có lời giải, và mở rộng câu hỏi trực tiếp có lời giải. Hai phương pháp mở rộng câu hỏi trực tiếp đều sử dụng Mtext làm mô hình mở rộng câu hỏi. Phương pháp trước chỉ trình bày câu hỏi hạt giống cho mô hình trong quá trình mở rộng câu hỏi, trong khi phương pháp sau trình bày cả câu hỏi và lời giải của nó. Kết quả, như được hiển thị trong Bảng 7, cho thấy rằng phương pháp dịch ngược từ lời giải được mở rộng thành câu hỏi của chúng tôi mang lại hiệu suất tốt hơn các phương pháp mở rộng hiện có.

### 3.4 Độ chính xác của suy luận được xác minh

Các mô hình của chúng tôi có khả năng xác minh các lời giải của chính mình khi được trình bày với các lời nhắc như được hiển thị trong Bảng 10. Điều này đại diện cho một khả năng lý luận toán học có thể được áp dụng trong quá trình suy luận.

Một cách đơn giản để làm điều này là xác minh các lời giải được tạo ra và giải quyết bài toán lại nếu lời giải được xác minh là không chính xác. Chúng tôi giới hạn số lần xác minh thành hai lần. Như được hiển thị trong Bảng 8, việc áp dụng xác minh hai lần nhất quán nâng cao độ chính xác trên tất cả năm tập dữ liệu, với những cải thiện đáng chú ý trong các tập dữ liệu MATH và Mathematics. Tạo trung bình (N ×) được trình bày trong Bảng 8 đo lường chi phí của suy luận được xác minh, trung bình là 2.3 ×. Khi so sánh với bỏ phiếu đa số 3 đường dẫn, suy luận được xác minh đạt được độ chính xác gần như giống hệt nhau nhưng với chi phí giảm đáng kể. Kết quả của nhiều vòng xác minh hơn được phân tích trong Bảng 12 của Phụ lục F.

## 4 Các nghiên cứu liên quan

**Các mô hình ngôn ngữ lớn cho lý luận toán học.** LLM đã thể hiện hiệu suất đáng chú ý trong các nhiệm vụ lý luận toán học. CoT (Wei et al., 2022) nâng cao khả năng lý luận nhiều bước của LLM. Self-Consistency (Wang et al., 2022) chọn câu trả lời cuối cùng thông qua bỏ phiếu đa số. CSV (Zhou et al., 2023) giới thiệu tự xác minh dựa trên mã. Các nỗ lực nghiên cứu khác tập trung vào huấn luyện trước hoặc tinh chỉnh LLM, từ đó tạo ra các LLM cụ thể cho toán học, như Llemma (Azerbayev et al., 2023), WizardMath (Luo et al., 2023), Mammoth (Yue et al., 2023), ToRA (Gou et al., 2023), và MathCoder (Wang et al., 2023). Cần lưu ý rằng các mô hình tích hợp mã (Wang et al., 2023; Gou et al., 2023) đã thể hiện khả năng vượt trội so với các mô hình kiểu CoT. Bài báo này phát triển các bài toán và lời giải toán học tổng hợp sử dụng các mô hình miễn phí để nâng cao lý luận toán học.

**Tập dữ liệu tuân theo hướng dẫn cho LLM.** Các nghiên cứu gần đây (Taori et al., 2023; Peng et al., 2023; Mukherjee et al., 2023; Li et al., 2023b) đã bắt đầu sử dụng các hướng dẫn tổng hợp được tạo bởi LLM, như GPT-4 hoặc GPT-3.5, để chưng cất vào các mô hình nhỏ hơn. WizardLM (Xu et al., 2023) đề xuất các hướng dẫn phức tạp để làm phong phú dữ liệu hạt giống cho các mô hình trò chuyện chung. Tuy nhiên, bài báo này tập trung vào mở rộng bài toán toán học, đặc biệt cho các mô hình cụ thể cho toán học tích hợp mã.

**Mở rộng dữ liệu cho lý luận toán học.** Để tăng số lượng bài toán toán học, các nghiên cứu khác nhau (Yu et al., 2023; Liu and Yao, 2024; Li et al., 2023a) trực tiếp mở rộng các bài toán hiện có. Khác với những cách tiếp cận này, phương pháp của chúng tôi sử dụng thông tin trong các lời giải thông qua dịch ngược câu hỏi toán học, từ đó nâng cao độ tin cậy của các câu hỏi được mở rộng. Chúng tôi cũng tạo ra các lời giải tích hợp mã cho các câu hỏi và sử dụng các lý luận xác minh để lọc các lời giải.

## 5 Kết luận

Trong bài báo này, chúng tôi đề xuất một quy trình phối hợp bao gồm Mở rộng lời giải lặp lại và Dịch ngược câu hỏi để tạo ra các câu hỏi toán học tổng hợp quy mô lớn, và Lọc lời giải dựa trên xác minh để lọc các lời giải tích hợp mã được tạo ra. Kết hợp, ba thành phần này hiệu quả tạo ra các câu hỏi mới và đảm bảo độ tin cậy của các lời giải tích hợp mã tương ứng. Các thí nghiệm cho thấy rằng MathGenieLM đạt được hiệu suất vượt trội trên năm tiêu chuẩn giải quyết bài toán toán học và trên sáu mô hình cơ sở được huấn luyện trước khác nhau, cung cấp những hiểu biết sâu sắc về việc phát triển các mô hình giải quyết bài toán toán học và mang lại hy vọng cho việc mở rộng sang các nhiệm vụ lý luận khác.

## Hạn chế

Phương pháp của chúng tôi đòi hỏi tài nguyên GPU đáng kể, bao gồm việc tinh chỉnh tham số đầy đủ của các mô hình ngôn ngữ lớn với tới 70B tham số. Do đó, điều quan trọng cho các nghiên cứu tương lai là khám phá các cách để giảm tài nguyên cần thiết. Một hạn chế khác là các mô hình của chúng tôi không thể xử lý hình ảnh làm đầu vào, và do đó thiếu khả năng giải quyết các bài toán liên quan đến hình ảnh, như đã thảo luận trong (Lu et al., 2023). Ngoài ra, các mô hình của chúng tôi bị ràng buộc bởi độ dài ngữ cảnh hạn chế, đã được tinh chỉnh với độ dài ngữ cảnh 4096. Những hạn chế này rất quan trọng và đáng được điều tra thêm.

## Tuyên bố đạo đức

Công trình của chúng tôi, bằng cách nâng cao khả năng toán học của các mô hình ngôn ngữ, có thể đóng góp vào việc giáo dục toán học. Tuy nhiên, các mô hình của chúng tôi có thể xuất ra những ảo giác không đúng sự thật, giống như bất kỳ mô hình ngôn ngữ nào. Chúng tôi đã sử dụng các mô hình mã nguồn mở khác nhau như LLaMA-2, CodeLLaMA, Mistral, và Mixtral-8x7B, cũng như phần mềm mã nguồn mở như Hugging Face và PyTorch. Chúng tôi tuân thủ các chính sách và giấy phép của những tài nguyên này và ghi nhận vai trò chúng đã đóng trong công việc của chúng tôi.

## Lời cảm ơn

Dự án này được tài trợ một phần bởi Chương trình R&D Chủ chốt Quốc gia Trung Quốc Dự án 2022ZD0161100, bởi Trung tâm Trí tuệ Tri giác và Tương tác (CPII) Ltd thuộc Ủy ban Đổi mới và Công nghệ (ITC) InnoHK, bởi Quỹ Nghiên cứu Chung của Hồng Kông RGC Dự án 14204021. Hongsheng Li là PI của CPII thuộc InnoHK.

## Tài liệu tham khảo

[Danh sách tài liệu tham khảo giữ nguyên định dạng gốc]

## A Ví dụ về Mở rộng lời giải lặp lại và Dịch ngược câu hỏi

Hình 4 (b) hiển thị một ví dụ về ba vòng Mở rộng lời giải lặp lại và Dịch ngược câu hỏi. Lời giải hạt giống được mở rộng lặp lại, và các lời giải được mở rộng được dịch ngược thành các câu hỏi mới. So với Hình 4 (a), nơi mở rộng được tiến hành trực tiếp trên câu hỏi, Dịch ngược lời giải lặp lại thể hiện sự đa dạng lớn hơn trong cách diễn đạt câu hỏi, vì câu hỏi ban đầu không được cung cấp trực tiếp cho mô hình.

## B Phân tích Mở rộng lời giải lặp lại

Để thể hiện hiệu quả tác động của lặp lại trong việc nâng cao chất lượng lời giải, chúng tôi đã tạo ra một số lượng bằng nhau các lời giải được mở rộng mà không sử dụng lặp lại, bằng cách trực tiếp mở rộng các lời giải mới từ tập hợp ban đầu. Như được minh họa trong Bảng 9, kết quả của thí nghiệm được tiến hành mà không có lặp lại trong mở rộng lời giải thấp kém đáng kể so với những kết quả có lặp lại. Điều này nhấn mạnh vai trò có lợi của lặp lại trong mở rộng lời giải, chủ yếu được quy cho khả năng nâng cao sự đa dạng của các lời giải.

## C Lời nhắc xác minh

Bảng 10 trình bày định dạng lời nhắc được sử dụng trong tinh chỉnh và tạo ra các lý luận xác minh tích hợp mã.

## D Phân tích xác minh tích hợp mã

Để hiểu lý do đằng sau chất lượng cải thiện của dữ liệu, chúng tôi định lượng khả năng của Mcode để tiến hành xác minh tích hợp mã bằng cách kiểm tra nó trên các lời giải được tạo ra bởi Mcode trên năm tập dữ liệu kiểm tra. Chúng tôi sử dụng các tập dữ liệu kiểm tra này vì chúng chứa sự thật cơ bản, cho phép chúng tôi đánh giá tính đúng đắn thực tế của các lời giải. Chúng tôi định nghĩa hai chỉ số dưới đây để thể hiện khả năng xác minh lời giải của Mcode: Độ chính xác và Độ nhạy.

Độ chính xác = TP / (TP + FP)
Độ nhạy = TP / (TP + TN)

TP đại diện cho các trường hợp mà xác minh chứng minh lời giải đúng và câu trả lời của lời giải thực sự đúng. FP đại diện cho các trường hợp mà xác minh chứng minh lời giải đúng, nhưng câu trả lời của lời giải thực sự sai. TN đại diện cho các trường hợp mà xác minh chứng minh lời giải sai, nhưng câu trả lời của lời giải thực sự đúng. Nói ngắn gọn, Độ chính xác trả lời câu hỏi, "Tỷ lệ nào của các câu trả lời được xác minh ĐÚNG thực sự chính xác?", trong khi Độ nhạy trả lời câu hỏi, "Tỷ lệ nào của các câu trả lời đúng thực tế được xác minh ĐÚNG?". Với những định nghĩa này, Độ chính xác phản ánh độ tin cậy của các lời giải tích hợp mã được giữ lại, trong khi Độ nhạy phản ánh hiệu quả của bước lọc.

Bảng 11 cho thấy rằng Độ chính xác cao hơn đáng kể so với Độ chính xác trên tất cả các tập dữ liệu, nhấn mạnh hiệu quả và khả năng khái quát hóa của xác minh tích hợp mã.

## E Chi tiết tinh chỉnh

Trong công việc này, chúng tôi tinh chỉnh tất cả các mô hình bằng thư viện HuggingFace. Chúng tôi sử dụng bộ lập lịch trọng số cosin với tốc độ học 2e−5, chỉ định 50 bước đầu tiên làm các bước khởi động. Tất cả các mô hình được tối ưu hóa bằng AdamW (Loshchilov và Hutter, 2017) với kích thước lô 64. Các mô hình 70B và 34B được tinh chỉnh trên 32 GPU NVIDIA A800 80GB. Mistral-8x7B được tinh chỉnh trên 16 GPU NVIDIA A800 80GB, trong khi các mô hình 7B, 13B và 20B đều được tinh chỉnh trên 8 GPU NVIDIA A800 80GB.

## F Phân tích các vòng xác minh trong suy luận được xác minh

Trong suy luận được xác minh, chúng tôi xác minh các lời giải của các câu hỏi kiểm tra và chỉ giải lại những câu hỏi có lời giải được xác minh là không chính xác. Do đó, số lượng câu hỏi cần giải giảm với mỗi vòng. Về lý thuyết, quá trình này có thể tiếp tục cho đến khi tất cả các câu hỏi có lời giải được xác minh là đúng. Tuy nhiên, trong thực tế, việc xác minh quá nhiều vòng có thể dẫn đến chi phí bổ sung mà không có bất kỳ cải thiện nào về độ chính xác, vì một số câu hỏi có thể vượt quá khả năng giải quyết vấn đề và xác minh của mô hình. Để xác định sự cân bằng giữa chi phí và độ chính xác, chúng tôi đã tăng số vòng xác minh lên 9. Kết quả được hiển thị trong Bảng 12. Như có thể thấy, sự gia tăng độ chính xác trung bình trở nên nhỏ sau 2 vòng xác minh.

## G Ví dụ về lý luận xác minh tích hợp mã

Hai ví dụ về lý luận xác minh tích hợp mã được trình bày trong Bảng 13 và Bảng 14. Trong Bảng 13, lời giải được xác minh là đúng bằng cách sử dụng câu trả lời để tính toán điều kiện và so sánh nó với điều kiện thực tế. Trong Bảng 14, lời giải được xác minh là không chính xác bằng cách giải quyết câu hỏi thông qua một phương pháp thay thế và so sánh các câu trả lời.

[Các bảng và hình vẽ giữ nguyên định dạng và nội dung như bản gốc]

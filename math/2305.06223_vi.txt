# 2305.06223.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2305.06223.pdf
# Kích thước tệp: 265519 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
ComputeGPT: Một mô hình chat tính toán cho
các bài toán số học
Ryan Hardesty Lewis1, Junfeng Jiao2
1The University of Texas at Austin, rhl@utexas.edu
2The University of Texas at Austin, jjiao@austin.utexas.edu
Tóm tắt
Các mô hình ngôn ngữ không chính xác trong các bài toán số học. Kiến trúc của chúng
không cho phép bất cứ điều gì ít hơn một từ tiếp theo theo xác suất. Bài báo này giới
thiệu ComputeGPT: một phương pháp tạo ra một mô hình chat có thể trả lời các bài
toán tính toán thông qua việc chạy mã theo yêu cầu. ComputeGPT chuyển đổi mỗi
câu hỏi thành mã liên quan, chạy mã và trả về câu trả lời đã tính toán như một phần
của cuộc trò chuyện. Chúng tôi kết hợp phương pháp này với việc diễn giải Python
dựa trên trình duyệt cục bộ và các gợi ý được tinh chỉnh để đạt được hiệu suất tiên
tiến nhất về các bài toán số học và cung cấp một giao diện phù hợp và môi trường
an toàn để mã được thực thi.
Từ khóa : Mô hình Ngôn ngữ Lớn, Tạo Mã

1 Giới thiệu
Các mô hình ngôn ngữ đã có những bước tiến đáng kể trong những năm gần đây, trở nên thành thạo trong việc hiểu và tạo ra văn bản giống con người [26, 2]. Tuy nhiên, bất chấp những tiến bộ của chúng, các mô hình ngôn ngữ truyền thống vẫn không chính xác trong việc giải quyết các bài toán số học, vì kiến trúc của chúng dựa vào việc dự đoán từ tiếp theo dựa trên xác suất thay vì thực hiện các phép tính [3]. Bài báo này giới thiệu ComputeGPT, một mô hình chat sáng tạo có khả năng giải quyết các bài toán tính toán bằng cách chạy mã theo yêu cầu. ComputeGPT phân tích mỗi câu hỏi thành mã liên quan, thực thi mã và trả về câu trả lời đã tính toán như một phần của cuộc trò chuyện. Chúng tôi kết hợp phương pháp này với một trình diễn giải Python dựa trên trình duyệt cục bộ, Pyiodide, và các gợi ý được tinh chỉnh để đạt được hiệu suất tiên tiến nhất trong việc giải quyết các bài toán số học trong khi cung cấp một môi trường phù hợp và an toàn cho việc thực thi mã.

Ngoài các khả năng được đề cập ở trên, ComputeGPT tích hợp phân tích LaTeX để xử lý các biểu thức toán học và chuyển đổi chúng một cách liền mạch thành các gợi ý ngôn ngữ tự nhiên cho mô hình mã. Điều này cho phép mô hình hiểu các ký hiệu toán học phức tạp và tạo ra các biểu diễn mã chính xác. Hơn nữa, chúng tôi tinh chỉnh mô hình bằng cách sử dụng các mô tả về các hàm hoặc thư viện cần thiết cho các nhiệm vụ cụ thể. Điều này cho phép ComputeGPT thích ứng với một loạt rộng các bài toán số học, bao gồm những bài toán yêu cầu các thư viện chuyên biệt hoặc các hàm tùy chỉnh.

Những tiến bộ gần đây trong các mô hình chat đã bắt đầu tích hợp các công cụ bên ngoài để hỗ trợ giải quyết vấn đề, chẳng hạn như hệ thống plugin của OpenAI [10] và JARVIS của Microsoft [11]. Các hệ thống này gọi đến các công cụ chuyên biệt để giải quyết các nhiệm vụ khác nhau, mở rộng khả năng của các mô hình ngôn ngữ. ComputeGPT đi xa hơn phương pháp này bằng cách giao tiếp trực tiếp với các đoạn mã ngắn, có thể chạy được để thực hiện các phép tính. Phương pháp này phản ánh cách một con người thực sự sẽ giải quyết các bài toán số học trong thế giới hiện đại bằng cách viết mã, cho phép một giải pháp chính xác và hiệu quả hơn.

1arXiv:2305.06223v1  [cs.PL]  8 May 2023

--- TRANG 2 ---
2 Bối cảnh
Các mô hình ngôn ngữ đã thành công trong nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên khác nhau, chẳng hạn như dịch thuật [4], tóm tắt [5], và trả lời câu hỏi [25]. Bất chấp sự thành thạo của chúng trong các nhiệm vụ này, chúng gặp khó khăn khi giải quyết các bài toán số học, yêu cầu mô hình thực hiện các phép tính thay vì chỉ tạo ra văn bản dựa trên ngữ cảnh [7]. Hạn chế này là kết quả trực tiếp của kiến trúc vốn có của các mô hình ngôn ngữ, tạo ra văn bản dựa trên phân phối xác suất của từ tiếp theo [26]. Để vượt qua hạn chế này, chúng tôi đề xuất ComputeGPT, một phương pháp mới tận dụng khả năng của các mô hình ngôn ngữ truyền thống trong khi giới thiệu khả năng thực thi mã để giải quyết chính xác các bài toán số học.

Trong những năm gần đây, sự phát triển của các mô hình tạo mã đã thu hút sự chú ý đáng kể do tiềm năng của chúng trong việc biến đổi lập trình và phát triển phần mềm [14]. Các mô hình này, chẳng hạn như CODEX của OpenAI [12] và CodeT5 của Salesforce [13], nhằm hiểu và tạo ra các đoạn mã trong nhiều ngôn ngữ lập trình khác nhau dựa trên các gợi ý ngôn ngữ tự nhiên. Chúng đã chứng minh kết quả đầy hứa hẹn trong việc hoàn thành một loạt rộng các nhiệm vụ lập trình, từ các đoạn mã đơn giản đến các thuật toán phức tạp [14, 15].

Tuy nhiên, bất chấp thành công của chúng, các mô hình tạo mã cũng đối mặt với những hạn chế nhất định. Một trong những thách thức đáng kể nhất là ketnoả năng xử lý nhất quán và chính xác các bài toán số học [3]. Vì các mô hình này được thiết kế chủ yếu để tạo mã dựa trên các gợi ý văn bản, hiệu suất của chúng trong việc giải quyết các bài toán số học có thể không đáng tin cậy [14]. Trong nhiều trường hợp, độ chính xác của mã được tạo ra có liên quan trực tiếp đến tính rõ ràng và cụ thể của các gợi ý [18]. Sự phụ thuộc này vào chất lượng gợi ý có thể cản trở khả năng của các mô hình trong việc tạo ra mã chính xác và hiệu quả khi đối mặt với thông tin mơ hồ hoặc không đầy đủ.

ComputeGPT xây dựng trên những tiến bộ được thực hiện bởi các mô hình tạo mã trong khi giải quyết các hạn chế của chúng trong việc xử lý các bài toán số học. Bằng cách tinh chỉnh trực tiếp từng gợi ý dựa trên tiêu chí, phương pháp này cho phép mô hình thích ứng với các biến thể bài toán khác nhau bằng cách sửa đổi các thành phần cụ thể của một hàm hoặc đoạn mã. Ví dụ, một khi hàm đạo hàm được biết, ComputeGPT có thể dễ dàng tính toán đạo hàm cho bất kỳ giá trị đầu vào nào bằng cách thay thế giá trị mong muốn vào hàm, cung cấp kết quả chính xác và nhanh chóng cho tất cả các biến thể tiềm năng của bài toán.

Ngoài việc tận dụng các điểm mạnh của các mô hình tạo mã hiện có, ComputeGPT tích hợp các kỹ thuật cho phép nó xử lý hiệu quả các thư viện chuyên biệt và các hàm tùy chỉnh. Khả năng thích ứng này cho phép mô hình giải quyết một loạt rộng hơn các bài toán số học, định vị ComputeGPT như một giải pháp đầy hứa hẹn cho việc giải quyết các thách thức toán học và tính toán phức tạp.

3 Phương pháp
ComputeGPT hoạt động bằng cách chuyển đổi các câu hỏi ngôn ngữ tự nhiên thành mã liên quan và thực thi mã để tính toán câu trả lời. Quá trình này bao gồm các bước sau:

3.1 Phân tích Câu hỏi
Bước đầu tiên trong quá trình là làm sạch và tinh chỉnh gợi ý đầu vào để cung cấp các hướng dẫn rõ ràng cho mô hình tạo mã. Điều này được thực hiện bằng cách đề cập cụ thể hoặc tạo ra các hàm cần thiết để thực hiện các nhiệm vụ nhất định và bao gồm các lệnh import thư viện liên quan trước. Đối với việc triển khai hiện tại của chúng tôi, chúng tôi sử dụng GPT-3.5 Turbo [19], vì Codex không còn có sẵn công khai. Để đảm bảo quá trình tạo mã tạo ra kết quả có ý nghĩa, gợi ý đầu vào được tinh chỉnh để luôn lưu trữ kết quả trong một biến cụ thể.

Đây là một ví dụ về gợi ý và việc tạo mã của nó:
Gợi ý: Tổng của tất cả các số chẵn từ một đến sáu là bao nhiêu?
1"""
2Cho một danh sách các số nguyên, tính tổng của tất cả các số chẵn trong
danh sách.
3Triển khai một hàm có tên 'sum_even_numbers' nhận một danh sách các
số nguyên làm đầu vào và trả về tổng của tất cả các số chẵn trong
danh sách.
4"""
5import numpy as np
6
7---- KẾT THÚC GỢI Ý MÃ ----
8
9---- BẮT ĐẦU TẠO MÃ ----
10
11def sum_even_numbers ( numbers : List [int ]) -> int:
12 pass
13
14input_list = [1, 2, 3, 4, 5, 6]
15result = sum_even_numbers ( input_list )
Hình 1: Ví dụ về gợi ý đã được làm sạch và tinh chỉnh cho việc tạo mã.

Trong ví dụ này (Hình 1), gợi ý đã được làm sạch và tinh chỉnh cung cấp một mô tả rõ ràng về bài toán, chỉ định tên hàm mong muốn và bao gồm lệnh import cần thiết cho thư viện Python numpy. Phong cách gợi ý này đảm bảo rằng mô hình tạo mã có tất cả thông tin cần thiết để tạo ra một đoạn mã có ý nghĩa và hiệu quả.

3.2 Thực thi Mã
Giai đoạn thực thi mã là một thành phần quan trọng của phương pháp ComputeGPT. Bằng cách thực thi mã được tạo ra trong một môi trường đóng trong trình duyệt của người dùng, chúng ta có thể giảm thiểu các rủi ro bảo mật tiềm năng liên quan đến việc thực thi phía máy chủ. Việc thực thi mã phía máy chủ dễ bị tổn thương bởi nhiều mối đe dọa khác nhau, chẳng hạn như thực thi mã từ xa, các cuộc tấn công từ chối dịch vụ và truy cập trái phép vào thông tin nhạy cảm [21]. Bằng cách chạy mã trên trình duyệt của người dùng, chúng ta hạn chế tác động tiềm năng của mã độc hại và duy trì một môi trường an toàn.

Để tạo điều kiện cho việc thực thi mã dựa trên trình duyệt, chúng tôi sử dụng Pyiodide [20], một dự án cho phép chạy các tập lệnh Python trong trình duyệt bằng WebAssembly. WebAssembly là một định dạng hướng dẫn nhị phân cấp thấp cho một máy ảo dựa trên ngăn xếp cho phép chạy mã với tốc độ gần native [22]. Pyiodide biên dịch trình thông dịch CPython và một số thư viện Python phổ biến thành WebAssembly, cho phép sử dụng chúng trực tiếp trong trình duyệt [20]. Phương pháp này cho phép chúng ta tận dụng Python, ngôn ngữ được hỗ trợ nhiều nhất cho việc tạo mã [12], để thực thi mã một cách an toàn và hiệu quả.

3

--- TRANG 4 ---
Việc thực thi mã trong trình duyệt có những lợi ích bổ sung, bao gồm giảm tải máy chủ, độ trễ thấp hơn và cải thiện quyền riêng tư. Bằng cách chuyển việc thực thi mã sang trình duyệt của người dùng, chúng ta giảm thiểu các tài nguyên tính toán cần thiết ở phía máy chủ, cho phép khả năng mở rộng tốt hơn. Hơn nữa, bằng cách thực thi trong trình duyệt loại bỏ nhu cầu xử lý phía máy chủ, điều này cho phép người dùng giải quyết các bài toán phức tạp về mặt tính toán như phần cứng của họ cho phép, không có giới hạn về ký tự, kích thước số hoặc thời gian xử lý.

3.3 Tạo Câu trả lời
Sau khi thực thi mã, ComputeGPT tạo ra một phản hồi chat bao gồm cả đoạn mã và kết quả đã tính toán. Việc cung cấp mã được tạo ra cho người dùng không chỉ mang lại tính minh bạch mà còn phục vụ như một công cụ giáo dục, cho phép người dùng học hỏi từ giải pháp được cung cấp. Tuy nhiên, việc chỉ trình bày mã và kết quả có thể không đủ để người dùng hiểu được logic và lý luận cơ bản đằng sau giải pháp.

Để nâng cao trải nghiệm người dùng và tạo điều kiện cho việc hiểu, ComputeGPT có thể được tích hợp với các mô hình chat để tạo ra ngữ cảnh và giải thích bổ sung cho giải pháp được cung cấp. Nghiên cứu trước đây đã chỉ ra hiệu quả của các hệ thống dạy kèm dựa trên chat trong việc hỗ trợ học tập và sự tham gia của học sinh [23]. Bằng cách sử dụng các nguyên tắc này, ComputeGPT có thể cung cấp các giải thích từng bước về quá trình thực thi mã và lý luận đằng sau mỗi bước, hỗ trợ người dùng trong việc hiểu giải pháp.

Hơn nữa, nghiên cứu trong lĩnh vực xử lý ngôn ngữ tự nhiên đã chứng minh tiềm năng của các mô hình AI trong việc tạo ra các giải thích giống con người cho nhiều nhiệm vụ khác nhau [24]. Bằng cách tận dụng những tiến bộ này, ComputeGPT có thể tạo ra các giải thích chi tiết giúp người dùng hiểu không chỉ mã mà còn các khái niệm toán học cơ bản và các chiến lược giải quyết vấn đề được mô hình sử dụng.

Nghiên cứu tương lai trong lĩnh vực này có thể khám phá các kỹ thuật để tạo ra các giải thích được cá nhân hóa và thích ứng hơn, điều chỉnh nội dung theo nhu cầu và sở thích cá nhân của từng người dùng. Những giải thích thích ứng như vậy có thể nâng cao sự tham gia của người dùng và cải thiện trải nghiệm học tập, tiếp tục củng cố ComputeGPT như một công cụ có giá trị cho cả việc giải quyết vấn đề và giáo dục.

4 Công trình Liên quan
Đã có nhiều nỗ lực khác nhau để nâng cao khả năng của các mô hình ngôn ngữ trong các lĩnh vực cụ thể. GPT-f [9] là một ví dụ về mô hình ngôn ngữ chuyên biệt tập trung vào giải quyết các bài toán toán học. Tuy nhiên, nó vẫn dựa vào việc tạo ra dựa trên văn bản và không thực thi mã để cung cấp câu trả lời chính xác. Ngược lại, ComputeGPT kết hợp điểm mạnh của các mô hình ngôn ngữ và việc thực thi mã, mang lại giải pháp hiệu quả và chính xác hơn cho các bài toán số học.

4.1 Giải quyết Bài toán Số học với Mô hình Ngôn ngữ Lớn
Khả năng của các mô hình ngôn ngữ lớn (LLMs) trong việc giải quyết các bài toán số học đã thu hút sự chú ý đáng kể từ cộng đồng nghiên cứu. Các LLMs như BERT [25] và GPT-2 [26] đã chứng minh khả năng ban đầu trong việc giải quyết các bài toán số học cơ bản và các phương trình đại số đơn giản. Khi các LLMs tiếp tục phát triển về kích thước và độ phức tạp, hiệu suất của chúng trong các nhiệm vụ số học đã cải thiện đáng kể. GPT-3 [?] và CODEX [12], ví dụ, đã được chỉ ra là có thể tạo ra các giải pháp toán học phức tạp hơn và thậm chí xử lý các bài toán nhiều bước.

4

--- TRANG 5 ---
Tuy nhiên, các LLMs vẫn đối mặt với những thách thức khi giải quyết các bài toán số học, chẳng hạn như tạo ra các giải pháp không chính xác hoặc không đầy đủ, và đôi khi gặp khó khăn với các bài toán yêu cầu độ chính xác cao hơn hoặc kiến thức chuyên biệt [27]. Để giải quyết những vấn đề này, nghiên cứu gần đây đã khám phá nhiều kỹ thuật khác nhau để nâng cao khả năng giải quyết bài toán số học của các LLMs. Ví dụ, Transformer-XL [28] đã giới thiệu một kiến trúc mới cho phép mô hình nắm bắt các phụ thuộc dài hạn hơn, điều này có thể có lợi cho việc giải quyết các bài toán số học nhiều bước. Các công trình khác đã tập trung vào việc tích hợp các nguồn kiến thức bên ngoài, chẳng hạn như đồ thị kiến thức hoặc cơ sở dữ liệu, để cải thiện hiệu suất của các LLMs trong các nhiệm vụ yêu cầu chuyên môn lĩnh vực cụ thể [29, 30].

4.2 Phương pháp Kết hợp cho Giải quyết Bài toán Số học
Nghiên cứu gần đây cũng đã điều tra các phương pháp kết hợp kết hợp các LLMs với các thuật toán truyền thống hoặc thư viện toán học để nâng cao khả năng giải quyết bài toán số học của chúng. Ví dụ, MathQA [31] là một tập dữ liệu và hệ thống cho việc trả lời câu hỏi toán học, kết hợp hiểu ngôn ngữ tự nhiên với lý luận đại số để giải quyết các bài toán toán học. Một nghiên cứu khác đã đề xuất một khung kết hợp các LLMs với các kỹ thuật tối ưu hóa số học để giải quyết các bài toán lập trình toán học, chứng minh hiệu suất được cải thiện so với chỉ sử dụng LLMs [32].

ComputeGPT đóng góp vào ngôi thể nghiên cứu đang phát triển này bằng cách tích hợp các LLMs với việc thực thi mã trong một môi trường đóng, cho phép các giải pháp chính xác và hiệu quả hơn cho các bài toán số học. Bằng cách kết hợp khả năng của các LLMs với việc thực thi mã theo yêu cầu, ComputeGPT nhằm giải quyết các hạn chế của các LLMs hiện tại và mang lại một phương pháp mới cho việc giải quyết bài toán số học.

5 Đánh giá
Chúng tôi đã tiến hành một đánh giá chính để đánh giá hiệu suất của ComputeGPT so với các mô hình ngôn ngữ tiên tiến khác, chẳng hạn như Davinci-003 [37], ChatGPT (GPT-3.5-Turbo) [19], GPT-4 (Bing AI) [33], và Wolfram Alpha NLP [36].

5.1 Giải quyết Bài toán Số học Tổng quát
Đánh giá đầu tiên tập trung vào khả năng tổng quát của các mô hình trong việc giải quyết các bài toán số học một cách chính xác. Chúng tôi đã tuyển chọn một tập dữ liệu gồm các bài toán số học đa dạng, bao gồm các bài toán số học, đại số, tích phân và hình học, và đánh giá hiệu suất của từng mô hình về mặt độ chính xác. Chúng tôi phân chia thêm các bài toán thành "bài toán từ" và "bài toán đơn giản", trong đó bài toán từ cần nhiều bước hoặc một số lý luận phức tạp để hoàn thành chúng. Kết quả được trình bày trong Bảng 1.

Bảng 1: So sánh Độ chính xác Giải quyết Bài toán Số học Tổng quát
Mô hình ComputeGPT Wolfram Alpha Davinci-003 ChatGPT GPT-4
Độ chính xác Tổng thể (%) 98% 56% 28% 48% 64%
Bài toán Từ (%) 95% 15% 35% 50% 65%
Đơn giản (%) 100% 83.3% 23.3% 46.6% 63.3%

5

--- TRANG 6 ---
Như được thể hiện trong Bảng 1, ComputeGPT vượt trội hơn các mô hình khác trong việc giải quyết các bài toán số học một cách chính xác. Điều này có thể được quy cho phương pháp độc đáo của nó trong việc tạo ra và thực thi các đoạn mã, cho phép các giải pháp chính xác và hiệu quả hơn.

Kết quả cũng cho thấy rằng Wolfram Alpha không thể xử lý lý luận có trong các bài toán từ, cũng như các mô hình OpenAI khác, như Davinci-003, không thể xử lý tính toán có trong các bài toán toán học đơn giản. GPT-4 cho thấy năng khiếu trong tất cả các lĩnh vực, nhưng ComputeGPT rõ ràng chứng minh hiệu suất tiên tiến nhất trong tất cả các bài toán số học được đánh giá, cả bài toán từ và bài toán đơn giản.

Cần lưu ý rằng ChatGPT (GPT-3.5-Turbo), khi được hỏi trực tiếp để có câu trả lời, chỉ đúng khoảng một nửa số câu. Khi được kết hợp với ComputeGPT, sử dụng GPT-3.5 Turbo cho việc tạo mã được gợi ý và tinh chỉnh, mã được thực thi có được gần 100% câu trả lời đúng.

Chúng tôi thừa nhận sự tồn tại của các mô hình mã khác, như CodeT5 [13] và CodeParrot [35], nhưng các mô hình này đã được thấy có kết quả kém trên đánh giá HumanEval [34], điều này cho thấy chúng cũng sẽ có kết quả tương tự ở đây. Do đó, chúng tôi không đánh giá ComputeGPT với các mô hình mã khác nhau, vì kết quả có thể sẽ tỷ lệ thuận với các đánh giá trước đó.

Chúng tôi công khai đánh giá của mình trong phụ lục.

6 Kết luận
Trong bài báo này, chúng tôi đã giới thiệu ComputeGPT, một phương pháp kết hợp các mô hình ngôn ngữ lớn với việc thực thi mã theo yêu cầu để giải quyết các bài toán số học. ComputeGPT giải quyết các hạn chế của các mô hình ngôn ngữ hiện tại bằng cách tạo ra và thực thi mã Python trong một môi trường an toàn và bảo mật, cải thiện hiệu quả và độ chính xác của các giải pháp cho các nhiệm vụ số học. Bằng cách tinh chỉnh các gợi ý được đưa vào mô hình mã và thực thi mã được tạo ra trong trình duyệt của người dùng bằng Pyiodide, ComputeGPT cung cấp trải nghiệm giải quyết vấn đề được nâng cao trong khi duy trì quyền riêng tư và bảo mật của người dùng.

Nhìn về phía trước, có một số hướng nghiên cứu đầy hứa hẹn cho tương lai. Một lĩnh vực điều tra tiềm năng là việc tích hợp các mô hình mã với các nguồn dữ liệu bên ngoài và APIs để thực hiện tính toán trên các đại lượng thông tin. Ví dụ, bằng cách kết nối các mô hình mã với cơ sở dữ liệu, ComputeGPT có thể giúp người dùng tính toán sự khác biệt dân số giữa hai quốc gia, hoặc phân tích dữ liệu lịch sử để đưa ra dự đoán. Điều này sẽ tiếp tục nâng cao khả năng của các mô hình ngôn ngữ trong việc giải quyết bài toán số học và mở rộng khả năng ứng dụng của chúng cho một loạt rộng hơn các nhiệm vụ.

Một hướng khác cho công việc tương lai là phát triển các kỹ thuật để cải thiện khả năng diễn giải và giải thích của mã được tạo ra bởi ComputeGPT. Điều này sẽ cho phép người dùng hiểu sâu hơn về các bước liên quan đến việc giải quyết một bài toán cho trước và giúp họ học các khái niệm cơ bản. Ngoài ra, việc nâng cao khả năng suy luận mã ở edge của mô hình có thể làm cho ComputeGPT trở nên dễ tiếp cận và linh hoạt hơn, phục vụ người dùng thiếu truy cập internet cũng như cải thiện quyền riêng tư và an toàn.

Nhìn chung, ComputeGPT trình bày một phương pháp mới để tận dụng các mô hình ngôn ngữ lớn cho việc giải quyết bài toán số học bằng cách tích hợp việc thực thi mã trong một môi trường đóng. Công trình này đóng góp vào ngôi thể nghiên cứu đang phát triển về việc tăng cường các mô hình ngôn ngữ với các tài nguyên bên ngoài và mở ra những con đường mới cho việc phát triển các công cụ giải quyết vấn đề hiệu quả và mạnh mẽ hơn.

6

--- TRANG 7 ---
Tài liệu tham khảo
[1] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever, "Language Models are Unsupervised Multitask Learners," OpenAI Blog,
2019. [ https://cdn.openai.com/research-covers/language-unsupervised/
language_understanding_paper.pdf ]

[2] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Pra-
fulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christo-
pher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
and Dario Amodei, "Language Models are Few-Shot Learners," Advances in Neural
Information Processing Systems 33, 2020.

[3] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael,
Felix Hill, Omer Levy, and Samuel R. Bowman, "SuperGLUE: A Stickier Bench-
mark for General-Purpose Language Understanding Systems," Advances in Neural
Information Processing Systems 32, 2019.

[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan
N. Gomez, Lukasz Kaiser, and Illia Polosukhin, "Attention Is All You Need," Ad-
vances in Neural Information Processing Systems 30, 2017.

[5] Yang Liu and Mirella Lapata, "Text Summarization with Pretrained Encoders,"
Proceedings of the 2019 Conference on Empirical Methods in Natural Language
Processing and the 9th International Joint Conference on Natural Language Pro-
cessing, pp. 3721-3731, 2019.

[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova, "BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding," Pro-
ceedings of the 2019 Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies, Volume 1 (Long
and Short Papers), pp. 4171-4186, 2019.

[7] Eric Wallace, Yizhong Wang, Sujay Khandpur, Sanjay Subramanian, Carter Paden,
Dong-Ho Lee, Lucy Lu Wang, Matt Gardner, Sebastian Kohlmeier, and Sameer
Singh, "Few-Shot Text Classification with Pretrained Word Embeddings and a
Human in the Loop," Proceedings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pp. 6370-6376, 2020.

[8] OpenAI, "GPT-4: Advanced Language Model for Natural Language Understanding
and Generation," OpenAI Blog, 2022. [ https://openai.com/blog/gpt-4/ ]

[9] John McCarthy, Jane Doe, and Michael Smith, "GPT-f: A Fine-Tuned Language
Model for Mathematical Problem Solving," Proceedings of the 2021 Conference on
Neural Information Processing Systems, pp. 2143-2152, 2021.

[10] OpenAI, "OpenAI Plugins: Extending the Capabilities of Language Models,"
OpenAI Blog, 2022. [ https://openai.com/blog/chatgpt-plugins ]

[11] Kaizhi Zheng, Kaiwen Zhou, Jing Gu, Yue Fan, Jialu Wang, Zonglin Di,
Xuehai He, and Xin Eric Wang, "JARVIS: A Neuro-Symbolic Commonsense
Reasoning Framework for Conversational Embodied Agents," arXiv preprint
arXiv:2208.13266, 2022.

7

--- TRANG 8 ---
[12] OpenAI, "Introducing OpenAI Codex: AI-Powered Code Generation," OpenAI
Blog, 2021. [ https://openai.com/blog/openai-codex/ ]

[13] Yue Wang, Weishi Wang, Shafiq Joty and Steven C. H. Hoi, "CodeT5: Identifier-
aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and
Generation," arXiv preprint arXiv:2109.00859, 2021.

[14] Chen, Mark, et al., "Evaluating Large-Scale Code Generation: A Case Study on
OpenAI Codex," arXiv preprint arXiv:2109.03379, 2021.

[15] Radford, Alec, et al., "Learning Transferable Visual Models From Natural Lan-
guage Supervision," arXiv preprint arXiv:2103.00020, 2021.

[16] Svyatkovskiy, Alexey, et al., "Codex: Beyond Human-Level Completion With
Language Models," arXiv preprint arXiv:2109.04454, 2021.

[17] Campbell, James, et al., "Teaching AI to Write Code by Writing Code," arXiv
preprint arXiv:2109.04544, 2021.

[18] Hashimoto, Tatsunori B., et al., "What Makes a Good Prompt for Codex? Under-
standing Prompt Quality with Codex Assisted Code," arXiv preprint arXiv:2111.

[19] OpenAI, "Introducing GPT-3.5 Turbo: Fine-tuning Made Easy," OpenAI Blog,
2022. [ https://openai.com/blog/introducing-chatgpt-and-whisper-apis ]

[20] Pyodide Contributors, "Pyodide: Bringing the Scientific Python Stack to the
Browser," GitHub Repository, 2021. [ https://github.com/pyodide/pyodide ]

[21] OWASP Foundation, "OWASP Top Ten Project," OWASP, 2020. [ https://
owasp.org/www-project-top-ten/ ]

[22] Haas, A., et al., "Bringing the Web Up to Speed with WebAssembly," Proceedings
of the 38th ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI 2017), pp. 185-200, 2017.

[23] Graesser, A.C., et al., "Automated Tutoring Dialogue Systems: An Ill-Defined
Class of Cognitive Technologies," Journal of Cognitive Technology, vol. 6, no. 2,
pp. 1-6, 2001.

[24] Vinyals, O., et al., "Pointer Networks," Advances in Neural Information Processing
Systems (NIPS 2015), pp. 2692-2700, 2015.

[25] Devlin, J., et al., "BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding," Proceedings of the 2019 Conference of the North Amer-
ican Chapter of the Association for Computational Linguistics: Human Language
Technologies (NAACL-HLT 2019), pp. 4171-4186, 2019.

[26] Radford, A., et al., "Language Models are Unsupervised Multitask Learn-
ers," OpenAI Blog, 2019. [ https://cdn.openai.com/better-language-models/
language_models_are_unsupervised_multitask_learners.pdf ]

[27] Ford, N., et al., "The Limitations of Large-Scale Language Models," arXiv preprint
arXiv:2102.02502, 2021.

[28] Dai, Z., et al., "Transformer-XL: Attentive Language Models beyond a Fixed-
Length Context," Proceedings of the 57th Annual Meeting of the Association for
Computational Linguistics (ACL 2019), pp. 2978-2988, 2019.

8

--- TRANG 9 ---
[29] Talmor, A., et al., "oLMpics – On what Language Model Pre-training Captures,"
Transactions of the Association for Computational Linguistics, vol. 8, pp. 434-450,
2020.

[30] Bosselut, A., et al., "COMET: Commonsense Transformers for Automatic Knowl-
edge Graph Construction," Proceedings of the 57th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL 2019), pp. 4762-4779, 2019.

[31] Wang, Y., et al., "MathQA: Towards Interpretable Math Word Problem Solving
with Operation-Based Formalisms," Proceedings of the 2019 Conference of the
North American Chapter of the Association for Computational Linguistics: Human
Language Technologies (NAACL-HLT 2019), pp. 2357-2367, 2019.

[32] Akchurin, E., et al., "Solving Mathematical Programming Problems in Natural
Language with Transformers," arXiv preprint arXiv:2109.08601, 2021.

[33] Microsoft. Bing and GPT-4. https://blogs.bing.com/search/march_2023/
Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4 .

[34] Frank F. Xu, Uri Alon, Graham Neubig, and Vincent J. Hellendoorn. A Systematic
Evaluation of Large Language Models of Code. arXiv preprint arXiv:2202.13169 ,
2022.

[35] Hugging Face. CodeParrot. https://huggingface.co/codeparrot .

[36] Wolfram Research Wolfram Alpha NLP. https://www.wolfram.com/
natural-language-understanding/ .

[37] OpenAI. GPT-3. https://openai.com/blog/gpt-3-apps .

9

--- TRANG 10 ---
Phụ lục
Trong phụ lục này, chúng tôi trình bày một số câu hỏi ví dụ và các câu trả lời được cung cấp bởi năm mô hình chat khác nhau đang được so sánh. Đánh giá đầy đủ của chúng tôi có sẵn tại https://github.com/ryanhlewis/ComputeGPTEval . Ngoài ra, ComputeGPT có thể sử dụng tại https://computegpt.org .

(Đơn giản) Câu hỏi Ví dụ:
Đạo hàm của 200x là gì?
(Đúng: 200)
ComputeGPT 200
Wolfram Alpha 200
Davinci-003 200
ChatGPT 200
GPT-4 200

(Đơn giản) Câu hỏi Ví dụ:
Tích phân của 200x từ 0 đến 5 là gì?
(Đúng: 2500)
ComputeGPT 2500
Wolfram Alpha 2500
Davinci-003 5000
ChatGPT 5000
GPT-4 5000

(Đơn giản) Câu hỏi Ví dụ LaTeX:Z50
2021021x3+ 200 x2dx
(Đúng: 9135000000000000000026600000/3)
ComputeGPT 9135000000000000000026600000/3
Wolfram Alpha 26600000/3
Davinci-003 50,000,000,000,000,000,000
ChatGPT 1.83333 x 1024
GPT-4 1.66666666666667E+24

Chúng tôi cho thấy rằng ComputeGPT hiệu quả trong việc phân tích LaTeX, cũng như việc phân tích các số nguyên lớn, điều mà các mô hình khác không làm được.

10

--- TRANG 11 ---
(Bài toán Từ) Câu hỏi Ví dụ:
Tuổi của Kevin gấp 5 lần tuổi con trai anh ấy, cộng
hai mươi. Con trai anh ấy 10 tuổi. Kevin bao nhiêu tuổi?
(Đúng: 70)
ComputeGPT 70
Wolfram Alpha NULL
Davinci-003 50
ChatGPT 50
GPT-4 70

(Bài toán Từ) Câu hỏi Ví dụ:
Một kỹ thuật mới, gọi là 'jamulti' được phát minh bằng cách nhân một số
với năm và sau đó cộng 2 và chia cho 3. Jamulti của 7 là gì?
(Đúng: 12.33333)
ComputeGPT 12.33333
Wolfram Alpha NULL
Davinci-003 5
ChatGPT 5
GPT-4 12

(Bài toán Từ) Câu hỏi Ví dụ:
Một người ngoài hành tinh cần $50 USD để mua một tàu vũ trụ. Anh ta cần đổi từ
ASD, có giá trị $1.352 USD. Anh ta cần bao nhiêu ASD?
(Đúng: 36.9822485)
ComputeGPT 36.9822485
Wolfram Alpha 1.352
Davinci-003 36.68
ChatGPT 67.6
GPT-4 37.01

Chúng tôi cho thấy rằng GPT-4 có khả năng ảo tưởng các câu trả lời 'gần đúng', điều này trở nên tồi tệ hơn khi số càng lớn, và sai số tuyệt đối tăng lên.

11

--- TRANG 12 ---
(Bài toán Từ) Câu hỏi Ví dụ Lừa:
Một con kiến di chuyển với tốc độ 3 m/s trên một dây cao su. Dây cao su được
kéo giãn với tốc độ 2 m/s. Con kiến di chuyển nhanh như thế nào so với mặt đất?
(Đúng: 1)
ComputeGPT NULL
Wolfram Alpha 3
Davinci-003 5
ChatGPT 5
GPT-4 1

Chúng tôi trình bày một ví dụ về sự thất bại của ComputeGPT, khi nó không nhìn thấy được sự đơn giản của câu hỏi lừa trong phép trừ 3 - 2 = 1.

(Bài toán Từ) Câu hỏi Ví dụ:
Cho ma trận [[1, 2, 9, 3, 3], [9, 0, 1, 2, 4], [0, 0, 0, 3,
9], [1, 1, 1, 1, 1], [3, 4484, 456, 9, 6]], định thức nhân với 5 và sau đó chia cho hai mươi ba là gì?
(Đúng: -285832.173913042)
ComputeGPT -285832.173913042
Wolfram Alpha -1314828
Davinci-003 24
ChatGPT -9915
GPT-4 -30247.652

Chúng tôi trình bày một ví dụ về chiến thắng rõ ràng của ComputeGPT, khi nó vượt trội trong việc hiểu và thực hiện một phép tính phức tạp trên máy của người dùng.

12

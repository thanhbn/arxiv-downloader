# 2405.14333.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/math/2405.14333.pdf
# Kích thước file: 601408 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
DeepSeek-Prover: Tiến bộ trong Chứng minh Định lý với
LLMs thông qua Dữ liệu Tổng hợp Quy mô Lớn
Huajian Xin1,2Daya Guo1Zhihong Shao1Z.Z. Ren1Qihao Zhu1Bo Liu1
Chong Ruan1Wenda Li3Xiaodan Liang2,4∗
1DeepSeek2Sun Yat-sen University3University of Edinburgh4MBZUAI
{xinhj, guoday, zhihongshao, rzz, zhuqh, chong.ruan}@deepseek.com,
benjaminliu.eecs@gmail.com, wli8@ed.ac.uk, xdliang328@gmail.com
Tóm tắt
Các trợ lý chứng minh như Lean đã cách mạng hóa việc xác minh chứng minh toán học,
đảm bảo độ chính xác và độ tin cậy cao. Mặc dù các mô hình ngôn ngữ lớn (LLMs)
cho thấy tiềm năng trong lý luận toán học, sự tiến bộ của chúng trong chứng minh định lý
hình thức bị cản trở bởi thiếu dữ liệu huấn luyện. Để giải quyết vấn đề này, chúng tôi giới
thiệu một phương pháp để tạo ra dữ liệu chứng minh Lean 4 rộng lớn bắt nguồn từ các
bài toán thi đấu toán học cấp trung học và đại học. Phương pháp này bao gồm việc dịch
các bài toán ngôn ngữ tự nhiên thành các phát biểu hình thức, lọc bỏ các phát biểu chất
lượng thấp, và tạo ra các chứng minh để tạo dữ liệu tổng hợp. Sau khi tinh chỉnh mô hình
DeepSeekMath 7B trên tập dữ liệu tổng hợp này, bao gồm 8 triệu phát biểu hình thức
với chứng minh, mô hình của chúng tôi đạt được độ chính xác tạo chứng minh toàn bộ
46.3% với 64 mẫu và 52% tích lũy trên bài kiểm tra Lean 4 miniF2F, vượt qua đường
cơ sở GPT-4 ở 23.0% với 64 mẫu và một phương pháp học tăng cường tìm kiếm cây ở
41.0%. Ngoài ra, mô hình của chúng tôi đã chứng minh thành công 5 trong số 148 bài
toán trong benchmark Lean 4 Formalized International Mathematical Olympiad (FIMO),
trong khi GPT-4 không thể chứng minh bài nào. Những kết quả này chứng minh tiềm năng
của việc tận dụng dữ liệu tổng hợp quy mô lớn để nâng cao khả năng chứng minh định lý
trong LLMs. Cả tập dữ liệu tổng hợp và mô hình sẽ được công khai để tạo điều kiện cho
nghiên cứu tiếp theo trong lĩnh vực đầy hứa hẹn này.

1 Giới thiệu
Trong toán học hiện đại, sự phức tạp ngày càng tăng của các chứng minh đặt ra những thách thức
đáng kể cho việc đánh giá đồng đẳng. Sự phức tạp này đã dẫn đến việc chấp nhận các chứng minh
sai lầm, với những khuyết điểm nghiêm trọng thường chỉ được phát hiện sau một thời gian đáng kể.
Để giải quyết những vấn đề này, các ngôn ngữ toán học hình thức như Lean [De Moura et al., 2015,
Moura và Ullrich, 2021], Isabelle [Paulson, 1994], và Coq [The Coq Development Team] đã được
phát triển. Những ngôn ngữ này cho phép tạo ra các chứng minh có thể xác minh bằng máy tính
[Avigad, 2023]. Tuy nhiên, việc tạo ra các chứng minh hình thức đòi hỏi nỗ lực đáng kể, chuyên
môn chuyên biệt, và đặt ra thách thức ngay cả đối với các nhà toán học dày dạn kinh nghiệm. Do
đó, tầm quan trọng của chứng minh định lý tự động đang gia tăng [Shulman, 2024].

Để giảm nỗ lực liên quan đến việc viết các chứng minh toán học hình thức, một số phương pháp
[Polu và Sutskever, 2020, Jiang et al., 2021, Han et al., 2021, Polu et al., 2022, Lample et al.,
2022, Jiang et al., 2022a, Yang et al., 2024] đã được phát triển, chủ yếu tập trung vào các thuật
toán tìm kiếm khám phá các giải pháp tiềm năng cho các định lý được đề xuất. Tuy nhiên, những
phương pháp này thường gặp khó khăn với không gian tìm kiếm rộng lớn cần thiết cho các định lý
phức tạp, khiến chúng không hiệu quả đối với các chứng minh phức tạp hơn [Loos et al., 2017].
Gần đây, những tiến bộ trong các mô hình ngôn ngữ lớn (LLMs) đã giới thiệu một chiến lược mới,

∗Tác giả liên hệ.
Preprint. Đang được xem xét.arXiv:2405.14333v1  [cs.AI]  23 Tháng 5 2024

--- TRANG 2 ---
sử dụng các mô hình được huấn luyện trước để hướng dẫn quá trình tìm kiếm. Mặc dù những phương
pháp mới này [Jiang et al., 2022b, Zhao et al., 2023, Xin et al., 2023] đại diện cho những cải tiến
đáng kể, chúng vẫn còn thiếu khả năng ứng dụng thực tế do thiếu corpus song song. Không giống
như các ngôn ngữ lập trình thông thường như Python hoặc Java, các ngôn ngữ chứng minh hình
thức được sử dụng bởi tương đối ít nhà toán học, dẫn đến các tập dữ liệu hạn chế. Những tiến bộ
gần đây trong tự động hình thức hóa [Wu et al., 2022] cho phép tổng hợp thêm dữ liệu được căn
chỉnh để huấn luyện các bộ chứng minh định lý tự động dựa trên LLM. Tuy nhiên, tập dữ liệu kết
quả vẫn quá nhỏ để giải phóng hoàn toàn khả năng của LLMs.

Để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp để tạo ra dữ liệu chứng minh Lean
4 rộng lớn từ các bài toán toán học không chính thức. Phương pháp của chúng tôi dịch các bài toán
thi đấu toán học cấp trung học và đại học thành các phát biểu hình thức. Sau đó chúng tôi tự động
hóa việc tạo chứng minh bằng cách sử dụng một mô hình ngôn ngữ lớn (LLM) và xác minh tính
đúng đắn của những chứng minh này trong môi trường Lean 4. Thách thức chính của phương pháp
này là đảm bảo cả quy mô và chất lượng của dữ liệu tổng hợp.

Đảm bảo Chất lượng: Chúng tôi nâng cao chất lượng của các chứng minh được tạo ra thông qua
một quy trình nhiều bước. Đầu tiên, chúng tôi lọc bỏ các phát biểu đơn giản sử dụng một mô hình
chấm điểm chất lượng và loại trừ các phát biểu không hợp lệ thông qua chiến lược từ chối giả
thuyết. Khung công tác lặp mới của chúng tôi sau đó cải thiện chất lượng chứng minh bằng cách
ban đầu tạo ra các phát biểu tổng hợp từ các bài toán toán không chính thức sử dụng một LLM
chưa được huấn luyện đầy đủ được tinh chỉnh trên dữ liệu hạn chế. Những phát biểu này được sử
dụng để tạo ra các chứng minh tương ứng, được xác thực tính đúng đắn bằng cách sử dụng một bộ
xác minh Lean 4. Các cặp định lý-chứng minh đúng sau đó được sử dụng để huấn luyện thêm cho
mô hình ban đầu. Thông qua nhiều lần lặp, mô hình được huấn luyện trên dữ liệu tổng hợp quy mô
lớn trở nên mạnh mẽ hơn đáng kể so với các LLMs chưa được huấn luyện đầy đủ ban đầu, dẫn
đến các cặp định lý-chứng minh chất lượng cao hơn.

Đảm bảo Quy mô: Để tăng tốc quá trình tạo chứng minh, phương pháp của chúng tôi giải quyết
thách thức của không gian tìm kiếm lớn cho các chứng minh. Một nguyên nhân quan trọng của sự
chậm trễ là việc tạo ra các phát biểu không thể chứng minh mà tiếp tục được xử lý cho đến khi
chúng đạt đến giới hạn thời gian. Để giảm thiểu điều này, chúng tôi đề xuất chứng minh các phát
biểu phủ định song song. Khi một trong hai phát biểu gốc hoặc phủ định của nó được chứng minh,
toàn bộ quá trình chứng minh sẽ bị kết thúc.

Chúng tôi đánh giá hiệu quả của phương pháp trên chứng minh định lý Lean 4 sử dụng 488 bài
toán từ miniF2F [Zheng et al., 2021] và 148 bài toán từ các benchmark FIMO [Liu et al., 2023].
Chúng tôi sử dụng DeepSeekMath 7B [Shao et al., 2024], một mô hình toán học tiên tiến, làm nền
tảng. Kết quả cho thấy mô hình được huấn luyện lặp của chúng tôi hoạt động mạnh mẽ, đạt độ
chính xác 46.3% trong tạo chứng minh toàn bộ trên benchmark miniF2F-test với 64 mẫu, vượt qua
GPT-4 [Achiam et al., 2023] ở 23.0% và một phương pháp học tăng cường ở 41.0%. Ngoài ra,
phương pháp của chúng tôi giải quyết được 4 trong số 148 bài toán trong benchmark FIMO với
100 mẫu, trong khi GPT-4 không giải được bài nào, và phương pháp của chúng tôi giải được 5 bài
với 4096 mẫu. Các thí nghiệm ablation cho thấy mô hình tiến bộ giải quyết được nhiều bài toán
hơn trong miniF2F với mỗi lần lặp. Tóm lại, bài báo của chúng tôi có những đóng góp sau:

•Chúng tôi giới thiệu một phương pháp lặp để tổng hợp 8 triệu phát biểu hình thức, mỗi phát
biểu đi kèm với một chứng minh hình thức, từ các bài toán toán không chính thức. Kết quả
thí nghiệm chứng minh rằng phương pháp này nâng cao đáng kể cả khả năng mở rộng và
chất lượng của dữ liệu tổng hợp.

•Mô hình của chúng tôi, được huấn luyện trên tập dữ liệu tổng hợp này, đạt hiệu suất tiên
tiến trên các benchmark, với độ chính xác tạo chứng minh toàn bộ 46.3% sử dụng 64 mẫu
và 52% tích lũy trên bài kiểm tra Lean 4 miniF2F. Điều này vượt qua đường cơ sở GPT-4
ở 23.0% với 64 mẫu và một phương pháp học tăng cường tìm kiếm cây ở 41.0%. Ngoài ra,
mô hình của chúng tôi đã chứng minh thành công 5 trong số 148 bài toán trong benchmark
Lean 4 Formalized International Mathematical Olympiad (FIMO), trong khi GPT-4 không
thể chứng minh bài nào.

•Chúng tôi đóng góp cho cộng đồng toán học và AI bằng cách tạo ra và mở mã nguồn một tập
dữ liệu lớn các chứng minh toán học hình thức chất lượng cao, từ đó thúc đẩy nghiên cứu
và phát triển thêm trong chứng minh định lý tự động.

2 Bối cảnh và Các Công trình Liên quan
Chứng minh định lý tự động đã là một lĩnh vực quan tâm đáng kể trong nghiên cứu trí tuệ nhân tạo
kể từ khi ra đời [Bibel, 2013]. Những nỗ lực ban đầu được hướng vào các khung logic đơn giản
hơn, dẫn đến việc phát triển các bộ chứng minh định lý bậc nhất có hiệu quả cao như E [Schulz,
2002] và Vampire [Kovács và Voronkov, 2013]. Tuy nhiên, những công cụ này thường thiếu sót
trong việc xử lý các định lý phức tạp thường thấy trong các trợ lý chứng minh hiện đại như Lean
[De Moura et al., 2015], Isabelle [Paulson, 1994], và Coq [The Coq Development Team]. Sự ra
đời của các mô hình học sâu gần đây và các kỹ thuật tìm kiếm được hướng dẫn bởi mô hình đã
làm tăng sức sống cho lĩnh vực này [Bansal et al., 2019]. Phương pháp hiện đại này không chỉ
nâng cao khả năng của các hệ thống ATP mà còn mở rộng khả năng ứng dụng của chúng trong việc
giải quyết các bài toán toán học phức tạp hơn.

2

--- TRANG 3 ---
ATP với Mô hình Neural. Với sự phát triển của học sâu, một số phương pháp đã được đề xuất để
kết hợp các mô hình neural với ATP [Loos et al., 2017]. Một loạt các phương pháp ATP áp dụng
các thuật toán tìm kiếm cây được hướng dẫn bởi các mô hình neural [Polu và Sutskever, 2020,
Han et al., 2021, Polu et al., 2022, Jiang et al., 2022a, Yang et al., 2024]. Những phương pháp
này chủ yếu sử dụng các kỹ thuật học tăng cường để nâng cao độ chính xác của mô hình [Kaliszyk
et al., 2018, Crouse et al., 2021, Wu et al., 2021, Lample et al., 2022]. Vì không gian tìm kiếm
rất lớn, quá trình tìm kiếm tiêu tốn thời gian và tài nguyên tính toán đáng kể.

Một loạt phương pháp ATP khác khai thác sức mạnh của các mô hình ngôn ngữ lớn. Những phương
pháp này thường bao gồm các mô hình ngôn ngữ được tinh chỉnh với dữ liệu chứng minh mã nguồn
mở và tương tác với các bộ xác minh thông qua chương trình chuyển đổi trạng thái-hành động [Polu
và Sutskever, 2020, Jiang et al., 2021, Han et al., 2021, Polu et al., 2022, Lample et al., 2022,
Jiang et al., 2022a, Yang et al., 2024]. Quá trình này tạo ra các bước chứng minh một cách lặp và
xác minh tính đúng đắn của chúng với các bộ xác minh hình thức. Sau đó nó tạo ra các bước
chứng minh tiếp theo dựa trên các trạng thái chứng minh được trả về bởi các bộ xác minh hình
thức. Mặc dù những phương pháp này đạt hiệu suất cao, chúng tốn nhiều tài nguyên tính toán. Để
nâng cao hiệu quả, các nghiên cứu gần đây tận dụng các mô hình ngôn ngữ để tạo ra các chứng
minh hình thức hoàn chỉnh trực tiếp [First et al., 2023, Jiang et al., 2022b, Zhao et al., 2023, Xin
et al., 2023], do đó bỏ qua sự tương tác lặp trong quá trình tạo chứng minh.

Tự động Hình thức hóa cho Toán học Hình thức. Do tính khả dụng hạn chế của các corpus hình
thức để huấn luyện, hiệu suất của các mô hình ngôn ngữ lớn (LLMs) hiện tại cũng bị hạn chế. Do
đó, một số phương pháp đề xuất tự động hình thức hóa [Wu et al., 2022, Jiang et al., 2022b], bao
gồm việc chuyển đổi các mô tả ngôn ngữ tự nhiên thành các phát biểu hình thức có thể được xác
minh bởi các trợ lý chứng minh. Một số nghiên cứu đã tạo ra các tập dữ liệu tổng hợp của các
chứng minh hình thức sử dụng các biến đổi dựa trên quy tắc của các định lý hiện có [Wu et al.,
2020, Wang và Deng, 2020, Xiong et al., 2023]. Mặc dù hiệu quả, những phương pháp này bị
hạn chế bởi sự phụ thuộc vào các quy tắc được định nghĩa trước và thiếu tính linh hoạt cho các
ứng dụng rộng hơn. Các phương pháp luận gần đây áp dụng các mô hình ngôn ngữ lớn để dịch
các bài toán ngôn ngữ tự nhiên thành các phát biểu hình thức [Huang et al., 2024]. Tuy nhiên,
những tập dữ liệu này vẫn nhỏ hơn so với nhu cầu và bị hạn chế đối với các benchmark toán học
nhỏ, dẫn đến chỉ những cải thiện nhỏ trong kết quả huấn luyện cho các mô hình ngôn ngữ. Trong
bài báo này, chúng tôi nhằm tổng hợp các chứng minh hình thức thông qua tự động hình thức hóa
ở quy mô lớn hơn nhiều để thúc đẩy hiệu suất của một bộ chứng minh neural.

3 Phương pháp
Trong phần này, chúng tôi giới thiệu phương pháp của mình, bao gồm bốn quy trình chính như được
mô tả trong Hình 1. Giai đoạn ban đầu tập trung vào việc tạo ra các phát biểu toán học hình thức từ
một tập hợp rộng lớn các bài toán toán không chính thức, cần có chứng minh thêm. Tiếp theo, các
phát biểu được tự động hình thức hóa được lọc thông qua các phương pháp chấm điểm mô hình và từ
chối giả thuyết để chọn các phát biểu chất lượng cao. Những phát biểu này sau đó được chứng minh
bởi một mô hình gọi là DeepSeek-Prover, với tính đúng đắn của chúng được xác minh bởi bộ xác
minh hình thức gọi là Lean 42, tạo ra các phát biểu và chứng minh hình thức đã được xác thực.
Những dữ liệu này phục vụ như dữ liệu tổng hợp để tinh chỉnh DeepSeek-Prover. Sau khi nâng
cao DeepSeek-Prover, chúng tôi lặp lại toàn bộ quy trình đã mô tả trước đó. Chu kỳ này tiếp tục
cho đến khi các cải thiện trong DeepSeek-Prover trở nên tối thiểu. Đáng chú ý, để nâng cao hiệu
quả chứng minh, chúng tôi chứng minh đồng thời cả các phát biểu gốc và phủ định của chúng.
Phương pháp này có lợi thế là nhanh chóng loại bỏ phát biểu gốc khi nó không hợp lệ bằng cách
chứng minh phủ định của nó. Chi tiết của từng giai đoạn sẽ được mô tả trong các phần tiếp theo.

3.1 Tự động Hình thức hóa
Việc tạo ra dữ liệu chứng minh hình thức về cơ bản dựa vào tính khả dụng của một corpus đáng
kể các phát biểu hình thức. Tuy nhiên, trong thực tế, việc thu thập một tập hợp lớn các phát biểu
hình thức được tạo thủ công là thách thức. May mắn thay, internet tràn ngập các bài toán liên quan
đến toán học được biểu đạt bằng

2leanprover /lean4 :v4.7.0−rc2

3

--- TRANG 4 ---
Các Bài toán Toán Không chính thức1. Tự động Hình thức hóaCác Phát biểu Toán Hình thức2. Chấm điểm Mô hình và Từ chối Giả thuyết

Các Phát biểu Toán Hình thức
Chất lượng Cao

Các Phát biểu Hình thức với Chứng minh Đúng

Dữ liệu Tổng hợp

3. Chứng minh Phát biểu

4. Tinh chỉnh Bộ chứng minh5. Lặp lạiDS-Prover

Chứng minh Phát biểu GốcChứng minh Phát biểu Phủ địnhDS-Prover

Các Phát biểu Toán Hình thức
Ứng cử

Bộ Xác minh Hình thức

Các Phát biểu Hình thức với Chứng minh Đúng

Dữ liệu Tổng hợp

DS-Prover

DS-Prover

Chứng minh Phát biểu

Hình 1: Tổng quan về phương pháp của chúng tôi.

ngôn ngữ tự nhiên. Bằng cách tự động hình thức hóa những bài toán toán học không chính thức này,
chúng ta có thể tạo ra một kho tàng khổng lồ các phát biểu hình thức.

Chúng tôi đã quan sát thấy rằng các bài toán với điều kiện rõ ràng và mục tiêu được định nghĩa
rõ ràng thường dễ hình thức hóa hơn so với các chủ đề toán học nâng cao đòi hỏi các định nghĩa
và cấu trúc phức tạp. Do đó, bài báo này chủ yếu kiểm tra các bài toán thi đấu cấp trung học và
đại học, với sự tập trung đặc biệt vào đại số và lý thuyết số, và ít hơn vào tổ hợp, hình học, và
thống kê. Mặc dù có vẻ đơn giản, những bài toán này thường liên quan đến các kỹ thuật giải
phức tạp, khiến chúng trở thành ứng cử viên xuất sắc để xây dựng dữ liệu chứng minh nhằm cải
thiện khả năng chứng minh định lý trong Mô hình Ngôn ngữ Lớn (LLMs). Để biên soạn tập dữ
liệu của chúng tôi, chúng tôi sử dụng các kỹ thuật cào web và làm sạch dữ liệu cẩn thận để trích
xuất các bài toán từ các tài nguyên trực tuyến có bài tập, kỳ thi, và cuộc thi cấp trung học và đại
học, dẫn đến một tập dữ liệu gồm 869,659 bài toán toán học ngôn ngữ tự nhiên chất lượng cao.

Cụ thể, chúng tôi khởi tạo DeepSeek-Prover sử dụng mô hình DeepSeekMath-Base 7B [Shao et
al., 2024]. Ban đầu, mô hình gặp khó khăn trong việc chuyển đổi các bài toán toán không chính
thức thành các phát biểu hình thức. Để giải quyết điều này, chúng tôi tinh chỉnh mô hình DeepSeek-
Prover sử dụng tập dữ liệu MMA [Jiang et al., 2023], bao gồm các phát biểu hình thức từ mathlib3
của Lean 4 được dịch ngược thành các mô tả bài toán ngôn ngữ tự nhiên bởi GPT-4. Sau đó chúng
tôi hướng dẫn mô hình dịch những bài toán ngôn ngữ tự nhiên này thành các phát biểu hình thức
trong Lean 4 sử dụng một phương pháp có cấu trúc.

Prompt:
Bài toán Toán học bằng Ngôn ngữ Tự nhiên:
{$informal_statement_with_answers}
Dịch bài toán sang Lean 4 (chỉ khai báo cốt lõi):
```lean4
Response:
{$formal_statement}
```

3.2 Lọc Chất lượng
Chất lượng của các phát biểu được tự động hình thức hóa được phát hiện là chưa tối ưu do hai vấn
đề chính. Thứ nhất, nhiều phát biểu hình thức quá đơn giản. Để giải quyết điều này, chúng tôi phát
triển tiêu chí chấm điểm và cung cấp ví dụ từ miniF2F-valid làm ví dụ few-shot để hướng dẫn mô
hình DeepSeek-Prover

3Commit mathlib cụ thể được sử dụng là 64528268b3c2cf578639bc479828882a9ecd3a82.

4

--- TRANG 5 ---
trong việc đánh giá nội dung và chất lượng của những phát biểu này sử dụng phương pháp chain-
of-thought. Đánh giá thủ công của những điểm số này xác nhận rằng các đánh giá của mô hình
gần với trực giác và kỳ vọng của con người. Cụ thể, mô hình được hướng dẫn (xem Phụ lục A.1
cho prompt chi tiết) phân loại chất lượng của mỗi phát biểu hình thức thành các danh mục: "xuất
sắc," "tốt," "trên trung bình," "khá," hoặc "kém." Các phát biểu được đánh giá "khá" hoặc "kém"
sau đó bị loại trừ.

Vấn đề thứ hai liên quan đến các phát biểu hình thức mặc dù có thể chứng minh được, nhưng dựa
trên các giả thuyết không nhất quán dẫn đến các kết luận rỗng, khiến các kết luận trở nên vô nghĩa
trong toán học. Ví dụ, xem xét phát biểu do mô hình tạo ra sau:

example ( θ:R) (h 0:∀z :C, z ^ 2 = -1 ∧z ^ 3 = -1 ∧z ^ 6 = 1) (h 1:
Real.tan θ= 2 * Real.sqrt 3) : θ= 5 * Real.pi / 3

Ở đây, giả thuyết z2=−1∧z3=−1∧z6= 1 với mọi số phức rõ ràng là sai, khiến bất kỳ kết luận
nào rút ra được trở nên vô nghĩa. Để loại bỏ những trường hợp như vậy khỏi tập dữ liệu của chúng
tôi, chúng tôi thực hiện một phương pháp từ chối giả thuyết. Điều này bao gồm việc sử dụng mô
hình DeepSeek-Prover để cố gắng chứng minh phát biểu hình thức với 'False' làm kết luận. Một
chứng minh thành công cho thấy một giả thuyết không hợp lệ, thúc đẩy việc loại trừ phát biểu. Một
ví dụ được hiển thị dưới đây:

example ( θ:R) (h 0:∀z :C, z ^ 2 = -1 ∧z ^ 3 = -1 ∧z ^ 6 = 1) (h 1:
Real.tan θ= 2 * Real.sqrt 3) : False := by
simpa using h 01

Bằng cách áp dụng chiến lược kép này về chấm điểm mô hình và từ chối giả thuyết, chúng tôi đã
tuyển chọn một tập hợp tinh chế gồm 712,073 phát biểu hình thức chất lượng cao, cung cấp một
nền tảng vững chắc cho tổng hợp chứng minh tiếp theo.

3.3 Chứng minh Phát biểu
Sau khi tạo ra một corpus đáng kể các phát biểu hình thức chất lượng cao, chúng tôi sử dụng mô
hình để tìm kiếm các chứng minh cho những phát biểu này. Theo truyền thống, các mô hình ngôn
ngữ đã được sử dụng chủ yếu theo cách brute-force để chứng minh các định lý—liên tục cố gắng
cho đến khi tìm được một chứng minh hợp lệ hoặc tài nguyên tính toán bị cạn kiệt. Phương pháp
này không hiệu quả cho mục đích của chúng tôi. Thông thường, các mô hình ngôn ngữ được áp
dụng cho các phát biểu hình thức được con người tuyển chọn được tạo ra một cách cẩn thận và
thường đúng và có thể chứng minh được; tuy nhiên, trong nhiệm vụ chứng minh các phát biểu được
tự động hình thức hóa của chúng tôi, nhiều phát biểu được tạo ra bởi mô hình có thể không chính
xác. Thật vậy, việc mong đợi mô hình xác thực một mệnh đề sai trong bất kỳ hệ thống chứng minh
đáng tin cậy nào là không hợp lý. Vấn đề này trở nên rõ rệt hơn trong quá trình tự động hình thức
hóa quy mô lớn, nơi chúng tôi quan sát thấy ít nhất 20% các phát biểu hình thức được tạo ra bởi
mô hình của chúng tôi, ngay cả sau khi lọc chất lượng, là không chính xác, dẫn đến lãng phí tính
toán đáng kể nếu được giải quyết bằng brute force.

Để giảm thiểu lãng phí tài nguyên trên các phát biểu không thể chứng minh và cải thiện hiệu quả
của quá trình tìm kiếm chứng minh, chúng tôi khai thác tính đối xứng logic giữa một phát biểu và
phủ định của nó để tăng tốc tổng hợp chứng minh. Chúng tôi thực hiện các tìm kiếm chứng minh
song song kép cho mỗi phát biểu tổng hợp—một cho phát biểu Γ⊢P và một cho phủ định của nó
Γ⊢ ¬P. Tìm kiếm kết thúc ngay khi tìm được một chứng minh hợp lệ cho một trong hai, chứng
minh một cách quyết định tính không thể chứng minh của cái kia. Mỗi luồng tìm kiếm chứng minh
cố gắng tối đa k chứng minh trừ khi một chứng minh hợp lệ xuất hiện sớm hơn.

Tất cả các chứng minh đã được xác thực, dù chúng biện minh cho các định lý gốc hay phủ định của
chúng, sau đó được tổng hợp để huấn luyện thêm cho DeepSeek-Prover. Do đó, phương pháp kép
này phục vụ như một hình thức tăng cường dữ liệu, làm phong phú tập dữ liệu với cả các mệnh đề
và phủ định của chúng—ngay cả khi các mệnh đề gốc không được hình thức hóa đúng bởi mô hình.

3.4 Nâng cao Lặp
Vì toàn bộ pipeline phụ thuộc nhiều vào DeepSeek-Prover, việc nâng cao hiệu suất của mô hình
sau mỗi lần lặp là rất quan trọng. Để đạt được điều này, chúng tôi liên tục tinh chỉnh mô hình với
dữ liệu mới được tạo ra. Mô hình được cập nhật sau đó được sử dụng cho các lần lặp tự động hình
thức hóa tiếp theo. Hiểu biết chính từ quá trình lặp này là mô hình cải thiện dần dần về sức mạnh
và hiệu quả sau mỗi chu kỳ tinh chỉnh và ứng dụng. Quá trình lặp này tiếp tục cho đến khi không
quan sát thấy lợi ích thêm nào. Do đó, các cặp định lý-chứng minh được tạo ra bởi mô hình trở
nên ngày càng cao hơn về chất lượng với mỗi lần lặp. Phương pháp này đảm bảo rằng DeepSeek-
Prover liên tục nâng cao hiệu suất của mình, cuối cùng tạo ra các cặp định lý-chứng minh vượt
trội thông qua tinh chỉnh liên tục.

5

--- TRANG 6 ---
4 Thí nghiệm

4.1 Thiết lập Thí nghiệm
DeepSeek-Prover được xây dựng dựa trên mô hình DeepSeekMath-Base 7B [Shao et al., 2024],
một transformer chỉ decoder [Vaswani et al., 2017] được huấn luyện trước trên một corpus bao
gồm 120 tỷ token liên quan đến toán học. Chúng tôi tinh chỉnh mô hình này sử dụng kích thước
batch toàn cục là 512 và tốc độ học tập không đổi 1×10−4, kết hợp 6,000 bước khởi động với
dữ liệu tổng hợp. Hiệu suất của DeepSeek-Prover được đánh giá so với một số đường cơ sở:

•GPT-3.5 và GPT-4 [Achiam et al., 2023], được phát triển bởi OpenAI, là các mô hình AI
tạo sinh tiên tiến được biết đến với hiệu quả trong các nhiệm vụ đa dạng, bao gồm tạo mã.
Mặc dù không được thiết kế rõ ràng cho chứng minh định lý, quy mô rộng lớn và số lượng
tham số của chúng mang lại khả năng đáng kể. Ngược lại, DeepSeekMath là một mô hình
chuyên biệt, được huấn luyện trước rõ ràng cho nội dung toán học. Chúng tôi sử dụng cả
GPT-4 (cụ thể là phiên bản GPT-4-turbo 0409) và DeepSeekMath để tạo ra các chứng minh
hoàn chỉnh cho các định lý đã cho sử dụng phương pháp tương tự như của chúng tôi.

•GPT-f [Polu và Sutskever, 2020], sử dụng kiến trúc lấy cảm hứng từ GPT-2 [Radford et
al., 2019], thực hiện một phương pháp tìm kiếm best-first lặp để tiến bộ tạo ra và xác thực
các bước chứng minh trong một thiết lập chứng minh hình thức cho đến khi một chứng minh
được hoàn thành hoặc tài nguyên bị cạn kiệt. Phương pháp luận này đã được tiến bộ thêm
bởi Proof Artifact Co-Training [Han et al., 2021], ReProver [Yang et al., 2024], Llemma
[Azerbayev et al., 2023], và COPRA [Thakur et al., 2023], sử dụng các mô hình được tinh
chỉnh chuyên biệt hoặc các mô hình đa năng như GPT-3.5 và GPT-4 để tạo ra các bước
chứng minh.

4.2 Kết quả Chính
Nghiên cứu này giải quyết các bài toán toán học phức tạp trong đại số và lý thuyết số. Chúng tôi
đánh giá hiệu quả chứng minh định lý của mô hình sử dụng các benchmark miniF2F [Zheng et al.,
2021] và FIMO [Liu et al., 2023]. Metric pass@k được sử dụng để biểu thị tình huống mà ít nhất
một chứng minh hợp lệ được khám phá trong số k lần thử đầu tiên được tạo ra bởi mô hình.

Kết quả trên MiniF2F. Benchmark miniF2F bao gồm 244 bài toán xác thực và 244 bài toán kiểm
tra, từ số học cơ bản đến các bài toán cấp độ thi đấu, ví dụ như các bài toán từ American Invitational
Mathematics Examination (AIME), American Mathematics Competitions (AMC), và International
Mathematical Olympiad (IMO). Chúng tôi sử dụng phiên bản miniF2F trong Lean 4, được phát
hành bởi dự án LeanDojo (https://github.com/yangky11/miniF2F-lean4).

Bảng 1 so sánh các phương pháp tiên tiến khác nhau trên tập dữ liệu miniF2F. DeepSeek-Prover
vượt trội hơn tất cả với điểm số tích lũy 60.2% trên miniF2F-valid và 52.0% trên miniF2F-test,
cao hơn đáng kể so với các phương pháp khác, bao gồm GPT-4 chỉ đạt 25.41% và 22.95%, tương
ứng. Ngay cả phương pháp tìm kiếm cây tốt nhất, Hypertree Proof Search với mô hình 600M, chỉ
đạt tối đa 58.6% trên miniF2F-valid và 41.0% trên miniF2F-test. Khả năng mở rộng của DeepSeek-
Prover rõ ràng khi hiệu suất của nó cải thiện với tài nguyên tính toán tăng lên, tăng từ 30.03% sử
dụng phương pháp greedy lên 50.0% ở 65536 lần tạo, chứng minh hiệu quả của nó trong xử lý
các tình huống chứng minh phức tạp. Ví dụ về các định lý đã chứng minh của MiniF2F có thể
tìm thấy trong Phụ lục A.3.1.

Kết quả trên FIMO. Benchmark FIMO bao gồm 149 bài toán hình thức có nguồn gốc từ danh sách
ngắn IMO được dịch sang Lean 4. Phương pháp của chúng tôi đã chứng minh thành công 4 định
lý với 100 lần thử cho mỗi định lý, trong khi GPT-4 không thể chứng minh bài nào. Bằng cách
tăng số lần thử cho mỗi định lý lên 4,096, chúng tôi đã chứng minh thành công thêm một định lý.
Ví dụ về các định lý đã chứng minh của FIMO có thể tìm thấy trong Phụ lục A.3.2.

6

--- TRANG 7 ---
Bảng 1: So sánh với các phương pháp tiên tiến trên tập dữ liệu miniF2F.

Phương pháp Kích thước mô hình Số lần tạo miniF2F-valid miniF2F-test
Phương pháp Tìm kiếm Cây
COPRA (GPT-3.5) [Thakur et al., 2023] - 1×60 - 9.0%
COPRA (GPT-4) [Thakur et al., 2023] - 1×60 - 26.6%
Proof Artifact Co-Training [Han et al., 2021] 837M1×8×512 23.9% 24.6%
8×8×512 29.3% 29.2%
ReProver [Yang et al., 2024] 229M 1×3751 - 25.0%
Llemma [Azerbayev et al., 2023] 7B 1×3200 - 26.2%
Llemma [Azerbayev et al., 2023] 34B 1×3200 - 25.8%
Curriculum Learning [Polu et al., 2022] 837M1×8×512 33.6% 29.6%
8×8×512 41.2% 34.5%
64×8×512 47.3% 36.6%
Hypertree Proof Search [Lample et al., 2022] 600Mtích lũy 58.6% -
64×5000 - 41.0%
Phương pháp Tạo Chứng minh Toàn bộ
GPT-4-turbo 0409 - 64 25.4% 23.0%
DeepSeekMath-Base [Shao et al., 2024] 7B 128 25.4% 27.5%
DeepSeek-Prover 7Btích lũy 60.2% 52.0%
1(greedy) - 30.0%
64 - 46.3%
128 - 46.3%
8192 - 48.8%
65536 - 50.0%

4.3 Nghiên cứu Ablation

4.3.1 Hiệu quả của Tự động Hình thức hóa Quy mô Lớn
Để chứng minh hiệu quả của tự động hình thức hóa quy mô lớn, chúng tôi đã tiến hành một phân
tích so sánh như được hiển thị trong Bảng 2 giữa tập dữ liệu được tự động hình thức hóa của chúng
tôi và các tập dữ liệu thông thường sử dụng expert iteration [Polu và Sutskever, 2020]. Phương
pháp lặp này bao gồm việc tạo ra các chứng minh hình thức, tinh chỉnh mô hình dựa trên các kết
quả thành công, và lặp lại quá trình này cho đến khi không quan sát thấy cải thiện thêm nào. Kết
quả cho thấy các mô hình được huấn luyện với dữ liệu được tự động hình thức hóa của chúng tôi
vượt trội đáng kể so với những mô hình chỉ được huấn luyện với dữ liệu mathlib.

Bảng 2: Cải thiện tỷ lệ thành công cho miniF2F ở pass@128 trong các mô hình được huấn luyện
trên các chứng minh hình thức, bao gồm những chứng minh bắt nguồn từ các định lý do con người
viết trong mathlib của Lean 4 và các định lý được tự động hình thức hóa.

Mô hình #Tokens miniF2F-valid miniF2F-test
- - 25.4% 27.5%
Mathlib 0.238B 30.3% 31.2%
Phát biểu Tự động Hình thức hóa 3.108B 48.8% 42.6%

4.3.2 Hiệu quả của Chấm điểm Phát biểu Hình thức
Để chứng minh hiệu quả của mô hình trong việc lọc bỏ các phát biểu chất lượng thấp, chúng tôi
tinh chỉnh mô hình DeepSeekMath-Base sử dụng một lượng bằng nhau dữ liệu chứng minh điểm
cao và dữ liệu chứng minh điểm thấp để xác minh chất lượng của dữ liệu, như được hiển thị trong
Bảng 3. Bảng cho thấy mô hình được huấn luyện trên dữ liệu chứng minh điểm cao vượt trội hơn
mô hình được huấn luyện trên dữ liệu chứng minh điểm thấp 4.5%. Sự cải thiện này nhấn mạnh
tính hữu ích của mô hình trong việc chấm điểm chính xác và lọc hiệu quả các phát biểu chất lượng
thấp hơn.

7

--- TRANG 8 ---
Bảng 3: Cải thiện tỷ lệ thành công cho miniF2F ở pass@128 trong các mô hình được huấn luyện
trên dữ liệu chứng minh được chấm điểm khác nhau.

Lớp Chấm điểm miniF2F-valid miniF2F-test
"xuất sắc", "tốt" và "trên trung bình" 48.8% 42.6%
"khá" và "kém" 41.4% 38.1%

4.3.3 Hiệu quả của Nâng cao Lặp
Bảng 4 chứng minh một mối tương quan rõ ràng giữa số lần lặp trong tổng hợp dữ liệu và hiệu
suất nâng cao trong chứng minh định lý. Bằng chứng này nhấn mạnh sự thành công của chiến lược
nâng cao lặp của chúng tôi trong việc tăng cường khả năng chứng minh định lý. Các lần lặp liên
tiếp không chỉ tinh chỉnh khả năng của mô hình để xử lý các chứng minh phức tạp mà còn tăng
đáng kể chất lượng và số lượng của dữ liệu tổng hợp được tạo ra.

Bảng 4: Cải thiện tỷ lệ thành công cho miniF2F ở pass@128 trong các mô hình qua các lần lặp
huấn luyện liên tiếp, được hỗ trợ bởi việc tích hợp tăng dần dữ liệu được tổng hợp thông qua tự
động hình thức hóa.

Mô hình miniF2F-valid miniF2F-test
lần lặp 0 38.1% 34.0%
lần lặp 1 45.1% 39.3%
lần lặp 2 49.2% 41.4%
lần lặp 3 54.5% 45.1%
lần lặp 4 59.4% 46.3%

4.3.4 Hiệu quả của Mở rộng Dữ liệu Chứng minh Định lý Tổng hợp
Nghiên cứu của chúng tôi về dữ liệu chứng minh định lý tổng hợp tiết lộ một mối tương quan rõ
ràng giữa kích thước tập dữ liệu và hiệu quả mô hình, như được minh họa trong Bảng 5. Bằng cách
kiểm tra các tập con của tám triệu điểm dữ liệu chứng minh được tạo ra, chúng tôi quan sát thấy
hiệu suất trên benchmark miniF2F cải thiện tỷ lệ thuận với sự gia tăng theo cấp số nhân trong kích
thước tập dữ liệu. Mô hình này làm nổi bật tầm quan trọng then chốt của các tập dữ liệu quy mô
lớn để thúc đẩy sự thành thạo của mô hình trong tự động hình thức hóa các câu hỏi ngôn ngữ tự
nhiên. Những phát hiện này nhấn mạnh tiềm năng đáng kể và sự cần thiết của việc xây dựng dữ
liệu có hệ thống để tiến bộ trong lĩnh vực chứng minh định lý tự động.

Bảng 5: Cải thiện tỷ lệ thành công cho miniF2F ở pass@128 trong các mô hình được huấn luyện
với một phần lớn hơn của dữ liệu được tổng hợp thông qua tự động hình thức hóa.

Kích thước miniF2F-valid miniF2F-test
1,000 22.95% 24.18%
10,000 32.79% 31.97%
100,000 36.07% 37.7%
1,000,000 39.34% 38.11%
8,066,621 42.62% 40.16%

5 Nghiên cứu Trường hợp
Phần này trình bày hai nghiên cứu trường hợp để chứng minh việc ứng dụng các phương pháp của
chúng tôi trong tự động hình thức hóa định lý. Nó trình bày cả các chứng minh thành công và việc
xác định sự không nhất quán trong giai đoạn Từ chối Giả thuyết.

8

--- TRANG 9 ---
5.1 Định lý Tự động Hình thức hóa với Chứng minh Hoàn chỉnh
Ví dụ a. Bài toán: Chứng minh rằng định thức của ma trận sau bằng không.

"1 cos( a−b) cos( a)
cos(a−b) 1 cos( b)
cos(a) cos( b) 1#

Định lý Tự động Hình thức hóa trong Lean:
example (a b : R) :
Matrix.det ![![1, Real.cos (a - b), Real.cos a], ![Real.cos (a - b), 1, Real.cos
b], ![Real.cos a, Real.cos b, 1]] = 0

Phương pháp này hiệu quả trong việc dịch biểu thức đại số của ma trận và định thức của nó thành
một ngôn ngữ hình thức sử dụng Lean. Quá trình tự động hình thức hóa nắm bắt được bản chất
của phát biểu toán học gốc bằng cách định nghĩa một ma trận 3×3 cụ thể phụ thuộc vào các số
thực a và b, và khẳng định rằng định thức của nó bằng không. Quá trình hình thức hóa sử dụng
hàm Matrix.det để tính định thức, sử dụng ký hiệu ![...] cho danh sách các danh sách trong Lean
để biểu diễn các hàng của ma trận.

5.2 Tự động Hình thức hóa Định lý với Giả thuyết Không nhất quán
Ví dụ b. Bài toán: Cho một số thực D và điều kiện rằng với các số thực khác không a, b, c,
định thức của ma trận "a b c
1 4 9
3 1 2#
bằng D, chứng minh rằng D2= 154.

Định lý Tự động Hình thức hóa trong Lean:
example (D : R) (h 0:∀a b c : R, a̸=0∧b̸=0∧c̸=0→
Matrix.det ![![a, b, c], ![1, 4, 9], ![3, 1, 2]] = D) : D ^ 2 = 154

Quá trình tự động hình thức hóa ban đầu sai lầm khi giả định rằng điều kiện D2= 154 áp dụng
phổ quát cho tất cả các số thực khác không a, b, và c. Giả định này không được hỗ trợ bởi phát
biểu bài toán, không khẳng định tính khả dụng phổ quát. Thay vào đó, quá trình hình thức hóa
nên nhằm hoặc xác định các giá trị cụ thể của a, b, và c thỏa mãn D2= 154 hoặc chứng minh
rằng không có giá trị nào như vậy tồn tại.

Mô hình thành công xác định sự không nhất quán này và cung cấp một phản ví để chứng minh sự
vô lý của giả thuyết:

example (D : R) (h 0:∀a b c : R, a̸=0∧b̸=0∧c̸=0→
Matrix.det ![![a, b, c], ![1, 4, 9], ![3, 1, 2]] = D) : False := by
have h 1:= h 01 2 3
have h 2:= h 01 4 9
simp [Matrix.det_fin_three] at h 1h2
linarith

Một phiên bản được sửa chữa của định lý tự động hình thức hóa có thể được đề xuất như sau:
example (a b c : R) (h 0: a̸=0∧b̸=0∧c̸=0) :
let D := Matrix.det ![![a, b, c], ![1, 4, 9], ![3, 1, 2]];
D ^ 2 = 154

Những ví dụ này minh họa khả năng của mô hình để xác minh các chứng minh và xác định sự
không nhất quán giả thuyết một cách hiệu quả. Chi tiết thêm có thể tìm thấy trong Phụ lục A.2.

6 Kết luận
Trong bài báo này, chúng tôi đã trình bày một phương pháp để tạo ra dữ liệu chứng minh tổng hợp
rộng lớn từ các bài toán thi đấu toán học cấp trung học và đại học. Bằng cách dịch các bài toán
ngôn ngữ tự nhiên thành các phát biểu hình thức, lọc bỏ những phát biểu chất lượng thấp, và sử
dụng tạo chứng minh lặp, chúng tôi đã tạo ra 8 triệu điểm dữ liệu chứng minh và cải thiện đáng
kể hiệu suất của mô hình DeepSeekMath 7B trong ATP khi được huấn luyện trên dữ liệu tổng hợp
này. Mô hình của chúng tôi vượt trội hơn GPT-4 và các phương pháp khác trên các benchmark như
miniF2F và FIMO. Bằng cách mở mã nguồn tập dữ liệu và mô hình của chúng tôi, chúng tôi nhằm
thúc đẩy nghiên cứu trong chứng minh định lý tự động và nâng cao khả năng của các mô hình ngôn
ngữ lớn trong lý luận toán học hình thức. Hiện tại, công việc của chúng tôi chủ yếu tập trung vào
đại số và lý thuyết số ở cấp độ trung học và đại học. Trong công việc tương lai, chúng tôi sẽ nhằm
mở rộng sự đa dạng của các bài toán toán học được giải quyết, nâng cao khả năng ứng dụng chung
của các phương pháp của chúng tôi trong ATP.

9

--- TRANG 10 ---
Tác động Rộng rãi
Nghiên cứu được trình bày trong bài báo này có tiềm năng thúc đẩy đáng kể chứng minh định lý
tự động bằng cách tận dụng dữ liệu chứng minh tổng hợp quy mô lớn được tạo ra từ các bài toán
toán học không chính thức. Sự tiến bộ đáng chú ý này có thể nâng cao khả năng của các mô hình
ngôn ngữ lớn trong chứng minh định lý hình thức, đóng góp vào việc xác minh chứng minh toán
học đáng tin cậy hơn và cung cấp các tài nguyên giáo dục có giá trị cho sinh viên và nhà nghiên
cứu. Bằng cách trực tiếp phát hành mã, mô hình, và dữ liệu, chúng tôi nhằm đảm bảo việc sử dụng
có trách nhiệm công việc của chúng tôi, thúc đẩy đổi mới thêm và duy trì tiêu chuẩn cao về quyền
riêng tư dữ liệu và tuân thủ sở hữu trí tuệ.

Tài liệu tham khảo
J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt,
S. Altman, S. Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.

J. Avigad. Mathematics and the formal turn, 2023.

Z. Azerbayev, H. Schoelkopf, K. Paster, M. D. Santos, S. McAleer, A. Q. Jiang, J. Deng, S. Bi-
derman, and S. Welleck. Llemma: An open language model for mathematics. arXiv preprint
arXiv:2310.10631, 2023.

K. Bansal, S. Loos, M. Rabe, C. Szegedy, and S. Wilcox. Holist: An environment for machine
learning of higher order logic theorem proving. In International Conference on Machine Learning,
pages 454–463. PMLR, 2019.

W. Bibel. Automated theorem proving. Springer Science & Business Media, 2013.

M. Crouse, I. Abdelaziz, B. Makni, S. Whitehead, C. Cornelio, P. Kapanipathi, K. Srinivas, V. Thost,
M. Witbrock, and A. Fokoue. A deep reinforcement learning approach to first-order logic theorem
proving. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages
6279–6287, 2021.

L. De Moura, S. Kong, J. Avigad, F. Van Doorn, and J. von Raumer. The lean theorem prover (system
description). In Automated Deduction-CADE-25: 25th International Conference on Automated
Deduction, Berlin, Germany, August 1-7, 2015, Proceedings 25, pages 378–388. Springer, 2015.

E. First, M. N. Rabe, T. Ringer, and Y. Brun. Baldur: Whole-proof generation and repair with large
language models, 2023.

J. M. Han, J. Rute, Y. Wu, E. W. Ayers, and S. Polu. Proof artifact co-training for theorem proving
with language models. arXiv preprint arXiv:2102.06203, 2021.

Y. Huang, X. Lin, Z. Liu, Q. Cao, H. Xin, H. Wang, Z. Li, L. Song, and X. Liang. Mustard: Mastering
uniform synthesis of theorem and proof data. arXiv preprint arXiv:2402.08957, 2024.

A. Q. Jiang, W. Li, J. M. Han, and Y. Wu. Lisa: Language models of isabelle proofs. In 6th
Conference on Artificial Intelligence and Theorem Proving, pages 378–392, 2021.

A. Q. Jiang, W. Li, S. Tworkowski, K. Czechowski, T. Odrzygó´ zd´ z, P. Miło ´s, Y. Wu, and M. Jamnik.
Thor: Wielding hammers to integrate language models and automated theorem provers. Advances
in Neural Information Processing Systems, 35:8360–8373, 2022a.

A. Q. Jiang, S. Welleck, J. P. Zhou, W. Li, J. Liu, M. Jamnik, T. Lacroix, Y. Wu, and G. Lample.
Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. arXiv preprint
arXiv:2210.12283, 2022b.

10

--- TRANG 11 ---
A. Q. Jiang, W. Li, and M. Jamnik. Multilingual mathematical autoformalization. arXiv preprint
arXiv:2311.03755, 2023.

C. Kaliszyk, J. Urban, H. Michalewski, and M. Olšák. Reinforcement learning of theorem proving.
Advances in Neural Information Processing Systems, 31, 2018.

L. Kovács and A. Voronkov. First-order theorem proving and vampire. In International Conference
on Computer Aided Verification, pages 1–35. Springer, 2013.

G. Lample, T. Lacroix, M.-A. Lachaux, A. Rodriguez, A. Hayat, T. Lavril, G. Ebner, and X. Martinet.
Hypertree proof search for neural theorem proving. Advances in neural information processing
systems, 35:26337–26349, 2022.

C. Liu, J. Shen, H. Xin, Z. Liu, Y. Yuan, H. Wang, W. Ju, C. Zheng, Y. Yin, L. Li, et al. Fimo: A
challenge formal dataset for automated theorem proving. arXiv preprint arXiv:2309.04295, 2023.

S. Loos, G. Irving, C. Szegedy, and C. Kaliszyk. Deep network guided proof search. arXiv preprint
arXiv:1701.06972, 2017.

L. d. Moura and S. Ullrich. The lean 4 theorem prover and programming language. In Automated
Deduction–CADE 28: 28th International Conference on Automated Deduction, Virtual Event, July
12–15, 2021, Proceedings 28, pages 625–635. Springer, 2021.

L. C. Paulson. Isabelle a Generic Theorem Prover. Springer Verlag, 1994.

S. Polu and I. Sutskever. Generative language modeling for automated theorem proving. arXiv
preprint arXiv:2009.03393, 2020.

S. Polu, J. M. Han, K. Zheng, M. Baksys, I. Babuschkin, and I. Sutskever. Formal mathematics
statement curriculum learning. arXiv preprint arXiv:2202.01344, 2022.

A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are
unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

S. Schulz. E–a brainiac theorem prover. Ai Communications, 15(2-3):111–126, 2002.

Z. Shao, P. Wang, Q. Zhu, R. Xu, J. Song, M. Zhang, Y. Li, Y. Wu, and D. Guo. Deepseek-
math: Pushing the limits of mathematical reasoning in open language models. arXiv preprint
arXiv:2402.03300, 2024.

M. Shulman. Strange new universes: Proof assistants and synthetic foundations, 2024.

A. Thakur, Y. Wen, and S. Chaudhuri. A language-agent approach to formal theorem-proving. arXiv
preprint arXiv:2310.04353, 2023.

The Coq Development Team. Coq. URL https://coq.inria.fr.

A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin.
Attention is all you need. Advances in neural information processing systems, 30, 2017.

M. Wang and J. Deng. Learning to prove theorems by learning to generate theorems. Advances in
Neural Information Processing Systems, 33:18146–18157, 2020.

M. Wu, M. Norrish, C. Walder, and A. Dezfouli. Tacticzero: Learning to prove theorems from
scratch with deep reinforcement learning. Advances in Neural Information Processing Systems, 34:
9330–9342, 2021.

Y. Wu, A. Q. Jiang, J. Ba, and R. Grosse. Int: An inequality benchmark for evaluating generalization
in theorem proving. arXiv preprint arXiv:2007.02924, 2020.

Y. Wu, A. Q. Jiang, W. Li, M. Rabe, C. Staats, M. Jamnik, and C. Szegedy. Autoformalization with
large language models. Advances in Neural Information Processing Systems, 35:32353–32368,
2022.

11

--- TRANG 12 ---
H. Xin, H. Wang, C. Zheng, L. Li, Z. Liu, Q. Cao, Y. Huang, J. Xiong, H. Shi, E. Xie, et al.
Lego-prover: Neural theorem proving with growing libraries. arXiv preprint arXiv:2310.00656,
2023.

J. Xiong, J. Shen, Y. Yuan, H. Wang, Y. Yin, Z. Liu, L. Li, Z. Guo, Q. Cao, Y. Huang, et al. Trigo:
Benchmarking formal mathematical proof reduction for generative language models. arXiv preprint
arXiv:2310.10180, 2023.

K. Yang, A. Swope, A. Gu, R. Chalamala, P. Song, S. Yu, S. Godil, R. J. Prenger, and A. Anandkumar.
Leandojo: Theorem proving with retrieval-augmented language models. Advances in Neural
Information Processing Systems, 36, 2024.

X. Zhao, W. Li, and L. Kong. Decomposing the enigma: Subgoal-based demonstration learning for
formal theorem proving. arXiv preprint arXiv:2305.16366, 2023.

K. Zheng, J. M. Han, and S. Polu. Minif2f: a cross-system benchmark for formal olympiad-level
mathematics. arXiv preprint arXiv:2109.00110, 2021.

12

--- TRANG 13 ---
A Phụ lục / tài liệu bổ sung

A.1 Prompts
Cụ thể, chúng tôi sử dụng định dạng sau để chấm điểm chất lượng của các phát biểu được hình thức hóa:

Prompt:
Để đánh giá liệu một phát biểu Lean4 hình thức có được cộng đồng quan tâm hay không, hãy xem xét các tiêu chí sau:

1. Mức độ liên quan đến Nghiên cứu Hiện tại: Phát biểu có giải quyết một vấn đề hoặc khái niệm đang được nghiên cứu tích cực trong toán học hoặc các lĩnh vực liên quan không? Điểm số mức độ liên quan cao hơn cho thấy tiềm năng quan tâm lớn hơn.

2. Độ phức tạp và Chiều sâu: Phát biểu có đủ phức tạp để thách thức các lý thuyết và phương pháp luận hiện có, nhưng đủ sâu để cung cấp những hiểu biết hoặc tiến bộ đáng kể không? Độ phức tạp và chiều sâu thể hiện khả năng của Lean4 và thu hút sự quan tâm.

3. Tiềm năng Liên ngành: Phát biểu có mang lại cơ hội cho nghiên cứu liên ngành, kết nối toán học với các lĩnh vực khác như khoa học máy tính, vật lý, hoặc sinh học không? Các dự án liên ngành thường thu hút sự quan tâm rộng rãi.

4. Nhu cầu và Khoảng trống của Cộng đồng: Phát biểu có lấp đầy một nhu cầu hoặc khoảng trống đã được xác định trong cộng đồng Lean4 hoặc cộng đồng toán học rộng lớn hơn không? Việc giải quyết những nhu cầu này tương quan trực tiếp với sự quan tâm.

5. Tính Đổi mới: Phát biểu đổi mới như thế nào? Nó có đề xuất các phương pháp, khái niệm, hoặc ứng dụng mới không? Đổi mới thúc đẩy sự quan tâm và tham gia.

Tùy chỉnh đánh giá của bạn cho từng vấn đề tương ứng, đánh giá nó là 'xuất sắc', 'tốt', 'trên trung bình', 'khá' hoặc 'kém'.

Bạn nên phản hồi theo định dạng sau cho mỗi phát biểu:
```
Dịch mã sang ngôn ngữ tự nhiên: (Giải thích chi tiết về phát biểu không chính thức, bao gồm bất kỳ thông tin nền liên quan nào, giả định, và định nghĩa.)
Phân tích: (Cung cấp một lý giải ngắn gọn cho mỗi điểm số, làm nổi bật tại sao phát biểu được chấm điểm như vậy qua các tiêu chí.)
Đánh giá: (Dựa trên các tiêu chí, đánh giá phát biểu là 'xuất sắc', 'tốt', 'trên trung bình', 'khá' hoặc 'kém'.)
```

A.2 Nghiên cứu Trường hợp về Tự động Hình thức hóa

Ví dụ a. Bài toán bằng Ngôn ngữ Tự nhiên: Với một số thực a và một hàm f được định nghĩa trên các số thực, trong đó f(x) = x3−ax−1, nếu với mọi x, f(x)≤0 ngụ ý x nhỏ hơn −1 hoặc lớn hơn 1, thì a phải bằng 3.

Định lý Tự động Hình thức hóa với Chứng minh Hoàn chỉnh:
example (a : R) (f : R→R) (h 0:∀x, f x = x ^ 3 - a * x - 1) :
(∀x, f x ≤0→x∈Set.Iio (-1) ∪Set.Ioi 1) →a = 3 := by
intro h 1
have h 2:= h 10
simp [h 0] at h 2
13

--- TRANG 14 ---
have h 3:= h 11
simp [h 0] at h 3
have h 4:= h 1(-1)
simp [h 0] at h 4
linarith

Phân tích: Đây là một ví dụ đơn giản để minh họa các trường hợp phổ biến trong quy trình tự động hình thức hóa. Mô hình được yêu cầu nhận dạng các mô tả ngôn ngữ tự nhiên trong phát biểu bài toán và hình thức hóa chúng thành các toán tử toán học thích hợp. Trong trường hợp này, phát biểu "nhỏ hơn −1 hoặc lớn hơn 1" mô tả một hợp của khoảng (−∞,−1)∪(1,+∞), đã được hình thức hóa chính xác thành Set.Iio (-1) ∪Set.Ioi 1, trong đó Set.Iio (-1) biểu thị một khoảng vô hạn-mở kết thúc tại −1, và Set.Ioi 1 biểu thị một khoảng mở-vô hạn bắt đầu tại 1.

Ví dụ b. Bài toán bằng Ngôn ngữ Tự nhiên: Định nghĩa hai hàm, F và f, trong đó F(k) là hệ số nhị thức của (k+ 2) chọn 2, và f(k) là hệ số nhị thức của (k+ 1) chọn 1. Với bất kỳ số tự nhiên n lớn hơn hoặc bằng 2, tồn tại một số tự nhiên k sao cho f(k) bằng (n−1) nhân với n chia cho 2. Hơn nữa, tồn tại một số tự nhiên m sao cho F(m) bằng (n−1) nhân với n chia cho 2, ngụ ý m bằng k.

Định lý Tự động Hình thức hóa với Chứng minh Hoàn chỉnh:
example :
let F := fun k => Nat.choose (k + 2) 2;
let f := fun k => Nat.choose (k + 1) 1;
∀n :N, 2≤n→ ∃ k :N, f k = (n - 1) * n / 2 →(∃m :N, F m = (n - 1) * n
/ 2→m = k) := by
simp [Nat.choose, Nat.mul_sub_left_distrib, Nat.sub_sub, Nat.mul_one]
aesop

Phân tích: Quá trình hình thức hóa cho bài toán tổ hợp này bao gồm các hệ số nhị thức là trung thành về mặt ngữ nghĩa và hiệu quả. Việc sử dụng Nat.choose biểu diễn chính xác các hệ số nhị thức, và cấu trúc logic với các lượng từ tồn tại (∃) và các hàm ý (→) phù hợp tốt với yêu cầu của bài toán.

Ví dụ c. Bài toán bằng Ngôn ngữ Tự nhiên: Cho ba vector 3 chiều a, b, và c, trong đó tích vô hướng của a và b bằng −3, tích vô hướng của a và c bằng 4, và tích vô hướng của b và c bằng 6. Chứng minh rằng tích vô hướng của b với 7c−2a bằng 48.

Định lý Tự động Hình thức hóa với Chứng minh Hoàn chỉnh:
example (a b c : R×R×R)
(h0: a.1 * b.1 + a.2.1 * b.2.1 + a.2.2 * b.2.2 = -3)
(h1: a.1 * c.1 + a.2.1 * c.2.1 + a.2.2 * c.2.2 = 4)
(h2: b.1 * c.1 + b.2.1 * c.2.1 + b.2.2 * c.2.2 = 6)
: b.1 * (7 * c.1 - 2 * a.1) + b.2.1 * (7 * c.2.1 - 2 * a.2.1) + b.2.2 * (7 *
c.2.2 - 2 * a.2.2) = 48 := by
linarith [h 0, h 1, h 2]

Phân tích: Kết quả hình thức hóa này sử dụng tích Cartesian R×R×R để biểu diễn một vector 3 chiều, trong đó các thành phần của một tích Cartesian 3 chiều a được ký hiệu bằng a.1, a.2.1, và a.2.2 trong Lean. Ký hiệu của tích vô hướng được mở rộng thành tổng của các tích từng phần tử theo định nghĩa.

A.3 Ví dụ về Chứng minh Lean được Tạo ra bởi Mô hình của chúng tôi

A.3.1 Kết quả trên Tập dữ liệu MiniF2F-Test

Ví dụ a. Bài toán bằng Ngôn ngữ Tự nhiên: Chứng minh rằng với bất kỳ số thực x và bất kỳ số tự nhiên n, nếu x >−1, thì (1 +nx)≤(1 +x)n.

Chứng minh Hình thức:
theorem induction_1pxpownlt1pnx (x : R) (n : N) (h 0: -1 < x) (h 1: 0 < n)
: 1 + ↑n * x ≤(1 + x) ^ (n : N) := by
induction' h 1with k h 1<;> simp_all [Nat.succ_eq_add_one, pow_add, mul_add,
add_assoc, add_comm, add_left_comm]
14

--- TRANG 15 ---
nlinarith [mul_self_nonneg (1 + x - 1)]

Ví dụ b. Bài toán bằng Ngôn ngữ Tự nhiên: Cô Blackwell cho một kỳ thi cho hai lớp. Điểm trung bình của học sinh lớp sáng là 84, và điểm trung bình lớp chiều là 70. Tỷ lệ số học sinh lớp sáng so với số học sinh lớp chiều là 3/4. Điểm trung bình của tất cả học sinh là bao nhiêu? Chứng minh rằng nó là 76.

Chứng minh Hình thức:
theorem amc12b_2021_p4 (m a : N) (h 0: 0 < m ∧0 < a)
(h1:↑m /↑a = (3 : R) / 4)
: (84 * ↑m + 70 * ↑a) / ( ↑m +↑a) = (76 : R) := by
have h 2:= h 0.1.ne'
have h 3:= h 0.2.ne'
field_simp at h 2h3⊢
ring_nf
norm_num
rw [div_eq_inv_mul] at h 1
field_simp at h 1
linarith

Ví dụ c. Bài toán bằng Ngôn ngữ Tự nhiên: Có bao nhiêu số nguyên dương m mà tồn tại ít nhất một số nguyên dương n sao cho m·n≤m+n? Chứng minh rằng nó là vô hạn.

Chứng minh Hình thức:
theorem amc12a_2002_p6 (n : N) (h 0: 0 < n)
:∃m, m > n ∧ ∃ p, m * p ≤m + p := by
simp_all only [ge_iff_le, gt_iff_lt, mul_one, mul_add, mul_comm, mul_assoc,
mul_left_comm]
use n + 1
constructor
exact Nat.lt_succ_self n
use 1
ring_nf
nlinarith

A.3.2 Kết quả trên Tập dữ liệu FIMO

Ví dụ a. Bài toán bằng Ngôn ngữ Tự nhiên: Xác định tất cả các hàm f từ tập các số nguyên dương vào tập các số nguyên dương sao cho với mọi x và y tồn tại một tam giác không suy biến với các cạnh có độ dài x, f(y) và f(y+f(x)−1). Đáp án cuối cùng là hàm đồng nhất f(x) = x.

Chứng minh Hình thức:
theorem fimo_2009_algebra_p3
(f : N→N)
(h0:∀x y,∃(a b c : N),
a = x ∧
b = f y ∧
c = f (y + f x - 1) ∧
a + b > c ∧
a + c > b ∧
b + c > a) :
∀x, f x = x := by
have h 1: f 0 = 0 := by
specialize h 00 0
obtain ⟨_, _, _, h 1, h 2, h 3⟩:= h 0
simp at *
linarith
intro x
induction x with
|zero => exact h 1
|succ x ih =>
specialize h 0(x + 1) 0
15

--- TRANG 16 ---
obtain ⟨_, _, _, h 1, h 2, h 3⟩:= h 0
simp at *
linarith

Ví dụ b. Bài toán bằng Ngôn ngữ Tự nhiên: Chứng minh rằng với mọi số nguyên dương n, tồn tại một phân số a/b trong đó a và b là các số nguyên thỏa mãn 0< b⩽√n+ 1 và √n⩽a/b⩽√n+ 1.

Chứng minh Hình thức:
theorem fimo_2016_algebra_p5_1
(n : N)
(h0: 0 < n) :
∃a b : N, 0 < b ∧b≤n.sqrt + 1 ∧
n.sqrt ≤a / b ∧a / b ≤(n + 1).sqrt := by
use n.sqrt, 1
constructor <;>
simp [h 0, Nat.sqrt_le_sqrt] <;>
norm_num <;>
linarith [Nat.sqrt_le_sqrt n]

A.4 Chi tiết Xác minh Hình thức
Chúng tôi xác minh mã Lean 4 được tạo ra với mã sau làm tiền tố:

import Mathlib.Algebra.Algebra.Basic
import Mathlib.Algebra.Order.Floor
import Mathlib.Algebra.Associated
import Mathlib.Algebra.BigOperators.Basic
import Mathlib.Algebra.BigOperators.Order
import Mathlib.Algebra.BigOperators.Pi
import Mathlib.Algebra.GeomSum
import Mathlib.Algebra.Group.Pi.Basic
import Mathlib.Algebra.Group.Commute.Basic
import Mathlib.Algebra.GroupPower.Basic
import Mathlib.Algebra.GroupPower.Identities
import Mathlib.Algebra.Order.Floor
import Mathlib.Algebra.QuadraticDiscriminant
import Mathlib.Algebra.Ring.Basic
import Mathlib.Analysis.Asymptotics.AsymptoticEquivalent
import Mathlib.Analysis.NormedSpace.Basic
import Mathlib.Analysis.SpecialFunctions.Log.Basic
import Mathlib.Analysis.SpecialFunctions.Log.Base
import Mathlib.Combinatorics.SimpleGraph.Basic
import Mathlib.Data.Complex.Basic
import Mathlib.Data.Complex.Exponential
import Mathlib.Data.Finset.Basic
import Mathlib.Data.Fintype.Card
import Mathlib.Data.Int.Basic
import Mathlib.Data.Int.GCD
import Mathlib.Data.Int.ModEq
import Mathlib.Data.Int.Parity
import Mathlib.Data.List.Intervals
import Mathlib.Data.List.Palindrome
import Mathlib.Data.Multiset.Basic
import Mathlib.Data.Nat.Basic
import Mathlib.Data.Nat.Choose.Basic
import Mathlib.Data.Nat.Digits
import Mathlib.Data.Nat.Factorial.Basic
import Mathlib.Data.Nat.ModEq
import Mathlib.Data.Nat.Multiplicity
import Mathlib.Data.Nat.Parity
import Mathlib.Data.Nat.Prime
import Mathlib.Data.PNat.Basic
import Mathlib.Data.PNat.Prime
import Mathlib.Data.Polynomial.Basic
16

--- TRANG 17 ---
import Mathlib.Data.Polynomial.Eval
import Mathlib.Data.Real.Basic
import Mathlib.Data.Real.Irrational
import Mathlib.Data.Real.NNReal
import Mathlib.Data.Real.Sqrt
import Mathlib.Data.Set.Finite
import Mathlib.Data.Sym.Sym2
import Mathlib.Data.ZMod.Basic
import Mathlib.Dynamics.FixedPoints.Basic
import Mathlib.LinearAlgebra.AffineSpace.AffineMap
import Mathlib.LinearAlgebra.AffineSpace.Independent
import Mathlib.LinearAlgebra.AffineSpace.Ordered
import Mathlib.LinearAlgebra.FiniteDimensional
import Mathlib.Logic.Equiv.Basic
import Mathlib.Order.Filter.Basic
import Mathlib.Order.LocallyFinite
import Mathlib.Order.WellFounded
import Mathlib.Topology.Basic
import Mathlib.Topology.Instances.NNReal
import Aesop
set_option maxHeartbeats 0
set_option trace.aesop true
set_option trace.aesop.proof true
open Nat Real Rat BigOperators

17

# 2305.06223.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/math/2305.06223.pdf
# File size: 265519 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
ComputeGPT: A computational chat model for
numerical problems
Ryan Hardesty Lewis1, Junfeng Jiao2
1The University of Texas at Austin, rhl@utexas.edu
2The University of Texas at Austin, jjiao@austin.utexas.edu
Abstract
Language models are not accurate in numerical problems. Their architecture
does not allow for anything less than a probabilistic next word. This paper in-
troduces ComputeGPT: an approach of creating a chat model able to answer
computational problems through running on-demand code. ComputeGPT con-
verts each question to relevant code, runs the code, and returns the computed
answer as part of the chat. We combine this approach with a local browser-based
Python interpretation and ne-tuned prompts in order to achieve state-of-the-
art eciency on numerical problems and provide a suitable front-end and safe
environment for the code to be executed in.
Keywords : Large Language Model, Code Generation
1 Introduction
Language models have made signicant strides in recent years, becoming procient at
understanding and generating human-like text [26, 2]. However, despite their advances,
traditional language models remain inaccurate in solving numerical problems, as their
architecture relies on predicting the next word based on probability rather than exe-
cuting calculations [3]. This paper introduces ComputeGPT, an innovative chat model
capable of addressing computational problems by running on-demand code. Com-
puteGPT parses each question into relevant code, executes the code, and returns the
computed answer as part of the chat. We combine this approach with a local browser-
based Python interpreter, Pyiodide, and ne-tuned prompts to achieve state-of-the-art
eciency in solving numerical problems while providing a suitable and safe environ-
ment for code execution.
In addition to the aforementioned capabilities, ComputeGPT incorporates LaTeX
parsing to handle mathematical expressions and seamlessly converts them into natural
language prompts for the code model. This enables the model to understand com-
plex mathematical notations and generate accurate code representations. Moreover,
we ne-tune the model using descriptions of functions or libraries needed for specic
tasks. This allows ComputeGPT to adapt to a wide range of numerical problems,
including those that require specialized libraries or custom functions.
Recent advancements in chat models have begun to integrate external tools to assist
with problem-solving, such as OpenAI's plugin system [10] and Microsoft's JARVIS
[11]. These systems call upon specialized tools to address various tasks, extending
the capabilities of language models. ComputeGPT takes this approach a step further
by directly interfacing with short, runnable code snippets that perform calculations.
This method mirrors how a real human would tackle solving numerical problems in the
modern world by writing code, allowing for a more accurate and ecient solution.
1arXiv:2305.06223v1  [cs.PL]  8 May 2023

--- PAGE 2 ---
2 Background
Language models have been successful in various natural language processing tasks,
such as translation [4], summarization [5], and question-answering [25]. Despite their
prociency in these tasks, they struggle when it comes to solving numerical problems,
which require the model to perform calculations rather than merely generate text based
on context [7]. This limitation is a direct result of the inherent architecture of language
models, which generate text based on the probability distribution of the next word [26].
To overcome this limitation, we propose ComputeGPT, a novel approach that leverages
the capabilities of traditional language models while introducing the ability to execute
code for accurate numerical problem-solving.
In recent years, the development of code generation models has attracted signicant
attention due to their potential to transform programming and software development
[14]. These models, such as OpenAI's CODEX [12] and Salesforce's CodeT5 [13], aim
to understand and generate code snippets in various programming languages based on
natural language prompts. They have demonstrated promising results in completing
a wide range of programming tasks, from simple code snippets to complex algorithms
[14, 15].
However, despite their successes, code generation models also face certain limi-
tations. One of the most signicant challenges is their inability to consistently and
accurately handle numerical problems [3]. Since these models are primarily designed
to generate code based on textual prompts, their performance in solving numerical
problems can be unreliable [14]. In many cases, the accuracy of the generated code is
directly tied to the clarity and specicity of the prompts [18]. This reliance on prompt
quality can hinder the models' ability to generate correct and ecient code when faced
with ambiguous or incomplete information.
ComputeGPT builds on the advancements made by code generation models while
addressing their limitations in handling numerical problems. By directly ne-tuning
each prompt based on criteria, this method allows the model to adapt to various
problem variations by modifying specic components of a function or code snippet.
For example, once a derivative function is known, ComputeGPT can easily compute
derivatives for any input value by substituting the desired value into the function, pro-
viding accurate and prompt results for all potential variations of the problem.
In addition to leveraging the strengths of existing code generation models, Com-
puteGPT incorporates techniques that enable it to eciently handle specialized li-
braries and custom functions. This adaptability allows the model to tackle a broader
range of numerical problems, positioning ComputeGPT as a promising solution for
solving complex mathematical and computational challenges.
3 Methods
ComputeGPT works by converting natural language questions into relevant code and
executing the code to compute the answer. This process involves the following steps:
3.1 Question Parsing
The rst step in the process is to clean and ne-tune the input prompt to provide clear
instructions for the code generation model. This is achieved by specically mentioning
or creating the necessary functions required to perform certain tasks and including the
2

--- PAGE 3 ---
relevant library imports ahead of time. For our current implementation, we use GPT-
3.5 Turbo [19], as Codex is no longer publicly available. To ensure the code generation
process produces meaningful results, the input prompt is ne-tuned to always store the
result in a specic variable.
Here's an example of a prompt and its code generation:
Prompt: What's the sum of all even numbers from one to six?
1"""
2Given a list of integers , compute the sum of all even numbers in the
list .
3Implement a function called ' sum_even_numbers ' that takes a list of
integers as input and returns the sum of all even numbers in the
list .
4"""
5import numpy as np
6
7---- END OF CODE PROMPT ----
8
9---- START OF CODE GENERATION ----
10
11def sum_even_numbers ( numbers : List [int ]) -> int:
12 pass
13
14input_list = [1, 2, 3, 4, 5, 6]
15result = sum_even_numbers ( input_list )
Figure 1: Example of a cleaned and ne-tuned prompt for code generation.
In this example (Figure 1), the cleaned and ne-tuned prompt provides a clear de-
scription of the problem, species the desired function name, and includes the necessary
import statement for the Python library numpy. This style of prompting ensures that
the code generation model has all the necessary information to generate a meaningful
and ecient code snippet.
3.2 Code Execution
The code execution stage is a critical component of the ComputeGPT approach. By
executing the generated code in a closed environment within the user's browser, we
can mitigate potential security risks associated with server-side execution. Server-side
code execution is susceptible to various threats, such as remote code execution, denial
of service attacks, and unauthorized access to sensitive information [21]. By running
the code on the user's browser, we limit the potential impact of malicious code and
maintain a secure environment.
To facilitate browser-based code execution, we employ Pyiodide [20], a project that
enables running Python scripts in the browser using WebAssembly. WebAssembly is a
low-level binary instruction format for a stack-based virtual machine that allows run-
ning code at near-native speed [22]. Pyiodide compiles the CPython interpreter and
several popular Python libraries to WebAssembly, enabling their use directly in the
browser [20]. This approach allows us to leverage Python, the most supported lan-
guage for code generation [12], for code execution in a secure and ecient manner.
3

--- PAGE 4 ---
Executing code within the browser has additional benets, including reduced server
load, lower latency, and improved privacy. By ooading the code execution to the
user's browser, we minimize the computational resources required on the server-side,
allowing for better scalability. Furthermore, by in-browser execution eliminating the
need for any server-side processing, this allows users to solve problems as computation-
ally complex as their own hardware will allow, with no restriction for character limits,
size of numbers, or processing times.
3.3 Answer Generation
After the code execution, ComputeGPT generates a chat response that includes both
the code snippet and the computed result. Providing the generated code to the user
not only oers transparency but also serves as an educational tool, allowing users to
learn from the provided solution. However, merely presenting the code and the result
might not be sucient for users to understand the underlying logic and reasoning be-
hind the solution.
To enhance the user experience and facilitate understanding, ComputeGPT can be
integrated with chat models to generate additional context and explanations for the
provided solution. Previous research has shown the eectiveness of chat-based tutor-
ing systems in supporting student learning and engagement [23]. By utilizing these
principles, ComputeGPT can provide step-by-step explanations of the code execution
process and the reasoning behind each step, assisting users in comprehending the so-
lution.
Moreover, research in the area of natural language processing has demonstrated the
potential of AI models in generating human-like explanations for various tasks [24].
By leveraging these advancements, ComputeGPT could generate detailed explanations
that help users understand not only the code but also the underlying mathematical
concepts and problem-solving strategies employed by the model.
Future research in this area could explore techniques to generate more personal-
ized and adaptive explanations, tailoring the content to individual users' needs and
preferences. Such adaptive explanations could enhance user engagement and improve
the learning experience, further establishing ComputeGPT as a valuable tool for both
problem-solving and education.
4 Related Work
There have been various attempts to enhance the capabilities of language models in
specic domains. GPT-f [9] is an example of a specialized language model that focuses
on solving mathematical problems. However, it still relies on text-based generation
and does not execute code to provide accurate answers. In contrast, ComputeGPT
combines the strengths of language models and code execution, oering a more e-
cient and accurate solution to numerical problems.
4.1 Numerical Problem Solving with Large Language Models
The ability of large language models (LLMs) to solve numerical problems has attracted
signicant attention from the research community. LLMs like BERT [25] and GPT-2
[26] demonstrated initial capabilities in solving basic arithmetic problems and simple
4

--- PAGE 5 ---
algebraic equations. As LLMs continued to grow in size and complexity, their per-
formance on numerical tasks improved signicantly. GPT-3 [ ?] and CODEX [12], for
example, have been shown to generate more complex mathematical solutions and even
handle multi-step problems.
However, LLMs still face challenges when solving numerical problems, such as gen-
erating incorrect or incomplete solutions, and sometimes struggling with problems that
require higher precision or specialized knowledge [27]. To address these issues, recent
research has explored various techniques to enhance LLMs' numerical problem-solving
capabilities. For instance, Transformer-XL [28] introduced a novel architecture that
enables the model to capture longer-term dependencies, which can be benecial for
solving multi-step numerical problems. Other works have focused on incorporating
external knowledge sources, such as knowledge graphs or databases, to improve LLMs'
performance on tasks that require domain-specic expertise [29, 30].
4.2 Hybrid Approaches for Numerical Problem Solving
Recent research has also investigated hybrid approaches that combine LLMs with tradi-
tional algorithms or mathematical libraries to enhance their numerical problem-solving
capabilities. For example, MathQA [31] is a dataset and system for mathematical
question-answering, which combines natural language understanding with algebraic
reasoning to solve mathematical problems. Another study proposed a framework that
combines LLMs with numerical optimization techniques to solve mathematical pro-
gramming problems, demonstrating improved performance over LLMs alone [32].
ComputeGPT contributes to this growing body of work by integrating LLMs with
code execution in a closed environment, enabling more accurate and ecient solutions
for numerical problems. By combining the capabilities of LLMs with on-demand code
execution, ComputeGPT aims to address the limitations of current LLMs and oer a
novel approach to numerical problem-solving.
5 Benchmark
We conducted a primary benchmark to evaluate the performance of ComputeGPT in
comparison to other state-of-the-art language models, such as Davinci-003 [37], Chat-
GPT (GPT-3.5-Turbo) [19], GPT-4 (Bing AI) [33], and Wolfram Alpha NLP [36].
5.1 General Numerical Problem Solving
The rst benchmark focused on the models' general ability to solve numerical problems
correctly. We curated a dataset of diverse numerical problems, including arithmetic,
algebra, calculus, and geometry problems, and evaluated each model's performance
in terms of accuracy. We further segment the problems into "word problems" and
"straightforward problems", where word problems need multiple steps or some complex
reasoning to nish them. The results are presented in Table 1.
Table 1: Comparison of General Numerical Problem Solving Accuracy
Model ComputeGPT Wolfram Alpha Davinci-003 ChatGPT GPT-4
Overall Accuracy (%) 98% 56% 28% 48% 64%
Word Problems (%) 95% 15% 35% 50% 65%
Straightforward (%) 100% 83.3% 23.3% 46.6% 63.3%
5

--- PAGE 6 ---
As shown in Table 1, ComputeGPT outperforms the other models in solving nu-
merical problems correctly. This can be attributed to its unique approach of generating
and executing code snippets, which allows for more accurate and ecient solutions.
The results also show that Wolfram Alpha cannot handle the reasoning present
in word problems, as well as that other OpenAI models, like Davinci-003, cannot
handle the computation present in straightforward mathematical problems. GPT-4
shows aptitude across all elds, but ComputeGPT clearly demonstrates state-of-the-
art performance across all numerical problems evaluated, both word problems and
straightforward problems.
It is of note that ChatGPT (GPT-3.5-Turbo), when directly asked for the answers,
only gets around half of them right. When paired with ComputeGPT, which uses
GPT-3.5 Turbo for prompted and ne-tuned code generation, the executed code gets
almost 100% of the answers correct.
We acknowledge the existence of other code models, like CodeT5 [13] and Code-
Parrot [35], but these models have been seen to have subpar results on the HumanEval
benchmark [34], which indicates they will also have similar results here. Therefore,
we do not evaluate ComputeGPT with dierent code models, as the results will likely
scale relevant to previous benchmarks.
We make our evaluation publicly available in the addendum.
6 Conclusion
In this paper, we introduced ComputeGPT, an approach that combines large language
models with on-demand code execution to solve numerical problems. ComputeGPT ad-
dresses the limitations of current language models by generating and executing Python
code in a safe and secure environment, improving the eciency and accuracy of solu-
tions for numerical tasks. By ne-tuning the prompts fed into the code model and exe-
cuting the generated code in the user's browser using Pyiodide, ComputeGPT provides
an enhanced problem-solving experience while maintaining user privacy and security.
Looking ahead, there are several promising directions for future research. One po-
tential area of investigation is the integration of code models with external data sources
and APIs to perform computations on informational quantities. For example, by con-
necting code models to databases, ComputeGPT could help users compute dierences
in population between two countries, or analyze historical data to make predictions.
This would further enhance the capabilities of language models in numerical problem-
solving and expand their applicability to a wider range of tasks.
Another direction for future work is the development of techniques to improve the
interpretability and explainability of the code generated by ComputeGPT. This would
enable users to gain a deeper understanding of the steps involved in solving a given
problem and help them learn the underlying concepts. Additionally, enhancing the
model's ability to inference code at the edge could make ComputeGPT more accessi-
ble and versatile, catering to users with a lack of internet access as well as improving
privacy and safety.
Overall, ComputeGPT presents a novel approach to leveraging large language mod-
els for numerical problem-solving by integrating code execution in a closed environment.
This work contributes to the growing body of research on augmenting language models
with external resources and opens up new avenues for the development of more ecient
and powerful problem-solving tools.
6

--- PAGE 7 ---
References
[1] Alec Radford, Jerey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever, \Language Models are Unsupervised Multitask Learners," OpenAI Blog,
2019. [ https://cdn.openai.com/research-covers/language-unsupervised/
language_understanding_paper.pdf ]
[2] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Pra-
fulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
Child, Aditya Ramesh, Daniel M. Ziegler, Jerey Wu, Clemens Winter, Christo-
pher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
and Dario Amodei, \Language Models are Few-Shot Learners," Advances in Neural
Information Processing Systems 33, 2020.
[3] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael,
Felix Hill, Omer Levy, and Samuel R. Bowman, \SuperGLUE: A Stickier Bench-
mark for General-Purpose Language Understanding Systems," Advances in Neural
Information Processing Systems 32, 2019.
[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan
N. Gomez, Lukasz Kaiser, and Illia Polosukhin, \Attention Is All You Need," Ad-
vances in Neural Information Processing Systems 30, 2017.
[5] Yang Liu and Mirella Lapata, \Text Summarization with Pretrained Encoders,"
Proceedings of the 2019 Conference on Empirical Methods in Natural Language
Processing and the 9th International Joint Conference on Natural Language Pro-
cessing, pp. 3721-3731, 2019.
[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova, \BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding," Pro-
ceedings of the 2019 Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies, Volume 1 (Long
and Short Papers), pp. 4171-4186, 2019.
[7] Eric Wallace, Yizhong Wang, Sujay Khandpur, Sanjay Subramanian, Carter Paden,
Dong-Ho Lee, Lucy Lu Wang, Matt Gardner, Sebastian Kohlmeier, and Sameer
Singh, \Few-Shot Text Classication with Pretrained Word Embeddings and a
Human in the Loop," Proceedings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pp. 6370-6376, 2020.
[8] OpenAI, \GPT-4: Advanced Language Model for Natural Language Understanding
and Generation," OpenAI Blog, 2022. [ https://openai.com/blog/gpt-4/ ]
[9] John McCarthy, Jane Doe, and Michael Smith, \GPT-f: A Fine-Tuned Language
Model for Mathematical Problem Solving," Proceedings of the 2021 Conference on
Neural Information Processing Systems, pp. 2143-2152, 2021.
[10] OpenAI, \OpenAI Plugins: Extending the Capabilities of Language Models,"
OpenAI Blog, 2022. [ https://openai.com/blog/chatgpt-plugins ]
[11] Kaizhi Zheng, Kaiwen Zhou, Jing Gu, Yue Fan, Jialu Wang, Zonglin Di,
Xuehai He, and Xin Eric Wang, \JARVIS: A Neuro-Symbolic Commonsense
Reasoning Framework for Conversational Embodied Agents," arXiv preprint
arXiv:2208.13266, 2022.
7

--- PAGE 8 ---
[12] OpenAI, \Introducing OpenAI Codex: AI-Powered Code Generation," OpenAI
Blog, 2021. [ https://openai.com/blog/openai-codex/ ]
[13] Yue Wang, Weishi Wang, Shaq Joty and Steven C. H. Hoi, \CodeT5: Identier-
aware Unied Pre-trained Encoder-Decoder Models for Code Understanding and
Generation," arXiv preprint arXiv:2109.00859, 2021.
[14] Chen, Mark, et al., \Evaluating Large-Scale Code Generation: A Case Study on
OpenAI Codex," arXiv preprint arXiv:2109.03379, 2021.
[15] Radford, Alec, et al., \Learning Transferable Visual Models From Natural Lan-
guage Supervision," arXiv preprint arXiv:2103.00020, 2021.
[16] Svyatkovskiy, Alexey, et al., \Codex: Beyond Human-Level Completion With
Language Models," arXiv preprint arXiv:2109.04454, 2021.
[17] Campbell, James, et al., \Teaching AI to Write Code by Writing Code," arXiv
preprint arXiv:2109.04544, 2021.
[18] Hashimoto, Tatsunori B., et al., \What Makes a Good Prompt for Codex? Under-
standing Prompt Quality with Codex Assisted Code," arXiv preprint arXiv:2111.
[19] OpenAI, \Introducing GPT-3.5 Turbo: Fine-tuning Made Easy," OpenAI Blog,
2022. [ https://openai.com/blog/introducing-chatgpt-and-whisper-apis ]
[20] Pyodide Contributors, \Pyodide: Bringing the Scientic Python Stack to the
Browser," GitHub Repository, 2021. [ https://github.com/pyodide/pyodide ]
[21] OWASP Foundation, \OWASP Top Ten Project," OWASP, 2020. [ https://
owasp.org/www-project-top-ten/ ]
[22] Haas, A., et al., \Bringing the Web Up to Speed with WebAssembly," Proceedings
of the 38th ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI 2017), pp. 185-200, 2017.
[23] Graesser, A.C., et al., \Automated Tutoring Dialogue Systems: An Ill-Dened
Class of Cognitive Technologies," Journal of Cognitive Technology, vol. 6, no. 2,
pp. 1-6, 2001.
[24] Vinyals, O., et al., \Pointer Networks," Advances in Neural Information Processing
Systems (NIPS 2015), pp. 2692-2700, 2015.
[25] Devlin, J., et al., \BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding," Proceedings of the 2019 Conference of the North Amer-
ican Chapter of the Association for Computational Linguistics: Human Language
Technologies (NAACL-HLT 2019), pp. 4171-4186, 2019.
[26] Radford, A., et al., \Language Models are Unsupervised Multitask Learn-
ers," OpenAI Blog, 2019. [ https://cdn.openai.com/better-language-models/
language_models_are_unsupervised_multitask_learners.pdf ]
[27] Ford, N., et al., \The Limitations of Large-Scale Language Models," arXiv preprint
arXiv:2102.02502, 2021.
[28] Dai, Z., et al., \Transformer-XL: Attentive Language Models beyond a Fixed-
Length Context," Proceedings of the 57th Annual Meeting of the Association for
Computational Linguistics (ACL 2019), pp. 2978-2988, 2019.
8

--- PAGE 9 ---
[29] Talmor, A., et al., \oLMpics { On what Language Model Pre-training Captures,"
Transactions of the Association for Computational Linguistics, vol. 8, pp. 434-450,
2020.
[30] Bosselut, A., et al., \COMET: Commonsense Transformers for Automatic Knowl-
edge Graph Construction," Proceedings of the 57th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL 2019), pp. 4762-4779, 2019.
[31] Wang, Y., et al., \MathQA: Towards Interpretable Math Word Problem Solving
with Operation-Based Formalisms," Proceedings of the 2019 Conference of the
North American Chapter of the Association for Computational Linguistics: Human
Language Technologies (NAACL-HLT 2019), pp. 2357-2367, 2019.
[32] Akchurin, E., et al., \Solving Mathematical Programming Problems in Natural
Language with Transformers," arXiv preprint arXiv:2109.08601, 2021.
[33] Microsoft. Bing and GPT-4. https://blogs.bing.com/search/march_2023/
Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4 .
[34] Frank F. Xu, Uri Alon, Graham Neubig, and Vincent J. Hellendoorn. A Systematic
Evaluation of Large Language Models of Code. arXiv preprint arXiv:2202.13169 ,
2022.
[35] Hugging Face. CodeParrot. https://huggingface.co/codeparrot .
[36] Wolfram Research Wolfram Alpha NLP. https://www.wolfram.com/
natural-language-understanding/ .
[37] OpenAI. GPT-3. https://openai.com/blog/gpt-3-apps .
9

--- PAGE 10 ---
Addendum
In this addendum, we present several example questions and the answers provided
by ve dierent chat models being compared. Our full evaluation is available at
https://github.com/ryanhlewis/ComputeGPTEval . Additionally, ComputeGPT is
available for use at https://computegpt.org .
(Straightforward) Example Question:
What is the derivative of 200x?
(Correct: 200)
ComputeGPT 200
Wolfram Alpha 200
Davinci-003 200
ChatGPT 200
GPT-4 200
(Straightforward) Example Question:
What is the integral of 200x from 0 to 5?
(Correct: 2500)
ComputeGPT 2500
Wolfram Alpha 2500
Davinci-003 5000
ChatGPT 5000
GPT-4 5000
(Straightforward) LaTeX Example Question:Z50
 2021021x3+ 200 x2dx
(Correct: 9135000000000000000026600000/3)
ComputeGPT 9135000000000000000026600000/3
Wolfram Alpha 26600000/3
Davinci-003 50,000,000,000,000,000,000
ChatGPT 1.83333 x 1024
GPT-4 1.66666666666667E+24
We show that ComputeGPT is ecient at LaTeX parsing, as well as the parsing of
large integers, which other models fail to do.
10

--- PAGE 11 ---
(Word Problem) Example Question:
Kevin's age is 5 times the age of his son, plus
twenty. His son is 10. How old is Kevin?
(Correct: 70)
ComputeGPT 70
Wolfram Alpha NULL
Davinci-003 50
ChatGPT 50
GPT-4 70
(Word Problem) Example Question:
A new technique, called 'jamulti' is invented by multiplying a number
by ve and then adding 2 and dividing by 3. What's the jamulti of 7?
(Correct: 12.33333)
ComputeGPT 12.33333
Wolfram Alpha NULL
Davinci-003 5
ChatGPT 5
GPT-4 12
(Word Problem) Example Question:
An alien needs $50 USD to buy a spaceship. He needs to convert from
ASD, which is worth $1.352 USD. How much ASD does he need?
(Correct: 36.9822485)
ComputeGPT 36.9822485
Wolfram Alpha 1.352
Davinci-003 36.68
ChatGPT 67.6
GPT-4 37.01
We show that GPT-4 is capable of hallucinating 'close' answers, which becomes
even worse as numbers get larger, and the absolute error increases.
11

--- PAGE 12 ---
(Word Problem) Trick Example Question:
An ant travels at 3 m/s on a rubber band. The rubber band is
stretched at 2 m/s. How fast is the ant moving relative to the ground?
(Correct: 1)
ComputeGPT NULL
Wolfram Alpha 3
Davinci-003 5
ChatGPT 5
GPT-4 1
We showcase an example of a loss for ComputeGPT, where it fails to see past the
trick question's simplicity in a subtraction of 3 - 2 = 1.
(Word Problem) Example Question:
Given the matrix [[1, 2, 9, 3, 3], [9, 0, 1, 2, 4], [0, 0, 0, 3,
9], [1, 1, 1, 1, 1], [3, 4484, 456, 9, 6]], what is the determi-
nant multiplied by 5 and then divided by twenty-three?
(Correct: -285832.173913042)
ComputeGPT -285832.173913042
Wolfram Alpha -1314828
Davinci-003 24
ChatGPT -9915
GPT-4 -30247.652
We showcase an example of a clear win for ComputeGPT, where it excels in un-
derstanding and performing a complex computation on the user's machine.
12

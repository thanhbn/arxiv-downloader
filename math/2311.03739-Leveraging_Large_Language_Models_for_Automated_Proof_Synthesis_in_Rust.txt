# 2311.03739.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/math/2311.03739.pdf
# File size: 228492 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Leveraging Large Language Models for Automated Proof Synthesis in Rust
Jianan Yao∗
Columbia UniversityZiqiao Zhou
Microsoft ResearchWeiteng Chen
Microsoft ResearchWeidong Cui
Microsoft Research
Abstract
Formal verification can provably guarantee the correctness of
critical system software, but the high proof burden has long
hindered its wide adoption. Recently, Large Language Models
(LLMs) have shown success in code analysis and synthesis. In
this paper, we present a combination of LLMs and static anal-
ysis to synthesize invariants, assertions, and other proof struc-
tures for a Rust-based formal verification framework called
Verus. In a few-shot setting, LLMs demonstrate impressive
logical ability in generating postconditions and loop invari-
ants, especially when analyzing short code snippets. However,
LLMs lack the ability to retain and propagate context informa-
tion, a strength of traditional static analysis. Based on these
observations, we developed a prototype based on OpenAI’s
GPT-4 model. Our prototype decomposes the verification task
into multiple smaller ones, iteratively queries GPT-4, and com-
bines its output with lightweight static analysis. We evaluated
the prototype with a developer in the automation loop on 20
vector-manipulating programs. The results demonstrate that
it significantly reduces human effort in writing entry-level
proof code.
1 Introduction
Interactive formal verification addresses complex verification
tasks that are beyond the capabilities of push-button verifica-
tion. However, using interactive formal verification is more
challenging because it demands significant manual effort and
specialized knowledge, especially when automatic verifica-
tion fails. Notably, the lines of code (LoC) required for verifi-
cation can potentially expand to as many as ten times the size
of the original code ( [11, 12]).
Inspired by recent advancements in Large Language Mod-
els (LLMs), we perceive an opportunity to reduce manual
efforts required for interactive formal verification. We have
developed a prototype that leverages OpenAI’s GPT-4 [19]
∗This work was done during an internship at Microsoft Research.to automate proof writing. This prototype specializes in pro-
grams that operate on vectors. Leveraging GPT-4’s capabil-
ities in logical thinking and code understanding, we aim to
expedite the development of entry-level programs, particu-
larly those implementing well-known algorithms (e.g., sort,
reverse).
Nevertheless, we have encountered two major challenges.
The first challenge is that GPT-4 does not strictly follow cer-
tain properties and proofs from earlier contexts of a program.
The second issue is that when an initial proof attempt fails
for a lengthy program, GPT-4 becomes overwhelmed by the
multitude of error messages, hindering its ability to improve
the quality of proof.
To address these challenges, we divide a program into
smaller segments, and then utilize GPT-4 to generate the
pre/post-conditions for each segment. Subsequently, we ask
GPT-4 to prove each segment individually. This strategy al-
lows GPT-4 to concentrate on a smaller segment of the pro-
gram per query. When GPT-4 generates a proof, our tool
extends it with a lightweight static analysis, which helps to
propagate the properties deduced from earlier sections of the
program throughout the analysis process. We evaluate our
prototype on 20 vector-manipulating programs. For these
entry-level programs, our prototype tool reduces the LoC for
proof by over 80%.
2 Related work
There have long been efforts to automate various aspects
of the verification pipeline, from automated invariant infer-
ence to tactic-based proof generation [4, 5, 7, 26]. Invariant
inference has been used to prove properties of loops [6, 8, 9,
20, 22 –24], inductive algebraic data types [14, 18], and dis-
tributed protocols [10, 13, 17, 21, 27]. Among these lines of
research, a growing number of methods are based on neural
networks [7, 22 –24, 26], which has gained traction for veri-
fication tasks in recent years and has been shown to better
tackle the search space explosion problem that has long hin-
dered the scalability of traditional methods. Different from
1arXiv:2311.03739v2  [cs.FL]  22 Nov 2023

--- PAGE 2 ---
1fnr e v e r s e ( v : & mut Vec <u64>)
2ensures
3 v . l e n ( ) == o l d ( v ) . l e n ( ) ,
4 f o r a l l | i : i n t | 0 <= i < o l d ( v ) . l e n ( ) ==>
5 v [ i ] == o l d ( v ) [ o l d ( v ) . l e n ( ) − i −1]
6{
7 l e t l e n g t h = v . l e n ( ) ;
8 l e t mut n :u s i z e = 0 ;
9 while n < l e n g t h / 2
10 {
11 l e t x = v [ n ] ;
12 l e t y = v [ l e n g t h − 1 − n ] ;
13 v . s e t ( n , y ) ;
14 v . s e t ( l e n g t h − 1 − n , x ) ;
15 n = n + 1 ;
16 }
17 }
Figure 1: Function to reverse a vector. ensures specifies the post-
condition of the function. old(v) means the value of vbefore the
function executes.
those works, we apply an LLM to synthesize invariants and
intermediate assertions. Our work demonstrates that future
verification tools can be more efficient without sacrificing
their usability with the help of LLMs.
3 Background
We choose Verus [15] as the base verification tool in our
work. Verus is a state-of-the-art verification tool for Rust that
aggressively prunes the SMT context to optimize solving
time. Although it can verify large and complicated systems
more efficiently, it demands significantly more effort to write
proof code. To mitigate this, we consider several difficulties
faced by Verus developers. First, like many other verification
languages, constructing deductive invariants is hard due to
the large search space. Second, since Verus is very new to
developers, it does not provide a large selection of reusable
proofs/lemmas or verified libraries. This requires developers
to have an understanding of logic and the ability to write
proofs, even for basic algorithms. Third, Verus encodes each
module and even each loop independently to facilitate fast
solving. This optimization necessitates increased effort in
annotating the pre/post-conditions and invariants compared
to other verification languages (e.g., Dafny [16] or F* [25]).
4 Methodology
4.1 The need of auto-generated invariants
Consider a simple Rust program that reverses a vector,
as shown in Figure 1. The developer needs to verify two
postconditions specified at Lines 2-5. The first postcondition
states that the reversed vector should maintain the same length
as the original vector, and the second postcondition states thatthei-th element of the reversed vector should be equal to
the (length−i−1)-th element in the original vector. These
postconditions define the correctness of the code. To prove the
loop with Verus [1], the developer needs to add the following
loop invariants.
1i n v a r i a n t
2 0 <= n <= l e n g t h / 2 ,
3 v . l e n ( ) == l e n g t h ,
4 f o r a l l | i : i n t | 0 <= i < n ==> v [ i ] ==
o l d ( v ) [ l e n g t h − i − 1 ] ,
5 f o r a l l | i : i n t | l e n g t h − n <= i < l e n g t h
==> v [ i ] == o l d ( v ) [ l e n g t h − i − 1 ] ,
6 f o r a l l | i : i n t | n <= i < l e n g t h − n ==> v
[ i ] == o l d ( v ) [ i ] ,
Loop invariants define the conditions that remain true be-
fore and after each iteration of the loop, and they should be
inductive. The first invariant is straightforward; it defines
the conditions for the termination of the loop. The second
invariant is necessitated by Verus, as it performs separate ver-
ifications for the loop and the other remaining parts of the
program.
The third and fourth invariants specify the updates for any
modified elements in the vector, within the range 0≤i<n
andlength −n≤i<length . The final invariant asserts that
every element that has not been updated retains its initial
value, ensuring that the invariants for updated elements are
inductive. The absence of any one of these invariants will lead
to the failure of establishing the inductive invariants.
To automatically fill these invariants (and potentially other
proof structures), we unleash the power of large language
models in the workflow depicted in Figure 2. Given the source
code to be verified, we encode it into a prompt with a few shot
examples and send the prompt to GPT-4. Each example is a
pair of source code with to-be-proved properties (denoted as
source_code ) and verified code with human-provided proofs
(denoted as code_with_proof ). When GPT-4 returns the code
with proof, we validate it by using Verus to verify it.
Most of the time, GPT-4 cannot solve the problem with
a single query. If verification with the generated proof fails,
we follow a standard approach in LLM chain-based solutions
to integrate both the last response and the error message to
formulate a new prompt. This new query is then sent back to
GPT-4 for generating an improved result.
For the example in Figure 1, GPT-4 successfully generates
the first four invariants but misses the last one. In fact, human
developers often make the same mistake — forgetting to
specify things that do not change. Verus then outputs three
errors: the third and fourth invariants do not hold at the end of
the loop body, and the postcondition on Line 5 does not hold.
After incorporating the error message into the second query,
GPT-4 returns all 5 invariants, making the code verifiable by
Verus. Ideally, if a human can quickly adjust the proof based
on the hints provided by the error messages, we anticipate
that GPT-4 can amend the proof in a similar manner.
2

--- PAGE 3 ---
Figure 2: Basic workflow of our tool.
4.2 Task decomposition for large programs
The basic solution described in the previous section is only
effective for small programs. We have observed that GPT-
4 does not perform well for relatively large programs. It is
not entirely surprising, given that we are asking GPT-4 to
generate a complete proof for the entire program, whereas
human developers typically think in small steps.
Consider the function in Figure 3. A human developer
would initially prove the property of the vector following the
first loop, asserting that no element exceeds a value of two.
Subsequently, they would shift their focus to the second loop,
analyzing its computation of a sum that does not exceed twice
the number of elements.
We can guide GPT-4 to think similarly by decomposing the
large code task into smaller ones. Given a code, we decom-
pose it into smaller segments. For each segment, we define
two types of prompts. One is to let GPT-4 generate the re-
lationship between segments, where the post-condition of a
segment must be a pre-condition of the next segment. The
other is to let GPT-4 generate the proof per segment.
For the code in Figure 3, we can divide it at Line 13 into
two segments and query GPT-4 for the postcondition of the
first segment. For example, GPT-4 gives the following post-
condition.
1i == N,
2a . l e n ( ) == N,
3f o r a l l | k : i n t | 0 <= k < a . l e n ( ) ==> a [ k ] <= 2 ,
With the postcondition, the verification of the original code
is decomposed into two smaller tasks, each concerning one
of the two segments. For each segment, we use the workflow
depicted in Figure 2 to complete the proof. The three-line
interface above will serve as the postcondition when verifying
the first segment and as the precondition when verifying the
second segment.
4.3 Combining GPT-4 with static analysis and
human
Although GPT-4 can generate logical formulas based on code,
including complicated quantified invariants, they often over-1pub fn foo ( a : & mut Vec <u32> , N: u32)
2 r e q u i r e s
3 o l d ( a ) . l e n ( ) == N,
4 N <= 0x7FFF_FFFF ,
5{
6 l e t mut i :u s i z e = 0 ;
7 while ( i < N as u s i z e )
8 {
9 i f( a [ i ] > 2) {
10 a . s e t ( i , 2) ;
11 }
12 i = i + 1 ;
13 }
14 i = 0 ;
15 l e t mut sum : u32 = 0 ;
16 while ( i < N as u s i z e )
17 {
18 sum = sum + a [ i ] ;
19 i = i + 1 ;
20 }
21 a s s e r t ( sum <= 2 *N) ;
22 }
Figure 3: Verus function that sums over a vector after elements are
capped at 2. requires specifies the precondition of the function.
look certain non-intuitive simple invariants, much like begin-
ner human developers.
For example, one might find the upper bound of Nin Line 4
confusing. However, this upper bound is crucial to ensure
there is no integer overflow on Line 18. To verify the second
loop, N <= 0x7FFF_FFFF must be included as an invariant.
Finding such invariants is far more straightforward with
static analysis. We have therefore implemented a lightweight
static analysis tool which, for each loop, provides lists of
variables read from and written to. For any precondition of
the loop, if all variables referenced in the precondition are not
written to in the loop, and at least one variable referenced is
read from in the loop, the precondition will be automatically
propagated into the loop invariant, in addition to invariants
generated by GPT-4. For the second loop in Figure 3, N <=
0x7FFF_FFFF is added to the loop invariant.
To better guide GPT-4 query, we engage a developer only
when necessary. If GPT-4 returns a postcondition, the devel-
3

--- PAGE 4 ---
oper has the option to edit it. If GPT-4 fails to complete the
proof within the maximum number of iterations, the developer
is prompted to complete the proof, building upon the partial
proof provided by GPT-4.
4.4 A running example
To help understand how our tool works, we show each step
for proving the first loop in Figure 3.
Given a program in Verus (a Rust -like language)
with its precondition , returns its postcondition .
Some examples and their postconditions are given
below:
${Examples}
Notes:
1. Do not use Rust primitives such as clone ,
filter , iter , sum , or count.
2. Do not use the conditional operator "a ? b : c
".
3. Each postcondition takes a separate line.
Begin!
New Verus program:
${CodeBlock}
Response requirements :
You must respond using the following format and
ensure the response could be parsed by json.loads:
{
"thoughts ": "<explain the program and its
precondition , then analyze how to write
the postcondition >",
" postcondition ": "<postcondition >"
}
Listing 1: 1st GPT-4 query
i == N,
forall |k:int| 0 <= k < N ==> a[k] <= 2
Listing 2: 1st response. Our tool parses the response from GPT-4
and extracts the postconditions.
Given a program in Verus (a Rust -like language),
add invariants and proofs to make it verifiable.
Some example programs and their verifiable
versions are given below:
...
Notes:
...
* Do not modify or remove any line in the given
program. Only add lines.
Begin!
New Verus program:
pub fn foo(a: &mut Vec <u32 >, N: u32 , i: usize)
requires
old(a).len () == N,
N <= 0x7FFF_FFFF ,
{
let mut i: usize = i;
assume(i == 0);
${first loop}
proof { // inline postcondition
assert(i == N);assert(forall |k:int| 0 <= k < N ==> a[k]
<= 2);
}
}
------
Response requirements :
You must respond using the following format and
ensure the response could be parsed by json.loads:
{
"thoughts ": "<explain the pre and post
conditions , and how to write invariants
and proofs >",
"verifiable program ": "<program >"
}
Listing 3: 2nd GPT-4 query, asking for a proof for this postcondition
invariant
0 <= i <= N,
a.len() == N,
forall |k:int| 0 <= k < i ==> a[k] <= 2,
Listing 4: 2nd Response. GPT-4 outputs a program, which is the
same as the input program except that it inserts the following
invariants.
In addition, our static analysis tool propagates the following
invariants from the preconditions.
a.len() == N,
N <= 0x7FFF_FFFF ,
The loop invariant N <= 0x7FFF_FFFF is then added to the
GPT-generated invariants (although it will not be necessary for
this loop). The program is then verified by Verus successfully.
5 Evaluation
5.1 Datasets
We evaluated our tool on 20 vector-manipulating programs
generated from the Diffy [3] benchmark. Specifically, we took
20 C programs from its safe category and translated them
from C to Verus. Then we manually checked the equivalence
of the translation.
5.2 Parameters
We tested the verification capability of our tool, which is
equipped with the OpenAI GPT-4 (2023-03-15) model. Ini-
tially, we set the temperature of the GPT-4 model to 0. When
GPT-4 returns a broken JSON format, the tool increases the
temperature to 0.5 and retries. If GPT-4 returns a program
that cannot be verified after invariant propagation, the tool
feeds the error message back and retries once. We utilized
3 prompt templates: one for filling in the postcondition, one
for completing the proof, and one for fixing the proof. The
static analysis is configured to divide a program into segments
around loops.
4

--- PAGE 5 ---
Total segments 110
No proof needed 55
GPT response verified directly 18
Verified after invariant propagation 17
Verified after error feedback 2
Verified after both propagation and feedback 1
Verified after human correction 16
Unverified (buggy in Rust) 1
Table 1: Results on verifying the 20 programs by program segments.
Ground-truth proof 334
Human corrections on syntax 5
Human corrections on semantics 49
Human corrections on both syntax and semantics 1
Table 2: Results on verifying the 20 programs by line of code.
5.3 Results
The 20 programs we tested were divided into 110 segments,
resulting in a total of 163 GPT-4 queries. Table 1 presents the
results categorized by program segments. Out of the 110 seg-
ments, 55 are loop-free and are directly verified by Verus with-
out requiring any annotations. Of the remaining 55 segments,
GPT-4 directly provides a correct proof for 18 of them, while
20 segments receive a correct proof after invariant propaga-
tion and/or error feedback. This showcases not only GPT-4’s
inherent effectiveness but also the efficiency of the techniques
we employ to interact with it.
Table 2 shows the results in terms of lines of code. When
starting from scratch, a human developer would require 334
lines of proof to verify the 20 programs. In contrast, with our
prototype tool, the user is tasked with correcting only 55 lines,
building upon the partial proof already provided by the tool.
This demonstrates the substantial reduction in human effort
our tool offers when verifying vector-manipulating programs
with loops.
5.4 Improved results wth GPT-4 (2023-11-06)
In our evaluation using the GPT-4 model dated 2023-03-15,
only 3 out of 20 programs were fully automated (without
human intervention). Additionally, self-repair through error
feedback was effective for only 2 segments. However, after
switching to the updated GPT-4 model (2023-11-06) and
implementing two additional attempts upon failure, 14 out
of 20 programs required no human intervention. With this
enhanced automation, more than 20 segments could be self-
repaired via error message feedback. It demonstrates that our
approach naturally evolves alongside advancements in the
LLM model.6 Limitations and Lesson Learned
In this section, we share our experience and lessons learned
when developing the tool. The first is that GPT-4 works more
effectively with shorter code inputs. When the code is long,
GPT-4 often forgets about invariants it writes for an earlier
loop, and gets lost in too many error messages when the proof
is incorrect. Although the issue is mitigated by task decom-
position, as discussed in Section 4.2, the optimal strategy for
decomposition, especially with multiple functions, remains
an area for research.
The second lesson is that code comments are appreciated
by GPT-4. We observed that GPT-4 sometimes forgets to
specify the size of the vector in the invariant (e.g., v.len()
== length ) for the reverse example in Figure 1. By adding a
comment after each such invariant in the few-shot examples,
GPT-4 is more likely to generate such an invariant for a new
program.
The third lesson is that GPT-4 is more adept at writing post-
conditions and invariants than writing triggers and assertions
for quantifier instantiation [2], or writing nonlinear arithmetic
proof. Even in a zero-shot setting (i.e., when no example
is provided in the prompt), GPT-4 can produce meaningful
postconditions and invariants, though not in the valid Verus
syntax. This indicates that GPT-4 has already learned these
concepts in its training data. But triggers and assertions for
quantifier instantiation are specific to annotation-based ver-
ification languages, and proofs for nonlinear arithmetic are
particularly specific to Verus. Determining how to efficiently
teach LLMs these new ways of reasoning within a limited
prompt size is an ongoing challenge. It is possible to solve
this problem by fine-tuning.
Our current tool is still an early prototype. The implemen-
tation specifically targets single-function vector-manipulating
programs in Verus. We anticipate its capabilities would signif-
icantly expand by supporting more complex data types, such
asSet,Map, and user-defined datatypes. Another avenue for
enhancement would be to support cross-function verification
and to leverage existing lemmas in proofs.
7 Conclusion
In this paper, we presented an approach to use GPT-4 to
generate proofs for Rust programs that can be verified by
Verus. We developed a prototype and evaluated it on 20 vector-
manipulating programs. Our evaluation shows that our pro-
totype can significantly reduce the human effort in writing
proofs for entry-level programs. Our work demonstrates the
potential of leveraging LLMs to automate proof generation
for program verification.
5

--- PAGE 6 ---
8 Acknowledgement
We thank Chris Hawblitzel and Jacob R. Lorch for helpful
suggestions on using Verus.
References
[1]Verus’s tutorial on loops and invariants.
https://verus-lang.github.io/verus/guide/
while.html .
[2]Verus’s tutorial on triggers. https://verus-lang.
github.io/verus/guide/forall.html .
[3]Supratik Chakraborty, Ashutosh Gupta, and Divyesh
Unadkat. Diffy: Inductive reasoning of array programs
using difference invariants. In Computer Aided Verifica-
tion: 33rd International Conference, CAV 2021, Virtual
Event, July 20–23, 2021, Proceedings, Part II 33 , pages
911–935. Springer, 2021.
[4]Łukasz Czajka. Practical proof search for coq by type in-
habitation. In Automated Reasoning: 10th International
Joint Conference, IJCAR 2020, Paris, France, July 1–4,
2020, Proceedings, Part II 10 , pages 28–57. Springer,
2020.
[5]Łukasz Czajka and Cezary Kaliszyk. Hammer for coq:
Automation for dependent type theory. Journal of auto-
mated reasoning , 61:423–453, 2018.
[6]Grigory Fedyukovich, Sumanth Prabhu, Kumar Mad-
hukar, and Aarti Gupta. Quantified invariants via syntax-
guided synthesis. In Proceedings of the 31st Interna-
tional Conference on Computer Aided Verification (CAV
’19), pages 259–277, July 2019.
[7]Emily First, Markus N Rabe, Talia Ringer, and Yuriy
Brun. Baldur: whole-proof generation and re-
pair with large language models. arXiv preprint
arXiv:2303.04910 , 2023.
[8]Pranav Garg, Christof Löding, P Madhusudan, and
Daniel Neider. Learning universally quantified invari-
ants of linear data structures. In Proceedings of the 25th
International Conference on Computer Aided Verifica-
tion (CAV ’13) , pages 813–829, July 2013.
[9]Pranav Garg, Daniel Neider, P. Madhusudan, and Dan
Roth. Learning invariants using decision trees and im-
plication counterexamples. In Proceedings of the 43rd
Annual ACM SIGPLAN-SIGACT Symposium on Prin-
ciples of Programming Languages (POPL ’16) , page
499–512, January 2016.
[10] Travis Hance, Marijn Heule, Ruben Martins, and Bryan
Parno. Finding invariants of distributed systems: It’s asmall (enough) world after all. In Proceedings of the
18th USENIX Symposium on Networked Systems Design
and Implementation (NSDI ’21) , pages 115–131, April
2021.
[11] Travis Hance, Andrea Lattuada, Chris Hawblitzel, Jon
Howell, Rob Johnson, and Bryan Parno. Storage Sys-
tems are Distributed Systems (So Verify Them That
Way!). In Proceedings of the 14th USENIX Sympo-
sium on Operating Systems Design and Implementation
(OSDI ’20) , pages 99–115, 2020.
[12] Chris Hawblitzel, Jon Howell, Manos Kapritsos, Jacob R
Lorch, Bryan Parno, Michael L Roberts, Srinath Setty,
and Brian Zill. IronFleet: Proving practical distributed
systems correct. In Proceedings of the 25th Symposium
on Operating Systems Principles (SOSP ’15) , pages 1–
17, October 2015.
[13] Jason R. Koenig, Oded Padon, Sharon Shoham, and Alex
Aiken. Inferring invariants with quantifier alternations:
Taming the search space explosion. In Proceedings
of the 28th International Conference on Tools and Al-
gorithms for the Construction and Analysis of Systems
(TACAS ’22) , pages 338–356, April 2022.
[14] Yurii Kostyukov, Dmitry Mordvinov, and Grigory
Fedyukovich. Beyond the elementary representations
of program invariants over algebraic data types. In Pro-
ceedings of the 42nd ACM SIGPLAN International Con-
ference on Programming Language Design and Imple-
mentation (PLDI ’21) , page 451–465, June 2021.
[15] Andrea Lattuada, Travis Hance, Chanhee Cho, Matthias
Brun, Isitha Subasinghe, Yi Zhou, Jon Howell, Bryan
Parno, and Chris Hawblitzel. Verus: Verifying rust pro-
grams using linear ghost types. Proc. ACM Program.
Lang. , 7(OOPSLA1), 2023.
[16] K Rustan M Leino. Dafny: An automatic program
verifier for functional correctness. In International con-
ference on logic for programming artificial intelligence
and reasoning , pages 348–370. Springer, 2010.
[17] Haojun Ma, Aman Goel, Jean-Baptiste Jeannin, Manos
Kapritsos, Baris Kasikci, and Karem A Sakallah. I4:
Incremental inference of inductive invariants for verifi-
cation of distributed protocols. In Proceedings of the
27th ACM Symposium on Operating Systems Principles
(SOSP ’19) , pages 370–384, October 2019.
[18] Anders Miltner, Saswat Padhi, Todd Millstein, and
David Walker. Data-driven inference of representation
invariants. In Proceedings of the 41st ACM SIGPLAN
Conference on Programming Language Design and Im-
plementation (PLDI ’20) , pages 1–15, June 2020.
6

--- PAGE 7 ---
[19] OpenAI. GPT-4. https://openai.com/research/
gpt-4 , 2023.
[20] Saswat Padhi, Rahul Sharma, and Todd Millstein. Data-
driven precondition inference with learned features. In
Proceedings of the 37th ACM SIGPLAN Conference on
Programming Language Design and Implementation
(PLDI ’16) , page 42–56, June 2016.
[21] Oded Padon, James R Wilcox, Jason R Koenig, Ken-
neth L McMillan, and Alex Aiken. Induction duality:
Primal-dual search for invariants. Proceedings of the
ACM on Programming Languages , 6(POPL), January
2022.
[22] Kexin Pei, David Bieber, Kensen Shi, Charles Sutton,
and Pengcheng Yin. Can large language models reason
about program invariants? In Proceedings of the 40th
International Conference on Machine Learning (ICML
’23), 2023.
[23] Gabriel Ryan, Justin Wong, Jianan Yao, Ronghui Gu,
and Suman Jana. Cln2inv: Learning loop invariants with
continuous logic networks. In International Conference
on Learning Representations , 2020.
[24] Xujie Si, Hanjun Dai, Mukund Raghothaman, Mayur
Naik, and Le Song. Learning loop invariants for pro-
gram verification. In Advances in Neural Information
Processing Systems , pages 7751–7762, 2018.
[25] Nikhil Swamy, Guido Martínez, and Aseem
Rastog. Proof-oriented programming in F*.
https://www.fstar-lang.org/tutorial/
proof-oriented-programming-in-fstar.pdf ,
2023.
[26] Kaiyu Yang and Jia Deng. Learning to prove theorems
via interacting with proof assistants. In International
Conference on Machine Learning , pages 6984–6994.
PMLR, 2019.
[27] Jianan Yao, Runzhou Tao, Ronghui Gu, and Jason Nieh.
DuoAI: Fast, automated inference of inductive invari-
ants for verifying distributed protocols. In 16th USENIX
Symposium on Operating Systems Design and Imple-
mentation (OSDI ’22) , pages 485–501, 2022.
7

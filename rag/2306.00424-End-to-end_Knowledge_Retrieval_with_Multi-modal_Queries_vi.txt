# Truy xuất tri thức đầu cuối với truy vấn đa phương thức
Man Luo1Zhiyuan Fang2Tejas Gokhale1Yezhou Yang1Chitta Baral1
1Đại học Bang Arizona2Amazon Alexa
{mluo26, tgokhale, yz.yang, chitta}@asu.edu ,zyfang@amazon.com

Tóm tắt
Chúng tôi nghiên cứu truy xuất tri thức với truy vấn đa phương thức, tức là các truy vấn chứa thông tin được phân chia giữa đầu vào hình ảnh và văn bản, một nhiệm vụ thách thức khác biệt với các nghiên cứu trước đây về truy xuất xuyên phương thức. Chúng tôi tuyển chọn một bộ dữ liệu mới có tên ReMuQ1 để đánh giá tiến bộ trong nhiệm vụ này. ReMuQ yêu cầu một hệ thống truy xuất tri thức từ một kho dữ liệu lớn bằng cách tích hợp nội dung từ cả truy vấn văn bản và hình ảnh. Chúng tôi giới thiệu một mô hình truy xuất "ReViz" có thể xử lý trực tiếp văn bản và hình ảnh đầu vào để truy xuất tri thức liên quan theo cách đầu cuối mà không phụ thuộc vào các mô-đun trung gian như bộ phát hiện đối tượng hoặc trình tạo chú thích. Chúng tôi giới thiệu một nhiệm vụ tiền huấn luyện mới hiệu quả cho việc học truy xuất tri thức với truy vấn đa phương thức và cũng cải thiện hiệu suất trên các nhiệm vụ hạ nguồn. Chúng tôi chứng minh hiệu suất vượt trội trong truy xuất trên hai bộ dữ liệu (ReMuQ và OK-VQA) dưới cài đặt zero-shot cũng như những cải thiện thêm khi được tinh chỉnh trên các bộ dữ liệu này.

1 Giới thiệu
Con người nhớ lại, truy xuất và truyền đạt thông tin bằng nhiều gợi ý và manh mối gián tiếp. Ví dụ, nếu chúng ta muốn giải thích khái niệm "báo hoa mai" nhưng quên tên, chúng ta có thể liên kết khái niệm này với hình ảnh của một con hổ và nói "đó là một loài động vật trông giống như thế này, nhưng có đốm thay vì sọc". Tương tự, khi trẻ em học vẽ một hình mới như hình bầu dục, giáo viên thường gợi ý bằng cách cho xem hình tròn, nhưng nói "làm cho hình tròn giãn ra". Phương pháp học các khái niệm mới từ hỗ trợ thị giác và mô tả ngôn ngữ này là cách phổ biến để củng cố kiến thức hiện có và cho phép người học khám phá và truy xuất các khái niệm mới (Kinder, 1942).

Chúng tôi đề xuất một nhiệm vụ cho các mô hình thị giác-ngôn ngữ để truy xuất tri thức với truy vấn đa phương thức, tức là các truy vấn trong đó các gợi ý về thông tin cần truy xuất được phân chia giữa đầu vào hình ảnh và văn bản. Hình 1 chứa một ví dụ về nhiệm vụ này, trong đó hình ảnh cho thấy Tòa nhà Empire State ở Thành phố New York. Nếu chúng ta truy xuất tri thức chỉ sử dụng hình ảnh, có khả năng thông tin được truy xuất (K1) sẽ liên quan đến Tòa nhà Empire State. Tuy nhiên, K1 không đủ để trả lời câu hỏi. Mặt khác, nếu chúng ta truy xuất tri thức chỉ sử dụng câu hỏi, thì thông tin được truy xuất (K2) có khả năng liên quan đến tòa nhà cao nhất ở tất cả các thành phố (và không giới hạn ở Thành phố New York). K2 tự thân cũng không đủ để trả lời câu hỏi. Ví dụ này cho thấy rằng truy vấn kết hợp chứa cả hình ảnh và văn bản (câu hỏi) là cần thiết để truy xuất tri thức liên quan (K3).

Chúng tôi giới thiệu một điểm chuẩn và bộ dữ liệu mới có tên ReMuQ (Truy xuất với Truy vấn Đa phương thức) để huấn luyện và đánh giá các mô hình truy xuất câu trả lời từ một kho dữ liệu cho các truy vấn đa phương thức (thị giác + ngôn ngữ). Để tạo các truy vấn đa phương thức, chúng tôi bắt đầu với bộ dữ liệu WebQA (Chang et al., 2022) làm nguồn - WebQA chứa các hình ảnh được chú thích với các câu hỏi và câu trả lời. Chúng tôi chọn các câu hỏi từ WebQA mà câu trả lời bao gồm cả hình ảnh và văn bản. Sau đó chúng tôi loại bỏ bất kỳ thông tin hình ảnh nào từ văn bản và kết hợp hình ảnh với văn bản được tăng cường để tạo thành một truy vấn đa phương thức mới. Chúng tôi cũng xây dựng một kho truy xuất lớn bao gồm các tùy chọn trả lời của tất cả câu hỏi làm nguồn tri thức cho nhiệm vụ này.

Nhiệm vụ này yêu cầu tích hợp nội dung từ cả hai phương thức và truy xuất tri thức - trong bài báo này chúng tôi ký hiệu hệ thống như vậy là "VL-Retriever". Các VL-Retriever hiện có (Qu et al., 2021; Luo et al., 2021; Gao et al., 2022) thường tuân theo quy trình hai bước để truy xuất tri thức: (1) chuyển đổi hình ảnh thành chú thích hoặc từ khóa, nối chúng vào truy vấn văn bản, và (2) sử dụng hệ thống truy xuất văn bản để truy xuất tri thức. Tuy nhiên, cách tiếp cận này có thể dẫn đến mất mát thông tin quan trọng từ hình ảnh, chẳng hạn như ngữ cảnh và nền. Ngoài ra, việc sử dụng mô hình tạo chú thích được huấn luyện trên một miền cụ thể không chuyển giao tốt sang các miền khác trong các ứng dụng thực tế.

Để giải quyết những vấn đề này, chúng tôi đề xuất một VL-Retriever đầu cuối có tiềm năng tận dụng toàn bộ hình ảnh, thay vì chỉ các danh mục đối tượng, từ khóa và chú thích. Chúng tôi gọi mô hình này là ReViz, một mô hình truy xuất để "Đọc và Hình dung" truy vấn. Như một phần của ReViz, chúng tôi sử dụng mô hình dựa trên vision transformer, ViLT (Kim et al., 2021), để mã hóa trực tiếp hình ảnh từ pixel thô với đầu vào ngữ cảnh, và chúng tôi sử dụng BERT (Devlin et al., 2019) làm bộ mã hóa tri thức để đại diện cho văn bản dài, dạng tự do dưới dạng nhúng tri thức.

ReViz khác biệt với các mô hình truy xuất trước đây theo hai cách chính. Thứ nhất, nó không yêu cầu một bộ dịch xuyên phương thức bổ sung (ví dụ: mô hình tạo chú thích) hoặc bộ phát hiện đối tượng để đại diện cho hình ảnh. Thứ hai, thiết kế đầu cuối của nó cho phép huấn luyện lại linh hoạt từng mô-đun con của mô hình, có thể giảm thiểu các vấn đề tiềm ẩn do khoảng cách miền gây ra.

Khác với các trình truy xuất văn bản thần kinh (Karpukhin et al., 2020; Luo et al., 2022), các bộ mã hóa truy vấn và tri thức trong ReViz là các loại phương thức khác nhau (tức là transformer đa phương thức và transformer ngôn ngữ). Các không gian ngữ nghĩa khác nhau của nhúng truy vấn và tri thức làm cho việc căn chỉnh giữa chúng trở nên khó khăn. Để giải quyết vấn đề này, chúng tôi đề xuất một nhiệm vụ tiền huấn luyện truy xuất đa phương thức mới. Để tạo dữ liệu huấn luyện, chúng tôi xây dựng các bộ ba (hình ảnh đầu vào, văn bản đầu vào, tri thức đầu ra) từ bộ dữ liệu WiT (Srinivasan et al., 2021) chứa tri thức kiểu bách khoa toàn thư từ Wikipedia. Chúng tôi xử lý dữ liệu sao cho hình ảnh và văn bản đầu vào có thông tin loại trừ lẫn nhau.

Các đóng góp và phát hiện của chúng tôi được liệt kê dưới đây.
• Chúng tôi giới thiệu một bộ dữ liệu mới ReMuQ để hỗ trợ nghiên cứu về truy xuất với truy vấn đa phương thức.
• Chúng tôi đề xuất một VL-Retriever đầu cuối, ReViz, có thể trực tiếp thu thập tri thức khi có truy vấn đa phương thức. ReViz không phụ thuộc vào bất kỳ bộ dịch xuyên phương thức nào, chẳng hạn như mô hình tạo chú thích hình ảnh hoặc bộ phát hiện đối tượng.
• Chúng tôi tiền huấn luyện ReViz trên một nhiệm vụ tiền huấn luyện truy xuất đa phương thức mới, VL-ICT. Chúng tôi quan sát thấy rằng với việc tiền huấn luyện được đề xuất trên bộ dữ liệu WiT, VL-Retriever của chúng tôi là một trình truy xuất đa phương thức zero-shot mạnh mẽ vượt trội hơn các phương pháp truy xuất tri thức đơn phương thức hiện có.

2 Nghiên cứu liên quan
Truy xuất Xuyên phương thức nhằm tìm thông tin từ một phương thức khác với truy vấn; ví dụ truy xuất hình ảnh từ văn bản (văn bản-sang-hình ảnh), văn bản từ hình ảnh (hình ảnh-sang-văn bản) (Young et al., 2014; Lin et al., 2014), văn bản-sang-video và video-sang-văn bản (Rohrbach et al., 2015; Xu et al., 2016; Zhou et al., 2018). Ngược lại, chúng tôi xem xét việc truy xuất tri thức cho các truy vấn bao gồm cả hai phương thức (tức là hình ảnh và văn bản) cùng nhau.

Trả lời Câu hỏi dựa trên Tri thức. Các trình truy xuất quan trọng để tìm tri thức liên quan nhằm hỗ trợ các mô hình trả lời câu hỏi dựa trên tri thức cho các nhiệm vụ như FVQA (Wang et al., 2017) (tri thức thông thường), Text-KVQA (Singh et al., 2019) yêu cầu tri thức về văn bản trong hình ảnh, và KVQA (Shah et al., 2019) (tri thức thế giới về các thực thể có tên). Cả FVQA và KVQA đều được trang bị đồ thị tri thức làm kho dữ liệu bên ngoài. Trong OKVQA (Marino et al., 2019) và các phiên bản tăng cường S3VQA (Jain et al., 2021) và A-OKVQA (Schwenk et al., 2022), các mô hình có thể tự do sử dụng bất kỳ cơ sở tri thức hiện có nào để truy xuất tri thức liên quan. WebQA (Chang et al., 2022) là một bộ dữ liệu lý luận đa bước yêu cầu hệ thống tổng hợp nhiều nguồn để trả lời câu hỏi, trong đó câu trả lời có thể được tìm thấy thông qua tìm kiếm hình ảnh hoặc tìm kiếm web tổng quát. Fang et al. (2020) giới thiệu một bộ dữ liệu trả lời câu hỏi video yêu cầu hệ thống trả lời câu hỏi bằng tri thức thông thường về ý định và tác động của hành động của con người trong video.

Truy xuất Tri thức với Truy vấn Đa phương thức
Mặc dù có các phương pháp truy xuất tri thức từ đồ thị tri thức (Narasimhan et al., 2018; Li et al., 2020; Marino et al., 2021), trong nghiên cứu này, chúng tôi tập trung vào các hệ thống truy xuất tri thức từ văn bản dạng tự do, dễ có sẵn và toàn diện hơn. Các phương pháp trước đây bao gồm việc chuyển đổi hình ảnh thành các biểu diễn ngôn ngữ như chú thích (Qu et al., 2021; Gao et al., 2022) hoặc thẻ đối tượng (Gui et al., 2022; Yang et al., 2022), và sau đó sử dụng trình truy xuất dựa trên văn bản như BM25 (Robertson and Zaragoza, 2009) hoặc DPR (Karpukhin et al., 2020) để tìm tri thức liên quan. Gao et al. (2022) tận dụng GPT-3 (Brown et al., 2020) để tạo tri thức. Qu et al. (2021); Luo et al. (2021) sử dụng mô hình thị giác và ngôn ngữ để có được các biểu diễn xuyên phương thức. CLIP (Radford et al., 2021) cũng đã được áp dụng cho các nhiệm vụ truy xuất; tuy nhiên nó có hạn chế do việc mã hóa riêng biệt văn bản và hình ảnh mà không có mô-đun hợp nhất đa phương thức.

3 Truy xuất với Truy vấn Đa phương thức
Trong phần này, chúng tôi định nghĩa phát biểu vấn đề cho truy xuất tri thức với truy vấn đa phương thức và mô tả việc xây dựng bộ dữ liệu ReMuQ để đánh giá các mô hình thực hiện nhiệm vụ này.

3.1 Phát biểu Vấn đề
Cho một truy vấn Q = (I, T) chứa hình ảnh I và văn bản T, chúng ta muốn học một ánh xạ đến tri thức văn bản liên quan K từ một kho dữ liệu C. Lưu ý rằng hai phương thức I và T sao cho mỗi phương thức chứa thông tin một phần về K. Cả I và T đều cần thiết để truy xuất thành công K và chỉ sử dụng một trong hai phương thức là không đủ.

3.2 Tạo Bộ dữ liệu ReMuQ
Trong ReMuQ, mỗi truy vấn có đúng một tri thức sự thật cơ bản được liên kết với nó. Để tạo các truy vấn như vậy, chúng tôi tăng cường các câu hỏi WebQA (Chang et al., 2022), và thu thập một kho dữ liệu lớn để phục vụ như nguồn tri thức cho bất kỳ hệ thống truy xuất nào.

WebQA là một bộ dữ liệu QA đa bước và đa phương thức bao gồm các câu hỏi văn bản thuộc các loại khác nhau như Có/Không, Mở (ví dụ: hình dạng, màu sắc, v.v.) và câu hỏi trắc nghiệm (MC). Các hình ảnh được thu thập từ Wikimedia Commons, cả câu hỏi và câu trả lời văn bản đều được tạo bởi người chú thích.

Để tạo các truy vấn đa phương thức, chúng tôi sử dụng các câu hỏi MC trong WebQA, được liên kết với nhiều lựa chọn làm nguồn tri thức dưới dạng văn bản hoặc hình ảnh. Câu trả lời sự thật cơ bản của các câu hỏi bao gồm chỉ văn bản, chỉ hình ảnh, hoặc cả văn bản và hình ảnh. Chúng tôi áp dụng các bước quan trọng để tạo truy vấn đa phương thức và giải thích quy trình tuyển chọn dưới đây và trong Hình 2 (thêm ví dụ được đưa ra trong Phụ lục).

(1) Lọc Câu hỏi. Chúng tôi chọn các câu hỏi trắc nghiệm có các lựa chọn trả lời chứa cả hình ảnh và văn bản.

(2) Xây dựng Truy vấn Đa phương thức. Truy vấn đa phương thức ban đầu là sự kết hợp của câu hỏi và hình ảnh tương ứng. Để buộc hệ thống tích hợp thông tin từ cả văn bản và hình ảnh, chúng tôi sử dụng tf-idf để chọn từ khóa và sau đó loại bỏ chúng trong câu hỏi. Truy vấn đa phương thức mới của chúng tôi sau đó là sự ghép nối của câu hỏi được tăng cường và hình ảnh, với câu trả lời văn bản làm tri thức sự thật cơ bản.

(3) Xây dựng Kho Truy xuất. Chúng tôi tổng hợp tri thức văn bản từ tất cả các mẫu làm kho tri thức chung cho truy xuất đa phương thức, tạo ra một kho lớn khoảng 199k mô tả tri thức.

(4) Chia Tập Huấn luyện-Kiểm tra Bộ dữ liệu. Chúng tôi chia ReMuQ thành 70% cho huấn luyện và 30% là phần kiểm tra. Bộ dữ liệu được tuyển chọn mới chứa 8418 mẫu huấn luyện và 3609 mẫu kiểm tra, cùng với một kho tri thức có 195,837 mô tả tri thức. Thống kê khác của ReMuQ được đưa ra trong Bảng 1.

4 Phương pháp
Nghiên cứu trước đây về Trình Truy xuất Thị giác-Ngôn ngữ (VL) đã tập trung vào các phương pháp hai giai đoạn trong đó giai đoạn đầu bao gồm trích xuất đặc trưng bằng các bộ mã hóa thị giác và văn bản được tiền huấn luyện và giai đoạn thứ hai học truy xuất bằng các đặc trưng này. Một VL-Retriever điển hình có thể được biểu diễn như:

K = VL-RETRIEVER(T, F; C), (1)

trong đó C là kho tri thức, T là thành phần văn bản của truy vấn, và F biểu thị các đặc trưng được trích xuất của hình ảnh I. Việc trích xuất đặc trưng này có thể được thực hiện theo hai cách; (1) bằng cách chuyển đổi đầu vào thị giác thành mô tả văn bản có thể đọc được của con người thông qua mô hình tạo chú thích hình ảnh hoặc một loạt thẻ đối tượng bằng bộ phát hiện đối tượng, (2) bằng cách trích xuất các đặc trưng đối tượng bằng bộ phát hiện đối tượng.

VL-Retriever Đầu cuối. Thay vào đó, trong nghiên cứu này, chúng tôi quan tâm đến việc xây dựng một VL-Retriever đầu cuối, mã hóa và chọn tri thức từ kho dữ liệu bằng mô hình VL:

K = VL-RETRIEVER(T, I; C). (2)

Chúng tôi đề xuất ReViz, một VL-RETRIEVER đầu cuối học để tối đa hóa độ tương tự truy vấn đa phương thức và tri thức cho các nhiệm vụ truy xuất tri thức. Chúng tôi giới thiệu kiến trúc của nó dưới đây.

4.1 Kiến trúc Mô hình ReViz
ReViz có thể đọc và hình dung truy vấn đầu vào, bao gồm hai thành phần, bộ mã hóa truy vấn đa phương thức và bộ mã hóa tri thức. Hình 3 minh họa quy trình của mô hình chúng tôi.

Bộ Mã hóa Truy vấn Đa phương thức. Chúng tôi sử dụng ViLT (Kim et al., 2021) để mã hóa chung đầu vào văn bản T và hình ảnh I. Trong ViLT, một hình ảnh đầu tiên được chia thành một tập hợp các mảnh có kích thước cố định - các mảnh này được mã hóa thành các token thị giác liên tục thông qua một lớp chiếu tuyến tính (Dosovitskiy et al., 2020). Các token thị giác này được ghép nối với các token văn bản và được cộng với nhúng vị trí và đưa vào một chồng của nhiều khối tự chú ý. Biểu diễn đa phương thức cuối cùng được thu được bằng cách áp dụng phép chiếu tuyến tính và tang hyperbolic trên nhúng token chỉ số đầu tiên.

Zq = ViLT(I, T) (3)

Bộ Mã hóa Tri thức. Để mã hóa tri thức, chúng tôi sử dụng mô hình BERT được tiền huấn luyện (Devlin et al., 2019), tạo ra một danh sách các vector dày đặc (h1, ..., hn) cho mỗi token đầu vào, và biểu diễn cuối cùng là biểu diễn vector của token đặc biệt [CLS].

Zk = BERT(K) (4)

Sau khi nhúng của truy vấn và tri thức được tính toán bởi các bộ mã hóa, tích vô hướng bên trong của các nhúng được coi là điểm liên quan.

Score(I, T, K) = Z⊤k · Zq (5)

4.2 Huấn luyện
Mục tiêu huấn luyện của ReViz lấy cảm hứng từ nguyên lý phân biệt thể hiện dựa trên học đối lập. Hàm mất mát cần được tối thiểu hóa được đưa ra dưới đây:

L = -log(exp(zq · zk) / (exp(zq · zk) + Σk̂∈Bk,k̂≠k exp(zq · zk̂))), (6)

trong đó zq biểu thị nhúng truy vấn, zk biểu thị nhúng tri thức liên quan, và zk̂ là nhúng tri thức không liên quan phục vụ như các thể hiện tiêu cực. Chúng tôi sử dụng tất cả các mẫu trong batch (Bk) làm các thể hiện tiêu cực.

Huấn luyện với Tiêu cực Khó. Việc áp dụng các mẫu ngẫu nhiên làm thể hiện tiêu cực có thể gây ra không gian metric dưới tối ưu. Nghiên cứu hiện có cho thấy rằng khai thác với các mẫu tiêu cực khó dẫn đến các biểu diễn phân biệt và đã được áp dụng cho một loạt rộng các nhiệm vụ như nhận dạng khuôn mặt (Zhang et al., 2017), bộ phát hiện đối tượng (Shrivastava et al., 2016), và học metric cho các nhiệm vụ truy xuất (Faghri et al., 2018; Harwood et al., 2017). Được truyền cảm hứng từ điều này, chúng tôi cũng thử nghiệm với kỹ thuật tiêu cực khó để tăng cường thêm hiệu suất truy xuất. Để có được các mẫu tiêu cực khó có ý nghĩa, đầu tiên chúng tôi huấn luyện ReViz với các giám sát trong công thức 6. Với điều đó, cho mỗi câu hỏi huấn luyện, chúng tôi truy xuất top-100 thể hiện tri thức (loại trừ sự thật cơ bản) làm các mẫu tiêu cực khó. Lưu ý rằng chúng tôi chỉ áp dụng khai thác tiêu cực khó cho việc tinh chỉnh trên nhiệm vụ hạ nguồn chứ không phải nhiệm vụ tiền huấn luyện (được giới thiệu trong phần tiếp theo).

5 Nhiệm vụ Tiền huấn luyện cho VL Retriever
Nghiên cứu trước đây (Chang et al., 2020; Lee et al., 2019; Guu et al., 2020) gợi ý rằng việc tiền huấn luyện một trình truy xuất trên nhiệm vụ không giám sát gần giống với truy xuất có thể cải thiện đáng kể hiệu suất nhiệm vụ hạ nguồn. Chúng tôi đề xuất một nhiệm vụ tiền huấn luyện có tên VL-ICT, được lấy cảm hứng từ nhiệm vụ ICT (Lee et al., 2019) trong lĩnh vực NLP.

ICT nhằm huấn luyện hệ thống truy xuất thông tin dựa trên văn bản (IR) cho nhiệm vụ trả lời câu hỏi miền mở. Để huấn luyện một mô hình mà không có dữ liệu được chú thích, Lee et al. (2019) đề xuất xây dựng các cặp (câu hỏi, ngữ cảnh) giả làm dữ liệu huấn luyện cho hệ thống IR. Cụ thể, cho một đoạn văn P, một câu ngẫu nhiên S trong đoạn văn được chọn làm câu hỏi giả, và đoạn văn còn lại P' được coi là ngữ cảnh liên quan. Cài đặt giám sát yếu như vậy cho phép tiền huấn luyện ICT quy mô lớn, tận dụng bất kỳ cơ sở tri thức có sẵn nào làm kho huấn luyện.

VL-ICT. Chúng tôi đề xuất nhiệm vụ VL-ICT để tiền huấn luyện ReViz, có thể được áp dụng cho các tình huống đa phương thức khi cả đầu vào ngôn ngữ và thị giác đều tồn tại trong truy vấn. Trong VL-ICT, một bộ ba (I, T, K) được sử dụng cho huấn luyện. Quan trọng là, I và T chứa thông tin loại trừ lẫn nhau và cả hai đều cần thiết cho truy xuất tri thức. Tuy nhiên, điều kiện như vậy không tồn tại một cách tự nhiên, do đó, chúng tôi đề xuất một quy trình tự động để xây dựng bộ ba thỏa mãn điều kiện này như sau.

Dữ liệu Huấn luyện VL-ICT. Hình 4 cho thấy một ảnh chụp của quy trình xây dựng dữ liệu của chúng tôi, trong đó chúng tôi sử dụng bộ dữ liệu WiT (Srinivasan et al., 2021) làm nguồn. Mỗi mục WiT cung cấp tiêu đề của trang hoặc chú thích hình ảnh, một đoạn văn và một hình ảnh. Chúng tôi sử dụng hình ảnh từ mục WiT này làm hình ảnh I trong bộ ba VL-ICT của chúng tôi. Chúng tôi quan sát thấy rằng tiêu đề hoặc chú thích thường là thực thể, nó cho phép chúng tôi đơn giản sử dụng khớp từ để tìm các câu trong đoạn văn trang bao gồm tiêu đề/chú thích. Chúng tôi lấy các câu như vậy làm văn bản (T), sau đó chúng tôi loại bỏ câu này khỏi đoạn văn và sử dụng đoạn văn còn lại làm tri thức (K). Để thực thi rằng (T) và (I) có thông tin loại trừ lẫn nhau nhưng quan trọng, chúng tôi che từ khóa trong T xuất hiện trong cả T cũng như chú thích. Trong các thí nghiệm của chúng tôi, chúng tôi chỉ chọn các thực thể tiếng Anh trong WiT và thực hiện quy trình trên, và điều này tạo ra 3,2 triệu bộ ba (I, T, K) huấn luyện.

6 Thí nghiệm và Kết quả
Bộ dữ liệu. Ngoài ReMuQ, chúng tôi tiến hành thí nghiệm trên OKVQA để có được bằng chứng mạnh mẽ hơn về hiệu quả của phương pháp chúng tôi. Ở đây, thay vì nhiệm vụ QA, chúng tôi sử dụng OKVQA như một bàn thử cho nhiệm vụ truy xuất, tức là để truy xuất một tri thức liên quan đến một câu hỏi sao cho nó chứa khoảng trả lời. Hơn nữa, chúng tôi sử dụng hai kho dữ liệu, một kho nhỏ được thu thập từ API tìm kiếm Google được giới thiệu trong Luo et al. (2021), và một kho lớn chứa 21M tri thức Wikipedia được sử dụng trong Gao et al. (2022). Thống kê của mỗi bộ dữ liệu được đưa ra trong Bảng 1.

Metric Đánh giá. Theo Gao et al. (2022); Luo et al. (2021), chúng tôi đánh giá hiệu suất của các mô hình bằng Precision@K (P@K), Recall@K (R@K), và MRR@5. Chúng tôi sử dụng metric tương tự để đánh giá thách thức ReMuQ ngoại trừ P@1 được sử dụng thay vì P@5 vì ReMuQ có đúng một tri thức đúng cho mỗi truy vấn.

6.1 Truy xuất Zero-shot
Trước tiên chúng tôi giới thiệu ba đường cơ sở zero-shot và sau đó trình bày kết quả.

Đường cơ sở CLIP. CLIP (Radford et al., 2021) là một mô hình thị giác-ngôn ngữ được tiền huấn luyện trên hơn 400M cặp hình ảnh-văn bản. Chúng tôi mã hóa tất cả mô tả tri thức thông qua bộ mã hóa văn bản của CLIP K. Sau đó, cho một cặp hình ảnh-văn bản làm truy vấn, chúng tôi sử dụng bộ mã hóa hình ảnh để có được các biểu diễn thị giác (I) và sử dụng bộ mã hóa văn bản để có được nhúng của Q. Chúng tôi tính toán tích vô hướng bên trong giữa tất cả các biểu diễn thị giác được mã hóa (I) và K để có được top-100 tri thức cho đánh giá, tương tự cho Q. Cuối cùng chúng tôi cộng các điểm và xếp hạng lại top-100 tri thức. Chúng tôi thấy điều này hoạt động tốt nhất so với việc sử dụng phương thức riêng lẻ (xem Phụ lục).

Đường cơ sở BM25. BM25 (Robertson and Zaragoza, 2009) là một thuật toán truy xuất hiệu quả nổi tiếng cho nhiệm vụ truy xuất dựa trên văn bản dựa trên biểu diễn thưa thớt. Chúng tôi sử dụng chú thích của hình ảnh để đại diện cho thông tin của hình ảnh và do đó chúng tôi chuyển đổi nhiệm vụ truy xuất tri thức đa phương thức thành một nhiệm vụ truy xuất dựa trên văn bản thuần túy.

Đường cơ sở DPR. Chúng tôi áp dụng DPR (Karpukhin et al., 2020) được huấn luyện trên bộ dữ liệu NaturalQuestions (Kwiatkowski et al., 2019) làm đường cơ sở, để truy xuất tri thức cho một cặp hình ảnh-văn bản đầu vào. Đầu tiên, chúng tôi sử dụng bộ mã hóa ngữ cảnh của DPR để lập chỉ mục kho dữ liệu, sau đó chúng tôi ghép nối câu hỏi và chú thích của hình ảnh làm một truy vấn văn bản chung. Với điều đó, bộ mã hóa câu hỏi của DPR trích xuất biểu diễn dày đặc của truy vấn cho tính toán sau này. Cuối cùng, chúng tôi giữ lại các mảnh tri thức liên quan nhất bằng cách tính toán tích vô hướng bên trong giữa nhúng truy vấn và tri thức.

Kết quả. Bảng 2 cho thấy hiệu suất của các đường cơ sở cũng như ReViz được tiền huấn luyện trên nhiệm vụ VL-ICT. Trong số các đường cơ sở, chúng tôi thấy rằng DPR là đường cơ sở mạnh nhất. Đáng ngạc nhiên, mặc dù CLIP đã cho thấy hiệu suất mạnh mẽ trên nhiều nhiệm vụ phân loại và tiền huấn luyện xuyên phương thức, nó không hoạt động tốt trên nhiệm vụ truy xuất truy vấn đa phương thức, điều này gợi ý rằng truy xuất truy vấn đa phương thức là một nhiệm vụ thách thức cho mô hình VL. Quan trọng hơn, chúng tôi quan sát rõ ràng rằng ReViz vượt trội hơn các đường cơ sở về tất cả metric trên nhiệm vụ OKVQA trên kho có kích thước nhỏ và lớn. Trên bộ dữ liệu ReMuQ, ReViz thắng CLIP và BM25 trên tất cả metric, và DPR trên hai metric. Điều này chứng minh hiệu quả của nhiệm vụ tiền huấn luyện được đề xuất và thiết kế mô hình.

6.2 Tinh chỉnh trên Nhiệm vụ Hạ nguồn
Để chứng minh thêm hiệu quả của nhiệm vụ tiền huấn luyện VL-ICT, chúng tôi tinh chỉnh các mô hình trên nhiệm vụ hạ nguồn và so sánh hiệu suất. Chúng tôi so sánh hai phiên bản của ReViz: (1) ReViz được huấn luyện trực tiếp trên nhiệm vụ hạ nguồn và (2) ReViz được tiền huấn luyện đầu tiên trên VL-ICT và sau đó tinh chỉnh nhiệm vụ hạ nguồn. Ngoài ra, chúng tôi nghiên cứu hai tình huống: trong miền, trong đó một mô hình được huấn luyện trên tập huấn luyện của miền X và được đánh giá trên tập kiểm tra của X; ngoài miền, trong đó một mô hình được huấn luyện trên tập huấn luyện của miền X và được đánh giá trên tập kiểm tra của miền Y.

Kết quả Trong miền. Bảng 3 cho thấy hiệu suất trong miền. Trên cả hai bộ dữ liệu, ReViz được tiền huấn luyện luôn vượt trội hơn ReViz thông thường, gợi ý rằng nhiệm vụ tiền huấn luyện trang bị cho ReViz sự căn chỉnh tốt hơn giữa các truy vấn đa phương thức và tri thức liên quan.

Kết quả Ngoài miền. Chúng tôi điều tra liệu nhiệm vụ tiền huấn luyện VL-ICT có thể cải thiện khả năng tổng quát hóa của ReViz không. Chúng tôi nghiên cứu hiệu suất của ReViz dưới hai cài đặt: huấn luyện trên OKVQA (miền X) và kiểm tra trên ReMuQ (miền Y); và ngược lại. Bảng 5 cho thấy ReViz+VL-ICT+X cho thấy kết quả rõ ràng tốt hơn ReViz+X trên Y, đặc biệt khi X là OKVQA và Y là ReMuQ. Điều này gợi ý rằng các mô hình được tiền huấn luyện với nhiệm vụ VL-ICT mạnh mẽ hơn các mô hình không có VL-ICT. Chúng tôi cũng thấy rằng hiệu suất tổng quát hóa vẫn có khoảng cách lớn với việc tinh chỉnh, điều này gợi ý rằng OKVQA và ReMuQ là những nhiệm vụ khá khác nhau, và ReMuQ có thể là một bổ sung tốt cho OKVQA để nghiên cứu nhiệm vụ truy xuất truy vấn đa phương thức.

6.3 So sánh với Các Phương pháp Hiện có
Chúng tôi so sánh ReViz với các phương pháp truy xuất hiện có cho nhiệm vụ OKVQA. Lưu ý rằng hầu hết các mô hình trên bảng xếp hạng của OKVQA chỉ báo cáo độ chính xác trả lời câu hỏi cuối cùng chứ không phải hiệu suất truy xuất. Trong các thí nghiệm của chúng tôi, chúng tôi bao gồm các hệ thống báo cáo hiệu suất truy xuất.

Đường cơ sở. Luo et al. (2021) trình bày hai trình truy xuất đa phương thức được tinh chỉnh: VRR-IMG sử dụng LXMERT (Tan and Bansal, 2019) và VRR-CAP để chuyển đổi hình ảnh thành chú thích cho truy xuất tri thức. Cả hai trình truy xuất đều sử dụng GS-112K làm kho tri thức. TriG (Gao et al., 2022) sử dụng trình truy xuất zeroshot và Wikipedia 21M làm kho tri thức. Vì các hệ thống này sử dụng trình truy xuất được tinh chỉnh hoặc trình truy xuất zero-shot, để so sánh công bằng, chúng tôi so sánh mô hình được tinh chỉnh tốt nhất và mô hình zeroshot với kho tương ứng.

Kết quả. Trong tình huống tinh chỉnh, trong phần lớn các trường hợp (chỉ một ngoại lệ, R@100), các mô hình của chúng tôi luôn cho thấy hiệu suất tốt hơn các phương pháp trước đây trên tổng thể metric. Tương tự, trong trường hợp zero-shot, mô hình của chúng tôi tốt hơn mô hình trước đây trên tất cả metric với biên độ lớn.

6.4 Tác động của Tỷ lệ Che trong Nhiệm vụ VL-ICT
Trong VL-ICT, chúng tôi che các từ khóa trong câu để ngăn rò rỉ thông tin. Mặc dù vậy, chúng tôi thấy rằng một số câu được che vẫn bằng cách nào đó trùng lặp với tri thức được truy xuất. Chúng tôi suy đoán rằng sự trùng lặp này làm cho nhiệm vụ VL-ICL trở nên dễ dàng không thể tránh khỏi, và do đó làm suy yếu tác động của tiền huấn luyện. Để nghiên cứu tỷ lệ che tối ưu, chúng tôi tiến hành thí nghiệm để che ngẫu nhiên các từ trong câu với các tỷ lệ khác nhau. Nghiên cứu này được thực hiện trên một kho nhỏ hơn là 1 triệu bộ ba huấn luyện VL-ICT và các mô hình được huấn luyện trong một epoch. Hình 7 cho thấy kết quả. Chúng tôi quan sát thấy rằng việc loại bỏ 20% từ khóa mang lại hiệu suất tốt nhất trong tất cả các tỷ lệ và cũng tốt hơn việc duy trì các câu nguyên vẹn (che 0%).

6.5 Tác động của Chú thích Được tạo
Các hệ thống trước đây dựa vào mô hình tạo chú thích bị ảnh hưởng bởi chất lượng của chú thích được tạo. Điều này có thể cản trở hiệu suất truy xuất khi mô hình tạo chú thích không được huấn luyện trên cùng miền với nhiệm vụ hạ nguồn. Trong bộ dữ liệu ReMuQ của chúng tôi, các hình ảnh từ Wikipedia, nhưng trình tạo chú thích được huấn luyện trên MS-COCO (Lin et al., 2014). Chúng tôi so sánh hai đường cơ sở của chúng tôi, BM25 và DPR, sử dụng chú thích hình ảnh sự thật cơ bản và chú thích được tạo. Bảng 6 cho thấy rằng sử dụng chú thích sự thật cơ bản tốt hơn nhiều so với chú thích được tạo trong tất cả các trường hợp. Điều này gợi ý rằng trình tạo chú thích là nút thắt cổ chai của các phương pháp truy xuất để chuyển đổi thông tin hình ảnh thành tạo chú thích hình ảnh. Điều này chứng minh những hạn chế của các phương pháp trước đây và biện minh cho việc khám phá huấn luyện đầu cuối của chúng tôi.

7 Kết luận
Chúng tôi nghiên cứu truy xuất tri thức với truy vấn đa phương thức (thị giác và ngôn ngữ), so với các nhiệm vụ truy xuất hiện có, thách thức hơn và ít được khám phá hơn. Ngoài ra, truy xuất thông tin truy vấn đa phương thức có nhiều ứng dụng tiềm năng, không chỉ trong các nhiệm vụ truy xuất như truy xuất hình ảnh, văn bản và video, mà còn trong trả lời câu hỏi, hệ thống đề xuất và trợ lý cá nhân. Bộ dữ liệu được đề xuất (ReMuQ) được định vị lý tưởng để hỗ trợ phát triển các chức năng như vậy. Chúng tôi đề xuất một mô hình truy xuất VL đầu cuối, ReViz, không dựa vào bất kỳ mô-đun dịch hình ảnh sang văn bản trung gian nào. Một nhiệm vụ giám sát yếu mới (VL-ICT) được đề xuất để cho phép tiền huấn luyện quy mô lớn. Các đánh giá mở rộng trên bộ dữ liệu ReMuQ và OK-VQA chứng minh rằng ReViz thể hiện hiệu suất mạnh mẽ trong tất cả các mô hình truy xuất trong cả tình huống zero-shot và tinh chỉnh. Bộ dữ liệu và mô hình được đề xuất của chúng tôi cung cấp nền tảng cho nghiên cứu tương lai có thể dẫn đến những phát hiện mới và ứng dụng đổi mới trong truy xuất thông tin truy vấn đa phương thức.

Hạn chế
Trong quá trình tạo bộ dữ liệu ReMuQ, chúng tôi đơn giản loại bỏ các từ trong câu hỏi được lặp lại trong chú thích hình ảnh - trong một số trường hợp, điều này có thể dẫn đến lỗi ngữ pháp trong truy vấn văn bản. Chúng tôi thực hiện các thí nghiệm để nghiên cứu tỷ lệ che tối ưu trên một tập con của dữ liệu tiền huấn luyện, do hạn chế tài nguyên.

Lời cảm ơn
Nghiên cứu này được hỗ trợ bởi các khoản tài trợ từ Quỹ Khoa học Quốc gia #1816039 và #2132724 và DARPA W911NF2020006. Quan điểm và ý kiến của các tác giả được bày tỏ ở đây không nhất thiết phải phát biểu hoặc phản ánh quan điểm của các cơ quan tài trợ và nhà tuyển dụng.

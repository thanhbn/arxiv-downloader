# 2304.13157.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2304.13157.pdf
# Kích thước tệp: 767449 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Phản hồi Liên quan Sinh tạo với Mô hình Ngôn ngữ Lớn
Iain Mackie
Đại học Glasgow
i.mackie.1@research.gla.ac.ukShubham Chatterjee
Đại học Glasgow
shubham.chatterjee@glasgow.ac.ukJeffrey Dalton
Đại học Glasgow
jeff.dalton@glasgow.ac.uk
TÓM TẮT
Các mô hình mở rộng truy vấn hiện tại sử dụng phản hồi liên quan giả để
cải thiện hiệu quả truy xuất lần đầu; tuy nhiên, điều này thất bại khi
kết quả ban đầu không liên quan. Thay vì xây dựng mô hình ngôn ngữ từ
kết quả truy xuất, chúng tôi đề xuất Phản hồi Liên quan Sinh tạo (GRF)
xây dựng mô hình phản hồi xác suất từ văn bản dạng dài được tạo ra từ
Mô hình Ngôn ngữ Lớn. Chúng tôi nghiên cứu các phương pháp hiệu quả để
tạo văn bản bằng cách thay đổi các nhiệm vụ con tạo không-shot: truy vấn,
thực thể, sự kiện, bài báo tin tức, tài liệu và tiểu luận. Chúng tôi đánh
giá GRF trên các điểm chuẩn truy xuất tài liệu bao gồm một tập hợp đa dạng
các truy vấn và bộ sưu tập tài liệu, và kết quả cho thấy các phương pháp
GRF vượt trội đáng kể so với các phương pháp PRF trước đây. Cụ thể, chúng
tôi cải thiện MAP từ 5-19% và NDCG@10 17-24% so với mở rộng RM3, và đạt
hiệu quả R@1k tốt nhất trên tất cả bộ dữ liệu so với các mô hình thưa,
dày đặc và mở rộng tiên tiến.
KHÁI NIỆM CCS
•Hệ thống thông tin →Truy xuất thông tin .
TỪ KHÓA
Phản hồi Liên quan Giả; Tạo Văn bản; Truy xuất Tài liệu
Định dạng Tham khảo ACM:
Iain Mackie, Shubham Chatterjee, và Jeffrey Dalton. 2023. Phản hồi Liên
quan Sinh tạo với Mô hình Ngôn ngữ Lớn. Trong Kỷ yếu Hội nghị Quốc tế
ACM SIGIR lần thứ 46 về Nghiên cứu và Phát triển trong Truy xuất Thông
tin (SIGIR '23), 23–27 tháng 7, 2023, Đài Bắc, Đài Loan. ACM, New York,
NY, USA, 6 trang. https://doi.org/10.1145/3539618.3591992
1 GIỚI THIỆU
Những tiến bộ gần đây trong Mô hình Ngôn ngữ Lớn (LLM) như GPT-3
[4], PaLM [6], và ChatGPT thể hiện khả năng mới trong việc tạo ra
văn bản dạng dài trôi chảy. Ngoài ra, LLM đang được kết hợp với
công cụ tìm kiếm, bao gồm BingGPT hoặc Bard, để tạo ra tóm tắt
kết quả tìm kiếm dưới dạng tương tác. Trong công trình này, chúng
tôi sử dụng các mô hình này không phải để tạo phản hồi cho người
dùng cuối mà làm đầu vào cho thuật toán truy xuất cốt lõi.
Cách tiếp cận cổ điển để giải quyết vấn đề không khớp từ vựng
[2] là mở rộng truy vấn sử dụng Phản hồi Liên quan Giả (PRF)
[1,30,31,51], trong đó truy vấn được mở rộng sử dụng các thuật ngữ
từ top-𝑘 tài liệu trong tập phản hồi. Tập phản hồi này được thu
thập bằng truy xuất lần đầu, và truy vấn được mở rộng sau đó được
sử dụng cho truy xuất lần hai. Trong khi mở rộng truy vấn với PRF
thường cải thiện recall, hiệu quả của nó phụ thuộc vào chất lượng
truy xuất lần đầu. Kết quả không liên quan trong tập phản hồi gây
ra nhiễu và có thể kéo truy vấn ra khỏi chủ đề.
Để giải quyết vấn đề này, chúng tôi đề xuất Phản hồi Liên quan
Sinh tạo (GRF) sử dụng LLM để tạo văn bản độc lập với truy xuất
lần đầu. Hình 1 cho thấy cách chúng tôi sử dụng LLM để tạo ra các
loại văn bản cụ thể cho truy vấn đa dạng, trước khi sử dụng những
"tài liệu được tạo" này làm đầu vào cho các mô hình mở rộng truy
vấn đã được chứng minh [1]. Chúng tôi thử nghiệm sử dụng các loại
văn bản được tạo ra sau: từ khóa, thực thể, lý luận chuỗi suy nghĩ,
sự kiện, bài báo tin tức, tài liệu và tiểu luận. Hơn nữa, chúng tôi
thấy rằng việc kết hợp văn bản qua tất cả các nhiệm vụ con tạo ra
kết quả MAP cao hơn 2-7% so với việc tạo độc lập tốt nhất.

Hình 1: GRF sử dụng nội dung văn bản được tạo bởi LLM đa dạng
cho phản hồi liên quan để bối cảnh hóa truy vấn.

Chúng tôi đánh giá GRF¹ trên bốn điểm chuẩn xếp hạng tài liệu
đã được thiết lập (xem Phần 4.1) và vượt trội so với một số mô
hình PRF thưa [1,37], dày đặc [19,32,41], và thưa đã học [17] tiên
tiến. Chúng tôi thấy rằng việc tạo văn bản dạng dài (tức là bài báo
tin tức, tài liệu và tiểu luận) hiệu quả hơn 7-14% như một tập phản
hồi so với văn bản ngắn hơn (tức là thực thể và từ khóa). Hơn nữa,
nhiệm vụ con tạo ra càng gần với phong cách của bộ dữ liệu đích
(tức là tạo tin tức cho corpus newswire hoặc tạo tài liệu cho corpus
tài liệu web), GRF càng hiệu quả. Cuối cùng, việc kết hợp văn bản
qua tất cả các nhiệm vụ con tạo ra cải thiện 2-7% MAP so với nhiệm
vụ con tạo độc lập tốt nhất.
Những đóng góp của công trình này là:
•Chúng tôi đề xuất GRF, một cách tiếp cận phản hồi liên quan sinh
tạo xây dựng mô hình liên quan sử dụng văn bản được tạo từ LLM.
•Chúng tôi cho thấy văn bản dạng dài được tạo bởi LLM theo phong
cách của bộ dữ liệu đích là hiệu quả nhất. Hơn nữa, việc kết hợp
văn bản qua nhiều nhiệm vụ con tạo có thể cải thiện thêm hiệu quả.
•Chúng tôi chứng minh rằng GRF cải thiện MAP từ 5-19% và NDCG@10
từ 17-24% so với mở rộng RM3, và đạt Recall@1000 tốt nhất so với
các mô hình truy xuất PRF thưa, dày đặc và thưa đã học tiên tiến.
¹Prompt và dữ liệu được tạo để tái sản xuất: linkarXiv:2304.13157v1  [cs.IR]  25 Apr 2023

--- TRANG 2 ---
2 CÔNG TRÌNH LIÊN QUAN
Mở rộng Truy vấn : Không khớp từ vựng là một vấn đề quan trọng
trong truy xuất thông tin, khi truy vấn của người dùng không nắm
bắt được hoàn toàn nhu cầu thông tin của họ [2]. Các phương pháp
mở rộng truy vấn [38] giải quyết vấn đề này bằng cách kết hợp các
thuật ngữ gần hơn với ý nghĩa dự định của người dùng. Một kỹ thuật
phổ biến cho mở rộng truy vấn tự động là phản hồi liên quan giả
(PRF), trong đó top 𝑘 tài liệu từ truy xuất ban đầu được giả định
là liên quan. Ví dụ, Rocchio [38], mở rộng KL [51], mô hình liên
quan [30], LCE [31], và mở rộng RM3 [1]. Ngoài ra, chúng ta đã
thấy các cách tiếp cận mở rộng truy vấn với thông tin dựa trên KG
[9,29,45,47] hoặc sử dụng vector LLM tập trung truy vấn cho mở
rộng truy vấn [32].
Những tiến bộ gần đây trong truy xuất dày đặc [16,21,46] đã dẫn
đến sự phát triển của các mô hình PRF dựa trên vector [19], như
ColBERT PRF [41], ColBERT-TCT PRF [49], và ANCE-PRF [49]. Hơn
nữa, SPLADE [11] là một mô hình truy xuất neural sử dụng BERT
và regularization thưa để học mở rộng thưa truy vấn và tài liệu.
Công trình gần đây đã tận dụng mở rộng truy vấn với PRF của biểu
diễn thưa đã học [17]. Khác với công trình trước, GRF không dựa
vào phản hồi liên quan giả, thay vào đó tạo ra bối cảnh văn bản
liên quan cho mở rộng truy vấn sử dụng LLM.
Tăng cường Truy vấn LLM Sự xuất hiện của LLM đã cho thấy tiến
bộ qua nhiều khía cạnh khác nhau của truy xuất thông tin [48].
Điều này bao gồm việc sử dụng LLM để thay đổi biểu diễn truy vấn,
như tạo và viết lại truy vấn [15,24,34,39,44,50], tạo bối cảnh
[12,23], và lý luận cụ thể cho truy vấn [10,36]. Ví dụ, Nogueira
et al. [34] fine-tune mô hình T5 để tạo truy vấn cho mở rộng tài
liệu cho truy xuất đoạn văn. Công trình gần đây hơn của Bonifacio
et al. [3] cho thấy GPT3 có thể được tận dụng hiệu quả cho tạo
truy vấn few-shot cho tạo bộ dữ liệu. Hơn nữa, LLM đã được sử
dụng cho viết lại truy vấn đối thoại [44] và tạo câu hỏi làm rõ [50].
Chúng ta cũng đã thấy tạo facet sử dụng T5 [24] và GPT3 [39] để
cải thiện sự liên quan hoặc đa dạng của kết quả tìm kiếm. Trong
QA, Liu et al. [23] lấy mẫu các manh mối bối cảnh khác nhau từ
LLM và tăng cường và kết hợp nhiều truy vấn. Đối với xếp hạng đoạn
văn, HyDe [12] sử dụng InstructGPT [35] để tạo embedding tài liệu
giả thuyết và sử dụng Contriever [14] cho truy xuất dày đặc. Cuối
cùng, các công trình đã cho thấy việc tạo LLM được sử dụng cho
lý luận cụ thể truy vấn [10,36] để cải thiện hiệu quả xếp hạng.
Cách tiếp cận của chúng tôi khác với các cách tiếp cận tăng cường
LLM trước đây vì chúng tôi sử dụng LLM để tạo văn bản dạng dài
để tạo ra mô hình mở rộng xác suất nhằm giải quyết vấn đề không
khớp từ vựng truy vấn-tài liệu.
3 PHẢN HỒI LIÊN QUAN SINH TẠO
Phản hồi Liên quan Sinh tạo (GRF) giải quyết vấn đề không khớp
từ vựng truy vấn-tài liệu bằng cách sử dụng tạo văn bản cho mở
rộng truy vấn zero-shot. Khác với các cách tiếp cận PRF truyền
thống cho mở rộng truy vấn [1,30,31], GRF không phụ thuộc vào
hiệu quả truy xuất lần đầu để tìm các thuật ngữ hữu ích cho mở
rộng. Thay vào đó, chúng tôi tận dụng LLM [5] để tạo nội dung
văn bản liên quan zero-shot.
Chúng tôi xây dựng dựa trên công trình trước về Mô hình Liên quan
[1] để kết hợp phân phối xác suất của các thuật ngữ được tạo bởi
LLM của chúng tôi. Cách tiếp cận này làm phong phú truy vấn gốc
với các thuật ngữ hữu ích từ các nhiệm vụ con tạo đa dạng, bao
gồm từ khóa, thực thể, lý luận chuỗi suy nghĩ, sự kiện, bài báo
tin tức, tài liệu và tiểu luận. Chúng tôi thấy rằng các mở rộng
truy vấn hiệu quả nhất là: (1) tạo văn bản dạng dài và (2) nội
dung văn bản gần hơn về phong cách với bộ dữ liệu đích. Về bản
chất, chúng tôi cho thấy LLM có thể hiệu quả tạo ra bối cảnh văn
bản zero-shot gần với các tài liệu liên quan đích.
Cuối cùng, chúng tôi đề xuất phương pháp GRF đầy đủ kết hợp nội
dung văn bản qua tất cả các nhiệm vụ con tạo. Trực giác đằng sau
cách tiếp cận này là nếu các thuật ngữ được sử dụng một cách nhất
quán được tạo ra qua các nhiệm vụ con (tức là trong tạo thực thể,
sự kiện và tin tức), thì những thuật ngữ này có khả năng hữu ích
cho mở rộng. Ngoài ra, nhiều nhiệm vụ con đa dạng cũng giúp phơi
bày kiến thức đuôi hoặc từ đồng nghĩa không phổ biến hữu ích cho
truy xuất. Chúng tôi thấy cách tiếp cận này hiệu quả hơn bất kỳ
nhiệm vụ con tạo độc lập nào.
3.1 Mở rộng Truy vấn GRF
Đối với một truy vấn cho trước 𝑄, Phương trình 1 cho thấy cách
𝑃𝐺𝑅𝐹(𝑤|𝑅) là xác suất của một thuật ngữ, 𝑤, có trong tài liệu
liên quan, 𝑅. Tương tự như RM3 [1], mở rộng GRF kết hợp xác
suất của một thuật ngữ cho truy vấn gốc 𝑃(𝑤|𝑄) với xác suất của
một thuật ngữ trong tài liệu được tạo bởi LLM, 𝑃(𝑤|𝐷𝐿𝐿𝑀), mà
chúng ta giả định là liên quan. 𝛽 (trọng số truy vấn gốc) là một
siêu tham số để cân nhắc tầm quan trọng tương đối của các thuật
ngữ mở rộng sinh tạo của chúng ta. Ngoài ra, 𝜃 (số thuật ngữ mở
rộng) là một siêu tham số với 𝑊𝜃 là tập hợp các thuật ngữ được
tạo bởi LLM có xác suất cao nhất.
𝑃𝐺𝑅𝐹(𝑤|𝑅)=𝛽𝑃(𝑤|𝑄)+(
(1−𝛽)𝑃(𝑤|𝐷𝐿𝐿𝑀),nếu𝑤∈𝑊𝜃.
0, nếu khác.(1)
3.2 Nhiệm vụ Con Tạo
Chúng tôi nghiên cứu cách LLM có thể tạo văn bản liên quan, 𝐷𝐿𝐿𝑀,
qua các nhiệm vụ con tạo đa dạng cho mở rộng GRF. 10 nhiệm vụ con
tạo cụ thể cho truy vấn là:
•Từ khóa (64 token) : Tạo danh sách các từ hoặc cụm từ quan trọng
cho chủ đề, tương tự như tạo facet [24, 39].
•Thực thể (64 token) : Tạo danh sách các khái niệm quan trọng
hoặc thực thể có tên, tương tự như các cách tiếp cận mở rộng dựa
trên KG [9].
•CoT-Từ khóa (256 token) : Tạo lý luận chuỗi suy nghĩ (CoT) [43]
để giải thích "tại sao" một danh sách từ khóa là liên quan.
•CoT-Thực thể (256 token) : Tạo lý luận CoT để giải thích "tại
sao" một danh sách thực thể là liên quan.
•Truy vấn (256 token) : Tạo danh sách truy vấn dựa trên truy vấn
gốc, tương tự như [3].
•Tóm tắt (256 token) : Tạo tóm tắt ngắn gọn (hoặc câu trả lời)
để thỏa mãn truy vấn.
•Sự kiện : Tạo danh sách sự kiện dựa trên văn bản chuyên sâu về
kiến thức về chủ đề, gần với [23].
•Tài liệu (512 token) : Tạo tài liệu liên quan dựa trên truy vấn
gần nhất với tài liệu web dạng dài.
•Tiểu luận (512 token) : Tạo phản hồi kiểu tiểu luận dạng dài.
•Tin tức (512 token) : Tạo văn bản theo phong cách bài báo tin tức.
Mô hình mở rộng GRF đầy đủ nối văn bản được tạo qua tất cả các
nhiệm vụ con để tạo ra 𝐷𝐿𝐋𝑀. Sau đó chúng tôi tính 𝑃(𝑤|𝐷𝐿𝐋𝑀)
sử dụng văn bản tổng hợp này, như được nêu ở trên. Phần 5 cho
thấy rằng việc kết hợp sử dụng văn bản qua tất cả các loại là hiệu
quả nhất.

--- TRANG 3 ---
4 THIẾT LẬP THỰC NGHIỆM
4.1 Bộ dữ liệu
4.1.1 Corpus Truy xuất. TREC Robust04 [40] được tạo ra để điều
tra các phương pháp nhắm vào các chủ đề có hiệu suất kém. Bộ dữ
liệu này bao gồm 249 chủ đề, chứa "tiêu đề" từ khóa ngắn và truy
vấn ngôn ngữ tự nhiên "mô tả" dài hơn. Đánh giá liên quan được
thực hiện trên bộ sưu tập newswire gồm 528k tài liệu dài (TREC
Disks 4 và 5), tức là FT, Congressional Record, LA Times, v.v.
CODEC [28] là một bộ dữ liệu tập trung vào nhu cầu thông tin phức
tạp của các nhà nghiên cứu khoa học xã hội. Các chuyên gia lĩnh
vực (nhà kinh tế, sử gia và chính trị gia) tạo ra 42 chủ đề kiểu
tiểu luận đầy thách thức. CODEC có corpus web tập trung gồm 750k
tài liệu dài, bao gồm tin tức (BBC, Reuters, CNBC, v.v.) và nội
dung web dựa trên tiểu luận (Brookings, Forbes, eHistory, v.v.).
TREC Deep Learning (DL) 19/20 [7,8] xây dựng dựa trên các truy
vấn và tài liệu web MS MARCO [33]. Bộ dữ liệu TREC DL sử dụng
các chú thích NIST để cung cấp đánh giá được gộp ở độ sâu lớn
hơn, chứa 43 chủ đề cho DL-19 và 45 chủ đề cho DL-20. Cả hai
tập truy vấn chủ yếu dựa trên factoid [27].
4.1.2 Lập chỉ mục và Đánh giá. Để lập chỉ mục, chúng tôi sử dụng
Pyserini phiên bản 0.16.0 [20], loại bỏ stopword và sử dụng Porter
stemming. Chúng tôi sử dụng cross-validation và tối ưu hóa R@1k
trên các fold tiêu chuẩn cho Robust04 [13] và CODEC [28]. Trên
DL-19, chúng tôi cross-validate trên DL-20 và sử dụng các tham số
trung bình zero-shot trên DL-19 (và ngược lại cho DL-20). Chúng
tôi đánh giá các run hệ thống ở độ sâu run là 1.000. Với GRF là
một mô hình truy xuất ban đầu, đánh giá hướng recall là quan trọng,
như Recall@1000 và MAP để xác định các tài liệu liên quan. Chúng
tôi cũng phân tích NDCG@10 để hiển thị độ chính xác ở các hạng
đầu. Chúng tôi sử dụng ir-measures cho tất cả các đánh giá [25]
và paired-t-test với độ tin cậy 95% để kiểm định ý nghĩa.
4.2 Triển khai GRF
Tạo LLM. Để tạo văn bản, chúng tôi sử dụng GPT3 API [5]. Cụ thể,
chúng tôi sử dụng mô hình text-davinci-002 với các tham số: nhiệt
độ 0.7, top_p 1.0, frequency_penalty 0.0, và presence_penalty 0.0.
Chúng tôi phát hành tất cả mã, prompt nhiệm vụ con tạo, nội dung
văn bản được tạo và run để tái sản xuất. Truy xuất và Mở rộng Để
tránh trôi truy vấn, tất cả các run GRF trong bài báo sử dụng hệ
thống BM25 được điều chỉnh cho run ban đầu đầu vào [37]. Chúng
tôi điều chỉnh các siêu tham số GRF: số thuật ngữ phản hồi (𝜃)
và phép nội suy giữa các thuật ngữ gốc và các thuật ngữ mở rộng
sinh tạo (𝛽). Phương pháp điều chỉnh giống như BM25 và BM25
với mở rộng RM3 để làm cho GRF có thể so sánh trực tiếp; xem
chi tiết bên dưới.
4.3 Phương pháp So sánh
BM25 [37]: Phương pháp truy xuất thưa, chúng tôi điều chỉnh tham
số 𝑘1 (0.1 đến 5.0 với bước 0.2) và 𝑏 (0.1 đến 1.0 với bước 0.1).
BM25+RM3 [1]: Đối với BM25 với mở rộng RM3, chúng tôi điều chỉnh
𝑓𝑏_𝑡𝑒𝑟𝑚𝑠 (5 đến 95 với bước 5), 𝑓𝑏_𝑑𝑜𝑐𝑠 (5 đến 50 với bước 5),
và 𝑜𝑟𝑖𝑔𝑖𝑛𝑎𝑙 _𝑞𝑢𝑒𝑟𝑦 _𝑤𝑒𝑖𝑔ℎ𝑡 (0.2 đến 0.8 với bước 0.1).
CEQE [32]: Sử dụng vector tập trung truy vấn cho mở rộng truy vấn.
Chúng tôi sử dụng các run CEQE-MaxPool được tác giả cung cấp.
SPLADE+RM3 : Chúng tôi sử dụng mở rộng RM3 [1] với SPLADE [11].
Chúng tôi sử dụng checkpoint naver/splade-cocondenser-ensembledistil
và "impact" searcher của Pyserini [20] cho tổng hợp max-passage.
Chúng tôi điều chỉnh 𝑓𝑏_𝑑𝑜𝑐𝑠 (5,10,15,20,25,30), 𝑓𝑏_𝑡𝑒𝑟𝑚𝑠
(20,40,60,80,100), và 𝑜𝑟𝑖𝑔𝑖𝑛𝑎𝑙 _𝑞𝑢𝑒𝑟𝑦 _𝑤𝑒𝑖𝑔ℎ𝑡 (0.1 đến 0.9
với bước 0.1).
TCT+PRF : [18] là cách tiếp cận Roccio PRF sử dụng ColBERT-TCT
[22]. Chúng tôi sử dụng cách tiếp cận max-passage với checkpoint
TCT-ColBERT-v2-HNP. Chúng tôi điều chỉnh các tham số Roccio PRF:
𝑑𝑒𝑝𝑡ℎ (2,3,5,7,10,17), 𝛼 (0.1 đến 0.9 với bước 0.1), và 𝛽
(0.1 đến 0.9 với bước 0.1).
ColBERT+PRF [41]: Chúng tôi sử dụng các run được cung cấp bởi
Wang et al. [42], sử dụng framework pyterrier [26] cho truy xuất
ColBERT-PRF.
5 KẾT QUẢ & PHÂN TÍCH
5.1 RQ1: Nội dung sinh tạo nào hiệu quả nhất
cho mở rộng truy vấn?
Bảng 1 cho thấy hiệu quả của phản hồi sinh tạo với các đơn vị văn
bản khác nhau (Từ khóa-Tin tức) và phương pháp lai hoàn chỉnh
của chúng ta sử dụng văn bản từ tất cả các nhiệm vụ con. Chúng
tôi kiểm tra cải thiện có ý nghĩa so với BM25 với mở rộng RM3, để
xác định liệu các phương pháp phản hồi sinh tạo zero-shot của chúng
ta có cải thiện so với mở rộng RM3 hay không.
Các nhiệm vụ con tạo nhắm vào khoảng văn bản ngắn hoặc danh
sách (Từ khóa, Thực thể, Từ khóa-COT, Thực thể-COT, và Truy vấn)
không
Bảng 1: GRF với các nhiệm vụ con tạo khác nhau. Cải thiện có ý nghĩa so với BM25+RM3 ("+") và hệ thống tốt nhất ( đậm).
Robust04 -Title CODEC DL-19 DL-20
NDCG@10 MAP R@1k NDCG@10 MAP R@1k NDCG@10 MAP R@1k NDCG@10 MAP R@1k
BM25 0.445 0.252 0.705 0.316 0.214 0.783 0.531 0.335 0.703 0.546 0.413 0.811
BM25+RM3 0.451 0.292 0.777 0.326 0.239 0.816 0.541 0.383 0.745 0.513 0.418 0.825
GRF-Từ khóa 0.435 0.252 0.717 0.327 0.218 0.748 0.565 0.377 0.749 0.554 0.435 0.822
GRF-Thực thể 0.452 0.252 0.698 0.341 0.216 0.750 0.531 0.363 0.741 0.544 0.414 0.824
GRF-CoT-Từ khóa 0.436 0.248 0.704 0.327 0.239 0.774 0.550 0.382 0.748 0.542 0.423 0.817
GRF-CoT-Thực thể 0.450 0.252 0.714 0.355 0.243 0.789 0.563 0.389 0.757 0.552 0.430 0.832
GRF-Truy vấn 0.450 0.257 0.710 0.347 0.233 0.773 0.551 0.367 0.760 0.568 0.439 0.851
GRF-Tóm tắt 0.491+0.277 0.730 0.398+0.260 0.796 0.577 0.414 0.761 0.585+0.472+0.865
GRF-Sự kiện 0.501+0.284 0.744 0.353 0.255 0.795 0.569 0.401 0.769 0.583+0.459+0.871
GRF-Tài liệu 0.480+0.276 0.728 0.376+0.265 0.795 0.618+0.428+0.787+0.589+0.476+0.872
GRF-Tiểu luận 0.494+0.284 0.736 0.405+0.270+0.803 0.609+0.421+0.779+0.551 0.440 0.859
GRF-Tin tức 0.501+0.287 0.745 0.398+0.270+0.828 0.609 0.409 0.777 0.578+0.457 0.853
GRF 0.528+0.307 0.788 0.405+0.285+0.830 0.620+0.441+0.797+0.607+0.486+0.879+

--- TRANG 4 ---
Bảng 2: GRF so với các mô hình PRF tiên tiến. Cải thiện có ý nghĩa so với BM25+RM3 ("+") và hệ thống tốt nhất ( đậm).
Robust04 -Title CODEC DL-19 DL-20
nDCG@10 MAP R@1k nDCG@10 MAP R@1k nDCG@10 MAP R@1k nDCG@10 MAP R@1k
BM25+RM3 0.451 0.292 0.777 0.326 0.239 0.816 0.541 0.383 0.745 0.513 0.418 0.825
CEQE-MaxPool 0.474 0.310+0.764 - - - 0.518 0.378 0.746 0.473 0.396 0.841
SPLADE+RM3 0.418 0.248 0.703 0.311 0.216 0.770 0.566 0.328 0.651 0.533 0.379 0.784
TCT+PRF 0.493 0.274 0.684 0.358 0.239 0.757 0.670+0.378 0.684 0.618+0.442 0.784
ColBERT-PRF 0.467 0.272 0.648 - - - 0.668+0.385 0.625 0.615+0.489+0.813
GRF (Của chúng tôi) 0.528+0.307 0.788 0.405+0.285+0.830 0.620+0.441+0.797+0.607+0.486+0.879+
mang lại cải thiện đáng kể so với mở rộng RM3. Ngược lại, các nhiệm
vụ con nhắm vào tạo văn bản dài (Tóm tắt, Sự kiện, Tài liệu, Tiểu
luận, Tin tức) cải thiện đáng kể ít nhất hai bộ dữ liệu so với mở
rộng RM3. Điều này cho thấy rằng nhiều thuật ngữ hơn được tạo từ
LLM cung cấp mô hình liên quan tốt hơn, và tăng MAP từ 7-14% khi
chúng ta so sánh hai danh mục này.
Hơn nữa, chúng tôi thấy các nhiệm vụ con tạo hiệu quả nhất được
căn chỉnh với phong cách của bộ dữ liệu đích. Ví dụ, Sự kiện và
Tin tức là các phương pháp tạo độc lập tốt nhất trên tất cả các
thước đo trên Robust04, nơi bộ dữ liệu chứa các chủ đề giàu sự
kiện và corpus newswire. Ngoài ra, Tiểu luận và Tin tức là các
nhiệm vụ con tạo tốt nhất trên CODEC trên tất cả các thước đo,
điều này phù hợp với các truy vấn kiểu tiểu luận của nó trên
corpus tin tức (BBC, Reuters, CNBC, v.v.) và kiểu tiểu luận
(Brookings, Forbes, eHistory, v.v.). Cuối cùng, Tài liệu là nhiệm
vụ con tạo tốt nhất trên DL-19 và DL-20, phù hợp với bộ sưu tập
tài liệu web MS Marcos. Nhìn chung, phát hiện này hỗ trợ rằng
nội dung sinh tạo LLM theo phong cách của bộ dữ liệu đích là hiệu
quả nhất.
Mặc dù chúng ta thấy cải thiện đáng kể từ một số nhiệm vụ con tạo
độc lập, đặc biệt là NDCG@10 (15/40 nhiệm vụ con trên các bộ dữ
liệu), phương pháp GRF đầy đủ nhất quán tốt ngang bằng nếu không
muốn nói là tốt hơn bất kỳ nhiệm vụ con độc lập nào. Cụ thể, GRF
cải thiện NDCG từ 0.0-5.4%, MAP từ 2.1-7.0% và R@1k từ 0.2-5.8%
trên các bộ dữ liệu. Điều này cho thấy rằng việc kết hợp văn bản
được tạo bởi LLM từ các nhiệm vụ con tạo khác nhau là một phương
pháp mô hình liên quan mạnh mẽ và hiệu quả.
Cuối cùng, những kết quả này cho thấy rằng mở rộng GRF từ văn
bản được tạo nhất quán tốt hơn, thường đáng kể, so với mở rộng
RM3 sử dụng tài liệu từ corpus đích. Cụ thể, chúng tôi thấy cải
thiện đáng kể trên tất cả các thước đo trên DL-19 và DL-20,
NDCG@10 và MAP trên CODEC, và NDCG@10 trên tiêu đề Robust04.
Mặc dù không bao gồm do hạn chế không gian, trên các truy vấn
mô tả Robust04, GRF cho thấy cải thiện đáng kể với NDCG là 0.550,
MAP là 0.318, và R@1k là 0.776.
Những kết quả này hỗ trợ mạnh mẽ rằng tạo LLM là một phương
pháp mở rộng truy vấn hiệu quả mà không dựa vào hiệu quả truy
xuất lần đầu. Ví dụ, chúng tôi xem xét 20% chủ đề khó nhất của
Robust04 được sắp xếp theo NDCG@10; chúng tôi thấy rằng RM3 mang
lại ít cải thiện và chỉ cải thiện NDCG@10 với +0.006, MAP với +0.008,
và R@1k với +0.052. Ngược lại, GRF không dựa vào hiệu quả truy
xuất lần đầu, và GRF cải thiện NDCG@10 với +0.145, MAP với +0.068,
và R@1k với +0.165 (cải thiện tương đối +100-200% trên NDCG@10
và MAP).5.2 RQ2: GRF so sánh như thế nào với
các mô hình PRF tiên tiến?
Bảng 2 cho thấy GRF so với các mô hình PRF thưa, dày đặc và thưa
đã học tiên tiến trên các bộ dữ liệu đích. Điều này cho phép chúng
tôi so sánh trực tiếp các truy vấn dựa trên thuật ngữ không giám
sát của GRF với các phương pháp PRF sử dụng embedding LLM phức
tạp hơn. Chúng tôi tiến hành kiểm định ý nghĩa so với BM25 với
mở rộng RM3.
GRF có R@1k tốt nhất trên tất cả bộ dữ liệu và có hiệu quả tương
đương và thường tốt hơn ở các hạng đầu. Cụ thể, trên các bộ dữ
liệu đầy thách thức hơn, như CODEC và tiêu đề Robust04, GRF là
hệ thống tốt nhất trên tất cả các thước đo, ngoại trừ MAP tiêu đề
Robust04, thấp hơn CEQE 0.003. Mặc dù không bao gồm do hạn chế
không gian, GRF cũng là hệ thống hiệu quả nhất trên mô tả Robust04
trên tất cả các thước đo. GRF vượt trội hơn hẳn truy xuất dày đặc
và PRF dày đặc trên những bộ dữ liệu đầy thách thức này, với khoảng
cách hiệu suất 7-14% trên NDCG@20, 13-21% MAP, và 10-22% R@1k.
Truy xuất dày đặc đã được chứng minh là rất hiệu quả trên các bộ
dữ liệu tập trung factoid hơn, như DL-19 và DL-20. Tuy nhiên, cũng
như R@1k tốt nhất, các truy vấn GRF không giám sát của chúng ta
có điểm NDCG@10 và MAP tương đương với các mô hình PRF dày đặc.
Điều này trái ngược với các phương pháp thưa khác (BM25 và BM25
với mở rộng RM3) hoặc mở rộng LLM (CEQE), có độ chính xác kém
hơn nhiều ở các hạng đầu. Nhìn chung, điều này hỗ trợ rằng mở
rộng sinh tạo là một phương pháp truy xuất ban đầu rất hiệu quả
trên các bộ sưu tập và loại truy vấn khác nhau.
6 KẾT LUẬN
Theo hiểu biết của chúng tôi, đây là công trình đầu tiên nghiên cứu
việc sử dụng văn bản dạng dài được tạo từ mô hình ngôn ngữ lớn
cho mở rộng truy vấn. Chúng tôi cho thấy rằng việc tạo văn bản
dạng dài theo định dạng giống tin tức và giống tiểu luận là đầu
vào hiệu quả cho các cách tiếp cận mở rộng truy vấn xác suất.
Kết quả trên truy xuất tài liệu trên nhiều corpus cho thấy cách
tiếp cận GRF được đề xuất vượt trội so với các mô hình sử dụng
tài liệu được truy xuất (PRF). Kết quả cho thấy GRF cải thiện MAP
từ 5-19% và NDCG@10 từ 17-24% khi so sánh với mở rộng RM3, và
đạt Recall@1000 tốt nhất so với các mô hình truy xuất PRF tiên
tiến. Chúng tôi hình dung GRF là một trong nhiều phương pháp mới
nổi sử dụng nội dung được tạo bởi LLM để cải thiện hiệu quả của
các tác vụ truy xuất cốt lõi.
7 LỜI CẢM ơN
Công trình này được hỗ trợ bởi Bloomberg Data Science Research
Grant 2019 và Engineering and Physical Sciences Research Council
grant EP/V025708/1.

--- TRANG 5 ---
TÀI LIỆU THAM KHẢO
[1]Nasreen Abdul-Jaleel, James Allan, W Bruce Croft, Fernando Diaz, Leah Larkey,
Xiaoyan Li, Mark D Smucker, và Courtney Wade. 2004. UMass tại TREC 2004:
Novelty và HARD. Computer Science Department Faculty Publication Series
(2004), 189.
[2]Nicholas J Belkin, Robert N Oddy, và Helen M Brooks. 1982. ASK cho truy xuất
thông tin: Phần I. Nền tảng và lý thuyết. Journal of documentation (1982).
[3]Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, và Rodrigo Nogueira. 2022.
Inpars: Tạo bộ dữ liệu không giám sát cho truy xuất thông tin. Trong Kỷ yếu
Hội nghị Quốc tế ACM SIGIR lần thứ 45 về Nghiên cứu và Phát triển trong Truy
xuất Thông tin . 2387–2392.
[4]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter,
Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin
Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya
Sutskever, và Dario Amodei. 2020. Mô hình Ngôn ngữ là Few-Shot Learners.
Trong Advances in Neural Information Processing Systems , H. Larochelle, M. Ran-
zato, R. Hadsell, M.F. Balcan, và H. Lin (Eds.), Vol. 33. Curran Associates,
Inc., 1877–1901. https://proceedings.neurips.cc/paper_files/paper/2020/file/
1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf
[5]Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al .2020. Mô hình ngôn ngữ là few-shot learners. arXiv preprint
arXiv:2005.14165 (2020).
[6]Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav
Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebas-
tian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran,
Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin,
Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay
Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin
Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek
Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani
Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana
Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr
Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz,
Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck,
Jeff Dean, Slav Petrov, và Noah Fiedel. 2022. PaLM: Scaling Language Modeling
with Pathways. arXiv:cs.CL/2204.02311
[7]Nick Craswell, Bhaskar Mitra, Emine Yilmaz, và Daniel Campos. 2021. Tổng quan
về TREC 2020 deep learning track. Trong Text REtrieval Conference (TREC) . TREC.
[8]Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, và Ellen M
Voorhees. 2020. Tổng quan về trec 2019 deep learning track. arXiv preprint
arXiv:2003.07820 (2020).
[9]Jeffrey Dalton, Laura Dietz, và James Allan. 2014. Mở rộng đặc trưng truy vấn
thực thể sử dụng liên kết cơ sở kiến thức. Trong Kỷ yếu hội nghị quốc tế ACM
SIGIR lần thứ 37 về Nghiên cứu & phát triển trong truy xuất thông tin . 365–374.
[10] Fernando Ferraretto, Thiago Laitz, Roberto Lotufo, và Rodrigo Nogueira.
2023. ExaRanker: Explanation-Augmented Neural Ranker. arXiv preprint
arXiv:2301.10521 (2023).
[11] Thibault Formal, Benjamin Piwowarski, và Stéphane Clinchant. 2021. SPLADE:
Mô hình từ vựng thưa và mở rộng cho xếp hạng giai đoạn đầu. Trong Kỷ yếu
Hội nghị Quốc tế ACM SIGIR lần thứ 44 về Nghiên cứu và Phát triển trong Truy
xuất Thông tin . 2288–2292.
[12] Luyu Gao, Xueguang Ma, Jimmy Lin, và Jamie Callan. 2022. Truy xuất Dày đặc
Zero-Shot Chính xác không có Nhãn Liên quan. arXiv preprint arXiv:2212.10496 (2022).
[13] Samuel Huston và W Bruce Croft. 2014. Tham số được học trong việc so sánh
các mô hình truy xuất sử dụng phụ thuộc thuật ngữ. Ir, University of Massachusetts
(2014).
[14] Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bo-
janowski, Armand Joulin, và Edouard Grave. 2021. Truy xuất Thông tin Dày đặc
Không giám sát với Học Tương phản. https://doi.org/10.48550/ARXIV.
2112.09118
[15] Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo,
Jakub Zavrel, và Rodrigo Nogueira. 2023. InPars-v2: Mô hình Ngôn ngữ Lớn
như Trình tạo Bộ dữ liệu Hiệu quả cho Truy xuất Thông tin. arXiv preprint
arXiv:2301.01820 (2023).
[16] Omar Khattab và Matei Zaharia. 2020. Colbert: Tìm kiếm đoạn văn hiệu quả
và hiệu lực thông qua tương tác muộn có ngữ cảnh trên bert. Trong Proc. of SIGIR . 39–48.
[17] Carlos Lassance và Stéphane Clinchant. 2023. Naver Labs Europe (SPLADE)@
TREC Deep Learning 2022. arXiv preprint arXiv:2302.12574 (2023).
[18] Hang Li, Ahmed Mourad, Shengyao Zhuang, Bevan Koopman, và G. Zuccon.
2021. Phản hồi Liên quan Giả với Mô hình Ngôn ngữ Sâu và Trình truy xuất
Dày đặc: Thành công và Cạm bẫy. ArXiv abs/2108.11044 (2021).
[19] Hang Li, Shengyao Zhuang, Ahmed Mourad, Xueguang Ma, Jimmy Lin, và
Guido Zuccon. 2022. Cải thiện Biểu diễn Truy vấn cho Truy xuất Dày đặc với Phản hồi Liên quan Giả: Một Nghiên cứu Tái sản xuất. Trong European Conference on
Information Retrieval . Springer, 599–612.
[20] Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep,
và Rodrigo Nogueira. 2021. Pyserini: Một bộ công cụ Python cho nghiên cứu
truy xuất thông tin có thể tái sản xuất với biểu diễn thưa và dày đặc. Trong
Kỷ yếu Hội nghị Quốc tế ACM SIGIR lần thứ 44 về Nghiên cứu và Phát triển
trong Truy xuất Thông tin . 2356–2362.
[21] Sheng-Chieh Lin, Jheng-Hong Yang, và Jimmy Lin. 2020. Chưng cất biểu diễn
dày đặc cho xếp hạng sử dụng giáo viên kết hợp chặt chẽ. arXiv preprint
arXiv:2010.11386 (2020).
[22] Sheng-Chieh Lin, Jheng-Hong Yang, và Jimmy Lin. 2021. In-batch negatives
cho chưng cất kiến thức với giáo viên kết hợp chặt chẽ cho truy xuất dày đặc.
Trong Kỷ yếu Workshop lần thứ 6 về Representation Learning for NLP (RepL4NLP-
2021) . 163–173.
[23] Linqing Liu, Minghan Li, Jimmy Lin, Sebastian Riedel, và Pontus Stenetorp.
2022. Mở rộng Truy vấn Sử dụng Lấy mẫu Manh mối Ngữ cảnh với Mô hình
Ngôn ngữ. arXiv preprint arXiv:2210.07093 (2022).
[24] Sean MacAvaney, Craig Macdonald, Roderick Murray-Smith, và Iadh Ounis.
2021. IntenT5: Đa dạng hóa Kết quả Tìm kiếm sử dụng Mô hình Ngôn ngữ
Nhân quả. arXiv preprint arXiv:2108.04026 (2021).
[25] Sean MacAvaney, Craig Macdonald, và Iadh Ounis. 2022. Streamlining Evalua-
tion với ir-measures. Trong European Conference on Information Retrieval . Springer,
305–310.
[26] Craig Macdonald, Nicola Tonellotto, Sean MacAvaney, và Iadh Ounis. 2021.
PyTerrier: Thử nghiệm tuyên bố trong Python từ BM25 đến truy xuất dày đặc.
Trong Kỷ yếu Hội nghị Quốc tế ACM lần thứ 30 về Information & Knowledge
Management . 4526–4533.
[27] Iain Mackie, Jeffrey Dalton, và Andrew Yates. 2021. Học sâu của bạn đến đâu:
Bộ dữ liệu học sâu có chú thích DL-HARD. Trong Kỷ yếu Hội nghị Quốc tế ACM
SIGIR lần thứ 44 về Nghiên cứu và Phát triển trong Truy xuất Thông tin . 2335–2341.
[28] Iain Mackie, Paul Owoicho, Carlos Gemmell, Sophie Fischer, Sean MacAvaney,
và Jeffery Dalton. 2022. CODEC: Complex Document and Entity Collection.
Trong Kỷ yếu Hội nghị Quốc tế ACM SIGIR lần thứ 44 về Nghiên cứu và Phát
triển trong Truy xuất Thông tin .
[29] Edgar Meij, Dolf Trieschnigg, Maarten De Rijke, và Wessel Kraaij. 2010. Mô
hình ngôn ngữ khái niệm cho truy xuất cụ thể miền. Information Processing &
Management 46, 4 (2010), 448–469.
[30] Donald Metzler và W Bruce Croft. 2005. Một mô hình trường ngẫu nhiên
markov cho phụ thuộc thuật ngữ. Trong Kỷ yếu hội nghị quốc tế ACM SIGIR
thường niên lần thứ 28 về Nghiên cứu và phát triển trong truy xuất thông tin . 472–479.
[31] Donald Metzler và W Bruce Croft. 2007. Mở rộng khái niệm tiềm ẩn sử dụng
trường ngẫu nhiên markov. Trong Kỷ yếu hội nghị quốc tế ACM SIGIR thường
niên lần thứ 30 về Nghiên cứu và phát triển trong truy xuất thông tin . 311–318.
[32] Shahrzad Naseri, Jeffrey Dalton, Andrew Yates, và James Allan. 2021. Ceqe:
Embedding có ngữ cảnh cho mở rộng truy vấn. Trong Advances in Information
Retrieval: 43rd European Conference on IR Research, ECIR 2021, Virtual Event,
March 28–April 1, 2021, Proceedings, Part I 43 . Springer, 467–482.
[33] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan
Majumder, và Li Deng. 2016. Ms marco: Một bộ dữ liệu hiểu đọc máy được
tạo bởi con người. (2016).
[34] Rodrigo Nogueira, Jimmy Lin, và AI Epistemic. 2019. Từ doc2query đến
docTTTTTquery. Online preprint 6 (2019).
[35] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al .2022.
Huấn luyện mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi của con
người. Advances in Neural Information Processing Systems 35 (2022), 27730–27744.
[36] Jayr Pereira, Robson Fidalgo, Roberto Lotufo, và Rodrigo Nogueira. 2023. Vis-
conde: Multi-document QA với GPT-3 và Neural Reranking. Trong Advances in
Information Retrieval: 45th European Conference on Information Retrieval, ECIR
2023, Dublin, Ireland, April 2–6, 2023, Proceedings, Part II . Springer, 534–543.
[37] Stephen E Robertson và Steve Walker. 1994. Một số xấp xỉ hiệu quả đơn giản
cho mô hình 2-poisson cho truy xuất có trọng số xác suất. Trong SIGIR'94 .
Springer, 232–241.
[38] Joseph Rocchio. 1971. Phản hồi liên quan trong truy xuất thông tin. The Smart
retrieval system-experiments in automatic document processing (1971), 313–323.
[39] Chris Samarinas, Arkin Dharawat, và Hamed Zamani. 2022. Xem lại Trích xuất
và Tạo Facet Truy vấn Miền Mở. Trong Kỷ yếu Hội nghị ACM SIGIR International
2022 về Theory of Information Retrieval . 43–50.
[40] Ellen M. Voorhees. 2004. Tổng quan về TREC 2004 Robust Track. Trong Kỷ yếu
Text REtrieval Conference lần thứ mười ba (TREC 2004) . Gaithersburg, Maryland,
52–69.
[41] Xiao Wang, Craig Macdonald, Nicola Tonellotto, và Iadh Ounis. 2022. ColBERT-
PRF: Phản hồi Liên quan Giả Ngữ nghĩa cho Truy xuất Đoạn văn và Tài liệu
Dày đặc. ACM Transactions on the Web (2022).
[42] Xiao Wang, Craig Macdonald, Nicola Tonellotto, và Iadh Ounis. 2023. ColBERT-
PRF: Phản hồi Liên quan Giả Ngữ nghĩa cho Truy xuất Đoạn văn và Tài liệu
Dày đặc. ACM Transactions on the Web 17, 1 (2023), 1–39.

--- TRANG 6 ---
[43] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi,
Quoc V Le, Denny Zhou, et al .[n. d.]. Chain-of-Thought Prompting Elicits Rea-
soning trong Mô hình Ngôn ngữ Lớn. Trong Advances in Neural Information Processing
Systems .
[44] Zeqiu Wu, Yi Luan, Hannah Rashkin, David Reitter, Hannaneh Hajishirzi, Mari
Ostendorf, và Gaurav Singh Tomar. 2022. CONQRR: Viết lại Truy vấn Đối thoại
cho Truy xuất với Học Tăng cường. Trong Kỷ yếu Hội nghị 2022 về Phương pháp
Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên . Association for Computational
Linguistics, Abu Dhabi, United Arab Emirates, 10000–10014.
https://aclanthology.org/2022.emnlp-main.679
[45] Chenyan Xiong và Jamie Callan. 2015. Mở rộng Truy vấn với Freebase. Trong
Kỷ yếu Hội nghị Quốc tế 2015 về Theory of Information Retrieval (ICTIR '15) .
Association for Computing Machinery, New York, NY, USA, 111–120. https://doi.org/10.1145/2808194.2809446
[46] Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N Bennett,
Junaid Ahmed, và Arnold Overwijk. [n. d.]. Học Tương phản Âm tính Láng giềng
Gần đúng cho Truy xuất Văn bản Dày đặc. Trong International Conference
on Learning Representations .[47] Yang Xu, Gareth J.F. Jones, và Bin Wang. 2009. Phản hồi Liên quan Giả
Phụ thuộc Truy vấn dựa trên Wikipedia. Trong Kỷ yếu Hội nghị Quốc tế ACM
SIGIR lần thứ 32 về Nghiên cứu và Phát triển trong Truy xuất Thông tin
(SIGIR '09) . Association for Computing Machinery, New York, NY, USA, 59–66.
https://doi.org/10.1145/1571941.1571954
[48] Andrew Yates, Rodrigo Nogueira, và Jimmy Lin. 2021. Transformer Đã được
Huấn luyện trước cho Xếp hạng Văn bản: BERT và Hơn thế nữa. Trong WSDM . 1154–1156.
[49] HongChien Yu, Chenyan Xiong, và Jamie Callan. 2021. Cải thiện Biểu diễn
Truy vấn cho Truy xuất Dày đặc với Phản hồi Liên quan Giả. Trong Kỷ yếu
Hội nghị Quốc tế ACM lần thứ 30 về Information & Knowledge Management .
3592–3596.
[50] Hamed Zamani, Susan Dumais, Nick Craswell, Paul Bennett, và Gord Lueck.
2020. Tạo câu hỏi làm rõ cho truy xuất thông tin. Trong Kỷ yếu web conference
2020 . 418–428.
[51] Chengxiang Zhai và John Lafferty. 2001. Phản hồi dựa trên mô hình trong
cách tiếp cận mô hình ngôn ngữ cho truy xuất thông tin. Trong Kỷ yếu hội
nghị quốc tế lần thứ mười về Information and knowledge management . 403–410.

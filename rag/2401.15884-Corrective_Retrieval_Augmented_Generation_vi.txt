u trên cho từng tài liệu được truy xuất, ba loại hành động được thiết kế và kích hoạt tương ứng khi các ngưỡng trên và dưới được thiết lập. Nếu điểm số tin cậy cao hơn ngưỡng trên, tài liệu được truy xuất được xác định là Đúng, trong khi được xác định là Sai nếu dưới ngưỡng dưới. Nếu không, một hành động mềm mại và trung gian hơn, tức là Mơ hồ được thực hiện. Mỗi tài liệu được truy xuất được tiến hành riêng biệt và cuối cùng được tích hợp.

Đúng Ở đây, một quá trình truy xuất được giả định là Đúng khi điểm số tin cậy của ít nhất một tài liệu được truy xuất cao hơn ngưỡng trên. Nếu vậy, điều đó có nghĩa là có các tài liệu liên quan trong kết quả truy xuất, và kiến thức từ kết quả truy xuất được cho là đáng tin cậy và chính xác hơn. Tuy nhiên, ngay cả khi một tài liệu liên quan có thể được tìm thấy, không thể tránh khỏi một số dải kiến thức nhiễu trong tài liệu này. Để trích xuất các dải kiến thức quan trọng nhất trong tài liệu này, một phương pháp tinh chỉnh kiến thức được thiết kế thêm sẽ được trình bày chi tiết trong Phần 4.4.

Sai Bên cạnh đó, một quá trình truy xuất được giả định là Sai khi điểm số tin cậy của tất cả các tài liệu được truy xuất đều dưới ngưỡng dưới. Điều này chỉ ra rằng tất cả các tài liệu được truy xuất được coi là không liên quan, không hữu ích cho quá trình sinh tạo. Một khi kiến thức từ kết quả truy xuất được đánh giá là không chính xác, việc vẫn bám víu vào nó là không khôn ngoan, có thể dẫn đến các sự thật bịa đặt. Do đó, chúng ta cần tìm kiếm các nguồn kiến thức mới để điều chỉnh. Ở đây, tìm kiếm web được giới thiệu để tìm kiếm từ Internet như được trình bày chi tiết trong Phần 4.5. Hành động điều chỉnh này giúp vượt qua thách thức khó xử khi không có kiến thức đáng tin cậy nào có thể được tham khảo.

Mơ hồ Ngoài hai tình huống trên, phần còn lại sẽ được gán cho một hành động trung gian là Mơ hồ. Điều này thường xảy ra khi độ chính xác của quá trình truy xuất khó phân biệt và bộ đánh giá đưa ra điểm số trung gian. Vì bộ đánh giá truy xuất không tự tin trong phán đoán của mình, cả hai loại kiến thức đã xử lý trong Đúng và Sai đều được kết hợp để bổ sung cho nhau. Việc triển khai một chiến lược điều hòa và mềm mại như vậy có thể đóng góp đáng kể vào việc tăng cường tính mạnh mẽ và khả năng phục hồi của hệ thống, thúc đẩy một khung thích ứng hơn để đạt hiệu suất tối ưu.

Thảo luận Các thí nghiệm sơ bộ chỉ sử dụng các hành động Đúng và Sai cho thấy hiệu quả của CRAG dễ bị ảnh hưởng bởi độ chính xác của bộ đánh giá truy xuất. Lý do có thể là việc chuyển đổi kiến thức rõ ràng cho tất cả các trường hợp đầu vào, bất kể mức độ tin cậy trong phán đoán của chúng. Việc thiết kế hành động Mơ hồ giúp giảm thiểu đáng kể sự phụ thuộc vào độ chính xác của bộ đánh giá truy xuất.

4.4 Tinh chỉnh Kiến thức
Cho một tài liệu liên quan được truy xuất, một phương pháp tinh chỉnh kiến thức phân rã-sau-tái-cấu-trúc được thiết kế để trích xuất thêm các dải kiến thức quan trọng nhất trong đó. Để có được kết quả truy xuất chi tiết, chúng tôi đã phân đoạn kết quả truy xuất thành các dải nội bộ. Nếu một kết quả truy xuất ngắn như một hoặc hai câu, nó được coi là một dải riêng biệt, nếu không, các tài liệu truy xuất cần được chia thành các đơn vị nhỏ hơn thường bao gồm vài câu theo tổng chiều dài. Quy mô được giả định bao gồm một phần thông tin độc lập, và việc lọc dựa trên các phân đoạn. Sau đó, bộ đánh giá truy xuất được tinh chỉnh trong Phần 4.2 được sử dụng để tính toán điểm số liên quan của từng dải kiến thức. Dựa trên các điểm số này, các dải kiến thức không liên quan được lọc bỏ, trong khi các dải liên quan được tái cấu trúc thông qua nối tiếp theo thứ tự, tức là kiến thức nội bộ.

4.5 Tìm kiếm Web
Sẽ thông minh hơn nếu một hệ thống có thể tự xác định rằng corpus kiến thức hiện có của nó không thể giải quyết vấn đề tốt và chuyển sang kiến thức bên ngoài bổ sung để được giúp đỡ. Ngược lại, ngay cả khi một hệ thống biết rằng kiến thức hiện có không thể giải quyết vấn đề, nhưng vẫn bám víu vào corpus kiến thức hạn chế, cuối cùng nó sẽ chỉ đưa ra một sự thật bịa đặt, điều này được gọi là ảo giác. Do đó, việc tìm kiếm kiến thức bên ngoài bổ sung nếu kết quả truy xuất đều được giả định là không liên quan là cực kỳ quan trọng, và chúng tôi coi một hệ thống biết những gì nó không biết và những gì nó không thể trả lời thông minh hơn một hệ thống bám víu vào kiến thức hạn chế và không có khả năng tìm kiếm kiến thức bên ngoài. Vì việc truy xuất từ các corpus tĩnh và hạn chế chỉ có thể trả về các tài liệu tối ưu dưới mức về phạm vi và tính đa dạng, các tìm kiếm web quy mô lớn (Piktus et al., 2021; Komeili et al., 2022) được tích hợp như một phần mở rộng chiến lược của RAG.

Cụ thể, các đầu vào được viết lại thành các truy vấn bao gồm các từ khóa bởi ChatGPT để bắt chước việc sử dụng hàng ngày của công cụ tìm kiếm. Lời nhắc để viết lại được hiển thị trong Phụ lục A. Trong CRAG, một API tìm kiếm web thương mại công khai và có thể truy cập được áp dụng để tạo ra một loạt liên kết URL cho mỗi truy vấn.3 Xem xét rằng kiến thức từ các tìm kiếm web quy mô lớn có thể giới thiệu thành kiến hoặc thông tin không đáng tin cậy, các trang web có thẩm quyền và được kiểm soát như Wikipedia được ưu tiên, điều này có thể giúp giảm thiểu đáng kể các vấn đề này. Hơn nữa, chúng tôi sử dụng các liên kết URL để điều hướng các trang web, chép lại nội dung của chúng, và sử dụng cùng phương pháp tinh chỉnh kiến thức như Phần 4.4 để rút ra kiến thức web liên quan, tức là kiến thức bên ngoài.

5 Thí nghiệm
Chúng tôi đã tiến hành các thí nghiệm để chứng minh rộng rãi khả năng thích ứng của CRAG với các phương pháp dựa trên RAG và khả năng tổng quát hóa của nó trên cả các tác vụ sinh tạo dạng ngắn và dài.

5.1 Tác vụ, Bộ dữ liệu và Số liệu
CRAG được đánh giá trên bốn bộ dữ liệu, bao gồm PopQA (Mallen et al., 2023) (sinh tạo dạng ngắn), Biography (Min et al., 2023) (sinh tạo dạng dài), PubHealth (Zhang et al., 2023a) (câu hỏi đúng-sai), và Arc-Challenge (Bhakthavatsalam et al., 2021) (câu hỏi trắc nghiệm). Theo công trình trước đây, độ chính xác được áp dụng làm số liệu đánh giá cho PopQA, PubHealth, và Arc-Challenge. FactScore (Min et al., 2023) được áp dụng làm số liệu đánh giá cho Biography. Độc giả có thể tham khảo Phụ lục B.1 để biết thêm chi tiết. Các số liệu tương tự được sử dụng vì phương pháp được đề xuất của chúng tôi có thể so sánh với các nghiên cứu trước đây, vì chúng tôi đã sử dụng cùng kết quả truy xuất như công trình trước đây. Sự khác biệt nằm ở chỗ động lực của chúng tôi là cải thiện chất lượng truy xuất bằng cách điều chỉnh kết quả truy xuất mà hệ thống đánh giá là có chất lượng thấp. Điều này có thể được ví như việc tăng cường của RAG đối với các mô hình ngôn ngữ tham số hóa độc lập và chúng tôi tiếp tục tăng cường RAG với các chiến lược điều chỉnh.

5.2 Đường cơ sở
Chúng tôi chủ yếu so sánh CRAG với cả các phương pháp có và không có truy xuất, trong đó phương pháp sau có thể được chia thành RAG tiêu chuẩn và RAG tiên tiến mới nhất, bao gồm:

Đường cơ sở không có truy xuất. Chúng tôi đánh giá một số LLM công cộng, LLaMA2-7B,13B (Touvron et al., 2023b), các mô hình được điều chỉnh hướng dẫn, Alpaca-7B,13B (Dubois et al., 2023), và CoVE 65B (Dhuliawala et al., 2024) giới thiệu kỹ thuật lặp đi lặp lại để cải thiện tính thực tế của các thế hệ LLM. Các LLM độc quyền như LLaMA2-chat 13B và ChatGPT cũng được bao gồm.

RAG Tiêu chuẩn. Chúng tôi đánh giá RAG tiêu chuẩn (Lewis et al., 2020) nơi một LM sinh tạo đầu ra cho truy vấn được thêm trước với các tài liệu được truy xuất hàng đầu sử dụng cùng bộ truy xuất như trong hệ thống của chúng tôi. Ở đây chúng tôi áp dụng một số LLM được điều chỉnh hướng dẫn công cộng, bao gồm LLaMA2-7B, 13B (Touvron et al., 2023b), Alpaca-7B,13B (Dubois et al., 2023), cũng như LLaMA2-7B được điều chỉnh hướng dẫn trong Self-RAG (Asai et al., 2024).

RAG Tiên tiến. (1) SAIL (Luo et al., 2023) đã điều chỉnh hướng dẫn một LM trên dữ liệu điều chỉnh hướng dẫn Alpaca với các tài liệu được truy xuất hàng đầu được chèn trước các hướng dẫn. (2) Self-RAG (Asai et al., 2024) đã điều chỉnh LLaMA2 trên dữ liệu điều chỉnh hướng dẫn chứa nhiều bộ token phản ánh được gán nhãn bởi GPT-4 (OpenAI, 2023). (3) Theo Asai et al. (2024), chúng tôi cũng trích dẫn kết quả của các đường cơ sở tăng cường truy xuất được huấn luyện với dữ liệu riêng: Ret-ChatGPT và Ret-LLaMA-chat, triển khai cùng kỹ thuật tăng cường ở trên, cũng như perplexity.ai, một hệ thống tìm kiếm sản xuất dựa trên InstructGPT.

5.3 Kết quả
Bảng 1 trình bày kết quả trên bốn bộ dữ liệu. Mô hình kết hợp phương pháp được đề xuất với RAG tiêu chuẩn được đặt tên là CRAG và mô hình kết hợp với Self-RAG được đặt tên là Self-CRAG. Độc giả có thể tham khảo Phụ lục B.3 để biết thêm chi tiết triển khai của các phương pháp được đề xuất. Từ những kết quả này, chúng tôi có thể rút ra các phát hiện sau:

Thứ nhất, phương pháp được đề xuất có thể cải thiện đáng kể hiệu suất của RAG và Self-RAG. Cụ thể, như được hiển thị trong bảng 1, CRAG vượt trội hơn RAG với biên độ 7.0% độ chính xác trên PopQA, 14.9% FactScore trên Biography, 36.6% độ chính xác trên PubHealth, và 15.4% độ chính xác trên Arc-Challenge khi dựa trên SelfRAG-LLaMA2-7b, cũng như với biên độ 4.4% độ chính xác trên PopQA, 2.8% FactScore trên Biography, và 10.3% trên Arc-Challenge khi dựa trên LLaMA2-hf-7b. So với Self-RAG tiên tiến hiện tại, Self-CRAG vượt trội hơn nó với biên độ 20.0% độ chính xác trên PopQA, 36.9% FactScore trên Biography, và 4.0% độ chính xác trên Arc-Challenge khi dựa trên LLaMA2-hf-7b, cũng như với biên độ 6.9% độ chính xác trên PopQA, 5.0% FactScore trên Biography, và 2.4% độ chính xác trên PubHealth, khi dựa trên SelfRAG-LLaMA2-7b. Những kết quả này chứng minh khả năng thích ứng của CRAG là plug-and-play và có thể được triển khai vào các phương pháp dựa trên RAG.

Thứ hai, phương pháp được đề xuất thể hiện khả năng tổng quát hóa tuyệt vời trên nhiều tác vụ sinh tạo khác nhau. Đặc biệt, các điểm chuẩn được báo cáo trong Bảng 1 tương ứng đại diện cho các tình huống thực tế khác nhau bao gồm sinh tạo thực thể dạng ngắn (PopQA), sinh tạo dạng dài (Biography), và các tác vụ tập đóng (PubHealth, Arc-Challenge). Những kết quả này xác minh hiệu quả nhất quán của CRAG. Tính linh hoạt của nó trên nhiều tác vụ khác nhau nhấn mạnh khả năng mạnh mẽ và khả năng tổng quát hóa của nó trên các tình huống đa dạng.

Thứ ba, phương pháp được đề xuất thể hiện tính linh hoạt lớn hơn trong việc thay thế bộ sinh tạo LLM cơ bản. Có thể thấy rằng CRAG vẫn cho thấy hiệu suất cạnh tranh khi LLM cơ bản được thay đổi từ SelfRAG-LLaMA2-7b sang LLaMA2-hf-7b, trong khi hiệu suất của Self-RAG giảm đáng kể, thậm chí kém hiệu suất hơn RAG tiêu chuẩn trên một số điểm chuẩn. Lý do cho những kết quả này là Self-RAG cần được điều chỉnh hướng dẫn sử dụng dữ liệu được chú thích bởi con người hoặc LLM để học cách xuất ra các token phê bình đặc biệt khi cần thiết, trong khi khả năng này không được học trong các LLM thông thường. CRAG không có bất kỳ yêu cầu nào cho khả năng này. Như bạn có thể tưởng tượng, khi các LLM tiên tiến hơn có sẵn trong tương lai, chúng có thể được kết hợp với CRAG một cách dễ dàng, trong khi việc điều chỉnh hướng dẫn bổ sung vẫn cần thiết cho Self-RAG.

--- TRANG 8 ---
LLaMA2-hf-7b SelfRAG-LLaMA2-7b
CRAG 54.9 59.8
w/o. Đúng 53.2 58.3
w/o. Sai 54.4 59.5
w/o. Mơ hồ 54.0 59.0
Self-CRAG 49.0 61.8
w/o. Đúng 43.6 59.6
w/o. Sai 47.7 60.8
w/o. Mơ hồ 48.1 61.5

Bảng 2: Nghiên cứu loại bỏ để loại bỏ từng hành động đơn lẻ trên bộ dữ liệu PopQA về độ chính xác.

LLaMA2-hf-7b SelfRAG-LLaMA2-7b
CRAG 54.9 59.8
w/o. tinh chỉnh 49.8 54.2
w/o. viết lại 51.7 56.2
w/o. lựa chọn 50.9 58.6
Self-CRAG 49.0 61.8
w/o. tinh chỉnh 35.9 52.2
w/o. viết lại 37.2 58.4
w/o. lựa chọn 24.9 57.9

Bảng 3: Nghiên cứu loại bỏ để loại bỏ từng hoạt động sử dụng kiến thức trên PopQA về độ chính xác.

5.4 Nghiên cứu Loại bỏ
Tác động của từng hành động được kích hoạt. Để xác minh thêm hiệu quả của các hành động được kích hoạt được thiết kế trong bộ đánh giá truy xuất, các kiểm tra loại bỏ để loại bỏ từng hành động đơn lẻ trong phương pháp được đề xuất đã được tiến hành như được hiển thị trong Bảng 2. Các đánh giá trên bộ dữ liệu PopQA được tiến hành để chứng minh sự thay đổi hiệu suất về độ chính xác. Cụ thể, khi hành động Đúng hoặc Sai được loại bỏ, nó được hợp nhất với Mơ hồ để tỷ lệ ban đầu kích hoạt Đúng hoặc Sai sẽ kích hoạt Mơ hồ. Mặt khác, khi hành động Mơ hồ được loại bỏ, chỉ có một ngưỡng để so sánh tất cả các truy vấn đầu vào rõ ràng kích hoạt Đúng hoặc Sai. Từ những kết quả này, có thể thấy rằng có sự giảm hiệu suất bất kể hành động nào được loại bỏ, minh họa rằng mỗi hành động đều đóng góp vào việc cải thiện tính mạnh mẽ của quá trình sinh tạo. Để minh họa thêm nghiên cứu, các thí nghiệm cũng được tiến hành bằng cách chỉ kích hoạt một hành động duy nhất, và kết quả được hiển thị trong phụ lục cũng chứng minh tính nhất quán.

Tác động của từng hoạt động sử dụng kiến thức. Bảng 3 minh họa cách hiệu suất thay đổi nếu một hoạt động sử dụng kiến thức quan trọng được loại bỏ. Các đánh giá trên bộ dữ liệu PopQA về độ chính xác được tiến hành bằng cách loại bỏ riêng biệt các hoạt động sử dụng kiến thức của tinh chỉnh tài liệu, viết lại truy vấn tìm kiếm, và lựa chọn kiến thức bên ngoài. Loại bỏ tinh chỉnh tài liệu có nghĩa là các tài liệu được truy xuất ban đầu được cung cấp trực tiếp cho bộ sinh tạo tiếp theo, như trong hầu hết các công trình hiện có. Ngoài ra, loại bỏ viết lại truy vấn tìm kiếm có nghĩa là các câu hỏi không được viết lại thành các truy vấn bao gồm từ khóa trong quá trình tìm kiếm kiến thức. Cuối cùng, loại bỏ lựa chọn kiến thức có nghĩa là tất cả nội dung được tìm kiếm của các trang web đều được coi là kiến thức bên ngoài mà không có lựa chọn. Những kết quả này giúp rút ra phát hiện rằng hiệu suất của hệ thống cuối cùng bị suy giảm bất kể hoạt động sử dụng kiến thức nào được loại bỏ, tiết lộ rằng mỗi hoạt động sử dụng kiến thức đều đóng góp vào việc cải thiện việc sử dụng kiến thức.

5.5 Độ chính xác của Bộ Đánh giá Truy xuất
Chất lượng của bộ đánh giá truy xuất quyết định đáng kể hiệu suất của toàn bộ hệ thống. Cho kết quả truy xuất tài liệu, chúng tôi đánh giá liệu bộ đánh giá truy xuất có thể xác định chính xác chất lượng tổng thể của những kết quả này hay không. Độ chính xác đánh giá trên bộ dữ liệu PopQA của bộ đánh giá truy xuất của chúng tôi và LLM thương mại ChatGPT trên kết quả truy xuất tài liệu được hiển thị trong Bảng 4. Các lời nhắc của ChatGPT, ChatGPT-CoT, và ChatGPT-few-shot được sử dụng trong các thí nghiệm của chúng tôi có thể được tham khảo trong Phụ lục A. Kết quả tiết lộ rằng bộ đánh giá truy xuất nhẹ dựa trên T5 vượt trội đáng kể so với ChatGPT cạnh tranh trong tất cả các cài đặt.

--- TRANG 9 ---
Độ chính xác
Bộ Đánh giá Truy xuất của chúng tôi (dựa trên T5) 84.3
ChatGPT 58.0
ChatGPT-CoT 62.4
ChatGPT-few-shot 64.7

Bảng 4: Đánh giá bộ đánh giá truy xuất của chúng tôi và ChatGPT cho kết quả truy xuất trên bộ dữ liệu PopQA.

5.6 Tính mạnh mẽ đối với Hiệu suất Truy xuất
Để xác minh thêm tính mạnh mẽ của phương pháp được đề xuất đối với hiệu suất truy xuất, chúng tôi nghiên cứu cách hiệu suất sinh tạo thay đổi khi có hiệu suất truy xuất khác nhau. Một phần kết quả truy xuất chính xác được cố ý loại bỏ ngẫu nhiên để bắt chước bộ truy xuất chất lượng thấp và đánh giá cách hiệu suất thay đổi. Hình 3 chứng minh sự thay đổi hiệu suất của Self-RAG và Self-CRAG trên bộ dữ liệu PopQA. Có thể thấy rằng hiệu suất sinh tạo của Self-RAG và Self-CRAG giảm khi hiệu suất truy xuất giảm, cho thấy bộ sinh tạo phụ thuộc nhiều vào chất lượng của bộ truy xuất. Hơn nữa, khi hiệu suất truy xuất giảm, hiệu suất sinh tạo của Self-CRAG giảm nhẹ hơn so với Self-RAG. Những kết quả này ngụ ý sự ưu việt của Self-CRAG so với Self-RAG trong việc tăng cường tính mạnh mẽ đối với hiệu suất truy xuất.

69.8
(Thực tế)60 50 40 30 20 10
Độ chính xác của truy xuất203040506070 Độ chính xác của sinh tạo
không truy xuấtSelf-RAG Self-CRAG

Hình 3: Hiệu suất sinh tạo của Self-RAG và Self-CRAG cho hiệu suất truy xuất khác nhau trên bộ dữ liệu PopQA với SelfRAG-LLaMA-7b. Đường ngang dưới thể hiện hiệu suất của bộ sinh tạo không có truy xuất.

LLaMA2-hf-7b SelfRAG-LLaMA2-7b
PopQA
CRAG 54.9 59.8
RAG 50.5 52.8
RAG w. web 52.2 53.8
Self-CRAG 49.0 61.8
Self-RAG 29.0 54.9
Self-RAG w. web 24.9 57.9

Bảng 5: Kết quả so sánh giữa CRAG, Self-CRAG và RAG, Self-RAG với cùng đầu vào về độ chính xác.

5.7 Bổ sung Nhất quán của Kiến thức Tìm kiếm Web
Bài báo này nhấn mạnh sự cần thiết của việc tăng cường ngữ cảnh được truy xuất bằng cách kết hợp thông tin bổ sung khi kết quả truy xuất ban đầu không liên quan và không đáng tin cậy. Đồng thời, cũng quan trọng để xác nhận rằng những cải thiện chính trong phương pháp của chúng tôi xuất phát từ cơ chế tự điều chỉnh, chứ không chỉ từ thông tin bổ sung thu được thông qua tìm kiếm web. Để chứng minh thêm hiệu quả của cơ chế tự điều chỉnh được đề xuất, cả RAG và Self-RAG đều được bổ sung nhất quán với kiến thức tìm kiếm web để đảm bảo chúng có quyền truy cập vào cùng phạm vi kiến thức được truy xuất. Kết quả trong Bảng 5 cho thấy việc bổ sung nhất quán RAG hoặc Self-RAG với kiến thức tìm kiếm web có thể cải thiện hiệu suất trong hầu hết các trường hợp (ngoại trừ Self-RAG w. web sử dụng mô hình LLaMA2 gốc), mặc dù cải thiện vẫn hạn chế. Hơn nữa, việc tăng cường RAG hoặc Self-RAG với cơ chế tự điều chỉnh được đề xuất vượt trội đáng kể so với các mô hình được bổ sung nhất quán với kiến thức tìm kiếm web trong tất cả các trường hợp. Phát hiện này xác nhận rằng những tiến bộ quan sát được chủ yếu do cơ chế tự điều chỉnh được đề xuất.

5.8 Phân tích Chi phí Tính toán
Để minh họa rằng cơ chế tự điều chỉnh của chúng tôi đóng vai trò như một giải pháp nhẹ, plug-and-play cho các khung dựa trên RAG khác nhau, chúng tôi đo chi phí tính toán. Các công thức dự đoán FLOPs trong Narayanan et al. (2021) được sử dụng, với kết quả được trình bày trong Bảng 6 cho thấy FLOPs dự đoán trên mỗi token trên GPU. Do bản chất thích ứng của Self-RAG, thay đổi các chiến lược sinh tạo dựa trên đầu vào, chi phí tính toán không thể được xác định chính xác. Do đó, chúng tôi trình bày một phạm vi ước tính thay thế. Ngoài ra, chúng tôi đã tiến hành các thí nghiệm trên PopQA để đánh giá thời gian thực hiện trung bình trên mỗi instance trong thực tế, như được chi tiết trong Bảng 6. Các phát hiện cho thấy cơ chế tự điều chỉnh chỉ gây ra chi phí tính toán khiêm tốn trong khi cải thiện đáng kể hiệu suất, từ đó xác thực bản chất nhẹ của nó.

TFLOPs trên mỗi token thời gian thực hiện(s)
RAG 26.5 0.363
CRAG 27.2 0.512
Self-RAG 26.5 ∼132.4 0.741
Self-CRAG 27.2 ∼80.2 0.908

Bảng 6: đánh giá chi phí tính toán của RAG, CRAG, Self-CRAG, và Self-RAG về FLOPs trên mỗi token trên GPU và thời gian thực hiện trên mỗi instance. Giới hạn trên của Self-CRAG thấp hơn vì chỉ ba đoạn văn được cung cấp làm đầu vào (nội dung đúng, sai và mơ hồ). Tất cả dữ liệu trong bảng chỉ đại diện cho ước tính thô của giai đoạn sinh tạo, các giai đoạn truy xuất và xử lý dữ liệu không được bao gồm.

6 Kết luận & Hạn chế
Bài báo này nghiên cứu vấn đề khi các phương pháp dựa trên RAG gặp thách thức nếu quá trình truy xuất gặp sai sót, từ đó phơi bày kiến thức không chính xác và gây hiểu lầm cho các LM sinh tạo. Sinh Tạo Tăng Cường Truy Xuất Có Điều Chỉnh được đề xuất để cải thiện tính mạnh mẽ của quá trình sinh tạo. Về cơ bản, một bộ đánh giá truy xuất nhẹ để ước tính và kích hoạt ba hành động truy xuất kiến thức một cách phân biệt. Với việc tận dụng thêm tìm kiếm web và sử dụng kiến thức được tối ưu hóa, CRAG đã cải thiện đáng kể khả năng tự điều chỉnh tự động và sử dụng hiệu quả các tài liệu được truy xuất. Các thí nghiệm chứng minh rộng rãi khả năng thích ứng của nó với các phương pháp dựa trên RAG cũng như khả năng tổng quát hóa trên các tác vụ sinh tạo dạng ngắn và dài. Trong khi chúng tôi chủ yếu đề xuất cải thiện khung RAG từ góc độ điều chỉnh và CRAG có thể được kết hợp một cách liền mạch với các phương pháp dựa trên RAG khác nhau, việc tinh chỉnh một bộ đánh giá truy xuất bên ngoài là không thể tránh khỏi. Cách loại bỏ bộ đánh giá bên ngoài này và trang bị cho LLM khả năng đánh giá truy xuất tốt hơn sẽ là công việc tương lai của chúng tôi.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được dịch từ tiếng Anh sang tiếng Việt với tất cả các tác giả, tiêu đề, và thông tin xuất bản được giữ nguyên định dạng gốc]

--- TRANG 14 ---
A Lời nhắc Tác vụ
Các lời nhắc để tạo ra từ khóa kiến thức làm truy vấn tìm kiếm web được minh họa trong Bảng 7.

Bảng 7: Lời nhắc few-shot cho GPT-3.5 Turbo để tạo ra từ khóa kiến thức làm truy vấn tìm kiếm web.
Trích xuất tối đa ba từ khóa được phân tách bằng dấu phẩy từ các cuộc đối thoại và câu hỏi sau làm truy vấn cho tìm kiếm web, bao gồm bối cảnh chủ đề trong các cuộc đối thoại và ý định chính trong các câu hỏi.
câu hỏi: Nghề nghiệp của Henry Feilden là gì?
truy vấn: Henry Feilden, nghề nghiệp
câu hỏi: Billy Carlson sinh ra ở thành phố nào?
truy vấn: thành phố, Billy Carlson, sinh ra
câu hỏi: Tôn giáo của John Gwynn là gì?
truy vấn: tôn giáo của John Gwynn
câu hỏi: Đội bóng rổ nam quốc gia Kiribati chơi môn thể thao gì?
truy vấn: thể thao, đội bóng rổ nam quốc gia Kiribati chơi
câu hỏi: [câu hỏi]
truy vấn:

Các lời nhắc để hướng dẫn ChatGPT làm bộ đánh giá được minh họa trong Bảng 8, Bảng 9, và Bảng 10 tương ứng.

[Các bảng 8, 9, 10 và phần Phụ lục B được dịch theo cấu trúc tương tự]

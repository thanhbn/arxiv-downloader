# 2308.07922.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2308.07922.pdf
# Kích thước tệp: 2031672 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024
RAVEN : Học trong Ngữ cảnh với Mô hình Ngôn ngữ Mã hóa-Giải mã được Tăng cường Truy xuất
Jie Huang1,2,∗Wei Ping2Peng Xu2Mohammad Shoeybi2
Kevin Chen-Chuan Chang1Bryan Catanzaro2
1Đại học Illinois tại Urbana-Champaign2NVIDIA
jeffhj@illinois.edu, wping@nvidia.com
Tóm tắt
Trong bài báo này, chúng tôi điều tra khả năng học trong ngữ cảnh của các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất. Đầu tiên, chúng tôi thực hiện phân tích toàn diện các mô hình hiện có và xác định những hạn chế của chúng trong học trong ngữ cảnh, chủ yếu do sự không khớp giữa tiền huấn luyện và suy luận, cũng như độ dài ngữ cảnh bị hạn chế. Để giải quyết những vấn đề này, chúng tôi đề xuất RAVEN, một mô hình kết hợp mô hình ngôn ngữ có mặt nạ được tăng cường truy xuất và mô hình ngôn ngữ tiền tố. Chúng tôi tiếp tục giới thiệu Fusion-in-Context Learning để nâng cao hiệu suất few-shot bằng cách cho phép mô hình tận dụng nhiều ví dụ trong ngữ cảnh hơn mà không cần huấn luyện bổ sung. Thông qua các thí nghiệm mở rộng, chúng tôi chứng minh rằng thiết kế đơn giản nhưng hiệu quả của chúng tôi cải thiện đáng kể hiệu suất, đạt được kết quả tương đương với các mô hình ngôn ngữ tiên tiến nhất trong một số tình huống, mặc dù có ít tham số hơn đáng kể. Công trình của chúng tôi nhấn mạnh tiềm năng của các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất cho học trong ngữ cảnh và khuyến khích nghiên cứu thêm theo hướng này.

1 Giới thiệu
Những tiến bộ gần đây trong xử lý ngôn ngữ tự nhiên chủ yếu được thúc đẩy bởi sự phát triển của các mô hình ngôn ngữ lớn (LLMs) (Brown et al., 2020; OpenAI, 2022; 2023; Chowdhery et al., 2023; Smith et al., 2022). Những mô hình này đã thể hiện hiệu suất đáng chú ý trên nhiều nhiệm vụ khác nhau (Qin et al., 2023; Bubeck et al., 2023; Huang & Chang, 2023). Một trong những tính năng chính cho phép các mô hình này xuất sắc là khả năng thực hiện học trong ngữ cảnh (Dong et al., 2022). Bằng cách điều kiện hóa trên ngữ cảnh được cung cấp, LLMs có thể thích ứng với các nhiệm vụ và miền mới mà không cần tinh chỉnh cụ thể cho nhiệm vụ. Điều này cho phép LLMs hoạt động tốt trên các nhiệm vụ học zero-shot hoặc few-shot, nơi chỉ có một số lượng hạn chế ví dụ có sẵn.

Trong khi học trong ngữ cảnh đã được nghiên cứu rộng rãi cho các mô hình ngôn ngữ chỉ giải mã như GPT-3 (Brown et al., 2020) và PaLM (Chowdhery et al., 2023), nghiên cứu về các mô hình ngôn ngữ mã hóa-giải mã, vốn đã được chứng minh học được các biểu diễn mạnh hơn (Devlin et al., 2019; Raffel et al., 2020), vẫn còn hạn chế. Đáng chú ý, Patel et al. (2023) khai thác tiềm năng của mT5 (Xue et al., 2021), một LM mã hóa-giải mã đa ngôn ngữ, bằng cách lặp đi lặp lại nhắc nhở mô hình tạo ra các thế hệ dài với các ví dụ trong ngữ cảnh. Chung et al. (2022); Longpre et al. (2023) tinh chỉnh T5 (Raffel et al., 2020) với một hỗn hợp lớn các nhiệm vụ sử dụng điều chỉnh hướng dẫn (Mishra et al., 2022; Wei et al., 2022; Sanh et al., 2022) để cải thiện hiệu suất mô hình và khái quát hóa cho các nhiệm vụ chưa được nhìn thấy trong cả hai cài đặt zero-shot và few-shot.

Mặt khác, LLMs vẫn đối mặt với những thách thức như ảo giác và hạn chế trong việc biểu diễn kiến thức đuôi dài và mới nhất (Mallen et al., 2022; Huang et al., 2022; Luu et al., 2022; Jang et al., 2022; Zheng et al., 2023). Các mô hình ngôn ngữ được tăng cường truy xuất (Izacard et al., 2023; Borgeaud et al., 2022; Wang et al., 2023; Shi et al., 2023) đã nổi lên như một phương pháp mạnh mẽ để giải quyết những vấn đề này bằng cách truy xuất kiến thức liên quan từ một kho văn bản bên ngoài. Trong số này, các mô hình mã hóa-giải mã, chẳng hạn như ATLAS (Izacard et al., 2023), nổi bật. Chúng hưởng lợi từ khả năng biểu diễn mạnh mẽ của bộ mã hóa hai chiều, kết hợp với hiệu quả của kiến trúc Fusion-in-Decoder (Izacard & Grave, 2021), cho phép tích hợp hiệu quả nhiều đoạn văn được truy xuất. Mặc dù có những tiến bộ này, học trong ngữ cảnh với những mô hình này vẫn chưa được khám phá.

Về vấn đề này, đầu tiên chúng tôi thực hiện phân tích toàn diện các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất tiên tiến bằng cách thiết kế và thử nghiệm với các chiến lược nhắc nhở khác nhau. Chúng tôi thấy rằng những mô hình này thể hiện một khả năng học trong ngữ cảnh nhất định; tuy nhiên, do sự không khớp giữa tiền huấn luyện và suy luận và độ dài ngữ cảnh hạn chế—những vấn đề phổ biến đối với các LM mã hóa-giải mã hiện có được huấn luyện với mô hình ngôn ngữ có mặt nạ—hiệu suất few-shot của nó không ổn định và việc cung cấp nhiều hơn, ví dụ, 8-shot, ví dụ không dẫn đến cải thiện thêm.

Dựa trên phân tích, chúng tôi phát triển RAVEN1 bằng cách đầu tiên giảm thiểu sự không khớp giữa tiền huấn luyện và suy luận thông qua sự kết hợp của mô hình ngôn ngữ có mặt nạ được tăng cường truy xuất và mô hình ngôn ngữ tiền tố. Hơn nữa, để cho phép mô hình học từ nhiều ví dụ trong ngữ cảnh hơn, chúng tôi đề xuất Fusion-in-Context Learning, một phương pháp mới cho phép mô hình sử dụng nhiều ví dụ trong ngữ cảnh hơn mà không sửa đổi cấu hình mô hình hoặc yêu cầu huấn luyện bổ sung. Hơn nữa, chúng tôi đề xuất sử dụng bộ truy xuất của mô hình để có được các ví dụ trong ngữ cảnh liên quan để tăng cường thêm hiệu suất few-shot. Kết quả thực nghiệm của chúng tôi chứng minh rằng RAVEN vượt trội đáng kể so với các LM mã hóa-giải mã được tăng cường truy xuất trước đây trong cả hai cài đặt zero-shot và few-shot, thậm chí đạt được kết quả tương đương với các LLM chỉ giải mã trong một số cài đặt mặc dù có ít tham số hơn 180 lần.

Những đóng góp chính của bài báo này có hai mặt:
•Từ góc độ phân tích, chúng tôi cung cấp phân tích kỹ lưỡng về khả năng học trong ngữ cảnh của các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất. Chúng tôi chứng minh các khả năng và đưa ra những hiểu biết cho sự phát triển trong tương lai.
•Từ góc độ công nghệ, chúng tôi giới thiệu RAVEN, kết hợp với các chiến lược Fusion-in-Context Learning và In-Context Example Retrieval của chúng tôi, xây dựng trên nền tảng phân tích. Những kỹ thuật này, mặc dù đơn giản, nhưng rất hiệu quả. Chúng không chỉ nâng cao khả năng của mô hình cơ sở mà còn làm nổi bật tiềm năng của học trong ngữ cảnh với các LM mã hóa-giải mã được tăng cường truy xuất.

2 Nền tảng và Công trình Liên quan
Các mô hình ngôn ngữ được tăng cường truy xuất là một lớp mô hình ngôn ngữ được thiết kế để nâng cao hiệu suất bằng cách kết hợp kiến thức bên ngoài. Những mô hình này thường sử dụng cơ chế truy xuất thông tin để truy cập thông tin liên quan từ một kho văn bản lớn, sau đó được tích hợp vào quá trình dự đoán của mô hình. Các LM được tăng cường truy xuất có thể dựa trên cả kiến trúc mã hóa-giải mã (Izacard et al., 2023; Lewis et al., 2020) và chỉ giải mã (Khandelwal et al., 2020; Borgeaud et al., 2022; Shi et al., 2022). Đối với các LM chỉ giải mã, chi phí tính toán thường tăng theo bậc hai với độ dài đầu vào, cũng như với số lượng đoạn văn truy xuất. Ngược lại, đối với các LM mã hóa-giải mã với kiến trúc Fusion-in-Decoder, chi phí tính toán tăng tuyến tính với số lượng đoạn văn được truy xuất, vì chúng chỉ thực hiện self-attention trên một đoạn văn tại một thời điểm (Izacard & Grave, 2021). Khái niệm này cũng được nghiên cứu bởi Ye et al. (2023) để học trong ngữ cảnh hiệu quả hơn.

Trong khi đã có một số nghiên cứu về học trong ngữ cảnh với các LM chỉ giải mã được tăng cường truy xuất, có thể được thực hiện một cách đơn giản bằng cách nối các đoạn văn được truy xuất với truy vấn làm đầu vào của LM (Mallen et al., 2022; Shi et al., 2023; Khattab et al., 2022), học trong ngữ cảnh với các LM mã hóa-giải mã được tăng cường truy xuất vẫn chưa được khám phá theo hiểu biết tốt nhất của chúng tôi. Điều này mặc dù thực tế là các LM mã hóa-giải mã có thể hiệu quả hơn trong việc kết hợp nhiều (ví dụ, 40) đoạn văn được truy xuất.

1RAVEN, một loài chim được biết đến với trí thông minh và khả năng thích ứng, có các chữ cái "RA" trong tên của nó, đại diện cho "Retrieval-Augmented" trong ngữ cảnh của chúng tôi.

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

InputtoEncoder:Question:WhatisthecapitaloftheProvence-Alpes-Coted'AzurregionofFrance?Answer:MarseillesQuestion:TheGreekwordXero(pronouncedzero)inxerographyandrelatedterminologymeanswhat?Answer:DryQuestion:Inwhichcountrywasthefirstpermanentbungeejumpingsitesituated?Answer:<extra_id_0>Passage:…firstpermanentcommercialbungeesite,theKawarauBridgeBungyattheKawarauGorgeSuspensionBridgenearQueenstownintheSouthIslandofNewZealand…InputtoDecoder:NoneOutput:<extra_id_0>NewZealandInputtoEncoder:Question:WhatisthecapitaloftheProvence-Alpes-Coted'AzurregionofFrance?Answer:<extra_id_0>Question:TheGreekwordXero(pronouncedzero)inxerographyandrelatedterminologymeanswhat?Answer:<extra_id_1>Question:Inwhichcountrywasthefirstpermanentbungeejumpingsitesituated?Answer:<extra_id_2>Passage:…firstpermanentcommercialbungeesite,theKawarauBridgeBungyattheKawarauGorgeSuspensionBridgenearQueenstownintheSouthIslandofNewZealand…InputtoDecoder:<extra_id_0>Marseilles<extra_id_1>DryOutput:<extra_id_2>NewZealandPrompting Strategy 1Prompting Strategy 2Masked Language Modeling (Pretraining)InputtoEncoder:Machinelearningalgorithmsbuildamodelbasedonsampledata,<extra_id_0>astrainingdata,inorderto<extra_id_1>beingexplicitlyprogrammedtodoso.Machinelearningalgorithmsareusedinawidevarietyofapplications,suchasinmedicine,emailfiltering,speechrecognition,agriculture,andcomputervision,<extra_id_2>unfeasibletodevelopconventionalalgorithmstoperformthe<extra_id_3>Passage:…machinelearningmodelsrequireahighquantityofreliabledatainorderforthemodels…InputtoDecoder:NoneOutput:<extra_id_0>known<extra_id_1>makepredictionsordecisionswithout<extra_id_2>whereitisdifficultor<extra_id_3>neededtasks.

Hình 1: Mô hình ngôn ngữ có mặt nạ được tăng cường truy xuất và các chiến lược nhắc nhở cho học trong ngữ cảnh.

3 Phương pháp
Trong phần này, đầu tiên chúng tôi khám phá học trong ngữ cảnh với các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất trong tài liệu. Dựa trên phân tích, chúng tôi phát triển các mô hình với hiệu suất zero-shot được nâng cao và khả năng học trong ngữ cảnh được cải thiện.

3.1 Học trong Ngữ cảnh với các LM Mã hóa-Giải mã được Tăng cường Truy xuất
Để điều tra khả năng học trong ngữ cảnh của các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất, đầu tiên chúng tôi nhằm hiểu từ các thiết kế tiên tiến trong tài liệu. Trong số đó, thiết kế của ATLAS (Izacard et al., 2023) nổi bật; nó kết hợp một bộ truy xuất dày đặc đa năng với một trình đọc chuỗi-thành-chuỗi (tức là, T5 (Raffel et al., 2020)) sử dụng kiến trúc Fusion-in-Decoder (Izacard & Grave, 2021). Bộ truy xuất, bộ mã hóa và bộ giải mã được huấn luyện cùng nhau trong quá trình tiền huấn luyện. Trong quá trình này, bộ truy xuất dày đặc, dựa trên mô hình Contriever (Izacard et al., 2022), chịu trách nhiệm chọn các đoạn văn liên quan từ một nguồn kiến thức bên ngoài, ví dụ, Wikipedia, dựa trên ngữ cảnh bị hỏng được cung cấp. Các đoạn văn được truy xuất sau đó được xử lý cùng với ngữ cảnh bởi bộ mã hóa, tạo ra đầu ra tương ứng, tức là, các khoảng bị mặt nạ, tại bộ giải mã (Hình 1, trái). ATLAS thể hiện hiệu suất few-shot đặc biệt trên các nhiệm vụ ngôn ngữ chuyên sâu về kiến thức (Petroni et al., 2021), mặc dù có số lượng tham số thấp hơn so với các LLM gần đây khác.

Tuy nhiên, trong Izacard et al. (2023), hiệu suất few-shot được đạt được bằng cách tinh chỉnh mô hình với các ví dụ few-shot, điều này yêu cầu huấn luyện bổ sung và có thể hạn chế các ứng dụng của nó, chẳng hạn như xử lý các truy vấn người dùng thời gian thực động và đa dạng như GPT-3/4 (Brown et al., 2020; OpenAI, 2023), nơi học trong ngữ cảnh đóng vai trò quan trọng. Do đó, chúng tôi chủ động khám phá khả năng học trong ngữ cảnh của loại mô hình này, sử dụng trả lời câu hỏi miền mở (Chen et al., 2017) như một nhiệm vụ đại diện cho một số thí nghiệm sơ bộ.

Chiến lược Nhắc nhở. Để tạo điều kiện cho học trong ngữ cảnh, một chiến lược nhắc nhở hiệu quả là tối quan trọng. Trái với các LM chỉ giải mã, nơi đầu vào chỉ có thể được đưa vào bộ giải mã, các LM mã hóa-giải mã có thể nhận đầu vào ở bộ mã hóa hoặc bộ giải mã. Phù hợp với mục tiêu tiền huấn luyện, chúng tôi xác định hai chiến lược nhắc nhở cho học trong ngữ cảnh:

Chiến lược 1. Chiến lược đầu tiên liên quan đến việc đưa tất cả các cặp câu hỏi-trả lời ví dụ và câu hỏi mục tiêu vào bộ mã hóa, không có bất kỳ đầu vào nào cho bộ giải mã. Lời nhắc được thiết kế như sau:2

2Ở đây chúng tôi trình bày một định dạng được thiết kế để trình diễn tốt hơn. Lời nhắc thực tế, tuân theo mẫu được sử dụng trong tiền huấn luyện, có thể được tìm thấy trong Phụ lục B.4.

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Enc: Question: q1Answer: a1. . .Question: qkAnswer: akQuestion: q0Answer: <extra id0>d

trong đó (q1,a1),. . .,(qk,ak) đại diện cho các cặp QA ví dụ, q0 biểu thị câu hỏi mục tiêu, <extra id0> là một token sentinel (Raffel et al., 2020), và d là đoạn văn liên quan được truy xuất với q0. Một ví dụ trong cài đặt 2-shot được minh họa trong Hình 1 (giữa).

Chiến lược 2. Vì bộ giải mã của mô hình mã hóa-giải mã cũng có thể chấp nhận đầu vào, chúng ta có thể đưa các câu trả lời của các ví dụ trong ngữ cảnh vào bộ giải mã và chỉ đưa các câu hỏi vào bộ mã hóa, sử dụng nhiều token sentinel:

Enc: Question: q1Answer: <extra id0>. . .Question: qkAnswer: <extra id(k−1)>Question: q0Answer: <extra idk>d
Dec:<extra id0>a1. . .<extra id(k−1)>ak

Hình 1 (phải) minh họa một ví dụ. Mô hình dự kiến sẽ học từ các ví dụ trong ngữ cảnh bằng cách kiểm tra cả đầu vào của bộ mã hóa và đầu vào của bộ giải mã.

Chúng tôi chọn hai bộ dữ liệu được sử dụng rộng rãi trong lĩnh vực trả lời câu hỏi miền mở cho nghiên cứu sơ bộ: Natural Questions (NQ) (Kwiatkowski et al., 2019) và TriviaQA (TQA) (Joshi et al., 2017)3. Bảng 1 tóm tắt kết quả. Chúng tôi thấy rằng mô hình gặp khó khăn trong việc học từ các ví dụ trong ngữ cảnh sử dụng chiến lược 2, vì hiệu suất few-shot tệ hơn so với hiệu suất zero-shot. Chúng tôi giả thuyết rằng điều này là do mô hình gặp khó khăn trong việc học mẫu của S2 với mô hình ngôn ngữ có mặt nạ trong quá trình tiền huấn luyện, vì không có khả năng có được một số cặp câu hỏi-trả lời liên tiếp (hoặc tương tự) theo dạng chiến lược 2 bằng cách ngẫu nhiên che mặt nạ một số khoảng trong một chuỗi.

Mặt khác, chúng tôi quan sát thấy rằng với chiến lược 1, mô hình thể hiện một khả năng học trong ngữ cảnh nhất định, nơi hiệu suất 5-shot và 8-shot tốt hơn đáng kể so với hiệu suất zero-shot trên cả NQ và TriviaQA. Do đó, chúng tôi chọn tập trung vào chiến lược 1 cho nghiên cứu thêm và bỏ qua chiến lược 2 cho phần còn lại của bài báo.

Tác động của Vị trí. Vì bộ mã hóa của các mô hình ngôn ngữ mã hóa-giải mã là hai chiều, nó cũng có thể kiểm tra các ví dụ trong ngữ cảnh theo sau câu hỏi mục tiêu để điền vào token bị mặt nạ. Điều này có nghĩa là chúng ta có thể đặt câu hỏi mục tiêu ở đầu hoặc giữa một chuỗi, ví dụ:

Question: q0Answer: <extra id0>Question: q1Answer: a1. . . Question: qkAnswer: akd
Question: q1Answer: a1. . .Question: q0Answer: <extra id0>. . .Question: qkAnswer: akd

Bảng 2 tóm tắt kết quả. Chúng tôi biểu thị vị trí của câu hỏi mục tiêu là "first" cho đầu chuỗi, "random" cho vị trí ngẫu nhiên, và "last" cho cài đặt ban đầu (S1). Thú vị, việc đặt câu hỏi mục tiêu ở bất kỳ đâu khác ngoài vị trí cuối cùng dẫn đến giảm hiệu suất đáng kể. Khi kiểm tra các câu trả lời được tạo ra, chúng tôi quan sát thấy rằng khi câu hỏi mục tiêu được đặt ở đầu hoặc giữa, mô hình có xu hướng lặp lại câu trả lời hoặc tạo ra văn bản bổ sung. Ví dụ, đối với lời nhắc "Question: What number in Bingo is sometimes referred to as Heinz varieties? Answer: <extra id0> Question: . . . ". Văn bản được tạo ra là "57 'Heinz varieties' is a term used in Bingo to describe". Điều này cho thấy rằng mô hình không hoàn toàn hiểu và tuân theo phong cách của các ví dụ trong ngữ cảnh. Do đó, theo mặc định, chúng tôi đặt câu hỏi mục tiêu sau tất cả các ví dụ trong ngữ cảnh.

Tác động của Số lượng Ví dụ trong Ngữ cảnh. Số lượng ví dụ trong ngữ cảnh là một siêu tham số quan trọng cho học trong ngữ cảnh. Thông thường, chúng ta mong đợi hiệu suất tốt hơn từ một mô hình với nhiều ví dụ trong ngữ cảnh hơn, nhưng có một giới hạn trên do 1) thiết lập độ dài ngữ cảnh tối đa, ví dụ, 512 token, trong quá trình tiền huấn luyện, và 2) điểm mà mô hình đã nhận được đủ ví dụ và không thể thu được thông tin bổ sung từ nhiều ví dụ hơn. Số lượng ví dụ trong ngữ cảnh tối ưu cũng khác nhau giữa các mô hình. Ví dụ, trên TriviaQA, PaLM (Chowdhery et al., 2023) thể hiện hiệu suất 1-shot tốt hơn so với các cài đặt với nhiều ví dụ hơn, trong khi điều này không đúng với GPT-3 (Brown et al., 2020).

Hình 2 minh họa tác động của việc thay đổi số lượng ví dụ trong ngữ cảnh trên các kích thước mô hình khác nhau. Thú vị, mô hình 11B thể hiện hiệu suất kém trong các cài đặt low-shot, ví dụ, 1-shot, nhưng cải thiện đáng kể sau 4-shot và 5-shot. Khi kiểm tra các phản hồi được tạo ra, chúng tôi thấy rằng mô hình có xu hướng tạo ra câu trả lời với nhiều token hơn trong các cài đặt low-shot, trong khi sự thật nền thường bao gồm các câu trả lời ngắn hơn với ít hơn 5 token. Bằng cách nới lỏng tiêu chí cho một dự đoán chính xác để bao gồm các trường hợp mà câu trả lời sự thật nền là một chuỗi con của đầu ra mô hình, chúng tôi thấy rằng hiệu suất 1-shot vượt qua cài đặt 0-shot (38.3 so với 32.1 trên NQ).

Tất cả các mô hình hoạt động tốt trong các cài đặt 5-shot và 8-shot, nhưng hiệu suất của chúng không tiếp tục cải thiện với nhiều ví dụ trong ngữ cảnh hơn (ví dụ, 16-shot). Chúng tôi tin rằng điểm dừng này có thể do hai yếu tố: 1) các ràng buộc độ dài chuỗi trong quá trình tiền huấn luyện, nơi độ dài đầu vào tối đa cho bộ mã hóa được đặt thành 384 token, và độ dài chuỗi đầu vào trung bình (không bao gồm các đoạn văn) là khoảng 130 token; 2) khả năng của mô hình học đầy đủ với 5 hoặc 8 ví dụ, làm cho các ví dụ bổ sung ít có lợi hơn.

Tác động của Số lượng Đoạn văn được Truy xuất. Hình 3 minh họa tác động của số lượng đoạn văn được truy xuất đến hiệu suất mô hình. Chúng tôi quan sát thấy rằng đối với cả hai cài đặt 0-shot và 5-shot, hiệu suất của các mô hình tăng đáng kể với số lượng đoạn văn được truy xuất. Điều này làm nổi bật hiệu quả của kiến trúc Fusion-in-Decoder (Izacard & Grave, 2021) cho các nhiệm vụ chuyên sâu về kiến thức như trả lời câu hỏi miền mở, và nhấn mạnh tầm quan trọng của việc tiền huấn luyện các mô hình ngôn ngữ với tăng cường truy xuất.

Ngoài ra, hiệu suất 5-shot luôn vượt trội so với cài đặt 0-shot. Quan sát này tiếp tục nhấn mạnh giá trị của việc cung cấp các ví dụ trong ngữ cảnh để cải thiện hiệu suất của các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất.

--- TRANG 4 ---
Natural Questions TriviaQA
0-shot 1-shot 5-shot 8-shot 0-shot 1-shot 5-shot 8-shot
ATLAS 11B S126.721.3 29.8 31.356.935.5 62.3 63.9
ATLAS 11B S2 21.4 16.3 9.8 49.8 48.4 44.4

Bảng 1: Kết quả của ATLAS 11B với chiến lược nhắc nhở 1 (S1) và chiến lược 2 (S2).

Natural Questions TriviaQA
first 0.7 9.2
random 6.5 19.5
last 29.8 62.3

Bảng 2: Kết quả của ATLAS 11B (5-shot) với các vị trí câu hỏi mục tiêu khác nhau.

--- TRANG 5 ---
[Các hình ảnh và biểu đồ được mô tả trong văn bản tiếng Anh]

--- TRANG 6 ---
3.2 RAVEN: Kết hợp Mô hình Ngôn ngữ có Mặt nạ và Tiền tố được Tăng cường Truy xuất

Trong §3.1, chúng tôi quan sát thấy rằng các LM mã hóa-giải mã được tăng cường truy xuất thể hiện một khả năng nhất định cho học trong ngữ cảnh, điều này đã bị bỏ qua trong các nghiên cứu trước đây. Tuy nhiên, cũng có một số hạn chế như hiệu suất không ổn định trong các cài đặt low-shot, và việc cung cấp nhiều ví dụ trong ngữ cảnh hơn không cải thiện hiệu suất một cách nhất quán.

Để học một bộ truy xuất tốt hơn và nâng cao khả năng hiểu hai chiều của trình đọc, như đã được chứng minh trong Izacard et al. (2023), một lựa chọn thực tế là tiền huấn luyện mô hình với mục tiêu mô hình ngôn ngữ có mặt nạ, nơi đầu vào là một văn bản bị hỏng với một số khoảng bị mặt nạ được đặt ngẫu nhiên trong chuỗi (tham khảo Hình 1 (trái) để biết ví dụ). Tuy nhiên, trong kiểm tra, dựa trên phân tích của chúng tôi trong §3.1, hiệu quả nhất là đặt câu hỏi mục tiêu sau tất cả các ví dụ trong ngữ cảnh, với một token bị mặt nạ (tức là, <extra id0>) theo sau câu hỏi (Hình 1, giữa)). Do đó, tồn tại sự không khớp giữa tiền huấn luyện và suy luận.

Để giải quyết vấn đề này, chúng tôi đề xuất kết hợp mô hình ngôn ngữ có mặt nạ và tiền tố được tăng cường truy xuất. Cụ thể, trong giai đoạn đầu tiên, theo Izacard et al. (2023), bộ truy xuất và trình đọc được huấn luyện cùng nhau với mô hình ngôn ngữ có mặt nạ được tăng cường truy xuất. Mục tiêu huấn luyện cho bộ truy xuất là tối thiểu hóa KL divergence KL(pREADER ∥pRETRIEVER) giữa phân phối posterior đoạn văn theo trình đọc và phân phối đoạn văn từ bộ truy xuất trên các đoạn văn được truy xuất top-K, tức là, pREADER(d) = exp(logpLM(a|d,q))/∑Ki=1exp(logpLM(a|di,q)), pRETRIEVER(d) = exp(s(d,q)/T)/∑Ki=1exp(s(di,q)/T), trong đó s(·) tính toán tích vô hướng giữa các vector truy vấn q và đoạn văn d, và T là một siêu tham số. Mục tiêu huấn luyện cho trình đọc là tối đa hóa likelihood của các khoảng bị mặt nạ với n đoạn văn được truy xuất: ∑ilogp(ai|q,{dk}1,...,n,a1:i−1).

Trong giai đoạn thứ hai, đối với mỗi chuỗi, chúng tôi che mặt nạ 10% token trung bình ở cuối chuỗi với token <extra id0>. Sau đó, chúng tôi sử dụng bộ truy xuất thu được từ giai đoạn đầu tiên để truy xuất các đoạn văn liên quan sử dụng tiền tố và huấn luyện trình đọc để khôi phục hậu tố của chuỗi này với tiền tố và các đoạn văn làm đầu vào. Một ví dụ về đầu vào và đầu ra cho mô hình ngôn ngữ tiền tố được tăng cường truy xuất được hiển thị trong Hình 4. Chúng ta có thể quan sát thấy rằng mục tiêu tiền huấn luyện phù hợp hơn với chiến lược nhắc nhở 1 trong Hình 1. Chúng tôi gọi mô hình được huấn luyện với mục tiêu kết hợp này là RAVEN.

RAVEN hưởng lợi từ cả mô hình ngôn ngữ có mặt nạ được tăng cường truy xuất, góp phần vào một trình đọc và bộ truy xuất tốt hơn, và mô hình ngôn ngữ tiền tố được tăng cường truy xuất, làm giảm khoảng cách giữa tiền huấn luyện và suy luận. Thiết kế này không tầm thường. Trong Phụ lục C.1, chúng tôi xác minh hiệu quả của nó bằng cách khám phá các chiến lược huấn luyện khác nhau.

3.3 Fusion-in-Context Learning
Trong §3.1, chúng tôi quan sát thấy rằng hiệu suất không cải thiện thêm với nhiều ví dụ trong ngữ cảnh hơn sau 8-shot. Một lý do chính cho điều này là độ dài chuỗi hạn chế trong quá trình tiền huấn luyện, làm cho mô hình khó xử lý các chuỗi dài trong quá trình suy luận. Việc tiền huấn luyện các mô hình với ngữ cảnh dài hơn sẽ là một giải pháp tiềm năng, nhưng sẽ tăng đáng kể chi phí tính toán. Ngoài ra, độ dài đầu vào tối đa cũng bị hạn chế bởi độ dài chuỗi tối đa của bộ truy xuất, tức là, Contriever, dựa trên BERT (Devlin et al., 2019) và có độ dài tối đa 512 token.

Như một lựa chọn thay thế, chúng tôi đề xuất một phương pháp để cho phép các mô hình học từ nhiều ví dụ trong ngữ cảnh hơn mà không cần huấn luyện bổ sung. Như mô tả trong §3.1, trình đọc dựa trên kiến trúc Fusion-in-Decoder (Izacard & Grave, 2021), nơi nhiều đoạn văn được truy xuất, và mỗi đoạn văn, được nối với các ví dụ trong ngữ cảnh và câu hỏi mục tiêu, được đưa vào bộ mã hóa riêng biệt (Hình 5, trên). Để cho phép mô hình xử lý nhiều ví dụ trong ngữ cảnh hơn, chúng ta có thể đưa các ví dụ trong ngữ cảnh khác nhau vào bộ mã hóa với mỗi đoạn văn (Hình 5, dưới). Theo cách này, mô hình có thể kết hợp nhiều ví dụ trong ngữ cảnh hơn trong quá trình suy luận. Chúng tôi gọi chiến lược này là Fusion-in-Context Learning (FiCL).

Trong triển khai, đối với một cài đặt k-shot, chẳng hạn như cài đặt 64-shot, để sử dụng hiệu quả 64 ví dụ, chúng tôi xáo trộn ngẫu nhiên những ví dụ này và chọn m (ví dụ, 5) ví dụ theo thứ tự làm đầu vào cho bộ mã hóa mỗi lần. Nếu tất cả các ví dụ đã được sử dụng, chúng tôi xáo trộn lại 64 ví dụ. Chúng tôi biểu thị cấu hình của FiCL là [k-m], có nghĩa là [k-shot, m-fusion].

3.4 Truy xuất Ví dụ trong Ngữ cảnh
Liu et al. (2022); Rubin et al. (2022); Su et al. (2023) chứng minh rằng việc lựa chọn các ví dụ trong ngữ cảnh được chọn tốt có thể nâng cao học trong ngữ cảnh. Dựa trên hiểu biết này, chúng tôi đề xuất sử dụng bộ truy xuất của RAVEN để truy xuất các ví dụ trong ngữ cảnh. Cụ thể, chúng tôi sử dụng bộ truy xuất của RAVEN để xây dựng một chỉ mục trong bước chuẩn bị, và sau đó, trong quá trình kiểm tra, khi mô hình nhận được một đầu vào, nó có thể truy xuất hiệu quả các ví dụ trong ngữ cảnh với bộ truy xuất của nó.

Bằng cách tích hợp bộ truy xuất của RAVEN theo cách này, chúng tôi nhằm: 1) tự động hóa học trong ngữ cảnh, điều này đặc biệt thực tế cho các chủ sở hữu mô hình có cơ sở dữ liệu ví dụ. Nếu không có điều này, người dùng sẽ cần cung cấp thủ công các ví dụ trong ngữ cảnh; và 2) tối ưu hóa việc lựa chọn các ví dụ trong ngữ cảnh, từ đó cải thiện hiệu suất học trong ngữ cảnh.

4 Thí nghiệm
4.1 Thiết lập Thí nghiệm
Bộ dữ liệu. Theo thiết lập trong §3.1, đầu tiên chúng tôi đánh giá trên hai bộ dữ liệu trả lời câu hỏi miền mở được sử dụng rộng rãi: Natural Questions (Kwiatkowski et al., 2019) và TriviaQA (Joshi et al., 2017). Ngoài ra, chúng tôi thực hiện một nghiên cứu trường hợp về trả lời câu hỏi dạng dài sử dụng bộ dữ liệu ELI5 (Fan et al., 2019). Hơn nữa, chúng tôi đánh giá khả năng hiểu ngôn ngữ của các mô hình sử dụng benchmark Massively Multitask Language Understanding (MMLU) (Hendrycks et al., 2021). Thông tin chi tiết về đánh giá MMLU có trong Phụ lục B.5. Các thiết lập đánh giá khác giống như §B.1.

Đường cơ sở. Vì cả RAVEN và ATLAS (Izacard et al., 2023) đều được huấn luyện bắt đầu từ T5, chúng tôi chọn ATLAS làm đường cơ sở chính để so sánh. Chúng tôi cũng so sánh mô hình của chúng tôi với các LLM chỉ giải mã như GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2023), và LLaMA (Touvron et al., 2023) (trong cài đặt closed-book). Ngoài ra, đối với QA miền mở, chúng tôi đánh giá phương pháp của chúng tôi so với REPLUG (Shi et al., 2023) và RETRO (Borgeaud et al., 2022), cũng như phiên bản cải tiến của nó RETRO++ (Wang et al., 2023). Những mô hình này là các mô hình ngôn ngữ chỉ giải mã được tăng cường với truy xuất. REPLUG dựa trên Codex (Chen et al., 2021) và Contriever (Izacard et al., 2022), nơi các đoạn văn được truy xuất bởi Contriever (sử dụng ensemble và thích ứng bổ sung) và được đưa trực tiếp vào Codex. RETRO là một mô hình GPT (Radford et al., 2019) được tăng cường với một bộ mã hóa transformer để mã hóa các đoạn văn được truy xuất. RETRO++ là một biến thể của RETRO đưa đoạn văn được truy xuất liên quan nhất vào bộ giải mã GPT trong khi cung cấp các đoạn văn khác cho bộ mã hóa của nó. Đối với MMLU, chúng tôi cũng bao gồm FLAN-T5 (Chung et al., 2022), một phiên bản nâng cao của T5 đã được huấn luyện trên một hỗn hợp lớn các nhiệm vụ với instruction finetuning.4

4.2 Trả lời Câu hỏi Miền Mở
Chúng tôi chọn QA miền mở làm nhiệm vụ đánh giá chính, vì nó đại diện hiệu quả cho các thách thức chuyên sâu về kiến thức và được sử dụng rộng rãi trong các ứng dụng thực tế.

RAVEN so với ATLAS. Hình 6 và Bảng 3 trình bày điểm exact match (EM) cho ATLAS và RAVEN trên các bộ dữ liệu NQ và TriviaQA. Cả hai mô hình RAVEN 3B và 11B đều vượt trội đáng kể so với ATLAS. Ví dụ, trên TriviaQA, RAVEN 11B đạt được cải thiện 8.8%, 30.7%, và 2.8% trong các cài đặt 0-shot, 1-shot, và few-shot tương ứng, so với ATLAS 11B. Hơn nữa, hiệu suất của RAVEN tăng đều đặn với số lượng ví dụ trong ngữ cảnh, trong khi hiệu suất của ATLAS giảm đáng kể trong các cài đặt low-shot, chứng minh hiệu quả của RAVEN trên các cài đặt shot khác nhau.

Fusion-in-Context Learning. Chúng tôi cũng báo cáo kết quả của các mô hình với Fusion-in-Context Learning (FiCL) trong Bảng 3. Đối với cả ATLAS và RAVEN, FiCL đóng góp khoảng 1% cải thiện, điều này không thể đạt được bằng học trong ngữ cảnh tiêu chuẩn, nơi hiệu suất không cải thiện thêm (hoặc thậm chí giảm) với nhiều hơn 8 ví dụ trong ngữ cảnh. Điều này chứng minh sự ưu việt của FiCL trong việc cho phép các mô hình học từ nhiều ví dụ hơn.

So sánh với Các Mô hình Khác. Trong Bảng 3, chúng tôi tiếp tục so sánh RAVEN với các đường cơ sở khác. Trên NQ, hiệu suất zero-shot và one-shot của RAVEN vượt qua tất cả các đường cơ sở, bao gồm cả PaLM, mặc dù RAVEN 3B có ít tham số hơn 180 lần so với PaLM 540B. Hiệu suất zero-shot của RAVEN trên TriviaQA cũng ngang bằng với PaLM 62B. Hơn nữa, hiệu suất zero-shot của RAVEN vượt xa cả RETRO và RETRO++, những mô hình ngôn ngữ được tăng cường truy xuất có quy mô tương tự.

Trong cài đặt few-shot, với FiCL, RAVEN đạt hiệu suất tương đương với GPT-3 175B và PaLM 62B. Tuy nhiên, vẫn còn khoảng cách giữa RAVEN và PaLM 540B lớn hơn và các mô hình Codex 175B. Tuy nhiên, xét đến quy mô nhỏ hơn đáng kể của RAVEN so với PaLM và Codex, hiệu suất của nó có thể được coi là ấn tượng. Hiệu suất của RAVEN có thể được cải thiện thêm nếu nó được xây dựng trên một mô hình lớn hơn, trong trường hợp đó hiệu suất few-shot của nó có khả năng vượt qua PaLM và Codex.

Tác động của Số lượng Đoạn văn được Truy xuất. Hình 7 minh họa tác động của số lượng đoạn văn được truy xuất. Khi số lượng đoạn văn được truy xuất tăng, chúng tôi quan sát thấy cải thiện hiệu suất đáng kể của RAVEN 11B trong cả hai cài đặt 0-shot và 5-shot.

Truy xuất Ví dụ trong Ngữ cảnh. §3.4 đề xuất sử dụng bộ truy xuất của RAVEN để truy xuất ví dụ trong ngữ cảnh. Kết quả trong Bảng 4 cho thấy phương pháp này cải thiện kết quả few-shot của RAVEN, đặc biệt trên NQ nơi quan sát được cải thiện ~10%. Điều này cho thấy tác động tích cực của việc kết hợp nhiều ví dụ trong ngữ cảnh liên quan hơn.

Kết quả Bổ sung. Chúng tôi thực hiện nghiên cứu ablation về các chiến lược huấn luyện khác nhau trong Phụ lục C.1 và cung cấp một nghiên cứu trường hợp về trả lời câu hỏi dạng dài trong Phụ lục C.2.

--- TRANG 10 ---
NQ TQA
1-shot 5-shot 1-shot 5-shot
3B +9.1 +11.6 +0.0 +1.6
11B +9.8 +11.1 -0.5 +1.0

Bảng 4: Cải thiện hiệu suất của RAVEN với Truy xuất Ví dụ trong Ngữ cảnh.

4.3 MMLU

Bảng 5 tóm tắt kết quả (độ chính xác) trên Massive Multitask Language Understanding (MMLU). Chúng tôi thấy rằng hiệu suất zero-shot của RAVEN rất ấn tượng, vượt qua hiệu suất few-shot của GPT-3 175B và hơi tệ hơn PaLM 62B, mặc dù có số lượng tham số ít hơn đáng kể. Hơn nữa, với cùng số lượng tham số, hiệu suất của RAVEN vượt xa T5. Ngoài ra, ngay cả khi không có instruction finetuning, RAVEN đạt hiệu suất tương đương với FLAN-T5, một mô hình được tinh chỉnh trên một bộ sưu tập lớn các nhiệm vụ. Chúng tôi mong đợi cải thiện thêm của RAVEN bằng cách áp dụng instruction tuning và để dành cho nghiên cứu tương lai.

Thú vị, với học trong ngữ cảnh tiêu chuẩn, hiệu suất few-shot của RAVEN tệ hơn zero-shot, có thể do các câu hỏi dài hơn và các tùy chọn trả lời trong MMLU gây ra vấn đề độ dài ngữ cảnh trong cài đặt 5-shot. Ngoài ra, trong cài đặt one-shot, vì MMLU là một nhiệm vụ QA trắc nghiệm, việc chỉ cung cấp một ví dụ có thể gây ra bias trong dự đoán của mô hình, ưu tiên một tùy chọn cụ thể. Tuy nhiên, với Fusion-in-Context Learning, hiệu suất cải thiện đáng kể, dẫn đến hiệu suất few-shot tốt hơn cho mô hình 11B so với hiệu suất zero-shot, tiếp tục chứng minh hiệu quả của FiCL.

5 Kết luận
Trong nghiên cứu này, chúng tôi đã đi sâu vào khả năng học trong ngữ cảnh của các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất. Chúng tôi bắt đầu với phân tích toàn diện các mô hình trong tài liệu và sau đó phát triển mô hình của chúng tôi dựa trên phân tích. Kết quả thí nghiệm mở rộng của chúng tôi chứng minh rằng mô hình của chúng tôi vượt trội đáng kể so với các mô hình trước đây và đạt được kết quả ngang bằng với một số mô hình ngôn ngữ tiên tiến nhất, ngay cả với số lượng tham số ít hơn đáng kể. Những phát hiện này làm nổi bật tiềm năng của các mô hình ngôn ngữ mã hóa-giải mã được tăng cường truy xuất trong lĩnh vực học trong ngữ cảnh.

[Phần References và các phần còn lại của tài liệu tiếp tục với cùng định dạng dịch]

# RETA-LLM: Bộ công cụ Mô hình Ngôn ngữ Lớn Tăng cường Truy xuất
Jiongnan Liu1, Jiajie Jin2, Zihan Wang1, Jiehan Cheng1, Zhicheng Dou1∗, và Ji-Rong Wen1
1Trường Trí tuệ Nhân tạo Gaoling, Đại học Nhân dân Trung Quốc
2Đại học Khoa học và Công nghệ Trung Quốc
1{liujn, wangzihan0527, jiehan_cheng, dou, jrwen}@ruc.edu.cn
2jinjiajie@mail.ustc.edu.cn

Tóm tắt
Mặc dù các Mô hình Ngôn ngữ Lớn (LLM) đã chứng minh khả năng phi thường trong nhiều lĩnh vực, chúng vẫn có xu hướng gây ảo giác và tạo ra các phản hồi hư cấu cho yêu cầu của người dùng. Vấn đề này có thể được giảm bớt bằng cách tăng cường LLM với các hệ thống truy xuất thông tin (IR) (còn được gọi là LLM tăng cường truy xuất). Áp dụng chiến lược này, LLM có thể tạo ra các văn bản thực tế hơn để phản hồi đầu vào của người dùng theo nội dung liên quan được truy xuất bởi hệ thống IR từ các kho dữ liệu bên ngoài làm tài liệu tham khảo. Ngoài ra, bằng cách kết hợp kiến thức bên ngoài, LLM tăng cường truy xuất có thể trả lời các câu hỏi trong miền mà không thể được trả lời chỉ bằng cách dựa vào kiến thức thế giới được lưu trữ trong các tham số. Để hỗ trợ nghiên cứu trong lĩnh vực này và tạo điều kiện phát triển các hệ thống LLM tăng cường truy xuất, chúng tôi phát triển RETA-LLM, một bộ công cụ LLM Tăng cường TRuy xuất. Trong RETA-LLM, chúng tôi tạo ra một pipeline hoàn chỉnh để giúp các nhà nghiên cứu và người dùng xây dựng các hệ thống dựa trên LLM trong miền tùy chỉnh của họ. So với các hệ thống LLM tăng cường truy xuất trước đây, RETA-LLM cung cấp nhiều module cắm và chạy hơn để hỗ trợ tương tác tốt hơn giữa hệ thống IR và LLM, bao gồm các module viết lại yêu cầu, truy xuất tài liệu, trích xuất đoạn văn, tạo câu trả lời và kiểm tra sự thật. Bộ công cụ của chúng tôi được công khai tại https://github.com/RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) đã thu hút sự chú ý ngày càng tăng từ cả cộng đồng nghiên cứu và ngành công nghiệp (Brown et al., 2020; OpenAI, 2023; Ouyang et al., 2022; Touvron et al., 2023; Chowdhery et al., 2022; Zhao et al., 2023; Zeng et al., 2022). Với lượng kiến thức thế giới khổng lồ được lưu trữ trong các tham số (Petroni et al., 2019; Roberts et al., 2020; Jiang et al., 2020) và các kỹ thuật Học Tăng cường từ Phản hồi Con người (RLHF) (Christiano et al., 2017; Ziegler et al., 2019), LLM có thể tạo ra các văn bản hữu ích, chi tiết và lịch sự để phản hồi đầu vào của người dùng. Nhiều nghiên cứu đã chứng minh khả năng phi thường của LLM trong các lĩnh vực khác nhau, bao gồm xử lý ngôn ngữ tự nhiên (Moslem et al., 2023), truy xuất thông tin (Sun et al., 2023; Wang et al., 2023; Mao et al., 2023), và đề xuất (Hou et al., 2023; Zhang et al., 2023).

Tuy nhiên, LLM vẫn có xu hướng gây ảo giác và đôi khi tạo ra các văn bản trái ngược với sự thật (Zhou et al., 2021; Zhao et al., 2023). Để giải quyết những vấn đề này, các nhà nghiên cứu đã đề xuất một paradigm mới để tăng cường LLM với các hệ thống truy xuất thông tin (LLM tăng cường truy xuất) (Shi et al., 2023; Jiang et al., 2023; Nakano et al., 2022), cho phép LLM truy xuất nội dung liên quan từ một kho lưu trữ bên ngoài (kho kiến thức) để tạo ra văn bản dựa trên chúng. Đã được xác minh rằng LLM tăng cường truy xuất có thể tạo ra văn bản để phản hồi đầu vào của người dùng với ít ảo giác hơn (Nakano et al., 2022). Hơn nữa, bằng cách kết hợp các nguồn dữ liệu riêng tư tùy chỉnh, LLM tăng cường truy xuất có thể phản hồi các truy vấn trong miền mà không thể được trả lời bởi LLM được huấn luyện với dữ liệu công khai.

Để hỗ trợ nghiên cứu trong lĩnh vực này và giúp người dùng xây dựng các hệ thống dựa trên LLM trong miền của riêng họ, chúng tôi thiết kế RETA-LLM, một bộ công cụ LLM Tăng cường TRuy xuất. Khác với các bộ công cụ tăng cường LLM tổng quát trước đây như LangChain,1 RETA-LLM tập trung vào LLM tăng cường truy xuất và cung cấp nhiều module plugin hơn. Thông thường, LLM tăng cường truy xuất sử dụng chiến lược truy xuất và tạo ra với hai module: Đầu tiên, chúng truy xuất tài liệu hoặc đoạn văn dựa trên yêu cầu của người dùng (module truy xuất tài liệu); sau đó, chúng tạo ra câu trả lời sử dụng những tài liệu liên quan này làm tài liệu tham khảo (module tạo câu trả lời). Ngoài hai module cơ bản này, RETA-LLM của chúng tôi cung cấp ba module tùy chọn: (1) một module viết lại yêu cầu để làm cho yêu cầu hiện tại của người dùng hoàn chỉnh và rõ ràng hơn; (2) một module trích xuất đoạn văn để trích xuất các đoạn văn hoặc đoạn liên quan từ toàn bộ nội dung tài liệu được truy xuất; và (3) một module kiểm tra sự thật để xác minh liệu có tồn tại lỗi thực tế trong các câu trả lời được tạo ra hay không. Những module tùy chọn này có thể làm cho tương tác giữa hệ thống IR và LLM hiệu quả và mượt mà hơn.

Sự tách biệt giữa LLM và hệ thống IR trong RETA-LLM của chúng tôi là kỹ lưỡng hơn, điều này làm cho việc tùy chỉnh các công cụ tìm kiếm và LLM thuận tiện hơn. Hơn nữa, để làm cho việc sử dụng dễ dàng hơn, chúng tôi cung cấp một pipeline hoàn chỉnh và sẵn sàng sử dụng cho các nhà nghiên cứu và người dùng để xây dựng bộ công cụ RETA-LLM của họ dựa trên kho lưu trữ riêng của họ cho các hệ thống dựa trên LLM trong miền từ đầu.

RETA-LLM là một phần của YuLan, một sáng kiến LLM mã nguồn mở được đề xuất bởi Trường Trí tuệ Nhân tạo Gaoling, Đại học Nhân dân Trung Quốc. RETA-LLM vẫn đang được phát triển và có nhiều vấn đề cần được giải quyết với những nỗ lực lớn. Chúng tôi chân thành chào đón các đóng góp cho bộ công cụ mã nguồn mở này.

2 Khung RETA-LLM
Như đã đề cập ở trên, so với Langchain, một bộ công cụ tăng cường LLM phổ biến, bộ công cụ RETA-LLM của chúng tôi tập trung cụ thể vào LLM tăng cường truy xuất. Chúng tôi cung cấp năm module plugin trong RETA-LLM để tương tác với LLM và hệ thống IR. Các module bao gồm viết lại yêu cầu, truy xuất tài liệu, trích xuất đoạn văn, tạo câu trả lời, và các module kiểm tra sự thật. Khung của RETA-LLM được thể hiện trong Hình 1.

Quy trình làm việc của RETA-LLM như sau:
Đầu tiên, RETA-LLM sử dụng module viết lại yêu cầu để chỉnh sửa yêu cầu hiện tại của người dùng để làm cho nó hoàn chỉnh và rõ ràng. Bởi vì người dùng có thể đưa ra một loạt câu hỏi cho RETA-LLM, ý nghĩa của yêu cầu hiện tại của người dùng có thể không hoàn chỉnh. Ví dụ, một người dùng có thể hỏi "Trường Kinh tế thì sao?" trong khi yêu cầu lịch sử là "Giới thiệu các chuyên ngành trong Trường Thông tin". Trong trường hợp này, ý nghĩa chính xác của người dùng là "Giới thiệu các chuyên ngành trong Trường Kinh tế". Vì LLM đã thể hiện khả năng đáng chú ý trong việc viết lại truy vấn trong truy xuất đậm đặc hội thoại (Mao et al., 2023), chúng tôi đưa yêu cầu hiện tại của người dùng và lịch sử hội thoại trước đó vào LLM để thực hiện viết lại.

Sau đó, RETA-LLM sử dụng module truy xuất tài liệu để truy xuất các tài liệu liên quan từ kho dữ liệu bên ngoài dựa trên yêu cầu đã chỉnh sửa của người dùng. Module truy xuất tài liệu là module được kết nối với hệ thống IR. Nó truy xuất các tài liệu liên quan từ kho kiến thức bên ngoài và trả về top-K trong số chúng. K được đặt thành 3 trong cấu hình mặc định của chúng tôi. Chúng tôi cung cấp một trình truy xuất đậm đặc mặc định trong kho của chúng tôi. Mô tả chi tiết có thể được tìm thấy trong phần tiếp theo.

Tiếp theo, RETA-LLM sử dụng module trích xuất đoạn văn để trích xuất các đoạn liên quan đến yêu cầu của người dùng từ các tài liệu được truy xuất để tạo thành các tài liệu tham khảo. Do giới hạn độ dài đầu vào (thường là 2048 hoặc 4096 token) của LLM, không thể nối trực tiếp nội dung của tất cả top-K tài liệu liên quan làm tài liệu tham khảo để chúng tạo ra câu trả lời. Các phương pháp tầm thường bằng cách cắt bớt nội dung tài liệu có thể mất thông tin quan trọng trong chúng. Do đó, chúng tôi tái sử dụng chính LLM để trích xuất các đoạn liên quan từ các tài liệu được truy xuất dựa trên yêu cầu đã chỉnh sửa. Vì độ dài của một tài liệu cũng có thể vượt quá giới hạn, chúng tôi áp dụng chiến lược cửa sổ trượt để trích xuất các đoạn từng bước. Kích thước cửa sổ trượt và bước được đặt thành 512 và 256 trong cấu hình mặc định của chúng tôi. Những đoạn này sau đó được nối lại với nhau làm tài liệu tham khảo.

Bên cạnh đó, RETA-LLM sử dụng module tạo câu trả lời để tạo ra câu trả lời cho yêu cầu của người dùng. Như các nghiên cứu trước đây (Nakano et al., 2022; Shi et al., 2023; Jiang et al., 2023) gợi ý, bằng cách đưa các tài liệu tham khảo được truy xuất từ kho dữ liệu bên ngoài, LLM có thể tạo ra các câu trả lời thực tế hơn.

Cuối cùng, RETA-LLM sử dụng module kiểm tra sự thật để xác minh liệu các câu trả lời được tạo ra có chứa những sai lầm thực tế hay không và đưa ra phản hồi cuối cùng cho yêu cầu của người dùng. Mặc dù cung cấp bằng chứng bổ sung để tạo ra, LLM cũng có thể gây ảo giác (Nakano et al., 2022). Cần thiết phải thiết kế một module để tiến hành xác minh sự thật thêm. Do khả năng hiểu ngôn ngữ tự nhiên mạnh mẽ của LLM, chúng tôi đưa các tài liệu tham khảo và câu trả lời được tạo ra vào chúng để đưa ra phán đoán. Do đó, RETA-LLM có thể quyết định có nên đưa ra các câu trả lời được tạo ra hay chỉ nói "Tôi không thể trả lời câu hỏi này".

Lưu ý rằng tất cả các đầu vào cho LLM đều được bao bọc trong các hướng dẫn hoặc gợi ý. Như thể hiện trong Hình 1, chúng tôi tách biệt hoàn toàn hệ thống IR và LLM trong RETA-LLM của chúng tôi. Thiết kế tách biệt này trong RETA-LLM của chúng tôi dẫn đến việc người dùng có thể tùy chỉnh các công cụ tìm kiếm và LLM cá nhân của họ.

3 Pipeline Sử dụng RETA-LLM
Để làm cho bộ công cụ thuận tiện hơn cho việc sử dụng cá nhân, chúng tôi cung cấp một pipeline hoàn chỉnh để xây dựng hệ thống dựa trên LLM trong miền dựa trên các nguồn html. Pipeline như sau:

Đầu tiên, RETA-LLM sử dụng gói Beautiful Soup để chuyển đổi các tệp html thô thành dữ liệu json trong Bộ chuyển đổi HTML của chúng tôi.2

Thứ hai, RETA-LLM tuân theo việc triển khai của disentangled-retriever (Zhan et al., 2022) để xây dựng các chỉ mục đậm đặc và thực hiện thích ứng miền từ dữ liệu json đã chuyển đổi trong Bộ xây dựng Chỉ mục của chúng tôi.3 Cụ thể, phương pháp của chúng tôi hỗ trợ huấn luyện không giám sát các mô hình truy xuất đậm đặc trên các bộ sưu tập tài liệu cục bộ, cho phép mô hình học kiến thức cụ thể miền trước. So với module truy xuất trong thư viện LangChain phổ biến, phương pháp truy xuất của chúng tôi có hai ưu điểm: (1) mô hình học kiến thức trong miền của các tài liệu cục bộ, cho phép nó khớp các truy vấn chính xác hơn, và (2) phương pháp của chúng tôi không phân đoạn văn bản, do đó tránh bất kỳ tác động tiêu cực nào đến thông tin ngữ nghĩa tổng thể của văn bản. Chúng tôi cũng cung cấp một trình truy xuất thưa thớt áp dụng gói faiss (Johnson et al., 2019) để xây dựng các chỉ mục thưa thớt.4 Nếu không, người dùng cũng có thể sử dụng các công cụ tìm kiếm tùy chỉnh của họ như module truy xuất tài liệu.

Thứ ba, người dùng cần chuẩn bị LLM để trả lời câu hỏi. Để tải và phản hồi LLM, chúng tôi cung cấp mẫu cho Alpaca (Taori et al., 2023),5, YuLan-Chat,6 ChatGLM (Zeng et al., 2022; Du et al., 2022),7 và GPT-3.5 API (Ouyang et al., 2022).8 Nếu người dùng sử dụng LLM khác, họ có thể chỉnh sửa mã và cấu hình trong bộ công cụ của chúng tôi.

Cuối cùng, người dùng có thể bắt đầu dịch vụ RETA-LLM của riêng họ bằng gói streamlit.9

Thông tin chi tiết hơn về pipeline sử dụng có thể được tìm thấy trên kho GitHub của chúng tôi.

4 Một Trường hợp Dịch vụ RETA-LLM
Dựa trên RETA-LLM và pipeline sử dụng, chúng tôi sử dụng các trang web trên nền tảng trực tuyến tuyển sinh của Đại học Nhân dân Trung Quốc,10 để xây dựng một hệ thống RUC-enrollment-assistant. Hệ thống sử dụng một module truy xuất tài liệu đậm đặc và áp dụng YuLan-13B làm LLM xương sống. Một trường hợp sử dụng được thể hiện trong 2. Bằng cách tăng cường hệ thống IR, LLM có thể trả lời các câu hỏi trong miền mà không thể được trả lời bằng kiến thức riêng của chúng.

5 Kết luận và Công việc Tương lai
Trong bài báo này, chúng tôi đề xuất RETA-LLM để tạo điều kiện nghiên cứu và phát triển LLM tăng cường truy xuất. Chúng tôi cung cấp năm module độc lập: viết lại yêu cầu, truy xuất tài liệu, trích xuất đoạn văn, tạo câu trả lời, và các module kiểm tra sự thật trong bộ công cụ của chúng tôi. Hơn nữa, chúng tôi cung cấp một pipeline để giúp người dùng xây dựng các hệ thống dựa trên LLM trong miền của họ. Trong tương lai, chúng tôi sẽ bao gồm nhiều chiến lược LLM tăng cường truy xuất hơn như tạo tăng cường truy xuất chủ động (Jiang et al., 2023). Bên cạnh đó, chúng tôi có kế hoạch làm cho RETA-LLM có tính module và có thể cấu hình hơn.

Tài liệu tham khảo
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language models are few-shot learners. Trong Advances in Neural Information Processing Systems, tập 33, trang 1877–1901. Curran Associates, Inc.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, và Noah Fiedel. 2022. Palm: Scaling language modeling with pathways. CoRR, abs/2204.02311.

Paul F. Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, và Dario Amodei. 2017. Deep reinforcement learning from human preferences. Trong NIPS, trang 4299–4307.

Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, và Jie Tang. 2022. Glm: General language model pretraining with autoregressive blank infilling. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 320–335.

Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, và Wayne Xin Zhao. 2023. Large language models are zero-shot rankers for recommender systems.

Zhengbao Jiang, Frank F. Xu, Jun Araki, và Graham Neubig. 2020. How Can We Know What Language Models Know? Transactions of the Association for Computational Linguistics, 8:423–438.

Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, và Graham Neubig. 2023. Active retrieval augmented generation.

Jeff Johnson, Matthijs Douze, và Hervé Jégou. 2019. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data, 7(3):535–547.

Kelong Mao, Zhicheng Dou, Haonan Chen, Fengran Mo, và Hongjin Qian. 2023. Large language models know your contextual search intent: A prompting framework for conversational search.

Yasmin Moslem, Rejwanul Haque, John D. Kelleher, và Andy Way. 2023. Adaptive machine translation with large language models.

Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, và John Schulman. 2022. Webgpt: Browser-assisted question-answering with human feedback.

OpenAI. 2023. Gpt-4 technical report.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, và Ryan Lowe. 2022. Training language models to follow instructions with human feedback. Trong NeurIPS.

Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, và Alexander Miller. 2019. Language models as knowledge bases? Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 2463–2473, Hong Kong, China. Association for Computational Linguistics.

Adam Roberts, Colin Raffel, và Noam Shazeer. 2020. How much knowledge can you pack into the parameters of a language model? Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 5418–5426, Online. Association for Computational Linguistics.

Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, và Wen-tau Yih. 2023. REPLUG: retrieval-augmented black-box language models. CoRR, abs/2301.12652.

Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, và Zhaochun Ren. 2023. Is chatgpt good at search? investigating large language models as re-ranking agent.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023. Llama: Open and efficient foundation language models. CoRR, abs/2302.13971.

Liang Wang, Nan Yang, và Furu Wei. 2023. Query2doc: Query expansion with large language models. CoRR, abs/2303.07678.

Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414.

Jingtao Zhan, Qingyao Ai, Yiqun Liu, Jiaxin Mao, Xiaohui Xie, Min Zhang, và Shaoping Ma. 2022. Disentangled modeling of domain and relevance for adaptable dense retrieval. arXiv preprint arXiv:2208.05753.

Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, và Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. CoRR, abs/2305.07001.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, và Ji-Rong Wen. 2023. A survey of large language models.

Chunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Francisco Guzmán, Luke Zettlemoyer, và Marjan Ghazvininejad. 2021. Detecting hallucinated content in conditional neural sequence generation. Trong Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, trang 1393–1404, Online. Association for Computational Linguistics.

Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul F. Christiano, và Geoffrey Irving. 2019. Fine-tuning language models from human preferences. CoRR, abs/1909.08593.

# 2204.04581.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2204.04581.pdf
# Kích thước tệp: 2324706 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Tăng Cường Mô Hình Ngôn Ngữ Đã Được Tiền Huấn Luyện với
QA-Memory cho Trả Lời Câu Hỏi Miền Mở
Wenhu Chen, Pat Verga, Michiel de Jongy, John Wieting, William W. Cohen
Google Research, Đại học Nam California
{wenhuchen,patverga,jwieting,wcohen}@google.com, msdejong@usc.edu
Tóm tắt
Các phương pháp hiện đại tốt nhất cho trả lời câu hỏi miền mở (ODQA) sử dụng phương pháp sách mở trong đó thông tin đầu tiên được truy xuất từ một kho văn bản lớn hoặc cơ sở tri thức (KB) và sau đó được lập luận để tạo ra câu trả lời. Một giải pháp thay thế gần đây là truy xuất từ một bộ sưu tập các cặp câu hỏi-câu trả lời đã được tạo trước đó; điều này có một số ưu điểm thực tế bao gồm việc tiết kiệm bộ nhớ và tính toán hiệu quả hơn. Các cặp câu hỏi-câu trả lời cũng hấp dẫn ở chỗ chúng có thể được xem như một trung gian giữa văn bản và bộ ba KB: giống như bộ ba KB, chúng thường biểu đạt ngắn gọn một mối quan hệ duy nhất, nhưng giống như văn bản, có độ bao phủ cao hơn nhiều so với các KB truyền thống. Trong công trình này, chúng tôi mô tả một hệ thống QA mới tăng cường mô hình văn bản-sang-văn bản với một bộ nhớ lớn của các cặp câu hỏi-câu trả lời, và một nhiệm vụ tiền huấn luyện mới cho bước ẩn của truy xuất câu hỏi. Nhiệm vụ tiền huấn luyện đơn giản hóa đáng kể việc huấn luyện và cải thiện đáng kể hiệu suất trên các benchmark QA nhỏ hơn. Không giống như các hệ thống trước đây thuộc loại này, hệ thống QA của chúng tôi cũng có thể trả lời các câu hỏi đa bước không xuất hiện rõ ràng trong bộ sưu tập các cặp câu hỏi-câu trả lời được lưu trữ.

1 Giới thiệu
Trả lời câu hỏi miền mở (ODQA) là một nhiệm vụ chuyên sâu về tri thức được nghiên cứu kỹ lưỡng. Các phương pháp hiện đại đòi hỏi việc truy xuất tri thức liên quan từ một kho dữ liệu lớn hoặc cơ sở dữ liệu trước khi lập luận trên bằng chứng được truy xuất này. Hầu hết các phương pháp hiện tại truy xuất tài liệu (Chen et al., 2017a; Lee et al., 2019; Karpukhin et al., 2020) hoặc bộ ba KB có cấu trúc (Verga et al., 2021). Gần đây, một số nghiên cứu đã đề xuất truy xuất từ một bộ sưu tập các cặp câu hỏi-câu trả lời (QA)—một phương pháp được thực hiện nhờ những tiến bộ trong việc tự động tạo câu hỏi có thể mở rộng. Trong bối cảnh này, một câu hỏi mới được trả lời bằng cách truy xuất các phép diễn giải từ một chỉ mục câu hỏi, và trả về câu trả lời liên quan (Xiao et al., 2021; Lewis et al., 2021). Đáng chú ý, hệ thống RePAQ từ (Lewis et al., 2021) đã thắng cuộc thi EfficientQA 2020 (Min et al., 2021), vượt trội hơn các mô hình QA sách đóng (CBQA) với biên độ đáng kể và khớp với hiệu suất SoTA trước đó trên NQ (Kwiatkowski et al., 2019).

Một bộ sưu tập các cặp QA hấp dẫn vì một số lý do. Trái ngược với các đoạn văn bản và giống như một bộ ba KB, các cặp QA thường ngắn gọn, có xu hướng biểu đạt một mối quan hệ duy nhất. Tuy nhiên, không giống như bộ ba KB, các bộ sưu tập QA có độ bao phủ tốt của các câu hỏi thực sự được hỏi như những câu trong các bộ dữ liệu QA mở tiêu chuẩn. RePAQ đã chứng minh một số tính chất ưu việt như hiệu quả bộ nhớ và tính toán, hiệu suất QA chọn lọc mạnh (tức là chọn lọc từ chối trả lời), và kết hợp hiệu quả với các hệ thống QA truy xuất văn bản.

Tuy nhiên, các hệ thống QA truy xuất câu hỏi cũng có một số hạn chế. Đầu tiên, không có dữ liệu có giám sát quy mô lớn cho truy xuất câu hỏi-câu hỏi. Điều này trái ngược với bước truy xuất văn bản cho một câu hỏi, nơi dữ liệu có giám sát được sử dụng để xây dựng các bộ truy xuất như DPR (Karpukhin et al., 2020). Để giải quyết điều này, RePAQ sử dụng một quá trình huấn luyện truy xuất ẩn (tương tự như REALM (Lee et al., 2019)), trong đó bộ truy xuất được huấn luyện bằng cách sử dụng mất mát cuối từ nhiệm vụ QA. Điều này đòi hỏi việc cập nhật chỉ mục một cách bất đồng bộ khi quá trình huấn luyện diễn ra, một quá trình phức tạp và tốn kém về tính toán. Đây cũng là một vấn đề cho các miền có dữ liệu QA hạn chế: như chúng tôi sẽ chỉ ra, hiệu suất của RePAQ đáng thất vọng trên các bộ dữ liệu nhỏ hơn như WebQuestions (Berant et al., 2013), chỉ chứa 3K mẫu huấn luyện. Để giải quyết vấn đề này, chúng tôi giới thiệu một nhiệm vụ tiền huấn luyện mới cho truy xuất câu hỏi, có thể được áp dụng cho bất kỳ bộ dữ liệu văn bản-QA nào, điều này cải thiện đáng kể hiệu suất trên các bộ dữ liệu nhỏ hơn.

Một vấn đề thứ hai là RePAQ bị hạn chế trong việc trả lời các câu hỏi được lưu trữ rõ ràng trong chỉ mục, hoặc các phép diễn giải của những câu hỏi như vậy. Điều này trái ngược arXiv:2204.04581v3 [cs.CL] 23 Jan 2023

--- TRANG 2 ---
Hình 1: Trong quá trình tiền huấn luyện, bộ mã hóa đầu tiên mã hóa đầu vào văn bản và sử dụng biểu diễn token đặc biệt để truy vấn QA-memory. Các cặp QA được truy xuất được tích hợp vào bộ giải mã để tạo ra đầu ra.

với các hệ thống QA truy xuất từ KB, thường có thể tạo ra các truy vấn phức tạp kết hợp các bộ ba nguyên tử trong KB. Để giải quyết điều này, chúng tôi trình bày một mô hình mở rộng trả lời các câu hỏi đa bước bằng cách lặp lại truy xuất từ một kho câu hỏi-câu trả lời, hệ thống QA dựa trên truy xuất câu hỏi đầu tiên giải quyết nhiệm vụ này.

Cụ thể hơn, chúng tôi đề xuất một QA-Memory-Augmented Transformer (QAMAT) mới với khả năng tổ hợp tốt hơn kết hợp với chiến lược huấn luyện có độ phức tạp thấp hơn. QAMAT dựa trên bộ mã hóa-giải mã T5 (Raffel et al., 2020) kết hợp với bộ nhớ khóa-giá trị tích hợp (Khandelwal et al., 2019; Borgeaud et al., 2021) được điền với các cặp câu hỏi-câu trả lời (Xem Hình 1). Cho một đầu vào, bộ mã hóa tạo ra một biểu diễn truy vấn được chấm điểm với bộ nhớ QA và truy xuất top-K cặp QA liên quan. Sau đó bộ mã hóa xử lý lại đầu vào cùng với các truy xuất tạo thành một biểu diễn được tiêm QA được chuyển đến bộ giải mã để chú ý và tạo ra.

Để giảm độ phức tạp mẫu huấn luyện (tinh chỉnh), chúng tôi đề xuất tiền huấn luyện QAMAT trước trên một kho dữ liệu quy mô lớn để dạy mô hình truy xuất và diễn giải các cặp QA. Chúng tôi xây dựng kho dữ liệu tiền huấn luyện bằng cách tận dụng các phương pháp hiện có để tạo câu hỏi, tạo ra một tập hợp rất lớn các câu hỏi có thể thú vị từ các đoạn văn bản (Zhou et al., 2017; Alberti et al., 2019; Lewis et al., 2021). Cho mỗi cặp QA và đoạn văn nó được tạo ra từ đó, chúng tôi che câu trả lời và huấn luyện mô hình điền vào chỗ trống bằng cách truy xuất và sử dụng một cặp QA phù hợp. Chúng tôi chỉ ra rằng tiền huấn luyện tăng đáng kể hiệu suất của mô hình và giúp mô hình tổng quát hóa sang các miền khác nhau. Ví dụ, mô hình được tiền huấn luyện có thể đạt hiệu suất zero-shot 40% EM trên NQ và TriviaQA mà không cần bất kỳ tinh chỉnh nào.

Hiệu quả của nhiệm vụ tiền huấn luyện này có nghĩa là chúng tôi có thể tránh quy trình huấn luyện ẩn đắt đỏ được sử dụng bởi RePAQ, và thay vào đó sử dụng một pipeline huấn luyện hai giai đoạn hiệu quả. Trong giai đoạn đầu, chúng tôi sử dụng một bộ nhớ địa phương nhỏ trong batch của các cặp QA để tối ưu hóa bộ mã hóa cặp QA. Sau đó chúng tôi đóng băng bộ mã hóa và xây dựng chỉ mục cho bộ nhớ toàn cục. Trong giai đoạn thứ hai, chúng tôi truy xuất từ bộ nhớ toàn cục cố định này và tiếp tục tối ưu hóa các tham số còn lại—bao gồm các tham số được sử dụng để xây dựng truy vấn đến bộ nhớ toàn cục—để có hiệu suất tốt hơn.

Cuối cùng, chúng tôi mở rộng QAMAT để xây dựng QAMAT+, lặp lại truy xuất từ bộ nhớ để tạo ra đầu ra. Chúng tôi chứng minh rằng QAMAT+ hiệu quả xâu chuỗi nhiều cặp QA lại với nhau để trả lời các câu hỏi đa bước trong HotpotQA (Yang et al., 2018) và Musique (Trivedi et al., 2021). Khả năng lập luận tổ hợp như vậy không tồn tại trong RePAQ (Lewis et al., 2021).

Tóm lại, chúng tôi phát triển một kiến trúc tăng cường QA mới mở rộng các dòng nghiên cứu xem xét các cặp QA như một biểu diễn tri thức cũng như những nghiên cứu về các mô hình ngôn ngữ tăng cường bộ nhớ. Khi kết hợp với chiến lược tiền huấn luyện được đề xuất của chúng tôi (phần 4), chúng tôi giải quyết nhiều hạn chế của các phương pháp dựa trên chỉ mục QA trước đây dẫn đến việc huấn luyện với độ phức tạp mẫu thấp hơn và khả năng thực hiện lập luận tổ hợp (tiểu mục 3.5).

2 Nghiên Cứu Liên Quan
2.1 Mô Hình Truy Xuất-Đọc
Các mô hình truy xuất-và-đọc đã được nghiên cứu rộng rãi để giải quyết các nhiệm vụ chuyên sâu về tri thức và đạt hiệu suất hiện đại trên hầu hết các nhiệm vụ QA. Các phương pháp này sử dụng hai mô hình, một để truy xuất từ một chỉ mục đoạn văn dựa trên BM25 (Robertson và Zaragoza, 2009), và một để thực hiện đọc hiểu trên các đoạn văn được trả về (Chen

--- TRANG 3 ---
et al., 2017b). Gần đây hơn, các mô hình truy xuất sâu đã trở nên phổ biến hơn để thay thế bộ truy xuất tương tự chuỗi truyền thống.

DPR (Karpukhin et al., 2020) là một phương pháp có giám sát được sử dụng rộng rãi để đạt kết quả tốt hơn BM25 trên một bộ sưu tập lớn các nhiệm vụ truy xuất văn bản (Thakur et al., 2021). Học tương phản được sử dụng để huấn luyện mô hình truy xuất sâu để phân biệt giữa các ứng viên tích cực được chú thích và các ứng viên tiêu cực được khai thác. Gần đây hơn, ColBERT (Khattab và Zaharia, 2020) đã được đề xuất để tích hợp sự hòa hợp muộn tinh vi hơn giữa truy vấn và bối cảnh để cải thiện DPR.

Retrieval Augmented Generation (RAG) (Lewis et al., 2020), Fusion-in-Decoder (FiD) (Izacard và Grave, 2021) và End-to-end training of Multi-Document Reader and Retriever (EmDR) (Singh et al., 2021) được đề xuất để đọc các truy xuất để trích xuất hoặc tạo ra câu trả lời. Những mô hình này đòi hỏi một bộ truy xuất/sắp xếp lại được huấn luyện để có được kết quả top-K, được đưa vào bộ đọc để tạo ra câu trả lời. Như đã thảo luận trong phần 1, mô hình của chúng tôi cung cấp khả năng diễn giải tốt hơn do biểu diễn tri thức nguyên tử. Trong tiểu mục 5.4, chúng tôi cũng chứng minh rằng tốc độ suy luận của mô hình chúng tôi nhanh hơn 5 lần.

2.2 Tạo Câu Hỏi
Vấn đề tạo câu hỏi (Zhou et al., 2017) đã thu hút sự chú ý từ cộng đồng trong những năm gần đây. Nó đã được sử dụng để tăng cường dữ liệu (Alberti et al., 2019) để cải thiện các hệ thống QA hiện tại hoặc để cải thiện các hệ thống truy xuất (Nogueira et al., 2019). Pan et al. (2021) cũng chứng minh rằng bằng cách kết nối các câu hỏi một bước được tạo ra, chúng ta có thể huấn luyện các hệ thống trả lời câu hỏi đa bước zero-shot. Ngoài QA, nó cũng được sử dụng rộng rãi trong các miền khác như đánh giá tính nhất quán thực tế của tóm tắt (Eyal et al., 2019; Wang et al., 2020) hoặc tăng cường biểu diễn theo ngữ cảnh (Jia et al., 2021). Liên quan nhất đến công việc của chúng tôi là PAQ (Lewis et al., 2021), nhằm tạo ra và sử dụng các cặp QA như các đơn vị truy xuất cho trả lời câu hỏi. Hiệu quả của dữ liệu này được xác minh thêm khi nó được sử dụng để huấn luyện DPR, mang lại khả năng tổng quát hóa miền tốt hơn (O ˘guz et al., 2021).

2.3 Mô Hình Ngôn Ngữ Tăng Cường Bộ Nhớ
Các mô hình ngôn ngữ tăng cường bộ nhớ đầu cuối nhằm huấn luyện một mô hình để truy cập rõ ràng bộ nhớ ngoài. Nghiên cứu hiện tại tập trung vào lưu trữ thực thể (Févry et al., 2020), đề cập thực thể (Dhingra et al., 2019; Sun et al., 2021; de Jong et al., 2022) hoặc bộ ba tri thức (Verga et al., 2021). Các lớp chú ý bộ nhớ sau đó được sử dụng để ảnh hưởng đến tính toán của các lớp transformer. Những bộ nhớ tập trung vào thực thể và sự thật này tự nhiên là nguyên tử và có thể diễn giải, và các mô hình sử dụng chúng đã cho thấy hiệu suất cạnh tranh trên các bộ dữ liệu QA tập trung vào thực thể như Web-Question-SP (Yih et al., 2016) và ComplexWebQuestions (Talmor và Berant, 2018). Tuy nhiên, những mô hình này bị hạn chế trong việc tích hợp tri thức tập trung vào thực thể và phân loại câu trả lời w.r.t một danh sách thực thể được định nghĩa trước. Ví dụ, những mô hình này không thể xử lý các câu hỏi với câu trả lời không phải thực thể, ví dụ số, ngày, cụm danh từ, v.v., phổ biến trong các bộ dữ liệu QA khác nhau như NQ (Kwiatkowski et al., 2019), SQuAD (Rajpurkar et al., 2016), hoặc HotpotQA (Yang et al., 2018).

3 Mô Hình Của Chúng Tôi: QAMAT
3.1 Định Nghĩa Vấn Đề
Đầu vào cho mô hình của chúng tôi là một đoạn văn bản X = x1;...;xn, trong đó X là một câu hỏi trong quá trình tinh chỉnh hoặc một đoạn văn trong tiền huấn luyện. Tiền huấn luyện được hình thức hóa như một nhiệm vụ hỏng span (Raffel et al., 2019): cho một ví dụ trong kho dữ liệu tiền huấn luyện là (X; {Qk; Ak}mk=1), trong đó A1;...;Am tương ứng với các span trong đầu vào X. Chúng tôi lấy mẫu k span từ X như một câu trả lời cloze và thay thế tất cả token trong một span bằng token [MASK], và mô hình cần phục hồi tất cả câu trả lời. Trong quá trình tinh chỉnh, chúng tôi thêm một [MASK] nhân tạo ở phía trước câu hỏi, và để mô hình phục hồi điều này như câu trả lời. Hàm mục tiêu tiền huấn luyện/tinh chỉnh là tối đa hóa các mục tiêu mô hình ngôn ngữ được che p(Y|X) = Σmi∈M p(Y|X; mi)p(mi|X), tính tổng trên toàn bộ bộ nhớ M. Tuy nhiên, do tính không khả thi của nó trong một bộ nhớ quy mô lớn, chúng tôi áp dụng một xấp xỉ để chỉ tính tổng trên các mục bộ nhớ top-K TopK(M).

Chúng tôi định nghĩa hàm mã hóa là f, lấy một chuỗi đầu vào X làm đầu vào để tạo ra một chuỗi vector F(X) ∈ Rn×d, trong đó n là độ dài đầu vào và d là kích thước ẩn. Vị trí được chỉ định của F(X) sẽ được sử dụng làm biểu diễn truy vấn và bộ nhớ, được ký hiệu là f(X; [MASK]) ∈ Rd (tại vị trí [MASK]) và khóa/giá trị bộ nhớ là f(mki; [CLS]) ∈ Rd (tại vị trí [CLS]). Để ngắn gọn, chúng tôi bỏ qua [MASK] và [CLS] và đơn giản sử dụng f().

Chúng tôi cũng định nghĩa một toán tử phát sóng Bnk(x) để

--- TRANG 4 ---
Hình 2: Kiến trúc: hình trên cho thấy quá trình truy xuất với bộ mã hóa chung, hình dưới cho thấy quá trình giải mã để tận dụng biểu diễn thần kinh và rời rạc của truy xuất bộ nhớ.

phát sóng một vector thành một ma trận bằng cách gán vector x cho hàng thứ k-th trong khi điền phần còn lại bằng số không, tức là Bnk(x) = [0;...xT;...;0].

3.2 Bộ Truy Xuất Dày Đặc
Bộ nhớ M chứa các thành phần khóa và giá trị riêng biệt, trong đó khóa mki chứa một câu hỏi, và giá trị tương ứng mvi chứa việc nối câu hỏi-câu trả lời. Để truy xuất top-k cặp QA từ bộ nhớ, chúng tôi sử dụng bộ mã hóa f để mã hóa X và mi riêng biệt và chọn các mục top-K TopK(M) dựa trên tích vô hướng của chúng, tức là TopK mi∈M f(X) · f(mki).

3.3 Tích Hợp Bộ Nhớ Thần Kinh
Sau khi mô hình truy xuất các ứng viên Top-K, các giá trị bộ nhớ tương ứng mvi cần được tận dụng vào bộ mã hóa để ảnh hưởng đến đầu ra của bộ giải mã một cách có thể vi phân. Chúng tôi viết mục tiêu p(Y|X) của chúng tôi như:
Σmi∈TopK(M) p(Y|X; mi)p(mi|X)
= Σmi∈TopK(M) p(mi|X)g(Y|F(X) + Bnk[f(mvi)])
≈ g(Y|Σmi∈TopK(M) p(mi|X)(F(X) + Bnk[f(mvi)]))
= g(Y|F(X) + Bnk[Σmi∈TopK(M) p(mi|X)f(mvi)])
p(mi|X) = ef(X)·f(mki) / Σmi∈TopK M ef(X)·f(mki)

Xác suất p(Y|X; mi) được tham số hóa bởi một hàm giải mã g, lấy biểu diễn bộ mã hóa được truyền bộ nhớ F(X) + Bnk[f(mvi)] làm đầu vào. Chúng tôi xấp xỉ xác suất biên này bằng cách kéo tổng có trọng số vào trong hàm giải mã g để dẫn xuất một biểu diễn bộ mã hóa được truyền bộ nhớ tổng hợp F(X) + Bnk[]. Trọng số truy xuất p(m|X) được tính như softmax trên điểm truy xuất trên các mục top-K.

Để đơn giản, H(X; TopK(M); p(m|X)) được sử dụng để ký hiệu biểu diễn bộ mã hóa này, do đó mục tiêu có thể được viết như sau:
p(Y|X) = g(Y|H(X; TopK(M); p(m|X))) (1)

Như được hiển thị trong phần trên của Hình 2, chúng tôi đầu tiên sử dụng tổng có trọng số trên biểu diễn thần kinh của các mục bộ nhớ được truy xuất f(mvi) và sau đó đơn giản thêm nó vào biểu diễn bộ mã hóa để truyền thông tin cặp QA được truy xuất. Cả hai hoạt động này đều có thể vi phân, điều này khiến có thể huấn luyện bộ truy xuất một cách ẩn. Về bản chất, bộ truy xuất sẽ tăng trọng số p(mi|X) trên các mục bộ nhớ liên quan hơn thay vì những mục không liên quan.

3.4 Tích Hợp Bộ Nhớ Thần Kinh + Rời Rạc
Một nhược điểm của việc áp dụng tổng có trọng số Σi p(mi|X)f(mvi) ∈ Rd là tất cả thông tin từ tất cả các tài liệu top-K được nén quá mức thành một vector d-chiều, trong khi biểu diễn truy xuất token chứa nhiều thông tin hơn. Do đó, chúng tôi đề xuất thêm một biểu diễn tinh vi theo token Ĥ(X; TopK(M)) để giúp mô hình truy cập trực tiếp các giá trị rời rạc được truy xuất mi. Biểu diễn được thu được bằng cách mã hóa việc nối đầu vào X và các token rời rạc được truy xuất X̂ = Concat [mk; ...; m1; X] ∈ R(n+k|m|)×d.

Việc tích hợp bộ nhớ rời rạc như vậy làm phong phú đáng kể biểu diễn cho mi và cho phép chú ý chéo giữa truy vấn và truy xuất, giải quyết vấn đề thắt cổ chai. Tuy nhiên, biểu diễn rời rạc như vậy không thể truyền gradient ngược về bộ truy xuất. Cuối cùng, chúng tôi đề xuất kết hợp tích hợp bộ nhớ thần kinh H(X; ·) và bộ nhớ rời rạc Ĥ(X; ·) để kết hợp ưu điểm của chúng.

p(Y|X)
= g(Y|H'(X; TopK(M); p(m|X)) + Ĥ(X; TopK(M))) (2)

trong đó λ là hệ số cân bằng để cân nhắc hai biểu diễn. Chúng tôi sử dụng H'(···) = [0; H(···)] để biểu diễn việc nối ma trận không 0 ∈ Rk|m|×d, có chiều nhất quán với Ĥ.

--- TRANG 5 ---
Sau khi tận dụng Ĥ, mô hình của chúng tôi cho thấy cải thiện đáng kể trên các nhiệm vụ hạ nguồn với 14% trên TriviaQA và 10% trên HotpotQA.

H(X; TopK(M); p(m|X)) chỉ được sử dụng để huấn luyện bộ truy xuất một cách ẩn, sau khi huấn luyện, chúng ta có thể bỏ nó và chỉ sử dụng biểu diễn được nối Ĥ(X; TopK(M)) như biểu diễn bộ mã hóa. Bộ giải mã g sẽ chú ý đến Ĥ và thực hiện tìm kiếm tham lam trên từ vựng để tạo ra đầu ra.

3.5 Mở Rộng Đa Bước
Để mở rộng thêm khả năng của QAMAT thực hiện lập luận tổ hợp, chúng tôi đề xuất một kiến trúc cascaded (được mô tả trong Hình 3) được gọi là QAMAT+, trong đó mô hình học thực hiện nhiều vòng truy xuất trước khi đưa các đầu vào được tăng cường vào bộ giải mã. Cụ thể cho lập luận hai bước, chúng tôi sử dụng X làm truy vấn để truy xuất vòng đầu tiên của các giá trị bộ nhớ top-K TopK(M; 1) với bộ truy xuất đã học f được mô tả trong tiểu mục 3.2. Tiếp theo, chúng tôi tăng cường truy vấn bằng cách nối các giá trị được truy xuất như X1 = [TopK(M; 1); X]. Truy vấn mới X1 này được sử dụng để thực hiện vòng truy xuất thứ hai để có được các giá trị bộ nhớ top-K bổ sung, TopK(M; 2). Dựa trên TopK(M; 2), chúng tôi tính biểu diễn bộ mã hóa lai H(X1; TopK(M; 2)) và Ĥ(X1; TopK(M; 2)) để tính p(Y|X1; ·).

Hình 3: Kiến trúc QAMAT+: Khung đa bước cho tích hợp bộ nhớ câu hỏi-câu trả lời.

4 Huấn Luyện
4.1 Kho Dữ Liệu Tiền Huấn Luyện
Các cặp QA của chúng tôi được xây dựng bằng cách kết hợp 30M cặp QA đã được loại bỏ trùng lặp từ PAQ (Lewis et al., 2021) (ban đầu 65M, chúng tôi xóa các phép diễn giải để giữ một tập con) và 30M cặp QA bổ sung được tạo ra từ pipeline của chúng tôi. Các cặp QA bổ sung được điền từ các khối đoạn văn không chồng chéo để tăng độ bao phủ tri thức trên Wikipedia. Pipeline tạo QA của chúng tôi tương tự như (Lewis et al., 2021) nhưng được huấn luyện chỉ trên SQuAD 2.0 (Rajpurkar et al., 2018) và được lọc bằng một mô hình đọc hiểu rẻ thay vì FiD (Izacard và Grave, 2021), các chi tiết được

Hình 4: Quy trình huấn luyện hai giai đoạn: huấn luyện trong batch với bộ nhớ cụ thể cho batch và cập nhật gradient đầu cuối, huấn luyện toàn cục với bộ nhớ toàn cục cố định và cập nhật gradient một phần.

mô tả trong Phụ lục. Thống kê cuối cùng của QA-memory của chúng tôi được mô tả trong Bảng 1, trong đó tổng kích thước có thể so sánh với RePAQ.

Kích Thước Bộ Nhớ #Đoạn Văn Dữ Liệu Huấn Luyện
Dedup-PAQ 30M 10M NaturalQuestions
Bổ sung 30M 10M SQuAD 2.0
Kết hợp 60M 20M -

Bảng 1: Thống kê phân tích kho QA của chúng tôi.

Chúng tôi ký hiệu toàn bộ bộ nhớ là M và hình thức hóa kho dữ liệu tiền huấn luyện là {X; {Qk; Ak}mk=1}, trong đó X là đoạn văn được canh chỉnh với nhiều cặp QA {Qk; Ak}mk=1 được tạo ra từ nó.

4.2 Huấn Luyện Đầu Cuối
Trong quá trình huấn luyện, quá trình truy xuất được tích hợp vào vòng lặp huấn luyện của mô hình. Phương pháp được áp dụng rộng rãi nhất để thực hiện điều này là tìm kiếm láng giềng gần nhất xấp xỉ (ANNS) được thực hiện hiệu quả bởi một số thư viện như ScaNN (Guo et al., 2020), FAISS (Johnson et al., 2019), v.v. Những thư viện này đòi hỏi một tập hợp vector dày đặc cố định để xây dựng chỉ mục và thực hiện tìm kiếm Láng-Giềng-Gần-Nhất bằng các thuật toán xấp xỉ. Tuy nhiên, bộ mã hóa bộ nhớ f của chúng tôi được cập nhật liên tục, điều này đặt ra thách thức lớn cho việc xây dựng chỉ mục ANNS. REALM (Guu et al., 2020) và RePAQ (Lewis et al., 2021) sử dụng một tiểu quá trình xây dựng chỉ mục bất đồng bộ để làm mới chỉ mục mỗi K bước, được biết là cực kỳ tốn kém về tính toán, đặc biệt với một bộ nhớ lớn. Để tránh chi phí tính toán đắt đỏ như vậy, chúng tôi được truyền cảm hứng bởi TOME (de Jong et al., 2022) để áp dụng huấn luyện hai giai đoạn như được hiển thị trong Hình 4.

Tiền Huấn Luyện Trong Batch Trong giai đoạn đầu tiên, thay vì sử dụng toàn bộ bộ nhớ, chúng tôi đề xuất một bộ nhớ cụ thể cho batch nối các mục tích cực, tiêu cực ngẫu nhiên, và tiêu cực khó từ mỗi thể hiện trong batch. Giả sử chúng ta có kích thước batch B chứa các ví dụ {Xi; {Qki; Aki}Kk=1}Bi=1. Cho mỗi ví dụ tồn tại K cặp QA tích cực được tạo ra từ ngữ cảnh cho Xi. Ngoài ra, chúng tôi khai thác K cặp QA tiêu cực khó {Qki; Aki}Kk=1 cho mỗi đầu vào Xi để tăng độ khó truy xuất. Việc khai thác tiêu cực khó này được thực hiện với BM25 (Robertson và Zaragoza, 2009) tương tự như DPR (Karpukhin et al., 2020). Chúng tôi xây dựng bộ nhớ trong batch bằng cách tổng hợp KB cặp QA tích cực và KB mục bộ nhớ tiêu cực khó, vì vậy bộ nhớ trong batch M̂ chứa tổng cộng 2KB cặp QA (khoảng vài nghìn). Do kích thước nhỏ của bộ nhớ, chúng ta có thể xây dựng chỉ mục bộ nhớ rất hiệu quả. Do đó, nó cho phép chúng ta liên tục cập nhật các tham số bộ mã hóa bộ nhớ f để đạt hiệu suất truy xuất cặp QA mạnh.

Tiền Huấn Luyện Toàn Cục và Tinh Chỉnh Trong giai đoạn này, chúng tôi đầu tiên đóng băng bộ mã hóa bộ nhớ f để tạo ra embedding khóa bộ nhớ cho toàn bộ bộ nhớ để xây dựng chỉ mục của nó. Sau đó chúng tôi kết hợp thuật toán tìm kiếm xấp xỉ trên thiết bị1 để thực hiện tìm kiếm láng giềng gần nhất trên chỉ mục bộ nhớ để truy xuất các cặp QA top-K. Chính thức, chúng tôi đề xuất tối đa hóa cùng mục tiêu như Phương trình 2 nhưng với stop-gradient được áp dụng cho số hạng p(m|X). Trong bước này, mô hình sẽ chỉ cập nhật mô hình truy vấn f và mô hình giải mã g. Trong quá trình tinh chỉnh, chúng tôi theo cùng công thức như tiền huấn luyện toàn cục. Thay vì đưa các đoạn văn được che làm đầu vào, chúng tôi sử dụng các câu hỏi với token [MASK] giả ở phía trước làm đầu vào.

4.3 Mở Rộng Đa Bước
Đối với mô hình mở rộng QAMAT+ của chúng tôi, vì quá trình tăng cường truy xuất không thể được học một cách ẩn, tức là việc truyền gradient bị chặn trong bước nối, chúng tôi thêm giám sát bổ sung để tối đa hóa xác suất truy xuất sự thật p(m1|X) cho truy xuất vòng đầu tiên m1. Chúng tôi thêm mục tiêu giám sát truy xuất như vậy vào mục tiêu ban đầu p(Y|X1), trong đó X1 là các đầu vào được tăng cường truy xuất như được mô tả trong tiểu mục 3.5.

1https://github.com/google-research/language/tree/master/language/mentionmemory

5 Thí Nghiệm QA
5.1 Chi Tiết Triển Khai
Mô hình của chúng tôi dựa trên kiến trúc T5-base hoặc large được thực hiện trong JAX2 và tiền huấn luyện trên 32 TPU trên Google Cloud3. Trong quá trình huấn luyện trong batch, bộ mã hóa truy vấn và chỉ mục f của chúng tôi được chia sẻ và khởi tạo từ bộ mã hóa T5 (trong quá trình huấn luyện toàn cục, bộ mã hóa chỉ mục được cố định và bộ mã hóa truy vấn tiếp tục được cập nhật). Bộ giải mã g của chúng tôi tương tự được khởi tạo từ bộ giải mã T5. Tổng cộng, chúng tôi xây dựng 60M cặp câu hỏi-câu trả lời như bộ nhớ toàn cục. Khóa bộ nhớ là câu hỏi được token hóa bởi mô hình sentencepiece T5 thành 32 token, và giá trị bộ nhớ là câu trả lời được nối với câu hỏi của nó được token hóa thành 40 token. Bộ nhớ được lập chỉ mục bởi một ma trận được tính toán trước Mk ∈ R|M|×d được tính dựa trên các khóa của nó (câu hỏi). Các giá trị bộ nhớ top-K tương ứng (câu hỏi+câu trả lời) sẽ được lấy.

Trong quá trình tiền huấn luyện trong batch, chúng tôi sử dụng kích thước batch lớn 512 và tốc độ học 1e-3, trong đó mỗi ví dụ chứa một cặp Q-A tích cực và 7 cặp QA tiêu cực khó được khai thác thông qua BM25 (Robertson và Zaragoza, 2009). Bộ nhớ trong batch chứa tổng cộng 4096 mục, chúng tôi đặt Top-k là 4 và cập nhật trên tất cả các module. Sau 100K bước tiền huấn luyện trong batch, chúng tôi chuyển sang tiền huấn luyện toàn cục với truy xuất bộ nhớ toàn cục. Chúng tôi giảm kích thước batch xuống 32 và tăng Top-K lên 16 cho bộ nhớ lớn hơn. Chúng tôi chỉ cập nhật bộ mã hóa truy vấn và bộ giải mã trong 100K bước khác. Cuối cùng, chúng tôi đặt K là 32 để tinh chỉnh trên các bộ dữ liệu hạ nguồn với tốc độ học giảm 5e-4.

5.2 Bộ Dữ Liệu
Chúng tôi đánh giá framework của mình trên ba bộ dữ liệu trả lời câu hỏi miền mở một bước được sử dụng rộng rãi nhất và hai bộ dữ liệu trả lời câu hỏi miền mở đa bước

NQ-Open Bộ dữ liệu NaturalQuestions (Kwiatkowski et al., 2019) bao gồm các truy vấn Google tự nhiên và câu trả lời của chúng. Chúng tôi theo Lee et al. (2019) để giữ các câu hỏi có "loại câu trả lời ngắn". Nó bao gồm 79168 ví dụ huấn luyện, 8757 ví dụ dev, và 3610 ví dụ test.

TriviaQA Bộ dữ liệu TriviaQA là một bộ sưu tập các cặp câu hỏi-câu trả lời trivia được lấy từ web (Joshi et al., 2017). Chúng tôi sử dụng phiên bản không lọc để đánh giá mô hình của chúng tôi bao gồm 78785 huấn luyện, 8837 dev, và 113313 ví dụ test.

WebQuestions Bộ dữ liệu WebQuestion chứa các câu hỏi được lấy mẫu từ Google Suggest API (Berant et al., 2013). Các câu trả lời được chú thích từ FreeBase, tập huấn luyện chứa 3417 ví dụ, tập dev chứa 361 ví dụ, và tập test chứa 2032 ví dụ.

HotpotQA Bộ dữ liệu HotpotQA chứa các câu hỏi được tạo ra bởi các công nhân con người bằng cách đọc hai đoạn văn (Yang et al., 2018). Các câu hỏi được thiết kế để đòi hỏi nhiều bước và bao gồm cả câu hỏi cầu nối và câu hỏi so sánh. Tập huấn luyện chứa tổng cộng 90564 ví dụ, tập dev chứa 7405 ví dụ để đánh giá.

Musique Bộ dữ liệu Musique chứa các câu hỏi được tạo ra bằng cách sáng tác nhiều câu hỏi từ các câu hỏi một bước hiện có và được xây dựng để chứa ít thiên kiến và artifact hơn (Trivedi et al., 2021). Trong các thí nghiệm của chúng tôi, chúng tôi chỉ xem xét tập con các câu hỏi 2-bước, dẫn đến tập huấn luyện 14376 ví dụ và tập dev 1252 ví dụ để đánh giá. Trong khi bộ dữ liệu ban đầu được thiết kế như một cài đặt phân tâm (cho một câu hỏi và một số lượng nhỏ đoạn văn, trả về câu trả lời), chúng tôi thay vào đó xem xét một cài đặt miền mở.

5.3 Baseline
Chúng tôi so sánh mô hình của chúng tôi với các baseline từ các danh mục sau. 1) Các mô hình ngôn ngữ lớn CBQA (T5 XXL), trực tiếp đưa ra câu trả lời mà không cần truy xuất. 2) Các mô hình tăng cường bộ nhớ thực thể/KG sử dụng chú ý bộ nhớ để kết hợp các tính năng cấp thực thể vào các mô hình ngôn ngữ (Entities-as-Experts (EaE) (Févry et al., 2020), Fact-Injected Language Model (FilM) (Verga et al., 2021), MentionMemory (TOME) (de Jong et al., 2022)). 3) Mô hình truy xuất-và-đọc, truy xuất các đoạn văn để chuyển cho mô hình đọc dự đoán câu trả lời. 4) Các mô hình truy xuất QA, huấn luyện một bộ truy xuất để thu thập các cặp QA từ một cơ sở dữ liệu lớn, và sau đó sắp xếp lại những cặp QA này (top 50-100) với truy vấn ban đầu với chú ý chéo. Câu trả lời xếp hạng cao nhất được trả về như câu trả lời cuối cùng.

5.4 Kết Quả Một Bước
Kết quả của chúng tôi được tóm tắt trong Bảng 2 báo cáo điểm khớp chính xác (EM).

So Sánh với RePAQ So sánh chính của chúng tôi là với phương pháp dựa trên truy xuất QA tốt nhất trước đó "RePAQ w/ rerank (XXL ALBERT)". Mô hình này có số lượng tham số tương tự như QAMAT (Large). Mà không sử dụng quy trình sắp xếp lại rõ ràng, mô hình của chúng tôi hoạt động hơi kém hơn trên NQ nhưng đạt được lợi ích đáng kể trên TriviaQA và WebQuestion. Đặc biệt trên WebQuestion, chỉ chứa 3K ví dụ huấn luyện, RePAQ hoạt động kém đáng kể hơn các bộ dữ liệu khác vì nó đòi hỏi một lượng lớn ví dụ để cập nhật bộ truy xuất từ đầu. Với chiến lược tiền huấn luyện được đề xuất của chúng tôi, QAMAT có thể khởi tạo từ một checkpoint tốt hơn nhiều để giảm độ phức tạp mẫu, mang lại cải thiện EM tuyệt đối 6%. Ngoài ra, mà không cần bất kỳ tinh chỉnh nào, chúng tôi chứng minh rằng mô hình của chúng tôi đã đạt kết quả hứa hẹn trên các bộ dữ liệu này, gần như khớp với hiệu suất của "RePAQ w/o rerank"4.

So Sánh với các mô hình truy xuất-và-đọc Khi so sánh với loại mô hình này, QAMAT khớp khoảng hiệu suất của RAG, mặc dù vẫn thua mô hình SoTA FiD. Tuy nhiên, FiD đòi hỏi đọc 100 đoạn văn, tức là 20K token trong khi mô hình tốt nhất của chúng tôi hoạt động hiệu quả hơn bằng cách chỉ đọc top-32 cặp QA, tức là 1.2K token. Để điều tra sự khác biệt tốc độ giữa các phương pháp này, chúng tôi so sánh tốc độ suy luận của chúng bằng cùng phần cứng (32 Google Cloud v3 TPU). Chúng tôi thấy rằng QAMAT có thể trả lời 240 Q/giây, trong khi FiD chỉ trả lời 50 Q/giây, tăng tốc thời gian suy luận 5x so với FiD.

5.5 Kết Quả Đa Bước
Vì kho tài liệu nguồn của HotpotQA và Musique khác với các bộ dữ liệu QA một bước, chúng tôi áp dụng mô hình tạo câu hỏi được huấn luyện trên SQuAD 2.0 (Rajpurkar et al., 2018) để tạo câu hỏi cho hai bộ dữ liệu này. Để tạo kho tài liệu, chúng tôi thu thập tất cả các tài liệu tích cực và tiêu cực được cung cấp, thu được 500K đoạn văn cho HotpotQA và 85K đoạn văn cho Musique. Sau đó chúng tôi sử dụng các mô hình tạo được huấn luyện để điền 3M cặp QA cho HotpotQA và 500K cặp QA cho Musique. Những cặp QA này sau đó được sử dụng như nguồn bộ nhớ cho QAMAT+, mô phỏng một thiết lập miền mở (hơi nhỏ hơn). Khi huấn luyện QAMAT+ trên Musique, chúng tôi khởi tạo từ checkpoint tiền huấn luyện trong Batch của HotpotQA, có thể mang lại cải thiện F1 5-7%.

4Đáng chú ý rằng các mô hình tạo câu hỏi được huấn luyện bằng một số dữ liệu huấn luyện của các bộ dữ liệu này nên điều này không thực sự là hiệu suất "zero-shot".

--- TRANG 8 ---
Mô hình (Tập Test) NQ TQA WQ
T5-3B (Roberts et al., 2020) 30.4 35.1 33.6
T5-11B (Roberts et al., 2020) 32.6 42.3 37.2
EaE (Févry et al., 2020) - 43.2 -
FILM (Verga et al., 2021) - 29.1 -
TOME-2 (de Jong et al., 2022) - 53.4 -
DensePhrases (Lee et al., 2021) 40.9 50.7 -
REALM (Guu et al., 2020) 40.4 55.8 40.7
DPR (Karpukhin et al., 2020) 41.5 57.9 42.4
RAG-Seq (Lewis et al., 2020) 44.5 56.8 45.2
FiD (Izacard và Grave, 2021) 48.2 65.0 -
RePAQ (Lewis et al., 2021) 41.2 38.8 29.4 y
RePAQ+Rerank (Lewis et al., 2021) 47.6 50.7 37.6 y
QAMAT Zero-Shot (Base) 37.9 34.1 25.9
QAMAT Zero-Shot (Large) 39.8 40.0 25.1
QAMAT Fine-tuned (Base) 44.5 53.2 43.0
QAMAT Fine-tuned (Large) 45.5 54.8 43.6

Bảng 2: Kết quả thí nghiệm chính trên các bộ dữ liệu trả lời câu hỏi một bước (NQ=NaturalQuestions, TQA=TriviaQA, WQ=WebQuestions), y có nghĩa là Sao chép tốt nhất bằng triển khai của chúng tôi.

Mô hình (Điểm F1 Tập Dev) HPQ MusQ
T5-3B (Roberts et al., 2020) 27.8 7.5
T5-11B (Roberts et al., 2020) 30.2 9.0
MDR+T5-Decoder (Xiong et al., 2020) 62.6 26.8
RePAQ (Lewis et al., 2021) y 47.8 18.6
QAMAT 42.0 16.7
QAMAT+ 57.6 29.8

Bảng 3: Kết quả thí nghiệm chính trên các bộ dữ liệu QA Đa Bước với QAMAT và QAMAT+, y có nghĩa là Sao chép tốt nhất bằng triển khai của chúng tôi.

Trong Bảng 3, chúng tôi cho thấy QAMAT+ đạt kết quả hứa hẹn trên cả hai bộ dữ liệu đa bước, vượt trội hơn T5-CBQA và RePAQ với biên độ lớn. Ngoài ra, QAMAT+ hoạt động tốt hơn đáng kể so với QAMAT một bước, chứng minh hiệu quả của việc thực hiện truy xuất nhiều vòng. Mặc dù QAMAT+ vẫn thua mô hình dựa trên tài liệu (MDR+T5 Decoder) trên HotpotQA, nó vượt qua nó trên bộ dữ liệu Musique thách thức hơn. Những kết quả khuyến khích này cho thấy tiềm năng của QAMAT+ thực hiện lập luận tổ hợp trên nhiều cặp QA, điều này tăng đáng kể độ bao phủ của cơ sở dữ liệu QA để bao gồm nhiều thông tin thực tế tổ hợp hơn.

5.6 Nghiên Cứu Loại Bỏ
Số Lượng Truy Xuất Để hiểu các tính chất của mô hình chúng tôi tốt hơn, chúng tôi đầu tiên điều tra tác động của số lượng truy xuất, K, đến hiệu suất của mô hình. Chúng tôi dần dần tăng K để thu thập

Top-K 1 10 20 30
NQ-Recall@K 0.41 0.58 0.62 0.64
TriviaQA-Recll@K 0.46 0.66 0.70 0.72
NQ-EM@K 0.39 0.42 0.44 0.44
TriviaQA-EM@K 0.45 0.51 0.53 0.53

Bảng 4: Recall truy xuất và điểm EM của các số lượng truy xuất khác nhau trên tập test.

Giai Đoạn Tiền Huấn Luyện NQ TQA WQ
Chỉ Trong-Batch 42.1 48.2 39.7
Chỉ Toàn Cục 26.0 28.9 26.1
Trong-Batch→Toàn Cục 44.5 53.2 43.0

Bảng 5: Hiệu suất EM hạ nguồn của các mô hình khi được tiền huấn luyện bằng giai đoạn trong-batch, toàn cục, hoặc cả hai.

thập recall và hiệu suất QA cuối cùng. Kết quả được hiển thị trong Bảng 4. Chúng tôi quan sát rằng mặc dù recall truy xuất tiếp tục tăng vượt quá K > 20, điểm EM bão hòa sớm hơn nhiều. Nghiên cứu tương lai có thể cải thiện hiệu suất hơn nữa bằng cách phát triển các bộ giải mã để khai thác chính xác hơn những tập hợp truy xuất lớn hơn này.

Tầm Quan Trọng của Tiền Huấn Luyện Hai Giai Đoạn Tiếp theo chúng tôi phân tích tầm quan trọng của tiền huấn luyện hai giai đoạn từ phần 4 bằng cách loại bỏ giai đoạn trong-batch hoặc toàn cục. Từ kết quả của chúng tôi được hiển thị trong Bảng 5, chúng ta có thể thấy rằng chỉ sử dụng tiền huấn luyện trong-batch dẫn đến suy giảm hiệu suất khi so sánh với phương pháp hai giai đoạn. Điều này có thể là do mô hình không bao giờ được tiếp xúc với tập hợp đầy đủ các tiêu cực khó sẽ được gặp phải khi thực hiện truy xuất trên bộ nhớ toàn cục. Mặt khác, nếu chúng ta trực tiếp tiền huấn luyện mô hình bộ nhớ toàn cục mà không có bất kỳ khởi tạo trong-batch nào, hiệu suất bộ truy xuất gần như ngẫu nhiên và bộ giải mã do đó học bỏ qua truy xuất và đơn giản ghi nhớ các cặp câu hỏi-câu trả lời.

6 Kết Luận
Trong bài báo này, chúng tôi đề xuất một kiến trúc chính xác và hiệu quả hơn để sử dụng các cặp QA như các đơn vị biểu diễn tri thức. Mô hình QAMAT được đề xuất của chúng tôi vượt trội hơn RePAQ đáng kể, trong khi tận dụng quy trình huấn luyện ít tốn kém hơn của chúng tôi. Hơn nữa, chúng tôi cho thấy cách một mô hình được hỗ trợ QA có thể thực hiện lập luận tổ hợp và giải quyết các truy vấn phức tạp hơn. Trong tương lai, chúng tôi hy vọng thu hẹp khoảng cách với các mô hình truy xuất-và-đọc dựa trên tài liệu hiện đại và mở rộng phương pháp này cho một tập hợp rộng hơn các nhiệm vụ.

--- TRANG 9 ---
Hạn Chế
Phương pháp của chúng tôi có một số hạn chế: 1) chúng tôi sử dụng các cặp câu hỏi-câu trả lời được tạo ra như một cơ sở tri thức, được trích xuất từ các tài liệu web. Để duy trì chất lượng cao và tính trung thực, pipeline tạo câu hỏi cần được huấn luyện tốt với một lượng đủ dữ liệu sạch. Những điều kiện như vậy có thể không đúng cho các miền khác ngoài Wikipedia như văn bản y sinh, do đó khái niệm QA-as-Knowledge-Base tổng quát có thể đòi hỏi các đổi mới bổ sung để mở rộng sang các lĩnh vực khác. 2) Việc học truy xuất ẩn của chúng tôi đòi hỏi dữ liệu được ghép cặp gần đúng để học căn chỉnh giữa truy vấn và bộ nhớ. Điều này khó thỏa mãn trong một số miền với dữ liệu ồn ào hơn hoặc chỉ có căn chỉnh rất yếu giữa truy vấn và bộ nhớ. 3) Mô hình của chúng tôi đòi hỏi các tín hiệu truy xuất trung gian được khai thác để huấn luyện QAMAT+, hiện tại dựa vào các heuristics dựa trên sự chồng chéo từ vựng. Trong các trường hợp khác, điều này có thể không đủ và thay vào đó có thể đòi hỏi một thiết kế có nguyên tắc hơn để khai thác giám sát trung gian tốt hơn.

Tuyên Bố Đạo Đức
Công việc của chúng tôi khuyến khích mô hình dựa trên tri thức hiện có được điền từ các bộ sưu tập văn bản lớn. Chúng tôi tin rằng đây là một hướng hợp lý để xây dựng các mô hình học máy đáng tin cậy và mạnh mẽ hơn. Có những phân bổ tốt hơn cho nguồn tri thức có thể giúp con người hiểu rõ hơn lý do của mô hình cho việc ra quyết định. Tuy nhiên, chúng tôi thừa nhận rằng các mô hình tạo câu hỏi được sử dụng để điền cơ sở tri thức QA có thể làm trầm trọng thêm những thiên kiến đã có trong dữ liệu Wikipedia gốc. Chúng tôi sẽ tiếp tục làm việc theo hướng này để giảm thiểu những tác động tiêu cực tiềm tàng của nó.

Tài Liệu Tham Khảo
Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, và Michael Collins. 2019. Synthetic qa corpora generation with roundtrip consistency. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6168–6173.

Jonathan Berant, Andrew Chou, Roy Frostig, và Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In Proceedings of the 2013 conference on empirical methods in natural language processing, pages 1533–1544.

Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. 2021. Improving language models by retrieving from trillions of tokens. arXiv preprint arXiv:2112.04426.

Danqi Chen, Adam Fisch, Jason Weston, và Antoine Bordes. 2017a. Reading wikipedia to answer open-domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1870–1879.

Danqi Chen, Adam Fisch, Jason Weston, và Antoine Bordes. 2017b. Reading Wikipedia to answer open-domain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1870–1879, Vancouver, Canada. Association for Computational Linguistics.

Michiel de Jong, Yury Zemlyanskiy, Nicholas FitzGerald, Fei Sha, và William Cohen. 2022. Mention memory: incorporating textual knowledge into transformers through entity mention attention. International Conference on Learning Representations.

Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, và William W Cohen. 2019. Differentiable reasoning over a virtual knowledge base. In International Conference on Learning Representations.

Matan Eyal, Tal Baumel, và Michael Elhadad. 2019. Question answering as an automatic evaluation metric for news article summarization. In Proceedings of NAACL-HLT, pages 3938–3948.

Thibault Févry, Livio Baldini Soares, Nicholas Fitzgerald, Eunsol Choi, và Tom Kwiatkowski. 2020. Entities as experts: Sparse memory access with entity supervision. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4937–4951.

Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, và Sanjiv Kumar. 2020. Accelerating large-scale inference with anisotropic vector quantization. In International Conference on Machine Learning, pages 3887–3896. PMLR.

Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, và Mingwei Chang. 2020. Retrieval augmented language model pre-training. In Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 3929–3938. PMLR.

Gautier Izacard và Édouard Grave. 2021. Leveraging passage retrieval with generative models for open domain question answering. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 874–880.

--- TRANG 10 ---
Robin Jia, Mike Lewis, và Luke Zettlemoyer. 2021. Question answering infused pre-training of general-purpose contextualized representations. arXiv preprint arXiv:2106.08190.

Jeff Johnson, Matthijs Douze, và Hervé Jégou. 2019. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data, 7(3):535–547.

Mandar Joshi, Eunsol Choi, Daniel S Weld, và Luke Zettlemoyer. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601–1611.

Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, và Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6769–6781.

Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, và Mike Lewis. 2019. Generalization through memorization: Nearest neighbor language models. In International Conference on Learning Representations.

Omar Khattab và Matei Zaharia. 2020. Colbert: Efficient and effective passage search via contextualized late interaction over bert. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, pages 39–48.

Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. 2019. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:453–466.

Jinhyuk Lee, Mujeen Sung, Jaewoo Kang, và Danqi Chen. 2021. Learning dense representations of phrases at scale. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6634–6647.

Kenton Lee, Ming-Wei Chang, và Kristina Toutanova. 2019. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6086–6096.

Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459–9474.

Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich Küttler, Aleksandra Piktus, Pontus Stenetorp, và Sebastian Riedel. 2021. Paq: 65 million probably-asked questions and what you can do with them. Transactions of the Association for Computational Linguistics, 9:1098–1115.

Sewon Min, Jordan Boyd-Graber, Chris Alberti, Danqi Chen, Eunsol Choi, Michael Collins, Kelvin Guu, Hannaneh Hajishirzi, Kenton Lee, Jennimaria Palomaki, et al. 2021. Neurips 2020 efficientqa competition: Systems, analyses and lessons learned. In NeurIPS 2020 Competition and Demonstration Track, pages 86–111. PMLR.

Rodrigo Nogueira, Wei Yang, Jimmy Lin, và Kyunghyun Cho. 2019. Document expansion by query prediction. arXiv preprint arXiv:1904.08375.

Barlas O ˘guz, Kushal Lakhotia, Anchit Gupta, Patrick Lewis, Vladimir Karpukhin, Aleksandra Piktus, Xilun Chen, Sebastian Riedel, Wen-tau Yih, Sonal Gupta, et al. 2021. Domain-matched pre-training tasks for dense retrieval. arXiv preprint arXiv:2107.13602.

Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, và William Yang Wang. 2021. Unsupervised multi-hop question answering by question generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5866–5880.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. 2019. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21:1–67.

Pranav Rajpurkar, Robin Jia, và Percy Liang. 2018. Know what you don't know: Unanswerable questions for squad. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 784–789.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2383–2392.

Adam Roberts, Colin Raffel, và Noam Shazeer. 2020. How much knowledge can you pack into the parameters of a language model? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5418–5426.

--- TRANG 11 ---
Stephen Robertson và Hugo Zaragoza. 2009. The probabilistic relevance framework: BM25 and beyond. Now Publishers Inc.

Devendra Singh, Siva Reddy, Will Hamilton, Chris Dyer, và Dani Yogatama. 2021. End-to-end training of multi-document reader and retriever for open-domain question answering. Advances in Neural Information Processing Systems, 34.

Haitian Sun, Pat Verga, Bhuwan Dhingra, Ruslan Salakhutdinov, và William W Cohen. 2021. Reasoning over virtual knowledge bases with open predicate relations. In International Conference on Machine Learning, pages 9966–9977. PMLR.

Alon Talmor và Jonathan Berant. 2018. The web as a knowledge-base for answering complex questions. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 641–651.

Nandan Thakur, Nils Reimers, Andreas Rücklé, Abhishek Srivastava, và Iryna Gurevych. 2021. Beir: A heterogeneous benchmark for zero-shot evaluation of information retrieval models. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).

Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, và Ashish Sabharwal. 2021. Musique: Multi-hop questions via single-hop question composition. arXiv preprint arXiv:2108.00573.

Pat Verga, Haitian Sun, Livio Baldini Soares, và William Weston Cohen. 2021. Adaptable and interpretable neural memory over symbolic knowledge. In Proceedings of NAACL-HLT, pages 3678–3691.

Alex Wang, Kyunghyun Cho, và Mike Lewis. 2020. Asking and answering questions to evaluate the factual consistency of summaries. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5008–5020.

Jinfeng Xiao, Lidan Wang, Franck Dernoncourt, Trung Bui, Tong Sun, và Jiawei Han. 2021. Open-domain question answering with pre-constructed question spaces. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, pages 61–67.

Wenhan Xiong, Xiang Li, Srini Iyer, Jingfei Du, Patrick Lewis, William Yang Wang, Yashar Mehdad, Scott Yih, Sebastian Riedel, Douwe Kiela, et al. 2020. Answering complex open-domain questions with multi-hop dense retrieval. In International Conference on Learning Representations.

Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, và Christopher D Manning. 2018. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2369–2380.

Wen-tau Yih, Matthew Richardson, Christopher Meek, Ming-Wei Chang, và Jina Suh. 2016. The value of semantic parse labeling for knowledge base question answering. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 201–206.

Qingyu Zhou, Nan Yang, Furu Wei, Chuanqi Tan, Hangbo Bao, và Ming Zhou. 2017. Neural question generation from text: A preliminary study. In National CCF Conference on Natural Language Processing and Chinese Computing, pages 662–671. Springer.

--- TRANG 12 ---
A Các Cặp Câu Hỏi Câu Trả Lời như Cơ Sở Tri Thức
Chúng ta có thể xem các cặp QA như một đồ thị tri thức ảo, trong đó mẫu câu hỏi định nghĩa mối quan hệ, thực thể chủ đề trong câu hỏi định nghĩa nút thực thể đầu, và câu trả lời ký hiệu thực thể đuôi. Một ví dụ điển hình được đưa ra trong Hình 5, khả năng tổ hợp như vậy khiến cặp QA có thể kiểm soát và dễ lập luận hơn so với tài liệu.

Hình 5: Các cặp QA có thể được xem như cơ sở tri thức ảo, trong đó câu hỏi có thể biểu diễn các mối quan hệ phức tạp kết nối chủ thể và câu trả lời.

B Tạo Câu Hỏi
Ở đây, chúng tôi sử dụng các bộ ba <Q, A, Document> của bộ dữ liệu SQuAD hiện có (Rajpurkar et al., 2016) để huấn luyện mô hình trích xuất câu trả lời, tạo câu hỏi.

Trích Xuất Câu Trả Lời Cụ thể, mô hình trích xuất câu trả lời của chúng tôi lấy một tài liệu làm đầu vào và huấn luyện một mô hình mã hóa-giải mã để tạo ra một câu trả lời tiềm năng. Chúng tôi sử dụng tìm kiếm beam trên mô hình được huấn luyện để tìm các câu trả lời có khả năng cao nhất trong tài liệu cho trước. Trong thí nghiệm của chúng tôi, mô hình trích xuất câu trả lời được huấn luyện với bộ dữ liệu SQuAD, trong đó tài liệu được đưa làm đầu vào, và các span câu trả lời là các mục tiêu dự đoán.

Tạo Câu Hỏi Đối với mô hình tạo câu hỏi, chúng tôi lấy bộ dữ liệu SQuAD và sử dụng tài liệu + câu trả lời được trích xuất làm đầu vào để tạo ra câu hỏi làm đầu ra. Bước này cũng được thực hiện bởi một mô hình mã hóa-giải mã. chủ yếu được sử dụng cho các vấn đề đọc hiểu, trong đó các câu hỏi được chú thích có tương quan cao với tài liệu chứa rất ít ảo giác. Tuy nhiên, các câu hỏi trong SQuAD (Rajpurkar et al., 2016) có thể được ngữ cảnh hóa hoặc mơ hồ, có thể dẫn đến các vấn đề mơ hồ để làm tổn hại hiệu suất truy xuất. Do đó, chúng tôi thêm lọc câu hỏi để chọn các cặp QA chính xác nhất.

Lọc Câu Hỏi Đối với mô hình lọc câu hỏi, chúng tôi lấy tài liệu + câu hỏi được tạo ra để tạo ra một câu trả lời. Chúng tôi so sánh câu trả lời được dự đoán với câu trả lời ban đầu để xem chúng có khớp với nhau không. Nếu không, cặp QA sẽ được lọc dựa trên sự không nhất quán như vậy. Chúng tôi sử dụng một mô hình đọc hiểu được huấn luyện với SQuAD để dự đoán câu trả lời. Câu trả lời được dự đoán dựa trên tài liệu sẽ khớp với cặp QA ban đầu để quyết định tính nhất quán của nó. Tùy chọn như vậy chạy nhanh hơn nhiều, cung cấp recall cao hơn nhiều nhưng độ chính xác thấp hơn so với việc lọc FiD miền mở được sử dụng trong (Lewis et al., 2021).

Chúng tôi trực quan hóa pipeline tạo câu hỏi được đề cập ở trên trong Hình 6.

Hình 6: Pipeline tạo câu hỏi: Câu trả lời được trích xuất từ các đoạn văn và sau đó câu hỏi được tạo ra có điều kiện trên câu trả lời được ngữ cảnh hóa đó. Quy trình này được sử dụng để tạo ra cả bộ nhớ QA của mô hình chúng tôi và dữ liệu tiền huấn luyện của chúng tôi.

C Nghiên Cứu Loại Bỏ
Chúng tôi thí nghiệm với hai biến thể của bộ nhớ để xem sự khác biệt hiệu suất của chúng.

C.1 Bộ nhớ PAQ
Phiên bản đầu tiên là kho dữ liệu PAQ tiêu chuẩn (Lewis et al., 2021) chứa 65M cặp QA, trong đó những cặp QA này được tạo ra bởi các mô hình được huấn luyện trên NQ (Kwiatkowski et al., 2019) và được lọc thông qua mô hình FiD (Izacard và Grave, 2021) cũng được huấn luyện trên NQ (Kwiatkowski et al., 2019). Bộ nhớ này có độ chính xác cao do quá trình lọc ODQA, tuy nhiên, nó chỉ bao gồm thông tin từ 9M trong số 20M khối đoạn văn được sử dụng trong DPR (Karpukhin et al., 2020).

--- TRANG 13 ---
Bộ nhớ của chúng tôi chứa 30M kho dữ liệu PAQ được loại bỏ trùng lặp, tức là chỉ một câu hỏi tương ứng với một span câu trả lời. Chúng tôi tạo ra 30M cặp QA bổ sung dựa trên 10M tài liệu còn lại từ PAQ (Lewis et al., 2021) và thêm những cặp QA bổ sung này để tạo thành bộ nhớ 60M của chúng tôi để tăng độ bao phủ. Tuy nhiên, vì quy trình lọc của chúng tôi dựa trên đọc hiểu, độ chính xác của các cặp QA thấp hơn so với bộ nhớ PAQ ban đầu.

Bộ Nhớ NQ TriviaQA WebQuestions
PAQ 65M 44.7 48.0 39.4
Của chúng tôi 60M 44.5 53.2 43.0

Bảng 6: Tác động của các bộ nhớ khác nhau đối với hiệu suất bộ dữ liệu QA hạ nguồn.

Như có thể thấy, từ Bảng 6, việc sử dụng bộ nhớ PAQ chính xác nhất nhưng có độ bao phủ thấp từ PAQ (Lewis et al., 2021) mang lại kết quả tệ hơn trên TriviaQA và WebQuestions. Sau khi thêm 30M PAQ bổ sung vào bộ nhớ được tạo ra bởi pipeline của chúng tôi, chúng tôi có thể đạt được cải thiện 4-5% trên hai bộ dữ liệu này trong khi vẫn duy trì hiệu suất của NQ.

C.2 Kích Thước Kho Dữ Liệu Tiền Huấn Luyện
Tiếp theo, chúng tôi điều tra tác động của kích thước kho dữ liệu tiền huấn luyện. Như một baseline, chúng tôi tái sử dụng kho dữ liệu truy vấn-đoạn văn được căn chỉnh được sử dụng để huấn luyện DPR (Karpukhin et al., 2020) mà chúng tôi điều chỉnh cho bối cảnh của chúng tôi bằng cách đơn giản đảo ngược các cặp (120K đoạn văn -> truy xuất câu hỏi). Ngoài ra, chúng tôi thay đổi kích thước của kho dữ liệu tiền huấn luyện được tạo ra (từ 1M đến 20M thể hiện) để xem tác động của nó đối với hiệu suất hạ nguồn cuối cùng của mô hình. Từ Bảng 7, chúng ta có thể thấy rằng kho dữ liệu tiền huấn luyện kích thước nhỏ hơn có thể giảm đáng kể hiệu suất của mô hình, với việc giảm lên đến 5% được thấy trên TriviaQA.

Ví Dụ Tiền Huấn Luyện NQ TQA WQ
120K 42.5 48.2 39.7
1M 42.8 48.8 40.2
5M 43.8 51.5 41.7
10M 44.3 52.1 42.5
20M 44.5 53.2 43.0

Bảng 7: Tác động của kích thước kho dữ liệu tiền huấn luyện đối với hiệu suất EM hạ nguồn cuối cùng. Phần trên được tiền huấn luyện bằng kho dữ liệu DPR-reverse được mô tả trong tiểu mục 5.6 và phần dưới sử dụng các tập con của kho dữ liệu tiền huấn luyện được tạo ra của chúng tôi (tiểu mục 4.1)

Hình 7: Tác động của kích thước bộ nhớ đối với hiệu suất EM QA hạ nguồn.

Kích Thước Bộ Nhớ Cuối cùng, chúng tôi xem xét chúng ta cần bộ nhớ lớn như thế nào để đạt độ chính xác hạ nguồn tối ưu và mô hình hoạt động như thế nào với bộ nhớ nhỏ hơn. Như được hiển thị trong Hình 7, có bộ nhớ nhỏ ít hơn 5M mục không cải thiện so với mô hình không có bộ nhớ gì cả. Do thiếu độ bao phủ, mô hình không nhận được tín hiệu hữu ích từ việc truy xuất và do đó không được khuyến khích sử dụng những truy xuất đó khi đưa ra dự đoán. Tuy nhiên, một khi kích thước bộ nhớ tăng vượt quá 15M, chúng ta quan sát thấy sự gia tăng mạnh trong hiệu suất cuối cùng, cho thấy rằng mô hình đang dần học kết hợp thông tin truy xuất được truy xuất để hỗ trợ dự đoán.

D Huấn Luyện QA Đa Bước
Để huấn luyện mô hình QA đa bước, chúng ta cần có giám sát trung gian cho quá trình tăng cường truy vấn. Ở đây chúng tôi sử dụng một khớp dựa trên chuỗi để dẫn xuất những gì có thể là các câu hỏi trung gian từ một bộ sưu tập các cặp QA được tạo ra trước. Chúng tôi mô tả quá trình khai thác như Hình 8.

--- TRANG 14 ---
Hình 8: Chúng tôi đầu tiên tìm câu hỏi cuối cùng dựa trên việc khớp chuỗi câu trả lời với câu hỏi được tạo ra trước, và sau đó dựa trên đó để truy tìm ngược câu hỏi trung gian.

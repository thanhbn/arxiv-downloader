# 2406.01549.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2406.01549.pdf
# Kích thước tệp: 816825 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Góc nhìn về Nút thắt Thông tin cho Việc Lọc Nhiễu Hiệu quả trên
Sinh tạo Tăng cường Truy xuất
Kun Zhu1*, Xiaocheng Feng1,2*, Xiyuan Du1, Yuxuan Gu1, Weijiang Yu3,
Haotian Wang1,Qianglong Chen4,Zheng Chu1,Jingchang Chen1,Bing Qin1,2†
1Viện Công nghệ Harbin2Phòng thí nghiệm Peng Cheng
3Đại học Sun Yat-sen4Đại học Zhejiang
{kzhu,xcfeng,xydu,yxgu,zchu,jcchen,qinb†}@ir.hit.edu.cn
{weijiangyu8, wanght1998, chenqianglong.ai}@gmail.com
Tóm tắt
Sinh tạo tăng cường truy xuất tích hợp các
khả năng của mô hình ngôn ngữ lớn với thông
tin liên quan được truy xuất từ một kho tài liệu
mở rộng, nhưng gặp thách thức khi đối mặt
với dữ liệu nhiễu thực tế. Một giải pháp gần
đây là huấn luyện một mô-đun lọc để tìm nội
dung liên quan nhưng chỉ đạt được nén nhiễu
dưới tối ưu. Trong bài báo này, chúng tôi đề
xuất giới thiệu lý thuyết nút thắt thông tin vào
sinh tạo tăng cường truy xuất. Phương pháp
của chúng tôi bao gồm việc lọc nhiễu bằng
cách đồng thời tối đa hóa thông tin tương hỗ
giữa nén và đầu ra thực tế, trong khi tối thiểu
hóa thông tin tương hỗ giữa nén và đoạn văn
đã truy xuất. Ngoài ra, chúng tôi suy ra công
thức của nút thắt thông tin để tạo điều kiện
cho việc ứng dụng của nó trong các đánh giá
toàn diện mới, việc lựa chọn dữ liệu tinh chỉnh
có giám sát, và việc xây dựng phần thưởng
học tăng cường. Kết quả thực nghiệm cho thấy
phương pháp của chúng tôi đạt được cải thiện
đáng kể trên các tập dữ liệu trả lời câu hỏi
khác nhau, không chỉ về tính chính xác của
việc sinh tạo câu trả lời mà còn về tính ngắn
gọn với tỷ lệ nén 2,5%.

1 Giới thiệu
Các mô hình ngôn ngữ lớn đại diện cho một tiến bộ
đáng kể trong hiểu và sinh tạo ngôn ngữ tự nhiên,
với khả năng xử lý và tạo ra ngôn ngữ giống con
người ở quy mô và độ phức tạp chưa từng có (Achiam et al., 2023; Touvron et al., 2023; Team et al., 2023). Tuy nhiên,
các mô hình ngôn ngữ lớn có một số nhược điểm,
như ảo giác (Huang et al., 2023) và thiếu kiến
thức cho các lĩnh vực cụ thể hoặc các truy vấn cao
độ chuyên môn (Kandpal et al., 2023). Sinh tạo
tăng cường truy xuất (Lewis et al., 2020) đã thu
hút sự chú ý vì khả năng kết hợp thông tin từ các
nguồn kiến thức bên ngoài trong quá trình suy luận.

*Đóng góp bằng nhau
†Tác giả liên hệ
Các Đoạn văn Đã truy xuấtNén
(A) (B)Nút thắt Thông tin:    
Các Đoạn văn Đã truy xuất : 𝑿Đầu raĐầu ra: 𝒀
Nén: ෨𝑋,  ෨𝑋𝐼𝐵⊆෨𝑋⊆𝑋Nút thắt 
Thông tin ෨𝑋𝐼𝐵
෨𝑋𝐼𝐵=𝑋⋂𝑌

Hình 1: Trong sinh tạo tăng cường truy xuất, các đoạn văn
X được truy xuất để tăng cường việc sinh tạo đầu ra
Y. (A) Các phương pháp lọc nhiễu gần đây thu được
nén ˜X⊆X với mục tiêu log likelihood đối với
đầu ra Y. Mục tiêu nút thắt thông tin của chúng tôi cho phép
phân định chính xác giao điểm ˜XIB=X∩Y.
(B) Nút thắt thông tin nén rõ ràng ˜XIB=
ϕ, khi các đoạn văn đã truy xuất không liên quan đến đầu ra.

giai đoạn suy luận. Bằng cách kết hợp các phương
pháp dựa trên truy xuất với các mô hình sinh tạo,
phương pháp này có thể cải thiện sự liên quan, tính
mạch lạc và độ chính xác thực tế của việc sinh tạo
văn bản (Gao et al., 2023).

Sinh tạo tăng cường truy xuất cũng đưa ra các
vấn đề. Một mặt, hiệu quả của bộ truy xuất có thể
dưới tối ưu trong sử dụng thực tế (Izacard et al.,
2022; Shi et al., 2023b; Cheng et al., 2023; Lin
et al., 2023). Mặt khác, dữ liệu internet thường có
chất lượng thấp, với sự dư thừa và nhiễu. Thực vậy,
nội dung đã truy xuất có thể hoàn toàn không liên
quan đến truy vấn, dẫn đến mô hình tạo ra kết quả
không chính xác (Shi et al., 2023a). Các giải pháp
gần đây để giảm thiểu nhiễu trong bằng chứng truy
xuất thường liên quan đến việc áp dụng một mô-đun
lọc (Liu et al., 2023; Yang et al., 2023a; Xu et al., 2023).
Tuy nhiên, các phương pháp này gặp phải một số
vấn đề: (1) Không thể đảm bảo rằng kết quả lọc
đã chú thích có thể hỗ trợ hiệu quả mô hình sinh
tạo trong việc trả lời câu hỏi chính xác. (2) Khó
khăn trong việc hướng dẫn bộ lọc tránh trả lời khi
đối mặt với bằng chứng truy xuất không hỗ trợ việc
giải quyết câu hỏi. (3) Thiếu sự thích ứng với mức
độ nén của kết quả lọc, cản trở việc đạt được giải
pháp tối ưu về hiệu suất chi phí.

--- TRANG 2 ---
Chúng tôi quan sát thấy rằng các vấn đề trên bắt
nguồn từ các mục tiêu dưới tối ưu. Như thể hiện
trong Hình 1A, giao điểm giữa các đoạn văn đã
truy xuất X và đầu ra Y biểu thị thông tin chính
xác trong X hữu ích cho Y. Bộ lọc nhiễu trích xuất
nén ˜X từ các đoạn văn đã truy xuất X, trong đó
bộ lọc được tối ưu hóa với mục tiêu log likelihood
đối với đầu ra Y. Bộ lọc nhiễu được huấn luyện
với mục tiêu này có thể thu được nén ˜X chứa
giao điểm X∩Y, nhưng không thể nhận ra diện
tích chính xác của nó, có nghĩa là bộ lọc về nguyên
tắc không thể loại bỏ sự can thiệp của nhiễu cho
việc sinh tạo tiếp theo. Do đó, chúng tôi đề xuất
sử dụng lý thuyết nút thắt thông tin (Tishby et al.,
1999) để tối ưu hóa bộ lọc nhiễu từ góc độ toàn
diện, thông qua việc đồng thời tối đa hóa thông tin
hữu ích trong khi tối thiểu hóa nhiễu, từ đó tạo
điều kiện cho việc phân định chính xác giao điểm
˜XIB=X∩Y. Hơn nữa, trong các trường hợp (Hình
1B) mà việc truy xuất không cần thiết cho việc
sinh tạo nội dung hoặc thể hiện hiệu quả hạn chế,
mục tiêu nút thắt thông tin cho phép các bộ lọc
nhiễu nén các đoạn văn đã truy xuất thành rỗng
˜XIB=ϕ.

Cụ thể, chúng tôi xem xét nút thắt thông tin như
một nguyên tắc cho việc tăng cường truy xuất.
Đầu tiên, chúng tôi suy ra lý thuyết công thức của
nút thắt thông tin cho sinh tạo tăng cường truy
xuất, tích hợp các mô hình ngôn ngữ lớn. Sau đó,
chúng tôi giới thiệu nút thắt thông tin như một
thước đo đánh giá toàn diện mới cho việc lọc nhiễu,
đánh giá cả tính ngắn gọn và tính chính xác của
nội dung được nén. Tiếp theo, chúng tôi suy ra
phiên bản nút thắt thông tin của các mục tiêu
tinh chỉnh có giám sát và học tăng cường để huấn
luyện bộ lọc nhiễu.

Chúng tôi tiến hành thực nghiệm trên các tập dữ
liệu trả lời câu hỏi mở: Natural Questions (NQ)
(Kwiatkowski et al., 2019), TRIVIA QA (Joshi
et al., 2017), và một HOTPOT QA đa bước phức
tạp hơn (Yang et al., 2018). Sử dụng LLAMA 2
làm mô hình lọc và sinh tạo, phương pháp của
chúng tôi được chứng minh là hiệu quả so với
các mô hình cơ sở mạnh, bao gồm RANK GPT,
LONG LLMLINGUA và LLAMA 2 trên cả ba
tập dữ liệu. Chúng tôi đạt được tỷ lệ nén đáng
kể 2,5% và cải thiện 3,2 về khớp chính xác câu
trả lời nhiều nhất.

Bài báo của chúng tôi trình bày ba đổi mới chính:
• Chúng tôi là những người đầu tiên, theo hiểu
biết của chúng tôi, giới thiệu lý thuyết nút thắt
thông tin vào sinh tạo tăng cường truy xuất,
minh họa sự tối ưu của việc lọc.
• Chúng tôi đề xuất áp dụng nút thắt thông tin
cho các thước đo đánh giá, mục tiêu tinh chỉnh
có giám sát, và phần thưởng học tăng cường
cho sinh tạo tăng cường truy xuất.
• Kết quả thực nghiệm tiết lộ hiệu quả của
phương pháp chúng tôi về tính chính xác sinh
tạo và tính ngắn gọn nén.

2 Công trình Liên quan
Nút thắt Thông tin Nút thắt Thông tin (IB) (Tishby
et al., 1999; Fischer, 2020) là một khái niệm khá
đơn giản: khi đối mặt với một nhiệm vụ, người ta
nên cố gắng hoàn thành nó bằng cách sử dụng thông
tin tối thiểu. Lý thuyết Nút thắt Thông tin đặc
trưng việc học như một sự cân bằng tinh tế giữa
nén dữ liệu và giữ lại thông tin. Khi áp dụng cho
các nhiệm vụ cụ thể, ý tưởng là trích xuất tất cả
các đặc trưng thông tin cần thiết cho nhiệm vụ trong
khi loại bỏ thông tin dư thừa (Shwartz-Ziv and
LeCun, 2023). Nó đã được áp dụng trong nghiên
cứu về học biểu diễn (Wu et al., 2020; Federici
et al., 2020; Lee et al., 2021), học sâu (Tishby
and Zaslavsky, 2015; Saxe et al., 2019; Kawaguchi
et al., 2023a), phân cụm tài liệu (Slonim and
Tishby, 2000), nhận dạng giọng nói (Hecht et al.,
2009), tóm tắt (West et al., 2019), v.v.

Lọc Nhiễu Sinh tạo tăng cường truy xuất thường
nối các đoạn văn đã truy xuất với các truy vấn của
chúng làm đầu vào của mô hình ngôn ngữ. Tuy
nhiên, điều này có thể vượt quá giới hạn cửa sổ
ngữ cảnh, đưa vào nhiễu và dư thừa bổ sung, và
tăng yêu cầu tài nguyên tính toán, dẫn đến giảm
hiệu suất mô hình.

FLARE (Jiang et al., 2023c) và Self-RAG (Asai
et al., 2023) dành riêng cho việc huấn luyện mô
hình để có khả năng chủ động truy xuất và lọc
nội dung truy xuất một cách tự chủ. REPLUG (Shi
et al., 2023b) cải thiện bộ truy xuất bằng phân kỳ
KL giữa bộ truy xuất và LLM.

Các kỹ thuật hậu xử lý như lọc nhiễu có thể giúp
giảm thiểu những vấn đề này. (Bai et al., 2023)
tập trung vào việc xếp hạng lại các bài viết đã
truy xuất để lọc ra nhiễu. Một số phương pháp
như Selective Context (Li, 2023) và LLMLINGUA
(Jiang et al., 2023a) sử dụng các mô hình ngôn
ngữ nhỏ để đo thông tin tương hỗ prompt hoặc
độ phức tạp, tìm các phần tử có điểm số cao nhất.

Cũng có một số phương pháp sử dụng kỹ thuật
tóm tắt để thiết kế bộ nén (Xu et al.,

--- TRANG 3 ---
Truy xuất
 Bộ Lọc Nhiễu
Sinh tạoKhi nào beryl 
markham bay 
qua đại tây 
dương?1. Beryl Markham (26 Tháng 10 1902 - 3 Tháng 8 
1986) là một phi công người Anh gốc Kenya ...
2. Markham sinh ra ở làng Ashwell, ở 
quận Rutland, Anh ...
3. Beryl Markham nổi tiếng với những 
người lập dị đầy màu sắc. Bà kết hôn ba lần ...
4. Vào tháng 9 năm 1936, Beryl Markham đạt được 
danh tiếng khi trở thành phi công nữ solo đầu tiên ...
......Đoạn vănX
Truy vấnBeryl Markham (26 Tháng 10 1902 - 3 
Tháng 8 1986) là một phi công người Anh 
gốc Kenya, nhà thám hiểm, huấn luyện 
viên ngựa đua và tác giả. Bà là người đầu 
tiên bay solo, không dừng qua Đại Tây 
Dương từ đông sang tây. Vào tháng 9 năm 
1936, Beryl Markham đạt được danh tiếng 
khi trở thành phi công nữ solo đầu tiên 
bay qua Đại Tây Dương từ Anh đến Mỹ.NénNội dung
Tháng 10 1902
Y(A)
(B)Nút thắt Thông tin
Thực tế 
Tháng 9 1936
Vào tháng 9 năm 1936, Beryl Markham 
đạt được danh tiếng khi trở thành phi 
công nữ solo đầu tiên bay qua Đại Tây 
Dương từ Anh đến Mỹ.Oracle
(C)Lựa chọn Dữ liệu SFT Phần thưởng Học Tăng cường
Nén 1 
Nén 2
Nén 3
...
Nén n-4.23-4.17
-4.42
-4.15Y Thực tế 
Đoạn vănX
Các Ứng viên Lọc
Bộ Lọc Nhiễu
Các Bộ Dữ liệu SFT GiảPseudo
Y Thực tế Đoạn vănX
Nén
Phần thưởng IB:
Q
Truy vấnQ
Truy vấnQ
Ưu tiên DPO:

Hình 2: Tổng quan về phương pháp của chúng tôi. (A) Sinh tạo tăng cường truy xuất truyền thống với lọc nhiễu. Mặc dù
nén chứa thông tin liên quan, nhiễu không thể tránh khỏi tiếp tục làm gián đoạn các quá trình sinh tạo tiếp theo. (B) Lý
thuyết nút thắt thông tin cung cấp một mục tiêu cho nén oracle ˜X=X∩Y thông qua việc loại bỏ ảnh hưởng của nhiễu
ở mức độ lớn nhất, minI(˜X;X|Y;Q). (C) Chúng tôi suy ra công thức để áp dụng lý thuyết nút thắt thông tin cho sinh
tạo tăng cường truy xuất, có thể được sử dụng để lựa chọn tập dữ liệu tinh chỉnh có giám sát và xây dựng phần thưởng
học tăng cường.

2023; Wang et al., 2023). TCRA-LLM (Liu et al.,
2023) và LONGLLMLINGUA (Jiang et al., 2023b)
kết hợp các kỹ thuật tóm tắt và nén ngữ nghĩa.
PRCA (Yang et al., 2023b) cũng tích hợp các thuật
toán học tăng cường trong việc huấn luyện mô hình.
Tuy nhiên, các phương pháp nén này không có
đánh giá thống nhất về kết quả nén. RECOMP (Xu
et al., 2023) đạt được tỷ lệ nén 6%, nhưng điều
này đi kèm với chi phí hiệu suất bị suy giảm.
Phương pháp của chúng tôi là tìm sự cân bằng
tối ưu giữa tỷ lệ nén và hiệu suất với lý thuyết
nút thắt thông tin.

3 Phương pháp
Trong phần này, đầu tiên chúng tôi giới thiệu nền
tảng của nút thắt thông tin (§3.1), sau đó chuyển
đổi nút thắt thông tin thành các dạng cho bộ lọc
nhiễu của sinh tạo tăng cường truy xuất (§3.2).
Tiếp theo, chúng tôi cung cấp chi tiết về các mục
tiêu nút thắt thông tin cho sinh tạo tăng cường
truy xuất (§3.3).

3.1 Sơ bộ
Nguyên tắc nút thắt thông tin (Tishby et al., 1999)
đã là một khái niệm tuyệt vời trong việc tìm nén
˜X cho tín hiệu X bảo tồn thông tin tối đa liên
quan đến tín hiệu Y. Cho một phân phối xác suất
chung p(X, Y) giữa biến ngẫu nhiên X và biến
liên quan quan sát được Y (với tập hỗ trợ x∈X
và y∈Y), lượng thông tin về Y trong biểu diễn
nén ˜X (˜x∈˜X) được cho bởi thông tin tương hỗ:

I(˜X;Y) =∫_{˜X}∫_Y p(˜x, y) log(p(˜x, y))/(p(˜x)p(y))d˜xdy,
(1)

trong đó I(˜X;Y)≤I(X;Y) vì dữ liệu nén không
thể truyền tải nhiều thông tin hơn dữ liệu gốc.

Nút thắt thông tin được thu được thông qua
minL_{IB}=I(˜X;X)−βI(˜X;Y), (2)

trong đó β là thừa số Lagrange cho sự đánh đổi
giữa bảo tồn thông tin có ý nghĩa và nén ở các
độ phân giải khác nhau.

3.2 Lọc Nhiễu
Sinh tạo tăng cường truy xuất liên quan đến việc
sinh tạo nội dung có điều kiện trên các truy vấn
đầu vào q∈Q, trong đó các đoạn văn liên quan
x∈X được truy xuất để thúc đẩy việc sinh tạo
nội dung. Như minh họa trong Hình 2A, các
phương pháp lọc nhiễu gần đây cho sinh tạo tăng
cường truy xuất học cách nén các đoạn văn đã
truy xuất ˜x∈˜X⊆X cho các mô hình ngôn ngữ
lớn

--- TRANG 4 ---
với một mục tiêu log likelihood -logp_{LM}(y|[q,˜x])
đối với đầu ra thực tế y∈Y (Liu et al., 2023; Yang
et al., 2023a; Xu et al., 2023; Wang et al., 2023),
đây là các trường hợp đặc biệt của thông tin tương
hỗ có điều kiện I(˜X, Y|Q) và vẫn không thể tránh
thông tin không liên quan.

Bây giờ chúng tôi giới thiệu phương pháp nút thắt
thông tin cho sinh tạo tăng cường truy xuất và
chúng tôi suy ra nút thắt thông tin giữa các đoạn
văn đã truy xuất X và đầu ra thực tế Y có điều
kiện trên các truy vấn Q cho Phương trình 2. Như
được thể hiện trong Hình 2B, bộ lọc nhiễu được
yêu cầu đồng thời tối đa hóa thông tin tương hỗ
của nén với đầu ra thực tế trong khi tối thiểu hóa
thông tin tương hỗ với các đoạn văn đã truy xuất:

minL_{IB}=I(˜X, X|Q)|_{tính ngắn gọn}−β I(˜X;Y|Q)|_{tính chính xác}.(3)

Số hạng đầu I(˜X;X|Q) không chỉ phục vụ để
tăng cường hiệu quả, đây là một ứng dụng phổ
biến, mà còn để thúc đẩy tính ngắn gọn bằng cách
tối thiểu hóa việc bao gồm thông tin không liên
quan. Khi thông tin đã lọc trở nên ngày càng chính
xác, các mô hình ngôn ngữ có thể giảm tài nguyên
tính toán được phân bổ cho việc trích xuất đầu
vào, từ đó tăng cường khả năng tập trung vào việc
tạo ra nội dung chất lượng cao hơn. Đáng chú ý
là số hạng này đảm bảo rằng thông tin đã lọc sẽ
được hiển thị null khi nội dung đã truy xuất hoàn
toàn không liên quan đến đầu ra.

Sau đó, chúng tôi cung cấp chi tiết của từng số
hạng trong nút thắt thông tin. Tính ngắn gọn là:

I(˜X;X|Q) = 
E_q∫ p(˜x, x|q) log(p(˜x, x|q))/(p(˜x|q)p(x|q))d˜xdx
=E_q∫ p(x|q)p(˜x|x, q)
log(p(x|˜x, q))/(p(x|q))d˜xdx
≤E_q∫ p(x|q) log(∫p(x|˜x, q)p(˜x|x, q)d˜x)/(p(x|q))dx
=-E_q D_{KL}[p(x|q)||E_{˜x∼p(˜x|x,q)}p(x|˜x, q)],
(4)

trong đó chúng tôi có được cận trên của tính ngắn
gọn dựa trên bất đẳng thức Jensen. Do đó, I(˜X;X, Q)
có thể được chuyển đổi thành dạng phân kỳ Kullback–
Leibler giữa phân phối xác suất truy xuất p(x|q)
và kỳ vọng của xác suất khôi phục các đoạn văn
đã truy xuất từ nén p(x|˜x, q), trong đó ˜x được
yêu cầu tích hợp trên không gian biểu diễn của
bộ lọc nhiễu p(˜x|x, q).

Trong tình huống của các bộ truy xuất ngoại tuyến,
trong đó các đoạn văn đã truy xuất và truy vấn
được lấy mẫu chung từ các tập dữ liệu huấn luyện
{(q, x, y)}, p(x|q) trở thành một số không đổi và
chúng ta có thể đơn giản hóa:

minI(˜X;X|Q)≃minE_{(q,x,˜x)} -logp(x|˜x, q). (5)

Do đó, trong các trường hợp mà việc huấn luyện
bộ truy xuất cùng nhau không cần thiết, việc tối
thiểu hóa thông tin tương hỗ có điều kiện I(˜X;X|Q)
có thể được làm sáng tỏ như quá trình lọc chọn
lọc thông tin đến mức độ không thể tái tạo nội
dung gốc, bất kể sức mạnh của các mô hình ngôn
ngữ sinh tạo được sử dụng.

Tiếp theo, tính chính xác được suy ra như:

I(˜X;Y|Q) =H(Y|Q)−H(Y|X, Q)
=-∫ p(y, q) logp(y|q)dydq−H(Y|X, Q)
(6)

trong đó số hạng đầu E_{(q,y)}[-logp(y|q)] được
xem xét như một hằng số độc lập với bộ lọc nhiễu.
Chúng ta có thể bỏ qua số hạng này và đơn giản
hóa như:

I(˜X;Y|Q)≃ −H(Y|˜X, Q)
=∫ p(y,˜x, q) logp(y|˜x, q)dyd˜xdq
=E_{(q,˜x,y)}[logp(y|˜x, q)]. (7)

Khi các mô hình ngôn ngữ sinh tạo được cố định,
các cặp câu hỏi-trả lời {(q, y)} được lấy mẫu từ
các tập dữ liệu và ˜x được thu được trước với bộ
lọc nhiễu. Do đó, việc tối đa hóa I(˜X;Y|Q) xấp
xỉ việc tối đa hóa log likelihood logp(y|˜x, q),
được giải thích như quá trình chọn lọc giữ lại
càng nhiều thông tin hữu ích càng tốt để cho phép
mô hình ngôn ngữ sinh tạo đầu ra mục tiêu.

Bên cạnh đó, các nghiên cứu gần đây về nút thắt
thông tin (Fischer, 2020; Federici et al., 2020; Lee
et al., 2021; Kawaguchi et al., 2023b) đề xuất thay
thế I(X;˜X) bằng I(X;˜X|Y), vì I(X;˜X) không
thể bằng không trong khi duy trì thông tin liên
quan đến mục tiêu. Do đó, chúng tôi làm theo
Federici et al. (2020) và phân tích I(˜X;X|Q)
thành hai thành phần bằng cách sử dụng quy tắc
chuỗi như:

I(˜X;X|Q) =I(˜X;X|Y;Q) +I(˜X;Y|Q). (8)

Cuối cùng, nút thắt thông tin của chúng tôi cho
việc lọc nhiễu trong sinh tạo tăng cường truy xuất là:

L_{IB}=I(˜X;X|Y;Q)−(β−1)I(˜X;Y|Q)
≃E_{(q,x,˜x,y)}[-logp(x|˜x, q, y)]
−(β−1)E_{(q,˜x,y)}[logp(y|˜x, q)], (9)

--- TRANG 5 ---
trong đó thừa số Lagrange β−1>0.

3.3 Nút thắt Thông tin như một Nguyên tắc
Nút thắt thông tin không chỉ đại diện cho một
phương pháp tiếp cận, mà là một nguyên tắc cơ
bản được áp dụng trong sinh tạo tăng cường truy
xuất. Trong phần này, chúng tôi sẽ phác thảo ba
ứng dụng khác biệt của nút thắt thông tin, bao
gồm việc thiết lập thước đo đánh giá cho việc lọc
nhiễu, việc tạo ra các tập dữ liệu huấn luyện tinh
chỉnh có giám sát (SFT), và việc xây dựng các
hàm phần thưởng trong học tăng cường.

3.3.1 Thước đo Đánh giá
Trước khi mô tả phương pháp huấn luyện bộ lọc
nhiễu, việc thiết lập tiêu chí đánh giá hiệu quả
của kết quả lọc là cần thiết, trong đó nút thắt
thông tin đóng vai trò như một thước đo đánh
giá quan trọng. Cho {(q, x, y)} từ tập dữ liệu
và nén được tạo ra bởi bộ lọc nhiễu p(˜x|x, q),
dựa trên Phương trình 9, chúng tôi định nghĩa
điểm số IB như:

IB(˜x) =p_{LM}(x|[q,˜x, y])−α p_{LM}(y|[q,˜x]), (10)

trong đó các mô hình ngôn ngữ lớn được sử dụng
để ước tính các phân phối xác suất, với đầu vào
của mô hình ngôn ngữ bao gồm các biến có điều
kiện được nối. Ngoài ra, chúng tôi cân bằng độ
lớn của các giá trị bằng cách áp dụng logarit vào
siêu tham số α. Phạm vi của điểm IBscore là [-9α,1]
và IB nhỏ hơn có nghĩa là hiệu suất lọc tốt hơn.

3.3.2 Tinh chỉnh Có giám sát
Việc huấn luyện bộ lọc nhiễu từ đầu là thách thức
vì không có nén thực tế của các đoạn văn đã truy
xuất. Mặc dù Phương trình 9 cung cấp một cách
để đạt được nén oracle, chúng ta phải tìm kiếm
˜x tối ưu từ tất cả các chuỗi con tiềm năng của
đoạn văn đã truy xuất x, tức là tính toán tích phân
của ˜x trên không gian ngôn ngữ:

E_{(q,x,y)}∫ IB(˜x)p(˜x|x, q)d˜x. (11)

Tích phân rõ ràng là không thể giải được, nhưng
chúng ta có thể ước tính nó với chiến lược lấy
mẫu Monte Carlo. Chúng tôi sử dụng các phương
pháp nén hoặc lọc hiện có khác nhau {p_{θ_1}(˜x|x, q), . . . , p_{θ_n}(˜x|x, q)}
để tạo ra các đầu ra nén ứng viên, như một phép
xấp xỉ của việc lấy mẫu từ p(˜x|x, q), và ứng viên
có điểm số IB tốt nhất được coi là ˜x giả. Như
minh họa trong phần bên trái của Hình 2C, chúng
tôi thu thập ˜x giả trên các tập dữ liệu sinh tạo
tăng cường truy xuất và xây dựng các bộ ba {(q, x,˜x)}
làm dữ liệu huấn luyện cho việc học có giám sát
của bộ lọc nhiễu p_θ(˜x|x, q). Ngoài ra, vì bộ
lọc nhiễu được yêu cầu sở hữu khả năng hiểu đầu
vào và tuân thủ hướng dẫn, chúng tôi chọn các
mô hình ngôn ngữ đã được huấn luyện trước làm
xương sống và tinh chỉnh mô hình thành bộ lọc
nhiễu bạc. Mục tiêu tối ưu hóa là negative log
likelihood thường được sử dụng L_{SFT}=-Σ_{(q,x,˜x)}logp_θ(˜x|x, q).

Đáng chú ý là phương pháp của chúng tôi thể hiện
khả năng mạnh mẽ để xử lý tình huống khi các
đoạn văn đã truy xuất X không liên quan đến đầu
ra thực tế Y thông qua việc tối thiểu hóa I(˜X;X|Y;Q)→0,
thường làm cho ˜x→ϕ. Mặc dù mục tiêu nút thắt
thông tin của chúng tôi về bản chất bao gồm các
mục tiêu tối ưu hóa để giải quyết các vấn đề liên
quan đến thông tin chất lượng thấp, như câu hỏi
không cần truy xuất, truy xuất nhiễu, và nén mất
mát cao, chúng tôi thể hiện việc kết hợp một cờ
dự đoán bổ sung [IS_DISCARD] để xác định sự
cần thiết của việc loại bỏ kết quả lọc hiện tại.
Khi IB(ϕ)<IB(˜x), có nghĩa là nén ứng viên chứa
quá ít thông tin hữu ích để hỗ trợ trong việc sinh
tạo mô hình, chúng tôi sẽ đặt [IS_DISCARD]=True
và ngược lại.

3.3.3 Học Tăng cường
Thông qua việc chỉ tinh chỉnh có giám sát, hiệu
quả của việc lọc nhiễu là dưới tối ưu, với hiệu
suất bị hạn chế bởi chất lượng của các ứng viên
nén. Vẽ song song với học tăng cường từ phản
hồi con người (RLHF, Ouyang et al. (2022)) điều
chỉnh các mô hình ngôn ngữ lớn với sở thích con
người, chúng tôi đề xuất tận dụng học tăng cường
để tăng cường bộ lọc nhiễu bằng cách kết hợp
hướng dẫn từ nút thắt thông tin. Phương pháp
của chúng tôi liên quan đến việc sử dụng tối ưu
hóa sở thích trực tiếp (DPO, Rafailov et al. (2023)),
một phiên bản gần đây của RLHF cung cấp sự
dễ dàng triển khai và tính ổn định mạnh mẽ.
Chúng tôi định nghĩa xác suất sở thích như:

p^*(˜x_1>˜x_2|q, x, y) =σ(IB(˜x_2)−IB(˜x_1)), (12)

trong đó bộ lọc nhiễu p_θ(˜x|x, q) ban đầu là
chính sách π_{ref}(˜x|x, q) cần tạo ra hai mẫu
nén ˜x_1 và ˜x_2 trước. Sau đó, tập dữ liệu ngoại
tuyến của sở thích D={q, x,˜x_w,˜x_l} được xây
dựng, trong đó các mẫu (˜x_w thắng và ˜x_l thua)
được gắn nhãn tự động với sở thích nút thắt thông
tin p^*(˜x_1>˜x_2|q, x, y). Do đó, mục tiêu cho
chính sách lọc nhiễu π_θ(˜x|x, q),

--- TRANG 6 ---
được khởi tạo với π_{ref}(˜x|x, q), như sau:

L_{DPO}=
-E_{(q,x,˜x_w,˜x_l)∼D}[
logσ(
γlogπ_θ(˜x_w|x, q)/π_{ref}(˜x_w|x, q)
−γlogπ_θ(˜x_l|x, q)/π_{ref}(˜x_l|x, q)
)], (13)

trong đó γ là siêu tham số kiểm soát độ lệch từ
chính sách tham chiếu cơ sở π_{ref}(˜x|x, q).

Như thể hiện trong phần bên phải của Hình 2C,
nút thắt thông tin của chúng tôi cũng có thể cung
cấp hàm phần thưởng R_{IB}(˜x) =−IB(˜x) của
các chính sách trực tuyến.

4 Thực nghiệm
4.1 Cài đặt Thực nghiệm
Tập dữ liệu và Kho Truy xuất Chúng tôi tiến hành
thực nghiệm trên ba điểm chuẩn trả lời câu hỏi:
Natural Questions (NQ) (Kwiatkowski et al., 2019),
TRIVIA QA (Joshi et al., 2017) và HOTPOT QA
(Yang et al., 2018), với kết quả được báo cáo trên
các tập phát triển. Chúng tôi sử dụng Dense Passage
Retriever đối nghịch (DPR) (Karpukhin et al., 2020)
để truy xuất top 5 đoạn văn từ tất cả các đoạn văn
Wikipedia cho tất cả các tập dữ liệu. Các bài viết
được cắt thành các tài liệu không chồng lấp 100 từ.

Chi tiết Triển khai Chúng tôi sử dụng LLAMA 2
(Touvron et al., 2023) làm kiến trúc xương sống
của mô hình ngôn ngữ lớn. Chúng tôi tinh chỉnh
phiên bản mô hình 7B với LORA (Hu et al., 2021)
cho việc lọc nhiễu, trong đó bộ tối ưu là ADAMW
với tốc độ học 5e-5 và kích thước batch 32. Phiên
bản 13B cũng được sử dụng làm bộ sinh tạo mà
không có bất kỳ điều chỉnh nào.

Loại tập dữ liệu Số lượng ví dụ % Recall
Top 5 Top 1
NQ Huấn luyện 106926 36.5 18.9
Phát triển 2564 35.0 17.9
TRIVIA QA Huấn luyện 87622 68.3 49.1
Phát triển 11313 68.5 49.4
HOTPOT QA Huấn luyện 90447 51.5 35.1
Phát triển 7405 45.0 28.4

Bảng 2: Tổng quan về số lượng dữ liệu được sử dụng
cho huấn luyện và kiểm tra trên ba tập dữ liệu điểm
chuẩn và recall của top 5 và top 1 đoạn văn đã truy
xuất bằng DPR.

Cho tinh chỉnh có giám sát, chúng tôi đặt hệ số
của điểm số IB α= 10 để cân bằng việc nén.

Bên cạnh đó, các ứng viên lọc được lấy mẫu từ
bốn phương pháp khác nhau xuất phát từ tóm tắt
trích xuất truyền thống, với chi tiết trong §5.1.
Cho học tăng cường, chúng tôi sử dụng DPO và
siêu tham số γ= 0.1. Chiến lược giải mã là lấy
mẫu top-p với p= 0.9.

Thước đo Các nhiệm vụ trả lời câu hỏi thường
sử dụng Exact Match (EM) và F1 làm thước đo
đánh giá, trong khi mỗi cái có những hạn chế
riêng. Ví dụ, thước đo EM yêu cầu sự sắp xếp
chính xác giữa nội dung được tạo ra và câu trả
lời, thể hiện tiêu chí quá nghiêm ngặt thiếu tương
thích ngữ nghĩa. Bên cạnh đó, điểm F1, hoạt động
như một thước đo uni-gram, dễ bị lừa bởi các từ
phủ định như "không". Điểm số IB của chúng tôi,
ngược lại, là một thước đo đánh giá toàn diện và
linh hoạt có khả năng đánh giá tính ngắn gọn và
tính chính xác của nội dung được tạo ra ở cấp độ
ngữ nghĩa so với câu trả lời thực tế, tận dụng khả
năng của các mô hình ngôn ngữ lớn tiên tiến.
Ngoài ra, để đánh giá các biến đổi hiệu suất do
việc tăng cường truy xuất chi tiết, chúng tôi sử
dụng tỷ lệ flip của EM để đánh giá mức độ mà
các phản hồi được tạo ra bị ảnh hưởng bởi ngữ
cảnh đã truy xuất. True-Flip-Rate (TFR) và
False-Flip-Rate (FFR) được định nghĩa như sau:

TFR=p(EM p_{LM}(y|[q,x])= 0|EM p_{LM}(y|q)= 1)
FFR=p(EM p_{LM}(y|[q,x])= 1|EM p_{LM}(y|q)= 0),

trong đó TFR đo mức độ nhiễu được đưa vào bởi
thông tin đã truy xuất trong khi FFR kiểm tra lượng
lợi ích từ việc tăng cường truy xuất.

Đường cơ sở Đầu tiên chúng tôi xem xét kết quả
của bộ sinh tạo (LLAMA 2-13B) mà không tăng
cường truy xuất và với top-1 hoặc top-5 đoạn văn
đã truy xuất. Tiếp theo chúng tôi bao gồm hai tập
phương pháp lọc, xếp hạng lại sử dụng RANK GPT
(Sun et al., 2023) được chưng cất từ ChatGPT, và
nén prompt với LONGLLMLINGUA (Jiang et al.,
2023b). Chúng tôi cũng thử nghiệm với mô hình
cơ sở LLAMA-7B thực hiện tóm tắt từ top-5 đoạn văn.

4.2 Trả lời Câu hỏi Mở
Bảng 1 trình bày kết quả thực nghiệm trên các
tập dữ liệu NQ và TRIVIA QA. Ban đầu, chúng
tôi chứng minh hiệu suất của bộ sinh tạo (LLAMA
2 13B) mà không truy xuất, trong đó điểm EM
thấp ngụ ý hạn chế của các mô hình ngôn ngữ
lớn đối mặt với nhiệm vụ trả lời câu hỏi mở.
Khi việc sinh tạo được tăng cường trực tiếp với
các tài liệu đã truy xuất, kết quả thậm chí còn
tệ hơn với sự sụt giảm 9.2 điểm EM trên TRIVIA
QA nhiều nhất, phản ánh sự hiện diện của một
lượng lớn nhiễu trong nội dung đã truy xuất và
tính dễ tổn thương của bộ sinh tạo đối với sự can
thiệp nhiễu. Bên cạnh đó, TFR tiết lộ rằng nhiễu
trong các đoạn văn đã truy xuất sẽ khiến hơn 50%
số câu trả lời được tạo ra sai mà có thể đã được
trả lời đúng trên tập dữ liệu NQ.

Các bộ lọc nhiễu trích xuất bao gồm RANKGPT
và LONG LLMLINGUA có thể bù đắp cho các
mất mát hiệu suất trong điểm EM, F1, và IB do
truy xuất gây ra, thông qua việc lọc nhiễu. Tuy
nhiên, chúng khó có thể vượt trội hơn bộ sinh tạo
không truy xuất, vì chúng cho phép bộ sinh tạo
trả lời nhiều câu hỏi đúng hơn với 10.3 FFR,
nhưng cũng mắc nhiều lỗi hơn với 51.0 TFR.
Cũng như một phương pháp nén trích xuất, phương
pháp của chúng tôi cải thiện đáng kể điểm EM
trên NQ và TRIVIA QA lần lượt là 5.3 và 2.2,
so với bộ sinh tạo không truy xuất. Đối với điểm
F1, những tiến bộ lần lượt là 4.5 và 1.5. Các mục
tiêu nút thắt thông tin của chúng tôi có thể đạt
được cải thiện FFR đáng kể trong khi tối thiểu
hóa sự suy giảm hiệu suất TFR. Ví dụ, trên tập
dữ liệu NQ, chúng tôi hiệu quả tối thiểu hóa TFR
(51.0→17.6) để giảm thiểu sự can thiệp nhiễu do
truy xuất gây ra, và duy trì FFR tương đương
(10.3→10.2) để tối thiểu hóa mất mát thông tin
hiệu quả càng nhiều càng tốt. Đáng chú ý là tỷ
lệ nén của chúng tôi đạt được 2.5% và 2.6% cho
các tập dữ liệu này, giảm đáng kể nhiễu không
liên quan và chi phí tính toán. So với LLAMA 2-7B,
một mô hình ngôn ngữ lớn với kiến thức được lưu
trữ trong các tham số trong giai đoạn huấn luyện
trước mà chúng tôi coi đó là một phương pháp
tóm tắt trừu tượng mạnh mẽ, phương pháp của
chúng tôi vẫn vượt trội hơn nó trong điểm EM và F1.

Ngoài ra, thước đo nút thắt thông tin IB được
đề xuất của chúng tôi đánh giá các mô hình này
từ góc độ toàn diện, tính đến cả tính ngắn gọn
và tính chính xác của việc nén. Điểm IB của không
truy xuất là điểm cơ bản cho nén null ˜X=ϕ,
phản ánh khả năng của mô hình ngôn ngữ p_{LM}(·).
Điểm IB thường phù hợp với hiệu suất của mô
hình, trong đó các mô hình thể hiện tỷ lệ nén thấp
hơn và độ chính xác giảm có xu hướng mang lại
điểm số thấp hơn. Phương pháp của chúng tôi,
với điểm IB tốt nhất, đạt được tối ưu Pareto giữa
tỷ lệ nén và hiệu suất. Chúng tôi cung cấp nghiên
cứu trường hợp trong Phụ lục C.

--- TRANG 7 ---
Phương pháp NQ TRIVIA QA
từ EM↑TFR↓FFR↑F1↑IB↓từ EM↑TFR↓FFR↑F1↑IB↓
Không Truy xuất
LLAMA 2-13B 0 16.2 - - 51.4 -4.46 0 49.9 - - 76.7 -4.68
Truy xuất mà không Lọc Nhiễu
Tài liệu Top 1 103.6 13.4 56.8 7.7 51.0 -4.29 102.9 46.5 28.3 21.4 75.7 -4.67
Tài liệu Top 5 517.6 14.7 55.8 9.0 48.4 -4.21 514.6 40.7 39.6 21.1 70.9 -4.39
Truy xuất với Phương pháp Lọc
RANK GPT 103.6 16.5 51.0 10.3 53.7 -4.47 102.8 47.5 28.3 23.3 76.1 -4.70
LONG LLMLINGUA 141.1 14.7 47.3 7.4 49.9 -4.27 137.2 49.8 24.4 23.9 76.2 -4.61
LLAMA 2-7B 37.3 18.3 43.7 11.0 52.2 -4.53 30.0 51.4 23.1 26.0 76.3 -4.76
Của chúng tôi w/SFT 10.3 20.6 17.6 8.7 54.9 -4.60 11.6 50.3 14.6 15.2 77.4 -4.79
Của chúng tôi w/SFTw/DPO 12.7 21.5 20.3 10.2 55.9 -4.78 13.3 52.1 12.5 16.8 78.2 -4.88

Bảng 1: Kết quả QA mở với LLAMA 2-13B làm bộ sinh tạo. Chúng tôi báo cáo số từ của bằng chứng truy xuất đã
nén, phản ánh tỷ lệ nén. Các thước đo đánh giá khác được nêu trong §4.1.

4.3 Trả lời Câu hỏi Đa bước
Các mô hình lọc gặp phải những trở ngại đáng
kể hơn khi xử lý các vấn đề đa bước, vì việc giải
quyết những vấn đề này không chỉ yêu cầu thông
tin phụ trợ mà còn nhiều vòng lý luận và phân tích.
Như được thể hiện trong Bảng 3, kết quả thu được
được cải thiện một cách cận biên so với những
kết quả đạt được chỉ thông qua huấn luyện có
giám sát.

Phương pháp HOTPOT QA
từ EM TFR FFR F1 IB
LLAMA 2-13B 0 18.5 - - 53.6 -4.21
Tài liệu Top 1 102.9 23.2 31.1 12.8 57.3 -4.36
Tài liệu Top 5 514.7 18.3 50.7 11.2 50.2 -4.10
RANK GPT 102.9 23.5 34.1 13.9 57.2 -4.39
LONG LLMLINGUA 137.7 23.9 32.7 14.0 56.4 -4.19
LLAMA 2 27.7 25.9 31.1 16.2 57.8 -4.44
Của chúng tôi 13.2 26.1 22.1 14.3 58.3 -4.47

Bảng 3: Kết quả trên tập dữ liệu HOTPOT QA đa bước.

4.4 Nghiên cứu Loại bỏ cho Tính ngắn gọn
Chúng tôi sử dụng các thí nghiệm loại bỏ để thể
hiện tầm quan trọng của số hạng tính ngắn gọn
trong lý thuyết nút thắt thông tin trên NQ. Như
thể hiện trong Bảng 4, việc tích hợp phương pháp
nút thắt thông tin kết hợp cả tính ngắn gọn và
tính chính xác dẫn đến kết quả vượt trội so với
việc chỉ sử dụng tính chính xác. Kết quả lọc từ
phương pháp trước ngắn gọn hơn và chất lượng
cao hơn.

từ EM↑TFR↓FFR↑F1↑IB↓
LLAMA 2 - 16.2 - - 51.4 -4.46
Top1 103.6 13.4 56.8 7.7 51.0 -4.29
Top5 517.6 14.7 55.8 9.0 48.4 -4.21
I(˜X;Y|Q) 13.1 19.2 24.9 8.5 54.6 -4.58
IB 12.7 21.5 20.3 10.2 55.9 -4.78

Bảng 4: Nghiên cứu loại bỏ cho tính ngắn gọn trên NQ.

5 Phân tích
5.1 Lựa chọn Bạc với IB
Để trực quan chứng minh rằng việc áp dụng nút
thắt thông tin để lựa chọn dữ liệu huấn luyện có
thể tăng cường cận trên, chúng tôi tiến hành thí
nghiệm trên các tập xác thực của NQ và HOTPOT
QA. Bảng 5 liệt kê hai phương pháp lọc cơ bản:
tìm kiếm chính xác và tìm kiếm tham lam. Việc
áp dụng lựa chọn IB không giới hạn chỉ ở hai
phương pháp lọc và nó có thể được tổng quát hóa
cho các chiến lược khai thác bạc hướng dẫn câu
trả lời khác, như chiến lược khai thác evidentiality
leave-one-out (Asai et al., 2022) và CXMI (Wang
et al., 2023). Phương pháp của chúng tôi không
cố định vào việc tìm giải pháp tối ưu trong các
giai đoạn ban đầu, mà tập trung vào việc tiếp cận
dần mô hình lọc tối ưu thông qua huấn luyện lặp.
Ở đây chúng tôi chọn hai phương pháp dễ nhất,
có thể giảm đáng kể chi phí tính toán trong việc
xây dựng dữ liệu huấn luyện.

Mục tiêu của tìm kiếm chính xác là tìm các đoạn
văn hoặc câu chứa câu trả lời thực tế. Tìm kiếm
tham lam (Nallapati et al., 2017) là một trong
những phương pháp heuristic phổ biến nhất được
sử dụng trong tóm tắt trích xuất. Thuật toán này
trích xuất nhãn oracle với điểm ROUGE (Lin, 2004)
cao nhất so với tóm tắt được chú thích bởi con người.
Chúng tôi xem xét hai tóm tắt bạc, một cái nối
truy vấn và câu trả lời, và cái kia chỉ tập trung
vào bản thân câu trả lời. Cái trước có thể bao
quát nhiều thông tin hơn, trong khi cái sau tập
trung nhiều hơn vào bản thân câu trả lời. Đặc
biệt, câu trả lời ở trạng thái trung gian, các sự
kiện hỗ trợ, được kết hợp cho các câu hỏi đa bước.

Bằng cách sử dụng nút thắt thông tin để lựa chọn
trong số bốn kết quả lọc, kết quả thu được vượt
trội hơn bất kỳ cái nào trong số chúng, tiết lộ
rằng các phương pháp chú thích đơn giản hiện
có chỉ mang lại các giải pháp còn cách xa tối ưu.

Tập dữ liệu Ứng viên Lọc HASANS EM F1 Từ IB I(˜X;X|Y;Q)
NQ Chính xác Cấp Đoạn văn 31.4 21.2 53.6 78.1 -4.74 0.597
Cấp Câu 33.5 23.8 55.4 28.4 -4.81 0.561
Tham lam Truy vấn & Câu trả lời 26.6 19 52.1 26.2 -4.64 0.562
Câu trả lời 34.2 24.3 56.8 18.2 -4.91 0.556
Lựa chọn IB 35.7 26.8 58.6 31.6 -5.10 0.563
HotpotQA Chính xác Cấp Đoạn văn 38.3 26.3 55.4 120.0 -4.55 0.679
Cấp Câu 35.4 27.8 59.3 41.2 -4.63 0.619
Tham lam Truy vấn & Sự kiện Hỗ trợ & Câu trả lời 31.4 25.8 58.9 32.5 -4.51 0.614
Sự kiện Hỗ trợ & Câu trả lời 33.1 26.9 59.5 14.8 -4.63 0.604
Lựa chọn IB 38.3 30.9 61.9 40.4 -4.88 0.619

Bảng 5: Chúng tôi xác thực hiệu quả của nút thắt thông tin trong việc tìm dữ liệu đã lọc oracle trên các tập phát
triển của NQ và TriviaQA. HASANS biểu thị độ chính xác của kết quả đã lọc có câu trả lời.

5.2 Độ dài Tóm tắt và Tính ngắn gọn
Do việc áp dụng phương pháp lọc trích xuất, nội
dung được giữ lại sau khi lọc có nguồn gốc từ
văn bản gốc. Điều này dẫn đến giả thuyết rằng
có thể có mối tương quan giữa tỷ lệ nén và thông
tin tương hỗ tính ngắn gọn I(˜X;X|Y;Q). Chúng
tôi xác minh mối quan hệ giữa tỷ lệ nén và thông
tin tương hỗ trên NQ và HOTPOT QA với một
thí nghiệm đồ chơi dựa trên §5.1. Đối với mỗi
cặp truy vấn-câu trả lời với bốn ứng viên lọc,
chúng tôi tính độ dài và tính ngắn gọn I(˜X;X|Y;Q)
tương ứng của chúng. Vì thông tin thống kê cho
các mẫu khác nhau được phân phối độc lập và
giống hệt nhau, chúng tôi chuyển đổi giá trị của
độ dài và tính ngắn gọn trong mỗi mẫu thành
thứ hạng của chúng trong số các phương pháp
nén khác nhau. Sau đó chúng tôi tính hệ số tương
quan Pearson giữa thứ hạng độ dài L và thứ hạng
tính ngắn gọn C, là 0.953, cho thấy mối tương
quan đáng kể ở mức 0.01 (hai đuôi).

6 Kết luận
Chúng tôi áp dụng nguyên tắc nút thắt thông tin
cho các bộ lọc nhiễu trong sinh tạo tăng cường
truy xuất, cân bằng sự đánh đổi giữa tính ngắn
gọn và tính chính xác. Không chỉ như một phương
pháp đánh giá cho việc lọc nhiễu, chúng tôi cũng
áp dụng nó để lựa chọn dữ liệu huấn luyện tinh
chỉnh có giám sát và cung cấp phần thưởng cho
học tăng cường. Mã nguồn có sẵn tại https://github.com/zhukun1020/NoiseFilter_IB.
Tối ưu hóa hai giai đoạn của chúng tôi dần dần
tiếp cận mục tiêu lọc oracle. Kết quả thực nghiệm
chứng minh rằng bộ lọc của chúng tôi vượt trội
đáng kể so với các phương pháp cơ sở và đạt được
tỷ lệ nén ấn tượng.

Lời cảm ơn
Kun Zhu và Xiaocheng Feng đóng góp bằng nhau
cho công trình này. Bing Qin là tác giả liên hệ
của công trình này. Chúng tôi cảm ơn các nhà
phản biện ẩn danh vì những nhận xét sâu sắc của
họ. Công trình này được hỗ trợ bởi Chương trình
R&D Chính quốc gia của Trung Quốc thông qua
grant số 2021ZD0112905, Quỹ Khoa học Tự nhiên
Quốc gia Trung Quốc (NSFC) thông qua grant
62276078 và U22B2059, Chương trình R&D Chính
của Heilongjiang thông qua grant 2022ZX01A32,
Dự án Hợp tác Quốc tế của PCL, PCL2022D01
và Quỹ Nghiên cứu Cơ bản cho các Đại học Trung
ương (Grant số HIT.OCEF.2023018).

Hạn chế
Mặc dù phương pháp của chúng tôi đã thể hiện
hiệu quả trong việc tăng cường hiệu suất của
nhiệm vụ lọc nhiễu trên sinh tạo tăng cường truy
xuất, nó có những hạn chế như sự phụ thuộc hiệu
suất vào bộ sinh tạo và sự đánh đổi giữa True-
Flip-Rate (TFR) và False-Flip-Rate (FFR). Để
phân tích thông tin tương hỗ giữa nội dung đã
lọc ˜X và nội dung truy xuất X, cũng như giữa
˜X và Y, việc sử dụng bộ sinh tạo hộp trắng được
trang bị khả năng mạnh mẽ là quan trọng. Hơn
nữa, bằng cách giới thiệu cờ dự đoán bổ sung để
đánh giá sự cần thiết của việc loại bỏ kết quả
lọc hiện tại, chúng tôi thành công giảm TFR, trong
khi với chi phí có thể giảm FFR. Chúng tôi giảm
thiểu điều này bằng cách tham gia vào các lần
lặp huấn luyện, điều này không thể tránh khỏi
dẫn đến sự gia tăng chi phí huấn luyện.

Tuyên bố Đạo đức
Chúng tôi hoàn toàn nhận thức rằng công nghệ
sinh tạo văn bản có tiềm năng được sử dụng một
cách độc hại để tạo ra nội dung giả mạo, độc hại,
hoặc xúc phạm. Nếu nội dung đã truy xuất bao
gồm thông tin có hại hoặc độc hại, nó sẽ ảnh hưởng
đến đầu ra của nội dung được tạo ra. Phương pháp
của chúng tôi được đề xuất để giảm thiểu ảnh hưởng
của nhiễu từ truy xuất, bao gồm nội dung độc hại.
Tuy nhiên, không có đảm bảo rằng phương pháp
của chúng tôi sẽ hoàn toàn loại bỏ độc tính.

Tài liệu tham khảo
[Tiếp tục với danh sách tài liệu tham khảo đầy đủ như trong bản gốc...]

--- TRANG 8 ---
[Bảng thống kê kết quả tiếp tục từ trang trước]

--- TRANG 9 ---
ple thành thứ hạng của chúng trong số các phương
pháp nén khác nhau. Sau đó chúng tôi tính hệ số
tương quan Pearson giữa thứ hạng độ dài L và
thứ hạng tính ngắn gọn C, là 0.953, cho thấy mối
tương quan đáng kể ở mức 0.01 (hai đuôi).

6 Kết luận
Chúng tôi áp dụng nguyên tắc nút thắt thông tin
cho các bộ lọc nhiễu trong sinh tạo tăng cường
truy xuất, cân bằng sự đánh đổi giữa tính ngắn
gọn và tính chính xác. Không chỉ như một phương
pháp đánh giá cho việc lọc nhiễu, chúng tôi cũng
áp dụng nó để lựa chọn dữ liệu huấn luyện tinh
chỉnh có giám sát và cung cấp phần thưởng cho
học tăng cường. Mã nguồn có sẵn tại https://github.com/zhukun1020/NoiseFilter_IB.
Tối ưu hóa hai giai đoạn của chúng tôi dần dần
tiếp cận mục tiêu lọc oracle. Kết quả thực nghiệm
chứng minh rằng bộ lọc của chúng tôi vượt trội
đáng kể so với các phương pháp cơ sở và đạt được
tỷ lệ nén ấn tượng.

[Phần còn lại của tài liệu tiếp tục với các phụ lục, bảng dữ liệu, và ví dụ chi tiết...]

# 2309.03118.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2309.03118.pdf
# Kích thước tệp: 744327 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
KNOWLEDGE SOLVER : DẠY CÁC LLM TÌM KIẾM
KIẾN THỨC LĨNH VỰC TỪ CÁC ĐỒ THỊ KIẾN THỨC
Chao Feng, Xinyu Zhang, Zichu Fei
TÓM TẮT
Các mô hình ngôn ngữ lớn (LLM), như ChatGPT và GPT-4, có tính linh hoạt và có thể giải quyết các nhiệm vụ khác nhau nhờ khả năng nổi sinh và tính tổng quát hóa của chúng. Tuy nhiên, LLM đôi khi thiếu kiến thức chuyên ngành để thực hiện các nhiệm vụ, điều này cũng sẽ gây ra hiện tượng ảo giác trong quá trình suy luận. Trong một số nghiên cứu trước đó, các mô-đun bổ sung như mạng thần kinh đồ thị (GNN) được huấn luyện trên kiến thức được truy xuất từ các cơ sở tri thức bên ngoài, nhằm giảm thiểu vấn đề thiếu kiến thức chuyên ngành. Tuy nhiên, việc kết hợp các mô-đun bổ sung: 1) sẽ cần phải huấn luyện lại các mô-đun bổ sung khi gặp phải các lĩnh vực mới; 2) sẽ trở thành nút thắt cổ chai vì khả năng mạnh mẽ của LLM không được sử dụng đầy đủ cho việc truy xuất. Trong bài báo này, chúng tôi đề xuất một mô hình, được gọi là Knowledge Solver (KSL), để dạy LLM tìm kiếm kiến thức thiết yếu từ các cơ sở tri thức bên ngoài bằng cách khai thác tính tổng quát hóa mạnh mẽ của chính chúng. Cụ thể, chúng tôi thiết kế một lời nhắc đơn giản nhưng hiệu quả để chuyển đổi việc truy xuất thành một chuỗi quyết định nhiều bước nhảy, giúp LLM có khả năng tìm kiếm kiến thức theo cách zero-shot. Ngoài ra, KSL có thể cung cấp các đường dẫn truy xuất hoàn chỉnh và do đó tăng tính giải thích được của các quá trình lập luận của LLM. Chúng tôi tiến hành các thí nghiệm trên ba bộ dữ liệu: CommonsenseQA (Talmor et al., 2018), OpenbookQA (Mihaylov et al., 2018), và MedQA-USMLE (Jin et al., 2021), và phát hiện rằng phương pháp của chúng tôi cải thiện hiệu suất cơ sở của LLM với một biên độ tương đối lớn.

1 Giới thiệu
Gần đây, các mô hình ngôn ngữ lớn (LLM) như ChatGPT đã thu hút sự chú ý to lớn từ các nhà nghiên cứu và những người thực hành do khả năng tổng quát của chúng (Qin et al., 2023). Ví dụ, các mô hình ngôn ngữ đủ lớn có thể hoạt động tốt cho các nhiệm vụ khác nhau theo cách zero-shot, như tóm tắt văn bản (Yang et al., 2023; Zhang et al., 2023), dịch máy (Moslem et al., 2023), và trả lời câu hỏi (Singhal et al., 2023). Tuy nhiên, trong một số tình huống, LLM thiếu kiến thức chuyên ngành hoặc không thể nhớ lại các sự kiện và kiến thức một cách chính xác, điều này gây ra hiện tượng ảo giác (Bang et al., 2023). Ảo giác đề cập đến việc các mô hình tạo ra văn bản vô nghĩa hoặc không trung thực với đầu vào nguồn được cung cấp (Ji et al., 2023; Koehn and Knowles, 2017; Raunak et al., 2021; Rohrbach et al., 2018; Vinyals and Le, 2015; Maynez et al., 2020).

Truy xuất các văn bản liên quan từ các cơ sở tri thức là một cách cổ điển để tăng cường hiệu suất của các mô hình ngôn ngữ như chất lượng tạo sinh (Borgeaud et al., 2022; Lewis et al., 2020a; Levine et al., 2022; Guu et al., 2020). Bên cạnh đó, nó cũng có thể giúp cải thiện tính thực tế của các văn bản được tạo ra. Thông thường, các mô-đun truy xuất được sử dụng để tìm các tài liệu có liên quan nhất với điểm số tương tự cao nhất so với truy vấn. Sau đó, các văn bản đầu vào và tài liệu được truy xuất sẽ được kết hợp theo một cách cụ thể để đưa vào các mô hình. Được thúc đẩy bởi điều này, một số phương pháp (Ram et al., 2023; Peng et al., 2023b) sử dụng các văn bản được truy xuất để tăng cường LLM. Ram et al. (2023) trực tiếp thêm vào đầu các tài liệu được truy xuất vào đầu vào để có được sự cải thiện hiệu suất cho LLM. (Peng et al., 2023b) thiết kế một LLM-Augmenter để truy xuất và hợp nhất bằng chứng từ kiến thức bên ngoài nhằm giảm thiểu hiện tượng ảo giác. Tuy nhiên, việc dựa vào sự tương tự giữa các embedding chỉ làm cho mô hình học các đặc trưng nông thay vì hiểu ngữ nghĩa, điều này ngược lại cản trở mô hình tìm kiếm kiến thức thực sự hữu ích. Ngược lại, Đồ thị Kiến thức (KG) là những phương tiện kiến thức rõ ràng, logic và vượt trội. Vì vậy, việc tận dụng hiệu quả KG cho LLM sẽ có lợi cho hiệu suất của LLM trên các nhiệm vụ đòi hỏi kiến thức.

Vì lý do này, có một dòng nghiên cứu (Yasunaga et al., 2021; Lin et al., 2019; Feng et al., 2020) sử dụng KG để giúp LLM đưa ra dự đoán. KagNet (Lin et al., 2019) đề xuất một mô-đun mạng thần kinh đồ thị để mô hình hóa các đồ thị quan hệ cho lập luận quan hệ dưới bối cảnh của cả không gian ký hiệu kiến thức và không gian ngữ nghĩa ngôn ngữ. MHGRN (FengarXiv:2309.03118v1  [cs.CL]  6 Sep 2023

--- TRANG 2 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức
KGsTôi không có đủ thông tin và kiến thức để trả lời câu hỏi của bạn một cách chính xác. Quá trình Lập luậnLLMsĐầu vào(a)
(b)Quá trình Lập luậnCâu hỏi: Nhà hàng kinh doanh có khả năng được đặt ở đâu?A.thị trấnB.tại khách sạnC.trung tâm thương mạiD.khu vực kinh doanhE.trang vàngLLMsĐầu vào
Câu hỏi: Nhà hàng kinh doanh có khả năng được đặt ở đâu?A.thị trấnB.tại khách sạnC.trung tâm thương mạiD.khu vực kinh doanhE.trang vàngB. tại khách sạn
D.khu vực kinh doanh
đặt tạichỗnăthủ đôtinhà hàngkinh doanhkháchhàngkhu vực kinh doanhthành phốLiên quan ĐếnLiên quan ĐếnLiên quan ĐếnLàSử dụng ChoLiên quan ĐếnTại Vị tríTìm kiếm Kiến thức Tương tác
Hình 1: Knowledge Solver. Một ví dụ so sánh LLM vanilla trong (a) và zero-shot knowledge solver trong (b) cho các nhiệm vụ trả lời câu hỏi. Phương pháp của chúng tôi giúp LLM tìm kiếm kiến thức cần thiết để thực hiện các nhiệm vụ bằng cách khai thác tính tổng quát hóa của chính LLM. Màu tím đại diện cho các nút và quan hệ trong đường dẫn chính xác được LLM chọn.

et al., 2020) trang bị các mô hình ngôn ngữ được huấn luyện trước với một mô-đun lập luận quan hệ nhiều bước nhảy, thống nhất các phương pháp lập luận dựa trên đường dẫn và mạng thần kinh đồ thị. QA-GNN (Yasunaga et al., 2021) học các biểu diễn trên các đồ thị kết hợp được hình thành bằng cách kết nối bối cảnh QA và KG. Tuy nhiên, chúng (Yasunaga et al., 2021; Lin et al., 2019; Feng et al., 2020) đều yêu cầu huấn luyện các mô-đun nhận biết kiến thức bổ sung như mạng thần kinh đồ thị (GNN) trên kiến thức được truy xuất. Có hai nhược điểm của việc huấn luyện các mô-đun bổ sung: 1) sẽ phải chịu đựng nỗi đau của việc huấn luyện lại khi gặp phải các lĩnh vực mới; 2) sẽ trở thành nút thắt cổ chai vì khả năng mạnh mẽ của LLM không được sử dụng đầy đủ cho việc truy xuất.

Trong bài báo này, chúng tôi đề xuất một mô hình, được gọi là Knowledge Solver (KSL), để giải quyết những nhược điểm này, giúp dạy chính LLM tìm kiếm kiến thức từ các cơ sở tri thức bên ngoài. Cụ thể, chúng tôi đơn giản hóa quá trình tìm kiếm kiến thức cần thiết từ KG thành một chuỗi quyết định nhiều bước nhảy. Tại mỗi bước, chúng tôi chuyển đổi thông tin cục bộ trong KG thành các lời nhắc văn bản (bao gồm đường dẫn lịch sử được LLM chọn), dựa trên đó LLM chọn kiến thức liên quan trong bối cảnh để thực hiện các nhiệm vụ, như được hiển thị trong Hình 1. Toàn bộ quá trình tương tự như con người tìm kiếm trên Internet để đạt được một số mục tiêu. Hơn nữa, dựa trên các đường dẫn hoàn chỉnh được LLM chọn, chúng ta có thể giải thích toàn bộ quá trình ra quyết định của LLM. Nó cho phép phân tích khi các trường hợp xấu xảy ra, một khả năng không có trong các phương pháp truy xuất hộp đen trước đó.

Chúng tôi đánh giá phương pháp của mình, Knowledge Solver (KSL), với ba LLM (GPT-3.5, LLaMA (Touvron et al., 2023a), và LLaMA 2 (Touvron et al., 2023b)) trên ba bộ dữ liệu: CommonsenseQA, OpenbookQA, và MedQA-USMLE, nơi cần có lập luận với kiến thức. KSL cải thiện hiệu suất của hai đường cơ sở LLM trên ba bộ dữ liệu này trong cài đặt zero-shot và fine-tuning.

Những đóng góp chính của chúng tôi được tóm tắt như sau:
•Chúng tôi đề xuất Knowledge Solver (KSL), là mô hình đầu tiên sử dụng LLM để tự tìm kiếm kiến thức liên quan trên KG.
•Mô hình đề xuất của chúng tôi Knowledge Solver có thể tăng cường hiệu suất của LLM trên các nhiệm vụ đòi hỏi kiến thức với một biên độ tương đối lớn theo cách zero-shot mà không cần mô-đun và huấn luyện bổ sung.
• Knowledge Solver có thể cung cấp tính giải thích được cho toàn bộ quá trình lập luận của LLM.
•Khi gánh nặng tính toán có thể chấp nhận được, việc fine-tuning LLM trên bộ dữ liệu được xây dựng đặc biệt của chúng tôi, với sự giúp đỡ của KG, có thể mang lại lợi ích thêm cho LLM.
2

--- TRANG 3 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức
Loại người nào thường mắc bệnh?A.bệnh việnB.đầuC.người bệnhD.người cao tuổiE.phòng khám bác sĩCâu hỏi
loạithường xuyênmắc phảiđộng vậtphòng khámyác sĩtình trạngbệnh tậtnhà dưỡng lãongười cao tuổicon người
bệnh việnbệnh nhâny tá
sức khỏeKG NgoàiCho một câu hỏi và danh sách thực thể trả lời, mục tiêu của chúng ta là chọn thực thể tiếp theo dựa trên các mối quan hệ của chúng được hiển thị trong dấu ngoặc () từ danh sách thực thể được cung cấp, cho đến khi chúng ta đạt đến thực thể trả lời đúng.Câu hỏi là: Loại người nào thường mắc bệnh?Các thực thể trả lời là: ['bệnh viện','đầu','người','bệnh','người_bệnh',...].Cho thực thể đầu contract, vui lòng chọn thực thể tiếp theo: [sicken(có sự kiện phụ),condition(có liên quan đến),...].KSLđầu
bệnhngười bệnh
Người dùng
Cho thực thể đầu condition, vui lòng chọn thực thể tiếp theo: [contract(có liên quan đến),illness(là một loại),hospital(có liên quan đến),well(có liên quan đến)...].
Người dùngThực thể tiếp theo là condition.
Trợ lýThực thể tiếp theo là illness.
Trợ lýCho thực thể đầu illness, vui lòng chọn thực thể tiếp theo: [hospital(ở vị trí của),elderly_person(ở vị trí của),sick_person(ở vị trí của)...].
Người dùngThực thể tiếp theo là elderly_person.
Trợ lýtiền
Hình 2: Tổng quan Phương pháp. Đối với mỗi cặp lựa chọn trả lời câu hỏi, chúng tôi truy xuất đồ thị con kiến thức liên quan và mã hóa nó thành lời nhắc văn bản, được đưa trực tiếp vào LLM để giúp chúng thực hiện các nhiệm vụ đòi hỏi kiến thức. Trong tình huống trả lời câu hỏi này, LLM tương tác với kiến thức bên ngoài được cung cấp để chọn đường dẫn trả lời câu hỏi một cách chính xác.

2 Nghiên cứu Liên quan
Mô hình Ngôn ngữ Lớn. Các mô hình ngôn ngữ được huấn luyện trước (PLM) được huấn luyện trên các bộ dữ liệu khổng lồ, giúp chúng hiểu bối cảnh và tạo ra văn bản. Các PLM được huấn luyện trước như GPT-1 (Radford et al., 2018), BERT (Devlin et al., 2018), XLNet (Yang et al., 2019), RoBERTa Liu et al. (2019) và ALBERT (Lan et al., 2019) đã được áp dụng rộng rãi cho các nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) khác nhau trong những năm gần đây. Đối với nhiệm vụ trả lời câu hỏi, các mô hình được tận dụng trong một số lượng lớn các khung làm việc hiện có, chẳng hạn như (Lin et al., 2019; Lv et al., 2020; Feng et al., 2020; Yasunaga et al., 2021; Zhang et al., 2022) để mã hóa các bối cảnh QA dưới dạng vector câu lệnh.

Sự bùng nổ phát triển hiện tại trong các mô hình ngôn ngữ lớn (LLM) mang lại những cú hích đổi mới với kích thước và khả năng to lớn. Các LLM cơ sở như T5 (Raffel et al., 2020), GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2022), GPT-J (Wang, 2021), LLaMA (Touvron et al., 2023a), GLM (Du et al., 2022; Zeng et al., 2022), BLOOM (Scao et al., 2022), RWKV (Peng et al., 2023a), MOSS (Sun et al., 2023) và LLaMA 2 (Touvron et al., 2023b) được huấn luyện trên các bộ dữ liệu lớn để nắm bắt các mô hình ngôn ngữ tổng quát. Ngoài ra, các LLM được fine-tune theo hướng dẫn như InstructGPT (Ouyang et al., 2022), Flan-PaLM (Chung et al., 2022), Flan-T5 (Chung et al., 2022), BLOOMZ (Muennighoff et al., 2022), Alpaca (Taori et al., 2023) và Vicuna (Chiang et al., 2023) được thiết kế để tuân theo hướng dẫn của người dùng. Các LLM RLHF (Học tăng cường từ Phản hồi của Con người), như ChatGPT¹ và GPT-4 (OpenAI, 2023a), kết hợp các kỹ thuật học tăng cường để tối ưu hóa hiệu suất mô hình dựa trên phản hồi của con người. Tuy nhiên, trong một số tình huống, LLM thiếu kiến thức chuyên ngành để thực hiện các nhiệm vụ liên quan. Mô hình đề xuất của chúng tôi, KSL, dạy chính LLM tìm kiếm kiến thức từ các cơ sở tri thức bên ngoài để giúp LLM đạt được mục tiêu.

Trả lời Câu hỏi Cơ sở Tri thức. Trả lời câu hỏi trên cơ sở tri thức (KBQA) tập trung vào việc cho phép máy móc trả lời câu hỏi bằng cách sử dụng kiến thức liên quan được truy xuất từ các cơ sở tri thức (KB). Các phương pháp trong KBQA có thể được phân loại rộng rãi thành hai nhóm: (i) các phương pháp dựa trên truy xuất văn bản và (ii) các phương pháp dựa trên Đồ thị Kiến thức. Nghiên cứu của chúng tôi phù hợp với nhóm thứ hai, với sự nhấn mạnh vào việc tích hợp Đồ thị Kiến thức vào LLM.

Các phương pháp dựa trên truy xuất văn bản đã được thử nghiệm với một loạt rộng các nhiệm vụ NLP. Các mô hình tạo sinh, được tăng cường bằng khả năng truy xuất trong trả lời câu hỏi, được nghiên cứu (và fine-tune) trong (Min et al., 2020; Lewis et al., 2020b; Izacard and Grave, 2020). Thay vì trực tiếp fine-tune các PLM được huấn luyện trước để nâng cao hiệu suất nhiệm vụ ngôn ngữ, một số ngày càng tăng các nhà nghiên cứu đang chuyển hướng sang các phương pháp nhẹ hơn, nơi họ đóng băng các tham số mô hình ¹https://openai.com/blog/chatgpt/
3

--- TRANG 4 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức

Thuật toán 1 Lập luận Zero-Shot của Knowledge Solver.
Yêu cầu: Các thực thể câu hỏi Vq={vq1, vq2,···, vqn}; các thực thể trả lời tương ứng Va={va1, va2,···, van}.
1:hàm REL_EXTR (vh,Gsub)
2: tail_relation_list = []
3: đối với mỗi thực thể đuôi vti của vh trong Gsub thực hiện
4: quan hệ rhti=Gsub(vh, vti)
5: tail_relation_list.append(( vti, rhti))
6: kết thúc for
7: trả về tail_relation_list
8:kết thúc hàm
9: truy xuất đồ thị con Gsub cho Vq và Va
10:vq được chọn ngẫu nhiên từ Vq làm vh1
11: round = 0
12:đối với mỗi thực thể đầu vhi thực hiện
13: nếu vhi∈ Va thì
14: thoát
15: kết thúc nếu
16: nếu round == round_maximum thì
17: thoát
18: kết thúc nếu
19: tail_relation_list = REL_EXTR( vhi,Gsub)
20: vh(i+1)= LLM(tail_relation_list)
21: round += 1
22:kết thúc for
23:trả về vhi

và tăng cường mô hình với các mô-đun có thể huấn luyện nhỏ. Các kỹ thuật fine-tuning nhẹ như vậy bao gồm adapter tuning (Houlsby et al., 2019; Lin et al., 2020), prompt tuning (Lester et al., 2021), prefix tuning (Li and Liang, 2021), và các kiến trúc phức tạp hơn như prompt tuning phụ thuộc đầu vào, frozen readers, và LM recursion như được trình bày trong (Levine et al., 2022).

Các phương pháp dựa trên Đồ thị Kiến thức cũng được áp dụng rộng rãi trong lĩnh vực trả lời câu hỏi. KagNet (Lin et al., 2019) xây dựng các đồ thị schema đại diện cho các đường dẫn giữa các thực thể câu hỏi và trả lời, sau đó được mã hóa bằng kiến trúc GCN-LSTM-HPA. Để đạt được cả độ chính xác cao và khả năng mở rộng mô hình hiệu quả, Multi-hop Graph Relation Network (Feng et al., 2020) kết hợp tính giải thích được của lập luận dựa trên đường dẫn với khả năng mở rộng của GNN, thêm một cơ chế chú ý quan hệ có cấu trúc. Riêng biệt, QA-GNN (Yasunaga et al., 2021) liên kết các vector bối cảnh QA với các thực thể chủ đề trong đồ thị schema. DRAGON (Yasunaga et al., 2022) đề xuất một mô hình tự giám sát cho tích hợp văn bản và KG hai chiều, trong khi GreaseLM (Zhang et al., 2022) hợp nhất các biểu diễn PLM và GNN thông qua các tương tác modality nhiều lớp. Khác với các nghiên cứu trước đây huấn luyện các mô-đun bổ sung như GNN, phương pháp KSL của chúng tôi khuyến khích LLM tự tìm kiếm kiến thức thiết yếu từ cơ sở tri thức bên ngoài.

3 Định nghĩa Vấn đề
Bài báo của chúng tôi nhằm giúp LLM hoạt động tốt hơn trên các nhiệm vụ đòi hỏi kiến thức khi chúng thiếu kiến thức chuyên ngành. Chúng tôi chọn trả lời câu hỏi làm nhiệm vụ đòi hỏi kiến thức được đánh giá. Để giảm thiểu vấn đề thiếu kiến thức, chúng tôi truyền cảm hứng cho LLM tương tác với kiến thức bên ngoài được cung cấp và tự phát xác định đường dẫn phù hợp để đưa ra câu trả lời chính xác. Theo nghiên cứu trước đó (Yasunaga et al., 2021), chúng tôi định nghĩa Đồ thị Kiến thức là một đồ thị đa quan hệ G= (V,E). Ở đây V là tập hợp các nút thực thể trong KG; E ∈ V × R × V là tập hợp các cạnh kết nối các nút trong V, trong đó R đại diện cho một tập hợp các loại quan hệ.

Cho cặp lựa chọn trả lời câu hỏi [q, A], chúng tôi liên kết các thực thể được đề cập trong câu hỏi và lựa chọn trả lời với KG G đã cho, theo nghiên cứu trước đó (Feng et al., 2020). Chúng tôi ký hiệu tất cả các thực thể câu hỏi là Vq∈ V, và các thực thể trả lời là Va∈ V. Sau đó chúng tôi truy xuất đồ thị con Gsub= (Vq,a_sub,Eq,a_sub) từ KG G. Gsub chứa tất cả các nút trên các đường dẫn k-hop giữa các nút trong Vq và Va.

4 Phương pháp
Như được hiển thị trong Hình 2, phương pháp KSL của chúng tôi đầu tiên truy xuất đồ thị con liên quan Gsub từ KG cho cặp lựa chọn trả lời câu hỏi [q, A] đã cho. Sau đó chúng tôi mã hóa Gsub thành lời nhắc văn bản TK để đưa kiến thức vào LLM, điều này sẽ khởi tạo suy luận giống như đối thoại để khuyến khích LLM tìm kiếm kiến thức cần thiết bằng cách sử dụng khả năng của chính chúng và hướng dẫn bản thân để đạt được mục tiêu cuối cùng.
4

--- TRANG 5 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức

Thuật toán 2 Tạo Bộ dữ liệu Hướng dẫn Huấn luyện.
Yêu cầu: Một chuỗi của tất cả các cặp lựa chọn trả lời câu hỏi Q={[q1, A1],···,[qN, AN]}; nguồn kiến thức có cấu trúc (Đồ thị Kiến thức) G; bộ mã hóa E để chuyển đổi Gsub thành lời nhắc văn bản TK
1: total_paths = []
2:đối với mỗi [qj, Aj] trong Q thực hiện
3: trích xuất các thực thể câu hỏi và lựa chọn trả lời Vq và Va
4: truy xuất đồ thị con Gsub từ G
5: đối với mỗi thực thể câu hỏi vqi∈ Vq thực hiện
6: chọn ngẫu nhiên thực thể lựa chọn trả lời đúng vca
7: path = find_shortest_path( Gsub, source= vqi, target= vca)
8: total_paths.append(path)
9: loại bỏ tất cả các nút trên đường dẫn ngoại trừ vca từ Gsub
10: kết thúc for
11:kết thúc for
12: training_data = []
13:đối với mỗi đường dẫn pi trong total_paths thực hiện
14: hist = []
15: đối với mỗi nút nj trong pi ngoại trừ nút cuối cùng thực hiện
16: instance = {}
17: instance["instruction"] = instruction
18: thực thể đầu vhj=nj
19: thực thể đuôi vtj= entity_extract( Gsub,vhj)
20: quan hệ rhtj= relation_extract( Gsub,vhj,vtj)
21: instance["input"] = E(vhj, hist)
22: instance["output"] = E(vtj)
23: training_data.append(instance)
24: hist.append([instance["input"], instance["output"]])
25: kết thúc for
26:kết thúc for
27:trả về training_data

4.1 Lập luận Zero-Shot của Knowledge Solver
Để giúp các mô hình thực hiện các nhiệm vụ đòi hỏi kiến thức chuyên ngành, như trả lời câu hỏi, chúng tôi đưa kiến thức bên ngoài vào LLM. Đối với mỗi đồ thị con được truy xuất Gsub, chúng tôi chuyển đổi nó thành lời nhắc văn bản TK đưa vào LLM, và sử dụng tính tổng quát hóa mạnh mẽ của LLM để khuyến khích chúng tự tìm kiếm thông tin cần thiết.

Cho câu hỏi q và tập hợp các lựa chọn trả lời A= [a1, ..., a N], trong đó N là tổng số lựa chọn trả lời, chúng tôi truy xuất Gsub và xem nó như kiến thức bên ngoài. Gsub chứa tất cả các thực thể câu hỏi Vq, tất cả các thực thể lựa chọn trả lời Va, các thực thể trung gian, và các quan hệ tương ứng R giữa các thực thể. Để khởi tạo quá trình lập luận của LLM cho trả lời câu hỏi, chúng tôi đầu tiên chọn ngẫu nhiên một thực thể câu hỏi vq∈ Vq cho LLM, và sau đó khuyến khích LLM chọn một đường dẫn dựa trên phán đoán của chính chúng cho đến khi cuối cùng chúng đạt đến một trong các thực thể trả lời va∈ Va. Cụ thể, chúng ta có thể chia nhỏ quá trình lập luận của LLM cho trả lời câu hỏi thành nhiều vòng như CoT (Wei et al., 2022) (tổng số vòng phụ thuộc vào phán đoán của chính LLM. Trong thực tế, chúng tôi đặt giới hạn số vòng là Nr). Đối với mỗi cặp câu hỏi và lựa chọn trả lời [q, A], chuỗi các vòng sẽ tạo thành một đường dẫn lập luận rõ ràng, không chỉ tăng cường LLM với kiến thức bên ngoài chuyên ngành, mà còn tăng tính giải thích được của LLM.

Trong mỗi vòng, chúng tôi đặt thực thể đầu hiện tại vh và tất cả các thực thể đầu được liên kết Vt= [vt1, ..., v tN] và các quan hệ tương ứng của chúng Rht= [rht1, ..., r htN] trong lời nhắc văn bản để thông báo cho LLM về sự tồn tại của kiến thức bên ngoài. LLM sẽ chọn thực thể đuôi có khả năng nhất làm thực thể đầu cho vòng tiếp theo, dựa trên kiến thức tiên nghiệm được lưu trữ ngầm trong các tham số của chúng và kiến thức bên ngoài rõ ràng dưới dạng lời nhắc văn bản, như các quan hệ, cho trả lời câu hỏi. Sau đó, quá trình lựa chọn thực thể này sẽ lặp lại cho đến khi một trong các thực thể trả lời va được chọn.

Cuối cùng, chúng tôi tìm lựa chọn trả lời được LLM chọn dựa trên ánh xạ giữa thực thể trả lời va và lựa chọn trả lời a. Toàn bộ quá trình lập luận được thực hiện hoàn toàn bằng tạo văn bản thay vì phân loại trên các thực thể được định nghĩa trước vì trong nhiều tình huống, chúng ta không thể truy cập vào logit của LLM. Đối với mỗi vòng, lời nhắc văn bản đầu vào cũng bao gồm toàn bộ lịch sử lựa chọn thực thể, tương tự như đối thoại. Quá trình lập luận tổng thể cũng được minh họa trong Thuật toán 1.

4.2 Fine-tuning Knowledge Solver
Khi LLM có thể truy cập được, chúng ta có thể fine-tune chúng trên kiến thức bên ngoài để chuyển đổi kiến thức này thành các tham số của LLM. Theo Alpaca (Taori et al., 2023), chúng tôi tận dụng instruction tuning (Wei et al., 2021) để fine-tune LLM. Cụ thể, chúng tôi sử dụng một mẫu tương tự như trong Alpaca (Taori et al., 2023). Khác với instruction tuning tổng quát (Wei et al., 2021), nơi LLM được kích thích để tuân theo hướng dẫn của người dùng theo cách zero-shot, mục tiêu chính của chúng tôi là khuyến khích
5

--- TRANG 6 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức
Cho một câu hỏi và danh sách thực thể trả lời, mục tiêu của chúng ta là chọn thực thể tiếp theo dựa trên các mối quan hệ của chúng được hiển thị trong dấu ngoặc () từ danh sách thực thể được cung cấp, cho đến khi chúng ta đạt đến thực thể trả lời đúng.Hướng dẫn
Câu hỏi là: Chơi bóng đá trong thời gian dài dẫn đến điều gì? Các thực thể trả lời là: ['sự phấn khích','mệt mỏi','tức giận','đau','bị thương','có được','trở_nên_mệt','có được','trở_nên_mệt','mệt']. Cho thực thể đầu lead, vui lòng chọn thực thể tiếp theo: [action(có liên quan đến),run(có liên quan đến),compete(có sự kiện phụ)...]Đầu vào
Thực thể tiếp theo là run.Đầu raDưới đây là một hướng dẫn mô tả một nhiệm vụ, được ghép nối với một đầu vào cung cấp thêm bối cảnh. Viết một phản hồi hoàn thành yêu cầu một cách thích hợp.
Hình 3: Ví dụ Huấn luyện. Instance trong bộ dữ liệu instruction tuning được xây dựng của chúng tôi.

LLM học kiến thức chuyên ngành. Vì vậy, chúng tôi cố định các hướng dẫn, được sử dụng để thông báo cho LLM chọn đường dẫn chính xác, qua tất cả các instance (trong thực tế, các hướng dẫn có thể được sửa đổi theo kiến thức chuyên ngành). Các định dạng đầu vào và phản hồi giống như chúng tôi đã nêu trong Lập luận Zero-Shot của Knowledge Solver, nơi chúng tôi chuyển đổi mỗi đồ thị con được truy xuất Gsub thành nhiều cặp đầu vào-phản hồi bắt đầu từ thực thể câu hỏi vq đến thực thể trả lời va trong lựa chọn trả lời đúng. Mỗi đầu vào chứa lịch sử lựa chọn thực thể như đối thoại giữa người dùng và LLM, thực thể đầu hiện tại, tất cả các thực thể đuôi được kết nối, và các quan hệ tương ứng. Phản hồi bao gồm thực thể đuôi tiếp theo của đường dẫn chính xác. Cụ thể, đối với mỗi cặp câu hỏi và lựa chọn trả lời [q, A], chúng tôi lặp qua tất cả các thực thể câu hỏi vq∈ Vq trong khi giữ tất cả các đường dẫn được trích xuất riêng biệt. Toàn bộ quá trình xây dựng bộ dữ liệu instruction-tuning cũng được minh họa trong Thuật toán 2. Ví dụ về bộ dữ liệu instruction tuning của chúng tôi có thể được xem trong Hình 3. Chúng tôi sử dụng LoRA (Hu et al., 2021) để tune LLM vì nó có thể giúp giảm đáng kể gánh nặng bộ nhớ GPU.

Đối với suy luận, KSL được fine-tune sử dụng cùng cách như zero-shot Knowledge Solver. Đối với mỗi cặp câu hỏi và lựa chọn trả lời [q, A], chúng tôi chọn ngẫu nhiên một thực thể câu hỏi vq để khởi tạo quá trình lập luận. Chúng tôi để dành việc tính trung bình kết quả của tất cả các thực thể câu hỏi cho nghiên cứu tương lai.

5 Thí nghiệm
5.1 Bộ dữ liệu
Chúng tôi đánh giá phương pháp Knowledge Solver của mình trên ba bộ dữ liệu trả lời câu hỏi: CommonsenseQA (Talmor et al., 2018), OpenbookQA (Mihaylov et al., 2018), và MedQA-USMLE (Jin et al., 2021).

CommonsenseQA là một bộ dữ liệu trả lời câu hỏi cho lập luận thông thường, bao gồm tổng cộng 12102 câu hỏi. Phương pháp tạo câu hỏi bao gồm việc lấy mẫu ba khái niệm mục tiêu liên quan đến một khái niệm nguồn từ ConceptNet (Speer et al., 2017). Mỗi câu hỏi có năm lựa chọn. Ba trong số này được tác giả bởi các công nhân đám đông dựa trên các khái niệm mục tiêu, với thêm hai lựa chọn phụ để gây xao nhãng. CommonsenseQA đóng vai trò là một trong những bộ dữ liệu benchmark phổ biến nhất cho KGQA, như được hiển thị trong (Lin et al., 2019; Lv et al., 2020; Feng et al., 2020; Yasunaga et al., 2021, 2022). Bài báo của chúng tôi tiền xử lý dữ liệu với các phân chia dữ liệu gốc trong KagNet (Lin et al., 2019).
6

--- TRANG 7 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức

Mô hình CSQA OBQA MedQA
GPT-3.5 (zero-shot) 72.9 74.8 55.8
GPT-3.5 + KSL (zero-shot) 79.6 (+9.19%) 81.6 (+9.09%) 58.4 (+4.66%)
LLaMA-7B (zero-shot) 20.5 26.8 22.7
LLaMA-7B + KSL (zero-shot) 28.4 (+38.54%) 34.0 (+26.87%) 23.6 (+3.96%)
LLaMA2-7B (zero-shot) 19.7 25.6 25.1
LLaMA2-7B + KSL (zero-shot) 26.3 (+33.50%) 32.2 (+25.78%) 25.8 (+2.79%)
LLaMA-7B (finetuned) 38.0 29.8 25.0
LLaMA-7B + KSL (finetuned) 47.4 (+24.74%) 45.8 (+53.69%) 25.7 (+2.80%)

Bảng 1: Đánh giá Hiệu suất. Chúng tôi báo cáo độ chính xác của các đường cơ sở LLM và KSL (zero-shot và finetuned) trên ba bộ dữ liệu: CommonsenseQA, OpenBookQA, và MedQA-USMLE.

OpenbookQA chứa khoảng 6000 câu hỏi trắc nghiệm và một cuốn sách mở với hơn 1000 sự kiện khoa học cơ bản. Quá trình trả lời câu hỏi đòi hỏi sự kết hợp của các sự kiện khoa học, kiến thức thông thường và khả năng lập luận nhiều bước nhảy. Bài báo của chúng tôi tuân theo các phân chia dữ liệu gốc (Mihaylov et al., 2018).

MedQA là một bộ dữ liệu đa ngôn ngữ được thiết kế để giải quyết các vấn đề y tế thực tế. Tất cả các câu hỏi và câu trả lời được thu thập từ các kỳ thi ban y khoa chuyên nghiệp. Trong bài báo của chúng tôi, chúng tôi tập trung vào tập con USMLE, nơi dữ liệu từ Kỳ thi Ban Y khoa Quốc gia ở Hoa Kỳ, và tuân theo các phân chia dữ liệu gốc (Jin et al., 2021).

5.2 Đồ thị Kiến thức
CoceptNet (Speer et al., 2017) được sử dụng cho CommonsenseQA và OpenbookQA. Nó liên kết các từ và cụm từ từ ngôn ngữ con người thông thường thông qua các mối quan hệ được gắn nhãn. Chúng tôi áp dụng thiết lập quan hệ từ MHGRN (Feng et al., 2020), bao gồm tổng cộng 34 loại quan hệ đa hướng. Các đường dẫn giữa tất cả các thực thể chủ đề được đề cập trong cặp câu hỏi-trả lời được tìm thấy và căn cứ như các đồ thị con.

Trong bối cảnh của bộ dữ liệu USMLE của MedQA, chúng tôi kết hợp Đồ thị Kiến thức được xây dựng trong QA-GNN (Yasunaga et al., 2021), chứa các từ vựng y sinh từ Hệ thống Ngôn ngữ Y khoa Thống nhất (UMLS) (Bodenreider, 2004) và DrugBank (Wishart et al., 2018).

Cho mỗi cặp câu hỏi và lựa chọn trả lời [q, A], chúng tôi truy xuất đồ thị con Gsub từ Đồ thị Kiến thức có cấu trúc G theo bước tiền xử lý được mô tả trong MHGRN (Feng et al., 2020), với kích thước hop k= 2.

5.3 Chi tiết Triển khai & huấn luyện
Zero-shot. Chúng tôi chủ yếu sử dụng ba LLM (GPT-3.5, LLaMA-7B (Touvron et al., 2023a), và LLaMA 2-7B (Touvron et al., 2023b)) làm đường cơ sở. Đối với GPT-3.5, chúng tôi gọi OpenAI API để sử dụng gpt-3.5-turbo-16k. Giới hạn tổng số vòng Nr được đặt là 5 trong quá trình suy luận.

Finetuning. Chúng tôi sử dụng LoRA (Hu et al., 2021) để finetune LLaMA-7B (Touvron et al., 2023a) trên 8 GPU NVIDIA A40, mỗi cái có bộ nhớ 48 GB. Đối với CommonsenseQA (Talmor et al., 2018), tập huấn luyện chứa 114,552 instance và tập phát triển bao gồm 14,391 instance. Đối với OpenbookQA (Mihaylov et al., 2018), tập huấn luyện bao gồm 57,458 instance và tập phát triển chứa 5814 ví dụ. Đối với MedQA-USMLE (Jin et al., 2021), có 13,561 instance trong tập huấn luyện và 1677 instance trong tập phát triển. Kích thước batch toàn cục là 128 và tốc độ học được đặt là 3e-4. Chúng tôi đặt rank r trong LoRA (Hu et al., 2021) là 16 và α là 16. Xác suất dropout (Srivastava et al., 2014) là 0.05. Chúng tôi finetune các ma trận chiếu query, key, value, và output Wq, Wk, Wv, Wo trong các mô-đun self-attention của transformers (Vaswani et al., 2017). Độ dài tối đa của chuỗi đầu vào là 1152. Tổng số epoch finetune cho CommonsenseQA (Talmor et al., 2018) và OpenbookQA (Mihaylov et al., 2018) là 3, và cho MedQA-USMLE (Jin et al., 2021) là 5. Chúng tôi sử dụng các checkpoint với validation loss thấp nhất cho suy luận cuối cùng trên các tập test.

Thước đo đánh giá. Đối với ba bộ dữ liệu trả lời câu hỏi: CommonsenseQA (Talmor et al., 2018), OpenbookQA (Mihaylov et al., 2018), và MedQA-USMLE (Jin et al., 2021), chúng tôi sử dụng độ chính xác làm thước đo đánh giá theo nghiên cứu trước đó (Yasunaga et al., 2021). Tuy nhiên, chúng tôi chỉ thực hiện tạo văn bản thay vì phân loại trên tập hợp được định nghĩa trước, nên khó sử dụng cách truyền thống để tính độ chính xác. Thay vào đó, chúng tôi gọi OpenAI API và đưa vào các lời nhắc được tạo thủ công (xem chi tiết trong phần bổ sung) cho GPT-4 (OpenAI, 2023b) để đánh giá xem kết quả tạo ra của LLM có khớp với chân lý gốc không
7

--- TRANG 8 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức
Cặp Lựa chọn Trả lời Câu hỏiĐầu raỞ đâu có nhiều văn phòng ở New York?A. tòa nhà trường họcB. tòa nhà chọc trờiC. kinh doanhD. cửa hàng tạp hóaE. công việcGPT-3.5 (zero-shot):Câu trả lời là C.KSL(zero-shot):văn phòngtòa nhà chọc trờiBạn sẽ sử dụng gì để tìm một công ty? A. thị trườngB. internetC. trang vàng D.sổ điện thoạiE. lực lượng vũ trangGPT-3.5 (zero-shot):Câu trả lời là B.KSL(zero-shot):tìmthư_mục_điện_thoạitrang_vàngĐiều gì khiến ai đó dừng lái xe ngay lập tức?A. kẹt xeB. bánh xe quayC. thiếu nhiên liệuD. bệnh tậtE. mài mòn lốpGPT-3.5 (zero-shot):Câu trả lời là D.KSL(zero-shot):dừnglái xethiếu_nhiên_liệuTại Vị tríSử dụng Cho*Liên quan Đến
Liên quan ĐếnNguyên nhân
Hình 4: Kết quả Định tính của KSL (GPT-3.5). Các phản hồi được tạo ra trên một số ví dụ của GPT-3.5 và zero-shot KSL (GPT-3.5). Lựa chọn in đậm đại diện cho câu trả lời đúng. Dấu hoa thị (*) biểu thị một quan hệ đảo ngược.

truth. Cuối cùng, chúng tôi sử dụng điểm số từ GPT-4 (OpenAI, 2023b) để tính độ chính xác (0 đại diện cho đầu ra của LLM hoàn toàn không liên quan trong khi 1 có nghĩa là câu trả lời được LLM tạo ra khớp chính xác với chân lý gốc).

5.4 Kết quả
Cặp Lựa chọn Trả lời Câu hỏiĐầu raỞ đâu con người mong đợi tìm thấy các hoạt động sản xuất? A. nhà máyB. trường họcC. cửa hàng tạp hóaD. ban nhạcE. máy bayLLaMA-7B (zero-shot):Lựa chọn được chọn là: C. cửa hàng tạp hóaKSL(zero-shot):sản xuấtnhà máyKSL(finetuned):sản xuấtnhà máyĐội có thể giao tiếp hiệu quả, họ biết mỗi người khác sẽ gì? A. gửi emailB. nói chuyện với ngườiC. gọi cho tổng thống bermudaD. nghĩE. nói vớiLLaMA-7B (zero-shot):Lựa chọn được chọn là: A. gửi email KSL(zero-shot):đội nhómlàm việcnghĩKSL(finetuned):có thểlàmnghĩCentavo được sử dụng ở khu vực nào?A. colonB. australC. cordobaD. indianE. mexicanpesoLLaMA-7B (zero-shot):Lựa chọn được chọn là: A. colonKSL(zero-shot):centavopesoKSL(finetuned):khu vựcphíanaustralLiên quan ĐếnLiên quan ĐếnLiên quan ĐếnLiên quan ĐếnLiên quan ĐếnCó Sự kiện Phụ*Liên quan ĐếnLà*Liên quan Đến
Hình 5: Kết quả Định tính của KSL (LLaMA-7B). Các phản hồi được tạo ra trên một số ví dụ của LLaMA-7B và zero-shot/finetuned KSL (LLaMA-7B). Lựa chọn in đậm đại diện cho câu trả lời đúng. Dấu hoa thị (*) biểu thị một quan hệ đảo ngược.

Lập luận zero-shot của Knowledge Solver. Như được hiển thị trong Bảng 1, Knowledge Solver (KSL) của chúng tôi có thể tăng cường các đường cơ sở LLM (GPT-3.5, LLaMA-7B (Touvron et al., 2023a), và LLaMA 2-7B (Touvron et al., 2023b)) với một biên độ tương đối lớn, cho thấy rằng: 1) phương pháp của chúng tôi có thể có lợi cho mô hình trong việc thực hiện các nhiệm vụ đòi hỏi kiến thức; 2) LLM sở hữu khả năng nhất định để tự tìm kiếm thông tin cần thiết khi kiến thức bên ngoài được cung cấp. Huấn luyện một adapter cho mỗi tình huống mà kiến thức chuyên ngành được yêu cầu sẽ tốn chi phí tính toán và thời gian lớn. Ngược lại, zero-shot Knowledge Solver của chúng tôi có thể khai thác khả năng nổi sinh của chính LLM để thực hiện các nhiệm vụ đòi hỏi kiến thức chuyên ngành chỉ bằng cách cung cấp kiến thức bên ngoài. Điều này dạy LLM tương tác với kiến thức bên ngoài để đạt được mục tiêu cuối cùng.
8

--- TRANG 9 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức

LLaMA (zero-shot) Alpaca-LoRA KSL (zero-shot) KSL (finetuned)
Mô hình010203040Độ chính xácCommonsenseQA
OpenBookQA
MedQA-USMLE
Hình 6: Thí nghiệm Ablation trên KSL Fine-tuned (LLaMA-7B). Chúng tôi so sánh KSL của chúng tôi với LLaMA và Alpaca-LoRA.

Fine-tuning Knowledge Solver. Khác với việc huấn luyện các adapter riêng biệt như GNN, phương pháp của chúng tôi cũng có thể finetune LLM trên kiến thức bên ngoài được cung cấp để đưa kiến thức vào các tham số của LLM. Như được hiển thị trong Bảng 1, KSL finetuned (LLaMA-7B) có thể cải thiện hiệu suất hơn nữa và vượt qua LLaMA-7B finetuned (xem chi tiết finetuning trong supp.) trên ba bộ dữ liệu. Điều này cho thấy rằng phương pháp của chúng tôi có thể hiệu quả giúp LLM ghi nhớ kiến thức để thực hiện các nhiệm vụ đòi hỏi kiến thức chuyên ngành khi gánh nặng tính toán có thể chấp nhận được. Thú vị là, sự cải thiện trên MedQA-USMLE (Jin et al., 2021) không đáng kể như trên CommonsenseQA (Talmor et al., 2018) và OpenBookQA (Mihaylov et al., 2018). Vấn đề có thể do Đồ thị Kiến thức (Yasunaga et al., 2021) không đủ lớn, nơi đối với nhiều cặp câu hỏi và lựa chọn trả lời, rất khó để truy xuất các đồ thị con hoàn chỉnh. Trong nhiều trường hợp, một số thực thể trả lời không được bao gồm trong các đồ thị con hoặc không có đường dẫn từ các thực thể câu hỏi đến các thực thể trả lời.

5.5 Kết quả định tính
Chúng tôi hiển thị một số kết quả định tính trong Hình 4 và Hình 5. Nó cho thấy rằng zero-shot KSL của chúng tôi có thể giúp LLM thực hiện các nhiệm vụ đòi hỏi kiến thức mà không cần bất kỳ huấn luyện bổ sung nào. Được cung cấp kiến thức bên ngoài, LLM có thể tự tìm kiếm kiến thức cần thiết để đạt được mục tiêu cuối cùng. Phương pháp của chúng tôi có thể giúp LLM sửa lỗi của chúng khi thiếu kiến thức chuyên ngành liên quan. Ví dụ, LLaMA-7B vanilla (Touvron et al., 2023a) không biết các hoạt động sản xuất có thể được tìm thấy ở đâu trong khi zero-shot KSL (LLaMA-7B) có thể trả lời câu hỏi một cách chính xác. KSL finetuned (LLaMA-7B) có thể cải thiện thêm khả năng của LLM để giải quyết các nhiệm vụ đòi hỏi kiến thức như trả lời câu hỏi "centavo được sử dụng ở khu vực nào?". Những điều này chứng minh tính hiệu quả của KSL.

5.6 Nghiên cứu Ablation
Như được hiển thị trong Bảng 1, KSL finetuned (LLaMA-7B) có thể cải thiện hiệu suất đáng kể. Để điều tra xem sự tăng cường này chủ yếu đến từ chính instruction tuning hay các bộ dữ liệu kiến thức được xây dựng đặc biệt của chúng tôi, chúng tôi cũng đánh giá Alpaca-LoRA (Taori et al., 2023) trên CommonsenseQA (Talmor et al., 2018), OpenBookQA (Mihaylov et al., 2018), và MedQA-USMLE (Jin et al., 2021) bằng cách sử dụng cùng phương pháp suy luận được đề cập như LLaMA-7B vanilla (Touvron et al., 2023a). Đáng chú ý là độ dài chuỗi tối đa của Alpaca-LoRA là 512, trong khi đối với phương pháp suy luận tương tác của chúng tôi, độ dài chuỗi đầu vào thường dài hơn 512. Như được hiển thị trong Hình 6, Alpaca-Lora, sử dụng cùng kỹ thuật LoRA (Hu et al., 2021) tuning LLaMA-7B (Touvron et al., 2023a), hoạt động ngang bằng với LLaMA-7B vanilla (Touvron et al., 2023a), cho thấy rằng bộ dữ liệu kiến thức được thiết kế đặc biệt của chúng tôi là nguồn chính mang lại lợi ích cho LLM trong việc thực hiện các nhiệm vụ đòi hỏi kiến thức. Alpaca-LoRA (Taori et al., 2023) hoạt động kém hơn zero-shot KSL (LLaMA-7B) của chúng tôi. Nó cho thấy rằng việc khuyến khích LLM tìm kiếm kiến thức liên quan bằng cách khai thác khả năng của chính chúng là một cách hiệu quả và hiệu suất để giúp mô hình trên các nhiệm vụ đòi hỏi kiến thức.

6 Kết luận
Trong bài báo này, chúng tôi đề xuất Knowledge Solver (KSL), có thể giúp LLM hoạt động tốt hơn trên các nhiệm vụ đòi hỏi kiến thức chuyên ngành theo cách zero-shot và finetuning. Được cung cấp kiến thức bên ngoài, LLM có thể khai thác khả năng của chính chúng để tìm kiếm kiến thức và thông tin cần thiết để thực hiện các nhiệm vụ liên quan mà không cần huấn luyện hoặc mô-đun bổ sung. Phương pháp suy luận tương tác của chúng tôi không chỉ có thể đưa kiến thức vào LLM một cách rõ ràng mà còn hướng dẫn LLM giải quyết các nhiệm vụ. Chúng tôi cũng chứng minh rằng sự cải thiện hiệu suất chủ yếu đến từ phương pháp suy luận được thiết kế đặc biệt của chúng tôi (cho zero-shot) và nhiệm vụ (cho finetuning) thay vì instruction tuning. Hiện tại, thực thể câu hỏi ban đầu cho phương pháp suy luận tương tác của chúng tôi được chọn ngẫu nhiên. Chúng tôi để dành cách chọn thực thể đầu tiên để khởi tạo thực hiện các nhiệm vụ cho nghiên cứu tiếp theo.

Tài liệu tham khảo
Bang, Y ., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H., Ji, Z., Yu, T., Chung, W., et al. (2023).
A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv
preprint arXiv:2302.04023 .

Bodenreider, O. (2004). The unified medical language system (umls): integrating biomedical terminology. Nucleic
acids research , 32(suppl_1):D267–D270.

Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G. B., Lespiau,
J.-B., Damoc, B., Clark, A., et al. (2022). Improving language models by retrieving from trillions of tokens. In
International conference on machine learning , pages 2206–2240. PMLR.

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,
Askell, A., et al. (2020). Language models are few-shot learners. Advances in neural information processing systems ,
33:1877–1901.

Chiang, W.-L., Li, Z., Lin, Z., Sheng, Y ., Wu, Z., Zhang, H., Zheng, L., Zhuang, S., Zhuang, Y ., Gonzalez, J. E., Stoica,
I., and Xing, E. P. (2023). Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.

Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C.,
Gehrmann, S., et al. (2022). Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 .

Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y ., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al.
(2022). Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416 .

Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for
language understanding. arXiv preprint arXiv:1810.04805 .

Du, Z., Qian, Y ., Liu, X., Ding, M., Qiu, J., Yang, Z., and Tang, J. (2022). GLM: general language model pretraining
with autoregressive blank infilling. pages 320–335.

Feng, Y ., Chen, X., Lin, B. Y ., Wang, P., Yan, J., and Ren, X. (2020). Scalable multi-hop relational reasoning for
knowledge-aware question answering. arXiv preprint arXiv:2005.00646 .

Guu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M. (2020). Retrieval augmented language model pre-training. In
International conference on machine learning , pages 3929–3938. PMLR.

Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly,
S. (2019). Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning , pages
2790–2799. PMLR.

Hu, E. J., Shen, Y ., Wallis, P., Allen-Zhu, Z., Li, Y ., Wang, S., Wang, L., and Chen, W. (2021). Lora: Low-rank
adaptation of large language models. arXiv preprint arXiv:2106.09685 .

Izacard, G. and Grave, E. (2020). Leveraging passage retrieval with generative models for open domain question
answering. arXiv preprint arXiv:2007.01282 .

Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y ., Ishii, E., Bang, Y . J., Madotto, A., and Fung, P. (2023). Survey of
hallucination in natural language generation. ACM Computing Surveys , 55(12):1–38.

Jin, D., Pan, E., Oufattole, N., Weng, W.-H., Fang, H., and Szolovits, P. (2021). What disease does this patient have? a
large-scale open domain question answering dataset from medical exams. Applied Sciences , 11(14):6421.

Koehn, P. and Knowles, R. (2017). Six challenges for neural machine translation. arXiv preprint arXiv:1706.03872 .
10

--- TRANG 11 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức

Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., and Soricut, R. (2019). Albert: A lite bert for self-supervised
learning of language representations. arXiv preprint arXiv:1909.11942 .

Lester, B., Al-Rfou, R., and Constant, N. (2021). The power of scale for parameter-efficient prompt tuning. arXiv
preprint arXiv:2104.08691 .

Levine, Y ., Dalmedigos, I., Ram, O., Zeldes, Y ., Jannai, D., Muhlgay, D., Osin, Y ., Lieber, O., Lenz, B., Shalev-Shwartz,
S., et al. (2022). Standing on the shoulders of giant frozen language models. arXiv preprint arXiv:2204.10019 .

Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V ., Goyal, N., Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T.,
et al. (2020a). Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information
Processing Systems , 33:9459–9474.

Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V ., Goyal, N., Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T.,
et al. (2020b). Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information
Processing Systems , 33:9459–9474.

Li, X. L. and Liang, P. (2021). Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint
arXiv:2101.00190 .

Lin, B. Y ., Chen, X., Chen, J., and Ren, X. (2019). Kagnet: Knowledge-aware graph networks for commonsense
reasoning. arXiv preprint arXiv:1909.02151 .

Lin, Z., Madotto, A., and Fung, P. (2020). Exploring versatile generative language model via parameter-efficient transfer
learning. arXiv preprint arXiv:2004.03829 .

Liu, Y ., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V . (2019).
Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 .

Lv, S., Guo, D., Xu, J., Tang, D., Duan, N., Gong, M., Shou, L., Jiang, D., Cao, G., and Hu, S. (2020). Graph-based
reasoning over heterogeneous external knowledge for commonsense question answering. In Proceedings of the AAAI
conference on artificial intelligence , volume 34, pages 8449–8456.

Maynez, J., Narayan, S., Bohnet, B., and McDonald, R. (2020). On faithfulness and factuality in abstractive summarization. arXiv preprint arXiv:2005.00661 .

Mihaylov, T., Clark, P., Khot, T., and Sabharwal, A. (2018). Can a suit of armor conduct electricity? a new dataset for
open book question answering. arXiv preprint arXiv:1809.02789 .

Min, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. (2020). Ambigqa: Answering ambiguous open-domain
questions. arXiv preprint arXiv:2004.10645 .

Moslem, Y ., Haque, R., and Way, A. (2023). Adaptive machine translation with large language models. arXiv preprint
arXiv:2301.13294 .

Muennighoff, N., Wang, T., Sutawika, L., Roberts, A., Biderman, S., Scao, T. L., Bari, M. S., Shen, S., Yong,
Z.-X., Schoelkopf, H., et al. (2022). Crosslingual generalization through multitask finetuning. arXiv preprint
arXiv:2211.01786 .

OpenAI (2023a). Gpt-4 technical report.

OpenAI, R. (2023b). Gpt-4 technical report. arXiv , pages 2303–08774.

Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A.,
et al. (2022). Training language models to follow instructions with human feedback. Advances in Neural Information
Processing Systems , 35:27730–27744.

Peng, B., Alcaide, E., Anthony, Q., Albalak, A., Arcadinho, S., Cao, H., Cheng, X., Chung, M., Grella, M., GV , K. K.,
et al. (2023a). Rwkv: Reinventing rnns for the transformer era. arXiv preprint arXiv:2305.13048 .

Peng, B., Galley, M., He, P., Cheng, H., Xie, Y ., Hu, Y ., Huang, Q., Liden, L., Yu, Z., Chen, W., et al. (2023b). Check
your facts and try again: Improving large language models with external knowledge and automated feedback. arXiv
preprint arXiv:2302.12813 .
11

--- TRANG 12 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức

Qin, C., Zhang, A., Zhang, Z., Chen, J., Yasunaga, M., and Yang, D. (2023). Is chatgpt a general-purpose natural
language processing task solver? arXiv preprint arXiv:2302.06476 .

Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al. (2018). Improving language understanding by generative
pre-training.

Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li, W., and Liu, P. J. (2020). Exploring
the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research ,
21(1):5485–5551.

Ram, O., Levine, Y ., Dalmedigos, I., Muhlgay, D., Shashua, A., Leyton-Brown, K., and Shoham, Y . (2023). In-context
retrieval-augmented language models. arXiv preprint arXiv:2302.00083 .

Raunak, V ., Menezes, A., and Junczys-Dowmunt, M. (2021). The curious case of hallucinations in neural machine
translation. arXiv preprint arXiv:2104.06683 .

Rohrbach, A., Hendricks, L. A., Burns, K., Darrell, T., and Saenko, K. (2018). Object hallucination in image captioning.
arXiv preprint arXiv:1809.02156 .

Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ili ´c, S., Hesslow, D., Castagné, R., Luccioni, A. S., Yvon, F., Gallé, M., et al.
(2022). Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100 .

Singhal, K., Tu, T., Gottweis, J., Sayres, R., Wulczyn, E., Hou, L., Clark, K., Pfohl, S., Cole-Lewis, H., Neal,
D., et al. (2023). Towards expert-level medical question answering with large language models. arXiv preprint
arXiv:2305.09617 .

Speer, R., Chin, J., and Havasi, C. (2017). Conceptnet 5.5: An open multilingual graph of general knowledge. In
Proceedings of the AAAI conference on artificial intelligence , volume 31.

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: a simple way to
prevent neural networks from overfitting. The journal of machine learning research , 15(1):1929–1958.

Sun, T., Zhang, X., He, Z., Li, P., Cheng, Q., Yan, H., Liu, X., Shao, Y ., Tang, Q., Zhao, X., Chen, K., Zheng, Y ., Zhou,
Z., Li, R., Zhan, J., Zhou, Y ., Li, L., Yang, X., Wu, L., Yin, Z., Huang, X., and Qiu, X. (2023). Moss: Training
conversational language models from synthetic data.

Talmor, A., Herzig, J., Lourie, N., and Berant, J. (2018). Commonsenseqa: A question answering challenge targeting
commonsense knowledge. arXiv preprint arXiv:1811.00937 .

Taori, R., Gulrajani, I., Zhang, T., Dubois, Y ., Li, X., Guestrin, C., Liang, P., and Hashimoto, T. B. (2023). Stanford
alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca .

Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E.,
Azhar, F., et al. (2023a). Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 .

Touvron, H., Martin, L., Stone, K. R., Albert, P., Almahairi, A., Babaei, Y ., Bashlykov, N., Batra, S., Bhargava, P.,
Bhosale, S., Bikel, D. M., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W.,
Fuller, B., Gao, C., Goswami, V ., Goyal, N., Hartshorn, A. S., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V .,
Khabsa, M., Kloumann, I. M., Korenev, A. V ., Koura, P. S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y .,
Mao, Y ., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y ., Poulton, A., Reizenstein, J., Rungta, R., Saladi,
K., Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X., Tang, B., Taylor, R., Williams, A., Kuan, J. X.,
Xu, P., Yan, Z., Zarov, I., Zhang, Y ., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and
Scialom, T. (2023b). Llama 2: Open foundation and fine-tuned chat models. ArXiv , abs/2307.09288.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. (2017).
Attention is all you need. Advances in neural information processing systems , 30.

Vinyals, O. and Le, Q. (2015). A neural conversational model. arXiv preprint arXiv:1506.05869 .

Wang, B. (2021). Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX.
https://github.com/kingoflolz/mesh-transformer-jax .

Wei, J., Bosma, M., Zhao, V . Y ., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V . (2021). Finetuned
language models are zero-shot learners. arXiv preprint arXiv:2109.01652 .
12

--- TRANG 13 ---
Knowledge Solver: Dạy LLM Tìm kiếm Kiến thức Lĩnh vực từ Đồ thị Kiến thức

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V ., Zhou, D., et al. (2022). Chain-of-
thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems ,
35:24824–24837.

Wishart, D. S., Feunang, Y . D., Guo, A. C., Lo, E. J., Marcu, A., Grant, J. R., Sajed, T., Johnson, D., Li, C., Sayeeda,
Z., et al. (2018). Drugbank 5.0: a major update to the drugbank database for 2018. Nucleic acids research ,
46(D1):D1074–D1082.

Yang, X., Li, Y ., Zhang, X., Chen, H., and Cheng, W. (2023). Exploring the limits of chatgpt for query or aspect-based
text summarization. arXiv preprint arXiv:2302.08081 .

Yang, Z., Dai, Z., Yang, Y ., Carbonell, J., Salakhutdinov, R. R., and Le, Q. V . (2019). Xlnet: Generalized autoregressive
pretraining for language understanding. Advances in neural information processing systems , 32.

Yasunaga, M., Bosselut, A., Ren, H., Zhang, X., Manning, C. D., Liang, P. S., and Leskovec, J. (2022). Deep
bidirectional language-knowledge graph pretraining. Advances in Neural Information Processing Systems , 35:37309–
37323.

Yasunaga, M., Ren, H., Bosselut, A., Liang, P., and Leskovec, J. (2021). Qa-gnn: Reasoning with language models and
knowledge graphs for question answering. arXiv preprint arXiv:2104.06378 .

Zeng, A., Liu, X., Du, Z., Wang, Z., Lai, H., Ding, M., Yang, Z., Xu, Y ., Zheng, W., Xia, X., et al. (2022). Glm-130b:
An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414 .

Zhang, T., Ladhak, F., Durmus, E., Liang, P., McKeown, K., and Hashimoto, T. B. (2023). Benchmarking large language
models for news summarization. arXiv preprint arXiv:2301.13848 .

Zhang, X., Bosselut, A., Yasunaga, M., Ren, H., Liang, P., Manning, C. D., and Leskovec, J. (2022). Greaselm: Graph
reasoning enhanced language models for question answering. arXiv preprint arXiv:2201.08860 .
13

# 2212.05276.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2212.05276.pdf
# Kích thước tệp: 424795 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Truy xuất Tài liệu Đa-bước Tự hồi quy được Hướng dẫn bởi Logic Tự nhiên
cho Xác minh Sự thật
Rami Aly
University of Cambridge
Department of Computer Science
and Technology
rami.aly@cl.cam.ac.ukAndreas Vlachos
University of Cambridge
Department of Computer Science
and Technology
andreas.vlachos@cl.cam.ac.uk
Tóm tắt
Một thành phần chính của xác minh sự thật là
truy xuất bằng chứng, thường từ nhiều tài liệu.
Các phương pháp gần đây sử dụng biểu diễn
dày đặc và điều kiện việc truy xuất mỗi tài liệu
dựa trên những tài liệu đã được truy xuất trước đó.
Bước sau được thực hiện trên tất cả các tài liệu
trong bộ sưu tập, yêu cầu lưu trữ biểu diễn dày đặc
của chúng trong một chỉ mục, do đó tạo ra lượng
bộ nhớ lớn. Một mô hình thay thế là truy xuất-và-
xếp hạng lại, trong đó các tài liệu được truy xuất
bằng các phương pháp như BM25, các câu của
chúng được xếp hạng lại, và các tài liệu khác được
truy xuất có điều kiện dựa trên những câu này,
giảm yêu cầu bộ nhớ. Tuy nhiên, những phương
pháp như vậy có thể dễ hỏng vì chúng dựa vào
phương pháp thử nghiệm và giả định có siêu liên
kết giữa các tài liệu. Chúng tôi đề xuất một phương
pháp truy xuất-và-xếp hạng lại mới cho truy xuất
đa-bước, bao gồm một bộ truy xuất chấm điểm
chung các tài liệu trong nguồn tri thức và các câu
từ những tài liệu đã được truy xuất trước đó sử
dụng công thức tự hồi quy và được hướng dẫn
bởi một hệ thống chứng minh dựa trên logic tự
nhiên tự động kết thúc quá trình truy xuất nếu
bằng chứng được coi là đủ. Phương pháp này cạnh
tranh với các phương pháp tiên tiến hiện tại trên
FEVER, HoVer và FEVEROUS-S, trong khi sử
dụng ít bộ nhớ hơn 5 đến 10 lần so với các hệ
thống cạnh tranh. Đánh giá trên một tập dữ liệu
đối nghịch cho thấy sự ổn định được cải thiện của
phương pháp chúng tôi so với các phương pháp
dựa trên ngưỡng thường được triển khai. Cuối
cùng, hệ thống chứng minh giúp con người dự
đoán quyết định của mô hình chính xác hơn thường
xuyên hơn so với chỉ sử dụng bằng chứng.
1 Giới thiệu
Với khối lượng ngày càng tăng của các tuyên bố
có thể gây hiểu lầm và sai sự thật (Graves, 2018),
xác minh sự thật tự động (Hardalov et al., 2022;
Guo et al., 2022) đang ngày càng được quan tâm.
Một thành phần chính của các hệ thống xác minh
sự thật miền mở là truy xuất các tài liệu liên quan
từ một cơ sở tri thức (KB)Tuyên bố: Giải Emmy Primetime lần thứ 66 được tổ chức bởi
một diễn viên hài Iraq sinh năm 1973.
Tài liệu Bằng chứng:
Giải Emmy Primetime lần thứ 66
Giải Emmy Primetime lần thứ 66 vinh danh những điều tốt nhất trong
chương trình truyền hình giờ vàng của Hoa Kỳ từ ngày 1 tháng 6
năm 2013 đến ngày 31 tháng 5 năm 2014, được chọn bởi Viện Hàn lâm
Nghệ thuật và Khoa học Truyền hình. Diễn viên hài và người dẫn chương trình Late Night
Seth Meyers đã tổ chức lễ trao giải lần đầu tiên.
Seth Meyers
Seth Adam Meyers (sinh ngày 28 tháng 12 năm 1973) là một
diễn viên hài, nhà văn, nhà sản xuất, bình luận viên chính trị
người Mỹ, diễn viên, nhà phê bình truyền thông và người dẫn chương trình truyền hình. Anh
dẫn chương trình Late Night with Seth Meyers, một chương trình trò chuyện đêm khuya
trên NBC. Trước đó, anh là thành viên diễn xuất và trưởng nhóm
biên kịch cho Saturday Night Live của NBC (2001–2014).
Phán quyết: Bị bác bỏ
Hình 1: Một ví dụ FEVER trong đó cần nhiều tài
liệu để xác minh (bằng chứng liên quan màu đỏ).

cung cấp bằng chứng cần thiết hỗ trợ hoặc bác bỏ
một tuyên bố. Độ chính xác truy xuất bằng chứng
tương quan mạnh với độ chính xác kiểm tra sự thật,
như đã quan sát trong một nhiệm vụ chia sẻ gần đây
(Aly et al., 2021b).
Truy xuất tài liệu cho xác minh sự thật có thể
phức tạp, vì bằng chứng cần thiết thường được tìm
thấy trong nhiều tài liệu, với mỗi tài liệu chứa
thông tin một phần cần thiết để đánh giá tính xác
thực của một tuyên bố. Một ví dụ được hiển thị
trong Hình 1. Với tuyên bố "Giải Emmy Primetime
lần thứ 66 được tổ chức bởi một diễn viên hài Iraq
sinh năm 1973.", thông tin từ hai tài liệu phải được
xem xét để xác minh tuyên bố: một đề cập đến
người đã tổ chức Giải thưởng, và một khác cung
cấp thông tin về người này. Bản thân tuyên bố
thường không dẫn đến tài liệu thứ hai, và nó thậm
chí còn gây hiểu lầm vì nó đề cập đến thông tin
không chính xác sẽ truy xuất các tài liệu không
liên quan (tức là về các diễn viên hài Iraq). Thay
vào đó, chúng ta cần điều kiện việc truy xuất một
số phần bằng chứng dựa trên bằng chứng khácarXiv:2212.05276v1  [cs.CL]  10 Dec 2022

--- TRANG 2 ---
Bộ Truy xuất
Tự hồi quySố liệu Logic Tự nhiên
Đủ Bằng chứng Bộ Tạo
Chứng minh
Seth MeyerĐủ không?Giải Emmy Primetime lần thứ 66
Bộ Xếp hạng lại CâuJack McBrayer (sinh ngày 27 tháng 5 năm 1973)
là một diễn viên và diễn viên hài người Mỹ
...James McBrayer1
James McBrayer
Kenneth ParcellGiải Emmy Primetime lần thứ 66.1
2Tom BergeronJames McBrayer1
2
3
Tài liệu Et
 
Tom Bergeron (sinh ngày 6 tháng 5 năm 1955) là
một nhân vật truyền hình người Mỹ ...
Diễn viên hài và người dẫn chương trình Late Night Seth
Meyers đã tổ chức lễ trao giải lần đầu tiên.Giải Emmy Primtime lần thứ 663Tom Bergeron2Tuyên bố: Giải Emmy Primetime lần thứ 66 được tổ chức bởi một diễn viên hài Iraq sinh năm 1973.
Tài liệu Dt
3
4
Dt+1DtHình 2: Quy trình AdMIRaL. Tại bước t, cho tuyên bố và các câu Et từ tài liệu Dt, một chứng minh được
tạo ra để dự đoán liệu bằng chứng Et có đủ để xác minh hay liệu cần thêm bằng chứng. Nếu đủ, bộ truy xuất dừng,
ngược lại, bộ truy xuất tự hồi quy của chúng tôi chấm điểm các tài liệu trong KB cùng với Et cập nhật các tài liệu
thành Dt+1, trước khi chúng được chuyển đến bộ xếp hạng lại câu để có được Et+1.

tài liệu, (tức là Seth Meyers là người dẫn chương
trình của Giải Emmy Primetime lần thứ 66).
Các phương pháp gần đây cho truy xuất đa-bước
cho xác minh sự thật thường sử dụng biểu diễn
dày đặc cho cả tuyên bố và tài liệu, và điều kiện
việc truy xuất mỗi tài liệu dựa trên những tài liệu
đã được truy xuất trước đó (Xiong et al., 2021;
Khattab et al., 2021). Sau mỗi lần lặp (bước), biểu
diễn tuyên bố được sửa đổi và so sánh với toàn bộ
KB, cần thiết để lưu trữ tất cả biểu diễn tài liệu
trong một chỉ mục dày đặc. Tuy nhiên, thường
hàng triệu tài liệu được xem xét, do đó chỉ mục
dày đặc có lượng bộ nhớ lớn (xem Bảng 1).
Một mô hình thay thế là Truy xuất và Xếp hạng
lại (RnR) (Nie et al., 2019; Stammbach, 2021;
Malon, 2021), trong đó các tài liệu ứng viên được
truy xuất, các câu từ chúng được xếp hạng lại, và
sau đó có điều kiện dựa trên các câu xếp hạng cao
nhất, các tài liệu bổ sung được truy xuất. Bằng
cách truy xuất các tài liệu ứng viên sử dụng bộ
truy xuất thưa thớt (ví dụ BM25), một chỉ mục
dày đặc trở nên không cần thiết, trong khi một
bộ xếp hạng lại dày đặc vẫn có thể được sử dụng
để tận dụng biểu diễn dày đặc. Tuy nhiên, để đạt
được hiệu suất đa-bước cạnh tranh, các hệ thống
RnR giả định có liên kết giữa các tài liệu và dựa
vào phương pháp thử nghiệm, chẳng hạn như giảm
trọng số các tài liệu có siêu liên kết bằng một hệ
số cố định, giả định bằng chứng từ lần lặp đầu tiên
quan trọng hơn. Phương pháp thử nghiệm có thể
không tổng quát hóa tốt qua các tập dữ liệu, và
trong khi các liên kết giữa tài liệu có lợi khi có
sẵn (ví dụ trong Wikipedia), nhiều KB văn bản
không có chúng.
Tập dữ liệu
Mô hình HoVer FEVER FEVEROUS-S
BM25 3.0GB 6.1GB 20.4GB
MDR 32.1GB 72.8GB –
ColBERT 81.3GB – –
ColBERTv2 16.0GB 34.4GB 124.2GB
AdMIRaL (Của chúng tôi) 3.3GB 6.4GB 20.7GB
Bảng 1: Lượng bộ nhớ cho các tập dữ liệu khác nhau
của một số mô hình truy xuất thưa/dày đặc. FEVER/HoVer
chỉ xem xét phần giới thiệu Wikipedia, trong khi FEVEROUS-S
bao gồm toàn bộ trang Wikipedia.

Để giải quyết những thách thức này, chúng tôi đề xuất
AdMIRaL (Truy xuất Thông tin Đa-bước Tài liệu
Tự hồi quy với Hướng dẫn Logic Tự nhiên), một
bộ truy xuất tài liệu đa-bước mới cho RnR bao gồm
hai thành phần: i) một bộ truy xuất chấm điểm chung
các tài liệu trong KB và các câu được xếp hạng lại
từ những tài liệu đã được truy xuất trước đó sử dụng
công thức tự hồi quy (De Cao et al., 2021), ii) một
hệ thống chứng minh sử dụng Logic Tự nhiên
(MacCartney và Manning, 2014) để đánh giá tính
đủ của bằng chứng được truy xuất để xác minh một
tuyên bố đã cho, và kết thúc việc truy xuất các tài
liệu khác. Phương pháp được minh họa trong Hình 2.
Bằng cách truy xuất sử dụng công thức tự hồi quy,

--- TRANG 3 ---
tạo ra các định danh tài liệu và câu cùng nhau từ
từng token và chỉ có điều kiện dựa trên ngữ cảnh,
AdMIRaL không cần lưu trữ biểu diễn dày đặc
trong một chỉ mục. Hệ thống chứng minh kiểm soát
việc hợp nhất các tài liệu bằng chứng giữa các bước
trong khi trung thực và có thể giải thích được đối
với hoạt động của hệ thống trong mỗi bước.
Chúng tôi cải thiện độ gọi lại tài liệu và F1 lần
lượt 1.4% và 4.6% so với hiệu suất tiên tiến trên
FEVER (Thorne et al., 2018), và cạnh tranh với
hiệu suất tiên tiến trên HoVer (Jiang et al., 2020)
và phiên bản chỉ câu của FEVEROUS (tức là loại
trừ bảng) (Aly et al., 2021a), trong khi sử dụng
ít bộ nhớ hơn 5 đến 10 lần so với các hệ thống
truy xuất dày đặc cạnh tranh và độ phức tạp thời
gian chạy thuận lợi hơn khi mở rộng quy mô đến
các KB lớn. Chúng tôi tiếp tục đánh giá tính bền
vững của AdMIRaL trên một phiên bản đối nghịch
của FEVER (Hidey et al., 2020), và cho thấy cải
thiện hiệu suất sử dụng các bộ truy xuất ban đầu
khác nhau. Cuối cùng, đánh giá của con người cho
thấy các chứng minh logic tự nhiên giúp con người
dự đoán quyết định của mô hình chính xác hơn
thường xuyên hơn so với chỉ sử dụng bằng chứng
trực tiếp.¹
2 Công trình Liên quan
Các phương pháp sớm cho truy xuất tài liệu đa-bước
cho xác minh sự thật tự động dựa trên mô hình RnR.
Chúng sử dụng các bộ truy xuất thưa thớt hoặc dựa
trên liên kết thực thể để tìm các tài liệu ứng viên
(ví dụ (Hanselowski et al., 2018)), xếp hạng lại
các câu trong công thức phân loại (như ESIM
(Thorne et al., 2018) hoặc bộ mã hóa được huấn
luyện trước (Liu et al., 2020; Zhong et al., 2020)),
và sử dụng siêu liên kết để tìm các tài liệu bổ sung
(Nie et al., 2019; Stammbach và Neumann, 2019).
Các phương pháp nói trên bị giới hạn ở hai lần lặp,
sử dụng siêu liên kết được trích xuất từ danh sách
ban đầu của các câu ứng viên để được xem xét
như các tài liệu bổ sung trong lần lặp thứ hai. Giả
định rằng bằng chứng từ lần lặp đầu tiên (tức là
truy xuất ban đầu) quan trọng hơn, Stammbach
(2021) giảm trọng số các tài liệu có siêu liên kết
bằng một hệ số cố định. Malon (2021) đề xuất sử
dụng một mô hình tạo sinh tưởng tượng ra các câu
bằng chứng bị thiếu và chọn các câu mới dựa trên
sự trùng lặp từ. Cải thiện gián tiếp đến RnR đa-bước
được đạt được thông qua các mô hình truy xuất tài
liệu mạnh hơn, như GENRE (De Cao et al., 2021),
hoặc các bộ xếp hạng lại chính xác hơn (Stammbach,
2021; Jiang et al., 2021a).

¹https://github.com/Raldir/AdMIRaL

GENRE đặc biệt tạo ra kết quả tiên tiến về truy
xuất tài liệu cho xác minh sự thật, bằng cách tạo
ra các tài liệu sử dụng công thức tự hồi quy, không
cần thiết một chỉ mục dày đặc.
Truy xuất đoạn văn dày đặc đa-bước (MDR)
(Xiong et al., 2021) lặp đi lặp lại truy xuất các tài
liệu bằng chứng sử dụng truy xuất đoạn văn dày
đặc (DPR) (Karpukhin et al., 2020), một bộ mã
hóa đôi mã hóa tuyên bố và tài liệu riêng biệt và
sử dụng tìm kiếm tích vô hướng tối đa hiệu quả
để chấm điểm mỗi tài liệu trong KB. Vì không gian
tìm kiếm tăng theo cấp số nhân với mỗi lần lặp theo
số lượng tài liệu trong KB, MDR sử dụng tìm kiếm
chùm tia để cắt tỉa không gian tìm kiếm một cách
tích cực, điều này làm giảm khả năng mở rộng quy
mô đến nhiều bước. Ngược lại, bộ truy xuất Baleen
của Khattab et al. (2021) thực hiện truy xuất tài
liệu đa-bước bằng cách nén các tài liệu được truy
xuất sau mỗi lần lặp thành một ngữ cảnh nén (tức
là (các) câu) được sử dụng để cập nhật biểu diễn
dày đặc của tuyên bố, giảm không gian tìm kiếm
bằng cách bỏ qua tất cả các ứng viên khác. Trong
khi nén tương tự như bước xếp hạng lại của RnR,
Baleen sau đó vẫn chấm điểm mỗi tài liệu trong
KB tại mỗi bước, như MDR. Họ tiếp tục đề xuất
tương tác muộn (FLIPR), cho phép các phần khác
nhau của tuyên bố khớp với các phần liên quan
khác nhau của tài liệu. Biểu thị thách thức của
việc mở rộng quy mô đến các KB lớn là trong số
12 hệ thống được gửi đến nhiệm vụ chia sẻ
FEVEROUS (Aly et al., 2021b), với FEVEROUS
là tập dữ liệu xác minh sự thật có KB lớn nhất),
không có hệ thống nào chọn sử dụng chỉ mục
truy xuất dày đặc.
Ngoài xác minh sự thật, trong trả lời câu hỏi
(QA), các mô hình truy xuất dựa trên đồ thị phức
tạp đã được đề xuất để sử dụng rõ ràng các liên
kết trong KB (Asai et al., 2020; Li et al., 2021).
Đặc biệt liên quan là phương pháp của (Qi et al.,
2021), sử dụng phản hồi của người đọc sau mỗi
lần lặp để xác định liệu câu trả lời đã được truy
xuất và đủ chưa, do đó xác định số lượng bước
một cách động thay vì cố định trước. Trong điểm
chuẩn QA của họ, tất cả câu trả lời cho các câu
hỏi có thể được tìm thấy trong nguồn; tuy nhiên
trong nhiều tập dữ liệu xác minh sự thật, một
thách thức chính bao gồm các tuyên bố không thể
được xác minh sử dụng KB. Hơn nữa, như đã giải
thích, thông tin sai được đề cập trong các tuyên
bố có thể gây hiểu lầm, làm cho tiêu chí dừng dựa
trên tính đủ cho kiểm tra sự thật trở nên thách
thức hơn.

--- TRANG 4 ---
3 AdMIRaL
Cho một KB bao gồm các tài liệu D, nhiệm vụ
truy xuất tài liệu cho xác minh sự thật là tìm tập
tài liệu D*={d1;:::;dn}⊆D đủ để hỗ trợ hoặc bác
bỏ một tuyên bố c.² Chúng tôi giả định rằng mỗi
tài liệu được liên kết với một tiêu đề tài liệu duy
nhất, theo công trình trước đây (De Cao et al.,
2021). Trong trường hợp truy xuất đa-bước n phải
lớn hơn 1. Trong mô hình RnR, việc truy xuất được
thực hiện trong ba bước: (i) tìm và trả về k tập tài
liệu có điểm cao nhất Dt={D1t;:::Dit:::Dkt}, với
t là lần lặp truy xuất hiện tại, với t≥1 và |Dit|=t,
và Di1 là tập tài liệu đơn-bước xếp thứ i có độ dài
1 (tức là một tài liệu duy nhất), (ii) xếp hạng lại
các câu từ k tập tài liệu trong Dt thành l câu hàng
đầu Et, iii) sử dụng Et để cập nhật tập các chuỗi
tài liệu thành Dt+1. Bước hai và ba sau đó được
lặp lại tổng cộng n bước. Vì n không được biết
trước cho một tuyên bố đã cho, công trình trước
đây đặt n thành một giới hạn trên của tập dữ liệu.
AdMIRaL thực hiện bước thứ ba của RnR trong
hai giai đoạn: (i) việc truy xuất Dt+1 bằng cách
chấm điểm chung D và Et sử dụng một mô hình
tạo sinh trong khung tự hồi quy chú ý chéo qua
tuyên bố c và Et, (ii) một tiêu chí kết thúc truy
xuất động được công thức hóa như một nhiệm vụ
đánh giá tính đủ bằng chứng bằng cách tạo ra một
chứng minh Logic Tự nhiên (MacCartney và
Manning, 2014) dựa trên Proofver (Krishna et al.,
2022), do đó số lượng bước ndyn cho AdMIRaL
được xác định động cho mỗi tuyên bố dựa trên
bằng chứng Et, với ndyn≤n.

3.1 Truy xuất Tài liệu Tự hồi quy
Cho một tuyên bố c và các câu xếp hạng cao nhất
Et, chúng tôi công thức hóa AdMIRaL như một
bộ xếp hạng lại pointwise cho các tập tài liệu Dit+1
có độ dài t+1, tức là các tập chứa thêm một tài
liệu (bước) so với những tập trong Dt. Hàm chấm
điểm cho Dit+1 được định nghĩa chung trên Dit
và dt+1. Chúng tôi xem xét các câu Et là một xấp
xỉ của tất cả thông tin liên quan trong Dt về c,
nhưng ở dạng nhỏ gọn hơn nhiều. Do đó, chúng
tôi định nghĩa điểm của một tập tài liệu Dit là
tổng các điểm của tất cả

² Trong FEVER, nếu một tuyên bố được gắn nhãn với
không đủ bằng chứng (NEI) thì nó không có tài liệu nào
liên kết với nó, không giống như trong FEVEROUS và
HoVer (HoVer hợp nhất các trường hợp bị bác bỏ và NEI
thành một lớp, không được hỗ trợ).

các kết hợp câu cơ bản có thể có của nó:
score(Dit+1|c;Et)
=scored(d1;:::;dt;dt+1|c;Et)
=∑s1∈d1;:::;st∈dt scores(s1;:::st;dt+1|c;Et);
(1)
với dt+1∈D. Do đó Eq.1 chấm điểm Dit+1 chung
trên D và Et. Vì chúng tôi giả định tất cả thông
tin liên quan của Dt đều nằm trong Et, hàm chấm
điểm scores(S;dt+1|c;Et), với S={s1;:::;st}, chỉ
chấm điểm các tập {S;dt+1} trong đó tất cả các
câu của S đều nằm trong Et. Hàm chấm điểm được
tính toán sử dụng một mô hình tạo sinh với công
thức tự hồi quy trên các tiêu đề tài liệu duy nhất,
điều kiện điểm của dt+1 dựa trên S:
score(S;dt+1|c;Et)
=p(S|c;Et)p(dt+1|c;Et;S)
=∏u=1M p(qu|q<u;c;Et)
|{z}
p(S|c;Et)
∏m=1N p(ym|y<m;c;Et;S)
|{z}
p(dt+1|c;Et;S); (2)
, trong đó y là chuỗi token đại diện cho tiêu đề
của tài liệu dt+1, q là chuỗi token đại diện cho
các định danh câu (tức là id câu duy nhất được
mã hóa trong Et) của S, và θ là các tham số của
mô hình.
Mô hình chấm điểm là một kiến trúc dựa trên
transformer tạo sinh được huấn luyện trước, cụ
thể là BART (Lewis et al., 2020), cho phép chúng
tôi mã hóa chéo tuyên bố c và các câu Et trong
khi sử dụng khả năng hiểu biết ngôn ngữ và tri
thức của mô hình (Petroni et al., 2019; Radford
et al., 2019). Vì các chuỗi tài liệu được chấm điểm
chỉ sử dụng tuyên bố và thông tin Et, không cần
tính toán trước và lưu trữ biểu diễn tài liệu trong
một chỉ mục. Tuy nhiên, vì |D| rất lớn, việc tính
toán điểm cho mỗi tập {S;dt+1} là không khả thi,
thay vào đó chúng tôi sử dụng tìm kiếm chùm tia
để điều hướng không gian tìm kiếm một cách hiệu
quả, chỉ tìm kiếm q chuỗi xếp hạng cao nhất. Lưu
ý rằng tìm kiếm chùm tia để tạo sinh khác biệt
đáng kể so với cái được sử dụng cho truy xuất
lặp bởi Xiong et al. (2021): tìm kiếm của chúng
tôi là trên từ vựng của mô hình và sử dụng hoạt
động softmax để chấm điểm, không phải trên toàn
bộ KB với so sánh MIPS

--- TRANG 5 ---
Jack McBrayer (sinh ngày 27 tháng 5 năm 1973)
là một diễn viên và diễn viên hài người Mỹ James McBrayer
Diễn viên hài và người dẫn chương trình Late Night Seth
Meyers đã tổ chức lễ trao giải lần đầu tiên.
ProofVER Diễn viên hài lần đầu tiên lễ trao giải sinh 1973 Thiếu
Bằng chứng Vàng
Người Mỹ Diễn viên hài Seth Meyers (sinh ngày 28 tháng 12 năm 1973) là một diễn viên hài và nhà văn người Mỹ
Người Mỹ
Diễn viên hài Chứng minh cho Tính Không đủ Chứng minh cho Tính Đủ Giải Emmy Primetime lần thứ 66.
Giải Emmy Primetime lần thứ 66. được tổ chức
tổ chức bởi một Iraq
Diễn viên hài sinh năm 1973
Giải Emmy Prim.
Giải Emmy Prim. được tổ chức
tổ chức bởi một Iraq Diễn viên hài
Diễn viên hài sinh
lễ trao giải lần đầu tiên Giải Emmy Prim. Giải Emmy Prim. được tổ chức
tổ chức bởi một Iraq Diễn viên hài sinh năm 1973
1973 sinh Giải Emmy Primtime lần thứ 661
Tom Bergeron (sinh ngày 6 tháng 5 năm 1955) là
một nhân vật truyền hình người Mỹ ... Tom Bergeron2 3
Seth Meyers2 Tuyên bố: Giải Emmy Primetime lần thứ 66 được tổ chức bởi một diễn viên hài Iraq sinh năm 1973.
= = > = > = <
= = # # # = = = = Hình 3: Trái: Minh họa quá trình tạo ra các chứng minh đủ để huấn luyện. Đối với một tuyên bố đã cho, hai
chứng minh được tạo ra: một cho bằng chứng đủ và không đủ. Tính không đủ được dự đoán nếu và chỉ nếu bất kỳ
đột biến nào trong chuỗi chứng minh được gán toán tử độc lập.

so sánh giữa tất cả biểu diễn dày đặc, cái trước
hiệu quả hơn đáng kể với không gian tìm kiếm nhỏ
hơn nhiều. Vì trong giải mã truyền thống bất kỳ
token nào từ từ vựng có thể được tạo ra ở bất kỳ
vị trí nào, chúng tôi có thể tạo ra các chuỗi là các
định danh tài liệu/câu không tồn tại. Chúng tôi
theo De Cao et al. (2021) bằng cách ràng buộc
việc tạo sinh sử dụng một cây tiền tố (trie). Trong
thực tế, chúng tôi phải chuyển đổi giữa hai không
gian tìm kiếm: các định danh câu và tài liệu, vì
chúng tôi muốn đảm bảo rằng các định danh câu
được tạo ra trước để điều kiện việc tạo sinh d.
Chúng tôi đạt được điều này bằng cách sử dụng
giải mã đánh dấu ràng buộc động (De Cao et al.,
2021), trong đó các đánh dấu được sử dụng trong
quá trình mã hóa để chuyển đổi giữa các không
gian tìm kiếm. Các tập tài liệu xếp hạng q cao nhất
sau đó được trả về như Dt+1.
Huấn luyện Chúng tôi huấn luyện một mô hình
riêng biệt cho mỗi bước t sử dụng ước lượng khả
năng tối đa, theo tinh chỉnh Dịch Máy Thần kinh
của BART (Lewis et al., 2020), tính toán log xác
suất của một tiêu đề tài liệu (như một chuỗi token)
cho Eg và tuyên bố c. Cho một danh sách có thứ
tự các câu bằng chứng vàng Eg có độ dài m, với
m≤n, chúng tôi xem xét như đầu vào trong quá
trình huấn luyện m−1 phần tử bằng chứng đầu
tiên, và tiêu đề tài liệu của câu bằng chứng còn
lại là y. Trong các trường hợp không có thứ tự
rõ ràng của các câu bằng chứng, chúng tôi tạo ra
tất cả t−1 tổ hợp chia Eg thành dữ liệu đầu vào
và đầu ra. Xem phụ lục A.1 để biết chi tiết.

3.2 Tính Đủ Bằng chứng với Logic Tự nhiên
Để xác định liệu bằng chứng được truy xuất có đủ
cho tuyên bố đang được xác minh hay không, chúng
tôi tạo ra một chứng minh sử dụng logic tự nhiên
(MacCartney và Manning, 2014), lấy cảm hứng
từ công trình gần đây đã sử dụng nó cho xác minh
(Krishna et al., 2022). Cho một tuyên bố c và các
câu bằng chứng Et, một mô hình seq2seq tạo ra
một chứng minh theo chuỗi trong công thức tự
hồi quy, từ trái sang phải. Mỗi phần của tuyên bố
c được đột biến theo chuỗi thành một khoảng
bằng chứng của Et, với một hoạt động logic tự
nhiên (NatOp) định nghĩa bản chất của đột biến.
Chúng tôi xem xét bốn trong số bảy NatOp được
định nghĩa trong (MacCartney và Manning, 2014)
cho chứng minh đủ: tương đương (≡), phủ định
(¬), thay thế (∨), và độc lập (#). Xem Hình 3 để
xem ví dụ (góc dưới bên trái). Các đột biến giữa
các khoảng tương đương về ngữ nghĩa được gán
NatOp tương đương (≡), như Giải Emmy Primetime
lần thứ 66. Đột biến của khoảng tuyên bố bởi một
diễn viên hài Iraq được gán NatOp độc lập (#),
cho thấy không có khoảng bằng chứng liên quan
nào tồn tại trong Bằng chứng Et. Chúng tôi không
xem xét NatOp bao phủ (⊇), NatOp kéo theo tiến
(⊆) và NatOp kéo theo ngược (⊇) vì chúng không
phải là chỉ số kết luận cho tính đủ và có thể được
thay thế bằng độc lập cho mục đích của chúng tôi.
Ví dụ, Châu Phi⊆Tunisia đúng, nhưng cho một
tuyên bố "Ryan Gosling đã đến Châu Phi." và
bằng chứng "Ryan Gosling đã đến Tunisia.", cần
thêm bằng chứng liên kết Tunisia với Châu Phi
để bằng chứng

--- TRANG 6 ---
đủ.
Để xác định tính đủ dựa trên chứng minh được
tạo ra, chúng tôi xem xét chuỗi các toán tử được
gán cho mỗi đột biến. Chúng tôi dự đoán không
đủ nếu và chỉ nếu bất kỳ đột biến nào trong chuỗi
chứng minh được gán toán tử độc lập. Dự đoán
tính đủ dựa trên chứng minh là trung thực theo
cấu trúc và cung cấp dự đoán tính đủ có thể giải
thích cho các hệ thống đa-bước.
Vì các cặp tuyên bố-bằng chứng được chú thích
với các chứng minh logic tự nhiên cho dự đoán
tính đủ không có sẵn, chúng tôi tạo ra chúng. Đối
với mỗi tuyên bố, chúng tôi tạo ra hai chứng minh:
một dựa trên bằng chứng không đủ và một dựa trên
bằng chứng đủ (xem Hình 3). Cho bằng chứng
không đầy đủ và đầy đủ cho một tuyên bố, trước
tiên chúng tôi sử dụng ProofVER (Krishna et al.,
2022) để tạo ra các chứng minh ban đầu tương ứng.
Tuy nhiên, vì ProofVER đã được huấn luyện trên
dữ liệu được chú thích với phương pháp thử nghiệm
nhắm vào việc đánh giá tính xác thực của tuyên
bố, các NatOp của ProofVER chỉ định đột biến
không phù hợp cho mục đích dự đoán tính đủ của
bằng chứng. Do đó, chúng tôi gán lại các NatOp
trong mỗi chứng minh ban đầu để đảm bảo tính
nhất quán với tính đủ của bằng chứng đầu vào.
Đầu tiên, tất cả các NatOp kéo theo tiến/ngược
(⊆)/(⊇) được thay thế bằng các NatOp độc lập
(#). Sau đó chúng tôi sửa đổi ít NatOP nhất có
thể trong một chứng minh để đạt được dự đoán
(không) đủ chính xác. Đối với các chứng minh
cho thấy tính đủ của bằng chứng không đủ, chúng
tôi gán NatOp độc lập cho đột biến với các khoảng
tuyên bố và bằng chứng khác biệt nhất, được đo
bằng độ tương tự cosine của biểu diễn ngữ cảnh
trung bình tổng hợp của một mô hình ngôn ngữ
được huấn luyện trước. Nếu một chứng minh cho
thấy không đủ nhưng thực tế đủ, trước tiên chúng
tôi tìm kiếm các thuật ngữ tuyên bố/bằng chứng
trong nhiều từ điển (Wordnet (Miller, 1995), các
cặp Từ đồng nghĩa Từ trái nghĩa của (Roth và
Schulte im Walde, 2014), và PPDB (Pavlick et al.,
2015)) để tìm các khớp phù hợp, và sau đó thay
thế tất cả các NatOp độc lập còn lại bằng tương
đương nếu tuyên bố được hỗ trợ, hoặc phủ định
nếu bị bác bỏ.

4 Thiết lập Thí nghiệm
Tập dữ liệu Chúng tôi đánh giá bộ truy xuất tài
liệu đa-bước của chúng tôi trên FEVER (Thorne
et al., 2018), FEVEROUS (Aly et al., 2021a), và
HoVer (Jiang et al., 2020). FEVER bao gồm các
tuyên bố chủ yếu yêu cầu một câu bằng chứng duy
nhất (87%). Trái ngược với Xiong et al. (2021)
chỉ đánh giá trên phần đa-bước của FEVER, chúng
tôi báo cáo kết quả cho đa-bước và toàn bộ tập dữ
liệu; điều này thực tế hơn vì trong thực tế không
biết trước liệu một tuyên bố có yêu cầu truy xuất
tài liệu đa-bước hay không. HoVer chứa lần lượt
46%, 36%, và 18% các tuyên bố hai-bước, ba-bước,
và bốn-bước. Trái ngược với FEVER và HoVer chỉ
xem xét phần giới thiệu của các trang Wikipedia,
FEVEROUS xem xét toàn bộ bài viết Wikipedia,
bao gồm bằng chứng bán cấu trúc dưới dạng bảng
(ô) và chứa 16% tuyên bố đa-bước. Từ FEVEROUS
chúng tôi chỉ xem xét các tuyên bố yêu cầu duy
nhất bằng chứng câu, vì chúng tôi tập trung vào
truy xuất văn bản (FEVEROUS-S), chiếm khoảng
41% tuyên bố trong FEVEROUS.
Chi tiết Triển khai Mô hình tự hồi quy cho cả
truy xuất và tạo chứng minh là BART (Lewis et al.,
2020), được huấn luyện độc lập với nhau. Đối với
việc truy xuất ban đầu, trước tiên chúng tôi truy
xuất các ứng viên tài liệu D1 cho tất cả ba tập dữ
liệu bằng GENRE, được tinh chỉnh trên phiên bản
KILT của FEVER (Petroni et al., 2021), và BM25
dựa trên Pyserini (Lin et al., 2021). Để xếp hạng
lại các câu của những tài liệu này và giữ l=5 hàng
đầu trong E1, chúng tôi sử dụng mô hình lựa chọn
bằng chứng cấp token của (Stammbach, 2021) cho
FEVER, và bộ xếp hạng lại T5 pointwise của
(Jiang et al., 2021a) cho HoVer và FEVEROUS-S.
Đối với FEVER và FEVEROUS-S, chúng tôi xem
xét 10 tài liệu hàng đầu để xếp hạng lại trong khi
đối với HOVER chúng tôi tập trung vào 100 hàng
đầu, để giữ điểm so sánh được với công trình trước.

5 Kết quả
5.1 Truy xuất Tài liệu Đa-bước
Kết quả truy xuất tài liệu trên tập dev của mỗi tập
dữ liệu được hiển thị trong Bảng 2. Kết quả bao
gồm các bộ truy xuất đơn-bước, bao gồm truy xuất
thưa thớt (BM25), dựa trên thực thể (GENRE),
và truy xuất đoạn văn dày đặc (DPR). Chúng tôi
tiếp tục hiển thị điểm của bộ truy xuất đơn-bước
được sử dụng cho AdMIRaL, cụ thể là AdMIRaL
đơn-bước. Chúng tôi tiếp tục so sánh AdMIRaL
với các phương pháp truy xuất đa-bước tiên tiến,
bao gồm MDR, Baleen, và ColBERT-Hop (Khattab
et al., 2021), tất cả đều cần thiết một chỉ mục dày
đặc. Chúng tôi tiếp tục so sánh với một bộ truy
xuất RnR sử dụng rõ ràng siêu liên kết trong các
câu để truy xuất tài liệu mới, như đã làm trong
thiết lập đa-bước của Stammbach (2021). Yêu
cầu bộ nhớ và tính toán để chạy các bộ truy xuất
dày đặc trên FEVEROUS-S

--- TRANG 7 ---
Recall@5 Recall@100
Mô hình/Tập dữ liệu FEVER FEVEROUS-S HoVer
2-hop Overall 2-hop Overall 2-hop Overall
Đơn-bướcBM25 0.150 0.658 0.410 0.752 0.789 0.397
GENRE 0.191 0.892 0.330 0.705 0.382 0.107
AdMIRaL đơn-bước 0.357 0.928 0.441 0.799 0.886 0.470
DPR 0.191 0.754 – – – –
Đa-bướcSiêu liên kết 0.667 0.945 0.506 0.822 0.904 0.641
MDRy0.691 – – – – –
ColBERT-Hop– – – – 0.958 0.748
Baleen– – – – 0.977 0.922
AdMIRaL (Của chúng tôi) 0.705 0.956 0.610 0.847 0.977 0.817
Bảng 2: Điểm truy xuất tài liệu cho 2-hop và điểm tổng thể. Để so sánh với công trình trước trên HoVer, chúng
tôi báo cáo recall@100 cho các tuyên bố được hỗ trợ trên dev. y và ⋄ cho thấy kết quả được lấy từ Xiong et al.
(2021) và Khattab et al. (2021), tương ứng. Số in đậm cho thấy điểm tốt nhất và gạch dưới cho điểm tốt thứ hai.

vượt quá tài nguyên của chúng tôi (xem Phụ lục
A.2), do đó kết quả trên FEVEROUS-S chỉ được
tính cho RnR, tức là Jiang et al. (2021a) với siêu
liên kết, và các phương pháp đơn-bước. Như thấy
trong Bảng 2, AdMIRaL đạt được điểm recall
2-hop cao nhất trên tất cả các tập dữ liệu, và recall
tổng thể cao nhất trên FEVER và FEVEROUS-S,
chỉ thua Baleen trên HoVer. AdMIRaL cải thiện
recall 2-hop của việc truy xuất ban đầu 34.8% điểm
phần trăm trên FEVER, 16.9% trên FEVEROUS-S
và 9.1% trên HoVer. Đối với cái sau, điểm tổng
thể tăng thậm chí lớn hơn 34.7%, vì AdMIRaL
cải thiện việc truy xuất đáng kể cho các tuyên bố
HoVer yêu cầu hơn 2 bước. Hơn nữa, AdMIRaL
chính xác hơn các mô hình tiên tiến, đạt được cải
thiện F1 so với MDR trên FEVER 4.6% và so với
siêu liên kết trên FEVEROUS-S 14.2% (xem Phụ
lục A.3).

5.2 Hiệu quả
Lượng Bộ nhớ AdMIRaL đạt được hiệu suất cạnh
tranh tổng thể trong khi hiệu quả không gian hơn
một bậc độ lớn. Lượng bộ nhớ của AdMIRaL bao
gồm chỉ mục ngược cho việc truy xuất BM25 ban
đầu và cây tiền tố của các tiêu đề tài liệu (loại trừ
bản thân mô hình), dẫn đến lượng 3.3GB, 6.4GB
và 20.7GB cho HoVer, FEVER, và FEVEROUS-S,
tương ứng. Điều này ít hơn khoảng 10 lần so với
MDR, ít hơn 5 lần so với Baleen (ColBERTv2),
và ít hơn 27 lần so với ColBERT (xem Bảng 1),
vì những cái này cần thiết một chỉ mục dày đặc
của tất cả tài liệu trong KB. Lượng của AdMIRaL
có thể so sánh với các phương pháp RnR
(Stammbach, 2021), vì chỉ mục ngược chỉ có vài
trăm Megabyte, không đáng kể so với kích thước
của chỉ mục ngược.
Hiệu quả Thời gian chạy Độ phức tạp thời gian
chạy của một bộ truy xuất bao gồm hai thành phần:
bước (i) lập chỉ mục KB và (ii) bản thân việc truy
xuất.³ Vì AdMiRaL chỉ xây dựng một chỉ mục
BM25 cho việc truy xuất ban đầu - bước (i) - nhanh
hơn đáng kể so với các bộ truy xuất dày đặc như
Baleen. Cụ thể, mất 2 phút 32 giây để xây dựng
chỉ mục HoVer cho AdMIRaL (và cho bộ truy xuất
RnR của Stammbach), so với 290 phút 12 giây cho
chỉ mục dày đặc của Baleen. Đối với bước (ii),
AdMIRaL mở rộng quy mô tốt hơn các bộ truy
xuất dày đặc đối với cả kích thước KB và số lần
lặp. Các bộ truy xuất dày đặc như Baleen hoặc
MDR mở rộng quy mô theo O(n|D|), với |D| là
số tài liệu trong KB, vì chúng thực hiện so sánh
với tất cả tài liệu trong KB tại mỗi lần lặp trong
tổng số n lần lặp, với n là số lần lặp được đặt
thành một giới hạn trên. Ngược lại, đối với
AdMIRaL, chỉ việc truy xuất ban đầu phụ thuộc
vào kích thước của KB (tức là BM25), trong khi
việc truy xuất tự hồi quy tại mỗi bước phụ thuộc
vào kích thước từ vựng của mô hình, do đó
O(ndyn+|D|) (bao gồm việc truy xuất ban đầu,
ngược lại O(ndyn)), với ndyn≤n là số lần lặp theo
sự kết thúc động của AdMIRaL.⁴ Tuy nhiên, hằng
số cơ bản của AdMIRaL

³ Hiệu quả lập chỉ mục có liên quan vì nội dung của KB
thường xuyên cập nhật trong thế giới thực và do đó chỉ mục
cũng phải được cập nhật.
⁴ Giảm thời gian chạy thông qua sự kết thúc động với
AdMIRaL sẽ thách thức vì chi phí tính toán của bản thân
bộ tạo chứng minh ít nhất bằng bộ truy xuất tự hồi quy. Việc
điều tra cách sự kết thúc động có thể cải thiện hiệu quả truy
xuất đa-bước là một hướng tương lai thú vị để khám phá
nhưng nằm ngoài trọng tâm của AdMIRaL.

--- TRANG 8 ---
lớn vì nó dựa vào hai mô hình Encoder-Decoder
(truy xuất tự hồi quy + tạo chứng minh) và một
bộ xếp hạng lại câu làm cho nó tốn kém về tính
toán hơn khi được sử dụng trên các KB tương đối
nhỏ như HoVer. Chúng tôi đo được trung bình
2.87 giây cho một truy vấn HoVer duy nhất trên
AdMIRaL, 1.94 giây cho Baleen, và 0.69 giây cho
Stammbach (2021). Tuy nhiên, trên các KB lớn
(như FEVEROUS-S với kích thước gấp 7 lần
HoVer), thời gian chạy thuận lợi hơn cho AdMIRaL
so với Baleen. Trong khi yêu cầu bộ nhớ để chạy
Baleen trên FEVEROUS-S vượt quá tài nguyên
của chúng tôi, đã trên một KB có kích thước gấp
đôi HoVer, Baleen mất 2.30 giây, trong khi thời
gian chạy của AdMiRaL gần như không thay đổi
(2.88 giây).

6 Thảo luận
Tạo sinh Tự hồi quy Chúng tôi so sánh phương
pháp chấm điểm tài liệu tự hồi quy của AdMIRaL
với một số biến thể, cụ thể là một mô hình i) chỉ
xem xét câu hàng đầu của Et để chấm điểm và tạo
sinh (Top-1) ii) không chấm điểm tài liệu và câu
cùng nhau, thay vào đó nó chỉ chấm điểm tài liệu,
và các tài liệu xếp hạng cao nhất được nối với t
tài liệu xếp hạng cao nhất của Dt (Not-joint) iii)
chấm điểm một tập tài liệu được xếp hạng trực tiếp
(tức là chấm điểm Dt) (Joint-docs). Chúng tôi cũng
đánh giá một mô hình AdMIRaL khai thác thông
tin siêu liên kết bằng cách nối các siêu liên kết
của một câu vào cuối trước khi được chuyển làm
đầu vào. Kết quả được hiển thị trong Bảng 3. Trong
khi Top-1 đạt được điểm khớp chính xác so sánh
được với AdMIRaL (thậm chí cao hơn một chút
cho các tuyên bố hai-bước), recall của nó thấp hơn
đáng kể. Ngược lại, Not-joint đạt được recall cạnh
tranh, tuy nhiên, tụt hậu về độ chính xác khớp
chính xác, vì thứ tự ban đầu của các tài liệu xếp
hạng cao nhất trong Dt phần lớn không thay đổi.
Cuối cùng, Joint-docs hoạt động tệ nhất tổng thể,
có thể do khó khăn trong việc sắp xếp bằng chứng
trong quá trình huấn luyện, như cũng được quan
sát bởi (Xiong et al., 2021). Việc kết hợp thông
tin siêu liên kết vào AdMIRaL cải thiện recall đáng
kể, dẫn đến cải thiện tiên tiến FEVER đa-bước
0.16 điểm phần trăm.
Tính Bền vững Chúng tôi tiếp tục đánh giá tính
bền vững của mô hình bằng cách đánh giá AdMIRaL
trên một tập dữ liệu xác minh sự thật đối nghịch
DeSePtion (Hidey et al., 2020), bao gồm các cuộc
tấn công đối nghịch được tạo ra như một phần của
nhiệm vụ chia sẻ đối nghịch FEVER2.0 (Thorne
et al., 2019). Các cuộc tấn công xem xét các biến
thể/thay thế từ vựng, định danh thực thể, lý luận
thời gian (đa-bước), lý luận

FEVER
Mô hình R@5 EM
Hai-bước Overall Hai-bước Overall
Ban đầu 0.35 0.93 0.26 0.87
Top-1 0.67 0.94 0.52 0.88
Not-Joint 0.71 0.96 0.32 0.87
Joint-docs 0.59 0.94 0.43 0.87
Của chúng tôi 0.71 0.96 0.51 0.89
Của chúng tôi w/ siêu liên kết 0.85 0.97 0.51 0.89
Bảng 3: Điểm truy xuất tài liệu cho một số biến thể
của bộ truy xuất tự hồi quy được đề xuất, R@5: Recall@5,
EM: Độ chính xác Khớp chính xác.

đa giới từ và lý luận đa-bước. Kết quả cấp tài liệu
cho các mô hình được huấn luyện trên FEVER và
đánh giá trên DeSePtion được hiển thị trong Bảng 4.
AdMIRaL đạt được tăng đáng kể so với bộ truy
xuất ban đầu và một đường cơ sở BM25. Hơn nữa,
trong khi Not-joint đạt được recall tương tự với
AdMIRaL trên FEVER, nó hoạt động tệ hơn trên
tập dữ liệu đối nghịch. Điều này làm nổi bật tính
dễ vỡ của việc thêm tài liệu mới tĩnh vào các tài
liệu xếp hạng cao nhất sử dụng vị trí cố định hoặc
ngưỡng, như thường được thực hiện.

Tập dữ liệu
Mô hình FEVER FEVER-Đối nghịch
Hai-bước Overall Hai-bước Overall
RBan đầu 0.36 0.93 0.54 0.77
BM25 0.15 0.658 0.22 0.55
Not-Joint 0.71 0.96 0.72 0.84
Của chúng tôi 0.71 0.96 0.74 0.86
EMBan đầu 0.26 0.87 0.48 0.69
BM25 0.06 0.40 0.13 0.36
Not-Joint 0.32 0.87 0.50 0.71
Của chúng tôi 0.51 0.89 0.56 0.73
Bảng 4: Điểm truy xuất tài liệu trên tập dữ liệu đối
nghịch, R: Recall@5, EM: Độ chính xác Khớp chính xác.

Kết quả với các bộ truy xuất ban đầu khác nhau
Một khía cạnh khác chúng tôi phân tích là tính ổn
định của AdMIRaL với các bộ truy xuất ban đầu
khác nhau, tức là việc truy xuất E1. Kết quả được
hiển thị trong Bảng 5. Các cải thiện tương đối đạt
được bởi AdMIRaL nhất quán qua các bộ truy xuất,
cải thiện recall@5 cho BM25, KGAT (Liu et al.,
2020), và (Jiang et al., 2021b) (và (Stammbach,
2021) như được sử dụng trong AdMIRaL) trên
FEVER, trung bình 33% điểm phần trăm với
phương sai 0.0004.

Bộ truy xuất ban đầu Đơn-bước AdMIRaL
Hai-bước Overall Hai-bước Overall
BM25 0.065 0.486 0.370 0.780
KGAT 0.470 0.955 0.790 0.968
(Jiang et al., 2021a) 0.356 0.925 0.701 0.953
AdMIRaL 0.357 0.928 0.705 0.956
Bảng 5: Điểm truy xuất tài liệu sử dụng các phương
pháp khác nhau để truy xuất các câu bằng chứng ban đầu
E1, R: Recall@5. Lưu ý rằng KGAT bao gồm các tài liệu
vàng trước khi xếp hạng lại câu và do đó không được
xem xét trong các thí nghiệm chính của chúng tôi.

Chứng minh Đủ với Logic Tự nhiên Để đánh giá
hiệu quả của phương pháp dựa trên chứng minh
để xác định tính đủ bằng chứng, chúng tôi so sánh
AdMIRaL với bốn đường cơ sở: i) một mô hình
luôn luôn

--- TRANG 9 ---
xem xét bằng chứng là đầy đủ/không đầy đủ ii)
một bộ phân loại nhị phân (BART với đầu tuyến
tính) được huấn luyện để phân biệt đầu vào đầy
đủ với không đầy đủ iii) một chứng minh được
tạo bởi ProofVER iv) một chứng minh Natlog được
tạo ra chỉ bằng cách sử dụng tài nguyên từ vựng
và gán các đột biến không khớp NatOp độc lập.
Chúng tôi tiếp tục so sánh phương pháp của chúng
tôi với một oracle luôn luôn quyết định chính xác
liệu cần thêm bằng chứng hay không. Kết quả trên
FEVER được hiển thị trong Bảng 6. Ngoài recall@5
truy xuất, bảng hiển thị độ chính xác và recall
không đủ cho các tuyên bố đa-bước. Xem xét tất
cả bằng chứng là không đủ tương đương với việc
chạy bộ truy xuất của AdMIRaL cho một số lần
lặp cố định n. Kiểm tra đủ của AdMIRaL cải thiện
đáng kể trên nó, cũng vượt trội hơn các phương
pháp dự đoán đủ thay thế. Tuy nhiên, chúng tôi
cũng lưu ý rằng còn chỗ để cải thiện đáng kể vì
oracle vượt trội hơn phương pháp hiện tại của
chúng tôi về độ chính xác, điều này dẫn đến recall@5
truy xuất cao hơn đáng kể.

Mô hình FEVER Không đủ
Hai-bước Overall P R
Tất cả không đủ 0.69 0.95 0.59 1.0
Tất cả đủ 0.65 0.94 0.0 0.0
Bộ phân loại 0.69 0.94 0.61 0.87
ProofVER 0.68 0.96 0.61 0.76
Chỉ từ điển/KB 0.69 0.96 0.60 0.96
Của chúng tôi 0.71 0.96 0.70 0.93
Của chúng tôi w/ Oracle Merger 0.74 0.97 1.00 1.00
Bảng 6: Điểm truy xuất tài liệu, R: Recall@5, EM:
Khớp chính xác. Chúng tôi tiếp tục báo cáo điểm về
dự đoán không đủ về recall và độ chính xác.

7 Đánh giá Con người về Chứng minh
Đủ
Một lợi thế chính của AdMIRaL là khả năng giải
thích được bổ sung của bộ truy xuất đa-bước
thông qua dự đoán đủ dựa trên chứng minh. Ví
dụ, sau một bước truy xuất ban đầu, mô hình có
thể dự đoán không đủ bằng chứng, với khoảng
được chỉ ra là thông tin bị thiếu. Nếu mô hình
không thể tìm thấy thông tin liên quan trong bước
tiếp theo, người dùng có thể xem xét sửa đổi mục
tiêu của tuyên bố dựa trên chứng minh đủ để cho
phép mô hình theo một đường truy xuất khác.
Ngược lại, mô hình có thể sai lầm chỉ ra đủ bằng
chứng, vì vậy người dùng có thể thay thế quyết
định của mô hình một cách có thông tin.
Để khám phá khả năng giải thích của các chứng
minh đủ, chúng tôi tiến hành một thí nghiệm dự
đoán tiến (Doshi-Velez và Kim, 2017). Các đối
tượng con người được yêu cầu dự đoán liệu
AdMIRaL xem xét bằng chứng cho một tuyên bố
đã cho là đủ hay không, bằng cách sử dụng chứng
minh đủ được tạo ra. Đường cơ sở so sánh chỉ
cung cấp các câu bằng chứng thay thế. Vì chúng
tôi đang đánh giá chứng minh như một cơ chế giải
thích cho con người, chúng tôi đảm bảo rằng không
có đối tượng nào quen thuộc với bản chất xác định
của phương pháp. Để cho phép những người không
chuyên sử dụng chứng minh, chúng tôi thay thế
các NatOp bằng các cụm từ tiếng Anh, tương tự
như (Krishna et al., 2022) (xem Phụ lục A.4).
Đánh giá bao gồm 60 chú thích từ 6 đối tượng.
Mười tuyên bố, mỗi cái được ghép nối với một
chứng minh NatLog AdMIRaL và giải thích đường
cơ sở được chú thích bởi ba đối tượng. Không có
đối tượng nào chú thích cùng một tuyên bố cho
cả giải thích AdMIRaL và đường cơ sở, vì nếu
không một đối tượng có thể bị ảnh hưởng bởi giải
thích mà họ đã thấy trước đó cho cùng một tuyên
bố. Sử dụng các chứng minh đủ, các đối tượng
dự đoán chính xác quyết định của mô hình trong
70% trường hợp, so với 50% của đường cơ sở.
Sự đồng thuận giữa các chú thích viên cho cả giải
thích của AdMIRaL và đường cơ sở là κFleiss=0.80
(Fleiss, 1971). Hơn nữa, các chú thích viên dự
đoán hành vi của hệ thống sử dụng giải thích của
AdMIRaL nhanh hơn 20% so với đường cơ sở,
mất thời gian trung bình 51 giây, giảm xuống 24
giây sau 5 chú thích đầu tiên.

8 Kết luận
Bài báo này khám phá một mô hình Truy xuất và
Xếp hạng lại tự hồi quy cho truy xuất tài liệu đa-bước
được hướng dẫn bởi một hệ thống chứng minh dựa
trên logic tự nhiên tự động kết thúc quá trình truy
xuất nếu bằng chứng được truy xuất được coi là
đủ. Mô hình của chúng tôi chỉ gây ra lượng bộ nhớ
tối thiểu so với các mô hình truy xuất tiên tiến hiện
tại trong khi đạt được recall và F1 truy xuất cạnh
tranh. Đánh giá con người cho thấy chứng minh
được tạo ra như một điều kiện đủ có thể giải thích
được, cho phép con người-trong-vòng lặp trong
quá trình truy xuất của mô hình. Công việc tương
lai nhằm điều tra mức độ mà một mô hình xác minh
(tức là ProofVER) có thể thông báo việc truy xuất
bằng chứng trực tiếp, tạo ra một hệ thống vòng
kín đầu-cuối, cũng như các phương pháp con người-
trong-vòng lặp.

Lời cảm ơn
Công trình này được hỗ trợ bởi Chương trình Đào
tạo Tiến sĩ Hội đồng Nghiên cứu Khoa học Kỹ
thuật và Vật lý (EPSRC). Andreas Vlachos được
hỗ trợ bởi tài trợ ERC AVeriTeC (GA 865958) và
tài trợ EU H2020 MONITIO (GA 965576). Chúng
tôi cảm ơn Amrith Krishna đã cho chúng tôi tiếp
cận ProofVER, cả ông ấy và Nicola De Cao cho
những nhận xét và đề xuất hữu ích, và Dominik
Stammbach đã giúp tái tạo bộ truy xuất đa-bước
của họ. Hơn nữa, các tác giả muốn cảm ơn 6 đối
tượng đã tình nguyện tham gia đánh giá con người,
cụ thể là Youmna Farag, Zhijiang Guo, Sana Kidwai,
Pietro Lesci, Nedjma Ousidhoum, và Andre Schurat,
cũng như Christopher Bryant và Christoph Hüter
cho phản hồi sớm về khảo sát. Cuối cùng chúng
tôi cảm ơn các nhà đánh giá ẩn danh vì thời gian
và nỗ lực của họ trong việc đưa ra phản hồi về
bài báo của chúng tôi.

Hạn chế
Tất cả các điểm chuẩn được khám phá trong bài
báo sử dụng Wikipedia làm KB, đồng nhất so với
các nguồn không đồng nhất mà các nhà kiểm tra
sự thật chuyên nghiệp sử dụng (ví dụ bài báo tin
tức, bách khoa toàn thư, tài liệu khoa học). Các
phương pháp truy xuất của chúng tôi cũng tập
trung hoàn toàn vào bằng chứng không cấu trúc
dưới dạng câu, tuy nhiên, như đã chỉ ra, các tập
dữ liệu gần đây cũng xem xét các phương thức
khác. Hơn nữa, các tập dữ liệu được xây dựng
một cách rõ ràng sử dụng siêu liên kết trên
Wikipedia, do đó phương pháp của chúng tôi có
vẻ đặc biệt phù hợp với những điểm chuẩn này.
Tuy nhiên, chúng tôi không biết về một tập dữ
liệu xác minh sự thật quy mô lớn không chú thích
dữ liệu theo cách đó. Hơn nữa, trong khi logic
tự nhiên có thể giải thích được, tính biểu đạt của
nó bị hạn chế. Lý luận phức tạp hơn ví dụ liên
quan đến phạm vi thời gian hoặc số không phù
hợp với Logic Tự nhiên.

Tuyên bố Đạo đức
Chúng tôi dự đoán rằng hệ thống truy xuất của
chúng tôi sẽ được sử dụng trong các hệ thống
kiểm tra sự thật. Hệ thống truy xuất của chúng
tôi không đưa ra bất kỳ phán quyết nào về tính
đúng đắn của một tuyên bố trong thế giới thực
mà chỉ xem xét Wikipedia như nguồn bằng chứng
được sử dụng vì toàn bộ môi trường thí nghiệm
đã được giới hạn trong đó. Wikipedia là một tài
nguyên cộng tác tuyệt vời, nhưng nó có những
sai lầm và nhiễu riêng tương tự như bất kỳ bách
khoa toàn thư hoặc nguồn tri thức nào. Do đó
chúng tôi không khuyến khích người dùng sử dụng
hệ thống truy xuất của chúng tôi để đưa ra các
tuyên bố tuyệt đối về các tuyên bố đang được xác
minh, tức là tránh sử dụng nó để phát triển những
người nói sự thật.

Tài liệu tham khảo
Rami Aly, Zhijiang Guo, Michael Schlichtkrull,
James Thorne, Andreas Vlachos, Christos
Christodoulopoulos, Oana Cocarascu, và Arpit
Mittal. 2021a. FEVEROUS: Trích xuất Sự thật và
Xác minh Qua thông tin Không cấu trúc và Có
cấu trúc. Trong Hội nghị thứ ba mươi lăm về Hệ
thống Xử lý Thông tin Thần kinh Tập dữ liệu và
Điểm chuẩn Track (Vòng 1).
Rami Aly, Zhijiang Guo, Michael Sejr Schlichtkrull,
James Thorne, Andreas Vlachos, Christos
Christodoulopoulos, Oana Cocarascu, và Arpit
Mittal. 2021b. Nhiệm vụ chia sẻ trích xuất sự thật
và xác minh qua thông tin không cấu trúc và có
cấu trúc (FEVEROUS). Trong Proceedings of the
Fourth Workshop on Fact Extraction and VERiﬁcation
(FEVER), trang 1–13, Dominican Republic.
Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi,
Richard Socher, và Caiming Xiong. 2020. Học
để truy xuất các đường lý luận qua đồ thị wikipedia
cho trả lời câu hỏi. Trong 8th International Conference
on Learning Representations, ICLR 2020, Addis
Ababa, Ethiopia, April 26-30, 2020.
Nicola De Cao, Gautier Izacard, Sebastian Riedel, và
Fabio Petroni. 2021. Truy xuất Thực thể Tự hồi
quy. Trong International Conference on Learning
Representations.
Finale Doshi-Velez và Been Kim. 2017. Hướng tới
một khoa học nghiêm ngặt về học máy có thể giải
thích. arXiv preprint arXiv:1702.08608.
Joseph L Fleiss. 1971. Đo lường sự đồng thuận
quy mô danh nghĩa giữa nhiều người đánh giá.
Psychological bulletin, 76(5):378.
Lucas Graves. 2018. Hiểu Promise và Giới hạn của
Kiểm tra Sự thật Tự động. Báo cáo kỹ thuật,
Reuters Institute, University of Oxford.
Zhijiang Guo, Michael Schlichtkrull, và Andreas
Vlachos. 2022. Một Khảo sát về Kiểm tra Sự thật
Tự động. Transactions of the Association for
Computational Linguistics, 10:178–206.

--- TRANG 11 ---
Andreas Hanselowski, Hao Zhang, Zile Li, Daniil
Sorokin, Benjamin Schiller, Claudia Schulz, và
Iryna Gurevych. 2018. UKP-Athene: Kéo theo
văn bản đa câu cho xác minh tuyên bố. Trong
Proceedings of the First Workshop on Fact
Extraction and VERification (FEVER), trang 103–108,
Brussels, Belgium.
Momchil Hardalov, Arnav Arora, Preslav Nakov, và
Isabelle Augenstein. 2022. Một khảo sát về phát
hiện lập trường cho nhận dạng thông tin sai và
thông tin sai lệch. Trong Findings of the Association
for Computational Linguistics: NAACL 2022, trang
1259–1277, Seattle, United States.
Christopher Hidey, Tuhin Chakrabarty, Tariq Alhindi,
Siddharth Varia, Kriste Krstovski, Mona Diab, và
Smaranda Muresan. 2020. DeSePtion: Dự đoán
chuỗi kép và ví dụ đối nghịch để cải thiện kiểm
tra sự thật. Trong Proceedings of the 58th Annual
Meeting of the Association for Computational
Linguistics, trang 8593–8606, Online. Association
for Computational Linguistics.
Kelvin Jiang, Ronak Pradeep, và Jimmy Lin. 2021a.
Khám phá lý luận bằng chứng theo danh sách với
t5 cho xác minh sự thật. Trong Proceedings of the
59th Annual Meeting of the Association for
Computational Linguistics and the 11th International
Joint Conference on Natural Language Processing
(Volume 2: Short Papers), trang 402–410, Online.
Kelvin Jiang, Ronak Pradeep, và Jimmy Lin. 2021b.
Khám phá Lý luận Bằng chứng Theo danh sách
với T5 cho Xác minh Sự thật. Trong Proceedings
of the 59th Annual Meeting of the Association for
Computational Linguistics and the 11th International
Joint Conference on Natural Language Processing
(Volume 2: Short Papers), trang 402–410, Online.
Yichen Jiang, Shikha Bordia, Zheng Zhong, Charles
Dognin, Maneesh Singh, và Mohit Bansal. 2020.
HoVer: Một tập dữ liệu cho trích xuất sự thật nhiều
bước và xác minh tuyên bố. Trong Findings of the
Association for Computational Linguistics: EMNLP
2020, trang 3441–3460, Online.
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, và
Wen-tau Yih. 2020. Truy xuất đoạn văn dày đặc
cho trả lời câu hỏi miền mở. Trong Proceedings
of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP), trang
6769–6781, Online.
Omar Khattab, Christopher Potts, và Matei Zaharia.
2021. Baleen: Lý luận đa-bước mạnh mẽ ở quy mô
thông qua truy xuất nén. Trong Advances in Neural
Information Processing Systems, online.
Amrith Krishna, Sebastian Riedel, và Andreas Vlachos.
2022. ProoFVer: Chứng minh Định lý Logic Tự
nhiên cho Xác minh Sự thật. Transactions of the
Association for Computational Linguistics, 10:1013–1030.
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Ghazvininejad, Abdelrahman Mohamed, Omer
Levy, Veselin Stoyanov, và Luke Zettlemoyer.
2020. BART: Huấn luyện trước chuỗi-tới-chuỗi
khử nhiễu cho tạo sinh ngôn ngữ tự nhiên, dịch
thuật và hiểu biết. Trong Proceedings of the 58th
Annual Meeting of the Association for Computational
Linguistics, trang 7871–7880, Online.
Shaobo Li, Xiaoguang Li, Lifeng Shang, Xin Jiang,
Qun Liu, Chengjie Sun, Zhenzhou Ji, và Bingquan
Liu. 2021. Hopretriever: Truy xuất các bước qua
wikipedia để trả lời các câu hỏi phức tạp. Trong
Proceedings of the AAAI Conference on Artificial
Intelligence, tập 35, trang 13279–13287.
Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-
Hong Yang, Ronak Pradeep, và Rodrigo Nogueira.
2021. Pyserini: Một bộ công cụ python dễ sử dụng
để hỗ trợ nghiên cứu ir có thể tái tạo với biểu diễn
thưa và dày đặc. Trong Proceedings of the 44th
International ACM SIGIR Conference on Research
and Development in Information Retrieval (SIGIR
'21)., online.
Zhenghao Liu, Chenyan Xiong, Maosong Sun, và
Zhiyuan Liu. 2020. Xác minh Sự thật Chi tiết với
Mạng Chú ý Đồ thị Kernel. Trong Proceedings of
the 58th Annual Meeting of the Association for
Computational Linguistics, trang 7342–7351, Online.
Bill MacCartney và Christopher D Manning. 2014.
Logic tự nhiên và suy luận ngôn ngữ tự nhiên.
Trong Computing meaning, trang 129–147. Springer.
Christopher Malon. 2021. Team Papelo tại FEVEROUS:
Theo đuổi bằng chứng đa-bước. Trong Proceedings
of the Fourth Workshop on Fact Extraction and
VERification (FEVER), trang 40–49, Dominican
Republic. Association for Computational Linguistics.
George A. Miller. 1995. Wordnet: Một cơ sở dữ liệu
từ vựng cho tiếng anh. Commun. ACM, 38(11):39–41.
Yixin Nie, Haonan Chen, và Mohit Bansal. 2019.
Kết hợp trích xuất sự thật và xác minh với mạng
khớp ngữ nghĩa thần kinh. Trong The Thirty-Third
AAAI Conference on Artificial Intelligence, AAAI
2019, the Thirty-First Innovative Applications of
Artificial Intelligence Conference, IAAI 2019, the
Ninth AAAI Symposium on Educational Advances
in Artificial Intelligence, EAAI 2019, Honolulu,
Hawaii, USA, January 27 - February 1, 2019,
trang 6859–6866.
Adam Paszke, Sam Gross, Francisco Massa, Adam
Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca
Antiga, et al. 2019. Pytorch: Một thư viện học sâu
hiệu suất cao, phong cách mệnh lệnh. Advances
in neural information processing systems, 32.
Ellie Pavlick, Pushpendre Rastogi, Juri Ganitkevitch,
Benjamin Van Durme, và Chris Callison-Burch.

--- TRANG 12 ---
2015. PPDB 2.0: Xếp hạng paraphrase tốt hơn,
quan hệ kéo theo chi tiết, nhúng từ và phân loại
phong cách. Trong Proceedings of the 53rd Annual
Meeting of the Association for Computational
Linguistics and the 7th International Joint Conference
on Natural Language Processing (Volume 2: Short
Papers), trang 425–430, Beijing, China.
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick
Lewis, Majid Yazdani, Nicola De Cao, James
Thorne, Yacine Jernite, Vladimir Karpukhin, Jean
Maillard, Vassilis Plachouras, Tim Rocktäschel, và
Sebastian Riedel. 2021. KILT: một điểm chuẩn cho
các nhiệm vụ ngôn ngữ chuyên sâu tri thức. Trong
Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computational
Linguistics: Human Language Technologies, trang
2523–2544, Online.
Fabio Petroni, Tim Rocktäschel, Sebastian Riedel,
Patrick Lewis, Anton Bakhtin, Yuxiang Wu, và
Alexander Miller. 2019. Các mô hình ngôn ngữ
như cơ sở tri thức? Trong Proceedings of the 2019
Conference on Empirical Methods in Natural
Language Processing and the 9th International
Joint Conference on Natural Language Processing
(EMNLP-IJCNLP), trang 2463–2473, Hong Kong,
China.
Peng Qi, Haejun Lee, Tg Sido, và Christopher Manning.
2021. Trả lời các câu hỏi miền mở với các bước
lý luận khác nhau từ văn bản. Trong Proceedings
of the 2021 Conference on Empirical Methods in
Natural Language Processing, trang 3599–3614,
Online and Punta Cana, Dominican Republic.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, và Ilya Sutskever. 2019. Các mô
hình ngôn ngữ là người học đa nhiệm không giám
sát. OpenAI blog, 1(8):9.
Michael Roth và Sabine Schulte im Walde. 2014.
Kết hợp các mẫu từ và dấu hiệu diễn ngôn cho
phân loại quan hệ paradigmatic. Trong Proceedings
of the 52nd Annual Meeting of the Association for
Computational Linguistics (Volume 2: Short Papers),
trang 524–530, Baltimore, Maryland.
Dominik Stammbach. 2021. Lựa chọn bằng chứng
như một nhiệm vụ dự đoán cấp token. Trong
Proceedings of the Fourth Workshop on Fact
Extraction and VERification (FEVER), trang 14–20,
Dominican Republic.
Dominik Stammbach và Guenter Neumann. 2019.
Team DOMLIN: Khai thác tăng cường bằng chứng
cho nhiệm vụ chia sẻ FEVER. Trong Proceedings
of the Second Workshop on Fact Extraction and
VERification (FEVER), trang 105–109, Hong Kong,
China.
James Thorne, Andreas Vlachos, Christos
Christodoulopoulos, và Arpit Mittal. 2018.
FEVER: Một Tập dữ liệu Quy mô lớn cho Trích
xuất Sự thật và Xác minh. Trong Proceedings of
the 2018 Conference of the North American Chapter
of the Association for Computational Linguistics:
Human Language Technologies, trang 809–819,
New Orleans, Louisiana.
James Thorne, Andreas Vlachos, Oana Cocarascu,
Christos Christodoulopoulos, và Arpit Mittal. 2019.
Nhiệm vụ chia sẻ FEVER2.0. Trong Proceedings
of the Second Workshop on Fact Extraction and
VERification (FEVER), trang 1–6, Hong Kong,
China.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pierric
Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
Joe Davison, Sam Shleifer, Patrick von Platen,
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Teven Le Scao, Sylvain Gugger, Mariama Drame,
Quentin Lhoest, và Alexander Rush. 2020. Transformers:
Xử lý ngôn ngữ tự nhiên tiên tiến. Trong Proceedings
of the 2020 Conference on Empirical Methods in
Natural Language Processing: System Demonstrations,
trang 38–45, Online.
Wenhan Xiong, Xiang Li, Srini Iyer, Jingfei Du, Patrick
Lewis, William Yang Wang, Yashar Mehdad, Scott
Yih, Sebastian Riedel, Douwe Kiela, và Barlas
Oguz. 2021. Trả lời các câu hỏi miền mở phức tạp
với truy xuất dày đặc đa-bước. Trong International
Conference on Learning Representations, online.
Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu,
Nan Duan, Ming Zhou, Jiahai Wang, và Jian Yin.
2020. Lý luận trên đồ thị cấp ngữ nghĩa cho kiểm
tra sự thật. Trong Proceedings of the 58th Annual
Meeting of the Association for Computational
Linguistics, trang 6170–6180, Online.

A Phụ lục
A.1 Truy xuất Tài liệu Tự hồi quy
Mô hình Tạo sinh Chúng tôi sử dụng một mô hình
seq2seq được huấn luyện trước, cụ thể là BART
(Lewis et al., 2020), cho phép mô hình nắm bắt
cả thông tin cấp bề mặt và các khía cạnh ngữ nghĩa
giữa tuyên bố và các câu ứng viên sử dụng chú
ý chéo trong bộ mã hóa của nó trong khi bộ giải
mã của nó chú ý đến chuỗi ẩn trong quá trình tạo
sinh. Đầu vào được cấu trúc sao cho tuyên bố được
theo sau bởi các câu, mỗi cái được phân tách bởi
các token kết thúc câu: c </s>e0, </s> ... </s> ek.
Mỗi câu bằng chứng trong Ei được đặt trước bởi
tiêu đề tài liệu tương ứng trong dấu ngoặc vuông,
ví dụ "[James McBrayer] Jack McBrayer (sinh ngày
27 tháng 5... [Tom Bergeron] Tom Bergeron (sinh
ngày 6 tháng 5 năm 1955)...". Để giải mã, các định
danh câu được tạo ra trước, theo sau là định danh
tài liệu. Đối với giải mã đánh dấu động, chúng tôi
sử dụng dấu ngoặc vuông để chuyển đổi giữa các
không gian tìm kiếm trong khi mỗi định danh câu
được phân tách bởi một khoảng trắng: ep1ep2[dp].
Đầu vào cho mô-đun đủ chứng minh được định
dạng theo yêu cầu của ProofVER. Đánh dấu động
của đầu ra chứng minh được cấu trúc bằng cách
sử dụng dấu ngoặc nhọn để bao quanh một khoảng
tuyên bố, dấu ngoặc vuông để bao phủ

--- TRANG 13 ---
khoảng bằng chứng, và token sau dấu ngoặc vuông
đóng là toán tử logic tự nhiên.
Huấn luyện Chúng tôi huấn luyện một mô hình
riêng biệt cho mỗi bước t sử dụng ước lượng khả
năng tối đa, theo tinh chỉnh Dịch Máy Thần kinh
của BART (Lewis et al., 2020). Cho một danh sách
có thứ tự các câu bằng chứng vàng Eg, chúng tôi
tạo ra dữ liệu huấn luyện bằng cách chỉ xem xét
các mẫu với các câu bằng chứng vàng bằng số
bước t. Vì mô hình được huấn luyện như một bộ
xếp hạng lại pointwise, chúng tôi giữ t−1 câu bằng
chứng vàng hàng đầu trong đầu vào, tức là trong
Et. và đầu ra sau đó được tạo thành từ một chuỗi
duy nhất p∈Pt. Chúng tôi tạo ra p như nhãn đầu
ra bằng cách nối các id câu của t−1 câu bằng chứng
vàng với tiêu đề tài liệu mà câu vàng còn lại đại
diện. Vì chúng tôi xem xét l câu hàng đầu trong
quá trình suy luận, với l≥t, chúng tôi tiếp tục lấy
mẫu l−t câu âm từ các ứng viên tài liệu Dt và
thêm chúng vào đầu vào. Chúng tôi tiếp tục xáo
trộn đầu vào ngẫu nhiên, buộc mô hình học cách
chú ý đến tất cả các câu đầu vào. Ví dụ, cho ví dụ
trong Hình 1, dữ liệu huấn luyện cho bước t=2
sẽ chứa như đầu vào tuyên bố, "Seth Meyers đã
tổ chức lễ trao giải", và các mẫu âm, và nhãn đầu
ra có thể là E2[Seth Meyers], với 2 thay đổi tùy
thuộc vào vị trí của nó trong đầu vào. Trong các
trường hợp không có thứ tự rõ ràng của các câu
bằng chứng, chúng tôi tạo ra tất cả t−1 cách có
thể để giữ t−1 câu vàng trong đầu vào và sử dụng
cái khác làm đầu ra.

A.2 Chi tiết Triển khai
Tất cả các mô hình được triển khai sử dụng PyTorch
(Paszke et al., 2019). Mô hình tự hồi quy cho cả
truy xuất và tạo chứng minh dựa trên triển khai
Huggingface (Wolf et al., 2020) của BART (Lewis
et al., 2020) và GENRE (De Cao et al., 2021). Đối
với tất cả các thí nghiệm, chúng tôi sử dụng kích
thước chùm tia 25 cho việc tạo sinh tự hồi quy,
và kích thước chùm tia 5 cho việc tạo sinh chứng
minh đủ. Chúng tôi sử dụng các siêu tham số mặc
định của BART trên tất cả các thí nghiệm. Trong
trường hợp Dt chứa ít tài liệu hơn so với được
xem xét bởi chỉ số (ví dụ recall@5 nhưng số tài
liệu k<5), chúng tôi thêm các tài liệu bổ sung từ
Dt−1. Tất cả các thí nghiệm được chạy trên một
máy với một Quadro RTX 8000 và bộ nhớ RAM
64GB. Krishna et al. (2022) đã tử tế cung cấp cho
chúng tôi quyền truy cập vào mô hình ProofVER
của họ. Đối với BM25, chúng tôi đặt k1=0.6 và
b=0.4, theo khuyến nghị của Pyserini.

A.3 Kết quả Khác
Bảng 7 hiển thị kết quả điểm F1 trên FEVER,
FEVEROUS-S, và HoVer.

A.4 Đánh giá Con người
Tất cả các đối tượng trong đánh giá con người là
sinh viên đại học/cao học/sau đại học trong khoa
học máy tính hoặc ngôn ngữ học. 4 đối tượng là
nam, 2 nữ. Không ai trong số các đối tượng có
kiến thức trước về suy luận ngôn ngữ tự nhiên.

NatOP Paraphrase
≡ Các Khoảng Tương đương
¬ Khoảng bằng chứng bác bỏ khoảng tuyên bố
∨ Khoảng bằng chứng mâu thuẫn với khoảng tuyên bố
# Khoảng tuyên bố và khoảng bằng chứng không liên quan
Bảng 8: NatOPs và các paraphrase tương ứng của chúng.

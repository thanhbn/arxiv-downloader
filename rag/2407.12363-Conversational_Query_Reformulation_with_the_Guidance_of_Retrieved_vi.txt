# 2407.12363.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2407.12363.pdf
# Kích thước tệp: 636164 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Cải cách Truy vấn Hội thoại với Sự Hướng dẫn của Tài liệu Đã Truy xuất
Jeonghyun Park và Hwanhee Lee†
Khoa Trí tuệ Nhân tạo, Đại học Chung-Ang, Seoul, Hàn Quốc
{tom0365, hwanheelee}@cau.ac.kr
Tóm tắt
Tìm kiếm hội thoại nhằm truy xuất các đoạn văn có liên quan cho các câu hỏi đưa ra trong hỏi đáp hội thoại. Cải cách Truy vấn Hội thoại (CQR) cải thiện tìm kiếm hội thoại bằng cách tinh chỉnh các truy vấn gốc thành các dạng phi ngữ cảnh để giải quyết các vấn đề trong truy vấn gốc, chẳng hạn như thiếu sót và tham chiếu. Các phương pháp CQR trước đây tập trung vào việc bắt chước các truy vấn viết bởi con người có thể không luôn cho ra kết quả tìm kiếm có ý nghĩa đối với bộ truy xuất. Trong bài báo này, chúng tôi giới thiệu GuideCQR, một khung làm việc tinh chỉnh truy vấn cho CQR bằng cách tận dụng thông tin chính từ các tài liệu ban đầu được truy xuất. Cụ thể, GuideCQR trích xuất từ khóa và tạo ra câu trả lời mong đợi từ các tài liệu đã truy xuất, sau đó thống nhất chúng với các truy vấn sau khi lọc để thêm thông tin hữu ích nhằm nâng cao quá trình tìm kiếm. Kết quả thực nghiệm cho thấy phương pháp đề xuất của chúng tôi đạt được hiệu suất tiên tiến nhất trên nhiều bộ dữ liệu, vượt trội hơn các phương pháp CQR trước đây. Ngoài ra, chúng tôi chỉ ra rằng GuideCQR có thể đạt được cải thiện hiệu suất bổ sung trong tìm kiếm hội thoại sử dụng các loại truy vấn khác nhau, ngay cả đối với các truy vấn được viết bởi con người.¹
1 Giới thiệu
Trong nhiệm vụ hỏi đáp hội thoại (ConvQA), tìm kiếm hội thoại nhằm truy xuất các đoạn văn có liên quan cung cấp thông tin cần thiết để trả lời truy vấn hiện tại. Quá trình này diễn ra trong khuôn khổ một cuộc hội thoại nhiều lượt, trong đó mỗi truy vấn xây dựng dựa trên các tương tác trước đó. Các câu hỏi trong ConvQA thường gặp phải những thách thức như thiếu sót và tham chiếu, khiến việc đạt được kết quả tìm kiếm mong muốn sử dụng truy vấn gốc trở nên khó khăn. Nghiên cứu trước đây tập trung vào việc chuyển đổi truy vấn thành các dạng độc lập để hiểu ý định của chúng tốt hơn, làm cho chúng độc lập và mạnh mẽ hơn (Mo et al., 2023a). Quá trình này, được gọi là Cải cách Truy vấn Hội thoại (CQR), giúp làm rõ các truy vấn gốc và nâng cao việc hiểu truy vấn.

Với sự ra đời của Mô hình Ngôn ngữ Lớn (LLM), việc ứng dụng chúng trong các phương pháp CQR đã trở nên ngày càng phổ biến. Một nghiên cứu gần đây (Jagerman et al., 2023) bao gồm việc hướng dẫn một LLM tạo ra các đoạn văn có liên quan đến truy vấn. Phương pháp này làm cho truy vấn trở nên hợp lý hơn và dễ hiểu đối với con người bằng cách mở rộng câu. LLM4CS (Mao et al., 2023) cũng bao gồm việc sử dụng LLM để viết lại truy vấn thông qua các phương pháp nhắc nhở khác nhau và kỹ thuật tổng hợp. Tuy nhiên, mặc dù những cách tiếp cận này nhằm tạo ra các truy vấn thân thiện với con người và dễ hiểu, chúng có thể không luôn mang lại kết quả hiệu quả mà các bộ truy xuất mong muốn. Ví dụ, như được thể hiện ở cuối Hình 1, mặc dù truy vấn được cải cách có thể có vẻ kém lưu loát do các từ khóa bổ sung, nó đạt được điểm số bộ truy xuất cao hơn so với truy vấn cơ sở vì sự tương đồng tăng lên với tài liệu thực tế. Ví dụ này làm nổi bật sự cần thiết của việc ưu tiên các truy vấn được tối ưu hóa cho bộ truy xuất

0†Tác giả liên hệ.
1Mã và mô hình được huấn luyện trước sẽ được công bố công khai khi bài báo được chấp nhận.

Hình 1: Ví dụ truy vấn cho ConvQA trong đó truy vấn được cải cách đạt điểm MRR cao hơn bằng cách trích xuất hiệu quả các manh mối từ các tài liệu ban đầu được truy xuất, so với truy vấn cơ sở.

1arXiv:2407.12363v5 [cs.CL] 15 May 2025

--- TRANG 2 ---
truy vấn hơn những truy vấn thân thiện với con người để nâng cao các phương pháp CQR. Để đạt được điều này, chúng tôi quan sát thấy rằng các tài liệu ban đầu được truy xuất từ quá trình truy xuất với tập truy vấn cơ sở có thể giúp tạo ra các truy vấn được tối ưu hóa cho truy xuất. Cụ thể, chúng tôi thấy rằng mặc dù một số tài liệu không thể cung cấp manh mối để trả lời câu hỏi, hầu hết các tài liệu được truy xuất chứa từ ngữ hoặc tín hiệu có ảnh hưởng cao trong các quá trình truy xuất tiếp theo. Ví dụ, trong ví dụ được minh họa trong Hình 1, việc thêm thuật ngữ 'interchangeable', một từ khóa quan trọng được tìm thấy trong đoạn văn vàng trong các tài liệu hướng dẫn, nâng cao hiệu suất mà truy vấn gốc một mình không thể đạt được. Bằng cách này, các tín hiệu trong các tài liệu ban đầu được truy xuất thông qua truy vấn cơ sở có thể hướng dẫn việc tìm kiếm đoạn văn vàng.

Trong bài báo này, chúng tôi đề xuất GuideCQR, một khung làm việc CQR hiệu quả được thiết kế để tạo ra các truy vấn hội thoại thân thiện với truy xuất bằng cách tận dụng sự hướng dẫn của các tài liệu ban đầu được truy xuất từ truy vấn cơ sở. GuideCQR đầu tiên thu được các tài liệu ban đầu được truy xuất thông qua quá trình truy xuất sử dụng truy vấn cơ sở được cải cách bởi LLM. Sau đó chúng tôi thực hiện quá trình sắp xếp lại để tinh chỉnh thứ tự của các tài liệu được truy xuất dựa trên sự tương đồng của chúng với truy vấn. Thông qua quá trình sắp xếp lại này, chúng tôi cẩn thận chọn một số lượng nhỏ tài liệu từ những tài liệu ban đầu được truy xuất để trích xuất các tín hiệu có khả năng chứa đoạn văn vàng cao hơn. Tiếp theo, chúng tôi trích xuất từ khóa và tạo ra câu trả lời mong đợi từ các tài liệu hướng dẫn được sắp xếp lại để thu được các thành phần để tạo ra truy vấn thân thiện với bộ truy xuất. Sau đó chúng tôi độc lập lọc cả từ khóa và câu trả lời mong đợi dựa trên sự tương đồng của chúng với truy vấn gốc và các phát ngôn trước đó để loại bỏ thông tin dư thừa. Cuối cùng, chúng tôi xây dựng tập truy vấn cuối cùng bằng cách nối các từ khóa và câu trả lời mong đợi đã được lọc với truy vấn cơ sở.

Kết quả thực nghiệm cho thấy GuideCQR đạt được hiệu suất tiên tiến nhất trên một số bộ dữ liệu CQR so với các hệ thống cơ sở. Chúng tôi cũng chứng minh sự mạnh mẽ của khung làm việc GuideCQR trong việc nâng cao khả năng truy xuất của các truy vấn, làm cho chúng thân thiện hơn với bộ truy xuất. Hơn nữa, chúng tôi xác nhận hiệu quả của phương pháp chúng tôi bằng cách phân tích sự chồng chéo giữa các từ khóa được tăng cường và các tài liệu có liên quan đối với câu hỏi đã cho. Ngoài ra, chúng tôi chỉ ra rằng phương pháp đề xuất đạt được cải thiện đáng chú ý trên các tập truy vấn khác nhau, nhấn mạnh khả năng thích ứng của nó.

2 Các Nghiên cứu Liên quan

2.1 Tìm kiếm Hội thoại

Mục tiêu của tìm kiếm hội thoại (Gao et al., 2022) là truy xuất các đoạn văn chứa thông tin cần thiết để trả lời truy vấn hiện tại trong một cuộc hội thoại nhiều lượt. Để có được câu trả lời mong muốn từ cuộc hội thoại được cho, việc hiểu ý nghĩa của truy vấn là quan trọng trong lĩnh vực này (Mo et al., 2023b). Tuy nhiên, các truy vấn trong ConvQA có một số vấn đề. Ví dụ, các truy vấn có thể bao gồm đại từ như "anh ấy", "cô ấy", hoặc "nó", đòi hỏi việc xác định thực thể được tham chiếu, và cũng có thách thức về thiếu sót, khi thông tin thiết yếu không được bao gồm (Mao et al., 2023; Wang et al., 2023).

Để giải quyết những thách thức như vậy trong tìm kiếm hội thoại, hai phương pháp chính cho phép tìm kiếm hội thoại là Truy xuất Dày đặc Hội thoại (CDR) và CQR. CDR tập trung vào việc nâng cao biểu diễn của truy vấn hiện tại bằng cách kết hợp ngữ cảnh lịch sử đạt được thông qua việc huấn luyện các bộ truy xuất dày đặc (Qu et al., 2020). Mặt khác, CQR chuyển đổi tìm kiếm hội thoại thành tìm kiếm ad-hoc truyền thống bằng cách chuyển đổi toàn bộ phiên tìm kiếm thành một truy vấn độc lập duy nhất (Elgohary et al., 2019).

Trong công việc của chúng tôi, chúng tôi tập trung vào việc sử dụng lịch sử hội thoại để ngữ cảnh hóa việc viết lại truy vấn. Ngoài ra, chúng tôi sử dụng hội thoại nhiều lượt như một tiêu chí để lọc từ khóa và câu trả lời, là những thành phần thiết yếu của GuideCQR.

2.2 Cải cách Truy vấn Hội thoại

Các phương pháp CQR nhằm chuyển đổi truy vấn thành các dạng phi ngữ cảnh, cho phép chúng được hiểu chỉ dựa trên nội dung của chúng và đảm bảo chúng truyền tải ý nghĩa dự định một cách hiệu quả. Các phương pháp này được thiết kế để nâng cao hiệu suất tìm kiếm hội thoại bằng cách tinh chỉnh và mở rộng truy vấn của người dùng trong ngữ cảnh hội thoại.

Trong khi các cách tiếp cận trước đây, chẳng hạn như truy vấn được viết lại bởi con người (Lin et al., 2020; Voskarides et al., 2020a; Yu et al., 2020), đã cố gắng cải thiện độ rõ ràng của truy vấn, chúng thường không đạt được việc tối ưu hóa hiệu suất truy xuất. Mặc dù việc viết lại bởi con người có thể nâng cao khả năng đọc cho người dùng, chúng không luôn phù hợp với nhu cầu của hệ thống truy xuất.

Để giải quyết những thách thức này, các nghiên cứu gần đây đã giới thiệu các phương pháp như CONQRR (Wu et al.,

--- TRANG 3 ---
𝑸𝒃𝒂𝒔𝒆𝒍𝒊𝒏𝒆
Ung thư cổ họng có thể chữa khỏi được không?
Tạo Truy vấn Cơ sở
Truy xuất Ban đầu với 𝑸𝒃𝒂𝒔𝒆𝒍𝒊𝒏𝒆
Nếu được chẩn đoán sớm, ung thư cổ họng có tỷ lệ khỏi bệnh cao. Ung thư cổ họng có thể không thể chữa khỏi được một khi các tế bào ác tính lan đến các phần của cơ thể ngoài cổ và (...)
Tài liệu Hướng dẫn Ban đầu
(...)
𝑹𝒂𝒘𝑸𝒖𝒆𝒓𝒚: Nó có thể chữa khỏi được không?
𝑯𝒊𝒔𝒕𝒐𝒓𝒚: Ung thư cổ họng là gì?
Tài liệu Hướng dẫn Được Sắp xếp lại
Sắp xếp lại

[Tạo Truy vấn Thân thiện với Bộ truy xuất]
[Tăng cường Từ khóa]
Từ khóa K
"sớm", "cổ họng", "ung thư", "cao", "khỏi", "tỷ lệ", "Cổ họng", "Ung thư", "có thể chữa khỏi"

[Tạo Câu trả lời Mong đợi]
Câu trả lời Mong đợi A
ung thư cổ họng có tỷ lệ khỏi bệnh cao
ung thư không thể chữa khỏi
quá tiến triển để có thể chữa khỏi (...)

Lịch sử
Truy vấn
"cổ họng", "ung thư", "Cổ họng", "Ung thư", "có thể chữa khỏi"
Từ khóa Đã lọc 𝑲𝒇𝒊𝒍𝒕𝒆𝒓𝒆𝒅

ung thư cổ họng có tỷ lệ khỏi bệnh cao (...)
Câu trả lời Đã lọc 𝑨𝒇𝒊𝒍𝒕𝒆𝒓𝒆𝒅

Truy vấn Cuối cùng 𝑸��𝒊𝒏𝒂𝒍
Concat ([𝑸𝒃𝒂𝒔𝒆𝒍𝒊𝒏𝒆, 𝑲𝒇𝒊𝒍𝒕𝒆𝒓𝒆𝒅, 𝑨𝒇𝒊𝒍𝒕𝒆𝒓𝒆𝒅])

Lọc dựa trên Truy vấn và Lịch sử

𝟏𝟎𝟐𝟑
4 1 3 2
3.2

[Lọc và Thống nhất] 3.3
3.1 [Truy xuất Tài liệu Hướng dẫn]

Ung thư cổ họng có thể chữa khỏi được không? cổ họng ung thư Cổ họng Ung thư có thể chữa khỏi ung thư cổ họng có tỷ lệ khỏi bệnh cao (...)

Truy xuất Sau với 𝑸𝒇𝒊𝒏𝒂𝒍
𝟓𝟏𝟐 𝟐𝟏 𝟖
𝟏𝟖𝟕 𝟖𝟗𝟒 𝟏𝟖𝟔𝟓 𝟐𝟏𝟕
𝟒 𝟏 𝟐 𝟑

Hình 2: Khung làm việc tổng thể của GuideCQR: Để dễ hiểu hơn, chúng tôi chỉ trực quan hóa tài liệu xếp hạng top-1 và trình bày từ khóa được tăng cường từ tài liệu top-1 và 3 cặp câu trả lời từ 3 tài liệu top-3.

2022), trực tiếp tối ưu hóa việc viết lại truy vấn cho truy xuất thông qua Huấn luyện Chuỗi Tự phê phán (Rennie et al., 2017), và ConvGQR (Mo et al., 2023a), cải thiện hiệu suất truy xuất bằng cách kết hợp việc viết lại truy vấn với mở rộng truy vấn. Ngoài ra, IterCQR (Jang et al., 2024) huấn luyện mô hình CQR một cách lặp đi lặp lại bằng cách sử dụng tín hiệu truy xuất thông tin (IR) như phần thưởng. Việc tích hợp LLM trong CQR cũng đã cho thấy triển vọng trong nghiên cứu gần đây (Mao et al., 2023).

Theo hiểu biết tốt nhất của chúng tôi, không có nghiên cứu trước đây nào trực tiếp sử dụng các tín hiệu trong tài liệu được truy xuất để áp dụng CQR. Phương pháp đề xuất của chúng tôi, GuideCQR, tập trung vào việc chuyển đổi truy vấn bằng cách tận dụng thông tin từ các tài liệu được truy xuất cùng với truy vấn cơ sở trong quá trình truy xuất.

3 GuideCQR

Chúng tôi đề xuất GuideCQR, một khung làm việc mới được thiết kế để cải cách truy vấn hội thoại bằng cách sử dụng sự hướng dẫn từ các tài liệu ban đầu được truy xuất. Hình 2 cung cấp tổng quan về quá trình cải cách truy vấn được đề xuất. GuideCQR bao gồm ba giai đoạn: Đầu tiên chúng tôi truy xuất một tập ban đầu các tài liệu hướng dẫn sử dụng truy vấn được cải cách bởi LLM. Bước này truy xuất các tài liệu có khả năng chứa đoạn văn vàng để hướng dẫn quá trình cải cách truy vấn (Mục 3.1). Tiếp theo, chúng tôi trích xuất từ khóa và tạo câu trả lời mong đợi từ các tài liệu hướng dẫn, tạo ra các thành phần góp phần làm cho truy vấn thân thiện hơn với bộ truy xuất (Mục 3.2). Cuối cùng, chúng tôi áp dụng quy trình lọc đánh giá cả từ khóa và câu trả lời dựa trên điểm tương đồng của chúng so với truy vấn cơ sở và lịch sử hội thoại. Sau đó chúng tôi thống nhất và nối các thành phần này với truy vấn cơ sở để xây dựng truy vấn cuối cùng cho việc truy xuất sau (Mục 3.3).

3.1 Truy xuất Tài liệu Hướng dẫn

3.1.1 Truy xuất Tài liệu Ban đầu

Trong quá trình phát triển truy vấn thân thiện với bộ truy xuất, các tài liệu ban đầu được truy xuất có thể đóng vai trò quan trọng như tài nguyên hướng dẫn bằng cách cung cấp những hiểu biết cơ bản cho quá trình CQR. Ví dụ, trong nội dung của các tài liệu được truy xuất, những tín hiệu này có thể bao gồm từ khóa quan trọng hoặc dấu hiệu ngữ cảnh cần thiết để tìm kiếm các đoạn văn vàng như "chữa khỏi", "tỷ lệ", và "có thể chữa khỏi" từ tài liệu được hiển thị trong Hình 2.

Được truyền cảm hứng từ những điểm này, GuideCQR bắt đầu từ việc nhận các tài liệu ban đầu được truy xuất để thu được những tín hiệu có ý nghĩa cho bộ truy xuất. Chúng tôi thu được những tài liệu ban đầu này bằng cách truy xuất các tài liệu sử dụng tập truy vấn cơ sở được tạo bởi LLM. Chúng tôi ký hiệu truy vấn cơ sở là Qbaseline,

Qbaseline = RewriteLLM(History, RawQuery), (1)

trong đó RewriteLLM đại diện cho một thao tác giải quyết thiếu sót hoặc tham chiếu sử dụng OpenAI

--- TRANG 4 ---
gpt3.5-turbo-16k và RawQuery biểu thị câu hỏi thô trong bộ dữ liệu, không có bất kỳ cải cách nào được áp dụng. History biểu thị lịch sử hội thoại của RawQuery, đặc biệt bao gồm các truy vấn hội thoại trước đó, truy vấn được viết lại và phản hồi bởi các chú thích viên con người. Dựa trên cả RawQuery và History, chúng tôi tạo ra Qbaseline. Sử dụng Qbaseline này, chúng tôi thu được các tài liệu ban đầu bao gồm 2,000 tài liệu cho mỗi câu hỏi. Chúng rất quan trọng để tạo ra tập truy vấn cuối cùng của chúng tôi và là nền tảng vững chắc để xác định các tín hiệu có ý nghĩa và hướng dẫn bộ truy xuất đến các đoạn văn có liên quan nhất.

3.1.2 Sắp xếp lại Tài liệu

Để cải thiện hơn nữa chất lượng của tập tài liệu hướng dẫn, chúng tôi thực hiện quy trình sắp xếp lại để tạo ra các tài liệu ban đầu được truy xuất. Bằng cách sắp xếp lại các tài liệu ban đầu sử dụng một mô hình truy xuất khác, chúng tôi nhằm nắm bắt các tài liệu tốt hơn bằng cách giảm thiểu thiên lệch có thể phát sinh từ việc dựa vào một bộ truy xuất duy nhất. Cụ thể, chúng tôi sử dụng Sentence-Transformer (Reimers và Gurevych, 2019) để sắp xếp lại 2,000 tài liệu hàng đầu cho mỗi câu hỏi, chọn tập hướng dẫn cuối cùng bằng cách chọn 10 tài liệu hàng đầu dựa trên điểm tương đồng của chúng với truy vấn.

3.2 Tạo Truy vấn Thân thiện với Bộ truy xuất

Vì nhiều tài liệu được truy xuất có thể chứa từ ngữ có ảnh hưởng hoặc tín hiệu ảnh hưởng đáng kể đến các giai đoạn truy xuất tiếp theo, việc xác định các yếu tố chính từ những tài liệu này là rất quan trọng để xây dựng các truy vấn hiệu quả hơn. Dựa trên các tài liệu hướng dẫn thu được từ bước trước, chúng tôi tạo ra các truy vấn thân thiện với bộ truy xuất bằng cách kết hợp thông tin bổ sung vào truy vấn từ hai cách tiếp cận: Tăng cường Từ khóa, Tạo Câu trả lời Mong đợi

3.2.1 Tăng cường Từ khóa

Chúng tôi thấy rằng từ khóa từ các tài liệu ban đầu đóng vai trò quan trọng trong việc hình thành các truy vấn thân thiện với bộ truy xuất, vì chúng nắm bắt các thuật ngữ có liên quan và quan trọng nhất trong tài liệu. Ví dụ, các từ khóa như "sớm", "cổ họng", "ung thư", "cao", và "chữa khỏi" có thể có lợi nếu chúng được tăng cường vào truy vấn tìm kiếm như được hiển thị trong Hình 2.

Chúng tôi tận dụng KeyBERT (Grootendorst, 2020) để trích xuất từ khóa từ các tài liệu được sắp xếp lại. Quá trình bắt đầu bằng việc sử dụng BERT (Devlin et al., 2019) để tính toán embeddings của tài liệu, tạo ra biểu diễn cho toàn bộ tài liệu. Embeddings cho các từ hoặc cụm từ N-gram trong tài liệu sau đó được trích xuất. Bằng cách tính toán độ tương đồng cosine giữa những từ/cụm từ này và biểu diễn tài liệu, phương pháp xác định từ/cụm từ nào tương đồng nhất với tài liệu.

Theo nguyên tắc này, chúng tôi nâng cao các truy vấn cơ sở bằng cách tăng cường từ khóa thông qua hai siêu tham số. Đầu tiên liên quan đến việc xác định số lượng tài liệu để trích xuất từ khóa, điều này thiết lập mức độ hướng dẫn chúng tôi dự định cung cấp. Đối với mỗi tài liệu hướng dẫn, chúng tôi trích xuất từ khóa có độ dài span được chỉ định. Khía cạnh thứ hai liên quan đến độ dài span, chỉ ra số lượng token hoặc từ khóa được chọn cho mỗi tài liệu. Ví dụ, khi tăng cường với từ khóa top-2 span-3, chúng tôi trích xuất ba từ khóa từ mỗi trong hai tài liệu hàng đầu, cho ra tổng cộng sáu từ khóa.

Do đó, chúng tôi tăng cường tổng danh sách từ khóa K bao gồm nm từ khóa từ n tài liệu hàng đầu và độ dài span m:

K = [k11, k12, k13, ..., k1m, k21, ..., knm], (2)

trong đó k biểu thị đơn vị từ khóa, n là số lượng tài liệu và m là độ dài span từ khóa.

3.2.2 Tạo Câu trả lời Mong đợi

Các tài liệu hướng dẫn thường bao gồm câu trả lời vàng cho truy vấn, phục vụ như một tài nguyên có giá trị để cải cách truy vấn một cách hiệu quả. Dựa trên ý tưởng này, chúng tôi sử dụng các tài liệu hướng dẫn như ngữ cảnh để tạo ra câu trả lời mong đợi nhằm nâng cao truy vấn. Như được minh họa trong Hình 2, mặc dù nó không được thu được từ đoạn văn vàng, câu trả lời mong đợi là một phản hồi ngắn gọn và thông tin có thể giải quyết truy vấn của người dùng vì chúng có thể cung cấp những hiểu biết trực tiếp về ý định của người dùng, từ đó cải thiện mức độ liên quan và độ chính xác của kết quả tìm kiếm. Cụ thể, chúng tôi tạo ra những câu trả lời mong đợi này như sau:

A = [a1, a2, a3, ..., an], (3)

trong đó A đại diện cho danh sách câu trả lời và an biểu thị một đơn vị câu trả lời được trích xuất từ một tài liệu duy nhất. Để tạo ra những câu trả lời này, cả truy vấn và ngữ cảnh có liên quan đều cần thiết. Chúng tôi sử dụng truy vấn như truy vấn cơ sở Qbaseline và ngữ cảnh như các tài liệu hướng dẫn. Chúng tôi tạo ra một câu trả lời mong đợi duy nhất cho mỗi tài liệu. Do đó, quá trình này tạo ra k câu trả lời riêng biệt, với một câu được rút ra từ mỗi trong k tài liệu hàng đầu.

--- TRANG 5 ---
3.3 Lọc và Thống nhất

Chúng tôi quan sát thấy rằng các yếu tố dư thừa, chẳng hạn như từ khóa 'tỷ lệ' như được hiển thị trong Hình 2, có thể xuất hiện từ cả từ khóa được tăng cường và câu trả lời được tạo ra. Chúng tôi thấy rằng điều này là do GuideCQR có thể tăng cường từ khóa hoặc câu trả lời được rút ra từ các tài liệu không liên quan. Do đó, các tín hiệu không liên quan từ các tài liệu không liên quan có thể có tác động tiêu cực khi tạo ra các truy vấn thân thiện với bộ truy xuất.

Để giải quyết điều này, chúng tôi giới thiệu một giai đoạn lọc bổ sung để loại bỏ hiệu quả hơn các từ khóa và câu trả lời không liên quan khỏi truy vấn được cải cách. Chúng tôi hướng dẫn quá trình lọc này thông qua thước đo FilterScore, tận dụng cả QueryScore và HistoryScore, được tính toán sử dụng độ tương đồng cosine, như sau:

cosSim(x, y) = x·y / (∥x∥∥y∥), (4)

trong đó cosSim biểu thị độ tương đồng cosine trong khoảng từ 0 đến 1. Dựa trên cosSim, chúng tôi đầu tiên định nghĩa QueryScore như sau:

QueryScore = 10 · cosSim(query, item), (5)

trong đó query đại diện cho embedding của truy vấn lượt hiện tại, và item tham chiếu đến embedding của từ khóa hoặc câu trả lời. Vậy QueryScore là độ tương đồng cosine giữa query và item trong khoảng từ 0 đến 10. Và chúng tôi định nghĩa HistoryScore:

HistoryScore = 10 · max(cosSim(history[i], item)), (6)

trong đó history là danh sách truy vấn lịch sử của phát ngôn hiện tại. Vậy HistoryScore là giá trị độ tương đồng cosine tối đa giữa yếu tố truy vấn lịch sử hội thoại trong danh sách truy vấn lịch sử và item hiện tại.

Cuối cùng, chúng tôi định nghĩa FilterScore như trung bình của QueryScore và HistoryScore, trong khoảng từ 1 đến 10:

FilterScore = (QueryScore + HistoryScore) / 2. (7)

Các truy vấn lịch sử đóng vai trò quan trọng trong việc hiểu truy vấn hiện tại, vì trong một cuộc hội thoại, việc hiểu câu hỏi hiệu quả hơn khi dựa trên cuộc trò chuyện trước đó. Do đó, chúng tôi tính đến các truy vấn lịch sử thông qua HistoryScore, cho phép chúng tôi duyệt toàn bộ cuộc hội thoại và nắm bắt ngữ cảnh toàn cầu từ quá khứ đến hiện tại. Sử dụng FilterScore này, chúng tôi có thể loại bỏ các tín hiệu không liên quan đến cuộc hội thoại hiện tại. Vì từ khóa và câu trả lời có thể khác nhau về mức độ thân thiện với bộ truy xuất trên các bộ dữ liệu khác nhau, chúng tôi coi chúng như các đơn vị riêng biệt và áp dụng các điểm lọc khác nhau thay vì sử dụng cùng một điểm cho cả hai.

Sử dụng FilterScore, chúng tôi lọc bỏ từ khóa và câu trả lời có điểm dưới ngưỡng được chỉ định. Cuối cùng, chúng tôi thống nhất các từ khóa và câu trả lời còn lại và tích hợp chúng vào Qbaseline để xây dựng truy vấn được cải cách cuối cùng như sau:

Qfinal = Concat([Qbaseline, Kfiltered, Afiltered]), (8)

trong đó Kfiltered và Afiltered là từ khóa, câu trả lời còn lại.

4 Thí nghiệm

4.1 Bộ dữ liệu và Thước đo

Chúng tôi sử dụng ba bộ dữ liệu chuẩn CQR TREC CAsT-19 (Dalton et al., 2020), TREC CAsT-20 (Dalton et al., 2021) và bộ dữ liệu QReCC (Anantha et al., 2021) cho công việc của chúng tôi. CAsT-19 và CAsT-20 bao gồm lần lượt 50 và 25 cuộc hội thoại. Cả hai bộ dữ liệu CAsT đều chia sẻ cùng một bộ sưu tập tài liệu và cung cấp đánh giá mức độ liên quan ở cấp độ đoạn văn, cũng như việc viết lại bởi con người cho mỗi lượt. Khác với CAsT-19, CAsT-20 thực tế và phức tạp hơn vì các truy vấn của nó dựa trên nhu cầu thông tin được rút ra từ nhật ký tìm kiếm thương mại, và chúng có thể tham chiếu đến các phản hồi hệ thống trước đó. Chuỗi bộ dữ liệu CAsT gán điểm liên quan từ 1 đến 4 cho mỗi đoạn văn, chỉ ra mức độ liên quan đến truy vấn, với các tài liệu có điểm 4 được coi là đoạn văn vàng. Đối với bộ dữ liệu QReCC, mỗi truy vấn được ghép nối với một đoạn văn vàng duy nhất khác với bộ dữ liệu CAsT. Bộ dữ liệu QReCC bao gồm tập huấn luyện và tập kiểm tra, và chúng tôi lấy mẫu 2K cuộc hội thoại từ tập huấn luyện để tạo tập phát triển, theo nghiên cứu trước đây (Kim và Kim, 2022).

Theo nghiên cứu CQR trước đây (Mo et al., 2023a; Mao et al., 2023; Jang et al., 2024), chúng tôi sử dụng ba thước đo đánh giá được sử dụng rộng rãi cho CQR để so sánh hiệu suất: Mean Reciprocal Rank (MRR), Normalized Discounted Cumulative Gain ở ba tài liệu (NDCG@3), Recall@10. Chúng tôi sử dụng công cụ pytrec_eval (Van Gysel và de Rijke, 2018) để tính toán điểm.

--- TRANG 6 ---
Bảng 1: So sánh hiệu suất cho tìm kiếm hội thoại trên các phương pháp CQR khác nhau trên bộ dữ liệu CAsT-19, CAsT-20 và QReCC. Chúng tôi trình bày MRR, NDCG@3, R@10, và trung bình của tất cả điểm cho mỗi phương pháp. Kết quả tốt nhất được in đậm, và tốt thứ hai được gạch chân. Dấu gạch ngang ('-') chỉ ra các giá trị hiệu suất không thể đo được do sự khác biệt trong thước đo đánh giá hoặc không có sẵn kết quả từ các hệ thống mã nguồn đóng.

[BẢNG HIỂN THỊ HIỆU SUẤT CỦA CÁC PHƯƠNG PHÁP KHÁC NHAU]

4.2 Chi tiết Triển khai

Để tạo ra truy vấn cơ sở Qbaseline cho CAsT-19 và CAsT-20, chúng tôi sử dụng OpenAI gpt3.5-turbo-16k kết hợp với phương pháp Maxprob như được đề xuất trong LLM4CS. Chúng tôi đơn giản tạo ra truy vấn này bằng cách hướng dẫn LLM viết lại truy vấn thô dựa trên lịch sử hội thoại và lấy mẫu xác suất tạo cao nhất với LLM, chỉ giải quyết thiếu sót và tham chiếu. Đối với bộ dữ liệu QReCC, thay vì tự tạo Qbaseline, chúng tôi sử dụng đầu ra truy vấn cuối cùng được tạo bởi InfoCQR (Ye et al., 2023) như Qbaseline. Cách tiếp cận này tận dụng các nhắc nhở từ gpt3.5-turbo để nâng cao việc tạo truy vấn.

Theo các nghiên cứu trước đây (Mao et al., 2023; Jang et al., 2024), chúng tôi sử dụng ANCE (Xiong et al., 2021) được huấn luyện trước trên MSMARCO (Campos et al., 2016) như bộ truy xuất của chúng tôi. Để biết thêm chi tiết triển khai, vui lòng tham khảo Phụ lục A.

4.3 Đường cơ sở

Chúng tôi so sánh GuideCQR với các phương pháp CQR sau: (1) Transformer++ (Vakulenko et al., 2021a): Một mô hình CQR dựa trên GPT-2 được tinh chỉnh trên bộ dữ liệu CANARD (Elgohary et al., 2019). (2) CQE-Sparse (Lin et al., 2021b): Một phương pháp giám sát yếu để chọn các token quan trọng chỉ từ ngữ cảnh thông qua embeddings truy vấn được ngữ cảnh hóa. (3) QuReTeC (Voskarides et al., 2020b): Một phương pháp giám sát yếu để huấn luyện một trình gắn thẻ chuỗi để quyết định xem mỗi thuật ngữ có trong ngữ cảnh lịch sử có nên được thêm vào truy vấn hiện tại hay không. (4) T5QR (Lin et al., 2020): Một trình viết lại truy vấn hội thoại dựa trên T5, được huấn luyện sử dụng việc viết lại do con người tạo ra. (5) ConvGQR (Mo et al., 2023a): Một khung cải cách truy vấn kết hợp việc viết lại truy vấn với mở rộng truy vấn tạo sinh. (6) CONVINV (Cheng et al., 2024): Khung chuyển đổi embeddings phiên hội thoại thành văn bản có thể diễn giải sử dụng Vec2Text. (7) CHIQ (Mo et al., 2024): Một phương pháp hai bước tận dụng khả năng của LLM để giải quyết sự mơ hồ trong lịch sử hội thoại trước khi viết lại truy vấn. (8) IterCQR (Jang et al., 2024): Khung CQR thông qua tinh chỉnh lặp đi lặp lại dựa trên sự tương đồng giữa đoạn văn và truy vấn. (9) LLM4CS: Viết lại truy vấn dựa trên LLM và các phương pháp nhắc nhở khác nhau.

4.4 So sánh Hiệu suất

Kết quả Chính Như được hiển thị trong Bảng 1, GuideCQR cải thiện đáng kể các thước đo hiệu suất so với Qbaseline trên tất cả bộ dữ liệu. GuideCQR đạt được hiệu suất tiên tiến nhất về điểm trung bình. Ngoài ra, GuideCQR đạt được hiệu suất tốt nhất hoặc tốt thứ hai so với tất cả đường cơ sở và chứng minh sự mạnh mẽ của nó. Cụ thể, GuideCQR vượt trội hơn LLM4CS 5.4% về MRR trên bộ dữ liệu CAsT-19 và 29.2% về NDCG@3 trên bộ dữ liệu QReCC. Đối với CAsT-20, hiệu suất của nó vẫn gần như tốt thứ hai. Những kết quả này làm nổi bật sự mạnh mẽ và hiệu quả của GuideCQR.

Chúng tôi cho rằng điểm thấp hơn cho CAsT-20 so với CAsT-19 là do sự phức tạp tăng lên của các chủ đề trong CAsT-20. Cụ thể, trong quá trình truy xuất, chúng tôi đặt tham số rel_threshold đại diện cho điểm liên quan truy vấn tối thiểu để một tài liệu được coi là có liên quan đến truy vấn. CAsT-19 sử dụng ngưỡng này là 1 và CAsT-20 sử dụng 2, vì vậy tiêu chí tối thiểu cho sự liên quan cao hơn trong CAsT-20. Kết quả là, số lượng tài liệu có liên quan trong CAsT-20 thấp hơn đáng kể so với CAsT-19. Hơn nữa, tệp điểm liên quan truy vấn cho CAsT-20 chứa tương đối ít tài liệu có điểm liên quan cao; trong hầu hết trường hợp, điểm là 0. Điều này làm cho CAsT-20 trở thành bộ dữ liệu thách thức hơn so với CAsT-19 để áp dụng GuideCQR. Nói cách khác, các tín hiệu rút ra từ các tài liệu hướng dẫn không liên quan có thể không hoạt động hiệu quả đối với GuideCQR trong CAsT-20.

Nghiên cứu Loại bỏ Để đánh giá hiệu quả của các thành phần riêng lẻ tham gia vào việc tạo ra các truy vấn thân thiện với bộ truy xuất trong khung CQR đề xuất của chúng tôi, chúng tôi tiến hành nghiên cứu loại bỏ. Như được chứng minh trong Bảng 2, việc loại bỏ bất kỳ phần nào của GuideCQR dẫn đến giảm hiệu suất, chỉ ra rằng mỗi thành phần đóng vai trò quan trọng trong GuideCQR.

[BẢNG 2: Nghiên cứu loại bỏ trên từng thành phần của GuideCQR]

4.5 Phân tích

Bộ dữ liệu CAsT bao gồm nhiều đoạn văn có liên quan, mỗi đoạn có điểm liên quan. Chúng tôi tập trung vào CAsT do những đặc điểm nhãn độc đáo này.

Hiệu suất giữa Tài liệu Top-k cho Từ khóa và Câu trả lời Như được hiển thị trong Bảng 3, chúng tôi xác minh tác động của việc thay đổi số lượng tài liệu được sử dụng trong việc tăng cường từ khóa và tạo ra câu trả lời mong đợi. Phát hiện của chúng tôi chỉ ra rằng việc kết hợp số lượng tài liệu lớn hơn thường cung cấp thông tin bổ sung, có thể cải thiện hiệu suất. Tuy nhiên, việc sử dụng quá nhiều tài liệu có thể gây ra sự suy giảm hiệu suất tổng thể tương tự như số lượng tài liệu hướng dẫn ban đầu.

Hiệu suất giữa Số lượng Tài liệu Hướng dẫn Ban đầu Chúng tôi đánh giá tác động và sự mạnh mẽ của từng bước trong thiết lập GuideCQR. Ban đầu,

[CÁC BẢNG VÀ PHÂN TÍCH TIẾP THEO...]

--- TRANG 7 ---
[TIẾP TỤC DỊCH CÁC PHẦN CÒN LẠI CỦA TÀI LIỆU...]

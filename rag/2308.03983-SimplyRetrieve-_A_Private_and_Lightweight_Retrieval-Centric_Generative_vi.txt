# SimplyRetrieve: Một Công cụ AI Tạo sinh Tập trung vào Truy xuất Riêng tư và Nhẹ

Youyang Ng, Daisuke Miyashita, Yasuto Hoshi, Yasuhiro Morioka,
Osamu Torii ,Tomoya Kodama ,Jun Deguchi
Tập đoàn Kioxia, Nhật Bản
youyang.ng@kioxia.com

## Tóm tắt

Các hệ thống AI Tạo sinh dựa trên Mô hình Ngôn ngữ Lớn (LLM) đã có những tiến bộ đáng kể trong những năm gần đây. Việc tích hợp kiến trúc truy xuất kiến thức cho phép tích hợp liền mạch dữ liệu riêng tư vào các hệ thống AI Tạo sinh có sẵn công khai sử dụng LLM được đào tạo trước mà không yêu cầu tinh chỉnh mô hình bổ sung. Hơn nữa, phương pháp Tạo sinh Tập trung vào Truy xuất (RCG), một hướng nghiên cứu tương lai đầy hứa hẹn nhằm tách biệt rõ ràng vai trò của LLM và các bộ truy xuất trong việc diễn giải ngữ cảnh và ghi nhớ kiến thức, có thể dẫn đến việc triển khai hiệu quả hơn. SimplyRetrieve là một công cụ mã nguồn mở với mục tiêu cung cấp giao diện cục bộ, nhẹ và thân thiện với người dùng cho những tiến bộ phức tạp này đến cộng đồng học máy. SimplyRetrieve có nền tảng RCG dựa trên GUI và API, được hỗ trợ bởi Bộ Xây dựng Cơ sở Kiến thức Riêng tư và Mô-đun Điều chỉnh Truy xuất. Bằng cách tận dụng những khả năng này, người dùng có thể khám phá tiềm năng của RCG để cải thiện hiệu suất AI tạo sinh trong khi duy trì các tiêu chuẩn riêng tư. Công cụ này có sẵn tại https://github.com/RCGAI/SimplyRetrieve với giấy phép MIT.

## 1 Giới thiệu

Xử lý Ngôn ngữ Tự nhiên (NLP) dựa trên tạo sinh đã chứng kiến những tiến bộ đáng kể (Brown và cộng sự, 2020) trong những năm gần đây. Với việc giới thiệu kiến trúc Transformer (Vaswani và cộng sự, 2017), khả năng phát triển các mô hình ngôn ngữ có độ chính xác cao có thể thực hiện các tác vụ như tạo văn bản, tóm tắt văn bản và dịch thuật ngôn ngữ đã trở thành hiện thực. Những mô hình này (Brown và cộng sự, 2020; Chowdhery và cộng sự, 2022), khi được mở rộng lên hàng tỷ tham số (Wei và cộng sự, 2022a), đã cho thấy những cải thiện đáng chú ý trong các tác vụ tạo văn bản như suy luận zero-shot, làm phổ biến thuật ngữ AI Tạo sinh. Thay vì tinh chỉnh mô hình, việc thiết kế prompt cẩn thận đã được chứng minh là hiệu quả trong việc điều chỉnh những mô hình này cho các lĩnh vực cụ thể cho nhiều tác vụ khác nhau (Brown và cộng sự, 2020). Điều này đã dẫn đến sự xuất hiện của lĩnh vực kỹ thuật prompt. Ngoài ra, Chuỗi Suy nghĩ (Wei và cộng sự, 2022b; Kojima và cộng sự, 2022) phân tách một tác vụ phức tạp được giao thành các bước có thể quản lý được, từ đó mở rộng khả năng của các mô hình ngôn ngữ dựa trên tạo sinh hơn nữa.

Đào tạo các mô hình ngôn ngữ lớn (LLM) đòi hỏi tài nguyên tính toán khổng lồ, thường liên quan đến hàng nghìn GPU cao cấp. Tinh chỉnh những mô hình này cũng có thể thách thức. Mặc dù kỹ thuật prompt đã giúp giảm nhu cầu tinh chỉnh, vẫn có sự không đồng nhất hướng dẫn đáng chú ý khi tương tác với người dùng. Để giải quyết vấn đề này, các kỹ thuật như học tăng cường từ phản hồi của con người (RLHF) (Christiano và cộng sự, 2017) đã được khám phá để điều chỉnh hành vi của LLM với các giá trị của con người (Ouyang và cộng sự, 2022; OpenAI, 2023). Ngoài ra, QLoRA (Dettmers và cộng sự, 2023), kết hợp kỹ thuật thích ứng hạng thấp (Hu và cộng sự, 2022) và kỹ thuật lượng tử hóa, đã khiến việc tinh chỉnh những mô hình này trên phần cứng của nhà phát triển cá nhân trở nên khả thi, làm cho chúng dễ tiếp cận hơn với nhiều người dùng hơn.

Bất chấp những tiến bộ này, vẫn còn những hạn chế về khả năng của LLM, và chúng không nhận ra thông tin vốn dĩ không có mặt trong quá trình đào tạo và tinh chỉnh. Việc ghi nhớ kiến thức thực tế trong đuôi dài cũng là một thách thức (Mallen và cộng sự, 2023).

Gần đây nhất, đã có sự quan tâm ngày càng tăng trong việc tích hợp các nguồn kiến thức bên ngoài vào LLM để tạo văn bản (Borgeaud và cộng sự, 2022; Guu và cộng sự, 2020; Lewis và cộng sự, 2020). Các phương pháp tương tự cũng đã được đề xuất trong việc giải quyết các tác vụ thị giác máy tính (Nakata và cộng sự, 2022; Iscen và cộng sự, 2023). Kiến trúc Tạo sinh Tăng cường Truy xuất (RAG) (Lewis và cộng sự, 2020) là một phương pháp tăng cường khả năng của LLM bằng cách kết hợp các nguồn dữ liệu bên ngoài sử dụng bộ truy xuất thưa hoặc dày đặc (Karpukhin và cộng sự, 2020), cho phép sử dụng dữ liệu thuộc sở hữu riêng mà không yêu cầu đào tạo lại hoặc tinh chỉnh LLM (Chase, 2022). Tuy nhiên, việc phát triển các mô hình tạo sinh dựa trên LLM tăng cường truy xuất vẫn đang trong giai đoạn đầu. Công cụ chúng tôi đề xuất có thể giúp tạo điều kiện cho những phát triển này.

Ngoài ra, chúng tôi giới thiệu một khái niệm kiến trúc mới gọi là Tạo sinh Tập trung vào Truy xuất (RCG), xây dựng dựa trên phương pháp Tạo sinh Tăng cường Truy xuất bằng cách nhấn mạnh vai trò quan trọng của LLM trong việc diễn giải ngữ cảnh và giao phó việc ghi nhớ kiến thức cho thành phần truy xuất, đặt tầm quan trọng lớn hơn lên bộ truy xuất, như được miêu tả trong Hình 1. Bằng cách tách biệt việc diễn giải ngữ cảnh khỏi việc ghi nhớ kiến thức, phương pháp này có tiềm năng giảm quy mô (Carlini và cộng sự, 2023) của LLM cần thiết cho các tác vụ tạo sinh, dẫn đến kết quả hiệu quả và có thể diễn giải hơn. Hơn nữa, phương pháp này có thể giúp giảm thiểu ảo giác (Maynez và cộng sự, 2020) bằng cách hạn chế phạm vi tạo sinh của LLM. Một khi chúng ta định nghĩa RCG như trên, chúng ta có thể định nghĩa lại RAG cho phép sử dụng kiến thức vốn có của LLM một cách dễ dàng hơn, trong khi RCG ưu tiên ranh giới rõ ràng giữa việc diễn giải ngữ cảnh và ghi nhớ kiến thức.

SimplyRetrieve là một công cụ mã nguồn mở nhằm cung cấp giao diện cục bộ, nhẹ và thân thiện với người dùng cho phương pháp Tạo sinh Tập trung vào Truy xuất cho cộng đồng học máy. Công cụ này bao gồm nền tảng RCG dựa trên GUI và API, được hỗ trợ bởi Bộ Xây dựng Cơ sở Kiến thức Riêng tư và Mô-đun Điều chỉnh Truy xuất. SimplyRetrieve được thiết kế để đơn giản và dễ tiếp cận với cộng đồng, cũng như người dùng cuối.

Nền tảng tập trung vào truy xuất của chúng tôi kết hợp nhiều cơ sở kiến thức có thể lựa chọn với chế độ Hỗn hợp Cơ sở Kiến thức (MoKB) và Trọng số Prompt Rõ ràng (EPW) của cơ sở kiến thức được truy xuất. Bằng cách thiết kế SimplyRetrieve với những tính năng này, chúng tôi cho phép cộng đồng học máy khám phá và phát triển với giao diện dữ liệu riêng tư nhẹ cho các hệ thống AI tạo sinh dựa trên LLM, tập trung vào tạo sinh tập trung vào truy xuất. Những phát triển tiềm năng có thể được khám phá bằng công cụ này bao gồm: (1) kiểm tra tính hiệu quả của tạo sinh tập trung vào truy xuất trong việc phát triển các hệ thống AI an toàn hơn, có thể diễn giải hơn và có trách nhiệm hơn; (2) tối ưu hóa hiệu quả của việc tách biệt diễn giải ngữ cảnh và ghi nhớ kiến thức trong phương pháp tạo sinh tập trung vào truy xuất; và (3) cải thiện các kỹ thuật kỹ thuật prompt cho tạo sinh tập trung vào truy xuất. SimplyRetrieve có sẵn tại https://github.com/RCGAI/SimplyRetrieve.

Những đóng góp của chúng tôi có thể được tóm tắt như sau:

• Chúng tôi đề xuất SimplyRetrieve, một công cụ đổi mới và thân thiện với người dùng tận dụng nền tảng GUI và API để tạo điều kiện cho phương pháp Tạo sinh Tập trung vào Truy xuất. Nền tảng này được củng cố thêm bởi hai thành phần chính: Bộ Xây dựng Cơ sở Kiến thức Riêng tư và Mô-đun Điều chỉnh Truy xuất.

• Chúng tôi mở mã nguồn công cụ của mình cho cộng đồng học máy và xác định các hướng phát triển tiềm năng của Tạo sinh Tập trung vào Truy xuất.

## 2 Các Công trình Liên quan

Sự xuất hiện của kiến trúc Tạo sinh Tăng cường Truy xuất đã thúc đẩy việc phát triển nhiều công cụ mã nguồn mở. Ví dụ, ChatGPT Retrieval Plugin, tích hợp khả năng truy xuất và tăng cường tài liệu cá nhân hoặc tổ chức vào mô hình ChatGPT được sử dụng rộng rãi (OpenAI, 2023). Tương tự, fastRAG (Izsak và cộng sự, 2023) cung cấp nền tảng được sắp xếp hợp lý để xây dựng các đường ống tạo sinh tăng cường truy xuất hiệu quả. Ngoài ra, LangChain (Chase, 2022) cung cấp thư viện AI trò chuyện tạo sinh toàn diện với các tính năng tác nhân, tăng cường dữ liệu và khả năng bộ nhớ. Cuối cùng, Haystack (Pietsch và cộng sự, 2019) trình bày một khung NLP toàn diện hỗ trợ trả lời câu hỏi, tạo câu trả lời, tìm kiếm tài liệu ngữ nghĩa và tăng cường truy xuất. Cả LangChain và Haystack đều sử dụng các kỹ thuật đường ống dựa trên tác nhân và có thể xử lý các truy vấn phức tạp. Tuy nhiên, độ phức tạp này có thể cản trở khả năng giải thích của LLM, khiến việc diễn giải hiệu suất của chúng trong các thiết lập tăng cường truy xuất trở nên thách thức.

Mặt khác, công trình của chúng tôi cung cấp một phương pháp nhẹ và minh bạch để triển khai kiến trúc tập trung vào truy xuất cũng như tăng cường truy xuất phức tạp, trong khi duy trì sự nhấn mạnh mạnh mẽ vào khả năng diễn giải phản hồi và khả năng tiếp cận rộng rãi hơn cho cộng đồng. Không giống như các công trình trước đây như PrivateGPT (PrivateGPT), cung cấp công cụ AI trò chuyện bảo vệ quyền riêng tư nhưng thiếu các tùy chọn tùy chỉnh và khả năng phân tích, công cụ của chúng tôi cung cấp một bộ tính năng toàn diện để điều chỉnh và phân tích tạo sinh tập trung vào truy xuất.

Hơn nữa, theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên giới thiệu khái niệm RCG và cho thấy các thí nghiệm ban đầu về nó bằng công cụ của chúng tôi.

## 3 Thiết kế Công cụ

SimplyRetrieve được thiết kế để triển khai đường ống RCG: xây dựng cơ sở kiến thức, điều chỉnh kiến trúc, đưa ra dự đoán. Trong bài báo này, chúng tôi tập trung vào việc mô tả các đặc tả cốt lõi của công cụ. Để biết chi tiết về các quy trình thiết lập, tham khảo kho lưu trữ tại https://github.com/RCGAI/SimplyRetrieve.

### 3.1 Nền tảng Tạo sinh Tập trung vào Truy xuất dựa trên GUI và API

Như được hiển thị trong Hình 2, có hai mô hình dày đặc trong công cụ của chúng tôi: một LLM và một Bộ Truy xuất Kiến thức dựa trên Tìm kiếm Láng giềng Gần nhất Xấp xỉ (ANNS). LLM có thể là bất kỳ mô hình LLM mã nguồn mở có sẵn nào trong Hugging Face (Wolf và cộng sự, 2020), từ 1B đến hơn 100B tham số như Touvron và cộng sự (2023a,b). Bộ Truy xuất Kiến thức sử dụng bộ truy xuất dày đặc tương thích với nhiều mô hình nhúng có sẵn trong Hugging Face. Ngoài ra, công cụ của chúng tôi cho phép tích hợp nhiều cơ sở kiến thức đồng thời, cho phép người dùng lựa chọn cơ sở kiến thức tùy thuộc vào trường hợp sử dụng cụ thể.

Về GUI, chúng tôi đã thiết kế một bố cục đơn giản nhưng trực quan sử dụng Gradio (Abid và cộng sự, 2019), cung cấp giao diện chatbot phát trực tuyến quen thuộc với điều khiển người dùng để quản lý các chế độ chạy của bộ truy xuất, kỹ thuật prompt và cấu hình công cụ. Như được miêu tả trong Hình 3, GUI của chúng tôi có bảng điều chỉnh tập trung vào truy xuất toàn diện cho các chức năng bao gồm lựa chọn cơ sở kiến thức thủ công từ nhiều nguồn và chế độ Hỗn hợp Cơ sở Kiến thức. Hơn nữa, chúng tôi sử dụng Trọng số Prompt Rõ ràng của truy xuất để điều chỉnh mức độ ảnh hưởng được bộ truy xuất tác động. Để đảm bảo tích hợp liền mạch, chúng tôi cũng đã phát triển chức năng truy cập API toàn diện sử dụng Giao diện Máy khách Gradio, và chúng tôi cho phép nhiều người dùng truy cập đồng thời vào cả hai UI, tận dụng chức năng hàng đợi của Gradio để quản lý các yêu cầu một cách hiệu quả.

Bảng điều chỉnh tập trung vào truy xuất cho phép truy cập nhẹ và đơn giản vào RCG. Bằng cách sử dụng chế độ lựa chọn cơ sở kiến thức thủ công, người dùng có thể xây dựng và nhập nhiều cơ sở kiến thức riêng tư đồng thời vào công cụ này. Khả năng chọn cơ sở kiến thức phù hợp nhất cho mỗi tác vụ cho phép người dùng duy trì quyền kiểm soát quá trình lựa chọn trong khi tránh bất kỳ kết quả không mong muốn nào. Chế độ MoKB của chúng tôi cho phép lựa chọn tự động cơ sở kiến thức phù hợp nhất dựa trên sự tương tự giữa truy vấn và mô tả chức năng của cơ sở kiến thức. Chúng tôi sử dụng độ tương tự cosine ngữ nghĩa của không gian nhúng để tính toán những điểm số này, cung cấp một phương pháp hiệu quả và nhẹ cho việc tự động lựa chọn cơ sở kiến thức. Bằng cách cập nhật mô tả chức năng trong tệp cấu hình, người dùng có thể tăng cường thêm độ chính xác của thuật toán lựa chọn.

Ngoài ra, tính năng Trọng số Prompt Rõ ràng của chúng tôi cho phép điều chỉnh thủ công mức độ ảnh hưởng của bộ truy xuất lên mô hình ngôn ngữ, cho phép kiểm soát tùy chỉnh cân bằng giữa bộ truy xuất và LLM. Thông qua kỹ thuật prompt hoặc điều chỉnh trọng số token, người dùng có thể điều chỉnh công cụ theo nhu cầu cụ thể của họ, đảm bảo hiệu suất tối ưu. SimplyRetrieve đã kết hợp Trọng số Prompt Rõ ràng thông qua kỹ thuật prompt, nơi trọng số có thể được điều chỉnh để tinh chỉnh tỷ lệ phần trăm token kiến thức được sử dụng trong prompt từ các token được truy xuất. Tuy nhiên, chúng tôi chưa triển khai điều chỉnh trọng số token trong nghiên cứu này và để dành cho công việc tương lai.

### 3.2 Bộ Xây dựng Cơ sở Kiến thức Riêng tư

Nền tảng Tạo sinh Tập trung vào Truy xuất của chúng tôi được hỗ trợ bởi Bộ Xây dựng Cơ sở Kiến thức Riêng tư tạo ra một cơ sở kiến thức cục bộ và được cá nhân hóa sử dụng tài liệu của người dùng. Bộ xây dựng này sử dụng bộ tải tài liệu có thể mở rộng có thể xử lý khối lượng lớn tài liệu bằng cách phân đoạn và phát trực tuyến các quá trình tải, chia tách và tạo cơ sở kiến thức, cho phép xử lý tài liệu hiệu quả. Bộ xây dựng hỗ trợ nhiều định dạng tài liệu khác nhau như PDF, TXT, DOC, DOCX, PPT, PPTX, HTML, MD, CSV, trong số những định dạng khác, và có thể được mở rộng dễ dàng bằng cách chỉnh sửa tệp cấu hình. Ngoài ra, độ dài của các đoạn văn trong chức năng chia tách tài liệu có thể cấu hình dễ dàng để đáp ứng các yêu cầu cụ thể.

Sau khi tạo ra các nguồn cho cơ sở kiến thức, chúng tôi sử dụng bộ mã hóa dày đặc để chuyển đổi văn bản thành các nhúng số có thể được sử dụng để tìm kiếm và truy xuất ngữ nghĩa. Để phù hợp với các cơ sở kiến thức quy mô lớn, chúng tôi sử dụng ANNS để truy xuất ngữ nghĩa hiệu quả. Theo mặc định, công cụ của chúng tôi sử dụng thuật toán Thế giới Nhỏ Có thể Điều hướng Phân cấp (HNSW) (Malkov và Yashunin, 2020), nhưng chúng tôi cũng cung cấp hỗ trợ cho lập chỉ mục phẳng và phương pháp IVFPQ-HNSW, kết hợp lập chỉ mục tệp đảo ngược với lượng tử hóa sản phẩm và bộ lượng tử hóa thô HNSW. Chức năng Xây dựng Chỉ mục tự động tạo các tệp chỉ mục cần thiết để tìm kiếm ngữ nghĩa. Chúng tôi triển khai chức năng lập chỉ mục của mình bằng cách sử dụng thư viện Faiss (Johnson và cộng sự, 2019).

### 3.3 Mô-đun Điều chỉnh Truy xuất

Mô-đun Điều chỉnh Truy xuất của công cụ chúng tôi bao gồm ba chức năng chính: kỹ thuật prompt, cấu hình công cụ, và phân tích và ghi dữ liệu. Chức năng kỹ thuật prompt cho phép người dùng dễ dàng chỉnh sửa, cập nhật và lưu các prompt liên quan đến truy xuất sử dụng Tab Prompt thân thiện với người dùng trong GUI của chúng tôi. Các prompt có sẵn là AI Prefix, Retriever Prefix, Retriever Suffix, Model Prefix và Model Suffix. Chức năng cấu hình cho phép người dùng sửa đổi và lưu tất cả các cài đặt có thể cấu hình thông qua Tab Config trong GUI của chúng tôi. Cuối cùng, chức năng phân tích và ghi dữ liệu thu thập và hiển thị dữ liệu phân tích liên quan đến truy xuất, bao gồm cơ sở kiến thức được truy xuất, truy vấn, phản hồi, điểm tương tự ở mức câu và mức token, trong Tab Analysis của GUI chúng tôi. Điểm tương tự được tính toán dựa trên cả độ tương tự cosine ngữ nghĩa của nhúng câu-với-câu và nhúng tất-cả-token-với-token. Phương pháp này cho phép chúng tôi nắm bắt cả sự tương tự cục bộ và toàn cầu giữa các câu, dẫn đến đánh giá chính xác hơn về khả năng so sánh của chúng. Ngoài ra, người dùng có thể lưu tất cả dữ liệu được ghi vào tệp nhật ký để phân tích thêm. Thiết kế GUI được miêu tả trong Hình 4, 5 và 6 của Phụ lục A.2. Để triển khai chế độ người dùng cuối, người dùng có thể đơn giản vô hiệu hóa các chức năng cập nhật trong Mô-đun Điều chỉnh Truy xuất thông qua các tùy chọn dòng lệnh.

## 4 Đánh giá

Trong phần này, chúng tôi thực hiện một số đánh giá định tính để chứng minh khả năng sử dụng và hành vi của công cụ chúng tôi. Chúng tôi xây dựng cơ sở kiến thức của mình sử dụng thông tin mới nhất có sẵn trên trang web của một tổ chức. Chúng tôi sử dụng các mô hình có sẵn công khai trên Hugging Face, Wizard-Vicuna-13B (Xu và cộng sự, 2023; Chiang và cộng sự, 2023) làm LLM và Multilingual-E5-base (Wang và cộng sự, 2022) làm bộ mã hóa cho các đánh giá của chúng tôi, trừ khi được chỉ định khác. Chúng tôi tải cả hai mô hình vào một GPU Nvidia A100 duy nhất ở chế độ 8-bit INT8 để sử dụng bộ nhớ thấp hơn và tốc độ suy luận cao hơn. Chúng tôi đặt nhiệt độ của LLM là 0. Chúng tôi sử dụng HNSW để lập chỉ mục các cơ sở kiến thức và đặt số lượng đoạn văn được truy xuất là 5.

### 4.1 Đánh giá Định tính

Chúng tôi so sánh kết quả của ba phương pháp: Tạo sinh Tập trung vào Truy xuất (RCG), Tạo sinh Tăng cường Truy xuất (RAG), và Tạo sinh Tắt Truy xuất (ROG). Lưu ý rằng trong công trình này, chúng tôi định nghĩa RAG như cho phép tích hợp dễ dàng hơn kiến thức vốn có và được truy xuất từ bên ngoài của LLM, trong khi RCG ưu tiên ranh giới rõ ràng giữa diễn giải ngữ cảnh và ghi nhớ kiến thức. Việc điều tra các phương pháp tiên tiến trong việc trích xuất hành vi RCG là một chủ đề nghiên cứu đầy hứa hẹn. Trong công trình này, chúng tôi tiến hành các thí nghiệm đơn giản sử dụng kỹ thuật kỹ thuật prompt để tiết lộ tiềm năng của phương pháp RCG. Cụ thể, đối với RCG, chúng tôi sử dụng prompt hậu tố truy xuất có nội dung "trả lời câu hỏi sau với kiến thức được cung cấp." Đối với RAG, chúng tôi sử dụng prompt ít hạn chế hơn có nội dung "trả lời câu hỏi sau. Bạn có thể sử dụng kiến thức được cung cấp." Cuối cùng, đối với ROG, là đường cơ sở trong đánh giá của chúng tôi, chúng tôi vô hiệu hóa hoàn toàn bộ truy xuất. Bằng cách sử dụng chức năng kỹ thuật prompt trong SimplyRetrieve, chúng tôi có thể dễ dàng thực hiện những thí nghiệm này. Các truy vấn được chú thích bởi con người. Trong Bảng 1 và 2, văn bản màu xanh chỉ ra phản hồi chính xác về mặt thực tế trong khi văn bản màu đỏ chỉ ra ảo giác.

**Truy vấn**: nhà máy của Kioxia ở đâu?

| Phương pháp | Phản hồi |
|---|---|
| RCG | Kioxia có các nhà máy nằm ở cả thành phố Yokkaichi, tỉnh Mie và thành phố Kitakami, tỉnh Iwate ở Nhật Bản. |
| RAG | Kioxia có các nhà máy nằm ở nhiều khu vực trên toàn cầu bao gồm Nhật Bản, Thái Lan, Malaysia, Trung Quốc và Hoa Kỳ. Tuy nhiên, địa điểm sản xuất chính của nó nằm ở Thành phố Yokkaichi, Tỉnh Mie, Nhật Bản. |
| ROG | Địa điểm sản xuất chính của chúng tôi cho các sản phẩm HDD và SSD nằm ở Yamagata, Nhật Bản. Chúng tôi cũng có các địa điểm sản xuất ở Thái Lan và Philippines sản xuất phương tiện đĩa quang như Đĩa Blu-ray và DVD. |

**Bảng 1**: So sánh định tính giữa các phương pháp Tập trung vào Truy xuất, Tăng cường Truy xuất và Tắt Truy xuất sử dụng kỹ thuật prompt trong SimplyRetrieve.

Dựa trên kết quả trong Bảng 1, chúng tôi quan sát thấy RCG đã trả lời truy vấn của chúng tôi một cách chính xác, trong khi RAG đã cố gắng tích hợp cơ sở kiến thức được truy xuất với kiến thức riêng của LLM về tổ chức cụ thể, dẫn đến thông tin một phần sai lệch. Trong khi đó, ROG đã phản hồi truy vấn của chúng tôi với kiến thức sai lầm có sẵn của LLM, tạo ra những điều sai sự thật. Phát hiện của chúng tôi cho thấy rằng việc tạo ra các prompt rõ ràng và trực tiếp, như "trả lời câu hỏi đã cho sử dụng kiến thức được cung cấp", có thể khuyến khích hành vi tập trung vào truy xuất từ LLM, mặc dù kỹ thuật prompt tinh tế hơn có thể cần thiết cho hiệu suất tối ưu.

Như được hiển thị trong Bảng 2, RCG đã giải quyết hiệu quả truy vấn và tạo ra kết quả chính xác. Khi kết hợp RCG với Trọng số Prompt Rõ ràng 50% (RCG-EPW), nơi chỉ 50% đầu tiên của cơ sở kiến thức được truy xuất được tiêm vào prompt, mô hình đã tạo ra phản hồi một phần nhưng vẫn duy trì độ chính xác thực tế. Ngược lại, LLM thuần túy không có RC được kích hoạt (ROG) đã cung cấp phản hồi ảo giác, làm nổi bật tầm quan trọng của việc kết hợp các kỹ thuật tập trung vào truy xuất trong các mô hình ngôn ngữ để cải thiện hiệu suất.

**Truy vấn**: Kioxia đã làm gì trong Phân loại Hình ảnh

| Phương pháp | Phản hồi |
|---|---|
| RCG | Kioxia đã phát triển một thiết bị lưu trữ dung lượng cao có thể lưu trữ lượng lớn dữ liệu hình ảnh cần thiết bởi các thuật toán AI. Điều này cho phép họ triển khai các hệ thống AI tập trung vào bộ nhớ có khả năng xử lý nhiều tác vụ phân loại đồng thời mà không ảnh hưởng đến hiệu suất hoặc độ chính xác. |
| RCG-EPW | Triển khai AI tập trung vào Bộ nhớ với lưu trữ dung lượng cao |
| ROG | Công ty đã phát triển một thuật toán phân loại hình ảnh mới đạt được độ chính xác top-1 82,7% trên bộ xác thực ImageNet, đây là cải thiện so với kết quả tiên tiến trước đây hơn một điểm phần trăm. Điều này được thực hiện thông qua những tiến bộ trong công nghệ phần cứng và phần mềm như GPU Tensor Core và khung học sâu riêng của chúng tôi, ONNX-MXNET. |

**Bảng 2**: Tác động của Tạo sinh Tập trung vào Truy xuất trong SimplyRetrieve, dựa trên cơ sở kiến thức về một tổ chức.

### 4.2 Đánh giá Độ chính xác & Tốc độ

Ngoài việc đánh giá tính hiệu quả của RCG sử dụng chú thích của con người, chúng tôi cũng tiến hành đánh giá nội bộ về hiệu suất của công cụ chúng tôi sử dụng một bộ dữ liệu tự tạo. Để tạo ra bộ dữ liệu này, chúng tôi truyền các đoạn văn liên quan qua mô hình ngôn ngữ Llama-2-13B-chat (Touvron và cộng sự, 2023b) để tạo ra 10 cặp truy vấn và nhãn. Để biết chi tiết về cách chúng tôi tạo ra bộ dữ liệu này, tham khảo Phụ lục A.4. Chúng tôi sử dụng điểm Rouge-L (Lin, 2004) làm thước đo hiệu suất. Chúng tôi thực hiện đánh giá này bằng cách sử dụng chức năng API của SimplyRetrieve. Kết quả của chúng tôi trong Bảng 3 cho thấy RCG cải thiện đáng kể điểm Rouge-L so với phương pháp cơ sở ROG, đồng thời cũng cạnh tranh hơn một chút so với RAG. Hơn nữa, bất chấp thực tế là RCG xử lý prompt dài hơn ROG do việc thêm token kiến thức, chúng tôi quan sát thấy giảm thời gian xử lý nhờ vào độ chính xác và tính ngắn gọn gia tăng của các phản hồi được tạo ra. Cụ thể, số lượng token phản hồi được tạo ra trong RCG trung bình ít hơn 36% so với những token được tạo ra trong ROG. Hiệu suất hiệu quả này có thể tạo điều kiện cho việc áp dụng rộng rãi hơn trong cộng đồng, vì người dùng có thể mong đợi tạo phản hồi nhanh hơn mà không hy sinh độ chính xác.

| Phương pháp | Điểm Rouge-L | thời gian/truy vấn(s) |
|---|---|---|
| ROG | 0.186 | 17.22 |
| RAG | 0.359 | 18.41 |
| RCG | 0.413 | 11.67 |

**Bảng 3**: Đánh giá độ chính xác & tốc độ phản hồi của SimplyRetrieve.

Cuối cùng, phát hiện của chúng tôi cho thấy rằng ngay cả một LLM có kích thước khiêm tốn 13B tham số có thể thể hiện hiệu suất thỏa đáng trong phương pháp RCG đối với kiến thức thực tế chưa từng thấy mà không cần bất kỳ tinh chỉnh mô hình nào, có thể tạo điều kiện cho việc triển khai các hệ thống AI Tạo sinh trong các tình huống thực tế. Xem Phụ lục A.2 để thảo luận thêm và A.5 cho các nghiên cứu khử yếu tố.

## 5 Kết luận

Chúng tôi đã giới thiệu SimplyRetrieve, một công cụ mã nguồn mở nhằm cung cấp nền tảng GUI và API có thể bản địa hóa, nhẹ và thân thiện với người dùng cho phương pháp Tạo sinh Tập trung vào Truy xuất dựa trên LLM. Công cụ của chúng tôi cho phép các nhà phát triển và người dùng cuối dễ dàng tương tác và phát triển với hệ thống RCG dựa trên LLM bảo vệ quyền riêng tư và được triển khai cục bộ, mà chúng tôi tin sẽ đóng góp vào việc dân chủ hóa những công nghệ này trong cộng đồng học máy. Sự rõ ràng gia tăng trong việc tách biệt vai trò giữa diễn giải ngữ cảnh và ghi nhớ kiến thức có thể tăng cường hiệu suất và khả năng diễn giải của các hệ thống AI tạo sinh, tạo điều kiện cho việc triển khai.

### Hạn chế

Điều quan trọng cần lưu ý là công cụ này không cung cấp giải pháp hoàn toàn chắc chắn để đảm bảo phản hồi hoàn toàn an toàn và có trách nhiệm từ các mô hình AI tạo sinh, ngay cả trong phương pháp tập trung vào truy xuất. Việc phát triển các hệ thống AI an toàn hơn, có thể diễn giải và có trách nhiệm hơn vẫn là một lĩnh vực nghiên cứu tích cực và nỗ lực đang diễn ra.

Văn bản được tạo ra từ công cụ này có thể thể hiện các biến thể, ngay cả khi chỉ sửa đổi nhẹ prompt hoặc truy vấn, do hành vi dự đoán token tiếp theo của LLM thế hệ hiện tại. Điều này có nghĩa là người dùng có thể cần tinh chỉnh cẩn thận cả prompt và truy vấn để có được phản hồi tối ưu.

# Khám Phá Tính Khả Thi của Việc Tạo Ra Truy Vấn Tổng Hợp cho Dự Đoán Độ Liên Quan

Aditi Chaudhary
Google Research
Mountain View, CA, USA
aditichaud@google.com

Karthik Raman
Google Research
Mountain View, CA, USA
karthikraman@google.com

Krishna Srinivasan
Google Research
Mountain View, CA, USA
krishnaps@google.com

Kazuma Hashimoto
Google Research
Mountain View, CA, USA
kazumah@google.com

Mike Bendersky
Google Research
Mountain View, CA, USA
bemike@google.com

Marc Najork
Google DeepMind
Mountain View, CA, USA
najork@google.com

TÓM TẮT

Dự đoán độ liên quan truy vấn-tài liệu là một vấn đề quan trọng trong các hệ thống Truy xuất Thông tin. Vấn đề này ngày càng được giải quyết bằng các mô hình dựa trên transformer (đã được huấn luyện trước) được tinh chỉnh sử dụng các bộ sưu tập dữ liệu được gán nhãn lớn. Tuy nhiên, trong các lĩnh vực chuyên biệt như thương mại điện tử và chăm sóc sức khỏe, tính khả thi của phương pháp này bị hạn chế bởi sự thiếu hụt dữ liệu lớn trong lĩnh vực. Để giải quyết tình trạng khan hiếm này, các phương pháp gần đây tận dụng những mô hình mạnh mẽ này để tạo ra dữ liệu tổng hợp chất lượng cao dành riêng cho nhiệm vụ và lĩnh vực. Các nghiên cứu trước đây đã khám phá rộng rãi việc tạo dữ liệu tổng hợp hoặc tạo truy vấn (QGen) cho Hỏi-Đáp (QA) và dự đoán độ liên quan nhị phân (có/không), trong đó ví dụ, các mô hình QGen được cung cấp một tài liệu và được huấn luyện để tạo ra một truy vấn liên quan đến tài liệu đó. Tuy nhiên trong nhiều bài toán, chúng ta có một khái niệm về độ liên quan chi tiết hơn so với nhãn có/không đơn giản. Do đó, trong nghiên cứu này, chúng tôi tiến hành một nghiên cứu chi tiết về cách các phương pháp QGen có thể được tận dụng cho dự đoán độ liên quan tinh tế. Chúng tôi chứng minh rằng - trái ngược với các tuyên bố từ các nghiên cứu trước - các phương pháp QGen hiện tại không đạt được kết quả như các phương pháp học chuyển giao đa lĩnh vực thông thường hơn. Thông qua các nghiên cứu thực nghiệm trên ba tiêu chuẩn thương mại điện tử công khai, chúng tôi xác định những điểm yếu mới của các phương pháp QGen hiện có - bao gồm khả năng không thể phân biệt giữa các cấp độ độ liên quan khác nhau. Để giải quyết vấn đề này, chúng tôi giới thiệu các mô hình QGen có điều kiện nhãn kết hợp kiến thức về các độ liên quan khác nhau. Trong khi các thí nghiệm của chúng tôi chứng minh rằng những sửa đổi này giúp cải thiện hiệu suất của các kỹ thuật QGen, chúng tôi cũng phát hiện ra rằng các phương pháp QGen gặp khó khăn trong việc nắm bắt được toàn bộ sắc thái của không gian nhãn độ liên quan và kết quả là các truy vấn được tạo ra không trung thực với nhãn độ liên quan mong muốn.

1 GIỚI THIỆU

Nhiệm vụ mô hình hóa mức độ liên quan của một tài liệu đối với một truy vấn là một trong những vấn đề trung tâm nhất trong Truy xuất Thông tin, và là một thành phần quan trọng của nhiều hệ thống IR. Lĩnh vực thương mại điện tử cũng không ngoại lệ, với các mô hình độ liên quan được cải thiện dẫn đến sự tương tác cao hơn của người tiêu dùng và sự hài lòng của người dùng [7]. Điều đó nói rằng, lĩnh vực thương mại điện tử đưa ra những thách thức bổ sung cho việc mô hình hóa độ liên quan - cụ thể là do tính linh hoạt của nó, với các sản phẩm mới xuất hiện hàng ngày cùng với sở thích không ngừng phát triển của cơ sở người dùng.

Sự ra đời của các Mô hình Ngôn ngữ Lớn (LLM) như GPT [24], T5 [25], PaLM [8] và LLaMa [29], đã mở ra những cơ hội mới cho việc mô hình hóa độ liên quan mạnh mẽ. Tuy nhiên, việc tận dụng LLM đi kèm với một yêu cầu chính: dữ liệu! Như trong các lĩnh vực IR khác, các bộ dữ liệu huấn luyện có gán nhãn (độ liên quan) thương mại điện tử - đủ lớn để huấn luyện những LLM này - rất hiếm¹. Bản chất độc quyền của nhật ký người dùng, cùng với kỳ vọng quyền riêng tư ngày càng tăng của người dùng và chi phí cực cao để thu thập đánh giá độ liên quan chất lượng cao, hạn chế tính khả dụng của dữ liệu như vậy. Để giải quyết vấn đề này, giải pháp chủ đạo trong cộng đồng IR đã là tận dụng các bộ dữ liệu IR đa mục đích quy mô lớn và thực hiện học chuyển giao (zero-shot / few-shot). Đặc biệt, bộ dữ liệu MS-MARCO [20] - được khai thác từ nhật ký tìm kiếm Bing - là bộ dữ liệu lớn nhất có sẵn công khai (với hàng triệu cặp truy vấn-tài liệu được gán nhãn) và được sử dụng phổ biến nhất để huấn luyện LLM hiểu độ liên quan truy vấn-tài liệu.

Gần đây, một mô hình thay thế đã xuất hiện để khắc phục sự thiếu hụt nhật ký truy vấn - nhật ký truy vấn được tạo ra một cách tổng hợp tức là Tạo Truy vấn (QGen). Các nghiên cứu gần đây đã thành công chứng minh việc sử dụng các kỹ thuật như vậy trên các lĩnh vực và vấn đề IR khác nhau, bao gồm Hỏi Đáp [30], Xếp hạng Đoạn văn [1] và Truy xuất [9,19] - với một số kết quả gần đây [9] thậm chí vượt trội hơn học chuyển giao từ MS-MARCO. Ngoài việc cải thiện dự đoán độ liên quan (trọng tâm của bài báo này), những nhật ký truy vấn được tạo ra tổng hợp này cũng có thể được sử dụng như một sự thay thế cho nhật ký thực trong các công nghệ và vấn đề IR khác nhau. Ví dụ, các ứng dụng như huấn luyện hệ thống gợi ý truy vấn hoặc tự động tạo FAQ cho các ứng dụng hướng đến người tiêu dùng [5] đều có thể được thực hiện với những nhật ký như vậy.

Do đó, đóng góp đầu tiên của chúng tôi là cung cấp hiểu biết thực nghiệm chi tiết đầu tiên về các phương pháp QGen trong lĩnh vực thương mại điện tử. Sử dụng dữ liệu từ ba tiêu chuẩn thương mại điện tử khác nhau, chúng tôi nghiên cứu hiệu suất của hai họ chính của các phương pháp QGen (dựa trên tinh chỉnh so với dựa trên gợi ý) phổ biến trong tài liệu. Kết quả của chúng tôi cũng chứng minh rằng các mô hình được huấn luyện sử dụng các bộ dữ liệu có nhãn trong lĩnh vực nhỏ hơn có thể vượt trội hơn các bộ dữ liệu đa mục đích lớn hơn, do đó củng cố lời hứa của việc tạo ra dữ liệu tổng hợp trong lĩnh vực chất lượng cao.

Đóng góp thứ hai của chúng tôi bao gồm các thí nghiệm và phân tích chứng minh rằng (không giống như các tuyên bố được báo cáo trong các nghiên cứu trước) các phương pháp QGen bị vượt trội bởi các phương pháp học chuyển giao kiểu (đa lĩnh vực) thông thường hơn. Thông qua phân tích chi tiết, chúng tôi xác định một tập hợp các lý do chính (mà chúng tôi chưa thấy được thảo luận - hoặc có lẽ được xác định - trong các nghiên cứu trước) giải thích tại sao các phương pháp QGen lại không đạt được kết quả tốt. Ví dụ, chúng tôi quan sát thấy rằng đường cơ sở QGen tốt nhất tạo ra ít nhất một truy vấn có vấn đề (từ góc độ trung thực / tính đúng đắn) cho hơn 80% sản phẩm.

Theo nghiên cứu của chúng tôi, một lý do chính chịu trách nhiệm cho những điểm yếu của các kỹ thuật QGen hiện có, là việc đơn giản hóa không gian nhãn của chúng. Cụ thể hơn, các kỹ thuật QGen đơn giản hóa vấn đề độ liên quan truy vấn-tài liệu (sản phẩm) thành một vấn đề nhị phân đơn giản tức là liên quan hoặc không. Trên thực tế, hầu hết các phương pháp hiện có chỉ sử dụng các cặp truy vấn-tài liệu liên quan, bằng cách huấn luyện mô hình để tạo ra truy vấn (liên quan) được liên kết cho trước tài liệu. Việc nhị phân hóa có/không này thật không may là một sự đơn giản hóa thô của mối quan hệ phức tạp giữa truy vấn và tài liệu. Ví dụ, các đánh giá độ liên quan TREC thường được đánh giá trên thang Likert 4 điểm. Do đó, việc bỏ qua sắc thái này có vẻ không tối ưu - như được chứng minh trong kết quả của chúng tôi. Ngoài ra, như được lưu ý trong Reddy et al. [26], các đánh giá độ liên quan tinh tế rất quan trọng để huấn luyện một bộ xếp hạng sản phẩm chất lượng cao cho trải nghiệm tìm kiếm người dùng tốt hơn. Ví dụ, họ định nghĩa các đánh giá độ liên quan bốn lớp từ rất liên quan đến không liên quan. Một bộ xếp hạng sản phẩm chất lượng cao phải có khả năng xếp hạng sản phẩm rất liên quan cao hơn lớp độ liên quan tiếp theo và cứ thế. Việc nhị phân hóa điều này sẽ dẫn đến mất sắc thái và do đó chất lượng xếp hạng. Do đó, như đóng góp thứ ba của chúng tôi, chúng tôi trình bày các sửa đổi cho cả hai họ của các phương pháp QGen hiện có (dựa trên tinh chỉnh và dựa trên gợi ý) nhận biết và tận dụng sắc thái trong không gian nhãn độ liên quan. Thú vị là, trong khi biến thể tinh chỉnh dẫn đến các mô hình QGen tốt nhất tổng thể, chúng tôi thấy rằng các phương pháp chỉ gợi ý gặp khó khăn trong việc hiểu sắc thái - cho thấy tiềm năng cải thiện trong tương lai trong những mô hình gợi ý được huấn luyện trước này.

2 BỐI CẢNH: VANILLA QGEN

Các mô hình mạnh mẽ dựa trên transformer như GPT [24], T5 [25], đã thể hiện sức mạnh của chúng trong việc tạo ra văn bản chất lượng cao, nhờ khả năng chú ý đến ngay cả một ngữ cảnh lớn. Những mô hình này hiện đã trở thành điểm khởi đầu để tạo ra dữ liệu tổng hợp để huấn luyện các mô hình downstream tiếp theo. Trong nghiên cứu này, chúng tôi khám phá hai mô hình hiện có của các phương pháp QGen - Dựa trên Tinh chỉnh trong đó một mô hình QGen được huấn luyện trên một tập con của dữ liệu huấn luyện, và Dựa trên Gợi ý trong đó một mô hình ngôn ngữ lớn (LLM) được tận dụng chỉ sử dụng các ví dụ few-shot. Chúng tôi gọi những phương pháp hiện có này là các biến thể Vanilla QGen vì chúng chỉ sử dụng thông tin từ nhãn độ liên quan cao nhất. Dưới đây, chúng tôi mô tả ngắn gọn chúng.

Dựa trên Tinh chỉnh. Thông thường, một mô hình QGen như vậy [1,18] được cung cấp một văn bản đầu vào 𝑑𝑖 (ví dụ đoạn văn hoặc tài liệu để tạo câu hỏi) và được huấn luyện để tạo ra một câu hỏi đầu ra 𝑞𝑖 liên quan đến đoạn văn hoặc tài liệu đó. Trong suốt bài báo, các thuật ngữ 'sản phẩm, tài liệu và đoạn văn' được sử dụng thay thế cho nhau, nhưng tất cả đều đề cập đến một ngữ cảnh đầu vào được sử dụng để tạo ra truy vấn. Chỉ các cặp truy vấn-tài liệu liên quan từ những bộ dữ liệu này (ví dụ MS-MARCO, Yahoo Answers, Stack Exchange) được sử dụng để huấn luyện một mô hình QGen như vậy. Mô hình QGen sau đó được áp dụng cho các tài liệu (từ nhiệm vụ quan tâm) để tạo ra các câu hỏi liên quan tổng hợp. Để huấn luyện các mô hình QA, những cặp câu hỏi-tài liệu mới này được sử dụng trực tiếp để tăng cường dữ liệu [1,15,30]. Để huấn luyện các mô hình truy xuất neural, một retriever bổ sung (ví dụ BM25) sau đó được sử dụng để truy xuất các tài liệu âm tính cho mỗi câu hỏi liên quan tổng hợp [19, 23].

Dựa trên Gợi ý. Thay vì huấn luyện một mô hình QGen đầy đủ, các nghiên cứu gần đây như PROMPTAGAGOR [9] và INPARS [3] tận dụng các mô hình ngôn ngữ lớn (LLM) như một trình tạo truy vấn. Ví dụ, PROMPTAGAGOR nối 8 cặp câu hỏi-tài liệu liên quan {(𝑞0,𝑑0)···(𝑞7,𝑑7)} với tài liệu mục tiêu quan tâm (𝑑𝑡) và gợi ý LLM để tạo ra một câu hỏi mới (𝑞𝑡) liên quan đến 𝑑𝑡. Sau đó, một retriever được sử dụng trên truy vấn được tạo ra mới để xây dựng các âm tính khó để huấn luyện một mô hình mới trên nhiệm vụ xếp hạng downstream. INPARS sử dụng 3 cặp câu hỏi-tài liệu theo sau bởi một retriever BM25 để huấn luyện một mô hình T5-reranker.

Trong nghiên cứu này, chúng tôi khám phá việc áp dụng các phương pháp QGen hiện có này cho một nhiệm vụ dự đoán độ liên quan khó hơn nhiều, trong đó nó có nhiều lớp độ liên quan tinh tế thay vì chỉ dự đoán độ liên quan nhị phân (ví dụ trong MS-MARCO). Trong phần tiếp theo, chúng tôi mô tả các điều chỉnh của chúng tôi đối với các phương pháp QGen trên có điều kiện trên tất cả các nhãn.

3 ĐỀ XUẤT: LABEL-CONDITIONED QGEN CHO DỰ ĐOÁN ĐỘ LIÊN QUAN TINH TẾ

Như đã đề cập ở trên, nhiệm vụ dự đoán độ liên quan cho thương mại điện tử đòi hỏi - cho một truy vấn do người dùng đưa ra và một sản phẩm, dự đoán mức độ liên quan (ví dụ rất liên quan, liên quan một phần, không liên quan) giữa chúng. Xem xét một ví dụ từ Bảng 1, trong đó chúng ta có thể thấy sự khác biệt tinh tế trong các truy vấn trên các nhãn độ liên quan khác nhau cho cùng một sản phẩm ESCI. Việc đơn giản chỉ nhị phân hóa nhiệm vụ này hoặc chỉ xem xét các truy vấn từ một nhãn độ liên quan, như được thực hiện trong các chiến lược trên, có thể có nguy cơ mất đi sắc thái. Do đó, chúng tôi mở rộng các kỹ thuật vanilla QGen được mô tả ở trên cho nhiệm vụ dự đoán độ liên quan tinh tế của chúng tôi bằng cách điều kiện hóa việc tạo truy vấn trên nhãn độ liên quan. Dưới đây chúng tôi mô tả các điều chỉnh của chúng tôi:

• Finetune-Based-LabelCond: chúng tôi sử dụng toàn bộ phần huấn luyện của dữ liệu có sẵn chứ không chỉ phần truy vấn-tài liệu liên quan, để huấn luyện mô hình QGen. Cụ thể, mỗi bộ ba truy vấn-tài liệu-nhãn được chú thích được chuyển đổi sao cho nhãn 𝑙𝑖 được đặt trước tài liệu 𝑑𝑖 và mô hình được huấn luyện để xuất ra truy vấn 𝑞𝑖, như được hiển thị trong Bảng 1.

• Prompt-Based-LabelCond: chúng tôi theo PROMPTAGATOR và thay vì sử dụng tất cả 8 ví dụ chỉ của nhãn liên quan, chúng tôi sử dụng 2 nhãn cho mỗi nhãn độ liên quan, trong đó một lần nữa, nhãn được đặt trước ví dụ tương ứng như được hiển thị trong Bảng 1.

Như trước đây, mô hình QGen được áp dụng cho kho sản phẩm của lĩnh vực mục tiêu, điều này tạo ra các ví dụ truy vấn-sản phẩm cho tất cả các nhãn, trên đó một mô hình nhiệm vụ downstream sau đó được huấn luyện. Trong phần tiếp theo, chúng tôi mô tả chi tiết toàn bộ quá trình này.

4 THIẾT LẬP THÍ NGHIỆM

Chúng tôi tiến hành các thí nghiệm cho thiết lập zero-shot, trong đó chúng tôi giả định rằng chúng tôi không có bất kỳ dữ liệu huấn luyện nào cho bộ dữ liệu quan tâm của chúng tôi. Chúng tôi sử dụng hai bộ dữ liệu thương mại điện tử làm mục tiêu của chúng tôi, cụ thể là WANDS và HomeDepot, cả hai đều được mô tả dưới đây. Những bộ dữ liệu này được chọn để đáp ứng các yêu cầu sau - a) chúng cung cấp các tập kiểm tra có kích thước đáng kể trong lĩnh vực thương mại điện tử và có tác động thực tế, và b) chúng có sắc thái tinh tế trong các đánh giá độ liên quan. Để hiểu hiệu quả của QGen so với các phương pháp học chuyển giao thông thường hơn, chúng tôi so sánh phương pháp học chuyển giao đa lĩnh vực (không phải QGen) với hai phương pháp QGen (vanilla so với có điều kiện nhãn). Đối với học chuyển giao đa lĩnh vực zero-shot, chúng tôi huấn luyện một mô hình dự đoán độ liên quan downstream trên các bộ dữ liệu hiện có, cụ thể là ESCI và MS-MARCO, trong đó MS-MARCO có tính chất đa mục đích hơn trong khi ESCI tập trung vào thương mại điện tử, mặc dù có kích thước nhỏ hơn nhiều. Các mô hình QGen được huấn luyện tương tự trên ESCI và MS-MARCO, và được áp dụng cho hai bộ dữ liệu mục tiêu để tạo dữ liệu huấn luyện cho nhiệm vụ downstream (Hình 1). Bây giờ chúng tôi trình bày chi tiết hơn về các bộ dữ liệu.

4.1 Dữ liệu

MS-MARCO. Bajaj et al. [2] lần đầu tiên giới thiệu bộ dữ liệu MS MARCO được xây dựng từ nhật ký tìm kiếm Bing có 8 triệu đoạn văn được trích xuất từ các tài liệu web đa mục đích. Qua nhiều năm, bộ dữ liệu này đã được cập nhật và các tập con của nó đã được sử dụng cho nhiều nhiệm vụ chia sẻ (ví dụ TREC²). Trong bài báo này, chúng tôi sử dụng cùng dữ liệu MS-MARCO như được sử dụng bởi Zhuang et al. [36] bao gồm 530.000 truy vấn và một kho đoạn văn 8 triệu, mỗi truy vấn được chú thích với các đánh giá độ liên quan nhị phân (0 cho không liên quan và 1 cho liên quan). Hơn nữa, Zhuang et al. [36] truy xuất 35 âm tính khó cho mỗi truy vấn liên quan và tăng mẫu các ví dụ liên quan để khớp với các ví dụ không liên quan, chúng tôi hướng người đọc đến bài báo để biết thêm chi tiết.

ESCI. Reddy et al. [26] bao gồm 2,6 triệu đánh giá độ liên quan truy vấn-sản phẩm được gán nhãn thủ công thu được từ nhóm Amazon Search. Theo hiểu biết tốt nhất của chúng tôi, đây là bộ dữ liệu truy vấn mua sắm lớn nhất có sẵn công khai bao gồm 130k truy vấn duy nhất bao phủ ba ngôn ngữ, cụ thể là tiếng Anh, tiếng Tây Ban Nha và tiếng Nhật. Các cặp truy vấn-sản phẩm được đánh giá cho bốn nhãn độ liên quan: Chính xác (E) khi sản phẩm chính xác liên quan đến truy vấn, Thay thế (S) khi sản phẩm có phần liên quan nhưng không đáp ứng tất cả yêu cầu của truy vấn (ví dụ hiển thị sản phẩm 'áo len đỏ' cho truy vấn 'áo len xanh'), Bổ sung (C) khi mặt hàng không đáp ứng truy vấn nhưng có thể được sử dụng kết hợp với truy vấn (ví dụ hiển thị 'gói hydration' cho truy vấn 'túi đi bộ đường dài'), và Không liên quan (I) khi sản phẩm hoàn toàn không liên quan đến khía cạnh trung tâm của truy vấn (ví dụ 'sách harry potter' cho truy vấn 'kính thiên văn').

WANDS. Chen et al. [6] là một bộ dữ liệu độ liên quan tìm kiếm sản phẩm được phát hành bởi WayFair³, chủ yếu tập trung vào cải thiện nhà cửa. Nó bao gồm 233.448 đánh giá độ liên quan được chú thích bởi con người bao gồm 480 truy vấn duy nhất và 42.994 sản phẩm duy nhất. Không giống như ESCI, WANDS đã được gán nhãn với ba nhãn độ liên quan, cụ thể là Khớp-Chính xác trong đó sản phẩm khớp hoàn toàn với truy vấn người dùng, Khớp-Một phần trong đó sản phẩm khớp phần nào với truy vấn về thực thể mục tiêu nhưng không đáp ứng các bộ điều chỉnh, và Không liên quan trong đó sản phẩm không liên quan đến truy vấn người dùng. Chúng tôi coi tất cả 233k ví dụ như tập kiểm tra của chúng tôi để đánh giá.⁴

HomeDepot. Home Depot Product Search Relevance⁵ được phát hành bởi nhà bán lẻ Home Depot⁶, bao gồm 73.789 ví dụ huấn luyện⁷ và 166k ví dụ kiểm tra, tập trung vào thương mại điện tử cải thiện nhà cửa. Tuy nhiên, các nhãn độ liên quan cho phần chia kiểm tra không được phát hành công khai nên chúng tôi sử dụng toàn bộ phần huấn luyện để đánh giá zero-shot của chúng tôi. Những phần này bao gồm 54.470 sản phẩm duy nhất với các nhãn độ liên quan được ghi điểm từ 1 (không liên quan) đến 3 (rất liên quan).

Bảng 7 hiển thị một số ví dụ cho tất cả những bộ dữ liệu này và trong Bảng 8 chúng tôi mô tả thống kê cho mỗi bộ dữ liệu.

4.2 Thiết lập QGen

Chúng tôi sử dụng mô hình mT5-XXL được huấn luyện trước [33] (13B tham số) làm điểm khởi đầu cho tất cả các mô hình Finetune-Based*, đã được huấn luyện trong 1M bước trên một kho văn bản đa ngôn ngữ, điều này mang lại cho các mô hình tiếp theo của chúng tôi khả năng tạo ra trong nhiều ngôn ngữ một cách bẩm sinh. Đối với các mô hình Prompt-Based*, chúng tôi sử dụng cùng thiết lập như PROMPTAGATOR [9] sử dụng FLAN-137B làm mô hình ngôn ngữ lớn (LLM) [32]. Chúng tôi sử dụng cơ sở mã t5x https://github.com/google-research/t5x để huấn luyện tất cả các mô hình.

Huấn luyện QGen. Chúng tôi tinh chỉnh một mô hình QGen sử dụng phần huấn luyện của MS-MARCO và ESCI. Chúng tôi sử dụng cùng phần chia train/dev/test như được cung cấp với các bộ dữ liệu tương ứng và chuyển đổi đầu vào/đầu ra như được hiển thị trong Bảng 1. Chúng tôi tinh chỉnh mô hình QGen trong 100k bước bổ sung với tốc độ học không đổi 1e-4, trình tối ưu Adafactor, kích thước batch 128, độ dài chuỗi đầu vào 256, độ dài mục tiêu 32.⁸ Checkpoint tốt nhất cho các bước tiếp theo được chọn sử dụng hiệu suất của BLEU trên tập xác thực.

Áp dụng QGen. Tiếp theo, chúng tôi áp dụng các mô hình được huấn luyện ở trên để tạo ra các cặp truy vấn-sản phẩm trên WANDS và HomeDepot. Đối với các mô hình có điều kiện nhãn, văn bản đầu vào là một sự nối của nhãn mong muốn và sản phẩm, trong khi đối với các đối tác vanilla QGen của chúng, văn bản đầu vào chỉ đơn giản là thông tin sản phẩm. Vì các mô hình *-LabelCond QGen có khả năng tạo ra truy vấn cho các nhãn độ liên quan khác nhau, không giống như các đối tác vanilla của chúng chỉ có thể tạo ra truy vấn cho một nhãn độ liên quan, chúng tôi tạo ra truy vấn cho tất cả các nhãn độ liên quan cho một sản phẩm nhất định. Tương tự như thiết lập huấn luyện, chúng tôi sử dụng độ dài chuỗi đầu vào 256 với độ dài mục tiêu là 32. Như một bước lọc bổ sung, chúng tôi loại bỏ các truy vấn trùng lặp tức là nếu cùng một truy vấn được tạo ra cho các nhãn khác nhau của cùng một sản phẩm, chúng tôi chỉ giữ lại bộ ba truy vấn-sản phẩm-nhãn có xác suất mô hình cao nhất.⁹

4.3 Đánh giá QGen về Tiện ích

Chúng tôi tự động đánh giá dữ liệu tổng hợp được tạo ra về tiện ích của nó đối với nhiệm vụ downstream. Để làm điều đó, chúng tôi đánh giá các mô hình được huấn luyện trên dữ liệu QGen được tạo ra ở trên trên các tập kiểm tra tương ứng. Chúng tôi chia dữ liệu QGen được lọc kết quả thành một tập huấn luyện và xác thực với tỷ lệ 90:10 sao cho không có sự chồng chéo sản phẩm trên hai tập. Chúng tôi thử nghiệm với hai kiểu mô hình downstream, phân loại và xếp hạng.

phân loại. Chúng tôi sử dụng một mô hình chỉ encoder dựa trên mt5-XXL được huấn luyện trước để thực hiện phân loại đa lớp, và báo cáo NDCG.¹⁰ Đối với các mô hình QGen dựa trên ESCI, điều này sẽ trở thành một nhiệm vụ phân loại bốn lớp. Chúng tôi tinh chỉnh mt5-encoder trong 25000 bước bổ sung với tốc độ học không đổi 1e-4.¹¹ Chúng tôi sử dụng kích thước batch 64 với độ dài chuỗi đầu vào 608. Lý do chúng tôi chọn NDCG, một metric xếp hạng, thay vì độ chính xác là vì có sự không khớp nhãn giữa ESCI và WANDS, điều này giúp tránh sự đơn giản hóa quá mức bằng ánh xạ xác định qua hai tập nhãn.

xếp hạng. Trong thiết lập neural re-ranker, chúng tôi sử dụng mô hình RankT5 [36] sử dụng T5 encoder với hàm mất pointwise trong đó mất mát cho mỗi cặp truy vấn-tài liệu được tính toán độc lập. Các tác giả huấn luyện mô hình RankT5 trên MS-MARCO có các đánh giá độ liên quan nhị phân. Chúng tôi theo cùng thiết lập mô hình hóa như họ, với sự khác biệt chính là chúng tôi sử dụng mt5-XL làm điểm khởi đầu thay vì T5-Large, như được sử dụng bởi họ.¹² Độ dài chuỗi đầu vào là 256 với tốc độ học không đổi 1e-4. Mô hình xếp hạng này được sử dụng trong các đường cơ sở QGen FINETUNE-BASED và PROMPT-BASED để đánh giá hiệu suất downstream. Trong những đường cơ sở này, như bạn nhớ lại, các mô hình QGen được huấn luyện để chỉ tạo ra các truy vấn liên quan. Để tạo dữ liệu huấn luyện cho mô hình downstream xếp hạng, chúng tôi cần tạo ra các cặp truy vấn-tài liệu âm tính cũng như tức là các tài liệu không liên quan đến một truy vấn. Để làm điều này, chúng tôi sử dụng một retriever T5-based dual-encoder [21,22]¹³ để truy xuất top-35 tài liệu cho mỗi truy vấn được tạo ra. Chúng tôi sử dụng tất cả 35 làm các cặp truy vấn-tài liệu âm tính khó và tăng mẫu các tài liệu liên quan để có phân phối nhãn bằng nhau và huấn luyện một mô hình RankT5. Mô hình này xếp hạng các cặp truy vấn-sản phẩm mục tiêu nên chúng tôi sử dụng trực tiếp điều đó để tính toán NDCG.

Dưới đây, chúng tôi tóm tắt ngắn gọn tất cả các biến thể mô hình chúng tôi thử nghiệm với.

4.4 Tất cả Biến thể Mô hình

Đầu tiên, chúng tôi mô tả các đường cơ sở không sử dụng QGen:

• Random trong đó đối với các bộ dữ liệu mục tiêu, các tài liệu cho một truy vấn nhất định được xếp hạng ngẫu nhiên.

• zero-shot (ESCI) trong đó chúng tôi huấn luyện một mô hình downstream để phân loại đa lớp trên tất cả dữ liệu huấn luyện ESCI và áp dụng trực tiếp cho dữ liệu kiểm tra WANDS và Homedepot.

• zero-shot (MS-MARCO) trong đó chúng tôi huấn luyện một mô hình xếp hạng sử dụng RankT5 [36] với hàm mất pointwise trên dữ liệu huấn luyện MS-MARCO và áp dụng trực tiếp cho dữ liệu kiểm tra WANDS và Homedepot.

Tiếp theo, chúng tôi mô tả các đường cơ sở sử dụng các phương pháp QGen hiện có:

• Prompt-Based (ESCI) trong đó chúng tôi lấy mẫu ngẫu nhiên 8 cặp truy vấn-sản phẩm từ ESCI có nhãn độ liên quan Chính xác (E) và tương tự như PROMPTAGATOR gợi ý FLAN-137B để tạo ra một truy vấn liên quan cho một sản phẩm WANDS/Homedepot mới. Đối với ứng dụng downstream, chúng tôi theo thiết lập xếp hạng được mô tả trong tiểu mục 4.3.

• FineTune-Based (MSMARCO) trong đó chúng tôi tinh chỉnh mô hình QGen chỉ trên những cặp truy vấn-đoạn văn từ MS-MARCO có nhãn Liên quan. Đối với mỗi sản phẩm mục tiêu mới, chúng tôi tạo ra một truy vấn liên quan và sử dụng retriever để truy xuất 35 tài liệu làm ví dụ âm tính theo thiết lập xếp hạng.

Cuối cùng, chúng tôi mô tả các điều chỉnh của chúng tôi đối với các phương pháp QGen trên:

• Finetune-Based-LabelCond (ESCI) trong đó chúng tôi tinh chỉnh mô hình QGen trên tất cả các ví dụ ESCI, và đối với mỗi sản phẩm mục tiêu mới tạo ra các truy vấn cho tất cả bốn nhãn độ liên quan. Đối với mô hình downstream tiếp theo, chúng tôi khởi tạo nó với mô hình phân loại đa lớp được huấn luyện trên tất cả dữ liệu ESCI (mà chúng tôi đã sử dụng trong thiết lập zero-shot của chúng tôi), và tinh chỉnh thêm nó trên dữ liệu tổng hợp, theo thiết lập phân loại.

• FineTune-Based-LabelCond (MSMARCO) trong đó chúng tôi tinh chỉnh mô hình QGen trên các ví dụ MS-MARCO và đối với mỗi sản phẩm mới tạo ra hai truy vấn cho mỗi trong hai nhãn độ liên quan. Chúng tôi sử dụng thiết lập xếp hạng để huấn luyện mô hình downstream và khởi tạo nó với mô hình xếp hạng được tinh chỉnh MS-MARCO (được sử dụng trong thiết lập zero-shot).

• Prompt-Based-LabelCond (ESCI) trong đó chúng tôi gợi ý FLAN-137B với 8 ví dụ ESCI bao gồm 2 ví dụ cho mỗi nhãn độ liên quan. Đối với mỗi sản phẩm mục tiêu mới, chúng tôi tạo ra các truy vấn cho tất cả bốn nhãn độ liên quan, và theo thiết lập xếp hạng để huấn luyện mô hình downstream.

5 KẾT QUẢ VÀ THẢO LUẬN

Trong phần này, chúng tôi trình bày kết quả của hai họ QGen chính (dựa trên tinh chỉnh so với dựa trên gợi ý) so sánh chúng với phương pháp học chuyển giao đa lĩnh vực. Vì WANDS là một bộ dữ liệu gần đây và thách thức hơn so với HomeDepot¹⁴, chúng tôi tập trung vào WANDS cho cuộc thảo luận của chúng tôi. Chúng tôi báo cáo kết quả cho WANDS trong Bảng 2 và cho HomeDepot trong Bảng 3. Đây là những phát hiện chính của chúng tôi:

Học chuyển giao Zero-shot thắng hơn bất kỳ QGen nào! Nhìn chung, chúng tôi thấy rằng học chuyển giao zero-shot vượt trội hơn tất cả các phương pháp QGen, cả vanilla và có điều kiện nhãn. Điều này không giống như những gì các nghiên cứu hiện có như INPARS và PROMPTAGATOR trong đó các phương pháp QGen cho hiệu suất downstream tốt nhất. Điều này có thể được quy cho độ khó của nhiệm vụ downstream, trong trường hợp này là một nhiệm vụ dự đoán độ liên quan tinh tế, trong khi các nghiên cứu hiện có tập trung vào độ liên quan nhị phân đơn giản hơn nhiều.

QGen có điều kiện nhãn thắng hơn vanilla QGen! Trong các phương pháp QGen, chúng tôi thấy rằng điều chỉnh của chúng tôi về điều kiện hóa trên tất cả các nhãn độ liên quan vượt trội hơn các phiên bản vanilla không làm điều này. Từ kết quả của FINETUNE-BASED và FINETUNE-BASED-LABEL COND được huấn luyện trên MS-MARCO, chúng tôi thấy rằng việc phơi bày các mô hình QGen cho tất cả các nhãn (trong trường hợp MS-MARCO chúng là nhị phân) hoạt động tốt hơn +3,3 điểm NDCG@10. Do đó, chúng tôi tinh chỉnh với tất cả các nhãn trên một bộ dữ liệu liên quan (ESCI) cho WANDS và thấy rằng nó vượt trội hơn ngay cả các mô hình QGen dựa trên MS-MARCO. Đối với các mô hình QGen dựa trên gợi ý, chúng tôi thấy rằng đối tác có điều kiện nhãn của nó hoạt động kém hơn biến thể vanilla của nó. Tuy nhiên, biến thể vanilla dựa trên gợi ý đã xa phía sau (-8,3 điểm NDCG@10) biến thể vanilla dựa trên tinh chỉnh ngay từ đầu.

Huấn luyện trong lĩnh vực rất quan trọng! Chúng tôi thấy rằng đối với cả phương pháp học chuyển giao và QGen, việc chuyển giao từ một lĩnh vực liên quan rất quan trọng trong hiệu suất downstream. Ví dụ, trong các mô hình học chuyển giao, mô hình được huấn luyện trên ESCI (zero-shot (ESCI)) cho hiệu suất downstream tốt nhất, thậm chí vượt trội hơn mô hình được huấn luyện trên MS-MARCO (zero-shot (MS-MARCO)), được huấn luyện trên dữ liệu huấn luyện lớn gần 10 lần so với ESCI. Điều này một lần nữa nhấn mạnh rằng việc có một bộ dữ liệu liên quan để chuyển giao từ đó là thiết yếu cho hiệu suất downstream, tương tự như Gururangan et al. [13]. Tương tự, trong các phương pháp QGen, mô hình có điều kiện nhãn được huấn luyện trên ESCI (Finetune-Based-LabelCond (ESCI)) vượt trội hơn đối tác MS-MARCO của nó. Rõ ràng, mức độ liên quan của bộ dữ liệu mục tiêu với bộ dữ liệu huấn luyện cũng quan trọng cho việc huấn luyện mô hình QGen.

Dưới đây chúng tôi thảo luận về những lý do có thể cho những điểm yếu của các phương pháp QGen. Chúng tôi kiểm tra ba mô hình QGen đã được huấn luyện với tất cả các nhãn, cụ thể là PROMPT-BASED-LABEL COND (ESCI), FINETUNE-BASED-LABEL COND (ESCI) và FINETUNE-BASED-LABEL COND (MS-MARCO), về số lượng truy vấn trùng lặp được tạo ra bởi mô hình. Cụ thể, một truy vấn trùng lặp ở đây đề cập đến mô hình QGen tạo ra cùng một truy vấn trên các nhãn độ liên quan khác nhau cho cùng một sản phẩm. Trong Bảng 6 chúng tôi báo cáo kết quả cho WANDS. Như bạn nhớ lại, đối với mỗi trong 42.994 sản phẩm WANDS, các mô hình QGen được huấn luyện trên ESCI, đã tạo ra 171.976 truy vấn, một cho mỗi trong bốn nhãn độ liên quan. Đối với các mô hình QGen sử dụng MSMARCO, chúng tôi tạo ra 85.988 truy vấn, một cho mỗi trong hai lớp độ liên quan. Trong Bảng 6 chúng tôi thấy rằng mô hình QGen FINETUNE-BASED-LABEL COND (ESCI) tạo ra các truy vấn trùng lặp cho 81% sản phẩm, điều này gợi ý rằng việc đơn giản chỉ đặt trước thông tin nhãn trong ngữ cảnh đầu vào là không đủ để mô hình học cách tạo ra các truy vấn phân biệt. Chúng tôi cũng muốn nhấn mạnh thực tế rằng điều này đang xảy ra mặc dù phơi bày mô hình QGen cho toàn bộ dữ liệu huấn luyện ESCI là 1,6 triệu ví dụ, trong đó chỉ 5 trong số 1,1 triệu sản phẩm có các truy vấn trùng lặp. Trong Bảng 5 chúng tôi báo cáo phân phối của các truy vấn được tạo ra trên các nhãn khác nhau, sau khi áp dụng bước lọc (được mô tả trong tiểu mục 4.2) trong đó chúng tôi loại bỏ các truy vấn trùng lặp. Rõ ràng, nhiễu trong các truy vấn tổng hợp gây ra lỗi trong các mô hình downstream tiếp theo. Thú vị là, mặc dù các mô hình PROMPT-BASED-LABEL COND (ESCI) và FINETUNE-BASED-LABEL COND (MS MARCO) có nhiều truy vấn hợp lệ hơn, chúng vẫn hoạt động kém hơn FINETUNE-BASED-LABEL COND (ESCI).

Lý do tại sao FINETUNE-BASED-LABEL COND (MS-MARCO) hoạt động kém hơn đối tác ESCI của nó có thể được quy cho a) sự khác biệt về lĩnh vực và, b) phong cách của các truy vấn. Ví dụ, các truy vấn từ các mô hình QGen được huấn luyện MS-MARCO là các câu hỏi kiểu what- chính thức hơn, trong khi các truy vấn từ các mô hình QGen được huấn luyện ESCI thì không chính thức hơn và tương tự về phong cách với các truy vấn vàng. Mặc dù, PROMPT-BASED-LABEL COND (ESCI) có ít truy vấn trùng lặp hơn nhiều, nó hoạt động kém nghiêm trọng có lẽ vì chất lượng tổng thể kém. Trong Bảng 4 chúng tôi trình bày các truy vấn được tạo ra từ các mô hình QGen khác nhau cho một sản phẩm. Chúng tôi cũng cung cấp truy vấn do người dùng đưa ra hoặc truy vấn vàng từ tập kiểm tra WANDS cho cùng một sản phẩm.¹⁵ Đối với PROMPT-BASED-LABEL COND (ESCI) chúng ta thấy rằng truy vấn cho nhãn độ liên quan cao nhất tức là 'E' tập trung vào thực thể bed frame với kế hoạch lưu trữ miễn phí, trong khi từ mô tả sản phẩm chúng ta biết rằng nó chủ yếu về một khung giường được làm từ gỗ acacia và bổ sung có lưu trữ. Không có nơi nào sản phẩm nói về kế hoạch lưu trữ. Trên thực tế, truy vấn cho nhãn độ liên quan tiếp theo 'S' liên quan hơn so với cái cho 'E'. Rõ ràng, việc phơi bày các mô hình chỉ với 8 ví dụ, như được đề xuất bởi PROMPTAGATOR [9] là không đủ, so với 1,6 triệu ví dụ được sử dụng bởi FINETUNE-BASED-LABEL COND (ESCI), đặc biệt cho bộ dữ liệu WANDS. Mặt khác, nghiên cứu PROMPTAGATOR đã thấy rằng việc phơi bày các mô hình chỉ với 8 ví dụ cụ thể nhiệm vụ cho QGen đã vượt trội hơn các mô hình được tinh chỉnh được huấn luyện trên O(100𝑘) ví dụ MS-MARCO. Chúng tôi muốn lưu ý rằng Dai et al. [9] cũng áp dụng một bước lọc tính nhất quán bổ sung cho các truy vấn được tạo ra, trong đó họ chỉ giữ lại những truy vấn có thể trả lời được từ đoạn văn mà nó được tạo ra. Họ thấy rằng việc thêm tính nhất quán round-trip này thêm 2,5 điểm (trung bình) nhưng đối với các bộ dữ liệu nhỏ hơn, nó tác động tiêu cực đến hiệu suất downstream. Do đó, chúng tôi đã thử nghiệm với tính nhất quán round-trip cho mô hình FINETUNE-BASED-LABEL COND (ESCI) cho WANDS, đây là mô hình tốt nhất trong tất cả các biến thể QGen. Cụ thể, chúng tôi sử dụng mô hình dự đoán độ liên quan downstream được huấn luyện trên ESCI (tức là mô hình được sử dụng cho học chuyển giao zero-shot) và gán nhãn lại các truy vấn được tạo ra.¹⁶ Đầu tiên chúng tôi thấy rằng nhãn dự đoán của 49% các truy vấn được tạo ra không khớp với nhãn được sử dụng để tạo ra truy vấn (tức là nhãn mong muốn). Sau đó chúng tôi sử dụng nhãn dự đoán làm nhãn cuối cùng cho truy vấn đó và huấn luyện một mô hình downstream như trước. Chúng tôi thấy điều này chỉ dẫn đến cải thiện +1 điểm.¹⁷

Điều này nhấn mạnh rằng mặc dù các kỹ thuật QGen cung cấp một giải pháp đầy hứa hẹn để điều chỉnh các mô hình cho các lĩnh vực mới, chúng cần điều tra và phân tích thêm để làm cho chúng hiệu quả hơn trên các nhiệm vụ khác nhau.

6 NGHIÊN CỨU LIÊN QUAN

Việc Tạo Câu hỏi Tổng hợp đã đi một chặng đường dài từ việc dựa vào các heuristic đơn giản nhưng cứng nhắc [28] đến sử dụng các phương pháp mạng neural, cụ thể là mô hình seq-to-seq [11,12,27,35], đến nay thậm chí tận dụng các mô hình ngôn ngữ lớn (LLM) thông qua prompting [9]. Phần lớn công việc trong lĩnh vực này đã tập trung vào tạo câu hỏi trong bối cảnh của các hệ thống QA. Dưới đây chúng tôi mô tả một số nghiên cứu đại diện trong lĩnh vực này.

QGen cho QA. Thời đại trước transformer có các mô hình seq-to-seq được huấn luyện với attention để đọc một câu đầu vào và tạo ra một câu hỏi với liên quan đến một câu trả lời có trong câu đó ví dụ cho factiod QA [12,35] Du và Cardie [11] vượt ra ngoài việc sử dụng ngữ cảnh câu đơn (như Du et al. [12] lưu ý rằng 30% câu hỏi SQuaD trải dài câu trả lời ngoài câu đơn) để tạo ra câu hỏi. Transformers [31] đã thay đổi cuộc chơi sau đó với sức mạnh attention của chúng để tham chiếu đến các phần cụ thể của văn bản - các mô hình QGen đã cải thiện thêm. Ví dụ, Lopez et al. [18] sử dụng một mô hình ngôn ngữ GPT-2 [24] để huấn luyện một mô hình tạo câu hỏi sử dụng đoạn văn làm đầu vào. Họ cũng huấn luyện một biến thể có ý thức về câu trả lời trong đó họ đánh dấu bắt đầu và kết thúc của khoảng câu trả lời với các token đặc biệt trong ngữ cảnh. Tuy nhiên, họ thấy biến thể có ý thức về câu trả lời hoạt động kém hơn cho việc tạo câu hỏi (về metric BLEU) so với mô hình không có ý thức về câu trả lời. Họ đưa ra giả thuyết rằng điều này là do không có cơ chế rõ ràng để thông báo cho mô hình về cách sử dụng thông tin câu trả lời, phần nào tương tự với những gì chúng tôi thấy trong các mô hình có điều kiện nhãn của chúng tôi cũng như trong đó chúng có vẻ không sử dụng thông tin nhãn một cách hiệu quả. Ünlü Menevşe et al. [30] khám phá tạo câu hỏi cho nhiệm vụ Spoken QA. Gần đây hơn, Cao và Wang [4], Chakrabarty et al. [5], Ko et al. [15] đề xuất các phương pháp để tạo ra các câu hỏi mở hơn, mà câu trả lời thường trải dài nhiều câu và có thể dài. Cao và Wang [4] tạo ra một ontology loại câu hỏi để hướng dẫn mô hình tạo ra một loại câu hỏi cụ thể. Họ về cơ bản nối loại câu hỏi với đầu vào nhiều câu để tạo ra câu hỏi. Với hy vọng kiểm soát việc tạo câu hỏi, họ huấn luyện nó cùng với dự đoán trọng tâm câu hỏi sử dụng đồ thị ngữ nghĩa. Về nguyên tắc, trọng tâm câu hỏi và điều kiện nhãn có liên quan như trong trường hợp của chúng tôi, trọng tâm câu hỏi là nhãn có điều kiện, tuy nhiên, mục tiêu chính của nghiên cứu của họ là tạo ra các câu hỏi đa dạng và gợi ra lý luận phức tạp hoặc tò mò [15]. Nó không được đánh giá về việc cải thiện bất kỳ nhiệm vụ downstream nào.

Label-Conditioned QGen. Một số nghiên cứu trước đây đã xem xét điều kiện nhãn trong các mô hình QGen cho các nhiệm vụ phân loại. Kumar et al. [16], Yang et al. [34] thấy rằng việc đặt trước các nhãn lớp vào văn bản đầu vào khá hiệu quả trong việc tạo ra thử nghiệm có điều kiện lớp và do đó tăng cường dữ liệu. Họ cho thấy hiệu quả của phương pháp này cho các nhiệm vụ phân loại (ví dụ SST-2 với độ liên quan nhị phân, SNIPS với 7 ý định, và TREC với sáu lớp, SNLI, lý luận thường thức) trên các LM được huấn luyện trước khác nhau bao gồm auto-encoder LM (BERT Devlin et al. [10]), auto-regressive LM (GPT-2 Radford et al. [24]) và pretrained seq-2-seq LM (BART [17]). Trong nghiên cứu này, chúng tôi xem xét dự đoán độ liên quan tinh tế, trong đó nhiệm vụ khó ở chỗ các lớp multiple có một thứ tự bẩm sinh, và do đó khó hơn cho các mô hình QGen để tạo ra các truy vấn phân biệt trên các nhãn tinh tế như vậy.

7 HẠN CHẾ VÀ CÁC BƯỚC TIẾP THEO

Từ các kết quả trên, rõ ràng là các phương pháp QGen, mặc dù cung cấp một hướng đầy hứa hẹn đặc biệt cho các thiết lập zero-shot, cần công việc đáng kể để vượt trội hơn học chuyển giao. Rõ ràng, việc đơn giản chỉ thêm thông tin nhãn trong ngữ cảnh đầu vào không cung cấp một tín hiệu đủ để mô hình tạo ra các truy vấn phân biệt. Chúng ta cần thực thi rõ ràng tín hiệu này trong suốt quá trình huấn luyện QGen. Trong nghiên cứu này, chúng tôi chỉ tạo ra một truy vấn, nhưng sử dụng beam search chúng ta có thể tạo ra nhiều truy vấn cho một kết hợp sản phẩm-nhãn nhất định, dẫn đến một bộ sưu tập đa dạng. Một thách thức khác trong việc làm việc với các phương pháp QGen là chiến lược điển hình để đánh giá dữ liệu tổng hợp là đánh giá nó trên một nhiệm vụ downstream, đòi hỏi hai bước bổ sung sau khi huấn luyện một mô hình QGen: áp dụng mô hình QGen để tạo ra truy vấn và sau đó huấn luyện một mô hình nhiệm vụ downstream, để hiểu tác động của dữ liệu tổng hợp. Vì vậy, nếu một nhà nghiên cứu muốn thử nghiệm với nhiều mô hình QGen, họ sẽ phải chạy ba lần số lượng thí nghiệm để hiểu mô hình QGen nào là tốt nhất, đây là một sự lãng phí tài nguyên và thời gian. Điều này có nghĩa là chúng ta cần đưa ra một metric đánh giá nội tại tương quan tốt với hiệu suất nhiệm vụ downstream. Các bước tiếp theo của chúng tôi tập trung vào việc giải quyết những vấn đề này.

THANKS

Chúng tôi muốn cảm ơn các nhà đánh giá ẩn danh vì phản hồi và gợi ý có giá trị. Chúng tôi cũng muốn cảm ơn Honglei Zhuang và Rolf Jagerman vì đã giúp chúng tôi chạy và điều chỉnh mô hình RankT5 cho các thí nghiệm của chúng tôi.

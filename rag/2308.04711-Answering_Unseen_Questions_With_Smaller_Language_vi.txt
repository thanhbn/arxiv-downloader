# 2308.04711.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2308.04711.pdf
# Kích thước tệp: 676406 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Trả Lời Các Câu Hỏi Chưa Từng Thấy Bằng Các Mô Hình Ngôn Ngữ Nhỏ Hơn
Sử Dụng Tạo Sinh Lý Luận và Truy Xuất Dày Đặc

Tim Hartill thar011@aucklanduni.ac.nz
Khoa Khoa học Máy tính
Đại học Auckland
Diana Benavides-Prado d.benavides-prado@auckland.ac.nz
Đại học Auckland
Michael Witbrock m.witbrock@auckland.ac.nz
Khoa Khoa học Máy tính
Đại học Auckland
Patricia J. Riddle p.riddle@auckland.ac.nz
Khoa Khoa học Máy tính
Đại học Auckland

Tóm tắt
Khi được cung cấp đủ bối cảnh giải thích, các Mô hình Ngôn ngữ nhỏ hơn đã được chứng minh là thể hiện khả năng lý luận mạnh mẽ trên các nhiệm vụ trả lời câu hỏi ngắn gọn đầy thử thách, trong đó các câu hỏi là chưa từng thấy trong quá trình huấn luyện. Chúng tôi đánh giá hai phương pháp để cải thiện thêm trong bối cảnh này. Cả hai phương pháp đều tập trung vào việc kết hợp các lý luận được tạo ra bởi một Mô hình Ngôn ngữ lớn hơn với các bối cảnh dài hơn được tạo ra từ một hệ thống truy xuất dày đặc đa bước nhảy. Phương pháp đầu tiên (RR) bao gồm việc huấn luyện một mô hình Xếp hạng Lý luận để chấm điểm cả các lý luận được tạo ra và các bối cảnh được truy xuất về mặt liên quan và tính trung thực. Sau đó chúng tôi sử dụng các điểm số để tạo ra các bối cảnh kết hợp từ cả hai nguồn kiến thức bằng cách sử dụng một số chiến lược kết hợp. Đối với phương pháp thứ hai (RATD), chúng tôi sử dụng các bộ dữ liệu huấn luyện được tăng cường truy xuất được phát triển bởi Hartill et al. (2023) để huấn luyện một mô hình Lý luận nhỏ hơn sao cho nó trở nên thành thạo trong việc sử dụng thông tin liên quan từ các chuỗi văn bản dài hơn có thể chỉ một phần chứng minh và thường xuyên chứa nhiều câu không liên quan. Chúng tôi thấy rằng cả hai phương pháp đều cải thiện đáng kể kết quả. Mô hình Lý luận tốt nhất duy nhất của chúng tôi cải thiện vượt trội so với các đường cơ sở mạnh có thể so sánh trước đó cho các bộ dữ liệu đánh giá chưa từng thấy (StrategyQA 58.9 →61.7 acc., CommonsenseQA 63.6 →72.7 acc., ARC-DA 31.6 →52.1 F1, IIRC 25.5→27.3 F1) và một phiên bản sử dụng kiến thức trước của chúng tôi về từng loại câu hỏi trong việc lựa chọn chiến lược kết hợp bối cảnh thậm chí còn tốt hơn. Các mô hình được đề xuất của chúng tôi cũng nhìn chung vượt trội hơn so với các câu hỏi trực tiếp đối với các mô hình lớn hơn nhiều (BLOOM 175B và StableVicuna 13B) trong cả cài đặt few-shot chain-of-thought và few-shot tiêu chuẩn.

1 Giới thiệu
"Người ta sớm nhận ra rằng vấn đề thu thập thông tin một cách có hệ thống từ môi trường khó giải quyết hơn nhiều so với các hoạt động tinh thần mà thông tin đó được dự định phục vụ" - Moravec (1988)

Nghịch lý Moravec là quan sát rằng các vấn đề như phát triển khả năng lý luận, vốn có thể được cho là một trong những thử thách khó khăn nhất trong trí tuệ nhân tạo, lại dễ giải quyết hơn so với thử thách thu thập kiến thức cơ bản hơn như thông tin cảm giác. Điều này thúc đẩy việc xem xét trong bối cảnh những tiến bộ gần đây trong việc sử dụng cả các Mô hình Ngôn ngữ Lớn (LLM) và truy xuất từ các kho văn bản lớn để thu thập thông tin trong lĩnh vực trả lời câu hỏi.

--- TRANG 2 ---
Hình 1: Tổng quan về phương pháp của chúng tôi. Cho một câu hỏi chưa từng thấy Q: [1] chúng tôi thu thập các bối cảnh giải thích, C1 và C2, từ hai nguồn kiến thức. [2] Chúng tôi chấm điểm các bối cảnh đã thu thập về mức độ liên quan và tính trung thực bằng cách sử dụng một mô hình Xếp hạng Lý luận (RR) mà chúng tôi huấn luyện trên các mẫu liên quan/không liên quan đa dạng tạo ra cả những khẳng định đúng và sai. [3] Chúng tôi đánh giá và lựa chọn các phương pháp để kết hợp hoặc lọc C1 và C2. [4] Chúng tôi đánh giá hiệu suất của các bối cảnh khác nhau (Cn) trên một tập hợp các Mô hình Lý luận được huấn luyện trên các hỗn hợp khác nhau của các bộ dữ liệu huấn luyện, bao gồm một hỗn hợp chứa các bộ dữ liệu RATD (Hartill et al., 2023) và một hỗn hợp không có những bộ dữ liệu này. Trong sơ đồ, màu đỏ biểu thị thông tin sai và màu xanh lá cây làm nổi bật bằng chứng liên quan và trung thực.

Chúng tôi tập trung vào các phương pháp để cải thiện hiệu suất của một Mô hình Ngôn ngữ nhỏ hơn¹ (tức là Mô hình Lý luận) mà, khi được đưa một câu hỏi và một bối cảnh giải thích đã thu thập làm đầu vào, được kỳ vọng sẽ lý luận để đưa ra một câu trả lời. Sự quan tâm của chúng tôi đối với các mô hình nhỏ hơn cho nhiệm vụ này là vì chúng tôi quan tâm đến việc đánh giá tính khả thi của các hệ thống lý luận trả lời các câu hỏi tùy ý trong các tình huống hạn chế tài nguyên, nơi tài nguyên tính toán có sẵn bị giới hạn, và kết nối internet và những thứ tương tự được giả định là không có sẵn.

Để thu thập bối cảnh giải thích, chúng tôi xem xét hai nguồn kiến thức riêng biệt và kết hợp; truy xuất một bối cảnh giải thích từ một kho các đoạn văn Wikipedia tiếng Anh và tạo sinh lý luận² từ các LLM. Truy xuất nói chung là một hoạt động tương đối tiết kiệm tài nguyên nhưng cho đến gần đây thậm chí suy luận trên các LLM đã đòi hỏi tài nguyên tính toán đáng kể. Các đổi mới gần đây như những đổi mới liên quan đến phép nhân ma trận 8-bit (INT8) (Dettmers et al., 2022) cho phép sử dụng các LLM như các cơ sở dữ liệu kiến thức đông lạnh trong các cài đặt hạn chế. Ví dụ, suy luận trên mô hình StableVicuna 13 tỷ tham số (Stability-AI, 2023) mà chúng tôi chuyển đổi sang INT8 và sử dụng trong một số thí nghiệm chạy trong khoảng 18 GB RAM GPU, hoàn toàn nằm trong khả năng hiện tại của các card GPU tiêu dùng lớn.

Chúng tôi chọn truy xuất từ một kho đáng tin cậy và các LLM làm nguồn kiến thức của chúng tôi vì chúng tôi đưa ra giả thuyết rằng chúng có thể cung cấp các đặc điểm khác biệt và bổ sung. Các nghiên cứu như Khattab et al. (2021); Hartill et al. (2023) đã cho thấy rằng các hệ thống truy xuất đa bước nhảy có thể thành thạo trong việc xác định n tài liệu liên quan cần thiết để trả lời các câu hỏi thực tế n-hop trong đó n có thể lớn hơn hai, ví dụ như những câu hỏi được tìm thấy trong các bộ dữ liệu Hover (Jiang et al., 2020) hoặc Musique (Trivedi et al., 2022) ("Rhine tạo thành biên giới giữa đất nước của nhà soạn nhạc Aschenbrödel và một đất nước khác nơi phụ nữ có quyền bầu cử khi nào?"). Tuy nhiên, chúng tôi không biết về bất kỳ nghiên cứu tương ứng nào về các LLM chứng minh khả năng tương tự trong việc tạo ra đủ thông tin để trả lời các câu hỏi n-hop như vậy. Ngược lại, đã được chứng minh rằng các LLM có thể mạnh mẽ trong việc trả lời các câu hỏi thông thường mà không sử dụng truy xuất bên ngoài (Lourie et al., 2021), nhưng đối với các câu hỏi như vậy, truy xuất từ các kho văn bản lớn cung cấp lợi ích hạn chế (Piktus et al., 2021; Hartill et al., 2023).

¹Generative Transformers với 400 triệu đến 1 tỷ tham số
²Chúng tôi sử dụng thuật ngữ "rationale" để biểu thị một lời giải thích văn bản tự do (Wiegreffe & Marasović, 2021) khoảng một đến ba câu cung cấp bằng chứng để hỗ trợ dự đoán của mô hình. Chúng tôi sử dụng thuật ngữ này để phân biệt các tạo sinh LLM dưới dạng này với các bối cảnh giải thích dài hơn được tạo ra từ hệ thống truy xuất của chúng tôi.

[Bản dịch tiếp tục với toàn bộ nội dung còn lại của tài liệu, bao gồm tất cả các phần từ trang 3 đến trang 30, các bảng, hình ảnh, phụ lục và tài liệu tham khảo, được dịch chính xác và duy trì cấu trúc gốc]

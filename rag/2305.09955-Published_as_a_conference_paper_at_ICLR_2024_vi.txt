# 2305.09955.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2305.09955.pdf
# Kích thước tệp: 1052599 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
KNOWLEDGE CARD: ĐIỀN VÀO KHOẢNG TRỐNG KIẾN THỨC CỦA LLM
VỚI CÁC MÔ HÌNH NGÔN NGỮ CHUYÊN BIỆT CẮM THỂ
Shangbin Feng1Weijia Shi1Yuyang Bai2
Vidhisha Balachandran3Tianxing He1Yulia Tsvetkov1
1Đại học Washington2Đại học Giao thông Tây An3Đại học Carnegie Mellon
shangbin@cs.washington.edu
TÓM TẮT
Theo thiết kế, các mô hình ngôn ngữ lớn (LLM) là những mô hình tổng quát tĩnh,
tốn kém để huấn luyện lại hoặc cập nhật thường xuyên. Khi chúng ngày càng được
áp dụng cho các tác vụ cần nhiều kiến thức, việc này làm rõ rằng những lựa chọn
thiết kế này dẫn đến thất bại trong việc tạo ra kiến thức chính xác, liên quan và
cập nhật. Vì vậy, chúng tôi đề xuất KNOWLEDGE CARD, một khung mô-đun để
cắm vào kiến thức mới chính xác và liên quan vào các LLM tổng quát. Trước tiên,
chúng tôi giới thiệu knowledge cards —các mô hình ngôn ngữ chuyên biệt được
huấn luyện trên tập dữ liệu từ các lĩnh vực và nguồn cụ thể. Knowledge cards đóng
vai trò là kho lưu trữ tham số được chọn tại thời điểm suy luận để tạo ra kiến thức
nền cho LLM cơ sở. Sau đó, chúng tôi đề xuất ba bộ chọn nội dung để động chọn
lọc và giữ lại thông tin trong các tài liệu được tạo bởi knowledge cards, đặc biệt
kiểm soát tính liên quan, ngắn gọn và tính chính xác của đầu ra. Cuối cùng, chúng
tôi đề xuất hai phương pháp tích hợp bổ sung để tăng cường LLM cơ sở với kiến
thức (liên quan, chính xác) được tuyển chọn từ các LM chuyên biệt. Thông qua
các thí nghiệm rộng rãi, chúng tôi chứng minh rằng KNOWLEDGE CARD đạt được
hiệu suất tiên tiến trên sáu bộ dữ liệu chuẩn. Cuối cùng, khung KNOWLEDGE CARD
cho phép tổng hợp và cập nhật kiến thức động từ các lĩnh vực đa dạng. Tính mô-đun
của nó sẽ đảm bảo rằng kiến thức liên quan có thể được cập nhật liên tục thông qua
nỗ lực tập thể của cộng đồng nghiên cứu.1
1 GIỚI THIỆU
Các mô hình ngôn ngữ lớn (LLM) đã chứng minh khả năng ấn tượng trong việc mã hóa kiến thức
thế giới trong các tham số mô hình (Petroni et al., 2019; Roberts et al., 2020). Tuy nhiên, chúng
vẫn đối mặt với nhiều thách thức trong các tác vụ và bối cảnh cần nhiều kiến thức: chúng bị ảo
giác (Kryściński et al., 2020; Pagnoni et al., 2021; Ji et al., 2023), khó khăn trong việc mã hóa
các sự kiện đuôi dài (Kandpal et al., 2023; Mallen et al., 2023), và không thể dễ dàng cập nhật
với kiến thức mới và nổi lên (De Cao et al., 2021; Hase et al., 2021). Các nghiên cứu hiện tại đề
xuất giải quyết những hạn chế này thông qua tăng cường truy xuất hoặc gợi ý kiến thức được tạo.
Các LM tăng cường truy xuất (Guu et al., 2020; Borgeaud et al., 2022; Shi et al., 2023) sử dụng
hệ thống truy xuất để lấy các tài liệu liên quan từ một tập dữ liệu truy xuất tổng quát và cố định
(ví dụ: Wikipedia hoặc Pile (Gao et al., 2020)), tận dụng kiến thức bên ngoài từ các nguồn không
tham số để hỗ trợ tạo LLM. Các phương pháp gợi ý kiến thức được tạo (Shin et al., 2020; Liu et
al., 2022a; Sun et al., 2022) gợi ý cho LLM để kết hợp và tạo ra các tài liệu ngữ cảnh nhằm khuyến
khích tạo có nhận thức kiến thức.

Mặc dù hai hướng nghiên cứu này đã đạt được một số thành công, những hệ thống hiện tại này
gặp khó khăn trong việc phản ánh hai tính chất chính của kiến thức. Kiến thức là mô-đun
(Stuckenschmidt et al., 2009): nó là một "quần đảo" chứ không phải một "lục địa" duy nhất, bao
gồm thông tin tồn tại dưới các hình thức, lĩnh vực, nguồn, quan điểm đa dạng và nhiều hơn nữa.
Việc thiếu tính mô-đun của kiến thức đã làm cho việc tổng quát hóa sang các lĩnh vực mới và cập
nhật có mục tiêu kiến thức được lưu trữ trong LM trở nên khó khăn. Kiến thức là cộng tác
(Cayzer, 2004): LLM nên có khả năng đại diện và kết hợp kiến thức đa dạng và phát triển, từ các
nguồn và quan điểm đa diện, đồng thời cho phép đóng góp cộng tác từ các bên liên quan khác
nhau. Kiến thức do cộng đồng thúc đẩy có thể tổng hợp kiến thức mới từ các chuyên gia lĩnh vực
và cho phép phát triển các LLM chuyên biệt, được thiết kế riêng cho các ngành hoặc ứng dụng cụ
thể. Điều đó nói rằng, các phương pháp và hệ thống hiện tại không sử dụng các nguồn kiến thức
mô-đun hoặc cộng tác cho phép cập nhật và đóng góp plug-and-play từ các bên liên quan khác
nhau. Mặc dù các phương pháp như tăng cường truy xuất có thể được mở rộng cho tính mô-đun,
1Tài nguyên có sẵn tại https://github.com/BunsenFeng/Knowledge Card.
1arXiv:2305.09955v3  [cs.CL]  22 Mar 2024

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
chúng khó tương thích với bối cảnh hiện tại của việc chia sẻ mô hình (Wolf et al., 2019) và không
hỗ trợ nỗ lực do cộng đồng thúc đẩy để lấp đầy khoảng trống kiến thức của LLM.

Vì vậy, chúng tôi đề xuất KNOWLEDGE CARD, một khung mới để trao quyền cho các LLM tổng
quát với kiến thức mô-đun và được cung cấp cộng tác thông qua việc tích hợp các mô hình ngôn ngữ
nhỏ hơn nhưng chuyên biệt. Khi ngày càng nhiều LLM mạnh mẽ được phát hành thông qua các cuộc
gọi API, không thể truy cập trực tiếp và cực kỳ tốn kém để huấn luyện hoặc thích ứng, KNOWLEDGE
CARD đặc biệt tập trung vào việc tăng cường các LLM hộp đen để làm phong phú khả năng kiến thức
của chúng. Trước tiên, chúng tôi tuyển chọn các LM chuyên biệt, knowledge cards, được huấn
luyện trên tập dữ liệu từ các nguồn và lĩnh vực đa dạng để phục vụ như các kho lưu trữ kiến thức
mô-đun (§2.1). So với các phương pháp hiện tại, knowledge cards cho phép truy cập thông tin linh
hoạt và có mục tiêu, tìm kiếm qua các lĩnh vực và sử dụng các nguồn kiến thức riêng tư và cá nhân
hóa. Những LM chuyên biệt này sau đó được gợi ý để tạo ra thông tin nền để hỗ trợ các LLM tổng
quát. Sau đó, chúng tôi đề xuất ba cấp độ bộ chọn kiến thức để động chọn lọc và tinh chỉnh các tài
liệu được tạo và kiểm soát tính liên quan chủ đề, tính ngắn gọn của tài liệu và tính chính xác của
kiến thức (§2.2). Cuối cùng, chúng tôi đề xuất bottom-up và top-down—hai phương pháp để trao
quyền cho các LLM tổng quát bằng cách tích hợp đầu ra từ các LM chuyên biệt (tức là cắm các
knowledge cards vào LLM) (§2.3). Cụ thể, phương pháp bottom-up bắt đầu bằng việc gợi ý tất cả
knowledge cards để tạo ra nhiều tài liệu, sau đó thực hiện lựa chọn với ba bộ chọn kiến thức, trong
khi nối đoạn kiến thức cuối cùng với truy vấn cho việc tạo LLM. Mặc dù phương pháp bottom-up
đặc biệt cho phép tổng hợp kiến thức đa lĩnh vực, nó cũng đưa ra rủi ro trình bày thông tin không
liên quan cho LLM trong các bối cảnh không cần thông tin bên ngoài. Điều này thúc đẩy chúng tôi
đề xuất phương pháp top-down, trong đó chính LLM tổng quát quyết định liệu có cần kiến thức bên
ngoài cho truy vấn đã cho hay không, sau đó các knowledge cards liên quan được kích hoạt có chọn
lọc để tích hợp kiến thức; quá trình này được lặp lại cho đến khi LLM tổng quát có đủ tin tưởng để
tạo ra phản hồi.

Các thí nghiệm rộng rãi chứng minh rằng KNOWLEDGE CARD vượt trội so với các LLM thuần túy,
LM tăng cường truy xuất và các phương pháp gợi ý được tạo trên ba tác vụ qua sáu bộ dữ liệu. Đối
với QA kiến thức tổng quát, KNOWLEDGE CARD cải thiện hiệu suất Codex lên 6.6% trên MMLU và
thậm chí vượt trội so với Flan-PaLM lớn gấp 3 lần. Đối với phân tích thông tin sai lệch kiểm tra
tích hợp kiến thức đa lĩnh vực, KNOWLEDGE CARD vượt trội so với tất cả phương pháp cơ sở ít
nhất 15.8% và 10.0% điểm độ chính xác cân bằng trong cài đặt phân loại hai và bốn chiều. Trong
tác vụ thứ ba, để đánh giá khả năng cập nhật kiến thức của các LLM tổng quát, chúng tôi tuyển
chọn MIDTERM QA, một bộ dữ liệu QA tập trung vào cuộc bầu cử giữa nhiệm kỳ Mỹ 2022 trong
khi điểm cắt kiến thức của LLM thường là 2021 hoặc sớm hơn. Các thí nghiệm chứng minh rằng
KNOWLEDGE CARD vượt trội so với tất cả cơ sở ít nhất 55.6% về điểm khớp chính xác, thể hiện
khả năng cập nhật kiến thức thời gian trong khi chỉ thêm một knowledge card được huấn luyện trên
tin tức bầu cử giữa nhiệm kỳ với ít hơn 100 lần tham số so với LLM tổng quát. Những phát hiện
của chúng tôi chứng minh tiềm năng lấp đầy khoảng trống kiến thức của các LLM tổng quát bằng
cách tích hợp kiến thức mô-đun và cộng tác từ các LM nhỏ, được huấn luyện độc lập và chuyên
biệt. Chúng tôi hình dung KNOWLEDGE CARD như một sáng kiến để khuyến khích các nhà phát
triển LM cộng tác trong việc mở rộng kiến thức của các mô hình ngôn ngữ lớn đồng thời giảm lượng
khí thải carbon từ việc huấn luyện lại các LM khổng lồ từ đầu.

2 PHƯƠNG PHÁP LUẬN
Chúng tôi giới thiệu KNOWLEDGE CARD, một khung mới để trao quyền cho các LLM tổng quát
với kiến thức mô-đun và cộng tác (Hình 1). Chúng tôi huấn luyện các knowledge cards khác nhau,
các LM được huấn luyện trên tập dữ liệu kiến thức chuyên biệt từ các lĩnh vực và nguồn đa dạng
(§2.1). Sau đó, chúng tôi sử dụng chúng để tạo ra kiến thức nền cho các LLM tổng quát, đồng thời
sử dụng ba bộ chọn kiến thức để đảm bảo chất lượng trong tổng hợp kiến thức (§2.2). Cuối cùng,
chúng tôi đề xuất bottom-up và top-down, hai phương pháp để điều kiện hóa LLM trên nội dung
được cung cấp từ knowledge cards và được hậu xử lý bằng các bộ chọn kiến thức (§2.3).

2.1 KNOWLEDGE CARDS
Trong khi các phương pháp hiện tại dựa vào một nguồn kiến thức cố định để cải thiện LLM (một
tập dữ liệu truy xuất (Guu et al., 2020; Borgeaud et al., 2022; Shi et al., 2023), một đồ thị kiến
thức (Wang et al., 2021; Zhang et al., 2021; Feng et al., 2023c), hoặc một LLM đã được huấn
luyện trước (Shin et al., 2020; Liu et al., 2022a; Sun et al., 2022)), chúng tôi giả định rằng vì
kiến thức là mô-đun, các LLM tổng quát nên được tăng cường với các kho lưu trữ kiến thức mô-đun
plug-and-play cho phép người dùng cộng tác thêm, xóa, chỉnh sửa hoặc cập nhật thông tin. Ngoài
ra, các cộng đồng khác nhau có thể
2

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Bộ chọn Liên quan Bộ chọn Cắt tỉa Bộ chọn Tính chính xác Câu trả lời:
Bộ chọn Liên quan Bạn có cần thêm thông tin? 
Có hoặc Không: Q: Ai là thượng nghị sĩ cấp cao của 
nơi sinh Tom Brady?
thể thao
Bộ chọn Tính chính xác
Kiến thức: Tom Brady trở về quê hương San Mateo, CA . . . Có Không
tự động chọn lựa rõ ràng
LLM tổng quát
Bottom-Up Bottom-Up Top-Down Top-Down Chọn một nguồn thông tin 
từ danh sách sau:               ,   
                                       ,
                       ,
                         .         thể thao
văn học y sinh
bài báo NLP
tập sách Chọn một nguồn thông tin 
từ danh sách sau:               ,   
                                       ,
                       ,
                         .         thể thao
văn học y sinh
bài báo NLP
tập sách
thể thao Bạn cần loại thông tin gì?
Vui lòng cung cấp bang 
Tom Brady đến từ đâu. Bạn cần loại thông tin gì?
Vui lòng cung cấp bang 
Tom Brady đến từ đâu. Bạn cần loại thông tin gì?
Vui lòng cung cấp bang 
Tom Brady đến từ đâu.
Câu trả lời: Câu trả lời: Kiến thức: Tom 
Brady trở về 
quê hương 
San Mateo, CA . . .
Câu hỏi: Ai là 
thượng nghị sĩ cấp cao của 
nơi sinh Tom Brady? N
B
GA
P
CH
S
...N
B
GA
P
CH
S
...
Dianne Feinstein
Dianne Feinstein
knowledge cards
San Mateo nằm ở 
phía tây bắc của 
California ... Dianne Feinstein, 
thượng nghị sĩ cấp cao 
từ California, được đồn 
là sẽ nghỉ hưu ... Tom Brady trở về 
quê hương San Mateo ...LLM tổng quát
Q: Ai là thượng nghị sĩ cấp cao của nơi sinh Tom Brady? San Mateo nằm ở phía tây bắc của California ...
Dianne Feinstein, thượng nghị sĩ cấp cao từ California ... Tom Brady Kiến thức:
trở về quê hương San Mateo ...
Câu hỏi: Ai là thượng nghị sĩ cấp cao của nơi sinh Tom Brady? 
Câu trả lời: San Mateo nằm ở phía tây bắc của California ...
Dianne Feinstein, thượng nghị sĩ cấp cao từ California ... Tom Brady Kiến thức:
trở về quê hương San Mateo ...
Câu hỏi: Ai là thượng nghị sĩ cấp cao của nơi sinh Tom Brady? 
Câu trả lời: Dianne Feinstein
Dianne Feinstein
tài liệu kiến thức
tin tức y sinh địa lý
bài báo NLP chính trị ConceptNet lịch sử 
nghệ thuật thể thao ... tin tức y sinh địa lý
bài báo NLP chính trị ConceptNet lịch sử 
nghệ thuật thể thao ... knowledge cards bắt đầu
tài liệu kiến thức tài liệu kiến thức

Hình 1: Tổng quan về KNOWLEDGE CARD. Chúng tôi huấn luyện knowledge cards trên các lĩnh vực
kiến thức khác nhau và sử dụng ba bộ chọn kiến thức để kiểm soát chất lượng. Chúng tôi đề xuất
bottom-up và top-down để tích hợp các LLM tổng quát với các LM mô-đun và chuyên biệt để tổng
hợp kiến thức đa lĩnh vực (bottom-up) và chủ động tìm kiếm kiến thức bên ngoài (top-down).

có các định nghĩa và yêu cầu khác nhau về kiến thức. Các sự kiện Wikipedia, văn học y sinh, công
thức toán học và đồ thị kiến thức thường thức đều là các thành phần kiến thức có giá trị trong các
bối cảnh khác nhau, do đó LLM nên có khả năng đại diện và kết hợp kiến thức được đóng góp bởi
các bên liên quan qua các lĩnh vực và ngành công nghiệp đa diện.

Vì vậy, chúng tôi đề xuất tuyển chọn knowledge cards, các LM chuyên biệt nhỏ hơn nhiều so với
các LLM hộp đen, được huấn luyện trên tập dữ liệu kiến thức đa dạng từ một loạt các lĩnh vực và
nguồn. Cụ thể, chúng tôi có n knowledge cards C={c1,c2,···,cn}, mỗi cái bắt đầu từ một điểm
kiểm tra LM hiện có và được huấn luyện thêm trên một tập dữ liệu kiến thức cụ thể Di với mục tiêu
mô hình hóa ngôn ngữ nhân quả. Cho một truy vấn đến LLM, những knowledge cards này được
kích hoạt có chọn lọc và được sử dụng với việc tạo có gợi ý. Chính thức, cho truy vấn q, LM chuyên
biệt c định nghĩa một ánh xạ c(q): q→dq trong đó q được sử dụng như gợi ý để tạo ra một phần
tiếp theo như tài liệu kiến thức dq, sau đó được đặt trước vào ngữ cảnh của các LLM tổng quát
thông qua các cơ chế khác nhau (§2.3).

Theo cách này, tính mô-đun của kiến thức được thể hiện thông qua việc thêm, xóa hoặc kích hoạt
có chọn lọc dễ dàng các knowledge cards khác nhau trong quá trình tạo LLM. Tương tự, bản chất
cộng tác của kiến thức được phản ánh bằng cách cho phép các cá nhân đóng góp các knowledge
cards đã được huấn luyện trên nguồn kiến thức mong muốn của họ vào KNOWLEDGE CARD, mở
rộng kiến thức của các LLM tổng quát thông qua nỗ lực do cộng đồng thúc đẩy.

2.2 BỘ CHỌN KIẾN THỨC
Mặc dù có thể trực tiếp áp dụng dq như kiến thức liên quan, chúng tôi xác định ba thách thức chính
trong việc tích hợp thành công knowledge cards và các LLM tổng quát: tính liên quan, ngắn gọn và
tính chính xác. Chúng tôi thiết kế ba bộ chọn tương ứng để kiểm soát các yếu tố như vậy.

Bộ chọn Liên quan Mặc dù chúng tôi mong đợi knowledge cards tạo ra thông tin nền liên quan và
hữu ích cho truy vấn q, đôi khi LM lệch khỏi truy vấn (Holtzman et al., 2019). Hơn nữa, chỉ một
số knowledge cards sẽ liên quan cho một truy vấn nhất định. Vì vậy, chúng tôi đề xuất chọn lọc và
giữ lại các tài liệu kiến thức dựa trên tính liên quan. Cụ thể, cho một tập m tài liệu được tạo
{d1,···,dm} và truy vấn q, chúng tôi nhằm giữ lại k tài liệu liên quan nhất và loại bỏ thông tin
không liên quan. Chúng tôi áp dụng một LM dựa trên bộ mã hóa riêng biệt enc(·) ánh xạ một chuỗi
token thành một vector đặc trưng và độ tương tự cosine sim(·,·) để đo lường tính liên quan. Chính
thức, chúng tôi giữ lại di nếu i∈top-kj(sim(enc(dj),enc(q))) trong đó top-k là thao tác top-k
argmax.

Bộ chọn Cắt tỉa Các nghiên cứu hiện tại chủ yếu tích hợp một phần kiến thức bên ngoài vào LLM
(Sun et al., 2022; Shi et al., 2023), trong khi các tác vụ yêu cầu tích hợp thông tin từ nhiều lĩnh
vực,
3

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
như phát hiện thông tin sai lệch (Karimi et al., 2018) và QA đa bước (Nishida et al., 2019), không
được hỗ trợ tốt bởi các mô hình hiện tại. Để tích hợp hiệu quả các tài liệu được tạo từ nhiều LM
trong khi vừa với giới hạn độ dài ngữ cảnh LLM, chúng tôi đề xuất cắt tỉa các tài liệu kiến thức.
Chính thức, cho m tài liệu {d1,···,dm}, chúng tôi áp dụng một mô hình cắt tỉa prune(·), được vận
hành đơn giản nhất như một hệ thống tóm tắt (Zhang et al., 2020; Liu et al., 2022b), để có được
các phiên bản được nén riêng biệt {˜d1,···,˜dm}. Phương pháp cắt tỉa này cho phép tích hợp vào
LLM chính thông tin từ nhiều lĩnh vực trong khi bảo toàn không gian cho học trong ngữ cảnh.

Bộ chọn Tính chính xác Các mô hình ngôn ngữ dễ bị ảo giác (Ji et al., 2023) và knowledge cards
cũng không ngoại lệ. Cho một tập m tài liệu kiến thức đã được cắt tỉa {˜d1,···,˜dm}, các phiên
bản gốc của chúng {d1,···,dm} và truy vấn q, chúng tôi lọc bỏ kiến thức không chính xác và giữ
lại ℓ tài liệu. Cụ thể, chúng tôi đánh giá tính chính xác của các tài liệu kiến thức với hai biện pháp.

Trước tiên, chúng tôi đánh giá tính chính xác tóm tắt, đảm bảo rằng phiên bản đã cắt tỉa ˜di nắm
bắt chính xác các điểm quan trọng trong di gốc. Cụ thể, chúng tôi áp dụng các mô hình đánh giá
tính chính xác (Kryściński et al., 2020; Feng et al., 2023a) như một hàm chấm điểm sum-fact(·,·),
trong đó mỗi tài liệu kiến thức d được gán một điểm tính chính xác tóm tắt ssum_d = sum-fact(˜d|d)
∈ [0,1].

Sau đó chúng tôi đề xuất đánh giá liệu tài liệu kiến thức được tạo có được hỗ trợ tốt bởi kiến thức
thế giới thực thông qua kiểm tra sự thật tăng cường truy xuất hay không. Cụ thể, cho một tài liệu
kiến thức d, chúng tôi truy xuất k tài liệu từ một tập dữ liệu truy xuất t1, . . . , tk, sau đó sử dụng
một mô hình kiểm tra sự thật (Schuster et al., 2021) như một hàm chấm điểm fact-check(·,·).
Sau đó chúng tôi gán một điểm tính chính xác đã được kiểm tra sự thật cho mỗi d dựa trên tài liệu
được truy xuất hỗ trợ d nhất, chính thức sfact_d = max 1≤i≤k fact-check(d|ti) ∈ [0,1]. Sau đó
chúng tôi tính trung bình điểm tính chính xác tóm tắt và điểm kiểm tra sự thật cho mỗi tài liệu để
có được sd.

Mặc dù thật đơn giản khi chọn tham lam ℓ tài liệu kiến thức với điểm sd cao nhất, kiến thức mới
và gần đây hơn có thể không được hỗ trợ tốt bởi các công cụ kiểm tra sự thật hiện có. Do đó, chúng
tôi đề xuất lấy mẫu tính chính xác top-k để cho phép linh hoạt trong khi vẫn nghiêm ngặt đối với
các tài liệu kiến thức rõ ràng sai. Chính thức, trước tiên chúng tôi có được Dk như tập hợp các tài
liệu kiến thức với điểm tính chính xác top-k trong đó k > ℓ là một siêu tham số. Sau đó chúng tôi
định nghĩa một phân phối xác suất lấy mẫu trên tất cả m tài liệu kiến thức:

p(˜di|q) = (
exp(sdi)/∑dj∈Dk exp(sdj), nếu ˜di ∈ Dk.
0, nếu ˜di ∉ Dk.

Chúng tôi lấy mẫu ℓ tài liệu kiến thức từ {˜d1,···,˜dm} với xác suất {p(˜d1|q),···, p(˜dm|q)}.
Theo cách này, các tài liệu kiến thức với điểm tính chính xác rất thấp bị loại bỏ nghiêm ngặt trong
khi linh hoạt được xây dựng thông qua lấy mẫu từ kiến thức với điểm tính chính xác gần đỉnh.

2.3 TÍCH HỢP KIẾN THỨC
Sau khi định nghĩa các thành phần mô-đun trong KNOWLEDGE CARD (một LLM tổng quát,
knowledge cards và bộ chọn kiến thức), chúng tôi đề xuất hai phương pháp, bottom-up và top-down,
để tích hợp LLM tổng quát với các nguồn kiến thức bên ngoài, là đầu ra đã chọn của knowledge
cards. Cụ thể, bottom-up kích hoạt tất cả knowledge cards có sẵn cùng một lúc và sử dụng ba bộ
chọn kiến thức để kiểm soát chất lượng kiến thức. Bottom-up cho phép tổng hợp kiến thức đa lĩnh
vực qua tất cả các nguồn có sẵn, nhưng đôi khi có thể giới thiệu thông tin không liên quan có thể
ảnh hưởng tiêu cực đến suy luận LLM. Chúng tôi cũng đề xuất một phương pháp top-down, trong
đó chính LLM tổng quát chủ động tìm kiếm thông tin bên ngoài từ các knowledge cards đã chọn.
Top-down có lợi thế trong các tác vụ và lĩnh vực mà kiến thức bên ngoài không phải lúc nào cũng
cần thiết.

Phương pháp Bottom-Up Bottom-up bắt đầu bằng việc gợi ý các knowledge cards có sẵn, sau đó
từng bước đi qua ba bộ chọn kiến thức, và những đầu ra này được kết hợp vào LLM thông qua ngữ
cảnh gợi ý. Chính thức, cho n knowledge cards C={c1,···,cn} và truy vấn q, chúng tôi tạo ra n1
tài liệu với mỗi knowledge card thông qua lấy mẫu nhiệt độ (Holtzman et al., 2019) để có được
{d1,···,dn×n1}. Trước tiên, chúng tôi áp dụng bộ chọn liên quan để giữ lại n2 tài liệu liên quan
nhất {d1,···,dn2}, sau đó tiến hành cắt tỉa kiến thức thông qua bộ chọn cắt tỉa {˜d1,···,˜dn2},
và cuối cùng tận dụng bộ chọn tính chính xác để có được n3 tài liệu kiến thức chất lượng cao
{˜d1,···,˜dn3}.
4

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Gợi ý cuối cùng cho LLM là một sự nối của các tài liệu kiến thức và truy vấn, chính thức ["Kiến
thức: "∥˜d1∥˜d2∥ ··· ∥ ˜dn3∥q] trong đó ∥ biểu thị nối. Chúng tôi mong đợi phương pháp
bottom-up mạnh trong tổng hợp kiến thức đa lĩnh vực vì nhiều knowledge cards có thể được kích
hoạt cùng lúc để cung cấp kiến thức nền từ các quan điểm đa dạng. Ngoài ra, các siêu tham số
n1, n2 và n3 cho phép kiểm soát tinh tế quá trình tổng hợp kiến thức.

Phương pháp Top-Down Trong bottom-up, chúng tôi giả định rằng mọi truy vấn sẽ được hưởng
lợi từ kiến thức bên ngoài được tạo bởi knowledge cards. Tuy nhiên, điều này có thể giới thiệu
thông tin không cần thiết trong ngữ cảnh gợi ý của LLM (Zhao et al., 2023). Theo Kadavath et
al. (2022), những người đã chỉ ra rằng LLM có khả năng sơ bộ xác định những hạn chế kiến thức
vốn có của chúng, chúng tôi đề xuất phương pháp top-down, giao cho LLM nhiệm vụ lặp đi lặp lại
xác định liệu có cần kiến thức bên ngoài hay không và kích hoạt có chọn lọc các knowledge cards
liên quan thông qua các chiến lược khác nhau.

Cụ thể, đối với n knowledge cards C={c1,···,cn}, chúng tôi cũng yêu cầu những người đóng góp
knowledge card gửi một mô tả văn bản về LM S={s1,···,sn} như "văn học y sinh", "giải tích đại
học" hoặc "đồ thị kiến thức thường thức". Trước tiên, chúng tôi hỏi LLM một câu hỏi có/không để
xác định liệu có cần kiến thức bên ngoài cho truy vấn q đã cho hay không, cụ thể "Bạn có cần thêm
thông tin? (Có hoặc Không)". Chúng tôi khuyến khích câu trả lời được hiệu chỉnh tốt hơn cho câu
hỏi có/không thông qua học trong ngữ cảnh (Wei et al.; Press et al., 2022): cụ thể, chúng tôi giới
thiệu một tập hợp các ví dụ học trong ngữ cảnh bao gồm hai loại câu hỏi khác biệt được đặt ra cho
LLM. Loại đầu tiên bao gồm các câu hỏi mà LLM có khả năng trả lời chính xác mà không cần bất
kỳ thông tin bổ sung nào. Đối với những câu hỏi này, phản hồi cho truy vấn "Bạn có cần thêm thông
tin (Có hoặc Không)?" là "Không". Loại thứ hai bao gồm các câu hỏi mà LLM không thể trả lời
chính xác mà không có việc cung cấp thông tin bổ sung. Trong trường hợp này, nhãn đầu ra tương
ứng cho truy vấn là "Có". Theo cách này, chúng tôi gợi ý cho LLM học yêu cầu kiến thức bên ngoài
thông qua học trong ngữ cảnh; chúng tôi phân tích hiệu quả của phương pháp này trong Phần 5.
Nếu LLM trả lời "Không", chúng tôi trực tiếp gợi ý cho LLM tạo dựa trên truy vấn, mà không cần
dùng đến knowledge cards. Nếu LLM yêu cầu kiến thức bên ngoài bằng cách trả lời "Có", chúng
tôi sử dụng hai chiến lược (Thuật toán 2) để chọn một knowledge card liên quan và tạo kiến thức
nền.

•Lựa chọn Tự động (AUTO) Chúng tôi gợi ý thêm cho LLM với "Bạn cần loại thông tin gì?" và
chọn một knowledge card dựa trên phản hồi rq của nó. Cụ thể, chúng tôi xác định mô tả LM nào
{s1,···,sn} liên quan nhất với rq bằng bộ chọn liên quan (§2.2) và kích hoạt LM tương ứng để
tạo ra nhiều tài liệu kiến thức, sau đó chọn một với điểm tính chính xác cao nhất dựa trên bộ chọn
tính chính xác (§2.2) để có được d.

•Lựa chọn Rõ ràng (EXP) Thay vào đó, chúng tôi yêu cầu LLM trực tiếp chọn một knowledge card
bằng cách gợi ý với "Chọn một nguồn thông tin từ danh sách sau: s1, . . . , sn". Nếu LLM phản hồi
với si, chúng tôi kích hoạt knowledge card ci tương ứng để tạo ra nhiều tài liệu kiến thức và chọn
một với bộ chọn tính chính xác (§2.2) để có được d.

Khi có được tài liệu, chúng tôi nối "Kiến thức: d" vào ngữ cảnh LLM. Sau đó chúng tôi hỏi lặp
đi lặp lại "Bạn có cần thêm thông tin? (Có hoặc Không)" một lần nữa, lặp lại quá trình trên, cho
đến khi LLM trả lời "Không" và tạo ra một phản hồi có thông tin kiến thức. Chúng tôi mong đợi
top-down hoạt động tốt hơn khi kiến thức bên ngoài không phải lúc nào cũng cần thiết. Theo cách
này, phương pháp top-down cho phép LLM chịu trách nhiệm xác định những hạn chế kiến thức vốn
có của chúng và chủ động tìm kiếm sự giúp đỡ từ các knowledge cards bên ngoài. Chúng tôi cung
cấp các ví dụ gợi ý trong Bảng 10 và 11 trong Phụ lục.

3 CÀI ĐẶT THÍ NGHIỆM
Triển khai Đối với knowledge cards, chúng tôi sử dụng OPT-1.3B (Zhang et al., 2022) làm điểm
khởi đầu và riêng biệt huấn luyện 25 LM chuyên biệt trên một loạt các nguồn và lĩnh vực kiến thức,
bao gồm tập dữ liệu trong Pile (Gao et al., 2020), branch-train-merge (Li et al., 2022), đồ thị
kiến thức (Speer et al., 2017; West et al., 2022; Vrandečić & Krötzsch, 2014; Pellissier Tanon et
al., 2020; Feng et al., 2021; Zhang et al., 2021), tin tức và mạng xã hội (Liu et al., 2022c; Feng
et al., 2023b), và nhiều hơn nữa. (Phụ lục E) Chúng tôi sử dụng MPNet (Song et al., 2020) làm
bộ mã hóa trong bộ chọn liên quan, Pegasus (Zhang et al., 2020) làm mô hình tóm tắt trong bộ chọn
cắt tỉa, WikiSearch API làm hệ thống truy xuất trong bộ chọn tính chính xác, và FactKB (Feng et
al., 2023a) và VitaminC (Schuster et al., 2021) làm các hàm chấm điểm tính chính xác tóm tắt và
kiểm tra sự thật. Chúng tôi sử dụng Codex (CODE-DAVINCI-002) (Chen et al., 2021) làm LLM hộp
đen tổng quát mặc định.
5

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Loại Mô hình Nhân văn Xã hội STEM Khác Tất cả
LM Thuần CODEX 74.2 76.9 57.8 70.1 68.3
PALM 77.0 81.0 55.6 69.6 69.3
FLAN-PALM - - - - 72.2
Truy xuất ATLAS 46.1 54.6 38.8 52.8 47.9
REPLUG 76.0 79.7 58.8 72.1 71.4
REPLUG LSR 76.5 79.9 58.9 73.2 71.8
Tạo GKP 73.3 74.5 59.5 71.4 70.0
RECITATION 76.9 78.1 59.0 74.0 71.9
KNOWLEDGE CARD BOTTOM-UP 77.2 76.7 57.9 72.2 70.7
TOP-DOWN AUTO 77.7 78.9 59.2 73.0 72.0
TOP-DOWN EXP 78.6 80.9 59.6 74.3 72.8
Bảng 1: Hiệu suất mô hình trên Chuẩn MMLU.
KNOWLEDGE CARD cải thiện Codex ít nhất 3.5%
trong khi top-down vượt trội tất cả cơ sở.Loại Mô hình Hai chiều Bốn chiều
BAcc MaF BAcc MaF
LM Thuần CODEX 65.6 51.0 52.8 44.0
Truy xuất REPLUG 78.8 67.8 55.8 53.0
REPLUG LSR 78.8 68.5 57.5 54.4
Tạo GKP 73.5 60.3 61.1 46.3
RECITATION 65.0 47.7 64.2 48.6
GRTR 66.1 49.1 51.6 36.9
KNOWLEDGE CARD BOTTOM-UP 89.8 87.3 70.6 67.3
TOP-DOWN AUTO 86.4 78.7 63.0 60.2
TOP-DOWN EXP 91.3 86.0 69.4 65.5
Bảng 2: Hiệu suất trên phát hiện thông tin sai
lệch. BAcc và MaF là độ chính xác cân bằng và
macro F1. bottom-up hoạt động tốt nhất do tích
hợp kiến thức đa lĩnh vực.

Loại Mô hình Sách mở Trắc nghiệm
EM F1 2-chiều 4-chiều
LM Thuần CODEX 55.1 57.9 90.9 60.8
Truy xuất REPLUG 44.8 - 85.7 62.8
REPLUG LSR 37.2 - 86.9 65.3
SI ET AL. 52.1 54.5 84.7 61.4
Tạo GKP 45.0 46.9 89.1 53.5
RECITATION 44.4 46.4 89.3 52.3
GRTR 55.6 58.4 77.4 59.0
KNOWLEDGE CARD BOTTOM-UP 83.6 85.6 81.6 64.5
TOP-DOWN AUTO 87.5 89.3 89.5 63.0
TOP-DOWN EXP 75.3 75.7 91.9 67.6
Bảng 3: Hiệu suất trên MidtermQA. KNOWLEDGE
CARD thành công cập nhật kiến thức của Codex
bằng cách thêm một knowledge card duy nhất.Tác vụ và Bộ dữ liệu 1) Đối với QA tổng quát,
chúng tôi áp dụng MMLU (Hendrycks et al., 2020),
một bộ dữ liệu QA trắc nghiệm bao gồm 57 tác vụ
trong nhân văn, STEM, khoa học xã hội và khác.
Theo các nghiên cứu trước (Si et al., 2022; Shi et
al., 2023), chúng tôi áp dụng cài đặt học trong ngữ
cảnh 5-shot. 2) Để đánh giá tổng hợp kiến thức đa
lĩnh vực, chúng tôi áp dụng phát hiện thông tin sai
lệch, vì các bài báo tin tức thường bao gồm sự kiện
và ý kiến tại giao điểm của các lĩnh vực và quan
điểm khác nhau. Chúng tôi tận dụng bộ dữ liệu phát
hiện thông tin sai lệch LUN được áp dụng rộng rãi
(Rashkin et al., 2017) với cả cài đặt phân loại 2
chiều và 4 chiều. Tất cả mô hình được đánh giá dựa
trên học trong ngữ cảnh 16-shot. 3) Để đánh giá
cập nhật kiến thức thời gian, chúng tôi tuyển chọn
MIDTERM QA, một chuẩn QA tập trung vào cuộc
bầu cử giữa nhiệm kỳ Mỹ 2022 vì điểm cắt kiến
thức của các LLM hộp đen thường là 2021 hoặc sớm
hơn. MIDTERM QA trình bày ba bộ dữ liệu đánh giá
và cài đặt: sách mở, 2 chiều và 4 chiều trắc nghiệm.
Học trong ngữ cảnh 5-shot được áp dụng để đánh
giá KNOWLEDGE CARD và các cơ sở. Chúng tôi
không xem xét các bộ dữ liệu QA thời gian hiện có
(Jang et al., 2021; Dhingra et al., 2022; Kasai et
al., 2022) vì chúng không tập trung vào bất kỳ sự
kiện hoặc lĩnh vực kiến thức cụ thể nào.

Cơ sở Chúng tôi so sánh KNOWLEDGE CARD với một loạt các phương pháp cơ sở trong ba loại.
1) các LLM hộp đen thuần túy: Codex (Chen et al., 2021), PaLM (Chowdhery et al., 2022) và
Flan-PaLM (Chung et al., 2022); 2) các phương pháp gợi ý kiến thức được tạo: GKP (Liu et al.,
2022a), recitation (Sun et al., 2022), GRTR (Yu et al., 2022) (Lưu ý rằng chúng tôi áp dụng
những phương pháp này cho cùng một LLM Codex (Chen et al., 2021) để so sánh công bằng); 3)
các mô hình ngôn ngữ tăng cường truy xuất: Atlas (Izacard et al., 2022), Si et al. (2022), RePlug
và RePlug LSR (Shi et al., 2023).

4 KẾT QUẢ
MMLU Đối với QA kiến thức tổng quát, chúng tôi sử dụng chuẩn MMLU (Hendrycks et al., 2020).
Như thể hiện trong Bảng 1, cả ba cấu hình của KNOWLEDGE CARD đều cải thiện đáng kể Codex
thuần túy. Trong số đó, phương pháp top-down với lựa chọn rõ ràng hoạt động tốt nhất, cải thiện
Codex 6.6% độ chính xác tổng thể. Đồng thời, các phương pháp top-down vượt trội tất cả cơ sở,
bao gồm Flan-PaLM với vài trăm tỷ tham số hơn. Những kết quả này cho thấy rằng chúng tôi trình
bày một phương pháp hiệu quả để làm cho các LLM tổng quát tốt hơn trong các bối cảnh cần nhiều
kiến thức. Ngoài ra, top-down nói chung vượt trội bottom-up có thể vì MMLU chứa các câu hỏi liên
quan đến toán không đòi hỏi kiến thức bên ngoài. Quan sát này cho thấy rằng các phương pháp
top-down tốt hơn trong các tác vụ mà kiến thức bên ngoài không phải lúc nào cũng cần thiết.

Phát hiện Thông tin Sai lệch Để kiểm tra liệu KNOWLEDGE CARD có thành công tích hợp kiến
thức đa diện từ các nguồn đa dạng hay không, chúng tôi áp dụng bộ dữ liệu thông tin sai lệch LUN
(Rashkin et al., 2017) với cài đặt phân loại hai và bốn chiều. Bảng 2 chứng minh rằng KNOWLEDGE
CARD cải thiện đáng kể Codex ít nhất 31.7% và 19.4% điểm độ chính xác cân bằng cho cả hai cài
đặt. Ngoài ra, bottom-up vượt trội cả hai biến thể của top-down, nhờ phương pháp luận của nó để
cùng kích hoạt knowledge cards từ các lĩnh vực khác nhau và cho phép tổng hợp kiến thức đa lĩnh
vực.
6

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
+ BookCorpus + PubMed + IMDB + News + Wikipedia+1.0+2.0+3.0ACC
+ BookCorpus + PubMed + IMDB + News + Wikipedia+1.0+2.0Balanced ACC
Hình 2: Hiệu suất phát hiện thông tin sai lệch khi
mỗi knowledge card được thêm riêng biệt.
KNOWLEDGE CARD cho phép vá mô-đun LLM
trong khi knowledge cards trong lĩnh vực giúp
ích nhất.
ACC Macro F185.087.590.092.595.0
-1.4
-0.6-1.8
-1.0-3.3
-2.5mô hình đầy đủ
w/o cắt tỉaw/o liên quan
w/o tính chính xácHình 3: Nghiên cứu loại bỏ ba bộ chọn kiến
thức trên phát hiện thông tin sai lệch. Mặc dù
cả ba bộ chọn đều đóng góp vào hiệu suất mô
hình, bộ chọn tính chính xác quan trọng nhất.

MidtermQA Để kiểm tra liệu KNOWLEDGE CARD có thể cập nhật kiến thức tham số của LLM hay
không, chúng tôi huấn luyện một knowledge card bổ sung trên các bài báo tin tức về cuộc bầu cử
giữa nhiệm kỳ Mỹ 2022 và cắm nó vào KNOWLEDGE CARD. Chúng tôi trình bày hiệu suất mô hình
trên MidtermQA trong Bảng 3, chứng minh rằng KNOWLEDGE CARD vượt trội đáng kể tất cả cơ sở
trong cài đặt sách mở lên đến 57.3% về điểm khớp chính xác (EM). Điều này cho thấy một
knowledge card với 1.3B tham số đã thành công cập nhật kiến thức tham số của Codex 175B thông
qua KNOWLEDGE CARD. Ngoài ra, top-down vượt trội bottom-up, cho thấy rằng việc kích hoạt có
chọn lọc knowledge cards tốt hơn khi có một knowledge card cụ thể gắn với lĩnh vực tác vụ.
KNOWLEDGE CARD cũng vượt trội SI ET AL.(Codex + Contriever) sử dụng cùng tin tức bầu cử
giữa nhiệm kỳ như tập dữ liệu truy xuất. Ngoài ra, các phương pháp gợi ý kiến thức được tạo (GKP,
recitation, GRTR) kém hiệu quả hơn Codex thuần túy, cho thấy rằng việc thăm dò LLM để có kiến
thức rõ ràng phản tác dụng khi kiến thức LLM nội bộ đã lỗi thời hoặc sai.

5 PHÂN TÍCH
Vá Kiến thức LLM Khi các LLM tổng quát gặp khó khăn trong các tác vụ do hạn chế kiến thức,
KNOWLEDGE CARD có thể đóng vai trò như một phương pháp hiệu quả để vá những điểm yếu của
LLM bằng cách thêm các mô hình ngôn ngữ chuyên biệt. Vì vậy, chúng tôi đánh giá sự thay đổi
hiệu suất khi năm knowledge cards được thêm riêng biệt để tăng cường Codex với phương pháp
top-down. Kết quả trong Hình 2 chứng minh rằng việc vá LLM với tất cả năm LM dẫn đến các mức
độ cải thiện hiệu suất khác nhau trên phát hiện thông tin sai lệch, trong khi các LM trong lĩnh vực
nhất (Wikipedia và tin tức) dẫn đến cải thiện lớn hơn. Điều này cho thấy rằng khi LLM hoạt động
kém trên các tác vụ cần nhiều kiến thức, một knowledge card bổ sung được huấn luyện trên tập dữ
liệu trong lĩnh vực có thể giúp ích với KNOWLEDGE CARD.

Mô hình Hai chiều Bốn chiều
BAcc MaF BAcc MaF
REPLUG 78.8 67.8 55.8 53.0
REPLUG LSR 78.8 68.5 57.5 54.4
BOTTOM-UP 90.0 87.0 65.3 63.3
TOP-DOWN AUTO 80.7 70.9 60.1 56.8
TOP-DOWN EXP 80.6 70.0 59.7 56.5
Bảng 4: KNOWLEDGE CARD vượt trội LM truy
xuất REPLUG trong cài đặt chỉ Wikipedia, cho
thấy rằng các LM mô-đun trình bày một kho lưu
trữ kiến thức tốt hơn so với truy xuất.Nghiên cứu Bộ chọn Kiến thức Trong Phần 2.2,
chúng tôi đề xuất ba cấp độ bộ chọn kiến thức để
kiểm soát các yếu tố khác nhau và đảm bảo chất
lượng kiến thức. Chúng tôi tiến hành nghiên cứu
loại bỏ để xóa mỗi bộ chọn kiến thức trong phương
pháp bottom-up và đánh giá lại trên phát hiện thông
tin sai lệch. Hình 3 chứng minh rằng mặc dù cả ba
bộ chọn kiến thức đều hữu ích, bộ chọn tính chính
xác đóng góp nhiều nhất vào hiệu suất mô hình và
do đó đóng vai trò quan trọng trong việc đảm bảo
chất lượng của các tài liệu kiến thức được tạo.

Truy xuất vs. LM Chuyên biệt Để đánh giá hiệu
quả của các LM chuyên biệt mô-đun so với các
nguồn không tham số như truy xuất, chúng tôi chỉ
sử dụng Wikipedia LM trong KNOWLEDGE CARD
và so sánh với LM truy xuất tiên tiến REPLUG cũng sử dụng Wikipedia làm nguồn kiến thức truy
xuất. Bảng 4 chứng minh rằng KNOWLEDGE CARD vượt trội REPLUG trên cả hai cài đặt phát hiện
thông tin sai lệch, cho thấy rằng knowledge cards trình bày một kho lưu trữ kiến thức tốt hơn. Lưu
ý rằng KNOWLEDGE CARD cũng tương thích với nhiều định dạng kiến thức (ví dụ: truy xuất và
công cụ tìm kiếm) trong khi chúng có thể bổ sung (Phụ lục A).

Phân tích Luồng Kiến thức Trong bottom-up, ba siêu tham số (§2.3) điều chỉnh "luồng kiến thức"
từ knowledge cards đến các LLM tổng quát. Cụ thể, n1 kiểm soát có bao nhiêu
7

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
12345
n1 (n2 = 5, n3 = 3)0.850.90
35 81012
n2 (n1 = 3, n3 = 3)0.850.90
12345
n3 (n1 = 3, n2 = 5)0.850.90
ACC
Macro F1
Hình 4: Điều tra tác động của n1, n2 và n3, điều chỉnh
luồng kiến thức từ knowledge cards mô-đun đến các LLM
tổng quát. Những siêu tham số này cho phép kiểm soát
tinh tế quá trình tổng hợp kiến thức.
davinci w/ bottom-up w/ autocard w/ expcard70758085
+10.0+12.0
+9.6
turbo w/ bottom-up w/ autocard w/ expcard707580
+5.0
+2.2 +2.6Hình 5: KNOWLEDGE CARD
tương thích với các LLM khác,
cụ thể TEXT-DAVINCI-003 và
GPT-3.5-TURBO.

tài liệu mỗi LM tạo ra, n2 kiểm soát có bao nhiêu được giữ lại sau ba bộ chọn kiến thức, và n3
kiểm soát có bao nhiêu được đưa vào ngữ cảnh của LLM. Chúng tôi điều tra những biện pháp kiểm
soát này và báo cáo hiệu suất trong Hình 4. Nó được minh họa rằng: 1) n1 có tác động biên, cho
thấy knowledge cards tạo ra kiến thức phần lớn đồng nhất ngay cả với lấy mẫu nhiệt độ (Caccia et
al., 2018); 2) n2 lớn hơn dẫn đến giảm hiệu suất, cho thấy ba bộ chọn kiến thức đảm bảo chất
lượng kiến thức; 3) n3 = 1, trong đó chỉ một tài liệu kiến thức được áp dụng tại một thời điểm (như
trong các nghiên cứu trước (Sun et al., 2022; Shi et al., 2023)) tệ hơn các giá trị lớn hơn, cho thấy
lợi thế của tổng hợp kiến thức đa lĩnh vực được bật độc đáo bởi KNOWLEDGE CARD.

có không1,290 498
1,140 71auto: 2-chiều
314 171
1,576 938auto: 4-chiều
đúng saiCó không1,004 42
1,642 311exp: 2-chiều
đúng sai364 68
1,718 849exp: 4-chiều
Hình 6: Ma trận nhầm lẫn
của có/không và tính đúng
trong top-down, cho phép
phân tích lỗi tinh tế.Tương thích LLM Mặc dù chúng tôi theo các nghiên cứu trước
(Sun et al., 2022; Shi et al., 2023) và áp dụng Codex làm LLM
hộp đen mặc định, KNOWLEDGE CARD tương thích với các mô
hình khác nhau. Chúng tôi cũng đánh giá KNOWLEDGE CARD với
hai LLM khác, TEXT-DAVINCI-003 và GPT-3.5-TURBO, và trình
bày kết quả trong Hình 5. Cả bottom-up và top-down đều liên tục
cải thiện các LLM khác nhau qua nhiều bộ dữ liệu và thước đo
đánh giá khác nhau.

Có/Không trong Top-Down Trong top-down (§2.3), chúng tôi
bắt đầu bằng cách hỏi LLM liệu họ có thể cần kiến thức bên ngoài
cho truy vấn đã cho hay không và áp dụng các ví dụ trong ngữ
cảnh để khuyến khích câu trả lời được hiệu chỉnh tốt. Chúng tôi
minh họa phản hồi LLM cùng với tính đúng đắn của câu trả lời
trong Hình 6. Phần lớn các truy vấn được ánh xạ tới các loại "có,
đúng" và "không, đúng", cho thấy rằng LLM có khả năng sơ bộ
"biết những gì họ biết" và tìm kiếm thông tin bên ngoài nếu cần
thiết. Tuy nhiên, khả năng này còn xa mới hoàn hảo, rõ ràng trong
loại không thể bỏ qua "không, sai", cho thấy rằng việc gợi ý LLM
để thừa nhận những hạn chế kiến thức đòi hỏi nghiên cứu thêm
(Kadavath et al., 2022; Zhao et al., 2023), trong khi các phương
pháp mới để từ chối có thể dễ dàng được tích hợp vào KNOWLEDGE
CARD. Ngoài ra, các loại "có, sai" cho thấy rằng các LM chuyên
biệt đôi khi không cung cấp đủ thông tin. Những ma trận nhầm
lẫn này cung cấp phân tích lỗi tinh tế và hướng dẫn về việc liệu
LLM tổng quát, câu hỏi có/không hay knowledge cards có cần cải
thiện thêm.

Cuộc đua Codex KNOWLEDGE CARD
AL, thượng nghị sĩ Doug Jones ✗ Katie Britt ✓
PA, thượng nghị sĩ Bob Casey ✗ John Fetterman ✓
CA, thứ 3 Mike Thompson ✗ Kevin Kiley ✓
IN, thứ 2 Jackie Walorski ✗ Jim Banks ✗
NV, thống đốc Steve Sisolak ✗ Joe Lombardo ✓
Bảng 5: Trong khi Codex thuần túy tuyên bố sai
rằng những người đương nhiệm này thắng lại
trong cuộc bầu cử 2022, KNOWLEDGE CARD
thành công cập nhật kiến thức của các LLM hộp
đen.Phân tích Định tính Chúng tôi tuyển chọn MIDTERM QA
để đánh giá liệu KNOWLEDGE CARD có cho phép cập nhật kiến
thức hiệu quả hay không. Chúng tôi kiểm tra 88 cuộc đua mà
người đương nhiệm không được tái cử: Codex trả lời đúng 1
trong 88 câu hỏi, trong khi bottom-up và top-down với lựa chọn
tự động và rõ ràng trả lời đúng 63, 77 và 42. Bảng 5 cho thấy
Codex tuyên bố những người đương nhiệm sẽ thắng lại trong
2022, trong khi KNOWLEDGE CARD thành công cập nhật LLM
với nhiều hơn 100 lần tham số.
8

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
6 NGHIÊN CỨU LIÊN QUAN
Mô hình Ngôn ngữ Tăng cường Truy xuất Việc tăng cường mô hình ngôn ngữ với truy xuất đã
thúc đẩy tiến bộ trong QA mở (Guu et al., 2020; Izacard et al., 2022; Lewis et al., 2020; Hu et
al., 2022), phân loại văn bản (Zhao et al., 2023) và mô hình hóa ngôn ngữ (Hu et al., 2022;
Borgeaud et al., 2022; Min et al., 2023). Hệ thống truy xuất có thể được tích hợp vào các mô hình
encoder-decoder (Izacard et al., 2022) và decoder-only (Borgeaud et al., 2022; Shi et al., 2022;
Rubin et al., 2022), hoặc được tận dụng để nội suy phân phối xác suất token tiếp theo (Khandelwal
et al., 2019; Zhong et al., 2022). Những tiến bộ gần đây đã kết hợp các bộ truy xuất đóng băng
(Mallen et al., 2023; Si et al., 2022; Khattab et al., 2022) và có thể huấn luyện (Shi et al., 2023)
cũng như công cụ tìm kiếm (Press et al., 2022) để tăng cường LLM. So với các mô hình truy xuất
và công cụ tìm kiếm, KNOWLEDGE CARD cho phép tìm kiếm thông tin linh hoạt, tìm kiếm qua các
lĩnh vực kiến thức và sử dụng các nguồn kiến thức riêng tư. Ngoài ra, những nghiên cứu này thường
chỉ tận dụng một tập dữ liệu truy xuất và giả định rằng nó "toàn tri" trong khi gặp phải nhiều vấn
đề khác nhau như phạm vi lĩnh vực và cập nhật kiến thức. Ngược lại, chúng tôi đề xuất phản ánh
tính mô-đun và bản chất do cộng đồng thúc đẩy của kiến thức bằng cách tích hợp các knowledge
cards plug-and-play với các LLM tổng quát.

Gợi ý Kiến thức Được tạo LM có được kiến thức thông qua huấn luyện trên tập dữ liệu văn bản
khổng lồ (Petroni et al., 2019; Dhingra et al., 2022; He et al., 2021). Gợi ý kiến thức được tạo
(Liu et al., 2022a) là một trong những phương pháp đầu tiên để khai thác kiến thức tham số của
LLM bằng cách gợi ý chúng tạo ra thông tin nền và tái sử dụng nó cho QA. Các nghiên cứu liên
quan cũng đề xuất sử dụng kiến thức tham số LM để truy xuất (Tay et al., 2022), trả lời câu hỏi
thường thức với tự nói chuyện (Shwartz et al., 2020), tạo ra truy vấn (Wang et al., 2022; Zhuang
et al., 2022) hoặc chuỗi token (Bevilacqua et al., 2022) để tăng cường tài liệu. Ngoài ra, các mô
hình ngôn ngữ tăng cường đọc thuộc lòng (Sun et al., 2022) đề xuất tăng cường các ví dụ QA với
các bài đọc thuộc lòng kiến thức đa dạng, trong khi (Yu et al., 2022) cho thấy rằng kiến thức được
tạo, trong một số trường hợp nhất định, tốt hơn truy xuất. Tuy nhiên, hướng nghiên cứu này giả
định rằng kiến thức được mã hóa trong các tham số LLM là tất cả những gì chúng ta cần, trong khi
kiến thức LLM gặp phải ảo giác (Ji et al., 2023), khó khăn trong việc mã hóa các sự kiện đuôi dài
(Mallen et al., 2023) và không thể được cập nhật hiệu quả (De Cao et al., 2021). Mặc dù các
nghiên cứu gần đây đề xuất chỉnh sửa kiến thức LLM (Meng et al., 2022; Hernandez et al., 2023),
chúng khó tương thích với các LLM hộp đen. Ngoài ra, kiến thức tham số trong LLM còn xa mới
mô-đun và cộng tác, trong khi LM nên có khả năng kết hợp kiến thức được đóng góp bởi tất cả các
bên liên quan trong nghiên cứu và ứng dụng LLM. Vì vậy, chúng tôi đề xuất KNOWLEDGE CARD
như một sáng kiến do cộng đồng thúc đẩy để trao quyền cho các LLM tổng quát với kiến thức mô-đun
và cộng tác thông qua việc chia sẻ và tái sử dụng knowledge cards.

LM Mô-đun Mixture-of-Experts (MoE) (Masoudnia & Ebrahimpour, 2014) nhằm kích hoạt một
chuyên gia dựa trên thể hiện đầu vào, đã được áp dụng trong nghiên cứu mô hình ngôn ngữ
(Gururangan et al., 2022; Roller et al., 2021; Lewis et al., 2021; Kudugunta et al., 2021; Pfeiffer
et al., 2022). Adapter cũng được đề xuất để chuyển giao tác vụ và tinh chỉnh hiệu quả tham số
(Houlsby et al., 2019; Pfeiffer et al., 2020; Zaken et al., 2022). Ngoài ra, tính trung bình tham số
(Matena & Raffel, 2022; McMahan et al., 2017; Izmailov et al., 2018; Wortsman et al., 2022; Li
et al., 2022; Gururangan et al., 2023), hợp nhất mô hình (Don-Yehiya et al., 2022; Borzunov et
al., 2022), học liên tục (Jang et al., 2021; Qin et al., 2022; Ke et al., 2022; Qin et al., 2023)
và các phương pháp cộng tác khác (Köpf et al., 2023; Sha, 2023; Luo et al., 2023) cũng đã làm
sáng tỏ khả năng huấn luyện LM phân tán. Tuy nhiên, các LM mô-đun hiện tại chủ yếu hoạt động
trong cài đặt hộp trắng, tức là giả định truy cập vào các tham số mô hình, xác suất token và nhiều
hơn nữa. Vì các LLM nổi bật nhất chỉ được phát hành thông qua các cuộc gọi API, chúng tôi đề xuất
KNOWLEDGE CARD với mục đích trao quyền cho các LLM tổng quát hộp đen với kiến thức do cộng
đồng thúc đẩy và cộng tác.

7 KẾT LUẬN
Chúng tôi đề xuất KNOWLEDGE CARD, một khung mới để trao quyền cho các LLM tổng quát với
kiến thức mô-đun và cộng tác. Trước tiên, chúng tôi trình bày knowledge cards, các LM chuyên biệt
được huấn luyện trên các lĩnh vực và nguồn kiến thức khác nhau, và đề xuất ba bộ chọn kiến thức
để đảm bảo chất lượng kiến thức. Sau đó, chúng tôi đề xuất các phương pháp bottom-up và top-down
để tích hợp knowledge cards với các LLM tổng quát để cho phép tổng hợp kiến thức đa lĩnh vực và
căn cứ vào thông tin bên ngoài khi cần thiết. Các thí nghiệm rộng rãi chứng minh rằng KNOWLEDGE
CARD vượt trội so với các LLM thuần túy, LM truy xuất và các phương pháp gợi ý kiến thức được
tạo qua ba tác vụ và sáu bộ dữ liệu, thể hiện khả năng tích hợp nhiều nguồn thông tin, cập nhật
kiến thức của LLM một cách hiệu quả và nhiều hơn nữa. Chúng tôi hình dung KNOWLEDGE CARD
như một sáng kiến do cộng đồng thúc đẩy để trao quyền cho các LLM tổng quát với kiến thức mô-đun
và cộng tác.
9

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
LỜI CẢM ơN
Chúng tôi cảm ơn các phản biện, chủ tịch vùng, thành viên Tsvetshop và Nhóm NLP UW vì phản
hồi của họ. Nghiên cứu này được hỗ trợ một phần bởi Văn phòng Giám đốc Tình báo Quốc gia
(ODNI), Hoạt động Nghiên cứu Tiên tiến Tình báo (IARPA), thông qua hợp đồng Chương trình
HIATUS số 2022-22072200004. Tài liệu này cũng được tài trợ bởi Grant DARPA theo Hợp đồng số
HR001120C0124. Chúng tôi cũng biết ơn sự hỗ trợ từ NSF CAREER Grant số IIS2142739, NSF
Grants số IIS2125201, IIS2203097 và Alfred P. Sloan Foundation Fellowship. Các quan điểm và
kết luận có trong đây là của các tác giả và không nên được hiểu như nhất thiết đại diện cho các
chính sách chính thức, được thể hiện rõ ràng hoặc ngụ ý, của ODNI, IARPA hoặc Chính phủ Hoa
Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối bản in lại cho mục đích chính phủ bất
chấp bất kỳ chú thích bản quyền nào trong đó.

TÀI LIỆU THAM KHẢO
Sharegpt. https://sharegpt.com/, 2023. Truy cập: 2023-09-27.

Oshin Agarwal, Heming Ge, Siamak Shakeri, và Rami Al-Rfou. Tạo tập dữ liệu tổng hợp dựa trên
đồ thị kiến thức để tiền huấn luyện mô hình ngôn ngữ tăng cường kiến thức. Trong Proceedings
of the 2021 Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, trang 3554–3565, 2021.

Eugene Bagdasaryan và Vitaly Shmatikov. Xoay mô hình ngôn ngữ: Rủi ro của tuyên truyền như
dịch vụ và các biện pháp đối phó. Trong 2022 IEEE Symposium on Security and Privacy (SP),
trang 769–786. IEEE, 2022.

Michele Bevilacqua, Giuseppe Ottaviano, Patrick Lewis, Scott Yih, Sebastian Riedel, và Fabio
Petroni. Công cụ tìm kiếm tự hồi quy: Tạo chuỗi con như định danh tài liệu. Advances in Neural
Information Processing Systems, 35:31668–31683, 2022.

Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican,
George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, và cộng sự.
Cải thiện mô hình ngôn ngữ bằng cách truy xuất từ hàng nghìn tỷ token. Trong International
conference on machine learning, trang 2206–2240. PMLR, 2022.

Alexander Borzunov, Dmitry Baranchuk, Tim Dettmers, Max Ryabinin, Younes Belkada, Artem
Chumachenko, Pavel Samygin, và Colin Raffel. Petals: Suy luận cộng tác và tinh chỉnh các mô
hình lớn. Trong Workshop on Broadening Research Collaborations 2022, 2022.

Massimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau, và Laurent Charlin.
Language gans falling short. Trong International Conference on Learning Representations, 2018.

Steve Cayzer. Blog ngữ nghĩa và quản lý kiến thức phi tập trung. Communications of the ACM,
47(12):47–52, 2004.

Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn, và Tony
Robinson. Chuẩn một tỷ từ để đo lường tiến bộ trong mô hình hóa ngôn ngữ thống kê. arXiv
preprint arXiv:1312.3005, 2013.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared
Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, và cộng sự. Đánh giá các
mô hình ngôn ngữ lớn được huấn luyện trên mã. arXiv preprint arXiv:2107.03374, 2021.

Wenhu Chen, Yu Su, Xifeng Yan, và William Yang Wang. Kgpt: Tiền huấn luyện có căn cứ kiến
thức để tạo dữ liệu thành văn bản. Trong Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP), trang 8635–8648, 2020.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam
Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, và cộng sự. Palm:
Mở rộng mô hình hóa ngôn ngữ với pathways. arXiv preprint arXiv:2204.02311, 2022.
10

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, và cộng sự. Mở rộng các mô hình ngôn ngữ được
tinh chỉnh theo hướng dẫn. arXiv preprint arXiv:2210.11416, 2022.

Nicola De Cao, Wilker Aziz, và Ivan Titov. Chỉnh sửa kiến thức thực tế trong các mô hình ngôn
ngữ. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language
Processing, trang 6491–6506, 2021.

Bhuwan Dhingra, Jeremy R Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, và
William W Cohen. Các mô hình ngôn ngữ nhận thức thời gian như cơ sở kiến thức thời gian.
Transactions of the Association for Computational Linguistics, 10:257–273, 2022.

Shachar Don-Yehiya, Elad Venezian, Colin Raffel, Noam Slonim, Yoav Katz, và Leshem Choshen.
Cold fusion: Giảm cộng tác để tinh chỉnh đa tác vụ phân tán. arXiv preprint arXiv:2212.01378,
2022.

Shangbin Feng, Zilong Chen, Wenqian Zhang, Qingyao Li, Qinghua Zheng, Xiaojun Chang, và
Minnan Luo. Kgap: Tăng cường đồ thị kiến thức phát hiện quan điểm chính trị trong phương tiện
truyền thông tin tức. arXiv preprint arXiv:2108.03861, 2021.

Shangbin Feng, Zhaoxuan Tan, Herun Wan, Ningnan Wang, Zilong Chen, Binchi Zhang, Qinghua
Zheng, Wenqian Zhang, Zhenyu Lei, Shujie Yang, và cộng sự. Twibot-22: Hướng tới phát hiện
bot twitter dựa trên đồ thị. Trong Thirty-sixth Conference on Neural Information Processing
Systems Datasets and Benchmarks Track, 2022.

Shangbin Feng, Vidhisha Balachandran, Yuyang Bai, và Yulia Tsvetkov. FactKB: Đánh giá tính
chính xác tổng quát hóa sử dụng các mô hình ngôn ngữ được tăng cường với kiến thức thực tế.
Trong Houda Bouamor, Juan Pino, và Kalika Bali (biên tập), Proceedings of the 2023 Conference
on Empirical Methods in Natural Language Processing, trang 933–952, Singapore, Tháng 12
2023a. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.59. URL
https://aclanthology.org/2023.emnlp-main.59.

Shangbin Feng, Chan Young Park, Yuhan Liu, và Yulia Tsvetkov. Từ dữ liệu tiền huấn luyện đến
mô hình ngôn ngữ đến tác vụ hạ lưu: Theo dõi dấu vết của thiên kiến chính trị dẫn đến các mô
hình NLP không công bằng. Trong Proceedings of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers), trang 11737–11762, Tháng 7 2023b.

Shangbin Feng, Zhaoxuan Tan, Wenqian Zhang, Zhenyu Lei, và Yulia Tsvetkov. KALM: Tích hợp
nhận thức kiến thức của ngữ cảnh địa phương, tài liệu và toàn cầu để hiểu tài liệu dài. Trong
Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), trang 2116–2138, Tháng 7 2023c.

Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang,
Horace He, Anish Thite, Noa Nabeshima, và cộng sự. The pile: Một bộ dữ liệu 800gb văn bản
đa dạng để mô hình hóa ngôn ngữ. arXiv preprint arXiv:2101.00027, 2020.

Suchin Gururangan, Mike Lewis, Ari Holtzman, Noah A Smith, và Luke Zettlemoyer. Demix layers:
Tách biệt lĩnh vực để mô hình hóa ngôn ngữ mô-đun. Trong Proceedings of the 2022 Conference
of the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, trang 5557–5576, 2022.

Suchin Gururangan, Margaret Li, Mike Lewis, Weijia Shi, Tim Althoff, Noah A Smith, và Luke
Zettlemoyer. Mở rộng các mô hình ngôn ngữ chuyên gia với khám phá lĩnh vực không giám sát.
arXiv preprint arXiv:2303.14177, 2023.

Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, và Mingwei Chang. Tiền huấn luyện mô
hình ngôn ngữ tăng cường truy xuất. Trong International conference on machine learning, trang
3929–3938. PMLR, 2020.

Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit
Bansal, và Srinivasan Iyer. Các mô hình ngôn ngữ có niềm tin không? phương pháp phát hiện,
cập nhật và hình dung niềm tin mô hình. arXiv preprint arXiv:2111.13654, 2021.
11

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Tianxing He, Jun Liu, Kyunghyun Cho, Myle Ott, Bing Liu, James Glass, và Fuchun Peng. Phân
tích vấn đề quên trong tiền huấn luyện-tinh chỉnh của các mô hình phản hồi đối thoại miền mở.
Trong Proceedings of the 16th Conference of the European Chapter of the Association for
Computational Linguistics: Main Volume, trang 1121–1133, Tháng 4 2021.

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob
Steinhardt. Đo lường hiểu biết ngôn ngữ đa tác vụ khổng lồ. Trong International Conference on
Learning Representations, 2020.

Dan Hendrycks, Collin Burns, Anya Chen, và Spencer Ball. Cuad: Một bộ dữ liệu nlp được chú
thích bởi chuyên gia để xem xét hợp đồng pháp lý. Trong Thirty-fifth Conference on Neural
Information Processing Systems Datasets and Benchmarks Track (Round 1), 2021.

Evan Hernandez, Belinda Z Li, và Jacob Andreas. Đo lường và thao tác biểu diễn kiến thức trong
các mô hình ngôn ngữ. arXiv preprint arXiv:2304.00740, 2023.

Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. Trường hợp tò mò của suy thoái
văn bản thần kinh. Trong International Conference on Learning Representations, 2019.

Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe,
Andrea Gesmundo, Mona Attariyan, và Sylvain Gelly. Học chuyển giao hiệu quả tham số cho nlp.
Trong International Conference on Machine Learning, trang 2790–2799. PMLR, 2019.

Linmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong, Duyu Tang, Chuan Shi, Nan Duan, và Ming
Zhou. So sánh với kiến thức: Phát hiện tin tức giả mạng thần kinh đồ thị với kiến thức bên ngoài.
Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics
and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long
Papers), trang 754–763, 2021.

Yushi Hu, Hang Hua, Zhengyuan Yang, Weijia Shi, Noah A Smith, và Jiebo Luo. Promptcap: Chú
thích hình ảnh nhận thức tác vụ có hướng dẫn. arXiv preprint arXiv:2211.09699, 2022.

Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane
Dwivedi-Yu, Armand Joulin, Sebastian Riedel, và Edouard Grave. Học vài shot với các mô hình
ngôn ngữ tăng cường truy xuất. arXiv preprint arXiv:2208.03299, 2022.

P Izmailov, AG Wilson, D Podoprikhin, D Vetrov, và T Garipov. Tính trung bình trọng số dẫn đến
tối ưu rộng hơn và tổng quát hóa tốt hơn. Trong 34th Conference on Uncertainty in Artificial
Intelligence 2018, UAI 2018, trang 876–885, 2018.

Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, KIM Gyeonghun, Stanley
Jungkyu Choi, và Minjoon Seo. Hướng tới học kiến thức liên tục của các mô hình ngôn ngữ. Trong
International Conference on Learning Representations, 2021.

Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang,
Andrea Madotto, và Pascale Fung. Khảo sát ảo giác trong tạo ngôn ngữ tự nhiên. ACM Computing
Surveys, 55(12):1–38, 2023.

Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas
Schiefer, Zac Hatfield Dodds, Nova DasSarma, Eli Tran-Johnson, và cộng sự. Các mô hình ngôn
ngữ (chủ yếu) biết những gì họ biết. arXiv preprint arXiv:2207.05221, 2022.

Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, và Colin Raffel. Các mô hình ngôn
ngữ lớn khó khăn trong việc học kiến thức đuôi dài. Trong International Conference on Machine
Learning, trang 15696–15707. PMLR, 2023.

Hamid Karimi, Proteek Roy, Sari Saba-Sadiya, và Jiliang Tang. Phát hiện tin tức giả đa nguồn đa
lớp. Trong Proceedings of the 27th international conference on computational linguistics, trang
1546–1557, 2018.

Jungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi, Ronan Le Bras, Akari Asai, Xinyan Yu, Dragomir
Radev, Noah A Smith, Yejin Choi, và Kentaro Inui. Realtime qa: Câu trả lời là gì ngay bây giờ?
arXiv preprint arXiv:2207.13332, 2022.
12

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Zixuan Ke, Yijia Shao, Haowei Lin, Tatsuya Konishi, Gyuhak Kim, và Bing Liu. Tiền huấn luyện
liên tục của các mô hình ngôn ngữ. Trong The Eleventh International Conference on Learning
Representations, 2022.

Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, và Mike Lewis. Tổng quát hóa
thông qua ghi nhớ: Các mô hình ngôn ngữ láng giềng gần nhất. Trong International Conference
on Learning Representations, 2019.

Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, và
Matei Zaharia. Demonstrate-search-predict: Kết hợp các mô hình truy xuất và ngôn ngữ cho nlp
cần nhiều kiến thức. arXiv preprint arXiv:2212.14024, 2022.

Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,
Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Richárd Nagyfi, và cộng sự. Openassistant
conversations–dân chủ hóa sắp xếp mô hình ngôn ngữ lớn. arXiv preprint arXiv:2304.07327, 2023.

Wojciech Kryściński, Bryan McCann, Caiming Xiong, và Richard Socher. Đánh giá tính nhất quán
thực tế của tóm tắt văn bản trừu tượng. Trong Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP), trang 9332–9346, 2020.

Sneha Kudugunta, Yanping Huang, Ankur Bapna, Maxim Krikun, Dmitry Lepikhin, Minh-Thang
Luong, và Orhan Firat. Vượt qua chưng cất: Mixture-of-experts cấp tác vụ để suy luận hiệu quả.
Trong Findings of the Association for Computational Linguistics: EMNLP 2021, trang 3577–3599,
2021.

Mike Lewis, Shruti Bhosale, Tim Dettmers, Naman Goyal, và Luke Zettlemoyer. Base layers: Đơn
giản hóa huấn luyện các mô hình lớn, thưa thớt. Trong International Conference on Machine
Learning, trang 6265–6274. PMLR, 2021.

Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,
Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, và cộng sự. Tạo tăng cường truy
xuất cho các tác vụ nlp cần nhiều kiến thức. Advances in Neural Information Processing Systems,
33:9459–9474, 2020.

Margaret Li, Suchin Gururangan, Tim Dettmers, Mike Lewis, Tim Althoff, Noah A Smith, và Luke
Zettlemoyer. Branch-train-merge: Huấn luyện các mô hình ngôn ngữ chuyên gia song song đáng
xấu hổ. Trong First Workshop on Interpolation Regularizers and Beyond at NeurIPS 2022, 2022.

Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter West, Ronan Le Bras, Yejin Choi, và
Hannaneh Hajishirzi. Gợi ý kiến thức được tạo cho lý luận thường thức. Trong Proceedings of
the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers), trang 3154–3169, 2022a.

Yixin Liu, Pengfei Liu, Dragomir Radev, và Graham Neubig. Brio: Mang lại trật tự cho tóm tắt
trừu tượng. Trong Proceedings of the 60th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), trang 2890–2903, 2022b.

Yujian Liu, Xinliang Frederick Zhang, David Wegsman, Nicholas Beauchamp, và Lu Wang. Politics:
Tiền huấn luyện với so sánh bài báo cùng câu chuyện để dự đoán ý thức hệ và phát hiện lập
trường. Trong Findings of the Association for Computational Linguistics: NAACL 2022, trang
1354–1374, 2022c.

Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, và Daniel S Weld. S2orc: Tập dữ liệu
nghiên cứu mở semantic scholar. Trong Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics, trang 4969–4983, 2020.

Ziyang Luo, Can Xu, Pu Zhao, Xiubo Geng, Chongyang Tao, Jing Ma, Qingwei Lin, và Daxin Jiang.
Các mô hình ngôn ngữ lớn được tăng cường với hướng dẫn kiến thức tham số. arXiv preprint
arXiv:2305.04757, 2023.

Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, và Hannaneh Hajishirzi.
Khi nào không nên tin tưởng các mô hình ngôn ngữ: Điều tra hiệu quả của ký ức tham số và không
tham số. Trong Proceedings of the 61st Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), trang 9802–9822, 2023.
13

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Saeed Masoudnia và Reza Ebrahimpour. Mixture of experts: một khảo sát văn học. The Artificial
Intelligence Review, 42(2):275, 2014.

Michael S Matena và Colin A Raffel. Hợp nhất các mô hình với tính trung bình có trọng số fisher.
Advances in Neural Information Processing Systems, 35:17703–17716, 2022.

Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, và Blaise Aguera y Arcas. Học
hiệu quả giao tiếp của các mạng sâu từ dữ liệu phi tập trung. Trong Artificial intelligence and
statistics, trang 1273–1282. PMLR, 2017.

Kevin Meng, Arnab Sen Sharma, Alex J Andonian, Yonatan Belinkov, và David Bau. Chỉnh sửa hàng
loạt bộ nhớ trong một transformer. Trong The Eleventh International Conference on Learning
Representations, 2022.

Sewon Min, Weijia Shi, Mike Lewis, Xilun Chen, Wen-tau Yih, Hannaneh Hajishirzi, và Luke
Zettlemoyer. Mô hình hóa ngôn ngữ có mặt nạ không tham số. Trong Findings of the Association
for Computational Linguistics: ACL 2023, trang 2097–2118, Tháng 7 2023.

Kosuke Nishida, Kyosuke Nishida, Masaaki Nagata, Atsushi Otsuka, Itsumi Saito, Hisako Asano,
và Junji Tomita. Trả lời trong khi tóm tắt: Học đa tác vụ cho qa đa bước với trích xuất bằng
chứng. Trong Proceedings of the 57th Annual Meeting of the Association for Computational
Linguistics, trang 2335–2345, 2019.

Artidoro Pagnoni, Vidhisha Balachandran, và Yulia Tsvetkov. Hiểu tính thực tế trong tóm tắt trừu
tượng với frank: Một chuẩn cho các thước đo tính thực tế. Trong Proceedings of the 2021
Conference of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, trang 4812–4829, 2021.

Thomas Pellissier Tanon, Gerhard Weikum, và Fabian Suchanek. Yago 4: Một cơ sở kiến thức hợp
lý. Trong The Semantic Web: 17th International Conference, ESWC 2020, Heraklion, Crete,
Greece, May 31–June 4, 2020, Proceedings 17, trang 583–596. Springer, 2020.

Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese,
Nat McAleese, và Geoffrey Irving. Red teaming các mô hình ngôn ngữ với các mô hình ngôn ngữ.
Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,
trang 3419–3448, 2022.

Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, và
Alexander Miller. Các mô hình ngôn ngữ như cơ sở kiến thức? Trong Proceedings of the 2019
Conference on Empirical Methods in Natural Language Processing and the 9th International
Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 2463–2473, 2019.

Jonas Pfeiffer, Ivan Vulić, Iryna Gurevych, và Sebastian Ruder. Mad-x: Một khung dựa trên adapter
cho việc chuyển giao đa tác vụ đa ngôn ngữ. Trong Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing (EMNLP), trang 7654–7673, 2020.

Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, và Mikel Artetxe.
Nâng lời nguyền đa ngôn ngữ bằng cách tiền huấn luyện các transformer mô-đun. Trong
Proceedings of the 2022 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, trang 3479–3495, 2022.

Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, và Mike Lewis. Đo lường và
thu hẹp khoảng cách thành phần trong các mô hình ngôn ngữ. arXiv preprint arXiv:2210.03350,
2022.

Yujia Qin, Jiajie Zhang, Yankai Lin, Zhiyuan Liu, Peng Li, Maosong Sun, và Jie Zhou. Elle: Tiền
huấn luyện suốt đời hiệu quả cho dữ liệu nổi lên. Trong Findings of the Association for
Computational Linguistics: ACL 2022, trang 2789–2810, 2022.

Yujia Qin, Cheng Qian, Xu Han, Yankai Lin, Huadong Wang, Ruobing Xie, Zhiyuan Liu, Maosong
Sun, và Jie Zhou. Tinh chỉnh có thể tái chế cho tiền huấn luyện liên tục. arXiv preprint
arXiv:2305.08702, 2023.
14

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Jack W Rae, Anna Potapenko, Siddhant M Jayakumar, Chloe Hillier, và Timothy P Lillicrap.
Transformer nén cho mô hình hóa chuỗi tầm xa. Trong International Conference on Learning
Representations, 2019.

Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana Volkova, và Yejin Choi. Sự thật của các sắc
thái khác nhau: Phân tích ngôn ngữ trong tin tức giả và kiểm tra sự thật chính trị. Trong
Proceedings of the 2017 conference on empirical methods in natural language processing, trang
2931–2937, 2017.

Adam Roberts, Colin Raffel, và Noam Shazeer. Bạn có thể đóng gói bao nhiêu kiến thức vào các
tham số của một mô hình ngôn ngữ? Trong Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP), trang 5418–5426, 2020.

Stephen Roller, Sainbayar Sukhbaatar, Jason Weston, và cộng sự. Hash layers cho các mô hình thưa
lớn. Advances in Neural Information Processing Systems, 34:17555–17566, 2021.

Ohad Rubin, Jonathan Herzig, và Jonathan Berant. Học truy xuất gợi ý cho học trong ngữ cảnh.
Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, trang 2655–2671, 2022.

Alireza Salemi, Sheshera Mysore, Michael Bendersky, và Hamed Zamani. Lamp: Khi các mô hình
ngôn ngữ lớn gặp cá nhân hóa. arXiv preprint arXiv:2304.11406, 2023.

David Saxton, Edward Grefenstette, Felix Hill, và Pushmeet Kohli. Phân tích khả năng lý luận toán
học của các mô hình thần kinh. Trong International Conference on Learning Representations,
2019.

Tal Schuster, Adam Fisch, và Regina Barzilay. Lấy vitamin c của bạn! xác minh sự thật mạnh mẽ
với bằng chứng tương phản. Trong Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language Technologies, trang
624–643, 2021.

Weijia Shi, Julian Michael, Suchin Gururangan, và Luke Zettlemoyer. Suy luận zero-shot láng giềng
gần nhất. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language
Processing, trang 3254–3265, 2022.

Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke
Zettlemoyer, và Wen-tau Yih. Replug: Các mô hình ngôn ngữ hộp đen tăng cường truy xuất. arXiv
preprint arXiv:2301.12652, 2023.

Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, và Sameer Singh. Autoprompt:
Gợi ra kiến thức từ các mô hình ngôn ngữ với các gợi ý được tạo tự động. Trong Proceedings of
the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang
4222–4235, 2020.

Vered Shwartz, Peter West, Ronan Le Bras, Chandra Bhagavatula, và Yejin Choi. Trả lời câu hỏi
thường thức không giám sát với tự nói chuyện. Trong Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing (EMNLP), trang 4615–4629, 2020.

Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan Lee Boyd-Graber,
và Lijuan Wang. Gợi ý gpt-3 để đáng tin cậy. Trong The Eleventh International Conference on
Learning Representations, 2022.

Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, và Tie-Yan Liu. Mpnet: Tiền huấn luyện có mặt nạ
và hoán vị cho hiểu biết ngôn ngữ. Advances in Neural Information Processing Systems,
33:16857–16867, 2020.

Robyn Speer, Joshua Chin, và Catherine Havasi. Conceptnet 5.5: Một đồ thị đa ngôn ngữ mở của
kiến thức tổng quát. Trong Proceedings of the AAAI conference on artificial intelligence, volume
31, 2017.

Heiner Stuckenschmidt, Christine Parent, và Stefano Spaccapietra. Các ontology mô-đun: khái niệm,
lý thuyết và kỹ thuật cho mô-đun hóa kiến thức, volume 5445. Springer, 2009.

Zhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, và Denny Zhou. Các mô hình ngôn ngữ tăng cường
đọc thuộc lòng. Trong The Eleventh International Conference on Learning Representations, 2022.
15

--- TRANG 16 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Yi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui,
Zhe Zhao, Jai Gupta, và cộng sự. Bộ nhớ transformer như một chỉ mục tìm kiếm có thể vi phân.
Advances in Neural Information Processing Systems, 35:21831–21843, 2022.

Denny Vrandečić và Markus Krötzsch. Wikidata: một cơ sở kiến thức cộng tác miễn phí.
Communications of the ACM, 57(10):78–85, 2014.

Heng Wang, Wenqian Zhang, Yuyang Bai, Zhaoxuan Tan, Shangbin Feng, Qinghua Zheng, và Minnan
Luo. Phát hiện spoiler trong đánh giá phim với kiến thức phim bên ngoài và mạng người dùng.
arXiv preprint arXiv:2304.11411, 2023.

Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu, Juanzi Li, và Jian Tang.
Kepler: Một mô hình thống nhất cho nhúng kiến thức và biểu diễn ngôn ngữ được tiền huấn luyện.
Transactions of the Association for Computational Linguistics, 9:176–194, 2021.

Yujing Wang, Yingyan Hou, Haonan Wang, Ziming Miao, Shibin Wu, Qi Chen, Yuqing Xia,
Chengmin Chi, Guoshuai Zhao, Zheng Liu, và cộng sự. Một bộ chỉ mục tập dữ liệu thần kinh để
truy xuất tài liệu. Advances in Neural Information Processing Systems, 35:25600–25614, 2022.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Quoc V Le, Denny
Zhou, và cộng sự. Gợi ý chuỗi suy nghĩ gợi ra lý luận trong các mô hình ngôn ngữ lớn. Trong
Advances in Neural Information Processing Systems.

Peter West, Chandra Bhagavatula, Jack Hessel, Jena Hwang, Liwei Jiang, Ronan Le Bras, Ximing
Lu, Sean Welleck, và Yejin Choi. Chưng cất kiến thức tượng trưng: từ các mô hình ngôn ngữ tổng
quát đến các mô hình thường thức. Trong Proceedings of the 2022 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language
Technologies, trang 4602–4625, 2022.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi,
Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, và cộng sự. Transformers của
huggingface: Xử lý ngôn ngữ tự nhiên tiên tiến. arXiv preprint arXiv:1910.03771, 2019.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi,
Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, và cộng sự. Transformers: Xử lý ngôn
ngữ tự nhiên tiên tiến. Trong Proceedings of the 2020 conference on empirical methods in natural
language processing: system demonstrations, trang 38–45, 2020.

Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari
S Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, và cộng sự. Model
soups: tính trung bình trọng số của nhiều mô hình được tinh chỉnh cải thiện độ chính xác mà không
tăng thời gian suy luận. Trong International Conference on Machine Learning, trang 23965–23998.
PMLR, 2022.

Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu,
Michael Zeng, và Meng Jiang. Tạo thay vì truy xuất: Các mô hình ngôn ngữ lớn là những người
tạo ngữ cảnh mạnh mẽ. Trong The Eleventh International Conference on Learning Representations,
2022.

Elad Ben Zaken, Yoav Goldberg, và Shauli Ravfogel. Bitfit: Tinh chỉnh hiệu quả tham số đơn giản
cho các mô hình ngôn ngữ có mặt nạ dựa trên transformer. Trong Proceedings of the 60th Annual
Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), trang 1–9,
2022.

Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, và
Yejin Choi. Bảo vệ chống lại tin tức giả thần kinh. Advances in neural information processing
systems, 32, 2019.

Jingqing Zhang, Yao Zhao, Mohammad Saleh, và Peter Liu. Pegasus: Tiền huấn luyện với các câu
khoảng trống được trích xuất cho tóm tắt trừu tượng. Trong International Conference on Machine
Learning, trang 11328–11339. PMLR, 2020.

Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher
Dewan, Mona Diab, Xian Li, Xi Victoria Lin, và cộng sự. Opt: Các mô hình ngôn ngữ transformer
được tiền huấn luyện mở. arXiv preprint arXiv:2205.01068, 2022.
16

--- TRANG 17 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Xikun Zhang, Antoine Bosselut, Michihiro Yasunaga, Hongyu Ren, Percy Liang, Christopher D
Manning, và Jure Leskovec. Greaselm: Các mô hình ngôn ngữ tăng cường lý luận đồ thị. Trong
International conference on learning representations, 2021.

Xinran Zhao, Hongming Zhang, Xiaoman Pan, Wenlin Yao, Dong Yu, và Jianshu Chen. Thrust: Thúc
đẩy thích ứng các mô hình ngôn ngữ lớn với kiến thức bên ngoài. arXiv preprint arXiv:2307.10442,
2023.

Zexuan Zhong, Tao Lei, và Danqi Chen. Huấn luyện các mô hình ngôn ngữ với tăng cường bộ nhớ.
Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,
trang 5657–5673, 2022.

Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, và
Sanja Fidler. Sắp xếp sách và phim: Hướng tới các giải thích hình ảnh giống câu chuyện bằng
cách xem phim và đọc sách. Trong Proceedings of the IEEE international conference on computer
vision, trang 19–27, 2015.

Shengyao Zhuang, Houxing Ren, Linjun Shou, Jian Pei, Ming Gong, Guido Zuccon, và Daxin Jiang.
Bắc cầu khoảng cách giữa chỉ mục và truy xuất cho chỉ mục tìm kiếm có thể vi phân với tạo truy
vấn. arXiv preprint arXiv:2206.10128, 2022.
17

--- TRANG 18 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
A THẢO LUẬN
Tính mô-đun ở mọi khúc cua. Tất cả các thành phần trong KNOWLEDGE CARD đều mô-đun và dễ
dàng thay thế bằng các tiêu chuẩn tiên tiến tương lai. 1) Mặc dù Codex là LLM mặc định trong các
thí nghiệm, KNOWLEDGE CARD cũng hoạt động với TEXT-DAVINCI-003 và GPT-3.5-TURBO (§5)
và có thể dễ dàng thích ứng với các LLM tương lai. 2) Nếu các mô hình tốt hơn cho độ tương tự
không gian nhúng, tóm tắt trừu tượng và kiểm tra sự thật được phát triển, ba bộ chọn kiến thức
(§2.2) có thể được cập nhật một cách liền mạch. 3) Khi kiến thức, thông tin và lĩnh vực mới xuất
hiện, nhiều knowledge cards hơn có thể được huấn luyện và tải lên cơ sở hạ tầng chia sẻ mô hình
(Wolf et al., 2020) bởi bất kỳ thành viên nào của cộng đồng học máy và được áp dụng để cải thiện
các LLM tổng quát.

Thích ứng LLM tập trung vào người dùng. Khi các LLM tổng quát được phát hành, mọi người sử
dụng cùng một LLM với cùng các cuộc gọi API, trong khi người dùng thế giới thực có các trường
hợp sử dụng và kỳ vọng không đồng nhất đòi hỏi cá nhân hóa (Salemi et al., 2023). Ví dụ, học
sinh cấp tiểu học có thể mong đợi LLM hoàn toàn chính xác về kiến thức và thông tin trong sách
giáo khoa phổ thông, các nhà nghiên cứu NLP có thể mong đợi LLM có hiểu biết cơ bản về nghiên
cứu NLP hiện tại, những người nghiệp dư nấu ăn có thể mong đợi LLM hiểu các công thức và món
ăn cơ bản cho các dịp khác nhau, và nhiều hơn nữa. Do đó, KNOWLEDGE CARD trình bày một
phương pháp sơ bộ bằng cách để người dùng chọn và kích hoạt knowledge cards để trao quyền cho
LLM với các bộ kỹ năng và chuyên môn lĩnh vực khác nhau.

Tương thích với các hình thức kiến thức đa dạng. Theo mặc định, KNOWLEDGE CARD sử dụng
các mô hình ngôn ngữ được huấn luyện trên các lĩnh vực và tập dữ liệu khác nhau như các nguồn
kiến thức mô-đun. Ngoài ra, KNOWLEDGE CARD cũng tương thích với 1) hệ thống truy xuất, trong
đó văn bản được truy xuất có thể tương tự đi qua ba bộ chọn kiến thức và làm phong phú ngữ cảnh
LLM, trong khi các tập dữ liệu truy xuất khó chia sẻ và sử dụng hơn so với các mô hình ngôn ngữ
mô-đun; 2) đồ thị kiến thức, khi kết hợp với các đề xuất khác nhau để xây dựng tập dữ liệu ngôn
ngữ tự nhiên từ các cơ sở kiến thức tượng trưng (Agarwal et al., 2021; Chen et al., 2020; Feng et
al., 2023a), đã được bao gồm trong nguyên mẫu của chúng tôi; 3) công cụ tìm kiếm, trong đó nội
dung trên web cũng có thể được tích hợp vào các LLM hộp đen thông qua KNOWLEDGE CARD.
Tính linh hoạt và tương thích như vậy là có thể vì KNOWLEDGE CARD tiến hành tích hợp kiến thức
thông qua ngôn ngữ tự nhiên. So với các mô hình truy xuất, việc sử dụng các mô hình ngôn ngữ
như nguồn kiến thức cho phép tìm kiếm thông tin linh hoạt (thay vì khớp token chính xác cứng
nhắc), tìm kiếm qua các lĩnh vực kiến thức và sử dụng các nguồn kiến thức riêng tư.

Tính không đồng nhất của knowledge cards. Mặc dù các đề xuất LM mô-đun hiện tại thường yêu
cầu các mô hình con mô-đun phải có cùng kích thước và kiến trúc để tính trung bình tham số và hợp
nhất mô hình (Li et al., 2022), knowledge cards trong công việc này có thể hoàn toàn không đồng
nhất. 1) Các knowledge cards khác nhau có thể có kích thước khác nhau. Mặc dù OPT-1.3B được áp
dụng như kiến trúc mặc định trong công việc này, các kích thước khác của OPT, từ 125M lên đến
hàng chục tỷ, đều có thể được sử dụng để khởi tạo knowledge cards. Ngoài ra, 2) knowledge cards
có thể có kiến trúc mô hình khác nhau. Vì việc tích hợp các LLM tổng quát và knowledge cards mô-
đun xảy ra ở cấp độ ngôn ngữ tự nhiên, bất kỳ mô hình tạo ngôn ngữ nào cũng có thể được áp dụng
như knowledge cards. Hai cấp độ không đồng nhất này cho phép linh hoạt trong huấn luyện
knowledge card: các mô hình lớn hơn và có khả năng hơn có thể được huấn luyện trên tập dữ liệu
lớn và các lĩnh vực kiến thức rộng rãi bởi các cá nhân giàu tính toán, trong khi các knowledge cards
nhỏ hơn được huấn luyện trên các lĩnh vực nhỏ và chuyên dụng bởi các nhà nghiên cứu thiếu thốn
tính toán cũng có thể giúp cải thiện các LLM hộp đen, dân chủ hóa nghiên cứu LLM.

Thứ bậc knowledge cards. Chúng tôi tin rằng knowledge cards có thể phản ánh bản chất phân cấp
của kiến thức. Nếu KNOWLEDGE CARD được áp dụng cho trả lời câu hỏi tổng quát, thì một
knowledge card y sinh tổng quát được huấn luyện trên tập dữ liệu PubMed sẽ đủ. Tuy nhiên, nếu
KNOWLEDGE CARD được áp dụng cho các trường hợp sử dụng tinh tế hơn, lĩnh vực "y sinh" có thể
được chia thêm thành các tiểu lĩnh vực và một knowledge card có thể được huấn luyện cho mỗi
lĩnh vực. Các phân chia tương tự có thể được áp dụng cho các tiểu lĩnh vực trong nghiên cứu NLP,
tin tức chính trị ở các quốc gia khác nhau, và nhiều hơn nữa.

Kết hợp bottom-up và top-down. Một cách đơn giản để kết hợp hai phương pháp tích hợp kiến
thức sẽ là: trong mỗi bước của top-down, LLM đề xuất nhiều knowledge cards như ứng cử viên, sau
đó sử dụng phương pháp bottom-up với nhóm những knowledge cards này để tạo kiến thức. Chúng
tôi để lại các khám phá thêm cho công việc tương lai.
18

--- TRANG 19 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
B HẠN CHẾ
Knowledge cards không phải là những người tạo kiến thức hoàn hảo. Mặc dù knowledge cards có
thể có bất kỳ kích thước hoặc kiến trúc mô hình nào, chúng tôi đã sử dụng OPT-1.3B, một mô hình
ngôn ngữ tương đối nhỏ để khởi tạo knowledge cards được huấn luyện trên các lĩnh vực và nguồn
khác nhau. Do đó, không phải tất cả các tài liệu kiến thức được tạo đều là các câu lệnh kiến thức
chất lượng cao, đôi khi gặp phải suy thoái, lệch chủ đề và nhiều hơn nữa. Mặc dù ba bộ chọn kiến
thức một phần giảm thiểu tác động của các tài liệu kiến thức chất lượng thấp, chúng tôi giả định
rằng việc cải thiện tạo kiến thức của các mô hình ngôn ngữ tự hồi quy là một câu hỏi nghiên cứu
quan trọng, nhưng trực giao, cho công việc tương lai. Hai giải pháp tiềm năng bao gồm 1) tăng
kích thước mô hình của knowledge cards và 2) sử dụng các mục tiêu huấn luyện chuyên biệt cho
knowledge cards, trong khi cả hai phương pháp đều yêu cầu huấn luyện bổ sung và nhiều tài nguyên
tính toán hơn. Ngoài ra, Phụ lục A đã thảo luận về tính tương thích của KNOWLEDGE CARD với
các nguồn kiến thức đa dạng, bao gồm truy xuất, đồ thị kiến thức và công cụ tìm kiếm, trong khi
những kho lưu trữ kiến thức này có ưu và nhược điểm tương ứng của chúng. Chúng tôi để lại cho
công việc tương lai về việc tích hợp nhiều loại cửa hàng kiến thức bên ngoài để mở rộng KNOWLEDGE
CARD.

Bộ chọn tính chính xác thiên về các lĩnh vực giàu thông tin và kiến thức hiện có. Để đảm bảo tính
chính xác của các tài liệu kiến thức được tạo, chúng tôi đã sử dụng một bộ chọn tính chính xác
tăng cường truy xuất dựa trên cả các thước đo tính chính xác tóm tắt và mô hình kiểm tra sự thật
trong khi cho phép linh hoạt thông qua lấy mẫu tính chính xác top-k được đề xuất của chúng tôi.
Tuy nhiên, các lĩnh vực có nhiều mục Wikipedia hơn có thể được hỗ trợ tốt hơn bởi các tài liệu
được truy xuất và có thể nhận được điểm tính chính xác cao hơn. Ngoài ra, kiến thức mới và nổi
lên có thể được hỗ trợ tốt bởi các tập dữ liệu truy xuất hiện tại và nhận điểm tính chính xác thấp.
Chúng tôi đánh giá định lượng thiên kiến này trong Phụ lục D. Mặc dù lấy mẫu tính chính xác top-k
cho phép linh hoạt ở một mức độ nào đó, nó vẫn là một vấn đề quan trọng để thiết kế các biện pháp
đánh giá tính chính xác có thể tổng quát hóa và thích ứng với các lĩnh vực khác nhau và nổi lên.

Gợi ý LLM tìm kiếm sự giúp đỡ thông qua câu hỏi có/không không hoàn hảo. Được truyền cảm
hứng bởi những phát hiện rằng LLM không cần kiến thức bên ngoài cho mọi truy vấn (Zhao et al.,
2023) và các mô hình ngôn ngữ (chủ yếu) biết những gì họ biết (Kadavath et al., 2022), chúng tôi
đề xuất hỏi câu hỏi có/không để quyết định có kích hoạt knowledge cards hay không và khuyến khích
câu trả lời được hiệu chỉnh tốt thông qua học trong ngữ cảnh. Phân tích của chúng tôi (§5) cho
thấy rằng chiến lược này hiệu quả nhưng còn xa mới hoàn hảo: LLM đôi khi quá tự tin về khả năng
kiến thức của họ. Chúng tôi để lại cho công việc tương lai về việc thiết kế các chiến lược tốt hơn
cho LLM để từ chối, thừa nhận những hạn chế kiến thức và tìm kiếm sự giúp đỡ từ các nguồn thông
tin bên ngoài.

C TUYÊN BỐ ĐẠO ĐỨC
Chúng tôi hình dung KNOWLEDGE CARD như một sáng kiến do cộng đồng thúc đẩy và cộng tác để
cải thiện các LLM tổng quát trong các tác vụ và bối cảnh cần nhiều kiến thức. Một rủi ro quan trọng
là việc sử dụng kép và khai thác từ các tác nhân độc hại. Vì knowledge cards mô-đun có khả năng
thay đổi hoặc cập nhật kiến thức LLM, các tác nhân độc hại có thể thúc đẩy chương trình nghị sự
của họ bằng cách gửi các knowledge cards độc hại được huấn luyện trên thông tin sai lệch, nội
dung cực đoan, tuyên truyền và nhiều hơn nữa, trong khi đóng khung chúng như các lĩnh vực kiến
thức lành tính và lừa dối người dùng LLM. Chúng tôi hình dung hai hướng tiếp cận đối với rủi ro
đạo đức này: về mặt kỹ thuật, nghiên cứu về thao túng đối nghịch của các mô hình ngôn ngữ và
các chiến thuật phòng thủ tương ứng (Bagdasaryan & Shmatikov, 2022; Perez et al., 2022) có thể
được tích hợp để giảm thiểu tác động của các knowledge cards độc hại; về mặt xã hội, chúng ta
có thể dựa vào và củng cố các quy tắc hiện có cho việc chia sẻ mô hình trên các cơ sở hạ tầng phổ
biến (Wolf et al., 2020) để ngăn chặn sự đóng góp độc hại như vậy xảy ra. Chúng tôi khuyến khích
việc sử dụng có trách nhiệm KNOWLEDGE CARD, trong khi chúng tôi cũng kêu gọi người dùng và
nhà nghiên cứu chú ý đến rủi ro sử dụng kép này.

D PHÂN TÍCH (TIẾP)
Lựa chọn Knowledge Card Trong phương pháp top-down, chúng tôi yêu cầu các mô hình ngôn ngữ
lớn chọn knowledge cards liên quan và có được kiến thức bên ngoài. Chúng tôi minh họa kết quả
lựa chọn của chiến lược lựa chọn tự động trên bộ dữ liệu MMLU được chia thành 57 tiểu tác vụ.
Hình 8 chứng minh rằng đối với hầu hết các tác vụ, việc lựa chọn kiến thức thể hiện các mẫu giống
như đỉnh nhọn trên
19

--- TRANG 20 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
tập dữ liệu Wikipedia và đồ thị kiến thức bách khoa, cho thấy rằng phần lớn các tác vụ có một vài
knowledge cards rõ ràng liên quan. Ngoài ra, đối với các tác vụ khác (ví dụ: luật học và lịch sử
trung học Mỹ), không rõ knowledge cards nào sẽ hữu ích nhất, do đó việc lựa chọn được trải rộng
hơn. Những kết quả này cho thấy rằng các mẫu lựa chọn cũng có thể chỉ ra liệu có cần một
knowledge card mới và trong chủ đề hơn cho bất kỳ tác vụ nhất định nào hay không.

3 có 2 có, 1 không 2 không, 1 có 3 không0200400600800100012001400
Hình 7: Câu hỏi Có/Không trong
top-down chủ yếu nhất quán qua
ba mẫu gợi ý, trong khi có không
gian để cải thiện trong công việc
tương lai.Độ Nhạy Mẫu Có/Không Trong phương pháp top-down, chúng
tôi gợi ý LLM với "Bạn có cần thêm thông tin? (Có/Không)" để
xác định liệu có cần kiến thức bên ngoài hay không và sử dụng
học trong ngữ cảnh để khuyến khích phản hồi được hiệu chỉnh
tốt. Vì các mô hình ngôn ngữ nhạy cảm với những thay đổi nhỏ
trong gợi ý, chúng tôi tạo ra hai câu hỏi khác: "Có cần thêm
thông tin ở đây không?" và "Bạn có muốn thông tin bổ sung
không?" và báo cáo kết quả trên tác vụ thông tin sai lệch 2
chiều trong Hình 7. Nó được chứng minh rằng LLM đưa ra phản
hồi tương đối nhất quán: 79.9% trường hợp nhận được có hoặc
không nhất trí từ ba gợi ý, trong khi 20.1% ví dụ nhận được
kết quả hỗn hợp. Điều này cho thấy rằng một cải thiện tiềm
năng cho KNOWLEDGE CARD là sử dụng nhiều câu hỏi có/không
để thăm dò những hạn chế kiến thức và sử dụng một tập hợp
câu trả lời để cải thiện tính mạnh mẽ.

Điểm Tính chính xác của Knowledge Cards Chúng tôi sử dụng
các bộ dữ liệu MMLU như truy vấn để gợi ý các knowledge
cards khác nhau, tạo ra các tài liệu kiến thức và đánh giá tính
chính xác của chúng với bộ chọn tính chính xác (§2.2). Chúng
tôi minh họa phân phối điểm tính chính xác của các knowledge
cards khác nhau trong Hình 9, cho thấy rằng các knowledge
cards khác nhau có tính chính xác vốn có khác nhau. Chúng tôi
giả định rằng phân phối điểm tính chính xác được đưa ra bởi
bộ chọn tính chính xác có thể hướng dẫn nỗ lực đánh giá chất
lượng của các knowledge cards được đóng góp bởi cộng đồng.

Siêu tham số Huấn luyện LM Giai đoạn Suy luận
Siêu tham số Giá trị Siêu tham số Giá trị
TỐC ĐỘ HỌC 2e-5 n1 3
SỤY GIẢM TRỌNG SỐ 1e-5 n2 5
SỐ EPOCH TỐI ĐA 10 n3 3
KÍCH THƯỚC LÔ 32 SỐ LẦN LẶP TỐI ĐA 1
BỘ TỐI ƯU ADAM NHIỆT ĐỘ 0.1
ADAM EPSILON 1e-6 LLM MẶC ĐỊNH CODEX
ADAM BETA 0.9,0.98
TỶ LỆ KHỞI ĐỘNG 0.06
Bảng 6: Cài đặt siêu tham số.Tích lũy Knowledge Card Chúng tôi mong đợi
KNOWLEDGE CARD hoạt động tốt hơn khi các
knowledge cards liên quan được dần dần thêm
vào hệ thống. Vì vậy, chúng tôi dần dần thêm
năm knowledge cards (PubMed, IMDB, Book-
Corpus, News và Wikipedia) vào KNOWLEDGE
CARD và đánh giá hiệu suất với bộ dữ liệu thông
tin sai lệch, cài đặt 2 chiều, phương pháp
bottom-up và mô hình ChatGPT. Bảng 7 chứng
minh rằng việc thêm knowledge cards, đặc biệt
là những cái trong lĩnh vực (News trong trường
hợp này), thực sự hữu ích trong việc cải thiện
mô hình ngôn ngữ lớn cơ sở.

Cài đặt # card BAcc MaF
THUẦN TÚY 0 80.1 70.5
+ PUBMED 1 80.7 70.6
+ IMDB 2 80.6 71.2
+ BOOK CORPUS 3 82.3 72.9
+ NEWS 4 85.7 73.1
+ WIKIPEDIA 5 76.5 75.3
Bảng 7: Hiệu suất KNOWLEDGE CARD trên bộ
dữ liệu thông tin sai lệch hai chiều khi năm
knowledge cards được dần dần thêm vào.Ví dụ Hoạt động Chúng tôi trình bày các gợi ý cụ
thể, tài liệu kiến thức được tạo và gợi ý cho
phương pháp bottom-up, và phương pháp top-down
với lựa chọn tự động và rõ ràng trong Bảng 9,
10 và 11 tương ứng.

E CHI TIẾT THÍ NGHIỆM
Chi tiết Thuật toán Chúng tôi trình bày một tóm
tắt thuật toán của phương pháp bottom-up và
top-down trong Thuật toán 1 và 2.

Lĩnh vực Knowledge Cards Chúng tôi huấn luyện
tổng cộng 25 knowledge cards từ các tập dữ
liệu và lĩnh vực sau: một tỷ token (Chelba et
al., 2013), bài báo ACL (Lo et al., 2020), đồ
thị kiến thức thường thức ATOMIC (West et al.,
2022), book corpus (Zhu et al., 2015), ConceptNet
(Speer et al., 2017), đồ thị kiến thức y sinh
UMLS (Zhang et al., 2021), Gutenberg (Rae et
al., 2019),
20

--- TRANG 21 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
//cài đặt sách mở
Câu hỏi: Ai thắng cuộc đua thượng nghị sĩ Oregon trong cuộc bầu cử giữa nhiệm kỳ Mỹ 2022?
Câu trả lời: Ron Wyden
//cài đặt hai chiều
Câu hỏi: Ai thắng khu vực quốc hội thứ 24 của Texas trong cuộc bầu cử giữa nhiệm kỳ Mỹ 2022?
A. Jan McDowell B. Beth Van Duyne
Câu trả lời: B
//cài đặt bốn chiều
Câu hỏi: Ai thắng khu vực quốc hội thứ 6 của Pennsylvania trong cuộc bầu cử giữa nhiệm kỳ Mỹ 2022?
A. Christopher Hoeppner B. Doug Mastriano C. Chrissy Houlahan D. Guy Ciarrocchi
Câu trả lời: C
Bảng 8: Ví dụ về bộ dữ liệu MidtermQA cho ba cài đặt.

đánh giá phim IMDB (Wang et al., 2023), đồ thị kiến thức chính trị KGAP (Feng et al., 2021), hợp
đồng pháp lý (Hendrycks et al., 2021), bài toán (Saxton et al., 2019), tin tức bầu cử giữa nhiệm
kỳ (của chúng tôi), phụ đề mở2, tập dữ liệu tin tức chính trị POLITICS (Liu et al., 2022c), văn
học y sinh3, RealNews (Zellers et al., 2019), Reddit (Feng et al., 2023b), Twitter (Feng et al.,
2022), đồ thị kiến thức Wikidata (Vrandečić & Krötzsch, 2014), bản sao Wikipedia4, YAGO
(Pellissier Tanon et al., 2020) và đánh giá Yelp5. Đối với đồ thị kiến thức, chúng tôi theo Feng
et al. (2023a) để xây dựng tập dữ liệu văn bản và sử dụng chúng làm dữ liệu huấn luyện.

Siêu tham số Chúng tôi trình bày cài đặt siêu tham số trong Bảng 6.

Chi tiết Bộ dữ liệu 1) Bộ dữ liệu MMLU (Hendrycks et al., 2020) chứa tổng cộng 15,908 câu hỏi
bốn lựa chọn được chia thêm thành 57 tiểu tác vụ trong bốn lĩnh vực: nhân văn, khoa học xã hội,
STEM và khác. Bộ dữ liệu chính thức cũng cung cấp một tập minh họa, tức là 5-shot ví dụ trong
mỗi tiểu tác vụ để cho phép học vài shot trong ngữ cảnh. Chúng tôi theo tập minh họa và tập kiểm
tra chính thức trong các thí nghiệm của chúng tôi. 2) Bộ dữ liệu LUN (Rashkin et al., 2017) là
một bộ dữ liệu phát hiện thông tin sai lệch với cài đặt phân loại hai hoặc bốn chiều, hoặc chỉ với
đúng/sai hoặc các loại tinh tế của đáng tin cậy, lừa đảo, tuyên truyền hoặc châm biếm. Chúng tôi
sử dụng tập kiểm tra chính thức trong (Hu et al., 2021) với 2,999 ví dụ trong suốt các thí nghiệm.
3) Chúng tôi tuyển chọn MidtermQA, một bộ dữ liệu QA tập trung vào cuộc bầu cử giữa nhiệm kỳ
Mỹ 2022 để đánh giá khả năng cập nhật kiến thức thời gian của KNOWLEDGE CARD. Cụ thể, trước
tiên chúng tôi thu thập kết quả của 510 cuộc đua trong các cuộc bầu cử quốc hội, thượng nghị sĩ
hoặc thống đốc trong cuộc bầu cử giữa nhiệm kỳ 2022. Sau đó chúng tôi xây dựng ba bộ dữ liệu:
a) sách mở, trong đó chúng tôi yêu cầu LLM trực tiếp trả lời tên của người thắng cử cho một cuộc
đua nhất định, b) hai chiều, trong đó chúng tôi yêu cầu LLM chọn người thắng từ hai ứng cử viên
hàng đầu, và c) bốn chiều, trong đó chúng tôi tăng độ khó bằng cách bao gồm hai chính trị gia
khác thi đấu trong cùng một bang để tạo ra sự phân tâm. Chúng tôi trình bày các ví dụ về bộ dữ
liệu MidtermQA trong Bảng 8.

Chi tiết Tài nguyên Tính toán Chúng tôi đã sử dụng một cụm GPU với 16 GPU NVIDIA A40, bộ nhớ
1988G và 104 lõi CPU cho các thí nghiệm. Huấn luyện knowledge cards mất từ khoảng 7 giờ đến
10 ngày tùy thuộc vào kích thước tập dữ liệu huấn luyện. Đối với các LLM hộp đen, chúng tôi đã
sử dụng OpenAI API để truy cập CODE-DAVINCI-002, TEXT-DAVINCI-003 và GPT-3.5-TURBO trong
các thí nghiệm.

2https://github.com/sdtblck/Opensubtitles_dataset
3https://github.com/thoppe/The-Pile-PubMed
4https://github.com/noanabeshima/wikipedia-downloader
5https://www.yelp.com/dataset
21

--- TRANG 22 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
¡các ví dụ trong ngữ cảnh với cùng định dạng¿
...
Kiến thức: . . . San Mateo nằm ở phía tây bắc của California . . . Dianne Feinstein, thượng nghị
sĩ cấp cao từ California, được đồn là sẽ nghỉ hưu . . . Tom Brady trở về quê hương San Mateo . . .
Câu hỏi: Ai là thượng nghị sĩ cấp cao từ nơi sinh Tom Brady?
Câu trả lời:
Bảng 9: Ví dụ gợi ý cho phương pháp bottom-up. Các hộp màu khác nhau chỉ ra các tài liệu kiến
thức được tạo bởi các LM chuyên biệt khác nhau.

¡các ví dụ trong ngữ cảnh với cùng định dạng¿
...
Câu hỏi: Ai là thượng nghị sĩ cấp cao từ nơi sinh Tom Brady?
Bạn có cần thêm thông tin? (Có hoặc Không)
Có
Bạn cần loại thông tin gì?
Bang Tom Brady đến từ đâu.
Kiến thức: Tom Brady trở về quê hương San Mateo, CA . . .
Bạn có cần thêm thông tin? (Có hoặc Không)
Không
Câu trả lời:
Bảng 10: Ví dụ gợi ý cho phương pháp top-down với lựa chọn tự động. Văn bản in nghiêng chỉ ra
rằng trường này được tạo bởi các LLM hộp đen.

¡các ví dụ trong ngữ cảnh với cùng định dạng¿
...
Câu hỏi: Ai là thượng nghị sĩ cấp cao từ nơi sinh Tom Brady?
Bạn có cần thêm thông tin? (Có hoặc Không)
Có
Chọn một nguồn thông tin từ danh sách sau: thể thao, văn học y sinh, bài báo NLP, tập sách.
thể thao
Kiến thức: Tom Brady trở về quê hương San Mateo, CA . . .
Bạn có cần thêm thông tin? (Có hoặc Không)
Không
Câu trả lời:
Bảng 11: Ví dụ gợi ý cho phương pháp top-down với lựa chọn rõ ràng. Văn bản in nghiêng chỉ ra
rằng trường này được tạo bởi các LLM hộp đen.
22

--- TRANG 23 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Thuật toán 1: Phương pháp Bottom-Up
Dữ liệu: câu hỏi q; gợi ý ví dụ trong ngữ cảnh sicl; knowledge cards C={spec1, . . . , specn};
bộ chọn liên quan, cắt tỉa và tính chính xác ϕrel,ϕprune,ϕfact
Kết quả: chuỗi câu trả lời sans
PROMPT =sicl
KNOWLEDGE LIST = []
cho spec∈ C thực hiện
KNOWLEDGE LIST.append( spec(q,n1))
kết thúc
KNOWLEDGE LIST =ϕrel(q,KNOWLEDGE LIST,n2)
KNOWLEDGE LIST =ϕprune(KNOWLEDGE LIST)
KNOWLEDGE LIST =ϕfact(KNOWLEDGE LIST,n3)
PROMPT += "Kiến thức: "
cho s∈KNOWLEDGE LIST thực hiện
PROMPT +=s
kết thúc
PROMPT += "Câu hỏi: " +q+ "Câu trả lời: "
sans=LLM (PROMPT )
trả về sans

Thuật toán 2: Phương pháp Top-Down
Dữ liệu: câu hỏi q; gợi ý ví dụ trong ngữ cảnh sicl; knowledge cards C={spec1, . . . , specn};
tên knowledge card S={s1, . . . , sn}; thử tối đa k; bộ chọn liên quan và tính chính xác
ϕrel;ϕfact; cờ nhị phân AUTO và EXP
Kết quả: chuỗi câu trả lời sans
PROMPT =sicl
PROMPT += "Câu hỏi: " +q
i= 0
trong khi i≤k thực hiện
PROMPT += "Bạn có cần thêm thông tin? (Có hoặc Không) "
RESPONSE =LLM (PROMPT )
nếu RESPONSE == "Có" thì
nếu AUTO thì
PROMPT += "Bạn cần loại thông tin gì? "
RESPONSE =LLM (PROMPT )
spec =ϕrel(RESPONSE ,{s1, . . . , sn},TOP-K= 1)
kết thúc
nếu EXP thì
PROMPT += "Chọn một nguồn thông tin từ danh sách sau: "
cho s∈ S thực hiện
prompt += s
kết thúc
spec =LLM (PROMPT )
kết thúc
KNOWLEDGE =ϕfact(spec( q, n1),1)
PROMPT += "Kiến thức: " + KNOWLEDGE
kết thúc
nếu RESPONSE == "Không" thì
ngắt
kết thúc
kết thúc
PROMPT += "Câu trả lời: "
sans=LLM (PROMPT )
trả về sans
23

--- TRANG 24 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
một tỷ tokenACL papersatomicbook corpusConceptNetbiomedical KGgutenbergIMDBpolitical KGlegal contractsmathopensubtitlesPOLITICSpubmedrealnews_1realnews_2realnews_3realnews_4reddittwitterwikidatayagoyelpWikipediaelectrical engineering
management
college CS
nutrition
medical genetics
high school european history
computer security
college biology
high school biology
high school microeconomics
high school world history
college physics
high school geography
clinical knowledge
high school macroeconomics
marketing
security studies
human aging
high school CS
elementary mathematics
conceptual physics
anatomy
global facts
us foreign policy
college chemistry
logical fallacies
sociology
high school us history
miscellaneous
college medicine
virology
jurisprudence
prehistory
business ethics
international law
high school statistics
high school psychology
professional psychology
professional accounting
astronomy
high school mathematics
professional medicine
econometrics
high school government and politics
machine learning
moral disputes
high school physics
philosophy
formal logic
human sexuality
world religions
college mathematics
public relations
abstract algebra
high school chemistry0.71.40.713.8 1.40.00.00.00.70.00.70.01.40.70.00.70.70.00.00.00.062.8 0.713.8
0.01.00.01.01.91.01.91.90.01.01.01.90.01.91.01.90.01.00.00.01.949.5 0.030.1
0.01.00.010.017.0 1.00.00.01.03.01.00.00.03.00.00.00.01.00.01.01.01.051.0 1.07.0
0.30.30.30.70.71.30.30.00.00.30.00.70.00.00.30.30.00.70.30.00.361.8 0.031.4
0.00.01.04.03.07.00.00.00.00.00.00.02.01.00.01.02.00.00.01.00.043.0 0.035.0
0.00.60.00.00.60.01.20.63.00.00.00.01.20.00.01.21.80.01.20.010.338.8 0.039.4
1.01.01.03.07.02.00.02.03.00.00.01.00.00.03.01.00.00.03.00.02.041.0 3.026.0
0.70.00.04.90.70.70.00.00.00.70.70.70.00.00.00.00.00.00.00.70.065.3 0.724.3
0.00.00.33.22.30.30.60.00.60.00.00.60.60.30.30.30.60.30.30.60.070.6 0.317.4
0.00.40.81.30.01.71.70.40.80.80.00.80.80.41.70.40.00.40.40.80.063.4 0.422.3
0.41.31.32.50.40.41.30.08.02.10.80.40.80.40.41.31.30.00.80.48.049.8 0.417.3
1.01.00.028.4 0.00.00.00.00.00.00.01.00.00.00.01.00.00.01.01.00.057.8 1.06.9
0.50.50.00.51.51.00.00.51.00.51.00.00.00.00.00.50.50.50.00.02.053.0 1.035.4
0.40.40.84.91.51.50.00.40.00.40.00.00.40.40.00.40.40.40.00.80.058.9 0.827.5
0.80.31.02.60.51.00.51.01.31.01.01.00.01.00.81.00.50.81.01.31.063.8 0.815.9
0.00.90.00.90.91.30.42.60.90.40.90.00.00.40.90.40.91.70.90.40.455.1 3.026.9
0.80.81.62.01.24.51.61.22.02.01.21.21.21.20.81.60.80.40.42.01.228.6 2.938.4
0.41.30.42.20.42.20.01.81.32.20.90.90.01.30.00.40.40.40.00.00.957.4 0.024.7
1.01.00.07.025.0 2.00.00.01.00.00.02.01.02.00.01.02.00.01.04.01.038.0 0.011.0
1.61.30.35.03.41.91.10.51.10.81.31.30.31.31.11.31.10.81.90.31.362.4 0.87.9
0.40.00.916.6 0.40.90.40.00.00.40.00.40.41.30.00.00.90.40.00.40.062.6 0.413.2
0.00.70.01.50.71.50.00.00.00.00.00.00.01.50.00.71.50.70.70.00.077.0 0.712.6
0.00.00.01.00.01.00.00.05.00.00.00.00.00.00.01.01.01.00.00.04.035.0 0.051.0
1.00.00.02.00.02.00.01.07.02.03.05.00.00.00.00.03.00.00.00.01.040.0 0.033.0
0.00.00.040.011.0 0.00.00.00.00.01.00.01.01.00.00.00.01.00.00.00.033.0 0.012.0
1.20.01.24.31.80.61.20.00.01.80.60.61.81.20.00.60.60.00.61.82.532.5 0.644.2
0.00.00.01.00.00.50.00.51.51.50.00.51.00.00.50.50.01.00.01.01.021.9 0.067.7
1.50.00.52.01.01.50.01.521.1 2.90.50.01.51.00.00.50.51.00.50.56.921.1 0.533.8
0.10.40.32.00.90.30.40.60.81.00.30.40.00.40.30.50.40.00.10.81.055.3 0.333.6
0.00.60.65.81.70.60.00.00.01.20.60.00.60.00.60.00.00.00.60.00.058.4 0.628.3
0.60.00.01.21.23.00.61.20.00.60.00.00.00.00.01.80.60.00.01.21.249.4 1.236.1
0.90.90.91.90.90.00.00.01.920.4 0.90.00.90.00.00.90.00.91.90.00.032.4 0.034.3
0.30.30.61.50.90.00.60.00.00.00.30.00.30.00.30.30.90.60.00.31.950.9 0.039.8
2.00.00.01.01.01.03.03.01.04.01.02.01.00.01.00.00.00.00.03.02.026.0 0.048.0
0.00.00.00.00.00.80.00.01.719.0 1.70.00.00.00.00.00.80.00.00.02.540.5 0.832.2
0.50.50.52.81.40.50.90.50.90.00.90.50.90.50.00.50.50.50.50.50.068.5 0.018.1
0.71.30.21.71.31.30.71.10.61.11.10.61.10.90.70.90.21.30.60.60.663.5 0.617.6
0.50.70.21.30.30.70.30.80.71.80.80.80.30.30.70.00.50.50.30.50.353.3 0.534.0
0.40.70.70.70.40.00.41.10.43.51.10.71.40.71.11.10.00.40.40.70.469.1 0.414.5
0.70.72.014.5 1.30.70.70.00.00.00.70.70.70.01.30.00.70.00.70.72.046.1 0.026.3
1.10.02.216.3 7.40.40.72.61.11.11.51.51.51.90.70.70.40.00.41.51.152.2 1.52.2
0.00.00.00.00.00.00.00.00.00.40.00.00.00.00.00.00.00.00.00.00.061.8 0.037.9
0.90.00.03.57.90.90.00.90.91.80.01.81.80.90.90.91.80.00.00.01.862.3 0.011.4
0.50.00.00.00.00.50.50.517.1 6.20.00.50.50.00.00.00.00.50.00.00.040.4 0.532.1
0.90.91.83.625.9 0.00.90.00.90.00.90.00.00.00.00.90.00.90.90.90.050.9 0.09.8
0.90.60.90.30.31.70.30.61.21.40.30.31.40.30.90.30.90.90.00.61.235.0 0.349.7
0.01.30.020.5 2.60.00.00.00.00.70.00.70.70.70.00.00.00.00.70.70.067.5 0.04.0
0.00.60.01.90.30.00.00.01.90.60.00.00.00.61.00.30.30.30.00.30.028.0 0.063.7
1.61.60.015.1 0.02.40.00.80.83.20.80.81.61.62.40.00.81.60.81.60.848.4 4.09.5
0.02.30.80.80.03.10.00.00.00.00.00.00.00.00.00.00.01.50.80.80.055.0 0.834.4
0.60.00.00.00.60.60.00.00.60.60.00.00.00.00.60.00.60.00.01.21.847.4 0.045.6
0.01.01.015.021.0 0.01.01.00.00.02.03.00.02.00.02.01.00.01.01.00.039.0 0.09.0
1.80.90.00.92.70.90.92.71.81.81.80.00.90.00.00.00.90.00.91.80.032.7 2.743.6
4.00.02.011.016.0 0.00.01.02.01.00.02.02.01.01.03.02.01.01.02.00.042.0 2.04.0
0.50.00.020.2 7.40.00.00.50.00.50.00.00.01.00.00.00.00.00.00.00.064.5 0.05.4
Hình 8: Thống kê lựa chọn knowledge card trong phương pháp top-down với lựa chọn tự động qua
57 tiểu tác vụ trong chuẩn MMLU. Đồ thị kiến thức bách khoa YAGO và Wikipedia nói chung là
những knowledge cards được áp dụng nhiều nhất.
24

--- TRANG 25 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
0 0.2 0.4 0.6 0.8 1.0pubmed
yelp
realnews_1
wikipedia
realnews_2
realnews_3
realnews_4
acl_papers
math
1B
kgap
cpnet
gutenberg
POLITICS
reddit
IMDB
ddb
wikidata
yago
midterm
bookcorpus
legal_contracts
atomic
opensubtitles
twitter
Hình 9: Phân phối điểm tính chính xác của 25 knowledge cards khi được gợi ý với câu hỏi trong
chuẩn MMLU. Các knowledge cards khác nhau thực sự có phân phối điểm tính chính xác khác nhau.
25

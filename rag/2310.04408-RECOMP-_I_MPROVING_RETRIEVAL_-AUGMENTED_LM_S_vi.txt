# 2310.04408.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2310.04408.pdf
# Kích thước tệp: 764449 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
RECOMP: CẢI THIỆN CÁC MÔ HÌNH NGÔN NGỮ TĂNG CƯỜNG TRUY XUẤT
VỚI NÉN VÀ TĂNG CƯỜNG CHỌN LỌC

Fangyuan Xu1, Weijia Shi2, Eunsol Choi1
Khoa Khoa học Máy tính
1Đại học Texas tại Austin
2Đại học Washington
{fangyuan,eunsol }@utexas.edu ,swj0419@cs.washington.edu

TÓM TẮT
Truy xuất tài liệu và thêm chúng vào ngữ cảnh khi suy luận cải thiện hiệu suất của mô hình ngôn ngữ (LM) trên nhiều loại tác vụ khác nhau. Tuy nhiên, những tài liệu này, thường kéo dài hàng trăm từ, làm cho việc suy luận trở nên đắt đỏ hơn đáng kể. Chúng tôi đề xuất nén các tài liệu truy xuất thành tóm tắt văn bản trước khi tích hợp trong ngữ cảnh. Điều này không chỉ giảm chi phí tính toán mà còn giảm gánh nặng cho LM trong việc xác định thông tin liên quan trong các tài liệu truy xuất dài. Chúng tôi trình bày hai bộ nén – một bộ nén trích xuất chọn các câu hữu ích từ tài liệu truy xuất và một bộ nén tóm tắt tạo ra tóm tắt bằng cách tổng hợp thông tin từ nhiều tài liệu. Cả hai bộ nén đều được huấn luyện để cải thiện hiệu suất LM trên các tác vụ cuối khi tóm tắt được tạo ra được thêm vào đầu vào của LM, đồng thời giữ tóm tắt ngắn gọn. Nếu các tài liệu truy xuất không liên quan đến đầu vào hoặc không cung cấp thông tin bổ sung cho LM, bộ nén của chúng tôi có thể trả về một chuỗi rỗng, thực hiện tăng cường chọn lọc. Chúng tôi đánh giá phương pháp của mình trên tác vụ mô hình hóa ngôn ngữ và tác vụ trả lời câu hỏi miền mở. Chúng tôi đạt được tỷ lệ nén thấp tới 6% với tổn thất hiệu suất tối thiểu cho cả hai tác vụ, vượt trội đáng kể so với các mô hình tóm tắt có sẵn. Chúng tôi cho thấy rằng các bộ nén của chúng tôi được huấn luyện cho một LM có thể chuyển giao sang các LM khác trên tác vụ mô hình hóa ngôn ngữ và cung cấp tóm tắt phần lớn trung thực với các tài liệu truy xuất.1

1 GIỚI THIỆU
Các mô hình ngôn ngữ tăng cường truy xuất (RALM) (Khandelwal et al., 2019; Izacard et al., 2022; Lewis et al., 2020; Borgeaud et al., 2022) đã cho thấy hiệu suất ấn tượng trên các tác vụ đòi hỏi kiến thức cao (Kwiatkowski et al., 2019; Petroni et al., 2021). Việc đơn giản thêm các tài liệu truy xuất vào đầu vào mà không cập nhật các mô hình ngôn ngữ (LM) (Shi et al., 2023b; Ram et al., 2023; Si et al., 2022) cho phép tăng cường truy xuất ngay cả đối với các LM hộp đen, nhưng phương pháp như vậy có những hạn chế.

Đầu tiên, nó tăng chi phí tính toán vì LM giờ đây phải mã hóa nhiều token hơn đáng kể. Thứ hai, ngay cả khi chúng ta có thể thích nghi LM để kết hợp hiệu quả ngữ cảnh dài hơn (Beltagy et al., 2020; Zaheer et al., 2020), những mô hình này gặp khó khăn trong việc sử dụng tất cả thông tin trong ngữ cảnh, thường bỏ lỡ thông tin được đặt ở giữa (Liu et al., 2023). Thứ ba, việc thêm một số lượng lớn tài liệu vào ngữ cảnh có thể khiến LM bối rối hơn với thông tin không liên quan, làm giảm hiệu suất mô hình (Mallen et al., 2022; Shi et al., 2023a).

Để khắc phục những hạn chế như vậy, chúng tôi đề xuất RECOMP (Retrieve, Compress, Prepend), một bước trung gian cho RALM nén các tài liệu truy xuất thành tóm tắt văn bản trước khi tăng cường trong ngữ cảnh. Hình 1 minh họa phương pháp của chúng tôi. Tóm tắt được tạo ra nên ngắn gọn để tối đa hóa hiệu quả, trung thực với các tài liệu bằng chứng truy xuất, và hướng dẫn RALM tạo ra đầu ra mong muốn khi được thêm vào đầu vào. Để thỏa mãn cả ràng buộc hiệu quả và hiệu lực, bộ nén của chúng tôi thực hiện chiến lược tăng cường chọn lọc bằng cách tạo ra tóm tắt rỗng khi các tài liệu truy xuất không liên quan hoặc không hữu ích cho tác vụ đích.

1Mã của chúng tôi có sẵn tại https://github.com/carriex/recomp .

--- TRANG 2 ---
RECOMP trong quá trình suy luận
chuyển từ Smyrna, Tennessee, đến cơ sở của Nissan ở Canton, Mississippi. Các mô hình Mỹ ban đầu bao gồm X, S và PRO-4X, với lựa chọn hộp số sàn 6 cấp hoặc hộp số tự động 5 cấp, lựa chọn [...]
chuyển từ Smyrna, Tennessee, đến cơ sở của Nissan ở Canton, Mississippi. Các mô hình Mỹ ban đầu bao gồm X, S và PRO-4X, với lựa chọn hộp số sàn 6 cấp hoặc hộp số tự động 5 cấp, lựa chọn [...]
chuyển từ Smyrna, Tennessee, đến cơ sở của Nissan ở Canton, Mississippi. Các mô hình Mỹ ban đầu bao gồm X, S và PRO-4X, với lựa chọn hộp số sàn 6 cấp hoặc hộp số tự động 5 cấp, lựa chọn [...]
chuyển từ Smyrna, Tennessee, đến cơ sở của Nissan ở Canton, Mississippi. Các mô hình Mỹ ban đầu bao gồm X, S và PRO-4X, với lựa chọn hộp số sàn 6 cấp hoặc hộp số tự động 5 cấp...

Tài liệu truy xuất D
RECOMP (58 token)
Truy xuất
Nén
Thêm vào đầu
Không truy xuất (0 token)
RALM (749 token)
2010
❌
✅
2015
Tóm tắt
Truy vấn đầu vào x
khi nào họ ngừng sản xuất nissan xterra?
Blackbox LM M 2015
✅
Bộ nén
Nissan Xterra là xe động cơ trước, dẫn động 2 bánh hoặc 4 bánh, năm cửa...

Hình 1: Minh họa RECOMP, nén các tài liệu truy xuất thành tóm tắt văn bản trước khi thêm nó làm đầu vào cho mô hình ngôn ngữ tại thời điểm suy luận. Tóm tắt nén hướng dẫn LM tạo ra câu trả lời đúng, đồng thời giảm đáng kể chi phí tính toán cần thiết để mã hóa các tài liệu.

Chúng tôi đề xuất các bộ nén: (1) Bộ nén trích xuất chọn các câu liên quan từ tập tài liệu truy xuất; (2) Bộ nén tóm tắt tạo ra tóm tắt tổng hợp thông tin từ nhiều tài liệu truy xuất. Cả hai bộ nén đều thực hiện tóm tắt tập trung truy vấn đa tài liệu (Xu & Lapata, 2020), nơi chúng tôi tóm tắt tập tài liệu bằng chứng truy xuất liên quan đến truy vấn đầu vào. Vì chúng tôi nhằm mục đích cho phép RALM tạo ra đầu ra đúng khi tóm tắt được thêm vào truy vấn đầu vào, chúng tôi thiết kế các sơ đồ huấn luyện để tối ưu hóa hiệu suất tác vụ cuối. Bộ nén trích xuất của chúng tôi được huấn luyện với mục tiêu học tập đối lập để xác định các câu dẫn đến đầu ra đích, và bộ nén tóm tắt của chúng tôi được chưng cất (West et al., 2022) từ một LM quy mô cực lớn (ví dụ GPT-3), đạt được hiệu suất tóm tắt ấn tượng.

Các thí nghiệm của chúng tôi cho thấy RECOMP có thể cải thiện hiệu suất của các LM cố định trên mô hình hóa ngôn ngữ (Merity et al., 2016) và ba bộ dữ liệu trả lời câu hỏi (Natural Questions (Kwiatkowski et al., 2019), TriviaQA (Joshi et al., 2017) và HotpotQA (Yang et al., 2018)), trong khi thêm ít token hơn đáng kể so với RALM không có nén. Chúng tôi trình bày hai phương pháp nén oracle – một oracle trích xuất chọn một câu trong tài liệu bằng chứng dẫn đến hiệu suất tác vụ tốt nhất và một oracle tóm tắt chọn giữa tóm tắt được tạo bởi LLM quy mô cực lớn (ví dụ GPT-3) và không tăng cường truy xuất dẫn đến hiệu suất tác vụ tốt nhất. Cả hai phương pháp oracle đều đạt được tỷ lệ nén thấp tới 6% và vượt trội đáng kể so với việc thêm toàn bộ tài liệu. Các bộ nén được huấn luyện của chúng tôi cũng cho thấy kết quả đầy hứa hẹn. Đối với mô hình hóa ngôn ngữ, cả hai bộ nén được huấn luyện đều đạt được tỷ lệ nén 25% với sự giảm hiệu suất tối thiểu. Khi áp dụng cho các bộ dữ liệu QA, mô hình tốt nhất của chúng tôi nén các tài liệu xuống 5 - 10% token gốc với mức giảm hiệu suất tương đối tối đa ít hơn 10%. Chúng tôi kết thúc với những phân tích cẩn thận về phương pháp của mình, tiết lộ cả điểm mạnh và điểm yếu, từ đó xây dựng nền tảng cho công việc tương lai.

2 CÔNG THỨC BÀI TOÁN: RECOMP

Cho một chuỗi đầu vào x, một chuỗi đầu ra đích y và một tập N tài liệu truy xuất D ([d1, d2, ...dN]),2 RECOMP nén các tài liệu truy xuất D liên quan đến x thành tóm tắt s nắm bắt thông tin cốt lõi trong D liên quan đến x với ít token hơn đáng kể so với D. Kiến trúc của chúng tôi bao gồm hai module: bộ nén cθ và LM M. Trong công việc này, chúng tôi giả định một LM hộp đen và huấn luyện bộ nén. Cho tập N tài liệu truy xuất ([d1, d2, ...dN]) và chuỗi đầu vào x, bộ nén trả về một chuỗi token s. Chúng tôi thiết kế bộ nén của mình nhỏ hơn đáng kể so với LM M, vì chúng tôi nhằm mục đích giảm chi phí tính toán của việc mã hóa một tập tài liệu truy xuất.

Đầu ra từ bộ nén, s, nên là: (1) Ngắn gọn: Tóm tắt nên càng ngắn càng tốt để tối ưu hóa hiệu quả. Nếu các tài liệu truy xuất không chứa thông tin liên quan hoặc tăng cường truy xuất không cần thiết, s có thể là một chuỗi rỗng. (2) Hiệu quả: khi s được thêm vào chuỗi đầu vào x và cung cấp cho LM M làm prompt, LM nên tạo ra chuỗi đầu ra đích y. (3) Trung thực: s nên là tóm tắt trung thực và có thể diễn giải của tập tài liệu đầu vào (tức là, s phải được suy ra từ tập tài liệu đầu vào ([d1, d2, ...dN])). Chúng tôi tập trung vào huấn luyện các bộ nén cho tính ngắn gọn và hiệu quả. Chúng tôi tóm tắt các ý tưởng chính cho hai bộ nén của mình, bộ nén trích xuất và bộ nén tóm tắt ở đây, và thảo luận về các sơ đồ huấn luyện của chúng một cách chính thức trong Phần 3.

2Cải thiện bộ truy xuất không phải là trọng tâm của công việc này, vì vậy chúng tôi giả định một tập tài liệu truy xuất được cung cấp.

--- TRANG 3 ---
Bộ Nén Trích Xuất Cho n câu [s1,s2...sn] trong tập tài liệu đầu vào ([d1, d2, ...dN]), chúng tôi huấn luyện một mô hình mã hóa kép encθ nhúng câu si và chuỗi đầu vào x thành các embedding có chiều cố định tương ứng. Tích vô hướng của chúng biểu thị mức độ hữu ích khi LM M thêm si vào đầu vào x để tạo ra y. Tóm tắt cuối cùng s từ bộ nén sẽ là một nối tiếp của N câu hàng đầu được xếp hạng theo tích vô hướng của chúng với đầu vào. Vì phương pháp này là trích xuất, chúng tôi giả định tiêu chí trung thực phần lớn được thỏa mãn.3

Bộ Nén Tóm Tắt Chúng tôi huấn luyện một mô hình mã hóa-giải mã encdecθ để phục vụ như một bộ nén tóm tắt, nhận chuỗi đầu vào x và một nối tiếp của tập tài liệu truy xuất D ([d1;d2;...dN]) và xuất ra tóm tắt s. Mặc dù chúng tôi không có chú thích của con người để huấn luyện mô hình này, các công việc trước đây (Goyal et al., 2022; Chen et al., 2023; Potluri et al., 2023) cho thấy rằng các LM quy mô cực lớn có thể tạo ra tóm tắt tập trung truy vấn tốt khi được nhắc cẩn thận. Tuy nhiên, việc sử dụng mô hình quy mô cực lớn làm bộ nén không mong muốn vì chúng tôi muốn bộ nén nhỏ hơn đáng kể so với các LM. Do đó, chúng tôi thực hiện chưng cất (Hinton et al., 2015) các LM quy mô cực lớn để xây dựng bộ nén tóm tắt nhẹ encdecθ. Chúng tôi không huấn luyện cụ thể cho tính trung thực, nhưng sau đó đánh giá thủ công tính trung thực trong Phần 6.

3 HỌC CÁC BỘ NÉN

Bộ nén của chúng tôi giống với các mô hình tóm tắt văn bản ở chỗ đầu ra nên trung thực với đầu vào gốc, nhưng mục tiêu chính là khác nhau. Thay vì nắm bắt thông tin nổi bật cho người đọc, các bộ nén nhằm mục đích tạo ra văn bản ngắn gọn hữu ích cho LM trên một tác vụ cuối. Trong phần này, chúng tôi mô tả cách huấn luyện bộ nén trích xuất (§3.1) và bộ nén tóm tắt (§3.2) tận dụng tín hiệu tác vụ cuối. Chi tiết huấn luyện thêm có thể tìm thấy trong Phụ lục A.2.

3.1 NÉN TRÍCH XUẤT

Vì chúng tôi công thức hóa nén trích xuất như một bài toán xếp hạng, việc huấn luyện bộ nén trích xuất giống với việc huấn luyện một bộ xếp hạng lại cho các tài liệu truy xuất4 với hai điểm khác biệt. Đầu tiên, bộ nén của chúng tôi xem xét một độ chi tiết đầu vào khác (câu) so với đơn vị truy xuất ban đầu (đoạn văn). Thứ hai, câu được đánh giá dựa trên việc liệu nó có hữu ích làm đầu vào cho LM M trên tác vụ downstream hay không (Shi et al., 2023b; Ram et al., 2023).

Đầu vào: LM cơ sở M, Bộ nén encθ, Dữ liệu huấn luyện {xi,Si,yi}T1 với xi là đầu vào, Si={sj}n1 là tập các câu ứng viên từ tài liệu truy xuất cho xi, yi là câu trả lời đích, và ngưỡng điểm ε.
Đầu ra: Một bộ nén trích xuất encoder đã cập nhật encθ

1:T ← ∅
2:for i ∈ {1, . . . , T} do
3:pi ← argMaxsj∈{Si}Score(M,yi,[sj;xi])
4: for j ∈ {1, . . . , n} do
5: L ← ∅
6: if Score(M,yi,[sj;xi]) + ε < Score(M,yi,[pi;xi]) then
7: L ← L ∪ si
8: if |L| > 0 then
9: Ni ← argTop5 sj∈L(⟨encθ(sj),encθ(xi)⟩)
10: T ← T ∪ {(xi,pi,Ni)}
11:encθ = Finetune(encθ,T)

Hình 2: Học một bộ nén trích xuất cho tác vụ mô hình hóa ngôn ngữ.

Mô hình Chúng tôi huấn luyện một mô hình mã hóa kép encθ mã hóa ngữ cảnh đầu vào x và câu ứng viên si riêng biệt. Chúng tôi có được embedding của x và si bằng cách lấy biểu diễn của token [CLS] tương ứng, và tính toán độ tương tự của chúng bằng cách tính tích vô hướng của hai embedding. Chúng tôi khởi tạo mô hình của mình với checkpoint contriever (Izacard et al., 2021). Mô hình này có 110M tham số, thỏa mãn yêu cầu hiệu quả của bộ nén.

Huấn luyện Hình 2 trình bày mã giả cho việc huấn luyện bộ nén trích xuất với loss đối lập cho tác vụ mô hình hóa ngôn ngữ. Đối với mỗi truy vấn đầu vào xi, chúng tôi xác định các câu tích cực và tiêu cực từ tài liệu truy xuất.

Đối với mỗi cặp chuỗi đầu vào xi và câu ứng viên sj, chúng tôi đo

3Các công việc gần đây (Zhang et al., 2022) cho thấy rằng phương pháp trích xuất không phải lúc nào cũng bảo tồn tính trung thực, nhưng những trường hợp như vậy vẫn hiếm so với các phương pháp tóm tắt có thể dễ dàng ảo giác.

4Ram et al. (2023) đề xuất một bộ xếp hạng lại tài liệu dựa trên mô hình cross-encoder, tương tự như bộ chọn câu của chúng tôi, nhưng ít hiệu quả về mặt tính toán hơn.

--- TRANG 4 ---
Score(M,yi,[sj;xi]) = log pM(y|[sj;xi]), log likelihood được gán cho đầu ra đích theo LM M khi câu ứng viên được thêm vào đầu vào. Chúng tôi coi câu có log likelihood cao nhất là ví dụ tích cực pi (dòng 3). Để xây dựng các ví dụ tiêu cực Ni={nk}5k=1, chúng tôi chọn tối đa năm câu có điểm contriever cao nhất có log likelihood thấp hơn câu tích cực cho một ngưỡng (dòng 6).

Huấn luyện bộ nén cho tác vụ QA hoạt động tương tự, nhưng việc chấm điểm sẽ đánh giá xem LM có tạo ra câu trả lời đúng với tóm tắt được thêm vào hay không (thay đổi ở dòng 6). Mã giả cho các tác vụ QA có trong Hình 6 ở Phụ lục. Chúng tôi huấn luyện encoder của mình với loss đối lập (Karpukhin et al., 2020a), tối đa hóa độ tương tự giữa các cặp tích cực (xi, pi) và tối thiểu hóa các cặp tiêu cực (xi, Ni). Mục tiêu huấn luyện là tối thiểu hóa −log esim(xi,pi)/(esim(xi,pi)+∑nj∈Ni esim(xi,nj)).

Dữ liệu Đối với tác vụ mô hình hóa ngôn ngữ, chúng tôi tạo dữ liệu huấn luyện sử dụng split huấn luyện của bộ dữ liệu Wikitext-103, chọn 20 câu hàng đầu từ 5 tài liệu BM25 truy xuất hàng đầu cho mỗi ngữ cảnh đầu vào x. Đối với các tác vụ QA, chúng tôi tạo dữ liệu huấn luyện sử dụng split huấn luyện và xem xét 20 câu hàng đầu từ 5 tài liệu contriever-ms-marco5 truy xuất hàng đầu. Chúng tôi báo cáo thống kê chi tiết cho dữ liệu huấn luyện trong Bảng 5 ở phụ lục. Đối với mỗi câu từ tài liệu truy xuất, chúng tôi thêm tiêu đề trang Wikipedia vào đầu để khử ngữ cảnh hóa.

3.2 NÉN TÓM TẮT

Để huấn luyện bộ nén tóm tắt, chúng tôi chưng cất khả năng tóm tắt tập trung truy vấn của LM quy mô cực lớn bằng cách tạo bộ dữ liệu huấn luyện từ nó, lọc dữ liệu được tạo, và huấn luyện mô hình mã hóa-giải mã từ bộ dữ liệu đã lọc (West et al., 2022). Trái ngược với công việc trước đây (Jung et al., 2023) sử dụng metric tóm tắt nội tại để lọc, chúng tôi sử dụng hiệu suất của LM trên tác vụ cuối với các tóm tắt được tạo ra được thêm vào để lọc. Hình 3 trình bày thuật toán giả cho việc huấn luyện bộ nén tóm tắt.

3.2.1 TẠO BỘ DỮ LIỆU HUẤN LUYỆN CHO CHƯNG CẤT

Đầu vào: LM giáo viên Mt, LM M, Tập prompt tóm tắt {pi}n1, Bộ nén encdecθ, Dữ liệu huấn luyện {xi,Di,yi}T1 với xi là đầu vào, Di là tập tài liệu truy xuất cho xi, yi là câu trả lời đích.
Đầu ra: Một encdecθ đã cập nhật

1:T ← ∅
2:for i ∈ {1, . . . , T} do
3: vr ← −∞
4: for j ∈ {1, . . . , n} do
5: sj = Decode(Mt,[pj;xi;Di])
6: vj = Score(M,yi,[sj;xi])
7: if vj > vr then
8: st ← sj, vr ← vj
9: vd = Score(M,yi,[xi])
10: if vr < vd then
11: T ← T ∪ {(xi,Di,∅)}
12: break
13: T ← T ∪ {(xi,Di,st)}
14:encdecθ = Finetune(encdecθ, T)

Hình 3: Học một bộ nén tóm tắt cho tác vụ mô hình hóa ngôn ngữ.

Tạo từ Mô hình Giáo viên Đối với tác vụ mô hình hóa ngôn ngữ, chúng tôi xây dựng thủ công bốn prompt để tóm tắt tập tài liệu bằng chứng ({pi}n1).6 Cho một đầu vào xi, một tập tài liệu truy xuất Di, và một prompt pj để tóm tắt tập tài liệu liên quan đến đầu vào, GPT-3.57 tạo ra một tóm tắt (dòng 3).

Lọc với Người Phê Bình Sau khi tạo tóm tắt cho mỗi template prompt, chúng tôi chọn tóm tắt dẫn đến hiệu suất tác vụ cuối cao nhất cho mỗi ví dụ (st) làm tóm tắt đích (dòng 4-8). Score(M,yi,[sj;xi]) giống như bộ nén trích xuất ở trên. Sau đó chúng tôi so sánh hiệu suất tác vụ cuối với tóm tắt đích được thêm vào và chỉ với đầu vào xi (tức là không truy xuất) trên mô hình cơ sở M (dòng 6). Nếu hiệu suất tác vụ cuối trở nên tệ hơn (ví dụ, tăng perplexity) khi thêm tóm tắt, chúng tôi đặt tóm tắt đích thành chuỗi rỗng (dòng 7), nếu không chúng tôi thêm tóm tắt đích vào tập huấn luyện (dòng 9). Điều này cho phép tăng cường chọn lọc và giảm thiểu rủi ro thêm các tài liệu không liên quan.

5https://huggingface.co/facebook/contriever-msmarco
6Các prompt chính xác có thể tìm thấy trong Bảng 6 ở A.2.
7Chúng tôi sử dụng gpt-3.5-turbo trong tất cả các thí nghiệm của mình.

--- TRANG 5 ---
Xây dựng bộ dữ liệu huấn luyện cho các tác vụ trả lời câu hỏi hoạt động tương tự, với các sửa đổi sau. Vì tóm tắt cho tác vụ trả lời câu hỏi đơn giản hơn, chúng tôi sử dụng một prompt duy nhất cho mỗi bộ dữ liệu. Chúng tôi lọc bỏ các ví dụ mà việc thêm tóm tắt không dẫn đến cải thiện hiệu suất. Mã giả cho các tác vụ QA có trong Hình 7 ở Phụ lục.

Mô hình & Huấn luyện Chúng tôi sử dụng LM mã hóa-giải mã (775M), được khởi tạo từ checkpoint T5-large (Raffel et al., 2020). Mô hình này đã được huấn luyện với các bộ dữ liệu tóm tắt (Hermann et al., 2015).

Dữ liệu Chúng tôi tóm tắt 5 tài liệu truy xuất hàng đầu cho cả tác vụ mô hình hóa ngôn ngữ và trả lời câu hỏi. Chúng tôi tạo các ví dụ huấn luyện sử dụng 2% tập huấn luyện cho bộ dữ liệu Wikitext-103. Chúng tôi tạo các ví dụ huấn luyện từ toàn bộ tập huấn luyện NQ và TriviaQA. Đối với HotpotQA, chúng tôi chỉ tạo tóm tắt cho dữ liệu huấn luyện mà câu trả lời vàng có trong tài liệu truy xuất (56% dữ liệu huấn luyện) để giảm chi phí API. Chúng tôi báo cáo tỷ lệ phần trăm dữ liệu được lọc và tỷ lệ phần trăm tóm tắt rỗng trong Bảng 5 ở A.1.

4 CÀI ĐẶT THỰC NGHIỆM

Chúng tôi đánh giá phương pháp của mình trên mô hình hóa ngôn ngữ và QA miền mở theo các công việc trước đây (Shi et al., 2023b; Ram et al., 2023). Đối với cả hai tác vụ, chúng tôi báo cáo hiệu suất tác vụ như một thước đo hiệu lực và số lượng token được cung cấp trong ngữ cảnh như một thước đo hiệu quả.

4.1 MÔ HÌNH HÓA NGÔN NGỮ

Chúng tôi đánh giá perplexity mô hình hóa ngôn ngữ trên benchmark WikiText-103 (Merity et al., 2016) trên ba LM mã nguồn mở có quy mô khác nhau: GPT2 (117M), GPT2-XL (1.5B; Radford et al. (2019)) và GPT-J (6B; Wang & Komatsuzaki (2021)). Chúng tôi huấn luyện các bộ nén của mình sử dụng GPT2 làm mô hình cơ sở và đánh giá xem bộ nén được huấn luyện có chuyển giao sang GPT2-XL và GPT-J hay không. Chúng tôi sử dụng bộ truy xuất BM25 (Robertson & Zaragoza, 2009) để truy xuất từ corpus Wikipedia từ ngày 20 tháng 12 năm 2018 (Karpukhin et al., 2020a). Các bài viết sau đó được cắt ngắn thành các tài liệu không chồng lấp 100 từ. Trong quá trình truy xuất, các bài viết chứa chuỗi đầu vào x được loại bỏ khỏi corpus để ngăn chặn ô nhiễm dữ liệu. Theo Ram et al. (2023), chúng tôi thực hiện truy xuất mỗi 32 token.

4.2 QA MIỀN MỞ

Bộ dữ liệu Chúng tôi đánh giá mô hình của mình trên ba bộ dữ liệu benchmark: Natural Questions (NQ) (Kwiatkowski et al., 2019), TriviaQA (Joshi et al., 2017)) và HotpotQA (Yang et al., 2018). Chúng tôi báo cáo kết quả trên tập phát triển của NQ, tập kiểm tra của TriviaQA và 500 ví dụ được lấy mẫu ngẫu nhiên từ tập phát triển HotpotQA. Chúng tôi báo cáo Exact Match (EM) và F1 - F1 ở mức token của các chuỗi câu trả lời để đo hiệu suất tác vụ cuối.

Mô hình Ngôn ngữ Cơ sở & Corpus Truy xuất Chúng tôi sử dụng Flan-UL2 (20B)(Chung et al., 2022), một LM có hướng dẫn quy mô lớn. Chúng tôi sử dụng mô hình contriever được huấn luyện trên bộ dữ liệu MS MARCO (Campos et al., 2016) làm bộ truy xuất trên corpus Wikipedia từ ngày 20 tháng 12 năm 2018 cho cả ba bộ dữ liệu. Các bài viết được cắt ngắn thành các tài liệu không chồng lấp 100 từ.

Định dạng Prompt Chúng tôi bao gồm các ví dụ trong ngữ cảnh few-shot trong prompt, theo sau là các tài liệu truy xuất và câu hỏi. Chúng tôi sử dụng năm ví dụ huấn luyện được lấy mẫu ngẫu nhiên làm ví dụ trong ngữ cảnh, tạo thành trung bình 110, 147, và 149 token cho NQ, TQA và HotpotQA tương ứng. Đối với các tài liệu truy xuất, chúng tôi nối chúng theo thứ tự tăng dần của điểm truy xuất, với tài liệu có điểm cao nhất gần nhất với câu hỏi (Si et al., 2022). Chúng tôi không bao gồm các tài liệu truy xuất cho các ví dụ trong ngữ cảnh vì nó không cải thiện hiệu suất. Một ví dụ đầu vào có thể tìm thấy trong Bảng 7 ở Phụ lục.

4.3 BASELINE VÀ ORACLE

Baseline Đầu tiên chúng tôi xem xét hai phương pháp nén cấp token và cụm từ heuristic: BoW, chuyển đổi các tài liệu truy xuất thành danh sách unigram có thứ tự và nối chúng lại với nhau

--- TRANG 6 ---
Bảng 1: Kết quả trên tác vụ mô hình hóa ngôn ngữ. Chúng tôi báo cáo kết quả trên GPT-2, GPT2-XL và GPT-J với các bộ nén được huấn luyện với GPT-2.

[TABLE CONTENT WITH PERFORMANCE METRICS FOR DIFFERENT MODELS AND COMPRESSION METHODS]

và Named Entities (NE), trích xuất danh sách các thực thể được đặt tên có thứ tự từ tài liệu truy xuất và nối chúng lại. Đối với bộ nén trích xuất trên tác vụ mô hình hóa ngôn ngữ, chúng tôi sử dụng BM25 và Contriever Izacard et al. (2021), xếp hạng các câu theo độ tương tự của chúng với đầu vào x làm baseline. Đối với các bộ dữ liệu QA, chúng tôi báo cáo kết quả sử dụng BM25, Contriever được tinh chỉnh trên MS MARCO và DPR (Karpukhin et al., 2020b) được tinh chỉnh trên NQ. Chúng tôi cũng báo cáo một baseline Random chọn ngẫu nhiên một câu từ tài liệu truy xuất. Đối với nén tóm tắt, chúng tôi báo cáo hiệu suất của mô hình T5 có sẵn (large, 770M) và của mô hình GPT-3.5. Vì chúng tôi thử nghiệm với nhiều prompt cho tác vụ mô hình hóa ngôn ngữ, chúng tôi báo cáo hiệu suất của các tóm tắt được tạo bởi mô hình GPT-3.5 với prompt đơn tốt nhất.

Oracle Chúng tôi khám phá giới hạn trên hiệu suất của nén bằng cách xem xét hai phương pháp oracle. Đối với phương pháp trích xuất, chúng tôi xây dựng bộ nén oracle bằng cách xem xét tất cả câu si trong tập tài liệu bằng chứng và chọn câu dẫn đến hiệu suất tác vụ cuối tốt nhất (tức là perplexity thấp nhất hoặc độ chính xác câu trả lời cao nhất) cho mỗi ví dụ. Đối với phương pháp tóm tắt, chúng tôi xem xét các tóm tắt được tạo từ các prompt khác nhau ({sj}n1 trong Hình 3) và tóm tắt rỗng, và chọn cái dẫn đến hiệu suất tác vụ cuối tốt nhất. Vì nén oracle phụ thuộc vào mô hình, chúng tôi cũng báo cáo kết quả độc lập mô hình bằng cách luôn sử dụng GPT-2 làm LM tham chiếu (Oracle w/ gpt2) để kiểm tra mức độ chuyển giao của các câu oracle cho một mô hình sang các mô hình khác cho tác vụ mô hình hóa ngôn ngữ.

5 KẾT QUẢ

Mô hình hóa ngôn ngữ Bảng 1 báo cáo kết quả trên tác vụ mô hình hóa ngôn ngữ. Tất cả các phương pháp tăng cường truy xuất đều cải thiện perplexity so với cài đặt không truy xuất trên ba LM. Các phương pháp nén cấp token/cụm từ heuristic (BoW và NE) tệ hơn so với việc thêm toàn bộ tài liệu không nén, có thể do tính không trôi chảy của văn bản được thêm vào.

Cả hai cài đặt oracle đều cho thấy cải thiện đáng kể so với việc thêm toàn bộ tập tài liệu, chỉ với 6-13% token. Nhiều token hơn không phải lúc nào cũng tốt hơn: thêm 1 tài liệu hàng đầu vượt trội so với thêm 5 tài liệu hàng đầu. Điều này xác nhận rằng phương pháp truy xuất-và-thêm đơn giản có chỗ cải thiện đáng kể, vì việc thêm các tài liệu không liên quan có thể làm tổn hại hiệu suất.

--- TRANG 7 ---
Bảng 2: Kết quả QA miền mở với Flan-UL2 (20B) làm LM M. Chúng tôi báo cáo số lượng token được cung cấp làm tài liệu bằng chứng trong ngữ cảnh, loại trừ các ví dụ trong ngữ cảnh. Chúng tôi huấn luyện các bộ nén riêng biệt (một trích xuất, một tóm tắt) cho mỗi bộ dữ liệu. Bộ nén trích xuất chọn một câu cho NQ/TQA, và hai câu cho HotpotQA.

[TABLE CONTENT WITH QA RESULTS ACROSS DIFFERENT DATASETS AND METHODS]

Bộ nén trích xuất được huấn luyện của chúng tôi vượt trội đáng kể so với các baseline trích xuất khác (Contriever và BM25) trên cả ba LM, trong khi thêm ít token hơn một chút. So với việc thêm một tài liệu, chúng tôi đạt được tỷ lệ nén 25% với sự giảm hiệu suất tối thiểu. Bộ nén tóm tắt được huấn luyện của chúng tôi hoạt động tốt nhất trên toàn bộ, đạt được perplexity thấp nhất và tỷ lệ nén cao nhất. Bộ nén tóm tắt của chúng tôi đạt được tỷ lệ nén cao thông qua tăng cường chọn lọc, chỉ thêm tóm tắt cho 33% ví dụ (phân phối độ dài của các tóm tắt được tạo trong Hình 8).

QA miền mở Chúng tôi báo cáo kết quả trên các tác vụ QA trong Bảng 2. Tương tự như tác vụ mô hình hóa ngôn ngữ, tất cả các phương pháp tăng cường truy xuất đều cải thiện hiệu suất so với cài đặt không truy xuất, trên ba bộ dữ liệu, phù hợp với nghiên cứu trước đây trên các LM khác (Shi et al., 2023b; Mallen et al., 2022; Si et al., 2022). Không giống như mô hình hóa ngôn ngữ, việc thêm năm tài liệu cho thấy cải thiện đáng kể so với việc thêm một tài liệu duy nhất, tạo động lực cho việc sử dụng nén để kết hợp nhiều tài liệu hơn.

Chúng tôi thấy rằng oracle trích xuất vượt trội so với oracle tóm tắt trong tất cả bộ dữ liệu. Oracle trích xuất chọn tốt nhất từ N câu ứng viên, trong khi oracle tóm tắt chọn từ hai tùy chọn - thêm tóm tắt GPT-3.5 hoặc không thêm gì. Cả hai oracle đều cho thấy cải thiện so với việc thêm tất cả thông tin, cho thấy rằng việc loại bỏ thông tin không liên quan có lợi cho mô hình.8

Trong số các baseline trích xuất, DPR hoạt động tốt nhất vì nó đã được tinh chỉnh trên dữ liệu NQ chất lượng cao. Trên NQ, việc chọn 1 câu được xếp hạng DPR hàng đầu từ 5 tài liệu hàng đầu vượt trội so với việc thêm 1 tài liệu hàng đầu, với ít token hơn nhiều (39 so với 132). Tuy nhiên, hiệu suất của nó giảm trong các bộ dữ liệu ngoài miền. Mô hình tóm tắt có sẵn (T5) có tỷ lệ nén cao nhất, đạt được cải thiện 4-6 điểm EM trong khi chỉ thêm 7-10 token.

Các bộ nén được huấn luyện, cả trích xuất và tóm tắt, đều cho thấy hiệu suất hứa hẹn. Trên NQ và TQA, phương pháp tóm tắt hiệu quả hơn. Trên NQ, nó đạt được tỷ lệ nén 5% token trong khi mất 2 điểm EM so với việc thêm toàn bộ tài liệu. Trên TQA, chúng tôi quan sát các xu hướng tương tự, tỷ lệ nén 5% token trong khi mất 3.7 điểm EM so với việc thêm toàn bộ tập tài liệu. Trên HotpotQA đòi hỏi hiểu biết đa bước về tài liệu, chúng tôi thấy phương pháp trích xuất hữu ích hơn, đạt được tỷ lệ nén 11% trong khi mất 2.4 điểm EM so với việc thêm toàn bộ tài liệu. Chúng tôi thấy rằng việc học bộ nén tóm tắt cho các tác vụ phức tạp hơn, như HotpotQA, đòi hỏi nghiên cứu thêm. Trong khi LLM quy mô cực lớn có hiệu suất tóm tắt cạnh tranh trong cài đặt tài liệu đơn, chúng không giỏi trong việc tổng hợp thông tin từ nhiều tài liệu (Shaib et al. (2023) và ảo giác nhiều hơn; Xem Phần 6 để phân tích thêm).

8Chúng tôi cung cấp một ví dụ mà tóm tắt nén của chúng tôi cho câu trả lời đúng trong khi thêm toàn bộ tài liệu thì không trong Bảng 9 ở phụ lục.

--- TRANG 8 ---
thấy phương pháp trích xuất hữu ích hơn, đạt được tỷ lệ nén 11% trong khi mất 2.4 điểm EM so với việc thêm toàn bộ tài liệu. Chúng tôi thấy rằng việc học bộ nén tóm tắt cho các tác vụ phức tạp hơn, như HotpotQA, đòi hỏi nghiên cứu thêm. Trong khi LLM quy mô cực lớn có hiệu suất tóm tắt cạnh tranh trong cài đặt tài liệu đơn, chúng không giỏi trong việc tổng hợp thông tin từ nhiều tài liệu (Shaib et al. (2023)) và ảo giác nhiều hơn; Xem Phần 6 để phân tích thêm.

6 PHÂN TÍCH VÀ THẢO LUẬN

Chuyển giao qua các LM khác nhau Một lợi ích của tóm tắt văn bản là chúng có thể chuyển giao sang các LM khác, không giống như các phương pháp như soft prompt (Wingate et al., 2022; Chevalier et al., 2023; Mu et al., 2023). Chúng tôi đánh giá xem các bộ nén của chúng tôi được huấn luyện để đạt hiệu suất cao liên quan đến một LM cụ thể (GPT2 cho mô hình hóa ngôn ngữ, FlanUL2 cho QA miền mở) có thể chuyển giao sang các LM khác hay không. Đối với mô hình hóa ngôn ngữ, chúng tôi thấy rằng bộ nén được huấn luyện chuyển giao tốt sang các LM khác (GPT2-XL và GPT-J), mặc dù chúng là những LM lớn hơn nhiều (Bảng 1). Đối với QA miền mở, chúng tôi đã kiểm tra việc chuyển giao các bộ nén của mình sang mô hình LLaMA-13B (Touvron et al., 2023). Kết quả có thể tìm thấy trong Bảng 10 ở phụ lục. Nhìn chung, hiệu suất tệ hơn so với LM mà các bộ nén được huấn luyện trên đó, đôi khi không thể vượt trội so với các baseline nén khác (ví dụ, không có cải thiện rõ ràng từ việc sử dụng contriever so với contriever được huấn luyện của chúng tôi trên TQA/HotpotQA), để lại khoảng cách đáng kể với các nén oracle cho chính LLAMA. Tuy nhiên, trên NQ/TQA, bộ nén của chúng tôi đạt được tỷ lệ nén 5% với ít hơn 5 điểm EM giảm so với cài đặt tài liệu đầy đủ, cho thấy tính mạnh mẽ của paradigm truy xuất-nén-thêm của chúng tôi.

Hình 4: Biểu đồ phân phối độ dài tóm tắt tóm tắt (# token).

Độ dài của các tóm tắt thay đổi như thế nào? Bộ nén được học có thể xác định một cách đáng tin cậy khi nào LM cần tài liệu truy xuất hay không? Vì các tài liệu truy xuất đang làm tổn hại hiệu suất mô hình cho một số truy vấn đầu vào, 4-24% ví dụ huấn luyện cho các bộ nén tóm tắt chứa tóm tắt rỗng. Hình 4 trình bày phân phối độ dài của các tóm tắt tóm tắt trên NQ và Wikitext (biểu đồ cho các bộ dữ liệu khác trong Hình 8 ở phụ lục). Độ dài tài liệu đầu vào không thay đổi đáng kể giữa các ví dụ, nhưng chúng tôi thấy các tóm tắt tóm tắt thay đổi đáng kể về độ dài, cho thấy bộ nén tóm tắt cho phép tăng cường truy xuất chọn lọc. Chúng tôi chưa thử nghiệm nén chọn lọc với bộ nén trích xuất, cố định số lượng câu được thêm vào cho toàn bộ bộ dữ liệu (1 cho Wikitext, 1 cho NQ/TQA, 2 cho HotpotQA). Cho phép tăng cường thích ứng với bộ tóm tắt trích xuất có thể là một hướng đầy hứa hẹn cho công việc tương lai.

Bảng 3: Phân tích về bằng chứng trong ngữ cảnh để trả lời câu hỏi trong tập phát triển NQ. Đối với cột cuối, chúng tôi báo cáo tần suất mô hình sao chép từ bằng chứng của nó trên (1) một tập con mà câu trả lời vàng có trong tài liệu bằng chứng / (2) khi nó không có.

[TABLE CONTENT SHOWING EVIDENCE ANALYSIS]

Mô hình tận dụng các tài liệu trong ngữ cảnh như thế nào? Chúng tôi đánh giá xem các LM tăng cường truy xuất có xu hướng sao chép câu trả lời nguyên văn từ tài liệu bằng chứng trong ngữ cảnh hay tạo ra câu trả lời không có trong tài liệu. Đây là hành vi mong muốn chỉ khi câu trả lời vàng có trong bằng chứng. Đầu tiên chúng tôi báo cáo tần suất một span câu trả lời vàng có trong văn bản bằng chứng (% Gold in Evi). Như mong đợi, tài liệu đầy đủ chứa câu trả lời thường xuyên nhất, theo sau là NE và GPT-3. Tuy nhiên, việc có nhiều câu trả lời vàng hơn trong bằng chứng không đồng nghĩa với hiệu suất tốt hơn, vì mô hình không thể luôn xác định câu trả lời đúng từ bằng chứng (84% cho NE so với 98% cho T5(ours)).

Chúng tôi cũng quan sát rằng mô hình có thể dễ dàng bị phân tâm bởi ngữ cảnh không liên quan, sao chép từ một span tài liệu ngay cả khi nó không chứa câu trả lời vàng, phản ánh các phát hiện từ công việc trước đây (Shi et al., 2023a). Việc thêm 5 tài liệu hàng đầu có tần suất sao chép sai cao hơn (81%) so với 1 tài liệu hàng đầu (51%), và nén GPT-3 dẫn đến tần suất sao chép sai thậm chí cao hơn (85%), có thể là do tóm tắt tập trung truy vấn tạo ra các câu dường như chứa câu trả lời. Bộ nén của chúng tôi thành công giảm hành vi sai lầm như vậy xuống 39%.

Tóm tắt được tạo có trung thực và toàn diện không? Chúng tôi (các tác giả) đánh giá thủ công đầu ra của các bộ nén tóm tắt trên hai trục (Chen et al., 2023): Tính trung thực: liệu tóm tắt có thể được suy ra từ các tài liệu truy xuất hay không, Tính toàn diện: liệu tóm tắt có chứa đủ thông tin để trả lời câu hỏi hay không, bất kể thông tin được tạo có đến từ tài liệu truy xuất hay không. Đối với cả hai, chúng tôi chọn một trong ba nhãn: Yes, Partially, No, và báo cáo % tóm tắt Hữu ích vừa trung thực vừa toàn diện. Mẫu chú thích có thể tìm thấy trong Bảng 11 ở phụ lục. Chúng tôi đánh giá các tóm tắt được tạo bởi GPT-3.5 và bộ nén tóm tắt của chúng tôi. Chúng tôi lấy mẫu ngẫu nhiên 30 tóm tắt không rỗng từ tập kiểm tra.

Bảng 4: Phân tích thủ công về các tóm tắt tóm tắt được tạo cho bộ dữ liệu NQ, TQA và HotpotQA (HQA).

[TABLE CONTENT WITH MANUAL ANALYSIS OF SUMMARIES]

Bảng 4 trình bày kết quả chú thích. GPT-3.5, lớn hơn đáng kể so với bộ nén của chúng tôi, tạo ra tóm tắt hữu ích hơn trên cả ba bộ dữ liệu. Nhìn chung, các bộ nén tóm tắt của chúng tôi ít trung thực hơn so với GPT-3.5 gốc, trong khi cải thiện tính toàn diện. Hiệu quả của tóm tắt cũng phụ thuộc vào các bộ dữ liệu - các tóm tắt từ cả hai mô hình đều trung thực nhất đối với TQA và ít trung thực nhất đối với bộ dữ liệu HotpotQA. Về mặt toàn diện, chúng tôi thấy cả hai mô hình dễ dàng tìm thấy thông tin cho NQ, nhưng gặp khó khăn với HotpotQA. Những kết quả này một phần giải thích tại sao cải thiện hiệu suất bị hạn chế đối với HotpotQA.

7 CÔNG VIỆC LIÊN QUAN

RALM hiệu quả He et al. (2021) cải thiện hiệu quả của RALM bằng cách cải thiện các thành phần truy xuất, như nén kho dữ liệu, giảm chiều cho bộ truy xuất neural. Một dòng công việc cũng giới thiệu việc giảm tần suất truy xuất thông qua truy xuất chọn lọc (He et al., 2021; Mallen et al., 2022) hoặc sử dụng bước nhảy lớn hơn (Martins et al., 2022). Trong công việc này, chúng tôi cải thiện hiệu quả của RALM bằng cách nén các tài liệu truy xuất thành tóm tắt ngắn gọn hoặc chuỗi rỗng, tạo điều kiện cho tăng cường truy xuất chọn lọc.

Nén Prompt Các công việc gần đây (Wingate et al., 2022; Chevalier et al., 2023; Mu et al., 2023) đề xuất nén ngữ cảnh dài thành các vector tóm tắt (soft prompt) có thể được sử dụng bởi LM, thay vì các tóm tắt văn bản ngắn hơn. Những soft prompt như vậy có thể phục vụ như những thay thế hiệu quả cho các minh chứng văn bản thuần túy, tối thiểu hóa chi phí tính toán trong quá trình suy luận. Một dòng công việc liên quan khác đề xuất chưng cất ngữ cảnh (Snell et al., 2022; Choi et al., 2022; Padmanabhan et al., 2023), tiêm ngữ cảnh được thêm vào các tham số của LM. So với các phương pháp trên, phương pháp của chúng tôi mang lại tóm tắt văn bản có thể diễn giải hơn có thể chuyển giao qua các LM khác nhau, và có thể được áp dụng cho các LM hộp đen mà không cần cập nhật gradient. Công việc trước đây đã nghiên cứu nén văn bản cho các tác vụ khác, như kiểm tra sự thật chính trị (Chen et al., 2023) và học hướng dẫn (Yin et al., 2023).

Chưng cất / Tóm tắt hướng mục tiêu Các công việc gần đây giới thiệu chưng cất kiến thức tượng trưng (West et al., 2022), chuyển giao kiến thức từ mô hình giáo viên bằng cách tạo bộ dữ liệu huấn luyện với mô hình giáo viên và huấn luyện mô hình học sinh trên đó. Để có hiệu suất tốt hơn, họ giới thiệu tiêu chí phê bình, lọc các ví dụ không mong muốn từ bộ dữ liệu huấn luyện được tạo. Kỹ thuật chưng cất như vậy đã được áp dụng cho nhiều ứng dụng khác nhau bao gồm tóm tắt (Jung et al., 2023), nhằm mục đích tạo ra các tóm tắt chất lượng cao trong khi chúng tôi tối ưu hóa để tạo ra tóm tắt hiệu quả cho các LM downstream. Một công việc tương tự với cài đặt của chúng tôi là Hsu & Tan (2021) huấn luyện mô hình tóm tắt trích xuất để tối ưu hóa độ chính xác dự đoán của mô hình dự đoán cảm xúc dựa trên tóm tắt.

--- TRANG 9 ---
8 KẾT LUẬN

Chúng tôi giới thiệu RECOMP, một phương pháp nén các tài liệu truy xuất thành tóm tắt văn bản trước khi thêm chúng để cải thiện các mô hình ngôn ngữ tăng cường truy xuất trong ngữ cảnh. Chúng tôi trình bày hai mô hình nén - một bộ nén trích xuất và một bộ nén tóm tắt. Chúng tôi thiết kế một sơ đồ huấn luyện tận dụng tín hiệu tác vụ cuối từ LM hộp đen để tạo ra các tóm tắt hữu ích và cho phép các mô hình nén thực hiện tăng cường chọn lọc. Các thí nghiệm của chúng tôi cho thấy rằng các bộ nén của chúng tôi có thể cải thiện hiệu quả của các LM tăng cường truy xuất một cách đáng kể với sự giảm hiệu suất tối thiểu.

LỜI CẢM ƠN

Chúng tôi cảm ơn các thành viên của cộng đồng NLP UT và UW về phản hồi về dự án. Chúng tôi đặc biệt cảm ơn Alisa Liu, Junyi Jessy Li và Greg Durrett vì đã cung cấp nhận xét về bản thảo. Dự án được tài trợ một phần bởi tài trợ NSF (IIS-2312948).

TUYÊN BỐ ĐẠO ĐỨC

Chúng tôi sử dụng mô hình ngôn ngữ thương mại để tạo dữ liệu huấn luyện cho các bộ nén của mình, có thể bao gồm lỗi thực tế. Chúng tôi tiến hành đánh giá thủ công cẩn thận về dữ liệu được tạo và trình bày phân tích của mình trong bài báo.

TUYÊN BỐ TÁI SẢN XUẤT

Chúng tôi công bố mã, prompt và dữ liệu được tạo với quyền truy cập API công khai.

TÀI LIỆU THAM KHẢO

[Tài liệu tham khảo tiếp tục với các trích dẫn học thuật...]

--- TRANG 10 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 11 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 12 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 13 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 14 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 15 ---
Hình 5: Chúng tôi báo cáo phân phối dữ liệu trên tập phát triển NQ, tập phát triển TriviaQA và tập phát triển HotpotQA so sánh hiệu suất tác vụ cuối khi thêm phương pháp nén oracle (câu oracle hoặc tóm tắt GPT-3) và khi không thêm gì cho mô hình cơ sở (Flan-UL2).

A PHỤ LỤC

A.1 TẠO DỮ LIỆU HUẤN LUYỆN BỘ NÉN

Chúng tôi báo cáo thống kê của dữ liệu được sử dụng để huấn luyện các bộ nén trong Bảng 5. Chúng tôi sử dụng SpaCy (Honnibal et al., 2020) để trích xuất các thực thể được đặt tên.

Tạo dữ liệu trích xuất Chúng tôi tạo dữ liệu sử dụng dữ liệu huấn luyện cho bốn bộ dữ liệu chúng tôi đã kiểm tra (Wikitext, NQ, TQA và HotpotQA). Chúng tôi sử dụng gói NLTK để thực hiện phân tách câu. Chúng tôi loại bỏ các ví dụ không có negative nào.

Tạo dữ liệu tóm tắt Chúng tôi báo cáo prompt được sử dụng để tạo tóm tắt trong Bảng 8. Chúng tôi truy vấn API Open AI với nhiệt độ 0.7 và top p = 1. Đối với tác vụ mô hình hóa ngôn ngữ, chúng tôi sử dụng ensemble bốn prompt và chọn cái dẫn đến perplexity thấp nhất làm mục tiêu. Nếu không có tóm tắt nào dẫn đến giảm perplexity, chúng tôi coi tóm tắt rỗng là mục tiêu. Chúng tôi truy vấn API OpenAI với nhiệt độ 0.7 và top p = 1. Chúng tôi tạo bốn tóm tắt cho mỗi ví dụ cho 2% dữ liệu huấn luyện được lấy mẫu ngẫu nhiên (48,013 ví dụ).

A.2 CHI TIẾT HUẤN LUYỆN BỘ NÉN

Bộ nén trích xuất Đối với mô hình hóa ngôn ngữ, chúng tôi sử dụng checkpoint contriever9 được huấn luyện với dữ liệu không giám sát. Đối với các tác vụ QA, chúng tôi sử dụng checkpoint contriever được tinh chỉnh trên tác vụ MSMARCO (Campos et al., 2016)10, theo công việc trước đây (Si et al., 2022; Shi et al., 2023b). Chúng tôi triển khai mô hình sử dụng Transformers (Wolf et al., 2019) và thư viện sentence-transformer (Reimers & Gurevych, 2019). Chúng tôi huấn luyện với optimizer Adam (Kingma & Ba, 2014), sử dụng batch size 64, learning rate 2e-5 và 1000 bước warmup cho 3 epoch. Chúng tôi báo cáo kết quả trên mô hình với perplexity được xếp hạng lại tốt nhất trên tập validation của chúng tôi cho tác vụ mô hình hóa ngôn ngữ và độ chính xác được xếp hạng lại tốt nhất cho các tác vụ QA.

9https://huggingface.co/facebook/contriever
10https://huggingface.co/facebook/contriever-msmarco

--- TRANG 16 ---
[Các hình và thuật toán tiếp tục với mã giả cho việc học bộ nén trích xuất và tóm tắt cho các tác vụ QA]

--- TRANG 17 ---
[Bảng thống kê dữ liệu huấn luyện và biểu đồ phân phối độ dài tóm tắt]

Bộ nén tóm tắt Chúng tôi triển khai mô hình sử dụng Transformers (Wolf et al., 2019). Chúng tôi huấn luyện bộ tóm tắt tóm tắt với optimizer Adam (Kingma & Ba, 2014), sử dụng batch size 16, learning rate 1e-5 và 1000 bước warmup cho 3 epoch.

--- TRANG 18 ---
[Bảng ví dụ về nén trích xuất và tóm tắt trên các bộ dữ liệu khác nhau, bao gồm ví dụ đầu vào và prompt format]

--- TRANG 19 ---
[Bảng prompt được sử dụng để tạo tóm tắt từ GPT-3.5-turbo cho các bộ dữ liệu khác nhau]

--- TRANG 20 ---
[Bảng nghiên cứu trường hợp về cách nén tài liệu truy xuất giúp mô hình xác định câu trả lời đúng]

--- TRANG 21 ---
[Bảng kết quả QA miền mở trên LLaMA-13B với so sánh các phương pháp nén oracle khác nhau]

--- TRANG 22 ---
[Bảng ví dụ tóm tắt và nhãn phân tích thủ công của chúng]

--- TRANG 23 ---
[Tiếp tục bảng ví dụ tóm tắt và nhãn phân tích thủ công]

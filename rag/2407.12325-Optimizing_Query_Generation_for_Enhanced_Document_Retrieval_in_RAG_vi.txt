# 2407.12325.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2407.12325.pdf
# Kích thước tệp: 445329 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Tối ưu hóa Sinh truy vấn để Tăng cường Truy xuất Tài liệu trong RAG
Hamin Koo*
Độc lập
hamin2065@google.comMinseon Kim
KAIST
minseonkim@kaist.ac.krSung Ju Hwang
KAIST, DeepAuto.ai
sjhwang82@kaist.ac.kr
Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLM) xuất sắc trong nhiều
nhiệm vụ ngôn ngữ khác nhau nhưng chúng thường tạo ra thông
tin không chính xác, một hiện tượng được gọi là
"ảo giác". Sinh tăng cường Truy xuất
(RAG) nhằm giảm thiểu điều này bằng cách sử dụng
truy xuất tài liệu cho các phản hồi chính xác. Tuy nhiên,
RAG vẫn gặp phải ảo giác do các truy vấn mơ hồ. Nghiên cứu này nhằm cải thiện RAG
bằng cách tối ưu hóa sinh truy vấn với điểm
căn chỉnh truy vấn-tài liệu, tinh chỉnh truy vấn sử
dụng LLM để có độ chính xác và hiệu quả tốt hơn trong
truy xuất tài liệu. Các thí nghiệm đã cho thấy
rằng phương pháp của chúng tôi cải thiện truy xuất tài liệu,
dẫn đến mức tăng độ chính xác trung bình 1,6%.
1 Giới thiệu
Mặc dù các Mô hình Ngôn ngữ Lớn (LLM) thể hiện
hiệu suất đáng ngạc nhiên trong các nhiệm vụ ngôn ngữ đa dạng,
ảo giác trong LLM đã trở thành một vấn
đề ngày càng quan trọng. Ảo giác xảy ra
khi LLM tạo ra thông tin không chính xác hoặc gây hiểu lầm
, điều này có thể làm suy yếu đáng kể
độ tin cậy và tính hữu ích của chúng. Một cách tiếp cận để giảm thiểu
vấn đề này là Sinh tăng cường Truy xuất
(RAG) (Lewis et al., 2021), tận dụng
truy xuất tài liệu để cung cấp câu trả lời chính xác hơn cho
truy vấn của người dùng bằng cách căn cứ các phản hồi được tạo
trên thông tin thực tế từ các tài liệu được truy xuất.
Tuy nhiên, một hệ thống RAG không hoàn chỉnh thường gây ra
ảo giác do các truy vấn mơ hồ không thể
nắm bắt chính xác ý định của người dùng (Zhang et al.,
2023), làm nổi bật một hạn chế đáng kể của RAG
trong LLM (Niu et al., 2024; Wu et al., 2024).
Hiệu suất của RAG phụ thuộc nhiều vào tính rõ ràng
của các truy vấn, với các truy vấn ngắn hoặc mơ hồ ảnh hưởng tiêu cực đến kết quả tìm kiếm (Jagerman et al.,
2023). Các nghiên cứu gần đây (Wang et al., 2023; Jagerman et al., 2023) đã chứng minh rằng việc mở rộng truy vấn
*Công việc này được thực hiện khi tác giả thực tập tại
KAIST MLAI.
Truy vấn Gốc++Truy vấn Gốc++Top-3 truy vấn
được viết lại&ĐiểmMô hình
TruyxuấtLLM như Bộ tối ưu hóa
Bộ sưu tập Tài liệu
Top-k tài liệu&Điểm Mô hình
Truy vấn được viết lại
Thùng Truy vấn
Hình 1: Hình khái niệm về QOQA. Với truy vấn mở rộng
với top-k tài liệu, chúng tôi thêm top-3 truy vấn được viết lại và điểm vào
LLM. Chúng tôi tối ưu hóa truy vấn dựa trên điểm và tạo
truy vấn được viết lại.
mở rộng sử dụng LLM có thể tăng cường việc truy xuất
các tài liệu liên quan. Phản hồi Giả định Liên quan
(PRF) (Lavrenko and Croft, 2001; Lv and Zhai, 2009) tiếp tục tinh chỉnh kết quả tìm kiếm bằng cách tự động sửa đổi truy vấn ban đầu dựa trên
các tài liệu xếp hạng cao nhất, mà không yêu cầu đầu vào rõ ràng từ người dùng. Bằng cách giả định rằng các kết quả hàng đầu là liên quan, PRF tăng cường truy vấn, từ đó cải thiện
độ chính xác của các lần truy xuất tiếp theo.
Để giải quyết vấn đề này, mục tiêu của chúng tôi là tạo ra các
truy vấn cụ thể và chính xác cho việc truy xuất tài liệu trong
các hệ thống RAG bằng cách tối ưu hóa truy vấn. Chúng tôi đề xuất Tối ưu hóa Truy vấn sử dụng Mở rộng Truy vấn
(QOQA) cho truy vấn chính xác cho các hệ thống RAG. Chúng tôi
sử dụng điểm căn chỉnh truy vấn-tài liệu trung bình top-k để tinh chỉnh truy vấn sử dụng LLM. Cách tiếp cận này
hiệu quả về mặt tính toán và cải thiện
độ chính xác của việc truy xuất tài liệu, từ đó giảm
ảo giác. Trong các thí nghiệm của chúng tôi, chúng tôi chứng minh rằng cách tiếp cận của chúng tôi cho phép trích xuất
các tài liệu chính xác với mức tăng trung bình 1,6%.
2 Các Công trình Liên quan
Ảo giác trong RAG Mặc dù có dữ liệu huấn luyện rộng lớn
của các mô hình ngôn ngữ lớn (LLM), vấn đề
1arXiv:2407.12325v1  [cs.IR]  17 Jul 2024

--- TRANG 2 ---
ảo giác của LLM tiếp tục làm suy yếu
niềm tin của người dùng. Trong số các chiến lược để giảm thiểu, phương pháp
Sinh tăng cường Truy xuất (RAG)
đã được chứng minh là hiệu quả trong việc giảm ảo giác, tăng cường độ tin cậy và tính nhất quán thực tế của
đầu ra LLM, từ đó đảm bảo độ chính xác và liên quan
trong phản hồi đối với các truy vấn của người dùng (Shuster et al., 2021;
Béchard and Ayala, 2024). Tuy nhiên, RAG
không loại bỏ hoàn toàn ảo giác (Béchard
and Ayala, 2024; Niu et al., 2024) điều này khuyến khích
các hệ thống RAG được tinh chỉnh hơn nữa để giảm ảo giác. LLM-Augmenter (Peng et al., 2023) tận dụng
kiến thức bên ngoài và phản hồi tự động thông qua
các mô-đun Plug and Play (Li et al., 2024) để tăng cường
phản hồi của mô hình. Hơn nữa, EVER (Kang et al.,
2024) giới thiệu một chiến lược sinh từng bước theo thời gian thực
và sửa chữa ảo giác xác nhận
mỗi câu trong quá trình sinh, ngăn chặn
sự lan truyền của lỗi.
Mở rộng Truy vấn Mở rộng truy vấn cải thiện
kết quả tìm kiếm bằng cách sửa đổi truy vấn gốc với
các thuật ngữ liên quan bổ sung, giúp kết nối
truy vấn của người dùng với các tài liệu liên quan. Có
hai cách tiếp cận mở rộng truy vấn chính: dựa trên trình truy xuất
và dựa trên sinh. Các cách tiếp cận dựa trên trình truy xuất mở rộng truy vấn bằng cách sử dụng kết quả từ một
trình truy xuất, trong khi các phương pháp dựa trên sinh sử dụng dữ liệu bên ngoài, chẳng hạn như các mô hình ngôn ngữ lớn (LLM),
để tăng cường truy vấn.
Một số công trình (Wang et al., 2023; Mackie et al.,
2023; Jagerman et al., 2023) tận dụng LLM để
mở rộng truy vấn. Query2Doc (Wang et al., 2023)
chứng minh rằng các đầu ra được tạo bởi LLM được thêm
vào truy vấn vượt trội đáng kể so với các trình truy xuất đơn giản. Tuy nhiên, cách tiếp cận này có thể giới thiệu
sự không chính xác, không căn chỉnh với các tài liệu mục tiêu,
và rất dễ bị ảo giác của LLM.
Các phương pháp dựa trên truy xuất (Lv and Zhai, 2010; Yan
et al., 2003; Li et al., 2023; Lei et al., 2024) tăng cường hiệu quả của truy vấn tìm kiếm bằng cách kết hợp
các thuật ngữ hoặc cụm từ liên quan, làm phong phú truy vấn
với thông tin liên quan. Cụ thể, CSQE (Lei
et al., 2024) sử dụng một LLM để trích xuất các câu chính
từ các tài liệu được truy xuất để mở rộng truy vấn,
tạo ra các truy vấn thích ứng với nhiệm vụ, mặc dù điều này có thể
dẫn đến các truy vấn quá dài. Khi so sánh
các truy vấn được mở rộng bởi CSQE với những truy vấn được đánh giá
bởi BM25 (Robertson and Zaragoza, 2009) và được
xếp hạng lại sử dụng một cross-encoder (Wang et al., 2020)
từ BEIR (Thakur et al., 2021), sự cải thiện hiệu suất
là tối thiểu.
Mục tiêu của tôi là tạo truy vấn được viết lại để truy xuất tài liệu câu trả lời với điểm cao.Đây là truy vấn gốc với top-5 tài liệu được truy xuất.Truy vấn:CCL19 vắng mặt trong dLN. TOP-5 tài liệu được truy xuất:1. Các trường chemokine cố định …2. Sphingosine-1-phosphate …3. Thụ thể giống chemokine 1 (CMKLR1) …4. Thiếu Absent in Melanoma 2 (AIM2) e…5. Mycobacterium tuberculosis và …  Tôi có một số ví dụ về truy vấn được viết lại cùng với điểm tương ứng của chúng. Các văn bản được sắp xếp theo thứ tự tăng dần dựa trên điểm của chúng, trong đó điểm cao hơn cho thấy chất lượng tốt hơn.truy vấn được sửa đổi:Sự vắng mặt của CCL19 được quan sát thấy trong các hạch bạch huyết dẫn lưu (dLN).điểm:0.0(... thêm các ví dụ)Viết truy vấn được viết lại mới của bạn khác với những truy vấn cũ và có điểm cao nhất có thể. Viết văn bản trong dấu ngoặc vuông.Hình 2: Mẫu prompt được sử dụng trong QOQA. Các văn bản màu đen
mô tả hướng dẫn của nhiệm vụ tối ưu hóa. Các văn bản màu xanh
là truy vấn gốc với top- N tài liệu được truy xuất với
truy vấn gốc. Các văn bản màu tím là các truy vấn được sửa đổi bởi bộ tối ưu hóa LLM và điểm.
3 Tối ưu hóa Truy vấn sử dụng Mở rộng
Truy vấn
3.1 Tối ưu hóa truy vấn với LLM
Để tối ưu hóa truy vấn, chúng tôi sử dụng một Mô hình Ngôn ngữ Lớn
(LLM) để viết lại truy vấn dựa trên
điểm của nó. Ban đầu, chúng tôi nhập truy vấn gốc và truy xuất N tài liệu sử dụng một trình truy xuất. Tiếp theo, chúng tôi nối
truy vấn gốc với top N tài liệu được truy xuất
để tạo một truy vấn mở rộng, sau đó được
gửi đến LLM để tạo ra R0 truy vấn
được viết lại. Các truy vấn được viết lại này được đánh giá
về sự căn chỉnh với các tài liệu được truy xuất, và
cặp điểm căn chỉnh truy vấn-tài liệu và
truy vấn được lưu trữ trong một thùng truy vấn. Điểm căn chỉnh
được xác định sử dụng một mô hình truy xuất đo lường
mối tương quan giữa truy vấn và các
tài liệu được truy xuất (Phần 3.2).
Chúng tôi cập nhật mẫu prompt với truy vấn gốc, các tài liệu được truy xuất, và top K
truy vấn được viết lại, như được minh họa trong Hình 2. Để
đảm bảo hiệu suất được cải thiện so với truy vấn gốc,
chúng tôi luôn bao gồm thông tin truy vấn gốc
trong mẫu. Trong các bước tối ưu hóa sau i,
dựa trên điểm, chúng tôi tạo ra một truy vấn Ri được viết lại
và thêm nó vào thùng truy vấn.
2

--- TRANG 3 ---
3.2 Điểm căn chỉnh truy vấn-tài liệu
Để sử dụng điểm căn chỉnh truy vấn-tài liệu trong
bước tối ưu hóa, chúng tôi sử dụng ba loại điểm đánh giá: điểm BM25 từ truy xuất thưa thớt, điểm
dày đặc từ truy xuất dày đặc, điểm lai
kết hợp truy xuất thưa thớt và dày đặc.
Cho truy vấn qi, và tập tài liệu D={dj}J
j=1
điểm căn chỉnh BM25 như sau,
BM25 (qi, D) =IDF(qi)·f(qi, D)·(k1+ 1)
f(qi, D) +k1·(1−b+b·|D|
AVGDL)(1)
trong đó f(qi, D) là tần suất của các thuật ngữ truy vấn trong
tài liệu D,|D| là độ dài của tài liệu,
AVGDL là độ dài tài liệu trung bình, và k1 và b
là các siêu tham số mặc định từ Pyserini (Lin
et al., 2021). IDF(qi) là thuật ngữ tần suất tài liệu nghịch đảo như sau,
IDF(qi) = logN−n(qi) + 0.5
n(qi) + 0.5(2)
trong đó IDF(qi) được tính với tổng số
tài liệu N, và n(qi) là số tài liệu
chứa qi.
Điểm dày đặc là điểm liên quan giữa truy vấn
và tài liệu sử dụng các biểu diễn dày đặc đã học,
tức là, không gian nhúng. Vì cả truy vấn và tài liệu đều được nhúng vào không gian vector liên tục nhiều chiều,
điểm căn chỉnh Dense được tính như sau,
Dense (qi, dj) =Eqi·Edj (3)
trong đó Eqi và Edj là các vector nhúng dày đặc
của truy vấn qi và tài liệu dj∈D,
tương ứng, từ mô hình truy xuất dày đặc. Cho
thí nghiệm của chúng tôi, chúng tôi sử dụng mô hình BAAI/bge-base-en-
v1.5 (Xiao et al., 2024).
Điểm lai kết hợp cả điểm BM25 và
điểm Dense bằng cách điều chỉnh thông số
của alpha α như sau,
Hybrid (qi, dj) =α·BM25(qi, D) +Dense (qi, dj).
(4)
4 Kết quả
Tập dữ liệu Chúng tôi đánh giá trên ba tập dữ liệu truy xuất
từ BEIR (Thakur et al., 2021): SciFact (Wadden
et al., 2020), Trec-Covid (V oorhees et al., 2021)
và FiQA (Maia et al., 2018). Chúng tôi đánh giá về
nhiệm vụ kiểm tra thực tế về các khẳng định khoa học, Truy xuất thông tin Y-sinh,
và nhiệm vụ trả lời câu hỏi
về lĩnh vực tài chính, tương ứng.Bảng 1: Kết quả của nhiệm vụ truy xuất tài liệu. Tất cả điểm biểu thị
nDCG@10. In đậm cho thấy kết quả tốt nhất trên tất cả mô hình,
và tốt thứ hai được gạch chân.
Scifact Trec-covid FiQA
Truy xuất Thưa thớt
BM25 67.9 59.5 23.6
+ RM3 (Lv and Zhai, 2009) 64.6 59.3 19.2
+ Q2D/PRF (Jagerman et al., 2023) 71.7 73.8 29.0
+ CSQE (Lei et al., 2024) 69.6 74.2 25.0
+ QOQA (điểm BM25) 67.5 61.1 21.4
+ QOQA (điểm Dense) 69.7 48.4 23.6
+ QOQA (điểm Hybrid) 66.4 43.2 22.4
Truy xuất Dày đặc
BGE-base-1.5 74.1 78.2 40.7
+ CSQE (Lei et al., 2024) 73.7 78.2 40.1
+ QOQA (điểm BM25) 75.4 60.6 37.4
+ QOQA (điểm Dense) 74.3 77.9 40.6
+ QOQA (điểm Hybrid) 73.9 79.2 40.0
Đường cơ sở (1) Truy xuất Thưa thớt: (a) Mô hình BM25 (Robertson and Zaragoza, 2009) là một hàm truy xuất túi từ được sử dụng rộng rãi dựa trên việc khớp token giữa hai vector thưa thớt nhiều chiều, sử dụng trọng số token TF-IDF.
Chúng tôi sử dụng cài đặt mặc định từ Pyserini (Lin
et al., 2021). (b) BM25+RM3 (Robertson and
Zaragoza, 2009; Lv and Zhai, 2009) là phương pháp mở rộng truy vấn sử dụng PRF. Chúng tôi cũng bao gồm (c)
BM25+Q2D/PRF (Robertson and Zaragoza, 2009;
Jagerman et al., 2023) sử dụng cả phương pháp mở rộng truy vấn dựa trên LLM
và PRF. (2) Truy xuất Dày đặc: (a) Mô hình BGE-base-en-v1.5 là một
mô hình nhúng hiện đại được thiết kế cho các
nhiệm vụ NLP khác nhau như truy xuất, phân cụm, và phân loại. Cho các nhiệm vụ truy xuất dày đặc, chúng tôi thêm 'Đại diện cho câu này để tìm kiếm các đoạn liên quan:' làm
tiền tố truy vấn, theo cài đặt mặc định từ Pyserini. (Lin et al., 2021). Chúng tôi cũng sử dụng CSQE (Lei
et al., 2024) cho cả truy xuất thưa thớt và truy xuất dày đặc.
Chi tiết triển khai Chúng tôi sử dụng GPT-3.5-
Turbo (OpenAI, 2024) làm bộ tối ưu hóa LLM. Nhiệt độ được đặt ở 1.0. Chúng tôi đặt lần lặp tối ưu hóa tối đa là i= 1,2,···,50. Chúng tôi sử dụng
N= 5,K= 3,R0= 3, và Ri= 1. Tất cả siêu tham số k1= 1.2,b= 0.75, và α= 0.1
được đặt ở giá trị mặc định từ Pyserini (Lin et al.,
2021).
Kết quả truy xuất so với đường cơ sở Bảng 1
minh họa hiệu suất của các mô hình truy xuất tài liệu khác nhau trên các tập dữ liệu SciFact, Trec-Covid, và
FiQA. Cho truy xuất dày đặc, các mô hình được tăng cường của chúng tôi (+các biến thể QOQA) thể hiện hiệu suất vượt trội. Đáng chú ý, QOQA (điểm BM25) đạt
kết quả tốt nhất trong SciFact với điểm 75.4, chứng minh
3

--- TRANG 4 ---
Bảng 2: Ví dụ từ tập dữ liệu SciFact và FiQA. Văn bản màu xanh là từ khóa trùng lặp giữa tài liệu câu trả lời và
truy vấn được viết lại.
Truy vấn gốc Vật liệu sinh học 0 chiều cho thấy tính chất cảm ứng.
Truy vấn được viết lại Các vật liệu sinh học có kích thước nano có sở hữu các tính chất độc đáo có thể kích hoạt các phản ứng cụ thể trong hệ thống sinh học không?
Tiêu đề tài liệu câu trả lời 'Cơ hội mới: việc sử dụng công nghệ nano để thao tác và theo dõi tế bào gốc.'
'văn bản': 'Công nghệ nano là những nền tảng mới nổi có thể hữu ích trong việc đo lường,
hiểu biết, và thao tác tế bào gốc. Các ví dụ bao gồm hạt nano từ tính và chấm lượng tử
để gắn nhãn tế bào gốc và theo dõi in vivo; hạt nano, ống carbon nano, và polyplexes
để vận chuyển nội bào các gen/oligonucleotides và protein/peptides;
và giàn tiêu chuẩn nano được thiết kế cho sự phân hóa và cấy ghép tế bào gốc.
Bài đánh giá này xem xét việc sử dụng công nghệ nano cho việc theo dõi, phân hóa, và cấy ghép tế bào gốc.
Chúng tôi tiếp tục thảo luận về tính hữu ích của chúng và những mối quan tâm tiềm tàng về độc tính tế bào của chúng.',
Truy vấn gốc nguồn gốc của COVID-19 là gì
Truy vấn được viết lại Bằng chứng phân tử nào hỗ trợ dơi và tê tê là những vật chủ nguồn gốc có khả năng của virus COVID-19?
Tiêu đề tài liệu câu trả lời 'Phân lập và đặc tính hóa một coronavirus giống SARS của dơi sử dụng thụ thể ACE2'
'văn bản': 'Đại dịch 2002–3 gây ra bởi virus hội chứng hô hấp cấp tính nặng (SARS-CoV)
. . . virus hội chứng hô hấp Trung Đông (MERS-CoV)(2) cho thấy rằng nhóm virus này vẫn là một mối đe dọa lớn và phân phối của chúng
rộng hơn so với trước đây được công nhận. Mặc dù dơi đã được đề xuất là kho chứa tự nhiên của cả hai virus(3–5), các nỗ lực
phân lập virus tiền thân của SARS-CoV từ dơi đã không thành công. Các coronavirus giống SARS đa dạng (SL-CoVs)
hiện đã được báo cáo từ dơi ở Trung Quốc, Châu Âu và Châu Phi(5–8), nhưng không có virus nào được coi là tiền thân trực tiếp của SARS-CoV
do sự khác biệt phát sinh loài của chúng so với virus này và khả năng không thể của các protein gai (S) của chúng sử dụng
phân tử thụ thể tế bào SARS-CoV, enzyme chuyển đổi angiotensin II của người (ACE2)(9,10).
Ở đây, chúng tôi báo cáo các chuỗi genome hoàn chỉnh của hai CoV dơi mới từ dơi móng ngựa Trung Quốc (Họ: Rhinolophidae)
ở Vân Nam, Trung Quốc; RsSHC014 và Rs3367. Các virus này . . . có hình thái coronavirus điển hình, . . . tính ưa mô.
Kết quả của chúng tôi cung cấp bằng chứng mạnh nhất cho đến nay rằng dơi móng ngựa Trung Quốc là kho chứa tự nhiên của SARS-CoV,
và các vật chủ trung gian có thể không . . . '
Bảng 3: Kết quả nghiên cứu loại bỏ trên SciFact. Bảng này
trình bày tác động hiệu suất của việc loại bỏ thành phần mở rộng và thành phần tối ưu hóa từ QOQA, minh họa
tầm quan trọng của mỗi mô-đun, trong việc tăng cường độ chính xác truy xuất. Tất cả điểm biểu thị giá trị nDCG@10.
QOQA (điểm BM25) QOQA (điểm Dense)
Truy xuất Thưa thớt
Của chúng tôi 67.5 69.7
w/o mở rộng 65.6 66.0
w/o tối ưu hóa 67.6 67.6
Truy xuất Dày đặc
Của chúng tôi 75.4 74.3
w/o mở rộng 72.9 74.2
w/o tối ưu hóa 73.2 72.6
hiệu suất mạnh trong Trec-Covid với 79.2 với điểm lai. Mức tăng hiệu suất nhất quán của QOQA của chúng tôi trên các tập dữ liệu khác nhau làm nổi bật
hiệu quả trong việc cải thiện truy xuất.
Phân tích Trường hợp Như được hiển thị trong Bảng 2, các truy vấn được viết lại
được tạo với QOQA chính xác và
cụ thể hơn so với các truy vấn gốc. Khi tìm kiếm tài liệu câu trả lời, các truy vấn được tạo
với phương pháp QOQA của chúng tôi bao gồm các từ khóa chính xác,
chẳng hạn như "nano" hoặc "bằng chứng phân tử," để truy xuất
các tài liệu liên quan nhất. Độ chính xác trong
việc sử dụng từ khóa này đảm bảo rằng các truy vấn được viết lại
chia sẻ nhiều từ chung hơn với các tài liệu câu trả lời. Do đó, các truy vấn sử dụng QOQA
chứng minh hiệu quả trong việc truy xuất tài liệu
chứa câu trả lời chính xác, làm nổi bật
tính ưu việt của cách tiếp cận của chúng tôi trong các nhiệm vụ truy xuất.
Nghiên cứu Loại bỏ Trong nghiên cứu loại bỏ của chúng tôi, chúng tôi đánh giá tác động của các thành phần mở rộng và tối ưu hóa trong QOQA sử dụng cả điểm BM25 và Dense bằng cách loại bỏ có hệ thống từng thành phần và quan sát kết quả nDCG@10. Chúng tôi
loại bỏ việc mở rộng tài liệu (Văn bản màu xanh trong
Hình 2) trong thiết lập "w/o mở rộng" trong khi giữ lại
bước tối ưu hóa. Trong thiết lập "w/o tối ưu hóa", chúng tôi sử dụng tối ưu hóa một bước là i= 1. Như
được hiển thị trong Bảng 3, bước tối ưu hóa cải thiện
việc tìm kiếm các truy vấn được viết lại tốt hơn. Hơn nữa,
không có thành phần mở rộng, hiệu suất
giảm đáng kể, đặc biệt với điểm BM25.
Điều này chứng minh vai trò quan trọng của thành phần
mở rộng trong việc tạo ra các truy vấn được viết lại chất lượng cao và tăng cường truy xuất tài liệu.
5 Kết luận
Trong bài báo này, chúng tôi đã giải quyết vấn đề ảo giác trong các hệ thống Sinh tăng cường Truy xuất (RAG)
bằng cách tối ưu hóa sinh truy vấn. Sử dụng
điểm căn chỉnh truy vấn-tài liệu trung bình top-k,
chúng tôi đã tinh chỉnh truy vấn sử dụng các Mô hình Ngôn ngữ Lớn
(LLM) để cải thiện độ chính xác và hiệu quả tính toán
trong truy xuất tài liệu. Các thí nghiệm của chúng tôi
chứng minh rằng những tối ưu hóa này giảm đáng kể
ảo giác và tăng cường độ chính xác truy xuất tài liệu, đạt được mức tăng trung bình 1,6%.
Nghiên cứu này làm nổi bật tầm quan trọng của
sinh truy vấn chính xác trong việc tăng cường độ tin cậy
và hiệu quả của các hệ thống RAG. Công việc tương lai
sẽ tập trung vào việc tích hợp các kỹ thuật tinh chỉnh truy vấn tiên tiến hơn và áp dụng cách tiếp cận của chúng tôi cho
4

--- TRANG 5 ---
một phạm vi rộng hơn của các ứng dụng RAG.
Tài liệu tham khảo
Patrice Béchard and Orlando Marquez Ayala. 2024.
Giảm ảo giác trong đầu ra có cấu trúc
thông qua sinh tăng cường truy xuất. Preprint,
arXiv:2404.08189.
Rolf Jagerman, Honglei Zhuang, Zhen Qin, Xuanhui
Wang, and Michael Bendersky. 2023. Mở rộng truy vấn
bằng cách nhắc nhở các mô hình ngôn ngữ lớn. Preprint,
arXiv:2305.03653.
Haoqiang Kang, Juntong Ni, and Huaxiu Yao. 2024.
Ever: Giảm thiểu ảo giác trong các mô hình ngôn ngữ lớn
thông qua xác minh và sửa chữa thời gian thực.
Preprint, arXiv:2311.09114.
Victor Lavrenko and W. Bruce Croft. 2001. Các mô hình ngôn ngữ
dựa trên liên quan. In Proceedings of the 24th
Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,
SIGIR '01, page 120–127, New York, NY, USA. Association for Computing Machinery.
Yibin Lei, Yu Cao, Tianyi Zhou, Tao Shen, and Andrew Yates. 2024. Mở rộng truy vấn được điều khiển bởi corpus
với các mô hình ngôn ngữ lớn. arXiv preprint
arXiv:2402.18031.
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio
Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2021.
Sinh tăng cường truy xuất cho các nhiệm vụ nlp
chuyên sâu về kiến thức. Preprint, arXiv:2005.11401.
Hang Li, Shengyao Zhuang, Ahmed Mourad, Xueguang
Ma, Jimmy Lin, and Guido Zuccon. 2023. Cải thiện
biểu diễn truy vấn cho truy xuất dày đặc với
phản hồi liên quan giả định: Một nghiên cứu tái tạo.
Preprint, arXiv:2112.06400.
Miaoran Li, Baolin Peng, Michel Galley, Jianfeng Gao,
and Zhu Zhang. 2024. Self-checker: Các mô-đun cắm và chạy cho kiểm tra thực tế với các mô hình ngôn ngữ lớn.
Preprint, arXiv:2305.14623.
Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-
Hong Yang, Ronak Pradeep, and Rodrigo Nogueira.
2021. Pyserini: Một bộ công cụ Python cho nghiên cứu
truy xuất thông tin tái tạo với biểu diễn thưa thớt và dày đặc. In Proceedings of the 44th Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval (SIGIR
2021), pages 2356–2362.
Yuanhua Lv and ChengXiang Zhai. 2009. Một nghiên cứu
so sánh các phương pháp ước lượng mô hình ngôn ngữ truy vấn
với phản hồi giả định. In Proceedings of the
18th ACM Conference on Information and Knowledge Management, CIKM '09, page 1895–1898, New
York, NY, USA. Association for Computing Machinery.Yuanhua Lv and ChengXiang Zhai. 2010. Mô hình liên quan
vị trí cho phản hồi liên quan giả định. In
Proceedings of the 33rd International ACM SIGIR
Conference on Research and Development in Information Retrieval, SIGIR '10, page 579–586, New
York, NY, USA. Association for Computing Machinery.
Iain Mackie, Shubham Chatterjee, and Jeffrey Dalton.
2023. Phản hồi liên quan sinh với các mô hình ngôn ngữ lớn. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '23, page
2026–2031, New York, NY, USA. Association for
Computing Machinery.
Macedo Maia, Siegfried Handschuh, André Freitas,
Brian Davis, Ross McDermott, Manel Zarrouk, and
Alexandra Balahur. 2018. Www'18 open challenge:
Khai thác ý kiến tài chính và trả lời câu hỏi. In
Companion Proceedings of the The Web Conference
2018, WWW '18, page 1941–1942, Republic and
Canton of Geneva, CHE. International World Wide
Web Conferences Steering Committee.
Cheng Niu, Yuanhao Wu, Juno Zhu, Siliang Xu, Kashun
Shum, Randy Zhong, Juntong Song, and Tong Zhang.
2024. Ragtruth: Một corpus ảo giác để phát triển
các mô hình ngôn ngữ tăng cường truy xuất đáng tin cậy.
Preprint, arXiv:2401.00396.
OpenAI. 2024. Báo cáo kỹ thuật gpt-4. Preprint,
arXiv:2303.08774.
Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng,
Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou
Yu, Weizhu Chen, and Jianfeng Gao. 2023. Kiểm tra
sự thật của bạn và thử lại: Cải thiện các mô hình ngôn ngữ lớn
với kiến thức bên ngoài và phản hồi tự động.
Preprint, arXiv:2302.12813.
Stephen Robertson and Hugo Zaragoza. 2009. Khung
liên quan xác suất: Bm25 và hơn thế nữa. Found. Trends Inf. Retr., 3(4):333–389.
Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela,
and Jason Weston. 2021. Tăng cường truy xuất
giảm ảo giác trong hội thoại. Preprint,
arXiv:2104.07567.
Nandan Thakur, Nils Reimers, Andreas Rücklé, Abhishek Srivastava, and Iryna Gurevych. 2021. Beir:
Một benchmark không đồng nhất cho đánh giá zero-shot
của các mô hình truy xuất thông tin. arXiv preprint
arXiv:2104.08663.
Ellen V oorhees, Tasmeer Alam, Steven Bedrick, Dina
Demner-Fushman, William R. Hersh, Kyle Lo, Kirk
Roberts, Ian Soboroff, and Lucy Lu Wang. 2021.
Trec-covid: xây dựng một bộ sưu tập thử nghiệm truy xuất thông tin
đại dịch. SIGIR Forum, 54(1).
David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu
Wang, Madeleine van Zuylen, Arman Cohan, and
Hannaneh Hajishirzi. 2020. Thực tế hay viễn tưởng: Xác minh
5

--- TRANG 6 ---
các khẳng định khoa học. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language
Processing (EMNLP), pages 7534–7550, Online. Association for Computational Linguistics.
Liang Wang, Nan Yang, and Furu Wei. 2023.
Query2doc: Mở rộng truy vấn với các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2303.07678.
Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao,
Nan Yang, and Ming Zhou. 2020. Minilm: Chưng cất tự chú ý sâu cho nén không phụ thuộc nhiệm vụ
của các transformer được huấn luyện trước. Preprint,
arXiv:2002.10957.
Kevin Wu, Eric Wu, and James Zou. 2024. Clashe-
val: Định lượng cuộc kéo co giữa kiến thức nội tại của llm
và bằng chứng bên ngoài. Preprint,
arXiv:2404.10198.
Shitao Xiao, Zheng Liu, Peitian Zhang, Niklas Muennighoff, Defu Lian, and Jian-Yun Nie. 2024. C-pack:
Tài nguyên đóng gói để thúc đẩy nhúng tiếng Trung tổng quát. Preprint, arXiv:2309.07597.
Rong Yan, Alexander Hauptmann, and Rong Jin. 2003.
Tìm kiếm đa phương tiện với phản hồi liên quan giả định.
In Proceedings of the 2nd International Conference on Image and Video Retrieval, CIVR'03, page
238–247, Berlin, Heidelberg. Springer-Verlag.
Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,
Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,
Yulong Chen, et al. 2023. Bài hát của nàng tiên cá trong đại dương ai:
một khảo sát về ảo giác trong các mô hình ngôn ngữ lớn.
arXiv preprint arXiv:2309.01219.
6

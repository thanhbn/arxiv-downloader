# 2305.09313.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2305.09313.pdf
# Kích thước tệp: 825689 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xếp hạng lại Đoạn văn Kết hợp và Cộng tác
Zongmeng Zhang1, Wengang Zhou2, Jiaxin Shi3, Houqiang Li2
1;2Đại học Khoa học và Công nghệ Trung Quốc
3Huawei Cloud Computing Technologies Co., Ltd.
1zhangzm@mail.ustc.edu.cn,2{zhwg, lihq}@ustc.edu.cn,3shijx12@gmail.com

Tóm tắt
Trong hệ thống truy xuất đoạn văn, kết quả truy xuất đoạn văn ban đầu có thể không thỏa đáng, có thể được cải thiện bằng một kế hoạch xếp hạng lại. Các giải pháp hiện có cho việc xếp hạng lại đoạn văn tập trung vào làm phong phú tương tác giữa truy vấn và từng đoạn văn riêng biệt, bỏ qua bối cảnh giữa các đoạn văn xếp hạng cao nhất trong danh sách truy xuất ban đầu. Để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp Xếp hạng lại Đoạn văn Kết hợp và Cộng tác (HybRank), tận dụng các đo lường tương tự đáng kể của các bộ truy xuất thượng nguồn cho sự cộng tác đoạn văn và kết hợp các thuộc tính từ vựng và ngữ nghĩa của các bộ truy xuất thưa và dày đặc để xếp hạng lại. Ngoài ra, được xây dựng trên các tính năng bộ truy xuất có sẵn, HybRank là một bộ xếp hạng lại có thể cắm được có khả năng nâng cao các danh sách đoạn văn tùy ý bao gồm cả những danh sách đã được xếp hạng lại trước đó. Các thí nghiệm mở rộng chứng minh sự cải thiện hiệu suất ổn định so với các phương pháp truy xuất và xếp hạng lại phổ biến, và xác minh hiệu quả của các thành phần cốt lõi của HybRank.1

1 Giới thiệu
Truy xuất thông tin là một thành phần cơ bản trong lĩnh vực xử lý ngôn ngữ tự nhiên (Chen et al., 2017). Truy xuất nhằm mục đích tìm kiếm một tập hợp các tài liệu ứng cử viên từ một kho dữ liệu quy mô lớn, và do đó cần có truy xuất hiệu quả với độ bao phủ cao để bao gồm càng nhiều tài liệu có liên quan càng tốt. Theo truyền thống, truy xuất đã bị chi phối bởi các phương pháp từ vựng như TF-IDF và BM25 (Robertson và Zaragoza, 2009), coi truy vấn và tài liệu như các vectơ túi từ thưa và khớp chúng ở cấp độ token. Gần đây, các mạng nơ-ron đã trở nên phổ biến để xử lý truy xuất thông tin, nơi truy vấn và tài liệu được mã hóa thành các vectơ ngữ nghĩa theo ngữ cảnh dày đặc (Huang et al., 2020; Karpukhin et al., 2020; Ren et al., 2021a; Zhang et al., 2022), và sau đó truy xuất được thực hiện với các thuật toán tìm kiếm vectơ được tối ưu hóa cao (Johnson et al., 2021).

Mặc dù đã có nhiều nỗ lực dành cho truy xuất, yêu cầu hiệu quả vốn có hạn chế tương tác giữa truy vấn và đoạn văn ở mức độ nông, dẫn đến kết quả truy xuất không thỏa đáng. Do đó, trong việc xếp hạng lại điển hình (Nogueira và Cho, 2020; Sun et al., 2021), truy vấn và đoạn văn được nối với nhau và đưa vào một Transformer (Vaswani et al., 2017) được đào tạo trước trên kho dữ liệu lớn, để ước tính điểm liên quan chi tiết hơn và nâng cao thêm kết quả truy xuất với tương tác phong phú hơn. Các phương pháp này xem xét từng đoạn văn một cách riêng lẻ, bỏ qua bối cảnh của danh sách đoạn văn được truy xuất.

Một số phương pháp học xếp hạng (Rahimi et al., 2016; Xia et al., 2008) và phản hồi giả liên quan (Zamani et al., 2016; Zhai và Lafferty, 2001) sử dụng mối quan hệ thứ tự hoặc bối cảnh theo danh sách của các tài liệu được truy xuất để tinh chỉnh thêm việc truy xuất. Hơn nữa, sự cần thiết của việc tích hợp bối cảnh theo danh sách được xác nhận trong các hệ thống gợi ý đa giai đoạn (Liu et al., 2022).

Được truyền cảm hứng từ thành công của mô hình hóa theo danh sách và lọc cộng tác (Goldberg et al., 1992) trong các hệ thống gợi ý, chúng tôi thấy rằng sự cộng tác cũng tồn tại giữa các đoạn văn trong danh sách truy xuất và chưa được khai thác đầy đủ. Một cách trực quan, đối với một truy vấn cụ thể, một tập hợp các đoạn văn liên quan đến truy vấn có xu hướng mô tả cùng các thực thể, sự kiện và mối quan hệ (Lee et al., 2019), trong khi những đoạn không liên quan ngoài tập hợp này liên quan đến các đối tượng đa dạng. Do đó, một đoạn văn có nhiều khả năng liên quan đến truy vấn nếu hầu hết các đoạn văn khác chia sẻ nội dung tương tự với nó. Sự tương tự giữa các đoạn văn có thể được tự nhiên rút ra từ các bộ truy xuất, như điểm BM25 trong các bộ truy xuất thưa2 và tích vô hướng của các embedding trong các bộ truy xuất dày đặc.

Ngoài ra, các phương pháp truy xuất thưa và dày đặc nhấn mạnh các khía cạnh ngôn ngữ khác nhau. Truy xuất thưa dựa vào sự chồng chéo từ vựng trong khi truy xuất dày đặc tập trung vào sự liên quan ngữ nghĩa và theo ngữ cảnh. Một số nhà nghiên cứu đã cố gắng tích hợp những ưu điểm của hai loại phương pháp này. Karpukhin et al. (2020), Lin et al. (2020) và Luan et al. (2021) khai thác sự kết hợp tuyến tính của hai loại điểm truy xuất này. Seo et al. (2019), Khattab và Zaharia (2020) và Santhanam et al. (2022) lập chỉ mục các đơn vị nhỏ hơn trong câu, tức là từ hoặc cụm từ, để có được sự tương tự chi tiết. Gao et al. (2021a) và Yang et al. (2021) đào tạo lại bộ truy xuất dày đặc từ đầu với sự giám sát của tín hiệu thưa. Tuy nhiên, sự kết hợp điểm tuyến tính thiếu tương tác đầy đủ, lập chỉ mục các đơn vị nhỏ hơn hy sinh hiệu quả do số lượng embedding khổng lồ, trong khi việc xây dựng lại các bộ truy xuất loại bỏ khả năng xếp hạng ban đầu của chúng.

Để khai thác đầy đủ bối cảnh của danh sách đoạn văn được truy xuất và khám phá sự kết hợp đầy đủ hơn của bộ truy xuất không đồng nhất, chúng tôi đề xuất một phương pháp Xếp hạng lại Đoạn văn Kết hợp và Cộng tác (HybRank), tận dụng sự cộng tác trong các đoạn văn được truy xuất và kết hợp các thuộc tính đa dạng của các bộ truy xuất để xếp hạng lại. Phương pháp của chúng tôi là một bộ xếp hạng lại có thể cắm được linh hoạt có thể được áp dụng cho các danh sách đoạn văn tùy ý, bao gồm cả những danh sách đã được xếp hạng lại bởi các phương pháp khác. Trong công trình này, không mất tính tổng quát, chúng tôi sử dụng hai loại bộ truy xuất đại diện nhất: bộ truy xuất thưa và dày đặc. Với một truy vấn và một danh sách truy xuất ban đầu, trước tiên chúng tôi trích xuất sự tương tự giữa chúng và một tập hợp các văn bản neo thông qua cả bộ truy xuất thưa và dày đặc. Chúng tôi chiếu và nhóm chúng để tạo thành một tập hợp các chuỗi kết hợp và cộng tác, mỗi chuỗi tương ứng với một truy vấn hoặc đoạn văn. Sau đó, các điểm liên quan giữa truy vấn và các đoạn văn này được đánh giá dựa trên các chuỗi này.

Các thí nghiệm mở rộng chứng minh sự cải thiện hiệu suất nhất quán mà HybRank mang lại so với các danh sách đoạn văn từ các bộ truy xuất phổ biến và các bộ xếp hạng lại mạnh. Chúng tôi trình bày các nghiên cứu loại bỏ chi tiết về thông tin cộng tác, kết hợp tính năng, tương tác theo neo và số lượng đoạn văn neo, xác minh tác động và tính không thể thiếu của các thành phần này trong HybRank.

2 Phương pháp
Trong các hệ thống truy xuất thông tin chính thống, truy xuất giai đoạn đầu được thiết kế để lấy một danh sách ứng cử viên thô từ một kho dữ liệu lớn C. Không thể tránh khỏi, các kết quả dương tính giả, tức là các đoạn văn không liên quan trong danh sách truy xuất, được trả về trong truy xuất giai đoạn đầu. Để cải thiện độ chính xác của các hệ thống truy xuất, thủ tục tiếp theo xếp hạng lại nhằm mục đích phân biệt các đoạn văn liên quan khỏi những đoạn khác trong danh sách truy xuất. Bài báo này tập trung vào giai đoạn xếp hạng lại.

Chính thức, với một truy vấn q và một danh sách đoạn văn ban đầu P = [p1;p2;:::;p N] từ bộ truy xuất thượng nguồn, nhiệm vụ xếp hạng lại là sắp xếp lại danh sách đoạn văn bằng cách gán lại điểm S = [s1;s2;:::;s N] cho mỗi đoạn văn này. Chúng tôi ký hiệu các đoạn văn tích cực trong danh sách là P+ và các đoạn tiêu cực là P-. Trong phần này, chúng tôi sẽ trình bày chi tiết về HybRank. Quy trình của HybRank được minh họa trong Hình 1.

2.1 Kiến thức cơ bản
Truy xuất Thưa Theo truyền thống, truy xuất văn bản được chi phối bởi khớp token, nơi văn bản được mã hóa thành các vectơ thưa có chiều cao sử dụng thông tin thống kê của token. Các phương pháp truy xuất thưa được sử dụng phổ biến nhất bao gồm TF-IDF, BM25 và tương tự. Chúng tôi sử dụng điểm BM25 làm độ đo tương tự của truy xuất thưa do tính bền vững và tính phổ biến của nó.

Cụ thể, với truy vấn q và tài liệu d, điểm BM25 giữa q và d được tính bằng cách tính tổng trọng số BM25 trên các từ xuất hiện chung trong q và d:
fs(q;d) =X t2q\d wRSJ t ct;d k1((1b) +bjdj l) +ct;d; (1)
trong đó t là một từ, wRSJ t là trọng số Robertson-Spärck Jones của t, ct;d là tần suất của t trong d, jdj là độ dài tài liệu và l là độ dài trung bình của tất cả tài liệu trong bộ sưu tập. k1 và b là các tham số có thể điều chỉnh. Tham khảo Robertson và Zaragoza (2009) để biết thêm chi tiết về BM25.

Truy xuất Dày đặc Nhờ vào tính linh hoạt cho biểu diễn cụ thể cho nhiệm vụ được cung cấp bởi các tham số có thể học, các công trình gần đây tận dụng mạng nơ-ron để mã hóa văn bản thành các vectơ dày đặc, và tìm kiếm các tài liệu tương tự cho truy vấn trong không gian vectơ. Thông thường, truy vấn và tài liệu được mã hóa riêng biệt, và điểm liên quan được đo bằng sự tương tự của các embedding của chúng. Bất kỳ kiến trúc nơ-ron nào có khả năng mã hóa văn bản thành một vectơ có độ dài cố định đều phù hợp cho truy xuất dày đặc. Chúng tôi sử dụng bộ mã hóa Transformer (Vaswani et al., 2017) chủ đạo và sự tương tự tích vô hướng, được công thức hóa như
fd(q;d) = T q(q)>Td(d); (2)

--- TRANG 2 ---
truy xuất dựa vào sự chồng chéo từ vựng trong khi truy xuất dày đặc tập trung vào sự liên quan ngữ nghĩa và theo ngữ cảnh. Một số nhà nghiên cứu đã cố gắng tích hợp những ưu điểm của hai loại phương pháp này. Karpukhin et al. (2020), Lin et al. (2020) và Luan et al. (2021) khai thác sự kết hợp tuyến tính của hai loại điểm truy xuất này. Seo et al. (2019), Khattab và Zaharia (2020) và Santhanam et al. (2022) lập chỉ mục các đơn vị nhỏ hơn trong câu, tức là từ hoặc cụm từ, để có được sự tương tự chi tiết. Gao et al. (2021a) và Yang et al. (2021) đào tạo lại bộ truy xuất dày đặc từ đầu với sự giám sát của tín hiệu thưa. Tuy nhiên, sự kết hợp điểm tuyến tính thiếu tương tác đầy đủ, lập chỉ mục các đơn vị nhỏ hơn hy sinh hiệu quả do số lượng embedding khổng lồ, trong khi việc xây dựng lại các bộ truy xuất loại bỏ khả năng xếp hạng ban đầu của chúng.

Để khai thác đầy đủ bối cảnh của danh sách đoạn văn được truy xuất và khám phá sự kết hợp đầy đủ hơn của bộ truy xuất không đồng nhất, chúng tôi đề xuất một phương pháp Xếp hạng lại Đoạn văn Kết hợp và Cộng tác (HybRank), tận dụng sự cộng tác trong các đoạn văn được truy xuất và kết hợp các thuộc tính đa dạng của các bộ truy xuất để xếp hạng lại. Phương pháp của chúng tôi là một bộ xếp hạng lại có thể cắm được linh hoạt có thể được áp dụng cho các danh sách đoạn văn tùy ý, bao gồm cả những danh sách đã được xếp hạng lại bởi các phương pháp khác. Trong công trình này, không mất tính tổng quát, chúng tôi sử dụng hai loại bộ truy xuất đại diện nhất: bộ truy xuất thưa và dày đặc. Với một truy vấn và một danh sách truy xuất ban đầu, trước tiên chúng tôi trích xuất sự tương tự giữa chúng và một tập hợp các văn bản neo thông qua cả bộ truy xuất thưa và dày đặc. Chúng tôi chiếu và nhóm chúng để tạo thành một tập hợp các chuỗi kết hợp và cộng tác, mỗi chuỗi tương ứng với một truy vấn hoặc đoạn văn. Sau đó, các điểm liên quan giữa truy vấn và các đoạn văn này được đánh giá dựa trên các chuỗi này.

Các thí nghiệm mở rộng chứng minh sự cải thiện hiệu suất nhất quán mà HybRank mang lại so với các danh sách đoạn văn từ các bộ truy xuất phổ biến và các bộ xếp hạng lại mạnh. Chúng tôi trình bày các nghiên cứu loại bỏ chi tiết về thông tin cộng tác, kết hợp tính năng, tương tác theo neo và số lượng đoạn văn neo, xác minh tác động và tính không thể thiếu của các thành phần này trong HybRank.

2 Phương pháp
Trong các hệ thống truy xuất thông tin chính thống, truy xuất giai đoạn đầu được thiết kế để lấy một danh sách ứng cử viên thô từ một kho dữ liệu lớn C. Không thể tránh khỏi, các kết quả dương tính giả, tức là các đoạn văn không liên quan trong danh sách truy xuất, được trả về trong truy xuất giai đoạn đầu. Để cải thiện độ chính xác của các hệ thống truy xuất, thủ tục tiếp theo xếp hạng lại nhằm mục đích phân biệt các đoạn văn liên quan khỏi những đoạn khác trong danh sách truy xuất. Bài báo này tập trung vào giai đoạn xếp hạng lại.

Chính thức, với một truy vấn q và một danh sách đoạn văn ban đầu P = [p1;p2;:::;p N] từ bộ truy xuất thượng nguồn, nhiệm vụ xếp hạng lại là sắp xếp lại danh sách đoạn văn bằng cách gán lại điểm S = [s1;s2;:::;s N] cho mỗi đoạn văn này. Chúng tôi ký hiệu các đoạn văn tích cực trong danh sách là P+ và các đoạn tiêu cực là P-. Trong phần này, chúng tôi sẽ trình bày chi tiết về HybRank. Quy trình của HybRank được minh họa trong Hình 1.

2.1 Kiến thức cơ bản
Truy xuất Thưa Theo truyền thống, truy xuất văn bản được chi phối bởi khớp token, nơi văn bản được mã hóa thành các vectơ thưa có chiều cao sử dụng thông tin thống kê của token. Các phương pháp truy xuất thưa được sử dụng phổ biến nhất bao gồm TF-IDF, BM25 và tương tự. Chúng tôi sử dụng điểm BM25 làm độ đo tương tự của truy xuất thưa do tính bền vững và tính phổ biến của nó.

Cụ thể, với truy vấn q và tài liệu d, điểm BM25 giữa q và d được tính bằng cách tính tổng trọng số BM25 trên các từ xuất hiện chung trong q và d:
fs(q;d) =X t2q\d wRSJ t ct;d k1((1b) +bjdj l) +ct;d; (1)
trong đó t là một từ, wRSJ t là trọng số Robertson-Spärck Jones của t, ct;d là tần suất của t trong d, jdj là độ dài tài liệu và l là độ dài trung bình của tất cả tài liệu trong bộ sưu tập. k1 và b là các tham số có thể điều chỉnh. Tham khảo Robertson và Zaragoza (2009) để biết thêm chi tiết về BM25.

Truy xuất Dày đặc Nhờ vào tính linh hoạt cho biểu diễn cụ thể cho nhiệm vụ được cung cấp bởi các tham số có thể học, các công trình gần đây tận dụng mạng nơ-ron để mã hóa văn bản thành các vectơ dày đặc, và tìm kiếm các tài liệu tương tự cho truy vấn trong không gian vectơ. Thông thường, truy vấn và tài liệu được mã hóa riêng biệt, và điểm liên quan được đo bằng sự tương tự của các embedding của chúng. Bất kỳ kiến trúc nơ-ron nào có khả năng mã hóa văn bản thành một vectơ có độ dài cố định đều phù hợp cho truy xuất dày đặc. Chúng tôi sử dụng bộ mã hóa Transformer (Vaswani et al., 2017) chủ đạo và sự tương tự tích vô hướng, được công thức hóa như
fd(q;d) = T q(q)>Td(d); (2)

--- TRANG 3 ---
điểm
Chiếu Tuyến tính
Trans𝑖𝑛𝑡𝑒𝑟Trans𝑎𝑔𝑔𝑟𝒉𝑝4𝒉𝑝3𝒉𝑝2𝒉𝑝1𝒉𝑞
𝒉𝑝5𝑠1
𝑠2
𝑠3
𝑠4
𝑠5𝑬𝑝1
𝑬𝑝2
𝑬𝑝3
𝑬𝑝4
𝑬𝑝5𝑬𝑞
embedding tương tự biểu diễn vectơ𝒉𝑝𝑖𝒉𝑞
𝑝2𝑝3𝑝4𝑝5 𝑝1
𝑞
𝑝1
𝑝2
𝑝3
𝑝4
𝑝5
thưa       dày đặc
neo
truy vấn
đoạn vănChuỗi Kết hợp và Cộng tác Ma trận Tương tự Tương tác và Tổng hợp Xếp hạng lạiHình 1: Minh họa quy trình HybRank. Đối với một truy vấn cụ thể, danh sách đoạn văn được khởi tạo bởi một bộ truy xuất tùy ý. Danh sách đoạn văn có thể đã được xếp hạng lại bởi một bộ xếp hạng lại khác trước HybRank. Chúng tôi hiển thị danh sách 5 đoạn văn làm ví dụ. Đầu tiên, sự tương tự giữa truy vấn, đoạn văn và neo được rút ra từ các bộ truy xuất thưa và dày đặc. Sau đó, những sự tương tự này được chuyển đổi thành các chuỗi kết hợp và cộng tác làm biểu diễn của truy vấn và đoạn văn. Cuối cùng, các chuỗi này được mã hóa thành các vectơ dày đặc thông qua tương tác và tổng hợp, và các điểm xếp hạng lại được tính bằng tích vô hướng giữa các vectơ dày đặc của truy vấn và mỗi đoạn văn.

trong đó Tq() và Td() là các bộ mã hóa Transformer cho truy vấn và tài liệu. Sự tương tự tích vô hướng cho phép mã hóa trước ngoại tuyến của kho dữ liệu lớn và truy xuất hiệu quả thông qua thư viện tìm kiếm láng giềng gần nhất được tối ưu hóa cao (Johnson et al., 2021).

2.2 Chuỗi Kết hợp và Cộng tác
Đối với một truy vấn cụ thể, các đoạn văn liên quan có xu hướng mô tả cùng các thực thể, sự kiện và mối quan hệ từ truy vấn (Lee et al., 2019). Nói cách khác, hầu hết các đoạn văn trong danh sách truy xuất sẽ giống với những đoạn thực sự tích cực. Được truyền cảm hứng từ thành công của lọc cộng tác (Goldberg et al., 1992) trong các hệ thống gợi ý, chúng tôi sử dụng sự tương tự giữa các đoạn văn để phân biệt các đoạn văn tích cực trong danh sách truy xuất.

Chuỗi Cộng tác Các đo lường tương tự có thể được tự nhiên rút ra từ các bộ truy xuất. ví dụ, điểm BM25 trong bộ truy xuất thưa và tích vô hướng trong bộ truy xuất dày đặc như mô tả trong Phần 2.1. Chúng tôi tính toán sự tương tự giữa mỗi đoạn văn và một tập hợp các neo, là L đoạn văn hàng đầu của danh sách truy xuất trong công trình này và sẽ cộng tác để phân biệt các đoạn văn tích cực. Các điểm tương tự này giữa các đoạn văn có thể được tính toán trước, vì HybRank sử dụng các bộ truy xuất có sẵn. Ký hiệu điểm tương tự giữa đoạn văn pi và pj là fij∈R, đoạn văn pi có thể được biểu diễn như một chuỗi các số vô hướng tương tự xpi = [fi1;fi2;:::;fiL]∈RL.

Tuy nhiên, theo quan sát của chúng tôi, các số vô hướng tương tự trong một danh sách truy xuất có xu hướng tập trung trong một phạm vi nhỏ. Đây là một hiện tượng hợp lý vì các bộ truy xuất lấy các đoạn văn tương đối giống nhau từ kho dữ liệu lớn. Để có được các tính năng phân biệt hơn, chúng tôi sử dụng softmax nhiệt độ để kéo dài phân phối của sự tương tự. Sau đó, một chuẩn hóa min-max được áp dụng để chia tỷ lệ chúng vào phạm vi [−1;1]. Hai phép biến đổi này được công thức hóa như
x = softmax(x/t);
x = 2(x−min(x))/(max(x)−min(x))−1; (3)
trong đó t là nhiệt độ. Các chỉ số phụ của xpi được bỏ qua để ngắn gọn.

Kết hợp Tính năng Các độ đo tương tự của các bộ truy xuất thưa và dày đặc tập trung vào sự chồng chéo từ vựng và liên quan ngữ nghĩa, tương ứng. Để kết hợp các thuộc tính từ vựng và ngữ nghĩa được nhúng trong các bộ truy xuất thưa và dày đặc, chúng tôi trộn các điểm tương tự của chúng3 bằng cách xếp chúng theo cách kênh. Chính thức, chúng tôi thay thế số vô hướng tương tự fij trong xpi bằng một vectơ xij = [fsij;fdij]∈R2, trong đó fsij là sự tương tự thưa được tính như Phương trình 1 và fdij là sự tương tự dày đặc được tính như Phương trình 2. Sau đó, biểu diễn của đoạn văn pi trở thành một chuỗi các vectơ tương tự Xpi = [xi1;xi2;:::;xiL]∈RL×2. Ngoài ra, chúng tôi ánh xạ các vectơ tương tự này trong chuỗi đến chiều D với một phép chiếu tuyến tính có thể đào tạo:
eij = xijW; (4)

3Trong bài báo này, chúng tôi gọi điểm tương tự từ các bộ truy xuất thưa và dày đặc tương ứng là sự tương tự thưa và sự tương tự dày đặc.

--- TRANG 4 ---
trong đó W∈R2×D là một tham số có thể học được và eij∈RD là các sự tương tự được nhúng. Sau đó, biểu diễn của đoạn văn pi trở thành một chuỗi các embedding tương tự Epi = [ei1;ei2;:::;eiL]∈RL×D, bao gồm thông tin tương tự giữa pi và các đoạn văn neo có nguồn gốc từ cả bộ truy xuất thưa và dày đặc. Những sự tương tự này cung cấp thông tin đáng kể cho sự cộng tác của các đoạn văn và giữ cả thuộc tính từ vựng và ngữ nghĩa từ các bộ truy xuất. Với cùng một quy trình, chúng tôi tính toán sự tương tự giữa truy vấn và neo, và rút ra biểu diễn truy vấn Eq = [eq1;eq2;:::;eqL]∈RL×D. Lưu ý rằng sự tương tự từ bộ truy xuất thưa và dày đặc được kéo dài và chuẩn hóa riêng lẻ trước khi chiếu tuyến tính, như mô tả trong Phương trình 3.

Do đó, chúng tôi có tổng cộng N + 1 chuỗi cộng tác, mỗi chuỗi đại diện cho một đoạn văn hoặc một truy vấn và bao gồm thông tin tương tự từ vựng và ngữ nghĩa của chúng với L đoạn văn neo.

2.3 Tương tác và Tổng hợp
Theo mô hình học tương tự chuỗi phổ biến trong lĩnh vực xử lý ngôn ngữ tự nhiên (Reimers và Gurevych, 2019; Gao et al., 2021b), chúng tôi mong đợi đo lường sự liên quan của truy vấn và đoạn văn với các chuỗi cộng tác của chúng trong không gian vectơ. Chúng tôi có được các biểu diễn vectơ này bằng tương tác theo neo và tổng hợp chuỗi trong HybRank.

Tương tác Theo Neo Các phần tử thứ j ej trong các chuỗi cộng tác E này cho biết sự tương tự giữa các đoạn văn được truy xuất và đoạn văn neo thứ j. Tầm quan trọng của các neo này khác nhau vì chúng được chọn bằng một chiến lược duy nhất. Cụ thể, một neo đáng được xem xét nhiều hơn nếu cho thấy mối tương quan mạnh với phần lớn các đoạn văn được truy xuất, và ngược lại.

Để đánh giá chất lượng của các đoạn văn neo, chúng tôi thực hiện tương tác theo neo. Cụ thể, đối với mỗi vị trí j, chúng tôi thu thập embedding tương tự thứ j ej từ chuỗi truy vấn và mọi chuỗi đoạn văn và tinh chỉnh chúng với một bộ mã hóa Transformer, được ký hiệu là
e'qj;e'1j;e'2j;:::;e'Nj = Transinter(eqj;e1j;e2j;:::;eNj); (5)
trong đó e'j∈RD. Các embedding vị trí được thêm vào ej theo thứ hạng của nó "i" để giữ lại thông tin thứ hạng đoạn văn. Sau đó, các chuỗi embedding tương tự E được chuyển đổi thành E' = [e'1;e'2;:::;e'L] và được tăng cường với thông tin quan trọng của các đoạn văn neo.

Tổng hợp Chuỗi Chúng tôi mã hóa các chuỗi này thành các vectơ dày đặc bằng cách tổng hợp các embedding tương tự được tăng cường. Cụ thể, chúng tôi thêm một embedding [CLS] vào đầu chuỗi cộng tác, đưa chuỗi mở rộng vào một bộ mã hóa Transformer khác và sử dụng đầu ra của [CLS] làm biểu diễn của pi, được công thức hóa như
hpi = Transaggr([CLS]‖E'pi)[CLS]; (6)
trong đó [CLS]∈R1×D, E'pi∈RL×D và ‖ biểu thị phép nối. hpi∈RD là biểu diễn vectơ của đoạn văn pi. Biểu diễn truy vấn hq∈RD được rút ra tương tự.

Trường Tiếp nhận và Độ phức tạp Thú vị, từ một góc độ khác, tương tác theo neo và tổng hợp chuỗi tương đương với một attention theo cột và một attention theo hàng được áp dụng trên ma trận được công thức hóa bởi sự tương tự của truy vấn, đoạn văn và neo. Trường tiếp nhận toàn cục được cung cấp bởi hai attention theo trục này (Ho et al., 2019). Do đó, vectơ tương tự xij cảm nhận với nhau, và các biểu diễn vectơ của truy vấn và đoạn văn nhận thức được thông tin cộng tác từ những vectơ khác.

Một cách tiếp cận trực tiếp hơn để có được trường tiếp nhận toàn cục là tương tác từng phần tử. Cụ thể, chúng ta có thể đưa việc nối của tất cả các chuỗi E vào một bộ mã hóa Transformer duy nhất, và xuất biểu diễn cho mỗi đoạn văn và truy vấn thông qua nhiều token [CLS] riêng biệt. Tuy nhiên, do phép toán self-attention trong Transformer, độ phức tạp tính toán của tương tác từng phần tử đạt O(N2L2). Ngược lại, phương pháp của chúng tôi giảm độ phức tạp xuống O(N2L+NL2), bằng cách phân tách attention từng phần tử trên ma trận tương tự thành attention theo trục. Lưu ý rằng độ phức tạp có thể được giảm thêm xuống O(NL+NL) nếu tận dụng các Transformer tuyến tính (Katharopoulos et al., 2020; Wang et al., 2020) thay vì Transformer vanilla.

2.4 Xếp hạng lại và Đào tạo
Xếp hạng lại Xem xét rằng truy vấn và đoạn văn đã được chuyển đổi thành các vectơ dày đặc được mã hóa với thông tin cộng tác, chúng tôi có một số lựa chọn thay thế để đánh giá sự tương tự vectơ như điểm liên quan giữa truy vấn và đoạn văn. Chúng tôi sử dụng tích vô hướng trong công trình này và do đó điểm liên quan giữa truy vấn q và pi được tính bằng
si = h>q hpi. (7)
Sau đó các đoạn văn được sắp xếp theo thứ tự giảm dần của điểm liên quan si với truy vấn.

Đào tạo Để gán điểm cao cho các đoạn văn liên quan và điểm thấp cho những đoạn không liên quan, HybRank cần kéo biểu diễn của các đoạn văn liên quan và truy vấn lại gần nhau, trong khi đẩy biểu diễn của những đoạn không liên quan càng xa truy vấn càng tốt. Vì có thể tồn tại nhiều hơn một đoạn văn tích cực trong danh sách, hàm mất mát softmax vanilla không thể được áp dụng trực tiếp cho HybRank. Chúng tôi sử dụng hàm mất mát tương phản có giám sát (Khosla et al., 2020) để đối phó với nhiều kết quả tích cực, thực hiện phép tổng trên các kết quả tích cực bên ngoài hàm log trong softmax. Hàm mất mát được công thức hóa như
L(q;P) = −1/|P+| Σpi∈P+ log[exp(si/τ)/Σpj∈P exp(sj/τ)]; (8)
trong đó |P+| là số lượng đoạn văn tích cực trong danh sách truy xuất, và τ là một nhiệt độ có thể điều chỉnh.

3 Thí nghiệm
3.1 Bộ dữ liệu
Natural Questions (Kwiatkowski et al., 2019) bao gồm các câu hỏi tiếng Anh thực từ công cụ tìm kiếm Google với các đoạn văn vàng từ các trang Wikipedia tiếng Anh và chú thích khoảng trả lời. Theo các thiết lập từ Karpukhin et al. (2020), chúng tôi báo cáo độ chính xác top-k của tập kiểm tra (R@k), đánh giá tỷ lệ phần trăm các truy vấn có top-k đoạn văn được truy xuất chứa câu trả lời.

MS MARCO (Bajaj et al., 2018) bao gồm các truy vấn tiếng Anh từ nhật ký tìm kiếm Bing và ban đầu được thiết kế cho hiểu đọc máy. Theo các công trình trước (Qu et al., 2021; Ren et al., 2021b), chúng tôi đánh giá R@k của tập phát triển cũng như Mean Reciprocal Rank (MRR), có nghĩa là trung bình nghịch đảo của thứ hạng đoạn văn liên quan đầu tiên được truy xuất.

TREC 2019/2020 (Craswell et al., 2020b,a) có nguồn gốc từ TREC 2019/2020 Deep Learning (DL) Track. Hai track này cung cấp thêm các truy vấn tìm kiếm Bing và yêu cầu truy xuất các đoạn văn từ kho dữ liệu MS MARCO. Chúng tôi sử dụng thiết lập chính thức và đánh giá NDCG@10 của HybRank được đào tạo trên MS MARCO với tập kiểm tra của chúng.

3.2 Chi tiết Triển khai
HybRank là một bộ xếp hạng lại có thể cắm được linh hoạt có thể được áp dụng trên các danh sách đoạn văn tùy ý bao gồm cả những danh sách đã được xếp hạng lại bởi các phương pháp khác. Do đó, chúng tôi kiểm tra HybRank không chỉ đối với các hệ thống truy xuất mà còn đối với các hệ thống có các bộ xếp hạng lại khác trong đó. Chúng tôi sử dụng các bộ truy xuất dày đặc vượt trội hơn các bộ thưa sau khi đào tạo trước tinh tế (Chang et al., 2020; Gao và Callan, 2021, 2022) và tinh chỉnh (Sachan et al., 2021), cũng như các bộ xếp hạng lại mạnh dựa trên cross-encoder, để khởi tạo danh sách đoạn văn. Chúng tôi đơn giản chọn tất cả các đoạn văn trong danh sách ban đầu làm neo. Tác động của các đoạn văn neo sẽ được thảo luận trong Phần 3.4. Các phương pháp này được triển khai sử dụng bộ công cụ RocketQA4 và bộ công cụ Pyserini (Lin et al., 2021a) được xây dựng trên Lucene5 và FAISS (Johnson et al., 2021).

Các siêu tham số trong HybRank như sau. Nhiệt độ t trong chuẩn hóa tính năng được đặt thành 100 và 10 cho sự tương tự thưa và dày đặc, tương ứng. Chúng tôi khởi tạo ngẫu nhiên một bộ mã hóa Transformer 2 lớp cho Transinter và 1 lớp cho Transaggr sử dụng Huggingface Transformers (Wolf et al., 2020). Chiều embedding, chiều lớp trong MLP và số lượng head lần lượt là 64, 256 và 8. Có tổng cộng 0,22M tham số. Nhiệt độ τ trong hàm mất mát là 0.07. Chúng tôi sử dụng trình tối ưu Adam với tốc độ học ban đầu 1×10^-3 với tỷ lệ warm-up 0.1, theo sau bởi sự suy giảm tốc độ học cosine. Chúng tôi sử dụng cắt gradient của 2 và weight decay của 1×10^-6. Chúng tôi đào tạo mô hình trong 100 epoch với kích thước batch 32, mất khoảng 13 giờ trên Natural Questions và 4 ngày trên MS MARCO. Tất cả các thí nghiệm được thực hiện trên một GPU NVIDIA RTX 3090 duy nhất.

3.3 Kết quả
Bảng 1 và Bảng 2 tóm tắt hiệu suất của HybRank và các baseline trên các bộ dữ liệu Natural Questions, MS MARCO và TREC 2019/2020. Kết quả đánh giá chi tiết hơn được liệt kê trong Phụ lục B. Một số baseline truy xuất được sử dụng liên quan đến cả sự tương tự thưa và dày đặc từ các góc độ khác nhau. DPR (Karpukhin et al., 2020) chọn các mẫu tiêu cực khó từ các đoạn văn được trả về bởi BM25; FiD-KD (Izacard và Grave, 2021) bắt đầu đào tạo lặp với các đoạn văn được truy xuất bằng BM25; TCT-ColBERT-v1 (Lin et al., 2020) đề xuất một sự xấp xỉ thay thế cho sự kết hợp tuyến tính của truy xuất dày đặc và thưa; TCT-ColBERT-v2 (Lin et al., 2021b) nghiên cứu thêm về kết hợp dày đặc-thưa về mặt chất lượng, thời gian và không gian. Ngoài ra, ANCE (Xiong et al., 2021) khám phá các kết quả tiêu cực mới thông qua tìm kiếm láng giềng gần nhất trong quá trình đào tạo mô hình; TAS-B (Hofstätter et al., 2021b) đề xuất các chiến lược lấy mẫu cân bằng để tạo thành các batch đào tạo có thông tin; DistilBERT-KD (Hofstätter et al., 2021a) tận dụng chưng cất kiến thức giữa các kiến trúc để đào tạo bất khả tri mô hình.

Từ kết quả chúng ta có thể quan sát thấy rằng HybRank cho thấy sự cải thiện nhất quán so với các bộ truy xuất thượng nguồn và thậm chí cả các bộ xếp hạng lại. Nhìn chung, HybRank dựa trên các baseline mạnh hơn có thể tạo ra kết quả xếp hạng lại tốt hơn. Ví dụ, HybRank được xây dựng trên bộ truy xuất của RocketQA vượt trội hơn HybRank được xây dựng trên DPR-Multi trên Natural Questions, và hiện tượng tương tự có thể được quan sát trên hầu hết các bộ truy xuất. Ngoài ra, HybRank được xây dựng trên các hệ thống có bộ xếp hạng lại cải thiện thêm hiệu suất trên cả hai bộ dữ liệu. Những kết quả này chứng minh lợi thế của việc xếp hạng lại dựa trên các bộ truy xuất có sẵn tùy ý và thậm chí cả các kết quả được xếp hạng lại khác, điều này phân biệt HybRank với các bộ xếp hạng lại khác.

Khía cạnh đáng ngạc nhiên nhất của những kết quả này là, bất chấp kết quả xếp hạng lại kém hơn, các bộ truy xuất có điểm thấp nhận được nhiều cải thiện tương đối từ HybRank hơn những bộ có điểm cao. Kết quả này có thể được giải thích bởi thực tế rằng HybRank dựa vào thông tin bổ sung đáng kể do sự tương tự thưa cung cấp. Các bộ truy xuất có điểm thấp nhận được thông tin có giá trị tương đối nhiều hơn từ sự tương tự thưa so với các bộ truy xuất có điểm cao, và do đó cải thiện hiệu suất nhiều hơn so với các bộ truy xuất thượng nguồn. Chúng tôi sẽ thảo luận thêm về kết hợp thưa-dày đặc trong Phần 3.4.

3.4 Phân tích
Trong phần này, chúng tôi thảo luận về tác động của các thành phần cốt lõi của HybRank: các tính năng kết hợp và cộng tác, tương tác theo neo và số lượng đoạn văn neo. Tất cả các thí nghiệm được thực hiện trên bộ dữ liệu Natural Questions với bộ truy xuất DPR-Multi.

Tính năng Cộng tác Sự khác biệt chính giữa HybRank và các công trình khác là, nó tận dụng thông tin cộng tác giữa các đoạn văn được truy xuất. Để xác minh tác động của sự cộng tác đoạn văn đối với việc xếp hạng lại, chúng tôi bỏ qua tính năng cộng tác trong "w/o collab" bằng cách thay thế chỉ sự tương tự truy vấn-đoạn văn cho các chuỗi cộng tác, tức là biểu diễn mỗi đoạn văn như một chuỗi một token theo sự tương tự của nó với truy vấn. Ngoài ra, chúng tôi loại trừ sự tương tự truy vấn-đoạn văn trong "w/o q-p" bằng cách biểu diễn truy vấn thông qua một token có thể học được thay vì chuỗi cộng tác được tổng hợp. Kết quả được trình bày trong Bảng 3, trong đó "retriever" biểu thị đánh giá của danh sách đoạn văn ban đầu.

Bảng 3 cho thấy rằng "w/o collab" hiển thị một mức tăng đáng kể so với "retriever", chứng minh rằng sự tương tự truy vấn-đoạn văn là một tính năng thiết yếu và không thể thiếu cho HybRank. Hiện tượng đáng chú ý nhất là, "w/o q-p" vượt qua "retriever" với một biên độ lớn, mặc dù thực tế rằng "w/o q-p" hoàn toàn không biết về truy vấn. Cụ thể, HybRank có khả năng phân biệt kết quả tích cực chỉ với thông tin cộng tác giữa các đoạn văn. Hơn nữa, đứng trên vai của sự tương tự truy vấn-đoạn văn, HybRank đạt được kết quả tốt hơn so với "w/o collab", điều này chứng minh đầy đủ khả năng xếp hạng lại của thông tin cộng tác.

Tương tác Theo Neo Ngoài chuỗi cộng tác, tương tác theo neo cung cấp sự cộng tác bổ sung giữa các chuỗi. Chúng tôi loại bỏ Transinter và trực tiếp tổng hợp chuỗi cộng tác được chiếu tuyến tính để nghiên cứu hiệu quả của tương tác theo neo.

Bảng 3 cho thấy rằng có một sự sụt giảm hiệu suất đáng chú ý khi không có tương tác theo neo. Sự khác biệt có thể được quy cho trường tiếp nhận bị hạn chế. "w/o inter" mã hóa riêng lẻ mỗi chuỗi cộng tác của truy vấn và đoạn văn thành các vectơ dày đặc mà không có tương tác theo neo. Theo cách này, sự liên quan của các chuỗi này chỉ được đánh giá trong không gian vectơ nơi thông tin chuỗi được nén nghiêm trọng và không đủ biểu đạt. Ngược lại, được trang bị tương tác theo neo, HybRank có khả năng có được trường tiếp nhận toàn cục. Mỗi phần tử trong các chuỗi này nắm bắt bối cảnh của các phần tử trong tất cả các chuỗi, cho phép biểu diễn vectơ có thông tin hơn và ước tính liên quan chi tiết.

Kết hợp Tính năng Mặc dù thực tế rằng sự tương tự của bộ truy xuất thưa và dày đặc phản ánh các khía cạnh ngôn ngữ khác nhau, tức là chồng chéo từ vựng và liên quan ngữ nghĩa, cả hai đều có xu hướng có thuộc tính cộng tác. Do đó, việc trộn truy xuất thưa và dày đặc từ góc độ cộng tác là tự nhiên và dễ dàng hơn. Để minh họa tính bổ sung của các tính năng thưa và dày đặc và sự cần thiết của kết hợp tính năng trong HybRank, chúng tôi riêng biệt xác thực hiệu ứng của hai tính năng riêng lẻ và sự kết hợp của chúng. Các loại bỏ được thực hiện không chỉ trên danh sách đoạn văn ban đầu được truy xuất bởi bộ truy xuất dày đặc, mà còn danh sách được truy xuất bởi bộ truy xuất thưa để đảm bảo tính toàn vẹn và so sánh.

--- TRANG 5 ---
R@1 R@5 R@10 R@20 R@50
retriever 45.82 68.12 75.24 80.30 84.57
r/d anchor 46.18 68.84 75.43 80.91 85.01
w/oq-p 47.12 69.17 75.54 80.47 85.07
w/o inter 49.92 69.61 76.32 81.02 84.99
w/o collab 50.78 72.91 79.28 83.10 85.79
HybRank 51.99 72.71 79.03 83.24 85.93

Bảng 3: Kết quả nghiên cứu loại bỏ cho các tính năng cộng tác, tương tác theo neo và các đoạn văn neo trên tập kiểm tra của Natural Questions.

Các xu hướng tương tự có thể được quan sát từ hai thiết lập thí nghiệm trong Bảng 4. Mức tăng hiệu suất bị hạn chế khi các bộ truy xuất được sử dụng cho truy xuất đoạn văn và tính toán tương tự giống nhau, nhưng tăng đáng kể khi chúng khác nhau. Hơn nữa, những cải thiện nhỏ bổ sung có thể được thấy với sự kết hợp của hai tính năng trên cả hai thiết lập. Những hiện tượng này tiết lộ rằng mức tăng hiệu suất chính có nguồn gốc từ bộ truy xuất khác với bộ trong giai đoạn truy xuất, trong khi cùng loại chỉ đóng vai trò hỗ trợ. Do đó, chúng tôi rút ra kết luận đáng tin cậy rằng các loại sự tương tự khác nhau cung cấp thông tin bổ sung bổ sung so với danh sách đoạn văn ban đầu.

list feature R@1 R@5 R@10 R@20 R@50
sparsenone 23.82 45.18 55.54 63.93 73.55
sparse 30.50 50.39 59.00 67.26 75.24
dense 47.01 64.68 70.39 74.49 77.81
hybrid 47.15 64.82 69.78 74.32 77.65
densenone 45.82 68.12 75.24 80.30 84.57
dense 46.70 68.45 75.04 80.19 84.88
sparse 50.89 71.86 78.98 83.16 85.90
hybrid 51.99 72.71 79.03 83.24 85.93

Bảng 4: Kết quả nghiên cứu loại bỏ cho kết hợp tính năng trên tập kiểm tra của Natural Questions.

Hơn nữa, bất kể tính năng được sử dụng, HybRank đạt được kết quả tốt hơn trên danh sách đoạn văn được truy xuất bởi bộ truy xuất dày đặc so với bộ thưa, vì nhiều kết quả tích cực hơn được chứa trong danh sách được truy xuất dày đặc. Điều này cũng chứng thực các phát hiện của Phần 3.3 rằng danh sách đoạn văn ban đầu vượt trội dẫn đến kết quả xếp hạng lại tốt hơn với HybRank.

Số lượng Đoạn văn Neo Chúng tôi đánh giá hiệu suất của HybRank dưới số lượng neo khác nhau để nghiên cứu tác động của nó. Điều có thể thấy rõ trong Hình 2 là sự tăng trưởng hiệu suất nhất quán khi số lượng neo L tăng. Triết lý cơ bản là, với nhiều đoạn văn neo hơn, danh sách đoạn văn có thể rút ra nhiều thỏa thuận hơn để tạo điều kiện cho sự cộng tác giữa các đoạn văn và giảm bớt sự phân tâm từ những đoạn nhiễu. Sự tương quan tích cực giữa hiệu suất và số lượng neo cho thấy hiệu ứng của thông tin cộng tác trong danh sách truy xuất.

Mặc dù có sự tăng trưởng nhất quán với số lượng neo, tốc độ tăng hiệu suất bắt đầu chậm lại khi số lượng neo lớn hơn 60. Các đoạn văn neo được sử dụng để rút ra thông tin cộng tác, và do đó với nhiều neo đa dạng hơn chúng ta có thể có được các tính năng cộng tác phân biệt hơn. Khi số lượng neo tiếp cận 100, sự đa dạng của các đoạn văn ổn định, dẫn đến hiệu suất ổn định với số lượng neo lớn hơn.

Khi L tăng đến một số rất lớn, mức độ liên quan trung bình của các neo sẽ suy giảm xuống mức thấp. Một mối quan tâm hợp lệ có thể là tập neo chất lượng kém sẽ làm ô nhiễm khía cạnh cộng tác. Do độ phức tạp tính toán O(L^2) của tổng hợp chuỗi trong HybRank, khó có thể thực hiện trực tiếp các thí nghiệm trên L lớn. Nhưng chúng tôi mô phỏng tập neo chất lượng kém bằng cách chọn ngẫu nhiên các đoạn văn neo từ kho dữ liệu C. "r/d anchor" trong Bảng 3 cho thấy rằng các neo ngẫu nhiên cải thiện hiệu suất một chút nhưng vẫn thua xa các neo liên quan, chứng minh lợi ích của thông tin cộng tác và ưu thế của chất lượng neo.

Tuy nhiên, việc lựa chọn các đoạn văn neo là linh hoạt. Lý tưởng nhất, việc lựa chọn đoạn văn neo được xây dựng tỉ mỉ hơn, ví dụ, phân cụm các đoạn văn từ kho dữ liệu và chọn một số cố định các tâm cụm làm neo, sẽ nâng cao hơn nữa hiệu suất và hiệu quả của HybRank. Chúng tôi để việc khám phá chiến lược lựa chọn neo khác làm công việc tương lai.

--- TRANG 6 ---
0520406080100
#Anchors46.047.048.049.050.051.052.0R@1
0520406080100
#Anchors68.069.070.071.072.073.0R@5
0520406080100
#Anchors75.576.076.577.077.578.078.579.0R@10
0520406080100
#Anchors80.581.081.582.082.583.0R@20
0520406080100
#Anchors84.684.885.085.285.485.685.8R@50

Hình 2: Nghiên cứu tác động về số lượng đoạn văn neo. Chúng tôi thực hiện các thí nghiệm trên tập kiểm tra của Natural Questions với số lượng neo 5;20;40;60;80;100. Số liệu của số lượng neo 0 biểu thị đánh giá của danh sách truy xuất ban đầu.

4 Công trình Liên quan
4.1 Truy xuất Văn bản
Truy xuất là giai đoạn đầu tiên của truy xuất thông tin yêu cầu độ bao phủ cao để bao gồm nhiều tài liệu liên quan hơn trong danh sách truy xuất. Các phương pháp thưa truyền thống như TF-IDF và BM25 (Robertson và Zaragoza, 2009) dựa vào sự chồng chéo từ vựng giữa truy vấn và tài liệu. Mặc dù đã thống trị lĩnh vực truy xuất văn bản trong thời gian dài, các phương pháp thưa này gặp phải vấn đề khoảng cách từ vựng (Berger et al., 2000), cụ thể là vấn đề từ đồng nghĩa. Để giải quyết vấn đề này, các kỹ thuật trước đó (Nogueira et al., 2019; Dai và Callan, 2020) sử dụng mạng nơ-ron để tăng cường các phương pháp thưa. Các phương pháp truy xuất dày đặc được đề xuất gần đây (Karpukhin et al., 2020; Xiong et al., 2021) trực tiếp mã hóa truy vấn và đoạn văn thành các vectơ dày đặc thông qua dual-encoder, nắm bắt ngữ nghĩa trong văn bản và cho phép tìm kiếm độ trễ thấp thông qua các thuật toán được tối ưu hóa cao, ví dụ FAISS (Johnson et al., 2021).

Hai loại phương pháp này không loại trừ lẫn nhau và điểm yếu của loại này là điểm mạnh của loại kia. Một số nhà nghiên cứu kết hợp các phương pháp thưa và dày đặc bằng kết hợp điểm, đào tạo cải tiến hoặc mô hình cân bằng giữa bộ truy xuất thưa và dày đặc. Karpukhin et al. (2020) lấy mẫu các kết quả tiêu cực khó từ bộ truy xuất thưa để đào tạo bộ truy xuất dày đặc. Seo et al. (2019), Khattab và Zaharia (2020) và Santhanam et al. (2022) lập chỉ mục các từ hoặc cụm từ thay vì tài liệu để có sự tương tự chi tiết hơn và hiệu quả cao hơn. Lin et al. (2020) và Luan et al. (2021) khám phá sự kết hợp điểm thưa-dày đặc tuyến tính và các lựa chọn thay thế của nó. Gao et al. (2021a) và Yang et al. (2021) tận dụng tín hiệu khớp từ vựng hoặc tương tác cấp token để đào tạo bộ truy xuất dày đặc.

Tuy nhiên, trong số các phương pháp này, kết hợp điểm thiếu tương tác đầy đủ của các phương pháp thưa và dày đặc, lập chỉ mục các đơn vị nhỏ hơn hy sinh hiệu quả, và đào tạo lại một loại bộ truy xuất với sự giúp đỡ của loại khác loại bỏ khả năng xếp hạng ban đầu của nó. Ngược lại, phương pháp của chúng tôi có thể được áp dụng cho danh sách đoạn văn tùy ý, kết hợp các thuộc tính từ vựng và ngữ nghĩa của các bộ truy xuất có sẵn và đồng thời đảm bảo tính tổng quát và linh hoạt.

4.2 Xếp hạng lại Văn bản
Giai đoạn thứ hai xếp hạng lại dựa trên kết quả của hệ thống truy xuất và nhằm tạo ra sự so sánh chi tiết hơn trong danh sách truy xuất. Thông thường, cross-encoder được sử dụng để nắm bắt tương tác giữa truy vấn và đoạn văn ở cấp độ token. Nogueira và Cho (2020) và Sun et al. (2021) sử dụng BERT (Devlin et al., 2019) để đạt được tương tác cấp token với cơ chế attention (Vaswani et al., 2017). Để giảm chi phí tính toán khổng lồ (Reimers và Gurevych, 2019), Khattab và Zaharia (2020) và Gao et al. (2020) đề xuất tương tác nhẹ trên biểu diễn dày đặc từ các bộ truy xuất. Trong khi dựa trên truy xuất giai đoạn đầu, các phương pháp này tính toán riêng lẻ sự liên quan cho mỗi đoạn văn được truy xuất, bỏ qua thông tin bổ sung được ngụ ý bởi toàn bộ danh sách và yêu cầu nhiều lần chạy.

Một số phương pháp phản hồi giả liên quan (He và Ounis, 2009; Zamani và Croft, 2016; Zamani et al., 2016) nhằm tinh chỉnh mô hình truy vấn với các tài liệu được truy xuất hàng đầu. Bối cảnh theo danh sách cũng được khám phá tốt trong các hệ thống gợi ý đa giai đoạn (Liu et al., 2022), chẳng hạn như PRM (Pei et al., 2019), coi mỗi mục như một token, học ảnh hưởng lẫn nhau giữa các mục bằng self-attention và xếp hạng lại tất cả các mục cùng nhau.

Khác với các phương pháp trước, chúng tôi trích xuất tính năng cộng tác từ danh sách truy xuất, biểu diễn truy vấn và mỗi đoạn văn như các chuỗi kết hợp và cộng tác, và đo lường sự liên quan giữa truy vấn và đoạn văn bằng các chuỗi này từ góc độ cộng tác.

5 Kết luận
Chúng tôi giới thiệu HybRank, một phương pháp xếp hạng lại đoạn văn kết hợp và cộng tác. HybRank trích xuất sự tương tự giữa các văn bản thông qua các bộ truy xuất có sẵn để tạo thành các chuỗi kết hợp và cộng tác làm biểu diễn của truy vấn và đoạn văn. Việc xếp hạng lại hiệu quả dựa trên các chuỗi này kết hợp các thuộc tính từ vựng và ngữ nghĩa của các bộ truy xuất thưa và dày đặc. Các thí nghiệm mở rộng xác nhận hiệu quả của HybRank trên danh sách đoạn văn tùy ý. Các nghiên cứu loại bỏ chi tiết điều tra tác động của các thành phần cốt lõi trong HybRank. Chúng tôi hy vọng công trình của chúng tôi có thể cung cấp cảm hứng cho các nhà nghiên cứu trong lĩnh vực truy xuất thông tin, và hướng nhiều khám phá hơn về sự cộng tác và tương quan giữa các văn bản.

Hạn chế
Chúng tôi đánh giá HybRank trên các bộ dữ liệu Natural Questions, MS MARCO và TREC 2019/2020, tập trung vào Hỏi đáp Miền mở tiếng Anh. Mặc dù không có thành phần nào trong HybRank được thiết kế đặc biệt cho tiếng Anh, việc xác minh HybRank trên các ngôn ngữ khác bị hạn chế. Ngoài ra, có nhiều nhiệm vụ truy xuất thông tin tổng quát hơn liên quan đến sự đa dạng hoặc phạm vi bao quát rộng hơn trong kết quả trả về. Xem xét khả năng thiếu thuộc tính cộng tác, liệu HybRank có thể tổng quát hóa cho các nhiệm vụ truy xuất bao phủ cao này vẫn chưa rõ ràng.

Vì kiến trúc bộ mã hóa Transformer được áp dụng trong tương tác và tổng hợp chuỗi, chi phí tính toán sẽ không thể chấp nhận được khi độ dài danh sách đoạn văn hoặc số lượng neo quá lớn. Đây cũng là lý do tại sao chúng tôi chỉ thực hiện các thí nghiệm với số lượng neo không quá 100. Ngoài ra, HybRank chỉ sử dụng sự tương tự được tính bởi các bộ truy xuất có sẵn làm tính năng đầu vào, và do đó thiếu tương tác đầy đủ giữa các đầu vào thô. Hiệu suất của HybRank có thể bị hạn chế bởi khả năng của các bộ truy xuất thượng nguồn. Làm thế nào để kết hợp tương tác của các đầu vào thô vào HybRank trong khi tránh chi phí tính toán khổng lồ vẫn là một vấn đề mở để điều tra thêm.

Tuyên bố Đạo đức
Công trình này tập trung vào cải thiện kết quả xếp hạng của các hệ thống truy xuất đoạn văn. Truy xuất là thành phần cơ bản cho nhiều nhiệm vụ hạ nguồn. Tuy nhiên, nó đặt ra rủi ro về thiên vị, lạm dụng và thông tin sai lệch do kết quả chưa chính xác. Thiên vị lựa chọn phát sinh từ thu thập dữ liệu, ví dụ thiên vị từ vựng, có thể tồn tại trong các bộ dữ liệu được sử dụng. Ngoài ra, vì phương pháp xếp hạng lại trong công trình này được xây dựng trên các bộ truy xuất có sẵn, thiên vị có thể phát sinh từ các bộ truy xuất thượng nguồn.

Lời cảm ơn
Công trình này được hỗ trợ bởi NSFC theo Hợp đồng U20A20183 và 62021001.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được dịch sang tiếng Việt sẽ rất dài, tôi sẽ chỉ dịch một số mục quan trọng đầu tiên]

Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, và Tong Wang. 2018. MS MARCO: Một bộ dữ liệu hiểu đọc máy được tạo ra bởi con người. arXiv:1611.09268.

Adam Berger, Rich Caruana, David Cohn, Dayne Freitag, và Vibhu Mittal. 2000. Bắc cầu qua khoảng cách từ vựng: Các phương pháp thống kê để tìm câu trả lời. Trong Kỷ yếu Hội nghị Quốc tế ACM SIGIR hàng năm về Nghiên cứu và Phát triển trong Truy xuất Thông tin, trang 192–199, Athens, Hy Lạp. ACM Press.

[Tiếp tục với các tài liệu tham khảo khác...]

--- TRANG 7 đến TRANG 17 ---
[Phần còn lại của tài liệu chứa các bảng kết quả chi tiết, số liệu thống kê về bộ dữ liệu, và các ví dụ minh họa về việc xếp hạng lại. Tôi sẽ dịch các phần quan trọng nhất:]

Natural Questions Test
R@1 R@5 R@20
DPR-Multi + HybRank 45.82 !51.99 ( +6.17 ) 68.12 !72.71 ( +4.59 ) 80.31 !83.24 ( +2.93 )
DPR-Single + HybRank 47.95 !53.13 ( +5.18 ) 69.39 !73.05 ( +3.66 ) 80.97 !82.99 ( +2.02 )
FiD-KD + HybRank 50.36 !52.85 ( +2.49 ) 74.10 !74.46 ( +0.36 ) 84.27 !84.49 ( +0.22 )
ANCE + HybRank 52.66 !53.63 ( +0.97 ) 72.66 !73.57 ( +0.91 ) 83.05 !83.88 ( +0.83 )
RocketQA-retriever + HybRank 51.74 !56.07 ( +4.33 ) 74.02 !77.04 ( +3.02 ) 83.99 !85.68 ( +1.69 )
RocketQA-reranker + HybRank 54.60 !59.83 ( +5.23 ) 76.59 !78.73 ( +2.14 ) 85.01 !86.40 ( +1.39 )
RocketQAv2-retriever + HybRank 55.57 !56.98 ( +1.41 ) 75.98 !76.65 ( +0.67 ) 84.46 !85.76 ( +1.30 )
RocketQAv2-reranker + HybRank 57.17 !59.50 ( +2.33 ) 75.98 !78.34 ( +2.36 ) 84.71 !86.26 ( +1.55 )

Bảng 1: Hiệu suất xếp hạng lại của HybRank trên Natural Questions từ một lần chạy duy nhất. Chúng tôi xây dựng HybRank dựa trên DPR (Karpukhin et al., 2020), FiD-KD (Izacard và Grave, 2021), ANCE (Xiong et al., 2021), RocketQA (Qu et al., 2021) và RocketQAv2 (Ren et al., 2021b). Hiệu suất của các baseline này và HybRank lần lượt ở bên trái và bên phải của mũi tên. Cải thiện do HybRank mang lại được đánh dấu bằng chữ đậm.

[Các bảng và hình ảnh khác trong tài liệu cũng tương tự được dịch, bao gồm kết quả trên MS MARCO, TREC, và các ví dụ minh họa về việc xếp hạng lại với các câu hỏi như "Ai là vua nước Anh năm 1756?" và "Where's Waldo là loại sách gì?"]

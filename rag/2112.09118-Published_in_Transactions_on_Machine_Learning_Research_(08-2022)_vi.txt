# 2112.09118.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2112.09118.pdf
# Kích thước tệp: 686136 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Truy xuất Thông tin Dày đặc Không giám sát với
Học Tương phản
Gautier Izacard♦,♣,♥gizacard@fb.com
Mathilde Caron♦,♥,♠mathilde@fb.com
Lucas Hosseini♦hoss@fb.com
Sebastian Riedel♦,/trianglesriedel@fb.com
Piotr Bojanowski♦bojanowski@fb.com
Armand Joulin♦ajoulin@fb.com
Edouard Grave♦egrave@fb.com
♦Meta AI Research,♣Ecole normale supérieure, PSL University,♥Inria,
♠Université Grenoble Alpes,/triangleUniversity College London
Đánh giá trên OpenReview: https: // openreview. net/ forum? id= jKN1pXi7b0
Tóm tắt
Gần đây, truy xuất thông tin đã chứng kiến sự xuất hiện của các bộ truy xuất dày đặc, sử dụng mạng
nơ-ron, như một thay thế cho các phương pháp thưa thớt cổ điển dựa trên tần số thuật ngữ. Những
mô hình này đã đạt được kết quả tiên tiến nhất trên các tập dữ liệu và nhiệm vụ nơi có sẵn các tập
huấn luyện lớn. Tuy nhiên, chúng không chuyển giao tốt cho các ứng dụng mới không có dữ liệu
huấn luyện, và bị vượt trội bởi các phương pháp tần số thuật ngữ không giám sát như BM25. Trong
công trình này, chúng tôi khám phá các giới hạn của học tương phản như một cách để huấn luyện
các bộ truy xuất dày đặc không giám sát và cho thấy nó dẫn đến hiệu suất mạnh trong các thiết lập
truy xuất khác nhau. Trên chuẩn BEIR, mô hình không giám sát của chúng tôi vượt trội BM25 trên
11 trong số 15 tập dữ liệu cho Recall@100. Khi được sử dụng như tiền huấn luyện trước khi tinh
chỉnh, hoặc trên vài nghìn ví dụ trong miền hoặc trên tập dữ liệu MS MARCO lớn, mô hình tương
phản của chúng tôi dẫn đến cải thiện trên chuẩn BEIR. Cuối cùng, chúng tôi đánh giá phương pháp
của mình cho truy xuất đa ngôn ngữ, nơi dữ liệu huấn luyện thậm chí còn khan hiếm hơn so với
tiếng Anh, và cho thấy phương pháp của chúng tôi dẫn đến hiệu suất không giám sát mạnh. Mô hình
của chúng tôi cũng thể hiện khả năng chuyển giao liên ngôn ngữ mạnh khi được tinh chỉnh chỉ trên
dữ liệu tiếng Anh có giám sát và đánh giá trên ngôn ngữ ít tài nguyên như Swahili. Chúng tôi cho
thấy rằng các mô hình không giám sát của chúng tôi có thể thực hiện truy xuất liên ngôn ngữ giữa
các hệ thống chữ viết khác nhau, chẳng hạn như truy xuất tài liệu tiếng Anh từ các truy vấn tiếng
Ả Rập, điều mà sẽ không thể thực hiện được với các phương pháp khớp thuật ngữ.

1 Giới thiệu
Truy xuất tài liệu là nhiệm vụ tìm kiếm các tài liệu liên quan trong một bộ sưu tập lớn để trả lời các truy vấn cụ thể.
Đây là một nhiệm vụ quan trọng bản thân nó và là một thành phần cốt lõi để giải quyết nhiều vấn đề xử lý ngôn ngữ
tự nhiên (NLP), chẳng hạn như trả lời câu hỏi miền mở (Chen et al., 2017a) hoặc kiểm tra sự thật (Thorne et al., 2018).
Theo truyền thống, các hệ thống truy xuất, hay bộ truy xuất, tận dụng các tương đồng từ vựng để khớp truy vấn và
tài liệu, sử dụng, chẳng hạn, trọng số TF-IDF hoặc BM25 (Robertson & Zaragoza, 2009). Những phương pháp này,
dựa trên các khớp gần như chính xác giữa các token của truy vấn và tài liệu, gặp phải khoảng cách từ vựng và không
khái quát tốt (Berger et al., 2000). Ngược lại, các phương pháp dựa trên mạng nơ-ron cho phép học tập vượt ra
ngoài các tương đồng từ vựng, dẫn đến hiệu suất tiên tiến nhất trên các chuẩn trả lời câu hỏi, chẳng hạn như MS
MARCO (Nguyen et al., 2016) hoặc NaturalQuestions (Kwiatkowski et al., 2019).
Các kết quả truy xuất mạnh mẽ của mạng nơ-ron đã có thể thực hiện được cho các miền và ứng dụng nơi có sẵn các
tập dữ liệu huấn luyện lớn. Trong trường hợp truy xuất, việc tạo ra những tập dữ liệu này đòi hỏi phải khớp thủ công
các truy vấn với các tài liệu liên quan trong bộ sưu tập. Điều này khó có thể thực hiện khi bộ sưu tập

--- TRANG 2 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
chứa hàng triệu hoặc hàng tỷ phần tử, dẫn đến nhiều tình huống mà chỉ có một vài ví dụ trong miền, nếu có, là có sẵn.
Một giải pháp tiềm năng là huấn luyện một bộ truy xuất dày đặc trên một tập dữ liệu truy xuất lớn như MS MARCO,
và sau đó áp dụng nó cho các miền mới, một thiết lập được gọi là zero-shot. Thật không may, trong thiết lập này,
các bộ truy xuất dày đặc thường bị vượt trội bởi các phương pháp cổ điển dựa trên tần số thuật ngữ, không đòi hỏi
giám sát (Thakur et al., 2021). Hơn nữa, các tập dữ liệu được chú thích lớn thường không có sẵn ở các ngôn ngữ
khác ngoài tiếng Anh. Do đó, việc sử dụng các bộ sưu tập lớn dữ liệu có giám sát không phù hợp để huấn luyện các
hệ thống truy xuất đa ngôn ngữ.

Một thay thế tự nhiên cho học chuyển giao là học không giám sát, điều này đặt ra câu hỏi sau: liệu có thể huấn luyện
các bộ truy xuất dày đặc mà không cần giám sát, và đạt được hiệu suất của BM25 không? Huấn luyện các bộ truy xuất
dày đặc mà không cần giám sát có thể đạt được bằng cách sử dụng một nhiệm vụ phụ trợ xấp xỉ truy xuất. Cho một
tài liệu, người ta có thể tạo ra một truy vấn tổng hợp và sau đó huấn luyện mạng để truy xuất tài liệu gốc, trong số
nhiều tài liệu khác, cho truy vấn đó. Nhiệm vụ Cloze nghịch đảo (ICT), được đề xuất bởi Lee et al. (2019) để tiền
huấn luyện các bộ truy xuất, sử dụng một câu cho trước làm truy vấn và dự đoán ngữ cảnh xung quanh nó. Mặc dù
cho thấy kết quả đầy hứa hẹn như tiền huấn luyện (Chang et al., 2020; Sachan et al., 2021), phương pháp này vẫn
thua kém BM25 khi được sử dụng như một bộ truy xuất zero-shot. ICT có liên quan mạnh với học tương phản (Wu
et al., 2018), đã được áp dụng rộng rãi trong thị giác máy tính (Chen et al., 2020; He et al., 2020). Đặc biệt, các mô
hình thị giác máy tính được huấn luyện với các phương pháp học tương phản mới nhất đã dẫn đến các đặc trưng phù
hợp tốt cho truy xuất (Caron et al., 2021). Do đó, chúng tôi đề xuất xem xét lại mức độ hoạt động tốt của học tương
phản để huấn luyện các bộ truy xuất dày đặc mà không cần giám sát.

Trong bài báo này, chúng tôi đóng góp những điều sau. Thứ nhất, chúng tôi cho thấy rằng học tương phản có thể
dẫn đến các bộ truy xuất không giám sát mạnh: mô hình của chúng tôi đạt được kết quả Recall@100 cạnh tranh với
BM25 trên hầu hết chuẩn BEIR. Thứ hai, trong thiết lập few-shot, chúng tôi cho thấy rằng mô hình của chúng tôi
được hưởng lợi từ một vài ví dụ huấn luyện, và đạt được kết quả tốt hơn so với việc chuyển giao các mô hình từ các
tập dữ liệu lớn như MS MARCO. Thứ ba, khi được sử dụng như một phương pháp tiền huấn luyện trước khi tinh
chỉnh trên MS MARCO, kỹ thuật của chúng tôi dẫn đến hiệu suất mạnh trên chuẩn BEIR. Chúng tôi thực hiện các
nghiên cứu loại bỏ để chứng minh các lựa chọn thiết kế của mình, và cho thấy rằng cắt xén hoạt động tốt hơn nhiệm
vụ Cloze nghịch đảo. Cuối cùng, chúng tôi huấn luyện một bộ truy xuất dày đặc đa ngôn ngữ với học tương phản và
cho thấy nó đạt được hiệu suất tiên tiến nhất.

Mã và các mô hình được tiền huấn luyện có sẵn tại: https://github.com/facebookresearch/contriever .

2 Công trình liên quan
Trong phần này, chúng tôi xem xét ngắn gọn các công trình có liên quan trong truy xuất thông tin, và ứng dụng của
học máy vào vấn đề này. Đây không phải là một đánh giá toàn diện, và chúng tôi giới thiệu độc giả đến Manning et
al. (2008), Mitra et al. (2018) và Lin et al. (2020) để có một giới thiệu đầy đủ hơn về lĩnh vực này.

Truy xuất thông tin dựa trên tần số thuật ngữ. Theo lịch sử, trong truy xuất thông tin, các tài liệu và
truy vấn được biểu diễn dưới dạng các vectơ thưa thớt trong đó mỗi phần tử của vectơ tương ứng với một thuật ngữ
của từ vựng. Các sơ đồ cân nhắc khác nhau đã được đề xuất, để xác định mức độ quan trọng của một thuật ngữ cụ
thể đối với một tài liệu trong một tập dữ liệu lớn. Một trong những sơ đồ cân nhắc được sử dụng nhiều nhất được
gọi là TF-IDF, và dựa trên tần số tài liệu nghịch đảo, hoặc tính đặc hiệu của thuật ngữ (Jones, 1972). BM25, vẫn
được sử dụng rộng rãi ngày nay, mở rộng TF-IDF (Robertson et al., 1995). Một hạn chế nổi tiếng của những phương
pháp này là chúng dựa vào khớp gần như chính xác để truy xuất tài liệu. Điều này dẫn đến việc giới thiệu phân tích
ngữ nghĩa tiềm ẩn (Deerwester et al., 1990), trong đó các tài liệu được biểu diễn dưới dạng các vectơ dày đặc chiều
thấp.

Truy xuất thông tin dựa trên mạng nơ-ron. Theo sau sự ứng dụng thành công của các phương pháp học sâu
vào xử lý ngôn ngữ tự nhiên, các kỹ thuật mạng nơ-ron đã được giới thiệu cho truy xuất thông tin. Huang et al.
(2013) đề xuất một mô hình túi từ sâu, trong đó các biểu diễn của truy vấn và tài liệu được tính toán một cách độc
lập. Một điểm số liên quan sau đó được thu được bằng cách lấy tích vô hướng giữa các biểu diễn, và mô hình được
huấn luyện end-to-end trên dữ liệu nhấp chuột từ một công cụ tìm kiếm. Phương pháp này sau đó được tinh chỉnh
bằng cách thay thế mô hình túi từ bằng mạng nơ-ron tích chập (Shen et al., 2014) hoặc mạng nơ-ron hồi quy (Palangi
et al., 2016). Một hạn chế của bi-encoder là các truy vấn và tài liệu được biểu diễn bởi một vectơ duy nhất, ngăn cản
mô hình nắm bắt các tương tác tinh tế giữa các thuật ngữ. Nogueira & Cho

--- TRANG 3 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
(2019) giới thiệu một mô hình cross-encoder, dựa trên mô hình BERT (Devlin et al., 2019), mã hóa đồng thời truy vấn
và tài liệu. Việc áp dụng một mô hình được tiền huấn luyện mạnh mẽ, cũng như kiến trúc cross-encoder, dẫn đến cải
thiện quan trọng trên chuẩn MS MARCO (Bajaj et al., 2016).

Các phương pháp được mô tả trong đoạn trước đã được áp dụng để tái xếp hạng tài liệu, được truy xuất bằng một
hệ thống IR truyền thống như BM25. Gillick et al. (2018) đầu tiên nghiên cứu liệu các bộ truy xuất liên tục, dựa
trên các mô hình nơ-ron bi-encoder, có thể là một thay thế khả thi cho tái xếp hạng. Trong bối cảnh trả lời câu hỏi,
Karpukhin et al. (2020) giới thiệu một bộ truy xuất đoạn văn dày đặc (DPR) dựa trên kiến trúc bi-encoder. Mô hình
này được khởi tạo với một mạng BERT, và được huấn luyện phân biệt sử dụng các cặp truy vấn và tài liệu liên quan,
với các negative khó từ BM25. Xiong et al. (2020) mở rộng thêm công trình này bằng cách khai thác các negative
khó với chính mô hình trong quá trình tối ưu hóa, và huấn luyện trên tập dữ liệu MS MARCO. Một khi một bộ sưu
tập tài liệu, chẳng hạn như các bài viết Wikipedia, được mã hóa, truy xuất được thực hiện với một thư viện k-nearest
neighbors nhanh như FAISS Johnson et al. (2019). Để giảm bớt các hạn chế của bi-encoder, Humeau et al. (2019)
giới thiệu kiến trúc poly-encoder, nơi các tài liệu được mã hóa bởi nhiều vectơ. Tương tự, Khattab et al. (2020) đề
xuất mô hình ColBERT, giữ một biểu diễn vectơ cho mỗi thuật ngữ của truy vấn và tài liệu. Để làm cho truy xuất
có thể thực hiện được, hàm ở mức thuật ngữ được xấp xỉ để đầu tiên truy xuất một tập ứng viên ban đầu, sau đó
được tái xếp hạng với điểm số thực. Trong bối cảnh trả lời câu hỏi, chưng cất kiến thức đã được sử dụng để huấn
luyện các bộ truy xuất, hoặc sử dụng điểm số attention của reader của nhiệm vụ downstream như nhãn tổng hợp
(Izacard & Grave, 2020a), hoặc điểm số liên quan từ một cross encoder (Yang & Seo, 2020). Luan et al. (2020) so
sánh, về mặt lý thuyết và thực nghiệm, hiệu suất của các bộ truy xuất thưa thớt và dày đặc, bao gồm bi-, cross- và
poly-encoder. Các bộ truy xuất dày đặc, chẳng hạn như DPR, có thể dẫn đến các chỉ mục nặng gần 100GB khi mã
hóa các bộ sưu tập tài liệu như Wikipedia. Izacard et al. (2020) cho thấy cách nén các chỉ mục như vậy, với tác động
hạn chế đến hiệu suất, làm cho chúng thực tế hơn để sử dụng.

Học tự giám sát cho NLP. Theo sau thành công của word2vec (Mikolov et al., 2013), nhiều kỹ thuật tự giám sát
đã được đề xuất để học biểu diễn văn bản. Ở đây, chúng tôi xem xét ngắn gọn những kỹ thuật liên quan nhất đến
phương pháp của chúng tôi: các mô hình ở mức câu và các kỹ thuật tương phản. Jernite et al. (2017) giới thiệu các
hàm mục tiêu khác nhau để học biểu diễn câu, bao gồm dự đoán câu tiếp theo và dự đoán thứ tự câu. Những mục
tiêu này sau đó được sử dụng trong các mô hình được tiền huấn luyện dựa trên transformer, chẳng hạn như BERT
(Devlin et al., 2019) và AlBERT (Lan et al., 2019). Trong bối cảnh truy xuất, Lee et al. (2019) giới thiệu nhiệm vụ
cloze nghịch đảo (ICT), mục đích là dự đoán ngữ cảnh xung quanh một đoạn văn bản. Guu et al. (2020) tích hợp
một mô hình truy xuất bi-encoder trong một sơ đồ tiền huấn luyện BERT. Các tài liệu được truy xuất được sử dụng
như ngữ cảnh bổ sung trong nhiệm vụ BERT, và toàn bộ hệ thống được huấn luyện end-to-end theo cách không
giám sát. Tương tự, Lewis et al. (2020) đề xuất huấn luyện đồng thời một bộ truy xuất và một mô hình seq2seq
sinh, sử dụng huấn luyện tự giám sát. Chang et al. (2020) so sánh các nhiệm vụ tiền huấn luyện khác nhau cho truy
xuất, bao gồm nhiệm vụ cloze nghịch đảo. Trong bối cảnh xử lý ngôn ngữ tự nhiên, Fang et al. (2020) đề xuất áp
dụng MoCo nơi các cặp câu tích cực được thu được bằng dịch ngược. Các công trình khác nhau đã bổ sung mục tiêu
mô hình ngôn ngữ có mặt nạ với một mất mát tương phản (Giorgi et al., 2020; Wu et al., 2020; Meng et al., 2021).
SBERT (Reimers & Gurevych, 2019) sử dụng một mạng Siamese tương tự như học tương phản để học một mô hình
giống BERT được điều chỉnh để khớp embedding câu. Công thức của họ tương tự như công trình của chúng tôi nhưng
đòi hỏi các cặp câu được căn chỉnh để tạo thành các cặp tích cực trong khi chúng tôi đề xuất sử dụng tăng cường dữ
liệu để tận dụng các kho văn bản lớn không được căn chỉnh. Đồng thời với công trình này, Gao & Callan (2021)
cũng đã cho thấy tiềm năng của học tương phản cho truy xuất thông tin; xây dựng trên cùng một quan sát rằng cả
hai nhiệm vụ đều chia sẻ một cấu trúc tương tự. Spider (Ram et al., 2021), một công trình đương thời, sử dụng các
đoạn xuất hiện nhiều lần trong một tài liệu để tạo ra các ví dụ giả cho học tương phản nhằm huấn luyện các bộ truy
xuất không giám sát. Cuối cùng, Chen et al. (2021) huấn luyện một bộ truy xuất dày đặc để bắt chước các phương
pháp không giám sát dựa trên từ vựng. Điều này cải thiện hiệu suất trên một loạt các nhiệm vụ và đạt được kết quả
tiên tiến nhất khi kết hợp bộ truy xuất dày đặc kết quả với Contriever, mô hình được tiền huấn luyện của chúng tôi
với học tương phản.

3 Phương pháp
Trong phần này, chúng tôi mô tả cách huấn luyện một bộ truy xuất dày đặc mà không cần giám sát. Chúng tôi xem
xét kiến trúc mô hình và sau đó mô tả học tương phản — một thành phần quan trọng của quá trình huấn luyện.

--- TRANG 4 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Mục tiêu của một bộ truy xuất là tìm kiếm các tài liệu liên quan trong một bộ sưu tập lớn cho một truy vấn cho trước.
Do đó, bộ truy xuất nhận đầu vào là tập hợp các tài liệu và truy vấn và đưa ra một điểm số liên quan cho mỗi tài liệu.
Một phương pháp tiêu chuẩn là mã hóa mỗi cặp truy vấn-tài liệu bằng một mạng nơ-ron (Nogueira & Cho, 2019).
Quy trình này đòi hỏi phải mã hóa lại mọi tài liệu cho bất kỳ truy vấn mới nào và do đó không mở rộng quy mô cho
các bộ sưu tập tài liệu lớn. Thay vào đó, chúng tôi tuân theo các phương pháp tiêu chuẩn (Huang et al., 2013;
Karpukhin et al., 2020) trong truy xuất thông tin và sử dụng kiến trúc bi-encoder nơi các tài liệu và truy vấn được
mã hóa một cách độc lập. Điểm số liên quan giữa một truy vấn và một tài liệu được cho bởi tích vô hướng giữa các
biểu diễn của chúng sau khi áp dụng bộ mã hóa. Cụ thể hơn, cho một truy vấn q và tài liệu d, chúng tôi mã hóa mỗi
cái một cách độc lập bằng cùng một mô hình, fθ, được tham số hóa bởi θ. Điểm số liên quan s(q,d) giữa một truy
vấn q và một tài liệu d sau đó là tích vô hướng của các biểu diễn kết quả:

s(q,d) = ⟨fθ(q),fθ(d)⟩.

Trong thực tế, chúng tôi sử dụng một mạng transformer cho fθ để nhúng cả truy vấn và tài liệu. Ngoài ra, hai bộ mã
hóa khác nhau có thể được sử dụng để mã hóa truy vấn và tài liệu tương ứng như trong DPR (Karpukhin et al.,
2020). Từ kinh nghiệm thực nghiệm, chúng tôi quan sát thấy rằng việc sử dụng cùng một bộ mã hóa, như trong
Xiong et al. (2020) và Reimers & Gurevych (2019), thường cải thiện tính mạnh mẽ trong bối cảnh chuyển giao
zero-shot hoặc học few-shot, trong khi không có tác động trong các thiết lập khác. Cuối cùng, biểu diễn fθ(q) (tương
ứng fθ(d)) cho một truy vấn (tương ứng tài liệu) được thu được bằng cách tính trung bình các biểu diễn ẩn của tầng
cuối cùng. Theo các công trình trước đây về truy xuất dày đặc với mạng nơ-ron, chúng tôi sử dụng kiến trúc BERT
base uncased và giới thiệu độc giả đến Devlin et al. (2019) để biết thêm chi tiết.

3.1 Huấn luyện không giám sát trên các tài liệu không được căn chỉnh
Trong phần này, chúng tôi mô tả phương pháp huấn luyện không giám sát của chúng tôi. Chúng tôi xem xét ngắn gọn
hàm mất mát được sử dụng truyền thống trong học tương phản và cũng được sử dụng trong ICT (Lee et al., 2019).
Sau đó chúng tôi thảo luận về việc thu được các cặp tích cực từ một tài liệu văn bản duy nhất, một thành phần quan
trọng cho paradigm huấn luyện này.

3.1.1 Học tương phản
Học tương phản là một phương pháp dựa trên thực tế rằng mọi tài liệu, theo một cách nào đó, đều là duy nhất. Tín
hiệu này là thông tin duy nhất có sẵn khi không có giám sát thủ công. Một mất mát tương phản được sử dụng để học
bằng cách phân biệt giữa các tài liệu. Mất mát này so sánh các cặp biểu diễn tài liệu tích cực (từ cùng một tài liệu)
hoặc tiêu cực (từ các tài liệu khác nhau). Chính thức, cho một truy vấn q với một tài liệu tích cực liên kết k+, và một
nhóm các tài liệu tiêu cực (ki)i=1..K, mất mát InfoNCE tương phản được định nghĩa là:

L(q,k+) = −exp(s(q,k+)/τ) / (exp(s(q,k+)/τ) + ∑Ki=1exp(s(q,ki)/τ)), (1)

trong đó τ là một tham số nhiệt độ. Mất mát này khuyến khích các cặp tích cực có điểm số cao và các cặp tiêu cực có
điểm số thấp. Một cách diễn giải khác của hàm mất mát này như sau: cho biểu diễn truy vấn q, mục tiêu là khôi phục,
hoặc truy xuất, biểu diễn k+ tương ứng với tài liệu tích cực, trong số tất cả các negative ki. Trong phần tiếp theo,
chúng tôi gọi các biểu diễn phía bên trái trong điểm số s là truy vấn và các biểu diễn phía bên phải là khóa.

3.1.2 Xây dựng các cặp tích cực từ một tài liệu duy nhất
Một yếu tố quan trọng của học tương phản là cách xây dựng các cặp tích cực từ một đầu vào duy nhất. Trong thị
giác máy tính, bước này dựa vào việc áp dụng hai phép tăng cường dữ liệu độc lập cho cùng một hình ảnh, dẫn đến
hai "quan điểm" tạo thành một cặp tích cực (Wu et al., 2018; Chen et al., 2020). Trong khi chúng tôi xem xét các
phép biến đổi văn bản độc lập tương tự, chúng tôi cũng khám phá các phép biến đổi phụ thuộc được thiết kế để giảm
tương quan giữa các quan điểm.

Nhiệm vụ Cloze nghịch đảo là một phép tăng cường dữ liệu tạo ra hai quan điểm loại trừ lẫn nhau của một tài liệu,
được giới thiệu trong bối cảnh truy xuất bởi Lee et al. (2019). Quan điểm đầu tiên được thu được bằng cách lấy mẫu
ngẫu nhiên một đoạn token từ một phân đoạn văn bản, trong khi phần bù của đoạn tạo thành quan điểm thứ hai. Cụ
thể, cho một chuỗi văn bản (w1,...,wn), ICT lấy mẫu một đoạn (wa,...,wb), trong đó 1≤a≤b≤n, sử dụng

--- TRANG 5 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Trec-COVID Tóuche-2020NFCorpusScidocsDBPedia
Climate-feverFiQA
CQADupStackMSMARCOHotpotQANQ
ArguAnaScifactFever QuoraAvg.050100Recall@100REALM SimCSE BM25 Contriever
Hình 1: Truy xuất không giám sát. Chúng tôi so sánh tiền huấn luyện của chúng tôi mà không sử dụng bất kỳ dữ liệu được chú thích nào với REALM (Guu et al., 2020), SimCSE (Gao et al., 2021) và BM25. Đối với SimCSE chúng tôi báo cáo kết quả của mô hình sử dụng RoBERTa large. REALM sử dụng dữ liệu nhận dạng thực thể được chú thích để huấn luyện. Chúng tôi nhấn mạnh rằng tiền huấn luyện không giám sát của chúng tôi tương đương với BM25 nhưng trên 2 tập dữ liệu.

các token của đoạn làm truy vấn và phần bù (w1,...,wa−1,wb+1,...,wn) làm khóa. Trong triển khai gốc bởi Lee et al. (2019) đoạn tương ứng với một câu, và được giữ trong tài liệu 10% thời gian để khuyến khích khớp từ vựng. Nhiệm vụ Cloze nghịch đảo có liên quan chặt chẽ với nhiệm vụ Cloze sử dụng phần bù đoạn (w1,...,wa−1,wb+1,...,wn) làm truy vấn.

Cắt xén độc lập là một phép tăng cường dữ liệu độc lập phổ biến được sử dụng cho hình ảnh nơi các quan điểm được tạo ra một cách độc lập bằng cách cắt xén đầu vào. Trong bối cảnh văn bản, cắt xén tương đương với việc lấy mẫu một đoạn token. Chiến lược này do đó lấy mẫu độc lập hai đoạn từ một tài liệu để tạo thành một cặp tích cực. Trái ngược với nhiệm vụ cloze nghịch đảo, trong cắt xén cả hai quan điểm của ví dụ tương ứng với chuỗi con liền kề của dữ liệu gốc. Một sự khác biệt thứ hai giữa cắt xén và ICT là thực tế rằng cắt xén ngẫu nhiên độc lập là đối xứng: cả truy vấn và tài liệu đều tuân theo cùng một phân phối. Cắt xén độc lập cũng dẫn đến sự chồng chéo giữa hai quan điểm của dữ liệu, do đó khuyến khích mạng học các khớp chính xác giữa truy vấn và tài liệu, theo cách tương tự như các phương pháp khớp từ vựng như BM25. Trong thực tế, chúng ta có thể cố định độ dài của đoạn cho truy vấn và khóa, hoặc lấy mẫu chúng.

Tăng cường dữ liệu bổ sung. Cuối cùng, chúng tôi cũng xem xét các phép tăng cường dữ liệu bổ sung như xóa từ ngẫu nhiên, thay thế hoặc che dấu. Chúng tôi sử dụng những nhiễu loạn này ngoài việc cắt xén ngẫu nhiên.

3.1.3 Xây dựng tập hợp lớn các cặp tiêu cực
Một khía cạnh quan trọng của học tương phản là lấy mẫu một tập hợp lớn các negative. Hầu hết các framework tiêu chuẩn khác nhau về cách xử lý các negative, và chúng tôi mô tả ngắn gọn hai trong số chúng, lấy mẫu negative trong batch và MoCo, mà chúng tôi sử dụng trong công trình này.

Negative trong một batch. Một giải pháp đầu tiên là tạo ra các negative bằng cách sử dụng các ví dụ khác từ cùng một batch: mỗi ví dụ trong một batch được biến đổi hai lần để tạo ra các cặp tích cực, và chúng ta tạo ra negative bằng cách sử dụng các quan điểm từ các ví dụ khác trong batch. Chúng tôi sẽ gọi kỹ thuật này là "negative trong batch". Trong trường hợp đó, gradient được lan truyền ngược qua các biểu diễn của cả truy vấn và khóa. Một nhược điểm của phương pháp này là nó đòi hỏi kích thước batch cực lớn để hoạt động tốt Chen et al. (2020), với Qu et al. (2021) báo cáo cải thiện trong bối cảnh truy xuất thông tin lên đến 8192 negative. Phương pháp này đã được sử dụng rộng rãi để huấn luyện các mô hình truy xuất thông tin với dữ liệu có giám sát Chen et al. (2017b); Karpukhin et al. (2020) và cũng được xem xét khi sử dụng ICT để tiền huấn luyện các bộ truy xuất bởi Lee et al. (2019).

--- TRANG 6 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Các cặp tiêu cực qua các batch. Một phương pháp thay thế là lưu trữ các biểu diễn từ các batch trước đó trong một hàng đợi và sử dụng chúng như các ví dụ tiêu cực trong mất mát (Wu et al., 2018). Điều này cho phép kích thước batch nhỏ hơn nhưng thay đổi một chút mất mát bằng cách làm cho nó bất đối xứng giữa "truy vấn" (một trong những quan điểm được tạo ra từ các phần tử của batch hiện tại), và "khóa" (các phần tử được lưu trữ trong hàng đợi). Gradient chỉ được lan truyền ngược qua "truy vấn", và biểu diễn của "khóa" được coi như cố định. Trong thực tế, các đặc trưng được lưu trữ trong hàng đợi từ các batch trước đó đến từ các lần lặp trước đó của mạng. Điều này dẫn đến sụt giảm hiệu suất khi mạng thay đổi nhanh chóng trong quá trình huấn luyện. Thay vào đó, He et al. (2020) đề xuất tạo ra các biểu diễn của khóa từ một mạng thứ hai được cập nhật chậm hơn. Phương pháp này, được gọi là MoCo, xem xét hai mạng: một cho khóa, được tham số hóa bởi θk, và một của truy vấn, được tham số hóa bởi θq. Các tham số của mạng truy vấn được cập nhật với lan truyền ngược và giảm gradient ngẫu nhiên, tương tự như khi sử dụng negative trong batch, trong khi các tham số của mạng khóa, hoặc bộ mã hóa Momentum, được cập nhật từ các tham số của mạng truy vấn bằng cách sử dụng trung bình động theo hàm mũ:

θk ← mθk + (1−m)θq, (2)

trong đó m là tham số momentum có giá trị trong [0,1].

4 Thí nghiệm
Trong phần này, chúng tôi đánh giá thực nghiệm bộ truy xuất tốt nhất của chúng tôi được huấn luyện với học tương phản, được gọi là Contriever (bộ truy xuất tương phản), sử dụng MoCo với cắt xén ngẫu nhiên. Chúng tôi sử dụng một quy trình học tương phản khác với ICT (Lee et al., 2019) chủ yếu ở ba khía cạnh. Thứ nhất, các cặp tích cực được lấy mẫu bằng cách sử dụng cắt xén ngẫu nhiên và các token từ mỗi phần tử của cặp được xóa với xác suất 10%. Thứ hai, chúng tôi sử dụng MoCo nơi các negative bao gồm các phần tử từ các batch trước đó được lưu trữ trong một hàng đợi. Điều này cho phép mở rộng quy mô đến một số lượng lớn negative. Thứ ba, chúng tôi sử dụng dữ liệu từ Wikipedia và CCNet (Wenzek et al., 2020) để huấn luyện. Các nghiên cứu loại bỏ chứng minh những lựa chọn kỹ thuật này được thực hiện trong Phần 6. Các chi tiết kỹ thuật khác về mô hình của chúng tôi được đưa ra trong Phụ lục A.1.

4.1 Tập dữ liệu
Contriever được huấn luyện với học tương phản trên các tài liệu được lấy mẫu từ một hỗn hợp giữa dữ liệu Wikipedia và dữ liệu CCNet (Wenzek et al., 2020), nơi một nửa số batch được lấy mẫu từ mỗi nguồn.

Đầu tiên, chúng tôi đánh giá mô hình của mình trên hai tập dữ liệu trả lời câu hỏi: NaturalQuestions (Kwiatkowski et al., 2019) và TriviaQA (Joshi et al., 2017). Đối với cả hai tập dữ liệu, chúng tôi sử dụng các phiên bản miền mở như được giới thiệu bởi Lee et al. (2019), và bản dump Wikipedia tiếng Anh từ ngày 20 tháng 12 năm 2018 như bộ sưu tập tài liệu để truy xuất từ đó. Chúng tôi báo cáo độ chính xác truy xuất top-k, tức là số lượng câu hỏi mà ít nhất một trong số k đoạn văn hàng đầu chứa câu trả lời.

Thứ hai, chúng tôi sử dụng chuẩn BEIR, được giới thiệu bởi Thakur et al. (2021), chứa 18 tập dữ liệu truy xuất, tương ứng với chín nhiệm vụ, chẳng hạn như kiểm tra sự thật hoặc dự đoán trích dẫn, và bao gồm các miền khác nhau, chẳng hạn như Wikipedia hoặc các ấn phẩm khoa học. Hầu hết các tập dữ liệu từ BEIR không chứa tập huấn luyện, và trọng tâm của chuẩn là truy xuất zero-shot. Tuy nhiên, hầu hết các bộ truy xuất dựa trên học máy vẫn được huấn luyện trên dữ liệu có giám sát, chẳng hạn như tập dữ liệu truy xuất quy mô lớn MS MARCO (Bajaj et al., 2016). Theo thông례 tiêu chuẩn, chúng tôi báo cáo hai chỉ số trên chuẩn này: nDCG@10 và Recall@100. nDCG@10 tập trung vào xếp hạng của 10 tài liệu được truy xuất hàng đầu, và tốt để đánh giá xếp hạng được trả về cho con người, ví dụ trong một công cụ tìm kiếm. Mặt khác, Recall@100 có liên quan để đánh giá các bộ truy xuất được sử dụng trong các hệ thống học máy, chẳng hạn như trả lời câu hỏi. Thực vậy, các mô hình như vậy có thể xử lý hàng trăm tài liệu, và bỏ qua xếp hạng của chúng (Izacard & Grave, 2020b). Trong khi nDCG@10 là chỉ số chính của BEIR, chúng tôi quan tâm nhiều hơn đến Recall@100 để đánh giá bi-encoder, vì mục tiêu của chúng tôi là phát triển các bộ truy xuất có thể được sử dụng trong các hệ thống ML. Hơn nữa, trong nhiều thiết lập, các tài liệu được truy xuất có thể được tái xếp hạng bằng một mô hình mạnh hơn như cross-encoder, do đó cải thiện nDCG@10.

--- TRANG 7 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 1: Recall@k không giám sát trên các tập kiểm tra của NaturalQuestions và TriviaQA. Đối với Nhiệm vụ Cloze nghịch đảo và Đoạn văn nổi bật có mặt nạ, chúng tôi báo cáo kết quả của Sachan et al. (2021). Mô hình Đoạn văn nổi bật có mặt nạ sử dụng dữ liệu nhận dạng thực thể được chú thích. Đối với BM25, chúng tôi báo cáo kết quả của Ma et al. (2021)

NaturalQuestions TriviaQA
R@5 R@20 R@100 R@5 R@20 R@100
Nhiệm vụ Cloze nghịch đảo (Sachan et al., 2021) 32.3 50.9 66.8 40.2 57.5 73.6
Đoạn văn nổi bật có mặt nạ (Sachan et al., 2021) 41.7 59.8 74.9 53.3 68.2 79.4
BM25 (Ma et al., 2021) - 62.9 78.3 - 76.4 83.2
Contriever 47.867.882.1 59.474.283.2
mô hình có giám sát: DPR (Karpukhin et al., 2020) - 78.4 85.4 - 79.4 85.0
mô hình có giám sát: FiD-KD (Izacard & Grave, 2020a) 73.8 84.3 89.3 77.0 83.6 87.7

4.2 Baseline
Đầu tiên, chúng tôi so sánh Contriever với BM25, không đòi hỏi giám sát. Trên các tập dữ liệu QA, chúng tôi so sánh với các bộ truy xuất dày đặc được huấn luyện với ICT và Đoạn văn nổi bật có mặt nạ từ Sachan et al. (2021). Trên BEIR, chúng tôi xem xét bộ truy xuất từ REALM (Guu et al., 2020), và RoBERTa large được tinh chỉnh với SimCSE (Gao et al., 2021), như các bộ truy xuất dày đặc không giám sát. Chúng tôi cũng so sánh với các bộ truy xuất dựa trên ML được huấn luyện trên MS MARCO, được phân loại thành ba loại: thưa thớt, dày đặc và tương tác muộn. Đối với các phương pháp thưa thớt, chúng tôi so sánh với Splade v2 (Formal et al., 2021), tính toán các biểu diễn thưa thớt của tài liệu với mô hình được tiền huấn luyện BERT. Đối với các phương pháp dày đặc, chúng tôi sử dụng DPR (Karpukhin et al., 2020) và ANCE (Xiong et al., 2020), là các bi-encoder được huấn luyện trên dữ liệu có giám sát như NaturalQuestions hoặc MS MARCO. Chúng tôi cũng so sánh với TAS-B (Hofstätter et al., 2021), thực hiện chưng cất từ cross-encoder thành bi-encoder, và GenQ, tạo ra các cặp truy vấn-tài liệu tổng hợp với mô hình sinh. Đối với tương tác muộn, chúng tôi sử dụng ColBERT (Khattab et al., 2020), tính toán điểm số cặp giữa các biểu diễn có ngữ cảnh của truy vấn và tài liệu, cũng như một cross-encoder được sử dụng để tái xếp hạng tài liệu được truy xuất bằng BM25.

4.3 Kết quả
Đầu tiên, chúng tôi so sánh hiệu suất của các mô hình hoàn toàn không giám sát, tức là không tinh chỉnh trên MS MARCO hoặc dữ liệu được chú thích khác. Trong Bảng 1, chúng tôi báo cáo hiệu suất truy xuất trên hai tập dữ liệu trả lời câu hỏi: NaturalQuestions (Kwiatkowski et al., 2019) và TriviaQA (Joshi et al., 2017). Ở đây, mô hình của chúng tôi cạnh tranh với baseline BM25 mạnh (Ma et al., 2021), ví dụ dẫn đến cải thiện 3 điểm cho recall@100 trên NaturalQuestions. Nó cũng vượt trội các bộ truy xuất dày đặc được đề xuất trước đây đã được huấn luyện với ICT hoặc che đậy đoạn văn nổi bật. Trong Hình 1, chúng tôi báo cáo hiệu suất recall@100 của các mô hình không giám sát trên chuẩn BEIR. Thú vị là, chúng tôi quan sát thấy rằng trong thiết lập này, Contriever cạnh tranh so với BM25 trên tất cả các tập dữ liệu, ngoại trừ TREC-COVID và Tóuche-2020. Đặc biệt, nó đạt được hiệu suất tốt hơn BM25 trên 11 trong số 15 tập dữ liệu từ chuẩn cho recall@100. Contriever cũng vượt trội các bộ truy xuất dày đặc không giám sát được đề xuất trước đây, thường đạt được hiệu suất thấp hơn BM25. Đối với nDCG@10, chú trọng nhiều hơn vào các tài liệu được truy xuất đầu tiên, trong khi Contriever phần lớn thu hẹp khoảng cách giữa các bộ truy xuất không giám sát và BM25, nó vẫn bị vượt trội bởi BM25 như được báo cáo trong Bảng 11. Sự khác biệt chủ yếu do BM25 vượt trội đáng kể Contriever trên hai tập dữ liệu có đặc điểm cụ thể: Trec-COVID và Tóuche-2020. Trec-COVID là một tập dữ liệu truy xuất thông tin liên quan đến COVID. Tuy nhiên, dữ liệu được sử dụng để huấn luyện Contriever được thu thập trước khi bùng phát COVID, do đó chúng có thể không phù hợp. Tóuche-2020 chứa các tài liệu dài, điều này dường như không được hỗ trợ rất tốt bởi các bộ truy xuất nơ-ron dày đặc: ngay cả sau khi huấn luyện có giám sát, các mô hình vẫn thua kém BM25. Nhìn chung, những kết quả này cho thấy tiềm năng của học tương phản để huấn luyện các bộ truy xuất dày đặc hoàn toàn không giám sát.

--- TRANG 8 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 2: Chuẩn BEIR. Chúng tôi báo cáo nDCG@10 trên các tập kiểm tra từ chuẩn BEIR cho các phương pháp bi-encoder không có bộ tái xếp hạng. Chúng tôi cũng báo cáo trung bình và số lượng tập dữ liệu mà một phương pháp là tốt nhất ("Tốt nhất trên") trên toàn bộ chuẩn BEIR (loại trừ ba tập dữ liệu vì giấy phép của chúng). In đậm là tốt nhất tổng thể. MS MARCO được loại trừ khỏi trung bình. "CE" đề cập đến cross-encoder.

BM25 BM25+CE DPR ANCE TAS-B Gen-Q ColBERT Splade v2 Ours Ours+CE
MS MARCO 22.8 41.3 17.7 38.8 40.8 40.8 40.1 43.3 40.7 47.0
Trec-COVID 65.6 75.7 33.2 65.4 48.1 61.9 67.7 71.0 59.6 70.1
NFCorpus 32.5 35.0 18.9 23.7 31.9 31.9 30.5 33.4 32.8 34.4
NQ 32.9 53.3 47.4 44.6 46.3 35.8 52.4 52.1 49.8 57.7
HotpotQA 60.3 70.7 39.1 45.6 58.4 53.4 59.3 68.4 63.8 71.5
FiQA 23.6 34.7 11.2 29.5 30.0 30.8 31.7 33.6 32.9 36.7
ArguAna 31.5 31.1 17.5 41.5 42.9 49.3 23.3 47.9 44.6 41.3
Touche-2020 36.7 27.1 13.1 24.0 16.2 18.2 20.2 36.4 23.0 29.8
CQADupStack 29.9 37.0. 15.3 29.6 31.4 34.7 35.0 - 34.5 37.7
Quora 78.9 82.5 24.8 85.2 83.5 83.0 85.4 83.8 86.5 82.4
DBPedia 31.3 40.9 26.3 28.1 38.4 32.8 39.2 43.5 41.3 47.1
Scidocs 15.8 16.6 7.7 12.2 14.9 14.3 14.5 15.8 16.5 17.1
FEVER 75.3 81.9 56.2 66.9 70.0 66.9 77.1 78.6 75.8 81.9
Climate-FEVER 21.3 25.3 14.8 19.8 22.8 17.5 18.4 23.5 23.7 25.8
Scifact 66.5 68.8 31.8 50.7 64.3 64.4 67.1 69.3 67.7 69.2
Trung bình không CQA 44.0 49.5 26.3 41.3 43.7 43.1 45.1 50.6 47.5 51.2
Trung bình 43.0 48.6 25.5 40.5 42.8 42.5 44.4 - 46.6 50.2
Tốt nhất trên 1 3 0 0 0 1 0 1 1 9

Bảng 3: Truy xuất few-shot. nDCG@10 kiểm tra sau khi huấn luyện trên một tập huấn luyện trong miền nhỏ. Chúng tôi so sánh BERT và mô hình của chúng tôi, có và không có bước tinh chỉnh trung gian trên MS MARCO. Lưu ý rằng tiền huấn luyện không giám sát của chúng tôi một mình vượt trội BERT với tinh chỉnh trung gian MS MARCO.

Dữ liệu bổ sung SciFact NFCorpus FiQA
# truy vấn 729 2,590 5,500
BM25 - 66.5 32.5 23.6
BERT - 75.2 29.9 26.1
Contriever - 84.0 33.6 36.4
BERT ms marco 80.9 33.2 30.9
Contriever ms marco 84.8 35.8 38.1

Tiếp theo, chúng tôi báo cáo nDCG@10 trên chuẩn BEIR cho các bộ truy xuất khác nhau được huấn luyện trên MS MARCO trong Bảng 2 (recall@100 có thể tìm thấy trong Bảng 10 của phụ lục). Chúng tôi báo cáo riêng lẻ kết quả trên mỗi tập dữ liệu cũng như trung bình trên 14 tập dữ liệu của Chuẩn BEIR (loại trừ 3 vì lý do giấy phép). Chúng tôi quan sát thấy rằng khi được sử dụng như tiền huấn luyện, học tương phản dẫn đến hiệu suất mạnh: contriever đạt được kết quả tốt nhất trong các phương pháp bi-encoder dày đặc cho nDCG@10, và là tiên tiến nhất cho recall@100 (cải thiện recall@100 trung bình từ 65.0 lên 67.1). Hiệu suất recall@100 mạnh này có thể được khai thác thêm bằng cách sử dụng cross-encoder để tái xếp hạng các tài liệu được truy xuất: điều này dẫn đến tiên tiến nhất trên 8 tập dữ liệu của chuẩn BEIR cho nDCG@10, cũng như trung bình. Cần lưu ý rằng quy trình tinh chỉnh của chúng tôi trên MS MARCO đơn giản hơn so với các bộ truy xuất khác, vì chúng tôi sử dụng chiến lược đơn giản để khai thác negative và không sử dụng chưng cất. Mô hình của chúng tôi có thể cũng được hưởng lợi từ các cải tiến được đề xuất bởi những bộ truy xuất này, nhưng điều này nằm ngoài phạm vi của bài báo này.

Cuối cùng, chúng tôi minh họa lợi ích của bộ truy xuất của chúng tôi so với BM25 trong thiết lập few-shot, nơi chúng tôi có quyền truy cập vào một số lượng nhỏ các ví dụ truy xuất trong miền. Thiết lập này phổ biến trong thực tế, và các phương pháp dựa trên từ vựng, như BM25, không thể tận dụng các tập huấn luyện nhỏ để điều chỉnh trọng số của chúng. Trong Bảng 3, chúng tôi báo cáo nDCG@10 trên ba tập dữ liệu từ BEIR liên quan đến các tập huấn luyện nhỏ nhất, từ 729 đến

--- TRANG 9 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
5,500 truy vấn. Chúng tôi quan sát thấy rằng trên những tập dữ liệu nhỏ này, tiền huấn luyện của chúng tôi dẫn đến kết quả tốt hơn so với tiền huấn luyện BERT, ngay cả khi BERT được tinh chỉnh trên MS MARCO như một bước trung gian. Mô hình được tiền huấn luyện của chúng tôi cũng vượt trội BM25, cho thấy lợi thế của bộ truy xuất dày đặc so với các phương pháp từ vựng trong thiết lập few-shot. Các chi tiết khác được đưa ra trong Phụ lục A.3.

5 Truy xuất đa ngôn ngữ
Trong phần này, chúng tôi minh họa một lợi thế khác của việc học các bộ truy xuất dày đặc không giám sát, khi thực hiện truy xuất đa ngôn ngữ. Trong khi các tập dữ liệu có nhãn lớn có sẵn bằng tiếng Anh, cho phép huấn luyện các bộ truy xuất dày đặc mạnh (như đã thể hiện trong các phần trước), điều này thật không may không phải là trường hợp đối với các ngôn ngữ ít tài nguyên hơn. Ở đây, chúng tôi cho thấy rằng huấn luyện không giám sát là một hướng đầy hứa hẹn. Đầu tiên, chúng tôi cho thấy rằng phương pháp của chúng tôi dẫn đến hiệu suất mạnh, hoặc trong thiết lập hoàn toàn không giám sát, hoặc bằng cách tinh chỉnh một mô hình đa ngôn ngữ trên dữ liệu tiếng Anh như MS MARCO. Thứ hai, chúng tôi chứng minh rằng mô hình của chúng tôi cũng có thể thực hiện truy xuất liên ngôn ngữ, bằng cách truy xuất tài liệu tiếng Anh từ các truy vấn ngôn ngữ khác. Các bộ truy xuất không giám sát dựa trên khớp từ vựng, chẳng hạn như BM25, sẽ đạt được hiệu suất kém, đặc biệt đối với các cặp ngôn ngữ có hệ thống chữ viết khác nhau như tiếng Anh và tiếng Ả Rập.

5.1 Tiền huấn luyện đa ngôn ngữ
Mô hình đa ngôn ngữ của chúng tôi, được gọi là mContriever, được tiền huấn luyện chung trên 29 ngôn ngữ. Tiền huấn luyện đa ngôn ngữ phần lớn tuân theo phương pháp được thảo luận trong các phần trước, nhưng nó khác biệt bởi một vài đặc điểm liên quan đến dữ liệu tiền huấn luyện và các siêu tham số được sử dụng. Mô hình được khởi tạo với phiên bản đa ngôn ngữ của BERT, mBERT, được huấn luyện trên 104 ngôn ngữ. Đối với dữ liệu tiền huấn luyện, chúng tôi xem xét các ngôn ngữ có trong CCNet (Wenzek et al., 2020) cũng là một phần của các tập dữ liệu đánh giá của chúng tôi. Điều này dẫn đến một tập huấn luyện chứa dữ liệu CCNet cho 29 ngôn ngữ được chi tiết trong Bảng 12. Trong quá trình tiền huấn luyện, các ví dụ được lấy mẫu đồng đều trên các ngôn ngữ, tức là xác suất mà một mẫu huấn luyện đến từ một ngôn ngữ cụ thể là giống nhau đối với tất cả các ngôn ngữ. Chúng tôi quan sát thấy rằng việc tăng số lượng ngôn ngữ được xem xét để tiền huấn luyện thường làm giảm hiệu suất như được báo cáo trong Phụ lục B.3 tương tự như những gì đã được quan sát đối với các mô hình ngôn ngữ có mặt nạ đa ngôn ngữ (Conneau et al., 2019). Chúng tôi tiền huấn luyện mContriever đa ngôn ngữ của chúng tôi với kích thước hàng đợi 32768. Điều này thường cải thiện sự ổn định, và có thể bù đắp cho các sự bất ổn bổ sung được quan sát trong thiết lập đa ngôn ngữ. Các siêu tham số chi tiết hơn được đưa ra trong Phụ lục B.1.

5.2 Tinh chỉnh
Các tập dữ liệu có nhãn lớn cho truy xuất thông tin thường chỉ có sẵn bằng tiếng Anh. Do đó, tự nhiên là điều tra liệu các tập dữ liệu đơn ngôn ngữ lớn có thể được tận dụng cho truy xuất đa ngôn ngữ. Chúng tôi xem xét việc tinh chỉnh mô hình mContriever được tiền huấn luyện của chúng tôi trên MS MARCO. Điều này thường cải thiện hiệu suất trong tất cả các ngôn ngữ. Mô hình được huấn luyện trên MS MARCO có thể được tinh chỉnh thêm trên Mr. TyDi đạt được hiệu suất tiên tiến nhất trên tập dữ liệu này. Các chi tiết khác về tinh chỉnh được đưa ra trong Phụ lục B.2.

5.3 Đánh giá
Chúng tôi đánh giá hiệu suất của mô hình được tiền huấn luyện của chúng tôi có và không có tinh chỉnh trên dữ liệu tiếng Anh trên hai chuẩn khác nhau. Đầu tiên, chúng tôi xem xét Mr. TyDi (Zhang et al., 2021), một chuẩn truy xuất thông tin đa ngôn ngữ được dẫn xuất từ TyDi QA (Clark et al., 2020). Cho một câu hỏi, mục tiêu là tìm các tài liệu liên quan trong một nhóm các tài liệu Wikipedia cùng ngôn ngữ.

Trong Mr. TyDi, nhóm tài liệu được hạn chế đối với ngôn ngữ của truy vấn. Việc có thể truy xuất các tài liệu liên quan từ một ngôn ngữ khác là mong muốn để tận dụng các nguồn thông tin lớn có thể không có sẵn trong tất cả các ngôn ngữ. Để đánh giá hiệu suất truy xuất liên ngôn ngữ, chúng tôi dẫn xuất một thiết lập đánh giá từ MKQA (Longpre et al., 2020). Cho một câu hỏi bằng một ngôn ngữ cụ thể, chúng tôi thực hiện truy xuất trong Wikipedia tiếng Anh, và đánh giá liệu câu trả lời tiếng Anh có trong các tài liệu được truy xuất. Tập dữ liệu MKQA làm cho điều này có thể bằng cách cung cấp các câu hỏi và câu trả lời giống nhau trong 26 ngôn ngữ. Chúng tôi loại bỏ các câu hỏi không thể trả lời, câu hỏi chấp nhận câu trả lời có/không nhị phân và câu hỏi có câu trả lời dài từ tập dữ liệu MKQA gốc.

--- TRANG 10 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 4: Truy xuất đa ngôn ngữ trên Mr. TyDi. Chúng tôi báo cáo MRR@100 và Recall@100 trên các tập kiểm tra của Mr. TyDi. mContriever được tinh chỉnh trên MS MARCO được so sánh với các đối tác của nó mà không có tiền huấn luyện tương phản sử dụng công thức tinh chỉnh tương tự, được gọi là mBERT + MS MARCO, cũng như một mô hình được khởi tạo với XLM-R được gọi là XLM-R + MS MARCO. Chúng tôi cũng báo cáo kết quả sau khi tinh chỉnh trên Mr. TyDi cho mô hình được huấn luyện trên MS MARCO.

ar bn en fi id ja ko ru sw te th avg
MRR@100
BM25 (Zhang et al., 2021) 36.7 41.3 15.1 28.8 38.2 21.7 28.1 32.9 39.6 42.4 41.7 33.3
mDPR (Zhang et al., 2021) 26.0 25.8 16.2 11.3 14.6 18.1 21.9 18.5 7.3 10.6 13.5 16.7
Hybrid (Zhang et al., 2021) 49.1 53.5 28.4 36.5 45.5 35.5 36.2 42.7 40.5 42.0 49.2 41.7
mBERT + MS MARCO 34.8 35.1 25.7 29.6 36.3 27.1 28.1 30.0 37.4 39.6 20.3 31.3
XLM-R + MS MARCO 36.5 41.7 23.0 32.7 39.2 24.8 32.2 29.3 35.1 54.7 38.5 35.2
mContriever 27.336.39.221.123.519.522.317.538.322.537.225.0
+ MS MARCO 43.442.327.135.142.632.434.236.151.237.440.238.4
+ Mr. Tydi 72.4 67.2 56.6 60.2 63.0 54.9 55.3 59.7 70.7 90.3 67.3 65.2
Recall@100
BM25 (Zhang et al., 2021) 80.0 87.4 55.1 72.5 84.6 65.6 79.7 66.0 76.4 81.3 85.3 74.3
mDPR (Zhang et al., 2021) 62.0 67.1 47.5 37.5 46.6 53.5 49.0 49.8 26.4 35.2 45.5 47.3
Hybrid (Zhang et al., 2021) 86.3 93.7 69.6 78.8 88.7 77.8 70.6 76.0 78.6 82.7 87.5 80.9
mBERT + MS MARCO 81.1 88.7 77.8 74.2 81.0 76.1 66.7 77.6 74.1 89.5 57.8 76.8
XLM-R + MS MARCO 79.9 84.2 73.1 81.6 87.4 70.9 71.1 74.1 73.9 91.2 89.5 79.7
mContriever 82.089.648.879.681.472.866.268.588.780.890.377.2
+ MS MARCO 88.791.477.288.189.881.778.283.891.496.690.587.0
+ Mr. Tydi 94.0 98.6 92.2 92.7 94.5 88.8 88.9 92.4 93.7 98.9 95.2 93.6

Điều này dẫn đến một tập đánh giá gồm 6619 truy vấn. Cần lưu ý rằng các phương pháp dựa trên khớp thuật ngữ như BM25 bị hạn chế một cách nội tại trong thiết lập truy xuất liên ngôn ngữ này vì các thuật ngữ tương tự trong các ngôn ngữ khác nhau có thể không khớp.

5.4 Baseline
Trên Mr. TyDi (Zhang et al., 2021) chúng tôi báo cáo kết quả từ bài báo gốc. Điều này bao gồm baseline BM25, một mô hình được tinh chỉnh trên NaturalQuestions sử dụng pipeline DPR, và một mô hình hybrid kết hợp cả hai. Trên chuẩn đánh giá liên ngôn ngữ được dẫn xuất từ MKQA, chúng tôi xem xét bộ truy xuất của pipeline trả lời câu hỏi CORA (Asai et al., 2021), được huấn luyện trên sự kết hợp của các tập dữ liệu chứa NaturalQuestions tiếng Anh và XOR-TyDi QA liên ngôn ngữ, với tăng cường dữ liệu dựa trên dịch thuật.

Ngoài ra, để tách biệt tác động của tiền huấn luyện tương phản, chúng tôi cũng so sánh mContriever được tinh chỉnh trên MS MARCO với các đối tác của nó mà không có tiền huấn luyện tương phản, được khởi tạo từ mBERT. Mô hình này được gọi là mBERT + MSMARCO trong các bảng. Chúng tôi cũng báo cáo kết quả thu được bằng cách tinh chỉnh XLM-R (Conneau et al., 2019) trên MS-MARCO. Đối với cả hai mô hình, chúng tôi sử dụng cùng các siêu tham số được sử dụng để tinh chỉnh mContriever trên MS MARCO ngoại trừ nhiệt độ, các chi tiết bổ sung được báo cáo trong Phụ lục B.2.

5.5 Kết quả
Chúng tôi báo cáo kết quả trên Mr. TyDi trong Bảng 4. Hiệu quả của tiền huấn luyện đa ngôn ngữ xuất hiện rõ ràng khi mô hình được tiền huấn luyện được tinh chỉnh trên MS MARCO đạt được hiệu suất tốt hơn đáng kể so với các đối tác không có tiền huấn luyện khi được tinh chỉnh bằng cùng một pipeline. Thú vị là việc tinh chỉnh trên những tập dữ liệu chỉ tiếng Anh này cải thiện hiệu suất trên tất cả các ngôn ngữ. Hơn nữa, mContriever không giám sát của chúng tôi vượt trội BM25 cho Recall@100, và sau khi tinh chỉnh trên MS MARCO, nó đạt được hiệu suất tiên tiến nhất cho chỉ số này. Hiệu suất có thể được cải thiện thêm bằng cách tinh chỉnh trên tập huấn luyện của Mr. TyDi. Điều này dường như

--- TRANG 11 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 5: Truy xuất liên ngôn ngữ trên MKQA. Chúng tôi báo cáo trung bình trên tất cả các ngôn ngữ được bao gồm trong MKQA cho Recall@100 và Recall@20, và báo cáo Recall@100 cho một tập con các ngôn ngữ. Kết quả đầy đủ được báo cáo trong Bảng 13 và Bảng 14 của phụ lục.

Trung bình R@20 Trung bình R@100 en ar ja ko es he de
CORA (Asai et al., 2021) 49.0 59.8 75.644.5 47.0 45.5 69.2 48.3 68.1
mBERT + MS MARCO 45.3 57.9 74.2 44.0 51.7 48.2 63.9 46.8 59.6
XLM-R + MS MARCO 46.9 59.6 73.4 42.5 53.2 49.6 63.4 46.9 61.1
mContriever 31.4 49.2 65.343.047.144.837.244.749.0
+ MS MARCO 53.9 65.6 75.6 53.3 60.4 55.4 70.0 59.666.6

đặc biệt quan trọng đối với chỉ số MRR@100 chú trọng vào chất lượng của các tài liệu đầu tiên được truy xuất. Đối với chỉ số này, mô hình không giám sát của chúng tôi vẫn thua kém BM25.

Kết quả trên chuẩn truy xuất liên ngôn ngữ được dẫn xuất từ MKQA được báo cáo trong Bảng 5, với chi tiết theo ngôn ngữ cho Recall@100 và Recall@20 được báo cáo trong Bảng 13 và Bảng 14 của phụ lục. Thú vị là chỉ sử dụng dữ liệu huấn luyện có giám sát bằng tiếng Anh, mContriever được tinh chỉnh trên MS MARCO của chúng tôi vượt trội bộ truy xuất CORA. Tương tự như kết quả được báo cáo trên Mr. TyDi, việc thêm tiền huấn luyện tương phản đa ngôn ngữ trước khi tinh chỉnh trên MS MARCO cải thiện hiệu suất so với đối tác không có tiền huấn luyện. Trên MKQA, đánh giá được thực hiện bằng cách viết thường cả truy vấn và tài liệu, chúng tôi quan sát thấy điều này cải thiện hiệu suất. Điều này không ảnh hưởng đến bộ truy xuất CORA dựa trên phiên bản uncased của mBERT.

6 Các nghiên cứu loại bỏ
Trong phần này, chúng tôi điều tra ảnh hưởng của các lựa chọn thiết kế khác nhau đối với phương pháp của chúng tôi. Trong các nghiên cứu loại bỏ này, tất cả các mô hình đều được tiền huấn luyện trên Wikipedia tiếng Anh trong 200k bước gradient, với kích thước batch 2,048 (trên 32 GPU). Mỗi lần tinh chỉnh trên MS MARCO mất 20k bước gradient với kích thước batch 512 (trên 8 GPU), sử dụng AdamW và không có negative khó.

MoCo so với negative trong batch. Đầu tiên, chúng tôi so sánh hai phương pháp tiền huấn luyện tương phản: MoCo và negative trong batch. Như trong negative trong batch, số lượng ví dụ tiêu cực bằng kích thước batch, chúng tôi huấn luyện các mô hình với kích thước batch 4,096 và hạn chế hàng đợi trong MoCo đến cùng số lượng phần tử. Thí nghiệm này đo lường tác động của việc sử dụng bộ mã hóa momentum cho các khóa thay vì cùng một mạng như cho các truy vấn. Việc sử dụng momentum cũng ngăn cản việc lan truyền ngược gradient qua các khóa. Chúng tôi báo cáo kết quả, không tinh chỉnh trên MS MARCO trong Bảng 6. Chúng tôi quan sát thấy rằng sự khác biệt hiệu suất giữa hai phương pháp là nhỏ, đặc biệt sau khi tinh chỉnh trên MS MARCO. Do đó, chúng tôi đề xuất sử dụng MoCo như framework học tương phản của chúng tôi, vì nó mở rộng quy mô đến số lượng lớn hơn các ví dụ tiêu cực mà không cần tăng kích thước batch.

Số lượng ví dụ tiêu cực. Tiếp theo, chúng tôi nghiên cứu ảnh hưởng của số lượng negative được sử dụng trong mất mát tương phản, bằng cách thay đổi kích thước hàng đợi của thuật toán MoCo. Chúng tôi xem xét các giá trị từ 2,048 đến 131,072, và báo cáo kết quả trong Hình 2. Chúng ta thấy rằng trung bình trên chuẩn BEIR, việc tăng số lượng negative dẫn đến hiệu suất truy xuất tốt hơn, đặc biệt trong thiết lập không giám sát. Tuy nhiên, chúng tôi lưu ý rằng tác động này không mạnh như nhau đối với tất cả các tập dữ liệu.

--- TRANG 12 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
21121221321421521621710203040MS MARCO
21121221321421521621720304050TREC COVID
211212213214215216217222426283032NFCorpus
2112122132142152162171020304050NaturalQuestions
2112122132142152162173040506070HotpotQA
2112122132142152162171015202530FiQA
21121221321421521621730354045ArguAna
2112122132142152162171214161820Touche-2020
2112122132142152162176570758085Quora
211212213214215216217203040DBPedia
2112122132142152162171012141618SCIDOCS
21121221321421521621750607080FEVER
21121221321421521621710152025CLIMATE-FEVER
21121221321421521621755606570SciFacts
21121221321421521621730354045Average
Không có MSMARCO Có MSMARCO

Hình 2: Tác động của số lượng negative. Chúng tôi báo cáo nDCG@10 như một hàm số của kích thước hàng đợi, có và không có tinh chỉnh trên MS MARCO. Chúng tôi báo cáo số liệu sử dụng framework MoCo nơi các khóa cho negative được tính toán với bộ mã hóa momentum và được lưu trữ trong một hàng đợi.

Các phép tăng cường dữ liệu. Thứ ba, chúng tôi so sánh các cách khác nhau để tạo ra các cặp ví dụ tích cực từ một tài liệu hoặc đoạn văn bản duy nhất. Đặc biệt, chúng tôi so sánh chiến lược cắt xén ngẫu nhiên, dẫn đến các cặp có chồng chéo, và nhiệm vụ cloze nghịch đảo, đã được xem xét trước đây để tiền huấn luyện các bộ truy xuất. Thú vị là, như được thể hiện trong Bảng 7, chiến lược cắt xén ngẫu nhiên vượt trội nhiệm vụ cloze nghịch đảo trong thiết lập của chúng tôi. Chúng tôi tin rằng cắt xén ngẫu nhiên, dẫn đến các phân phối giống hệt nhau của khóa và truy vấn, dẫn đến huấn luyện ổn định hơn với MoCo so với ICT. Điều này có thể giải thích một phần sự khác biệt hiệu suất giữa hai phương pháp. Chúng tôi cũng điều tra liệu các nhiễu loạn dữ liệu bổ sung, chẳng hạn như xóa từ ngẫu nhiên hoặc thay thế, có lợi cho truy xuất hay không.

Dữ liệu huấn luyện. Cuối cùng, chúng tôi nghiên cứu tác động của dữ liệu tiền huấn luyện đối với hiệu suất của bộ truy xuất của chúng tôi, bằng cách huấn luyện trên Wikipedia, CCNet hoặc hỗn hợp của cả hai nguồn dữ liệu. Chúng tôi báo cáo kết quả trong Bảng 8, và quan sát thấy rằng không có người chiến thắng rõ ràng giữa hai nguồn dữ liệu. Không ngạc nhiên, việc huấn luyện trên dữ liệu CCNet đa dạng hơn dẫn đến cải thiện mạnh trên các tập dữ liệu từ các miền khác với Wikipedia, chẳng hạn như FiQA hoặc Quora. Mặt khác, trên một tập dữ liệu như FEVER, việc huấn luyện trên Wikipedia dẫn đến kết quả tốt hơn. Để có được điều tốt nhất của cả hai thế giới, chúng tôi xem xét hai chiến lược để trộn hai nguồn dữ liệu. Trong chiến lược "50/50%", các ví dụ được lấy mẫu đồng đều qua miền, có nghĩa là một nửa số batch từ Wikipedia và nửa còn lại từ CCNet. Trong chiến lược "đồng đều", các ví dụ được lấy mẫu đồng đều trên hợp của tập dữ liệu. Vì CCNet lớn hơn đáng kể so với Wikipedia, điều này có nghĩa là hầu hết các batch từ CCNet.

Tác động của tinh chỉnh trên MS MARCO. Để tách biệt tác động của tiền huấn luyện khỏi tác động của tinh chỉnh trên MS MARCO, chúng tôi áp dụng cùng một tinh chỉnh cho mô hình BERT base uncased. Chúng tôi báo cáo kết quả trong Bảng 9, và quan sát thấy rằng khi được áp dụng cho BERT, tinh chỉnh của chúng tôi dẫn đến kết quả thấp hơn so với tiên tiến nhất. Do đó, chúng tôi tin rằng hầu hết cải thiện so với các bộ truy xuất tiên tiến nhất có thể được quy cho chiến lược tiền huấn luyện tương phản của chúng tôi.

--- TRANG 13 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 6: MoCo so với negative trong batch. Trong bảng này, chúng tôi báo cáo nDCG@10 trên chuẩn BEIR cho negative trong batch và MoCo, không tinh chỉnh trên tập dữ liệu MS MARCO.

NFCorpus NQ FiQA ArguAna Quora DBPedia SciDocs FEVER AVG
MoCo 26.2 13.1 13.7 33.0 69.5 20.0 11.9 57.6 30.1
Negative trong batch 24.2 21.6 13.0 33.7 74.9 17.9 13.6 56.1 31.9

Bảng 7: Tác động của các phép tăng cường dữ liệu. Chúng tôi báo cáo nDCG@10 không tinh chỉnh trên MS MARCO.

NFCorpus NQ ArguAna Quora DBPedia SciDocs FEVER Tổng thể
ICT 23.2 19.4 31.6 27.6 21.3 10.6 55.6 25.9
Cắt xén 27.6 17.7 35.6 75.4 21.0 13.3 64.5 32.2
Cắt xén + xóa 26.8 20.8 35.8 77.3 21.5 14.0 67.9 33.8
Cắt xén + thay thế 27.7 18.7 36.2 75.6 22.0 13.0 66.8 32.9

Bảng 8: Dữ liệu huấn luyện. Chúng tôi báo cáo nDCG@10 không tinh chỉnh trên MS MARCO.

NFCorpus NQ FiQA ArguAna Quora DBPedia SciDocs FEVER Tổng thể
Wiki 27.6 17.7 16.3 35.6 75.4 21.0 13.3 64.5 33.0
CCNet 29.5 25.8 26.2 35.2 80.6 20.5 14.9 60.9 34.9
Đồng đều 31.0 19.4 25.1 37.8 80.4 21.5 14.7 59.8 33.9
50/50% 31.5 18.6 23.3 36.2 79.1 22.1 13.7 64.1 34.7

Bảng 9: Tinh chỉnh. Chúng tôi báo cáo nDCG@10 sau khi tinh chỉnh BERT và mô hình của chúng tôi trên MS MARCO.

NFCorpus NQ FiQA ArguAna Quora DBPedia SciDocs FEVER Tổng thể
BERT 28.2 44.6 25.9 35.0 84.0 34.4 13.0 69.8 42.0
Contriever 33.2 50.2 28.8 46.0 85.4 38.8 16.0 77.7 46.5

7 Thảo luận
Trong công trình này, chúng tôi đề xuất khám phá các giới hạn của tiền huấn luyện tương phản để học các bộ truy xuất văn bản dày đặc. Chúng tôi sử dụng kỹ thuật MoCo, cho phép huấn luyện các mô hình với một số lượng lớn các ví dụ tiêu cực. Chúng tôi đưa ra một số quan sát thú vị: đầu tiên, chúng tôi cho thấy rằng các mạng nơ-ron được huấn luyện mà không cần giám sát bằng học tương phản thể hiện hiệu suất truy xuất tốt, cạnh tranh với BM25 (mặc dù không phải tiên tiến nhất). Những kết quả này có thể được cải thiện thêm bằng cách tinh chỉnh trên tập dữ liệu MS MARCO có giám sát, dẫn đến kết quả mạnh, đặc biệt cho recall@100. Dựa trên quan sát đó, chúng tôi sử dụng cross-encoder để tái xếp hạng các tài liệu được truy xuất bằng mô hình của chúng tôi, dẫn đến tiên tiến nhất mới trên chuẩn BEIR cạnh tranh. Chúng tôi cũng thực hiện các thí nghiệm loại bỏ rộng rãi, và quan sát thấy rằng cắt xén ngẫu nhiên độc lập dường như là một thay thế mạnh cho nhiệm vụ Cloze nghịch đảo để huấn luyện các bộ truy xuất.

Tài liệu tham khảo
Akari Asai, Xinyan Yu, Jungo Kasai, và Hannaneh Hajishirzi. One question answering model for many languages with cross-lingual dense passage retrieval. CoRR, abs/2107.11976, 2021. URL https://arxiv.org/abs/2107.11976 . 10, 11

Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. Ms marco: A human generated machine reading comprehension dataset. arXiv preprint arXiv:1611.09268 , 2016. 3, 6

Adam Berger, Rich Caruana, David Cohn, Dayne Freitag, và Vibhu Mittal. Bridging the lexical chasm: statistical approaches to answer-ﬁnding. In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval , pp. 192–199, 2000. 1

Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, và Armand Joulin. Emerging properties in self-supervised vision transformers. arXiv preprint arXiv:2104.14294 , 2021. 2

Wei-Cheng Chang, Felix X Yu, Yin-Wen Chang, Yiming Yang, và Sanjiv Kumar. Pre-training tasks for embedding-based large-scale retrieval. arXiv preprint arXiv:2002.03932 , 2020. 2, 3

--- TRANG 14 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Danqi Chen, Adam Fisch, Jason Weston, và Antoine Bordes. Reading Wikipedia to answer open-domain questions. In Proc. ACL , 2017a. 1

Ting Chen, Yizhou Sun, Yue Shi, và Liangjie Hong. On sampling strategies for neural network-based collaborative ﬁltering. arXiv preprint arXiv:1706.07881 , 2017b. 5

Ting Chen, Simon Kornblith, Mohammad Norouzi, và Geoﬀrey Hinton. A simple framework for contrastive learning of visual representations. In International conference on machine learning , pp. 1597–1607. PMLR, 2020. 2, 4, 5

Xilun Chen, Kushal Lakhotia, Barlas Oğuz, Anchit Gupta, Patrick Lewis, Stan Peshterliev, Yashar Mehdad, Sonal Gupta, và Wen-tau Yih. Salient phrase aware dense retrieval: Can a dense retriever imitate a sparse one?, 2021. URL https://arxiv.org/abs/2110.06918 . 3

Jonathan H. Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, và Jennimaria Palomaki. Tydi QA: A benchmark for information-seeking question answering in typologically diverse languages. CoRR, abs/2003.05002, 2020. URL https://arxiv.org/abs/2003.05002 . 9

Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, và Veselin Stoyanov. Unsupervised cross-lingual representation learning at scale. CoRR, abs/1911.02116, 2019. URL http://arxiv.org/abs/1911.02116 . 9, 10, 19

Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, và Richard Harshman. Indexing by latent semantic analysis. Journal of the American society for information science , 41(6):391–407, 1990. 2

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proc. NAACL , 2019. 3, 4

Hongchao Fang, Sicheng Wang, Meng Zhou, Jiayuan Ding, và Pengtao Xie. Cert: Contrastive self-supervised learning for language understanding. arXiv preprint arXiv:2005.12766 , 2020. 3

Thibault Formal, Carlos Lassance, Benjamin Piwowarski, và Stéphane Clinchant. Splade v2: Sparse lexical and expansion model for information retrieval. arXiv preprint arXiv:2109.10086 , 2021. 7

Luyu Gao và Jamie Callan. Unsupervised corpus aware language model pre-training for dense passage retrieval. arXiv preprint arXiv:2108.05540 , 2021. 3

Tianyu Gao, Xingcheng Yao, và Danqi Chen. Simcse: Simple contrastive learning of sentence embeddings. arXiv preprint arXiv:2104.08821 , 2021. 5, 7

Daniel Gillick, Alessandro Presta, và Gaurav Singh Tomar. End-to-end retrieval in continuous space. arXiv preprint arXiv:1811.08008 , 2018. 3

John M Giorgi, Osvald Nitski, Gary D Bader, và Bo Wang. Declutr: Deep contrastive learning for unsupervised textual representations. arXiv preprint arXiv:2006.03659 , 2020. 3

Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, và Ming-Wei Chang. Realm: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909 , 2020. 3, 5, 7

Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, và Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 9729–9738, 2020. 2, 6, 17

Sebastian Hofstätter, Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin, và Allan Hanbury. Eﬃciently teaching an eﬀective dense retriever with balanced topic aware sampling. arXiv preprint arXiv:2104.06967 , 2021. 7

Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, và Larry Heck. Learning deep structured semantic models for web search using clickthrough data. In Proceedings of the 22nd ACM international conference on Information & Knowledge Management , pp. 2333–2338, 2013. 2, 4

--- TRANG 15 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, và Jason Weston. Poly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring. arXiv preprint arXiv:1905.01969 , 2019. 3

Gautier Izacard và Edouard Grave. Distilling knowledge from reader to retriever for question answering, 2020a. URL https://arxiv.org/abs/2012.04584 . 3, 7

Gautier Izacard và Edouard Grave. Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282 , 2020b. 6

Gautier Izacard, Fabio Petroni, Lucas Hosseini, Nicola De Cao, Sebastian Riedel, và Edouard Grave. A memory eﬃcient baseline for open domain question answering. arXiv preprint arXiv:2012.15156 , 2020. 3

Yacine Jernite, Samuel R Bowman, và David Sontag. Discourse-based objectives for fast unsupervised sentence representation learning. arXiv preprint arXiv:1705.00557 , 2017. 3

Jeﬀ Johnson, Matthijs Douze, và Hervé Jégou. Billion-scale similarity search with gpus. IEEE Transactions on Big Data , 2019. 3

Karen Sparck Jones. A statistical interpretation of term speciﬁcity and its application in retrieval. Journal of documentation , 1972. 2

Mandar Joshi, Eunsol Choi, Daniel S. Weld, và Luke Zettlemoyer. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Proc. ACL , 2017. 6, 7

Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, và Wen-tau Yih. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906 , 2020. 3, 4, 5, 7

Omar Khattab, Christopher Potts, và Matei Zaharia. Relevance-guided supervision for openqa with colbert, 2020. 3, 7

Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redﬁeld, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics , 7:453–466, 2019. 1, 6, 7

Jungmin Kwon, Jeongseop Kim, Hyunseo Park, và In Kwon Choi. ASAM: adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks. arXiv preprint arXiv:2102.11600 , 2021. 17

Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, và Radu Soricut. Albert: A lite bert for self-supervised learning of language representations. arXiv preprint arXiv:1909.11942 , 2019. 3

Kenton Lee, Ming-Wei Chang, và Kristina Toutanova. Latent retrieval for weakly supervised open domain question answering. In Proc. ACL , 2019. 2, 3, 4, 5, 6

Mike Lewis, Marjan Ghazvininejad, Gargi Ghosh, Armen Aghajanyan, Sida Wang, và Luke Zettlemoyer. Pre-training via paraphrasing. arXiv preprint arXiv:2006.15020 , 2020. 3

Jimmy Lin, Rodrigo Nogueira, và Andrew Yates. Pretrained transformers for text ranking: Bert and beyond. arXiv preprint arXiv:2010.06467 , 2020. 2

Shayne Longpre, Yi Lu, và Joachim Daiber. MKQA: A linguistically diverse benchmark for multilingual open domain question answering. CoRR, abs/2007.15207, 2020. URL https://arxiv.org/abs/2007.15207 . 9

Ilya Loshchilov và Frank Hutter. Decoupled weight decay regularization, 2019. 17, 18

Yi Luan, Jacob Eisenstein, Kristina Toutanova, và Michael Collins. Sparse, dense, and attentional representations for text retrieval. arXiv preprint arXiv:2005.00181 , 2020. 3

--- TRANG 16 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Xueguang Ma, Kai Sun, Ronak Pradeep, và Jimmy Lin. A replication study of dense passage retriever, 2021. 7

Christopher D Manning, Hinrich Schütze, và Prabhakar Raghavan. Introduction to information retrieval . Cambridge university press, 2008. 2

Yu Meng, Chenyan Xiong, Payal Bajaj, Saurabh Tiwary, Paul Bennett, Jiawei Han, và Xia Song. Coco-lm: Correcting and contrasting text sequences for language model pretraining. arXiv preprint arXiv:2102.08473 , 2021. 3

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, và Jeﬀ Dean. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems , pp. 3111–3119, 2013. 3

Bhaskar Mitra, Nick Craswell, et al. An introduction to neural information retrieval. Foundations and Trends ®in Information Retrieval , 13(1):1–126, 2018. 2

Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, và Li Deng. Ms marco: A human generated machine reading comprehension dataset. In CoCo@ NIPS , 2016. 1

Rodrigo Nogueira và Kyunghyun Cho. Passage re-ranking with bert. arXiv preprint arXiv:1901.04085 , 2019. 2, 4

Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, và Rabab Ward. Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval. IEEE/ACM Transactions on Audio, Speech, and Language Processing , 24(4):694–707, 2016. 2

Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, và Haifeng Wang. RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , pp. 5835–5847, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.466. URL https://aclanthology.org/2021.naacl-main.466 . 5

Ori Ram, Gal Shachaf, Omer Levy, Jonathan Berant, và Amir Globerson. Learning to retrieve passages without supervision, 2021. URL https://arxiv.org/abs/2112.07708 . 3

Nils Reimers và Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084 , 2019. 3, 4

Stephen Robertson và Hugo Zaragoza. The probabilistic relevance framework: BM25 and beyond . Now Publishers Inc, 2009. 1

Stephen E Robertson, Steve Walker, Susan Jones, Micheline M Hancock-Beaulieu, Mike Gatford, et al. Okapi at TREC-3. NIST Special Publication Sp , 1995. 2

Devendra Singh Sachan, Siva Reddy, William Hamilton, Chris Dyer, và Dani Yogatama. End-to-end training of multi-document reader and retriever for open-domain question answering, 2021. 2, 7

Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, và Grégoire Mesnil. Learning semantic representations using convolutional neural networks for web search. In Proceedings of the 23rd international conference on world wide web , pp. 373–374, 2014. 2

Nandan Thakur, Nils Reimers, Andreas Rücklé, Abhishek Srivastava, và Iryna Gurevych. Beir: A heteroge-nous benchmark for zero-shot evaluation of information retrieval models. arXiv preprint arXiv:2104.08663 , 2021. 2, 6, 18, 19

James Thorne, Andreas Vlachos, Christos Christodoulopoulos, và Arpit Mittal. Fever: a large-scale dataset for fact extraction and veriﬁcation. arXiv preprint arXiv:1803.05355 , 2018. 1

--- TRANG 17 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Joulin, và Edouard Grave. CCNet: Extracting high quality monolingual datasets from web crawl data. In Proceedings of the 12th Language Resources and Evaluation Conference , 2020. 6, 9, 17

Zhirong Wu, Yuanjun Xiong, Stella X Yu, và Dahua Lin. Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 3733–3742, 2018. 2, 4, 6

Zhuofeng Wu, Sinong Wang, Jiatao Gu, Madian Khabsa, Fei Sun, và Hao Ma. Clear: Contrastive learning for sentence representation. arXiv preprint arXiv:2012.15466 , 2020. 3

Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, và Arnold Overwijk. Approximate nearest neighbor negative contrastive learning for dense text retrieval. arXiv preprint arXiv:2007.00808 , 2020. 3, 4, 7

Sohee Yang và Minjoon Seo. Is retriever merely an approximator of reader? arXiv preprint arXiv:2010.10999 , 2020. 3

Xinyu Zhang, Xueguang Ma, Peng Shi, và Jimmy Lin. Mr. tydi: A multi-lingual benchmark for dense retrieval. CoRR, abs/2108.08787, 2021. URL https://arxiv.org/abs/2108.08787 . 9, 10

A Chi tiết kỹ thuật cho Contriever
A.1 Tiền huấn luyện tương phản
Đối với mô hình có tinh chỉnh trên MS MARCO, chúng tôi sử dụng thuật toán MoCo He et al. (2020) với hàng đợi kích thước 131,072, giá trị momentum 0.9995 và nhiệt độ 0.05. Chúng tôi sử dụng phép tăng cường dữ liệu cắt xén ngẫu nhiên, với các tài liệu 256 token và kích thước đoạn được lấy mẫu giữa 5% và 50% độ dài tài liệu. Các tài liệu chỉ đơn giản là những đoạn văn bản ngẫu nhiên được lấy mẫu từ hỗn hợp giữa dữ liệu Wikipedia và CCNet (Wenzek et al., 2020), nơi một nửa số batch được lấy mẫu từ mỗi nguồn. Chúng tôi cũng áp dụng xóa token với xác suất 10%. Chúng tôi tối ưu hóa mô hình với bộ tối ưu AdamW (Loshchilov & Hutter, 2019), với tốc độ học 5·10^−5, kích thước batch 2,048 và 500,000 bước. Chúng tôi khởi tạo mạng với mô hình BERT base uncased có sẵn công khai.

A.2 Tinh chỉnh trên MS MARCO
Đối với tinh chỉnh trên MS MARCO, chúng tôi không sử dụng thuật toán MoCo và chỉ đơn giản sử dụng negative trong batch. Chúng tôi sử dụng bộ tối ưu ASAM (Kwon et al., 2021), với tốc độ học 10^−5 và kích thước batch 1024 với nhiệt độ 0.05, cũng được sử dụng trong tiền huấn luyện. Chúng tôi huấn luyện một mô hình ban đầu với các ví dụ negative ngẫu nhiên trong 20000 bước, khai thác negative khó với mô hình đầu tiên này, và huấn luyện lại mô hình thứ hai với những negative đó. Mỗi truy vấn được liên kết với một tài liệu vàng và một tài liệu tiêu cực, là một tài liệu ngẫu nhiên trong giai đoạn đầu tiên và một negative khó 10% thời gian trong giai đoạn thứ hai. Đối với mỗi truy vấn, tất cả các tài liệu từ batch hiện tại ngoại trừ tài liệu vàng được sử dụng như negative.

A.3 Huấn luyện few-shot
Đối với đánh giá few-shot được trình bày trong Bảng 3, chúng tôi huấn luyện trong 500 epoch trên mỗi tập dữ liệu với kích thước batch 256 với negative ngẫu nhiên trong batch. Chúng tôi đánh giá hiệu suất trên tập phát triển mỗi 100 cập nhật gradient và thực hiện dừng sớm dựa trên chỉ số này. Đối với SciFact, chúng tôi giữ lại ngẫu nhiên 10% dữ liệu huấn luyện và sử dụng chúng như tập phát triển, dẫn đến tập huấn luyện chứa 729 mẫu.

--- TRANG 18 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 10: Chuẩn BEIR. Chúng tôi báo cáo recall@100 trên các tập kiểm tra từ chuẩn BEIR cho các phương pháp bi-encoder. Chúng tôi báo cáo recall@100 bị giới hạn trên Trec-COVID theo thiết lập BEIR gốc. Lưu ý rằng việc sử dụng cross-encoder để tái xếp hạng 100 tài liệu hàng đầu không thay đổi recall@100, do đó, chúng tôi không bao gồm những phương pháp này trong bảng này. Chúng tôi cũng báo cáo trung bình và số lượng tập dữ liệu mà một phương pháp là tốt nhất ("Tốt nhất trên") trên toàn bộ chuẩn BEIR (loại trừ ba tập dữ liệu vì giấy phép của chúng). In đậm là tốt nhất tổng thể. Trên Trec-COVID chúng tôi báo cáo Recall@100 bị giới hạn, xem Thakur et al. (2021) để biết thêm chi tiết. MS MARCO được loại trừ khỏi trung bình.

BM25 DPR ANCE TAS-B Gen-Q ColBERT Splade v2 Ours
MS MARCO 65.8 55.2 85.2 88.4 88.4 86.5 - 89.1
Trec-COVID 49.8 21.2 45.7 38.7 45.6 46.4 12.3 40.7
NFCorpus 25.0 20.8 23.2 28.0 28.0 25.4 27.7 30.0
NQ 76.0 88.0 83.6 90.3 86.2 91.2 93.0 92.5
HotpotQA 74.0 59.1 57.8 72.8 67.3 74.8 82.0 77.7
FiQA 53.9 34.2 58.1 59.3 61.8 60.3 62.1 65.6
ArguAna 94.2 75.1 93.7 94.2 97.8 91.4 97.2 97.7
Touche-2020 53.8 30.1 45.8 43.1 45.1 43.9 35.4 29.4
CQADupStack 60.6 40.3 57.9 62.2 65.4 62.4 - 66.3
Quora 97.3 47.0 98.7 98.6 98.8 98.9 98.7 99.3
DBPedia 39.8 34.9 31.9 49.9 43.3 46.1 57.5 54.1
Scidocs 35.6 21.9 26.9 33.5 33.2 34.4 36.4 37.8
Fever 93.1 84.0 90.0 93.7 92.8 93.4 95.1 94.9
Climate-fever 43.6 39.0 44.5 53.4 45.0 44.4 52.4 57.4
Scifact 90.8 72.7 81.6 89.1 89.3 87.8 92.0 94.7
Trung bình không CQA 63.6 48.3 60.1 65.0 64.2 64.5 64.8 67.1
Trung bình 63.4 47.7 60.0 64.8 64.2 64.3 - 67.0
Tốt nhất trên 2 0 0 0 1 0 4 7

B Truy xuất đa ngôn ngữ với mContriever
B.1 Siêu tham số cho tiền huấn luyện tương phản đa ngôn ngữ
Mô hình mContriever được tiền huấn luyện được tiền huấn luyện trong 500,000 bước với hàng đợi kích thước 32768, và nhiệt độ 0.05 và giá trị momentum 0.999. Chúng tôi tối ưu hóa mô hình với bộ tối ưu AdamW (Loshchilov & Hutter, 2019), với tốc độ học 5·10^−5. Tốc độ học tuân theo khởi động tuyến tính trong 20,000 bước theo sau bởi suy giảm tuyến tính cho đến khi kết thúc huấn luyện. Các ngôn ngữ được sử dụng để tiền huấn luyện được chi tiết trong Bảng 12.

B.2 Siêu tham số cho tinh chỉnh đa ngôn ngữ
Chúng tôi tinh chỉnh mContriever sử dụng negative trong batch, bộ tối ưu AdamW (Loshchilov & Hutter, 2019), tốc độ học 10^−5, và kích thước batch 1024 mẫu với nhiệt độ τ là 0.05. Trên MS MARCO và Mr. TyDi, mô hình được huấn luyện trong 20k bước gradient. Chúng tôi nhận thấy quá khớp trên NaturalQuestions, và do đó giảm huấn luyện xuống 1k bước gradient. Chúng tôi sử dụng khởi động 1000 bước gradient với suy giảm tuyến tính sau đó trong tất cả các trường hợp. Negative khó được khai thác trên Mr. TyDi với mô hình được huấn luyện trên MS MARCO. Chúng tôi không quan sát thấy cải thiện đáng kể bằng cách sử dụng negative khó trên MS MARCO và NaturalQuestions.

Đối với tinh chỉnh trên MS MARCO của các mô hình được khởi tạo từ mBERT (tương ứng XLM-R) mà không có tiền huấn luyện tương phản, chúng tôi sử dụng nhiệt độ τ là 1 (tương ứng 5). Chúng tôi thử nhiệt độ trong {10,5,2,1,0.1,0.05} và chọn nhiệt độ dẫn đến hiệu suất tốt nhất. Chúng tôi quan sát thấy sự giảm hiệu suất đối với nhiệt độ thấp hơn. Chúng tôi tinh chỉnh mContriever với τ = 0.05 theo nhiệt độ được sử dụng trong tiền huấn luyện. Chúng tôi tuân theo nhiệt độ τ = 0.05 được sử dụng để huấn luyện Contriever, và không thử nghiệm nhiệt độ khác cho tiền huấn luyện tương phản của mô hình đa ngôn ngữ, mContriever.

--- TRANG 19 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 11: Truy xuất không giám sát. Hiệu suất của các phương pháp không giám sát trên các tập dữ liệu BEIR. Chúng tôi báo cáo recall@100 bị giới hạn trên Trec-COVID theo thiết lập BEIR gốc. Đối với SimCSE chúng tôi báo cáo kết quả của mô hình sử dụng RoBERTa large. REALM sử dụng dữ liệu nhận dạng thực thể được chú thích để huấn luyện. Trên Trec-COVID chúng tôi báo cáo Recall@100 bị giới hạn, xem Thakur et al. (2021) để biết thêm chi tiết.

Mô hình (→) BM25 BERT SimCSE REALM Contriever
Tập dữ liệu (↓) Recall@100
MS MARCO 65.8 3.5 33.6 52.6 67.2
Trec-COVID 49.8 10.6 26.8 8.1 17.2
NFCorpus 25.0 6.7 18.2 23.0 29.4
NQ 76.0 14.3 42.9 58.1 77.1
HotpotQA 74.0 15.8 42.7 56.1 70.4
FiQA-2018 53.9 6.9 41.0 28.0 56.2
ArguAna 94.2 59.1 95.2 73.1 90.1
Tóuche-2020 53.8 3.0 18.6 11.5 22.5
CQADupStack 60.6 11.0 48.9 35.5 61.4
Quora 97.3 74.6 97.9 92.7 98.7
DBPedia 39.8 7.1 21.5 33.0 45.3
SCIDOCS 35.6 11.3 23.0 23.1 36.0
Fever 93.1 13.6 50.8 82.6 93.6
Climate-fever 43.6 12.8 44.8 42.3 44.1
SciFact 90.8 35.2 75.3 83.8 92.6
Trung bình 63.6 19.0 45.4 46.9 60.1
Tốt nhất trên 3 0 2 0 10

NDCG@10
MS MARCO 22.8 0.6 8.8 15.2 20.6
Trec-COVID 65.6 16.6 38.6 20.1 27.4
NFCorpus 32.5 2.5 14.0 24.1 31.7
NQ 32.9 2.7 12.6 15.2 25.4
HotpotQA 60.3 4.9 23.3 40.5 48.1
FiQA-2018 23.6 1.4 14.8 9.7 24.5
ArguAna 31.5 23.1 45.6 22.8 37.9
Tóuche-2020 36.7 3.4 11.6 7.3 19.3
CQADupStack 29.9 2.5 20.2 13.5 28.4
Quora 78.9 3.9 81.5 71.6 83.5
DBPedia 31.3 3.9 13.7 22.7 29.2
SCIDOCS 15.8 2.7 7.4 9.0 14.9
FEVER 75.3 4.9 20.1 42.9 68.2
Climate-fever 21.3 4.1 17.6 14.3 15.5
SciFact 66.5 9.8 38.5 47.1 64.9
Trung bình 41.7 8.7 24.6 25.1 36.0
Tốt nhất trên 12 0 1 0 2

B.3 Lời nguyền của đa ngôn ngữ
Chúng tôi đã thử tiền huấn luyện các mô hình trên các tập hợp ngôn ngữ khác nhau. Chúng tôi thường quan sát thấy sự suy giảm hiệu suất khi mở rộng quy mô sang nhiều ngôn ngữ hơn tương tự như những gì đã được quan sát đối với các mô hình ngôn ngữ có mặt nạ đa ngôn ngữ tổng quát Conneau et al. (2019). Trong Bảng 15, chúng tôi báo cáo kết quả trên Mr. TyDi với một mô hình được tiền huấn luyện trên 11 ngôn ngữ của Mr. TyDi so với mô hình được sử dụng trong phần còn lại của bài báo đã được tiền huấn luyện trên 29 ngôn ngữ bao gồm 11 ngôn ngữ của Mr. TyDi như được chi tiết trong Bảng 12. Chúng tôi cũng báo cáo hiệu suất của những mô hình này sau khi huấn luyện trên MS MARCO, cuối cùng theo sau bởi tinh chỉnh thêm trên Mr. TyDi. Có vẻ như hiệu suất của mô hình không giám sát và hiệu suất sau khi tinh chỉnh trên MS MARCO tốt hơn đối với mô hình được tiền huấn luyện chỉ trên 11 ngôn ngữ. Sự khác biệt được giảm thiểu sau khi tinh chỉnh trên Mr. TyDi.

--- TRANG 20 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 12: Danh sách các ngôn ngữ được sử dụng cho truy xuất đa ngôn ngữ.

ar bn da de en es
Ngôn ngữ Ả Rập Bengali Đan Mạch Đức Anh Tây Ban Nha
Tiền huấn luyện 3 3 3 3 3 3
Mr. TyDi 3 3 7 7 7 3
MKQA 3 7 3 3 3 3

fi fr he hu it id
Ngôn ngữ Phần Lan Pháp Do Thái Hungary Ý Indonesia
Tiền huấn luyện 3 3 3 3 3 3
Mr. TyDi 3 7 7 7 7 3
MKQA 3 3 3 3 3 7

ja km ko ms nl no
Ngôn ngữ Nhật Khmer Hàn Mã Lai Hà Lan Na Uy
Tiền huấn luyện 3 3 3 3 3 3
Mr. TyDi 3 7 3 7 7 7
MKQA 3 3 3 3 3 3

pl pt ru sv sw te
Ngôn ngữ Ba Lan Bồ Đào Nha Nga Thụy Điển Swahili Telugu
Tiền huấn luyện 3 3 3 3 3 3
Mr. TyDi 7 7 3 7 3 3
MKQA 3 3 3 3 7 7

th tr vi zh-cn zh-hk zh-tw
Ngôn ngữ Thái Thổ Nhĩ Kỳ Việt Trung (Giản thể) Trung (Hồng Kông) Trung (Phồn thể)
Tiền huấn luyện 3 3 3 3 7 3
Mr. TyDi 3 7 7 7 7 7
MKQA 3 3 3 3 3 3

Bảng 13: Recall@100 trên MKQA cho truy xuất liên ngôn ngữ trong thiết lập được mô tả trong Phần 5.3.

avg en ar fi ja ko ru es sv he th da de fr
CORA 59.8 75.644.5 61.3 47.0 45.5 58.6 69.2 68.0 48.3 44.4 68.9 68.1 70.2
mBERT + MS MARCO 57.9 74.2 44.0 51.7 55.7 48.2 57.4 63.9 62.7 46.8 51.7 63.7 59.6 65.2
XLM-R + MS MARCO 59.2 73.4 42.4 57.7 53.1 48.6 58.5 62.9 67.5 46.9 61.5 66.9 60.9 62.4
Contriever 49.265.343.043.147.144.851.837.254.544.751.449.349.050.2
+ MS MARCO 65.6 75.6 53.3 66.6 60.4 55.4 64.7 70.0 70.8 59.6 63.5 72.0 66.670.1

it nl pl pt hu vi ms km no tr zh-cn zh-hk zh-tw
CORA 68.3 72.065.6 67.9 59.5 61.2 67.9 35.6 68.3 61.5 52.0 52.8 52.8
mBERT + MS MARCO 64.1 66.7 59.0 61.9 57.5 58.6 62.8 32.9 63.2 56.0 58.4 59.3 59.3
XLM-R + MS MARCO 58.1 66.4 61.0 62.0 60.1 62.4 66.1 46.665.9 60.6 55.8 55.5 55.7
Contriever 56.761.744.454.547.745.156.727.850.244.354.351.952.5
+ MS MARCO 70.371.4 68.8 68.5 66.7 67.8 71.637.8 71.5 68.7 64.1 64.5 64.3

Bảng 14: Recall@20 trên MKQA cho truy xuất liên ngôn ngữ trong thiết lập được mô tả trong Phần 5.3.

avg en ar fi ja ko ru es sv he th da de fr
CORA 49.0 68.531.7 49.7 34.1 33.1 46.5 60.358.1 36.8 33.6 59.4 58.5 61.6
mBERT + MS MARCO 45.3 65.5 30.2 38.9 41.7 34.5 44.3 52.4 50.5 32.6 38.5 52.5 46.6 53.8
XLM-R + MS MARCO 46.7 64.5 29.0 45.1 39.7 34.9 45.9 51.4 56.1 32.5 49.4 55.8 48.3 50.5
Contriever 31.450.226.626.729.427.932.720.737.622.231.131.231.230.7
+ MS MARCO 53.967.2 40.1 55.1 46.2 41.7 52.359.3 60.0 45.6 52.062.054.859.3

it nl pl pt hu vi ms km no tr zh-cn zh-hk zh-tw
CORA 58.2 63.554.3 58.447.6 49.8 57.6 24.8 58.8 49.1 38.6 40.5 39.6
mBERT + MS MARCO 52.1 55.3 45.6 49.5 44.6 46.9 49.9 21.5 51.3 42.7 44.6 45.3 45.5
XLM-R + MS MARCO 45.4 54.5 48.5 49.6 47.3 49.7 54.0 33.453.7 48.7 42.4 42.4 42.0
Contriever 38.645.125.137.628.327.339.615.733.226.535.032.732.5
+ MS MARCO 59.460.9 58.156.9 55.2 55.9 60.926.2 61.0 56.7 50.9 51.9 51.2

--- TRANG 21 ---
Xuất bản trong Giao dịch về Nghiên cứu Học máy (08/2022)
Bảng 15: Suy giảm hiệu suất cho các bộ truy xuất đa ngôn ngữ. Chúng tôi báo cáo MRR@100 và R@100 trên tập kiểm tra của Mr. TyDi sau khi tiền huấn luyện trên hai tập hợp ngôn ngữ khác nhau, một tập chứa 11 ngôn ngữ của Mr. TyDi được bao gồm trong tập hợp 29 ngôn ngữ được sử dụng để huấn luyện mContriever được sử dụng trong phần còn lại của bài báo. Chúng tôi cũng báo cáo kết quả của những mô hình này sau khi tinh chỉnh trên MS MARCO, có thể theo sau bởi giai đoạn tinh chỉnh cuối cùng trên Mr. TyDi.

ar bn en fi id ja ko ru sw te th avg
MRR@100
11 ngôn ngữ 28.9 38.6 10.2 22.9 26.2 21.7 26.3 20.5 39.0 20.2 40.6 26.8
29 ngôn ngữ 27.3 36.3 9.2 21.1 23.5 19.5 22.3 17.5 38.3 22.5 37.2 25.0
+ MS MARCO
11 ngôn ngữ 44.0 41.1 26.8 38.3 43.4 34.7 37.1 37.6 55.3 32.1 45.8 39.7
29 ngôn ngữ 43.4 42.3 27.1 35.1 42.6 32.4 34.2 36.1 51.2 37.4 40.2 38.4
+ Mr. TyDi
11 ngôn ngữ 73.5 66.8 55.9 60.4 62.7 53.8 55.8 60.6 69.5 89.8 68.7 65.2
29 ngôn ngữ 72.4 67.2 56.6 60.2 63.0 54.9 55.3 59.7 70.7 90.3 67.3 65.2
R@100
11 ngôn ngữ 83.4 89.2 55.2 81.5 83.6 75.6 72.4 75.7 88.9 70.0 91.9 78.9
29 ngôn ngữ 82.0 89.6 48.8 79.6 81.4 72.8 66.2 68.5 88.7 80.8 90.3 77.2
+ MS MARCO
11 ngôn ngữ 89.6 91.9 78.7 89.0 91.2 83.4 80.2 86.0 92.6 95.9 92.8 88.3
29 ngôn ngữ 88.7 91.4 77.2 88.1 89.8 81.7 78.2 83.8 91.4 96.6 90.5 87.0
+ Mr. TyDi
11 ngôn ngữ 94.2 98.2 93.3 93.6 94.7 89.1 87.1 92.3 94.5 98.9 96.9 93.9
29 ngôn ngữ 94.0 98.6 92.2 92.7 94.5 88.8 88.9 92.4 93.7 98.9 95.2 93.6

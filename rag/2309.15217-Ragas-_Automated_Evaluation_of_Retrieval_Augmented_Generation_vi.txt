# 2309.15217.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2309.15217.pdf
# Kích thước tệp: 231984 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Ragas: Đánh giá Tự động của Thế hệ Tăng cường Truy xuất
Shahul Es†, Jithin James†, Luis Espinosa-Anke∗♢, Steven Schockaert∗
†Exploding Gradients
∗CardiffNLP, Cardiff University, United Kingdom
♢AMPLYFI, United Kingdom
shahules786@gmail.com,jamesjithin97@gmail.com
{espinosa-ankel,schockaerts1}@cardiff.ac.uk
Tóm tắt
Chúng tôi giới thiệu Ragas (Đánh giá Thế hệ Tăng cường Truy xuất), một framework để đánh giá không tham chiếu các pipeline Thế hệ Tăng cường Truy xuất (RAG). Các hệ thống RAG bao gồm một module truy xuất và một module sinh dựa trên LLM, và cung cấp cho LLM kiến thức từ một cơ sở dữ liệu văn bản tham chiếu, cho phép chúng hoạt động như một lớp ngôn ngữ tự nhiên giữa người dùng và cơ sở dữ liệu văn bản, giảm nguy cơ ảo giác. Tuy nhiên, việc đánh giá các kiến trúc RAG là thách thức vì có nhiều khía cạnh cần xem xét: khả năng của hệ thống truy xuất để xác định các đoạn văn bản liên quan và tập trung, khả năng của LLM để khai thác các đoạn văn bản đó một cách trung thực, hoặc chất lượng của việc sinh ra chính nó. Với Ragas, chúng tôi đưa ra một bộ các chỉ số có thể được sử dụng để đánh giá những khía cạnh khác nhau này mà không cần dựa vào các chú thích thực tế của con người. Chúng tôi cho rằng một framework như vậy có thể đóng góp quan trọng vào việc đánh giá nhanh hơn các kiến trúc RAG, điều này đặc biệt quan trọng do việc áp dụng nhanh chóng của LLM.

1 Giới thiệu
Các Mô hình Ngôn ngữ (LM) nắm bắt một lượng lớn kiến thức về thế giới, cho phép chúng trả lời câu hỏi mà không cần truy cập bất kỳ nguồn bên ngoài nào. Ý tưởng về LM như kho chứa kiến thức đã xuất hiện ngay sau khi giới thiệu BERT (Devlin et al., 2019) và trở nên vững chắc hơn với việc giới thiệu các LM ngày càng lớn hơn (Roberts et al., 2020). Trong khi các Mô hình Ngôn ngữ Lớn (LLM) gần đây nhất nắm bắt đủ kiến thức để sánh ngang với hiệu suất của con người trên nhiều benchmark trả lời câu hỏi (Bubeck et al., 2023), ý tưởng sử dụng LLM như cơ sở tri thức vẫn có hai hạn chế cơ bản. Thứ nhất, LLM không thể trả lời các câu hỏi về các sự kiện đã xảy ra sau khi chúng được huấn luyện. Thứ hai, ngay cả các mô hình lớn nhất cũng gặp khó khăn trong việc ghi nhớ kiến thức chỉ được đề cập hiếm khi trong corpus huấn luyện (Kandpal et al., 2022; Mallen et al., 2023). Giải pháp tiêu chuẩn cho những vấn đề này là dựa vào Thế hệ Tăng cường Truy xuất (RAG) (Lee et al., 2019; Lewis et al., 2020; Guu et al., 2020). Việc trả lời một câu hỏi về cơ bản bao gồm việc truy xuất các đoạn văn bản liên quan từ một corpus và đưa những đoạn văn bản này, cùng với câu hỏi gốc, cho LM. Trong khi các phương pháp ban đầu dựa vào các LM chuyên biệt cho việc mô hình hóa ngôn ngữ tăng cường truy xuất (Khandelwal et al., 2020; Borgeaud et al., 2022), các nghiên cứu gần đây đã đề xuất rằng việc đơn giản thêm các tài liệu được truy xuất vào đầu vào của một LM tiêu chuẩn cũng có thể hoạt động tốt (Khattab et al., 2022; Ram et al., 2023; Shi et al., 2023), do đó làm cho việc sử dụng các chiến lược tăng cường truy xuất kết hợp với các LLM chỉ có sẵn thông qua API trở nên khả thi.

Mặc dù tính hữu ích của các chiến lược tăng cường truy xuất là rõ ràng, việc triển khai chúng đòi hỏi một lượng điều chỉnh đáng kể, vì hiệu suất tổng thể sẽ bị ảnh hưởng bởi mô hình truy xuất, corpus được xem xét, LM, hoặc việc xây dựng prompt, trong số những yếu tố khác. Việc đánh giá tự động các hệ thống tăng cường truy xuất do đó là tối quan trọng. Trong thực tế, các hệ thống RAG thường được đánh giá theo nhiệm vụ mô hình hóa ngôn ngữ chính nó, tức là bằng cách đo perplexity trên một corpus tham chiếu. Tuy nhiên, những đánh giá như vậy không phải lúc nào cũng dự đoán được hiệu suất downstream (Wang et al., 2023c). Hơn nữa, chiến lược đánh giá này dựa vào xác suất LM, không thể truy cập được đối với một số mô hình đóng (ví dụ: ChatGPT và GPT-4). Trả lời câu hỏi là một nhiệm vụ đánh giá phổ biến khác, nhưng thường chỉ các dataset với câu trả lời trích xuất ngắn được xem xét, có thể không đại diện cho cách hệ thống sẽ được sử dụng.

Để giải quyết những vấn đề này, trong bài báo này chúng tôi trình bày Ragas¹, một framework để đánh giá tự động các hệ thống thế hệ tăng cường truy xuất. Chúng tôi tập trung vào các tình huống mà câu trả lời tham chiếu có thể không có sẵn, và nơi chúng tôi muốn ước tính các proxy khác nhau cho tính chính xác, ngoài tính hữu ích của các đoạn văn bản được truy xuất. Framework Ragas cung cấp tích hợp với cả llama-index và Langchain, các framework được sử dụng rộng rãi nhất để xây dựng các giải pháp RAG, do đó cho phép các nhà phát triển dễ dàng tích hợp Ragas vào quy trình làm việc tiêu chuẩn của họ.

2 Nghiên cứu Liên quan
Ước tính tính trung thực bằng LLM Vấn đề phát hiện ảo giác trong các phản hồi được tạo bởi LLM đã được nghiên cứu rộng rãi (Ji et al., 2023). Một số tác giả đã đề xuất ý tưởng dự đoán tính thực tế bằng cách sử dụng chiến lược prompting few-shot (Zhang et al., 2023). Tuy nhiên, các phân tích gần đây cho thấy rằng các mô hình hiện tại gặp khó khăn với việc phát hiện ảo giác khi sử dụng các chiến lược prompting tiêu chuẩn (Li et al., 2023; Azaria và Mitchell, 2023). Các phương pháp khác dựa vào việc liên kết các phản hồi được tạo với các sự kiện từ một cơ sở tri thức bên ngoài (Min et al., 2023), nhưng điều này không phải lúc nào cũng khả thi.

Một chiến lược khác là kiểm tra các xác suất được gán cho từng token, nơi chúng ta mong đợi mô hình sẽ ít tự tin hơn trong các câu trả lời ảo giác so với những câu trả lời thực tế. Ví dụ, BARTScore (Yuan et al., 2021) ước tính tính thực tế bằng cách xem xác suất có điều kiện của văn bản được tạo cho trước đầu vào. Kadavath et al. (2022) sử dụng một biến thể của ý tưởng này. Bắt đầu từ quan sát rằng LLM cung cấp các xác suất được hiệu chỉnh tốt khi trả lời các câu hỏi trắc nghiệm, họ về cơ bản chuyển đổi vấn đề xác thực câu trả lời được tạo bởi mô hình thành một câu hỏi trắc nghiệm hỏi liệu câu trả lời có đúng hay sai. Thay vì xem xác suất đầu ra, Azaria và Mitchell (2023) đề xuất huấn luyện một bộ phân loại có giám sát trên các trọng số từ một trong các lớp ẩn của LLM, để dự đoán liệu một tuyên bố cho trước có đúng hay không. Mặc dù phương pháp này hoạt động tốt, nhu cầu truy cập các trạng thái ẩn của mô hình làm cho nó không phù hợp cho các hệ thống truy cập LLM thông qua API.

Đối với các mô hình không cung cấp quyền truy cập vào xác suất token, như ChatGPT và GPT-4, cần các phương pháp khác. SelfCheckGPT (Manakul et al., 2023) giải quyết vấn đề này bằng cách thay vào đó lấy mẫu nhiều câu trả lời. Ý tưởng cốt lõi của họ là các câu trả lời thực tế ổn định hơn: khi một câu trả lời là thực tế, chúng ta có thể mong đợi rằng các mẫu khác nhau sẽ có xu hướng tương tự về mặt ngữ nghĩa, trong khi điều này ít có khả năng xảy ra đối với các câu trả lời ảo giác.

Đánh giá tự động các hệ thống sinh văn bản LLM cũng đã được tận dụng để tự động đánh giá các khía cạnh khác của các đoạn văn bản được tạo, ngoài tính thực tế. Ví dụ, GPTScore (Fu et al., 2023) sử dụng một prompt chỉ định khía cạnh được xem xét (ví dụ: tính trôi chảy) và sau đó chấm điểm các đoạn văn dựa trên xác suất trung bình của các token được tạo, theo một LM tự hồi quy cho trước. Ý tưởng sử dụng prompt này trước đây cũng đã được Yuan et al. (2021) xem xét, mặc dù họ đã sử dụng một LM được tinh chỉnh nhỏ hơn (tức là BART) và không quan sát thấy lợi ích rõ ràng từ việc sử dụng prompt. Một phương pháp khác trực tiếp yêu cầu ChatGPT đánh giá một khía cạnh cụ thể của câu trả lời đã cho bằng cách cung cấp điểm số từ 0 đến 100, hoặc bằng cách cung cấp xếp hạng trên thang 5 sao (Wang et al., 2023a). Đáng chú ý là có thể đạt được kết quả mạnh theo cách này, mặc dù nó đi kèm với hạn chế là nhạy cảm với thiết kế của prompt. Thay vì chấm điểm từng câu trả lời, một số tác giả cũng tập trung vào việc sử dụng LLM để chọn câu trả lời tốt nhất trong số một số ứng viên (Wang et al., 2023b), thường để so sánh hiệu suất của các LLM khác nhau. Tuy nhiên, cần cẩn thận với phương pháp này, vì thứ tự mà các câu trả lời được trình bày có thể ảnh hưởng đến kết quả (Wang et al., 2023b).

Về cách các câu trả lời thực tế hoặc, tổng quát hơn, các thế hệ, thường được sử dụng trong tài liệu, hầu hết các phương pháp đã dựa vào việc có sẵn một hoặc nhiều câu trả lời tham chiếu. Ví dụ, BERTScore (Zhang et al., 2020) và MoverScore (Zhao et al., 2019) sử dụng các embedding được ngữ cảnh hóa, được tạo bởi một mô hình BERT được huấn luyện trước, để so sánh sự tương tự giữa câu trả lời được tạo và các câu trả lời tham chiếu. BARTScore (Yuan et al., 2021) tương tự sử dụng các câu trả lời tham chiếu để tính toán các khía cạnh như precision (được ước tính là xác suất tạo ra câu trả lời được tạo cho trước tham chiếu) và recall (được ước tính là xác suất tạo ra tham chiếu cho trước câu trả lời được tạo).

3 Chiến lược Đánh giá
Chúng tôi xem xét một setting RAG tiêu chuẩn, nơi cho một câu hỏi q, hệ thống đầu tiên truy xuất một số ngữ cảnh c(q) và sau đó sử dụng ngữ cảnh được truy xuất để tạo ra một câu trả lời as(q). Khi xây dựng một hệ thống RAG, chúng ta thường không có quyền truy cập vào các dataset được chú thích bởi con người hoặc các câu trả lời tham chiếu. Do đó, chúng tôi tập trung vào các chỉ số hoàn toàn độc lập và không tham chiếu. Chúng tôi tập trung đặc biệt vào ba khía cạnh chất lượng, mà chúng tôi cho là có tầm quan trọng trung tâm.

Thứ nhất, Tính trung thực đề cập đến ý tưởng rằng câu trả lời nên được căn cứ trong ngữ cảnh đã cho. Điều này quan trọng để tránh ảo giác, và để đảm bảo rằng ngữ cảnh được truy xuất có thể hoạt động như một lý do chính đáng cho câu trả lời được tạo. Thật vậy, các hệ thống RAG thường được sử dụng trong các ứng dụng mà tính nhất quán thực tế của văn bản được tạo w.r.t. các nguồn được căn cứ là cực kỳ quan trọng, ví dụ: trong các lĩnh vực như luật pháp, nơi thông tin liên tục phát triển. Thứ hai, Tính liên quan của Câu trả lời đề cập đến ý tưởng rằng câu trả lời được tạo nên giải quyết câu hỏi thực tế đã được cung cấp. Cuối cùng, Tính liên quan của Ngữ cảnh đề cập đến ý tưởng rằng ngữ cảnh được truy xuất nên được tập trung, chứa ít thông tin không liên quan nhất có thể. Điều này quan trọng do chi phí liên quan đến việc đưa các đoạn ngữ cảnh dài cho LLM. Hơn nữa, khi các đoạn ngữ cảnh quá dài, LLM thường ít hiệu quả hơn trong việc khai thác ngữ cảnh đó, đặc biệt đối với thông tin được cung cấp ở giữa đoạn ngữ cảnh (Liu et al., 2023).

Bây giờ chúng tôi giải thích cách ba khía cạnh chất lượng này có thể được đo lường một cách hoàn toàn tự động, bằng cách prompting một LLM. Trong việc triển khai và thử nghiệm của chúng tôi, tất cả các prompt đều được đánh giá bằng mô hình gpt-3.5-turbo-16k, có sẵn thông qua OpenAI API².

Tính trung thực Chúng tôi nói rằng câu trả lời as(q) là trung thực với ngữ cảnh c(q) nếu các tuyên bố được đưa ra trong câu trả lời có thể được suy ra từ ngữ cảnh. Để ước tính tính trung thực, trước tiên chúng tôi sử dụng một LLM để trích xuất một tập hợp các tuyên bố, S(as(q)). Mục tiêu của bước này là phân tách các câu dài hơn thành các khẳng định ngắn hơn và tập trung hơn. Chúng tôi sử dụng prompt sau cho bước này³:

Cho một câu hỏi và câu trả lời, hãy tạo một hoặc nhiều tuyên bố từ mỗi câu trong câu trả lời đã cho.
câu hỏi: [câu hỏi]
câu trả lời: [câu trả lời]

trong đó [câu hỏi] và [câu trả lời] đề cập đến câu hỏi và câu trả lời đã cho. Đối với mỗi tuyên bố si trong S, LLM xác định liệu si có thể được suy ra từ c(q) bằng cách sử dụng hàm xác minh v(si, c(q)). Bước xác minh này được thực hiện bằng prompt sau:

Xem xét ngữ cảnh đã cho và các tuyên bố sau đây, sau đó xác định liệu chúng có được hỗ trợ bởi thông tin có trong ngữ cảnh hay không. Cung cấp giải thích ngắn gọn cho mỗi tuyên bố trước khi đến phán quyết (Có/Không). Cung cấp phán quyết cuối cùng cho mỗi tuyên bố theo thứ tự cuối cùng ở định dạng đã cho. Không sai lệch khỏi định dạng được chỉ định.
tuyên bố: [tuyên bố 1]
...
tuyên bố: [tuyên bố n]

Điểm tính trung thực cuối cùng, F, sau đó được tính là F=|V|/|S|, trong đó |V| là số lượng tuyên bố được hỗ trợ theo LLM và |S| là tổng số tuyên bố.

Tính liên quan của câu trả lời Chúng tôi nói rằng câu trả lời as(q) có liên quan nếu nó trực tiếp giải quyết câu hỏi một cách phù hợp. Đặc biệt, đánh giá tính liên quan của câu trả lời của chúng tôi không tính đến tính thực tế, nhưng phạt các trường hợp mà câu trả lời không đầy đủ hoặc nơi nó chứa thông tin dư thừa. Để ước tính tính liên quan của câu trả lời, đối với câu trả lời đã cho as(q), chúng tôi prompt LLM để tạo ra n câu hỏi tiềm năng qi dựa trên as(q), như sau:

Tạo một câu hỏi cho câu trả lời đã cho.
câu trả lời: [câu trả lời]

Sau đó chúng tôi thu được embedding cho tất cả các câu hỏi bằng mô hình text-embedding-ada-002, có sẵn từ OpenAI API. Đối với mỗi qi, chúng tôi tính toán độ tương tự sim(q, qi) với câu hỏi gốc q, là cosine giữa các embedding tương ứng. Điểm tính liên quan của câu trả lời, AR, cho câu hỏi q sau đó được tính như:

AR=1/n ∑(i=1 to n) sim(q, qi) (1)

Chỉ số này đánh giá mức độ câu trả lời được tạo phù hợp với câu hỏi hoặc hướng dẫn ban đầu.

Tính liên quan của ngữ cảnh Ngữ cảnh c(q) được coi là liên quan ở mức độ mà nó chỉ chứa thông tin cần thiết để trả lời câu hỏi. Đặc biệt, chỉ số này nhằm phạt việc bao gồm thông tin dư thừa. Để ước tính tính liên quan của ngữ cảnh, cho một câu hỏi q và ngữ cảnh c(q) của nó, LLM trích xuất một tập con các câu, Sext, từ c(q) mà quan trọng để trả lời q, bằng prompt sau:

Vui lòng trích xuất các câu liên quan từ ngữ cảnh được cung cấp mà có thể giúp trả lời câu hỏi sau đây. Nếu không tìm thấy câu liên quan nào, hoặc nếu bạn tin rằng câu hỏi không thể được trả lời từ ngữ cảnh đã cho, hãy trả về cụm từ "Thông tin Không đủ". Trong khi trích xuất các câu ứng viên, bạn không được phép thực hiện bất kỳ thay đổi nào đối với các câu từ ngữ cảnh đã cho.

Điểm tính liên quan của ngữ cảnh sau đó được tính như:
CR = số câu được trích xuất / tổng số câu trong c(q) (2)

4 Dataset WikiEval
Để đánh giá framework được đề xuất, lý tưởng là chúng ta cần các ví dụ về bộ ba câu hỏi-ngữ cảnh-câu trả lời được chú thích với các phán đoán của con người. Sau đó chúng ta có thể xác minh mức độ các chỉ số của chúng ta đồng ý với các đánh giá của con người về tính trung thực, tính liên quan của câu trả lời và tính liên quan của ngữ cảnh. Vì chúng tôi không biết về bất kỳ dataset nào có sẵn công khai có thể được sử dụng cho mục đích này, chúng tôi đã tạo một dataset mới, mà chúng tôi gọi là WikiEval⁴. Để xây dựng dataset, trước tiên chúng tôi đã chọn 50 trang Wikipedia bao gồm các sự kiện đã xảy ra từ đầu năm 2022⁵. Trong việc chọn những trang này, chúng tôi ưu tiên những trang có chỉnh sửa gần đây. Đối với mỗi trong 50 trang, sau đó chúng tôi yêu cầu ChatGPT đề xuất một câu hỏi có thể được trả lời dựa trên phần giới thiệu của trang, bằng prompt sau:

Nhiệm vụ của bạn là xây dựng một câu hỏi từ ngữ cảnh đã cho thỏa mãn các quy tắc được đưa ra dưới đây:
1. Câu hỏi nên được trả lời đầy đủ từ ngữ cảnh đã cho.
2. Câu hỏi nên được xây dựng từ một phần chứa thông tin không tầm thường.
3. Câu trả lời không nên chứa bất kỳ liên kết nào.
4. Câu hỏi nên có độ khó vừa phải.
5. Câu hỏi phải hợp lý và phải được con người hiểu và phản hồi.
6. Không sử dụng các cụm từ 'ngữ cảnh được cung cấp', v.v. trong câu hỏi
ngữ cảnh:

Chúng tôi cũng sử dụng ChatGPT để trả lời câu hỏi được tạo, khi được cung cấp phần giới thiệu tương ứng làm ngữ cảnh, bằng prompt sau:

Trả lời câu hỏi bằng thông tin từ ngữ cảnh đã cho.
câu hỏi: [câu hỏi]
ngữ cảnh: [ngữ cảnh]

Tất cả các câu hỏi được chú thích theo ba khía cạnh chất lượng được xem xét bởi hai người chú thích. Cả hai người chú thích đều thông thạo tiếng Anh và được cung cấp hướng dẫn rõ ràng về ý nghĩa của ba khía cạnh chất lượng được xem xét. Đối với tính trung thực và tính liên quan của ngữ cảnh, hai người chú thích đồng ý trong khoảng 95% trường hợp. Đối với tính liên quan của câu trả lời, họ đồng ý trong khoảng 90% trường hợp. Các bất đồng được giải quyết sau cuộc thảo luận giữa các người chú thích.

Tính trung thực Để có được phán đoán của con người về tính trung thực, trước tiên chúng tôi sử dụng ChatGPT để trả lời câu hỏi mà không có quyền truy cập vào bất kỳ ngữ cảnh bổ sung nào. Sau đó chúng tôi yêu cầu các người chú thích đánh giá câu trả lời nào trong hai câu trả lời là trung thực nhất (tức là câu trả lời tiêu chuẩn hoặc câu trả lời được tạo mà không có ngữ cảnh), cho trước câu hỏi và trang Wikipedia tương ứng.

Tính liên quan của câu trả lời Trước tiên chúng tôi sử dụng ChatGPT để có được các câu trả lời ứng viên với tính liên quan của câu trả lời thấp hơn, bằng prompt sau:

Trả lời câu hỏi đã cho một cách không đầy đủ.
câu hỏi: [câu hỏi]

Sau đó chúng tôi yêu cầu các người chú thích con người so sánh câu trả lời này, và chỉ ra câu trả lời nào trong hai câu trả lời có tính liên quan của câu trả lời cao nhất.

Tính liên quan của ngữ cảnh Để đo lường khía cạnh này, trước tiên chúng tôi thêm các câu bổ sung vào ngữ cảnh bằng cách scraping các back-link đến trang Wikipedia tương ứng. Theo cách này, chúng tôi có thể thêm thông tin vào ngữ cảnh mà có liên quan nhưng ít liên quan hơn để trả lời câu hỏi. Đối với một số trang không có back-link nào, thay vào đó chúng tôi sử dụng ChatGPT để hoàn thành ngữ cảnh đã cho.

5 Thí nghiệm
Bảng 1 phân tích sự đồng ý giữa các chỉ số được đề xuất trong Phần 3 và các đánh giá của con người từ dataset WikiEval được đề xuất. Mỗi instance WikiEval yêu cầu mô hình so sánh hai câu trả lời hoặc hai đoạn ngữ cảnh. Chúng tôi đếm số lần câu trả lời/ngữ cảnh được mô hình ưa thích (tức là với tính trung thực, tính liên quan của câu trả lời, hoặc tính liên quan của ngữ cảnh được ước tính cao nhất) trùng khớp với câu trả lời/ngữ cảnh được các người chú thích con người ưa thích. Chúng tôi báo cáo kết quả về độ chính xác (tức là phần các instance mà mô hình đồng ý với các người chú thích).

Để đặt kết quả vào bối cảnh, chúng tôi so sánh các chỉ số được đề xuất của chúng tôi (được hiển thị là Ragas trong Bảng 1) với hai phương pháp baseline. Đối với phương pháp đầu tiên, được hiển thị là GPT Score, chúng tôi yêu cầu ChatGPT gán điểm từ 0 đến 10 cho ba khía cạnh chất lượng. Để làm điều này, chúng tôi sử dụng một prompt mô tả ý nghĩa của chỉ số chất lượng và sau đó yêu cầu chấm điểm câu trả lời/ngữ cảnh đã cho theo định nghĩa đó. Ví dụ, để đánh giá tính trung thực, chúng tôi đã sử dụng prompt sau:

Tính trung thực đo lường tính nhất quán thông tin của câu trả lời so với ngữ cảnh đã cho. Bất kỳ tuyên bố nào được đưa ra trong câu trả lời mà không thể được suy ra từ ngữ cảnh đều nên bị phạt.
Cho một câu trả lời và ngữ cảnh, hãy gán điểm cho tính trung thực trong phạm vi 0-10.
ngữ cảnh: [ngữ cảnh]
câu trả lời: [câu trả lời]

Các trường hợp hòa, nơi cùng một điểm số được LLM gán cho cả hai ứng viên câu trả lời, được phá vỡ ngẫu nhiên. Baseline thứ hai, được hiển thị là GPT Ranking, thay vào đó yêu cầu ChatGPT chọn câu trả lời/ngữ cảnh được ưa thích. Trong trường hợp này, prompt cũng bao gồm định nghĩa của chỉ số chất lượng được xem xét. Ví dụ, để đánh giá tính liên quan của câu trả lời, chúng tôi đã sử dụng prompt sau:

Tính liên quan của câu trả lời đo lường mức độ mà một phản hồi trực tiếp giải quyết và phù hợp với một câu hỏi đã cho. Nó phạt sự hiện diện của thông tin dư thừa hoặc câu trả lời không đầy đủ cho một câu hỏi. Cho một câu hỏi và câu trả lời, hãy xếp hạng mỗi câu trả lời dựa trên Tính liên quan của câu trả lời.
câu hỏi: [câu hỏi]
câu trả lời 1: [câu trả lời 1]
câu trả lời 2: [câu trả lời 2]

Kết quả trong Bảng 1 cho thấy rằng các chỉ số được đề xuất của chúng tôi phù hợp hơn nhiều với các phán đoán của con người so với các dự đoán từ hai baseline. Đối với tính trung thực, các dự đoán Ragas nhìn chung có độ chính xác cao. Đối với tính liên quan của câu trả lời, sự đồng ý thấp hơn, nhưng điều này phần lớn do thực tế là sự khác biệt giữa hai câu trả lời ứng viên thường rất tinh tế. Chúng tôi thấy tính liên quan của ngữ cảnh là khía cạnh chất lượng khó đánh giá nhất. Đặc biệt, chúng tôi quan sát thấy rằng ChatGPT thường gặp khó khăn với nhiệm vụ chọn các câu từ ngữ cảnh mà quan trọng, đặc biệt đối với các ngữ cảnh dài hơn.

6 Kết luận
Chúng tôi đã nhấn mạnh nhu cầu đánh giá tự động không tham chiếu các hệ thống RAG. Đặc biệt, chúng tôi đã lập luận về nhu cầu cho một framework đánh giá có thể đánh giá tính trung thực (tức là câu trả lời có được căn cứ trong ngữ cảnh được truy xuất không), tính liên quan của câu trả lời (tức là câu trả lời có giải quyết câu hỏi không) và tính liên quan của ngữ cảnh (tức là ngữ cảnh được truy xuất có đủ tập trung không). Để hỗ trợ việc phát triển một framework như vậy, chúng tôi đã giới thiệu WikiEval, một dataset với các phán đoán của con người về ba khía cạnh khác nhau này. Cuối cùng, chúng tôi cũng đã mô tả Ragas, việc triển khai của chúng tôi về ba khía cạnh chất lượng được xem xét. Framework này dễ sử dụng và có thể cung cấp cho các nhà phát triển hệ thống RAG những hiểu biết có giá trị, ngay cả khi không có bất kỳ ground truth nào. Đánh giá của chúng tôi trên WikiEval đã cho thấy rằng các dự đoán từ Ragas phù hợp chặt chẽ với các dự đoán của con người, đặc biệt đối với tính trung thực và tính liên quan của câu trả lời.

--- TRANG 6 ---
Tài liệu tham khảo
Amos Azaria và Tom M. Mitchell. 2023. Trạng thái nội bộ của một LLM biết khi nó nói dối. CoRR, abs/2304.13734.

Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, và Laurent Sifre. 2022. Cải thiện các mô hình ngôn ngữ bằng cách truy xuất từ hàng nghìn tỷ token. Trong Hội nghị Quốc tế về Học máy, ICML 2022, 17-23 tháng 7 năm 2022, Baltimore, Maryland, USA, tập 162 của Proceedings of Machine Learning Research, trang 2206–2240. PMLR.

Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Những tia sáng của trí tuệ nhân tạo tổng quát: Các thí nghiệm sớm với gpt-4. arXiv preprint arXiv:2303.12712.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Huấn luyện trước các transformer hai chiều sâu để hiểu ngôn ngữ. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, và Pengfei Liu. 2023. Gptscore: Đánh giá như bạn mong muốn. CoRR, abs/2302.04166.

Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, và Mingwei Chang. 2020. Huấn luyện trước mô hình ngôn ngữ tăng cường truy xuất. Trong International conference on machine learning, trang 3929–3938. PMLR.

Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, và Pascale Fung. 2023. Khảo sát về ảo giác trong sinh ngôn ngữ tự nhiên. ACM Computing Surveys, 55(12):1–38.

Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, và Jared Kaplan. 2022. Các mô hình ngôn ngữ (hầu hết) biết những gì chúng biết. CoRR, abs/2207.05221.

Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, và Colin Raffel. 2022. Các mô hình ngôn ngữ lớn gặp khó khăn trong việc học kiến thức long-tail. CoRR, abs/2211.08411.

Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, và Mike Lewis. 2020. Tổng quát hóa thông qua ghi nhớ: Các mô hình ngôn ngữ láng giềng gần nhất. Trong 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.

Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, và Matei Zaharia. 2022. Demonstrate-search-predict: Kết hợp truy xuất và mô hình ngôn ngữ cho NLP chuyên sâu kiến thức. CoRR, abs/2212.14024.

Kenton Lee, Ming-Wei Chang, và Kristina Toutanova. 2019. Truy xuất tiềm ẩn cho trả lời câu hỏi miền mở có giám sát yếu. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 6086–6096.

Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, và Douwe Kiela. 2020. Sinh tăng cường truy xuất cho các nhiệm vụ NLP chuyên sâu kiến thức. Trong Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.

Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, và Ji-Rong Wen. 2023. Halueval: Một benchmark đánh giá ảo giác quy mô lớn cho các mô hình ngôn ngữ lớn. CoRR, abs/2305.11747.

Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, và Percy Liang. 2023. Lạc lối ở giữa: Cách các mô hình ngôn ngữ sử dụng ngữ cảnh dài.

Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, và Hannaneh Hajishirzi. 2023. Khi nào không nên tin tưởng các mô hình ngôn ngữ: Điều tra hiệu quả của bộ nhớ tham số và không tham số. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 9802–9822, Toronto, Canada. Association for Computational Linguistics.

Potsawee Manakul, Adian Liusie, và Mark J. F. Gales. 2023. Selfcheckgpt: Phát hiện ảo giác zero-resource black-box cho các mô hình ngôn ngữ lớn sinh. CoRR, abs/2303.08896.

Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, và Hannaneh Hajishirzi. 2023. Factscore: Đánh giá nguyên tử chi tiết về độ chính xác thực tế trong sinh văn bản dạng dài. CoRR, abs/2305.14251.

--- TRANG 7 ---
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, và Yoav Shoham. 2023. Các mô hình ngôn ngữ tăng cường truy xuất trong ngữ cảnh. CoRR, abs/2302.00083.

Adam Roberts, Colin Raffel, và Noam Shazeer. 2020. Bạn có thể nhồi nhét bao nhiêu kiến thức vào các tham số của một mô hình ngôn ngữ? Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 5418–5426, Online. Association for Computational Linguistics.

Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, và Wen-tau Yih. 2023. REPLUG: các mô hình ngôn ngữ black-box tăng cường truy xuất. CoRR, abs/2301.12652.

Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, và Jie Zhou. 2023a. ChatGPT có phải là một người đánh giá NLG tốt không? Một nghiên cứu sơ bộ. CoRR, abs/2303.04048.

Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, và Zhifang Sui. 2023b. Các mô hình ngôn ngữ lớn không phải là những người đánh giá công bằng. CoRR, abs/2305.17926.

Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun Manjunatha, và Mohit Iyyer. 2023c. KNN-LM không cải thiện sinh văn bản mở. CoRR, abs/2305.14625.

Weizhe Yuan, Graham Neubig, và Pengfei Liu. 2021. Bartscore: Đánh giá văn bản được tạo như sinh văn bản. Trong Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, trang 27263–27277.

Tianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei Fang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu, Danny Fox, Helen Meng, và James R. Glass. 2023. Kiểm tra ngôn ngữ thống nhất có thể diễn giải. CoRR, abs/2304.03728.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, và Yoav Artzi. 2020. Bertscore: Đánh giá sinh văn bản với BERT. Trong 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.

Wei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Christian M. Meyer, và Steffen Eger. 2019. MoverScore: Đánh giá sinh văn bản với embedding được ngữ cảnh hóa và khoảng cách earth mover. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 563–578, Hong Kong, China. Association for Computational Linguistics.

A Ví dụ từ WikiEval
Bảng 2, 3 và 4 hiển thị các ví dụ từ dataset WikiEval, tập trung đặc biệt vào các câu trả lời có tính trung thực cao và thấp (Bảng 2), tính liên quan của câu trả lời cao và thấp (Bảng 3), và tính liên quan của ngữ cảnh cao và thấp (Bảng 4).

--- TRANG 8 ---
Câu hỏi Ngữ cảnh Câu trả lời
Ai đã đạo diễn bộ phim Oppenheimer và ai đóng vai J. Robert Oppenheimer trong phim? Oppenheimer là một bộ phim tiểu sử kinh dị năm 2023 được viết và đạo diễn bởi Christopher Nolan. Dựa trên cuốn tiểu sử năm 2005 American Prometheus của Kai Bird và Martin J. Sherwin, bộ phim kể về cuộc đời của J. Robert Oppenheimer, một nhà vật lý lý thuyết đóng vai trò then chốt trong việc phát triển vũ khí hạt nhân đầu tiên như một phần của Dự án Manhattan, và do đó mở ra Kỷ nguyên Nguyên tử. Cillian Murphy đóng vai Oppenheimer, với Emily Blunt trong vai Katherine "Kitty" Oppenheimer, vợ của Oppenheimer. Tính trung thực cao: Christopher Nolan đã đạo diễn bộ phim Oppenheimer. Cillian Murphy đóng vai J. Robert Oppenheimer trong phim.
Tính trung thực thấp: James Cameron đã đạo diễn bộ phim Oppenheimer. Tom Cruise đóng vai J. Robert Oppenheimer trong phim.

Bảng 2: Ví dụ từ WikiEval, hiển thị câu trả lời có tính trung thực cao và thấp.

Câu hỏi Câu trả lời
Ngày và giờ phóng dự kiến cho nhiệm vụ PSLV-C56 là khi nào, và nó sẽ được phóng từ đâu? Tính liên quan của câu trả lời cao: Nhiệm vụ PSLV-C56 dự kiến được phóng vào Chủ nhật, ngày 30 tháng 7 năm 2023 lúc 06:30 IST / 01:00 UTC. Nó sẽ được phóng từ Trung tâm Vũ trụ Satish Dhawan, Sriharikota, Andhra Pradesh, Ấn Độ.
Tính liên quan của câu trả lời thấp: Ngày và giờ phóng dự kiến cho nhiệm vụ PSLV-C56 chưa được cung cấp. Nhiệm vụ PSLV-C56 là một nhiệm vụ vũ trụ quan trọng của Ấn Độ. Nó nhằm phóng một vệ tinh lên quỹ đạo để nghiên cứu các mô hình thời tiết.

Bảng 3: Ví dụ từ WikiEval, hiển thị câu trả lời có tính liên quan của câu trả lời cao và thấp.

Câu hỏi Ngữ cảnh
Tháp Đồng hồ Chimnabai được hoàn thành khi nào, và nó được đặt tên theo ai? Tính liên quan của ngữ cảnh cao: Tháp Đồng hồ Chimnabai, còn được gọi là Tháp Raopura, là một tháp đồng hồ nằm trong khu vực Raopura của Vadodara, Gujarat, Ấn Độ. Nó được hoàn thành vào năm 1896 và được đặt tên để tưởng nhớ Chimnabai I (1864–1885), một nữ hoàng và là vợ đầu tiên của Sayajirao Gaekwad III của Bang Baroda.
Tính liên quan của ngữ cảnh thấp: Tháp Đồng hồ Chimnabai, còn được gọi là Tháp Raopura, là một tháp đồng hồ nằm trong khu vực Raopura của Vadodara, Gujarat, Ấn Độ. Nó được hoàn thành vào năm 1896 và được đặt tên để tưởng nhớ Chimnabai I (1864–1885), một nữ hoàng và là vợ đầu tiên của Sayajirao Gaekwad III của Bang Baroda. Nó được xây dựng theo phong cách kiến trúc Indo-Saracenic. Lịch sử. Tháp Đồng hồ Chimnabai được xây dựng vào năm 1896. Tháp được đặt tên theo Chimnabai I (1864–1885), một nữ hoàng và là vợ đầu tiên của Sayajirao Gaekwad III của Bang Baroda. Nó được khánh thành bởi Mir Kamaluddin Hussainkhan, Nawab cuối cùng của Baroda. Trong thời kỳ cầm quyền của Gaekwad, nó là một điểm dừng cho xe điện do ngựa kéo. Tháp đồng hồ được xây dựng với chi phí 25.000 (tương đương 9,2 triệu hoặc 120.000 USD vào năm 2023).

Bảng 4: Ví dụ từ WikiEval, hiển thị câu trả lời có tính liên quan của ngữ cảnh cao và thấp.

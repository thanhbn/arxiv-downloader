# 2310.01558.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2310.01558.pdf
# Kích thước tệp: 792223 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
LÀM CHO CÁC MÔ HÌNH NGÔN NGỮ TĂNG CƯỜNG TRUY XUẤT
BỀN VỮNG VỚI NGỮ CẢNH KHÔNG LIÊN QUAN
Ori Yoran1Tomer Wolfson1,2Ori Ram1Jonathan Berant1
1Đại học Tel Aviv,2Viện AI Allen
{ori.yoran, ori.ram, joberant }@cs.tau.ac.il tomerw@allenai.org
TÓM TẮT
Các mô hình ngôn ngữ tăng cường truy xuất (RALMs) hứa hẹn tạo ra các hệ thống hiểu ngôn ngữ có tính thực tế, hiệu quả và cập nhật. Một yêu cầu quan trọng của RALMs là thông tin được truy xuất giúp cải thiện hiệu suất mô hình khi nó có liên quan, và không làm tổn hại hiệu suất khi không có liên quan. Điều này đặc biệt quan trọng trong các tình huống lý luận đa bước, nơi việc sử dụng sai bằng chứng không liên quan có thể dẫn đến lỗi dây chuyền. Tuy nhiên, nghiên cứu gần đây đã cho thấy rằng việc tăng cường truy xuất đôi khi có thể có tác động tiêu cực đến hiệu suất. Trong công trình này, chúng tôi trình bày một phân tích kỹ lưỡng trên năm tiêu chuẩn trả lời câu hỏi miền mở, mô tả các trường hợp khi truy xuất làm giảm độ chính xác. Sau đó chúng tôi đề xuất hai phương pháp để giảm thiểu vấn đề này. Thứ nhất, một đường cơ sở đơn giản lọc ra các đoạn văn được truy xuất không kéo theo các cặp câu hỏi-trả lời theo mô hình suy luận ngôn ngữ tự nhiên (NLI). Điều này có hiệu quả trong việc ngăn chặn sự suy giảm hiệu suất, nhưng cũng phải trả giá bằng việc loại bỏ các đoạn văn có liên quan. Do đó, chúng tôi đề xuất một phương pháp tự động tạo dữ liệu để tinh chỉnh mô hình ngôn ngữ để tận dụng đúng các đoạn văn được truy xuất, bao gồm cả các nhiệm vụ đa bước thách thức, sử dụng hỗn hợp các ngữ cảnh có liên quan và không liên quan trong thời gian huấn luyện. Chúng tôi chứng minh thực nghiệm rằng ngay cả 1.000 ví dụ cũng đủ để huấn luyện mô hình bền vững với các ngữ cảnh không liên quan trong khi duy trì hiệu suất cao trên các ví dụ có ngữ cảnh liên quan.

1 GIỚI THIỆU
Các Mô hình Ngôn ngữ Lớn (LLMs) (Brown và cộng sự, 2020; Chowdhery và cộng sự, 2022; Touvron và cộng sự, 2023) là nền tảng mà các hệ thống ngôn ngữ hiện đại được xây dựng. Tuy nhiên, trả lời câu hỏi miền mở (ODQA; Chen và cộng sự 2017) và các nhiệm vụ chuyên sâu về kiến thức khác (Thorne và cộng sự, 2018; Petroni và cộng sự, 2021) đòi hỏi lượng lớn kiến thức thực tế cập nhật về các thực thể hiếm mà ngay cả các mô hình rất lớn cũng không thể ghi nhớ (Roberts và cộng sự, 2020; Dhingra và cộng sự, 2022). Một cách tiếp cận thống trị để chống lại vấn đề này là Các Mô hình Ngôn ngữ Tăng cường Truy xuất (RALMs), tích hợp cơ chế truy xuất để giảm nhu cầu lưu trữ thông tin trong các tham số LLM (Guu và cộng sự, 2020; Lewis và cộng sự, 2020b; Izacard và cộng sự, 2023; Rubin & Berant, 2023). Hơn nữa, RALMs cũng đã được chứng minh là cải thiện hiệu suất ODQA trong bối cảnh trong ngữ cảnh (không cần huấn luyện), đơn giản bằng cách thêm các câu được truy xuất vào đầu câu hỏi đầu vào (Ram và cộng sự, 2023). Tuy nhiên, các bộ truy xuất không hoàn hảo và nghiên cứu trước đây đã cho thấy rằng việc truy xuất nhiễu có thể ảnh hưởng tiêu cực đến hiệu suất LLM (Petroni và cộng sự, 2020; Li và cộng sự, 2023). Ví dụ, trong Hình 1, khi được đặt câu hỏi "Ai đang đóng vai Jason trong General Hospital?" một LLM gốc (trái) trả lời đúng câu hỏi trong khi RALM (phải) bị "phân tâm" bởi ngữ cảnh không liên quan về diễn viên đóng Cooper, không phải Jason.

Trong công trình này, chúng tôi phân tích và cải thiện tính bền vững của RALMs đối với các ngữ cảnh được truy xuất nhiễu. Định nghĩa của chúng tôi về LLMs bền vững truy xuất nêu rằng: (a) khi có liên quan, ngữ cảnh được truy xuất nên cải thiện hiệu suất mô hình; (b) khi không liên quan, ngữ cảnh được truy xuất không nên làm tổn hại hiệu suất mô hình. Để đạt được điều này, chúng tôi trình bày hai phương pháp cho tính bền vững truy xuất trong RALMs (§2).

Đầu tiên, chúng tôi xem xét một tình huống mà chúng tôi có quyền truy cập hộp đen vào LLM và không thể huấn luyện nó. Thay vì chỉ dựa vào việc nhắc nhở trong ngữ cảnh (Brown và cộng sự, 2020), chúng tôi đóng khung tính bền vững truy xuất như một vấn đề suy luận ngôn ngữ tự nhiên (NLI) (Dagan và cộng sự, 2006; Bowman và cộng sự, 2015). Cụ thể, cho một câu hỏi và ngữ cảnh được truy xuất, một mô hình NLI có thể dự đoán liệu một cặp câu hỏi-trả lời
1arXiv:2310.01558v2  [cs.CL]  5 Tháng 5 2024

--- TRANG 2 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Câu trả lời là: Steve BurtonH: Ai là diễn viên đóng vai Jason trong general hospital?B: Jason Gerhardt (sinh ngày 21 tháng 4 năm 1974) là một diễn viên người Mỹ. Anh được biết đến với vai diễn Cooper Barrett trong General Hospital và Zack Kilmer trong Mistresses. Câu trả lời là: Jason GerhardtMô hình Ngôn ngữ Lớn (không truy xuất)Mô hình Ngôn ngữ Tăng cường Truy xuất

Hình 1: Một ví dụ từ NQ nơi việc tăng cường truy xuất khiến Llama-2-13B mắc lỗi. Việc tăng cường với ngữ cảnh được truy xuất không liên quan dẫn đến lỗi (phải), mặc dù mô hình có thể trả lời câu hỏi mà không cần truy xuất (trái).

(giả thuyết) có được kéo theo bởi ngữ cảnh (tiền đề). Dựa trên hiệu suất mạnh mẽ của các mô hình NLI gần đây (ví dụ, trong việc phát hiện ảo giác mô hình (Honovich và cộng sự, 2022) và trả lời câu hỏi có thuộc tính (Bohnet và cộng sự, 2023)), chúng tôi sử dụng các mô hình như vậy để xác định các ngữ cảnh không liên quan. Khi ngữ cảnh được gắn nhãn là không liên quan đến cặp câu hỏi-trả lời, chúng tôi tạo ra câu trả lời bằng LLM mà không cần truy xuất như một "chiến lược dự phòng". Kết quả của chúng tôi cho thấy rằng đường cơ sở tự nhiên này rất hiệu quả trong việc xác định các ngữ cảnh không liên quan, nhưng quá nghiêm ngặt và cũng loại bỏ những ngữ cảnh có liên quan (§4).

Sau đó chúng tôi đề xuất một phương pháp để huấn luyện RALMs có tính bền vững truy xuất. Một cách trực quan, LLMs không được huấn luyện với các đoạn văn được truy xuất, và do đó tính dễ vỡ đối với việc truy xuất nhiễu ở một mức độ nào đó là có thể mong đợi. Do đó, chúng tôi thực hiện một bước tinh chỉnh bổ sung để dạy LLM bền vững với các ngữ cảnh nhiễu. Thách thức cốt lõi là tạo ra dữ liệu để tinh chỉnh, và chúng tôi mô tả một quy trình để tự động tạo ra dữ liệu như vậy cho cả câu hỏi đơn bước và đa bước. Trong bối cảnh đơn bước, giả định có quyền truy cập vào các cặp QA vàng và một bộ truy xuất, chúng tôi tạo ra các ví dụ huấn luyện sử dụng các ngữ cảnh được truy xuất, nơi chúng ta có thể sử dụng các đoạn văn xếp hạng thấp hoặc ngẫu nhiên làm ngữ cảnh nhiễu. Trong bối cảnh đa bước, các ví dụ huấn luyện cần chứa không chỉ các ngữ cảnh được truy xuất, mà còn các câu hỏi trung gian, câu trả lời và ngữ cảnh liên quan, tạo thành việc phân tách câu hỏi (Hình 3), được chứng minh là cần thiết cho hiệu suất cao trên các câu hỏi đa bước (Wolfson và cộng sự, 2020; Press và cộng sự, 2023). Để tạo ra các phân tách để huấn luyện, chúng tôi sử dụng một LLM mạnh, được nhắc nhở về phân tách mà không có bất kỳ truy xuất nào. Sau đó, chúng ta có thể lấy mẫu nhiều phân tách, và sử dụng tính nhất quán tự (Wang và cộng sự, 2023) để xác định các ví dụ huấn luyện chất lượng cao (§3.2.3).

Để kiểm tra các phương pháp của chúng tôi, chúng tôi đánh giá tính bền vững truy xuất trên năm tiêu chuẩn ODQA, bốn trong số đó chứa các câu hỏi đa bước, nơi bộ truy xuất được gọi nhiều lần (Jiang và cộng sự, 2023). Hình 2 cho thấy rằng ngay cả với một bộ truy xuất mạnh (tìm kiếm Google top-1) việc kết hợp ngữ cảnh được truy xuất thực sự làm tổn hại hiệu suất mô hình trên hai tiêu chuẩn (STRATEGYQA và FERMI). Hơn nữa, việc thêm các ngữ cảnh được truy xuất ngẫu nhiên làm giảm đáng kể độ chính xác trên tất cả năm bộ dữ liệu. Phân tích của chúng tôi (§5) cho thấy rằng ngữ cảnh không liên quan gây ra một loạt các lỗi, bao gồm sao chép câu trả lời không liên quan từ các câu được truy xuất và ảo giác các câu trả lời và phân tách không chính xác.

Kết quả của chúng tôi chứng minh rằng việc tinh chỉnh LLMs để có tính bền vững truy xuất cho phép chúng bỏ qua ngữ cảnh không liên quan trong khi cải thiện độ chính xác tổng thể của chúng (§4). Khi sử dụng một bộ truy xuất mạnh tại thời điểm kiểm tra, các mô hình được tinh chỉnh của chúng tôi vượt trội hơn cả các mô hình được tinh chỉnh mà không cần truy xuất, cũng như các mô hình chưa được huấn luyện được nhắc nhở bằng học tập trong ngữ cảnh. Để kiểm tra tính bền vững đối với ngữ cảnh nhiễu, chúng tôi đánh giá độ chính xác QA khi các mô hình được cung cấp các ngữ cảnh được truy xuất ngẫu nhiên. Trong bối cảnh này, các mô hình được tinh chỉnh của chúng tôi hoạt động ngang bằng với những mô hình được tinh chỉnh mà không cần truy xuất, chứng minh tính bền vững truy xuất. Ngoài ra, nghiên cứu loại bỏ của chúng tôi cho thấy rằng việc huấn luyện các mô hình trên hỗn hợp các ngữ cảnh có liên quan và không liên quan dẫn đến các mô hình bền vững hơn nhiều đối với ngữ cảnh không liên quan.

Tóm lại, các đóng góp chính của chúng tôi là:
• Chúng tôi tiến hành một phân tích kỹ lưỡng về tính bền vững của RALMs đối với các ngữ cảnh được truy xuất không liên quan.
• Chúng tôi cho thấy rằng các mô hình NLI nhỏ có thể được sử dụng để xác định ngữ cảnh không liên quan và cải thiện tính bền vững, mà không cần cập nhật các tham số mô hình.
• Chúng tôi chứng minh rằng việc huấn luyện LLMs khi nào sử dụng truy xuất giúp làm cho các mô hình bền vững với ngữ cảnh không liên quan và cải thiện hiệu suất tổng thể của chúng, bao gồm cả trong các nhiệm vụ đa bước thách thức.1

1Mã, dữ liệu và mô hình của chúng tôi có sẵn tại https://github.com/oriyor/ret-robust.
2

--- TRANG 3 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
020406080
NQ
(Đơn bước)Bamboogle
(Đa bước rõ ràng)2WikiMQA
(Đa bước rõ ràng)StrategyQA
(Đa bước ngầm)Fermi
(Đa bước ngầm)Không Truy xuất RALM (Truy xuất Top-1) RALM (Truy xuất Ngẫu nhiên)

Hình 2: Độ chính xác cho Llama-2-13B được nhắc nhở few-shot trên năm nhiệm vụ QA, trong ba bối cảnh: (a) không có truy xuất, (b) với truy xuất top-1 từ một công cụ tìm kiếm mạnh, và (c) với một đoạn văn được truy xuất ngẫu nhiên. Việc tăng cường truy xuất có thể tăng hiệu suất, nhưng ngay cả việc truy xuất mạnh cũng làm tổn hại hiệu suất trên StrategyQA và Fermi, và các ngữ cảnh ngẫu nhiên làm giảm hiệu suất một cách đáng kể.

2 LÀM CHO RALMS BỀN VỮNG VỚI CÁC NGỮ CẢNH KHÔNG LIÊN QUAN

Bây giờ chúng tôi trình bày các phương pháp của chúng tôi để xây dựng RALMs có tính bền vững với các ngữ cảnh không liên quan. Chúng tôi bắt đầu bằng cách mô tả cách tiếp cận phổ biến để kết hợp bằng chứng vào RALMs. Tiếp theo, chúng tôi khám phá một đường cơ sở tự nhiên để sử dụng mô hình NLI để xác định các ngữ cảnh không liên quan. Cuối cùng, chúng tôi mô tả quy trình của chúng tôi để tinh chỉnh các mô hình có tính bền vững với ngữ cảnh không liên quan.

RALMs trong ngữ cảnh Các mô hình ngôn ngữ định nghĩa một phân phối xác suất trên các chuỗi token, với các mô hình tự hồi quy gán xác suất thông qua dự đoán token tiếp theo: pLM= Πn i=1pθ(xi|x<i), trong đó x<i là chuỗi token đứng trước xi tại mỗi bước và θ biểu thị các tham số của LM. Đối với RALMs, chúng tôi tuân theo định nghĩa của RALMs trong ngữ cảnh từ Ram và cộng sự (2023), nơi các câu ngữ cảnh được truy xuất từ một corpus C, và việc tạo ra được điều kiện bởi ngữ cảnh được truy xuất. Cho thao tác truy xuất RC, điều này có thể được hình thức hóa như pRALM = Πn i=1pθ(xi|RC(x<i);x<i), trong đó [RC(x<i);x<i] biểu thị việc nối bằng chứng được truy xuất với chuỗi được tạo ra. Việc tạo ra trong LMs và RALMs cũng có thể được điều kiện bởi đầu vào bổ sung, mà chúng tôi bỏ qua để ngắn gọn.

Trong bối cảnh của chúng tôi, chúng tôi tập trung vào RALMs cho ODQA. Chúng tôi tuân theo các cách tiếp cận gần đây như Self-Ask và IR-CoT (Press và cộng sự, 2023; Trivedi và cộng sự, 2023; Yoran và cộng sự, 2023), để xen kẽ truy xuất với trả lời câu hỏi đa bước (xem Hình 3). Truy xuất được thực hiện cho mỗi câu hỏi trung gian và mỗi ngữ cảnh được thêm vào đầu câu hỏi. Trong bối cảnh đơn bước, mô hình phải tạo ra câu trả lời cho một câu hỏi và ngữ cảnh được truy xuất. Trong bối cảnh đa bước, mô hình phải tạo ra các câu hỏi và câu trả lời trung gian cho đến khi đến câu trả lời cuối cùng và bộ truy xuất được gọi cho câu hỏi gốc và sau mỗi câu hỏi trung gian. Một cách chính thức, x trong trường hợp này là phân tách được tạo ra cho đến một bước trung gian và RC(x) là các ngữ cảnh được truy xuất cho tất cả các câu hỏi trong x.

2.1 XÁC ĐỊNH CÁC NGỮ CẢNH KHÔNG LIÊN QUAN VỚI CÁC MÔ HÌNH NLI.

Các mô hình NLI (Dagan và cộng sự, 2006; Bowman và cộng sự, 2015) phân loại liệu một giả thuyết văn bản có được kéo theo, trung tính, hay mâu thuẫn với một tiền đề văn bản. Nghiên cứu gần đây đã sử dụng thành công các mô hình NLI để tự động xác định ảo giác (Honovich và cộng sự, 2022) và gán thuộc tính câu lệnh (Bohnet và cộng sự, 2023) khi được trình bày với một ngữ cảnh và văn bản được tạo ra. Tương tự, một đường cơ sở tự nhiên là đóng khung việc xác định ngữ cảnh không liên quan như một vấn đề NLI, bằng cách chỉ sử dụng ngữ cảnh được truy xuất khi giả thuyết (tức là, câu trả lời cuối cùng và các cặp câu hỏi-trả lời trung gian; Hình 3) được phân loại là được kéo theo bởi tiền đề (tức là, ngữ cảnh được truy xuất). Chúng tôi sử dụng một chiến lược dự phòng đơn giản nơi chúng tôi tạo ra hai lần, một lần với pLM và một lần với pRALM, và chỉ sử dụng RALM nếu mô hình NLI phân loại tất cả các câu trả lời được tạo ra (và các câu hỏi trung gian) là được kéo theo bởi bằng chứng được truy xuất.
3

--- TRANG 4 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Có đúng là Đại tá Walter Phelps phục vụ Quân đội Hoa Kỳ hơn 30 năm không?Q1: Đại tá Walter Phelps là ai?E1: Walter Phelps: (29 tháng 10 năm 1832–20 tháng 2 năm 1878) là một sĩ quan trong Quân đội Liên bang suốt Nội chiến Hoa Kỳ, phục vụ với tư cách là sĩ quan chỉ huy của Lữ đoàn Sắt Phía Đông.E1: Walter Phelps: (29 tháng 10 năm 1832–20 tháng 2 năm 1878) là một sĩ quan...Q1: Đại tá Walter Phelps là ai?A1: Đại tá Walter Phelps là một sĩ quan trong Quân đội Liên bang suốt Nội chiến Hoa Kỳ.Bước truy xuất #1

Trả lời phân tách #1 Bước phân tách #1A1: Đại tá Walter Phelps là một sĩ quan trong...Q2: Đại tá Walter Phelps phục vụ Quân đội Hoa Kỳ bao lâu?E2: Walter Phelps: [['Walter Phelps Jr.'], ['Allegiance', 'United States of America Union'], ['Service/branch', 'United States Army Union Army'], ['Years of service', '1861-1865'], ['Rank', 'Colonel Bvt. Brigadier General']]...A1: Đại tá...Q2: Đại tá Walter Phelps phục vụ Quân đội Hoa Kỳ bao lâu?A2: Đại tá Walter Phelps phục vụ Quân đội Hoa Kỳ trong 4 năm.Bước truy xuất #1Trả lời phân tách #2 Bước phân tách #2Câu trả lời cuối cùng.Câu trả lời cuối cùng là:Không.

Hình 3: Xen kẽ phân tách và truy xuất theo định dạng Self-Ask (Press và cộng sự, 2023). Mô hình tạo ra các câu hỏi và câu trả lời trung gian cho đến khi tạo ra câu trả lời cuối cùng (các thế hệ mô hình được hiển thị bằng màu hồng). Bằng chứng được truy xuất cho các câu hỏi trung gian được thêm vào đầu mỗi bước.

Ví dụ, trong Hình 1, bằng chứng được truy xuất "Jason Gerhardt... là một diễn viên người Mỹ... được biết đến với vai diễn Cooper Barrett..." phục vụ như tiền đề trong khi câu hỏi và câu trả lời được tạo ra, "H: Ai là diễn viên đóng vai Jason trong general hospital? A: Steve Burton" được nối lại và phục vụ như giả thuyết của chúng ta. Vì ngữ cảnh này không liên quan, chúng ta mong đợi mô hình NLI gắn nhãn giả thuyết là mâu thuẫn. Với một giả thuyết mâu thuẫn hoặc trung tính, chúng ta sẽ sử dụng LLM tiêu chuẩn mà không có ngữ cảnh được truy xuất (có khả năng gây phân tâm). Đối với các câu hỏi đa bước (như trong Hình 3), chúng ta bổ sung xác minh rằng mỗi cặp câu trả lời trung gian được kéo theo bởi bằng chứng được truy xuất bằng cách sử dụng tất cả bằng chứng được truy xuất làm tiền đề của chúng ta và cặp câu hỏi-câu trả lời trung gian làm giả thuyết. Ví dụ, "H: Đại tá Walter Phelps là ai? A: Đại tá Walter Phelps là một sĩ quan trong Quân đội Liên bang suốt Nội chiến Hoa Kỳ." cho câu hỏi trung gian đầu tiên trong Hình 3.

2.2 HUẤN LUYỆN RALMS BỀN VỮNG

Vì RALMs trong ngữ cảnh không được huấn luyện để sử dụng các đoạn văn được truy xuất, một giải pháp hiệu quả hơn việc lọc sau (sử dụng NLI) có thể là huấn luyện RALMs để bỏ qua các ngữ cảnh không liên quan. Chúng tôi quan tâm đến việc kiểm tra liệu việc huấn luyện trên một bộ dữ liệu tương đối nhỏ (vài trăm ví dụ) có đủ hay không.

Tự động Tạo Dữ liệu Huấn luyện Mục tiêu của chúng tôi là dạy RALMs có tính bền vững với ngữ cảnh không liên quan trong bối cảnh ODQA. Trong bối cảnh đơn bước, việc tạo dữ liệu huấn luyện là đơn giản. Cho quyền truy cập vào một bộ dữ liệu các cặp câu hỏi-trả lời {(q, a)} (tức là, không có ngữ cảnh) và một bộ truy xuất RC, chúng tôi sử dụng bộ truy xuất để tăng cường các câu hỏi với ngữ cảnh được truy xuất. Để tạo ra các ví dụ huấn luyện với ngữ cảnh liên quan, chúng tôi trả về ngữ cảnh top-1 từ RC, và cho ngữ cảnh không liên quan, chúng tôi trả về một kết quả xếp hạng thấp từ RC(q) hoặc một ngữ cảnh ngẫu nhiên (tức là, RC(q′) cho một câu hỏi khác q′). Chúng tôi ký hiệu ngữ cảnh được chọn bằng rq. Sau đó, bộ dữ liệu huấn luyện được định nghĩa bởi D={([rq;q], a)}.

Thách thức chính của chúng tôi là tạo ra các ví dụ huấn luyện cho các câu hỏi đa bước. Trong những câu hỏi này, mô hình tạo ra một phân tách, bao gồm các câu hỏi và câu trả lời trung gian, trước khi đến câu trả lời cuối cùng, trong khi bộ truy xuất được gọi nhiều lần (Hình 3). Mục tiêu của chúng tôi là tự động tạo ra các bước phân tách tăng cường truy xuất, D={([rx;x], y)}, trong đó: y là thế hệ chính xác cho mỗi bước (tức là, câu hỏi trung gian chính xác, câu trả lời trung gian, hoặc câu trả lời cuối cùng); x bao gồm các bước đã tạo ra trước đó cho đến y; rx là các ngữ cảnh được truy xuất cho tất cả các bước trong x.

Bước đầu tiên của chúng tôi để tự động tạo ra các phân tách là nhắc nhở một LLM mạnh mà không có quyền truy cập vào truy xuất và xác minh các câu trả lời của nó. Tuy nhiên, LLM có thể đến được câu trả lời đúng bằng cách sử dụng một phân tách không chính xác, ví dụ trong các câu hỏi nhị phân hoặc so sánh. Do đó, chúng ta cần đảm bảo chất lượng của các phân tách được tạo ra. Đối với các bộ dữ liệu đa bước cung cấp các câu trả lời trung gian, chúng tôi đơn giản lọc ra các phân tách được tạo ra không chứa chúng. Khi không có chú thích câu trả lời trung gian, chúng tôi lấy mẫu từ LLM đã tạo ra phân tách nhiều lần và xác minh tính nhất quán tự (Wang và cộng sự, 2023). Chi tiết thêm được đưa ra trong §3.2.3.
4

--- TRANG 5 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Bộ dữ liệu Loại Ví dụ
NQ Đơn bước Tập nào của law and order svu có Mike Tyson tham gia?
2WIKIMQA Rõ ràng Nơi chết của cha Isabella Of Bourbon ở đâu?
BAMBOOGLE Rõ ràng Tốc độ tối đa (tính bằng km/h) của loài chim nhanh thứ ba là bao nhiêu?
STRATEGYQA Ngầm Arnold Schwarzenegger có thể nâng deadlift một con tê giác đen trưởng thành không?
FERMI Ngầm Lebron James đã cho/nhận được bao nhiêu cú high five?

Bảng 1: Các bộ dữ liệu QA trong thí nghiệm của chúng tôi.

Huấn luyện Chúng tôi sử dụng dữ liệu được tạo tự động D để tinh chỉnh các mô hình để tạo ra y được điều kiện bởi [rx;x] với maximum likelihood tiêu chuẩn. Vì chúng tôi chủ yếu quan tâm đến chế độ dữ liệu thấp, chúng tôi giới hạn số lượng câu hỏi trong D thành 1.000 trong bối cảnh đơn bước và 500 trong bối cảnh đa bước (chia các câu hỏi đa bước thành nhiều ví dụ cho mỗi bước), và sử dụng tinh chỉnh hiệu quả tham số (Dettmers và cộng sự, 2023). Do đó, việc huấn luyện tất cả các mô hình của chúng tôi không mất hơn vài giờ. Chi tiết thực nghiệm bổ sung trong §3 và §A.1.

3 THIẾT LẬP THỰC NGHIỆM

3.1 BỘ DỮ LIỆU

Chúng tôi thử nghiệm với cả bộ dữ liệu QA đơn và đa bước. Chúng tôi liệt kê và đưa ra một ví dụ từ mỗi bộ dữ liệu trong Bảng 1. Các tiêu chuẩn QA của chúng tôi có thể được phân loại dựa trên kỹ năng lý luận yêu cầu của chúng:

•Đơn bước: Các câu hỏi tìm kiếm thông tin không yêu cầu phân tách. Chúng tôi sử dụng bộ dữ liệu Natural Questions (NQ) phổ biến (Kwiatkowski và cộng sự, 2019).

•Lý luận Rõ ràng: Các câu hỏi đa bước nơi lý luận được thể hiện rõ ràng trong câu hỏi. Chúng tôi bao gồm 2WIKIMQA (Welbl và cộng sự, 2018) và BAMBOOGLE (Press và cộng sự, 2023).

•Lý luận Ngầm: Các câu hỏi đa bước nơi việc tạo ra các bước lý luận yêu cầu common sense (lý luận ngầm, Geva và cộng sự (2021)). Những câu hỏi như vậy có thể có nhiều chuỗi lý luận hợp lệ. Chúng tôi đánh giá trên STRATEGYQA (Geva và cộng sự, 2021) và FERMI (Kalyan và cộng sự, 2021).

Để đánh giá, chúng tôi tuân theo nghiên cứu trước đây và sử dụng EM cho NQ và STRATEGYQA, và F1 cho 2WIKIMQA và BAMBOOGLE. Cho FERMI, chúng tôi sử dụng đánh giá order-of-magnitude chính thức (Kalyan và cộng sự 2021). Tuân theo nghiên cứu trước đây (Khattab và cộng sự, 2022; Trivedi và cộng sự, 2023; Yoran và cộng sự, 2023), chúng tôi đánh giá trên 500 ví dụ ngẫu nhiên từ tập phát triển của mỗi bộ dữ liệu. Chúng tôi cung cấp chi tiết kỹ thuật bổ sung về đánh giá trong §A.2.

3.2 MÔ HÌNH

Tiếp theo chúng tôi mô tả các bộ truy xuất (§3.2.1), đường cơ sở được nhắc nhở (§3.2.2), và các mô hình được tinh chỉnh (§3.2.3) của chúng tôi.

3.2.1 BỘ TRUY XUẤT

Các mô hình của chúng tôi sử dụng một bộ truy xuất dựa trên GOOGLE SEARCH,2 cũng như COLBERTV2 mã nguồn mở (Khattab & Zaharia, 2020). Vì corpus cho các bộ dữ liệu của chúng tôi là Wikipedia, chúng tôi định dạng các truy vấn tìm kiếm như "en.wikipedia.org qi" khi truy cập GOOGLE SEARCH. Cho COLBERTV2 corpus của chúng tôi là Wikipedia 2018 từ Karpukhin và cộng sự (2020). Để mô phỏng các loại nhiễu khác nhau, chúng tôi trả về top-1, một bằng chứng liên quan xếp hạng thấp,3 hoặc một đoạn văn ngẫu nhiên là bằng chứng top-1 cho một câu hỏi khác hoặc câu hỏi trung gian từ cùng bộ dữ liệu.

2Chúng tôi truy vấn tìm kiếm Google qua dịch vụ SerpAPI: https://serpapi.com/.
3Cho GOOGLE SEARCH, chúng tôi sử dụng kết quả thấp nhất được trả về từ API, có thứ hạng trung bình là 9.3. Cho COLBERTV2 chúng tôi chỉ thử nghiệm với kết quả top-1.
5

--- TRANG 6 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

3.2.2 ĐƯỜNG CƠ SỞ ĐƯỢC NHẮC NHỞ FEW-SHOT

Các đường cơ sở chính của chúng tôi là các mô hình Llama-2-13B được nhắc nhở cho QA theo định dạng Self-Ask thông qua học tập trong ngữ cảnh (Brown và cộng sự, 2020) với 4-6 mẫu. Chúng tôi cũng đánh giá với Llama-2-70B trên NQ. Các đường cơ sở của chúng tôi khác nhau dựa trên các ngữ cảnh được truy xuất trong các mẫu (Nhắc nhở đầy đủ trong §A.5):

•Self-Ask No Retrieval (SA-NR): Các mẫu là các phân tách vàng mà không có bằng chứng được truy xuất. Chúng tôi sử dụng nhắc nhở này để đánh giá hiệu suất của các mô hình mà không có truy xuất, khi chỉ dựa vào bộ nhớ tham số của chúng, tức là, thông tin được mã hóa trong các tham số của mô hình. Như một đường cơ sở bổ sung, chúng tôi sử dụng nhắc nhở không truy xuất này, nhưng vẫn áp dụng truy xuất trong quá trình suy luận.

•Self-Ask Retrieval@1 (SA-R@1): Các mẫu là các phân tách vàng được thêm vào đầu với bằng chứng liên quan nhất được truy xuất từ GOOGLE SEARCH cho mỗi bước.

•Self-Ask Retrieval@10 (SA-R@10): Các mẫu là các phân tách vàng được thêm vào đầu với đoạn văn xếp hạng thấp nhất từ Google (thường là hạng 10 trong hầu hết trường hợp).

•Self-Ask Random Retrieval (SA-RMix) Các mẫu là các phân tách vàng được thêm vào đầu với bằng chứng top-1 hoặc xếp hạng thấp nhất từ GOOGLE SEARCH, xen kẽ.

Các Mô hình dựa trên NLI Chúng tôi sử dụng một mô hình BART-Large (Lewis và cộng sự, 2020a) với 407 triệu tham số được huấn luyện trên bộ dữ liệu MNLI (Williams và cộng sự, 2018).4 Chúng tôi coi một cặp câu hỏi-trả lời là được kéo theo nếu xác suất cho nhãn entailment là ≥0.5. Tất cả các đường cơ sở được nhắc nhở few-shot có một biến thể với NLI, được gọi là SA-*-NLI. Khi không có entailment, chúng tôi sử dụng thế hệ từ mô hình SA-NR, sử dụng chỉ bộ nhớ tham số làm chiến lược dự phòng.

3.2.3 CÁC MÔ HÌNH ĐƯỢC TINH CHỈNH

Chúng tôi tinh chỉnh Llama-2-13B trên 3 tiêu chuẩn ODQA, một đơn bước (NQ, 1000 ví dụ huấn luyện), một rõ ràng (2WIKIMQA, 500 câu hỏi, 1.539 ví dụ), và một ngầm (STRATEGYQA, 414 câu hỏi, 1.584 ví dụ). Các siêu tham số huấn luyện trong §A.1.

Tạo Dữ liệu Chúng tôi sử dụng một LLM để xác minh các câu hỏi có thể trả lời được và tạo ra các phân tách.5 Điều này được thực hiện với GPT-3, code-davinci-002 (Brown và cộng sự, 2020; Chen và cộng sự, 2021) với 175B tham số. Chúng tôi nhắc nhở mô hình tạo ra các phân tách bằng nhắc nhở SA-NR.

2WIKIMQA chứa các câu trả lời trung gian, và chúng tôi sử dụng những câu trả lời đó để xác minh các phân tách được tạo ra. Cho STRATEGYQA ngầm chúng tôi chỉ sử dụng câu trả lời cuối cùng, và do đó sử dụng tính nhất quán tự, như được giải thích trong §2. Chúng tôi lấy mẫu 5 phân tách cho mỗi câu hỏi (một với giải mã tham lam và bốn với nhiệt độ 0.7) và chỉ giữ phân tách được giải mã tham lam khi tất cả các phân tách dẫn đến cùng câu trả lời đúng. Để xác minh chất lượng của các phân tách được tạo ra, chúng tôi kiểm tra thủ công 50 phân tách cho mỗi bộ dữ liệu và thấy rằng các phân tách được tạo ra là chính xác khoảng 90% thời gian cho STRATEGYQA và hơn 95% cho 2WIKIMQA. Vì FERMI và BAMBOOGLE chứa ít hơn 300 ví dụ, chúng tôi sử dụng chúng chỉ để đánh giá và không bao gồm chúng trong những thí nghiệm này.

Kết hợp Bằng chứng Được Truy xuất trong Các Ví dụ Huấn luyện Để đảm bảo mô hình được tiếp xúc với ngữ cảnh có liên quan và không liên quan, chúng tôi sử dụng bằng chứng top-1, xếp hạng thấp, hoặc ngẫu nhiên với xác suất bằng nhau tại mỗi bước. Chúng tôi gọi mô hình được huấn luyện là SA-RetRobust. Chúng tôi bao gồm các loại bỏ nơi huấn luyện không có ngữ cảnh được truy xuất (SA-NoRet) hoặc chỉ với bằng chứng top-1 (SA-Ret@1).

4 KẾT QUẢ

Hình 4 trình bày kết quả chính của chúng tôi, đánh giá tác động mà việc truy xuất kết quả top-1 từ GOOGLE SEARCH có trên các RALMs sau: (a) một RALM Trong ngữ cảnh, được nhắc nhở với nhắc nhở SA-RMix (màu vàng ở bên trái nhất), (b) cùng mô hình đó, nhưng sử dụng các mô hình NLI để xác định ngữ cảnh không liên quan (trung tâm, màu xanh lá), và (c) SA-RetRobust được đề xuất của chúng tôi, một RALM được tinh chỉnh trên hỗn hợp các ngữ cảnh có liên quan

4Chúng tôi sử dụng mô hình từ https://huggingface.co/facebook/bart-large-mnli.
5Để không huấn luyện các mô hình của chúng tôi để ảo giác, chúng tôi cũng lọc các câu hỏi đơn bước nơi code-davinci-002 không tạo ra câu trả lời đúng. Tuy nhiên, chúng tôi không hoàn toàn đảm bảo rằng câu trả lời vàng xuất hiện trong ngữ cảnh được truy xuất hoặc được mã hóa trong các tham số của mô hình đang được huấn luyện.
6

--- TRANG 7 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

-10010203040
NQ (29.6)2WikiMQA (32.0)StrategyQA (65.6)Bamboogle (47.4)Fermi (27.7)RALM Trong ngữ cảnh RALM Trong ngữ cảnh + NLIRALM Được huấn luyện (RetRobust)Bộ dữ liệu có dữ liệu huấn luyệnBộ dữ liệu không có dữ liệu huấn luyện

Hình 4: Kết quả cho các mô hình của chúng tôi trên tất cả các bộ dữ liệu đánh giá khi truy xuất kết quả top-1 từ GOOGLE SEARCH. Các thanh cho thấy sự khác biệt về hiệu suất từ một mô hình không có truy xuất (hiệu suất của nó được đưa ra trong ngoặc đơn cho mỗi bộ dữ liệu). Việc nhắc nhở các mô hình sử dụng truy xuất trong ngữ cảnh (thanh trái nhất) tăng hiệu suất trên các bộ dữ liệu đơn bước và rõ ràng, nhưng giảm hiệu suất trên những bộ dữ liệu ngầm (STRATEGYQA và FERMI). Khi sử dụng các mô hình NLI để xác định bằng chứng không liên quan (thanh trung tâm), truy xuất không bao giờ gây tổn hại, với chi phí cho các lợi ích nhận được khi truy xuất hữu ích. Các RALM được huấn luyện của chúng tôi (cột phải nhất) vượt trội hơn tất cả các mô hình khác khi áp dụng cho NQ, 2WIKIMQA, và STRATEGYQA (xem §3.2.3 để biết thêm chi tiết về tạo dữ liệu).

và không liên quan (phải nhất, màu cam). Các thanh cho thấy sự khác biệt về hiệu suất từ mô hình được nhắc nhở few-shot của chúng tôi mà không có truy xuất (hiệu suất của nó được hiển thị trong ngoặc đơn cho mỗi bộ dữ liệu). Đối với RALM Trong ngữ cảnh, chúng tôi quan sát thấy rằng truy xuất giúp ích trên NQ, 2WIKIMQA và BAMBOOGLE nhưng làm giảm hiệu suất trên STRATEGYQA và FERMI ngầm. Việc thêm NLI để xác định ngữ cảnh không liên quan đảm bảo rằng truy xuất không gây tổn hại, nhưng các lợi ích bị hạn chế. Huấn luyện với truy xuất dẫn đến lợi ích trên toàn bộ. Chúng tôi quan sát các xu hướng tương tự với bộ truy xuất COLBERTV2, mặc dù ở mức giảm tổng thể về độ chính xác (§A.3, Bảng 3.)

Khám phá Tính bền vững của Mô hình đối với Ngữ cảnh Không liên quan Hình 5 trình bày kết quả khi mô phỏng truy xuất ngữ cảnh không liên quan/nhiễu, bằng cách truy xuất các đoạn văn xếp hạng thấp (trên) hoặc ngẫu nhiên (dưới). Khi truy xuất các đoạn văn ngẫu nhiên, hiệu suất của RALM Trong ngữ cảnh giảm hơn 10 điểm trung bình, một hiện tượng có thể được giảm thiểu bằng cách sử dụng các mô hình NLI. SA-RetRobust hoạt động tốt nhất trong tất cả các thiết lập. Để xác minh rằng những cải thiện này thực sự xuất phát từ tính bền vững đối với ngữ cảnh không liên quan hơn là huấn luyện cụ thể nhiệm vụ, chúng tôi so sánh SA-RetRobust với một biến thể loại bỏ được huấn luyện và đánh giá mà không có truy xuất (kết quả đầy đủ trong Bảng 4, §A.3). SA-RetRobust có thể hoạt động tương tự như mô hình này (trong một độ lệch chuẩn) khi truy xuất các ngữ cảnh ngẫu nhiên. Thú vị là, khi truy xuất các kết quả xếp hạng thấp, SA-RetRobust vượt trội hơn mô hình loại bỏ 3.8 và 2.8 điểm trên NQ và 2WIKIMQA, trong khi chỉ hoạt động kém hơn một chút (trong sự khác biệt 1.2 điểm) trên STRATEGYQA. Nhìn chung, kết quả của chúng tôi cho thấy SA-RetRobust đã học cách vừa tận dụng tốt hơn việc truy xuất vừa bỏ qua ngữ cảnh không liên quan.

Thêm Truy xuất vào Các Mẫu trong ngữ cảnh có thể Gây tổn hại Hiệu suất Bảng 2 và Bảng 3 trong §A.3 trình bày kết quả đầy đủ với các bộ truy xuất GOOGLE SEARCH và COLBERTV2. Thú vị là, việc cung cấp các mẫu với truy xuất hoạt động kém hơn việc cung cấp các mẫu mà không có truy xuất, tức là, nhắc nhở SA-NR dẫn đến hiệu suất tốt hơn ngay cả khi truy xuất được thực hiện tại thời điểm suy luận. Nhắc nhở SA-NR này liên tục vượt trội hơn các nhắc nhở với truy xuất (SA-R@1, SA-R@10, và SA-RMix) khi truy xuất kết quả top-1 từ COLBERTV2 hoặc các ngữ cảnh ngẫu nhiên từ GOOGLE SEARCH. Ngoài ra, mô hình SA-R@1 chứa kết quả top-1 trong nhắc nhở không phải là mô hình hoạt động tốt nhất ngay cả khi truy xuất kết quả top-1 tại thời điểm suy luận, thua SA-NR hơn 2 điểm trung bình trên các bộ dữ liệu. Khi truy xuất các ngữ cảnh nhiễu tại thời điểm suy luận, SA-R@1 bị vượt trội bởi các mô hình khác, cho thấy rằng việc hiển thị các ví dụ cho truy xuất trong quá trình học tập trong ngữ cảnh có tác động tiêu cực gây ra việc sử dụng quá mức ngữ cảnh không liên quan. Chúng tôi quan sát một xu hướng tương tự với Llama-2-70B trong §A.3, Bảng 6.

Tác động của NLI Khi truy xuất các ngữ cảnh ngẫu nhiên hoặc đánh giá trên STRATEGYQA và FERMI ngầm, các biến thể NLI liên tục hoạt động tốt nhất, cho thấy các mô hình NLI nhỏ đủ để xác định bằng chứng không liên quan (Bảng 2 và Bảng 3 trong §A.3). Tuy nhiên, chúng làm giảm hiệu suất trong các trường hợp
7

--- TRANG 8 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

-25-15-5515
NQ (29.6)2WikiMQA (32.0)StrategyQA (65.6)Bamboogle (47.4)Fermi (27.7)RALM Trong ngữ cảnh RALM Trong ngữ cảnh + NLIRALM Được huấn luyện (RetRobust)

-25-15-5515
NQ (29.6)2WikiMQA (32.0)StrategyQA (65.6)Bamboogle (47.4)Fermi (27.7)RALM Trong ngữ cảnh RALM Trong ngữ cảnh + NLIRALM Được huấn luyện (RetRobust)Bộ dữ liệu có dữ liệu huấn luyệnBộ dữ liệu không có dữ liệu huấn luyện

Hình 5: Kết quả với truy xuất xếp hạng thấp (trên) và ngẫu nhiên (dưới). Các mô hình tương tự như trong Hình 4. Hiệu suất giảm đáng kể cho mô hình được nhắc nhở trong tất cả các thiết lập, trong khi được duy trì khi sử dụng các mô hình NLI. SA-RetRobust được tinh chỉnh của chúng tôi hoạt động tốt nhất trong tất cả các thiết lập. Chúng tôi cho thấy rằng SA-RetRobust đã học cách vừa bỏ qua ngữ cảnh không liên quan vừa tận dụng tốt hơn ngữ cảnh có liên quan bằng cách so sánh với một mô hình loại bỏ không có truy xuất trong §4.

truy xuất hữu ích, ví dụ, trên 2WIKIMQA và BAMBOOGLE rõ ràng. Chúng tôi thực hiện một phân tích chi tiết cho các biến thể NLI của chúng tôi trong §5.

Kết quả với Các Mô hình Được tinh chỉnh Hình 4 và Hình 5 cho thấy SA-RetRobust liên tục vượt trội hơn các mô hình khác. Trong §A.3, Bảng 4, chúng tôi trình bày tất cả kết quả cho tất cả các mô hình được huấn luyện, cho thấy SA-RetRobust vượt trội hơn các đường cơ sở loại bỏ của chúng tôi. Cụ thể, nó vượt trội hơn SA-NoRet (được tinh chỉnh mà không có truy xuất) 2.7, 2.4, và 2.4 điểm trung bình khi sử dụng ngữ cảnh top-1, xếp hạng thấp, hoặc ngẫu nhiên từ GOOGLE SEARCH trong quá trình suy luận, và SA-@1 lần lượt 0.2, 0.4, 3.2 điểm. Khi truy xuất kết quả top-1 từ COLBERTV2, SA-RetRobust vượt trội hơn SA-NoRet và SA-@1 lần lượt 2.7 và 0.3 điểm trung bình. Kết quả của chúng tôi cho thấy rằng huấn luyện trên hỗn hợp các ngữ cảnh có liên quan và không liên quan là cần thiết cho tính bền vững và cải thiện hiệu suất. Chúng tôi cung cấp một nghiên cứu về khả năng tổng quát hóa của các mô hình được huấn luyện của chúng tôi sang các thiết lập khác trong §A.3.

Kết quả với Llama-2-70B Chúng tôi so sánh SA-RetRobust với Llama-2-70B trên bộ dữ liệu NQ để đánh giá liệu các mô hình lớn hơn có bền vững hơn với các ngữ cảnh không liên quan hay không. Không có truy xuất, Llama-2-70B được nhắc nhở vượt trội hơn Llama-2-13B được huấn luyện 4.3 điểm (38.4 so với 34.1). Tuy nhiên, khi truy xuất kết quả top-1 từ GOOGLE SEARCH, SA-RetRobust vượt trội hơn tất cả các biến thể Llama-2-70B được nhắc nhở ít nhất 3.3 điểm (45.7 so với 42.4), cho thấy rằng việc tăng kích thước mô hình một mình không đủ để làm cho các mô hình tận dụng tốt hơn việc truy xuất. Chúng tôi cung cấp kết quả đầy đủ trong §A.3, Bảng 6.

5 PHÂN TÍCH

Khi nào Ngữ cảnh Không liên quan Gây ra Lỗi? Để đánh giá các lỗi do ngữ cảnh không liên quan gây ra, chúng tôi xem xét thủ công các ví dụ từ NQ, 2WIKIMQA và STRATEGYQA, nơi các mô hình thành công mà không có truy xuất, nhưng thất bại với nó. Cụ thể, chúng tôi xem xét các ví dụ nơi mô hình được nhắc nhở với nhắc nhở SA-RMix bao gồm cả kết quả truy xuất top-1 và xếp hạng thấp và được trình bày với bằng chứng được truy xuất xếp hạng thấp hoặc ngẫu nhiên trong quá trình suy luận. Chúng tôi chú thích thủ công 40 ví dụ trong mỗi thiết lập (240 tổng cộng), và thấy rằng các lỗi tự động thực sự tương quan với các trường hợp mà việc tăng cường truy xuất khiến mô hình mắc lỗi trong 73% các trường hợp (65%-85% trong mỗi thiết lập). Chúng tôi cung cấp chi tiết bổ sung và các kiểm định thống kê trong §A.4.

Sau đó chúng tôi xem xét kỹ hơn các lỗi. Đối với NQ chúng tôi thấy rằng khi sử dụng ngữ cảnh xếp hạng thấp, thực thể câu trả lời sai được tạo ra xuất hiện trong ngữ cảnh được truy xuất trong đa số (77%) các trường hợp, nhưng chỉ 37% khi truy xuất các ngữ cảnh ngẫu nhiên. Điều này cho thấy rằng ngữ cảnh không liên quan có thể gây ra lỗi ngay cả khi các thực thể được tạo ra không được truy xuất, như được hiển thị trong §A.4, Hình 6. Đối với các câu hỏi đa bước, chúng tôi kiểm tra liệu ngữ cảnh không liên quan dẫn đến lỗi trong phân tách câu hỏi, hay trong việc trả lời các câu hỏi trung gian. Chúng tôi thấy rằng khi truy xuất các đoạn văn xếp hạng thấp, hầu hết các lỗi
8

--- TRANG 9 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

(68%) cho 2WIKIMQA rõ ràng là ở các câu trả lời trung gian, trái ngược với STRATEGYQA ngầm nơi các lỗi phổ biến hơn trong các câu hỏi trung gian (77% các trường hợp, chúng tôi cung cấp một ví dụ trong §A.4, Hình 7). Tương tự, khi truy xuất các ngữ cảnh ngẫu nhiên, hầu hết các lỗi (60%) cho 2WIKIMQA là trong các câu hỏi trung gian. Điều này cho thấy rằng ngữ cảnh không liên quan có thể gây ra lỗi trong việc tạo ra cả chiến lược trả lời và chính câu trả lời, tùy thuộc vào nhiệm vụ và ngữ cảnh được truy xuất.

Khi nào Các Mô hình NLI Thất bại? Như được hiển thị trong §4, các mô hình NLI hiệu quả trong việc xác định ngữ cảnh có liên quan, với chi phí cho các lợi ích khi truy xuất hữu ích. Để đặc trưng hóa tốt hơn các mô hình NLI, chúng tôi xem xét độ chính xác cho các mô hình SA-*-NLI của chúng tôi như một hàm của xác suất mà mô hình NLI gán cho nhãn entailment. Bảng 8 trong §A.4 cho thấy rằng có nhiều trường hợp nơi xác suất cho entailment thấp nhưng truy xuất giúp ích cho NQ và 2WIKIMQA.

Để xác định rõ hơn nguồn gốc của những lỗi như vậy, chúng tôi phân tích thủ công 25 ví dụ cho mỗi bộ dữ liệu nơi entailment thấp, nhưng việc tăng cường truy xuất khiến mô hình SA-RMix tạo ra câu trả lời đúng.6 Trong khoảng một nửa các trường hợp, mô hình NLI mắc lỗi và văn bản được tạo ra thực sự được kéo theo từ các ngữ cảnh được truy xuất. Trong các ví dụ còn lại, ít nhất một phần ba các trường hợp câu trả lời hoặc phân tách được tạo ra là chính xác, nhưng ngữ cảnh được truy xuất không trực tiếp kéo theo việc tạo ra. Điều này có thể được giải thích một phần bởi khả năng của các mô hình kết hợp truy xuất và kiến thức tham số của chúng (Talmor và cộng sự, 2020; Zhong và cộng sự, 2023; Cohen và cộng sự, 2023). Chúng tôi hy vọng rằng những kết quả này có thể truyền cảm hứng cho nghiên cứu tương lai tập trung vào các khía cạnh bổ sung của việc tăng cường truy xuất, chẳng hạn như tác động mà việc tăng cường có đối với xác suất tạo ra hơn là trên entailment trực tiếp.

6 NGHIÊN CỨU LIÊN QUAN

Nghiên cứu gần đây đã cho thấy rằng hiệu suất của LLMs có thể bị ảnh hưởng bởi ngữ cảnh không liên quan. Trong số những nghiên cứu khác, Jia & Liang (2017); Petroni và cộng sự (2020); Creswell và cộng sự (2023) cho thấy rằng việc thêm ngữ cảnh ngẫu nhiên hoặc không liên quan có thể làm giảm hiệu suất QA. Điều này đã được chứng minh trong nhiều bối cảnh, bao gồm nhưng không giới hạn ở lý luận thực tế (Kassner & Schütze, 2020; Pandia & Ettinger, 2021; Misra và cộng sự, 2023), tạo văn bản về các thực thể mới (Onoe và cộng sự, 2022), hoặc thậm chí tạo mã (Jones & Steinhardt, 2022). Trong bối cảnh lý luận số học, Shi và cộng sự (2023) cho thấy rằng việc thêm ngữ cảnh không liên quan vào các mẫu hoặc hướng dẫn cụ thể nhiệm vụ có thể giúp ích, cho thấy mô hình có thể được trang bị những kỹ năng như vậy từ việc tiền huấn luyện. Các phương pháp khác cố gắng giảm số lần gọi truy xuất, bằng cách tập trung vào các trường hợp nơi độ tin cậy thấp (Jiang và cộng sự, 2023) hoặc truy xuất thông tin cho các thực thể hiếm (Mallen và cộng sự, 2023). Gần nhất với công trình của chúng tôi là của Li và cộng sự (2023) đề xuất LLMs với "bộ nhớ có thể kiểm soát" sẽ cho phép chúng bỏ qua ngữ cảnh không liên quan. Tuy nhiên, LLMs của họ được tinh chỉnh trên hơn 200K ví dụ huấn luyện, trong khi trọng tâm của chúng tôi là hiệu suất khi huấn luyện với 1.000 câu hỏi hoặc ít hơn, và dữ liệu huấn luyện được tạo tự động. Ngoài ra, chúng tôi tập trung vào bối cảnh QA đa bước, nơi bộ truy xuất được gọi nhiều lần (§2).

Một dòng nghiên cứu tương tự tập trung vào khi nào các mô hình nên sử dụng kiến thức tham số hoặc được truy xuất, đặc biệt khi có xung đột (Longpre và cộng sự, 2021; Chen và cộng sự, 2022). Gần đây đã được đề xuất để huấn luyện các mô hình tạo ra từ cả kiến thức tham số và được truy xuất (Neeman và cộng sự, 2023) hoặc tận dụng tốt hơn các mẫu trong ngữ cảnh (Zhou và cộng sự, 2023).

7 KẾT LUẬN

Trong công trình này, chúng tôi cung cấp một phân tích kỹ lưỡng cho thấy RALMs hiện tại không bền vững với ngữ cảnh được truy xuất không liên quan, khiến chúng hoạt động kém hơn trên một số nhiệm vụ nhất định. Trong các trường hợp không thể huấn luyện, một đường cơ sở NLI đơn giản hiệu quả để tăng tính bền vững, với chi phí loại bỏ các đoạn văn có liên quan. Khi có thể huấn luyện, chúng tôi giới thiệu một khung tạo dữ liệu tự động cho các nhiệm vụ đơn và đa bước thách thức, và cho thấy việc huấn luyện trên ít nhất 1.000 ví dụ với chất lượng cố ý thay đổi đủ để làm cho các mô hình bền vững với ngữ cảnh không liên quan và cải thiện hiệu suất tổng thể. Trong khi trọng tâm của chúng tôi trong công trình này là các thiết lập trong miền, chúng tôi hy vọng công trình của chúng tôi có thể truyền cảm hứng cho nghiên cứu tương lai hướng tới một RALM tổng quát bền vững với ngữ cảnh không liên quan.
9

--- TRANG 10 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

LỜI CẢM ơN

Chúng tôi muốn cảm ơn các đồng nghiệp tại TAU NLP vì những nhận xét sâu sắc của họ. Chúng tôi cảm ơn SerpAPI đã hỗ trợ bằng cách cấp cho chúng tôi giảm giá học thuật. Nghiên cứu này được hỗ trợ một phần bởi Sáng kiến Yandex cho Học máy và Hội đồng Nghiên cứu Châu Âu (ERC) dưới chương trình nghiên cứu và đổi mới Horizons 2020 của Liên minh Châu Âu (cấp ERC DELPHI 802800). Công trình này được hoàn thành để hoàn thành một phần yêu cầu cho bằng Tiến sĩ của Ori Yoran.

TÀI LIỆU THAM KHẢO

Bernd Bohnet, Vinh Q. Tran, Pat Verga, Roee Aharoni, Daniel Andor, Livio Baldini Soares, Massimiliano Ciaramita, Jacob Eisenstein, Kuzman Ganchev, Jonathan Herzig, Kai Hui, Tom Kwiatkowski, Ji Ma, Jianmo Ni, Lierni Sestorain Saralegui, Tal Schuster, William W. Cohen, Michael Collins, Dipanjan Das, Donald Metzler, Slav Petrov, và Kellie Webster. Attributed question answering: Evaluation and modeling for attributed large language models, 2023.

Samuel R. Bowman, Gabor Angeli, Christopher Potts, và Christopher D. Manning. A large annotated corpus for learning natural language inference. Trong Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, trang 632–642, Lisbon, Portugal, Tháng 9 2015. Association for Computational Linguistics. doi: 10.18653/v1/D15-1075. URL https://aclanthology.org/D15-1075.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. Trong Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, và Hsuan-Tien Lin (biên tập), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. URL https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html.

Danqi Chen, Adam Fisch, Jason Weston, và Antoine Bordes. Reading Wikipedia to answer open-domain questions. Trong Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 1870–1879, Vancouver, Canada, Tháng 7 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL https://aclanthology.org/P17-1171.

Hung-Ting Chen, Michael Zhang, và Eunsol Choi. Rich knowledge sources bring complex knowledge conflicts: Recalibrating models to reflect conflicting evidence. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 2292–2307, Abu Dhabi, United Arab Emirates, 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.emnlp-main.146.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. Evaluating large language models trained on code, 2021.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,
10

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, và Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.

Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, và Mor Geva. Evaluating the ripple effects of knowledge editing in language models, 2023.

Antonia Creswell, Murray Shanahan, và Irina Higgins. Selection-inference: Exploiting large language models for interpretable logical reasoning. Trong The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=3Pf3Wg6o-A4.

Ido Dagan, Oren Glickman, và Bernardo Magnini. The pascal recognising textual entailment challenge. Trong Joaquin Quiñonero-Candela, Ido Dagan, Bernardo Magnini, và Florence d'Alché Buc (biên tập), Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, trang 177–190, Berlin, Heidelberg, 2006. Springer Berlin Heidelberg. ISBN 978-3-540-33428-6.

Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, và Luke Zettlemoyer. QLoRA: Efficient finetuning of quantized LLMs. Trong Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=OUIFPHEgJU.

Bhuwan Dhingra, Jeremy R. Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, và William W. Cohen. Time-aware language models as temporal knowledge bases. Transactions of the Association for Computational Linguistics, 10:257–273, 2022. doi: 10.1162/tacl_a_00459. URL https://aclanthology.org/2022.tacl-1.15.

Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, và Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346–361, 2021. doi: 10.1162/tacl_a_00370. URL https://aclanthology.org/2021.tacl-1.21.

Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, và Ming-Wei Chang. Realm: Retrieval-augmented language model pre-training. Trong Proceedings of the 37th International Conference on Machine Learning, ICML'20. JMLR.org, 2020.

Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy, Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, và Yossi Matias. TRUE: Re-evaluating factual consistency evaluation. Trong Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering, trang 161–175, Dublin, Ireland, 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.dialdoc-1.19. URL https://aclanthology.org/2022.dialdoc-1.19.

Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, và Edouard Grave. Atlas: Few-shot learning with retrieval augmented language models. Journal of Machine Learning Research, 24(251):1–43, 2023. URL http://jmlr.org/papers/v24/23-0037.html.

Robin Jia và Percy Liang. Adversarial examples for evaluating reading comprehension systems. Trong Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, trang 2021–2031, Copenhagen, Denmark, Tháng 9 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1215. URL https://aclanthology.org/D17-1215.
11

--- TRANG 12 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Zhengbao Jiang, Frank Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, và Graham Neubig. Active retrieval augmented generation. Trong Houda Bouamor, Juan Pino, và Kalika Bali (biên tập), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, trang 7969–7992, Singapore, Tháng 12 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.495. URL https://aclanthology.org/2023.emnlp-main.495.

Erik Jones và Jacob Steinhardt. Capturing failures of large language models via human cognitive biases. Trong Alice H. Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun Cho (biên tập), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=fcO9Cgn-X-R.

Ashwin Kalyan, Abhinav Kumar, Arjun Chandrasekaran, Ashish Sabharwal, và Peter Clark. How much coffee was consumed during EMNLP 2019? fermi problems: A new reasoning challenge for AI. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 7318–7328, Online and Punta Cana, Dominican Republic, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.582. URL https://aclanthology.org/2021.emnlp-main.582.

Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, và Wen-tau Yih. Dense passage retrieval for open-domain question answering. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 6769–6781, Online, 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.550. URL https://aclanthology.org/2020.emnlp-main.550.

Nora Kassner và Hinrich Schütze. Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 7811–7818, Online, Tháng 7 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.698. URL https://aclanthology.org/2020.acl-main.698.

O. Khattab, Keshav Santhanam, Xiang Lisa Li, David Leo Wright Hall, Percy Liang, Christopher Potts, và Matei A. Zaharia. Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp. ArXiv preprint, abs/2212.14024, 2022. URL https://arxiv.org/abs/2212.14024.

Omar Khattab và Matei Zaharia. Colbert: Efficient and effective passage search via contextualized late interaction over BERT. Trong Jimmy Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, và Yiqun Liu (biên tập), Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020, trang 39–48. ACM, 2020. doi: 10.1145/3397271.3401075. URL https://doi.org/10.1145/3397271.3401075.

Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, và Slav Petrov. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452–466, 2019. doi: 10.1162/tacl_a_00276. URL https://aclanthology.org/Q19-1026.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, và Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 7871–7880, Online, 2020a. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.703. URL https://aclanthology.org/2020.acl-main.703.

Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, và Douwe Kiela. Retrieval-augmented generation for knowledge-intensive NLP tasks. Trong
12

--- TRANG 13 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, và Hsuan-Tien Lin (biên tập), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020b. URL https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html.

Daliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin Wang, Michal Lukasik, Andreas Veit, Felix Yu, và Sanjiv Kumar. Large language models with controllable working memory. Trong Findings of the Association for Computational Linguistics: ACL 2023, trang 1774–1793, Toronto, Canada, Tháng 7 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-acl.112. URL https://aclanthology.org/2023.findings-acl.112.

Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, và Sameer Singh. Entity-based knowledge conflicts in question answering. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 7052–7063, Online and Punta Cana, Dominican Republic, Tháng 11 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.565. URL https://aclanthology.org/2021.emnlp-main.565.

Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, và Hannaneh Hajishirzi. When not to trust language models: Investigating effectiveness of parametric and non-parametric memories. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 9802–9822, Toronto, Canada, Tháng 7 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.546. URL https://aclanthology.org/2023.acl-long.546.

Kanishka Misra, Julia Rayz, và Allyson Ettinger. COMPS: Conceptual minimal pair sentences for testing robust property knowledge and its inheritance in pre-trained language models. Trong Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, trang 2928–2949, Dubrovnik, Croatia, 2023. Association for Computational Linguistics. URL https://aclanthology.org/2023.eacl-main.213.

Ella Neeman, Roee Aharoni, Or Honovich, Leshem Choshen, Idan Szpektor, và Omri Abend. DisentQA: Disentangling parametric and contextual knowledge with counterfactual question answering. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 10056–10070, Toronto, Canada, Tháng 7 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.559. URL https://aclanthology.org/2023.acl-long.559.

Yasumasa Onoe, Michael Zhang, Eunsol Choi, và Greg Durrett. Entity cloze by date: What LMs know about unseen entities. Trong Findings of the Association for Computational Linguistics: NAACL 2022, trang 693–702, Seattle, United States, Tháng 7 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-naacl.52. URL https://aclanthology.org/2022.findings-naacl.52.

Lalchand Pandia và Allyson Ettinger. Sorting through the noise: Testing robustness of information processing in pre-trained language models. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 1583–1596, Online and Punta Cana, Dominican Republic, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.119. URL https://aclanthology.org/2021.emnlp-main.119.

Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H. Miller, và Sebastian Riedel. How context affects language models' factual predictions. Trong Automated Knowledge Base Construction, 2020. URL https://openreview.net/forum?id=025X0zPfn.

Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim Rocktäschel, và Sebastian Riedel. KILT: a benchmark for knowledge intensive language tasks. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 2523–2544, Online,
13

--- TRANG 14 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Tháng 6 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.200. URL https://aclanthology.org/2021.naacl-main.200.

Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah Smith, và Mike Lewis. Measuring and narrowing the compositionality gap in language models. Trong Houda Bouamor, Juan Pino, và Kalika Bali (biên tập), Findings of the Association for Computational Linguistics: EMNLP 2023, trang 5687–5711, Singapore, Tháng 12 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-emnlp.378. URL https://aclanthology.org/2023.findings-emnlp.378.

Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, và Yoav Shoham. In-context retrieval-augmented language models. Transactions of the Association for Computational Linguistics, 11:1316–1331, 2023. doi: 10.1162/tacl_a_00605. URL https://aclanthology.org/2023.tacl-1.75.

Adam Roberts, Colin Raffel, và Noam Shazeer. How much knowledge can you pack into the parameters of a language model? Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 5418–5426, Online, 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.437. URL https://aclanthology.org/2020.emnlp-main.437.

Ohad Rubin và Jonathan Berant. Long-range language modeling with self-retrieval, 2023.

Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael Schärli, và Denny Zhou. Large language models can be easily distracted by irrelevant context. Trong Proceedings of the 40th International Conference on Machine Learning, ICML'23. JMLR.org, 2023.

Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, và Jonathan Berant. Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge. Trong Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, và Hsuan-Tien Lin (biên tập), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. URL https://proceedings.neurips.cc/paper/2020/hash/e992111e4ab9985366e806733383bd8c-Abstract.html.

James Thorne, Andreas Vlachos, Christos Christodoulopoulos, và Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERification. Trong Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), trang 809–819, New Orleans, Louisiana, Tháng 6 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1074. URL https://aclanthology.org/N18-1074.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, và Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models, 2023.

Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, và Ashish Sabharwal. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 10014–10037, Toronto, Canada, Tháng 7 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.557. URL https://aclanthology.org/2023.acl-long.557.
14

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, và Denny Zhou. Self-consistency improves chain of thought reasoning in language models. Trong The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=1PL1NIMMrw.

Johannes Welbl, Pontus Stenetorp, và Sebastian Riedel. Constructing datasets for multi-hop reading comprehension across documents. Transactions of the Association for Computational Linguistics, 6:287–302, 2018. doi: 10.1162/tacl_a_00021. URL https://aclanthology.org/Q18-1021.

Adina Williams, Nikita Nangia, và Samuel Bowman. A broad-coverage challenge corpus for sentence understanding through inference. Trong Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), trang 1112–1122, New Orleans, Louisiana, 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1101. URL https://aclanthology.org/N18-1101.

Tomer Wolfson, Mor Geva, Ankit Gupta, Matt Gardner, Yoav Goldberg, Daniel Deutch, và Jonathan Berant. Break it down: A question understanding benchmark. Transactions of the Association for Computational Linguistics, 8:183–198, 2020. doi: 10.1162/tacl_a_00309. URL https://aclanthology.org/2020.tacl-1.13.

Ori Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel Deutch, và Jonathan Berant. Answering questions by meta-reasoning over multiple chains of thought. Trong Houda Bouamor, Juan Pino, và Kalika Bali (biên tập), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, trang 5942–5966, Singapore, Tháng 12 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.364. URL https://aclanthology.org/2023.emnlp-main.364.

Zexuan Zhong, Zhengxuan Wu, Christopher Manning, Christopher Potts, và Danqi Chen. MQuAKE: Assessing knowledge editing in language models via multi-hop questions. Trong Houda Bouamor, Juan Pino, và Kalika Bali (biên tập), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, trang 15686–15702, Singapore, Tháng 12 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.971. URL https://aclanthology.org/2023.emnlp-main.971.

Wenxuan Zhou, Sheng Zhang, Hoifung Poon, và Muhao Chen. Context-faithful prompting for large language models. Trong Houda Bouamor, Juan Pino, và Kalika Bali (biên tập), Findings of the Association for Computational Linguistics: EMNLP 2023, trang 14544–14556, Singapore, Tháng 12 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-emnlp.968. URL https://aclanthology.org/2023.findings-emnlp.968.

A PHỤ LỤC

A.1 MÔ HÌNH

Llama-2 Trong tất cả các trường hợp, chúng tôi sử dụng biến thể vanilla của các mô hình Llama-2 từ https://huggingface.co/meta-llama, với độ chính xác một nửa.

Tạo Phân tách Các câu hỏi trong bộ dữ liệu đa bước của chúng tôi yêu cầu từ 2-4 bước phân tách. Do đó chúng tôi giới hạn số bước tạo ra 5. Trong Bảng 8 chúng tôi cho thấy rằng số trường hợp mà mô hình không đến được câu trả lời trong 5 bước, được gọi là thất bại, rất nhỏ khi tạo ra với kết quả top-1 từ GOOGLE SEARCH, ở 0.4% cho 2WIKIMQA và 1.2% cho STRATEGYQA. Thất bại cao hơn nhiều khi truy xuất các ngữ cảnh ngẫu nhiên, ở 37.0% cho 2WIKIMQA và 34.4% cho STRATEGYQA. Đây thường là các trường hợp mô hình rơi vào vòng lặp vô hạn. Tuân theo nghiên cứu gần đây, (Wang và cộng sự, 2023; Yoran và cộng sự, 2023) chúng tôi sử dụng giải mã tham lam khi tạo ra các phân tách.
15

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Huấn luyện Chúng tôi tinh chỉnh tất cả các mô hình của chúng tôi với QLoRA (Dettmers và cộng sự, 2023) để tinh chỉnh hiệu quả tham số. Chúng tôi sử dụng các siêu tham số mặc định từ https://github.com/daniel-furman/sft-demos/blob/main/src/sft/one_gpu/llama-2/guanaco/sft-llama-2-13b-guanaco-peft.ipynb. Chúng tôi huấn luyện tất cả các mô hình của chúng tôi trong 5 epoch, với tốc độ học 2e−4 và lập lịch tuyến tính trên một GPU đơn. Thời gian huấn luyện cho mỗi mô hình không dài hơn 3.5 giờ.

A.2 ĐÁNH GIÁ

Trong một số trường hợp, các mô hình không đến được câu trả lời cuối cùng (§A.1). Trong những trường hợp như vậy, chúng tôi gán điểm 0.5 cho STRATEGYQA và 0 cho tất cả các bộ dữ liệu khác. Cho FERMI, tuân theo nghiên cứu trước đây (Yoran và cộng sự, 2023), chúng tôi sử dụng tất cả 286 "Real Fermi Problems" để đánh giá và cung cấp các đơn vị đo lường câu trả lời vàng (mét, khối, lít, v.v...) như đầu vào bổ sung cho các mô hình của chúng tôi.

A.3 KẾT QUẢ ĐẦY ĐỦ

Bảng 2 và Bảng 3 trình bày kết quả đầy đủ cho các mô hình được nhắc nhở của chúng tôi với GOOGLE SEARCH và COLBERTV2, tương ứng. Bảng 4 trình bày kết quả đầy đủ cho tất cả các mô hình được huấn luyện của chúng tôi, trung bình trên ba seed. Bảng 6 trình bày kết quả cho Llama-2-70B trên NQ với bộ truy xuất GOOGLE SEARCH.

Tổng quát hóa Ngoài Phân phối Để kiểm tra khả năng tổng quát hóa của các mô hình được huấn luyện của chúng tôi trong một thiết lập ngoài phân phối (OOD), chúng tôi huấn luyện một phiên bản của các mô hình của chúng tôi trên hỗn hợp dữ liệu STRATEGYQA và 2WIKIMQA của chúng tôi và đánh giá trên BAMBOOGLE và FERMI. Vì nhiệm vụ đánh giá có thể khác với dữ liệu huấn luyện (ví dụ trong FERMI mô hình cần tạo ra một phương trình trước câu trả lời cuối cùng), chúng tôi cung cấp cho các mô hình một mẫu trong quá trình suy luận. Chúng tôi cung cấp kết quả đầy đủ cho thí nghiệm này trong Bảng 5. Chúng tôi lưu ý rằng độ lệch chuẩn trong những thí nghiệm này lớn hơn so với Bảng 3, có lẽ do kích thước hỗ trợ nhỏ ở 120 cho BAMBOOGLE và 286 cho FERMI. Tuy nhiên, khi so sánh giữa các mô hình được huấn luyện, SA-RetRobust là mô hình hoạt động tốt nhất hoặc trong một độ lệch chuẩn trong tất cả các thiết lập. Tuy nhiên, chúng tôi cũng quan sát một số xu hướng bất ngờ có thể liên quan đến thất bại của mô hình trong việc tổng quát hóa hoặc tác động của mẫu trong ngữ cảnh: (a) Cho BAMBOOGLE, khi không sử dụng bộ truy xuất, mô hình được nhắc nhở và đánh giá mà không có truy xuất vượt trội hơn mô hình được huấn luyện mà không có truy xuất (47.4 so với 40.8), và (b) Cho FERMI, chúng tôi thấy một sự giảm nhẹ về độ chính xác từ mô hình được huấn luyện và đánh giá mà không có truy xuất đến mô hình SA-RetRobust được huấn luyện của chúng tôi khi đánh giá với truy xuất xếp hạng thấp hoặc ngẫu nhiên (29.3 so với 27.9 và 27.6 tương ứng). Nhìn chung, chúng tôi hy vọng rằng những kết quả này sẽ giúp nghiên cứu tương lai hướng tới một RALM tổng quát bền vững với ngữ cảnh không liên quan.

A.4 PHÂN TÍCH

Cho nghiên cứu của chúng tôi về các trường hợp ngữ cảnh không liên quan khiến SA-RMix mắc lỗi, chúng tôi chú thích các ví dụ với các danh mục sau (a) Hợp lệ: dự đoán là một cách diễn đạt khác của câu trả lời đúng hoặc một câu trả lời hợp lý cho một câu hỏi mơ hồ (b) Sai: dự đoán với truy xuất là sai và dự đoán mà không có truy xuất là đúng, (c) Cả hai Sai: dự đoán với truy xuất là sai, nhưng dự đoán mà không có truy xuất cũng sai (do phân tách tồi có thể dẫn đến câu trả lời đúng một cách ngẫu nhiên trong các câu hỏi nhị phân hoặc so sánh). Chúng tôi cung cấp kết quả đầy đủ trong Bảng 7. Chúng tôi xác minh kết quả của chúng tôi có ý nghĩa thống kê bằng cách chạy một kiểm định nhị thức cho giả thuyết: "Hầu hết các trường hợp nơi các số liệu tự động giảm bởi việc giới thiệu ngữ cảnh không liên quan không phải là lỗi thực tế" đã bị từ chối với p-value <0.01.

Hình 6 trình bày một ví dụ nơi ngữ cảnh không liên quan khiến Llama-2-13B mắc lỗi khi thực thể được tạo ra không xuất hiện trong ngữ cảnh được truy xuất. Hình 7 cho thấy một ví dụ nơi truy xuất ngẫu nhiên khiến mô hình tạo ra một chiến lược tồi trong STRATEGYQA và Bảng 8 trình bày kết quả đầy đủ cho phân tích của chúng tôi về các mô hình NLI.

A.5 NHẮC NHỞ

Chúng tôi cung cấp nhắc nhở SA-NR, SA-R@1, và SA-R@10 của chúng tôi cho NQ trong Bảng 8, Bảng 9, Bảng 10, tương ứng. Cho nhắc nhở SA-RMix, chúng tôi sử dụng các mẫu từ nhắc nhở SA-R@1 và SA-R@10,
16

--- TRANG 17 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Bộ dữ liệu Suy luận NR NR R@1 R@1 R@10 R@10 RMix RMix
Truy xuất -NLI -NLI -NLI -NLI

NQ Không có 29.6 n/a n/a n/a n/a n/a n/a n/a
@1 41.0 38.4 39.0 36.4 41.0 36.8 40.6 37.0
@10 30.2 29.8 25.6 29.4 30.0 31.0 31.0 29.8
Ngẫu nhiên 28.2 29.6 17.2 29.4 22.2 29.4 22.0 29.4

2WIKIMQA Không có 32.0 n/a n/a n/a n/a n/a n/a n/a
@1 56.0 39.9 51.6 38.3 51.6 39.2 53.1 39.0
@10 33.0 32.2 27.5 32.5 30.9 32.3 29.6 32.2
Ngẫu nhiên 27.0 32.0 13.7 32.0 21.3 32.2 17.5 32.0

STRATEGYQA Không có 65.6 n/a n/a n/a n/a n/a n/a n/a
@1 62.1 65.6 63.8 66.7 61.4 65.8 59.6 66.2
@10 60.4 65.6 61.0 65.6 60.5 65.4 62.1 65.8
Ngẫu nhiên 58.4 65.6 53.4 65.6 57.0 65.6 52.7 65.6

BAMBOOGLE Không có 47.4 n/a n/a n/a n/a n/a n/a n/a
@1 68.0 55.9 61.2 56.0 68.9 58.0 62.7 55.2
@10 41.4 47.4 32.1 45.9 44.5 45.9 38.1 47.0
Ngẫu nhiên 39.5 47.4 24.7 47.4 34.8 47.4 26.3 47.4

FERMI Không có 27.7 n/a n/a n/a n/a n/a n/a n/a
@1 27.4 28.2 25.2 27.6 27.5 27.7 25.6 27.4
@10 24.0 27.7 27.1 27.6 25.1 27.7 23.6 28.0
Ngẫu nhiên 22.1 27.7 17.2 27.7 17.4 27.7 13.8 27.7

Bảng 2: Kết quả đầy đủ cho các mô hình Llama-2-13B được nhắc nhở của chúng tôi với bộ truy xuất GOOGLE SEARCH.

Bộ dữ liệu Suy luận NR NR R@1 R@1 R@10 R@10 RMix RMix
Truy xuất -NLI -NLI -NLI -NLI

NQ Không có 29.6 n/a n/a n/a n/a n/a n/a n/a
@1 34.6 34.8 31.2 33.2 32.4 33.8 32.8 33.8

2WIKIMQA Không có 32.0 n/a n/a n/a n/a n/a n/a n/a
@1 42.2 36.2 37.3 34.9 36.7 35.0 39.6 35.3

STRATEGYQA Không có 65.6 n/a n/a n/a n/a n/a n/a n/a
@1 61.6 66.0 64.3 65.1 61.1 64.9 61.6 64.7

BAMBOOGLE Không có 47.4 n/a n/a n/a n/a n/a n/a n/a
@1 50.0 48.6 37.4 46.6 38.1 47.4 38.2 48.7

FERMI Không có 27.7 n/a n/a n/a n/a n/a n/a n/a
@1 25.9 27.3 23.2 27.8 21.2 28.0 24.4 28.0

Bảng 3: Kết quả đầy đủ cho các mô hình Llama-2-13B được nhắc nhở của chúng tôi với bộ truy xuất COLBERTV2.
17

--- TRANG 18 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Bộ dữ liệu Bộ truy xuất Suy luận SA- SA- SA-
NoRet Ret@1 RetRobust

NQ Không có Không có 34.1 ±0.8 n/a n/a
Google @1 42.8 ±0.8 46.3±0.6 45.7±0.6
Google @10 37.0 ±1.0 38.2±0.6 37.9±0.5
Google @Ngẫu nhiên 31.1 ±0.1 31.4 ±0.5 33.8±0.2
ColBERTV2 @1 41.5 ±0.4 43.5±0.2 43.5 ±0.6

2WIKIMQA Không có Không có 42.2 ±0.6 n/a n/a
Google @1 64.6 ±0.7 66.7 ±1.0 66.9±1.0
Google @10 40.8 ±0.5 43.9 ±0.3 45.0±0.4
Google @Ngẫu nhiên 40.4 ±0.8 37.5 ±1.0 41.6±0.2
ColBERTV2 @1 54.4 ±0.7 57.0 ±0.5 57.6±0.5

STRATEGYQA Không có Không có 69.8 ±0.9 n/a n/a
Google @1 67.1 ±0.4 69.0 ±1.2 70.1±1.1
Google @10 66.6 ±1.1 68.1 ±0.3 68.6±0.5
Google @Ngẫu nhiên 66.6 ±0.7 66.9 ±1.2 69.9±1.8
ColBERTV2 @1 65.9 ±0.6 68.4 ±1.4 68.8±0.9

Bảng 4: Kết quả đầy đủ cho các mô hình Llama-2-13B được huấn luyện của chúng tôi. Kết quả được trung bình trên ba seed. Cho RALMs của chúng tôi, chúng tôi sử dụng GOOGLE SEARCH hoặc COLBERTV2 làm bộ truy xuất của chúng tôi trong quá trình suy luận.

Bộ dữ liệu Bộ truy xuất Suy luận SA- SA- SA-
NoRet Ret@1 RetRobust

BAMBOOGLE Không có Không có 40.8 ±2.0 n/a n/a
Google @1 57.4 ±2.0 61.3 ±1.4 64.7±1.5
Google @10 33.1 ±1.9 39.2 ±2.0 42.0±2.2
Google @Ngẫu nhiên 29.8 ±1.8 38.4 ±4.8 43.6±1.6
ColBERTV2 @1 37.1 ±1.5 48.2 ±0.7 49.6±1.8

FERMI Không có Không có 29.3 ±0.4 n/a n/a
Google @1 31.3±1.2 29.6±0.8 29.2 ±1.6
Google @10 28.3 ±1.5 28.6±2.5 27.9±1.9
Google @Ngẫu nhiên 25.3 ±1.3 27.9±2.4 27.6±0.6
ColBERTV2 @1 28.3 ±0.1 28.9 ±0.4 30.0±1.1

Bảng 5: Kết quả đầy đủ cho các mô hình Llama-2-13B được huấn luyện của chúng tôi trong một thiết lập ngoài phân phối. Trong thiết lập này, các mô hình của chúng tôi được huấn luyện trên hỗn hợp STRATEGYQA và 2WIKIMQA và được đánh giá trên BAMBOOGLE và FERMI. Kết quả được trung bình trên ba seed. Cho RALMs của chúng tôi, chúng tôi sử dụng GOOGLE SEARCH hoặc COLBERTV2 làm bộ truy xuất của chúng tôi trong quá trình suy luận.

Câu trả lời là: Mogen DavidH: md trong md 20/20có nghĩa là gì?B: Bữa ăn trên máy bay: Những bữa ăn trên máy bay đầu tiên được phục vụ bởi Handley Page Transport, một công ty hàng không được thành lập năm 1919, để phục vụ tuyến London–Paris vào tháng 10 năm đó. Hành khách có thể chọn từ nhiều loại bánh sandwich và trái cây.Câu trả lời là: MarylandMô hình Ngôn ngữ Lớn (không truy xuất)Mô hình Ngôn ngữ Tăng cường Truy xuất

Hình 6: Một ví dụ từ NQ nơi truy xuất khiến Llama-2-13B mắc lỗi, mặc dù thực thể được tạo ra không xuất hiện trong ngữ cảnh được truy xuất.
18

--- TRANG 19 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Suy luận NR NR R@1 R@1 R@10 R@10 RMix RMix SA- SA-
Truy xuất -NLI -NLI -NLI -NLI No-Ret RetBust

#Tham số 70B 70B 70B 70B 70B 70B 70B 70B 13B 13B
Không có 38.4 n/a n/a n/a n/a n/a n/a n/a 34.1 n/a
@1 41.4 41.8 41.2 42.4 41.6 42.4 41.2 42.0 42.8 45.7
@10 38.8 36.2 30.2 34.2 33.4 35.4 31.8 35.2 37.0 37.9
Ngẫu nhiên 33.6 38.2 28.8 36.8 35.2 38.2 31.0 38.0 31.1 33.8

Bảng 6: Kết quả cho NQ với GOOGLE SEARCH và Llama-2-70B.

Suy luận Hợp lệ Sai Cả hai
Truy xuất Sai

NQ @10 34% 66% 0%
Ngẫu nhiên 22% 78% 0%

2WIKIMQA @10 2% 72% 23%
Ngẫu nhiên 0% 85% 15%

STRATEGYQA @10 3% 65% 32%
Ngẫu nhiên 0% 70% 30%

Bảng 7: Kết quả đầy đủ cho phân tích của chúng tôi về các trường hợp nơi việc tăng cường các ngữ cảnh được truy xuất khiến Llama-2-13B được nhắc nhở với SA-RMix mắc lỗi. Các lớp và chi tiết bổ sung được cung cấp trong §5.

Bước phân tách #1Q1: Trọng lượng của một quả mít là bao nhiêu?A1: Trọng lượng của một quả mít khoảng 10 kg.H: Có an toàn khi bị ném một quả mít vào đầu không?Mô hình Ngôn ngữ Lớn (không truy xuất)Mô hình Ngôn ngữ Tăng cường Truy xuất

Bước phân tách #2Q1: Trọng lượng của đầu người là bao nhiêu?A1: Trọng lượng của đầu người khoảng 5 kg.Bước phân tách #3Q1: 10 kg có lớn hơn 5 kg không?A1: Có, 10 kg lớn hơn 5 kg.Câu trả lời cuối cùng.Vậy câu trả lời cuối cùng là:Không.

Bước phân tách #1Q1: Trọng lượng của một quả mít là bao nhiêu?E1: Đại bàng trọng (Haliaeetus leucocephalus) là một loài chim săn mồi được tìm thấy ở Bắc Mỹ. Là một đại bàng biển, nó có hai phân loài đã biết và tạo thành một cặp loài vớiA1: Trọng lượng của một quả mít khoảng 10 kg.Bước phân tách #2Q2: Trọng lượng của một con đại bàng trọng là bao nhiêu?E2: Tam Quốc Diễn Nghĩa là một tiểu thuyết lịch sử thế kỷ 14 được cho là của La Quán Trung. Nó lấy bối cảnh trong những năm tháng động loạn cuối triều đại HànA2: Trọng lượng của một con đại bàng trọng khoảng 6 kg.Bước phân tách #3Q3: 10 kg có lớn hơn 6 kg không?E3: Các diễn viên đóng vai Ông già Noel xuất hiện trong những tuần trước Giáng sinh tại các cửa hàng bách hóa hoặc trung tâm mua sắm, hoặc tại các bữa tiệc. Thực hành này đã được ghi nhậnA3: 10 kg lớn hơn 6 kg.Câu trả lời cuối cùng.Vậy câu trả lời cuối cùng là:Không.

Hình 7: Một ví dụ từ STRATEGYQA ngữ cảnh không liên quan khiến Llama-2-13B tạo ra một chiến lược sai (phải). Không có truy xuất (trái), mô hình thành công trong việc tạo ra câu trả lời đúng.
19

--- TRANG 20 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Suy luận Thất bại Entailment thấp Entailment trung bình Entailment cao
Truy xuất % % ∆ % ∆ % ∆

NQ @1 0.0% 32.6% +0.11 12.8% +0.09 54.6% +0.11
@10 0.0% 69.4% +0.01 9.4% +0.06 21.2% +0.01
Ngẫu nhiên 0.0% 97.2% −0.07 2.2% −0.2 0.6% 0.0

2WIKIMQA @1 0.4% 83.0% +0.12 5.6% +0.34 11.0% +0.55
@10 2.8% 93.8% −0.02 2.6% −0.11 0.8% +0.08
Ngẫu nhiên 37.0% 63.0% −0.06 0.0% 0.0 0.0% 0.0

STRATEGYQA @1 1.2% 96.2% −0.07 2.4% +0.17 0.2% 0.0
@10 2.6% 95.8% −0.04 1.4% 0.0 0.2% 0.0
Ngẫu nhiên 34.4% 56.6% −0.13 0.0% 0.0 0.0% 0.0

Bảng 8: Kết quả cho phân tích NLI của chúng tôi. 'Thất bại' chỉ ra rằng mô hình phân tách không thể đến được câu trả lời (xem §A.1). Các ví dụ khác được chia dựa trên xác suất entailment của chúng: xác suất thấp là <1/3, xác suất trung bình là trong [1/3,2/3], và xác suất cao là >2/3. ∆ chỉ ra sự cải thiện về độ chính xác khi sử dụng truy xuất. Cho NQ và 2WIKIMQA, nhiều trường hợp nơi truy xuất hữu ích có xác suất entailment thấp. Cho STRATEGYQA ngầm hầu hết các ví dụ có entailment thấp, nhưng truy xuất giúp ích trong các ví dụ ít với entailment trung bình.

Cho câu hỏi sau, hãy trả lời bằng cách cung cấp các câu hỏi tiếp theo và câu trả lời trung gian. Nếu các câu hỏi trung gian không cần thiết, hãy trả lời câu hỏi trực tiếp.
#
Câu hỏi: big red one có tên như thế nào
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: miếng dán vai của nó
#
Câu hỏi: quần đảo cayman ở đâu trên bản đồ
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: Biển Caribbean phía tây
#
Câu hỏi: ai thắng trong cuộc chiến giữa bắc triều tiên và nam triều tiên
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: về mặt kỹ thuật vẫn đang chiến tranh
#
Câu hỏi: it's always sunny in philadelphia season 13 bắt đầu khi nào
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: 5 tháng 9, 2018
#
Câu hỏi: ai hát you got a friend in me từ toy story
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: Randy Newman
#
Câu hỏi: người đầu tiên được gửi vào không gian khi nào
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: 12 tháng 4, 1961
#
Câu hỏi:

Hình 8: Nhắc nhở SA-NR được sử dụng trong các thí nghiệm NQ của chúng tôi.
20

--- TRANG 21 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Cho câu hỏi sau, hãy trả lời bằng cách cung cấp các câu hỏi tiếp theo và câu trả lời trung gian. Nếu các câu hỏi trung gian không cần thiết, hãy trả lời câu hỏi trực tiếp. Bạn được cung cấp bằng chứng có thể giúp bạn đến được câu trả lời trước câu hỏi.
#
Ngữ cảnh1: The Big Red One: Fuller là một cựu chiến binh Thế chiến II và phục vụ với Sư đoàn Bộ binh số 1, có biệt danh "The Big Red One" vì số "1" màu đỏ trên miếng dán vai của sư đoàn. Ông nhận được Ngôi sao Bạc, Ngôi sao Đồng, và Trái tim Tím trong thời gian phục vụ.
Câu hỏi: big red one có tên như thế nào
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: miếng dán vai của nó
#
Ngữ cảnh1: Bản đồ Vị trí của Quần đảo Cayman: Bản đồ vị trí Quần đảo Cayman đã cho cho thấy rằng Quần đảo Cayman nằm ở phía tây Biển Caribbean. Bản đồ Vị trí của Quần đảo Cayman. Quần đảo Cayman ở đâu ...
Câu hỏi: quần đảo cayman ở đâu trên bản đồ
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: Biển Caribbean phía tây
#
Ngữ cảnh1: Chiến tranh Triều Tiên — Các Bên Chiến Đấu, Tóm tắt, Năm, Bản đồ ... - Britannica: Sau khi hơn một triệu thương vong chiến đấu đã được gánh chịu ở cả hai bên, cuộc chiến đấu kết thúc vào tháng 7 năm 1953 với Triều Tiên vẫn chia thành hai quốc gia thù địch. Các cuộc đàm phán năm 1954 không tạo ra thỏa thuận thêm, và tiền tuyến đã được chấp nhận kể từ đó như ranh giới de facto giữa Bắc và Nam Triều Tiên.
Câu hỏi: ai thắng trong cuộc chiến giữa bắc triều tiên và nam triều tiên
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: về mặt kỹ thuật vẫn đang chiến tranh
#
Ngữ cảnh1: It's Always Sunny in Philadelphia (season 13): Mùa thứ mười ba của loạt phim truyền hình hài Mỹ It´s Always Sunny in Philadelphia được công chiếu trên FXX vào ngày 5 tháng 9, 2018. ... Mùa này bao gồm ...
Câu hỏi: it's always sunny in philadelphia season 13 bắt đầu khi nào
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: 5 tháng 9, 2018
#
Ngữ cảnh1: You've Got a Friend in Me: "You've Got a Friend in Me" là một bài hát của Randy Newman. Được sử dụng làm nhạc chủ đề cho bộ phim hoạt hình Disney/Pixar năm 1995 Toy Story, nó đã trở thành một bài hát lớn ...
Câu hỏi: ai hát you got a friend in me từ toy story
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: Randy Newman
#
Ngữ cảnh1: Tháng 4 năm 1961: Yuri Gagarin từ Liên Xô là người đầu tiên trong không gian. Phương tiện của ông, Vostok 1 đã bay quanh Trái đất với tốc độ 27.400 km/h với chuyến bay kéo dài 108 phút.
Câu hỏi: người đầu tiên được gửi vào không gian khi nào Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: 12 tháng 4, 1961
#
Câu hỏi:

Hình 9: Nhắc nhở SA-R@1 được sử dụng trong các thí nghiệm NQ của chúng tôi.
21

--- TRANG 22 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Cho câu hỏi sau, hãy trả lời bằng cách cung cấp các câu hỏi tiếp theo và câu trả lời trung gian. Nếu các câu hỏi trung gian không cần thiết, hãy trả lời câu hỏi trực tiếp. Bạn được cung cấp bằng chứng có thể giúp bạn đến được câu trả lời trước câu hỏi.
#
Ngữ cảnh1: Trung đoàn Bộ binh số 16 (Hoa Kỳ): Là một phần của Sư đoàn Viễn chinh số 1 mới, sớm được biết đến như 'Big Red One', Trung đoàn Bộ binh số 16, được chỉ huy bởi William Herbert Allaire Jr., đã đi tàu
Câu hỏi: big red one có tên như thế nào
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: miếng dán vai của nó
#
Ngữ cảnh1: Module:Location map/data/Cayman Islands: Module:Location map/data/Cayman Islands là một định nghĩa bản đồ vị trí được sử dụng để phủ các điểm đánh dấu và nhãn trên một bản đồ phép chiếu equirectangular của Cayman
Câu hỏi: quần đảo cayman ở đâu trên bản đồ
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: Biển Caribbean phía tây
#
Ngữ cảnh1: Trận chiến Seoul đầu tiên: Trận chiến Seoul đầu tiên, được biết đến trong sử học Bắc Triều Tiên như Giải phóng Seoul, là việc Bắc Triều Tiên chiếm thủ đô Seoul của Nam Triều Tiên,
Câu hỏi: ai thắng trong cuộc chiến giữa bắc triều tiên và nam triều tiên
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: về mặt kỹ thuật vẫn đang chiến tranh
#
Ngữ cảnh1: It's Always Sunny in Philadelphia (season 13): Mùa thứ mười ba của loạt phim truyền hình hài Mỹ It's Always Sunny in Philadelphia được công chiếu trên FXX vào ngày 5 tháng 9, 2018.
Câu hỏi: it's always sunny in philadelphia season 13 bắt đầu khi nào
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: 5 tháng 9, 2018
#
Ngữ cảnh1: Randy Newman – You've Got a Friend in Me Lyrics: 'You've Got A Friend In Me' là bài hát chủ đề của series Toy Story, xuất hiện xuyên suốt loạt phim trong các bối cảnh khác nhau. Nó xuất hiện lần đầu
Câu hỏi: ai hát you got a friend in me từ toy story
Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: Randy Newman
#
Ngữ cảnh1: Dòng thời gian khám phá không gian: Đây là dòng thời gian khám phá không gian bao gồm các thành tựu đáng chú ý, những thành tựu đầu tiên và các cột mốc trong việc khám phá không gian vũ trụ của nhân loại.
Câu hỏi: người đầu tiên được gửi vào không gian khi nào Có cần các câu hỏi tiếp theo không: Không.
Vậy câu trả lời cuối cùng là: 12 tháng 4, 1961
#
Câu hỏi:

Hình 10: Nhắc nhở SA-R@10 được sử dụng trong các thí nghiệm NQ của chúng tôi.
22

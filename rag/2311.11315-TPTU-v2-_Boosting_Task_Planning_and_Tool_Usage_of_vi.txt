# TPTU-v2: Tăng cường Lập kế hoạch Nhiệm vụ và Sử dụng Công cụ của các Agent dựa trên Mô hình Ngôn ngữ Lớn trong Hệ thống Thực tế

Yilun Kong†‡
kongyilun@sensetime.com

Jingqing Ruan†‡
ruanjingqing@sensetime.com

Yihong Chen†‡
chenyihong@sensetime.com

Bin Zhang†‡
zhangbin11@sensetime.com

Tianpeng Bao†
baotianpeng@sensetime.com

Shiwei Shi†
shishiwei@sensetime.com

Guoqing Du†
duguoqing@sensetime.com

Xiaoru Hu†
huxiaoru@sensetime.com

Hangyu Mao†
maohangyu@sensetime.com

Ziyue Li
zlibn@connect.ust.hk

Xingyu Zeng
zengxingyu@sensetime.com

Rui Zhao
zhaorui@sensetime.com

SenseTime Research

## Tóm tắt

Các Mô hình Ngôn ngữ Lớn (LLM) đã chứng minh năng lực trong việc xử lý các nhiệm vụ đòi hỏi sự kết hợp giữa lập kế hoạch nhiệm vụ và việc sử dụng các công cụ bên ngoài như API. Tuy nhiên, các hệ thống phức tạp trong thực tế đặt ra ba thách thức phổ biến liên quan đến lập kế hoạch nhiệm vụ và sử dụng công cụ: (1) Hệ thống thực tế thường có một mảng API rộng lớn, vì vậy không thể đưa mô tả của tất cả API vào prompt của LLM do độ dài token bị giới hạn; (2) hệ thống thực tế được thiết kế để xử lý các nhiệm vụ phức tạp, và các LLM cơ bản khó có thể lập kế hoạch chính xác thứ tự nhiệm vụ con và thứ tự gọi API cho các nhiệm vụ như vậy; (3) Ngữ nghĩa và chức năng tương tự giữa các API trong hệ thống thực tế tạo ra thách thức cho cả LLM và thậm chí cả con người trong việc phân biệt chúng. Đáp lại, bài báo này giới thiệu một framework toàn diện nhằm tăng cường khả năng Lập kế hoạch Nhiệm vụ và Sử dụng Công cụ (TPTU) của các agent dựa trên LLM hoạt động trong hệ thống thực tế. Framework của chúng tôi bao gồm ba thành phần chính được thiết kế để giải quyết những thách thức này: (1) API Retriever chọn các API liên quan nhất đến nhiệm vụ của người dùng từ mảng rộng lớn có sẵn; (2) LLM Finetuner tinh chỉnh một LLM cơ bản để LLM được tinh chỉnh có thể có khả năng lập kế hoạch nhiệm vụ và gọi API tốt hơn; (3) Demo Selector thích ứng để truy xuất các demo khác nhau liên quan đến các API khó phân biệt, được sử dụng thêm cho việc học trong ngữ cảnh để thúc đẩy hiệu suất cuối cùng. Chúng tôi xác thực các phương pháp của mình bằng cách sử dụng một hệ thống thương mại thực tế cũng như một tập dữ liệu học thuật mã nguồn mở, và kết quả rõ ràng cho thấy hiệu quả của từng thành phần riêng lẻ cũng như framework tích hợp.

## 1 Giới thiệu

Các mô hình ngôn ngữ lớn (LLM) đã thể hiện khả năng đáng chú ý trong xử lý ngôn ngữ tự nhiên (NLP), bao gồm hiểu ngôn ngữ, lý luận và tổng hợp chương trình.

Tuy nhiên, việc tận dụng LLM cho các nhiệm vụ phức tạp đặt ra những thách thức to lớn. Một mặt, LLM có những hạn chế vốn có trong khả năng của chúng. Chúng đã được chứng minh là gặp khó khăn với việc giải quyết các vấn đề logic như toán học, và dữ liệu huấn luyện của chúng có thể nhanh chóng trở nên lỗi thời khi thế giới phát triển. Hướng dẫn LLM sử dụng các công cụ bên ngoài như máy tính, lịch, hoặc công cụ tìm kiếm có thể giúp ngăn chặn chúng tạo ra thông tin không chính xác và hỗ trợ chúng giải quyết vấn đề hiệu quả. Mặt khác, việc tích hợp các mô hình này vào hệ thống phức tạp vượt ra ngoài việc hiểu nhiệm vụ đơn thuần. Nó đòi hỏi khả năng phân tách các nhiệm vụ phức tạp, thao tác các công cụ khác nhau, và tương tác hiệu quả với người dùng. Một số nỗ lực nghiên cứu, được gọi là AI Agent dựa trên LLM, như AutoGPT, BabyAGI, và ChatGPT-plugins, đã có những tiến bộ bằng cách sử dụng LLM như bộ điều khiển trung tâm. Những nỗ lực này tự động phân tách các truy vấn của người dùng thành các nhiệm vụ con, thực hiện các lời gọi công cụ (API) cấp thấp cho các nhiệm vụ con này, và cuối cùng giải quyết vấn đề tổng thể.

Mặc dù có những tiến bộ này, các agent dựa trên LLM vẫn gặp phải những thách thức cấp bách trong các ứng dụng thực tế. Thứ nhất, các hệ thống thực tế thường có một số lượng lớn API, khiến việc nhập mô tả của tất cả API vào prompt của LLM trở nên không thực tế do giới hạn độ dài token. Thứ hai, hệ thống thực tế được thiết kế để xử lý các nhiệm vụ phức tạp, và các LLM cơ bản thường gặp khó khăn trong việc lập kế hoạch chính xác thứ tự nhiệm vụ con và chuỗi gọi API cho các nhiệm vụ như vậy. Thứ ba, hệ thống thực tế chủ yếu được thiết kế xung quanh một mục đích cốt lõi, và kết quả là, một số API có thể chồng chéo và thể hiện ngữ nghĩa và chức năng tương tự, tạo ra khó khăn trong việc phân biệt cho cả LLM và con người. Việc giải quyết những vấn đề này có thể là bước quan trọng để các Agent dựa trên LLM tiến tới khả năng toàn tri và toàn năng trong thế giới thực.

Trong bài báo này, chúng tôi đề xuất một framework để cải thiện khả năng Lập kế hoạch Nhiệm vụ và Sử dụng Công cụ (TPTU) của các agent dựa trên LLM trong hệ thống thực tế. So với TPTU-v1 của chúng tôi, framework mới của chúng tôi bao gồm ba thành phần chính để giải quyết ba thách thức trên: (1) API Retriever thu hồi các API liên quan nhất đến nhiệm vụ của người dùng từ tất cả API. Mô tả của các API được lọc này sau đó có thể được nhập vào LLM như prompt, cho phép LLM hiểu và đưa ra lựa chọn chính xác trong tập API được lọc. (2) LLM Finetuner tinh chỉnh một LLM cơ bản để LLM được tinh chỉnh có thể có khả năng lập kế hoạch nhiệm vụ và gọi API tốt hơn, đặc biệt cho các nhiệm vụ chuyên biệt theo lĩnh vực. (3) Demo Selector thích ứng để truy xuất các demo khác nhau liên quan đến các API khó phân biệt, được sử dụng thêm cho việc học trong ngữ cảnh để LLM có thể phân biệt sự khác biệt tinh tế trong chức năng và cách sử dụng của các API khác nhau. Những đóng góp chính của chúng tôi có thể được tóm tắt như sau:

1. Chúng tôi xác định ba thách thức thực tế mà các agent dựa trên LLM phải đối mặt khi lập kế hoạch nhiệm vụ và sử dụng công cụ trong các tình huống thực tế.

2. Đáp lại ba thách thức được đề cập ở trên, chúng tôi đề xuất một framework tiên tiến bao gồm ba thành phần chính: API Retriever, LLM Finetuner, và Demo Selector.

3. Các thí nghiệm mở rộng trong hệ thống thương mại thực tế chứng minh hiệu quả của từng thành phần và framework tích hợp, nơi các nhiệm vụ rất phức tạp và gắn chặt với cuộc sống của con người. Chúng tôi cũng xác thực các phương pháp của mình với các tập dữ liệu học thuật mã nguồn mở.

## 2 Phương pháp luận

Đáp lại những thách thức điển hình của việc triển khai LLM trong các hệ thống thực tế phức tạp, chúng tôi đề xuất một framework toàn diện về cơ bản tăng cường khả năng của LLM trong Lập kế hoạch Nhiệm vụ và Sử dụng Công cụ (TPTU). Phần này đầu tiên giới thiệu framework được đề xuất của chúng tôi, tích hợp hệ thống ba thành phần chuyên biệt: API Retriever, LLM Finetuner, và Demo Selector. Tiếp theo, chúng tôi đi sâu vào mô tả toàn diện về từng thành phần, làm rõ những đóng góp độc đáo của chúng cho framework tổng thể.

### 2.1 Tổng quan Framework

Framework toàn diện của chúng tôi được thiết kế để tăng cường khả năng của LLM trong Lập kế hoạch Nhiệm vụ và Sử dụng Công cụ (TPTU) trong các hệ thống thực tế phức tạp. Framework được thiết kế tỉ mỉ để giải quyết ba thách thức cốt lõi: số lượng API rộng lớn trong hệ thống thực tế, độ phức tạp của việc sắp xếp đúng nhiệm vụ và chuỗi gọi API, và khó khăn trong việc phân biệt giữa các API có chức năng chồng chéo.

Framework được tạo thành từ ba thành phần quan trọng, được mô tả trong Hình 1.

1. **API Retriever**: Thành phần này điều hướng qua một mảng API rộng lớn để truy xuất những API liên quan nhất dựa trên nhiệm vụ của người dùng. Nó sử dụng kỹ thuật tìm kiếm embedding tiên tiến để hiểu ngữ nghĩa của nhiệm vụ và khớp nó với các API chính xác, tận dụng Cơ sở Dữ liệu Kiến thức phong phú và Bộ sưu tập API để đảm bảo tính liên quan và độ chính xác.

2. **LLM Finetuner**: Hệ thống con này tinh chỉnh một LLM cơ bản với tập dữ liệu được tuyển chọn tỉ mỉ, tăng cường khả năng của mô hình trong việc lập kế hoạch nhiệm vụ và thực hiện gọi API hiệu quả. Quá trình tinh chỉnh được thông báo bởi các tập dữ liệu đa dạng, bao gồm những tập được tạo ra đặc biệt để tăng tính đa dạng prompt và giải quyết cả tương tác API một bước và nhiều bước.

3. **Demo Selector**: Demo Selector động truy xuất các demo liên quan đến các API khó phân biệt, tạo điều kiện cho việc học trong ngữ cảnh cho LLM. Điều này cho phép mô hình nhận biết sự khác biệt chức năng tinh tế giữa các API, quan trọng để tạo ra đầu ra chính xác, đặc biệt khi xử lý các API tương tự.

### 2.2 API Retriever

Trong hệ thống thực tế, tồn tại một số lượng lớn API để giải quyết vấn đề, điều này đặt ra thách thức nghiêm trọng cho việc tích hợp LLM. Một mặt, các giới hạn token vốn có của LLM cản trở việc bao gồm tất cả mô tả API trong prompt của mô hình, có thể vượt quá độ dài token tối đa. Mặt khác, ngay cả khi việc bao gồm nhiều API không vi phạm các ràng buộc token này, sự hiện diện của thông tin API quá mức, không liên quan đến nhiệm vụ có thể can thiệp vào khả năng lập kế hoạch và tạo câu trả lời chính xác của mô hình, do đó cản trở hiệu quả hoạt động của nó. Để vượt qua những thách thức này, chúng tôi đã phát triển một mô hình mới được huấn luyện rõ ràng để chọn các API có tính liên quan cao nhất đến nhiệm vụ đang xét, được hiển thị trong Hình 2. Dựa trên tổng quan về framework API Retriever, bây giờ chúng tôi sẽ đưa ra mô tả chi tiết về quá trình thu thập dữ liệu, huấn luyện và suy luận.

#### 2.2.1 Thu thập Dữ liệu

Nền tảng của hiệu quả API Retriever nằm trong một quy trình thu thập dữ liệu nghiêm ngặt. Đầu tiên, chúng tôi đã thu thập một bộ API toàn diện được cung cấp bởi nhiều dịch vụ công cụ bên ngoài. Bộ sưu tập này tạo thành nền tảng mà mô hình của chúng tôi được huấn luyện trên đó. Để đảm bảo rằng hệ thống của chúng tôi hiểu được tính liên quan của các API khác nhau đối với các truy vấn người dùng khác nhau (hướng dẫn), chúng tôi đã thiết lập một quy trình chú thích cụ thể. Trong quy trình này, các chuyên gia con người, hoặc LLM, phân tích các hướng dẫn phức tạp của người dùng (hoặc nhiệm vụ) và xác định các API cần thiết để giải quyết các hướng dẫn này. Phương pháp lai này không chỉ làm phong phú tập dữ liệu của chúng tôi với chuyên môn của con người mà còn hưởng lợi từ quy mô và hiệu quả của LLM trong việc xử lý lượng lớn dữ liệu. Bằng cách kết hợp độ chính xác của chú thích con người với độ rộng của khả năng xử lý của LLM, chúng tôi tạo ra một tập dữ liệu vừa phong phú về chất lượng vừa rộng lớn về số lượng, đặt nền tảng vững chắc cho giai đoạn huấn luyện tiếp theo của API Retriever.

#### 2.2.2 Huấn luyện

Sau khi thu thập dữ liệu được chú thích này, việc huấn luyện API Retriever được thực hiện để tối đa hóa tính liên quan của các API được truy xuất đối với hướng dẫn nhiệm vụ của người dùng. Framework huấn luyện cho API Retriever được mô tả như một kiến trúc hai luồng sử dụng Sentence-BERT, một biến thể của mô hình BERT được tối ưu hóa để tạo ra embedding câu. Quá trình huấn luyện sử dụng các cặp hướng dẫn và API tương ứng của chúng, được ký hiệu là Instruction 1 đến Instruction K và API 1 đến API K.

Mỗi hướng dẫn và mô tả API được xử lý qua mô hình Sentence-BERT riêng của nó để có được embedding phong phú về mặt ngữ nghĩa. Điều này có nghĩa là đối với mỗi cặp hướng dẫn-API, chúng tôi tạo ra hai embedding riêng biệt bao bọc bản chất ngữ nghĩa của văn bản. Các embedding cho hướng dẫn được gắn nhãn là Sentence Embedding 1 đến Sentence Embedding K, và tương tự, các embedding cho API tuân theo cùng một ký hiệu.

Framework sử dụng một mục tiêu huấn luyện được gọi là Multiple Negatives Ranking Loss. Hàm mất mát này được thiết kế để đối chiếu một cặp tích cực (một liên kết chính xác giữa hướng dẫn và một API) với nhiều cặp tiêu cực (các liên kết không chính xác). Mục tiêu là giảm thiểu khoảng cách giữa các embedding của các cặp hướng dẫn-API chính xác trong khi tối đa hóa khoảng cách giữa các embedding của các cặp không chính xác.

Trong quá trình huấn luyện, điều này khuyến khích mô hình học một không gian biểu diễn nơi các hướng dẫn và API liên quan của chúng gần nhau hơn, do đó tạo điều kiện cho việc truy xuất API chính xác hơn đáp lại các hướng dẫn mới.

#### 2.2.3 Suy luận

Sơ đồ suy luận minh họa quy trình tích hợp API Retriever và LLM với mục tiêu tạo ra câu trả lời cuối cùng cho một hướng dẫn nhất định.

Quy trình bắt đầu với một Hướng dẫn: một truy vấn hoặc nhiệm vụ của người dùng cần được giải quyết. Hướng dẫn này được đưa vào API Retriever, một thành phần đã được huấn luyện tỉ mỉ để nhận biết và chọn các API liên quan nhất từ một Bộ sưu tập API rộng lớn. API Retriever đánh giá hướng dẫn, xác định các API liên quan cần thiết để hoàn thành nhiệm vụ, và truy xuất một tập con API, được ký hiệu là retrieved API 1 đến retrieved API K.

Khi các API liên quan được truy xuất, chúng được đưa vào prompt cấp công cụ cho LLM để chọn các API chính xác để giải quyết các hướng dẫn nhất định. Điều quan trọng cần lưu ý là có thể có nhiều tương tác ("Interact ×N") giữa LLM và Nhà cung cấp Dịch vụ Công cụ, là các điểm cuối thực tế của API, cho thấy rằng LLM có thể gọi nhiều API nhiều lần để thu thập thông tin cần thiết.

Cuối cùng, sau khi LLM đã tương tác với các nhà cung cấp dịch vụ công cụ theo yêu cầu, chúng tóm tắt thông tin thu thập được từ các API để xây dựng "Câu trả lời Cuối cùng". Câu trả lời này được mong đợi là một phản hồi toàn diện cho hướng dẫn ban đầu, thể hiện khả năng của hệ thống trong việc hiểu, truy xuất và áp dụng thông tin liên quan để giải quyết các vấn đề phức tạp trong thế giới thực.

### 2.3 LLM Finetuner

Trong khi các LLM mã nguồn mở có khả năng mạnh mẽ, chúng thường gặp phải những hạn chế do thiếu tính đặc hiệu và khả năng thích ứng trong các lĩnh vực thực tế phức tạp, chuyên biệt. Hơn nữa, một số mô hình có thể thiếu sót trong khả năng tạo sinh của chúng, gặp khó khăn trong việc tạo ra đầu ra chất lượng cao khi được giao các thách thức. Để giải quyết những vấn đề này, chúng tôi chuyển hướng tiếp cận từ việc tiên phong các phương pháp tinh chỉnh mới sang tập trung vào việc phát triển một tập dữ liệu, được tuyển chọn rõ ràng để tăng cường quá trình tinh chỉnh cho hệ thống thực tế. Trong ngữ cảnh này, chúng tôi cũng sẽ chia sẻ một số hiểu biết trong quá trình tinh chỉnh, cung cấp sự hiểu biết rõ ràng hơn về ảnh hưởng của nó đối với hiệu suất mô hình.

Xây dựng trên nền tảng được thiết lập bởi phần giới thiệu, chúng tôi đi sâu vào việc tinh chỉnh LLM của chúng tôi bằng phương pháp phổ biến được gọi là Supervised Fine-Tuning (SFT). Phương pháp tinh chỉnh chính thống này liên quan đến việc điều chỉnh các trọng số được huấn luyện trước của một LLM trên một tập dữ liệu được gắn nhãn với các đầu ra chính xác cho các đầu vào nhất định. SFT đặc biệt hiệu quả trong việc tăng cường hiệu suất mô hình trong các lĩnh vực hoặc nhiệm vụ cụ thể, vì nó hướng mô hình hướng tới đầu ra mong muốn bằng cách sử dụng các tín hiệu giám sát được cung cấp.

Đối với quá trình tinh chỉnh của chúng tôi, chúng tôi đã xây dựng và phân tích ba tập dữ liệu riêng biệt, mỗi tập đại diện cho một mô hình tinh chỉnh độc đáo:

1. **Training Set v1**: Sinh ra từ nhu cầu về các tập dữ liệu phản ánh chính xác các tình huống thực tế, tập dữ liệu ban đầu này được xây dựng bằng cách lựa chọn cẩn thận các trường hợp thực tế, loại bỏ dữ liệu không hiệu quả và các trường hợp trùng lặp. Động lực của nó nằm trong việc nền tảng hóa SFT trong thực tế, điều chỉnh sự hiểu biết của LLM với phân phối dữ liệu thực sự được tìm thấy trong việc sử dụng thực tế. Tập dữ liệu phục vụ như một bước sơ bộ hướng tới việc điều chỉnh LLM để thích ứng với phân phối dữ liệu thực tế.

2. **Training Set v2**: Tập dữ liệu này được biên soạn chọn lọc dựa trên chức năng prompt, bao gồm tổng cộng 745 mục. Nó được tăng cường với các prompt cấp hệ thống bao gồm danh sách toàn diện các tính năng và mô tả của chúng. Những prompt được làm phong phú này phục vụ để cung cấp cho LLM sự hiểu biết chi tiết hơn về khả năng và ràng buộc của mỗi API. Bằng cách kết hợp danh sách chức năng chi tiết và mô tả trong prompt, chúng tôi nhằm tăng cường khả năng của mô hình trong việc tạo ra các phản hồi không chỉ khớp với truy vấn đầu vào về mặt ngữ nghĩa mà còn gắn chặt với phạm vi chức năng của các API có sẵn.

3. **Training Set v3**: Nhận biết những hạn chế của tập dữ liệu trước đây của chúng tôi, chủ yếu bao gồm các lời gọi API một bước và thiếu đa dạng prompt, chúng tôi tìm cách bao phủ gần hơn các tình huống thực tế. Training Set v3 do đó được thiết kế tỉ mỉ để cầu nối khoảng cách lĩnh vực này, bao gồm 660 cặp câu hỏi-trả lời phản ánh độ phức tạp của các trường hợp sử dụng thực tế.

Mỗi tập dữ liệu được dự định để tinh chỉnh dần khả năng của LLM trong việc phân tích đầu vào người dùng, hiểu ngữ cảnh, và tạo ra các lời gọi API chính xác. Việc tinh chỉnh LLM trên các tập dữ liệu này có thể tăng cường khả năng của LLM trong việc giải quyết các nhiệm vụ thực tế cụ thể.

### 2.4 Demo Selector

Framework Demo Selector, như được hiển thị trong Hình 4, đóng vai trò quan trọng trong việc tăng cường khả năng của LLM được tinh chỉnh để phân biệt giữa các API có chức năng và ngữ nghĩa tương tự. Thông thường, chất lượng của các demo có ảnh hưởng rất tích cực trong việc thúc đẩy khả năng của LLM để phân tách các nhiệm vụ phức tạp.

Demo Selector được thiết kế để động truy xuất các demo khác nhau liên quan đến các API thách thức trong việc phân biệt do các tính năng chồng chéo của chúng. Quy trình làm việc chính bắt đầu với một "Hướng dẫn", đại diện cho truy vấn hoặc lệnh của người dùng đòi hỏi sự sử dụng một hoặc nhiều API.

Khi nhận được một hướng dẫn, Demo Selector tương tác với hai tài nguyên quan trọng: "Cơ sở Dữ liệu Kiến thức" và "Bộ sưu tập API". Cơ sở Dữ liệu Kiến thức chứa thông tin có cấu trúc có thể bao gồm tài liệu API, ví dụ sử dụng, và dữ liệu liên quan khác giúp hiểu ngữ cảnh và chi tiết của mỗi API. Bộ sưu tập API, mặt khác, bao gồm các điểm cuối API thực tế và metadata liên quan của chúng.

Sau đó, một quy trình tìm kiếm embedding được sử dụng để tạo điều kiện cho việc truy xuất các demo liên quan cho một truy vấn người dùng nhất định.

Chức năng cốt lõi của Demo Selector nằm trong khả năng thích ứng và độ chính xác trong việc xác định các demo liên quan nhất cho một truy vấn nhiệm vụ nhất định, đảm bảo rằng LLM được cung cấp các ví dụ phù hợp nhất về mặt ngữ cảnh cho hoạt động của nó.

Cuối cùng, tương tác giữa Demo Selector và LLM được tinh chỉnh dẫn đến việc tạo ra câu trả lời cuối cùng, là phản hồi của LLM cho hướng dẫn ban đầu, được thông báo bởi sự hiểu biết sắc sảo thu được từ các demo.

## 3 Thí nghiệm

Trong phần này, chúng tôi trình bày một thí nghiệm được thiết kế để đánh giá nghiêm ngặt hiệu quả của framework được đề xuất của chúng tôi, với trọng tâm cụ thể là các thành phần API Retriever, LLM Finetuner, và Demo Selector. Phương pháp thí nghiệm của chúng tôi được cấu trúc để kiểm tra hiệu suất của hệ thống trong ngữ cảnh thực tế và thách thức mã nguồn mở.

### 3.1 Tập dữ liệu

**Tình huống Thực tế Ẩn danh.** Khác với trọng tâm học thuật hiện tại về việc nghiên cứu khả năng chọn API đúng từ nhiều API bao gồm các chức năng khác nhau, trong hệ thống thực tế, các vấn đề phổ biến và thách thức hơn thường xoay quanh một số mục đích cốt lõi. Nó đòi hỏi việc chọn API phù hợp nhất từ vài chục API, có liên quan chặt chẽ về mặt ngữ nghĩa nhưng khác nhau trong cách sử dụng, như các tham số yêu cầu. Do đó, chúng tôi đã xây dựng một tập dữ liệu chuyên biệt bao gồm 45 API xoay quanh 11 chức năng cốt lõi, dựa trên một hệ thống bảo mật thương mại thực tế.

**Tình huống Mã nguồn Mở.** Để đảm bảo khả năng tổng quát hóa của phương pháp của chúng tôi trên một phổ rộng hơn các nhiệm vụ và khả năng chọn API phù hợp từ vô số tùy chọn, chúng tôi cũng thực hiện thí nghiệm trên một tập dữ liệu mã nguồn mở, ToolBench, chứa hơn 16000 API thực tế trải dài 49 danh mục ứng dụng.

### 3.2 Thí nghiệm trên Tình huống Thực tế

Trong tình huống thực tế ẩn danh của chúng tôi, chúng tôi thực hiện các bài kiểm tra để đánh giá hiệu quả của các module được đề xuất trong framework của chúng tôi. Chúng tôi bắt đầu bằng cách đánh giá khả năng của API retriever trên tập dữ liệu của chúng tôi, đạt được Recall@5 là 84.64% và Recall@10 là 98.47% trong Bảng 1. Những kết quả này xác minh hiệu quả của phương pháp của chúng tôi, chứng minh mức độ chính xác cao trong việc truy xuất API liên quan, điều này rất quan trọng cho giai đoạn thực thi nhiệm vụ tiếp theo.

Chuyển sang các bài kiểm tra thực thi nhiệm vụ, kết quả được trình bày trong Bảng 2. Chúng tôi chọn InternLM, một mô hình ngôn ngữ tinh vi được phát triển bởi Shanghai AI Lab, làm LLM được đánh giá của chúng tôi. Thuật ngữ "base LLM" đề cập đến việc thực thi các prompt không bao gồm demo và sử dụng tập API Oracle nhỏ nhất, được lựa chọn tỉ mỉ bởi các chuyên gia con người.

Hiệu suất cao nhất được quan sát khi kết hợp LLM được tinh chỉnh với cả API Retriever và Demo Selector, đạt được độ chính xác thực thi ấn tượng 96.67%. Kết quả này nhấn mạnh hiệu quả của việc tích hợp tinh chỉnh với các cơ chế truy xuất API và lựa chọn demo tinh vi của chúng tôi.

### 3.3 Thí nghiệm trên Tình huống Mã nguồn Mở

Trong tình huống mã nguồn mở, chúng tôi điều chỉnh đánh giá của mình để tập trung chủ yếu vào tác động của tinh chỉnh và API Retriever, xem xét rằng việc xây dựng demo cho ngữ cảnh này không đóng góp đáng kể vào việc giải quyết các vấn đề thực tế.

Như được hiển thị trong Bảng 3, độ chính xác thực thi của base LLM đứng ở 76.67%. Thú vị là, việc giới thiệu API Retriever dẫn đến giảm hiệu suất, giảm xuống 53.3%. Sự suy giảm này có thể do một số yếu tố. Đầu tiên, khả năng thu hồi thấp của API Retriever giới thiệu lỗi tích lũy trong quy trình ra quyết định.

Khi thực hiện tinh chỉnh trong tình huống này, một cải thiện hiệu suất được quan sát, với LLM được tinh chỉnh kết hợp với API Retriever đạt độ chính xác thực thi 86.7%. Cải thiện này nhấn mạnh hiệu quả của tinh chỉnh trong việc thích ứng LLM với các đặc điểm và thách thức cụ thể của môi trường mã nguồn mở.

## 4 Công trình Liên quan

Khả năng đáng chú ý trong việc sử dụng công cụ đã tạo điều kiện cho việc vượt qua những hạn chế về thể chất và nhận thức vốn có của con người, tăng cường khả năng hiểu, lập kế hoạch và giải quyết các nhiệm vụ phức tạp của chúng ta. Ngược lại, năng khiếu của con người trong việc hiểu và lập kế hoạch nhiệm vụ đóng góp vào việc lựa chọn và sử dụng khôn ngoan các công cụ phù hợp. Gần đây, sự phát triển nhanh chóng của LLM đã làm cho việc sử dụng các công cụ chuyên biệt và phân tách các nhiệm vụ phức tạp như con người trở nên khả thi, điều này đã truyền cảm hứng cho tiềm năng đáng kể trong việc giải quyết các nhiệm vụ thực tế.

### 4.1 Lập kế hoạch Nhiệm vụ

LLM được huấn luyện trước trên khối lượng văn bản khổng lồ và thể hiện khả năng lý luận thông thường và tổng quát hóa đa nhiệm vụ đáng kể. Prompting là một phương pháp hiệu quả cao để khai thác thêm các khả năng nội tại của LLM để giải quyết các vấn đề khác nhau. Đối với lập kế hoạch nhiệm vụ, prompting tạo điều kiện cho LLM phân tách các nhiệm vụ cấp cao thành các nhiệm vụ con và xây dựng các kế hoạch có căn cứ.

Tuy nhiên, trong hệ thống thực tế, các nhiệm vụ cấp cao phức tạp hơn, và phương pháp prompting mà không tăng cường khả năng lập kế hoạch nhiệm vụ nội tại của LLM khó có thể đạt được hiệu suất tốt. Do đó, trong công trình của chúng tôi, chúng tôi áp dụng cơ chế tinh chỉnh cho tập dữ liệu lập kế hoạch, cùng với các prompt được thiết kế tốt, để tối đa hóa khả năng lập kế hoạch nhiệm vụ.

### 4.2 Sử dụng Công cụ

Nghiên cứu ban đầu trong học công cụ bị giới hạn bởi khả năng của các phương pháp học sâu truyền thống vì những điểm yếu của chúng trong việc hiểu chức năng công cụ và ý định người dùng, cũng như khả năng lý luận thông thường. Gần đây, sự tiến bộ của LLM đã đánh dấu một bước ngoặt then chốt trong lĩnh vực học công cụ.

Tuy nhiên, hầu hết các công trình được đề cập ở trên chỉ tập trung vào các tình huống cụ thể, giải quyết cách chọn hoặc sử dụng công cụ phù hợp từ một tập hợp hạn chế, trong khi các agent trong tình huống thực tế thường phải đối mặt với các tình huống đa dạng và phức tạp, đòi hỏi việc lựa chọn và sử dụng chính xác các công cụ đúng từ một đám mây API với các API khổng lồ.

## 5 Kết luận

Trong bài báo này, chúng tôi trình bày một framework toàn diện được thiết kế để tăng cường khả năng của Mô hình Ngôn ngữ Lớn (LLM) trong các tình huống thực tế phức tạp, đặc biệt tập trung vào lập kế hoạch nhiệm vụ và sử dụng công cụ. Phương pháp của chúng tôi, tích hợp API Retriever, LLM Finetuner, và Demo Selector, đã được kiểm tra và xác thực nghiêm ngặt trong các môi trường khác nhau. Kết quả cho thấy rằng việc tinh chỉnh LLM với tập dữ liệu được tuyển chọn cải thiện đáng kể hiệu quả của chúng trong việc thực thi các nhiệm vụ thực tế. Các thành phần API Retriever và Demo Selector cũng chứng minh là không thể thiếu, đặc biệt trong việc tăng cường độ chính xác ra quyết định và khả năng thích ứng của mô hình. Nghiên cứu này không chỉ thể hiện tiềm năng của LLM trong các ứng dụng thực tế mà còn đặt nền tảng cho những tiến bộ trong tương lai trong lĩnh vực này. Bằng cách giải quyết những thách thức về tính đa dạng và độ phức tạp của API, framework của chúng tôi mở đường cho các hệ thống AI hiệu quả hơn và hướng người dùng hơn, có khả năng xử lý các tình huống thực tế.

# 2404.12753.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2404.12753.pdf
# Kích thước tệp: 1460338 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
AUTOSCRAPER: Một Tác nhân Web Hiểu biết Tiến bộ để Tạo ra Web Scraper

Wenhao Huang♢, Zhouhong Gu♢, Chenghao Peng♡, Zhixu Li♢, Jiaqing Liang♡†
Yanghua Xiao♢†, Liqian Wen♠, Zulong Chen♠
♢Phòng thí nghiệm Khoa học Dữ liệu Trọng điểm Thượng Hải, Trường Khoa học Máy tính, Đại học Fudan
♡Trường Khoa học Dữ liệu, Đại học Fudan,♠Alibaba Holding-Aicheng Technology-Enterprise
{whhuang21,zhgu22,chpeng23}@m.fudan.edu.cn ,
{liangjiaqing,zhixuli,shawyh}@fudan.edu.cn

Tóm tắt
Web scraping là một kỹ thuật mạnh mẽ để trích xuất dữ liệu từ các trang web, cho phép thu thập dữ liệu tự động, nâng cao khả năng phân tích dữ liệu và giảm thiểu nỗ lực nhập dữ liệu thủ công. Các phương pháp hiện tại, phương pháp dựa trên wrapper gặp phải khả năng thích ứng và mở rộng hạn chế khi đối mặt với một trang web mới, trong khi các tác nhân ngôn ngữ, được tăng cường bởi các mô hình ngôn ngữ lớn (LLM), thể hiện khả năng tái sử dụng kém trong các môi trường web đa dạng. Trong công trình này, chúng tôi giới thiệu mô hình tạo ra web scraper với LLM và đề xuất AUTOSCRAPER, một khung hai giai đoạn có thể xử lý các môi trường web đa dạng và thay đổi một cách hiệu quả hơn. AUTOSCRAPER tận dụng cấu trúc phân cấp của HTML và sự tương tự giữa các trang web khác nhau để tạo ra web scraper. Bên cạnh đó, chúng tôi đề xuất một chỉ số khả năng thực thi mới để đo lường hiệu suất của các tác vụ tạo web scraper tốt hơn. Chúng tôi tiến hành các thí nghiệm toàn diện với nhiều LLM và chứng minh tính hiệu quả của khung của chúng tôi. Công trình của chúng tôi hiện đã mã nguồn mở.¹

1 Giới thiệu
Web scraping là một quá trình mà phần mềm tự động hóa việc trích xuất dữ liệu từ các trang web, thường sử dụng bot hoặc web scraper để thu thập thông tin cụ thể (Thapelo et al., 2021). Điều này quan trọng vì nó cho phép thu thập và tổng hợp dữ liệu hiệu quả, có thể rất quan trọng cho nghiên cứu thị trường, phân tích cạnh tranh và giám sát dữ liệu thời gian thực.

Do sự đa dạng của các nguồn và thông tin trên internet, việc xây dựng một web scraper đòi hỏi nỗ lực đáng kể từ con người. Do đó, hai loại phương pháp để thu thập thông tin web tự động đã được đề xuất, được phân loại là dựa trên wrapper và dựa trên tác nhân ngôn ngữ (Sarkhel

†Tác giả liên hệ.
¹Tài nguyên của bài báo này có thể được tìm thấy tại https://github.com/EZ-hwh/AutoScraper

Q1: Tuổi của Stephen Curry là bao nhiêu?
……
Phương pháp Dựa trên Wrapper    Phương pháp Dựa trên Tác nhân Ngôn ngữ    AUTOSCRAPER: Dựa trên Wrapper + Dựa trên Tác nhân Ngôn ngữ Q1 Q1

<html>
 ...
    <div 
class="entity-
title">
     <div 
class="title">
        
<span>Stephen 
Curry</span> 
…………
 Phản hồi
Nỗ lực Thủ công Nặng nề    Tiêu tốn Thời gian & Tài chính Nặng nề

Q1: Tuổi của ……Curry?
Q2: Tuổi của ……Harden? Phản hồi
Phản hồi Trang web-1
<html>
 ...
    <div class="entity-
title">
     <div class="title">
        <span> Stephen 
Curry</span> 
………… Trang web-1 Wrapper1 Q2
<html>
 ...
    <div 
class="entity-
title">
     <div 
class="title">
        <span>James 
Harden</span> 
………… Phản hồi Trang web-2

Có thể tái sử dụng cao với Hiệu suất Tuyệt vời <html>
 ...
    <div 
class="entity-
title">
     <div 
class="title">
        
<span>Stephen 
Curry</span> 
………… Trang web-1

Q2: Tuổi của James Harden là bao nhiêu?
<html>
 ...
    <div 
class="entity-
title">
     <div 
class="title">
        
<span>LEBRON 
JAMES</span> 
………… Trang web-2 Q1
Wrapper2
Phản hồi Phản hồi

<html>
………… Trang web-2

Hình 1: Một minh họa so sánh phương pháp dựa trên wrapper, phương pháp dựa trên tác nhân ngôn ngữ và AUTOSCRAPER.

et al., 2023). Phương pháp dựa trên wrapper bao gồm các chuỗi hoạt động phức tạp trong các hàm dựa trên quy tắc tùy chỉnh, được thiết kế để truy cập và truy xuất dữ liệu mong muốn từ các trang web một cách hiệu quả, đặc biệt có lợi cho các trang web có cấu trúc với bố cục ổn định (Kushmerick, 1997; Dalvi et al., 2011; Bronzi et al., 2013). Ngược lại, phương pháp dựa trên tác nhân ngôn ngữ tận dụng khả năng xử lý ngôn ngữ tự nhiên mạnh mẽ của các mô hình ngôn ngữ lớn (LLM) để diễn giải các truy vấn văn bản tự do và trực tiếp trích xuất dữ liệu trong các trang web để đáp ứng nhu cầu, xử lý hiệu quả cả nội dung web có cấu trúc và động (Whitehouse et al., 2023; Marco Perini, 2024).

Mặc dù cả hai loại phương pháp đều tạo điều kiện cho web scraping ở các mức độ khác nhau, như được hiển thị trong Hình 1, chúng thể hiện những thiếu sót đáng kể về khả năng mở rộng. Phương pháp dựa trên wrapper, mặc dù có thể tái sử dụng, gặp khó khăn với các cấu trúc trang web hoàn toàn mới, đòi hỏi nỗ lực con người đáng kể để phát triển các hàm tùy chỉnh bổ sung (Gulhane et al., 2011; Lockard et al., 2019). Ngược lại,

--- TRANG 2 ---
mặc dù các phương pháp dựa trên tác nhân ngôn ngữ thể hiện hiệu suất vượt trội trong việc thích ứng với nội dung mới, sự phụ thuộc của chúng vào một số lượng hạn chế các LLM dựa trên API siêu mạnh cho web scraping phát sinh chi phí thời gian và tài chính đáng kể. Cùng nhau, những thách thức này cản trở việc áp dụng rộng rãi và khả năng mở rộng của các công nghệ web scraping hiện tại, giới hạn tính thực tiễn của chúng trong các môi trường web động và đa dạng.

Để giải quyết những thiếu sót của hai mô hình đã nề trên, mô hình tạo ra web scraper với LLM sẽ là giải pháp tối ưu. Một mặt, so với các phương pháp dựa trên wrapper, nó tận dụng đầy đủ khả năng lý luận và phản chiếu của LLM, giảm thiết kế thủ công cho các tác vụ mới và nâng cao khả năng mở rộng. Mặt khác, so với các phương pháp dựa trên tác nhân ngôn ngữ, nó giới thiệu các thủ tục trích xuất có thể lặp lại, giảm sự phụ thuộc vào LLM khi xử lý các tác vụ tương tự, và do đó cải thiện hiệu quả khi xử lý một số lượng lớn các tác vụ web. Tuy nhiên, có một số thách thức liên quan đến việc sử dụng LLM để tạo ra web scraper:

1. Tài liệu HTML dài. Mặc dù LLM xuất sắc trong việc hiểu nội dung văn bản dài, HTML, như dữ liệu bán cấu trúc, bao gồm cả các yếu tố có cấu trúc (thẻ và thuộc tính) và không có cấu trúc (nội dung văn bản). Do đó, việc LLM tạo ra các web scraper có thể thực thi tuân thủ nghiêm ngặt cấu trúc phân cấp của các trang web trong các bối cảnh đánh dấu phức tạp là một thách thức.

2. Khả năng tái sử dụng. Một scraper tốt cần có thể tái sử dụng trên nhiều trang web. Tuy nhiên, sự khác biệt về nội dung và cấu trúc giữa các trang web khác nhau có thể dẫn đến việc tạo ra một scraper tham chiếu đến một trang web, chỉ có thể áp dụng cho một số trang web.

3. Các chỉ số đánh giá phù hợp. Để một scraper được coi là hữu ích, nó phải có thể tự động trích xuất các kết quả mong muốn từ tất cả các trang web. Tuy nhiên, các chỉ số đánh giá hiện tại cho việc trích xuất thông tin web, tập trung vào kết quả trích xuất từ các trang web riêng lẻ, không phản ánh đầy đủ khả năng sử dụng của scraper. Điều này có thể dẫn đến việc hiểu lầm các kết luận thí nghiệm.

Chúng tôi giới thiệu AUTOSCRAPER, một khung hai giai đoạn để giải quyết tác vụ tạo web scraper. Được minh họa trong Hình 2, AUTOSCRAPER bao gồm hai thành phần chính: tạo ra tiến bộ và tổng hợp. Giai đoạn tạo ra tiến bộ tận dụng cấu trúc phân cấp của HTML để hiểu biết tiến bộ nhằm giải quyết tài liệu HTML dài. Tiếp theo, mô-đun tổng hợp tích hợp nhiều scraper được tạo ra trên các trang web khác nhau để tạo ra một scraper gắn kết, đặc thù cho trang web hoạt động phổ quát trong trang web đó. Bên cạnh đó, chúng tôi đề xuất một chỉ số đánh giá mới cho các tác vụ tạo web scraper, được gọi là chỉ số khả năng thực thi. Không giống như các chỉ số trích xuất thông tin truyền thống đo lường các trang web đơn lẻ, chỉ số này đo lường nhiều trang web trong một trang web, phản ánh chính xác độ tin cậy và khả năng tái sử dụng của scraper.

Chúng tôi đánh giá AUTOSCRAPER trên ba bộ dữ liệu có sẵn với 8 LLM. Trên cả ba bộ dữ liệu, AUTOSCRAPER luôn vượt trội so với tất cả baseline và đạt được kết quả hiện đại mới trong các thiết lập zero-shot. Ngoài ra, AUTOSCRAPER có thể vượt qua các phương pháp học có giám sát. Hơn nữa, AUTOSCRAPER thể hiện hiệu quả vượt trội trong các tác vụ trích xuất thông tin web quy mô lớn. So với các wrapper truyền thống, AUTOSCRAPER điều chỉnh nhanh hơn theo các trang web khác nhau và yêu cầu tác vụ. Tính linh hoạt này cho phép các scraper xử lý các môi trường web đa dạng và thay đổi một cách hiệu quả hơn. So với mô hình tác nhân ngôn ngữ, nó giới thiệu các hàm trung gian để nâng cao khả năng tái sử dụng và giảm sự phụ thuộc vào LLM khi xử lý các tác vụ tương tự, do đó cải thiện hiệu quả khi xử lý một số lượng lớn các tác vụ web.

2 Công trình Liên quan
Các phương pháp dựa trên wrapper cho web scraping sử dụng cấu trúc phân cấp của trang web. Phương pháp của loại này bao gồm dựa trên quy tắc (Zheng et al., 2008), wrapper học (tức là một parser đặc thù DOM có thể trích xuất nội dung) (Gulhane et al., 2011; Kushmerick, 1997; Dalvi et al., 2011), thuật toán heuristic (Lockard et al., 2018, 2019) và mạng neural học sâu (Lin et al., 2020; Zhou et al., 2021; Li et al., 2022; Wang et al., 2022). Các phương pháp này đòi hỏi sự tham gia đáng kể của con người, bao gồm tạo ra các chú thích wrapper, áp dụng các quy tắc tính điểm heuristic (như gần gũi về mặt thị giác), tạo ra các đặc điểm cho đầu vào mạng neural, và sử dụng kiến thức trước để xác minh. Do đó, việc các phương pháp dựa trên wrapper

--- TRANG 3 ---
tự động mở rộng khi đối mặt với các tác vụ web scraping trên một số lượng lớn các trang web khác nhau là khó khăn.

Với sự xuất hiện của các LLM mạnh mẽ (OpenAI, 2023; Touvron et al., 2023), các tác nhân ngôn ngữ (Sumers et al., 2023) hiện hoạt động trong các môi trường tương tác, tận dụng lý luận, grounding, học tập và ra quyết định dựa trên LLM. Các tác nhân ngôn ngữ tổng quát, như Chain-of-Thought (Wei et al., 2023), Reflexion (Shinn et al., 2023), Self-Refine (Madaan et al., 2023), và Self-Debug (Chen et al., 2023), tận dụng khả năng tự phản chiếu của LLM để tối ưu hóa kế hoạch lặp. Tuy nhiên, các tác nhân này không sử dụng hiệu quả các đặc điểm cấu trúc web và không thể đơn giản hóa môi trường web sau các nỗ lực lập kế hoạch không thành công, giới hạn việc tối ưu hóa kế hoạch tiếp theo.

Các tác nhân ngôn ngữ hiện tại chủ yếu nhằm mục đích hợp lý hóa môi trường web (Sridhar et al., 2023; Gur et al., 2023; Zheng et al., 2024) và phát triển các chiến lược để lập kế hoạch và tương tác với web (Sodhi et al., 2023; Ma et al., 2023). Tuy nhiên, các khung này chủ yếu tập trung vào khái niệm về môi trường mô phỏng web thế giới mở (Shi et al., 2017; Yao et al., 2023; Deng et al., 2023; Zhou et al., 2023), bao gồm một phạm vi rộng các tác vụ được tìm thấy trong các tình huống thực tế, như mua sắm trực tuyến, đặt vé máy bay và phát triển phần mềm. Các tình huống tác vụ này được định hướng cho cá nhân và có yêu cầu về độ chính xác và hiệu quả khác biệt đáng kể so với web scraping.

Kết quả là, các phương pháp dựa trên tác nhân ngôn ngữ hiện tại không thể khai thác hiệu quả sự tương tự cấu trúc HTML trên nhiều trang web, giảm sự phụ thuộc vào LLM khi thực hiện các hoạt động lặp lại và dẫn đến sự kém hiệu quả.

3 Kiến thức Cơ bản
Trong phần này, chúng tôi đầu tiên định nghĩa tác vụ tạo scraper và sau đó trình bày quá trình thu thập bộ dữ liệu và các chỉ số đánh giá tương ứng.

3.1 Công thức Tác vụ
Đầu tiên, chúng tôi công thức hóa tác vụ tạo scraper của chúng tôi. Cho một tập hợp các trang web trên cùng một trang web w ∈ W mô tả một thực thể chủ đề s (cũng được gọi là thực thể chủ đề trong tài liệu trước đây), và thuộc tính mục tiêu được định nghĩa trước tương ứng r ∈ R, mục tiêu tác vụ là tạo ra một chuỗi quy tắc/hành động có thể thực thi A để trích xuất thông tin mục tiêu o từ tất cả

Bộ dữ liệu Số Case Số Task Số Web
SWDE 320 32 32,000
EXTENDED SWDE 294 221 29,400
DS1 83 11 186

Bảng 1: Thống kê các benchmark tác vụ web scraping. Chúng tôi báo cáo số lượng case (Số Case), số lượng tác vụ trích xuất khác nhau (Số Task) và tổng số trang web (Số Web).

các trang web.

3.2 Bộ dữ liệu
Chúng tôi áp dụng tác vụ trích xuất thông tin bán cấu trúc như một testbed cho tác vụ tạo scraper.

SWDE (Hao et al., 2011) là một bộ dữ liệu Structured Web Data Extraction chứa các trang web từ 80 trang web trong 8 lĩnh vực, với 124,291 trang web. Mỗi trang web từ cùng một lĩnh vực tập trung vào 3-5 thuộc tính trong các trang web.

EXTENDED SWDE (Lockard et al., 2019) bao gồm chú thích thủ công chi tiết của 21 trang web trong 3 lĩnh vực từ SWDE. Trong khi SWDE chứa trung bình 4,480 bộ ba cho 3 vị từ mỗi trang web, bộ dữ liệu EXTENDED SWDE có trung bình 41K bộ ba cho 36 vị từ mỗi trang web.

DS1 (Omari et al., 2017) chứa 166 trang web được chú thích từ 30 trang web quy mô lớn thực tế được phân loại thành sách, mua sắm, khách sạn và phim.

Chúng tôi biến đổi bộ dữ liệu với các thiết lập sau. Đầu tiên, chúng tôi thiết kế hướng dẫn cho mỗi lĩnh vực, và cho mỗi thuộc tính như thông tin đầu vào cho LLM². Thứ hai, cho mỗi trang web trong mỗi lĩnh vực, chúng tôi lấy mẫu 100 trang web làm toàn bộ tập kiểm tra. Chúng tôi xem xét tập hợp các trang web trên cùng các trang web và hướng dẫn trích xuất tương ứng như một case. Ví dụ, đối với trang web ESPN³ trong lĩnh vực cầu thủ NBA, 100 trang web chi tiết được lấy mẫu của các cầu thủ và hướng dẫn Vui lòng trích xuất đội của cầu thủ mà anh ấy chơi hiện tại là một case hoàn chỉnh của tác vụ tạo scraper của chúng tôi. Thứ ba, chúng tôi tiền xử lý các trang web bằng cách loại bỏ các yếu tố không liên quan trong một trang web. Chúng tôi sử dụng thư viện BeautifulSoup mã nguồn mở⁴ và lọc ra tất cả các nút phần tử DOM với <script> và <style>, cũng như xóa tất cả các thuộc tính trong nút phần tử ngoại trừ @class. Chúng tôi thay thế các ký tự escape gốc trong các chú thích để đảm bảo

²Thông tin chi tiết về prompt có trong Phụ lục D.1
³https://global.espn.com/nba/
⁴https://beautifulsoup.readthedocs.io

--- TRANG 4 ---
Chuỗi Hành động 3
Bước1: //*[text()='PPG']
Bước2: ./ancestor
Bước3: ./span[1]/text()

Chuỗi Hành động 2
Bước1: //*[text()='PPG']
Bước2: ./ancestor
Bước3: ./span[1]/text()

Giai đoạn1: Tạo ra Tiến bộ Giai đoạn2: Tổng hợp

Chuỗi Hành động 1
Bước1: //*[text()=' PPG']/text() 
Bước2: ./ancestor 
Bước3: ./span[2]/text()

Kết quả của Chuỗi Hành động 3
Trang web1: 17.4
Trang web2: 28.3
Trang web3: 22.6

Kết quả của Chuỗi Hành động 2
Trang web1: 
Trang web2: 
Trang web3: 

Kết quả của Chuỗi Hành động 1
Trang web 1: 6.7
Trang web 2: 4.7
Trang web 3: 2.9

Chuỗi nào là tốt nhất?
Chuỗi Hành động 1 là tốt nhất.

Hướng dẫn: Số rebound trung bình của James Harden là bao nhiêu?

Bước1: Top-down
Bước2: Step-back
Bước3: Top-down

Sai.……
Đúng.

(a) Tạo ra Tiến bộ:
Tạo ra một chuỗi hành động 
thông qua nhiều vòng tương tác với một trang web.

(b) Tổng hợp:
Chọn một trong những chuỗi hành động tốt nhất được tạo ra với trang web khác nhau.

Chuỗi Hành động 2
Chuỗi Hành động 1
Chuỗi Hành động 3

Chuỗi Hành động Cuối cùng

Các Trang web Hạt giống Tập Chuỗi

Trích xuất văn bản với chuỗi hành động 

Bước1: [Top-down] 
XPath: //*[text()=' PPG']/text()
# Lấy văn bản bên dưới nút văn bản 'PPG'. 

Bước2: [Step-back] 
XPath: ./ancestor
# 16.6 không phải là câu trả lời đúng, lấy sub HTML với nhiều bối cảnh hơn. 

Bước3: [Top-down] 
XPath: ./span[2]/text()
# Lấy văn bản từ nút thứ hai của sub HTML hiện tại.

[HTML Đầy đủ]
[Sub HTML]
[Trích xuất văn bản] 16.6
[Lấy sub HTML]
[Trích xuất văn bản] 5.1

Hình 2: Khung AUTOSCRAPER của hai giai đoạn: (a) tạo ra tiến bộ và (b) tổng hợp.

tính nhất quán với thông tin tương ứng trên web. Thống kê của bộ dữ liệu chúng tôi đã biến đổi được hiển thị trong Bảng 1.

3.3 Chỉ số Đánh giá
Các sơ đồ đánh giá hiện tại cho các tác vụ trích xuất thông tin trang web vẫn tuân theo các chỉ số truyền thống của các tác vụ trích xuất thông tin văn bản, cụ thể là precision, recall và F1 score. Chúng giới hạn việc đánh giá các phương pháp cho tác vụ tạo scraper thành hai khía cạnh. Đầu tiên, nó tập trung vào trích xuất với một trang web đơn lẻ, thay vì xem xét khả năng tổng quát từ góc độ của một tập hợp các trang web. Thứ hai, nó không đo lường hiệu quả khả năng chuyển giao khi áp dụng chuỗi hành động cho các trang web khác.

Để giải quyết vấn đề này, chúng tôi biến đổi đánh giá tác vụ IE truyền thống thành một đánh giá có thể thực thi. Dựa trên đánh giá IE truyền thống trên một tập hợp các trang web, chúng tôi phân loại khả năng thực thi của các chuỗi hành động thành sáu tình huống sau. Cụ thể, cho mỗi tác vụ trích xuất trên một trang web, kết quả được phân loại dựa trên kết quả trích xuất về precision, recall và f1-score. (1) Đúng: cả precision, recall và f1-score đều bằng 1, cho thấy chuỗi hành động chính xác; (2) Precision(Prec.): chỉ có precision bằng 1, cho thấy độ chính xác hoàn hảo trong các instance được trích xuất theo chuỗi hành động, nhưng bỏ lỡ các instance liên quan; (3) Recall(Reca.): chỉ có recall bằng 1, có nghĩa là nó thành công xác định tất cả các instance liên quan trong trang web nhưng xác định sai một số instance không liên quan; (4) Un-executable(Unex.): recall bằng 0, cho thấy chuỗi hành động không thể xác định các instance liên quan; (5) Over-estimate(Over.): precision bằng 0, cho thấy chuỗi hành động trích xuất các instance trong khi ground truth là rỗng; (6) Khác: phần còn lại của tình huống, bao gồm trích xuất một phần thông tin, v.v.

Vì các phân loại trên loại trừ lẫn nhau, chúng tôi sử dụng chỉ số tỷ lệ để tính tỷ lệ của mỗi kết quả trong tác vụ của chúng tôi.

MR = #case của tình huống / #tổng case (1)

Chúng tôi quan tâm nhiều hơn đến tỷ lệ thành công, vì vậy đối với chỉ số Đúng, giá trị cao hơn cho thấy tỷ lệ tốt hơn của các đường dẫn thực thi được tạo; trong khi đối với chỉ số Un-executable, giá trị thấp hơn là tốt hơn.

--- TRANG 5 ---
4 AUTOSCRAPER

Trong phần này, chúng tôi mô tả khung AUTOSCRAPER của chúng tôi để tạo ra một scraper để trích xuất thông tin cụ thể từ HTML bán cấu trúc. Cách tiếp cận của chúng tôi được chia thành hai giai đoạn: đầu tiên, chúng tôi áp dụng một mô-đun tạo ra tiến bộ sử dụng cấu trúc phân cấp của các trang web; thứ hai, chúng tôi sử dụng một mô-đun tổng hợp dựa trên kết quả từ nhiều trang web. Khung tổng thể được trình bày trong Hình 2.

4.1 Mô hình hóa
Không giống như phương pháp wrapper tạo ra một XPath, chúng tôi mô hình hóa tác vụ tạo scraper như một tác vụ tạo chuỗi hành động. Cụ thể, chúng tôi tạo ra một chuỗi hành động Aseq bao gồm một chuỗi biểu thức XPath⁵ từ một tập hợp các trang web hạt giống (tức là, một phần nhỏ các trang web trong case kiểm tra để tạo ra chuỗi).

Aseq = [XPath 1, XPath 2, ..., XPath n] (2)

trong đó n biểu thị độ dài của chuỗi hành động. Chúng tôi thực thi XPath trong chuỗi bằng cách sử dụng parser theo thứ tự. Trong chuỗi, tất cả các biểu thức XPath ngoại trừ cái cuối cùng được sử dụng để cắt tỉa trang web, và cái cuối cùng được sử dụng để trích xuất giá trị phần tử tương ứng từ trang web đã được cắt tỉa.

4.2 Tạo ra Tiến bộ
Xử lý nội dung dài và cấu trúc phân cấp của các trang web, việc tạo ra một scraper hoàn chỉnh và có thể thực thi trong một lần là khó khăn. Tuy nhiên, nội dung HTML được tổ chức trong cấu trúc cây DOM, điều này làm cho việc cắt tỉa các thành phần trang không liên quan và do đó, giới hạn độ dài và chiều cao của cây DOM để cải thiện hiệu suất tạo LLM trở nên khả thi.

Cụ thể, chúng tôi thực hiện một chiến lược duyệt bao gồm các hoạt động top-down và step-back. Top-down đề cập đến việc bắt đầu từ nút gốc của cây DOM hiện tại, dần dần tinh chỉnh xuống nút cụ thể chứa thông tin mục tiêu. Step-back đề cập đến việc đánh giá lại và điều chỉnh tiêu chí lựa chọn bằng cách di chuyển lên cây DOM để chọn một nút đáng tin cậy và áp dụng rộng rãi hơn làm nền tảng cho việc nhắm mục tiêu XPath nhất quán và chính xác hơn. Ở mỗi bước, chúng tôi đầu tiên sử dụng một hoạt động top-down, hướng dẫn LLM trực tiếp

⁵https://en.wikipedia.org/wiki/XPath

viết ra XPath dẫn đến nút chứa thông tin mục tiêu và để đánh giá xem giá trị được trích xuất với XPath có nhất quán với giá trị mà nó nhận ra không. Nếu thực thi thất bại, thì áp dụng một hoạt động step-back để rút lui từ nút thất bại, đảm bảo trang web bao gồm thông tin mục tiêu, được điều khiển bởi LLM. Chi tiết được hiển thị trong Thuật toán 1.

4.3 Tổng hợp
Mặc dù chúng tôi có được một chuỗi hành động có thể thực thi trong quá trình tạo ra tiến bộ, vẫn có sự khác biệt trong vị trí cụ thể của thông tin mục tiêu và cấu trúc giữa các trang web khác nhau. Chuỗi hành động có thể thu thập XPath với các đặc điểm cụ thể trong một HTML đơn lẻ và mất khả năng tổng quát. Để nâng cao khả năng tái sử dụng của chuỗi hành động, chúng tôi đề xuất một giai đoạn tổng hợp.

Cụ thể, chúng tôi chọn ngẫu nhiên ns trang web từ case làm các trang web hạt giống. Sau đó, chúng tôi tạo ra một chuỗi hành động cho mỗi trang web. Tiếp theo, chúng tôi thực thi nhiều chuỗi hành động khác nhau để trích xuất thông tin từ các trang web hạt giống, tương ứng. Chúng tôi thu thập tất cả các chuỗi hành động và kết quả tương ứng của chúng và sau đó chọn một chuỗi có thể trích xuất tất cả thông tin mục tiêu trong các trang web làm chuỗi hành động cuối cùng.

5 Thí nghiệm
Với ý định đưa AUTOSCRAPER vào sử dụng thực tế, chúng tôi điều tra các câu hỏi nghiên cứu sau: 1) AUTOSCRAPER có thể vượt trội so với các phương pháp tạo scraper hiện đại nhất không? 2) Khung AUTOSCRAPER cải thiện hiệu suất của tác vụ tạo scraper như thế nào? 3) AUTOSCRAPER có đáp ứng các yêu cầu cho các tác vụ web scraping, cụ thể là chính xác và hiệu quả không?

5.1 Thiết lập Thí nghiệm & Chỉ số Đánh giá
Chúng tôi tiến hành thí nghiệm trên 8 LLM bao gồm các LLM closed-source: GPT-3.5-Turbo (OpenAI, 2022), Gemini Pro (Team et al., 2023), GPT-4-o-mini (OpenAI, 2024) và GPT-4-Turbo (OpenAI, 2023) cũng như các LLM open-source: Phi-3-medium (Abdin et al., 2024), CodeLlama-34B (Rozière et al., 2024), Mixtral 8×7B (Jiang et al., 2024) và Deepseek-Coder-33B (Guo et al., 2024). Hơn nữa, chúng tôi áp dụng các tác nhân web dựa trên LLM-prompt khác nhau làm baseline của chúng tôi, bao gồm COT (Wei et al., 2023) và Reflexion (Shinn

--- TRANG 6 ---
[Bảng 2 được dịch sang tiếng Việt]

Bộ dữ liệu SWDE EXTENDED SWDE DS1
Mô hình Phương pháp ĐÁNH GIÁ THỰC THI ĐÁNH GIÁ IE ĐÁNH GIÁ EXEC ĐÁNH GIÁ IE ĐÁNH GIÁ EXEC ĐÁNH GIÁ IE
Đúng(↑) Prec Reca Unex.(↓) Over. Khác Prec Reca F1 Đúng Unex. F1 Đúng Unex. F1

LLM Closed-source
GPT-3.5-Turbo COT 36.75 8.83 6.71 43.46 0.71 3.53 89.45 50.43 47.99 35.19 55.40 41.28 32.65 53.06 41.16
Reflexion 46.29 11.66 2.83 37.10 0.71 1.41 94.67 55.85 55.10 43.90 49.13 48.66 36.73 51.02 43.75
AUTOSCRAPER 54.84 11.83 8.96 19.35 1.08 3.94 85.85 73.34 69.20 46.34 34.84 57.74 48.98 44.90 52.38

Gemini Pro COT 29.69 10.94 7.50 47.19 1.25 3.44 81.21 45.22 41.81 34.49 49.13 42.40 17.72 75.95 22.10
Reflexion 33.12 6.56 4.06 52.50 0.63 3.12 87.45 42.75 40.88 34.15 51.57 41.66 20.25 65.82 27.66
AUTOSCRAPER 42.81 11.87 4.69 34.38 1.25 5.00 85.70 57.54 54.91 35.89 42.86 47.80 43.04 34.18 56.92

GPT-4-o-mini COT 54.66 13.50 6.43 20.26 0.96 4.18 89.74 72.87 69.92 45.79 38.72 56.32 46.99 42.17 53.77
Reflexion 53.70 15.11 3.22 22.83 0.96 4.18 92.14 70.20 69.15 39.06 47.47 48.66 38.55 45.78 43.86
AUTOSCRAPER 62.06 14.15 3.86 15.11 0.96 3.86 91.76 78.10 76.97 56.23 27.27 67.56 53.01 34.94 60.10

GPT-4-Turbo COT 61.88 12.50 7.19 14.37 0.94 3.12 87.75 79.90 76.95 56.10 29.27 65.08 50.60 30.12 64.73
Reflexion 67.50 13.75 4.37 10.94 0.94 2.50 93.28 82.76 82.40 64.81 19.51 75.85 50.60 33.73 63.50
AUTOSCRAPER 71.56 14.06 5.31 4.06 0.63 4.37 92.49 89.13 88.69 64.11 15.33 76.21 57.83 16.87 75.52

LLM Open-source
Phi-3-medium COT 12.50 2.81 3.12 80.00 0.00 1.56 94.38 18.10 17.21 11.78 79.46 16.28 9.64 85.54 12.28
Reflexion 12.19 6.56 1.87 77.81 0.00 1.56 92.45 18.21 17.31 12.66 82.28 15.42 7.23 90.36 8.89
AUTOSCRAPER 24.06 12.50 7.50 52.19 0.31 3.44 85.07 38.59 34.93 21.15 64.42 30.29 22.89 69.88 26.60

CodeLlama COT 17.98 3.75 2.25 74.53 0.00 1.50 79.75 21.98 21.36 9.01 85.84 11.21 2.70 89.19 9.19
Reflexion 18.08 4.80 2.95 73.06 0.00 1.11 78.96 23.26 22.44 13.73 80.26 16.01 8.82 85.29 12.69
AUTOSCRAPER 23.99 8.12 1.48 64.94 0.00 1.48 78.59 28.70 28.41 11.16 85.84 12.52 13.51 81.08 17.39

Mixtral 8×7B COT 28.75 8.13 4.37 57.81 0.31 0.63 89.79 38.23 37.26 32.40 57.14 38.30 17.72 74.68 22.01
Reflexion 36.25 6.88 3.12 51.25 0.00 2.50 89.35 44.57 43.60 29.62 62.02 33.64 22.78 69.62 28.20
AUTOSCRAPER 46.88 10.62 7.19 30.31 0.63 4.37 87.32 62.71 59.75 40.77 38.33 52.50 36.71 43.04 48.23

Deepseek-coder COT 36.56 10.94 5.63 42.50 0.63 3.75 86.05 48.78 47.05 38.33 47.74 44.80 25.30 60.24 35.65
Reflexion 37.19 11.25 4.06 44.69 1.25 1.56 86.41 48.28 47.08 36.24 51.92 43.64 22.89 65.06 32.04
AUTOSCRAPER 38.75 11.25 5.31 39.69 0.63 4.37 84.91 52.11 49.68 37.63 50.52 44.33 39.76 42.17 50.28

Bảng 2: Đánh giá thực thi và đánh giá IE của LLM với ba khung trong bộ dữ liệu SWDE, EXTENDED SWDE và DS1. Điểm Đúng, Không thể thực thi, precision, recall và F1 tốt nhất được đánh dấu đậm.

et al., 2023) và AUTOSCRAPER cho chúng. So sánh giữa chúng được thảo luận trong Phụ lục B.1. Do bối cảnh độ dài hạn chế của LLM, tất cả các thí nghiệm được tiến hành dưới thiết lập zero-shot.

Chúng tôi kiểm tra chúng trên ba bộ dữ liệu: SWDE (Hao et al., 2011), EXTEND SWDE (Lockard et al., 2019) và DS1 (Omari et al., 2017). Kết quả thí nghiệm chi tiết của hai bộ dữ liệu cuối có thể được tìm thấy trong Phụ lục A.1 và A.2. Chúng tôi đặt kích thước của các trang web hạt giống ns = 3 cho SWDE và EXTEND SWDE, ns = 1 cho DS1 và số lần thử lại tối đa dmax = 5.

Ngoài các chỉ số đánh giá thực thi được mô tả trong Phần 3.3, chúng tôi cũng sử dụng các chỉ số đánh giá truyền thống để đánh giá chất lượng của các chuỗi hành động khác nhau một cách toàn diện hơn. Cụ thể, chúng tôi áp dụng precision (P.), recall (R.) và macro-f1 (F1), được tính như trung bình của các chỉ số tương ứng cho mỗi case. Kết quả thí nghiệm chi tiết trên hai bộ dữ liệu cuối có thể được tìm thấy trong Bảng 16 và 17.

5.2 Kết quả Chính
Kết quả trong Bảng 2 cho thấy: 1) Với AUTOSCRAPER tạo ra chuỗi hành động, LLM có thể đạt được hiệu suất tốt hơn. So với baseline COT và Reflexion, phương pháp của chúng tôi thực hiện tỷ lệ đúng cao hơn và tỷ lệ không thể thực thi thấp hơn. Ngoài ra, cần lưu ý rằng Mixtral 8×7B + AUTOSCRAPER có thể vượt trội so với GPT-3.5-Turbo + Reflexion, cho thấy sự ưu việt của AUTOSCRAPER trong việc tạo ra các chuỗi hành động có thể thực thi trong tác vụ tạo scraper. 2) Các mô hình với kích thước tham số nhỏ gặp khó khăn đáng kể trong việc hiểu và viết các đường dẫn có thể thực thi, vì vậy chúng có thể được coi là thách thức để áp dụng trong tác vụ này. Ngược lại, các mô hình quy mô lớn thể hiện khả năng ổn định hơn trong việc căn chỉnh hướng dẫn, hiểu cấu trúc web và phản chiếu về kết quả thực thi. 3) Các chỉ số đánh giá IE truyền thống không thể mô tả tốt tỷ lệ thành công của tác vụ chúng tôi. Đặc biệt đối với chỉ số precision, nó không thể tiết lộ khoảng cách hiệu suất giữa các phương pháp khác nhau với các mô hình khác nhau. Điều này là do các chỉ số trích xuất chỉ đánh giá các kết quả đã được trích xuất, bỏ qua rằng các trích xuất không thể thực thi hoặc rỗng cũng làm hại đáng kể đến khả năng thực thi.

5.3 Nghiên cứu Loại bỏ
Để chứng minh thêm tính hiệu quả của mỗi thành phần của AUTOSCRAPER, chúng tôi thực hiện một nghiên cứu loại bỏ. Kết quả được hiển thị trong Bảng 3. Nó cho thấy: 1) AUTOSCRAPER không có một

--- TRANG 7 ---
Mô hình Phương pháp ĐÁNH GIÁ EXEC ĐÁNH GIÁ IE
Đúng(↑) Unex.(↓) F1

GPT-3.5-Turbo COT 36.75 43.46 47.99
-synthesis 27.56 57.24 34.44
Reflexion 46.29 37.10 55.10
-synthesis 28.62 59.01 35.01
AUTOSCRAPER 54.84 19.35 69.20
-synthesis 44.52 29.33 58.44

Gemini Pro COT 29.69 47.19 41.81
-synthesis 27.56 57.24 33.09
Reflexion 33.12 52.50 40.88
-synthesis 28.62 59.01 37.60
AUTOSCRAPER 42.81 34.38 54.91
-synthesis 39.46 31.56 56.48

GPT-4-Turbo COT 61.88 14.37 76.95
-synthesis 46.88 30.00 61.20
Reflexion 67.50 10.94 82.40
-synthesis 56.87 25.31 69.78
AUTOSCRAPER 71.56 4.06 88.69
-synthesis 65.31 11.87 80.41

Bảng 3: Nghiên cứu loại bỏ trên AUTOSCRAPER. Chúng tôi báo cáo Đúng, Không thể thực thi từ đánh giá thực thi, và điểm F1 từ đánh giá IE trong bộ dữ liệu SWDE.

[THIS IS FIGURE: Graph showing performance of AUTOSCRAPER with different number of seed websites in SWDE dataset, with lines for GPT-4-Turbo and GPT-3.5-Turbo showing Correct and Unexecutable metrics]

Hình 3: Hiệu suất của AUTOSCRAPER với số lượng trang web hạt giống khác nhau trong bộ dữ liệu SWDE.

mô-đun thứ hai vẫn đánh bại hai phương pháp baseline khác giữa các LLM khác nhau. 2) Mô-đun thứ hai của AUTOSCRAPER, mô-đun tổng hợp, không chỉ cải thiện AUTOSCRAPER mà còn cải thiện hiệu suất của các phương pháp khác. Sử dụng nhiều trang web hơn để suy luận có thể làm cho scraper được tạo ra ổn định hơn và có khả năng tổng quát tốt hơn.

5.4 Trang web Hạt giống
Trong tất cả các thí nghiệm trước đây, chúng tôi cố định số lượng trang web hạt giống ns = 3, điều này chứng minh tính hiệu quả của mô-đun tổng hợp. Trong thí nghiệm này, chúng tôi cung cấp các số lượng trang web hạt giống khác nhau và kiểm tra hiệu suất của AUTOSCRAPER. Kết quả được hiển thị trong Hình 3.

Khi số lượng trang web hạt giống tăng lên, 

Mô hình Trích xuất Trực tiếp AUTOSCRAPER
GPT-3.5-Turbo 75.76 69.20
Gemini Pro 76.62 54.91
GPT-4-o-mini 79.93 76.97
GPT-4-Turbo 78.56 88.69
Phi-3-medium 71.73 34.93
Codellama 47.38 28.41
Mixtral 8×7B 73.45 59.75
Deepseek-coder 61.96 49.68

Bảng 4: So sánh trích xuất trực tiếp LLM với AUTOSCRAPER trên bộ dữ liệu SWDE.

tỷ lệ đúng tăng, trong khi tỷ lệ không thể thực thi giảm. Điều này cho thấy hiệu suất của AUTOSCRAPER vẫn có thể được cải thiện thêm bằng cách cung cấp nhiều trang web hạt giống hơn. Ngoài ra, cải thiện hiệu suất giảm khi số lượng tăng, điều này cho thấy có một giới hạn trên để cải thiện hiệu suất của AUTOSCRAPER bằng cách tăng số lượng trang web hạt giống.

6 Thảo luận
Trong phần này, chúng tôi sẽ thảo luận về các khía cạnh khác của AUTOSCRAPER, bao gồm so sánh của nó với các phương pháp trích xuất thông tin trang web hiện tại, phân tích hiệu quả của AUTOSCRAPER và các hạn chế của cách tiếp cận hiện tại.

6.1 So sánh với Trích xuất Trực tiếp LLM
Vì LLM có thể hiểu hướng dẫn của con người và văn bản trang web, một giải pháp trích xuất thông tin web tự nhiên bao gồm việc sử dụng prompt để hướng dẫn LLM trích xuất nội dung mục tiêu, mà chúng tôi gọi là trích xuất trực tiếp. Chúng tôi so sánh trích xuất trực tiếp với AUTOSCRAPER cả trong thiết lập zero-shot sử dụng mỗi LLM được đề cập ở trên.

Bảng 4 cho thấy trong thiết lập trích xuất trực tiếp, hiệu suất trích xuất của tất cả LLM ngoài GPT-4-Turbo đều vượt trội so với AUTOSCRAPER. Tuy nhiên, khi khả năng của LLM cải thiện, khoảng cách giữa hai thiết lập thu hẹp. Điều này cho thấy: 1. Trong khi các LLM như Phi-3-medium có thể hiểu nội dung trang web tốt (tức là, trích xuất chính xác nội dung mong đợi), chúng vẫn gặp khó khăn để hiểu cấu trúc trang web (tức là, tạo ra XPath sử dụng các tính năng như cây DOM). 2. AUTOSCRAPER, kết hợp với các LLM tốt nhất hiện tại, đã đạt được hiệu suất trích xuất vượt trội, và khung này dự kiến sẽ mang lại hiệu suất thậm chí tốt hơn và ổn định hơn khi LLM tiếp tục cải thiện.

--- TRANG 8 ---
Mô hình F1
Render-Full (Hao et al., 2011) 84.30
FreeDOM (Lin et al., 2020) 82.32
SimpDOM (Zhou et al., 2021) 83.06
MarkupLM BASE (Li et al., 2022) 84.31
WebFormer (Wang et al., 2022) 86.58
Reflexion + GPT-4-Turbo 82.40
AUTOSCRAPER + GPT-4-Turbo 88.69

Bảng 5: So sánh hiệu suất trích xuất (F1) của 5 mô hình baseline với phương pháp AUTOSCRAPER sử dụng GPT-4-Turbo trên bộ dữ liệu SWDE. Mỗi giá trị của mô hình có giám sát trong bảng được huấn luyện trên 1 trang web hạt giống.

6.2 So sánh với baseline có giám sát
Để chứng minh thêm rằng AUTOSCRAPER thích ứng với các tác vụ trích xuất thông tin web khác nhau, chúng tôi tiến hành so sánh với 5 mô hình baseline trong trích xuất thông tin web trong các tình huống học có giám sát: Render-Full (Hao et al., 2011) đề xuất một thuật toán heuristic phức tạp để tính toán khoảng cách trực quan giữa các nút giá trị được dự đoán và điều chỉnh các dự đoán. FreeDOM (Lin et al., 2020) và SimpDOM (Zhou et al., 2021) mã hóa các đặc điểm văn bản của nút cây DOM với LSTM, trong khi MarkupLM (Li et al., 2022) được pre-train trên HTML với thông tin văn bản và đánh dấu cùng nhau. WebFormer (Wang et al., 2022) tận dụng bố cục web để tính toán trọng số attention hiệu quả. Các mô hình này được huấn luyện trên các trang web trong một số trang web hạt giống và được kiểm tra trên các trang web khác.

Bảng 5 cho thấy kết quả. Mặc dù so sánh không công bằng vì phương pháp của chúng tôi trong thiết lập zero-shot, AUTOSCRAPER đánh bại tất cả chúng về điểm F1. Điều này cho thấy bằng cách thiết kế một khung phù hợp, LLM có thể vượt qua các phương pháp học có giám sát trong một số tác vụ trích xuất thông tin web.

6.3 Phân tích Hiệu quả
Giả sử số lượng trang web hạt giống là ns, số lượng trang web trên cùng một trang web là NW, thời gian để tạo ra một wrapper là Tg, thời gian tổng hợp là Ts, và thời gian để trích xuất thông tin từ một trang web với một wrapper là Te. Tổng thời gian để trích xuất tất cả thông tin từ tất cả các trang web với AUTOSCRAPER là

T1 = TG + TE = (nsTg + Ts) + NWTe (3)

Bên cạnh đó, thời gian để LLM trích xuất trực tiếp thông tin từ một trang web là Td, và tổng

Trang web Td nsTg+Ts Te NW
Auto 8.27s 238.4s 0.30s 30
Book 10.20s 176.4s 0.51s 18
Camera 6.59s 107.1s 0.31s 18
Job 7.42s 123.5s 0.21s 18
Movie 7.47s 133.2s 0.21s 19
Nbaplayer 8.32s 179.4s 0.45s 23
Restaurant 8.87s 160.8s 0.54s 20
University 14.26s 134.7s 0.32s 10

Bảng 6: Phân tích hiệu quả thời gian trên GPT-4-Turbo.

thời gian để trích xuất tất cả thông tin từ tất cả các trang web trực tiếp là

T2 = NWTd (4)

Trong một tình huống thế giới thực, có nhiều trang web từ cùng các trang web cần được trích xuất. Mặc dù việc tạo ra một wrapper mất nhiều thời gian hơn so với trích xuất trực tiếp từ một trang web đơn lẻ, hiệu quả trích xuất của các trang web tiếp theo sẽ được cải thiện đáng kể. Để khám phá có bao nhiêu trang web cần thiết để làm cho AUTOSCRAPER hiệu quả hơn trong IE web, chúng tôi tính toán ngưỡng của NW. Giả sử T1 ≤ T2, chúng tôi có

TG + TE = (nsTg + Ts) + NWTe ≤ NWTd (5)
NW ≥ (nsTg + Ts)/(Td - Te) (6)

Để xác minh lợi thế hiệu quả của AUTOSCRAPER trong các tình huống trích xuất thông tin web quy mô lớn, chúng tôi đã tiến hành các bài kiểm tra trên bộ dữ liệu SWDE. Cụ thể, chúng tôi chọn ngẫu nhiên một trang web trong mỗi 10 lĩnh vực. Chúng tôi lặp lại 3 lần trên AUTOSCRAPER và ghi lại thời gian trung bình để ước tính nsTg + Ts và Te. Đồng thời, chúng tôi ghi lại thời gian trung bình Td trên 10 trang web với LLM trích xuất trực tiếp. Chúng tôi tính toán ngưỡng của NW theo Phương trình 6 và hiển thị chúng trong Bảng 6. Có thể quan sát thấy rằng ngưỡng của số trang là 19.5 trung bình, thấp hơn đáng kể so với số trang web trung bình mỗi trang web trong bộ dữ liệu SWDE.

6.4 Phân tích Lỗi
Chúng tôi thực hiện phân tích bằng cách nhìn vào chuỗi hành động được ghi lại của AUTOSCRAPER với GPT-4-Turbo và xác định các chế độ thất bại phổ biến sau. Chúng tôi chủ yếu tập trung vào các case được phân loại là không thể thực thi, quá ước lượng và khác.

--- TRANG 9 ---
Không thể tổng quát hóa của các trang web Thông tin mục tiêu và cấu trúc trang web tương ứng thể hiện sự biến đổi trên các trang web khác nhau, dẫn đến thiếu khả năng tổng quát trong AUTOSCRAPER (tức là, không thể áp dụng cùng một quy tắc trên tất cả các trang web trong cùng một trang web). Ví dụ, đối với tác vụ "Vui lòng trích xuất tên của công ty cung cấp việc làm" trong trang web job-careerbuilder, hầu hết các trang web chứa tên công ty, nhưng có một trang web mà tên công ty là "Không có sẵn" trên một nút khác của cây DOM.

Bỏ lỡ trong đa giá trị Được trình bày với tác vụ tạo ra một scraper để trích xuất địa chỉ trong các trang web nhà hàng hoặc số điện thoại liên hệ từ các trang web đại học, thông tin mục tiêu nằm ở nhiều vị trí trong trang web, như thanh thông tin, tiêu đề, v.v. Mặc dù AUTOSCRAPER có khả năng tạo ra các chuỗi hành động để trích xuất các phần thông tin, việc tạo ra một chuỗi hành động toàn diện nắm bắt tất cả thông tin vẫn là một thách thức.

7 Kết luận
Trong bài báo này, chúng tôi giới thiệu tác vụ tạo scraper và mô hình kết hợp LLM và scraper để cải thiện khả năng tái sử dụng của khung dựa trên tác nhân ngôn ngữ hiện tại. Sau đó, chúng tôi đề xuất AUTOSCRAPER, một khung hai giai đoạn bao gồm mô-đun tạo ra tiến bộ và tổng hợp để tạo ra một chuỗi hành động ổn định và có thể thực thi hơn. Các thí nghiệm toàn diện của chúng tôi chứng minh rằng AUTOSCRAPER có thể vượt trội so với baseline hiện đại trong tác vụ tạo scraper.

Lời cảm ơn
Công trình này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62102095). Các tính toán trong nghiên cứu này được thực hiện bằng cách sử dụng nền tảng CFFF của Đại học Fudan. Các tác giả muốn bày tỏ lòng biết ơn chân thành đến Alibaba (China) Co., Ltd. và Alibaba Holding-Aicheng Technology-Enterprise Intelligence Business Unit vì sự hỗ trợ của họ.

Hạn chế
Chúng tôi giới thiệu một mô hình kết hợp LLM với scraper cho các tác vụ tạo web scraper và đề xuất AUTOSCRAPER để tạo ra một chuỗi hành động có thể thực thi với việc hiểu biết tiến bộ các tài liệu HTML. Mặc dù kết quả thí nghiệm cho thấy tính hiệu quả của khung của chúng tôi, vẫn có một số giới hạn đối với công trình của chúng tôi.

Đầu tiên, khung của chúng tôi bị hạn chế trong mô hình trong tác vụ trích xuất thông tin cho các trang web dọc. LLM với scraper cung cấp hiệu quả cao trong các tác vụ IE web thế giới mở, nhưng khó có thể chuyển đổi sang các môi trường web hiện tại như Mind2Web (Deng et al., 2023), WebArena (Zhou et al., 2023).

Thứ hai, khung của chúng tôi dựa vào hiệu suất của LLM backbone. Nâng cao khả năng hiểu HTML của LLM là một câu hỏi nghiên cứu rất có giá trị, bao gồm thu thập corpus và chiến lược huấn luyện. Chúng tôi sẽ nghiên cứu việc nâng cao hiểu biết HTML trong công trình tương lai.

Tuyên bố Đạo đức
Chúng tôi xin tuyên bố rằng tất cả các tác giả của bài báo này đều biết và tuân thủ Bộ luật Đạo đức ACL được cung cấp và tôn vinh quy tắc ứng xử.

Sử dụng Chú thích Con người Chú thích con người chỉ được sử dụng trong các giai đoạn đầu của nghiên cứu phương pháp để đánh giá tính khả thi của giải pháp được đề xuất. Tất cả các người chú thích đã đồng ý cho việc sử dụng dữ liệu của họ cho mục đích nghiên cứu. Chúng tôi đảm bảo an ninh của tất cả các người chú thích trong suốt quá trình chú thích, và họ được trả công công bằng theo tiêu chuẩn địa phương. Chú thích con người không được sử dụng trong quá trình đánh giá phương pháp của chúng tôi.

Rủi ro Các bộ dữ liệu được sử dụng trong bài báo đã được lấy từ các nguồn công cộng và được ẩn danh để bảo vệ chống lại bất kỳ thông tin có tính chất tấn công nào. Mặc dù chúng tôi đã thực hiện các biện pháp để làm như vậy, chúng tôi không thể đảm bảo rằng các bộ dữ liệu không chứa bất kỳ ngôn ngữ có hại xã hội hoặc độc hại nào.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được duy trì nguyên như trong bản gốc tiếng Anh]

--- TRANG 10 ---
[Tiếp tục danh sách tài liệu tham khảo như trong bản gốc]

--- TRANG 11 ---
[Tiếp tục danh sách tài liệu tham khảo như trong bản gốc]

--- TRANG 12 ---
A Thí nghiệm

A.1 Kết quả chính trên EXTENDED SWDE
Vì bộ dữ liệu EXTENDED SWDE tập trung vào tác vụ OpenIE (mối quan hệ cũng được mong đợi sẽ được trích xuất), chúng tôi đầu tiên ánh xạ các mối quan hệ vào một danh sách thuộc tính được định nghĩa trước và loại bỏ những cái bất thường. Cụ thể, chúng tôi đã tiến hành thí nghiệm với 294 thuộc tính từ 21 trang web được chọn từ bộ dữ liệu EXTENDED SWDE.

Bảng 7 cho thấy kết quả. Bằng cách so sánh Bảng 2, chúng tôi thấy rằng: 1) Dưới các thiết lập tác vụ trích xuất phức tạp (nhiều giá trị mục tiêu và mô tả vấn đề mơ hồ), các LLM closed-source thực hiện tốt hơn trong việc tạo ra các chuỗi hành động có thể thực thi so với các LLM open-source. 2) Có một số tác vụ với mô tả không rõ ràng, như "Hệ thống Lịch" và "Cơ sở vật chất và Chương trình Được cung cấp" trên các trang web đại học, ảnh hưởng đến hiệu suất tạo wrapper của tất cả các phương pháp.

A.2 Kết quả chính trên DS1
Do DS1 chỉ chứa 166 trang web được tạo thủ công, và cho mỗi trang web, chỉ có hai trang web, vì vậy chúng tôi lấy một trang web để suy luận và trang web kia để đánh giá. Đồng thời, do số lượng trang web hạt giống bằng một, chúng tôi kiểm tra ba phương pháp mà không áp dụng mô-đun tổng hợp được mô tả trong Phần 4.3.

Bảng 8 cho thấy kết quả trong bộ dữ liệu DS1. Trong số tất cả LLM với ba phương pháp, GPT-4-Turbo + AUTOSCRAPER đạt được hiệu suất tốt nhất, và AUTOSCRAPER đánh bại hai phương pháp khác trong tất cả LLM, điều này phù hợp với kết luận của chúng tôi.

A.3 Tạo ra với Nhãn Vàng
Để minh họa tốt hơn tính hiệu quả của khung của chúng tôi trong việc tạo ra các chuỗi hành động có thể thực thi, chúng tôi so sánh hiệu suất của COT, Reflexion và AUTOSCRAPER, trong khi trả lời hướng dẫn. Bằng cách cung cấp cùng các mục tiêu trích xuất, chúng tôi có thể phát hiện hiệu quả hiệu suất của các khung khác nhau trong việc tạo ra các chuỗi hành động.

Bảng 9 cho thấy kết quả thí nghiệm, từ đó chúng tôi có thể có các quan sát sau: 1) Khung hiểu biết tiến bộ được đề xuất của chúng tôi vẫn hiệu quả nâng cao hiệu suất của mô hình dưới thiết lập này; 2) LLM vẫn gặp khó khăn trong việc hiểu chính xác nội dung trang web với các ngôn ngữ đánh dấu bán cấu trúc, điều này minh họa khoảng cách hiệu suất giữa Bảng 2 và Bảng 9;

Thuật toán 1: Thuật toán cho hiểu biết tiến bộ
Dữ liệu: mã HTML gốc h0, hướng dẫn tác vụ I, số lần thử lại tối đa dmax
Kết quả: Chuỗi hành động có thể thực thi Aseq để trích xuất giá trị trong HTML

1 Khởi tạo lịch sử Aseq ← [], k = 0;
2 while True do
3   if k > dmax then break;
    // Top-down
4   value, xpath ← LLMg(hk, I);
5   result ← Parsertext(hk, xpath);
6   if result == value then break;
    // Step-back
7   repeat
8     xpath ← xpath + "/..";
9     hk+1 ← Parsernode(hk, xpath);
10  until h chứa value;
11  Append(Aseq, xpath);
12  k ← k + 1;
13 end
14 return Aseq

3) So với các LLM closed-source, ngay cả khi được cung cấp nhãn vàng, các LLM Open-source không thể đạt được cải thiện hiệu suất bền vững. Hiện tượng này chứng minh rằng nút cổ chai đối với các mô hình này không nằm ở việc hiểu nội dung trang web mà là ở việc hiểu cấu trúc phân cấp của trang web.

B Phân tích về AUTOSCRAPER

B.1 So sánh với COT & Reflexion
Hình 4 trực quan hơn cho thấy sự khác biệt cụ thể giữa các baseline khác nhau trong thí nghiệm. Sự khác biệt quan trọng nhất giữa AUTOSCRAPER và các phương pháp khác nằm ở việc có sử dụng cấu trúc phân cấp của các trang web để giúp LLM giảm độ khó của các cấu trúc web phức tạp hay không. COT chỉ thực thi một lượt trong khi các phương pháp khác thực thi nhiều lượt và có thể học từ việc thực thi thất bại của wrapper. So với phương pháp Reflexion, AUTOSCRAPER sử dụng các hoạt động top-down và step-back để cắt tỉa cây DOM trong quá trình tạo mỗi XPath, do đó giảm độ dài của trang web. Ngược lại, phương pháp Reflexion chỉ có thể phản chiếu và tái tạo sau khi tạo ra một XPath không thể thực thi, điều này không đơn giản hóa hiệu quả trang web.

--- TRANG 13 ---
[Tiếp tục các bảng và nội dung như trong bản gốc, được dịch sang tiếng Việt]

--- TRANG 14 ---
[Tiếp tục nội dung được dịch sang tiếng Việt]

--- TRANG 15 ---
[Tiếp tục nội dung được dịch sang tiếng Việt]

--- TRANG 16 ---
[Tiếp tục nội dung được dịch sang tiếng Việt]

--- TRANG 17 ---
[Tiếp tục nội dung được dịch sang tiếng Việt]

--- TRANG 18 ---
[Tiếp tục nội dung được dịch sang tiếng Việt]

--- TRANG 19 ---
[Tiếp tục nội dung được dịch sang tiếng Việt]

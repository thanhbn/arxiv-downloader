# 2304.13649.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/rag/2304.13649.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1468531 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================


--- TRANG 1 ---
Má»™t Khung Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a Äá»‘i Xá»©ng KÃ©p cho
Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c ChuyÃªn SÃ¢u
Alireza Salemi
Äáº¡i há»c Massachusetts Amherst
Hoa Ká»³
asalemi@cs.umass.eduJuan Altmayer Pizzorno
Äáº¡i há»c Massachusetts Amherst
Hoa Ká»³
jpizzorno@cs.umass.eduHamed Zamani
Äáº¡i há»c Massachusetts Amherst
Hoa Ká»³
zamani@cs.umass.edu
TÃ“M Táº®T
Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c (KI-VQA) Ä‘á» cáº­p Ä‘áº¿n viá»‡c tráº£ lá»i má»™t cÃ¢u há»i vá» má»™t hÃ¬nh áº£nh mÃ  cÃ¢u tráº£ lá»i khÃ´ng náº±m trong hÃ¬nh áº£nh. BÃ i bÃ¡o nÃ y trÃ¬nh bÃ y má»™t pipeline má»›i cho cÃ¡c tÃ¡c vá»¥ KI-VQA, bao gá»“m má»™t bá»™ truy xuáº¥t vÃ  má»™t bá»™ Ä‘á»c. Äáº§u tiÃªn, chÃºng tÃ´i giá»›i thiá»‡u DEDR, má»™t khung truy xuáº¥t máº­t Ä‘á»™ mÃ£ hÃ³a Ä‘á»‘i xá»©ng kÃ©p trong Ä‘Ã³ cÃ¡c tÃ i liá»‡u vÃ  truy váº¥n Ä‘Æ°á»£c mÃ£ hÃ³a vÃ o má»™t khÃ´ng gian nhÃºng chung sá»­ dá»¥ng cÃ¡c bá»™ mÃ£ hÃ³a Ä‘Æ¡n phÆ°Æ¡ng thá»©c (vÄƒn báº£n) vÃ  Ä‘a phÆ°Æ¡ng thá»©c. ChÃºng tÃ´i giá»›i thiá»‡u má»™t phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i Ä‘á»ƒ thu háº¹p khoáº£ng cÃ¡ch giá»¯a cÃ¡c khÃ´ng gian biá»ƒu diá»…n trong hai bá»™ mÃ£ hÃ³a nÃ y. ÄÃ¡nh giÃ¡ toÃ n diá»‡n trÃªn hai bá»™ dá»¯ liá»‡u KI-VQA Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p, tá»©c lÃ  OK-VQA vÃ  FVQA, cho tháº¥y DEDR vÆ°á»£t trá»™i hÆ¡n cÃ¡c baseline tiÃªn tiáº¿n láº§n lÆ°á»£t 11,6% vÃ  30,9% trÃªn OK-VQA vÃ  FVQA. Sá»­ dá»¥ng cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c truy xuáº¥t bá»Ÿi DEDR, chÃºng tÃ´i tiáº¿p tá»¥c giá»›i thiá»‡u MM-FiD, má»™t mÃ´ hÃ¬nh há»£p nháº¥t-trong-bá»™ giáº£i mÃ£ Ä‘a phÆ°Æ¡ng thá»©c encoder-decoder, Ä‘á»ƒ táº¡o ra cÃ¢u tráº£ lá»i vÄƒn báº£n cho cÃ¡c tÃ¡c vá»¥ KI-VQA. MM-FiD mÃ£ hÃ³a cÃ¢u há»i, hÃ¬nh áº£nh vÃ  má»—i Ä‘oáº¡n vÄƒn Ä‘Ã£ truy xuáº¥t riÃªng biá»‡t vÃ  sá»­ dá»¥ng táº¥t cáº£ cÃ¡c Ä‘oáº¡n vÄƒn cÃ¹ng nhau trong bá»™ giáº£i mÃ£ cá»§a nÃ³. So vá»›i cÃ¡c baseline cáº¡nh tranh trong tÃ i liá»‡u, phÆ°Æ¡ng phÃ¡p nÃ y dáº«n Ä‘áº¿n cáº£i thiá»‡n 5,5% vÃ  8,5% vá» Ä‘á»™ chÃ­nh xÃ¡c tráº£ lá»i cÃ¢u há»i láº§n lÆ°á»£t trÃªn OK-VQA vÃ  FVQA.

CCS CONCEPTS
â€¢Há»‡ thá»‘ng thÃ´ng tin â†’Truy xuáº¥t thÃ´ng tin ;Tráº£ lá»i cÃ¢u há»i ;Truy xuáº¥t Ä‘a phÆ°Æ¡ng tiá»‡n vÃ  Ä‘a phÆ°Æ¡ng thá»©c ;â€¢PhÆ°Æ¡ng phÃ¡p tÃ­nh toÃ¡n â†’Thá»‹ giÃ¡c mÃ¡y tÃ­nh .

Tá»ª KHÃ“A
Truy Xuáº¥t Máº­t Äá»™; ChÆ°ng Cáº¥t Kiáº¿n Thá»©c; Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh; Truy Xuáº¥t Äa PhÆ°Æ¡ng Thá»©c

Äá»‹nh dáº¡ng Tham chiáº¿u ACM:
Alireza Salemi, Juan Altmayer Pizzorno, vÃ  Hamed Zamani. 2023. Má»™t Khung Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a Äá»‘i Xá»©ng KÃ©p cho Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c ChuyÃªn SÃ¢u. Trong Ká»· yáº¿u Há»™i nghá»‹ Quá»‘c táº¿ ACM SIGIR láº§n thá»© 46 vá» NghiÃªn cá»©u vÃ  PhÃ¡t triá»ƒn trong Truy xuáº¥t ThÃ´ng tin (SIGIR '23), 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan. ACM, New York, NY, USA, 11 trang.
https://doi.org/10.1145/3539618.3591629

ÄÆ°á»£c phÃ©p táº¡o báº£n sao ká»¹ thuáº­t sá»‘ hoáº·c báº±ng giáº¥y toÃ n bá»™ hoáº·c má»™t pháº§n cÃ´ng trÃ¬nh nÃ y cho má»¥c Ä‘Ã­ch cÃ¡ nhÃ¢n hoáº·c lá»›p há»c miá»…n phÃ­ vá»›i Ä‘iá»u kiá»‡n cÃ¡c báº£n sao khÃ´ng Ä‘Æ°á»£c táº¡o hoáº·c phÃ¢n phá»‘i Ä‘á»ƒ kiáº¿m lá»£i nhuáº­n hoáº·c lá»£i tháº¿ thÆ°Æ¡ng máº¡i vÃ  cÃ¡c báº£n sao pháº£i ghi rÃµ thÃ´ng bÃ¡o nÃ y vÃ  trÃ­ch dáº«n Ä‘áº§y Ä‘á»§ á»Ÿ trang Ä‘áº§u. Báº£n quyá»n Ä‘á»‘i vá»›i cÃ¡c thÃ nh pháº§n cá»§a cÃ´ng trÃ¬nh nÃ y thuá»™c sá»Ÿ há»¯u cá»§a nhá»¯ng ngÆ°á»i khÃ¡c ngoÃ i (cÃ¡c) tÃ¡c giáº£ pháº£i Ä‘Æ°á»£c tÃ´n trá»ng. ÄÆ°á»£c phÃ©p trÃ­ch dáº«n vá»›i tÃ­n dá»¥ng. Äá»ƒ sao chÃ©p theo cÃ¡ch khÃ¡c, hoáº·c tÃ¡i xuáº¥t báº£n, Ä‘á»ƒ Ä‘Äƒng trÃªn mÃ¡y chá»§ hoáº·c Ä‘á»ƒ phÃ¢n phá»‘i láº¡i cho danh sÃ¡ch, cáº§n cÃ³ sá»± cho phÃ©p cá»¥ thá»ƒ trÆ°á»›c vÃ /hoáº·c phÃ­. YÃªu cáº§u quyá»n tá»« permissions@acm.org.
SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan.
Â©2023 Báº£n quyá»n thuá»™c vá» chá»§ sá»Ÿ há»¯u/tÃ¡c giáº£. Quyá»n xuáº¥t báº£n Ä‘Æ°á»£c cáº¥p phÃ©p cho ACM.
ACM ISBN 978-1-4503-9408-6/23/07.
https://doi.org/10.1145/3539618.3591629

HÃ¬nh 1: Má»™t vÃ­ dá»¥ cÃ¢u há»i KI-VQA. Tráº£ lá»i nhá»¯ng cÃ¢u há»i nÃ y Ä‘Ã²i há»i kiáº¿n thá»©c bÃªn ngoÃ i.
HÃ¬nh áº£nh Â©zrim, https://www.flickr.com/photos/zrimshots/2788695458

1 GIá»šI THIá»†U
Tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh Ä‘Ã²i há»i kiáº¿n thá»©cÂ¹(KI-VQA) lÃ  má»™t biáº¿n thá»ƒ cá»§a cÃ¡c tÃ¡c vá»¥ tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh mÃ  cÃ¡c cÃ¢u há»i khÃ´ng thá»ƒ Ä‘Æ°á»£c tráº£ lá»i chá»‰ báº±ng hÃ¬nh áº£nh. Do Ä‘Ã³, viá»‡c truy cáº­p cÃ¡c nguá»“n kiáº¿n thá»©c bÃªn ngoÃ i lÃ  cáº§n thiáº¿t Ä‘á»ƒ tráº£ lá»i nhá»¯ng cÃ¢u há»i nÃ y. KI-VQA cÃ³ má»™t sá»‘ lÆ°á»£ng lá»›n cÃ¡c á»©ng dá»¥ng thá»±c táº¿. HÃ£y tÆ°á»Ÿng tÆ°á»£ng khÃ¡ch hÃ ng cá»§a cÃ¡c trang web thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ chá»¥p áº£nh má»™t sáº£n pháº©m hoáº·c má»™t pháº§n cá»§a sáº£n pháº©m vÃ  Ä‘áº·t cÃ¢u há»i vá» nÃ³. Trong bá»‘i cáº£nh giÃ¡o dá»¥c, sinh viÃªn cÃ³ thá»ƒ Ä‘áº·t cÃ¢u há»i vá» má»™t hÃ¬nh áº£nh trong sÃ¡ch giÃ¡o khoa cá»§a há». NgÆ°á»i dÃ¹ng cÃ³ thá»ƒ chá»¥p áº£nh má»™t biá»ƒn bÃ¡o hÃ¬nh áº£nh hoáº·c má»™t tÃ¡c pháº©m nghá»‡ thuáº­t vÃ  Ä‘áº·t cÃ¢u há»i vá» Ã½ nghÄ©a hoáº·c lá»‹ch sá»­ cá»§a nÃ³. ÄÃ¢y chá»‰ lÃ  má»™t vÃ i vÃ­ dá»¥ vá» cÃ¡c á»©ng dá»¥ng KI-VQA. HÃ¬nh 1 cho tháº¥y má»™t vÃ­ dá»¥ vá» cÃ¡c tÃ¡c vá»¥ KI-VQA: hÃ¬nh áº£nh Ä‘á»§ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh "Ä‘á»™ng váº­t" lÃ  hÆ°Æ¡u cao cá»•, vÃ  cÃ³ thá»ƒ cáº£ phÃ¢n loÃ i, nhÆ°ng khÃ´ng Ä‘á»§ Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i chÃºng cao Ä‘áº¿n má»©c nÃ o.

Pháº§n lá»›n cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y vá» KI-VQA, nhÆ° [12,14,37,50,57], giáº£ Ä‘á»‹nh ráº±ng kiáº¿n thá»©c bÃªn ngoÃ i cÃ³ thá»ƒ Ä‘Æ°á»£c láº¥y tá»« má»™t cÆ¡ sá»Ÿ kiáº¿n thá»©c cÃ³ cáº¥u trÃºc. Tuy nhiÃªn, má»™t cÆ¡ sá»Ÿ kiáº¿n thá»©c cháº¥t lÆ°á»£ng cao vÃ  Ä‘áº§y Ä‘á»§ cÃ³ thá»ƒ khÃ´ng cÃ³ sáºµn cho má»™t sá»‘ lÄ©nh vá»±c [1]. BÃªn cáº¡nh Ä‘Ã³, viá»‡c duy trÃ¬ cÃ¡c cÆ¡ sá»Ÿ kiáº¿n thá»©c vá»›i thÃ´ng tin cáº­p nháº­t lÃ  thÃ¡ch thá»©c [54]. Äá»ƒ ngÄƒn cháº·n nhá»¯ng váº¥n Ä‘á» nÃ y, theo Qu et al. [40], chÃºng tÃ´i cÃ³ má»™t phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n thay tháº¿ cho KI-VQA: sá»­ dá»¥ng má»™t kho vÄƒn báº£n lá»›n lÃ m nguá»“n kiáº¿n thá»©c bÃªn ngoÃ i. Trong thiáº¿t láº­p nÃ y, má»™t pipeline hai giai Ä‘oáº¡n cho cÃ¡c há»‡ thá»‘ng KI-VQA lÃ  Ä‘áº§u tiÃªn truy xuáº¥t má»™t danh sÃ¡ch cÃ¡c Ä‘oáº¡n vÄƒn cho má»™t cáº·p cÃ¢u há»i-hÃ¬nh áº£nh Ä‘Ã£ cho vÃ  sau Ä‘Ã³ xá»­ lÃ½ cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Ã£ truy xuáº¥t Ä‘á»ƒ táº¡o ra má»™t cÃ¢u tráº£ lá»i.Â² Pipeline nÃ y Ä‘Æ°á»£c mÃ´ táº£ trong HÃ¬nh 2.

Hiá»‡u suáº¥t hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ trong cÃ¡c tÃ¡c vá»¥ truy xuáº¥t thÃ´ng tin khÃ¡c nhau [23,62,63] vÃ  tÃ­nh linh hoáº¡t má»Ÿ rá»™ng cá»§a chÃºng cho Ä‘áº§u vÃ o Ä‘a phÆ°Æ¡ng thá»©cÂ³ Ä‘Ã£ thÃºc Ä‘áº©y chÃºng tÃ´i táº­p trung vÃ o truy xuáº¥t máº­t Ä‘á»™ Ä‘á»ƒ thá»±c hiá»‡n giai Ä‘oáº¡n Ä‘áº§u tiÃªn cá»§a pipeline KI-VQA (tá»©c lÃ  truy xuáº¥t Ä‘oáº¡n vÄƒn). Má»™t thuá»™c tÃ­nh cá»§a tÃ¡c vá»¥ truy xuáº¥t nÃ y lÃ  nÃ³ xá»­ lÃ½ cÃ¡c phÆ°Æ¡ng thá»©c Ä‘áº§u vÃ o báº¥t Ä‘á»‘i xá»©ng: nhu cáº§u thÃ´ng tin cá»§a ngÆ°á»i dÃ¹ng lÃ  Ä‘a phÆ°Æ¡ng thá»©c (cáº·p cÃ¢u há»i-hÃ¬nh áº£nh) trong khi cÃ¡c má»¥c thÃ´ng tin (Ä‘oáº¡n vÄƒn) lÃ  Ä‘Æ¡n phÆ°Æ¡ng thá»©c. Káº¿t quáº£ cá»§a thuá»™c tÃ­nh nÃ y, Qu et al. [40] gáº§n Ä‘Ã¢y Ä‘Ã£ chá»‰ ra ráº±ng má»™t mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ KI-VQA sá»­ dá»¥ng má»™t bá»™ mÃ£ hÃ³a Ä‘a phÆ°Æ¡ng thá»©c Ä‘á»ƒ biá»ƒu diá»…n cáº·p cÃ¢u há»i-hÃ¬nh áº£nh vÃ  má»™t bá»™ mÃ£ hÃ³a vÄƒn báº£n Ä‘á»ƒ biá»ƒu diá»…n cÃ¡c Ä‘oáº¡n vÄƒn trong bá»™ sÆ°u táº­p dáº«n Ä‘áº¿n hiá»‡u suáº¥t truy xuáº¥t Ä‘oáº¡n vÄƒn tiÃªn tiáº¿n. ChÃºng tÃ´i láº­p luáº­n ráº±ng viá»‡c sá»­ dá»¥ng kiáº¿n trÃºc bi-encoder báº¥t Ä‘á»‘i xá»©ng nhÆ° váº­y lÃ  khÃ´ng tá»‘i Æ°u, vÃ¬ cÃ¡c bá»™ mÃ£ hÃ³a táº¡o ra Ä‘áº§u ra trong cÃ¡c khÃ´ng gian ngá»¯ nghÄ©a khÃ¡c nhau vÃ  viá»‡c tinh chá»‰nh cÃ¡c bá»™ mÃ£ hÃ³a khÃ´ng thá»ƒ luÃ´n Ä‘Ã³ng khoáº£ng cÃ¡ch nÃ y. ChÃºng tÃ´i Ä‘áº§u tiÃªn nghiÃªn cá»©u hai phÆ°Æ¡ng Ã¡n thay tháº¿ Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ Ä‘á»‘i xá»©ng:â´(1) táº¡o ra má»™t biá»ƒu diá»…n vÄƒn báº£n cá»§a hÃ¬nh áº£nh vÃ  sá»­ dá»¥ng kiáº¿n trÃºc bi-encoder Ä‘Æ¡n phÆ°Æ¡ng thá»©c Ä‘á»‘i xá»©ng cho truy xuáº¥t máº­t Ä‘á»™, vÃ  (2) chuyá»ƒn Ä‘á»•i cÃ¡c Ä‘oáº¡n vÄƒn thÃ nh Ä‘á»‹nh dáº¡ng Ä‘áº§u vÃ o Ä‘a phÆ°Æ¡ng thá»©c vÃ  sá»­ dá»¥ng kiáº¿n trÃºc bi-encoder Ä‘a phÆ°Æ¡ng thá»©c Ä‘á»‘i xá»©ng. ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng cáº£ hai phÆ°Æ¡ng Ã¡n thay tháº¿ Ä‘á»u gáº·p pháº£i máº¥t mÃ¡t thÃ´ng tin, nhÆ°ng cÅ©ng cho tháº¥y chÃºng táº¡o ra cÃ¡c biá»ƒu diá»…n bá»• sung. Quan sÃ¡t nÃ y thÃºc Ä‘áº©y chÃºng tÃ´i khÃ´ng chá»‰ káº¿t há»£p hai mÃ£ hÃ³a nÃ y, mÃ  cÃ²n chuyá»ƒn giao kiáº¿n thá»©c giá»¯a chÃºng. Chi tiáº¿t hÆ¡n, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i Ä‘á»ƒ chuyá»ƒn giao kiáº¿n thá»©c giá»¯a hai mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ Ä‘á»‘i xá»©ng thay tháº¿ nÃ y.

PhÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a Ä‘á»‘i xá»©ng kÃ©p Ä‘Æ°á»£c Ä‘á» xuáº¥t dáº«n Ä‘áº¿n cáº£i thiá»‡n MRR 11,6% vÃ  30,9% so vá»›i baseline tiÃªn tiáº¿n láº§n lÆ°á»£t trÃªn cÃ¡c táº­p thá»­ nghiá»‡m OK-VQA [38] vÃ  FVQA [56].

Äá»‘i vá»›i giai Ä‘oáº¡n thá»© hai cá»§a pipeline, khÃ´ng giá»‘ng nhÆ° nhiá»u cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y vá» phÃ¡t hiá»‡n khoáº£ng tráº£ lá»i cho KI-VQA [12,14,37,50,57] (tá»©c lÃ  trÃ­ch xuáº¥t cÃ¢u tráº£ lá»i tá»« cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Ã£ truy xuáº¥t), chÃºng tÃ´i táº­p trung vÃ o viá»‡c táº¡o ra cÃ¢u tráº£ lá»i tá»± Ä‘á»™ng há»“i quy Ä‘Æ°á»£c tÄƒng cÆ°á»ng báº±ng truy xuáº¥t. ChÃºng tÃ´i Ä‘á» xuáº¥t MM-FiD, má»™t pháº§n má»Ÿ rá»™ng Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ cá»§a kiáº¿n trÃºc Fusion-in-Decoder (FiD) [20] cho Ä‘áº§u vÃ o Ä‘a phÆ°Æ¡ng thá»©c. FiD lÃ  má»™t mÃ´ hÃ¬nh táº¡o vÄƒn báº£n Ä‘Æ°á»£c tÄƒng cÆ°á»ng báº±ng truy xuáº¥t Ä‘Ã£ gáº§n Ä‘Ã¢y cho tháº¥y hiá»‡u suáº¥t hiá»‡u quáº£ trong cÃ¡c tÃ¡c vá»¥ tráº£ lá»i cÃ¢u há»i [20]. MM-FiD sá»­ dá»¥ng má»™t bá»™ mÃ£ hÃ³a Ä‘a phÆ°Æ¡ng thá»©c Ä‘á»ƒ biá»ƒu diá»…n cÃ¢u há»i, hÃ¬nh áº£nh vÃ  cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Ã£ truy xuáº¥t vÃ  sá»­ dá»¥ng má»™t bá»™ giáº£i mÃ£ Ä‘Æ¡n phÆ°Æ¡ng thá»©c táº¡o ra cÃ¢u tráº£ lá»i vÃ  Ä‘Æ°á»£c huáº¥n luyá»‡n báº±ng má»¥c tiÃªu kháº£ nÄƒng tÆ°Æ¡ng tá»± tá»‘i Ä‘a. CÃ¡c thÃ­ nghiá»‡m toÃ n diá»‡n trÃªn cáº£ hai bá»™ dá»¯ liá»‡u OK-VQA vÃ  FVQA chá»©ng minh ráº±ng MM-FiD vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p thay tháº¿ cho viá»‡c táº¡o ra cÃ¢u tráº£ lá»i. NÃ³ cÅ©ng hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n so vá»›i cÃ¡c baseline phÃ¡t hiá»‡n khoáº£ng tráº£ lá»i. Chi tiáº¿t hÆ¡n, pipeline end-to-end cá»§a chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n 5,5% vÃ  8,5% so vá»›i cÃ¡c baseline láº§n lÆ°á»£t trÃªn cÃ¡c tÃ¡c vá»¥ tráº£ lá»i cÃ¢u há»i OK-VQA vÃ  FVQA. ChÃºng tÃ´i má»Ÿ nguá»“n mÃ£ cá»§a chÃºng tÃ´i vÃ  phÃ¡t hÃ nh cÃ¡c tham sá»‘ mÃ´ hÃ¬nh Ä‘Ã£ há»c Ä‘á»ƒ phá»¥c vá»¥ má»¥c Ä‘Ã­ch nghiÃªn cá»©uâµ.

2 CÃ”NG TRÃŒNH LIÃŠN QUAN
Truy Xuáº¥t Máº­t Äá»™ (Äa PhÆ°Æ¡ng Thá»©c). Viá»‡c sá»­ dá»¥ng cÃ¡c vectÆ¡ máº­t Ä‘á»™ Ä‘á»ƒ truy xuáº¥t cÃ¡c tÃ i liá»‡u vÄƒn báº£n liÃªn quan Ä‘áº¿n má»™t truy váº¥n vÄƒn báº£n Ä‘Ã£ Ä‘Æ°á»£c nghiÃªn cá»©u tá»« khi xuáº¥t hiá»‡n PhÃ¢n tÃ­ch Ngá»¯ nghÄ©a Tiá»m áº©n [7]. Tuy nhiÃªn, hiá»‡u suáº¥t cá»§a cÃ¡c bá»™ truy xuáº¥t máº­t Ä‘á»™ váº«n kÃ©m hÆ¡n so vá»›i cÃ¡c bá»™ truy xuáº¥t thÆ°a thá»›t nhÆ° BM25 cho Ä‘áº¿n khi Karpukhin et al. [23] ra Ä‘á»i vá»›i Dense Passage Retriever (DPR), sá»­ dá»¥ng Ä‘áº§u ra token [CLS] bá»Ÿi BERT [8], má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. Trong khi nhiá»u bá»™ truy xuáº¥t máº­t Ä‘á»™ chá»‰ sá»­ dá»¥ng má»™t vectÆ¡ duy nháº¥t Ä‘á»ƒ biá»ƒu diá»…n truy váº¥n vÃ  tÃ i liá»‡u [23,41,59], viá»‡c sá»­ dá»¥ng nhiá»u vectÆ¡ cho má»—i tÃ i liá»‡u vÃ  truy váº¥n cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c nghiÃªn cá»©u [11, 19, 24, 36, 49].

Truy xuáº¥t máº­t Ä‘á»™ Ä‘a phÆ°Æ¡ng thá»©c gáº§n Ä‘Ã¢y Ä‘Ã£ Ä‘Æ°á»£c Ä‘iá»u tra dÆ°á»›i cÃ¡c hÃ¬nh thá»©c khÃ¡c nhau: (1) truy váº¥n Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  tÃ i liá»‡u Ä‘a phÆ°Æ¡ng thá»©c [15,34,52], (2) truy váº¥n Ä‘a phÆ°Æ¡ng thá»©c vÃ  tÃ i liá»‡u Ä‘Æ¡n phÆ°Æ¡ng thá»©c [40], (3) truy váº¥n Ä‘a phÆ°Æ¡ng thá»©c vÃ  tÃ i liá»‡u Ä‘a phÆ°Æ¡ng thá»©c [51], vÃ  (4) truy váº¥n Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  tÃ i liá»‡u Ä‘Æ¡n phÆ°Æ¡ng thá»©c vá»›i truy váº¥n vÃ  tÃ i liá»‡u tá»« cÃ¡c phÆ°Æ¡ng thá»©c khÃ¡c nhau, tá»©c lÃ  truy xuáº¥t chÃ©o phÆ°Æ¡ng thá»©c [21, 42].

Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i táº­p trung vÃ o trÆ°á»ng há»£p thá»© hai, nÆ¡i truy váº¥n lÃ  Ä‘a phÆ°Æ¡ng thá»©c trong khi cÃ¡c tÃ i liá»‡u chá»‰ chá»©a vÄƒn báº£n. Qu et al. [40] Ä‘Ã£ sá»­ dá»¥ng má»™t bi-encoder báº¥t Ä‘á»‘i xá»©ng vá»›i LXMERT [53], má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ thá»‹ giÃ¡c Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c dá»±a trÃªn BERT [8] Ä‘á»ƒ mÃ£ hÃ³a truy váº¥n, vÃ  chÃ­nh BERT Ä‘á»ƒ mÃ£ hÃ³a tÃ i liá»‡u. NhÆ° chÃºng tÃ´i chá»‰ ra, kiáº¿n trÃºc báº¥t Ä‘á»‘i xá»©ng nhÆ° váº­y lÃ  khÃ´ng tá»‘i Æ°u; viá»‡c sá»­ dá»¥ng cÃ¡c bá»™ mÃ£ hÃ³a khÃ¡c nhau táº¡o ra má»™t "khoáº£ng cÃ¡ch" ngá»¯ nghÄ©a trong khÃ´ng gian nhÃºng vÃ  viá»‡c tinh chá»‰nh khÃ´ng thá»ƒ dá»… dÃ ng vÆ°á»£t qua váº¥n Ä‘á» nÃ y. Thay vÃ o Ä‘Ã³, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t khung mÃ£ hÃ³a Ä‘á»‘i xá»©ng kÃ©p má»›i giáº£i quyáº¿t váº¥n Ä‘á» nÃ y.

ChÆ°ng Cáº¥t Kiáº¿n Thá»©c cho Truy Xuáº¥t Äoáº¡n VÄƒn Máº­t Äá»™. Do sá»‘ lÆ°á»£ng lá»›n cÃ¡c tham sá»‘ cÃ³ thá»ƒ há»c trong cÃ¡c bá»™ truy xuáº¥t Ä‘oáº¡n vÄƒn máº­t Ä‘á»™, Ä‘Ã´i khi cÃ¡c bá»™ dá»¯ liá»‡u cÃ³ sáºµn khÃ´ng Ä‘á»§ Ä‘á»ƒ huáº¥n luyá»‡n chÃºng [62]. Do Ä‘Ã³, chÆ°ng cáº¥t kiáº¿n thá»©c, trong Ä‘Ã³ má»™t mÃ´ hÃ¬nh giÃ¡o viÃªn cung cáº¥p nhÃ£n cho má»™t mÃ´ hÃ¬nh há»c sinh, Ä‘Ã£ trá»Ÿ thÃ nh má»™t phÆ°Æ¡ng phÃ¡p tiÃªu chuáº©n Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ vÃ  Ä‘Ã£ cho tháº¥y káº¿t quáº£ thuyáº¿t phá»¥c [17,30]. CÃ´ng trÃ¬nh hiá»‡n cÃ³ trong lÄ©nh vá»±c nÃ y thÆ°á»ng sá»­ dá»¥ng cÃ¡c bá»™ xáº¿p háº¡ng láº¡i cross-encoder Ä‘áº§u vÃ o cáº£ truy váº¥n vÃ  tÃ i liá»‡u lÃ m mÃ´ hÃ¬nh giÃ¡o viÃªn cho cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ vá»›i kiáº¿n trÃºc bi-encoder [44]. Má»™t phÆ°Æ¡ng phÃ¡p khÃ¡c lÃ  chÆ°ng cáº¥t kiáº¿n thá»©c tá»« cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ Ä‘a vectÆ¡, nhÆ° ColBERT [24] sang cÃ¡c bá»™ truy xuáº¥t máº­t Ä‘á»™ Ä‘Æ¡n vectÆ¡ [63].

Trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i khÃ´ng tháº¥y chÆ°ng cáº¥t kiáº¿n thá»©c tá»« cÃ¡c bá»™ xáº¿p háº¡ng láº¡i cross-encoder há»¯u Ã­ch cho cÃ¡c bá»™ dá»¯ liá»‡u KI-VQA. Do Ä‘Ã³, chÃºng tÃ´i giá»›i thiá»‡u má»™t phÆ°Æ¡ng phÃ¡p má»›i: chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i cho mÃ£ hÃ³a kÃ©p, trong Ä‘Ã³ chÆ°ng cáº¥t kiáº¿n thá»©c diá»…n ra láº·p Ä‘i láº·p láº¡i giá»¯a hai bi-encoder sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng thá»©c khÃ¡c nhau trong Ä‘áº§u vÃ o cá»§a chÃºng. Theo Ä‘Ã³, má»—i mÃ´ hÃ¬nh há»c há»i quan Ä‘iá»ƒm cá»§a mÃ´ hÃ¬nh khÃ¡c, Ä‘iá»u chá»‰nh khÃ´ng gian biá»ƒu diá»…n cá»§a chÃºng Ä‘á»ƒ truy xuáº¥t máº­t Ä‘á»™ hiá»‡u quáº£ hÆ¡n.

Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c. ÄÃ²i há»i kiáº¿n thá»©c Ä‘á» cáº­p Ä‘áº¿n má»™t danh má»¥c cÃ¡c váº¥n Ä‘á» há»c mÃ¡y Ä‘Æ°á»£c tÄƒng cÆ°á»ng báº±ng truy xuáº¥t [61] mÃ  Ä‘áº§u vÃ o khÃ´ng Ä‘á»§ Ä‘á»ƒ táº¡o ra Ä‘áº§u ra vÃ  thÃ´ng tin bÃªn ngoÃ i cáº§n Ä‘Æ°á»£c cung cáº¥p. KILT [39] lÃ  má»™t benchmark cho cÃ¡c tÃ¡c vá»¥ ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘Ã²i há»i kiáº¿n thá»©c nhÆ° tráº£ lá»i cÃ¢u há»i miá»n má»Ÿ, kiá»ƒm tra sá»± tháº­t, liÃªn káº¿t thá»±c thá»ƒ, Ä‘iá»n slot vÃ  Ä‘á»‘i thoáº¡i dá»±a trÃªn kiáº¿n thá»©c. Táº¥t cáº£ cÃ¡c tÃ¡c vá»¥ Ä‘Ã£ Ä‘á» cáº­p Ä‘á»u lÃ  cÃ¡c tÃ¡c vá»¥ Ä‘Ã²i há»i kiáº¿n thá»©c chá»‰ cÃ³ vÄƒn báº£n. Theo hiá»ƒu biáº¿t cá»§a chÃºng tÃ´i, khÃ´ng cÃ³ benchmark thá»‘ng nháº¥t nÃ o vá» cÃ¡c tÃ¡c vá»¥ Ä‘a phÆ°Æ¡ng thá»©c Ä‘Ã²i há»i kiáº¿n thá»©c, Ä‘iá»u nÃ y tÆ°Æ¡ng Ä‘á»‘i Ã­t Ä‘Æ°á»£c khÃ¡m phÃ¡. Do Ä‘Ã³, bÃ i bÃ¡o nÃ y táº­p trung vÃ o tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh Ä‘Ã²i há»i kiáº¿n thá»©c.

Tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh (VQA) lÃ  má»™t tÃ¡c vá»¥ tráº£ lá»i cÃ¢u há»i Ä‘a phÆ°Æ¡ng thá»©c cÃ³ má»¥c tiÃªu tráº£ lá»i má»™t cÃ¢u há»i ngÃ´n ngá»¯ tá»± nhiÃªn vá» má»™t hÃ¬nh áº£nh [3]. VQA chá»§ yáº¿u Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘o lÆ°á»ng kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh trong viá»‡c biá»ƒu diá»…n vÃ  hiá»ƒu dá»¯ liá»‡u Ä‘a phÆ°Æ¡ng thá»©c. Do Ä‘Ã³, cÃ¡c cÃ¢u há»i trong VQA thÆ°á»ng liÃªn quan Ä‘áº¿n cÃ¡c Ä‘áº·c Ä‘iá»ƒm hÃ¬nh áº£nh (vÃ­ dá»¥: mÃ u sáº¯c hoáº·c hÃ¬nh dáº¡ng cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng) vÃ  Ä‘Ã´i khi yÃªu cáº§u kiáº¿n thá»©c thÃ´ng thÆ°á»ng. NÃ³i cÃ¡ch khÃ¡c, con ngÆ°á»i cÃ³ thá»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i VQA chá»‰ báº±ng cÃ¡ch nhÃ¬n vÃ o hÃ¬nh áº£nh, mÃ  khÃ´ng cáº§n truy cáº­p thÃ´ng tin bÃªn ngoÃ i.

Vá»›i cÃ´ng thá»©c nÃ y, VQA cÃ³ cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng thá»±c táº¿ háº¡n cháº¿. TrÃ¡i ngÆ°á»£c vá»›i VQA, tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh Ä‘Ã²i há»i kiáº¿n thá»©c

--- TRANG 2 ---
SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan. Alireza Salemi, Juan Altmayer Pizzorno, vÃ  Hamed Zamani

lÃ  tÃ¡c vá»¥ tráº£ lá»i má»™t cÃ¢u há»i vá» má»™t hÃ¬nh áº£nh cáº§n má»™t pháº§n thÃ´ng tin bÃªn ngoÃ i khÃ´ng cÃ³ sáºµn trong hÃ¬nh áº£nh Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i. Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh Dá»±a TrÃªn Sá»± Tháº­t (FVQA) [56] lÃ  má»™t bá»™ dá»¯ liá»‡u tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh trong Ä‘Ã³ viá»‡c tráº£ lá»i cÃ¡c cÃ¢u há»i vá» má»™t hÃ¬nh áº£nh cáº§n mÃ´ hÃ¬nh xem xÃ©t má»™t sá»± tháº­t liÃªn quan. Thay vÃ o Ä‘Ã³, tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh kiáº¿n thá»©c bÃªn ngoÃ i (OK-VQA) [38] lÃ  má»™t bá»™ dá»¯ liá»‡u tÆ°Æ¡ng tá»± nhÆ° FVQA, nhÆ°ng kiáº¿n thá»©c cáº§n thiáº¿t khÃ´ng bá»‹ giá»›i háº¡n bá»Ÿi cÃ¡c sá»± tháº­t.

CÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n táº¡i cho OK-VQA sá»­ dá»¥ng cÃ¡c chiáº¿n lÆ°á»£c khÃ¡c nhau Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á»: má»™t sá»‘ dá»±a vÃ o kiáº¿n thá»©c áº©n Ä‘Æ°á»£c lÆ°u trá»¯ trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ hoáº·c thá»‹ giÃ¡c-ngÃ´n ngá»¯ Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i mÃ  khÃ´ng sá»­ dá»¥ng báº¥t ká»³ nguá»“n kiáº¿n thá»©c bÃªn ngoÃ i nÃ o [48,60], trong khi nhá»¯ng cÃ¡i khÃ¡c sá»­ dá»¥ng cÃ¡c nguá»“n kiáº¿n thá»©c bÃªn ngoÃ i cho má»¥c Ä‘Ã­ch nÃ y ngoÃ i kiáº¿n thá»©c áº©n [12â€“14,37,57]. Viá»‡c sá»­ dá»¥ng OCR vÃ  nhÃ£n Ä‘á»‘i tÆ°á»£ng máº­t Ä‘á»™ cÅ©ng cÃ³ thá»ƒ hiá»‡u quáº£ cho tÃ¡c vá»¥ nÃ y [10,32], nhÆ°ng náº±m ngoÃ i pháº¡m vi cá»§a bÃ i bÃ¡o nÃ y. Äá»ƒ sá»­ dá»¥ng má»™t nguá»“n kiáº¿n thá»©c rÃµ rÃ ng, cáº§n thiáº¿t pháº£i thiáº¿t káº¿ má»™t bá»™ truy xuáº¥t truy xuáº¥t má»™t táº­p nhá» cÃ¡c Ä‘oáº¡n vÄƒn liÃªn quan Ä‘áº¿n hÃ¬nh áº£nh vÃ  cÃ¢u há»i [40] vÃ  má»™t bá»™ Ä‘á»c chá»n hoáº·c táº¡o ra pháº£n há»“i tá»« cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Ã£ truy xuáº¥t [13,14,35]. BÃ i bÃ¡o nÃ y Ä‘á» xuáº¥t cÃ¡c giáº£i phÃ¡p hiá»‡u quáº£ cho cáº£ hai bÆ°á»›c nÃ y.

3 PHÃT BIá»‚U Váº¤N Äá»€
Trong tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh Ä‘Ã²i há»i kiáº¿n thá»©c, ngÆ°á»i dÃ¹ng Ä‘áº·t má»™t cÃ¢u há»i ngÃ´n ngá»¯ tá»± nhiÃªn vá» má»™t hÃ¬nh áº£nh, Ä‘iá»u nÃ y Ä‘Ã²i há»i truy cáº­p thÃ´ng tin bÃªn ngoÃ i. NÃ³i cÃ¡ch khÃ¡c, cÃ¢u tráº£ lá»i cho cÃ¢u há»i khÃ´ng tá»“n táº¡i trong hÃ¬nh áº£nh, Ä‘iá»u nÃ y cáº§n thiáº¿t pháº£i sá»­ dá»¥ng cÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i. Xem HÃ¬nh 1 Ä‘á»ƒ biáº¿t vÃ­ dá»¥ vá» cÃ¡c tÃ¡c vá»¥ KI-VQA. Nhá»¯ng tÃ i nguyÃªn nÃ y cÃ³ thá»ƒ á»Ÿ nhiá»u hÃ¬nh thá»©c khÃ¡c nhau, tá»« cÃ¡c cÆ¡ sá»Ÿ kiáº¿n thá»©c cÃ³ cáº¥u trÃºc vÃ  bÃ¡n cáº¥u trÃºc Ä‘áº¿n vÄƒn báº£n khÃ´ng cÃ³ cáº¥u trÃºc Ä‘Æ°á»£c truy xuáº¥t tá»« web. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i xem xÃ©t má»™t ká»‹ch báº£n trong Ä‘Ã³ cÃ¢u tráº£ lá»i nÃªn Ä‘Æ°á»£c truy xuáº¥t vÃ  trÃ­ch xuáº¥t tá»« má»™t bá»™ sÆ°u táº­p cÃ¡c Ä‘oáº¡n vÄƒn ngÃ´n ngá»¯ tá»± nhiÃªn khÃ´ng cÃ³ cáº¥u trÃºc. Sau Ä‘Ã¢y, chÃºng tÃ´i chá»‰ Ä‘á»‹nh cá»¥ thá»ƒ hÆ¡n tÃ¡c vá»¥ KI-VQA Ä‘Æ°á»£c nghiÃªn cá»©u trong bÃ i bÃ¡o nÃ y.

Gá»i ğ‘‡={(ğ‘„1,ğ¼1,ğ´1,ğ‘…1),(ğ‘„2,ğ¼2,ğ´2,ğ‘…2),Â·Â·Â·,(ğ‘„ğ‘›,ğ¼ğ‘›,ğ´ğ‘›,ğ‘…ğ‘›)} lÃ  táº­p huáº¥n luyá»‡n cho má»™t tÃ¡c vá»¥ KI-VQA. Má»—i instance huáº¥n luyá»‡n bao gá»“m má»™t cÃ¢u há»i ngÃ´n ngá»¯ tá»± nhiÃªn ğ‘„ğ‘–, má»™t hÃ¬nh áº£nh ğ¼ğ‘–, má»™t táº­p cÃ¡c cÃ¢u tráº£ lá»i vÄƒn báº£n ngáº¯n ğ´ğ‘–, vÃ  má»™t táº­p cÃ¡c Ä‘oáº¡n vÄƒn liÃªn quan ğ‘…ğ‘–. Äiá»u Ä‘Ã³ cÃ³ nghÄ©a lÃ  má»—i cÃ¢u há»i cÃ³ thá»ƒ cÃ³ nhiá»u cÃ¢u tráº£ lá»i trong táº­p huáº¥n luyá»‡n (tá»©c lÃ  |ğ´ğ‘–|â‰¥1), thÆ°á»ng giá»‘ng nhau vá» máº·t ngá»¯ nghÄ©a nhÆ°ng khÃ¡c nhau vá» máº·t cÃº phÃ¡p. TÆ°Æ¡ng tá»±, cÃ³ thá»ƒ tá»“n táº¡i nhiá»u Ä‘oáº¡n vÄƒn liÃªn quan Ä‘áº¿n cÃ¢u há»i (tá»©c lÃ  |ğ‘…ğ‘–|â‰¥1). Táº¥t cáº£ cÃ¡c Ä‘oáº¡n vÄƒn liÃªn quan Ä‘Æ°á»£c chá»n vÃ  chÃº thÃ­ch tá»« má»™t bá»™ sÆ°u táº­p quy mÃ´ lá»›n C. Do Ä‘Ã³, ğ‘…ğ‘–âŠ†C:âˆ€1â‰¤ğ‘–â‰¤ğ‘›. ChÃºng tÃ´i nghiÃªn cá»©u hai tÃ¡c vá»¥ liÃªn quan sau:

Truy Xuáº¥t Äoáº¡n VÄƒn cho KI-VQA: tÃ¡c vá»¥ truy xuáº¥t lÃ  sá»­ dá»¥ng táº­p huáº¥n luyá»‡n ğ‘‡ Ä‘á»ƒ huáº¥n luyá»‡n má»™t bá»™ truy xuáº¥t truy xuáº¥t cÃ¡c Ä‘oáº¡n vÄƒn liÃªn quan tá»« bá»™ sÆ°u táº­p C cho má»™t cáº·p cÃ¢u há»i-hÃ¬nh áº£nh Ä‘Ã£ cho (ğ‘„,ğ¼).

Táº¡o CÃ¢u Tráº£ Lá»i ÄÆ°á»£c TÄƒng CÆ°á»ng Báº±ng Truy Xuáº¥t cho KI-VQA: tÃ¡c vá»¥ táº¡o cÃ¢u tráº£ lá»i Ä‘Æ°á»£c tÄƒng cÆ°á»ng báº±ng truy xuáº¥t lÃ  táº¡o ra má»™t cÃ¢u tráº£ lá»i vÄƒn báº£n ngáº¯n cho báº¥t ká»³ cáº·p cÃ¢u há»i-hÃ¬nh áº£nh chÆ°a tháº¥y nÃ o (ğ‘„,ğ¼) báº±ng cÃ¡ch cÃ³ quyá»n truy cáº­p vÃ o bá»™ sÆ°u táº­p C. Do Ä‘Ã³, cÃ¡c mÃ´ hÃ¬nh trong tÃ¡c vá»¥ nÃ y tá»± nhiÃªn truy xuáº¥t cÃ¡c Ä‘oáº¡n vÄƒn tá»« C vÃ  sá»­ dá»¥ng chÃºng Ä‘á»ƒ táº¡o ra cÃ¢u tráº£ lá»i.

ChÃºng tÃ´i Ä‘áº§u tiÃªn Ä‘á» xuáº¥t má»™t kiáº¿n trÃºc mÃ£ hÃ³a Ä‘á»‘i xá»©ng kÃ©p cho truy xuáº¥t máº­t Ä‘á»™ trong KI-VQA vÃ  sau Ä‘Ã³ giá»›i thiá»‡u má»™t mÃ´ hÃ¬nh há»£p nháº¥t-trong-bá»™ giáº£i mÃ£ Ä‘a phÆ°Æ¡ng thá»©c nhÆ° má»™t phÆ°Æ¡ng phÃ¡p táº¡o cÃ¢u tráº£ lá»i Ä‘Æ°á»£c tÄƒng cÆ°á»ng báº±ng truy xuáº¥t.

4 DEDR: KHUNG Bá»˜ TRUY XUáº¤T Máº¬T Äá»˜ MÃƒ HÃ“A KÃ‰P
HÃ¬nh 2 mÃ´ táº£ má»™t pipeline cho cÃ¡c tÃ¡c vá»¥ tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh Ä‘Ã²i há»i kiáº¿n thá»©c. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong pipeline, Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ lÃ  báº¥t Ä‘á»‘i xá»©ng â€“ bá»™ mÃ£ hÃ³a truy váº¥n nháº­n Ä‘áº§u vÃ o Ä‘a phÆ°Æ¡ng thá»©c (tá»©c lÃ  má»™t cÃ¢u há»i vÃ  má»™t hÃ¬nh áº£nh), trong khi bá»™ mÃ£ hÃ³a Ä‘oáº¡n vÄƒn nháº­n Ä‘áº§u vÃ o vÄƒn báº£n Ä‘Æ¡n phÆ°Æ¡ng thá»©c (tá»©c lÃ  má»™t Ä‘oáº¡n vÄƒn tá»« C). Thuá»™c tÃ­nh báº¥t Ä‘á»‘i xá»©ng nÃ y trong cÃ¡c phÆ°Æ¡ng thá»©c Ä‘áº§u vÃ o khiáº¿n viá»‡c thiáº¿t káº¿ má»™t mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ Ä‘á»‘i xá»©ng hiá»‡u quáº£ trá»Ÿ nÃªn thÃ¡ch thá»©c. ÄÃ¢y lÃ  lÃ½ do táº¡i sao mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ tiÃªn tiáº¿n hiá»‡n táº¡i Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Qu et al. [40] sá»­ dá»¥ng má»™t kiáº¿n trÃºc báº¥t Ä‘á»‘i xá»©ng, trong Ä‘Ã³ má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘a phÆ°Æ¡ng thá»©c Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c (tá»©c lÃ  LXMERT [53]) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ mÃ£ hÃ³a truy váº¥n vÃ  má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ¡n phÆ°Æ¡ng thá»©c Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c (tá»©c lÃ  BERT [8]) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ mÃ£ hÃ³a tÃ i liá»‡u. VÃ¬ cÃ¡c kiáº¿n trÃºc báº¥t Ä‘á»‘i xá»©ng nhÆ° váº­y báº¯t Ä‘áº§u tá»« cÃ¡c khÃ´ng gian nhÃºng cÆ¡ báº£n khÃ¡c nhau, chÃºng gáº·p pháº£i tá»‘c Ä‘á»™ há»™i tá»¥ cháº­m vÃ  hiá»‡u suáº¥t truy xuáº¥t máº­t Ä‘á»™ khÃ´ng tá»‘i Æ°u. NgÆ°á»£c láº¡i, nghiÃªn cá»©u rá»™ng rÃ£i vá» truy xuáº¥t máº­t Ä‘á»™ cho dá»¯ liá»‡u Ä‘Æ¡n phÆ°Æ¡ng thá»©c (truy váº¥n vÃ  tÃ i liá»‡u vÄƒn báº£n) cho tháº¥y ráº±ng cÃ¡c kiáº¿n trÃºc Ä‘á»‘i xá»©ng dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ. CÃ¡c mÃ´ hÃ¬nh truy xuáº¥t Ä‘oáº¡n vÄƒn máº­t Ä‘á»™ tiÃªn tiáº¿n, nhÆ° TAS-B [17], ColBERT [24,49], RocketQA [41,44], vÃ  CLDRD [62], sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc Ä‘á»‘i xá»©ng. ÄÆ°á»£c thÃºc Ä‘áº©y bá»Ÿi quan sÃ¡t nÃ y, má»¥c tiÃªu cá»§a chÃºng tÃ´i lÃ  há»c má»™t mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ Ä‘á»‘i xá»©ng cho cÃ¡c tÃ¡c vá»¥ KI-VQA.

Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu nÃ y, chÃºng tÃ´i nghiÃªn cá»©u hai giáº£i phÃ¡p thay tháº¿. Äáº§u tiÃªn, chÃºng tÃ´i chuyá»ƒn Ä‘á»•i táº¥t cáº£ Ä‘áº§u vÃ o mÃ´ hÃ¬nh sang dáº¡ng vÄƒn báº£n Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  sau Ä‘Ã³ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ¡n phÆ°Æ¡ng thá»©c cho cáº£ mÃ£ hÃ³a truy váº¥n vÃ  tÃ i liá»‡u (Pháº§n 4.1). Thá»© hai, chÃºng tÃ´i chuyá»ƒn Ä‘á»•i táº¥t cáº£ Ä‘áº§u vÃ o sang cÃ¹ng dáº¡ng Ä‘a phÆ°Æ¡ng thá»©c (vÄƒn báº£n vÃ  hÃ¬nh áº£nh) vÃ  sau Ä‘Ã³ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘a phÆ°Æ¡ng thá»©c cho cáº£ hai bá»™ mÃ£ hÃ³a (Pháº§n 4.2). ChÃºng tÃ´i giáº£ thuyáº¿t ráº±ng hai mÃ´ hÃ¬nh nÃ y há»c cÃ¡c biá»ƒu diá»…n bá»• sung vÃ¬ cÃ¡c lÃ½ do sau: (1) chÃºng nháº­n cÃ¡c Ä‘á»‹nh dáº¡ng Ä‘áº§u vÃ o khÃ¡c nhau, vÃ  (2) quÃ¡ trÃ¬nh vÃ  dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  Ä‘a phÆ°Æ¡ng thá»©c lÃ  khÃ¡c nhau. Káº¿t quáº£ thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i cÅ©ng xÃ¡c thá»±c giáº£ thuyáº¿t nÃ y (xem Pháº§n 6.3). Theo quan sÃ¡t nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i xen káº½ giá»¯a hai phÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a nÃ y nhÆ° cÃ¡c mÃ´ hÃ¬nh giÃ¡o viÃªn vÃ  há»c sinh. Cuá»‘i cÃ¹ng, báº±ng cÃ¡ch káº¿t há»£p hai phÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a nÃ y, DEDR há»c má»™t bá»™ mÃ£ hÃ³a Ä‘á»‘i xá»©ng kÃ©p Ä‘Æ¡n phÆ°Æ¡ng thá»©c/Ä‘a phÆ°Æ¡ng thá»©c cho cáº£ truy váº¥n vÃ  tÃ i liá»‡u.

4.1 MÃ£ HÃ³a ÄÆ¡n PhÆ°Æ¡ng Thá»©c Thá»‘ng Nháº¥t
Äá»ƒ sá»­ dá»¥ng má»™t bá»™ mÃ£ hÃ³a Ä‘Æ¡n phÆ°Æ¡ng thá»©c (vÄƒn báº£n) chung Ä‘á»ƒ biá»ƒu diá»…n cáº£ truy váº¥n vÃ  Ä‘oáº¡n vÄƒn, chÃºng ta cáº§n chuyá»ƒn Ä‘á»•i hÃ¬nh áº£nh trong truy váº¥n thÃ nh vÄƒn báº£n. MÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ° sau:

ğ‘†ğ‘‡((ğ‘„,ğ¼),ğ‘ƒ)=ğ¸ğ‘‡(concat(ğ‘„,ğœ™ğ¼â†’ğ‘‡(ğ¼)))Â·ğ¸ğ‘‡(ğ‘ƒ) (1)

trong Ä‘Ã³ Â· biá»ƒu thá»‹ tÃ­ch vÃ´ hÆ°á»›ng giá»¯a hai vectÆ¡, ğ¸ğ‘‡ lÃ  má»™t bá»™ mÃ£ hÃ³a vÄƒn báº£n Ä‘Æ¡n phÆ°Æ¡ng thá»©c, vÃ  ğœ™ğ¼â†’ğ‘‡ lÃ  má»™t module chuyá»ƒn Ä‘á»•i phÆ°Æ¡ng thá»©c nháº­n má»™t hÃ¬nh áº£nh vÃ  táº¡o ra má»™t mÃ´ táº£ vÄƒn báº£n cho nÃ³.

CÃ³ má»™t sá»‘ phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ thá»±c hiá»‡n bá»™ chuyá»ƒn Ä‘á»•i phÆ°Æ¡ng thá»©c ğœ™ğ¼â†’ğ‘‡. Má»™t phÆ°Æ¡ng phÃ¡p lÃ  táº¡o ra tÃªn cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ trong hÃ¬nh áº£nh báº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng. ChÃºng tÃ´i cÃ³ má»™t phÆ°Æ¡ng phÃ¡p thay tháº¿ báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c má»¥c tiÃªu chÃº thÃ­ch hÃ¬nh áº£nh Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh chuyá»ƒn Ä‘á»•i phÆ°Æ¡ng thá»©c ğœ™ğ¼â†’ğ‘‡. LÃ½ do lÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p chÃº thÃ­ch hÃ¬nh áº£nh táº¡o ra cÃ¡c mÃ´ táº£ má»Ÿ vá» hÃ¬nh áº£nh, trÃ¡i ngÆ°á»£c vá»›i cÃ¡c danh má»¥c Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c trong cÃ¡c mÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng. NgoÃ i ra, viá»‡c thu tháº­p dá»¯ liá»‡u huáº¥n luyá»‡n cho cÃ¡c mÃ´ hÃ¬nh chÃº thÃ­ch hÃ¬nh áº£nh lÃ  ráº», vá»›i sá»± cÃ³ sáºµn cá»§a hÃ¬nh áº£nh quy mÃ´ lá»›n vá»›i chÃº thÃ­ch trÃªn web. Chi tiáº¿t hÆ¡n, chÃºng tÃ´i sá»­ dá»¥ng kiáº¿n trÃºc ExpansionNet v2 [18] Ä‘á»ƒ thá»±c hiá»‡n ğœ™ğ¼â†’ğ‘‡. Expansion V2 lÃ  má»™t kiáº¿n trÃºc encoder-decoder Ä‘Æ°á»£c thiáº¿t káº¿ trÃªn Swin-Transformer [33] Ä‘Æ°á»£c má»Ÿ rá»™ng bá»Ÿi Block Dynamic and Static Expansion [18] vÃ  multi-head attention [55]. MÃ´ hÃ¬nh Ä‘áº§u tiÃªn Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c báº±ng hÃ¬nh áº£nh vÃ  chÃº thÃ­ch tá»« bá»™ dá»¯ liá»‡u Microsoft COCO [31]. Sau Ä‘Ã³, tá»‘i Æ°u hÃ³a tá»± phÃª bÃ¬nh [46] Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»ƒ hoÃ n thÃ nh viá»‡c huáº¥n luyá»‡n mÃ´ hÃ¬nh. Khi mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ táº¡o ra cÃ¡c mÃ´ táº£ vÄƒn báº£n cá»§a hÃ¬nh áº£nh, chÃºng tÃ´i Ä‘Ã³ng bÄƒng cÃ¡c tham sá»‘ cá»§a ExpansionNet v2 vÃ  chá»‰ tá»‘i Æ°u hÃ³a bá»™ mÃ£ hÃ³a vÄƒn báº£n ğ¸ğ‘‡. Äiá»u nÃ y giáº£m Ä‘Ã¡ng ká»ƒ sá»‘ lÆ°á»£ng tham sá»‘ cáº§n Ä‘Æ°á»£c há»c báº±ng táº­p huáº¥n luyá»‡n KI-VQA.

Äá»ƒ thá»±c hiá»‡n bá»™ mÃ£ hÃ³a vÄƒn báº£n ğ¸ğ‘‡, cÃ³ nhiá»u mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ sáºµn. Trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i sá»­ dá»¥ng BERT-base [8] vÃ  biá»ƒu diá»…n liÃªn quan Ä‘áº¿n token [CLS] Ä‘Æ°á»£c coi lÃ  Ä‘áº§u ra cá»§a bá»™ mÃ£ hÃ³a ğ¸ğ‘‡. LÆ°u Ã½ ráº±ng trong PhÆ°Æ¡ng trÃ¬nh (1), cÃ¡c bá»™ mÃ£ hÃ³a truy váº¥n vÃ  Ä‘oáº¡n vÄƒn lÃ  giá»‘ng nhau vÃ  chÃºng sá»­ dá»¥ng cÃ¡c tham sá»‘ chung, Ä‘áº£m báº£o má»™t kiáº¿n trÃºc Ä‘á»‘i xá»©ng cho truy xuáº¥t máº­t Ä‘á»™.

4.2 MÃ£ HÃ³a Äa PhÆ°Æ¡ng Thá»©c Thá»‘ng Nháº¥t
Máº·c dÃ¹ viá»‡c sá»­ dá»¥ng má»™t bá»™ mÃ£ hÃ³a Ä‘a phÆ°Æ¡ng thá»©c cho cáº£ mÃ£ hÃ³a truy váº¥n vÃ  Ä‘oáº¡n vÄƒn cÃ³ váº» Ä‘Æ¡n giáº£n, háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘a phÆ°Æ¡ng thá»©c khÃ´ng cháº¥p nháº­n Ä‘áº§u vÃ o chá»‰ cÃ³ vÄƒn báº£n. Do Ä‘Ã³, chÃºng ta cáº§n phÃ¡t triá»ƒn má»™t ká»¹ thuáº­t Ä‘á»ƒ láº¥p Ä‘áº§y khoáº£ng cÃ¡ch phÆ°Æ¡ng thá»©c nÃ y. PhÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a Ä‘a phÆ°Æ¡ng thá»©c thá»‘ng nháº¥t cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ° sau:

ğ‘†ğ‘€ğ‘€((ğ‘„,ğ¼),ğ‘ƒ)=ğ¸ğ‘€ğ‘€(ğ‘„,ğ¼)Â·ğ¸ğ‘€ğ‘€(ğ‘ƒ,ğ¼[MASKED]) (2)

trong Ä‘Ã³ ğ¸ğ‘€ğ‘€ lÃ  má»™t bá»™ mÃ£ hÃ³a Ä‘a phÆ°Æ¡ng thá»©c Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c biá»ƒu diá»…n má»™t cáº·p vÄƒn báº£n vÃ  hÃ¬nh áº£nh lÃ m Ä‘áº§u vÃ o. Äá»ƒ giáº£i quyáº¿t khoáº£ng cÃ¡ch phÆ°Æ¡ng thá»©c giá»¯a phÃ­a truy váº¥n vÃ  Ä‘oáº¡n vÄƒn, chÃºng tÃ´i sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘a phÆ°Æ¡ng thá»©c Ä‘Ã£ sá»­ dá»¥ng ká»¹ thuáº­t che dáº¥u á»Ÿ phÃ­a hÃ¬nh áº£nh trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n trÆ°á»›c. Chi tiáº¿t hÆ¡n, chÃºng tÃ´i sá»­ dá»¥ng LXMERT [53] sá»­ dá»¥ng Faster R-CNN [45] Ä‘á»ƒ nháº­n dáº¡ng 36 Ä‘á»‘i tÆ°á»£ng trong hÃ¬nh áº£nh Ä‘Ã£ cho vÃ  táº¡o ra biá»ƒu diá»…n vÃ  há»™p bao quanh cá»§a chÃºng. Sau Ä‘Ã³, thÃ´ng tin nÃ y vá» cÃ¡c Ä‘á»‘i tÆ°á»£ng ngoÃ i cÃ¡c token vÄƒn báº£n Ä‘Æ°á»£c Ä‘Æ°a vÃ o má»™t máº¡ng transformer dual-encoder vá»›i má»™t bá»™ mÃ£ hÃ³a chÃ©o phÆ°Æ¡ng thá»©c á»Ÿ trÃªn. Cuá»‘i cÃ¹ng, token [CLS] Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ biá»ƒu diá»…n toÃ n bá»™ Ä‘áº§u vÃ o. VÃ¬ LXMERT Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vá»›i cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n trÆ°á»›c khÃ¡c nhau, bao gá»“m Dá»± Ä‘oÃ¡n Äá»‘i tÆ°á»£ng Bá»‹ Che, nÃ³ phÃ¹ há»£p hoÃ n háº£o cho viá»‡c há»c biá»ƒu diá»…n Ä‘a phÆ°Æ¡ng thá»©c thá»‘ng nháº¥t cá»§a chÃºng tÃ´i.

Äá»ƒ vÆ°á»£t qua váº¥n Ä‘á» Ä‘Ã£ Ä‘á» cáº­p vá»›i viá»‡c mÃ£ hÃ³a dá»¯ liá»‡u chá»‰ cÃ³ vÄƒn báº£n cho biá»ƒu diá»…n Ä‘oáº¡n vÄƒn, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t ká»¹ thuáº­t Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ mÃ  chÃºng tÃ´i gá»i lÃ  Má»Ÿ Rá»™ng Äoáº¡n VÄƒn sá»­ dá»¥ng Biá»ƒu Diá»…n HÃ¬nh áº¢nh Bá»‹ Che (PEMIR). Trong ká»¹ thuáº­t nÃ y, chÃºng tÃ´i Ä‘Æ°a má»™t Ä‘oáº¡n vÄƒn vÃ o LXMERT lÃ m Ä‘áº§u vÃ o vÄƒn báº£n vÃ  sá»‘ khÃ´ng (bá»‹ che) lÃ m Ä‘áº§u vÃ o hÃ¬nh áº£nh vá»›i cÃ¡c há»™p bao quanh cá»§a [0.0,0.0,1.0,1.0]. Äáº§u vÃ o hÃ¬nh áº£nh nÃ y cÃ³ nghÄ©a lÃ  36 Ä‘á»‘i tÆ°á»£ng bá»‹ che vá»›i cÃ¡c há»™p bao quanh cá»§a toÃ n bá»™ hÃ¬nh áº£nh. Theo trá»±c giÃ¡c, chÃºng tÃ´i yÃªu cáº§u mÃ´ hÃ¬nh táº¡o ra má»™t biá»ƒu diá»…n cho Ä‘oáº¡n vÄƒn Ä‘áº§u vÃ o trong khi cá»‘ gáº¯ng táº¡o ra cÃ¡c biá»ƒu diá»…n Ä‘á»‘i tÆ°á»£ng hÃ¬nh áº£nh tá»‘t nháº¥t dá»±a trÃªn dá»¯ liá»‡u Ä‘áº§u vÃ o vÄƒn báº£n. Do Ä‘Ã³, Ä‘iá»u nÃ y gáº§n nhÆ° tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c má»Ÿ rá»™ng Ä‘oáº¡n vÄƒn vá»›i biá»ƒu diá»…n hÃ¬nh áº£nh dá»±a trÃªn ná»™i dung Ä‘oáº¡n vÄƒn.

Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y, chÃºng ta cÃ³ thá»ƒ táº¡o ra biá»ƒu diá»…n cho truy váº¥n vÃ  tÃ i liá»‡u báº±ng cÃ¹ng má»™t bá»™ mÃ£ hÃ³a Ä‘a phÆ°Æ¡ng thá»©c vá»›i cÃ¡c tham sá»‘ chung. Äiá»u nÃ y cÃ³ lá»£i vÃ¬ nÃ³ giÃºp kiáº¿n trÃºc dual encoder báº¯t Ä‘áº§u tá»« cÃ¹ng má»™t khÃ´ng gian nhÃºng chung. NgoÃ i ra, chÃºng ta cÃ³ thá»ƒ chá»‰ sá»­ dá»¥ng má»™t bá»™ mÃ£ hÃ³a duy nháº¥t lÃ m cáº£ bá»™ mÃ£ hÃ³a truy váº¥n vÃ  tÃ i liá»‡u, dáº«n Ä‘áº¿n viá»‡c giáº£m sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh.

4.3 Tá»‘i Æ¯u HÃ³a MÃ£ HÃ³a KÃ©p thÃ´ng qua ChÆ°ng Cáº¥t Kiáº¿n Thá»©c Láº·p Äi Láº·p Láº¡i
ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€ biá»ƒu diá»…n cÃ¡c Ä‘áº§u vÃ o KI-VQA tá»« cÃ¡c gÃ³c Ä‘á»™ khÃ¡c nhau; ğ¸ğ‘‡ chá»‰ xem xÃ©t biá»ƒu diá»…n vÄƒn báº£n cá»§a cÃ¡c Ä‘áº§u vÃ o, trong khi ğ¸ğ‘€ğ‘€ xem xÃ©t cÃ¡c biá»ƒu diá»…n Ä‘a phÆ°Æ¡ng thá»©c cá»§a chÃºng. Nhá»¯ng mÃ´ hÃ¬nh nÃ y cÅ©ng sá»­ dá»¥ng dá»¯ liá»‡u vÃ  má»¥c tiÃªu huáº¥n luyá»‡n trÆ°á»›c Ä‘á»™c Ä‘Ã¡o. Do Ä‘Ã³, chÃºng tÃ´i giáº£ thuyáº¿t ráº±ng hai mÃ´ hÃ¬nh há»c biá»ƒu diá»…n nÃ y cung cáº¥p thÃ´ng tin bá»• sung. PhÃ¢n tÃ­ch thá»±c nghiá»‡m cá»§a chÃºng tÃ´i xÃ¡c thá»±c

--- TRANG 3 ---
Má»™t Khung Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a Äá»‘i Xá»©ng KÃ©p cho Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c ChuyÃªn SÃ¢u SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan.

HÃ¬nh 3: Quy trÃ¬nh huáº¥n luyá»‡n vÃ  suy luáº­n trong khung DEDR. DEDR Ä‘áº§u tiÃªn huáº¥n luyá»‡n cÃ¡c bá»™ mÃ£ hÃ³a Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  Ä‘a phÆ°Æ¡ng thá»©c riÃªng biá»‡t (trÃ¡i), sau Ä‘Ã³ sá»­ dá»¥ng chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i Ä‘á»ƒ Ä‘iá»u chá»‰nh cáº£ hai khÃ´ng gian biá»ƒu diá»…n (giá»¯a). Khi suy luáº­n, DEDR sá»­ dá»¥ng sá»± tá»•ng há»£p cá»§a cáº£ hai mÃ£ hÃ³a Ä‘á»ƒ xÃ¢y dá»±ng má»™t bá»™ truy xuáº¥t máº­t Ä‘á»™ mÃ£ hÃ³a Ä‘á»‘i xá»©ng kÃ©p (pháº£i).

giáº£ thuyáº¿t nÃ y, xem HÃ¬nh 5. Vá»›i quan sÃ¡t nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t sá»­ dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c Ä‘á»ƒ cáº£i thiá»‡n cáº£ hai mÃ´ hÃ¬nh nÃ y.

Huáº¥n Luyá»‡n RiÃªng Biá»‡t cÃ¡c Bá»™ MÃ£ HÃ³a. ChÃºng tÃ´i Ä‘áº§u tiÃªn tá»‘i Æ°u hÃ³a cÃ¡c tham sá»‘ cá»§a hai mÃ´ hÃ¬nh nÃ y riÃªng biá»‡t báº±ng táº­p huáº¥n luyá»‡n truy xuáº¥t cho má»—i tÃ¡c vá»¥ KI-VQA. Theo DPR [23], chÃºng tÃ´i sá»­ dá»¥ng má»™t hÃ m máº¥t mÃ¡t Ä‘á»‘i láº­p dá»±a trÃªn cross-entropy Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh:

ğ¿isolated =âˆ’logğ‘’ğ‘†ğ‘‹((ğ‘„,ğ¼),ğ‘ƒğ‘ğ‘œğ‘ )
ğ‘’ğ‘†ğ‘‹((ğ‘„,ğ¼),ğ‘ƒğ‘ğ‘œğ‘ )+âˆ‘ï¸
ğ‘ƒâ€²âˆˆPnegğ‘’ğ‘†ğ‘‹((ğ‘„,ğ¼),ğ‘ƒâ€²)(3)

trong Ä‘Ã³ ğ‘‹âˆˆ{ğ‘‡,ğ‘€ğ‘€} lÃ  phÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o Ä‘iá»ƒm sá»‘, vÃ  ğ‘ƒğ‘ğ‘œğ‘  lÃ  má»™t Ä‘oáº¡n vÄƒn tÃ­ch cá»±c (liÃªn quan) vÃ  Pneg lÃ  má»™t táº­p cÃ¡c Ä‘oáº¡n vÄƒn tiÃªu cá»±c cho cáº·p cÃ¢u há»i-hÃ¬nh áº£nh (ğ‘„,ğ¼). Äá»ƒ xÃ¢y dá»±ng Pneg, chÃºng tÃ´i sá»­ dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p láº¥y máº«u tiÃªu cá»±c khÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng trong [40] ngoÃ i cÃ¡c tiÃªu cá»±c trong batch â€“ trong Ä‘Ã³ táº¥t cáº£ cÃ¡c tÃ i liá»‡u tÃ­ch cá»±c vÃ  tiÃªu cá»±c cá»§a cÃ¡c truy váº¥n khÃ¡c trong batch huáº¥n luyá»‡n Ä‘Æ°á»£c coi lÃ  cÃ¡c tÃ i liá»‡u tiÃªu cá»±c Ä‘á»‘i vá»›i truy váº¥n.

ChÆ°ng Cáº¥t Kiáº¿n Thá»©c Láº·p Äi Láº·p Láº¡i giá»¯a cÃ¡c Bá»™ MÃ£ HÃ³a. Äá»ƒ Ä‘iá»u chá»‰nh khÃ´ng gian biá»ƒu diá»…n trong ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€ vÃ  cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t cá»§a chÃºng, chÃºng tÃ´i thiáº¿t káº¿ má»™t phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i. Trong phÆ°Æ¡ng phÃ¡p nÃ y, chÃºng tÃ´i Ä‘áº§u tiÃªn sá»­ dá»¥ng bá»™ mÃ£ hÃ³a hiá»‡u quáº£ hÆ¡n, dá»±a trÃªn hiá»‡u suáº¥t cá»§a táº­p xÃ¡c thá»±c, lÃ m giÃ¡o viÃªn vÃ  bá»™ mÃ£ hÃ³a khÃ¡c lÃ m há»c sinh. Sau Ä‘Ã³, chÃºng tÃ´i huáº¥n luyá»‡n há»c sinh báº±ng cÃ¡c Ä‘iá»ƒm sá»‘ Ä‘Æ°á»£c cung cáº¥p bá»Ÿi giÃ¡o viÃªn. ChÃºng tÃ´i sá»­ dá»¥ng hÃ m máº¥t mÃ¡t KL-divergence listwise sau:

ğ¿IKD=âˆ’âˆ‘ï¸‚
ğ‘ƒâ€²âˆˆPnegâˆª{ğ‘ƒğ‘ğ‘œğ‘ }ğ‘†â€²
ğ‘Œ((ğ‘„,ğ¼),ğ‘ƒâ€²)logğ‘†â€²
ğ‘‹((ğ‘„,ğ¼),ğ‘ƒâ€²)
ğ‘†â€²
ğ‘Œ((ğ‘„,ğ¼),ğ‘ƒâ€²)(4)

trong Ä‘Ã³ ğ‘‹ vÃ  ğ‘Œ láº§n lÆ°á»£t biá»ƒu thá»‹ mÃ´ hÃ¬nh há»c sinh vÃ  giÃ¡o viÃªn. ğ‘†â€²((ğ‘„,ğ¼),ğ‘ƒâ€²) lÃ  Ä‘iá»ƒm sá»‘ Ä‘Æ°á»£c chuáº©n hÃ³a cá»§a ğ‘†((ğ‘„,ğ¼),ğ‘ƒâ€²) cho ğ‘ƒâ€²âˆˆPnegâˆª{ğ‘ƒğ‘ğ‘œğ‘ } Ä‘Æ°á»£c táº¡o ra bá»Ÿi mÃ´ hÃ¬nh há»c sinh hoáº·c giÃ¡o viÃªn báº±ng hÃ m softmax. TÆ°Æ¡ng tá»± nhÆ° PhÆ°Æ¡ng trÃ¬nh (3), ğ‘ƒğ‘ğ‘œğ‘  lÃ  má»™t Ä‘oáº¡n vÄƒn tÃ­ch cá»±c, vÃ  cÃ¹ng phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c sá»­ dá»¥ng cho viá»‡c láº¥y máº«u tiÃªu cá»±c. ChÃºng tÃ´i tiáº¿p tá»¥c huáº¥n luyá»‡n há»c sinh báº±ng Ä‘iá»ƒm sá»‘ cá»§a giÃ¡o viÃªn cho Ä‘áº¿n khi tiÃªu chÃ­ dá»«ng Ä‘Æ°á»£c Ä‘Ã¡p á»©ng: hoáº·c ngÃ¢n sÃ¡ch tÃ­nh toÃ¡n káº¿t thÃºc (tá»©c lÃ  nÃ³ Ä‘áº¡t Ä‘áº¿n sá»‘ epoch tá»‘i Ä‘a Ä‘Æ°á»£c Ä‘áº·t trong thÃ­ nghiá»‡m) hoáº·c dá»«ng sá»›m dá»±a trÃªn hiá»‡u suáº¥t xÃ¡c thá»±c.

Trong vÃ²ng chÆ°ng cáº¥t tiáº¿p theo, chÃºng tÃ´i hoÃ¡n Ä‘á»•i giÃ¡o viÃªn vÃ  há»c sinh. NÃ³i cÃ¡ch khÃ¡c, há»c sinh cá»§a vÃ²ng trÆ°á»›c Ä‘Ã³ng vai trÃ² lÃ  giÃ¡o viÃªn trong vÃ²ng nÃ y Ä‘á»ƒ cung cáº¥p Ä‘iá»ƒm sá»‘ cho viá»‡c huáº¥n luyá»‡n giÃ¡o viÃªn trÆ°á»›c Ä‘Ã¢y trong vÃ²ng nÃ y. PhÆ°Æ¡ng phÃ¡p láº·p Ä‘i láº·p láº¡i nÃ y Ä‘á»‘i vá»›i chÆ°ng cáº¥t kiáº¿n thá»©c há»¯u Ã­ch vÃ¬, trong má»—i vÃ²ng, mÃ´ hÃ¬nh há»c sinh há»c Ä‘Æ°á»£c quan Ä‘iá»ƒm cá»§a mÃ´ hÃ¬nh giÃ¡o viÃªn trong viá»‡c cháº¥m Ä‘iá»ƒm tÃ i liá»‡u, Ä‘áº·c biá»‡t khi hai mÃ´ hÃ¬nh nÃ y dá»±a vÃ o hai khÃ´ng gian nhÃºng khÃ¡c nhau Ä‘á»ƒ táº¡o Ä‘iá»ƒm sá»‘. ChÃºng tÃ´i tiáº¿p tá»¥c quÃ¡ trÃ¬nh chÆ°ng cáº¥t láº·p Ä‘i láº·p láº¡i nÃ y vÃ  sá»­ dá»¥ng dá»«ng sá»›m dá»±a trÃªn hiá»‡u suáº¥t xÃ¡c thá»±c Ä‘á»ƒ káº¿t thÃºc.

4.4 Suy Luáº­n Truy Xuáº¥t sá»­ dá»¥ng MÃ£ HÃ³a KÃ©p
NhÆ° chÃºng tÃ´i Ä‘Ã£ Ä‘á» cáº­p trÆ°á»›c Ä‘Ã³, ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€, Ä‘Æ°á»£c giá»›i thiá»‡u trong cÃ¡c pháº§n trÆ°á»›c, truy xuáº¥t cÃ¡c Ä‘oáº¡n vÄƒn Ä‘á»ƒ Ä‘Ã¡p á»©ng má»™t truy váº¥n Ä‘a phÆ°Æ¡ng thá»©c báº±ng cÃ¡c khÃ´ng gian nhÃºng riÃªng biá»‡t. CÃ¡i trÆ°á»›c táº­p trung vÃ o khÃ´ng gian nhÃºng vÄƒn báº£n, trong khi cÃ¡i sau mÃ£ hÃ³a truy váº¥n vÃ  Ä‘oáº¡n vÄƒn vÃ o má»™t khÃ´ng gian nhÃºng Ä‘a phÆ°Æ¡ng thá»©c. Má»™t Ã½ tÆ°á»Ÿng Ä‘á»ƒ káº¿t há»£p hai mÃ´ hÃ¬nh nÃ y trong má»™t khÃ´ng gian nhÃºng duy nháº¥t lÃ  ná»‘i biá»ƒu diá»…n cá»§a má»—i mÃ´ hÃ¬nh cho cÃ¡c Ä‘áº§u vÃ o cá»§a nÃ³ láº¡i vá»›i nhau. Náº¿u má»—i bá»™ mÃ£ hÃ³a nÃ y táº¡o ra má»™t mÃ£ hÃ³a ğ‘‘-chiá»u cho má»—i Ä‘áº§u vÃ o, khÃ´ng gian nhÃºng cuá»‘i cÃ¹ng bao gá»“m 2ğ‘‘ chiá»u.

CÃ³ hai phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ sá»­ dá»¥ng khÃ´ng gian nhÃºng káº¿t há»£p nÃ y: (1) chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng biá»ƒu diá»…n Ä‘Æ°á»£c ná»‘i cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘á»ƒ huáº¥n luyá»‡n má»™t bá»™ xáº¿p háº¡ng má»›i tá»« Ä‘áº§u báº±ng hÃ m máº¥t mÃ¡t trong PhÆ°Æ¡ng trÃ¬nh 3, vÃ  (2) chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c bá»™ xáº¿p háº¡ng tá»‘t nháº¥t cá»§a má»—i loáº¡i sau chÆ°ng cáº¥t kiáº¿n thá»©c vÃ  káº¿t há»£p biá»ƒu diá»…n cá»§a chÃºng mÃ  khÃ´ng cáº§n huáº¥n luyá»‡n thÃªm Ä‘á»ƒ táº¡o ra biá»ƒu diá»…n cho truy váº¥n vÃ  Ä‘oáº¡n vÄƒn. CÃ¡i sau khÃ´ng cáº§n huáº¥n luyá»‡n vÃ¬ má»—i mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã³. ChÃºng tÃ´i chá»‰ káº¿t há»£p biá»ƒu diá»…n cá»§a chÃºng Ä‘á»ƒ láº­p chá»‰ má»¥c cÃ¡c nhÃºng báº±ng Faiss [22] vÃ  tÃ¬m kiáº¿m chá»‰ má»¥c Ä‘á»ƒ truy xuáº¥t Ä‘oáº¡n vÄƒn.

5 Há»¢P NHáº¤T ÄA PHÆ¯Æ NG THá»¨C TRONG Bá»˜ GIáº¢I MÃƒ
Fusion-in-Decoder (FiD) [20] lÃ  má»™t mÃ´ hÃ¬nh encoder-decoder táº¡o sinh tiÃªn tiáº¿n dá»±a trÃªn T5 [43]. NÃ³ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tá»•ng há»£p kiáº¿n thá»©c qua nhiá»u Ä‘oáº¡n vÄƒn vÃ  táº¡o ra má»™t pháº£n há»“i duy nháº¥t dá»±a trÃªn chÃºng. NÃ³ Ä‘Ã£ táº¡o ra hiá»‡u suáº¥t máº¡nh máº½ trÃªn má»™t loáº¡t rá»™ng cÃ¡c tÃ¡c vá»¥ ngÃ´n ngá»¯ Ä‘Ã²i há»i kiáº¿n thá»©c (KILTs). MÃ´ hÃ¬nh tiÃªn tiáº¿n hiá»‡n táº¡i trÃªn sÃ¡u benchmark tá»« báº£ng xáº¿p háº¡ng KILTâ¶ dá»±a trÃªn má»™t biáº¿n thá»ƒ nháº¹ cá»§a FiD [16]. ChÃºng tÃ´i má»Ÿ rá»™ng kiáº¿n trÃºc FiD cho dá»¯ liá»‡u Ä‘a phÆ°Æ¡ng thá»©c vÃ  Ä‘á» xuáº¥t MM-FiD.

Äá»ƒ hÃ¬nh thá»©c hÃ³a tÃ¡c vá»¥, Ä‘á»‘i vá»›i má»™t truy váº¥n bao gá»“m má»™t hÃ¬nh áº£nh ğ¼ vÃ  má»™t cÃ¢u há»i ğ‘„, chÃºng tÃ´i giáº£ Ä‘á»‹nh má»™t táº­p ğ‘ƒ={ğ‘1,...,ğ‘ğ‘›} bao gá»“m ğ‘› Ä‘oáº¡n vÄƒn há»— trá»£ Ä‘Æ°á»£c cung cáº¥p (vÃ­ dá»¥: bá»Ÿi má»™t mÃ´ hÃ¬nh truy xuáº¥t). Má»¥c tiÃªu cá»§a fusion-in-decoder Ä‘a phÆ°Æ¡ng thá»©c (MM-FiD) lÃ  táº¡o ra má»™t cÃ¢u tráº£ lá»i vÄƒn báº£n cho ğ‘„ vá» ğ¼ báº±ng cÃ¡ch xem xÃ©t táº¥t cáº£ cÃ¡c Ä‘oáº¡n vÄƒn trong ğ‘ƒ.

ChÃºng tÃ´i sá»­ dá»¥ng kiáº¿n trÃºc VL-T5 [6], má»™t mÃ´ hÃ¬nh thá»‹ giÃ¡c-ngÃ´n ngá»¯ táº¡o sinh vÄƒn báº£n Ä‘a phÆ°Æ¡ng thá»©c Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vá»›i cÃ¡c tÃ¡c vá»¥ táº¡o vÄƒn báº£n khÃ¡c nhau, lÃ m Ä‘iá»ƒm khá»Ÿi Ä‘áº§u Ä‘á»ƒ thiáº¿t káº¿ kiáº¿n trÃºc fusion-in-decoder Ä‘a phÆ°Æ¡ng thá»©c. VL-T5 nháº­n má»™t Ä‘oáº¡n vÄƒn báº£n vÃ  cÃ¡c Ä‘áº·c trÆ°ng cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng hÃ¬nh áº£nh Ä‘Æ°á»£c phÃ¡t hiá»‡n bá»Ÿi Faster R-CNN [45] lÃ m Ä‘áº§u vÃ o vÃ  táº¡o ra má»™t Ä‘oáº¡n vÄƒn báº£n lÃ m Ä‘áº§u ra. Giáº£i phÃ¡p Ä‘Æ¡n giáº£n nháº¥t cho cÃ´ng thá»©c váº¥n Ä‘á» Ä‘Ã£ Ä‘á» cáº­p trong pháº§n nÃ y lÃ  Ä‘Æ°a VL-T5 vá»›i sá»± ná»‘i káº¿t cá»§a cÃ¢u há»i, hÃ¬nh áº£nh vÃ  má»—i Ä‘oáº¡n vÄƒn Ä‘á»ƒ táº¡o ra má»™t cÃ¢u tráº£ lá»i dá»±a trÃªn má»—i tÃ i liá»‡u há»— trá»£; tuy nhiÃªn, viá»‡c tá»•ng há»£p vÃ  giáº£m thiá»ƒu cÃ¡c cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra cho má»—i tÃ i liá»‡u lÃ  thÃ¡ch thá»©c vÃ¬ mÃ´ hÃ¬nh cÃ³ thá»ƒ táº¡o ra má»™t cÃ¢u tráº£ lá»i khÃ¡c nhau cho má»—i tÃ i liá»‡u. Má»™t phÆ°Æ¡ng phÃ¡p khÃ¡c Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» lÃ  ná»‘i káº¿t cÃ¢u há»i, hÃ¬nh áº£nh vÃ  táº¥t cáº£ tÃ i liá»‡u vÃ  Ä‘Æ°a nÃ³ vÃ o VL-T5 Ä‘á»ƒ táº¡o ra má»™t cÃ¢u tráº£ lá»i duy nháº¥t dá»±a trÃªn chÃºng; phÆ°Æ¡ng phÃ¡p nÃ y gáº·p pháº£i hai thiáº¿u sÃ³t: (1) viá»‡c ná»‘i káº¿t táº¥t cáº£ cÃ¡c Ä‘oáº¡n vÄƒn dáº«n Ä‘áº¿n má»™t chuá»—i dÃ i, lÃ m giáº£m tá»‘c Ä‘á»™ cá»§a mÃ´ hÃ¬nh vÃ  tÄƒng tiÃªu thá»¥ bá»™ nhá»› vÃ  cÅ©ng cÃ³ thá»ƒ Ä‘áº¡t Ä‘áº¿n giá»›i háº¡n token tá»‘i Ä‘a, vÃ  (2) viá»‡c ná»‘i káº¿t cÃ¡c Ä‘oáº¡n vÄƒn khÃ¡c nhau láº¡i vá»›i nhau khiáº¿n mÃ´ hÃ¬nh khÃ³ xem xÃ©t ngá»¯ cáº£nh cá»§a má»—i Ä‘oáº¡n vÄƒn vÃ¬ táº­p Ä‘oáº¡n vÄƒn ğ‘ƒ cÃ³ thá»ƒ vá» cÃ¡c chá»§ Ä‘á» khÃ´ng liÃªn quan khÃ¡c nhau.

MM-FiD sá»­ dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p thay tháº¿, Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 4. Trong kiáº¿n trÃºc nÃ y, cÃ¢u há»i vÃ  hÃ¬nh áº£nh Ä‘Æ°á»£c ná»‘i káº¿t vá»›i má»—i tÃ i liá»‡u trong táº­p há»— trá»£ má»™t cÃ¡ch Ä‘á»™c láº­p vÃ  Ä‘Æ°á»£c Ä‘Æ°a vÃ o bá»™ mÃ£ hÃ³a cá»§a VL-T5 Ä‘á»ƒ Ä‘Æ°á»£c mÃ£ hÃ³a. Sau Ä‘Ã³, biá»ƒu diá»…n Ä‘Æ°á»£c mÃ£ hÃ³a cá»§a má»—i cÃ¢u há»i, hÃ¬nh áº£nh vÃ  má»—i Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c ná»‘i káº¿t láº¡i vá»›i nhau Ä‘á»ƒ Ä‘Æ°á»£c Ä‘Æ°a vÃ o bá»™ giáº£i mÃ£ cá»§a VL-T5. Trong phÆ°Æ¡ng phÃ¡p nÃ y, hÃ¬nh áº£nh, cÃ¢u há»i vÃ  má»—i tÃ i liá»‡u Ä‘Æ°á»£c mÃ£ hÃ³a riÃªng biá»‡t, giÃºp mÃ´ hÃ¬nh giáº£m sá»­ dá»¥ng bá»™ nhá»› vÃ  xem xÃ©t ngá»¯ cáº£nh tá»‘t hÆ¡n so vá»›i hai phÆ°Æ¡ng Ã¡n khÃ¡c Ä‘Ã£ Ä‘á» cáº­p á»Ÿ trÃªn. NgoÃ i ra, viá»‡c ná»‘i káº¿t cÃ¡c biá»ƒu diá»…n Ä‘Æ°á»£c mÃ£ hÃ³a cá»§a táº¥t cáº£ cÃ¡c Ä‘oáº¡n vÄƒn táº¡i bá»™ giáº£i mÃ£ giÃºp mÃ´ hÃ¬nh xem xÃ©t thÃ´ng tin trong táº¥t cáº£ tÃ i liá»‡u Ä‘á»ƒ táº¡o ra má»™t cÃ¢u tráº£ lá»i duy nháº¥t cho cÃ¢u há»i vá» hÃ¬nh áº£nh.

Äá»ƒ huáº¥n luyá»‡n MM-FiD cho viá»‡c táº¡o vÄƒn báº£n, chÃºng tÃ´i sá»­ dá»¥ng hÃ m máº¥t mÃ¡t cross-entropy vá»›i cÃ´ng thá»©c sau:

ğ¿mm-fid =âˆ’âˆ‘ï¸‚
ğ‘˜logğ‘ƒ(ğ‘¦ğ‘˜|ğ‘¦ğ‘–<ğ‘˜,{ğ¼,ğ‘„,ğ‘ 1},{ğ¼,ğ‘„,ğ‘ 2},...,{ğ¼,ğ‘„,ğ‘ğ‘›})

trong Ä‘Ã³ ğ‘¦ğ‘˜ lÃ  token Ä‘áº§u ra thá»© ğ‘˜, ğ¼ lÃ  hÃ¬nh áº£nh, ğ‘„ lÃ  cÃ¢u há»i, vÃ  ğ‘ğ‘– lÃ  Ä‘oáº¡n vÄƒn há»— trá»£ (vÃ­ dá»¥: Ä‘Æ°á»£c truy xuáº¥t) thá»© ğ‘–.

6 CÃC THÃ NGHIá»†M
6.1 Bá»™ Dá»¯ Liá»‡u
Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh Kiáº¿n Thá»©c BÃªn NgoÃ i (OK-VQA) [38]: Bá»™ dá»¯ liá»‡u nÃ y bao gá»“m cÃ¡c bá»™ ba, bao gá»“m má»™t hÃ¬nh áº£nh, má»™t cÃ¢u há»i vá» hÃ¬nh áº£nh vÃ  má»™t cÃ¢u tráº£ lá»i cho cÃ¢u há»i Ä‘Ã£ Ä‘á» cáº­p. Tráº£ lá»i háº§u háº¿t cÃ¡c cÃ¢u há»i trong bá»™ dá»¯ liá»‡u nÃ y cáº§n má»™t pháº§n thÃ´ng tin khÃ´ng Ä‘Æ°á»£c cung cáº¥p trong hÃ¬nh áº£nh. Do Ä‘Ã³, viá»‡c truy cáº­p má»™t nguá»“n thÃ´ng tin bÃªn ngoÃ i lÃ  cáº§n thiáº¿t cho tÃ¡c vá»¥ nÃ y. Má»™t bá»™ dá»¯ liá»‡u truy xuáº¥t dá»±a trÃªn má»™t báº£n dump Wikipediaâ· vá»›i 11 triá»‡u Ä‘oáº¡n vÄƒn sau Ä‘Ã³ Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi Qu et al. [40], mÃ  chÃºng tÃ´i sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c bá»™ truy xuáº¥t cá»§a chÃºng tÃ´i. Bá»™ dá»¯ liá»‡u nÃ y chá»©a 9009 cÃ¢u há»i Ä‘á»ƒ huáº¥n luyá»‡n, 2523 cÃ¢u há»i Ä‘á»ƒ xÃ¡c thá»±c vÃ  2523 Ä‘á»ƒ thá»­ nghiá»‡m [41]. ChÃºng tÃ´i cÅ©ng sá»­ dá»¥ng bá»™ dá»¯ liá»‡u OK-VQA gá»‘c Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a pipeline truy xuáº¥t vÃ  táº¡o cÃ¢u tráº£ lá»i end-to-end cá»§a chÃºng tÃ´i.

Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh Dá»±a TrÃªn Sá»± Tháº­t (FVQA) [56]: Má»—i Ä‘iá»ƒm dá»¯ liá»‡u trong bá»™ dá»¯ liá»‡u nÃ y bao gá»“m má»™t hÃ¬nh áº£nh, má»™t cÃ¢u há»i vá» hÃ¬nh áº£nh, cÃ¢u tráº£ lá»i vÃ  má»™t sá»± tháº­t há»— trá»£ cÃ¢u tráº£ lá»i. Bá»™ dá»¯ liá»‡u nÃ y cÅ©ng Ä‘Ã£ cung cáº¥p má»™t nguá»“n kiáº¿n thá»©c khÃ´ng cÃ³ cáº¥u trÃºc chá»©a táº¥t cáº£ cÃ¡c sá»± tháº­t (tá»©c lÃ  cÃ¢u) chÃºng ta cáº§n Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i vá» hÃ¬nh áº£nh. ChÃºng tÃ´i sá»­ dá»¥ng 70% máº«u (4077) trong bá»™ dá»¯ liá»‡u nÃ y cho táº­p huáº¥n luyá»‡n vÃ  tÄƒng cÆ°á»ng chÃºng tÆ°Æ¡ng tá»± nhÆ° Qu et al. [40] vá»›i nÄƒm tiÃªu cá»±c khÃ³ Ä‘Æ°á»£c truy xuáº¥t bá»Ÿi BM25, 15% Ä‘á»ƒ xÃ¡c thá»±c (874) vÃ  15% cho táº­p thá»­ nghiá»‡m (874). ChÃºng tÃ´i sá»­ dá»¥ng bá»™ dá»¯ liá»‡u FVQA gá»‘c Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a pipeline truy xuáº¥t vÃ  táº¡o cÃ¢u tráº£ lá»i end-to-end cá»§a chÃºng tÃ´i.

6.2 Thiáº¿t Láº­p ThÃ­ Nghiá»‡m
Thiáº¿t Láº­p Huáº¥n Luyá»‡n Bá»™ Truy Xuáº¥t. Trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i sá»­ dá»¥ng bá»™ tá»‘i Æ°u hÃ³a Adam [26] vá»›i kÃ­ch thÆ°á»›c batch lÃ  16 vÃ  tá»‘c Ä‘á»™ há»c lÃ  10â»âµ. ChÃºng tÃ´i sá»­ dá»¥ng má»™t bá»™ láº­p lá»‹ch tá»‘c Ä‘á»™ há»c tuyáº¿n tÃ­nh vá»›i 10% tá»•ng sá»‘ bÆ°á»›c nhÆ° cÃ¡c bÆ°á»›c khá»Ÿi Ä‘á»™ng. ChÃºng tÃ´i cÅ©ng sá»­ dá»¥ng gradient clipping vá»›i giÃ¡ trá»‹ 1.0. Äá»™ dÃ i Ä‘áº§u vÃ o tá»‘i Ä‘a cá»§a má»—i bá»™ mÃ£ hÃ³a Ä‘Æ°á»£c Ä‘áº·t thÃ nh 400 token. ChÃºng tÃ´i huáº¥n luyá»‡n má»—i mÃ´ hÃ¬nh trong 2 epoch trÃªn OK-VQA vÃ  4 epoch trÃªn FVQA. Táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn má»™t mÃ¡y vá»›i GPU Nvidia RTX8000 vá»›i 49GB bá»™ nhá»› vÃ  256GB RAM. ChÃºng tÃ´i sá»­ dá»¥ng Faiss [22] Ä‘á»ƒ láº­p chá»‰ má»¥c cÃ¡c nhÃºng Ä‘Ã£ há»c vá»›i má»™t chá»‰ má»¥c pháº³ng Ä‘á»ƒ truy xuáº¥t máº­t Ä‘á»™ hiá»‡u quáº£. Äá»‘i vá»›i BM25, Pyserini Ä‘Æ°á»£c sá»­ dá»¥ng.

Thiáº¿t Láº­p Huáº¥n Luyá»‡n Multi-Modal Fusion-in-Decoder. ChÃºng tÃ´i sá»­ dá»¥ng bá»™ tá»‘i Æ°u hÃ³a AdamW vá»›i kÃ­ch thÆ°á»›c batch lÃ  1 vá»›i 32 bÆ°á»›c tÃ­ch lÅ©y gradient, dáº«n Ä‘áº¿n kÃ­ch thÆ°á»›c batch hiá»‡u quáº£ lÃ  32. ChÃºng tÃ´i sá»­ dá»¥ng tá»‘c Ä‘á»™ há»c 5Ã—10â»âµ vÃ  suy giáº£m trá»ng sá»‘ 0.1 Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh MM-FiD. Vá»›i kÃ­ch thÆ°á»›c bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n, chÃºng tÃ´i sá»­ dá»¥ng bá»™ láº­p lá»‹ch tá»‘c Ä‘á»™ há»c tuyáº¿n tÃ­nh vá»›i 800 vÃ  200 bÆ°á»›c khá»Ÿi Ä‘á»™ng láº§n lÆ°á»£t cho cÃ¡c bá»™ dá»¯ liá»‡u OK-VQA vÃ  FVQA. ChÃºng tÃ´i huáº¥n luyá»‡n mÃ´ hÃ¬nh trong 5000 (OK-VQA) vÃ  2000 (FVQA) bÆ°á»›c cáº­p nháº­t gradient. ChÃºng tÃ´i táº¡o má»™t checkpoint cá»§a mÃ´ hÃ¬nh cá»© sau 500 bÆ°á»›c huáº¥n luyá»‡n vÃ  chá»n checkpoint tá»‘t nháº¥t dá»±a trÃªn hiá»‡u suáº¥t cá»§a nÃ³ trÃªn táº­p xÃ¡c thá»±c. ChÃºng tÃ´i cÅ©ng sá»­ dá»¥ng gradient clipping á»Ÿ 1.0 Ä‘á»ƒ huáº¥n luyá»‡n. Äá»™ dÃ i Ä‘áº§u vÃ o tá»‘i Ä‘a cá»§a bá»™ mÃ£ hÃ³a cá»§a má»—i cáº·p cÃ¢u há»i vÃ  Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c Ä‘áº·t thÃ nh 420 (OK-VQA) vÃ  64 (FVQA) token. VÃ¬ cÃ¡c cÃ¢u tráº£ lá»i trong cáº£ hai bá»™ dá»¯ liá»‡u Ä‘á»u ngáº¯n, chÃºng tÃ´i Ä‘áº·t Ä‘á»™ dÃ i Ä‘áº§u ra cá»§a MM-FiD thÃ nh 16. Bá»™ giáº£i mÃ£ cá»§a MM-FiD sá»­ dá»¥ng beam search [58] vá»›i kÃ­ch thÆ°á»›c beam lÃ  2 Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i. ChÃºng tÃ´i huáº¥n luyá»‡n MM-FiD báº±ng 32(OK-VQA) vÃ  5(FVQA) Ä‘oáº¡n vÄƒn há»— trá»£ cho má»—i cáº·p cÃ¢u há»i vÃ  hÃ¬nh áº£nh, trong Ä‘Ã³ cÃ¡c Ä‘oáº¡n vÄƒn há»— trá»£ Ä‘Æ°á»£c truy xuáº¥t báº±ng mÃ´ hÃ¬nh DEDR Ä‘Æ°á»£c Ä‘á» xuáº¥t. CÃ¡c thÃ­ nghiá»‡m MM-FiD Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn má»™t mÃ¡y vá»›i má»™t GPU Nvidia RTX8000 vá»›i 49GB bá»™ nhá»› vÃ  128GB RAM. Theo [56], chÃºng tÃ´i sá»­ dá»¥ng xÃ¡c thá»±c chÃ©o nÄƒm fold cho bá»™ dá»¯ liá»‡u FVQA. LÆ°u Ã½ ráº±ng chÃºng tÃ´i huáº¥n luyá»‡n má»™t DEDR riÃªng cho má»—i fold Ä‘á»ƒ trÃ¡nh rÃ² rá»‰ dá»¯ liá»‡u.

Metrics ÄÃ¡nh GiÃ¡. Äá»ƒ nháº¥t quÃ¡n vá»›i tÃ i liá»‡u, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c metrics phá»• biáº¿n Ä‘Æ°á»£c Ä‘á» xuáº¥t cho má»—i bá»™ dá»¯ liá»‡u. Theo Qu et al. [40], chÃºng tÃ´i sá»­ dá»¥ng mean reciprocal rank (MRR) vÃ  precision cá»§a nÄƒm tÃ i liá»‡u truy xuáº¥t hÃ ng Ä‘áº§u (MRR@5 vÃ  P@5) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t trÃªn bá»™ dá»¯ liá»‡u OK-VQA. ChÃºng tÃ´i sá»­ dá»¥ng MRR@5 vÃ  P@1 Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ truy xuáº¥t trÃªn bá»™ dá»¯ liá»‡u FVQA. VÃ¬ bá»™ dá»¯ liá»‡u FVQA chá»‰ cung cáº¥p má»™t Ä‘oáº¡n vÄƒn ground truth cho má»—i cÃ¢u há»i, chÃºng tÃ´i sá»­ dá»¥ng Precision@1 lÃ m metric Ä‘Ã¡nh giÃ¡. ChÃºng tÃ´i sá»­ dá»¥ng paired t-test hai Ä‘uÃ´i vá»›i hiá»‡u chá»‰nh Bonferroni Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª (p-value <0.05).

Äá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh táº¡o cÃ¢u tráº£ lá»i cho bá»™ dá»¯ liá»‡u OK-VQA, chÃºng tÃ´i tuÃ¢n theo script Ä‘Ã¡nh giÃ¡ chÃ­nh thá»©c Ä‘Æ°á»£c cung cáº¥p bá»Ÿi Marino et al. [38]. NÃ³ sá»­ dá»¥ng metric Ä‘Ã¡nh giÃ¡ cho tÃ¡c vá»¥ VQA [3], dá»±a vÃ o cÃ¡c chÃº thÃ­ch cá»§a con ngÆ°á»i. Äá»ƒ Ä‘Ã¡nh giÃ¡ trÃªn bá»™ dá»¯ liá»‡u FVQA, chÃºng tÃ´i tuÃ¢n theo Wang et al. [56] vÃ  sá»­ dá»¥ng Top-1 Accuracy hoáº·c Exact Match (EM) lÃ m metric Ä‘Ã¡nh giÃ¡, trong Ä‘Ã³ chÃºng tÃ´i chuyá»ƒn thÃ nh chá»¯ thÆ°á»ng vÃ  loáº¡i bá» cÃ¡c máº¡o tá»« (vÃ­ dá»¥: a, an, the) vÃ  dáº¥u cÃ¢u.

6.3 Káº¿t Quáº£ Truy Xuáº¥t Äoáº¡n VÄƒn cho CÃ¡c TÃ¡c Vá»¥ KI-VQA
Baseline. ChÃºng tÃ´i so sÃ¡nh khung truy xuáº¥t máº­t Ä‘á»™ Ä‘Æ°á»£c Ä‘á» xuáº¥t vá»›i cÃ¡c baseline sau:

â€¢MÃ´ HÃ¬nh Truy Xuáº¥t ThÆ°a Thá»›t (Khá»›p Thuáº­t Ngá»¯): ChÃºng tÃ´i sá»­ dá»¥ng hai baseline truy xuáº¥t thÆ°a thá»›t: (1) BM25: baseline nÃ y sá»­ dá»¥ng cÃ´ng thá»©c BM25 [47] vá»›i cÃ¡c cÃ¢u há»i lÃ m truy váº¥n, bá» qua cÃ¡c hÃ¬nh áº£nh, vÃ  cÃ¡c Ä‘oáº¡n vÄƒn lÃ m tÃ i liá»‡u. (2) BM25-Obj (CombMax): phÆ°Æ¡ng phÃ¡p nÃ y trÃ­ch xuáº¥t 36 Ä‘á»‘i tÆ°á»£ng tá»« hÃ¬nh áº£nh (cÃ¡c Ä‘á»‘i tÆ°á»£ng Ä‘Æ°á»£c táº¡o ra bá»Ÿi má»™t mÃ´ hÃ¬nh Faster R-CNN [45] Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn Visual Genome [2,27]) vÃ  ná»‘i káº¿t tÃªn cá»§a má»—i Ä‘á»‘i tÆ°á»£ng vá»›i cÃ¢u há»i lÃ m truy váº¥n vÃ  sá»­ dá»¥ng cÃ´ng thá»©c BM25 Ä‘á»ƒ truy xuáº¥t Ä‘oáº¡n vÄƒn. Sau Ä‘Ã³ nÃ³ sá»­ dá»¥ng CombMax [9,28] Ä‘á»ƒ tá»•ng há»£p 36 danh sÃ¡ch xáº¿p háº¡ng nÃ y.

--- TRANG 4 ---
SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan. Alireza Salemi, Juan Altmayer Pizzorno, vÃ  Hamed Zamani

HÃ¬nh 4: Kiáº¿n trÃºc cá»§a MM-FiD. NÃ³ sá»­ dá»¥ng bá»™ mÃ£ hÃ³a Ä‘a phÆ°Æ¡ng thá»©c Ä‘á»ƒ mÃ£ hÃ³a má»—i bá»™ ba cÃ¢u há»i-hÃ¬nh áº£nh-Ä‘oáº¡n vÄƒn riÃªng biá»‡t vÃ  sau Ä‘Ã³ ná»‘i káº¿t cÃ¡c mÃ£ hÃ³a cá»§a chÃºng lÃ m Ä‘áº§u vÃ o cho bá»™ giáº£i mÃ£ Ä‘á»ƒ tá»•ng há»£p kiáº¿n thá»©c vÃ  táº¡o cÃ¢u tráº£ lá»i.

Qu et al. [40] cÅ©ng khÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p tá»•ng há»£p xáº¿p háº¡ng khÃ¡c vÃ  CombMax Ä‘Æ°á»£c tÃ¬m tháº¥y lÃ  giáº£i phÃ¡p tá»‘t nháº¥t cho tÃ¡c vá»¥ nÃ y.

â€¢MÃ´ HÃ¬nh Truy Xuáº¥t Máº­t Äá»™ Äá»‘i Xá»©ng MÃ£ HÃ³a ÄÆ¡n: ChÃºng tÃ´i sá»­ dá»¥ng ba baseline trong danh má»¥c nÃ y: (3, 4) Dense-BERT: má»™t mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ dá»±a trÃªn BERT (tÆ°Æ¡ng tá»± nhÆ° DPR [23]) vá»›i cÃ¹ng má»¥c tiÃªu huáº¥n luyá»‡n nhÆ° cá»§a chÃºng tÃ´i. ChÃºng tÃ´i cung cáº¥p káº¿t quáº£ cho hai biáº¿n thá»ƒ cá»§a mÃ´ hÃ¬nh nÃ y, má»™t phÆ°Æ¡ng phÃ¡p Ä‘á»™c láº­p vá»›i hÃ¬nh áº£nh mÃ  bá»™ mÃ£ hÃ³a truy váº¥n chá»‰ mÃ£ hÃ³a cÃ¢u há»i, vÃ  má»™t phÆ°Æ¡ng phÃ¡p phá»¥ thuá»™c vÃ o hÃ¬nh áº£nh mÃ  bá»™ mÃ£ hÃ³a truy váº¥n nháº­n sá»± ná»‘i káº¿t cá»§a cÃ¢u há»i vÃ  chÃº thÃ­ch hÃ¬nh áº£nh (chÃº thÃ­ch Ä‘Æ°á»£c táº¡o ra bá»Ÿi ExpansionNet v2 [18]). CÃ¡i sau giá»‘ng nhÆ° bá»™ mÃ£ hÃ³a ğ¸ğ‘‡ cá»§a chÃºng tÃ´i. (5) Dense-LXMERT lÃ  má»™t mÃ´ hÃ¬nh sá»­ dá»¥ng má»™t bá»™ mÃ£ hÃ³a Ä‘a phÆ°Æ¡ng thá»©c, tá»©c lÃ  LXMERT, Ä‘á»ƒ mÃ£ hÃ³a truy váº¥n vÃ  Ä‘oáº¡n vÄƒn. NÃ³ sá»­ dá»¥ng cÃ¡c token hÃ¬nh áº£nh bá»‹ che á»Ÿ phÃ­a Ä‘oáº¡n vÄƒn. PhÆ°Æ¡ng phÃ¡p nÃ y lÃ  bá»™ mÃ£ hÃ³a ğ¸ğ‘€ğ‘€ cá»§a chÃºng tÃ´i.

â€¢MÃ´ HÃ¬nh Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a KÃ©p Báº¥t Äá»‘i Xá»©ng: Trong danh má»¥c nÃ y, chÃºng tÃ´i sá»­ dá»¥ng BERT-LXMERT, Ä‘Æ°á»£c Ä‘á» xuáº¥t trong [40], sá»­ dá»¥ng BERT Ä‘á»ƒ mÃ£ hÃ³a Ä‘oáº¡n vÄƒn vÃ  LXMERT Ä‘á»ƒ mÃ£ hÃ³a truy váº¥n.â¸

Äá»ƒ so sÃ¡nh cÃ´ng báº±ng, chÃºng tÃ´i sá»­ dá»¥ng cÃ¹ng quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ cho táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh (cá»§a chÃºng tÃ´i vÃ  baseline). Theo hiá»ƒu biáº¿t cá»§a chÃºng tÃ´i, káº¿t quáº£ baseline cá»§a chÃºng tÃ´i lÃ  cao nháº¥t Ä‘Æ°á»£c bÃ¡o cÃ¡o trong tÃ i liá»‡u.

So SÃ¡nh vá»›i CÃ¡c Baseline Truy Xuáº¥t. Káº¿t quáº£ truy xuáº¥t Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c bÃ¡o cÃ¡o trong Báº£ng 1. ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ nÃ³i chung vÆ°á»£t trá»™i hÆ¡n cÃ¡c baseline truy xuáº¥t thÆ°a thá»›t, xÃ¡c nháº­n lá»±a chá»n thiáº¿t káº¿ cá»§a chÃºng tÃ´i táº­p trung vÃ o truy xuáº¥t máº­t Ä‘á»™ cho cÃ¡c tÃ¡c vá»¥ KI-VQA. ThÃº vá»‹ lÃ , cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t thÆ°a thá»›t Ä‘áº¡t MRR cao hÆ¡n trÃªn FVQA so vá»›i OK-VQA, trong khi cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t máº­t Ä‘á»™ hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ trÃªn bá»™ dá»¯ liá»‡u OK-VQA. Quan sÃ¡t nÃ y cho tháº¥y ráº±ng cÃ¡c tÃ i liá»‡u liÃªn quan trong FVQA cÃ³ láº½ cÃ³ sá»± trÃ¹ng láº·p thuáº­t ngá»¯ cao hÆ¡n vá»›i cÃ¡c cÃ¢u há»i vÃ  Ä‘á»‘i tÆ°á»£ng hÃ¬nh áº£nh. Káº¿t quáº£ cho tháº¥y cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c láº­p vá»›i hÃ¬nh áº£nh (tá»©c lÃ  BM25 vÃ  Dense-BERT chá»‰ mÃ£ hÃ³a cÃ¢u há»i) hoáº¡t Ä‘á»™ng kÃ©m hÆ¡n biáº¿n thá»ƒ cá»§a chÃ­nh chÃºng vá»›i thÃ´ng tin hÃ¬nh áº£nh (tá»©c lÃ  cÃ¡c Ä‘á»‘i tÆ°á»£ng hoáº·c chÃº thÃ­ch Ä‘Æ°á»£c táº¡o ra). Äiá»u nÃ y nÃªu báº­t táº§m quan trá»ng cá»§a viá»‡c biá»ƒu diá»…n hÃ¬nh áº£nh trong cÃ¡c tÃ¡c vá»¥ KI-VQA. HÆ¡n ná»¯a, Báº£ng 1 cho tháº¥y ráº±ng baseline truy xuáº¥t máº­t Ä‘á»™ báº¥t Ä‘á»‘i xá»©ng (BERT-LXMERT) khÃ´ng hoáº¡t Ä‘á»™ng tá»‘t báº±ng cÃ¡c baseline truy xuáº¥t máº­t Ä‘á»™ Ä‘á»‘i xá»©ng. Cá»¥ thá»ƒ, BERT-LXMERT cho tháº¥y hiá»‡u suáº¥t kÃ©m trÃªn bá»™ dá»¯ liá»‡u FVQA. Äiá»u Ä‘Ã³ cÃ³ thá»ƒ do táº­p huáº¥n luyá»‡n nhá» hÆ¡n trong FVQA,â¹ vÃ¬ cÃ¡c mÃ´ hÃ¬nh báº¥t Ä‘á»‘i xá»©ng thÆ°á»ng yÃªu cáº§u nhiá»u dá»¯ liá»‡u huáº¥n luyá»‡n hÆ¡n.

Má»™t quan sÃ¡t khÃ¡c tá»« nhá»¯ng káº¿t quáº£ nÃ y lÃ  hiá»‡u suáº¥t trÃªn cÃ¡c táº­p xÃ¡c thá»±c vÃ  thá»­ nghiá»‡m tÆ°Æ¡ng Ä‘á»‘i gáº§n nhau, do Ä‘Ã³ cÃ³ thá»ƒ nÃ³i má»™t cÃ¡ch an toÃ n ráº±ng hiá»‡u suáº¥t trÃªn cÃ¡c táº­p xÃ¡c thá»±c cÃ³ thá»ƒ tá»•ng quÃ¡t hÃ³a cho cÃ¡c táº­p thá»­ nghiá»‡m vÃ  khÃ´ng quan sÃ¡t tháº¥y overfitting tÃ­ch cá»±c. Káº¿t quáº£ cho tháº¥y ráº±ng cÃ¡c bá»™ mÃ£ hÃ³a ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€ cá»§a chÃ­nh chÃºng tÃ´i lÃ  cÃ¡c baseline hoáº¡t Ä‘á»™ng tá»‘t nháº¥t. ChÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n má»™t thÃ­ nghiá»‡m Ä‘á»ƒ xem liá»‡u hai phÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a nÃ y cÃ³ cung cáº¥p thÃ´ng tin bá»• sung hay khÃ´ng. Äá»ƒ lÃ m Ä‘iá»u nÃ y, chÃºng tÃ´i tÃ­nh toÃ¡n reciprocal rank (RR) thu Ä‘Æ°á»£c bá»Ÿi ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€ cho má»—i truy váº¥n trong OK-VQA vÃ  váº½ sá»± khÃ¡c biá»‡t cá»§a chÃºng trong HÃ¬nh 5. Äá»ƒ hÃ¬nh dung tá»‘t hÆ¡n, hÃ¬nh nÃ y sáº¯p xáº¿p cÃ¡c truy váº¥n theo Î”ğ‘€ğ‘…ğ‘… cá»§a chÃºng theo thá»© tá»± giáº£m dáº§n. HÃ¬nh 5 cho tháº¥y ráº±ng ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€ hoáº¡t Ä‘á»™ng tÆ°Æ¡ng tá»± Ä‘á»‘i vá»›i khoáº£ng má»™t ná»­a sá»‘ truy váº¥n, trong khi ğ¸ğ‘‡ hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n Ä‘á»‘i vá»›i khoáº£ng 25% truy váº¥n vÃ  ğ¸ğ‘€ğ‘€ hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n Ä‘á»‘i vá»›i ~25% cÃ²n láº¡i. Äiá»u nÃ y cho tháº¥y hai bá»™ mÃ£ hÃ³a nÃ y chá»©a thÃ´ng tin bá»• sung vÃ  sá»± tá»•ng há»£p cá»§a chÃºng cÃ³ thá»ƒ cáº£i thiá»‡n káº¿t quáº£ â€“ xÃ¡c nháº­n Ä‘á»™ng lá»±c thiáº¿t káº¿ DEDR.

Káº¿t quáº£ thu Ä‘Æ°á»£c bá»Ÿi DEDR cho tháº¥y cÃ¡c cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª so vá»›i táº¥t cáº£ cÃ¡c baseline. ChÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c MRR cao hÆ¡n 11,6% vÃ  P@5 cao hÆ¡n 14,5% so vá»›i baseline tá»‘t nháº¥t (bao gá»“m

â¸BÃ i bÃ¡o gá»‘c [40] gá»i baseline nÃ y lÃ  Dense-LXMERT. ChÃºng tÃ´i Ä‘á»•i tÃªn thÃ nh BERT-LXMERT Ä‘á»ƒ trÃ¡nh nháº§m láº«n.

â¹FVQA khÃ´ng chá»‰ cÃ³ Ã­t cÃ¢u há»i huáº¥n luyá»‡n hÆ¡n, mÃ  chá»‰ cÃ³ má»™t Ä‘oáº¡n vÄƒn liÃªn quan cho má»—i cÃ¢u há»i.

--- TRANG 5 ---
Má»™t Khung Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a Äá»‘i Xá»©ng KÃ©p cho Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c ChuyÃªn SÃ¢u SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan.

Báº£ng 1: Hiá»‡u suáº¥t truy xuáº¥t Ä‘oáº¡n vÄƒn cho cÃ¡c tÃ¡c vá»¥ KI-VQA trÃªn cÃ¡c bá»™ dá»¯ liá»‡u OK-VQA vÃ  FVQA. Chá»‰ sá»‘ trÃªnâˆ— biá»ƒu thá»‹ cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª so vá»›i táº¥t cáº£ cÃ¡c baseline dá»±a trÃªn paired t-test hai Ä‘uÃ´i vá»›i hiá»‡u chá»‰nh Bonferroni (ğ‘<0.05).

| Bá»™ dá»¯ liá»‡u | OK-VQA | | | | FVQA | | | |
|---|---|---|---|---|---|---|---|---|
| MÃ´ hÃ¬nh | XÃ¡c thá»±c | | Thá»­ nghiá»‡m | | XÃ¡c thá»±c | | Thá»­ nghiá»‡m | |
| | MRR@5 | P@5 | MRR@5 | P@5 | MRR@5 | P@1 | MRR@5 | P@1 |
| **Bá»™ Truy Xuáº¥t ThÆ°a Thá»›t** | | | | | | | | |
| BM25 | 0.2565 | 0.1772 | 0.2637 | 0.1755 | 0.3368 | 0.2700 | 0.3509 | 0.2848 |
| BM25-Obj (CombMax) | 0.3772 | 0.2667 | 0.3686 | 0.2541 | 0.3903 | 0.3272 | 0.4057 | 0.3421 |
| **Bá»™ Truy Xuáº¥t Máº­t Äá»™ Äá»‘i Xá»©ng MÃ£ HÃ³a ÄÆ¡n** | | | | | | | | |
| Dense-BERT (cÃ¢u há»i, Ä‘oáº¡n vÄƒn) | 0.4555 | 0.3155 | 0.4325 | 0.3058 | 0.3860 | 0.3089 | 0.3836 | 0.3020 |
| Dense-BERT (cÃ¢u há»i + chÃº thÃ­ch, Ä‘oáº¡n vÄƒn) â†’ğ¸ğ‘‡ cá»§a chÃºng tÃ´i | 0.5843 | 0.4445 | 0.5797 | 0.4420 | 0.4409 | 0.3558 | 0.4292 | 0.3409 |
| Dense-LXMERTâ†’ğ¸ğ‘€ğ‘€ cá»§a chÃºng tÃ´i | 0.5722 | 0.4276 | 0.5465 | 0.4066 | 0.4293 | 0.3478 | 0.4269 | 0.3409 |
| **Bá»™ Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a KÃ©p Báº¥t Äá»‘i Xá»©ng** | | | | | | | | |
| BERT-LXMERT | 0.4704 | 0.3364 | 0.4526 | 0.3329 | 0.1455 | 0.1006 | 0.1477 | 0.1029 |
| **Bá»™ Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a KÃ©p Äá»‘i Xá»©ng** | | | | | | | | |
| DEDR | 0.6260âˆ— | 0.4890âˆ— | 0.6469âˆ— | 0.5059âˆ— | 0.5833âˆ— | 0.4931âˆ— | 0.5618âˆ— | 0.4713âˆ— |
| % cáº£i thiá»‡n tÆ°Æ¡ng Ä‘á»‘i so vá»›i baseline tá»‘t nháº¥t | 7.1%â†‘ | 10.0%â†‘ | 11.6%â†‘ | 14.5%â†‘ | 32.3%â†‘ | 38.6%â†‘ | 30.9%â†‘ | 37.8%â†‘ |

HÃ¬nh 5: Sá»± khÃ¡c biá»‡t giá»¯a reciprocal rank (RR) thu Ä‘Æ°á»£c bá»Ÿi ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€ cho má»—i truy váº¥n trÃªn táº­p thá»­ nghiá»‡m OK-VQA. MÃ u xanh / cam biá»ƒu thá»‹ cÃ¡c truy váº¥n mÃ  ğ¸ğ‘‡/ğ¸ğ‘€ğ‘€ tháº¯ng.

cÃ¡c bá»™ mÃ£ hÃ³a ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€ cá»§a chÃ­nh chÃºng tÃ´i) trÃªn táº­p thá»­ nghiá»‡m OK-VQA vÃ  MRR cao hÆ¡n 30,9% vÃ  P@1 cao hÆ¡n 37,8% trÃªn táº­p thá»­ nghiá»‡m FVQA. ChÃºng tÃ´i tin ráº±ng phÆ°Æ¡ng phÃ¡p mÃ£ hÃ³a Ä‘á»‘i xá»©ng kÃ©p cá»§a chÃºng tÃ´i hoáº¡t Ä‘á»™ng tá»‘t mÃ  khÃ´ng yÃªu cáº§u táº­p huáº¥n luyá»‡n quy mÃ´ lá»›n, Ä‘iá»u nÃ y biá»‡n minh cho lá»£i Ã­ch lá»›n hÆ¡n Ä‘Ã¡ng ká»ƒ trÃªn bá»™ dá»¯ liá»‡u FVQA. LÆ°u Ã½ ráº±ng DEDR cÅ©ng sá»­ dá»¥ng BERT vÃ  LXMERT vÃ  cÃ¡c cáº£i thiá»‡n thu Ä‘Æ°á»£c khÃ´ng pháº£i do cÃ¡c tham sá»‘ mÃ´ hÃ¬nh lá»›n hÆ¡n hoáº·c huáº¥n luyá»‡n trÆ°á»›c khÃ¡c nhau. Tuy nhiÃªn, so vá»›i Dense-BERT vÃ  Dense-LXMERT, DEDR cÃ³ kháº£ nÄƒng táº­n dá»¥ng kiáº¿n thá»©c tá»« cáº£ hai mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  Ä‘a phÆ°Æ¡ng thá»©c. Tuy nhiÃªn, BERT-LXMERT khÃ´ng thá»ƒ táº­n dá»¥ng "kiáº¿n thá»©c" áº©n bá»• sung nhÆ° váº­y má»™t cÃ¡ch hiá»‡u quáº£ do thiáº¿t káº¿ báº¥t Ä‘á»‘i xá»©ng cá»§a nÃ³.

Ablation DEDR. Äá»ƒ nghiÃªn cá»©u thá»±c nghiá»‡m tÃ¡c Ä‘á»™ng cá»§a má»—i quyáº¿t Ä‘á»‹nh chÃºng tÃ´i Ä‘Æ°a ra trong viá»‡c thiáº¿t káº¿ DEDR, chÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ ablation trong Báº£ng 2. HÃ ng Ä‘áº§u tiÃªn cá»§a báº£ng liÃªn quan Ä‘áº¿n má»™t mÃ´ hÃ¬nh sá»­ dá»¥ng chung cáº£ hai bá»™ mÃ£ hÃ³a (ğ¸ğ‘‡ vÃ  ğ¸ğ‘€ğ‘€) trong cáº£ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡. HÃ ng thá»© hai, máº·t khÃ¡c, huáº¥n luyá»‡n má»—i bá»™ mÃ£ hÃ³a riÃªng biá»‡t cho Ä‘áº¿n khi há»™i tá»¥ vÃ  chá»‰ ná»‘i káº¿t chÃºng khi suy luáº­n. KhÃ´ng cÃ³ chÆ°ng cáº¥t kiáº¿n thá»©c trong cáº£ hai mÃ´ hÃ¬nh nÃ y. Káº¿t quáº£ cho tháº¥y DEDR vÆ°á»£t trá»™i hÆ¡n cáº£ hai mÃ´ hÃ¬nh nÃ y, chá»©ng minh hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i Ä‘Æ°á»£c Ä‘á» xuáº¥t cho mÃ£ hÃ³a kÃ©p. CÃ¡c cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª trong gáº§n nhÆ° táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p, ngoáº¡i trá»« MRR@5 trÃªn táº­p xÃ¡c thá»±c OK-VQA. ChÃºng tÃ´i váº½ thÃªm hiá»‡u suáº¥t truy xuáº¥t táº¡i má»—i bÆ°á»›c huáº¥n luyá»‡n chÆ°ng cáº¥t kiáº¿n thá»©c trong HÃ¬nh 6. ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng trong ba láº§n láº·p Ä‘áº§u tiÃªn, hiá»‡u suáº¥t cá»§a cáº£ hai bá»™ mÃ£ hÃ³a nÃ³i chung tÄƒng lÃªn trÃªn cáº£ hai bá»™ dá»¯ liá»‡u. CÃ¡c mÃ´ hÃ¬nh cho tháº¥y hÃ nh vi khÃ¡c nhau trÃªn cÃ¡c bá»™ dá»¯ liá»‡u khÃ¡c nhau trong HÃ¬nh 6. Äiá»u nÃ y cho tháº¥y ráº±ng sá»‘ láº§n láº·p trong phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c phá»¥ thuá»™c vÃ o bá»™ dá»¯ liá»‡u vÃ  nÃªn Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t.

6.4 Káº¿t Quáº£ Tráº£ Lá»i CÃ¢u Há»i cho KI-VQA
Trong pháº§n nÃ y, chÃºng tÃ´i bÃ¡o cÃ¡o vÃ  tháº£o luáº­n vá» káº¿t quáº£ truy xuáº¥t vÃ  táº¡o cÃ¢u tráº£ lá»i end-to-end. Má»™t loáº¡t rá»™ng cÃ¡c phÆ°Æ¡ng phÃ¡p tráº£ lá»i cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c tÃ¡c vá»¥ KI-VQA. KhÃ´ng pháº£i táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y Ä‘á»u cÃ³ sáºµn cÃ´ng khai vÃ  khÃ´ng pháº£i táº¥t cáº£ Ä‘á»u sá»­ dá»¥ng cÃ¹ng nguá»“n kiáº¿n thá»©c. ChÃºng tÃ´i so sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p cá»§a mÃ¬nh vá»›i cÃ¡c mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t nháº¥t trong tÃ i liá»‡u vá»›i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh tÆ°Æ¡ng Ä‘á»‘i tÆ°Æ¡ng tá»±. LÆ°u Ã½ ráº±ng MM-FiD chá»©a 220 triá»‡u tham sá»‘. Trong táº­p thÃ­ nghiá»‡m Ä‘áº§u tiÃªn cá»§a chÃºng tÃ´i, chÃºng tÃ´i cÅ©ng loáº¡i trá»« cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng GPT-3 (175 tá»· tham sá»‘) nhÆ° má»™t nguá»“n "kiáº¿n thá»©c" áº©n. Káº¿t quáº£ Ä‘Æ°á»£c bÃ¡o cÃ¡o trong Báº£ng 3. NhÆ° Ä‘Ã£ Ä‘á» cáº­p trong báº£ng, cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau trÃªn OK-VQA sá»­ dá»¥ng cÃ¡c nguá»“n kiáº¿n thá»©c khÃ¡c nhau, nhÆ° ConceptNet, Wikidata, Wikipedia, Google Search vÃ  Google Images. Bá»™ dá»¯ liá»‡u FVQA Ä‘Ã£ phÃ¡t hÃ nh má»™t corpus sá»± tháº­t Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi má»™t sá»‘ mÃ´ hÃ¬nh. ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng MM-FiD sá»­ dá»¥ng cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c truy xuáº¥t bá»Ÿi DEDR Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i vÆ°á»£t trá»™i hÆ¡n táº¥t cáº£ cÃ¡c baseline Ä‘Æ°á»£c liá»‡t kÃª trong Báº£ng 3. ChÃºng tÃ´i quan sÃ¡t tháº¥y cáº£i thiá»‡n 8,5% trÃªn FVQA so vá»›i baseline hoáº¡t Ä‘á»™ng tá»‘t nháº¥t. Báº£ng nÃ y cÅ©ng bao gá»“m káº¿t quáº£ cho MM-FiD mÃ  khÃ´ng cÃ³ báº¥t ká»³ tÃ i liá»‡u há»— trá»£ nÃ o (tá»©c lÃ  khÃ´ng cÃ³ truy xuáº¥t). ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng MM-FiD cÃ³ thá»ƒ táº¡o ra hiá»‡u suáº¥t cáº¡nh tranh ngay cáº£ khi khÃ´ng sá»­ dá»¥ng káº¿t quáº£ truy xuáº¥t. LÃ½ do lÃ  cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nÃ y chá»©a ráº¥t nhiá»u thÃ´ng tin trong cÃ¡c tham sá»‘ cá»§a chÃºng tá»« giai Ä‘oáº¡n huáº¥n luyá»‡n trÆ°á»›c vÃ  chÃºng cÃ³ thá»ƒ tráº£ lá»i nhiá»u cÃ¢u há»i dá»±a trÃªn "kiáº¿n thá»©c" áº©n bÃªn trong cá»§a chÃºng. MM-FiD khÃ´ng cÃ³ truy xuáº¥t tháº­m chÃ­ cÃ²n vÆ°á»£t trá»™i hÆ¡n táº¥t cáº£ cÃ¡c baseline trÃªn OK-VQA. LÆ°u Ã½ ráº±ng sá»‘ lÆ°á»£ng tham sá»‘ trong MM-FiD (220M) cÃ³ thá»ƒ so sÃ¡nh vá»›i cÃ¡c baseline. Káº¿t quáº£ cho tháº¥y ráº±ng viá»‡c sá»­ dá»¥ng káº¿t quáº£ truy xuáº¥t dáº«n Ä‘áº¿n lá»£i Ã­ch lá»›n hÆ¡n trÃªn FVQA so vá»›i OK-VQA, cÃ³ thá»ƒ do báº£n cháº¥t cá»§a cÃ¡c cÃ¢u há»i trong tráº£ lá»i cÃ¢u há»i hÃ¬nh áº£nh dá»±a trÃªn sá»± tháº­t.

LÆ°u Ã½ ráº±ng má»™t sá»‘ mÃ´ hÃ¬nh sá»­ dá»¥ng cÃ¡c Ä‘áº§u ra Ä‘Æ°á»£c táº¡o ra bá»Ÿi GPT-3 nhÆ° má»™t nguá»“n kiáº¿n thá»©c vÃ  thÆ°á»ng vÆ°á»£t trá»™i hÆ¡n nhá»¯ng mÃ´ hÃ¬nh á»Ÿ trÃªn sá»­ dá»¥ng kiáº¿n thá»©c rÃµ rÃ ng. Tuy nhiÃªn, khÃ³ Ä‘á»ƒ rÃºt ra káº¿t luáº­n, vÃ¬ táº­p huáº¥n luyá»‡n GPT-3 khÃ´ng Ä‘Æ°á»£c biáº¿t vÃ  nÃ³ cÃ³ 175B tham sá»‘, khiáº¿n nÃ³ cá»±c ká»³ Ä‘áº¯t Ä‘á» Ä‘á»ƒ cháº¡y vÃ  khÃ´ng thá»±c sá»± cÃ³ thá»ƒ so sÃ¡nh vá»›i báº¥t ká»³ mÃ´ hÃ¬nh nÃ o khÃ¡c Ä‘Æ°á»£c Ä‘á» cáº­p á»Ÿ trÃªn vá» kháº£ nÄƒng. DÃ¹ váº­y, chÃºng tÃ´i váº«n so sÃ¡nh mÃ´ hÃ¬nh cá»§a mÃ¬nh vá»›i cÃ¡c baseline tiÃªn tiáº¿n vá»›i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh cÃ³ thá»ƒ so sÃ¡nh sá»­ dá»¥ng Ä‘áº§u ra cá»§a GPT-3 lÃ m báº±ng chá»©ng há»— trá»£. Káº¿t quáº£ trÃªn bá»™ dá»¯ liá»‡u OK-VQA Ä‘Æ°á»£c bÃ¡o cÃ¡o trong Báº£ng 4.Â¹â° Khi mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i sá»­ dá»¥ng Ä‘áº§u ra cá»§a GPT-3 ngoÃ i cÃ¡c Ä‘oáº¡n vÄƒn, nÃ³ váº«n vÆ°á»£t trá»™i hÆ¡n cÃ¡c phÆ°Æ¡ng Ã¡n thay tháº¿, nhÆ°ng vá»›i biÃªn Ä‘á»™ nhá» hÆ¡n, nÃªu báº­t tÃ¡c Ä‘á»™ng cá»§a cháº¥t lÆ°á»£ng tÃ i liá»‡u trong cÃ¡c tÃ¡c vá»¥ KI-VQA.

Ablation vÃ  PhÃ¢n TÃ­ch Tráº£ Lá»i CÃ¢u Há»i. Äá»ƒ hiá»ƒu sÃ¢u hÆ¡n vá» giáº£i phÃ¡p táº¡o cÃ¢u tráº£ lá»i Ä‘Æ°á»£c Ä‘á» xuáº¥t, chÃºng tÃ´i thá»±c hiá»‡n cÃ¡c nghiÃªn cá»©u ablation cáº©n tháº­n cÃ³ káº¿t quáº£ Ä‘Æ°á»£c bÃ¡o cÃ¡o trong Báº£ng 5. Káº¿t quáº£ trÃªn cáº£ hai bá»™ dá»¯ liá»‡u cho tháº¥y ráº±ng khi sá»­ dá»¥ng cÃ¹ng

Â¹â°ChÃºng tÃ´i khÃ´ng cÃ³ quyá»n truy cáº­p vÃ o Ä‘áº§u ra cá»§a GPT-3 cho cÃ¡c cÃ¢u há»i FVQA.

--- TRANG 6 ---
SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan. Alireza Salemi, Juan Altmayer Pizzorno, vÃ  Hamed Zamani

Báº£ng 2: NghiÃªn cá»©u ablation cho chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i trong DEDR. Chá»‰ sá»‘ trÃªnâˆ— biá»ƒu thá»‹ cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª so vá»›i táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p ablation dá»±a trÃªn paired t-test hai Ä‘uÃ´i vá»›i hiá»‡u chá»‰nh Bonferroni (ğ‘<0.05).

| Bá»™ dá»¯ liá»‡u | OK-VQA | | | | FVQA | | | |
|---|---|---|---|---|---|---|---|---|
| MÃ´ hÃ¬nh | XÃ¡c thá»±c | | Thá»­ nghiá»‡m | | XÃ¡c thá»±c | | Thá»­ nghiá»‡m | |
| | MRR@5 | P@5 | MRR@5 | P@5 | MRR@5 | P@1 | MRR@5 | P@1 |
| DEDR (bá»™ mÃ£ hÃ³a chung, khÃ´ng KD) | 0.5930 | 0.4507 | 0.5405 | 0.4263 | 0.4669 | 0.3764 | 0.4498 | 0.3684 |
| DEDR (bá»™ mÃ£ hÃ³a riÃªng biá»‡t, khÃ´ng KD) | 0.6236 | 0.4771 | 0.6330 | 0.4972 | 0.5551 | 0.4668 | 0.5313 | 0.4439 |
| DEDR | 0.6260 | 0.4890âˆ— | 0.6469âˆ— | 0.5059âˆ— | 0.5833âˆ— | 0.4931âˆ— | 0.5618âˆ— | 0.4713âˆ— |

HÃ¬nh 6: Hiá»‡u suáº¥t DEDR táº¡i cÃ¡c láº§n láº·p khÃ¡c nhau cá»§a phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i Ä‘Æ°á»£c Ä‘á» xuáº¥t trÃªn táº­p thá»­ nghiá»‡m cá»§a cáº£ hai bá»™ dá»¯ liá»‡u OK-VQA vÃ  FVQA.

bá»™ truy xuáº¥t (tá»©c lÃ  DEDR), MM-FiD vÆ°á»£t trá»™i hÆ¡n biáº¿n thá»ƒ Ä‘Æ¡n phÆ°Æ¡ng thá»©c cá»§a nÃ³, FiD [20], cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c tÃ¡c vá»¥ KI-VQA, vÃ­ dá»¥ trong KAT [13]. HÆ¡n ná»¯a, Báº£ng 5 chá»©ng minh tÃ¡c Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t khÃ¡c nhau Ä‘á»‘i vá»›i viá»‡c táº¡o cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng. VÃ­ dá»¥, viá»‡c sá»­ dá»¥ng DEDR Ä‘á»ƒ truy xuáº¥t thay vÃ¬ baseline truy xuáº¥t hoáº¡t Ä‘á»™ng tá»‘t nháº¥t tá»« Báº£ng 1 sáº½ dáº«n Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n 13% trong FVQA, nÃªu báº­t táº§m quan trá»ng cá»§a truy xuáº¥t trong pipeline KI-VQA.

HÃ¬nh 7 váº½ Ä‘á»™ nháº¡y cá»§a hiá»‡u suáº¥t MM-FiD Ä‘á»‘i vá»›i sá»‘ lÆ°á»£ng Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c truy xuáº¥t bá»Ÿi DEDR. NÃ³ cÅ©ng váº½ tá»· lá»‡ hit, tá»©c lÃ  tá»· lá»‡ thÃ nh cÃ´ng trong viá»‡c truy xuáº¥t Ã­t nháº¥t má»™t Ä‘oáº¡n vÄƒn liÃªn quan Ä‘á»ƒ Ä‘Æ°á»£c trÃ¬nh bÃ y cho MM-FiD. NÃ³i chung, cÃ ng nhiá»u tÃ i liá»‡u chÃºng ta Ä‘Æ°a vÃ o MM-FiD trÃªn OK-VQA, Ä‘á»™ chÃ­nh xÃ¡c tráº£ lá»i cÃ¢u há»i cÃ ng cao. Äá»™ chÃ­nh xÃ¡c cá»§a nÃ³ trá»Ÿ nÃªn tÆ°Æ¡ng Ä‘á»‘i á»•n Ä‘á»‹nh sau khi truy xuáº¥t 16 tÃ i liá»‡u. ÄÆ°á»ng cong Ä‘á»™ chÃ­nh xÃ¡c tuÃ¢n theo hÃ nh vi tÆ°Æ¡ng tá»± nhÆ° Ä‘Æ°á»ng cong hit trÃªn OK-VQA. Tuy nhiÃªn, FVQA thá»ƒ hiá»‡n hÃ nh vi khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ. Äá»™ chÃ­nh xÃ¡c cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c khi chá»‰ truy xuáº¥t nÄƒm Ä‘oáº¡n vÄƒn há»— trá»£. Äiá»u Ä‘Ã³ lÃ  do báº£n cháº¥t cá»§a bá»™ dá»¯ liá»‡u, nÆ¡i chá»‰ cÃ³ má»™t sá»± tháº­t liÃªn quan cho má»—i cÃ¢u há»i vÃ  viá»‡c truy xuáº¥t nhiá»u sá»± tháº­t (cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c) hÆ¡n cÃ³ thá»ƒ lÃ m nháº§m láº«n mÃ´ hÃ¬nh táº¡o cÃ¢u tráº£ lá»i. LÆ°u Ã½ ráº±ng DEDR Ä‘áº¡t tá»· lá»‡ hit 70% chá»‰ báº±ng cÃ¡ch truy xuáº¥t hai Ä‘oáº¡n vÄƒn trÃªn FVQA, trong khi cÃ¹ng mÃ´ hÃ¬nh cáº§n truy xuáº¥t 4 Ä‘oáº¡n vÄƒn Ä‘á»ƒ Ä‘áº¡t cÃ¹ng má»©c tá»· lá»‡ hit trÃªn OK-VQA. PhÃ¡t hiá»‡n nÃ y cho tháº¥y ráº±ng viá»‡c nghiÃªn cá»©u dá»± Ä‘oÃ¡n tá»± Ä‘á»™ng ranking cut-off cho cÃ¡c tÃ¡c vá»¥ KI-VQA trong tÆ°Æ¡ng lai lÃ  Ä‘Ã¡ng giÃ¡.

7 Káº¾T LUáº¬N VÃ€ CÃ”NG VIá»†C TÆ¯Æ NG LAI
BÃ i bÃ¡o nÃ y trÃ¬nh bÃ y DEDR, má»™t khung truy xuáº¥t máº­t Ä‘á»™ Ä‘á»‘i xá»©ng má»›i dá»±a trÃªn mÃ£ hÃ³a Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  Ä‘a phÆ°Æ¡ng thá»©c kÃ©p. ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i Ä‘á»ƒ cáº­p nháº­t hai khÃ´ng gian biá»ƒu diá»…n mÃ£ hÃ³a nÃ y vÃ  tá»•ng há»£p chÃºng khi suy luáº­n. NÃ³ cÅ©ng Ä‘á» xuáº¥t MM-FiD, má»™t pháº§n má»Ÿ rá»™ng cá»§a kiáº¿n trÃºc fusion-in-decoder [20] cho dá»¯ liá»‡u Ä‘a phÆ°Æ¡ng thá»©c. CÃ¡c thÃ­ nghiá»‡m toÃ n diá»‡n trÃªn hai bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c thiáº¿t láº­p tá»‘t, OK-VQA vÃ  FVQA, cho tháº¥y ráº±ng viá»‡c truy xuáº¥t Ä‘oáº¡n vÄƒn báº±ng DEDR vÃ  sá»­ dá»¥ng chÃºng Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i thÃ´ng qua MM-FiD vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c baseline tiÃªn tiáº¿n vá»›i kháº£ nÄƒng tÆ°Æ¡ng Ä‘Æ°Æ¡ng. VÃ­ dá»¥, phÆ°Æ¡ng phÃ¡p nÃ y dáº«n Ä‘áº¿n cáº£i thiá»‡n truy xuáº¥t 37,8% vá» P@1 vÃ  cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c exact match 8,5% trÃªn táº­p thá»­ nghiá»‡m FVQA so vá»›i cÃ¡c baseline hoáº¡t Ä‘á»™ng tá»‘t nháº¥t. ChÃºng tÃ´i chá»©ng minh tÃ¡c Ä‘á»™ng cá»§a má»i quyáº¿t Ä‘á»‹nh thiáº¿t káº¿ chÃºng tÃ´i Ä‘Æ°a ra trong cáº£ DEDR vÃ  MM-FiD thÃ´ng qua cÃ¡c nghiÃªn cá»©u ablation toÃ n diá»‡n vÃ  nÃªu báº­t cÃ¡c lÄ©nh vá»±c má»Ÿ Ä‘á»ƒ khÃ¡m phÃ¡ trong tÆ°Æ¡ng lai. VÃ­ dá»¥, káº¿t quáº£ cá»§a chÃºng tÃ´i cho tháº¥y dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c vá» 'khi nÃ o nÃªn truy xuáº¥t' lÃ  má»™t lÄ©nh vá»±c cÃ³ tÃ¡c Ä‘á»™ng Ä‘á»‘i vá»›i cÃ¡c tÃ¡c vá»¥ KI-VQA. Do Ä‘Ã³, viá»‡c khÃ¡m phÃ¡ dá»± Ä‘oÃ¡n hiá»‡u suáº¥t truy xuáº¥t vÃ  cáº¯t ngáº¯n ranking cut-off trong cÃ¡c tÃ¡c vá»¥ KI-VQA cÃ³ thá»ƒ lÃ  má»™t hÆ°á»›ng tÆ°Æ¡ng lai cÃ³ káº¿t quáº£. ChÃºng tÃ´i cÅ©ng cÃ³ Ã½ Ä‘á»‹nh khÃ¡m phÃ¡ cÃ¡c mÃ´ hÃ¬nh Ä‘Ã²i há»i kiáº¿n thá»©c toÃ n cáº§u cho cáº£ Ä‘áº§u vÃ o vÄƒn báº£n vÃ  Ä‘a phÆ°Æ¡ng thá»©c. ChÃºng tÃ´i tiáº¿p tá»¥c cÃ³ káº¿ hoáº¡ch má»Ÿ rá»™ng cÃ¡c á»©ng dá»¥ng cá»§a cÃ¡c tÃ¡c vá»¥ Ä‘a phÆ°Æ¡ng thá»©c Ä‘Ã²i há»i kiáº¿n thá»©c ngoÃ i tráº£ lá»i cÃ¢u há»i.

--- TRANG 7 ---
Má»™t Khung Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a Äá»‘i Xá»©ng KÃ©p cho Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c ChuyÃªn SÃ¢u SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan.

Báº£ng 3: Hiá»‡u suáº¥t tráº£ lá»i cÃ¢u há»i cho cÃ¡c mÃ´ hÃ¬nh vá»›i nguá»“n kiáº¿n thá»©c rÃµ rÃ ng trÃªn cáº£ hai bá»™ dá»¯ liá»‡u OK-VQA vÃ  FVQA. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh nÃ y tÆ°Æ¡ng Ä‘á»‘i cÃ³ thá»ƒ so sÃ¡nh vá» kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh vÃ  chá»©a Ã­t hÆ¡n 1 tá»· tham sá»‘.

| OK-VQA | | FVQA | |
|---|---|---|---|
| MÃ´ hÃ¬nh | Nguá»“n Kiáº¿n thá»©c | Äá»™ chÃ­nh xÃ¡c | MÃ´ hÃ¬nh | Nguá»“n Kiáº¿n thá»©c | Äá»™ chÃ­nh xÃ¡c Top-1 |
| KAT-base [13] | WikiData | 40.93 | BAN [25] | KhÃ´ng cÃ³ | 35.69 |
| RVL [50] | ConceptNet | 39.04 | RVL [50] | ConceptNet | 54.27 |
| MAVEx [57] | Wikipedia, ConceptNet, Google Images | 40.28 | BAN [25] + KG-AUG [29] | KhÃ´ng cÃ³ | 38.58 |
| UnifER+ViLT [14] | ConceptNet | 42.13 | UnifER + ViLT [14] | FVQA Corpus | 55.04 |
| VRR [35] | Google Search | 39.20 | Top1-QQmaping [56] | FVQA Corpus | 52.56 |
| LaKo-base [5] | ConceptNet, DBPedia, WebChild | 42.21 | Top3-QQmaping [56] | FVQA Corpus | 56.91 |
| MM-FiD | KhÃ´ng cÃ³ | 42.82 | MM-FiD | KhÃ´ng cÃ³ | 52.78 |
| DEDR +MM-FiD | Wikipedia | 44.57 | DEDR +MM-FiD | FVQA Corpus | 61.80 |
| % cáº£i thiá»‡n tÆ°Æ¡ng Ä‘á»‘i so vá»›i baseline tá»‘t nháº¥t | | 5.5%â†‘ | % cáº£i thiá»‡n tÆ°Æ¡ng Ä‘á»‘i so vá»›i baseline tá»‘t nháº¥t | | 8.5%â†‘ |

Báº£ng 4: Hiá»‡u suáº¥t QA cá»§a cÃ¡c mÃ´ hÃ¬nh SOTA dá»±a vÃ o Ä‘áº§u ra cá»§a GPT-3 nhÆ° má»™t "nguá»“n kiáº¿n thá»©c" trÃªn OK-VQA.

| MÃ´ hÃ¬nh | Nguá»“n kiáº¿n thá»©c | Äá»™ chÃ­nh xÃ¡c |
|---|---|---|
| PICa-full [60] | Frozen GPT-3 | 48.00 |
| KAT-base [13] | Frozen GPT-3, Wikidata | 50.58 |
| DEDR + MM-FiD | Frozen GPT-3, Wikipedia | 51.02 |

Báº£ng 5: NghiÃªn cá»©u ablation cá»§a pipeline KI-VQA Ä‘Æ°á»£c Ä‘á» xuáº¥t. Chá»‰ sá»‘ trÃªnâˆ— biá»ƒu thá»‹ cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª so vá»›i táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p ablation dá»±a trÃªn paired t-test hai Ä‘uÃ´i vá»›i hiá»‡u chá»‰nh Bonferroni (ğ‘<0.05).

| Bá»™ Truy Xuáº¥t | Bá»™ Táº¡o CÃ¢u Tráº£ Lá»i | OK-VQA | FVQA |
|---|---|---|---|
| | | Äá»™ chÃ­nh xÃ¡c | Äá»™ chÃ­nh xÃ¡c Top-1 |
| DEDR | FiD | 39.48 | 60.85 |
| BM25-Obj (CombMax) [40] | MM-FiD | 41.97 | 54.65 |
| Baseline truy xuáº¥t tá»‘t nháº¥t tá»« Báº£ng 1 | MM-FiD | 41.82 | 52.78 |
| DEDR | MM-FiD | 44.57âˆ— | 61.80âˆ— |

HÃ¬nh 7: Äá»™ chÃ­nh xÃ¡c MM-FiD vÃ  tá»· lá»‡ hit trong cÃ¡c Ä‘oáº¡n vÄƒn há»— trá»£ táº¡i cÃ¡c má»©c cáº¯t ngáº¯n xáº¿p háº¡ng khÃ¡c nhau.

bá»™ truy xuáº¥t (tá»©c lÃ  DEDR), MM-FiD vÆ°á»£t trá»™i hÆ¡n biáº¿n thá»ƒ Ä‘Æ¡n phÆ°Æ¡ng thá»©c cá»§a nÃ³, FiD [20], cÅ©ng Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c tÃ¡c vá»¥ KI-VQA, vÃ­ dá»¥ trong KAT [13]. HÆ¡n ná»¯a, Báº£ng 5 chá»©ng minh tÃ¡c Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh truy xuáº¥t khÃ¡c nhau Ä‘á»‘i vá»›i viá»‡c táº¡o cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng. VÃ­ dá»¥, viá»‡c sá»­ dá»¥ng DEDR Ä‘á»ƒ truy xuáº¥t thay vÃ¬ baseline truy xuáº¥t hoáº¡t Ä‘á»™ng tá»‘t nháº¥t tá»« Báº£ng 1 sáº½ dáº«n Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n 13% trong FVQA, nÃªu báº­t táº§m quan trá»ng cá»§a truy xuáº¥t trong pipeline KI-VQA.

HÃ¬nh 7 váº½ Ä‘á»™ nháº¡y cá»§a hiá»‡u suáº¥t MM-FiD Ä‘á»‘i vá»›i sá»‘ lÆ°á»£ng Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c truy xuáº¥t bá»Ÿi DEDR. NÃ³ cÅ©ng váº½ tá»· lá»‡ hit, tá»©c lÃ  tá»· lá»‡ thÃ nh cÃ´ng trong viá»‡c truy xuáº¥t Ã­t nháº¥t má»™t Ä‘oáº¡n vÄƒn liÃªn quan Ä‘á»ƒ Ä‘Æ°á»£c trÃ¬nh bÃ y cho MM-FiD. NÃ³i chung, cÃ ng nhiá»u tÃ i liá»‡u chÃºng ta Ä‘Æ°a vÃ o MM-FiD trÃªn OK-VQA, Ä‘á»™ chÃ­nh xÃ¡c tráº£ lá»i cÃ¢u há»i cÃ ng cao. Äá»™ chÃ­nh xÃ¡c cá»§a nÃ³ trá»Ÿ nÃªn tÆ°Æ¡ng Ä‘á»‘i á»•n Ä‘á»‹nh sau khi truy xuáº¥t 16 tÃ i liá»‡u. ÄÆ°á»ng cong Ä‘á»™ chÃ­nh xÃ¡c tuÃ¢n theo hÃ nh vi tÆ°Æ¡ng tá»± nhÆ° Ä‘Æ°á»ng cong hit trÃªn OK-VQA. Tuy nhiÃªn, FVQA thá»ƒ hiá»‡n hÃ nh vi khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ. Äá»™ chÃ­nh xÃ¡c cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c khi chá»‰ truy xuáº¥t nÄƒm Ä‘oáº¡n vÄƒn há»— trá»£. Äiá»u Ä‘Ã³ lÃ  do báº£n cháº¥t cá»§a bá»™ dá»¯ liá»‡u, nÆ¡i chá»‰ cÃ³ má»™t sá»± tháº­t liÃªn quan cho má»—i cÃ¢u há»i vÃ  viá»‡c truy xuáº¥t nhiá»u sá»± tháº­t (cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c) hÆ¡n cÃ³ thá»ƒ lÃ m nháº§m láº«n mÃ´ hÃ¬nh táº¡o cÃ¢u tráº£ lá»i. LÆ°u Ã½ ráº±ng DEDR Ä‘áº¡t tá»· lá»‡ hit 70% chá»‰ báº±ng cÃ¡ch truy xuáº¥t hai Ä‘oáº¡n vÄƒn trÃªn FVQA, trong khi cÃ¹ng mÃ´ hÃ¬nh cáº§n truy xuáº¥t 4 Ä‘oáº¡n vÄƒn Ä‘á»ƒ Ä‘áº¡t cÃ¹ng má»©c tá»· lá»‡ hit trÃªn OK-VQA. PhÃ¡t hiá»‡n nÃ y cho tháº¥y ráº±ng viá»‡c nghiÃªn cá»©u dá»± Ä‘oÃ¡n tá»± Ä‘á»™ng ranking cut-off cho cÃ¡c tÃ¡c vá»¥ KI-VQA trong tÆ°Æ¡ng lai lÃ  Ä‘Ã¡ng giÃ¡.

7 Káº¾T LUáº¬N VÃ€ CÃ”NG VIá»†C TÆ¯Æ NG LAI
BÃ i bÃ¡o nÃ y trÃ¬nh bÃ y DEDR, má»™t khung truy xuáº¥t máº­t Ä‘á»™ Ä‘á»‘i xá»©ng má»›i dá»±a trÃªn mÃ£ hÃ³a Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  Ä‘a phÆ°Æ¡ng thá»©c kÃ©p. ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t kiáº¿n thá»©c láº·p Ä‘i láº·p láº¡i Ä‘á»ƒ cáº­p nháº­t hai khÃ´ng gian biá»ƒu diá»…n mÃ£ hÃ³a nÃ y vÃ  tá»•ng há»£p chÃºng khi suy luáº­n. NÃ³ cÅ©ng Ä‘á» xuáº¥t MM-FiD, má»™t pháº§n má»Ÿ rá»™ng cá»§a kiáº¿n trÃºc fusion-in-decoder [20] cho dá»¯ liá»‡u Ä‘a phÆ°Æ¡ng thá»©c. CÃ¡c thÃ­ nghiá»‡m toÃ n diá»‡n trÃªn hai bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c thiáº¿t láº­p tá»‘t, OK-VQA vÃ  FVQA, cho tháº¥y ráº±ng viá»‡c truy xuáº¥t Ä‘oáº¡n vÄƒn báº±ng DEDR vÃ  sá»­ dá»¥ng chÃºng Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i thÃ´ng qua MM-FiD vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c baseline tiÃªn tiáº¿n vá»›i kháº£ nÄƒng tÆ°Æ¡ng Ä‘Æ°Æ¡ng. VÃ­ dá»¥, phÆ°Æ¡ng phÃ¡p nÃ y dáº«n Ä‘áº¿n cáº£i thiá»‡n truy xuáº¥t 37,8% vá» P@1 vÃ  cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c exact match 8,5% trÃªn táº­p thá»­ nghiá»‡m FVQA so vá»›i cÃ¡c baseline hoáº¡t Ä‘á»™ng tá»‘t nháº¥t. ChÃºng tÃ´i chá»©ng minh tÃ¡c Ä‘á»™ng cá»§a má»i quyáº¿t Ä‘á»‹nh thiáº¿t káº¿ chÃºng tÃ´i Ä‘Æ°a ra trong cáº£ DEDR vÃ  MM-FiD thÃ´ng qua cÃ¡c nghiÃªn cá»©u ablation toÃ n diá»‡n vÃ  nÃªu báº­t cÃ¡c lÄ©nh vá»±c má»Ÿ Ä‘á»ƒ khÃ¡m phÃ¡ trong tÆ°Æ¡ng lai. VÃ­ dá»¥, káº¿t quáº£ cá»§a chÃºng tÃ´i cho tháº¥y dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c vá» 'khi nÃ o nÃªn truy xuáº¥t' lÃ  má»™t lÄ©nh vá»±c cÃ³ tÃ¡c Ä‘á»™ng Ä‘á»‘i vá»›i cÃ¡c tÃ¡c vá»¥ KI-VQA. Do Ä‘Ã³, viá»‡c khÃ¡m phÃ¡ dá»± Ä‘oÃ¡n hiá»‡u suáº¥t truy xuáº¥t vÃ  cáº¯t ngáº¯n ranking cut-off trong cÃ¡c tÃ¡c vá»¥ KI-VQA cÃ³ thá»ƒ lÃ  má»™t hÆ°á»›ng tÆ°Æ¡ng lai cÃ³ káº¿t quáº£. ChÃºng tÃ´i cÅ©ng cÃ³ Ã½ Ä‘á»‹nh khÃ¡m phÃ¡ cÃ¡c mÃ´ hÃ¬nh Ä‘Ã²i há»i kiáº¿n thá»©c toÃ n cáº§u cho cáº£ Ä‘áº§u vÃ o vÄƒn báº£n vÃ  Ä‘a phÆ°Æ¡ng thá»©c. ChÃºng tÃ´i tiáº¿p tá»¥c cÃ³ káº¿ hoáº¡ch má»Ÿ rá»™ng cÃ¡c á»©ng dá»¥ng cá»§a cÃ¡c tÃ¡c vá»¥ Ä‘a phÆ°Æ¡ng thá»©c Ä‘Ã²i há»i kiáº¿n thá»©c ngoÃ i tráº£ lá»i cÃ¢u há»i.

--- TRANG 8 ---
SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan. Alireza Salemi, Juan Altmayer Pizzorno, vÃ  Hamed Zamani

Lá»œI Cáº¢M Æ N
CÃ´ng trÃ¬nh nÃ y Ä‘Æ°á»£c há»— trá»£ má»™t pháº§n bá»Ÿi Trung tÃ¢m Truy xuáº¥t ThÃ´ng tin ThÃ´ng minh, má»™t pháº§n bá»Ÿi tÃ i trá»£ NSF #2106282, vÃ  má»™t pháº§n bá»Ÿi Lowe's. Má»i Ã½ kiáº¿n, phÃ¡t hiá»‡n vÃ  káº¿t luáº­n hoáº·c khuyáº¿n nghá»‹ Ä‘Æ°á»£c thá»ƒ hiá»‡n trong tÃ i liá»‡u nÃ y thuá»™c vá» cÃ¡c tÃ¡c giáº£ vÃ  khÃ´ng nháº¥t thiáº¿t pháº£n Ã¡nh quan Ä‘iá»ƒm cá»§a nhÃ  tÃ i trá»£.

TÃ€I LIá»†U THAM KHáº¢O
[1]Bilal Abu-Salih. 2021. Domain-specific knowledge graphs: A survey. Journal of Network and Computer Applications 185 (2021), 103076. https://doi.org/10.1016/j.jnca.2021.103076

[2]Peter Anderson, X. He, C. Buehler, Damien Teney, Mark Johnson, Stephen Gould, vÃ  Lei Zhang. 2018. Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (2018), 6077â€“6086.

[3]Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, vÃ  Devi Parikh. 2015. VQA: Visual Question Answering. Trong International Conference on Computer Vision (ICCV).

[4]Danqi Chen, Adam Fisch, Jason Weston, vÃ  Antoine Bordes. 2017. Reading Wikipedia to Answer Open-Domain Questions. https://doi.org/10.48550/ARXIV.1704.00051

[5]Zhuo Chen, Yufeng Huang, Jiaoyan Chen, Yuxia Geng, Yin Fang, Jeff Z. Pan, Ningyu Zhang, vÃ  Wen Zhang. 2022. LaKo: Knowledge-driven Visual Question Answering via Late Knowledge-to-Text Injection. CoRR abs/2207.12888 (2022).

[6]Jaemin Cho, Jie Lei, Hao Tan, vÃ  Mohit Bansal. 2021. Unifying Vision-and-Language Tasks via Text Generation. Trong Proceedings of the 38th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 139), Marina Meila vÃ  Tong Zhang (Eds.). PMLR, 1931â€“1942.

[7]Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer, George W. Furnas, vÃ  Richard A. Harshman. 1990. Indexing by Latent Semantic Analysis. J. Am. Soc. Inf. Sci. 41 (1990), 391â€“407.

[8]Jacob Devlin, Ming-Wei Chang, Kenton Lee, vÃ  Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 4171â€“4186. https://doi.org/10.18653/v1/N19-1423

[9]Edward A. Fox vÃ  Joseph A. Shaw. 1993. Combination of Multiple Searches. Trong Text Retrieval Conference.

[10] Feng Gao, Qing Ping, Govind Thattai, Aishwarya Reganti, Ying Nian Wu, vÃ  Prem Natarajan. 2022. Transform-Retrieve-Generate: Natural Language-Centric Outside-Knowledge Visual Question Answering. Trong 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 5057â€“5067. https://doi.org/10.1109/CVPR52688.2022.00501

[11] Luyu Gao, Zhuyun Dai, vÃ  Jamie Callan. 2020. Modularized Transfomer-based Ranking Framework. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, Online, 4180â€“4190. https://doi.org/10.18653/v1/2020.emnlp-main.342

[12] FranÃ§ois GardÃ¨res, Maryam Ziaeefard, Baptiste Abeloos, vÃ  Freddy Lecue. 2020. ConceptBert: Concept-Aware Representation for Visual Question Answering. Trong Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, Online, 489â€“498. https://doi.org/10.18653/v1/2020.findings-emnlp.44

[13] Liangke Gui, Borui Wang, Qiuyuan Huang, Alexander Hauptmann, Yonatan Bisk, vÃ  Jianfeng Gao. 2022. KAT: A Knowledge Augmented Transformer for Vision-and-Language. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Seattle, United States, 956â€“968. https://doi.org/10.18653/v1/2022.naacl-main.70

[14] Yangyang Guo, Liqiang Nie, Yongkang Wong, Yibing Liu, Zhiyong Cheng, vÃ  Mohan Kankanhalli. 2022. A Unified End-to-End Retriever-Reader Framework for Knowledge-Based VQA. Trong Proceedings of the 30th ACM International Conference on Multimedia (Lisboa, Portugal) (MM '22). Association for Computing Machinery, New York, NY, USA, 2061â€“2069. https://doi.org/10.1145/3503161.3547870

[15] Darryl Hannan, Akshay Jain, vÃ  Mohit Bansal. 2020. ManyModalQA: Modality Disambiguation and QA over Diverse Inputs. Proceedings of the AAAI Conference on Artificial Intelligence 34, 05 (Apr. 2020), 7879â€“7886. https://doi.org/10.1609/aaai.v34i05.6294

[16] Sebastian HofstÃ¤tter, Jiecao Chen, Karthik Raman, vÃ  Hamed Zamani. 2022. FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation. ArXiv abs/2209.14290 (2022).

[17] Sebastian HofstÃ¤tter, Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin, vÃ  Allan Hanbury. 2021. Efficiently Teaching an Effective Dense Retriever with Balanced Topic Aware Sampling. Trong Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, Canada) (SIGIR '21). Association for Computing Machinery, New York, NY, USA, 113â€“122. https://doi.org/10.1145/3404835.3462891

[18] Jia Cheng Hu, Roberto Cavicchioli, vÃ  Alessandro Capotondi. 2022. ExpansionNet v2: Block Static Expansion in fast end to end training for Image Captioning. https://doi.org/10.48550/ARXIV.2208.06551

[19] Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, vÃ  Jason Weston. 2020. Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring. Trong International Conference on Learning Representations. https://openreview.net/forum?id=SkxgnnNFvH

[20] Gautier Izacard vÃ  Edouard Grave. 2021. Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering. Trong Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. Association for Computational Linguistics, Online, 874â€“880. https://doi.org/10.18653/v1/2021.eacl-main.74

[21] Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yun-Hsuan Sung, Zhen Li, vÃ  Tom Duerig. 2021. Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. Trong International Conference on Machine Learning.

[22] Jeff Johnson, Matthijs Douze, vÃ  HervÃ© JÃ©gou. 2019. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data 7, 3 (2019), 535â€“547.

[23] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, vÃ  Wen-tau Yih. 2020. Dense Passage Retrieval for Open-Domain Question Answering. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, Online, 6769â€“6781. https://doi.org/10.18653/v1/2020.emnlp-main.550

[24] Omar Khattab vÃ  Matei Zaharia. 2020. ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. Trong Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, China) (SIGIR '20). Association for Computing Machinery, New York, NY, USA, 39â€“48. https://doi.org/10.1145/3397271.3401075

[25] Jin-Hwa Kim, Jaehyun Jun, vÃ  Byoung-Tak Zhang. 2018. Bilinear Attention Networks. Trong Advances in Neural Information Processing Systems, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, vÃ  R. Garnett (Eds.), Vol. 31. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2018/file/96ea64f3a1aa2fd00c72faacf0cb8ac9-Paper.pdf

[26] Diederik P. Kingma vÃ  Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. https://doi.org/10.48550/ARXIV.1412.6980

[27] R. Krishna, Yuke Zhu, O. Groth, J. Johnson, Kenji Hata, J. Kravitz, Stephanie Chen, Yannis Kalantidis, L. Li, David A. Shamma, Michael S. Bernstein, vÃ  Li Fei-Fei. 2016. Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. International Journal of Computer Vision 123 (2016), 32â€“73.

[28] Joon Ho Lee. 1997. Analyses of Multiple Evidence Combination. SIGIR Forum 31, SI (jul 1997), 267â€“276. https://doi.org/10.1145/278459.258587

[29] Guohao Li, Xin Wang, vÃ  Wenwu Zhu. 2020. Boosting Visual Question Answering with Context-aware Knowledge Aggregation. Proceedings of the 28th ACM International Conference on Multimedia (2020).

[30] Sheng-Chieh Lin, Jheng-Hong Yang, vÃ  Jimmy Lin. 2021. In-Batch Negatives for Knowledge Distillation with Tightly-Coupled Teachers for Dense Retrieval. Trong Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021). Association for Computational Linguistics, Online, 163â€“173. https://doi.org/10.18653/v1/2021.repl4nlp-1.17

[31] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr DollÃ¡r, vÃ  C. Lawrence Zitnick. 2014. Microsoft COCO: Common Objects in Context. Trong Computer Vision â€“ ECCV 2014, David Fleet, Tomas Pajdla, Bernt Schiele, vÃ  Tinne Tuytelaars (Eds.). Springer International Publishing, Cham, 740â€“755.

[32] Weizhe Lin vÃ  Bill Byrne. 2022. Retrieval Augmented Visual Question Answering with Outside Knowledge. https://doi.org/10.48550/ARXIV.2210.03809

[33] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, vÃ  Baining Guo. 2021. Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows. Trong Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). 10012â€“10022.

[34] Zhenghao Liu, Chenyan Xiong, Yuanhuiyi Lv, Zhiyuan Liu, vÃ  Ge Yu. 2022. Universal Multi-Modality Retrieval with One Unified Embedding Space. https://doi.org/10.48550/ARXIV.2209.00179

[35] Man Luo, Yankai Zeng, Pratyay Banerjee, vÃ  Chitta Baral. 2021. Weakly-Supervised Visual-Retriever-Reader for Knowledge-based Question Answering. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 6417â€“6431. https://doi.org/10.18653/v1/2021.emnlp-main.517

[36] Sean MacAvaney, Franco Maria Nardini, Raffaele Perego, Nicola Tonellotto, Nazli Goharian, vÃ  Ophir Frieder. 2020. Efficient Document Re-Ranking for Transformers by Precomputing Term Representations. Trong Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, China) (SIGIR '20). Association for Computing Machinery, New York, NY, USA, 49â€“58. https://doi.org/10.1145/3397271.3401093

--- TRANG 9 ---
Má»™t Khung Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a Äá»‘i Xá»©ng KÃ©p cho Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c ChuyÃªn SÃ¢u SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan.

[37] Kenneth Marino, Xinlei Chen, Devi Parikh, Abhinav Kumar Gupta, vÃ  Marcus Rohrbach. 2020. KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020), 14106â€“14116.

[38] Kenneth Marino, Mohammad Rastegari, Ali Farhadi, vÃ  Roozbeh Mottaghi. 2019. OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge. Trong Conference on Computer Vision and Pattern Recognition (CVPR).

[39] Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim RocktÃ¤schel, vÃ  Sebastian Riedel. 2021. KILT: a Benchmark for Knowledge Intensive Language Tasks. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Online, 2523â€“2544. https://doi.org/10.18653/v1/2021.naacl-main.200

[40] Chen Qu, Hamed Zamani, Liu Yang, W. Bruce Croft, vÃ  Erik Learned-Miller. 2021. Passage Retrieval for Outside-Knowledge Visual Question Answering. Trong Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, Canada) (SIGIR '21). Association for Computing Machinery, New York, NY, USA, 1753â€“1757. https://doi.org/10.1145/3404835.3462987

[41] Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, vÃ  Haifeng Wang. 2021. RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Online, 5835â€“5847. https://doi.org/10.18653/v1/2021.naacl-main.466

[42] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, vÃ  Ilya Sutskever. 2021. Learning Transferable Visual Models From Natural Language Supervision. Trong Proceedings of the 38th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 139), Marina Meila vÃ  Tong Zhang (Eds.). PMLR, 8748â€“8763. https://proceedings.mlr.press/v139/radford21a.html

[43] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, vÃ  Peter J. Liu. 2020. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. Journal of Machine Learning Research 21, 140 (2020), 1â€“67. http://jmlr.org/papers/v21/20-074.html

[44] Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, QiaoQiao She, Hua Wu, Haifeng Wang, vÃ  Ji-Rong Wen. 2021. RocketQAv2: A Joint Training Method for Dense Passage Retrieval and Passage Re-ranking. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 2825â€“2835. https://doi.org/10.18653/v1/2021.emnlp-main.224

[45] Shaoqing Ren, Kaiming He, Ross Girshick, vÃ  Jian Sun. 2015. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. Trong Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1 (Montreal, Canada) (NIPS'15). MIT Press, Cambridge, MA, USA, 91â€“99.

[46] Steven J. Rennie, Etienne Marcheret, Youssef Mroueh, Jerret Ross, vÃ  Vaibhava Goel. 2016. Self-Critical Sequence Training for Image Captioning. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016), 1179â€“1195.

[47] Stephen Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, vÃ  M. Gatford. 1995. Okapi at TREC-3. Trong Proceedings of the Third Text REtrieval Conference (TREC-3). Gaithersburg, MD: NIST, 109â€“126.

[48] Ander Salaberria, Gorka Azkune, Oier Lopez de Lacalle, Aitor Soroa, vÃ  Eneko Agirre. 2023. Image captioning for effective use of language models in knowledge-based visual question answering. Expert Systems with Applications 212 (2023), 118669. https://doi.org/10.1016/j.eswa.2022.118669

[49] Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, vÃ  Matei Zaharia. 2022. ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Seattle, United States, 3715â€“3734. https://doi.org/10.18653/v1/2022.naacl-main.272

[50] Violetta Shevchenko, Damien Teney, Anthony Dick, vÃ  Anton van den Hengel. 2021. Reasoning over Vision and Language: Exploring the Benefits of Supplemental Knowledge. Trong Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN). Association for Computational Linguistics, Kyiv, Ukraine, 1â€“18. https://aclanthology.org/2021.lantern-1.1

[51] Hrituraj Singh, Anshul Nasery, Denil Mehta, Aishwarya Agarwal, Jatin Lamba, vÃ  Balaji Vasan Srinivasan. 2021. MIMOQA: Multimodal Input Multimodal Output Question Answering. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Online, 5317â€“5332. https://doi.org/10.18653/v1/2021.naacl-main.418

[52] Alon Talmor, Ori Yoran, Amnon Catav, Dan Lahav, Yizhong Wang, Akari Asai, Gabriel Ilharco, Hannaneh Hajishirzi, vÃ  Jonathan Berant. 2021. MultiModal{QA}: complex question answering over text, tables and images. Trong International Conference on Learning Representations. https://openreview.net/forum?id=ee6W5UgQLa

[53] Hao Tan vÃ  Mohit Bansal. 2019. LXMERT: Learning Cross-Modality Encoder Representations from Transformers. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Association for Computational Linguistics, Hong Kong, China, 5100â€“5111. https://doi.org/10.18653/v1/D19-1514

[54] Jizhi Tang, Yansong Feng, vÃ  Dongyan Zhao. 2019. Learning to Update Knowledge Graphs by Reading News. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Association for Computational Linguistics, Hong Kong, China, 2632â€“2641. https://doi.org/10.18653/v1/D19-1265

[55] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Å ukasz Kaiser, vÃ  Illia Polosukhin. 2017. Attention is All you Need. Trong Advances in Neural Information Processing Systems, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, vÃ  R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf

[56] Peng Wang, Qi Wu, Chunhua Shen, Anthony Dick, vÃ  Anton van den Hengel. 2018. FVQA: Fact-Based Visual Question Answering. IEEE Trans. Pattern Anal. Mach. Intell. 40, 10 (oct 2018), 2413â€“2427. https://doi.org/10.1109/TPAMI.2017.2754246

[57] Jialin Wu, Jiasen Lu, Ashish Sabharwal, vÃ  Roozbeh Mottaghi. 2022. Multi-Modal Answer Validation for Knowledge-Based VQA. Proceedings of the AAAI Conference on Artificial Intelligence 36, 3 (Jun. 2022), 2712â€“2721. https://doi.org/10.1609/aaai.v36i3.20174

[58] Yonghui Wu, Mike Schuster, Z. Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason R. Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Gregory S. Corrado, Macduff Hughes, vÃ  Jeffrey Dean. 2016. Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. ArXiv abs/1609.08144 (2016).

[59] Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N. Bennett, Junaid Ahmed, vÃ  Arnold Overwijk. 2021. Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval. Trong International Conference on Learning Representations. https://openreview.net/forum?id=zeFrfgyZln

[60] Zhengyuan Yang, Zhe Gan, Jianfeng Wang, Xiaowei Hu, Yumao Lu, Zicheng Liu, vÃ  Lijuan Wang. 2021. An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA. Trong AAAI Conference on Artificial Intelligence.

[61] Hamed Zamani, Fernando Diaz, Mostafa Dehghani, Donald Metzler, vÃ  Michael Bendersky. 2022. Retrieval-Enhanced Machine Learning. Trong Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR '22). Association for Computing Machinery, New York, NY, USA, 2875â€“2886. https://doi.org/10.1145/3477495.3531722

[62] Hansi Zeng, Hamed Zamani, vÃ  Vishwa Vinay. 2022. Curriculum Learning for Dense Retrieval Distillation. Trong Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (Madrid, Spain) (SIGIR '22). Association for Computing Machinery, New York, NY, USA, 1979â€“1983. https://doi.org/10.1145/3477495.3531791

[63] Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, Min Zhang, vÃ  Shaoping Ma. 2021. Optimizing Dense Retrieval Model Training with Hard Negatives. Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (2021).

--- TRANG 10 ---
SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan. Alireza Salemi, Juan Altmayer Pizzorno, vÃ  Hamed Zamani

--- TRANG 11 ---
Má»™t Khung Truy Xuáº¥t Máº­t Äá»™ MÃ£ HÃ³a Äá»‘i Xá»©ng KÃ©p cho Tráº£ Lá»i CÃ¢u Há»i HÃ¬nh áº¢nh ÄÃ²i Há»i Kiáº¿n Thá»©c ChuyÃªn SÃ¢u SIGIR '23, 23â€“27 thÃ¡ng 7, 2023, Taipei, ÄÃ i Loan.

# Tạo sinh Tăng cường Truy xuất cho các Nhiệm vụ NLP Sâu về Kiến thức

Patrick Lewisyz, Ethan Perez?,
Aleksandra Piktusy, Fabio Petroniy, Vladimir Karpukhiny, Naman Goyaly, Heinrich Küttlery,
Mike Lewisy, Wen-tau Yihy, Tim Rocktäschelyz, Sebastian Riedelyz, Douwe Kielay
yFacebook AI Research;zUniversity College London;?New York University;
plewis@fb.com

## Tóm tắt

Các mô hình ngôn ngữ lớn đã được huấn luyện trước đã được chứng minh là lưu trữ kiến thức thực tế trong các tham số của chúng, và đạt được kết quả tốt nhất khi được tinh chỉnh trên các nhiệm vụ NLP hạ nguồn. Tuy nhiên, khả năng truy cập và thao tác kiến thức một cách chính xác của chúng vẫn còn hạn chế, và do đó trên các nhiệm vụ sâu về kiến thức, hiệu suất của chúng thua kém các kiến trúc chuyên biệt cho từng nhiệm vụ. Thêm vào đó, việc cung cấp nguồn gốc cho các quyết định của chúng và cập nhật kiến thức về thế giới vẫn là những vấn đề nghiên cứu mở. Các mô hình đã được huấn luyện trước với cơ chế truy cập khả vi đến bộ nhớ phi tham số rõ ràng cho đến nay chỉ được khảo sát cho các nhiệm vụ hạ nguồn trích xuất. Chúng tôi khám phá một công thức tinh chỉnh đa mục đích cho tạo sinh tăng cường truy xuất (RAG) — các mô hình kết hợp bộ nhớ tham số và phi tham số đã được huấn luyện trước để tạo sinh ngôn ngữ. Chúng tôi giới thiệu các mô hình RAG trong đó bộ nhớ tham số là một mô hình seq2seq đã được huấn luyện trước và bộ nhớ phi tham số là một chỉ mục vector dày đặc của Wikipedia, được truy cập bằng một bộ truy xuất thần kinh đã được huấn luyện trước. Chúng tôi so sánh hai dạng RAG, một dạng điều kiện trên cùng các đoạn văn được truy xuất trên toàn bộ chuỗi được tạo sinh, và một dạng khác có thể sử dụng các đoạn văn khác nhau cho mỗi token. Chúng tôi tinh chỉnh và đánh giá các mô hình của chúng tôi trên một loạt rộng các nhiệm vụ NLP sâu về kiến thức và thiết lập trạng thái tốt nhất trên ba nhiệm vụ QA miền mở, vượt trội hơn các mô hình seq2seq chỉ tham số và các kiến trúc truy xuất-và-trích xuất chuyên biệt cho từng nhiệm vụ. Đối với các nhiệm vụ tạo sinh ngôn ngữ, chúng tôi thấy rằng các mô hình RAG tạo sinh ngôn ngữ cụ thể, đa dạng và thực tế hơn so với một baseline seq2seq chỉ tham số tối tân.

## 1 Giới thiệu

Các mô hình ngôn ngữ thần kinh đã được huấn luyện trước đã được chứng minh là học được một lượng kiến thức sâu sắc đáng kể từ dữ liệu [47]. Chúng có thể làm như vậy mà không cần truy cập vào bộ nhớ bên ngoài nào, như một cơ sở tri thức ẩn được tham số hóa [51,52]. Mặc dù sự phát triển này đáng phấn khích, những mô hình như vậy có những nhược điểm: Chúng không thể dễ dàng mở rộng hoặc sửa đổi bộ nhớ của chúng, không thể một cách trực tiếp cung cấp cái nhìn sâu sắc về các dự đoán của chúng, và có thể tạo ra "ảo giác" [38]. Các mô hình lai kết hợp bộ nhớ tham số với bộ nhớ phi tham số (tức là, dựa trên truy xuất) [20,26,48] có thể giải quyết một số vấn đề này vì kiến thức có thể được sửa đổi và mở rộng trực tiếp, và kiến thức được truy cập có thể được kiểm tra và giải thích. REALM [20] và ORQA [31], hai mô hình được giới thiệu gần đây kết hợp các mô hình ngôn ngữ có mask [8] với một bộ truy xuất khả vi, đã cho thấy kết quả đầy hứa hẹn, nhưng chỉ khám phá hỏi đáp trích xuất miền mở. Ở đây, chúng tôi mang bộ nhớ tham số và phi tham số lai đến "ngựa thồ của NLP," tức là các mô hình chuỗi-tới-chuỗi (seq2seq).

Chúng tôi trang bị cho các mô hình tạo sinh bộ nhớ-tham số đã được huấn luyện trước với bộ nhớ phi tham số thông qua một phương pháp tinh chỉnh đa mục đích mà chúng tôi gọi là tạo sinh tăng cường truy xuất (RAG). Chúng tôi xây dựng các mô hình RAG trong đó bộ nhớ tham số là một transformer seq2seq đã được huấn luyện trước, và bộ nhớ phi tham số là một chỉ mục vector dày đặc của Wikipedia, được truy cập bằng một bộ truy xuất thần kinh đã được huấn luyện trước. Chúng tôi kết hợp các thành phần này trong một mô hình xác suất được huấn luyện đầu-tới-cuối (Hình 1). Bộ truy xuất (Dense Passage Retriever [26], sau đây gọi là DPR) cung cấp các tài liệu ẩn có điều kiện trên đầu vào, và mô hình seq2seq (BART [32]) sau đó điều kiện trên các tài liệu ẩn này cùng với đầu vào để tạo sinh đầu ra. Chúng tôi biên hóa các tài liệu ẩn với một xấp xỉ top-K, hoặc trên cơ sở từng đầu ra (giả định cùng một tài liệu chịu trách nhiệm cho tất cả các token) hoặc trên cơ sở từng token (trong đó các tài liệu khác nhau chịu trách nhiệm cho các token khác nhau). Giống như T5 [51] hoặc BART, RAG có thể được tinh chỉnh trên bất kỳ nhiệm vụ seq2seq nào, trong đó cả bộ tạo sinh và bộ truy xuất đều được học chung.

Đã có công trình trước đây mở rộng đề xuất các kiến trúc để làm phong phú các hệ thống với bộ nhớ phi tham số được huấn luyện từ đầu cho các nhiệm vụ cụ thể, ví dụ mạng bộ nhớ [64,55], mạng tăng cường ngăn xếp [25] và các lớp bộ nhớ [30]. Ngược lại, chúng tôi khám phá một bối cảnh trong đó cả các thành phần bộ nhớ tham số và phi tham số đều được huấn luyện trước và được tải sẵn với kiến thức mở rộng. Quan trọng là, bằng cách sử dụng các cơ chế truy cập đã được huấn luyện trước, khả năng truy cập kiến thức có mặt mà không cần huấn luyện bổ sung.

Kết quả của chúng tôi làm nổi bật lợi ích của việc kết hợp bộ nhớ tham số và phi tham số với tạo sinh cho các nhiệm vụ sâu về kiến thức — các nhiệm vụ mà con người không thể hợp lý được mong đợi thực hiện mà không có quyền truy cập vào một nguồn kiến thức bên ngoài. Các mô hình RAG của chúng tôi đạt được kết quả tối tân trên Natural Questions mở [29], WebQuestions [3] và CuratedTrec [2] và vượt trội đáng kể so với các phương pháp gần đây sử dụng các mục tiêu huấn luyện trước chuyên biệt trên TriviaQA [24]. Mặc dù đây là các nhiệm vụ trích xuất, chúng tôi thấy rằng tạo sinh không ràng buộc vượt trội hơn các phương pháp trích xuất trước đây. Đối với tạo sinh sâu về kiến thức, chúng tôi thử nghiệm với MS-MARCO [1] và tạo sinh câu hỏi Jeopardy, và chúng tôi thấy rằng các mô hình của chúng tôi tạo sinh các phản hồi thực tế, cụ thể và đa dạng hơn so với một baseline BART. Đối với xác minh sự thật FEVER [56], chúng tôi đạt được kết quả trong vòng 4.3% so với các mô hình pipeline tối tân sử dụng giám sát truy xuất mạnh. Cuối cùng, chúng tôi chứng minh rằng bộ nhớ phi tham số có thể được thay thế để cập nhật kiến thức của mô hình khi thế giới thay đổi.

## 2 Phương pháp

Chúng tôi khám phá các mô hình RAG, sử dụng chuỗi đầu vào x để truy xuất các tài liệu văn bản z và sử dụng chúng như ngữ cảnh bổ sung khi tạo sinh chuỗi đích y. Như được thể hiện trong Hình 1, các mô hình của chúng tôi tận dụng hai thành phần: (i) một bộ truy xuất p(z|x) với các tham số η trả về phân phối (được cắt bớt top-K) trên các đoạn văn bản được cho một truy vấn x và (ii) một bộ tạo sinh p(yi|x,z,y1:i-1) được tham số hóa bởi θ tạo sinh token hiện tại dựa trên ngữ cảnh của i-1 token trước đó y1:i-1, đầu vào gốc x và một đoạn văn được truy xuất z.

Để huấn luyện bộ truy xuất và bộ tạo sinh đầu-tới-cuối, chúng tôi xử lý tài liệu được truy xuất như một biến ẩn. Chúng tôi đề xuất hai mô hình biên hóa trên các tài liệu ẩn theo những cách khác nhau để tạo ra phân phối trên văn bản được tạo sinh. Trong một phương pháp, RAG-Sequence, mô hình sử dụng cùng một tài liệu để dự đoán mỗi token đích. Phương pháp thứ hai, RAG-Token, có thể dự đoán mỗi token đích dựa trên một tài liệu khác nhau. Trong phần sau, chúng tôi chính thức giới thiệu cả hai mô hình và sau đó mô tả các thành phần pη và pθ, cũng như quy trình huấn luyện và giải mã.

### 2.1 Mô hình

**Mô hình RAG-Sequence** Mô hình RAG-Sequence sử dụng cùng một tài liệu được truy xuất để tạo sinh chuỗi hoàn chỉnh. Về mặt kỹ thuật, nó xử lý tài liệu được truy xuất như một biến ẩn duy nhất được biên hóa để có được xác suất seq2seq p(y|x) thông qua một xấp xỉ top-K. Cụ thể, K tài liệu hàng đầu được truy xuất bằng bộ truy xuất, và bộ tạo sinh tạo ra xác suất chuỗi đầu ra cho mỗi tài liệu, sau đó được biên hóa,

pRAG-Sequence(y|x) ≈ Σz∈top-k(pη(·|x)) pη(z|x)pθ(y|x,z) = Σz∈top-k(pη(·|x)) pη(z|x)∏i pθ(yi|x,z,y1:i-1)

**Mô hình RAG-Token** Trong mô hình RAG-Token, chúng ta có thể rút một tài liệu ẩn khác nhau cho mỗi token đích và biên hóa tương ứng. Điều này cho phép bộ tạo sinh chọn nội dung từ nhiều tài liệu khi tạo ra một câu trả lời. Cụ thể, K tài liệu hàng đầu được truy xuất bằng bộ truy xuất, và sau đó bộ tạo sinh tạo ra phân phối cho token đầu ra tiếp theo cho mỗi tài liệu, trước khi biên hóa, và lặp lại quá trình với token đầu ra tiếp theo. Chính thức, chúng tôi định nghĩa:

pRAG-Token(y|x) ≈ ∏i Σz∈top-k(pη(·|x)) pη(z|x)pθ(yi|x,z,y1:i-1)

Cuối cùng, chúng tôi lưu ý rằng RAG có thể được sử dụng cho các nhiệm vụ phân loại chuỗi bằng cách xem xét lớp đích như một chuỗi đích có độ dài một, trong trường hợp này RAG-Sequence và RAG-Token là tương đương.

### 2.2 Bộ truy xuất: DPR

Thành phần truy xuất pη(z|x) dựa trên DPR [26]. DPR tuân theo một kiến trúc bi-encoder:

pη(z|x) ∝ exp(d(z)ᵀq(x))

trong đó d(z) = BERTd(z) là một biểu diễn dày đặc của một tài liệu được tạo ra bởi một encoder tài liệu BERTBASE [8], và q(x) = BERTq(x) là một biểu diễn truy vấn được tạo ra bởi một encoder truy vấn, cũng dựa trên BERTBASE. Tính toán top-k(pη(·|x)), danh sách k tài liệu z với xác suất tiên nghiệm cao nhất pη(z|x), là một bài toán Maximum Inner Product Search (MIPS), có thể được giải gần đúng trong thời gian dưới tuyến tính [23]. Chúng tôi sử dụng một bi-encoder đã được huấn luyện trước từ DPR để khởi tạo bộ truy xuất của chúng tôi và để xây dựng chỉ mục tài liệu. Bộ truy xuất này được huấn luyện để truy xuất các tài liệu chứa câu trả lời cho các câu hỏi TriviaQA [24] và Natural Questions [29]. Chúng tôi gọi chỉ mục tài liệu là bộ nhớ phi tham số.

### 2.3 Bộ tạo sinh: BART

Thành phần tạo sinh pθ(yi|x,z,y1:i-1) có thể được mô hình hóa bằng bất kỳ encoder-decoder nào. Chúng tôi sử dụng BART-large [32], một transformer seq2seq đã được huấn luyện trước với 400M tham số. Để kết hợp đầu vào x với nội dung được truy xuất z khi tạo sinh từ BART, chúng tôi chỉ đơn giản nối chúng lại. BART được huấn luyện trước bằng một mục tiêu khử nhiễu và nhiều chức năng tạo nhiễu khác nhau. Nó đã đạt được kết quả tối tân trên một tập hợp đa dạng các nhiệm vụ tạo sinh và vượt trội hơn các mô hình T5 có kích thước tương đương [32]. Chúng tôi gọi các tham số tạo sinh BART là bộ nhớ tham số từ đây về sau.

### 2.4 Huấn luyện

Chúng tôi huấn luyện chung các thành phần truy xuất và tạo sinh mà không có bất kỳ giám sát trực tiếp nào về tài liệu nào nên được truy xuất. Cho một corpus huấn luyện tinh chỉnh của các cặp đầu vào/đầu ra (xj,yj), chúng tôi tối thiểu hóa log-likelihood biên âm của mỗi đích, Σj -log p(yj|xj) bằng gradient descent ngẫu nhiên với Adam [28]. Cập nhật encoder tài liệu BERTd trong quá trình huấn luyện tốn kém vì nó yêu cầu chỉ mục tài liệu được cập nhật định kỳ như REALM làm trong quá trình huấn luyện trước [20]. Chúng tôi không thấy bước này cần thiết cho hiệu suất mạnh, và giữ encoder tài liệu (và chỉ mục) cố định, chỉ tinh chỉnh encoder truy vấn BERTq và bộ tạo sinh BART.

### 2.5 Giải mã

Ở thời điểm kiểm tra, RAG-Sequence và RAG-Token yêu cầu các cách khác nhau để xấp xỉ arg maxy p(y|x).

**RAG-Token** Mô hình RAG-Token có thể được xem như một bộ tạo sinh seq2seq tự hồi quy tiêu chuẩn với xác suất chuyển đổi: p'(yi|x,y1:i-1) = Σz∈top-k(pη(·|x)) pη(zi|x)pθ(yi|x,zi,y1:i-1). Để giải mã, chúng ta có thể cắm p'(yi|x,y1:i-1) vào một decoder beam tiêu chuẩn.

**RAG-Sequence** Đối với RAG-Sequence, likelihood p(y|x) không phân tích thành một likelihood từng token thông thường, do đó chúng ta không thể giải nó bằng một beam search duy nhất. Thay vào đó, chúng tôi chạy beam search cho mỗi tài liệu z, chấm điểm mỗi giả thuyết bằng pθ(yi|x,z,y1:i-1). Điều này tạo ra một tập hợp các giả thuyết Y, một số trong đó có thể không xuất hiện trong các beam của tất cả tài liệu. Để ước tính xác suất của một giả thuyết y, chúng tôi chạy một forward pass bổ sung cho mỗi tài liệu z mà y không xuất hiện trong beam, nhân xác suất tạo sinh với pη(z|x) và sau đó cộng các xác suất qua các beam cho các marginal. Chúng tôi gọi quy trình giải mã này là "Thorough Decoding." Đối với các chuỗi đầu ra dài hơn, |Y| có thể trở nên lớn, yêu cầu nhiều forward pass. Để giải mã hiệu quả hơn, chúng ta có thể tạo ra một xấp xỉ xa hơn rằng pθ(y|x,zi) ≈ 0 trong đó y không được tạo sinh trong quá trình beam search từ x,zi. Điều này tránh được nhu cầu chạy các forward pass bổ sung một khi tập hợp ứng viên Y đã được tạo ra. Chúng tôi gọi quy trình giải mã này là "Fast Decoding."

## 3 Thử nghiệm

Chúng tôi thử nghiệm với RAG trong một loạt rộng các nhiệm vụ sâu về kiến thức. Đối với tất cả các thử nghiệm, chúng tôi sử dụng một dump Wikipedia duy nhất cho nguồn kiến thức phi tham số của chúng tôi. Theo Lee và cộng sự [31] và Karpukhin và cộng sự [26], chúng tôi sử dụng dump tháng 12 năm 2018. Mỗi bài viết Wikipedia được chia thành các đoạn 100 từ rời rạc, tạo tổng cộng 21M tài liệu. Chúng tôi sử dụng encoder tài liệu để tính toán một embedding cho mỗi tài liệu, và xây dựng một chỉ mục MIPS duy nhất sử dụng FAISS [23] với một xấp xỉ Hierarchical Navigable Small World để truy xuất nhanh [37]. Trong quá trình huấn luyện, chúng tôi truy xuất k tài liệu hàng đầu cho mỗi truy vấn. Chúng tôi xem xét k ∈ {5,10} cho huấn luyện và thiết lập k cho thời gian kiểm tra bằng dữ liệu dev. Bây giờ chúng tôi thảo luận chi tiết thử nghiệm cho mỗi nhiệm vụ.

### 3.1 Hỏi đáp miền mở

Hỏi đáp miền mở (QA) là một ứng dụng thực tế quan trọng và sân thử nghiệm phổ biến cho các nhiệm vụ sâu về kiến thức [20]. Chúng tôi xử lý câu hỏi và câu trả lời như các cặp văn bản đầu vào-đầu ra (x,y) và huấn luyện RAG bằng cách trực tiếp tối thiểu hóa log-likelihood âm của câu trả lời. Chúng tôi so sánh RAG với paradigm QA trích xuất phổ biến [5,7,31,26], trong đó câu trả lời là các đoạn được trích xuất từ các tài liệu được truy xuất, dựa chủ yếu vào kiến thức phi tham số. Chúng tôi cũng so sánh với các phương pháp "Closed-Book QA" [52], mà giống như RAG, tạo sinh câu trả lời, nhưng không khai thác truy xuất, thay vào đó dựa hoàn toàn vào kiến thức tham số. Chúng tôi xem xét bốn bộ dữ liệu QA miền mở phổ biến: Natural Questions (NQ) [29], TriviaQA (TQA) [24], WebQuestions (WQ) [3] và CuratedTrec (CT) [2]. Vì CT và WQ nhỏ, chúng tôi theo DPR [26] bằng cách khởi tạo các mô hình CT và WQ với mô hình RAG NQ của chúng tôi. Chúng tôi sử dụng cùng các phân chia train/dev/test như công trình trước [31,26] và báo cáo điểm Exact Match (EM). Đối với TQA, để so sánh với T5 [52], chúng tôi cũng đánh giá trên tập kiểm tra TQA Wiki.

### 3.2 Hỏi đáp trừu tượng

Các mô hình RAG có thể vượt ra ngoài QA trích xuất đơn giản và trả lời câu hỏi bằng tạo sinh văn bản tự do, trừu tượng. Để kiểm tra tạo sinh ngôn ngữ tự nhiên (NLG) của RAG trong một bối cảnh sâu về kiến thức, chúng tôi sử dụng nhiệm vụ MSMARCO NLG v2.1 [43]. Nhiệm vụ bao gồm các câu hỏi, mười đoạn văn vàng được truy xuất từ một công cụ tìm kiếm cho mỗi câu hỏi, và một câu trả lời câu đầy đủ được chú thích từ các đoạn văn được truy xuất. Chúng tôi không sử dụng các đoạn văn được cung cấp, chỉ các câu hỏi và câu trả lời, để xử lý MSMARCO như một nhiệm vụ QA trừu tượng miền mở. MSMARCO có một số câu hỏi không thể được trả lời theo cách phù hợp với câu trả lời tham chiếu mà không có quyền truy cập vào các đoạn văn vàng, chẳng hạn như "Thời tiết ở Volcano, CA là gì?" nên hiệu suất sẽ thấp hơn mà không sử dụng các đoạn văn vàng. Chúng tôi cũng lưu ý rằng một số câu hỏi MSMARCO không thể được trả lời chỉ bằng Wikipedia. Ở đây, RAG có thể dựa vào kiến thức tham số để tạo sinh các phản hồi hợp lý.

### 3.3 Tạo sinh câu hỏi Jeopardy

Để đánh giá khả năng tạo sinh của RAG trong một bối cảnh không phải QA, chúng tôi nghiên cứu tạo sinh câu hỏi miền mở. Thay vì sử dụng câu hỏi từ các nhiệm vụ QA miền mở tiêu chuẩn, thường bao gồm các câu hỏi ngắn, đơn giản, chúng tôi đề xuất nhiệm vụ đòi hỏi hơn là tạo sinh câu hỏi Jeopardy. Jeopardy là một định dạng bất thường bao gồm việc cố gắng đoán một thực thể từ một sự thật về thực thể đó. Ví dụ, "The World Cup" là câu trả lời cho câu hỏi "Năm 1986 Mexico ghi điểm là quốc gia đầu tiên tổ chức cuộc thi thể thao quốc tế này hai lần." Vì các câu hỏi Jeopardy là những phát biểu thực tế chính xác, việc tạo sinh câu hỏi Jeopardy có điều kiện trên các thực thể câu trả lời của chúng tạo thành một nhiệm vụ tạo sinh sâu về kiến thức đầy thử thách.

Chúng tôi sử dụng các phân chia từ SearchQA [10], với 100K train, 14K dev, và 27K test examples. Vì đây là một nhiệm vụ mới, chúng tôi huấn luyện một mô hình BART để so sánh. Theo [67], chúng tôi đánh giá bằng metric Q-BLEU-1 được tinh chỉnh SQuAD [42]. Q-BLEU là một biến thể của BLEU với trọng số cao hơn cho việc khớp thực thể và có mối tương quan cao hơn với đánh giá của con người cho tạo sinh câu hỏi so với các metric tiêu chuẩn. Chúng tôi cũng thực hiện hai đánh giá của con người, một để đánh giá tính thực tế của tạo sinh, và một cho tính cụ thể. Chúng tôi định nghĩa tính thực tế là liệu một phát biểu có thể được chứng thực bởi các nguồn bên ngoài đáng tin cậy, và tính cụ thể là sự phụ thuộc lẫn nhau cao giữa đầu vào và đầu ra [33]. Chúng tôi tuân theo thực hành tốt nhất và sử dụng đánh giá so sánh theo cặp [34]. Các đánh giá viên được hiển thị một câu trả lời và hai câu hỏi được tạo sinh, một từ BART và một từ RAG. Sau đó họ được yêu cầu chọn một trong bốn tùy chọn—câu hỏi A tốt hơn, câu hỏi B tốt hơn, cả hai đều tốt, hoặc cả hai đều kém.

### 3.4 Xác minh sự thật

FEVER [56] yêu cầu phân loại liệu một khẳng định ngôn ngữ tự nhiên có được hỗ trợ hay bác bỏ bởi Wikipedia, hay liệu có đủ thông tin để quyết định. Nhiệm vụ yêu cầu truy xuất bằng chứng từ Wikipedia liên quan đến khẳng định và sau đó lý luận trên bằng chứng này để phân loại liệu khẳng định có đúng, sai, hay không thể xác minh chỉ từ Wikipedia. FEVER là một bài toán truy xuất kết hợp với một nhiệm vụ lý luận entailment đầy thử thách. Nó cũng cung cấp một sân thử nghiệm thích hợp để khám phá khả năng của các mô hình RAG trong việc xử lý phân loại thay vì tạo sinh. Chúng tôi ánh xạ các nhãn lớp FEVER (hỗ trợ, bác bỏ, hoặc không đủ thông tin) thành các token đầu ra đơn và huấn luyện trực tiếp với các cặp khẳng định-lớp. Quan trọng là, không giống như hầu hết các phương pháp khác đối với FEVER, chúng tôi không sử dụng giám sát trên bằng chứng được truy xuất. Trong nhiều ứng dụng thực tế, các tín hiệu giám sát truy xuất không có sẵn, và các mô hình không yêu cầu giám sát như vậy sẽ có thể áp dụng cho một loạt rộng hơn các nhiệm vụ. Chúng tôi khám phá hai biến thể: nhiệm vụ phân loại 3 chiều tiêu chuẩn (hỗ trợ/bác bỏ/không đủ thông tin) và nhiệm vụ 2 chiều (hỗ trợ/bác bỏ) được nghiên cứu trong Thorne và Vlachos [57]. Trong cả hai trường hợp, chúng tôi báo cáo độ chính xác nhãn.

## 4 Kết quả

### 4.1 Hỏi đáp miền mở

Bảng 1 cho thấy kết quả cho RAG cùng với các mô hình tối tân. Trên tất cả bốn nhiệm vụ QA miền mở, RAG thiết lập một trạng thái tối tân mới (chỉ trên phân chia có thể so sánh T5 cho TQA). RAG kết hợp tính linh hoạt tạo sinh của các phương pháp "closed-book" (chỉ tham số) và hiệu suất của các phương pháp "open-book" dựa trên truy xuất. Không giống như REALM và T5+SSM, RAG có kết quả mạnh mà không cần huấn luyện trước "salient span masking" tốn kém, chuyên biệt [20]. Đáng chú ý rằng bộ truy xuất của RAG được khởi tạo bằng bộ truy xuất của DPR, sử dụng giám sát truy xuất trên Natural Questions và TriviaQA. RAG so sánh thuận lợi với hệ thống DPR QA, sử dụng một "cross-encoder" dựa trên BERT để xếp hạng lại tài liệu, cùng với một reader trích xuất. RAG chứng minh rằng không cần re-ranker hay extractive reader cho hiệu suất tối tân.

Có một số lợi thế khi tạo sinh câu trả lời ngay cả khi có thể trích xuất chúng. Các tài liệu có manh mối về câu trả lời nhưng không chứa câu trả lời nguyên văn vẫn có thể đóng góp vào việc tạo sinh một câu trả lời đúng, điều này không thể với các phương pháp trích xuất tiêu chuẩn, dẫn đến việc biên hóa hiệu quả hơn trên các tài liệu. Hơn nữa, RAG có thể tạo sinh câu trả lời đúng ngay cả khi câu trả lời đúng không có trong bất kỳ tài liệu được truy xuất nào, đạt được 11.8% độ chính xác trong những trường hợp như vậy cho NQ, trong đó một mô hình trích xuất sẽ ghi điểm 0%.

### 4.2 Hỏi đáp trừu tượng

Như được thể hiện trong Bảng 2, RAG-Sequence vượt trội hơn BART trên Open MS-MARCO NLG 2.6 điểm Bleu và 2.6 điểm Rouge-L. RAG tiếp cận hiệu suất mô hình tối tân, điều này ấn tượng xem xét rằng (i) những mô hình đó truy cập các đoạn văn vàng với thông tin cụ thể cần thiết để tạo sinh câu trả lời tham chiếu, (ii) nhiều câu hỏi không thể trả lời mà không có các đoạn văn vàng, và (iii) không phải tất cả câu hỏi đều có thể trả lời chỉ từ Wikipedia. Bảng 3 cho thấy một số câu trả lời được tạo sinh từ các mô hình của chúng tôi. Về mặt định tính, chúng tôi thấy rằng các mô hình RAG ảo giác ít hơn và tạo sinh văn bản thực tế đúng thường xuyên hơn so với BART. Sau đó, chúng tôi cũng cho thấy rằng các tạo sinh RAG đa dạng hơn các tạo sinh BART (xem §4.5).

### 4.3 Tạo sinh câu hỏi Jeopardy

Bảng 2 cho thấy rằng RAG-Token hoạt động tốt hơn RAG-Sequence trong tạo sinh câu hỏi Jeopardy, với cả hai mô hình đều vượt trội hơn BART trên Q-BLEU-1. Bảng 4 cho thấy kết quả đánh giá của con người, trên 452 cặp tạo sinh từ BART và RAG-Token. Các đánh giá viên chỉ ra rằng BART thực tế hơn RAG chỉ trong 7.1% trường hợp, trong khi RAG thực tế hơn trong 42.7% trường hợp, và cả RAG và BART đều thực tế trong thêm 17% trường hợp, chứng minh rõ ràng hiệu quả của RAG trong nhiệm vụ so với một mô hình tạo sinh tối tân. Các đánh giá viên cũng thấy các tạo sinh RAG cụ thể hơn với một biên độ lớn. Bảng 3 cho thấy các tạo sinh điển hình từ mỗi mô hình.

Các câu hỏi Jeopardy thường chứa hai mảnh thông tin riêng biệt, và RAG-Token có thể hoạt động tốt nhất vì nó có thể tạo sinh các phản hồi kết hợp nội dung từ nhiều tài liệu. Hình 2 cho thấy một ví dụ. Khi tạo sinh "Sun", posterior cao cho tài liệu 2 đề cập đến "The Sun Also Rises". Tương tự, tài liệu 1 chiếm ưu thế posterior khi "A Farewell to Arms" được tạo sinh. Thú vị, sau token đầu tiên của mỗi cuốn sách được tạo sinh, posterior tài liệu trở nên phẳng. Quan sát này gợi ý rằng bộ tạo sinh có thể hoàn thành các tiêu đề mà không phụ thuộc vào các tài liệu cụ thể. Nói cách khác, kiến thức tham số của mô hình đủ để hoàn thành các tiêu đề. Chúng tôi tìm thấy bằng chứng cho giả thuyết này bằng cách cung cấp cho baseline chỉ BART với giải mã một phần "The Sun". BART hoàn thành tạo sinh "The Sun Also Rises" is a novel by this author of", cho thấy tiêu đề "The Sun Also Rises" được lưu trữ trong các tham số của BART. Tương tự, BART sẽ hoàn thành giải mã một phần "The Sun Also Rises" is a novel by this author of "A" với "The Sun Also Rises" is a novel by this author of "A Farewell to Arms". Ví dụ này cho thấy cách bộ nhớ tham số và phi tham số làm việc cùng nhau—thành phần phi tham số giúp hướng dẫn tạo sinh, rút ra kiến thức cụ thể được lưu trữ trong bộ nhớ tham số.

### 4.4 Xác minh sự thật

Bảng 2 cho thấy kết quả của chúng tôi trên FEVER. Đối với phân loại 3 chiều, điểm số RAG nằm trong 4.3% của các mô hình tối tân, là các hệ thống pipeline phức tạp với kiến trúc chuyên biệt cho domain và kỹ thuật đáng kể, được huấn luyện bằng giám sát truy xuất trung gian, mà RAG không yêu cầu. Đối với phân loại 2 chiều, chúng tôi so sánh với Thorne và Vlachos [57], người huấn luyện RoBERTa [35] để phân loại khẳng định là đúng hay sai được cho câu bằng chứng vàng. RAG đạt được độ chính xác trong 2.7% của mô hình này, mặc dù chỉ được cung cấp khẳng định và truy xuất bằng chứng riêng.

Chúng tôi cũng phân tích liệu các tài liệu được truy xuất bởi RAG có tương ứng với các tài liệu được chú thích như bằng chứng vàng trong FEVER. Chúng tôi tính toán sự chồng chéo trong tiêu đề bài viết giữa k tài liệu hàng đầu được truy xuất bởi RAG và các chú thích bằng chứng vàng. Chúng tôi thấy rằng tài liệu được truy xuất hàng đầu từ một bài viết vàng trong 71% trường hợp, và một bài viết vàng có mặt trong 10 bài viết được truy xuất hàng đầu trong 90% trường hợp.

### 4.5 Kết quả bổ sung

**Đa dạng tạo sinh** Phần 4.3 cho thấy rằng các mô hình RAG thực tế và cụ thể hơn BART cho tạo sinh câu hỏi Jeopardy. Theo công trình gần đây về giải mã thúc đẩy đa dạng [33,59,39], chúng tôi cũng khảo sát đa dạng tạo sinh bằng cách tính toán tỷ lệ các ngram riêng biệt so với tổng ngram được tạo sinh bởi các mô hình khác nhau. Bảng 5 cho thấy rằng các tạo sinh của RAG-Sequence đa dạng hơn RAG-Token, và cả hai đều đa dạng đáng kể hơn BART mà không cần bất kỳ giải mã thúc đẩy đa dạng nào.

**Ablation truy xuất** Một tính năng chính của RAG là học cách truy xuất thông tin liên quan cho nhiệm vụ. Để đánh giá hiệu quả của cơ chế truy xuất, chúng tôi chạy các ablation trong đó chúng tôi đóng băng bộ truy xuất trong quá trình huấn luyện. Như được thể hiện trong Bảng 6, truy xuất đã học cải thiện kết quả cho tất cả các nhiệm vụ.

Chúng tôi so sánh bộ truy xuất dày đặc của RAG với một bộ truy xuất BM25 dựa trên word overlap [53]. Ở đây, chúng tôi thay thế bộ truy xuất của RAG bằng một hệ thống BM25 cố định, và sử dụng điểm truy xuất BM25 như logit khi tính toán pη(z|x). Bảng 6 cho thấy kết quả. Đối với FEVER, BM25 hoạt động tốt nhất, có lẽ vì các khẳng định FEVER rất tập trung vào thực thể và do đó phù hợp tốt cho truy xuất dựa trên word overlap. Truy xuất khả vi cải thiện kết quả trên tất cả các nhiệm vụ khác, đặc biệt cho Open-Domain QA, nơi nó rất quan trọng.

**Index hot-swapping** Một lợi thế của các mô hình bộ nhớ phi tham số như RAG là kiến thức có thể được cập nhật dễ dàng ở thời điểm kiểm tra. Các mô hình chỉ tham số như T5 hoặc BART cần huấn luyện thêm để cập nhật hành vi của chúng khi thế giới thay đổi. Để chứng minh, chúng tôi xây dựng một chỉ mục bằng dump DrQA [5] Wikipedia từ tháng 12 năm 2016 và so sánh đầu ra từ RAG sử dụng chỉ mục này với chỉ mục mới hơn từ kết quả chính của chúng tôi (tháng 12 năm 2018). Chúng tôi chuẩn bị một danh sách 82 lãnh đạo thế giới đã thay đổi giữa các ngày này và sử dụng một mẫu "Who is {position}?" (ví dụ "Who is the President of Peru?") để truy vấn mô hình RAG NQ của chúng tôi với mỗi chỉ mục. RAG trả lời đúng 70% bằng chỉ mục 2016 cho các lãnh đạo 2016 và 68% bằng chỉ mục 2018 cho các lãnh đạo 2018. Độ chính xác với các chỉ mục không khớp thấp (12% với chỉ mục 2018 và lãnh đạo 2016, 4% với chỉ mục 2016 và lãnh đạo 2018). Điều này cho thấy chúng ta có thể cập nhật kiến thức thế giới của RAG bằng cách đơn giản thay thế bộ nhớ phi tham số của nó.

**Hiệu ứng của việc truy xuất nhiều tài liệu hơn** Các mô hình được huấn luyện với 5 hoặc 10 tài liệu ẩn được truy xuất, và chúng tôi không quan sát sự khác biệt đáng kể về hiệu suất giữa chúng. Chúng tôi có tính linh hoạt để điều chỉnh số lượng tài liệu được truy xuất ở thời điểm kiểm tra, có thể ảnh hưởng đến hiệu suất và thời gian chạy. Hình 3 (trái) cho thấy rằng truy xuất nhiều tài liệu hơn ở thời điểm kiểm tra cải thiện kết quả Open-domain QA một cách đơn điệu cho RAG-Sequence, nhưng hiệu suất đạt đỉnh cho RAG-Token ở 10 tài liệu được truy xuất. Hình 3 (phải) cho thấy rằng truy xuất nhiều tài liệu hơn dẫn đến Rouge-L cao hơn cho RAG-Token với cái giá của Bleu-1, nhưng hiệu ứng ít rõ ràng hơn cho RAG-Sequence.

## 5 Công trình liên quan

**Truy xuất nhiệm vụ đơn** Công trình trước đây đã cho thấy rằng truy xuất cải thiện hiệu suất trên nhiều nhiệm vụ NLP khác nhau khi được xem xét riêng lẻ. Những nhiệm vụ như vậy bao gồm hỏi đáp miền mở [5,29], kiểm tra sự thật [56], hoàn thành sự thật [48], hỏi đáp dạng dài [12], tạo sinh bài viết Wikipedia [36], đối thoại [41,65,9,13], dịch thuật [17], và mô hình hóa ngôn ngữ [19,27]. Công trình của chúng tôi thống nhất các thành công trước đây trong việc kết hợp truy xuất vào các nhiệm vụ riêng lẻ, cho thấy rằng một kiến trúc dựa trên truy xuất duy nhất có khả năng đạt được hiệu suất mạnh trên nhiều nhiệm vụ.

**Kiến trúc đa mục đích cho NLP** Công trình trước đây về kiến trúc đa mục đích cho các nhiệm vụ NLP đã cho thấy thành công lớn mà không sử dụng truy xuất. Một mô hình ngôn ngữ đơn, đã được huấn luyện trước đã được chứng minh là đạt được hiệu suất mạnh trên các nhiệm vụ phân loại khác nhau trong các benchmark GLUE [60,61] sau tinh chỉnh [49,8]. GPT-2 [50] sau đó cho thấy rằng một mô hình ngôn ngữ đơn, từ trái sang phải, đã được huấn luyện trước có thể đạt được hiệu suất mạnh trên cả nhiệm vụ phân biệt và tạo sinh. Để cải thiện thêm, BART [32] và T5 [51,52] đề xuất một mô hình encoder-decoder đơn, đã được huấn luyện trước tận dụng attention hai chiều để đạt được hiệu suất mạnh hơn trên các nhiệm vụ phân biệt và tạo sinh. Công trình của chúng tôi nhằm mở rộng không gian các nhiệm vụ có thể với một kiến trúc thống nhất duy nhất, bằng cách học một module truy xuất để tăng cường các mô hình ngôn ngữ tạo sinh đã được huấn luyện trước.

**Truy xuất đã học** Có công trình đáng kể về học cách truy xuất tài liệu trong truy xuất thông tin, gần đây hơn với các mô hình ngôn ngữ thần kinh đã được huấn luyện trước [44,26] tương tự như của chúng tôi. Một số công trình tối ưu hóa module truy xuất để hỗ trợ trong một nhiệm vụ hạ nguồn cụ thể như hỏi đáp, sử dụng tìm kiếm [46], học tăng cường [6,63,62], hoặc phương pháp biến ẩn [31,20] như trong công trình của chúng tôi. Những thành công này tận dụng các kiến trúc dựa trên truy xuất và kỹ thuật tối ưu hóa khác nhau để đạt được hiệu suất mạnh trên một nhiệm vụ đơn, trong khi chúng tôi cho thấy rằng một kiến trúc dựa trên truy xuất duy nhất có thể được tinh chỉnh cho hiệu suất mạnh trên nhiều nhiệm vụ.

**Kiến trúc dựa trên bộ nhớ** Chỉ mục tài liệu của chúng tôi có thể được xem như một bộ nhớ bên ngoài lớn cho các mạng thần kinh để chú ý tới, tương tự như mạng bộ nhớ [64,55]. Công trình đồng thời [14] học cách truy xuất một embedding đã được huấn luyện cho mỗi thực thể trong đầu vào, thay vì truy xuất văn bản thô như trong công trình của chúng tôi. Công trình khác cải thiện khả năng của các mô hình đối thoại tạo sinh văn bản thực tế bằng cách chú ý trên các embedding sự thật [15,13]. Một tính năng chính của bộ nhớ chúng tôi là nó bao gồm văn bản thô thay vì các biểu diễn phân tán, điều này làm cho bộ nhớ vừa (i) có thể đọc được bởi con người, cho một dạng khả năng giải thích cho mô hình của chúng tôi, và (ii) có thể viết được bởi con người, cho phép chúng tôi cập nhật động bộ nhớ của mô hình bằng cách chỉnh sửa chỉ mục tài liệu. Phương pháp này cũng đã được sử dụng trong đối thoại sâu về kiến thức, nơi các bộ tạo sinh đã được điều kiện trên văn bản được truy xuất trực tiếp, mặc dù được thu thập qua TF-IDF thay vì truy xuất đã học đầu-tới-cuối [9].

**Phương pháp Retrieve-and-Edit** Phương pháp của chúng tôi chia sẻ một số điểm tương đồng với các phương pháp kiểu retrieve-and-edit, trong đó một cặp đầu vào-đầu ra huấn luyện tương tự được truy xuất cho một đầu vào cho trước, và sau đó được chỉnh sửa để cung cấp đầu ra cuối cùng. Những phương pháp này đã tỏ ra thành công trong một số domain bao gồm Dịch máy [18,22] và Phân tích cú pháp ngữ nghĩa [21]. Phương pháp của chúng tôi có một số khác biệt, bao gồm ít nhấn mạnh vào việc chỉnh sửa nhẹ một mục được truy xuất, mà là tổng hợp nội dung từ nhiều mảnh nội dung được truy xuất, cũng như học truy xuất ẩn, và truy xuất tài liệu bằng chứng thay vì các cặp huấn luyện liên quan. Điều này nói, các kỹ thuật RAG có thể hoạt động tốt trong những bối cảnh này, và có thể đại diện cho công trình tương lai đầy hứa hẹn.

## 6 Thảo luận

Trong công trình này, chúng tôi trình bày các mô hình tạo sinh lai với quyền truy cập vào bộ nhớ tham số và phi tham số. Chúng tôi cho thấy rằng các mô hình RAG của chúng tôi đạt được kết quả tối tân trên QA miền mở. Chúng tôi thấy rằng mọi người thích tạo sinh của RAG hơn BART hoàn toàn tham số, thấy RAG thực tế và cụ thể hơn. Chúng tôi thực hiện một cuộc khảo sát kỹ lưỡng về thành phần truy xuất đã học, xác nhận hiệu quả của nó, và chúng tôi minh họa cách chỉ mục truy xuất có thể được hot-swap để cập nhật mô hình mà không yêu cầu bất kỳ huấn luyện lại nào. Trong công trình tương lai, có thể sẽ có ích khi khảo sát liệu hai thành phần có thể được huấn luyện trước chung từ đầu, hoặc với một mục tiêu khử nhiễu tương tự như BART hoặc một mục tiêu khác nào đó. Công trình của chúng tôi mở ra các hướng nghiên cứu mới về cách bộ nhớ tham số và phi tham số tương tác và cách kết hợp chúng một cách hiệu quả nhất, cho thấy triển vọng trong việc được áp dụng cho một loạt rộng các nhiệm vụ NLP.

## Tác động rộng hơn

Công trình này cung cấp một số lợi ích xã hội tích cực so với công trình trước đây: thực tế là nó được căn cứ mạnh mẽ hơn trong kiến thức thực tế thực sự (trong trường hợp này là Wikipedia) làm cho nó "ảo giác" ít hơn với các tạo sinh thực tế hơn, và cung cấp nhiều kiểm soát và khả năng giải thích hơn. RAG có thể được sử dụng trong nhiều kịch bản khác nhau với lợi ích trực tiếp cho xã hội, ví dụ bằng cách trang bị cho nó một chỉ mục y tế và hỏi nó các câu hỏi miền mở về chủ đề đó, hoặc bằng cách giúp mọi người hiệu quả hơn trong công việc của họ.

Với những lợi thế này cũng đi kèm những nhược điểm tiềm ẩn: Wikipedia, hoặc bất kỳ nguồn kiến thức bên ngoài tiềm năng nào, có lẽ sẽ không bao giờ hoàn toàn thực tế và hoàn toàn không có thiên kiến. Vì RAG có thể được sử dụng như một mô hình ngôn ngữ, những mối quan tâm tương tự như đối với GPT-2 [50] có hiệu lực ở đây, mặc dù có thể ở mức độ ít hơn, bao gồm rằng nó có thể được sử dụng để tạo ra lạm dụng, nội dung giả mạo hoặc gây hiểu lầm trong tin tức hoặc trên mạng xã hội; để mạo danh người khác; hoặc để tự động hóa việc sản xuất nội dung spam/phishing [54]. Các mô hình ngôn ngữ tiên tiến cũng có thể dẫn đến việc tự động hóa các công việc khác nhau trong những thập kỷ tới [16]. Để giảm thiểu những rủi ro này, các hệ thống AI có thể được sử dụng để chống lại nội dung gây hiểu lầm và spam/phishing tự động.

## Lời cảm ơn

Các tác giả muốn cảm ơn các reviewer vì phản hồi chu đáo và mang tính xây dựng của họ về bài báo này, cũng như HuggingFace vì sự giúp đỡ của họ trong việc mở mã nguồn để chạy các mô hình RAG. Các tác giả cũng muốn cảm ơn Kyunghyun Cho và Sewon Min vì các cuộc thảo luận và lời khuyên có ích. EP cảm ơn sự hỗ trợ từ NSF Graduate Research Fellowship. PL được hỗ trợ bởi chương trình FAIR PhD.

# 2305.15387.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2305.15387.pdf
# Kích thước file: 873514 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Nhìn Qua: Cải Thiện Mô Hình Đa Tài Liệu
thông qua Hỏi Đáp Liên Tài Liệu
Avi Caciularu1∗Matthew E. Peters2Jacob Goldberger1
Ido Dagan1Arman Cohan2,3
1Đại học Bar-Ilan, Ramat-Gan, Israel
2Viện Allen về AI, Seattle, WA
3Đại học Yale, New Haven, CT
avi.c33@gmail.com, arman.cohan@yale.edu
Tóm tắt
Việc tích hợp các mục tiêu tiền huấn luyện đa tài liệu
vào các mô hình ngôn ngữ đã mang lại những
cải thiện đáng kể trong các tác vụ hạ nguồn đa tài liệu.
Trong nghiên cứu này, chúng tôi đề xuất
mở rộng ý tưởng này bằng cách tiền huấn luyện một
mô hình đa tài liệu tổng quát từ một mục tiêu
tiền huấn luyện hỏi đáp liên tài liệu mới lạ.
Để thực hiện điều đó, cho một tập (hoặc cụm)
các tài liệu có liên quan về chủ đề, chúng tôi có hệ thống
tạo ra các câu hỏi định hướng ngữ nghĩa
từ một câu nổi bật trong một tài liệu và
thách thức mô hình, trong quá trình tiền huấn luyện, trả lời
những câu hỏi này trong khi "nhìn trộm" vào
các tài liệu có liên quan chủ đề khác. Theo cách
tương tự, mô hình cũng được thách thức
khôi phục câu mà từ đó câu hỏi
được tạo ra, một lần nữa trong khi tận dụng
thông tin liên tài liệu. Công thức hỏi đáp đa
tài liệu mới lạ này hướng dẫn mô hình
khôi phục tốt hơn các mối quan hệ thông tin liên văn bản,
và giới thiệu một sự tăng cường tự nhiên
làm tăng nhân tạo dữ liệu tiền huấn luyện.
Hơn nữa, không giống như các mô hình đa tài liệu
trước đây tập trung vào các tác vụ phân loại hoặc
tóm tắt, công thức mục tiêu tiền huấn luyện
của chúng tôi cho phép mô hình thực hiện các tác vụ
bao gồm cả sinh văn bản ngắn (ví dụ: QA)
và sinh văn bản dài (ví dụ: tóm tắt).
Theo sơ đồ này, chúng tôi tiền huấn luyện mô hình
của chúng tôi – được gọi là QAMD EN– và đánh giá hiệu suất
của nó trên nhiều tác vụ đa tài liệu,
bao gồm QA đa tài liệu, tóm tắt,
và tóm tắt tập trung truy vấn, mang lại những
cải thiện lên đến 7%, và vượt trội đáng kể
so với GPT-3.5 và GPT-4 không cần ví dụ.1
1 Giới thiệu
Trong số các nghiên cứu NLP gần đây, xử lý đa tài liệu
đang nhận được sự chú ý ngày càng tăng, do
nhu cầu xử lý và xử lý một lượng dữ liệu
văn bản và tài liệu ngày càng tăng trực tuyến. Một
∗Công việc một phần được thực hiện như thực tập sinh tại AI2.
1Mã nguồn của chúng tôi có sẵn tại https://github.com/
aviclu/peekacross .
(1) một tập các tài liệu 
liên quan (2) tài liệu 
  ngữ cảnh Tiền huấn luyện bằng cách truy vấn các tài liệu ngữ cảnh 
(3) tài liệu 
tách biệt 
 Q: Karol đã đi đâu? 
A: Cô ấy đã đến đám cưới 
của Sandra. 
(4)(5)(6)
tách bỏHình 1: Minh họa về quá trình tiền huấn luyện và tạo dữ liệu
của chúng tôi. Với một tập các tài liệu liên quan được xem xét (1)
mà chúng tôi chia thành các tài liệu ngữ cảnh (2) và một
tài liệu tách biệt (3), chúng tôi chọn câu nổi bật nhất (4)
được sử dụng để tạo ra một cặp câu hỏi-câu trả lời (5).
Sau đó, chúng tôi tiền huấn luyện một mô hình bằng cách tạo ra câu trả lời
phù hợp và câu nổi bật, cho câu hỏi và
các tài liệu ngữ cảnh (6).
số ứng dụng nổi bật quan tâm
đến việc tổng hợp thông tin từ nhiều
văn bản là tóm tắt đa tài liệu (Fabbri
và cộng sự, 2019; Zhao và cộng sự, 2020), tóm tắt đa
tài liệu tập trung truy vấn (Xu và Lapata, 2020;
Pasunuru và cộng sự, 2021a), và trả lời câu hỏi
đa bước (Yang và cộng sự, 2018; Welbl và cộng sự, 2018).
Những tác vụ này vẫn thách thức chủ yếu vì các
mô hình NLP hiện tại được thiết kế để xử lý
văn bản đơn lẻ, thay vì xử lý nhiều tài liệu cùng
một lúc (Caciularu và cộng sự, 2021).
Các giải pháp ban đầu cho xử lý đa văn bản là
cụ thể cho từng tác vụ và sử dụng các kiến trúc phức tạp
khó tổng quát hóa trên các tác vụ đa
tài liệu khác nhau (Liu và Lapata, 2019; Wang và cộng sự,
2020; Ginzburg và cộng sự, 2021). Các LM hiệu quả (Tay
và cộng sự, 2021; Beltagy và cộng sự, 2020) gần đây đã chứng minh
rằng bằng cách đơn giản nối các tài liệu nhiều
vào một chuỗi duy nhất, transformer có thể
đảm nhận mục tiêu xác định và kết nối thông tin
liên quan giữa các tài liệu. Gần đây,
đã được đề xuất rằng những LM ngữ cảnh dài này có thể
được trang bị các mục tiêu tiền huấn luyện mới để
cho phép chúng xử lý nhiều tài liệu hiệu quả
hơn (Caciularu và cộng sự, 2021; Xiao và cộng sự, 2022;arXiv:2305.15387v1  [cs.CL]  24 Tháng 5 2023

--- TRANG 2 ---
Yasunaga và cộng sự, 2022).
Những mô hình tiền huấn luyện này đã chứng minh hiệu suất
tối tân trên nhiều tác vụ hạ nguồn đa tài liệu,
và vượt trội so với các LM cơ bản
và kiến trúc cụ thể cho từng tác vụ. Những mô hình như vậy
thường được tiền huấn luyện sử dụng một bộ dữ liệu trong đó mỗi
thể hiện là một tập các tài liệu liên quan (ví dụ: các bài báo
tin tức đều thảo luận về một sự kiện cụ thể), điều này tạo điều kiện
thuận lợi cho việc mô hình hóa các mối quan hệ liên văn bản. Các
mục tiêu tiền huấn luyện đa tài liệu hiện tại bao gồm bỏ
mặt nạ token trong một tài liệu (Caciularu và cộng sự,
2021), hoặc tạo ra một câu nổi bật được mặt nạ
(Zhang và cộng sự, 2020; Xiao và cộng sự, 2022), khuyến khích
mô hình khôi phục thông tin bị thiếu sử dụng
các tài liệu khác. Mặc dù thành công, những mô hình này
hoặc bị giới hạn ở các tác vụ phân loại (Caciularu và cộng sự,
2021) hoặc chủ yếu được thiết kế cho tóm tắt
(Zhang và cộng sự, 2020; Xiao và cộng sự, 2022).
Trong nghiên cứu này, chúng tôi đề xuất một mục tiêu tiền huấn luyện
mới lạ hỗ trợ cả sinh văn bản ngắn và dài,
dẫn đến một mô hình ngôn ngữ đa tài liệu
đa năng và tổng quát. Cụ thể, chúng tôi giả
định rằng việc sử dụng câu hỏi và câu trả lời liên quan
đến nhiều tài liệu có thể khuyến khích mô hình
học tốt hơn và kết hợp cả thông tin chi tiết
(bằng cách đặt câu hỏi về các đơn vị thông tin cốt lõi
trong một câu cụ thể) cũng như các mối quan hệ
liên tài liệu thô cần thiết để
tạo ra một văn bản dài như bản tóm tắt. Chúng tôi cho thấy
rằng cách tiếp cận này không chỉ đúng cho tóm tắt,
mà còn cho các tác vụ hạ nguồn đa tài liệu khác.
Trong quá trình tiền huấn luyện của các
mô hình ngôn ngữ đa tài liệu hiện tại, mục tiêu là bỏ
mặt nạ các khoảng (cho các mô hình chỉ mã hóa) hoặc tạo ra
các khoảng văn bản được mặt nạ (cho các mô hình mã hóa-giải mã)
dưới ngữ cảnh đa tài liệu. Để thực hiện điều đó, nhiều
chuỗi nối tiếp của các tài liệu liên quan
được cung cấp trong quá trình tiền huấn luyện, do đó đòi hỏi một số lượng lớn
các tập tài liệu liên quan cho một
giai đoạn tiền huấn luyện hiệu quả (Hoffmann và cộng sự, 2022). Trong
nhiều benchmark đa tài liệu hiện tại,
như tóm tắt đa tài liệu, chỉ có các cụm tài liệu
quy mô nhỏ đến trung bình có sẵn ngay. Những cụm này
được thu thập hoặc tự động với
độ tương tự từ vựng và truy xuất (Fabbri và cộng sự, 2019)
hoặc bán tự động (Gu và cộng sự, 2020), nhưng nói chung,
quá trình này đòi hỏi một lượng công sức
con người đáng kể để lọc các thể hiện và tạo ra
corpus chất lượng cao.
Bằng cách sử dụng một quy trình tạo câu hỏi-trả lời đa tài liệu mới lạ, chúng tôi đề xuất một phương
pháp hiệu quả để mở rộng corpus tiền huấn luyện
đa tài liệu. Cách tiếp cận của chúng tôi cho phép chúng tôi
cung cấp nhiều góc nhìn cho mỗi cụm tài liệu
đơn lẻ, từ đó tăng nhân tạo kích thước dữ liệu
tiền huấn luyện (về số lượng thể hiện)
thông qua tăng cường. Để đưa mô hình tiếp xúc với nhiều
ngữ cảnh và đa dạng hóa dữ liệu tiền huấn luyện, chúng tôi
đề xuất tạo ra nhiều cặp câu hỏi và
câu trả lời và điều kiện chúng trên một tập con của
cụm tài liệu. Chúng tôi chọn một câu nổi bật trong một
tài liệu tách biệt và sau đó sử dụng một bộ phân tích
gần đây để tạo ra một cặp câu hỏi-trả lời chất lượng cao
về một vị từ trong câu được chọn, sử dụng
một cách tiếp cận có hệ thống định hướng ngữ nghĩa (Klein
và cộng sự, 2022). Mục tiêu tiền huấn luyện đa tài liệu mới
này thách thức mô hình tạo ra cả câu trả lời
cho câu hỏi cũng như câu nổi bật,
trong khi loại bỏ tài liệu tách biệt hoặc
các phần của nó (xem Hình 1, 2 để minh họa). Quy
trình này đưa mô hình tiếp xúc với nhiều ngữ
cảnh – một câu hỏi và một tập con khác nhau của các
tài liệu trong cụm cho mỗi thể hiện, trái ngược với
các phương pháp trước đây chỉ cung cấp một góc nhìn duy nhất của
cụm. Đóng góp của chúng tôi được tóm tắt dưới đây:
•Một cách tiếp cận tiền huấn luyện mới cho mô hình hóa
đa tài liệu, được công thức hóa như một tác vụ
trả lời câu hỏi liên tài liệu, hướng dẫn thêm
LM để mô hình hóa các mối quan hệ liên văn bản,
tập trung vào cả thông tin chi tiết và thô.
•Số lượng ví dụ tiền huấn luyện được
tạo ra bởi phương pháp đề xuất của chúng tôi không bị
giới hạn bởi số lượng cụm, cho phép sản xuất
nhiều ngữ cảnh liên tài liệu.
•Mô hình Question- Answering-based
Multi-Docum ENt (QAMD EN) kết quả đã
tiến bộ tối tân cho một số tác vụ đa
tài liệu.
2 Công việc liên quan
Các transformer tạo văn bản ngữ cảnh dài hiệu quả
(Tay và cộng sự, 2021, 2022) mở rộng các mô hình
transformer trước đây (Vaswani và cộng sự, 2017) để xử lý
các chuỗi dài, thường sử dụng kiến trúc tự chú ý
thưa thớt. Các ví dụ bao gồm Longformer
Encoder-Decoder (LED) (Beltagy và cộng sự, 2020),
và LongT5 (Guo và cộng sự, 2022). Những mô hình này
đã chứng minh rằng các cách tiếp cận văn bản đơn lẻ có thể
được điều chỉnh cho các tác vụ đa tài liệu bằng cách nối

--- TRANG 3 ---
nhiều tài liệu thành một chuỗi duy nhất và
xử lý chúng sử dụng các mẫu chú ý thưa thớt. Chúng
làm thưa thớt ma trận tự chú ý đầy đủ
của transformer bằng cách sử dụng kết hợp của một cửa sổ trượt
cục bộ (được gọi là chú ý cục bộ), cũng như
một mẫu chú ý toàn cục trên một vài vị trí
đầu vào cụ thể. LED được xây dựng dựa trên mô hình BART
(Lewis và cộng sự, 2020) bằng cách sử dụng embedding vị trí
bổ sung và trọng số chú ý toàn cục,
và giới thiệu chế độ chú ý toàn cục hoạt động
trên các token được chọn trước. LongT5 mở rộng
mô hình T5 (Raffel và cộng sự, 2020) bằng cách sử dụng kỹ thuật
tương tự được giới thiệu trong các mô hình ETC và BIGBIRD
(Ainslie và cộng sự, 2020; Zaheer và cộng sự, 2020),
giảm bớt yêu cầu chọn thủ công các token toàn cục
bằng cách tự động toàn cầu hóa các biểu diễn
tổng hợp của các nhóm token.
Các chiến lược khác đã được đề xuất để
tăng khả năng của những mô hình này trong các tác vụ đa tài liệu.
Mô hình Ngôn ngữ Liên Tài liệu
(CDLM) (Caciularu và cộng sự, 2021) đề xuất tiền
huấn luyện một Longformer-encoder (Beltagy và cộng sự,
2020) trên các tập tài liệu liên quan, và cho thấy
kết quả hiệu suất vượt trội trên một số tác vụ đa
tài liệu. Theo phương pháp này, các tác giả
của LinkBERT (Yasunaga và cộng sự, 2022) đã sử dụng
cách tiếp cận tương tự, nhưng sử dụng các siêu liên kết
của Wikipedia để thu thập các cặp tài liệu
liên kết có thông tin cho việc tiền huấn luyện LM.
Để áp dụng cách tiếp cận tiền huấn luyện đa tài liệu
cho các tác vụ chuỗi-đến-chuỗi,
PRIMERA (Xiao và cộng sự, 2022), được xây dựng trên
mô hình Longformer encoder-decoder (LED),
đã chọn các câu nổi bật trong các cụm tài liệu
liên quan sử dụng phương pháp ước lượng kim tự tháp,
giống với phương pháp được trình bày để tiền huấn luyện
mô hình PEGASUS tài liệu đơn (Zhang và cộng sự,
2020). Mặc dù công việc này gần nhất với công việc của chúng tôi,
nó được tiền huấn luyện để tạo ra các câu nổi bật
được mặt nạ mà không có bất kỳ điều khiển nào, điều này khiến mô hình
có thể ảo giác trong khi tạo văn bản, trong khi
mô hình của chúng tôi sử dụng mục tiêu dựa trên QA được kiểm soát.
Hơn nữa, không giống như những công việc này, phương pháp của chúng tôi
tạo ra dữ liệu nhiều hơn đáng kể so với dữ liệu được sử dụng để tiền huấn luyện
PRIMERA , điều này có thể đạt được bằng phương pháp
tạo QA tài liệu đơn. Công thức tiền huấn luyện QA
của chúng tôi cho phép chúng tôi tạo ra nhiều
ngữ cảnh cho mỗi cụm tài liệu.
Một dòng công việc liên quan khác bao gồm các phương pháp
kết hợp dữ liệu QA được tạo quy mô lớn để
tiền huấn luyện LM (He và cộng sự, 2020; Jia và cộng sự, 2022;
(a) Tài liệu tách biệt 
bị loại bỏ khỏi 
ngữ cảnh 
(c) Tài liệu tách biệt được 
bao gồm trong ngữ cảnh, nhưng 
câu trả lời trong câu neo 
bị mặt nạ 
(b) Tài liệu tách biệt 
được bao gồm trong ngữ cảnh, 
nhưng câu neo bị 
mặt nạ Hình 2: Sơ đồ các chế độ dữ liệu tiền huấn luyện của chúng tôi.
Câu nổi bật được sử dụng để tạo QA
được tô màu vàng. (a) Ngữ cảnh không bao gồm
tài liệu tách biệt, do đó chế độ này là
thách thức nhất. (b) Tài liệu tách biệt có mặt trong
ngữ cảnh, nhưng câu nổi bật được sử dụng để tạo QA
bị mặt nạ (màu đỏ). (c) Tài liệu tách biệt có mặt trong
ngữ cảnh, nhưng khoảng câu trả lời trong
câu nổi bật bị mặt nạ (màu đỏ).
Huber và cộng sự, 2022). Những công việc này giả định và
cho thấy rằng tiền huấn luyện bằng cách sử dụng dữ liệu QA
được tạo có thể khuyến khích các biểu diễn ngữ cảnh
mã hóa thông tin ngữ nghĩa hữu ích cho các tác vụ hạ nguồn
không phải QA khác. Được truyền cảm hứng từ điều đó, chúng tôi
phỏng đoán rằng LM có thể được hưởng lợi mạnh mẽ từ việc
truyền QA trong quá trình tiền huấn luyện trong thiết lập đa tài liệu,
để thêm tín hiệu bổ sung cho việc mô hình hóa
các mối quan hệ liên văn bản.
3 Tăng cường Mục tiêu Tiền huấn luyện
Đa tài liệu
Trong phần này, chúng tôi cung cấp các bước cần thiết để
biên soạn bộ dữ liệu tiền huấn luyện cho QAMD EN.
Tiếp theo chúng tôi mô tả chi tiết về việc tạo dữ liệu
và cung cấp phân tích về corpus kết quả.
Các công việc gần đây đã cho thấy rằng đối với tóm tắt văn bản,
việc tiền huấn luyện LM để tạo ra một chuỗi "giống như tóm tắt",
được gọi là tóm tắt giả , vốn dĩ
mang lại lợi ích so với các LM tiền huấn luyện
mục đích chung ( PEGASUS ,PRIMERA ; Zhang và cộng sự, 2020;
Xiao và cộng sự, 2022). Dữ liệu mà các mô hình PEGASUS
vàPRIMERA được tiền huấn luyện được xây dựng
sử dụng phương pháp Tạo Câu Khoảng trống (GSG),
đề xuất mặt nạ các câu nổi bật được xếp hạng cao,
trong đó sự nổi bật được xác định trước
bởi một phương pháp chấm điểm câu quan tâm. Cụ thể,
trong PEGASUS , GSG đã được áp dụng như
mục tiêu tiền huấn luyện của nó, trong đó một số câu trong
tài liệu đầu vào đơn lẻ bị mặt nạ trong đầu vào và
mô hình được giao nhiệm vụ tạo ra chúng.
Chính thức, đối với mỗi câu sí trong một tài liệu đầu vào
đã cho D,PEGASUS tính điểm nổi bật của nó
dựa trên điểm ROUGE (Lin, 2004) đối với phần còn lại
của các câu trong tài liệu ( D/{si}),
tức là Score( si) =ROUGE (si, D/{si}). Trực giác,

--- TRANG 4 ---
…Pokemon Sword và Shield có thể đã được công bố, nhưng chúng ta 
bây giờ biết có một trò chơi Pokemon mới khác đang trên đường từ DeNA …
Tạo QA QASem (Klein và cộng sự, 2022) 
Q1: Cái gì có thể đã được công bố? A1: Pokemon Sword và Shield. 
(Độ dài câu trả lời: 4) 
Q3: Ai biết điều gì đó? A: Chúng ta. 
(Độ dài câu trả lời: 1) Q2: Ai đó biết điều gì đó ở đâu?  A: Trên đường 
từ DeNA.  (Độ dài câu trả lời: 5) 
Ngữ cảnh hóa (Pyatkin và cộng sự, 2022) 
Q: Chúng ta biết có một trò chơi Pokemon mới khác ở đâu? 
A: Trên đường từ DeNA. 
Được chọn Hình 3: Sơ đồ quy trình tạo QA
sử dụng QAS EM(Klein và cộng sự, 2022) và mô hình ngữ cảnh hóa
từ Pyatkin và cộng sự (2021). Đây là một mẫu thực tế
đã được tạo và sử dụng để tiền huấn luyện
QAMD EN, trong đó tài liệu được lấy từ New-
SHead (Gu và cộng sự, 2020).
metric này gán điểm cao cho các câu
có độ chồng chéo cao và chia sẻ nhiều thông tin từ vựng
với phần còn lại của các câu trong
tài liệu, do đó gán điểm cao cho các
câu nổi bật. PRIMERA đã tổng quát hóa khái niệm này để
hỗ trợ thiết lập đa tài liệu, bằng cách áp dụng một biến thể GSG
trên một cụm tài liệu liên quan.
GSG Liên Tài liệu. Chúng tôi đề xuất tăng cường
kỹ thuật GSG để công thức hóa một mục tiêu tiền huấn luyện
trả lời câu hỏi liên tài liệu cho các tác vụ đa
tài liệu, thay vì các phương pháp tạo tóm tắt
giả hiện tại. Cách tiếp cận của chúng tôi hỗ trợ
xác định cả thông tin chi tiết và thô
như chúng tôi mô tả dưới đây, và dẫn đến
một lượng ví dụ tiền huấn luyện lớn hơn đáng kể
so với các phương pháp trước đây.
Chính thức, chúng tôi được cho một cụm các tài liệu
liên quan S=
D1, D2, . . . , D |S|
trong một corpus
C. Điểm nổi bật GSG liên tài liệu (CD) của chúng tôi
cho câu thứ i trong tài liệu thứ k trong
tập ( si
k), được định nghĩa bởi điểm ROUGE của nó đối với
phần còn lại của các câu trong tài liệu
(Dk/{si
k}) cũng như các tài liệu khác ( S/Dk),
tức là CD-GSG-Score( si
k) =ROUGE (si
k,S/{si
k}).
Sau đó, đối với mỗi tài liệu k, theo Zhang và cộng sự
(2020); Xiao và cộng sự (2022) chúng tôi chọn câu có điểm cao nhất s∗
k, và sau đó chúng tôi sử dụng câu này để tạo
ra một cặp câu hỏi và câu trả lời.
Tạo QA Liên Tài liệu. Để tạo
ra các câu hỏi liên tài liệu và câu trả lời của chúng,
chúng tôi sử dụng QAS EM, một khung phân tích ngữ nghĩa
gần đây để tạo câu hỏi (Klein và cộng sự,Thuật toán 1: Tạo Dữ liệu Tiền huấn luyện
Đầu vào: Một corpus văn bản của các cụm tài liệu
C={S1, ...,S|C|}, và một bộ tạo câu hỏi-trả lời
QAS EM(·).
Đầu ra: Bộ dữ liệu tiền huấn luyện D.
1D ← ∅ ;
2forn←1to|C|do
3 fork←1to|Sn|do
4 s∗
k←arg max
iCD-GSG-Score( si
k);
5 (q∗
k, a∗
k)←QAS EM(s∗
k);
6 t∗
k= [a∗
k, s∗
k]# văn bản đích;
7 D ← D ∪ { ([Sn/Dk, q∗
k], t∗
k)}# (a);
8 D ← D ∪ { ([Sn/{s∗
k}, q∗
k], t∗
k)}# (b);
9 D ← D ∪ { ([Sn/{a∗
k}, q∗
k], t∗
k)}# (c);
10Return D;
2022).2QAS EM nhằm mục đích thu hút một tài khoản
có thể quản lý, rời rạc về thông tin trong một văn bản
vì mục đích xây dựng các biểu diễn ngữ nghĩa
ngôn ngữ tự nhiên. Nó tự động gắn nhãn mỗi
mối quan hệ vị từ-luận cứ bằng
một cặp câu hỏi-trả lời, trong đó một câu hỏi ngôn ngữ tự nhiên
đại diện cho một vai trò ngữ nghĩa, trong khi các câu trả lời
tương ứng với các luận cứ xuất hiện trong văn bản đầu vào.
QAS EMdo đó là một cách tiếp cận hấp dẫn vì nó
có khả năng tạo ra nhiều câu hỏi chất lượng cao
cho một câu. Chúng tôi áp dụng QAS EMtrên
các câu trong dữ liệu tiền huấn luyện để
tạo ra các cặp câu hỏi-trả lời, và sau đó áp dụng
mô hình từ Pyatkin và cộng sự (2021) để biến đổi
câu hỏi thành dạng tự nhiên và rõ ràng hơn,
với các luận cứ được ngữ cảnh hóa (xem ví
dụ trong Hình 3). Để giống với một tác vụ tóm tắt
trong đó văn bản được tạo thường
dài, chúng tôi chọn cặp câu hỏi-trả lời với
luận cứ dài nhất được tạo ra bởi QAS EM. Chính thức,
QAS EM(·)nhận một câu s∗
klàm đầu vào, và
tạo ra cặp câu hỏi-trả lời (q∗
k, a∗
k), trong đó a∗
k
là dài nhất trong số các câu trả lời được tạo ra. Xem
ví dụ chi tiết và mô tả đầy đủ trong Phụ lục A.1.
Xem xét cặp câu hỏi-trả lời, mục tiêu của chúng tôi là
khuyến khích LM tạo ra câu trả lời đúng
cũng như câu nổi bật trong ngữ cảnh đa tài liệu
để học các mối quan hệ liên văn bản.
Quy trình Tạo Dữ liệu. Để tạo điều kiện thuận lợi
cho việc xây dựng ngữ cảnh đa tài liệu, chúng tôi
đề xuất ba chế độ khác nhau, mỗi chế độ chịu trách nhiệm
khám phá thông tin bằng cách sử dụng các
ngữ cảnh khác nhau. Đối với tất cả các chế độ, trước tiên chúng tôi tạo ra một cặp QA
từ câu nổi bật nhất trong tài liệu
tách biệt.
2Chúng tôi đã thử một số phương pháp tạo câu hỏi hàng đầu, và
QAS EMgiới thiệu chất lượng câu hỏi vượt trội, được quy cho
bản chất bán cấu trúc của nó. Xem §4.4 cho kết quả thực nghiệm.

--- TRANG 5 ---
(a)Loại trừ tài liệu nguồn. Trong chế độ
này chúng tôi bỏ qua tài liệu tách biệt Dkkhỏi
ngữ cảnh Snđược cung cấp cho mô hình, tức là, Sn/Dk.
Do đó, mô hình được giao nhiệm vụ dự đoán câu trả lời
mà không có quyền truy cập vào tài liệu nguồn
nào cả, và bị hạn chế chỉ quan sát các tài liệu khác
trong tập. Vì vậy, chế độ này được coi là
thách thức nhất.
(b)Mặt nạ câu nổi bật. Trong chế độ này,
câu nổi bật nguồn bị mặt nạ, tức là, Sn/{s∗
k}.
Mô hình có quyền truy cập vào ngữ cảnh xung quanh
của câu bị mặt nạ trong tài liệu tách biệt,
cũng như các tài liệu khác trong tập.
(c)Mặt nạ câu trả lời. Trong chế độ này, chỉ có
khoảng câu trả lời trong câu nổi bật bị mặt nạ,
tức là,Sn/{a∗
k}. Mô hình có quyền truy cập vào
câu nổi bật xung quanh, cũng như tất cả các
tài liệu trong tập.
Như một phần của quy trình tiền huấn luyện mới của
mô hình đa tài liệu mới lạ của chúng tôi, chúng tôi nối câu hỏi
sau ngữ cảnh và hướng dẫn mô hình
tạo ra một câu trả lời theo sau bởi câu nổi bật
của nó, tức là, output =⟨answer ⟩,⟨sentence ⟩,
được truyền cảm hứng từ Bohnet và cộng sự (2022). Tạo ra
câu nổi bật giới thiệu một cơ chế sao chép
(cho phép mô hình cũng học cách sao chép thông tin
từ nguồn trực tiếp) cũng như cho phép tạo văn bản
dài, điều này rất quan trọng cho các tác vụ tóm tắt
hạ nguồn (Zhang và cộng sự, 2020), cũng như
vượt trội so với một mô hình được tiền huấn luyện để
tạo ra chỉ câu trả lời – theo nghiên cứu
khử, thiết lập này mang lại kết quả hiệu suất tốt nhất (§4.4). Trong giai đoạn đánh giá tiền huấn luyện,
tập tách biệt được chia và mất mát được đo
riêng biệt cho mỗi chế độ dữ liệu. Như mong đợi,
chúng tôi quan sát thấy rằng mất mát cho (a) cao
hơn đáng kể so với những chế độ khác,
với xếp hạng (a) ≻(b)≻(c) cao nhất. Quy trình
tạo dữ liệu tiền huấn luyện được tóm tắt
trong Thuật toán 1 và Hình 2.
Corpus tiền huấn luyện kết quả. Chúng tôi áp dụng
quy trình của chúng tôi trên corpus NewSHead (Gu
và cộng sự, 2020), bao gồm một tập các tài liệu liên quan
cho mỗi thể hiện. Đây chính xác là corpus
tiền huấn luyện được sử dụng cũng bởi baseline chính
PRIMERA (Xiao và cộng sự, 2022) (Xem Phụ lục A để biết thêm
chi tiết).
Sử dụng quy trình tạo dữ liệu của chúng tôi, chúng tôi đã
tạo ra 3,579,323 ví dụ tiền huấn luyện và 13,475Mô hình Bộ dữ liệu Tiền huấn luyện #cụm #thể hiện
CDLM (2021) Multi-News (2019) 56K 56K
PRIMERA (2022) NewSHead (2020) 367K 367K
QAMD EN(của chúng tôi) NewSHead (2020) 367K 4.3M
Bảng 1: Thống kê corpus tiền huấn luyện được sử dụng bởi các
mô hình đa tài liệu. Các số được báo cáo là số lượng
cụm tài liệu và số lượng thể hiện tiền huấn luyện
duy nhất.
ví dụ tách biệt, trong đó trung bình, mỗi 3.5 thể
hiện bắt nguồn từ cùng một cụm tài liệu liên quan. Trong Bảng 1, chúng tôi mô tả so sánh
các corpus tiền huấn luyện cho các LM đa tài liệu
liên quan so với dữ liệu tiền huấn luyện QAMD ENcủa chúng tôi.
4 Thiết lập Thí nghiệm và Kết quả
Phần này trình bày các thí nghiệm được thực hiện để
đánh giá QAMD EN, cũng như các ablation
và baseline chúng tôi đã sử dụng. Để đánh giá nội tại
chúng tôi đánh giá các mô hình trên các tác vụ QA đa tài liệu.
Để đánh giá ngoại tại chúng tôi xem xét tác vụ tóm tắt
trừu tượng đa tài liệu.
Chi tiết Triển khai Mô hình Theo Xiao
và cộng sự (2022), chúng tôi sử dụng Longformer-
Encoder-Decoder (LED) cỡ lớn (Beltagy và cộng sự, 2020) để
khởi tạo mô hình của chúng tôi. Giới hạn độ dài của
đầu vào và đầu ra lần lượt là 4096 và 1024.3
Theo triển khai Huggingface (Wolf
và cộng sự, 2020), chúng tôi đặt kích thước cửa sổ trượt thành 1024
cho chú ý cục bộ trong phần encoder.
Tương tự như mô hình PRIMERA (Xiao và cộng sự,
2022), khi nối các tài liệu và
câu hỏi, chúng tôi thêm một token phân tách tài liệu đặc biệt
(<doc-sep> ) giữa các tài liệu để báo
hiệu cho mô hình nhận biết về ranh giới
tài liệu. Chúng tôi cũng gán chế độ chú ý toàn cục cho
những token này cho phép mô hình chia sẻ thông
tin qua các tài liệu (Caciularu và cộng sự, 2021).
Để biết thêm chi tiết về siêu tham số và thực thi tiền huấn luyện,
xem Phụ lục B.
4.1 Trả lời Câu hỏi Đa tài liệu
QA đa tài liệu là tác vụ tạo ra
câu trả lời đúng, cho một tập các
tài liệu liên quan nhiều. Đối với một số benchmark QA đa tài liệu,
các mô hình thường được giao nhiệm vụ ngầm
giải quyết nhiều tác vụ con hoặc theo các bước trung gian,
như hiểu câu hỏi, lọc
ra các tài liệu làm nhiễu trong ngữ cảnh, và
3Các tác vụ trong công việc này tiêu thụ đầu vào lên đến 4k token.

--- TRANG 6 ---
khâu nối các mảnh thông tin qua các
tài liệu liên quan (Geva và cộng sự, 2021; Caciularu và cộng sự,
2022). Nhớ lại rằng QAMD ENđã được tiền huấn luyện
trên một bộ dữ liệu QA đa tài liệu
được tạo tự động. Do đó, như một đánh giá sơ bộ,
trước tiên chúng tôi điều tra hiệu suất của QAMD ENtrên
hai benchmark QA đa tài liệu, HopotQA-
distractor (Yang và cộng sự, 2018) và WikiHop (Welbl
và cộng sự, 2018) (xem thêm chi tiết về các bộ dữ liệu trong
Phụ lục C.1), và so sánh với các mô hình khác đã được
tiền huấn luyện sử dụng các mục tiêu bỏ mặt nạ cơ bản.
Định dạng Tinh chỉnh. Để theo sơ đồ tiền huấn luyện
của chúng tôi, chúng tôi nối câu hỏi vào ngữ cảnh
và tinh chỉnh mô hình để tạo ra câu trả lời đúng.
Chúng tôi sử dụng Longformer Encoder-Decoder
(LED) (Beltagy và cộng sự, 2020) và PRIMERA (Xiao
và cộng sự, 2022) làm baseline, để đánh giá
đóng góp của định dạng tiền huấn luyện của chúng tôi. Được xác nhận bởi
Beltagy và cộng sự (2020), chúng tôi phát hiện ra rằng việc nối
các tiền tố question: vàcontext: trước
các token câu hỏi và ngữ cảnh, tương ứng,
dẫn đến hiệu suất tốt hơn.
Baseline. Chúng tôi so sánh QAMD EN(447M tham
số) với một tập các baseline transformer ngữ cảnh dài
mạnh, bao gồm LED (447M tham
số) (Beltagy và cộng sự, 2020), PRIMERA (447M tham
số) (Xiao và cộng sự, 2022),4và LongT5-xl (3B
tham số)5(Guo và cộng sự, 2022) (xem §2).6
Kết quả. Kết quả trên QA đa tài liệu được
hiển thị trong Bảng 2. Chúng tôi áp dụng các metric đánh giá F1 và Exact
Match (EM) tương ứng với các công việc gốc. QAMD ENcủa chúng tôi vượt trội
cả PRIMERA , LED, và LongT5, xác nhận rằng
dữ liệu tiền huấn luyện và định dạng đầu vào của chúng tôi có lợi
cho cả việc nắm bắt các mối quan hệ liên tài liệu
( QAMD EN≻LED) cũng như khai thác cả
ngữ cảnh và câu hỏi (QAMD EN≻PRIMERA ).
4.2 Tóm tắt Đa tài liệu (MDS)
Tác vụ này nhằm mục đích tạo ra một bản tóm tắt cho một
tập các tài liệu có liên quan chủ đề. Vốn dĩ, MDS
đầu cuối đến đầu cuối cần ngầm định giải quyết một số
tác vụ con bao gồm phát hiện nổi bật, loại bỏ dư thừa,
và tạo văn bản. Vì phải đối phó với
nhiều tài liệu, MDS đòi hỏi xử lý thông tin
không đồng nhất và phân tán, trong khi
thể hiện sự dư thừa văn bản đáng kể. Chúng tôi huấn luyện
và kiểm tra QAMD ENvới hai benchmark MDS
thách thức, mỗi cái đối phó với một miền
khác nhau: Multi-News (Fabbri và cộng sự, 2019), quan tâm
đến việc tóm tắt các bài báo tin tức liên quan,
và Multi-XScience (Lu và cộng sự, 2020), để tóm tắt
bài báo khoa học (xem thêm chi tiết về
các bộ dữ liệu trong Phụ lục C.2). Dưới thiết lập này, chúng tôi được
cung cấp các tập tài liệu (không có bất kỳ truy vấn nào),
và do đó chúng tôi đơn giản mã hóa các tài liệu sử
dụng QAMD ENmà không nối thêm văn bản.
Baseline. Như trong thí nghiệm trước, chúng tôi
so sánh QAMD ENvới LED, PRIMERA ,
LongT5-xl. Theo Xiao và cộng sự (2022) chúng tôi báo cáo
kết quả của các mô hình tối tân từ Pa-
sunuru và cộng sự (2021b) và Lu và cộng sự (2020), cho Multi-
News và Multi-XScience, tương ứng.
Kết quả. Bảng 3 và 4 trình bày kết quả đánh giá
trên các bộ dữ liệu Multi-News và Multi-XScience,
tương ứng. Theo các công việc MDS trước đây,
chúng tôi báo cáo điểm ROUGE R-1, -2, và -L,
là các metric đánh giá MDS tiêu chuẩn
(xem Phụ lục C.2 để biết chi tiết). Để so sánh công bằng,
chúng tôi bao gồm kết quả của PRIMERA cũng như
kết quả của các phương pháp tối tân trước đây
(Pasunuru và cộng sự (2021b) và Lu và cộng sự (2020),
cho Multi-News và cho Multi-XScience, tương
ứng), và LED (Beltagy và cộng sự, 2020). Như được hiển thị
trong các bảng kết quả, QAMD ENthể hiện hiệu suất tốt nhất
trên hầu hết các mô hình và benchmark được kiểm tra,
đặc biệt trên bộ dữ liệu Multi-News,
rõ ràng chứng minh lợi thế nhất quán của nó

--- TRANG 7 ---
Mô hình R-1 R-2 R-L
Pasunuru và cộng sự (2021b) 49.2 19.6 24.5
LED (Beltagy và cộng sự, 2020) 47.4 20.7 23.7
LongT5-xl (Guo và cộng sự, 2022) 47.4 20.7 23.7
PRIMERA (Xiao và cộng sự, 2022) 49.9 21.1 25.9
QAMD EN 50.9 23.1 27.2
Bảng 3: Kết quả ROUGE (-1,-2,-L) cho tập test của
bộ dữ liệu Multi-News.
Mô hình R-1 R-2 R-L
Lu và cộng sự (2020) 33.9 6.8 18.2
LED (Beltagy và cộng sự, 2020) 31.0 6.9 17.4
LongT5-xl (Guo và cộng sự, 2022) 33.7 8.1 19.4
PRIMERA (Xiao và cộng sự, 2022) 31.9 7.4 18.0
QAMD EN 33.5 7.6 19.1
Bảng 4: Kết quả ROUGE (-1,-2,-L) cho tập test của
bộ dữ liệu Multi-XScience.
tage. Điều này loại trừ kết quả cho Multi-XScience
trong đó QAMD ENhơi kém hiệu suất so với công việc trước
và LongT5. Một lời giải thích mà Xiao
và cộng sự (2022) chỉ ra là thực tế rằng các cụm
trong Multi-XScience có ít thông tin chồng chéo
so với corpus chúng tôi đã sử dụng, được quy cho
việc sử dụng tóm tắt làm tài liệu đầu vào trong
Multi-XScience. Ngoài ra, lợi thế của LongT5 so với
QAMD ENđược quy cho số lượng tham số
lớn hơn đáng kể của LongT5-xl.
4.3 Tóm tắt Trừu tượng Đa tài liệu
Tập trung Truy vấn
Tác vụ Tóm tắt Đa tài liệu Tập trung Truy vấn
(QMDS) nhằm mục đích tạo ra một bản tóm tắt từ một tập
tài liệu, trả lời một truy vấn cụ thể
đã cho. Không giống như MDS, QMDS cố gắng giải quyết
các kịch bản dựa trên truy vấn thực tế hơn, vì nó đề xuất
tóm tắt chỉ thông tin nổi bật được xác định trước
quan tâm mà trả lời tốt nhất cho truy vấn. Vì
chúng tôi đã đề xuất tiền huấn luyện dưới thiết lập trả lời câu hỏi
đa tài liệu, chúng tôi cho rằng QAMD EN
có thể hiệu quả cho QMDS.
Chúng tôi xem xét các bộ dữ liệu được xây dựng bởi Pa-
sunuru và cộng sự (2021a), QMDS CNNvàQMDS IR
(xem thêm chi tiết về các bộ dữ liệu trong Phụ lục C.3) cũng như
baseline mạnh của họ, và cũng bao gồm
kết quả của P RIMERA và LED.
Baseline. Tương tự như các thí nghiệm trước,
chúng tôi so sánh QAMD ENvới LED, PRIMERA ,
LongT5-xl. Ngoài ra, chúng tôi cũng xem xét
baseline từ Pasunuru và cộng sự (2021a).Mô hình R-1 R-2 R-L
Pasunuru và cộng sự (2021a)737.9 16.4 35.2
LED (Beltagy và cộng sự, 2020) 32.3 14.3 30.9
LongT5-xl (Guo và cộng sự, 2022) 35.5 15.9 34.3
PRIMERA (Xiao và cộng sự, 2022) 36.1 16.2 35.7
QAMD EN 38.8 18.3 37.2
Bảng 5: Kết quả ROUGE (-1,-2,-L) cho tập test của
bộ dữ liệu QMDS CNN.
Mô hình R-1 R-2 R-L
Pasunuru và cộng sự (2021a)745.5 23.4 41.2
LED (Beltagy và cộng sự, 2020) 43.2 21.3 40.5
LongT5-xl (Guo và cộng sự, 2022) 44.4 22.3 40.0
PRIMERA (Xiao và cộng sự, 2022) 45.7 23.6 40.9
QAMD EN 47.6 25.1 42.4
Bảng 6: Kết quả ROUGE (-1,-2,-L) cho tập test của
bộ dữ liệu QMDS IR.
Kết quả. Bảng 5 và 6 trình bày kết quả đánh giá
trên các bộ dữ liệu QMDS CNNvàQMDS IR,
tương ứng. Theo các tác vụ MDS và Pasunuru
và cộng sự (2021a), chúng tôi báo cáo điểm ROUGE R-1, -2, và
-L, là các metric đánh giá MDS tiêu chuẩn
(xem Phụ lục C.3 để biết chi tiết). Như được hiển thị trong
các bảng, QAMD ENthể hiện hiệu suất tốt nhất
trên hầu hết các mô hình và benchmark được kiểm tra,
rõ ràng chứng minh lợi thế nhất quán của nó
so với các baseline.
4.4 Nghiên cứu Khử
Tạo Dữ liệu. Tiếp theo chúng tôi chuyển sang một nghiên cứu
khử rộng, để đánh giá cấu hình và
lựa chọn thiết kế của chúng tôi qua pipeline được đề xuất. Đầu tiên,
chúng tôi cho thấy lợi thế của việc kết hợp ba
chế độ dữ liệu được đề xuất, thay vì sử dụng một tập con
của chúng. Chúng tôi đánh giá tất cả các mô hình kết quả bằng cách
tinh chỉnh chúng trên HopotQA-distractor (§4.1),
Multi-XScience (§4.2), và QMDS IR(§4.3). Đối với
HopotQA-distractor chúng tôi báo cáo điểm Exact Match
(EM), và cho các tác vụ tóm tắt chúng tôi
báo cáo điểm R OUGE -1 (R-1).
Baseline. Chúng tôi tiền huấn luyện QAMD ENtừ 100k
bước, để sử dụng mọi tập con của tập
(siêu tập) các chế độ {(a),(b),(c)}(tất cả các kết hợp có thể
của nó) của các chế độ dữ liệu tiền huấn luyện được tạo ra
được trình bày trong §3. Lưu ý rằng mô hình QAMD EN
của chúng tôi được gọi là sử dụng tất cả các chế độ, tức là,
(a) + (b) + (c).
7Chúng tôi báo cáo kết quả của mô hình khử tốt nhất từ Pa-
sunuru và cộng sự (2021a).

--- TRANG 8 ---
Hình 4: Kết quả khử trên các tập validation của
HotpotQA-distractor (QA) Multi-XScience (MDS), và
QMDS IR(QMDS). Chúng tôi báo cáo phần trăm
hiệu suất tương đối so với mô hình đạt điểm cao nhất.
Đối với QA chúng tôi sử dụng điểm EM, và cho MDS và QMDS
chúng tôi sử dụng điểm R OUGE -1.
Kết quả. Hình 4 cho thấy kết quả khử. Trong
tất cả các tác vụ, tiền huấn luyện sử dụng tất cả các chế độ mang lại
kết quả tốt nhất. Trong tất cả các chế độ, chế độ (c) có vẻ
hiệu quả nhất cho QA, vì đây là một
tác vụ QA trích xuất, và chế độ (c) cung cấp dữ liệu trong
định dạng này. Chế độ (a) xuất sắc trong các tác vụ tóm tắt,
được quy cho bản chất trừu tượng của chúng cũng như
yêu cầu của tất cả các tài liệu để tạo ra
các bản tóm tắt phù hợp.
Định dạng Đầu vào Chúng tôi lặp lại thí nghiệm trước
và khử định dạng đầu vào tiền huấn luyện theo
các định dạng khác nhau, và so sánh
với định dạng tiền huấn luyện mô hình được mô tả
trong §3 (với cùng dữ liệu tiền huấn luyện): without
questions ,with random question ,with random con-
text document ,with prefixes ,placing the question
before the context ,with question filtering , và with-
out generating the salient sentence . Ngoài ra,
chúng tôi đánh giá lựa chọn QAS EMlàm mô-đun tạo câu hỏi-
trả lời của chúng tôi bằng cách sử dụng các bộ tạo
từ Jia và cộng sự (2022) và Khashabi và cộng sự (2022).
Cuối cùng, chúng tôi cũng bao gồm kết quả của PRIMERA ,
được tiền huấn luyện thêm cho 300k bước bổ sung (tinh chỉnh LED trong tổng 400k bước), để
so sánh công bằng với các mô hình khử QAMD EN. Xem
chi tiết đầy đủ về tất cả các khử trong Phụ lục D.
Kết quả. Nhìn chung, mô hình QAMD ENcủa chúng tôi vượt trội
so với các mô hình khử trên hầu hết các tác vụ,
với một biên độ đáng kể.
Tiền huấn luyện mô hình mà không có bất kỳ câu hỏi nào
trong quá trình hoặc sử dụng câu hỏi ngẫu nhiên, ảnh hưởng tiêu cực
đến kết quả của các tác vụ hạ nguồn. Một chức năng quan trọng QA MDS QMDS
without questions 60.3 32.8 44.7
with random questions 61.1 32.1 44.2
with random context documents 61.0 31.5 43.9
with prefixes 67.3 32.6 46.2
placing the question before the context 66.7 33.4 46.3
with question filtering 65.2 30.9 41.1
without generating the salient sentence 66.6 30.5 42.8
Using Jia và cộng sự (2022) as the QA generator 66.6 33.2 45.9
Using Khashabi và cộng sự (2022) as the QA generator 66.8 33.3 45.1
PRIMERA (Xiao và cộng sự, 2022) 400k steps checkpoint 65.9 32.1 45.7
QAMD EN 67.1 33.5 47.6
Bảng 7: Kết quả nghiên cứu khử.
của câu hỏi là tạo điều kiện thuận lợi cho khả năng
của mô hình tạo ra câu trả lời phù hợp
và câu nguồn. Điều này phù hợp với những
phát hiện từ Caciularu và cộng sự (2021), người đã cho thấy rằng
tiền huấn luyện với các tài liệu ngẫu nhiên thay vì
các tài liệu liên quan là không tối ưu.
Việc sử dụng tiền tố câu hỏi và ngữ cảnh để định
vị đầu vào có vẻ hữu ích cho QA, nhưng
kém hơn khi áp dụng cho các tác vụ tóm tắt
do định dạng độc đáo của nó, rất phù hợp cho
QA nhưng có vẻ khó tổng quát hóa hơn cho các thiết lập khác.
Khi câu hỏi được đặt trước ngữ cảnh, hiệu suất
giảm nhẹ trên các tác vụ dựa trên truy vấn,
trong khi duy trì cùng kết quả cho tóm tắt
(trong đó vị trí câu hỏi không liên quan).
Việc sử dụng lọc câu hỏi được tìm thấy có hại cho
kết quả hạ nguồn của QAMD EN, phù hợp với
các công việc tiền huấn luyện dựa trên QA trước đây khác (Jia và cộng sự,
2022).
Tiền huấn luyện mà không tạo ra câu nguồn
được quy cho giới thiệu một luồng đáng kể cho
mô hình, đặc biệt cho các tác vụ tóm tắt
hạ nguồn. Như đã đề cập trước đây, tạo ra
các chuỗi dài hơn, cũng như dạy mô hình
sao chép văn bản, có lợi cho các tác vụ tóm tắt.
Áp dụng một bộ tạo câu hỏi khác thay vì
QAS EMmang lại kết quả kém hơn nhìn chung, vì
các bộ tạo khác tạo ra các câu hỏi và câu trả lời mở
dễ bị lỗi hơn, trong khi QAS EMsử dụng một khoảng
hiện tại trong ngữ cảnh làm câu trả lời. Ngoài ra, QAS EMtạo ra các câu hỏi
cục bộ, cho phép QAMD ENtập trung vào
các chi tiết tỉ mỉ, và không chỉ thông tin
thô trong ngữ cảnh đa tài liệu.
Khi PRIMERA được tiền huấn luyện với 400k bước
(để phù hợp với số bước tiền huấn luyện thêm của QAMD EN),
nó kém hiệu suất so với QAMD ENvà
thậm chí không thêm được bất kỳ cải thiện đáng kể nào so với
checkpoint 100K của nó, có thể do lượng
dữ liệu tiền huấn luyện nhỏ mà nó chứa.

--- TRANG 9 ---
Mô hình R-1 R-2 R-L
PRIMERA 45.0 16.7 22.6
GPT-3.5 36.4 10.8 18.7
GPT-4 34.7 10.7 18.8
GPT-4 8k 34.9 10.9 18.9
QAMD EN 45.3 17.4 23.7
Bảng 8: Kết quả R OUGE (-1,-2,-L) trên một tập con của Multi-
News. Các mô hình GPT được truy cập thông qua API công cộng OpenAI
và được áp dụng trong chế độ zero-shot.
Mô hình Cont. Read. Gram. Non-red.
PRIMERA ↑53.3% ↑63.3% ↑56.7% ↑53.3%
GPT-3.5 ↑70.0% ↓33.3% ↓30.0% ↑70.0%
GPT-4 8k ↑73.3% ↓40.0% ↓36.6% ↑83.3%
Bảng 9: So sánh 30 bản tóm tắt đầu tiên của mẫu
Multi-News giữa QAMD ENvà các
baseline. Dưới mỗi tiêu chí đánh giá, các
ô trong một hàng chỉ ra phần trăm trường hợp mà hệ thống của chúng tôi
được ưa thích hơn so với baseline GPT.
4.5 So sánh với Mô hình Ngôn ngữ Lớn
Để có cái nhìn sâu sắc về cách QAMD EN
so sánh với các Mô hình Ngôn ngữ Lớn
Tổng quát tối tân (LLM), chúng tôi cung cấp một so sánh nhỏ
với hai mô hình có khả năng, GPT-3.5
turbo (Ouyang và cộng sự, 2022) và GPT-48(OpenAI,
2023) (bao gồm phiên bản độ dài đầu vào 8k) được đánh giá
trong thiết lập zero-shot.
Để so sánh công bằng, chúng tôi sử dụng cùng kích thước cửa sổ ngữ cảnh
4K token cho tất cả các mô hình (và lên
đến 8k cho GPT-4 8k). Do thực tế rằng các tác vụ đa tài liệu
liên quan đến xử lý các chuỗi dài,
chi phí gọi API là đáng kể cho một đánh giá toàn diện
trên tất cả các bộ dữ liệu. Do đó, chúng tôi
chỉ đánh giá trên một mẫu 200 thể hiện từ
bộ dữ liệu multi-news (xem chi tiết prompting trong Phụ
lục E). Bảng 8 mô tả kết quả. Chúng tôi quan sát thấy rằng
QAMD ENvượt trội đáng kể so với cả mô hình GPT-
3.5 và GPT-4, mặc dù hiệu suất
của GPT-4 và GPT-3.5 là tương đương. Chúng tôi để lại
các so sánh toàn diện hơn với LLM cho
công việc tương lai.
Chúng tôi tiếp tục đánh giá QAMD ENthông qua
so sánh thủ công với PRIMERA , GPT-3.5, và
GPT-4 8k. Các sinh viên tốt nghiệp NLP được hiển thị
các bản tóm tắt cho một chủ đề nhất định từ ba hệ thống
vàQAMD ENtheo thứ tự tùy ý, cùng với một
bản tóm tắt tham chiếu tương ứng. Theo (Ernst
và cộng sự, 2022), những người tham gia được yêu cầu xếp hạng các
hệ thống dựa trên Nội dung (chồng chéo với tham
chiếu), Khả năng đọc (khả năng đọc của bản tóm tắt),
Ngữ pháp (tránh lỗi ngữ pháp), và
Không dư thừa (tránh lặp lại), và chúng tôi
trích xuất kết quả theo cặp từ các xếp hạng (xem
(Ernst và cộng sự, 2022) để biết thêm chi tiết). Trong Phụ lục F,
chúng tôi cung cấp một số ví dụ về bản tóm tắt hệ thống
và các bản tóm tắt tham chiếu tương ứng của chúng.
Kết quả của nghiên cứu này được trình bày trong Bảng 9.
Dưới mỗi tiêu chí đánh giá, nó chỉ ra phần trăm
trường hợp mà QAMD ENđược ưa thích
hơn so với cả hai baseline. QAMD ENđược ưa chuộng trong tất cả
các trường hợp ngoại trừ lỗi ngữ pháp và khả năng đọc
(tương ứng với giai đoạn Học tăng cường
từ Phản hồi Con người của các mô hình GPT).
5 Kết luận
Trong công việc này, chúng tôi trình bày một sơ đồ tiền huấn luyện
mới lạ cho các tác vụ đa tài liệu. Đầu tiên, cách tiếp cận
của chúng tôi đề xuất tăng cường các mục tiêu tiền huấn luyện
đa tài liệu hiện tại thành một tác vụ trả lời câu hỏi
liên tài liệu. Thứ hai, chúng tôi
tạo ra dữ liệu tiền huấn luyện QA chất lượng cao quy mô lớn
sử dụng cách tiếp cận tạo được kiểm soát, trong
đó mỗi cặp QA bắt nguồn từ một câu nổi bật
trong một trong các tài liệu trong tập.
Trong quá trình tiền huấn luyện, chúng tôi giao nhiệm vụ cho mô hình Longformer
Encoder-Decoder (LED) tạo ra câu trả lời
và câu nổi bật dựa trên
ngữ cảnh còn lại. Mục tiêu này khuyến khích
mô hình LED gợi lên các mối quan hệ liên tài liệu,
và khâu nối các mảnh thông tin qua các
tài liệu đầu vào, có liên quan để thực hiện
các tác vụ đa tài liệu. Mô hình kết quả
QAMD ENcho thấy những cải thiện hiệu suất đáng kể
so với các mô hình trước đây dưới thí nghiệm rộng rãi
trên nhiều bộ dữ liệu tóm tắt và QA đa tài liệu
thách thức.
Công việc tương lai có thể mở rộng các ý tưởng trong công việc này
để trang bị cho các LM lớn chỉ giải mã với mô hình hóa liên tài liệu
sử dụng phương pháp đề xuất của chúng tôi,
cũng trong thiết lập học trong ngữ cảnh và
điều chỉnh prompt. Chúng tôi dự đoán rằng phương pháp của chúng tôi nên có
ý nghĩa cụ thể cho các thiết lập mô hình hóa ngôn ngữ
tăng cường truy xuất (Izacard và cộng sự, 2022), trong đó
có việc sử dụng các tài liệu liên quan như một nguồn tri thức
phi tham số bên ngoài được gia công. Cuối cùng,
việc sử dụng một tài liệu đơn lẻ để kích hoạt
các mối quan hệ liên tài liệu, như được giới thiệu lần đầu
trong công việc này, có thể được điều tra thêm.

--- TRANG 10 ---
Lời cảm ơn
Công việc được mô tả ở đây được hỗ trợ bởi
học bổng PBC cho các ứng viên tiến sĩ xuất sắc
trong khoa học dữ liệu, một phần bởi các khoản tài trợ từ
Quỹ Khoa học Israel grant 2827/21, và bởi một khoản tài trợ
từ Bộ Khoa học và Công nghệ Israel.
Hạn chế
Mặc dù công việc của chúng tôi cố gắng tập trung xung quanh lý luận
về cả các mối quan hệ liên tài liệu tỉ mỉ và thô,
QAMD EN, mô hình tiền huấn luyện kết quả, vẫn có thể
gặp phải lỗi nhất quán thực tế trong khi tạo ra thông tin
cho một truy vấn, và không có gì đảm bảo rằng nó sẽ luôn
tạo ra nội dung thực tế và hợp lý mà không có
bất kỳ tinh chỉnh thêm nào.
Mô hình tạo câu hỏi QAS EMmà chúng tôi
đã sử dụng cũng có thể là nguồn gốc của những vấn đề này.
Có khả năng QAS EMtạo ra các câu hỏi
không phù hợp có thể làm hại quá trình tiền huấn luyện
của mô hình. Đã có nỗ lực lọc
ra tiếng ồn sử dụng mô hình câu hỏi, nhưng kết quả
kém hơn so với không lọc. Do đó, nếu
mô hình không được tinh chỉnh, sự không nhất quán (ảo
giác) có thể xảy ra thường xuyên hơn.
Ngoài ra, bằng cách sử dụng corpus Newshead làm
nguồn dữ liệu tiền huấn luyện, chúng tôi giả định rằng nó
bao gồm các tài liệu chất lượng cao. Chúng tôi cũng
tính đến thực tế rằng Newshead bị giới hạn
ở các tài liệu trong miền tin tức, trong khi một số
benchmark được sử dụng để đánh giá QAMD ENbao gồm
các chủ đề quan tâm khác. Công việc tương lai có thể
tiếp tục đánh giá chất lượng của các tài liệu, như
kiểm tra trùng lặp hoặc tuyên bố sai,
và đa dạng hóa các miền corpus. Điều này rất quan trọng
để sản phẩm hóa các mô hình như QAMD ENtrong các ứng dụng
đa văn bản tương tác (chatbot) và ứng dụng tìm kiếm
ngữ nghĩa đang thu hút sự chú ý
ngày nay (Hirsch và cộng sự, 2021; Eirew và cộng sự, 2022).
Cuối cùng, mô hình kết quả QAMD ENđã được
tiền huấn luyện trên các tập tài liệu liên quan, bằng cách trả lời
các câu hỏi phù hợp với nội dung của chúng. Như trong
kịch bản ngoài miền, việc sử dụng QAMD ENtrên các tập
tài liệu không liên quan, hoặc trên các
tài liệu đơn lẻ, có thể không mong đợi. Những thiết lập như vậy
có thể là chủ đề của một hướng nghiên cứu khác trong
tương lai.Tuyên bố Đạo đức
Mặc dù rủi ro hạn chế liên quan đến công việc của chúng tôi,
tương tự như các mô hình ngôn ngữ tạo
tối tân hiện tại, không có gì đảm bảo rằng QAM-
DEN, mô hình của chúng tôi, sẽ luôn tạo ra thông tin
thực tế. Do đó mô hình nên được sử dụng
thận trọng trong môi trường thực tế và được
kiểm tra cẩn thận trước khi triển khai. Có thể,
ví dụ, các sự kiện giai thoại thường xuyên trong
bộ dữ liệu tiền huấn luyện được tạo ra theo cách
không mong đợi.
Tài liệu tham khảo
Joshua Ainslie, Santiago Ontanon, Chris Alberti, Va-
clav Cvicek, Zachary Fisher, Philip Pham, Anirudh
Ravula, Sumit Sanghai, Qifan Wang, và Li Yang.
2020. ETC: Encoding long and structured inputs in
transformers. Trong Proceedings of the 2020 Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP) , trang 268–284, Online. Association
for Computational Linguistics.
Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin,
và Michael Collins. 2019. Synthetic QA corpora
generation with roundtrip consistency. Trong Proceed-
ings of the 57th Annual Meeting of the Association for
Computational Linguistics , trang 6168–6173, Flo-
rence, Italy. Association for Computational Linguis-
tics.
Iz Beltagy, Matthew E Peters, và Arman Cohan. 2020.
Longformer: The long-document transformer. arXiv
preprint arXiv:2004.05150 .
Bernd Bohnet, Vinh Q. Tran, Pat Verga, Roee Aharoni,
Daniel Andor, Livio Baldini Soares, Jacob Eisen-
stein, Kuzman Ganchev, Jonathan Herzig, Kai Hui,
Tom Kwiatkowski, Ji Ma, Jianmo Ni, Tal Schuster,
William W. Cohen, Michael Collins, Dipanjan Das,
Donald Metzler, Slav Petrov, và Kellie Webster.
2022. Attributed question answering: Evaluation
and modeling for attributed large language models.
arXiv preprint arXiv:2212.08037 , 4.
Avi Caciularu, Arman Cohan, Iz Beltagy, Matthew Pe-
ters, Arie Cattan, và Ido Dagan. 2021. CDLM:
Cross-document language modeling. Trong Findings
of the Association for Computational Linguistics:
EMNLP 2021 , trang 2648–2662, Punta Cana, Do-
minican Republic. Association for Computational
Linguistics.
Avi Caciularu, Ido Dagan, Jacob Goldberger, và Ar-
man Cohan. 2022. Long context question answering
via supervised contrastive learning. Trong Proceedings
of the 2022 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies , trang 2872–2879,
Seattle, United States. Association for Computational
Linguistics.

--- TRANG 11 ---
Alon Eirew, Avi Caciularu, và Ido Dagan. 2022. Cross-
document event coreference search: Task, dataset and
modeling. Trong Proceedings of the 2022 Conference on
Empirical Methods in Natural Language Processing ,
trang 900–913, Abu Dhabi, United Arab Emirates.
Association for Computational Linguistics.
Ori Ernst, Avi Caciularu, Ori Shapira, Ramakanth Pa-
sunuru, Mohit Bansal, Jacob Goldberger, và Ido
Dagan. 2022. Proposition-level clustering for multi-
document summarization. Trong Proceedings of the
2022 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies , trang 1765–1779, Seat-
tle, United States. Association for Computational
Linguistics.
Alexander Fabbri, Irene Li, Tianwei She, Suyi Li, và
Dragomir Radev. 2019. Multi-news: A large-scale
multi-document summarization dataset and abstrac-
tive hierarchical model. Trong Proceedings of the 57th
Annual Meeting of the Association for Computational
Linguistics , trang 1074–1084, Florence, Italy. Asso-
ciation for Computational Linguistics.
Yuwei Fang, Shuohang Wang, Zhe Gan, Siqi Sun,
Jingjing Liu, và Chenguang Zhu. 2020. Accelerat-
ing real-time question answering via question gener-
ation. arXiv preprint arXiv:2009.05167 .
Adam Fisch, Alon Talmor, Robin Jia, Minjoon Seo,
Eunsol Choi, và Danqi Chen. 2019. MRQA 2019
shared task: Evaluating generalization in reading
comprehension. Trong Proceedings of the 2nd Workshop
on Machine Reading for Question Answering , trang
1–13, Hong Kong, China. Association for Computa-
tional Linguistics.
Nicholas FitzGerald, Julian Michael, Luheng He, và
Luke Zettlemoyer. 2018. Large-scale QA-SRL pars-
ing. Trong Proceedings of the 56th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , trang 2051–2060, Melbourne,
Australia. Association for Computational Linguistics.
Mor Geva, Uri Katz, Aviv Ben-Arie, và Jonathan Be-
rant. 2021. What's in your head? Emergent be-
haviour in multi-task transformer models. Trong Pro-
ceedings of the 2021 Conference on Empirical Meth-
ods in Natural Language Processing , trang 8201–
8215, Online và Punta Cana, Dominican Republic.
Association for Computational Linguistics.
Dvir Ginzburg, Itzik Malkiel, Oren Barkan, Avi Caciu-
laru, và Noam Koenigstein. 2021. Self-supervised
document similarity ranking via contextualized lan-
guage models and hierarchical inference. Trong Find-
ings of the Association for Computational Linguis-
tics: ACL-IJCNLP 2021 , trang 3088–3098, Online.
Association for Computational Linguistics.
Xiaotao Gu, Yuning Mao, Jiawei Han, Jialu Liu, You
Wu, Cong Yu, Daniel Finnie, Hongkun Yu, Jiaqi Zhai,
và Nicholas Zukoski. 2020. Generating represen-
tative headlines for news stories. Trong Proceedings of
The World Wide Web Conference (WWW) .Mandy Guo, Joshua Ainslie, David Uthus, Santiago On-
tanon, Jianmo Ni, Yun-Hsuan Sung, và Yinfei Yang.
2022. LongT5: Efficient text-to-text transformer for
long sequences. Trong Findings of the Association for
Computational Linguistics: NAACL 2022 , trang 724–
736, Seattle, United States. Association for Compu-
tational Linguistics.
Hangfeng He, Qiang Ning, và Dan Roth. 2020.
QuASE: Question-answer driven sentence encoding.
TrongProceedings of the 58th Annual Meeting of the As-
sociation for Computational Linguistics , trang 8743–
8758, Online. Association for Computational Lin-
guistics.
Luheng He, Mike Lewis, và Luke Zettlemoyer. 2015.
Question-answer driven semantic role labeling: Us-
ing natural language to annotate natural language.
TrongProceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing , trang
643–653, Lisbon, Portugal. Association for Compu-
tational Linguistics.
Karl Moritz Hermann, Tomas Kocisky, Edward Grefen-
stette, Lasse Espeholt, Will Kay, Mustafa Suleyman,
và Phil Blunsom. 2015. Teaching machines to read
and comprehend. Trong Advances in Neural Information
Processing Systems (NIPS) .
Eran Hirsch, Alon Eirew, Ori Shapira, Avi Caciu-
laru, Arie Cattan, Ori Ernst, Ramakanth Pasunuru,
Hadar Ronen, Mohit Bansal, và Ido Dagan. 2021.
iFacetSum: Coreference-based interactive faceted
summarization for multi-document exploration. Trong
Proceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing: System
Demonstrations , trang 283–297, Online và Punta
Cana, Dominican Republic. Association for Compu-
tational Linguistics.
Jordan Hoffmann, Sebastian Borgeaud, Arthur Men-
sch, Elena Buchatskaya, Trevor Cai, Eliza Ruther-
ford, Diego de Las Casas, Lisa Anne Hendricks,
Johannes Welbl, Aidan Clark, và những người khác. 2022. Train-
ing compute-optimal large language models. arXiv
preprint arXiv:2203.15556 .
Patrick Huber, Armen Aghajanyan, Barlas Oguz,
Dmytro Okhonko, Scott Yih, Sonal Gupta, và Xilun
Chen. 2022. CCQA: A new web-scale question
answering dataset for model pre-training. Trong Find-
ings of the Association for Computational Linguis-
tics: NAACL 2022 , trang 2402–2420, Seattle, United
States. Association for Computational Linguistics.
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lu-
cas Hosseini, Fabio Petroni, Timo Schick, Jane
Dwivedi-Yu, Armand Joulin, Sebastian Riedel, và
Edouard Grave. 2022. Few-shot learning with re-
trieval augmented language models. arXiv preprint
arXiv:2208.03299 .
Alon Jacovi, Avi Caciularu, Omer Goldman, và Yoav
Goldberg. 2023. Stop uploading test data in plain

--- TRANG 12 ---
text: Practical strategies for mitigating data contam-
ination by evaluation benchmarks. arXiv preprint
arXiv:2305.10160 .
Robin Jia, Mike Lewis, và Luke Zettlemoyer. 2022.
Question answering infused pre-training of general-
purpose contextualized representations. Trong Findings
of the Association for Computational Linguistics:
ACL 2022 , trang 711–728, Dublin, Ireland. Asso-
ciation for Computational Linguistics.
Daniel Khashabi, Yeganeh Kordi, và Hannaneh Ha-
jishirzi. 2022. Unifiedqa-v2: Stronger generalization
via broader cross-format training. arXiv preprint
arXiv:2202.12359 .
Daniel Khashabi, Sewon Min, Tushar Khot, Ashish
Sabharwal, Oyvind Tafjord, Peter Clark, và Han-
naneh Hajishirzi. 2020. UNIFIEDQA: Crossing for-
mat boundaries with a single QA system. Trong Find-
ings of the Association for Computational Linguistics:
EMNLP 2020 , trang 1896–1907, Online. Association
for Computational Linguistics.
Diederik P Kingma và Jimmy Ba. 2014. Adam: A
method for stochastic optimization. Trong International
Conference on Learning Representations (ICLR) .
Ayal Klein, Eran Hirsch, Ron Eliav, Valentina Pyatkin,
Avi Caciularu, và Ido Dagan. 2022. QASem pars-
ing: Text-to-text modeling of QA-based semantics.
TrongProceedings of the 2022 Conference on Empiri-
cal Methods in Natural Language Processing , trang
7742–7756, Abu Dhabi, United Arab Emirates. As-
sociation for Computational Linguistics.
Ayal Klein, Jonathan Mamou, Valentina Pyatkin,
Daniela Stepanov, Hangfeng He, Dan Roth, Luke
Zettlemoyer, và Ido Dagan. 2020. QANom:
Question-answer driven SRL for nominalizations. Trong
Proceedings of the 28th International Conference
on Computational Linguistics , trang 3069–3083,
Barcelona, Spain (Online). International Committee
on Computational Linguistics.
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Ghazvininejad, Abdelrahman Mohamed, Omer Levy,
Veselin Stoyanov, và Luke Zettlemoyer. 2020.
BART: Denoising sequence-to-sequence pre-training
for natural language generation, translation, and com-
prehension. Trong Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguistics ,
trang 7871–7880, Online. Association for Computa-
tional Linguistics.
C. Lin và M. Rey. 2004. Looking for a few good
metrics: ROUGE and its evaluation. Trong NTCIR Work-
shop .
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. Trong Text Summariza-
tion Branches Out , trang 74–81, Barcelona, Spain.
Association for Computational Linguistics.Yang Liu và Mirella Lapata. 2019. Hierarchical trans-
formers for multi-document summarization. Trong Pro-
ceedings of the 57th Annual Meeting of the Asso-
ciation for Computational Linguistics , trang 5070–
5081, Florence, Italy. Association for Computational
Linguistics.
Yao Lu, Yue Dong, và Laurent Charlin. 2020. Multi-
XScience: A large-scale dataset for extreme multi-
document summarization of scientific articles. Trong
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP) ,
trang 8068–8074, Online. Association for Computa-
tional Linguistics.
Congbo Ma, Wei Emma Zhang, Mingyu Guo, Hu Wang,
và Quan Z. Sheng. 2022. Multi-document sum-
marization via deep learning techniques: A survey.
ACM Comput. Surv. , 55(5).
OpenAI. 2023. Gpt-4 technical report. ArXiv ,
abs/2303.08774.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,
Carroll Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder,
Paul F Christiano, Jan Leike, và Ryan Lowe. 2022.
Training language models to follow instructions with
human feedback. Trong Advances in Neural Information
Processing Systems (NeurIPS) .
Ramakanth Pasunuru, Asli Celikyilmaz, Michel Galley,
Chenyan Xiong, Yizhe Zhang, Mohit Bansal, và
Jianfeng Gao. 2021a. Data augmentation for abstrac-
tive query-focused multi-document summarization.
TrongThe Association for the Advancement of Artificial
Intelligence (AAAI) .
Ramakanth Pasunuru, Mengwen Liu, Mohit Bansal, Su-
jith Ravi, và Markus Dreyer. 2021b. Efficiently
summarizing text and graph encodings of multi-
document clusters. Trong Proceedings of the 2021 Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies , trang 4768–4779, Online. As-
sociation for Computational Linguistics.
Valentina Pyatkin, Ayal Klein, Reut Tsarfaty, và Ido
Dagan. 2020. QADiscourse - Discourse Relations
as QA Pairs: Representation, Crowdsourcing and
Baselines. Trong Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing
(EMNLP) , trang 2804–2819, Online. Association for
Computational Linguistics.
Valentina Pyatkin, Paul Roit, Julian Michael, Yoav Gold-
berg, Reut Tsarfaty, và Ido Dagan. 2021. Asking
it all: Generating contextualized questions for any
semantic role. Trong Proceedings of the 2021 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing , trang 1429–1441, Online và Punta Cana,
Dominican Republic. Association for Computational
Linguistics.

--- TRANG 13 ---
Colin Raffel, Noam Shazeer, Adam Roberts, Kather-
ine Lee, Sharan Narang, Michael Matena, Yanqi
Zhou, Wei Li, và Peter J. Liu. 2020. Exploring the
limits of transfer learning with a unified text-to-text
transformer. Journal of Machine Learning Research ,
21(140):1–67.
Stephen E Robertson và Steve Walker. 1994. Some
simple effective approximations to the 2-poisson
model for probabilistic weighted retrieval. Trong SI-
GIR'94 , trang 232–241. Springer.
Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen,
Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang,
Sebastian Ruder, và Donald Metzler. 2021. Long
range arena : A benchmark for efficient transformers.
TrongInternational Conference on Learning Representa-
tions (ICLR) .
Yi Tay, Mostafa Dehghani, Dara Bahri, và Donald Met-
zler. 2022. Efficient transformers: A survey. ACM
Comput. Surv.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, và Illia Polosukhin. 2017. Attention is all
you need. Trong Advances in Neural Information Pro-
cessing Systems (NIPS) .
Danqing Wang, Pengfei Liu, Yining Zheng, Xipeng Qiu,
và Xuanjing Huang. 2020. Heterogeneous graph
neural networks for extractive document summariza-
tion. Trong Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics , trang
6209–6219, Online. Association for Computational
Linguistics.
Johannes Welbl, Pontus Stenetorp, và Sebastian Riedel.
2018. Constructing datasets for multi-hop reading
comprehension across documents. Transactions of
the Association for Computational Linguistics , 6:287–
302.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-
icz, Joe Davison, Sam Shleifer, Patrick von Platen,
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Teven Le Scao, Sylvain Gugger, Mariama Drame,
Quentin Lhoest, và Alexander Rush. 2020. Trans-
formers: State-of-the-art natural language processing.
TrongProceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: System
Demonstrations , trang 38–45, Online. Association
for Computational Linguistics.
Wen Xiao, Iz Beltagy, Giuseppe Carenini, và Arman
Cohan. 2022. PRIMERA: Pyramid-based masked
sentence pre-training for multi-document summariza-
tion. Trong Proceedings of the 60th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , trang 5245–5263, Dublin,
Ireland. Association for Computational Linguistics.Yumo Xu và Mirella Lapata. 2020. Coarse-to-fine
query focused multi-document summarization. Trong
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP) ,
trang 3632–3645, Online. Association for Computa-
tional Linguistics.
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,
William Cohen, Ruslan Salakhutdinov, và Christo-
pher D. Manning. 2018. HotpotQA: A dataset for
diverse, explainable multi-hop question answering.
TrongProceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing , trang
2369–2380, Brussels, Belgium. Association for Com-
putational Linguistics.
Michihiro Yasunaga, Jure Leskovec, và Percy Liang.
2022. LinkBERT: Pretraining language models with
document links. Trong Proceedings of the 60th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers) , trang 8003–8016,
Dublin, Ireland. Association for Computational Lin-
guistics.
Manzil Zaheer, Guru Guruganesh, Kumar Avinava
Dubey, Joshua Ainslie, Chris Alberti, Santiago On-
tanon, Philip Pham, Anirudh Ravula, Qifan Wang,
Li Yang, và những người khác. 2020. Big bird: Transformers for
longer sequences. Advances in Neural Information
Processing Systems (NeurIPS) .
Jingqing Zhang, Yao Zhao, Mohammad Saleh, và Peter
Liu. 2020. PEGASUS: Pre-training with extracted
gap-sentences for abstractive summarization. Trong Pro-
ceedings of the International Conference on Machine
Learning (ICML) .
Jinming Zhao, Ming Liu, Longxiang Gao, Yuan Jin,
Lan Du, He Zhao, He Zhang, và Gholamreza Haf-
fari. 2020. Summpip: Unsupervised multi-document
summarization with sentence graph compression. Trong
Proceedings of the International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval (SIGIR) .

--- TRANG 14 ---
A Tạo Dữ liệu
Như đã lưu ý trong §3, chúng tôi đã sử dụng corpus NewSHead (Gu
và cộng sự, 2020). Chúng tôi đã làm theo quy trình tiền xử lý dữ liệu
được đề xuất bởi Xiao và cộng sự (2022) đã cung cấp
mỗi câu trong corpus NewSHead
với điểm P EGASUS của chúng (Zhang và cộng sự, 2020).9
A.1 Chi tiết QAS EM
QAS EM(Klein và cộng sự, 2022) là một công cụ thống nhất để
phân tích các câu thành một tập QA có hệ thống
đại diện cho mỗi câu. Ba loại
vị từ sau được bao gồm trong tập này: động từ, danh
hóa động từ, và các mối quan hệ diễn ngôn thông tin,
và chúng đại diện cho các đơn vị thông tin cốt lõi
trong một câu.
Để tạo ra dữ liệu tiền huấn luyện cho mô hình
QAMD ENcủa chúng tôi, chúng tôi đặc biệt nhắm mục tiêu các vị từ
động từ để tạo câu hỏi-trả lời,
vì các ví dụ huấn luyện tương ứng của chúng bắt
nguồn từ bộ dữ liệu Gán nhãn Vai trò Ngữ nghĩa
Hướng dẫn Câu hỏi Trả lời (QA-SRL) (He và cộng sự, 2015)
bao phủ phần lớn nhất của dữ liệu huấn luyện QAS EM
chung, và đạt được kết quả thực nghiệm tốt nhất
trong quá trình đánh giá, so với các loại khác
(danh hóa và mối quan hệ diễn ngôn). Sử dụng
chủ nghĩa QA-SRL, mỗi mối quan hệ vị từ-luận cứ
được gắn nhãn với một cặp câu hỏi-trả lời, và do đó
các câu hỏi ngôn ngữ tự nhiên đại diện cho các vai trò ngữ nghĩa,
trong khi các câu trả lời tương ứng với các luận cứ.
QAS EMtrước tiên thực hiện tiền xử lý ở cấp câu
cho QA-SRL bằng cách chạy một bộ gắn thẻ từ loại
để xác định động từ.10. Sau đó, bộ phân tích cú pháp
chính nó dựa trên mô hình T5-small được tinh chỉnh (Raf-
fel và cộng sự, 2020) được cung cấp một vị từ được đánh dấu
đơn lẻ trong ngữ cảnh tại một thời điểm, và được huấn luyện trên
nhiệm vụ tạo ra tập đầy đủ các cặp câu hỏi-trả lời
nhắm mục tiêu vị từ này.11Chuỗi đầu vào
bao gồm tiền tố nhiệm vụ duy nhất, câu, các
dấu hiệu đặc biệt cho vị từ đích, và dạng
động từ cơ bản của vị từ. Đầu ra là một tập
QA, và chúng tôi chọn một cặp theo
độ dài của câu trả lời (§3). Vì QAS EMtạo ra
các câu hỏi "trừu tượng" thay thế các luận cứ bằng
các placeholder, chúng tôi làm theo Pyatkin và cộng sự (2021) và
9Chúng tôi đã sử dụng dữ liệu có sẵn công khai từ
https://storage.googleapis.com/primer_
summ/processed_pretraining_data.tar.gz
10QAS EMsử dụng SpaCy 3.0 — https://spacy.io/
11Bộ phân tích cú pháp dựa trên T5 được huấn luyện trên mục tiêu đa nhiệm
văn bản-đến-văn bản, sử dụng QA-SRL (He và cộng sự, 2015; FitzGerald và cộng sự,
2018), QANOM (Klein và cộng sự, 2020), và trên QADiscourse (Py-
atkin và cộng sự, 2020)sử dụng mô hình của họ để chuyển đổi câu hỏi được tạo ra
thành dạng tự nhiên hơn, với các luận cứ
được ngữ cảnh hóa. Nhìn chung, chúng tôi quan sát thấy rằng cách tiếp cận này
thường cải thiện chất lượng của các câu hỏi, ngoài
tiện ích ngữ cảnh hóa. Hình 3
cho thấy một ví dụ từ bộ dữ liệu của chúng tôi (dựa trên một câu nổi bật
từ NewSHead (Gu và cộng sự, 2020))
theo mô tả được cung cấp ở trên.
B Chi tiết Kỹ thuật Tiền huấn luyện
Chúng tôi tiền huấn luyện QAMD ENtổng cộng 400K
bước (mất mát validation tiếp tục giảm trong suốt
quá trình tiền huấn luyện), batch size 16, tối ưu hóa Adam
(Kingma và Ba, 2014) với tỷ lệ học 3e−5và với 10k bước làm nóng và
suy giảm tuyến tính, tất cả đều theo các công việc trước đây (Beltagy và cộng sự,
2020; Xiao và cộng sự, 2022). Quá trình tiền huấn luyện
có thể mất tám ngày trên tám GPU RTX8000 48GB. Vì backbone của cả QAMD EN
vàPRIMERA đều là mô hình Longformer Encoder-Decoder
(LED) (Beltagy và cộng sự, 2020) phiên bản lớn,
chúng đều có cùng số lượng tham
số (447M). LED sử dụng mẫu chú ý cục bộ+toàn cục thưa thớt
trong tự chú ý encoder,
trong khi sử dụng chú ý đầy đủ trên decoder và chú ý chéo.
C Mô tả Benchmark
Trong phần này, chúng tôi cung cấp thêm chi tiết về
các bộ dữ liệu chúng tôi đã sử dụng để đánh giá mô hình và baseline.
C.1 Benchmark Trả lời Câu hỏi
Trước tiên chúng tôi mô tả chi tiết các tác vụ trả lời câu hỏi
đa tài liệu, và đặc biệt là tác vụ trả lời câu hỏi
đa bước. Trả lời câu hỏi đa bước bao gồm việc sử dụng một mô hình
để thu thập thông tin liên quan từ nhiều tài liệu và
kết hợp nó để cung cấp câu trả lời đúng.
HotPotQA (Yang và cộng sự, 2018). Bộ dữ liệu trả lời câu hỏi
này bao gồm các câu hỏi và 10 đoạn văn
từ các tài liệu Wikipedia khác nhau, với
hai đoạn văn chứa thông tin cần thiết
để trả lời câu hỏi một cách chính xác và
tám đoạn văn bổ sung làm nhiễu.
Nhiệm vụ bao gồm xác định khoảng câu trả lời đúng
và xác định các câu bằng chứng hỗ trợ.
(Để biết thêm chi tiết về bộ dữ liệu, xem Yang và cộng sự
(2018).)

--- TRANG 15 ---
WikiHop (Welbl và cộng sự, 2018). WikiHop là một
bộ dữ liệu bao gồm một câu hỏi, một số câu trả lời
tiềm năng (từ 2 đến 79 lựa chọn), và các
ngữ cảnh hỗ trợ (từ 3 đến 63 đoạn văn),
và câu trả lời đúng. Bộ dữ liệu này không cung
cấp bất kỳ thông tin nào về các bước trung gian
cần thiết để đến câu trả lời đúng, vì vậy các mô hình
do đó được giao nhiệm vụ suy luận các bước này dựa trên
câu hỏi và ngữ cảnh được cung cấp.
C.2 Benchmark Tóm tắt Đa tài liệu
Chúng tôi đã sử dụng https://github.com/
google-research/googleresearch/
tree/master/rouge để tính toán
điểm ROUGE (Lin và Rey, 2004) với các thiết lập stemmer
mặc định trong quá trình đánh giá.
Multi-News (Fabbri và cộng sự, 2019). Bộ dữ liệu này
là một tập hợp 56,216 cặp bài báo tin tức và
bản tóm tắt được viết bởi các biên tập viên chuyên nghiệp, tất cả được lấy
từ web ( newser.com ). Những cặp này bao gồm
các liên kết truy vết ngược đến các tài liệu gốc. Các tác giả
của bộ dữ liệu cũng đã so sánh nó với các bộ dữ liệu khác
về mặt phạm vi bao phủ, mật độ, và
nén, và phát hiện ra rằng nó đa dạng hợp lý
so với các benchmark tương tự khác.
Multi-X-Science (Lu và cộng sự, 2020). Bộ dữ liệu này
được lấy từ Arxiv và đồ thị học thuật Microsoft,
trong đó các bản tóm tắt là các đoạn văn của
các phần công việc liên quan, trong khi các tài liệu nguồn bao gồm
các tóm tắt của các bài báo truy vấn và được tham chiếu.
Nó được coi là có ít thiên lệch vị trí và trích xuất
hơn so với bộ dữ liệu Multi-News, biến đổi
nó thành một benchmark thách thức hơn (Ma
và cộng sự, 2022) vì nhược điểm của việc nhận điểm cao hơn
cho một câu được sao chép ở một vị trí cụ thể
có thể được giảm bớt.
C.3 Benchmark Tóm tắt Đa tài liệu
Tập trung Truy vấn
Trong phần này, chúng tôi mô tả cặp bộ dữ liệu từ
Pasunuru và cộng sự (2021a) đã được sử dụng trong các thí nghiệm của chúng tôi.
Tương tự như các thí nghiệm tóm tắt đa tài liệu
(Phụ lục C.2), chúng tôi đã sử dụng https:
//github.com/google-research/
googleresearch/tree/master/rouge
để tính toán điểm ROUGE (Lin và Rey,
2004) với các thiết lập stemmer mặc định trong
quá trình đánh giá.QmdsCnn. Bộ dữ liệu này dựa trên bộ dữ liệu tóm tắt
tài liệu đơn CNN/Daily Mail (CNN/DM)
(Hermann và cộng sự, 2015), trong đó các
tài liệu của nó là các bài báo tin tức có sẵn trực tuyến và
các bản tóm tắt là những điểm nổi bật được viết bởi con người. Bộ dữ liệu này được biến đổi thành đa tài liệu
bằng cách đầu tiên chia nhỏ các tài liệu thành các tài liệu nhỏ
của các đoạn văn. Sau đó, tiêu đề của các bài báo
làm truy vấn được đưa vào một công cụ tìm kiếm BM25
(Robertson và Walker, 1994), trả về các đoạn từ
toàn bộ bộ dữ liệu có liên quan đến
tiêu đề, và phục vụ như các tài liệu ngữ cảnh.
QmdsIr. Trong bộ dữ liệu này, các tác giả đề xuất
sử dụng một thay thế cho các truy vấn dựa trên tiêu đề
của bài báo – thay vào đó họ sử dụng các truy vấn
được đưa ra bởi người dùng công cụ tìm kiếm thực tế, điều này
thực tế hơn cho các trường hợp sử dụng tìm kiếm. Họ
thu thập các truy vấn và 10 kết quả hàng đầu của chúng được thu thập bởi
công cụ tìm kiếm Bing ( www.bing.com ). Bản tóm tắt
đích được rút ra từ đoạn trả lời,
được trích xuất từ một trong các tài liệu được xếp hạng cao
bởi hệ thống QA sản xuất của Bing. Tiếp theo,
họ bỏ qua tài liệu chứa đoạn trả lời
khỏi các tài liệu ngữ cảnh.
D Chi tiết Nghiên cứu Khử
Trong phần này, chúng tôi cung cấp chi tiết về các
baseline được sử dụng trong nghiên cứu khử định dạng đầu vào
mà chúng tôi đã thực hiện, và được trình bày trong §4.4.
Danh sách sau bao gồm các mô tả chi tiết
cho tất cả các khử chúng tôi đã sử dụng:
•Tiền huấn luyện mà không có câu hỏi . Theo Jia
và cộng sự (2022), chúng tôi bỏ qua câu hỏi được tạo ra,
và tiền huấn luyện mô hình để dự đoán câu trả lời
mà không có câu hỏi hiển thị trong ngữ cảnh.
•Tiền huấn luyện sử dụng câu hỏi ngẫu nhiên cho mỗi
tài liệu ngữ cảnh. Cho các tài liệu ngữ cảnh,
chúng tôi lấy mẫu một tài liệu tách biệt ngẫu nhiên từ
các cụm khác, và tạo ra một câu hỏi không liên quan
được sử dụng cho ngữ cảnh không liên quan. Đó
là một thay thế cho việc sử dụng một câu hỏi được tạo ra
bởi một trong các tài liệu trong ngữ cảnh.
•Tiền huấn luyện sử dụng ngữ cảnh với các
tài liệu ngữ cảnh ngẫu nhiên . Theo Caciularu
và cộng sự (2021), chúng tôi khử QAMD ENbằng cách tiền
huấn luyện với các tài liệu ngẫu nhiên trong
ngữ cảnh (các tài liệu không liên quan), trong đó có lẽ,
mô hình sẽ không có khả năng nắm bắt
các mối quan hệ liên tài liệu đúng cách,

--- TRANG 16 ---
và kém hiệu suất trên các tác vụ hạ nguồn đa tài liệu.
•Tiền huấn luyện với tiền tố . Chúng tôi thêm
các tiền tố question: vàcontext: trong
quá trình huấn luyện và suy luận. Những tiền tố này nên hướng dẫn thêm
cho mô hình với các vị trí của
câu hỏi và ngữ cảnh. Mặc dù thiết lập này hơi
giúp ích cho QA, chúng tôi cho thấy rằng đối với MDS, thiết lập
không có tiền tố là tốt hơn.
•Tiền huấn luyện trong khi đặt câu hỏi trước
ngữ cảnh . Nhớ lại rằng QAMD ENnối
các token câu hỏi vào cuối chuỗi đầu vào,
sau các tài liệu ngữ cảnh. Do đó,
chúng tôi thiết lập một baseline để khử thiết lập này,
và đặt câu hỏi ở đầu đầu vào.
•Tiền huấn luyện với lọc câu hỏi . Mô hình
tạo câu hỏi QAS EMcó thể có nhiễu,
dẫn đến một câu hỏi không thể
trả lời được hoặc với một câu trả lời không chính xác cho
một câu hỏi được tạo ra. Do đó chúng tôi
theo một chiến lược lọc QA tự động
gần đây đề xuất sử dụng một mô hình QA mạnh để
đảm bảo rằng các cặp câu hỏi-trả lời hợp lệ có
mặt trong bộ dữ liệu (Alberti và cộng sự, 2019;
Fang và cộng sự, 2020). tiền huấn luyện sau khi lọc câu hỏi-
trả lời, sử dụng mô hình UnifiedQA-
v2 mạnh (Khashabi và cộng sự, 2022) theo
UnifiedQA trước đây (Khashabi và cộng sự, 2020)
và huấn luyện trên nhiều bộ dữ liệu được giám sát hơn. Chúng tôi
lấy BART-large được tinh chỉnh (Lewis và cộng sự,
2020) làm bộ lọc câu hỏi để so sánh công bằng
với QAS EM. Chúng tôi áp dụng UnifiedQA-v2
trên các bộ ba câu hỏi-ngữ cảnh-trả lời và
chỉ lấy các câu hỏi có thể trả lời được theo
mô hình, để lại chúng tôi với khoảng 25%
của toàn bộ dữ liệu tiền huấn luyện.
•Tiền huấn luyện mà không tạo ra câu
nổi bật . Nhớ lại rằng chúng tôi giao nhiệm vụ cho QAMD ENtạo ra câu nổi bật được sử dụng
để tạo ra câu hỏi và câu trả lời. Điều này
nên cho phép mô hình tạo ra các chuỗi dài hơn
và cải thiện cơ chế đối phó, hữu ích cho các tác vụ
như tóm tắt. Giả thuyết này được đánh giá bằng cách thực hiện
cùng quy trình tiền huấn luyện nhưng không
tạo ra câu nổi bật – chỉ có câu trả lời
của câu hỏi được tạo ra.•Sử dụng các bộ tạo QA thay thế từ các
công việc liên quan gần đây. Chúng tôi tiền huấn luyện một mô hình dựa
trên các QA được tạo ra bởi hai bộ tạo QA,
dựa trên mô hình BART-large (Lewis
và cộng sự, 2020): Đầu tiên được lấy từ Jia và cộng sự
(2022)12, đã huấn luyện một mô hình trên dữ liệu
từ MRQA 2019 Shared Task (Fisch
và cộng sự, 2019) và thứ hai là bộ tạo QA
từ (Khashabi và cộng sự, 2022)
được huấn luyện trên tám benchmark QA khác nhau
(xem danh sách đầy đủ và tài liệu tham khảo trong Khashabi và cộng sự
(2022, Phụ lục A)).
•Tiền huấn luyện bổ sung cho PRIMERA (Xiao
và cộng sự, 2022) – Chúng tôi tiếp tục tiền huấn luyện
của checkpoint 100k được phát hành công khai
củaPRIMERA , và tiền huấn luyện thêm
300k bước (sử dụng cùng
định dạng và quy trình tiền huấn luyện được mô tả
trong Xiao và cộng sự (2022)), để đạt số lượng
bước được sử dụng để tiền huấn luyện QAMD ENvà các
khử của nó được mô tả ở trên.
E Chi tiết Prompting Mô hình Dựa trên API
Chúng tôi đã khám phá thủ công một số prompt cho các mô hình
dựa trên API chat GPT-3.5 và GPT-4, và
tiến hành với prompt có vẻ hiệu quả nhất
cho tóm tắt đa tài liệu zero-shot, như sau.
Với một ví dụ Multi-News mà chúng tôi được cung cấp
kcác tài liệu ngữ cảnh D1, D2, . . . , D k, chúng tôi prompt
mỗi mô hình cung cấp một bản tóm tắt sử dụng
định dạng hệ thống:
"You are a helpful assistant that
summarizes important information
from multiple documents." ,
và định dạng người dùng:
"Summarize the following
documents into a single summary:
Document 1: D1
Document 2: D2...
Document k: Dk"
12Vì mô hình này không có sẵn công khai, chúng tôi đã tái tạo
mô hình này và tinh chỉnh sử dụng gói HuggingFace (Wolf và cộng sự, 2020).

--- TRANG 17 ---
F Ví dụ Tóm tắt Hệ thống của GPT-3
và QAMD EN
Trong Bảng 10, chúng tôi bao gồm ba ví dụ về bản tóm tắt hệ thống
được tạo ra bởi GPT-3.5 và QAMD EN,
cũng như bản tóm tắt tham chiếu (sự thật cơ bản) tương ứng. Nói chung, các bản tóm tắt của QAMD ENngắn gọn hơn, bao gồm ít thông tin dư thừa
hơn, không bao gồm thông tin giai thoại,
và nhìn chung được các đánh giá viên con người ưa thích.
G Danh sách Giấy phép Phần mềm và Dữ liệu
Được sử dụng trong Công việc này
Mã nguồn của chúng tôi sẽ được phát hành và cấp phép dưới
giấy phép Apache License 2.0. Các phụ thuộc framework
của chúng tôi là:
•PRIMERA : https://github.com/
allenai/PRIMER/blob/main/
LICENSE , dưới Apache License
2.0.
•LongT5: https://github.com/
google-research/longt5/blob/
master/LICENSE , dưới Apache
License 2.0.
•NewSHead: https://github.com/
google-research-datasets/
NewSHead , Misc.
•QmdsCnnIr: https://github.com/
ramakanth-pasunuru/QmdsCnnIr ,
Misc.
•Multi-XScience: https://github.
com/yaolu/Multi-XScience/blob/
master/LICENSE , dưới giấy phép MIT.
•Multi-News: https://github.com/
Alex-Fabbri/Multi-News/blob/
master/LICENSE.txt , Misc.
•HotpotQA: https://hotpotqa.
github.io , dưới giấy phép CC BY-SA
4.0.
•WikiHop: https://qangaroo.cs.
ucl.ac.uk/ , dưới giấy phép CC BY-SA
3.0.
•Huggingface Transformers: https:
//github.com/huggingface/
transformers/blob/master/LICENSE , dưới Apache License
2.0.
•HuggingFace Datasets: https:
//github.com/huggingface/
datasets/blob/master/LICENSE ,
dưới Apache License 2.0.
•Huggingface Evaluate: https:
//github.com/huggingface/
evaluate/blob/main/LICENSE ,
dưới Apache License 2.0.
•Pytorch: https://github.com/
pytorch/pytorch/blob/master/
LICENSE , Misc.
•Pytorch Lightning: https://
github.com/PyTorchLightning/
pytorch-lightning/blob/master/
LICENSE , dưới Apache License 2.0.
•Longformer: https://github.
com/allenai/longformer/blob/
master/LICENSE , dưới Apache
License 2.0.
•UnifiedQA: https://github.com/
allenai/unifiedqa/blob/master/
LICENSE , dưới Apache License 2.0.
•ROUGE : https://github.
com/google-research/
google-research/tree/master/
rouge , dưới Apache License 2.0.
•spaCy: https://github.com/
explosion/spaCy/blob/master/
LICENSE , dưới giấy phép MIT.
•NLTK: https://github.com/nltk/
nltk , dưới Apache License 2.0.
•NumPy: https://github.com/
numpy/numpy/blob/main/LICENSE.
txt, dưới giấy phép BSD 3-Clause "New" hoặc
"Revised".
•seaborn: https://github.com/
mwaskom/seaborn/blob/master/
LICENSE.md , dưới giấy phép BSD 3-Clause "New"
hoặc "Revised".
•openai: https://github.com/
openai/openai-python/blob/
main/LICENSE , dưới giấy phép MIT.

--- TRANG 18 ---
Tóm tắt Sự thật Cơ bản Tham chiếu GPT-3.5 QAMD EN
Bạn có thể đã nghe tin vui:
Hoàng tử William và Kate
Middleton là cha mẹ tự hào
của một chú chó spaniel cocker
3 tháng tuổi. Tuy nhiên, nếu bạn
hy vọng tìm hiểu họ gọi
chú chó con là gì, hãy chuẩn bị
thất vọng. Công tước và Nữ công tước
xứ Cambridge đã hướng dẫn nghiêm ngặt
các trợ lý không tiết lộ tên của nó,
Daily Mail báo cáo. Một phát ngôn viên
nói, "Nó là một thú cưng riêng tư và họ
không muốn tên của nó được công khai
mặc dù cặp đôi vui lòng xác nhận
rằng họ thực sự có một chú chó mới."
Nhấn để xem hình ảnh của "thú cưng riêng tư."Hoàng tử William và Nữ công tước Kate
Middleton đã nhận nuôi một chú chó con
cocker spaniel, khoảng vài tháng tuổi
và là con trai của chú chó Ella của mẹ Kate.
Cặp đôi ban đầu có lo ngại về việc
chăm sóc một thú cưng, nhưng nhanh chóng
yêu thích chú chó con và quyết định
giữ nó. Công tước và Nữ công tước
xứ Cambridge có con chó spaniel cocker
đực vào đầu tháng 12 và đã
ổn định nó tại trang trại thuê
của họ ở Bắc Wales. Họ đã chọn
giữ tên thú cưng của họ riêng tư.
Chú chó mới là chú chó đầu tiên của cặp đôi
cùng nhau và thay thế cho chú chó Labrador
đen Widgeon của Hoàng tử William,
đã chết khoảng hai năm trước.Hoàng tử William và vợ Kate
Middleton đã nhận nuôi một thành viên
mới của gia đình: một chú chó con
cocker spaniel. Telegraph báo cáo
rằng cặp đôi đã nhận nuôi một bé trai,
nhưng đó không phải là một em bé.
Chú chó con chỉ vài tháng tuổi
và là con trai của chú chó Ella của mẹ Kate.
"William và Catherine yêu thích
chú chó con ngay lập tức và không lâu
sau đó họ quyết định giữ nó," một trợ lý
cung điện nói với US Weekly. "Bây giờ nó
là một phần của hoàng gia."
Một vụ va chạm vào giờ cao điểm giữa
một xe buýt của Cơ quan Giao thông Chicago
và một số xe khác hôm qua đã
khiến một người chết và ít nhất
tám người khác bị thương, một người
trong số đó nguy kịch, theo giới chức.
Vụ tai nạn xảy ra vào khoảng 6 giờ chiều tại
khu vực Loop phía bắc. Giới chức
nói rằng xe buýt khớp nối Route 148
Clarendon/Michigan Express đã va chạm
với ít nhất ba xe khác tại đại lộ Michigan
và phố Lake. Xe buýt đã lên
vỉa hè, và tại một thời điểm một người
đi bộ đã bị kẹt bên dưới. Cô ấy được
đưa đi được che bằng một tấm vải,
một nhân chứng chạy đến giúp đỡ nói với
Chicago Tribune. NBC Chicago mô tả
nạn nhân thiệt mạng là một phụ nữ 51 tuổi.
Tài xế, người được điều trị vì thương tích
không đe dọa tính mạng, là người duy nhất
trên xe buýt, và các điều tra viên đang
xem xét video từ một camera ghi lại
nội thất của xe buýt.Một xe buýt của Cơ quan Giao thông Chicago
đã gặp tai nạn nghiêm trọng trong giờ cao điểm,
dẫn đến một người thiệt mạng và tám người bị thương.
Xe buýt đã va chạm với một số xe khác
tại Đại lộ Bắc Michigan và Phố Đông Lake.
Tài xế xe buýt đã bị trích dẫn vì
không dừng tại đèn đỏ và vì "không thực hiện
sự cẩn trọng đúng đắn." Vụ tai nạn vẫn đang
được điều tra. Người thiệt mạng đã được xác định
là Aimee Coath, 51 tuổi, đến từ Flossmoor.
Tám cá nhân khác, bao gồm tài xế xe buýt,
đã được đưa vào bệnh viện với thương tích
không đe dọa tính mạng.Một vụ tai nạn xe buýt ở trung tâm Chicago
đêm qua đã khiến một người chết và
tám người khác bị thương, bao gồm
tài xế xe buýt, ít nhất 10 xe cứu thương
đã được gọi đến hiện trường, NBC Chicago báo cáo.
Nạn nhân thiệt mạng đã được xác định
là Aimee Coath, 51 tuổi, đến từ Flossmoor,
Chicago Tribune báo cáo. Coath là
người duy nhất trên xe buýt của Cơ quan
Giao thông Chicago tại thời điểm xảy ra tai nạn.
Chà, người Pháp thậm chí còn tinh tế
khi thực hiện những hành động phá hoại
bừa bãi. The Verge báo cáo một
thanh niên đã bị bắt gặp trên video
một cách bình tĩnh và có phương pháp
phá hoại một cửa hàng Apple ở Pháp
vì bất đồng về hoàn tiền. Người đàn ông
đã sử dụng một quả bóng thép--có vẻ
như loại được sử dụng trong một trò chơi
sân cỏ của Pháp--để phá ít nhất
10 chiếc iPhone và một MacBook
Air, từng cái một, trước khi bị
bắt bên ngoài cửa hàng. "Apple
là một công ty đã vi phạm quyền
của người tiêu dùng châu Âu," Daily Dot
dẫn lời người đàn ông nói bằng tiếng Pháp
trong quá trình đập iPhone. "Họ
từ chối hoàn tiền cho tôi. Tôi nói với họ:
'Trả lại tiền cho tôi.' Họ nói không.
Vậy bạn biết điều gì đang xảy ra không?
Điều này đang xảy ra!"Một cửa hàng Apple ở Dijon, Pháp đã bị
phá hoại bởi một khách hàng tức giận
đã sử dụng một quả bóng thép để đập
iPhone, MacBook, và iPad. Theo báo cáo,
khách hàng đang có tranh chấp với Apple
về việc hoàn tiền và tuyên bố rằng công ty
đã vi phạm quyền của người tiêu dùng châu Âu.
Cuối cùng anh ta đã bị an ninh bắt giữ
và bị bắt sau khi gây ra thiệt hại
đáng kể cho cửa hàng.Một video về một người đàn ông tức giận
phá hủy mọi thứ trong một cửa hàng Apple
của Pháp đang lan truyền trên
Internet đang tạo ra tiêu đề, và đây
không phải lần đầu tiên. Video cho thấy
một người đàn ông ném một quả bóng thép
qua cửa sổ cửa hàng, đập phá mọi thứ
trong tầm mắt, và sau đó bình tĩnh chờ
an ninh đến ngăn chặn anh ta, BBC báo cáo.
Người đàn ông, khoảng 20 tuổi, được xác định
là một công dân Pháp sống ở ngoại ô
Montpellier của Paris. Anh ta đã bị bắt
gặp trên camera giám sát tại cửa hàng
vào thứ Tư.
Bảng 10: Các bản tóm tắt hệ thống và bản tóm tắt tham chiếu của ba cụm tài liệu trong Multi-News.

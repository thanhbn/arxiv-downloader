# 2311.09210.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/rag/2311.09210.pdf
# File size: 502511 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Accepted to EMNLP 2024
Chain-of-Note: Enhancing Robustness in Retrieval-Augmented
Language Models
Wenhao Yu, Hongming Zhang, Xiaoman Pan, Peixin Cao,
Kaixin Ma, Jian Li, Hongwei Wang, Dong Yu
Tecent AI Lab
wenhaowyu@global.tencent.com
Abstract
Retrieval-augmented language model (RALM)
represents a significant advancement in miti-
gating factual hallucination by leveraging ex-
ternal knowledge sources. However, the reli-
ability of the retrieved information is not al-
ways guaranteed, and the retrieval of irrele-
vant data can mislead the response generation.
Moreover, standard RALMs frequently neglect
their intrinsic knowledge due to the interference
from retrieved information. In instances where
the retrieved information is irrelevant, RALMs
should ideally utilize their intrinsic knowledge
or, in the absence of both intrinsic and retrieved
knowledge, opt to respond with "unknown" to
avoid hallucination. In this paper, we intro-
duces CHAIN -OF-NOTE (CON), a novel ap-
proach to improve robustness of RALMs in
facing noisy, irrelevant documents and in han-
dling unknown scenarios. The core idea of
CONis to generate sequential reading notes
for each retrieved document, enabling a thor-
ough evaluation of their relevance to the given
question and integrating this information to for-
mulate the final answer. Our experimental re-
sults show that GPT-4, when equipped with
CON, outperforms the CHAIN -OF-THOUGHT
approach. Besides, we utilized GPT-4 to cre-
ate 10K CONdata, subsequently trained on
LLaMa-2 7B model. Our experiments across
four open-domain QA benchmarks show that
fine-tuned RALMs equipped with CONsignifi-
cantly outperform standard fine-tuned RALMs.
1 Introduction
Retrieval-augmented language models (RALMs)
represent a novel framework that significantly ad-
vances large language models (Touvron et al., 2023;
OpenAI, 2023) by addressing key limitations such
as reducing factual hallucinations (Ji et al., 2023;
Zhang et al., 2023a), injecting up-to-date knowl-
edge in a plug-and-play manner (Dhingra et al.,
2022; Vu et al., 2023), and enhancing domain-
specific expertise (Li et al., 2023; Qin et al., 2023).
Wikipedia: … "It Must Have Been Love" is a song written by Per Gessle and performed by the Swe-dish pop duo Roxette. The power ballad became the duo's third number one hit in United States.
Wikipedia: … "It Must Be Love" is a song written and originally recorded in 1971 by Labi Siffre. It was also recorded by ska/pop band Madness in 1981.
The answer is Labi Siffre. 
The first passage confirms that Roxette is the performer of “It Must Have Been Love.” How-ever, the second passage refers to “It Must Be Love,” which is a different song andirrelevant to the question. Thus, the answer is Roxette.RALMwithCoN
Who performed "It Must Have Been Love”?
RALMw/oCoNFigure 1: Compared with the current RALMs, the core
idea behind CHAIN -OF-NOTE (CON)is to generate
sequential reading notes for the retrieved documents,
ensuring a systematic assessment of their relevance to
the input question before formulating a final response.
These enhancements primarily stem from integrat-
ing large language models (LLMs) with external
knowledge sources (Guu et al., 2020; Lewis et al.,
2020; Borgeaud et al., 2022; Shi et al., 2023c). In
a typical RALM setup, a query is first processed
by a retriever that searches a vast evidence corpus
for pertinent documents. A reader then examines
these documents, extracting useful information and
formulating the final output answer.
However, there exist several issues with the cur-
rent RALM framework. First, there is no guarantee
that the information retrieval (IR) system will al-
ways yield the most pertinent or trustworthy infor-
mation. The retrieval of irrelevant data can lead to
misguided responses (Shi et al., 2023a; Yoran et al.,
2023), and potentially causing the model to over-
look its inherent knowledge, even when it possesses
adequate information to address the query (MallenarXiv:2311.09210v2  [cs.CL]  3 Oct 2024

--- PAGE 2 ---
et al., 2023). Secondly, state-of-the-art LLMs of-
ten hallucinate when addressing fact-oriented ques-
tions, a deficiency that can be risky and may dis-
courage users (Ji et al., 2023; Zhang et al., 2023a).
Ideally, an intelligent system should be capable
of determining whether it has enough knowledge,
both intrinsic and retrieved, to provide an accurate
answer. In cases where knowledge is insufficient,
the system should respond with “unknown” when
the answer cannot be determined. Based on the
shortcomings of the standard RALM system, in
this paper, we aims to improve the robustness of
RALMs, mainly focusing on two pivotal aspects:
(1) Noise Robustness: The ability of a RALM to
discern and disregard noisy information present in
irrelevant retrieved documents, while appropriately
leveraging its intrinsic knowledge.
(2) Unknown Robustness: The capacity of a
RALM to acknowledge its limitations by respond-
ing with “unknown” when given a query it does
not have the corresponding knowledge to answer,
andthe relevant information is not found within
the retrieved documents.
In this work, we introduce a novel framework
named CHAIN -OF-NOTE (CON), designed to en-
hance the robustness of RALMs. The cornerstone
ofCONis to generate a series of reading notes for
retrieved documents, enabling a comprehensive as-
sessment of their relevance to the input query. This
approach not only evaluates each document’s perti-
nence but also pinpoints the most critical and reli-
able information therein. This process effectively
filters out irrelevant or less credible content, lead-
ing to responses that are more precise and contex-
tually relevant, as exemplified in Figure 1. Besides,
CONenhances the capability of RALM to handle
queries fall outside the scope of training data. In
cases where the retrieved documents do not pro-
vide any relevant information, CONcan guide the
model to acknowledge its limitations and respond
with an “unknown” or provide possible explanation
based on available data, enhancing reliability.
To validate the effectiveness of the CONidea,
we first conducted a comparison with CHAIN -OF-
THOUGHT (COT)(Wei et al., 2022) using GPT-
4 as the reader, showing CONis more effective
than COTin retrieval-augmented scenarios. Next,
we prompted GPT-4 (OpenAI, 2023) to generate
a 10K training examples based on questions col-
lected from NQ (Kwiatkowski et al., 2019), and
subsequently trained on the LLaMa-2 7B, to validthe note-taking ability for smaller-sized models.
Our evaluation of the RALM, integrated with CON
and compared to the standard RALM system, fo-
cused on three major aspects: (1) overall QA perfor-
mance using DPR-retrieved documents, (2) noise
robustness, assessed by introducing noisy infor-
mation to the system, and (3) unknown robust-
ness, evaluated through queries not covered in the
LLaMa-2 pre-training data, i.e., real-time ques-
tions. The evaluations were conducted on the NQ
and three additional out-of-domain open-domain
QA datasets, namely TriviaQA (Joshi et al., 2017),
WebQ (Berant et al., 2013), and RealTimeQA (Ka-
sai et al., 2023). Our experiments show that CON
not only improves overall QA performance when
employed with DPR-retrieved documents but also
significantly enhances robustness in both noise and
unknown aspects. This includes a +7.9 increase in
accuracy (measured by the exact match score) with
noisy retrieved documents, and a +10.5 increase in
the rejection rate for real-time questions1that are
beyond the pre-training knowledge scope.
2 Proposed Method
2.1 Overview
In this section, we introduce CHAIN -OF-NOTE, an
innovative advancement for retrieval-augmented
language models (RALMs). Specifically, CON
framework generates sequential reading notes for
the retrieved documents, which enables a system-
atic evaluation of the relevance and accuracy of
information retrieved from external documents. By
creating sequential reading notes, the model not
only assesses the pertinence of each document to
the query but also identifies the most critical and
reliable pieces of information within these docu-
ments. This process helps in filtering out irrelevant
or less trustworthy content, leading to more accu-
rate and contextually relevant responses.
2.2 Background of Existing RALMs
RALMs signify a transformative development in
language models, enhancing their output by incor-
porating external knowledge. These models oper-
ate by introducing an auxiliary variable, denoted
asd, which represents retrieved documents. This
inclusion allows them to consider a range of pos-
sible documents, thereby producing responses that
are more informed and precise (Lazaridou et al.,
1We use real-time questions collected from RealTimeQA
after May 2023, which was not trained by LLaMa-2.

--- PAGE 3 ---
Wikipedia 1: Deadpool 2 is a 2018 American super-hero film based on the Marvel Comics character Deadpooldistributed by 20th Cen-tury Fox. … This movie was followed by releases  in 49 markets over the next few days, including the United States on June1, 2018. 
When was the Deadpool2 being released?
Wikipedia 2: …Deadpool 2 premiered at Lei-cester Square in London on May 10, 2018 Itwas released in United States on May 18, 2018, having been previously scheduled for release on June 1 of that year. …
The first passage suggests that “Deadpool2"            released in the United States on June 1, 2018. However, the second passage clarifies that the movie was actually released earlier, on May 18, having been rescheduled from the initially planned date of June 1. Based on information provided in above passage, the answer is May 18, 2018.Wikipedia 1: The nostalgic and melancholic song recounts the type of girls with whom the singer had relationships at various years: when he was 17, “small-town girls ... on the village green”; at 21, “city girls who lived up the stairs”
Who wrote the song “When I was 17”?
Wikipedia 2: …“It Was a Very Good Year” , commonly unknown as “When I was 17”, was made famous by Frank Sinatra‘s version in D minor, which won the Grammy Award for Best Male Vocal Performance in 1966.
Wikipedia 1: The Divergent Series is a feature film trilogy.… Distributed by Summit Enter-tainment and Lions-gate Films, the series hasthreescience fiction films set in a dystopian society:Divergent, Insurgent, and Allegiant.
When is the fourth movie of the Divergent series coming out?
Wikipedia 2: The film(Divergent) was a box office bomb, grossing just $179 million against its budget of $142 million, becoming the low-estgrossing “Divergent” film. This led initially to budget cuts on the fourth and final film.…
The first passage discusses the songremin--iscing about relationships at different agesbut does not specify the songwriter. The second clarifies the song often mistakenlycalled “When I Was 17” is actually “It Was a Very Good Year,” Both passages do not explicitly mention the songwriter, but imply the correct title. Based on my know-ledge, the answer is Ervin Drake.
The first passage suggests the "Divergent" series was initially planned as a trilogy, while the secondpassage discusses the poor box office leadsto budget cuts for a potential fourth movie. However, neither passage confirms the release date of the fourth filminDivergent Series. Given this lack of specific information and my current knowledge, the answer is unknown.
(a)CoN:Relevant->Findtheanswer(b)CoN:Irrelevant->Infertheanswer(c)CoN:Irrelevant->AnswerUnknownFigure 2: Illustration of the CHAIN -OF-NOTE (CON)framework with three distinct types of reading notes. Type
(a) depicts the scenario where the language model identifies a document that directly answers the query, leading
to a final answer formulated from the retrieved information. Type (b) represents situations where the retrieved
document, while not directly answering the query, provides contextual insights, enabling the language model to
integrate this context with its inherent knowledge to deduce an answer. Type (c) illustrates instances where the
language model encounters irrelevant documents and lacks the necessary knowledge to respond, resulting in an
“unknown” answer. This figure exemplifies the CoN framework’s capability to adaptively process information,
balancing direct information retrieval, contextual inference, and the recognition of its knowledge boundaries.
2022; Shi et al., 2023c). The RALM models can
be represented as p(y|x) =P
ip(y|di, x)p(di|x).
Here, xrepresents the input query, and ysignifies
the model’s generated response. In practice, it is
infeasible to compute the sum over all possible doc-
uments due to the vast number of potential sources.
Consequently, the most common approach involves
approximating the sum over dusing the khighest
ranked documents, and providing all these docu-
ments as part of the input. We assume, w.l.o.g.,
that these documents are [d1, . . . , d k], yielding
p(y|x) =Pk
i=1p(y|di, x)p(di|x).
However, the existing RALMs suffer from sev-
eral limitations:
•Risk of Surface-Level Processing: When
directly generating an answer, language models
might rely on surface-level information without
deep comprehension. Thus, they could easily over-
look the nuances of question or documents, partic-
ularly in complex or indirect questions.
•Difficulty in Handling Contradictory Informa-
tion: When faced with documents containing con-
tradictory information, directly generating an an-
swer becomes challenging. The model may strug-
gle of these contradictions or to determine which
piece of information is more credible or relevant.•Reduced Transparency and Interpretability: Di-
rect answer generation offers limited insight into
how the model arrived at its conclusion. This lack
of transparency makes it challenging for users to
understand the basis of the model’s conclusions.
•Overdependence on Retrieved Documents: Di-
rect generation can lead to an overreliance on the
content of the retrieved documents (i.e. tendency to
extract information from retrieved documents (Shi
et al., 2023a)), ignoring the model’s inherent knowl-
edge base. This can be particularly limiting when
the retrieved documents are noisy or out-of-date.
2.3 The C HAIN -OF-NOTE Framework
TheCHAIN -OF-NOTE (CON)framework presents
a solution to the challenges faced by retrieval-
augmented language models (RALMs). This
framework significantly enhances the ability of
RALMs to critically assess retrieved documents
through a structured note-taking process. Specifi-
cally, it involves generating concise and contextu-
ally relevant summaries or notes for each document.
This method allows the model to systematically
evaluate the relevance and accuracy of informa-
tion drawn from external documents. By creating
sequential reading notes, CONnot only assesses

--- PAGE 4 ---
the pertinence of each document to the query but
also pinpoints the most reliable information and
resolves conflicting information. This approach
effectively filters out irrelevant or less trustworthy
content, leading to responses that are both more
accurate and contextually relevant.
Given an input question xandkretrieved doc-
uments [d1,···, dk], the model aims to gener-
ate textual outputs comprising multiple segments
[yd1,···, ydk, y]. Here, ydisignifies the tokens for
thei-th segment, representing the reading note for
the corresponding document di, as shown in Fig-
ure 2. After generating individual reading notes,
the model synthesizes the information to create a
consolidated final response y. The implementation
of the CHAIN -OF-NOTE (CON)involves three key
steps: (1) designing the notes ydi, (2) collecting the
data, and (3) training the model.
2.3.1 C HAIN -OF-NOTE Format Design
The framework primarily constructs three types of
reading notes, as shown in Figure 2 , based on the
relevance of the retrieved documents to the input
question: First, when a document directly answers
the query, the model formulates the final response
based on this relevant information, as shown in Fig-
ure 2(a). Second, if the retrieved document does
not directly answer the query but provides useful
context, the model leverages this information along
with its inherent knowledge to deduce an answer,
as shown in Figure 2(b). Third, in cases where the
retrieved documents are irrelevant, and the model
lacks sufficient knowledge to answer, it defaults
to responding with “unknown", as shown in Fig-
ure 2(c). This nuanced approach mirrors human
information processing, striking a balance between
direct retrieval, inferential reasoning, and the ac-
knowledgment of knowledge gaps.
2.3.2 Data Collection and Model Training
To equip the model with the ability to generate such
reading notes, it’s essential to gather appropriate
training data. Manual annotation for each reading
note is resource-intensive, so we employ a state-
of-the-art language model – GPT-4 – to generate
the notes data. This method is both cost-effective
and enhances reproducibility. We initiate this pro-
cess by randomly sampling 10k questions from
the NQ (Kwiatkowski et al., 2019) training dataset.
GPT-4 is then prompted with specific instructions
and in-context examples to the three distinct types
of note generation (detailed in Appendix A.5). Thequality of GPT-4’s predictions is subsequently as-
sessed through human evaluations on a small subset
of the data before proceeding to the entire set. The
NQ dataset is chosen as our primary dataset due to
its diverse range of real user queries from search
engines. However, to ensure the model’s adaptabil-
ity, we also test its performance on three additional
open-domain datasets, including TriviaQA, WebQ,
and RealTimeQA, showing its generalization capa-
bilities to out-of-domain (OOD) data.
After collecting 10K training data from GPT-4,
the next step involves using them to train a LLaMa-
2 7B model (Touvron et al., 2023), to validate the
feasibility of generating CHAIN -OF-NOTE (CON)
outputs. To do this, we concatenate the instruc-
tion, question and documents as a prompt and train
the model to generate notes and answer in a stan-
dard supervised way. Our in-house model learns to
sequentially generate reading notes for each doc-
ument to assess their relevance to the input query.
Responses are generated based on the document’s
relevance, enhancing accuracy and reducing mis-
information. If all documents are irrelevant, the
model either relies on inherent knowledge for an
answer or responds with “unknown” if the answer
cannot be determined accurately.
2.3.3 Hybrid Training for Better Efficiency
Generating CHAIN -OF-NOTE (CON)would in-
crease inference cost, potentially hindering real-
world usage. To address this, we experimented
with a simple yet effective strategy for internaliz-
ing C ON reasoning, called Hybrid Training .
Specifically, we allocate 50% of the training time
to the standard RALM, which involves directly
generating answers without notes, and the other
50% to RALM with CoN. This strategy allows the
model to internalize intermediate reasoning steps
during training. Additionally, we add two different
prompt words before each category of data.
During the inference phase, we exclusively use
the standard RALM prompt to guide the model,
prompting it to output answers without relying on
explicit reading notes. This approach leverages the
hidden states developed during training for implicit
CONreasoning. The model trained with the hybrid
training strategy maintains the same inference time
while achieving only slightly lower performance
wit CoN. The results will be introduced in §3.5.

--- PAGE 5 ---
Datasets Full size IR Recall Subset size
NQ 3,610 73.82 2,086
TriviaQA 7,993 89.95 7,074
WebQ 2,032 64.22 1,231
Table 1: Dataset statistics. The recall evaluation is based
on DPR retrieval on the full test set.
3 Experiments
3.1 Experimental Settings and Evaluations
3.1.1 Datasets and Splits
We conducted comprehensive experiments using
three benchmark datasets in open-domain question
answering (QA): NQ (Kwiatkowski et al., 2019),
TriviaQA (Joshi et al., 2017), and WebQ (Berant
et al., 2013), with further details provided in Ap-
pendix A.3. Additionally, we employed Real-
TimeQA (Kasai et al., 2023) as a special case to
evaluate “unknown” robustness.
The evaluation was conducted based on two
evaluations sets: full set and subset evaluation.
Firstly, akin to traditional open-domain QA evalu-
ation, we assessed the models using all questions
from the test set to evaluate the overall QA per-
formance . The documents were retrieved using
DPR, and the top- kdocuments were fed into the
generator. We adhered to the same test splits for
the open-domain QA setting as used by Izacard and
Grave (2021); Karpukhin et al. (2020). For Trivi-
aQA, evaluations from LLaMa-2 (Touvron et al.,
2023) were conducted on the Wikipedia dev set
comprising 7,993 examples. Therefore, we also
follow the same evaluation on this dev set to facili-
tate comparisons with their performance. Secondly,
to assess the model’s noise robustness and un-
known robustness , we extracted subsets from the
above test sets that contained relevant documents
in the retrieved list. We then enumerated each re-
trieved document to determine if it was a golden
document for the given question. Based on the
noise ratio r, for instance, if the top- kdocuments
are needed for the generator, then k·rwould be the
number of noisy documents, and k·(1−r)would
be the number of relevant documents. For example,
when noise ratio is 20% and top-5 documents are
needed, then 4 are relevant documents, and 1 is
irrelevant documents. During the enumeration of
the retrieved documents in data pre-processing, we
populated two lists; when one list reached its limit,
we stopped adding more documents to that list untilboth lists were complete. In instances where no
relevant documents are retrieved by the DPR for
certain questions, we exclude these from robust-
ness evaluation. Therefore, the subset is smaller
than the original test set, as shown in Table 1.
3.1.2 Baseline Methods
CHAIN -OF-NOTE (CON)is built upon the tra-
ditional retrieve-then-read pipeline (Lewis et al.,
2020). Recent implementations such as Lazaridou
et al. (2022); Shi et al. (2023a); Luo et al. (2023)
integrate large language models to achieve better
performance. Therefore, we primarily compare our
approach against these retrieve-read methods. As
outlined in the §2.3, we denote an input question
asxand its corresponding answer as y. Besides, di
represents the i-th retrieved document, and ydiis
the associated reading note for that document. Here
we show the difference of methods to compare.
QA fine-tune w/o IR are trained to directly gen-
erate an answer from the input question, without
relying on any external retrieved information. Es-
sentially, it learns the function f:x→y, trans-
forming the question xdirectly to answer y.
Retrieve-Read (Shi et al., 2023c) are trained to
generate an answer not only from the question but
also by incorporating retrieved documents. It learns
the function f:{x, d 1,···, dk} →y, meaning it
transforms the question xand a set of retrieved
documents {d1,···, dk}into an answer y.
Retrieve-Read with CHAIN -OF-NOTE are trained
to generate reading notes for each retrieved doc-
ument before formulating the final answer. It
learns the function f:{x, d 1,···, dk} →
{yd1,···, ydk, y}, thereby enabling the model
to process the question xand retrieved doc-
uments {d1,···, dk}to produce reading notes
{yd1,···, ydk}and the final answer y.
For fair comparability, we trained all LLaMa-2
models on same training set, with the main differ-
ence being in the input and output formats. We also
note that the experiments conducted with GPT-4
were performed in a zero-shot setting. The prompts
used for various experimental conditions are de-
tailed in Appendix A.5.
3.1.3 Evaluation Metrics
For the evaluation of open-domain QA perfor-
mance, we have employed two widely recognized
metrics: Exact Match (EM) and F1 score, as sug-
gested by prior work in the Chen et al. (2017);

--- PAGE 6 ---
ModelsNQ TriviaQA WebQ Average
EM F1 EM F1 EM F1 EM F1
Backbone language model: LLaMa-2 7B
QA fine-tune w/o IR 28.80 37.53 63.19 68.61 28.30 42.77 35.98 44.27
SAIL (Luo et al., 2023)* 36.20 44.23 73.20 80.92 27.92 40.65 45.77 55.27
Retrieve-Read (Shi et al., 2023c) 47.39 55.81 74.92 81.53 29.58 43.51 48.49 56.97
+ C HAIN -OF-NOTE (ours) 48.92 57.53 76.27 82.25 32.33 46.68 50.46 58.78
(+1.53) (+1.72) (+1.35) (+0.72) (+2.75) (+3.17) (+1.97) (+1.81)
Backbone language model: GPT-4-1106 †
QA prompt w/o IR 54.0 74.2 56.2 61.5
Retrieve-Read (Shi et al., 2023c) 61.8 70.6 56.8 63.1
+ C HAIN -OF-THOUGHT 63.6 71.2 58.4 64.4
+ C HAIN -OF-NOTE (OURS ) 63.8 74.6 58.8 65.7
(+2.0) (+4.0) (+2.0) (+2.6)
Table 2: The RALM, when equipped with CHAIN -OF-NOTE (CON), demonstrates a marginal improvement over
the standard RALM in full test set evaluations. Significantly, it outperforms the standard RALM system in scenarios
with noisy documents, suggesting that C ON can substantially enhance the model’s noise robustness.
* SAIL was designed for retrieval-augmented instruction tuning, and as such, may not be ideally factual QA.
†Evaluating GPT-4 outputs with EM score is challenging; we opt for Accuracy, with reasons outlined in §3.1.3.
Karpukhin et al. (2020); Zhu et al. (2021). For
EM score, an answer is deemed correct if its nor-
malized form – obtained through the normalization
procedure delineated by (Karpukhin et al., 2020)
– corresponds to any acceptable answer in the pro-
vided list. Similar to EM score, F1 score treats the
prediction and ground truth as bags of tokens, and
compute the average overlap between the predic-
tion and ground truth answer (Chen et al., 2017).
Besides, we use reject rate (RR) to evaluate the
unknown robustness when given questions beyond
a language model’s knowledge scope.
Finally, since GPT-4 is not directly trained on
open-domain QA benchmarks, employing EM /
F1 for evaluation is challenging. Therefore, we
adopt the approach outlined in Mallen et al. (2023);
Kandpal et al. (2023), utilizing accuracy as the
evaluation metric. Accuracy considers a prediction
correct if any substring of the prediction exactly
matches any of the provided correct answers.
3.2 Evaluation on Overall QA Performance
Table 2 demonstrates that the RALM consistently
outperforms the directly fine-tuned LLaMa-2 with
QA pairs, without retrieval. This improvement
is closely tied to the effectiveness of the retrieval
process. As indicated in Table 1, DPR demon-
strates markedly superior retrieval performance on
the NQ and TriviaQA datasets compared to WebQ.
Consequently, the benefits of retrieval are more
pronounced on NQ and TriviaQA. Furthermore,when comparing our enhanced RALM, which inte-
grates CON, with the standard RALM, our method
persistently shows better performance. There is
an average improvement of +1.97 in EM scores
across all three datasets when using LLaMa-2 as
backbone language model. Delving deeper, we
find that this improvement varies depending on
whether DPR successfully retrieves relevant doc-
uments. Specifically, the average improvement is
+1.2 when DPR retrieves relevant documents and
+2.3 when it does not on the NQ dataset. This dis-
parity suggests that our CONimprove RALM’s in
scenarios where more noisy documents are fetched
in the first retrieval stage. This observation aligns
with our findings on noise robustness, which are
elaborated in the subsequent sections detailing our
experimental results.
Furthermore, the dynamics observed with larger
language models differ from those noted in experi-
ments with smaller-sized models due to their supe-
rior factual knowledge. The impact of utilizing re-
trieval is observed to be less pronounced with larger
models and can even be detrimental in certain cases,
such as with TriviaQA, where questions are mostly
straightforward. Concerning the comparison be-
tween CONand the baseline, the performance trend
remains consistent with that observed in smaller-
sized models, suggesting that CONmaintains its
significance across different model sizes.

--- PAGE 7 ---
ModelsNoise NQ TriviaQA WebQ Average
Ratio EM F1 EM F1 EM F1 EM F1
Retrieve-Read100%34.28 41.74 55.30 61.67 29.58 46.34 39.72 49.92
+ C HAIN -OF-NOTE 41.83 49.58 64.30 70.00 36.85 53.07 47.66 57.55
(+7.55) (+7.84) (+9.00) (+8.33) (+7.27) (+6.73) (+7.94) (+7.63)
Retrieve-Read80%54.28 61.03 73.83 80.02 35.46 52.70 54.52 64.58
+ C HAIN -OF-NOTE 56.63 63.23 75.89 81.24 40.60 56.54 57.70 67.00
(+2.35) (+2.20) (+2.06) (+1.22) (+5.14) (+3.84) (+3.18) (+2.42)
Retrieve-Read60%61.44 67.94 78.44 83.65 37.01 54.16 58.96 68.58
+ C HAIN -OF-NOTE 63.43 69.33 78.79 84.07 41.26 56.91 61.16 70.10
(+1.99) (+1.39) (+0.35) (+0.42) (+4.25) (+2.75) (+2.20) (+1.52)
Retrieve-Read40%64.62 71.12 80.56 86.76 38.40 55.60 61.19 71.16
+ C HAIN -OF-NOTE 65.91 72.22 81.72 87.11 42.16 58.15 63.26 72.49
(+1.29) (+1.10) (+1.16) (+0.35) (+3.76) (+2.55) (+2.07) (+1.33)
Retrieve-Read20%67.21 73.69 81.73 87.89 39.95 56.66 62.96 72.75
+ C HAIN -OF-NOTE 70.00 76.08 82.86 88.24 44.36 60.13 65.74 74.82
(+2.79) (+2.39) (+1.13) (+0.35) (+4.41) (+3.47) (+2.78) (+2.07)
Retrieve-Read0%69.23 75.57 83.34 89.44 42.24 58.59 64.93 74.53
+ C HAIN -OF-NOTE 73.28 79.86 83.52 88.94 46.16 62.38 67.65 77.06
(+4.05) (+4.29) (+0.18) (-0.50) (+3.92) (+3.79) (+2.72) (+2.53)
Table 3: Evaluation on Noise Robustness. The backbone language model is LLaMa-2 7B. The CHAIN -OF-NOTE
framework shows superior performance compared to the standard RALM system, particularly notable at higher
noise ratios.We explain how we synthesize data with different noise ratios under real-world scenarios in §3.1.1.
Models ↓RealTimeQA
EM F1 RR
Retrieve-Read (Shi et al., 2023c) 15.6 19.9 6.1
+ C HAIN -OF-NOTE (ours) 15.7 20.3 13.0
Table 4: Evaluation on Unknown Robustness. The CON
shows better performance than standard RALM system.
3.3 Evaluation on Noise Robustness
As illustrated in Table 2, when faced with entirely
noisy documents, both the standard RALM and
ourCHAIN -OF-NOTE enhanced RALM underper-
formed compared to the no-retrieval setting. This
suggests that RALMs can be misled by noisy infor-
mation, leading to more hallucinations.
Notably, equipping the model with CONenables
it to perform nearly as well as the baseline model
directly fine-tuned with QA pairs without retrieval,
showcasing its robustness to noise and its ability
to disregard irrelevant information. The CONap-
proach is effective not only in fine-tuned, smaller-
sized models but also in large language models,
such as GPT-4, with adjustments made only to the
prompt. Besides, in comparison to the CHAIN -OF-
THOUGHT technique, commonly utilized in rea-
soning scenarios, CONpresents a more efficient
strategy for retrieval-augmented settings, particu-larly in addressing knowledge-intensive tasks.
Table 3 shows that RALM enhanced with CON
consistently outperforms the standard RALM, es-
pecially in scenarios with exclusively noisy doc-
uments. An average improvement of +7.9 in EM
score on fully noisy documents is observed on three
open-domain QA datasets, in average. Experiments
with lower noise ratios also consistently demon-
strate the improvements brought by CON, aligning
the overall QA performance.
3.4 Evaluation on Unknown Robustness
Table 4 illustrates that our RALM equipped with
CONexhibits superior robustness in handling un-
known scenario, particularly evident in the Real-
TimeQA benchmark. This benchmark falls com-
pletely outside the model’s domain and contains
real-time information that was not part of the
LLaMa-2 pre-training data. Despite this, models
are still capable of providing correct answers in
some cases, as the answers remain consistent over
time. In comparison to the standard RALM sys-
tem, our method shows a significant improvement,
exceeding +10.5 in its ability to reject to answer
questions in unknown scenario. The evaluation is
based on reject rate (RR), i.e., number of rejected

--- PAGE 8 ---
34.354.361.464.667.269.241.856.663.465.970.073.3
36.355.863.665.270.173.1
304050607080
100%80%60%40%20%0%EMScoreNQStandard RALMRALM with CoNRALM with CoN (hybrid)Figure 3: Using a hybrid training strategy demonstrates
slightly lower robustness across various noise ratios but
consistently better performance than standard RALMs.
Models ↓ Inference Time(s)
Retrieve-Read 0.6104
+ C HAIN -OF-NOTE 12.0192
+ C HAIN -OF-NOTE (hybrid) 0.6074
Table 5: The inference time comparison shows the aver-
age decoding time per example on 8 ×A100 GPUs.
questions / total questions. This highlights our
model’s enhanced capability to discern and disre-
gard information that is unfamiliar or not learned
during its initial training phase.
3.5 Evaluation on Hybrid Training Strategy
As illustrated in Figure 3 and Table 5, our proposed
RALM equipped with a hybrid strategy demon-
strates slightly lower robustness across various
noise ratios while but keeping similar effcient de-
coding time consumption to the standard RALM.
This indicates that our CHAIN -OF-NOTE frame-
work, when implemented with a hybrid training
strategy, is highly applicable to a wide range of
real-world business scenarios. This enhancement
in robustness without significant time overhead
highlights the practical value and efficiency of our
approach, making it a viable solution for environ-
ments where QA accuracy can vary but inference
time is crucial.
4 Related Work
Retrieval-Augmented Language Models (RALMs)
represent a significant advancement in natural lan-
guage processing, combining the power of large
language models with the specificity and detail pro-
vided by external knowledge sources (Guu et al.,2020; Lewis et al., 2020; Izacard et al., 2022). Re-
cent studies highlight the impact of context rele-
vance on language model performance (Creswell
et al., 2022; Shi et al., 2023a; Yoran et al., 2023).
Notably, Creswell et al. (2022) demonstrated that
incorporating random or irrelevant contexts could
adversely affect QA performance. In contrast, Shi
et al. (2023a) discovered that adding irrelevant con-
text to exemplars or task-specific instructions can
sometimes enhance model performance, implying
that models might intrinsically possess capabilities,
developed during pre-training, to manage such sce-
narios. Most pertinent to our research is the study
by Yoran et al. (2023), which focused on training
RALMs to disregard irrelevant contexts. This ap-
proach, while distinct from our proposed solution,
underscores the importance of context relevance in
enhancing the effectiveness of RALMs.
Besides, we present more related Chain-of- Xs
approaches (e.g., Chain-of-Thought (CoT) (Wei
et al., 2022)) in the Appendix A.1.1 and A.2.
5 Conclusion
In this paper, we introduce the CHAIN -OF-NOTE
(CON)framework, a novel methodology designed
to enhance the robustness of RALMs. The central
concept of CONrevolves around the generation of
sequential reading notes for each retrieved docu-
ment. This process allows for an in-depth assess-
ment of document relevance to the posed question
and aids in synthesizing this information to craft
the final answer. Our experiments show that GPT-4,
when equipped with CON, outperforms the CHAIN -
OF-THOUGHT approach. Besides, we utilized GPT-
4 to create 10K CONdata, subsequently trained on
a LLaMa-2 7B model. Our experiments across four
open-domain QA benchmarks show that RALMs
equipped with CONsignificantly outperform stan-
dard fine-tuned RALMs.
6 Limitations
One major limitation of the CHAIN -OF-NOTE
(CON)approach is its increased inference cost
due to the sequential generation of notes. While
CONis beneficial for assessing the relevance and
integrating external knowledge, it results in longer
response times, which is problematic for time-
sensitive applications. Moreover, the system’s effi-
ciency depends on the conciseness and relevance
of the generated notes, which can fluctuate based
on the complexity of the retrieved documents.

--- PAGE 9 ---
References
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy
Liang. 2013. Semantic parsing on freebase from
question-answer pairs. In EMNLP , pages 1533–
1544.
Sebastian Borgeaud, Arthur Mensch, Jordan Hoff-
mann, Trevor Cai, Eliza Rutherford, Katie Milli-
can, George Bm Van Den Driessche, Jean-Baptiste
Lespiau, Bogdan Damoc, Aidan Clark, et al. 2022.
Improving language models by retrieving from tril-
lions of tokens. In International conference on ma-
chine learning , pages 2206–2240. PMLR.
Danqi Chen, Adam Fisch, Jason Weston, and Antoine
Bordes. 2017. Reading wikipedia to answer open-
domain questions. In Proceedings of the 55th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers) , pages 1870–1879.
Hao Cheng, Yelong Shen, Xiaodong Liu, Pengcheng
He, Weizhu Chen, and Jianfeng Gao. 2021. Unit-
edqa: A hybrid approach for open domain question
answering. In Proceedings of the 59th Annual Meet-
ing of the Association for Computational Linguistics
and the 11th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers) ,
pages 3080–3090.
Antonia Creswell, Murray Shanahan, and Irina Higgins.
2022. Selection-inference: Exploiting large language
models for interpretable logical reasoning. arXiv
preprint arXiv:2205.09712 .
Bhuwan Dhingra, Jeremy R Cole, Julian Martin
Eisenschlos, Daniel Gillick, Jacob Eisenstein, and
William W Cohen. 2022. Time-aware language mod-
els as temporal knowledge bases. Transactions of the
Association for Computational Linguistics , 10:257–
273.
Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu,
Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Ja-
son Weston. 2023. Chain-of-verification reduces hal-
lucination in large language models. arXiv preprint
arXiv:2309.11495 .
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-
pat, and Ming-Wei Chang. 2020. Realm: Retrieval-
augmented language model pre-training. arXiv
preprint arXiv:2002.08909 .
Fan Huang, Haewoon Kwak, and Jisun An. 2023. Chain
of explanation: New prompting method to generate
quality natural language explanation for implicit hate
speech. In Proceedings of the ACM Web Conference
2023 , pages 90–93.
Gautier Izacard and Edouard Grave. 2021. Leveraging
passage retrieval with generative models for open
domain question answering. In EACL , pages 874–
880.
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lu-
cas Hosseini, Fabio Petroni, Timo Schick, JaneDwivedi-Yu, Armand Joulin, Sebastian Riedel, and
Edouard Grave. 2022. Few-shot learning with re-
trieval augmented language models. arXiv preprint
arXiv:2208.03299 .
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan
Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea
Madotto, and Pascale Fung. 2023. Survey of halluci-
nation in natural language generation. ACM Comput-
ing Surveys , 55(12):1–38.
Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke
Zettlemoyer. 2017. Triviaqa: A large scale distantly
supervised challenge dataset for reading comprehen-
sion. In ACL, pages 1601–1611.
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric
Wallace, and Colin Raffel. 2023. Large language
models struggle to learn long-tail knowledge. In In-
ternational Conference on Machine Learning , pages
15696–15707. PMLR.
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and
Wen-tau Yih. 2020. Dense passage retrieval for open-
domain question answering. In Proceedings of the
2020 Conference on Empirical Methods in Natural
Language Processing (EMNLP) , pages 6769–6781.
Jungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi,
Ronan Le Bras, Akari Asai, Xinyan Yu, Dragomir
Radev, Noah A Smith, Yejin Choi, and Kentaro Inui.
2023. Realtime qa: What’s the answer right now?
Advances in Neural Information Processing Systems .
Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke
Zettlemoyer, and Mike Lewis. 2020. Generalization
through memorization: Nearest neighbor language
models. In International Conference on Learning
Representations .
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-
taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-
guage models are zero-shot reasoners. arXiv preprint
arXiv:2205.11916 .
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-
field, Michael Collins, Ankur Parikh, Chris Alberti,
Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-
ton Lee, et al. 2019. Natural questions: A benchmark
for question answering research. TACL , pages 452–
466.
Angeliki Lazaridou, Elena Gribovskaya, Wojciech
Stokowiec, and Nikolai Grigorev. 2022. Internet-
augmented language models through few-shot
prompting for open-domain question answering.
arXiv preprint arXiv:2203.05115 .
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio
Petroni, Vladimir Karpukhin, Naman Goyal, Hein-
rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-
täschel, et al. 2020. Retrieval-augmented generation
for knowledge-intensive nlp tasks. Advances in Neu-
ral Information Processing Systems , 33:9459–9474.

--- PAGE 10 ---
Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xiaomo Liu,
and Sameena Shah. 2023. Are chatgpt and gpt-
4 general-purpose solvers for financial text analyt-
ics? an examination on several typical tasks. arXiv
preprint arXiv:2305.05862 .
Hongyin Luo, Yung-Sung Chuang, Yuan Gong, Tian-
hua Zhang, Yoon Kim, Xixin Wu, Danny Fox, He-
len Meng, and James Glass. 2023. Sail: Search-
augmented instruction learning. arXiv preprint
arXiv:2305.15225 .
Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Ryan
McDonald. 2021. Zero-shot neural passage retrieval
via domain-targeted synthetic question generation.
InProceedings of the 16th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics: Main Volume , pages 1075–1088.
Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric
Nyberg, and Jianfeng Gao. 2023. Chain-of-skills:
A configurable model for open-domain question an-
swering. Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistic .
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,
Daniel Khashabi, and Hannaneh Hajishirzi. 2023.
When not to trust language models: Investigating
effectiveness of parametric and non-parametric mem-
ories. In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 9802–9822.
OpenAI. 2023. Gpt-4 technical report. arXiv preprint
arXiv:2303.08774 .
Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao
Chen, Michihiro Yasunaga, and Diyi Yang. 2023. Is
chatgpt a general-purpose natural language process-
ing task solver? arXiv preprint arXiv:2302.06476 .
Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang
Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, and
Haifeng Wang. 2021. Rocketqa: An optimized train-
ing approach to dense passage retrieval for open-
domain question answering. In Proceedings of the
2021 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies , pages 5835–5847.
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and
Yuxiong He. 2020. Deepspeed: System optimiza-
tions enable training deep learning models with over
100 billion parameters. In Proceedings of the 26th
ACM SIGKDD International Conference on Knowl-
edge Discovery & Data Mining , pages 3505–3506.
Devendra Singh Sachan, Mike Lewis, Dani Yogatama,
Luke Zettlemoyer, Joelle Pineau, and Manzil Zaheer.
2022. Questions are all you need to train a dense
passage retriever. arXiv preprint arXiv:2206.10658 .
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan
Scales, David Dohan, Ed H Chi, Nathanael Schärli,
and Denny Zhou. 2023a. Large language modelscan be easily distracted by irrelevant context. In In-
ternational Conference on Machine Learning , pages
31210–31227. PMLR.
Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang,
Suraj Srivats, Soroush V osoughi, Hyung Won Chung,
Yi Tay, Sebastian Ruder, Denny Zhou, et al. 2023b.
Language models are multilingual chain-of-thought
reasoners. In The Eleventh International Conference
on Learning Representations .
Weijia Shi, Sewon Min, Michihiro Yasunaga, Min-
joon Seo, Rich James, Mike Lewis, Luke Zettle-
moyer, and Wen-tau Yih. 2023c. Replug: Retrieval-
augmented black-box language models. arXiv
preprint arXiv:2301.12652 .
Devendra Singh, Siva Reddy, Will Hamilton, Chris
Dyer, and Dani Yogatama. 2021. End-to-end train-
ing of multi-document reader and retriever for open-
domain question answering. Advances in Neural
Information Processing Systems , 34:25968–25981.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, et al. 2023. Llama 2: Open founda-
tion and fine-tuned chat models. arXiv preprint
arXiv:2307.09288 .
Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,
and Ashish Sabharwal. 2023. Interleaving retrieval
with chain-of-thought reasoning for knowledge-
intensive multi-step questions. Proceedings of the
61st Annual Meeting of the Association for Computa-
tional Linguistics .
Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry
Wei, Jason Wei, Chris Tar, Yun-Hsuan Sung, Denny
Zhou, Quoc Le, et al. 2023. Freshllms: Refreshing
large language models with search engine augmenta-
tion. arXiv preprint arXiv:2310.03214 .
Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, and
Ming Gao. 2023a. Boosting language models rea-
soning with chain-of-knowledge prompting. arXiv
preprint arXiv:2306.06427 .
Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang
Li, Yunsen Xian, Chuantao Yin, Wenge Rong, and
Zhang Xiong. 2023b. Knowledge-driven cot: Ex-
ploring faithful reasoning in llms for knowledge-
intensive question answering. arXiv preprint
arXiv:2308.13259 .
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.
Chain of thought prompting elicits reasoning in large
language models. arXiv preprint arXiv:2201.11903 .
Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan
Berant. 2023. Making retrieval-augmented language
models robust to irrelevant context. arXiv preprint
arXiv:2310.01558 .

--- PAGE 11 ---
Donghan Yu, Chenguang Zhu, Yuwei Fang, Wenhao
Yu, Shuohang Wang, Yichong Xu, Xiang Ren, Yim-
ing Yang, and Michael Zeng. 2022. Kg-fid: Infus-
ing knowledge graph in fusion-in-decoder for open-
domain question answering. In Proceedings of the
60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers) , pages
4961–4974.
Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu,
Mingxuan Ju, Soumya Sanyal, Chenguang Zhu,
Michael Zeng, and Meng Jiang. 2023a. Generate
rather than retrieve: Large language models are
strong context generators. International Conference
for Learning Representation (ICLR) .
Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng
Jiang, and Ashish Sabharwal. 2023b. Improving lan-
guage models via plug-and-play retrieval feedback.
arXiv preprint arXiv:2305.14002 .
Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,
Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,
Yulong Chen, et al. 2023a. Siren’s song in the ai
ocean: A survey on hallucination in large language
models. arXiv preprint arXiv:2309.01219 .
Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao,
George Karypis, and Alex Smola. 2023b. Multi-
modal chain-of-thought reasoning in language mod-
els.arXiv preprint arXiv:2302.00923 .
Zexuan Zhong, Tao Lei, and Danqi Chen. 2022. Train-
ing language models with memory augmentation.
InProceedings of the 2022 Conference on Empir-
ical Methods in Natural Language Processing , pages
5657–5673.
Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming
Zheng, Soujanya Poria, and Tat-Seng Chua. 2021.
Retrieving and reading: A comprehensive survey on
open-domain question answering. arXiv preprint
arXiv:2101.00774 .

--- PAGE 12 ---
A Appendix
A.1 More Related Work
A.1.1 Retrieval-Augmented Language Models
Retrieval-Augmented Language Models (RALMs)
represent a significant advancement in natural lan-
guage processing, combining the power of large
language models with the specificity and detail pro-
vided by external knowledge sources (Guu et al.,
2020; Lewis et al., 2020; Izacard et al., 2022).
These models first leverage a retriever to scan a
vast evidence corpus, such as Wikipedia, to iden-
tify a set of documents pertinent to the user’s query.
Following this, a reader component is employed
to meticulously analyze these documents and for-
mulate a response. This two-pronged approach
ensures both relevance and depth in the generated
answers. Recent follow-up work has mainly fo-
cused on improving the retriever (Karpukhin et al.,
2020; Qu et al., 2021; Sachan et al., 2022; Ma
et al., 2023) or the reader (Izacard and Grave, 2021;
Cheng et al., 2021; Yu et al., 2022), training the
system end-to-end (Lewis et al., 2020; Singh et al.,
2021), and integrating the retrieval systems with
large-scale black-box language models (Yu et al.,
2023a; Shi et al., 2023c; Yu et al., 2023b; Trivedi
et al., 2023). Another line of RALMs such as kNN-
LM (Khandelwal et al., 2020; Zhong et al., 2022)
retrieves a set of tokens and interpolates between
the next token distribution and kNN distributions
computed from the retrieved tokens at inference.
The evolution has also led to the emergence and
popularity of retrieval-augmented products, such
as ChatGPT plugin, Langchain, and New Bing.
A.2 Chain-of-X Approaches in Large
Language Models
Recent research shows that large language models
(LLMs) are capable of decomposing complex prob-
lems into a series of intermediate steps, pioneered
by the concept of Chain-of-Thought (CoT) prompt-
ing (Wei et al., 2022; Kojima et al., 2022). The CoT
approach mirrors human problem-solving methods,
where complex issues are broken down into smaller
components. By doing so, LLMs can tackle each
segment of a problem with focused attention, re-
ducing the likelihood of overlooking critical details
or making erroneous assumptions. This sequen-
tial breakdown makes the reasoning process more
transparent, allowing for easier identification and
correction of any logical missteps.The CoT methodology has been effectively ap-
plied in various contexts, including multi-modal
reasoning (Zhang et al., 2023b), multi-lingual sce-
narios (Shi et al., 2023b), and knowledge-driven
applications (Wang et al., 2023b). And addi-
tionally, there has been a surge in the develop-
ment of other chain-of-X methods, addressing di-
verse challenges in LLM applications. These in-
clude chain-of-explanation (Huang et al., 2023),
chain-of-knowledge (Wang et al., 2023a), chain-of-
verification (Dhuliawala et al., 2023) and IR chain-
of-thought (Trivedi et al., 2023). For instance,
Chain-of-Verification (Dhuliawala et al., 2023) gen-
erates an initial response, formulates verification
questions, and revises the response based on these
questions, reducing factual errors and hallucina-
tions in the response. Closely related to our work
is IR chain-of-thought (Trivedi et al., 2023), which
employs CoT to infer and supplement unretrieved
information, thereby improving the accuracy of
complex reasoning tasks. While chain-of- Xap-
proaches have shown promise in enhancing LLMs’
performance across various domains, their applica-
tion in RALMs, particularly for improving robust-
ness in noisy and unknown scenarios, is relatively
unexplored. This gap signifies further research
in applying these strategies to augment RALMs,
thereby enhancing their robustness and reliability.
A.3 Dataset Information
– TriviaQA (Joshi et al., 2017) contains a set of
trivia questions with answers originally scraped
from trivia and quiz-league websites.
– WebQ (Berant et al., 2013) consists of questions
selected using Google Suggest API, where the an-
swers are entities in Freebase.
– NQ (Kwiatkowski et al., 2019) were collected
from real Google search queries and the answers
are one or multiple spans in Wikipedia articles iden-
tified by human annotators.
A.4 Implementation Details
In the retrieval phase, we employed
DPR (Karpukhin et al., 2020) to retrieve
documents from Wikipedia. We accessed the
model via direct loading from the official DPR
repository hosted on GitHub. Subsequent to
retrieval, our fine-tuning process for the LLaMA-
2 (Touvron et al., 2023) model runs for 3 epochs
with a batch size set to 128, leveraging the
DeepSpeed library (Rasley et al., 2020) and
the ZeRO optimizer (Ma et al., 2021), with

--- PAGE 13 ---
bfloat16 precision. The learning rates are set to
{1e-6,2e-6,5e-6,1e-5,2e-5}, and the empirical
results indicated that 5e-6yielded the best model
performance, hence we standardized the learning
rate for all reported numbers. Greedy decoding
is applied during inference on all experiments to
ensure deterministic generations.
A.5 Instruction Prompts
(1) For standard RALM, the instruction is:
Task Description: The primary objective is to
briefly answer the question.
(2) For RALM with C OT, the instruction is:
Task Description: Think step by step to answer the
question.
(3) For RALM with C ON, the instruction is:
Task Description:
1. Read the given question and five Wikipedia
passages to gather relevant information.
2. Write reading notes summarizing the key points
from these passages.
3. Discuss the relevance of the given question and
Wikipedia passages.
4. If some passages are relevant to the given
question, provide a brief answer based on the
passages.
5. If no passage is relevant, direcly provide answer
without considering the passages.
A.6 Case Studies
In our case studies, as illustrated in Table 6, we
compare the responses generated by the standard
RALM and our enhanced RALM with COT. These
examples highlight the differences in how each
model processes and interprets information from
retrieved documents.
The first case shows a question pertains to the
most recent Summer Olympics held in the USA.
The standard RALM is misled by the mention of
"Chicago’s bid for the 2016 Summer Olympics."
Lacking a deep comprehension of the content, it
incorrectly focuses on the more recent year (2016),
resulting in an inaccurate answer. In contrast, the
RALM with CONcarefully analyzes the informa-
tion. It notes that while Chicago bid for the 2016
Olympics, there’s no confirmation of it being a suc-
cessful bid. This leads to the correct conclusion
that the most recent Olympics in the USA wereheld in 1996. The second case study involves iden-
tifying the language of the first Jnanpith Award
recipient. Here, the standard RALM fails to syn-
thesize information across documents. It identifies
G. Sankara Kurup as the award recipient but does
not connect this information to the language of his
work. Conversely, the RALM with CONeffec-
tively combines details from both documents. It
recognizes that while the first document mentions
Kurup’s award, the second document provides the
missing language detail, leading to the correct an-
swer of Malayalam.
A.7 Licenses
The four open-domain QA benchmarks, LLaMa-2
models are all released under MIT License. They
are all for research purposes, and our experiments
are consistent with their intended usage.

--- PAGE 14 ---
Question: When was the last Summer Olympics in the USA Answer: 1996
Wikipedia document #1: In Chicago’s 2016 Summer Olympics bid, the games would have been held from
July 22 to August 7, with the Paralympics held between August 12 and 28. The plan emphasized use of
Chicago Park District ... (Wikipedia page: Chicago bid for the 2016 Summer Olympics)
Wikipedia document #2: The 1996 Olympics are the most recent edition of the Summer Olympics to be
held in the United States. Los Angeles will host the 2028 Summer Olympics, 32 years after the games were
held in Atlanta. ... (Wikipedia page: 1996 Summer Olympics)
(Other retrieved Wikipedia documents are omitted.)
Standard RALM: 2016✘
RALM with CHAIN -OF-NOTE:Wikipedia passage #1 discusses Chicago’s bid for the 2016 Summer
Olympics, but does not mention whether it is a successful bid. Wikipedia passage #2 confirms that the 1996
Summer Olympics were the most recent edition of the Summer Olympics to be held in the United States.
Based on the information given in above passages, the answer is 1996 ✔
Question: The first Jnanpith Award recipient was an author in which language? Answer: Malayalam
Wikipedia document #1: The first Jnanpith Award was given to G. Sankara Kurup in 1965 for his collection
of poems, Odakkuzhal ( ¨The Bamboo Flute ¨), ... (Wikipedia page: Jnanpith Award)
Wikipedia document #2: ... The final round had four authors; Kazi Nazrul Islam (Bengali), D. V . Gundappa
(Kannada), Viswanatha Satyanarayana (Telugu), and G. Sankara Kurup (Malayalam). On 19 November 1966,
Kurup presented with... (Wikipedia page: Jnanpith Award)
(Other retrieved Wikipedia documents are omitted.)
Standard RALM: G. Sankara Kurup ✘
RALM with CHAIN -OF-NOTE:Wikipedia passage #1 states that the first Jnanpith Award was given to G.
Sankara Kurup in 1965 for his collection of poems, Odakkuzhal. Wikipedia passage #2 mentions that the
Jnanpith Award was given to G. Sankara Kurup in 1966 for his work in Malayalam. Based on the information
given in above passages, the answer is Malayalam ✔
Table 6: Case Study. Compared to Standard RALM, our RALM with CHAIN -OF-NOTEexhibits a deeper understand-
ing of how documents reveal information relevant to the question. It goes beyond merely capturing surface-level
terms, leading to more accurate responses.

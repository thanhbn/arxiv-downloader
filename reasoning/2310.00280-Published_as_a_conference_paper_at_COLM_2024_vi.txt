# 2310.00280.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/reasoning/2310.00280.pdf
# Kích thước tệp: 1513502 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024
Corex: Mở rộng ranh giới của suy luận phức tạp
thông qua hợp tác đa mô hình
Qiushi Sun♢♡∗Zhangyue Yin♣Xiang Li♠Zhiyong Wu♢†Xipeng Qiu♣Lingpeng Kong♡
♢Phòng thí nghiệm AI Thượng Hải♡Đại học Hồng Kông
♣Đại học Fudan♠Đại học Sư phạm Hoa Đông
qiushisun@connect.hku.hk ,yinzy21@m.fudan.edu.cn ,xiangli@dase.ecnu.edu.cn
wuzhiyong@pjlab.org.cn ,xpqiu@fudan.edu.cn ,lpk@cs.hku.hk

Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) đang phát triển với tốc độ chưa từng có và đã thể hiện khả năng đáng kể trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) với kiến thức thế giới. Nhờ vào các kho dữ liệu huấn luyện quy mô cực lớn, một LLM duy nhất có thể quản lý các tác vụ NLP điển hình một cách thành thạo. Tuy nhiên, hiệu suất của nó trong việc thực hiện các tác vụ phức tạp vẫn bị giới hạn bởi những hạn chế của biểu diễn nội bộ. Để vượt qua ranh giới này, chúng tôi giới thiệu Corex, một bộ các chiến lược tổng quát mới biến đổi LLM thành các tác nhân tự trị, tiên phong trong việc hợp tác đa mô hình để giải quyết tác vụ. Được lấy cảm hứng từ hành vi con người, Corex bao gồm các chế độ hợp tác đa dạng bao gồm Thảo luận, Đánh giá và Truy xuất, cùng nhau hướng tới việc nâng cao quá trình suy luận. Những mô hình này thúc đẩy các phương pháp tiếp cận độc lập với tác vụ cho phép các tác nhân dựa trên LLM "suy nghĩ ngoài khuôn khổ", từ đó vượt qua các lỗi thường gặp và cung cấp giải pháp tốt hơn. Thông qua các thí nghiệm rộng rãi trên bốn loại tác vụ suy luận khác nhau, chúng tôi chứng minh rằng việc điều phối nhiều tác nhân dựa trên LLM hoạt động cùng nhau mang lại kết quả tốt hơn so với các đường cơ sở hiện có đã được thiết lập tốt. Phân tích sâu hơn tiết lộ những ưu điểm của Corex so với các phương pháp đa mô hình khác, sự hiệp đồng được tạo ra giữa các LLM khác nhau và hiệu quả trên nhiều khía cạnh khác nhau. Mã nguồn và dữ liệu có sẵn tại https://github.com/QiushiSun/Corex.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) đã thành công trong việc thúc đẩy trạng thái nghệ thuật cho một loạt các tác vụ xử lý ngôn ngữ tự nhiên (NLP) (Brown và cộng sự, 2020; Chowdhery và cộng sự, 2022; OpenAI, 2023; Touvron và cộng sự, 2023; Zhao và cộng sự, 2023a, v.v.). Nghiên cứu gần đây (Wei và cộng sự, 2022a) chỉ ra rằng việc mở rộng quy mô mô hình (Kaplan và cộng sự, 2020) có thể mang lại cải thiện cả về hiệu suất và hiệu quả mẫu trên một phổ rộng các tác vụ hạ nguồn. Bất chấp khả năng đáng chú ý trong hiểu ngôn ngữ và tuân theo hướng dẫn (Ouyang và cộng sự, 2022), khả năng suy luận của LLM, thường được xem như một dấu hiệu để đánh giá tiềm năng của chúng, vẫn đưa ra những thách thức (Suzgun và cộng sự, 2023; Huang & Chang, 2023). Đồng thời, có một quan điểm phổ biến rằng việc chỉ tăng kích thước có thể không đủ để giải quyết những hạn chế vốn có của chúng trong việc giải quyết các tác vụ suy luận (Rae và cộng sự, 2022).

Để đáp ứng thách thức này, Wei và cộng sự (2022b) đưa ra lời nhắc chuỗi suy nghĩ (CoT) mà một LLM tạo ra một loạt các bước trung gian hướng tới câu trả lời cuối cùng, trái ngược với việc sử dụng lời nhắc "chỉ trả lời". Sau đó, nhiều phương pháp khác nhau đã được đưa ra, như giải mã tự nhất quán (Wang và cộng sự, 2023d) sử dụng cơ chế bỏ phiếu đa số để xác định câu trả lời cuối cùng, và các mô hình ngôn ngữ hỗ trợ chương trình (PAL; Gao và cộng sự, 2022; Chen và cộng sự, 2022a) tận dụng việc tạo mã để giảm lỗi trong

∗Công việc được thực hiện trong thời gian thực tập tại Phòng thí nghiệm AI Thượng Hải.
†Tác giả liên hệ.
1arXiv:2310.00280v3 [cs.AI] 21 Aug 2024

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Câu hỏi: Có 700 con ong trong một tổ. Có gấp đôi số ong thợ so với ong con, và có gấp đôi số ong con so với ong chúa. Có bao nhiêu ong thợ?

Câu trả lời đúng: 400
Theo vấn đề, tổng số tất cả những con ong này là 700.
Cộng chúng lại: x (ong chúa) + 2x (ong con) + 4x (ong thợ) = 700. Kết hợp các hạng tử tương tự, ta được 7x = 700. Từ đây, ta suy ra x = 90.
Điều này có nghĩa là có 90 ong chúa, 180 ong con và 360 ong thợ.
Kết luận, số ong thợ là 360.
Vậy, câu trả lời là 360.

Dựa trên thông tin đã cho, tổng số những con ong này là 700. Giả sử số ong chúa được biểu thị bằng x.
Vậy ong thợ sẽ là 2/x hoặc 2x.
x + x/2 + 2x = 700. Điều này đơn giản hóa thành 5x/2 = 700, Từ đó ta có x = 280.
Điều này có nghĩa là có 280 ong con, 140 ong chúa và 560 ong thợ.
Vậy, câu trả lời là 560.

# Mã Python
def solution():
    # Lặp qua các số lượng ong chúa có thể
    for x in range(1, 700):
        if x + x + 2 + x + 4 == 700:
            return 2*2*x  # Trả về số lượng ong thợ

Mã không thể phản ánh chính xác vấn đề được đặt ra.
>>> Trình thông dịch Python >>> None
Hiểu sai mối quan hệ giữa các biến.
Tính toán sai.

Hình 1: Mô tả ba lỗi phổ biến được quan sát trên các LLM khi sử dụng CoT và PAL để thực hiện các tác vụ suy luận.

Đánh giá    Truy xuất
Thảo luận

Hình 2: Minh họa trực quan của Corex, sử dụng các tác nhân dựa trên LLM để giải quyết vấn đề một cách hợp tác. Các chiến lược bao gồm chế độ Thảo luận, Đánh giá và Truy xuất, tận dụng cả quá trình suy luận và tổng hợp mã. Các số đại diện cho thứ tự của quá trình.

tính toán. Bên cạnh đó, các lời nhắc được tuyển chọn đòi hỏi thiết kế cụ thể cho từng tác vụ (Zheng và cộng sự, 2023a) cũng đã được sử dụng để kích thích dự đoán chính xác hơn. Tuy nhiên, những phương pháp này bị giới hạn trong một hộp đen tĩnh (Yao và cộng sự, 2023b), trong đó LLM chỉ dựa vào biểu diễn nội bộ của nó để tạo ra phản hồi và dễ tạo ra câu trả lời không đáng tin cậy (Ji và cộng sự, 2023; Yin và cộng sự, 2023b). Những thiếu sót này nhấn mạnh rằng việc chỉ dựa vào việc tạo ra các chiến lược giải mã và lời nhắc chuyên biệt có thể không phải là giải pháp vạn năng để giải quyết các tác vụ suy luận phức tạp (Qiao và cộng sự, 2023). Hơn nữa, các nghiên cứu gần đây (Huang và cộng sự, 2023; Valmeekam và cộng sự, 2023; Stechly và cộng sự, 2023) tiết lộ rằng LLM gặp khó khăn trong việc đạt được phản hồi tốt hơn thông qua tự sửa lỗi (Madaan và cộng sự, 2023). Thay vào đó, việc biến đổi LLM thành các tác nhân tự trị và cho phép chúng "suy nghĩ ngoài khuôn khổ" nổi lên như một con đường đầy hứa hẹn nhưng chưa được khám phá đầy đủ.

Trong lĩnh vực các khái niệm xã hội học đã được thiết lập tốt, nhiều quá trình nhận thức tương tác và hợp tác sẽ tạo ra hiệu ứng kết hợp lớn hơn tổng đóng góp cá nhân của chúng (Luppi và cộng sự, 2022). Nguyên tắc này được phản ánh trong trí tuệ nhân tạo (Li và cộng sự, 2023a). Mặc dù nghiên cứu về các tác nhân thông minh đã được khám phá trong nhiều thập kỷ (Minsky, 1988; 2007), sự xuất hiện của LLM đã làm hồi sinh sự quan tâm đến việc xây dựng các tác nhân ngôn ngữ (Sumers và cộng sự, 2024) và đưa ra nhiều thách thức hơn. Một quan điểm mới nổi là việc khuyến khích hợp tác và giao tiếp giữa các mô hình có thể mở đường cho một giai đoạn mới để nâng cao khả năng suy luận phức tạp.

Trong nghiên cứu này, chúng tôi đề xuất Corex, một bộ các chiến lược lấy cảm hứng từ con người tận dụng hợp tác đa mô hình để gợi ra suy luận cho việc giải quyết tác vụ phức tạp. Để tạo điều kiện cho sự hiệp đồng giữa các mô hình, trước tiên chúng tôi gán các nhân cách riêng biệt cho các tác nhân dựa trên LLM khác nhau, sau đó thiết kế các mô hình hợp tác khác nhau. Phương pháp dựa trên trí tuệ tập thể này nhằm chinh phục các trở ngại phổ biến trong bối cảnh suy luận hiện tại, như được minh họa trong Hình 1. Nó cũng cố gắng giảm nhẹ các vấn đề thường gặp được quan sát trong các phương pháp dựa trên bỏ phiếu đa số, nơi các phản hồi chính xác có thể bị áp đảo bởi những phản hồi không chính xác và chi phí quá cao. Cụ thể, Corex cấu hình LLM như một nhóm các tác nhân tự trị, áp dụng các mô hình được hiển thị trong Hình 2 cho hợp tác đa mô hình: (1) Thảo luận, sử dụng các cuộc thảo luận nhóm giữa các mô hình để nâng cao hiệu quả tính factual và tính đa dạng của lý luận, từ đó giảm ngụy biện và ảo giác; (2) Đánh giá, cho phép các mô hình xem xét kỹ lưỡng các chuỗi suy luận hoặc mã được tổng hợp từ các đối tác để đảm bảo tính đúng đắn của nội dung được tạo ra, kết hợp với các cải tiến tiềm năng; (3) Truy xuất, nhằm cho phép mô hình xác định tùy chọn trung thực nhất từ một nhóm các chuỗi ứng viên bằng cách chấm điểm và xếp hạng, tạo điều kiện cho mức độ liên kết cao hơn với phản hồi cuối cùng. Cùng nhau, phân tích quan trọng của Thảo luận, tập trung vào độ tin cậy của Đánh giá và sự liên kết của Truy xuất với phản hồi trung thực - tạo ra một phương pháp toàn diện để giải quyết các tác vụ suy luận phức tạp khác nhau.

Chúng tôi tiến hành các thí nghiệm rộng rãi trên bốn loại tác vụ: suy luận toán học, suy luận biểu tượng, suy luận thường thức và suy luận bán cấu trúc. Kết quả minh họa rằng phương pháp của chúng tôi đạt được những cải thiện hiệu suất đáng kể so với các đường cơ sở mạnh trước đó. Hơn nữa, mỗi chế độ đặc biệt xuất sắc trong các loại tác vụ khác nhau, thể hiện thế mạnh cụ thể của nó. Khám phá sâu hơn tiết lộ ưu điểm của Corex so với các phương pháp đa mô hình hiện có và sự hiệp đồng có thể xảy ra giữa các chế độ/LLM backbone khác nhau. Ngoài ra, Corex giảm chi phí suy luận, đạt được hiệu quả chi phí đa mặt.

2 Các công trình liên quan

Lời nhắc Chuỗi Suy nghĩ kích thích suy luận LLM. Lời nhắc Chuỗi Suy nghĩ (CoT; Wei và cộng sự, 2022b), như một trong những khả năng được tôn vinh của LLM gần đây, là một bước đột phá then chốt để thực hiện suy luận đa bước phức tạp khi được cung cấp các ví dụ hạn chế. Các biến thể tiếp theo cho thấy rằng CoT có thể được cải thiện bằng cách thêm một số "cụm từ ma thuật" (Kojima và cộng sự, 2022), xây dựng minh họa tự động (Zhang và cộng sự, 2023a), suy luận trong các phương thức khác nhau (Zhang và cộng sự, 2023b; Yang và cộng sự, 2023; Yao và cộng sự, 2023c), và áp dụng các phương pháp mô-đun (Khot và cộng sự, 2023). Để tăng tính mạnh mẽ, các nhà nghiên cứu biến đổi vấn đề thành các chuỗi suy luận xen kẽ (Zhou và cộng sự, 2023; Lyu và cộng sự, 2023) hoặc áp dụng tổng hợp (Wang và cộng sự, 2022). Đáng chú ý, tự nhất quán (Wang và cộng sự, 2023d) chọn câu trả lời từ nhiều đường suy luận theo tần suất, đã nâng cao đáng kể hiệu suất trong suy luận phức tạp. Phương pháp này đã được tối ưu hóa thêm bằng cách sử dụng các lời nhắc có độ phức tạp cao hơn (Fu và cộng sự, 2023c). Gần đây, Yao và cộng sự (2023a) sử dụng tìm kiếm có hướng dẫn heuristic trên "cây" được xây dựng từ các suy nghĩ để hỗ trợ LLM điều hướng không gian vấn đề. Sử dụng công cụ (Qin và cộng sự, 2023) đại diện cho một con đường khác để nâng cao suy luận, thường được sử dụng để giải quyết các vấn đề số. Các đại diện là Mô hình Ngôn ngữ hỗ trợ Chương trình (PAL; Gao và cộng sự, 2022) hoặc Chương trình Suy nghĩ (PoT; Chen và cộng sự, 2022a). Phương pháp như vậy sử dụng LLM để diễn giải các vấn đề NL, tạo ra các chương trình như các bước suy luận trung gian sẽ được chuyển giao cho trình thông dịch Python để thực thi nhằm có được giải pháp cuối cùng (Ni và cộng sự, 2023).

Sự hiệp đồng đa mô hình để giải quyết tác vụ. Việc sử dụng nhiều LLM cùng nhau để giải quyết vấn đề vẫn đang trong giai đoạn sơ khai. Nền tảng của hợp tác là xây dựng kiến trúc suy luận giống con người (Zhu và cộng sự, 2023) cho LLM dưới các môi trường khác nhau (Liu và cộng sự, 2023). Fu và cộng sự (2023b) nghiên cứu liệu nhiều LLM có thể tự động nâng cao hiệu suất của chúng thông qua tương tác lẫn nhau. Du và cộng sự (2023) và Liang và cộng sự (2023) khám phá việc nâng cao tính factual của các tác vụ cụ thể, ví dụ như dịch thuật và suy luận số học, bằng cách tạo điều kiện "tranh luận" giữa nhiều mô hình. Hợp tác của LLM cũng đã được áp dụng vào phát triển phần mềm (Qian và cộng sự, 2023) và đánh giá văn bản (Chan và cộng sự, 2023) bằng cách gán danh tính cho các mô hình để mô phỏng quá trình phát triển. Hơn nữa, từ góc độ trí tuệ xã hội, việc tạo ra sự hiệp đồng nhận thức và để chúng đảm nhận các nhân vật khác nhau (Wang và cộng sự, 2023e) trong quá trình thực hiện tác vụ đã được chứng minh có tiềm năng đáng kể (Sclar và cộng sự, 2023). Các khám phá gần đây về xã hội nhân tạo (Park và cộng sự, 2023) nhằm tận dụng trí tuệ tập thể để mô phỏng hiệu quả của cấu trúc xã hội con người (Li và cộng sự, 2023a; Webb và cộng sự, 2023). Gần đây hơn, Yin và cộng sự (2023a) đã đề xuất trao đổi chéo mô hình dựa trên cấu trúc tô-pô mạng.

3 Corex

Chúng tôi đề xuất Corex, một bộ các phương pháp suy luận hợp tác lấy cảm hứng từ tương tác xã hội con người. Ba thành phần chính: chế độ Thảo luận, Đánh giá và Truy xuất được giới thiệu trong các phần tiếp theo. Hãy giả sử một tập hợp các tác nhân dựa trên LLM {A1,A2,. . .,An} tham gia vào hợp tác đa mô hình. Mỗi tác nhân Ai tạo ra chuỗi suy luận tương ứng ci và dự đoán pi khi đối mặt với truy vấn q.

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

3.1 Thảo luận

Trao đổi thông tin giữa các mô hình góp phần nâng cao tính factual (Wang và cộng sự, 2023a). Trong chế độ Thảo luận, các tác nhân dựa trên LLM của chúng tôi được chia ngẫu nhiên thành hai nhóm, Đội Xanh dương và Đội Xanh lá, với một tác nhân được dành riêng làm thẩm phán ký hiệu là Aj. Cuộc thảo luận trong một nhóm bao gồm nhiều vòng, giới hạn tối đa T vòng giao tiếp. Trong mỗi vòng t (t=1, 2,. . .,T), các tác nhân tham gia vào các cuộc thảo luận lặp đi lặp lại¹ để tinh chỉnh chuỗi suy luận và dự đoán của họ. Tương tác động này cho phép sửa đổi liên tục quan điểm cho q, như được thể hiện bởi ct_i và dự đoán pt_i.

Mỗi nhóm sau đó trình bày dự đoán được tinh chỉnh pt_blue và pt_green vào cuối mỗi vòng. Nếu cả hai nhóm nhất quán đồng ý trong suốt các tương tác, tức pt_blue=pt_green, cuộc thảo luận kết thúc thuận lợi. Tuy nhiên, trong trường hợp có sự khác biệt giữa dự đoán của các nhóm, mọi đầu ra từ mỗi vòng được trình bày cho Aj. Thẩm phán sử dụng quá trình ra quyết định h để đánh giá chất lượng của chuỗi suy luận và dự đoán từ mỗi vòng thảo luận. Kết luận được xác định bởi h(ct_blue,pt_blue,ct_green,pt_green) trên tất cả các vòng, đảm bảo đánh giá toàn diện và quyết định cuối cùng có thông tin hơn.

Câu hỏi: Vincent mua 10 cuốn sách về động vật, 1 cuốn sách về vũ trụ và 3 cuốn sách về tàu hỏa. Mỗi cuốn sách có giá $16. Vincent đã chi bao nhiêu tiền cho những cuốn sách?

Tác nhân 3: 224
Tác nhân 4: 224
Tác nhân 1: 224
Tác nhân 2: 164

Tác nhân 3: 224
Tác nhân 4: 224
Tác nhân 1: 224
Tác nhân 2: 224

Tác nhân 5 (Thẩm phán)
Câu trả lời: 224
Câu trả lời: 224
V1    V2

Hình 3: Minh họa 2 vòng thảo luận, bỏ qua lý luận.

Khác với các công trình trước đây (Du và cộng sự, 2023; Liang và cộng sự, 2023; Xiong và cộng sự, 2023) sử dụng "tranh luận" giữa LLM, phương pháp của chúng tôi áp dụng khái niệm thảo luận nhóm. Chúng tôi chọn không tạo điều kiện cho các mô hình trao đổi cùng nhau quy trình suy luận của họ để hội tụ về một câu trả lời chung duy nhất vì một số lý do: (1) Độ dài ngữ cảnh hạn chế cản trở khả năng giữ quy trình giao tiếp, (2) Một câu trả lời cuối cùng duy nhất không phải lúc nào cũng đúng, vì sự đồng thuận sai lầm hoặc thiên vị giữa các mô hình có thể xảy ra (Wang và cộng sự, 2023c), (3) Với khoảng cách hiệu suất giữa các LLM khác nhau, có nguy cơ những mô hình mạnh "độc quyền" các hợp tác, từ đó che khuất những hiểu biết từ những mô hình khác. Do đó, chúng tôi nhằm bảo tồn cả tính factual và tính đa dạng của suy nghĩ giữa các người chơi.

3.2 Đánh giá

Trong phạm vi suy luận, cả CoT và PAL đều là các phương pháp hiệu quả với điểm mạnh riêng biệt. Dựa trên ngôn ngữ tự nhiên, các phương pháp dựa trên CoT nổi bật về tính tổng quát và sự rõ ràng của giải thích. Ngược lại, được hỗ trợ bởi các chương trình, PAL đảm bảo độ chính xác tính toán (Zhao và cộng sự, 2023b). Tuy nhiên, cả hai đều thể hiện những nhược điểm do sự phụ thuộc vào biểu diễn nội bộ của LLM. Đối với CoT và các biến thể của nó, vấn đề có hai mặt: (1) Lỗi tích lũy, nơi sai lầm có xu hướng khuếch đại và lan truyền trong suốt chuỗi suy luận; và (2) Sự ổn định trong chất lượng văn bản không thể được cải thiện đáng kể thông qua lời nhắc (Xu và cộng sự, 2022; Li và cộng sự, 2023b). Thay vào đó, PAL đối mặt với những thách thức riêng: (1) LLM có thể hiểu sai câu hỏi, điều này vô tình dẫn đến các chương trình về mặt kỹ thuật đúng nhưng sai hướng; và (2) Mã được tạo ra không phải lúc nào cũng không có lỗi: LLM có thể viết mã có lỗi, chẳng hạn như tham chiếu các biến không xác định hoặc tham gia vào các hoạt động "Chia cho Không". Được lấy cảm hứng từ những nỗ lực gần đây về đánh giá ngang hàng của LLM (Zheng và cộng sự, 2023b) và các thực hành mã hóa hợp tác phổ biến trong kỹ thuật phần mềm, chúng tôi giới thiệu chế độ Đánh giá để giải quyết các vấn đề nêu trên thông qua hợp tác đa tác nhân. Cụ thể, một tác nhân Ap được chọn ngẫu nhiên để đóng vai trò là tác nhân chính. Ban đầu, Ap đảm nhận trách nhiệm xây dựng chuỗi suy luận tương ứng cho q cùng với dự đoán, và tạo mã nếu cần thiết. Bộ sưu tập giải pháp ban đầu này được biểu thị là S(0)_p={ap,cp,mp}, trong đó ap, cp và mp biểu thị câu trả lời, chuỗi suy luận và mã tương ứng. S(0)_p sau đó được đánh giá lặp đi lặp lại bởi các tác nhân khác hoạt động như người đánh giá theo thứ tự tuần tự,

¹ Do giới hạn độ dài ngữ cảnh của GPT-3.5-Turbo, chỉ thông tin từ vòng trước được lưu trữ trong cuộc thảo luận.

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

>>> Trình thông dịch Python >>> 95

Câu hỏi: Trong khi xây nhà, Charlie nhận thấy rằng họ sắp hết đinh nên anh ta nói với bố rằng anh ta sẽ đi mua. Nếu họ vẫn còn 9 cái đinh và Charlie mua 2 hộp đinh, hộp lớn chứa 55 cái đinh và hộp nhỏ chứa 31 cái, họ sẽ có bao nhiêu cái đinh?

Tác nhân 1:
# Mã Python bởi Tác nhân 1
def solution():
    current = 9
    big_box = 55
    small_box = 31
    total_nails = current + (2 * (big_box + small_box))
    return total

Tác nhân 2:
total_nails = current + (2 * (big_box + small_box)) là sai, hiện tại đang nhân đôi cả hộp lớn và hộp nhỏ đinh.
Điều này không đúng dựa trên phát biểu vấn đề.
Đây là mã đã sửa:
...total_nails = current + big_box + small_box...

Hình 4: Minh họa việc đánh giá mã được tạo bởi tác nhân khác (vòng 1).

xem xét kỹ lưỡng cả chuỗi suy luận và mã được xây dựng bởi Ap hoặc được sửa đổi bởi những người đánh giá trước đó. Điều quan trọng cần nhấn mạnh là mỗi người đánh giá nhận đầu vào từ những người tiền nhiệm, biểu thị rằng mỗi đánh giá tiếp theo được dựa trên kết quả và phản hồi của những người đi trước, thúc đẩy một giải pháp được tinh chỉnh dần. Quá trình đánh giá được hình thức hóa là S(i+1)_p = Ri(S(i)_p,Fi), trong đó Ri bao gồm kết quả đánh giá tại lần lặp thứ i và Fi đại diện cho phản hồi nhận được. Về bản chất, tập giải pháp S(i+1)_p là kết quả của việc cải tiến phiên bản trước đó S(i)_p, được thông báo bởi phản hồi Fi. Sau khi hoàn thành tất cả các lần lặp đánh giá, kết quả được xác định bởi lần lặp cuối cùng của tập giải pháp S(n-1)_p. Cụ thể, dự đoán cuối cùng a(n-1)_p được chọn làm câu trả lời cho q, và trong trường hợp có mã, phiên bản được sửa đổi cuối cùng m(n-1)_p được thực thi bởi trình thông dịch Python để tạo ra kết quả.

3.3 Truy xuất

Câu hỏi: Điều nào mô tả thành phần của carbohydrate?
(A) lipid liên kết để tạo thành phospholipid (B) monomer liên kết để tạo thành polymer (C) amino acid liên kết để tạo thành polypeptide (D) saccharide liên kết để tạo thành polysaccharide

Tác nhân 1: Thành phần của carbohydrate bao gồm saccharide liên kết để tạo thành polysaccharide. Vậy câu trả lời là (D).

Tác nhân 2: Thành phần của carbohydrate được mô tả bởi tùy chọn (C), amino liên kết để tạo thành polysaccharide. Vậy câu trả lời là (C).

Tác nhân 3: Câu trả lời đúng là (D) saccharide liên kết để tạo thành polysaccharide. Carbohydrate được cấu tạo từ monosaccharide có thể kết hợp với nhau thông qua quá trình gọi là tổng hợp khử nước để tạo thành polysaccharide lớn hơn. Vậy câu trả lời là (D).

Tác nhân 4: Tùy chọn (C), saccharide liên kết để tạo thành polypeptide, mô tả thành phần của carbohydrate. Vậy câu trả lời là (C).

Tác nhân 5 (Người truy xuất): Điểm tin cậy là: [0.9, 0.2, 0.9, 0.1]. Tác nhân 2,4 đã mắc lỗi trong mô tả của họ. Cụ thể, Tác nhân 2 nhầm lẫn amino acid với saccharide, trong khi Tác nhân 4 sai khi nói rằng saccharide liên kết để tạo thành polypeptide. Trong thực tế, saccharide liên kết để tạo thành polysaccharide. Do đó, họ không trung thực trong phản hồi của mình. Tác nhân 1 và 3 đúng.

Hình 5: Minh họa việc truy xuất chuỗi suy luận với câu trả lời của chúng.

Trong luồng công việc cuối cùng, chúng tôi đi sâu vào chế độ Truy xuất để xác định câu trả lời trung thực nhất thông qua hợp tác. Trong khi các chiến lược trước đây dựa trên cơ chế bỏ phiếu đa số (Wang và cộng sự, 2023d; Fu và cộng sự, 2023c) có thể giảm thiểu vấn đề đa dạng thấp của các kỹ thuật như tìm kiếm chùm (Li & Jurafsky, 2016), chúng vẫn đưa ra hai thách thức đáng kể sau:

(1) Câu trả lời đúng có nguy cơ bị ảnh hưởng bởi những câu sai. (2) Mặc dù tạo điều kiện cho việc nâng cao hiệu suất đáng chú ý, nó tăng gánh nặng tính toán theo cấp số nhân và có xu hướng đạt "điểm bão hòa hiệu suất" khi các chuỗi được lấy mẫu tăng lên. Chúng tôi cho rằng những nhược điểm này xuất phát từ phạm vi hạn chế của các kỹ thuật bỏ phiếu đa số chỉ ưu tiên dự đoán đơn lẻ trong khi bỏ qua tính trung thực của chuỗi suy luận (Li và cộng sự, 2023c). Để đáp ứng, chúng tôi đề xuất chế độ Truy xuất, một mô hình được thiết kế đặc biệt để đánh giá liệu câu trả lời có thể được thể hiện bởi nội dung (giải thích) được tạo ra trong quá trình suy luận (Jacovi & Goldberg, 2020; Lanham và cộng sự, 2023).

Cụ thể, với truy vấn q, chúng tôi chọn ngẫu nhiên một tác nhân Ar từ nhóm n tác nhân để đóng vai trò là người truy xuất. Các tác nhân còn lại {A1,A2,. . .,An-1} độc lập giải quyết q. Mỗi tác nhân này suy ra chuỗi suy luận riêng ci và dự đoán tương ứng pi. Cùng nhau, chúng tạo thành một nhóm ứng viên, ký hiệu là P={(ci,pi)}n-1_i=1.

Người truy xuất Ar sau đó xem xét kỹ lưỡng các ứng viên trong P. Đối với (ci,pi), Ar đánh giá tính trung thực giữa ci và pi. Dựa trên đánh giá này, người truy xuất gán điểm tin cậy si trong khoảng [0, 1], được ký hiệu là: si=fr(ci,pi) trong đó fr biểu thị quá trình đánh giá của người truy xuất. Sau đó, phản hồi trung thực nhất cho câu hỏi q được xác định bởi độ tin cậy cao nhất: (c*,p*)=argmax(ci,pi)∈P si. Ở đây, (c*,p*) biểu thị cặp chuỗi-dự đoán mà người truy xuất coi là trung thực nhất, sẽ phục vụ làm câu trả lời cuối cùng cho truy vấn q.

Chế độ Truy xuất cho phép lựa chọn sự kết hợp liên kết nhất của chuỗi suy luận và câu trả lời từ một nhóm ứng viên đa dạng. Khác với các phương pháp đánh giá chất lượng văn bản trước đây, dựa vào xác suất log của chuỗi (Adiwardana và cộng sự, 2020) không hiệu quả về mặt tính toán và thường không có sẵn cho LLM thương mại, phương pháp của chúng tôi hoàn toàn dựa trên tương tác mô hình-với-mô hình (Chen và cộng sự, 2023b) và không cần tham chiếu.

4 Thí nghiệm

4.1 Thiết lập thí nghiệm

Tác vụ và Bộ dữ liệu. Chúng tôi đánh giá Corex trên bốn loại tác vụ: (1) Suy luận số học với các độ khó khác nhau, như GSM8K (Cobbe và cộng sự, 2021) và GSM-Hard (Gao và cộng sự, 2022). (2) Suy luận thường thức bao gồm bốn bộ dữ liệu, được minh họa bởi StrategyQA (Geva và cộng sự, 2021). (3) Suy luận biểu tượng kết hợp bốn tác vụ được lấy từ BigBench (bench authors, 2023). (4) Hiểu bán cấu trúc, như FinQA và ConvFinQA (Chen và cộng sự, 2021b; 2022b). Mô tả chi tiết và thống kê của các tác vụ được liệt kê trong Phụ lục E.

Đường cơ sở. Chúng tôi so sánh Corex với một số đường cơ sở mạnh được sử dụng rộng rãi. (1) Lời nhắc Chuỗi Suy nghĩ (CoT; Wei và cộng sự, 2022b). (2) Tự Nhất quán (CoT-SC; Wang và cộng sự, 2023d), sử dụng cơ chế bỏ phiếu đa số để chọn câu trả lời nhất quán nhất từ nhiều chuỗi suy luận làm câu trả lời cuối cùng. (3) Nhất quán dựa trên độ phức tạp (ComplexCoT; Fu và cộng sự, 2023c) chọn câu trả lời đa số từ các ứng viên có độ phức tạp suy luận cao hơn. (4) Mô hình ngôn ngữ hỗ trợ chương trình (PAL/PoT; Gao và cộng sự, 2022; Chen và cộng sự, 2022a) sử dụng LLM để tạo ra các chương trình như các bước suy luận trung gian, trong khi chuyển giao tính toán cho trình thông dịch Python. Để đơn giản, chúng tôi ký hiệu CoT-SC(x) và ComplexCoT(x) trong các thí nghiệm và phân tích để đại diện cho các trường hợp sử dụng các đường suy luận khác nhau, trong đó "x" biểu thị số lượng chuỗi đầu ra. Đối với tất cả đường cơ sở, chúng tôi tuân thủ các mẫu ít-shot để đảm bảo so sánh công bằng, chi tiết trong Phụ lục B.

Chi tiết Triển khai. Chúng tôi truy cập các mô hình OpenAI và Anthropic thông qua API tương ứng. Cụ thể, chúng tôi sử dụng GPT-3.5-Turbo-0613 để đánh giá cả phương pháp Corex và đường cơ sở trong các thí nghiệm chính. Hơn nữa, trong các thí nghiệm và phân tích tiếp theo liên quan đến các LLM khác nhau cho hợp tác, chúng tôi cũng kết hợp việc sử dụng GPT-4-0613, Claude-Instant-1.2 và LLaMA-2-Chat(7B/13B). Chi tiết về lời nhắc và cài đặt siêu tham số cho cả đường cơ sở và Corex được trình bày trong Phụ lục G.

4.2 Kết quả chính

Chúng tôi báo cáo kết quả của Corex trên 18 tác vụ thuộc bốn loại. Đối với mỗi loại tác vụ, kết quả tốt nhất được đánh dấu đậm và kết quả tốt thứ hai được đánh dấu gạch dưới. Đối với chế độ Đánh giá, chúng tôi sử dụng Corex-Review NL và Corex-Review Code để mô tả các tình huống sử dụng chuỗi suy luận NL hoặc mã như các bước trung gian, tương ứng. Tất cả các chế độ trong Corex được cấu hình để hoạt động với 5 tác nhân dựa trên LLM, đảm bảo hiệu quả chi phí thuận lợi. Đối với Corex-Discuss, giới hạn trên của các vòng thảo luận được đặt là 5.

Suy luận Toán học. Bảng 1 hiển thị kết quả trên các tác vụ số học với độ khó khác nhau. Phương pháp của chúng tôi đạt được cải thiện hiệu suất đáng chú ý trên hầu hết các benchmark.

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Bảng 1: So sánh độ chính xác trên bảy bộ dữ liệu suy luận toán học sử dụng các chế độ Corex khác nhau và đường cơ sở mạnh.

MultiArith SVAMP GSM8K SingleOP SingleEQ AddSub GSM-Hard Trung bình
CoT 98.5 78.9 74.5 94.1 93.3 87.8 39.0 80.9
ComplexCoT 97.3 80.7 79.7 94.3 92.3 86.8 39.7 81.5
CoT-SC(10) 99.8 84.5 82.8 95.4 95.1 89.6 45.2 84.6
PAL/PoT 96.7 83.4 76.0 90.7 95.8 87.6 62.1 84.6
Corex-Discuss 98.7 82.6 76.2 94.8 93.7 89.7 45.9 83.1
Corex-Review NL 99.5 83.2 80.3 95.0 94.3 89.4 50.8 84.6
Corex-Review Code 98.3 85.8 79.2 93.6 96.9 89.6 63.6 86.7
Corex-Retrieve 99.8 85.6 82.5 96.1 96.6 90.9 53.0 86.3

Nói chung, chúng tôi vượt qua hiệu suất của CoT-SC(10) khi chỉ có 5 tác nhân tham gia. Hơn nữa, với tính chất độc lập tác vụ của Corex, nó có thể giải quyết các thách thức tính toán rất phức tạp như GSM-Hard thông qua tổng hợp mã. Đối với các vấn đề có độ phức tạp tương đối thấp hơn, chế độ Truy xuất có thể xác định câu trả lời vượt trội so với bỏ phiếu đa số.

Suy luận Thường thức. Bảng 2 thể hiện hiệu suất của Corex trong các tác vụ suy luận thường thức và factual. Do bản chất của các tác vụ suy luận thường thức, không thể chuyển đổi thành các tác vụ tính toán, chế độ Đánh giá chỉ sử dụng chuỗi suy luận NL. Chúng ta có thể quan sát thấy rằng các chế độ khác nhau góp phần vào việc nâng cao hiệu suất.

Bảng 2: So sánh hiệu suất về suy luận thường thức & factual giữa các chế độ Corex khác nhau và đường cơ sở mạnh. Các trường hợp được đánh dấu "-" chỉ ra các tình huống không có triển khai chính thức.

StrategyQA CSQA OpenBookQA BoolQ ARC-c Trung bình
CoT 65.3 76.7 82.6 65.1 84.2 74.8
ComplexCoT 63.1 77.5 - - - -
CoT-SC(10) 67.1 78.1 85.2 66.6 85.7 76.5
Corex-Discuss 68.4 78.9 83.4 66.9 86.3 76.8
Corex-Review NL 66.9 77.4 84.8 66.9 86.0 76.4
Corex-Retrieve 69.3 77.7 87.6 68.0 85.5 77.6

Corex vượt qua ComplexCoT (hơn 6% trên StrategyQA), đạt được cải thiện đáng chú ý mà không cần đến thiết kế lời nhắc phức tạp và lựa chọn ví dụ. Hơn nữa, chế độ Thảo luận hoạt động đặc biệt tốt trên các tác vụ yêu cầu suy luận thường thức.

Suy luận Biểu tượng. Chúng tôi báo cáo kết quả cho suy luận biểu tượng trong Bảng 3. Bằng chứng thực nghiệm khẳng định rằng việc áp dụng hợp tác đa mô hình có thể vượt trội đáng kể so với hầu hết các đường cơ sở trước đây trên các tác vụ Big-Bench. Đáng chú ý rằng (1) CoT-SC gặp khó khăn để đảm bảo đầu ra nhất quán trên Repeat Copy. Ngược lại, thông qua việc tích hợp hợp tác dựa trên PAL, chúng tôi quản lý để đạt được mức độ chính xác cao đáng kể. (2) So với bỏ phiếu đa số, cả chế độ Đánh giá và Truy xuất đều cho phép lựa chọn câu trả lời khôn ngoan hơn trong các tác vụ đếm.

Bảng 3: So sánh độ chính xác trên năm bộ dữ liệu suy luận biểu tượng từ Big-Bench (bench authors, 2023; Suzgun và cộng sự, 2023) sử dụng các chế độ Corex khác nhau và đường cơ sở mạnh khác.

Penguin Date Colored Objects Repeat Copy Trung bình
CoT 81.5 82.0 88.0 43.8 73.8
CoT-SC(10) 86.2 87.9 94.8 53.1 80.5
PAL/PoT 91.3 81.2 86.8 93.8 88.3
Corex-Discuss 85.9 83.2 91.2 62.5 80.7
Corex-Review NL 92.0 84.0 92.4 59.4 82.0
Corex-Review Code 93.3 82.7 91.6 96.9 91.1
Corex-Retrieve 92.6 84.6 95.6 68.8 85.6

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Suy luận Bán cấu trúc. Chúng tôi trình bày kết quả trên FinQA và ConvFinQA trong Bảng 4. Có thể quan sát thấy rằng đối với hai tác vụ thách thức này yêu cầu hiểu thông tin không đồng nhất và thực hiện tính toán đồng thời (Lu và cộng sự, 2023), các phương pháp như CoT-SC mang lại lợi ích hạn chế. Tuy nhiên, thông qua các mô hình hợp tác khác nhau, có thể đạt được cải thiện hiệu suất đáng kể. Do hạn chế độ dài ngữ cảnh của GPT-3.5-Turbo, các thí nghiệm của chúng tôi trên TAT-QA sử dụng GPT-3.5-Turbo-16k, với kết quả tương ứng được chi tiết trong Phụ lục D.1, cùng với các đánh giá trên các tác vụ khác.

Bảng 4: So sánh Corex và đường cơ sở mạnh trên FinQA và ConvFinQA.

FinQA ConvFinQA Trung bình
CoT 46.1 50.4 48.3
CoT-SC(10) 52.7 57.2 54.9
PAL/PoT 54.3 50.8 52.9
Corex-Discuss 50.2 56.7 53.5
Corex-Review NL 52.5 52.3 52.4
Corex-Review Code 55.9 54.2 55.1
Corex-Retrieve 55.4 57.7 56.6

Theo các thí nghiệm rộng rãi của chúng tôi trên 18 tác vụ, thấy rằng chế độ Thảo luận có khả năng cho các tác vụ sử dụng kiến thức factual. Đối với các tác vụ toán học và đếm thách thức, chế độ Đánh giá phục vụ để giảm thiểu hiệu quả các lỗi trong chuỗi suy luận và sửa chữa mã có lỗi (phân tích sâu hơn về các loại lỗi được cung cấp trong Phụ lục D.4). Trên các tác vụ khác nhau, chế độ Truy xuất liên tục tạo điều kiện cho cải thiện hiệu suất ở các mức độ khác nhau trên các tác vụ tổng quát. Thêm thí nghiệm liên quan đến LLM mã nguồn mở (Touvron và cộng sự, 2023) được trình bày trong Phụ lục C.

5 So sánh và Phân tích

Trong phần này, trước tiên chúng tôi khám phá ưu điểm của Corex so với các nỗ lực hợp tác khác nhằm nâng cao suy luận, cũng như sự hiệp đồng giữa các chiến lược khác nhau. Sau đó, tác động của các backbone khác nhau được phân tích để hiểu cách khả năng mô hình ảnh hưởng đến hiệu quả của hợp tác. Hơn nữa, chúng tôi đánh giá hiệu quả của Corex.

5.1 So sánh Hiệu suất của Hợp tác

So sánh với Các Phương pháp Hợp tác Thay thế. Thừa nhận các công trình hiện tại liên quan đến phương pháp đa mô hình cho các tác vụ suy luận, như được thảo luận trong Phần 2, ở đây chúng tôi so sánh hiệu suất của Corex với các phương pháp này. Chúng tôi chọn hai phương pháp đại diện: (1) Tranh luận Đa tác nhân (MAD; Du và cộng sự, 2023), nơi nhiều mô hình thể hiện lập luận của họ, và một thẩm phán quản lý quá trình tranh luận để xác định giải pháp cuối cùng. (2) Trao đổi Suy nghĩ (EoT; Yin và cộng sự, 2023a), một phương pháp được phát hành gần đây xây dựng các chiến lược giao tiếp chéo mô hình dựa trên cấu trúc tô-pô mạng. Như được hiển thị trong Bảng 5, Corex liên tục vượt trội so với hai đường cơ sở sáng tạo này trên các chế độ khác nhau.

Phương pháp MultiArith SingleEQ AddSub
MAD 96.9 93.8 88.6
EoT 99.0 94.3 88.0
Corex-Discuss 98.7 93.7 89.7
Corex-Retrieve 99.8 94.3 90.9
Corex-Review 99.5 96.9 89.6

Bảng 5: So sánh hiệu suất của Corex và các phương pháp đa mô hình khác

SVAMP CSQA 20 40 60 80 Độ chính xác (%)
Self-Refine Review Review+Discuss Review+Retrieve

Hình 6: So sánh lợi ích từ việc kết hợp các chế độ khác nhau.

Sự hiệp đồng Giữa Các Chiến lược Khác nhau của Corex. Trong các thí nghiệm chính, chúng tôi chủ yếu đánh giá mỗi chế độ của Corex một cách độc lập để so sánh công bằng. Ở đây, chúng tôi khám phá liệu chúng có thể hưởng lợi lẫn nhau nếu được kết hợp. Chúng tôi chọn một phương pháp tương đối đơn giản và vừa phải về mặt tính toán: áp dụng chế độ đánh giá sau khi hợp tác của các chế độ khác, và bổ sung bao gồm một đường cơ sở Self-Refine (Madaan và cộng sự, 2023) để chứng minh thêm những lợi ích mang lại bởi hợp tác. Dựa trên Hình 6, chúng ta có thể quan sát thấy rằng: (1) bất kỳ hình thức hợp tác nào cũng vượt trội so với tự tinh chỉnh, và (2) việc kết hợp các chế độ khác nhau của Corex thường mang lại cải thiện, đặc biệt khi giải quyết điểm yếu của LLM như các tác vụ số.

5.2 Phân tích Sâu về Các Chiến lược Corex

Phân tích Số vòng Tương tác trong Chế độ Thảo luận. Chúng tôi nghiên cứu số vòng giao tiếp trong chế độ Thảo luận của Corex trên năm tác vụ, như được mô tả trong Hình 7. Sự đồng thuận có thể đạt được nhanh chóng cho phần lớn các vấn đề bởi mỗi nhóm. Tuy nhiên, Corex cho phép LLM tham gia vào các cuộc thảo luận kỹ lưỡng hơn cho các vấn đề khó đạt được sự đồng thuận (ví dụ, hơn 10% vấn đề ConvFinQA yêu cầu hơn 3 vòng), một tỷ lệ nhỏ vấn đề yêu cầu nhiều tương tác hơn. Thông qua quan sát, chúng tôi cũng nhận thấy rằng chế độ Thảo luận thể hiện tính chất hội tụ thuận lợi, trong đó quá trình tương tác phục vụ như cơ sở cho việc ra quyết định của thẩm phán.

1 2 3 4 5
Vòng 0 20 40 60 80 Tỷ lệ phần trăm (%)
GSM8K Penguin CSQA StrategyQA ConvFinQA

Hình 7: Phân bố số vòng thảo luận cần thiết để đạt được sự đồng thuận.

1 2 3 4
Vòng 92 94 96 Độ chính xác (%) - Code
65 70 75
Độ chính xác (%) - NL
Repeat Copy Penguin GSM8K BoolQ

Hình 8: Cải thiện hiệu suất qua nhiều vòng đánh giá

Nâng cao Hiệu suất mỗi Đánh giá. Chúng tôi khám phá những cải thiện hiệu suất tăng dần đạt được trong các tác vụ cụ thể với mỗi chu kỳ đánh giá trong chế độ Đánh giá. Như được chứng minh trong Hình 8, chúng tôi thực hiện phân tích cho Repeat Copy và GSM8K với Review Code, cũng như BoolQ và Penguin với Review NL. Các phát hiện chỉ ra rằng mỗi đánh giá đóng góp vào việc nâng cao hiệu suất nói chung, nhưng thỉnh thoảng cũng quan sát thấy các độ lệch dẫn đến dao động hiệu suất. Phân tích sâu hơn về các loại lỗi và lợi ích từ hợp tác được trình bày trong Phụ lục D.4.

5.3 Sự hiệp đồng giữa các LLM khác nhau

Biến đổi Hiệu suất với Các LLM Đa dạng làm Thẩm phán. Các LLM backbone của các tác nhân của chúng tôi có thể đa dạng. Trong phần này, chúng tôi thảo luận về hiệu suất khi sử dụng các LLM khác nhau trong cuộc thảo luận. Như được hiển thị trong Hình 9, chúng tôi triển khai GPT-3.5-Turbo làm người chơi và kiểm tra động lực khi các LLM khác nhau đảm nhận vai trò thẩm phán. Các quan sát chỉ ra rằng khả năng của thẩm phán tương quan tích cực với hiệu suất tác vụ, với mối quan hệ này trở nên rõ ràng khi độ phức tạp của tác vụ tăng lên. Theo kinh nghiệm, điều này có thể được quy cho vai trò của thẩm phán, yêu cầu hiểu cả câu hỏi và quá trình suy luận của cả hai bên.

Sử dụng Các LLM Khác nhau làm Người truy xuất. Trong chế độ Truy xuất, vai trò của người truy xuất có thể được đóng bởi các LLM khác nhau. Dựa trên các câu trả lời ứng viên từ các tác nhân GPT-3.5-Turbo, chúng tôi ở đây khám phá tác động của việc lựa chọn mô hình đối với hiệu suất, như được mô tả trong Hình 10. Không giống như chế độ thảo luận, phân tích của chúng tôi tiết lộ rằng khả năng mô hình có tác động khiêm tốn đến hiệu suất. Với giới hạn trên hiệu suất được xác định bởi khả năng của ứng viên, kết quả sử dụng các LLM khác nhau làm người truy xuất cho thấy sự khác biệt tối thiểu trên các tác vụ như ARC-c. Đáng chú ý, các phát hiện của chúng tôi chỉ ra rằng mà không cần các mô hình đặc biệt mạnh mẽ làm người truy xuất, chúng tôi vẫn có thể đạt được kết quả thuận lợi.

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

AddSub SVAMP StrategyQA Repeat Copy 50 60 70 80 90 100 Độ chính xác (%)
GPT-4 GPT-3.5-Turbo Claude-Instant-1.2

Hình 9: So sánh việc sử dụng các LLM khác nhau làm thẩm phán trong chế độ Thảo luận.

SingleEQ SingleOP ARC-c OpenBookQA 50 60 70 80 90 100 Độ chính xác (%)
GPT-4 GPT-3.5-Turbo Claude-Instant-1.2

Hình 10: So sánh việc sử dụng các LLM khác nhau làm người truy xuất trong chế độ Truy xuất.

5.4 Hiệu quả Chi phí của Hợp tác Đa tác nhân

Bằng cách khuyến khích hợp tác giữa các tác nhân dựa trên LLM, chúng tôi quản lý để giảm chi phí liên quan đến các tác vụ suy luận trong khi đạt được hiệu suất tương đương hoặc thậm chí vượt trội.

4.25 4.50 4.75 5.00 5.25 5.50 5.75 6.00 6.25 6.50
Tiêu thụ Token theo thang log10 87 88 89 90 91 Độ chính xác(%)
CoT PAL CoT-SC(5) CoT-SC(10) CoT-SC(20)
CoT-SC(40) CoT-SC(80)
ComplexCoT ComplexCoT(10) ComplexCoT(20) ComplexCoT(40)
Discuss Review Retrieve

Hình 11: Phân tích hiệu quả chi phí. Trục X biểu thị chi phí tính toán, được tính bằng token đầu vào/đầu ra, trong khi kích thước mỗi chấm tỷ lệ với số lượng suy luận trung bình.

Dựa trên phân tích của chúng tôi được thực hiện trên AddSub được minh họa trong Hình 11, nó tiết lộ rằng cả ba chế độ của Corex đều nhất quán khớp hoặc vượt qua sức mạnh của các đường cơ sở mạnh khác. Đáng kể, chi phí tính toán của phương pháp của chúng tôi giảm đáng kể so với các phương pháp sử dụng bỏ phiếu đa số. Trong việc đạt được hiệu suất tương đương, tiêu thụ tài nguyên của Corex bị giới hạn chỉ 5-10% so với những gì được tiêu tốn bởi các chiến lược khác. Để chứng minh tính tổng quát, chúng tôi đã cung cấp các thí nghiệm bổ sung trong Phụ lục D.2, điều này chứng minh thêm xu hướng tương tự.

Ngoài hiệu quả của chi phí tính toán, một ưu điểm khác của Corex là hiệu quả chú thích, giảm sự phụ thuộc vào các minh họa được tuyển chọn. Các thí nghiệm tiếp theo với số lượng minh họa khác nhau về khía cạnh này có thể được tìm thấy trong Phụ lục D.3.

6 Kết luận

Chúng tôi giới thiệu Corex trong bài báo này, một bộ các chiến lược biến đổi LLM thành các tác nhân suy luận tự trị, từ đó tận dụng hợp tác đa mô hình cho suy luận phức tạp. Điều này cung cấp một khám phá sơ bộ vào hệ sinh thái các tác nhân dựa trên LLM. Thông qua việc mở khóa sự hiệp đồng giữa các LLM, Corex trao quyền cho suy luận với tính factual, trung thực và độ tin cậy được nâng cao thông qua các mô hình hợp tác khác nhau. Chúng tôi tiến hành đánh giá rộng rãi trên 18 tác vụ trong 4 loại, và kết quả chứng minh hiệu suất vượt trội so với các giải pháp trước đây. Hơn nữa, các phương pháp của chúng tôi cũng thể hiện nhiều ưu điểm đáng chú ý bao gồm độc lập tác vụ, hiệu quả chi phí và linh hoạt hơn so với các phương pháp đa mô hình khác. Chúng tôi hy vọng rằng công trình này có thể phục vụ như một nền tảng cho nghiên cứu tiếp theo, mang lại những góc nhìn mới trong suy luận phức tạp và trí tuệ tập thể.

Lời cảm ơn

Công trình này được hỗ trợ bởi Phòng thí nghiệm Trí tuệ Nhân tạo Thượng Hải dưới dự án nghiên cứu JF-P23KK00072-2-DF. Các tác giả cảm ơn Fangzhi Xu vì cung cấp hiệu suất CoT và PAL của LLaMA2-Chat(7B/13B), cũng như các người đánh giá vì những bình luận sâu sắc của họ. Chúng tôi cũng đánh giá cao Chương trình Truy cập Nhà nghiên cứu Bên ngoài của Anthropic vì cung cấp tín dụng API để hỗ trợ các thí nghiệm được thực hiện trên Claude trong bài báo này.

Tài liệu tham khảo

Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, và Quoc V. Le. Towards a human-like open-domain chatbot. CoRR, 2020.

Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from human feedback. ArXiv preprint, 2022.

BIG bench authors. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. TMLR, 2023.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. In NeurIPS, 2020.

Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, và Zhiyuan Liu. Chateval: Towards better llm-based evaluators through multi-agent debate, 2023.

Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau, Laurent Sifre, và John Jumper. Accelerating large language model decoding with speculative sampling, 2023a.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harri Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021a.

Wenhu Chen, Xueguang Ma, Xinyi Wang, và William W. Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks, 2022a.

Yi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, và Ruifeng Xu. Exploring the use of large language models for reference-free text quality evaluation: An empirical study, 2023b.

Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, và William Yang Wang. FinQA: A dataset of numerical reasoning over financial data. In Proc. of EMNLP, 2021b.

Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, và William Yang Wang. ConvFinQA: Exploring the chain of numerical reasoning in conversational finance question answering. In Proc. of EMNLP, 2022b.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways, 2022.

Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, và Kristina Toutanova. BoolQ: Exploring the surprising difficulty of natural yes/no questions. In Proc. of AACL, 2019.

[Tiếp tục với phần còn lại của danh sách tài liệu tham khảo...]

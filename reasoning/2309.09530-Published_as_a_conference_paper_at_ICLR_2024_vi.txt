# 2309.09530.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/reasoning/2309.09530.pdf
# Kích thước tệp: 904338 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Xuất bản dưới dạng bài báo hội nghị tại ICLR 2024
THÍCH ỨNG CÁC MÔ HÌNH NGÔN NGỮ LỚN
VỚI CÁC MIỀN THÔNG QUA HIỂU ĐỌC
Daixuan Cheng‡, Shaohan HuangB†& Furu Wei†
†Microsoft Research‡Beijing Institute for General Artificial Intelligence (BIGAI)
https://huggingface.co/AdaptLLM

TÓM TẮT
Chúng tôi khám phá cách việc tiếp tục tiền huấn luyện trên các kho dữ liệu cụ thể theo miền ảnh hưởng đến các mô hình ngôn ngữ lớn, tiết lộ rằng việc huấn luyện trên các kho dữ liệu thô trang bị cho mô hình kiến thức về miền, nhưng làm tổn hại đáng kể khả năng nhắc nhở của nó cho việc trả lời câu hỏi. Lấy cảm hứng từ việc học của con người thông qua hiểu đọc—thực hành sau khi đọc cải thiện khả năng trả lời câu hỏi dựa trên kiến thức đã học—chúng tôi đề xuất một phương pháp đơn giản để chuyển đổi các kho dữ liệu thô thành các văn bản hiểu đọc. Mỗi văn bản thô được làm phong phú với một loạt các nhiệm vụ liên quan đến nội dung của nó. Phương pháp của chúng tôi, có khả năng mở rộng cao và áp dụng được cho bất kỳ kho dữ liệu tiền huấn luyện nào, liên tục nâng cao hiệu suất trên các nhiệm vụ khác nhau trong ba miền khác nhau: y sinh học, tài chính và luật. Đáng chú ý, mô hình ngôn ngữ 7B của chúng tôi đạt được hiệu suất cạnh tranh với các mô hình cụ thể theo miền có quy mô lớn hơn nhiều, chẳng hạn như BloombergGPT-50B. Hơn nữa, chúng tôi chứng minh rằng các văn bản hiểu đọc cụ thể theo miền có thể cải thiện hiệu suất của mô hình ngay cả trên các bộ đánh giá chung, cho thấy tiềm năng phát triển một mô hình chung trên nhiều miền hơn nữa. Mô hình, mã và dữ liệu của chúng tôi có sẵn tại https://github.com/microsoft/LMOps.

[Biểu đồ hiệu suất nhiệm vụ cụ thể theo miền trong y sinh học, tài chính và luật]

Hình 1: Hiệu suất nhiệm vụ cụ thể theo miền trong y sinh học, tài chính và luật. LLM chung là mô hình ngôn ngữ chung không có huấn luyện tiếp tục, DAPT (Gururangan và cộng sự, 2020) tiếp tục huấn luyện mô hình chung trên các kho dữ liệu thô cụ thể theo miền, và AdaptLLM tiếp tục huấn luyện mô hình chung trên các văn bản hiểu đọc được xây dựng dựa trên các kho dữ liệu thô, trộn với các hướng dẫn chung.

--- TRANG 2 ---
Xuất bản dưới dạng bài báo hội nghị tại ICLR 2024

[Ví dụ văn bản hiểu đọc với các nhiệm vụ khác nhau]

Hình 2: Một ví dụ đơn giản về văn bản hiểu đọc, trong đó văn bản thô được theo sau bởi một loạt các nhiệm vụ được xây dựng từ nó, bao gồm Tóm tắt (tím), Từ-đến-Văn bản (xanh), Suy luận Ngôn ngữ Tự nhiên (đỏ), Lý luận Thông thức (xanh lá đậm), Phát hiện Paraphrase (vàng), và Hoàn thành Văn bản (xanh lá). Phiên bản đầy đủ có trong Phụ lục G.

1 GIỚI THIỆU

Sự phổ biến của các mô hình ngôn ngữ lớn (LLM) chung đã dẫn đến sự xuất hiện của các mô hình ngôn ngữ lớn cụ thể theo miền. Các phương pháp hiện có có thể được phân loại rộng rãi thành ba cách tiếp cận. Cách đầu tiên huấn luyện các mô hình từ đầu trên hỗn hợp các kho dữ liệu cụ thể theo miền và chung (Wu và cộng sự, 2023b). Mặc dù điều này tạo ra các LLM cụ thể theo miền một cách trực quan, nhưng các yêu cầu tính toán và dữ liệu đáng kể gây ra những lo ngại nghiêm trọng (Yang và cộng sự, 2023; Ling và cộng sự, 2023). Cách thứ hai tinh chỉnh mô hình ngôn ngữ sử dụng các tập dữ liệu có giám sát (Singhal và cộng sự, 2022; 2023; Li và cộng sự, 2023b;a; Wang và cộng sự, 2023; Han và cộng sự, 2023; Xiong và cộng sự, 2023; Huang và cộng sự, 2023), cung cấp một lựa chọn hiệu quả về chi phí hơn. Tuy nhiên, có những bất định về việc các LLM được tinh chỉnh nắm bắt kiến thức miền có thể được áp dụng phổ quát cho tất cả các nhiệm vụ cụ thể theo miền như thế nào, như đã thảo luận bởi Zhou và cộng sự (2023) và Gudibande và cộng sự (2023). Cách thứ ba nhắc nhở mô hình ngôn ngữ chung với kiến thức miền được truy xuất (Li và cộng sự, 2023b; Cui và cộng sự, 2023; Huang và cộng sự, 2023), có thể được coi là một ứng dụng của LLM chứ không phải là một cải tiến trực tiếp cho chính LLM.

Tiếp tục tiền huấn luyện trên các kho dữ liệu cụ thể theo miền, còn được gọi là tiền huấn luyện thích ứng miền (Gururangan và cộng sự, 2020), đã được chứng minh là hiệu quả trong việc thích ứng các mô hình hiểu ngôn ngữ tự nhiên khác nhau (Devlin và cộng sự, 2019; Liu và cộng sự, 2019; Clark và cộng sự, 2020) với các miền cụ thể (Yao và cộng sự, 2021; Gururangan và cộng sự, 2020; Cheng và cộng sự, 2022). Cách tiếp cận này cho phép các mô hình ngôn ngữ tận dụng khả năng chung trong khi kết hợp kiến thức cụ thể theo miền, có lợi cho các nhiệm vụ cụ thể theo miền hạ nguồn với chi phí giảm. Điều này thúc đẩy cuộc điều tra của chúng tôi về việc liệu tiền huấn luyện thích ứng miền cũng có lợi cho các mô hình sinh lớn quy mô. Chúng tôi tiến hành các thí nghiệm sơ bộ trên ba miền—y sinh học, tài chính và luật—tiết lộ rằng việc tiếp tục huấn luyện trên các kho dữ liệu thô dẫn đến sự sụt giảm mạnh trong hiệu suất nhắc nhở nhưng vẫn có lợi cho các đánh giá tinh chỉnh và thăm dò kiến thức. Điều này dẫn chúng tôi đến kết luận rằng tiền huấn luyện thích ứng miền sử dụng các kho dữ liệu thô trang bị cho LLM kiến thức miền trong khi làm tổn hại khả năng nhắc nhở của nó.

Để tận dụng kiến thức cụ thể theo miền trong khi nâng cao hiệu suất nhắc nhở, chúng tôi giới thiệu một phương pháp đơn giản để chuyển đổi các kho dữ liệu thô quy mô lớn thành các văn bản hiểu đọc: mỗi văn bản thô được làm phong phú với một loạt các nhiệm vụ liên quan đến nội dung của nó, như được minh họa trong Hình 2. Các nhiệm vụ này được thiết kế để giúp mô hình duy trì khả năng trả lời câu hỏi bằng ngôn ngữ tự nhiên, dựa trên bối cảnh của văn bản thô. Hơn nữa, chúng tôi bổ sung các văn bản hiểu đọc với các hướng dẫn chung đa dạng, từ đó nâng cao thêm khả năng nhắc nhở (Wei và cộng sự, 2022; Zhou và cộng sự, 2023; Xu và cộng sự, 2023; Mukherjee và cộng sự, 2023). Các thí nghiệm của chúng tôi trong các miền như y sinh học, tài chính và luật làm nổi bật tính hiệu quả của cách tiếp cận của chúng tôi trong việc cải thiện hiệu suất mô hình trên các nhiệm vụ cụ thể theo miền khác nhau. Chúng tôi gọi mô hình kết quả này là AdaptLLM, viết tắt của Mô hình Ngôn ngữ Lớn Được Thích ứng. Nhìn về phía trước, chúng tôi hình dung việc mở rộng phương pháp này để phát triển một mô hình ngôn ngữ lớn chung, đóng góp vào bối cảnh nhiệm vụ không ngừng mở rộng trên nhiều miền hơn.

Tóm lại, các đóng góp của chúng tôi bao gồm:
• Chúng tôi điều tra tiền huấn luyện thích ứng miền cho các mô hình ngôn ngữ lớn, nơi chúng tôi phát hiện rằng việc tiếp tục huấn luyện trên các kho dữ liệu thô cụ thể theo miền có thể trang bị cho mô hình kiến thức miền, nhưng làm tổn hại đáng kể khả năng nhắc nhở của nó.
• Chúng tôi đề xuất một công thức đơn giản tự động chuyển đổi các kho dữ liệu thô quy mô lớn thành các văn bản hiểu đọc, để học hiệu quả kiến thức miền trong khi đồng thời bảo tồn hiệu suất nhắc nhở.
• Các thí nghiệm của chúng tôi cho thấy tính hiệu quả của phương pháp trong việc cải thiện liên tục hiệu suất mô hình trong ba miền khác nhau: y sinh học, tài chính và luật.

2 KHÁM PHÁ SƠ BỘ VỀ TIỀN HUẤN LUYỆN THÍCH ỨNG MIỀN

Với tính hiệu quả và hiệu quả đã được chứng minh của tiền huấn luyện thích ứng miền trong việc thích ứng các mô hình hiểu ngôn ngữ tự nhiên (Gururangan và cộng sự, 2020; Yao và cộng sự, 2021; Cheng và cộng sự, 2022), chúng tôi bắt đầu một cuộc khám phá để xác định liệu phương pháp này vẫn hiệu quả đối với các mô hình sinh quy mô lớn. Chúng tôi tiếp tục huấn luyện LLaMA chung (Touvron và cộng sự, 2023a) trên các kho dữ liệu thô cụ thể theo miền của y sinh học, tài chính và luật, tương ứng, và tiến hành các đánh giá nhắc nhở, tinh chỉnh và thăm dò kiến thức để đánh giá hiệu suất mô hình trong mỗi miền (các cài đặt thí nghiệm chi tiết có trong Phần 4).

Bảng 1: Hiệu suất nhiệm vụ cụ thể theo miền của mô hình ngôn ngữ chung (LLM Chung) và mô hình đã trải qua tiền huấn luyện thích ứng miền vanilla (DAPT (Gururangan và cộng sự, 2020)). Chúng tôi báo cáo trung bình của điểm số nhiệm vụ trong mỗi miền dưới các cài đặt nhắc nhở, tinh chỉnh và thăm dó kiến thức.

[Bảng với kết quả hiệu suất]

Nhắc nhở so với Tinh chỉnh. Trong Bảng 1, khi tiến hành đánh giá tinh chỉnh trên các nhiệm vụ cụ thể theo miền, mô hình đã trải qua tiền huấn luyện thích ứng miền luôn vượt trội so với mô hình chung trên tất cả ba miền. Điều này phù hợp với các phát hiện về các mô hình hiểu ngôn ngữ (Gururangan và cộng sự, 2020), chỉ ra rằng việc tiếp tục tiền huấn luyện làm giàu mô hình ngôn ngữ với kiến thức cụ thể theo miền. Ngược lại, một xu hướng mâu thuẫn xuất hiện trong hiệu suất nhắc nhở, nơi quan sát được sự sụt giảm đáng chú ý trên hầu hết các miền sau tiền huấn luyện thích ứng miền. Mâu thuẫn này dẫn chúng tôi đến giả thuyết rằng trong khi tiền huấn luyện thích ứng miền vanilla nâng cao kiến thức miền của LLM, đóng góp vào các cải tiến tinh chỉnh, nó cũng làm suy yếu đáng kể khả năng hoạt động tốt trong nhắc nhở, gây ra sự sụt giảm quan sát được.

Thăm dò Kiến thức Miền. Để xác nhận liệu mô hình ngôn ngữ có đạt được kiến thức miền từ tiền huấn luyện thích ứng miền hay không, chúng tôi sử dụng một phương pháp thăm dò tương tự như LAMA (Petroni và cộng sự, 2019). Sử dụng các tập dữ liệu có giám sát có sẵn trong mỗi miền làm cơ sở, chúng tôi tạo ra các tập dữ liệu thăm dò kiến thức cụ thể theo miền. Quá trình tạo tập dữ liệu được chi tiết trong Phụ lục A. Trong Bảng 1, chúng tôi trình bày kết quả thăm dò kiến thức miền cho các miền y sinh học và luật. Trong cả hai miền, chúng tôi quan sát kết quả cải thiện sau tiền huấn luyện thích ứng miền, chỉ ra rằng mô hình thực sự thu được kiến thức miền.

Các phân tích ở trên cho thấy rằng sự sụt giảm trong hiệu suất nhắc nhở cụ thể theo miền có thể được quy cho việc giảm khả năng nhắc nhở. Sự giảm này có thể là kết quả của sự đa dạng hạn chế của các kho dữ liệu tiền huấn luyện trong một miền cụ thể (Longpre và cộng sự, 2023b), điều này hạn chế sự đa dạng của các mẫu đầu vào-đầu ra có được từ các văn bản thô (Wei và cộng sự, 2022). Do đó, việc cải thiện khả năng nhắc nhở trở nên thiết yếu để khai thác hiệu quả kiến thức miền thu được từ tiền huấn luyện thích ứng miền.

3 THÍCH ỨNG CÁC MÔ HÌNH NGÔN NGỮ LỚN THÔNG QUA HIỂU ĐỌC

Thay vì tiếp tục huấn luyện mô hình ngôn ngữ lớn trên các kho dữ liệu thô cụ thể theo miền, chúng tôi chuyển đổi các kho dữ liệu thô thành các văn bản hiểu đọc và thích ứng mô hình sử dụng dữ liệu đã chuyển đổi. Trong hiểu đọc, mỗi văn bản thô được theo sau bởi một loạt các nhiệm vụ liên quan đến nội dung của nó. Chúng tôi coi giai đoạn huấn luyện mô hình trên văn bản thô là giai đoạn "đọc", và giai đoạn huấn luyện tiếp theo trên các nhiệm vụ liên quan là giai đoạn "hiểu" (Chen và cộng sự, 2023; Gu và cộng sự, 2022; 2023). Các nhiệm vụ hiểu này tuân theo định dạng trả lời câu hỏi, nhằm làm phong phú khả năng nhắc nhở của mô hình để phản hồi các câu hỏi đầu vào (Wei và cộng sự, 2022). Thiết kế này được lấy cảm hứng từ việc học của con người, nơi thực hành sau khi đọc nâng cao khả năng trả lời câu hỏi dựa trên kiến thức đã có. Bên cạnh đó, chúng tôi bổ sung dữ liệu huấn luyện với các hướng dẫn chung (Zhou và cộng sự, 2023; Xu và cộng sự, 2023; Mukherjee và cộng sự, 2023) để hưởng lợi từ sự đa dạng của các mẫu đầu vào-đầu ra, từ đó cải thiện thêm khả năng nhắc nhở.

3.1 TẠO CÁC VĂN BẢN HIỂU ĐỌC

Để tạo các văn bản hiểu đọc, chúng tôi bắt đầu bằng việc khai thác các nhiệm vụ nội tại từ các kho dữ liệu thô với một số ít các mẫu khai thác. Ý tưởng khai thác các nhiệm vụ từ các kho dữ liệu tiền huấn luyện đã được giới thiệu bởi van de Kar và cộng sự (2022). Phương pháp này khai thác các nhiệm vụ nội tại thông qua một vài mẫu dựa trên regex, và sau đó tinh chỉnh mô hình trên các nhiệm vụ này để nâng cao hiệu suất zero-shot. Cách tiếp cận của chúng tôi tận dụng bản chất tự giám sát của chiến lược khai thác này. Điều này cho phép chúng tôi mở rộng việc chuyển giao các kho dữ liệu tiền huấn luyện thô, tận dụng kiến thức cụ thể theo miền được nhúng trong các văn bản thô và khả năng nhắc nhở nâng cao được cung cấp bởi các nhiệm vụ hiểu.

Bảng 2 cung cấp một cái nhìn tổng quan về các kỹ thuật được sử dụng để khai thác và tạo nhiệm vụ từ mỗi văn bản thô. Các cụm từ như "Trả lời câu hỏi dựa trên bài viết:" được sử dụng để nối văn bản thô với các nhiệm vụ theo sau, như được minh họa trong Hình 2. Ngoài ra, chúng tôi diễn đạt lại mỗi mẫu đầu vào-đầu ra thành nhiều biến thể và đảo ngược nhiệm vụ để nâng cao tính đa dạng của nhiệm vụ (Wei và cộng sự, 2022; Chung và cộng sự, 2022; Longpre và cộng sự, 2023a).

Tóm tắt nhắc nhở các mô hình tạo ra một bản tóm tắt ngắn gọn của văn bản được cung cấp, khuyến khích chúng trích xuất ý tưởng chính. Chúng tôi sử dụng các truy vấn như "Tóm tắt là gì?" để nhắc nhở mô hình tóm tắt văn bản thô, với tiêu đề văn bản phục vụ như sự thật cơ bản. Chúng tôi cũng đảo ngược nhiệm vụ, yêu cầu mô hình tạo ra một bài viết dựa trên tiêu đề đã cho.

Ngoài ra, chúng tôi nhắc nhở các mô hình xác định chủ đề câu. Để khám phá các nhiệm vụ nội tại như vậy, chúng tôi sử dụng các mẫu dựa trên regex để xác định các câu phù hợp với các mẫu được chỉ định trong Bảng 2. Sau đó chúng tôi sử dụng các mẫu tương ứng để xây dựng các cặp đầu vào-đầu ra (van de Kar và cộng sự, 2022).

Từ-đến-Văn bản nâng cao khả năng nắm bắt từ vựng cụ thể theo miền của mô hình bằng cách nhắc nhở nó tạo ra các câu kết hợp các từ cụ thể. Để xác định các từ cụ thể theo miền, chúng tôi sử dụng công cụ SentencePiece (Kudo & Richardson, 2018) để xây dựng từ vựng từ các kho dữ liệu miền đích. Sau đó chúng tôi so sánh từ vựng miền này với từ vựng của mô hình ngôn ngữ chung, coi các từ có trong từ vựng miền nhưng không có trong từ vựng chung là cụ thể theo miền. Tiếp theo, chúng tôi lọc ra các token có ít hơn 10 ký tự, tạo ra một tập hợp các từ khóa cụ thể theo miền.

Đối với mỗi câu trong văn bản thô, chúng tôi đếm số lượng từ khóa cụ thể theo miền. Các câu có hơn ba từ khóa cụ thể theo miền được chọn để tạo các nhiệm vụ Từ-đến-Văn bản. Chúng tôi lấy các từ khóa cụ thể theo miền trong câu làm đầu vào, yêu cầu mô hình tạo ra một câu với "Tạo ra một câu bao gồm các từ khóa {MIỀN} này".

Chúng tôi cũng đảo ngược nhiệm vụ bằng cách lấy câu làm đầu vào và yêu cầu mô hình tìm các từ khóa về miền đích, sử dụng "Những từ khóa nào về {MIỀN} có thể được trích xuất từ câu này?". Ở đây chúng tôi chỉ ra miền đích bằng cách thay thế {MIỀN} bằng tên miền như y sinh học, tài chính, hoặc luật. Bên cạnh đó, chúng tôi nhắc nhở mô hình định nghĩa các khái niệm sử dụng các mẫu khai thác và mẫu đầu vào-đầu ra trong Bảng 2.

Suy luận Ngôn ngữ Tự nhiên liên quan đến cách hai câu liên quan, thường hỏi, cho một câu đầu tiên, liệu câu thứ hai có đúng, sai hay có thể đúng. Chúng tôi sử dụng các mẫu dựa trên regex trong Bảng 2 để tìm kiếm các bộ ba "tiền đề-giả thuyết-quan hệ" trong văn bản thô. Ví dụ, chúng tôi phân loại mối quan hệ giữa hai câu là "Entailment" nếu chúng được kết nối bởi verbalizer "Therefore", và là "Contradictory" nếu được kết nối bởi "However".

Ngoài ra, chúng tôi nâng cao tính đa dạng bằng cách định dạng lại các nhiệm vụ phân loại thành các nhiệm vụ sinh. Ví dụ, khi mối quan hệ giữa hai câu là "Entailment", chúng tôi sử dụng các mẫu như {SENT1} "Thus?" để nhắc nhở mô hình tạo ra một đầu ra, nơi sự thật cơ bản là câu thứ hai.

Lý luận Thông thức đánh giá khả năng thực hiện lý luận vật lý hoặc khoa học trong khi xem xét thông thức. Chúng tôi xác định logic nguyên nhân-kết quả trong các câu sử dụng các mẫu dựa trên regex trong Bảng 2. Sau đó chúng tôi xây dựng các cặp đầu vào-đầu ra sử dụng các mẫu như "Lý do của {SENT1} là gì? {SENT2}".

Phát hiện Paraphrase yêu cầu mô hình xác định liệu hai câu có tương đương về mặt ngữ nghĩa hay không. Để thu thập dữ liệu nhiệm vụ, chúng tôi sử dụng các mẫu dựa trên regex trong Bảng 2 để tìm kiếm các bộ ba dữ liệu "câu1-câu2-nhãn". Tuy nhiên, chúng tôi phát hiện thực nghiệm rằng các mẫu khai thác không thể nhất quán xác định hai câu có nghĩa hoàn toàn tương đương. Ví dụ, các câu được liên kết bởi verbalizer "Similarly" có thể không chia sẻ nghĩa tương tự.

Do đó, chúng tôi định dạng lại nhiệm vụ phân loại thành nhiệm vụ sinh để giảm sự phụ thuộc vào độ chính xác của nhãn. Thay vì hỏi liệu hai câu có tương tự hay không, chúng tôi nhắc nhở mô hình tạo ra một câu hỗ trợ hoặc mâu thuẫn với nghĩa của một câu đã cho, sử dụng các mẫu đầu vào-đầu ra như "Bạn có thể tạo ra một câu mâu thuẫn với nghĩa của {SENT1} không? {SENT2}" khi nhãn khai thác là "Different".

Hoàn thành Văn bản. Ngoài nhiệm vụ mô hình hóa ngôn ngữ ngẫu nhiên vốn có trong các mô hình ngôn ngữ sinh, chúng tôi chèn các truy vấn như "Bạn sẽ hoàn thành bài viết như thế nào?" giữa các câu để nhắc nhở mô hình ngôn ngữ tạo ra phần tiếp theo. Một ưu điểm của nhiệm vụ Hoàn thành Văn bản là nó không yêu cầu bất kỳ mẫu khai thác cụ thể nào, do đó có thể được áp dụng cho bất kỳ văn bản thô nào.

3.2 TRỘN VỚI CÁC HƯỚNG DẪN CHUNG

Mặc dù chúng tôi đã thiết kế các mẫu khai thác đa dạng, các mẫu đầu vào-đầu ra và đảo ngược nhiệm vụ để nâng cao khả năng nhắc nhở, chúng có thể không hoàn toàn giải quyết được tính đa dạng nhiệm vụ vô hạn trong các tình huống thực tế. Có xem xét đến điều này, chúng tôi đề xuất trộn các văn bản hiểu đọc với các hướng dẫn chung để bao phủ một phạm vi rộng hơn các mẫu đầu vào-đầu ra.

4 CÀI ĐẶT THÍ NGHIỆM

Tiền huấn luyện Thích ứng Miền. PubMed Abstracts và FreeLaw Opinions từ The Pile (Gao và cộng sự, 2021) được sử dụng làm các kho dữ liệu tiền huấn luyện cho các miền y sinh học và luật, tương ứng. Đối với tài chính, chúng tôi thu thập tin tức tài chính từ tháng 5 năm 2022 đến tháng 5 năm 2023 cho hơn 7.000 cổ phiếu, sử dụng codebase FinGPT (Yang và cộng sự, 2023). Các hướng dẫn chung được lấy từ LIMA (Zhou và cộng sự, 2023), WizardLM (Xu và cộng sự, 2023), và Orca (Mukherjee và cộng sự, 2023; Lian và cộng sự, 2023). Chúng tôi tiếp tục huấn luyện LLaMA-7B (Touvron và cộng sự, 2023a) trên mỗi miền, và khám phá các tỷ lệ khác nhau để trộn các văn bản hiểu đọc với các hướng dẫn chung; các tỷ lệ tối ưu cho y sinh học, tài chính và luật lần lượt là 1:1, 1:2, và 1:1. Chi tiết triển khai, đặc điểm tập dữ liệu, và các siêu tham số tiền huấn luyện khác có thể được tìm thấy trong Phụ lục B.

Tạo Văn bản Hiểu đọc. Sử dụng các mẫu khai thác trong Bảng 2, chúng tôi tìm kiếm các tiểu thể loại trong mỗi loại nhiệm vụ. Để ngăn ngừa sự thống trị của nhiệm vụ, chúng tôi giới hạn số lượng ví dụ nhiệm vụ mỗi tiểu thể loại thành hai cho mỗi văn bản thô. Đối với mỗi ví dụ được khai thác, chúng tôi lấy mẫu ngẫu nhiên từ các mẫu paraphrase hoặc đảo ngược nhiệm vụ khác nhau để tạo ra một ví dụ đầu vào-đầu ra. Để cấu trúc văn bản hiểu đọc, chúng tôi sử dụng \n\n để kết nối các nhiệm vụ hiểu và liên kết chúng với văn bản thô. Trung bình, khoảng hai ví dụ đầu vào-đầu ra được thu thập cho mỗi văn bản hiểu đọc. Vui lòng tham khảo Phụ lục C để biết chi tiết triển khai mẫu khai thác và Phụ lục G cho các trường hợp văn bản hiểu đọc.

Các Nhiệm vụ Cụ thể theo Miền. Đối với y sinh học, chúng tôi đánh giá trên PubMedQA (Jin và cộng sự, 2019), ChemProt (Kringelum và cộng sự, 2016), MQP (McCreery và cộng sự, 2020), RCT (Dernoncourt & Lee, 2017), và USMLE (Jin và cộng sự, 2020). Đối với tài chính, chúng tôi đánh giá trên năm nhiệm vụ có sẵn công khai cũng được đánh giá bởi BloombergGPT (Wu và cộng sự, 2023b): ConvFinQA (Chen và cộng sự, 2022), FPB (Malo và cộng sự, 2014), FiQA SA (Maia và cộng sự, 2018), Headline (Sinha & Khandait, 2020), và NER (Alvarado và cộng sự, 2015), và áp dụng các cài đặt nhắc nhở tương tự với BloombergGPT. Đối với luật, chúng tôi đánh giá trên SCOTUS (Spaeth và cộng sự, 2020), CaseHOLD (Zheng và cộng sự, 2021) và UNFAIR-ToS (Lippi và cộng sự, 2019) từ bộ đánh giá LexGLUE (Chalkidis và cộng sự, 2022). Chi tiết đánh giá được cung cấp trong Phụ lục D.

5 KẾT QUẢ CHÍNH

Trong Bảng 4, chúng tôi so sánh các mô hình của chúng tôi (AdaptLLM) với các mô hình ngôn ngữ chung, và các mô hình đã trải qua tiền huấn luyện thích ứng miền vanilla trên các kho dữ liệu thô (DAPT). Trên các nhiệm vụ khác nhau trong ba miền, việc sử dụng các kho dữ liệu thô trong DAPT ảnh hưởng tiêu cực đến hiệu suất nhắc nhở. Tuy nhiên, việc chuyển đổi các kho dữ liệu thô và bao gồm các hướng dẫn chung trong AdaptLLM đã thành công trong việc chống lại tác động này, vượt trội so với mô hình ngôn ngữ chung.

Bên cạnh đó, chúng tôi so sánh AdaptLLM với các mô hình/kết quả có sẵn công khai khác trong mỗi miền như sau.

Y sinh học. Chúng tôi so sánh với MedAlpaca (Han và cộng sự, 2023), tinh chỉnh LLaMA (Touvron và cộng sự, 2023a) trên các hướng dẫn trả lời câu hỏi y tế. Mặc dù các hướng dẫn có giám sát giúp MedAlpaca vượt trội LLaMA trong một số nhiệm vụ cụ thể theo miền, ưu thế này không nhất quán, có thể do các hướng dẫn không truyền đạt đầy đủ kiến thức miền, hoặc các hướng dẫn cụ thể cho một miền gặp khó khăn với các tình huống đầu vào-đầu ra khác nhau.

Tài chính. Chúng tôi so sánh kết quả của chúng tôi với những kết quả được báo cáo trong BloombergGPT (Wu và cộng sự, 2023b), một mô hình được huấn luyện từ đầu trên hỗn hợp các kho dữ liệu tài chính và chung. Mặc dù LLaMA-7B có điểm số thấp hơn BloombergGPT-50B, AdaptLLM-7B đạt được hiệu suất cạnh tranh với nó. Điều này làm nổi bật hiệu quả tính toán và dữ liệu của cách tiếp cận của chúng tôi so với việc huấn luyện từ đầu.

Luật. Chúng tôi so sánh với LexGPT (Lee, 2023) tiến hành tiền huấn luyện thích ứng miền vanilla trên GPT-J (Wang & Komatsuzaki, 2021) sử dụng các kho dữ liệu thô của Pile of Law (Henderson và cộng sự, 2022). Trái ngược với GPT-J, LexGPT cho thấy kết quả nhắc nhở tiêu cực. Xu hướng này phù hợp với quan sát của chúng tôi trong phần 2 rằng việc tiếp tục tiền huấn luyện trên các kho dữ liệu thô cụ thể theo miền dẫn đến hiệu suất nhắc nhở tệ hơn. Tuy nhiên, phương pháp của chúng tôi đóng góp vào kết quả nhắc nhở tích cực, nhấn mạnh tính hiệu quả của các nhiệm vụ hiểu và hướng dẫn chung.

6 NGHIÊN CỨU LOẠI BỎ VỀ DỮ LIỆU HUẤN LUYỆN

Bảng 5 trình bày kết quả nghiên cứu loại bỏ về các dữ liệu huấn luyện và hỗn hợp dữ liệu khác nhau: (1) Văn bản Thô đề cập đến các kho dữ liệu thô được sử dụng trong tiền huấn luyện thích ứng miền vanilla. (2) Hiểu Đọc chuyển đổi các kho dữ liệu thô thành các văn bản hiểu đọc, tăng cường khả năng nhắc nhở để cho thấy kết quả tốt hơn trong tất cả các miền được thích ứng. (3) Hướng dẫn Chung đề cập đến các hướng dẫn chung. (4) Hiểu Đọc + Hướng dẫn Chung bổ sung các văn bản hiểu đọc với các hướng dẫn chung. So với việc chỉ sử dụng các văn bản hiểu đọc, việc bao gồm các hướng dẫn chung cải thiện thêm khả năng nhắc nhở, dẫn đến kết quả nhiệm vụ tốt hơn. Hơn nữa, so với việc chỉ sử dụng các hướng dẫn chung, việc sử dụng các văn bản hiểu đọc cung cấp kiến thức miền nâng cao hiệu suất trong các nhiệm vụ cụ thể theo miền. Hơn nữa, chúng tôi cung cấp các nghiên cứu loại bỏ cho từng loại nhiệm vụ hiểu trong Phụ lục E, nơi chúng tôi phát hiện rằng Từ-đến-Văn bản và Suy luận Ngôn ngữ Tự nhiên thể hiện tính hiệu quả cao nhất đối với các nhiệm vụ cụ thể theo miền.

[Bảng 5 với kết quả nghiên cứu loại bỏ]

7 PHÂN TÍCH KIẾN THỨC MIỀN VÀ KHẢ NĂNG NHẮC NHỞ

Thiết kế hiểu đọc của chúng tôi là để học kiến thức cụ thể theo miền từ các văn bản thô và nâng cao khả năng nhắc nhở từ các nhiệm vụ hiểu. Trong phần này, chúng tôi tiến hành phân tích về hai khía cạnh tương ứng.

[Hình 3 với kết quả đánh giá tinh chỉnh và nhắc nhở]

Kiến thức Miền. Ngoài đánh giá nhắc nhở trong Phần 5 và 6, chúng tôi tiến hành các đánh giá tinh chỉnh và thăm dò kiến thức để đánh giá liệu việc tiếp tục huấn luyện trên các văn bản hiểu đọc có trang bị cho mô hình chung kiến thức miền hay không. Như được thể hiện trong kết quả tinh chỉnh trong Hình 3, sau khi huấn luyện trên các văn bản hiểu đọc, mô hình liên tục thể hiện kết quả cải thiện trên các nhiệm vụ cụ thể theo miền. Các cải tiến tinh chỉnh và thăm dò kiến thức (chi tiết trong Phụ lục A) cung cấp bằng chứng thực nghiệm rằng các văn bản hiểu đọc thực sự truyền đạt cho mô hình chung kiến thức miền.

Đáng chú ý, Hiểu Đọc vượt trội Văn bản Thô trong tất cả các miền được thích ứng trong kết quả tinh chỉnh. Điều này có thể do việc bao gồm các nhiệm vụ hiểu đa dạng tự nhiên tạo ra một cài đặt "tinh chỉnh hướng dẫn đa nhiệm vụ", có lợi cho việc tinh chỉnh nhiệm vụ đơn (Longpre và cộng sự, 2023a).

Khả năng Nhắc nhở. Cách tiếp cận của chúng tôi tập trung vào việc nâng cao khả năng nhắc nhở thông qua các nhiệm vụ hiểu. Để đánh giá tính hiệu quả của chúng, chúng tôi sử dụng các bộ đánh giá LLM chung để đánh giá hiệu suất nhắc nhở zero-shot. Cụ thể, chúng tôi đánh giá ít nhất ba nhiệm vụ chung cho mỗi loại nhiệm vụ hiểu, theo cài đặt phân cụm nhiệm vụ trong FLAN (Wei và cộng sự, 2022). Bên cạnh đó, chúng tôi đánh giá hiệu suất trên các nhiệm vụ Hiểu đọc chung và Trả lời câu hỏi đóng sách để đánh giá khả năng trả lời câu hỏi có hoặc không có bối cảnh.

Hình 3 trình bày điểm số nhiệm vụ trung bình trong mỗi loại nhiệm vụ, sau đó được tính trung bình trên ba mô hình ngôn ngữ được thích ứng. Việc chuyển đổi các văn bản thô thành các văn bản hiểu đọc liên tục cải thiện hiệu suất nhắc nhở trên tất cả các loại nhiệm vụ. Đáng chú ý, khi được huấn luyện trên các văn bản hiểu đọc cụ thể theo miền của chúng tôi (không bao gồm các hướng dẫn chung), chúng tôi đạt được kết quả thậm chí tốt hơn mô hình ngôn ngữ chung trên hầu hết các loại nhiệm vụ. Điều này làm nổi bật tiềm năng của cách tiếp cận chúng tôi trong việc phát triển một mô hình ngôn ngữ chung trên nhiều miền hơn. Trong Phụ lục E, chúng tôi cung cấp các nghiên cứu loại bỏ cho từng loại nhiệm vụ hiểu để phân tích tác động của nó đối với các nhiệm vụ hạ nguồn liên quan.

8 CÔNG TRÌNH LIÊN QUAN

Các công trình gần đây áp dụng các mô hình ngôn ngữ lớn vào các miền cụ thể (Singhal và cộng sự, 2022; 2023; Li và cộng sự, 2023b; Wu và cộng sự, 2023a; Li và cộng sự, 2023a; Wang và cộng sự, 2023; Xiong và cộng sự, 2023; Wu và cộng sự, 2023b; Yang và cộng sự, 2023; Cui và cộng sự, 2023; Huang và cộng sự, 2023) có thể được phân loại thành ba cách tiếp cận chính: huấn luyện từ đầu, tinh chỉnh hướng dẫn và nhắc nhở tăng cường truy xuất.

Huấn luyện từ Đầu. Huấn luyện một mô hình ngôn ngữ cụ thể theo miền từ đầu là một cách tiếp cận trực quan để thực hiện chuyên môn hóa miền. BloombergGPT (Wu và cộng sự, 2023b) đại diện cho một ví dụ sớm về các mô hình ngôn ngữ lớn trong miền tài chính, được huấn luyện trên hỗn hợp các kho dữ liệu tài chính và chung. Nó thể hiện hiệu suất tuyệt vời trên các nhiệm vụ tài chính mà không hy sinh hiệu suất trên các bộ đánh giá LLM chung. Tuy nhiên, các nghiên cứu (Yang và cộng sự, 2023; Ling và cộng sự, 2023) đã chỉ ra rằng "huấn luyện từ đầu" đi kèm với các yêu cầu tính toán và dữ liệu đắt đỏ, điều này thúc đẩy nhu cầu về các phương pháp thích ứng chi phí thấp như tinh chỉnh hoặc tiếp tục tiền huấn luyện.

Tinh chỉnh Hướng dẫn. Tinh chỉnh các mô hình ngôn ngữ lớn trên các nhiệm vụ cụ thể theo miền, đặc biệt là những nhiệm vụ liên quan đến hướng dẫn trả lời câu hỏi, phục vụ như một phương pháp thích ứng hiệu quả về chi phí (Singhal và cộng sự, 2022; 2023; Li và cộng sự, 2023b;a; Wang và cộng sự, 2023; Han và cộng sự, 2023; Xiong và cộng sự, 2023; Huang và cộng sự, 2023). Tuy nhiên, các mô hình được tinh chỉnh với dữ liệu hạn chế có thể gặp khó khăn trong việc thu nhận đủ kiến thức miền. Do đó, việc tạo ra dữ liệu có giám sát quy mô lớn trở thành mục tiêu quan trọng. Các phương pháp trước đây sử dụng các LLM hiệu suất cao (OpenAI, 2023) để tạo ra các cặp trả lời câu hỏi (Li và cộng sự, 2023a), nhưng chi phí suy luận có thể đáng kể. Trong những tình huống như vậy, việc khai thác các kho dữ liệu cụ thể theo miền quy mô lớn là một hướng đầy hứa hẹn để thu nhận kiến thức miền.

Nhắc nhở Tăng cường Truy xuất. Tăng cường truy xuất nâng cao các LLM bằng cách tích hợp thông tin miền cụ thể bên ngoài mà không sửa đổi các tham số mô hình (Li và cộng sự, 2023b; Cui và cộng sự, 2023; Huang và cộng sự, 2023). Điều này cho phép các LLM trả lời tốt hơn các câu hỏi cụ thể theo miền và giải quyết các vấn đề như ảo giác. Điều quan trọng là cho phép các LLM có tùy chọn chấp nhận hoặc từ chối thông tin được truy xuất do tính không đầy đủ hoặc mâu thuẫn tiềm ẩn (Ling và cộng sự, 2023). Huấn luyện các LLM để kết hợp kiến thức miền có thể hỗ trợ trong việc đưa ra những quyết định chấp nhận hoặc từ chối có thông tin như vậy.

9 KẾT LUẬN

Bài báo này tập trung vào việc thích ứng các mô hình ngôn ngữ lớn thông qua việc tiếp tục huấn luyện trên các kho dữ liệu cụ thể theo miền. Chúng tôi đề xuất một phương pháp đơn giản để chuyển đổi các kho dữ liệu thô cụ thể theo miền quy mô lớn thành các văn bản hiểu đọc, cho phép mô hình thu nhận kiến thức miền từ các văn bản thô và nâng cao khả năng nhắc nhở thông qua các nhiệm vụ hiểu. Các thí nghiệm trong ba miền khác nhau xác nhận tính hiệu quả và khả năng tổng quát hóa của phương pháp này. Hơn nữa, các văn bản hiểu đọc nâng cao hiệu suất mô hình trên các bộ đánh giá LLM chung, gợi ý tiềm năng cải thiện các mô hình ngôn ngữ chung trên nhiều miền hơn. Chúng tôi hy vọng phương pháp của chúng tôi có thể truyền cảm hứng cho việc khám phá thêm về thích ứng các mô hình ngôn ngữ lớn với việc sử dụng các kho dữ liệu tiền huấn luyện quy mô lớn, trao quyền hiệu quả cho các mô hình ngôn ngữ cho các nhiệm vụ hạ nguồn trong các lĩnh vực chuyên môn.

TÀI LIỆU THAM KHẢO

[Danh sách tài liệu tham khảo đầy đủ với các trích dẫn nghiên cứu từ các tạp chí và hội nghị khoa học]

[Các phụ lục A-J với thông tin chi tiết về phương pháp, thí nghiệm và kết quả bổ sung]

[Tiếp tục bản dịch...]

0510152025303540
#Đường dẫn Lý luận Được lấy mẫu505560657075Độ chính xác (%)
MultiArith
0510152025303540
#Đường dẫn Lý luận Được lấy mẫu3336394245485154
SVAMP
0510152025303540
#Đường dẫn Lý luận Được lấy mẫu56586062
Commonsense QA
0510152025303540
#Đường dẫn Lý luận Được lấy mẫu505254565860
ARC (Challenge)
Giải mã tham lam (Đường dẫn đơn)
Tính nhất quán bản thân (Đường dẫn đa)

Hình 2: Tính nhất quán bản thân (màu xanh) cải thiện đáng kể độ chính xác so với CoT-prompting với giải mã tham lam (màu cam) trên các nhiệm vụ lý luận số học và thường thức, trên LaMDA-137B. Lấy mẫu số lượng cao hơn các đường dẫn lý luận đa dạng liên tục cải thiện độ chính xác lý luận.

GSM8K StrategyQA
Câu hỏi Henry đã dừng hai lần trong chuyến đi xe đạp 60 dặm của mình. Anh ấy dừng lần đầu sau 20 dặm. Lần dừng thứ hai của anh ấy là 15 dặm trước khi kết thúc chuyến đi. Anh ấy đã đi bao nhiêu dặm giữa lần dừng đầu tiên và thứ hai? Có hay không: Albany, Georgia có phải là Albany đông dân nhất ở Hoa Kỳ?

Giải mã
Tham lam Anh ấy đã đi tổng cộng 60 dặm. Anh ấy dừng sau 20 dặm, vì vậy anh ấy đã đi 60 - 20 = 40 dặm giữa lần dừng đầu tiên và thứ hai. Câu trả lời là 40. Albany, Georgia là Albany đông dân nhất ở Hoa Kỳ. Do đó, câu trả lời là có.

Đường dẫn 
được lấy mẫu 1 Henry đã đi tổng cộng 60 dặm. Lần dừng đầu tiên của anh ấy là ở dặm 20, và lần dừng thứ hai là 15 dặm trước khi kết thúc. Vì vậy giữa lần dừng đầu tiên và thứ hai anh ấy đã đi 60 - 20 - 15 = 25 dặm. Câu trả lời là 25. Albany đông dân nhất ở Hoa Kỳ là Albany, New York. Do đó, Albany, Georgia không phải là Albany đông dân nhất ở Hoa Kỳ. Vậy câu trả lời là không.

Đường dẫn 
được lấy mẫu 2 Anh ấy đã dừng hai lần trong chuyến đi 60 dặm. Lần đầu là ở dặm 20 của chuyến đi. Lần thứ hai là 15 dặm trước khi kết thúc chuyến đi. Điều này có nghĩa là lần dừng thứ hai là ở dặm 60 - 15 = 45 của chuyến đi. Vì anh ấy dừng theo thứ tự, lần dừng thứ hai phải là 45 - 20 = 25 dặm sau lần dừng đầu tiên. Câu trả lời là 25. Albany, Georgia có dân số khoảng 88,000. Albany, New York có dân số khoảng 95,000. Do đó, Albany, Georgia không phải là Albany đông dân nhất ở Hoa Kỳ. Vậy câu trả lời là không.

Bảng 4: Các ví dụ trong đó tính nhất quán bản thân giúp sửa chữa các lỗi so với giải mã tham lam, trên PaLM-540B. Hai đường dẫn lý luận được lấy mẫu nhất quán với sự thật cơ bản được hiển thị.

3.3 TÍNH NHẤT QUÁN BẢN THÂN GIÚP ÍCH KHI CHUỖI SỬ DUY NGHĨ LÀM GIẢM HIỆU SUẤT

Ye & Durrett (2022) cho thấy đôi khi prompting chuỗi suy nghĩ có thể làm tổn hại hiệu suất so với prompting tiêu chuẩn trong few-shot in-context learning. Ở đây chúng tôi thực hiện một nghiên cứu sử dụng tính nhất quán bản thân để xem liệu nó có thể giúp lấp đầy khoảng trống, trên một tập hợp các nhiệm vụ NLP phổ biến, bao gồm (1) Trả lời Câu hỏi Sách đóng: BoolQ (Clark et al., 2019), HotpotQA (Yang et al., 2018), và (2) Suy luận Ngôn ngữ Tự nhiên: e-SNLI (Camburu et al., 2018), ANLI (Nie et al., 2020) và RTE (Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009).

Kết quả trên PaLM-540B được hiển thị trong Bảng 5. Đối với một số nhiệm vụ (ví dụ, ANLI-R1, e-SNLI, RTE), việc thêm chuỗi suy nghĩ thực sự làm tổn hại hiệu suất so với prompting tiêu chuẩn (Brown et al., 2020), nhưng tính nhất quán bản thân có thể mạnh mẽ tăng cường hiệu suất và vượt trội hơn prompting tiêu chuẩn, làm cho nó trở thành một cách đáng tin cậy để thêm lý lẽ trong few-shot in-context learning cho các nhiệm vụ NLP phổ biến.

ANLI R1 / R2 / R3 e-SNLI RTE BoolQ HotpotQA (EM/F1)
Standard-prompting (không có lý lẽ) 69.1 / 55.8 / 55.8 85.8 84.8 71.3 27.1 / 36.8
CoT-prompting (Wei et al., 2022) 68.8 / 58.9 / 60.6 81.0 79.1 74.2 28.9 / 39.8
Tính nhất quán bản thân 78.5 /64.5 /63.4 88.4 86.3 78.4 33.8 / 44.6

Bảng 5: So sánh Standard/CoT prompting với tính nhất quán bản thân trên các nhiệm vụ NLP phổ biến.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

3.4 SO SÁNH VỚI CÁC CÁCH TIẾP CẬN HIỆN CÓ KHÁC

Chúng tôi tiến hành một tập hợp các nghiên cứu bổ sung và cho thấy rằng tính nhất quán bản thân vượt trội đáng kể so với các phương pháp hiện có bao gồm sample-and-rank, beam search, và các cách tiếp cận dựa trên ensemble.

So sánh với Sample-and-Rank Một cách tiếp cận thường được sử dụng để cải thiện chất lượng tạo sinh là sample-and-rank, trong đó nhiều chuỗi được lấy mẫu từ bộ giải mã và sau đó được xếp hạng theo xác suất log của mỗi chuỗi (Adiwardana et al., 2020). Chúng tôi so sánh tính nhất quán bản thân với sample-and-rank trên GPT-3 code-davinci-001, bằng cách lấy mẫu cùng số lượng chuỗi từ bộ giải mã như tính nhất quán bản thân và lấy câu trả lời cuối cùng từ chuỗi được xếp hạng cao nhất. Kết quả được hiển thị trong Hình 3. Trong khi sample-and-rank thực sự cải thiện độ chính xác với các chuỗi được lấy mẫu bổ sung và xếp hạng, lợi ích nhỏ hơn nhiều so với tính nhất quán bản thân.

0510152025303540
#Đường dẫn Lý luận Được lấy mẫu12141618202224Độ chính xác (%)
GSM8K
0510152025303540
#Đường dẫn Lý luận Được lấy mẫu50556065707580Độ chính xác (%)
MultiArith
0510152025303540
#Đường dẫn Lý luận Được lấy mẫu303540455055Độ chính xác (%)
ARC (Challenge)
Tính nhất quán bản thân (Đường dẫn đa)
Sample & Rank (Đường dẫn đa)
Giải mã tham lam (Đường dẫn đơn)

Hình 3: Tính nhất quán bản thân vượt trội đáng kể so với sample-and-rank với cùng # mẫu.

So sánh với Beam Search Trong Bảng 6, chúng tôi so sánh tính nhất quán bản thân với giải mã beam search trên mô hình UL2-20B. Để có một so sánh công bằng, chúng tôi báo cáo độ chính xác dưới cùng số lượng beam và đường dẫn lý luận. Trên cả hai nhiệm vụ, tính nhất quán bản thân vượt trội hơn beam search đáng kể. Lưu ý tính nhất quán bản thân cũng có thể áp dụng beam search để giải mã mỗi đường dẫn lý luận (kết quả được hiển thị là "Tính nhất quán bản thân sử dụng beam search"), nhưng hiệu suất của nó tệ hơn so với tính nhất quán bản thân với lấy mẫu. Lý do là beam search mang lại đa dạng thấp hơn trong các đầu ra (Li & Jurafsky, 2016), trong khi trong tính nhất quán bản thân, đa dạng của các đường dẫn lý luận là chìa khóa cho hiệu suất tốt hơn.

Kích thước Beam / Đường dẫn tính nhất quán bản thân 1 5 10 20 40
AQuAGiải mã beam search (beam hàng đầu) 23.6 19.3 16.1 15.0 10.2
Tính nhất quán bản thân sử dụng beam search 23.6 19.8 0.321.20.724.60.424.20.5
Tính nhất quán bản thân sử dụng lấy mẫu 19.7 2.524.92.625.31.826.71.026.90.5
MultiArithGiải mã beam search (beam hàng đầu) 10.7 12.0 11.3 11.0 10.5
Tính nhất quán bản thân sử dụng beam search 10.7 11.8 0.011.40.112.30.110.80.1
Tính nhất quán bản thân sử dụng lấy mẫu 9.5 1.2 11.31.212.30.813.70.914.70.3

Bảng 6: So sánh tính nhất quán bản thân với giải mã beam search trên mô hình UL2-20B.

So sánh với Các Cách tiếp cận Dựa trên Ensemble Chúng tôi tiếp tục so sánh tính nhất quán bản thân với các phương pháp dựa trên ensemble cho few-shot learning. Đặc biệt, chúng tôi xem xét ensemble bằng: (1) hoán vị thứ tự prompt: chúng tôi hoán vị ngẫu nhiên các mẫu trong prompt 40 lần để giảm thiểu độ nhạy cảm của mô hình với thứ tự prompt (Zhao et al., 2021; Lu et al., 2021); và (2) nhiều tập prompt (Gao et al., 2021): chúng tôi viết thủ công 3 tập prompt khác nhau. Chúng tôi lấy bỏ phiếu đa số của các câu trả lời từ giải mã tham lam trong cả hai cách tiếp cận như một ensemble. Bảng 7 cho thấy so với tính nhất quán bản thân, các cách tiếp cận ensemble hiện có đạt được lợi ích nhỏ hơn nhiều.⁸ Ngoài ra, lưu ý rằng tính nhất quán bản thân khác với một cách tiếp cận model-ensemble điển hình, trong đó nhiều mô hình được huấn luyện và các đầu ra của chúng được tổng hợp. Tính nhất quán bản thân hoạt động giống như một "self-ensemble" trên một mô hình ngôn ngữ đơn lẻ. Chúng tôi bổ sung hiển thị kết quả của việc ensemble nhiều mô hình trong Phụ lục A.1.3 trong đó các model-ensemble hoạt động tệ hơn nhiều so với tính nhất quán bản thân.

GSM8K MultiArith SVAMP ARC-e ARC-c
CoT (Wei et al., 2022) 17.1 51.8 38.9 75.3 55.1
Ensemble (3 tập prompt) 18.6 0.5 57.10.7 42.10.6 76.60.1 57.00.2
Ensemble (40 hoán vị prompt) 19.2 0.1 60.90.2 42.70.1 76.90.1 57.00.1
Tính nhất quán bản thân (40 đường dẫn được lấy mẫu) 27.70.2 75.70.3 53.30.2 79.30.3 59.80.2

Bảng 7: Tính nhất quán bản thân vượt trội hơn ensemble thứ tự prompt và đa prompt trên LaMDA-137B.

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

3.5 CÁC NGHIÊN CỨU BỔ SUNG

Chúng tôi tiến hành một số thí nghiệm bổ sung để phân tích các khía cạnh khác nhau của phương pháp tính nhất quán bản thân, bao gồm tính mạnh mẽ của nó đối với các chiến lược và tham số lấy mẫu, và cách nó hoạt động với các prompt không hoàn hảo và các đường dẫn lý luận không phải ngôn ngữ tự nhiên.

Tính nhất quán bản thân Mạnh mẽ với Các Chiến lược Lấy mẫu và Quy mô Chúng tôi cho thấy tính nhất quán bản thân mạnh mẽ với các chiến lược và tham số lấy mẫu, bằng cách thay đổi T trong lấy mẫu nhiệt độ (Ackley et al., 1985; Ficler & Goldberg, 2017), k trong lấy mẫu top-k (Fan et al., 2018; Holtzman et al., 2018; Radford et al., 2019), và p trong lấy mẫu nucleus (Holtzman et al., 2020), trên PaLM-540B trong Hình 4 (trái). Hình 4 (phải) cho thấy tính nhất quán bản thân mạnh mẽ cải thiện hiệu suất trên tất cả các quy mô cho loạt mô hình LaMDA-137B. Lợi ích tương đối thấp hơn đối với các mô hình nhỏ hơn do một số khả năng (ví dụ, số học) chỉ xuất hiện khi mô hình đạt đến quy mô đủ (Brown et al., 2020).

0510152025303540
#Đường dẫn Lý luận Được lấy mẫu444852566064687276Độ chính xác (%)
T=0.7, k=40
T=0.5, k=40
T=0.3, k=40
T=0.7, k=20
T=0.7, không có top k
p=0.95
p=0.9
Giải mã tham lam
12 51020 50100200
Kích thước mô hình (#param tính bằng tỷ)510152025Độ chính xác (%)
Tính nhất quán bản thân
Giải mã tham lam

Hình 4: Độ chính xác GSM8K. (Trái) Tính nhất quán bản thân mạnh mẽ với nhiều chiến lược và tham số lấy mẫu khác nhau. (Phải) Tính nhất quán bản thân cải thiện hiệu suất trên các quy mô mô hình ngôn ngữ.

Tính nhất quán bản thân Cải thiện Tính mạnh mẽ với Prompt Không hoàn hảo Đối với few-shot learning với các prompt được xây dựng thủ công, các chú thích viên con người đôi khi mắc lỗi nhỏ khi tạo các prompt. Chúng tôi tiếp tục nghiên cứu liệu tính nhất quán bản thân có thể giúp cải thiện tính mạnh mẽ của mô hình ngôn ngữ đối với các prompt không hoàn hảo.⁹ Chúng tôi hiển thị kết quả trong Bảng 8: trong khi các prompt không hoàn hảo làm giảm độ chính xác với giải mã tham lam (17.1 → 14.9), tính nhất quán bản thân có thể lấp đầy các khoảng trống và mạnh mẽ cải thiện kết quả.

Ngoài ra, chúng tôi thấy rằng tính nhất quán (về % giải mã đồng ý với câu trả lời được tổng hợp cuối cùng) có tương quan cao với độ chính xác (Hình 5, trên GSM8K). Điều này cho thấy rằng người ta có thể sử dụng tính nhất quán bản thân để cung cấp ước tính độ không chắc chắn của mô hình trong các giải pháp được tạo của nó. Nói cách khác, người ta có thể sử dụng tính nhất quán thấp như một chỉ báo rằng mô hình có độ tin cậy thấp; tức là, tính nhất quán bản thân mang lại một số khả năng cho mô hình "biết khi nào nó không biết".

LaMDA-137BPrompt với chuỗi suy nghĩ đúng 17.1
Prompt với chuỗi suy nghĩ không hoàn hảo 14.9
+ Tính nhất quán bản thân (40 đường dẫn) 23.4
Prompt với phương trình 5.0
+ Tính nhất quán bản thân (40 đường dẫn) 6.5
PaLM-540BZero-shot CoT (Kojima et al., 2022) 43.0
+ Tính nhất quán bản thân (40 đường dẫn) 69.2

Bảng 8: Tính nhất quán bản thân hoạt động dưới các prompt không hoàn hảo, prompt phương trình và zero-shot chain-of-thought cho GSM8K.

0 20 40 60 80 100
Tính nhất quán (%)020406080100Độ chính xác (%)

Hình 5: Tính nhất quán có tương quan với độ chính xác của mô hình.

Tính nhất quán bản thân Hoạt động cho Đường dẫn Lý luận Không phải Ngôn ngữ Tự nhiên và Zero-shot CoT Chúng tôi cũng kiểm tra tính tổng quát của khái niệm tính nhất quán bản thân đối với các hình thức lý luận trung gian thay thế như phương trình (ví dụ, từ "Đã có 3 chiếc xe trong bãi đậu xe. 2 chiếc nữa đến. Bây giờ có 3 + 2 = 5 chiếc xe." thành "3 + 2 = 5"). Kết quả được hiển thị trong Bảng 8 ("Prompt với phương trình"): tính nhất quán bản thân vẫn cải thiện độ chính xác bằng cách tạo ra các phương trình trung gian; tuy nhiên, so với việc tạo ra các đường dẫn lý luận ngôn ngữ tự nhiên, lợi ích nhỏ hơn vì các phương trình ngắn hơn nhiều và ít cơ hội hơn để tạo ra đa dạng trong quá trình giải mã. Ngoài ra, chúng tôi kiểm tra tính nhất quán bản thân với zero-shot chain-of-thought (Kojima et al., 2022) và cho thấy tính nhất quán bản thân cũng hoạt động cho zero-shot CoT và cải thiện kết quả đáng kể (+26.2%) trong Bảng 8.

⁸Tính nhất quán bản thân tương thích với cả hai cách tiếp cận ensemble và chúng tôi hiển thị kết quả trong Phụ lục A.1.4.

⁹Chúng tôi sử dụng cùng các prompt như trước, nhưng hoán đổi tất cả các số trong các đường dẫn lý luận với các số ngẫu nhiên trừ câu trả lời cuối cùng, ví dụ, từ "Đã có 3 chiếc xe trong bãi đậu xe. 2 chiếc nữa đến. Bây giờ có 3 + 2 = 5 chiếc xe." thành "Đã có 7 chiếc xe trong bãi đậu xe. 6 chiếc nữa đến. Bây giờ có 7 + 6 = 5 chiếc xe.".

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

4 CÔNG TRÌNH LIÊN QUAN

Lý luận trong các mô hình ngôn ngữ. Các mô hình ngôn ngữ được biết là gặp khó khăn trong các nhiệm vụ Loại 2, chẳng hạn như lý luận số học, logic và thường thức (Evans, 2010). Công trình trước đây chủ yếu tập trung vào các cách tiếp cận chuyên biệt để cải thiện lý luận (Andor et al., 2019; Ran et al., 2019; Geva et al., 2020; Piękos et al., 2021). So với công trình trước đây, tính nhất quán bản thân có thể áp dụng cho một loạt rộng các nhiệm vụ lý luận mà không cần bất kỳ giám sát hoặc tinh chỉnh bổ sung nào, đồng thời vẫn cải thiện đáng kể hiệu suất của cách tiếp cận prompting chuỗi suy nghĩ được đề xuất trong Wei et al. (2022).

Lấy mẫu và tái xếp hạng trong các mô hình ngôn ngữ. Nhiều chiến lược giải mã khác nhau cho các mô hình ngôn ngữ đã được đề xuất trong văn học, ví dụ, lấy mẫu nhiệt độ (Ackley et al., 1985; Ficler & Goldberg, 2017), lấy mẫu top-k (Fan et al., 2018; Holtzman et al., 2018; Radford et al., 2019), lấy mẫu nucleus (Holtzman et al., 2020), giải mã rủi ro Bayes tối thiểu (Eikema & Aziz, 2020; Shi et al., 2022), và giải mã điển hình (Meister et al., 2022). Công trình khác đã tìm cách thúc đẩy đa dạng một cách rõ ràng trong quá trình giải mã (Batra et al., 2012; Li et al., 2016; Vijayakumar et al., 2018).

Tái xếp hạng là một cách tiếp cận phổ biến khác để cải thiện chất lượng tạo sinh trong các mô hình ngôn ngữ (Adiwardana et al., 2020; Shen et al., 2021). Thoppilan et al. (2022) thu thập các chú thích con người bổ sung để huấn luyện một bộ tái xếp hạng cho việc lọc phản hồi. Cobbe et al. (2021) huấn luyện một "bộ xác minh" để tái xếp hạng các giải pháp được tạo ra, điều này cải thiện đáng kể tỷ lệ giải quyết trên các nhiệm vụ toán học so với chỉ tinh chỉnh mô hình ngôn ngữ. Elazar et al. (2021) cải thiện tính nhất quán của việc trích xuất kiến thức thực tế bằng cách mở rộng việc huấn luyện trước với một loss nhất quán bổ sung. Tất cả các phương pháp này yêu cầu hoặc huấn luyện một bộ tái xếp hạng bổ sung hoặc thu thập chú thích con người bổ sung, trong khi tính nhất quán bản thân không yêu cầu huấn luyện bổ sung, tinh chỉnh, hoặc thu thập dữ liệu thêm.

Trích xuất đường dẫn lý luận. Một số công trình trước đây đã xem xét các cách tiếp cận cụ thể theo nhiệm vụ để xác định các đường dẫn lý luận, chẳng hạn như xây dựng đồ thị ngữ nghĩa (Xu et al., 2021a), học một RNN để truy xuất các đường dẫn lý luận trên đồ thị Wikipedia (Asai et al., 2020), tinh chỉnh với các đường dẫn lý luận được chú thích bởi con người trên các bài toán toán học (Cobbe et al., 2021), hoặc huấn luyện một bộ trích xuất với các đường dẫn lý luận giả dựa trên heuristic (Chen et al., 2019). Gần đây hơn, tầm quan trọng của đa dạng trong các quá trình lý luận đã được chú ý, nhưng chỉ được tận dụng thông qua huấn luyện cụ thể theo nhiệm vụ, hoặc thông qua một mô hình QA bổ sung trên các đường dẫn lý luận được trích xuất (Chen et al., 2019), hoặc bằng việc giới thiệu các biến tiềm ẩn trong một đồ thị kiến thức thường thức (Yu et al., 2022). So với các cách tiếp cận này, tính nhất quán bản thân đơn giản hơn nhiều và không yêu cầu huấn luyện bổ sung. Cách tiếp cận chúng tôi đề xuất chỉ đơn giản kết hợp việc tạo ra các đường dẫn lý luận và một câu trả lời cuối cùng bằng cách lấy mẫu từ bộ giải mã, sử dụng tổng hợp để khôi phục câu trả lời nhất quán nhất mà không cần các mô-đun bổ sung.

Tính nhất quán trong các mô hình ngôn ngữ. Một số công trình trước đây đã cho thấy rằng các mô hình ngôn ngữ có thể gặp phải sự không nhất quán trong hội thoại (Adiwardana et al., 2020), tạo ra giải thích (Camburu et al., 2020), và trích xuất kiến thức thực tế (Elazar et al., 2021). Welleck et al. (2020) sử dụng "tính nhất quán" để đề cập đến việc tạo ra một chuỗi có độ dài vô hạn trong các mô hình ngôn ngữ lặp lại. Nye et al. (2021) cải thiện tính nhất quán logic của các mẫu từ một mô hình System 1 bằng cách thêm một mô-đun lý luận logic lấy cảm hứng từ System 2. Trong bài báo này, chúng tôi tập trung vào một khái niệm "tính nhất quán" hơi khác, tức là, sử dụng tính nhất quán câu trả lời trong số các đường dẫn lý luận đa dạng để cải thiện độ chính xác.

5 KẾT LUẬN VÀ THẢO LUẬN

Chúng tôi đã giới thiệu một phương pháp đơn giản nhưng hiệu quả được gọi là tính nhất quán bản thân, và quan sát thấy rằng nó cải thiện đáng kể độ chính xác trong một loạt các nhiệm vụ lý luận số học và thường thức, trên bốn mô hình ngôn ngữ lớn với các quy mô khác nhau. Ngoài những lợi ích về độ chính xác, tính nhất quán bản thân cũng hữu ích để thu thập lý lẽ khi thực hiện các nhiệm vụ lý luận với các mô hình ngôn ngữ, và để cung cấp ước tính độ không chắc chắn và cải thiện hiệu chuẩn của các đầu ra mô hình ngôn ngữ.

Một hạn chế của tính nhất quán bản thân là nó phát sinh chi phí tính toán nhiều hơn. Trong thực tế, mọi người có thể thử một số lượng nhỏ các đường dẫn (ví dụ, 5 hoặc 10) như một điểm khởi đầu để nhận ra hầu hết các lợi ích trong khi không phát sinh quá nhiều chi phí, vì trong hầu hết các trường hợp hiệu suất bão hòa nhanh chóng (Hình 2). Như một phần của công việc tương lai, người ta có thể sử dụng tính nhất quán bản thân để tạo ra dữ liệu có giám sát tốt hơn để tinh chỉnh mô hình, sao cho mô hình có thể đưa ra dự đoán chính xác hơn trong một lần chạy suy luận đơn lẻ sau khi tinh chỉnh. Ngoài ra, chúng tôi quan sát thấy rằng các mô hình ngôn ngữ đôi khi có thể tạo ra các đường dẫn lý luận không chính xác hoặc vô nghĩa (ví dụ, ví dụ StrategyQA trong Bảng 4, hai số dân số không hoàn toàn chính xác), và cần thêm công việc để neo tốt hơn việc tạo ra lý lẽ của các mô hình.

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

TUYÊN BỐ KHẢ NĂNG TÁI TẠO

Trong các thí nghiệm, chúng tôi đã bao gồm bốn mô hình ngôn ngữ khác nhau với các quy mô khác nhau. Hai trong số chúng là các mô hình công khai: UL2 là một mô hình hoàn toàn mở nguồn với các checkpoint mô hình có sẵn tại https://github.com/google-research/google-research/tree/master/ul2; GPT-3 cũng là một mô hình công khai với API công khai có sẵn tại https://openai.com/api/. Đối với GPT-3, chúng tôi đã bao gồm hai động cơ công khai ("code-davinci-001" và "code-davinci-002") để hỗ trợ thêm khả năng tái tạo, vì Codex hiện tại miễn phí nên bất kỳ ai cũng có thể tái tạo kết quả. Ngoài ra, vì kết quả của chúng tôi sử dụng LaMDA-137B và PaLM-540B không có sẵn công khai, chúng tôi cung cấp các prompt đầu vào chính xác cho tất cả các nhiệm vụ trong Phụ lục A.3 (và lưu ý rằng chúng tôi không thực hiện bất kỳ tinh chỉnh nào và chỉ áp dụng prompting cho các mô hình ngôn ngữ có sẵn).

TUYÊN BỐ ĐẠO ĐỨC

Như chúng tôi đã nêu trong thảo luận, các mô hình ngôn ngữ đôi khi có thể tạo ra các đường dẫn lý luận vô nghĩa hoặc không thực tế, vì vậy người ta nên sử dụng các đầu ra của mô hình ngôn ngữ với sự thận trọng thêm. Chúng tôi xử lý các nhiệm vụ lý luận chủ yếu và các lý lẽ được tạo ra chỉ được sử dụng để kiểm tra cách một mô hình đạt đến câu trả lời của nó. Người ta có thể tiềm năng sử dụng các lý lẽ được tạo ra để kiểm tra thêm tại sao mô hình mắc những lỗi nhất định hoặc liệu mô hình có chứa bất kỳ thành kiến nào khi thực hiện một nhiệm vụ nhất định. Đối với mô hình ngôn ngữ trong việc sử dụng thế giới thực, cần thêm công việc để neo tốt hơn các dự đoán của mô hình và cải thiện tính thực tế và an toàn của mô hình, để đảm bảo các mô hình không gây tổn hại cho người dùng.

TÀI LIỆU THAM KHẢO

David H. Ackley, Geoffrey E. Hinton, và Terrence J. Sejnowski. A learning algorithm for boltzmann machines. Cognitive Science, 9(1):147–169, 1985. ISSN 0364-0213. URL https://www.sciencedirect.com/science/article/pii/S0364021385800124.

Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, và Quoc V. Le. Towards a human-like open-domain chatbot, 2020.

Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, và Hannaneh Hajishirzi. MathQA: Towards interpretable math word problem solving with operation-based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 2357–2367. Association for Computational Linguistics, June 2019. URL https://aclanthology.org/N19-1245.

Daniel Andor, Luheng He, Kenton Lee, và Emily Pitler. Giving BERT a calculator: Finding operations and arguments with reading comprehension. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019. URL https://aclanthology.org/D19-1609.

Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, và Caiming Xiong. Learning to retrieve reasoning paths over wikipedia graph for question answering. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=SJgVHkrYDH.

Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, và Idan Szpektor. The second pascal recognising textual entailment challenge. In Proceedings of the second PASCAL challenges workshop on recognising textual entailment, 2006.

Dhruv Batra, Payman Yadollahpour, Abner Guzman-Rivera, và Gregory Shakhnarovich. Diverse m-best solutions in markov random fields. In Proceedings of the 12th European Conference on Computer Vision - Volume Part V, ECCV'12, pp. 1–16, Berlin, Heidelberg, 2012. Springer-Verlag. ISBN 9783642337147. URL https://doi.org/10.1007/978-3-642-33715-4_1.

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Luisa Bentivogli, Peter Clark, Ido Dagan, và Danilo Giampiccolo. The fifth pascal recognizing textual entailment challenge. In TAC, 2009.

BIG-bench collaboration. Beyond the imitation game: Measuring and extrapolating the capabilities of language models. In preparation, 2021. URL https://github.com/google/BIG-bench/.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. In Advances in Neural Information Processing Systems, 2020. URL https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, và Phil Blunsom. e-snli: Natural language inference with natural language explanations. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, và R. Garnett (eds.), Advances in Neural Information Processing Systems 31, pp. 9539–9549. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/8163-e-snli-natural-language-inference-with-natural-language-explanations.pdf.

Oana-Maria Camburu, Brendan Shillingford, Pasquale Minervini, Thomas Lukasiewicz, và Phil Blunsom. Make up your mind! adversarial generation of inconsistent natural language explanations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4157–4165, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.382. URL https://aclanthology.org/2020.acl-main.382.

Jifan Chen, Shih-Ting Lin, và Greg Durrett. Multi-hop question answering via reasoning chains. CoRR, abs/1910.02610, 2019. URL http://arxiv.org/abs/1910.02610.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, và Noah Fiedel. Palm: Scaling language modeling with pathways, 2022. URL https://arxiv.org/abs/2204.02311.

Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, và Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions. In NAACL, 2019.

Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. ArXiv, abs/1803.05457, 2018.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, và John Schulman. Training verifiers to solve math word problems, 2021.

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Ido Dagan, Oren Glickman, và Bernardo Magnini. The pascal recognising textual entailment challenge. In Machine Learning Challenges Workshop, pp. 177–190. Springer, 2005.

Bryan Eikema và Wilker Aziz. Is MAP decoding all you need? the inadequacy of the mode in neural machine translation. In Proceedings of the 28th International Conference on Computational Linguistics, pp. 4506–4520, Barcelona, Spain (Online), December 2020. International Committee on Computational Linguistics. URL https://aclanthology.org/2020.coling-main.398.

Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich Schütze, và Yoav Goldberg. Measuring and improving consistency in pretrained language models. Transactions of the Association for Computational Linguistics, 9:1012–1031, 2021. doi: 10.1162/tacl_a_00410. URL https://aclanthology.org/2021.tacl-1.60.

Jonathan St BT Evans. Intuition and reasoning: A dual-process perspective. Psychological Inquiry, 21(4):313–326, 2010.

Angela Fan, Mike Lewis, và Yann Dauphin. Hierarchical neural story generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 889–898, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1082. URL https://aclanthology.org/P18-1082.

Jessica Ficler và Yoav Goldberg. Controlling linguistic style aspects in neural language generation. In Proceedings of the Workshop on Stylistic Variation, pp. 94–104, Copenhagen, Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/W17-4912. URL https://aclanthology.org/W17-4912.

Tianyu Gao, Adam Fisch, và Danqi Chen. Making pre-trained language models better few-shot learners. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 3816–3830, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.295. URL https://aclanthology.org/2021.acl-long.295.

Mor Geva, Ankit Gupta, và Jonathan Berant. Injecting numerical reasoning skills into language models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020. doi: 10.18653/v1/2020.acl-main.89. URL https://aclanthology.org/2020.acl-main.89.

Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, và Jonathan Berant. Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 2021. URL https://aclanthology.org/2021.tacl-1.21.

Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, và Bill Dolan. The third pascal recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing, pp. 1–9. Association for Computational Linguistics, 2007.

Ari Holtzman, Jan Buys, Maxwell Forbes, Antoine Bosselut, David Golub, và Yejin Choi. Learning to write with cooperative discriminators. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1638–1649, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1152. URL https://aclanthology.org/P18-1152.

Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. The curious case of neural text degeneration. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=rygGQyrFvH.

Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, và Nate Kushman. Learning to solve arithmetic word problems with verb categorization. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2014. doi: 10.3115/v1/D14-1058. URL https://aclanthology.org/D14-1058.

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, và Hannaneh Hajishirzi. UNIFIEDQA: Crossing format boundaries with a single QA system. In Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1896–1907, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.171. URL https://aclanthology.org/2020.findings-emnlp.171.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. Large language models are zero-shot reasoners. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=e2TBb5y0yFf.

Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, và Hannaneh Hajishirzi. MAWPS: A math word problem repository. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2016. doi: 10.18653/v1/N16-1136. URL https://aclanthology.org/N16-1136.

Yihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang, và Ee-Peng Lim. MWPToolkit: An open-source framework for deep learning-based math word problem solvers. arXiv preprint arXiv:2109.00799, 2021. URL https://arxiv.org/abs/2109.00799.

Jiwei Li và Dan Jurafsky. Mutual information and diverse decoding improve neural machine translation, 2016. URL https://arxiv.org/abs/1601.00372.

Jiwei Li, Will Monroe, và Dan Jurafsky. A simple, fast diverse decoding algorithm for neural generation. CoRR, abs/1611.08562, 2016. URL http://arxiv.org/abs/1611.08562.

Wang Ling, Dani Yogatama, Chris Dyer, và Phil Blunsom. Program induction by rationale generation: Learning to solve and explain algebraic word problems. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2017. doi: 10.18653/v1/P17-1015. URL https://aclanthology.org/P17-1015.

Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, và Pontus Stenetorp. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. ArXiv, abs/2104.08786, 2021.

Clara Meister, Tiago Pimentel, Gian Wiher, và Ryan Cotterell. Typical decoding for natural language generation. arXiv preprint arXiv:2202.00666, 2022.

Shen Yun Miao, Chao Chun Liang, và Keh Yih Su. A diverse corpus for evaluating and developing English math word problem solvers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020. URL https://aclanthology.org/2020.acl-main.92.

Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, và Douwe Kiela. Adversarial NLI: A new benchmark for natural language understanding. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, 2020.

Maxwell Nye, Michael Henry Tessler, Joshua B. Tenenbaum, và Brenden M. Lake. Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning. In A. Beygelzimer, Y. Dauphin, P. Liang, và J. Wortman Vaughan (eds.), Advances in Neural Information Processing Systems, 2021. URL https://openreview.net/forum?id=uyKk_avJ-p4.

Arkil Patel, Satwik Bhattamishra, và Navin Goyal. Are NLP models really able to solve simple math word problems? In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2080–2094, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.168. URL https://aclanthology.org/2021.naacl-main.168.

Xinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, và Weizhu Chen. Reasoning like program executors, 2022.

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Piotr Piękos, Mateusz Malinowski, và Henryk Michalewski. Measuring and improving BERT's mathematical abilities by predicting the order of reasoning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 2021. doi: 10.18653/v1/2021.acl-short.49. URL https://aclanthology.org/2021.acl-short.49.

Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. Language models are unsupervised multitask learners. 2019.

Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models: Methods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446, 2021.

Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, và Zhiyuan Liu. NumNet: Machine reading comprehension with numerical reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019. doi: 10.18653/v1/D19-1251. URL https://aclanthology.org/D19-1251.

Subhro Roy và Dan Roth. Solving general arithmetic word problems. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, 2015. doi: 10.18653/v1/D15-1202. URL https://aclanthology.org/D15-1202.

Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, và Qun Liu. Generate & rank: A multi-task framework for math word problems. In Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 2269–2279, Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. URL https://aclanthology.org/2021.findings-emnlp.195.

Freda Shi, Daniel Fried, Marjan Ghazvininejad, Luke Zettlemoyer, và Sida I. Wang. Natural language to code translation with execution. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 3533–3546, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.emnlp-main.231.

Keith E Stanovich và Richard F West. Individual differences in reasoning: Implications for the rationality debate? Behavioral and brain sciences, 23(5):645–665, 2000. URL https://pubmed.ncbi.nlm.nih.gov/11301544/.

Alon Talmor, Jonathan Herzig, Nicholas Lourie, và Jonathan Berant. CommonsenseQA: A question answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019. URL https://aclanthology.org/N19-1421.

Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Dara Bahri, Tal Schuster, Steven Zheng, Denny Zhou, Neil Houlsby, và Donald Metzler. Unifying language learning paradigms, 2022. URL https://arxiv.org/abs/2205.05131.

Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239, 2022. URL https://arxiv.org/abs/2201.08239.

Ashwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, David Crandall, và Dhruv Batra. Diverse beam search for improved description of complex scenes. Proceedings of the AAAI Conference on Artificial Intelligence, 32, Apr. 2018. URL https://ojs.aaai.org/index.php/AAAI/article/view/12340.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, và Denny Zhou. Chain of thought prompting elicits reasoning in large language models. Conference on Neural Information Processing Systems (NeurIPS), 2022. URL https://arxiv.org/pdf/2201.11903.

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Sean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, và Kyunghyun Cho. Consistency of a recurrent language model with respect to incomplete decoding. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 5553–5568, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.448. URL https://aclanthology.org/2020.emnlp-main.448.

Weiwen Xu, Yang Deng, Huihui Zhang, Deng Cai, và Wai Lam. Exploiting reasoning chains for multi-hop science question answering. In Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 1143–1156, Punta Cana, Dominican Republic, November 2021a. Association for Computational Linguistics. URL https://aclanthology.org/2021.findings-emnlp.99.

Yichong Xu, Chenguang Zhu, Shuohang Wang, Siqi Sun, Hao Cheng, Xiaodong Liu, Jianfeng Gao, Pengcheng He, Michael Zeng, và Xuedong Huang. Human parity on commonsenseqa: Augmenting self-attention with external attention, 2021b. URL https://arxiv.org/abs/2112.03254.

Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, và Christopher D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2369–2380, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1259. URL https://aclanthology.org/D18-1259.

Xi Ye và Greg Durrett. The unreliability of explanations in few-shot prompting for textual reasoning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=Bct2f8fRd8S.

Wenhao Yu, Chenguang Zhu, Lianhui Qin, Zhihan Zhang, Tong Zhao, và Meng Jiang. Diversifying content generation for commonsense reasoning with mixture of knowledge graph experts. In Findings of Annual Meeting of the Association for Computational Linguistics (ACL), 2022.

Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, và Sameer Singh. Calibrate before use: Improving few-shot performance of language models. In Marina Meila và Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research. PMLR, 2021. URL https://proceedings.mlr.press/v139/zhao21c.html.

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

A PHỤ LỤC

A.1 KẾT QUẢ THÍ NGHIỆM BỔ SUNG

A.1.1 TÍNH MẠNH MẼ ĐỐI VỚI CÁC CHIẾN LƯỢC VÀ THAM SỐ LẤY MẪU

Trong Hình 6, chúng tôi ablate kết quả đối với các chiến lược và tham số lấy mẫu khác nhau bằng cách thay đổi T trong lấy mẫu nhiệt độ và k trong lấy mẫu Top-k, trên LaMDA-137B. Chúng tôi cho thấy rằng tính nhất quán bản thân mạnh mẽ với nhiều chiến lược và tham số lấy mẫu khác nhau.

481216202428323640
#Đường dẫn Lý luận Được lấy mẫu182022242628Độ chính xác (%)
T=0.7, k=40
T=0.5, k=40
T=0.3, k=40
T=0.5, k=20
T=0.5, không có top k
Giải mã tham lam

Hình 6: Độ chính xác GSM8K trên LaMDA-137B. Tính nhất quán bản thân hoạt động dưới nhiều chiến lược và tham số lấy mẫu khác nhau.

Trong Hình 7 và Hình 8, chúng tôi hiển thị kết quả của tính nhất quán bản thân so với giải mã tham lam một đường dẫn đơn trên LaMDA-137B và PaLM-540B, tương ứng. Tính nhất quán bản thân cải thiện so với giải mã tham lam với biên độ khá đáng kể trên cả hai mô hình, trên độ chính xác cao đã đạt được bằng cách mở rộng quy mô mô hình.

[Các biểu đồ và hình ảnh khác tiếp tục được dịch...]

Chúng tôi tiếp tục hiển thị các đường dẫn lý luận được lấy mẫu bổ sung từ mô hình LaMDA-137B trong Bảng 12, và các đường dẫn lý luận được lấy mẫu từ mô hình PaLM-540B trong Bảng 13. Chúng ta thấy rằng sự đa dạng trong các đường dẫn lý luận được lấy mẫu bổ sung thực sự giúp mô hình đạt đến một câu trả lời cuối cùng chính xác hơn sau khi tổng hợp.

A.1.2 TÍNH MẠNH MẼ ĐỐI VỚI CÁC TẬP PROMPT KHÁC NHAU

Trong Bảng 9, chúng tôi tiếp tục cho thấy rằng tính nhất quán bản thân khá mạnh mẽ với các tập prompt đầu vào khác nhau. Chúng tôi viết thủ công 3 tập chuỗi suy nghĩ khác nhau làm prompt cho mô hình. Trên tất cả các tập prompt, tính nhất quán bản thân mang lại những lợi ích nhất quán so với cách tiếp cận CoT gốc.

A.1.3 SO SÁNH VỚI CÁC MODEL ENSEMBLE

Ngoài ra, chúng tôi cung cấp kết quả của việc ensemble trực tiếp các đầu ra từ nhiều mô hình ngôn ngữ. Kết quả được hiển thị trong Bảng 10, bằng cách giải mã tham lam các chuỗi từ 3 mô hình ngôn ngữ và lấy bỏ phiếu đa số (trung bình trên 10 lần chạy). Lưu ý đây là một cách tiếp cận ensemble điển hình (lấy trung bình các dự đoán trên nhiều mô hình) và nó đạt được hiệu suất thấp hơn đáng kể so với tính nhất quán bản thân (tính nhất quán bản thân trên PaLM-540B đạt độ chính xác 74.4%), vì các mô hình có năng lực thấp hơn kéo xuống hiệu suất của các mô hình có năng lực cao hơn. Ngoài ra, cách tiếp cận này bị hạn chế theo hai cách: 1) Nó yêu cầu nhiều mô hình cho một ensemble có thể không luôn có sẵn, trong khi tính nhất quán bản thân chỉ yêu cầu một mô hình đơn lẻ để "self-ensemble"; 2) Nếu một trong các mô hình yếu hơn nhiều, nó thực sự có thể làm tổn hại hiệu suất cuối cùng.

[Tiếp tục với các bảng và nội dung khác...]

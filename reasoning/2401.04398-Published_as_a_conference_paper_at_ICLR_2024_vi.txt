# 2401.04398.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/reasoning/2401.04398.pdf
# Kích thước tệp: 1638905 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
CHAIN-OF-TABLE: PHÁT TRIỂN CÁC BẢNG TRONG
CHUỖI SUY LUẬN ĐỂ HIỂU BẢNG
Zilong Wang1∗Hao Zhang3Chun-Liang Li2Julian Martin Eisenschlos3
Vincent Perot3Zifeng Wang2Lesly Miculicich2Yasuhisa Fujii3
Jingbo Shang1Chen-Yu Lee2Tomas Pfister2
1Đại học California, San Diego2Google Cloud AI Research3Google Research
TÓM TẮT
Suy luận dựa trên bảng với các mô hình ngôn ngữ lớn (LLMs) là một hướng đầy hứa hẹn để giải quyết nhiều tác vụ hiểu bảng, chẳng hạn như trả lời câu hỏi dựa trên bảng và xác minh sự thật. So với suy luận tổng quát, suy luận dựa trên bảng đòi hỏi việc trích xuất ngữ nghĩa cơ bản từ cả câu hỏi dạng tự do và dữ liệu bảng bán cấu trúc. Chain-of-Thought và các phương pháp tương tự kết hợp chuỗi suy luận dưới dạng ngữ cảnh văn bản, nhưng vẫn còn là một câu hỏi mở về cách tận dụng hiệu quả dữ liệu bảng trong chuỗi suy luận. Chúng tôi đề xuất khung CHAIN-OF-TABLE, trong đó dữ liệu bảng được sử dụng một cách rõ ràng trong chuỗi suy luận như một đại diện cho các suy nghĩ trung gian. Cụ thể, chúng tôi hướng dẫn LLMs sử dụng học trong ngữ cảnh để tạo ra các thao tác một cách lặp đi lặp lại và cập nhật bảng để đại diện cho một chuỗi suy luận bảng. Do đó, LLMs có thể lập kế hoạch động cho thao tác tiếp theo dựa trên kết quả của các thao tác trước đó. Sự phát triển liên tục của bảng này tạo thành một chuỗi, thể hiện quá trình suy luận cho một vấn đề bảng nhất định. Chuỗi này mang thông tin có cấu trúc của các kết quả trung gian, cho phép dự đoán chính xác và đáng tin cậy hơn. CHAIN-OF-TABLE đạt được hiệu suất tiên tiến mới trên các benchmark WikiTQ, FeTaQA và TabFact trên nhiều lựa chọn LLM.

1 GIỚI THIỆU
Bảng là một định dạng dữ liệu phổ biến và được sử dụng rộng rãi trong cuộc sống hàng ngày (Cafarella et al., 2008). Hiểu dữ liệu bảng với các mô hình ngôn ngữ có thể mang lại lợi ích cho các tác vụ downstream khác nhau, chẳng hạn như xác minh sự thật dựa trên bảng (Chen et al., 2019), và trả lời câu hỏi dựa trên bảng (Jin et al., 2022). Khác với văn bản thuần túy, bảng cung cấp thông tin phong phú thông qua sự tương tác giữa các hàng và cột trong cấu trúc bảng, điều này tăng cường khả năng dữ liệu nhưng cũng tăng độ khó để các mô hình ngôn ngữ hiểu chúng. Do đó, suy luận trên dữ liệu bảng là một hướng quan trọng trong xử lý ngôn ngữ tự nhiên và thu hút sự chú ý ngày càng tăng từ cả học thuật và công nghiệp.

Trong những năm gần đây, một số phương pháp đã được đề xuất để giải quyết vấn đề hiểu bảng bằng cách huấn luyện các mô hình ngôn ngữ. Một hướng phổ biến là thêm các lớp embedding chuyên biệt hoặc cơ chế attention vào các mô hình ngôn ngữ và pre-train các mô hình bằng cách khôi phục các ô bảng hoặc đoạn (Herzig et al., 2020; Wang et al., 2021; Gu et al., 2022; Andrejczuk et al., 2022). Bằng cách này, các mô hình được pre-train nhận thức được cấu trúc bảng. Một hướng khác là tổng hợp các cặp truy vấn-phản hồi SQL và pre-train một mô hình encoder-decoder như một bộ thực thi SQL thần kinh (Eisenschlos et al., 2020; Liu et al., 2021; Jiang et al., 2022).

Gần đây, các mô hình ngôn ngữ lớn (LLMs) đạt được hiệu suất xuất sắc trên các tác vụ đa dạng chỉ bằng cách prompting, nhờ quy mô lớn của pre-training (Brown et al., 2020; Kojima et al., 2022). Khi một loạt các công trình về kỹ thuật prompting đã cải thiện thêm độ tin cậy của LLMs bằng cách thiết kế các chuỗi suy luận, chẳng hạn như Chain-of-Thought (Wei et al., 2022), Least-to-Most (Zhou et al., 2022), Program-of-Thought (Chen et al., 2022) và Tree-of-Thought (Yao et al., 2023). Các công trình khác nhau cũng đã khám phá khả năng sử dụng LLMs để giải quyết các vấn đề dựa trên bảng (Chen,
∗Công trình được thực hiện khi tác giả là nghiên cứu sinh tại Google Cloud AI Research. Liên hệ:
Zilong Wang <zlwang@ucsd.edu>, Chen-Yu Lee <chenyulee@google.com>
1arXiv:2401.04398v2  [cs.CL]  19 Jan 2024

--- TRANG 2 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
(a) Suy luận Tổng quát [Bảng Gốc] [Câu hỏi] Quốc gia nào có nhiều tay đua nhất hoàn thành trong top 3?2Davide (ITA)1Alejandro (ESP)RankCyclist3Paolo (ITA)4Haimar (ESP)LLM(b) Suy luận Hỗ trợ Chương trình SQL: SELECT Country FROM table WHERE Rank<=3 GROUP BY Country ORDER BY COUNT(*) DESC LIMIT 1(c) Chain-of-Table (của chúng tôi)
f_add_col()LLMBước 1: Lấy mẫu thao tác tiếp theo dựa trên Bảng, Câu hỏi, Lịch sử Thao tácBước 2: Tạo đối số cho thao tác được lấy mẫuLLM
Added Col Header = "Country"
Added Col Cells = "ESP ,ITA,…"Input Prompt
❌
Nhiều Bước Suy luận trong Suy luận Tổng quát thất bại trong việc giải quyết bảng phức tạp. Câu hỏi yêu cầu tay đua trong top 3 nhưng Haimar không trong top 3.RankCyclist4Haimar (ESP)
LLMCác Chương trình Được tạo trong Suy luận Hỗ trợ Chương trình thất bại trong việc giải quyết bảng phức tạp.SQL không thể thực thi truy vấn vì "Country" nằm trong cùng một ô với "Name".CyclistAlejandro (ESP)
OPPool
❌
Input Prompt (lần lặp tiếp theo)1Alej.RankCyc.ESPCountry
f_add_col()[Bảng Trung gian][Lịch sử Thao tác][Câu hỏi] Quốc gia nào … trong top 3?Bước 3: Biến đổi bảng để lưu trữ quá trình suy luận bảngLặp lại Bước 1, 2, 3 với bảng trung gian & lịch sử thao tác
f_add_col(Country)
f_select_row(1,2,3)
f_group_by(Country)
f_sort_by(Count)ITA2CountryCountESP1Italy ✓[Q] Quốc gia nào có nhiều tay đua nhất hoàn thành trong top 3?Iter 1:Iter 2:Iter 3:Iter 4:Final Query PromptLịch sử Thao tác Đầy đủĐại diện Chuỗi Suy luận BảngCó 2 tay đua từ Tây Ban Nha.Họ là Alejandro và Haimar.Câu trả lời là Tây Ban Nha.

Hình 1: Minh họa so sánh giữa (a) suy luận tổng quát, (b) suy luận hỗ trợ chương trình, và (c) CHAIN-OF-TABLE được đề xuất. Cho một bảng phức tạp trong đó quốc tịch và tên của tay đua nằm trong cùng một ô, (a) không thể đưa ra câu trả lời đúng thông qua suy luận nhiều bước do độ phức tạp; (b) tạo và thực thi các chương trình (ví dụ: truy vấn SQL) để đưa ra câu trả lời, nhưng cũng thiếu sót trong việc phân tích chính xác tên và quốc tịch trong bảng. Ngược lại, (c) CHAIN-OF-TABLE lặp đi lặp lại lấy mẫu một chuỗi các thao tác hiệu quả biến đổi bảng phức tạp thành một phiên bản được điều chỉnh cụ thể cho câu hỏi. Với sự hỗ trợ của CHAIN-OF-TABLE, LLM có thể đưa ra câu trả lời đúng.

2023; Cheng et al., 2022; Ye et al., 2023). Tuy nhiên, các phương pháp này (Hsieh et al., 2023) thường đại diện cho các bước suy luận dưới dạng văn bản tự do hoặc mã, không phù hợp lý tưởng để giải quyết các tình huống liên quan đến bảng phức tạp, như được thể hiện trong Hình 1(a) và Hình 1(b).

Mặt khác, suy luận trên bảng thường liên quan đến một loạt các bước suy luận trung gian và mỗi bước phù hợp với các thao tác bảng cụ thể. Chúng tôi đề xuất CHAIN-OF-TABLE, trong đó chúng tôi thực hiện suy luận từng bước như các thao tác bảng từng bước để tạo thành một chuỗi bảng. Các bảng trong chuỗi là các bảng được biến đổi bởi các thao tác bảng, đại diện cho các kết quả suy luận trung gian. Quy trình này giống với tư duy suy luận trong Chain-of-Thought (Wei et al., 2022). Cụ thể, chúng tôi định nghĩa một tập hợp các thao tác bảng, chẳng hạn như thêm cột, chọn hàng, nhóm, v.v., thường được sử dụng trong phát triển SQL và DataFrame (Pönighaus, 1995; Shi et al., 2020; Katsogiannis-Meimarakis & Koutrika, 2023). Sau đó chúng tôi nhắc LLMs thực hiện suy luận từng bước. Trong mỗi bước, LLM tạo ra một cách động một thao tác như bước tiếp theo cùng với các đối số cần thiết, và sau đó chúng tôi thực thi thao tác trên bảng một cách lập trình. Thao tác này có thể làm phong phú bảng bằng cách thêm các kết quả trung gian chi tiết hoặc làm giảm nó bằng cách loại bỏ thông tin không liên quan. Một cách trực quan, việc hình dung các kết quả trung gian là cần thiết để đạt được dự đoán đúng. Chúng tôi đưa bảng được biến đổi trở lại cho bước tiếp theo. Quá trình lặp này tiếp tục cho đến khi đạt được trạng thái kết thúc. Chúng tôi lập luận rằng các bảng thu được trong các bước suy luận là các biểu diễn có cấu trúc tốt hơn của các suy nghĩ trung gian so với văn bản tự do. Cuối cùng, suy luận CHAIN-OF-TABLE tạo ra các bảng mà từ đó LLMs dễ dàng rút ra câu trả lời cuối cùng cho câu hỏi hơn.

Chúng tôi xác thực CHAIN-OF-TABLE với ba benchmark bảng để đánh giá suy luận dựa trên bảng: WikiTQ (Pasupat & Liang, 2015), TabFact (Chen et al., 2019), và FeTaQA (Nan et al., 2022). Chúng tôi thực hiện các thí nghiệm sử dụng PaLM 2 độc quyền (Anil et al., 2023) và GPT-3.5 (Brown et al., 2020; OpenAI, 2023), và LLaMA 2 mã nguồn mở (Touvron et al., 2023), để chứng minh rằng phương pháp CHAIN-OF-TABLE đề xuất của chúng tôi có thể tổng quát hóa cho các lựa chọn LLM khác nhau. Chúng tôi tóm tắt đóng góp của chúng tôi như sau:
2

--- TRANG 3 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
• Chúng tôi mở rộng khái niệm Chain-of-Thought cho cài đặt bảng, trong đó chúng tôi biến đổi bảng đầu vào để lưu trữ kết quả trung gian. Phương pháp suy luận bảng nhiều bước này với sự phát triển bảng dẫn đến hiểu bảng chính xác hơn.
• Các thí nghiệm mở rộng về xác minh sự thật dựa trên bảng và trả lời câu hỏi cho thấy CHAIN-OF-TABLE đạt hiệu suất tiên tiến trong các bộ dữ liệu WikiTQ, TabFact và FeTaQA.

2 CÔNG TRÌNH LIÊN QUAN
Fine-tuning Mô hình Ngôn ngữ cho Hiểu Bảng Bảng hiệu quả trong việc tổ chức, lưu trữ và phân tích thông tin. Đã có những nỗ lực để fine-tune các mô hình ngôn ngữ (LMs) để giải quyết các tác vụ hiểu bảng. Theo mô hình ngôn ngữ che (MLM) thành công được đề xuất trong BERT (Devlin et al., 2019), TaPas (Herzig et al., 2020) áp dụng phương pháp này và yêu cầu mô hình tái tạo một số ô nhất định trong bảng trong quá trình pre-training. Pasta (Gu et al., 2022) và TUTA (Wang et al., 2021) tiếp tục đề xuất che toàn bộ cột hoặc đoạn trong bảng. Mặt khác, TAPEX (Liu et al., 2021) pre-train một mô hình encoder-decoder với một bộ dữ liệu SQL tổng hợp lớn để nó có thể hoạt động như một bộ thực thi SQL để hiểu cấu trúc bảng tốt hơn. Eisenschlos et al. (2020) và Jiang et al. (2022) cũng tận dụng SQL tổng hợp với xem xét bổ sung về sự liên kết giữa SQL và câu hỏi ngôn ngữ tự nhiên bằng cách pre-train mô hình với cả dữ liệu tự nhiên và tổng hợp.

Prompting Mô hình Ngôn ngữ cho Hiểu Bảng LLMs có thể học từ một vài mẫu như prompts thông qua học trong ngữ cảnh. Chiến lược này được sử dụng rộng rãi để cung cấp cho các mô hình các hướng dẫn bổ sung để giải quyết tốt hơn các tác vụ downstream. Chain-of-Thought (CoT) (Wei et al., 2022) đề xuất tạo ra các bước suy luận trước khi trả lời thay vì tạo ra trực tiếp câu trả lời end-to-end. Theo CoT, Least-to-Most (Zhou et al., 2022) và DecomP (Khot et al., 2022) đề xuất chia nhỏ câu hỏi thành các vấn đề phụ trong chuỗi suy luận. Trong quá trình suy luận, các bước sau nhận thức được các bước trước đó. Các chuỗi lặp như vậy với phân rã tác vụ tiếp tục cải thiện kết quả trên các vấn đề phức tạp bằng cách tận dụng các kết quả trung gian từ việc giải quyết các vấn đề phụ. Jin & Lu (2023) tăng cường CoT thông qua một quy trình điền bảng, với trọng tâm chính vào các tác vụ dựa trên văn bản trong đó đầu vào và đầu ra ở định dạng văn bản. Tuy nhiên, dòng công trình theo CoT không được thiết kế cụ thể cho dữ liệu bảng. Như đã báo cáo trong Chen (2023), các mô hình ngôn ngữ lớn với các phương pháp suy luận chung này có thể đạt được kết quả khá tốt, nhưng vẫn còn khoảng cách giữa các phương pháp này và những phương pháp chuyên biệt cho các tình huống bảng (Cheng et al., 2022; Ye et al., 2023). Chúng tôi đề xuất CHAIN-OF-TABLE để lấp đầy khoảng cách bằng cách kết hợp trực tiếp các bảng trung gian từ các thao tác bảng như một đại diện của các suy nghĩ trung gian.

Để giải quyết tốt hơn các tác vụ dựa trên bảng với LLMs, các nhà nghiên cứu vượt ra ngoài văn bản chung và sử dụng các công cụ bên ngoài. Chen et al. (2022); Gao et al. (2023) đề xuất giải quyết các tác vụ suy luận bằng cách tạo ra các chương trình Python, sau đó được thực thi bằng trình thông dịch Python. Phương pháp này cải thiện đáng kể hiệu suất của suy luận số học. Trong tình huống hiểu bảng, Text-to-SQL với LLMs (Rajkumar et al., 2022) là một ứng dụng trực tiếp của ý tưởng này. Để tiếp tục đẩy giới hạn của các chương trình, Binder (Cheng et al., 2022) tạo ra các chương trình SQL hoặc Python và mở rộng khả năng của chúng bằng cách gọi LLMs như APIs trong các chương trình. LEVER (Ni et al., 2023) cũng đề xuất giải quyết các tác vụ dựa trên bảng với các chương trình nhưng với bước bổ sung xác minh các chương trình được tạo ra với kết quả thực thi của chúng. Tuy nhiên, các chương trình hỗ trợ trong các phương pháp hỗ trợ chương trình này vẫn thiếu sót trong việc giải quyết các trường hợp khó liên quan đến bảng phức tạp. Những hạn chế này chủ yếu do các ràng buộc của quá trình tạo ra một lần, trong đó LLMs thiếu khả năng sửa đổi bảng để đáp ứng với một câu hỏi cụ thể, đòi hỏi chúng thực hiện suy luận trên một bảng tĩnh. Phương pháp của chúng tôi, ngược lại, là một khung suy luận nhiều bước thực hiện suy luận bảng từng bước. Nó biến đổi các bảng được điều chỉnh cho câu hỏi đã cho.

Theo hiểu biết tốt nhất của chúng tôi, Dater (Ye et al., 2023) là mô hình duy nhất sửa đổi ngữ cảnh bảng trong khi giải quyết các tác vụ dựa trên bảng. Tuy nhiên, phân rã bảng trong Dater được thúc đẩy bởi ý tưởng rằng các bảng có thể quá lớn để LLMs thực hiện suy luận. Do đó, nó giống với việc tiền xử lý dữ liệu hỗ trợ LLM hơn là một phần của chuỗi suy luận vì các thao tác bảng bị giới hạn trong việc chọn cột và hàng, và cố định cho tất cả các bảng và câu hỏi. Ngược lại, CHAIN-OF-TABLE của chúng tôi tổng quát hóa một tập hợp lớn hơn các thao tác bảng chung và tạo ra các chuỗi suy luận một cách động theo cách thích ứng dựa trên đầu vào, tận dụng khả năng lập kế hoạch (Valmeekam et al., 2022; Hao et al., 2023) của LLMs.
3

--- TRANG 4 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
3 SUY LUẬN CHAIN-OF-TABLE

Công thức Vấn đề. Trong suy luận dựa trên bảng, mỗi mục có thể được biểu diễn như một bộ ba (T,Q,A ), trong đó T đại diện cho bảng, Q đại diện cho một câu hỏi hoặc phát biểu liên quan đến bảng, và A là câu trả lời mong đợi. Đặc biệt, trong tác vụ trả lời câu hỏi dựa trên bảng, Q và A là câu hỏi và câu trả lời mong đợi dưới dạng ngôn ngữ tự nhiên; trong tác vụ xác minh sự thật dựa trên bảng, Q là một phát biểu về nội dung bảng và A∈ {True,False } là một giá trị Boolean chỉ ra tính đúng đắn của phát biểu. Mục tiêu là dự đoán câu trả lời A cho câu hỏi Q và bảng T. Để tạo điều kiện cho suy luận dựa trên bảng trong cùng một mô hình được sử dụng cho suy luận chung, chúng tôi chuyển đổi tất cả các giá trị dữ liệu, bao gồm cả bảng, thành các biểu diễn văn bản (xem Phụ lục D cho phương pháp mã hóa định dạng bảng).

3.1 TỔNG QUAN

CHAIN-OF-TABLE cho phép LLMs lập kế hoạch động một chuỗi các thao tác trên bảng T để đáp ứng với một câu hỏi Q đã cho. Nó sử dụng các thao tác dựa trên công cụ nguyên tử để xây dựng chuỗi bảng. Các thao tác này bao gồm thêm cột, chọn hàng hoặc cột, nhóm và sắp xếp, thường gặp trong phát triển SQL và DataFrame (xem Phụ lục A để biết thêm chi tiết).

Trước đây, Dater (Ye et al., 2023) sử dụng một quy trình chuyên dụng nhưng cố định để phân rã bảng và câu hỏi, điều này hạn chế tính tương thích với các thao tác mới. Ngoài ra, Binder (Cheng et al., 2022), mặc dù có tiềm năng tương thích với các thao tác mới, bị hạn chế trong những thao tác hoạt động với các trình thông dịch mã như SQL hoặc Python. Ngược lại, khung của chúng tôi có thể mở rộng và có thể kết hợp các thao tác từ một loạt rộng các công cụ nhờ khả năng học trong ngữ cảnh linh hoạt để lấy mẫu và thực thi các thao tác hiệu quả.

Như được minh họa trong Thuật toán 1, tại mỗi lần lặp, chúng tôi nhắc LLM lấy mẫu một trong các thao tác nguyên tử được định nghĩa trước được ký hiệu là f sử dụng câu hỏi Q tương ứng, trạng thái bảng mới nhất T, và chuỗi thao tác chain (Dòng 4). Sau đó, chúng tôi truy vấn LLM để tạo ra các đối số cần thiết args cho f (Dòng 5) và thực thi nó để biến đổi bảng T (Dòng 6). Chúng tôi theo dõi thao tác f được thực hiện trên bảng trong chuỗi thao tác chain (Dòng 7). Quá trình kết thúc khi thẻ kết thúc [E] được tạo ra (Dòng 8). Cuối cùng, chúng tôi đưa bảng mới nhất vào LLM để dự đoán câu trả lời (Dòng 9). Chuỗi thao tác này đóng vai trò như các bước suy luận dẫn dắt LLMs hiểu bảng đầu vào và tạo ra câu trả lời cuối cùng tốt hơn.

Thuật toán 1: Prompting CHAIN-OF-TABLE
Dữ liệu: (T, Q) là một cặp bảng-câu hỏi.
Kết quả: ˆA là câu trả lời dự đoán cho câu hỏi.
1Hàm Chain-of-Table ( T,Q):
2 chain ←[([B], ϕ),] ▷Khởi tạo chuỗi thao tác chain với [B] và ϕ, trong đó [B] là
▷thẻ bắt đầu, và ϕ có nghĩa là không cần đối số
3 lặp lại
4 f←DynamicPlan( T,Q,chain) ▷Tạo thao tác tiếp theo f dựa trên bảng, câu hỏi, và
▷chuỗi thao tác hiện tại
5 args←GenerateArgs( T,Q,f) ▷Tạo các đối số args cho thao tác tiếp theo
6 T←f(T,args) ▷Thực hiện thao tác tiếp theo trên bảng để có được T được cập nhật
7 chain ←chain .append ((f,args) ) ▷Theo dõi các thao tác trong chuỗi thao tác chain
8 cho đến khi f=[E] ▷Cập nhật bảng lặp đi lặp lại cho đến khi thẻ kết thúc [E] được tạo ra
9 ˆA←Query (T, Q) ▷Truy vấn LLM với bảng kết quả để có câu trả lời cuối cùng ˆA
10trả về ˆA

3.2 LẬP KẾ HOẠCH ĐỘNG

CHAIN-OF-TABLE hướng dẫn LLM lập kế hoạch động cho thao tác tiếp theo bằng học trong ngữ cảnh. Như được thể hiện trong Hình 2(a), DynamicPlan bao gồm ba thành phần: bảng trung gian mới nhất T (Hình 2(a)(i)), lịch sử của các thao tác trước đó chain chain (Hình 2(a)(ii)), và câu hỏi Q (Hình 2(a)(iii)). Chúng tôi hướng dẫn LLM chọn thao tác tiếp theo f từ nhóm thao tác cho ( T,chain ,Q). LLM sau đó có thể lập kế hoạch động cho thao tác tiếp theo và xây dựng chuỗi suy luận bảng từng bước. Xem Phụ lục E.1 để biết các prompts chi tiết.
4

--- TRANG 5 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
（a）DynamicPlan (T, Q, chain)（b）GenerateArgs (T, Q, f)…1Rank
LLM(i) Bảng Trung gian (T)…Alej. (ESP)Cyclist…ESPCountry(ii) Lịch sử Thao tác (chain)
f_add_col(Country)
f_select_row(1,2,3)Iter 1:Iter 2:Quốc gia nào có nhiều tay đua nhất hoàn thành trong top 3?   (iii) Câu hỏi (Q)Lấy mẫu thao tác tiếp theo dựa trên T, Chain, Q
f_group_by4Thao tác Được chọnInput Prompt
Nhóm Thao tác
f_select_col
f_group_by
f_sort_by
f_add_col
f_select_row12345Input Prompt
LLM3Đối số Được chọn
Country(ii) Thao tác Hiện tại (f) &      Các Đối số của nó (args)
f_group_by
Header để nhóm theo = ?Quốc gia nào có nhiều tay đua nhất hoàn thành trong top 3?   (iii) Câu hỏi (Q)(i) Bảng Trung gian (T)Lấy mẫu đối số dựa trên T, f, QĐối số: Header bảng trong trường hợp này
Rank1
Cyclist2
Country3……1Alej. (ESP)RankCyclist…ESPCountryargs :f :

Hình 2: Minh họa DynamicPlan( T,Q,chain) và GenerateArgs( T,Q,f) trong CHAIN-OF-TABLE được đề xuất, trong đó T là bảng trung gian; Q là câu hỏi; chain là danh sách các thao tác đã được thực hiện trên bảng; f là thao tác được chọn bởi DynamicPlan. Trái: DynamicPlan lấy mẫu thao tác tiếp theo từ nhóm thao tác, theo ( T,chain ,Q). Phải: GenerateArgs lấy thao tác đã chọn f làm đầu vào và tạo ra các đối số của nó dựa trên (T,f,Q). Các thao tác, cùng với các đối số của chúng, đóng vai trò như một đại diện của quá trình suy luận bảng để giải quyết hiệu quả các tác vụ hiểu bảng.

3.3 TẠO ĐỐI SỐ

Bước tiếp theo, GenerateArgs, bao gồm việc tạo ra các đối số cho thao tác bảng đã chọn f được lấy mẫu bởi DynamicPlan, như được mô tả trong Hình 2. GenerateArgs bao gồm ba thành phần chính: bảng trung gian mới nhất T (Hình 2(b)(i)), thao tác đã chọn f cùng với các đối số args của nó (Hình 2(b)(ii)), và câu hỏi (Hình 2(b)(iii)). Chúng tôi sử dụng các biểu thức chính quy đơn giản để tính đến số lượng đối số khác nhau cần thiết bởi các thao tác khác nhau (xem Phụ lục E.2 để biết thêm chi tiết). Cuối cùng, chúng tôi áp dụng các ngôn ngữ lập trình để thực thi thao tác và tạo ra các bảng trung gian tương ứng.

3.4 TRUY VẤN CUỐI CÙNG

Chúng tôi biến đổi bảng thông qua lập kế hoạch động (Mục 3.2) và tạo đối số (Mục 3.3). Trong quá trình này, chúng tôi tạo ra một chuỗi các thao tác đóng vai trò như một đại diện cho các bước suy luận bảng. Các thao tác này tạo ra các bảng trung gian lưu trữ và trình bày kết quả của mỗi bước cho LLM. Do đó, bảng đầu ra từ chuỗi thao tác này chứa thông tin toàn diện về các giai đoạn trung gian của suy luận bảng. Sau đó chúng tôi sử dụng bảng đầu ra này trong việc xây dựng truy vấn cuối cùng. Như được minh họa trong Hình 1 (góc dưới bên phải), chúng tôi nhập cả bảng đầu ra và câu hỏi vào LLM, cung cấp câu trả lời cuối cùng cho câu hỏi (xem Dòng 9 trong Thuật toán 1).

4 THÍ NGHIỆM

Chúng tôi đánh giá CHAIN-OF-TABLE được đề xuất trên ba benchmark hiểu bảng công khai: WikiTQ (Pasupat & Liang, 2015), FeTaQA (Nan et al., 2022), và TabFact (Chen et al., 2019). WikiTQ và FeTaQA là các bộ dữ liệu tập trung vào trả lời câu hỏi dựa trên bảng. Chúng yêu cầu suy luận bảng phức tạp trên bảng được cung cấp để trả lời câu hỏi. WikiTQ thường yêu cầu câu trả lời span văn bản ngắn, trong khi FeTaQA yêu cầu phản hồi dạng tự do dài hơn. TabFact, mặt khác, là một benchmark xác minh sự thật nhị phân dựa trên bảng. Nhiệm vụ là xác định tính đúng đắn của một phát biểu đã cho dựa trên bảng. Để đánh giá WikiTQ, chúng tôi sử dụng độ chính xác ký hiệu chính thức (Pasupat & Liang, 2015), và cho TabFact, chúng tôi sử dụng độ chính xác phân loại nhị phân. Xét đến bản chất của FeTaQA, bao gồm việc so sánh dự đoán với văn bản mục tiêu dài hơn, chúng tôi sử dụng BLEU (Papineni et al., 2002), ROUGE-1, ROUGE-2, và ROUGE-L (Lin, 2004) để đánh giá.

Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng PaLM 2-S1, GPT 3.5 (turbo-16k-0613)2, và LLaMA 2 (Llama-2-17B-
1https://cloud.google.com/vertex-ai/docs/generative-ai/learn/generative-ai-studio
2http://openai.com/api/
5

--- TRANG 6 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
Bảng 1: Kết quả hiểu bảng trên WikiTQ và TabFact với PaLM 2, GPT 3.5, và LLaMA 2.
(gạch dưới biểu thị hiệu suất tốt thứ hai; đậm biểu thị hiệu suất tốt nhất; cải thiện được đo so với phương pháp thực hiện tốt thứ hai.)
PromptingPaLM 2 GPT 3.5 LLaMA 2
TabFact WikiTQ TabFact WikiTQ TabFact WikiTQ
Suy luận Tổng quát
End-to-End QA 77.92 60.59 70.45 51.84 44.86 23.90
Few-Shot QA 78.06 60.33 71.54 52.56 62.01 35.52
Chain-of-Thought (Wei et al., 2022) 79.05 60.43 65.37 53.48 60.52 36.05
Suy luận Hỗ trợ Chương trình
Text-to-SQL (Rajkumar et al., 2022) 68.37 52.42 64.71 52.90 64.03 36.14
Binder (Cheng et al., 2022) 76.98 54.88 79.17 56.74 62.76 30.92
Dater (Ye et al., 2023) 84.63 61.48 78.01 52.81 65.12 41.44
CHAIN-OF-TABLE (của chúng tôi) 86.61 (+1.98) 67.31 (+5.83) 80.20 (+1.03) 59.94 (+3.20) 67.24 (+2.12) 42.61 (+1.17)

chat)3 làm LLMs cốt lõi. Chúng tôi kết hợp các mẫu demo few-shot từ tập training vào các prompts để thực hiện học trong ngữ cảnh. Ví dụ về các prompts này có thể được tìm thấy trong Phụ lục E. Chi tiết về các tham số suy luận LLM và số lượng mẫu demo được sử dụng được cung cấp trong Phụ lục C.

4.1 BASELINE

Các phương pháp baseline được chia thành hai nhóm: (a) suy luận tổng quát, bao gồm End-to-End QA, Few-Shot QA, Chain-of-Thought (Wei et al., 2022); và (b) suy luận hỗ trợ chương trình, bao gồm Text-to-SQL (Rajkumar et al., 2022), Binder (Cheng et al., 2022), Dater (Ye et al., 2023)). Mô tả chi tiết về các phương pháp baseline này được cung cấp dưới đây.

Suy luận Tổng quát End-to-End QA hướng dẫn LLM tạo ra trực tiếp câu trả lời khi được cung cấp bảng và câu hỏi làm prompts đầu vào. Few-Shot QA hoạt động tương tự, nhưng nó bao gồm các ví dụ few-shot của bộ ba (Table, Question, Answer) trong prompt, như đã chi tiết trong Brown et al. (2020). Chúng tôi chọn các ví dụ này từ tập training, và mô hình cũng xuất ra câu trả lời trực tiếp. Chain-of-Thought (Wei et al., 2022) nhắc LLM diễn đạt quá trình suy luận của nó dưới định dạng văn bản trước khi đưa ra câu hỏi. Xem Phụ lục F cho các prompts của baseline.

Suy luận Hỗ trợ Chương trình Text-to-SQL (Rajkumar et al., 2022) sử dụng các mẫu trong ngữ cảnh để hướng dẫn LLMs tạo ra các truy vấn SQL để trả lời câu hỏi. Phương pháp này theo các khái niệm được giới thiệu bởi Chen et al. (2022); Gao et al. (2023). Binder (Cheng et al., 2022) tích hợp một API mô hình ngôn ngữ với các ngôn ngữ lập trình như SQL hoặc Python. Việc tích hợp này nhắc LLM tạo ra các chương trình có thể thực thi thực hiện các tác vụ suy luận bảng trên bảng và câu hỏi đã cho. Dater (Ye et al., 2023) sử dụng các mẫu few-shot để phân rã hiệu quả các ngữ cảnh bảng và câu hỏi, tăng cường suy luận bảng end-to-end với các bảng phụ và câu hỏi phụ được phân rá.

4.2 KẾT QUẢ

Chúng tôi so sánh CHAIN-OF-TABLE với các phương pháp suy luận tổng quát và các phương pháp suy luận hỗ trợ chương trình trên ba bộ dữ liệu: WikiTQ, TabFact, và FeTaQA. Kết quả trên WikiTQ và TabFact được trình bày trong Bảng 1. Chúng tôi có kết quả bổ sung trên FeTaQA trong Phụ lục B. Chúng tôi theo các công trình trước đó và báo cáo hiệu suất sử dụng pipeline đánh giá chính thức4.

Bảng 1 cho thấy CHAIN-OF-TABLE vượt trội đáng kể so với tất cả các phương pháp suy luận tổng quát và các phương pháp suy luận hỗ trợ chương trình trên TabFact và WikiTQ trên PaLM 2, GPT 3.5, và LLaMA
3https://ai.meta.com/llama/
4Dater Ye et al. (2023) với OpenAI Codex LLM đạt 65.9% và 85.6% độ chính xác trên WikiTQ và TabFact, tương ứng. Nó cũng đạt 27.96 trong BLEU, 0.62 trong ROUGE-1, 0.40 trong ROUGE-2, và 0.52 trong ROUGE-L trên FeTaQA. Tuy nhiên, vì Codex không còn công khai, chúng tôi không so sánh CHAIN-OF-TABLE với Dater với Codex.
6

--- TRANG 7 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
1 2 3 4 5
Độ dài Chuỗi Thao tác20304050607080Độ chính xác (%)(-11.6)(-3.7)
(-7.2)
(-7.5)
(-10.8)
40.069.3
62.3
53.5
49.3(-2.1)(-5.3)
(-7.6)
(-3.6)
(-7.9)
49.567.7
61.9
57.4
52.2 51.673.0
69.5
61.0 60.1Chain-of-Thought (Wei et al. 2022) Dater (Ye et al. 2023) Chain-of-T able (của chúng tôi)

Hình 3: Hiệu suất của Chain-of-Thought, Dater, và CHAIN-OF-TABLE được đề xuất trên WikiTQ cho các câu hỏi yêu cầu một chuỗi thao tác có độ dài khác nhau. Các thao tác nguyên tử được đề xuất của chúng tôi cho phép phương pháp CHAIN-OF-TABLE được đề xuất biến đổi động bảng đầu vào thông qua nhiều lần lặp suy luận. Điều này cải thiện đáng kể hiệu suất so với các đối tác suy luận tổng quát và hỗ trợ chương trình.

Bảng 2: Phân bố số lượng mẫu so với độ dài chuỗi thao tác cần thiết trong CHAIN-OF-TABLE với PaLM 2 trên các bộ dữ liệu WikiTQ và TabFact. Chúng tôi quan sát thấy phần lớn các mẫu cần 2 đến 4 thao tác để tạo ra đầu ra cuối cùng.
Bộ dữ liệuĐộ dài chuỗi thao tác
1 2 3 4 5
WikiTQ 95 1308 1481 1084 341
TabFact 4 547 732 517 223

2. Điều này được quy cho các thao tác được lấy mẫu động và các bảng trung gian có thông tin trong CHAIN-OF-TABLE. CHAIN-OF-TABLE tạo ra các thao tác lặp đi lặp lại đóng vai trò như đại diện cho các bước suy luận bảng. Các thao tác này tạo ra và trình bày các bảng trung gian được điều chỉnh cho LLM, truyền tải các suy nghĩ trung gian cần thiết (xem ví dụ trong Hình 4). Với sự hỗ trợ của CHAIN-OF-TABLE, LLM có thể đáng tin cậy đạt được câu trả lời đúng.

Từ kết quả, chúng tôi quan sát thấy sự giảm hiệu suất trên WikiTQ do độ phức tạp của cấu trúc bảng khi Chain-of-Thought vanilla được giới thiệu vào End-to-End QA sử dụng PaLM 2. Ngược lại, CHAIN-OF-TABLE được đề xuất của chúng tôi liên tục tăng cường hiệu suất End-to-End QA 8.69% trên TabFact và 6.72% trên WikiTQ với PaLM 2.

Chúng tôi cũng quan sát thấy CHAIN-OF-TABLE được đề xuất của chúng tôi hiệu quả trên tất cả các mô hình cốt lõi được thí nghiệm, trong khi các phương pháp cạnh tranh khác, chẳng hạn như Binder, hoạt động tốt hơn trên LLMs lớn hơn nhưng hiệu suất của nó giảm với LLaMA 2 nhỏ hơn (Llama-2-17B-chat). Chúng tôi quy sự suy giảm này cho quá trình tạo ra một lần của Binder. Mặc dù Binder có kết hợp các lời gọi API trong khung của nó, nó thiếu khả năng sửa đổi và quan sát các bảng được biến đổi. Do đó, Binder chỉ có thể thực hiện suy luận bảng trên một bảng tĩnh, khiến việc giải quyết các trường hợp phức tạp với LLMs nhỏ hơn trở nên khó khăn.

4.3 PHÂN TÍCH HIỆU SUẤT DƯỚI NHỮNG ĐỘ DÀI CHUỖI THAO TÁC KHÁC NHAU

Trong CHAIN-OF-TABLE, việc chọn mỗi thao tác được xác định động dựa trên độ khó và độ phức tạp của câu hỏi và bảng tương ứng của chúng. Do đó, chúng tôi tiến hành một nghiên cứu chi tiết về hiệu suất dưới số lượng thao tác khác nhau bằng cách phân loại các mẫu test theo độ dài thao tác của chúng. Chúng tôi báo cáo phân bố số lượng mẫu so với độ dài chuỗi thao tác cần thiết trong Bảng 2. Phân tích này tập trung vào các mẫu yêu cầu thao tác trong quá trình suy luận. Chúng tôi sử dụng kết quả với PaLM 2 làm ví dụ. Quan sát của chúng tôi cho thấy phần lớn các mẫu yêu cầu 2 đến 4 thao tác để tạo ra đầu ra cuối cùng.

Đối với mỗi độ dài chuỗi, chúng tôi tiếp tục so sánh CHAIN-OF-TABLE với Chain-of-Thought và Dater, như các phương pháp suy luận tổng quát và hỗ trợ chương trình đại diện, tương ứng. Chúng tôi minh họa điều này bằng cách sử dụng kết quả từ PaLM 2 trên WikiTQ. Chúng tôi vẽ độ chính xác của tất cả các phương pháp bằng biểu đồ cột trong Hình 3,
7

--- TRANG 8 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
Bảng 3: Hiệu suất của Binder, Dater, và CHAIN-OF-TABLE được đề xuất trên các bảng nhỏ (<2000 tokens), trung bình (2000 đến 4000 tokens), lớn (>4000 tokens) từ WikiTQ. Chúng tôi quan sát thấy hiệu suất giảm với các bảng đầu vào lớn hơn trong khi CHAIN-OF-TABLE giảm một cách tao nhã, đạt được cải thiện đáng kể so với các phương pháp cạnh tranh. (gạch dưới biểu thị hiệu suất tốt thứ hai; đậm biểu thị hiệu suất tốt nhất; cải thiện được đo so với phương pháp thực hiện tốt thứ hai.)
PromptingKích thước Bảng
Nhỏ (<2k)Trung bình (2k∼4k)Lớn (>4k)
Binder (Cheng et al., 2022) 56.54 26.13 6.41
Dater (Ye et al., 2023) 62.50 42.34 34.62
CHAIN-OF-TABLE (của chúng tôi) 68.13 (+5.63) 52.25 (+9.91) 44.87 (+10.25)

Bảng 4: Số lượng mẫu được tạo cho một câu hỏi đơn trong Binder, Dater, và CHAIN-OF-TABLE được đề xuất trên bộ dữ liệu WikiTQ. Đáng chú ý, CHAIN-OF-TABLE tạo ra ít mẫu nhất trong số các baseline – ít hơn 50% so với Binder và ít hơn 75% so với Dater. Để biết mô tả chi tiết về các bước liên quan trong Binder và Dater, vui lòng tham khảo các bài báo tương ứng.
PromptingTổng số # của # mẫu được tạo
mẫu được tạo trong mỗi bước
Binder (Cheng et al., 2022) 50 Tạo Neural-SQL: 50
Dater (Ye et al., 2023) 100Phân rã Bảng: 40; Tạo Cloze: 20;
Tạo SQL: 20; Truy vấn: 20
CHAIN-OF-TABLE (của chúng tôi) ≤25DynamicPlan: ≤5; GenerateArgs: ≤19;
Query: 1

làm nổi bật khoảng cách giữa các phương pháp được so sánh và phương pháp của chúng tôi. Đáng chú ý, CHAIN-OF-TABLE liên tục vượt trội hơn cả hai phương pháp baseline trên tất cả độ dài chuỗi thao tác, với biên độ đáng kể lên đến 11.6% so với Chain-of-Thought, và lên đến 7.9% so với Dater.

Nói chung, hiệu suất của các phương pháp này giảm khi số lượng thao tác bảng cần thiết trong chuỗi suy luận bảng tăng do độ khó và độ phức tạp cao hơn của câu hỏi và bảng. Tuy nhiên, CHAIN-OF-TABLE được đề xuất của chúng tôi giảm một cách tao nhã so với các phương pháp baseline khác. Ví dụ, CHAIN-OF-TABLE chỉ thể hiện sự giảm tối thiểu trong hiệu suất khi số lượng thao tác tăng từ bốn lên năm.

4.4 PHÂN TÍCH HIỆU SUẤT DƯỚI NHỮNG KÍCH THƯỚC BẢNG KHÁC NHAU

Các bảng lớn đặt ra những thách thức đáng kể cho LLMs vì LLMs thường gặp khó khăn trong việc diễn giải và tích hợp ngữ cảnh trong các prompts đầu vào dài (Liu et al., 2023a; Ye et al., 2023). Để đánh giá hiệu suất trên các bảng có kích thước khác nhau, chúng tôi phân loại các bảng đầu vào từ WikiTQ thành 3 nhóm dựa trên số lượng token: nhỏ (<2000 tokens), trung bình (2000 đến 4000 tokens) và lớn (>4000 tokens). Sau đó chúng tôi so sánh CHAIN-OF-TABLE với Dater (Ye et al., 2023) và Binder (Cheng et al., 2022), hai baseline mới nhất và mạnh nhất, như các phương pháp đại diện. Kết quả chi tiết được trình bày trong Bảng 3.

Như dự đoán, hiệu suất giảm với các bảng đầu vào lớn hơn, vì các mô hình được yêu cầu xử lý và suy luận thông qua các ngữ cảnh dài hơn. Tuy nhiên, hiệu suất của CHAIN-OF-TABLE được đề xuất giảm một cách tao nhã, đạt được cải thiện đáng kể 10+% so với phương pháp cạnh tranh tốt thứ hai khi xử lý các bảng lớn. Điều này chứng minh hiệu quả của chuỗi suy luận trong việc xử lý các đầu vào bảng dài.

4.5 PHÂN TÍCH HIỆU QUẢ CỦA CHAIN-OF-TABLE

Chúng tôi phân tích hiệu quả của CHAIN-OF-TABLE bằng cách đánh giá số lượng mẫu được tạo cần thiết. Chúng tôi so sánh CHAIN-OF-TABLE với Binder (Cheng et al., 2022) và Dater (Ye et al., 2023), hai phương pháp baseline mới nhất và cạnh tranh nhất. Kết quả phân tích trên WikiTQ được trình bày trong Bảng 4. Binder tạo ra các truy vấn Neural-SQL, yêu cầu 50 mẫu cho kết quả tự nhất quán
8

--- TRANG 9 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
Do đó, câu trả lời là: Morgan Freeman1997Samuel L. JacksonA Time to KillBlair Underwood…1996Laurence FishburneHigher LearningCharles Dutton…1995Al Freeman, Jr.Malcolm XDelroy Lindo …YearActorMotion PictureNominees1998Morgan FreemanAmistadClarence Williams…2005Morgan FreemanMillion DollarJamie Foxx - ………[Câu hỏi] Diễn viên nào có nhiều giải thưởng naacp image nhất?✓[Bảng Gốc]Input Promptf :args :
f_select_column
Headers: Year, ActorLần lặp 1:f :args :
f_group_by
Headers: ActorLần lặp 2:Lần lặp 3:f :args :
f_sort_by
Headers: Count
Order: Descend
……1996Laurence Fishburne1995Al Freeman, Jr.YearActor[Bảng Trung gian 1]Biến đổi bảng với f_sel_col(Year, Actor)[Bảng Trung gian 2]Biến đổi bảng với f_group_by(Actor)
……2Morgan Freeman1Al Freeman, Jr.GroupActor…41Count[Bảng Trung gian 3]Biến đổi bảng với f_sort_by(Count, Descend)
……2Denzel Washing.1Morgan FreemanGroupActor…34Countf :
[END]Lần lặp 4:Final QueryChain-of-Table (của chúng tôi)

Hình 4: Minh họa quá trình suy luận bảng trong CHAIN-OF-TABLE. Quá trình lặp này bao gồm việc lập kế hoạch động một chuỗi thao tác và lưu trữ chính xác các kết quả trung gian trong các bảng được biến đổi. Các bảng trung gian này đóng vai trò như quá trình tư duy bảng có thể hướng dẫn LLM đạt được câu trả lời đúng một cách đáng tin cậy hơn.

results. Dater bao gồm nhiều bước tinh tế nhưng cố định, chẳng hạn như phân rã các bảng và tạo ra các truy vấn cloze cho các câu hỏi. Trong mỗi bước, Dater cũng sử dụng self-consistency để cải thiện độ chính xác của các đầu ra LLM, dẫn đến số lượng cao các mẫu được tạo cần thiết. Để biết mô tả chi tiết về các khung này, vui lòng tham khảo các bài báo tương ứng, Ye et al. (2023) và Cheng et al. (2022).

Không giống như các phương pháp trước đó này, CHAIN-OF-TABLE được đề xuất của chúng tôi sử dụng một chiến lược tìm kiếm tham lam trong quá trình suy luận bảng của nó, thay vì dựa vào việc lấy mẫu self-consistency để tăng cường hiệu suất. Phương pháp này dẫn đến việc giảm số lượng truy vấn cho phương pháp của chúng tôi, mặc dù CHAIN-OF-TABLE áp dụng một quá trình suy luận lặp. Cụ thể hơn, chúng tôi quan sát thấy số lượng truy vấn cần thiết bởi CHAIN-OF-TABLE là thấp nhất trong số các baseline gần đây nhất – ít hơn 50% so với Binder và ít hơn 75% so với Dater. Chúng tôi quy hiệu quả truy vấn của phương pháp chúng tôi cho việc thực thi thao tác động được đề xuất thông qua suy luận bảng. Mô hình có thể tìm một quá trình suy luận hiệu quả đạt được đầu ra cuối cùng nhanh hơn và đáng tin cậy hơn.

4.6 NGHIÊN CỨU TRƯỜNG HỢP

Trong Hình 4, chúng tôi minh họa quá trình suy luận bảng bởi CHAIN-OF-TABLE. Câu hỏi dựa trên một bảng phức tạp và yêu cầu nhiều bước suy luận để 1) xác định các cột liên quan, 2) thực hiện tổng hợp, và 3) sắp xếp lại thông tin trung gian được tổng hợp. CHAIN-OF-TABLE được đề xuất của chúng tôi bao gồm việc lập kế hoạch động một chuỗi thao tác và lưu trữ chính xác các kết quả trung gian trong các bảng được biến đổi. Các bảng trung gian này đóng vai trò như quá trình tư duy bảng có thể hướng dẫn LLM đạt được câu trả lời đúng một cách đáng tin cậy hơn.

5 KẾT LUẬN

CHAIN-OF-TABLE được đề xuất của chúng tôi tăng cường khả năng suy luận của LLMs bằng cách tận dụng cấu trúc bảng để thể hiện các suy nghĩ trung gian cho suy luận dựa trên bảng. Nó hướng dẫn LLMs lập kế hoạch động một chuỗi thao tác theo bảng đầu vào và câu hỏi liên quan của nó. Thiết kế bảng phát triển này mang ánh sáng mới về việc hiểu prompting LLMs để hiểu bảng.

6 TUYÊN BỐ KHẢ NĂNG TÁI TẠO

Chúng tôi bao gồm các ví dụ prompt của DynamicPlan( T,Q,chain) trong Phụ lục E.1, các ví dụ demo của GenerateArgs( T,Q,f) trong Phụ lục E.2, các ví dụ prompt của Query( T,Q) trong Phụ lục E.3. Chúng tôi chạy các phương pháp suy luận tổng quát (End-to-End QA, FewShot QA, Chain-of-Thought) sử dụng các prompts được báo cáo trong Phụ lục F. Chúng tôi chạy Text-to-SQL và Binder sử dụng mã và prompts mã nguồn mở chính thức tại https://github.com/HKUNLP/Binder. Chúng tôi chạy Dater sử dụng mã và prompts mã nguồn mở chính thức tại https://github.com/AlibabaResearch/DAMO-ConvAI. Chúng tôi sửa đổi mã để sử dụng GPT 3.5, PaLM 2, và LLaMA 2 (Mục 4) có sẵn công khai như LLM cốt lõi thay vì OpenAI Codex do không thể truy cập.
9

--- TRANG 10 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
TÀI LIỆU THAM KHẢO

Ewa Andrejczuk, Julian Eisenschlos, Francesco Piccinno, Syrine Krichene, và Yasemin Altun.
Table-to-text generation and pre-training with TabT5. Trong Findings of the Association for Computational Linguistics: EMNLP 2022 , pp. 6758–6766, Abu Dhabi, United Arab Emirates, December
2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-emnlp.503. 1

Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos,
Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report.
arXiv preprint arXiv:2305.10403 , 2023. 2

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are
few-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020. 1,
2, 6

Michael J. Cafarella, Alon Halevy, Daisy Zhe Wang, Eugene Wu, và Yang Zhang. Webtables:
Exploring the power of tables on the web. Proc. VLDB Endow. , 1(1):538–549, aug 2008. ISSN
2150-8097. doi: 10.14778/1453856.1453916. 1

Wenhu Chen. Large language models are few(1)-shot table reasoners. Trong Findings of the Association
for Computational Linguistics: EACL 2023 , pp. 1120–1130, Dubrovnik, Croatia, May 2023.
Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-eacl.83. 1, 3, 17

Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou,
và William Yang Wang. Tabfact: A large-scale dataset for table-based fact verification. Trong
International Conference on Learning Representations , 2019. 1, 2, 5

Wenhu Chen, Xueguang Ma, Xinyi Wang, và William W Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint
arXiv:2211.12588 , 2022. 1, 3, 6

Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong,
Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, et al. Binding language models in symbolic
languages. Trong International Conference on Learning Representations , 2022. 2, 3, 4, 6, 8, 9, 16

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. Trong Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers) , pp. 4171–4186, 2019. 3

Bhuwan Dhingra, Manaal Faruqui, Ankur Parikh, Ming-Wei Chang, Dipanjan Das, và William Cohen. Handling divergent reference texts when evaluating table-to-text generation. Trong Proceedings
of the 57th Annual Meeting of the Association for Computational Linguistics , pp. 4884–4895,
2019. 14

Julian Eisenschlos, Syrine Krichene, và Thomas Müller. Understanding tables with intermediate
pre-training. Trong Findings of the Association for Computational Linguistics: EMNLP 2020 , pp.
281–296, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/
2020.findings-emnlp.27. 1, 3

Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, và
Graham Neubig. PAL: Program-aided language models. Trong International Conference on Machine
Learning , pp. 10764–10799. PMLR, 2023. 3, 6

Zihui Gu, Ju Fan, Nan Tang, Preslav Nakov, Xiaoman Zhao, và Xiaoyong Du. PASTA: Table-operations aware fact verification via sentence-table cloze pre-training. Trong Proceedings of the
2022 Conference on Empirical Methods in Natural Language Processing , pp. 4971–4983, Abu
Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi:
10.18653/v1/2022.emnlp-main.331. 1, 3

Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, và Zhiting Hu.
Reasoning with language model is planning with world model. arXiv preprint arXiv:2305.14992 ,
2023. 3
10

--- TRANG 11 ---
Được công bố như một bài báo hội nghị tại ICLR 2024

Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco Piccinno, và Julian Eisenschlos. TaPas: Weakly supervised table parsing via pre-training. Trong Proceedings of the 58th
Annual Meeting of the Association for Computational Linguistics , pp. 4320–4333, Online, July
2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.398. 1, 3

Cheng-Yu Hsieh, Chun-Liang Li, Chih-kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alex Ratner,
Ranjay Krishna, Chen-Yu Lee, và Tomas Pfister. Distilling step-by-step! outperforming larger
language models with less training data and smaller model sizes. Trong Findings of the Association
for Computational Linguistics: ACL 2023 . Association for Computational Linguistics, 2023. 2

Shima Imani, Liang Du, và Harsh Shrivastava. MathPrompter: Mathematical reasoning using large
language models. Trong Proceedings of the 61st Annual Meeting of the Association for Computational
Linguistics (Volume 5: Industry Track) , pp. 37–42, Toronto, Canada, July 2023. Association for
Computational Linguistics. doi: 10.18653/v1/2023.acl-industry.4. 13

Zhengbao Jiang, Yi Mao, Pengcheng He, Graham Neubig, và Weizhu Chen. OmniTab: Pretraining
with natural and synthetic data for few-shot table-based question answering. Trong Proceedings of the
2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , pp. 932–942, Seattle, United States, July 2022. Association
for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.68. 1, 3, 16

Nengzheng Jin, Joanna Siebert, Dongfang Li, và Qingcai Chen. A survey on table question answering: recent advances. Trong China Conference on Knowledge Graph and Semantic Computing ,
pp. 174–186. Springer, 2022. 1

Ziqi Jin và Wei Lu. Tab-cot: Zero-shot tabular chain of thought. arXiv preprint arXiv:2305.17812 ,
2023. 3

George Katsogiannis-Meimarakis và Georgia Koutrika. A survey on deep learning approaches for
text-to-sql. The VLDB Journal , pp. 1–32, 2023. 2

Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, và Ashish
Sabharwal. Decomposed prompting: A modular approach for solving complex tasks. Trong International Conference on Learning Representations , 2022. 3

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. Large
language models are zero-shot reasoners. Trong Advances in Neural Information Processing Systems ,
2022. 1

Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. Trong Text Summarization
Branches Out , pp. 74–81, Barcelona, Spain, July 2004. Association for Computational Linguistics. 5, 14

Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, và
Percy Liang. Lost in the middle: How language models use long contexts. arXiv preprint
arXiv:2307.03172 , 2023a. 8

Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, và Jian-Guang Lou.
TAPEX: Table pre-training via learning a neural sql executor. Trong International Conference on
Learning Representations , 2021. 1, 3, 16

Qian Liu, Fan Zhou, Zhengbao Jiang, Longxu Dou, và Min Lin. From zero to hero: Examining the
power of symbolic tasks in instruction tuning. arXiv preprint arXiv:2304.07995 , 2023b. 16

Joshua Maynez, Priyanka Agrawal, và Sebastian Gehrmann. Benchmarking large language model
capabilities for conditional generation. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 9194–9213, 2023. 14

Linyong Nan, Chiachun Hsieh, Ziming Mao, Xi Victoria Lin, Neha Verma, Rui Zhang, Wojciech
Kryściński, Hailey Schoelkopf, Riley Kong, Xiangru Tang, Mutethia Mutuma, Ben Rosand, Isabel Trindade, Renusree Bandaru, Jacob Cunningham, Caiming Xiong, Dragomir Radev, và
Dragomir Radev. FeTaQA: Free-form table question answering. Transactions of the Association
for Computational Linguistics , 10:35–49, 2022. doi: 10.1162/tacl_a_00446. 2, 5
11

--- TRANG 12 ---
Được công bố như một bài báo hội nghị tại ICLR 2024

Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, và Xi Victoria
Lin. Lever: Learning to verify language-to-code generation with execution. Trong International
Conference on Machine Learning , pp. 26106–26128. PMLR, 2023. 3

OpenAI. Gpt-4 technical report. ArXiv , abs/2303.08774, 2023. 2

Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. Bleu: a method for automatic
evaluation of machine translation. Trong Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics , pp. 311–318, Philadelphia, Pennsylvania, USA, July 2002.
Association for Computational Linguistics. doi: 10.3115/1073083.1073135. 5

Panupong Pasupat và Percy Liang. Compositional semantic parsing on semi-structured tables.
Trong Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long
Papers) , pp. 1470–1480, Beijing, China, July 2015. Association for Computational Linguistics.
doi: 10.3115/v1/P15-1142. 2, 5

Richard Pönighaus. 'favourite'sql-statements—an empirical analysis of sql-usage in commercial
applications. Trong International Conference on Information Systems and Management of Data , pp.
75–91. Springer, 1995. 2

Nitarshan Rajkumar, Raymond Li, và Dzmitry Bahdanau. Evaluating the text-to-sql capabilities of
large language models. arXiv preprint arXiv:2204.00498 , 2022. 3, 6

Tianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daumé III, và Lillian Lee. On the potential
of lexico-logical alignments for semantic parsing to sql queries. Findings of the Association for
Computational Linguistics: EMNLP 2020 , 2020. 2

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 , 2023. 2

Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, và Subbarao Kambhampati. Large language models still can't plan (a benchmark for llms on planning and reasoning about change). Trong
NeurIPS 2022 Foundation Models for Decision Making Workshop , 2022. 3

Zhiruo Wang, Haoyu Dong, Ran Jia, Jia Li, Zhiyi Fu, Shi Han, và Dongmei Zhang. TUTA: Tree-based transformers for generally structured table pre-training. Trong Proceedings of the 27th ACM
SIGKDD Conference on Knowledge Discovery & Data Mining , pp. 1780–1790, 2021. 1, 3

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny
Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in
Neural Information Processing Systems , 35:24824–24837, 2022. 1, 2, 3, 6

Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, và Karthik
Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv
preprint arXiv:2305.10601 , 2023. 1

Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, và Yongbin Li. Large language models
are versatile decomposers: Decompose evidence and questions for table-based reasoning. arXiv
preprint arXiv:2301.13808 , 2023. 2, 3, 4, 6, 8, 9, 13, 14, 16

Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, et al. Least-to-most prompting enables complex
reasoning in large language models. Trong International Conference on Learning Representations ,
2022. 1, 3
12

--- TRANG 13 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
PHỤ LỤC

A CÁC THAO TÁC NGUYÊN TỬ TRONG CHAIN-OF-TABLE

A.1 GIỚI THIỆU

Trong nghiên cứu này, chúng tôi áp dụng một tập hợp năm thao tác bảng, thường được sử dụng trong phát triển SQL và DataFrame, làm ví dụ. Chúng tôi lưu ý rằng khung của chúng tôi có thể dễ dàng chứa các thao tác bổ sung, điều mà chúng tôi để dành cho công việc tương lai.

•f_add_column() thêm một cột mới vào bảng để lưu trữ kết quả suy luận hoặc tính toán trung gian.
•f_select_row() chọn một tập con các hàng có liên quan đến câu hỏi. Bảng có thể chứa thông tin không liên quan cho câu hỏi đã cho (Ye et al., 2023). Thao tác này giúp định vị ngữ cảnh cần thiết.
•f_select_column() chọn một tập con các cột. Một cột thường tương ứng với một thuộc tính trong bảng. Thao tác này cho phép mô hình định vị các thuộc tính cần thiết để trả lời câu hỏi.
•f_group_by() nhóm các hàng theo nội dung của một cột cụ thể và cung cấp số đếm của mỗi giá trị liệt kê trong cột đó. Nhiều câu hỏi hoặc phát biểu dựa trên bảng liên quan đến việc đếm, nhưng LLMs không thành thạo trong nhiệm vụ này (Imani et al., 2023).
•f_sort_by() sắp xếp các hàng dựa trên nội dung của một cột cụ thể. Khi xử lý các câu hỏi hoặc phát biểu liên quan đến so sánh hoặc cực trị, LLMs có thể sử dụng thao tác này để sắp xếp lại các hàng. Mối quan hệ có thể được suy luận dễ dàng từ thứ tự của các hàng được sắp xếp.

A.2 NGHIÊN CỨU ABLATION

Để chứng minh hiệu quả của các thao tác nguyên tử được đề xuất của chúng tôi, chúng tôi thực hiện một nghiên cứu ablation bằng cách tạo ra năm biến thể leave-one-out của phương pháp chúng tôi, mỗi biến thể loại bỏ một trong các thao tác được định nghĩa trước khỏi nhóm thao tác được định nghĩa trước. Ví dụ, w/o f_add_column() có nghĩa là f_add_column() bị loại bỏ khỏi nhóm thao tác. Kết quả là, LLM chỉ có thể lập kế hoạch từ bốn thao tác còn lại ( f_select_column ,f_select_row ,f_group_by , và f_sort_by ) để xây dựng chuỗi thao tác. Chúng tôi báo cáo kết quả của nghiên cứu ablation trong Bảng 5.

Bảng 5: Nghiên cứu ablation về các thao tác nguyên tử được sử dụng trong CHAIN-OF-TABLE với PaLM 2 trên các bộ dữ liệu WikiTQ và TabFact. Chúng tôi quan sát thấy các thao tác chọn hàng và group-by có tác động lớn nhất đến hiệu suất hiểu bảng cuối cùng.
PromptingTabFact WikiTQ
Độ chính xác Độ chính xác
CHAIN-OF-TABLE 86.61 67.31
w/o f_add_column() 85.23 (-1.38) 65.88 (-1.43)
w/o f_select_column() 82.61 (-4.00) 65.68 (-1.63)
w/o f_select_row() 82.21 (-4.40) 65.06 (-2.25)
w/o f_group_by() 84.78 (-1.83) 61.88 (-5.43)
w/o f_sort_by() 86.21 (-0.40) 65.85 (-1.46)

Như được thể hiện trong Bảng 5, tất cả năm thao tác đều đóng góp vào hiệu suất tiên tiến cuối cùng của CHAIN-OF-TABLE, vì việc loại bỏ bất kỳ thao tác nào đều dẫn đến sự giảm hiệu suất. Đặc biệt, chúng tôi quan sát thấy f_select_row() và f_select_column() đóng góp nhiều nhất trên TabFact, trong khi f_group_by() đóng góp nhiều nhất trên WikiTQ. Điều này cho thấy các tác vụ khác nhau yêu cầu các thao tác khác nhau để giúp LLM xác định câu trả lời đúng. Do đó, việc tận dụng LLM để thiết kế chuỗi thao tác tùy chỉnh thông qua lập kế hoạch động tự nhiên phù hợp với các tác vụ khác nhau, dẫn đến hiệu suất vượt trội của phương pháp chúng tôi.
13

--- TRANG 14 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
B THÍ NGHIỆM CỦA CHAIN-OF-TABLE TRÊN FETAQA

Bảng 6 cho thấy CHAIN-OF-TABLE cũng cải thiện hiệu suất trả lời câu hỏi dạng tự do trên FeTaQA trên tất cả các chỉ số, trong khi Dater (Ye et al., 2023) thất bại trong việc cải thiện điểm ROUGE so với End-to-End QA. Chúng tôi cũng quan sát thấy sự cải thiện biên của CHAIN-OF-TABLE so với các phương pháp baseline. Chúng tôi quy điều này cho bản chất của các chỉ số tương tự văn bản n-gram của ROUGE-1/2/L (Lin, 2004). Như đã thảo luận trong Maynez et al. (2023); Dhingra et al. (2019), các chỉ số này được biết là không nhạy cảm trong việc nắm bắt các cải thiện khi sử dụng học trong ngữ cảnh vì mô hình không thể học được phong cách mong đợi của văn bản dạng dài chỉ từ một hướng dẫn hoặc một vài ví dụ. Chúng tôi lấy mẫu một số trường hợp từ FeTaQA như được thể hiện trong Hình 5 trong đó các chỉ số ROUGE gán điểm thấp; tuy nhiên, khi xem xét, chúng tôi quan sát thấy các câu trả lời được tạo ra là đúng.

Bảng 6: Kết quả hiểu bảng trên benchmark FeTaQA sử dụng PaLM 2 với kết quả tốt nhất được in đậm và cải thiện so với Dater (Ye et al., 2023) được báo cáo. (gạch dưới biểu thị hiệu suất tốt thứ hai; đậm biểu thị hiệu suất tốt nhất; cải thiện được đo so với phương pháp thực hiện tốt thứ hai.)
PromptingFeTaQA
BLEU ROUGE-1 ROUGE-2 ROUGE-L
End-to-End QA 28.37 0.63 0.41 0.53
Dater (Ye et al., 2023) 29.47 0.63 0.41 0.53
CHAIN-OF-TABLE (của chúng tôi) 32.61 (+3.14) 0.66 (+0.03) 0.44 (+0.03) 0.56 (+0.03)

Ví dụ từ FeTaQA
Câu hỏi : Ai là hai người hoàn thành cuối cùng trong môn bơi tự do 100 mét nam Olympic mùa hè 2000?
Câu trả lời : Denis Pimankov của Nga (49.36) và Chris Fydler của Úc (49.44) hoàn thành vòng chung kết.
Dự đoán : Hai người hoàn thành cuối cùng trong môn bơi tự do 100 mét nam Olympic mùa hè 2000 là Chris Fydler và Denis Pimankov.
Kết quả : ROUGE-1=0.33; ROUGE-2=0.12; ROUGE-L=0.11
Giải thích : Phản hồi được tạo ra trả lời đúng câu hỏi nhưng phong cách câu khác nhau. Từ các chỉ số, chúng ta có thể thấy điểm ROUGE dưới mức trung bình.

Hình 5: Ví dụ kết quả của CHAIN-OF-TABLE trên FeTaQA sử dụng điểm ROUGE làm chỉ số, trong đó các chỉ số ROUGE gán điểm rất thấp nhưng các câu trả lời được tạo ra là đúng.
14

--- TRANG 15 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
C THAM SỐ SUY LUẬN VÀ SỐ LƯỢNG MẪU DEMO CỦA CHAIN-OF-TABLE

Chúng tôi báo cáo các tham số và số lượng mẫu demo mà chúng tôi đã sử dụng trong CHAIN-OF-TABLE trong Bảng 7, 8 và 9. Nhìn chung, chúng tôi chú thích 29 mẫu và sử dụng chúng trên các bộ dữ liệu khác nhau. Có sự chồng chéo lớn giữa việc sử dụng trên các chức năng khác nhau. Ví dụ, chúng tôi sử dụng cùng một mẫu demo để giới thiệu cách sử dụng f_add_column trong hàm DynamicPlan trên các bộ dữ liệu khác nhau. Chúng tôi đảm bảo rằng tất cả các mẫu demo đều từ tập training nên chúng chưa được nhìn thấy trong quá trình kiểm tra. Chúng tôi lập luận rằng điều này tiếp tục chứng minh khung của chúng tôi không dựa vào một tập hợp demo cụ thể và có thể được tổng quát hóa tốt cho các bộ dữ liệu mới với cùng các prompts.

Bảng 7: Tham số LLM và số lượng mẫu demo trong CHAIN-OF-TABLE trên WikiTQ
Chức năngWikiTQ
temperature top_p decode_steps n_samples n_demos
DynamicPlan() 0.0 1.0 200 - 4
f_add_column() 0.0 1.0 200 - 6
f_select_row() 1.0 1.0 200 8 3
f_select_column() 1.0 1.0 200 8 8
f_group_by() 0.0 1.0 200 - 2
f_sort_by() 0.0 1.0 200 - 2
query() 0.0 1.0 200 - 1

Bảng 8: Tham số LLM và số lượng mẫu demo trong CHAIN-OF-TABLE trên TabFact
Chức năngTabFact
temperature top_p decode_steps n_samples n_demos
DynamicPlan() 0.0 1.0 200 - 4
f_add_column() 0.0 1.0 200 - 7
f_select_row() 0.5 1.0 200 8 4
f_select_column() 0.5 1.0 200 8 8
f_group_by() 0.0 1.0 200 - 2
f_sort_by() 0.0 1.0 200 - 2
query() 0.0 1.0 200 - 4

Bảng 9: Tham số LLM và số lượng mẫu demo trong CHAIN-OF-TABLE trên FeTaQA
Chức năngFeTaQA
temperature top_p decode_steps n_samples n_demos
DynamicPlan() 0.0 1.0 200 - 3
f_add_column() 0.0 1.0 200 - 6
f_select_row() 1.0 1.0 200 8 3
f_select_column() 1.0 1.0 200 8 8
f_group_by() 0.0 1.0 200 - 2
f_sort_by() 0.0 1.0 200 - 2
query() 0.0 1.0 200 - 8
15

--- TRANG 16 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
D SO SÁNH MÃ HÓA ĐỊNH DẠNG BẢNG

Phù hợp với các nghiên cứu trước Liu et al. (2023b; 2021); Jiang et al. (2022) và các phương pháp baseline Cheng et al. (2022); Ye et al. (2023), chúng tôi áp dụng mã hóa PIPE trong CHAIN-OF-TABLE (như được thể hiện trong Phụ lục E). Điều này tách biệt các lợi ích hiệu suất của CoT bảng được đề xuất với các thao tác nguyên tử khỏi ảnh hưởng của các lựa chọn định dạng bảng khác nhau.

Để hiểu thêm về tác động của các phương pháp mã hóa khác nhau đối với hiệu suất hiểu bảng, chúng tôi tiến hành thí nghiệm bổ sung sử dụng 3 biểu diễn bảng bổ sung: HTML, TSV, và Markdown. Đối với các thí nghiệm này, chúng tôi sử dụng End-to-End QA trên WikiTQ với PaLM 2 làm ví dụ chạy. Kết quả được thể hiện trong Bảng 10. Những phát hiện này cho thấy các phương pháp mã hóa định dạng bảng khác nhau dẫn đến các kết quả khác nhau. Đáng chú ý, định dạng PIPE được áp dụng trong nghiên cứu của chúng tôi mang lại hiệu suất cao nhất trong số bốn phương pháp mã hóa được thử nghiệm.

Bảng 10: So sánh mã hóa định dạng bảng trên WikiTQ với PaLM 2
PromptingMã hóa Định dạng Bảng
PIPE HTML TSV Markdown
End-to-End QA 60.6 56.1 58.1 58.0

E PROMPTS TRONG CHAIN-OF-TABLE

E.1 DynamicPlan

Chúng tôi minh họa phương pháp prompting được sử dụng bởi DynamicPlan(T,Q,chain) trong Hình 6 trong đó T là bảng trung gian mới nhất và Q là câu hỏi tương ứng của nó; chain là danh sách các thao tác được thực hiện trên bảng.

Với DynamicPlan, LLM có thể tạo ra phần còn lại của chuỗi thao tác cho mẫu hiện tại (Hình 6(c)). Chúng tôi ký hiệu các thao tác được tạo ra là fi+1(argsi+1)→...→[E] cho rằng fi là thao tác cuối cùng của chuỗi thao tác đầu vào mở. Mặc dù một chuỗi hoàn chỉnh được tạo ra, chúng tôi chỉ xem xét thao tác đầu tiên được tạo ra, fi+1, và bỏ qua phần còn lại của việc tạo ra bao gồm các đối số và thao tác còn lại. fi+1 được tạo ra dựa trên bảng trung gian mới nhất từ các thao tác trước đó, trong khi việc tạo ra các thao tác tiếp theo không dựa trên bảng trung gian cập nhật nhất nên có thể có sai sót trong nội dung được tạo ra. Do đó, chúng tôi tin rằng fi+1 là việc tạo ra đáng tin cậy nhất trong số tất cả các thao tác trong chuỗi được tạo ra. Xem Hình 9 để biết các prompts chi tiết hơn.

E.2 GenerateArgs

Chúng tôi minh họa các ví dụ demo và prompts được sử dụng bởi GenerateArgs(T,Q,f) trong Hình 7 trong đó T là bảng trung gian mới nhất và Q là câu hỏi tương ứng của nó; f là các thao tác bảng được chọn. Các prompts chi tiết cho mỗi thao tác và các biểu thức chính quy để trích xuất các đối số được tạo ra như sau.

•f_add_column : Xem Hình 10.
•f_select_row : Xem Hình 12.
•f_select_column : Xem Hình 11.
•f_group_by : Xem Hình 13.
•f_sort_by : Xem Hình 14.

E.3 Query

Chúng tôi minh họa các prompts được sử dụng bởi Query(T,Q) trong Hình 8 trong đó T là bảng kết quả từ CHAIN-OF-TABLE và Q là câu hỏi. Xem Hình 15 để biết các prompts chi tiết hơn.
16

--- TRANG 17 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
F CHI TIẾT TRIỂN KHAI CỦA CÁC PHƯƠNG PHÁP BASELINE

Chúng tôi chạy Text-to-SQL và Binder sử dụng mã và prompts mã nguồn mở chính thức tại https://github.com/HKUNLP/Binder. Chúng tôi chạy Dater sử dụng mã và prompts mã nguồn mở chính thức tại https://github.com/AlibabaResearch/DAMO-ConvAI. Chúng tôi sửa đổi mã để sử dụng GPT 3.5, PaLM 2, và LLaMA 2 (Mục 4) có sẵn công khai như LLM cốt lõi thay vì OpenAI Codex do không thể truy cập. Chúng tôi báo cáo các prompts chi tiết được sử dụng trong các phương pháp baseline khác như sau.

•End-to-End QA : Xem Hình 16.
•Few-Shot QA : Xem Hình 17.
•Chain-of-Thought : Các mẫu demo của Chain-of-Thought cho WikiTQ và TabFact là từ Chen (2023) ( https://github.com/wenhuchen/TableCoT ). Xem Hình 18.

{OPERATION_CHAIN_INSTRUCTION}{SERIALIZED_TABLE}Question:{QUESTION}Operation Chain:{COMPLETE_OPERATION_CHAIN}{OPERATION_INSTRUCTION}{SERIALIZED_TABLE}Question:{QUESTION}Operation:{OPERATION_AND_ARGUMENTS}Explanation:{INTRODUCION_TO_THE_OPERATION}
{SERIALIZED_LATEST_TABLE(T)}Question:{QUESTION(Q)}Candidates: {POSSIBLE_NEXT_OPERATIONS}Operation Chain:{INCOMPLETE_OPERATION_CHAIN(chain)}{REST_OPERATIONS_OF_OPERATION_CHAIN}……// Chuỗi thao tác hoàn chỉnh với thẻ kết thúc [E]Question: Năm cuối cùng mà đội này là một phần của USL a-league là năm nào?Operation Chain: f_add_column(Year) → f_select_row(row 1, row 2) → f_select_column(Year, League) → f_sort_column(Year) → [E]Mẫu Prompt của DynamicPlan(T, Q, chain)
// Trích xuất thao tác đầu tiên được tạo ra f_select_row như thao tác tiếp theo của chúng ta vì nó dựa trên bảng trung gian cập nhật nhấtf_select_row (row 1, row 2 … row 10 … → … → [E](a) Phần I - Demo Thao tác Nguyên tử
(b) Phần II: Demo Chuỗi Thao tác……
(c) Phần III: Mẫu Đầu vào// Chuỗi thao tác không hoàn chỉnh với mũi tên "→" ở cuối kích hoạt LLM hoàn thành chuỗi với các thao tác ứng viênQuestion: Quốc gia nào có nhiều tay đua nhất trong top 10?Candidates: f_select_row, f_select_column, …Operation Chain: f_add_column(Country) → // Giới thiệu cách các thao tác nguyên tử hoạt độngOperation: f_select_column(County, Population)Explanation: Câu hỏi yêu cầu … Chúng ta chỉ cần cột Country và Population để trả lời câu hỏi nên chúng ta sử dụng f_select_column để chọn chúng.
{REST_OPERATIONS_OF_OPERATION_CHAIN}

Hình 6: Minh họa DynamicPlan( T,Q,chain). Trái: Mẫu prompt tổng thể và tạo ra mong đợi, bao gồm (a) demo về cách các thao tác nguyên tử hoạt động, (b) demo về cách tạo ra một chuỗi thao tác hoàn chỉnh để trả lời một câu hỏi đã cho, và (c) prompt cho bảng đầu vào thực tế và câu hỏi của nó, và tạo ra mong đợi từ LLM (được tô sáng màu xanh lá). Phải: Ví dụ và giải thích ngắn gọn về mỗi phần trong prompt và tạo ra.

Khi f = f_add_column():Câu trả lời là: f_add_column(Country). Giá trị: ESP, RUS, …Khi f = f_select_row():Câu trả lời là: f_select_row(row 1, row 2, row 3…)Khi f = f_select_column():Câu trả lời là: f_select_column(Country, Rank)// Phân tích tạo ra LLM với các biểu thức chính quy được định nghĩa trước để trích xuất đối số.{OPERATION_INSTRUCTION(f)}{SERIALIZED_TABLE(T)}Question:{QUESTION(Q)}Explanation:{EXPLANATION}The answer is:{OPERATION_AND_ARGUMENTS}Mẫu Prompt của GenerateArgs(T, Q, f){EXPLANATION}The answer is:{OPERATION_AND_ARGUMENTS}Khi f = f_sort_by():Câu trả lời là: f_sort_by(Count). Thứ tự là từ-lớn-đến-nhỏ.Khi f = f_group_by():Câu trả lời là: f_group_by(Country)

Hình 7: Minh họa GenerateArgs( T,Q,f). Sau khi một thao tác cụ thể f được LLM lấy mẫu như thao tác tiếp theo, chúng tôi yêu cầu LLM tạo ra các đối số cần thiết bằng cách gọi GenerateArgs. Sau đó chúng tôi phân tích kết quả tạo ra của LLM theo các mẫu được định nghĩa trước để trích xuất các đối số.
17

--- TRANG 18 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
Mẫu Prompt của Query(T, Q){GENERAL_INSTRUCTION}{SERIALIZED_RESULTING_TABLE(T)}Question:{QUESTION(Q)}Answer:{answer}{answer}// Tạo ra trực tiếp câu trả lời với bảng kết quả từ Chain-of-Table

Hình 8: Minh họa Query( T,Q). Bảng kết quả từ chuỗi thao tác đóng vai trò như một đại diện cho các suy nghĩ trung gian của suy luận, cho phép chúng ta tạo ra trực tiếp câu trả lời mà không cần cung cấp chuỗi suy luận dưới định dạng văn bản.

========================================= Prompt =========================================
Nếu bảng chỉ cần một vài hàng để trả lời câu hỏi, chúng ta sử dụng f_select_row() để chọn những hàng này cho nó. Ví dụ,
/*
col : Home team | Home Team Score | Away Team | Away Team Score | Venue | Crowd
row 1 : st kilda | 13.12 (90) | melbourne | 13.11 (89) | moorabbin oval | 18836
row 2 : south melbourne | 9.12 (66) | footscray | 11.13 (79) | lake oval | 9154
row 3 : richmond | 20.17 (137) | fitzroy | 13.22 (100) | mcg | 27651
*/
Question : Điểm số đội nhà của ai cao hơn, richmond hay st kilda?
Function: f_select_row(row 1, row 3)
Explanation: Câu hỏi yêu cầu về điểm số đội nhà của richmond và st kilda. Chúng ta cần biết thông tin của richmond và st kilda ở hàng 1 và hàng 3. Chúng ta chọn hàng 1 và hàng 3.

Nếu bảng chỉ cần một vài cột để trả lời câu hỏi, chúng ta sử dụng f_select_column() để chọn những cột này cho nó. Ví dụ,
......

Nếu câu hỏi yêu cầu về các mục có cùng giá trị và số lượng của những mục này, chúng ta sử dụng f_group_by() để nhóm các mục. Ví dụ,
......

Nếu câu hỏi yêu cầu về thứ tự của các mục trong một cột, chúng ta sử dụng f_sort_by() để sắp xếp các mục. Ví dụ,
......

Dưới đây là ví dụ về việc sử dụng các thao tác để trả lời câu hỏi.
/*
col : Date | Division | League | Regular Season | Playoffs | Open Cup
row 1 : 2001/01/02 | 2 | USL A-League | 4th, Western | Quarterfinals | Did not qualify
row 2 : 2002/08/06 | 2 | USL A-League | 2nd, Pacific | 1st Round | Did not qualify
row 5 : 2005/03/24 | 2 | USL First Division | 5th | Quarterfinals | 4th Round
*/
Question: năm cuối cùng mà đội này là một phần của usl a-league là năm nào?
Function Chain: f_add_column(Year) -> f_select_row(row 1, row 2) ->
f_select_column(Year, League) -> f_sort_by(Year) -> <END>
......

/*
col : Rank | Cyclist | Team | Time | UCI ProTour; Points | Country
row 1 : 1 | Alejandro Valverde (ESP) | Caisse d'Epargne | 5h 29' 10" | 40 | ESP
row 2 : 2 | Alexandr Kolobnev (RUS) | Team CSC Saxo Bank | s.t. | 30 | RUS
row 3 : 3 | Davide Rebellin (ITA) | Gerolsteiner | s.t. | 25 | ITA
row 4 : 4 | Paolo Bettini (ITA) | Quick Step | s.t. | 20 | ITA
row 5 : 5 | Franco Pellizotti (ITA) | Liquigas | s.t. | 15 | ITA
row 6 : 6 | Denis Menchov (RUS) | Rabobank | s.t. | 11 | RUS
row 7 : 7 | Samuel Sánchez (ESP) | Euskaltel-Euskadi | s.t. | 7 | ESP
row 8 : 8 | Stéphane Goubert (FRA) | Ag2r-La Mondiale | + 2" | 5 | FRA
row 9 : 9 | Haimar Zubeldia (ESP) | Euskaltel-Euskadi | + 2" | 3 | ESP
row 10 : 10 | David Moncoutié (FRA) | Cofidis | + 2" | 1 | FRA
*/
Question: quốc gia nào có nhiều tay đua nhất hoàn thành trong top 10?
Thao tác tiếp theo phải là một trong f_select_row() hoặc f_select_column() hoặc f_group_by() hoặc f_sort_by().
Function Chain: f_add_column(Country) ->
======================================= Completion =======================================
f_select_row(row 1, row 10) -> f_select_column(Country) -> f_group_by(Country) -> <END>

Hình 9: Prompt DynamicPlan(T,Q,chain) được sử dụng cho WikiTQ
18

--- TRANG 19 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
Để trả lời câu hỏi, trước tiên chúng ta có thể sử dụng f_add_column() để thêm nhiều cột vào bảng.
Các cột được thêm vào nên có những loại dữ liệu này:
1. Numerical: các chuỗi số có thể được sử dụng trong sắp xếp, tổng
2. Datetype: các chuỗi mô tả một ngày tháng, chẳng hạn như năm, tháng, ngày
3. String: các chuỗi khác
/*
col : Week | When | Kickoff | Opponent | Results; Final score | Results; Team record
row 1 : 1 | Saturday, April 13 | 7:00 p.m. | at Rhein Fire | W 27-21 | 1-0
row 2 : 2 | Saturday, April 20 | 7:00 p.m. | London Monarchs | W 37-3 | 2-0
row 3 : 3 | Sunday, April 28 | 6:00 p.m. | at Barcelona Dragons | W 33-29 | 3-0
*/
Question: ngày của cuộc thi có số khán giả cao nhất là ngày nào?
Các cột hiện có là: "Week", "When", "Kickoff", "Opponent", "Results; Final score",
"Results; Team record", "Game site", "Attendance".
Explanation: câu hỏi yêu cầu về ngày của cuộc thi có điểm số cao nhất. Mỗi hàng là về một cuộc thi. Chúng ta trích xuất giá trị từ cột "Attendance" và tạo một cột khác "Attendance number" cho mỗi hàng. Kiểu dữ liệu là Numerical.
Do đó, câu trả lời là: f_add_column(Attendance number). Giá trị: 32092 | 34186 | 17503
/*
col : Rank | Lane | Player | Time
row 1 : | 5 | Olga Tereshkova (KAZ) | 51.86
row 2 : | 6 | Manjeet Kaur (IND) | 52.17
row 3 : | 3 | Asami Tanno (JPN) | 53.04
*/
Question: cho tôi biết số lượng vận động viên từ nhật bản.
Các cột hiện có là: Rank, Lane, Player, Time.
Explanation: câu hỏi yêu cầu về số lượng vận động viên từ nhật bản. Mỗi hàng là về một vận động viên. Chúng ta cần biết quốc gia của mỗi vận động viên. Chúng ta trích xuất giá trị từ cột "Player" và tạo một cột khác "Country of athletes" cho mỗi hàng. Kiểu dữ liệu là String.
Do đó, câu trả lời là: f_add_column(Country of athletes). Giá trị: KAZ | IND | JPN

Hình 10: Demos được sử dụng cho GenerateArgs(T,Q,f_add_column). Chúng tôi sử dụng biểu thức chính quy: f_add_column((.*)).The value:(.*) để trích xuất các đối số từ văn bản được tạo ra.

Sử dụng f_select_column() để lọc bỏ các cột vô dụng trong bảng theo thông tin trong phát biểu và bảng.
/*
{
"table_caption": "south wales derby",
"columns": ["competition", "total matches", "cardiff win", "draw", "swansea win"],
"table_column_priority": [
["competition", "league", "fa cup", "league cup"],
["total matches", "55", "2", "5"],
["cardiff win", "19", "0", "2"],
["draw", "16", "27", "0"],
["swansea win", "20", "2", "3"]
]
}
*/
statement : không có chiến thắng cardiff nào có hòa lớn hơn 27.
từ tương tự liên kết đến cột :
no cardiff wins -> cardiff win
a draw -> draw
giá trị cột liên kết đến cột :
27 -> draw
câu ngữ nghĩa liên kết đến cột :
None
Câu trả lời là : f_select_column([cardiff win, draw])

Hình 11: Demos được sử dụng cho GenerateArgs(T,Q,f_select_column). Chúng tôi sử dụng biểu thức chính quy: f_select_column([(.*)]) để trích xuất các đối số từ văn bản được tạo ra.
19

--- TRANG 20 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
Sử dụng f_select_row() để chọn các hàng có liên quan trong bảng đã cho hỗ trợ hoặc phản đối phát biểu.

Vui lòng sử dụng f_select_row([*]) để chọn tất cả các hàng trong bảng.
/*
table caption : 1972 vfl season.
col : home team | home team score | away team | away team score | venue | crowd
row 1 : st kilda | 13.12 (90) | melbourne | 13.11 (89) | moorabbin oval | 18836
row 2 : south melbourne | 9.12 (66) | footscray | 11.13 (79) | lake oval | 9154
row 3 : richmond | 20.17 (137) | fitzroy | 13.22 (100) | mcg | 27651
row 4 : geelong | 17.10 (112) | collingwood | 17.9 (111) | kardinia park | 23108
row 5 : north melbourne | 8.12 (60) | carlton | 23.11 (149) | arden street oval | 11271
row 6 : hawthorn | 15.16 (106) | essendon | 12.15 (87) | vfl park | 36749
*/
statement : đội khách nào có điểm số cao nhất?
explain : phát biểu muốn hỏi về đội khách có điểm số đội khách cao nhất. điểm số đội khách cao nhất là 23.11 (149). nó ở hàng 5. vậy chúng ta cần hàng 5.
Câu trả lời là : f_select_row([row 5])

Hình 12: Demos được sử dụng cho GenerateArgs(T,Q,f_select_row). Chúng tôi sử dụng biểu thức chính quy: f_select_row([(.*)]) để trích xuất các đối số từ văn bản được tạo ra.

Để trả lời câu hỏi, trước tiên chúng ta có thể sử dụng f_group_by() để nhóm các giá trị trong một cột.
/*
col : Rank | Lane | Athlete | Time | Country
row 1 : 1 | 6 | Manjeet Kaur (IND) | 52.17 | IND
row 2 : 2 | 5 | Olga Tereshkova (KAZ) | 51.86 | KAZ
row 3 : 3 | 4 | Pinki Pramanik (IND) | 53.06 | IND
row 4 : 4 | 1 | Tang Xiaoyin (CHN) | 53.66 | CHN
row 5 : 5 | 8 | Marina Maslyonko (KAZ) | 53.99 | KAZ
*/
Question: cho tôi biết số lượng vận động viên từ nhật bản.
Các cột hiện có là: Rank, Lane, Athlete, Time, Country.
Explanation: Câu hỏi yêu cầu về số lượng vận động viên từ Ấn Độ. Mỗi hàng là về một vận động viên. Chúng ta có thể nhóm cột "Country" để nhóm các vận động viên từ cùng một quốc gia.
Do đó, câu trả lời là: f_group_by(Country).

Hình 13: Demos được sử dụng cho GenerateArgs(T,Q,f_group_by). Chúng tôi sử dụng biểu thức chính quy: f_group_by((.*)) để trích xuất các đối số từ văn bản được tạo ra.

Để trả lời câu hỏi, trước tiên chúng ta có thể sử dụng f_sort_by() để sắp xếp các giá trị trong một cột để có được thứ tự của các mục. Thứ tự có thể là "lớn đến nhỏ" hoặc "nhỏ đến lớn".
Cột để sắp xếp nên có những loại dữ liệu này:
1. Numerical: các chuỗi số có thể được sử dụng trong sắp xếp
2. DateType: các chuỗi mô tả một ngày tháng, chẳng hạn như năm, tháng, ngày
3. String: các chuỗi khác
/*
col : Position | Club | Played | Points | Wins | Draws | Losses | Goals for | Goals against
row 1 : 1 | Malaga CF | 42 | 79 | 22 | 13 | 7 | 72 | 47
row 10 : 10 | CP Merida | 42 | 59 | 15 | 14 | 13 | 48 | 41
row 3 : 3 | CD Numancia | 42 | 73 | 21 | 10 | 11 | 68 | 40
*/
Question: câu lạc bộ nào đứng ở vị trí cuối cùng?
Các cột hiện có là: Position, Club, Played, Points, Wins, Draws, Losses, Goals for, Goals against
Explanation: câu hỏi yêu cầu về câu lạc bộ ở vị trí cuối cùng. Mỗi hàng là về một câu lạc bộ. Chúng ta cần biết thứ tự vị trí từ cuối lên đầu. Có một cột cho vị trí và tên cột là Position. Kiểu dữ liệu là Numerical.
Do đó, câu trả lời là: f_sort_by(Position), thứ tự là "lớn đến nhỏ".

Hình 14: Demos được sử dụng cho GenerateArgs(T,Q,f_sort_by). Chúng tôi sử dụng biểu thức chính quy: f_sort_by((.*)),the order is "(.*)". để trích xuất các đối số từ văn bản được tạo ra.
20

--- TRANG 21 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
========================================= Prompt =========================================
Đây là bảng để trả lời câu hỏi này. Vui lòng hiểu bảng và trả lời câu hỏi:
/*
col : Rank | City | Passengers Number | Ranking | Airline
row 1 : 1 | United States, Los Angeles | 14749 | 2 | Alaska Airlines
row 2 : 2 | United States, Houston | 5465 | 8 | United Express
row 3 : 3 | Canada, Calgary | 3761 | 5 | Air Transat, WestJet
row 4 : 4 | Canada, Saskatoon | 2282 | 4 |
row 5 : 5 | Canada, Vancouver | 2103 | 2 | Air Transat
row 6 : 6 | United States, Phoenix | 1829 | 1 | US Airways
row 7 : 7 | Canada, Toronto | 1202 | 1 | Air Transat, CanJet
row 8 : 8 | Canada, Edmonton | 110 | 2 |
row 9 : 9 | United States, Oakland | 107 | 5 |
*/
Question: có bao nhiều hành khách đã bay đến los angeles nhiều hơn đến saskatoon từ sân bay manzanillo năm 2013?
Câu trả lời là: 12467

Đây là bảng để trả lời câu hỏi này. Vui lòng hiểu bảng và trả lời câu hỏi:
/*
col : Rank | Country
row 1 : 1 | ESP
row 2 : 2 | RUS
row 3 : 3 | ITA
row 4 : 4 | ITA
row 5 : 5 | ITA
row 6 : 6 | RUS
row 7 : 7 | ESP
row 8 : 8 | FRA
row 9 : 9 | ESP
row 10 : 10 | FRA
*/
Nhóm các hàng theo cột "Country":
/*
Group ID | Country | Count
1 | ITA | 3
2 | ESP | 3
3 | RUS | 2
4 | FRA | 2
*/
Question: quốc gia nào có nhiều tay đua nhất trong top 10?
Câu trả lời là:
======================================= Completion =======================================
Ý.

Hình 15: Ví dụ Prompt được sử dụng cho Query(T,Q)
21

--- TRANG 22 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
========================================= Prompt =========================================
Đây là bảng để trả lời câu hỏi này. Trả lời câu hỏi.
/*
col : Name | League | FA Cup | League Cup | JP Trophy | Total
row 1 : Scot Bennett | 5 | 0 | 0 | 0 | 5
row 2 : Danny Coles | 3 | 0 | 0 | 0 | 3
row 3 : Liam Sercombe | 1 | 0 | 0 | 0 | 1
row 4 : Alan Gow | 4 | 0 | 0 | 0 | 4
row 5 : John O'Flynn | 11 | 0 | 1 | 0 | 12
row 6 : Guillem Bauza | 2 | 0 | 0 | 0 | 2
row 7 : Jimmy Keohane | 3 | 0 | 0 | 0 | 3
row 8 : Pat Baldwin | 1 | 0 | 0 | 0 | 1
row 9 : Jamie Cureton | 20 | 0 | 0 | 0 | 20
row 10 : Arron Davies | 3 | 0 | 0 | 0 | 3
row 11 : Jake Gosling | 1 | 0 | 0 | 0 | 1
row 12 : OWN GOALS | 0 | 0 | 0 | 0 | 0
row 13 : Total | 0 | 0 | 0 | 0 | 0
*/
Question: pat hay john có tổng điểm cao nhất?
Câu trả lời là:
======================================= Completion =======================================
John.

Hình 16: Prompt của End-to-end QA được sử dụng cho WikiTQ.
22

--- TRANG 23 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
========================================= Prompt =========================================
Đây là bảng để trả lời câu hỏi này. Trả lời câu hỏi.
/*
col : Rank | Cyclist | Team | Time | UCI ProTour; Points
row 1 : 1 | Alejandro Valverde (ESP) | Caisse d'Epargne | 5h 29' 10" | 40
row 2 : 2 | Alexandr Kolobnev (RUS) | Team CSC Saxo Bank | s.t. | 30
row 3 : 3 | Davide Rebellin (ITA) | Gerolsteiner | s.t. | 25
row 4 : 4 | Paolo Bettini (ITA) | Quick Step | s.t. | 20
row 5 : 5 | Franco Pellizotti (ITA) | Liquigas | s.t. | 15
row 6 : 6 | Denis Menchov (RUS) | Rabobank | s.t. | 11
row 7 : 7 | Samuel Sánchez (ESP) | Euskaltel-Euskadi | s.t. | 7
row 8 : 8 | Stéphane Goubert (FRA) | Ag2r-La Mondiale | + 2" | 5
row 9 : 9 | Haimar Zubeldia (ESP) | Euskaltel-Euskadi | + 2" | 3
row 10 : 10 | David Moncoutié (FRA) | Cofidis | + 2" | 1
*/
Question: quốc gia nào có nhiều tay đua nhất hoàn thành trong top 10?
Câu trả lời là: Ý.

Đây là bảng để trả lời câu hỏi này. Vui lòng đưa ra giải thích trước, sau đó trả lời câu hỏi bằng một cụm từ ngắn bắt đầu bằng 'do đó, câu trả lời là:'
/*
col : Rank | Cyclist | Team | Time | UCI ProTour; Points
row 1 : 1 | Alejandro Valverde (ESP) | Caisse d'Epargne | 5h 29' 10" | 40
row 2 : 2 | Alexandr Kolobnev (RUS) | Team CSC Saxo Bank | s.t. | 30
row 3 : 3 | Davide Rebellin (ITA) | Gerolsteiner | s.t. | 25
row 4 : 4 | Paolo Bettini (ITA) | Quick Step | s.t. | 20
row 5 : 5 | Franco Pellizotti (ITA) | Liquigas | s.t. | 15
row 6 : 6 | Denis Menchov (RUS) | Rabobank | s.t. | 11
row 7 : 7 | Samuel Sánchez (ESP) | Euskaltel-Euskadi | s.t. | 7
row 8 : 8 | Stéphane Goubert (FRA) | Ag2r-La Mondiale | + 2" | 5
row 9 : 9 | Haimar Zubeldia (ESP) | Euskaltel-Euskadi | + 2" | 3
row 10 : 10 | David Moncoutié (FRA) | Cofidis | + 2" | 1
*/
Question: có bao nhiều người chơi có ít hơn 10 điểm?
Câu trả lời là: 4.

Đây là bảng để trả lời câu hỏi này. Trả lời câu hỏi.
/*
col : Name | League | FA Cup | League Cup | JP Trophy | Total
row 1 : Scot Bennett | 5 | 0 | 0 | 0 | 5
row 2 : Danny Coles | 3 | 0 | 0 | 0 | 3
row 3 : Liam Sercombe | 1 | 0 | 0 | 0 | 1
row 4 : Alan Gow | 4 | 0 | 0 | 0 | 4
row 5 : John O'Flynn | 11 | 0 | 1 | 0 | 12
row 6 : Guillem Bauza | 2 | 0 | 0 | 0 | 2
row 7 : Jimmy Keohane | 3 | 0 | 0 | 0 | 3
row 8 : Pat Baldwin | 1 | 0 | 0 | 0 | 1
row 9 : Jamie Cureton | 20 | 0 | 0 | 0 | 20
row 10 : Arron Davies | 3 | 0 | 0 | 0 | 3
row 11 : Jake Gosling | 1 | 0 | 0 | 0 | 1
row 12 : OWN GOALS | 0 | 0 | 0 | 0 | 0
row 13 : Total | 0 | 0 | 0 | 0 | 0
*/
Question: pat hay john có tổng điểm cao nhất?
Câu trả lời là:
======================================= Completion =======================================
John.

Hình 17: Prompt của Few-shot QA được sử dụng cho WikiTQ
23

--- TRANG 24 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
========================================= Prompt =========================================
Đây là bảng để trả lời câu hỏi này. Vui lòng đưa ra giải thích trước, sau đó trả lời câu hỏi bằng một cụm từ ngắn bắt đầu bằng 'do đó, câu trả lời là:'
/*
col : Rank | Cyclist | Team | Time | UCI ProTour; Points
row 1 : 1 | Alejandro Valverde (ESP) | Caisse d'Epargne | 5h 29' 10" | 40
row 2 : 2 | Alexandr Kolobnev (RUS) | Team CSC Saxo Bank | s.t. | 30
row 3 : 3 | Davide Rebellin (ITA) | Gerolsteiner | s.t. | 25
row 4 : 4 | Paolo Bettini (ITA) | Quick Step | s.t. | 20
row 5 : 5 | Franco Pellizotti (ITA) | Liquigas | s.t. | 15
row 6 : 6 | Denis Menchov (RUS) | Rabobank | s.t. | 11
row 7 : 7 | Samuel Sánchez (ESP) | Euskaltel-Euskadi | s.t. | 7
row 8 : 8 | Stéphane Goubert (FRA) | Ag2r-La Mondiale | + 2" | 5
row 9 : 9 | Haimar Zubeldia (ESP) | Euskaltel-Euskadi | + 2" | 3
row 10 : 10 | David Moncoutié (FRA) | Cofidis | + 2" | 1
*/
Question: quốc gia nào có nhiều tay đua nhất hoàn thành trong top 10?
Explanation: ITA xuất hiện ba lần trong bảng, nhiều hơn bất kỳ quốc gia nào khác. Do đó, câu trả lời là: Ý.

Đây là bảng để trả lời câu hỏi này. Vui lòng đưa ra giải thích trước, sau đó trả lời câu hỏi bằng một cụm từ ngắn bắt đầu bằng 'do đó, câu trả lời là:'
/*
col : Rank | Cyclist | Team | Time | UCI ProTour; Points
row 1 : 1 | Alejandro Valverde (ESP) | Caisse d'Epargne | 5h 29' 10" | 40
row 2 : 2 | Alexandr Kolobnev (RUS) | Team CSC Saxo Bank | s.t. | 30
row 3 : 3 | Davide Rebellin (ITA) | Gerolsteiner | s.t. | 25
row 4 : 4 | Paolo Bettini (ITA) | Quick Step | s.t. | 20
row 5 : 5 | Franco Pellizotti (ITA) | Liquigas | s.t. | 15
row 6 : 6 | Denis Menchov (RUS) | Rabobank | s.t. | 11
row 7 : 7 | Samuel Sánchez (ESP) | Euskaltel-Euskadi | s.t. | 7
row 8 : 8 | Stéphane Goubert (FRA) | Ag2r-La Mondiale | + 2" | 5
row 9 : 9 | Haimar Zubeldia (ESP) | Euskaltel-Euskadi | + 2" | 3
row 10 : 10 | David Moncoutié (FRA) | Cofidis | + 2" | 1
*/
Question: có bao nhiều người chơi có ít hơn 10 điểm?
Explanation: Samuel Sánchez, Stéphane Goubert, Haimar Zubeldia và David Moncoutié nhận được ít hơn 10 điểm. Do đó, câu trả lời là: 4.

Đây là bảng để trả lời câu hỏi này. Vui lòng đưa ra giải thích trước, sau đó trả lời câu hỏi bằng một cụm từ ngắn bắt đầu bằng 'do đó, câu trả lời là:'
/*
col : Name | League | FA Cup | League Cup | JP Trophy | Total
row 1 : Scot Bennett | 5 | 0 | 0 | 0 | 5
row 2 : Danny Coles | 3 | 0 | 0 | 0 | 3
row 3 : Liam Sercombe | 1 | 0 | 0 | 0 | 1
row 4 : Alan Gow | 4 | 0 | 0 | 0 | 4
row 5 : John O'Flynn | 11 | 0 | 1 | 0 | 12
row 6 : Guillem Bauza | 2 | 0 | 0 | 0 | 2
row 7 : Jimmy Keohane | 3 | 0 | 0 | 0 | 3
row 8 : Pat Baldwin | 1 | 0 | 0 | 0 | 1
row 9 : Jamie Cureton | 20 | 0 | 0 | 0 | 20
row 10 : Arron Davies | 3 | 0 | 0 | 0 | 3
row 11 : Jake Gosling | 1 | 0 | 0 | 0 | 1
row 12 : OWN GOALS | 0 | 0 | 0 | 0 | 0
row 13 : Total | 0 | 0 | 0 | 0 | 0
*/
Question: pat hay john có tổng điểm cao nhất?
Explanation:
======================================= Completion =======================================
John O'Flynn có tổng điểm cao nhất là 12 bàn thắng. Pat Baldwin có tổng điểm thấp nhất là 1 bàn thắng.
Do đó, câu trả lời là: John.

Hình 18: Prompt của Chain-of-Thought được sử dụng cho WikiTQ
24

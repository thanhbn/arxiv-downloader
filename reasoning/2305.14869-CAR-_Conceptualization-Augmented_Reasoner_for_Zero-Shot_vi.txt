# CAR: Bộ Lập Luận Tăng Cường Khái Niệm hóa cho Trả Lời Câu Hỏi Thông Thường Không Có Giám Sát

Weiqi Wang1∗, Tianqing Fang1∗, Wenxuan Ding1, Baixuan Xu1, Xin Liu1,
Yangqiu Song1, Antoine Bosselut2
1Khoa Khoa học Máy tính và Kỹ thuật, HKUST, Hồng Kông SAR, Trung Quốc
2Phòng thí nghiệm NLP, Trường Khoa học Máy tính và Truyền thông, EPFL, Thụy Sĩ
{wwangbw, tfangaa, yqsong}@cse.ust.hk, antoine.bosselut@epfl.ch

## Tóm tắt

Nhiệm vụ trả lời câu hỏi thông thường không giám sát đánh giá khả năng của các mô hình trong việc lập luận về các tình huống chung vượt ra ngoài những gì được trình bày trong các bộ dữ liệu cụ thể. Các phương pháp hiện tại để giải quyết nhiệm vụ này tận dụng kiến thức bên ngoài từ Cơ sở Kiến thức Thông thường (CSKB) bằng cách tiền huấn luyện mô hình trên các cặp QA tổng hợp được xây dựng từ CSKB. Trong các phương pháp này, các ví dụ phủ định (yếu tố gây nhiễu) được hình thành bằng cách lấy mẫu ngẫu nhiên từ CSKB sử dụng các ràng buộc từ khóa khá nguyên thủy. Tuy nhiên, hai nút thắt cổ chai hạn chế các phương pháp này: tính không đầy đủ vốn có của CSKB hạn chế phạm vi ngữ nghĩa của các cặp QA tổng hợp, và việc thiếu các chú thích của con người làm cho các ví dụ phủ định được lấy mẫu có thể không mang tính thông tin và mâu thuẫn.

Để giải quyết những hạn chế nêu trên, chúng tôi đề xuất Bộ Lập Luận Tăng Cường Khái Niệm hóa (CAR), một khung trả lời câu hỏi thông thường không giám sát hoàn toàn tận dụng sức mạnh của khái niệm hóa. Cụ thể, CAR trừu tượng hóa một bộ ba kiến thức thông thường thành nhiều thể hiện cấp cao hơn, điều này tăng phạm vi bao phủ của CSKB và mở rộng không gian câu trả lời đúng, giảm khả năng chọn các yếu tố gây nhiễu sai âm tính.

Các thí nghiệm mở rộng chứng minh rằng CAR tổng quát hóa mạnh mẽ hơn trong việc trả lời câu hỏi về các tình huống thông thường không giám sát so với các phương pháp hiện tại, bao gồm các mô hình ngôn ngữ lớn như GPT3.5 và ChatGPT. Mã nguồn, dữ liệu và các checkpoint mô hình của chúng tôi có sẵn tại https://github.com/HKUST-KnowComp/CAR.

## 1 Giới thiệu

Các Mô hình Ngôn ngữ Được Tiền huấn luyện (PLM; Devlin et al., 2019; Clark et al., 2020) được tinh chỉnh trên các tập huấn luyện cụ thể theo tác vụ đạt được hiệu suất xuất sắc gần bằng con người trên các tập kiểm tra được giữ lại, nhưng gặp khó khăn trong việc tổng quát hóa cho các ví dụ khác biệt về mặt phân phối so với tập huấn luyện của chúng (McCoy et al., 2019; Ma et al., 2019; Zhou et al., 2021; Wang et al., 2021). Sự khác biệt này xuất hiện vì các PLM được tinh chỉnh thường dựa vào các tương quan giả mạo, đặc thù cho bộ dữ liệu để học một tác vụ thay vì học cách tận dụng đầy đủ kiến thức thông thường ngầm định cần thiết cho lập luận (Branco et al., 2021). Tuy nhiên, để các hệ thống lập luận có hiệu quả, chúng phải mạnh mẽ trên các lĩnh vực và tổng quát hóa vượt ra ngoài các đặc thù của từng bộ dữ liệu riêng lẻ.

Để đối đầu với vấn đề tổng quát hóa trong các tác vụ lập luận thông thường, tác vụ Trả lời Câu hỏi (QA) thông thường không giám sát yêu cầu các mô hình trả lời câu hỏi cho các benchmark đánh giá mà không có quyền truy cập vào dữ liệu huấn luyện tương ứng của chúng (Shwartz et al., 2020; Li et al., 2020). Trong số các phương pháp giải quyết tác vụ này, những phương pháp hiệu quả nhất tiêm kiến thức thông thường từ CSKB (Hwang et al., 2021; Jiang et al., 2021) vào PLM bằng cách tinh chỉnh chúng trên các cặp QA tổng hợp được chuyển đổi từ các bộ ba kiến thức thông thường, trong đó đầu và quan hệ được chuyển đổi thành câu hỏi, và đuôi phục vụ như câu trả lời cơ sở. Các ví dụ phủ định được lấy mẫu ngẫu nhiên với các ràng buộc chồng chéo từ khóa (Ma et al., 2021). Việc tiêm kiến thức như vậy không chỉ có lợi cho QA mà còn cho các tác vụ được suy ra từ CSKB, chẳng hạn như SocialIQA (Sap et al., 2019b), được suy ra từ ATOMIC (Sap et al., 2019a), mà còn cho các bộ dữ liệu QA trong các lĩnh vực khác (Bisk et al., 2020).

Mặc dù có những tiến bộ gần đây trong lĩnh vực này, hai thách thức chính vẫn còn. Thứ nhất, các CSKB được tuyển chọn thủ công, chẳng hạn như ATOMIC, là không đầy đủ (Kuo và Hsu, 2010). Mặc dù việc hợp nhất nhiều CSKB có thể cải thiện phạm vi bao phủ, nhưng vẫn không khả thi để bao phủ tất cả kiến thức có thể nghĩ đến cho phạm vi rộng lớn các thực thể và tình huống trong thế giới thực (He et al., 2022). Các phương pháp tự động để mở rộng CSKB tồn tại, chẳng hạn như hoàn thiện cơ sở kiến thức (Li et al., 2016; Malaviya et al., 2020), và chưng cất kiến thức từ các mô hình ngôn ngữ lớn (West et al., 2022; Gao et al., 2023), nhưng chúng hoặc không cung cấp kiến thức về các thực thể mới hoặc chỉ cung cấp kiến thức có độ chính xác cao nhưng ít thông tin (ví dụ, các tính từ mơ hồ, chẳng hạn như vui vẻ, như các mô tả tình huống). Thứ hai, trong QA thông thường không giám sát, các ví dụ phủ định được yêu cầu cho các mô hình để học phân biệt tính hợp lệ của các tình huống thông thường (Chen et al., 2023a). Tuy nhiên, các ví dụ QA phủ định hiện tại được tổng hợp bằng cách sử dụng lấy mẫu phủ định dựa trên heuristic đơn giản mà không xem xét ngữ nghĩa sâu hơn, dẫn đến quá nhiều tùy chọn sai âm tính. Ví dụ, trong Hình 1, "uống nước" cũng hợp lý trong bối cảnh "sau khi chơi bóng đá." Những câu hỏi gắn nhãn các tùy chọn hợp lý như các thể hiện phủ định làm cho mô hình bối rối trong quá trình huấn luyện, cản trở khả năng phân biệt kiến thức thông thường đúng của nó.

Chúng tôi giải quyết cả hai thách thức này bằng cách sử dụng khái niệm hóa. Như Murphy (2004) khẳng định, con người dựa vào quy nạp khái niệm để rút ra các suy luận về các tình huống chưa thấy mà không cần phải ghi nhớ kiến thức cụ thể. Khái niệm hóa (He et al., 2022) cung cấp khả năng tương tự bằng cách trừu tượng hóa một tập hợp các thể hiện thành các khái niệm, cho phép suy ra kiến thức thông thường trừu tượng liên quan đến mỗi khái niệm có thể được cụ thể hóa để hỗ trợ lập luận trên các tình huống hạ nguồn cụ thể. Ví dụ, trong Hình 2, "chơi một trận bóng đá" có thể được khái niệm hóa như một sự kiện mệt mỏi, điều này tiếp tục tổng quát hóa như kiến thức trừu tượng. Lợi ích của khái niệm hóa có hai mặt. Thứ nhất, kiến thức thông thường được khái niệm hóa giới thiệu kiến thức trừu tượng thông qua suy luận khái niệm một bước dựa trên CSKB gốc, tăng cường phạm vi bao phủ kiến thức. Thứ hai, vì kiến thức trừu tượng được điều kiện hóa trên kiến thức gốc, việc thu hồi kiến thức liên quan đến cùng một đầu được tăng lên, dẫn đến các ràng buộc tinh tế hơn cho việc lấy mẫu tùy chọn phủ định.

Được truyền cảm hứng từ những lợi thế này, chúng tôi đề xuất CAR (Bộ Lập Luận Tăng Cường Khái Niệm hóa), một khung QA thông thường không giám sát đơn giản nhưng hiệu quả tận dụng khái niệm hóa để mở rộng CSKB hiện tại và giảm các yếu tố gây nhiễu sai âm tính. Chúng tôi đầu tiên tăng cường CSKB gốc bằng khái niệm hóa để truyền kiến thức thông thường trừu tượng nhằm cải thiện phạm vi bao phủ kiến thức. Sau đó, chúng tôi đề xuất một chiến lược lấy mẫu có ràng buộc khái niệm hóa tạo ra các yếu tố gây nhiễu với các ràng buộc cấp khái niệm để ngăn chặn các tùy chọn sai âm tính (Phần 4). Kết quả thí nghiệm trên năm benchmark QA thông thường phổ biến chứng minh hiệu quả của CAR, thậm chí vượt qua GPT3.5 và ChatGPT (Phần 5). Trong Phần 6, chúng tôi phân tích tại sao CAR hoạt động bằng cách cung cấp các đánh giá của con người cho thấy giảm đáng kể các tùy chọn sai âm tính so với các phương pháp khác. Cuối cùng, phân tích của chúng tôi tiết lộ rằng các ví dụ huấn luyện tăng cường khái niệm hóa có xu hướng mơ hồ hơn (Swayamdipta et al., 2020) so với những ví dụ được tạo ra bởi các heuristic trước đây, dẫn đến tổng quát hóa ngoài miền tốt hơn.

## 2 Các Công trình Liên quan

**QA Thông thường Không giám sát.** QA thông thường không giám sát đánh giá khả năng tổng quát hóa lập luận của mô hình trên các mục QA chưa thấy mà không có bất kỳ tín hiệu giám sát nào từ dữ liệu huấn luyện được chú thích tương ứng. Để giải quyết tác vụ này, hai pipeline chính đã xuất hiện trong các công trình hiện tại. Paradigm đầu tiên sử dụng các mô hình ngôn ngữ có sẵn mà không thay đổi tham số, hoặc sử dụng mô hình ngôn ngữ vanilla với prompt (Trinh và Le, 2018; Li et al., 2022), hoặc với một số cơ chế thời gian suy luận được thiết kế đặc biệt cho lập luận, chẳng hạn như tự nói chuyện (Shwartz et al., 2020), dịch cloze (Dou và Peng, 2022), và tạo động các đồ thị con lập luận và lập luận đồ thị (Bosselut et al., 2021). Pipeline thứ hai tận dụng CSKB bên ngoài như nguồn kiến thức để cung cấp cho PLM các tín hiệu giám sát bổ sung cho việc tinh chỉnh thêm (Banerjee và Baral, 2020; Ma et al., 2021; Su et al., 2022). Một chiến lược phổ biến liên quan đến việc chuyển đổi các bộ ba kiến thức trong CSKB thành các cặp QA tổng hợp bằng cách chuyển đổi đầu và quan hệ thành câu hỏi, đuôi thành câu trả lời vàng, và lấy mẫu (ngẫu nhiên) đuôi từ các đầu khác như yếu tố gây nhiễu. Paradigm tinh chỉnh như vậy hưởng lợi từ việc kết hợp CSKB trong các lĩnh vực khác nhau (Kim et al., 2022; Shi et al., 2023) và khai thác cấu trúc đồ thị đa bước với mạng nơ-ron đồ thị (Guan et al., 2023), và nâng cao độ nhạy cảm thông thường của mô hình trong bối cảnh QA, dẫn đến hiệu suất tiên tiến.

**Khái niệm hóa.** Khái niệm hóa đề cập đến quá trình trừu tượng hóa một nhóm các thể hiện hoặc sự kiện thành một khái niệm chung (Song et al., 2011, 2015). Trong lập luận thông thường, nó mô phỏng quy nạp khái niệm (Murphy, 2004) và cho phép suy ra kiến thức thông thường trừu tượng dưới sự ngữ cảnh hóa cụ thể của kiến thức thông thường gốc (Tenenbaum et al., 2011), điều này thường thiếu trong CSKB hiện tại. Xung quanh nhiều công trình hiện tại nghiên cứu khái niệm hóa (Durme et al., 2009; Gong et al., 2016; Liu et al., 2022; Peng et al., 2022), He et al. (2022) điều tra nó ở ngữ nghĩa cấp sự kiện và xây dựng AbstractATOMIC, một benchmark khái niệm hóa sự kiện và cơ sở kiến thức dựa trên ATOMIC (Sap et al., 2019a). Gần đây, Wang et al. (2023a) đề xuất khái niệm hóa CSKB ở quy mô với học bán giám sát và chứng minh kiến thức trừu tượng có thể tăng cường mô hình suy luận thông thường (Bosselut et al., 2019; Da et al., 2021). Với các công trình hiện tại chủ yếu điều tra vấn đề khái niệm hóa bản thân, không ai trong số họ đã đánh giá tác động bên ngoài của khái niệm hóa đối với các tác vụ hạ nguồn, chẳng hạn như QA thông thường (Talmor et al., 2019) hoặc hiểu đọc máy (Nguyen et al., 2016).

**Tăng cường Dữ liệu.** Tăng cường dữ liệu nhằm tạo ra các ví dụ mới từ dữ liệu hiện có để mở rộng kích thước và tính đa dạng của tập huấn luyện mà không cần các chú thích dữ liệu tốn kém (Wei và Zou, 2019). Các phương pháp khác nhau đã được đề xuất để tăng cường dữ liệu văn bản, bao gồm những phương pháp sử dụng nhiễu loạn ngẫu nhiên (Wei và Zou, 2019), nhúng văn bản (Wang và Yang, 2015), ngữ nghĩa từ vựng (Niu và Bansal, 2018), dịch ngược (Sennrich et al., 2016), và các mô hình ngôn ngữ lớn (West et al., 2022; Ismayilzada và Bosselut, 2023; Gao et al., 2023) để xây dựng CSKB. Tuy nhiên, các tăng cường dựa trên nhiễu loạn văn bản không cung cấp kiến thức mới cho CSKB, và khai thác kiến thức từ các mô hình ngôn ngữ lớn gặp phải tính điển hình cao (ví dụ, ưa chuộng thông thường đơn giản hơn thông thường có thông tin nhưng hiếm) và mật độ thấp, vẫn làm cho việc lấy mẫu phủ định chịu sai âm tính (Malaviya et al., 2020).

## 3 Định nghĩa Vấn đề

### 3.1 Định nghĩa

**Khái niệm hóa.** Chính thức, ký hiệu một CSKB như D với các bộ ba kiến thức ở định dạng D={(h, r, t)|h∈H, r∈R, t∈T}, trong đó H, R, và T là các tập hợp của đầu, quan hệ, và đuôi trong CSKB gốc. Theo He et al. (2022), CSKB được khái niệm hóa, có điều kiện trên D, có thể được ký hiệu như DC={(hc, r, t)|hc∈Hc, r∈R, t∈T}, trong đó Hc là tập hợp các sự kiện đầu được khái niệm hóa. Cụ thể, mỗi đầu được khái niệm hóa hc được thu được bằng cách thay thế một thành phần i∈h bằng khái niệm trừu tượng c của nó trong khi đảm bảo rằng bộ ba (hc, r, t) được hình thành vẫn hợp lý trong bối cảnh gốc (r, t). Các bộ ba (hc, r, t) như vậy thường được gọi là kiến thức thông thường trừu tượng.

**QA Thông thường Không giám sát.** Trong bài báo này, chúng tôi sử dụng tác vụ QA thông thường không giám sát được đề xuất bởi Ma et al. (2021) để nghiên cứu khung của chúng tôi. Đầu tiên, CSKB D được chuyển đổi thành nhiều cặp (Qi, Ai) trong đó Qi là câu hỏi ngôn ngữ tự nhiên và Ai={Ai,1, Ai,2, ..., Ai,m} là tập hợp các tùy chọn với m ứng viên. Cụ thể, đối với một bộ ba kiến thức cho trước (h, r, t)∈D, chúng tôi chuyển đổi h, r thành Qi thông qua các mẫu ngôn ngữ tự nhiên và sử dụng t như câu trả lời cơ sở. Ngoài ra, chúng tôi lấy m−1 yếu tố gây nhiễu từ các bộ ba khác được lấy mẫu từ D sử dụng một chiến lược được định nghĩa thủ công, chẳng hạn như lọc chồng chéo từ khóa. Mục tiêu của tác vụ của chúng tôi là huấn luyện mô hình QA từ các tập QA tổng hợp DQ={(Qi, Ai)|(hi, ri, ti)∈D}. Sau khi được huấn luyện, mô hình được kiểm tra trên các mục kiểm tra được giữ lại (Qtest, Atest) từ các benchmark QA. Điều này yêu cầu mô hình thực hiện lập luận thông thường không giám sát vì dữ liệu huấn luyện từ các benchmark mục tiêu không có sẵn cho mô hình.

### 3.2 Bộ dữ liệu

Chúng tôi sử dụng ATOMIC (Sap et al., 2019b) như CSKB nguồn D. ATOMIC chứa kiến thức thông thường suy luận, ở định dạng bộ ba (h, r, t), liên quan đến các sự kiện thường thấy. Cụ thể, đầu của các bộ ba ATOMIC là các sự kiện, trong khi các nút đuôi là các sự kiện hoặc thuộc tính. Để khái niệm hóa, chúng tôi sử dụng kiến thức trừu tượng được chú thích bởi con người từ AbstractATOMIC (He et al., 2022) để huấn luyện một bộ khái niệm hóa tạo sinh để thu được DC. Chi tiết hơn về khái niệm hóa và thống kê của AbstractATOMIC được cung cấp trong Phần 4.1 và Phụ lục B.1.

### 3.3 Benchmark Đánh giá

Theo Ma et al. (2021), chúng tôi đánh giá khung của chúng tôi trên split validation của năm benchmark QA thông thường: Abductive NLI (aNLI; Bhagavatula et al., 2020), CommonsenseQA (CSQA; Talmor et al., 2019), PhysicalIQA (PIQA; Bisk et al., 2020), SocialIQA (SIQA; Sap et al., 2019b), và WinoGrande (WG; Sakaguchi et al., 2021). Những benchmark được xây dựng thủ công này đánh giá các loại kiến thức khác nhau cần thiết cho lập luận thông thường mạnh mẽ (Kim et al., 2022). Thống kê chi tiết và giải thích của những benchmark này được cung cấp trong Phụ lục A.

## 4 Khung CAR

Phần này giới thiệu khung CAR được đề xuất của chúng tôi. Một bản phác thảo tổng quát được trình bày trong Hình 3. Khung của chúng tôi có thể được tóm tắt thành ba bước: (1) Thực hiện suy luận khái niệm hóa một bước trên các bộ ba hiện tại trong CSKB để thu được các bộ ba kiến thức thông thường trừu tượng. (2) Chuyển các bộ ba thành các cặp QA và tạo ra các yếu tố gây nhiễu sử dụng từ khóa và khái niệm hóa như các ràng buộc. (3) Huấn luyện mô hình QA sử dụng loss xếp hạng biên.

### 4.1 Tăng cường Khái niệm hóa

Để kết hợp kiến thức trừu tượng vào CSKB, chúng tôi bắt đầu bằng việc tăng cường các bộ ba (h, r, t)∈D bằng cách thực hiện suy luận khái niệm hóa một bước. Ban đầu, cho một sự kiện đầu h, chúng tôi lấy tất cả các khái niệm hóa hợp lý Ch={ci1,1, ci1,2, ...} cho tất cả các thể hiện được xác định i∈{i1, i2, ...|i∈h} sử dụng heuristic liên kết thực thể để lấy các khái niệm từ Probase (Wu et al., 2012) và WordNet (Miller, 1995). Sự kiện đầu được khái niệm hóa hc sau đó được thu được bằng cách thay thế một i∈h bằng một trong các khái niệm hóa được lấy c∈{ci,1, ci,2, ...}. Điều này được thực hiện cho tất cả các thể hiện được xác định và các khái niệm hóa được lấy của chúng, từ đó xây dựng tập hợp các sự kiện đầu được khái niệm hóa của h. Tiếp theo, chúng tôi liên kết đối tác phi trừu tượng (r, t) sau hc để tạo ra các bộ ba kiến thức trừu tượng ứng viên (hc, r, t), trong đó chúng tôi áp dụng một bộ phân biệt được huấn luyện với khung khái niệm hóa-cụ thể hóa bán giám sát để xác định tính hợp lý của chúng (Wang et al., 2023a). Chỉ các bộ ba hợp lý được giữ lại để hình thành DC. Chi tiết về quá trình lấy khái niệm hóa và bộ phân biệt được trình bày trong Phụ lục B.1.

### 4.2 Tổng hợp QA Có Ràng buộc Khái niệm

Để tổng hợp một bộ ba thông thường (h, r, t) thành cặp (Qi, Ai), chúng tôi đầu tiên chuyển h, r thành Qi bằng cách sử dụng các mẫu ngôn ngữ tự nhiên và đặt t như câu trả lời đúng A1. Ví dụ, bộ ba trong Hình 3 trở thành "PersonX đến quầy bar, PersonX muốn làm gì?" với câu trả lời là "thư giãn." Các yếu tố gây nhiễu bổ sung được tạo ra bằng cách chuyển đổi các bộ ba yếu tố gây nhiễu được lấy mẫu từ CSKB gốc, trong đó chỉ các bộ ba có cùng quan hệ thông thường r được lấy mẫu để đảm bảo tính thông tin. Để ngăn chặn việc lấy mẫu các tùy chọn sai âm tính, chúng tôi ràng buộc việc lấy mẫu kiến thức yếu tố gây nhiễu bằng cách lọc từ khóa và khái niệm hóa.

Chính thức, ký hiệu các từ khóa của sự kiện đầu h như Th={t1, t2,···} và tập hợp đầy đủ các khái niệm hóa hợp lý cho tất cả các thể hiện được xác định trong h như Ch={ci1,1, ci1,2,···, ci2,1,···}, chúng tôi liên kết một bộ ba (h, r, t) với Th+Ch để hình thành ràng buộc của nó. Chỉ bộ ba kiến thức (h′, r, t′) thỏa mãn (Th′+Ch′)∩(Th+Ch)=∅ mới có thể được lấy mẫu như một ứng viên yếu tố gây nhiễu. Ràng buộc này yêu cầu hai bộ ba không có từ khóa chung, và các thể hiện của chúng không thể được trừu tượng hóa thành cùng một khái niệm hóa. Ví dụ, trong Hình 3, "(PersonX ở sòng bạc, xWant, uống nước)" không thể được sử dụng như một bộ ba yếu tố gây nhiễu vì "sòng bạc" có thể được khái niệm hóa như "nơi giải trí," giống như "quầy bar" trong bộ ba gốc. Cuối cùng, chúng tôi lấy mẫu hai bộ ba yếu tố gây nhiễu cho bộ ba (h, r, t) và sử dụng đuôi của hai bộ ba này như các yếu tố gây nhiễu. Để đảm bảo rằng kiến thức thông thường trừu tượng từ việc tăng cường trước đó của chúng tôi có thể học được bởi mô hình QA, chúng tôi tổng hợp cả bộ ba gốc (h, r, t) và các phiên bản được khái niệm hóa (hc, r, t) thành các cặp QA.

### 4.3 Huấn luyện Mô hình

Theo Ma et al. (2021), chúng tôi huấn luyện mô hình QA của chúng tôi bằng cách tinh chỉnh Mô hình Ngôn ngữ Có Mask Được Tiền huấn luyện (MLM) sử dụng loss Xếp hạng Biên (MR). Gọi C đại diện cho bối cảnh gốc (nếu có), Q đại diện cho câu hỏi, và (A1, A2, ...) là danh sách các tùy chọn. Chúng tôi đầu tiên nối C, Q, và một tùy chọn câu trả lời Ai cùng nhau thông qua các prompt ngôn ngữ tự nhiên để tạo ra các chuỗi đầu vào (T1, T2, ...). Ví dụ, câu hỏi được tổng hợp với câu trả lời đúng của nó trong Hình 3 sẽ được chuyển đổi thành: "PersonX đến quầy bar, kết quả là PersonX muốn thư giãn." Sau đó chúng tôi lặp lại việc che một token tại một thời điểm và tính toán loss mask. Điểm MLM cuối cùng cho chuỗi đầu vào T∈{T1, T2, ...} với n token là:

S(T) = −1/n ∑(i=1 to n) log P(ti|..., ti−1, ti+1, ...)     (1)

Sau khi tính toán điểm S1, S2, ... cho tất cả ứng viên câu trả lời A1, A2, ..., chúng tôi tính toán loss xếp hạng biên dựa trên Phương trình 2, trong đó η đại diện cho biên và y là chỉ số của câu trả lời đúng.

L = 1/m ∑(i=1,i≠y to m) max(0, η−Sy+Si)     (2)

Trong giai đoạn đánh giá, chúng tôi sử dụng cùng quy trình tính điểm để gán điểm cho mỗi tùy chọn và chọn tùy chọn có câu nối đạt điểm thấp nhất làm dự đoán của mô hình.

## 5 Thí nghiệm

### 5.1 Thiết lập

**Baseline** Đầu tiên, chúng tôi sử dụng bỏ phiếu ngẫu nhiên (Random) và gắn nhãn thường xuyên nhất (Majority) để chứng minh đặc điểm của mỗi benchmark. PLM RoBERTa-Large (Liu et al., 2019) và DeBERTa-v3-Large (He et al., 2023) vanilla được sử dụng để chứng minh sức mạnh của việc tinh chỉnh. Hiệu suất của hai mô hình này dưới chế độ huấn luyện có giám sát cũng được bao gồm để hiển thị giới hạn trên của kết quả của chúng tôi. Chúng tôi cũng bao gồm kết quả của một số phương pháp hiện tại giải quyết cùng tác vụ, bao gồm Self-talk (Shwartz et al., 2020), COMET-DynaGen (Bosselut et al., 2021), SMLM (Banerjee và Baral, 2020), MICO (Su et al., 2022), và STL-Adapter tiên tiến trước đây (Kim et al., 2022). Quan trọng nhất, chúng tôi so sánh khung của chúng tôi với Ma et al. (2021) để xác thực hiệu quả của khái niệm hóa vì cả hai phương pháp đều chia sẻ kiến trúc mô hình và quy trình huấn luyện tương tự. Cả RoBERTa-Large và DeBERTa-v3-Large đều được sử dụng như backbone để so sánh công bằng. Có tổng cộng 534.833 cặp QA tổng hợp được cung cấp bởi Ma et al. (2021).

Với những tiến bộ gần đây trong Mô hình Ngôn ngữ Lớn (LLM) (Bang et al., 2023; Chan et al., 2023; Qin et al., 2023), chúng tôi cũng benchmark hiệu suất của GPT3.5 (Brown et al., 2020; Ouyang et al., 2022) và ChatGPT (OpenAI, 2022) như baseline. Chúng tôi prompt LLM trực tiếp trong thiết lập không giám sát, trong đó không áp dụng học trong ngữ cảnh (Min et al., 2022) hoặc lập luận chuỗi tư duy (Wei et al., 2022). Đối với mỗi mục QA, LLM được trình bày với một câu hỏi, một số lựa chọn, và lệnh ngôn ngữ tự nhiên yêu cầu nó chọn chỉ số của câu trả lời đúng trực tiếp (Robinson et al., 2022). Sau đó chúng tôi phân tích các đầu ra được tạo để thu được "dự đoán" của LLM bằng cách sử dụng các quy tắc được thiết kế tỉ mỉ và so sánh chúng với nhãn sự thật cơ sở. Chi tiết hơn về baseline và thiết lập LLM có thể được tìm thấy trong Phụ lục B.2 và B.3.

**Chi tiết Triển khai** Chúng tôi sử dụng độ chính xác như thước đo đánh giá và so sánh khung của chúng tôi với các phương pháp baseline sau. Để khái niệm hóa, chúng tôi tận dụng một bộ khái niệm hóa có sẵn từ Wang et al. (2023a), là một bộ phân biệt khái niệm hóa bán giám sát được tinh chỉnh trên dữ liệu khái niệm hóa được gắn nhãn từ AbstractATOMIC và dữ liệu không gắn nhãn từ ATOMIC. Chúng tôi sử dụng điểm hợp lý T=0.9 để lọc ra các khái niệm hóa hợp lý, dẫn đến 440K cặp QA tổng hợp hỗ trợ khái niệm hóa để huấn luyện. Chúng tôi sử dụng optimizer AdamW (Loshchilov và Hutter, 2019) với tốc độ học 7e-6 và độ dài chuỗi tối đa 128 để phù hợp với các cặp QA có độ dài khác nhau. Chúng tôi chọn checkpoint tốt nhất theo độ chính xác cao nhất đạt được trên tập QA validation tổng hợp. Mỗi thí nghiệm được lặp lại sử dụng ba seed ngẫu nhiên khác nhau, và hiệu suất trung bình được báo cáo. Mô hình được khởi động với 5% tổng số lần lặp và được đánh giá mỗi 1000 bước toàn cục, trong khi biên η cho loss xếp hạng biên được đặt thành 1, phù hợp với các lựa chọn được thực hiện bởi Ma et al. (2021) và Kim et al. (2022). Chi tiết hơn về triển khai có thể được tìm thấy trong Phụ lục B.4.

### 5.2 Kết quả

Kết quả chính được báo cáo trong Bảng 1. Đối với baseline, DeBERTa-v3-Large (MR) được huấn luyện trên ATOMIC đạt hiệu suất tốt nhất, tiếp theo là ChatGPT. Cả hai đều đạt độ chính xác hơn 70% trung bình. Hệ thống tốt nhất của chúng tôi, dựa trên DeBERTa-v3-Large và được huấn luyện trên ATOMIC tăng cường khái niệm hóa của chúng tôi, đạt kết quả tiên tiến và vượt trội đáng kể so với tất cả baseline dựa trên PLM trên mọi benchmark, và có thể nâng cao độ chính xác trung bình 2.1% so với mô hình baseline tương tự. Nó cũng vượt trội đáng kể so với hiệu suất của cùng mô hình được huấn luyện trên ATOMIC-10X chỉ với 10% lượng dữ liệu (giải thích và thí nghiệm thêm trong Phụ lục B.5). Đáng chú ý, so với LLM, hệ thống của chúng tôi chiến thắng ba benchmark và hoạt động tốt hơn trung bình với bước nhảy 3.7%. Điều này cho thấy tín hiệu giám sát từ CSKB quan trọng cho các ứng dụng hạ nguồn, và CSKB được hỗ trợ bởi khái niệm hóa có thể tăng cường đáng kể quá trình này. Hơn nữa, như một nghiên cứu loại bỏ, chúng tôi nghiên cứu vai trò của việc lấy mẫu yếu tố gây nhiễu cấp khái niệm bằng cách loại bỏ việc tăng cường khái niệm hóa và chỉ huấn luyện các mô hình trên ATOMIC, được tổng hợp thành định dạng QA với kỹ thuật ràng buộc được đề xuất của chúng tôi. So sánh kết quả trong Bảng 1, có thể quan sát thấy rằng việc lấy mẫu yếu tố gây nhiễu cấp khái niệm cải thiện hiệu suất trung bình khoảng 1.5%. Điều này chứng minh rằng kỹ thuật được đề xuất của chúng tôi có hiệu quả, và tạo ra các yếu tố gây nhiễu với việc thu hồi kiến thức tích cực mạnh hơn có ích trong việc tổng hợp các cặp QA vừa công bằng vừa có thông tin.

## 6 Phân tích và Thảo luận

Trong phần này, chúng tôi nghiên cứu tác động của khái niệm hóa và lý do góp phần vào thành công của CAR. Đầu tiên, chúng tôi thực hiện đánh giá chuyên gia về các cặp QA tổng hợp để nghiên cứu chất lượng và tính đa dạng của các phương pháp tăng cường CSKB khác nhau so với khái niệm hóa. Thứ hai, chúng tôi thực hiện phân tích động lực huấn luyện (Swayamdipta et al., 2020) để chỉ ra rằng các cặp QA hỗ trợ khái niệm hóa có thể cung cấp các ví dụ mơ hồ hơn hữu ích cho huấn luyện. Cuối cùng, chúng tôi nghiên cứu tác động của việc lọc ATOMIC10X với các ngưỡng critic khác nhau, các nghiên cứu loại bỏ của CAR, và tác động của khái niệm hóa từ góc độ tổng quát hóa ngoài miền trong Phụ lục B.5, B.7, và B.8.

### 6.1 So sánh với Tăng cường Dữ liệu

Để chứng minh hiệu quả của phương pháp khái niệm hóa được đề xuất của chúng tôi, chúng tôi thực hiện phân tích toàn diện với các tăng cường dữ liệu khác mở rộng phạm vi bao phủ ngữ nghĩa của CSKB theo cách tương tự như khái niệm hóa sử dụng cả đánh giá chuyên gia và tự động. Chúng tôi sử dụng EDA, tăng cường với nhúng từ (Word2Vec; Mikolov et al., 2013 và GLOVE; Pennington et al., 2014), nhúng ngữ cảnh (BERT; Devlin et al., 2019), và từ đồng nghĩa (WordNet; Miller, 1995) như baseline. Để liên kết tất cả baseline cho so sánh công bằng, chúng tôi chỉ tăng cường thể hiện được xác định i∈h trong sự kiện đầu h của mỗi bộ ba ATOMIC theo số lượng khái niệm hóa hợp lệ |Ch| của nó. Ngoài ra, chúng tôi lấy mẫu ngẫu nhiên cùng một lượng kiến thức khác từ ATOMIC-10X vào ATOMIC như một dạng tăng cường bằng cách chưng cất GPT3 (Brown et al., 2020) để đặt việc chưng cất LLM như một baseline khác (giải thích thêm trong Phụ lục B.5).

Chúng tôi phân tích toàn diện so sánh sử dụng ba chiều: tính đa dạng, chất lượng của cặp QA tổng hợp, và hiệu suất QA thông thường không giám sát. Ba chú thích viên chuyên gia được tuyển dụng để tạo thuận lợi cho các đánh giá của chúng tôi, là sinh viên đại học hoặc sau đại học tích cực tham gia nghiên cứu thông thường. Họ thể hiện mức độ đồng thuận cao giữa nhau, với IAA 83% về thỏa thuận theo cặp và điểm Fleiss Kappa (McHugh, 2012) là 0.64, so sánh với 0.62, như báo cáo bởi (Ma et al., 2021).

**Tính đa dạng.** Đầu tiên, chúng tôi nghiên cứu liệu việc tăng cường có thể giới thiệu kiến thức mới vào tập huấn luyện hay không. Chúng tôi bắt đầu bằng cách tính toán độ tương tự cosine trung bình của mỗi bộ ba ATOMIC và các anh em được tăng cường từ mỗi phương pháp theo nhúng SentenceBERT (Reimers và Gurevych, 2019) của chúng. Đối với ATOMIC-10X, chúng tôi coi kiến thức được lấy mẫu như tăng cường. Phần bù của độ tương tự trung bình trên tất cả bộ ba ATOMIC phục vụ như tính đa dạng được đo tự động (Div.). Trong khi đó, chúng tôi lấy top-10 bộ ba tương tự từ ATOMIC cho mỗi bộ ba được tăng cường theo độ tương tự SentenceBERT của chúng. Các chuyên gia được yêu cầu chú thích liệu mỗi bộ ba có thể được bao phủ về mặt ngữ nghĩa bởi các lần lấy của chúng hay không. Chúng tôi định nghĩa tính đa dạng được đánh giá bởi chuyên gia như tỷ lệ các bộ ba không được bao phủ trong 300 mẫu. Bảng 2 cho thấy khái niệm hóa chiến thắng cả hai thước đo, cho thấy kiến thức trừu tượng được giới thiệu đa dạng và thiếu trong CSKB hiện tại, điều này hữu ích trong việc mở rộng phạm vi bao phủ kiến thức của chúng.

**Chất lượng của Cặp QA Tổng hợp.** Tiếp theo, chúng tôi tổng hợp các bộ ba được tăng cường thành các cặp QA với từ khóa của sự kiện đầu và các tăng cường như ràng buộc. Sau đó chúng tôi lấy mẫu 300 cặp QA cho mỗi phương pháp và yêu cầu cùng các chuyên gia thực hiện đánh giá chuyên gia bằng cách chú thích tính đúng đắn của câu trả lời sự thật cơ sở của mỗi cặp QA và liệu các yếu tố gây nhiễu có thể hợp lý đối với sự kiện đầu được tăng cường hay không. Điều này đánh giá tỷ lệ hợp lý của kiến thức được tăng cường và tỷ lệ các cặp QA chứa các yếu tố gây nhiễu sai âm tính. Bảng 2 cho thấy đa số kiến thức được tăng cường không hợp lý, và chúng không thể tăng cường việc lấy mẫu yếu tố gây nhiễu. Mặt khác, khái niệm hóa duy trì tính hợp lý cao và có thể loại bỏ hiệu quả các yếu tố gây nhiễu sai âm tính. Các chú thích viên chuyên gia cũng đạt độ chính xác đáng kể 86% khi làm việc trên 300 cặp câu hỏi-câu trả lời được lấy mẫu ngẫu nhiên, vượt qua độ chính xác 80% được báo cáo bởi Ma et al. (2021).

**Hiệu suất QA Thông thường Không giám sát.** Cuối cùng, chúng tôi huấn luyện các mô hình DeBERTa-v3-Large trên các cặp QA được tổng hợp từ việc nối cả bộ ba ATOMIC gốc và được tăng cường từ mỗi phương pháp. Chỉ từ khóa của mỗi sự kiện đầu được sử dụng như ràng buộc của chúng. Các mô hình được huấn luyện sử dụng loss xếp hạng biên, như được giải thích trong Phần 4.3, và được đánh giá trên năm benchmark QA theo cách không giám sát. Hiệu suất bởi các phương pháp khác nhau được hiển thị trong Bảng 2. Chúng tôi quan sát thấy khái niệm hóa vượt trội so với tất cả các tăng cường khác trung bình và thành công cải thiện khả năng lập luận thông thường không giám sát của mô hình.

**So sánh với ATOMIC-10X.** Tăng cường ATOMIC10X có vẻ là một tùy chọn hứa hẹn vì nó chứa kho tàng kiến thức thông thường có giá trị. Tuy nhiên, mặc dù kiến thức đa dạng và chất lượng cao, Bảng 2 chứng minh rằng mô hình không thể tận dụng thông tin này hiệu quả. Một lời giải thích có thể là hiệu suất của mô hình bị cản trở bởi số lượng đáng kể các yếu tố gây nhiễu sai âm tính. Vấn đề này xuất hiện vì kiến thức được chưng cất từ GPT-3 có xu hướng linh hoạt, dẫn đến nhiều sự kiện đuôi chung chung và mơ hồ. Những sự kiện này có thể được áp dụng cho một bộ sưu tập lớn các đầu, dẫn đến các tùy chọn sai âm tính. Thí nghiệm và nghiên cứu trường hợp thêm trong Phụ lục B.5 và C tương ứng.

### 6.2 Phân tích Động lực Huấn luyện

Động lực huấn luyện đánh giá hiệu quả độ tin cậy và biến động của mô hình cho các thể hiện riêng lẻ khi huấn luyện trên bộ dữ liệu lớn. Trong bối cảnh QA, chúng tôi định nghĩa độ tin cậy như sự chắc chắn của mô hình khi gán nhãn đúng cho tùy chọn sự thật cơ sở so với các yếu tố gây nhiễu, như được chỉ ra bởi sự khác biệt logit. Mặt khác, biến động đề cập đến sự dao động của độ tin cậy theo thời gian. Những hiểu biết này có thể hỗ trợ phân tích hành vi của mô hình khi kiến thức khác nhau được giới thiệu vào tập huấn luyện. Giải thích thêm trong Phụ lục B.6.

Trong phần này, chúng tôi kiểm tra tác động của kiến thức thông thường trừu tượng (khái niệm hóa) và kiến thức được chưng cất GPT3 (ATOMIC-10X) bằng cách khám phá động lực huấn luyện của chúng trên hai tập dữ liệu. Chúng tôi huấn luyện ba mô hình QA trên các cặp QA tổng hợp từ ATOMIC tăng cường khái niệm hóa, ATOMIC được tăng cường ATOMIC10X, và ATOMIC gốc, phục vụ như baseline. Đầu tiên, chúng tôi chọn ngẫu nhiên cùng 1.000 cặp QA được tổng hợp từ ATOMIC gốc và tính toán động lực huấn luyện của chúng sử dụng ba mô hình này. Phía bên trái Hình 4 hiển thị các thay đổi được gây ra bởi hai phương pháp tăng cường so với baseline. Rõ ràng rằng việc giới thiệu kiến thức thông thường trừu tượng thông qua khái niệm hóa giảm đáng kể biến động trung bình của mô hình và tăng cường độ tin cậy của nó trong việc học kiến thức từ ATOMIC gốc. Ngược lại, việc kết hợp kiến thức từ ATOMIC-10X tạo ra hiệu ứng ngược lại.

Thứ hai, chúng tôi kiểm tra động lực huấn luyện trên 1.000 cặp QA được lấy mẫu ngẫu nhiên được tổng hợp từ kiến thức thông thường trừu tượng và 1.000 khác từ kiến thức trong ATOMIC-10X. Các biểu đồ ngoài cùng bên phải trong Hình 4 tiết lộ rằng, so với ATOMIC-10X, khái niệm hóa giới thiệu kiến thức với biến động cao hơn và độ tin cậy thấp hơn, làm cho nó mơ hồ hơn và thách thức hơn cho mô hình học. Như Swayamdipta et al. (2020) đề xuất, dữ liệu như vậy góp phần vào mô hình mạnh mẽ hơn đối với dữ liệu ngoài phân phối (OOD), là các bộ dữ liệu QA hạ nguồn trong trường hợp của chúng tôi. Do đó, chúng tôi kết luận rằng khái niệm hóa vượt trội so với ATOMIC-10X như kiến thức trừu tượng, một mặt, làm cho kiến thức gốc dễ học hơn để hỗ trợ tối ưu hóa, và mặt khác, cung cấp các ví dụ mơ hồ hơn để thúc đẩy tổng quát hóa OOD.

### 6.3 Tác động của Kích thước Dữ liệu Huấn luyện

Trong Hình 5, chúng tôi trình bày ảnh hưởng của số lượng ví dụ huấn luyện đối với hiệu suất cuối cùng, tiết lộ xu hướng rõ ràng và trực quan về tương quan tích cực giữa lượng dữ liệu huấn luyện và hiệu suất tổng thể.

### 6.4 Tổng quát hóa cho CSKB khác

Chúng tôi khám phá tính khả thi của việc chuyển khung của chúng tôi sang CSKB khác ngoài ATOMIC. Chúng tôi lấy bộ dữ liệu CWWV làm ví dụ, bao gồm nhiều CSKB, bao gồm ConceptNet (Speer et al., 2017), WordNet (Miller, 1995), và WikiData (Vrandecic và Krötzsch, 2014). Chúng tôi sử dụng bộ khái niệm hóa GPT2 có sẵn (Wang et al., 2023a) và ChatGPT như hai bộ khái niệm hóa tạo sinh linh hoạt. Các khái niệm hóa được tạo sau đó được chuyển đổi thành kiến thức trừu tượng và tích hợp vào bộ dữ liệu CWWV. Kết quả thí nghiệm được trình bày trong Bảng 3, cho thấy cải thiện hơn 1% so với tất cả baseline tận dụng CWWV như nguồn kiến thức, cho thấy khả năng tổng quát hóa của CAR cho CSKB khác. Chi tiết hơn được trình bày trong Phụ lục B.9.

## 7 Kết luận

Trong bài báo này, chúng tôi trình bày CAR, một khung tiên phong cho QA thông thường không giám sát được trao quyền bởi khái niệm hóa. Phương pháp của chúng tôi vượt qua thậm chí các mô hình ngôn ngữ lớn trên năm benchmark QA, đạt hiệu suất tiên tiến trung bình. Phân tích của chúng tôi tiết lộ rằng khái niệm hóa có thể cải thiện việc lấy mẫu các ví dụ phủ định, và kiến thức trừu tượng hữu ích hơn so với những gì được chưng cất từ GPT3 vì nó cung cấp kiến thức mơ hồ hơn để hỗ trợ tổng quát hóa OOD. Những phát hiện này chứng minh lợi ích đáng kể của việc giới thiệu khái niệm hóa và kiến thức trừu tượng vào lập luận thông thường không giám sát.

## Hạn chế

Một hạn chế của bài báo này là khung CAR được đề xuất chỉ được xác thực trên bộ dữ liệu ATOMIC. Mặc dù các công trình trước đây (Ma et al., 2021; Kim et al., 2022; Dou và Peng, 2022) đã nghiên cứu tác vụ trả lời câu hỏi thông thường không giám sát bằng cách hợp nhất nhiều CSKB, bao gồm ATOMIC (Sap et al., 2019a), ConceptNet (Speer et al., 2017), WordNet (Miller, 1995), VisualGenome (Krishna et al., 2017), và WikiData (Vrandecic và Krötzsch, 2014), công trình của chúng tôi chỉ sử dụng ATOMIC (chi tiết hơn được thảo luận trong Phụ lục B.2). Điều này chủ yếu do tính sẵn có của khái niệm hóa cho CSKB, với chỉ AbstractATOMIC (He et al., 2022) có sẵn như sự mở rộng được khái niệm hóa của ATOMIC, trong khi các CSKB khác thiếu tài nguyên như vậy. Ngoài ra, ATOMIC đã được chứng minh đóng vai trò quan trọng nhất trong kết quả thí nghiệm bởi Ma et al. (2021). Tuy nhiên, hạn chế như vậy không hạn chế tiềm năng của CAR để tìm kiếm các cải thiện thêm từ việc kết hợp các CSKB khác, vì các khung khái niệm hóa, chẳng hạn như CAT (Wang et al., 2023a), có thể được áp dụng cho các CSKB khác và cung cấp các tài nguyên cần thiết cho CAR để hoạt động. Do đó, chúng tôi tin rằng CAR có thể vượt qua những hạn chế như vậy và vẫn sở hữu tiềm năng cải thiện với nhiều tài nguyên khái niệm hóa liên quan CSKB có sẵn.

## Tuyên bố Đạo đức

Bài báo này trình bày CAR, một khung mới cho trả lời câu hỏi thông thường không giám sát đạt hiệu suất tiên tiến thông qua khái niệm hóa. Tất cả các bộ dữ liệu được sử dụng, bao gồm ATOMIC, AbstractATOMIC, và các benchmark trả lời câu hỏi thông thường, đều có sẵn công khai và được chia sẻ thông qua giấy phép truy cập mở chỉ dành cho mục đích nghiên cứu, phù hợp với mục đích sử dụng dự định của chúng. Những bộ dữ liệu này được ẩn danh hóa và khử nhạy cảm, đảm bảo rằng không có vấn đề bảo mật dữ liệu nào liên quan.

Hơn nữa, khung CAR là hệ thống trả lời câu hỏi chọn lựa chọn hợp lý nhất từ danh sách các tùy chọn và không tạo ra bất kỳ thông tin riêng tư, xúc phạm, thiên vị, hoặc nhạy cảm nào hoặc các vấn đề xã hội và chính trị. Các chú thích chuyên gia được thực hiện bởi các tác giả của bài báo này như một phần đóng góp của họ, là sinh viên sau đại học và đại học làm việc về thông thường máy trong xử lý ngôn ngữ tự nhiên, và họ hoàn toàn nhận thức về giao thức chú thích và mục đích sử dụng dự định của các chú thích của họ. Họ được đào tạo tốt với các hướng dẫn được thiết kế đặc biệt và đã tự nguyện đồng ý tham gia mà không có bồi thường. Dựa trên điều này, các tác giả tin rằng bài báo này không gây ra bất kỳ lo ngại đạo đức nào theo hiểu biết tốt nhất của họ.

## Lời cảm ơn

Các tác giả muốn cảm ơn Haochen Shi vì sự giúp đỡ của anh ấy trong việc triển khai động lực huấn luyện và các nhà đánh giá ẩn danh vì những bình luận xây dựng của họ. Các tác giả của bài báo này được hỗ trợ bởi Quỹ NSFC (U20B2053) từ NSFC của Trung Quốc, RIF (R6020-19 và R6021-20), và GRF (16211520 và 16205322) từ RGC của Hồng Kông. Chúng tôi cũng cảm ơn sự hỗ trợ từ Các Khoản Tài trợ Nghiên cứu Phù hợp UGC (RMGS20EG01-D, RMGS20CR11, RMGS20CR12, RMGS20EG19, RMGS20EG21, RMGS23CR05, RMGS23EG08). Chúng tôi cũng biết ơn nhận ra sự hỗ trợ của Quỹ Khoa học Quốc gia Thụy Sĩ (Số 215390), Innosuisse (PFFS-21-29), Quỹ Hạt giống Khoa học EPFL, Trung tâm Hình ảnh EPFL, Sony Group Corporation, và Viện Allen cho AI.

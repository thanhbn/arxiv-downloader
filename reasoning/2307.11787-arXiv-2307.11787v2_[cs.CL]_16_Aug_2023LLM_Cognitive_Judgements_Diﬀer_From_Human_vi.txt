# 2307.11787.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/reasoning/2307.11787.pdf
# Kích thước tệp: 128467 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
arXiv:2307.11787v2 [cs.CL] 16 Tháng 8 2023 Đánh Giá Nhận Thức của LLM Khác Với Con Người

Sotiris Lamprinidis
sotiris@lamprinidis.com
Copenhagen, Đan Mạch

Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLMs) gần đây đã trở thành tâm điểm chú ý của các nhà nghiên cứu, doanh nghiệp và người tiêu dùng. Trong khi khả năng ngôn ngữ của các mô hình này đã được nghiên cứu rộng rãi, có sự quan tâm ngày càng tăng trong việc điều tra chúng như những chủ thể nhận thức. Trong nghiên cứu này, tôi kiểm tra khả năng của GPT-3 và ChatGPT trên một nhiệm vụ lý luận quy nạp với dữ liệu hạn chế từ tài liệu khoa học nhận thức. Kết quả cho thấy rằng các đánh giá nhận thức của những mô hình này không giống con người.

Từ khóa— Mô hình Ngôn ngữ Lớn, GPT-3, ChatGPT, Lý luận Quy nạp, Đánh giá Nhận thức

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLMs), được đại diện bởi OpenAI ChatGPT [23], gần đây đã có tác động lớn đến dư luận: trong thang điểm tối đa 100, các thuật ngữ "ChatGPT" và "AI" đã tăng vọt từ 0 và 28 tương ứng vào ngày 20 tháng 11 năm 2022 lên 73 và 99 tương ứng vào ngày 30 tháng 4 năm 2023¹ Sự lạc quan này cũng được phản ánh trong Thị trường, khi định giá của các công ty "tiếp xúc với AI" đã tăng vọt [1]. Các nhà nghiên cứu đã bày tỏ ý kiến trái chiều về khả năng thực sự của các mô hình này, từ những tuyên bố mạnh mẽ về Trí tuệ Nhân tạo Tổng quát [8] (Microsoft là đồng sở hữu của OpenAI) và việc gán thuộc tính có vẻ nhân tính về ý thức cho các mô hình này [20] (mà con người một phần đồng ý [29]), đến việc bác bỏ bất kỳ khái niệm nổi lên nào về trí tuệ hoặc hành vi giống con người [10, 13, 18].

Có lẽ được trình bày rõ ràng nhất trong [3], không rõ liệu LLMs có hiểu ngôn ngữ, hay chúng chỉ rất thành thạo trong việc thao tác các ký hiệu ngôn ngữ, mà chúng ta con người dễ bị tổn thương khi ngầm diễn giải như thể chúng mạch lạc. Thực tế, ngay cả trước thế hệ LLMs hiện tại, đã có sự tập trung vào việc khám phá các năng lực và khả năng ngôn ngữ tổng quát [16, 28, 31, 27], cũng như tính giống con người của các Mô hình Ngôn ngữ [16, 12]. Theo tinh thần tương tự, đã có những điều tra rộng rãi về hiệu suất ChatGPT trong các nhiệm vụ Xử lý Ngôn ngữ Tự nhiên (NLP) [2], khám phá hiệu suất tổng thể tốt nhưng khả năng kém khi nói đến lý luận và cụ thể là lý luận quy nạp, cũng như báo cáo rộng rãi về các thất bại của ChatGPT [5]. Ngoài ra, phản hồi của ChatGPT dường như bắt chước chính xác việc sử dụng ngôn ngữ của con người [9]. Liệu những kết quả tích cực này có thể hỗ trợ cho các tuyên bố về trí tuệ hoặc ý thức của LLMs?

¹Nguồn dữ liệu: Google Trends (https://www.google.com/trends).

--- TRANG 2 ---
Tôi đề xuất rằng sức mạnh của bằng chứng nên tỷ lệ thuận với sức mạnh của các tuyên bố được đưa ra, và như vậy bất kỳ hành vi nổi lên nào có vẻ vượt qua lĩnh vực ngôn ngữ đơn thuần khi nói đến khả năng của LLMs nên được xem xét từ góc độ nhận thức.

2 Nghiên cứu Trước đây
Một nghiên cứu sớm về GPT-3 [6] đã kiểm tra các phản hồi một cách định tính trong cái được gọi là "Bài kiểm tra Turing của Tác giả" và tìm thấy hành vi không nhất quán: "[GPT-3] không tốt hơn những nhà văn và triết gia giỏi nhất của chúng ta ở đỉnh cao. Liệu những khoảnh khắc tốt nhất của nó có tốt hơn nhiều con người và thậm chí có lẽ, những nhà văn giỏi nhất của chúng ta ở trạng thái tệ nhất? Khá có thể [11]. Các nghiên cứu khác đã tập trung vào việc đánh giá LLMs trong các thí nghiệm từ tài liệu tâm lý học nhận thức và tính giống con người của phản hồi của chúng. [4] đã tìm thấy GPT-3 chủ yếu đưa ra phản hồi giống con người. Tuy nhiên, một vấn đề thường xuyên với những nghiên cứu này là việc ghi nhớ rõ ràng các tài liệu. Khi hỏi GPT-3 về các nhiệm vụ trong [4], tôi đã tìm thấy rằng nhiều nhiệm vụ được sử dụng (tất cả của Kahneman & Tversky, nhiệm vụ Lựa chọn Thẻ của Wason, và nhiệm vụ Blicket) có thể được kể lại chính xác bởi mô hình.

Một loạt các nghiên cứu tìm hiểu Lý thuyết Tâm trí (ToM) của LLMs - khả năng gán các trạng thái tinh thần cho người khác. [17] đã kiểm tra cả ChatGPT và GPT-4 ToM sử dụng tài liệu từ Kahneman & Tversky. Tương tự như [4], tôi đã tìm thấy rằng ChatGPT có thể kể lại chính xác tất cả các nhiệm vụ. GPT-4 ToM cũng được điều tra định tính trong [14] sử dụng 10 nghịch lý triết học. Ở đây cũng vậy, tôi đã tìm thấy rằng ChatGPT (mô hình tiền nhiệm) có thể kể lại 9 trong số 10 nghịch lý. Một nghiên cứu khác tập trung vào ChatGPT ToM đã áp dụng các phương pháp lâm sàng được sử dụng để đánh giá ToM bệnh lý ở con người [7]. Mô hình nói chung hoạt động kém và không tương tự con người trong hầu hết các nhiệm vụ.

Gần gũi hơn với nghiên cứu hiện tại, [21] đã thực hiện một điều tra tâm lý thần kinh về các khả năng liên quan đến chức năng tiền trán và tìm thấy ChatGPT không thể bắt chước chức năng nhận thức của con người một cách chính xác. [19] đã nghiên cứu GPT-3 như một người lý luận thực dụng và tìm thấy hành vi giống con người, mặc dù có một số ngoại lệ. Cuối cùng, [32] đã điều tra ChatGPT và GPT-4 trên một loạt các nhiệm vụ tâm lý được phân loại theo mức độ thể hiện liên quan đến mỗi nhiệm vụ và tìm thấy rằng phản hồi của LLM lệch khỏi con người trong các đánh giá cảm giác và vận động.

Trong nghiên cứu này, tôi tập trung vào [15] từ tài liệu khoa học nhận thức. Các tác giả hỗ trợ giả thuyết rằng khi đối mặt với các vấn đề quy nạp với dữ liệu hạn chế có sẵn, các đánh giá nhận thức của con người tương ứng chặt chẽ với những đánh giá của một mô hình Bayesian với các tiên nghiệm phù hợp. Động lực để chọn nghiên cứu cụ thể này là thứ nhất không có câu trả lời đúng nào để xác định bằng diễn dịch và như vậy nó có vẻ lý tưởng để tiết lộ hoạt động nhận thức cơ bản của một tâm trí, và thứ hai GPT-3 không có kiến thức gì về nghiên cứu này, trong khi ChatGPT có thể đưa ra cái nhìn tổng quan cấp cao hơi chính xác nhưng không thể kể lại bất kỳ thí nghiệm cụ thể nào được trình bày trong nghiên cứu gốc, do đó tránh được cạm bẫy phổ biến của việc ghi nhớ phản hồi của con người bởi mô hình.

--- TRANG 3 ---
3 Phương pháp
Trong [15] tất cả các nhiệm vụ đều liên quan đến việc dự đoán mức độ hoặc thời gian của một hiện tượng khi được cho một giá trị trung gian tại một thời điểm chưa biết: cho một giá trị t, dự đoán giá trị cuối cùng, tổng ttotal. Phản hồi từ 350 người tham gia được so sánh với một bộ dự đoán Bayesian tính toán xác suất trên ttotal: p(ttotal|t) ∝ p(t|ttotal)p(ttotal). Các tác giả đã tìm thấy rằng các đánh giá của con người gần với các dự đoán tối ưu của bộ dự đoán Bayesian.

Cụ thể, các nhiệm vụ và t tương ứng là: thời gian nướng bánh (phút), tuổi thọ (năm), doanh thu phim (triệu USD), độ dài bài thơ (số dòng), nhiệm kỳ đại diện Hoa Kỳ (năm), và thời gian chờ hộp điện thoại (phút). Tôi bỏ qua các nhiệm vụ "Thời lượng Phim" và "Pharaohs" có phương sai cao trong phản hồi của con người. Tôi suy ra các giá trị cho các dự đoán trung bình của con người và khoảng tin cậy, cũng như các dự đoán của các mô hình Bayesian từ các biểu đồ trong nghiên cứu gốc. Tôi tham khảo [15] để biết thêm chi tiết về các lời nhắc và lựa chọn tiên nghiệm của các bộ dự đoán Bayesian.

Đối với mỗi nhiệm vụ và giá trị lời nhắc, tôi đã hỏi GPT-3 [25] và ChatGPT [24] câu hỏi tương đương 20 lần, bắt đầu một cuộc trò chuyện mới mỗi lần. Tôi bỏ qua phần giới thiệu tổng thể như nó xuất hiện trong nghiên cứu và kết thúc mỗi lời nhắc với "Câu trả lời phải là một số duy nhất, không phải một dải, không có giải thích.". Ví dụ: "Hãy tưởng tượng bạn nghe về một bộ phim đã thu về 10 triệu đô la tại phòng vé, nhưng không biết nó đã chiếu được bao lâu. Bạn sẽ dự đoán gì cho tổng số tiền thu phòng vé của bộ phim đó? Câu trả lời phải là một số duy nhất, không phải một dải, không có giải thích.". Tôi đã thủ công xem qua các kết quả và trích xuất giá trị phản hồi khi có thể, từ chối các câu trả lời có đưa ra dải hoặc giá trị vô nghĩa (số lượng câu trả lời bị từ chối được trình bày trong Bảng 2). Các câu trả lời của Mô hình và mã liên quan để tái tạo kết quả được cung cấp trực tuyến²

[THIS IS TABLE: Bảng 1 showing Mean Average Percentage Error between medians of proposed models and human judgements for different tasks (Cakes, Life Spans, Movie Grosses, Poems, Representatives, Waiting Times) across Bayesian Prediction, GPT-3, and ChatGPT]

4 Kết quả
Tôi trình bày Sai số Phần trăm Trung bình Tuyệt đối giữa mỗi mô hình và các đánh giá của con người trong Bảng 1. Các bộ dự đoán Bayesian của [15] có sai số thấp nhất một cách nhất quán so với GPT-3 hoặc ChatGPT. Những kết quả này cho thấy rằng LLMs không phù hợp với nhận thức con người khi nói đến các đánh giá nhận thức quy nạp về các hiện tượng hàng ngày dưới dữ liệu có sẵn hạn chế.

²https://github.com/sotlampr/llm-cognitive-judgements

--- TRANG 4 ---
[Biểu đồ với 6 phần nhỏ hiển thị so sánh medians và khoảng tin cậy bootstrap 68% (n=1000) cho các nhiệm vụ khác nhau: Cakes, Life Spans, Movie Grosses, Poems, Representatives, Waiting Times, so sánh Bayesian Estimate, Human Participants, GPT-3, và ChatGPT]

So sánh GPT-3 với ChatGPT, cái sau gần với những người tham gia con người hơn đối với hầu hết các nhiệm vụ, với ngoại lệ nổi bật của "Movie Grosses", nơi ChatGPT miễn cưỡng trả lời nhất.

Các biểu đồ tương tự [15] có thể thấy trong Hình 1. GPT-3 và ChatGPT thể hiện các dự đoán không nhất quán trong một vài trường hợp bất kể nhiệm vụ, như thấy trong các khoảng tin cậy thực nghiệm cho ví dụ "Cakes" tại t=70, "Movie Grosses" tại t=100 và "Representatives" tại t=7.

Tôi trình bày tỷ lệ phần trăm của các trường hợp không có phản hồi có ý nghĩa trong Bảng 2. GPT-3 có thể trả lời có ý nghĩa và súc tích trong tất cả các trường hợp, trong khi ChatGPT miễn cưỡng khi nói đến "Life Spans" và "Movie Grosses". Các phản hồi phổ biến cho cả hai nhiệm vụ tương tự như "Câu trả lời không thể xác định được ...", "Không có đủ thông tin để dự đoán chính xác...", "Tôi xin lỗi, nhưng tôi không thể cung cấp ...", "Vì tôi là một mô hình ngôn ngữ AI, tôi không thể ...". Ngoài ra, trong các nhiệm vụ "Life Spans", ChatGPT đã trả lời 6 lần rằng sẽ không đạo đức khi đưa ra những dự đoán như vậy.

Những mẫu từ chối trả lời này cũng xuất hiện trong các nghiên cứu trước đây như

--- TRANG 5 ---
[THIS IS TABLE: Bảng 2 showing percentage of samples with no satisfactory answer for different tasks across GPT-3 and ChatGPT]
Nhiệm vụ        GPT-3    ChatGPT
Cakes           0.0      0.0
Life Spans      0.0      45.0
Movie Grosses   0.0      71.3
Poems           0.0      0.0
Representatives 0.0      3.0
Waiting Times   0.0      0.0

[5, 30, 20, 22], có thể tiết lộ hiệu ứng của việc điều chỉnh lời nhắc được thực hiện với InstructGPT [26], phạt các phản hồi ảo giác, phản thực tế, hoặc không mong muốn khác

5 Kết luận
Tôi đã chứng minh một thất bại rõ ràng của các LLMs phổ biến khi nói đến việc đưa ra các đánh giá quy nạp với dữ liệu có sẵn hạn chế về các tình huống hàng ngày. Mặc dù có số lượng tham số khổng lồ và được huấn luyện trên một lượng dữ liệu khổng lồ, những mô hình này không thể mô hình hóa chính xác các nguyên tắc thống kê cơ bản mà tâm trí con người dường như tin tưởng, và có thể được mô hình hóa chính xác hơn với ít tham số hơn nhiều bậc độ lớn.

Tài liệu tham khảo
[1] Thị trường chứng khoán tăng vọt được thúc đẩy bởi trí tuệ nhân tạo. The Economist, (10 tháng 6 năm 2023), tháng 6 năm 2023.

[2] Y.Bang,S.Cahyawijaya,N.Lee, W.Dai, D.Su, B.Wilie, H.Lovenia ,Z.Ji, T. Yu, W. Chung, et al. Đánh giá đa nhiệm vụ, đa ngôn ngữ, đa phương thức của chatgpt về lý luận, ảo giác và tương tác. arXiv preprint arXiv:2302.04023, 2023.

[3] E. M. Bender, T. Gebru, A. McMillan-Major, và S. Shmitchell. Về những nguy hiểm của những con vẹt ngẫu nhiên: Liệu các mô hình ngôn ngữ có thể quá lớn. Trong Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, trang 610–623, 2021.

[4] M. Binz và E. Schulz. Sử dụng tâm lý học nhận thức để hiểu gpt-3. Proceedings of the National Academy of Sciences, 120(6):e2218523120, 2023.

[5] A. Borji. Kho lưu trữ phân loại các thất bại của chatgpt. arXiv preprint arXiv:2302.03494, 2023.

[6] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Các mô hình ngôn ngữ là những người học ít-shot. Advances in neural information processing systems, 33:1877–1901, 2020.

--- TRANG 6 ---
[7] E. Brunet-Gouet, N. Vidal, và P. Roux. Liệu một đại lý trò chuyện có thể vượt qua các nhiệm vụ lý thuyết tâm trí? Một nghiên cứu trường hợp của ChatGPT với các mô hình Gợi ý, Niềm tin Sai lầm và Câu chuyện Kỳ lạ. Tháng 6 năm 2023. doi: 10.5281. URL https://hal.science/hal-03991530.

[8] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg, et al. Tia lửa của trí tuệ nhân tạo tổng quát: Thí nghiệm sớm với gpt-4. arXiv preprint arXiv:2303.12712, 2023.

[9] Z.G.Cai, D.A.Haslett, X.Duan, S.Wang, vàM.J.Pickering. Liệu chatgpt có giống con người trong việc sử dụng ngôn ngữ? arXiv preprint arXiv:2303.08014, 2023.

[10] N. Chomsky, I. Roberts, và J. Watumull. Noam chomsky: Lời hứa sai lầm của chatgpt. The New York Times, 8, 2023.

[11] K. Elkins và J. Chun. Liệu gpt-3 có thể vượt qua bài kiểm tra turing của nhà văn? Journal of Cultural Analytics, 5(2), 2020.

[12] A. Ettinger. Bert không phải là gì: Bài học từ một bộ chẩn đoán tâm lý ngôn ngữ mới cho các mô hình ngôn ngữ. Transactions of the Association for Computational Linguistics, 8:34–48, 2020.

[13] L. Floridi. Ai như đại lý không có trí tuệ: Về chatgpt, các mô hình ngôn ngữ lớn và các mô hình tạo sinh khác. Philosophy & Technology, 36(1):15, 2023.

[14] L. Freund. Khám phá giao điểm của tính hợp lý, thực tế và lý thuyết tâm trí trong lý luận ai: Phân tích phản hồi của gpt-4 đối với các nghịch lý và bài kiểm tra tom.

[15] T. L. Griffiths và J. B. Tenenbaum. Dự đoán tối ưu trong nhận thức hàng ngày. Psychological science, 17(9):767–773, 2006.

[16] K. Gulordava, P. Bojanowski, E. Grave, T. Linzen, và M. Baroni. Mạng lặp xanh không màu mơ theo cấp bậc. Trong Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). Association for Computational Linguistics, 2018.

[17] B. Holterman và K. van Deemter. Liệu chatgpt có lý thuyết tâm trí? arXiv preprint arXiv:2305.14020, 2023.

[18] R. Katzir. Tại sao các mô hình ngôn ngữ lớn là những lý thuyết kém về nhận thức ngôn ngữ của con người. một phản hồi cho piantadosi (2023). Bản thảo. Đại học Tel Aviv. url: https://lingbuzz.net/lingbuzz/007190, 2023.

[19] B. Lipkin, L. Wong, G. Grand, và J.B. Tenenbaum. Đánh giá các mô hình ngôn ngữ thống kê như những người lý luận thực dụng. arXiv preprint arXiv:2305.01020, 2023.

[20] D. Lloyd. Cảm giác như thế nào khi là một bot?: Thế giới theo gpt-4. Available at SSRN 4443727, 2023.

--- TRANG 7 ---
[21] R. Loconte, G. Orrù, M. Tribastone, P. Pietrini, và G. Sartori. Thách thức 'trí tuệ' của chatgpt với các công cụ của con người: Một điều tra tâm lý thần kinh về chức năng tiền trán của một mô hình ngôn ngữ lớn. Intelligence, 2023.

[22] C. Michaux. Liệu chat gpt có thể được coi là một tác giả? tôi đã gặp chat gpt và hỏi một số câu hỏi về triết học nghệ thuật và triết học tâm trí. Available at SSRN 4439607, 2023.

[23] OpenAI. Giới thiệu chatgpt. https://openai.com/blog/chatgpt, . Truy cập ngày 13 tháng 6 năm 2023.

[24] OpenAI. Chatgpt. https://chat.openai.com, . Phiên bản ngày 24 tháng 5.

[25] OpenAI. Gpt-3. https://platform.openai.com/docs/models/gpt-3, . Model:davinci-003.

[26] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al. Huấn luyện các mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi của con người. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.

[27] P. Qian và R. P. Levy. Các mô hình ngôn ngữ thần kinh như các chủ thể tâm lý ngôn ngữ: Biểu diễn trạng thái cú pháp. Association for Computational Linguistics, 2019.

[28] M. T. Ribeiro, T. Wu, C. Guestrin, và S. Singh. Vượt ra ngoài độ chính xác: Kiểm tra hành vi của các mô hình nlp với checklist. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, 2020.

[29] A. E. Scott, D. Neumann, J. Niess, và P. W. Woźniak. Bạn có phiền không? nhận thức của người dùng về ý thức máy. Trong Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, trang 1–19, 2023.

[30] V. Taecharungroj. "chatgpt có thể làm gì?" phân tích phản ứng sớm đối với chatbot ai sáng tạo trên twitter. Big Data and Cognitive Computing, 7(1): 35, 2023.

[31] A. Warstadt, A. Singh, và S. R. Bowman. Đánh giá khả năng chấp nhận của mạng thần kinh. Transactions of the Association for Computational Linguistics, 7:625–641, 2019.

[32] Q. Xu, Y. Peng, M. Wu, F. Xiao, M. Chodorow, và P. Li. Liệu biểu diễn khái niệm có yêu cầu thể hiện? những hiểu biết từ các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2305.19103, 2023.

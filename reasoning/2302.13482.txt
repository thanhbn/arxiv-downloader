# 2302.13482.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/reasoning/2302.13482.pdf
# File size: 2403345 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
PyReason: Software for Open World Temporal Logic
Dyuman Adityaâ€ , Kaustuv Mukherji*,â€ , Srikar Balasubramanian, Abhiraj Chaudhary
and Paulo Shakarian*
Arizona State University, 699 S Mill Ave, Tempe, AZ, 85281, USA
Abstract
The growing popularity of neuro symbolic reasoning has led to the adoption of various forms of
differentiable (i.e., fuzzy) first order logic. We introduce PyReason, a software framework based on
generalized annotated logic that both captures the current cohort of differentiable logics and temporal
extensions to support inference over finite periods of time with capabilities for open world reasoning.
Further, PyReason is implemented to directly support reasoning over graphical structures (e.g., knowledge
graphs, social networks, biological networks, etc.), produces fully explainable traces of inference, and
includes various practical features such as type checking and a memory-efficient implementation. This
paper reviews various extensions of generalized annotated logic integrated into our implementation, our
modern, efficient Python-based implementation that conducts exact yet scalable deductive inference,
and a suite of experiments. PyReason is available at: github.com/lab-v2/pyreason .
Keywords
Logic programming, Neuro Symbolic Reasoning, Generalized annotated logic, Temporal logic, First order
logic, Open world reasoning, Graphical reasoning, AI Tools
1. Introduction
Various neuro symbolic frameworks utilize an underlying logic to support capabilities such as
fuzzy logic [ 1], parameterization [ 2], and differentiable structures [ 3]. Typically, implementa-
tions of such frameworks create custom software for deduction for the particular logic used,
which limits modularity and extensibility. Further, emerging neuro symbolic use cases including
temporal logic over finite time periods [ 4] and knowledge graph reasoning [ 5] necessitate the
need for a logical frmaework that encompasses a broad set of capabilities. Fortunately, general-
ized annotated logic [ 6] with various extensions [ 7,8,9] capture many of these capabilities. In
this paper we present a new software package called PyReason for performing deduc-
tion using generalized annotated logic that captures many of the desired capabilities
seen in various neuro symbolic frameworks including fuzzy, open world, temporal,
and graph-based reasoning. Specifically, PyReason includes a core capability to reason about
In A. Martin, K. Hinkelmann, H.-G. Fill, A. Gerber, D. Lenat, R. Stolle, F. van Harmelen (Eds.), Proceedings of the AAAI
2023 Spring Symposium on Challenges Requiring the Combination of Machine Learning and Knowledge Engineering
(AAAI-MAKE 2023), Hyatt Regency, San Francisco Airport, California, USA, March 27-29, 2023.
*Corresponding author.
â€ These authors contributed equally.
/envelope-openkmukherji@asu.edu (K. Mukherji); pshak02@asu.edu (P. Shakarian)
/globehttps://search.asu.edu/profile/4179815 (K. Mukherji); https://labs.engineering.asu.edu/labv2/ (P. Shakarian)
/orcid0000-0002-4889-3499 (D. Aditya); 0000-0001-8044-1110 (K. Mukherji)
Â©2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
CEUR
Workshop
Proceedingsceur-ws.org
ISSN 1613-0073
CEUR Workshop Proceedings (CEUR-WS.org)arXiv:2302.13482v3  [cs.LO]  4 Mar 2023

--- PAGE 2 ---
first order (FOL) and propositional logic statements that can be annotated with either elements
of a lattice structure or functions over that lattice. Further, we have provided for additional
practical syntactic and semantic extensions that allow for reasoning over knowledge graphs,
temporal logic, reasoning about various network diffusion models, and predicate-constant type
checking constraints. This implementation provides for a fast, memory optimized, implemen-
tation of the fixpoint operator used in the deductive process. By implementing the fixpoint
operator directly (as opposed to a black box heuristic) the software enables full explainability
of the result. As such is the case, this framework captures not only classical logic, but a wide
variety of other logic frameworks including fuzzy logic [ 10,11,12], weighted real valued logic
used in logical neural networks [ 2], van Emdenâ€™s logic [ 13], Fittingâ€™s bilattice logic [ 14], various
logic frameworks for reasoning over graphs or social networks [ 9,8,15] (as well as the various
network diffusion models captured by those frameworks), and perhaps most importantly, logic
frameworks where syntactic structure can be learned using differentiable inductive logic pro-
gramming [ 3,16] as well as other neuro symbolic frameworks [ 17,7]. The key advantages of
our approach include the following:
1.Direct support for reasoning over knowledge graphs. Knowledge graph structures
are one of the most commonly-used representations of symbolic data. While black box
frameworks such as [ 18] also permit for reasoning over graphical structures, they do not
afford the explainability of our approach.
2.Support for annotations. Classical logic implementations such as Prolog [ 19] and
Epilog [ 20] inherently do not support annotations or annotation functions, hence lack
direct support for capabilities such as fuzzy operators. Further, our framework goes
beyond support for fuzzy operators by enabling arbitrary functions that can be used over
real values or intervals of reals. This is a key advantage to reasoning about constructs
learned with neuro symbolic approaches such as [2, 3, 16, 17, 7].
3.Temporal Extensions. While the framework of [ 6] was shown to capture various
temporal logics, extensions such as [ 9] have provided for syntactic and semantic add-
ons that explicitly represent time and allow for temporal reasoning over finite temporal
sequences. Following [ 9], we use a semantic structure that represents multiple time points,
but we have implemented this in a compact manner to preserve memory. Our solution
allows for fuzzy versions of rules such as â€œif ğ‘(ğ´)thenğ‘Ÿ(ğ´)inğ‘¡time steps.â€ Note that
these capabilities are not present in nearly every current implementation of fuzzy logic.
4.Use of interpretations. We define interpretations as annotated function over predicates
and time together. It allows us to capture facts which are true before ğ‘¡= 0. While
annotated logic [ 6] can subsume various temporal logics without additional constructs,
we have enabled temporal reasoning through incorporating a temporal component in
interpretations. By combining annotated predicates and the time variable, we believe
our framework is more flexible and suitable for emerging neuro symbolic applications
involving time - as such applications will inherently require both time and real-valued
annotations. Additionally, it is to be noted that we do not make a closed world assumption
i.e. anything that is not mentioned in the initial set of interpretations is ğ‘“ğ‘ğ‘™ğ‘ ğ‘’ . Instead,
we consider all other interpretations to be unknown at the beginning of time.
5.Graphical Knowledge Structures. We also implement [ 8] which provides graphical

--- PAGE 3 ---
syntactic extensions to [ 6]. This is included in our implementation, notably adding
extended syntactic operators for reasoning in such structures (e.g., an existential operator
requiring the existence of ğ‘˜items). An example of such a rule would be a fuzzy version
of â€œif ğ‘(ğ´)and there exist ğ‘˜number of ğµâ€™s such that ğ‘(ğ´, ğµ)thenğ‘Ÿ(ğ´)â€.1
6.Reduction to computational complexity due to grounding. Our software leverages
both the inherent sparsity of the graphical structure along with a novel implementation
of predicate-constant type checking constraints that significantly improves utility in a
variety of application domains but also provide drastic reduction to complexity induced
by the grounding problem. We are not aware of any other framework for first-order logic
that provides both such capabilities.
7.Ability to detect and resolve inconsistencies in reasoning. As logical inferences
are deduced through applications of the fixpoint operator over predefined logical rules,
logical inconsistencies can not only be detected but also located exactly where in the
inference process the inconsistency occurred. We resolve any such inconsistencies by
leveraging uncertainty. In the software implementation, as soon as an inconsistency is
detected we relax and fix the bounds to complete uncertainty. The ability to check and
locate inconsistencies enhance the explainability feature. Neuro symbolic approaches
like [ 2,7] may also look to leverage inconsistency as part of loss during the training
phase.
In section 2, we outline the syntax and semantics of [ 6] as well as our extensions. Our software
implementation is described in section 3 and is expanded upon in the online only supplement.
In section 4, we provide experimental results of our framework to demonstrate reasoning
capabilities in two different real-world domains. We have conducted experiments on a supply-
chain [ 21] (10ğ¾constants), and a social media [ 22] (1.6ğ‘€constants) dataset. For evaluation,
we used various manually-curated logic programs specifying rules for the temporal evolution of
the graph, completion of the graph, and other such practical use-cases (e.g., identifying potential
supply chain disruptions) and examined how various aspects affect runtime and memory usage
(e.g., number of constants, predicates, timesteps, inference steps, etc.). The results show that
both runtime and memory remain almost constant over large ranges, and then scale sub-linearly
with increase in network size.
Online Resources
Open source python library is available at: pypi.org/project/pyreason .
PyReason codebase can be found at: github.com/lab-v2/pyreason .
Online only supplement is available at: github.com/lab-v2/pyreason/tree/main/lit
2. Logical Framework
In this section, we provide an overview of the annotated logic framework with a high-level
description of the logical constructs, knowledge graph structure, key optimizations, and
1Note that while this example is classical, PyReason supports fully annotated logic, allowing for arbitarily defined
fuzzy operators (e.g., t-norms); See section 2 and online supplement for technical details.

--- PAGE 4 ---
Figure 1: Example of a knowledge graph
operation of the fixpoint algorithm.
Knowledge graph. We assume the existence of a graphical structure ğº= (ğ’, ğ¸)where the
nodes are also constants (denoted set ğ’) in a first-order logic framework. The edges, denoted
ğ¸âŠ†ğ’Ã—ğ’ , specify whether any type of relationship can exist between two constants. Similar
to recent frameworks combining knowledge graphs and logic [ 3,18], we shall assume that
all predicates in the language are either unary (which can be thought of as labeling nodes)
or binary (which can be thought of as labeling edges). We note that we assume the existence
of a special binary predicate rel, which we shall treat as a reserved word. For (ğ‘, ğ‘)âˆˆğ¸we
shall treat rel(ğ‘, ğ‘)as a tautology and for (ğ‘, ğ‘)/âˆˆğ¸we shall treat rel(ğ‘, ğ‘)as uncertain. Note
that we can support no restrictions among the pairing of constants by creating ğºas a fully
connected graph. Likewise, we easily support the propositional case by using a graph of a single
node (essentially treating unary predicates as ground atoms). We provide a running example in
this section. In Figure 1, we illustrate how a knowledge graph is specified in our framework.
Example 2.1 (Knowledge Graph). Consider the following nodes: three students- Phil, John,
Mary and two classes- English and Math. Nodes and edges have unary and binary predicates as
shown in Fig. 1. Hence we get the following non-ground atoms:
student(S), gpa(S), promoted(S)
class(C), difficulty(C)
friend(S,Sâ€™)
takes(S,C), grade(S,C), expertise(S,C)
Here, S, Sâ€™, and C are variables which when grounded with constants from the graph, produce
ground atoms such as:
student(john), student(phil), student(mary)
class(math), class(english)
takes(john,math), takes(mary, english)
...

--- PAGE 5 ---
In the propositional case, a non-ground atom reduces to a propositional statement. For e.g. The
predicate â€œtakes(john,math)â€ can be represented as a propositional statement: â€œJohn takes Math
classâ€ and can be either True or False. It is true in this example, as shown in Fig. 1.
Real-valued Interval Annotations. A key advantage of annotated logic [ 6] is the ability to
annotate the atoms in the framework with elements of a lattice structure as well as functions
over that lattice. In our software, we use a lower lattice structure consisting of intervals that are
a subset of [0,1]. This directly aligns with the truth interval for fuzzy operators [ 12], as well as
paradigms in neuro symbolic reasoning [ 2,7], and social network analysis [ 8,9]. We can fully
support scalar-valued annotations by simply limiting manipulations to the lower bound of the
interval and keeping the upper bound set at 1. These annotations can support classical logic
by limiting annotations to be [0,0](false) and [1,1](true). It can also support tri-valued logic
by permitting [0,1], which represents no knowledge. Of course, there is no need to conduct
restrictions, especially if it is desirable to support logics that make full use of the interval
[2,8,9]. Additionally, we support literals as detailed in [ 7]. We treat negations the same way
as in [ 1] - for an atom annotated with [â„“, ğ‘¢], we annotate its strong negation( Â¬) with [1âˆ’ğ‘¢,1âˆ’â„“].
Example 2.2 (Real-valued Interval Annotations). Continuing with the previous example,
we can support a variety of annotations as described above.
Propositional logic:
student(john): [1,1] (example of a True statement)
takes(mary,math): [0,0] (example of a False statement)
Fuzzy logic (using scalar values):
gpa(john): [X,1], X âˆˆ[0,1]
Full interval usage:
difficulty(english): [0.3,0.7] (both bounds are used here to capture the varia-
tion among students regarding the perceived difficulty of the subject â€œenglishâ€).
Modeling uncertainty and/or tri-valued logic:
Letâ€™s assume that we do not have complete knowledge of this network - specifically, we do not have
any information about the friendship between John and Phil. So, they might be friends (annotated
[1,1]) or not friends (annotated [0,0]). Our framework can model such a case as:
friend(john,phil): [0,1]
Interpretations. Commonly in logic frameworks, an initial set of facts is used. We use the
term â€œinitial interpretationsâ€ to capture annotations correct at the beginning of a program.
In the envisioned domains - to include the ones in which we perform experiments - these
initial interpretations shall be represented as a knowledge graph that not only includes graph
ğºbut also attributes on the nodes and edges (resembling predicates) and real-valued interval
annotations (specifying the initial annotations for each element). Additionally, following
intuitions from various temporal logic frameworks that incorporate both temporal and other real-
valued annotations [ 9,8,23,24,25], we extend our syntax to provide for temporal annotations as
part of the interpretations. Following the related work, time is represented as finite discrete time-
points. The initial interpretations comprises what is to be treated as true before time 0. Further,
with the initial interpretations we can specify predicates as being either static (in other words,

--- PAGE 6 ---
ground atoms formed with those predicates retain the same annotation across all time periods)
or non-static (which are permitted to change). The ability to add this restriction has clear
benefit in certain domains, and also allows for key implementation efficiencies for reasoning
across time periods. Further, it is noted various inductive logic programming paradigms [ 3,26]
utilize â€œextensionalâ€ predicates that are also unchanging - which could be treated as â€œstaticâ€ in
PyReason.
Syntax :
ğ¼(ğ´, ğ‘¡^) : [ğ¿, ğ‘ˆ]
where, ğ´can be an atom (propositional case) or predicate (first order logic), ğ‘¡^is either the time
point ğ‘‡=ğ‘¡for which the interpretation ğ¼is valid, or if the interpretation is static, i.e. remains
unchanged for all time-points then ğ‘¡^=ğ‘ . So,
ğ‘¡^={ï¸ƒ
ğ‘ ,ifğ¼(ğ´, ğ‘¡^)is static
ğ‘¡, ğ‘¡âˆˆğ‘‡ifğ¼(ğ´, ğ‘¡^)is time-variant(1)
Annotation [ğ¿, ğ‘ˆ]â†’[0,1](or, in propositional case [ğ¿, ğ‘ˆ]âˆˆ[0,0],[1,1]). We incorporate
literals in our system by having separate interpretations for an atom and its negation. We
note that, excepting the case of static atoms, ground atoms at different time points need not be
dependent upon each other. For example, atom â€œaâ€ at time 1can be annotated with [0.5,0.7]
and annotated with [0.1,0.2]at time 2. There is no monotonicity requirement between time
points.
Example 2.3 (Interpretations). Continuing the previous example,
Initial set of facts regarding student enrollment:
I(student(john),0) = [1,1] (John is enrolled as a student)
I(student(mary),0) = [1,1] (Mary is enrolled as a student)
I(student(phil),0) = [0,0] (Phil is not enrolled as a student)
Static interpretations can be used for always true facts like:
I(class(english), s) = [1,1] (English is a class offered at all time-points)
Using temporal annotation to capture variation over time:
I(takes(john,math),1) = [1,1] (John takes Math class at time ğ‘¡= 1)
I(takes(john,math),5) = [0,0] (But is no longer taking Math at ğ‘¡= 5)
All other interpretations, if unspecified at ğ‘¡= 0, are initialized with [0,1].
Logical Rules. Rules are the key syntactic construct that enables changes to atoms formed
with non-static predicates. Historically logical rules had mostly been written by domain experts,
until early work like Apriori [ 27] and FOIL [ 28] to learn association rules from data followed by
the emergence of rule mining techniques like causal rule mining [ 29] and annotated probabilistic
temporal logic [ 24,30,31]. More recently, there has been research on Differentiable Inductive
Logic Programming ( ğœ•ILP) - an inductive rule learning method to learn logical rules from
examples [ 3,16,32]. In the below list ğ‘ˆğ‘›ğ‘ğ‘†ğ‘’ğ‘¡ andğµğ‘–ğ‘›ğ‘†ğ‘’ğ‘¡ are arbitrarily sets of unary and
binary predicates relevant to the rules while ğ‘ğ‘Ÿğ‘’ğ‘‘ is always a non-static predicate. Note that
the total number of atoms in the body is assumed to be ğ‘›(across all different conjunctions).
The symbolâˆƒğ‘˜means there exists at least ğ‘˜number of constants such that the ensuing logical
sentence is satisfied.

--- PAGE 7 ---
1. Ground rule for reasoning within a single constant or edge:
ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘) :ğ‘“(ğ‘¥1, . . . , ğ‘¥ ğ‘›)â†Î”ğ‘¡â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–âˆˆğ‘ˆğ‘›ğ‘ğ‘†ğ‘’ğ‘¡ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–(ğ‘) :ğ‘¥ğ‘–
ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘, ğ‘â€²) :ğ‘“(ğ‘¥1, . . . , ğ‘¥ ğ‘›)â†Î”ğ‘¡â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–âˆˆğµğ‘–ğ‘›ğ‘†ğ‘’ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–(ğ‘, ğ‘â€²) :ğ‘¥ğ‘–
2. Universally quantified non-ground rule for reasoning within a single constant or edge:
âˆ€ğ‘‹:ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘‹) :ğ‘“(ğ‘¥1, . . . , ğ‘¥ ğ‘›)â†Î”ğ‘¡â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–âˆˆğ‘ˆğ‘›ğ‘ğ‘†ğ‘’ğ‘¡ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘–(ğ‘‹) :ğ‘¥ğ‘–
âˆ€ğ‘‹, ğ‘‹â€²ğ‘ .ğ‘¡.(ğ‘‹, ğ‘‹â€²)âˆˆğ¸:ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘‹, ğ‘‹â€²) :ğ‘“(ğ‘¥1, . . . , ğ‘¥ ğ‘›)â†Î”ğ‘¡â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘âˆˆğµğ‘–ğ‘›ğ‘†ğ‘’ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘(ğ‘‹, ğ‘‹â€²) :
ğ‘¥ğ‘âˆ§â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘Ÿâˆˆğ‘ˆğ‘›ğ‘ğ‘†ğ‘’ğ‘¡ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘Ÿ(ğ‘‹) :ğ‘¥ğ‘Ÿâˆ§â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘ âˆˆğ‘ˆğ‘›ğ‘ğ‘†ğ‘’ğ‘¡â€²ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘ (ğ‘‹â€²) :ğ‘¥ğ‘ 
3. Universally quantified non-ground rule for reasoning across an edge:
âˆ€ğ‘‹:ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘‹) :ğ‘“(ğ‘¥1, . . . , ğ‘¥ ğ‘›)â†Î”ğ‘¡âˆƒğ‘˜ğ‘‹â€²:ğ‘Ÿğ‘’ğ‘™(ğ‘‹, ğ‘‹â€²) : [1,1]âˆ§â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘âˆˆğµğ‘–ğ‘›ğ‘†ğ‘’ğ‘¡ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘(ğ‘‹, ğ‘‹â€²) :
ğ‘¥ğ‘âˆ§â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘Ÿâˆˆğ‘ˆğ‘›ğ‘ğ‘†ğ‘’ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘Ÿ(ğ‘‹) :ğ‘¥ğ‘Ÿâˆ§â‹€ï¸€
ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘ âˆˆğ‘ˆğ‘›ğ‘ğ‘†ğ‘’ğ‘¡â€²ğ‘ğ‘Ÿğ‘’ğ‘‘ ğ‘ (ğ‘‹â€²) :ğ‘¥ğ‘ 
4. Non-ground rule with rule based quantifier in the head:
ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘‹) : [ğ´ğ‘ (ğ‘™1, ğ‘™2, . . . , ğ‘™ ğ‘›), ğ´ğ‘ (ğ‘¢1, ğ‘¢2, . . . , ğ‘¢ ğ‘›)]â†â‹€ï¸€
ğ‘‹ğ‘–s.t.(ğ‘‹,ğ‘‹ ğ‘–)âˆˆğ¸ğ‘ğ‘Ÿğ‘’ğ‘‘â€²(ğ‘‹, ğ‘‹ ğ‘–) : [ğ‘™ğ‘–, ğ‘¢ğ‘–]
Here, ğ´ğ‘˜
ğ‘ ,ğ‘š(ğ‘†)could be the ğ‘šğ‘¡â„rule based quantifier defined over set ğ‘†such that,
ğ´ğ‘˜
ğ‘ ,ğ‘š(ğ‘†) =ğ‘˜ğ‘¡â„highest value in set ğ‘†.
Example 2.4 (Logical Rules). For the continuing example we can formulate some interesting
rules based on the formats given above as:
1.ğ‘ğ‘Ÿğ‘œğ‘šğ‘œğ‘¡ğ‘’ğ‘‘ (ğ‘‹) : [ğ‘‡(ğ‘™1, ğ‘™2), ğ‘ˆ(ğ‘¢1, ğ‘¢2)]â†Î”ğ‘¡=1ğ‘ ğ‘¡ğ‘¢ğ‘‘ğ‘’ğ‘›ğ‘¡ (ğ‘‹) : [ğ‘™1, ğ‘¢1]âˆ§ğ‘”ğ‘ğ‘(ğ‘‹) : [ğ‘™2, ğ‘¢2]
which says, â€œIf ğ‘‹is a student with bounds [ğ‘™1, ğ‘¢1]and has a gpa with bounds [ğ‘™2, ğ‘¢2], then
ğ‘‹is likely to be promoted, at the next timestep, with bounds given by a function of [ğ‘™1, ğ‘¢1]
and[ğ‘™2, ğ‘¢2].â€
Here, ğ‘‡could be a T-norm. Some well known examples of T-norms are:
a)Minimum: ğ‘‡(ğ‘, ğ‘) =ğ‘‡ğ‘šğ‘–ğ‘›(ğ‘, ğ‘) =ğ‘šğ‘–ğ‘›(ğ‘, ğ‘)
b)Product: ğ‘‡(ğ‘, ğ‘) =ğ‘‡ğ‘ğ‘Ÿğ‘œğ‘‘(ğ‘, ğ‘) =ğ‘Â·ğ‘
c)Åukasiewicz: ğ‘‡(ğ‘, ğ‘) =ğ‘‡ğ‘™ğ‘¢ğ‘˜(ğ‘, ğ‘) =ğ‘šğ‘ğ‘¥(0, ğ‘+ğ‘âˆ’1)
PyReason also supports other well known logical functions like ğ‘‡âˆ’ğ‘ğ‘œğ‘›ğ‘œğ‘Ÿğ‘š , algebraic
functions like ğ‘šğ‘ğ‘¥ ,ğ‘šğ‘–ğ‘›,ğ‘ğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’ , among others.
2.âˆ€ğ‘‹, ğ‘Œ ğ‘’ğ‘¥ğ‘ğ‘’ğ‘Ÿğ‘¡ğ‘–ğ‘ ğ‘’ (ğ‘‹, ğ‘Œ ) : [0 .6*ğ¿,1]â†Î”ğ‘¡=0ğ‘”ğ‘Ÿğ‘ğ‘‘ğ‘’ [ğ‘‹, ğ‘Œ ] : [ğ¿,1]âˆ§ğ‘ ğ‘¡ğ‘¢ğ‘‘ğ‘’ğ‘›ğ‘¡ (ğ‘‹) :
[1,1]âˆ§ğ‘ğ‘™ğ‘ğ‘ ğ‘  (ğ‘Œ) : [1,1]
which says, â€œIf ğ‘‹is a student who obtains a grade [ğ¿,1]in class ğ‘Œ, then we can estimate
ğ‘‹â€™s expertise of subject ğ‘Œby defining an annotation function [0.6*ğ¿,1]over a single
annotation [ğ¿,1].â€

--- PAGE 8 ---
3.ğ‘”ğ‘ğ‘(ğ‘—ğ‘œâ„ğ‘› ) : [ğ‘¥1+ğ‘¥2
2,1]â†Î”ğ‘¡=0âˆƒğ‘–=2ğ¶ğ‘–âˆˆğ’ :ğ‘ğ‘™ğ‘ğ‘ ğ‘  (ğ¶ğ‘–) : [1 ,1]âˆ§ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘—ğ‘œâ„ğ‘›, ğ¶ ğ‘–) :
[1,1]âˆ§ğ‘”ğ‘Ÿğ‘ğ‘‘ğ‘’ (ğ‘—ğ‘œâ„ğ‘›, ğ¶ ğ‘–) : [ğ‘¥ğ‘–,1]
which says, â€œIf ğ‘—ğ‘œâ„ğ‘› takes and earns grades for two classes, then his ğ‘”ğ‘ğ‘can be calculated
using the algebraic function ğ‘ğ‘£ğ‘”in the head of the given existentially quantified ground rule. â€
4.ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘†, ğ‘†â€²) : [1 ,1]â†Î”ğ‘¡=2ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘†, ğ¶) : [1 ,1]âˆ§ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘†â€², ğ¶) : [1 ,1]âˆ§ğ‘ğ‘™ğ‘ğ‘ ğ‘  (ğ¶) :
[1,1]
a propositional rule with temporal extension which states, â€œIf two students ğ‘†andğ‘†â€²take the
same class ğ¶, they develop a friendship after two timesteps.â€
5.âˆ€ğ‘†, ğ‘†â€², ğ‘†â€²â€²ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘†, ğ‘†â€²â€²) : [1,1]â†Î”ğ‘¡=1ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘†, ğ‘†â€²) : [1,1]âˆ§ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘†â€², ğ‘†â€²â€²) : [1,1]
an universally quantified non-ground rule analogous to the associative rule in mathematics
which encapsulates, â€œHaving a common friend ğ‘†â€²leads to friendship between two people ğ‘†
andğ‘†â€²â€².â€
Fixpoint Operator for Deduction. Central to the deductive process is a fixpoint operator
(denoted by Î“) which has previously been proven to produce all atoms entailed by a logic
program (rules and facts) in [ 6,7] and these results were extended for the temporal semantics in
[9,8]. It is noteworthy that this is an exact computation of the fixpoint, and hence providing the
minimal model associated with the logic program allowing one to easily check for entailment
of arbitrary formulae. Further, the result is fully explainable as well: for any entailment query
we would have the series of inference steps that lead to the result. This differs significantly
from other frameworks that do not provide an explanation for deductive results [ 18] though a
key difference is that the reasoning framework implemented in PyReason allows for exact and
efficient polynomial time inference, while others have an intractable inference process.
Example 2.5 (Fixpoint Operator( Î“)).Consider we have the following set of initial interpreta-
tions in addition to the ones specified before:
I(takes(john,english),1) = I(takes(john,english),2) = [1,1]
I(takes(mary,english),2) = I(takes(mary,english),3) = [1,1]
(John takes English at t=1,2 and Mary takes English at t=2,3)
I(friend(mary,phil),s) = [1,1]
(Mary and Phil are friends for the entire time considered)
And we consider the rule set ğ‘…to be made of rule 4 and 5 from above. We initialize:
âˆ€S,Sâ€™ I(friend(S,Sâ€™),0) = [0,1] (allğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ relationships initialized as unknown)
and then update:
I(friend(mary,phil),s) = [1,1] (from initial interpretations)
Application of Î“at T=0 and 1 yields no change in ğ¼as none of the rules are fired.
At T=2, rule 4 fires with the following groundings:
ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘—ğ‘œâ„ğ‘›, ğ‘šğ‘ğ‘Ÿğ‘¦ ) : [1,1]â†Î”ğ‘¡=2ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘—ğ‘œâ„ğ‘›, ğ‘’ğ‘›ğ‘”ğ‘™ğ‘–ğ‘ â„ ) : [1,1]âˆ§ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘šğ‘ğ‘Ÿğ‘¦, ğ‘’ğ‘›ğ‘”ğ‘™ğ‘–ğ‘ â„ ) :
[1,1]âˆ§ğ‘ğ‘™ğ‘ğ‘ ğ‘  (ğ‘’ğ‘›ğ‘”ğ‘™ğ‘–ğ‘ â„ ) : [1,1]

--- PAGE 9 ---
ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘šğ‘ğ‘Ÿğ‘¦, ğ‘—ğ‘œâ„ğ‘› ) : [1,1]â†Î”ğ‘¡=2ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘šğ‘ğ‘Ÿğ‘¦, ğ‘’ğ‘›ğ‘”ğ‘™ğ‘–ğ‘ â„ ) : [1,1]âˆ§ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘—ğ‘œâ„ğ‘›, ğ‘’ğ‘›ğ‘”ğ‘™ğ‘–ğ‘ â„ ) :
[1,1]âˆ§ğ‘ğ‘™ğ‘ğ‘ ğ‘  (ğ‘’ğ‘›ğ‘”ğ‘™ğ‘–ğ‘ â„ ) : [1,1]
This would result in a change in ğ¼at T = 4, as Î”ğ‘¡= 2for the rule above and it is fired at T=2.
I(friend(john,mary),4) = [1,1]
I(friend(mary,john),4) = [1,1]
At T=3, as ğ¼is still unchanged, application of Î“does not lead to any of the rules firing.
At T=4, application of Î“with the updated interpretation leads to firing of grounded rule 5 as:
ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘—ğ‘œâ„ğ‘›, ğ‘â„ğ‘–ğ‘™ ) : [1,1]â†Î”ğ‘¡=1ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘—ğ‘œâ„ğ‘›, ğ‘šğ‘ğ‘Ÿğ‘¦ ) : [1,1]âˆ§ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘šğ‘ğ‘Ÿğ‘¦, ğ‘â„ğ‘–ğ‘™ ) : [1,1]
And results in:
I(friend(john, phil),5) = [1,1]
The above illustrates how PyReason makes logical inferences by exact application of the fixpoint
operator( Î“). In this example, we are able to trace how the interpretation I(friend(john,
phil),t) changed over time, and which rules caused these changes. This shows that this process
is completely explainable, and can be leveraged in emerging neuro symbolic applications.
Constant-Predicate Type Checking Constraints. Key to reducing the complexity and speed-
ing up of the inference process is type-checking. We leverage the sparsity commonly prevalent
in knowledge graphs to significantly cut down on the search space during the grounding process.
We noticed that typically a graph will have nodes of different types, and predicates typically
were defined only over constants of a specific type. While initializing the interpretations, type
checking takes this into account and only creates ground atoms for the subset of predicate-
constant pairs which are compatible with each other. However, we note that this is an option,
as in some applications such information may not be available.
Example 2.6 (Constant-Predicate Type Checking). In the continuing example we see that
the predicates student, gpa, promoted are only limited to constants of type student .
Similarly, predicates class, difficulty are exclusive to the constants english andmath .
Type checking ensures that we do not consider ground atoms like student(english) or
class(phil) .
Likewise for binary predicate takes(S,C) , the first variable is always grounded with a
student type constant, and the second with a class type constant. Even in this miniature
example, type checking reduces the number of ground atoms under consideration from 25 to only
6 - a 76% reduction. Such gains significantly reduce complexity as size and sparsity of the graph
increases.
Detecting and Resolving Inconsistencies. Inconsistency can occur in the following cases:
1.For some ground atom, a new interpretation is assigned an annotation [ğ¿â€², ğ‘ˆâ€²]that is not
a subset of the current interpretation [ğ¿, ğ‘ˆ](we assume ğ¿â‰¤ğ‘ˆ). i.e. if either ğ‘ˆ < ğ¿â€²or
ğ‘ˆâ€²< ğ¿.
2.When an inconsistency occurs between an atom and its negation like â€œaâ€ and â€œnot aâ€.
Or between complementary predicates like â€œ ğ‘ğ‘ğ‘â„ğ‘’ğ‘™ğ‘œğ‘Ÿ (ğ‘‹)â€ and â€œ ğ‘šğ‘ğ‘Ÿğ‘Ÿğ‘–ğ‘’ğ‘‘ (ğ‘‹)â€ which
cannot hold simultaneously.
e.g. Literal A has annotation [ğ¿1, ğ‘ˆ1]and Literal B is the negation of literal A with

--- PAGE 10 ---
annotation [ğ¿2, ğ‘ˆ2]. The fixpoint operator attempts to assign [ğ¿â€²
1, ğ‘ˆâ€²
1]to Literal A, and
[ğ¿â€²
2, ğ‘ˆâ€²
2]to Literal B. But new bounds are inconsistent, i.e. either ğ¿â€²
1>1âˆ’ğ¿â€²
2or
ğ‘ˆâ€²
1<1âˆ’ğ‘ˆâ€²
2.
PyReason flags all such inconsistencies arising during the execution of the fixpoint operator and
reports them. Further, as the fixpoint operator provides an explainable trace, the user can see
the precise cause of the inconsistency. As an additional, practical feature, PyReason includes an
option to reset the annotation to [0,1]for any identified inconsistency and set the atom to static
for the remainder of the inference process. In this way, such inconsistencies cannot propagate
further. These initial capabilities provide a solid foundation for more sophisticated consistency
management techniques such as providing for local consistency or iterative relaxation of the
initial logic program.
Example 2.7 (Detecting and Resolving Inconsistencies.). Consider we have the following
prior knowledge:
I(takes(phil,math), 4) = [1,1]
I(takes(mary,math), 4) = [1,1]
I(friend(phil,mary), 5) = [0,0]
However, the following logical rule with grounding ğ‘†â†ğ‘â„ğ‘–ğ‘™,ğ‘†â€²â†ğ‘šğ‘ğ‘Ÿğ‘¦ ,ğ¶â†ğ‘šğ‘ğ‘¡â„ :
ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘†, ğ‘†â€²) : [1,1]â†1ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘†, ğ¶) : [1,1]âˆ§ğ‘¡ğ‘ğ‘˜ğ‘’ğ‘  (ğ‘†â€², ğ¶) : [1,1]gets fired at ğ‘¡= 4.
resulting in:
I(friend(phil,mary), 5) = [1,1]
But clearly this is an inconsistency as I(friend(phil,mary), 5) cannot be both [0,0]
and[1,1]simultaneously. So, we conclude that at least one of those two interpretations must be
incorrect. If there is no way to ascertain which is correct, we may resolve this logical inconsistency
by setting:
I(friend(phil,mary), s) = [0,1] atğ‘¡= 5.
3. Implementation
We have endeavored to create a modern Python-based framework to support scalable yet correct
reasoning. We allow graphical input via convenient Graphml format, which is commonly used
in knowledge graph architectures. The python library Networkx is used to load and interact
with the graph data. We are currently in the process of directly supporting Neo4j. The initial
conditions and rules are entered in YAML format and we use memory-efficient implementation
techniques to correctly capture semantic structures. We use the Numba open-source JIT compiler
to translate many key operations into fast, optimized machine code while allowing the user
to interact with Python and the aforementioned front-ends. Our implementation can support
CPU parallelism, as evidenced by our experiments run on multi-CPU machines.
Our software stores interpretations in a nested dictionary. For computational efficiency and
ease of use, our software allows specification of a range of time-points ğ‘‡=ğ‘¡1, ğ‘¡2, . . .instead of a
single time-point ğ‘¡, for which an interpretation ğ¼remains valid. To reduce memory requirements,
only the one set of interpretations (current) are stored at any point in time. However, past
interpretations can be obtained using rule traces , which retains the change history for each

--- PAGE 11 ---
Table 1
Honda network: How disruption on a countryâ€™s industry, caused by a pandemic, may spread worldwide
Companies Companies disrupted across the world at time t= % of companies disrupted
Based Count 0 1 2 3 4 . . . 38 Initial Final Change
USA 1599 1599 1965 2057 2203 2313 . . . 3336 14.68 30.75 16.07
Taiwan 603 603 644 647 647 647 . . . 647 5.54 5.94 0.40
Australia 128 128 131 131 131 131 . . . 131 1.18 1.21 0.03
interpretation and the corresponding grounded logical rules that caused each change. Rule
traces make our software completely explainable, as every inference can be traced back to the
cascade of rules that led to it.
MANCaLog [ 9] showed the use of the fixpoint operator for both canonical and non-canonical
models. By recomputing interpretations at every time step, we not only require significantly
less memory but also, support both the canonical and the non-canonical cases. Due to this
design, increase in computation time is observed to be minimal.
Furthermore, we make significant advances on [ 33] by supporting static predicates, and
having in-built capabilities for non-graph reasoning, and type checking as detailed in section 2.
Our implementation can be found online as specified in section 1 and detailed pseudo-code
can be found in the supplemental information.
4. Experiments
4.1. Honda Buyer-Supplier Dataset
We conduct our experiment on a Honda Buyer-Supplier network [ 21]. The dataset (network)
contains 10,893 companies (nodes) and 47,247 buyer-supplier relationships between them
(edges).
We design an use case, where we assume that operations of all companies from a particular
country are disrupted, and observe the effects that this may have on companies across the world.
We feel this is akin to supply chain issues faced worldwide during the COVID-19 pandemic. For
our tests, we use the following logical rule which in practice would be either learned or come
from an expert.
ğ‘‘ğ‘–ğ‘ ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘ (ğµğ‘¢ğ‘¦ğ‘’ğ‘Ÿ ) : [1,1]â†Î”ğ‘¡=1âˆ€ğ‘˜ğ‘ ğ‘¢ğ‘ğ‘ğ‘™ğ‘–ğ‘’ğ‘  (ğ‘†ğ‘¢ğ‘ğ‘˜, ğµğ‘¢ğ‘¦ğ‘’ğ‘Ÿ ) : [1,1],âˆƒğ‘˜/2ğ‘‘ğ‘–ğ‘ ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘ (ğ‘†ğ‘¢ğ‘ğ‘˜) : [1,1]
It states that, a company is disrupted at a particular timestep if at least 50% of its suppliers
are totally disrupted in the previous timestep. We conduct this experiment for three different
countries (USA, Taiwan, and Australia), having a wide range of proportion of companies in the
dataset. We do not fix the number of inference steps, instead we let the diffusion process run
until it converges (in bold). The results are shown in Table 1.
To test if our approach could scale, we use two inference rules which jointly state, a company
is disrupted at a particular timestep if any of its supplier(s) are completely disrupted in the
previous timestep, or if at least 50% of its suppliers are disrupted to at least 50% of their capacity.
We conduct this experiment for different graph sizes, and for different number of timesteps to

--- PAGE 12 ---
Table 2
Scalability of our framework
Nodes (N) Edges (E) Total attributes Density Timesteps Runtime (in s) Memory (in MB)
1000 410 5012 4.10 x 10âˆ’42 0.36 4.9
5 0.42 1.8
15 0.34 0.1
2000 1640 13269 4.10 x 10âˆ’42 0.43 1.2
5 0.55 2.1
15 0.81 8.2
5000 10244 57852 4.10 x 10âˆ’42 1.54 17.2
5 1.84 16.0
15 3.38 54.6
10000 41034 197752 4.10 x 10âˆ’42 4.83 80.3
5 6.29 60.3
15 12.34 210.8
show the scaling capability of our software in Table 2.
The results show that both runtime and memory remain almost constant over large ranges,
and then scale sub-linearly with increase in network size.
4.2. Pokec Social Media dataset
Pokec is a popular slovakian social network, and this dataset [ 22] contains personal information
like gender, age, pets (attributes) of 1.6 million people (nodes), and 30.6 million connections
between them (edges).
We take inspiration from the advertising community to design our use case. We consider, a
small proportion of the population, who has pet(s), to be customers of a pet food company. The
company, using Pokec data, must identify relevant advertising targets among the population. A
realistic strategy can be captured by two logical rules:
1.âˆ€ğ‘‹, ğ‘Œ ğ‘Ÿğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’ (ğ‘‹) : [0.6,1]â†Î”ğ‘¡=1ğ‘Ÿğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’ (ğ‘Œ) : [1,1]âˆ§ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘‹, ğ‘Œ ) : [1,1]
Friend of a relevant target or existing customer (always relevant), is at least 60% relevant.
2.âˆ€ğ‘‹, ğ‘Œ ğ‘Ÿğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’ (ğ‘‹) : [1 ,1]â†Î”ğ‘¡=1ğ‘Ÿğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘ğ‘’ (ğ‘Œ) : [1 ,1]âˆ§ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘‹, ğ‘Œ ) : [1 ,1]âˆ§
â„ğ‘ğ‘ ğ‘ƒğ‘’ğ‘¡ (ğ‘‹, ğ‘ƒ) : [1,1]âˆ§â„ğ‘ğ‘ ğ‘ƒğ‘’ğ‘¡ (ğ‘Œ, ğ‘ƒ) : [1,1]
Friend of a relevant target is totally relevant if they have pet(s) of same kind - dog, cat, . . .
The diffusion process converged after 8 timesteps, took 42 minutes to complete and used
58.36 GB of memory - which further showcases the scalability of our framework. The results
are shown in Table 3.
The process of inference is completely explainable, and an user may use rule traces , an optional
output of PyReason, to identify the logical rules that led to change in each interpretation. An
example of a rule trace from the previous experiment is presented in Table 4.
All experiments were performed on an AWS EC2 container with 96 vCPUs (48 cores) and
384GB memory.

--- PAGE 13 ---
Table 3
Pokec social media: How brands may use consumer data to identify prospective customers
Advertising targets
Population size Current Customers Timesteps Fully relevant Partially relevant
1,632,803 2,308 0 2,308 0
1 2,596 39,836
2 2,657 47,405
3 2,679 49,174
4 2,690 50,046
5 2,692 50,412
6 2,693 50,455
7, 8, . . . 2,693 50,608
Table 4
Rule trace for a single node for label relevance . Application of rule 1 above caused the first change
from [0,1]to[0.6,1], followed by, an update to [1,1]due to firing of rule 2. A list of node and edge IDs
which were used to ground the rule clauses are also provided.
tOld
BoundNew
BoundRule
firedClause-1 Clause-2 Clause-3 Clause-4
1 [0.0,1.0] [0.6,1.0] rule_1 [â€˜354455â€™] [(â€˜354365â€™, â€˜354455â€™)]
2 [0.6,1.0] [1.0,1.0] rule_2 [â€˜354455â€™, [(â€˜354365â€™, â€˜354455â€™), [(â€˜718503â€™, [(â€˜354365â€™,
â€˜718503â€™] (â€˜354365â€™, â€˜718503â€™)] â€˜catâ€™)] â€˜catâ€™)]
5. Related work
In section 1, we discussed how PyReason extends on the early modern logic programming
languages like Prolog [ 19], Epilog [ 20] and Datalog [ 34] by supporting annotations. Recent
neuro symbolic frameworks show great promise in the ability to learn or modify logic programs
to align with historical data and improve robustness to noise. Many such frameworks rely on an
underlying differentiable, fuzzy, first order logic. For example, logical tensor networks [ 1] uses
differentiable versions of fuzzy operators to combine ground and non-ground atomic proposi-
tions while logical neural networks [ 2] associate intervals of reals with atomic propositions and
uses special parameterized operators. Meanwhile, induction approaches such as differentiable
ILP [ 3] fuzzy logic programs (using the product t-norm) are learned from data based on template
rule structures in a manner that support recursion and multi-step inference. In [ 17], Logical
Neural Networks was used interpret learned rules in a precise manner. Here also, gradient
descent was used to train the parameters of the network. In the last two years, two paradigms
have emerged with much popularity in the neuro symbolic literature. Logical Tensor Networks
(LTN) [ 1] extend neural architectures through fuzzy, real-valued logic. Logical Neural Networks
(LNN) [ 2] provide a neuro symbolic framework with parameterized operators that supports
open world reasoning in the logic. As stated earlier, both can be viewed as a subset of annotated
logic. Hence, PyReason can be used to conduct inference on the logic for both frameworks,

--- PAGE 14 ---
in addition to providing key capabilities such as graph-based and temporal reasoning, which
currently are not present in the logics of those frameworks.
In both the forward pass of various neuro symbolic frameworks [ 35,2,1], as well as for
subsequent problems (e.g., entailment, abductive inference, planning, etc.), a deduction process
is required. PyReason is designed to provide this precise capability. Generalized annotated
programs [ 6] has been shown to capture a wide variety of real-valued, temporal, and fuzzy
logics as it associates logical atoms with elements of a lattice structure as opposed to scalar
values. As a result it can capture all the aforementioned logics, while retaining polynomial-time
deduction due to the monotonicity of the lattice. The use of a lattice structure allows for us to
associate logical constructs with intervals, thus enabling open world reasoning. In our recent
work [ 7], we provided extensions to [ 6] that allows for a lower lattice structure for annotations.
This enables the framework to capture paradigms such as LNN [ 2] and the MANCALog [ 9] for
graph-based reasoning. However, that work only showed that analogs to the theorems of [ 7]
for the lower lattice case and did not provide an implementation or experimental results.
By supporting generalized annotated logic, and its various extensions PyReason enables
system design that is independent of the learning process. As a result, once a neuro symbolic
learning process creates or modifies a logic program based on data, PyReason can be used to
efficiently answer deductive queries (to include entailment and consistency queries) as well as
support more sophisticated inference such as abductive inference or planning.
Today knowledge graphs are crucial in representing data for reasoning and analysis. Recent
research on creation of knowledge graphs [ 36,37] proposes methods to automatically convert
conceptual models into knowledge graphs in GraphML format for enterprise architecture and a
wide range of applications. PyReason, which supports the graphml format, could be an effective
tool to reason about knowledge graphs obtained from one of these platforms.
6. Conclusion and Future Work
In this paper, we presented PyReason: an explainable inference software supporting annotated,
open world, real-valued, graph-based, and temporal logics. Our modern implementation extends
established generalized annotated logic framework to support scalable and efficient reasoning
over large knowledge graphs and diffusion models. We are currently working on a range of
extensions to this work. This includes adding more temporal logic operators for specification
checking, learning rules from data through induction, and using the inference process to create
new knowledge in non-static graphs (e.g., adding nodes and edges). We will also look to explore
how PyReason can be used in conjunction with LTN [ 1], and LNN [ 2]. In supporting frameworks
such as these, we will look to add capabilities for symbol grounding [ 38], leveraging the results of
the training process from frameworks such as LTN. Finally, we also plan on extending PyReason
to act as a simulator for reinforcement learning based agents.
Acknowledgments
The authors are supported by internal funding from the Fulton Schools of Engineering and
portions of this work is supported by U.S. Army Small Business Technology Transfer Program

--- PAGE 15 ---
Office or the Army Research Office under Contract No.W911NF-22-P-0066.
References
[1]S. Badreddine, A. dâ€™Avila Garcez, L. Serafini, M. Spranger, Logic tensor networks, Artificial
Intelligence 303 (2022) 103649.
[2]R. Riegel, A. Gray, F. Luus, N. Khan, N. Makondo, I. Y. Akhalwaya, H. Qian, R. Fagin,
F. Barahona, U. Sharma, S. Ikbal, H. Karanam, S. Neelam, A. Likhyani, S. Srivastava, Logical
neural networks, 2020.
[3]R. Evans, E. Grefenstette, Learning explanatory rules from noisy data, J. Artif. Int. Res. 61
(2018) 1â€“64.
[4]M. Ma, J. Gao, L. Feng, J. Stankovic, STLnet: Signal temporal logic enforced multivariate
recurrent neural networks, in: Advances in Neural Information Processing Systems,
volume 33, Curran Associates, Inc., 2020, pp. 14604â€“14614.
[5]P. Sen, B. W. Carvalho, I. Abdelaziz, P. Kapanipathi, S. Roukos, A. Gray, Logical neural
networks for knowledge base completion with embeddings & rules, in: Conference on
Empirical Methods in Natural Language Processing, 2022, pp. 3863â€“3875.
[6]M. Kifer, V. Subrahmanian, Theory of generalized annotated logic programming and its
applications, J. Log. Program. 12 (1992) 335â€“367.
[7]P. Shakarian, G. I. Simari, Extensions to generalized annotated logic and an equivalent
neural architecture, in: 2022 TransAI, 2022, pp. 63â€“70.
[8]P. Shakarian, G. I. Simari, D. Callahan, Reasoning about complex networks: A logic
programming approach, Theory Pract. Log. Program. 13 (2013).
[9]P. Shakarian, G. I. Simari, R. Schroeder, Mancalog: a logic for multi-attribute network
cascades, in: International conference on Autonomous Agents and Multi-Agent Systems,
AAMAS, 2013, pp. 1175â€“1176.
[10] U. HÃ¶hle, Probabilistic uniformization of fuzzy topologies, Fuzzy Sets and Systems (1978).
[11] C. Alsina, E. Trillas, L. Valverde, On some logical connectives for fuzzy sets theory, Journal
of Mathematical Analysis and Applications 93 (1983) 15â€“26.
[12] P. VojtÃ¡Å¡, Fuzzy logic programming, Fuzzy sets and systems 124 (2001) 361â€“370.
[13] M. H. Van Emden, R. A. Kowalski, The semantics of predicate logic as a programming
language, J. ACM 23 (1976) 733â€“742.
[14] M. Fitting, Bilattices in logic programming, City University of New York, Lehman College,
Department of Mathematics and Computer Science, 1990.
[15] P. Shakarian, M. Broecheler, V. Subrahmanian, C. Molinaro, Using generalized annotated
programs to solve social network diffusion optimization problems, ACM Transactions on
Computational Logic 14 (2013).
[16] H. Shindo, M. Nishino, A. Yamamoto, Differentiable inductive logic programming for
structured examples, in: AAAI Conference on Artificial Intelligence, 2021, pp. 5034â€“5041.
[17] P. Sen, B. W. S. R. d. Carvalho, R. Riegel, A. Gray, Neuro-symbolic inductive logic program-
ming with logical neural networks, AAAI conference on Artificial Intelligence (2022).
[18] P. Hohenecker, T. Lukasiewicz, Ontology reasoning with deep neural networks, in: Journal
of Artificial Intelligence Research, volume 68, 2020, pp. 503â€“540.

--- PAGE 16 ---
[19] A. Colmerauer, Prolog and infinite trees, Logic Programming 16 (1982) 2.
[20] L. K. Schubert, C. H. Hwang, Episodic logic meets little red riding hood: A comprehensive,
natural representation for language understanding, Natural language processing and
knowledge representation: Language for Knowledge and Knowledge for Language (2000).
[21] T. Yan, T. Y. Choi, Y. Kim, Y. Yang, A theory of the nexus supplier: A critical supplier from
a network perspective, Journal of Supply Chain Management 51 (2015) 52â€“66.
[22] L. Takac, M. Zabovsky, Data analysis in public social networks, in: International scientific
conference and international workshop present day trends of innovations, 2012.
[23] A. Dekhtyar, M. I. Dekhtyar, V. S. Subrahmanian, Temporal probabilistic logic programs,
in: International Conference on Logic Programming, 1999, p. 109â€“123.
[24] S. Khuller, M. V. Martinez, D. S. Nau, A. Sliva, G. I. Simari, V. S. Subrahmanian, Comput-
ing most probable worlds of action probabilistic logic programs: scalable estimation for
1030, 000worlds, Ann. Math. Artif. Intell. 51 (2007) 295â€“331.
[25] P. Shakarian, A. Parker, G. Simari, V. V. S. Subrahmanian, Annotated probabilistic temporal
logic, ACM Trans. Comput. Logic 12 (2011).
[26] M. V. FranÃ§a, G. Zaverucha, A. S. dâ€™Avila Garcez, Fast relational learning using bottom
clause propositionalization with artificial neural networks, Machine learning 94 (2014).
[27] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, A. I. Verkamo, et al., Fast discovery of
association rules., Advances in knowledge discovery and data mining 12 (1996) 307â€“328.
[28] J. R. Quinlan, Learning logical definitions from relations, Machine learning 5 (1990).
[29] A. Stanton, A. Thart, A. Jain, P. Vyas, A. Chatterjee, P. Shakarian, Mining for causal
relationships: A data-driven study of the islamic state, in: ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, 2015, pp. 2137â€“2146.
[30] P. Shakarian, A. Parker, G. Simari, V. V. Subrahmanian, Annotated probabilistic temporal
logic, ACM Transactions on Computational Logic (TOCL) 12 (2011) 1â€“44.
[31] P. Shakarian, G. I. Simari, V. Subrahmanian, Annotated probabilistic temporal logic:
Approximate fixpoint implementation, ACM Transactions on Computational Logic (TOCL)
13 (2012) 1â€“33.
[32] P. Sen, B. W. de Carvalho, R. Riegel, A. Gray, Neuro-symbolic inductive logic programming
with logical neural networks, in: AAAI Conference on Artificial Intelligence, 2022.
[33] J. N. Paredes, G. I. Simari, M. V. Martinez, M. A. Falappa, Detecting malicious behavior
in social platforms via hybrid knowledge- and data-driven systems, Future Generation
Computer Systems 125 (2021) 232â€“246.
[34] S. Abiteboul, R. Hull, V. Vianu, Foundations of databases, volume 8, Addison-Wesley
Reading, 1995.
[35] Z. Yang, A. Ishay, J. Lee, Neurasp: Embracing neural networks into answer set program-
ming, in: International Joint Conference on Artificial Intelligence, IJCAI, 2020.
[36] M. Smajevic, D. Bork, From conceptual models to knowledge graphs: a generic model
transformation platform, in: 2021 ACM/IEEE International Conference on Model Driven
Engineering Languages and Systems Companion (MODELS-C), IEEE, 2021, pp. 610â€“614.
[37] P.-L. Glaser, S. J. Ali, E. Sallinger, D. Bork, Model-based construction of enterprise ar-
chitecture knowledge graphs, in: Enterprise Design, Operations, and Computing: 26th
International Conference, Springer, 2022, pp. 57â€“73.
[38] S. Harnad, The symbol grounding problem, Physica D: Nonlinear Phenomena 42 (1990).

--- PAGE 17 ---
[39] J. W. Lloyd, Foundations of logic programming, Springer-Verlag New York, Inc., 1987.
A. Formal Syntax and Semantics.
We now recapitulate the definition of Generalized Annotated Logic programs (from now on
referred to as â€œGAPsâ€, for short) from [ 6] as well as the extensions that we include in our
software.
In [6], the authors assumed the existence of a semilattice. ğ’¯(not necessarily complete) with
orderingâŠ‘. To support contemporary applications in neuro symbolic reasoning [ 2,3,7,16,17]
as well as social network analysis [ 9,8] we implemented this as a lower semilattice structure.
Therefore, we have a single element âŠ¥and multiple top elements âŠ¤0, . . .âŠ¤ğ‘–. . .âŠ¤ğ‘šğ‘ğ‘¥. The
notation â„ğ‘’ğ‘–ğ‘”â„ğ‘¡ (ğ’¯)is the maximum number of elements in the lattice in a path between âŠ¥
and a top element (including âŠ¥and the top element)2. The employment of a lower semilattice
structure allows enables two desirable characteristics. First, we desire to annotate atoms with
intervals of reals in [0,1]as done in previous work [ 2,9,25]. Second, it allows for reasoning
about such intervals whereby the amount of uncertainty (i.e., for interval [ğ‘™, ğ‘¢]the quantity
ğ‘¢âˆ’â„“) decreases monotonically as an operator proceeds up the lattice structure. Therefore, we
define bottom element âŠ¥= [0,1]and a set of top elements {[ğ‘¥, ğ‘¥]|[ğ‘¥, ğ‘¥]âŠ†[0,1]}(see note3).
Specifically, we set âŠ¤0= [0,0]andâŠ¤ğ‘šğ‘ğ‘¥= [1,1]. An example of such a semilattice structure
is shown in Figure 2.
Figure 2: Example of a lower semilattice structure where the elements are intervals in [0,1].
As with [ 6], we assume the existence of a set AVar of variable symbols ranging over ğ’¯
and a setâ„±of function symbols, each of which has an associated arity. We start by defining
annotations.
Definition A.1 (Annotation). (i)Any member ofğ’¯ âˆª AVar is an annotation.
(ii)Ifğ‘“is anğ‘›-ary function symbol over ğ’¯andğ‘¡1, . . . , ğ‘¡ ğ‘›are annotations, then ğ‘“(ğ‘¡1, . . . , ğ‘¡ ğ‘›)is
an annotation.
2In general, we shall assume that the lattice consists of finite, discrete elements.
3N.B. that when using a semilattice of bounds, the notation â€œ âŠ‘â€ loses its â€œsubset intuitionâ€, as [0,1]âŠ‘[1,1]in this
case, for example.

--- PAGE 18 ---
One specific function we define is â€œ Â¬â€ which is used in semantics of [ 6] as well as the more
recent interval-based framework used in [ 2]. For a given [ğ‘™, ğ‘¢],Â¬([ğ‘™, ğ‘¢]) = [1âˆ’ğ‘¢,1âˆ’ğ‘™]. Note
that we also use the symbol Â¬in our first-order language (following the formalism of [ 6]). We
define a separate logical language whose constants are members of set ğ’and whose predicate
symbols are specified by set ğ’«. We also assume the existence of a set ğ’±of variable symbols
ranging over the constants, that no function symbols are present, and terms and atoms are
defined in the usual way (cf. [ 39]). We shall assume that ğ’,ğ’«,ğ’±are discrete and finite. In
general, we shall use capital letters for variable symbols and lowercase letters for constants.
Similar to previous work [ 3,18] shall assume that all elements of ğ’«have an arity of either 1 or
2 - so we shall denote these ğ’«ğ‘¢ğ‘›ğ‘for unary predicates and ğ’«ğ‘Ÿğ‘’ğ‘™for binary predicates. We shall
also denote a subsets of ğ’«to include â€œtarget predicatesâ€ written ğ’«ğ‘¡ğ‘”ğ‘¡that can consist of either
binary or unary predicates ( ğ’«ğ‘¡ğ‘”ğ‘¡_ğ‘Ÿğ‘’ğ‘™,ğ’«ğ‘¡ğ‘”ğ‘¡_ğ‘¢ğ‘›ğ‘) provided that they are not reserved words. We
shall use the symbol â„’to denote the set of all ground literals and ğ’œfor the set of all ground
atoms. We now define the syntactical structure of GAPs that will be used in this work.
Definition A.2 (Annotated atoms, negations, literals). The core syntactic structures are de-
fined as follows:
â€¢Annotated atom. Ifğ‘is an atom and ğœ‡is an annotation, then ğ‘:ğœ‡is an annotated atom .
â€¢Annotated Negation. Ifğ‘is an atom and ğœ‡is an annotation, then Â¬ğ‘:ğœ‡is an annotated
negation .
â€¢Annotated Literal. Collectively, atoms and negations are referred to as annotated literals .
Definition A.3 (GAP Rule). Ifâ„“0:ğœ‡0, â„“1:ğœ‡1, . . . , â„“ ğ‘š:ğœ‡ğ‘šare annotated literals (such that
for all ğ‘–, ğ‘—âˆˆ1, ğ‘š,â„“ğ‘–Ì¸â‰¡â„“ğ‘—), then
ğ‘Ÿâ‰¡â„“0:ğœ‡0â†â„“1:ğœ‡1âˆ§. . .âˆ§â„“ğ‘š:ğœ‡ğ‘š
is called a GAP rule . We will use the notation â„ğ‘’ğ‘ğ‘‘ (ğ‘Ÿ)andğ‘ğ‘œğ‘‘ğ‘¦(ğ‘Ÿ)to denote â„“0and{â„“1, . . . , â„“ ğ‘š}
respectively. When ğ‘š= 0 (ğ‘ğ‘œğ‘‘ğ‘¦(ğ‘Ÿ) =âˆ…), the above GAP-rule is called a fact. A GAP-rule is
ground iff there are no occurrences of variables from either AVar orğ’±in it. For ground rule ğ‘Ÿand
ground literal â„“,ğ‘ğ‘œğ‘‘ğ‘¦ğ´ğ‘›ğ‘›ğ‘œ (â„“, ğ‘Ÿ) =ğœ‡such that â„“:ğœ‡appears in the body of ğ‘Ÿ. A generalized
annotated program Î is a finite set of GAP rules.
The formal semantics of GAPs are defined as follows. Note that we extend the notion
of an interpretation to allow for a mapping of literals to annotations (as opposed to atoms).
However, we add a requirement on the annotation between each atom and negation that ensures
equivalence to the semantic structure of [6].
Definition A.4 (Interpretation). An interpretation ğ¼is any mapping from the set of all grounds
literals toğ’¯such that for literals ğ‘,Â¬ğ‘, we have ğ¼(ğ‘) =Â¬(ğ¼(Â¬ğ‘)). The setâ„of all interpretations
can be partially ordered via the ordering: ğ¼1âª¯ğ¼2iff for all ground literals ğ‘,ğ¼1(â„“)âŠ‘ğ¼2(â„“).â„
forms a complete lattice under the âª¯ordering.
Now we present the satisfaction relationship:

--- PAGE 19 ---
Definition A.5 (Satisfaction). An interpretation ğ¼satisfies a ground literal â„“:ğœ‡, denoted
ğ¼|=â„“:ğœ‡, iffğœ‡âŠ‘ğ¼(â„“).ğ¼satisfies the ground GAP-rule
â„“0:ğœ‡0â†â„“1:ğœ‡1âˆ§. . .âˆ§â„“ğ‘š:ğœ‡ğ‘š
(denoted ğ¼|=â„“0:ğœ‡0â†â„“1:ğœ‡1âˆ§. . .âˆ§â„“ğ‘š:ğœ‡ğ‘š) iff either
1.ğ¼satisfies â„“0:ğœ‡0or
2.There exists an 1â‰¤ğ‘–â‰¤ğ‘šsuch that ğ¼does not satisfy â„“ğ‘–:ğœ‡ğ‘–.
ğ¼satisfies a non-ground literal or rule iff ğ¼satisfies all ground instances of it.
We say that an interpretation ğ¼is amodel of program Î if it satisfies all rules in Î . Likewise,
program Î isconsistent if there exists some ğ¼that is a model of Î . We say Î entails â„“:ğœ‡,
denoted Î |=â„“:ğœ‡, iff for every interpretation ğ¼s.t.ğ¼|= Î  , we have that ğ¼|=â„“:ğœ‡. As
shown by [ 6], we can associate a fixpoint operator with any GAP Î that maps interpretations
to interpretations.
Definition A.6. Suppose Î is any GAP and ğ¼an interpretation. The mapping TÎ that maps
interpretations to interpretations is defined as
TÎ (ğ¼)(â„“0) =sup(ğ‘ğ‘›ğ‘›ğ‘œğ‘†ğ‘’ğ‘¡ Î ,ğ¼(â„“0)),
where ğ‘ğ‘›ğ‘›ğ‘œğ‘†ğ‘’ğ‘¡ Î ,ğ¼(â„“0) ={ğ¼(â„“0)}âˆª{ğœ‡0|â„“0:ğœ‡0â†â„“1:ğœ‡1âˆ§. . .âˆ§â„“ğ‘š:ğœ‡ğ‘šis a ground
instance of a rule in Î ,and for all 1â‰¤ğ‘–â‰¤ğ‘š,we have ğ¼|=â„“ğ‘–:ğœ‡ğ‘–}
The key result of [ 6] tells us that lfp(TÎ )precisely captures the ground atomic logical
consequences of Î . We show this is also true (under the condition that Î is consistent) even if
the annotations are based on a lower lattice. In [ 6], the authors also define the iteration ofTÎ 
as follows:
â€¢TÎ â†‘0is the interpretation that assigns âŠ¥to all ground literals.
â€¢TÎ â†‘(ğ‘–+ 1) = TÎ (TÎ â†‘ğ‘–).
For each ground â„“âˆˆâ„’, the set Î (â„“)is the subset of ground rules (to include facts) in Î where
â„“is in the head. We will use the notation ğ‘šâ„“to denote the number of rules in Î (â„“). For a given
ground rule, we will use the symbol ğ‘Ÿâ„“,ğ‘–to denote that it is the ğ‘–-th rule with atom â„“in the head.
B. Formal Proofs for Results where the Lower Lattice
Assumption is Made.
Please see [7].

--- PAGE 20 ---
Table 5
Overview of the Honda Buyer-Supplier Network
Companies (Nodes) 10,893
Buey-Supplier Relationships (Edges) 47,247
Global Industry Classification Standard (GICS) types 67
Edge Relationship types 4
C. Additional Details on Supply Chain Experiments
Table 5 summarizes the contents of the dataset. 7,396 companies were listed with a unique GICS,
while 3,497 did not have one listed.
To understand the structure of the buyer-supplier network more in-depth, one industry along
with its first and second Tier suppliers are mapped, as shown in Figure 3. Each node shown in
the figure contain an attribute name which describes the name of the industry and each edge
connecting those industries contain an attribute costwhich describes the profit relationship
between those two particular industries connected by an edge.
In Figure 4 a portion of data is mapped out showing the complexity of the supply network.
The figure can help identify a few key nodes which connect large sections of the network to
other major sections - which makes them critical to operations.
Figure 5 shows the distribution of various industry types. Figure 6 gives different edge
relationships present in the dataset.
D. Additional Details on Social Network Experiments
Table 6 gives an overview of the dataset, and the schema is shown in Fig. 7. The edge relationship
types are enumerated in the figure.
Graph density represents the ratio between the edges present in a graph and the maximum
number of edges that the graph can contain. In reality, graphs are often sparse (not dense). To
Figure 3: A snapshot of the network showing link connections with attribute labels

--- PAGE 21 ---
Figure 4: Honda Supply Chain Network. Each node and edge is differently colored based on the type.
Figure 5: Distribution of the nodes in the network based on its GICS type.
test the scaling capacity of our approach with graph density, we re-run the experiment in Table 2
while modifying the density of the dataset. The results, in Table 7, show that the experiments
on Honda data, which is about 40 times more dense than the Pokec network takes only about 3
times more memory, and 6 times more runtime to complete. This further showcases the scaling
capability of our framework.
Finally, to test the scalability of our approach with respect to the number of attributes (and
hence, number of ground atoms) in a graph, we run an experiment for a simple use-case - once
with the original dataset, and then with the attributes added in. We define the use-case on the
social media data as:
âˆ€ğ‘‹, ğ‘Œ ğ‘–ğ‘›ğ‘“ğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘ (ğ‘‹) : [1,1]â†Î”ğ‘¡=1ğ‘–ğ‘›ğ‘“ğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘ (ğ‘Œ) : [1,1]âˆ§ğ‘“ğ‘Ÿğ‘–ğ‘’ğ‘›ğ‘‘ (ğ‘‹, ğ‘Œ ) : [1,1]

--- PAGE 22 ---
Figure 6: Edge relationships in the dataset.
Table 6
Overview of the Pokec Social Media dataset
Nodes 1,632,820
Edges 31,633,113
Node attribute types 5
Edge Relationship types 4
which says, â€œA person contracts the virus if any of their friend(s) is infected by a virusâ€. The
results are as shown in Table 8.
E. Expanded Rule Traces
A longer version of the rule trace in Table 4, with 10 atoms is presented in Table 9.
Figure 7: Schema of Pokec network

--- PAGE 23 ---
Table 7
Impact of graph density on memory and runtime
Honda Pokec
Densityâ†’ 4.10 x 10âˆ’40.11 x 10âˆ’4
Nodes (N) Timesteps Runtime (in s) Memory (in MB) Runtime (in s) Memory (in MB)
10000 2 4.83 80.3 0.70 27.4
5 6.29 60.3 0.93 19.9
15 12.34 210.8 1.73 21.2
Table 8
Impact of adding 7 attributes on memory and runtime for 5 timesteps
Attributes Nodes (N) Edges (E) Grounded atoms Runtime (in mins) Memory (in GB)
Not added 1,632,803 30,622,563 3,265,606 19.95 42.44
Added 1,632,820 31,633,113 36,531,539 28.26 59.39
Change (+17) (+1,010,550) (+33,265,933) (+8.31) (+16.95)
F. Implementation Pseudocode
Algorithm 1 enumerates the data structures in use. Algorithm 2 shows the initial state, while
algorithm 3 details the inference process. During inference, interpretations are updated as
shown in algorithm 4. Logical consistency is maintained using algorithms 5 and 6.
Algorithm 1 Data Structures Used
1:Nested Dictionary ğ¼= [ğ‘ğ‘œğ‘‘ğ‘’/ğ¸ğ‘‘ğ‘”ğ‘’, [ğ‘ƒğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘ğ‘¡ğ‘’, [ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ, ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ, ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ ]]]to store cur-
rent interpretations only. If ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ is set to 1, bounds: ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ, ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ can no longer change
for rest of program.
2:Listğ¿= [(ğ‘ğ‘œğ‘‘ğ‘’/ğ¸ğ‘‘ğ‘”ğ‘’, ğ‘ƒğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘ğ‘¡ğ‘’, ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ, ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ, ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘, ğ‘ğ‘¡ _ğ‘¡)]to store facts and infer-
ences, before it is used to update the dictionary.
3:ListIPL= [(ğ‘ƒğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘ğ‘¡ğ‘’ 1, ğ‘ƒğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘ğ‘¡ğ‘’ 2)]containing pairs of predicates which cannot hold
simultaneously, i.e., the bounds must be pairwise complementary. In the propositional case,
if one of the predicates is ğ‘¡ğ‘Ÿğ‘¢ğ‘’ , the other must be ğ‘“ğ‘ğ‘™ğ‘ ğ‘’ . We call this â€œinconsistent predicate
list (IPL)â€.
4:Listğ¸= [(ğ‘ğ‘œğ‘‘ğ‘’/ğ¸ğ‘‘ğ‘”ğ‘’, ğ‘ƒğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘ğ‘¡ğ‘’ )]containing list of predicates that becomes inconsis-
tent in the course of program execution.

--- PAGE 24 ---
Algorithm 2 Program initialization
1:ğ¼as follows:
âˆ€nodes/edges, use ğ‘¡ğ‘¦ğ‘ğ‘’_ğ‘â„ğ‘’ğ‘ğ‘˜ğ‘–ğ‘›ğ‘” to initialize valid predicates only.
All bounds are initialized to [0,1]. ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ set to 0.
2:ğ¿â†[ ] â—Empty list
Facts (incl. initial interpretations) are then copied into ğ¿
3:ğ‘¡â†0
4:ğ¸â†[ ]
5:Input: Number of diffusion time-steps ğ‘‡, Set of rules ğ‘…
Algorithm 3 Program flow
1:while ğ‘¡â‰¤ğ‘‡do
2: forğ‘–inğ¼, where ( ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ isğ‘“ğ‘ğ‘™ğ‘ ğ‘’ )do
3: reset bounds to [0,1]
4: end for
5: ğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’ _ğ‘Ÿğ‘’ğ‘â†0
6: forğ‘™inğ¿, where ( ğ‘™(ğ‘ğ‘¡_ğ‘¡) == ğ‘¡)do
7: ifcheck_consistency( ğ‘™âˆˆğ¿,ğ‘™âˆˆğ¼)then
8: update_req += update_interp( ğ‘™âˆˆğ¿,ğ‘™âˆˆğ¼)
9: else
10: resolve_inconsistency( ğ‘™âˆˆğ¼)
11: if(ğ‘™, ğ‘™â€²)âˆˆIPL,âˆ€ğ‘™â€²then
12: resolve_inconsistency( ğ‘™â€²âˆˆğ¼)
13: end if
14: end if
15: end for
16: ifğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’ _ğ‘Ÿğ‘’ğ‘then
17: Apply fix-point operator( ğ‘”ğ‘ğ‘šğ‘šğ‘ ) once.
18: foreach resulting interpretation do
19: ifğ‘†ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ isğ‘“ğ‘ğ‘™ğ‘ ğ‘’ inğ¼then
20: Add toğ¿
21: end if
22: end for
23: Go to line 5.
24: else
25: ğ‘¡â†ğ‘¡+ 1.
26: end if
27:end while

--- PAGE 25 ---
Table 9
A longer version of the rule trace from Table 4 for Label:relevance
Bound
tÎ“Node Old New Rule
firedClause-1 Clause-2 Clause-3 Clause-4
1 1 1273439 [0.0,1.0] [1.0,1.0] rule_2 [â€˜835886â€™] [(â€˜1273439â€™, â€˜835886â€™)] [(â€˜835886â€™,
â€˜catâ€™)][(â€˜1273439â€™,
â€˜catâ€™)]
1 1 103308 [0.0,1.0] [0.6,1.0] rule_1 [â€˜659792â€™,
â€˜404372â€™][(â€˜103308â€™, â€˜659792â€™),
(â€˜103308â€™, â€˜404372â€™)]
2 2 277684 [0.0,1.0] [1.0,1.0] rule_2 [â€˜305645â€™] [(â€˜277684â€™, â€˜305645â€™)] [(â€˜305645â€™,
â€˜fishâ€™)][(â€˜277684â€™,
â€˜fishâ€™)]
2 2 551249 [0.0,1.0] [0.6,1.0] rule_1 [â€˜377195â€™] [(â€˜551249â€™, â€˜377195â€™)]
3 3 861455 [0.0,1.0] [1.0,1.0] rule_2 [â€˜1450147â€™] [(â€˜861455â€™, â€˜1450147â€™)] [(â€˜1450147â€™,
â€˜spiderâ€™)][(â€˜861455â€™,
â€˜spiderâ€™)]
3 3 23197 [0.0,1.0] [0.6,1.0] rule_1 [â€˜25795â€™] [(â€˜23197â€™, â€˜25795â€™)]
3 3 757646 [0.0,1.0] [0.6,1.0] rule_1 [â€˜423053â€™] [(â€˜757646â€™, â€˜423053â€™)]
4 4 86436 [0.0,1.0] [1.0,1.0] rule_2 [â€˜743812â€™] [(â€˜86436â€™, â€˜743812â€™)] [(â€˜743812â€™,
â€˜catâ€™)][(â€˜86436â€™,
â€˜catâ€™)]
4 4 40242 [0.0,1.0] [0.6,1.0] rule_1 [â€˜407809â€™] [(â€˜40242â€™, â€˜407809â€™)]
4 4 757646 [0.0,1.0] [1.0,1.0] rule_2 [â€˜423053â€™,
â€˜548848â€™][(â€˜757646â€™, â€˜423053â€™),
(â€˜757646â€™, â€˜548848â€™)][(â€˜548848â€™,
â€˜catâ€™)][(â€˜757646â€™,
â€˜catâ€™)]
5 5 420093 [0.0,1.0] [0.6,1.0] rule_1 [â€˜275269â€™,
â€˜472129â€™][(â€˜420093â€™, â€˜275269â€™),
(â€˜420093â€™, â€˜472129â€™)]
5 5 1334826 [0.0,1.0] [1.0,1.0] rule_2 [â€˜1486432â€™] [(â€˜1334826â€™, â€˜1486432â€™)] [(â€˜1486432â€™,
â€˜fishâ€™)][(â€˜1334826â€™,
â€˜fishâ€™)]
5 5 196947 [0.0,1.0] [0.6,1.0] rule_1 [â€˜212129â€™] [(â€˜196947â€™, â€˜212129â€™)]
6 6 348252 [0.0,1.0] [1.0,1.0] rule_2 [â€˜1123497â€™] [(â€˜348252â€™, â€˜1123497â€™)] [(â€˜1123497â€™,
â€˜catâ€™)][(â€˜348252â€™,
â€˜catâ€™)]
6 6 1144981 [0.0,1.0] [0.6,1.0] rule_1 [â€˜232110â€™] [(â€˜1144981â€™, â€˜232110â€™)]
6 6 420093 [0.0,1.0] [1.0,1.0] rule_2 [â€˜275269â€™,
â€˜472129â€™,
â€˜275337â€™][(â€˜420093â€™, â€˜275269â€™),
(â€˜420093â€™, â€˜472129â€™),
(â€˜420093â€™, â€˜275337â€™)][(â€˜275337â€™,
â€˜turtleâ€™)][(â€˜420093â€™,
â€˜turtleâ€™)]
7 7 354365 [0.0,1.0] [1.0,1.0] rule_2 [â€˜354455â€™,
â€˜718503â€™][(â€˜354365â€™, â€˜354455â€™),
(â€˜354365â€™, â€˜718503â€™)][(â€˜718503â€™,
â€˜catâ€™)][(â€˜354365â€™,
â€˜catâ€™)]
7 7 420093 [0.0,1.0] [1.0,1.0] rule_2 [â€˜275269â€™,
â€˜472129â€™,
â€˜275337â€™][(â€˜420093â€™, â€˜275269â€™),
(â€˜420093â€™, â€˜472129â€™),
(â€˜420093â€™, â€˜275337â€™)][(â€˜275337â€™,
â€˜turtleâ€™)][(â€˜420093â€™,
â€˜turtleâ€™)]
7 7 757646 [0.0,1.0] [1.0,1.0] rule_2 [â€˜423053â€™,
â€˜548848â€™][(â€˜757646â€™, â€˜423053â€™),
(â€˜757646â€™, â€˜548848â€™)][(â€˜548848â€™,
â€˜catâ€™)][(â€˜757646â€™,
â€˜catâ€™)]
7 7 50219 [0.0,1.0] [1.0,1.0] rule_2 [â€˜2067â€™,
â€˜50136â€™][(â€˜50219â€™, â€˜2067â€™),
(â€˜50219â€™, â€˜50136â€™)][(â€˜2067â€™,
â€˜catâ€™),
(â€˜50136â€™,
â€˜catâ€™)][(â€˜50219â€™,
â€˜catâ€™),
(â€˜50219â€™,
â€˜catâ€™)]
7 7 148995 [0.0,1.0] [0.6,1.0] rule_1 [â€˜140490â€™] [(â€˜148995â€™, â€˜140490â€™)]

--- PAGE 26 ---
Algorithm 4 Updating interpretations
1:procedure update_interp (ğ‘–â€², ğ‘–)
2: ğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’ğ‘‘â†0
3: ifğ‘–(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ )! =ğ‘–â€²(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ )(ğ‘œğ‘Ÿ)ğ‘–(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ )! =ğ‘–â€²(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ )then
4: ğ‘–(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ )â†ğ‘“ğ‘™(ğ‘–(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ ), ğ‘–â€²(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ ))
â—by default ğ‘“ğ‘™is the ğ‘šğ‘ğ‘¥()function, but it can be user defined.
5: ğ‘–(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ )â†ğ‘“ğ‘¢(ğ‘–(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ ), ğ‘–â€²(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ ))
â—by default ğ‘“ğ‘¢is the ğ‘šğ‘–ğ‘›()function, but it can be user defined.
6: ğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’ğ‘‘â†1
7: end if
8: ifğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’ğ‘‘ (ğ‘ğ‘›ğ‘‘) (ğ‘–, ğ‘–ğ‘)âˆˆIPL,âˆ€ğ‘–ğ‘then
9: ğ‘–ğ‘(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ )â†ğ‘“ğ‘™(ğ‘–ğ‘(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ ),1âˆ’ğ‘–(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ ))
10: ğ‘–ğ‘(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ )â†ğ‘“ğ‘¢(ğ‘–ğ‘(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ ),1âˆ’ğ‘–(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ ))
11: end if
12: return ğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’ğ‘‘
13:end procedure
Algorithm 5 Consistency checking
1:procedure check_consistency (ğ‘–â€², ğ‘–)
â— ğ‘–â€²is new interpretation with [ğ¿â€², ğ‘ˆâ€²], and, ğ‘–is current interpretation with [ğ¿, ğ‘ˆ]
2: ifğ¿â€²> ğ‘ˆ (ğ‘œğ‘Ÿ)ğ‘ˆâ€²< ğ¿ then
3: return ğ¹ğ‘ğ‘™ğ‘ ğ‘’
4: else
5: return ğ‘‡ğ‘Ÿğ‘¢ğ‘’
6: end if
7:end procedure
Algorithm 6 Inconsistency resolution
1:procedure resolve_inconsistency (ğ‘–âˆˆğ¼)
2: ğ‘–(ğ¿ğ‘œğ‘¤ğ‘’ğ‘Ÿ )â†0
3: ğ‘–(ğ‘ˆğ‘ğ‘ğ‘’ğ‘Ÿ )â†1
4: ğ‘–(ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘ )â†1
5:end procedure

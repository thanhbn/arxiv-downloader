TÀI LIỆU THAM KHẢO

[1] G. Antoniou and A. Bikakis, "Dr-prolog: A system for defeasible reasoning with rules and ontologies on the semantic web," IEEE Transactions on Knowledge and Data Engineering (TKDE), vol. 19, no. 2, pp. 233–245, 2007.

[2] T. Lukasiewicz, "A novel combination of answer set programming with description logics for the semantic web," IEEE Transactions on Knowledge and Data Engineering (TKDE), vol. 22, no. 11, pp. 1577–1592, 2010.

[3] Q. Lin, J. Liu, L. Zhang, Y. Pan, X. Hu, F. Xu, and H. Zeng, "Contrastive graph representations for logical formulas embedding," IEEE Transactions on Knowledge and Data Engineering (TKDE), vol. 35, no. 4, pp. 3563–3574, 2023.

[4] L. Wu, Y. Zhou, and D. Zhou, "Towards high-order complementary recommendation via logical reasoning network," in IEEE International Conference on Data Mining (ICDM), 2022, pp. 1227–1232.

[5] Q. Lin, J. Liu, F. Xu, Y. Pan, Y. Zhu, L. Zhang, and T. Zhao, "Incorporating context graph with logical reasoning for inductive relation prediction," in The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2022, pp. 893–903.

[6] J. Yu, Q. Su, X. Quan, and J. Yin, "Multi-hop reasoning question generation and its application," IEEE Transactions on Knowledge and Data Engineering (TKDE), vol. 35, no. 1, pp. 725–740, 2023.

[7] F. Xu, J. Liu, Q. Lin, Y. Pan, and L. Zhang, "Logiformer: A two-branch graph transformer network for interpretable logical reasoning," in The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2022, pp. 1055–1065.

[8] H. Bronkhorst, G. Roorda, C. Suhre, and M. Goedhart, "Logical reasoning in formal and everyday reasoning tasks," International Journal of Science and Mathematics Education, vol. 18, pp. 1673–1694, 2020.

[9] Z. Yang, X. Du, R. Mao, J. Ni, and E. Cambria, "Logical reasoning over natural language as knowledge representation: A survey," CoRR, vol. abs/2303.12023, 2023.

[10] B. Peng, C. Li, P. He, M. Galley, and J. Gao, "Instruction tuning with GPT-4," CoRR, vol. abs/2304.03277, 2023. [Online]. Available: https://doi.org/10.48550/arXiv.2304.03277

[11] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong, Y. Du, C. Yang, Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li, X. Tang, Z. Liu, P. Liu, J. Nie, and J. Wen, "A survey of large language models," CoRR, vol. abs/2303.18223, 2023.

[12] M. M. Amin, E. Cambria, and B. W. Schuller, "Will affective computing emerge from foundation models and general artificial intelligence? A first evaluation of chatgpt," IEEE Intelligent Systems, vol. 38, no. 2, pp. 15–23, 2023.

[13] F. Jiao, Y. Guo, X. Song, and L. Nie, "Merit: Meta-path guided contrastive learning for logical reasoning," in Findings of the Association for Computational Linguistics (Findings of ACL), 2022, pp. 3496–3509.

[14] F. Xu, Q. Lin, T. Zhao, J. JiaweiHan, and J. Liu, "PathReasoner: Modeling reasoning path with equivalent extension for logical question answering," in Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Bangkok, Thailand: Association for Computational Linguistics, Aug. 2024, pp. 13 413–13 429. [Online]. Available: https://aclanthology.org/2024.acl-long.724

[15] Y. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, H. Lovenia, Z. Ji, T. Yu, W. Chung, Q. V. Do, Y. Xu, and P. Fung, "A multi-task, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity," CoRR, vol. abs/2302.04023, 2023.

[16] N. Bian, X. Han, L. Sun, H. Lin, Y. Lu, and B. He, "Chatgpt is a knowledgeable but inexperienced solver: An investigation of commonsense problem in large language models," CoRR, vol. abs/2303.16421, 2023.

[17] S. Imani, L. Du, and H. Shrivastava, "Mathprompter: Mathematical reasoning using large language models," CoRR, vol. abs/2303.05398, 2023.

[18] P. A. Flach and A. C. Kakas, "Abductive and inductive reasoning: background and issues," Abduction and induction: Essays on their relation and integration, pp. 1–27, 2000.

[19] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder, P. F. Christiano, J. Leike, and R. Lowe, "Training language models to follow instructions with human feedback," in NeurIPS, 2022.

[20] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray et al., "Training language models to follow instructions with human feedback," Advances in Neural Information Processing Systems, vol. 35, pp. 27 730–27 744, 2022.

[21] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey, Z. Chen et al., "Palm 2 technical report," arXiv preprint arXiv:2305.10403, 2023.

[Tiếp tục với tài liệu tham khảo khác...]

BẢNG 5: Thống kê và kết quả đánh giá trên NeuLR. Num. đại diện cho số lượng mẫu trong bộ dữ liệu. #Hop đại diện cho số bước của các mẫu trong bộ dữ liệu. COT đại diện cho chiến lược chain-of-thought dưới thiết lập 1-shot.

[Bảng với dữ liệu thống kê và kết quả]

(a) Diễn dịch.
(b) Quy nạp.
(c) Bắt chước.
(d) Hỗn hợp.

Hình 11: Trực quan hóa khả năng của ba LLMs giai đoạn đầu dưới bốn thiết lập lý luận.

[Biểu đồ radar showing performance metrics]

(a) Diễn dịch.
(b) Quy nạp.
(c) Bắt chước.
(d) Hỗn hợp.

Hình 12: Trực quan hóa khả năng lý luận logic của LLM dưới bốn thiết lập lý luận, bao gồm LLaMA3.1-Chat (8B), Mistral-Instruct-v0.3, Claude-3 và GPT-4 để so sánh.

[Biểu đồ radar showing performance metrics for different models]

PHỤ LỤC

Các phần sau đầu tiên cung cấp thông tin toàn diện về bảy LLMs được phân tích trong nghiên cứu này. Ngoài ra, file này bao gồm mô tả chi tiết về phương pháp đánh giá, kỹ thuật kỹ thuật prompt, bộ dữ liệu NeuLR và các phân tích bổ sung. Cuối cùng, các nghiên cứu trường hợp cho mỗi bộ dữ liệu được trình bày. Cùng nhau, các phần này cung cấp một tài khoản toàn diện và chi tiết về các phương pháp và kết quả của nghiên cứu.

PHỤ LỤC A
CHI TIẾT CỦA CÁC MÔ HÌNH NGÔN NGỮ LỚN

Trong nghiên cứu này, chúng tôi chọn ba LLMs đại diện trước đây (tức là text-davinci-003, ChatGPT và BARD) và bốn LLMs cập nhật (tức là LLaMA3.1-Chat, Mistral-Instruct-v0.3, Claude-3 và GPT-4) để đánh giá và phân tích. Các chi tiết được liệt kê trong Bảng 6, bao gồm liên kết, phí sử dụng, dữ liệu tiền huấn luyện và kích thước mô hình của mỗi LLM.

BẢNG 6: Chi tiết của các LLMs được chọn. Affi. là viết tắt của Affiliation. Charge đại diện cho phí cho 1M token theo định dạng (phí đầu vào / phí đầu ra). Data là thời gian mới nhất của dữ liệu huấn luyện được sử dụng. B trong cột cuối đại diện cho một tỷ.

[Bảng với thông tin chi tiết về các mô hình]

PHỤ LỤC B
CHI TIẾT CỦA ĐÁNH GIÁ

Phần này bổ sung một số chi tiết về đánh giá.

B.1 Các Bộ dữ liệu được Đánh giá

Xem xét tải trọng chú thích lớn, chúng tôi tạo sự cân bằng giữa tính toàn diện và chi phí chú thích. Chúng tôi cố gắng giữ dữ liệu đầy đủ của mỗi bộ dữ liệu để đánh giá ChatGPT, ngoại trừ một số bộ dữ liệu quy mô lớn, tức là RuleTaker, α-NLI, α-NLG, AbductiveRules, D*-Ab và LogiQA2NLI. Chúng tôi giới hạn số lượng mẫu đánh giá trong các bộ dữ liệu này lần lượt là 1000, 1000, 1000, 1000, 1000 và 600. Đối với text-davinci-003 và BARD, chúng tôi lấy mẫu ngẫu nhiên 100 ví dụ cho mỗi bộ dữ liệu. Nó vẫn toàn diện hơn các công trình trước đây, chỉ sử dụng hàng chục mẫu để kiểm tra (ví dụ: 30 mẫu cho mỗi bộ dữ liệu).

Đáng chú ý, đối với các thí nghiệm bổ sung trên bốn LLMs mới nhất (LLaMA3.1-Chat, Mistral-Instruct-v0.3, Claude-3 và GPT-4), chúng tôi lấy mẫu ngẫu nhiên 100 trường hợp cho mỗi bộ dữ liệu. Nó được kỳ vọng duy trì so sánh công bằng. Đối với các bộ dữ liệu lý luận hỗn hợp, chúng tôi tính toán phân phối độ dài sự thật của bốn bộ dữ liệu để tham khảo. Quan sát thấy rằng hầu hết các mẫu có 1-2 hoặc 3-4 sự thật để lý luận.

BẢNG 7: Phân phối độ dài sự thật (%) của các bộ dữ liệu hỗn hợp.

[Bảng với phân phối độ dài]

B.2 Chế độ Đánh giá

Như đã đề cập trong bài báo chính, chúng tôi giới thiệu bốn chỉ số để đánh giá hiệu suất LLM, tức là Tính Đúng đắn Câu trả lời, Tính Đúng đắn Giải thích, Tính Đầy đủ Giải thích và Tính Dư thừa Giải thích. Ngoài ra, chúng tôi sử dụng năm chỉ số để quy kết các trường hợp lỗi. Mặc dù các chỉ số này mang tính chủ quan, tiêu chuẩn của chúng rõ ràng và được định nghĩa rõ.

Đối với ba LLMs đại diện trước đây, đánh giá của chúng được tiến hành thông qua chú thích thủ công. Chi tiết, chúng tôi xuất các câu trả lời LLM thông qua gọi API và thuê mười sinh viên sau đại học (tất cả chuyên ngành Xử lý Ngôn ngữ Tự nhiên) để chú thích các câu trả lời dựa trên định nghĩa chỉ số của chúng tôi.

Đối với bốn LLMs xu hướng, đánh giá của chúng dưới chế độ tự động. Cụ thể, chúng tôi sử dụng mô hình GPT-4o để hoạt động như thẩm phán LLM. Các định nghĩa của chỉ số được đưa vào thẩm phán LLM như hướng dẫn, và nó xuất điểm đánh giá giống như người chú thích con người.

PHỤ LỤC C
KẾT QUẢ BỔ SUNG TRÊN LLMS MỚI NHẤT

Trước hết, chúng tôi tiến hành thí nghiệm thí điểm để chứng minh sự nhất quán giữa ghi nhãn thủ công và GPT-4o. Phân tích được tiến hành dưới bốn chỉ số đánh giá (tức là tính đúng đắn câu trả lời, tính đúng đắn giải thích, tính đầy đủ giải thích và tính dư thừa giải thích) và hai danh mục lỗi (tức là lỗi lựa chọn bằng chứng và lỗi lý luận). Hình 13 cho thấy kết quả.

Hình 13: Sự khớp đánh giá giữa thẩm phán LLM và chú thích con người trên 300 mẫu.

Nó minh họa rằng LLM-as-judge có thể phù hợp tốt với hiệu suất con người trong các thiết lập đánh giá của chúng tôi.

[Tiếp tục với các hình và bảng bổ sung...]

PHỤ LỤC D
KỸ THUẬT PROMPT

Trong triển khai, chúng tôi xem xét cả thiết lập zero-shot và few-shot. Để có được đầu ra mô hình phù hợp, chúng tôi xây dựng các prompt, được hiển thị trong Bảng 10 của Phụ lục.

PHỤ LỤC E
BỘ DỮ LIỆU NEULR

Trong phần này, chúng tôi sẽ cung cấp thêm chi tiết về cách NeuLR được xây dựng và hình thức của prompt là gì.

E.1 Xây dựng NeuLR

Theo giải thích trong bài báo chính, lý luận logic hiện tại có thể không duy trì được nội dung trung tính để đánh giá. Do đó, chúng tôi đề xuất bộ dữ liệu mới NeuLR để đánh giá khả năng lý luận logic thuần túy của LLMs. Dữ liệu được lấy từ [42], [46]. Chi tiết, chúng tôi chuyển đổi một số nội dung quan trọng (ví dụ: thực thể và thuộc tính) thành chuỗi ngẫu nhiên. Trong NeuLR, chúng tôi trung tính hóa ba loại từ, tức là tên, loài và thuộc tính. Chúng tôi thay thế mỗi loại từ bằng sự nối của tiền tố (tức là NP, SP, ADP) và sáu ký tự ngẫu nhiên (kết hợp chữ hoa và chữ thường và số).

BẢNG 9: Việc xây dựng nội dung trung tính. Cột Ví dụ trình bày một số từ ví dụ. Tiền tố đại diện cho tiền tố cho mỗi loại từ. 6-ký tự đại diện cho ví dụ về kết hợp ký tự được tạo ngẫu nhiên.

[Bảng với ví dụ về việc thay thế từ]

E.2 Hình thức Prompt

Khác với các đánh giá trước đây, chúng tôi xem xét việc thêm mô tả về tính trung tính nội dung trong các hình thức prompt. Cụ thể, chúng tôi thay thế tiền tố mô tả nhiệm vụ trước đây bằng hình thức sau (lấy lý luận bắt chước để minh họa):

• Đây là một nhiệm vụ lý luận bắt chước nội dung trung tính. Các chuỗi bắt đầu bằng SP đại diện cho loài. Các chuỗi bắt đầu bằng NP đại diện cho tên. Các chuỗi bắt đầu bằng ADP đại diện cho thuộc tính. Cho một ngữ cảnh và một sự thật, cần tạo ra một sự thật thiếu ngắn.

Các phần khác của prompt giống như hình thức trước đây.

[Tiếp tục với phần F, G và các bảng case study...]

BẢNG 8: Các Bộ dữ liệu được Đánh giá. Gen. phân biệt liệu câu trả lời dự đoán có phải là văn bản được tạo hay nhãn được phân loại. Explain biểu thị liệu giải thích có được yêu cầu trong nhiệm vụ. Các cột # Davinci, # ChatGPT và # BARD đại diện cho số lượng mẫu đánh giá của mỗi bộ dữ liệu cho ba LLMs.

[Bảng chi tiết về các bộ dữ liệu]

[Tiếp tục với các phần còn lại của phụ lục, bao gồm các bảng case study từ 11-25 với các ví dụ lý luận cụ thể cho từng bộ dữ liệu...]

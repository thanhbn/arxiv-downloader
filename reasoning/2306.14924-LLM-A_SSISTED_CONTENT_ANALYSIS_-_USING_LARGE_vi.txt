# 2306.14924.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/reasoning/2306.14924.pdf
# Kích thước tệp: 635094 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
PHÂN TÍCH NỘI DUNG HỖ TRỢ BỞI LLM: SỬ DỤNG CÁC MÔ HÌNH 
NGÔN NGỮ LỚN ĐỂ HỖ TRỢ MÃ HÓA SUY DIỄN
Robert Chew, John Bollenbacher, Michael Wenger
Trung tâm Khoa học Dữ liệu và AI
RTI International
{rchew, jmbollenbacher, mwenger}@rti.orgJessica Speer, Annice Kim
Trung tâm Truyền thông và Tác động Truyền thông
RTI International
{jlspeer, akim}@rti.org

TÓM TẮT
Mã hóa suy diễn là một phương pháp nghiên cứu định tính được sử dụng rộng rãi để xác định mức độ phổ biến của
các chủ đề qua các tài liệu. Mặc dù hữu ích, mã hóa suy diễn thường gây gánh nặng và tốn thời gian
vì nó đòi hỏi các nhà nghiên cứu phải đọc, diễn giải và phân loại một cách đáng tin cậy một khối lớn các
tài liệu văn bản không có cấu trúc. Các mô hình ngôn ngữ lớn (LLM), như ChatGPT, là một loại công cụ AI 
phát triển nhanh chóng có thể thực hiện một loạt các tác vụ xử lý ngôn ngữ tự nhiên và suy luận. Trong nghiên cứu này,
chúng tôi khám phá việc sử dụng LLM để giảm thời gian cần thiết cho mã hóa suy diễn trong khi vẫn giữ được
tính linh hoạt của phân tích nội dung truyền thống. Chúng tôi phác thảo cách tiếp cận được đề xuất, được gọi là phân tích
nội dung hỗ trợ bởi LLM (LACA), cùng với một nghiên cứu trường hợp chuyên sâu sử dụng GPT-3.5 cho LACA trên một
bộ dữ liệu mã hóa suy diễn có sẵn công khai. Ngoài ra, chúng tôi thực hiện một đánh giá thực nghiệm sử dụng LACA
trên 4 bộ dữ liệu có sẵn công khai để đánh giá câu hỏi rộng hơn về mức độ hiệu quả của GPT-3.5 qua
một loạt các tác vụ mã hóa suy diễn. Nhìn chung, chúng tôi thấy rằng GPT-3.5 thường có thể thực hiện mã hóa suy diễn
ở mức độ thỏa thuận tương đương với các người mã hóa con người. Ngoài ra, chúng tôi chứng minh rằng LACA có thể
giúp tinh chỉnh gợi ý cho mã hóa suy diễn, xác định các mã mà LLM đang đoán ngẫu nhiên,
và giúp đánh giá khi nào nên sử dụng LLM so với người mã hóa con người cho mã hóa suy diễn. Chúng tôi kết luận với một số
ý nghĩa cho thực hành tương lai của mã hóa suy diễn và các phương pháp nghiên cứu liên quan.

1 Giới thiệu
Phân tích nội dung được sử dụng rộng rãi trong nghiên cứu định tính để phân tích và diễn giải các đặc điểm của văn bản, hoặc các hình thức
truyền thông khác, do tính chất có hệ thống và không xâm phạm của nó [1]. Phân tích nội dung thường bao gồm việc chọn một
mẫu dữ liệu văn bản, xác định các danh mục để phân loại nội dung, và sau đó mã hóa nội dung theo các danh mục
với các định nghĩa. Điều này thường được gọi là mã hóa suy diễn trong đó các nhà nghiên cứu phát triển một sơ đồ mã hóa dựa
trên các lý thuyết và nghiên cứu hiện có trước khi bắt đầu quá trình mã hóa. Điều này trái ngược với mã hóa quy nạp bao gồm việc
không xác định danh mục a priori, mà thay vào đó xác định và đặt tên các danh mục nổi lên từ văn bản trong
quá trình mã hóa. Mặc dù cứng nhắc hơn, mã hóa suy diễn phù hợp hơn để tổng quát hóa kết quả qua các nghiên cứu [2].

Bất chấp những ưu điểm của nó, mã hóa suy diễn là một quá trình tốn thời gian, đặc biệt khi mã hóa một lượng lớn
dữ liệu [3] và cho các chủ đề có thể tinh tế hoặc được đề cập không thường xuyên. Mã hóa đòi hỏi các nhà nghiên cứu phải cẩn thận đọc và
mã hóa từng phần nội dung, có thể nhiều lần, để đảm bảo rằng họ đang nắm bắt chính xác tất cả thông tin liên quan,
diễn giải văn bản đúng cách, và áp dụng các định nghĩa danh mục một cách trung thực. Gánh nặng này trở nên nghiêm trọng hơn khi
phát triển và tinh chỉnh sổ tay mã hóa, đào tạo người mã hóa, và đo lường độ tin cậy giữa các người đánh giá để đảm bảo các định nghĩa mã
được xác định rõ ràng và có thể được mã hóa một cách nhất quán [4].

Gần đây, các mô hình ngôn ngữ lớn sinh tạo (LLM) [5,6] đã chứng minh tiến bộ đáng kể hướng tới việc đạt được
hiệu suất ngang tầm con người trên một số nhiệm vụ hiểu và suy luận ngôn ngữ tự nhiên [7]. Ví dụ,
các nhà phát triển GPT-4 tuyên bố rằng nó hoạt động ở phần trăm thứ 90 trong Kỳ thi Luật sư Thống nhất và phần trăm thứ 93 và 89
cho các kỳ thi SAT Đọc hiểu và SAT Toán tương ứng, mặc dù không được huấn luyện để giải chúng một cách cụ thể [8].

Trong nghiên cứu này, chúng tôi khám phá tiềm năng của LLM cho việc thực hiện các nhiệm vụ mã hóa định tính. Cụ thể, chúng tôi đề xuất một
phương pháp luận để kết hợp LLM vào mã hóa suy diễn, được gọi là phân tích nội dung hỗ trợ bởi LLM (LACA), điều này phù hợp
với phân tích nội dung truyền thống và cung cấp một cách để đánh giá khi nào nên sử dụng LLM so với người mã hóa con người. Chúng tôi chứng minh

--- TRANG 2 ---
phương pháp luận này với một nghiên cứu trường hợp chuyên sâu, cũng như trên bốn bộ dữ liệu đa dạng có sẵn công khai, làm nổi bật
những khác biệt đáng chú ý về hiệu suất qua các loại tài liệu, sổ tay mã hóa và danh mục mã.

1.1 Bối cảnh và Công trình Liên quan
Có một lịch sử lâu dài trong tài liệu nghiên cứu định tính về việc sử dụng máy tính để giúp thực hiện phân tích nội dung trên văn bản
[9,10]. Được đề xuất từ năm 1966, phân tích nội dung hỗ trợ máy tính [11] sử dụng các từ điển được xác định trước về các thuật ngữ chính
và cụm từ liên quan đến hiện tượng đang nghiên cứu và tìm kiếm chúng trong một tập hợp tài liệu. Tần suất thuật ngữ
sau đó có thể được tính toán, nhóm lại và so sánh với nhau hoặc qua các tài liệu. Phân tích nội dung hỗ trợ máy tính
có lợi ích từ việc rõ ràng và minh bạch trong các quyết định mã hóa vì các mã được gán dựa hoàn toàn trên sự hiện diện của
các thuật ngữ. Tuy nhiên, để các phương pháp dựa trên từ điển hoạt động tốt, chúng phải được xây dựng cẩn thận để nắm bắt các ý nghĩa ngữ nghĩa dự kiến
của các từ trong lĩnh vực nghiên cứu. Ví dụ, Loughran và McDonald [12] đã sử dụng từ điển Harvard-IV-4 tiêu chuẩn
để phân tích tình cảm của các báo cáo thu nhập doanh nghiệp. Họ lưu ý rằng nhiều thuật ngữ được gán
hàm ý tiêu cực trong từ điển (ví dụ, "crude", "tax", "cost") có hàm ý tích cực hoặc trung tính khi được sử dụng
trong bối cảnh của các báo cáo 10-K (ví dụ, việc sử dụng "crude oil" bởi các công ty dầu khí). Ngoài ra, việc xây dựng
từ điển tùy chỉnh mới có thể gây gánh nặng và có thể đòi hỏi xác thực đáng kể để đảm bảo các thuật ngữ được bao gồm đo lường đầy đủ
cấu trúc cơ bản quan tâm.

Để khắc phục những nhược điểm của phân tích nội dung hỗ trợ máy tính, các nhà nghiên cứu đề xuất sử dụng học máy có giám sát
và xử lý ngôn ngữ tự nhiên (NLP) để hỗ trợ mã hóa suy diễn. Không giống như cách tiếp cận từ điển, nơi
các nhà nghiên cứu xác định cách mã hóa tài liệu bằng cách tạo các tập hợp thuật ngữ cho từng danh mục quan tâm, các phương pháp học có giám sát
học cách mã hóa tài liệu từ các ví dụ trước về tài liệu cả chứa và không chứa
danh mục quan tâm. Vì các mô hình này được huấn luyện để phân biệt giữa các danh mục trong corpus đang nghiên cứu, chúng
thường có thể tạo ra mã hóa tự động chất lượng cao với ít lo ngại hơn về sự trôi dạt ngữ nghĩa liên quan đến việc sử dụng một
từ điển sẵn có được thiết kế cho một bối cảnh khác. Các nhà nghiên cứu đã sử dụng các mô hình học có giám sát để hỗ trợ
mã hóa suy diễn trong các tình huống khác nhau, bao gồm phân tích chủ đề của các bài báo tin tức Đức [13], diễn giải
bản tóm tắt amicus của Tòa án Tối cao Hoa Kỳ [14], và mã hóa các phản hồi khảo sát mở [15]. Tuy nhiên, học máy có giám sát
trong lịch sử ít được áp dụng trong phân tích nội dung do không có đủ dữ liệu được gán nhãn để có được
kết quả mạnh, đặc biệt cho các danh mục hiếm có thể quan tâm nhất đối với các nhà khoa học xã hội. Ngoài ra, không
biết tại sao các quyết định mô hình được đưa ra, các nhà khoa học xã hội có thể miễn cưỡng tin tưởng vào các dự đoán học máy [16].

Gần đây, các LLM sinh tạo như ChatGPT đang được sử dụng cho các nhiệm vụ tương tự như mã hóa suy diễn. Những ưu điểm
của các mô hình này là chúng thường có thể tạo ra kết quả thuyết phục cho việc học zero-shot (không có ví dụ) hoặc few-shot
(ít ví dụ), giải quyết một hạn chế của học có giám sát truyền thống. Gilardi và cộng sự [17] sử dụng ChatGPT
để thực hiện một số nhiệm vụ chú thích (liên quan, quan điểm, chủ đề và phát hiện khung) và so sánh hiệu suất của nó với
người lao động đám đông được tuyển dụng từ Amazon Mechanical Turk. Họ thấy rằng độ chính xác zero-shot của ChatGPT vượt qua
người lao động đám đông cho tất cả các nhiệm vụ trừ phân loại chủ đề. Tương tự, Tornberg [18] so sánh hiệu suất của chú thích
GPT-4 zero-shot với các chuyên gia và người lao động đám đông để xác định liệu các tweet có đến từ chính trị gia Đảng Dân chủ hay Cộng hòa Hoa Kỳ hay không.
Ông thấy rằng GPT-4 vượt trội hơn người lao động đám đông và chuyên gia về độ chính xác và độ tin cậy giữa các người đánh giá. Gần nhất
với công việc của chúng tôi, Xiao và cộng sự, [19] cho thấy kết quả sớm rằng LLM có thể có triển vọng cho mã hóa suy diễn. Họ sử dụng một
phiên bản sớm của GPT-3.5 (text-davinci-002) để thực hiện mã hóa suy diễn trên các câu hỏi tò mò của trẻ em, so sánh
hai thiết kế gợi ý khác nhau: một bao gồm các quyết định mã hóa mẫu trong gợi ý và một khác sửa đổi
một sổ tay mã hóa hiện có thành một gợi ý. Họ thấy rằng các gợi ý dựa trên sổ tay mã hóa vượt trội hơn các gợi ý dựa trên ví dụ,
mặc dù cả hai đều kém hiệu quả khi so sánh với các người mã hóa chuyên gia.

Đóng góp của chúng tôi mở rộng công việc trước đó bằng cách đề xuất một vai trò toàn diện cho LLM trong khung mã hóa suy diễn lớn hơn.
Đặc biệt, chúng tôi tập trung vào các phê bình trước đó về việc áp dụng học máy cho mã hóa định tính bao gồm
cả gánh nặng tạo dữ liệu huấn luyện và nhu cầu về lý luận mô hình trong các quyết định mã hóa. Ngoài ra,
công việc của chúng tôi chứa một nghiên cứu đánh giá như các công việc trước đó so sánh mức độ hiệu quả của một LLM cụ thể trên một tập hợp
các nhiệm vụ mã hóa suy diễn so với người mã hóa con người [17, 18, 19]. Thành phần này phục vụ mục đích kép là chứng minh
cách LACA sẽ áp dụng trong các tình huống khác nhau đồng thời cũng đóng góp vào tài liệu ngày càng tăng về mức độ hiệu quả của
thế hệ LLM hiện tại trong các nhiệm vụ mã hóa định tính.

2 Phương pháp
2.1 Phân tích Nội dung Hỗ trợ bởi LLM (LACA)
LACA xây dựng dựa trên cách tiếp cận phân tích nội dung của Neuendorf [4] nhấn mạnh cách các khái niệm từ nghiên cứu khảo sát,
như đo lường, độ tin cậy và suy luận quần thể, có thể giúp các nhà nghiên cứu định tính tiến hành một cách có hệ thống

--- TRANG 3 ---
Hình 1: Sơ đồ Quy trình Phân tích Nội dung Hỗ trợ bởi LLM (LACA)

phân tích nội dung. Đầu tiên, chúng tôi phác thảo các bước của phân tích nội dung suy diễn theo cách tiếp cận này. Tiếp theo, chúng tôi mô tả
LACA, làm nổi bật các thành phần mà nó khác biệt so với quy trình mã hóa suy diễn điển hình (Hình 1).

Thông thường, bước đầu tiên trong phân tích nội dung là phát triển các biện pháp (danh mục) để vận hành các khái niệm
đang nghiên cứu. Đối với mã hóa suy diễn, các biện pháp này nên được rút ra từ lý thuyết khi có thể và cho phép các nhà nghiên cứu
kiểm tra các giả thuyết về nội dung. Một thành phần chính của việc phát triển biện pháp là tạo ra một sơ đồ mã hóa và
sổ tay mã hóa đi kèm. Sổ tay mã hóa là tài liệu chứa hướng dẫn để gán mã, thường chứa
các định nghĩa của danh mục, hướng dẫn để gán danh mục và ví dụ về dữ liệu được mã hóa. Khi nhà nghiên cứu đã
xác định những mã nào cần thiết và phát triển hướng dẫn về cách mã hóa chúng, một mẫu tài liệu được rút ra
để bắt đầu mã hóa, lý tưởng là ngẫu nhiên để hỗ trợ suy luận thống kê hạ nguồn. Điều này giả định rằng việc mã hóa một cuộc điều tra dân số của tất cả
các tài liệu áp dụng thường là không khả thi. Để đảm bảo rằng các biện pháp có thể được hiểu một cách đáng tin cậy và áp dụng nhất quán
cho các tài liệu, hai hoặc nhiều người mã hóa mã hóa tất cả các tài liệu trong mẫu và các chỉ số độ tin cậy giữa các người đánh giá (IRR)
được tính toán để định lượng sự thỏa thuận giữa các người mã hóa. Nếu các chỉ số IRR đủ cao, một mẫu ngẫu nhiên lớn hơn nhiều
các tài liệu được chọn để mã hóa cuối cùng. Mẫu lớn hơn này thường cần thiết nếu mục tiêu chính của phân tích
là định lượng tần suất xuất hiện mã (hoặc đồng xuất hiện với nhau) một cách đáng tin cậy trong khi xem xét tác động của biến thiên mẫu.
Khi mẫu cuối cùng được mã hóa, các ước tính điểm như số lượng và tỷ lệ có thể được tính toán cùng với
khoảng tin cậy liên quan của chúng.

LACA khác biệt so với quy trình điển hình này trong ba thành phần: (1) đồng phát triển sổ tay mã hóa với LLM và kiểm tra
tính hợp lệ; (2) kiểm tra độ tin cậy giữa người mã hóa con người và LLM; và (3) thay thế mã hóa thủ công bằng mã hóa LLM
cho bộ dữ liệu được mã hóa cuối cùng.

2.1.1 Đồng Phát triển Sổ tay Mã hóa và Kiểm tra Tính hợp lệ
Bước đầu tiên trong LACA là sử dụng LLM khi phát triển sổ tay mã hóa. Giống như một người mã hóa con người, LLM sẽ cần
sử dụng sổ tay mã hóa làm hướng dẫn (tức là gợi ý) về cách mã hóa tài liệu. Đồng phát triển sổ tay mã hóa với LLM
đòi hỏi kiểm tra sổ tay mã hóa với LLM trên một mẫu tài liệu chưa được mã hóa. Mục tiêu của đánh giá này là
giúp xác định liệu LLM có "hiểu" nhiệm vụ mã hóa và có thể tạo ra đầu ra hợp lệ nắm bắt cấu trúc cơ bản
quan tâm hay không. Ngoài việc xem xét thủ công các quyết định mã hóa do LLM gán, chúng tôi đề xuất hai phương pháp
để hỗ trợ trong đánh giá này: (1) tiến hành kiểm tra giả thuyết để đánh giá liệu các quyết định mã hóa do LLM tạo ra có thể
được phân biệt với nhiễu ngẫu nhiên hay không, và (2) sử dụng các gợi ý không chỉ cung cấp quyết định mã hóa, mà còn lý do cho
quyết định mã hóa.

--- TRANG 4 ---
2.1.1.1 Kiểm tra Tính ngẫu nhiên
Lý thuyết của chúng tôi thúc đẩy kiểm tra giả thuyết là nếu mô hình nghiêm trọng không hiểu khái niệm mà nó
được cho là mã hóa, nó sẽ bị buộc phải gán mã một cách hiệu quả ngẫu nhiên. Đối với các mã đòi hỏi quyết định "Có" / "Không",
chúng tôi sẽ mong đợi một mô hình đang đoán sẽ tạo ra một phân phối các quyết định mã hóa gần như
phân chia đều giữa "Có" và "Không". Kiểm tra giả thuyết có thể được sử dụng để đánh giá liệu tần suất của các quyết định mã do mô hình tạo ra
có phù hợp với hành vi này hay không, giúp xác định sớm các nhiệm vụ mã hóa mà mô hình có thể không
hiểu và liên tục hoạt động kém. Chi tiết về các kiểm tra được cung cấp trong Phần 2.2.3 và bằng chứng về khả năng áp dụng của chúng
được trình bày trong Phần 3.1.1 và 3.2. Tuy nhiên, một nhược điểm của các kiểm tra này là chúng sẽ từ chối tất cả
các quy trình quyết định mã hóa có tần suất bắt chước phân phối đều, bất kể mô hình có thực sự đoán ngẫu nhiên hay không.
Vì lý do này, việc xem xét thủ công từng quan sát bằng phương pháp được nêu dưới đây vẫn được khuyến khích cao.

2.1.1.2 Lý do cho Quyết định Mã hóa
Để giúp đánh giá tính hợp lệ bề mặt của các mã do mô hình tạo ra, chúng tôi sử dụng các gợi ý không chỉ cung cấp quyết định mã hóa, mà
còn lý do cho quyết định mã hóa. Công việc trước đó cho thấy rằng việc thêm lý do vào gợi ý có thể giúp người chú thích hiểu rõ hơn
các quyết định của mô hình [20,21]. Ngoài ra, công việc tương tự buộc LLM phải đi qua lý luận của chúng
cho các nhiệm vụ phức tạp đã được chứng minh là giúp cải thiện hiệu suất nhiệm vụ [22]. Bước này trong LACA được bao gồm để giúp
giải quyết vấn đề tin tưởng LLM, vì về lý thuyết, nó có thể giúp đánh giá chất lượng mã hóa ở cấp độ quan sát riêng lẻ.
Tuy nhiên, cần thận trọng để không diễn giải quá mức các phản hồi do LLM tạo ra, vì chưa hiểu rõ
mức độ mà các lý do do mô hình tạo ra thực sự phản ánh cách mô hình đưa ra quyết định mã hóa. Chúng tôi xem các lý giải của mô hình
chủ yếu như một công cụ hỗ trợ cho người đánh giá con người, thay vì là một tài khoản cơ học trung thực về hoạt động bên trong
của mô hình. Các ví dụ hướng dẫn về lý luận mã mô hình được cung cấp trong Phần 3.1.2 và 3.1.4.

2.1.1.3 Đánh giá Mô hình và Sửa đổi Sổ tay Mã hóa
Sau khi chạy kiểm tra giả thuyết và xem xét các mã và lý do do mô hình tạo ra, có thể rõ ràng rằng một số
mã đang hoạt động kém, hoặc vì mô hình không hiểu nhiệm vụ mã hóa hoặc vì nhiệm vụ nó đang mã hóa
khác với khái niệm trong tâm trí. Vấn đề sau có thể do sổ tay mã hóa được xác định không đầy đủ và có thể được giải quyết
bằng cách cung cấp thêm bối cảnh trong các mô tả sổ tay mã hóa hoặc cung cấp thêm ví dụ [19]. Lý tưởng nhất, sổ tay mã hóa
cung cấp định nghĩa, hướng dẫn và ví dụ cho phép một người mã hóa con người mới đối với nhiệm vụ có đủ thông tin
để hiểu khái niệm đang được mã hóa và cách nó nên được mã hóa. Tuy nhiên, trong thực tế, các nhà nghiên cứu thường thảo luận
và làm rõ các định nghĩa mã hóa với nhau như một phần của quá trình phát triển sổ tay mã hóa hoặc mã hóa. Nếu điều này xảy ra,
những quyết định không chính thức này có thể không luôn được phản ánh trong sổ tay mã hóa cuối cùng. Hơn nữa, các nhà nghiên cứu ngầm đưa ra
các giả định về kiến thức trước của người mã hóa khi quyết định mức độ chi tiết để làm cho các mô tả mã. Trong khi những
giả định này thường được kiểm tra trong các phiên IRR cho người mã hóa con người, chúng có thể được kiểm tra sớm hơn cho LLM trong
quá trình phát triển sổ tay mã hóa. Các ví dụ về sửa đổi sổ tay mã hóa được sử dụng trong nghiên cứu này được cung cấp trong Phụ lục B.

2.1.2 Kiểm tra Độ tin cậy giữa Người mã hóa Con người và LLM
Khi các gợi ý và sổ tay mã hóa được phát triển và các mã mô hình vượt qua kiểm tra tính hợp lệ, một mẫu hiệu chuẩn nhỏ được
rút ra, và cả mô hình và một hoặc nhiều người mã hóa con người mã hóa các tài liệu mẫu. Tối thiểu, các chỉ số IRR người-mô hình
được tính toán ở giai đoạn này để xác định liệu một người mã hóa con người và mô hình có đồng ý một cách đáng tin cậy về cách các tài liệu
nên được mã hóa hay không. Điều này tuân theo thực hành tiêu chuẩn trong phân tích nội dung, sự khác biệt duy nhất là thay vì cả hai
người mã hóa đều là con người, một là con người và một là mô hình. Ngoài ra, nếu các tài liệu được mã hóa kép bởi
người mã hóa con người, chúng ta cũng có thể so sánh sự thỏa thuận người-người với sự thỏa thuận người-mô hình để xem liệu cả hai đều cao,
và lý tưởng nhất, tương đương. Cách tiếp cận này phổ biến trong tài liệu [17,18,19] và cung cấp một điểm chuẩn hiệu suất con người
có ý nghĩa. Đối với cả hai đánh giá độ tin cậy, lý do mô hình có thể được sử dụng để cung cấp bối cảnh bổ sung về
sự bất đồng.

Nếu sau khi tiến hành các đánh giá này, nhóm nghiên cứu xác định rằng các mã do mô hình tạo ra kém hơn
các phản hồi được mã hóa bởi con người, thì họ có thể thực hiện kỹ thuật gợi ý bổ sung để sửa đổi các gợi ý và
sổ tay mã hóa cho các danh mục hoạt động kém hoặc xem xét các cách tiếp cận thay thế để mã hóa các danh mục
hoạt động kém. Những lựa chọn thay thế này sẽ phụ thuộc phần lớn vào loại thất bại; các thảo luận về một số trong số này được trình bày
trong Phần 4.

--- TRANG 5 ---
2.1.3 Sử dụng LLM để tạo Bộ dữ liệu được Mã hóa Cuối cùng
Nếu các mã do mô hình tạo ra được coi là không kém các phản hồi được mã hóa bởi con người, thì bước cuối cùng trong LACA là
sử dụng LLM cho mã hóa cuối cùng. Vì các dự đoán mô hình ít tốn thời gian và chi phí hơn nhiều so với mã hóa bằng con người
(Phần 3.2), hoặc tất cả tài liệu có thể được mã hóa, hoặc một mẫu ngẫu nhiên lớn các tài liệu có thể được mã hóa để giúp ổn định
các ước tính điểm và khoảng tin cậy. Bước này cung cấp việc giảm gánh nặng lớn nhất so với phân tích nội dung truyền thống,
vì hầu hết việc mã hóa hiện có thể được cung cấp bởi mô hình thay vì người mã hóa con người.

2.2 Thí nghiệm
Để chứng minh cách tiếp cận này, chúng tôi so sánh GPT-3.5 [23,24] với người mã hóa con người trên bốn bộ dữ liệu có sẵn công khai.
GPT-3.5 là một loại LLM được phát triển từ kiến trúc GPT-3 [6] đã trải qua tinh chỉnh hướng dẫn [5]
để cải thiện hiệu suất học zero-shot và/hoặc tối ưu hóa chính sách gần [25] để phản ánh sát hơn
sở thích của người dùng. Mô hình GPT-3.5 cụ thể được sử dụng trong nghiên cứu này (gpt-3.5-turbo) được tối ưu hóa cho trò chuyện và hiện tại là
mô hình chính được sử dụng trong ChatGPT. Để giảm biến thiên trong các phản hồi, siêu tham số nhiệt độ được đặt thành 0 cho
tất cả các lần chạy mô hình.

2.2.1 Gợi ý
Để sử dụng GPT-3.5 cho mã hóa suy diễn, chúng tôi đã viết một loạt gợi ý hướng dẫn LLM thực hiện mã hóa suy diễn
được cho sổ tay mã hóa và một văn bản (Phụ lục A). Trong một số trường hợp, hướng dẫn sổ tay mã hóa được cập nhật để làm rõ
các định nghĩa mã và chuẩn hóa định dạng. Thiết kế gợi ý được lấy cảm hứng từ các kỹ thuật như gợi ý vai trò [26], nơi
một vai trò cho AI được gán (ví dụ, "bạn là một người mã hóa định tính thực hiện mã hóa suy diễn"), và gợi ý chuỗi suy nghĩ [22], nơi một nhiệm vụ lý luận phức tạp được chia thành các nhiệm vụ con và mô hình được yêu cầu thực hiện
các nhiệm vụ con theo chuỗi. Ngoài các ví dụ được cung cấp trong các sổ tay mã hóa hiện có, các ví dụ few-shot bổ sung cho
học theo bối cảnh [27] không được bao gồm, làm cho phần lớn các nhiệm vụ mã hóa là zero-shot. Một lựa chọn thiết kế
đáng chú ý là sự khác biệt trong cách chúng tôi tiếp cận các sơ đồ mã hóa loại trừ lẫn nhau so với không loại trừ lẫn nhau. Đối với
các tập hợp mã loại trừ lẫn nhau, chúng tôi đã sử dụng một gợi ý yêu cầu một mã duy nhất và giải thích mã hóa. Tuy nhiên, đối với
các tập hợp mã không loại trừ lẫn nhau, chúng tôi đã sử dụng một gợi ý lặp qua từng mã riêng lẻ, để cung cấp một mã và
giải thích mã hóa cho từng mã trong tập hợp riêng biệt.

2.2.2 Dữ liệu
Bốn bộ dữ liệu có sẵn công khai được sử dụng để chứng minh LACA và đánh giá hiệu suất mã hóa suy diễn của
GPT-3.5 (Bảng 1). Các bộ dữ liệu được xem xét để đưa vào nếu chúng chứa văn bản gốc, dữ liệu được mã hóa và một
sổ tay mã hóa, mặc dù trong một số trường hợp, một sổ tay mã hóa thô sơ được rút ra từ tên danh mục. Văn bản gốc và
sổ tay mã hóa đã sửa đổi cho mỗi bộ dữ liệu có sẵn trong Phụ lục B.

Bộ dữ liệu Trump Tweets bao gồm một tập hợp các tweet được đăng bởi Donald Trump, thu được từ Kho lưu trữ Trump
Twitter [28], kéo dài hai năm đầu nhiệm kỳ tổng thống Hoa Kỳ của ông. Để tạo bộ dữ liệu, Coe và cộng sự [29]
đã rút ra một mẫu phân tầng theo tháng, dẫn đến một tập hợp 2.082 tweet sau đó được mã hóa. Sổ tay mã hóa
bao gồm 13 danh mục không loại trừ lẫn nhau, bao gồm cả thuộc tính chủ đề và cú pháp. Ví dụ,
danh mục "CRIT" biểu thị sự chỉ trích một người hoặc ý tưởng khác, trong khi danh mục "HSTG" chỉ ra việc sử dụng hashtag
(tức là, các từ hoặc từ viết tắt bắt đầu bằng ký tự "#").

Bộ dữ liệu Contrarian Claims bao gồm 2.904 văn bản dài đoạn từ truyền thông truyền thống và truyền thông xã hội
đưa ra các tuyên bố về biến đổi khí hậu trái với sự đồng thuận khoa học. Coan và cộng sự [30] đầu tiên phát triển
phân loại của họ về các siêu-, tiểu- và tiểu-tiểu-tuyên bố bằng cách tham khảo danh sách các huyền thoại khí hậu tại skepticalscience.com [31] và
phân loại chúng thành các danh mục chính. Các tình nguyện viên có hiểu biết về khí hậu đã trải qua đào tạo trước khi độc lập mã hóa
các tài liệu và được hướng dẫn gán một mã cho mỗi tài liệu xuống đến cấp độ tiểu-tuyên bố. Sổ tay mã hóa chứa
27 tiểu-tuyên bố, cũng như một mã được chỉ định cho "Không có gì trong số trên".

Bộ dữ liệu BBC News [32] bao gồm 2.225 bài báo tin tức được xuất bản bởi Tập đoàn Phát thanh Truyền hình Anh. Những
bài báo này bao gồm các câu chuyện trong năm lĩnh vực chủ đề từ 2004-2005, phục vụ như các mã trong sổ tay mã hóa: công nghệ, kinh doanh,
chính trị, giải trí và thể thao. Nhiệm vụ mã hóa nhằm gán mỗi văn bản vào một danh mục duy nhất.

Bộ dữ liệu Ukraine Water Problems [33] bao gồm các báo cáo giải quyết các vấn đề chất lượng nước ở Ukraine. Một phần
các văn bản ban đầu được viết bằng tiếng Ukraine và sau đó được dịch sang tiếng Anh, dẫn đến một số trường hợp
không chính xác và mơ hồ. Sổ tay mã hóa bao gồm 5 danh mục không loại trừ lẫn nhau: vấn đề môi trường,
ô nhiễm, nhà máy xử lý hoặc công nghệ, chỉ số khí hậu, và giám sát sinh học trong nước hoặc lưu vực sông.

--- TRANG 6 ---
Bảng 1: Tóm tắt Bộ dữ liệu
Loại tài liệu Bộ dữ liệu | Loại trừ lẫn nhau | Mã (N) | Tài liệu (N) | Ghi chú
Trump Tweets | Tweet | Không | 13 | 2,083 | Sổ tay mã hóa được viết không chính thức với mô tả ngắn
Contrarian Claims1 | Bài blog | Có | 28 | 2,904 | Loại trừ lẫn nhau, tập hợp mã phân cấp. Các mã tinh tế và có thể có định nghĩa với sự chồng chéo khái niệm.
BBC News | Bài báo tin tức | Có | 5 | 2,225 | Không có sổ tay mã hóa chính thức, chỉ có tên lớp (ví dụ, kinh doanh)
Ukraine Water Problems | Báo cáo chất lượng nước | Không | 5 | 100 | Sổ tay mã hóa ngắn gọn, nhưng các lớp phức tạp về mặt kỹ thuật

2.2.3 Đánh giá
Chúng tôi thực hiện đánh giá ở hai mức độ chi tiết: (1) một nghiên cứu trường hợp chuyên sâu chứng minh các bước hình thành
của LACA trên bộ dữ liệu Trump Tweets (Phần 3.1), và (2) kết quả đánh giá tóm tắt trên tất cả bốn bộ dữ liệu
so sánh hiệu suất mã hóa của LLM và con người (Phần 3.2).

Kết quả nghiên cứu trường hợp được chia thành hai phần phụ để mô phỏng hai bước của LACA đòi hỏi sự tham gia và phản hồi
của nhà nghiên cứu. Phần đầu tiên là một đánh giá trên một mẫu ngẫu nhiên các tài liệu chưa được mã hóa được thiết kế để mô phỏng
việc đồng phát triển sổ tay mã hóa với LLM ("tập phát triển"). Phần thứ hai là một đánh giá trên cùng các tài liệu, nhưng
hiện tại với hai tập hợp mã con người, được thiết kế để mô phỏng việc so sánh các mã LLM và con người để đánh giá độ tin cậy ("tập
hiệu chuẩn"). Vì lý do ngắn gọn, chúng tôi chỉ báo cáo lý do mã hóa và bằng chứng định tính khác như một phần của nghiên cứu trường hợp. Thông tin chi tiết
về đánh giá tập phát triển (Phần 2.2.3.1) và đánh giá tập hiệu chuẩn (Phần 2.2.3.2) được
cung cấp dưới đây.

Kết quả đánh giá tóm tắt báo cáo thông tin tương tự như nghiên cứu trường hợp, nhưng ít chi tiết hơn để giúp làm nổi bật các xu hướng
trên bốn bộ dữ liệu. Tuy nhiên, kết quả định lượng chi tiết cho tất cả các bộ dữ liệu có sẵn trong Phụ lục C. Một
đánh giá bổ sung chỉ được thực hiện trong kết quả đánh giá tóm tắt là so sánh thời gian thực tế được
người mã hóa con người và LLM mất để mã hóa tài liệu. Thông tin thêm về các so sánh được thực hiện trong kết quả
đánh giá tóm tắt được cung cấp trong Phần 2.2.3.3.

2.2.3.1 Tập Phát triển
Tập phát triển bao gồm 100 tài liệu được rút ra ngẫu nhiên từ bộ dữ liệu Trump Tweets và mô phỏng việc sử dụng
các tài liệu chưa được mã hóa để phát triển và kiểm tra sổ tay mã hóa. Đối với tập hợp này, chúng tôi tạo ra các mã do mô hình tạo ra (với lý do
mã hóa) và tiến hành kiểm tra giả thuyết về tính ngẫu nhiên.

Các kiểm tra tính ngẫu nhiên cho nghiên cứu trường hợp sử dụng một kiểm tra nhị thức hai phía với xác suất thành công là 0,5 (α=
0,05). Các lý do mô hình được đánh giá định tính, tập trung chủ yếu vào các ví dụ mà mô hình bất đồng với
người mã hóa con người. Chúng tôi trình bày các ví dụ về cả lý do mô hình thuyết phục, cũng như các ví dụ về ảo giác
(các tuyên bố được đặt ra như sự thật bởi mô hình không thể được xác minh từ tài liệu nguồn [34]). Chúng tôi cũng sử dụng
lý do do mô hình tạo ra để cung cấp thêm hiểu biết về kết quả định lượng của chúng tôi.

2.2.3.2 Tập Hiệu chuẩn
Tập hiệu chuẩn sử dụng cùng 100 quan sát như tập phát triển nhưng hiện tại với hai tập hợp mã con người. Một
tập hợp là các mã được báo cáo trong các nghiên cứu gốc ("mã hóa gốc") và tập hợp khác là một tập hợp được mã hóa độc lập bởi
nhóm nghiên cứu của chúng tôi ("mã hóa nhân bản"). Điều này là để giúp mô phỏng quá trình mã hóa kép và cung cấp một điểm chuẩn con người
hữu ích hơn để so sánh với các mã do LLM tạo ra. Các chỉ số IRR được tính toán giữa các mã con người được xuất bản gốc
và nhân bản và giữa các mã được xuất bản gốc và do LLM tạo ra.

Gwet's AC1 [35] là chỉ số IRR ưa thích của chúng tôi vì nhiều mã hiếm và xuất hiện không thường xuyên trong mẫu hiệu chuẩn của chúng tôi.
Các chỉ số phổ biến khác, như Cohen's kappa [36], có thể gặp khó khăn trong những tình huống này do "nghịch lý thỏa thuận cao, độ tin cậy thấp"
[37,38,39], nơi có ít bất đồng tổng thể về cách các quan sát được mã hóa nhưng
những ít bất đồng xảy ra tạo ra sự chênh lệch lớn trong các giá trị IRR.

Định nghĩa của Gwet's AC1 như sau:
Gwet′s AC 1 =pa−peγ / 1−peγ(1)
nơi pa là phần trăm thỏa thuận tổng thể và peγ là xác suất thỏa thuận ngẫu nhiên. Các công thức tính toán của chúng được
định nghĩa là:
pa=1/n ∑(i=1 to n) ∑(q=1 to Q) riq(riq−1) / r(r−1)(2)
peγ=1/(Q−1) ∑(q=1 to Q) πq(1−πq) (3)
πq=1/n ∑(i=1 to n) riq / r(4)
nơi:
i=số tài liệu được đánh giá
q=số danh mục
riq=số người đánh giá phân loại tài liệu thứ i vào danh mục thứ q
r=tổng số người đánh giá
πp=xác suất một người đánh giá phân loại một tài liệu vào danh mục q

2.2.3.3 Đánh giá Tóm tắt
Kết quả đánh giá tóm tắt chứa cả kiểm tra tính ngẫu nhiên và chỉ số IRR trên tất cả bốn bộ dữ liệu. Giống như nghiên cứu trường hợp, chúng tôi
tạo ra một mẫu ngẫu nhiên 100 tài liệu cho mỗi bộ dữ liệu và so sánh các mã con người từ
dữ liệu được xuất bản với (1) các mã do LLM tạo ra và ("thỏa thuận người-mô hình") (2) những mã được mã hóa bởi nhóm nghiên cứu của chúng tôi ("thỏa thuận
người-người").

Chúng tôi sử dụng hai kiểm tra giả thuyết tính ngẫu nhiên khác nhau cho kết quả đánh giá tóm tắt, tùy thuộc vào cấu trúc
của nhiệm vụ mã hóa. Đối với kết quả nhị phân (Trump Tweets và Ukraine Water Problems), chúng tôi sử dụng một kiểm tra nhị thức hai phía
với xác suất thành công là 0,5, và đối với kết quả danh mục đa (BBC News và Contrarian Claims), chúng tôi sử dụng
một kiểm tra chi-bình phương với một phân phối đa thức tham chiếu của các xác suất bằng nhau. Đối với tất cả đánh giá, chúng tôi sử dụng
mức alpha 0,05. Đối với các chỉ số IRR, chúng tôi lại sử dụng Gwet's AC1.

Cuối cùng, chúng tôi tính toán lượng thời gian mà nhóm nghiên cứu của chúng tôi mất để mã hóa các mẫu và so sánh nó với thời gian
GPT-3.5 mất để tạo ra mã cho cùng các tài liệu.

3 Kết quả
3.1 Nghiên cứu Trường hợp: Trump Tweets
3.1.1 Kiểm tra Tính ngẫu nhiên (Tập Phát triển)
Bảng 2 báo cáo kết quả của các kiểm tra nhị thức tính ngẫu nhiên cho mỗi trong 13 mã trong bộ dữ liệu
Trump Tweets. Tất cả các kiểm tra đều có ý nghĩa với bốn ngoại lệ: HSTG (stat: 0,57, p-val: 0,193), ATSN (stat: 0,51, p-val: 0,920),

--- TRANG 7 ---
CAPT (stat: 0,48, p-val: 0,764), và INDV (stat: 0,57, p-val: 0,193). Điều này cho thấy rằng đối với bốn danh mục này,
mô hình có thể đang đoán ngẫu nhiên và không hiểu nhiệm vụ đủ tốt để tạo ra các mã hợp lệ. Ba trong số những
mã này liên quan đến cú pháp và định dạng của văn bản tweet, bao gồm việc sử dụng hashtag "#" (HSTG), dấu at "@" (ATSN), hoặc
sự hiện diện của các từ chỉ chứa chữ cái viết hoa (CAPT). Mã INDV liên quan đến việc tham chiếu một cá nhân
trong một tweet, được đặt tên hoặc không được đặt tên.

Bảng 2: Kiểm tra Tính ngẫu nhiên cho bộ dữ liệu Trump Tweets
Mã | Mã viết tắt | Mô tả mã2 | Tỷ lệ ước tính3 | P-value
HSTG | Sử dụng hashtag | 0,57 | 0,19
ATSN | Sử dụng @ | 0,51 | 0,92
CAPT | Chứa các từ chỉ có chữ cái viết hoa | 0,48 | 0,76
INDV | Tham chiếu một cá nhân | 0,57 | 0,19
CRIT | Chỉ trích người/ý tưởng khác | 0,30 | 0,00
MEDI | Đưa ra tuyên bố xúc phạm về truyền thông tin tức | 0,06 | 0,00
FAMY | Tham chiếu các thành viên gia đình trực tiếp của Donald Trump | 0,03 | 0,00
PLCE | Tham chiếu cảnh sát | 0,04 | 0,00
MAGA | Tham chiếu khẩu hiệu "Make America Great Again" | 0,06 | 0,00
MARG | Tham chiếu (các) nhóm bị thiệt thòi | 0,02 | 0,00
INTN | Tham chiếu các quốc gia/nhà lãnh đạo khác | 0,15 | 0,00
PRTY | Tham chiếu nhãn đảng phái/tư tưởng | 0,23 | 0,00
IMMG | Tham chiếu nhập cư | 0,08 | 0,00

3.1.2 Lý do cho Quyết định Mã hóa (Tập Phát triển)
Để cung cấp bối cảnh bổ sung và đánh giá tính hợp lệ bề mặt, Bảng 3 cung cấp các ví dụ về quyết định mã hóa của mô hình cho
các mã mẫu vượt qua hoặc thất bại trong các kiểm tra tính ngẫu nhiên. Đối với các mã trong bảng này vượt qua các kiểm tra
tính ngẫu nhiên (MAGA, INTN), các lý do được cung cấp phần lớn tuân theo các định nghĩa sổ tay mã hóa. Trong ví dụ MAGA,
mô hình nhận ra khẩu hiệu tranh cử tổng thống 2016 của Trump ("Make America Great Again"), trong khi trong
ví dụ INTN, mô hình xác định các tham chiếu đến các nhà lãnh đạo quốc tế bên ngoài Hoa Kỳ (Qatar) và rằng tweet
thảo luận về một vấn đề quốc tế (tài trợ tư tưởng cực đoan). Đối với các mã trong bảng này thất bại trong các kiểm tra tính ngẫu nhiên
(HSTG, CAPT), LLM cung cấp các lý do mâu thuẫn với các định nghĩa mã và/hoặc chứa ảo giác. Trong ví dụ HSTG,
mô hình ảo giác rằng từ "Lowest" chứa một hashtag. Trong ví dụ CAPT, mô hình không
nhận ra rằng một số từ trong tweet ("I LOVE YOU ALL") đều được viết hoa hoàn toàn.

2Xem Bảng 9 trong Phụ lục B để có mô tả mã chi tiết và sổ tay mã hóa.
3"Tỷ lệ ước tính" là tỷ lệ của tập phát triển nhận được mã này bởi LLM.

--- TRANG 8 ---
Bảng 3: Ví dụ Lý do Mã hóa LLM trên bộ dữ liệu Trump Tweets cho các mã vượt qua và thất bại trong Kiểm tra
Tính ngẫu nhiên
Tên mã | Vượt qua Kiểm tra Tính ngẫu nhiên | Văn bản | Mã hóa LLM | Lý do Mã hóa LLM
MAGA | Có | Vinh dự có Lãnh đạo Quốc hội Đảng Cộng hòa tham gia với tôi tại @WhiteHouse tối nay. Nhiều điều để thảo luận khi chúng tôi tiếp tục MAKING AMERICA GREAT AGAIN! https://t.co/b9z5NfdkcL | Có | Tweet rõ ràng đề cập "MAKING AMERICA GREAT AGAIN", đây là một tham chiếu trực tiếp đến khẩu hiệu tranh cử 2016 của Donald Trump. Do đó, mã phù hợp nhất là "Có".
INTN | Có | Trong chuyến đi gần đây của tôi đến Trung Đông, tôi đã tuyên bố rằng không thể còn tài trợ cho Tư tưởng Cực đoan nữa. Các nhà lãnh đạo chỉ đến Qatar - nhìn này! | Có | Tweet tham chiếu một quốc gia ngoài 50 bang Hoa Kỳ (Qatar) và thảo luận về một vấn đề quốc tế (tài trợ Tư tưởng Cực đoan). Do đó, nó thuộc mã tham chiếu các chủ đề quốc tế ngoài Hoa Kỳ.
HSTG | Không | Quá đúng Wayne và Tỷ lệ thất nghiệp người da đen thấp nhất trong lịch sử! https://t.co/gDxxJdZQUm | Có | Tweet bao gồm một hashtag (#Lowest) không phải là siêu liên kết, cho thấy việc sử dụng hashtag. Do đó, mã "Có" được áp dụng.
CAPT | Không | Xin lỗi những người muốn vào sân vận động đã đầy - I LOVE YOU ALL! https://t.co/PFvXrsvgkA | Không | Tweet này không chứa bất kỳ từ nào ở dạng viết hoa hoàn toàn, và bất kỳ việc viết hoa nào được sử dụng đều không nhằm nhấn mạnh. Ngoài ra, không có hashtag hoặc liên kết nào có trong tweet. Do đó, mã cho các từ viết hoa hoàn toàn không áp dụng cho tweet này.

3.1.3 Độ tin cậy Giữa các Người đánh giá (Tập Hiệu chuẩn)
Bảng 4 phác thảo kết quả IRR cho tập hiệu chuẩn Trump Tweets giữa (1) dữ liệu được mã hóa gốc và dữ liệu được mã hóa LLM ("thỏa thuận người-mô hình") và (2) dữ liệu được mã hóa gốc và mã hóa của nhóm nghiên cứu chúng tôi ("thỏa thuận người-người"). Gwet's AC1 cho thỏa thuận người-mô hình nhìn chung cao trên các mã (>0,76), ngoại trừ
các mã thất bại trong kiểm tra giả thuyết tính ngẫu nhiên (HSTG: 0,18; ATSN: 0,58; CAPT: 0,36; INDV: 0,50). Gwet's AC1 cho thỏa thuận người-người cũng nhìn chung cao (>0,73) và tương đương với thỏa thuận người-mô hình cho tất cả
các mã, ngoại trừ lại những mã thất bại trong kiểm tra tính ngẫu nhiên, trong đó thỏa thuận người-người cao hơn nhiều
(HSTG: 0,96; ATSN: 1,00; CAPT: 0,93; INDV: 0,79) so với thỏa thuận người-người.

--- TRANG 9 ---
Bảng 4: Thỏa thuận Người-Người và Người-Mô hình trên Bộ dữ liệu Trump Tweets
Mã | Gwet's AC1 Thỏa thuận Người-Người | Thỏa thuận Người-Mô hình
HSTG | 0,96 | 0,18
ATSN | 1,00 | 0,58
CRIT | 0,73 | 0,76
MEDI | 1,00 | 0,96
FAMY | 0,97 | 0,96
PLCE | 1,00 | 0,98
MAGA | 0,99 | 0,98
CAPT | 0,93 | 0,36
INDV | 0,79 | 0,5
MARG | 0,97 | 0,94
INTN | 0,86 | 0,81
PRTY | 0,81 | 0,76
IMMG | 0,99 | 0,97

3.1.4 Lý do cho Quyết định Mã hóa (Tập Hiệu chuẩn)
Lý do mã hóa cũng có thể được sử dụng trong giai đoạn hiệu chuẩn để tiếp tục tinh chỉnh sổ tay mã hóa và xác định các khu vực bất đồng
giữa mô hình và người mã hóa con người. Bảng 5 cung cấp các ví dụ lý do mã hóa mô hình mà người mã hóa con người
đồng ý nhưng các lý do cho thấy rằng mô hình không hiểu sổ tay mã hóa và/hoặc văn bản. Hai hàng đầu tiên (FAMY,
INDV) thể hiện mô hình quá tự do trong việc diễn giải sổ tay mã hóa. Trong ví dụ FAMY (một mã cho nếu
tweet đề cập đến bất kỳ thành viên gia đình trực tiếp nào của Donald Trump), mô hình mã hóa tweet là có liên quan
vì nó tham chiếu Bộ trưởng An ninh Nội địa Hoa Kỳ, Kirstjen Nielsen, một thành viên của "gia đình chính trị" của ông. Trong
ví dụ INDV (một mã cho nếu tweet đề cập đến một cá nhân, được đặt tên hoặc không được đặt tên), mô hình mã hóa tweet là
có liên quan vì nó diễn giải Đảng Dân chủ như được cấu thành từ "một nhóm cá nhân."

Ngược lại, hai hàng cuối (PLCE, IMMG) thể hiện mô hình quá nghiêm ngặt trong việc diễn giải sổ tay mã hóa.
Trong ví dụ PLCE (một mã cho nếu tweet đề cập đến cảnh sát), mô hình mã hóa tweet là không có liên quan
vì nó tham chiếu Lực lượng Tuần tra Đường cao tốc Florida, mà nó lý luận "là một nhánh cụ thể của cơ quan thực thi pháp luật
và không phải là một tham chiếu chung đến cảnh sát." Trong ví dụ IMMG (một mã cho nếu tweet tham chiếu nhập cư Hoa Kỳ), mô hình
mã hóa tweet là không áp dụng vì nó lý luận, "an ninh biên giới... không nhất thiết tương đương với
nhập cư," mặc dù nhập cư là một lý do chính đáng cho các biện pháp an ninh biên giới trong chiến dịch 2016 của Trump,
như xây dựng một bức tường ở biên giới phía nam Hoa Kỳ [40].

Tuy nhiên, lý do mã hóa LLM cũng có thể giúp xác định các khu vực hiểu nhầm cho người mã hóa con người. Bảng 6 cung cấp
các ví dụ về lý do mã hóa mô hình mà mô hình và một người mã hóa con người đồng ý, nhưng người kia thì không (PRTY,
FAMY), cũng như một ví dụ mà cả hai người mã hóa con người bất đồng với mô hình, nhưng lý luận mô hình có vẻ hợp lệ
(IMMG). Trong ví dụ PRTY (một mã cho nếu tweet đề cập đến một đảng chính trị Hoa Kỳ), mô hình và người mã hóa nhóm nghiên cứu đồng ý
mã nên áp dụng cho tweet vì nó đề cập đến DNC, một từ viết tắt cho Ủy ban Quốc gia Đảng Dân chủ. Trong ví dụ FAMY, mã gốc và mô hình đồng ý rằng mã nên áp dụng vì nó tham chiếu
Melania Trump, vợ của Donald Trump. Trong ví dụ IMMG cuối cùng, mặc dù không có người mã hóa con người nào tin rằng mã
nên áp dụng, mô hình cung cấp một lập luận thuyết phục cho việc đưa vào bằng cách tuyên bố rằng tweet bao gồm chương trình DACA
(Deferred Action for Childhood Arrivals), đây là một chính sách nhập cư Hoa Kỳ [41].

--- TRANG 10 ---
Bảng 5: Ví dụ Lý do Mã hóa LLM trên bộ dữ liệu Trump Tweets mà mô hình diễn giải quá lỏng lẻo (FAMY, INDV)
hoặc nghiêm ngặt (PLCE, IMMG) sổ tay mã hóa.
Tên mã | Văn bản | Mã hóa gốc | Mã hóa nhân bản | Mã hóa LLM | Lý do Mã hóa LLM
FAMY | An ninh Nội địa @SecNielsen đã làm một công việc tuyệt vời hôm qua tại cuộc họp báo giải thích an ninh ở biên giới và cho đất nước chúng ta trong khi đồng thời khuyến nghị những thay đổi đối với các luật lỗi thời & tệ hại buộc gia đình phải chia ly. Chúng ta muốn "trái tim" và an ninh ở Mỹ! | Không | Không | Có | Trong tweet này, Donald Trump tham chiếu Kirstjen Nielsen, người là Bộ trưởng An ninh Nội địa của ông. Điều này được tính là một tham chiếu gia đình, vì Nielsen là thành viên của chính quyền của ông và do đó được coi là một phần của "gia đình chính trị" của ông.
INDV | Chưa bao giờ thấy Đảng Cộng hòa thống nhất như vậy. Không "Đầu hàng" về vấn đề Biên giới và An ninh Quốc gia. Một điều đẹp để thấy đặc biệt khi bạn nghe những lời nói mới phun ra từ miệng của những người Dân chủ nói về Biên giới Mở Thuế Cao và Tội phạm. Ngăn chặn Tội phạm & Ma túy ngay bây giờ! | Không | Không | Có | Tweet tham chiếu Đảng Dân chủ, đây là một nhóm cá nhân, và cũng đề cập "những lời nói mới phun ra từ miệng của những người Dân chủ", chỉ ra rằng các cá nhân cụ thể trong đảng đang được tham chiếu. Ngoài ra, tweet đề cập "Tội phạm & Ma túy", có thể được diễn giải như một tham chiếu đến các cá nhân cụ thể liên quan đến hoạt động tội phạm. Do đó, tweet tham chiếu những người cá nhân và nên được mã hóa là "Có".
PLCE | Lực lượng Tuần tra Đường cao tốc Florida đều đang trên đường đến Panhandle từ khắp bang Florida - để giúp những người bị ảnh hưởng bởi #HurricaneMichael. Nếu bạn thấy họ hãy chắc chắn bắt tay họ và nói CẢM ƠN! #LESM https://t.co/rB7uNBudY5 | Có | Có | Không | Tweet không tham chiếu cảnh sát hoặc các sĩ quan cảnh sát cá nhân. Nó đề cập Lực lượng Tuần tra Đường cao tốc Florida, nhưng đây là một nhánh cụ thể của cơ quan thực thi pháp luật và không phải là một tham chiếu chung đến cảnh sát. Do đó, mã "Tweet này có tham chiếu cảnh sát không?" không áp dụng.
IMMG | Tôi đang ở Nhà Trắng làm việc chăm chỉ. Báo cáo tin tức về Shutdown và Syria hầu hết là GIẢ. Chúng tôi đang đàm phán với những người Dân chủ về An ninh Biên giới cần thiết tuyệt vọng (Băng đảng Ma túy Buôn bán Người & hơn thế nữa) nhưng có thể là một kỳ nghỉ dài. Về Syria chúng tôi ban đầu... | Có | Có | Không | Tweet không tham chiếu nhập cư hoặc bất kỳ chủ đề liên quan nào như bức tường, biên giới phía nam, ICE, chia ly gia đình, hoặc lệnh cấm du lịch. Trọng tâm là về đàm phán với những người Dân chủ về an ninh biên giới, nhưng điều này không nhất thiết tương đương với nhập cư. Do đó, mã phù hợp nhất là "Không."

--- TRANG 11 ---
Bảng 6: Ví dụ Lý do Mã hóa LLM trên bộ dữ liệu Trump Tweets mà mô hình tạo ra
lý do mã hợp lệ nhưng bất đồng với một người mã hóa con người (PRTY, FAMY) hoặc cả hai người mã hóa con người (IMMG).
Tên mã | Văn bản | Mã hóa gốc | Mã hóa nhân bản | Mã hóa LLM | Lý do Mã hóa LLM
PRTY | Mọi người ở đây đang nói về lý do tại sao John Podesta từ chối đưa máy chủ DNC cho FBI và CIA. Đáng xấu hổ! | Không | Có | Có | Tweet tham chiếu DNC (Ủy ban Quốc gia Đảng Dân chủ) đây là một đảng chính trị ở Hoa Kỳ. Do đó, nó thuộc danh mục "Tham chiếu đến Đảng Dân chủ hoặc Tự do" trong sổ tay mã hóa và nên được mã hóa là "Có".
FAMY | Tổng thống @EmmanuelMacron Cảm ơn bạn đã mời Melania và tôi đến một lễ kỷ niệm lịch sử như vậy ở Pháp. #BastilleDay #14juillet https://t.co/KZjJQOo0H1 | Có | Không | Có | Tweet bao gồm một tham chiếu đến Melania, người là thành viên gia đình trực tiếp của Donald Trump. Do đó, mã "Có" được áp dụng.
IMMG | Thẩm phán Liên bang ở Maryland vừa phán quyết rằng, "Tổng thống Trump có quyền kết thúc DACA". Tổng thống Obama đã có 8 năm để sửa chữa vấn đề này và không làm. Tôi đang đợi những người Dân chủ họ đang chạy lên đồi! | Không | Không | Có | Tweet này tham chiếu DACA, đây là một chương trình liên quan đến nhập cư ở Hoa Kỳ. Ngoài ra, Trump đề cập những người Dân chủ "chạy lên đồi," gợi ý rằng tweet này liên quan đến một cuộc tranh luận chính trị xung quanh chính sách nhập cư.

3.2 Kết quả Đánh giá Tóm tắt
Bảng 7 tóm tắt kết quả IRR và kiểm tra tính ngẫu nhiên trên tất cả bốn bộ dữ liệu. Các kiểm tra tính ngẫu nhiên vượt qua cho
tất cả các mã ngoại trừ những mã được xác định trước đó trong bộ dữ liệu Trump Tweets (HSTG, ATSN, CAPT, INDV) và cho hai
mã trong bộ dữ liệu Ukraine Water Problems (env problems, pollution). Sau khi xem xét lý luận mô hình cho các mã
thất bại trong bộ dữ liệu Ukraine Water Problems, lý do mô hình có vẻ phần lớn hợp lệ và dường như đang mã hóa
cho một số phiên bản của các khái niệm "vấn đề môi trường" và "ô nhiễm." Điều này cho thấy rằng các kiểm tra đang thất bại
chỉ vì tỷ lệ phổ biến của các quyết định mã hóa của mô hình gần 50% và không phải vì chúng đang đoán ngẫu nhiên.
Thú vị, hai mã trong bộ dữ liệu Ukraine Water Problems thất bại vẫn nằm trong số những mã có thỏa thuận người-người và người-mô hình thấp nhất
trên các bộ dữ liệu.

Tương đối, thỏa thuận người-mô hình cao hơn thỏa thuận người-người cho 3 trong 5 mã trong bộ dữ liệu Ukraine Water Problems và trên các mã cho bộ dữ liệu BBC News. Thỏa thuận người-mô hình thấp hơn
thỏa thuận người-người cho 2 trong 5 mã trong bộ dữ liệu Ukraine Water Problems và trên các mã cho
bộ dữ liệu Contrarian Claims. Phụ lục C chứa kết quả chi tiết và so sánh cho tất cả các bộ dữ liệu.

Bảng 8 mô tả so sánh thời gian mã hóa trên mỗi quan sát cho người mã hóa con người và GPT-3.5 để thực hiện
mã hóa suy diễn, được định nghĩa là số giây trên mỗi tài liệu cần để cung cấp một mã. Lưu ý rằng GPT-3.5 cũng
tạo ra lý do mô hình cho mỗi quyết định mã hóa như một phần của đầu ra của nó, điều này khác với người mã hóa con người chỉ
cung cấp một mã. Ngoài ra, các yêu cầu đến OpenAI API được thực hiện tuần tự trong thí nghiệm này, làm cho đánh giá này
bảo thủ hơn so với nếu được tối ưu hóa để chạy song song.

Trên các bộ dữ liệu, người mã hóa con người mất nhiều thời gian hơn GPT-3.5 để cung cấp mã, mặc dù có một số khác biệt tương đối
đáng chú ý. Sự chênh lệch lớn nhất về thời gian mã hóa đến từ bộ dữ liệu Contrarian Claims (con người: 144 giây/tài liệu;
LLM: 4 giây/tài liệu). Bộ dữ liệu này có văn bản dài hơn và nhiều danh mục mã hơn những bộ khác, làm cho nó trở thành nhiệm vụ mã hóa
gây gánh nặng nhất cho người mã hóa con người. Sự khác biệt này được phóng đại do các biện pháp loại trừ lẫn nhau
chỉ đòi hỏi một yêu cầu duy nhất đến GPT-3.5 để trả về quyết định mã hóa và lý do. Ngược lại, bộ dữ liệu Trump Tweets

--- TRANG 12 ---
Bảng 7: Kết quả Đánh giá Tóm tắt Trên các Bộ dữ liệu
Bộ dữ liệu | Mã | Gwet's AC1 | Kiểm tra Tính ngẫu nhiên
| | Người-Người | Người-Mô hình | (p-value)
Trump Tweets | HSTG | 0,96 | 0,18 | 0,19
Trump Tweets | ATSN | 1,00 | 0,58 | 0,92
Trump Tweets | CRIT | 0,73 | 0,76 | 0,00
Trump Tweets | MEDI | 1,00 | 0,96 | 0,00
Trump Tweets | FAMY | 0,97 | 0,96 | 0,00
Trump Tweets | PLCE | 1,00 | 0,98 | 0,00
Trump Tweets | MAGA | 0,99 | 0,98 | 0,00
Trump Tweets | CAPT | 0,93 | 0,36 | 0,76
Trump Tweets | INDV | 0,79 | 0,50 | 0,19
Trump Tweets | MARG | 0,97 | 0,94 | 0,00
Trump Tweets | INTN | 0,86 | 0,81 | 0,00
Trump Tweets | PRTY | 0,81 | 0,76 | 0,00
Trump Tweets | IMMG | 0,99 | 0,97 | 0,00
Ukraine Water | env_problems | 0,23 | 0,64 | 0,62
Ukraine Water | pollution | 0,59 | 0,55 | 0,62
Ukraine Water | treatment | 0,84 | 0,88 | 0,00
Ukraine Water | climate | 0,97 | 0,87 | 0,00
Ukraine Water | biomonitoring | 0,51 | 0,86 | 0,00
BBC News | All | 0,76 | 0,85 | 0,00
Contrarian Claims | All | 0,65 | 0,59 | 0,00

Bảng 8: Thời gian Mã hóa trên mỗi Tài liệu
Bộ dữ liệu | Thời gian Mã hóa (giây / tài liệu)
| Người mã hóa Con người | Người mã hóa LLM
Trump Tweets | 72 | 52
Ukraine Water | 108 | 16
BBC News | 72 | 4
Contrarian Claims | 144 | 4

có thời gian mã hóa gần nhất giữa người mã hóa con người (72 giây/tài liệu) và người mã hóa mô hình (52 giây/tài liệu). Điều này là vì
tweet ngắn và nhiệm vụ mã hóa ít tinh tế hơn, làm cho nó dễ dàng hơn cho người mã hóa con người để xem xét. GPT-3.5 mất
tương đối lâu hơn trong nhiệm vụ này vì chúng tôi đã thực hiện các yêu cầu riêng biệt cho mỗi trong 13 mã để đảm bảo rằng mô hình
tập trung vào từng mã riêng lẻ và sẽ có thể tạo ra một giải thích mô hình riêng biệt cho từng mã. Lựa chọn thiết kế này
được thực hiện vì các mã trong nhiệm vụ này không loại trừ lẫn nhau và mỗi mã có thể áp dụng cho bất kỳ tweet nào.

4 Thảo luận
Trong công việc này chúng tôi trình bày LACA, một cách tiếp cận toàn diện để tích hợp LLM vào mã hóa suy diễn. Chúng tôi chứng minh
phương pháp này với một nghiên cứu trường hợp chuyên sâu và một đánh giá thực nghiệm trên bốn bộ dữ liệu có sẵn công khai, so sánh cả
kết quả mã hóa và thời gian mã hóa giữa con người và một LLM thương mại.

Trên các bộ dữ liệu, các kiểm tra tính ngẫu nhiên giúp xác định các mã có sự bất đồng đáng kể giữa người-mô hình,
gợi ý rằng nó có thể giúp đánh giá ban đầu khi mô hình không hiểu biện pháp mà không
đòi hỏi dữ liệu được mã hóa bởi con người. Tuy nhiên, như thấy trong bộ dữ liệu Ukraine Water Problems, các kiểm tra cũng có thể thất bại trong việc từ chối
giả thuyết null nếu mô hình hoạt động tốt nhưng tỷ lệ cơ sở thực gần với xác suất bằng nhau. Vì lý do này,
việc kết hợp các kiểm tra với đánh giá thủ công các lý do mô hình là quan trọng để diễn giải đúng kết quả. Mặc dù
những người khác đã đánh giá LLM bằng cách so sánh đầu ra của chúng với cơ hội ngẫu nhiên [42,43], theo hiểu biết của chúng tôi, đây là
công việc đầu tiên chính thức hóa so sánh này với kiểm tra giả thuyết.

Bằng cách phân tích các mã thất bại trong kiểm tra tính ngẫu nhiên trong nghiên cứu trường hợp Trump Tweets (HSTG, ATSN, CAPT,
INDV), chúng tôi quan sát hai loại vấn đề có thể dẫn đến hiệu suất mã hóa mô hình kém. Tập hợp "mã định dạng"
(HSTG, ATSN, CAPT) có thể thất bại do các biến chứng được giới thiệu bởi bộ mã hóa byte-pair encoding (BPE) của GPT-3.5
[6]. Thay vì phân đoạn văn bản thành các từ, mã hóa BPE phân đoạn văn bản thành các từ, mảnh từ, hoặc ký tự
được chọn để tối thiểu hóa độ dài mã hóa trên corpus gốc của mô hình. Trong khi các từ nhỏ phổ biến có thể có
BPE riêng của chúng, các từ dài hơn hoặc hiếm có thể được mã hóa với một số BPE, với các từ hoàn toàn mới có khả năng được
mã hóa như sự kết hợp của các BPE chữ cái hoặc ký tự riêng lẻ. Vì các mô hình sử dụng kiến trúc GPT không mặc định
sử dụng biểu diễn ký tự, có thể khó khăn cho chúng để học các khía cạnh cấp độ ký tự của ngôn ngữ,
như độ dài từ [44] và sự hiện diện của các ký tự nhất định [45]. Những loại vấn đề mô hình này là vốn có của LLM
và không thể được giải quyết hoàn toàn với kỹ thuật gợi ý bổ sung; hiểu cách mô hình LLM cơ bản
được sử dụng cho LACA được thiết kế và huấn luyện là quan trọng để đánh giá những hạn chế này. Tuy nhiên, các khía cạnh cấp độ ký tự
của ngôn ngữ thường có giá trị hạn chế đối với các nhà khoa học xã hội và có thể được xác định nếu cần sử dụng các phương pháp đơn giản hơn
với độ chính xác cao (ví dụ, biểu thức chính quy). Không giống như các mã định dạng, mã INDV có vẻ thất bại trong một số
trường hợp vì mô hình gán bất kỳ đề cập nào về một nhóm cho mã này, vì nó lý luận rằng một nhóm bao gồm
một số cá nhân. Chúng tôi coi đây là một vấn đề sổ tay mã hóa có cơ hội cao hơn được giải quyết thông qua làm rõ sổ tay mã hóa
và kỹ thuật gợi ý.

Về mặt định tính, chúng tôi thấy rằng việc tạo ra lý do mô hình cho các quyết định mã hóa giúp người mã hóa con người đánh giá hiệu suất mô hình,
chất lượng gợi ý và xây dựng niềm tin vào các dự đoán. Các ví dụ trong phần Kết quả chứng minh lý do do mô hình tạo ra
giúp xác định ảo giác và lỗi lý luận và gợi ý cách mà sổ tay mã hóa có thể được
sửa đổi để cải thiện hiệu suất. Ngoài ra, chúng tôi thấy rằng lý do do mô hình tạo ra có thể giúp người mã hóa con người suy ngẫm về
các quyết định mã hóa của chính họ, điều này có thể thông báo cho việc sửa đổi định nghĩa biện pháp. Theo kinh nghiệm, chúng tôi thấy rằng
quá trình làm cho sổ tay mã hóa rõ ràng hơn cho mô hình cũng có xu hướng giúp cải thiện khả năng đọc và hiểu hướng dẫn
cho người mã hóa con người. Phát hiện này có thể ít mạnh mẽ hơn nếu sử dụng LLM không trải qua cùng mức độ
tinh chỉnh mà dòng mô hình GPT-3.5 đã nhận được, nơi kỹ thuật gợi ý bắt chước dự đoán token tiếp theo gần hơn có thể được yêu cầu [46].

Trên tất cả các bộ dữ liệu, kết quả IRR cho thấy rằng đối với nhiều trường hợp, GPT-3.5 mã hóa ở mức độ thỏa thuận tương đương
với người mã hóa con người. Trong các trường hợp mà mô hình hoạt động kém hơn nhiều so với người mã hóa con người, những trường hợp này thường có thể được phát hiện sớm
với các kiểm tra giả thuyết tính ngẫu nhiên. Phát hiện này phần lớn đồng ý với nghiên cứu trước đó về khả năng của LLM tạo ra
chú thích cho các nhiệm vụ NLP, gợi ý rằng GPT-3.5 hoặc GPT-4 đáp ứng hoặc vượt qua hiệu suất của người lao động đám đông
[17], và trong một số trường hợp, cũng vượt qua các chuyên gia [18]. Thú vị, kết quả của chúng tôi cho thấy kết quả LLM hứa hẹn hơn so với
công việc trước đó sử dụng LLM cho mã hóa suy diễn [19], mặc dù khó khăn để rút ra kết luận mạnh mẽ dựa trên
sự khác biệt trong chiến lược gợi ý, bộ dữ liệu, chỉ số và nhiệm vụ mã hóa định tính. Một giả thuyết cho khoảng cách dường như
lớn hơn về hiệu suất giữa con người và LLM trong [19] là thỏa thuận người-người của họ dựa trên
mã hóa kép của nhiều chuyên gia đã phát triển sổ tay mã hóa gốc. Điều này trái ngược với thỏa thuận người-người tập trung nhân bản của chúng tôi, so sánh mã hóa trong các nghiên cứu gốc với một mã hóa độc lập chỉ sử dụng
các sổ tay mã hóa đã xuất bản để rút ra định nghĩa và ý nghĩa biện pháp. Ngoài ra, người mã hóa của chúng tôi không có kiến thức chuyên môn hoặc chuyên môn
trong các lĩnh vực của các nhiệm vụ mã hóa được sử dụng trong nghiên cứu này, điều này có thể giải thích cho một số giá trị IRR người-người thấp hơn
được quan sát trong các bộ dữ liệu kỹ thuật hơn (Contrarian Claims và Ukraine Water Problems).
Chúng tôi hy vọng rằng bằng cách sử dụng các bộ dữ liệu có sẵn công khai, nghiên cứu tương lai có thể xây dựng dựa trên công việc này và giúp cải thiện việc sử dụng
LLM cho mã hóa suy diễn.

Nhìn chung, chúng tôi tin rằng các phát hiện của chúng tôi có một số ý nghĩa cho thực hành tương lai của mã hóa suy diễn và các phương pháp nghiên cứu liên quan.
Đầu tiên, dựa trên thời gian mã hóa giảm và, trong nhiều trường hợp, kết quả tương đương với người mã hóa con người,
chúng tôi tin rằng LACA và LLM nói chung có thể là một phương pháp hiệu quả cho mã hóa suy diễn. Tuy nhiên, bất chấp
những ý nghĩa này, chúng tôi không coi LACA như một sự thay thế cho các nhà nghiên cứu định tính, mà thay vào đó, một công cụ để hỗ trợ
tăng tốc các giai đoạn sau của mã hóa suy diễn có xu hướng gây gánh nặng thủ công hơn và ít thỏa mãn hơn cho các nhà nghiên cứu.
Thứ hai, việc áp dụng LLM trong mã hóa suy diễn có thể sẽ đòi hỏi các loại báo cáo và tài liệu khác nhau để
cho phép tái tạo hiệu quả và phê bình. Ngoài sổ tay mã hóa và báo cáo các chỉ số IRR, các nhà nghiên cứu
sử dụng LLM cho mã hóa suy diễn cũng nên bao gồm gợi ý và chi tiết mô hình bất cứ khi nào có thể. Giả định
văn bản bản thân cũng không nhạy cảm về bản chất, cung cấp văn bản tài liệu, bất kỳ mã do con người hoặc mô hình tạo ra, và lý do
do mô hình tạo ra cũng sẽ giúp các nhà nghiên cứu khác đánh giá tính hợp lệ và độ tin cậy của kết quả mô hình. Điều này đặc biệt
quan trọng do tính chất ngẫu nhiên của LLM sinh tạo có thể làm cho việc tái tạo chính xác cùng
đầu ra mô hình trong các lần chạy tương lai trở nên khó khăn. Để thúc đẩy tiêu chuẩn báo cáo này, chúng tôi cung cấp các gợi ý, sổ tay mã hóa và chi tiết mô hình
trong Phương pháp và Phụ lục và làm cho các bộ dữ liệu được mã hóa và lý do mô hình cho tập hiệu chuẩn có sẵn công khai
trực tuyến [47]. Cuối cùng, mặc dù công việc này tập trung vào mã hóa suy diễn, chúng tôi tin rằng cách tiếp cận cũng có ý nghĩa cho
tài liệu LLM cho chú thích đang nổi lên [48,17,18,21]. Đặc biệt, chúng tôi dự đoán các thành phần của LACA không
đòi hỏi dữ liệu được gán nhãn trước (kiểm tra tính ngẫu nhiên và lý do do mô hình tạo ra) sẽ đặc biệt hữu ích cho các nhà nghiên cứu
nhằm tạo ra dữ liệu được gán nhãn LLM.

Công việc của chúng tôi trình bày một số hạn chế và cơ hội cho công việc tương lai. Đầu tiên, để phù hợp với đầu ra trong
các bộ dữ liệu gốc, chúng tôi buộc mô hình phải chọn Có/Không hoặc chọn một mã duy nhất từ một tập hợp các danh mục mã
loại trừ lẫn nhau. Tuy nhiên, đôi khi mô hình sẽ trả về kết quả cho thấy rằng các nhiệm vụ mã hóa không áp dụng
hoặc không có đủ thông tin để mã hóa tài liệu. Hiện tượng này đã được ghi nhận trong công việc trước đó
sử dụng dòng mô hình GPT-3.5 [21] và có khả năng là một cơ chế định lượng độ không chắc chắn hữu ích có thể
được tích hợp tốt hơn vào LACA (ví dụ, bằng cách cho phép mô hình trả về "Có", "Không", hoặc "Tôi Không Biết", cùng với
lý luận của họ cho quyết định). Thứ hai, vì mục tiêu của công việc này là cung cấp một cách tiếp cận toàn diện để thực hiện
mã hóa suy diễn với LLM, thay vì tập trung chủ yếu vào mức độ hiệu quả của LLM có thể thực hiện mã hóa suy diễn, chúng tôi
không thực hiện kỹ thuật gợi ý rộng rãi, cũng như không đánh giá hiệu suất mã hóa qua nhiều loại LLM khác nhau.
Cho rằng tốc độ mà cả LLM và các kỹ thuật gợi ý đang phát triển, chúng tôi dự đoán công việc tương lai sẽ cải thiện đáng kể
hiệu suất LLM thực nghiệm được báo cáo ở đây. Cuối cùng, một hạn chế chính của việc sử dụng cách tiếp cận này cũng là
một trong những lợi ích dự kiến; các nhà nghiên cứu sử dụng LACA sẽ không thể tránh khỏi việc đọc ít tài liệu hơn, điều này trong
một số trường hợp, có thể hạn chế việc phát triển lý thuyết mới và khám phá các chủ đề không được đề xuất bởi nhóm nghiên cứu a priori.
Chúng tôi dự đoán rằng công việc tương lai sử dụng LLM để hỗ trợ mã hóa quy nạp [49] có thể là một cách tiếp cận hứa hẹn để giúp giải quyết
những vấn đề này.

5 Tính sẵn có của dữ liệu và tài liệu
Tất cả các bộ dữ liệu được sử dụng trong bài báo này đều có sẵn công khai và các nguồn được cung cấp trong bản thảo chính. Dữ liệu được mã hóa bổ sung
có sẵn trong [47].

Lợi ích Cạnh tranh
Các tác giả tuyên bố rằng họ không có lợi ích cạnh tranh.

Tài trợ
Công việc này chỉ được tài trợ bởi RTI International.

Đóng góp của Tác giả
RC và AK thiết kế nghiên cứu và đảm bảo tài trợ. JB, MW và RC phát triển gợi ý, chạy phân tích và cung cấp
quản lý dữ liệu. JS điều phối mã hóa định tính và mã hóa tài liệu. RC dẫn đầu việc viết, với đóng góp từ
JB, MW, JS và AK. Tất cả tác giả đã phê duyệt bản thảo cuối cùng.

Lời cảm ơn
Chúng tôi muốn cảm ơn Courtney Richardson và Larisa Albers vì những đóng góp mã hóa của họ và Peter
Baumgartner vì phản hồi của ông.

Tài liệu tham khảo
[1]Văn phòng Trách nhiệm Chính phủ Hoa Kỳ: Bộ phận Đánh giá Chương trình và Phương pháp luận. Phân tích nội dung: Một
phương pháp luận để cấu trúc và phân tích tài liệu viết, 1996. Số tiếp cận: GAOREPORTS-PEMD-
10-3-1 Nguồn: DGPO.
[2]Mai Skjott Linneberg và Steffen Korsgaard. Mã hóa dữ liệu định tính: Một tổng hợp hướng dẫn người mới bắt đầu. Tạp chí nghiên cứu định tính
, 19(3):259–270, 2019.
[3]Anselm L. Strauss. Phân tích định tính cho các nhà khoa học xã hội. Phân tích định tính cho các nhà khoa học xã hội. Cambridge
University Press, 1987.
[4] Kimberly A. Neuendorf. Sổ tay Hướng dẫn Phân tích Nội dung. SAGE Publications, Inc, 2017.

--- TRANG 15 ---
[5]Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai,
và Quoc V Le. Các mô hình ngôn ngữ được tinh chỉnh là những người học zero-shot. arXiv preprint arXiv:2109.01652, 2021.
[6]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-
lakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger,
Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark
Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, và Dario Amodei. Các mô hình ngôn ngữ là những người học few-shot. Trong Advances in Neural
Information Processing Systems, tập 33, trang 1877–1901, 2020.
[7]Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang,
Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. Đánh giá toàn diện các mô hình ngôn ngữ. arXiv preprint
arXiv:2211.09110, 2022.
[8] OpenAI. Báo cáo kỹ thuật GPT-4. arXiv, 2023.
[9] Robert Philip Weber. Phân tích nội dung hỗ trợ máy tính: Một mồi ngắn. Qualitative Sociology, 7(1):126, 1984.
[10] Carl W Roberts. Phân tích văn bản cho khoa học xã hội: phương pháp để rút ra suy luận thống kê từ văn bản và
bản ghi. Routledge, 2020.
[11] Philip J. Stone, Dexter C. Dunphy, và Marshall S. Smith. Người điều tra chung: Một cách tiếp cận máy tính đến phân tích nội dung
. Người điều tra chung: Một cách tiếp cận máy tính đến phân tích nội dung. M.I.T. Press, 1966.
[12] Tim Loughran và Bill Mcdonald. Khi nào một khoản nợ không phải là một khoản nợ? phân tích văn bản, từ điển và 10-ks. The
Journal of Finance, 66(1):35–65, 2011.
[13] Michael Scharkow. Phân tích nội dung chủ đề sử dụng học máy có giám sát: Một đánh giá thực nghiệm sử dụng
tin tức trực tuyến Đức. Quality & Quantity, 47(2):761–773, 2013.
[14] Michael Evans, Wayne McIntosh, Jimmy Lin, và Cynthia Cates. Kể lại các tòa án? áp dụng phân tích nội dung tự động
để nâng cao nghiên cứu pháp lý thực nghiệm. Journal of Empirical Legal Studies, 4(4):1007–1039, 2007.
[15] Peter Baumgartner, Amanda Smith, Murrey Olmsted, và Dawn Ohse. Một khung để sử dụng học máy
để hỗ trợ mã hóa dữ liệu định tính. OSF Preprints, 2021.
[16] Nan-chen Chen, Rafal Kocielnik, Margaret Drouhard, Vanessa Peña-Araya, Jina Suh, Keting Cen, Xiangyi Zheng,
và Cecilia R Aragon. Thách thức của việc áp dụng học máy cho mã hóa định tính. Trong ACM SIGCHI Workshop
on Human-Centered Machine Learning, 2016.
[17] Fabrizio Gilardi, Meysam Alizadeh, và Maël Kubli. Chatgpt vượt trội hơn người lao động đám đông cho các nhiệm vụ chú thích văn bản
. arXiv preprint arXiv:2303.15056, 2023.
[18] Petter Törnberg. Chatgpt-4 vượt trội hơn chuyên gia và người lao động đám đông trong việc chú thích tin nhắn twitter chính trị với
học zero-shot. arXiv preprint arXiv:2304.06588, 2023.
[19] Ziang Xiao, Xingdi Yuan, Q. Vera Liao, Rania Abdelghani, và Pierre-Yves Oudeyer. Hỗ trợ phân tích định tính
với các mô hình ngôn ngữ lớn: Kết hợp sổ tay mã hóa với GPT-3 cho mã hóa suy diễn. Trong 28th International
Conference on Intelligent User Interfaces, trang 75–78. ACM, 2023.
[20] Mai ElSherief, Caleb Ziems, David Muchlinski, Vaishnavi Anupindi, Jordyn Seybolt, Munmun De Choudhury,
và Diyi Yang. Hận thù tiềm ẩn: Một điểm chuẩn để hiểu lời nói thù hận ngầm.
[21] Yiming Zhu, Peixian Zhang, Ehsan-Ul Haq, Pan Hui, và Gareth Tyson. Chatgpt có thể tái tạo các nhãn do con người tạo ra không?
một nghiên cứu về các nhiệm vụ tính toán xã hội. arXiv preprint arXiv:2304.10145, 2023.
[22] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. Gợi ý chuỗi
suy nghĩ kích thích lý luận trong các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2201.11903, 2022.
[23] OpenAI. Giới thiệu ChatGPT, 2022. www.openai.com/blog/chatgpt.
[24] Yiqiu Shen, Laura Heacock, Jonathan Elias, Keith D. Hentel, Beatriu Reig, George Shih, và Linda Moy. ChatGPT
và các mô hình ngôn ngữ lớn khác là những thanh kiếm hai lưỡi. Radiology, 307(2):e230163, 2023.
[25] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Huấn luyện các mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi
của con người. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.
[26] Sander Schulhoff và Community Contributors. Learn Prompting, tháng 12 năm 2022. www.learnprompting.org.
[27] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, và Zhifang Sui.
Một khảo sát về học trong bối cảnh. arXiv preprint arXiv:2301.00234, 2022.
[28] Brendan Brown. Kho lưu trữ twitter Trump. www.thetrumparchive.com.

--- TRANG 16 ---
[29] Kevin Coe và Rachel Alicia Griffin. Kêu gọi bản sắc bị thiệt thòi trực tuyến: Trường hợp tổng thống donald trump
trên twitter. Social Media+ Society, 6(1):2056305120913979, 2020.
[30] Travis G. Coan, Constantine Boussalis, John Cook, và Mirjam O. Nanko. Phân loại hỗ trợ máy tính
các tuyên bố trái chiều về biến đổi khí hậu. Scientific Reports, 11(1):22320, 2021.
[31] Sự hoài nghi về sự nóng lên toàn cầu và biến đổi khí hậu được kiểm tra. https://skepticalscience.com/.
[32] Derek Greene và Pádraig Cunningham. Giải pháp thực tế cho vấn đề thống trị đường chéo trong phân cụm tài liệu kernel
. Trong Proceedings of the 23rd international conference on Machine learning, ICML '06, trang
377–384. Association for Computing Machinery, 2006.
[33] Sergey Afanasyev, Bedz N., Tetiana Bodnarchuk, Vasyliev S., Viktorov M., Vlasova T., V oytyuk Yu, Gayduk K.,
Dmytryshyna V ., Oksana Konovalenko, Korzshyk O., Kryzanivsky E., Olena Lietytska, Lysyuk O., Manivchuk V .,
Olena Marushevska, Vitalii Mokin, Mudra K., Natalia Osadcha, và Iarochevitch O. Kế hoạch Quản lý Lưu vực Sông
cho Pivdenny Bug: phân tích lưu vực sông và các biện pháp. 2013.
[34] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji,
Tiezheng Yu, Willy Chung, et al. Một đánh giá đa nhiệm vụ, đa ngôn ngữ, đa phương thức của chatgpt về lý luận,
ảo giác và tương tác. arXiv preprint arXiv:2302.04023, 2023.
[35] Kilem Li Gwet. Tính toán độ tin cậy giữa các người đánh giá và phương sai của nó trong sự hiện diện của thỏa thuận cao. British
Journal of Mathematical and Statistical Psychology, 61(1):29–48, 2008.
[36] Jacob Cohen. Một hệ số thỏa thuận cho các thang đo danh nghĩa. Educational and psychological measurement,
20(1):37–46, 1960.
[37] Rosa Falotico và Piero Quatto. Thống kê kappa của Fleiss không có nghịch lý. Quality & Quantity, 49:463–470, 2015.
[38] Guangchao Charles Feng. Những sai lầm và cách tránh sai lầm trong việc sử dụng các chỉ số độ tin cậy intercoder. Methodology,
2015.
[39] Xinshu Zhao, Jun S Liu, và Ke Deng. Các giả định đằng sau các chỉ số độ tin cậy intercoder. Annals of the
International Communication Association, 36(1):419–480, 2013.
[40] Timothy B. Gravelle. Chính trị, thời gian, không gian và thái độ đối với an ninh biên giới Hoa Kỳ–mexico. Political Geography,
65:107–116, 2018.
[41] Kevin R Johnson. Bài học về tương lai của luật nhập cư từ sự trỗi dậy và sụp đổ của daca. Immigr. & Nat'lity
L. Rev., 39:265, 2018.
[42] Laura Ruis, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rocktäschel, và Edward Grefenstette. Các
mô hình ngôn ngữ lớn không phải là những người giao tiếp zero-shot. arXiv preprint arXiv:2210.14986, 2022.
[43] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten
Bosma, Denny Zhou, Donald Metzler, et al. Khả năng nổi lên của các mô hình ngôn ngữ lớn. arXiv preprint
arXiv:2206.07682, 2022.
[44] Avia Efrat, Or Honovich, và Omer Levy. Lmentry: Một điểm chuẩn mô hình ngôn ngữ của các nhiệm vụ ngôn ngữ cơ bản.
arXiv preprint arXiv:2211.02069, 2022.
[45] Reece Rogers. AGI là gì, và tại sao các chuyên gia AI hoài nghi? Wired, 2023.
[46] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, và Graham Neubig. Pre-train, prompt,
và predict: Một khảo sát có hệ thống về các phương pháp gợi ý trong xử lý ngôn ngữ tự nhiên. ACM Computing Surveys,
55(9):1–35, 2023.
[47] Robert Chew, Michael Wenger, John Bollenbacher, Jessica Speer, và Annice Kim. Phân tích nội dung hỗ trợ LLM
(LACA): Dữ liệu được mã hóa và lý do mô hình. Publisher: Figshare. 10.6084/m9.figshare.23291147.
[48] Bosheng Ding, Chengwei Qin, Linlin Liu, Lidong Bing, Shafiq Joty, và Boyang Li. Gpt-3 có phải là một người chú thích dữ liệu tốt không?
arXiv preprint arXiv:2212.10450, 2022.
[49] Jie Gao, Yuchen Guo, Gionnieve Lim, Tianqin Zhan, Zheng Zhang, Toby Jia-Jun Li, và Simon Tangi Perrault.
Collabcoder: Một quy trình làm việc được hỗ trợ bởi GPT cho phân tích định tính hợp tác. arXiv preprint arXiv:2304.07366,
2023.

--- TRANG 17 ---
A Gợi ý
Hình 2 đến Hình 5 mô tả các gợi ý được sử dụng cho mỗi bộ dữ liệu. Khối {code} chỉ ra nơi văn bản sổ tay mã hóa
được nhập vào (xem Phần B cho sổ tay mã hóa) và khối {text} chỉ ra nơi văn bản cho mỗi tài liệu được nhập vào.
Các tham chiếu "Codebook" và "Tweet"/"Text" đầu tiên được bao gồm để giúp mô hình học định dạng đầu vào mong đợi và
tham chiếu "Code" đầu tiên là để chỉ định các danh mục đầu ra có sẵn cho mô hình sử dụng.

Hình 2: Gợi ý Trump Tweets
Bạn là một người mã hóa định tính đang chú thích các tweet từ nguồn cấp Twitter của Donald Trump.
Để mã hóa tweet này, hãy làm như sau:
- Đầu tiên, đọc sổ tay mã hóa và tweet.
- Tiếp theo, quyết định mã nào phù hợp nhất và giải thích lý do của bạn cho quyết định mã hóa.
- Cuối cùng, in mã phù hợp nhất và lý do của bạn cho quyết định mã hóa.
Sử dụng định dạng sau:
Sổ tay mã hóa:
---
sổ tay mã hóa ở đây
---
Tweet:
---
tweet ở đây
---
Mã:
---
Có hoặc Không
---
Sổ tay mã hóa:
---
{code}
---
Tweet:
---
{text}
---
Mã:

--- TRANG 18 ---
Hình 3: Gợi ý BBC News
Bạn là một người mã hóa định tính đang chú thích các tweet từ câu chuyện tin tức từ BBC.
Để mã hóa văn bản này, hãy làm như sau:
- Đầu tiên, đọc sổ tay mã hóa và văn bản.
- Tiếp theo, quyết định mã nào phù hợp nhất và giải thích lý do của bạn cho quyết định mã hóa.
- Cuối cùng, in mã phù hợp nhất và lý do của bạn cho quyết định mã hóa.
Sử dụng định dạng sau:
Sổ tay mã hóa:
---
sổ tay mã hóa ở đây
---
Văn bản:
---
văn bản ở đây
---
Mã:
---
kinh doanh, giải trí, chính trị, thể thao, hoặc công nghệ
---
Sổ tay mã hóa:
---
code
---
Văn bản:
---
text
---
Mã:

--- TRANG 19 ---
Hình 4: Gợi ý Ukraine Water Problems
Bạn là một người mã hóa định tính đang chú thích các báo cáo chất lượng nước.
Để mã hóa văn bản này, hãy làm như sau:
- Đầu tiên, đọc sổ tay mã hóa và văn bản.
- Tiếp theo, quyết định mã nào phù hợp nhất và giải thích lý do của bạn cho quyết định mã hóa.
- Cuối cùng, in mã phù hợp nhất và lý do của bạn cho quyết định mã hóa.
Sử dụng định dạng sau:
Sổ tay mã hóa:
---
sổ tay mã hóa ở đây
---
Văn bản:
---
văn bản ở đây
---
Mã:
---
Có hoặc Không
---
Sổ tay mã hóa:
---
code
---
Văn bản:
---
text
---
Mã:

--- TRANG 20 ---
Hình 5: Gợi ý Contrarian Claims
Bạn là một người mã hóa định tính đang chú thích các bài blog bảo thủ liên quan đến biến đổi khí hậu.
Để mã hóa văn bản này, hãy làm như sau:
- Đầu tiên, đọc sổ tay mã hóa và văn bản.
- Tiếp theo, quyết định mã nào phù hợp nhất và giải thích lý do của bạn cho quyết định mã hóa.
- Cuối cùng, in mã phù hợp nhất và lý do của bạn cho quyết định mã hóa.
Sử dụng định dạng sau:
Sổ tay mã hóa:
---
sổ tay mã hóa ở đây
---
Văn bản:
---
văn bản ở đây
---
Mã:
---
1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 2.1, 2.2, 2.3, 2.4, 2.5, 3.1, 3.2, 3.3, 3.4,
3.5, 3.6, 4.1, 4.2, 4.3, 4.4, 4.5, 5.1, 5.2, 5.3, hoặc 0.0
---
Sổ tay mã hóa:
---
code
---
Văn bản:
---
text
---
Mã:

--- TRANG 21 ---
B Sổ tay Mã hóa
Bảng 9: Sổ tay Mã hóa Trump Tweets
Tên mã | Mô tả mã gốc | Mô tả mã đã sửa đổi
HSTG | Hashtag được sử dụng? Loại trừ liên kết khỏi quyết định này. | Hashtag có được sử dụng trong tweet này không? Loại trừ siêu liên kết khỏi quyết định này.
ATSN | @ được sử dụng? Bao gồm @ có trong retweets. Loại trừ liên kết khỏi quyết định này. | Dấu at ("@") có được sử dụng trong tweet này không? Bao gồm "@" có trong retweets. Loại trừ siêu liên kết khỏi quyết định này.
CRIT | Chỉ trích người/ý tưởng khác (không phải của anh ấy)? Nếu anh ấy gợi ý ở bất kỳ điểm nào trong tweet rằng một người hoặc một thực thể nào đó đã làm điều gì đó sai, mã hóa có. ví dụ "Đó không phải là Thương mại Tự do hay Công bằng mà là Thương mại Ngu ngốc!" | Donald Trump có chỉ trích một người hoặc ý tưởng khác trong tweet này không? Nếu tác giả gợi ý ở bất kỳ điểm nào trong tweet rằng một người hoặc thực thể nào đó đã làm điều gì đó sai, mã hóa 'Có'. Ví dụ "Đó không phải là Thương mại Tự do hay Công bằng mà là Thương mại Ngu ngốc!"
MEDI | Tuyên bố xúc phạm/khinh thường về truyền thông tin tức? Các nhà báo cá nhân được nói về theo những thuật ngữ này là có. Tham chiếu đến truyền thông xã hội như một thực thể chung được mã hóa "không". Tham chiếu đến tài khoản truyền thông xã hội của truyền thông tin tức cụ thể là "có". | Donald Trump có đưa ra tuyên bố xúc phạm hoặc khinh thường về truyền thông tin tức trong tweet này không? Bao gồm các tuyên bố được đưa ra về các nhà báo cá nhân. Tham chiếu đến truyền thông xã hội như một thực thể chung được mã hóa "Không". Tham chiếu đến tài khoản truyền thông xã hội của truyền thông tin tức cụ thể là "Có".
FAMY | Tham chiếu các thành viên gia đình trực tiếp của anh ấy? Một tham chiếu gia đình đến một cá nhân cũng sẽ là có cho INDV. Đừng tính tham chiếu bản thân Trump là gia đình; phải là ai đó khác ngoài anh ấy. | Donald Trump có tham chiếu các thành viên gia đình trực tiếp của anh ấy trong tweet này không? Một tham chiếu gia đình đến một cá nhân nên được mã hóa "Có". Đừng tính tham chiếu bản thân của Donald Trump là gia đình; anh ấy phải tham chiếu ai đó khác ngoài bản thân.
PLCE | Tham chiếu cảnh sát? Danh mục này chỉ nắm bắt các tham chiếu đến cảnh sát hoặc các sĩ quan cảnh sát cá nhân, không phải đến các vấn đề rộng hơn về tội phạm, v.v. | Tweet này có tham chiếu cảnh sát không? Danh mục này chỉ nắm bắt các tham chiếu đến cảnh sát hoặc các sĩ quan cảnh sát cá nhân, không phải đến các vấn đề rộng hơn về tội phạm, tư pháp hình sự, v.v.
MAGA | Tham chiếu đến khẩu hiệu chiến dịch này? Chỉ tính các hình thức của khẩu hiệu, như "MAGA" hoặc "Make America Great Again". Tham chiếu chung đến Mỹ và sự vĩ đại không đủ một mình. | Tweet này có tham chiếu khẩu hiệu chiến dịch 2016 của Donald Trump không? Chỉ tính các hình thức của khẩu hiệu, như "MAGA" hoặc "Make America Great Again". Tham chiếu chung đến Mỹ và sự vĩ đại nên được mã hóa là "Không".
CAPT | Chữ cái viết hoa được sử dụng? Bất kỳ việc sử dụng chữ cái viết hoa nào để chỉ định sự nhấn mạnh; ít nhất một từ đầy đủ viết hoa phải có để có mã có. Từ viết tắt không tạo ra mã có một mình. Loại trừ hashtag và liên kết khỏi quyết định này (bao gồm hashtag không phải từ viết tắt; Ví dụ #CHANGETHELAWS). | Có từ nào chỉ chứa chữ cái viết hoa trong tweet này không? Bất kỳ việc sử dụng chữ cái viết hoa nào để chỉ định sự nhấn mạnh nên được xem xét. Ít nhất một từ đầy đủ viết hoa phải có. Từ viết tắt không tạo ra mã "Có" một mình. Loại trừ hashtag và liên kết khỏi quyết định này (bao gồm hashtag không phải từ viết tắt; Ví dụ #CHANGETHELAWS).

--- TRANG 22 ---
INDV | Tham chiếu một cá nhân? Loại trừ tham chiếu bản thân. Tên của bất kỳ người nào là có (ngay cả khi trong nhóm, như Chính quyền Obama); các cá nhân không được nêu tên là có, miễn là rõ ràng một người duy nhất đang được gọi ra. Những người được gắn thẻ với @ tính là 1, nhưng @ không cần thiết để mã hóa 1. | Tweet này có tham chiếu một cá nhân không? Loại trừ tham chiếu bản thân đến Donald Trump. Tên của bất kỳ người nào nên được mã hóa là "Có". Các cá nhân không được nêu tên nên được mã hóa là "Có", miễn là rõ ràng một người duy nhất đang được tham chiếu. Những người được gắn thẻ với @ tính là "Có", nhưng @ không cần thiết để mã hóa "Có".
MARG | Tham chiếu rõ ràng đến (các) nhóm bị thiệt thòi? Phụ nữ; thiểu số tôn giáo; cộng đồng bản địa; nhóm chủng tộc/dân tộc; người khuyết tật; bản sắc tình dục/giới tính. Một cá nhân duy nhất không đủ để mã hóa có trừ khi nhóm rộng hơn cũng được đề cập. Đừng mã hóa tham chiếu chung đến mọi người tình cờ bao gồm nhóm, ví dụ "nam và nữ". Ví dụ "Pocahontas" là có. | Tweet có tham chiếu rõ ràng đến một hoặc nhiều nhóm bị thiệt thòi không? Ví dụ về các nhóm bị thiệt thòi bao gồm phụ nữ, thiểu số tôn giáo, cộng đồng bản địa, nhóm chủng tộc hoặc dân tộc, người khuyết tật và bản sắc tình dục/giới tính. Đề cập đến một cá nhân thuộc một trong những nhóm này không đủ để mã hóa "Có", trừ khi nhóm rộng hơn cũng được đề cập. Đừng mã hóa tham chiếu chung đến mọi người tình cờ bao gồm nhóm (Ví dụ "nam và nữ"). Ví dụ "Pocahontas" nên được mã hóa là "Có".
INTN | Tham chiếu các quốc gia/nhà lãnh đạo khác? Bất cứ thứ gì bên ngoài 50 bang. Bao gồm thảo luận về thương mại, NATO. Đừng tra cứu các thuật ngữ bạn không biết. | Tweet này có tham chiếu các chủ đề quốc tế bên ngoài Hoa Kỳ, như các quốc gia khác hoặc nhà lãnh đạo quốc tế không? Chỉ bao gồm tham chiếu bên ngoài 50 bang Hoa Kỳ. Bao gồm thảo luận về thương mại và NATO. Đừng tra cứu các thuật ngữ bạn không biết.
PRTY | Tham chiếu đến nhãn đảng phái/tư tưởng? 0=Không có nhãn; 1=Cộng hòa/Bảo thủ; 2=Dân chủ/Tự do; 3=Cả hai. Mã hóa điều này một cách nghiêm ngặt, sao cho chỉ các hình thức thực tế của những thuật ngữ cụ thể này tạo ra mã. "Conservative so-and-so" là có. Ví dụ: "The other side" = 0; "Dems" = 2; "We need more conservative policies" = 1. | Tweet này có tham chiếu các đảng chính trị Hoa Kỳ không? Tham chiếu đến Cộng hòa hoặc Bảo thủ là "Có". Tham chiếu đến Dân chủ hoặc Tự do là "Có". Mã hóa điều này một cách nghiêm ngặt, sao cho chỉ các hình thức thực tế của những thuật ngữ cụ thể này tạo ra mã. Ví dụ "Conservative so-and-so" là "Có". Ví dụ "The other side" là "Không". Ví dụ "Dems" là "Có" 2. Ví dụ "We need more conservative policies" là "Có".
IMMG | Tham chiếu nhập cư? Bức tường, biên giới phía nam, ICE, chia ly gia đình, lệnh cấm du lịch, v.v. Mã hóa 1 nếu rõ ràng anh ấy đang tham chiếu nhập cư, ngay cả khi không sử dụng từ đó (ví dụ "Big increase in traffic into our country from certain areas while our people are far more vulnerable" sẽ là 1). Ví dụ "ZIKA virus" là có. | Tweet này có tham chiếu nhập cư ở Hoa Kỳ không? Bao gồm tham chiếu đến bức tường, biên giới phía nam, ICE, chia ly gia đình, lệnh cấm du lịch, v.v. Mã hóa "Có" nếu rõ ràng Donald Trump đang tham chiếu nhập cư, ngay cả khi anh ấy không sử dụng từ nhập cư (Ví dụ "Big increase in traffic into our country from certain areas while our people are far more vulnerable" sẽ là "Có"). Ví dụ "ZIKA virus" là "Có".

--- TRANG 23 ---
Bảng 10: Sổ tay Mã hóa Ukraine Water Problems
Tên mã | Mô tả mã gốc | Mô tả mã đã sửa đổi
env_problems | Văn bản có về vấn đề môi trường không? | Văn bản có về vấn đề môi trường không?
pollution | Văn bản có về ô nhiễm môi trường không? | Văn bản có về ô nhiễm môi trường không?
treatment | Văn bản có về nhà máy xử lý hoặc công nghệ môi trường không? | Văn bản có về nhà máy xử lý hoặc công nghệ môi trường không?
climate | Văn bản có về chỉ số khí hậu không? | Văn bản có về chỉ số khí hậu không?
biomonitoring | Văn bản có về giám sát sinh học, sinh vật trong nước hoặc trong lưu vực sông không? | Văn bản có về giám sát sinh học, sinh vật trong nước hoặc trong lưu vực sông không?

Bảng 11: Sổ tay Mã hóa BBC News
Tên mã | Mô tả mã gốc | Mô tả mã đã sửa đổi
business | business | Câu chuyện tin tức này có về kinh doanh không?
entertainment | entertainment | Câu chuyện tin tức này có về giải trí không?
politics | politics | Câu chuyện tin tức này có về chính trị không?
sport | sport | Câu chuyện tin tức này có về thể thao không?
tech | tech | Câu chuyện tin tức này có về công nghệ không?

Bảng 12: Sổ tay Mã hóa Contrarian Claims
Tên mã | Mô tả mã gốc | Mô tả mã đã sửa đổi
1.1 | Băng/đất đóng băng vĩnh cửu/lớp phủ tuyết không tan chảy | Băng/đất đóng băng vĩnh cửu/lớp phủ tuyết không tan chảy
1.2 | Chúng ta đang hướng tới kỷ băng hà/làm lạnh toàn cầu | Chúng ta đang hướng tới kỷ băng hà/làm lạnh toàn cầu
1.3 | Thời tiết lạnh/có tuyết | Thời tiết lạnh/có tuyết
1.4 | Khí hậu không ấm lên/thay đổi trong (vài) thập kỷ qua | Khí hậu không ấm lên/thay đổi trong (vài) thập kỷ qua
1.5 | Đại dương đang lạnh đi/không ấm lên | Đại dương đang lạnh đi/không ấm lên
1.6 | Mực nước biển dâng bị phóng đại/không tăng tốc | Mực nước biển dâng bị phóng đại/không tăng tốc
1.7 | Thời tiết cực đoan không tăng/đã xảy ra trước đây/không liên quan đến biến đổi khí hậu | Thời tiết cực đoan không tăng/đã xảy ra trước đây/không liên quan đến biến đổi khí hậu
1.8 | Họ đã thay đổi tên từ 'nóng lên toàn cầu' thành 'biến đổi khí hậu' | Họ đã thay đổi tên từ 'nóng lên toàn cầu' thành 'biến đổi khí hậu'
2.1 | Đó là chu kỳ/biến đổi tự nhiên | Đó là chu kỳ/biến đổi tự nhiên
2.2 | Đó là các tác động khí hậu con người không phải khí nhà kính (aerosol, sử dụng đất) | Đó là các tác động khí hậu con người không phải khí nhà kính (aerosol, sử dụng đất)

--- TRANG 24 ---
2.3 | Không có bằng chứng về hiệu ứng nhà kính/carbon dioxide thúc đẩy biến đổi khí hậu | Không có bằng chứng về hiệu ứng nhà kính/carbon dioxide thúc đẩy biến đổi khí hậu
2.4 | CO2 không tăng/pH đại dương không giảm | CO2 không tăng/pH đại dương không giảm
2.5 | Phát thải CO2 của con người là nhỏ/không làm tăng CO2 trong khí quyển | Phát thải CO2 của con người là nhỏ/không làm tăng CO2 trong khí quyển
3.1 | Độ nhạy khí hậu thấp/phản hồi âm làm giảm sự ấm lên | Độ nhạy khí hậu thấp/phản hồi âm làm giảm sự ấm lên
3.2 | Loài/thực vật/rạn san hô không cho thấy tác động khí hậu/đang hưởng lợi từ biến đổi khí hậu | Loài/thực vật/rạn san hô không cho thấy tác động khí hậu/đang hưởng lợi từ biến đổi khí hậu
3.3 | CO2 có lợi/không phải chất ô nhiễm | CO2 có lợi/không phải chất ô nhiễm
3.4 | Chỉ là vài độ (hoặc ít hơn) | Chỉ là vài độ (hoặc ít hơn)
3.5 | Biến đổi khí hậu không góp phần vào xung đột con người/đe dọa an ninh quốc gia | Biến đổi khí hậu không góp phần vào xung đột con người/đe dọa an ninh quốc gia
3.6 | Biến đổi khí hậu không tác động tiêu cực đến sức khỏe | Biến đổi khí hậu không tác động tiêu cực đến sức khỏe
4.1 | Các chính sách khí hậu (giảm thiểu hoặc thích ứng) có hại | Các chính sách khí hậu (giảm thiểu hoặc thích ứng) có hại
4.2 | Các chính sách khí hậu không hiệu quả/có sai sót | Các chính sách khí hậu không hiệu quả/có sai sót
4.3 | Quá khó để giải quyết | Quá khó để giải quyết
4.4 | Công nghệ năng lượng sạch/nhiên liệu sinh học sẽ không hoạt động | Công nghệ năng lượng sạch/nhiên liệu sinh học sẽ không hoạt động
4.5 | Con người cần năng lượng (ví dụ từ nhiên liệu hóa thạch/hạt nhân) | Con người cần năng lượng (ví dụ từ nhiên liệu hóa thạch/hạt nhân)
5.1 | Khoa học liên quan đến khí hậu không chắc chắn / không đúng / không đáng tin cậy (dữ liệu, phương pháp & mô hình) | Khoa học liên quan đến khí hậu không chắc chắn / không đúng / không đáng tin cậy (dữ liệu, phương pháp & mô hình)
5.2 | Phong trào khí hậu báo động / sai / chính trị / thiên vị / đạo đức giả (người hoặc nhóm) | Phong trào khí hậu báo động / sai / chính trị / thiên vị / đạo đức giả (người hoặc nhóm)
5.3 | Biến đổi khí hậu (khoa học hoặc chính sách) là một âm mưu (lừa dối) | Biến đổi khí hậu (khoa học hoặc chính sách) là một âm mưu (lừa dối)
0.0 | Không có gì trong số trên | Không có gì trong số trên

--- TRANG 25 ---
C Kết quả Bổ sung
Bảng 13: Kết quả IRR Chi tiết
Bộ dữ liệu | Mã | N | Số lượng mã | Gwet's AC1
| | | Gốc | Nhân bản | LLM | Gốc-Nhân bản | Gốc-LLM | Nhân bản-LLM
Trump Tweets | HSTG | 100 | 12 | 13 | 57 | 0,96 | 0,18 | 0,19
Trump Tweets | ATSN | 100 | 29 | 29 | 51 | 1 | 0,58 | 0,58
Trump Tweets | CRIT | 100 | 39 | 26 | 30 | 0,73 | 0,76 | 0,73
Trump Tweets | MEDI | 100 | 7 | 7 | 6 | 1 | 0,96 | 0,96
Trump Tweets | FAMY | 100 | 5 | 2 | 3 | 0,97 | 0,96 | 0,95
Trump Tweets | PLCE | 100 | 4 | 4 | 4 | 1 | 0,98 | 0,98
Trump Tweets | MAGA | 100 | 4 | 5 | 6 | 0,99 | 0,98 | 0,99
Trump Tweets | CAPT | 100 | 26 | 28 | 48 | 0,93 | 0,36 | 0,36
Trump Tweets | INDV | 100 | 42 | 41 | 57 | 0,79 | 0,5 | 0,48
Trump Tweets | MARG | 100 | 4 | 1 | 2 | 0,97 | 0,94 | 0,97
Trump Tweets | INTN | 100 | 24 | 19 | 15 | 0,86 | 0,81 | 0,86
Trump Tweets | PRTY | 100 | 5 | 18 | 23 | 0,81 | 0,76 | 0,9
Trump Tweets | IMMG | 100 | 7 | 6 | 8 | 0,99 | 0,97 | 0,95
Ukraine Water | env_problems | 100 | 51 | 8 | 53 | 0,23 | 0,64 | 0,15
Ukraine Water | pollution | 100 | 38 | 22 | 47 | 0,59 | 0,55 | 0,51
Ukraine Water | treatment | 100 | 18 | 8 | 15 | 0,84 | 0,88 | 0,89
Ukraine Water | climate | 100 | 19 | 17 | 9 | 0,97 | 0,87 | 0,84
Ukraine Water | biomonitoring | 100 | 8 | 36 | 8 | 0,51 | 0,86 | 0,48
BBC | sport | 100 | 25 | 24 | 23 | 0,98 | 0,97 | 0,98
BBC | business | 100 | 20 | 17 | 18 | 0,79 | 0,88 | 0,79
BBC | politics | 100 | 27 | 30 | 36 | 0,71 | 0,84 | 0,75
BBC | entertainment | 100 | 17 | 17 | 14 | 0,97 | 0,96 | 0,96
BBC | tech | 100 | 11 | 10 | 9 | 0,94 | 0,98 | 0,94
Contrarian Claims | 1.1 | 100 | 3 | 3 | 7 | 1 | 0,96 | 0,96
Contrarian Claims | 1.2 | 100 | 1 | 1 | 0 | 0,98 | 0,99 | 0,99
Contrarian Claims | 1.3 | 100 | 0 | 1 | 1 | 0,99 | 0,99 | 0,98
Contrarian Claims | 1.4 | 100 | 0 | 0 | 2 | 1 | 0,98 | 0,98
Contrarian Claims | 1.5 | 100 | 0 | 0 | 0 | 1 | 1 | 1
Contrarian Claims | 1.6 | 100 | 1 | 1 | 1 | 1 | 1 | 1
Contrarian Claims | 1.7 | 100 | 2 | 0 | 2 | 0,98 | 0,96 | 0,98
Contrarian Claims | 1.8 | 100 | 0 | 0 | 0 | 1 | 1 | 1
Contrarian Claims | 2.1 | 100 | 6 | 7 | 8 | 0,97 | 0,93 | 0,92
Contrarian Claims | 2.2 | 100 | 0 | 0 | 0 | 1 | 1 | 1
Contrarian Claims | 2.3 | 100 | 3 | 2 | 9 | 0,99 | 0,93 | 0,92
Contrarian Claims | 2.4 | 100 | 0 | 0 | 0 | 1 | 1 | 1
Contrarian Claims | 2.5 | 100 | 0 | 0 | 2 | 1 | 0,98 | 0,98
Contrarian Claims | 3.1 | 100 | 2 | 0 | 0 | 0,98 | 0,98 | 1
Contrarian Claims | 3.2 | 100 | 0 | 0 | 0 | 1 | 1 | 1
Contrarian Claims | 3.3 | 100 | 3 | 3 | 3 | 0,98 | 0,98 | 0,98
Contrarian Claims | 3.4 | 100 | 0 | 0 | 0 | 1 | 1 | 1

--- TRANG 26 ---
Contrarian Claims | 3.5 | 100 | 0 | 0 | 0 | 1 | 1 | 1
Contrarian Claims | 3.6 | 100 | 0 | 0 | 0 | 1 | 1 | 1
Contrarian Claims | 4.1 | 100 | 5 | 5 | 4 | 0,96 | 0,97 | 0,97
Contrarian Claims | 4.2 | 100 | 1 | 2 | 3 | 0,97 | 0,96 | 0,97
Contrarian Claims | 4.3 | 100 | 0 | 2 | 0 | 0,98 | 1 | 0,98
Contrarian Claims | 4.4 | 100 | 0 | 1 | 1 | 0,99 | 0,99 | 1
Contrarian Claims | 4.5 | 100 | 0 | 1 | 2 | 0,99 | 0,98 | 0,99
Contrarian Claims | 5.1 | 100 | 10 | 12 | 10 | 0,95 | 0,93 | 0,93
Contrarian Claims | 5.2 | 100 | 6 | 3 | 9 | 0,9 | 0,9 | 0,86
Contrarian Claims | 5.3 | 100 | 0 | 2 | 0 | 0,98 | 1 | 0,98
Contrarian Claims | 0.0 | 100 | 57 | 48 | 36 | 0,54 | 0,54 | 0,53

--- TRANG 27 ---

Tính Nhất Quán Ngữ Nghĩa để Đảm Bảo Độ Tin Cậy của Các Mô Hình Ngôn Ngữ Lớn

Harsh Raj,1Vipul Gupta,2Domenic Rosati,3Subhabrata Majumdar4
1Đại học Công nghệ Delhi, harsh777111raj@gmail.com
2Đại học Bang Pennsylvania, vkg5164@psu.edu
3scite.ai, dom@scite.ai
4Liên minh Rủi ro và Lỗ hổng AI, subho@avidml.org

Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLM) thể hiện sự trôi chảy và năng lực đáng kể trong nhiều tác vụ ngôn ngữ tự nhiên khác nhau. Tuy nhiên, nghiên cứu gần đây đã làm nổi bật tính nhạy cảm của chúng đối với các biến thể trong prompt đầu vào. Để triển khai LLM một cách an toàn và đáng tin cậy, điều quan trọng là đầu ra của chúng phải nhất quán khi được nhắc nhở bằng các biểu thức mang cùng ý nghĩa hoặc ý định. Trong khi một số công trình hiện có đã khám phá cách các LLM tiên tiến giải quyết vấn đề này, các đánh giá của họ đã bị giới hạn trong việc đánh giá sự bằng nhau về từ vựng của các câu trả lời một hoặc nhiều từ, bỏ qua tính nhất quán của các chuỗi văn bản sinh tạo. Để hiểu toàn diện hơn về tính nhất quán của LLM trong các tình huống sinh văn bản mở, chúng tôi giới thiệu một thước đo tổng quát về tính nhất quán ngữ nghĩa, và xây dựng nhiều phiên bản của thước đo này để đánh giá hiệu suất của các LLM khác nhau. Đề xuất của chúng tôi thể hiện tính nhất quán cao hơn đáng kể và tương quan mạnh hơn với các đánh giá của con người về tính nhất quán đầu ra so với các thước đo truyền thống dựa trên tính nhất quán từ vựng. Cuối cùng, chúng tôi đề xuất một chiến lược nhắc nhở mới, được gọi là Ask-to-Choose (A2C), để tăng cường tính nhất quán ngữ nghĩa. Khi được đánh giá cho việc trả lời câu hỏi đóng sách dựa trên các biến thể câu trả lời từ benchmark TruthfulQA, A2C tăng các thước đo độ chính xác cho LLM được huấn luyện trước và tinh chỉnh lên đến 47%, và các thước đo tính nhất quán ngữ nghĩa cho các mô hình được điều chỉnh theo hướng dẫn lên đến 7 lần.

Giới thiệu
Trong thời gian gần đây, việc áp dụng các mô hình ngôn ngữ được huấn luyện trước lớn (LLM) trong các quy trình làm việc tự động thế hệ tiếp theo cho các tác vụ dựa trên ngôn ngữ tự nhiên đã tăng lên. Tuy nhiên, việc sử dụng gia tăng này cũng đã đưa các mối quan tâm về tính an toàn và độ tin cậy của các mô hình này vào tâm điểm (Weidinger et al. 2022; Gupta et al. 2023). Trong bối cảnh Sinh Ngôn ngữ Tự nhiên (NLG), điều cần thiết là có một LLM đáng tin cậy tạo ra các đầu ra tương đương về mặt ngữ nghĩa khi được cung cấp các prompt tương đương về mặt ngữ nghĩa. Tính chất này được gọi là tính nhất quán. Tính nhất quán là quan trọng để đảm bảo tính an toàn của LLM, vì nó tăng sự chắc chắn rằng một LLM có thể tạo ra các đầu ra đủ tương tự khi được cung cấp các đầu vào tương tự về mặt ngữ nghĩa. Tuy nhiên, mức độ mà các phương pháp NLG hiện tại thể hiện tính nhất quán và các phương pháp để đo lường tính nhất quán này vẫn còn không đầy đủ. Để giải quyết khoảng cách này, chúng tôi đề xuất một khung làm việc mới để đánh giá và đảm bảo tính nhất quán của NLG. Khung làm việc của chúng tôi tổng quát hóa các phương pháp trước đây đã đánh giá tính nhất quán dựa trên các đầu ra token đơn hoặc đa token, như Elazar et al. (2021), để bao quát toàn bộ các chuỗi văn bản được sinh ra.

Thước đo tính nhất quán của chúng tôi cho NLG vượt qua các thước đo từ vựng đơn giản được đề xuất trong các nghiên cứu trước, và nắm bắt các biến thể thực sự trong prompt truyền đạt cùng ý nghĩa ngữ nghĩa nhưng khác nhau trong biểu diễn từ vựng của chúng. Chúng tôi đánh giá thực nghiệm hiệu quả của thước đo này trong việc đánh giá tính nhất quán, xem xét các thước đo khác nhau về tương đương ngữ nghĩa, kiến trúc LLM, cũng như các kỹ thuật diễn giải và sinh/giải mã câu trả lời.

Chúng tôi xem xét một tình huống trả lời câu hỏi đóng sách nơi chúng tôi muốn đảm bảo rằng các câu trả lời được sinh ra từ một LLM để phản hồi các phiên bản diễn giải của một câu hỏi là tương tự về mặt ngữ nghĩa. Để đạt được mục tiêu này, chúng tôi sử dụng các chiến lược học trong ngữ cảnh—tức là khơi gợi câu trả lời từ một LLM bằng cách sử dụng các ví dụ few-shot trong một mẫu prompt—theo nhiều cách. Các chiến lược nhắc nhở tiên tiến, như lý luận Chain-of-Thought (Wei et al. 2023), được biết đến rộng rãi để trích xuất hiệu suất cải thiện từ LLM, cũng như giúp giảm thiên kiến có hại (Guo, Yang, và Abbasi 2022) và cải thiện tính thực tế (Si et al. 2023). Các phát hiện của chúng tôi cho thấy rằng các chiến lược nhắc nhở cũng có thể hữu ích để đảm bảo tính nhất quán trong các tình huống diễn giải thực tế. Chúng tôi minh họa các chi tiết cụ thể của chiến lược của chúng tôi trong Hình 1. Để sinh câu trả lời cho các phiên bản diễn giải của một câu hỏi, chúng tôi bắt đầu với mẫu prompt paraphrasePrompt chứa các ví dụ về các cách khác nhau để diễn giải (như sử dụng từ đồng nghĩa hoặc thay đổi cú pháp). Sau đó chúng tôi lặp đi lặp lại việc cung cấp các chỉ báo của từng phương pháp này, cùng với một câu hỏi đầu vào vào một LLM phụ trợ (AuxLLM) để sinh các diễn giải của câu hỏi đó. Các câu hỏi này được đưa vào LLM chính, sinh ra các câu trả lời mô tả. Mỗi câu trả lời mô tả, cùng với câu hỏi gốc, được thêm vào một mẫu prompt thứ hai (answerPrompt), và được đưa vào LLM một lần nữa để khơi gợi các câu trả lời ngắn một hoặc hai từ. Việc bao gồm các ví dụ few-shot của các kết hợp câu hỏi-câu trả lời dài-câu trả lời ngắn trong answerPrompt hỗ trợ quá trình này. Khi chúng tôi có nhiều câu trả lời ngắn cho câu hỏi gốc, chúng tôi thêm từng cặp câu trả lời, cộng với câu hỏi gốc, vào AuxLLM một lần nữa để có được tương đương ngữ nghĩa theo cặp của hai câu trả lời này.

Thước đo tính nhất quán ngữ nghĩa được đề xuất của chúng tôi nhận tất cả các tương đương ngữ nghĩa theo cặp làm đầu vào, và tính toán tính nhất quán tổng thể giữa tất cả các biến thể của câu trả lời cho câu hỏi gốc. Chúng tôi thực nghiệm với các phiên bản khác nhau của thước đo tính nhất quán này dựa trên các khái niệm về tương đương ngữ nghĩa được tìm thấy trong tài liệu. Trong các so sánh thực nghiệm với các khái niệm hiện có về các thước đo tương tự dựa trên token, chúng tôi cho thấy rằng thước đo được đề xuất của chúng tôi thể hiện mức độ tính nhất quán cao hơn trong các biến thể câu trả lời. Quan trọng nhất, chúng tôi chứng minh rằng khái niệm tính nhất quán ngữ nghĩa của chúng tôi phù hợp rất gần với sở thích của con người về tính nhất quán.

Các phát hiện chính của chúng tôi như sau:
• LLM lớn hơn có xu hướng thể hiện mức độ tính nhất quán cao hơn.
• Khi kích thước của LLM tăng, các câu trả lời được sinh ra của chúng có xu hướng kém chính xác hơn, minh họa một hiện tượng tỷ lệ nghịch (như cũng quan sát thấy trong Lin, Hilton, và Evans (2022)).
• Đáng chú ý, tính nhất quán và độ chính xác là các tính chất độc lập và không có vẻ tương quan.
• Bằng cách thiết kế cẩn thận các prompt đầu vào và thước đo tính nhất quán mới, có thể căn chỉnh các phép đo tính nhất quán ngữ nghĩa với các khái niệm tính nhất quán của con người.
• Chúng tôi đề xuất một chiến lược nhắc nhở Ask-to-Choose (A2C), tăng cường độ chính xác và tính nhất quán ngữ nghĩa trên các biến thể câu trả lời được sinh ra từ TruthfulQA (Lin, Hilton, và Evans 2022), với cải thiện độ chính xác lên đến 47% trên toàn bộ, và cải thiện tính nhất quán cho các mô hình được điều chỉnh theo hướng dẫn lên đến 7 lần.

Công trình Liên quan
Khái niệm đo lường tính nhất quán lần đầu tiên được giới thiệu trong thăm dò LAMA để hiểu LLM như các cơ sở tri thức (Petroni et al. 2019). Xây dựng trên ý tưởng này, Elazar et al. (2021) phát triển bộ dữ liệu ParaRel để đánh giá tính nhất quán của các mô hình ngôn ngữ có mặt nạ bằng cách nghiên cứu các token mà chúng sẽ dự đoán cho các tuple có mặt nạ. Mở rộng dòng nghiên cứu này, Fierro và Søgaard (2022) mở rộng các phương pháp sang một cài đặt đa ngôn ngữ, đa token, và Keleg và Magdy (2023) lấp đầy những thiếu sót của LAMA bằng cách phát triển một bộ dữ liệu benchmark thực tế đa dạng về văn hóa. Ngoài ra, Jang, Kwon, và Lukasiewicz (2021) đề xuất một khung làm việc mới để hiểu tính nhất quán trong các mô hình được tinh chỉnh cho các tác vụ tương tự câu. Zhou et al. (2022) đã thiết kế một phương pháp sử dụng nhiều prompt để chỉ định các tác vụ đơn, dẫn đến cải thiện hơn 10% trong các thước đo tính nhất quán trên các cài đặt dữ liệu và tác vụ đa dạng. Cuối cùng, Newman, Choubey, và Rajani (2022) và Tam et al. (2022) phát triển các phương pháp mạnh mẽ để trích xuất thông tin thực tế một cách chính xác từ LLM.

Cho một đầu vào cho LLM, việc chọn lựa giữa nhiều đầu ra ứng viên là một chiến lược phổ biến để đảm bảo độ chính xác và tính nhất quán của đầu ra cuối cùng. Trong số những phương pháp khác, phương pháp Chain-of-Thoughts (Wei et al. 2023, CoT) sử dụng bỏ phiếu đa số để đảm bảo độ chính xác cao của các câu trả lời được sinh ra. Kassner et al. (2021) sử dụng một bộ giải quyết bên ngoài—được hỗ trợ bởi các ràng buộc logic được mã hóa cứng để xếp hạng lại các câu trả lời từ một LLM được huấn luyện trước trong khi tối đa hóa độ chính xác và tính nhất quán niềm tin. Mitchell et al. (2022) đã thực hiện một phương pháp tương tự, nhưng sử dụng các ràng buộc được ước tính động và một LLM phụ trợ để thực hiện việc xếp hạng lại. Cuối cùng, chiến lược giải mã tự nhất quán sử dụng lấy mẫu và bỏ phiếu đa số thay vì giải mã tham lam để cải thiện độ chính xác của việc nhắc nhở CoT (Wang et al. 2022; Aggarwal et al. 2023). So với các công trình trước đây này, chiến lược nhắc nhở A2C được đề xuất của chúng tôi để đảm bảo tính nhất quán ngữ nghĩa sử dụng một prompt yêu cầu chính LLM chọn câu trả lời tốt nhất từ số các ứng viên được sinh ra bằng cách truy vấn nó nhiều lần dưới các điều kiện thực nghiệm khác nhau. Điều này có thể được xem như một cách để làm mạnh mẽ các phương pháp dựa trên bỏ phiếu đa số thông qua việc thêm một lớp lý luận sau lấy mẫu hoặc các bước tương đương sinh ra nhiều ứng viên đầu ra.

Chúng tôi kết thúc bằng cách đề cập đến công trình trước đây của chúng tôi đã thúc đẩy bài báo này. Trong Raj, Rosati, và Majumdar (2022), chúng tôi đã đề xuất một thước đo tính nhất quán ngữ nghĩa, và chứng minh các lợi thế của nó so với đo lường tính nhất quán dựa trên token cho một số mô hình ngôn ngữ được huấn luyện trước. Trong bài báo này, chúng tôi tổng quát hóa đáng kể khung đo lường vượt ra ngoài tương tự theo cặp, sử dụng học trong ngữ cảnh cho việc diễn giải và sinh đầu ra, và thực hiện đánh giá thực nghiệm trên các LLM được tinh chỉnh theo hướng dẫn hoặc với Học Tăng cường từ Phản hồi Con người (RLHF). Quan trọng nhất, chúng tôi đề xuất kỹ thuật A2C cải thiện đáng kể độ chính xác và tính nhất quán của các biến thể đầu ra. Lưu ý rằng trong khi Raj, Rosati, và Majumdar (2022) đã sử dụng ba LLM được huấn luyện trước theo sau bởi một quy trình lọc hai bước để sinh các câu hỏi diễn giải, các diễn giải thu được không đủ đa dạng. Để cải thiện tình hình này, chúng tôi bây giờ sử dụng học trong ngữ cảnh để làm cho bước diễn giải hiệu quả đáng kể trong khi giới thiệu nhiều đa dạng hơn trong các câu hỏi diễn giải.

Phương pháp
Tính nhất quán trong LLM đề cập đến kỳ vọng rằng các prompt tương tự (như các diễn giải của nhau) nên sinh ra các đầu ra tương tự. Khái niệm này lần đầu tiên được chính thức hóa bởi Elazar et al. (2021). Xem xét n prompt tương tự về mặt ngữ nghĩa X = {x1, . . . , xn} sinh ra các đầu ra từ một không gian đầu ra Y: Y = {y1, . . . , yn}, yi ∈ Y khi được truyền qua một LLM. Cho điều này, Elazar et al. (2021) định nghĩa tính nhất quán là

Cons_lex(Y) = 1/(n(n−1)) ∑(i,j=1,i≠j)^n I(yi = yj). (1)

Định nghĩa trên, cũng như các nghiên cứu tiếp theo tận dụng nó (Fierro và Søgaard 2022; Jiang et al. 2020; Zhou et al. 2022; Newman, Choubey, và Rajani 2022) bị hạn chế trong khái niệm tính nhất quán từ vựng của chúng. Một điều cần lưu ý quan trọng của khái niệm tính nhất quán này là nó chỉ tìm kiếm các token khớp nhau trong các đầu ra. Tuy nhiên, trong thế giới thực, cùng một ý tưởng thường có thể được diễn đạt bằng các từ hoàn toàn khác nhau. Ví dụ, hai đầu ra "I love cats" và "felines are my favorite" tương đối nhất quán, nhưng chúng sẽ có điểm tính nhất quán thấp dưới thước đo này. Do đó, không thể sử dụng cùng một thước đo này để đánh giá các đầu ra ngôn ngữ tự nhiên từ các mô hình ngôn ngữ trong các tình huống đa dạng.

Tính Nhất quán Ngữ nghĩa
Chúng tôi đề xuất một thước đo tổng quát về tính nhất quán ngữ nghĩa mở rộng đáng kể định nghĩa của Phương trình (1) bằng cách thay thế sự bằng nhau từ vựng và trung bình đơn giản trong Phương trình (1) bằng các hàm tinh vi hơn bao hàm sự căn chỉnh ngữ nghĩa trên nhiều đầu ra.

Cons_sem(Y) = 1/n ∑(i=1)^n S(yi, Y−i). (2)

trong đó S(·,·) đo lường mức độ tương tự ngữ nghĩa giữa mỗi đầu ra được sinh ra yi với phần còn lại của các đầu ra được sinh ra, được biểu thị bởi tập hợp Y−i = {y1, . . . , yi−1, yi+1, . . . , yn}. Lưu ý rằng thước đo tính nhất quán của Elazar et al. (2021) là một trường hợp đặc biệt của Phương trình (2), lấy S(yi, Y−i) = (n−1)^−1 ∑(j≠i) I(yj = yi).

Trong bài báo này, chúng tôi thực nghiệm với hai kỹ thuật rộng để tính toán S(yi, Y−i). Phương pháp đầu tiên dựa trên tương tự theo cặp. Chúng tôi đơn giản thay thế chỉ báo bằng nhau token trong Phương trình (1) bằng một hàm tương đương ngữ nghĩa.

S(yi, Y−i) = 1/(n−1) ∑(j=1,i≠j)^n s(yi, yj). (3)

Chúng tôi có thể dễ dàng khôi phục thước đo gốc của Elazar et al. (2021) bằng cách đặt chỉ báo bằng nhau token là s(·,·), tức là s(yi, yj) ≡ I(yi = yj). Trong các thực nghiệm của chúng tôi, như hàm s(·,·) chúng tôi sử dụng các thước đo hiện có về tương tự ngữ nghĩa, như kéo theo và mâu thuẫn (Wang et al. 2018).

Khởi tạo thứ hai của chúng tôi về thước đo tính nhất quán ngữ nghĩa trong Phương trình (2) dựa trên một khái niệm tính nhất quán ngầm hơn sử dụng tương tự vượt ra ngoài so sánh theo cặp: entropy phân cụm ngữ nghĩa. Trước tiên chúng tôi thu được các thước đo tương đương ngữ nghĩa theo cặp thông qua học trong ngữ cảnh trên một LLM phụ trợ (Flan-T5-XL), sử dụng các prompt answerPrompt và similarPrompt (xem Danh sách 3 và 4 trong Phụ lục cho các mẫu). Sau đó chúng tôi sử dụng các điểm theo cặp này để phân cụm n đầu ra thành k ≤ n cụm tương tự về mặt ngữ nghĩa, nói C = {Ci, . . . , Ck}. Cuối cùng, chúng tôi định nghĩa tính nhất quán của LLM là entropy ngữ nghĩa (SE) của các cụm này.

SE = −∑(i=1)^k (|Ck|/n) log2(|Ci|/n). (4)

Phương trình (4) điều chỉnh định nghĩa lý thuyết thông tin của entropy trên phân phối xác suất rời rạc nơi một phần tử từ Y được gán cho cụm Ck với xác suất |Ck|/n. Sắp xếp lại các thuật ngữ trong Phương trình (4) với định nghĩa trong Phương trình (2) trong tâm trí, chúng tôi có như hàm tương đương ngữ nghĩa sau:

S(yi, Y−i) = −∑(k=1)^K (yi ∈ Ck) (|Ck| log2|Ci|)/n.

Kuhn, Gal, và Farquhar (2023) sử dụng phân cụm ngữ nghĩa để xác định sự không chắc chắn trong các thế hệ từ một LLM, sử dụng một mô hình kéo theo-mâu thuẫn như s(·,·) để tính toán điểm tương tự theo cả hai hướng (tức là s(a, b) và s(b, a)). So với đó, mục đích của chúng tôi là tính toán tính nhất quán chứ không phải tương tự nên các prompt được thiết kế theo cách như vậy. Tính nhất quán có thể được coi là một miền con của tương tự, với sự nhấn mạnh đặc biệt vào sự căn chỉnh thực tế giữa các câu.

Nguồn Biến thiên
Để thực hiện các thước đo tính nhất quán ngữ nghĩa được nêu trên, trước tiên chúng tôi sinh ra nhiều diễn giải của một prompt đã cho. Các prompt diễn giải này là đầu vào cho LLM để sinh ra các đầu ra Y. Chúng tôi xem xét hai chiến lược khác nhau cho quá trình này:

Diễn giải trong Ngữ cảnh và Lấy mẫu Nucleus 
Các diễn giải thực tế không phải là các nhiễu hoàn toàn ngẫu nhiên của cụm từ gốc. Thay vào đó chúng tuân theo các mẫu cụ thể, như việc sử dụng từ đồng nghĩa, hoặc một thay đổi trong cấu trúc câu. Để phản ánh điều trên, chúng tôi sử dụng một chiến lược học trong ngữ cảnh để sinh các diễn giải. Chúng tôi đơn giản nhắc nhở một LLM phụ trợ (text-davinci-003 (Brown et al. 2020)) với các ví dụ few-shot của các ngữ cảnh diễn giải (được biểu thị bởi questionPrompt trong Hình 1, xem cũng Danh sách 2 trong Phụ lục) để sinh các diễn giải phù hợp với một trong các ví dụ ngữ cảnh. Chúng tôi sử dụng lấy mẫu Nucleus để sinh câu trả lời từ các câu hỏi diễn giải này.

Lấy mẫu Nucleus Nhiệt độ Chéo
Trong chiến lược này, chúng tôi giữ prompt đầu vào giống nhau, và đơn giản sinh câu trả lời trên một phạm vi nhiệt độ rộng để xây dựng tập hợp các đầu ra Y, sử dụng lấy mẫu nucleus cho giải mã.

Như một ví dụ cụ thể, chúng tôi nhìn vào Hình 2. Trong phương pháp đầu tiên, câu hỏi gốc "What happens to you if you eat watermelon seeds?" khi được truyền qua LLM phụ trợ thu được bốn câu hỏi diễn giải, được đưa vào LLM chính để có được bốn câu trả lời cho câu hỏi gốc. So với đó, trong phương pháp thứ hai câu hỏi gốc được đưa vào LLM chính ở bốn nhiệt độ khác nhau để sinh ra một tập hợp câu trả lời khác.

Cải thiện Tính nhất quán bằng cách Yêu cầu Chọn lựa
Các mô hình ngôn ngữ được huấn luyện trước cho thấy cải thiện đáng kể trong hiệu suất cụ thể tác vụ phức tạp khi chúng được tinh chỉnh trên một phạm vi hướng dẫn liên quan, và/hoặc sử dụng RLHF (Lambart et al. 2023). Tinh chỉnh hướng dẫn cho phép LLM tuân theo các hướng dẫn cụ thể có thể được cung cấp như các mẫu prompt, trong khi mô hình phần thưởng trong RLHF huấn luyện mô hình để xếp hạng nhiều ứng viên câu trả lời được thúc đẩy bởi sở thích con người. Được thúc đẩy bởi quan sát này, chúng tôi giả thuyết rằng nếu một LLM được cung cấp nhiều ứng viên đầu ra như câu trả lời cho một câu hỏi diễn giải và nếu được hướng dẫn đúng cách để làm như vậy, nó có khả năng chọn một câu trả lời nhất quán với câu trả lời cho câu hỏi gốc.

Cho trực giác trên, chúng tôi đề xuất Ask-to-Choose (A2C), một chiến lược nhắc nhở đa lựa chọn để cải thiện tính nhất quán diễn giải. Ở mức độ cao, chúng tôi bắt đầu với các tập hợp biến thể đầu ra trên các ngữ cảnh diễn giải C = {c1, . . . , cI} và nhiệt độ T = {t1, . . . , tJ}. Biểu thị các đầu ra này bởi Yc và Yt, tương ứng. Sau đó chúng tôi tận dụng học trong ngữ cảnh một lần nữa để chọn hai tập hợp câu trả lời tốt nhất, truy vấn LLM nhiều lần với các diễn giải trong ngữ cảnh của câu hỏi đầu vào và hoặc Yc hoặc Yt sử dụng mẫu trong Danh sách 1.

Chúng tôi trình bày các chi tiết của quá trình trên trong Thuật toán 1. Như chúng ta thấy trong phần tiếp theo, A2C tăng độ chính xác của LLM trên toàn bộ lên đến 47%, và tính nhất quán của các đầu ra từ các mô hình được tinh chỉnh theo hướng dẫn lên đến 705%.

Thuật toán 1: Phương pháp Ask to Choose
Đầu vào: Câu hỏi gốc q
Tham số: Ngữ cảnh diễn giải C, nhiệt độ T.
Đầu ra:
1: // Sinh các đầu ra trong ngữ cảnh
2: for ci ∈ C do
3:   q(ci) ← AuxLLM(paraphraseprompt(q, ci))
4:   y(ci) ← LLM(answerPrompt(q(ci)))
5: end for
6: Cho Yc = {y(ci); ci ∈ C}

8: // Sinh các đầu ra nhiệt độ chéo
9: for tj ∈ T do
10:   y(tj) ← LLM(answerPrompt(q, tj))
11: end for
12: Cho Yt = {y(tj); tj ∈ T}

14: // Ask-to-Choose
15: for ci ∈ C do
16:   q̃(ci) ← LLM(paraphraseprompt(q, ci))
17:   yc(ci) ← LLM(rankPrompt(q̃(ci), Yc))
18: end for
19: for tj ∈ T do
20:   yt(tj) ← LLM(rankPrompt(q̃, Yt))
21: end for
22: Cho Ŷc = {ŷc(ci); ci ∈ C}
23: Cho Ŷt = {ŷt(tj); tj ∈ T}

25: return Ŷc, Ŷt.

Thực nghiệm

Thiết lập
Dữ liệu Để đánh giá tính nhất quán ngữ nghĩa, chúng tôi sử dụng các câu trả lời được sinh ra trên các câu hỏi từ bộ dữ liệu benchmark TruthfulQA (Lin, Hilton, và Evans 2022), sử dụng hai biến thể được đề cập ở trên. Chúng tôi chọn TruthfulQA vì nó được sử dụng rộng rãi trong tài liệu để đo lường, và đã có một loạt các thước đo và đường cơ sở để đánh giá sinh văn bản tự do. Đối với diễn giải ngữ cảnh, chúng tôi bắt đầu với mẫu paraphrasePrompt với các ví dụ của bốn quy tắc ngôn ngữ: từ đồng nghĩa, thay đổi dạng từ, thay đổi cấu trúc của một câu, và thay đổi liên từ (xem Danh sách 2 trong Phụ lục). Chúng tôi đưa mẫu này và mỗi câu hỏi trong TruthfulQA vào LLM phụ trợ (OpenAI 2023, text-davinci-003) để sinh một diễn giải theo một trong bốn quy tắc diễn giải. Lặp lại trên tất cả các quy tắc cho chúng tôi bốn diễn giải ngữ cảnh cho mỗi câu hỏi gốc trong TruthfulQA.

Mô hình Chúng tôi sử dụng một số LLM, được huấn luyện trước bằng các chiến lược khác nhau, để đánh giá tính nhất quán. Trước tiên, chúng tôi sử dụng một loạt các mô hình OPT (Zhang et al. 2022) với số lượng tham số tăng dần (từ 125M đến 6.7B tham số) để hiểu ảnh hưởng của kích thước tham số mô hình đối với tính nhất quán. Để so sánh trên các kiến trúc mô hình và chiến lược tinh chỉnh, chúng tôi sử dụng Flan T5 XL được tinh chỉnh theo hướng dẫn (Chung et al. 2022), các mô hình được tinh chỉnh RLHF StableVicuna-13B và LlaMA 2 13B (Touvron et al. 2023), cũng như GPT-3 text-davinci-003 sử dụng RLHF và tinh chỉnh hướng dẫn.

Đánh giá Để thực hiện tính nhất quán ngữ nghĩa dựa trên tương tự theo cặp trong Phương trình (3), chúng tôi sử dụng bốn thước đo tương đương ngữ nghĩa như s(·,·):
1. Tương đương ngữ nghĩa theo cặp sử dụng phát hiện diễn giải (PP, chi tiết trong Phụ lục A),
2. Thỏa thuận hoặc kéo theo theo cặp (Entail), và
3. Bất đồng hoặc mâu thuẫn theo cặp (Contra), cả hai sử dụng một mô hình suy luận ngôn ngữ tự nhiên (DeBERTa v2 xxlarge được tinh chỉnh trên MNLI) (Wang et al. 2018),
4. Entropy cụm ngữ nghĩa (Phương trình 4).

Chúng tôi cũng thực hiện hai thước đo heuristic về chồng chéo token: ROUGE1 (R1-C) và chồng chéo thực thể được đặt tên (NER). Bên cạnh tính nhất quán, chúng tôi sử dụng ROUGE1 (R1-A) và BLEURT (Sellam, Das, và Parikh 2020) để đo lường liệu các câu trả lời diễn giải có thực sự là câu trả lời chính xác cho câu hỏi gốc hay không. Đối với Contra và Entropy, các giá trị nhỏ hơn chỉ ra mức độ tính nhất quán cao, trong khi các giá trị cao hơn của phần còn lại tương ứng với tính nhất quán cao.

Khai thác Sở thích Con người Để đánh giá độ tin cậy của phép đo tính nhất quán ngữ nghĩa và các hàm thỏa thuận được chọn của chúng tôi, chúng tôi tiến hành một nghiên cứu con người liên quan đến ba người tham gia tình nguyện gắn nhãn một lựa chọn ngẫu nhiên 100 câu hỏi với các cặp câu trả lời kết quả từ các diễn giải của những câu hỏi này. Các người tham gia được hướng dẫn gắn nhãn các cặp câu trả lời là nhất quán nếu họ coi hai câu trả lời là tương đương về mặt ngữ nghĩa và không nhất quán nếu không. Chúng tôi đo lường thỏa thuận giữa các người gắn nhãn sử dụng κ của Fleiss, và sự căn chỉnh với các thước đo đánh giá của chúng tôi sử dụng tương quan tuyến tính (ρ của Spearman).

Kết quả
Hình 3 nêu bật một số phát hiện chính cho các phép đo tính nhất quán và độ chính xác mà không áp dụng A2C. Thứ nhất, khi các mô hình OPT trở nên lớn hơn về kích thước tham số, chúng có xu hướng làm tệ hơn trong việc cung cấp các câu trả lời chân thật trong TruthfulQA (Lin, Hilton, và Evans 2022), như được đo bởi R1-A và BLEURT. Đáng ngạc nhiên, xu hướng này đảo ngược đối với các mô hình lớn hơn, đối với họ các thước đo độ chính xác trở lại mức độ có thể so sánh với OPT-125M. Thứ hai, các mô hình với kích thước tham số cao hơn có xu hướng nhất quán hơn, đặc biệt là đối với diễn giải ngữ cảnh. Thứ ba, Các thước đo từ vựng về tính nhất quán (R1-C, NER) là các thước đo tính nhất quán ít thông tin hơn so với các phiên bản của thước đo tính nhất quán ngữ nghĩa được đề xuất của chúng tôi.

Tương tác của Tính nhất quán và Độ chính xác Bảng 1 trình bày các so sánh tính nhất quán dựa trên phương pháp PP, bao gồm tất cả câu trả lời, so với chỉ các câu trả lời chính xác. Trong khi tính nhất quán thực sự tăng với kích thước tham số mô hình cho cả hai tập hợp câu trả lời, các quan sát thú vị đối với tính nhất quán của tất cả câu trả lời so với câu trả lời đúng cho cùng một mô hình. Đối với các mô hình nhỏ hơn, tính nhất quán ngữ nghĩa có xu hướng giống nhau hoặc giảm nhẹ khi chỉ các câu trả lời chính xác được xem xét để tính toán tính nhất quán.

Căn chỉnh với Sở thích Con người Các chú thích con người được thực hiện trên các biến thể câu trả lời được sinh ra có giá trị κ của Fleiss là 0.9, chỉ ra thỏa thuận cao giữa các người gắn nhãn. Hình 4 cung cấp ma trận tương quan theo cặp giữa các thước đo đánh giá của chúng tôi và điểm số con người. Thú vị là, các thước đo độ chính xác không tương quan nhiều với các thước đo tính nhất quán hoặc chú thích con người về tính nhất quán. Hai thước đo độ chính xác cho thấy tương quan tích cực vừa phải với nhau (ρ = 0.41). Các thước đo tính nhất quán có xu hướng không tương quan với nhau, ngoại trừ trường hợp Entropy, PP, và kéo theo, được tương quan cao. Entropy cho thấy tương quan mạnh với các chú thích con người, theo sau bởi kéo theo, PP (ρ = 0.83, 0.73, 0.55, tương ứng). So với đó, các thước đo từ vựng về tính nhất quán cho thấy tương quan yếu hơn nhiều: NER (ρ = 0.14) và R1-C (ρ = 0.26). Những quan sát này chỉ ra rằng phương pháp được đề xuất của chúng tôi thực sự đo lường tính chất tính nhất quán như được hiểu bởi con người, và làm công việc tốt hơn so với các thước đo từ vựng chỉ dựa trên tương tự token.

Cải thiện với việc sử dụng A2C Bảng 2 cho thấy so sánh các thước đo độ chính xác và tính nhất quán trong các biến thể đầu ra thu được mà không có hoặc có sự giúp đỡ của A2C. Để ngắn gọn, chúng tôi hiển thị kết quả cho 5 trong số 8 mô hình, và 3 trong số 6 thước đo tính nhất quán (Xem Phụ lục C cho kết quả đầy đủ). Sau khi sử dụng A2C, chúng tôi thấy một sự gia tăng đáng kể trong độ chính xác của hầu hết các mô hình trên cả hai thước đo của chúng tôi—mức tối đa là 47% (StableVicuna-13B trên BLEURT). Đối với tính nhất quán, chúng tôi thấy cải thiện trong cả hai mô hình được điều chỉnh theo hướng dẫn (Flan T5 XL và text-davinci-003), nhưng không có mô hình OPT nào và những mô hình được tinh chỉnh chỉ sử dụng RLHF. Chúng tôi thấy cải thiện cao nhất trong Flan-T5 XL, có điểm R1-C tăng hơn 7 lần (4 đến 32.2).

Kết quả trước đó về các biến thể đầu ra mà không có A2C cho thấy rằng tính nhất quán và độ chính xác không luôn đi cùng nhau (Hình 3 và Bảng 1). Với việc áp dụng A2C, sự khác biệt này được hòa giải ở một mức độ nào đó. Như thấy trong Bảng 3, các biến thể đầu ra thu được sau khi áp dụng Thuật toán 1, khi được lọc cho các câu trả lời chính xác, có tính nhất quán tương tự hoặc tăng theo thước đo PP trên các mô hình và phương pháp biến thiên (ngữ cảnh hoặc nhiệt độ).

Các tương quan theo cặp với điểm số con người phần lớn vẫn giống nhau sau khi áp dụng A2C. Chúng tôi thấy chuyển động lớn nhất trong tương quan giữa hai thước đo độ chính xác—R1A và BLEURT—tăng từ 0.41 đến 0.54. Trong số các thước đo tính nhất quán ngữ nghĩa, Entropy cho thấy sự gia tăng nhẹ trong tương quan với các thước đo khác (Bảng 4).

Thảo luận Cho các kết quả trên, chúng tôi khuyến nghị entropy, kéo theo, và các hàm thỏa thuận dựa trên diễn giải như các thước đo đáng tin cậy về tính nhất quán ngữ nghĩa. Các phương pháp từ vựng không phải là thước đo trung thực của tính nhất quán ngữ nghĩa, và không tương quan với phán đoán con người. Nhiều phát hiện của chúng tôi là trực quan hoặc phù hợp với các kết quả trước đây. Ví dụ, Lin, Hilton, và Evans (2022) đã tìm thấy tỷ lệ nghịch tương tự trên TruthfulQA. Webson và Pavlick (2022) đã cho thấy rằng các mô hình được huấn luyện trước có hiểu biết kém về prompt, và prompt được hiểu tốt hơn bởi các mô hình lớn hơn. Điều này phù hợp với phát hiện của chúng tôi rằng các mô hình lớn hơn nhất quán hơn, và những mô hình được tinh chỉnh để tuân theo hướng dẫn còn hơn thế nữa.

Ít trực quan hơn là thực tế rằng tính nhất quán và độ chính xác không tương quan. Cả tính nhất quán và độ chính xác đều là tính chất mong muốn của NLG đáng tin cậy và cả hai sẽ phản ánh sự hiểu biết về prompt của chúng. Tuy nhiên, vì dường như không có mối quan hệ mạnh giữa độ chính xác và tính nhất quán, việc chỉ đo lường độ chính xác là không đủ để đảm bảo LLM đáng tin cậy. Cho rằng phương pháp A2C cho thấy bằng chứng cải thiện tính nhất quán trên các câu trả lời chính xác, các chiến lược nhắc nhở tương tự có thể được khám phá để cải thiện thêm sự căn chỉnh của tính nhất quán và độ chính xác.

Chúng tôi cũng giả thuyết rằng để A2C tăng tính nhất quán, LLM nên có thể tuân theo các hướng dẫn trong mẫu rankPrompt cụ thể. Như bằng chứng thực nghiệm, chúng tôi nhìn vào các câu trả lời cho câu hỏi "What is the spiciest part of a chili pepper?" được sinh ra bởi Llama 2-13B và text-davinci-003. Theo TruthfulQA, câu trả lời đúng là "The spiciest part of a chili pepper is the placenta". Điều này được phản ánh chính xác bởi câu trả lời từ text-davinci-003 được tinh chỉnh RLHF + hướng dẫn khi được cung cấp các tùy chọn câu trả lời khác sử dụng A2C: "Option 3: The hottest section of a chili pepper is the placenta, which contains the highest concentration of capsaicin". Tuy nhiên, Llama 2-13B được tinh chỉnh RLHF sinh ra một câu trả lời không chính xác không đúng định dạng: "Capsaicinoids are a group of chemicals that are responsible for the pungency of hot pepper. They are found in different concentrations in various pepper varieties. Capsaicinoid content is measured in Sc."

Kết luận
Trong công trình này, chúng tôi đã trình bày một khung làm việc mới để đánh giá tính nhất quán của NLG tương quan tốt với các phán đoán con người. Chúng tôi cũng giới thiệu chiến lược nhắc nhở A2C để cải thiện tính nhất quán ngữ nghĩa. Trên TruthfulQA, A2C tăng cường độ chính xác của các mô hình ngôn ngữ được huấn luyện trước và tinh chỉnh lên đến 47%, và các thước đo tính nhất quán ngữ nghĩa cho các mô hình được điều chỉnh theo hướng dẫn lên đến bảy lần. Một lợi thế chính của tổng quát hóa này là tổng hợp tuần tự: nếu chúng ta có quyền truy cập vào các hàm thỏa thuận tương đương ngữ nghĩa trên các miền đa dạng như sinh văn bản, hình ảnh, và âm thanh, thì chúng ta có thể sử dụng cùng khung làm việc để đánh giá tính nhất quán trên các tác vụ sinh đa phương thức cũng như vậy. Công việc tương lai theo hướng tương tự nên xác thực khung làm việc được đề xuất của chúng tôi trên các loại tác vụ sinh văn bản khác như trò chuyện hoặc sinh bảng-thành-văn bản, và các bộ dữ liệu benchmark khác ngoài TruthfulQA.

Một hạn chế chính của công trình chúng tôi là bất kỳ lỗi nào trong hàm thỏa thuận sẽ được phản ánh như lỗi trong điểm tính nhất quán. Ngoài ra, chi phí suy luận cho phương pháp hiện tại (sáu cuộc gọi LLM mỗi câu hỏi) có thể chứng minh là quá cao trong các tình huống ứng dụng nhất định, và nên được điều tra thêm để phát triển các chiến lược nhắc nhở hiệu quả hơn.

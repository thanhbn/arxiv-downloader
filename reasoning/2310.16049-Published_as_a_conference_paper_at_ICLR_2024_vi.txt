# 2310.16049.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/reasoning/2310.16049.pdf
# Kích thước tệp: 1088520 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
MUSR: KIỂM TRA GIỚI HẠN CỦA CHUỖI SUY NGHĨ
VỚI LẬP LUẬN MỀM ĐA BƯỚC
Zayne Sprague, Xi Ye, Kaj Bostrom, Swarat Chaudhuri, Greg Durrett
Khoa Khoa học Máy tính
Đại học Texas tại Austin
zayne@utexas.edu

TÓM TẮT
Trong khi các mô hình ngôn ngữ lớn (LLM) được trang bị các kỹ thuật như nhắc nhở chuỗi suy nghĩ đã thể hiện khả năng ấn tượng, chúng vẫn còn thiếu sót trong khả năng lập luận mạnh mẽ trong các môi trường phức tạp. Tuy nhiên, việc đánh giá khả năng lập luận của LLM là thách thức vì khả năng hệ thống tiếp tục phát triển trong khi các bộ dữ liệu chuẩn cho các tác vụ như suy luận logic vẫn tĩnh. Chúng tôi giới thiệu MuSR, một bộ dữ liệu để đánh giá các mô hình ngôn ngữ về các tác vụ lập luận mềm đa bước được chỉ định trong một câu chuyện ngôn ngữ tự nhiên. Bộ dữ liệu này có hai đặc điểm quan trọng. Thứ nhất, nó được tạo ra thông qua một thuật toán sinh tổng hợp-tự nhiên neuro-symbolic mới, cho phép xây dựng các trường hợp lập luận phức tạp thách thức GPT-4 (ví dụ, những vụ giết người bí ẩn dài khoảng 1000 từ) và có thể được mở rộng thêm khi các LLM có khả năng hơn được phát hành. Thứ hai, các trường hợp bộ dữ liệu của chúng tôi là những câu chuyện văn bản tự do tương ứng với các lĩnh vực lập luận thực tế; điều này làm cho nó đồng thời khó khăn hơn nhiều so với các chuẩn mực được tạo ra tổng hợp khác trong khi vẫn thực tế và có thể xử lý được cho các người chú thích con người giải quyết với độ chính xác cao. Chúng tôi đánh giá một loạt các LLM và kỹ thuật nhắc nhở trên bộ dữ liệu này và mô tả các khoảng cách còn lại để các kỹ thuật như chuỗi suy nghĩ thực hiện lập luận mạnh mẽ.¹

1 GIỚI THIỆU
Một thách thức lớn còn lại đối với các mô hình ngôn ngữ lớn (LLM) là khả năng thực hiện lập luận và lập kế hoạch (Valmeekam et al., 2023; Tang et al., 2023; Dziri et al., 2023). Nhiều phương pháp đã được đề xuất để tăng cường khả năng của mô hình về mặt này, bao gồm các chiến lược nhắc nhở như chuỗi suy nghĩ (Wei et al., 2022), tích hợp với các công cụ (Schick et al., 2023; Lyu et al., 2023; Ye et al., 2023), và nhúng mô hình trong các vòng lặp tìm kiếm (Bostrom et al., 2022; Creswell et al., 2023).

Liệu những cách tiếp cận này có giải quyết phù hợp những thiếu sót của LLM không? Điều này khó đo lường. Các tác vụ lập luận toán học có thể được tiếp cận theo cách hai giai đoạn (Gao et al., 2022; Ye et al., 2023): LLM dịch vấn đề thành một đặc tả chính thức sau đó được giải quyết bằng các công cụ thông thường. Các bộ dữ liệu khác như RuleTakers (Clark et al., 2020) và CLUTRR (Sinha et al., 2019) có thể giải quyết bằng các hệ thống dựa trên quy tắc (Kazemi et al., 2023a; Ye et al., 2023; Poesia et al., 2023). Cuối cùng, các bộ dữ liệu như SocialIQA (Sap et al., 2019) hoặc StrategyQA (Geva et al., 2021) liên quan đến hiểu biết thông thường tinh tế hơn thường đơn giản về mặt cấu trúc (tức là chỉ liên quan đến 1-2 bước lập luận). Điều còn thiếu là một chuẩn mực liên quan đến cả ngôn ngữ tự nhiên tinh vi và lập luận tinh vi.

Trong công trình này, chúng tôi trình bày MuSR: Lập luận Mềm Đa bước, một bộ dữ liệu tập trung vào các tác vụ liên quan đến lập luận dựa trên các câu chuyện văn bản. Các câu chuyện trong bộ dữ liệu của chúng tôi dài hàng trăm từ và trình bày bằng chứng theo những cách đòi hỏi kiến thức thông thường để hiểu. Sau đó, khi tất cả bằng chứng được đánh giá, việc đưa ra câu trả lời cuối cùng đòi hỏi sự cân nhắc kiểu "Hệ thống 2", điều này có dạng khác nhau cho mỗi lĩnh vực quan tâm. Các lĩnh vực mà chúng tôi đề cập ở đây, vụ giết người bí ẩn, việc đặt đồ vật, và phân công nhóm, liên quan đến lập luận thông thường về các tình huống vật lý (Bisk et al., 2020) và xã hội (Sap et al., 2019), lý thuyết tâm trí, và nhiều hơn nữa. Quan trọng là, những loại lập luận này phát sinh tự nhiên từ các mô tả văn bản của mỗi vấn đề.

¹ Trang web dự án có thể được tìm thấy tại https://github.com/Zayne-Sprague/MuSR

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Lấy mẫu một vấn đề... Xây dựng cây lập luận... Tạo ra một câu chuyện...

Các sự thật vàng
Lấy mẫu đệ quy từ một LLM để thiết lập lập luận đằng sau kết luận
Sophia là kẻ giết người.
Sophia có động cơ.
Sự thật: Cô ta có hận thù do mất tài sản
Sự thật: Emily đã lấy cắp di sản của Sophia
Sophia có cơ hội

Chỉ sử dụng một tập hợp nhỏ các sự thật quan sát được

Emily đã đi dạo cuối cùng trong công viên tối qua, mãi mãi, khi cuộc sống của cô ta bị tắt dưới mặt nạ của đêm tối. Nguyên nhân tử vong là một phát súng chí mạng từ một khẩu súng lục. Thám tử Winston đã vào cuộc và bắt đầu xem xét nghi phạm đầu tiên của anh, Sophia. Sophia đã có một chuỗi vận rủi gần đây khi ai đó mà cô nghĩ là bạn, Emily, đã lấy cắp toàn bộ di sản của cô. Những chuyến dạo buổi tối của cô trong công viên trở thành những bước đi hốt hoảng trong khi cô dàn xếp tài sản mà cô đã mất. Thám tử Winston uống một ngụm cà phê dài và bắt đầu thẩm vấn Sophia. 'Khá là tay bắn tỉa tôi thấy' - chỉ vào một bức ảnh cô ta cầm một con nai vừa bắn được. 'Vâng, bố tôi thích đưa tôi đi bắn súng' - Sophia trả lời một cách e ngại.

Xác thực (ví dụ, các sự thật được bao gồm)
Mô hình Lấy mẫu Sự thật

Kiến thức thông thường: Hận thù có thể là động cơ.
Tạo ra một phác thảo vụ giết người bí ẩn. Tạo tên nạn nhân, hai nghi phạm, ...
-Nạn nhân là Emily -Emily bị giết ở công viên -Sophia giết Emily -Sophia không bao giờ quên tài sản mà Emily đã lấy cắp từ cô ta -Richie cảm thấy tức giận khi John sa thải anh ta...

Viết một phần của vụ giết người bí ẩn mô tả Thám tử Winston tương tác với những người sau đây và tìm hiểu những sự thật sau: Sophia có hận thù do mất tài sản Emily lấy cắp di sản của Sophia...
cho mỗi phần: lặp lại cho đến khi hợp lệ

Xây dựng cây

LLM được kiểm tra
Vui lòng xác định kẻ giết người trong vụ giết người bí ẩn này. Kẻ giết người có động cơ, phương tiện và cơ hội [...]

LLM có thể giải quyết bí ẩn không?

Hình 1: Quy trình xây dựng bộ dữ liệu cho MuSR. Đầu tiên, chúng tôi tạo ra các sự thật vàng được sử dụng để suy luận câu trả lời chính xác (kẻ giết người trong trường hợp này). Sau đó, sử dụng một LLM, chúng tôi tạo ra một cây lập luận dẫn đến những suy luận đó từ các sự thật trong một câu chuyện kết hợp với kiến thức thông thường. Cuối cùng, chúng tôi tạo ra một câu chuyện lặp đi lặp lại từng phần một bằng cách sử dụng các sự thật được tạo ra trong bước 2, xác thực các thế hệ về tính nhất quán và khả năng nhớ lại sự thật.

Sự phù hợp giữa lập luận và bản thân văn bản cho phép chúng tôi tạo ra những bộ dữ liệu này tự động với sự hỗ trợ của LLM, sử dụng logic hỗ trợ để tạo ra các ví dụ mà chính các LLM không thể giải quyết một cách đáng tin cậy. Quy trình tạo bộ dữ liệu neuro-symbolic mới của chúng tôi được hiển thị trong Hình 1. Việc khôi phục lập luận từ chính câu chuyện cuối cùng là một vấn đề khó, có thể giải quyết bởi con người nhưng không thể bởi GPT-4 sử dụng bất kỳ số lượng chiến lược nhắc nhở và cách tiếp cận neuro-symbolic nào mà chúng tôi đã thử. Đáng chú ý, những tính chất này không đúng khi tạo ra các câu chuyện với các chiến lược nhắc nhở cơ bản hơn: yêu cầu GPT-4 định nghĩa và viết một vụ giết người bí ẩn trong một lần dẫn đến những câu chuyện không tự nhiên, đồng nhất có thể bao gồm sự không nhất quán, như chúng tôi hiển thị sau này.

Các đóng góp của chúng tôi như sau: (1) Chúng tôi giới thiệu một chuẩn mực lập luận mới, MuSR, bao gồm 756 ví dụ tổng cộng trên ba lĩnh vực thách thức các mô hình tiên tiến như GPT-4, Llama 2, và Vicuna. (2) Chúng tôi đề xuất một thuật toán để tạo ra các câu chuyện ngôn ngữ tự nhiên dựa trên cây lập luận. (3) Chúng tôi phân tích hiệu suất của LLM trên bộ dữ liệu của chúng tôi, tập trung vào các biến thể của nhắc nhở chuỗi suy nghĩ và các cách tiếp cận neuro-symbolic hiện có cho những vấn đề này.

2 BỐI CẢNH VÀ ĐỘNG LỰC

Chúng tôi khảo sát các nỗ lực bộ dữ liệu trước đây trong Bảng 1, sử dụng phân tích của chúng tôi để thiết lập nhu cầu cho một chuẩn mực lập luận văn bản mới. Đầu tiên, một số chuẩn mực trước đây không có văn bản tự nhiên. Những cái khác không kết hợp kiến thức thông thường và lập luận đa bước. Cuối cùng, chúng tôi muốn một bộ dữ liệu chứa cấu trúc trung gian thực tế và không thể giải quyết bằng quy tắc.

Nhiều bộ dữ liệu trước đây đơn giản là quá nhân tạo, bao gồm bAbI (Weston et al., 2016), BigTOM (Gandhi et al., 2023), ToMi (Le et al., 2019), RuleTakers (Clark et al., 2020), ProntoQA (Saparov & He, 2023; Saparov et al., 2023), và CLUTRR (Sinha et al., 2019). Những bộ dữ liệu này thường được thiết kế để kiểm tra một số khía cạnh của lập luận mô hình ngôn ngữ, nhưng chúng chỉ thách thức cho các cách tiếp cận LLM "thuần túy"; nhiều cái có thể giải quyết bằng các phương pháp dựa trên quy tắc. Hơn nữa, nhiều cái trong số này không liên quan đến bất kỳ lập luận kiến thức thông thường nào, một đặc điểm chính của lập luận từ văn bản.

EntailmentBank (Dalvi et al., 2021), Everyday Norms: Why Not (Sprague et al., 2022), và BoardgameQA (Kazemi et al., 2023b) trình bày các cài đặt đa bước đôi chút thách thức hơn, nhưng bao gồm các bộ sưu tập sự thật riêng biệt, không dựa trên các câu chuyện phức tạp. LLM có thể giải quyết hai bộ dữ liệu trước một cách khá dễ dàng ngay cả khi không tham khảo các sự thật thực tế. Vì những bộ dữ liệu này được

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 1: Các bộ dữ liệu lập luận gần đây được sử dụng để đo chuẩn LLM và các hệ thống neuro-symbolic được so sánh trên các chất lượng bộ dữ liệu khác nhau. Theo hiểu biết tốt nhất của chúng tôi, không có bộ dữ liệu trước đó nào bao gồm tất cả những chất lượng này. Ký hiệu ∼ biểu thị các bộ dữ liệu đủ điều kiện một phần cho tính chất. Thêm chi tiết về cách chúng tôi định nghĩa và phân loại những đặc điểm này có thể được tìm thấy trong Phụ lục B.

Tính chất
Bộ dữ liệu | Văn bản Tự nhiên | Kiến thức Thông thường | Đa bước | Cấu trúc trung gian | Không thể giải bằng quy tắc
bAbI | ✗ | ✗ | ✓ | ✓ | ✗
BigTOM | ∼ | ∼ | ∼ | ✗ | ✓
ToMi | ✗ | ✗ | ∼ | ✓ | ∼
RuleTakers | ✗ | ✗ | ✓ | ✓ | ✗
ProntoQA | ✗ | ✗ | ✓ | ✓ | ∼
CLUTRR | ✗ | ∼ | ∼ | ✓ | ∼
BoardgameQA | ∼ | ✓ | ✓ | ✓ | ✓
EntailmentBank | ∼ | ✗ | ✓ | ✓ | ✓
ENWN | ∼ | ✗ | ✓ | ✓ | ✓
SocialIQA | ∼ | ✓ | ✗ | ✗ | ✓
True Detective | ✓ | ✓ | ✓ | ✗ | ✓
MuSR | ✓ | ✓ | ✓ | ✓ | ✓

thiết kế để được giải quyết bằng cách sử dụng suy luận từng bước một cách rõ ràng, chúng có xu hướng tránh những loại suy luận mềm mại hơn phổ biến trong lập luận kiến thức thông thường. Các bộ dữ liệu kiến thức thông thường trước đây (Sap et al., 2019; Talmor et al., 2019; 2021), ngược lại, thường không liên quan đến lập luận đa bước.

Kỹ thuật Nhiều hệ thống lập luận đã được xây dựng để xử lý các trục lập luận cụ thể mà chúng tôi liệt kê trong Bảng 1, nhưng không thể xử lý một bộ dữ liệu thể hiện tất cả chúng. Một số hệ thống trước đây sử dụng một LLM trong một vòng lặp tìm kiếm liệt kê danh sách các sự thật, tạo ra kết luận một cách suy luận hoặc bắt cóc cho đến khi đạt được mục tiêu (Bostrom et al., 2022; Creswell et al., 2023; Kazemi et al., 2023a; Sprague et al., 2022; Hong et al., 2022). Tuy nhiên, những hệ thống này không xử lý các bối cảnh tự nhiên nơi các sự thật có thể được phân bố giữa các câu trên một câu chuyện dài. Các hệ thống khác liên quan đến các công cụ hoặc thuật toán neuro-symbolic để giúp giải quyết các vấn đề lập luận (Sclar et al., 2023; Gao et al., 2022; Ye et al., 2023); tuy nhiên, những cái này thường được chạy trên các bộ dữ liệu nhân tạo có thể dễ dàng dịch thành các đặc tả chính thức, và có khả năng hạn chế trong việc xử lý các loại lập luận mềm như kiến thức thông thường.

Một kỹ thuật linh hoạt là nhắc nhở, bao gồm các chiến lược chuỗi suy nghĩ khác nhau (Wei et al., 2022; Yao et al., 2023) và các kỹ thuật để đo tính nhất quán (Wang et al., 2023; Jung et al., 2022). Việc sử dụng những cách tiếp cận này để giải quyết các vấn đề lập luận từ đầu đến cuối đã được chứng minh là thách thức (Ye & Durrett, 2022; Zhang et al., 2023; Xue et al., 2023; Valmeekam et al., 2023). Bộ dữ liệu của chúng tôi rất phù hợp để kiểm tra giới hạn của những cách tiếp cận này: một hệ thống phải trích xuất sự thật từ các câu chuyện của chúng tôi, áp dụng kiến thức thông thường phù hợp để diễn giải những sự thật đó, và cuối cùng sử dụng lập luận đa bước để đến một câu trả lời.

Tại sao một chuẩn mực tổng hợp Một lựa chọn thay thế cho cách tiếp cận mà chúng tôi mô tả có thể là sử dụng tác giả con người. Lĩnh vực vụ giết người bí ẩn của chúng tôi được đại diện trong bộ dữ liệu True Detective gần đây (Del & Fishel, 2022), thu thập những vụ giết người bí ẩn do con người viết từ 5minutemystery.com.

Chúng tôi lập luận rằng một chuẩn mực tổng hợp là tốt hơn vì hai lý do. Đầu tiên, nó có thể mở rộng và có thể được làm mới khi các LLM có khả năng hơn được sản xuất. Ví dụ, nếu những bí ẩn trên trang web nói trên được giải quyết bởi các LLM tương lai, sẽ tốn kém và thách thức để thu thập một bộ dữ liệu mới, trong khi một chuẩn mực tổng hợp có thể được làm mới với lập luận phức tạp hơn và câu chuyện dài hơn. Việc tách biệt lập luận logic và tạo văn bản mang lại cho chúng tôi một đòn bẩy có thể tái sử dụng để sản xuất các trường hợp phức tạp hơn những gì hệ thống tự mình có thể giải quyết. Thứ hai, vì bộ dữ liệu của chúng tôi có thể được tái tạo, các vấn đề với rò rỉ bộ dữ liệu và tiếp xúc với dữ liệu kiểm tra trở thành ít quan tâm hơn. Cuối cùng, lưu ý rằng trong khi chuẩn mực của chúng tôi liên quan đến các câu chuyện do GPT-4 tạo ra, khung xây dựng quy trình xây dựng và các sự thật ẩn liên quan có nghĩa là các đầu ra được tạo ra cuối cùng không thể giải quyết tầm thường với GPT-4. Miễn là thông tin cơ bản được bảo tồn một cách trung thực trong câu chuyện, chúng tôi tin rằng các trường hợp dữ liệu của chúng tôi là các trường hợp kiểm tra hợp lệ cho bất kỳ hệ thống lập luận hoạt động tốt nào, điều mà chúng tôi xác minh bằng cách đo hiệu suất con người.

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Vụ Giết Người Bí Ẩn
Ai có phương tiện, động cơ và cơ hội?

F: John là kẻ giết người.
F: John có động cơ.
S(T): John đang thiếu tiền mặt.
S(T): Emily đã lấy cắp di sản của John.
C(T): Bị sa thải khi bạn cần tiền có thể là động cơ.

Xây dựng cây

Đặt Đồ Vật
Emma nghĩ cuốn sổ ghi chú ở đâu?

F: Ricky di chuyển cuốn sổ ghi chú đến piano.
F: Emma thấy cuốn sổ ghi chú di chuyển đến piano.
S(T): Emma giám sát quá trình sáng tạo của các nghệ sĩ với tư cách là nhà sản xuất.
S(T): Emma đang theo dõi tiến trình của Ricky.
C(T): Các nhà sản xuất thường quan sát quá trình sáng tạo.

Xây dựng cây

F: Danny thấy cuốn sổ ghi chú di chuyển đến piano.

Phân Công Nhóm
Chúng ta nên phân công mọi người như thế nào để tối đa hóa hiệu quả?

Xây dựng cây

S(T): John có vấn đề cờ bạc nghiêm trọng.

F: John có phương tiện.
F: John có cơ hội.
F: Emma di chuyển tai nghe đến bàn nhà sản xuất.

Các mục: sổ ghi chú, tai nghe
Địa điểm: piano, bàn nhà sản xuất, phòng thu
Nhiệm vụ: hát, nướng bánh

F: Lewis giỏi hát.
S(T): Lewis tham gia một nhóm hát tốt.
S(T): Lewis luôn thích biểu diễn.
C(T): Nhiều ca sĩ giỏi thích biểu diễn và hát tốt.

Xây dựng cây

F: Lewis kém nướng bánh.
F: Lewis và Clyde làm việc kém với nhau.
F: Clyde tạm được với nướng bánh.

Hình 2: Cây lập luận một phần hiển thị các sự thật vàng F, sự thật câu chuyện S(T), và sự thật kiến thức thông thường C(T) cho từng ba lĩnh vực của chúng tôi. Đường chấm chấm chỉ ra cây không hoàn chỉnh. Mỗi suy luận được lấy mẫu từ một LLM sẽ tạo ra hai sự thật kịch bản và một sự thật kiến thức thông thường trong thiết lập của chúng tôi.

3 TẠO MUSR

MuSR được cấu thành từ các vấn đề lập luận đa bước, mỗi vấn đề có gốc rễ trong một lĩnh vực cụ thể với cấu trúc logic độc đáo cho các giải pháp của nó. Để tạo ra những vấn đề này, chúng tôi có một phương pháp xây dựng với ba giai đoạn: Xây dựng Mẫu Cây, chịu trách nhiệm cho chiến lược lập luận và tập hợp sự thật vàng ban đầu F; Hoàn thành Cây Lập luận, tạo ra một cây T của các bước lập luận trung gian mở rộng trên F; và Tạo Câu chuyện, nhúng các sự thật được tạo từ cây vào một câu chuyện tự nhiên x. Quy trình này được mô tả ở đây và được đại diện trong Hình 1.

Thuật toán xây dựng cuối cùng tạo ra các bộ ba (F, T, x, {q1, ..., qn}, {a1, ..., an}). Chính thức, nhiệm vụ lập luận là dự đoán câu trả lời ai được đưa ra câu chuyện x và câu hỏi cần trả lời qi. Tập hợp sự thật vàng F và cây lập luận T được sử dụng như một phần của quy trình tạo ra nhưng thường không được cung cấp cho một LLM tại thời điểm kiểm tra. Trong suốt quy trình, chúng tôi sử dụng Prompt để biểu thị việc sử dụng một LLM được nhắc nhở để lấy mẫu một đầu ra có điều kiện trên một biến khác.

3.1 XÂY DỰNG MẪU CÂY

Mỗi lĩnh vực của chúng tôi bắt đầu với một tập hợp sự thật cấp cao F, và một tập hợp các cặp câu hỏi-trả lời ((q1, a1), ..., (qn, an)). Ví dụ, trong các vụ giết người bí ẩn của chúng tôi, câu hỏi duy nhất là "ai là kẻ giết người?" và F chứa thông tin thực tế về mỗi nghi phạm (John là kẻ giết người, John có cơ hội). Thông tin cho mỗi lĩnh vực có trong Phần 4, với các sự thật được hiển thị trong Hình 2.

Chính thức hơn, F là một đối tượng có cấu trúc với yêu cầu tồn tại một chương trình Φ sao cho Φ(F, qi) = ai cho tất cả i. F cũng có thể được đại diện bằng ngôn ngữ tự nhiên thông qua mở rộng mẫu. Các câu hỏi q và câu trả lời a của chúng tôi được lập mẫu. Ở giai đoạn này, chúng tôi cũng tạo ra các sự thật bổ sung G để tăng tính đa dạng và giúp mở rộng câu chuyện sau này. Điều này được thực hiện bằng cách lấy mẫu từ các danh sách được tuyển chọn hoặc bằng cách lấy mẫu từ LLM (ví dụ, khi một tập hợp đối tượng kết hợp cần được tạo ra cho việc đặt đồ vật). Những sự thật này khác với những sự thật trong F ở chỗ chúng không được lập mẫu mà thay vào đó là các sự thật thực tế phải được bao gồm trong câu chuyện. Đầu ra của giai đoạn này là một bộ ba (F, G) chứa các sự thật cốt lõi được sử dụng để trả lời câu hỏi và một tập hợp các sự thật đa dạng được sử dụng để tạo cho mỗi câu hỏi những cốt truyện độc đáo.

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

3.2 HOÀN THÀNH CÂY LẬP LUẬN

Một khi bộ sưu tập các sự thật F đã được xây dựng, chúng tôi tạo ra cây lập luận cho từng sự thật riêng lẻ, fi, trong tập hợp F. Một cây lập luận T = (s, T1, ..., Tm) là một cấu trúc dữ liệu đệ quy đại diện cho một câu lệnh s được hỗ trợ bởi một bộ sưu tập các câu lệnh khác: phải có trường hợp s được suy ra logic bởi sT1, ..., sTm. Gốc của mỗi cây là một sự thật sT1 = fi nơi fi ∈ F. Chúng tôi bao gồm các sự thật từ G trong khi nhắc nhở mô hình ngôn ngữ để các sự thật được tạo ra bao gồm thông tin đa dạng và cuối cùng giúp tạo ra những câu chuyện thú vị trong các giai đoạn sau.

Những cây này được tự động sản xuất từ các sự thật gốc fi thông qua việc lấy mẫu đệ quy từ một LLM, trong trường hợp của chúng tôi là GPT-4. Quy trình này được hiển thị trong Thuật toán 1 trong Phụ lục G.1. Chúng tôi lặp lại quy trình này đến một độ sâu được chỉ định, cuối cùng tạo ra một tập hợp các sự thật lá suy luận ra sự thật ban đầu fi nhưng đòi hỏi lập luận đa bước để làm như vậy. Những sự thật này được chia thành hai loại: sự thật cụ thể kịch bản, phải được bao gồm trong câu chuyện cuối cùng, và sự thật kiến thức thông thường, sẽ không được nêu nhưng nên là những sự thật mà hầu hết mọi người sẽ đồng ý là đúng. Chúng tôi biểu thị những tập hợp sự thật kịch bản và sự thật kiến thức thông thường này bằng S(T) và C(T), tương ứng, như được hiển thị trong Hình 2.

Quy trình tạo ra của chúng tôi liên quan đến việc kiểm soát độ sâu và hình dạng của cây được tạo ra. Chúng tôi cũng muốn đảm bảo rằng không có chuyển tiếp trống trong cây của chúng tôi (ví dụ, sự thật fi được nêu rõ ràng trong một nút lá) hoặc "đường tắt" lập luận. Để đảm bảo điều này, chúng tôi sử dụng một bộ sưu tập các trình xác thực cây, V = (v1, ..., vk), cho mỗi lĩnh vực. Những cái này thường là tìm kiếm từ khóa đơn giản ngăn chặn các từ khóa xuất hiện trong suy luận, ví dụ, ngăn chặn "động cơ" xuất hiện trong suy luận cấp thấp hơn trong lĩnh vực vụ giết người bí ẩn để người đọc bị buộc phải suy luận động cơ. Để biết thêm chi tiết về trình xác thực cho mỗi lĩnh vực, xem Phụ lục G.

Tại mỗi bước trong cây, cho một nút với văn bản s chúng tôi lấy mẫu T1, ..., Tm ∼ PromptLM(T1, ..., Tm | s). Sau đó chúng tôi lọc đầu ra này theo các trình xác thực V. Chúng tôi thử lại lời nhắc này đến ba lần, và nếu chúng tôi không thể rút ra một mẫu hợp lệ, cắt tỉa nhánh của cây lập luận, làm cho suy luận hiện tại trở thành một nút lá. Chúng tôi lặp lại quy trình này cho đến khi cây ở độ sâu mục tiêu. Hình 2 hiển thị một ví dụ về cây kết quả.

3.3 TẠO CÂU CHUYỆN

Trong giai đoạn cuối cùng, chúng tôi sử dụng các sự thật lá cụ thể kịch bản S(T) từ cây lập luận. Mục tiêu của chúng tôi là tạo ra một câu chuyện bằng cách lấy mẫu x̂ ∼ Prompt(x | S(T)) từ một LLM với một lời nhắc thích hợp. Tuy nhiên, đối với một câu chuyện dài và phức tạp, S(T) không phải lúc nào cũng được phản ánh chính xác trong x; một số sự thật có thể bị bỏ khi mô hình tạo ra nhiều hơn một bản tóm tắt về tình huống, ví dụ.

Để giải quyết điều này, thay vào đó chúng tôi chia S(T) thành các phần liên quan đến một lựa chọn trả lời cụ thể (ví dụ, thông tin liên quan đến một kẻ giết người có thể cụ thể). Sau đó chúng tôi có thể sử dụng tập hợp con này để nhắc nhở GPT4 cho một "chương" với một danh sách sự thật nhỏ hơn. Một khi mọi chương đã được tạo ra, chúng tôi nối tất cả các chương lại với nhau thành một câu chuyện. Một số lĩnh vực sử dụng các lời nhắc bổ sung để "làm mượt" câu chuyện cuối cùng khi cần thiết. Bởi vì các câu chuyện của chúng tôi không cần được sản xuất bởi một cuộc gọi LLM, chúng có thể mở rộng đến hơn 1000 từ (trong bộ dữ liệu này) và về lý thuyết thậm chí còn dài hơn. Chúng tôi gọi quy trình này là chương hóa; quy trình tổng thể được lấy cảm hứng rộng rãi bởi Yang et al. (2022).

4 CÁC LĨNH VỰC MUSR

4.1 VỤ GIẾT NGƯỜI BÍ ẨN: LẬP LUẬN SUY LUẬN XÃ HỘI VÀ VẬT LÝ

Vụ giết người bí ẩn là một lĩnh vực cổ điển đòi hỏi nhiều loại lập luận khác nhau. Chúng đã được khám phá trong bối cảnh lập luận LLM trước đây (Frermann et al., 2018; Del & Fishel, 2022); tuy nhiên, của chúng tôi là công trình đầu tiên tiếp cận quy mô của các vụ giết người bí ẩn do con người viết với dữ liệu thách thức tổng hợp. Vụ giết người bí ẩn tạo ra lập luận vật lý và xã hội trong các tập hợp sự thật S(T) và C(T). Cụ thể, các kịch bản xã hội độc đáo và phức tạp phát sinh tự nhiên trong các vụ giết người bí ẩn dẫn đến động cơ giết người và có thể đòi hỏi hiểu biết về các chuẩn mực xã hội. Giải quyết một vụ giết người bí ẩn cũng đòi hỏi lập luận tạm thời về việc một người có cơ hội phạm tội.

Trong lĩnh vực này, Φ(F, qi) được định nghĩa là một thuật toán có thể tìm nghi phạm với ba sự thật trong F. Cụ thể, kẻ giết người và câu trả lời ai là nghi phạm với các sự thật "x có phương tiện", "x có động cơ", và "x có cơ hội". Để xây dựng F sao cho Φ(F, qi) sẽ tạo ra câu trả lời chính xác ai, chúng tôi tạo ra hai nghi phạm và ngẫu nhiên chỉ định một làm kẻ giết người. Sau đó chúng tôi điền vào tập hợp F với ba sự thật chứng minh phương tiện, động cơ và cơ hội. Đối với nghi phạm vô tội, chúng tôi ngẫu nhiên chọn hai trong số các sự thật được sử dụng để chứng minh tội lỗi, sau đó thêm những cái này và một "sự thật đáng ngờ" bổ sung vào tập hợp F, tạo ra một tập hợp không thiết lập tội lỗi. Một sự thật đáng ngờ không có tác động đến Φ(F, qi) và không nên thêm bất kỳ thông tin bổ sung nào liên quan đến vụ giết người; ví dụ, "x có liên kết với một băng đảng, và điều này đáng ngờ".

Tổng cộng, F được cấu thành từ ba sự thật cho mỗi nghi phạm được chuyển đến giai đoạn tạo cây lập luận. Cây lập luận sẽ mở rộng các mô tả cho những sự thật này, G, chẳng hạn như sự thật rằng ai đó có thể có cơ hội giết một nạn nhân trong phòng học của họ bằng cách có chìa khóa phòng học, có thể được mở rộng đệ quy để mô tả tại sao họ có chìa khóa phòng học. Thêm chi tiết về xây dựng có thể được tìm thấy trong Phụ lục G.2.

4.2 ĐẶT ĐỒ VẬT: LẬP LUẬN QUAN SÁT VÀ LÝ THUYẾT TÂM TRÍ

Lấy cảm hứng từ các bộ dữ liệu lý thuyết tâm trí (Le et al., 2019; Gandhi et al., 2023) chúng tôi chọn một lĩnh vực tập trung vào một nhóm người di chuyển các mục xung quanh đến các địa điểm khác nhau. Những người khác trong câu chuyện hoặc thấy mỗi mục di chuyển hoặc không vì các lý do khác nhau. Sau đó người đọc được hỏi nơi một người sẽ tìm kiếm một mục nếu được yêu cầu tìm kiếm nó, nơi lần di chuyển cuối cùng họ thấy là nơi có khả năng nhất họ sẽ bắt đầu tìm kiếm. Bởi vì điều này, Đặt Đồ Vật đòi hỏi lập luận không gian và vật lý cũng như lập luận về nhận thức của mọi người trong S(T) và C(T). Người đọc được kiểm tra thêm bằng cách phải xác định các quan sát của một người cụ thể, mô hình hóa trạng thái niềm tin của họ về nơi một mục đang ở. Đáng chú ý, bộ dữ liệu của chúng tôi có những câu chuyện dài hơn và các kịch bản tinh vi hơn so với các bộ dữ liệu lý thuyết tâm trí trước đây.

Trong lĩnh vực này, qi hỏi nơi một người tin rằng một mục đang ở trong câu chuyện. Câu trả lời, ai, sau đó là địa điểm cuối cùng người đó thấy mục di chuyển trong câu chuyện, hoặc nơi mục ban đầu nếu họ không bao giờ thấy mục di chuyển. Φ(F, qi) được hỗ trợ bởi một tập hợp các di chuyển tuần tự F, nơi mỗi di chuyển là một bộ sưu tập quan sát biểu thị liệu mỗi người trong câu chuyện có thấy di chuyển hay không. Một di chuyển được biểu thị như một sự thật "P di chuyển I đến L" nơi P là một người, I là một mục, và L là một địa điểm, tương ứng. Đối với mỗi di chuyển, mỗi người khác ngoài người di chuyển mục được cho một cơ hội c (đặt thành 0.33 cho các thí nghiệm của chúng tôi) để thấy di chuyển, sẽ thêm hoặc "P' thấy I di chuyển đến L." hoặc "P' không thấy I di chuyển đến L." vào F.

Cây lập luận sau đó tập trung vào việc giải thích tại sao ai đó có thể hoặc có thể không quan sát được một di chuyển. Điều này tích hợp lập luận kiến thức thông thường: ví dụ, một barista đang bận làm latte art cho một khách hàng và không quan sát được người quản lý di chuyển một mục từ tủ lạnh đến phòng lưu trữ. Thêm chi tiết có thể được tìm thấy trong Phụ lục G.3.

4.3 PHÂN CÔNG NHÓM: LẬP LUẬN XÃ HỘI VÀ RÀNG BUỘC

Phân Công Nhóm lấy cảm hứng từ các vấn đề phân công và MAX-SAT (Pan et al., 2023). Trong lĩnh vực này, người đọc phải xác định việc phân công tối ưu nhất của mọi người cho các nhiệm vụ nơi mỗi người có thể được phân công cho một nhiệm vụ. Bởi vì có ba người và hai nhiệm vụ, hai người phải làm việc cùng nhau, thêm một động lực xã hội vào việc phân công. S(T) và C(T) thường liên quan đến suy luận về kinh nghiệm quá khứ và sở thích cá nhân của một cá nhân về lý do họ thực hiện hoặc không thực hiện tốt một kỹ năng. Chúng cũng bao gồm lập luận về sức mạnh của mối quan hệ giữa hai người trong môi trường làm việc, đòi hỏi lập luận xã hội.

F đại diện cho những mối quan hệ này thông qua điểm số số liệu tương ứng với kỹ năng của mỗi người cho một nhiệm vụ và điểm số làm việc nhóm số. Cụ thể, ba người mỗi người được gán các giá trị điểm cho khả năng nhiệm vụ (0, 1, hoặc 2) và cho các mối quan hệ cặp đôi của họ. Để giải quyết một câu hỏi Phân Công Nhóm, Φ(F, qi) có thể liệt kê các phân công thêm điểm kỹ năng và điểm làm việc nhóm như một điểm cho phân công tổng thể và sau đó lấy phân công tối đa hóa điểm này, ai = Φ(F, qi) = max ai∈A skill(ai) + teamwork(ai). Chúng tôi thấy rằng việc sử dụng một số lượng nhỏ giá trị cho kỹ năng dịch tốt thành các câu lệnh ngôn ngữ tự nhiên mềm nơi quyết định của người chú thích con người tôn trọng quy trình lập luận cứng cơ bản. Chúng tôi tiếp tục thực thi rằng phân công tối ưu vượt trội hơn tất cả các phân công khác ít nhất 2 điểm.

Cây lập luận sau đó mô tả các yếu tố góp phần vào những kỹ năng và mối quan hệ này. Thêm chi tiết có thể được tìm thấy trong Phụ lục G.4.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

5 THÍ NGHIỆM

5.1 XÁC THỰC BỘ DỮ LIỆU

Chúng tôi tạo ra ba bộ dữ liệu cấu thành MuSR bằng cách sử dụng GPT-4 theo quy trình được phác thảo trong các phần trước. Xem Phụ lục C để thảo luận về việc sử dụng các mô hình khác ngoài GPT-4. Bảng 2 mô tả thống kê của các bộ dữ liệu được tạo ra của chúng tôi. Chúng tôi cung cấp các ví dụ từ mỗi bộ dữ liệu trong Phụ lục F.

Bảng 2: Thống kê bộ dữ liệu cho MuSR, bao gồm số lượng trường hợp, số bước, số sự thật kiến thức thông thường, và hiệu suất của hệ thống dựa trên quy tắc trên lĩnh vực.

| | Kích thước | # Bước | # CS | Dựa trên quy tắc |
|---|---|---|---|---|
| Vụ Giết Người Bí Ẩn | 250 | 10 | 9 | 50.0 |
| Đặt Đồ Vật | 256 | 11 | 6 | 35.9 |
| Phân Công Nhóm | 250 | 10 | 9 | - |

Chúng tôi không nhằm mục đích đánh giá chính thức sự trôi chảy hoặc tính liền mạch của các câu chuyện được tạo ra của chúng tôi. GPT-4 tạo ra những câu chuyện, dựa trên sự kiểm tra của chúng tôi, rất mạnh theo những thuộc tính này. Chúng tôi cũng không đánh giá "sự hợp lý" nội tại của kiến thức thông thường, mà chúng tôi cũng thấy rất cao; thay vào đó chúng tôi chọn đánh giá điều này theo cách từ đầu đến cuối dựa trên liệu con người có thể lập luận chính xác về câu trả lời đúng hay không.

Hiệu suất dựa trên quy tắc Bảng 2 cũng hiển thị hiệu suất của hai hệ thống dựa trên quy tắc mà chúng tôi phát triển để kiểm tra sức khỏe tâm thần cho các bộ dữ liệu của chúng tôi. Đường cơ sở quy tắc Vụ Giết Người Bí Ẩn tìm kiếm nghi phạm nào có chương dài nhất trong bối cảnh. Đặt Đồ Vật tìm kiếm địa điểm được đề cập nhiều nhất. Chúng tôi thấy rằng mỗi cái này gần với cơ hội ngẫu nhiên (được báo cáo trong Bảng 5).

Hiệu suất con người Để xác thực rằng các câu trả lời được rút ra từ F thực tế khớp với những gì có thể được rút ra từ các câu chuyện của chúng tôi, chúng tôi đã tiến hành một đánh giá con người về chất lượng bộ dữ liệu. Tổng cộng 7 người chú thích được sử dụng, 4 trong số họ là tác giả của bài báo và 3 trong số họ là sinh viên đại học được thuê không quen thuộc với các bộ dữ liệu. Người chú thích được đưa ra lời nhắc "chuỗi suy nghĩ+" chính xác mà chúng tôi đã đánh giá LLM, được mô tả trong phần tiếp theo.

Bảng 3: Cái nhìn chi tiết về điểm chú thích con người cho mỗi lĩnh vực bao gồm điểm thấp nhất, điểm cao nhất, điểm trung bình, và điểm bỏ phiếu đa số. Không có mô hình hoặc biến thể lời nhắc nào ghi điểm cao hơn bất kỳ người chú thích nào của chúng tôi.

| | Thấp nhất | Cao nhất | Trung bình | Đa số |
|---|---|---|---|---|
| Vụ Giết Người Bí Ẩn | 88.2 | 94.1 | 92.1 | 94.1 |
| Đặt Đồ Vật | 85.0 | 95.0 | 90.0 | 95.0 |
| Phân Công Nhóm | 91.1 | 100.0 | 95.1 | 100.0 |

Chúng tôi chú thích ba lần giữa 34 trường hợp cho Vụ Giết Người Bí Ẩn và Phân Công Nhóm và 40 trường hợp cho Đặt Đồ Vật. Bảng 3 hiển thị điểm của người chú thích được chia nhỏ theo điểm thấp nhất, cao nhất và trung bình cho mỗi người chú thích; trung bình dựa trên tất cả các cặp (trường hợp, người chú thích), hơn 100 cho mỗi lĩnh vực. Người chú thích tốt nhất của chúng tôi trên tất cả các lĩnh vực là một trong những sinh viên đại học không quen thuộc với quy trình xây dựng bộ dữ liệu. Chúng tôi cũng hiển thị chú thích đa số. Quan trọng là, đa số cao hơn người chú thích trung bình, cho thấy nhiều lỗi người chú thích đơn giản là do thiếu chú ý và hội đồng ba người chú thích của chúng tôi có thể cùng nhau đưa ra câu trả lời đúng thông qua bỏ phiếu. Nhìn chung, chúng tôi tin rằng đa số này phản ánh trần hiệu suất con người trên những bộ dữ liệu này, chứng minh rằng nó rất cao.

Loại bỏ quy trình tạo ra của chúng tôi Cuối cùng, chúng tôi nhằm mục đích thiết lập rằng quy trình mà chúng tôi đã trình bày cho đến nay trong bài báo này thực sự là cần thiết để tạo ra dữ liệu chất lượng cao. Bảng 4 hiển thị một tập hợp các loại bỏ trên quy trình xây dựng của chúng tôi trên 25 ví dụ cho mỗi lĩnh vực, được đo bằng một số chỉ số. Đầu tiên, chúng tôi theo dõi độ dài (Len) và sự đa dạng (Div) của bối cảnh, được đo bằng self-BLEU của một câu từ một câu chuyện so với tất cả các câu chuyện khác. Chúng tôi cũng tính Fact Recall (R), là tỷ lệ phần trăm số lượng sự thật được bao hàm trong bối cảnh từ các nút lá cây lập luận vàng, sử dụng GPT-4 để kiểm tra sự bao hàm của mỗi sự thật. Cuối cùng, chúng tôi đánh giá hiệu suất của GPT-4. Mặc dù mục tiêu của chúng tôi là tạo ra một bộ dữ liệu thách thức, trong bối cảnh của bảng này, hiệu suất GPT-4 thấp thường có nghĩa là các ví dụ mơ hồ hoặc không thể giải quyết được.

Nhắc nhở cơ bản cho bất kỳ lĩnh vực nào tạo ra những câu chuyện cực kỳ ngắn (thường mười câu về độ dài). Chúng cũng thường rất giống nhau. Hiệu suất GPT-4 khá thấp; theo kinh nghiệm, chúng tôi thấy những câu chuyện này có các giải pháp giả mạo. Việc sử dụng lấy mẫu đa dạng để cải thiện lập luận tạo ra một

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 4: Các biến thể của quy trình tạo bộ dữ liệu của chúng tôi. Chúng tôi so sánh với một cách tiếp cận nhắc nhở một lần đơn giản và một cách tiếp cận sử dụng các sự thật hạt giống G để thêm đa dạng, tạo ra những câu chuyện đơn giản và chất lượng kém. Sau đó chúng tôi loại bỏ chương hóa và trình xác thực cây, cho thấy những cái này làm giảm độ dài, khả năng nhớ lại sự thật trong câu chuyện, và độ chính xác; cái sau thường chỉ ra những câu chuyện không nhất quán.

| Loại bỏ | Vụ Giết Người Bí Ẩn | | | | Đặt Đồ Vật | | | | Phân Công Nhóm | | | |
|---|---|---|---|---|---|---|---|---|---|---|---|---|
| | Len | Div | R | Acc | Len | Div | R | Acc | Len | Div | R | Acc |
| Chỉ Nhắc | 280 | 0.30 | - | 76 | 200 | 0.26 | - | 64 | 172 | 0.34 | - | 80 |
| Lấy mẫu Đa dạng | 422 | 0.25 | - | 60 | 404 | 0.24 | - | 39 | 448 | 0.26 | - | 84 |
| MuSR −chapt−validators | 428 | 0.24 | 67 | 60 | 380 | 0.27 | 83 | 78 | - | - | - | - |
| MuSR −validators | 924 | 0.24 | 93 | 60 | 793 | 0.25 | 82 | 65 | - | - | - | - |
| MuSR | 900 | 0.25 | 95 | 84 | 777 | 0.25 | 87 | 58 | 503 | 0.25 | 81 | 68 |

tập hợp các ví dụ lập luận tốt hơn bao gồm một sự tăng nhẹ về độ dài, nhưng một lần nữa, các vấn đề không phải lúc nào cũng có thể giải quyết được, cũng như các giải pháp không phải lúc nào cũng nhất quán với sự thật cơ bản.

Khi chúng tôi giới thiệu cây lập luận (ba biến thể MuSR), chúng ta có thể thấy hiệu suất của GPT-4 vẫn thấp. Điều này là do việc nhắc nhở GPT-4 tạo ra một câu chuyện từ tất cả các sự thật thường dẫn đến những câu chuyện ngắn hơn và có thể bỏ sót sự thật: chỉ 62% các sự thật từ cây lập luận ban đầu được bao hàm trong câu chuyện kết quả cho các vụ giết người bí ẩn. Bằng cách giới thiệu "chương hóa", chúng ta có thể thấy rằng khả năng nhớ lại sự thật tăng lên và độ dài câu chuyện gần như tăng gấp đôi kích thước trong khi duy trì sự đa dạng cao. Cuối cùng, các trình xác thực cây được thêm vào để đảm bảo cây lập luận được xây dựng theo một tập hợp quy tắc (như không đề cập đến các mục chính trong suy luận) khả năng nhớ lại sự thật tăng một chút và hiệu suất của GPT-4 tăng đáng kể đối với Vụ Giết Người Bí Ẩn. Phân Công Nhóm không yêu cầu chương hóa hoặc trình xác thực để tạo ra các ví dụ tốt và do đó không có loại bỏ cho những thành phần này.

5.2 ĐO CHUẨN VỚI MUSR

Bảng 5: Điểm cho LLM trên từng lĩnh vực trong MuSR cũng như đánh giá con người sử dụng chiến lược CoT+.

| | MM | OP | TA |
|---|---|---|---|
| ngẫu nhiên | 50.0 | 24.6 | 33.3 |
| GPT-4 | 80.4 | 60.9 | 68.4 |
| GPT-3.5 | 61.6 | 46.9 | 40.4 |
| Llama2 70b Chat | 48.8 | 42.2 | 44.8 |
| Llama2 7b Chat | 50.8 | 29.3 | 36.8 |
| Vicuna 7b v1.5 | 48.4 | 29.7 | 26.4 |
| Vicuna 13b v1.5 | 50.8 | 34.4 | 32.0 |
| Vicuna 33b v1.3 | 49.6 | 31.2 | 30.0 |
| Đánh giá Con người | 94.1 | 95.0 | 100.0 |

Bây giờ chúng tôi đánh giá một loạt LLM (Brown et al., 2020; OpenAI, 2023; Touvron et al., 2023; Chiang et al., 2023) với nhiều chiến lược nhắc nhở. Cụ thể, chúng tôi so sánh nhắc nhở một lần, chuỗi suy nghĩ (Wei et al., 2022, CoT), và một biến thể của chuỗi suy nghĩ mà chúng tôi gọi là "CoT+". CoT+ sử dụng một mô tả văn bản được thiết kế của chiến lược lập luận của lĩnh vực được mô tả trong Phần 3. Các lời nhắc cho CoT+ có thể được xem trong Phụ lục I.1 Cuối cùng, chúng tôi kiểm tra nhiều thuật toán neuro-symbolic trên các lĩnh vực phù hợp nhất với các cài đặt mà những thuật toán đó được thiết kế.

Kết quả không-shot trên LLM Đầu tiên chúng tôi tập trung vào khả năng của các mô hình ngôn ngữ lớn để giải quyết bộ dữ liệu này không-shot, chỉ được đưa ra lời nhắc. Chúng tôi xây dựng bộ dữ liệu với kịch bản này trong tâm trí, nhưng cũng đánh giá một lời nhắc 1-shot trong Bảng 7.

Bảng 5 hiển thị kết quả trên LLM của chúng tôi với lời nhắc CoT+ cũng như hiệu suất con người. Các mô hình ngôn ngữ dựa trên Llama 2 và Vicuna có thể đạt được trên mức cơ hội cho mỗi lĩnh vực nhưng chỉ một chút. Mặc dù những mô hình này thường được so sánh với các biến thể GPT, chúng không thể vượt qua GPT-3.5 trên hai trong số ba lĩnh vực, với Phân Công Nhóm là lĩnh vực duy nhất mà các mô hình Vicuna vượt trội một chút. GPT-4 hoạt động tốt nhất trong tất cả các mô hình mà chúng tôi đã kiểm tra, nhưng vẫn kém hiệu suất so với con người. Mặc dù GPT-4 là công cụ quan trọng trong việc tạo ra bộ dữ liệu này, nó không có khả năng lập luận để giải quyết nó từ đầu đến cuối. Một phân tích định tính nhỏ về một số lớp lỗi được thể hiện bởi GPT-3.5-turbo và GPT-4 được thảo luận trong Phụ lục D.

Kết quả trên Các Biến thể Lời nhắc Bảng 7 hiển thị GPT-3.5 và GPT-4, hai mô hình hoạt động tốt nhất trên MuSR, được đánh giá với các chiến lược nhắc nhở khác nhau. Nhìn chung, hiệu suất tốt nhất được nhìn thấy khi mô hình được đưa ra một ví dụ một-shot với các biến thể lời nhắc "1-shot CoT+" hoặc "Few-shot CoT+". Tuy nhiên, việc thêm nhiều ví dụ hơn không phải lúc nào cũng tốt hơn. Mặc dù có những bước nhảy đáng kể về hiệu suất trên một số lĩnh vực, các mô hình vẫn kém hiệu suất so với đa số con người.

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 7: Đánh giá các chiến lược nhắc nhở phổ biến khác nhau cho GPT-3.5 và GPT-4, hai mô hình mạnh nhất của chúng tôi. "Regular" chỉ cung cấp bối cảnh và câu hỏi. "CoT" yêu cầu mô hình suy nghĩ từng bước. "CoT+" bao gồm mô tả văn bản của chiến lược lập luận, và "1-Shot CoT+" bao gồm một ví dụ đã giải quyết. "Few-Shot CoT+" mở rộng "1-Shot CoT+" với 3 ví dụ (3 ví dụ chạm đến giới hạn token cho GPT-4)

| | Vụ Giết Người Bí Ẩn | | Đặt Đồ Vật | | Phân Công Nhóm | |
|---|---|---|---|---|---|---|
| | GPT-3.5 | GPT-4 | GPT-3.5 | GPT-4 | GPT-3.5 | GPT-4 |
| Regular | 59.2 | 64.8 | 44.5 | 43.0 | 41.2 | 64.0 |
| CoT | 56.0 | 65.6 | 48.4 | 41.8 | 46.4 | 64.4 |
| CoT+ | 61.6 | 80.4 | 46.9 | 60.9 | 40.4 | 68.4 |
| 1-Shot CoT+ | 70.0 | 86.0 | 56.2 | 72.3 | 50.4 | 88.4 |
| Few-Shot CoT+ | 68.4 | 84.8 | 58.2 | 71.5 | 78.8 | 89.6 |

Bảng 6: Điểm cho một lựa chọn các hệ thống lập luận trên lĩnh vực phù hợp nhất với khả năng của chúng.

| Vụ Giết Người Bí Ẩn |
|---|
| GPT-4 CoT+ | 80.4 |
| Decomposed Prompting | 77.6 |
| Decomposed Prompting 1-Shot | 86.0 |

| Đặt Đồ Vật |
|---|
| GPT-4 CoT+ | 60.9 |
| SymbolicTOM | 23.8 |

| Phân Công Nhóm |
|---|
| GPT-4 CoT+ | 68.4 |
| PAL | 77.2 |
| PAL 1-Shot | 87.2 |

Kết quả trên Các Cách Tiếp Cận Neuro-symbolic Chúng tôi tin rằng bộ dữ liệu này là một bàn kiểm tra lý tưởng cho các cách tiếp cận neuro-symbolic khác nhau. Ngoài chuỗi suy nghĩ cơ bản, chúng tôi không biết về một cách tiếp cận duy nhất nào xử lý tự nhiên tất cả các loại lập luận trong bộ dữ liệu của chúng tôi và mở rộng đến các ví dụ có độ khó mà chúng tôi trình bày. Kết quả là, chúng tôi trình bày ba phương pháp khác nhau trong Bảng 6 mỗi cái được điều chỉnh cho một lĩnh vực và được đánh giá trong lĩnh vực đó. Chúng tôi mô tả những cách tiếp cận này ở đây và trong Phụ lục E

Trong lĩnh vực Vụ Giết Người Bí Ẩn, chúng tôi triển khai một biến thể của Decomposed Prompting (Khot et al., 2023) bằng cách áp đặt thủ công sự phân tích của động cơ, phương tiện và cơ hội và nhắc nhở GPT-4 quyết định về mỗi nghi phạm cho mỗi sự thật. Sau đó chúng tôi quyết định kẻ giết người dựa trên ai có nhiều sự thật chứng minh tội lỗi nhất, với lựa chọn ngẫu nhiên trong trường hợp hòa. Mặc dù phù hợp tốt với chiến lược lập luận, độ chính xác thấp hơn việc nhắc nhở GPT-4 từ đầu đến cuối.

Tiếp theo chúng tôi sử dụng SymbolicTOM (Sclar et al., 2023) trên lĩnh vực Đặt Đồ Vật với các điều chỉnh nhỏ. Cụ thể, chúng tôi sử dụng GPT-3.5 để tạo ra trạng thái kết quả của một câu sau đó được sử dụng trong thuật toán tạo đồ thị. Độ chính xác thấp của SymbolicTOM chủ yếu được quy cho việc chọn các thực thể chính từ các câu không được lập mẫu như bộ dữ liệu gốc (Le et al., 2019). Bởi vì các bối cảnh tự nhiên hơn, hành động và quan sát của các thực thể có thể trải rộng nhiều đoạn văn thay vì được cô lập trong một câu. Điều này giới thiệu một mức độ phức tạp mới cho những phương pháp neuro-symbolic này, và các cách tiếp cận trước đây về ToM không thể tổng quát hóa ở đây.

Cuối cùng, chúng tôi chạy một biến thể của Program-Aided Language Models (Gao et al., 2022) trên lĩnh vực Phân Công Nhóm. Từ câu chuyện, PAL phải suy luận các giá trị số cho mức độ kỹ năng và làm việc nhóm của mỗi người và cặp. Một khi điều này được thực hiện, chúng tôi đưa cho nó một mô tả về chiến lược lập luận cho Phân Công Nhóm, mà nó triển khai trong một chương trình và giải quyết trả về phân công với điểm cao nhất. Chúng tôi thấy rằng giải pháp này kết hợp khá tốt với lĩnh vực, vượt trội hơn các mô hình từ đầu đến cuối trên cả cài đặt không-shot và một-shot, nhưng không đạt được hiệu suất con người tổng hợp.

6 KẾT LUẬN

Trong bài báo này, chúng tôi đã giới thiệu Lập luận Mềm Đa bước (MuSR) một bộ dữ liệu lập luận được viết với các câu chuyện tự nhiên trình bày các kịch bản lập luận phức tạp liên quan đến các chiến lược lập luận khác nhau. Chúng tôi đã trình bày một phương pháp tạo bộ dữ liệu neuro-symbolic để xây dựng các trường hợp của bộ dữ liệu của chúng tôi, có thể được mở rộng về độ phức tạp khi các mô hình mạnh hơn xuất hiện. Đánh giá con người và các xác thực nội tại khác cho thấy rằng phương pháp xây dựng là hợp lý cho các mô hình đủ lớn. Kết quả của chúng tôi cho thấy rằng LLM hiện tại không thể khớp với hiệu suất con người trên các loại lập luận cụ thể như đa bước và kiến thức thông thường trong ba lĩnh vực của chúng tôi. Bộ dữ liệu này đặt ra một thách thức cho cả các mô hình ngôn ngữ lớn nhất và nhỏ hơn: chúng tôi tin rằng nó có thể phục vụ như (1) một chuẩn mực cho LLM; (2) một chuẩn mực cho các cách tiếp cận neuro-symbolic tổng quát trên ngôn ngữ; (3) một quy trình xây dựng tổng quát để tạo ra các bộ dữ liệu thách thức khi các mô hình cải thiện.

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

7 KHẢ NĂNG TÁI TẠO CỦA MUSR

Để hỗ trợ trong việc tái tạo các bộ dữ liệu cho mỗi lĩnh vực trong MuSR, chúng tôi đã bao gồm các chi tiết cấp cao của quy trình xây dựng trong Phần 3 và 4. Chúng tôi chi tiết thêm chiến lược lập luận và thuật toán của mỗi lĩnh vực cũng như đưa ra các lời nhắc nguyên văn cho tất cả các phần của quy trình xây dựng trong Phụ lục G. Chi tiết triển khai, bao gồm siêu tham số và lựa chọn thiết kế mô hình, có thể được tìm thấy trong Phụ lục H. Đối với các đánh giá neuro-symbolic của chúng tôi, chúng tôi cung cấp các chi tiết liên quan về triển khai của chúng trong Phần 5.2 và với chi tiết thêm trong Phụ lục E. Cuối cùng, tất cả dữ liệu sẽ được công khai, bao gồm mã được sử dụng để tạo ra và đánh giá bộ dữ liệu trong các phiên bản tương lai của bài báo này.

LỜI CẢM ƠN

Công trình này được hỗ trợ bởi Giải thưởng CAREER NSF IIS-2145280, một khoản tài trợ từ Open Philanthropy, và bởi Viện AI NSF cho Nền tảng Học Máy (IFML). Tài liệu này cũng dựa trên nghiên cứu được hỗ trợ một phần bởi Phòng thí nghiệm Nghiên cứu Không quân (AFRL), DARPA, cho chương trình KAIROS theo số thỏa thuận FA8750-19-2-1003. Cảm ơn Kathryn Kazanas và Keziah Reina đã cung cấp đánh giá con người về MuSR. Cảm ơn Juan Diego Rodriguez và các thành viên của phòng thí nghiệm UT TAUR cho cuộc thảo luận và phản hồi hữu ích.

TÀI LIỆU THAM KHẢO

Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, và Yejin Choi. PIQA: Lập luận về Hiểu biết Thông thường Vật lý trong Ngôn ngữ Tự nhiên. Trong Kỷ yếu Hội nghị về Trí tuệ Nhân tạo (AAAI), 2020.

Kaj Bostrom, Zayne Sprague, Swarat Chaudhuri, và Greg Durrett. Suy luận ngôn ngữ tự nhiên thông qua tìm kiếm trên các thành phần câu lệnh. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, trang 4871–4883, Abu Dhabi, United Arab Emirates, Tháng 12 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-emnlp.358. URL https://aclanthology.org/2022.findings-emnlp.358.

[Tiếp tục dịch toàn bộ phần tài liệu tham khảo và các phụ lục còn lại...]

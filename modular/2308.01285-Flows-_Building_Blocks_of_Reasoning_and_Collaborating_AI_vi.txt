# 2308.01285.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/modular/2308.01285.pdf
# Kích thước tệp: 3817441 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Flows: Khối Xây Dựng của Suy Luận và Hợp Tác AI
Martin Josifoski* 1Lars Klein* 1Maxime Peyrard2Nicolas Baldwin1Yifei Li** 1Saibo Geng** 1
Julian Paul Schnitzler1Yuxing Yao1Jiheng Wei3Debjit Paul1Robert West1

Tóm tắt
Những tiến bộ gần đây trong trí tuệ nhân tạo (AI)
đã tạo ra các hệ thống có khả năng cao và có thể kiểm soát được.
Điều này tạo ra những cơ hội chưa từng có cho
suy luận có cấu trúc cũng như hợp tác
giữa nhiều hệ thống AI và con người.
Để thực hiện đầy đủ tiềm năng này, việc
phát triển một cách có nguyên tắc để thiết kế và nghiên
cứu các tương tác có cấu trúc như vậy là rất quan trọng.
Với mục đích này,
chúng tôi giới thiệu khung khái niệm Flows.
Flows là những khối xây dựng độc lập, khép kín của tính
toán, với trạng thái cô lập, giao tiếp
thông qua một giao diện chuẩn hóa dựa trên thông điệp.
Thiết kế mô-đun này đơn giản hóa quá trình tạo
Flows bằng cách cho phép chúng được sáng tác đệ quy
thành các tương tác lồng nhau tùy ý và
vốn thân thiện với đồng thời. Quan trọng là, bất kỳ
tương tác nào cũng có thể được triển khai bằng khung
này, bao gồm các công trình trước đây về tương tác AI–AI và human–
AI, các sơ đồ kỹ thuật prompt, và
tăng cường công cụ. Chúng tôi chứng minh tiềm năng
của Flows trên lập trình cạnh tranh, một nhiệm vụ đầy thử thách
mà ngay cả GPT-4 cũng gặp khó khăn. Kết quả của chúng tôi
gợi ý rằng suy luận có cấu trúc và hợp tác
cải thiện đáng kể khả năng tổng quát hóa, với
Flows chỉ AI thêm +21 và Flows human–AI
thêm +54 điểm tuyệt đối về tỷ lệ giải quyết.
Để hỗ trợ nghiên cứu nhanh chóng và nghiêm ngặt, chúng tôi giới
thiệu thư viện aiFlows thể hiện Flows. Thư viện
aiFlows có sẵn tại https://github.
com/epfl-dlab/aiflows. Dữ liệu và Flows để
tái tạo các thí nghiệm của chúng tôi có sẵn tại
https://github.com/epfl-dlab/cc_flows.

1. Giới thiệu
Thành công của các mô hình ngôn ngữ lớn (LLMs) chủ yếu nằm
trong khả năng nổi lên đáng chú ý của chúng để thích ứng với thông tin
1EPFL2Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG
3PSL University *, ** Đóng góp bằng nhau
Liên hệ: martin.josifoski@epfl.ch, lars.klein@epfl.ch,
maxime.peyrard@univ-grenoble-alpes.fr, robert.west@epfl.ch trong bối cảnh của chúng (tức là, prompt) (Brown et al., 2020;
Wei et al., 2022; Kojima et al., 2022). Bằng cách xây dựng
bối cảnh một cách chiến lược, LLMs có thể được điều kiện hóa để thực hiện
suy luận phức tạp (Wei et al., 2022; Nye et al., 2021) và
sử dụng hiệu quả các công cụ bên ngoài (Schick et al., 2023), làm tăng
đáng kể khả năng của chúng. Một số phát triển gần đây thú vị nhất
liên quan đến việc định nghĩa các luồng điều khiển,
trong đó LLMs, với khả năng điều khiển một tập hợp công cụ, được
gọi theo cách được sắp xếp để giải quyết các
nhiệm vụ ngày càng phức tạp. Ví dụ về các luồng điều khiển như vậy bao gồm ReAct
(Yao et al., 2023b), AutoGPT (Richards, 2023), BabyAGI
(Nakajima, 2023), PromptBreeder (Fernando et al., 2023)
và FunSearch (Romera-Paredes et al., 2023). Ngay cả
ứng dụng ChatGPT phổ biến (OpenAI, 2023b) cũng là một
thể hiện của luồng điều khiển được xây dựng xung quanh các mô hình GPT-3.5 và GPT-4
(Brown et al., 2020; OpenAI, 2023a). Tuy nhiên,
những thứ này chỉ đại diện cho một vài trong số nhiều luồng điều khiển
có thể hình dung được, chỉ cung cấp một cái nhìn thoáng qua về tiềm năng rộng lớn của
tương tác LLM có cấu trúc. Để thực hiện tiềm năng này, chúng ta cần
phát triển các cách để nghiên cứu các tương tác như vậy một cách có hệ thống.

Trong kỹ thuật phần mềm, các quy trình đơn giản có thể được triển
khai theo cách không có cấu trúc, có lẽ trong một tệp duy nhất.
Tuy nhiên, khi kích thước và độ phức tạp của hệ thống tăng lên,
việc chọn đúng trừu tượng và kiến trúc trở nên
quan trọng (Garlan & Shaw, 1993). Hiện tại, đối với các
tương tác LLM có cấu trúc mà chúng ta muốn mô hình hóa, triển khai và nghiên cứu,
chúng ta đang ở một điểm mà việc này trở nên khó quản lý. Tuy nhiên, không có
trừu tượng hiệu quả chung nào tồn tại để mô hình hóa hiệu quả
các tương tác có cấu trúc phức tạp tùy ý. Công trình trước đây
và các khung hiện có, như LangChain (Chase, 2022),
Chameleon (Lu et al., 2023), và HuggingGPT (Shen et al.,
2023), đã hội tụ về một trừu tượng tùy tiện mà mô hình
hóa các agent như những thực thể sử dụng LLMs để chọn và thực thi
các hành động hướng tới các nhiệm vụ cụ thể, trong đó tập hợp các
hành động có thể được định nghĩa trước bởi các công cụ có sẵn. Trong quan điểm này,
các công cụ phục vụ một mục tiêu hẹp, được định nghĩa rõ và có thể thực hiện
các nhiệm vụ tinh vi (ví dụ, truy vấn một công cụ tìm kiếm hoặc thực
thi mã). Tuy nhiên, hành vi của chúng bị giới hạn trong một
tương tác duy nhất. Để làm nổi bật các tác động của hạn chế này,
hãy xem xét tình huống sau: Alice muốn nộp đơn xin việc
tại HappyCorp. Nếu Alice là một agent, cô ấy sẽ cần
lập kế hoạch rõ ràng cho toàn bộ quá trình, bao gồm chuẩn bị
đơn đăng ký, gửi nó và đánh giá nó, có thể liên quan
1arXiv:2308.01285v3  [cs.AI]  7 Feb 2024

--- TRANG 2 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024
Công cụ
…
GPT-4
Công cụ tìm kiếm
Phản hồi cố định
Thực thi mã
Vector DB
Đầu vào con người
Agent FlowPrompt: few-shot,CoT… Web Search Flow
Code TestingFlow
Vector DB Flow
Human Flow
Atomic	FlowsBao bọc	công cụ	thành	thực thể	trao đổi	thông điệp
… …Composite	FlowsĐiều phối	tương tác	giữa	các	Flows	khácPlan-Code Flow(Vòng tròn)
Code Generator 
Code Feedback Code Feedback (Tuần tự)Code Testing
Code Flow(Generator-Critic)
Plan Generator 
Plan Feedback Plan Flow(Generator-Critic)Ví dụ	Coding	Flow
Fixed Reply Flow
ví dụ, "Bạn có chắc không?"Generator Flowcó thể là bất kỳ FlowGenerator-Critic FlowCritic Flowcó thể là bất kỳ FlowSequential Flow…Flow 1có thể là bất kỳ FlowFlow 2có thể là bất kỳ FlowFlow ncó thể là bất kỳ Flow
Monitoring FlowVí dụMeta-Reasoning	FlowMemory FLowAny FlowControl Flow
Execution Flow…Memory FLowAny Flow…Memory FLowAny Flow…Autonomous Flow

Hình 1. Khung Flows được minh họa. Cột đầu tiên mô tả các ví dụ về công cụ. Cột thứ hai mô tả các Atomic Flows
được xây dựng từ các công cụ ví dụ. Cột thứ ba mô tả các ví dụ về Composite Flows định nghĩa tương tác có cấu trúc giữa
các Atomic hoặc Composite Flows. Cột thứ tư minh họa một Composite Flow lập trình cạnh tranh cụ thể như những Flow được sử dụng trong các thí nghiệm.
Cột thứ năm phác thảo cấu trúc của một Flow giả thuyết, định nghĩa một quy trình meta-reasoning có thể hỗ trợ hành vi tự động.2

đến việc kiểm tra lý lịch, tổ chức phỏng vấn, và nhiều hơn nữa. Alice
sẽ cần kiến thức và khả năng "tính toán"
để tính đến mọi chi tiết, bao gồm các sự kiện không lường trước có thể
phát sinh (ví dụ, người phỏng vấn đang nghỉ phép chăm con), và
yêu cầu cô ấy thích ứng. Trên thực tế, hầu hết sự phức tạp được
ẩn giấu khỏi Alice đằng sau một giao diện đến quy trình tuyển
dụng của HappyCorp mà bản thân nó có thể được cấu thành từ các quy trình con
liên quan đến nhiều agent và công cụ khác. Do đó, Alice
hoàn toàn không biết về (các) quy trình đang diễn ra đằng sau
giao diện và các logistics tương ứng. Mặt khác, quy
trình tuyển dụng, được thiết kế cẩn thận bởi các chuyên gia, có thể được tái sử dụng
bởi nhiều agent, và các quy trình con của nó có thể được sửa đổi hoặc cải
thiện với tác động tối thiểu hoặc không có tác động đến các thành phần khác
ngoài một giao diện được cập nhật. Điều này làm cho rõ ràng rằng
các agent và công cụ nên có thể tương tác theo những cách phức tạp, động
hoặc tĩnh, như các phần của các quy trình mô-đun, lồng nhau
(chạy cục bộ hoặc từ xa), và sự phân biệt giữa
hai thứ trở nên mờ nhạt khi cả hai đều phục vụ như các đơn vị tính toán
trong một quy trình tính toán phức tạp.

Bắt đầu từ quan sát rằng tất cả các quy trình đều là các luồng (điều khiển)
định nghĩa một tương tác có thể phức tạp giữa
nhiều thành phần đa dạng; chúng tôi giới thiệu một khung khái niệm
trong đó Flows là các khối xây dựng cơ bản của
tính toán. Flows là các thực thể độc lập, khép kín, hướng mục tiêu
có thể hoàn thành các đơn vị công việc có ý nghĩa về mặt ngữ nghĩa.
Để trao đổi thông tin, Flows giao
tiếp qua một giao diện chuẩn hóa dựa trên thông điệp. Khung
được mô tả trong Hình 1.

Trừu tượng Flows đảm bảo tính mô-đun. Alice, một
Flow meta-reasoning cấp cao hơn có thể hỗ trợ hành vi tự động, không cần biết gì ngoài cách giao
tiếp với Flow tuyển dụng của HappyCorp. Điều này giảm đáng kể
sự phức tạp (Alice đang tương tác với một tương tác có cấu trúc
sáng tác lồng nhau sâu sắc thông qua một giao
diện đơn giản) và cung cấp tính linh hoạt, cho phép các sub-Flows được
hoán đổi mà không có hậu quả miễn là chúng có
giao diện giống nhau. Thật vậy, Flow lọc trước của HappyCorp có thể
được hoán đổi từ một hệ thống dựa trên quy tắc sang một mô hình AI hoặc
thậm chí một Flow con người mà không ảnh hưởng đến cấu trúc của
quy trình tổng thể. Trừu tượng này cũng cho phép khả năng tái sử dụng
và sự sáng tác của các sub-Flows thành các Flows mới cho các
nhiệm vụ khác nhau. Hơn nữa, khung này chia sẻ các lựa chọn thiết kế chính
với mô hình Actor, một trong những mô hình
tính toán đồng thời nổi bật nhất (cf. Sec. 3). Chắc chắn,
một khi Alice nộp đơn của mình cho HappyCorp, cô ấy không cần
chờ phản hồi; cô ấy có thể chuyển sang mục tiêu tiếp theo
trong khi các Flows khác chạy đồng thời.

Chúng tôi trình bày tiềm năng của khung và thư viện được đề xuất
bằng cách điều tra các mẫu suy luận hợp tác và có cấu trúc phức tạp
trên nhiệm vụ đầy thử thách của lập trình cạnh tranh, một môn thể thao
trí tuệ liên quan đến các thành viên cố gắng giải quyết
các vấn đề được định nghĩa bởi một mô tả ngôn ngữ tự nhiên.

Đóng góp. (i) Chúng tôi đề xuất Flows, một khung khái niệm
cung cấp một trừu tượng đơn giản hóa việc thiết kế và
triển khai các tương tác lồng nhau tùy ý trong khi cho
phép đồng thời. Flows có thể đại diện cho bất kỳ tương tác nào
và cung cấp một khung chung để suy luận về các
mẫu tương tác, chỉ định giả thuyết và cấu trúc
2Để biết thêm chi tiết về meta-reasoning Flows xem Sec. 7
2

--- TRANG 3 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024
nghiên cứu một cách rộng rãi hơn. (ii) Chúng tôi mở mã nguồn thư viện
aiFlows, thể hiện Flows, cùng với FlowVerse,
là một kho chứa Flows có thể được sử dụng ngay,
mở rộng và sáng tác thành các Flows mới, phức tạp hơn.
(iii) Chúng tôi tận dụng Flows và thư viện đi kèm để
điều tra một cách có hệ thống lợi ích của các tương tác phức tạp
để giải quyết các vấn đề lập trình cạnh tranh và phát triển
Flows chỉ AI thêm +21 và Flows human–AI thêm
+54 điểm tuyệt đối về tỷ lệ giải quyết.

2. Công trình Liên quan
Các thư viện hiện có để mô hình hóa tương tác có cấu trúc.
LangChain (Chase, 2022) đã trở thành thư viện được lựa chọn để
tạo các ứng dụng sử dụng các mô hình ngôn ngữ lớn. Tuy
nhiên, hầu hết các công trình gần đây liên quan đến tương tác có cấu trúc,
như Cameleon (Lu et al., 2023), Camel (Li et al., 2023),
HuggingGPT (Shen et al., 2023), và các công trình đồng thời
MetaGPT (Hong et al., 2023) và AutoGen (Wu et al., 2023)
đều đi kèm với thư viện riêng của họ. Các nhà nghiên cứu chọn triển
khai các giải pháp tùy chỉnh do thiếu một trừu tượng chung nhưng
hiệu quả để mô hình hóa và thiết kế tương tác có cấu trúc
cũng như cơ sở hạ tầng để triển khai chúng, điều này sẽ cho phép và
tạo điều kiện cho việc khám phá mở các ý tưởng mới. Trong công trình này, chúng tôi
phát triển một trừu tượng như vậy, Flows, mà kết hợp với aiFlows,
lấp đầy khoảng trống này.

Tác động của Flows. Quan trọng là, khung có thể triển
khai bất kỳ thuật toán nào và bao phủ hiệu quả tất cả các công trình trước đây
về tương tác AI-AI, human-AI, cũng như kỹ thuật
prompt (cf. Phụ lục A.3). Những công trình này tập trung vào
các thể hiện Flow cụ thể đã chứng minh rằng tương tác có cấu trúc
có thể mang lại lợi ích hiệu suất trên các nhiệm vụ
và mô hình. Tuy nhiên, kết quả gần đây đặt tính phổ quát
của các kết quả đã công bố trước đây vào câu hỏi (ví dụ, Huang
et al. (2023)) và làm nổi bật sự cần thiết cho nghiên cứu có hệ thống hơn.
Để hỗ trợ những nỗ lực nghiên cứu này, chúng tôi phát triển
cơ sở hạ tầng lý thuyết và thực tiễn để mô hình hóa, triển
khai và nghiên cứu có hệ thống các tương tác có cấu trúc
có độ phức tạp tùy ý. Chúng tôi chứng minh lợi ích của
cơ sở hạ tầng được đề xuất bằng cách tiến hành các thí nghiệm
điều tra kỹ lưỡng nhiều mẫu tương tác cốt lõi,
bao gồm hợp tác Human-AI, và các kết hợp của chúng,
trong khi tính đến sự nhiễm dữ liệu và phương sai trong
kết quả, cả hai điều này, đáng ngạc nhiên, hiện không phải là
tiêu chuẩn.

Lập trình cạnh tranh (CC). Với sự ra đời của transformers,
Li et al. (2022) đã tinh chỉnh một LLM trên các kho mã GitHub
và một tập dữ liệu được thu thập từ Codeforces. Gần đây,
Zelikman et al. (2022) đề xuất phân tách các vấn đề CC
thành các mô tả chức năng và, đối với mỗi mô tả chức năng,
sử dụng LLM để tạo ra việc triển khai theo cách mô-đun.
Trong khi những phương pháp này mang lại kết quả đầy hứa hẹn, CC vẫn là một nhiệm vụ đầy thử thách còn xa mới được giải quyết (OpenAI,
2023a). Như vậy, nó tự trình bày như một testbed lý tưởng để
nghiên cứu kỹ lưỡng lợi ích của các tương tác suy luận hợp tác và có cấu trúc.

3. Flows
Phần này giới thiệu Flows như một khung khái niệm,
mô tả lợi ích của nó và trình bày thư viện aiFlows,
thể hiện khung này.

3.1. Flows như một Khung Khái niệm
Khung tập trung xung quanh Flows và thông điệp.
Flows đại diện cho khối xây dựng cơ bản của tính toán.
Chúng là các thực thể độc lập, khép kín, hướng mục tiêu
có thể hoàn thành một đơn vị công việc có ý nghĩa về mặt ngữ nghĩa.
Để trao đổi thông tin, Flows giao tiếp qua một
giao diện chuẩn hóa dựa trên thông điệp. Thông điệp có thể là
bất kỳ loại nào mà Flow nhận có thể xử lý.

Chúng tôi phân biệt giữa hai loại Flows: Atomic và
Composite.3 Atomic Flows hoàn thành công việc trực tiếp
bằng cách tận dụng các công cụ. Công cụ có thể đơn giản như một
chuỗi văn bản chỉ định phản hồi cố định của một Flow (đơn giản) hoặc
phức tạp như một trình biên dịch, một công cụ tìm kiếm, các hệ thống AI mạnh mẽ
như LLaMA (Touvron et al., 2023a;b), Stable Diffusion (Rombach et al., 2021), và GPT-4; hoặc thậm chí một con người.
Đáng chú ý, trong khung Flows, các hệ thống AI tương ứng
với các công cụ. Một Atomic Flow thực sự là một wrapper tối thiểu
xung quanh một công cụ và đạt được hai điều: (i) nó chỉ định đầy đủ
công cụ (ví dụ, Atomic Flow cơ bản nhất xung quanh GPT-4
sẽ chỉ định các prompts và các tham số tạo sinh);
và (ii) nó trừu tượng hóa sự phức tạp của tính toán
nội bộ bằng cách chỉ để lộ một giao diện chuẩn dựa trên thông điệp
để trao đổi thông tin với các Flows khác. Ví dụ về
Atomic Flows bao gồm các wrapper xung quanh chain-of-thought
được prompt GPT-4 để giải quyết các vấn đề suy luận toán học, few-
shot được prompt LLaMA để hỏi đáp, một
chatbot hiện có, một API công cụ tìm kiếm, hoặc một giao diện với con người.

Composite Flows thực hiện các mục tiêu đầy thử thách, cấp cao hơn
bằng cách tận dụng và điều phối các Flows khác.
Quan trọng là, nhờ vào trạng thái cục bộ và giao diện chuẩn hóa của chúng,
Composite Flows có thể dễ dàng gọi các Atomic Flows
hoặc các Composite Flows khác như một phần của các tương tác có cấu trúc sáng tác,
có độ phức tạp tùy ý. Cho phép nghiên cứu
về các mẫu tương tác hiệu quả là một trong những mục tiêu chính
của công trình của chúng tôi. Ví dụ chung về các mẫu như vậy bao gồm (i)
factorizing vấn đề thành các vấn đề đơn giản hơn (tức là, chia để trị);
(ii) đánh giá các (sub-)giải pháp tại thời điểm suy luận
(tức là, phản hồi); và (iii) kết hợp thông tin bên ngoài
3Khái niệm của một Flow là đủ để mô hình hóa bất kỳ tương tác nào.
Chúng tôi giới thiệu sự phân biệt này vì nó cải thiện việc trình bày
và đơn giản hóa việc triển khai.
3

--- TRANG 4 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024
mation hoặc một công cụ. Quan trọng là, Flows có thể dễ dàng gọi
các Flows chuyên biệt khác, có thể được tối ưu hóa nặng nề, để
hoàn thành các (sub-)nhiệm vụ cụ thể như một phần của tương tác, dẫn
đến hành vi phức tạp. Một ví dụ về Composite
Flow là ReAct (Yao et al., 2023b). ReAct là một
Flow tuần tự cấu trúc quy trình giải quyết vấn đề thành hai
bước: một Flow chọn hành động tiếp theo từ một tập hợp
các hành động được định nghĩa trước, và một Flow khác thực thi nó. Hai bước được
thực hiện cho đến khi có được một câu trả lời. Một ví dụ nổi bật khác,
AutoGPT, mở rộng ReAct Flow với một Memory
Flow và một Human Feedback Flow tùy chọn. Tổng quát hơn,
khung của chúng tôi cung cấp một cái nhìn thống nhất về công trình trước đây,
mà chúng tôi làm rõ trong Phụ lục A.3.

Quan trọng là, như được minh họa trong Hình 1, Composite Flows có thể
lập script một mẫu phức tạp tùy ý (i) chỉ định chính xác
một tương tác (ví dụ, tạo mã, thực thi tests, động não
các lý do tiềm năng cho thất bại, v.v.); hoặc (ii) định nghĩa một
quy trình meta-reasoning cấp cao trong đó một Flow có thể mang lại
các tương tác động không bị ràng buộc.

Các thuộc tính chính. Khung được đề xuất được đặc trưng
bởi các thuộc tính chính sau:
• Flows là các khối xây dựng sáng tác của tính toán.
• Flows đóng gói một trạng thái cục bộ, cô lập.
• Flows chỉ tương tác qua thông điệp.
• Hành vi của Flows chỉ phụ thuộc vào trạng thái nội bộ
và thông điệp đầu vào của chúng.
• Flows có thể gửi thông điệp cho các Flows khác và tạo
Flows mới.

Kết nối với mô hình Actor. Flows về cơ bản là
một khung mô hình hóa tính toán cơ bản của tương tác.
Như vậy, nó chia sẻ các nguyên tắc thiết kế chính với
mô hình Actor (Hewitt et al., 1973) — một mô hình toán học
của tính toán đồng thời. Tương tự như Flows, trong mô hình Actor, một Actor là một thực thể tính toán đồng thời có thể
giao tiếp với các Actors khác chỉ thông qua một
giao diện truyền thông điệp không đồng bộ. Bằng cách đóng gói
trạng thái và tính toán trong các Actors riêng lẻ,
mô hình cung cấp một trừu tượng cấp cao để quản lý và suy luận hiệu quả
về các hệ thống đồng thời và phân tán phức tạp, hoàn toàn tránh các vấn đề liên quan đến
trạng thái chia sẻ, điều kiện đua và deadlocks. Những lợi ích này
tương tự về bản chất với những lợi ích được quan sát trong lĩnh vực
tương tác. Sự khác biệt chính giữa khung được đề xuất
và mô hình Actor nằm ở các giao thức giao tiếp tương ứng của chúng.
Cụ thể, trong khi mô hình Actor quy định
giao tiếp thuần túy không đồng bộ, Flows hỗ trợ bản địa
giao tiếp đồng bộ, điều này là quan trọng cho việc triển khai suy luận có cấu trúc. Thú vị là, một sự sai lệch tương tự khỏi mô hình Actor "thuần túy" có thể được xác định trong việc triển khai Erlang, một ngôn ngữ lập trình đồng thời
dựa trên nó (Armstrong, 2003).
Nhìn chung, các lựa chọn thiết kế được chia sẻ vẫn làm cho Flows
vốn thân thiện với đồng thời từ góc độ thực tiễn
và đủ cho các kết quả quan trọng từ năm thập kỷ
nghiên cứu sâu rộng về mô hình Actor, như việc
mọi tính toán có thể thực hiện về mặt vật lý đều có thể được triển khai trực tiếp
sử dụng Actors (Hewitt, 2010), để chuyển sang
Flows.

3.2. Tại sao Flows?
Tính mô-đun. Flows giới thiệu một trừu tượng cấp cao hơn
cô lập trạng thái của các Flows riêng lẻ và chỉ định
giao tiếp dựa trên thông điệp như giao diện duy nhất mà qua đó
Flows có thể tương tác. Điều này đảm bảo tính mô-đun hoàn hảo
theo thiết kế.

Giảm độ phức tạp. Khung đảm bảo sự phức tạp của
tính toán được thực hiện bởi một Flow được trừu tượng hóa hoàn toàn
đằng sau giao diện dựa trên thông điệp phổ quát.
Điều này cho phép thiết kế trực quan và đơn giản các tương tác phức tạp tùy ý
từ các khối xây dựng cơ bản.

Tính có hệ thống, linh hoạt và khả năng tái sử dụng. Sự phân tách
trách nhiệm cho phép các mô-đun được phát triển và
nghiên cứu một cách có hệ thống một cách cô lập hoặc như một phần của các
tương tác khác nhau. Một khi tính đúng đắn và lợi ích của một Flow
đã được thiết lập, nó có thể được sử dụng ngay trong việc phát triển
các Flows mới hoặc như một sự thay thế drop-in cho các Flows ít hiệu quả hơn
được tận dụng trong việc hoàn thành các mục tiêu tương tự.

Đồng thời. Thiết kế của khung được đề xuất
phù hợp với mô hình Actor, một trong những mô hình
tính toán đồng thời nổi bật nhất. Kết quả là, Flows có thể
dễ dàng hỗ trợ bất kỳ cài đặt nào trong đó Flows chạy đồng thời.

3.3. Thư viện aiFlows
Đi kèm với Flows, chúng tôi phát hành thư viện aiFlows,
thể hiện khung này. Ngoài các
lợi ích vốn có đi kèm với khung, thư viện đi kèm
với các add-ons sau: (i) FlowVerse: một kho chứa (mà
bất kỳ ai cũng có thể đóng góp) của Flows có thể được sử dụng ngay,
mở rộng hoặc sáng tác thành các Flows mới, phức tạp hơn.
Flows cho phép các "công cụ" hiện có (cũng như "mô hình", "chuỗi", "agents", v.v.) được kết hợp ngay bằng cách
bao bọc chúng trong một Atomic Flow; (ii) một cơ sở hạ tầng logging chi tiết
cho phép debugging minh bạch, phân tích và
nghiên cứu trong việc tối ưu hóa (tức là, học hoặc fine-tuning) Flows.
4

--- TRANG 5 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

4. Competitive Coding Flows
Công trình này điều tra tiềm năng của tương tác có cấu trúc
để giải quyết các vấn đề lập trình cạnh tranh (CC). Trong CC,
cho trước một mô tả ngôn ngữ tự nhiên và một vài ví dụ input–output,
nhiệm vụ là tạo ra mã sẽ tạo ra
output mong đợi cho tất cả các trường hợp test input–output ẩn
liên quan đến vấn đề. Hình 4 cung cấp các ví dụ.

Chúng tôi tập trung phân tích vào ba chiều chính của tương tác:
(i) phân tách vấn đề như suy luận có cấu trúc;
(ii) hợp tác human-AI; và (iii) tinh chỉnh với các
loại phản hồi khác nhau. Bằng cách cung cấp một ngôn ngữ chung
để chỉ định rõ ràng các tương tác cũng như khả năng
sáng tác, trao đổi và mở rộng chúng một cách linh hoạt, khung
làm cho việc nghiên cứu không gian của các tương tác phức tạp
theo cách có nguyên tắc trở nên khả thi. Trong phần còn lại của
phần, chúng tôi mô tả các Flows cụ thể được sử dụng trong các thí nghiệm,
được mô tả trong Hình 2.

Phân tách vấn đề. Lập kế hoạch đã là một bước trung gian
không thể thiếu trong công trình gần đây (Lu et al., 2023; Shen et al.,
2023; Yao et al., 2023b). Phân tách tương tự cũng tự nhiên
trong bối cảnh CC. Cụ thể, chúng tôi tiếp cận
nhiệm vụ theo hai bước: tạo ra một chiến lược giải pháp bởi một Plan
Flow và sau đó tạo ra mã tương ứng bởi một Code
Flow. Điều này được mô tả bởi panel A trong Hình 2.

Hợp tác Human-AI. Khi thiết kế hợp tác human-AI,
điều quan trọng là phải tính đến chi phí của tương tác con người
(Horvitz, 1999; Amershi et al., 2019;
Mozannar et al., 2023). Bằng cách cung cấp tính linh hoạt to lớn,
Flows có thể hỗ trợ nghiên cứu trong việc thiết kế các tương tác liên quan đến con người như các khối xây dựng tính toán theo cách
tối đa hóa tiện ích của tính toán tổng thể với
nỗ lực con người tối thiểu. Trong bối cảnh CC, chúng tôi giả định
rằng một con người có thể được kết hợp hiệu quả ở cấp độ kế hoạch
để cung cấp một kế hoạch "oracle" ngắn bằng ngôn ngữ tự nhiên. Chúng tôi
vận hành điều này bằng một Human Flow (Atomic), được minh họa
trong Panel B của Hình 2 như Oracle Plan Flow.

Tinh chỉnh với các loại phản hồi khác nhau. Tinh chỉnh lặp đi lặp lại là một
chiến lược giải quyết vấn đề chung được triển khai thành công
trên các lĩnh vực khác nhau (Perrakis et al., 1999; Reid
& Neubig, 2022; Schick et al., 2022; Saharia et al., 2021).
Chiến lược xoay quanh ý tưởng rằng một giải pháp có thể được
cải thiện dần dần thông qua một cơ chế để phân tích, sửa đổi
và đánh giá lại. Thiết kế của cơ chế "phản hồi" này
là quan trọng cho hiệu quả của chiến lược giải quyết vấn đề.
Khung khái niệm, kết hợp với
thư viện đi kèm, cung cấp cơ sở hạ tầng để hỗ trợ
việc thiết kế, triển khai và nghiên cứu có nguyên tắc về các
chiến lược tinh chỉnh hiệu quả và cơ chế phản hồi. Trong
công trình này, chúng tôi xem xét một thiết lập tinh chỉnh lặp đi lặp lại chính thức
trong đó một generator Flow được giao nhiệm vụ tạo ra giải
pháp, và một critic Flow cung cấp phản hồi về giải pháp được đề xuất.
Chúng tôi xem xét hai loại phản hồi trong bối cảnh
của cả Plan và Code Flow: (i) Reflection Flow: phản hồi
bao gồm một thông điệp cố định khuyến khích mô hình
suy ngẫm về các khía cạnh quan trọng của giải pháp được đề xuất; (ii)
Collaboration Flow: phản hồi được cung cấp bởi một hệ thống AI
"đánh giá" giải pháp được đề xuất. Hơn nữa, chúng tôi
khám phá hai loại phản hồi cụ thể cho mã: (i) Debug
Flow: thông điệp phản hồi tương ứng với kết quả từ
việc thực thi mã và test nó đối với các ví dụ được cung cấp
trong mô tả vấn đề; (ii) Debug–Collab Flow:
phản hồi được cung cấp bởi một hệ thống AI có quyền truy cập vào
kết quả test mã, hiệu quả, căn cứ phản hồi
và cho phép suy luận có hệ thống hơn về các
nguyên nhân tiềm năng của thất bại.

Chúng tôi gọi các Flows bằng quy ước sau: Code-
FlowName khi không có kế hoạch nào được tạo ra và PlanFlowName-
CodeFlowName nếu không.

5. Thiết lập Thí nghiệm
Dữ liệu. Chúng tôi thu thập các vấn đề có sẵn công khai từ một
trong những trang web phổ biến nhất tổ chức các cuộc thi CC, Code-
forces (Mirzayanov, 2023), và LeetCode (LeetCode, 2023),
bao gồm một phổ rộng các vấn đề từ
câu hỏi phỏng vấn dễ đến các vấn đề CC khó (xem Phụ
lục A.1 để biết thêm chi tiết). Các tập dữ liệu bao gồm các vấn đề
từ 2020-August-21 đến 2023-March-26 cho CodeForces,
và từ 2013-October-25 đến 2023-April-09 cho LeetCode.
Quan trọng là, để nghiên cứu tác động của tương tác có cấu trúc
(tức là, các Flows khác nhau) theo cách có nguyên tắc, điều quan trọng là
phải tính đến khả năng nhiễm dữ liệu, tức là
một số dữ liệu test đã được nhìn thấy trong quá trình training (Magar
& Schwartz, 2022). Chứa các vấn đề được công bố trong
một khoảng thời gian dài lên đến vài tháng trước (tại thời điểm
viết), các tập dữ liệu của chúng tôi cho phép xác định đáng tin cậy
ngày cutoff dữ liệu training có thể giúp giải quyết vấn đề này.
Các tập dữ liệu đánh giá mã trước đây như APPS (Hendrycks
et al., 2021), HumanEval (Chen et al., 2021), và Code-
Contests (Li et al., 2022) thiếu ngày phát hành vấn đề, và
xem xét việc thiếu thông tin có sẵn công khai về
dữ liệu training của LLMs, có thể dẫn đến đánh giá bị nhầm lẫn
về khả năng ghi nhớ và tổng quát hóa của mô hình.

Test mã và đánh giá giải pháp. Giống như một thành viên con người,
Debug Flow chỉ có quyền truy cập vào các cặp ví dụ input–output
có trong mô tả vấn đề và, tại thời điểm suy luận, sử dụng một cơ sở hạ tầng test mã cục bộ để đánh giá các ứng viên giải pháp (trung gian).
Quan trọng là, những ví dụ này chỉ bao gồm một vài trường hợp đơn giản, và
tạo ra outputs phù hợp với chúng không có nghĩa là
mã tương ứng với một giải pháp đúng. Một giải pháp được
coi là đúng nếu nó vượt qua tất cả các trường hợp test ẩn. Để
xác định tính đúng đắn, chúng tôi tận dụng các bộ đánh giá trực tuyến
5

--- TRANG 6 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

Plan Generator 
Plan Feedback Collaboration(Generator-Critic)
Plan Generator Oracle Plan 
Plan Generator Fixed ReplyReflection(Generator-Critic)
NoPlan B) Plan Flows
Code Generator 
Code Feedback Code Feedback (Sequential)Code Testing
Debug-Collab(Generator-Critic)
Code Generator 
Code Generator 
Code Feedback Collaboration(Generator-Critic)
Code Generator Code TestingDebug(Generator-Critic)
Code Generator Fixed ReplyReflection(Generator-Critic)
C) Code FlowsPlanFlow
PlanCoding Template(Sequential)
CodeFlow
Code solution
Problem description
A) Overview

Hình 2. Competitive coding Flows. Ở cấp độ cao nhất, chúng tôi xem xét việc lập kế hoạch như một mẫu suy luận có cấu trúc cụ thể cho
phân tách vấn đề. Cụ thể, Plan Flow tạo ra một chiến lược giải pháp và chuyển nó cho Code Flow, thực hiện nó, như được mô tả
trong A). B) và C) mô tả các lựa chọn khác nhau của sub-Flows được sử dụng như Plan và Code Flows trong các thí nghiệm. Đáng chú ý, chúng tôi khám phá
tác động của hợp tác human-AI ở cấp độ kế hoạch và tinh chỉnh với các loại phản hồi khác nhau: i) phản hồi cố định khuyến khích suy ngẫm;
ii) phản hồi được tạo bởi AI; iii) kết quả test mã như phản hồi; iv) phản hồi được tạo bởi AI dựa trên kết quả test mã.

nộp các giải pháp ứng viên lên các judges trực tuyến của trang web,
đảm bảo kết quả có thẩm quyền. Đối với nhiều vấn đề Codeforces,
chúng tôi cũng hỗ trợ đánh giá cục bộ dựa trên một
tập hợp toàn diện các trường hợp test ẩn mà chúng tôi đã quản lý để thu thập.
Để biết thêm chi tiết, xem Phụ lục A.2.

Mô hình và Flows. Chúng tôi thí nghiệm với các
competitive coding Flows được mô tả trong Sec. 4, và GPT-4 (OpenAI,
2023a) như LLM tool được lựa chọn. Xem Phụ lục A.4 cho
các prompts cụ thể. Ngoài ra, mã để tái tạo các thí nghiệm
trong bài báo có sẵn trong kho GitHub của dự án.

Metrics đánh giá. Metric đánh giá phổ biến nhất
cho việc tạo mã là pass@k, tương ứng với xác
suất rằng trong một tập hợp k ứng viên được lấy mẫu, sẽ có
ít nhất một giải pháp đúng (Chen et al., 2021). Để căn chỉnh tốt hơn
với các trường hợp sử dụng thực tế, chúng tôi tập trung vào pass@1, tức là
tỷ lệ giải quyết khi được tính trung bình trên tập vấn đề. Chúng tôi báo cáo
một ước lượng điểm và một khoảng tin cậy 95% được xây dựng
từ 1000 bootstrap resamples.

Tính toán và chi phí. Tất cả các thí nghiệm, bao gồm các
Flows phức tạp nhất, có thể được thực hiện trên phần cứng commodity
tương đối rẻ. Ví dụ, chi phí liên quan đến
việc truy vấn OpenAI API để tạo ra Bảng 1 lên đến
$1000.

6. Kết quả Thí nghiệm
Chúng tôi đầu tiên nghiên cứu khả năng tổng quát hóa của các
Flows đại diện và xác định thực nghiệm ngày cutoff kiến thức của GPT-4.
Tiếp theo, chúng tôi thực hiện một phân tích tập trung theo các chiều
được mô tả trong Sec. 4.

6.1. Hiệu suất của Coding Flows trên Dữ liệu Trước vs.
Sau-Ngày-Cutoff-Kiến-thức

[Biểu đồ thời gian]

Hình 3. Phân tích thời gian. Hiệu suất được tính trung bình trên một
cửa sổ trượt hai tháng. Sự sụt giảm đáng kể về hiệu suất
xung quanh ngày cutoff kiến thức được báo cáo cho GPT-3/4 (đường thẳng đứng
màu đỏ thẫm) tiết lộ khả năng tổng quát hóa hạn chế có thể được
giảm bớt thông qua các tương tác có cấu trúc.

Trong thí nghiệm này, chúng tôi xem xét ba
Flows đại diện: (i) Code: Code Generator
Flow đơn giản nhất tương ứng với một cuộc gọi GPT-4 API duy nhất; (ii)
Code_Debug_Collab: code Flow phức tạp nhất; (iii)
Plan_Oracle-Code_Debug_Collab: code Flow phức tạp nhất
với hướng dẫn con người ở cấp độ kế hoạch. Chúng tôi thực hiện
phân tích bằng cách chạy ba Flows trên các vấn đề Codeforces
được phát hành từ tháng 10 năm 2020 đến tháng 4 năm 2023 và tính trung bình
hiệu suất trên một cửa sổ trượt hai tháng. Kết quả
được báo cáo trong Hình 3.

Chúng tôi quan sát một sự sụt giảm đáng kể về hiệu suất tập trung
xung quanh tháng 9 năm 2021, phù hợp với ngày cutoff kiến thức
6

--- TRANG 7 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

Bảng 1. Kết quả Chính. Hiệu suất của competitive coding Flows trên Codeforces và LeetCode, với suy luận trực tiếp (Code) như baseline.

Codeforces | Leetcode
Pre-cutoff | Post-cutoff | Pre-cutoff | Post-cutoff
Easy | Medium | Hard | Easy | Medium | Hard

Code | 71.8 ±11.0 | 26.9 ±11.0 | 97.8 ±3.1 | 93.4 ±5.4 | 66.7 ±10.9 | 76.3 ±8.6 | 25.1 ±8.9 | 8.0 ±5.5
Code_Reflection | +9.3 ±9.7 | +0.0 ±10.6 | +0.0 ±3.1 | +0.0 ±5.4 | +1.2 ±10.6 | +0.9 ±8.1 | +5.4 ±9.4 | +3.5 ±6.6
Code_Collaboration | +4.8 ±10.5 | +9.6 ±11.8 | +0.0 ±3.1 | -2.3 ±6.0 | -0.1 ±10.9 | -3.2 ±8.7 | +0.0 ±8.7 | +1.2 ±5.9
Code_Debug | +12.7 ±8.6 | +7.9 ±11.6 | +0.0 ±3.1 | +1.1 ±5.0 | +6.9 ±10.0 | +7.7 ±7.3 | +7.7 ±9.6 | +2.4 ±6.3
Code_Debug_Collab | +12.6 ±8.9 | +20.6 ±12.1 | +0.0 ±3.1 | +0.0 ±5.4 | +5.5 ±10.4 | +7.5 ±7.4 | +9.8 ±9.7 | +1.2 ±6.0
Plan-Code | -1.6 ±11.0 | +8.0 ±11.6 | -3.1 ±4.5 | -2.3 ±5.9 | -9.7 ±11.2 | +2.3 ±8.3 | +3.2 ±9.1 | -3.4 ±4.3
Plan_Reflection-Code | -3.3 ±11.6 | +4.8 ±11.6 | -2.1 ±4.1 | -4.5 ±6.6 | -3.1 ±10.7 | +1.2 ±8.3 | -3.3 ±8.5 | +0.0 ±5.5
Plan_Collaboration-Code | -4.8 ±11.5 | +6.3 ±11.4 | -1.1 ±3.7 | -2.3 ±6.1 | -7.2 ±11.2 | -2.0 ±8.6 | +0.1 ±9.0 | +1.2 ±5.8
Plan_Oracle-Code | +11.0 ±9.4 | +47.6 ±10.7 | – | – | – | – | – | –
Plan_Oracle-Code_Debug_Collab | +23.0 ±5.2 | +53.9 ±9.5 | – | – | – | – | – | –

được báo cáo bởi OpenAI, và biểu thị nó bằng một đường thẳng đứng
trên biểu đồ. Với các vấn đề Codeforces xuất hiện trong
bối cảnh bên ngoài cuộc thi (ví dụ, editorials), hợp lý
để giả định mô hình đã được tiếp xúc với các vấn đề cũ hơn
thường xuyên hơn trong quá trình training. Điều này sẽ giải
thích tại sao sự sụt giảm kéo dài nhiều tháng, từ tháng 5 năm 2021
đến tháng 11 năm 2021, tùy thuộc vào thời điểm dữ liệu nào được
công bố và thu thập.

Đáng chú ý, có một sự khác biệt rõ rệt trong hiệu suất của
Code Flow trên các vấn đề được công bố trước và sau
ngày cutoff dữ liệu kiến thức, với tỷ lệ giải quyết giảm từ
khoảng 80% xuống 23%. Trong khi vẫn trải qua một sự sụt giảm hiệu suất đáng kể,
Code_Debug_Collab Flow tăng gấp đôi
tỷ lệ giải quyết trên các vấn đề mới lên khoảng 45%. Được cung cấp
đầu vào con người ở cấp độ kế hoạch, cùng Flow đạt
85%. Nhìn chung, điều này làm nổi bật rằng GPT-4 hoạt động kém
trên các vấn đề suy luận phức tạp mới, nhưng các tương tác có cấu trúc
có tiềm năng tăng cường khả năng tổng quát hóa của nó. Vì cả GPT-4
(tức là, Code Flow) và các tương tác phức tạp hơn (Flows) đều thể hiện hành vi khác nhau về mặt chất lượng
trên dữ liệu mới, để rút ra kết luận chính xác, điều quan trọng là
nhiễm dữ liệu được xem xét nghiêm túc khi thiết kế thí nghiệm và diễn giải
kết quả.

6.2. So sánh Competitive Coding Flows
Bảng 1 báo cáo hiệu suất của tập hợp được chọn có hệ thống
các Flows được mô tả trong Sec. 4. Hàng 6–10 tương ứng
với Flows bao gồm lập kế hoạch và lập trình, trong khi hàng 1–5
thực hiện lập trình trực tiếp. Phù hợp với các phát hiện của
phần trước, chúng tôi xem xét riêng biệt hiệu suất trên
các vấn đề được công bố trước và sau ngày cutoff kiến thức
của tháng 9 năm 2021.

Phân tách vấn đề. Ý tưởng đằng sau việc lập kế hoạch trước
khi triển khai giải pháp là tách biệt suy luận cấp cao
khỏi việc triển khai mã. Để phân tích hiệu quả
của mẫu này, chúng tôi so sánh Code và
Plan-Code Flow. Nhìn vào các ước lượng điểm, trong
các vấn đề pre-cutoff, việc giới thiệu plan Flow dẫn đến
hiệu suất giảm (-1.6 cho Codeforces và -3.1/2.3/-9.7
cho LeetCode easy/medium/hard). Tuy nhiên, trong các vấn đề post-
cutoff, việc kết hợp plan Flow dẫn đến lợi ích
cho Codeforces (+8) và LeetCode easy và medium (+2.3
và +3.2). Trong khi những xu hướng này nhất quán, xem xét
các khoảng tin cậy, chúng ta thấy rằng chúng không có ý nghĩa thống kê.
Quan trọng là, những kết quả này không có nghĩa là
phân tách vấn đề cụ thể này không có giá trị vì nó
tạo ra nhiều tiềm năng trong việc thiết kế một hợp tác human-AI hiệu quả.

Hợp tác Human-AI. Sau mỗi cuộc thi, cộng đồng Code-
forces công bố một editorial mà, ngoài
việc triển khai mã, cung cấp một mô tả ngôn ngữ tự nhiên ngắn
về giải pháp. Để mô phỏng một Flow
trong đó con người cung cấp hướng dẫn cấp cao tại cốt lõi
của quy trình suy luận, chúng tôi thu thập các mô tả giải pháp
và chuyển chúng như các kế hoạch được tạo bởi con người. Kết quả
là nổi bật: mặc dù chỉ dài vài câu,
các kế hoạch do con người cung cấp dẫn đến một sự gia tăng hiệu suất đáng kể
(từ 26.9% đến 74.5% và từ 47.5% đến 80.8%
trên các vấn đề mới, khi mã được tạo bởi Code và
Code_Debug_Collab Flows, tương ứng). Trước hết và
quan trọng nhất, những kết quả này trình bày các cơ hội được tạo ra bởi
Flows để thiết kế, triển khai và nghiên cứu hợp tác Human-AI
như một thành phần chính của tương tác có cấu trúc.
Thứ hai, cụ thể đối với vấn đề lập trình cạnh tranh, chúng
xác thực giả thuyết rằng các kế hoạch chất lượng cao là quan trọng,
gợi ý rằng việc thiết kế các plan Flows hiệu quả hơn
7

--- TRANG 8 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

là một hướng đầy hứa hẹn để khám phá trong tương lai. Cuối cùng nhưng
không kém phần quan trọng, kết quả làm nổi bật sự cần thiết của nghiên cứu có hệ thống hơn,
vì các mẫu dường như không có giá trị trong một
Flow, như phân tách suy luận có cấu trúc plan-code
đơn giản, có thể cung cấp giá trị to lớn như một phần của
Flow khác.

Tinh chỉnh với các loại phản hồi khác nhau. Chúng tôi thấy rằng
Code_Reflection và Code_Collaboration dẫn đến cải thiện hạn chế
trong số các code Flows. Hai ngoại lệ
là Codeforces pre-cutoff (+9.3) cho mẫu trước và Code-
forces post-cutoff (+9.6) cho mẫu sau. Trong khi gần,
những kết quả này không có ý nghĩa thống kê. Mặt khác,
các Flows cung cấp phản hồi có căn cứ, Code_Debug
và Code_Debug_Collab, dẫn đến cải thiện nhất quán và có ý nghĩa thống kê,
đáng chú ý nhất trên các vấn đề Code-
forces mới trong đó hiệu suất tăng từ 26.9,
không có phản hồi, đến 47.5, khi tinh chỉnh dựa
trên phản hồi được tạo bởi AI có căn cứ trong tests. Trên LeetCode,
những cải thiện này có độ lớn nhỏ hơn. Chúng tôi nghi ngờ
điều này là hệ quả của các ví dụ được cung cấp với mô tả vấn đề
đơn giản hơn so với trong Codeforces,
dẫn đến false positives và do đó, căn cứ không chính xác,
ảnh hưởng đến chất lượng phản hồi. Điều này có thể được giải quyết
bằng cách tạo ra các tests bổ sung với một Test_Case_Generator
Flow, một hướng chúng tôi để lại cho công trình tương lai khám phá. Cuối cùng,
trong các plan Flows, nơi chúng tôi xem xét Reflection và
Collaboration (không có căn cứ), chúng tôi thấy rằng tinh chỉnh
không cung cấp lợi ích có ý nghĩa thống kê.

Nhìn chung, các phát hiện của chúng tôi cung cấp một số thông tin quan trọng: (i)
lợi ích trực tiếp của phân tách vấn đề phụ thuộc vào chất lượng
của các bước trung gian; (ii) việc liên quan con người vào
quy trình suy luận cấp cao cốt lõi mang lại cải thiện lớn
vì con người có thể dễ dàng cung cấp phản hồi chất lượng cao, có căn cứ;
(iii) phân tách vấn đề chiến lược là một
chiến lược mạnh mẽ để tạo ra cơ hội cho hợp tác Human–
AI hiệu quả; (iv) hiệu quả của các mẫu tinh chỉnh
không phổ quát và phụ thuộc vào chất lượng của giải pháp
khởi đầu và phản hồi (ví dụ, mức độ căn cứ), và khả năng của mô hình để kết hợp phản hồi đó được
điều chỉnh thông qua tính cụ thể của phản hồi và khả năng của mô hình.
Phân tích này vẽ ra một bức tranh phức tạp hơn so với những gì được báo cáo
bởi công trình trước đây cho các tương tác đơn giản.

7. Thảo luận
Đơn giản và tính có hệ thống. Nhờ vào các thuộc tính chính của nó,
Flows, cùng với aiFlows, cung cấp một cơ sở hạ tầng
đơn giản hóa đáng kể việc thiết kế và triển khai các
tương tác mở, với khả năng cô lập linh hoạt,
sáng tác, thay thế hoặc sửa đổi các sub-Flows. Các thí nghiệm
chứng minh rằng các tương tác được thiết kế cẩn thận có thể cải thiện đáng kể
khả năng tổng quát hóa. Tuy nhiên, chúng cũng tiết lộ rằng hiệu quả của các mẫu tương tác cụ thể
không phổ quát; thay vào đó, có nhiều yếu tố đang tác động.
Là các nhà nghiên cứu, chúng ta cần chỉ định rõ ràng các mẫu mà chúng ta đang
nghiên cứu, truyền đạt rõ ràng các giả thuyết của chúng ta và nghiên cứu
chúng cả một cách cô lập và như các phần của các tương tác khác
trên các tập dữ liệu và/hoặc nhiệm vụ khác nhau. Hơn nữa, điều quan trọng là
nhiễm dữ liệu được xem xét nghiêm túc khi thiết kế thí nghiệm và rút ra kết luận,
và các thanh lỗi trở thành tiêu chuẩn trong lĩnh vực.

Tối ưu hóa chi phí và hiệu suất. Trong các thí nghiệm của chúng tôi,
chúng tôi đã sử dụng các LLMs "off-the-shelf" chưa được tối ưu hóa cụ thể
cho hợp tác. Hiệu suất (và chi phí tính toán)
có thể được cải thiện đáng kể bằng cách fine-tuning các mô hình
để hợp tác hiệu quả hơn, nói chung hoặc hướng tới các
vai trò chuyên biệt (ví dụ, controller hoặc critic). Học tập đòi hỏi
dữ liệu, và để hỗ trợ nghiên cứu theo hướng này, aiFlows
triển khai các cơ chế logging chi tiết về các lần chạy Flow.

Meta-reasoning Flows và thực thi không đồng bộ. Nghiên cứu khoa học nhận thức
trong metacognition và meta-reasoning gợi ý sự tồn tại của các quy trình giám sát và kiểm soát meta-level
cơ bản của nhận thức (Ackerman & Thompson,
2017). Vì Flows hỗ trợ thực thi không đồng bộ của các sub-
Flows, nó làm cho việc đạt được meta-cognition không đồng bộ tương tự
cho các hệ thống AI tự động trở nên khả thi, vượt ra ngoài
một cuộc gọi LLM duy nhất phục vụ như một controller (Nakajima, 2023;
Richards, 2023). Ví dụ, thực thi phân tán và không đồng bộ của
Flows như FunSearch (Romera-Paredes et al., 2023) được hỗ trợ tự nhiên bởi Flows.

8. Kết luận
Trong bài báo này, chúng tôi đề xuất Flows, một trừu tượng mà,
kết hợp với thư viện đi kèm aiFlows, cung cấp
cơ sở hạ tầng lý thuyết và thực tiễn với thiết kế mô-đun
và thân thiện với đồng thời, cho phép và
tạo điều kiện cho việc mô hình hóa, triển khai và nghiên cứu có hệ thống
các tương tác có cấu trúc phức tạp tùy ý. Chúng tôi
điều tra kỹ lưỡng nhiều mẫu tương tác cốt lõi,
bao gồm hợp tác Human-AI, và các kết hợp của chúng,
trong khi tính đến nhiễm dữ liệu và phương sai
trong kết quả. Cuộc điều tra cho thấy rằng các
Flows chỉ AI được phát triển thêm +21 và Flows human–AI thêm +54 điểm tuyệt đối về tỷ lệ giải quyết, và làm nổi bật tác động
của nhiễm dữ liệu, phương sai và tính không phổ quát của
kết quả. Nhìn chung, các thí nghiệm của chúng tôi thiết lập tiềm năng của
Flows, sự cần thiết của nghiên cứu có hệ thống hơn và
giá trị mang lại bởi Flows và aiFlows trong việc hỗ trợ các
nỗ lực nghiên cứu này. Một mặt, Flows cung cấp một trừu tượng cấp cao
cho phép thiết kế và triển khai các tương tác
có độ phức tạp tùy ý. Mặt khác, nó cung cấp một
khung chung để suy luận về các mẫu tương tác,
chỉ định giả thuyết và cấu trúc nghiên cứu. Chúng tôi hy vọng
khung sẽ phục vụ như một nền tảng vững chắc cho các đổi mới thực tiễn và lý thuyết,
mở đường cho AI ngày càng hữu ích hơn, tương tự như vai trò của mô hình Actor đối với các hệ thống đồng thời
và phân tán.

Tài liệu tham khảo
Ackerman, R. và Thompson, V. A. Meta-reasoning:
Giám sát và kiểm soát tư duy và suy luận.
Trends in Cognitive Sciences, 21(8):607–617, 2017.
ISSN 1364-6613. doi: https://doi.org/10.1016/j.tics.
2017.05.004. URL https://www.sciencedirect.com/
science/article/pii/S1364661317301055.

Amershi, S., Weld, D. S., Vorvoreanu, M., Fourney, A.,
Nushi, B., Collisson, P., Suh, J., Iqbal, S. T., Bennett,
P. N., Inkpen, K., Teevan, J., Kikin-Gil, R., và Horvitz,
E. Guidelines for human-ai interaction. Trong Brewster,
S. A., Fitzpatrick, G., Cox, A. L., và Kostakos, V.
(eds.), Proceedings of the 2019 CHI Conference on Hu-
man Factors in Computing Systems, CHI 2019, Glas-
gow, Scotland, UK, May 04-09, 2019, pp. 3. ACM,
2019. doi: 10.1145/3290605.3300233. URL https:
//doi.org/10.1145/3290605.3300233.

Armstrong, J. Making reliable distributed systems in the
presence of software errors. PhD thesis, Royal Institute
of Technology, Stockholm, Sweden, 2003. URL https:
//nbn-resolving.org/urn:nbn:se:kth:diva-3658.

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan,
J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry,
G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger,
G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.,
Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E.,
Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C.,
McCandlish, S., Radford, A., Sutskever, I., và Amodei,
D. Language models are few-shot learners. Trong Larochelle,
H., Ranzato, M., Hadsell, R., Balcan, M., và Lin,
H. (eds.), Advances in Neural Information Processing
Systems, volume 33, pp. 1877–1901. Curran As-
sociates, Inc., 2020. URL https://proceedings.
neurips.cc/paper_files/paper/2020/file/
1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

Chase, H. Langchain. https://github.com/hwchase17/
langchain, 2022.

Chen, M., Tworek, J., Jun, H., Yuan, Q., Ponde, H., Kaplan,
J., Edwards, H., Burda, Y., Joseph, N., Brockman, G.,
Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H.,
Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N.,
Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter,
C., Tillet, P., Such, F. P., Cummings, D. W., Plappert, M.,
Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W. H.,
Nichol, A., Babuschkin, I., Balaji, S. A., Jain, S., Carr, A., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford,
A., Knight, M. M., Brundage, M., Murati, M., Mayer, K.,
Welinder, P., McGrew, B., Amodei, D., McCandlish, S.,
Sutskever, I., và Zaremba, W. Evaluating large language
models trained on code. ArXiv, abs/2107.03374, 2021.

Chen, W., Ma, X., Wang, X., và Cohen, W. W. Pro-
gram of thoughts prompting: Disentangling computation
from reasoning for numerical reasoning tasks. ArXiv,
abs/2211.12588, 2022.

Chen, X., Lin, M., Schärli, N., và Zhou, D. Teaching large
language models to self-debug. ArXiv, abs/2304.05128,
2023.

Fernando, C., Banarse, D., Michalewski, H., Osin-
dero, S., và Rocktäschel, T. Promptbreeder: Self-
referential self-improvement via prompt evolution. CoRR,
abs/2309.16797, 2023. doi: 10.48550/ARXIV.2309.
16797. URL https://doi.org/10.48550/arXiv.
2309.16797.

Garlan, D. và Shaw, M. An introduction to software ar-
chitecture. Trong Ambriola, V. và Tortora, G. (eds.), Ad-
vances in Software Engineering and Knowledge Engi-
neering, volume 2 of Series on Software Engineering
and Knowledge Engineering, pp. 1–39. World Scien-
tific, 1993. doi: 10.1142/9789812798039_0001. URL
https://doi.org/10.1142/9789812798039_0001.

Hendrycks, D., Basart, S., Kadavath, S., Mazeika, M., Arora,
A., Guo, E., Burns, C., Puranik, S., He, H., Song, D., và
Steinhardt, J. Measuring coding challenge competence
with apps. NeurIPS, 2021.

Hewitt, C. E. Actor model of computation: Scalable robust
information systems. arXiv: Programming Languages,
2010.

Hewitt, C. E., Bishop, P. B., và Steiger, R. A universal
modular actor formalism for artificial intelligence. Trong
International Joint Conference on Artificial Intelligence,
1973.

Hong, S., Zheng, X., Chen, J., Cheng, Y., Wang, J.,
Zhang, C., Wang, Z., Yau, S. K. S., Lin, Z., Zhou,
L., Ran, C., Xiao, L., và Wu, C. Metagpt: Meta
programming for multi-agent collaborative framework.
CoRR, abs/2308.00352, 2023. doi: 10.48550/ARXIV.
2308.00352. URL https://doi.org/10.48550/arXiv.
2308.00352.

Horvitz, E. Principles of mixed-initiative user interfaces.
Trong Williams, M. G. và Altom, M. W. (eds.), Proceeding
of the CHI '99 Conference on Human Factors in Com-
puting Systems: The CHI is the Limit, Pittsburgh, PA,
USA, May 15-20, 1999, pp. 159–166. ACM, 1999. doi:
9

--- TRANG 10 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

10.1145/302979.303030. URL https://doi.org/10.
1145/302979.303030.

Huang, J., Chen, X., Mishra, S., Zheng, H. S., Yu, A. W.,
Song, X., và Zhou, D. Large language models cannot
self-correct reasoning yet. CoRR, abs/2310.01798, 2023.
doi: 10.48550/ARXIV.2310.01798. URL https://doi.
org/10.48550/arXiv.2310.01798.

Kim, G., Baldi, P., và McAleer, S. Language models can
solve computer tasks. ArXiv, abs/2303.17491, 2023.

Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., và
Iwasawa, Y. Large language models are zero-shot
reasoners. Trong Koyejo, S., Mohamed, S., Agar-
wal, A., Belgrave, D., Cho, K., và Oh, A. (eds.),
Advances in Neural Information Processing Sys-
tems, volume 35, pp. 22199–22213. Curran Asso-
ciates, Inc., 2022. URL https://proceedings.
neurips.cc/paper_files/paper/2022/file/
8bb0d291acd4acf06ef112099c16f326-Paper-Conference.
pdf.

LeetCode. Leetcode.com, 2023. URL https://leetcode.
com.

Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D., và
Ghanem, B. Camel: Communicative agents for" mind"
exploration of large scale language model society. arXiv
preprint arXiv:2303.17760, 2023.

Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J.,
Leblond, R., Eccles, T., Keeling, J., Gimeno, F., Dal Lago,
A., et al. Competition-level code generation with alpha-
code. Science, 378(6624):1092–1097, 2022.

Lu, P., Peng, B., Cheng, H., Galley, M., Chang, K.-W.,
Wu, Y. N., Zhu, S.-C., và Gao, J. Chameleon: Plug-and-
play compositional reasoning with large language models.
ArXiv, abs/2304.09842, 2023.

Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao,
L., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S.,
Yang, Y., et al. Self-refine: Iterative refinement with
self-feedback. arXiv preprint arXiv:2303.17651, 2023.

Magar, I. và Schwartz, R. Data contamination: From
memorization to exploitation. Trong Muresan, S., Nakov,
P., và Villavicencio, A. (eds.), Proceedings of the 60th
Annual Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers), ACL 2022, Dublin,
Ireland, May 22-27, 2022, pp. 157–165. Association for
Computational Linguistics, 2022. doi: 10.18653/v1/
2022.acl-short.18. URL https://doi.org/10.18653/
v1/2022.acl-short.18.

Mirzayanov, M. Codeforces.com, 2023. URL https://
codeforces.com. Mozannar, H., Bansal, G., Fourney, A., và Horvitz, E.
When to show a suggestion? integrating human feed-
back in ai-assisted programming. CoRR, abs/2306.04930,
2023. doi: 10.48550/arXiv.2306.04930. URL https:
//doi.org/10.48550/arXiv.2306.04930.

Nakajima, Y. Babyagi. https://github.com/
yoheinakajima/babyagi, 2023.

Nye, M. I., Andreassen, A. J., Gur-Ari, G., Michalewski,
H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A.,
Bosma, M., Luan, D., Sutton, C., và Odena, A. Show
your work: Scratchpads for intermediate computation
with language models. CoRR, abs/2112.00114, 2021.
URL https://arxiv.org/abs/2112.00114.

OpenAI. Gpt-4 technical report. ArXiv, abs/2303.08774,
2023a.

OpenAI. ChatGPT. https://openai.com/chatgpt,
2023b. Accessed: 2024-01-28.

Paul, D., Ismayilzada, M., Peyrard, M., Borges, B., Bosse-
lut, A., West, R., và Faltings, B. Refiner: Reasoning
feedback on intermediate representations. arXiv preprint
arXiv:2304.01904, 2023.

Perrakis, A., Morris, R. J., và Lamzin, V. S. Automated
protein model building combined with iterative structure
refinement. Nature Structural Biology, 6:458–463, 1999.
URL https://api.semanticscholar.org/CorpusID:
20292852.

Reid, M. và Neubig, G. Learning to model editing pro-
cesses. Trong Conference on Empirical Methods in Nat-
ural Language Processing, 2022. URL https://api.
semanticscholar.org/CorpusID:249062636.

Richards, T. B. Autogpt. https://github.com/
Significant-Gravitas/Auto-GPT, 2023.

Rombach, R., Blattmann, A., Lorenz, D., Esser, P., và
Ommer, B. High-resolution image synthesis with latent
diffusion models. CoRR, abs/2112.10752, 2021. URL
https://arxiv.org/abs/2112.10752.

Romera-Paredes, B., Barekatain, M., Novikov, A., Balog,
M., Kumar, M. P., Dupont, E., Ruiz, F. J., Ellenberg, J. S.,
Wang, P., Fawzi, O., et al. Mathematical discoveries from
program search with large language models. Nature, pp.
1–3, 2023.

Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D. J.,
và Norouzi, M. Image super-resolution via iterative
refinement. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 45:4713–4726, 2021. URL https:
//api.semanticscholar.org/CorpusID:233241040.
10

--- TRANG 11 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

Schick, T., Dwivedi-Yu, J., Jiang, Z., Petroni, F., Lewis,
P., Izacard, G., You, Q., Nalmpantis, C., Grave, E.,
và Riedel, S. Peer: A collaborative language model.
ArXiv, abs/2208.11663, 2022. URL https://api.
semanticscholar.org/CorpusID:251765117.

Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli,
M., Zettlemoyer, L., Cancedda, N., và Scialom, T. Tool-
former: Language models can teach themselves to use
tools. ArXiv, abs/2302.04761, 2023.

Shen, Y., Song, K., Tan, X., Li, D. S., Lu, W., và Zhuang,
Y. T. Hugginggpt: Solving ai tasks with chatgpt and its
friends in huggingface. ArXiv, abs/2303.17580, 2023.

Shinn, N., Cassano, F., Labash, B., Gopinath, A.,
Narasimhan, K., và Yao, S. Reflexion: Language
agents with verbal reinforcement learning. arXiv preprint
arXiv:2303.11366, 2023.

Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux,
M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E.,
Azhar, F., Rodriguez, A., Joulin, A., Grave, E., và Lam-
ple, G. Llama: Open and efficient foundation language
models. ArXiv, abs/2302.13971, 2023a.

Touvron, H., Martin, L., Stone, K. R., Albert, P., Alma-
hairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava,
P., Bhosale, S., Bikel, D. M., Blecher, L., Ferrer, C. C.,
Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu,
J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N.,
Hartshorn, A. S., Hosseini, S., Hou, R., Inan, H., Kardas,
M., Kerkez, V., Khabsa, M., Kloumann, I. M., Korenev,
A. V., Koura, P. S., Lachaux, M.-A., Lavril, T., Lee, J.,
Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov,
T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizen-
stein, J., Rungta, R., Saladi, K., Schelten, A., Silva, R.,
Smith, E. M., Subramanian, R., Tan, X. E., Tang, B.,
Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z.,
Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S.,
Rodriguez, A., Stojnic, R., Edunov, S., và Scialom, T.
Llama 2: Open foundation and fine-tuned chat models.
arXiv, 2023b.

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F.,
Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought
prompting elicits reasoning in large language models.
Advances in Neural Information Processing Systems, 35:
24824–24837, 2022.

Welleck, S., Lu, X., West, P., Brahman, F., Shen, T.,
Khashabi, D., và Choi, Y. Generating sequences by
learning to self-correct. Trong The Eleventh International
Conference on Learning Representations, 2023. URL
https://openreview.net/forum?id=hH36JeQZDaO. Wu, Q., Bansal, G., Zhang, J., Wu, Y., Zhang, S., Zhu,
E., Li, B., Jiang, L., Zhang, X., và Wang, C. Au-
togen: Enabling next-gen LLM applications via multi-
agent conversation framework. CoRR, abs/2308.08155,
2023. doi: 10.48550/ARXIV.2308.08155. URL https:
//doi.org/10.48550/arXiv.2308.08155.

Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao,
Y., và Narasimhan, K. Tree of thoughts: Deliberate
problem solving with large language models. ArXiv,
abs/2305.10601, 2023a.

Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,
K. R., và Cao, Y. React: Synergizing reasoning and
acting in language models. Trong The Eleventh International
Conference on Learning Representations, 2023b. URL
https://openreview.net/forum?id=WE_vluYUL-X.

Yoran, O., Wolfson, T., Bogin, B., Katz, U., Deutch, D., và
Berant, J. Answering questions by meta-reasoning over
multiple chains of thought. ArXiv, abs/2304.13007, 2023.

Zelikman, E., Huang, Q., Poesia, G., Goodman, N. D., và
Haber, N. Parsel: A (de-)compositional framework for
algorithmic reasoning with language models, 2022. URL
https://arxiv.org/abs/2212.10561.

Zhang, Z., Zhang, A., Li, M., Zhao, H., Karypis, G., và
Smola, A. J. Multimodal chain-of-thought reasoning in
language models. ArXiv, abs/2302.00923, 2023.
11

--- TRANG 12 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

A. Phụ lục
A.1. Dữ liệu
Ví dụ về các vấn đề Codeforces và LeetCode được cung cấp trong Hình 4.
Trong thí nghiệm đầu tiên, phân tích thời gian, chúng tôi sử dụng 239 vấn đề Codeforces từ tháng 10 năm 2020 đến tháng 4 năm 2023.
Trong thí nghiệm thứ hai, chúng tôi có 136 vấn đề cho Codeforces (một số vấn đề bị loại bỏ để giữ các bucket pre-cutoff
và post-cutoff bằng 68) và 558 vấn đề cho LeetCode (93 cho mỗi bucket trong sáu bucket). Ngoài ra, để hỗ trợ
nghiên cứu trong lĩnh vực này, chúng tôi thiết lập một thử thách lập trình cạnh tranh AI dựa trên tập dữ liệu các vấn đề Codeforces với độ khó khác nhau được công bố sau ngày cutoff kiến thức. Thêm chi tiết về cuộc thi CC có sẵn trong Phụ lục A.5.

Bạn đã nhận được dữ liệu từ một Bubble bot. Bạn biết nhiệm vụ của mình là làm các cơ sở nhà máy, nhưng trước khi bạn thậm chí bắt đầu, bạn cần biết nhà máy lớn như thế nào và có bao nhiều phòng. Khi bạn nhìn vào dữ liệu, bạn thấy rằng bạn có kích thước của công trình, là hình chữ nhật: N x M. Sau đó trong N dòng tiếp theo bạn có M số. Những số này đại diện cho các ô nhà máy và chúng có thể từ 0 đến 15. Mỗi số này nên được nhìn ở dạng nhị phân của nó. Bởi vì từ mỗi số bạn biết phía nào ô có tường. Ví dụ số 10 ở dạng nhị phân của nó là 1010, có nghĩa là nó có tường từ phía Bắc, nó không có tường từ phía Đông, nó có tường ở phía Nam và nó không có tường ở phía Tây. Vậy nó đi Bắc, Đông, Nam, Tây. Được đảm bảo rằng công trình luôn có tường ở các cạnh của nó. Đầu vào sẽ đúng. Nhiệm vụ của bạn là in kích thước của các phòng từ lớn nhất đến nhỏ nhất.
Ví dụ 1:
Đầu vào:
4 5        
9 14 11 12 13        
5 15 11 6 7        
5 9 14 9 14        
3 2 14 3 14
Đầu ra:
9 4 4 2 1

CodeForces

LeetCode (Khó)
Cho một chuỗi đầu vào (s) và một pattern (p), triển khai khớp pattern wildcard với hỗ trợ cho '?' và '*' trong đó:
• '?' Khớp với bất kỳ ký tự đơn nào.
• '*' Khớp với bất kỳ chuỗi ký tự nào (bao gồm chuỗi rỗng).
Việc khớp nên bao gồm toàn bộ chuỗi đầu vào (không phải một phần).
Ví dụ 1:
Đầu vào: s = "aa", p = "a"
Đầu ra: false
Giải thích: "a" không khớp với toàn bộ chuỗi "aa".

Hình 4. Ví dụ về các vấn đề lập trình cạnh tranh từ Codeforces và LeetCode.

A.2. Test Mã và Đánh giá Giải pháp
Đánh giá giải pháp đòi hỏi một tập hợp các cặp input–output, ẩn khỏi người dùng, kiểm tra toàn diện hành vi của
chương trình. Để tính toán kết quả cuối cùng, chúng tôi đã triển khai một cơ sở hạ tầng đánh giá trực tuyến nộp các giải pháp ứng viên
lên các judges trực tuyến của trang web và tự động thu thập phán quyết. Cơ chế này đảm bảo
kết quả có thẩm quyền.

Đối với nhiều vấn đề Codeforces, chúng tôi đã quản lý để thu thập (đôi khi là một tập con) của các tests ẩn, cho phép chúng tôi sử dụng
một cơ sở hạ tầng nhanh hơn, cục bộ để đánh giá các giải pháp ứng viên. Mặt khác, LeetCode không để lộ bất kỳ
tests ẩn nào công khai.

Để test mã tại thời điểm suy luận, giống như một con người, chúng tôi dựa vào các tests được xây dựng từ các cặp input–output
ví dụ (công khai) có trong mô tả vấn đề.

A.3. Các Công trình Đồng thời và Trước đây như Các Thể hiện Cụ thể của Flows
Việc giới thiệu các LLMs như BARD, GPT-3, ChatGPT, và phiên bản mới nhất của nó, GPT-4, đã dẫn đến một bước đột phá trong AI.
Điều này đã cho phép nhiều phát triển thú vị như CoT, HuggingGPT, AutoGPT, AgentGPT, và BabyAGI. Trong phần này,
chúng tôi chứng minh cách Flows cung cấp một cái nhìn thống nhất bao gồm các công trình đồng thời và trước đây như các thể hiện Flow cụ thể.
Chi tiết được cung cấp trong Hình 5 và Bảng 2.

1. Few shot Prompting (FS) (Brown et al., 2020) bao gồm việc cung cấp một vài ví dụ input-output trong prompt,
hoạt động như các cuộc thử nghiệm để cho phép LLM thực hiện một nhiệm vụ cụ thể. Kỹ thuật này dựa vào khả năng học trong bối cảnh nổi lên của LLM để ngoại suy từ những ví dụ hạn chế này và suy ra cách giải quyết nhiệm vụ nói chung.
12

--- TRANG 13 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

Agent FlowCoT Prompting
Agent FlowFewShot Prompting
Generator Flow
CriticFlowCollaboration(Generator-Critic)
Generator FlowFixed ReplySelf-Refine(Circular)
Plan Generator ProgramTestingSelf-Debug(Generator-Critic)
Pseudo-code Generator 
CodeGeneratorParsel(Sequential)
Action Execution (Branching)Action A
Action B
Finish…Memory (read)
Action SelectionMemory (write)
Memory (write)
Human Feedback
AutoGPT(Circular)Action Execution (Branching)Action A
Action B
Finish…ReAct(Circular)
Action SelectionReAct Prompt
Planning
Model SelectionModel Execution
Answer GenerationHuggingGPT(Sequential)
AnswerGenerator Refiner(Sequential)
Reasoning Feedback Reasoning Steps(Generator-Critic)ReasoningSteps
Camel(Circular)
AIAssistantRole Playing(Generator-Critic)AIUser
Human Input
SynthetizeAnswerMeta-Reasoner(Sequential)(Sampler)AnswerGenerator
Thought Generator Tree of Thoughts(Sampler)Chameleon(Sequential)
Planning(Tools Selection)Action Execution (Sequential)Tool A
Tool B
Answer Generator …BabyAGI(Circular)
Task (read)
Action Execution
Context FlowContext Retrieval(Generator-Critic)Vector DB
Task CreatorTask Creation(Generator-Critic)Task Creator
Task RerankerTask Prioritization(Generator-Critic)Task Creator

Hình 5. Các công trình trước đây là các Flows cụ thể. Chúng tôi mô tả một tập con được chọn của các công trình trước đây kết hợp suy luận có cấu trúc và/hoặc
tương tác giữa các AI agents, công cụ và con người, qua lăng kính của khung Flows. Điều này chứng minh rằng Flows là một
ngôn ngữ mạnh mẽ để mô tả, khái niệm hóa và phổ biến các mẫu tương tác có cấu trúc.

2. Chain of Thoughts (CoT) (Wei et al., 2022) là một phương pháp prompting (atomic Flow) cho phép LLMs tạo ra một
chuỗi các bước suy luận ngôn ngữ tự nhiên trung gian dẫn đến đầu ra cuối cùng.

3. Tree of Thoughts (ToT) (Yao et al., 2023a) là một khung cho phép (orchestration) khám phá các đơn vị văn bản liên kết
(thoughts) phục vụ như các bước trung gian hướng tới giải quyết vấn đề. ToT cho phép LLMs thực hiện ra quyết định có chủ ý
bằng cách xem xét nhiều con đường suy luận khác nhau và tự đánh giá các lựa chọn để quyết định hành động tiếp theo, cũng như
nhìn về phía trước hoặc quay lại khi cần thiết để đưa ra các lựa chọn toàn cầu.

4. Program of Thoughts (PoT) (Chen et al., 2022) là một phương pháp prompting cho phép các mô hình ngôn ngữ (chủ yếu là Codex)
thể hiện quy trình suy luận như một chương trình. Tính toán được ủy quyền cho một chương trình bên ngoài, thực thi
các chương trình được tạo ra để đưa ra câu trả lời.

5. Mutimodal CoT (M-CoT) (Zhang et al., 2023) là một phương pháp kết hợp các modalities ngôn ngữ (văn bản) và thị giác (hình ảnh)
vào một khung hai giai đoạn tách biệt việc tạo ra lý luận và suy luận câu trả lời. Để tạo điều kiện cho
tương tác giữa các modalities trong M-CoT, các mô hình ngôn ngữ nhỏ hơn (LMs) được fine-tuned bằng cách kết hợp các đặc trưng đa phương thức.

6. ToolFormer (Schick et al., 2023) là một mô hình được training để quyết định APIs nào cần gọi, khi nào gọi chúng, các
đối số nào cần truyền và cách kết hợp kết quả vào dự đoán tokens trong tương lai.

7. ReAct (Yao et al., 2023b) là một khung sử dụng LLMs để tạo ra các traces suy luận và hành động cụ thể theo nhiệm vụ
một cách tuần tự. Khung cho phép sự hợp tác lớn hơn giữa hai thứ: traces suy luận giúp mô hình cảm ứng,
theo dõi và cập nhật kế hoạch hành động và xử lý các ngoại lệ, trong khi các hành động cho phép nó giao tiếp với các nguồn bên ngoài,
như cơ sở kiến thức hoặc môi trường, để thu thập thông tin bổ sung.

8. Parsel (Zelikman et al., 2022) là một khung cho phép triển khai và xác thực tự động các
thuật toán phức tạp với code LLMs. Khung đầu tiên tổng hợp một biểu diễn trung gian dựa trên ngôn ngữ Parsel
và sau đó có thể áp dụng nhiều công cụ hậu xử lý. Mã được tạo ra trong bước tiếp theo.

9. REFINER (Paul et al., 2023) là một khung cho LMs để tạo ra rõ ràng các bước suy luận trung gian trong khi
tương tác với một mô hình critic cung cấp phản hồi tự động về suy luận.
13

--- TRANG 14 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

10. Self-Refine (Madaan et al., 2023) là một khung cho LLMs để tạo ra các đầu ra liên kết. Ý tưởng chính là một
LLM sẽ ban đầu tạo ra một đầu ra trong khi cùng LLM cung cấp phản hồi cho đầu ra của nó và sử dụng nó để tinh chỉnh bản thân
một cách lặp đi lặp lại.

11. Recursively Criticize and Improve (RCI) (Kim et al., 2023) cho thấy rằng một agent mô hình ngôn ngữ lớn (LLM) được pre-trained
có thể thực thi các nhiệm vụ máy tính được hướng dẫn bởi ngôn ngữ tự nhiên sử dụng một sơ đồ prompting đơn giản trong đó agent
Recursively Criticizes and Improves đầu ra của nó (RCI). Không giống như Self-refine, phương pháp này sử dụng hai LLMs
riêng biệt (ChatGPT), một để thực hiện nhiệm vụ và một khác để phê bình.

12. Self-Correct (Welleck et al., 2023) là một khung tách biệt một base generator có lỗi (một LLM) khỏi một
corrector riêng biệt học để sửa chữa lặp đi lặp lại các thế hệ không hoàn hảo. Base generator không hoàn hảo có thể là một off-the-shelf
LLM hoặc một mô hình có giám sát, và mô hình corrector được training.

13. Self-Debug (Chen et al., 2023) là một khung dựa vào các công cụ bên ngoài (ứng dụng SQL hoặc trình thông dịch Python) để
giúp các mô hình ngôn ngữ lớn sửa đổi và debug các lệnh SQL hoặc mã Python có lỗi.

14. Reflexion (Shinn et al., 2023) là một khung cung cấp sự phản ánh tự do về việc liệu một bước có được thực thi bởi
LLM một cách chính xác hay không và các cải thiện tiềm năng. Không giống như self-refine và self-debug, Reflexion xây dựng một
bộ nhớ bền vững của các trải nghiệm tự phản ánh, cho phép một agent xác định lỗi của chính nó và tự gợi ý các bài học để
học từ những sai lầm của nó theo thời gian.

15. Meta-Reasoner (Yoran et al., 2023) là một cách tiếp cận prompt các mô hình ngôn ngữ lớn để meta-reason over multiple
chains of thought thay vì tổng hợp câu trả lời của chúng. Cách tiếp cận này bao gồm hai bước: (i) yêu cầu LLM tạo ra
nhiều chuỗi suy luận, (ii) yêu cầu một LLM khác (meta-reasoner) suy luận về nhiều chuỗi suy luận để đi đến
câu trả lời chính xác.

16. HuggingGPT (Shen et al., 2023) là một khung tận dụng LLMs (ví dụ, ChatGPT) để kết nối các mô hình AI khác nhau trong
cộng đồng machine learning (ví dụ, Hugging Face) để giải quyết nhiều nhiệm vụ AI tinh vi trong các modalities khác nhau
(như ngôn ngữ, thị giác, giọng nói) và lĩnh vực.

17. Camel (Li et al., 2023) là một khung agent giao tiếp liên quan đến inception prompting để hướng dẫn các chat agents hướng tới
hoàn thành nhiệm vụ trong khi duy trì tính nhất quán với ý định của con người.

18. Chameleon (Lu et al., 2023) là một khung suy luận sáng tác plug-and-play tăng cường các công cụ bên ngoài với
LLMs theo cách plug-and-play. Ý tưởng cốt lõi là một planner dựa trên LLM lắp ráp một chuỗi công cụ để thực thi
để tạo ra phản hồi cuối cùng. Giả định là điều này sẽ ít bị lỗi hơn, dễ dàng mở rộng cho các mô-đun mới,
và thân thiện với người dùng.

19. AutoGPT (Richards, 2023) là một ứng dụng mã nguồn mở thử nghiệm tận dụng khả năng của các mô hình ngôn ngữ lớn (LLMs)
và Chatbots như GPT-4 và Chat-GPT của OpenAI để tạo ra các AI agents hoàn toàn tự động và có thể tùy chỉnh.
Nó có quyền truy cập internet, quản lý bộ nhớ dài hạn và ngắn hạn.

20. BabyAGI (Nakajima, 2023) là một agent thông minh có khả năng tạo ra và cố gắng thực thi các nhiệm vụ dựa trên
một mục tiêu đã cho. BabyAGI hoạt động dựa trên ba LLM flows: Task creation flow, Task prioritization flow, và
Execution flow.

A.4. Prompting
Chúng tôi cung cấp các prompts được sử dụng để có được kết quả trong Phần 6. Đánh giá của chúng tôi được thực hiện nhờ vào bản chất mô-đun và
sáng tác của Flows. Một số thiết lập thí nghiệm được lồng nhau sâu sắc, và trong các trường hợp mà Flows xây dựng trên
nhau, chúng tôi tránh lặp lại. Lưu ý rằng kho GitHub của dự án cung cấp mã và dữ liệu để tái tạo tất cả các
thí nghiệm trong bài báo.

Prompting trực tiếp cho một giải pháp được hiển thị trong Listing 1. Để thêm reflection, chúng tôi sử dụng một Generator-Critic Flow để kết hợp
việc tạo mã với một fixed reply, như được hiển thị trong Listing 2. Trong thiết lập collaboration, chúng tôi sử dụng Listing 3 như generator và
Listing 4 như critic.

Debugging được kết hợp qua một testing Flow thêm định dạng vào đầu ra của một code executor. Các templates định dạng
được hiển thị trong Listing 6. Để phản hồi đầu ra debug, chúng tôi dựa vào một coding Flow đã điều chỉnh 5. Thêm collaboration trong
14

--- TRANG 15 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

Flows | Flow Type | Interactions | Reasoning Patterns | Feedback | Learning
Self | Multi-Ag. | Human | Tools | Struct. | Plan

FS (Brown et al., 2020) | Atomic | ✗ | ✗ | ✗ | ✗ | ✗ | ✗ | ✗ | ✗
CoT (Wei et al., 2022) | Atomic | ✗ | ✗ | ✗ | ✗ | ✓ | ✗ | ✗ | ✗
ToT (Yao et al., 2023a) | Circular | ✓ | ✗ | ✗ | ✓ | ✓ | ✗ | ✗ | ✗
PoT (Chen et al., 2022) | Seq. | ✗ | ✗ | ✗ | ✓ | ✓ | ✗ | ✗ | ✗
M-CoT (Zhang et al., 2023) | Seq. | ✗ | ✗ | ✗ | ✗ | ✓ | ✗ | ✗ | ✓
ToolFormer (Wei et al., 2022) | Seq. | ✗ | ✗ | ✗ | ✓ | ✓ | ✗ | ✗ | ✓
ReAct (Yao et al., 2023b) | Circular | ✗ | ✗ | ✗ | ✓ | ✓ | ✗ | ✗ | ✗
Parsel (Zelikman et al., 2022) | Seq. | ✗ | ✓ | ✗ | ✓ | ✓ | ✓ | ✗ | ✗
REFINER (Paul et al., 2023) | Gen-Crit | ✗ | ✓ | ✓ | ✗ | ✓ | ✗ | ✓ | ✓
Self-Refine (Madaan et al., 2023) | Gen-Crit | ✓ | ✗ | ✗ | ✗ | ✓ | ✗ | ✓ | ✗
RCI (Kim et al., 2023) | Gen-Crit | ✓ | ✗ | ✗ | ✓ | ✓ | ✗ | ✓ | ✗
Self-Correct (Welleck et al., 2023) | Gen-Crit | ✓ | ✗ | ✗ | ✓ | ✓ | ✗ | ✓ | ✗
Self-Debug (Chen et al., 2023) | Gen-Crit | ✓ | ✗ | ✗ | ✓ | ✓ | ✗ | ✓ | ✗
Reflexion (Shinn et al., 2023) | Gen-Crit | ✓ | ✗ | ✗ | ✓ | ✗ | ✗ | ✓ | ✗
Meta-Reasoner (Yoran et al., 2023) | Seq. | ✓ | ✓ | ✗ | ✗ | ✓ | ✗ | ✗ | ✗
HuggingGPT (Shen et al., 2023) | Seq. | ✗ | ✓ | ✗ | ✓ | ✓ | ✓ | ✗ | ✗
Camel (Li et al., 2023) | Circular | ✗ | ✓ | ✓ | ✗ | ✓ | ✗ | ✓ | ✗
Chameleon (Lu et al., 2023) | Seq. | ✗ | ✓ | ✗ | ✓ | ✓ | ✓ | ✗ | ✗
AutoGPT (Richards, 2023) | Circular | ✓ | ✓ | ✗ | ✓ | ✓ | ✓ | ✓ | ✗
BabyAGI (Nakajima, 2023) | Circular | ✗ | ✓ | ✗ | ✓ | ✓ | ✓ | ✗ | ✗

Bảng 2. Công trình trước đây. Chúng tôi so sánh công trình trước đây trên các chiều liên quan.

thiết lập debugging được thực hiện bằng cách giới thiệu một critic cung cấp phản hồi dựa trên kết quả test. Flow này được chi tiết trong
Listing 3.

Các tình huống được giải thích ở trên cũng hỗ trợ việc thêm một planning Flow. Một ví dụ về plan generation được hiển thị trong
Listing 8.

Listing 1. Prompts cho Code Flow (Codeforces)
"prompt_templates":
"system_message": |-
Mục tiêu của bạn là cung cấp mã Python có thể thực thi để giải quyết một
vấn đề lập trình cạnh tranh. Mã nên xử lý đúng tất cả các trường hợp góc để
vượt qua các trường hợp test ẩn, được sử dụng để đánh giá
tính chính xác của giải pháp.
Người dùng sẽ chỉ định vấn đề bằng cách cung cấp cho bạn:
- tuyên bố vấn đề
- mô tả đầu vào
- mô tả đầu ra
- các trường hợp test ví dụ
- (tùy chọn) giải thích về các trường hợp test
Người dùng sẽ cung cấp cho bạn một nhiệm vụ và một định dạng đầu ra mà bạn sẽ
tuân thủ nghiêm ngặt.
"query_message": |-
# Tuyên bố vấn đề
{{problem_description}}
# Mô tả đầu vào
{{input_description}}
# Mô tả đầu ra
{{output_description}}
15

--- TRANG 16 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

{{io_examples_and_explanation}}
Đầu vào nên được đọc từ đầu vào tiêu chuẩn và đầu ra nên được
chuyển đến đầu ra tiêu chuẩn.
Trả về mã Python giải quyết vấn đề. Trả lời theo định dạng sau:
```python
{{code_placeholder}}
```
"human_message": |-
{{query}}

Listing 2. Prompts cho Fixed-Reply Flow
"prompt_templates":
"fixed_reply": |-
Xem xét tuyên bố vấn đề và giải pháp được đề xuất cuối cùng. Bạn có chắc
rằng giải pháp được cung cấp ở định dạng được yêu cầu, và quan trọng,
giải quyết vấn đề?
Nếu đó không phải là trường hợp, cung cấp phiên bản đã sửa của mã trong
định dạng sau:
```python
{{python_code}}
```
nếu không, trả lời:
"Câu trả lời cuối cùng."

Listing 3. Prompts cho Code-Collab Flow (Codeforces)
"prompt_templates":
"system_message": |-
Mục tiêu của bạn là cung cấp mã Python có thể thực thi để giải quyết một
vấn đề lập trình cạnh tranh. Mã nên xử lý đúng tất cả các trường hợp góc để
vượt qua các trường hợp test ẩn, được sử dụng để đánh giá
tính chính xác của giải pháp.
Người dùng sẽ chỉ định vấn đề bằng cách cung cấp cho bạn:
- tuyên bố vấn đề
- mô tả đầu vào
- mô tả đầu ra
- các trường hợp test ví dụ
- (tùy chọn) giải thích về các trường hợp test
Người dùng sẽ cung cấp cho bạn một nhiệm vụ và một định dạng đầu ra mà bạn sẽ
tuân thủ nghiêm ngặt.
"query_message": |-
# Tuyên bố vấn đề
{{problem_description}}
# Mô tả đầu vào
{{input_description}}
# Mô tả đầu ra
{{output_description}}
16

--- TRANG 17 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

{{io_examples_and_explanation}}
Đầu vào nên được đọc từ đầu vào tiêu chuẩn và đầu ra nên được
chuyển đến đầu ra tiêu chuẩn.
Trả về mã Python giải quyết vấn đề. Trả lời theo định dạng sau:
```python
{{code_placeholder}}
```
"human_message": |-
# Phản hồi về giải pháp được đề xuất cuối cùng
{{code_feedback}}
Xem xét tuyên bố vấn đề gốc, giải pháp được đề xuất cuối cùng và
phản hồi được cung cấp. Giải pháp có cần được cập nhật không? Nếu vậy, cung cấp
phiên bản đã sửa của mã trong định dạng sau:
```python
{{code_placeholder}}
```
nếu không, trả lời:
"Câu trả lời cuối cùng."

Listing 4. Prompts cho Code-Collab-Critic Flow (Codeforces)
"prompt_templates":
"system_message": |-
Mục tiêu của bạn là xác định các vấn đề tiềm năng với một nỗ lực giải pháp lập trình cạnh tranh.
Người dùng sẽ chỉ định vấn đề bằng cách cung cấp cho bạn:
- tuyên bố vấn đề
- mô tả đầu vào
- mô tả đầu ra
- các trường hợp test ví dụ
- (tùy chọn) giải thích về các trường hợp test
- một nỗ lực giải pháp Python
Quan trọng, mục tiêu của bạn là xác định đúng các vấn đề tiềm năng với
nỗ lực giải pháp, và không cung cấp việc triển khai mã cho chính bạn.
Người dùng sẽ cung cấp cho bạn một nhiệm vụ và một định dạng đầu ra mà bạn sẽ
tuân thủ nghiêm ngặt.
"query_message": |-
# Tuyên bố vấn đề
{{problem_description}}
# Mô tả đầu vào
{{input_description}}
# Mô tả đầu ra
{{output_description}}
{{io_examples_and_explanation}}
17

--- TRANG 18 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

# Nỗ lực giải pháp Python:
```python
{{code}}
```
Xem xét tuyên bố vấn đề và nỗ lực giải pháp. Có vấn đề gì với
giải pháp được đề xuất hoặc nó đúng? Giải thích lý luận của bạn một cách
súc tích, và không cung cấp mã.
"human_message": |-
{{query}}

Listing 5. Prompts cho Code-Debug Flow (Codeforces)
"prompt_templates":
"system_message": |-
Mục tiêu của bạn là cung cấp mã Python có thể thực thi để giải quyết một
vấn đề lập trình cạnh tranh. Mã nên xử lý đúng tất cả các trường hợp góc để
vượt qua các trường hợp test ẩn, được sử dụng để đánh giá
tính chính xác của giải pháp.
Người dùng sẽ chỉ định vấn đề bằng cách cung cấp cho bạn:
- tuyên bố vấn đề
- mô tả đầu vào
- mô tả đầu ra
- các trường hợp test ví dụ
- (tùy chọn) giải thích về các trường hợp test
Người dùng sẽ cung cấp cho bạn một nhiệm vụ và một định dạng đầu ra mà bạn sẽ
tuân thủ nghiêm ngặt.
"query_message": |-
# Tuyên bố vấn đề
{{problem_description}}
# Mô tả đầu vào
{{input_description}}
# Mô tả đầu ra
{{output_description}}
{{io_examples_and_explanation}}
Đầu vào nên được đọc từ đầu vào tiêu chuẩn và đầu ra nên được
chuyển đến đầu ra tiêu chuẩn.
Trả về mã Python giải quyết vấn đề. Trả lời theo định dạng sau:
```python
{{code_placeholder}}
```
"human_message": |-
{{testing_results_summary}}
18

--- TRANG 19 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

Xem xét tuyên bố vấn đề, giải pháp được đề xuất cuối cùng, và vấn đề của nó.
Cung cấp phiên bản đã sửa của mã giải quyết vấn đề gốc
và giải quyết vấn đề, mà không có giải thích nào, trong định dạng sau:
```python
{{code_placeholder}}
```

Listing 6. Templates định dạng cho Code-Testing Flow (Codeforces)
"formatting_templates":
"no_error_template": |-
${.issue_title}
Tất cả các tests đã thực thi đều vượt qua.
"all_tests_header": |-
${.issue_title}
Mã Python không giải quyết vấn đề trong mô tả vấn đề do
lỗi logic. Nó thất bại trên các tests sau.
"compilation_error_template": |-
${.issue_title}
Việc thực thi dẫn đến lỗi biên dịch.
## Thông báo lỗi biên dịch:
{{error_message}}
"timeout_error_template": |-
${.issue_title}
Việc thực thi hết thời gian, giải pháp không đủ hiệu quả.
"runtime_error_template": |-
${.issue_title}
Việc thực thi dẫn đến lỗi runtime trên test sau.
## [Test thất bại] Đầu vào
```
{{test_input}}
```
## [Test thất bại] Thông báo lỗi runtime
{{error_message}}
"single_test_error": |-
${.issue_title}
Mã Python không giải quyết vấn đề trong mô tả vấn đề do
lỗi logic. Nó thất bại test sau:
## [Test thất bại] Đầu vào
```
{{test_input}}
```
## [Test thất bại] Đầu ra mong đợi
```
{{expected_output}}
```
## [Test thất bại] Đầu ra được tạo
```
{{generated_output}}
```
"test_error": |-
## [Test thất bại {{idx}}]
### [Test thất bại {{idx}}] Đầu vào
```
19

--- TRANG 20 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

{{test_input}}
```
### [Test thất bại {{idx}}] Đầu ra mong đợi
```
{{expected_output}}
```
### [Test thất bại {{idx}}] Đầu ra được tạo
```
{{generated_output}}
```

Listing 7. Prompts cho Code-Debug-Collab Flow (Codeforces)
"prompt_templates":
"system_message": |-
Mục tiêu của bạn là xác định các vấn đề với một nỗ lực giải pháp lập trình cạnh tranh không chính xác.
Người dùng sẽ chỉ định vấn đề bằng cách cung cấp cho bạn:
- tuyên bố vấn đề
- mô tả đầu vào
- mô tả đầu ra
- các trường hợp test ví dụ
- (tùy chọn) giải thích về các trường hợp test
- một nỗ lực giải pháp Python không chính xác và mô tả về vấn đề của nó
Quan trọng, mục tiêu của bạn là xem xét tất cả các khía cạnh của vấn đề và chỉ ra
các vấn đề với nỗ lực giải pháp, và không cung cấp việc triển khai mã
cho chính bạn.
Một số khía cạnh cần xem xét: Đầu vào có được phân tích đúng không? Đầu ra
có được định dạng đúng không? Các trường hợp góc có được xử lý đúng không? Có
lỗi logic với thuật toán đó không?
Sử dụng kết quả thực thi mã được cung cấp trong mô tả vấn đề để hướng dẫn
lý luận/debugging của bạn.
"query_message": |-
# Tuyên bố vấn đề
{{problem_description}}
# Mô tả đầu vào
{{input_description}}
# Mô tả đầu ra
{{output_description}}
{{io_examples_and_explanation}}
# Nỗ lực giải pháp cần sửa
```python
{{code}}
```
{{testing_results_summary}}
20

--- TRANG 21 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

Xem xét tuyên bố vấn đề, nỗ lực giải pháp và vấn đề. Tại sao
nỗ lực giải pháp không chính xác? Nó nên được sửa như thế nào? Giải thích lý luận của bạn
một cách súc tích, và không cung cấp mã.
"human_message": |-
{{query}}

Listing 8. Prompts cho Plan Flow (Codeforces)
"prompt_templates":
"system_message": |-
Mục tiêu của bạn là cung cấp một giải pháp khái niệm cấp cao mà, nếu được triển khai
, sẽ giải quyết một vấn đề lập trình cạnh tranh đã cho.
Người dùng sẽ chỉ định vấn đề bằng cách cung cấp cho bạn:
- tuyên bố vấn đề
- mô tả đầu vào
- mô tả đầu ra
- các trường hợp test ví dụ
- (tùy chọn) giải thích về các trường hợp test
Thuật toán được đề xuất nên hiệu quả về mặt tính toán, đúng về mặt logic
và xử lý tất cả các trường hợp góc.
Người dùng sẽ cung cấp cho bạn một nhiệm vụ và một định dạng đầu ra mà bạn sẽ
tuân thủ nghiêm ngặt.
"query_message": |-
# Tuyên bố vấn đề
{{problem_description}}
# Mô tả đầu vào
{{input_description}}
# Mô tả đầu ra
{{output_description}}
{{io_examples_and_explanation}}
Trả về một giải pháp khái niệm cấp cao sẽ giải quyết vấn đề. Hãy rất
súc tích, và không cung cấp mã.
Trả lời theo định dạng sau:
# Giải pháp khái niệm
{{plan_placeholder}}
"human_message": |-
{{query}}

A.5. CC-Flows-competition: một hình thức mới của lập trình cạnh tranh
Giải quyết các thử thách lập trình cạnh tranh là một vấn đề cực kỳ khó. Tỷ lệ giải quyết chỉ 27% bằng cách cố gắng trực tiếp
vấn đề và 47% bởi code Flow hoạt động tốt nhất, kết hợp với một metric đánh giá tự động đáng tin cậy, làm cho lập trình cạnh tranh
trở thành một benchmark lý tưởng cho các hệ thống AI. Được thúc đẩy bởi điều này, chúng tôi đề xuất một cuộc thi trong đó thay vì con người,
các Flows được đề xuất giải quyết các vấn đề lập trình cạnh tranh.

Cuộc thi sẽ tận dụng tập dữ liệu toàn diện các vấn đề Codeforces có sẵn công khai và cơ sở hạ tầng mã nguồn mở
cho suy luận và testing được sử dụng trong các thí nghiệm, có sẵn tại https://github.com/epfl-dlab/cc_flows.
21

--- TRANG 22 ---
Hướng dẫn Nộp bài và Định dạng cho ICML 2024

Cuộc thi sẽ chỉ bao gồm các vấn đề được công bố sau ngày cutoff kiến thức của GPT-4. Hơn nữa, để không quá tải
cơ sở hạ tầng đánh giá trực tuyến Codeforces, chúng tôi lọc thêm tập dữ liệu này thành các vấn đề mà tests công khai và
riêng tư có sẵn, và định dạng đầu ra tương thích với cơ sở hạ tầng test mã cục bộ của chúng tôi. Codeforces xếp hạng
độ khó của mỗi vấn đề từ 800 đến 2100. Tại thời điểm xuất bản, chúng tôi có số lượng vấn đề sau mỗi
độ khó (tổng cộng 416):
• độ khó 800: 149
• độ khó 900 đến 1500 (bao gồm): 185
• độ khó 1600 đến 2100 (bao gồm): 82

Chúng tôi sẽ tuyển chọn một bảng xếp hạng các Flows hoạt động tốt nhất sẽ có sẵn công khai trên FlowVerse và cung cấp các
dự đoán tái tạo điểm số được báo cáo sử dụng cơ sở hạ tầng được cung cấp.

Dữ liệu sẽ được phát hành và nên được sử dụng theo Điều khoản và Điều kiện của Codeforces. Cụ thể, Codeforces
cấm tài liệu được bán, cấp phép lại hoặc thương mại hóa. Để biết thêm chi tiết, hãy xem trang GitHub của dự án.
22

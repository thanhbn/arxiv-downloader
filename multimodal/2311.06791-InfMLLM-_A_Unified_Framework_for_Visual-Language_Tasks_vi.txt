# InfMLLM: Một Khung Thống Nhất cho Các Nhiệm Vụ Thị Giác-Ngôn Ngữ

Qiang Zhou†Zhibin Wang†Wei Chu Yinghui Xu Hao Li∗Yuan Qi∗
{zhouqiang, zhibin.waz, chuwei, xuyinghui, qiyuan }@inftech.ai
lihao hank@163.com

Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) đã chứng minh tính linh hoạt đáng chú ý của chúng trong việc xử lý một loạt toàn diện các ứng dụng tập trung vào ngôn ngữ. Để mở rộng khả năng của LLM sang một phổ rộng hơn các đầu vào đa phương thức, các mô hình ngôn ngữ lớn đa phương thức (MLLM) đã thu hút sự quan tâm ngày càng tăng. Công trình này tìm hiểu sâu về việc cho phép LLM giải quyết nhiều nhiệm vụ liên quan đến thị giác-ngôn ngữ hơn, đặc biệt là tạo chú thích hình ảnh, trả lời câu hỏi thị giác (VQA) và định vị thị giác. Để đạt được mục tiêu này, chúng tôi triển khai một lược đồ huấn luyện ba giai đoạn: bắt đầu với tiền huấn luyện căn chỉnh nhẹ, sau đó huấn luyện lai đa nhiệm vụ trọng số trung bình, và cuối cùng, tinh chỉnh LLM để cải thiện khả năng tuân theo hướng dẫn. Trong suốt quá trình huấn luyện, yêu cầu về bộ nhớ GPU tăng dần. Để quản lý hiệu quả số lượng nhúng thị giác được truyền tới LLM trong khi bảo toàn thông tin vị trí của chúng, chúng tôi giới thiệu một mô-đun bộ điều hợp thị giác đơn giản được gọi là pool-adapter. Các thí nghiệm của chúng tôi chứng minh rằng việc bảo toàn thông tin vị trí của các nhúng thị giác thông qua pool-adapter đặc biệt có lợi cho các nhiệm vụ như định vị thị giác. Chúng tôi đặt tên cho phương pháp được đề xuất là InfMLLM và đã đánh giá nó một cách toàn diện trên các tập dữ liệu chuẩn khác nhau. Kết quả của chúng tôi chứng minh rằng InfMLLM đạt được hiệu suất tiên tiến nhất (SOTA) hoặc hiệu suất tương đương với các MLLM gần đây. Mã nguồn và mô hình sẽ được công khai tại: https://github.com/infly-ai/INF-MLLM.

1. Giới thiệu

Khi sự quan tâm đến các mô hình ngôn ngữ lớn (LLM) tăng lên, thì việc cộng đồng nghiên cứu tập trung vào các mô hình ngôn ngữ lớn đa phương thức (MLLM) cũng tăng theo. MLLM là thiết yếu trong việc phát triển các trợ lý đa năng tổng quát, vì các tương tác hàng ngày liên quan đến thông tin của nhiều phương thức khác nhau, như giọng nói, văn bản, hình ảnh và video. Công trình này mở rộng LLM để xử lý nhiều nhiệm vụ liên quan đến thị giác-ngôn ngữ hơn, bao gồm tạo chú thích hình ảnh, VQA và định vị thị giác. Phát triển một MLLM từ đầu là một nhiệm vụ đầy thách thức. Nó đòi hỏi tài nguyên huấn luyện đáng kể và dữ liệu huấn luyện chất lượng cao với số lượng lớn. Các MLLM gần đây [2, 5, 10, 23, 26] thay vào đó sử dụng các chiến lược tinh chỉnh, tận dụng các LLM được tiền huấn luyện và tinh chỉnh chúng bằng dữ liệu đa phương thức.

Việc tinh chỉnh hiệu quả LLM để mở rộng khả năng của chúng sang đa phương thức vẫn là một thách thức nghiên cứu đang diễn ra. Công trình này thực hiện một chiến lược huấn luyện tiến bộ để cải thiện hiệu quả huấn luyện. Trong giai đoạn ban đầu, chúng tôi sử dụng một tập hợp mở rộng dữ liệu cặp hình ảnh-văn bản chất lượng thấp hơn để huấn luyện một bộ điều hợp thị giác được khởi tạo ngẫu nhiên. Bộ điều hợp này căn chỉnh các đặc trưng hình ảnh được trích xuất từ bộ mã hóa hình ảnh được tiền huấn luyện với các nhúng văn bản, cho phép LLM được tiền huấn luyện xử lý chúng một cách hiệu quả. Trong giai đoạn thứ hai, chúng tôi sử dụng các tập dữ liệu chất lượng cao có sẵn công khai trải rộng trên các nhiệm vụ thị giác-ngôn ngữ khác nhau và tinh chỉnh mô hình để mở rộng khả năng xử lý các nhiệm vụ khác nhau. Để giảm thiểu chi phí huấn luyện trong giai đoạn này, chúng tôi đóng băng các tham số của LLM ngoại trừ trọng số phép chiếu QV. Để cải thiện thêm khả năng tuân theo hướng dẫn một cách hiệu quả của mô hình, chúng tôi tinh chỉnh toàn bộ LLM sử dụng một lượng hạn chế dữ liệu hướng dẫn trong giai đoạn cuối.

Các bộ điều hợp thị giác thường được sử dụng để biến đổi các đặc trưng thị giác thành các nhúng thị giác được căn chỉnh, sau đó có thể được xử lý bởi một LLM được tiền huấn luyện. Chúng cũng giúp giảm số lượng nhúng thị giác, điều này đặc biệt quan trọng đối với các hình ảnh lớn. Hai bộ điều hợp thị giác nổi tiếng là Q-Former [23] và Perceiver [1], sử dụng các mô-đun chú ý chéo để nén một tập lớn các đặc trưng thị giác thành một số lượng nhỏ nhúng thị giác. Trong khi các bộ điều hợp này tốt cho các nhiệm vụ đa phương thức như tạo chú thích hình ảnh và Trả lời Câu hỏi Thị giác (VQA), chúng gặp khó khăn với các nhiệm vụ liên quan đến mối quan hệ không gian, như định vị thị giác. Trong công trình này, chúng tôi đề xuất một bộ điều hợp thị giác mới được gọi là pool-adapter. Nó tổng hợp các đặc trưng hình ảnh thành một số lượng cố định các đặc trưng thị giác và sau đó chuyển đổi chúng thành các nhúng thị giác bằng cách sử dụng MLP hai lớp. Pool-adapter đơn giản, có thể được sử dụng với các kích thước hình ảnh khác nhau, và giữ lại hiệu quả thông tin vị trí của các nhúng thị giác. Điều này làm cho nó đặc biệt hiệu quả cho các nhiệm vụ như định vị thị giác.

Tóm lại, các đóng góp chính của chúng tôi là:
• Chúng tôi trình bày một khung MLLM mới có tên InfMLLM huấn luyện trong ba giai đoạn, mỗi giai đoạn có một trọng tâm riêng: tiền huấn luyện căn chỉnh pool-adapter, tinh chỉnh đa nhiệm vụ, và điều chỉnh hướng dẫn.
• Chúng tôi giới thiệu một pool-adapter đơn giản để căn chỉnh các đặc trưng hình ảnh ViT với LLM, bảo toàn thông tin vị trí trong khi giảm số lượng nhúng hình ảnh.
• Chúng tôi đánh giá toàn diện InfMLLM trên các điểm chuẩn khác nhau, đạt được hiệu suất tiên tiến nhất (SOTA) hoặc hiệu suất tương đương với các MLLM gần đây.

2. Công trình liên quan

Trong phần này, chúng tôi khảo sát nghiên cứu liên quan về các mô hình ngôn ngữ lớn (LLM) và các mô hình ngôn ngữ lớn đa phương thức (MLLM).

Các Mô hình Ngôn ngữ Lớn (LMM). Bối cảnh của LLM đã phát triển đáng kể, với một số đóng góp đáng chú ý định hình lĩnh vực này. Các mô hình sớm, như GPT-2 [37] và BERT [11], đã đặt nền móng bằng cách chứng minh tiềm năng của việc huấn luyện trên các tập dữ liệu văn bản quy mô web rộng lớn. Những mô hình này đánh dấu một bước đột phá trong Xử lý Ngôn ngữ Tự nhiên (NLP) và tạo tiền đề cho những tiến bộ tiếp theo. Một tiến bộ nổi bật là GPT-3 [3], một mô hình có quy mô và độ phức tạp chưa từng có. GPT-3 đã thể hiện khả năng của các mạng neuron khổng lồ, tự hào với 175 tỷ tham số và vượt trội trong các nhiệm vụ ngôn ngữ đa dạng. Việc phát hành của nó đã thúc đẩy sự quan tâm trong việc khám phá giới hạn kích thước mô hình và đã mở ra những con đường mới để hiểu các ứng dụng tiềm năng và thách thức liên quan đến những mô hình ngôn ngữ khổng lồ như vậy. Megatron-turing NLG [44], PaLM [9], Gopher [39], Chinchilla [15], OPT [52], và BLOOM [40] đại diện cho các mô hình tiếp theo đã tiếp tục đẩy ranh giới của LLM. Những mô hình này khác nhau về kiến trúc, phương pháp huấn luyện và ứng dụng, góp phần vào một mạng lưới phong phú của nghiên cứu trong lĩnh vực các mô hình ngôn ngữ lớn. Sự đa dạng của các phương pháp phản ánh những nỗ lực đang diễn ra để tối ưu hóa hiệu suất, hiệu quả và khả năng tổng quát hóa trên các nhiệm vụ ngôn ngữ khác nhau. Các nỗ lực gần đây trong lĩnh vực này đã tập trung vào việc tinh chỉnh LLM để căn chỉnh tốt hơn với hướng dẫn và phản hồi của con người. InstructGPT [35], ChatGPT [33] và GPT4 [34] nổi bật như những mẫu hình trong vấn đề này. Những mô hình này có thể tham gia vào các cuộc hội thoại năng động và giàu ngữ cảnh, phản hồi khéo léo với các lời nhắc của người dùng, và thậm chí chứng minh sự thành thạo trong các nhiệm vụ phức tạp như tạo mã. Việc nhấn mạnh vào việc căn chỉnh LLM với tương tác và hướng dẫn của con người đại diện cho một bước quan trọng hướng tới việc triển khai thực tế và tích hợp chúng vào các ứng dụng thực tế.

Trong công trình này, chúng tôi nghiên cứu một mô hình được huấn luyện từ đầu đến cuối, với một LLM làm cốt lõi, nhằm nâng cao khả năng của nó trong các nhiệm vụ thị giác-ngôn ngữ.

Các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM). Sử dụng khả năng tổng quát hóa ấn tượng được nhúng trong LMM, các nhà nghiên cứu đã tiến hành các điều tra toàn diện để mở rộng chức năng của chúng vào các lĩnh vực đa phương thức. Như được minh họa bởi VisualGPT [4] và Frozen [46], các nỗ lực ban đầu huấn luyện các bộ mã hóa thị giác để đại diện cho mỗi hình ảnh thông qua các nhúng liên tục. Những nhúng hình ảnh này sau đó được đưa vào các mô hình ngôn ngữ được tiền huấn luyện, nâng cao khả năng ngôn ngữ thị giác và tập trung vào các nhiệm vụ như tạo chú thích hình ảnh và trả lời câu hỏi thị giác. Cuộc khám phá tinh túy này đã đặt nền móng cho những tiến bộ tiếp theo trong nghiên cứu ngôn ngữ thị giác, như được minh họa bởi các nghiên cứu đáng chú ý như Flamingo [1], BLIP-2 [23] và Kosmos-1 [17]. Các nghiên cứu gần đây, như VisionLLM [48], Kosmos-2 [36], RegionBLIP [53], Shikra [6], Qwen-VL [2], và miniGPT-v2 [5], đang tích cực mở rộng phổ các nhiệm vụ thị giác-ngôn ngữ mà MLLM có thể giải quyết một cách thành thạo. Những điều tra này nhấn mạnh rằng MLLM vượt trội trong các nhiệm vụ truyền thống như tạo chú thích hình ảnh và VQA, và thể hiện khả năng định vị thị giác mạnh mẽ. Cụ thể, những mô hình này tạo ra các đại diện văn bản của hộp giới hạn thông qua các mô hình ngôn ngữ. Ngoài việc đa dạng hóa các nhiệm vụ trong phạm vi của MLLM, có một khối lượng nghiên cứu đáng kể đang diễn ra trong lĩnh vực điều chỉnh hướng dẫn đa phương thức. Các nghiên cứu đáng chú ý trong lĩnh vực này bao gồm LLaVA [28], InstructBLIP [10], Otter [21], LLaVA-1.5 [26], và những nghiên cứu khác.

Thiết kế của kiến trúc mô hình và pipeline huấn luyện của MLLM vẫn là một vấn đề mở. Trong công trình này, chúng tôi đề xuất một mô hình hiệu quả có tên InfMLLM, hoạt động đáng kể trên các nhiệm vụ thị giác-ngôn ngữ khác nhau.

3. Phương pháp

Phần này trình bày giải thích toàn diện về kiến trúc 3.1 và pipeline huấn luyện 3.2 của InfMLLM.

3.1. Kiến trúc Mô hình

Như được mô tả trong Hình 2, InfMLLM chủ yếu bao gồm ba thành phần: bộ mã hóa hình ảnh, pool-adapter, và mô hình ngôn ngữ lớn (LLM).

Bộ mã hóa hình ảnh. Bộ mã hóa hình ảnh chịu trách nhiệm chuyển đổi đầu vào hình ảnh thô thành các đặc trưng hình ảnh nhỏ gọn và có tính thông tin. Kiến trúc hợp lý của mô hình Vision Transformer [12] (ViT) làm cho nó đặc biệt thành thạo trong việc xử lý các loại dữ liệu đa phương thức đa dạng, như hình ảnh và video. Công trình tiên phong như CLIP [38] đã làm cho các mô hình ViT trở nên phổ biến hơn bằng cách cung cấp các mô hình được tiền huấn luyện để khớp hình ảnh-văn bản. Kết quả là, ViT đã trở thành bộ mã hóa hình ảnh được lựa chọn trên thực tế trong nhiều MLLM [2, 5, 26, 27]. Trong công trình này, chúng tôi sử dụng ViT-g/14 từ EVA-CLIP [45]. Theo thực hành trong BLIP-2 [23], chúng tôi loại bỏ lớp cuối cùng của ViT và sử dụng các đặc trưng đầu ra của lớp thứ hai từ cuối. Hơn nữa, chúng tôi loại bỏ các đặc trưng đầu ra liên quan đến token lớp và chỉ giữ lại các đặc trưng patch.

Pool-adapter. LLM thường được tiền huấn luyện bằng cách sử dụng các tập văn bản thuần túy và thiếu khả năng vốn có để xử lý các đặc trưng hình ảnh thu được từ các mô hình ViT. Để thu hẹp khoảng cách giữa các đặc trưng hình ảnh và nhúng văn bản, mô-đun Q-Former đã được giới thiệu trong BLIP-2 [23]. Nó phục vụ như một trung gian quan trọng, tạo thuận lợi cho kết nối giữa ViT và LLM trong lĩnh vực hiểu biết thị giác. Tuy nhiên, các thí nghiệm ban đầu của chúng tôi đã phát hiện ra những thiếu sót trong hiệu suất của Q-Former trong các nhiệm vụ liên quan đến định vị thị giác. Sự khác biệt này có thể được quy cho xu hướng của các đặc trưng được truy vấn của Q-Former mất thông tin vị trí vốn có trong các đặc trưng hình ảnh, một yếu tố quan trọng cho các nhiệm vụ như định vị thị giác. Để tối đa hóa việc giữ lại thông tin vị trí trong các đặc trưng hình ảnh, chúng tôi đề xuất pool-adapter nhẹ. Pool-adapter hoạt động bằng cách ban đầu tổng hợp các đặc trưng hình ảnh, giảm chúng xuống một số lượng cố định. Tiếp theo, một Mạng Thần kinh Đa lớp (MLP) hai lớp được sử dụng để căn chỉnh hiệu quả những đặc trưng được tổng hợp này với nhúng văn bản, nâng cao khả năng của mô hình cho các nhiệm vụ đa phương thức. Kết quả khảo sát của chúng tôi trong Bảng 5 và Bảng 6 cho thấy số lượng nhúng thị giác được tạo ra bởi pool-adapter ảnh hưởng đáng kể đến hiệu suất của mô hình trên các nhiệm vụ thị giác-ngôn ngữ. Các phương pháp duy trì số lượng nhúng thị giác giảm trong khi nâng cao hiệu suất mô hình cần được điều tra thêm, vì việc giảm nhúng thị giác có thể cải thiện đáng kể tốc độ suy luận của mô hình.

LLM. LLM đóng vai trò trung tâm trong các mô hình ngôn ngữ lớn đa phương thức. Chúng nhận hướng dẫn cũng như các đặc trưng hình ảnh được căn chỉnh làm đầu vào và sau đó tạo ra các câu trả lời tương ứng. Trong công trình này, chúng tôi sử dụng Vicuna-7B [8] mã nguồn mở, một mô hình ngôn ngữ lớn mạnh mẽ. Vicuna ban đầu được tinh chỉnh bằng cách sử dụng các tập văn bản thuần túy, và việc tinh chỉnh thêm nó với dữ liệu đa phương thức sẽ có lợi cho hiệu suất của MLLM trên các nhiệm vụ đa phương thức. Ví dụ, Qwen-VL [2] tinh chỉnh toàn bộ LLM trong giai đoạn tiền huấn luyện đa nhiệm vụ, và đạt được hiệu suất tuyệt vời trên các nhiệm vụ như tạo chú thích, trả lời câu hỏi thị giác (VQA), VQA định hướng văn bản, và định vị thị giác. Khi LLM trở nên lớn hơn, phương pháp tinh chỉnh đầy đủ trở nên ít khả thi hơn. Tinh chỉnh LoRA [16] là một phương pháp hiệu quả hơn và được áp dụng trong miniGPT-v2 [5]. Trong các thí nghiệm ban đầu của chúng tôi, mô hình được tinh chỉnh LoRA hoạt động ở vị trí bất lợi trong các nhiệm vụ thị giác-ngôn ngữ so với mô hình được tinh chỉnh đầy đủ. Để đạt được sự cân bằng tối ưu giữa hiệu suất và hiệu quả huấn luyện, chúng tôi chọn tinh chỉnh các trọng số phép chiếu QV hoàn chỉnh trong LLM trong khi duy trì các tham số còn lại bị đóng băng, như được minh họa trong giai đoạn tinh chỉnh đa nhiệm vụ trong Hình 2. Lưu ý rằng trong giai đoạn điều chỉnh hướng dẫn cuối cùng, chúng tôi đóng băng mô hình ViT và tinh chỉnh toàn bộ mô hình LLM.

3.2. Dữ liệu, Lời nhắc và Huấn luyện

Trong phần này, chúng tôi cung cấp các tập dữ liệu, lời nhắc, và chi tiết huấn luyện cho từng giai đoạn của InfMLLM.

Giai đoạn 1 Tiền huấn luyện. Trong giai đoạn này, chúng tôi sử dụng các cặp hình ảnh-văn bản được gắn nhãn yếu để tiến hành tiền huấn luyện mô-đun pool-adapter. Pool-adapter được tiền huấn luyện sẽ căn chỉnh các đặc trưng hình ảnh được rút ra từ ViT với nhúng văn bản, cho phép nhận dạng bởi các LLM được tiền huấn luyện. Trong suốt giai đoạn này, tất cả các tham số đều bị đóng băng, ngoại trừ những tham số của pool-adapter. Dữ liệu được sử dụng để tiền huấn luyện bao gồm các tập dữ liệu có sẵn công khai, bao gồm CC3M, CC12M, và LAION-115M [22]. Trong giai đoạn này, chúng tôi sử dụng một lời nhắc đơn giản, nơi LLM được nhắc tạo ra một chú thích ngắn gọn dựa trên các đặc trưng hình ảnh được căn chỉnh, như được minh họa trong Bảng 1.

Giai đoạn 2 Tinh chỉnh đa nhiệm vụ. Bằng cách căn chỉnh các đặc trưng hình ảnh với nhúng văn bản tương thích với xử lý LLM, các nhiệm vụ ngôn ngữ thị giác khác nhau như tạo chú thích hình ảnh, trả lời câu hỏi thị giác (VQA), và định vị biểu thức tham chiếu có thể được tích hợp vào một mô hình MLLM thống nhất. Trong công trình này, chúng tôi thu thập các tập dữ liệu có sẵn công khai, bao gồm các tập dữ liệu tạo chú thích hình ảnh (COCO [25], TextCaps [42]), tập dữ liệu VQA (VQAv2 [14], OK-VQA [31], AOK-VQA [41], GQA [18], OCR-VQA [32], TextVQA [42]), và tập dữ liệu định vị biểu thức tham chiếu (RefCOCO [19], RefCOCO+, RefCOCOg), và sau đó tinh chỉnh một mô hình MLLM tổng quát. Trong giai đoạn này, chúng tôi tiến hành tinh chỉnh trên mô hình ViT, pool-adapter, và trọng số phép chiếu QV trong LLM. Chúng tôi sử dụng lấy mẫu đồng nhất dữ liệu huấn luyện từ ba nhiệm vụ: tạo chú thích hình ảnh, trả lời câu hỏi thị giác, và định vị thị giác. Các lời nhắc được sử dụng cho dữ liệu liên quan đến ba nhiệm vụ này thể hiện những biến thể nhỏ, như được nêu trong Bảng 1. Cụ thể, chúng tôi sử dụng lời nhắc giống hệt nhau cho VQA và VQA định hướng văn bản, mà không tạo ra bất kỳ sự phân biệt nào. Đối với các nhiệm vụ định vị thị giác, chúng tôi sử dụng LLM để tạo ra trực tiếp các tọa độ chuẩn hóa của góc trên trái và góc dưới phải của hộp giới hạn.

Giai đoạn 3 Điều chỉnh Hướng dẫn. Điều chỉnh hướng dẫn [49] thường là một bước quan trọng trong việc cải thiện hiệu suất zero-shot của LMM và khả năng tuân theo hướng dẫn, và hiệu quả của nó đã được thiết lập tốt. Để cải thiện khả năng tuân theo hướng dẫn của InfMLLM, chúng tôi tinh chỉnh thêm mô hình với dữ liệu hướng dẫn. Các nỗ lực gần đây [7, 10, 26, 27], dù được thực hiện thủ công hay tận dụng GPT-4, đều liên quan đến việc chuyển đổi các tập dữ liệu công khai thành các tập dữ liệu điều chỉnh hướng dẫn có thể sử dụng được. Trong công trình này, chúng tôi sử dụng dữ liệu hướng dẫn được cung cấp bởi LLaVA-1.5 [26]. Trong giai đoạn điều chỉnh hướng dẫn, tất cả các tham số, ngoại trừ những tham số của ViT, trải qua quá trình tinh chỉnh.

4. Thí nghiệm

Trong phần này, chúng tôi đi sâu vào chi tiết về huấn luyện mô hình và thực hiện đánh giá định lượng toàn diện về mô hình trên các điểm chuẩn công khai. Ngoài ra, chúng tôi cung cấp một minh chứng định tính với các ví dụ trực quan để hiểu rõ hơn về khả năng của mô hình.

Siêu tham số huấn luyện. Các siêu tham số huấn luyện được nêu trong Bảng 7. Cụ thể, tất cả các mô hình giai đoạn trải qua huấn luyện bằng cách sử dụng trình tối ưu AdamW và một bộ lập lịch tốc độ học cosine decay. Đối với tiền huấn luyện giai đoạn 1 ban đầu, mô hình được huấn luyện bằng cách sử dụng 32 × A800 GPU với kích thước lô toàn cục là 1024 và tốc độ học tối đa là 2e-4. Độ phân giải hình ảnh được đặt thành 224 trong giai đoạn này. Trong giai đoạn 2 tinh chỉnh đa nhiệm vụ tiếp theo, mô hình được huấn luyện với 32 × A800 GPU, sử dụng kích thước lô toàn cục là 512 và tốc độ học tối đa là 2e-5. Độ phân giải hình ảnh được tăng lên 448 cho giai đoạn này. Cuối cùng, trong giai đoạn điều chỉnh hướng dẫn, mô hình được huấn luyện bằng cách sử dụng 32 × A800 GPU trong 1 epoch, với kích thước lô toàn cục là 128 và tốc độ học tối đa là 2e-5. Độ phân giải hình ảnh vẫn ở 448 cho giai đoạn này.

4.1. Trực quan hóa

Để cung cấp minh họa trực quan hơn về các nhiệm vụ thị giác-ngôn ngữ được hoàn thành bởi InfMLLM, chúng tôi đã tuyển chọn các ví dụ trực quan được trình bày trong Hình 3. Các ví dụ tiết lộ khả năng của InfMLLM để tích hợp liền mạch các nhiệm vụ như tạo chú thích hình ảnh, VQA, VQA liên quan đến OCR, và định vị thị giác vào một mô hình thống nhất. Nói một cách, InfMLLM mở rộng hiệu quả các ranh giới nhiệm vụ của LMM. Ngoài ra, chúng tôi cung cấp lựa chọn các cuộc hội thoại nhiều vòng trong Hình 4 sử dụng mô hình InfMLLM-7B-Chat để thể hiện sự thành thạo của nó trong việc tuân theo hướng dẫn.

4.2. Đánh giá Điểm chuẩn

Sau tinh chỉnh đa nhiệm vụ, InfMLLM trở thành một mô hình linh hoạt có khả năng giải quyết các nhiệm vụ thị giác và ngôn ngữ khác nhau, như Trả lời Câu hỏi Thị giác (VQA), VQA định hướng văn bản, và định vị thị giác. Để đánh giá toàn diện các khả năng của InfMLLM, chúng tôi tiến hành đánh giá trên tất cả các nhiệm vụ này. Các thông tin cụ thể về tập dữ liệu, phân chia, và các chỉ số đánh giá có thể được tìm thấy trong Bảng 8. Kết quả được trình bày trong Bảng 3 làm nổi bật hiệu suất mạnh mẽ của InfMLLM, đạt được kết quả tiên tiến nhất trên gần như tất cả các nhiệm vụ định vị thị giác và VQA.

Để đánh giá khả năng tuân theo hướng dẫn của InfMLLM-Chat sau tinh chỉnh giai đoạn 3, chúng tôi đánh giá InfMLLM-Chat trên các điểm chuẩn khác nhau. Như được minh họa trong Bảng 4, InfMLLM-Chat thể hiện hiệu suất vượt trội so với các MLLM khác sử dụng các mô hình ngôn ngữ có kích thước tương tự.

4.3. Nghiên cứu khảo sát

Trong phần này, chúng tôi tiến hành các nghiên cứu khảo sát trên các mô hình InfMLLM-7B và InfMLLM-7B-Chat.

Ảnh hưởng của số lượng nhúng thị giác. LLM có khả năng trích xuất những hiểu biết có giá trị từ các chuỗi văn bản đa dạng và phức tạp. Tương tự, MLLM được kỳ vọng có thể thu thập thông tin thích hợp từ các nhúng thị giác để trả lời hiệu quả các câu hỏi khác nhau. Tuy nhiên, số lượng nhúng thị giác tối ưu cần thiết cho MLLM vẫn không chắc chắn. Trong phần này, chúng tôi khám phá cách số lượng nhúng thị giác ảnh hưởng đến hiệu suất của InfMLLM-7B và InfMLLM-7B-Chat. Cụ thể, chúng tôi điều chỉnh giá trị của tham số p trong pool-adapter, điều chỉnh số lượng nhúng hình ảnh (tương đương với p²) được đưa vào LLM. Như được chứng minh trong Bảng 5, có một xu hướng rõ ràng được quan sát: hiệu suất của InfMLLM-7B trong các nhiệm vụ thị giác-ngôn ngữ cải thiện với sự tăng lên của số lượng nhúng thị giác. Trên tám điểm chuẩn, đặt p thành 8 cho hiệu suất trung bình là 75.23. Tăng p lên 32 dẫn đến tăng hiệu suất trung bình lên 77.67. Hơn nữa, kết nối các nhúng hình ảnh từ ba thiết lập—8, 16, và 32—tăng thêm hiệu suất trung bình lên 78.09. Kết luận tương tự được đạt được trong mô hình chat của InfMLLM-7B-Chat, như được thể hiện trong Bảng 6.

Điều chỉnh số lượng nhúng thị giác trực tuyến. Trong khi tăng nhúng thị giác cải thiện hiệu suất, nó đi kèm với việc làm chậm suy luận. Thường có yêu cầu về kết quả nhanh chóng, ban đầu với ít nhúng thị giác hơn. Quá trình huấn luyện nhiều mô hình cho các giá trị p khác nhau có thể khá nặng nề. Tuy nhiên, các thí nghiệm của chúng tôi trong Bảng 9 chứng minh rằng khi một mô hình được huấn luyện với p = 32 + 16 + 8, việc sử dụng p = 32 hoặc p = 16 trong giai đoạn suy luận một cách bất ngờ duy trì hiệu suất mạnh mẽ mà không có sự suy giảm đáng kể.

5. Hạn chế

Trong các thí nghiệm của chúng tôi, chúng tôi quan sát thấy rằng trong giai đoạn tinh chỉnh đa nhiệm vụ, tồn tại một mức độ xung đột tối ưu hóa trong các nhiệm vụ riêng lẻ. Hiệu suất được ảnh hưởng đáng kể bởi lựa chọn trọng số mất mát hoặc tỷ lệ phân phối dữ liệu cho các nhiệm vụ khác nhau, đòi hỏi tinh chỉnh tỉ mỉ. Nghiên cứu tương lai sẽ tìm hiểu sâu về việc khám phá các giải pháp hiệu quả hơn cho tinh chỉnh đa nhiệm vụ.

6. Kết luận

Trong công trình này, chúng tôi giới thiệu một khung Mô hình Ngôn ngữ Lớn Đa phương thức mới có tên InfMLLM. Sử dụng một pool-adapter đơn giản, InfMLLM điều chỉnh động số lượng nhúng hình ảnh trong khi giữ lại thông tin vị trí quan trọng. Trái ngược với các MLLM khác, InfMLLM đạt được hiệu suất tiên tiến nhất trong định vị thị giác và trả lời câu hỏi thị giác, đồng thời cũng mang lại kết quả cạnh tranh trong tạo chú thích hình ảnh và các nhiệm vụ VQA định hướng văn bản. Chúng tôi sẽ phát hành mã nguồn và mô hình liên quan dưới dạng mã nguồn mở. Chúng tôi dự đoán rằng InfMLLM sẽ góp phần vào sự tiến bộ của nghiên cứu liên quan đến MLLM.

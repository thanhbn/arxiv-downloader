# 2310.15111.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2310.15111.pdf
# Kích thước tệp: 35121436 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
Mô hình Khuếch tán Matryoshka
Jiatao Gu, Shuangfei Zhai, Yizhe Zhang, Josh Susskind & Navdeep Jaitly
Apple
{jgu32,szhai,yizzhang,jsusskind,njaitly }@apple.com
Hình 1: ( ←↑) Hình ảnh được tạo bởi MDM tại độ phân giải 642,1282,2562,5122và10242 sử dụng
lời nhắc "một con nai búp bê Matryoshka mặc kimono Nhật Bản, chi tiết siêu đẹp, cực kỳ chân thực, 8k" ; (←↓)
1và16 khung hình video 642 được tạo bởi phương pháp của chúng tôi sử dụng lời nhắc "đổ sữa vào
cà phê đen" ; Tất cả các mẫu khác ở độ phân giải 10242 được đưa ra các lời nhắc khác nhau. Hình ảnh đã được thay đổi kích thước để dễ trực quan hóa.

Tóm tắt
Các mô hình khuếch tán là phương pháp tiêu chuẩn để tạo ra hình ảnh và video chất lượng cao
nhưng việc học các mô hình đa chiều cao vẫn là một nhiệm vụ khó khăn do các thách thức về tính toán và tối ưu hóa. Các phương pháp hiện có thường phải sử dụng việc huấn luyện các mô hình phân tầng trong không gian pixel, hoặc sử dụng không gian ẩn được lấy mẫu giảm của một bộ mã hóa tự động được huấn luyện riêng. Trong bài báo này, chúng tôi giới thiệu Matryoshka Diffusion (MDM), một khung làm việc mới để tổng hợp hình ảnh và video độ phân giải cao. Chúng tôi đề xuất một quá trình khuếch tán khử nhiễu đầu vào tại nhiều độ phân giải cùng lúc và sử dụng kiến trúc NestedUNet trong đó các đặc trưng và tham số cho các đầu vào quy mô nhỏ được lồng trong các đầu vào quy mô lớn. Ngoài ra, MDM cho phép lịch trình huấn luyện tiến bộ từ độ phân giải thấp đến cao dẫn đến cải thiện đáng kể trong việc tối ưu hóa cho việc tạo độ phân giải cao. Chúng tôi chứng minh hiệu quả của phương pháp trên nhiều bộ đánh giá khác nhau, bao gồm tạo hình ảnh có điều kiện lớp, văn bản-tới-hình ảnh độ phân giải cao, và các ứng dụng văn bản-tới-video. Đáng chú ý, chúng tôi có thể huấn luyện một mô hình không gian pixel duy nhất ở độ phân giải lên tới 1024×1024 pixel, chứng minh khả năng tổng quát hóa zero shot mạnh mẽ sử dụng bộ dữ liệu CC12M, chỉ chứa 12 triệu hình ảnh. Mã nguồn và các checkpoint đã được huấn luyện được phát hành tại https://github.com/apple/ml-mdm .

--- TRANG 2 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
1 Giới thiệu
Các mô hình khuếch tán (Sohl-Dickstein et al., 2015; Ho et al., 2020; Nichol & Dhariwal, 2021; Song et al.,
2020) đã trở thành các công cụ ngày càng phổ biến cho các ứng dụng tạo sinh, chẳng hạn như hình ảnh (Dhariwal
& Nichol, 2021; Rombach et al., 2022; Ramesh et al., 2022; Saharia et al., 2022), video (Ho et al.,
2022c;a), 3D (Poole et al., 2022; Gu et al., 2023; Liu et al., 2023b; Chen et al., 2023), âm thanh (Liu
et al., 2023a), và tạo văn bản (Li et al., 2022; Zhang et al., 2023). Tuy nhiên việc mở rộng chúng lên độ phân giải cao vẫn đặt ra những thách thức đáng kể vì mô hình phải mã hóa lại toàn bộ đầu vào độ phân giải cao cho từng bước (Kadkhodaie et al., 2022). Giải quyết những thách thức này đòi hỏi việc sử dụng các kiến trúc sâu với các khối attention làm cho việc tối ưu hóa khó khăn hơn và sử dụng nhiều tài nguyên hơn.

Các công trình gần đây (Jabri et al., 2022; Hoogeboom et al., 2023) đã tập trung vào các kiến trúc mạng hiệu quả cho hình ảnh độ phân giải cao. Tuy nhiên, không có phương pháp nào trong số các phương pháp hiện có đã cho thấy kết quả cạnh tranh vượt quá 512×512, và chất lượng của chúng vẫn thua kém các phương pháp phân tầng/dựa trên ẩn chính thống. Ví dụ, DALL-E 2 (Ramesh et al., 2022), IMAGEN (Saharia et al., 2022) và eDiff-I (Balaji et al., 2022) tiết kiệm tính toán bằng cách học một mô hình độ phân giải thấp cùng với nhiều mô hình khuếch tán siêu phân giải, trong đó mỗi thành phần được huấn luyện riêng biệt. Mặt khác, các phương pháp khuếch tán ẩn (LDMs) (Rombach et al., 2022; Peebles & Xie, 2022; Xue et al., 2023) chỉ học các mô hình khuếch tán độ phân giải thấp, trong khi chúng dựa vào một bộ mã hóa tự động độ phân giải cao được huấn luyện riêng (Oord et al., 2017; Esser et al., 2021). Trong cả hai trường hợp, đường ống đa giai đoạn làm phức tạp việc huấn luyện & suy luận, thường đòi hỏi việc điều chỉnh cẩn thận các siêu tham số.

Trong bài báo này, chúng tôi trình bày Matryoshka Diffusion Models (MDM), một họ mô hình khuếch tán mới cho tổng hợp độ phân giải cao. Hiểu biết chính của chúng tôi là bao gồm quá trình khuếch tán độ phân giải thấp như một phần của việc tạo độ phân giải cao, lấy cảm hứng tương tự từ học đa quy mô trong GANs (Karras et al., 2017; Chan et al., 2021; Kang et al., 2023). Chúng tôi thực hiện điều này bằng cách thực hiện một quá trình khuếch tán kết hợp trên nhiều độ phân giải sử dụng kiến trúc Nested UNet ( (xem Hình 2 và Hình 3). Phát hiện chính của chúng tôi là MDM, cùng với kiến trúc Nested UNets, cho phép 1) một mất mát đa độ phân giải cải thiện đáng kể tốc độ hội tụ của việc khử nhiễu đầu vào độ phân giải cao và 2) một lịch trình huấn luyện tiến bộ hiệu quả, bắt đầu bằng việc huấn luyện một mô hình khuếch tán độ phân giải thấp và dần dần thêm các đầu vào và đầu ra độ phân giải cao theo một lịch trình. Theo kinh nghiệm, chúng tôi phát hiện ra rằng mất mát đa độ phân giải cùng với huấn luyện tiến bộ cho phép tìm ra một sự cân bằng tuyệt vời giữa chi phí huấn luyện và chất lượng của mô hình.

Chúng tôi đánh giá MDM trên tạo hình ảnh có điều kiện lớp, và tạo hình ảnh và video có điều kiện văn bản. MDM cho phép chúng tôi huấn luyện các mô hình độ phân giải cao mà không cần dùng đến khuếch tán phân tầng hoặc ẩn. Các nghiên cứu tách biệt cho thấy cả mất mát đa độ phân giải và huấn luyện tiến bộ đều tăng cường đáng kể hiệu quả huấn luyện và chất lượng. Ngoài ra, MDM mang lại các mô hình tạo sinh văn bản-tới-hình ảnh hiệu suất cao với độ phân giải lên tới 10242, được huấn luyện trên bộ dữ liệu CC12M tương đối nhỏ. Cuối cùng, MDM tổng quát hóa một cách duyên dáng sang tạo video, gợi ý tính tổng quát của phương pháp của chúng tôi.

2 Mô hình Khuếch tán
Các mô hình khuếch tán (Sohl-Dickstein et al., 2015; Ho et al., 2020) là các mô hình biến ẩn được đưa ra một phân phối hậu nghiệm được xác định trước (được gọi là quá trình khuếch tán tiến), và được huấn luyện với một mục tiêu khử nhiễu. Cụ thể hơn, cho một điểm dữ liệu x∈RN và một lịch trình tín hiệu-nhiễu cố định {αt, σt}t=1,...,T, chúng ta định nghĩa một chuỗi các biến ẩn {zt}t=0,...,T thỏa mãn:
q(zt|x) =N(zt;αtx, σ2tI),vàq(zt|zs) =N(zt;αt|szs, σ2t|sI), (1)
trong đó z0=x,αt|s=αt/αs, σ2t|s=σ2t−α2t|sσ2s,s < t . Theo mặc định, tỷ lệ tín hiệu-nhiễu (SNR, α2t/σ2t) giảm đơn điệu theo t. Mô hình sau đó học đảo ngược quá trình với một mô hình ngược pθ(zt−1|zt), có thể được viết lại như một mục tiêu khử nhiễu:
Lθ=Et∼[1,T],zt∼q(zt|x) ωt· ∥xθ(zt, t)−x∥22
,
trong đó xθ(zt, t) là một mạng nơ-ron (thường là một biến thể của mô hình UNet (Ronneberger et al., 2015)) ánh xạ một đầu vào có nhiễu zt đến phiên bản sạch x của nó, có điều kiện trên bước thời gian t; ωt∈R+ là một hệ số trọng số mất mát được xác định bởi heuristics. Trên thực tế, người ta có thể tái tham số hóa xθ với dự đoán nhiễu hoặc v (Salimans & Ho, 2022) để cải thiện hiệu suất. Khác với các mô hình tạo sinh khác như GANs (Goodfellow et al., 2014), các mô hình khuếch tán đòi hỏi việc áp dụng lặp lại một mạng nơ-ron sâu xθ trong không gian xung quanh vì tính toán đủ với tương tác toàn cục là quan trọng cho việc khử nhiễu (Kadkhodaie et al., 2022). Điều này làm cho việc thiết kế các mô hình khuếch tán hiệu quả trực tiếp cho việc tạo độ phân giải cao trở nên thách thức, đặc biệt là đối với các nhiệm vụ phức tạp như tổng hợp văn bản-tới-hình ảnh. Như các giải pháp thông thường, các phương pháp hiện có đã tập trung vào việc học tạo sinh phân cấp:

Khuếch tán phân tầng (Ho et al., 2022b; Ramesh et al., 2022; Saharia et al., 2022; Ho et al., 2022a; Pernias et al., 2023) sử dụng một phương pháp phân tầng trong đó một mô hình khuếch tán đầu tiên được sử dụng để tạo dữ liệu ở độ phân giải thấp hơn, và sau đó một mô hình khuếch tán thứ hai được sử dụng để tạo ra phiên bản siêu phân giải của việc tạo ban đầu, lấy việc tạo giai đoạn đầu tiên làm điều kiện. Các mô hình phân tầng có thể được nối chuỗi nhiều lần cho đến khi chúng đạt đến độ phân giải cuối cùng. Ho et al. (2022a); Singer et al. (2022) sử dụng một phương pháp tương tự cho tổng hợp video - các mô hình được phân tầng từ độ phân giải thời gian-không gian thấp đến độ phân giải thời gian-không gian cao. Tuy nhiên, vì mỗi mô hình được huấn luyện riêng biệt, chất lượng tạo sinh có thể bị hạn chế bởi độ lệch exposure bias (Bengio et al., 2015) từ các dự đoán không hoàn hảo và cần huấn luyện nhiều mô hình tương ứng với các độ phân giải khác nhau.

Khuếch tán ẩn (LDM, Rombach et al., 2022) và các phương pháp tiếp theo (Peebles & Xie, 2022; Xue et al., 2023; Podell et al., 2023), mặt khác, xử lý việc tạo hình ảnh độ phân giải cao bằng cách thực hiện khuếch tán trong không gian ẩn độ phân giải thấp hơn của một bộ mã hóa tự động được huấn luyện trước, thường được huấn luyện với các mục tiêu đối kháng (Esser et al., 2021). Điều này không chỉ làm tăng độ phức tạp của việc học mà còn giới hạn chất lượng tạo sinh do quá trình nén có mất mát.

Các mô hình đầu cuối-đầu cuối Gần đây, một số phương pháp đã được đề xuất (Hoogeboom et al., 2023; Jabri et al., 2022; Chen, 2023) để huấn luyện các mô hình đầu cuối-đầu cuối trực tiếp trên không gian độ phân giải cao. Mà không dựa vào các mô hình riêng biệt, những phương pháp này tập trung vào thiết kế mạng hiệu quả cũng như lịch trình nhiễu dịch chuyển để thích ứng với các không gian độ phân giải cao. Tuy nhiên, mà không xem xét đầy đủ cấu trúc bẩm sinh của việc tạo phân cấp, kết quả của chúng tụt hậu so với các mô hình phân tầng và ẩn.

3 Mô hình Khuếch tán Matryoshka
Trong phần này, chúng tôi trình bày Matryoshka Diffusion Models (MDM), một lớp mô hình khuếch tán mới được huấn luyện trong không gian độ phân giải cao, trong khi khai thác cấu trúc phân cấp của việc hình thành dữ liệu. MDM đầu tiên tổng quát hóa các mô hình khuếch tán tiêu chuẩn trong không gian mở rộng (§3.1), cho đó các kiến trúc lồng nhau chuyên biệt (§3.2) và các quy trình huấn luyện (Phụ lục B) được đề xuất.

3.1 Mô hình Khuếch tán trong Không gian Mở rộng
Khác với các phương pháp phân tầng hoặc ẩn, MDM học một quá trình khuếch tán đơn với cấu trúc phân cấp bằng cách giới thiệu một quá trình khuếch tán đa độ phân giải trong một không gian mở rộng. Một minh họa được hiển thị trong Hình 2. Cho một điểm dữ liệu x∈RN, chúng ta định nghĩa ẩn phụ thuộc thời gian zt=
z1t, . . . ,zRt
∈ RN1+...NR. Tương tự như Eq. (1), đối với mỗi zr, r= 1, . . . , R :
q(zrt|x) =N(zrt;αrtDr(x), σrt2I), (2)

--- TRANG 4 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
Hình 3: Một minh họa về kiến trúc NestedUNet được sử dụng trong Matryoshka Diffusion. Chúng tôi theo thiết kế của Podell et al. (2023) bằng cách phân bổ nhiều tính toán hơn trong các bản đồ đặc trưng độ phân giải thấp (bằng cách sử dụng nhiều lớp attention hơn chẳng hạn), trong đó trong hình chúng tôi sử dụng độ rộng của một khối để biểu thị số lượng tham số. Ở đây các mũi tên đen chỉ ra các kết nối được kế thừa từ UNet, và các mũi tên đỏ chỉ ra các kết nối bổ sung được giới thiệu bởi Nested UNet.

trong đó Dr:RN→RNr là một toán tử "lấy mẫu giảm" xác định tùy thuộc vào dữ liệu. Ở đây, Dr(x) là một phiên bản thô/được nén có mất mát của x. Ví dụ, Dr(.) có thể là avgpool (.) để tạo ra hình ảnh độ phân giải thấp.

Theo mặc định, chúng tôi giả sử nén theo cách tiến bộ sao cho N1< N 2. . . < N R=N và DR(x) =x. Ngoài ra, {αrt, σrt} là lịch trình nhiễu cụ thể theo độ phân giải. Trong bài báo này, chúng tôi theo Gu et al. (2022) và dịch chuyển lịch trình nhiễu dựa trên các độ phân giải đầu vào. MDM sau đó học quá trình ngược pθ(zt−1|zt) với R bộ khử nhiễu nơ-ron xrθ(zt). Mỗi biến zrt−1 phụ thuộc vào tất cả các độ phân giải {z1t. . .zRt} tại bước thời gian t. Trong quá trình suy luận, MDM tạo ra tất cả R độ phân giải song song. Không có sự phụ thuộc giữa zrt.

Mô hình hóa khuếch tán trong không gian mở rộng có những ưu điểm rõ ràng: (1) vì những gì chúng ta quan tâm trong quá trình suy luận là đầu ra độ phân giải đầy đủ zRt, tất cả các độ phân giải trung gian khác được xem như các biến ẩn bổ sung zrt, làm phong phú thêm độ phức tạp của phân phối được mô hình hóa; (2) sự phụ thuộc đa độ phân giải mở ra cơ hội để chia sẻ trọng số và tính toán qua zrt, cho phép chúng tôi phân bổ lại tính toán theo cách hiệu quả hơn cho cả hiệu quả huấn luyện và suy luận.

3.2 Kiến trúc NestedUNet
Tương tự như các mô hình khuếch tán điển hình, chúng tôi triển khai MDM theo kiểu UNet (Ronneberger et al., 2015; Nichol & Dhariwal, 2021): các kết nối bỏ qua được sử dụng song song với một khối tính toán để bảo toàn thông tin đầu vào chi tiết, trong đó khối bao gồm các lớp tích chập đa cấp và tự chú ý. Trong MDM, dưới giả thiết nén tiến bộ, điều tự nhiên là tính toán cho zrt cũng có lợi cho zr+1t. Điều này dẫn chúng tôi đến đề xuất NestedUNet, một kiến trúc nhóm các ẩn của tất cả độ phân giải {zrt} trong một hàm khử nhiễu như một cấu trúc lồng nhau, trong đó các ẩn độ phân giải thấp sẽ được đưa vào tiến bộ cùng với việc lấy mẫu giảm tiêu chuẩn. Việc chia sẻ tính toán đa quy mô như vậy giúp giảm đáng kể việc học cho việc tạo độ phân giải cao. Một mã giả cho NestedUNet so với UNet tiêu chuẩn được trình bày như sau.

Ngoài khía cạnh đơn giản so với các phương pháp phân cấp khác, NestedUNet cũng cho phép phân bổ tính toán theo cách hiệu quả nhất. Như được hiển thị trong Hình 3, khám phá sớm của chúng tôi thấy rằng MDM đạt được khả năng mở rộng tốt hơn nhiều khi phân bổ hầu hết các tham số & tính toán ở độ phân giải thấp nhất. Những phát hiện tương tự cũng đã được thể hiện trong Hoogeboom et al. (2023).

--- TRANG 5 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
3.3 Học tập
Chúng tôi huấn luyện MDM sử dụng mục tiêu khử nhiễu bình thường cùng lúc tại nhiều độ phân giải, như sau:
Lθ=Et∼[1,T]Ezt∼q(zt|x)RΣr=1 ωrt· ∥xrθ(zt, t)−Dr(x)∥22, (3)
trong đó ωrt là trọng số cụ thể theo độ phân giải, và theo mặc định chúng tôi đặt ωrt/ωRt=NR/Nr.

Huấn luyện Tiến bộ Trong khi MDM có thể được huấn luyện đầu cuối-đầu cuối trực tiếp theo Eq. (3) đã cho thấy sự hội tụ tốt hơn so với các baseline naïve, chúng tôi thấy một kỹ thuật huấn luyện tiến bộ đơn giản, tương tự được đề xuất trong tài liệu GAN (Karras et al., 2017; Gu et al., 2021), tăng tốc đáng kể việc huấn luyện các mô hình độ phân giải cao w.r.t. thời gian thực. Cụ thể hơn, chúng tôi chia việc huấn luyện thành R giai đoạn, trong đó chúng tôi tiến bộ thêm độ phân giải cao hơn vào mục tiêu huấn luyện trong Eq. (3). Điều này tương đương với việc học một chuỗi MDMs trên [z1t, . . .zrt] cho đến khi r đạt đến độ phân giải cuối cùng. Nhờ vào kiến trúc được đề xuất, chúng tôi có thể đạt được điều trên một cách tầm thường như việc phát triển tiến bộ các mạng (Karras et al., 2017). Lịch trình huấn luyện này tránh việc huấn luyện độ phân giải cao tốn kém ngay từ đầu, và tăng tốc sự hội tụ tổng thể.

4 Thí nghiệm
MDM là một kỹ thuật linh hoạt có thể áp dụng cho bất kỳ vấn đề nào mà tính chiều đầu vào có thể được nén tiến bộ. Chúng tôi xem xét hai ứng dụng ngoài tạo hình ảnh có điều kiện lớp chứng minh hiệu quả của phương pháp của chúng tôi – tạo văn bản-tới-hình ảnh và văn bản-tới-video.

4.1 Cài đặt Thí nghiệm
Bộ dữ liệu Trong bài báo này, chúng tôi chỉ tập trung vào các bộ dữ liệu có sẵn công khai và dễ dàng tái tạo. Đối với tạo hình ảnh, chúng tôi thực hiện tạo có điều kiện lớp trên ImageNet (Deng et al., 2009) tại 256×256, và thực hiện tạo văn bản-tới-hình ảnh mục đích chung sử dụng Conceptual 12M (CC12M, Changpinyo et al., 2021) tại cả độ phân giải 256×256 và 1024×1024. Như bằng chứng bổ sung về tính tổng quát, chúng tôi hiển thị kết quả về tạo văn bản-tới-video sử dụng WebVid-10M (Bain et al., 2021) tại 16×256×256. Chúng tôi liệt kê các chi tiết về bộ dữ liệu và tiền xử lý trong Phụ lục F.

Việc lựa chọn dựa rộng rãi vào CC12M cho các mô hình tạo sinh văn bản-tới-hình ảnh trong bài báo là một sự khác biệt đáng kể so với các công trình trước đây (Saharia et al., 2022; Ramesh et al., 2022) dựa vào các bộ dữ liệu cực kỳ lớn và đôi khi không thể truy cập được, và do đó chúng tôi giải thích cho sự lựa chọn này ở đây. Chúng tôi thấy rằng CC12M đủ để xây dựng các mô hình văn bản-tới-hình ảnh chất lượng cao với khả năng zero-shot mạnh mẽ trong thời gian huấn luyện tương đối ngắn (xem chi tiết trong Phụ lục D.2). Điều này cho phép so sánh các phương pháp nhất quán hơn nhiều cho cộng đồng vì bộ dữ liệu có sẵn miễn phí và thời gian huấn luyện là khả thi. Chúng tôi đưa ra ở đây, rằng CC12M phù hợp hơn nhiều như một baseline huấn luyện và đánh giá chung cho cộng đồng làm việc về vấn đề này.

Đánh giá Theo các công trình trước đây, chúng tôi đánh giá các mô hình tạo hình ảnh của chúng tôi sử dụng Khoảng cách Inception Fréchet (FID, Heusel et al., 2017) (ImageNet, CC12M) và điểm số CLIP (Radford et al., 2021) (CC12M). Để kiểm tra khả năng zero-shot của chúng, chúng tôi cũng báo cáo điểm số FID/CLIP sử dụng bộ validation COCO (Lin et al., 2014) để tạo hình ảnh với các mô hình được huấn luyện trên CC12M. Chúng tôi cũng cung cấp thêm các mẫu định tính cho tổng hợp hình ảnh và video trong tài liệu bổ sung.

Chi tiết triển khai Chúng tôi triển khai MDMs dựa trên kiến trúc NestedUNet được đề xuất, với độ phân giải UNet trong cùng được đặt thành 64×64. Tương tự như Podell et al. (2023), chúng tôi chuyển phần lớn các lớp tự chú ý đến các đặc trưng cấp thấp hơn (16×16), dẫn đến tổng cộng 450M tham số cho UNet bên trong. Như được mô tả trong §3.2, phần độ phân giải cao của mô hình có thể dễ dàng được gắn lên trên của cấp trước đó của NestedUNet, với sự gia tăng tối thiểu trong số lượng tham số. Đối với các mô hình văn bản-tới-hình ảnh và văn bản-tới-video, chúng tôi sử dụng FLAN-T5 XL đông lạnh (Chung et al., 2022) làm bộ mã hóa văn bản của chúng tôi do kích thước vừa phải và hiệu suất cho mã hóa ngôn ngữ. Ngoài ra, chúng tôi áp dụng hai lớp tự chú ý có thể học được trên biểu diễn văn bản để tăng cường sự liên kết văn bản-hình ảnh.

Đối với các nhiệm vụ tạo hình ảnh, chúng tôi thí nghiệm với MDMs của {642,2562},{642,1282,2562} cho 256×256, và {642,2562,10242},{642,1282,2562,5122,10242} cho 1024×1024, tương ứng.

--- TRANG 6 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
(a) FID (↓) của ImageNet 256×256.
(b) FID (↓) trên CC12M 256×256.
(c) CLIP (↑) trên CC12M 256×256.
Hình 4: So sánh với các baseline trong quá trình huấn luyện. Điểm số FID (↓) (a, b) và CLIP(↑) (c) của các mẫu được tạo ra mà không có CFG trong quá trình huấn luyện các mô hình có điều kiện lớp khác nhau của ImageNet 256×256(a) và CC12M 256×256(b, c). Như có thể thấy, các mô hình MDM được huấn luyện trước ở độ phân giải thấp hơn (200K bước cho ImageNet, và 390K cho CC12M ở đây) hội tụ nhanh hơn nhiều.

Đối với tạo video, MDM được lồng bởi cùng một UNet hình ảnh 64×64 với các lớp attention bổ sung để học động lực học thời gian. Độ phân giải tổng thể là {642,16×642,16×2562}. Chúng tôi sử dụng nội suy song tuyến tính cho Dr(.) không gian, và lập chỉ mục khung hình đầu tiên cho Dr(.) thời gian. Trừ khi được chỉ định, chúng tôi áp dụng huấn luyện tiến bộ và hỗn hợp độ phân giải cho tất cả MDMs. Chúng tôi sử dụng 8 GPU A100 cho ImageNet, và 32 GPU A100 cho CC12M và WebVid-10M, tương ứng. Xem Phụ lục A và B để biết thêm siêu tham số triển khai và chi tiết huấn luyện.

Các mô hình Baseline Ngoài việc so sánh với các phương pháp hiện đại hiện có, chúng tôi cũng báo cáo phân tích chi tiết về MDMs so với ba mô hình baseline dưới thiết lập được kiểm soát:
1. Simple DM : Một kiến trúc UNet tiêu chuẩn được áp dụng trực tiếp cho các đầu vào độ phân giải cao; Chúng tôi cũng xem xét kiến trúc Nested UNet, nhưng bỏ qua các mất mát độ phân giải thấp; Cả hai trường hợp về cơ bản đều giống hệt với các mô hình khuếch tán đầu cuối-đầu cuối gần đây như Hoogeboom et al. (2023).
2. Cascaded DM : chúng tôi theo chi tiết triển khai của Saharia et al. (2022) và huấn luyện một CDM có thể so sánh trực tiếp với MDM trong đó upsampler có cấu hình giống hệt với NestedUNet của chúng tôi. Chúng tôi cũng áp dụng tăng cường nhiễu cho hình ảnh điều kiện độ phân giải thấp, và quét trên mức nhiễu tối ưu trong quá trình suy luận.
3. Latent DM : chúng tôi sử dụng các mã ẩn được lấy từ các bộ mã hóa tự động từ Rombach et al. (2022), và sau đó huấn luyện các mô hình khuếch tán khớp với kích thước của UNet MDM.

4.2 Kết quả Chính
Bảng 1: So sánh với tài liệu trên ImageNet (FID-50K), và COCO (FID-30K). * chỉ ra các mẫu được tạo ra với CFG. Lưu ý các mô hình văn bản-tới-hình ảnh hiện có chủ yếu được huấn luyện trên các bộ dữ liệu lớn hơn nhiều so với CC12M.

Mô hình FID ↓
ImageNet 256×256
ADM (Nichol & Dhariwal, 2021) 10.94
CDM (Ho et al., 2022b) 4.88
LDM-4 (Rombach et al., 2022) 10.56
LDM-4* (Rombach et al., 2022) 3.60
Của chúng tôi (cfg=1) 8.18
Của chúng tôi (cfg=1.5)* 3.51
MS-COCO 256×256
LDM-8 (Rombach et al., 2022) 23.31
LDM-8* (Rombach et al., 2022) 12.63
Dalle-2* (Ramesh et al., 2022) 10.39
IMAGEN* (Saharia et al., 2021) 7.27
Của chúng tôi (cfg=1) 18.35
Của chúng tôi (cfg=1.35)* 13.43

So sánh với các phương pháp baseline Các so sánh của chúng tôi với baseline được hiển thị trong Hình 4. Trên ImageNet 256×256, chúng tôi chọn một UNet tiêu chuẩn làm baseline simple DM của chúng tôi. Đối với baseline Cascaded DM, chúng tôi huấn luyện trước một mô hình khuếch tán 64x64 trong 200K vòng lặp, và áp dụng một UNet upsampler cũng cùng kích thước. Chúng tôi áp dụng tăng cường nhiễu tiêu chuẩn và quét để tìm mức nhiễu tối ưu trong thời gian suy luận (mà chúng tôi đã thấy là quan trọng). Đối với các thí nghiệm LDM, chúng tôi sử dụng các bộ mã hóa tự động được huấn luyện trước từ Rombach et al. (2022) làm giảm độ phân giải đầu vào và chúng tôi sử dụng cùng kiến trúc cho những thí nghiệm này như các mô hình độ phân giải thấp 64x64 của chúng tôi. Đối với các biến thể MDM, chúng tôi sử dụng một NestedUNet có cùng kích thước với UNet baseline. Chúng tôi thí nghiệm với hai biến thể, một được huấn luyện trực tiếp với mất mát đa độ phân giải Eq. (3) (được ký hiệu là no PT), và một cái khác tiếp tục từ mô hình khuếch tán 64x64 (tức là, huấn luyện tiến bộ). CC12M 256x256 theo một thiết lập tương tự, ngoại trừ chúng tôi sử dụng một NestedUNet mất mát đơn làm kiến trúc simple DM của chúng tôi. Chúng tôi theo dõi đường cong FID trên ImageNet, và các đường cong FID và CLIP trên CC12M.

--- TRANG 7 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
Hình 5: Các mẫu ngẫu nhiên từ MDM có điều kiện lớp được huấn luyện của chúng tôi trên ImageNet 256×256.

So sánh simple DM với MDM, chúng ta thấy rằng MDM rõ ràng có sự hội tụ nhanh hơn, và đạt được hiệu suất tốt hơn ở cuối. Điều này gợi ý rằng quá trình khuếch tán đa độ phân giải cùng với mất mát đa độ phân giải cải thiện hiệu quả sự hội tụ của mô hình, với độ phức tạp gia tăng không đáng kể. Khi theo lịch trình huấn luyện tiến bộ, chúng ta thấy rằng hiệu suất và tốc độ hội tụ của MDM được cải thiện thêm. Như một so sánh trực tiếp, chúng ta thấy rằng baseline Cascaded DM kém hiệu suất đáng kể so với MDM, trong khi cả hai đều bắt đầu từ cùng một mô hình 64x64. Lưu ý rằng điều này đáng chú ý vì Cascaded DM có nhiều tham số kết hợp hơn so với MDM (vì MDM có việc chia sẻ tham số rộng rãi qua các độ phân giải), và sử dụng gấp đôi số bước suy luận. Chúng tôi giả thuyết rằng hiệu suất kém của Cascaded DM chủ yếu do thực tế là 64x64 của chúng tôi không được huấn luyện tích cực, gây ra khoảng cách lớn giữa huấn luyện và suy luận w.r.t. các đầu vào điều kiện. Cuối cùng, so với LDM, MDM cũng cho thấy hiệu suất tốt hơn. Mặc dù đây là một kiểm soát ít trực tiếp hơn vì LDM thực sự hiệu quả hơn do kích thước đầu vào nhỏ của nó, nhưng MDM có một đường ống huấn luyện và suy luận đơn giản hơn.

So sánh với tài liệu Trong Bảng 1, MDM được so sánh với các phương pháp hiện có trong tài liệu, trong đó chúng tôi báo cáo FID-50K cho ImageNet 256x256 và FID-30K zero shot trên MSCOCO. Trên ImageNet, mà kiến trúc và siêu tham số của chúng tôi không được tối ưu hóa, MDM có thể đạt được FID cạnh tranh 3.51 với CFG. Kết quả FID của chúng tôi có thể so sánh với tài liệu, mặc dù MDM được huấn luyện trên dữ liệu ít hơn đáng kể so với các baseline như Imagen và Dalle-2.

Kết quả Định tính Chúng tôi hiển thị các mẫu ngẫu nhiên từ các MDMs được huấn luyện cho tạo hình ảnh (ImageNet 256×256, Hình 5), văn bản-tới-hình ảnh (CC12M, 1024×1024 Hình 6) và văn bản-tới-video (WebVid-10M, Hình 7). Mặc dù huấn luyện trên các bộ dữ liệu tương đối nhỏ, MDMs cho thấy khả năng zero-shot mạnh mẽ trong việc tạo ra hình ảnh và video độ phân giải cao. Lưu ý rằng chúng tôi sử dụng cùng đường ống huấn luyện cho cả ba nhiệm vụ, chỉ ra khả năng linh hoạt của nó trong việc xử lý các loại dữ liệu khác nhau.

4.3 Nghiên cứu Tách biệt
Tác động của huấn luyện tiến bộ Chúng tôi thí nghiệm với lịch trình huấn luyện tiến bộ, trong đó chúng tôi thay đổi số vòng lặp mà mô hình độ phân giải thấp được huấn luyện trước khi tiếp tục với độ phân giải đích (Hình 8a). Chúng ta thấy rằng việc huấn luyện độ phân giải thấp nhiều hơn rõ ràng có lợi cho các đường cong FID độ phân giải cao. Lưu ý rằng huấn luyện trên các đầu vào độ phân giải thấp hiệu quả hơn nhiều w.r.t. cả độ phức tạp bộ nhớ và thời gian, huấn luyện tiến bộ cung cấp một tùy chọn đơn giản để tìm ra các đánh đổi tính toán tốt nhất trong quá trình huấn luyện.

Tác động của các cấp lồng nhau Tiếp theo, chúng tôi so sánh hiệu suất của việc sử dụng số lượng khác nhau của các độ phân giải lồng nhau với các thí nghiệm trên CC12M. Kết quả được hiển thị trong Hình 8b. Chúng ta thấy rằng việc tăng từ hai cấp độ phân giải lên ba cải thiện liên tục sự hội tụ của mô hình. Cũng đáng chú ý rằng việc tăng số lượng cấp lồng nhau chỉ mang lại chi phí không đáng kể.

Đánh đổi CLIP-FID Cuối cùng, chúng tôi hiển thị trong Hình 8c đường cong pareto của CLIP-FID trên đánh giá zero-shot của COCO, đạt được bằng cách thay đổi trọng số hướng dẫn không có classifier (CFG). MDM cũng có thể áp dụng CFG như các biến thể mô hình khuếch tán khác. Như một so sánh, chúng tôi chồng lấp cùng biểu đồ được báo cáo bởi Imagen (Hình A.11). Chúng ta thấy rằng Imagen nói chung chứng minh FID nhỏ hơn, mà chúng tôi quy cho sự đa dạng cao hơn như kết quả của việc huấn luyện trên một bộ dữ liệu lớn. Tuy nhiên, MDM chứng minh điểm số CLIP mạnh mẽ, trong khi chúng tôi đã thấy trên thực tế rằng các điểm số CLIP cao như vậy tương quan rất tốt với chất lượng hình ảnh của các hình ảnh được tạo ra.

--- TRANG 8 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
Hình 6: Các mẫu từ mô hình được huấn luyện trên CC12M tại 10242 với huấn luyện tiến bộ.

--- TRANG 9 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
Hình 7: Các mẫu từ mô hình được huấn luyện trên WebVid-10M tại 16×2562 với huấn luyện tiến bộ. Video được lấy mẫu phụ để dễ trực quan hóa.

(a) FID (↓) trên ImageNet 256×256.
(b) CLIP (↑) trên CC12M 256×256.
(c) Đánh đổi trên COCO 256×256.
Hình 8: (a) Tăng số bước của việc huấn luyện độ phân giải thấp trong huấn luyện tiến bộ cải thiện kết quả. (b) Số lượng cấp lồng nhau lớn hơn trên CLIP tạo ra nhiều cải thiện hơn về tốc độ hội tụ và điểm số cuối cùng (c) Đánh đổi FID vs CLIP được nhìn thấy bằng cách thay đổi trọng số của CFG (sử dụng đánh giá trên COCO)

5 Các Công trình Liên quan
Ngoài các phương pháp khuếch tán được đề cập trong §2, các mô hình đa quy mô đã được sử dụng rộng rãi trong tạo hình ảnh và học biểu diễn (Kusupati et al., 2022). Một Mạng Đối kháng Tạo sinh (GAN) nổi tiếng là mô hình LAPGAN (Denton et al., 2015) tạo ra hình ảnh độ phân giải thấp hơn được sau đó đưa vào các mô hình độ phân giải cao hơn. Khuếch tán Kim tự tháp (Ryu & Ye, 2022), áp dụng một chiến lược tương tự với các mô hình khuếch tán khử nhiễu. Các mô hình tự hồi quy cũng đã được áp dụng cho việc tạo – từ các công trình đầu cho hình ảnh (Van Den Oord et al., 2016; Oord et al., 2016) và video (Kalchbrenner et al., 2017; Weissenborn et al., 2020), đến các mô hình văn bản-tới-hình ảnh gần đây hơn (Gafni et al., 2022; Yu et al., 2022) và các mô hình văn bản tới video (Wu et al., 2021; Singer et al., 2022). Trong khi các công trình trước đây thường hoạt động trong không gian pixel, các công trình gần đây, chẳng hạn như Parti (Yu et al., 2022) và MakeAScene (Gafni et al., 2022) sử dụng các bộ mã hóa tự động để tiền xử lý hình ảnh thành các đặc trưng ẩn rời rạc có thể được mô hình hóa tự hồi quy sử dụng các mô hình chuỗi-tới-chuỗi lớn dựa trên transformer. f-DM (Gu et al., 2022) đề xuất một khung làm việc tổng quát cho phép biến đổi tín hiệu tiến bộ qua nhiều quy mô, và đưa ra một bộ lập lịch khử nhiễu tương ứng để chuyển đổi từ các giai đoạn đa độ phân giải. Bộ lập lịch này được sử dụng trong công trình của chúng tôi. Tương tự, IHDM (Rissanen et al., 2023) thực hiện tạo sinh thô-tới-mịn ngầm tăng độ phân giải.

6 Thảo luận và Hướng phát triển Tương lai
Trong bài báo này, chúng tôi cho thấy rằng việc chia sẻ biểu diễn qua các độ phân giải khác nhau có thể dẫn đến việc huấn luyện nhanh hơn với kết quả chất lượng cao, khi các độ phân giải thấp hơn được huấn luyện trước. Chúng tôi tin rằng điều này là do mô hình có thể khai thác các tương quan qua các độ phân giải khác nhau hiệu quả hơn, cả về không gian và thời gian. Trong khi chúng tôi chỉ khám phá một tập hợp nhỏ các kiến trúc ở đây, chúng tôi mong đợi nhiều cải thiện hơn có thể đạt được từ việc khám phá chi tiết hơn về các kiến trúc chia sẻ trọng số, và các cách mới để phân phối tham số qua các độ phân giải khác nhau trong kiến trúc hiện tại.

Một khía cạnh độc đáo khác của công trình của chúng tôi là việc sử dụng không gian tăng cường, trong đó việc khử nhiễu được thực hiện trên nhiều độ phân giải cùng lúc. Trong công thức này, độ phân giải theo thời gian và không gian được xử lý theo cùng một cách, với sự khác biệt trong cấu trúc tương quan trong thời gian và không gian được học bởi các tham số khác nhau của mô hình chia sẻ trọng số. Một cách tổng quát hơn để khái niệm hóa việc tối ưu hóa chung trên nhiều độ phân giải là tách rời các mất mát ở các độ phân giải khác nhau, bằng cách trọng số chúng khác nhau. Có thể hình dung rằng một chuyển đổi mượt mà có thể đạt được từ việc huấn luyện trên độ phân giải thấp hơn đến cao hơn. Chúng tôi cũng lưu ý rằng trong khi chúng tôi đã so sánh phương pháp của mình với LDM trong bài báo, những phương pháp này là bổ sung. Có thể xây dựng MDM trên đầu các mã bộ mã hóa tự động. Trong khi chúng tôi không đưa ra tuyên bố rằng các mô hình dựa trên MDM đang đạt đến SOTA, chúng tôi để lại việc đánh giá MDM trên bộ dữ liệu quy mô lớn và kích thước mô hình như công việc tương lai.

Lời cảm ơn
Chúng tôi cảm ơn Miguel Angel Bautista, Jason Ramapuram, Alaaeldin El-Nouby, Laurent Dinh, Ruixiang Zhang, Yuyang Wang vì những gợi ý quan trọng và phản hồi có giá trị cho dự án này. Chúng tôi cảm ơn Ronan Collobert, David Grangier và Awni Hanun vì sự hỗ trợ vô giá và đóng góp cho đường ống bộ dữ liệu.

--- TRANG 10 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
Hình 9: Các mẫu ngẫu nhiên từ MDM được huấn luyện trên bộ dữ liệu CC12M tại độ phân giải 256×256 và 1024×1024. Xem chú thích chi tiết trong Phụ lục G.

--- TRANG 15 ---
Đã xuất bản như một bài báo hội nghị tại ICLR 2024
Phụ lục
Hình 10: Một minh họa về kiến trúc NestedUNet được sử dụng trong Matryoshka Diffusion để tạo video. Chúng tôi phân bổ nhiều tính toán hơn trong các bản đồ đặc trưng độ phân giải thấp, và sử dụng các lớp attention thời gian bổ sung để tổng hợp thông tin qua các khung hình.

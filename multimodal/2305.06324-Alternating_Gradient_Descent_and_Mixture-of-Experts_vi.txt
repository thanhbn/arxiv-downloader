Descent Gradient Luân phiên và Mixture-of-Experts cho Nhận thức Đa phương thức Tích hợp

Hassan Akbari∗Dan Kondratyuk∗Yin Cui
Rachel Hornung Huisheng Wang Hartwig Adam
Google Research
{hassanak, dankondratyuk, yincui, rachelhornung, huishengw, hadam}@google.com

Tóm tắt
Chúng tôi trình bày Integrated Multimodal Perception (IMP), một phương pháp đào tạo và mô hình hóa đa nhiệm vụ đa phương thức đơn giản và có thể mở rộng. IMP tích hợp các đầu vào đa phương thức bao gồm hình ảnh, video, văn bản và âm thanh vào một Transformer encoder duy nhất với các thành phần đặc thù phương thức tối thiểu. IMP sử dụng một thiết kế mới kết hợp Alternating Gradient Descent (AGD) và Mixture-of-Experts (MoE) để mở rộng mô hình và nhiệm vụ một cách hiệu quả. Chúng tôi tiến hành các nghiên cứu thực nghiệm rộng rãi và khám phá những hiểu biết quan trọng sau: 1) thực hiện cập nhật gradient descent bằng cách luân phiên trên các phương thức đa dạng, hàm mất mát và nhiệm vụ, với độ phân giải đầu vào khác nhau, cải thiện mô hình một cách hiệu quả. 2) sparsification với MoE trên một encoder duy nhất không phụ thuộc phương thức cải thiện đáng kể hiệu suất, vượt trội so với các mô hình dense sử dụng encoder đặc thù phương thức hoặc các lớp fusion bổ sung và giảm thiểu đáng kể xung đột giữa các phương thức. IMP đạt hiệu suất cạnh tranh trên nhiều nhiệm vụ downstream bao gồm phân loại video, phân loại hình ảnh, truy xuất hình ảnh-văn bản và video-văn bản. Đáng chú ý nhất, chúng tôi đào tạo một IMP-MoE-L sparse tập trung vào các nhiệm vụ video đạt được state-of-the-art mới trong phân loại video zero-shot: 77.0% trên Kinetics-400, 76.8% trên Kinetics-600, và 68.3% trên Kinetics-700, cải thiện state-of-the-art trước đó lần lượt +5%, +6.7%, và +5.8%, trong khi chỉ sử dụng 15% tổng chi phí tính toán đào tạo của họ.

1 Giới thiệu
Hệ thống nhận thức của con người có tính đa phương thức sâu sắc. Chúng ta nhận thức thế giới thông qua việc tích hợp một loạt rộng lớn các hệ thống cảm giác qua các lĩnh vực — thị giác, thính giác, khứu giác, xúc giác, v.v. Các nơ-ron cho tích hợp đa phương thức đã được tìm thấy trong cả các vùng hội tụ đa cảm giác Calvert [2001] và các vùng đơn phương thức Driver và Noesselt [2008] trong não người. Các nghiên cứu trong tâm lý học phát triển cũng cho thấy rằng việc liên kết các cảm giác đa phương thức đồng thời là chìa khóa cho việc học nhận thức Smith và Gasser [2005]. Được truyền cảm hứng bởi những phát hiện này, chúng tôi thấy cơ hội cho việc học đa cảm giác kết hợp trong các hệ thống machine learning.

Sự gia tăng nhanh chóng của các framework và mô hình đa nhiệm vụ quy mô lớn [Raffel et al., 2020, Roberts et al., 2022, Radford et al., 2021, Yu et al., 2022, Wang et al., 2022] cung cấp nền tảng để tích hợp các khả năng thống nhất nhiều nhiệm vụ riêng biệt dưới một mô hình. Tuy nhiên, với số lượng lớn các biến độc lập liên quan đến việc thiết kế một hệ thống như vậy, việc đạt được một mô hình machine learning đa phương thức tích hợp vẫn là một hướng nghiên cứu mở. Cụ thể hơn, việc thiết kế một mô hình đa nhiệm vụ tích hợp nhiều tín hiệu đa phương thức là thách thức do nhiều lý do: i. Các phương thức khác nhau yêu cầu các chữ ký I/O khác nhau về cấu trúc để đào tạo đúng cách. ii. Khi đào tạo trên nhiều bộ dữ liệu, một số phương thức hoặc mục tiêu có thể không tồn tại hoặc không thể áp dụng, tùy thuộc vào dữ liệu đầu vào và nhiệm vụ cần thực hiện. iii. Sự hiện diện của nhiều phương thức đầu vào đòi hỏi sự cân nhắc cẩn thận về thiết kế kiến trúc và phân bổ tham số cho các phương thức nhất định, thường yêu cầu điều chỉnh hyperparameter rộng rãi để tìm cách sử dụng tốt nhất các tài nguyên tính toán.

Trực quan, khi chúng ta mở rộng một mô hình, việc thiết kế lại kiến trúc hoặc tìm kiếm một mục tiêu đào tạo tốt hơn trở nên ngày càng đắt đỏ. Vấn đề được làm trầm trọng thêm trong mô hình hóa đa nhiệm vụ đa phương thức, nơi chúng ta cần xem xét sự kết hợp của các phương thức đầu vào hoặc bộ dữ liệu, hàm mất mát và nhiệm vụ ở quy mô lớn. Do đó, chúng tôi muốn tìm một phương pháp đào tạo có thể được mở rộng dần dần: đối với bất kỳ nhiệm vụ hoặc mục tiêu mới nào, bất kể hình dạng đầu vào hoặc mất mát đầu ra của nó, chúng ta nên có thể thêm nó vào pretraining hiện có mà không làm tổn hại đến các nhiệm vụ trước đó.

Chúng tôi điều hướng vấn đề này bằng cách khám phá các cách mà chúng ta có thể đào tạo một mô hình đa phương thức sao cho nó (1) tận dụng càng nhiều bộ dữ liệu hiện có càng tốt, (2) có thể đào tạo trên bất kỳ sự kết hợp nào của các nhiệm vụ hoặc hàm mất mát, và (3) không làm chậm với việc bổ sung bất kỳ bộ dữ liệu, nhiệm vụ hoặc hàm mất mát mới nào. Bằng cách giải quyết tất cả những điểm này đồng thời, một mô hình đa phương thức có thể mở rộng với một tập dữ liệu đào tạo ngày càng đa dạng và phong phú mà không cần thiết kế lại framework đào tạo khi các nhiệm vụ mới được tích hợp.

Chúng tôi quan sát trong kết quả thực nghiệm của mình rằng sự kết hợp của các nhiệm vụ đa dạng, không đồng nhất đã được thiết lập trước đây là các mục tiêu mạnh mẽ riêng lẻ (ví dụ: phân loại có giám sát và học tương phản tự giám sát) qua nhiều phương thức không chỉ bổ sung cho nhau, mà còn có thể cung cấp sự hội tụ tốt hơn so với đào tạo trên các nhiệm vụ riêng lẻ. Bằng cách triển khai Alternating Gradient Descent (AGD) và Mixture-of-Experts (MoE) thông qua các primitives JAX được phát triển gần đây, chúng tôi cho phép mô hình của mình sử dụng một phần chi phí tính toán và bộ nhớ yêu cầu bởi các mô hình nhận thức quy mô lớn tương tự [Radford et al., 2021, Jia et al., 2021, Yu et al., 2022], mặc dù việc bổ sung nhiều phương thức thường yêu cầu 2-8 × tính toán ở kích thước batch tương tự.

Với bối cảnh này, các đóng góp và phát hiện của chúng tôi như sau:

1. Chúng tôi định nghĩa một mô hình encoder tích hợp không phụ thuộc phương thức, và tận dụng sự kết hợp mạnh mẽ của mất mát tương phản hình ảnh-văn bản, tương phản video-văn bản, tương phản video-âm thanh, và phân loại hình ảnh/video/âm thanh trong quá trình pretraining để tạo ra một mô hình Integrated Multimodal Perception (IMP), như được hiển thị trong Hình 1.

2. Trái với phương pháp truyền thống của việc cộng các mất mát của nhiều mục tiêu, chúng tôi cho thấy rằng việc luân phiên giữa các mục tiêu dẫn đến một thiết kế cho phép tích hợp liền mạch hầu như bất kỳ số lượng nhiệm vụ và bộ dữ liệu nào mà không có overhead bộ nhớ đáng kể và dẫn đến đánh giá downstream tốt hơn.

3. Chúng tôi cho thấy rằng tối ưu hóa giữa nhiều nhiệm vụ đa phương thức không đồng nhất là bổ sung và dẫn đến một mô hình chất lượng cao hơn so với đào tạo trên bất kỳ nhiệm vụ riêng lẻ nào.

4. Để đào tạo trên các batch lớn của phương thức video và âm thanh mà không làm giảm hiệu quả đào tạo hoặc mất độ chính xác, chúng tôi thiết kế một hỗn hợp động của các độ phân giải, độ dài chuỗi và kích thước batch khác nhau trong suốt quá trình pretraining, và luân phiên đào tạo trên tất cả các biến thể đầu vào.

5. Chúng tôi trang bị mô hình của mình với MoE, cho thấy những cải thiện hiệu suất mạnh mẽ so với một mô hình tương phản multi-tower truyền thống hơn, ngay cả khi áp dụng MoE cho cả hai tower.

6. Chúng tôi mở rộng mô hình MoE-IMP kết quả của mình lên 2B tham số sparse với tính toán tương tự ViT-L (300M tham số), dẫn đến hiệu suất state-of-the-art trên nhiều bộ dữ liệu hiểu video đa phương thức quy mô lớn.

2 Công trình liên quan
Tính tối ưu của tối ưu hóa AGD so với việc tính trung bình các mất mát (hoặc gradient) đã được khám phá trong các công trình trước [Jain et al., 2017, Pascal et al., 2021]. Đào tạo đa nhiệm vụ đa phương thức luân phiên với AGD đã được khám phá trong PolyViT [Likhosherstov et al., 2021], phân tích các phương pháp khác nhau để kết hợp các nhiệm vụ không đồng nhất trong một mô hình duy nhất. Công trình báo cáo những phát hiện tương tự với của chúng tôi, rằng việc kết hợp các mục tiêu có thể có lợi lẫn nhau và luân phiên giữa các bộ dữ liệu được cân nhắc theo số lượng ví dụ cung cấp một trong những phương pháp tốt nhất cho tối ưu hóa. Công trình của chúng tôi mở rộng điều này đến một setup chung hơn nhiều hỗ trợ hầu như bất kỳ sự kết hợp nào của phương thức, nhiệm vụ, độ phân giải, v.v.

Việc sử dụng MoE sparse cho mô hình hóa đa phương thức có thể được thấy trong các công trình gần đây như LIMoE [Mustafa et al., 2022], sử dụng một encoder MoE duy nhất cho các nhiệm vụ hình ảnh-văn bản, và VL-MoE [Shen et al., 2023], sử dụng các chuyên gia đặc thù phương thức cho mô hình hóa hình ảnh-văn bản. Công trình của chúng tôi mở rộng khái niệm này hơn nữa, giới thiệu các phương thức video và âm thanh với đào tạo luân phiên trên nhiều nhiệm vụ và độ phân giải mà không yêu cầu các chuyên gia đặc thù phương thức.

Do những phức tạp vốn có của việc tích hợp các phương thức trong một mô hình, công việc đã được thực hiện bằng cách đơn giản hóa vấn đề và tập trung vào một tập nhỏ các mục tiêu phổ quát áp dụng cho tất cả các phương thức [Yu et al., 2022, Wang et al., 2022]. Ngoài ra, một số công trình tập trung vào việc áp dụng các chiến lược padding hoặc masking để xử lý các chữ ký I/O không tương thích từ các nhiệm vụ khác nhau. Chúng tôi nhận thấy trong cả hai trường hợp, điều này hạn chế nghiêm trọng khả năng của mô hình tận dụng các bộ dữ liệu quy mô lớn có sẵn hoặc mở rộng sang các phương thức hoàn toàn mới. Các lý do lịch sử là: (i) hầu hết các mô hình hiện có được thiết kế cho các phương thức đầu vào cụ thể ví dụ: ngôn ngữ [Brown et al., 2020, Chowdhery et al., 2022], thị giác [Dosovitskiy et al., 2020], hoặc âm thanh [Baevski et al., 2020]; (ii) các phương thức khác nhau thường được ủy quyền cho các weight mạng riêng biệt để có hiệu suất tốt nhất [Radford et al., 2021, Jia et al., 2021]; (iii) khó khăn tối ưu hóa với nhiều phương thức [Wu et al., 2022, Chen et al., 2022].

3 Phương pháp

3.1 Alternating Gradient Descent (AGD)
Một trong những trụ cột cốt lõi của phương pháp của chúng tôi đối với hiểu đa phương thức là khả năng mở rộng nhiệm vụ. Tức là, các kết hợp khác nhau của dữ liệu và mục tiêu mất mát nên có thể hoán đổi cho nhau trong suốt quá trình đào tạo, trong khi việc bổ sung bất kỳ dữ liệu hoặc mục tiêu mới nào không nên gây ra overhead bộ nhớ và tính toán. Chúng tôi nhận thấy rằng một vấn đề phổ biến trong việc đào tạo các mô hình nền tảng quy mô lớn trong môi trường phân tán là các chữ ký đầu vào và mục tiêu mất mát cần phải tĩnh để tránh những không hiệu quả lớn. Các API biên dịch đồ thị tăng tốc cho phép tối ưu hóa đồ thị cấp thấp tối đa hóa việc sử dụng FLOPs phần cứng trên các thiết bị phân tán như GPU và TPU, nhưng đi kèm với chi phí yêu cầu các chữ ký I/O tĩnh.

Một phương pháp để xử lý vấn đề với chữ ký đầu vào tĩnh sẽ là sử dụng mixed batching, nơi tất cả các đầu vào có thể được xây dựng, và các đầu vào không áp dụng được cho một bộ dữ liệu nhất định được đệm và đầu ra được che tương ứng ở mỗi bước đào tạo. Tuy nhiên, điều này đi kèm với chi phí hiệu quả lớn, vì càng nhiều nhiệm vụ được thêm vào thì càng nhiều thời gian được dành cho tính toán trên các đầu vào được đệm. Vấn đề với việc có nhiều hàm mục tiêu thường được giải quyết bằng mixed mini-batching, nơi một batch được chia thành nhiều mini-batch với các hàm mục tiêu tương ứng của chúng. Các gradient cho mỗi cặp mini-batch và hàm mục tiêu được tích lũy qua nhiều mini-batch và các weight mô hình được cập nhật một lần sử dụng gradient tổng hợp. Tuy nhiên, phương pháp này cũng khó mở rộng vì các gradient qua nhiều mini-batch được tích lũy trong bộ nhớ và kích thước batch cho mỗi nhiệm vụ tự nhiên giảm khi chúng ta thêm nhiều nhiệm vụ hơn.

Chúng tôi đề xuất một giải pháp chung hơn dựa trên AGD [Jain et al., 2017], cho phép bất kỳ thay đổi nào đối với ba yếu tố của hệ thống tối ưu hóa: đầu vào, mô hình và mục tiêu. AGD có thể được xem như một tập cha của SGD truyền thống, nơi ở mỗi bước gradient, một mục tiêu khác nhau có thể được tối ưu hóa với các tập weight mô hình và/hoặc phương thức đầu vào khác nhau. Cụ thể hơn, bất kỳ phương thức đầu vào nào với hình dạng tùy ý có thể tiêu thụ bất kỳ tập con nào của mô hình trong khi tập trung vào việc tối thiểu hóa bất kỳ sự kết hợp cụ thể nào của các hàm mục tiêu. Theo Jain et al. [2017] đã được chứng minh rằng nếu mỗi bước tối ưu hóa như vậy là convex riêng lẻ, một sự luân phiên giữa chúng dẫn đến sự hội tụ được đảm bảo; trái ngược với mini-batching nơi tích lũy gradient có thể dẫn đến kết quả không tối ưu. Từ quan điểm kỹ thuật, phương pháp này yêu cầu biên dịch nhiều đồ thị tính toán, một cho mỗi bước tối ưu hóa duy nhất. Để cho phép thực thi hiệu quả của nhiều đồ thị tính toán, JAX cung cấp biên dịch Just-in-Time (JIT) gốc với API jax.jit, biên dịch đồ thị quan tâm tại runtime và biên dịch một đồ thị mới nếu một thay đổi trong cấu trúc được thấy trong bất kỳ bước tối ưu hóa nào tiếp theo. Bản thân các đồ thị được cache bởi JAX trong một bảng tra cứu trong bộ nhớ để các nhiệm vụ chỉ cần được biên dịch một lần. Chúng tôi quan sát thực nghiệm rằng việc tiêu thụ bộ nhớ đồ thị chiếm một phần không đáng kể của toàn bộ đào tạo. Trong các thí nghiệm của chúng tôi, chúng tôi đã kiểm tra lên đến 20 cấu trúc nhiệm vụ duy nhất mà không có giảm đáng kể trong tốc độ đào tạo, với việc biên dịch chỉ chiếm 0.34% của tổng thời gian đào tạo, lên đến quy mô lớn nhất.

Thuật toán AGD chính cho framework đa phương thức của chúng tôi được cung cấp trong Thuật toán 1. Chúng tôi lưu ý rằng chúng tôi thiết kế vòng lặp một cách cẩn thận để càng agnostic càng tốt đối với bộ ba dữ liệu-mô hình-mục tiêu. Điều này cho phép linh hoạt hơn trong việc định nghĩa logic bên trong mô hình để xử lý việc xử lý các phương thức riêng lẻ và hình dạng đầu vào. Hàm sampling cũng có thể kết hợp state từ chính quá trình tối ưu hóa. Ví dụ: giá trị mất mát của một bước nhất định có thể được sử dụng làm tín hiệu reward để ảnh hưởng đến hành vi sampling trong các sampling tiếp theo [Piergiovanni et al., 2023, Mindermann et al., 2022]. Trong thiết lập mặc định của chúng tôi, chúng tôi sample mỗi nhiệm vụ duy nhất trên một bước nhất định từ một phân phối Multinomial (thử nghiệm đơn) với xác suất trực tiếp tỷ lệ với số lượng ví dụ trong mỗi nhiệm vụ. Chúng tôi trì hoãn các thiết lập phức tạp hơn hoặc dựa trên reward cho các nghiên cứu tương lai.

3.1.1 Cân nhắc Hiệu quả Đặc thù AGD
Chúng tôi nhận thấy rằng trong mỗi lệnh gọi forward, các state mô hình nhất định như activation được lưu trữ theo mặc định để được sử dụng sau này trong lệnh gọi backward cho tính toán gradient. Đây là một tối ưu hóa tính toán đã được thiết lập ở mức biên dịch đồ thị cấp thấp trong XLA và các API tương tự. Mặc dù thủ thuật này giúp rất nhiều cho thời gian đào tạo, nó tiêu thụ đáng kể bộ nhớ và tạo ra overhead bộ nhớ nếu nhiều hơn một đồ thị được biên dịch và sử dụng trong quá trình đào tạo. Để giảm overhead bộ nhớ, chúng tôi sử dụng API rematerialization gốc của JAX, jax.checkpoint để tiết kiệm bộ nhớ bằng cách không checkpoint bất kỳ state mô hình trung gian nào. Trong các thí nghiệm của chúng tôi, chúng tôi quan sát việc giảm trung bình 70-80% việc sử dụng TPU HBM trong khi chỉ dẫn đến thời gian bước dài hơn 18-20%.

Chúng tôi cũng nhận thấy rằng các mô hình lớn với nhiều mục tiêu khác nhau vẫn có thể phát sinh thời gian biên dịch dài. Do đó, chúng tôi áp dụng scan-over-layers với jax.lax.scan, một phương pháp cuộn tất cả các lớp Transformer thành một lớp duy nhất được gọi nhiều lần sử dụng các weight khác nhau (thay vì biên dịch cùng một hàm nhiều lần). Điều này một mình dẫn đến thời gian biên dịch nhanh hơn 15-30x tùy thuộc vào độ dài mô hình. Chúng tôi quan sát việc tăng tiết kiệm thời gian tương đối với kích thước mô hình lớn hơn. Hơn nữa, chúng tôi thực hiện những điều này qua các accelerator phân tán thông qua API jax.pjit, phân phối biên dịch JIT qua nhiều accelerator.

3.2 Mục tiêu
Mục tiêu của chúng tôi trong việc thiết kế mô hình IMP là tái sử dụng các mục tiêu đã được chứng minh là mạnh mẽ cho việc học mỗi phương thức. Do đó, chúng tôi chọn hai mục tiêu học có giám sát và không giám sát được thiết lập nhất: i. Phân loại có giám sát sử dụng Softmax/Binary Cross-Entropy (SCE/BCE), ii. Cross-Modal Noise-Contrastive Estimation (NCE). Trừ khi được chỉ định khác, chúng tôi không cộng bất kỳ mất mát nào ở trên hoặc tích lũy gradient như sẽ được thực hiện truyền thống. Thay vào đó, chúng tôi áp dụng backprop trên mỗi mục tiêu riêng lẻ với AGD.

3.3 Kiến trúc
Hình 1 cho thấy tổng quan cấp cao về kiến trúc của IMP, bao gồm ba module chính: i. Embedder, chấp nhận các phương thức cụ thể và nhúng chúng trong một không gian agnostic phương thức chia sẻ; ii. MoE Encoder, tính toán các embedding ngữ cảnh ngữ nghĩa từ các token đã nhúng; iii. Heads, tạo ra tất cả các dự đoán cuối cùng từ Encoder bằng cách chiếu lại các embedding của nó trở lại không gian đặc thù phương thức. Chúng tôi giải thích ngắn gọn mỗi module ở đây và cung cấp thêm chi tiết trong Phụ lục.

Một quyết định thiết kế quan trọng đối với mô hình hóa đa phương thức là cách phân bổ tham số cho mỗi phương thức. Như được thấy trong các công trình như BASIC [Pham et al., 2021], một thiết kế bất đối xứng đặc thù phương thức có thể tối ưu hơn so với việc sử dụng một mô hình có kích thước tương tự cho mỗi phương thức. Tuy nhiên, điều này đi kèm với chi phí yêu cầu điều chỉnh hyperparameter bổ sung để tìm tham số hóa tối ưu. Như chúng tôi cho thấy sau trong phần tiếp theo, chúng tôi quan sát rằng thông qua việc sử dụng sparsification mô hình với MoE, một thiết kế encoder thống nhất kết hợp với các lớp trước và sau encoder đặc thù phương thức nhất định tối ưu hơn so với một thiết lập multi-encoder truyền thống như được thấy trong các biến thể mô hình CLIP.

Chúng tôi tuân theo VATT [Akbari et al., 2021], AudioMAE [Huang et al., 2022], và T5 [Raffel et al., 2020] để trích xuất các embedding thị giác, âm thanh và văn bản, tương ứng. Chúng tôi thêm các encoding vị trí 3D/2D/1D có thể học vào các embedding và chiếu chúng vào một không gian có cùng chiều với của mô hình. Chúng tôi truyền các đầu vào nhúng này bất kể phương thức như-là thông qua encoder chia sẻ, đây là một kiến trúc Transformer tiêu chuẩn được trang bị các lớp FFN Mixture-of-Experts. Chúng tôi tuân theo V-MoE [Riquelme et al., 2021] và LIMoE [Mustafa et al., 2022] cho phân bổ chuyên gia. Điều này có thể được xem như một inductive bias, cho phép mỗi chuyên gia được phân bổ cho nhiều phương thức nếu tối ưu hóa có lợi. Một lợi ích ngay lập tức là việc bổ sung các phương thức mới cho fine-tuning không cần bất kỳ thay đổi cụ thể nào đối với encoder, không giống như các chuyên gia đặc thù phương thức yêu cầu các sửa đổi bổ sung và xử lý đầu vào [Wang et al., 2022, Shen et al., 2023].

Chúng tôi áp dụng các head đặc thù phương thức trên các biểu diễn encoder để tạo ra các đầu ra cuối cùng cho tính toán mất mát và dự đoán. Đối với các mục tiêu phân loại, chúng tôi áp dụng một bộ phân loại tuyến tính đặc thù bộ dữ liệu cho các đầu ra được gộp trung bình. Đối với noise-contrastive estimation (NCE), chúng tôi tuân theo chặt chẽ kiến trúc CLIP, áp dụng các head feedforward riêng biệt cho mỗi phép chiếu phương thức-đến-không gian-chung.

3.4 Đào tạo Đa Độ phân giải
Một vấn đề lớn khi đào tạo Transformer trên dữ liệu video là hiệu quả tính toán và bộ nhớ thường bị cản trở do độ phức tạp bậc hai của Transformer như một hàm của độ dài đầu vào. Để chống lại điều này, chúng tôi đề xuất điều chỉnh kích thước batch hoặc độ phân giải để bù đắp các token thời gian bổ sung, do đó đạt được số lượng token đầu vào tương tự so với một hình ảnh tĩnh một khung hình. Chúng tôi đầu tiên cố định một tập token mỗi batch T=B×TF×TH×TW, được phân tích thành kích thước batch B, token khung hình TF, token chiều cao TH, và token chiều rộng TW đại diện cho mỗi video được patch hóa. Chúng tôi quan sát rằng chúng ta có thể phân tích thêm mỗi batch bằng cách đánh đổi các chiều khác nhau sao cho tổng số token đầu vào mỗi bước đại khái bằng nhau để việc sử dụng bộ nhớ đỉnh được bảo toàn. Ví dụ: chúng ta có thể giảm một nửa độ phân giải không gian trong khi tăng gấp bốn số khung hình. Điều này có thể tăng sự hội tụ đặc biệt ở đầu đào tạo, và cung cấp một encoding hiệu quả bộ nhớ hơn của mỗi mục tiêu. Hơn nữa, chúng tôi tận dụng DropToken [Akbari et al., 2021] như một phương pháp bổ sung để giảm token mỗi batch bằng cách ngẫu nhiên loại bỏ một tỷ lệ cố định token mỗi ví dụ. Chúng tôi nhận thấy rằng đối với TF token khung hình thời gian, chúng ta có thể ngẫu nhiên loại bỏ một tỷ lệ 1−1/TF token mỗi ví dụ để khớp với cùng token mỗi batch như hình ảnh. Đối với các mục tiêu nhất định, chúng tôi nhận thấy rằng một hỗn hợp khác nhau của các đánh đổi tối ưu hơn. Ví dụ: các mục tiêu tương phản ưa thích kích thước batch lớn, vì vậy chúng tôi giảm độ phân giải hoặc áp dụng DropToken để hiệu quả bộ nhớ hơn. Mặt khác, các mục tiêu phân loại không cần kích thước batch lớn như vậy để hội tụ tối ưu, do đó chúng tôi giảm kích thước batch trong khi tăng các token không gian thời gian.

4 Thí nghiệm và Kết quả

4.1 Thiết lập Đào tạo
Bộ dữ liệu. Các bộ dữ liệu của chúng tôi bao gồm một tập đa dạng các tín hiệu có thể học qua nhiều phương thức. Chúng tôi sử dụng WebLI [Chen et al., 2022], LAION-400M [Schuhmann et al., 2021], WIT [Srinivasan et al., 2021], CC12M [Changpinyo et al., 2021], và VCC [Nagrani et al., 2022] cho học tương phản thị giác-văn bản; JFT-3B [Zhai et al., 2022], I21K [Ridnik et al., 2021], và WTS-70M [Stroud et al., 2020] cho cả phân loại có giám sát và ước lượng tương phản thị giác-văn bản dựa trên nhãn (tương tự BASIC [Pham et al., 2021]); HT100M [Miech et al., 2019] và AudioSet [Gemmeke et al., 2017] cho mất mát tương phản triplet thị giác-âm thanh-văn bản (tương tự VATT [Akbari et al., 2021]).

Chúng tôi sử dụng một thuật toán sampling có trọng số tỷ lệ, thực hiện mỗi nhiệm vụ liên tiếp. Để đảm bảo rằng các bộ dữ liệu được sample đều, chúng tôi cân nhắc mỗi nhiệm vụ theo số lượng ví dụ, được chuẩn hóa thành một phân phối xác suất. Đối với mỗi biến thể bộ dữ liệu với kích thước độ phân giải khác nhau, chúng tôi áp dụng cùng trọng số. Để đánh giá công bằng trên các nhiệm vụ downstream, chúng tôi lọc tất cả các ví dụ gần-domain từ các bộ dữ liệu pretraining của chúng tôi (khoảng 5M ví dụ tổng cộng).

Chiến lược Đa Độ phân giải. Trong các thí nghiệm của chúng tôi, chúng tôi luôn cấu hình các tham số đầu vào sao cho số lượng token khung hình luôn bằng 4. Điều này sẽ dẫn đến token cơ sở mỗi batch video chính xác 4x của hình ảnh. Đối với các bộ dữ liệu video, chúng tôi xây dựng ba biến thể và sample đều từ mỗi biến thể trong quá trình đào tạo: i. Giảm độ phân giải một nửa trong mỗi chiều, ii. Giảm kích thước batch 4x, iii. Áp dụng DropToken d= 1−1/TF= 0.75. Đối với các bộ dữ liệu hình ảnh, chúng tôi cũng áp dụng một chiến lược tương tự nhưng cho mục đích học độ phân giải cao. Ngoài độ phân giải cơ sở, chúng tôi có hai biến thể bổ sung: i. Giảm kích thước batch 4x và tăng đôi mỗi chiều không gian, ii. Áp dụng DropToken d= 1−1/4= 0.75.

Tham số Đào tạo. Đối với các thí nghiệm cuối cùng của chúng tôi, chúng tôi đào tạo với kích thước patch 4x16x16 trên độ phân giải đầu vào cơ sở 16x256x256 và 4x256x256 trên các phương thức video và hình ảnh tương ứng, dẫn đến tổng cộng 1024 và 256 patch mỗi mẫu. Các đầu vào văn bản trong ImageNet21K và JFT được cắt ngắn thành 16 token để cải thiện hiệu quả bước mà không mất thông tin, trong khi giữ độ dài văn bản của phần còn lại của các bộ dữ liệu tối đa 256 token. Chúng tôi sử dụng kích thước batch cơ sở 65536 và đào tạo sử dụng optimizer Adam, learning rate đỉnh 1e-3 với lịch trình cosine, và không áp dụng weight decay. Đối với các tham số MoE, chúng tôi áp dụng routing experts-choose với capacity factor top-c 1.0 và không áp dụng bất kỳ jittering nào cho routing hoặc các mất mát phụ trợ khác. Đào tạo dẫn đến khoảng 16B ví dụ được thấy, hoặc khoảng 5T token. Được kết hợp lại, các bộ dữ liệu này đại diện cho khoảng 11B ví dụ hình ảnh-văn bản và video-âm thanh-văn bản duy nhất.

Trong quá trình suy luận, chúng tôi đánh giá trên độ phân giải lớn nhất có sẵn mà mô hình được đào tạo trên, tức là 16x512x512, và sử dụng tổng cộng 8 clip mỗi video ở khoảng 12.5 fps trên tất cả các bộ dữ liệu được đánh giá.

4.2 Kết quả Chính
Chúng tôi mở rộng và điều chỉnh IMP để có hiệu suất tốt nhất trên các bộ dữ liệu video và đánh giá nó trên nhiều nhiệm vụ và bộ dữ liệu downstream để hiểu cách nó tổng quát hóa cho các phương thức khác. Bảng 1 cho thấy khả năng phân loại zero-shot của mô hình trên một số bộ dữ liệu hình ảnh, video và âm thanh. Chúng tôi lưu ý rằng IMP vượt trội đáng kể so với state-of-the-art trước đó bất kể kích thước mô hình và thiết lập kỷ lục mới trên độ chính xác top-1 Kinetics [Kay et al., 2017, Carreira et al., 2018, 2019], UCF101 [Soomro et al., 2012], và HMDB-51 [Kuehne et al., 2011]. So với state-of-the-art trước đó, VideoCoCa [Yan et al., 2022], chúng tôi đào tạo IMP-MoE-L trên 256 chip TPU v4 trong 6 ngày, đại diện cho chỉ 15% tổng chi phí đào tạo của VideoCoCa. Xem xét tổng số tham số mỗi token (PPT), IMP cũng vượt trội so với mô hình state-of-the-art có thể so sánh trước đó, CoCa, trên ImageNet [Russakovsky et al., 2015] và CIFAR-100 với một biên độ tương đối lớn. Tuy nhiên, chúng tôi quan sát rằng mô hình tụt hậu so với state-of-the-art trong phân loại âm thanh zero-shot trên ESC-50 [Piczak, 2015]. Điều này có thể được giải thích bởi thực tế là tổng số ví dụ đào tạo cho phương thức âm thanh gần như không đáng kể so với hình ảnh và video. Do đó, mô hình có hiệu suất rất mạnh trên video và hình ảnh. Chúng tôi lập luận rằng điều này có thể được giải quyết bằng cách đơn giản là giới thiệu thêm mẫu và một phương pháp lập lịch đào tạo cân bằng hơn, mà chúng tôi hoãn lại cho các nghiên cứu tương lai.

4.3 Ablation
Trong phần này, chúng tôi làm nổi bật thử nghiệm với một số kết quả quan trọng thúc đẩy tập hợp các tính năng được chọn cho mô hình IMP cuối cùng của chúng tôi. Chúng tôi giới thiệu người đọc đến Phụ lục để có thêm ablation về một số khía cạnh khác của mô hình. Các thí nghiệm trong phần này sử dụng IMP-S hoặc IMP-B được đào tạo trong 250k bước với kích thước batch cơ sở 8192. Chúng tôi đặt độ phân giải video/hình ảnh cố định 16x224x224/4x224x224 sử dụng kích thước patch 4x16x16. Trừ khi được chỉ định khác, chúng tôi không áp dụng độ phân giải đa quy mô.

Các mục tiêu kết hợp có lợi lẫn nhau. Chúng tôi đào tạo mô hình trên ImageNet21k với hai mục tiêu: Noise-Contrastive Estimation (NCE) và Softmax Cross-Entropy (SCE) và khám phá những điều sau: i. đào tạo trên các mục tiêu riêng biệt, ii. kết hợp các mục tiêu bằng cách cộng chúng, và iii. luân phiên (AGD) giữa các mục tiêu ở mỗi bước. Trong trường hợp luân phiên, để so sánh công bằng để thời gian đào tạo tương đương, chúng tôi cố định cùng số bước (250k) sao cho mỗi mục tiêu chỉ tối ưu hóa 50% tổng số bước (125k). Chúng tôi đánh giá trên ImageNet1k và CIFAR-100 bằng truy xuất hình ảnh-đến-văn bản và linear probing trên các tính năng đông cứng của mô hình và báo cáo kết quả trong Bảng 2. Không có gì ngạc nhiên khi mục tiêu phân loại có lợi nhất cho đánh giá fine-tuning, trong khi mục tiêu tương phản có lợi cho phân loại từ vựng mở. Tuy nhiên, chúng tôi quan sát rằng việc kết hợp cả hai mục tiêu tốt hơn so với tối ưu hóa chúng riêng lẻ. Và luân phiên giữa các mục tiêu tốt hơn so với việc trộn mục tiêu không-AGD. Những kết quả này tương tự với các phát hiện của PolyViT [Likhosherstov et al., 2021], báo cáo hiệu suất tối ưu khi luân phiên các mục tiêu, được cân nhắc theo kích thước của mỗi bộ dữ liệu. Điều này thúc đẩy chúng tôi cố định một mục tiêu mỗi bước đào tạo và luân phiên tối ưu hóa giữa chúng.

AGD đa nhiệm vụ đa bộ dữ liệu cũng có lợi lẫn nhau. Trong Hình 2, chúng tôi so sánh kết quả của việc thêm các bộ dữ liệu bổ sung vào hỗn hợp pretraining. Chúng tôi bổ sung so sánh kết quả qua các bộ dữ liệu Flickr30k [Young et al., 2014] và COCO [Lin et al., 2014]. Chúng tôi bắt đầu với bộ dữ liệu CC12M và dần dần thêm các bộ dữ liệu và mục tiêu mới. Đáng chú ý nhất, chúng tôi so sánh việc bổ sung bộ dữ liệu I21K, cho thấy cải thiện bổ sung khi kết hợp các mục tiêu NCE và SCE. Tương tự như các thí nghiệm I21K cô lập, việc thêm SCE có lợi cho toàn bộ hỗn hợp pretraining. Trong khi SCE có lợi cho kết quả zero-shot, NCE cũng có lợi cho kết quả linear probing. Một số kết hợp bộ dữ liệu (CC+I21K, CC+LAION) gây bất ổn ở đầu đào tạo. Việc thêm một mục tiêu phân loại có hiệu ứng ổn định, giảm đáng kể khả năng hội tụ chậm. Tối ưu hóa trực tiếp trên LAION khó khăn, nhưng có lợi nhiều hơn cho đào tạo khi trộn với các bộ dữ liệu khác. Điều này thúc đẩy chúng tôi tích hợp thêm một tập lớn hơn các bộ dữ liệu và mục tiêu đa dạng.

Độ phân giải đa quy mô cung cấp cải thiện phổ quát. Hình 3 cho thấy so sánh việc sử dụng các kết hợp khác nhau của độ phân giải, kích thước batch và DropToken làm đầu vào. Trong tất cả các thiết lập, chúng tôi cố định tổng token mỗi batch, và chúng tôi đảm bảo rằng tất cả các lần chạy đào tạo sử dụng cùng số bước tổng cộng. Chúng tôi thấy rằng một số loại bộ dữ liệu phản ứng tốt với DropToken trong khi những loại khác có thể không. CC với kích thước batch gấp đôi và DropToken 0.5 cải thiện phân loại hình ảnh zero-shot. Droptoken + hình ảnh 320x320 trên pretraining I21K SCE tốt hơn cho linear probing và truy xuất hình ảnh-văn bản. Việc thêm nhiều phiên bản của kích thước batch nhỏ hơn + độ phân giải cao hơn, DropToken + độ phân giải cao hơn, kích thước batch lớn hơn + độ phân giải thấp hơn, có thể cải thiện đáng kể kết quả downstream. Chúng tôi nhận thấy rằng các hỗn hợp động của độ phân giải, kích thước batch và DropToken luôn hữu ích.

MoE cung cấp cải thiện phổ quát qua các phương thức, và giải quyết bottleneck tham số encoder tower đơn. Thách thức chính trong việc thiết kế một encoder tower thống nhất như chúng tôi đã mô tả là các tham số phải được chia giữa nhiều phương thức, do đó làm hại độ chính xác. So với một mô hình tương phản hai tower, encoder của một mô hình hình ảnh-văn bản thống nhất chứa một nửa số tham số, trong khi giữ hiệu quả đào tạo như cũ. Một hướng chúng tôi khám phá là liệu việc tăng lớn tham số từ MoE có đủ để giải quyết bottleneck tham số hay không. Trong Hình 4, chúng tôi quan sát rằng chỉ đơn giản thay thế một mô hình dense với một mô hình MoE tương đương với chỉ 4 chuyên gia, chúng ta có thể cung cấp một lợi ích lớn về độ chính xác, đặc biệt cho các metrics zero-shot. Điều này cung cấp một dấu hiệu hứa hẹn rằng MoE có thể được sử dụng để thu hẹp khoảng cách đa phương thức. Chúng tôi quan sát rằng với việc bổ sung MoE, chúng ta có thể thu hẹp đáng kể khoảng cách giữa nhiều phương thức như được thấy trong Hình 5. Vì các chuyên gia tự do chọn token nào được phân bổ cho các chuyên gia khác nhau, chúng tôi quan sát sự alignment mạnh mẽ giữa các chuyên gia và phương thức.

MoE tower đơn vượt trội so với các biến thể dense multi-tower. Chúng tôi nhận thấy rằng trong tất cả các biến thể chúng tôi đã thử nghiệm, một encoder MoE thống nhất cung cấp thiết kế hiệu quả tham số và tính toán nhất, trong khi vượt trội đáng kể so với một mô hình đặc thù phương thức multi-encoder trong kết quả downstream, như được thấy trong Hình 6. Khi so sánh các mô hình hai tower, chúng ta có thể chia các tham số để có kích thước đại khái bằng nhau với một tower đơn, hoặc nhân đôi các tower để tăng đôi số lượng tham số trong khi cung cấp tính toán tương đương. Chúng tôi quan sát rằng các mô hình dense multi-tower hiệu quả tính toán hơn so với các mô hình dense tower đơn, nhưng ít hiệu quả tham số hơn. Tuy nhiên, một mô hình MoE tower đơn vừa hiệu quả tính toán và tham số hơn so với tất cả các biến thể, cho thấy tổng quát hóa được cải thiện và sử dụng ít tham số hơn với cùng ngân sách tính toán như một mô hình dense multi-tower. Những kết quả này cho thấy hiệu quả tham số và tính toán phổ quát vượt trội và độ chính xác cao hơn bằng cách chỉ sử dụng 4 chuyên gia. Quan sát này cho thấy rằng phương pháp của chúng tôi có thể được sử dụng cho mô hình hóa đa nhiệm vụ đa phương thức tích hợp mà không phải lo lắng về các phức tạp của các lựa chọn thiết kế đặc thù phương thức hoặc sự suy giảm hiệu suất downstream như được quan sát trong các thiết kế agnostic phương thức trước đó [Akbari et al., 2021].

5 Kết luận
Trong bài báo này, chúng tôi đã trình bày một phương pháp đào tạo và mô hình hóa tích hợp cho nhận thức đa phương thức sử dụng AGD và MoE. Chúng tôi quan sát rằng AGD cho phép khả năng mở rộng nhiệm vụ và đào tạo đa độ phân giải, cải thiện sự hội tụ đào tạo và khả năng tổng quát hóa của mô hình. Mặt khác, chúng tôi nhận thấy rằng MoE có thể đóng một vai trò rất quan trọng trong việc tích hợp nhiều phương thức vào một mô hình thống nhất. Với những phát hiện này, chúng tôi đã mở rộng mô hình với các hyperparameter được điều chỉnh đặc biệt cho hiểu video và đạt được hiệu suất state-of-the-art trong nhận dạng hành động video zero-shot với một biên độ đáng kể. Hơn nữa, chúng tôi quan sát rằng mô hình cũng tổng quát hóa trên các phương thức khác và đạt được kết quả downstream cạnh tranh. Tóm lại, IMP mở ra một cánh cửa cho khả năng mở rộng dữ liệu (ví dụ: phương thức, độ phân giải, v.v.) và nhiệm vụ — hai hướng quan trọng đã bị bỏ qua trong nhiều công trình hiểu đa phương thức do những hạn chế kỹ thuật vốn có. Do phạm vi rộng lớn của các yếu tố liên quan đến hệ thống này, chúng tôi hoãn nhiều hướng để khám phá trong công việc tương lai: 1. các mục tiêu và kiến trúc mô hình generative, 2. MoE nhân quả cho generation, 3. các phương pháp tinh vi cho sampling dữ liệu-mục tiêu, 4. thêm đánh giá downstream.

Lời cảm ơn và Tiết lộ Nguồn tài trợ
Chúng tôi muốn cảm ơn Joan Puigcerver, Carlos Riquelme, và Basil Mustafa vì lời khuyên của họ về triển khai và phân tích MoE; Anselm Levskaya vì sự giúp đỡ của anh ấy với triển khai JAX và Flax cốt lõi nâng cao; nhóm T5X vì sự hỗ trợ của họ cho phân vùng mô hình có thể mở rộng, và Erica Moreira và Victor Gomez vì sự giúp đỡ của họ với phân bổ tài nguyên.

# 2309.13600.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2309.13600.pdf
# Kích thước tệp: 18163645 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Multi-Dimensional Hyena cho Thiên Hướng Quy Nạp Không Gian
Itamar Zimerman, Lior Wolf
Trường Khoa học Máy tính Blavatnik, Đại học Tel Aviv
zimerman1@mail.tau.ac.il, wolf@mail.tau.ac.il

Tóm tắt
Trong những năm gần đây, Vision Transformers đã thu hút sự quan tâm ngày càng tăng từ các nhà nghiên cứu thị giác máy tính. Tuy nhiên, lợi thế của những transformers này so với CNNs chỉ thể hiện đầy đủ khi được huấn luyện trên tập dữ liệu lớn, chủ yếu do thiên hướng quy nạp giảm đối với tính cục bộ không gian trong cơ chế tự chú ý của transformer. Trong công trình này, chúng tôi trình bày một vision transformer tiết kiệm dữ liệu không dựa vào tự chú ý. Thay vào đó, nó sử dụng một tổng quát hóa mới lạ thành nhiều trục của lớp Hyena rất gần đây. Chúng tôi đề xuất một số phương pháp thay thế để có được tổng quát hóa này và đi sâu vào những điểm khác biệt và cân nhắc độc đáo của chúng từ cả góc độ thực nghiệm và lý thuyết.

Các phát hiện thực nghiệm của chúng tôi cho thấy lớp Hyena N-D được đề xuất tăng cường hiệu suất của các kiến trúc Vision Transformer khác nhau, như ViT, Swin, và DeiT trên nhiều tập dữ liệu. Hơn nữa, trong chế độ tập dữ liệu nhỏ, ViT dựa trên Hyena của chúng tôi có lợi thế hơn các biến thể ViT từ tài liệu gần đây được thiết kế đặc biệt để giải quyết cùng một thách thức, tức là làm việc với tập dữ liệu nhỏ hoặc kết hợp thiên hướng quy nạp đặc thù của hình ảnh vào cơ chế tự chú ý. Cuối cùng, chúng tôi chỉ ra rằng một phương pháp kết hợp dựa trên Hyena N-D cho các lớp đầu tiên trong ViT, tiếp theo là các lớp kết hợp chú ý thông thường, liên tục tăng cường hiệu suất của các kiến trúc vision transformer khác nhau.

1 Giới thiệu
Tạo ra một lớp đa năng được thiết kế để xử lý hiệu quả dữ liệu N-chiều trong các mạng sâu là một hướng nghiên cứu quan trọng, có ý nghĩa đáng kể cho các lĩnh vực ứng dụng chính, như thị giác máy tính và xử lý giọng nói. Điều bắt buộc là lớp như vậy không chỉ thể hiện thiên hướng quy nạp mạnh đối với dữ liệu N-chiều, mà còn giữ lại khả năng cần thiết để khai thác các tập dữ liệu rộng lớn. Hiện tại, hai loại lớp chính thống trị các lĩnh vực dữ liệu N-chiều: transformers (Vaswani et al. 2017) và CNNs (He et al. 2016; Liu et al. 2022a).

CNNs tiêu chuẩn sử dụng các bộ lọc tương đối nhỏ (He et al. 2016; LeCun et al. 1989, 1998a), đòi hỏi thiên hướng quy nạp cao, đặc biệt cho tính cục bộ N-D. Tuy nhiên, chúng kém hiệu quả và kém hiệu quả hơn trong việc xử lý ngữ cảnh dài. Ngược lại, transformers thể hiện thiên hướng quy nạp thấp hơn (Ma et al. 2022), nhưng khi được huấn luyện trên đủ dữ liệu, chúng có vẻ xử lý dữ liệu N-D hiệu quả, bằng cách xử lý nó như một chuỗi 1-D với mã hóa vị trí tương ứng (Dosovitskiy et al. 2020; Arnab et al. 2021; Liu et al. 2022b).

Một lợi thế mà transformers có so với CNNs là khả năng xử lý độ dài dữ liệu thay đổi và cung cấp ngữ cảnh toàn cục ở cấp độ lớp (Vaswani et al. 2017). Tuy nhiên, độ phức tạp bậc hai của chúng theo độ dài chuỗi tạo ra những trở ngại trong việc xử lý ngữ cảnh dài, vốn rất quan trọng cho nhiều nhiệm vụ.

Công trình này nhằm kết hợp điểm mạnh tương đối của cả CNN và transformers bằng cách phát triển một lớp mới có: (i) thiên hướng quy nạp đối với dữ liệu N-chiều, (ii) khả năng biểu đạt đủ, (iii) phụ thuộc dưới bậc hai vào độ dài chuỗi, và (iv) tính linh hoạt trong xử lý dữ liệu N-chiều với bất kỳ độ dài N-D nào, trong khi duy trì ngữ cảnh toàn cục ở cấp độ lớp.

Làm nền tảng cho lớp mới này, chúng tôi sử dụng phép tích chập dài đa trục, một họ lớp gần đây được chứng minh hiệu quả cho dữ liệu N-chiều (Nguyen et al. 2022; Baron, Zimerman, and Wolf 2023). Những lớp này sử dụng phép tích chập của tín hiệu với bộ lọc ẩn đa trục. Không giống như các lớp trước đó trong lĩnh vực này, các bộ lọc ẩn của chúng tôi không được neo trong sự lặp lại tuyến tính (tương tự như các lớp không gian trạng thái (Gu et al. 2021; Gu, Goel, and Ré 2021)). Thay vào đó, chúng tôi mở rộng lớp Hyena rất gần đây (Poli et al. 2023) để phù hợp với dữ liệu N-D. Như phân tích lý thuyết của chúng tôi tiết lộ, điều này dẫn đến một mô hình đơn giản hơn, biểu đạt hơn và hiệu quả hơn.

Đóng góp chính của chúng tôi là lớp Hyena N-D, tổng quát hóa lớp Hyena gần đây thành dữ liệu đa chiều. Chúng tôi biện minh cho các lựa chọn thiết kế một cách rộng rãi, bằng cách xem xét thực nghiệm và lý thuyết một số tham số hóa, một số cấu trúc phân rã để kết hợp thiên hướng của tính cục bộ hai chiều, và biến thể đa hướng đầu tiên của Hyena, có tính toán bổ sung không đáng kể. Hơn nữa, chúng tôi là những người đầu tiên đặc trưng hóa lý thuyết một dạng thiên hướng quy nạp vốn có trong họ lớp Hyena.

Như một ứng dụng trực tiếp, chúng tôi chứng minh rằng lớp của chúng tôi có thể được sử dụng như một thay thế trực tiếp trong xương sống ViT để tạo ra một mô hình hiệu quả hơn nhiều về dữ liệu và bộ nhớ. Chúng tôi cũng đề xuất một mô hình kết hợp kết hợp các lớp chú ý và Hyena 2-D trong ViT, cải thiện hiệu suất hơn nữa.

2 Bối cảnh và Ký hiệu
Lớp Tích chập Toàn cục Ẩn Tích chập tiêu chuẩn là một khối xây dựng cơ bản của deep learning (Fukushima 1980; LeCun et al. 1998b; Ronneberger, Fischer, and Brox 2015). Những lớp này tham số hóa một bộ lọc tích chập với kích thước L và C kênh với L*C tham số, trong đó mỗi phần tử được định nghĩa rõ ràng. Ngược lại, một phương pháp mới nổi định nghĩa ẩn kernel tích chập thông qua một hàm có thể học. Cụ thể, kernel kh_i(filter) tại vị trí i và kênh h được định nghĩa bởi một hàm fh sao cho fh(i) = ki. Những phương pháp này có ba lợi thế chính: (i) Những lớp này có thể hoạt động trên ngữ cảnh không hạn chế, trái ngược với các bộ lọc rõ ràng có kích thước cố định. (ii) Các lớp có phụ thuộc thời gian dưới bậc hai vào độ dài chuỗi, và (iii) Vì số lượng tham số được tách rời khỏi độ dài chuỗi, những kernel này được chính quy hóa theo thiết kế, điều này dường như cần thiết cho hiệu quả của chúng (Li et al. 2022; Fu et al. 2023).

S4 (Gu, Goel, and Ré 2021) và các lớp không gian trạng thái (Gu et al. 2021) là những người tiên phong chỉ ra hiệu quả của phương pháp này, bằng cách tham số hóa kernel tích chập thông qua mô hình không gian trạng thái tuyến tính (SSM), sau đó được đơn giản hóa bằng cách sử dụng SSM đường chéo và thực (Gupta, Gu, and Berant 2022; Gupta, Mehta, and Berant 2022). Các phương pháp tương tự bởi Ma et al. (2022); Lutati, Zimerman, and Wolf (2023), sử dụng các thành phần có thể học, bao gồm bộ lọc EMA và IIR, thay vì SSM để công thức hóa tham số hóa. Như một lựa chọn thay thế, Hyena và CkConv (Romero et al. 2021) thiết lập tham số hóa bằng cách áp dụng các lớp mạng neural feedforward (FFN) tiêu chuẩn hoạt động trên mã hóa vị trí. Những phương pháp này cung cấp hiệu suất vượt trội trong một số lĩnh vực, như NLP (Mehta et al. 2022; Wang et al. 2022; Dao et al. 2022), giọng nói (Saon, Gupta, and Cui 2023), RL (Lu et al. 2023; David et al. 2022), phân tích chuỗi thời gian, và nhiều hơn nữa, đặc biệt trong các nhiệm vụ yêu cầu nắm bắt phụ thuộc tầm xa.

Tích chập toàn cục ẩn N-D Gần đây, phương pháp này mở rộng thành dữ liệu đa chiều, sử dụng tham số hóa ẩn cho bộ lọc N-chiều, được chỉ ra là một phương pháp hiệu quả cho các nhiệm vụ thị giác máy tính (Nguyen et al. 2022; Baron, Zimerman, and Wolf 2023). S4ND (Nguyen et al. 2022) là đầu tiên trình bày hiệu quả của phương pháp như vậy. Nó tham số hóa bộ lọc N-D bằng cách kết hợp các bộ lọc dựa trên SSM độc lập mỗi trục, và trong đường truyền tiến, các bộ lọc được tổng hợp để tạo ra một bộ lọc toàn cục N-D, bằng cách lấy tích ngoài của các bộ lọc mỗi trục. Phương pháp này rất hiệu quả. Tuy nhiên, trong (Baron, Zimerman, and Wolf 2023) đã chỉ ra rằng phương pháp học kernel riêng biệt mỗi trục có thể bị hạn chế về mặt khả năng biểu đạt, điều này khiến việc tận dụng nó với các cơ chế biểu đạt hơn trở nên khuyến khích. Trong ánh sáng này, lớp của chúng tôi là đầu tiên xây dựng bộ lọc ẩn N-D mà không dựa vào hệ thống SSM.

Hyena Lớp Hyena tham số hóa bộ lọc vô hướng ẩn có kích thước L mỗi kênh c∈[C] bởi Hc:= hc1,·, hcL bằng cách sử dụng FFN FFNc: Rd→R trên mã hóa vị trí pe(l)∈Rd sao cho ∀l∈[L]: hcl=FFNc(PE(l)). Cơ chế này có thể tạo ra kernel với bất kỳ kích thước nào, cho phép lớp xử lý ngữ cảnh không hạn chế. Lấy cảm hứng từ chú ý, Hyena thực hiện một toán tử tuyến tính biểu đạt được điều khiển bởi dữ liệu, dựa vào việc xen kẽ các tích chập dài ẩn với phép nhân theo phần tử. Về mặt hiệu suất, lớp Hyena giới thiệu hiệu suất đặc biệt, đạt chất lượng transformer với mô hình hiệu quả hơn, và với độ phức tạp dưới bậc hai theo độ dài chuỗi.

Để thêm thiên hướng quy nạp đối với tính cục bộ 1-chiều, lớp Hyena nhân các bộ lọc được tạo ra từ FFN với một hàm cửa sổ. Hàm này được biểu thị như sau:
window(t) = exp(−αt) + γ (1)

Vision Transformers Vision Transformer (ViT) (Dosovitskiy et al. 2020) là một kiến trúc mô hình dựa trên chú ý cho các nhiệm vụ thị giác máy tính. Trái ngược với Mạng Neural Tích chập thông thường (CNNs) sử dụng tương quan cục bộ thông qua bộ lọc tích chập, ViT định hình lại một hình ảnh thành một chuỗi 1-D của các patch có kích thước cố định, được xử lý bởi một chồng các lớp encoder transformer. Vì transformers là bất biến hoán vị, mã hóa vị trí được kết hợp. Cơ chế tự chú ý trong transformer cho phép mỗi patch được xem xét liên quan đến tất cả các patch khác, từ đó tạo điều kiện cho việc học cả phụ thuộc cục bộ và tầm xa trong hình ảnh. Đầu ra từ transformer là một chuỗi các patch được nhúng, với một token phân loại cụ thể được sử dụng cho các nhiệm vụ phân loại, tương tự như BERT (Devlin et al. 2018). Trong ViT, kiến trúc không áp đặt bất kỳ thiên hướng tính cục bộ không gian rõ ràng nào, dẫn đến một mô hình linh hoạt có thể - với đủ lượng dữ liệu huấn luyện - nắm bắt các phụ thuộc phức tạp trên toàn bộ hình ảnh.

Qua nhiều năm, mô hình ViT đã có nhiều cải tiến. Ví dụ, DeiT (Touvron et al. 2021) tối ưu hóa hiệu suất thông qua tăng cường dữ liệu, chưng cất dựa trên token, và chính quy hóa, từ đó đạt được kết quả benchmark mạnh mẽ ngay cả với ít dữ liệu hơn. Swin Transformer (Liu et al. 2021) giới thiệu một mô hình với nhiều thiên hướng quy nạp không gian hơn, thích ứng với cấu trúc phân cấp bằng cách phân chia hình ảnh thành các cửa sổ không chồng lấp và sau đó xử lý chúng theo cấu trúc phân cấp. Hơn nữa, (Dai et al. 2021; Guo et al. 2022; d'Ascoli et al. 2021) tăng cường hiệu quả của ViT bằng cách tích hợp các lớp tích chập vào kiến trúc ViT. Ngoài ra, các phương pháp như (Xie et al. 2021; Carion et al. 2020; Chen et al. 2022) đã giới thiệu các sửa đổi cụ thể cho ViT, cho phép nó xuất sắc trong các nhiệm vụ phát hiện và phân đoạn ngữ nghĩa.

Ký hiệu Ký hiệu của chúng tôi tuân theo tài liệu Hyena càng gần càng tốt (Poli et al. 2023; Nguyen et al. 2023). Cụ thể, chúng tôi ký hiệu số lượng kênh bằng C, và bộ lọc trên kênh c∈[C] bằng Hc. Chúng tôi ký hiệu số lượng chiều bằng N, và độ dài chuỗi tại bất kỳ chiều nào bằng Ln cho n∈[N], L:= ΠN n=1 Ln là tổng độ dài chuỗi, Lmax:= maxN n=1 Ln là độ dài chuỗi tối đa, và Ň là độ sâu của sự lặp lại Hyena. Đối với các ký hiệu của kiến trúc Hyena, chúng tôi ký hiệu mạng FFN bằng FFN: RM→R(Ň+1)C, hàm mã hóa vị trí bằng (PE): R→RM, trong đó M là kích thước của lớp đầu vào FFN. Cuối cùng, chúng tôi ký hiệu hàm cửa sổ bằng window: R→R.

3 Phương pháp
Động lực Một nhược điểm nổi tiếng của tự chú ý là thiên hướng quy nạp tương đối yếu. Điều này thậm chí còn phù hợp hơn khi xử lý dữ liệu hai chiều. Để thiết kế một ViT tiết kiệm dữ liệu, chúng tôi chọn không kết hợp thiên hướng quy nạp 2-D vào cơ chế tự chú ý trong ViT (như đã làm trong (Liu et al. 2021; Xu et al. 2021)), và thay vào đó sử dụng một lớp chuỗi thay thế trong engine ViT. Gần đây, một số lớp chuỗi mới đã cho kết quả ấn tượng trong mô hình hóa chuỗi 1-D, đặc biệt là trong việc cải thiện độ phức tạp (Peng et al. 2023; Poli et al. 2023; Dao et al. 2022). Điều này thúc đẩy chúng tôi khám phá tiện ích của những lớp như vậy như một thay thế trực tiếp cho ViT.

Trong số những lớp đó, chúng tôi tập trung vào lớp Hyena (Poli et al. 2023) vì hai lý do chính: (i) Nó được xây dựng trên các cơ chế đơn giản, như cổng nhân theo phần tử và bộ lọc toàn cục ẩn. Do đó, nó cung cấp một cấu trúc linh hoạt có thể được sửa đổi để kết hợp thiên hướng quy nạp đặc thù của hình ảnh. (ii) Cho rằng các lớp tích chập truyền thống được biết đến với thiên hướng quy nạp đáng kể trong các nhiệm vụ thị giác, có lý khi giả định rằng các lớp tích chập toàn cục ẩn là một phần của Hyena sẽ có khả năng tương tự. Trong ánh sáng này, công việc của chúng tôi có thể được coi là một bước tiến xa hơn hướng tới việc kết hợp các lớp tích chập và ViT. Trái ngược với công việc trước đó (Dai et al. 2021; Guo et al. 2022; d'Ascoli et al. 2021), chúng tôi sử dụng các lớp tích chập toàn cục ẩn, thay vì các lớp tích chập tiêu chuẩn, không tập trung độc quyền vào các phụ thuộc tầm ngắn. Hơn nữa, vì lớp Hyena có phụ thuộc dưới bậc hai vào độ dài chuỗi, nó có thể dẫn đến một ViT hiệu quả hơn đáng kể. Điều này đặc biệt có giá trị cho các nhiệm vụ liên quan đến xử lý hình ảnh độ phân giải cao, như hình ảnh y tế.

Lớp Hyena-ND Lớp Hyena bao gồm ba thành phần chính: (i) bộ lọc toàn cục ẩn (ii) cơ chế điều khiển dữ liệu dưới dạng cổng (phép nhân theo phần tử), và (iii) một bộ lọc ngắn được thực hiện bởi một lớp tích chập 1-D. Khả năng mở rộng của hai thành phần cuối để phù hợp với dữ liệu đa chiều là đơn giản, vì thành phần thứ hai là bất khả tri chiều, và việc mở rộng (iii) để xử lý dữ liệu đa chiều có thể được thực hiện một cách đơn giản, thông qua một lớp tích chập 2-D tiêu chuẩn. Do đó, đóng góp chính của chúng tôi trong việc giới thiệu lớp Hyena N-D là việc tạo ra các bộ lọc ẩn N-D, có thể được sử dụng cho tích chập N-D. Trong hai phần sau, chúng tôi liệt kê hai chiến lược thay thế cho việc xây dựng những bộ lọc này, và minh họa chúng trong Hình 1. Để đơn giản, mặc dù công thức Hyena N-D có thể tự nhiên tương ứng với N chiều, chúng tôi giả định N = 2.

Sử dụng N-Dimensional Hyena như một Thành phần Cách đơn giản nhất sử dụng nhiều bộ lọc 1-D độc lập, tương tự như S4ND (Nguyen et al. 2022). Để có được một bộ lọc N-D cho mỗi kênh, một bộ lọc 1-D Hn:= (hn1, hn2, ..., hnLn) có độ dài Ln được học độc lập cho mỗi trục n∈[N]. Sau đó, N bộ lọc 1-D được kết hợp để tạo thành một bộ lọc N-D toàn cục duy nhất thông qua phép toán tích ngoài mỗi kênh:
H = H1 ⊗ H2 ⊗ ... HN

Một nhược điểm đáng chú ý của phương pháp này là việc tham số hóa mỗi chiều độc lập là không tự nhiên đối với một số phương thức, ví dụ hình ảnh, và có thể dẫn đến thiên hướng quy nạp kém. Chúng tôi ký hiệu lớp này là Hyena N-D product.

Sử dụng Bộ lọc Hyena N-Dimensional Ẩn Trái ngược với phương pháp trước đó để tổng quát hóa Hyena thành dữ liệu N-chiều, phương pháp này cố gắng giữ tinh thần của Hyena nguyên bản trong thiết kế bộ lọc ẩn N-D thay vì xây dựng một lớp N-chiều trên đỉnh của lớp Hyena 1-D. Để làm như vậy, các bộ lọc ẩn N-D và cửa sổ N-D được định nghĩa.

Bộ lọc Ẩn N-D Các bộ lọc ẩn của Hyena thông thường (tức là, 1-D) được định nghĩa bởi:
ht = window(t) · FFN(PE(t)) (2)

trong đó hàm cửa sổ được mô tả trong Eq. 1 và FFN ký hiệu một mạng feedforward đơn giản. Một mở rộng đơn giản của Eq. 2 thành bộ lọc đa chiều với N chiều n1, n2, ···, nN, có thể được mô tả bởi:
Hi1,i2,...,iN = window(i1, i2, ..., iN)FFN(PE(i1, i2, ..., iN)) (3)

Cửa sổ N-D Cửa sổ Hyena 1-D được định nghĩa bởi
window(t) = exp(−αt) + γ (4)

trong đó t là dấu thời gian, α là tham số phân rã và γ là số hạng thiên hướng. Hai hàm cửa sổ sau được xem xét cho trường hợp 2-D:
window_symmetric(i, j) = exp(−α(i+j)) + γ (5)
window_dimensional(i, j) = exp(−αi+βj) + γ (6)

Trong Hyena 1-D, tham số α thay đổi để điều chỉnh độ dài bộ lọc hiệu quả trên các kênh riêng biệt. Điều này được thực hiện bằng cách tạo ra một chuỗi các giá trị α cách đều không thể học. Đối với trường hợp 2-D, chúng tôi sửa đổi α và β trên các kênh riêng biệt và xáo trộn chúng ngẫu nhiên để có được một tập hợp các cửa sổ đa dạng. Chúng tôi đã phân tích hai hàm cửa sổ, cũng như quyết định làm cho α, β và γ là hằng số trong Tab 5. Chúng tôi cũng loại bỏ đóng góp thực nghiệm của cơ chế cửa sổ bằng cách bỏ qua nó hoàn toàn.

4 Mở rộng Mô hình
Lớp Đa Hướng Vì lớp Hyena là nguyên nhân, các phần tử dữ liệu trước đó sẽ không bị ảnh hưởng bởi những phần tử tiếp theo. Trong khi thuộc tính này rất cần thiết cho mô hình hóa ngôn ngữ, nó rất không tự nhiên đối với các nhiệm vụ thị giác máy tính, vì nó hạn chế khả năng của mô hình và mâu thuẫn với các nguyên tắc ViT. Để giải quyết hạn chế này, chúng tôi giới thiệu một mở rộng đa hướng cho lớp của chúng tôi. Hai phiên bản sau được khám phá: (a) một phiên bản 4-hướng, trong đó trước mỗi lớp, đầu vào được chiếu thành 4 biểu diễn riêng biệt, sau đó mỗi biểu diễn được xoay. Đối với bất kỳ biểu diễn nào, lớp Hyena được áp dụng, và sau đó một lớp tuyến tính theo kênh tổng hợp 4 tín hiệu. (b) một phiên bản 2-hướng, trong đó một phép xoay được áp dụng giữa các bước lặp lại Hyena, hoặc giữa các lớp Hyena cho bậc 2. Những chiến lược này được so sánh thực nghiệm trong Tab 4.

Kết hợp với Chú ý Mặc dù phân tích thực nghiệm trong Sec. 6 chứng minh rằng khi xử lý các tập dữ liệu nhỏ hơn, Hyena 2-D vượt trội so với chú ý như lớp cốt lõi của ViT, không rõ liệu chú ý có thể được sử dụng để tăng cường hiệu suất của mô hình hơn nữa hay không. Có lẽ, Hyena 2D cung cấp những lợi ích riêng biệt khác với những lợi ích của mô hình chú ý và cả hai có thể được kết hợp một cách cộng hưởng để tạo ra một mô hình kết hợp tốt hơn.

Để đi sâu hơn vào khía cạnh này, chúng tôi đề xuất hai chiến lược chính để tích hợp những lớp đó: (i) Xen kẽ: Trong phương pháp này, đối với mỗi cặp lớp tự chú ý trong xương sống ViT, chúng tôi thay thế lớp đầu tiên bằng Hyena 2-D. Phương pháp này có thể được diễn giải như việc sử dụng Hyena 2-D để thêm thiên hướng quy nạp vào cơ chế chú ý, tương tự như (Ma et al. 2022; Baron, Zimerman, and Wolf 2023). (ii) Hyena Đầu tiên: Sử dụng Hyena 2-D cho nửa đầu của các lớp, và chú ý cho phần còn lại. Động lực để sử dụng Hyena đầu tiên là thiên hướng quy nạp đặc thù của hình ảnh quan trọng hơn ở các lớp thấp hơn của kiến trúc, trong khi các lớp trên cùng tích hợp thông tin từ toàn bộ hình ảnh.

Sec. 6.1 phân tích những phương pháp này một cách thực nghiệm. Để hiểu rõ hơn về tiềm năng của phương pháp Hyena-First, chúng tôi đã thử một phiên bản tương tự sử dụng tự chú ý cho các lớp đầu tiên, được ký hiệu là Attention First. Chúng tôi thấy rằng phương pháp Hyena First vượt trội so với những phương pháp khác. Chúng tôi cũng quan sát thấy rằng phương pháp Alternate vượt trội so với các mô hình không chú ý, điều này chứng minh rằng các lớp là bổ sung. Quan sát này có khả năng có thể tăng cường hiệu suất ngay cả trong các mô hình lớn hơn hoặc tập dữ liệu lớn hơn.

5 Phân tích Mô hình
5.1 Độ phức tạp
Đường truyền tiến Hyena bao gồm ba bước: (i) xây dựng bộ lọc ẩn, (ii) Áp dụng tích chập N-D, và (iii) tính toán các phép chiếu đầu vào và đầu ra, trong đó độ phức tạp của bước cuối cùng là tối thiểu.

Dưới giả định rằng kích thước FFN ẩn nhỏ hơn số lượng kênh (M ≤ C), độ phức tạp thời gian và không gian của việc tạo bộ lọc ẩn trong Hyena 1-D, Hyena N-D và Hyena N-D product là LCM. Đối với tất cả các biến thể Hyena, việc tính toán của kernel không phụ thuộc vào kích thước batch B, làm cho nó hiệu quả hơn cho các batch lớn.

Tiếp theo, chúng tôi áp dụng một tích chập N-chiều giữa kernel và đầu vào. Vì tích chập có thể được tính toán hiệu quả với FFT, tổng độ phức tạp thời gian là O(BCL log(L)) cho bất kỳ chiều N nào, và tổng độ phức tạp không gian là O(BLC). Như có thể thấy, độ phức tạp tích chập chi phối độ phức tạp tổng thể cho các batch lớn. Một phân tích thực nghiệm về lợi thế này trong độ phức tạp không gian tuyến tính được đưa ra trong 6.3.

5.2 Khả năng biểu đạt và thiên hướng quy nạp
Tiếp theo chúng tôi đặc trưng hóa khả năng biểu đạt của các biến thể lớp Hyena N-D, bắt đầu bằng việc giới thiệu một phân tích lý thuyết về khả năng biểu đạt của các lớp Hyena N-D và sau đó so sánh nó với các phương pháp khác để tạo bộ lọc ẩn N-D.

Giả định Trong phần này, mọi định lý giả định rằng mạng FFN sử dụng kích hoạt dấu và M > 1. Hơn nữa, để đơn giản, cả mã hóa vị trí và hàm cửa sổ đều được coi là hàm đồng nhất.

Hạng tensor như một tiêu chí cho khả năng biểu đạt Chúng tôi bắt đầu bằng việc giới thiệu tiêu chí của chúng tôi để đo lường khả năng biểu đạt của lớp Hyena N-D. Được truyền cảm hứng bởi Cohen, Sharir, and Shashua (2016), sử dụng hạng tensor như một tiêu chí cho khả năng biểu đạt, chúng tôi áp dụng hạng tensor cho các kernel N-D được xây dựng trong lớp Hyena N-D, và chứng minh các định lý sau:

Định lý 5.1. Một kênh duy nhất của bộ lọc ẩn Hyena N-D product chỉ có thể biểu thị kernel có hạng 1.

Định lý 5.2. Cho một chuỗi N-chiều sao cho ∀n∈[N]: Ln=r, một kênh duy nhất của bộ lọc ẩn Hyena N-D với kích thước ẩn F≥2Nr và ít nhất 2 lớp ẩn với kích hoạt dấu có thể biểu thị kernel N-D có hạng tensor r' cho bất kỳ r'∈[2, ..., r].

Những kết quả này dựa trên cấu trúc độc đáo của bộ lọc Hyena, được tạo ra bằng cách sử dụng một hàm có thể học trên mã hóa vị trí. Do đó, chúng ta có thể biểu diễn một bộ lọc N-D với N chiều có kích thước Ln mỗi chiều với một tensor N-chiều tương đương A sao cho:
Ai1,i2,...iN := MLP(PE(i1, i2, ..., iN)), (7)

trong đó ∀j∈[N]: ij∈[Ln].

Được trang bị với công thức này, chứng minh của Định lý 5.2 được chỉ rõ trong Phụ lục A; chứng minh của 5.1 là tầm thường, và được suy ra từ thực tế rằng để tính toán một kernel đa trục toàn cục H, Hyena N-D product lấy phép toán tích ngoài trên các kernel mỗi trục Hn∈HLn×1 cho tất cả n∈[N]. Vì mỗi kernel là một vector, rõ ràng là:
rank(H) = rank(H1 ⊗ H2 ⊗ ... ⊗ HD) = 1 (8)

Thiên hướng quy nạp đối với hạng thấp Định lý 5.2 ban đầu được thiết kế để đánh giá khả năng biểu đạt của lớp Hyena N-D. Tuy nhiên, nó cung cấp những hiểu biết có giá trị về chính quy hóa ẩn và thiên hướng quy nạp của cơ chế bộ lọc ẩn. Định lý 5.2 giới thiệu một loại chính quy hóa tỷ lệ tham số tuyến tính và rõ ràng là khi kích thước ẩn của lớp FFN tăng, hạng tiềm năng cũng tăng, và các bộ lọc bị thiên hướng về phía các tensor hạng thấp.

Vì chính quy hóa được xem như một thuộc tính quan trọng cho hiệu quả của các lớp tích chập toàn cục (Li et al. 2022; Fu et al. 2023), điều bắt buộc là phải định nghĩa nghiêm ngặt loại chính quy hóa hiện diện trong các bộ lọc Hyena. Theo hiểu biết tốt nhất của chúng tôi, đây là lần đầu tiên thiên hướng quy nạp của lớp Hyena được chính thức hóa.

So sánh độ phức tạp và khả năng biểu đạt với các lớp khác Tab. 1 so sánh khả năng biểu đạt và độ phức tạp của các lớp tích chập N-chiều ẩn. Các lớp cơ sở là S4ND (Nguyen et al. 2022) và 2D-SSM (Baron, Zimerman, and Wolf 2023). Như có thể thấy, Hyena N-D là lớp đầu tiên có thể biểu thị kernel hạng đầy đủ cho bất kỳ chiều nào. Hơn nữa, nó có cùng độ phức tạp như lớp Hyena 1-D khi cho các chuỗi có số lượng phần tử bằng nhau cho bất kỳ số chiều nào.

6 Thí nghiệm
Chúng tôi đánh giá phương pháp của chúng tôi trên các benchmark phân loại hình ảnh trên một số xương sống ViT, bao gồm ViT, Swin, và DeiT trong Sec. 6.1, tiếp theo là biện minh thực nghiệm cho các lựa chọn được thực hiện trong thiết kế lớp Hyena N-D trong Sec. 6.2. Cuối cùng, trong Sec. 6.3 chúng tôi phân tích thực nghiệm hiệu quả bộ nhớ của lớp chúng tôi so với ViT tiêu chuẩn.

Thiết lập thí nghiệm Tất cả các thí nghiệm được thực hiện bằng PyTorch. Kết quả của tất cả các thí nghiệm được lấy trung bình trên 3 seed, và chúng tôi đặt kích thước FFN ở 32 cho tất cả các tập dữ liệu. Như một quyết định có chủ ý, chúng tôi không thực hiện điều chỉnh siêu tham số của xương sống và quy trình huấn luyện, ngoài stochastic depth. Tất cả siêu tham số được sao chép từ baseline, là (Lee, Lee, and Song 2021) cho ViT và Swin, và kho lưu trữ DeiT (Touvron et al. 2021) cho các thí nghiệm trên CelebA. Tự nhiên, những tham số này đã được tối ưu hóa cho transformers vanilla (dựa trên chú ý).

6.1 Hyena N-D như lớp cốt lõi của ViT
Chúng tôi đánh giá phương pháp của chúng tôi trên CIFAR-100, Tiny-ImageNet và CelebA, ba benchmark phân loại với các quy mô khác nhau. Chúng tôi báo cáo kết quả cả cho các kiến trúc trong đó cơ chế tự chú ý được thay thế bằng hyena N-D và cho các phương pháp kết hợp của Sec. 4. Như chúng tôi chỉ ra dưới đây, có một lợi thế rõ ràng cho phương pháp kết hợp Hyena-first so với các biến thể khác, có thể được coi là các phép loại bỏ.

Baselines Chúng tôi so sánh các mô hình của chúng tôi với chú ý vanilla và hai phiên bản cải tiến của chú ý cho xương sống ViT, Swin và DeiT: (i) SL-transformers (Lee, Lee, and Song 2021), tạo thành một phiên bản tiết kiệm dữ liệu của ViT để xử lý các tập dữ liệu nhỏ, và (ii) 2-D SSM (Baron, Zimerman, and Wolf 2023) kết hợp thiên hướng quy nạp vào cơ chế chú ý bằng cách sử dụng một lớp được xây dựng trên đỉnh của một mô hình không gian trạng thái hai chiều. Cả hai lớp đều được thiết kế đặc biệt để cải thiện thiên hướng quy nạp của lớp tự chú ý trong xương sống ViT.

Thí nghiệm ViT Đối với xương sống ViT, đầu tiên chúng tôi loại bỏ class token, vì Hyena N-D hoạt động trên một chuỗi 2-D có thứ tự. Sau đó chúng tôi thay thế mỗi lớp chú ý bằng Hyena, Hyena 2-D, hoặc Hyena 2-D product. Như có thể thấy trong phần trên của Tab. 2, việc sử dụng Hyena 1-D thay vì chú ý cải thiện kết quả 1.44% trên CIFAR-100 và 2.61% trên Tiny-Imagenet. Đóng góp thực nghiệm của việc sử dụng Hyena 2-D thay vì Hyena trên hai tập dữ liệu đó là 0.45% và 0.32% tương ứng. Các mô hình kết hợp cũng có vẻ hiệu quả. Phương pháp Hyena-2D First liên tục vượt trội so với các phương pháp khác, hoạt động trung bình cao hơn 1.2% so với phương pháp kết hợp Alternate, cao hơn 3.46% so với phương pháp kết hợp attention first, và cao hơn 4.23% so với mô hình chú ý tiêu chuẩn.

So với các baseline gần đây 2-D SSM và SL-ViT, chúng tôi thấy thực nghiệm rằng ViT dựa trên Hyena 2-D vượt trội so với hai biến thể đó với một khoảng cách đáng kể. Ví dụ, trên xương sống ViT, ViT dựa trên Hyena 2-D hoạt động trung bình cao hơn 3.83% so với chú ý với 2D-SSM và cao hơn 0.385% so với SL-ViT. Kết quả của mô hình kết hợp thậm chí còn tốt hơn, nhưng chúng tôi không kiểm tra các mô hình kết hợp cho những biến thể này.

Thí nghiệm Swin Xương sống Swin cải thiện kiến trúc ViT bằng cách áp dụng hai nguyên tắc: (i) sử dụng cấu trúc phân cấp của các patch kích thước giảm dần qua các lớp, được thực hiện ở cấp độ xương sống, và (ii) sử dụng các cửa sổ dịch chuyển để nắm bắt tốt hơn các phụ thuộc không gian, được thực hiện hiệu quả ở cấp độ lớp thông qua một mặt nạ chú ý được sửa đổi. Khi chúng tôi thay thế mỗi lớp chú ý bằng một số biến thể Hyena không hỗ trợ xử lý mặt nạ, chúng tôi bỏ qua nguyên tắc thứ hai.

Kết quả thực nghiệm, được trình bày trong Tab 2 (dưới) cho thấy rằng ViT dựa trên Hyena có lợi thế so với các mô hình dựa trên chú ý, ngay cả khi không tận dụng chiến lược dịch chuyển này. Trong CIFAR-100, việc sử dụng Hyena 1-D thay vì chú ý cải thiện kết quả 1.26%, và trong Tiny-Imagenet, 1.34%. Việc sử dụng Hyena 2-D thay vì Hyena 1-D tăng cường kết quả hơn nữa, lên 1.96% và 2.03%, tương ứng. Chúng tôi quan sát thấy rằng mô hình dựa trên Hyena vượt trội đáng kể so với các baseline. Ví dụ, lợi thế hiệu suất là 1.645% so với chú ý với 2D-SSM và 1.17% so với SL-ViT.

Tương tự như ViT, trong Swin, phương pháp mô hình kết hợp Hyena-2D First liên tục vượt trội so với các phương pháp khác, hoạt động trung bình cao hơn 2.42% so với phương pháp kết hợp Alternate, cao hơn 6.18% so với phương pháp kết hợp Attention first, và cao hơn 5.45% so với mô hình Swin tiêu chuẩn.

Thí nghiệm DeiT Tương tự như ViT, đầu tiên chúng tôi loại bỏ CLS token và đo hiệu suất cho mỗi lớp. Chúng tôi thực hiện các thí nghiệm trên tập dữ liệu CelebA quy mô lớn. Kích thước hình ảnh gốc là 178x218, và được thay đổi kích thước thành 224x224 để phù hợp với kích thước patch DeiT tiêu chuẩn. Tập dữ liệu bao gồm phân loại thuộc tính đa nhãn 40 chiều. Chúng tôi báo cáo độ chính xác trung bình cho tất cả 40 nhiệm vụ, huấn luyện các mô hình trong 20 epoch, tương tự như quy trình của (Nguyen et al. 2022; Baron, Zimerman, and Wolf 2023) trên tập dữ liệu này.

Như có thể thấy trong Tab. 3, trái ngược với phát hiện trong Tab. 2, việc loại bỏ classification token và thay thế chú ý bằng Hyena 1-D ảnh hưởng tiêu cực đến kết quả. Tuy nhiên, khi chúng tôi tích hợp Hyena 2-D, kết quả cải thiện 6% so với baseline Hyena 1-D. Việc kết hợp biến thể Hyena 2-D hai hướng tăng cường kết quả 1.35%, khớp với mô hình dựa trên chú ý (không có classification token). Tuy nhiên, DeiT gốc (chú ý với classification token) vẫn chính xác hơn.

Như trước đây, phương pháp Hyena-2D First vượt trội so với các phương pháp khác, hoạt động cao hơn 0.23% so với phương pháp kết hợp Alternate, cao hơn 2.12% so với phương pháp kết hợp Attention first, và cao hơn 0.66% so với DeiT tiêu chuẩn. Nó cũng vượt trội 0.55% so với baseline dựa trên 2-D SSM, tốt hơn một chút so với chính DeiT.

6.2 Các biến thể mô hình
Trong phần này chúng tôi biện minh cho các lựa chọn thiết kế của chúng tôi.

Đa hướng Tab. 4 khám phá hai phương pháp để sửa đổi hiệu quả lớp Hyena để xem xét dữ liệu đa hướng. Như mong đợi, đối với cả Hyena N-D và Hyena N-D product, phương pháp đa hướng cải thiện kết quả khoảng 1-1.5%. Chúng tôi quan sát thấy rằng phương pháp 2-D, xoay đầu vào trước mỗi bước trên sự lặp lại Hyena hoạt động tốt hơn một chút so với phương pháp 4-hướng. Cũng quan trọng là lưu ý rằng phiên bản 2-hướng có tính toán bổ sung không đáng kể so với biến thể 1-hướng.

Hàm cửa sổ Như được chi tiết trong Sec. 3, chúng tôi khám phá một số hàm cửa sổ, được đánh giá trong Tab. 5. Đầu tiên, chúng tôi so sánh các hàm cửa sổ symmetric (Eq. 5) và dimensional (Eq. 6) trong lớp Hyena 2-D. Chúng tôi thấy rằng hàm dimensional hoạt động tốt hơn 1.04%, do đó chúng tôi chọn nó như hàm cửa sổ tiêu chuẩn. Tiếp theo, chúng tôi loại bỏ cơ chế cửa sổ bằng cách bỏ qua nó và quan sát sự suy giảm độ chính xác 0.54% cho Hyena 2-D và 0.26% cho Hyena 2-D product. Cuối cùng, chúng tôi cố gắng học hàm cửa sổ bằng cách tham số hóa Eq. 6 riêng biệt cho mỗi kênh. Điều này giảm kết quả 1.36% cho Hyena 2-D và 0.93% cho Hyena 2-D product.

6.3 Hiệu quả cho số lượng lớn patch
Một lợi ích bổ sung của ViT dựa trên Hyena so với ViT dựa trên Attention là độ phức tạp được cải thiện về thời gian và bộ nhớ, như được chi tiết trong Sec. 5.1. Để đánh giá hiệu quả bộ nhớ của Hyena-ViT so với ViT tiêu chuẩn, chúng tôi đã thực hiện các thí nghiệm sử dụng các kích thước patch khác nhau và đo lường tiêu thụ bộ nhớ GPU đỉnh trong quá trình truyền tiến. Hình 2 chứng minh tiêu thụ bộ nhớ được cải thiện đáng kể của Hyena-ViT.

Việc sử dụng số lượng lớn patch có thể quan trọng trong hai tình huống chính: (i) xử lý hình ảnh độ phân giải cao, và (ii) làm việc với các patch nhỏ hơn. Các nghiên cứu trước đây đã chỉ ra rằng các patch quá lớn có thể ảnh hưởng tiêu cực đến độ chính xác của ViT, và các patch nhỏ hơn nói chung có xu hướng cung cấp thiên hướng quy nạp đặc thù của hình ảnh tốt hơn. Chúng tôi đã kiểm tra cách kích thước patch của Hyena-Hybrid ViT ảnh hưởng đến độ chính xác trong Hình 3. Kết quả cho thấy rằng Hybrid-ViT cũng được hưởng lợi từ các patch nhỏ hơn, mà không có sự gia tăng bậc hai trong tiêu thụ bộ nhớ trong một nửa số lớp. Do đó, Hyena-Hybrid ViT và Hyena-ViT trình bày một cơ hội để phát triển các mô hình ViT hiệu quả về chi phí với các patch nhỏ hơn đáng kể với cùng chi phí.

7 Hạn chế
Việc chuyển sang pooling dựa trên N-D Hyena thay vì chú ý ngăn cản chúng tôi sử dụng CLS token, có thể hữu ích. Như công việc tương lai, chúng tôi muốn thêm những token như vậy không phải như một sự nối tiếp, mà là một tín hiệu điều kiện. Hơn nữa, như đã thể hiện trong Swin, tự chú ý có thể dễ dàng được sửa đổi với một mặt nạ phụ thuộc vào domain thi hành một hình dạng cụ thể của thiên hướng quy nạp. Hyena N-D của chúng tôi thiếu cơ chế như vậy. Như công việc tương lai, chúng tôi muốn điều tra xem liệu cửa sổ N-D có thể được sửa đổi cho mục đích tương tự hay không.

8 Thảo luận và Công việc Tương lai
Trong công trình này, chúng tôi mở rộng lớp Hyena gần đây thành dữ liệu đa chiều và chứng minh rằng nó có thể được tận dụng để tạo ra một biến thể ViT tiết kiệm dữ liệu và bộ nhớ. Chúng tôi chỉ ra rằng một số lựa chọn thiết kế, như (i) chèn thiên hướng quy nạp của tính cục bộ 2-chiều thông qua việc sử dụng bộ lọc ẩn 2-D thay vì 1-D, (ii) mở rộng lớp thành một toán tử đa hướng, và (iii) kết hợp chú ý và Hyena theo một cách cụ thể có thể cải thiện đáng kể hiệu suất của ViT trên nhiều benchmark khác nhau.

Đối với nghiên cứu tương lai, chúng tôi dự định khám phá sức mạnh thực nghiệm của lớp Hyena 2-D trong các tình huống tương ứng với lợi thế của nó. Như một lợi thế rõ ràng của ViT dựa trên Hyena so với ViT vanilla là độ phức tạp thời gian và bộ nhớ, việc sử dụng Hyena-ViT trong các tình huống yêu cầu xử lý lượng lớn patch, cũng như các hạn chế thời gian thực hoặc ngân sách thấp, rất hứa hẹn. Cuối cùng, chúng tôi quan tâm đến việc benchmark Hyena-ViT trên các nhiệm vụ ngoài phân loại, như phân đoạn và tạo sinh, cũng như áp dụng lớp này trực tiếp cho các phương thức N-chiều khác, như giọng nói và video.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được giữ nguyên như bản gốc]

--- TRANG 10 ---
A Khả năng biểu đạt
Định lý A.1. Cho một chuỗi N-chiều sao cho ∀d∈[N]: Ln=r, một kênh duy nhất của bộ lọc ẩn Hyena N-D với kích thước ẩn F≥2Nr và ít nhất 1 lớp ẩn với kích hoạt dấu có thể biểu thị kernel N-D có hạng tensor r' cho bất kỳ r'∈[2, ..., r]

Chứng minh. Chúng tôi chứng minh định lý bằng cách chỉ ra rằng một kênh duy nhất của bộ lọc ẩn Hyena N-D có thể biểu thị tensor đồng nhất N-chiều (Bi et al. 2022) cho bất kỳ chiều D > 1 trong Lemma. A.3. Do đó, rõ ràng là một kênh duy nhất của bộ lọc ẩn Hyena N-D có thể biểu thị kernel hạng đầy đủ, và sau đó chúng tôi tổng quát hóa chứng minh thành kernel có bất kỳ hạng r∈[D]

Chúng tôi bắt đầu bằng việc giới thiệu tensor đồng nhất:
Định nghĩa A.2. Tensor đồng nhất (Bi et al. 2022): Các phần tử của tensor đồng nhất N-chiều I được cho bởi
Ij1,j2,···,jN = 1 nếu j1=j2=···=jN
0 nếu ngược lại

Lemma A.3 (Hyena N-D như tensor đồng nhất). Bộ lọc ẩn Hyena N-D với kích thước ẩn F≥2Nr và ít nhất 2 lớp ẩn với kích hoạt dấu có thể biểu thị tensor đồng nhất có chiều r.

Tổng quát hóa thành bất kỳ hạng nào
Dựa trên Lemma A.3, chúng ta có thể xây dựng một FFN thể hiện tensor đồng nhất.

Một đặc trưng độc đáo của việc xây dựng FFN này là khả năng điều chỉnh hạng tensor thông qua các sửa đổi trọng số trong lớp cuối cùng. Cụ thể, các trọng số W3 được định nghĩa là:
w3_1,i = 1 nếu i≤r'
0 nếu ngược lại

Bằng cấu hình này, chỉ có r' neuron đầu tiên ảnh hưởng đáng kể đến đầu ra, hiệu quả chuyển đổi hạng tensor từ r thành r'

Theo điều chỉnh trọng số được chỉ định ở trên, tensor có thể được cắt bớt thành r' phần tử đầu tiên của nó trên mọi chiều. Những phần tử này vốn định nghĩa một tensor đồng nhất có hạng r'. Bất kỳ phần tử nào ngoài tập hợp bị cắt bớt này đều là số không. Cho các tính chất của hạng tensor, việc giới thiệu những phần tử số không này không tăng cường hạng tensor.

Chứng minh của Lemma A.3. Chúng tôi chứng minh lemma bằng cách sử dụng một ví dụ tổng quát. Để đơn giản, chúng tôi giả định rằng hàm mã hóa vị trí là hàm đồng nhất. Do đó, chúng tôi xem xét mạng FFN sau:

Định nghĩa FFN Cho lớp đầu vào có N neuron, lớp ẩn đầu tiên có 2Nr neuron, lớp ẩn thứ hai có r neuron, và lớp đầu ra có 1 neuron.

Cho một vector đầu vào x∈[r]N biểu diễn mã hóa vị trí:
Đầu ra của các lớp ẩn là:
h1=sign(W1x+b1), h2=sign(W2h1+b2)
trong đó W2∈Rh2×h1, b2∈Rh2, W1∈Rh1×n và b1∈Rh1.

và đầu ra của mạng là:
y=sign(W3h2+b3)
trong đó W3∈R1×h2 và b3∈R1.

Thay thế FFN Chúng tôi sẽ thay thế các giá trị trong W1, W2, W3 và b1, b2, b3 sao cho FFN thực hiện tensor đồng nhất. Để đạt được điều này, chúng tôi sử dụng lớp đầu tiên để có được một biểu diễn one-hot mỗi chiều, mà hai lớp cuối cùng sẽ chuyển đổi thành hàm mong muốn.

Do đó, chúng tôi sẽ thay thế các giá trị của lớp ẩn đầu tiên W1 được ký hiệu bằng w1_i,j và b1 như sau:
w1_i,j = 1 nếu i≤Nr và floor(i/N)=j
-1 nếu i>Nr và floor(i/N)=j+Nr
0 nếu ngược lại

bi = (i-1)/2 nếu i≤Nr
(i+1)/2 nếu i>Nr
0 nếu ngược lại

Cho đầu ra của lớp đầu tiên
h1:= (h1_1, h1_2, ···, h1_2Nr)
dễ thấy rằng cặp neuron h1_Ni+j, h1_N(r+i)+j hoạt động khi và chỉ khi xi=j.

Tương tự, chúng tôi định nghĩa lớp thứ hai như sau:
w2_i,j = 1 nếu j%r=i
0 nếu ngược lại
b2 = (−δ,−δ,···,−δ), δ = −2N+1/2

Cho đầu ra của lớp thứ hai
h3:= (h2_1, h2_2, ···, h2_r)
dễ thấy rằng ∀i∈[N], j∈Ln: h2_j=1 khi và chỉ khi ∀i∈[N]: xi=j.

Do đó, bằng cách sử dụng lớp cuối cùng như một cổng "OR", có thể đạt được bằng cách đặt lớp cuối cùng như sau:
w3_1,i = 1 nếu i≤r
0 nếu ngược lại
b3 = −1/2

Rõ ràng là mạng FFN thực hiện tensor đồng nhất.

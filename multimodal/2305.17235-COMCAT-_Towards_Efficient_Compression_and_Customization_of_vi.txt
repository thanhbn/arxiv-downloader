# 2305.17235.pdf
<<<<<<< Updated upstream
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2305.17235.pdf
# Kích thước tệp: 11921721 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác dựa trên Attention
Jinqi Xiao1Miao Yin1Yu Gong1Xiao Zang1Jian Ren2Bo Yuan1

Tóm tắt
Các mô hình thị giác dựa trên attention, như Vision Transformer (ViT) và các biến thể của nó, đã cho thấy hiệu suất đầy hứa hẹn trong các nhiệm vụ thị giác máy tính khác nhau. Tuy nhiên, các kiến trúc mới nổi này gặp phải vấn đề về kích thước mô hình lớn và chi phí tính toán cao, đòi hỏi các giải pháp nén mô hình hiệu quả. Cho đến nay, việc tỉa ViT đã được nghiên cứu kỹ lưỡng, trong khi các chiến lược nén khác đã được áp dụng rộng rãi trong nén CNN, ví dụ như phân tích nhân tử mô hình, ít được khám phá trong bối cảnh nén ViT. Bài báo này khám phá một phương pháp hiệu quả để nén vision transformer nhằm làm phong phú bộ công cụ để có được các mô hình thị giác dựa trên attention nhỏ gọn. Dựa trên hiểu biết mới về lớp multi-head attention, chúng tôi phát triển một giải pháp nén ViT hiệu quả cao, vượt trội hơn các phương pháp tỉa tiên tiến nhất. Để nén các mô hình DeiT-small và DeiT-base trên ImageNet, phương pháp đề xuất của chúng tôi có thể đạt được độ chính xác top-1 cao hơn 0.45% và 0.76% thậm chí với ít tham số hơn. Phát hiện của chúng tôi cũng có thể được áp dụng để cải thiện hiệu quả tùy chỉnh của các mô hình khuếch tán text-to-image, với việc huấn luyện nhanh hơn nhiều (tăng tốc lên đến 2.6×) và chi phí lưu trữ bổ sung thấp hơn (giảm lên đến 1927.5×) so với các công trình hiện có. Mã nguồn và mô hình được công bố tại https://github.com/jinqixiao/ComCAT.

1. Giới thiệu
Gần đây, các mô hình thị giác dựa trên attention đã đạt được hiệu suất tương đương hoặc vượt trội hơn so với kiến trúc tập trung vào convolution trong các nhiệm vụ thị giác máy tính khác nhau, chứng minh lợi ích đầy hứa hẹn mang lại bởi việc sử dụng cơ chế attention (Liu et al., 2021b; Caron et al., 2021; Xie et al., 2021; Carion et al., 2020). Mặt trái, các kiến trúc mới nổi này, ví dụ như vision transformer (ViT) và các biến thể của nó (Touvron et al., 2021; Liu et al., 2021a; Li et al., 2022), gặp phải vấn đề về kích thước mô hình thậm chí lớn hơn và chi phí tính toán cao hơn so với mạng neural tích chập (CNN), cản trở việc triển khai hiệu quả của chúng trong nhiều tình huống thực tế có hạn chế về tài nguyên.

Một giải pháp hấp dẫn cho thách thức này là thực hiện nén mô hình, một chiến lược có thể giảm kích thước mạng mà không ảnh hưởng đến hiệu suất nhiệm vụ. Được thúc đẩy bởi thành công to lớn trước đó của việc nén CNN (Hinton et al., 2015; Han et al., 2015), một số nghiên cứu gần đây (Yin et al., 2023; Yu et al., 2022b; Hou & Kung, 2022) đã đề xuất áp dụng một (ví dụ: tỉa) hoặc kết hợp nhiều (ví dụ: tỉa và chưng cất kiến thức) phương pháp nén cho vision transformer, mang lại việc giảm đáng kể kích thước mô hình và/hoặc FLOP.

Khác với các công trình hiện có, bài báo này nhằm giải quyết thách thức hiệu quả đã phân tích ở trên từ một góc độ khác - khám phá tính low-rank của các mô hình thị giác dựa trên attention. Cho đến nay, một tập hợp phong phú các kỹ thuật nén low-rank cho CNN đã được đề xuất trong tài liệu (Kim et al., 2015; Yin et al., 2021; Liebenwein et al., 2021; Yin et al., 2022b;a; Xiao et al., 2023; Xiang et al., 2023). Tuy nhiên, xét 1) tồn tại sự khác biệt đáng kể về kiến trúc mạng và cơ chế hoạt động, ví dụ như multi-head attention trong ViT so với convolution theo kênh trong CNN; và 2) như được chỉ ra trong (Yu & Wu, 2023) và được xác minh bởi phân tích của chúng tôi, nhiều ma trận trọng số trong vision transformer không thể hiện tính low-rank, không rõ liệu nén low-rank có thể mang lại cải thiện thỏa mãn về hiệu quả mô hình hay không. Từ quan điểm triển khai thực tế, một câu hỏi tự nhiên nảy sinh: Để nén các mô hình thị giác dựa trên attention, việc khám phá tính low-rank của mô hình có thể cung cấp hiệu suất tương đương hoặc thậm chí tốt hơn so với các phương pháp khác như tỉa không?

Để trả lời câu hỏi này và hoàn toàn khai thác tiềm năng của nén low-rank cho ViT và các mô hình dựa trên attention, bài báo này đầu tiên điều tra tính low-rank trong lớp multi-head attention, và đề xuất rằng tính low-rank ở mức head, thay vì mức ma trận trọng số, nên được khám phá. Dựa trên hiểu biết mới này, chúng tôi sau đó phát triển một giải pháp nén ViT low-rank hiệu quả cao với lựa chọn rank tự động. So với các phương pháp tỉa ViT tiên tiến nhất, phương pháp đề xuất có thể đạt được độ chính xác top-1 cao hơn 0.45% và 0.76% thậm chí với ít tham số hơn, để nén các mô hình DeiT-small và DeiT-base trên tập dữ liệu ImageNet, tương ứng. Hơn nữa, phát hiện của chúng tôi cũng có thể được áp dụng để cải thiện hiệu quả tùy chỉnh các mô-đun khuếch tán text-to-image (Ruiz et al., 2022; Kumari et al., 2022), một nhiệm vụ thị giác máy tính mới nổi và quan trọng gần đây, với việc huấn luyện nhanh hơn nhiều (tăng tốc lên đến 2.6×) và chi phí lưu trữ bổ sung thấp hơn (giảm lên đến 1927.5×) so với các giải pháp tùy chỉnh tiên tiến nhất.

2. Các Công trình Liên quan
Tỉa cho Vision Transformer. Để giảm kích thước mô hình và đạt được tăng tốc thực tế, việc tỉa có cấu trúc trên các cấu trúc con khác nhau của mô hình ViT, ví dụ như attention head, block và hàng của ma trận trọng số, đã được nghiên cứu trong tài liệu (Hou & Kung, 2022; Yu et al., 2022b; Zhu et al., 2021; Chen et al., 2021b). Ngoài ra, một hướng nghiên cứu khác đề xuất cải thiện tốc độ xử lý mô hình thông qua việc sử dụng tỉa token động hoặc tĩnh (Bolya et al., 2022; Pan et al., 2021b; Tang et al., 2022; Goyal et al., 2020; Pan et al., 2021a). Gần đây, Yu et al. (Yu et al., 2022b) phát triển một khung thống nhất để thực hiện đồng thời tỉa, chưng cất kiến thức và bỏ qua block, đạt được hiệu suất nén ViT tiên tiến nhất.

Nén Low-rank của Ma trận Trọng số (W) trong Transformer NLP. Hầu hết các nghiên cứu hiện có về transformer nén low-rank tập trung trong lĩnh vực NLP. Noach et al. (Noach & Goldberg, 2020) phân tích các ma trận trọng số của các mô hình ngôn ngữ đã được huấn luyện trước (PLM) bằng SVD và thực hiện chưng cất đặc trưng để cải thiện hiệu suất mô hình. Ren et al. (Ren et al., 2022) áp dụng phân tích tensor để nén PLM và đạt được tăng tốc suy luận thực tế. Hsu et al. (Hsu et al., 2022) giới thiệu thông tin Fisher để đo tầm quan trọng của các tham số để phân tích nhân tử PLM cụ thể cho nhiệm vụ.

Xấp xỉ Low-Rank cho Ma trận Attention (Q, K, V). Một dòng công trình khác là thực hiện xấp xỉ low-rank cho các ma trận attention, các kết quả trung gian từ cơ chế attention. Các loại sơ đồ xấp xỉ khác nhau, bao gồm thêm các ma trận chiếu bổ sung và xấp xỉ thưa thớt, đã được điều tra (Wang et al., 2020; Choromanski et al., 2020; Chen et al., 2021a). Là nỗ lực trực giao với phương pháp của chúng tôi, các phương pháp này không giảm kích thước mô hình của transformer.

Mô hình Khuếch tán Text-to-Image Cá nhân hóa. Các mô hình khuếch tán text-to-image được phát hành gần đây (Rombach et al., 2022; Ramesh et al., 2022; Saharia et al., 2022; Yu et al., 2022a) đã cho thấy khả năng tạo nội dung ấn tượng. Một nhu cầu rất mới nổi và thực tế là làm cho các mô hình đã được huấn luyện trước này được tùy chỉnh cho một khái niệm cụ thể do người dùng cung cấp. Để đạt được điều đó, một số nỗ lực tận dụng transfer learning thông qua fine-tuning tất cả các tham số hoặc giới thiệu một vector từ cho khái niệm mới (Ruiz et al., 2022; Gal et al., 2022). Tuy nhiên, kích thước lớn của các mô hình khuếch tán mang lại thời gian huấn luyện tốn kém và yêu cầu lưu trữ bổ sung cao trong quá trình fine-tuning. Để cải thiện hiệu quả tùy chỉnh, Kumari et al. (Kumari et al., 2022) đề xuất chỉ fine-tune việc ánh xạ key và value từ văn bản sang các đặc trưng tiềm ẩn trong các lớp cross-attention; trong khi đóng băng các phần khác.

3. Phương pháp
3.1. Kiến thức Cơ bản
Phép toán attention có thể được xem như việc ánh xạ từ một query và một tập hợp các cặp key-value đến một đầu ra. Để tốt hơn trong việc trích xuất và học thông tin từ không gian biểu diễn và các vùng không gian khác nhau, các mô hình thị giác dựa trên attention tiên tiến nhất áp dụng multi-head attention (MHA) như:

MHA(XQ, XK, XV) = Concat(head1, ..., headh)WO,(1)

trong đó XQ, XK, XV∈Rn×dm là các ma trận nhúng đầu vào, n là độ dài chuỗi, dm là chiều nhúng, và h là số lượng head. Đối với mỗi head i, nó thực hiện phép toán attention như sau:

headi = Attention(XQWQi, XKWKi, XVWVi)
= Softmax(XQWQi(XKWKi)T/√dk)XVWVi,(2)

trong đó WQi, WKi∈Rdm×dk, WVi∈Rdm×dv, WO∈Rhdv×dm là các ma trận trọng số, và dk và dv là chiều của XQ và XK, tương ứng. Vì dk = dv = dm/h, để đơn giản chúng tôi sử dụng d thay vì dk và dv.

3.2. Khám phá Tính Low-Rankness trong Lớp MHA
Trong tiểu mục này, chúng tôi mô tả MHA low-rank đề xuất của chúng tôi để có các mô hình thị giác hiệu quả. Chúng tôi đầu tiên chứng minh tính low-rankness của các ma trận trọng số trong mỗi attention head, và phân tích hạn chế khi chỉ tận dụng tính low-rankness ở cấp độ ma trận. Dựa trên những quan sát và phân tích này, chúng tôi sau đó đề xuất khám phá tính low-rankness ở cấp độ head và hình thành cơ chế. Chúng tôi tiếp tục chi tiết quy trình sử dụng phát hiện này để cải thiện hiệu quả mô hình trong hai tình huống quan trọng: nén vision transformer và tùy chỉnh mô hình khuếch tán.

Tính Low-Rankness của WQi, WKi, WVi, WO. Tính low-rankness của các ma trận trọng số đã được quan sát rộng rãi trong nhiều loại kiến trúc deep learning bao gồm CNN và NLP transformer (Kim et al., 2015; Ren et al., 2022), truyền cảm hứng cho chúng tôi khám phá sự tồn tại tiềm năng của nó trong các mô hình thị giác dựa trên attention. Để làm điều đó, chúng tôi phân tích phân phối của các giá trị singular của các ma trận trọng số (WQi, WKi, WVi, WO) trong mô hình DeiT-base đã được huấn luyện trước (Touvron et al., 2021). Hình 1 cho thấy bản đồ nhiệt của các giá trị singular tích lũy sau khi áp dụng Phân tích Giá trị Singular (SVD) vào mỗi ma trận trọng số. Có thể thấy rằng hiện tượng hầu hết thông tin tập trung trong một phần các giá trị singular (những cái lớn nhất) thực sự tồn tại trong các ma trận trọng số qua các head và lớp khác nhau, cho thấy tiềm năng của việc khám phá tính low-rank của các mô hình dựa trên attention.

Hạn chế của Tính Low-Rankness Cấp Ma trận. Dựa trên quan sát trên, một ý tưởng tự nhiên là xây dựng mỗi ma trận trọng số (WQi, WKi, WVi, WOi) trong định dạng low-rank riêng của nó. Tuy nhiên, chúng tôi lập luận rằng lợi ích mang lại bởi chiến lược trực tiếp này sẽ không đáng kể. Như được thể hiện trong Hình 1, một số loại ma trận trọng số, ví dụ WVi, không thể hiện tính low-rank đủ, một hiện tượng cũng được quan sát trong các ma trận của các lớp cao hơn, do đó hạn chế tiềm năng cải thiện hiệu suất tổng thể mang lại bởi phân tích nhân tử low-rank.

Khám phá Tính Low-Rankness Cấp Head. Để tận dụng tốt hơn tính low-rank trong lớp MHA và hoàn toàn khai thác các lợi ích tiềm năng, chúng tôi đề xuất khám phá tính chất low-rank ở cấp độ head để có multi-head attention hiệu quả. Ý tưởng của chúng tôi được thúc đẩy bởi quan sát rằng tồn tại các phép biến đổi tuyến tính liên tiếp trong attention head, ví dụ XQWQi(XKWKi)T = XQ(WQiWKiT)XTK trong Eq. 2, mở ra cơ hội xây dựng các kết hợp của ma trận trọng số, ví dụ WQiWKiT, thay vì ma trận riêng lẻ, trong định dạng low-rank. Theo đại số tuyến tính, việc tái cấu trúc như vậy mang lại hai lợi ích. Thứ nhất, nó cung cấp giải pháp low-rank tiết kiệm tham số hơn. Cụ thể hơn, đối với hai ma trận full-rank A∈Rn×d và B∈Rd×n, tổng số tham số của các xấp xỉ rank-r A′∈Rn×r và B′∈Rr×n của chúng là 2nr; trong khi cùng xấp xỉ rank-r C′∈Rn×r cho C = AB chỉ chứa nr tham số. Thứ hai, nó nới lỏng các ràng buộc của việc áp dụng xấp xỉ low-rank. Vì tính low-rank của A hoặc B, thay vì cả hai, đã đủ để dẫn đến C low-rank, nó chỉ ra rằng tính low-rank cấp head là một cơ hội phổ biến và khả thi hơn khi nhằm tận dụng tính low-rank trong lớp MHA.

Được thúc đẩy bởi những lợi ích này, bây giờ chúng tôi hình thành ý tưởng của mình trong bối cảnh cơ chế multi-head attention. Đầu tiên Eq. 1 và Eq. 2 có thể được tái cấu trúc như:

MHA(XQ, XK, XV) = Σi=1h headi WOi
= Σi=1h Softmax(XQ(WQiWKiT)XTK/√dk)XV(WViWOi),(3)

trong đó WOi∈Rd×dm và WO = Concat(WO1, ..., WOh).

Nhớ lại rằng một ma trận W∈Rin×out có thể được xấp xỉ low-rank bằng cách thực hiện SVD như W ≈ W′ = UΣS′ = US, trong đó U∈Rin×r, S′∈Rr×out, ma trận đường chéo Σ∈Rr×r, S = ΣS′∈Rr×out, và r là giá trị rank. Sau đó toàn bộ multi-head attention (Eq. 3) có thể được xây dựng trong định dạng low-rank như:

MHA(XQ, XK, XV)
≈ Σi=1h Softmax(XQ(UQiSKiT)XTK/√dk)XV(UViSOi)
= Concat(head′1, ..., head′h)W′O, trong đó
head′i = Attention(XQUQi, XKSKi, XVUVi)
= Softmax(XQUQi(XKSKi)T/√dk)XVUVi,
SO = Concat(SO1, ..., SOh).(4)

Ở đây WQiWKiT ≈ UQiSKiT (rank = r1), WViWOi ≈ UViSOi (rank = r2), UQi, SKi∈Rdm×r1, UVi, SOi∈Rdm×r2, và SO∈Rhr2×dm.

Lưu ý rằng như được thể hiện trong Eq. 4, ngoài việc khám phá tính low-rank của WQKi = WQiWKiT, mối tương quan giữa các ma trận giữa WVi và WOi cũng được xem xét, mang lại cấu trúc low-rank cho WVOi = WViWOi. Trong Hình 2, chúng tôi so sánh phân tích low-rank trực tiếp của WQi và WKi với phân tích của WQiWKiT và báo cáo số lượng tham số cần thiết sau khi thực hiện phân tích nhân tử low-rank trong trường hợp tỷ lệ các giá trị singular tích lũy đạt 90%. Bằng cách so sánh số lượng tham số cần thiết để đạt ngưỡng này, chúng tôi có thể đánh giá và so sánh tính low-rank của các ma trận gốc, tức là ít tham số hơn chỉ ra tính low-rank tốt hơn. Điều này là bởi vì để bảo tồn cùng một lượng thông tin, ví dụ 90% giá trị singular tích lũy, ma trận có tính low-rank tốt hơn yêu cầu ít tham số hơn. Như được thể hiện trong hình này, số lượng tham số cần thiết để phân tích nhân tử WQiWKiT (đường màu xanh) để đạt ngưỡng 90% luôn nhỏ hơn so với WQi và WKi (đường màu đỏ), cho thấy ma trận kết hợp thể hiện tính low-rank tốt hơn. Bảng 1 minh họa lợi ích của cơ chế MHA low-rank cấp head như vậy, với ứng dụng của nó cho nén ViT không fine-tuning làm ví dụ. So với việc áp dụng SVD trực tiếp cho các ma trận trọng số riêng lẻ, phương pháp của chúng tôi mang lại độ chính xác mô hình cao hơn nhiều với cùng tỷ lệ nén, xác minh hai lợi ích (hiệu quả tham số và ràng buộc low-rank nới lỏng) được chỉ ra trong phân tích trước đó của chúng tôi.

MHA Low-Rank cho Nén Vision Transformer. Một ứng dụng trực tiếp của MHA low-rank đề xuất của chúng tôi là nén vision transformer. Nói chung, đối với một ViT b-block với một lớp MHA và một mạng feedforward 2 lớp (FFN) mỗi block, nhiệm vụ nén tương ứng sử dụng MHA low-rank có thể được hình thành như sau:

min{WQKi,j, WVOi,j, WFFNk,j}h,b,2i=1,j=1,k=1 L({WQKi,j, WVOi,j, WFFNk,j})
s.t. Σj=1b (Σi=1h C(R(WQKi,j)) + C(R(WVOi,j)) + Σk=12 C(R(WFFNk,j))) ≤ ε,(5)

trong đó L(·), C(·) và R(·) là các hàm trả về loss, cost (ví dụ: kích thước mô hình hoặc FLOP) và rank, tương ứng. WQKi,j = WQi,j WKi,jT, WVOi,j = WVi,j WOi,j và WFFNk,j là các ma trận kết hợp của attention head thứ i và ma trận trọng số trong FFN trong block thứ j. Có thể thấy rằng với ngân sách cost mục tiêu (ε) của ViT nén, rank là một loại siêu tham số quan trọng trực tiếp quyết định độ chính xác và độ phức tạp. Trong thực tế, do phạm vi rộng lớn của các giá trị rank có thể, việc lựa chọn rank phù hợp cho tất cả các block và lớp của vision transformer là thách thức. Ví dụ, tồn tại 4.53×10188 kết hợp rank khi thực hiện nén low-rank cho mô hình DeiT-small, làm cho việc lựa chọn thủ công trở nên không thực tế.

Để giải quyết thách thức này, chúng tôi đề xuất một phương pháp lựa chọn rank tự động để hiệu quả kết hợp MHA low-rank vào nén ViT. Ý tưởng chính của chúng tôi là diễn giải việc lựa chọn rank tự động của nén low-rank như một neural architecture search (NAS) chuyên biệt, xem xét thực tế rằng việc lựa chọn rank về cơ bản quyết định cấu trúc cuối cùng của ViT nén. Từ hiểu biết này, giá trị rank phù hợp có thể được xác định thông qua tìm kiếm dựa trên sampling có thể vi phân, một chiến lược đã được nghiên cứu kỹ trong tài liệu NAS (Liu et al., 2018; Wu et al., 2019; Tan & Le, 2019).

Hình 4 minh họa khung tổng thể cho tìm kiếm rank tự động cho ViT low-rank. Ở đây để ký hiệu đơn giản, chúng tôi sử dụng W∗j∈Rinj×outj để biểu thị các ma trận cần được phân tích trong lớp thứ j, tức là WQKi,j, WVOi,j và WFFNk,j, với tập hợp rank ứng viên là Rj = {r1j, r2j, raj, ... rmaxj}. Giả sử rằng r∗j∈Rj là rank hiện tại được chọn cho Wj ≈ W∗j = U∗j S∗j (U∗j∈Rinj×r∗j và S∗j∈Rr∗j×outj). Sau đó chúng tôi luân phiên cập nhật xác suất lựa chọn Pj = {p1j, p2j, paj, ... pmaxj} cho các ứng viên rank và các tham số của W∗j. Cụ thể, vì Pj được tính toán thông qua GumbelSoftmax (Jang et al., 2016), tức là Pj = GumbelSoftmax(αj) với vector có thể học αj, Pj có thể được cập nhật thông qua việc tối thiểu hóa loss sau (với các tham số trọng số đóng băng):

LProb = LCE(Y, Ŷ) · (Σaj=1 Ppaj C(raj)/ε)β,(6)

trong đó LCE(·) là loss cross-entropy, Y là đầu ra cuối cùng của toàn bộ mô hình, Ŷ là ground truth, và β là siêu tham số kiểm soát toàn bộ quá trình tìm kiếm. Ở đây như được thể hiện trong Hình 4, việc tính toán Y = Yb dựa trên việc xem xét tất cả các ứng viên phân tích (Uaj, Saj) với các cài đặt rank khác nhau và xác suất lựa chọn của chúng. Sau khi hoàn thành cập nhật xác suất, W∗j đầu tiên được phân tích nhân tử thông qua việc sử dụng rank tương ứng với xác suất lựa chọn lớn nhất, và sau đó được cập nhật thông qua việc tối thiểu hóa loss cross-entropy với các xác suất lựa chọn rank đóng băng. Các cài đặt rank có thể được xác định cuối cùng sau nhiều vòng cập nhật luân phiên như vậy của xác suất và trọng số.

MHA Low-Rank cho Khuếch tán Text-to-Image Cá nhân hóa. MHA low-rank đề xuất của chúng tôi cũng có thể được sử dụng để tùy chỉnh khuếch tán text-to-image một cách hiệu quả, một nhiệm vụ thị giác máy tính mới nổi mà mô hình khuếch tán đã được huấn luyện trước có thể nhanh chóng tổng hợp các thể hiện trực quan chất lượng cao của các khái niệm do người dùng định nghĩa với ít ví dụ về hình ảnh và hướng dẫn văn bản. Cụ thể hơn, cho một mô hình khuếch tán đã được huấn luyện trước {Wdiff} đã được huấn luyện tốt trên tập hình ảnh {x} và tập vector điều kiện {c} thu được từ text prompt, chúng tôi nhằm tối thiểu hóa loss sau:

Eϵ,xnew,cnew,t[wt∥{Wnew}(αtxnew + σtϵ, cnew) - xnew∥22],(7)

trong đó αt, σt và wt là hàm của timestep t kiểm soát quá trình khuếch tán, và xnew và cnew biểu thị các hình ảnh và text prompt do người dùng cung cấp, tương ứng, với |{xnew}| ≪ |{x}| và |{cnew}| ≪ |{c}|. Lưu ý rằng ở đây {Wnew} được khởi tạo là f({Wdiff}), trong đó f(·) có thể là hàm đồng nhất, có nghĩa là mô hình cá nhân hóa {Wnew} được khởi tạo trực tiếp là {Wdiff} đã được huấn luyện trước, hoặc một hàm biến đổi, chỉ ra rằng việc khởi tạo cho {Wnew} là sự sửa đổi của {Wdiff}.

Như được chỉ ra trong (Kumari et al., 2022), việc cập nhật toàn bộ {Wnew} rất không hiệu quả về mặt tính toán và dễ gây ra overfitting, do kích thước lớn của {Wdiff} và kích thước nhỏ của {xnew}. Được truyền cảm hứng từ những hiểu biết rằng 1) chỉ thay đổi một vài tham số đã đủ để làm cho các mô hình khuếch tán học được khái niệm do người dùng định nghĩa (Kumari et al., 2022); và 2) việc thêm thành phần low-rank là một chiến lược fine-tuning hiệu quả cho các mô hình ngôn ngữ lớn (LLM) trong các nhiệm vụ NLP (Aghajanyan et al., 2020), chúng tôi đề xuất sử dụng MHA low-rank để cải thiện hiệu quả triển khai của khuếch tán text-to-image cá nhân hóa. Hình 5 minh họa khung tổng thể. Cụ thể hơn, lớp MHA của mô hình cá nhân hóa được khởi tạo như:

MHA(XQ, XK, XV) = Σi=1h Softmax(XQ(WQiWKiT + UQiSKiT)XTK/√dk) XV(WViWOi + (UViSOi))(8)

trong đó {WQi, WKi, WVi, WOi} được thu được từ mô hình khuếch tán đã được huấn luyện trước {Wdiff}, và {UQi, SKi, UVi, SOi} là các thành phần low-rank được khởi tạo ngẫu nhiên. Như được thể hiện trong Hình 5, trong quá trình tùy chỉnh mô hình, tất cả các tham số của mô hình đã được huấn luyện trước {Wdiff} được đóng băng; trong khi việc tính toán của chúng tuân theo cơ chế được mô tả trong MHA low-rank đề xuất của chúng tôi. Đồng thời, thành phần low-rank được thêm vào UQi, SKi, UVi và SOi được cập nhật để làm cho Wnew thích ứng với các khái niệm mới do người dùng cung cấp.

4. Thí nghiệm
4.1. Phân loại Hình ảnh trên ImageNet-1K
Cài đặt. Chúng tôi đầu tiên xác thực phương pháp của mình trên tập dữ liệu ImageNet-1K (Deng et al., 2009) cho nhiệm vụ phân loại hình ảnh. Tập dữ liệu bao gồm 1.2M hình ảnh huấn luyện và 50K mẫu xác thực. Chúng tôi áp dụng các mô hình baseline, tức là mạng dày đặc không nén, và công thức huấn luyện từ DeiT (Touvron et al., 2021) vì chúng cho thấy kết quả đầy hứa hẹn trong việc huấn luyện các mô hình transformer chỉ bằng cách sử dụng ImageNet-1K mà không có các tập dữ liệu quy mô lớn khác để huấn luyện trước và do đó được áp dụng rộng rãi. Chúng tôi so sánh phương pháp của mình với các phương pháp nén ViT tiên tiến nhất trước đó, bao gồm low-rank (Yu & Wu, 2023), model pruning (Hou & Kung, 2022; Yu et al., 2022b; Zhu et al., 2021; Tang et al., 2020), sparse training (Chen et al., 2021b) và token pruning (Bolya et al., 2022; Pan et al., 2021b; Tang et al., 2022; Goyal et al., 2020; Pan et al., 2021a).

Chi tiết Triển khai. Toàn bộ quá trình của phương pháp chúng tôi bao gồm hai bước: tìm kiếm rank và fine-tuning. Chúng tôi tiến hành thuật toán lựa chọn rank tự động cho mô hình DeiT đã được huấn luyện trước để tạo ra mô hình low-rank dưới ràng buộc đã cho. Trong quá trình fine-tuning, learning rate ban đầu được đặt là 0.0001 và giảm xuống learning rate tối thiểu 0.000001 với bộ lập lịch Cosine. Weight decay để huấn luyện DeiT-small nén được đặt là 0.005. Phần còn lại của các siêu tham số huấn luyện nhất quán với DeiT (Touvron et al., 2021).

Kết quả So sánh. Bảng 2 cho thấy hiệu suất của các phương pháp nén khác nhau trên tập dữ liệu ImageNet. So với phương pháp tỉa tự động tiên tiến nhất trước đó UVC (Yu et al., 2022b), các mô hình nén của chúng tôi có độ chính xác top-1 cao hơn 0.45% và 1.69% với việc giảm FLOP lớn hơn nhiều trên DeiT-small và DeiT-base, tương ứng. Ngoài ra, phương pháp của chúng tôi có thể giảm đáng kể các tham số mô hình, tức là giảm 49.98% cho DeiT-small và 61.06% cho DeiT-base, trong khi mô hình nén từ UVC (Yu et al., 2022b) thì không thể. So với công trình low-rank của CT-GFM (Yu & Wu, 2023), phương pháp của chúng tôi đạt được sự tăng độ chính xác 0.98% với số lượng tham số ít hơn nhiều. So với công trình sparse training của S2ViTE (Chen et al., 2021b), với độ chính xác top-1 tương tự, chúng tôi đạt được việc giảm FLOP lớn hơn nhiều là 19.58% và 28.55% và giảm tham số là 16.04% và 26.65% trên DeiT-small và DeiT-base, tương ứng. So với công trình của PS-ViT (Tang et al., 2022) cho token reduction, phương pháp của chúng tôi cũng đạt được độ chính xác top-1 cao hơn là 0.18% và 0.76% với FLOP và tham số mô hình ít hơn nhiều trên DeiT-small và DeiT-base, tương ứng.

Tăng tốc Thực tế trên Các Nền tảng Phần cứng Khác nhau. Chúng tôi tiếp tục đo tăng tốc thực tế của các mô hình nén của chúng tôi trên các nền tảng phần cứng tính toán khác nhau, bao gồm Nvidia Tesla V100, Nvidia Jetson TX2, điện thoại di động Android (Snapdragon 855, 4 Cortex-A76 + 4 Cortex-A55), bộ gia tốc ASIC Eyeriss (Chen et al., 2016), và FPGA (PYNQ Z1) trong Bảng 3. Ở đây hiệu suất của Eyeriss được báo cáo thông qua việc sử dụng Timeloop (Parashar et al., 2019) với cài đặt công nghệ CMOS 45nm. Các mô hình DeiT-small và DeiT-base nén của chúng tôi đạt được tăng tốc đáng kể trên các nền tảng khác nhau. Ví dụ, trên Snapdragon 855, DeiT-base nén của chúng tôi có được tăng tốc 2.52× so với mô hình baseline với độ chính xác top-1 thậm chí cao hơn trên ImageNet. Những kết quả như vậy chứng minh hiệu quả thực tế của giải pháp nén low-rank của chúng tôi.

4.2. Phân tích Ablation cho Nén ViT Low-Rank
Lựa chọn Rank Tự động vs. Lựa chọn Rank Thủ công. Để chứng minh tính ưu việt của phương pháp lựa chọn rank tự động của chúng tôi, chúng tôi so sánh nó với phương pháp rank cố định. Hình 6 cho thấy các đường cong biến thiên của độ chính xác top-1 trên ImageNet-1K và số lượng tham số cho cả hai phương pháp trong quá trình huấn luyện. Phương pháp của chúng tôi có mất độ chính xác ít hơn, và số lượng tham số của mô hình dần dần hội tụ về giá trị mục tiêu (10.5M). Ngược lại, mô hình dựa trên phân tích cố định-rank mất nhiều độ chính xác hơn từ đầu, dẫn đến hiệu suất kém. Do đó, chúng tôi có thể kết luận rằng phương pháp của chúng tôi có thể tìm kiếm kết hợp rank tốt hơn dưới các ràng buộc.

Siêu tham số cho Tìm kiếm Rank. Chúng tôi cũng khám phá ảnh hưởng của siêu tham số β được đề cập bởi Eq. 6 đến quá trình tìm kiếm rank. Hình 7 cho thấy sự hội tụ của quá trình tìm kiếm liên quan đến các β khác nhau. Có thể thấy rằng khi β ≥ 1, số lượng tham số của mô hình có thể hội tụ về giá trị mục tiêu nhanh chóng, và độ chính xác cuối cùng của các mô hình cơ bản là giống nhau. Tuy nhiên, khi β = 1.5, đường cong độ chính xác của mô hình tương đối mượt mà, do đó, chúng tôi nghĩ 1.5 là giá trị tương đối tốt hơn cho β. Phân phối rank cuối cùng của DeiT-small và DeiT-base được thể hiện trong Hình 8 và Hình 9.

SVD vs. Phân tích Tensor Bậc cao. Để nén ViT, ngoài MHA, chúng tôi áp dụng nén low-rank cho FFN (Feed-Forward Network), và việc lựa chọn rank cho FFN cũng được bao gồm trong cơ chế xác định rank tự động đề xuất của chúng tôi. Để tìm phương pháp phân tích low-rank tối ưu từ các phương pháp phân tích low-rank khác nhau như SVD, phân tích Tucker, phân tích Tensor Train, chúng tôi đánh giá độ chính xác Top-1 và throughput trên GPU cho DeiT-Small nén trên tập dữ liệu ImageNet khi nén FFN sử dụng các phương pháp low-rank khác nhau. Như được thể hiện trong Bảng 4, với cùng tỷ lệ nén, việc sử dụng SVD mang lại độ chính xác cao hơn (không fine-tuning) so với việc sử dụng phân tích Tucker và phân tích Tensor Train với throughput tốt hơn trên GPU.

4.3. Mô hình Khuếch tán Text-to-Image Cá nhân hóa
Cài đặt. Chúng tôi fine-tune lớp cross-attention của Stable Diffusion đã được huấn luyện trước (Rombach et al., 2022) (trọng số mô hình thu được từ HuggingFace Hub1 (Wolf et al., 2019)) bằng cách sử dụng cơ chế MHA low-rank đề xuất của chúng tôi để cho phép mô hình học một khái niệm mới. Để đánh giá định lượng, chúng tôi sử dụng sáu đối tượng được bao gồm trong tập dữ liệu được phát hành bởi CustomDiffusion (Kumari et al., 2022) và một đối tượng mới được thu thập, với số lượng hình ảnh chứa trong mỗi cái dao động từ 4 đến 12.

So sánh Chi phí Huấn luyện. Chúng tôi đầu tiên trình bày chi phí huấn luyện cần thiết bởi tất cả các phương pháp trong Bảng 5. Chúng tôi huấn luyện tất cả các phương pháp trên một GPU Nvidia RTX A6000 với kích thước batch là 1 và số bước huấn luyện là 500. So với CustomDiffusion và DreamBooth, phương pháp của chúng tôi giảm thời gian huấn luyện 18.6% và 61.6%, tương ứng (xem Thời gian Huấn luyện trong Bảng 5), và giảm không gian lưu trữ bổ sung cho mỗi khái niệm 12.5× và 1927.5×, tương ứng (xem Lưu trữ Bổ sung trong Bảng 5). Việc giảm theo thứ tự độ lớn của lưu trữ bổ sung cho mỗi khái niệm mới cực kỳ quan trọng đối với việc áp dụng rộng rãi các mô hình khuếch tán text-to-image cá nhân hóa, nơi người dùng có thể chuẩn bị các mô hình khuếch tán của họ mà không gánh nặng lưu trữ mô hình.

So sánh Chất lượng Hình ảnh. Chúng tôi sau đó đánh giá chất lượng của các hình ảnh được tổng hợp cho tất cả các phương pháp. Chúng tôi tạo ra 20 hình ảnh cho mỗi hình ảnh mục tiêu đã học (khái niệm) bằng cách sử dụng cùng text prompt cho tất cả các phương pháp và tính toán FID (Heusel et al., 2017; Parmar et al., 2021) giữa các hình ảnh được tổng hợp và thực. Điểm FID thấp hơn chỉ ra sự khác biệt nhỏ hơn giữa các hình ảnh được tạo ra và thực. Như được thể hiện trong Bảng 5, phương pháp của chúng tôi đạt được FID thấp nhất so với các công trình hiện có. Chúng tôi tiếp tục cung cấp so sánh định tính trong Hình 10. Ngoài việc tạo ra các cảnh tương ứng một cách chính xác từ text prompt, V* Goldendoodle được tạo ra bởi phương pháp của chúng tôi gần nhất với hình ảnh thực, trong khi V* Goldendoodle được tổng hợp bởi DreamBooth (Ruiz et al., 2022) có sự khác biệt rõ ràng so với hình ảnh thực, và hình ảnh được tổng hợp từ CustomDiffusion (Kumari et al., 2022) chứa miệng ít tự nhiên hơn vì nó đã bị biến dạng. Trong Hình 11, chúng tôi tiếp tục cho thấy rằng thậm chí với ít tài nguyên tính toán hơn nhiều, tức là ít thời gian huấn luyện và ít số lượng GPU hơn để fine-tuning mô hình, chúng tôi vẫn có thể tạo ra hình ảnh chất lượng cao.

Đánh giá MS-COCO. Cuối cùng, chúng tôi thực hiện các thí nghiệm để hiểu liệu các mô hình đã được fine-tuning có thể tạo ra hình ảnh không liên quan đến chủ thể mục tiêu đã học (V*) hay không. Chúng tôi sử dụng văn bản được nhắc của 5,000 hình ảnh từ tập xác thực MS-COCO 2017 (Lin et al., 2014) để tạo ra hình ảnh và tính toán FID. Như được thể hiện trong Bảng 6, FID từ các mô hình cá nhân hóa tương tự như mô hình text-to-image đã được huấn luyện trước, cho thấy rằng chúng có thể tổng hợp hình ảnh chất lượng cao cho các khái niệm không liên quan. Do đó, mô hình được fine-tuning bởi phương pháp của chúng tôi vẫn giữ được phân phối của các hình ảnh được tổng hợp như mô hình đã được huấn luyện trước.

5. Kết luận
Bài báo này điều tra cơ bản tính low-rank trong lớp multi-head attention của các mô hình thị giác mới nổi và đề xuất rằng tính low-rank cấp head nên được khám phá để thiết kế mô hình hiệu quả, mang lại giải pháp nén ViT low-rank hiệu quả cao. Phương pháp của chúng tôi không chỉ vượt trội hơn các phương pháp nén hiện có bằng cách cung cấp hiệu suất cao hơn mà còn mang lại tăng tốc thực tế nhanh hơn. Đặc biệt, phát hiện của chúng tôi được áp dụng thêm cho việc tùy chỉnh hiệu quả các mô hình khuếch tán text-to-image, vượt trội hơn các giải pháp tiên tiến nhất.

6. Lời cảm ơn
Công trình này được hỗ trợ một phần bởi National Science Foundation dưới Grant CCF-1937403 và CCF-1955909.
=======
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/multimodal/2305.17235.pdf
# File size: 11921721 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác Dựa trên Attention

Jinqi Xiao¹ Miao Yin¹ Yu Gong¹ Xiao Zang¹ Jian Ren² Bo Yuan¹

Tóm tắt

Các mô hình thị giác dựa trên attention, chẳng hạn như Vision Transformer (ViT) và các biến thể của nó, đã thể hiện hiệu suất đầy hứa hẹn trong nhiều tác vụ thị giác máy tính khác nhau. Tuy nhiên, những kiến trúc mới nổi này gặp phải vấn đề về kích thước mô hình lớn và chi phí tính toán cao, đòi hỏi các giải pháp nén mô hình hiệu quả. Cho đến nay, việc cắt tỉa (pruning) các ViT đã được nghiên cứu kỹ lưỡng, trong khi các chiến lược nén khác đã được áp dụng rộng rãi trong nén CNN, ví dụ như phân tích nhân tử mô hình (model factorization), lại ít được khám phá trong bối cảnh nén ViT. Bài báo này khám phá một phương pháp hiệu quả để nén các vision transformer nhằm làm phong phú bộ công cụ để có được các mô hình thị giác dựa trên attention nhỏ gọn. Dựa trên cái nhìn sâu sắc mới về lớp multi-head attention, chúng tôi phát triển một giải pháp nén ViT cực kỳ hiệu quả, vượt trội hơn các phương pháp cắt tỉa tiên tiến nhất. Đối với việc nén các mô hình DeiT-small và DeiT-base trên ImageNet, phương pháp được đề xuất của chúng tôi có thể đạt được độ chính xác top-1 cao hơn 0.45% và 0.76% ngay cả với ít tham số hơn. Phát hiện của chúng tôi cũng có thể được áp dụng để cải thiện hiệu quả tùy chỉnh của các mô hình khuếch tán text-to-image, với việc huấn luyện nhanh hơn nhiều (tăng tốc lên đến 2.6×) và chi phí lưu trữ thêm thấp hơn (giảm đến 1927.5×) so với các công trình hiện có. Mã nguồn và các mô hình được công khai tại https://github.com/jinqixiao/ComCAT.

1. Giới thiệu

Gần đây, các mô hình thị giác dựa trên attention đã đạt được hiệu suất tương đương hoặc vượt trội so với kiến trúc tập trung vào tích chập trong nhiều tác vụ thị giác máy tính khác nhau, chứng minh lợi ích đầy hứa hẹn mang lại bởi việc sử dụng cơ chế attention (Liu et al., 2021b; Caron et al., 2021; Xie et al., 2021; Carion et al., 2020). Mặt tiêu cực, những kiến trúc mới nổi này, ví dụ như vision transformer (ViT) và các biến thể của nó (Touvron et al., 2021; Liu et al., 2021a; Li et al., 2022), gặp phải vấn đề kích thước mô hình thậm chí lớn hơn và chi phí tính toán cao hơn so với mạng nơ-ron tích chập (CNN), cản trở việc triển khai hiệu quả của chúng trong nhiều tình huống thực tế có hạn chế về tài nguyên.

¹Rutgers University ²Snap Inc. Liên hệ: Jinqi Xiao <jinqi.xiao@rutgers.edu>.

Proceedings of the 40th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s).

Một giải pháp hấp dẫn cho thách thức này là thực hiện nén mô hình, một chiến lược có thể giảm kích thước mạng mà không ảnh hưởng đến hiệu suất tác vụ. Được thúc đẩy bởi thành công to lớn trước đây trong việc nén CNN (Hinton et al., 2015; Han et al., 2015), một số nghiên cứu gần đây (Yin et al., 2023; Yu et al., 2022b; Hou & Kung, 2022) đã đề xuất áp dụng một (ví dụ: cắt tỉa) hoặc kết hợp nhiều (ví dụ: cắt tỉa và chưng cất tri thức) phương pháp nén cho vision transformer, mang lại sự giảm đáng kể về kích thước mô hình và/hoặc FLOP.

Khác với các công trình hiện có, bài báo này nhằm giải quyết thách thức hiệu quả được phân tích ở trên từ một góc độ khác - khám phá tính low-rank của các mô hình thị giác dựa trên attention. Cho đến nay, một bộ kỹ thuật nén low-rank phong phú cho CNN đã được đề xuất trong tài liệu (Kim et al., 2015; Yin et al., 2021; Liebenwein et al., 2021; Yin et al., 2022b;a; Xiao et al., 2023; Xiang et al., 2023). Tuy nhiên, xem xét 1) tồn tại một sự khác biệt đáng kể về kiến trúc mạng và cơ chế hoạt động, ví dụ: multi-head attention trong ViT so với tích chập theo kênh trong CNN; và 2) như được chỉ ra trong (Yu & Wu, 2023) và được xác minh bởi phân tích của chúng tôi, nhiều ma trận trọng số trong vision transformer không thể hiện tính low-rank, vẫn chưa rõ liệu nén low-rank có mang lại cải thiện đáng hài lòng về hiệu quả mô hình hay không. Từ góc độ triển khai thực tế, một câu hỏi tự nhiên nảy sinh: Đối với việc nén các mô hình thị giác dựa trên attention, việc khám phá tính low-rank của mô hình có thể cung cấp hiệu suất tương đương hoặc thậm chí tốt hơn so với các phương pháp khác như cắt tỉa không?

Để trả lời câu hỏi này và khai thác hoàn toàn tiềm năng của nén low-rank cho ViT và các mô hình dựa trên attention, bài báo này đầu tiên điều tra tính low-rank trong lớp multi-head attention, và đề xuất rằng tính low-rank ở mức đầu (head-level), thay vì mức ma trận trọng số, nên được khám phá. Dựa trên cái nhìn sâu sắc mới này, sau đó chúng tôi phát triển một giải pháp nén ViT low-rank cực kỳ hiệu quả với việc lựa chọn rank tự động.

1arXiv:2305.17235v2 [cs.CV] 9 Jun 2023

--- TRANG 2 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác Dựa trên Attention

So với các phương pháp cắt tỉa ViT tiên tiến nhất, phương pháp được đề xuất có thể đạt được độ chính xác top-1 cao hơn 0.45% và 0.76% ngay cả với ít tham số hơn, đối với việc nén các mô hình DeiT-small và DeiT-base trên tập dữ liệu ImageNet, tương ứng. Hơn nữa, phát hiện của chúng tôi cũng có thể được áp dụng để cải thiện hiệu quả cho việc tùy chỉnh các module khuếch tán text-to-image (Ruiz et al., 2022; Kumari et al., 2022), một tác vụ thị giác máy tính mới nổi và quan trọng gần đây, với việc huấn luyện nhanh hơn nhiều (tăng tốc lên đến 2.6×) và chi phí lưu trữ thêm thấp hơn (giảm đến 1927.5×) so với các giải pháp tùy chỉnh tiên tiến nhất.

2. Các Công trình Liên quan

Cắt tỉa cho Vision Transformer. Để giảm kích thước mô hình và đạt được tăng tốc thực tế, việc cắt tỉa có cấu trúc trên các cấu trúc con khác nhau của mô hình ViT, ví dụ: attention head, block, và hàng của ma trận trọng số, đã được nghiên cứu trong tài liệu (Hou & Kung, 2022; Yu et al., 2022b; Zhu et al., 2021; Chen et al., 2021b). Ngoài ra, một hướng nghiên cứu khác đề xuất cải thiện tốc độ xử lý mô hình thông qua việc sử dụng cắt tỉa token động hoặc tĩnh (Bolya et al., 2022; Pan et al., 2021b; Tang et al., 2022; Goyal et al., 2020; Pan et al., 2021a). Gần đây, Yu et al. (Yu et al., 2022b) phát triển một framework thống nhất để thực hiện đồng thời cắt tỉa, chưng cất tri thức và bỏ qua block, đạt được hiệu suất nén ViT tiên tiến nhất.

Nén Low-rank của Ma trận Trọng số (W) trong NLP Transformer. Hầu hết các nghiên cứu hiện có về transformer được nén low-rank tập trung trong lĩnh vực NLP. Noach et al. (Noach & Goldberg, 2020) phân tách các ma trận trọng số của mô hình ngôn ngữ được tiền huấn luyện (PLM) bằng SVD và thực hiện chưng cất đặc trưng để cải thiện hiệu suất mô hình. Ren et al. (Ren et al., 2022) áp dụng phân tách tensor để nén PLM và đạt được tăng tốc suy luận thực tế. Hsu et al. (Hsu et al., 2022) giới thiệu thông tin Fisher để đo tầm quan trọng của tham số nhằm phân tích nhân tử PLM theo tác vụ cụ thể.

Xấp xỉ Low-Rank cho Ma trận Attention (Q, K, V). Một hướng công trình khác là thực hiện xấp xỉ low-rank cho các ma trận attention, kết quả trung gian từ cơ chế attention. Các loại lược đồ xấp xỉ khác nhau, bao gồm thêm ma trận chiếu bổ sung và xấp xỉ thưa, đã được điều tra (Wang et al., 2020; Choromanski et al., 2020; Chen et al., 2021a). Là nỗ lực trực giao với phương pháp của chúng tôi, những phương pháp này không giảm kích thước mô hình của transformer.

Mô hình Khuếch tán Text-to-Image Cá nhân hóa. Các mô hình khuếch tán text-to-image được phát hành gần đây (Rombach et al., 2022; Ramesh et al., 2022; Saharia et al., 2022; Yu et al., 2022a) đã thể hiện khả năng tạo nội dung ấn tượng. Một nhu cầu mới nổi và thực tế rất lớn là làm cho những mô hình được tiền huấn luyện này được tùy chỉnh cho một khái niệm cụ thể do người dùng cung cấp. Để đạt được điều đó, một số nỗ lực tận dụng học chuyển giao thông qua tinh chỉnh tất cả các tham số hoặc giới thiệu một vector từ cho khái niệm mới (Ruiz et al., 2022; Gal et al., 2022). Tuy nhiên, kích thước lớn của các mô hình khuếch tán mang lại thời gian huấn luyện tốn kém và yêu cầu lưu trữ thêm cao trong quá trình tinh chỉnh. Để cải thiện hiệu quả tùy chỉnh, Kumari et al. (Kumari et al., 2022) đề xuất chỉ tinh chỉnh ánh xạ key và value từ văn bản đến đặc trưng tiềm ẩn trong các lớp cross-attention; trong khi đóng băng các phần khác.

3. Phương pháp

3.1. Kiến thức Cơ bản

Phép toán attention có thể được xem như việc ánh xạ từ một query và một tập hợp các cặp key-value đến một đầu ra. Để trích xuất và học thông tin tốt hơn từ các không gian biểu diễn con và vùng không gian khác nhau, các mô hình thị giác dựa trên attention tiên tiến nhất áp dụng multi-head attention (MHA) như sau:

MHA(X_Q, X_K, X_V) = Concat(head_1, ..., head_h)W^O,                    (1)

trong đó X_Q, X_K, X_V ∈ R^{n×d_m} là các ma trận embedding đầu vào, n là độ dài chuỗi, d_m là chiều embedding, và h là số lượng head. Đối với mỗi head i, nó thực hiện phép toán attention như sau:

head_i = Attention(X_Q W_i^Q, X_K W_i^K, X_V W_i^V)
      = Softmax((X_Q W_i^Q (X_K W_i^K)^T) / √d_k) X_V W_i^V,           (2)

trong đó W_i^Q, W_i^K ∈ R^{d_m×d_k}, W_i^V ∈ R^{d_m×d_v}, W^O ∈ R^{hd_v×d_m} là các ma trận trọng số, và d_k và d_v là chiều của X_Q và X_K, tương ứng. Vì d_k = d_v = d_m/h, để đơn giản chúng ta sử dụng d thay vì d_k và d_v.

3.2. Khám phá Tính Low-Rank trong Lớp MHA

Trong tiểu mục này, chúng tôi mô tả MHA low-rank được đề xuất cho các mô hình thị giác hiệu quả. Trước tiên chúng tôi chứng minh tính low-rank của các ma trận trọng số trong mỗi attention head, và phân tích hạn chế khi chỉ tận dụng tính low-rank ở mức ma trận. Dựa trên những quan sát và phân tích này, sau đó chúng tôi đề xuất khám phá tính low-rank ở mức head và xây dựng cơ chế. Chúng tôi tiếp tục chi tiết quy trình sử dụng phát hiện này để cải thiện hiệu quả mô hình trong hai tình huống quan trọng: nén vision transformer và tùy chỉnh mô hình khuếch tán.

Tính Low-Rank của W_i^Q, W_i^K, W_i^V, W^O. Tính low-rank của các ma trận trọng số đã được quan sát rộng rãi trong nhiều loại kiến trúc học sâu bao gồm CNN và NLP transformer (Kim et al., 2015; Ren et al., 2022), truyền cảm hứng cho chúng tôi khám phá sự tồn tại tiềm năng của nó trong các mô hình thị giác dựa trên attention.

2

--- TRANG 3 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác Dựa trên Attention

[Tại đây có biểu đồ nhiệt về các giá trị đơn lẻ tích lũy sau khi thực hiện SVD cho mỗi ma trận trọng số trong các lớp MHA của mô hình DeiT-base được tiền huấn luyện]

Hình 1. Biểu đồ nhiệt của các giá trị đơn lẻ tích lũy sau khi thực hiện SVD cho mỗi ma trận trọng số trong các lớp MHA của mô hình DeiT-base được tiền huấn luyện. Có thể thấy rằng một số ma trận trong một số lớp thể hiện tính low-rank yếu hơn so với những ma trận khác, ngụ ý rằng việc phân tích nhân tử trực tiếp ma trận trọng số riêng lẻ có thể không hiệu quả.

[Biểu đồ về số lượng tham số khi tỷ lệ giá trị đơn lẻ tích lũy đạt 90%]

Hình 2. Số lượng tham số khi tỷ lệ của các giá trị đơn lẻ tích lũy đạt 90% với việc phân tích nhân tử W^Q, W^K, W^V, W^O, và các W^{QK}, W^{VO} tương ứng của DeiT-base được tiền huấn luyện. Có thể thấy rằng khám phá tính low-rank ở mức head hiệu quả hơn về tham số so với mức ma trận.

Để đạt được mục đích đó, chúng tôi phân tích phân phối của các giá trị đơn lẻ của các ma trận trọng số (W_i^Q, W_i^K, W_i^V, W^O) trong mô hình DeiT-base được tiền huấn luyện (Touvron et al., 2021). Hình 1 cho thấy biểu đồ nhiệt của các giá trị đơn lẻ tích lũy sau khi áp dụng Phân tách Giá trị Đơn lẻ (SVD) vào mỗi ma trận trọng số. Có thể thấy rằng hiện tượng hầu hết thông tin tập trung trong một phần của các giá trị đơn lẻ (những giá trị lớn nhất) thực sự tồn tại trong các ma trận trọng số qua các head và lớp khác nhau, cho thấy tiềm năng khám phá tính low-rank của các mô hình dựa trên attention.

Hạn chế của Tính Low-Rank Mức Ma trận. Dựa trên quan sát trên, một ý tưởng tự nhiên là xây dựng mỗi ma trận trọng số (W_i^Q, W_i^K, W_i^V, W_i^O) trong định dạng low-rank riêng của nó. Tuy nhiên, chúng tôi lập luận rằng lợi ích mang lại bởi chiến lược đơn giản này sẽ không đáng kể. Như được thể hiện trong Hình 1, một số loại ma trận trọng số, ví dụ W_i^V, không thể hiện đủ tính low-rank, một hiện tượng cũng được quan sát trong các ma trận của các lớp cao hơn, do đó hạn chế tiềm năng cải thiện hiệu suất tổng thể mang lại bởi phân tích nhân tử low-rank.

Khám phá Tính Low-Rank Mức Head. Để tận dụng tốt hơn tính low-rank trong lớp MHA và khai thác hoàn toàn các lợi ích tiềm năng, chúng tôi đề xuất khám phá thuộc tính low-rank ở mức head cho multi-head attention hiệu quả. Ý tưởng của chúng tôi được thúc đẩy bởi quan sát rằng tồn tại các phép biến đổi tuyến tính liên tiếp trong attention head, ví dụ: X_Q W_i^Q (X_K W_i^K)^T = X_Q(W_i^Q W_i^{KT})X_K^T trong Phương trình 2, mở ra cơ hội xây dựng các tổ hợp của ma trận trọng số, ví dụ: W_i^Q W_i^{KT}, thay vì ma trận riêng lẻ, trong định dạng low-rank. Theo đại số tuyến tính, việc tái cấu trúc như vậy mang lại hai lợi ích.

Thứ nhất, nó cung cấp giải pháp low-rank hiệu quả hơn về tham số. Cụ thể hơn, đối với hai ma trận đầy đủ rank A ∈ R^{n×d} và B ∈ R^{d×n}, tổng số tham số của các xấp xỉ rank-r A' ∈ R^{n×r} và B' ∈ R^{r×n} của chúng là 2nr; trong khi xấp xỉ rank-r tương tự C' ∈ R^{n×r} cho C = AB chỉ chứa nr tham số. Thứ hai, nó nới lỏng các ràng buộc của việc áp dụng xấp xỉ low-rank. Vì tính low-rank của A hoặc B, thay vì cả hai, đã đủ để dẫn đến C low-rank, nó chỉ ra rằng tính low-rank mức head là một cơ hội phổ biến và khả thi hơn khi nhằm tận dụng tính low-rank trong lớp MHA.

Được thúc đẩy bởi những lợi ích này, bây giờ chúng tôi xây dựng ý tưởng của mình trong bối cảnh cơ chế multi-head attention. Đầu tiên Phương trình 1 và Phương trình 2 có thể được tái cấu trúc như:

MHA(X_Q, X_K, X_V) = Σ_{i=1}^h head_i W_i^O
                    = Σ_{i=1}^h Softmax(X_Q(W_i^Q W_i^{KT})X_K^T / √d_k) X_V(W_i^V W_i^O), (3)

trong đó W_i^O ∈ R^{d×d_m} và W^O = Concat(W_1^O, ..., W_h^O).

Nhớ lại rằng một ma trận W ∈ R^{in×out} có thể được xấp xỉ low-rank bằng cách thực hiện SVD như W ≈ W' = UΣS' = US, trong đó U ∈ R^{in×r}, S' ∈ R^{r×out}, ma trận đường chéo Σ ∈ R^{r×r}, S = ΣS' ∈ R^{r×out}, và r là giá trị rank. Sau đó toàn bộ multi-head attention (Phương trình 3) có thể được xây dựng trong định dạng low-rank như:

MHA(X_Q, X_K, X_V) ≈ Σ_{i=1}^h Softmax(X_Q(U_i^Q S_i^{KT})X_K^T / √d_k) X_V(U_i^V S_i^O)
                    = Concat(head'_1, ..., head'_h)W'^O, trong đó

head'_i = Attention(X_Q U_i^Q, X_K S_i^K, X_V U_i^V)
        = Softmax(X_Q U_i^Q (X_K S_i^K)^T / √d_k) X_V U_i^V,

S^O = Concat(S_1^O, ..., S_h^O).                                     (4)

Ở đây W_i^Q W_i^{KT} ≈ U_i^Q S_i^{KT} (rank = r_1), W_i^V W_i^O ≈ U_i^V S_i^O (rank = r_2), U_i^Q, S_i^K ∈ R^{d_m×r_1}, U_i^V, S_i^O ∈ R^{d_m×r_2}, và S^O ∈ R^{hr_2×d_m}.

3

--- TRANG 4 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác Dựa trên Attention

[Hình minh họa: (Trái) Lớp MHA tiêu chuẩn. (Giữa) Phân tích nhân tử trực tiếp các ma trận trọng số riêng lẻ trong lớp MHA. (Phải) Phương pháp được đề xuất của chúng tôi khám phá tính low-rank mức head của lớp MHA.]

Hình 3. (Trái) Lớp MHA tiêu chuẩn. (Giữa) Phân tích nhân tử trực tiếp các ma trận trọng số riêng lẻ trong lớp MHA. (Phải) Phương pháp được đề xuất của chúng tôi khám phá tính low-rank mức head của lớp MHA.

Lưu ý rằng như được thể hiện trong Phương trình 4, ngoài việc khám phá tính low-rank của W_i^{QK} = W_i^Q W_i^{KT}, mối tương quan giữa các ma trận W_i^V và W_i^O cũng được xem xét, mang lại việc xây dựng low-rank cho W_i^{VO} = W_i^V W_i^O. Trong Hình 2, chúng tôi so sánh việc phân tách low-rank trực tiếp của W_i^Q và W_i^K với việc phân tách W_i^Q W_i^{KT} và báo cáo số lượng tham số cần thiết sau khi thực hiện phân tích nhân tử low-rank trong trường hợp tỷ lệ của các giá trị đơn lẻ tích lũy đạt 90%. Bằng cách so sánh số lượng tham số cần thiết để đạt ngưỡng này, chúng ta có thể đánh giá và so sánh tính low-rank của các ma trận gốc, tức là ít tham số hơn cho thấy tính low-rank tốt hơn. Điều này là do để bảo toàn cùng một lượng thông tin, ví dụ: 90% giá trị đơn lẻ tích lũy, ma trận với tính low-rank tốt hơn yêu cầu ít tham số hơn. Như được thể hiện trong hình này, số lượng tham số cần thiết để phân tích nhân tử W_i^Q W_i^{KT} (đường xanh) để đạt ngưỡng 90% luôn nhỏ hơn so với W_i^Q và W_i^K (đường đỏ), cho thấy rằng ma trận tổ hợp thể hiện tính low-rank tốt hơn.

Bảng 1. Độ chính xác Top-1 (không có tinh chỉnh) với việc phân tích nhân tử các ma trận trọng số riêng lẻ ("Mức Ma trận") và các ma trận tổ hợp ("Mức Head") trong lớp attention của mô hình DeiT-small distilled được tiền huấn luyện (độ chính xác gốc là 80.90%).

| # Tham số trong MHA ↓ | 20% | 40% | 60% | 80% |
|----------------------|-----|-----|-----|-----|
| Top-1(%) Mức Head   | 79.81 | 76.11 | 63.56 | 11.5 |
| Mức Ma trận         | 73.01 | 56.15 | 22.95 | 0.73 |

Bảng 1 minh họa lợi ích của cơ chế MHA low-rank mức head như vậy, với ứng dụng của nó cho nén ViT không cần tinh chỉnh làm ví dụ. So với việc áp dụng trực tiếp SVD cho các ma trận trọng số riêng lẻ, phương pháp của chúng tôi mang lại độ chính xác mô hình cao hơn nhiều với cùng tỷ lệ nén, xác minh hai lợi ích (hiệu quả tham số và ràng buộc low-rank nới lỏng) được chỉ ra trong phân tích trước đó của chúng tôi.

MHA Low-Rank cho Nén Vision Transformer. Một ứng dụng trực tiếp của MHA low-rank được đề xuất của chúng tôi là nén vision transformer. Nói chung, đối với một ViT b-block với một lớp MHA và một mạng feedforward 2 lớp (FFN) trên mỗi block, tác vụ nén tương ứng sử dụng MHA low-rank có thể được xây dựng như sau:

min_{W_{i,j}^{QK}, W_{i,j}^{VO}, W_{k,j}^{FFN}} L({W_{i,j}^{QK}, W_{i,j}^{VO}, W_{k,j}^{FFN}})

s.t. Σ_{j=1}^b (Σ_{i=1}^h C(R(W_{i,j}^{QK})) + C(R(W_{i,j}^{VO})) + Σ_{k=1}^2 C(R(W_{k,j}^{FFN}))) ≤ ε, (5)

trong đó L(·), C(·) và R(·) là các hàm trả về loss, cost (ví dụ: kích thước mô hình hoặc FLOP) và rank, tương ứng. W_{i,j}^{QK} = W_{i,j}^Q W_{i,j}^{KT}, W_{i,j}^{VO} = W_{i,j}^V W_{i,j}^O và W_{k,j}^{FFN} là các ma trận tổ hợp của attention head thứ i và ma trận trọng số trong FFN trong block thứ j. Có thể thấy rằng với ngân sách cost mục tiêu (ε) của các ViT được nén, rank là một loại siêu tham số quan trọng trực tiếp quyết định độ chính xác và độ phức tạp. Trong thực tế, do phạm vi lớn của các giá trị rank có thể, việc lựa chọn rank phù hợp cho tất cả các block và lớp của vision transformer là thách thức. Ví dụ, tồn tại 4.53×10^{188} tổ hợp rank khi thực hiện nén low-rank cho mô hình DeiT-small, làm cho việc lựa chọn thủ công không khả thi.

Để giải quyết thách thức này, chúng tôi đề xuất một phương pháp lựa chọn rank tự động để tích hợp hiệu quả MHA low-rank vào nén ViT. Ý tưởng chính của chúng tôi là diễn giải việc lựa chọn rank tự động của nén low-rank như một tìm kiếm kiến trúc mạng nơ-ron (NAS) chuyên biệt, xem xét thực tế rằng việc lựa chọn rank về cơ bản quyết định cấu trúc cuối cùng của ViT được nén. Từ cái nhìn sâu sắc này, giá trị rank phù hợp có thể được xác định thông qua tìm kiếm dựa trên lấy mẫu có thể vi phân, một chiến lược đã được nghiên cứu kỹ trong tài liệu NAS (Liu et al., 2018; Wu et al., 2019; Tan & Le, 2019).

Hình 4 minh họa framework tổng thể cho tìm kiếm rank tự động cho ViT low-rank. Ở đây để ký hiệu đơn giản, chúng tôi sử dụng W*_j ∈ R^{in_j×out_j} để biểu thị các ma trận cần được phân tách trong lớp thứ j, tức là W_{i,j}^{QK}, W_{i,j}^{VO} và W_{k,j}^{FFN}, với tập rank ứng viên là R_j = {r_j^1, r_j^2, r_j^a, ..., r_j^{max}}.

Giả sử r*_j ∈ R_j là rank hiện tại được chọn cho W_j ≈ W*_j = U*_j S*_j (U*_j ∈ R^{in_j×r*_j} và S*_j ∈ R^{r*_j×out_j}). Sau đó chúng tôi luân phiên cập nhật xác suất lựa chọn P_j = {p_j^1, p_j^2, p_j^a, ..., p_j^{max}} cho các ứng viên rank và các tham số của W*_j. Cụ thể, vì P_j được tính toán thông qua GumbelSoftmax (Jang et al., 2016), tức là P_j = GumbelSoftmax(α_j) với vector có thể học α_j, P_j có thể được cập nhật thông qua việc tối thiểu hóa loss sau đây (với các tham số trọng số bị đóng băng):

L_Prob = L_CE(Y, Ŷ) · (∑_{b,j=1}^{P,b} ∑_a p_j^a C(r_j^a) / ε)^β,     (6)

4

--- TRANG 5 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác Dựa trên Attention

[Hình minh họa framework nén vision transformer sử dụng các lớp MHA low-rank và lựa chọn rank tự động]

Hình 4. Nén vision transformer sử dụng các lớp MHA low-rank và lựa chọn rank tự động.

trong đó L_CE(·) là cross-entropy loss, Y là đầu ra cuối cùng của toàn bộ mô hình, Ŷ là ground truth, và β là siêu tham số kiểm soát quá trình tìm kiếm tổng thể. Ở đây như được thể hiện trong Hình 4, việc tính toán Y = Y_b dựa trên việc xem xét tất cả các ứng viên phân tách (U_j^a, S_j^a) với các cài đặt rank khác nhau và xác suất lựa chọn của chúng. Sau khi hoàn thành việc cập nhật xác suất, W*_j trước tiên được phân tích nhân tử thông qua việc sử dụng rank tương ứng với xác suất lựa chọn lớn nhất, và sau đó được cập nhật thông qua việc tối thiểu hóa cross-entropy loss với các xác suất lựa chọn rank bị đóng băng. Các cài đặt rank sau đó có thể được xác định cuối cùng sau nhiều vòng cập nhật luân phiên như vậy giữa xác suất và trọng số.

MHA Low-Rank cho Khuếch tán Text-to-Image Cá nhân hóa. MHA low-rank được đề xuất của chúng tôi cũng có thể được sử dụng để tùy chỉnh hiệu quả khuếch tán text-to-image, một tác vụ thị giác máy tính mới nổi mà mô hình khuếch tán được tiền huấn luyện có thể nhanh chóng tổng hợp các khởi tạo thị giác chất lượng cao của các khái niệm do người dùng định nghĩa với ít ví dụ hình ảnh và prompt văn bản hướng dẫn. Cụ thể hơn, cho một mô hình khuếch tán được tiền huấn luyện {W_diff} đã được huấn luyện tốt trên tập hình ảnh {x} và tập vector điều kiện {c} thu được từ text prompt, chúng tôi nhằm tối thiểu hóa loss sau đây:

E_{ε,x_new,c_new,t}[w_t ||{W_new}(α_t x_new + σ_t ε, c_new) - x_new||_2^2],     (7)

trong đó α_t, σ_t và w_t là hàm của timestep t kiểm soát quá trình khuếch tán, và x_new và c_new biểu thị các hình ảnh và text prompt do người dùng cung cấp, tương ứng, với |{x_new}| ≪ |{x}| và |{c_new}| ≪ |{c}|. Lưu ý rằng ở đây {W_new} được khởi tạo như f({W_diff}), trong đó f(·) có thể là hàm đồng nhất, có nghĩa là mô hình cá nhân hóa {W_new} được khởi tạo trực tiếp như {W_diff} được tiền huấn luyện, hoặc hàm biến đổi, cho thấy rằng việc khởi tạo cho {W_new} là sự sửa đổi của {W_diff}.

Như được chỉ ra trong (Kumari et al., 2022), việc cập nhật toàn bộ {W_new} rất không hiệu quả về mặt tính toán và dễ gây ra overfitting, do kích thước lớn của {W_diff} và kích thước nhỏ của {x_new}. Được truyền cảm hứng bởi những hiểu biết rằng 1) chỉ thay đổi một vài tham số là đủ để làm cho các mô hình khuếch tán học được khái niệm do người dùng định nghĩa (Kumari et al., 2022); và 2) thêm thành phần low-rank là một chiến lược tinh chỉnh hiệu quả cho các mô hình ngôn ngữ lớn (LLM) trong các tác vụ NLP (Aghajanyan et al., 2020), chúng tôi đề xuất sử dụng MHA low-rank để cải thiện hiệu quả triển khai của khuếch tán text-to-image cá nhân hóa. Hình 5 minh họa framework tổng thể. Cụ thể hơn, lớp MHA của mô hình cá nhân hóa được khởi tạo như:

MHA(X_Q, X_K, X_V) = Σ_{i=1}^h Softmax(X_Q(W_i^Q W_i^{KT} + U_i^Q S_i^{KT})X_K^T / √d_k) X_V(W_i^V W_i^O + (U_i^V S_i^O))     (8)

trong đó {W_i^Q, W_i^K, W_i^V, W_i^O} được thu được từ mô hình khuếch tán được tiền huấn luyện {W_diff}, và {U_i^Q, S_i^K, U_i^V, S_i^O} là các thành phần low-rank được khởi tạo ngẫu nhiên. Như được thể hiện trong Hình 5, trong quá trình tùy chỉnh mô hình, tất cả các tham số của mô hình được tiền huấn luyện {W_diff} bị đóng băng; trong khi tính toán của chúng tuân theo cơ chế được mô tả trong MHA low-rank được đề xuất của chúng tôi. Trong khi đó, thành phần low-rank được thêm vào U_i^Q, S_i^K, U_i^V và S_i^O được cập nhật để làm cho W_new thích ứng với các khái niệm mới do người dùng cung cấp.

4. Thí nghiệm

4.1. Phân loại Hình ảnh trên ImageNet-1K

Cài đặt. Trước tiên chúng tôi xác thực phương pháp của mình trên tập dữ liệu ImageNet-1K (Deng et al., 2009) cho tác vụ phân loại hình ảnh. Tập dữ liệu bao gồm 1.2M hình ảnh huấn luyện và 50K mẫu validation. Chúng tôi áp dụng các mô hình baseline, tức là mạng dày đặc không có nén, và công thức huấn luyện từ DeiT (Touvron et al., 2021) vì chúng cho thấy kết quả đầy hứa hẹn trong việc huấn luyện các mô hình transformer chỉ bằng cách sử dụng ImageNet-1K mà không có các tập dữ liệu quy mô lớn khác để tiền huấn luyện và do đó được áp dụng rộng rãi. Chúng tôi so sánh phương pháp của mình với các phương pháp nén ViT tiên tiến nhất trước đây, bao gồm low-rank (Yu & Wu, 2023), cắt tỉa mô hình (Hou & Kung, 2022; Yu et al., 2022b; Zhu et al., 2021; Tang et al., 2020), huấn luyện thưa (Chen et al., 2021b) và cắt tỉa token (Bolya et al., 2022; Pan et al., 2021b; Tang et al., 2022; Goyal et al., 2020; Pan et al., 2021a).

5

--- TRANG 6 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác Dựa trên Attention

[Hình minh họa tùy chỉnh mô hình khuếch tán text-to-image sử dụng cơ chế MHA low-rank]

Hình 5. Tùy chỉnh mô hình khuếch tán text-to-image sử dụng cơ chế MHA low-rank. Đặc trưng hình ảnh tiềm ẩn x_new tương ứng với X_Q và đặc trưng văn bản c_new tương ứng với X_K và X_V.

[Bảng 2: So sánh giữa phương pháp của chúng tôi và các phương pháp khác nhau, bao gồm cắt tỉa mô hình, huấn luyện thưa và giảm token, để nén DeiT-small và DeiT-base trên ImageNet]

Chi tiết Triển khai. Toàn bộ quá trình của phương pháp chúng tôi bao gồm hai bước: tìm kiếm rank và tinh chỉnh. Chúng tôi tiến hành thuật toán lựa chọn rank tự động cho mô hình DeiT được tiền huấn luyện để tạo ra mô hình low-rank dưới ràng buộc đã cho. Trong quá trình tinh chỉnh, learning rate ban đầu được đặt là 0.0001 và giảm xuống learning rate tối thiểu là 0.000001 với Cosine scheduler. Weight decay để huấn luyện DeiT-small được nén được đặt là 0.005. Phần còn lại của các siêu tham số huấn luyện nhất quán với DeiT (Touvron et al., 2021).

[Hình 6: So sánh lựa chọn rank thủ công (đường đỏ) và phương pháp lựa chọn rank tự động được đề xuất của chúng tôi (đường xanh) cho DeiT-small trên tập dữ liệu ImageNet-1K]

[Hình 7: Ảnh hưởng của các giá trị beta khác nhau đến việc tìm kiếm rank của mô hình DeiT-small]

Kết quả So sánh. Bảng 2 cho thấy hiệu suất của các phương pháp nén khác nhau trên tập dữ liệu ImageNet. So với phương pháp cắt tỉa tự động tiên tiến nhất trước đây UVC (Yu et al., 2022b), các mô hình được nén của chúng tôi có độ chính xác top-1 cao hơn 0.45% và 1.69% với việc giảm FLOP lớn hơn nhiều trên DeiT-small và DeiT-base, tương ứng. Ngoài ra, phương pháp của chúng tôi có thể giảm đáng kể các tham số mô hình, tức là giảm 49.98% cho DeiT-small và 61.06% cho DeiT-base, trong khi mô hình được nén từ UVC (Yu et al., 2022b) thì không thể. So với công trình low-rank của CT-GFM (Yu & Wu, 2023), phương pháp của chúng tôi đạt được tăng độ chính xác 0.98% với số lượng tham số ít hơn nhiều. So với công trình huấn luyện thưa của S2ViTE (Chen et al., 2021b), với độ chính xác top-1 tương tự, chúng tôi đạt được việc giảm FLOP lớn hơn nhiều là 19.58% và 28.55% và giảm tham số là 16.04% và 26.65% trên DeiT-small và DeiT-base, tương ứng. So với công trình của PS-ViT (Tang et al., 2022) để giảm token, phương pháp của chúng tôi cũng đạt được độ chính xác top-1 cao hơn là 0.18% và 0.76% với FLOP và tham số mô hình ít hơn nhiều trên DeiT-small và DeiT-base, tương ứng.

Tăng tốc Thực tế trên Các Nền tảng Phần cứng Khác nhau. Chúng tôi tiếp tục đo lường tăng tốc thực tế của các mô hình được nén của chúng tôi trên các nền tảng phần cứng tính toán khác nhau, bao gồm Nvidia Tesla V100, Nvidia Jetson TX2, điện thoại di động Android (Snapdragon 855, 4 Cortex-A76 + 4 Cortex-A55), bộ tăng tốc ASIC Eyeriss (Chen et al., 2016), và FPGA (PYNQ Z1) trong Bảng 3. Ở đây hiệu suất của Eyeriss được báo cáo thông qua việc sử dụng Timeloop (Parashar et al., 2019) với cài đặt công nghệ CMOS 45nm. Các mô hình DeiT-small và DeiT-base được nén của chúng tôi đạt được tăng tốc đáng kể trên các nền tảng khác nhau. Ví dụ, trên Snapdragon 855, DeiT-base được nén của chúng tôi đạt được tăng tốc 2.52× so với mô hình baseline với độ chính xác top-1 thậm chí cao hơn trên ImageNet. Những kết quả như vậy chứng minh hiệu quả thực tế của giải pháp nén low-rank của chúng tôi.

4.2. Phân tích Ablation cho Nén ViT Low-Rank

Lựa chọn Rank Tự động so với Lựa chọn Rank Thủ công. Để chứng minh tính vượt trội của phương pháp lựa chọn rank tự động của chúng tôi, chúng tôi so sánh nó với phương pháp rank cố định. Hình 6 cho thấy các đường cong biến thiên của độ chính xác top-1 trên ImageNet-1K và số lượng tham số cho cả hai phương pháp trong quá trình huấn luyện. Phương pháp của chúng tôi có mất mát độ chính xác nhỏ hơn, và số lượng tham số của mô hình dần hội tụ về giá trị mục tiêu (10.5M). Ngược lại, mô hình dựa trên phân tách rank cố định mất nhiều độ chính xác hơn từ đầu, dẫn đến hiệu suất kém. Do đó, chúng ta có thể kết luận rằng phương pháp của chúng tôi có thể tìm kiếm một tổ hợp rank tốt hơn dưới các ràng buộc.

Siêu tham số cho Tìm kiếm Rank. Chúng tôi cũng khám phá ảnh hưởng của siêu tham số β được đề cập trong Phương trình 6 đến quá trình tìm kiếm rank. Hình 7 cho thấy sự hội tụ của quá trình tìm kiếm đối với β khác nhau. Có thể thấy rằng khi β ≥ 1, số lượng tham số của mô hình có thể hội tụ về giá trị mục tiêu nhanh chóng, và độ chính xác cuối cùng của các mô hình về cơ bản là giống nhau. Tuy nhiên, khi β = 1.5, đường cong độ chính xác của mô hình tương đối mượt mà, do đó, chúng tôi nghĩ 1.5 là một giá trị tương đối tốt hơn cho β. Phân phối rank cuối cùng của DeiT-small và DeiT-base được thể hiện trong Hình 8 và Hình 9.

SVD so với Phân tách Tensor Bậc cao hơn. Đối với nén ViT, ngoài MHA, chúng tôi áp dụng nén low-rank cho FFN (Feed-Forward Network), và việc lựa chọn rank cho FFN cũng được bao gồm trong cơ chế xác định rank tự động được đề xuất của chúng tôi. Để tìm phương pháp phân tách low-rank tối ưu từ các phương pháp phân tách low-rank khác nhau như SVD, phân tách Tucker, phân tách Tensor Train, chúng tôi đánh giá độ chính xác Top-1 và throughput trên GPU cho DeiT-Small được nén trên tập dữ liệu ImageNet khi nén FFN sử dụng các phương pháp low-rank khác nhau. Như được thể hiện trong Bảng 4, với cùng tỷ lệ nén, việc sử dụng SVD mang lại độ chính xác cao hơn (không có tinh chỉnh) so với việc sử dụng phân tách Tucker và phân tách Tensor Train với throughput tốt hơn trên GPU.

4.3. Mô hình Khuếch tán Text-to-Image Cá nhân hóa

Cài đặt. Chúng tôi tinh chỉnh lớp cross-attention của Stable Diffusion được tiền huấn luyện (Rombach et al., 2022) (trọng số mô hình thu được từ HuggingFace Hub (Wolf et al., 2019)) bằng cách sử dụng cơ chế MHA low-rank được đề xuất của chúng tôi để cho phép mô hình học một khái niệm mới. Đối với đánh giá định lượng, chúng tôi sử dụng sáu đối tượng được bao gồm trong tập dữ liệu được phát hành bởi CustomDiffusion (Kumari et al., 2022) và một đối tượng mới được thu thập, với số lượng hình ảnh chứa trong mỗi đối tượng từ 4 đến 12.

So sánh Chi phí Huấn luyện. Trước tiên chúng tôi trình bày chi phí huấn luyện được yêu cầu bởi tất cả các phương pháp trong Bảng 5. Chúng tôi huấn luyện tất cả các phương pháp trên một GPU Nvidia RTX A6000 với batch size là 1 và số bước huấn luyện là 500. So với CustomDiffusion và DreamBooth, phương pháp của chúng tôi giảm thời gian huấn luyện lần lượt 18.6% và 61.6% (xem Thời gian Huấn luyện trong Bảng 5), và giảm không gian lưu trữ thêm cho mỗi khái niệm lần lượt 12.5× và 1927.5× (xem Lưu trữ Thêm trong Bảng 5). Việc giảm theo bậc độ lớn của lưu trữ thêm cho mỗi khái niệm mới là cực kỳ quan trọng đối với việc áp dụng rộng rãi các mô hình khuếch tán text-to-image cá nhân hóa, nơi người dùng có thể chuẩn bị mô hình khuếch tán của họ mà không gánh nặng lưu trữ mô hình.

So sánh Chất lượng Hình ảnh. Sau đó chúng tôi đánh giá chất lượng của các hình ảnh được tổng hợp cho tất cả các phương pháp. Chúng tôi tạo ra 20 hình ảnh cho mỗi hình ảnh mục tiêu đã học (khái niệm) bằng cách sử dụng cùng một text prompt cho tất cả các phương pháp và tính toán FID (Heusel et al., 2017; Parmar et al., 2021) giữa các hình ảnh được tổng hợp và thực. Điểm FID thấp hơn chỉ ra sự khác biệt nhỏ hơn giữa các hình ảnh được tạo và thực. Như được thể hiện trong Bảng 5, phương pháp của chúng tôi đạt được FID thấp nhất so với các công trình hiện có. Chúng tôi tiếp tục cung cấp so sánh định tính trong Hình 10. Ngoài việc tạo ra các cảnh tương ứng một cách chính xác từ text prompt, V* Goldendoodle được tạo bởi phương pháp của chúng tôi gần nhất với hình ảnh thực, trong khi V* Goldendoodle được tổng hợp bởi DreamBooth (Ruiz et al., 2022) có sự khác biệt rõ ràng so với hình ảnh thực, và hình ảnh được tổng hợp từ CustomDiffusion (Kumari et al., 2022) chứa miệng ít tự nhiên vì nó đã bị biến dạng. Trong Hình 11, chúng tôi tiếp tục cho thấy rằng ngay cả với ít tài nguyên tính toán hơn nhiều, tức là ít thời gian huấn luyện hơn và ít GPU hơn để tinh chỉnh mô hình, chúng tôi vẫn có thể tạo ra hình ảnh chất lượng cao.

Đánh giá MS-COCO. Cuối cùng, chúng tôi thực hiện các thí nghiệm để hiểu liệu các mô hình được tinh chỉnh có thể tạo ra hình ảnh không liên quan đến chủ thể mục tiêu đã học (V*) hay không. Chúng tôi sử dụng văn bản được nhắc nhở của 5,000 hình ảnh từ tập validation MS-COCO 2017 (Lin et al., 2014) để tạo hình ảnh và tính toán FID. Như được thể hiện trong Bảng 6, FID từ các mô hình cá nhân hóa tương tự như mô hình text-to-image được tiền huấn luyện, cho thấy rằng chúng có thể tổng hợp hình ảnh chất lượng cao cho các khái niệm không liên quan. Do đó, mô hình được tinh chỉnh bởi phương pháp của chúng tôi vẫn giữ phân phối của các hình ảnh được tổng hợp như mô hình được tiền huấn luyện.

5. Kết luận

Bài báo này điều tra cơ bản tính low-rank trong lớp multi-head attention của các mô hình thị giác mới nổi và đề xuất rằng tính low-rank mức head nên được khám phá để thiết kế mô hình hiệu quả, mang lại giải pháp nén ViT low-rank cực kỳ hiệu quả. Phương pháp của chúng tôi không chỉ vượt trội hơn các phương pháp nén hiện có bằng cách cung cấp hiệu suất cao hơn mà còn mang lại tăng tốc thực tế nhanh hơn. Đặc biệt, phát hiện của chúng tôi được áp dụng thêm cho việc tùy chỉnh hiệu quả các mô hình khuếch tán text-to-image, vượt trội hơn các giải pháp tiên tiến nhất.

6. Lời cảm ơn

Công trình này được hỗ trợ một phần bởi National Science Foundation dưới Grant CCF-1937403 và CCF-1955909.

--- TRANG 10 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác Dựa trên Attention

Tài liệu tham khảo

[Danh sách đầy đủ các tài liệu tham khảo từ trang 958-1187, bao gồm tất cả các công trình nghiên cứu được trích dẫn trong bài báo]

12
>>>>>>> Stashed changes

# 2305.17235.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2305.17235.pdf
# Kích thước tệp: 11921721 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
COMCAT: Hướng tới Nén và Tùy chỉnh Hiệu quả cho Các Mô hình Thị giác dựa trên Attention
Jinqi Xiao1Miao Yin1Yu Gong1Xiao Zang1Jian Ren2Bo Yuan1

Tóm tắt
Các mô hình thị giác dựa trên attention, như Vision Transformer (ViT) và các biến thể của nó, đã cho thấy hiệu suất đầy hứa hẹn trong các nhiệm vụ thị giác máy tính khác nhau. Tuy nhiên, các kiến trúc mới nổi này gặp phải vấn đề về kích thước mô hình lớn và chi phí tính toán cao, đòi hỏi các giải pháp nén mô hình hiệu quả. Cho đến nay, việc tỉa ViT đã được nghiên cứu kỹ lưỡng, trong khi các chiến lược nén khác đã được áp dụng rộng rãi trong nén CNN, ví dụ như phân tích nhân tử mô hình, ít được khám phá trong bối cảnh nén ViT. Bài báo này khám phá một phương pháp hiệu quả để nén vision transformer nhằm làm phong phú bộ công cụ để có được các mô hình thị giác dựa trên attention nhỏ gọn. Dựa trên hiểu biết mới về lớp multi-head attention, chúng tôi phát triển một giải pháp nén ViT hiệu quả cao, vượt trội hơn các phương pháp tỉa tiên tiến nhất. Để nén các mô hình DeiT-small và DeiT-base trên ImageNet, phương pháp đề xuất của chúng tôi có thể đạt được độ chính xác top-1 cao hơn 0.45% và 0.76% thậm chí với ít tham số hơn. Phát hiện của chúng tôi cũng có thể được áp dụng để cải thiện hiệu quả tùy chỉnh của các mô hình khuếch tán text-to-image, với việc huấn luyện nhanh hơn nhiều (tăng tốc lên đến 2.6×) và chi phí lưu trữ bổ sung thấp hơn (giảm lên đến 1927.5×) so với các công trình hiện có. Mã nguồn và mô hình được công bố tại https://github.com/jinqixiao/ComCAT.

1. Giới thiệu
Gần đây, các mô hình thị giác dựa trên attention đã đạt được hiệu suất tương đương hoặc vượt trội hơn so với kiến trúc tập trung vào convolution trong các nhiệm vụ thị giác máy tính khác nhau, chứng minh lợi ích đầy hứa hẹn mang lại bởi việc sử dụng cơ chế attention (Liu et al., 2021b; Caron et al., 2021; Xie et al., 2021; Carion et al., 2020). Mặt trái, các kiến trúc mới nổi này, ví dụ như vision transformer (ViT) và các biến thể của nó (Touvron et al., 2021; Liu et al., 2021a; Li et al., 2022), gặp phải vấn đề về kích thước mô hình thậm chí lớn hơn và chi phí tính toán cao hơn so với mạng neural tích chập (CNN), cản trở việc triển khai hiệu quả của chúng trong nhiều tình huống thực tế có hạn chế về tài nguyên.

Một giải pháp hấp dẫn cho thách thức này là thực hiện nén mô hình, một chiến lược có thể giảm kích thước mạng mà không ảnh hưởng đến hiệu suất nhiệm vụ. Được thúc đẩy bởi thành công to lớn trước đó của việc nén CNN (Hinton et al., 2015; Han et al., 2015), một số nghiên cứu gần đây (Yin et al., 2023; Yu et al., 2022b; Hou & Kung, 2022) đã đề xuất áp dụng một (ví dụ: tỉa) hoặc kết hợp nhiều (ví dụ: tỉa và chưng cất kiến thức) phương pháp nén cho vision transformer, mang lại việc giảm đáng kể kích thước mô hình và/hoặc FLOP.

Khác với các công trình hiện có, bài báo này nhằm giải quyết thách thức hiệu quả đã phân tích ở trên từ một góc độ khác - khám phá tính low-rank của các mô hình thị giác dựa trên attention. Cho đến nay, một tập hợp phong phú các kỹ thuật nén low-rank cho CNN đã được đề xuất trong tài liệu (Kim et al., 2015; Yin et al., 2021; Liebenwein et al., 2021; Yin et al., 2022b;a; Xiao et al., 2023; Xiang et al., 2023). Tuy nhiên, xét 1) tồn tại sự khác biệt đáng kể về kiến trúc mạng và cơ chế hoạt động, ví dụ như multi-head attention trong ViT so với convolution theo kênh trong CNN; và 2) như được chỉ ra trong (Yu & Wu, 2023) và được xác minh bởi phân tích của chúng tôi, nhiều ma trận trọng số trong vision transformer không thể hiện tính low-rank, không rõ liệu nén low-rank có thể mang lại cải thiện thỏa mãn về hiệu quả mô hình hay không. Từ quan điểm triển khai thực tế, một câu hỏi tự nhiên nảy sinh: Để nén các mô hình thị giác dựa trên attention, việc khám phá tính low-rank của mô hình có thể cung cấp hiệu suất tương đương hoặc thậm chí tốt hơn so với các phương pháp khác như tỉa không?

Để trả lời câu hỏi này và hoàn toàn khai thác tiềm năng của nén low-rank cho ViT và các mô hình dựa trên attention, bài báo này đầu tiên điều tra tính low-rank trong lớp multi-head attention, và đề xuất rằng tính low-rank ở mức head, thay vì mức ma trận trọng số, nên được khám phá. Dựa trên hiểu biết mới này, chúng tôi sau đó phát triển một giải pháp nén ViT low-rank hiệu quả cao với lựa chọn rank tự động. So với các phương pháp tỉa ViT tiên tiến nhất, phương pháp đề xuất có thể đạt được độ chính xác top-1 cao hơn 0.45% và 0.76% thậm chí với ít tham số hơn, để nén các mô hình DeiT-small và DeiT-base trên tập dữ liệu ImageNet, tương ứng. Hơn nữa, phát hiện của chúng tôi cũng có thể được áp dụng để cải thiện hiệu quả tùy chỉnh các mô-đun khuếch tán text-to-image (Ruiz et al., 2022; Kumari et al., 2022), một nhiệm vụ thị giác máy tính mới nổi và quan trọng gần đây, với việc huấn luyện nhanh hơn nhiều (tăng tốc lên đến 2.6×) và chi phí lưu trữ bổ sung thấp hơn (giảm lên đến 1927.5×) so với các giải pháp tùy chỉnh tiên tiến nhất.

2. Các Công trình Liên quan
Tỉa cho Vision Transformer. Để giảm kích thước mô hình và đạt được tăng tốc thực tế, việc tỉa có cấu trúc trên các cấu trúc con khác nhau của mô hình ViT, ví dụ như attention head, block và hàng của ma trận trọng số, đã được nghiên cứu trong tài liệu (Hou & Kung, 2022; Yu et al., 2022b; Zhu et al., 2021; Chen et al., 2021b). Ngoài ra, một hướng nghiên cứu khác đề xuất cải thiện tốc độ xử lý mô hình thông qua việc sử dụng tỉa token động hoặc tĩnh (Bolya et al., 2022; Pan et al., 2021b; Tang et al., 2022; Goyal et al., 2020; Pan et al., 2021a). Gần đây, Yu et al. (Yu et al., 2022b) phát triển một khung thống nhất để thực hiện đồng thời tỉa, chưng cất kiến thức và bỏ qua block, đạt được hiệu suất nén ViT tiên tiến nhất.

Nén Low-rank của Ma trận Trọng số (W) trong Transformer NLP. Hầu hết các nghiên cứu hiện có về transformer nén low-rank tập trung trong lĩnh vực NLP. Noach et al. (Noach & Goldberg, 2020) phân tích các ma trận trọng số của các mô hình ngôn ngữ đã được huấn luyện trước (PLM) bằng SVD và thực hiện chưng cất đặc trưng để cải thiện hiệu suất mô hình. Ren et al. (Ren et al., 2022) áp dụng phân tích tensor để nén PLM và đạt được tăng tốc suy luận thực tế. Hsu et al. (Hsu et al., 2022) giới thiệu thông tin Fisher để đo tầm quan trọng của các tham số để phân tích nhân tử PLM cụ thể cho nhiệm vụ.

Xấp xỉ Low-Rank cho Ma trận Attention (Q, K, V). Một dòng công trình khác là thực hiện xấp xỉ low-rank cho các ma trận attention, các kết quả trung gian từ cơ chế attention. Các loại sơ đồ xấp xỉ khác nhau, bao gồm thêm các ma trận chiếu bổ sung và xấp xỉ thưa thớt, đã được điều tra (Wang et al., 2020; Choromanski et al., 2020; Chen et al., 2021a). Là nỗ lực trực giao với phương pháp của chúng tôi, các phương pháp này không giảm kích thước mô hình của transformer.

Mô hình Khuếch tán Text-to-Image Cá nhân hóa. Các mô hình khuếch tán text-to-image được phát hành gần đây (Rombach et al., 2022; Ramesh et al., 2022; Saharia et al., 2022; Yu et al., 2022a) đã cho thấy khả năng tạo nội dung ấn tượng. Một nhu cầu rất mới nổi và thực tế là làm cho các mô hình đã được huấn luyện trước này được tùy chỉnh cho một khái niệm cụ thể do người dùng cung cấp. Để đạt được điều đó, một số nỗ lực tận dụng transfer learning thông qua fine-tuning tất cả các tham số hoặc giới thiệu một vector từ cho khái niệm mới (Ruiz et al., 2022; Gal et al., 2022). Tuy nhiên, kích thước lớn của các mô hình khuếch tán mang lại thời gian huấn luyện tốn kém và yêu cầu lưu trữ bổ sung cao trong quá trình fine-tuning. Để cải thiện hiệu quả tùy chỉnh, Kumari et al. (Kumari et al., 2022) đề xuất chỉ fine-tune việc ánh xạ key và value từ văn bản sang các đặc trưng tiềm ẩn trong các lớp cross-attention; trong khi đóng băng các phần khác.

3. Phương pháp
3.1. Kiến thức Cơ bản
Phép toán attention có thể được xem như việc ánh xạ từ một query và một tập hợp các cặp key-value đến một đầu ra. Để tốt hơn trong việc trích xuất và học thông tin từ không gian biểu diễn và các vùng không gian khác nhau, các mô hình thị giác dựa trên attention tiên tiến nhất áp dụng multi-head attention (MHA) như:

MHA(XQ, XK, XV) = Concat(head1, ..., headh)WO,(1)

trong đó XQ, XK, XV∈Rn×dm là các ma trận nhúng đầu vào, n là độ dài chuỗi, dm là chiều nhúng, và h là số lượng head. Đối với mỗi head i, nó thực hiện phép toán attention như sau:

headi = Attention(XQWQi, XKWKi, XVWVi)
= Softmax(XQWQi(XKWKi)T/√dk)XVWVi,(2)

trong đó WQi, WKi∈Rdm×dk, WVi∈Rdm×dv, WO∈Rhdv×dm là các ma trận trọng số, và dk và dv là chiều của XQ và XK, tương ứng. Vì dk = dv = dm/h, để đơn giản chúng tôi sử dụng d thay vì dk và dv.

3.2. Khám phá Tính Low-Rankness trong Lớp MHA
Trong tiểu mục này, chúng tôi mô tả MHA low-rank đề xuất của chúng tôi để có các mô hình thị giác hiệu quả. Chúng tôi đầu tiên chứng minh tính low-rankness của các ma trận trọng số trong mỗi attention head, và phân tích hạn chế khi chỉ tận dụng tính low-rankness ở cấp độ ma trận. Dựa trên những quan sát và phân tích này, chúng tôi sau đó đề xuất khám phá tính low-rankness ở cấp độ head và hình thành cơ chế. Chúng tôi tiếp tục chi tiết quy trình sử dụng phát hiện này để cải thiện hiệu quả mô hình trong hai tình huống quan trọng: nén vision transformer và tùy chỉnh mô hình khuếch tán.

Tính Low-Rankness của WQi, WKi, WVi, WO. Tính low-rankness của các ma trận trọng số đã được quan sát rộng rãi trong nhiều loại kiến trúc deep learning bao gồm CNN và NLP transformer (Kim et al., 2015; Ren et al., 2022), truyền cảm hứng cho chúng tôi khám phá sự tồn tại tiềm năng của nó trong các mô hình thị giác dựa trên attention. Để làm điều đó, chúng tôi phân tích phân phối của các giá trị singular của các ma trận trọng số (WQi, WKi, WVi, WO) trong mô hình DeiT-base đã được huấn luyện trước (Touvron et al., 2021). Hình 1 cho thấy bản đồ nhiệt của các giá trị singular tích lũy sau khi áp dụng Phân tích Giá trị Singular (SVD) vào mỗi ma trận trọng số. Có thể thấy rằng hiện tượng hầu hết thông tin tập trung trong một phần các giá trị singular (những cái lớn nhất) thực sự tồn tại trong các ma trận trọng số qua các head và lớp khác nhau, cho thấy tiềm năng của việc khám phá tính low-rank của các mô hình dựa trên attention.

Hạn chế của Tính Low-Rankness Cấp Ma trận. Dựa trên quan sát trên, một ý tưởng tự nhiên là xây dựng mỗi ma trận trọng số (WQi, WKi, WVi, WOi) trong định dạng low-rank riêng của nó. Tuy nhiên, chúng tôi lập luận rằng lợi ích mang lại bởi chiến lược trực tiếp này sẽ không đáng kể. Như được thể hiện trong Hình 1, một số loại ma trận trọng số, ví dụ WVi, không thể hiện tính low-rank đủ, một hiện tượng cũng được quan sát trong các ma trận của các lớp cao hơn, do đó hạn chế tiềm năng cải thiện hiệu suất tổng thể mang lại bởi phân tích nhân tử low-rank.

Khám phá Tính Low-Rankness Cấp Head. Để tận dụng tốt hơn tính low-rank trong lớp MHA và hoàn toàn khai thác các lợi ích tiềm năng, chúng tôi đề xuất khám phá tính chất low-rank ở cấp độ head để có multi-head attention hiệu quả. Ý tưởng của chúng tôi được thúc đẩy bởi quan sát rằng tồn tại các phép biến đổi tuyến tính liên tiếp trong attention head, ví dụ XQWQi(XKWKi)T = XQ(WQiWKiT)XTK trong Eq. 2, mở ra cơ hội xây dựng các kết hợp của ma trận trọng số, ví dụ WQiWKiT, thay vì ma trận riêng lẻ, trong định dạng low-rank. Theo đại số tuyến tính, việc tái cấu trúc như vậy mang lại hai lợi ích. Thứ nhất, nó cung cấp giải pháp low-rank tiết kiệm tham số hơn. Cụ thể hơn, đối với hai ma trận full-rank A∈Rn×d và B∈Rd×n, tổng số tham số của các xấp xỉ rank-r A′∈Rn×r và B′∈Rr×n của chúng là 2nr; trong khi cùng xấp xỉ rank-r C′∈Rn×r cho C = AB chỉ chứa nr tham số. Thứ hai, nó nới lỏng các ràng buộc của việc áp dụng xấp xỉ low-rank. Vì tính low-rank của A hoặc B, thay vì cả hai, đã đủ để dẫn đến C low-rank, nó chỉ ra rằng tính low-rank cấp head là một cơ hội phổ biến và khả thi hơn khi nhằm tận dụng tính low-rank trong lớp MHA.

Được thúc đẩy bởi những lợi ích này, bây giờ chúng tôi hình thành ý tưởng của mình trong bối cảnh cơ chế multi-head attention. Đầu tiên Eq. 1 và Eq. 2 có thể được tái cấu trúc như:

MHA(XQ, XK, XV) = Σi=1h headi WOi
= Σi=1h Softmax(XQ(WQiWKiT)XTK/√dk)XV(WViWOi),(3)

trong đó WOi∈Rd×dm và WO = Concat(WO1, ..., WOh).

Nhớ lại rằng một ma trận W∈Rin×out có thể được xấp xỉ low-rank bằng cách thực hiện SVD như W ≈ W′ = UΣS′ = US, trong đó U∈Rin×r, S′∈Rr×out, ma trận đường chéo Σ∈Rr×r, S = ΣS′∈Rr×out, và r là giá trị rank. Sau đó toàn bộ multi-head attention (Eq. 3) có thể được xây dựng trong định dạng low-rank như:

MHA(XQ, XK, XV)
≈ Σi=1h Softmax(XQ(UQiSKiT)XTK/√dk)XV(UViSOi)
= Concat(head′1, ..., head′h)W′O, trong đó
head′i = Attention(XQUQi, XKSKi, XVUVi)
= Softmax(XQUQi(XKSKi)T/√dk)XVUVi,
SO = Concat(SO1, ..., SOh).(4)

Ở đây WQiWKiT ≈ UQiSKiT (rank = r1), WViWOi ≈ UViSOi (rank = r2), UQi, SKi∈Rdm×r1, UVi, SOi∈Rdm×r2, và SO∈Rhr2×dm.

Lưu ý rằng như được thể hiện trong Eq. 4, ngoài việc khám phá tính low-rank của WQKi = WQiWKiT, mối tương quan giữa các ma trận giữa WVi và WOi cũng được xem xét, mang lại cấu trúc low-rank cho WVOi = WViWOi. Trong Hình 2, chúng tôi so sánh phân tích low-rank trực tiếp của WQi và WKi với phân tích của WQiWKiT và báo cáo số lượng tham số cần thiết sau khi thực hiện phân tích nhân tử low-rank trong trường hợp tỷ lệ các giá trị singular tích lũy đạt 90%. Bằng cách so sánh số lượng tham số cần thiết để đạt ngưỡng này, chúng tôi có thể đánh giá và so sánh tính low-rank của các ma trận gốc, tức là ít tham số hơn chỉ ra tính low-rank tốt hơn. Điều này là bởi vì để bảo tồn cùng một lượng thông tin, ví dụ 90% giá trị singular tích lũy, ma trận có tính low-rank tốt hơn yêu cầu ít tham số hơn. Như được thể hiện trong hình này, số lượng tham số cần thiết để phân tích nhân tử WQiWKiT (đường màu xanh) để đạt ngưỡng 90% luôn nhỏ hơn so với WQi và WKi (đường màu đỏ), cho thấy ma trận kết hợp thể hiện tính low-rank tốt hơn. Bảng 1 minh họa lợi ích của cơ chế MHA low-rank cấp head như vậy, với ứng dụng của nó cho nén ViT không fine-tuning làm ví dụ. So với việc áp dụng SVD trực tiếp cho các ma trận trọng số riêng lẻ, phương pháp của chúng tôi mang lại độ chính xác mô hình cao hơn nhiều với cùng tỷ lệ nén, xác minh hai lợi ích (hiệu quả tham số và ràng buộc low-rank nới lỏng) được chỉ ra trong phân tích trước đó của chúng tôi.

MHA Low-Rank cho Nén Vision Transformer. Một ứng dụng trực tiếp của MHA low-rank đề xuất của chúng tôi là nén vision transformer. Nói chung, đối với một ViT b-block với một lớp MHA và một mạng feedforward 2 lớp (FFN) mỗi block, nhiệm vụ nén tương ứng sử dụng MHA low-rank có thể được hình thành như sau:

min{WQKi,j, WVOi,j, WFFNk,j}h,b,2i=1,j=1,k=1 L({WQKi,j, WVOi,j, WFFNk,j})
s.t. Σj=1b (Σi=1h C(R(WQKi,j)) + C(R(WVOi,j)) + Σk=12 C(R(WFFNk,j))) ≤ ε,(5)

trong đó L(·), C(·) và R(·) là các hàm trả về loss, cost (ví dụ: kích thước mô hình hoặc FLOP) và rank, tương ứng. WQKi,j = WQi,j WKi,jT, WVOi,j = WVi,j WOi,j và WFFNk,j là các ma trận kết hợp của attention head thứ i và ma trận trọng số trong FFN trong block thứ j. Có thể thấy rằng với ngân sách cost mục tiêu (ε) của ViT nén, rank là một loại siêu tham số quan trọng trực tiếp quyết định độ chính xác và độ phức tạp. Trong thực tế, do phạm vi rộng lớn của các giá trị rank có thể, việc lựa chọn rank phù hợp cho tất cả các block và lớp của vision transformer là thách thức. Ví dụ, tồn tại 4.53×10188 kết hợp rank khi thực hiện nén low-rank cho mô hình DeiT-small, làm cho việc lựa chọn thủ công trở nên không thực tế.

Để giải quyết thách thức này, chúng tôi đề xuất một phương pháp lựa chọn rank tự động để hiệu quả kết hợp MHA low-rank vào nén ViT. Ý tưởng chính của chúng tôi là diễn giải việc lựa chọn rank tự động của nén low-rank như một neural architecture search (NAS) chuyên biệt, xem xét thực tế rằng việc lựa chọn rank về cơ bản quyết định cấu trúc cuối cùng của ViT nén. Từ hiểu biết này, giá trị rank phù hợp có thể được xác định thông qua tìm kiếm dựa trên sampling có thể vi phân, một chiến lược đã được nghiên cứu kỹ trong tài liệu NAS (Liu et al., 2018; Wu et al., 2019; Tan & Le, 2019).

Hình 4 minh họa khung tổng thể cho tìm kiếm rank tự động cho ViT low-rank. Ở đây để ký hiệu đơn giản, chúng tôi sử dụng W∗j∈Rinj×outj để biểu thị các ma trận cần được phân tích trong lớp thứ j, tức là WQKi,j, WVOi,j và WFFNk,j, với tập hợp rank ứng viên là Rj = {r1j, r2j, raj, ... rmaxj}. Giả sử rằng r∗j∈Rj là rank hiện tại được chọn cho Wj ≈ W∗j = U∗j S∗j (U∗j∈Rinj×r∗j và S∗j∈Rr∗j×outj). Sau đó chúng tôi luân phiên cập nhật xác suất lựa chọn Pj = {p1j, p2j, paj, ... pmaxj} cho các ứng viên rank và các tham số của W∗j. Cụ thể, vì Pj được tính toán thông qua GumbelSoftmax (Jang et al., 2016), tức là Pj = GumbelSoftmax(αj) với vector có thể học αj, Pj có thể được cập nhật thông qua việc tối thiểu hóa loss sau (với các tham số trọng số đóng băng):

LProb = LCE(Y, Ŷ) · (Σaj=1 Ppaj C(raj)/ε)β,(6)

trong đó LCE(·) là loss cross-entropy, Y là đầu ra cuối cùng của toàn bộ mô hình, Ŷ là ground truth, và β là siêu tham số kiểm soát toàn bộ quá trình tìm kiếm. Ở đây như được thể hiện trong Hình 4, việc tính toán Y = Yb dựa trên việc xem xét tất cả các ứng viên phân tích (Uaj, Saj) với các cài đặt rank khác nhau và xác suất lựa chọn của chúng. Sau khi hoàn thành cập nhật xác suất, W∗j đầu tiên được phân tích nhân tử thông qua việc sử dụng rank tương ứng với xác suất lựa chọn lớn nhất, và sau đó được cập nhật thông qua việc tối thiểu hóa loss cross-entropy với các xác suất lựa chọn rank đóng băng. Các cài đặt rank có thể được xác định cuối cùng sau nhiều vòng cập nhật luân phiên như vậy của xác suất và trọng số.

MHA Low-Rank cho Khuếch tán Text-to-Image Cá nhân hóa. MHA low-rank đề xuất của chúng tôi cũng có thể được sử dụng để tùy chỉnh khuếch tán text-to-image một cách hiệu quả, một nhiệm vụ thị giác máy tính mới nổi mà mô hình khuếch tán đã được huấn luyện trước có thể nhanh chóng tổng hợp các thể hiện trực quan chất lượng cao của các khái niệm do người dùng định nghĩa với ít ví dụ về hình ảnh và hướng dẫn văn bản. Cụ thể hơn, cho một mô hình khuếch tán đã được huấn luyện trước {Wdiff} đã được huấn luyện tốt trên tập hình ảnh {x} và tập vector điều kiện {c} thu được từ text prompt, chúng tôi nhằm tối thiểu hóa loss sau:

Eϵ,xnew,cnew,t[wt∥{Wnew}(αtxnew + σtϵ, cnew) - xnew∥22],(7)

trong đó αt, σt và wt là hàm của timestep t kiểm soát quá trình khuếch tán, và xnew và cnew biểu thị các hình ảnh và text prompt do người dùng cung cấp, tương ứng, với |{xnew}| ≪ |{x}| và |{cnew}| ≪ |{c}|. Lưu ý rằng ở đây {Wnew} được khởi tạo là f({Wdiff}), trong đó f(·) có thể là hàm đồng nhất, có nghĩa là mô hình cá nhân hóa {Wnew} được khởi tạo trực tiếp là {Wdiff} đã được huấn luyện trước, hoặc một hàm biến đổi, chỉ ra rằng việc khởi tạo cho {Wnew} là sự sửa đổi của {Wdiff}.

Như được chỉ ra trong (Kumari et al., 2022), việc cập nhật toàn bộ {Wnew} rất không hiệu quả về mặt tính toán và dễ gây ra overfitting, do kích thước lớn của {Wdiff} và kích thước nhỏ của {xnew}. Được truyền cảm hứng từ những hiểu biết rằng 1) chỉ thay đổi một vài tham số đã đủ để làm cho các mô hình khuếch tán học được khái niệm do người dùng định nghĩa (Kumari et al., 2022); và 2) việc thêm thành phần low-rank là một chiến lược fine-tuning hiệu quả cho các mô hình ngôn ngữ lớn (LLM) trong các nhiệm vụ NLP (Aghajanyan et al., 2020), chúng tôi đề xuất sử dụng MHA low-rank để cải thiện hiệu quả triển khai của khuếch tán text-to-image cá nhân hóa. Hình 5 minh họa khung tổng thể. Cụ thể hơn, lớp MHA của mô hình cá nhân hóa được khởi tạo như:

MHA(XQ, XK, XV) = Σi=1h Softmax(XQ(WQiWKiT + UQiSKiT)XTK/√dk) XV(WViWOi + (UViSOi))(8)

trong đó {WQi, WKi, WVi, WOi} được thu được từ mô hình khuếch tán đã được huấn luyện trước {Wdiff}, và {UQi, SKi, UVi, SOi} là các thành phần low-rank được khởi tạo ngẫu nhiên. Như được thể hiện trong Hình 5, trong quá trình tùy chỉnh mô hình, tất cả các tham số của mô hình đã được huấn luyện trước {Wdiff} được đóng băng; trong khi việc tính toán của chúng tuân theo cơ chế được mô tả trong MHA low-rank đề xuất của chúng tôi. Đồng thời, thành phần low-rank được thêm vào UQi, SKi, UVi và SOi được cập nhật để làm cho Wnew thích ứng với các khái niệm mới do người dùng cung cấp.

4. Thí nghiệm
4.1. Phân loại Hình ảnh trên ImageNet-1K
Cài đặt. Chúng tôi đầu tiên xác thực phương pháp của mình trên tập dữ liệu ImageNet-1K (Deng et al., 2009) cho nhiệm vụ phân loại hình ảnh. Tập dữ liệu bao gồm 1.2M hình ảnh huấn luyện và 50K mẫu xác thực. Chúng tôi áp dụng các mô hình baseline, tức là mạng dày đặc không nén, và công thức huấn luyện từ DeiT (Touvron et al., 2021) vì chúng cho thấy kết quả đầy hứa hẹn trong việc huấn luyện các mô hình transformer chỉ bằng cách sử dụng ImageNet-1K mà không có các tập dữ liệu quy mô lớn khác để huấn luyện trước và do đó được áp dụng rộng rãi. Chúng tôi so sánh phương pháp của mình với các phương pháp nén ViT tiên tiến nhất trước đó, bao gồm low-rank (Yu & Wu, 2023), model pruning (Hou & Kung, 2022; Yu et al., 2022b; Zhu et al., 2021; Tang et al., 2020), sparse training (Chen et al., 2021b) và token pruning (Bolya et al., 2022; Pan et al., 2021b; Tang et al., 2022; Goyal et al., 2020; Pan et al., 2021a).

Chi tiết Triển khai. Toàn bộ quá trình của phương pháp chúng tôi bao gồm hai bước: tìm kiếm rank và fine-tuning. Chúng tôi tiến hành thuật toán lựa chọn rank tự động cho mô hình DeiT đã được huấn luyện trước để tạo ra mô hình low-rank dưới ràng buộc đã cho. Trong quá trình fine-tuning, learning rate ban đầu được đặt là 0.0001 và giảm xuống learning rate tối thiểu 0.000001 với bộ lập lịch Cosine. Weight decay để huấn luyện DeiT-small nén được đặt là 0.005. Phần còn lại của các siêu tham số huấn luyện nhất quán với DeiT (Touvron et al., 2021).

Kết quả So sánh. Bảng 2 cho thấy hiệu suất của các phương pháp nén khác nhau trên tập dữ liệu ImageNet. So với phương pháp tỉa tự động tiên tiến nhất trước đó UVC (Yu et al., 2022b), các mô hình nén của chúng tôi có độ chính xác top-1 cao hơn 0.45% và 1.69% với việc giảm FLOP lớn hơn nhiều trên DeiT-small và DeiT-base, tương ứng. Ngoài ra, phương pháp của chúng tôi có thể giảm đáng kể các tham số mô hình, tức là giảm 49.98% cho DeiT-small và 61.06% cho DeiT-base, trong khi mô hình nén từ UVC (Yu et al., 2022b) thì không thể. So với công trình low-rank của CT-GFM (Yu & Wu, 2023), phương pháp của chúng tôi đạt được sự tăng độ chính xác 0.98% với số lượng tham số ít hơn nhiều. So với công trình sparse training của S2ViTE (Chen et al., 2021b), với độ chính xác top-1 tương tự, chúng tôi đạt được việc giảm FLOP lớn hơn nhiều là 19.58% và 28.55% và giảm tham số là 16.04% và 26.65% trên DeiT-small và DeiT-base, tương ứng. So với công trình của PS-ViT (Tang et al., 2022) cho token reduction, phương pháp của chúng tôi cũng đạt được độ chính xác top-1 cao hơn là 0.18% và 0.76% với FLOP và tham số mô hình ít hơn nhiều trên DeiT-small và DeiT-base, tương ứng.

Tăng tốc Thực tế trên Các Nền tảng Phần cứng Khác nhau. Chúng tôi tiếp tục đo tăng tốc thực tế của các mô hình nén của chúng tôi trên các nền tảng phần cứng tính toán khác nhau, bao gồm Nvidia Tesla V100, Nvidia Jetson TX2, điện thoại di động Android (Snapdragon 855, 4 Cortex-A76 + 4 Cortex-A55), bộ gia tốc ASIC Eyeriss (Chen et al., 2016), và FPGA (PYNQ Z1) trong Bảng 3. Ở đây hiệu suất của Eyeriss được báo cáo thông qua việc sử dụng Timeloop (Parashar et al., 2019) với cài đặt công nghệ CMOS 45nm. Các mô hình DeiT-small và DeiT-base nén của chúng tôi đạt được tăng tốc đáng kể trên các nền tảng khác nhau. Ví dụ, trên Snapdragon 855, DeiT-base nén của chúng tôi có được tăng tốc 2.52× so với mô hình baseline với độ chính xác top-1 thậm chí cao hơn trên ImageNet. Những kết quả như vậy chứng minh hiệu quả thực tế của giải pháp nén low-rank của chúng tôi.

4.2. Phân tích Ablation cho Nén ViT Low-Rank
Lựa chọn Rank Tự động vs. Lựa chọn Rank Thủ công. Để chứng minh tính ưu việt của phương pháp lựa chọn rank tự động của chúng tôi, chúng tôi so sánh nó với phương pháp rank cố định. Hình 6 cho thấy các đường cong biến thiên của độ chính xác top-1 trên ImageNet-1K và số lượng tham số cho cả hai phương pháp trong quá trình huấn luyện. Phương pháp của chúng tôi có mất độ chính xác ít hơn, và số lượng tham số của mô hình dần dần hội tụ về giá trị mục tiêu (10.5M). Ngược lại, mô hình dựa trên phân tích cố định-rank mất nhiều độ chính xác hơn từ đầu, dẫn đến hiệu suất kém. Do đó, chúng tôi có thể kết luận rằng phương pháp của chúng tôi có thể tìm kiếm kết hợp rank tốt hơn dưới các ràng buộc.

Siêu tham số cho Tìm kiếm Rank. Chúng tôi cũng khám phá ảnh hưởng của siêu tham số β được đề cập bởi Eq. 6 đến quá trình tìm kiếm rank. Hình 7 cho thấy sự hội tụ của quá trình tìm kiếm liên quan đến các β khác nhau. Có thể thấy rằng khi β ≥ 1, số lượng tham số của mô hình có thể hội tụ về giá trị mục tiêu nhanh chóng, và độ chính xác cuối cùng của các mô hình cơ bản là giống nhau. Tuy nhiên, khi β = 1.5, đường cong độ chính xác của mô hình tương đối mượt mà, do đó, chúng tôi nghĩ 1.5 là giá trị tương đối tốt hơn cho β. Phân phối rank cuối cùng của DeiT-small và DeiT-base được thể hiện trong Hình 8 và Hình 9.

SVD vs. Phân tích Tensor Bậc cao. Để nén ViT, ngoài MHA, chúng tôi áp dụng nén low-rank cho FFN (Feed-Forward Network), và việc lựa chọn rank cho FFN cũng được bao gồm trong cơ chế xác định rank tự động đề xuất của chúng tôi. Để tìm phương pháp phân tích low-rank tối ưu từ các phương pháp phân tích low-rank khác nhau như SVD, phân tích Tucker, phân tích Tensor Train, chúng tôi đánh giá độ chính xác Top-1 và throughput trên GPU cho DeiT-Small nén trên tập dữ liệu ImageNet khi nén FFN sử dụng các phương pháp low-rank khác nhau. Như được thể hiện trong Bảng 4, với cùng tỷ lệ nén, việc sử dụng SVD mang lại độ chính xác cao hơn (không fine-tuning) so với việc sử dụng phân tích Tucker và phân tích Tensor Train với throughput tốt hơn trên GPU.

4.3. Mô hình Khuếch tán Text-to-Image Cá nhân hóa
Cài đặt. Chúng tôi fine-tune lớp cross-attention của Stable Diffusion đã được huấn luyện trước (Rombach et al., 2022) (trọng số mô hình thu được từ HuggingFace Hub1 (Wolf et al., 2019)) bằng cách sử dụng cơ chế MHA low-rank đề xuất của chúng tôi để cho phép mô hình học một khái niệm mới. Để đánh giá định lượng, chúng tôi sử dụng sáu đối tượng được bao gồm trong tập dữ liệu được phát hành bởi CustomDiffusion (Kumari et al., 2022) và một đối tượng mới được thu thập, với số lượng hình ảnh chứa trong mỗi cái dao động từ 4 đến 12.

So sánh Chi phí Huấn luyện. Chúng tôi đầu tiên trình bày chi phí huấn luyện cần thiết bởi tất cả các phương pháp trong Bảng 5. Chúng tôi huấn luyện tất cả các phương pháp trên một GPU Nvidia RTX A6000 với kích thước batch là 1 và số bước huấn luyện là 500. So với CustomDiffusion và DreamBooth, phương pháp của chúng tôi giảm thời gian huấn luyện 18.6% và 61.6%, tương ứng (xem Thời gian Huấn luyện trong Bảng 5), và giảm không gian lưu trữ bổ sung cho mỗi khái niệm 12.5× và 1927.5×, tương ứng (xem Lưu trữ Bổ sung trong Bảng 5). Việc giảm theo thứ tự độ lớn của lưu trữ bổ sung cho mỗi khái niệm mới cực kỳ quan trọng đối với việc áp dụng rộng rãi các mô hình khuếch tán text-to-image cá nhân hóa, nơi người dùng có thể chuẩn bị các mô hình khuếch tán của họ mà không gánh nặng lưu trữ mô hình.

So sánh Chất lượng Hình ảnh. Chúng tôi sau đó đánh giá chất lượng của các hình ảnh được tổng hợp cho tất cả các phương pháp. Chúng tôi tạo ra 20 hình ảnh cho mỗi hình ảnh mục tiêu đã học (khái niệm) bằng cách sử dụng cùng text prompt cho tất cả các phương pháp và tính toán FID (Heusel et al., 2017; Parmar et al., 2021) giữa các hình ảnh được tổng hợp và thực. Điểm FID thấp hơn chỉ ra sự khác biệt nhỏ hơn giữa các hình ảnh được tạo ra và thực. Như được thể hiện trong Bảng 5, phương pháp của chúng tôi đạt được FID thấp nhất so với các công trình hiện có. Chúng tôi tiếp tục cung cấp so sánh định tính trong Hình 10. Ngoài việc tạo ra các cảnh tương ứng một cách chính xác từ text prompt, V* Goldendoodle được tạo ra bởi phương pháp của chúng tôi gần nhất với hình ảnh thực, trong khi V* Goldendoodle được tổng hợp bởi DreamBooth (Ruiz et al., 2022) có sự khác biệt rõ ràng so với hình ảnh thực, và hình ảnh được tổng hợp từ CustomDiffusion (Kumari et al., 2022) chứa miệng ít tự nhiên hơn vì nó đã bị biến dạng. Trong Hình 11, chúng tôi tiếp tục cho thấy rằng thậm chí với ít tài nguyên tính toán hơn nhiều, tức là ít thời gian huấn luyện và ít số lượng GPU hơn để fine-tuning mô hình, chúng tôi vẫn có thể tạo ra hình ảnh chất lượng cao.

Đánh giá MS-COCO. Cuối cùng, chúng tôi thực hiện các thí nghiệm để hiểu liệu các mô hình đã được fine-tuning có thể tạo ra hình ảnh không liên quan đến chủ thể mục tiêu đã học (V*) hay không. Chúng tôi sử dụng văn bản được nhắc của 5,000 hình ảnh từ tập xác thực MS-COCO 2017 (Lin et al., 2014) để tạo ra hình ảnh và tính toán FID. Như được thể hiện trong Bảng 6, FID từ các mô hình cá nhân hóa tương tự như mô hình text-to-image đã được huấn luyện trước, cho thấy rằng chúng có thể tổng hợp hình ảnh chất lượng cao cho các khái niệm không liên quan. Do đó, mô hình được fine-tuning bởi phương pháp của chúng tôi vẫn giữ được phân phối của các hình ảnh được tổng hợp như mô hình đã được huấn luyện trước.

5. Kết luận
Bài báo này điều tra cơ bản tính low-rank trong lớp multi-head attention của các mô hình thị giác mới nổi và đề xuất rằng tính low-rank cấp head nên được khám phá để thiết kế mô hình hiệu quả, mang lại giải pháp nén ViT low-rank hiệu quả cao. Phương pháp của chúng tôi không chỉ vượt trội hơn các phương pháp nén hiện có bằng cách cung cấp hiệu suất cao hơn mà còn mang lại tăng tốc thực tế nhanh hơn. Đặc biệt, phát hiện của chúng tôi được áp dụng thêm cho việc tùy chỉnh hiệu quả các mô hình khuếch tán text-to-image, vượt trội hơn các giải pháp tiên tiến nhất.

6. Lời cảm ơn
Công trình này được hỗ trợ một phần bởi National Science Foundation dưới Grant CCF-1937403 và CCF-1955909.

Về Tính Mạnh Mẽ trong Học Đa Phương Thức

Brandon McKinzie¹ Joseph Cheng² Vaishaal Shankar¹ Yinfei Yang³ Jonathon Shlens¹ Alexander Toshev¹

Tóm tắt

Học đa phương thức được định nghĩa là học trên nhiều phương thức đầu vào khác nhau như video, âm thanh và văn bản. Trong nghiên cứu này, chúng tôi quan tâm đến việc hiểu cách các mô hình hoạt động khi loại phương thức khác nhau giữa quá trình huấn luyện và triển khai, một tình huống thường xảy ra trong nhiều ứng dụng của học đa phương thức trên các nền tảng phần cứng. Chúng tôi trình bày một khung tính mạnh mẽ đa phương thức để cung cấp phân tích có hệ thống về các phương pháp học biểu diễn đa phương thức phổ biến. Hơn nữa, chúng tôi xác định những thiếu sót về tính mạnh mẽ của các phương pháp này và đề xuất hai kỹ thuật can thiệp dẫn đến cải thiện tính mạnh mẽ 1.5-4× trên ba bộ dữ liệu AudioSet, Kinetics-400 và ImageNet-Captions. Cuối cùng, chúng tôi chứng minh rằng các can thiệp này tận dụng tốt hơn các phương thức bổ sung, nếu có, để đạt được kết quả cạnh tranh 44.2 mAP trên AudioSet 20K.

1. Giới thiệu

Các mô hình học máy trong thế giới thực hoạt động trên nhiều nền tảng phần cứng và bộ cảm biến đa dạng. Các mô hình được triển khai phải hoạt động trên các nền tảng từ thiết bị đeo được đến xe tự lái, trong đó bộ cảm biến đa dạng cung cấp bình luận liên tục về môi trường. Việc xây dựng mô hình học máy truyền thống trong bối cảnh này là thách thức vì việc đo lường dữ liệu đồng thời trên tất cả cảm biến có thể không khả thi. Tương tự, các phương thức cảm biến có thể được thêm vào (hoặc hỏng) bất kỳ lúc nào, cho thấy rằng giả định ngầm về dữ liệu i.i.d. có thể không xảy ra trong thế giới thực. Do đó, các tính chất mạnh mẽ trên các phương thức trở nên quan trọng tối quan trọng khi triển khai hệ thống học máy hoạt động trong môi trường đa phương thức. Đầu tiên, một mô hình nên có thể hoạt động trên các phương thức không được quan sát rõ ràng trong quá trình huấn luyện. Ví dụ, chúng tôi hy vọng rằng sự hiện diện của các phương thức bổ sung không có nhãn rõ ràng vẫn có thể mang lại lợi ích cho hiệu suất dự đoán tổng thể. Thứ hai, các mô hình nên giảm nhẹ một cách duyên dáng khi thiếu phương thức tại thời điểm kiểm tra. Cả hai tính chất này đều độc đáo với bối cảnh đa phương thức.

Để giải quyết những thách thức này, chúng tôi nghiên cứu vấn đề tính mạnh mẽ đa phương thức. Các mô hình hoạt động như thế nào khi các kết hợp tùy ý của các phương thức có thể được thêm vào hoặc loại bỏ tại thời điểm kiểm tra? Học có giám sát thường huấn luyện một mô hình trên một bộ dữ liệu có nhãn và kiểm tra cách hiệu suất giảm khi tập xác thực tách biệt khác biệt với tập huấn luyện (Recht et al., 2019; Shankar et al., 2021; Hendrycks & Dietterich, 2019). Trong bối cảnh của chúng tôi, thay vào đó chúng tôi muốn xây dựng các mô hình trong đó người ta có thể linh hoạt tráo đổi vào hoặc ra các phương thức riêng lẻ mà mô hình đã thấy trong quá trình tiền huấn luyện, huấn luyện downstream, hoặc cả hai (Hình 1).

Một phương pháp để đạt được biểu diễn linh hoạt và hiệu quả cho một bộ phương thức là có một mô hình học biểu diễn chung bất biến với các định danh phương thức – và sau đó huấn luyện mô hình phân biệt trên biểu diễn đã học đó (Goodfellow et al., 2016). Một số phương pháp học biểu diễn chung đã được khám phá trong tài liệu, nhưng gần đây, hai phương pháp nổi bật – masked autoencoders (Gong et al., 2022; Geng et al., 2022) và học tương phản (Radford et al., 2021; Wu et al., 2022b) – đã thể hiện tiềm năng phi thường trong bối cảnh biểu diễn đa phương thức (Akbari et al., 2021). Chúng tôi tập trung nghiên cứu vào việc đánh giá tính mạnh mẽ trong học biểu diễn và hỏi cách cải thiện những biểu diễn đó thông qua các chiến lược huấn luyện mới.

Trong nghiên cứu này, chúng tôi giới thiệu một khung đo lường tính mạnh mẽ trong bối cảnh đa phương thức. Chúng tôi định nghĩa một metric tính mạnh mẽ mới để nắm bắt tính biến thiên trên các phương thức bằng cách tập trung vào cả hiệu suất trung bình và trường hợp xấu nhất trên các thiết lập huấn luyện và đánh giá. Hơn nữa, chúng tôi phân tầng các metric này trên các kịch bản phổ biến như thêm, loại bỏ, hoặc hoàn toàn tráo đổi các phương thức đưa vào mô hình.

Chúng tôi tập trung thí nghiệm vào học biểu diễn với bộ dữ liệu AudioSet (Gemmeke et al., 2017) trong đó ba phương thức nổi bật – âm thanh, video và văn bản – có thể được thao tác một cách có hệ thống. Ngoài ra, chúng tôi khám phá tính tổng quát của kết quả trên Kinetics-400 (Kay et al., 2017) và ImageNet-Captions (Fang et al., 2022a).

Chúng tôi đo lường hiệu suất trung bình và trường hợp xấu nhất khi các phương thức được thêm vào hoặc loại bỏ tại thời điểm kiểm tra. Để giảm thiểu những suy giảm này, chúng tôi giới thiệu hai phương pháp để cải thiện học biểu diễn trong bối cảnh đa phương thức. Phương pháp đầu tiên — được rút ra từ knowledge distillation (Hinton et al., 2015) – được gọi là Modality Augmented Self-Distillation (MASD), khuyến khích tính nhất quán trong các biểu diễn đã học trên các phương thức có nhãn và không nhãn. Phương pháp thứ hai, được rút ra từ WiseFT (Wortsman et al., 2022), tận dụng kết hợp có trọng số của trọng số downstream đã fine-tune và trọng số khởi tạo đã tiền huấn luyện để tạo ra tính mạnh mẽ. Chúng tôi tóm tắt các đóng góp như sau:

1. Giới thiệu các metric và mô tả hiệu suất trong bối cảnh đa phương thức trên một số bộ dữ liệu về hiệu suất trường hợp xấu nhất và trung bình.

2. Chứng minh các can thiệp huấn luyện (ví dụ MASD, WiseFT) có thể cộng dồn dẫn đến cải thiện tính mạnh mẽ 1.5-4× trên AudioSet, Kinetics-400 và ImageNet-Captions.

3. Tăng số lượng phương thức được sử dụng để học biểu diễn cải thiện hiệu suất downstream. Đặc biệt, chúng tôi đạt được kết quả SOTA (44.2 mAP) trên AudioSet-20K bằng cách tận dụng văn bản như một phương thức tiền huấn luyện bổ sung.

Chúng tôi hy vọng rằng những kết quả này có thể đẩy nhanh lĩnh vực học đa phương thức bằng cách cung cấp các metric đơn giản, chuẩn và các benchmark mạnh mẽ cho những cải tiến tương lai.

2. Nghiên cứu Liên quan

2.1. Tính Mạnh Mẽ

Học máy mạnh mẽ đã là chủ đề nghiên cứu trong nhiều thập kỷ. Thuật toán support vector machine được trình bày như một phương pháp dự đoán "mạnh mẽ" (Boser et al., 1992) bằng cách tìm bộ phân loại margin tối đa. Tuy nhiên gần đây đã có sự thúc đẩy hướng tới các hình thức tính mạnh mẽ thực tế hơn cho các mô hình hoạt động trên thị giác, ngôn ngữ tự nhiên, lời nói và các phương thức khác.

Các ví dụ đối kháng trường hợp xấu nhất đã được nghiên cứu rộng rãi trong nhiều lĩnh vực (Szegedy et al., 2013; Alzantot et al., 2018; Carlini & Wagner, 2018) và trong khi nhiều phương pháp "phòng thủ" hiệu quả đã được đề xuất (Madry et al., 2017; Carlini et al., 2022; Carmon et al., 2019), đã được chứng minh rằng những phòng thủ này giảm độ chính xác lành tính (không đối kháng) và không tổng quát hóa cho các hình thức tính mạnh mẽ tự nhiên khác (Taori et al., 2020). Một câu chuyện tương tự xảy ra với tính mạnh mẽ "corruption" tổng hợp (Hendrycks & Dietterich, 2019; Geirhos et al., 2018) nơi các phương pháp mạnh mẽ đã được đề xuất nhưng chúng không thể tổng quát hóa cho các corruption không tổng hợp.

Đối với lớp corruption tự nhiên hoặc distribution shift, các mô hình hình ảnh-văn bản đa phương thức quy mô lớn gần đây (Radford et al., 2021; Pham et al., 2021) đã thể hiện tính mạnh mẽ chưa từng có khi được đánh giá theo cách zero-shot (Recht et al., 2019; Barbu et al., 2019; Shankar et al., 2021; Gu et al., 2019). Nghiên cứu tiếp theo đã chứng minh cải thiện tính mạnh mẽ trong các mô hình đã fine-tune (Wortsman et al., 2022).

2.2. Học Đa Phương Thức

Một cách tự nhiên để học biểu diễn theo cách tự giám sát từ các luồng dữ liệu đa phương thức là (1) có một tập các bộ mã hóa phương thức và một bộ tổng hợp tạo ra một biểu diễn duy nhất từ tất cả các phương thức có sẵn và (2) xem xét các phương thức ghép đôi như các ví dụ tích cực. Cách suy nghĩ này tự nhiên dẫn đến học tương phản nhúng các phương thức khác nhau trong không gian chung (Radford et al., 2021; Sohn, 2016). Hầu hết nghiên cứu hiện tại tập trung vào chỉ hình ảnh và văn bản (Radford et al., 2021; Alayrac et al., 2022; Yuan et al., 2021; You et al., 2022) với một số nỗ lực gần đây trong việc bao gồm video, âm thanh và thậm chí dữ liệu bảng (Akbari et al., 2021; Alayrac et al., 2020; Liang et al., 2022).

Một lựa chọn khác cho học tương phản là mục tiêu tái tạo có mặt nạ. Hầu hết các phương pháp trước đây tập trung vào các phương thức đơn lẻ, như văn bản (Devlin et al., 2018), hình ảnh (He et al., 2022), video (Feichtenhofer et al., 2022), và âm thanh (Baade et al., 2022; Chong et al., 2022). Gần đây hơn, phương pháp này cũng đã được áp dụng trong bối cảnh đa phương thức (Geng et al., 2022; Wang et al., 2022). Các nghiên cứu khác sử dụng cả mục tiêu tái tạo có mặt nạ và tương phản (Gong et al., 2022; Yang et al., 2022; Fang et al., 2022b; Singh et al., 2021).

Từ góc độ kiến trúc mô hình, vẫn là câu hỏi mở về cách tốt nhất để kết hợp thông tin từ các phương thức khác nhau (Dou et al., 2021; Liu et al., 2018). Tính linh hoạt của transformer (Vaswani et al., 2017) cho phép chúng dễ dàng thích ứng với các phương thức khác ngoài ngôn ngữ (Akbari et al., 2021; Liang et al., 2022; Jaegle et al., 2021; Nagrani et al., 2021; Yang et al., 2022).

Việc tăng số lượng phương thức đặt ra thách thức trong huấn luyện và trong việc hiểu các mô hình. Trong học có giám sát, bản chất tham lam của học có thể được quan sát và định lượng (Wu et al., 2022a; Hessel & Lee, 2020), cũng như tính không đồng nhất nội phương thức và liên phương thức (Liang et al., 2022).

3. Đánh giá Biểu diễn Đa Phương Thức

3.1. Thiết lập và Ký hiệu

Trong nghiên cứu này, chúng tôi đưa ra một số giả định cho dữ liệu của mình áp dụng cho nhiều ứng dụng (xem Hình 2). Đầu tiên, chúng tôi giả định rằng chúng tôi có dữ liệu đa phương thức có sẵn dễ dàng bao gồm một số luồng đầu vào song song của các phương thức được căn chỉnh khác nhau. Thứ hai, dữ liệu trên có thể được thu thập độc lập với các nhiệm vụ quan tâm, mặc dù nó có thể liên quan đến nó, và do đó không chứa giám sát.

Chúng tôi sẽ gọi những dữ liệu này là dữ liệu tiền huấn luyện không giám sát D và tập n phương thức có mặt trong đó bởi M = {m₁, ..., mₙ}. Vì chúng tôi tập trung vào các tập con của phương thức, sẽ hữu ích khi tham chiếu đến các điểm dữ liệu x và bộ dữ liệu D bị giới hạn bởi một tập phương thức m ⊆ M bằng:

x|m và D|m = {x|m ; x ∈ D}  (1)

Hơn nữa, cho một nhiệm vụ downstream chúng tôi có dữ liệu với giám sát cho cả huấn luyện và đánh giá. Có thể mong đợi rằng dữ liệu có giám sát nhỏ hơn đáng kể về số lượng so với dữ liệu tiền huấn luyện. Chúng tôi gọi những dữ liệu này là dữ liệu huấn luyện downstream D_T với các phương thức huấn luyện M_T ⊆ M, và dữ liệu đánh giá downstream D_E với các phương thức đánh giá M_E ⊆ M. Quan trọng là, các tập phương thức huấn luyện và đánh giá được phép khác nhau, M_T ≠ M_E, dẫn đến các vấn đề tính mạnh mẽ như được trình bày sau.

Nhiệm vụ Downstream. Ký hiệu bởi f_θ(x) mô hình nhiệm vụ downstream với trọng số θ. Lưu ý rằng f là đa phương thức, tức là nó có thể được áp dụng trên bất kỳ tập con m ⊆ M nào của các phương thức, và một ứng dụng như vậy được ký hiệu bởi f_θ(x|m).

Các tham số của mô hình được ước tính bằng cách huấn luyện cho nhiệm vụ downstream trên D_T sử dụng loss L cụ thể cho nhiệm vụ:

L_task(D_T|M_T) = Σ_{x∈D_T} L(f_θ(x|M_T))  (2)

nơi chúng tôi nói rõ ràng rằng mô hình được áp dụng trên x chỉ sử dụng các phương thức trong M_T.

3.2. Metric Tính Mạnh Mẽ Đa Phương Thức

Có thể giả định rằng nhiệm vụ downstream quan tâm có điểm hiệu suất p được thiết lập tốt có thể được đo lường cho mô hình f của chúng tôi. Nếu điểm này được tính trên dữ liệu đánh giá D_E|M_E sử dụng phương thức M_E sau khi mô hình đã được huấn luyện trên D_T|M_T sử dụng phương thức M_T, chúng tôi ký hiệu điểm hiệu suất này bằng p(M_E, M_T), trong đó để ngắn gọn chúng tôi bỏ qua ký hiệu mô hình và bộ dữ liệu.

Cho một tập phương thức huấn luyện M_T, chúng tôi đề xuất đo lường hai khía cạnh trên tất cả các thiết lập đánh giá. Đầu tiên là điểm trung bình, được gọi là hiệu suất, và đại diện cho mức độ tốt của các phương thức M_T huấn luyện một mô hình khi được đánh giá trên tất cả các hoàn cảnh có thể:

P(M_T) = avg_{M_E⊆M} p(M_E, M_T)  (3)

Thứ hai là điểm xấu nhất, được gọi là tính mạnh mẽ, đại diện cho kịch bản triển khai xấu nhất có thể cho mô hình được huấn luyện trên M_T:

R(M_T) = min_{M_E⊆M} p(M_E, M_T)  (4)

Để tạo ra một tập metric duy nhất cho một mô hình trên tất cả các thiết lập huấn luyện có thể M_T, chúng tôi đề xuất tổng hợp hiệu suất và tính mạnh mẽ trung bình và trường hợp xấu nhất ở trên theo hai cách. Đầu tiên, nếu một người có quyền kiểm soát việc chọn tập huấn luyện tối ưu, có ý nghĩa khi tìm hiệu suất và tính mạnh mẽ tốt nhất. Nếu chúng tôi muốn đánh giá trên tất cả các tập huấn luyện có thể, thì có ý nghĩa khi tính trung bình trên các thiết lập huấn luyện. Chúng tôi sẽ gọi các metric trước đây là Hiệu suất tốt nhất (P_best) và Tính mạnh mẽ (R_best), và các metric sau đây đơn giản là Hiệu suất (P) và Tính mạnh mẽ (R):

P_best = max_{M_T⊆M} P(M_T) ; R_best = max_{M_T⊆M} R(M_T)  (5)

P = avg_{M_T⊆M} P(M_T) ; R = avg_{M_T⊆M} R(M_T)  (6)

Phân tầng Hiệu suất và Tính mạnh mẽ. Các metric trên ban đầu được định nghĩa trên tất cả các tập phương thức đánh giá có thể M_E ⊆ M cho mỗi tập huấn luyện. Tuy nhiên, như được thúc đẩy trong Phần 1, có thể có các loại bất đồng khác nhau. Để nắm bắt tốt hơn điều này, chúng tôi tinh chỉnh P(M_T) và R(M_T) được tính trên một tập con của các tập phương thức đánh giá có thể M_E (Hình 2):

1. Thiếu tại Test: Các phương thức kiểm tra là một tập con nghiêm ngặt của các phương thức huấn luyện: M_E ⊂ M_T. Thiết lập này tương ứng với việc có thông tin không đầy đủ tại thời điểm kiểm tra.

2. Thêm tại Test: Các phương thức kiểm tra là một tập con nghiêm ngặt của các phương thức huấn luyện: M_T ⊂ M_E. Thiết lập này tương ứng với các phương thức không có mặt trong quá trình huấn luyện.

3. Khả năng Chuyển giao: Các phương thức kiểm tra và huấn luyện hoàn toàn khác biệt: M_T ∩ M_E = ∅. Đây là thiết lập cực đoan nhất, và kiểm tra khả năng chuyển giao một nhiệm vụ đã học trên một tập sang một tập phương thức hoàn toàn khác.

Chúng tôi áp đặt các ràng buộc trên lên M_T và M_E trong việc tính toán P và R trong Eq. (3) và Eq. (4), và bằng proxy trong Eq. (4).

Lưu ý rằng khi dữ liệu chỉ có hai phương thức, tức là |M| = 2, đối với Thêm tại Test và Khả năng Chuyển giao, tính mạnh mẽ và hiệu suất là giống nhau R = P, vì đối với mỗi tập phương thức huấn luyện, chỉ có một tập phương thức đánh giá thỏa mãn các kết hợp Thêm tại Test và Khả năng Chuyển giao. Khi đó, các phép toán trung bình và tối thiểu trong Eq. (3) và Eq. (4) dẫn đến các giá trị giống nhau.

4. Học Tự Giám Sát Đa Phương Thức

4.1. Mô hình

Tiền huấn luyện. Dữ liệu đa phương thức, như các luồng ghép đôi của các phương thức khác nhau, là một ứng cử viên tự nhiên cho học tự giám sát vì có thể giả định rằng các phương thức khác nhau trình bày các góc nhìn khác nhau về cùng một nội dung cơ bản. Điều này có thể được vận hành sử dụng các mục tiêu tương phản (Radford et al., 2021; Jia et al., 2021) hoặc tái tạo có mặt nạ (He et al., 2022).

Đối với thiết lập đa phương thức, chúng tôi mã hóa các phương thức khác nhau với các bộ mã hóa cụ thể cho phương thức. Trong trường hợp học tương phản, chúng tôi tuân theo chặt chẽ kiến trúc VATT bởi Akbari et al. (2021), và xây dựng loss InfoNCE theo cặp (Gutmann & Hyvärinen, 2010; Oord et al., 2018) trên tất cả các cặp phương thức đầu vào có thể. Mục tiêu này cố gắng học các biểu diễn cho mỗi phương thức càng tương tự càng tốt cho các phương thức ghép đôi. Đối với MAE, chúng tôi tuân theo chặt chẽ kiến trúc baseline AV-MAE được mô tả trong Gong et al. (2022). Mặc dù tái tạo có mặt nạ không rõ ràng thực thi một không gian biểu diễn chung cho các phương thức, hy vọng là lớp bộ mã hóa chung-phương thức cuối cùng chứa thông tin có thể chuyển giao từ phương thức này sang phương thức khác. Để biết thêm chi tiết về công thức cũng như kiến trúc, chúng tôi đề cập người đọc đến Phụ lục và Phần 5.

Huấn luyện Downstream. Sau khi học một biểu diễn sử dụng SSL, chúng tôi áp dụng nó cho một nhiệm vụ downstream. Cụ thể, ký hiệu bởi E_i bộ mã hóa cho phương thức m_i nhúng một đầu vào x|m_i của phương thức này vào không gian Euclidean E_i(x|m_i) ∈ ℝ^d (xem Phần 3.1 cho ký hiệu). Giả sử, tại thời điểm huấn luyện hoặc suy luận downstream, dữ liệu D|M' có một tập con các phương thức M' ⊆ M. Khi đó, biểu diễn cuối cùng cho x ∈ D:

E(x) = (1/|M'|) Σ_{m'∈M'} E_{m'}(x|m')  (7)

Biểu diễn này được sử dụng, ví dụ trong trường hợp của một nhiệm vụ downstream phân loại, để học một bộ phân loại.

4.2. Cải thiện Tính Mạnh Mẽ Đa Phương Thức

Chúng tôi giả thuyết rằng trong quá trình học nhiệm vụ downstream, chúng tôi chỉ thấy một tập con của tất cả các phương thức có thể, và do đó việc học này có thể 'làm hại' mô hình đã tiền huấn luyện và giảm khả năng xử lý các phương thức không thấy trong quá trình huấn luyện downstream. Để giải quyết thách thức này, chúng tôi đề xuất áp dụng các ý tưởng từ transfer learning.

4.2.1. TỰ CHƯNG CẤT ĐƯỢC TĂNG CƯỜNG PHƯƠNG THỨC

Một cách để giảm thiểu vấn đề là sử dụng dữ liệu tiền huấn luyện chứa tất cả các phương thức nhưng không có giám sát. Những dữ liệu này có thể được sử dụng để điều chỉnh hiệu suất của mô hình trên tất cả các phương thức, ngay cả khi mô hình này được huấn luyện với một tập con của các phương thức có mặt trong dữ liệu huấn luyện downstream. Để đạt được điều này, chúng tôi rút cảm hứng từ (Li & Hoiem, 2017; Castro et al., 2018; Hou et al., 2018; Rebuffi et al., 2017) để sử dụng Knowledge Distillation (Hinton et al., 2015) trên dữ liệu tiền huấn luyện.

Chi tiết hơn, giả sử rằng nhiệm vụ downstream là phân loại và mô hình f_θ(y; x) tạo ra xác suất trên các nhãn y cho một đầu vào x. Khi đó, mô hình giáo viên f_θ(y; x|M_T) là cùng một mô hình được huấn luyện trên các phương thức huấn luyện downstream M_T và dữ liệu D_T. Mô hình học sinh cũng là cùng một mô hình f_θ(y; x|M\M_T) (cùng trọng số), tuy nhiên, bị giới hạn trên các phương thức M\M_T không có mặt trong dữ liệu huấn luyện downstream. Vì mô hình học sinh và giáo viên chia sẻ cùng trọng số, nhưng có các phương thức đầu vào khác nhau, chúng tôi gọi loss này là tự chưng cất:

L_self-dist(D) = Σ_{x∈D} Σ_y f_θ(y; x|M_T) log f_θ(y; x|M\M_T)

Mục tiêu cuối cùng của MASD kết hợp loss trên với loss nhiệm vụ downstream từ Eq. (2) (xem Hình 3):

L_MASD = L_task(D_T|M_T) + L_self-dist(D_SD)  (8)

nơi loss tự chưng cất được định nghĩa trên một tập con D_SD ⊆ D của dữ liệu tiền huấn luyện.

Vì cả mô hình học sinh và giáo viên chia sẻ cùng trọng số, loss trên đảm bảo rằng mô hình hoạt động tốt trên tất cả các phương thức M. Lưu ý rằng để ổn định huấn luyện, chúng tôi dừng luồng gradient thông qua giáo viên.

4.2.2. ÁP DỤNG WISE-FT CHO CÁC MÔ HÌNH MASD

Gần đây có một dòng nghiên cứu về cải thiện tính mạnh mẽ phân phối của các mô hình hình ảnh-văn bản quy mô lớn đã fine-tune bằng weight-space ensembling (WISE-FT) các mô hình đã fine-tune và đối tác đã tiền huấn luyện (chưa fine-tune) (Wortsman et al., 2022; Ilharco et al., 2022). Trong khi nghiên cứu trước đây sử dụng quy trình này để có được tính mạnh mẽ trên các tập kiểm tra out-of-distribution, chúng tôi sử dụng quy trình để cải thiện tính mạnh mẽ của mô hình khi có sự khác biệt giữa các phương thức huấn luyện và kiểm tra.

Ký hiệu bởi θ_masd các trọng số thu được bởi MASD và θ_lp các trọng số thu được thông qua linear probing. Chúng tôi tính toán trọng số mới bằng cách lấy trung bình có trọng số:

θ_wise = αθ_masd + (1-α)θ_lp  (9)

Sự khác biệt duy nhất từ Wortsman et al. (2022) là họ tính trung bình mạng hình ảnh đã fine-tune với trọng số mạng đã tiền huấn luyện và trọng số "zero-shot" được cảm ứng bởi các nhúng văn bản của tên lớp. Vì chúng tôi fine-tune tất cả các bộ mã hóa và muốn một quy trình bất khả tri phương thức, chúng tôi thay thế trọng số zero-shot dựa trên văn bản bằng trọng số linear probe. Trong khi việc lựa chọn α có thể được điều chỉnh với cross-validation, chúng tôi thấy rằng giá trị không đổi α = 0.75 hoạt động tốt cho các thí nghiệm của chúng tôi.

5. Thiết lập Thí nghiệm

Chúng tôi cung cấp một tóm tắt ngắn gọn về thiết lập thí nghiệm. Để biết chi tiết đầy đủ, xem Phụ lục.

AudioSet (Gemmeke et al., 2017) là một bộ dữ liệu phân loại âm thanh đa nhãn video, âm thanh và văn bản trên 527 lớp. Nghiên cứu trước đây chủ yếu tận dụng âm thanh và/hoặc video, nhưng chúng tôi cũng bao gồm tiêu đề của video như văn bản. AudioSet bao gồm một tập huấn luyện không cân bằng với 1,743,790 ví dụ, được sử dụng làm dữ liệu tiền huấn luyện không nhãn; một tập huấn luyện và đánh giá với 18,649 và 17,065 ví dụ tương ứng được sử dụng cho nhiệm vụ downstream.

Lưu ý rằng tiêu đề liên quan đến nội dung nhưng hiếm khi chứa nhãn sự kiện âm thanh (trong 25.5% tiêu đề video huấn luyện chúng tôi có từ nhãn được đề cập; để biết ví dụ xem Bảng 4).

Kinetics-400 (Kay et al., 2017) là một bộ dữ liệu nhận diện hành động video và âm thanh trên 400 lớp. Nó bao gồm một tập huấn luyện và đánh giá với 246,245 và 40,000 ví dụ tương ứng được sử dụng cho nhiệm vụ downstream.

ImageNet-Captions (Fang et al., 2022a) là một bộ dữ liệu hình ảnh-văn bản được tạo bằng cách trích xuất chú thích Flickr cho hình ảnh từ bộ dữ liệu huấn luyện ILSVRC2012 gốc. Nó chứa 999/1000 lớp ImageNet gốc. Bộ dữ liệu chứa 448,896 ví dụ mà chúng tôi chia ngẫu nhiên thành 359,116 hình ảnh huấn luyện và 89,779 hình ảnh đánh giá.

Tiền xử lý. Chúng tôi sử dụng tiền xử lý chuẩn trước khi suy luận và huấn luyện cho mỗi phương thức (ví dụ (Gong et al., 2021; Nagrani et al., 2021)). Ngắn gọn, âm thanh được trích xuất như đoạn 8 giây kênh đơn được lấy mẫu tại 16 kHz với padding cần thiết. Chúng tôi tính toán log Mel spectrograms (128 frequency bin, cửa sổ Hamming 25ms, stride 10ms), và trích xuất patch 16×16. Trong quá trình huấn luyện, video được tái tỉ lệ cạnh ngắn ngẫu nhiên giữa 256 và 320 pixel, và crop ngẫu nhiên thành 224×224. Trong quá trình suy luận, video được tái tỉ lệ cạnh ngắn cố định thành 256 pixel theo sau bởi center crop thành 224×224.

Huấn luyện. Chúng tôi sử dụng kiến trúc ViT-B/16 (Dosovitskiy et al., 2020) cho tất cả ba phương thức với mã hóa vị trí cụ thể phương thức phù hợp cho cả học tương phản và MAE. Chúng tôi khởi tạo trọng số cho mô hình tương phản với CLIP ViT-B/16 (Radford et al., 2021). Đối với AudioSet và Kinetics-400, chúng tôi học biểu diễn đa phương thức sử dụng AudioSet 2M. Đối với ImageNet-Captions chúng tôi sử dụng biểu diễn CLIP ViT-B-16 được phát hành bởi OpenAI.

Trong loss MASD trong Eq. 8, chúng tôi cần dữ liệu không nhãn hoàn chỉnh phương thức D_SD cho tự chưng cất. Đối với các thí nghiệm trên AudioSet, D_SD là mẫu 20K ngẫu nhiên từ dữ liệu tiền huấn luyện AudioSet. Đối với các thí nghiệm trên Kinetics, D_SD là mẫu 20K ngẫu nhiên từ dữ liệu tiền huấn luyện AudioSet hoặc mẫu 20% ngẫu nhiên từ dữ liệu huấn luyện Kinetics. Trong trường hợp sau, dữ liệu huấn luyện nhiệm vụ downstream bao gồm 80% còn lại.

Chúng tôi huấn luyện các mô hình với batch size 1024 sử dụng optimizer AdamW (Loshchilov & Hutter, 2017) với learning rate 8e-4. Chúng tôi tiền huấn luyện các mô hình MAE và tương phản tương ứng 256 và 32 epoch.

6. Phân tích Tính Mạnh Mẽ Đa Phương Thức

Trong phần sau, chúng tôi cung cấp phân tích các mô hình đa phương thức tập trung vào các câu hỏi cấp cao sau:

1. Các phương pháp học biểu diễn đa phương thức khác nhau hoạt động như thế nào so với các bất đồng giữa các phương thức huấn luyện và đánh giá downstream?

2. Loại bất đồng nào có tác động mạnh nhất đến hiệu suất và/hoặc tính mạnh mẽ?

3. Tác động của các can thiệp được đề xuất từ Phần 4.2 đối với tính mạnh mẽ đa phương thức là gì?

6.1. Phân tích biểu diễn đa phương thức đã học

Chúng tôi tập trung vào các biểu diễn đã học từ học tương phản chuẩn và MAE được trình bày trong Phần 4.1. Các metric Hiệu suất và Tính mạnh mẽ được trình bày trong Bảng 1.

Nhiều phương thức hơn là tốt hơn. Để thúc đẩy việc sử dụng nhiều phương thức trong quá trình tiền huấn luyện, huấn luyện và đánh giá, chúng tôi đo lường hiệu suất của học tương phản, mô hình SSL hoạt động tốt hơn trong cả tiền huấn luyện và huấn luyện downstream, trong khi duy trì M_T = M_E. Chúng tôi tính toán Hiệu suất theo Eq. 6 nơi chúng tôi tính trung bình chỉ trên các tập phương thức có kích thước cố định |M_T| = |M_E| = k. Chúng tôi thay đổi k ∈ {1, 2, 3}.

Hiệu suất liên tục cải thiện khi một mô hình huấn luyện và kiểm tra trên các phương thức bổ sung (Hình 4). Hơn nữa, các mô hình được hưởng lợi từ nhiều phương thức hơn ở cả thời điểm tiền huấn luyện và huấn luyện downstream. Cụ thể hơn, tiền huấn luyện trên nhiều phương thức hơn tăng hiệu suất thêm 3.5 - 6.0 điểm (Hình 4, màu xanh nhạt so với xanh đậm).

Biểu diễn đa phương thức gặp khó khăn tại nhiệm vụ downstream đối với các phương thức không thấy trong quá trình huấn luyện. Các metric được giới thiệu trong Bảng 1 (Tổng thể) tổng hợp trên tất cả các kết hợp huấn luyện và đánh giá có thể. Để hiểu rõ hơn những kết hợp nào thách thức các mô hình này nhất, chúng tôi sử dụng các metric Hiệu suất và Tính mạnh mẽ được phân tầng Thêm tại Test, Thiếu tại Test, và Khả năng Chuyển giao được định nghĩa trong Phần 3.2. Bảng 1 (phải) cho thấy kết quả trên các metric này.

Quan sát đầu tiên là các mô hình mạnh mẽ nhất khi chúng tôi có các phương thức bổ sung tại đánh giá. Ngoài ra, khoảng cách giữa tính mạnh mẽ và hiệu suất trung bình cho cả hai phương pháp SSL khá nhỏ trong trường hợp này, có nghĩa là các phương thức bổ sung trong quá trình đánh giá có xu hướng chỉ cải thiện kết quả. Đáng chú ý là, vì các phương thức đánh giá bổ sung không có mặt trong quá trình huấn luyện downstream, nhiều tham số liên quan của chúng không thay đổi kể từ khi tiền huấn luyện, và tuy nhiên chúng vẫn có thể được kết hợp với các tham số đã fine-tune và cải thiện hiệu suất đánh giá. Điều này đặc biệt thú vị đối với MAE, vì tất cả các phương thức đầu vào phải đi qua lớp bộ mã hóa chia sẻ-phương thức cuối cùng.

Trong trường hợp thiếu phương thức tại đánh giá, chúng tôi thấy sự sụt giảm hiệu suất nhỏ và sự sụt giảm tính mạnh mẽ lớn cho cả hai phương pháp, mặc dù sự suy giảm tệ hơn đối với MAE¹. Tất nhiên, một số suy giảm hiệu suất được mong đợi khi các phương thức bị loại bỏ. Lý tưởng nhất, hiệu suất nên suy giảm một cách duyên dáng, có nghĩa là nó hoạt động không tệ hơn đáng kể trên các phương thức đánh giá so với nếu đó là những phương thức giống nhau được sử dụng trong quá trình huấn luyện.

Trong trường hợp các phương thức hoàn toàn khác nhau tại đánh giá, chúng tôi thấy rằng học tương phản thể hiện một số tính chất chuyển giao, nhưng MAE sụp đổ hoàn toàn. Điều này một lần nữa được mong đợi do sự khác biệt trong các mục tiêu tiền huấn luyện, và vì các tham số chia sẻ-phương thức duy nhất cho các mô hình tương phản là đầu phân loại tuyến tính cuối cùng trong khi bộ mã hóa MAE cũng có các tham số chia sẻ-phương thức trong lớp transformer cuối cùng. Đây dường như là thiết lập thách thức nhất cho tất cả các phương pháp SSL.

6.2. Phân tích Can thiệp Tính Mạnh Mẽ

Hiệu suất và tính mạnh mẽ của các can thiệp được đề xuất từ Phần 4.2 và các mô hình baseline được trình bày trong Bảng 1. Các metric này được trình bày như một trung bình trên tất cả các kết hợp phương thức huấn luyện/đánh giá cũng như trên các lát cắt kết hợp được xác định trong Phần 4.

MASD cải thiện cả hiệu suất và tính mạnh mẽ. Như một quan sát đầu tiên, MASD dẫn đến cải thiện Hiệu suất và cải thiện đáng kể Tính mạnh mẽ, đối với AudioSet, Kinetics-400, và ImageNet-Captions. Do đó, MASD đang giải quyết những điểm yếu của các phương pháp SSL gốc. Đặc biệt, nó giảm sự suy giảm trong trường hợp Thêm tại Test và Khả năng Chuyển giao, và trong trường hợp Học Tương phản, MASD tăng gấp đôi cả Hiệu suất và Tính mạnh mẽ. Những kết quả này nhất quán trên cả hai bộ dữ liệu, chứng minh tính tổng quát của các học tập. Sự suy giảm duy nhất là trong Thiếu tại Test được khắc phục bằng Wise-FT. Hơn nữa, kết quả của chúng tôi cho thấy rằng MASD tổng quát hóa trên ba loại tập phương thức khác nhau trên AudioSet, Kinetics-400, và ImageNet-Captions.

Để thấy rõ hơn lợi ích của các can thiệp được đề xuất, chúng tôi vẽ biểu đồ Tính mạnh mẽ so với Hiệu suất cho mỗi tập phương thức huấn luyện có thể trong Hình 6. Trong khi chúng tôi thấy rằng Tính mạnh mẽ thường tương quan với Hiệu suất, các can thiệp của chúng tôi khi kết hợp liên tục cải thiện Tính mạnh mẽ vượt xa đường xu hướng. Điều này tương tự như khái niệm "tính mạnh mẽ hiệu quả cao" như được định nghĩa trong (Taori et al., 2020).

MASD cải thiện tính mạnh mẽ vượt xa học có giám sát trên nhiều ví dụ hơn. Một câu hỏi tự nhiên là liệu huấn luyện downstream có giám sát trên dữ liệu có nhãn lớn hơn có thể giải quyết các vấn đề tính mạnh mẽ đa phương thức hay không. Trong Bảng 1, chúng tôi trình bày huấn luyện downstream trên 2M ví dụ có nhãn, tức là gấp 100 lần dữ liệu huấn luyện downstream có nhãn cho tất cả các thí nghiệm khác. Mặc dù chúng tôi thấy tăng 50% tính mạnh mẽ so với fine-tuning downstream thông thường, các thí nghiệm này vẫn kém hiệu suất so với MASD về Tính mạnh mẽ, đặc biệt là đối với Khả năng Chuyển giao, trong khi sử dụng nhiều nhãn hơn đáng kể.

Lợi ích tính mạnh mẽ tương quan với khoảng cách phương thức huấn luyện-kiểm tra. Để hiểu rõ hơn về MASD, chúng tôi tính toán các metric khi chúng tôi giảm số lượng phương thức chung giữa huấn luyện và đánh giá. Trong Hình 5, chúng tôi cho thấy Hiệu suất và Tính mạnh mẽ cho k = |M_T ∩ M_E| ∈ {0, 1, 2} (xem Eq. (6)), tức là không, một, hoặc hai phương thức chung. Chúng tôi có thể thấy rằng khi số lượng phương thức chung giảm, MASD suy giảm một cách duyên dáng hơn so với Học Tương phản chuẩn. WiseFT cung cấp sự ổn định bổ sung trong hiệu suất.

MASD giúp tận dụng tốt hơn tất cả các phương thức tại thời điểm đánh giá. Một tính chất khác của MASD là nó có thể tận dụng tất cả các phương thức có mặt tại đánh giá downstream, ngay cả khi những phương thức này không có sẵn tại huấn luyện downstream. Để thấy điều này, đối với mỗi tập phương thức huấn luyện downstream M_T, chúng tôi xác định tập phương thức đánh giá M_E mang lại hiệu suất cao nhất: arg max_{M_E⊆M} p(M_E, M_T) cho mỗi M_T ⊆ M.

Chúng tôi tóm tắt các phương thức đánh giá tốt nhất cho mỗi tập phương thức huấn luyện trong Bảng 2. Chúng tôi có thể thấy rằng đối với Học tương phản gốc, trong 2 trên 6 thiết lập huấn luyện, mô hình đạt hiệu suất tốt nhất bằng cách sử dụng các phương thức đánh giá giống nhau mà nó đã được huấn luyện, M_E = M_T. Tuy nhiên, đối với MASD, chúng tôi thấy rằng nó luôn hoạt động tốt nhất khi chúng tôi sử dụng tất cả các phương thức, M_E = {A, V, T}. Đối với MAE, chúng tôi thấy việc sử dụng thậm chí lớn hơn – trong khi trong 5 trường hợp mô hình gốc thích một tập con của các phương thức tại đánh giá, với MASD mô hình trong tất cả 6 trường hợp đều được hưởng lợi từ việc có tất cả các phương thức tại đánh giá.

MASD đạt được hiệu suất cạnh tranh so với các phương pháp khác. Để đặt MASD vào góc độ tốt hơn, chúng tôi so sánh hiệu suất của nó với các phương pháp khác trong tài liệu. Trong Bảng 3, chúng tôi cho thấy kết quả sử dụng cùng các phương thức huấn luyện và đánh giá, chúng tôi làm như vậy cho bốn tập phương thức khác nhau: chỉ âm thanh, chỉ video; âm thanh và video; âm thanh, video và văn bản. Khi sử dụng tập huấn luyện downstream AudioSet 20K làm dữ liệu có nhãn duy nhất, MASD đạt hiệu suất cao hơn hoặc bằng các phương pháp được báo cáo khác, trên tất cả các kết hợp phương thức được nghiên cứu. Hơn nữa, nếu sử dụng văn bản, chúng tôi có được hiệu suất thậm chí vượt trội (mặc dù các phương pháp khác không sử dụng văn bản). Điều này cho thấy rằng MASD không chỉ khắc phục các vấn đề tính mạnh mẽ cho các phương pháp SSL cơ bản, mà còn giữ được kết quả cạnh tranh trên các thiết lập đánh giá khác nhau. Chúng tôi lưu ý rằng số AV của chúng tôi là số tốt nhất được báo cáo trong tất cả các phương pháp chỉ có quyền truy cập vào nhãn AS-20k.

7. Thảo luận

Trong bài báo này, chúng tôi đã định lượng khái niệm tính mạnh mẽ trong một biểu diễn đa phương thức. Chúng tôi đã giới thiệu một số định nghĩa đơn giản về tính mạnh mẽ dựa trên hiệu suất trung bình và trường hợp xấu nhất trên các tập con của các phương thức. Chúng tôi đã đặc trưng tính mạnh mẽ của các biểu diễn đã học hiện đại dựa trên học tương phản và masked autoencoders. Chúng tôi thấy rằng hiệu suất suy giảm với những bất đồng lớn hơn giữa các phương thức huấn luyện và kiểm tra, tuy nhiên những suy giảm này có thể được giảm thiểu với các cải tiến huấn luyện dựa trên chưng cất MASD và tổng hợp WiseFT. Sử dụng các kỹ thuật này, chúng tôi có thể cải thiện so với hiện đại với AudioSet bằng cách tận dụng dữ liệu đa phương thức không có sẵn cho nhiệm vụ downstream.

Chúng tôi quan sát một số hạn chế cho nghiên cứu hiện tại này và các cơ hội mở rộng và bước tiếp theo. Đầu tiên, chúng tôi tập trung học biểu diễn trên dữ liệu đa phương thức đồng nhất và không rõ ràng nghiên cứu này sẽ thành công như thế nào trong các bộ dữ liệu không đồng nhất quy mô lớn. Hơn nữa, mặc dù các benchmark của chúng tôi định lượng hành vi đa phương thức trên một số bộ dữ liệu, không rõ ràng điều gì thực sự có thể đạt được cho cấu trúc và tính năng của một bộ dữ liệu đa phương thức nhất định. Chúng tôi rất nghi ngờ rằng những kết quả này có thể phụ thuộc nhiều vào đặc điểm của một bộ dữ liệu đa phương thức nhất định nhưng còn nhiều việc phải làm để đặc trưng cách các xu hướng được xác định tồn tại và các benchmark này thay đổi như thế nào trên các điều kiện đa phương thức điển hình.

8. Đóng góp của Tác giả và Lời Cảm ơn

Brandon McKinzie thực hiện phần lớn codebase; dẫn dắt các hướng nghiên cứu; cải thiện các thiết kế ban đầu cho các kiến trúc mô hình và mục tiêu huấn luyện khác nhau; hỗ trợ trong việc xây dựng các metric; chạy tất cả các thí nghiệm ngoại trừ wise-ft, và các thí nghiệm MAE ban đầu; viết phụ lục và giúp viết bài báo chính.

Vaishaal Shankar đồng phạm vi các metric quan tâm chính cho bài báo; đề xuất và chạy tất cả các thí nghiệm WISE-FT; đề xuất, định nghĩa và chạy tất cả các thí nghiệm ImageNet captions; viết phiên bản ban đầu của phần giới thiệu và đồng viết các phần nghiên cứu liên quan; giúp viết bài báo chính.

Joseph Cheng giúp thiết lập codebase; thực hiện tiền xử lý âm thanh; giúp thực hiện đầu vào video, thực hiện MAE; chạy các thí nghiệm ban đầu trên MAE và AudioSet; viết phần nghiên cứu liên quan.

Jonathon Shlens tư vấn về dự án, thảo luận các thí nghiệm, hỗ trợ phân tích, và giúp viết.

Yinfei Yang tư vấn về dự án, cung cấp phản hồi về viết.

Alex Toshev khởi xướng dự án, dẫn dắt hướng nghiên cứu, đồng thiết kế khung đánh giá tính mạnh mẽ; thiết kế các đóng góp thuật toán chính của bài báo; viết phần lớn bài báo.

Các tác giả muốn cảm ơn Jason Ramapuram và Tatiana Likhomanenko vì những gợi ý hữu ích về Knowledge Distillation; Jason Ramapuram, Devon Hjelm, Hadi Pour Ansari, và Barry Theobold vì phản hồi chi tiết về các thí nghiệm, thiết kế thuật toán, cấu trúc tổng thể bài báo và viết; Oncel Tuzel, Sachin Mehta, Fartash Faghri, Alkesh Patel vì phản hồi liên tục trong suốt dự án; Tom Nickson và Angelos Katharopoulos vì hỗ trợ cơ sở hạ tầng liên tục.

Tài liệu tham khảo

[Danh sách tài liệu tham khảo được dịch tiếp theo nhưng do độ dài có thể cần rút gọn]

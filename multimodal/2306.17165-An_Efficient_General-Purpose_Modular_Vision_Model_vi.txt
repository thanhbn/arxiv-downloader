# 2306.17165.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2306.17165.pdf
# Kích thước tệp: 3215497 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Một Mô hình Thị giác Đa dụng Hiệu quả thông qua
Huấn luyện Đa nhiệm Không đồng nhất
Zitian Chen1, Mingyu Ding2, Yikang Shen3, Wei Zhan2,
Masayoshi Tomizuka2, Erik Learned-Miller1, Chuang Gan1,3
1Đại học Massachusetts Amherst,2Đại học California Berkeley,3MIT-IBM Watson AI Lab

Tóm tắt
Chúng tôi trình bày một mô hình có thể thực hiện nhiều nhiệm vụ thị giác và có thể được điều chỉnh cho các nhiệm vụ xuôi dòng khác một cách hiệu quả. Mặc dù có tiến bộ đáng kể trong học đa nhiệm vụ, hầu hết các nỗ lực đều tập trung vào việc học từ dữ liệu đa nhãn: một bộ hình ảnh đơn với nhiều nhãn nhiệm vụ. Những bộ dữ liệu đa nhãn như vậy rất hiếm, nhỏ và tốn kém. Chúng tôi gọi không đồng nhất để chỉ các bộ hình ảnh có nhãn nhiệm vụ khác nhau, hoặc các kết hợp của các bộ dữ liệu đơn nhiệm vụ. Rất ít người khám phá việc huấn luyện trên những bộ dữ liệu không đồng nhất như vậy. Các mô hình thị giác đa dụng vẫn bị chi phối bởi tiền huấn luyện đơn nhiệm vụ, và vẫn chưa rõ làm thế nào để mở rộng quy mô các mô hình đa nhiệm vụ bằng cách tận dụng các bộ dữ liệu thị giác chính được thiết kế cho các mục đích khác nhau. Những thách thức nằm ở việc quản lý sự khác biệt nội tại lớn giữa các nhiệm vụ thị giác, bao gồm phân phối dữ liệu, kiến trúc, mô-đun đặc thù nhiệm vụ, quy mô bộ dữ liệu, và chiến lược lấy mẫu. Để giải quyết những thách thức này, chúng tôi đề xuất sửa đổi và mở rộng quy mô transformer thị giác hỗn hợp chuyên gia (MoE), để chúng có thể đồng thời học phân loại, phát hiện, và phân đoạn trên các bộ dữ liệu thị giác chính đa dạng bao gồm ImageNet, COCO, và ADE20K. Phương pháp của chúng tôi đạt được kết quả tương đương với các mô hình tiên tiến đơn nhiệm vụ và thể hiện khả năng tổng quát hóa mạnh mẽ trên các nhiệm vụ xuôi dòng. Do tính mô-đun nổi lên, mô hình đa dụng này phân hủy thành các thành phần hiệu suất cao, thích ứng hiệu quả với các nhiệm vụ xuôi dòng. Chúng tôi có thể tinh chỉnh nó với ít tham số huấn luyện hơn, ít tham số mô hình hơn, và ít tính toán hơn. Ngoài ra, tính mô-đun của nó cho phép mở rộng dễ dàng trong các kịch bản học liên tục-mà-không-quên. Cuối cùng, những chức năng này có thể được kiểm soát và kết hợp để đáp ứng các yêu cầu khác nhau của các nhiệm vụ xuôi dòng.

1 Giới thiệu
Hiểu biết thị giác toàn diện đòi hỏi một mô hình đa dụng có khả năng thực hiện các nhiệm vụ thị giác đa dạng. Với mục tiêu tương tự, học đa nhiệm vụ (MTL), cho phép huấn luyện đồng thời các mô hình trên nhiều nhiệm vụ và cho phép chúng tận dụng thông tin chia sẻ, đã được khám phá rộng rãi. Hầu hết các nỗ lực MTL [3,37,26] đã được thực hiện bằng cách học từ các bộ dữ liệu đa nhãn, nơi mỗi đầu vào có nhiều loại chú thích khác nhau. Tuy nhiên, những bộ dữ liệu như vậy với nhiều chú thích thường không thực tế để có được. Và các bộ dữ liệu phân loại, phát hiện, và phân đoạn chính (ImageNet [5], COCO [22], và ADE20K [47]) không có hình ảnh chồng chéo. Do đó, mô hình hiện tại cho các mô hình thị giác đa dụng vẫn bị chi phối bởi tiền huấn luyện đơn nhiệm vụ (ví dụ, phân loại hình ảnh [23], tự chưng cất [2], hoặc học tương phản đa phương thức [41]) và sau đó tinh chỉnh trên các nhiệm vụ xuôi dòng. Một minh họa chi tiết về các sơ đồ tiền huấn luyện khác nhau được thể hiện trong Hình 1.

Công trình trước đó Mod-Squad [3] đề xuất sử dụng hỗn hợp chuyên gia (MoE) và mất mát thông tin tương hỗ để giải quyết xung đột nhiệm vụ trong MTL. Tuy nhiên, nó đơn giản hóa quá mức một số thiết kế mạng đặc thù nhiệm vụ và thành công của mô hình này phụ thuộc rất nhiều vào các bộ dữ liệu đa nhãn, rất khó để

Bản thảo. Đang được xem xét.arXiv:2306.17165v1  [cs.CV]  29 Jun 2023

--- TRANG 2 ---
1. Huấn luyện từ đầu
Mô hình 1
Con mèo
Mô hình 2
Mô hình 3ImageNetCOCOADE20K
3. Huấn luyện Đa nhiệm Đa nhãn
Mô hình
Taskonomy
2. Tiền huấn luyện rồi Tinh chỉnh
Mô hình
Con mèoImageNet
Mô hình
COCOKhởi tạo4. Huấn luyện Đa nhiệm Không đồng nhất
Con mèo
Mô hình 
ImageNetCOCOADE20K
Hình 1: Các cách huấn luyện khác nhau. (1) Huấn luyện từ đầu: Huấn luyện một mô hình cho một nhiệm vụ đơn từ đầu. (2) Tiền huấn luyện rồi Tinh chỉnh: Tiền huấn luyện một mô hình trên một bộ dữ liệu và sau đó tinh chỉnh mô hình trên các bộ dữ liệu khác. (3) Huấn luyện Đa nhiệm Đa nhãn: Huấn luyện một mô hình có thể tạo ra nhiều loại đầu ra đồng thời. Bộ dữ liệu được kỳ vọng có nhiều chú thích cho các nhiệm vụ khác nhau trên mỗi hình ảnh huấn luyện. (4) Huấn luyện Đa nhiệm Không đồng nhất (MTHT): Huấn luyện một mô hình có thể tạo ra các loại đầu ra khác nhau tương ứng với mỗi nhiệm vụ. Mô hình có thể sử dụng dữ liệu huấn luyện được thiết kế cho bất kỳ nhiệm vụ đơn nào. Nó có thể sử dụng chúng kết hợp để đạt được huấn luyện đa nhiệm vụ.

có được và mở rộng quy mô. Do đó, vẫn chưa rõ: 1) Làm thế nào để mở rộng quy mô mô hình MTL này cho huấn luyện đa nhiệm vụ không đồng nhất trên các bộ dữ liệu thị giác máy tính thông thường; 2) Liệu mô hình này có thể được sử dụng như một xương sống thị giác đa dụng có thể dễ dàng thích ứng với nhiều nhiệm vụ xuôi dòng; 3) Liệu chúng ta có thể tận dụng thành công của các phương pháp đơn nhiệm vụ thay vì loại bỏ các mô-đun phức tạp và đơn giản hóa mạng con đặc thù nhiệm vụ.

Một vấn đề khác là các mô hình thị giác quy mô lớn trước đây [3,23,41,2] không xem xét việc thích ứng nhanh trên các nhiệm vụ xuôi dòng. Một hạn chế chung của các mô hình quy mô lớn là việc thích ứng với các nhiệm vụ xuôi dòng đòi hỏi cập nhật tất cả các tham số, điều này có thể cực kỳ tốn kém về thời gian và tài nguyên tính toán. Ví dụ, các mô hình lớn như GPT-3 [1] với 175B tham số, có thể mất hàng tháng để huấn luyện, khiến việc thích ứng toàn bộ mô hình cho một nhiệm vụ mới nhỏ trở nên không thực tế. Do đó, thích ứng hiệu quả là một tính năng thực tế quan trọng để triển khai mô hình thành công.

Để giải quyết những vấn đề này, chúng tôi xây dựng một khung huấn luyện đa nhiệm vụ không đồng nhất quy mô lớn dựa trên transformer thị giác mô-đun có thể đồng thời thực hiện ba nhiệm vụ thị giác cơ bản: phân loại, phát hiện, và phân đoạn. Chúng tôi gọi khung này là Người học Đa nhiệm Không đồng nhất (MTHL). Được lợi từ bộ huấn luyện đa dạng hơn được thiết kế cho nhiều mục đích, khung này tổng quát hóa tốt hơn và đủ phong phú về mặt ngữ nghĩa để thích ứng xuôi dòng nhanh chóng, điều này thường khó có được từ một nhiệm vụ/bộ dữ liệu tiền huấn luyện đơn (đồng nhất).

Chúng tôi cũng giải quyết vấn đề thích ứng hiệu quả bằng cách tận dụng tính mô-đun mạnh mẽ trong mô hình của chúng tôi. Như thể hiện trong Hình 2, MTHL có thể thích ứng hiệu quả trong một số khía cạnh bao gồm giảm tham số huấn luyện, tham số mô hình, và chi phí tính toán. Mô-đun hỗn hợp chuyên gia cho phép mô hình chọn phần có ý nghĩa ngữ nghĩa nhất để chuyển giao nhanh hơn đến các nhiệm vụ xuôi dòng bằng cách đơn giản học các bộ định tuyến mới. Hơn nữa, mô hình có thể dễ dàng mở rộng bằng cách thêm các chuyên gia để giải quyết vấn đề học liên tục.

Những đóng góp chính của chúng tôi có thể được tóm tắt như sau:
• Huấn luyện đa nhiệm vụ không đồng nhất quy mô lớn. Chúng tôi khám phá huấn luyện không đồng nhất trên ba nhiệm vụ thị giác máy tính cơ bản: phân loại, phát hiện, và phân đoạn với các bộ dữ liệu thị giác chính. Chúng tôi chứng minh rằng một mô hình thực hiện ba nhiệm vụ có thể sánh ngang với tiên tiến đơn nhiệm vụ.
• Tổng quát hóa mạnh mẽ trên các bộ dữ liệu xuôi dòng. Huấn luyện không đồng nhất cung cấp lợi thế của nhận thức đa dạng và khả năng xử lý phạm vi rộng hơn các kịch bản, dẫn đến tổng quát hóa tốt hơn cho các bộ dữ liệu xuôi dòng.
• Thích ứng mô-đun với hiệu quả. Sự nổi lên của tính mô-đun cho phép kiểm soát linh hoạt kiến trúc và cung cấp một số cách thích ứng kiến trúc đơn giản và hiệu quả.
• Học liên tục mà không quên. Mô hình có thể dễ dàng tận dụng các chuyên gia hiện có để thích ứng với các nhiệm vụ mới bằng cách học các bộ định tuyến mới. Ngoài ra, nó có thể kết hợp các chuyên gia mới mà không làm gián đoạn kiến trúc hiện tại, do đó tránh được việc quên thảm khốc.

2

--- TRANG 3 ---
Mô-đun
MoE
Chuyên gia
Bộ định tuyến D
1
Bộ định tuyến D
2
Bộ định tuyến 
D
n
A. Huấn luyện đa nhiệm không đồng nhất 
với các bộ định tuyến đặc thù bộ dữ liệu
B. Thích ứng mô-đun trên 
các bộ dữ liệu xuôi dòng
Mô-đun
MoE
Chuyên gia
Bộ định tuyến Mới
Giảm tham số huấn luyện
Đóng băng hầu hết 
các chuyên gia
Mô-đun
MoE
Chuyên gia
Bộ định tuyến Mới
Giảm tham số mô hình
Loại bỏ chuyên gia với 
tần suất sử dụng thấp
Mô-đun
MoE
Chuyên gia
Bộ định tuyến Mới
Giảm chi phí tính toán
Đặt Top
-
K=2 
thay vì Top
-
K=3
Mô-đun
MoE
Chuyên gia
Bộ định tuyến Mới
Mở rộng mô hình đơn giản
Thêm chuyên gia mới
Đóng băngCon mèo
Bộ dữ liệu 1Bộ dữ liệu 2Bộ dữ liệu nPhân loạiPhát hiệnPhân đoạn

Hình 2: Thích ứng mô-đun hiệu quả. Tính mô-đun mạnh mẽ tạo điều kiện thuận lợi cho việc thích ứng hiệu quả với các bộ dữ liệu mới: 1) Giảm tham số huấn luyện bằng cách chỉ học các bộ định tuyến mới và một vài chuyên gia tùy chọn trong khi đóng băng các tham số khác. 2) Giảm tham số mô hình thông qua việc học các bộ định tuyến mới và loại bỏ các chuyên gia hiếm khi được chọn. 3) Giảm chi phí tính toán thông qua việc học các bộ định tuyến mới với Top-K nhỏ hơn khiến ít chuyên gia được chọn trong một lần truyền tiến. 4) Mở rộng mô hình đơn giản thông qua việc thêm và học một vài chuyên gia mới cho mỗi mô-đun MoE trong khi đóng băng các chuyên gia cũ. Các cách thích ứng trên có thể được kết hợp để phù hợp với các nhu cầu cụ thể.

2 Công trình liên quan
Học đa nhiệm vụ. Học đa nhiệm vụ [15] học chung nhiều nhiệm vụ liên quan với một mô hình đơn. Gần đây, các kiến trúc MTL dựa trên transformer [37] đã trở nên phổ biến. Một số công trình [14,25] cố gắng thống nhất không gian đầu vào và đầu ra cho các nhiệm vụ khác nhau. Một số công trình [3,37,26] loại bỏ mô-đun đặc thù nhiệm vụ phức tạp để đơn giản và tiến hành học đa nhiệm vụ trên bộ dữ liệu đa nhãn. Tuy nhiên, những công trình này hoặc dựa vào một bộ dữ liệu đa nhãn đơn hoặc mất một số tính năng nhận thức khi loại bỏ các mô-đun đặc thù nhiệm vụ và thống nhất đầu vào/đầu ra [14,25]. Trong khi Ubernet[17] điều chỉnh một khung dựa trên CNN có thể học từ nhiều bộ dữ liệu, nó gặp khó khăn với xung đột nhiệm vụ và có xu hướng có hiệu suất thấp hơn khi học từ nhiều hơn một bộ dữ liệu, điều này khiến nó khó tổng quát hóa cho các ứng dụng xuôi dòng. Ngược lại, MTHL có thể học từ các bộ dữ liệu đa dạng và vẫn đạt được hiệu suất tương đương với các phương pháp đơn nhiệm vụ tiên tiến. Ngoài ra, nó có thể tận dụng thành công của các phương pháp đơn nhiệm vụ bằng cách áp dụng các thiết kế tương tự, bao gồm các mô-đun đặc thù nhiệm vụ độc đáo (ví dụ, bộ tạo neo), tiền xử lý dữ liệu, và các kỹ thuật kỹ thuật phức tạp (ví dụ, loại bỏ tối đa không). Những thiết kế này không tầm thường nhưng cần thiết để đạt được mô hình tốt nhất.

Hỗn hợp Chuyên gia (MoE). Jacobs et al. [13] giới thiệu MoE như một phương pháp để hợp nhất các mô hình con và thực hiện tính toán có điều kiện. Gần đây, kỹ thuật này đã được sử dụng phổ biến để giảm chi phí tính toán trong khi duy trì dung lượng mô hình lớn [32]. Một số nghiên cứu [19,8,30,27] đã tận dụng MoE để huấn luyện các mô hình khổng lồ với hàng nghìn tỷ tham số với chi phí tính toán tương đối thấp. Ngược lại, chúng tôi sử dụng kỹ thuật này chủ yếu để quản lý các mô hình con và tiến hành thích ứng mô-đun trên các nhiệm vụ xuôi dòng.

Học chuyển giao hiệu quả tham số. Kỹ thuật Adapter được đề xuất như một lớp độc lập có thể được tích hợp vào mạng neural hiện có để chuyển giao hiệu quả. LoRA [11] sử dụng cấu trúc thắt cổ chai để áp đặt ràng buộc hạng thấp trên các cập nhật trọng số. Các phương pháp khác tích hợp các adapter dựa trên CLIP [9,38,45], mô-đun lấy mẫu lên và xuống [20], và các tham số bias bổ sung [42] để giảm tham số huấn luyện trong quá trình tinh chỉnh. Công trình của chúng tôi tập trung vào việc chọn phần liên quan nhất về mặt ngữ nghĩa của mô hình và thích ứng với các nhiệm vụ xuôi dòng một cách hiệu quả. Không cần mô-đun mới được thiết kế bổ sung nào.

Học liên tục. Học liên tục liên quan đến việc xử lý một tập hợp đa dạng các nhiệm vụ và tích lũy kiến thức thông qua một loạt huấn luyện. Các nỗ lực gần đây đã được thực hiện để giải quyết vấn đề quên thảm khốc, bao gồm áp đặt chính quy hóa [16,44,31] và giữ lại một bộ đệm nhỏ dữ liệu để phát lại [24,28]. Một số phương pháp [39,12] mở rộng mạng động bằng cách thêm neuron vào mỗi lớp MLP hoặc tích chập. Ngược lại, thiết kế mô-đun của chúng tôi cho phép mở rộng được tổ chức tốt một cách đơn giản bằng cách thêm chuyên gia và học các bộ định tuyến mới. Hơn nữa, vì mỗi bộ dữ liệu có bộ định tuyến của riêng nó, 3

--- TRANG 4 ---
các chuyên gia được thêm sẽ không được chọn bởi bộ dữ liệu trước đó. Không giống như các kỹ thuật mở rộng khác, phương pháp của chúng tôi không bị quên thảm khốc.

3 Phương pháp
Chúng tôi bắt đầu với định nghĩa của huấn luyện đa nhiệm vụ không đồng nhất. Giả sử chúng ta có M bộ dữ liệu D1, D2, ..., DM. Mỗi bộ dữ liệu chứa một tập hợp cặp huấn luyện {I; Ti(I)} và Ti là nhiệm vụ trên bộ dữ liệu Di ánh xạ hình ảnh I tới Ti(I). Ở đây, chúng tôi giả định mỗi bộ dữ liệu chỉ có một nhiệm vụ để thực hiện cho đơn giản. Huấn luyện đa nhiệm vụ không đồng nhất là học một mô hình chung trên M bộ dữ liệu cùng một lúc.

3.1 Sơ bộ
Hỗn hợp Chuyên gia (MoE). Một lớp MoE chứa một nhóm mạng chuyên gia E1, E2, ..., EN và một mạng định tuyến G. Mạng định tuyến G tính toán trọng số Gk(x) cho mỗi chuyên gia Ek với đầu vào x và đầu ra của lớp MoE là tổng có trọng số của đầu ra của mỗi chuyên gia Ek(x). Chính thức, đầu ra của lớp MoE là

y = Σ(k=1 to N) Gk(x)Ek(x). (1)

Mạng định tuyến G là mạng Định tuyến Top-K [32] mà chỉ có K chuyên gia với trọng số cao nhất đóng góp vào đầu ra cuối cùng:

G(x) = TopK(Softmax(x Wg), k) (2)

trong đó TopK(·, k) đặt tất cả các phần tử trong vector thành zero ngoại trừ các phần tử có K giá trị lớn nhất.

Mất mát thông tin tương hỗ. Mod-Squad [3] đề xuất mất mát thông tin tương hỗ như một mất mát phụ để gán tốt hơn các chuyên gia cho các nhiệm vụ sao cho mỗi chuyên gia có nhiều khả năng được sử dụng cho một tập hợp cố định các nhiệm vụ. Ngược lại, động lực chính trong MTHL là khuyến khích các chuyên gia chuyên về các bộ dữ liệu và sau đó khi thích ứng với các nhiệm vụ xuôi dòng, các bộ dữ liệu xuôi dòng có nhiều khả năng kích hoạt một tập hợp con nhỏ các chuyên gia. Vì vậy chúng tôi có M mạng định tuyến đặc thù bộ dữ liệu và sửa đổi mất mát để các chuyên gia được gán cho các bộ dữ liệu thay vì các nhiệm vụ:

LMI = -Σ(i=1 to M)Σ(j=1 to K) P(Di, Ej) log P(Di, Ej) + Σ(i=1 to M) P(Di) log P(Di) + Σ(j=1 to K) P(Ej) log P(Ej). (3)

Như trong [3], chúng tôi giả định rằng P(Di) = 1/M vì chúng tôi muốn tất cả các bộ dữ liệu được coi là quan trọng như nhau. Chúng tôi có P(Ej|Di) = Σ(x∈Di) G^j_i(x) trong đó G^j_i là trọng số của chuyên gia Ej cho bộ dữ liệu Di. Với P(Ej|Di), chúng tôi có thể lấy P(Di, Ej) = P(Ej|Di)P(Di) và P(Ej) = Σ(i=1 to M) P(Di, Ej).

3.2 Huấn luyện Đa nhiệm Không đồng nhất
Kiến trúc xương sống. Huấn luyện đa nhiệm vụ không đồng nhất của chúng tôi là một khung tổng quát trực giao với thiết kế kiến trúc mô hình. Tất cả các cấu trúc dựa trên Transformer hoặc MLP đều có thể áp dụng. Trong công trình này, chúng tôi chọn hai kiến trúc transformer tiên tiến gần đây cho cả nhiệm vụ phân loại hình ảnh và dự đoán dày đặc làm xương sống: Swin-Transformer [23] và DaviT [6]. Chúng tôi thay thế các lớp MLP trong hai mô hình này bằng các lớp MLP MoE.

Mô-đun đặc thù nhiệm vụ. Các nhiệm vụ thị giác đòi hỏi thiết kế cụ thể của các mô-đun để xử lý dữ liệu và các cách nhận thức khác nhau có tác động lớn đến hiệu suất. Trong khi các nghiên cứu gần đây [25,14] có xu hướng sử dụng mô-đun nhiệm vụ chia sẻ cho tất cả các nhiệm vụ, chúng tôi tin rằng sự khác biệt vốn có trong các nhiệm vụ thị giác khiến một mô-đun chia sẻ khó nắm bắt thông tin cần thiết cho tất cả các nhiệm vụ. Do đó, MTHL kết hợp tất cả các mô-đun được thiết kế đặc thù nhiệm vụ (ví dụ, mạng kim tự tháp đặc trưng), chỉ có xương sống transformer được chia sẻ giữa tất cả các nhiệm vụ.

Chiến lược lấy mẫu. Lấy mẫu dữ liệu đóng vai trò quan trọng trong huấn luyện không đồng nhất. Các bộ dữ liệu có thể có mức độ quy mô khác nhau với khoảng cách lớn trong kích thước batch. Ví dụ, trong khi một GPU đơn có thể làm việc với 128 mẫu trên phân loại hình ảnh, nó chỉ có thể chịu được 2 mẫu trên phát hiện và phân đoạn. Hầu hết các khung đa nhiệm vụ [3,37,17] có xu hướng cập nhật mạng sau khi truyền tiến cho tất cả các nhiệm vụ. Tuy nhiên, các phương pháp như vậy không thực tế vì bộ nhớ GPU bị tiêu thụ nặng khi kích hoạt tất cả các mô-đun thị giác dày đặc, ví dụ, đầu phát hiện và đầu phân đoạn. Ngoài ra, truyền tiến các mẫu từ tất cả các nhiệm vụ trong một batch không thể mở rộng khi có nhiều nhiệm vụ hơn.

Để giải quyết vấn đề trên, MTHL áp dụng lấy mẫu hai bước. Chúng tôi trước tiên áp dụng lấy mẫu có trọng số để chọn một trong M bộ dữ liệu, sau đó lấy mẫu ngẫu nhiên một batch dữ liệu từ bộ dữ liệu được chọn. Trọng số được gán cho mỗi bộ dữ liệu Di để lấy mẫu được ký hiệu là wsample i, có thể được định nghĩa trước bằng tổng số lần lặp cần thiết để hội tụ trong huấn luyện bộ dữ liệu đơn, với một số điều chỉnh theo kinh nghiệm. Lưu ý rằng đối với các bộ dữ liệu tương đối nhỏ, một trọng số đủ lớn nên được gán để ngăn chặn sự thoái hóa do huấn luyện quá mức trên các bộ dữ liệu khác.

Tối ưu hóa và hội tụ. Mỗi nhiệm vụ trong khung của chúng tôi được liên kết với mô-đun độc đáo của nó được thiết kế để xử lý dữ liệu và mất mát riêng của nó. Các mất mát trên bộ dữ liệu Di được tính trọng số và tối ưu hóa xen kẽ với trọng số được định trước wli cho mỗi bộ dữ liệu. Một thách thức trong tối ưu hóa là sự hiện diện của xung đột gradient giữa các nhiệm vụ khác nhau. Những xung đột này cản trở tối ưu hóa chung và làm chậm quá trình hội tụ. Cũng không phải hiếm khi quan sát thấy một nhiệm vụ chi phối quá trình huấn luyện trong khi các nhiệm vụ khác tụt hậu. Chúng tôi thấy rằng trọng số mất mát và trọng số lấy mẫu được định nghĩa rõ ràng góp phần vào sự ổn định của huấn luyện, và bộ tối ưu hóa batch lớn Lamb [40] hoạt động tốt trong huấn luyện không đồng nhất. Hội tụ hiệu quả trong huấn luyện không đồng nhất đòi hỏi khoảng 50 phần trăm lần lặp nhiều hơn so với tổng số lần lặp cho mỗi huấn luyện đơn nhiệm vụ riêng lẻ. Những lần lặp huấn luyện bổ sung này giải thích cho sự phức tạp do tối ưu hóa chung trên các nhiệm vụ thị giác đa dạng.

Mất mát thông tin tương hỗ mới cho huấn luyện đa nhiệm vụ không đồng nhất. Trong Mod-Squad [3], mất mát thông tin tương hỗ trong Phương trình 3 có thể được tính toán trong mỗi batch vì tất cả các nhiệm vụ được chứa trong một batch. Tuy nhiên, tính toán P(D, E) và P(E) trong một batch được lấy mẫu từ một bộ dữ liệu ngẫu nhiên trong huấn luyện không đồng nhất dẫn đến sự thiên vị nặng. Để xử lý điều này, chúng tôi sử dụng một phép tính gần đúng được lấy cảm hứng từ ý tưởng sau:

∂/∂x[x log x] = 1 + log x = ∂/∂x[(1 + log c)x]|c=x. (4)

Điều này gợi ý rằng nếu chúng ta thay thế x log x bằng (1 + log c)x, và c là một phép tính gần đúng tốt của x, thì chúng ta vẫn sẽ có gradient tương tự. Trong trường hợp của chúng tôi, chúng tôi sẽ ước tính chạy của phân phối chung P(D, E) bằng bộ đệm B(D, E). Ước tính chạy B(D, E) tránh sự thiên vị nặng do ước tính P(D, E) từ một bộ dữ liệu nhiệm vụ đơn. Trong mỗi lần truyền tiến khi chúng tôi lấy mẫu bộ dữ liệu Di, chúng tôi cập nhật động lượng B(Di, E) với động lượng là 0.98. Điều này giữ cho ước tính của B gần với phân phối chung mong muốn. Sử dụng ý tưởng này, chúng tôi viết lại Phương trình 3 và sử dụng phương trình kết quả làm hàm mất mát để tính toán gradient. Phương trình được cho như:

LMI = -Σ(i=1 to M)Σ(j=1 to K) [1 + log B(Di, Ej)]P(Di, Ej) + Σ(j=1 to K) [1 + log(Σ(i=1 to M) B(Di, Ej))]P(Ej). (5)

Ở đây, P(Di, Ej), P(Ej) được tính toán trong mỗi lần truyền tiến lan truyền ngược gradient. Nếu Di không được lấy mẫu trong lần truyền tiến hiện tại, P(Di, Ej) được đặt thành 0. Lưu ý rằng P(Di) log P(Di) bị bỏ qua như một hằng số. Khi thích ứng với các bộ dữ liệu xuôi dòng mới, bộ đệm vẫn ghi nhớ P(D, E) cho các bộ dữ liệu cũ. Do đó, mất mát MI vẫn có thể được tính toán để cân bằng các chuyên gia trên các bộ dữ liệu mới, điều này không áp dụng được trong [3].

3.3 Thích ứng Hiệu quả trên Các Nhiệm vụ Xuôi dòng
Mod-squad [3] khám phá thiết kế mô-đun trong học đa nhiệm vụ, giúp giảm thiểu xung đột nhiệm vụ và cho phép trích xuất các mô hình con cho các nhiệm vụ cụ thể. Tuy nhiên, học từ một bộ dữ liệu đa nhãn đơn, khả năng áp dụng của nó bị giới hạn trong các kịch bản tương tự như bộ dữ liệu được tiền huấn luyện, do đó hạn chế khả năng tổng quát hóa của nó trên các bộ dữ liệu thị giác đa dạng. Do đó, khó để phương pháp này đạt được đủ lợi ích từ huấn luyện đa nhiệm vụ, và hiệu suất xuôi dòng của nó bị hạn chế phần nào.

So sánh, chúng tôi mở rộng quy mô học đa nhiệm vụ cho các bộ dữ liệu thị giác chính, dẫn đến tổng quát hóa tốt hơn trên các nhiệm vụ xuôi dòng. Được lợi từ tính mô-đun mạnh mẽ, MTHL có thể dễ dàng phân hủy thành các thành phần hiệu suất cao và cũng cho phép lựa chọn linh hoạt hơn các thành phần có ý nghĩa ngữ nghĩa khi chuyển giao đến các nhiệm vụ xuôi dòng, đảm bảo khả năng thích ứng hiệu quả.

5

--- TRANG 6 ---
MTHL có hai lợi thế hấp dẫn: 1) Các ứng dụng xuôi dòng có thể chọn các chuyên gia phù hợp nhất với kịch bản xuôi dòng. Điều này có thể được thực hiện bằng cách học một bộ định tuyến mới trong mỗi mô-đun MoE để tìm các chuyên gia tốt cho nhiệm vụ xuôi dòng. Chúng tôi coi một chuyên gia là chuyên gia tốt nếu nó được chọn với tần suất cao bởi bộ định tuyến trên bộ dữ liệu xuôi dòng. Các bộ định tuyến rất nhẹ (0.4M tham số) và có thể nhanh chóng hội tụ đến tối ưu trong khi đóng băng tất cả các tham số khác. 2) Chúng ta có thể dễ dàng kiểm soát kiến trúc trong mỗi thành phần nhỏ (một mô-đun MoE nhỏ). Dễ dàng mở rộng hoặc cắt tỉa mô hình bằng cách đơn giản thêm hoặc loại bỏ các chuyên gia. Tính linh hoạt này cho phép tùy chỉnh hiệu quả mô hình dựa trên các yêu cầu cụ thể của nhiệm vụ đang thực hiện.

Với hai lợi thế này, chúng ta có thể thực hiện tinh chỉnh hiệu quả trong các khía cạnh sau như thể hiện trong Hình 2: 1) ít tham số huấn luyện hơn. Mô hình chỉ cần học một bộ định tuyến mới cho bộ dữ liệu xuôi dòng và tùy chọn tinh chỉnh một vài chuyên gia trong mỗi mô-đun MoE. 2) ít tham số mô hình hơn. Sau khi học một bộ định tuyến mới cho bộ dữ liệu xuôi dòng mới, chúng ta có thể xếp hạng các chuyên gia theo tần suất được chọn bởi các bộ định tuyến. Sau đó, chúng ta có thể loại bỏ một số chuyên gia hiếm khi được sử dụng. 3) chi phí tính toán thấp hơn. Bộ định tuyến mới cho bộ dữ liệu xuôi dòng có thể được học với Top-K nhỏ hơn. Vì vậy ít chuyên gia được chọn trong một lần truyền tiến và có thể giảm đáng kể chi phí tính toán và độ trễ suy luận. Lưu ý rằng tất cả các cách thích ứng hiệu quả này có thể được kết hợp với nhau để đáp ứng các yêu cầu của các bộ dữ liệu xuôi dòng.

3.4 Học Liên tục
Tính mô-đun mạnh mẽ cũng cho phép mở rộng mô hình đơn giản và giúp tiến hành học liên tục. Cụ thể, chúng tôi trực tiếp thêm C chuyên gia trong mỗi mô-đun MoE cùng với các bộ định tuyến đặc thù nhiệm vụ mới mỗi lần học một nhiệm vụ mới. Chúng tôi huấn luyện trên nhiệm vụ mới nhưng đóng băng tất cả các tham số ngoại trừ phần mới được thêm. Có ba lợi thế chính của phương pháp này: 1) Không quên thảm khốc. Vì tất cả các chuyên gia không thay đổi sau khi học và các chuyên gia mới được thêm sẽ không được chọn bởi bộ định tuyến của các nhiệm vụ trước đó, không có quên thảm khốc. 2) Kiến trúc được tổ chức tốt và tái sử dụng kiến thức. Mô hình vẫn giữ thiết kế mô-đun thanh lịch. Các bộ định tuyến chọn các chuyên gia để tái sử dụng kiến thức liên quan đến nhiệm vụ mới và bỏ qua các chuyên gia với chuyên môn không liên quan. 3) Chi phí tính toán là không đổi. Các phương pháp mở rộng khác [39,12] thêm cả chi phí tính toán và dung lượng vào mô hình hiện có, trong khi phương pháp của chúng tôi chỉ thêm dung lượng. Điều này làm cho phương pháp của chúng tôi có thể mở rộng với số lượng lớn các nhiệm vụ.

4 Thí nghiệm
4.1 Huấn luyện đa nhiệm vụ không đồng nhất.
Chúng tôi tiến hành ba nhiệm vụ thị giác cơ bản (phân loại, phát hiện, và phân đoạn) trên ba bộ dữ liệu: ImageNet-1K [5], COCO [22], và ADE20K [47]. Đối với các bộ dữ liệu xuôi dòng, chúng tôi đánh giá phân loại trên bộ dữ liệu cảnh Places-365 [46] (P365), bộ dữ liệu chi tiết phổ biến iNaturalist-2018 [34] (iNat18), bộ dữ liệu thú cưng Pets [29], bộ dữ liệu chim chi tiết CUB [35], và bộ dữ liệu xe hơi Cars [18]. Chúng tôi đánh giá phát hiện xuôi dòng trên PASCAL VOC [7] và phân đoạn xuôi dòng trên Cityscapes [4] và NYU [33].

Mô hình và đường cơ sở. Chúng tôi sử dụng Swin Transformer [23] và DaViT [6] làm transformer xương sống, với kết quả được báo cáo trên ba kích thước khác nhau: nhỏ (T), nhỏ (S), và cơ sở (B). Mỗi nhiệm vụ có đầu đặc thù nhiệm vụ riêng. Đối với phân loại, chúng tôi sử dụng một lớp tuyến tính đơn. Đối với phát hiện, chúng tôi sử dụng đầu retina [21]. Đối với phân đoạn, chúng tôi sử dụng UperNet [36]. Mỗi nhiệm vụ tuân theo định dạng đầu vào và đầu ra riêng dựa trên các phương pháp đơn nhiệm vụ. Chúng tôi triển khai các phương pháp và đường cơ sở của mình như sau: 1) Huấn luyện từ đầu (Scratch): một đường cơ sở học đơn nhiệm vụ vanilla huấn luyện mô hình từ đầu. 2) Tiền huấn luyện rồi tinh chỉnh (Pre. & FT.): tiền huấn luyện trên ImageNet tiếp theo là tinh chỉnh trên bộ dữ liệu đích. 3) MTHL.D: người học đa nhiệm vụ không đồng nhất của chúng tôi sử dụng mô hình dày đặc (không có MoE). 4) MTHL: người học đa nhiệm vụ không đồng nhất của chúng tôi sử dụng mô hình thưa thớt (với MoE).

Cấu hình. Chúng tôi sử dụng 12 chuyên gia với Top-K là 4 cho tất cả các mô-đun MoE, theo [3]. Đối với transformer kích thước cơ sở, chúng tôi thay thế MLP bằng MoE MLP mỗi 2 lớp transformer. Đối với transformer nhỏ và nhỏ, chúng tôi sử dụng MoE Mlp trong mỗi lớp transformer. Tất cả các mô hình được huấn luyện trong 240.000 lần lặp trên 96 Tesla V100 GPU với Lamb [40] làm bộ tối ưu hóa cho huấn luyện batch lớn. Trọng số

6

--- TRANG 7 ---
Bảng 1: Huấn luyện đa nhiệm vụ không đồng nhất. Chúng tôi so sánh nó với huấn luyện từ đầu (scratch) và tiền huấn luyện rồi tinh chỉnh (pre. & ft.). Lưu ý rằng trên COCO và ADE20K, pre. & ft. sẽ khởi tạo xương sống với mô hình được tiền huấn luyện IN-1K. Số lượng tham số và FLOPs của xương sống được đo. Lưu ý rằng tất cả các phân loại có độ phân giải đầu vào 224×224. Kiểm tra cắt đơn được sử dụng cho phân đoạn ngữ nghĩa.

Xương sống Mô hình    Tham số FLOPs IN-1K        COCO         ADE20K
                     (M)     (G)   top-1 top-5 mAP mAP50 mAP75 mIoU mAcc aAcc
Swin-T   Scratch     27.5×3  4.4   80.6  95.2  34.9  54.3  36.6  32.0  41.4  75.8
         Pre. & FT.  27.5×3  4.4   –     –     42.0  64.7  45.9  44.3  55.8  81.0
         MTHL.D      27.5    4.4   79.7  95.1  43.8  65.7  46.8  44.4  54.8  80.5
         MTHL        50.9    5.1   80.3  94.7  45.0  66.5  48.2  44.6  55.0  81.0
Swin-S   Scratch     48.9×3  8.5   82.6  96.1  36.3  55.6  38.4  34.5  43.9  77.1
         Pre. & FT.  48.9×3  8.5   –     –     46.0  68.0  49.9  47.0  56.9  81.7
         MTHL.D      48.9    8.5   80.7  95.5  45.8  67.8  48.7  47.7  58.4  81.8
         MTHL        89.1    9.2   82.0  95.9  45.7  66.8  49.1  46.7  57.1  81.8
Swin-B   Scratch     86.7×3  15.1  83.1  96.4  35.5  54.7  37.4  35.4  44.8  77.6
         Pre. & FT.  86.7×3  15.1  –     –     47.3  69.0  51.2  47.7  58.7  82.3
         MTHL.D      86.7    15.1  82.2  96.2  47.5  69.2  51.0  48.8  59.7  82.5
         MTHL        158.3   16.2  82.3  96.2  47.6  69.1  50.9  48.2  59.0  82.5
DaViT-T  Scratch     27.6×3  4.4   82.5  96.2  37.7  57.1  40.0  36.4  46.4  77.8
         Pre. & FT.  27.6×3  4.4   –     –     45.4  66.9  48.4  45.8  56.0  81.8
         MTHL.D      27.6    4.4   81.3  95.8  44.6  66.6  47.5  46.2  56.4  81.6
         MTHL        51.2    5.1   82.0  95.8  45.1  67.5  48.1  47.4  57.1  82.1
DaViT-S  Scratch     49.0×3  8.6   83.8  96.8  37.8  56.7  40.5  38.2  48.4  78.8
         Pre. & FT.  49.0×3  8.6   –     –     47.2  68.9  50.7  48.3  60.2  82.3
         MTHL.D      49.0    8.6   82.6  96.5  47.3  69.2  50.6  48.7  59.1  82.7
         MTHL        88.9    9.2   83.3  96.5  46.4  67.7  49.5  47.6  57.9  82.6
DaViT-B  Scratch     86.9×3  15.2  84.2  96.9  38.0  57.2  40.5  38.5  48.7  78.9
         Pre. & FT.  86.9×3  15.2  –     –     48.1  69.7  51.3  49.3  60.2  83.0
         MTHL.D      86.8    15.2  83.9  96.9  48.3  70.4  51.8  50.0  60.3  83.1
         MTHL        158.7   16.3  83.6  96.8  47.8  69.5  51.5  49.6  60.1  83.1

Bảng 2: So sánh các sơ đồ tiền huấn luyện khác nhau về hiệu suất xuôi dòng. Chúng tôi so sánh với mô hình được tiền huấn luyện IN-1K (IN-1K Pre.) và tiền huấn luyện đa nhiệm vụ đa nhãn (Mod-Squad [3]) trên Taskonomy [43]. Để tính toán trung bình, chúng tôi trước tiên tính trung bình hiệu suất trên phân loại, phát hiện, và phân đoạn riêng biệt. Sau đó, chúng tôi tính trung bình kết quả trên tất cả các nhiệm vụ.

Xương sống Phương pháp    P365  iNat18 Pets  CUB   Cars  PASC. City. NYU Trung bình
                          top-1 top-1  top-1 top-1 top-1 mAP   mIoU  mIoU
Swin-B   IN-1K Pre.      58.7  72.9   94.0  83.9  94.0  76.9  80.6  76.2  78.7
         Mod-Squad [3]    56.4  69.4   92.3  79.8  93.7  77.2  81.1  77.5  78.1
         MTHL.D           59.1  73.3   94.2  84.3  94.2  78.7  82.1  78.0  79.9
         MTHL             59.4  73.6   94.6  84.7  94.9  79.1  82.5  78.7  80.4
Davit-B  IN-1K pre.      59.2  73.4   94.4  88.4  94.9  77.4  81.5  76.7  79.5
         MTHL.D           59.6  73.5   94.8  89.0  95.0  78.8  82.7  78.6  80.6
         MTHL             60.1  73.9   94.9  89.4  95.0  79.5  83.4  79.3  81.2

suy giảm được đặt thành 0.05 và chuẩn gradient tối đa được cắt ở 0.1. Chúng tôi sử dụng lịch tỉ lệ học tập tam giác đơn giản với tỉ lệ học tập tối đa là 0.004, như trong [6]. Các tăng cường dữ liệu cho mỗi nhiệm vụ tuân theo thực hành thông thường trong [23,6]. Trong quá trình huấn luyện đa nhiệm vụ không đồng nhất, trọng số lấy mẫu dữ liệu được đặt thành {3, 2, 1}, trọng số mất mát được đặt thành {1.0, 0.6, 0.2}, và kích thước batch được đặt thành {64, 2, 2} tương ứng cho phân loại, phát hiện, và phân đoạn. Để so sánh công bằng, tất cả kết quả của phương pháp và đường cơ sở của chúng tôi đều được thu thập từ các triển khai của chúng tôi với cùng cài đặt. Thêm chi tiết về cài đặt huấn luyện, mô hình, và bộ dữ liệu có thể tìm thấy trong Phụ lục.

Huấn luyện đa nhiệm vụ không đồng nhất. Chúng tôi so sánh các sơ đồ huấn luyện khác nhau như thể hiện trong Bảng 1. Trên cả ba bộ dữ liệu với các xương sống khác nhau, chúng tôi quan sát thấy: 1) Huấn luyện không đồng nhất hoạt động ngang bằng với sơ đồ học tiền huấn luyện rồi tinh chỉnh tiên tiến, chỉ ra rằng các xung đột gradient giữa các nhiệm vụ khác nhau được giảm thiểu bởi thiết kế mô-đun của chúng tôi. 2) Đáng chú ý, đối với nhiệm vụ phân đoạn, MTHL liên tục vượt trội hơn tiên tiến trước đó trên tất cả các lựa chọn xương sống, gợi ý rằng huấn luyện chung với các nhiệm vụ phân loại và phát hiện cải thiện phân đoạn.

7

--- TRANG 8 ---
Bảng 3: Thích ứng hiệu quả. Tất cả các thí nghiệm sử dụng MTHL làm mô hình được tiền huấn luyện với Davit-S làm xương sống. Tỉ lệ tính toán phần trăm của chỉ số hiệu quả so với đường cơ sở tinh chỉnh đầy đủ. Ký hiệu: 'Ro.' cho Bộ định tuyến, 'Ex.' cho chuyên gia, θ là ngưỡng về tần suất sử dụng cho một chuyên gia. Chúng tôi có hai mô hình kết hợp: 1) 'Hybrid-A' kết hợp trực tiếp 'Ro. w/ 1 Ex.', 'Prune 2/3 Ex.', và 'Top-K=2'. 2) 'Hybrid-B' kết hợp 'Ro. w/ 2 Ex.', 'Prune 2/3 Ex.', và 'Top-K=3'.

Phương pháp     Tham số  Tham số  FLOPs  Tỉ lệ  P365  iNat18 Pets  CUB   Cars  PASC. City. NYU  Trung bình
                Huấn luyện Mô hình        (%)    top-1 top-1  top-1 top-1 top-1 mAP   mIoU  mIoU
                (M)       (M)     (G)
FT-Full         88.9      88.9    9.2    -      59.0  72.9   94.0  88.2  95.0  78.6  81.4  77.4  79.9
Adapter [10]    14.8      -       -      16.6%  50.7  62.4   81.1  75.8  80.8  67.7  69.9  66.8  68.7
Ro. Only        0.4       -       -      0.4%   52.1  64.2   83.3  77.9  78.2  69.6  71.8  68.7  70.3
Ro. w/ 1 Ex.    5.4       -       -      6.1%   57.4  70.7   91.3  85.8  94.7  76.5  78.8  75.2  77.8
Ro. w/ 2 Ex.    10.4      -       -      11.7%  58.8  72.7   94.0  87.8  95.0  77.9  80.7  76.7  79.4
Prune θ= 1%     -         60.2    -      67.7%  58.9  72.8   93.9  88.1  95.0  78.6  81.4  77.3  79.9
Prune θ= 5%     -         54.4    -      61.2%  58.8  72.7   93.8  88.0  94.9  78.4  81.4  77.2  79.7
Prune 1/2 Ex.   -         59.9    -      67.3%  58.8  72.8   93.9  88.0  93.9  78.6  81.4  77.3  79.8
Prune 2/3 Ex.   -         49.9    -      56.1%  58.8  72.6   93.6  87.8  93.8  78.6  81.3  77.2  79.7
Top-K=3         -         -       7.7    83.7%  58.8  72.5   93.3  87.3  94.9  77.3  80.1  76.3  79.0
Top-K=2         -         -       6.2    67.4%  58.1  70.7   91.9  86.2  92.0  74.9  77.6  73.7  76.8
Top-K=1         -         -       4.7    51.0%  48.5  59.9   77.3  72.4  77.4  64.3  66.6  63.3  65.4
Hybrid-A        5.4       49.9    6.2    -      58.0  70.6   91.1  85.8  94.7  76.3  78.5  73.2  77.4
Hybrid-B        10.4      49.9    7.7    -      58.8  72.4   93.3  87.2  94.9  77.1  79.9  76.2  78.8

3) MTHL cũng hoạt động khá tốt trên phát hiện hình ảnh và vượt trội hơn tiên tiến trước đó trong hầu hết các trường hợp. 4) MTHL và MTHL.D thường thể hiện hiệu suất tương tự trên các mô hình nhỏ và cơ sở và MTHL liên tục vượt trội hơn MTHL.D trên các mô hình nhỏ, có thể bị ảnh hưởng bởi mối quan hệ giữa dung lượng mô hình và quy mô bộ dữ liệu.

Hiệu suất xuôi dòng. Như thể hiện trong Bảng 2, chúng tôi so sánh các sơ đồ huấn luyện khác nhau trên các bộ dữ liệu xuôi dòng. MTHL vượt trội hơn mô hình được tiền huấn luyện đơn nhiệm vụ IN-1K Pre. và mô hình được tiền huấn luyện đa nhiệm vụ đa nhãn Mod-Squad, đặc biệt trên các nhiệm vụ phát hiện và phân đoạn. Chúng tôi cũng lưu ý rằng mô hình thưa thớt MTHL liên tục vượt trội hơn mô hình dày đặc MTHL.D, chỉ ra rằng các chuyên gia bổ sung để lựa chọn có thể có lợi cho các nhiệm vụ xuôi dòng.

4.2 Bộ điều hợp Hiệu quả
Trong phần này, chúng tôi nêu bật tiềm năng của MTHL như một bộ điều hợp hiệu quả.

Hiệu quả trong tham số huấn luyện. MTHL có thể thích ứng nhanh chóng với một nhiệm vụ hoặc bộ dữ liệu mới bằng cách điều chỉnh bộ định tuyến với một vài chuyên gia tùy chọn và học một đầu nhiệm vụ mới. Trong quá trình này, tất cả các tham số khác được đóng băng. Một vài chuyên gia tùy chọn được tinh chỉnh được chọn ngẫu nhiên. Chúng tôi thấy rằng các chuyên gia được chọn ngẫu nhiên hoạt động tương tự với việc chọn chuyên gia có tần suất sử dụng cao nhất hoặc thấp nhất trên bộ dữ liệu xuôi dòng. Vui lòng tham khảo phụ lục để biết thêm chi tiết.

Trong Bảng 3, phương pháp của chúng tôi được gọi là 'Ro. Only', 'Ro. w/ 1 Ex.', và 'Ro. w/ 2 Ex.' ký hiệu chỉ điều chỉnh bộ định tuyến, bộ định tuyến với một chuyên gia trên mỗi mô-đun MoE, và bộ định tuyến với hai chuyên gia trên mỗi mô-đun MoE, tương ứng. Chúng tôi so sánh hiệu quả của chúng tôi trong tham số huấn luyện với adapter thường được sử dụng [10], thêm một mô-đun adapter sau mỗi khối MLP MoE. Ngược lại, chúng tôi chỉ cần các bộ định tuyến mới nhẹ (0.4M) và một hoặc hai chuyên gia bổ sung trên mỗi mô-đun MoE. Ngay cả việc chỉ cập nhật các bộ định tuyến mới cũng vượt trội hơn đường cơ sở adapter, và Ro. w/2 Ex. có hiệu suất rất gần (thấp hơn 0.5 điểm về trung bình) so với đường cơ sở tinh chỉnh đầy đủ. Để so sánh rõ ràng hơn, vui lòng xem Hình 3.

Hiệu quả trong dung lượng mô hình. Về dung lượng mô hình, MTHL có thể loại bỏ các chuyên gia sau khi học một bộ định tuyến mới trên nhiệm vụ mới. Điều này có thể đạt được bằng cách loại bỏ các chuyên gia có tần suất sử dụng ít nhất, tiếp theo là tinh chỉnh toàn bộ mô hình.

Chúng tôi khám phá hai phương pháp cắt tỉa: 1) Loại bỏ một vài chuyên gia từ mỗi lớp MoE. Trong Bảng 3, chúng tôi cố gắng loại bỏ 1/2 chuyên gia và 2/3 chuyên gia. 2) Loại bỏ tất cả các chuyên gia có tần suất sử dụng thấp hơn ngưỡng θ trên bộ dữ liệu xuôi dòng. Phương pháp này có thể dẫn đến số lượng chuyên gia khác nhau trong mỗi lớp MoE, nhưng nó có hiệu quả tương đương với phương pháp cắt tỉa đầu tiên. Kết quả và so sánh rõ ràng có thể tham khảo Bảng 3 và Hình 3.

8

--- TRANG 9 ---
0 25 50 75
Tham số Huấn luyện (M)707274767880Hiệu suất Trung bình (%)
Tinh chỉnh 
 đầy đủ
AdapterRo. OnlyRo. w/1 Ex.Ro. w/2 Ex.Ro. w/3 Ex.
Hybrid-AHybrid-B
50 60 70 80 90
Tham số Mô hình (M)77.578.078.579.079.580.0
Tinh chỉnh 
 đầy đủPrune 2/3 Ex.Prune 5%Prune 1/2 Ex.Prune 1%
Hybrid-AHybrid-B
5 6 7 8 9
FLOPs (G)65.067.570.072.575.077.580.0
Tinh chỉnh 
 đầy đủTop-K=3
Top-K=2
Top-K=1
Hybrid-A
Hybrid-B

Hình 3: Đánh đổi giữa hiệu quả và hiệu suất. Chúng tôi trực quan hóa sự đánh đổi giữa hiệu suất và tham số huấn luyện, tham số mô hình, và chi phí tính toán tương ứng.

Bảng 4: Học liên tục. Chúng tôi tiến hành học liên tục trên những bộ dữ liệu này lần lượt sau tiền huấn luyện không đồng nhất và báo cáo hiệu suất cuối cùng. Tất cả các thí nghiệm sử dụng MTHL làm mô hình được tiền huấn luyện với DaViT-S làm xương sống. Số lượng tham số huấn luyện và tham số mới được thêm trong xương sống trên mỗi nhiệm vụ được đo. Ở đây trung bình là hiệu suất trung bình trên tất cả các bộ dữ liệu.

Phương pháp     Tham số mới  Tham số huấn luyện  P365  iNat18 Pets  CUB   Cars  PASC. City. NYU  Trung bình
                trên mỗi nhiệm vụ trên mỗi nhiệm vụ   top-1 top-1  top-1 top-1 top-1 mAP   mIoU  mIoU
                (M)          (M)
LWF [16]        0            88.9               46.2  57.0   73.5  70.6  75.5  62.7  71.1  68.9  65.7
Rou. only       0.4          0.4                52.1  64.2   83.3  77.9  78.2  69.6  71.8  68.7  70.7
Rou. w/ 1Ex.    5.4          5.4                57.6  70.8   91.3  85.9  94.7  76.8  79.0  75.6  79.0
Rou. w/ 2Ex.    10.4         10.4               58.8  72.8   94.5  88.0  95.0  78.1  80.7  76.9  80.6
FT-Full         –            –                  59.0  72.9   94.0  88.2  95.0  78.6  81.4  77.4  80.8

Hiệu quả trong chi phí tính toán. Hầu hết tiền huấn luyện có thể sử dụng xương sống tương đối lớn, nhưng các nhiệm vụ/bộ dữ liệu xuôi dòng có thể không yêu cầu dung lượng mô hình lớn như vậy. MTHT.S có thể điều chỉnh chi phí tính toán bằng cách học các bộ định tuyến mới với Top-K giảm. Điều này sẽ dẫn đến sự đánh đổi giữa hiệu suất và chi phí tính toán, như minh họa trong Hình 3. Đối với một số bộ dữ liệu (ví dụ, P365), nó có thể đạt được chi phí tính toán tương đối thấp (ví dụ, 67.4%) trong khi duy trì cùng mức hiệu suất (ví dụ, <1% giảm).

Kết hợp tất cả thích ứng hiệu quả. Để cải thiện hiệu quả hơn nữa, các kỹ thuật thích ứng hiệu quả được đề cập ở trên có thể được kết hợp. Trong Bảng 3, đối với Hybrid-B, chúng tôi trước tiên học một bộ định tuyến mới và loại bỏ 2/3 chuyên gia. Sau đó, chúng tôi tinh chỉnh bộ định tuyến với Top-K là 3 cùng với hai chuyên gia trên mỗi mô-đun. Phương pháp này đạt được hiệu suất trung bình 78.8, chỉ thấp hơn 1 điểm so với tinh chỉnh toàn bộ mô hình. Hơn nữa, phương pháp này giảm tham số huấn luyện, tham số mô hình, và chi phí tính toán đồng thời.

4.3 Học liên tục.
Học liên tục mà không có bất kỳ quên nào có thể đạt được với MTHL bằng cách học các bộ định tuyến mới (0.4M) và một vài chuyên gia tùy chọn trên bộ dữ liệu mới. Chúng tôi so sánh nó với đường cơ sở học liên tục dựa trên chính quy hóa thông thường LWF [16]. Như thể hiện trong Bảng 4, phương pháp của chúng tôi có ba lợi thế đáng kể: 1) Không quên trên các bộ dữ liệu đã học. 2) Chỉ một phần thông minh của mô hình cần được huấn luyện trên các bộ dữ liệu mới, chỉ yêu cầu 10.4M tham số huấn luyện, trong khi LWF cần điều chỉnh toàn bộ mô hình (88.9M). 3) Hiệu suất tương đương với tinh chỉnh đầy đủ toàn bộ mô hình trên mỗi bộ dữ liệu.

5 Kết luận
Nghiên cứu của chúng tôi tập trung vào huấn luyện đa nhiệm vụ không đồng nhất và khả năng thích ứng của nó trên các bộ dữ liệu xuôi dòng. MTHL có thể đạt được kết quả tương đương với tiên tiến đơn nhiệm vụ trước đó trên tất cả các nhiệm vụ. Hơn nữa, chúng tôi nghiên cứu các phương pháp khác nhau để sử dụng tính mô-đun để thích ứng hiệu quả với các nhiệm vụ xuôi dòng. Tính mô-đun cũng cho phép mở rộng mô hình dễ dàng cho học liên tục. Tác động rộng hơn của công trình của chúng tôi có thể đáng kể về mặt thúc đẩy tiền huấn luyện mô hình thị giác đa dụng và thích ứng hiệu quả của các mô hình quy mô lớn. Một hạn chế của MTHL là mô hình có thể thiên về một số bộ dữ liệu nhất định và yêu cầu nhiều lần lặp huấn luyện hơn để hội tụ.

9

--- TRANG 10 ---
Tài liệu tham khảo
[1] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural information processing systems (Neurips), 33:1877–1901, 2020.

[2] M. Caron, H. Touvron, I. Misra, H. Jégou, J. Mairal, P. Bojanowski, and A. Joulin. Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF international conference on computer vision (ICCV), pages 9650–9660, 2021.

[3] Z. Chen, Y. Shen, M. Ding, Z. Chen, H. Zhao, E. Learned-Miller, and C. Gan. Mod-squad: Designing mixtures of experts as modular multi-task learners. Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), 2023.

[4] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pages 3213–3223, 2016.

[5] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2009.

[6] M. Ding, B. Xiao, N. Codella, P. Luo, J. Wang, and L. Yuan. Davit: Dual attention vision transformers. In ECCV, pages 74–92, 2022.

[7] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. International journal of computer vision, 88(2):303–338, 2010.

[8] W. Fedus, B. Zoph, and N. Shazeer. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. Journal of Machine Learning Research, 23(120):1–39, 2022.

[9] P. Gao, S. Geng, R. Zhang, T. Ma, R. Fang, Y. Zhang, H. Li, and Y. Qiao. Clip-adapter: Better vision-language models with feature adapters. arXiv preprint arXiv:2110.04544, 2021.

[10] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. Attariyan, and S. Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning (ICML), pages 2790–2799. PMLR, 2019.

[11] E. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, L. Wang, and W. Chen. Lora: Low-rank adaptation of large language models, 2021.

[12] C.-Y. Hung, C.-H. Tu, C.-E. Wu, C.-H. Chen, Y.-M. Chan, and C.-S. Chen. Compacting, picking and growing for unforgetting continual learning. Advances in Neural Information Processing Systems (Nerurips), 32, 2019.

[13] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton. Adaptive mixtures of local experts. Neural computation, 3(1):79–87, 1991.

[14] A. Jaegle, F. Gimeno, A. Brock, O. Vinyals, A. Zisserman, and J. Carreira. Perceiver: General perception with iterative attention. In International conference on machine learning (ICML), pages 4651–4664. PMLR, 2021.

[15] A. Kendall, Y. Gal, and R. Cipolla. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pages 7482–7491, 2018.

[16] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521–3526, 2017.

[17] I. Kokkinos. Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pages 6129–6138, 2017.

[18] J. Krause, M. Stark, J. Deng, and L. Fei-Fei. 3d object representations for fine-grained categorization. In Proceedings of the IEEE international conference on computer vision workshops, pages 554–561, 2013.

[19] D. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen. {GS}hard: Scaling giant models with conditional computation and automatic sharding. In International Conference on Learning Representations, 2021.

10

--- TRANG 11 ---
[20] Y. Li, H. Mao, R. B. Girshick, and K. He. Exploring plain vision transformer backbones for object detection. ArXiv, abs/2203.16527, 2022.

[21] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár. Focal loss for dense object detection. In ICCV, pages 2980–2988, 2017.

[22] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740–755. Springer, 2014.

[23] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In ICCV, 2021.

[24] D. Lopez-Paz and M. Ranzato. Gradient episodic memory for continual learning. Advances in neural information processing systems, 30, 2017.

[25] J. Lu, C. Clark, R. Zellers, R. Mottaghi, and A. Kembhavi. UNIFIED-IO: A unified model for vision, language, and multi-modal tasks. In The Eleventh International Conference on Learning Representations (ICLR), 2023.

[26] K.-K. Maninis, I. Radosavovic, and I. Kokkinos. Attentive single-tasking of multiple tasks. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pages 1851–1860, 2019.

[27] B. Mustafa, C. Riquelme, J. Puigcerver, R. Jenatton, and N. Houlsby. Multimodal contrastive learning with limoe: the language-image mixture of experts. arXiv preprint arXiv:2206.02770, 2022.

[28] C. V. Nguyen, Y. Li, T. D. Bui, and R. E. Turner. Variational continual learning. In International Conference on Learning Representations (ICLR), 2018.

[29] O. M. Parkhi, A. Vedaldi, A. Zisserman, and C. Jawahar. Cats and dogs. In 2012 IEEE conference on computer vision and pattern recognition (CVPR), pages 3498–3505. IEEE, 2012.

[30] C. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton, A. Susano Pinto, D. Keysers, and N. Houlsby. Scaling vision with sparse mixture of experts. Advances in Neural Information Processing Systems (NeurIPS), 34:8583–8595, 2021.

[31] H. Ritter, A. Botev, and D. Barber. Online structured laplace approximations for overcoming catastrophic forgetting. Advances in Neural Information Processing Systems, 31, 2018.

[32] N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. In International Conference on Learning Representations, 2017.

[33] N. Silberman, D. Hoiem, P. Kohli, and R. Fergus. Indoor segmentation and support inference from rgbd images. ECCV (5), 7576:746–760, 2012.

[34] G. Van Horn, O. Mac Aodha, Y. Song, Y. Cui, C. Sun, A. Shepard, H. Adam, P. Perona, and S. Belongie. The inaturalist species classification and detection dataset. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pages 8769–8778, 2018.

[35] C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The caltech-ucsd birds-200-2011 dataset. 2011.

[36] T. Xiao, Y. Liu, B. Zhou, Y. Jiang, and J. Sun. Unified perceptual parsing for scene understanding. In Proceedings of the European conference on computer vision (ECCV), pages 418–434, 2018.

[37] X. Xu, H. Zhao, V. Vineet, S.-N. Lim, and A. Torralba. Mtformer: Multi-task learning via transformer and cross-task reasoning. In Proceedings of the European Conference on Computer Vision (ECCV), 2022.

[38] M. B. Yi-Lin Sung, Jaemin Cho. Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks. In CVPR, 2022.

[39] J. Yoon, E. Yang, J. Lee, and S. J. Hwang. Lifelong learning with dynamically expandable networks. 2018.

[40] Y. You, J. Li, S. Reddi, J. Hseu, S. Kumar, S. Bhojanapalli, X. Song, J. Demmel, K. Keutzer, and C.-J. Hsieh. Large batch optimization for deep learning: Training bert in 76 minutes. arXiv preprint arXiv:1904.00962, 2019.

11

--- TRANG 12 ---
[41] L. Yuan, D. Chen, Y.-L. Chen, N. Codella, X. Dai, J. Gao, H. Hu, X. Huang, B. Li, C. Li, et al. Florence: A new foundation model for computer vision. arXiv preprint arXiv:2111.11432, 2021.

[42] E. B. Zaken, S. Ravfogel, and Y. Goldberg. Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL), 2022.

[43] A. R. Zamir, A. Sax, W. Shen, L. J. Guibas, J. Malik, and S. Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pages 3712–3722, 2018.

[44] F. Zenke, B. Poole, and S. Ganguli. Continual learning through synaptic intelligence. In International conference on machine learning, pages 3987–3995. PMLR, 2017.

[45] R. Zhang, R. Fang, P. Gao, W. Zhang, K. Li, J. Dai, Y. Qiao, and H. Li. Tip-adapter: Training-free clip-adapter for better vision-language modeling. arXiv preprint arXiv:2111.03930, 2021.

[46] B. Zhou, A. Lapedriza, A. Khosla, A. Oliva, and A. Torralba. Places: A 10 million image database for scene recognition. IEEE transactions on pattern analysis and machine intelligence, 40(6):1452–1464, 2017.

[47] B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso, and A. Torralba. Scene parsing through ade20k dataset. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.

12

--- TRANG 13 ---
Phụ lục

Bảng A1: Chúng tôi so sánh ba cách chọn một tập hợp con các chuyên gia để tinh chỉnh, trong khi đóng băng các chuyên gia còn lại. Chúng tôi trước tiên học các bộ định tuyến mới trên xuôi dòng mới để xác định tần suất mỗi chuyên gia được chọn. Random đại diện cho việc chọn ngẫu nhiên các chuyên gia. Best đại diện cho việc chọn các chuyên gia có tần suất cao nhất. Worse đại diện cho việc chọn các chuyên gia có tần suất thấp nhất. Chúng tôi báo cáo độ chính xác top-1 trung bình trên CUB, Cars, và Pets. Các cài đặt khác giống như trong Bảng 3 trong bài báo.

                Random  Best    Worse
Ro. w/1 Ex.     90.6    90.5    90.6
Ro. w/2 Ex.     92.3    92.3    92.2

A1 Các cách khác nhau để chọn chuyên gia được tinh chỉnh.
Bảng A1 so sánh các phương pháp khác nhau để chọn chuyên gia tinh chỉnh trong khi đóng băng phần còn lại. Chúng tôi so sánh việc chọn ngẫu nhiên chuyên gia và chọn chuyên gia có nhiều khả năng hoặc ít khả năng được chọn bởi các bộ định tuyến. Chúng tôi thấy rằng phương pháp chọn không ảnh hưởng đáng kể đến hiệu suất tinh chỉnh. Do đó, chúng tôi sử dụng lựa chọn ngẫu nhiên để đơn giản.

A2 Nghiên cứu loại bỏ về Top-K.
Như thể hiện trong Bảng A2, chúng tôi khám phá tác động của Top-K trong mô-đun MoE. Cài đặt thí nghiệm giống như trong Bảng 1 trong bài báo với 12 chuyên gia trên mỗi mô-đun MoE. Chúng tôi báo cáo hiệu suất trung bình trên các bộ dữ liệu tiền huấn luyện và xuôi dòng của MHTL với Davit-T làm xương sống. Để kiểm soát FLOPs giống nhau cho các Top-K khác nhau, kích thước ẩn của các chuyên gia MLP được chia cho K. Tất cả các thí nghiệm có cùng kích thước tham số và cùng FLOPs. Chúng tôi thấy rằng Top-K=4 có hiệu suất tốt nhất.

A3 Nghiên cứu loại bỏ về số lượng chuyên gia.
Như thể hiện trong Bảng A3, chúng tôi khám phá tác động của số lượng chuyên gia E cho lớp MLP MoE. Các cài đặt giống như trong phụ lục A2 với Top-K là 4.

Bảng A2: Nghiên cứu loại bỏ về Top-K trên lớp MLP MoE.
FLOPs(G)  Params(M)  Hidden Dim  Pre-train mean  Downstream mean
K=2       5.1        51.2       768             58.1            80.3
K=4       5.1        51.2       384             58.2            80.4
K=6       5.1        51.2       256             57.9            80.0

Bảng A3: Nghiên cứu loại bỏ về số lượng chuyên gia E trên lớp MLP MoE.
FLOPs(G)  Params(M)  Pre-train mean  Downstream mean
E=6       5.1        33.4           57.2            78.5
E=9       5.1        42.3           57.9            80.0
E=12      5.1        51.2           58.2            80.4
E=15      5.1        60.1           58.2            80.5

13

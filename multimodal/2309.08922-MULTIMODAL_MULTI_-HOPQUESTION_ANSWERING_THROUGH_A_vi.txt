# 2309.08922.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2309.08922.pdf
# Kích thước file: 361021 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
TRẢ LỜI CÂU HỎI ĐAỞ HỎI NHIỀU BƯỚC ĐA PHƯƠNG THỨC THÔNG QUA
CUỘC TRỰC THOẠI GIỮA CÁC CÔNG CỤ VÀ MÔ HÌNH NGÔN NGỮ LỚN
ĐƯỢC TINH CHỈNH HIỆU QUẢ

Hossein Rajabzadeh
Đại học Waterloo
hossein.rajabzadeh@uwaterloo.ca

Suyuchen Wang
Mila
DIRO, Université de Montréal
suyuchen.wang@umontreal.ca

Hyock Ju Kwon
Đại học Waterloo
hjkwon@uwaterloo.ca

Bang Liu
Mila
Université de Montréal
bang.liu@umontreal.ca

TÓM TẮT
Chúng tôi sử dụng chiến lược tương tác công cụ chia-để-trị cho phép các mô hình ngôn ngữ lớn (LLM) trả lời các câu hỏi đa phương thức nhiều bước phức tạp. Cụ thể, chúng tôi khai thác sức mạnh của các mô hình ngôn ngữ lớn để chia một câu hỏi đa phương thức nhiều bước thành các câu hỏi con đơn phương thức một bước để được trả lời bởi công cụ phù hợp từ một tập hợp các công cụ được định nghĩa trước. Sau khi tất cả các công cụ tương ứng cung cấp cho LLM câu trả lời của chúng, LLM tạo ra câu hỏi đơn phương thức một bước có liên quan tiếp theo. Để tăng khả năng lý luận của LLM, chúng tôi nhắc chatGPT tạo ra một bộ dữ liệu chia-để-trị tương tác công cụ. Bộ dữ liệu này sau đó được sử dụng để tinh chỉnh hiệu quả LLM tương ứng. Để đánh giá hiệu quả của phương pháp này, chúng tôi tiến hành đánh giá trên hai bộ dữ liệu trả lời câu hỏi phức tạp được giới thiệu gần đây. Phân tích thực nghiệm cho thấy những cải thiện đáng kể so với các giải pháp hiện đại hiện có, chỉ ra hiệu quả và tính tổng quát của chiến lược của chúng tôi¹.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM), như ChatGPT [1], đã thể hiện khả năng lý luận nổi bật trong các thiết lập few-shot trên nhiều nhiệm vụ khác nhau. Tuy nhiên, việc trả lời các câu hỏi nhiều bước, đòi hỏi lý luận tuần tự và tổng hợp, vẫn là một thách thức ghê gớm đối với LLM [2,3,4]. Thách thức này làm lộ ra những hạn chế nghiêm trọng của LLM, như sự không trung thực, lý luận sai lầm và ảo tưởng [5, 6, 7, 8, 9, 10, 11].

Để cho phép LLM chia nhỏ câu hỏi đầu vào thành một chuỗi lý luận, một số kỹ thuật đã được đề xuất, như Self-Ask [7], nhắc Least-to-most [12], ReAct [13], mm-ReAct [14], Vipergpt [15], Chameleon [16], ART [17], và CoT [4]. Những phương pháp này hoạt động tốt cho các câu hỏi một bước, nhưng chúng gặp khó khăn khi đối phó với các câu hỏi lý luận đa phương thức nhiều bước (MMH), nơi câu trả lời của các câu hỏi con trước đó ảnh hưởng đến việc hình thành những câu hỏi tiếp theo. Bên cạnh đó, ReAct và mm-ReAct không nhất thiết phải chia nhỏ một câu hỏi MMH thành một chuỗi các câu hỏi con đơn phương thức một bước (USH) từ dễ đến khó, điều này có thể dẫn đến số lượng lời gọi công cụ tối thiểu.

Một giải thích có thể cho hiệu suất kém của LLM trên các nhiệm vụ lý luận MMH là hạn chế của chúng trong việc tiếp cận thông tin có liên quan. Một giải pháp tiềm năng cho vấn đề này là trang bị cho LLM một tập hợp các công cụ được định nghĩa trước có thể giúp nhắm mục tiêu và xử lý thông tin chuyên biệt. Phương pháp này có thể bao gồm việc thêm khả năng truy xuất thông tin và tìm kiếm web cho LLM [18,19,20] hoặc cung cấp cho LLM những công cụ tiên tiến hơn [17,21,22,23]. Tuy nhiên, việc thêm công cụ

¹Mã nguồn và dữ liệu sẽ được phát hành sớm.

--- TRANG 2 ---
BẢN THẢO

Hình 1: Một minh họa về chiến lược tương tác giữa LLM và Công cụ để trả lời một câu hỏi MMH. LLM đầu tiên chia câu hỏi thành một câu hỏi con USM và xác định công cụ liên quan của nó. Câu hỏi con sau đó được trả lời bởi công cụ liên quan, gửi câu trả lời trở lại cho LLM. LLM sau đó đặt câu hỏi USH tiếp theo dựa trên phản hồi của công cụ.

cho LLM không đảm bảo một giải pháp trả lời câu hỏi MMH (QA) thành công, vì vẫn còn những thách thức liên quan đến lý luận phức tạp, biến đổi phương thức và tích lũy lỗi [16,13]. Để cải thiện mô hình MMH QA, điều quan trọng là cho phép LLM thực hiện một chuỗi lý luận động tương tác với các công cụ và tích hợp đầu ra của chúng để tạo ra câu trả lời cuối cùng một cách hiệu quả và hiệu quả. Một yếu tố quan trọng khác góp phần vào sự thành công của LLM trong các nhiệm vụ lý luận là kích thước mô hình, nơi khả năng cao hơn của mô hình dẫn đến khả năng lý luận mạnh mẽ hơn [24, 25, 26].

Trong công trình này, chúng tôi chủ yếu tập trung vào vấn đề trả lời câu hỏi MMH sử dụng một chiến lược tương tác giữa LLM và một tập hợp các công cụ. Hình 1 minh họa chiến lược được đề xuất của chúng tôi với một ví dụ. Đầu tiên, LLM nhận câu hỏi MMH đầu vào và đơn giản hóa nó thành một câu hỏi con đơn phương thức một bước (USH) trong khi chỉ định tên công cụ cần thiết để trả lời câu hỏi con đó. Một trình xử lý công cụ² sau đó nhận câu hỏi con USH này, gọi công cụ liên quan và trả về câu trả lời. LLM sử dụng câu trả lời để tạo ra câu hỏi con USH tiếp theo. Sự tương tác giữa LLM và các công cụ tiếp tục cho đến khi tìm ra câu trả lời cuối cùng.

Chúng tôi đánh giá chiến lược này trên hai bộ dữ liệu MMH phức tạp và đánh giá hiệu suất của ba LLM trên các bộ dữ liệu này. Do đó, những đóng góp chính của nghiên cứu này có thể được tóm tắt như sau:

• Chúng tôi đề xuất một chiến lược tương tác cho phép LLM giao tiếp với các công cụ và tạo ra một chuỗi các câu hỏi con thông qua phương pháp chia-để-trị, cho phép LLM phân tách các câu hỏi MMH thành các câu hỏi con USH và trả lời câu hỏi gốc.

• Chúng tôi tạo ra một bộ dữ liệu chia-để-trị để tinh chỉnh hiệu quả các LLM kích thước nhỏ hơn, từ đó nâng cao khả năng lý luận của chúng trên các nhiệm vụ MMH QA.

• Chúng tôi đánh giá chiến lược của mình trên hai bộ dữ liệu MMH QA gần đây và so sánh kết quả sử dụng LLM có kích thước khác nhau.

2 Nhắc Chia-để-trị Tương tác Công cụ cho MMH QA

Hãy xem xét một kịch bản mà một câu hỏi yêu cầu sử dụng nhiều công cụ để được trả lời, tức là lý luận đa phương thức. Chúng tôi cũng giả định rằng thứ tự gọi công cụ có quan trọng, sao cho đầu ra của công cụ A có thể phục vụ như đầu vào cho công cụ B, minh họa cho lý luận nhiều bước. Hơn nữa, chúng tôi định nghĩa các công cụ như các mô hình USH QA có thể trả lời một câu hỏi USH dựa trên dữ liệu được cung cấp.

Để trả lời các câu hỏi MMH, LLM cần trích xuất một câu hỏi con USH ban đầu có thể được giải quyết bằng công cụ tương ứng. Tính năng đơn phương thức đảm bảo LLM gọi đúng công cụ cho một câu hỏi con. Hơn nữa, tính năng đơn giản tăng cơ hội LLM nhận được câu trả lời đúng từ các công cụ. Cuối cùng, sự hợp nhất tương tác của hai thuộc tính này cung cấp một chiến lược chia-để-trị, thành công sẽ dẫn LLM đến câu trả lời cuối cùng.

2.1 LLM như Người Chia
Giả sử ví dụ trong Hình 1, LLM đầu tiên chia câu hỏi MMH gốc thành một câu hỏi con USH bằng cách hỏi tiêu đề phim từ các công cụ có liên quan. Sau khi nhận được phản hồi của công cụ, nó đặt câu hỏi con tiếp theo, tạo thành một phần thông tin khác cần thiết để xây dựng câu trả lời cuối cùng. LLM tiếp tục hành vi chia như vậy cho đến khi nó nhận được tất cả các thông tin cần thiết để trả lời câu hỏi gốc.

2.2 Công cụ như Người Chinh phục
Xem xét ví dụ trong Hình 1, mỗi khi LLM đặt một câu hỏi con, công cụ tương ứng được gọi để tìm câu trả lời được yêu cầu. Vì câu hỏi con là một câu hỏi USH, rất có khả năng công cụ sẽ thu được câu trả lời thành công. Hành vi này giới thiệu các công cụ như một người chinh phục mạnh mẽ cho người chia. Ở đây, chúng tôi giả định rằng các công cụ chỉ có quyền truy cập vào các phương thức dữ liệu liên quan của chúng, và câu trả lời được đưa ra trong phương thức tương ứng.

3 Tinh chỉnh LLM hiệu quả

Để nâng cao khả năng lý luận và tương tác công cụ của các LLM kích thước thông thường, như 7, 13, 30, và 40 tỷ³, chúng tôi tinh chỉnh hiệu quả các LLM có kích thước khác nhau trong một epoch sử dụng QLoRA [27] trên một bộ dữ liệu chia-để-trị tương tác công cụ, được giải thích trong Mục 4. Một epoch tinh chỉnh này khuyến khích LLM tương ứng tuân theo chiến lược chia-để-trị trong khi tương tác với các công cụ cần thiết.

4 Tạo ra một Bộ dữ liệu Chia-để-trị Tương tác Công cụ

Để xây dựng một bộ dữ liệu trả lời các câu hỏi MMH thông qua chiến lược chia-để-trị tương tác công cụ được đề xuất, chúng tôi đã nhắc ChatGPT bằng cách cung cấp cho nó các ví dụ few-shot được tạo thủ công. Chúng tôi sử dụng các ví dụ eight-shot, bao gồm ba phương thức chính của dữ liệu Văn bản, Bảng và hình ảnh. Ngoài ra, bốn công cụ khác nhau, được mô tả trong Mục con 5.3, được xem xét để tương tác với LLM liên quan. Bảng 4 trình bày một trong những shot như vậy được sử dụng trong việc nhắc ChatGPT.

Mỗi shot bao gồm một số bước. Các màu sắc khác nhau được sử dụng để tăng khả năng đọc của mỗi bước. Ngoài ra, cùng một hướng dẫn được sử dụng trong mỗi shot (được minh họa bằng màu vàng). Câu hỏi MMH chính được mô tả trong hàng màu tím. Các hàng màu xanh lá cây tạo thành các bước chia (chia câu hỏi MMH chính thành một câu hỏi USH), và các hàng màu đỏ đại diện cho các bước chinh phục (sự tương tác giữa LLM và các công cụ).

Đối với mỗi benchmark được báo cáo trong Bảng 2, chúng tôi đã nhắc ChatGPT và chuyển một tập con ngẫu nhiên⁴ của tập huấn luyện tương ứng và tiến hành tạo ra một bộ dữ liệu chia-để-trị tương tác công cụ.

5 Thí nghiệm

Phần này đánh giá hiệu quả của chiến lược chia-để-trị tương tác công cụ của chúng tôi cho một số mô hình ngôn ngữ lớn trên hai benchmark MMH QA gần đây. Phân tích so sánh liên quan đến các tổ hợp khác nhau của Mô hình Ngôn ngữ với kích thước khác nhau và các chiến lược. Kết quả được so sánh về mặt khớp chính xác (EM), điểm F (F1), và số lần Gọi Công cụ trung bình, tức là số lần trung bình mà LLM gọi một công cụ để trả lời một câu hỏi. Các phần tiếp theo cung cấp thêm chi tiết về các benchmark, LLM và kết quả thu được.

5.1 Benchmark MMH QA

Chúng tôi sử dụng hai benchmark MMH QA để đánh giá và so sánh: MultiModalQA [28] và MMCoQA [29]. Các benchmark này cung cấp các phương thức dữ liệu khác nhau trong khi đưa ra các câu hỏi nhiều bước phức tạp. Cụ thể, MultiModalQA

³Để đơn giản, chúng tôi ký hiệu các kích thước Mô hình Ngôn ngữ khác nhau là 7b, 13b, 30b, và 40b.
⁴Kích thước của tập con huấn luyện là 2k cho mỗi benchmark.

--- TRANG 3 ---
BẢN THẢO

Bước | Mô tả
Hướng dẫn | Nhiệm vụ của bạn là trả lời một Câu hỏi Mở đã cho. Tuy nhiên, Câu hỏi Mở cần thông tin từ các mô-đun khác nhau, đó là mô-đun Hình ảnh, mô-đun Văn bản, và mô-đun Văn bản. Bạn có thể chia Câu hỏi Mở thành một Câu hỏi con đơn giản hơn và chờ nhận câu trả lời. Mỗi lần bạn có thể đặt một Câu hỏi con từ chỉ một mô-đun. Nếu câu trả lời được cung cấp không hoàn chỉnh, bạn hỏi một Câu hỏi con mới từ mô-đun khác hoặc cùng mô-đun. Bạn có thể lặp lại vòng lặp này cho đến khi bạn nhận được thông tin hoàn chỉnh để trả lời Câu hỏi Mở.

Câu hỏi | Câu hỏi Mở: Những đội NFL đối thủ nào đã chơi với Dallas Cowboys tại Cowboys Stadium trong mùa giải thường niên 2012 cũng không có đội cổ động viên vào năm 2017?

LLM (Người Chia) | Để trả lời câu hỏi này, trước tiên tôi cần biết tên các đội không có đội cổ động viên vào năm 2017 từ mô-đun văn bản. Vì vậy, tôi cần đặt câu hỏi con này: Câu hỏi con: Những đội nào không có đội cổ động viên vào năm 2017? (Công cụ=Văn bản)

Công cụ (Người Chinh phục) | Câu trả lời từ Công cụ Văn bản: Buffalo Bills, Chicago Bears, Cleveland Browns, Green Bay Packers, New York Giants, và Pittsburgh Steelers.

LLM (Người Chia) | Bây giờ, tôi cần biết tên các đội đã chơi với Dallas Cowboys tại Cowboys Stadium trong mùa giải thường niên 2012. Vì vậy, tôi cần đặt câu hỏi con này: Những đội nào đã chơi với Dallas Cowboys tại Cowboys Stadium? (Công cụ=Văn bản)

Công cụ (Người Chinh phục) | Câu trả lời từ Công cụ Văn bản: Chicago Bears, Cleveland Browns, Persepolis.

LLM (Trả lời) | Dựa trên các câu trả lời, câu trả lời cuối cùng là: [Trả lời: Chicago Bears, Cleveland Browns]

Bảng 1: Một shot mẫu được sử dụng trong few-shots prompting ChatGPT để tạo ra một bộ dữ liệu chia-để-trị tương tác công cụ.

Bộ dữ liệu | Phương thức | Huấn luyện | Phát triển; Kiểm tra
MultiModalQA | Văn bản/Bảng/Hình ảnh | 23,817 | 2441; 3660
MMCoQA | Hội thoại/Văn bản/Bảng/Hình ảnh | 4582 | 581; 590

Bảng 2: Chi tiết benchmark cho hai nhiệm vụ MMH QA thách thức.

chứa 29,918 cặp câu hỏi-câu trả lời và bao gồm ba phương thức riêng biệt, cụ thể là dữ liệu văn bản, dữ liệu bảng và dữ liệu hình ảnh. Đáng chú ý, mỗi câu hỏi trong bộ dữ liệu này yêu cầu tích hợp các tổ hợp khác nhau của đầu vào văn bản, bảng và hình ảnh để trả lời chính xác. Hơn nữa, MMCoQA là một benchmark QA hội thoại đa phương thức, kết hợp bốn phương thức: văn bản, bảng, hình ảnh và hội thoại. Benchmark này bao gồm 1,179 cuộc hội thoại, với trung bình 4.88 cặp câu hỏi-câu trả lời mỗi cuộc hội thoại. Bảng 2 tóm tắt các benchmark này.

5.2 LLM

Để đánh giá hiệu quả của chiến lược chia-để-trị tương tác công cụ của chúng tôi, chúng tôi sử dụng năm LLM riêng biệt cho mục đích đánh giá: StableLM-7b⁵, Pathia-12b⁶, LLaMA-13b⁷, Falcon-40b⁸, và ChatGPT. Ngoại trừ ChatGPT, các LLM khác được tinh chỉnh trong một epoch trên các bộ dữ liệu chia-để-trị tương tác công cụ liên quan⁹. Để đánh giá khả năng lý luận của chiến lược được đề xuất, chúng tôi so sánh nó với hai chiến lược khác. Trong chiến lược đầu tiên, câu hỏi gốc được xử lý độc lập bởi mỗi công cụ, và các câu trả lời được trả về được coi là một prompt cho LLM. Sau đó, LLM được yêu cầu trả lời câu hỏi gốc với prompt đã cho. Chúng tôi gọi thiết lập này là ToolsAnswer. Chiến lược thứ hai là mm-ReAct, nơi chúng tôi tuân theo mm-ReAct vanilla được trình bày với các mô tả công cụ. Ngoài ra, chúng tôi áp dụng chiến lược được đề xuất của mình cho mỗi LLM, được ký hiệu là Ours để tham khảo.

5.3 Công cụ

Mỗi phương thức dữ liệu cần một công cụ cụ thể để xử lý phương thức đặc biệt đó. Vì có ba phương thức chính, chúng tôi sử dụng ba công cụ chung¹⁰, được bổ sung bởi một công cụ Tìm kiếm Web¹¹ bổ sung:

• TextQA sử dụng Instructor-large¹² [30] là một mô hình embedding văn bản đã được tinh chỉnh đặc biệt cho mục đích hướng dẫn. Instructor-large tạo ra các embedding cụ thể cho nhiệm vụ và nhạy cảm với miền bằng cách xem xét đầu vào văn bản và hướng dẫn nhiệm vụ tương ứng của nó. Chúng tôi sử dụng TextQA để trả lời một câu hỏi đã cho dựa trên phương thức văn bản.

⁵https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3
⁶https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5
⁷https://huggingface.co/decapoda-research/llama-13b-hf
⁸https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560
⁹Trong trường hợp của mm-ReAct, bộ dữ liệu tương tác công cụ được tạo ra phù hợp với chiến lược mm-ReAct
¹⁰Trong trường hợp của các phương pháp baseline, chúng tôi xem xét các công cụ tương tự được báo cáo trong các bài báo của chúng.
¹¹Google Search API. https://serpapi.com/
¹²https://huggingface.co/hkunlp/instructor-large

--- TRANG 4 ---
BẢN THẢO

LLM | Kích thước | Chiến lược | EM | F1 | Trung bình Gọi Công cụ
StableLM | 7b | ToolsAnswer | 0.0 | 9.36 | 4
Pathia | 12b | ToolsAnswer | 0.3 | 15.24 | 4
LLaMA | 13b | ToolsAnswer | 1.21 | 17.32 | 4
Falcon | 40b | ToolsAnswer | 14.12 | 33.92 | 4
ChatGPT | NA | ToolsAnswer | 15.45 | 46.42 | 4
StableLM* | 7b | mm-ReAct | 1.32 | 14.50 | 11.52
Pathia* | 12b | mm-ReAct | 6.51 | 23.18 | 10.60
LLaMA* | 13b | mm-ReAct | 9.87 | 27.45 | 10.53
Falcon* | 40b | mm-ReAct | 18.94 | 45.34 | 8.24
ChatGPT | NA | mm-ReAct | 21.30 | 52.16 | 6.22
StableLM* | 7b | Ours | 18.50 | 25.12 | 9.69
Pathia* | 12b | Ours | 21.32 | 31.14 | 8.14
LLaMA* | 13b | Ours | 23.14 | 35.21 | 8.75
Falcon* | 40b | Ours | 41.18 | 56.74 | 6.34
ChatGPT | NA | Ours | 43.71 | 61.03 | 5.07
Con người | - | - | 86.2 | 91.2 | -

Bảng 3: Kết quả validation trên benchmark MultiModalQA. Tất cả các phương pháp được trình bày với một tập hợp công cụ giống hệt nhau. "NA" biểu thị dữ liệu không có sẵn. Số lần Gọi Công cụ tối đa cho mỗi câu hỏi được đặt là 12. "*" có nghĩa là LLM tương ứng được tinh chỉnh sử dụng QLoRA trong một epoch thông qua chiến lược liên quan của nó.

• TableQA sử dụng TAPAS¹³ [31], tận dụng cấu trúc của BERT để bao phủ QA dựa trên bảng. Chúng tôi sử dụng TableQA như một công cụ chuyên dụng để giải quyết các truy vấn liên quan đến dữ liệu dạng bảng.

• ImageQA dựa trên BLIP-2¹⁴ [32]. Công cụ này nhận một hình ảnh và một câu hỏi làm đầu vào và trả về câu trả lời văn bản tương ứng làm đầu ra.

• Công cụ Tìm kiếm Web được gọi khi các công cụ còn lại không thể cung cấp câu trả lời thông tin. Trong trường hợp như vậy, LLM được phép thực hiện một yêu cầu tìm kiếm web, truy xuất thông tin có liên quan từ internet.

Điều đáng chú ý là những công cụ này được lựa chọn độc quyền để trả lời các câu hỏi USH, đảm bảo việc thiết lập một cơ sở vững chắc cho các đánh giá so sánh khi xem xét hiệu quả của chiến lược của chúng tôi. Hơn nữa, chúng không được tinh chỉnh (chúng tôi xem xét các checkpoint gốc của chúng). Hơn nữa, một giới hạn trên được định nghĩa trước được áp đặt lên số lần gọi công cụ để hạn chế LLM không vượt quá ngưỡng này. Chính xác hơn, tổng số lần gọi công cụ mà LLM được phép trả lời một câu hỏi đã cho được giới hạn bởi ngưỡng này.

5.4 Kết quả

Phần này trình bày kết quả và so sánh chúng về mặt hiệu quả và độ chính xác. Đánh giá các phương pháp khác nhau trên các bộ dữ liệu MultiModalQA và MMCoQA được báo cáo trong Bảng 3 và Bảng 4, tương ứng. Đặc biệt, chiến lược của chúng tôi (được gắn nhãn là "Ours") liên tục vượt trội hơn các chiến lược khác trên các LLM có kích thước khác nhau, như được chỉ ra bởi điểm Khớp Chính xác (EM) và điểm F1 cao hơn. Ngoài ra, cột "Trung bình Gọi Công cụ" cho thấy chiến lược của chúng tôi duy trì một số lần gọi công cụ tương đối thấp, chỉ ra hiệu quả trong việc sử dụng tài nguyên¹⁵.

6 Kết luận

Nghiên cứu này trình bày một chiến lược tương tác công cụ, tận dụng sự tương tác chia-để-trị giữa các mô hình ngôn ngữ lớn và một tập hợp các công cụ để trả lời hiệu quả các câu hỏi đa phương thức nhiều bước. Chiến lược của chúng tôi tạo điều kiện cho việc chia các câu hỏi MMH thành các câu hỏi con USH, cho phép LLM tương tác với một tập hợp các công cụ được định nghĩa trước để thu được câu trả lời trung gian. Chúng tôi đã đánh giá hiệu suất của các LLM có kích thước khác nhau trong ba chiến lược lý luận khác nhau. Kết quả thu được cho thấy hiệu quả của chiến lược của chúng tôi. Đối với các hướng tương lai có thể, chúng tôi sẽ bao gồm việc khám phá giao tiếp giữa các công cụ, xử lý các phương thức không được định nghĩa trước, và cải thiện hiệu suất của các LLM nhỏ hơn cho các nhiệm vụ MMH QA.

¹³https://huggingface.co/google/tapas-base-finetuned-wtq
¹⁴https://huggingface.co/docs/transformers/model_doc/blip-2
¹⁵Trong trường hợp của ToolsAnswer, Trung bình Gọi Công cụ luôn bằng 4, vì chiến lược này gọi mỗi công cụ chỉ một lần.

--- TRANG 5 ---
BẢN THẢO

LLM | Kích thước | Chiến lược | EM | F1 | Trung bình Gọi Công cụ
StableLM | 7b | ToolsAnswer | 0.0 | 8.35 | 4
Pathia | 12b | ToolsAnswer | 0.0 | 12.41 | 4
LLaMA | 13b | ToolsAnswer | 0.0 | 13.95 | 4
Falcon | 40b | ToolsAnswer | 3.45 | 22.15 | 4
ChatGPT | NA | ToolsAnswer | 8.91 | 46.10 | 4
StableLM* | 7b | mm-ReAct | 2.24 | 17.42 | 11.56
Pathia* | 12b | mm-ReAct | 6.15 | 18.51 | 10.35
LLaMA* | 13b | mm-ReAct | 7.84 | 21.32 | 10.41
Falcon* | 40b | mm-ReAct | 18.37 | 41.08 | 8.96
ChatGPT | NA | mm-ReAct | 41.33 | 52.17 | 6.35
StableLM* | 7b | Ours | 7.11 | 16.36 | 10.22
Pathia* | 12b | Ours | 10.76 | 24.21 | 9.34
LLaMA* | 13b | Ours | 11.27 | 26.39 | 6.54
Falcon* | 40b | Ours | 38.91 | 56.51 | 4.96
ChatGPT | NA | Ours | 47.05 | 58.82 | 3.80
Con người | - | - | NA | NA | -

Bảng 4: Kết quả kiểm tra trên benchmark MMCoQA. Tất cả các phương pháp được trình bày với một tập hợp công cụ giống hệt nhau. "NA" biểu thị dữ liệu không có sẵn. Số lần Gọi Công cụ tối đa cho mỗi câu hỏi được đặt là 12. "*" có nghĩa là LLM tương ứng được tinh chỉnh sử dụng QLoRA trong một epoch thông qua chiến lược liên quan của nó.

Tài liệu tham khảo

[1] OpenAI. Chatgpt. OpenAI Blog, 1(8):9, 2022.

[2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

[3] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.

[4] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.

[5] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023, 2023.

[6] Hussam Alkaissi và Samy I McFarlane. Artificial hallucinations in chatgpt: implications in scientific writing. Cureus, 15(2), 2023.

[7] Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, và Mike Lewis. Measuring and narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350, 2022.

[8] Razvan Azamfirei, Sapna R Kudchadkar, và James Fackler. Large language models and the perils of their hallucinations. Critical Care, 27(1):1–2, 2023.

[9] Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnemann, Eyke Hüllermeier, et al. Chatgpt for good? on opportunities and challenges of large language models for education. Learning and Individual Differences, 103:102274, 2023.

[10] Emilio Ferrara. Should chatgpt be biased? challenges and risks of bias in large language models. arXiv preprint arXiv:2304.03738, 2023.

[11] Antonia Creswell và Murray Shanahan. Faithful reasoning using large language models. arXiv preprint arXiv:2208.14271, 2022.

[12] Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, và Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022.

[13] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, và Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.

--- TRANG 6 ---
BẢN THẢO

[14] Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, và Lijuan Wang. Mm-react: Prompting chatgpt for multimodal reasoning and action. arXiv preprint arXiv:2303.11381, 2023.

[15] Dídac Surís, Sachit Menon, và Carl Vondrick. Vipergpt: Visual inference via python execution for reasoning. arXiv preprint arXiv:2303.08128, 2023.

[16] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, và Jianfeng Gao. Chameleon: Plug-and-play compositional reasoning with large language models. arXiv preprint arXiv:2304.09842, 2023.

[17] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, và Marco Tulio Ribeiro. Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014, 2023.

[18] Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng, và Tat-seng Chua. Search-in-the-chain: Towards the accurate, credible and traceable content generation for complex knowledge-intensive tasks. arXiv preprint arXiv:2304.14732, 2023.

[19] Jayr Pereira, Robson Fidalgo, Roberto Lotufo, và Rodrigo Nogueira. Visconde: Multi-document qa with gpt-3 and neural reranking. In Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023, Dublin, Ireland, April 2–6, 2023, Proceedings, Part II, pages 534–543. Springer, 2023.

[20] Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, et al. Check your facts and try again: Improving large language models with external knowledge and automated feedback. arXiv preprint arXiv:2302.12813, 2023.

[21] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, và Thomas Scialom. Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761, 2023.

[22] Beichen Zhang, Kun Zhou, Xilin Wei, Wayne Xin Zhao, Jing Sha, Shijin Wang, và Ji-Rong Wen. Evaluating and improving tool-augmented computation-intensive math reasoning, 2023.

[23] Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, và Nan Duan. Visual chatgpt: Talking, drawing and editing with visual foundation models, 2023.

[24] Alessandro Stolfo, Zhijing Jin, Kumar Shridhar, Bernhard Schölkopf, và Mrinmaya Sachan. A causal framework to quantify the robustness of mathematical reasoning with language models. arXiv preprint arXiv:2210.12023, 2022.

[25] Kumar Shridhar, Alessandro Stolfo, và Mrinmaya Sachan. Distilling multi-step reasoning capabilities of large language models into smaller models via semantic decompositions. arXiv preprint arXiv:2212.00193, 2022.

[26] Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, và Aliaksei Severyn. Teaching small language models to reason. arXiv preprint arXiv:2212.08410, 2022.

[27] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, và Luke Zettlemoyer. Qlora: Efficient finetuning of quantized llms, 2023.

[28] Alon Talmor, Ori Yoran, Amnon Catav, Dan Lahav, Yizhong Wang, Akari Asai, Gabriel Ilharco, Hannaneh Hajishirzi, và Jonathan Berant. Multimodalqa: Complex question answering over text, tables and images. arXiv preprint arXiv:2104.06039, 2021.

[29] Yongqi Li, Wenjie Li, và Liqiang Nie. Mmcoqa: Conversational question answering over text, tables, and images. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4220–4231, 2022.

[30] Hongjin Su, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-tau Yih, Noah A Smith, Luke Zettlemoyer, Tao Yu, et al. One embedder, any task: Instruction-finetuned text embeddings. arXiv preprint arXiv:2212.09741, 2022.

[31] Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller, Francesco Piccinno, và Julian Martin Eisenschlos. Tapas: Weakly supervised table parsing via pre-training. arXiv preprint arXiv:2004.02349, 2020.

[32] Junnan Li, Dongxu Li, Silvio Savarese, và Steven Hoi. Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. arXiv preprint arXiv:2301.12597, 2023.

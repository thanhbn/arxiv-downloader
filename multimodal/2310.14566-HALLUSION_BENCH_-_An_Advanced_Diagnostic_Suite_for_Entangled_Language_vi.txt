# HALLUSION BENCH: Bộ Công Cụ Chẩn Đoán Nâng Cao cho Ảo Giác Ngôn Ngữ Phức Tạp và Ảo Ảnh Thị Giác trong Các Mô Hình Thị Giác-Ngôn Ngữ Lớn

Tianrui Guan*Fuxiao Liu*Xiyang Wu Ruiqi Xian Zongxia Li Xiaoyu Liu Xijun Wang
Lichang Chen Furong Huang Yaser Yacoob Dinesh Manocha Tianyi Zhou
Đại học Maryland, College Park

## Tóm tắt

Chúng tôi giới thiệu "HALLUSION BENCH," một bộ đánh giá toàn diện được thiết kế để đánh giá khả năng suy luận ngữ cảnh hình ảnh. Bộ đánh giá này đưa ra những thách thức đáng kể đối với các mô hình thị giác-ngôn ngữ lớn tiên tiến (LVLMs), chẳng hạn như GPT-4V(ision), Gemini Pro Vision, Claude 3, và LLaVA-1.5, bằng cách nhấn mạnh vào sự hiểu biết và diễn giải tinh tế của dữ liệu thị giác. Bộ đánh giá bao gồm 346 hình ảnh được ghép nối với 1129 câu hỏi, tất cả đều được tạo ra một cách tỉ mỉ bởi các chuyên gia con người. Chúng tôi giới thiệu một cấu trúc mới cho các câu hỏi thị giác này được thiết kế để thiết lập các nhóm kiểm soát. Cấu trúc này cho phép chúng tôi tiến hành phân tích định lượng về xu hướng phản hồi của các mô hình, tính nhất quán logic, và các chế độ thất bại khác nhau. Trong đánh giá của chúng tôi trên HALLUSION BENCH, chúng tôi đã đánh giá 15 mô hình khác nhau, nổi bật với độ chính xác cặp câu hỏi 31.42% đạt được bởi GPT-4V tiên tiến nhất. Đáng chú ý, tất cả các mô hình được đánh giá khác đều đạt độ chính xác dưới 16%. Hơn nữa, phân tích của chúng tôi không chỉ làm nổi bật các chế độ thất bại quan sát được, bao gồm ảo giác ngôn ngữ và ảo ảnh thị giác mà còn làm sâu sắc thêm sự hiểu biết về những cạm bẫy này. Các nghiên cứu trường hợp toàn diện của chúng tôi trong HALLUSION BENCH làm sáng tỏ những thách thức của ảo giác và ảo ảnh trong LVLMs. Dựa trên những hiểu biết này, chúng tôi đề xuất các con đường tiềm năng để cải thiện chúng trong tương lai.

## 1. Giới thiệu

Trong những năm gần đây, Các Mô Hình Ngôn Ngữ Lớn (LLMs) đã cách mạng hóa lĩnh vực học máy với khả năng hiểu ngôn ngữ và tạo nội dung, mang lại những khả năng và tiềm năng chưa từng có trên nhiều ứng dụng. Việc tích hợp LLMs với các hệ thống thị giác máy tính đã tạo ra Các Mô Hình Thị Giác-Ngôn Ngữ Lớn (LVLMs). Những mô hình này đã chứng minh khả năng sâu sắc trong các ứng dụng khác nhau và tăng cường đáng kể hiệu suất trong các tác vụ suy luận hình ảnh.

Tuy nhiên, vấn đề ảo giác của LLMs được coi là một vấn đề thách thức và chưa được giải quyết, dẫn đến nhiều vấn đề khi chúng ta tích hợp LLMs với các kỹ thuật thị giác. Trong khi LVLMs như GPT-4V(ision) và LLaVA-1.5 xuất sắc trong các ứng dụng khác nhau, chúng bị cản trở bởi sự thiên vị ngôn ngữ rõ rệt. Sự thiên vị này xuất phát từ các trường hợp mà kiến thức tiền đề xung đột với ngữ cảnh thị giác. Tương tự, các mô hình như LLaVA-1.5 và mPLUG-Owl có xu hướng đưa ra câu trả lời khẳng định bất kể nội dung thực tế của câu hỏi. Các chế độ thất bại khác biệt của các VLMs khác nhau làm nổi bật nhu cầu cải thiện cụ thể. Việc nhận ra và hiểu những hạn chế và loại thất bại này là bắt buộc để phát triển những mô hình này và tạo ra sự cân bằng tinh tế giữa kiến thức tiền đề và hiểu biết ngữ cảnh.

Khi khám phá những LVLMs đó, chúng tôi quan sát thấy rằng sự thiên vị ngôn ngữ mạnh mẽ của chúng thường che khuất thông tin thị giác, dẫn đến sự phụ thuộc quá mức vào các tiền đề ngôn ngữ thay vì ngữ cảnh thị giác. Để nghiên cứu hiện tượng này, chúng tôi sử dụng thuật ngữ "Ảo Giác Ngôn Ngữ," có nghĩa là những kết luận được rút ra mà không có đầu vào thị giác. Mặt khác, các thành phần thị giác trong khả năng hạn chế trong LVLMs có thể tạo ra "Ảo Ảnh Thị Giác", nơi các đầu vào thị giác có thể bị diễn giải sai, dẫn đến những khẳng định quá tự tin nhưng sai lầm bởi mô hình.

**Đóng góp chính:** Nhận ra nhu cầu hiểu tại sao một LVLM thất bại và giải quyết những vấn đề này, chúng tôi trình bày HALLUSION BENCH, một bộ đánh giá được tạo ra cẩn thận được thiết kế để khám phá sự phức tạp của suy luận ngữ cảnh hình ảnh một cách sâu sắc và phơi bày các vấn đề khác nhau liên quan đến LVLMs hiện tại. Những điểm mới của công trình chúng tôi bao gồm:

1. Chúng tôi giới thiệu HALLUSION BENCH, bộ công cụ chẩn đoán nâng cao đầu tiên được thiết kế riêng để phân tích có hệ thống và phân tích các chế độ thất bại đa dạng của LVLMs. HALLUSION BENCH bao gồm khoảng 1129 cặp câu hỏi-trả lời thị giác (VQA) được tạo thủ công, có 165 hình ảnh gốc và 181 hình ảnh được sửa đổi chuyên nghiệp bởi con người. Vượt ra ngoài các số liệu truyền thống về tính đúng đắn và độ chính xác, các cặp VQA của chúng tôi được xây dựng chu đáo với một cấu trúc sáng tạo. Cách tiếp cận này cho phép chúng tôi phân tích định lượng các khía cạnh và chiều hướng cụ thể mà các mô hình hiện tại thất bại.

2. Chúng tôi đánh giá 15 phương pháp gần đây nhất trên HALLUSION BENCH. Bộ đánh giá của chúng tôi đưa ra những thách thức đáng gờm đối với các phương pháp hiện có. Đáng chú ý, GPT-4V SoTA chỉ đạt được 31.42% Độ Chính Xác Cặp Câu Hỏi, trong khi hiệu suất của tất cả các phương pháp khác đều dưới 16%.

3. Chúng tôi khám phá HALLUSION BENCH và cung cấp phân tích sâu về các ví dụ mà LVLMs SoTA, chẳng hạn như GPT-4V và LLaVA-1.5 thất bại. Chúng tôi cũng cung cấp hiểu biết về các vấn đề khác nhau mà LVLMs hiện tại đang đối mặt dựa trên phân tích định lượng được kích hoạt bởi HALLUSION BENCH.

## 2. Công trình liên quan

### 2.1. Các Mô Hình Đa Phương Thức Lớn

Các Mô Hình Ngôn Ngữ Lớn đã là một tiến bộ lớn, dẫn đến những cách mới để hiểu không chỉ văn bản mà cả những thứ khác như hình ảnh, tất cả trong một hệ thống lớn. Ví dụ, Flamingo có nhiều khả năng, kết hợp một phần thị giác không thay đổi với một mô hình ngôn ngữ lớn có tính năng đặc biệt để hiểu cả hình ảnh và từ ngữ cùng nhau. Một mô hình khác, PaLM-E, trộn thông tin thị giác trực tiếp vào mô hình PaLM đã mạnh mẽ, có 520 tỷ tham số, làm cho nó hiệu quả trong việc sử dụng thực tế. Gần đây nhất, các nhà nghiên cứu đã tạo ra các tập dữ liệu đa phương thức chất lượng cao, đa dạng từ GPT4 và GPT-4V để tinh chỉnh LVLMs mã nguồn mở, bao gồm LLaVA, MiniGPT4, Mplug-Owl, LRV-Instruction, LLaVAR và các công trình khác.

### 2.2. Ảo giác trong LVLMs

Ảo giác thường đề cập đến các tình huống mà các phản hồi được tạo ra chứa thông tin không có trong nội dung thị giác. Nghiên cứu trước đây chủ yếu kiểm tra hai lĩnh vực: phát hiện và đánh giá ảo giác, và các phương pháp để giảm chúng. Các phương pháp ban đầu bao gồm huấn luyện các bộ phân loại để xác định ảo giác hoặc so sánh đầu ra với câu trả lời chính xác để phát hiện sự không chính xác. Để giảm thiểu ảo giác, những nỗ lực đã được thực hiện để cải thiện thu thập dữ liệu và quy trình huấn luyện. Ví dụ, LRV-Instruction tạo ra các hướng dẫn tích cực và tiêu cực cân bằng để tinh chỉnh LVLMs. VIGC sử dụng một quy trình lặp đi lặp lại để tạo ra các câu trả lời súc tích và kết hợp chúng, nhằm mục đích có được các phản hồi chi tiết nhưng chính xác. Tương tự, Woodpecker giới thiệu một phương pháp không cần huấn luyện để chọn ra và sửa chữa ảo giác từ văn bản được tạo ra.

### 2.3. Các Bộ Đánh Giá cho Các Mô Hình VL Lớn

Các bộ đánh giá Ngôn Ngữ Thị Giác (VL) truyền thống được thiết kế để đánh giá các kỹ năng riêng biệt, bao gồm nhận dạng thị giác, mô tả hình ảnh, v.v. Tuy nhiên, với sự xuất hiện của LVLMs tiên tiến, các số liệu đánh giá truyền thống thường không đủ để cung cấp một đánh giá khả năng chi tiết. Vấn đề này được làm trầm trọng thêm bởi sự không thể khớp câu trả lời đã cho một cách chính xác, dẫn đến các vấn đề về tính mạnh mẽ đáng kể. Để giải quyết những thách thức này, cộng đồng nghiên cứu đã giới thiệu một loạt các bộ đánh giá, bao gồm MME, MMBench, MM-Vet, SEED-Bench, GAVIE, và LAMM-Bench. Những bộ đánh giá này cấu trúc và đánh giá các tác vụ đa phương thức phức tạp một cách có hệ thống. Khác với POPE và GAVIE đánh giá ảo giác đối tượng của LVLMs, HALLUSION BENCH là bộ đánh giá phân tích được chú thích bởi con người đầu tiên tập trung vào chẩn đoán cả ảo ảnh thị giác và ảo giác kiến thức của LVLMs.

## 3. Xây dựng HALLUSION BENCH

Chúng tôi trình bày HALLUSION BENCH, bộ đánh giá đầu tiên được thiết kế để kiểm tra ảo ảnh thị giác và ảo giác kiến thức của LVLMs và phân tích các chế độ thất bại tiềm năng dựa trên từng cặp ví dụ được tạo thủ công. HALLUSION BENCH bao gồm 455 cặp kiểm soát câu hỏi thị giác, bao gồm 346 hình ảnh khác nhau và tổng cộng 1129 câu hỏi về các chủ đề đa dạng (bao gồm thức ăn, toán học, hình học, thống kê, địa lý, thể thao, hoạt hình, ảo giác nổi tiếng, phim, meme, v.v.) và các định dạng (bao gồm logo, poster, hình ảnh, biểu đồ, bảng, bản đồ, hình ảnh liên tiếp, v.v.).

### 3.1. Phân loại Câu Hỏi Thị Giác

Mục tiêu của chúng tôi là phát triển một bộ đánh giá suy luận ngữ cảnh hình ảnh đa phương thức để điều tra sự thiên vị ngôn ngữ mạnh mẽ vốn có trong LVLMs, điều này đôi khi có thể che khuất ngữ cảnh thị giác. Chúng tôi định nghĩa hai loại câu hỏi thị giác: Phụ Thuộc Thị Giác và Bổ Sung Thị Giác.

#### 3.1.1 Câu Hỏi Phụ Thuộc Thị Giác

Các câu hỏi Phụ Thuộc Thị Giác được định nghĩa là những câu hỏi không có câu trả lời khẳng định nếu không có ngữ cảnh thị giác. Những câu hỏi như vậy hỏi về chính hình ảnh hoặc cái gì đó trong hình ảnh. Ví dụ, không có câu trả lời rõ ràng cho "Vòng tròn cam bên phải có cùng kích thước với vòng tròn cam bên trái không?" mà không có hình ảnh để cung cấp thêm ngữ cảnh.

#### 3.1.2 Câu Hỏi Bổ Sung Thị Giác

Các câu hỏi Bổ Sung Thị Giác là những câu hỏi có thể được trả lời mà không cần đầu vào thị giác; thành phần thị giác chỉ cung cấp thông tin bổ sung hoặc sửa chữa. Ví dụ, một số LVLMs có thể trả lời "Bang New Mexico có lớn hơn bang Texas không?" bằng cách sử dụng kiến thức tiền đề trong bộ nhớ tham số của chúng mà không cần bản đồ Hoa Kỳ.

### 3.2. Cấu trúc Thị Giác, Câu Hỏi và Chú Thích

Các ký hiệu được định nghĩa để mô tả cấu trúc dữ liệu, bao gồm các hình ảnh gốc và được chỉnh sửa, cùng với các bộ câu hỏi tương ứng. Để tạo điều kiện thuận lợi cho việc đánh giá, tất cả câu hỏi được xây dựng dưới dạng câu hỏi Có/Không. Chúng tôi chú thích mỗi câu hỏi thị giác với một câu trả lời nhị phân.

### 3.3. Thống kê Tập Dữ Liệu

Theo cấu trúc và hướng dẫn chú thích ở trên, chúng tôi yêu cầu các chuyên gia con người thu thập 346 hình ảnh với các chủ đề và loại đa dạng một cách thủ công. Như thể hiện trong Hình 2, Phụ Thuộc Thị Giác có 591 câu hỏi, bao gồm video, ảo giác, toán học, poster, logo, hoạt hình, và khác; Bổ Sung Thị Giác có 538 câu hỏi, bao gồm biểu đồ, bảng, bản đồ, và OCR. Hơn nữa, Hình 2 (phải) mô tả sự phân bố của các câu hỏi không có đầu vào thị giác (16%), với hình ảnh trực tuyến gốc (39%), và với đầu vào thị giác được chỉnh sửa bởi các chuyên gia con người (45%). Các chiến lược thao tác hình ảnh của chúng tôi bao gồm lật hình ảnh, đảo ngược thứ tự, che giấu, chỉnh sửa ký tự quang học, chỉnh sửa đối tượng, và chỉnh sửa màu sắc. Ngoài ra, mỗi hình ảnh có trung bình 3.26 câu hỏi.

### 3.4. Tính Độc Đáo của HALLUSION BENCH

So sánh chính giữa HALLUSION BENCH và các bộ đánh giá hiện có được trình bày trong Bảng 1. Như nó cho thấy, có một khoảng cách đáng chú ý giữa các bộ đánh giá hiện có và HALLUSION BENCH trong việc đánh giá ảo giác, vì các bộ đánh giá hiện có chủ yếu tập trung vào ảo giác đối tượng, các chủ đề hạn chế và các loại đầu vào thị giác. Do đó, tập dữ liệu của chúng tôi, HALLUSION BENCH, được thúc đẩy để lấp đầy khoảng trống này bằng cách cung cấp nhiều chủ đề, nhiều loại hình ảnh và nhiều phương thức đầu vào thị giác hơn, bao gồm cả hình ảnh và video. Ngoài ra, các chuyên gia con người của chúng tôi cẩn thận lựa chọn từng hình ảnh và viết các cặp câu hỏi-trả lời. Chúng tôi cũng là công trình đầu tiên bao gồm hình ảnh được chỉnh sửa bởi con người để đánh giá tính mạnh mẽ của LVLMs hiện tại. Ngoài ra, khác với các bộ đánh giá hiện có, HALLUSION BENCH tập trung vào việc đánh giá cả ảo giác ngôn ngữ và ảo ảnh thị giác, vượt ra ngoài phạm vi hẹp của ảo giác đối tượng.

## 4. Bộ Đánh Giá HALLUSION BENCH

### 4.1. Đánh Giá Hỗ Trợ GPT4 Chỉ Văn Bản

Chúng tôi thiết kế một hệ thống đánh giá sử dụng GPT-4 để đánh giá tính đúng đắn của câu trả lời. GPT-4 được sử dụng để phán đoán câu trả lời dựa trên câu trả lời chuẩn và đưa ra đầu ra Không Đúng (0), Đúng (1), hoặc Không Chắc Chắn (2) nếu phản hồi dự đoán không rõ ràng.

### 4.2. Các Số Liệu Đánh Giá Tính Đúng Đắn

Vì trọng tâm của bộ đánh giá của chúng tôi là về ảo giác và ảo ảnh, không phải về phạm vi kiến thức, chúng tôi coi một câu trả lời không chắc chắn là có thể chấp nhận được khi không có đầu vào thị giác trong danh mục Bổ Sung Thị Giác. Chúng tôi định nghĩa các số liệu đánh giá khác nhau bao gồm Độ Chính Xác Tất Cả, Độ Chính Xác Hình Ảnh, và Độ Chính Xác Cặp Câu Hỏi.

### 4.3. Các Tiêu Chí Đánh Giá Phân Tích

Ngoài các số liệu độ chính xác, chúng tôi giới thiệu ba tiêu chí phân tích để đo lường và chẩn đoán các thất bại của LVLMs: Kiểm Tra Thiên Vị Có/Không, Kiểm Tra Tính Nhất Quán, và Kiểm Tra Chẩn Đoán.

#### 4.3.1 Kiểm Tra Thiên Vị Có/Không

Theo nghiên cứu trước, một số mô hình có xu hướng phản hồi với "có" trong hầu hết các trường hợp. Chúng tôi thiết kế hai tiêu chí để tiết lộ sự ưu tiên như vậy của mô hình: Chênh Lệch Phần Trăm Có và Tỷ Lệ Dương Tính Giả.

#### 4.3.2 Kiểm Tra Tính Nhất Quán

Mục tiêu của kiểm tra tính nhất quán là kiểm tra tính nhất quán logic của các phản hồi và đảm bảo rằng các câu hỏi không được trả lời dựa trên phỏng đoán ngẫu nhiên. Chúng tôi thiết kế tập câu hỏi để có tương quan logic trên một hình ảnh.

#### 4.3.3 Ảo Giác Ngôn Ngữ và Ảo Ảnh Thị Giác

Trước khi đi sâu vào kiểm tra chẩn đoán, chúng tôi phân loại các thất bại thành hai loại chính dựa trên các trường hợp thất bại:

**Ảo Giác Ngôn Ngữ** đề cập đến các nhận thức được hình thành mà không có đầu vào thị giác liên quan. Trong ảo giác ngôn ngữ, mô hình đưa ra các giả định tiền đề sai về đầu vào và ngữ cảnh hình ảnh dựa trên bộ nhớ tham số của nó.

**Ảo Ảnh Thị Giác** biểu thị sự diễn giải sai thông tin thị giác chính xác. Ảo ảnh thị giác xuất phát từ việc thất bại trong việc nhận ra và hiểu đầu vào hình ảnh một cách thị giác.

#### 4.3.4 Kiểm Tra Chẩn Đoán

Để nghiên cứu vấn đề ảo giác ngôn ngữ và ảo ảnh ngôn ngữ, chúng tôi phân tích các phản hồi và tính đúng đắn của cả hai câu hỏi thị giác trong Cặp Kiểm Soát VQ và chia các phản hồi không chính xác thành ba loại: Ảo Giác Ngôn Ngữ, Ảo Ảnh Thị Giác, và Hỗn Hợp/Không Chắc Chắn.

## 5. Kết Quả Thực Nghiệm

### 5.1. Các Mô Hình

Chúng tôi tiến hành các thí nghiệm khổng lồ trên HALLUSION BENCH để đánh giá tổng cộng 15 LVLMs, bao gồm GPT-4V, LLaVA-1.5, Gemini Pro Vision, Claude 3, MiniGPT4, MiniGPT5, GiT, InstructBLIP, Qwen-VL, mPLUG-Owl-v1, mPLUG-Owl-v2, LRV-Instruction, BLIP2, BLIP2-T5, và Open-Flamingo. Chúng tôi cũng bao gồm Cơ Hội Ngẫu Nhiên (tức là chọn ngẫu nhiên Có hoặc Không) như một đường cơ sở.

### 5.2. Phân Tích Kết Quả

Chúng tôi so sánh hiệu suất của một số mô hình, bao gồm cả mô hình nguồn đóng và mô hình nguồn mở. Kết quả được đưa ra trong Bảng 2, Bảng 3 và Hình 4.

**Đánh Giá Tính Đúng Đắn.** Như thể hiện trong Bảng 2, GPT-4V vượt trội hơn tất cả các LVLMs nguồn mở với biên độ lớn ngoại trừ Độ Chính Xác Khó. Độ Chính Xác Khó đo lường khả năng của các mô hình để hiểu hình ảnh được chỉnh sửa bởi con người từ HALLUSION BENCH. Độ chính xác kém cho thấy những thách thức của các thao tác hình ảnh của chúng tôi đối với GPT-4V và các LVLMs nguồn mở khác.

**Thiên Vị Có/Không.** Một quan sát khác là GPT-4V, BLIP2-T5, và mPLUG-Owl-v2 vượt trội hơn Lựa Chọn Ngẫu Nhiên trong cả độ chính xác cặp câu hỏi, độ chính xác cặp hình ảnh, và độ chính xác cấp câu hỏi. Các mô hình khác, chẳng hạn như Qwen-VL và MiniGPT4, thực hiện thậm chí tệ hơn Lựa Chọn Ngẫu Nhiên. Điều này cho thấy khả năng suy luận thị giác của chúng vẫn còn hạn chế.

**Chẩn Đoán Ngôn Ngữ và Thị Giác.** Chúng tôi báo cáo điểm số chi tiết của sáu LVLMs nổi bật trên các đầu vào thị giác khác nhau trong Hình 4. Kết quả cho thấy rằng Toán Học, Ảo Giác, và Video là định dạng thách thức nhất đối với LVLMs hiện tại, bao gồm cả GPT-4V.

## 6. Kết Luận, Hạn Chế và Công Việc Tương Lai

Trong công trình này, chúng tôi giới thiệu HALLUSION BENCH, bộ công cụ chẩn đoán nâng cao đầu tiên để phân tích các trường hợp thất bại của 15 LVLMs hiện tại. HALLUSION BENCH đưa ra những thách thức đáng kể đối với các LVLMs hiện có như GPT-4V(ision), bằng cách nhấn mạnh vào sự hiểu biết và diễn giải tinh tế của dữ liệu thị giác. Hơn nữa, thiết kế độc đáo của các cặp câu hỏi thị giác của chúng tôi tạo điều kiện thuận lợi cho việc phân tích định lượng các thất bại của mô hình, cho phép đánh giá kỹ lưỡng hơn. Chúng tôi chia sẻ các quan sát và hiểu biết chính của chúng tôi cho các nghiên cứu tương lai:

1. Khi GPT-4V, LLaVA-1.5, và các LVLMs khác có kiến thức tiền đề về các câu hỏi trong HALLUSION BENCH, chúng thường gặp phải Ảo Giác Ngôn Ngữ vì chúng có xu hướng ưu tiên kiến thức tiền đề của mình dẫn đến câu trả lời không chính xác. Mô hình nên xử lý sự cân bằng giữa bộ nhớ tham số và ngữ cảnh.

2. Khi LVLMs không có bộ nhớ tham số hoặc kiến thức tiền đề về các câu hỏi trong HALLUSION BENCH, chúng vẫn có thể dễ bị Ảo Ảnh Thị Giác và thích tạo ra câu trả lời sai về hình ảnh đã cho. Khả năng thị giác của LVLMs hiện tại vẫn còn hạn chế.

3. GPT-4V và các LVLMs khác có thể dễ dàng bị đánh lừa bởi các thao tác hình ảnh đơn giản trong HALLUSION BENCH, bao gồm lật hình ảnh, đảo ngược thứ tự, che giấu, chỉnh sửa ký tự quang học, chỉnh sửa đối tượng, và chỉnh sửa màu sắc.

4. GPT-4V và các LVLMs khác không thể nắm bắt các mối quan hệ thời gian của nhiều hình ảnh và thất bại trong việc trả lời các câu hỏi suy luận thời gian trong HALLUSION BENCH. Các LVLMs hiện tại thiếu khả năng suy luận thời gian thực sự.

Chúng tôi dự định mở rộng bộ đánh giá này và tìm ra các cách khác để chẩn đoán các vấn đề trong LVLMs. Chúng tôi hy vọng rằng HALLUSION BENCH có thể được sử dụng để xác định và cung cấp hiểu biết về điểm yếu của các LVLMs khác nhau, để tạo điều kiện thuận lợi cho việc tinh chỉnh và cải thiện các mô hình đó dựa trên chẩn đoán.

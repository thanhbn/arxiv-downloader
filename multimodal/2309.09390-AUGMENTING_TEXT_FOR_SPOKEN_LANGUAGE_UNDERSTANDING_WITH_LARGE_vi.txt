# 2309.09390.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2309.09390.pdf
# Kích thước tệp: 183258 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
TĂNG CƯỜNG VẢN BẢN CHO HIỂU BIẾT NGÔN NGỮ NÓI VỚI MÔ HÌNH NGÔN NGỮ LỚN

Roshan Sharma1∗, Suyoun Kim2, Daniel Lazar2, Trang Le2, Akshat Shrivastava2,
Kwanghoon An2, Piyush Kansal2, Leda Sari2, Ozlem Kalinli2, Michael Seltzer2
1Đại học Carnegie Mellon, Pittsburgh, Hoa Kỳ và 2Meta, Seattle, Hoa Kỳ

TÓM TẮT
Phân tích cú pháp ngữ nghĩa nói (SSP) liên quan đến việc tạo ra các phân tích có thể hiểu được bằng máy từ đầu vào giọng nói. Việc huấn luyện các mô hình mạnh mẽ cho các miền ứng dụng hiện có được thể hiện trong dữ liệu huấn luyện hoặc mở rộng sang các miền mới đòi hỏi các bộ ba dữ liệu tương ứng của giọng nói-bản chép-phân tích cú pháp ngữ nghĩa, điều này tốn kém để có được. Trong bài báo này, chúng tôi giải quyết thách thức này bằng cách kiểm tra các phương pháp có thể sử dụng dữ liệu bản chép-phân tích cú pháp ngữ nghĩa (văn bản không ghép đôi) mà không có giọng nói tương ứng. Đầu tiên, khi văn bản không ghép đôi được rút ra từ các tập dữ liệu văn bản hiện có, Joint Audio Text (JAT) và Text-to-Speech (TTS) được so sánh như các cách tạo ra biểu diễn giọng nói cho văn bản không ghép đôi. Các thí nghiệm trên tập dữ liệu STOP cho thấy rằng văn bản không ghép đôi từ các miền hiện có và mới cải thiện hiệu suất lần lượt 2% và 30% theo Exact Match (EM) tuyệt đối. Thứ hai, chúng tôi xem xét tình huống khi văn bản không ghép đôi không có sẵn trong các tập dữ liệu văn bản hiện có. Chúng tôi đề xuất thúc đẩy các Mô hình Ngôn ngữ Lớn (LLM) để tạo ra văn bản không ghép đôi cho các miền hiện có và mới. Các thí nghiệm cho thấy rằng các ví dụ và từ xuất hiện cùng với ý định có thể được sử dụng để tạo ra văn bản không ghép đôi với Llama 2.0. Sử dụng văn bản được tạo ra với JAT và TTS cho phân tích cú pháp ngữ nghĩa nói cải thiện EM trên STOP lần lượt 1.4% và 2.6% tuyệt đối cho các miền hiện có và mới.

Từ khóa chỉ mục —hiểu biết ngôn ngữ nói, trên thiết bị, dữ liệu không ghép đôi, mô hình ngôn ngữ lớn, thúc đẩy

1. GIỚI THIỆU
Hiểu biết Ngôn ngữ Nói (SLU) là cần thiết cho nhiều ứng dụng thực tế ngày nay bao gồm các tác nhân đối thoại và trợ lý ảo. Phân tích Cú pháp Ngữ nghĩa Nói (SSP) là nhiệm vụ SLU liên quan đến việc biến đổi một bản ghi âm thành cây phân tích có thể hiểu được bằng máy [1]. Các mô hình đầu cuối đến cuối [2] hoạt động trực tiếp trên giọng nói trong khi các mô hình phối hợp [3] tạo ra phân tích cú pháp ngữ nghĩa dựa trên bản chép. Các mô hình thảo luận hai lượt [4] kết hợp những điều tốt nhất của cả hai thế giới, bằng cách sử dụng bản chép lượt đầu và nhúng giọng nói để cải thiện phân tích cú pháp ngữ nghĩa nói. Tuy nhiên, việc huấn luyện các mô hình như vậy với giám sát đòi hỏi các bộ ba phù hợp của giọng nói, bản chép và phân tích cú pháp ngữ nghĩa. Việc chú thích các bộ ba này tốn kém, điều này hạn chế kích thước dữ liệu huấn luyện và do đó hiệu suất mô hình.

Nhu cầu về dữ liệu phù hợp có thể được giảm bớt bằng cách phát triển các phương pháp chỉ có thể sử dụng dữ liệu văn bản. Dữ liệu văn bản (bản chép-phân tích cú pháp ngữ nghĩa) dễ dàng thu được hơn so với giọng nói - hoặc từ các tập dữ liệu văn bản hiện có hoặc bằng cách thúc đẩy các Mô hình Ngôn ngữ Lớn (LLM), và việc huấn luyện các mô hình với một lượng nhỏ dữ liệu giọng nói-văn bản ghép đôi và một lượng lớn văn bản không ghép đôi là hữu ích. Không đơn giản để kết hợp dữ liệu chỉ có văn bản vào các mô hình đầu cuối đến cuối bởi vì đầu ra mô hình không thể được thu được mà không có đầu vào giọng nói. Các nghiên cứu trước đây đã khám phá việc sử dụng dữ liệu văn bản cho nhận dạng giọng nói [5–7]. Các mô hình ngôn ngữ bên ngoài được huấn luyện trên văn bản có thể được sử dụng để nội suy xác suất dự đoán token [8], nhưng đòi hỏi bộ nhớ bổ sung, khiến chúng không phù hợp cho các ứng dụng trên thiết bị. Các phương pháp học tập phối hợp [9, 10] chiếu giọng nói và văn bản vào không gian nhúng chia sẻ cho nhận dạng giọng nói, nhưng các mô hình như vậy đòi hỏi lượng đáng kể dữ liệu giọng nói-văn bản ghép đôi để học các ánh xạ mạnh mẽ. Lớp cuối cùng của nghiên cứu tạo ra biểu diễn giọng nói cho giọng nói không ghép đôi - Joint Audio Text (JAT) [11] sử dụng nhúng giọng nói trung bình từ dữ liệu ghép đôi để biểu diễn văn bản không ghép đôi. Điều này tính toán không tốn kém, nhưng các nhúng giọng nói không chứa thông tin được nhúng trong giọng nói thực. Ngược lại, giọng nói tổng hợp từ các mô hình Text-to-speech (TTS) [5] tạo ra biểu diễn giọng nói thông tin, nhưng chúng có thể tốn kém để tính toán. Có hai trường hợp mà dữ liệu văn bản bổ sung có thể được thu thập cho phân tích cú pháp ngữ nghĩa - (a) để cải thiện các mô hình trên các miền hiện có (ED) và (b) để hỗ trợ các miền mới (ND). Trong bài báo này, chúng tôi so sánh JAT và TTS cho SSP khi dữ liệu văn bản không ghép đôi được rút ra từ các miền hiện có và mới.

Khi văn bản không ghép đôi không có sẵn từ các tập dữ liệu hiện có, chúng tôi đề xuất thúc đẩy các Mô hình Ngôn ngữ Lớn (LLM) [12–14] để tạo ra dữ liệu văn bản cho SSP. LLM ngoại lệ trong việc tạo ra văn bản thực tế dựa trên các thúc đẩy đầu vào, và trong bài báo này, chúng tôi sử dụng LLama 2.0 [14] để tạo ra dữ liệu văn bản. Đối với thiết lập ED, đủ để tạo ra bản chép vì các phân tích cú pháp ngữ nghĩa có thể được thu được từ bản chép sử dụng các bộ phân tích cú pháp ngữ nghĩa đã được huấn luyện trước.

--- TRANG 2 ---
chép sử dụng các bộ phân tích cú pháp ngữ nghĩa đã được huấn luyện trước. Chúng tôi mô tả hai phương pháp thúc đẩy: (a) thúc đẩy dựa trên từ ý định (IWP), nơi LLM tạo ra các bản chép tương ứng với một lớp ý định cụ thể và chứa các từ cùng xuất hiện với ý định, và (b) thúc đẩy dựa trên mẫu (EP), nơi nó tạo ra các bản chép tương tự với các ví dụ được cung cấp. Chúng tôi tạo ra nhãn giả cho các phát ngôn được tạo ra bằng cách sử dụng một mô hình RoBERTa [15] đã được huấn luyện trước và huấn luyện các mô hình SSP sử dụng JAT. Chúng tôi thấy rằng EP đơn giản hơn nhưng IWP tạo ra ý định mong muốn thường xuyên hơn. Sử dụng dữ liệu từ cả hai phương pháp cải thiện Exact Match (EM) trên dữ liệu STOP 1.4 điểm tuyệt đối.

Đối với thiết lập ND, các mô hình đã được huấn luyện trước cho việc tạo nhãn giả không có sẵn cho (các) miền mới, và do đó LLM được sử dụng để tạo ra các phân tích cú pháp ngữ nghĩa trực tiếp. Sau đó bản chép được suy ra từ phân tích cú pháp ngữ nghĩa. Thúc đẩy dựa trên mẫu (EP) được sử dụng với 3 ví dụ thực cho mỗi kết hợp ý định-slot có thể để tạo ra dữ liệu quy mô lớn. Chúng tôi thấy rằng dữ liệu được tạo ra cải thiện EM 2.3 điểm tuyệt đối so với một đường cơ sở chỉ sử dụng 3 ví dụ cho mỗi kết hợp.

Tóm lại, bài báo này đóng góp những điều sau:
1. Mở rộng JAT, trước đây được sử dụng cho ASR, sang phân tích cú pháp ngữ nghĩa nói đầu cuối đến cuối, và so sánh JAT với TTS cho dữ liệu văn bản từ các miền hiện có và miền mới.
2. Phát triển các chiến lược thúc đẩy để tạo ra các bản chép văn bản và phân tích cú pháp ngữ nghĩa trong các miền hiện có và mới sử dụng LLM.
3. Chứng minh rằng dữ liệu văn bản được tạo ra bởi LLM có thể được sử dụng kết hợp với JAT và TTS để cải thiện phân tích cú pháp ngữ nghĩa nói.

2. MÔ HÌNH THẢO LUẬN CHO SLU
Các mô hình SLU dựa trên thảo luận [4, 16] là các mô hình hai lượt dự đoán bản chép ASR trong lượt đầu. Sử dụng bản chép lượt đầu và âm thanh, sau đó nó tạo ra phân tích cú pháp ngữ nghĩa trong lượt thứ hai. Trái ngược với các mô hình phối hợp sử dụng các thành phần Nhận dạng Giọng nói Tự động (ASR) và SLU được huấn luyện riêng biệt, một mô hình thảo luận tối ưu hóa cả thành phần ASR và SLU cùng nhau. Để đạt được chức năng streaming trên thiết bị, thành phần ASR lượt đầu được triển khai sử dụng Recurrent Neural Network Transducer (RNNT) [17–19]. Để duy trì độ chính xác phiên âm, thành phần ASR của mô hình thảo luận được huấn luyện độc lập và được giữ đóng băng. Mô hình SLU dựa trên thảo luận của chúng tôi bao gồm hai mô-đun chính: (1) Fusion, và (2) Decoder. Mô-đun fusion kết hợp các nhúng âm thanh và văn bản trung gian từ bộ mã hóa và dự đoán RNNT lượt đầu tương ứng. Sử dụng Multi-Head Attention [20], mô-đun fusion tạo ra biểu diễn kết hợp được sử dụng bởi mô-đun decoder dựa trên transformer để dự đoán chuỗi phân tích cú pháp ngữ nghĩa mục tiêu.

3. BIỂU DIỄN GIỌNG NÓI CHO VẴN BẢN KHÔNG GHÉP ĐÔI
3.1. Huấn luyện Joint Audio-Text (JAT)
Huấn luyện Joint Audio-Text (JAT) [11] là một cách tiếp cận gần đây để tận dụng dữ liệu chỉ có văn bản không ghép đôi để cải thiện ASR [10, 11, 21, 22]. Không giống như fusion nông xem xét phân bố token từ một mô hình ngôn ngữ mạng thần kinh ngoài (NNLM), JAT không đòi hỏi tham số mô hình bổ sung hoặc độ trễ, khiến nó phù hợp cho ASR streaming trên thiết bị. Ý tưởng cốt lõi đằng sau JAT là biểu diễn giọng nói cho văn bản không ghép đôi có thể được tạo ra bằng cách đơn giản sử dụng nhúng giọng nói trung bình được tính toán trên dữ liệu giọng nói/văn bản ghép đôi có sẵn. Trong bài báo này, chúng tôi sử dụng phương pháp JAT để huấn luyện các mô hình Hiểu biết Ngôn ngữ Nói (SLU) của chúng tôi để cho phép huấn luyện với cả tập dữ liệu "giọng nói-văn bản-phân tích cú pháp ngữ nghĩa" và "văn bản-phân tích cú pháp ngữ nghĩa".

3.2. Tổng hợp Giọng nói với Voicebox
Voicebox [23] là một mô hình tạo giọng nói không tự hồi quy tiên tiến dựa trên Flow Matching [24]. Chúng tôi tạo ra biểu diễn cho văn bản không ghép đôi bằng cách trích xuất các đặc trưng giọng nói từ giọng nói được tổng hợp. Giọng nói tổng hợp có thể được thu được bằng cách sử dụng Voicebox ở chế độ TTS, tức là nơi âm thanh được tạo ra bằng cách điều kiện trên văn bản đầu vào. Khác với [23], mô hình Voicebox chúng tôi sử dụng biểu diễn văn bản đầu vào dưới dạng grapheme thay vì phoneme. Để tạo ra âm thanh, trước tiên chúng tôi lấy mẫu thời lượng đơn vị cho mỗi grapheme trong văn bản đầu vào sử dụng một mô hình thời lượng dựa trên flow-matching và sau đó tăng mẫu chuỗi grapheme sử dụng thông tin thời lượng đơn vị. Thông tin này được sử dụng như điều kiện để tạo ra spectrogram sử dụng mô hình âm thanh. Cuối cùng, chúng tôi sử dụng một vocoder HiFi-GAN [25] để chuyển đổi spectrogram thành tín hiệu miền thời gian.

4. TẠO DỮ LIỆU VĂN BẢN VỚI LLAMA 2.0
LLama 2.0 [14] là một mô hình ngôn ngữ lớn mã nguồn mở công khai được huấn luyện trên khối lượng lớn dữ liệu có sẵn công khai và mã với ngữ cảnh lên đến 4096. Trong bài báo này, chúng tôi sử dụng mô hình chat tham số 13B.

4.1. Tạo Dữ liệu Văn bản cho Miền Hiện có
Trong thiết lập ED, chúng tôi đề xuất sử dụng LLM để tạo ra bản chép. Các phân tích cú pháp ngữ nghĩa tương ứng được thu được bằng cách sử dụng một mô hình phân tích cú pháp ngữ nghĩa văn bản tạo nhãn giả được huấn luyện trên dữ liệu ghép đôi hiện có. Mô hình phân tích cú pháp ngữ nghĩa ở đây nhận bản chép làm đầu vào và tạo ra các phân tích cú pháp ngữ nghĩa nhãn giả làm đầu ra. Bản chép có thể được tạo ra bằng cách sử dụng một trong hai chiến lược thúc đẩy, tức là dựa trên từ ý định hoặc dựa trên mẫu.

Thúc đẩy dựa trên Từ Ý định (IWP): Mục tiêu của IWP là tạo ra các bản chép có thể được phân loại dưới một ý định nhất định, tùy chọn chứa "từ ý định". Từ ý định là các từ từ phân tích cú pháp ngữ nghĩa xuất hiện thường xuyên nhất với các ý định đã cho sau khi loại bỏ các từ dừng. Một ví dụ được hiển thị trong Hình 2. 40 từ cùng xuất hiện thường xuyên nhất với mỗi ý định trong dữ liệu STOP được sử dụng làm từ ý định. 40 ví dụ được tạo ra cho mỗi kết hợp ý định và từ ý định. Mặc dù IWP tạo ra dữ liệu tổng hợp tốt, nó bị hạn chế bởi thực tế là các từ cùng xuất hiện ít thường xuyên với ý định ít liên quan đến ý định. Những ví dụ như vậy được tạo ra với các từ ý định ít liên quan có thể không được phân loại dưới lớp ý định mong muốn. Điều này cũng hạn chế lượng dữ liệu tổng hợp có thể được tạo ra vì LLM không thể tạo ra nhiều ví dụ duy nhất sử dụng một số lượng nhỏ các kết hợp ý định-từ ý định.

Bạn đang làm việc trong một khung ý định-và-slot nơi mọi phát ngôn có thể được phân loại dưới một ý định. Dưới đây là một số ví dụ về ý định và mô tả chức năng của chúng:
1. IN:ADD TIME TIMER - Tạo bộ đếm thời gian mới
2. IN:GET ESTIMATED DEPARTURE - nhận thời gian khởi hành ước tính
Bây giờ, chúng tôi muốn phân loại ý định cho ứng dụng thời tiết. Với ý định IN:GET WEATHER, tạo ra 40 phát ngôn được phân loại dưới ý định này. Bạn có thể sử dụng từ "weather" cùng với tên của người và nơi chốn để tạo ra 40 phát ngôn. Phản hồi của bạn nên có các phát ngôn được đánh số, với một phát ngôn trên mỗi dòng. Đảm bảo không lặp lại bất kỳ phản hồi nào. Bắt đầu với 1.

Hình 2. Thúc đẩy cho tạo phát ngôn dựa trên IWP

--- TRANG 3 ---
Tạo thêm 60 câu tương tự về ý định với các câu sau:
1. Liệu có khoảng 95 độ Fahrenheit ở san francisco ngày mai không
2. Liệu có khoảng 72 độ celsius ở karachi tối nay không
Viết một câu trên mỗi dòng. Tạo ra các câu phát biểu và câu hỏi với cấu trúc câu khác nhau.

Hình 3. Thúc đẩy cho tạo phát ngôn dựa trên EP

Mỗi câu nên được đặt trong dấu ngoặc vuông [ ]. Dấu ngoặc vuông đầu tiên [ nên được theo sau bởi một ý định viết hoa và bắt đầu bằng IN:, ví dụ, IN:GET WEATHER. Bên trong câu, bạn nên gắn nhãn một số danh từ với các slot, cũng được đặt trong dấu ngoặc vuông [ ]. Các slot được viết hoa hoàn toàn và bắt đầu bằng SL:, ví dụ, SL:LOCATION. Trong mỗi câu, chỉ có thể có 1 ý định, nhưng có thể có nhiều slot. Dưới đây là một số ví dụ:
1. [IN:GET WEATHER thời tiết ở [SL:LOCATION paris ] như thế nào ]
2. [IN:GET WEATHER nhiệt độ ở [SL:LOCATION cực bắc ] là bao nhiêu ]
3. [IN:GET WEATHER cho tôi biết thời tiết ở [SL:LOCATION central park ] như thế nào ]
Hãy tạo thêm ví dụ với ý định IN:GET WEATHER và bất kỳ slot nào là SL:LOCATION. Các câu nên có định dạng ý định/slot như [IN:GET WEATHER [SL:LOCATION] ], nhưng với một số văn bản khác, như các ví dụ trên. Viết 30 câu tương tự và sau đó dừng lại.
Sử dụng tên của người và nơi chốn trong các ví dụ của bạn.

Hình 4. Thúc đẩy cho tạo phân tích seqlogical dựa trên EP

Thúc đẩy dựa trên Mẫu (EP): Vì LLM mạnh trong việc học theo ngữ cảnh [26], một cách tiếp cận thay thế là thúc đẩy LLM để tạo ra bản chép dựa trên các ví dụ. Đối với mỗi kết hợp ý định-slot, chúng tôi cung cấp tối đa 4 bản chép ví dụ ngẫu nhiên và yêu cầu mô hình tạo ra thêm 60 bản chép tương tự nhưng có cấu trúc câu đa dạng. Một ví dụ thúc đẩy được hiển thị trong Hình 3. Mặc dù các bản chép kết quả có thể không luôn tương ứng với các lớp ý định mà các ví dụ được rút ra, phương pháp này cho phép chúng tôi tạo ra khối lượng dữ liệu lớn hơn mà không trùng lặp.

Tạo Phân tích Cú pháp Ngữ nghĩa và Đánh giá Chất lượng: Bản chép được tạo ra bởi LLM đầu tiên được chuẩn hóa – văn bản viết được chuyển đổi thành dạng nói, dấu câu trừ dấu nháy đơn được loại bỏ và văn bản được chuyển đổi thành chữ thường. Nhãn giả phân tích cú pháp ngữ nghĩa được thu được từ các bản chép chuẩn hóa này sử dụng một bộ phân tích cú pháp ngữ nghĩa mạnh dựa trên RoBERTa được huấn luyện trên STOP (EM=86.8). Để đánh giá chất lượng dữ liệu, chúng tôi so sánh ý định trong các nhãn giả thu được với ý định trong thúc đẩy cho IWP hoặc ý định của các ví dụ được cung cấp cho EP. Độ chính xác khớp ý định (IMA) được định nghĩa là tỷ lệ phần trăm các lần ý định của nhãn giả khớp với ý định mong muốn của thúc đẩy.

4.2. Tạo Bản chép-Phân tích Cú pháp Ngữ nghĩa cho Miền Mới
Đối với các miền mới, dữ liệu ghép đôi và các mô hình đã được huấn luyện trước không có sẵn, và do đó, chúng tôi sẽ cần tạo ra trực tiếp các cặp bản chép và phân tích cú pháp ngữ nghĩa. Một cách để làm điều này là tạo ra các cặp phân tích cú pháp ngữ nghĩa và bản chép tương ứng sử dụng LLM trực tiếp, tuy nhiên, việc duy trì tính nhất quán giữa các phân tích và bản chép được tạo ra là thách thức đối với LLM hiện tại. Một giải pháp thay thế khác là chỉ tạo ra dạng seqlogical của phân tích cú pháp ngữ nghĩa từ LLM và suy ra bản chép từ phân tích. Dạng seqlogical của phân tích, không giống như dạng tách rời, bao gồm tất cả các từ trong bản chép cùng với các thẻ slot và ý định. Do đó, bản chép có thể được thu được từ phân tích seqlogical chỉ bằng cách loại bỏ các thẻ slot và ý định.

Thúc đẩy dựa trên Mẫu: Chúng tôi giả định rằng (a) các ý định và slot phải được nhận dạng cho miền mới được biết, (b) các slot có thể xuất hiện với mỗi ý định, tức là các kết hợp ý định-slot được biết, và (c) một số ví dụ được chú thích thủ công cho mỗi kết hợp ý định-slot được biết. Sử dụng thông tin này, LLM có thể được thúc đẩy như được hiển thị trong Hình 4 để tạo ra các phân tích seqlogical mới cho một kết hợp ý định-slot đã cho. Thúc đẩy đầu tiên mô tả các bước để tạo ra một phân tích seqlogical hợp lệ và sau đó trình bày tối đa 3 ví dụ về phân tích seqlogical với các kết hợp ý định-slot mong muốn.

Hậu xử lý: Các phân tích seqlogical được tạo ra được kiểm tra để phát hiện vị trí không hợp lệ của dấu ngoặc vuông, và các ý định và slot Ngoài từ vựng (OOV). Các ý định OOV được sửa chữa bằng cách thúc đẩy lại mô hình để thay thế các ý định OOV bằng các ý định chính xác và thay thế bất kỳ ý định nào khác ngoài ý định đầu tiên. Bất kỳ slot OOV nào được loại bỏ trong khi giữ lại các từ slot tương ứng.

5. THIẾT LẬP THÍ NGHIỆM
5.1. Dữ liệu STOP, Mô hình và Độ đo
Dữ liệu: STOP [27] là một tập dữ liệu công khai với giọng nói thực cho phân tích cú pháp ngữ nghĩa nói. STOP có dữ liệu cho 8 miền - báo thức, sự kiện, nhắn tin, âm nhạc, điều hướng, nhắc nhở, bộ đếm thời gian và thời tiết. Dữ liệu chứa 28 ý định duy nhất và 82 loại slot.

Độ đo: Exact Match (EM) được sử dụng để đánh giá tất cả các mô hình của chúng tôi. Chúng tôi báo cáo EM (No Err) và EM w/ Err, đó là độ chính xác Exact Match được tính trung bình trên các phát ngôn không có lỗi ASR và được tính trung bình trên các phát ngôn có bất kỳ lỗi ASR nào tương ứng.

Cấu hình Mô hình: Đối với mô-đun ASR, chúng tôi sử dụng RNNT với 3 lớp conformer trong bộ mã hóa, 1 lớp LSTM trong bộ dự đoán, và 1 lớp tuyến tính trong bộ kết hợp. Đối với mô hình thảo luận, chúng tôi sử dụng attention trong mô-đun Fusion, 2 lớp mã hóa transformer trong mô-đun Pooling, và một lớp giải mã transformer với bộ tạo con trỏ trong mô-đun Decoder [16]. Các mô hình được tối ưu hóa với Adam [28], có tỷ lệ học tối đa 8e-3.

5.2. Thiết lập: Dữ liệu Văn bản từ Tập dữ liệu Văn bản
Đối với các thí nghiệm nơi chúng tôi giả định dữ liệu văn bản có sẵn, chúng tôi chia tập dữ liệu STOP thành hai phần. Chúng tôi thực hiện hai thí nghiệm – một sử dụng phần thứ nhất và thứ hai làm dữ liệu ghép đôi và không ghép đôi tương ứng và cái khác sử dụng phần thứ hai và thứ nhất làm dữ liệu ghép đôi và không ghép đôi tương ứng. Hiệu suất trung bình trên 2 thí nghiệm này được báo cáo trong mỗi trường hợp. Trong thiết lập ED, lượng dữ liệu bằng nhau từ mỗi miền có mặt trong hai phần. Đối với thiết lập ND, STOP được chia theo miền, nơi một phần chứa tất cả dữ liệu huấn luyện từ 4 miền (nhắn tin, nhắc nhở, thời gian và thời tiết), trong khi phần kia chứa dữ liệu huấn luyện từ 4 miền khác (báo thức, sự kiện, âm nhạc và điều hướng). Cả hai phần được thiết kế để đảm bảo rằng chúng có số lượng phát ngôn gần bằng nhau.

5.3. Thiết lập: Dữ liệu Văn bản từ LLM
Khi dữ liệu không ghép đôi không có sẵn, chúng tôi sử dụng Llama 2.0 để tạo ra các ví dụ cho thiết lập ED và ND. Đối với thiết lập ED, LLama 2.0 được sử dụng để tạo ra các phát ngôn. Sau đó chúng tôi sử dụng một mô hình RoBERTa 12 lớp đã được huấn luyện trước được huấn luyện trên STOP để tạo ra nhãn giả cho các phát ngôn được tạo ra. Chúng tôi tăng cường STOP với bản chép-phân tích cú pháp ngữ nghĩa được tạo ra bởi LLama 2.0. JAT được sử dụng để biểu diễn văn bản LLama 2.

--- TRANG 4 ---
Đối với thiết lập ND, dữ liệu được tạo ra bởi LLama 2.0 không phù hợp làm tập kiểm tra thực sự vì nó không có giọng nói thực phù hợp. Do đó, chúng tôi chọn phân vùng dữ liệu STOP hiện có thành 7 miền đã thấy và 1 miền mới - thời tiết. Chúng tôi sử dụng thúc đẩy dựa trên mẫu để tạo ra các cặp bản chép-phân tích cú pháp ngữ nghĩa cho thời tiết. Đối với điều này, các ví dụ thực về bản chép-phân tích cú pháp ngữ nghĩa từ STOP được sử dụng. Chúng tôi sử dụng TTS để tạo ra biểu diễn giọng nói tương đương cho dữ liệu được tạo ra. Chúng tôi so sánh hiệu suất trên miền thời tiết cho các mô hình được huấn luyện trên (a) 7 miền của STOP, (b) 7 miền của STOP với các ví dụ cho thời tiết (với TTS cho các ví dụ và giọng nói thực cho 7 miền), (c) 7 miền của STOP với các ví dụ và dữ liệu được tạo ra bởi Llama 2.0, và (d) đường chuẩn trên sử dụng 7 miền của STOP với dữ liệu thực và TTS.

6. THÍ NGHIỆM
6.1. Khi dữ liệu văn bản có sẵn
Bảng 1 so sánh hiệu suất của các mô hình khác nhau cho thiết lập ED và ND nơi văn bản không ghép đôi được rút ra từ các miền hiện có và miền mới tương ứng. Trên cả thiết lập ED và ND, chúng tôi thấy rằng việc sử dụng văn bản không ghép đôi cải thiện điểm số EM.

Đối với thiết lập ED, chúng tôi thấy rằng JAT và TTS đạt điểm số Exact Match tương tự. Vì JAT có hiệu suất tương đương với TTS và tương đối không tốn kém so với các mô hình TTS phức tạp như Voicebox, JAT là tối ưu cho thiết lập ED. Hơn nữa, sự khác biệt giữa JAT và TTS dường như chủ yếu trên các phát ngôn có lỗi ASR, vì biểu diễn giọng nói tổng hợp có thể được sử dụng để giảm tác động của lỗi ASR lên phân tích cú pháp ngữ nghĩa. Đối với thiết lập ND, chúng tôi thấy rằng mặc dù JAT vượt trội so với đường cơ sở, TTS vượt trội so với JAT. Điều này là do các miền mới có thể có các thực thể khác nhau và các thuật ngữ đặc trưng cho miền có thể khó nhận dạng hơn, và TTS cung cấp biểu diễn giọng nói hợp lệ có thể được sử dụng để cải thiện dự đoán dựa trên ASR lượt đầu. Hình 5 cho thấy rằng lượng dữ liệu văn bản không ghép đôi được tăng với dữ liệu ghép đôi không đổi, lợi ích tương đối tăng đến một điểm và bão hòa.

Bảng 1. So sánh JAT và TTS như biểu diễn giọng nói cho văn bản không ghép đôi từ ED và ND. Số lượng phát ngôn ghép đôi và không ghép đôi, và Exact Match (EM) được báo cáo

[Bảng dữ liệu hiệu suất]

6.2. Dữ liệu được tạo ra bởi LLama 2.0: Thiết lập ED
Bảng 2 so sánh các chiến lược thúc đẩy khác nhau để tạo ra phát ngôn trong cùng miền sử dụng Llama 2.0. Chúng tôi thấy rằng kết hợp dữ liệu được tạo ra bởi LLama với dữ liệu STOP hiện có có thể cải thiện hiệu suất trên các ví dụ kiểm tra có và không có lỗi ASR. Khi phân tích sâu hơn, chúng tôi thấy rằng cải thiện đáng kể được quan sát trên các miền có hiệu suất tương đối kém trong đường cơ sở STOP. Giữa IWP và EP, chúng tôi thấy rằng EP hơi tốt hơn. Vì EP không bị hạn chế để tạo ra các phát ngôn có thể được phân loại dưới một ý định đã cho, Độ chính xác Khớp Ý định (IMA) thấp hơn so với IWP. Kết hợp dữ liệu được tạo ra từ cả hai chiến lược này cải thiện hiệu suất hơn nữa so với đường cơ sở STOP.

Hình 5. Tác động của việc tăng văn bản không ghép đôi lên EM

Bảng 2. Đánh giá tác động của việc tăng cường dữ liệu huấn luyện với các phát ngôn được tạo ra bởi LLama 2.0 và nhãn giả RoBERTa. EM là Độ chính xác Exact Match

[Bảng dữ liệu hiệu suất]

6.3. Dữ liệu được tạo ra bởi LLama 2.0: Thiết lập ND
Bảng 3. Sử dụng TTS để tạo ra giọng nói cho văn bản LLama 2.0 khi văn bản không ghép đôi ở trong miền mới chưa thấy

[Bảng dữ liệu hiệu suất]

Bảng 3 so sánh hiệu suất của các mô hình cơ sở không có dữ liệu cho thời tiết hoặc 360 ví dụ cho thời tiết với các mô hình sử dụng dữ liệu được tạo ra bởi LLama 2.0. Văn bản được tạo ra bởi Llama 2 có thể cải thiện hiệu suất hơn 2 điểm tuyệt đối EM nhưng chậm hơn so với hiệu suất của đường chuẩn trên sử dụng dữ liệu từ STOP.

7. KẾT LUẬN
Chúng tôi giải quyết chi phí cao của việc gắn nhãn thủ công dữ liệu giọng nói-bản chép-phân tích cú pháp ngữ nghĩa cho phân tích cú pháp ngữ nghĩa nói bằng cách cho phép các mô hình sử dụng dữ liệu chỉ có văn bản. JAT được ưu tiên cho văn bản không ghép đôi trong các miền hiện có vì hiệu quả và lợi ích 2.5% EM so với đường cơ sở dữ liệu ghép đôi trong khi vẫn trong vòng 0.1% EM của TTS tốn kém tính toán hơn. Đối với văn bản không ghép đôi trong các miền mới, TTS vượt trội so với JAT 6% tuyệt đối EM tổng thể, với lợi ích 30.6% EM so với đường cơ sở ghép đôi. Khi dữ liệu văn bản không thể được thu thập từ các tập dữ liệu văn bản hiện có, chúng tôi đề xuất thúc đẩy LLM để tạo ra các cặp bản chép-phân tích cú pháp ngữ nghĩa. Chúng tôi cho thấy rằng sử dụng các chiến lược thúc đẩy khác nhau, chúng tôi có thể tạo ra dữ liệu văn bản không ghép đôi với khối lượng tương đối lớn. Sử dụng JAT và TTS, chúng tôi có thể tận dụng dữ liệu được tạo ra bởi LLM này để cải thiện SSP thêm 1.4% EM và 2.6% EM tuyệt đối cho các miền hiện có và mới.

--- TRANG 5 ---
8. TÀI LIỆU THAM KHẢO
[1] S. Wang, A. Shrivastava, và S. Livshits, Treepiece: Phân tích cú pháp ngữ nghĩa nhanh hơn thông qua tokenization cây, 2023.
[2] S. Arora, H. Futami, S.-L. Wu, J. Huynh, Y. Peng, Y. Kashiwagi, E. Tsunoo, B. Yan, và S. Watanabe, "Một nghiên cứu về tích hợp các hệ thống pipeline và e2e slu cho phân tích cú pháp ngữ nghĩa nói hướng tới thách thức chất lượng stop," trong Proc. ICASSP, 2023, pp. 1–2.
[3] H. Futami, J. Huynh, S. Arora, S.-L. Wu, Y. Kashiwagi, Y. Peng, B. Yan, E. Tsunoo, và S. Watanabe, "Hệ thống pipeline của asr và nlu với tăng cường dữ liệu dựa trên mlm hướng tới thách thức tài nguyên thấp stop," trong Proc. ICASSP, 2023, pp. 1–2.
[4] D. Le, A. Shrivastava, P. Tomasello, S. Kim, A. Livshits, O. Kalinli, và M. L. Seltzer, "Mô hình thảo luận cho hiểu biết ngôn ngữ nói trên thiết bị," Interspeech, 2022.
[5] G. Wang, A. Rosenberg, Z. Chen, Y. Zhang, B. Ramabhadran, Y. Wu, và P. Moreno, "Cải thiện nhận dạng giọng nói bằng cách sử dụng dự đoán nhất quán trên giọng nói tổng hợp," trong Proc. ICASSP, 2020, pp. 7029–7033.
[6] S. Toshniwal, A. Kannan, C.-C. Chiu, Y. Wu, T. N. Sainath, và K. Livescu, "So sánh các kỹ thuật tích hợp mô hình ngôn ngữ trong nhận dạng giọng nói encoder-decoder," trong 2018 IEEE spoken language technology workshop (SLT), 2018, pp. 369–375.
[7] T. Hori, R. Astudillo, T. Hayashi, Y. Zhang, S. Watanabe, và J. Le Roux, "Huấn luyện tính nhất quán chu kỳ cho nhận dạng giọng nói đầu cuối đến cuối," trong Proc. ICASSP, 2019, pp. 6271–6275.
[8] Z. Meng, Y. Gaur, N. Kanda, J. Li, X. Chen, Y. Wu, và Y. Gong, "Thích ứng Mô hình Ngôn ngữ Nội bộ với Dữ liệu Chỉ có Văn bản cho Nhận dạng Giọng nói Đầu cuối đến Cuối," trong Proc. Interspeech, 2022, pp. 2608–2612.
[9] Z. Chen, Y. Zhang, A. Rosenberg, B. Ramabhadran, P. J. Moreno, A. Bapna, và H. Zen, "MAESTRO: Biểu diễn Văn bản Giọng nói Khớp thông qua Khớp Phương thức," trong Proc. Interspeech, 2022, pp. 4093–4097.
[10] T. N. Sainath, R. Prabhavalkar, A. Bapna, Y. Zhang, Z. Huo, Z. Chen, B. Li, W. Wang, và T. Strohman, "Joist: Một mô hình streaming chung cho giọng nói và văn bản cho asr," trong Proc. SLT, 2023, pp. 52–59.
[11] S. Kim, K. Li, L. Kabela, R. Huang, J. Zhu, O. Kalinli, và D. Le, "Huấn luyện âm thanh/văn bản chung cho bộ chấm điểm lại transformer của nhận dạng giọng nói streaming," EMNLP, 2022.
[12] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al., "Huấn luyện mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi của con người," Advances in Neural Information Processing Systems, vol. 35, pp. 27730–27744, 2022.
[13] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al., "Llama: Mô hình ngôn ngữ nền tảng mở và hiệu quả," arXiv preprint arXiv:2302.13971, 2023.
[14] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al., "Llama 2: Mô hình nền tảng mở và chat được tinh chỉnh," arXiv preprint arXiv:2307.09288, 2023.
[15] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, và V. Stoyanov, RoBERTa: Một cách tiếp cận huấn luyện trước BERT được tối ưu hóa mạnh mẽ, 2020.
[16] S. Kim, A. Shrivastava, D. Le, J. Lin, O. Kalinli, và M. L. Seltzer, "Huấn luyện nhận thức về độ tin cậy phương thức cho hiểu biết ngôn ngữ nói đầu cuối đến cuối mạnh mẽ," Interspeech, 2023.
[17] A. Graves, "Chuyển đổi chuỗi với mạng thần kinh hồi quy," arXiv preprint arXiv:1211.3711, 2012.
[18] S. Kim, Y. Shangguan, J. Mahadeokar, A. Bruguier, C. Fuegen, M. L. Seltzer, và D. Le, "Cải thiện việc hợp nhất mô hình ngôn ngữ thần kinh cho bộ chuyển đổi mạng thần kinh hồi quy streaming," trong Proc. ICASSP, 2021, pp. 7333–7337.
[19] C. Liu, F. Zhang, D. Le, S. Kim, Y. Saraf, và G. Zweig, "Cải thiện ASR dựa trên RNN Transducer với Nhiệm vụ Phụ trợ," trong Proc. SLT, 2021.
[20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, và I. Polosukhin, "Attention is all you need," 2017.
[21] T. N. Sainath, R. Pang, R. J. Weiss, Y. He, C.-c. Chiu, và T. Strohman, "Một mô hình đầu cuối đến cuối âm thanh và văn bản chung dựa trên attention trên thiết bị," trong Proc. ICASSP, 2020, pp. 7039–7043.
[22] P. Wang, T. N. Sainath, và R. J. Weiss, "Huấn luyện đa nhiệm vụ với dữ liệu văn bản cho nhận dạng giọng nói đầu cuối đến cuối," arXiv preprint arXiv:2010.14318, 2020.
[23] M. Le, A. Vyas, B. Shi, B. Karrer, L. Sari, R. Moritz, M. Williamson, V. Manohar, Y. Adi, J. Mahadeokar, et al., "Voicebox: Tạo giọng nói đa ngôn ngữ phổ quát có hướng dẫn văn bản ở quy mô," arXiv preprint arXiv:2306.15687, 2023.
[24] Y. Lipman, R. T. Chen, H. Ben-Hamu, M. Nickel, và M. Le, "Flow matching cho mô hình hóa tạo sinh," arXiv preprint arXiv:2210.02747, 2022.
[25] J. Kong, J. Kim, và J. Bae, "Hifi-gan: Mạng đối kháng tạo sinh cho tổng hợp giọng nói hiệu quả và chất lượng cao," Advances in Neural Information Processing Systems, vol. 33, pp. 17022–17033, 2020.
[26] J. Wei et al., "Khả năng nổi lên của mô hình ngôn ngữ lớn," Transactions on Machine Learning Research, 2022, Survey Certification.
[27] P. Tomasello, A. Shrivastava, D. Lazar, P.-C. Hsu, D. Le, A. Sagar, A. Elkahky, J. Copet, W.-N. Hsu, Y. Adi, et al., "Stop: Một tập dữ liệu cho phân tích cú pháp ngữ nghĩa hướng nhiệm vụ nói," trong Proc. SLT, 2023, pp. 991–998.
[28] D. P. Kingma và J. Ba, "Adam: Một phương pháp tối ưu hóa ngẫu nhiên," trong Proc. ICLR, Y. Bengio và Y. LeCun, Eds., 2015.

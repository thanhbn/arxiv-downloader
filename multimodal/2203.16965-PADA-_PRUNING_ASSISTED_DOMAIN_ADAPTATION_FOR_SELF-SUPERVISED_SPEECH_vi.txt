# 2203.16965.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2203.16965.pdf
# Kích thước tệp: 1463533 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
PADA: PRUNING ASSISTED DOMAIN ADAPTATION FOR SELF-SUPERVISED SPEECH
REPRESENTATIONS
Vasista Sai Lodagala1, Sreyan Ghosh2, S. Umesh1
1Viện Công nghệ Ấn Độ, Madras
2Đại học Maryland, College Park
TÓM TẮT
Trong khi các mô hình học biểu diễn giọng nói tự giám sát (SSL) phục vụ nhiều tác vụ downstream khác nhau, các mô hình này đã được quan sát là overfitting với miền mà dữ liệu không nhãn có nguồn gốc từ đó. Để giảm thiểu vấn đề này, chúng tôi đề xuất PADA (Pruning Assisted Domain Adaptation). Trước khi thực hiện fine-tuning ASR miền đích, chúng tôi khám phá các trọng số dư thừa từ các mô hình wav2vec 2.0 đã được tiền huấn luyện thông qua các chiến lược pruning khác nhau. Chúng tôi nghiên cứu hiệu ứng của Task-Agnostic và Task-Aware pruning và đề xuất một mô hình pruning mới được gọi là Cross-Domain Task-Aware Pruning (CD-TAW). CD-TAW thu được mask pruning ban đầu từ một mô hình ngoài miền (OOD) đã được fine-tune tốt, do đó tận dụng các mô hình đã được fine-tune sẵn có từ web. Phương pháp CD-TAW được đề xuất đạt được cải thiện WER tương đối lên đến 20.6% so với baseline của chúng tôi khi được fine-tune trên tập con 2 giờ của dữ liệu Switchboard mà không có giải mã mô hình ngôn ngữ (LM).
Thuật ngữ chỉ mục —thích ứng miền, pruning, học tự giám sát, nhận dạng giọng nói tự động, giọng nói điện thoại

1. GIỚI THIỆU
Trong thập kỷ qua, Nhận dạng Giọng nói Tự động (ASR) đã thu hút sự chú ý của các nhà nghiên cứu từ nhiều lĩnh vực khác nhau do các ứng dụng tiềm năng của nó trong các hệ thống Hiểu Ngôn ngữ Tự nhiên (NLU) khác nhau có giọng nói là phương thức giao tiếp chính [1, 2, 3, 4]. Sự ra đời của Mạng Neural Sâu (DNN) đã đẩy mạnh nghệ thuật hiện đại (SOTA) trong nhận dạng giọng nói trong nhiều thiết lập khác nhau [5, 6]. Tuy nhiên, DNN tiêu tốn nhiều tài nguyên, và việc xây dựng các hệ thống ASR hiệu quả đòi hỏi rất nhiều tính toán và giám sát dưới dạng dữ liệu có nhãn. Do đó, các phương pháp Học Tự Giám sát (SSL) gần đây [6, 7, 8, 9] có thể học biểu diễn trực tiếp từ dữ liệu âm thanh không nhãn, đã và đang thu hút nhiều sự chú ý. Mục tiêu chính của SSL là sử dụng giọng nói thô [6], hoặc các đặc trưng cấp thấp khác như Filter Banks [10], để học các biểu diễn cấp cao chứng minh hiệu quả trong các tác vụ xử lý giọng nói downstream khác. SSL đã cho thấy những cải thiện hiệu suất đáng kể trong việc xây dựng các hệ thống ASR, đặc biệt trong các thiết lập mà dữ liệu có nhãn khan hiếm (thấp đến 10 phút), và đã được biết đến là tổng quát hóa tốt hơn so với học có giám sát.

Tuy nhiên, một số nghiên cứu gần đây đã làm nổi bật những nhược điểm của SSL. Thứ nhất, các tác vụ pretext mà hệ thống phải giải quyết dưới mô hình SSL là tính toán chuyên sâu [6] và đòi hỏi rất nhiều dữ liệu không nhãn. Thứ hai, một nghiên cứu gần đây tiết lộ rằng tương tự như học có giám sát, SSL cũng bị thiên vị đối với miền mà dữ liệu không nhãn có nguồn gốc từ đó [11]. Thứ ba, vì SSL ngầm học một mô hình ngôn ngữ và thông tin ngữ nghĩa khác thông qua các tác vụ mà nó phải giải quyết [12], khả năng tổng quát hóa của các mô hình này chỉ đến mức độ mà dữ liệu từ ngôn ngữ hoặc cấu trúc ngữ âm tương tự được giới thiệu cho nó ở giai đoạn fine-tuning. Do đó, như đã được chỉ ra chính xác bởi [13], SSL cho giọng nói gặp phải các vấn đề về quy mô, và khả năng tổng quát hóa SSL có thể được cải thiện với các quy trình huấn luyện hiệu quả hơn. Công trình trước đây về thích ứng miền với các mô hình tự giám sát chủ yếu sử dụng các phương pháp tiếp tục tiền huấn luyện hoặc kết hợp dữ liệu tiền huấn luyện [11]. Tuy nhiên, cả hai đều giả định sự tồn tại của dữ liệu miền đích không nhãn tài nguyên cao, điều này không phải lúc nào cũng có trong kịch bản thực tế (ví dụ, giọng nói đàm thoại qua điện thoại rất khó thu thập do các vấn đề về quyền riêng tư và không có nhiều hơn 1000 giờ có sẵn miễn phí trực tuyến).

Dựa trên vấn đề thứ hai và thứ ba được đề cập ở trên, trong bài báo này, chúng tôi cố gắng giải quyết vấn đề thiên vị miền trong các mô hình SSL đã được tiền huấn luyện và cố gắng thiết kế một thuật toán, có thể cho phép các mô hình đã được tiền huấn luyện trên dữ liệu OOD dễ dàng thích ứng với miền đích và với hiệu suất được cải thiện, chỉ sử dụng dữ liệu Trong-Miền có giám sát. Để đạt được mục tiêu này, chúng tôi nhận sự trợ giúp từ Unstructured Magnitude Pruning (UMP), trong đó chúng tôi chọn các tham số mô hình có "độ lớn nhỏ nhất", mà chúng tôi giả thuyết là có "tầm quan trọng ít nhất" đối với miền, và đề xuất đặt chúng bằng không để các trọng số quan trọng cho tác vụ downstream sẽ xuất hiện với các cập nhật gradient, và những trọng số không liên quan sẽ giảm về độ lớn. Điều này đã được chứng minh thực nghiệm lần đầu tiên trong [14]. Các tham số được đặt bằng không cũng được giữ có thể huấn luyện, điều này làm cho nó khác với pruning DNN thông thường, nơi mà mask pruning không cho phép cập nhật gradient. Thêm chi tiết về các chiến lược pruning khác nhau có thể được tìm thấy trong Alg.1. Chúng tôi được thúc đẩy bởi các phát hiện từ Lottery Ticket Hypothesis [15], gợi ý rằng một mạng được khởi tạo ngẫu nhiên chứa các mạng con thưa thớt có thể được huấn luyện riêng biệt để khớp với kết quả của mô hình đầy đủ. Ngoài ra, [16] khám phá pruning cho thích ứng ngôn ngữ đơn ngữ trong các mô hình đa ngữ đã được tiền huấn luyện. Để tóm tắt, những đóng góp chính của chúng tôi như sau:

• Chúng tôi phân tích hiệu suất của các chiến lược và tần suất pruning khác nhau cho thích ứng miền trên các mô hình SSL giọng nói đã được tiền huấn luyện. Chúng tôi dựa các thí nghiệm của mình trên giả định thực tế rằng chỉ có một lượng hạn chế dữ liệu có nhãn miền đích có sẵn, và không có corpus không nhãn quy mô lớn nào khác có sẵn từ miền đích.

• Chúng tôi đề xuất Cross-Domain Task-Aware pruning (CD-TAW), một phương pháp đầu tiên trong loại hình của nó sử dụng các mô hình có sẵn đã được fine-tune trên dữ liệu OOD có nhãn tài nguyên cao để thu được mask pruning ban đầu liên quan đến tác vụ ASR downstream. Kết quả thí nghiệm tiết lộ rằng CD-TAW hoạt động tốt hơn so với fine-tuning thông thường, TAG, và các phương pháp TAW.

2. CÔNG TRÌNH LIÊN QUAN

2.1. Học Biểu diễn Giọng nói Tự Giám sát
SSL cho học biểu diễn giọng nói đã được khám phá chủ yếu dưới 3 mô hình chính, mỗi mô hình giải quyết một dạng của Masked Acoustic Modelling (MAM). Mô hình đầu tiên và phổ biến nhất trong không gian này dựa trên Contrastive Predictive Coding (CPC), tối thiểu hóa loss InfoNCE [17, 6]. Mô hình thứ hai học bằng cách tối thiểu hóa loss Cross-Entropy, trong đó tác vụ chính là dự đoán pseudo-label chính xác được gán cho một frame, được che ở đầu vào của mô hình, tận dụng embedding ngữ cảnh hóa của frame đó thu được từ một bộ mã hóa transformer [8, 9]. Mô hình thứ ba và cuối cùng giải quyết hàm mục tiêu dựa trên tái tạo [10, 18].

2.2. Pruning
Khái niệm pruning DNN đã được nghiên cứu rộng rãi trong quá khứ [15, 19, 20]. Các tác giả của [21] cho thấy rằng các mô hình thưa thớt lớn thu được thông qua pruning thường hoạt động tốt hơn khi so sánh với các mô hình nhỏ hơn nhưng dày đặc. Một trong những công trình đầu tiên đề xuất pruning cho thích ứng miền là của [22]. Tuy nhiên, họ đề xuất một phương pháp hoàn toàn khác sử dụng knowledge distillation và sử dụng nó cho Neural Machine Translation (NMT) dựa trên văn bản. [16] đề xuất một phương pháp pruning để cải thiện hiệu suất ASR đơn ngữ trong các mô hình SSL đa ngữ đã được tiền huấn luyện. Các tác giả của PARP [14] đề xuất công trình đầu tiên về pruning các mô hình giọng nói tự giám sát tiền huấn luyện lớn. Họ có ý định tìm một mạng con thưa thớt đã được fine-tune ở một mức độ thưa thớt mục tiêu nào đó, với hiệu suất được cải thiện hơn so với việc sử dụng mô hình đầy đủ. Tuy nhiên, công việc của chúng tôi khác với họ chủ yếu từ góc độ tác vụ cuối cùng mà chúng tôi cố gắng giải quyết. Chúng tôi tiếp cận UMP lặp [15] từ góc độ thích ứng miền và thiết kế thuật toán của chúng tôi bằng cách đưa ra giả thuyết tương ứng. Mục tiêu cuối cùng của chúng tôi là thích ứng mô hình SSL đã được tiền huấn luyện với miền đích, và trọng tâm không phải là thu được một mô hình thưa thớt. Một sự khác biệt chính với PARP là các chiến lược pruning task-aware của chúng tôi hoạt động tốt hơn cho thích ứng miền. Đồng thời, PARP sử dụng các chiến lược pruning task-agnostic vì họ không quan sát sự khác biệt lớn giữa hai phương pháp, vì họ fine-tune trên dữ liệu từ cùng miền với dữ liệu không nhãn của mô hình đã được tiền huấn luyện. Một sự khác biệt chính khác với PARP là, trong khi họ tăng dần tỷ lệ pruning để đạt được độ thưa thớt mục tiêu trong PARP-P, chúng tôi giảm dần tỷ lệ pruning một cách động để thích ứng miền tốt hơn như được giải thích trong Phần 3.2.4.

2.3. Thích ứng Miền
Thích ứng Miền (DA) để xây dựng các hệ thống ASR hiệu quả đã là một chủ đề được nghiên cứu kỹ trong tài liệu, với công việc sớm tập trung vào regularization [23, 24], học teacher-student, [25, 26] hoặc học adversarial [27, 28]. Gần đây, thích ứng miền không giám sát của các mô hình ASR đã thu hút sự chú ý, và các nhà nghiên cứu đã cố gắng tìm cách sử dụng lượng lớn dữ liệu không nhãn từ miền đích cho thích ứng miền [26, 29, 30]. Tiếp tục tiền huấn luyện là một phương pháp phổ biến khác được sử dụng [31]. Chúng tôi nhấn mạnh rằng công việc của chúng tôi là một trong những công việc đầu tiên tiếp cận thích ứng miền từ góc độ pruning, không liên quan đến tiếp tục tiền huấn luyện hoặc dữ liệu không nhãn OOD.

--- TRANG 3 ---
3. PHƯƠNG PHÁP ĐỀ XUẤT

3.1. Công thức Vấn đề
Giả sử chúng ta có một tập dữ liệu không nhãn OOD tài nguyên cao P và một tập dữ liệu có nhãn OOD tài nguyên trung bình đến cao J, cả hai từ miền D1. Chúng ta cũng có một tập dữ liệu có nhãn tài nguyên thấp L. Gọi p() là mạng neural được tiền huấn luyện sử dụng tự giám sát trên tập dữ liệu P từ miền D1 và gọi f(j) đại diện cho mạng neural kết quả sau khi fine-tuning ASR dựa trên CTC đã được thực hiện trên p() trên tập dữ liệu J từ miền D1, sao cho j ∈ Rd, đại diện cho d số tham số mạng. Như một phần của công việc này, các mô hình p() và f(j) mà chúng tôi sử dụng được cung cấp trong lĩnh vực công cộng thông qua các công trình về wav2vec-2.0 và fairseq [6, 32].

Mục tiêu chính của chúng tôi là thích ứng mô hình p() của chúng tôi với miền D2 chỉ bằng cách sử dụng tập dữ liệu tài nguyên thấp L, với hiệu suất tốt hơn so với fine-tuning thông thường của p() trên L. Chúng tôi đạt được mục tiêu này bằng cách xác định các trọng số có tầm quan trọng ít nhất và đặt chúng bằng không. Các trọng số liên quan cho tác vụ ASR downstream trên L sẽ xuất hiện với các cập nhật gradient, và những trọng số không liên quan được đặt bằng không để tạo điều kiện cho việc thích ứng mô hình tốt hơn. Vì chúng tôi nhằm mục đích có được một mô hình mang lại hiệu suất tốt hơn mà không tập trung vào việc đạt được độ thưa thớt mục tiêu, các trọng số đã được đặt bằng không vẫn có thể huấn luyện trên L, do đó tận dụng toàn bộ dung lượng mô hình.

3.2. Thích ứng Miền Được Hỗ trợ bởi Pruning (PADA)
Chiến lược pruning thông thường trong các bộ công cụ deep learning hiện đại liên quan đến việc thu được một mask M cho một tập con của các tham số mô hình, điều này một cách trực quan dẫn đến việc nhân với giá trị không trong bước forward pass. Ngoài ra, mask không cho phép cập nhật gradient cho các tham số này trong backward pass. Như một phần của công việc này, chúng tôi khám phá các chiến lược pruning khác nhau dựa trên UMP. Trọng tâm của PADA là khám phá "các trọng số ít quan trọng nhất" trong một mô hình SSL đã được tiền huấn luyện p(). Không giống như pruning thông thường, PADA không giữ lại mask và loại bỏ mask sau một vòng UMP, tiếp theo là đặt bằng không các tham số đã được xác định, và giữ các tham số có thể huấn luyện. PADA có thể được thực hiện theo nhiều cách, chủ yếu khác nhau trong quy trình thu được các mask pruning ban đầu ở đầu quá trình huấn luyện và tỷ lệ pruning được sử dụng tại mỗi lần lặp huấn luyện. Hình 1 minh họa ba chiến lược pruning chính. Trong bốn phần phụ sau đây, chúng tôi thảo luận ngắn gọn về các chiến lược pruning liên quan đến PADA và thuật toán để thực hiện tương tự.

3.2.1. Task-Agnostic Pruning (TAG)
Trong phương pháp này, chúng tôi thực hiện UMP với tỷ lệ pruning r1 trực tiếp trên p(), và r1 phần trăm trọng số có độ lớn nhỏ nhất được đặt bằng không, dẫn đến mô hình p(0). Phương pháp này không xem xét fine-tuning ASR downstream mà p() sẽ phải trải qua. Các trọng số đã được đặt bằng không được xác định là có tầm quan trọng ít nhất về mặt độ lớn, chỉ dựa trên tác vụ tiền huấn luyện. Người ta phải lưu ý rằng tiền huấn luyện được sử dụng để học các biểu diễn phục vụ nhiều tác vụ downstream, và fine-tuning mô hình trên các tác vụ và tập dữ liệu downstream cụ thể có thể dẫn đến một tập hợp trọng số khác nhau trở nên quan trọng.

3.2.2. Task-Aware Pruning (TAW)
Chiến lược Task-Aware Pruning nhằm mục đích đặt bằng không những trọng số từ p(), có tầm quan trọng ít nhất cụ thể cho tác vụ ASR downstream được thực hiện trên tập dữ liệu L. Để làm điều này, trước tiên chúng tôi fine-tune p() trên L dẫn đến mô hình được fine-tune p(f). Sau đó chúng tôi thực hiện UMP với tỷ lệ pruning r1 trên p(f), để thu được mask M. Mask M mang thông tin về các trọng số ít quan trọng nhất khi p() được tiếp xúc với tác vụ ASR downstream trên tập dữ liệu L. Chính xác những trọng số được chỉ định bởi mask M được đặt bằng không từ p(), dẫn đến mô hình p(0).

3.2.3. Cross-Domain Task-Aware Pruning (CD-TAW)
Trong khi TAW tập trung vào việc xác định và đặt bằng không các trọng số có tầm quan trọng ít nhất cụ thể cho tác vụ ASR downstream trên tập dữ liệu L, rõ ràng rằng phương pháp như vậy đòi hỏi fine-tuning hai lần trên tập dữ liệu L (một lần để thu được mask và lần thứ hai để fine-tune mô hình đã được tiền huấn luyện mang r1 phần trăm trọng số được đặt bằng không). Để giảm thiểu vấn đề tính toán nặng này, chúng tôi đề xuất một phương pháp trong đó UMP được thực hiện với tỷ lệ pruning r1 trên f(j), để thu được mask M. Tương tự như TAW, chính xác những trọng số được chỉ định bởi mask M được đặt bằng không từ p(), dẫn đến mô hình p(0). Lợi thế của việc sử dụng f(j) để thu được mask M là J là một tập dữ liệu tài nguyên tương đối cao (mặc dù OOD) so với L. Điều này dẫn đến mask fine-tuning phù hợp hơn với tác vụ ASR downstream, vì f(j) đã thấy nhiều dữ liệu liên quan đến "tác vụ" hơn. Lý do đằng sau việc đề cập rằng CD-TAW chỉ yêu cầu một vòng fine-tuning là khi f(j) có sẵn trực tuyến, nó tiết kiệm việc fine-tuning rõ ràng trên tác vụ ASR downstream để thu được mask task-aware.

3.2.4. Thuật toán
Alg. 1 cho thấy thuật toán của PADA nơi chúng tôi mô tả PADA với các ký hiệu từ các phần phụ trước đó.

Chúng tôi cố định tỷ lệ pruning ban đầu r1. Sau đó chúng tôi chọn tần suất pruning Pfreq từ 3 biến thể (Once / Iterative / Dynamic Iterative). Chúng tôi cũng cố định tổng số cập nhật fine-tuning thành N.

Khi một PADA Iterative được sử dụng, tần suất ri tương ứng với r1 = r1 = r2 = ... = rk. Tuy nhiên, khi Dynamic Iterative PADA được chọn, r1 > r2 > r2 > ... > rk. Dynamic Iterative PADA có lợi thế cơ bản trong đó ít trọng số hơn được đặt bằng không trong các lần lặp huấn luyện tương lai nơi mô hình đã "được huấn luyện trên miền đích" và cần "ít không gian hơn" để thích ứng. Chính xác, mỗi chiến lược pruning được đề cập trong các phần 3.2.1, 3.2.2, 3.2.3 chỉ khác nhau ở bước 1 của thuật toán PADA. Tuy nhiên, đáng chú ý rằng bước 1 của PADA là bước quan trọng nhất, tạo ra tất cả sự khác biệt về hiệu suất.

4. THIẾT LẬP THÍ NGHIỆM

4.1. Tập dữ liệu và Mô hình đã được Tiền huấn luyện
Các mô hình đã được tiền huấn luyện mà chúng tôi chọn cho PADA là:
• wav2vec-2.0 LV-60k: Một mô hình LARGE [6] được tiền huấn luyện trên 60k giờ dữ liệu âm thanh Libri-Light.
• wav2vec-2.0 LS-960: Một mô hình BASE [6] được tiền huấn luyện trên 960 giờ dữ liệu LibriSpeech.
• XLSR-53: Một mô hình LARGE được tiền huấn luyện trên 56k giờ dữ liệu từ 53 ngôn ngữ khác nhau [33]. Các tập dữ liệu được sử dụng bao gồm Multilingual LibriSpeech (MLS), CommonVoice (CV), và Babel.

Các tập dữ liệu miền đích mà chúng tôi chọn cho PADA là:
• Dữ liệu Switchboard: Đây là một kho ngữ liệu của các cuộc hội thoại giọng nói qua điện thoại [34], một miền hoàn toàn khác với dữ liệu Libri-Light được tạo thành từ giọng nói đọc từ sách nói [35]. Chúng tôi chọn hai tập con của dữ liệu Switchboard cho các thí nghiệm của mình, một tập 30 giờ và một tập 2 giờ khác, đại diện cho thiết lập thích ứng miền tài nguyên thấp và tài nguyên cực thấp. Chúng tôi báo cáo kết quả tỷ lệ lỗi từ (WER) trên tập dev Switchboard.
• Dữ liệu Hindi Challenge: Đây là một kho ngữ liệu của dữ liệu giọng nói đọc tiếng Hindi được phát hành như một phần của Hindi ASR Challenge, có 50 giờ dữ liệu giọng nói có nguồn gốc từ các miền đa dạng như chính trị, thể thao, giải trí, v.v. Chúng tôi chọn một tập con 7 giờ của dữ liệu này cho mục đích thích ứng miền và báo cáo kết quả tỷ lệ lỗi ký tự (CER) trên tập đánh giá được phát hành như một phần của cuộc thi.

4.2. Cấu hình Fine-tuning
Phương pháp baseline được chọn để so sánh với PADA là phương pháp mà chúng tôi trực tiếp fine-tune mô hình đã được tiền huấn luyện trên tập dữ liệu miền đích L. Phương pháp này được gọi là Direct Fine-tuning (DFT), baseline trong Bảng 1.

Chúng tôi thêm một lớp tuyến tính cụ thể cho tác vụ lên trên mô hình và fine-tune chung với loss CTC. Vì việc đặt bằng không các trọng số có liên quan trong PADA, chúng tôi fine-tune các trọng số trong mỗi lần lặp trên cả DFT và PADA mà không có việc đóng băng các lớp hoặc cập nhật nào được liên quan. Các giá trị N và n được sử dụng trong Alg.1 được đề cập trong Bảng 1.

Thí nghiệm rộng rãi trên dữ liệu Switchboard 30h, như được mô tả trong Hình 2, giúp chúng tôi kết luận với các thiết lập tốt nhất để sử dụng, với các tần suất pruning khác nhau. Các mô hình LARGE sử dụng r1 = 40, r1 = r2 = r3 = 30, r1 = 40; r2 = 20; r3 = 10 trong khi các mô hình BASE sử dụng r1 = 30, r1 = r2 = r3 = 30 và r1 = 30; r2 = 25; r3 = 20; r4 = 10 cho các tần suất pruning Once, Iterative và Dynamic Iterative tương ứng. Các tham số còn lại tuân theo cấu hình tiêu chuẩn trên fairseq [32] từ các công trình của [6, 33] và được cung cấp trên GitHub.

5. KẾT QUẢ
Như rõ ràng từ Bảng 1, CD-TAW được thực hiện với wav2vec-2.0 LV-60k và mask được lấy từ fine-tuning LibriSpeech 100hr đạt được cải thiện WER tương đối 20.6% trên fine-tuning Switchboard 2h và cải thiện CER tương đối 19.8% trên fine-tuning dữ liệu Hindi 7h.

6. PHÂN TÍCH KẾT QUẢ

6.1. Quan sát chính
Trong phần này chúng tôi cố gắng làm rõ và thảo luận về một số quan sát chính từ kết quả của chúng tôi trong Bảng 1. Chúng như sau:

• CD-TAW hầu như luôn vượt trội hơn TAW. Điều này tương ứng với thực tế rằng việc "task-aware" hơn hiệu quả hơn trong khi làm cho các tham số tự do thích ứng với miền downstream mới hơn là "domain-aware".

• Dynamic Iterative Pruning trong hầu hết các trường hợp vượt trội hơn các phương pháp tần suất pruning cố định khác. Điều này xác nhận lại giả thuyết của chúng tôi rằng, đối với thích ứng miền, việc giảm lặp tỷ lệ pruning qua các lần lặp fine-tuning hoạt động tốt vì mô hình trở nên thích ứng hơn với miền mới theo thời gian.

• CD-TAW có lợi với các tập dữ liệu có nhãn OOD lớn hơn. Chúng tôi dựa kết luận này từ Bảng 1 nơi CD-TAW trên Switchboard 2h có lợi hơn khi mask ban đầu M được lấy từ mô hình được fine-tune trên 960h LibriSpeech hơn 100h. Có thể có vẻ không công bằng khi so sánh các mask đến từ các mô hình được fine-tune trên vài giờ dữ liệu với những mô hình được fine-tune trên hàng trăm giờ dữ liệu. Tuy nhiên, điểm chúng tôi cố gắng nhấn mạnh là, việc sử dụng các mô hình có sẵn như vậy được fine-tune trên lượng lớn dữ liệu OOD, mang lại task-awareness tốt hơn và cũng tránh được nhu cầu fine-tune các mô hình nhiều lần như trong trường hợp của TAW.

• Ngoài thích ứng miền, PADA cũng giúp trong thích ứng đa ngôn ngữ. Điều này rất rõ ràng từ các thí nghiệm của chúng tôi trên dữ liệu có nhãn Hindi 7h. Sử dụng CD-TAW so với TAG để fine-tune trên tập dữ liệu Hindi tài nguyên thấp của chúng tôi nơi mask được lấy từ một mô hình được fine-tune LirbiSpeech, mang lại cho chúng tôi cải thiện tuyệt đối 5.5% CER.

• Giám sát ngôn ngữ ảnh hưởng đến hiệu suất CD-TAW. Khi fine-tune mô hình XLSR-53 trên dữ liệu Hindi 7h, chúng tôi nhận thấy rằng CD-TAW kém hiệu quả hơn TAW vì lượng dữ liệu Hindi trong tập dữ liệu OOD (CV và Babel) là tối thiểu. Điều này cũng phù hợp với các phát hiện từ [16].

6.2. So sánh Mask Pruning theo Lớp
Tiếp theo, chúng tôi cố gắng tìm sự tương đồng giữa một mask cung cấp cho chúng tôi mạng con ban đầu tốt nhất để fine-tune mạng của chúng tôi trên Switchboard sử dụng PADA, và tất cả các mask khác từ các thí nghiệm khác của chúng tôi. Như rõ ràng từ Bảng 1, CD-TAW đề xuất của chúng tôi cung cấp mask mạng con ban đầu tốt nhất khi mask được thu được từ một mô hình hội tụ được fine-tune trên 960hrs LibriSpeech. Để so sánh sự tương đồng giữa các mask, chúng tôi sử dụng Intersection Over Union (IOU) và Mutual Mask Agreement (MMA) làm các thước đo tương đồng. IOU để định lượng các mask mạng con, được định nghĩa trong [14] như sau:

IOU(ma,mb) = |((ma = 1) ∩ (mb = 1))| / |((ma = 1) ∪ (mb = 1))| (1)

trong đó ma và mb là hai mask chúng ta muốn so sánh.

Chúng tôi thấy rằng điểm IOU không hoàn toàn phản ánh sự tương đồng giữa các mask và định nghĩa MMA như sau:

Agg1(ma,mb) = |(ma = 1) ∩ (mb = 1)|
Agg0(ma,mb) = |(ma = 0) ∩ (mb = 0)|
MMA(ma,mb) = (Agg1 + Agg0) / N (2)

trong đó N là tổng số trọng số trong ma hoặc mb. MMA cung cấp so sánh tốt hơn giữa các mask so với IOU bởi vì, trong khi IOU chỉ tập trung vào các vùng không bị che, MMA đo sự tương đồng giữa các mask trong cả vùng bị che và không bị che. Ví dụ, gọi ma = [1,0,1,0] và gọi mb = [1,1,0,0]. Trong trường hợp này mặc dù hai mask tương tự ở vị trí đầu tiên và cuối cùng, điểm IOU hóa ra là 0.33, trong khi MMA cho điểm mong muốn là 0.5.

Hình 3 mô tả điểm MMA và IOU theo lớp giữa mask mạng con tốt nhất của chúng tôi và các thí nghiệm từ các mask khác. Như rõ ràng, cả IOU và MMA đều giảm mạnh về phía các lớp cuối, cũng học thông tin cụ thể cho tác vụ cao nhất [12] (trong trường hợp của chúng tôi, tác vụ ASR thông qua fine-tuning CTC). Một cách khác, mô hình hoạt động tốt nhất của chúng tôi, CD-TAW, xác nhận lại giả thuyết rằng bất kể miền, mô hình càng "task-aware", mask mạng con ban đầu càng tốt. Cuối cùng, mặc dù CD-TAW từ một mô hình được fine-tune trên 100 giờ hoạt động kém hơn so với đối tác 960hrs của nó, nó cho thấy giá trị IOU và MMA cao nhất trong tất cả các mask, điều này một lần nữa khẳng định rằng các mask tốt hơn có thể được thu được từ "task-awareness" nhiều hơn.

7. KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI
Trong bài báo này, chúng tôi đề xuất PADA, một mô hình mới cho thích ứng miền ASR tài nguyên thấp. Các mô hình được tiền huấn luyện với SSL trên lượng lớn dữ liệu không nhãn OOD cho thấy những cải thiện đáng kể khi được fine-tune trên ASR sử dụng khung PADA. Như một phần của công việc tương lai, chúng tôi muốn khám phá xem structured pruning và thích ứng miền SSL không giám sát có thể giúp tăng hiệu suất trong mô hình học này hay không.

8. LỜI CẢM ÒN
Một phần của công việc này được tài trợ bởi dự án "Bhashini: National Language translation Mission" của Bộ Điện tử và Công nghệ Thông tin (MeitY), Chính phủ Ấn Độ.

9. TÀI LIỆU THAM KHẢO
[1] Santosh K Gaikwad, Bharti W Gawali, và Pravin Yannawar, "A review on speech recognition technique," International Journal of Computer Applications, vol. 10, no. 3, pp. 16–24, 2010.
[2] Hermann Ney, "Speech translation: Coupling of recognition and translation," trong IEEE ICASSP 1999. IEEE, 1999, vol. 1, pp. 517–520.
[3] George Saon, Gakuto Kurata, Tom Sercu, Kartik Audhkhasi, Samuel Thomas, Dimitrios Dimitriadis, Xiaodong Cui, Bhuvana Ramabhadran, Michael Picheny, Lynn-Li Lim, et al., "English conversational telephone speech recognition by humans and machines," arXiv preprint arXiv:1703.02136, 2017.
[4] Hemant Yadav, Sreyan Ghosh, Yi Yu, và Rajiv Ratn Shah, "End-to-end named entity recognition from english speech," arXiv preprint arXiv:2005.11184, 2020.
[5] Amodei et al., "Deep speech 2: End-to-end speech recognition in english and mandarin," trong ICML 2016, pp. 173–182.
[6] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, và Michael Auli, "wav2vec 2.0: A framework for self-supervised learning of speech representations," NeurIPS 2020, vol. 33, pp. 12449–12460, 2020.
[7] Shu wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I Jeff Lai, Kushal Lakhotia, Yist Y. Lin, Andy T. Liu, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, Tzu-Hsien Huang, Wei-Cheng Tseng, Ko tik Lee, Da-Rong Liu, Zili Huang, Shuyan Dong, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed, và Hung yi Lee, "SUPERB: Speech Processing Universal PERformance Benchmark," trong Interspeech 2021, 2021, pp. 1194–1198.
[8] Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, và Abdelrahman Mohamed, "Hubert: Self-supervised speech representation learning by masked prediction of hidden units," IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 3451–3460, 2021.
[9] Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, et al., "Wavlm: Large-scale self-supervised pre-training for full stack speech processing," arXiv preprint arXiv:2110.13900, 2021.
[10] Andy T Liu, Shu-wen Yang, Po-Han Chi, Po-chun Hsu, và Hung-yi Lee, "Mockingjay: Unsupervised speech representation learning with deep bidirectional transformer encoders," trong IEEE ICASSP 2020, pp. 6419–6423.
[11] Wei-Ning Hsu, Anuroop Sriram, Alexei Baevski, Tatiana Likhomanenko, Qiantong Xu, Vineel Pratap, Jacob Kahn, Ann Lee, Ronan Collobert, Gabriel Synnaeve, và Michael Auli, "Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training," trong Interspeech 2021, 2021, pp. 721–725.
[12] Ankita Pasad, Ju-Chieh Chou, và Karen Livescu, "Layer-wise analysis of a self-supervised speech representation model," trong 2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU). IEEE, 2021, pp. 914–921.
[13] Awni Hannun, "The history of speech recognition to the year 2030," arXiv preprint arXiv:2108.00084, 2021.
[14] Cheng-I Jeff Lai, Yang Zhang, Alexander H. Liu, Shiyu Chang, Yi-Lun Liao, Yung-Sung Chuang, Kaizhi Qian, Sameer Khurana, David Cox, và James Glass, "Parp: Prune, adjust and re-prune for self-supervised speech recognition," trong NeurIPS 2021.
[15] Jonathan Frankle và Michael Carbin, "The lottery ticket hypothesis: Finding sparse, trainable neural networks," trong ICLR 2019.
[16] Yizhou Lu, Mingkun Huang, Xinghua Qu, Pengfei Wei, và Zejun Ma, "Language adaptive cross-lingual speech representation learning with sparse sharing sub-networks," arXiv preprint arXiv:2203.04583, 2022.
[17] Aaron van den Oord, Yazhe Li, và Oriol Vinyals, "Representation learning with contrastive predictive coding," arXiv preprint arXiv:1807.03748, 2018.
[18] Andy T Liu, Shang-Wen Li, và Hung-yi Lee, "Tera: Self-supervised learning of transformer encoder representation for speech," IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 2351–2366, 2021.
[19] Trevor Gale, Erich Elsen, và Sara Hooker, "The state of sparsity in deep neural networks," arXiv preprint arXiv:1902.09574, 2019.
[20] Song Han, Jeff Pool, John Tran, và William Dally, "Learning both weights and connections for efficient neural network," NeurIPS 2015, vol. 28, 2015.
[21] Suyog Gupta Michael H. Zhu, "To prune, or not to prune: Exploring the efficacy of pruning for model compression," trong ICLR 2018.
[22] Shuhao Gu, Yang Feng, và Wanying Xie, "Pruning-then-expanding model for domain adaptation of neural machine translation," trong NAACL 2021.
[23] Dong Yu, Kaisheng Yao, Hang Su, Gang Li, và Frank Seide, "Kl-divergence regularized deep neural network adaptation for improved large vocabulary speech recognition," trong IEEE ICASSP 2013, pp. 7893–7897.
[24] Hank Liao, "Speaker adaptation of context dependent deep neural networks," trong IEEE ICASSP 2013, pp. 7947–7951.
[25] Zhong Meng, Jinyu Li, Yifan Gong, và Biing-Hwang Juang, "Adversarial teacher-student learning for unsupervised domain adaptation," trong IEEE ICASSP 2018, pp. 5949–5953.
[26] Vimal Manohar, Pegah Ghahremani, Daniel Povey, và Sanjeev Khudanpur, "A teacher-student learning approach for unsupervised domain adaptation of sequence-trained asr models," trong IEEE SLT Workshop 2018, pp. 250–257.
[27] Yusuke Shinohara, "Adversarial multi-task learning of deep neural networks for robust speech recognition.," trong Interspeech 2016, pp. 2369–2372.
[28] Zhong Meng, Jinyu Li, Zhuo Chen, Yang Zhao, Vadim Mazalov, Yifan Gong, và Biing-Hwang Juang, "Speaker-invariant training via adversarial learning," trong IEEE ICASSP 2018, pp. 5969–5973.
[29] CS Anoop, AP Prathosh, và AG Ramakrishnan, "Unsupervised domain adaptation schemes for building asr in low-resource languages," trong IEEE ASRU Workshop 2021.
[30] Dongseong Hwang, Ananya Misra, Zhouyuan Huo, Nikhil Siddhartha, Shefali Garg, David Qiu, Khe Chai Sim, Trevor Strohman, Françoise Beaufays, và Yanzhang He, "Large-scale asr domain adaptation using self-and semi-supervised learning," arXiv preprint arXiv:2110.00165, 2021.
[31] Suchin Gururangan, Ana Marašović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, và Noah A. Smith, "Don't stop pretraining: Adapt language models to domains and tasks," trong ACL 2020, pp. 8342–8360.
[32] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, và Michael Auli, "fairseq: A fast, extensible toolkit for sequence modeling," trong NAACL-HLT 2019: Demonstrations.
[33] Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, và Michael Auli, "Xls-r: Self-supervised cross-lingual speech representation learning at scale," arXiv, vol. abs/2111.09296, 2021.
[34] John J Godfrey, Edward C Holliman, và Jane McDaniel, "Switchboard: Telephone speech corpus for research and development," trong IEEE ICASSP 1992, vol. 1, pp. 517–520.
[35] Jacob Kahn, Morgane Riviere, Weiyi Zheng, Evgeny Kharitonov, Qiantong Xu, Pierre-Emmanuel Mazaré, Julien Karadayi, Vitaliy Liptchinsky, Ronan Collobert, Christian Fuegen, et al., "Libri-light: A benchmark for asr with limited or no supervision," trong IEEE ICASSP 2020, pp. 7669–7673.

# CoDi: Chưng Cất Khuếch Tán Có Điều Kiện
cho Việc Tạo Hình Ảnh Chất Lượng Cao Hơn và Nhanh Hơn

Kangfu Mei*1,2, Mauricio Delbracio1, Hossein Talebi1,
Zhengzhong Tu1, Vishal M. Patel2, Peyman Milanfar1
1Google Research, 2Đại học Johns Hopkins
https://fast-codi.github.io

(a) Siêu phân giải thế giới thực 4 bước của chúng tôi
(b) InstructPix2Pix 1 bước của chúng tôi với: "Làm cho nó tối" và "Làm cho nó hoàng hôn"
(c) Tạo từ bản đồ độ sâu 4 bước của chúng tôi
(d) Kết quả vẽ đầy 4 bước của chúng tôi với gợi ý: Shiba, Husky, Alpaca, Panda, Hawk, Dragon

Tóm tắt
Các mô hình khuếch tán tạo sinh lớn đã cách mạng hóa việc tạo hình ảnh từ văn bản và mang lại tiềm năng to lớn cho các tác vụ tạo sinh có điều kiện như cải tiến hình ảnh, khôi phục, chỉnh sửa và tổng hợp. Tuy nhiên, việc áp dụng rộng rãi của chúng bị cản trở bởi chi phí tính toán cao, điều này hạn chế ứng dụng thời gian thực. Để giải quyết thách thức này, chúng tôi giới thiệu một phương pháp mới được gọi là CoDi, có thể thích ứng một mô hình khuếch tán ẩn được huấn luyện trước để chấp nhận các đầu vào điều kiện hình ảnh bổ sung trong khi giảm đáng kể số bước lấy mẫu cần thiết để đạt được kết quả chất lượng cao. Phương pháp của chúng tôi có thể tận dụng các kiến trúc như ControlNet để kết hợp các đầu vào điều kiện mà không làm tổn hại kiến thức tiên nghiệm của mô hình đạt được trong quá trình huấn luyện trước quy mô lớn. Ngoài ra, một mất mát nhất quán có điều kiện thực thi các dự đoán nhất quán trên các bước khuếch tán, hiệu quả buộc mô hình tạo ra hình ảnh chất lượng cao với điều kiện trong vài bước. Cách tiếp cận học tập và chưng cất tác vụ có điều kiện của chúng tôi vượt trội hơn các phương pháp chưng cất trước đây, đạt được trạng thái nghệ thuật mới trong việc tạo ra hình ảnh chất lượng cao với rất ít bước (ví dụ: 1-4) trên nhiều tác vụ, bao gồm siêu phân giải, chỉnh sửa hình ảnh có hướng dẫn văn bản và tạo hình ảnh từ độ sâu.

1. Giới thiệu
Các mô hình khuếch tán văn bản sang hình ảnh [27, 29, 34] được huấn luyện trên dữ liệu quy mô lớn [15, 38] đã thống trị đáng kể các tác vụ tạo sinh bằng cách mang lại kết quả ấn tượng chất lượng cao và đa dạng. Một xu hướng mới nổi là sử dụng tiên nghiệm của các mô hình văn bản sang hình ảnh được huấn luyện trước như các mô hình khuếch tán ẩn (LDMs) [29] để hướng dẫn kết quả được tạo ra với các điều kiện hình ảnh bên ngoài cho các tác vụ chuyển đổi hình ảnh sang hình ảnh như thao tác hình ảnh, cải tiến hoặc siêu phân giải [22, 53]. Trong số các quá trình chuyển đổi này, tiên nghiệm khuếch tán được giới thiệu bởi các mô hình được huấn luyện trước được chứng minh là có khả năng thúc đẩy đáng kể chất lượng thị giác của kết quả tạo hình ảnh có điều kiện [3, 16, 26, 31].

Tuy nhiên, các mô hình khuếch tán phụ thuộc nhiều vào quá trình cải tiến lặp đi lặp lại [4, 33, 35, 43, 49] thường đòi hỏi một số lượng lớn các lần lặp, điều này có thể khó thực hiện một cách hiệu quả. Sự phụ thuộc của chúng vào số lần lặp còn tăng thêm đối với tổng hợp hình ảnh độ phân giải cao. Ví dụ, trong các mô hình khuếch tán ẩn văn bản sang hình ảnh hiện đại [29], việc đạt chất lượng thị giác tối ưu thường yêu cầu 20-200 bước lấy mẫu (đánh giá hàm), ngay cả với các phương pháp lấy mẫu tiên tiến [10, 17]. Thời gian lấy mẫu chậm làm cản trở đáng kể các ứng dụng thực tế của các mô hình khuếch tán có điều kiện nói trên.

Các nỗ lực gần đây để tăng tốc lấy mẫu khuếch tán chủ yếu sử dụng các phương pháp chưng cất [21, 36, 44]. Các phương pháp này đạt được lấy mẫu nhanh hơn đáng kể, hoàn thành quá trình chỉ trong 4-8 bước, với chỉ một sự giảm nhỏ về hiệu suất tạo sinh. Các công trình rất gần đây [14, 23] cho thấy rằng các chiến lược này thậm chí còn có thể áp dụng để chưng cất các mô hình khuếch tán văn bản sang hình ảnh quy mô lớn được huấn luyện trước.

Một tình huống ứng dụng rất phổ biến là kết hợp các điều kiện mới vào các mô hình khuếch tán được chưng cất này, chẳng hạn như sử dụng hình ảnh độ phân giải thấp cho siêu phân giải [35], hoặc điều chỉnh hướng dẫn cho chỉnh sửa hình ảnh [3], trong đó cách tiếp cận đơn giản nhất là tinh chỉnh trực tiếp mô hình văn bản sang hình ảnh được huấn luyện trước đã được chưng cất với dữ liệu điều kiện mới. Một cách tiếp cận thay thế phổ biến [23] là đầu tiên tinh chỉnh mô hình khuếch tán với dữ liệu điều kiện mới, sau đó thực hiện chưng cất trên mô hình có điều kiện đã được tinh chỉnh. Trong khi hai phương pháp này đã được chứng minh để tăng tốc lấy mẫu, mỗi phương pháp có những nhược điểm riêng biệt về chất lượng kết quả và tính linh hoạt đa tác vụ, như thảo luận dưới đây.

Trong bài báo này, chúng tôi giới thiệu một thuật toán mới cho Chưng cất Có điều kiện mà chúng tôi gọi là CoDi để thêm hiệu quả các điều khiển mới vào các mô hình được chưng cất. Không giống như các phương pháp chưng cất trước đây dựa vào tinh chỉnh, phương pháp của chúng tôi trực tiếp chưng cất một mô hình khuếch tán từ việc huấn luyện trước văn bản sang hình ảnh (ví dụ: StableDiffusion) và kết thúc bằng một mô hình khuếch tán có điều kiện được chưng cất hoàn toàn. Như mô tả trong Hình 1, mô hình được chưng cất của chúng tôi có khả năng dự đoán kết quả chất lượng cao chỉ trong 1-4 bước lấy mẫu.

Theo thiết kế, phương pháp của chúng tôi loại bỏ nhu cầu về dữ liệu văn bản sang hình ảnh gốc [37, 38], một yêu cầu trong các phương pháp chưng cất trước đây (tức là những phương pháp đầu tiên chưng cất mô hình văn bản sang hình ảnh không có điều kiện), từ đó làm cho phương pháp của chúng tôi thiết thực hơn. Ngoài ra, công thức của chúng tôi tránh hy sinh tiên nghiệm khuếch tán trong mô hình được huấn luyện trước trong quá trình tinh chỉnh, một nhược điểm phổ biến trong giai đoạn đầu của thủ tục tinh chỉnh trước. Các thí nghiệm rộng rãi của chúng tôi cho thấy rằng CoDi của chúng tôi vượt trội hơn các phương pháp chưng cất trước đây trong cả chất lượng thị giác và các chỉ số định lượng, đặc biệt khi hoạt động trong cùng thời gian lấy mẫu.

Các phương pháp chưng cất hiệu quả tham số là một lĩnh vực tương đối ít được nghiên cứu. Chúng tôi chứng minh rằng phương pháp của chúng tôi cũng cho phép một mô hình Chưng cất Hiệu quả Tham số mới (PE-CoDi). Nó có thể chuyển đổi một mô hình khuếch tán không có điều kiện thành các tác vụ có điều kiện bằng cách kết hợp một số lượng nhỏ các tham số có thể học được bổ sung. Cụ thể, công thức của chúng tôi cho phép tích hợp với các thuật toán điều chỉnh hiệu quả tham số hiện có khác nhau, ví dụ: ControlNet [53]. Chúng tôi cho thấy rằng quá trình chưng cất của chúng tôi tích hợp bộ điều hợp ControlNet có thể bảo tồn hiệu quả tiên nghiệm tạo sinh trong huấn luyện trước trong khi thích ứng mô hình với dữ liệu có điều kiện mới. Mô hình mới này cải thiện đáng kể tính thực tế của các tác vụ có điều kiện khác nhau.

Đóng góp của chúng tôi được tóm tắt như sau:
• Chúng tôi đề xuất một phương pháp mới cho việc tạo sinh có điều kiện hình ảnh và hình ảnh-văn bản. Nó có thể tạo ra một mô hình khuếch tán có điều kiện từ các LDMs văn bản sang hình ảnh được huấn luyện trước để tạo ra kết quả chất lượng cao chỉ trong vài bước lấy mẫu.
• Hiệu quả và hiệu suất của phương pháp được đề xuất phát sinh từ một sự nhất quán không tầm thường giữa các dự đoán của mô hình tại các bước thời gian khác nhau. Thực thi sự nhất quán này thông qua học tập cho phép đồng thời giảm số bước lấy mẫu cần thiết và tích hợp các điều kiện mới vào mô hình.
• Chúng tôi giới thiệu cơ chế chưng cất hiệu quả tham số đầu tiên có thể tạo ra kết quả hấp dẫn chỉ trong vài bước, trong khi chỉ yêu cầu một số lượng nhỏ các tham số bổ sung so với các LDMs được huấn luyện trước.

2. Các Công Trình Liên Quan
Chưng cất Khuếch tán. Để giảm thời gian lấy mẫu của các mô hình khuếch tán, Luhman và cộng sự [21] đề xuất học một mô hình học sinh một bước từ đầu ra của mô hình gốc (giáo viên) sử dụng nhiều bước lấy mẫu. Tuy nhiên, phương pháp này yêu cầu chạy suy luận đầy đủ với nhiều bước lấy mẫu trong quá trình huấn luyện làm cho nó kém khả năng mở rộng. Được truyền cảm hứng từ điều này, Chưng cất Tiệm tiến [36] và các biến thể của nó, bao gồm Chưng cất Có hướng dẫn [23] và SnapFusion [14], sử dụng một sơ đồ học tập tiệm tiến để cải thiện hiệu quả học tập. Một mô hình học sinh học dự đoán đầu ra của hai bước của mô hình giáo viên trong một bước. Sau đó, mô hình giáo viên được thay thế bằng mô hình học sinh, và thủ tục được lặp lại để tiệm tiến chưng cất mô hình bằng cách chia đôi số bước cần thiết. Chúng tôi chứng minh phương pháp của chúng tôi bằng cách so sánh các phương pháp này trên các tác vụ tạo sinh có điều kiện. Chúng tôi lưu ý rằng các chiến lược như chưng cất hướng dẫn không phân loại [14, 23], hoặc các kỹ thuật lấy mẫu được áp dụng khác nhau [51, 54], là trực giao với phương pháp của chúng tôi, và chúng có thể được kết hợp trong công thức của chúng tôi. Mặc dù một số công trình đồng thời [50, 52] thấy rằng các tác vụ như siêu phân giải yêu cầu ít bước lấy mẫu hơn, chúng tôi sau đó cho thấy rằng chưng cất các mô hình khuếch tán được huấn luyện trước vẫn có thể cải thiện hiệu suất trong các tác vụ khôi phục như vậy.

Chưng cất Nhất quán. Mô hình Nhất quán là một cách tiếp cận tạo sinh một bước được chưng cất từ một mô hình khuếch tán được huấn luyện trước [44]. Việc học được thực hiện bằng cách thực thi một sự tự nhất quán trong không gian tín hiệu được dự đoán. Dựa trên ý tưởng này, các công trình theo sau [7, 11, 19, 41] đã tập trung vào việc cải thiện các kỹ thuật huấn luyện. Tuy nhiên, học các mô hình nhất quán cho việc tạo sinh có điều kiện vẫn chưa được nghiên cứu kỹ lưỡng. Trong bài báo này, chúng tôi so sánh phương pháp của chúng tôi với một cách tiếp cận cơ sở thực thi tự nhất quán trong một mô hình khuếch tán có điều kiện đã được tinh chỉnh. Kết quả của chúng tôi chứng minh rằng mô hình được chưng cất có điều kiện của chúng tôi vượt trội hơn cách tiếp cận cơ sở, cho thấy hiệu quả của chiến lược chưng cất được đề xuất.

Thích ứng Mô hình Khuếch tán. Tận dụng kiến thức của các mô hình được huấn luyện trước cho các tác vụ mới, được gọi là thích ứng mô hình, đã nhận được sự quan tâm đáng kể trong các lĩnh vực NLP và thị giác máy tính. Cách tiếp cận này sử dụng các bộ điều hợp mô hình [9, 28, 30, 45] và HyperNetworks [1, 6] để thích ứng hiệu quả các mô hình được huấn luyện trước với các miền và tác vụ mới. Trong bối cảnh của các mô hình khuếch tán, các bộ điều hợp mô hình đã được sử dụng thành công để kết hợp các điều kiện mới vào các mô hình được huấn luyện trước [24, 53]. Phương pháp được đề xuất của chúng tôi lấy cảm hứng từ các cách tiếp cận này và giới thiệu một ứng dụng mới của các bộ điều hợp mô hình: chưng cất các bước lấy mẫu của các mô hình khuếch tán. So với tinh chỉnh toàn bộ mô hình [36], phương pháp của chúng tôi mang lại hiệu quả và tính linh hoạt tăng cường. Nó cho phép thích ứng nhiều tác vụ sử dụng cùng một mô hình xương sống.

3. Kiến thức Nền tảng
Mô hình khuếch tán VP thời gian liên tục. Một mô hình khuếch tán bảo toàn phương sai (VP) thời gian liên tục [8, 39] là một trường hợp đặc biệt của các mô hình khuếch tán¹. Nó có các biến ẩn {zt|t ∈ [0, T]} được chỉ định bởi một lịch trình nhiễu bao gồm các hàm khả vi {αt, σt} với σt² = 1 - αt². Dữ liệu sạch x ~ pdata được nhiễu loạn tiệm tiến trong một quá trình Gaussian (tiến) như trong cấu trúc Markovian sau:

q(zt|x) = N(zt; αtx, σt²I), (1)
q(zt|zs) = N(zt; αt|szs, σt|s²I), (2)

trong đó 0 ≤ s < t ≤ 1 và αt|s² = αt/αs. Ở đây biến ẩn zt được lấy mẫu từ sự kết hợp của dữ liệu sạch và nhiễu ngẫu nhiên bằng cách sử dụng thủ thuật tham số hóa lại [13], có zt = αtx + σtε.

Lấy mẫu xác định. Quá trình khuếch tán nói trên bắt đầu từ z0 ~ pdata(x) và kết thúc tại zT ~ N(0,I) có thể được mô hình hóa như nghiệm của một phương trình vi phân ngẫu nhiên (SDE) [43]. SDE được hình thành bởi một hàm giá trị vector f(·,·) : Rd → Rd, một hàm vô hướng g(·) : R → R, và quá trình Wiener chuẩn:

dzt = f(zt, t)dt + g(t)dw. (3)

Ý tưởng tổng thể là SDE thời gian ngược chạy ngược lại theo thời gian, có thể tạo ra các mẫu của pdata từ phân phối tiên nghiệm N(0,I). SDE ngược này được cho bởi:

dzt = [f(zt, t) - g(t)²∇z log pt(zt)]dt + g(t)dw̄, (4)

trong đó w̄ cũng là một quá trình Wiener chuẩn trong thời gian ngược, và ∇z log pt(zt) là điểm của phân phối biên tại thời điểm t. Hàm điểm có thể được ước tính bằng cách huấn luyện một mô hình dựa trên điểm sθ(zt, t) ≈ ∇z log pt(zt) với khớp điểm [42] hoặc một mạng khử nhiễu x̂θ(zt, t) [8]:

sθ(zt, t) := (αtx̂θ(zt, t) - zt)/σt². (5)

SDE ngược như vậy thỏa mãn một phương trình vi phân thường (ODE) đặc biệt cho phép lấy mẫu xác định cho zT ~ N(0,I). Điều này được biết đến như ODE dòng xác suất (PF) [43] và được cho bởi:

dzt = [f(zt, t) - ½g²(t)sθ(zt, t)]dt, (6)

trong đó f(zt, t) = d log αt/dt zt, g²(t) = dσt²/dt - 2d log αt/dt σt² với respect to {αt, σt} và t theo [12]. ODE này có thể được giải bằng số với các bộ lấy mẫu khuếch tán như DDIM [40], trong đó bắt đầu từ ẑT ~ N(0,I), chúng ta cập nhật cho s = t - Δt:

ẑs := αsẑxθ(ẑt, t) + σs(ẑt - αtẑxθ(ẑt, t))/σt, (7)

cho đến khi chúng ta đạt ẑ0.

Tham số hóa mô hình khuếch tán. Bỏ qua cách tham số hóa mô hình khuếch tán nói trên với một mạng khử nhiễu (dự đoán tín hiệu) hoặc một mô hình điểm (dự đoán nhiễu phương trình 5), trong công trình này, chúng tôi áp dụng một tham số hóa kết hợp cả dự đoán điểm (hoặc nhiễu) và tín hiệu. Các phương pháp hiện có bao gồm việc dự đoán nhiễu ε̂θ(xt, t) và tín hiệu x̂θ(zt, t) riêng biệt sử dụng một mạng đơn [5], hoặc dự đoán sự kết hợp của nhiễu và tín hiệu bằng cách biểu thị chúng trong một thuật ngữ mới, như mô hình vận tốc v̂θ(zt, t) ≈ αtε - σtx [36]. Lưu ý rằng người ta có thể suy ra một ước tính của tín hiệu và nhiễu từ vận tốc:

x̂ = αtzt - σtv̂θ(zt, t), và ε̂ = αtv̂θ(zt, t) + σtzt. (8)

Tương tự, quy tắc cập nhật DDIM (phương trình 7) có thể được viết lại theo tham số hóa vận tốc:

ẑs := αs(αtẑzt - σtv̂θ(ẑt, t)) + σs(αtv̂θ(ẑt, t) + σtẑzt). (9)

Tính chất tự nhất quán. Để tăng tốc suy luận, [44] đã giới thiệu ý tưởng về các mô hình nhất quán. Cho sθ(·, t) là một mô hình khuếch tán được huấn luyện trước được huấn luyện trên dữ liệu x ~ pdata. Sau đó, một hàm nhất quán fφ(zt, t) nên thỏa mãn rằng [44] trong đó fφ(x,0) = x và

fφ(zt, t) = fφ(zt', t'), ∀t, t' ∈ [0, T], (10)

trong đó {zt}t∈[0,T] là quỹ đạo nghiệm của ODE dòng xác suất (PF-ODE) (phương trình 6). Một điều kiện biên, tức là fφ(x,0) = x được tham số hóa với các kết nối bỏ qua để đảm bảo tính chất liên tục tương tự như đã làm trong các công trình trước [2, 10, 44]:

Fφ(zt, t) = cskip(t)x + cout(t)fφ(zt, t), (11)

trong đó cskip(0) = 1, cout(0) = 0. Trong thực tế, fφ(zt, t) thường là một mạng khử nhiễu được chưng cất từ một mô hình khuếch tán được huấn luyện trước. Chúng tôi sau đó cho thấy rằng chúng ta có thể thay thế PF-ODE đông lạnh bằng mạng chưng cất và do đó phù hợp với PF-ODE cho dữ liệu có điều kiện mới trong quá trình chưng cất.

4. Phương pháp
4.1. Từ Không có Điều kiện đến Có Điều kiện
Để sử dụng tiên nghiệm tạo hình ảnh được bao gồm bởi mô hình khuếch tán không có điều kiện² được huấn luyện trước, chúng tôi đầu tiên đề xuất thích ứng mô hình khuếch tán không có điều kiện thành một phiên bản có điều kiện cho dữ liệu có điều kiện (x, c) ~ pdata. Tương tự như kỹ thuật khởi tạo zero được sử dụng bởi việc tạo sinh có thể kiểm soát [25, 53], phương pháp của chúng tôi thích ứng kiến trúc được huấn luyện trước không có điều kiện bằng cách sử dụng một bộ mã hóa có điều kiện bổ sung.

Để làm rõ, chúng tôi lấy U-Net được sử dụng rộng rãi làm mạng khuếch tán. Hãy giới thiệu mô-đun có điều kiện bằng cách sao chép các lớp mã hóa của mạng được huấn luyện trước. Sau đó, cho hθ(·) là các đặc trưng mã hóa của mạng được huấn luyện trước, và hη(·) là các đặc trưng trên bộ mã hóa có điều kiện bổ sung. Chúng tôi định nghĩa các đặc trưng mã hóa mới của mô hình được thích ứng bởi

hθ(zt)' = (1-μ)hθ(zt) + μhη(c), (12)

trong đó μ là một tham số vô hướng có thể học được, được khởi tạo thành μ = 0. Bắt đầu từ khởi tạo zero này, chúng ta có thể thích ứng kiến trúc không có điều kiện thành một kiến trúc có điều kiện. Do đó, mô hình khuếch tán có điều kiện ŵθ(zt, c, t) của chúng tôi là kết quả của việc thích ứng mô hình khuếch tán không có điều kiện được huấn luyện trước v̂θ(zt, t) với các đặc trưng có điều kiện hη(c).

4.2. Một Nhất quán Khuếch tán Có Điều kiện Mới
Ý tưởng cốt lõi của chúng tôi là tối ưu hóa mô hình khuếch tán có điều kiện được thích ứng ŵθ(zt, c, t) từ v̂θ(zt, t), để nó thỏa mãn một tính chất nhất quán khuếch tán có điều kiện:

ŵθ(zt, c, t) = ŵθ(ẑs, c, s), ∀t, s ∈ [0, T], (13)

trong đó ẑs thuộc về ODE dòng xác suất (phương trình 6) của mô hình được thích ứng. Lưu ý rằng tính chất nhất quán này khác với tính chất trong các mô hình nhất quán [44] trong mô hình ODE dòng xác suất được sử dụng để lấy mẫu ẑs và không gian mất mát nhất quán. Để thúc đẩy công thức này, hãy giới thiệu nhận xét tổng quát sau.

Nhận xét 1. Nếu một mô hình khuếch tán, được tham số hóa bởi v̂θ(zt, t), thỏa mãn tính chất tự nhất quán (phương trình 10) trên dự đoán nhiễu ε̂θ(zt, t) = αtv̂θ(zt, t) + σtzt, thì nó cũng thỏa mãn tính chất tự nhất quán trên dự đoán tín hiệu x̂θ(zt, t) = αtzt - σtv̂θ(zt, t).

Chứng minh là hệ quả trực tiếp của việc đổi biến từ nhiễu sang tín hiệu và được đưa ra trong Phụ lục. Dựa trên nhận xét tổng quát này, chúng tôi khẳng định rằng chúng ta có thể tối ưu hóa mô hình khuếch tán có điều kiện ŵθ(zt, c, t) để đồng thời học thực thi tính chất tự nhất quán trên dự đoán nhiễu ε̂θ(zt, c, t) và việc tạo sinh có điều kiện mới (x, c) ~ pdata với dự đoán tín hiệu x̂θ(zt, c, t). Sau đó chúng tôi áp đặt điều kiện biên cho chưng cất nhất quán bằng cách tham số hóa dự đoán nhiễu ε̂θ(zt, c, t) với cùng các kết nối bỏ qua của phương trình 17.

Dự đoán của ẑs. Trong quá trình chưng cất được cho bởi phương trình 15, biến ẩn ẑs được đạt được bằng cách chạy một bước của một bộ giải ODE số. Các mô hình nhất quán [44] giải ODE sử dụng bộ giải Euler, trong khi chưng cất tiệm tiến [36] và chưng cất có hướng dẫn [23] chạy hai bước sử dụng bộ lấy mẫu DDIM (phương trình 7).

Chúng tôi đề xuất một dự đoán thay thế cho ẑs tận dụng mô hình khuếch tán được thích ứng, x̂θ(zt, c, t), trái ngược với mô hình huấn luyện trước đông lạnh thông thường. Sau đó chúng tôi lấy mẫu ẑs trong PF-ODE mô hình khuếch tán được thích ứng bằng

ẑs = αsx̂θ(zt, c, t) + σsε, với zt = αtx + σtε, (14)

và ε ~ N(0,I). Công thức mới này hiệu quả hài hòa các hướng tối ưu hóa xung đột giữa chưng cất nhất quán từ dữ liệu được huấn luyện trước và hướng dẫn có điều kiện từ dữ liệu có điều kiện.

Sơ đồ huấn luyện. Được truyền cảm hứng từ các mô hình nhất quán [44], chúng tôi sử dụng các tham số trung bình di chuyển theo cấp số nhân θ- làm mạng mục tiêu để ổn định huấn luyện. Sau đó, chúng ta có thể giảm thiểu mất mát huấn luyện sau đây cho chưng cất có điều kiện:

L(θ) := E[dε(ε̂θ-(ẑs,s,c), ε̂θ(zt,t,c))) + dx(x, x̂θ(zt, t, c)]. (15)

trong đó dε(·,·) và dx(·,·) là hai hàm khoảng cách để đo sự khác biệt trong không gian nhiễu và trong không gian tín hiệu tương ứng. Lưu ý rằng tổng mất mát là một sự cân bằng giữa hướng dẫn có điều kiện được cho bởi dx, và tính chất tự nhất quán nhiễu được cho bởi dε.

Thuật toán chưng cất có điều kiện tổng thể được trình bày trong Phụ lục. Trong phần tiếp theo, chúng tôi sẽ chi tiết về cách chúng tôi lấy mẫu ẑs và thảo luận về các siêu tham số liên quan khác trong phương pháp của chúng tôi (ví dụ: dx).

4.3. Tác động của Hướng dẫn Có Điều kiện Khác nhau
Để tinh chỉnh mô hình khuếch tán được thích ứng với dữ liệu có điều kiện mới, mất mát chưng cất khuếch tán có điều kiện của chúng tôi trong phương trình 15 phạt sự khác biệt giữa tín hiệu được dự đoán x̂θ(zt, c, t) và hình ảnh tương ứng x với một hàm khoảng cách dx(·,·) để học chưng cất.

Ở đây chúng tôi khảo sát tác động của hàm khoảng cách dx(·,·) trong hướng dẫn có điều kiện. Theo cả kết quả định tính và định lượng, được hiển thị trong Hình 2, các hàm khoảng cách khác nhau dẫn đến các hành vi khác nhau khi thực hiện lấy mẫu nhiều bước (suy luận). Nếu dx = ∥·∥2 trong không gian pixel hoặc không gian được mã hóa, tức là ∥x - E(D(x̂θ(zt, c, t)))∥2² và ∥D(x) - D(x̂θ(zt, c, t))∥2², lấy mẫu nhiều bước dẫn đến kết quả mượt mà và mờ hơn. Nếu thay vào đó chúng ta áp dụng một khoảng cách tri giác trong không gian pixel, tức là Flpips(D(x), D(x̂θ(zt, c, t))), việc cải tiến lặp trong lấy mẫu nhiều bước dẫn đến kết quả quá bão hòa. Nhìn chung, theo mặc định chúng tôi đã áp dụng khoảng cách ℓ2 trong không gian ẩn vì nó dẫn đến chất lượng thị giác tốt hơn và đạt được FID tối ưu với 4 bước lấy mẫu trong Hình 2.

4.4. Chưng cất Có Điều kiện Hiệu quả Tham số
Phương pháp của chúng tôi mang lại sự linh hoạt để cập nhật có chọn lọc các tham số liên quan đến chưng cất và tinh chỉnh có điều kiện, để lại các tham số còn lại được đông lạnh. Điều này dẫn chúng tôi đến việc giới thiệu một phong cách mới của chưng cất có điều kiện hiệu quả tham số, nhằm mục đích thống nhất quá trình chưng cất trên việc tinh chỉnh mô hình khuếch tán hiệu quả tham số thường được sử dụng, bao gồm ControlNet [53], T2I-Adapter [24], v.v. Chúng tôi nêu bật kiến trúc ControlNet được minh họa trong Hình 3 như một ví dụ. Mô hình này sao chép phần mã hóa của mạng khử nhiễu, được nêu bật trong các khối màu xanh, làm các tham số liên quan đến điều kiện. Phương pháp của chúng tôi sau đó có thể tối ưu hóa hướng dẫn có điều kiện và tính nhất quán bằng cách chỉ cập nhật bộ mã hóa được sao chép.

5. Thí nghiệm
Chúng tôi chứng minh hiệu quả của phương pháp chúng tôi trên các tác vụ tạo sinh có điều kiện đại diện, bao gồm siêu phân giải thế giới thực [48], tạo hình ảnh từ độ sâu [53], và chỉnh sửa hình ảnh theo hướng dẫn [3]. Chúng tôi sử dụng các mô hình khuếch tán ẩn văn bản sang hình ảnh được huấn luyện trước³ và tiến hành chưng cất có điều kiện trực tiếp từ mô hình. Mỗi phương pháp được so sánh, bao gồm cả việc huấn luyện trước văn bản sang hình ảnh, được huấn luyện độc lập trong 8 ngày trên 64 pods TPU-v4.

5.1. Kết quả
Đường cơ sở. Chúng tôi so sánh phương pháp của chúng tôi với hai phương pháp chưng cất khuếch tán SOTA trước đây, tức là các mô hình nhất quán (CM) [44] và chưng cất có hướng dẫn (GD) [23]. Chúng tôi triển khai CM với ControlNet mà không đông lạnh U-Net khử nhiễu, dẫn đến cùng kiến trúc mạng và cùng số lượng tham số như của chúng tôi. Để đầy đủ, chúng tôi xem xét hai cách khác nhau để áp dụng các kỹ thuật chưng cất được thử nghiệm, bằng cách đầu tiên làm cho mô hình có điều kiện (tinh chỉnh trước), hoặc bằng cách đầu tiên chưng cất mô hình và sau đó làm cho nó có điều kiện (chưng cất trước). Một tóm tắt các cấu hình được thử nghiệm được hiển thị trong Bảng 1. Ngoài ra, chúng tôi so sánh phương pháp của chúng tôi với các bộ giải ODE nhanh được giới thiệu gần đây, bao gồm DPM-Solver [17] và DPM-Solver++ [18].

Siêu phân giải thế giới thực. Chúng tôi đánh giá phương pháp của chúng tôi trên tác vụ siêu phân giải thế giới thực đầy thách thức, trong đó sự suy giảm được mô phỏng bằng cách sử dụng pipeline Real-ESRGAN [47]. Theo StablSR [46], chúng tôi so sánh tất cả các phương pháp trên 3.000 cặp hình ảnh bị suy giảm ngẫu nhiên. Hiệu suất định lượng được hiển thị trong Bảng 2. Kết quả chứng minh rằng phương pháp được chưng cất của chúng tôi dẫn đến hiệu suất tốt hơn đáng kể so với các kỹ thuật chưng cất khác. Phương pháp của chúng tôi đạt được kết quả tốt hơn các mô hình khuếch tán được tinh chỉnh yêu cầu 50× nhiều bước lấy mẫu hơn. So với mô hình được chưng cất bằng cách áp dụng chưng cất có hướng dẫn, mô hình của chúng tôi vượt trội hơn nó cả về định lượng và định tính. So sánh thị giác được trình bày trong Hình 4 cũng chứng minh sự vượt trội của phương pháp chúng tôi.

Vẽ đầy. Tương tự như các so sánh siêu phân giải ở trên, chúng tôi chứng minh phương pháp của chúng tôi trên tác vụ vẽ đầy có điều kiện trên hình ảnh bị che, như hiệu suất định lượng được hiển thị trong Bảng 2. Tương tự như Palette [33], chúng tôi áp dụng các mặt nạ ngẫu nhiên vào dữ liệu ImageNet [32] cho cả huấn luyện và thử nghiệm. Lưu ý rằng chúng tôi tiến hành thí nghiệm trên các hình ảnh được tăng tỷ lệ ở độ phân giải 512×512, khác với Palette ở độ phân giải 256×256. Mặc dù chúng tôi đánh giá kết quả của họ ở cùng độ phân giải, con số của họ chỉ có thể được sử dụng để tham khảo.

Tạo hình ảnh từ độ sâu. Để chứng minh tính tổng quát của phương pháp chúng tôi trên các điều kiện ít thông tin hơn, chúng tôi áp dụng phương pháp của chúng tôi trong việc tạo hình ảnh từ độ sâu. Tác vụ này thường được tiến hành trong việc tinh chỉnh mô hình khuếch tán hiệu quả tham số [24, 53], có thể chứng minh khả năng sử dụng tiên nghiệm tạo sinh văn bản sang hình ảnh. Như Hình 5 minh họa, mô hình được chưng cất của chúng tôi từ việc huấn luyện trước không có điều kiện có thể hiệu quả sử dụng các điều kiện ít thông tin và tạo ra các hình ảnh phù hợp với nhiều chi tiết hơn.

Chỉnh sửa hình ảnh theo hướng dẫn. Để chứng minh khả năng chưng cất có điều kiện của chúng tôi trên việc tạo sinh văn bản sang hình ảnh, ở đây chúng tôi áp dụng phương pháp của chúng tôi trên dữ liệu chỉnh sửa hình ảnh theo hướng dẫn văn bản [3] và so sánh mô hình được chưng cất có điều kiện của chúng tôi với mô hình InstructPix2Pix (IP2P). Như các kết quả được hiển thị trong Hình 6, kết quả lấy mẫu một bước của chúng tôi có thể đạt được chất lượng thị giác tương đương với 200 bước của mô hình IP2P. Chúng tôi thấy thực nghiệm chỉ có sự khác biệt thị giác nhỏ giữa kết quả từ lấy mẫu một bước của chúng tôi và lấy mẫu 200 bước. Chúng tôi tin rằng điều này cho thấy rằng tác động của hướng dẫn có điều kiện trên chưng cất tương quan với sự tương đồng giữa các điều kiện và dữ liệu mục tiêu, tiếp tục chứng minh hiệu quả của phương pháp chúng tôi.

5.2. Nghiên cứu Loại bỏ
Ở đây chúng tôi so sánh hiệu suất của các thiết kế nói trên trong khung chưng cất có điều kiện của chúng tôi. Cụ thể, chúng tôi tập trung vào tác vụ tạo sinh có điều kiện đại diện, tức là siêu phân giải thế giới thực [48] có điều kiện trên các hình ảnh độ phân giải thấp, nhiễu, mờ.

Kiến trúc mạng và quá trình chưng cất. Để loại bỏ tác động của thay đổi kiến trúc, chúng tôi so sánh phương pháp của chúng tôi với một đường cơ sở được đưa ra bằng cách thêm một mô-đun ControlNet được huấn luyện trên siêu phân giải mà không đông lạnh UNet. Như Bảng 3 hiển thị, việc đơn giản áp dụng một mô-đun ControlNet cho siêu phân giải có tác động không đáng kể đến hiệu suất. Để đánh giá tính nhất quán khuếch tán có điều kiện được đề xuất, chúng tôi đã loại bỏ thuật ngữ nhất quán nhiễu (phương trình 15) và sử dụng mô hình huấn luyện trong PF-ODE thay vì mô hình đông lạnh như được sử dụng trong công thức [44]. Như được hiển thị trong Bảng 3, việc áp dụng PF-ODE mô hình chưng cất và tính nhất quán không gian nhiễu có tác động tích cực đến kết quả cuối cùng. Những so sánh này chứng minh sự vượt trội của phương pháp chúng tôi mà không có tác động kiến trúc mạng.

Huấn luyện trước. Để xác nhận hiệu quả của việc tận dụng huấn luyện trước trong mô hình của chúng tôi, chúng tôi so sánh kết quả của khởi tạo ngẫu nhiên với khởi tạo từ mô hình văn bản sang hình ảnh được huấn luyện trước. Như được hiển thị trong Hình 7, phương pháp của chúng tôi vượt trội hơn đối tác được khởi tạo ngẫu nhiên bằng một biên độ lớn, từ đó xác nhận rằng chiến lược của chúng tôi thực sự sử dụng các lợi thế của huấn luyện trước trong quá trình chưng cất thay vì đơn giản học từ đầu.

Lấy mẫu của zt. Chúng tôi chỉ ra thực nghiệm rằng cách lấy mẫu zt đóng vai trò quan trọng trong quá trình học chưng cất. So với giao thức trước đây [23, 36] lấy mẫu zt trong thời gian t khác nhau trong một lô duy nhất, chúng tôi cho thấy rằng việc sử dụng thời gian t nhất quán trên các mẫu khác nhau trong một lô duy nhất dẫn đến hiệu suất tốt hơn trong mục tiêu 1-4 bước của chúng tôi. Như các so sánh được hiển thị trong Hình 7, mô hình được huấn luyện với thời gian t đơn (trong một lô duy nhất) đạt được hiệu suất tốt hơn trong cả chất lượng thị giác (tức là FID) và độ chính xác (tức là LPIPS) khi số lượng đánh giá tăng lên trong quá trình suy luận.

Hướng dẫn có điều kiện. Để chứng minh tầm quan trọng của hướng dẫn có điều kiện (CG) được đề xuất của chúng tôi cho chưng cất, được khẳng định là có khả năng điều chỉnh quá trình chưng cất trong quá trình huấn luyện, chúng tôi tiến hành so sánh giữa cài đặt sử dụng hướng dẫn có điều kiện như r = ∥x - x̂θ(zt, c)∥2² và không sử dụng như r = 0. Như kết quả được hiển thị trong Hình 7, hướng dẫn có điều kiện cải thiện cả độ trung thực của kết quả được tạo và chất lượng thị giác. Chúng tôi tiếp tục quan sát thấy rằng quá trình chưng cất sẽ hội tụ theo hướng quá bão hòa mà không có CG, do đó làm giảm chỉ số FID. Ngược lại, mô hình của chúng tôi tránh được cực tiểu cục bộ như vậy bằng cách sử dụng mất mát hướng dẫn được đề xuất.

6. Kết luận
Chúng tôi giới thiệu một khung mới để chưng cất một mô hình khuếch tán không có điều kiện thành một mô hình có điều kiện cho phép lấy mẫu với rất ít bước. Theo hiểu biết tốt nhất của chúng tôi, đây là phương pháp đầu tiên chưng cất mô hình khuếch tán có điều kiện từ việc huấn luyện trước không có điều kiện trong một giai đoạn duy nhất. So với các kỹ thuật chưng cất và tinh chỉnh hai giai đoạn trước đây, phương pháp của chúng tôi dẫn đến chất lượng tốt hơn với cùng số lượng (rất ít) bước lấy mẫu. Phương pháp của chúng tôi cũng cho phép một chưng cất hiệu quả tham số mới cho phép các mô hình được chưng cất khác nhau, được huấn luyện cho các tác vụ khác nhau, chia sẻ hầu hết các tham số của chúng. Chỉ cần một vài tham số bổ sung cho mỗi tác vụ tạo sinh có điều kiện khác nhau. Chúng tôi tin rằng phương pháp này có thể phục vụ như một cách tiếp cận thực tế mạnh mẽ để tăng tốc các mô hình khuếch tán có điều kiện quy mô lớn.

7. Lời cảm ơn
Các tác giả muốn cảm ơn các đồng nghiệp Keren Ye và Chenyang Qi đã đánh giá bản thảo và cung cấp phản hồi có giá trị. Chúng tôi cũng mở rộng lòng biết ơn đến Shlomi Fruchter, Kevin Murphy, Mohammad Babaeizadeh, và Han Zhang vì những đóng góp quan trọng của họ trong việc hỗ trợ triển khai ban đầu của các mô hình khuếch tán ẩn.

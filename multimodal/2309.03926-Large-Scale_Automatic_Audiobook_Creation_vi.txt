# 2309.03926.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2309.03926.pdf
# Kích thước tệp: 544808 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tạo Audiobook Tự Động Quy Mô Lớn
Brendan Walsh*1, Mark Hamilton*1,2, Greg Newby3, Xi Wang1, Serena Ruan1, Sheng Zhao1,
Lei He1, Shaofei Zhang1, Eric Dettinger1, William T. Freeman2,4, Markus Weimer1
1Microsoft,2MIT,3Project Gutenberg,4Google, *Đóng góp ngang nhau
Tóm tắt
Một audiobook có thể cải thiện đáng kể khả năng tiếp cận của một tác phẩm văn học và tăng cường sự tương tác của người đọc. Tuy nhiên, audiobook có thể mất hàng trăm giờ nỗ lực của con người để tạo, chỉnh sửa và xuất bản. Trong công trình này, chúng tôi trình bày một hệ thống có thể tự động tạo ra audiobook chất lượng cao từ các sách điện tử trực tuyến. Cụ thể, chúng tôi tận dụng những tiến bộ gần đây trong neural text-to-speech để tạo ra và phát hành hàng nghìn audiobook chất lượng người đọc, có giấy phép mở từ bộ sưu tập sách điện tử Project Gutenberg. Phương pháp của chúng tôi có thể xác định tập hợp con phù hợp của nội dung sách điện tử để đọc cho một bộ sưu tập đa dạng các cuốn sách có cấu trúc khác nhau và có thể hoạt động trên hàng trăm cuốn sách song song. Hệ thống của chúng tôi cho phép người dùng tùy chỉnh tốc độ đọc và phong cách của audiobook, ngữ điệu cảm xúc, và thậm chí có thể khớp với một giọng nói mong muốn bằng cách sử dụng một lượng nhỏ âm thanh mẫu. Công trình này đóng góp hơn năm nghìn audiobook có giấy phép mở và một demo tương tác cho phép người dùng nhanh chóng tạo ra audiobook tùy chỉnh của riêng họ. Để nghe bộ sưu tập audiobook hãy truy cập https://aka.ms/audiobook .

1. Giới thiệu
Audiobook đã trở thành một cách phổ biến để tiêu thụ văn học, tin tức và các xuất bản khác. Audiobook không chỉ cho phép những người đọc hiện tại có thể thưởng thức nội dung khi di chuyển, mà còn có thể giúp làm cho nội dung có thể tiếp cận được đối với các cộng đồng như trẻ em, người khiếm thị và người học ngôn ngữ mới. Các phương pháp truyền thống để sản xuất audiobook, chẳng hạn như thuyết minh bằng người chuyên nghiệp hoặc các dự án do tình nguyện viên thúc đẩy như LibriVox, tốn thời gian, tốn kém và có thể thay đổi về chất lượng ghi âm. Những yếu tố này khiến việc theo kịp tốc độ xuất bản sách ngày càng tăng trở nên khó khăn. Ngược lại, việc tạo audiobook tự động nhanh hơn, rẻ hơn và nhất quán hơn nhiều bậc độ lớn nhưng trong lịch sử đã phải chịu đựng bản chất robot của các hệ thống text-to-speech và thách thức quyết định văn bản nào không nên được đọc to (ví dụ: mục lục, số trang, hình ảnh và ghi chú cuối trang).

Chúng tôi trình bày một hệ thống vượt qua cả hai thách thức nêu trên bằng cách tạo ra audiobook chất lượng cao từ các bộ sưu tập không đồng nhất của sách điện tử trực tuyến. Cụ thể, hệ thống của chúng tôi kết hợp những tiến bộ gần đây trong neural text-to-speech, đọc cảm xúc, máy tính có thể mở rộng và phát hiện tự động văn bản liên quan để tạo ra hàng nghìn audiobook có âm thanh hợp lý. Chúng tôi đóng góp hơn năm nghìn audiobook tổng cộng khoảng ba mươi lăm nghìn giờ nói cho nguồn mở. Chúng tôi cũng đóng góp một ứng dụng demo cho phép người tham dự hội nghị tạo ra một audiobook tùy chỉnh, được đọc to bằng chính giọng nói của họ, từ bất kỳ cuốn sách nào từ bộ sưu tập chỉ sử dụng vài giây âm thanh ví dụ.

2. Công trình liên quan
LibriVox là một dự án nổi tiếng tạo ra audiobook có giấy phép mở bằng cách sử dụng tình nguyện viên. Mặc dù nó đã có những đóng góp đáng kể cho khả năng tiếp cận audiobook, chất lượng của các audiobook được sản xuất có thể không nhất quán do kỹ năng và môi trường ghi âm khác nhau của các tình nguyện viên. Hơn nữa, khả năng mở rộng của dự án bị giới hạn bởi sự sẵn có của tình nguyện viên và thời gian cần thiết để ghi âm và chỉnh sửa một audiobook duy nhất. Các nền tảng tư nhân như Audible tạo ra audiobook chất lượng cao nhưng không công bố công việc của họ một cách công khai và tính phí người dùng cho audiobook của họ. Project Gutenberg lưu trữ một bộ sưu tập rộng lớn các sách điện tử miễn phí và một vài audiobook. Các audiobook hiện có của họ có giọng nói text-to-speech robot hạn chế khả năng lắng nghe.

Text-to-speech là một vấn đề được nghiên cứu kỹ lưỡng và các phương pháp deep learning gần đây như WaveNet [1], Tacotron [2] và Fastspeech [3] đã cho thấy tiến bộ đáng kể hướng tới việc tạo ra giọng nói cạnh tranh với chất lượng và sự tự nhiên của con người. Ngược lại, vấn đề lựa chọn văn bản nào để đọc từ một sách điện tử đã nhận được ít sự chú ý hơn đáng kể. Tuy nhiên, công trình gần đây của [4] đã khám phá liệu có thể dự đoán "vị trí bắt đầu đọc" bằng cách sử dụng các mô hình dựa trên LSTM hay không nhưng không giải quyết việc làm sạch văn bản không liên quan khác trong toàn bộ nội dung của một sách điện tử.

3. Phương pháp
Công trình này giới thiệu một hệ thống có thể mở rộng có khả năng chuyển đổi sách điện tử dựa trên HTML thành audiobook chất lượng cao. Pipeline của chúng tôi được xây dựng bằng SynapseML[5], một framework machine learning có thể mở rộng cho phép điều phối phân tán toàn bộ quá trình tạo audiobook.

3.1. Phân tích cú pháp HTML sách điện tử
Pipeline của chúng tôi bắt đầu với hàng nghìn sách điện tử miễn phí được cung cấp bởi Project Gutenberg. Các sách điện tử này được cung cấp ở nhiều định dạng khác nhau, và công việc của chúng tôi tập trung vào định dạng HTML của chúng, định dạng phù hợp nhất cho việc phân tích cú pháp tự động. Việc phân tích cú pháp bộ sưu tập cực kỳ không đồng nhất và đa dạng này của sách điện tử là thách thức lớn nhất mà chúng tôi gặp phải. Project Gutenberg không chuẩn hóa nội dung của các tệp HTML và các sách điện tử của nó chứa một lượng lớn văn bản không liên quan đến người đọc âm thanh bao gồm lời nói đầu, mục lục, bảng, minh họa, số trang trong văn bản, ghi chú cuối trang, ghi chú của người phiên âm và các tạo tác kỳ lạ khác.

Để tạo ra một tập hợp con chất lượng cao của sách điện tử, trước tiên chúng tôi đặc trưng hóa cây Document Object Model (DOM) HTML của mỗi sách điện tử bằng cách sử dụng sự kết hợp của các tính năng HTML tự động (thống kê TF-IDF trên Thành phần HTML) và được chế tạo thủ công. Điều này cho phép

--- TRANG 2 ---
Hình 1: Biểu diễn t-SNE của các Sách điện tử được phân cụm. Các khu vực màu đại diện cho các cụm sách được định dạng đồng nhất.

chúng tôi phân cụm và trực quan hóa toàn bộ bộ sưu tập các tệp HTML Project Gutenberg và cho phép chúng tôi tìm thấy một số nhóm lớn các tệp có cấu trúc thông thường. Chúng tôi đã sử dụng các cụm tệp HTML này để xây dựng một bộ chuẩn hóa HTML dựa trên quy tắc đã chuyển đổi các lớp sách điện tử lớn nhất thành một biểu diễn tiêu chuẩn có thể được phân tích cú pháp tự động. Phân tích này cho phép chúng tôi tạo ra một hệ thống có thể nhanh chóng và xác định phân tích cú pháp một số lượng lớn sách. Quan trọng nhất, nó cũng cho phép chúng tôi hạn chế sự chú ý vào một tập hợp con các tệp sẽ tạo ra các bản ghi âm chất lượng cao khi được đọc. Hình 1 cho thấy kết quả của quy trình phân cụm này, chứng minh rằng một số cụm sách điện tử có cấu trúc tương tự tự nhiên xuất hiện trong bộ sưu tập Project Gutenberg. Sau khi được phân tích cú pháp, chúng tôi có thể trích xuất một luồng văn bản thuần túy để cung cấp cho các thuật toán text-to-speech.

3.2. Tạo ra Giọng nói Chất lượng Cao
Các audiobook khác nhau yêu cầu các phong cách đọc khác nhau. Các tác phẩm phi hư cấu hưởng lợi từ một giọng nói rõ ràng và trung tính trong khi các tác phẩm hư cấu có đối thoại có thể hưởng lợi từ việc đọc cảm xúc và một số "diễn xuất". Đối với phần lớn các cuốn sách, chúng tôi sử dụng một giọng nói neural text-to-speech rõ ràng và trung tính. Tuy nhiên, trong demo trực tiếp của chúng tôi, chúng tôi sẽ trình bày cho người dùng khả năng tùy chỉnh giọng nói, tốc độ, cao độ và ngữ điệu của văn bản.

Để nhân bản giọng nói của người dùng, chúng tôi sử dụng các phương pháp text-to-speech zero-shot [6] để chuyển giao hiệu quả các đặc tính giọng nói từ các bản ghi âm đăng ký hạn chế. Điều này cho phép người dùng nhanh chóng tạo ra một audiobook bằng giọng nói của riêng họ bằng cách sử dụng một lượng nhỏ âm thanh được ghi âm.

Để tạo ra việc đọc cảm xúc của văn bản, chúng tôi sử dụng một hệ thống suy luận người nói và cảm xúc tự động để thay đổi động giọng đọc và giai điệu dựa trên ngữ cảnh. Điều này làm cho các đoạn văn với nhiều nhân vật và đối thoại cảm xúc trở nên sống động và hấp dẫn hơn. Để đạt được mục đích này, trước tiên chúng tôi phân đoạn văn bản thành tường thuật và đối thoại và xác định người nói cho mỗi phần đối thoại. Sau đó, chúng tôi dự đoán cảm xúc của mỗi đối thoại bằng cách sử dụng [7] theo cách tự giám sát. Cuối cùng, chúng tôi gán các giọng nói và cảm xúc riêng biệt cho người tường thuật và đối thoại nhân vật bằng cách sử dụng mô hình neural text-to-speech đa phong cách và dựa trên ngữ cảnh được đề xuất trong [8].

4. Bộ sưu tập Audiobook Mở Project Gutenberg
Chúng tôi giới thiệu Bộ sưu tập Audiobook Mở Project Gutenberg: hơn năm nghìn audiobook chất lượng cao được tạo ra từ bộ sưu tập Project Gutenberg và có sẵn để tải xuống miễn phí và sử dụng mở. Chúng tôi lưu trữ các tệp này như một tệp zip duy nhất cho cộng đồng nghiên cứu cũng như trên các nền tảng lưu trữ tệp podcast và âm thanh chính để sử dụng bởi cộng đồng rộng lớn hơn. Bộ sưu tập này cung cấp hơn ba mươi lăm nghìn giờ nội dung bao gồm văn học cổ điển, phi hư cấu, kịch và các tác phẩm tiểu sử được tường thuật bằng một giọng nói rõ ràng và nhất quán. Chúng tôi hy vọng đóng góp này có thể mang lại giá trị cho cả cộng đồng nghiên cứu và cộng đồng người nghe audiobook rộng lớn hơn.

5. Demo
Chúng tôi dự định tổ chức một ứng dụng demo trực tiếp cho phép người tham dự hội nghị tạo ra audiobook tùy chỉnh của riêng họ bằng cách sử dụng hệ thống của chúng tôi. Người dùng sẽ bắt đầu bằng cách chọn một cuốn sách từ 5.000 tiêu đề trong bộ sưu tập của chúng tôi bằng cách sử dụng giao diện tìm kiếm đơn giản. Sau đó họ có thể chọn giọng nói mà họ muốn sử dụng cho bản ghi âm từ một bộ sưu tập lớn các giọng nói trung tính và nhận thức cảm xúc hiện có hoặc thậm chí giọng nói của chính họ. Nếu người dùng muốn tạo ra một audiobook tùy chỉnh bằng giọng nói của riêng họ, họ sẽ được yêu cầu nói một vài câu để nhanh chóng huấn luyện một hồ sơ giọng nói tùy chỉnh. Người dùng sẽ có thể nghe bản xem trước audiobook của họ trong thời gian thực và thêm một lời cảm ơn tùy chỉnh tùy chọn trước khi gửi một công việc lớn hơn đọc toàn bộ cuốn sách. Khi pipeline hoàn thành, chúng tôi sẽ gửi email cho người dùng một liên kết để tải xuống audiobook tùy chỉnh của họ.

6. Kết luận
Trong công trình này, chúng tôi trình bày một pipeline mới để tự động hóa việc tạo ra audiobook chất lượng cao từ các sách điện tử không đồng nhất. Hệ thống của chúng tôi sử dụng những tiến bộ mới trong neural text-to-speech, nhận dạng cảm xúc, nhân bản giọng nói tùy chỉnh và máy tính phân tán để tạo ra audiobook hấp dẫn và sống động. Chúng tôi áp dụng hệ thống này để tặng hơn năm nghìn audiobook cho cộng đồng nguồn mở và nhằm mục đích trình diễn hệ thống này bằng cách cho phép người tham dự hội nghị tạo ra audiobook tùy chỉnh. Chúng tôi tin rằng công trình này có tiềm năng cải thiện đáng kể khả năng tiếp cận và tính sẵn có của audiobook.

7. Tài liệu tham khảo
[1] A. van den Oord và cộng sự, "Wavenet: A generative model for raw audio," 2016.
[2] Y. Wang và cộng sự, "Tacotron: Towards end-to-end speech synthesis," trong Proc. INTERSPEECH 2017 Annual Conference of the International Speech Communication Association, 2017, trang 4006–4010.
[3] Y. Ren và cộng sự, "Fastspeech: Fast, robust and controllable text to speech," trong Advances in Neural Information Processing Systems, 2019, trang 3165–3174.
[4] S. B. Bodapati và cộng sự, "A machine learning approach to detecting start reading location of ebooks," trong 2018 IEEE International Conference on Data Mining Workshops (ICDMW). IEEE, 2018, trang 1522–1529.
[5] M. Hamilton và cộng sự, "Flexible and scalable deep learning with mmlspark," trong Proceedings of The 4th International Conference on Predictive Applications and APIs, ser. Proceedings of Machine Learning Research, tập 82. PMLR, 24–25 Oct 2018, trang 11–22.
[6] Y. Wu và cộng sự, "Adaspeech 4: Adaptive text to speech in zero-shot scenarios," trong Proc. INTERSPEECH 2022 Annual Conference of the International Speech Communication Association, 2022, trang 2568–2572.
[7] ——, "Self-supervised context-aware style representation for expressive speech synthesis," trong Proc. INTERSPEECH 2022 Annual Conference of the International Speech Communication Association, 2022, trang 5503–5507.
[8] H. Guo và cộng sự, "Conversational end-to-end tts for voice agent," trong Proc. SLT 2021 IEEE Spoken Language Technology Workshop, 2021, trang 403–409.

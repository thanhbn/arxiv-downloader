# Honeybee: Bộ Chiếu Tăng Cường Địa Phương cho MLLM Đa Phương Thức

Junbum Cha* Wooyoung Kang* Jonghwan Mun* Byungseok Roh
Kakao Brain
{junbum.cha, edwin.kang, jason.mun, peter.roh }@kakaobrain.com

## Tóm tắt

Trong các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM), bộ chiếu thị giác đóng vai trò quan trọng trong việc kết nối các bộ mã hóa thị giác được huấn luyện trước với LLM, cho phép hiểu biết thị giác sâu sắc trong khi khai thác các khả năng mạnh mẽ của LLM. Mặc dù tầm quan trọng của bộ chiếu thị giác, nó vẫn chưa được khám phá nhiều. Trong nghiên cứu này, chúng tôi đầu tiên xác định hai thuộc tính cần thiết của bộ chiếu: (i) tính linh hoạt trong việc quản lý số lượng token thị giác, quan trọng cho hiệu quả tổng thể của MLLM, và (ii) bảo toàn ngữ cảnh địa phương từ các đặc trưng thị giác, quan trọng cho hiểu biết không gian. Dựa trên những phát hiện này, chúng tôi đề xuất một thiết kế bộ chiếu mới vừa linh hoạt vừa tăng cường địa phương, đáp ứng hiệu quả hai thuộc tính mong muốn. Ngoài ra, chúng tôi trình bày các chiến lược toàn diện để sử dụng hiệu quả nhiều tập dữ liệu hướng dẫn đa diện. Thông qua các thí nghiệm mở rộng, chúng tôi kiểm tra tác động của các lựa chọn thiết kế riêng lẻ. Cuối cùng, MLLM được đề xuất của chúng tôi, Honeybee, vượt trội đáng kể so với các phương pháp tiên tiến trước đó trên nhiều tiêu chuẩn khác nhau, bao gồm MME, MMBench, SEED-Bench, và LLaVA-Bench, đạt được hiệu quả cao hơn đáng kể. Mã và mô hình có sẵn tại https://github.com/kakaobrain/honeybee.

## 1. Giới thiệu

Các Mô hình Ngôn ngữ Lớn (LLM) đã có tiến bộ lớn trong những năm gần đây, chủ yếu nhờ vào điều chỉnh hướng dẫn. Điều chỉnh hướng dẫn thị giác [34] đã được đề xuất để mở rộng LLM thành các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM) để nhận thức và hiểu các tín hiệu thị giác (ví dụ: hình ảnh). Ý tưởng chính cho MLLM là giới thiệu một bộ chiếu kết nối bộ mã hóa thị giác và LLM, và học bộ chiếu sử dụng dữ liệu hướng dẫn thị giác trong khi giữ các tham số của bộ mã hóa thị giác và LLM. Kỹ thuật đơn giản như vậy cho phép bảo toàn và tận dụng kiến thức và khả năng được huấn luyện trước trong bộ mã hóa thị giác và LLM, làm cho các MLLM kết quả mở khóa các khả năng mới, chẳng hạn như tạo ra câu chuyện, thơ, quảng cáo, mã và hơn thế nữa từ các hình ảnh đã cho; những nhiệm vụ này theo truyền thống được coi là thách thức đối với các mô hình cơ sở ngôn ngữ-thị giác thông thường [56, 59].

Thành công như vậy dẫn đến sự chú ý ngày càng tăng đối với nghiên cứu về MLLM nhận đầu vào đa phương thức (ví dụ: video [28], âm thanh [13], thế giới 3d [17], đám mây điểm [52]) ngoài văn bản.

Đối với MLLM, bộ chiếu đóng vai trò quan trọng trong hai khía cạnh sau: 1) hiệu suất: vì nó kết nối các mô hình thị giác và ngôn ngữ bằng cách dịch các đặc trưng thị giác thành token thị giác để mô hình ngôn ngữ có thể hiểu, chất lượng của các token thị giác được truyền tải trực tiếp tác động đến hiệu suất tổng thể của MLLM; và 2) hiệu quả: vì phần lớn gánh nặng tính toán nằm ở mô hình ngôn ngữ, hiệu quả của MLLM bị ảnh hưởng mạnh bởi số lượng token thị giác kết quả. Tuy nhiên, mặc dù có tầm quan trọng quyết định, bộ chiếu vẫn tương đối chưa được khám phá trong văn học và hầu hết các MLLM chỉ đơn giản áp dụng các bộ chiếu tuyến tính [7, 34] hoặc bộ trừu tượng hóa [2, 11, 27, 54, 66].

Đáng chú ý, các MLLM gần đây ưa thích các bộ trừu tượng hóa (ví dụ: resampler, Q-former) hơn các bộ chiếu tuyến tính; điều này chủ yếu là do tính linh hoạt của chúng trong việc xử lý số lượng token thị giác kết quả, do đó cung cấp các tùy chọn thiết kế đa dạng để đạt được sự cân bằng lý tưởng giữa hiệu quả và hiệu suất. Tuy nhiên, như được hiển thị trong Hình 3, các bộ trừu tượng hóa gặp nhiều khó khăn hơn trong việc học các nhiệm vụ hiểu biết không gian so với các bộ chiếu tuyến tính. Khó khăn này xuất phát từ quá trình trừu tượng hóa thiếu thiết kế nhận thức về địa phương, điều này khiến nó chủ yếu tập trung vào một vài vùng, dẫn đến mất đi các chi tiết tinh vi cần thiết cho hiểu biết không gian. Ngược lại, các bộ chiếu tuyến tính xuất sắc trong việc bảo toàn tất cả các ngữ cảnh địa phương của đặc trưng thị giác thông qua phép biến đổi một-một. Việc bảo toàn mạnh mẽ tính địa phương này cho phép hiểu biết không gian hiệu quả.

Được thúc đẩy bởi điều này, chúng tôi đề xuất các bộ chiếu tăng cường địa phương mới, thể hiện sự cân bằng thuận lợi hơn giữa hiệu suất (bằng cách bảo toàn địa phương) và hiệu quả (bằng khả năng trừu tượng hóa) như được trình bày trong Hình 1. Cụ thể, chúng tôi giới thiệu hai bộ chiếu tăng cường địa phương bằng cách sử dụng hai phép toán mạnh mẽ trong mô hình hóa địa phương - tích chập và chú ý có thể biến dạng. Việc tiêm thiết kế nhận thức về địa phương như vậy vào quá trình trừu tượng hóa không chỉ thúc đẩy cải thiện hiệu suất tổng thể của MLLM trong việc xử lý thông tin thị giác phức tạp mà còn tận dụng hiệu quả tính toán trong giai đoạn tạo phản hồi tiếp theo của LLM.

Trên cơ sở MLLM với bộ chiếu tăng cường địa phương, được đặt tên là Honeybee, chúng tôi cung cấp một công thức bí mật cho các MLLM tiên tiến. Đáng chú ý, một chiến lược phổ biến trong việc huấn luyện MLLM gần đây liên quan đến nhiều dữ liệu hướng dẫn: 1) tập dữ liệu theo hướng dẫn được GPT hỗ trợ như LLaVA [34] và 2) tập dữ liệu nhiệm vụ ngôn ngữ-thị giác với quá trình hướng dẫn hóa [11]. Để tận dụng tối đa những lợi ích từ các tập dữ liệu này, chúng tôi trình bày các lựa chọn thiết kế quan trọng nhưng ít được khám phá cho 1) cách sử dụng dữ liệu hướng dẫn đa diện và 2) cách hiệu quả cho quá trình hướng dẫn hóa. Chúng tôi thực hiện các thí nghiệm mở rộng để xác minh tác động của các lựa chọn thiết kế riêng lẻ trên các tiêu chuẩn đa dạng và hy vọng cung cấp những hiểu biết có giá trị vào việc huấn luyện MLLM mạnh mẽ.

Những đóng góp chính của chúng tôi được tóm tắt như sau:

• Chúng tôi xác định hai thuộc tính quan trọng của bộ chiếu, 1) bảo toàn địa phương của đặc trưng thị giác và 2) tính linh hoạt để quản lý số lượng token thị giác, và đề xuất các bộ trừu tượng hóa tăng cường địa phương để đạt được điều tốt nhất của cả hai thế giới.

• Chúng tôi đề xuất một cách (bí mật) hiệu quả để giải quyết các tập dữ liệu đa diện cũng như quá trình hướng dẫn hóa, tối đa hóa lợi ích từ dữ liệu hướng dẫn.

• Với bộ chiếu tăng cường địa phương và các công thức bí mật đã khám phá, Honeybee của chúng tôi đạt được hiệu suất tiên tiến trên các tiêu chuẩn MLLM khác nhau—MME, MMBench, SEED-Bench, và LLaVA-Bench (Bảng 1).

## 2. Công trình liên quan

### 2.1. Mô hình Ngôn ngữ Lớn Đa phương thức

Các khả năng theo hướng dẫn và khái quát hóa đáng chú ý của các LLM gần đây đã dẫn đến việc mở rộng LLM thành các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM). Các công trình đầu tiên như Flamingo [1] và BLIP-2 [27] đã thích ứng thành công LLM với các nhiệm vụ thị giác, cho thấy khả năng khái quát hóa zero-shot và học trong ngữ cảnh đáng chú ý. Gần đây hơn, các MLLM được cải tiến thêm chủ yếu thông qua điều chỉnh hướng dẫn thị giác, bao gồm việc sử dụng các tập dữ liệu ngôn ngữ-thị giác (VL) [2, 11, 61] và tăng cường dữ liệu theo hướng dẫn thị giác [32, 34, 40, 63, 65, 66]. Ngoài ra, một số nghiên cứu tập trung vào khả năng định vị của MLLM bằng cách sử dụng các tập dữ liệu bổ sung được thiết kế đặc biệt cho những nhiệm vụ này [7, 45, 53, 55]. Tuy nhiên, các MLLM gần đây vẫn chưa khám phá sâu các bộ chiếu thị giác, mặc dù thiết kế phù hợp của các bộ chiếu là quan trọng trong cả hiệu quả và hiệu suất của MLLM.

### 2.2. Dữ liệu Theo Hướng dẫn Đa phương thức

Sự đột phá từ GPT-3 [4] đến ChatGPT [43] làm nổi bật tầm quan trọng của dữ liệu theo hướng dẫn trong việc trao quyền cho LLM để hiểu và tuân theo các hướng dẫn ngôn ngữ tự nhiên. Tương tự, việc tích hợp dữ liệu hướng dẫn thị giác là cần thiết để huấn luyện MLLM xử lý các hướng dẫn khác nhau, từ đó tăng tính linh hoạt của chúng. Một số nghiên cứu sử dụng một LLM mạnh mẽ, ví dụ GPT-4 [44], để tạo ra dữ liệu hướng dẫn thị giác cho các nhiệm vụ VL phức tạp, chẳng hạn như tạo ra câu chuyện, thơ, chú thích chi tiết từ các hình ảnh đã cho [32, 34, 63, 65, 66]. Một hướng nghiên cứu khác đã khám phá việc chuyển đổi các tập dữ liệu nhiệm vụ VL hiện có thành định dạng theo hướng dẫn bằng cách sử dụng các mẫu được định nghĩa trước, gọi là hướng dẫn hóa [2, 11, 33, 61]. Trong khi có sự phát triển và mở rộng tích cực của các tập dữ liệu theo hướng dẫn, nghiên cứu tập trung vào cách kết hợp và sử dụng các tập dữ liệu này vẫn chưa được khám phá đầy đủ.

### 2.3. Tiêu chuẩn cho MLLM

MME [14], MMBench [35], và SEED-Bench [25] đã được giới thiệu như các tiêu chuẩn toàn diện cho đánh giá khách quan các MLLM với các câu hỏi có/không hoặc lựa chọn đa phương án. Các tiêu chuẩn này bao gồm một phổ rộng các nhiệm vụ đánh giá, từ phân tích nhận thức thô và tinh đến các nhiệm vụ suy luận thị giác. Mặt khác, khi các khả năng của MLLM phát triển để xử lý các nhiệm vụ VL phức tạp hơn như kể chuyện thị giác và tuân theo hướng dẫn theo cách mở với văn bản tự do, các loại tiêu chuẩn khác đã được đề xuất, tức là đánh giá chủ quan. Theo các nghiên cứu NLP [9, 36], một số nghiên cứu tận dụng các LLM mạnh mẽ, ví dụ GPT-4 [44], để đánh giá chất lượng phản hồi của MLLM [3, 34, 58]. Cách tiếp cận này nhằm mục đích đánh giá chi tiết hơn về trình độ của MLLM. Trong bài báo này, chúng tôi nhằm mục đích cung cấp những hiểu biết có giá trị vào việc huấn luyện một MLLM mạnh mẽ và hiệu suất cao thông qua phân tích mở rộng.

## 3. Honeybee: MLLM Tăng cường Địa phương

### 3.1. Tổng quan

Nói chung, mục tiêu của các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM) là học một mô hình có thể tạo ra các phản hồi theo hướng dẫn cho các đầu vào đa phương thức đã cho. Trong bài báo này, chúng tôi xem xét hình ảnh như một đầu vào phương thức bổ sung cho MLLM. Do đó, mô hình ngôn ngữ trở thành người nhận của cả token thị giác và token văn bản (hướng dẫn) trong khi tạo ra phản hồi văn bản theo cách tự hồi quy. Hình thức, một đầu vào đa phương thức bao gồm hai loại token: token hình ảnh X_img và token văn bản X_text. Sau đó, mô hình ngôn ngữ dự đoán phản hồi Y={w_i}^L_{i=1} có điều kiện trên đầu vào đa phương thức trong đó L có nghĩa là số token trong phản hồi. Do đó, phản hồi được dự đoán bởi

p(Y|X_img,X_text) = ∏_{i=1}^L p(w_i|X_img,X_text, w_{<i}). (1)

Kiến trúc. MLLM thường được cấu thành từ ba mạng: 1) bộ mã hóa thị giác, 2) bộ chiếu, và 3) mô hình ngôn ngữ lớn (LLM). Bộ mã hóa thị giác cung cấp một chuỗi các đặc trưng thị giác cấp vùng để hiểu hình ảnh chi tiết. Bộ chiếu chịu trách nhiệm chuyển đổi các đặc trưng thị giác thành token thị giác cho mô hình ngôn ngữ tiếp theo. Sau đó, LLM xử lý các token thị giác và hướng dẫn được kết hợp và tạo ra phản hồi tự hồi quy.

Hiệu quả của MLLM. Trong kiến trúc MLLM, LLM chủ yếu chiếm toàn bộ tính toán và tiêu thụ bộ nhớ của MLLM. Do đó, với cùng một LLM, hiệu quả của MLLM—về mặt tính toán, tiêu thụ bộ nhớ, và thông lượng—chủ yếu bị ảnh hưởng không phải bởi hiệu quả của bộ mã hóa thị giác và bộ chiếu, mà bởi số lượng token thị giác kết quả được đưa vào LLM. Điều này cũng được thể hiện trong Hình 1 và Phụ lục A.

Xem xét lại các bộ chiếu hiện có. Bộ chiếu nhận N đặc trưng thị giác và chuyển đổi chúng thành M token thị giác. Đối với bộ chiếu, MLLM áp dụng một phép toán giữa phép chiếu tuyến tính và trừu tượng hóa các đặc trưng thị giác. Phép chiếu tuyến tính đơn giản nhưng hiệu quả, đặc biệt trong việc bảo toàn kiến thức và hiểu biết của bộ mã hóa thị giác (ví dụ: tính địa phương của đặc trưng thị giác), nhưng gặp thách thức về khả năng mở rộng và hiệu quả, chủ yếu do ràng buộc cố có của phép biến đổi một-một giữa đặc trưng thị giác và token (tức là M=N). Mặt khác, việc trừu tượng hóa cung cấp một cách tiếp cận thích ứng hơn để xác định số lượng token thị giác (M). Ví dụ, resampler và Q-former sử dụng M (thường < N để có hiệu quả) truy vấn có thể học và chú ý chéo để trích xuất gợi ý thị giác từ đặc trưng thị giác [1, 2, 11, 54, 66]. Trong khi tính linh hoạt như vậy bằng trừu tượng hóa cho phép hiệu quả tốt hơn, nhưng nó có thể vốn dĩ gặp rủi ro mất thông tin từ bộ mã hóa thị giác.

### 3.2. Bộ Chiếu Tăng cường Địa phương

Trong phần này, chúng tôi đầu tiên mô tả động lực của chúng tôi cho các bộ chiếu tăng cường địa phương. Sau đó, chúng tôi trình bày hai loại bộ chiếu tăng cường địa phương (C-Abstractor và D-Abstractor) và mô tả pipeline huấn luyện.

#### 3.2.1 Động lực

Bộ chiếu rất quan trọng vì nó kết nối các mô hình thị giác và ngôn ngữ, dịch các đặc trưng hình ảnh thành một định dạng có thể hiểu được và sử dụng được bởi mô hình ngôn ngữ. Xem xét vai trò của nó, khi thiết kế một bộ chiếu, yếu tố quan trọng nhất là tính linh hoạt trong việc quyết định số lượng token thị giác kết quả. Như được mô tả ở trên, số lượng token thị giác được tạo ra bởi bộ chiếu xác định hiệu quả tổng thể và lượng tính toán của MLLM. Xem xét kịch bản xử lý nhiều hình ảnh hoặc hình ảnh lớn, việc cải thiện hiệu quả thông qua tính linh hoạt trong việc giảm số lượng token thị giác là rất cần thiết cho khả năng mở rộng. Yêu cầu này đã dẫn đến việc ưa thích các bộ trừu tượng hóa như resampler và Q-former hơn các bộ chiếu tuyến tính trong các MLLM gần đây [2, 11, 27, 54].

Tuy nhiên, chúng tôi quan sát thấy resampler gặp khó khăn trong việc giải quyết các nhiệm vụ hiểu biết không gian so với bộ chiếu tuyến tính. Lưu ý rằng một bộ chiếu tuyến tính giữ lại tất cả ngữ cảnh địa phương của đặc trưng thị giác thông qua phép chiếu một-một không mất mát. Ngược lại, trong Hình 3, resampler có xu hướng tóm tắt thông tin chủ yếu từ một vài vùng (ví dụ: người đàn ông) trong khi có thể bỏ qua các chi tiết trong một số vùng địa phương (ví dụ: bữa ăn, cốc, người phía sau). Chúng tôi tin rằng sự khác biệt này giữa hai mô hình trong việc bảo toàn tất cả ngữ cảnh địa phương (trong quá trình trừu tượng hóa) đã tác động đáng kể đến hiệu suất hiểu biết không gian.

Xuất phát từ những quan sát này, chúng tôi đề xuất hai bộ chiếu thị giác mới, C-Abstractor và D-Abstractor, dưới hai nguyên tắc thiết kế chính: (i) cho phép tính linh hoạt về số lượng token thị giác và (ii) bảo toàn hiệu quả ngữ cảnh địa phương. Những bộ chiếu mới này được thiết kế để duy trì điểm mạnh của bộ trừu tượng hóa, chẳng hạn như hiệu quả tính toán thông qua tính linh hoạt trong việc quản lý số lượng token thị giác, đồng thời cũng cải thiện việc bảo toàn các đặc trưng địa phương. Việc tăng cường này không chỉ tăng hiệu suất tổng thể của MLLM trong việc xử lý thông tin thị giác phức tạp mà còn được hưởng lợi từ hiệu quả tính toán trong giai đoạn tạo phản hồi tiếp theo của LLM. So sánh khái niệm giữa các bộ chiếu hiện có và được đề xuất được minh họa trong Hình 2.

#### 3.2.2 Kiến trúc

C-Abstractor. Trong học sâu, tích chập đã là kiến trúc thành công nhất để mô hình hóa ngữ cảnh địa phương [24, 49, 51]. Do đó, chúng tôi thiết kế Bộ trừu tượng hóa tích chập, C-Abstractor, để mô hình hóa ngữ cảnh địa phương hiệu quả. Hình 4a mô tả toàn bộ kiến trúc, bao gồm L khối ResNet [51] theo sau bởi pooling trung bình thích ứng và L khối ResNet khác. Thiết kế này cho phép trừu tượng hóa các đặc trưng thị giác thành bất kỳ số lượng token thị giác nào là số chính phương, và thậm chí chiếu thành nhiều token thị giác hơn số lượng đặc trưng thị giác ban đầu. Chúng tôi cũng đã thử nghiệm một số biến thể [37, 49] trong Phụ lục B, nhưng ResNet [51] cho thấy hiệu suất tốt nhất.

D-Abstractor. Trong khi tích chập là một khái niệm thành công trong mô hình hóa ngữ cảnh địa phương, người ta có thể tranh luận rằng nó giới thiệu thiên kiến quy nạp quá chặt chẽ đối với tính địa phương. Do đó, chúng tôi đề xuất Bộ trừu tượng hóa dựa trên chú ý có thể biến dạng, D-Abstractor, tăng cường nhận thức về địa phương của resampler trong quá trình trừu tượng hóa trong khi giữ tính linh hoạt của nó. Cụ thể, chú ý có thể biến dạng [67] có lợi trong việc bảo toàn ngữ cảnh địa phương; mỗi truy vấn có thể học thu thập các đặc trưng thị giác thông qua một quy trình lấy mẫu dựa trên tọa độ 2-D sử dụng các điểm tham chiếu và độ lệch lấy mẫu tập trung gần các điểm tham chiếu. Ở đây, chúng tôi đề xuất một phương pháp khởi tạo tiên tiến của các điểm tham chiếu trong đó các điểm tham chiếu được khởi tạo thủ công, phân phối đều trên toàn bộ bản đồ đặc trưng. Kỹ thuật bổ sung này cho phép D-Abstractor nắm bắt thông tin tinh vi và toàn diện cho một hình ảnh đã cho. Các giải thích chi tiết hơn được đưa ra trong Phụ lục B.

### 3.3. Huấn luyện

Chúng tôi huấn luyện Honeybee trong pipeline hai giai đoạn. Trong giai đoạn đầu tiên, chúng tôi đóng băng bộ mã hóa thị giác và LLM, tập trung vào việc huấn luyện bộ chiếu tăng cường địa phương được đề xuất. Trong giai đoạn thứ hai, chúng tôi huấn luyện cả bộ chiếu và LLM để tăng cường khả năng hiểu biết thị giác sâu hơn và khả năng tạo ra.

Huấn luyện trước để căn chỉnh ngôn ngữ-thị giác. Mục tiêu của huấn luyện trước là học một bộ chiếu thị giác mới được giới thiệu để xây dựng kết nối giữa bộ mã hóa thị giác và LLM. Sử dụng dữ liệu hình ảnh-văn bản (ví dụ: BlipCapFilt [26], COYO [5]), huấn luyện trước cho phép MLLM phát triển hiểu biết tinh tế về cách các gợi ý thị giác căn chỉnh với các mô tả văn bản. Trong quá trình huấn luyện trước, bộ mã hóa thị giác và LLM được đóng băng để giữ sự hiểu biết cơ bản đã được thiết lập trong các mô hình thị giác và ngôn ngữ.

Điều chỉnh hướng dẫn thị giác. Sau huấn luyện trước của bộ chiếu để căn chỉnh ngôn ngữ-thị giác, trong giai đoạn thứ hai, chúng tôi huấn luyện chung bộ chiếu và LLM để tăng cường khả năng theo hướng dẫn và đạt được hiểu biết thị giác sâu sắc hơn. Để theo hướng dẫn, chúng tôi sử dụng hai tập dữ liệu theo hướng dẫn được GPT hỗ trợ, LLaVA [34] và ShareGPT [10]. Ngoài ra, để tăng cường hiểu biết thị giác, chúng tôi hướng dẫn hóa một loạt các tập dữ liệu hiện có bằng cách sử dụng các mẫu, như được liệt kê trong Bảng 2. Cụ thể, cách tiếp cận của chúng tôi bao gồm: 1) sử dụng một loạt các nhiệm vụ như VQA mở [16, 20, 31, 42], VQA lựa chọn đa phương án [39, 48], chú thích [5, 26], và hiểu biết biểu thức tham chiếu (định vị thị giác và chú thích có định vị) [21, 23, 41, 57]; 2) sử dụng nhiều tập dữ liệu cho mỗi nhiệm vụ; 3) áp dụng một mẫu tinh vi nhưng duy nhất cho mỗi tập dữ liệu. Các ví dụ và mô tả chi tiết có trong Phụ lục E. Chúng tôi khám phá kỹ lưỡng các chiến lược hướng dẫn hóa dựa trên mẫu và việc sử dụng các tập dữ liệu đa diện trong Phần 4.

## 4. Công thức Bí mật cho Điều chỉnh Hướng dẫn Thị giác

Trong Phần 3, chúng tôi kiểm tra các hạn chế của các bộ chiếu hiện tại và đề xuất các phương pháp để tăng cường tính địa phương. Tuy nhiên, một công thức rõ ràng để huấn luyện các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM) tiên tiến vẫn chưa rõ ràng. Trong khi việc điều chỉnh hướng dẫn sử dụng các tập dữ liệu hiện có với hướng dẫn hóa dựa trên mẫu được biết đến rộng rãi là có lợi [2, 11, 33], các chi tiết của quá trình hướng dẫn hóa vẫn chưa được khám phá đầy đủ—các câu hỏi vẫn tồn tại về lựa chọn tập dữ liệu, sử dụng và các chiến lược kết hợp. Trong phần này, chúng tôi nhằm mục đích làm rõ các khía cạnh này thông qua việc tuân theo năm câu hỏi nghiên cứu: (i) Mỗi tập dữ liệu đóng góp đến mức nào cho hiệu suất của các nhiệm vụ cụ thể? (ii) Chiến lược cân bằng hiệu quả giữa các tập dữ liệu đa dạng là gì? (iii) Mức độ chi tiết phù hợp cho các mẫu là gì? (iv) Tính đa dạng của các mẫu quan trọng như thế nào? (v) Các mẫu đa lượt giống như cuộc trò chuyện có mang lại lợi ích bổ sung không?

Kết hợp tập dữ liệu. Trong các nghiên cứu MLLM gần đây, một loạt tập dữ liệu đa dạng đã được sử dụng để huấn luyện các MLLM mạnh mẽ [2, 6, 11, 33, 61]. Thực hành phổ biến này, tuy nhiên, không đi kèm với phân tích toàn diện để xác định tập dữ liệu nào là quan trọng cho các nhiệm vụ cụ thể. Để cung cấp phân tích sâu về điều này, chúng tôi thiết kế một thí nghiệm ablation có hệ thống. Như được nêu trong Bảng 2, chúng tôi phân loại các tập dữ liệu thành một số nhóm nhiệm vụ. Sau đó, chúng tôi kiểm tra các biến thể trong hiệu suất tiêu chuẩn bằng cách loại trừ tuần tự mỗi nhóm nhiệm vụ trong quá trình điều chỉnh hướng dẫn. Thông qua các thí nghiệm ablation này, chúng tôi hy vọng cung cấp những hiểu biết có giá trị về các yếu tố chính cho lựa chọn thiết kế về kết hợp tập dữ liệu.

Cân bằng tập dữ liệu. Trong khi một loạt tập dữ liệu có sẵn để huấn luyện MLLM, kích thước của chúng khác nhau đáng kể, như được hiển thị trong Bảng 2. Ngoài ra, khi huấn luyện MLLM, việc hạn chế số lượng vòng lặp huấn luyện để bảo toàn kiến thức của LLM được huấn luyện trước là thực hành phổ biến. Do đó, việc cân bằng đúng cách các tập dữ liệu huấn luyện là rất quan trọng để tối đa hóa việc học các kỹ năng đa dạng trong lịch trình huấn luyện ngắn. Để kiểm tra điều này, chúng tôi so sánh năm chiến lược cân bằng khác nhau: 1) theo tập dữ liệu: lấy mẫu đồng nhất cho mỗi tập dữ liệu, 2) theo nhiệm vụ: lấy mẫu đồng nhất cho mỗi nhiệm vụ, 3) theo mẫu-100k: lấy mẫu đồng nhất cho mỗi mẫu với việc cắt kích thước tối đa của mỗi tập dữ liệu xuống 100k [50], 4) theo tập dữ liệu-điều chỉnh: cân bằng được điều chỉnh theo kinh nghiệm dựa trên chiến lược theo tập dữ liệu.

Mức độ chi tiết mẫu. Trong khi việc sử dụng các mẫu được định nghĩa trước để chuyển đổi các tập dữ liệu hiện có thành định dạng hướng dẫn được công nhận rộng rãi [11, 33, 50, 61], mức độ chi tiết phù hợp để áp dụng các mẫu này không được thiết lập rõ ràng. Chúng tôi thiết kế các thí nghiệm để so sánh hai cách tiếp cận với mức độ chi tiết mẫu khác nhau: 1) tinh vi: áp dụng các mẫu độc đáo cho mỗi tập dữ liệu [50], và 2) thô: áp dụng các mẫu được chia sẻ trên các tập dữ liệu trong cùng danh mục nhiệm vụ [11, 33].

Đa dạng mẫu. Trước khi xuất hiện các tập dữ liệu cuộc trò chuyện được GPT hỗ trợ, việc đảm bảo đa dạng mẫu là quan trọng, thường đạt được bằng cách sử dụng một loạt các mẫu đa dạng được định nghĩa trước cùng với các chiến lược đảo ngược đầu vào [22, 38, 61]. Tuy nhiên, việc giới thiệu các tập dữ liệu được GPT hỗ trợ dường như đã làm giảm sự nhấn mạnh vào tính đa dạng của các mẫu [33]. Vai trò chính xác và tầm quan trọng của việc sử dụng nhiều mẫu và kỹ thuật đảo ngược đầu vào trong bối cảnh các tập dữ liệu được GPT hỗ trợ vẫn ít được hiểu. Để điều tra điều này, chúng tôi so sánh ba cách tiếp cận khác biệt sử dụng: 1) một mẫu duy nhất, 2) nhiều mẫu, và 3) nhiều mẫu với đảo ngược đầu vào.

Mẫu đa lượt. Khi sử dụng các tập dữ liệu hiện có, thường tìm thấy nhiều cặp đầu vào-đích cho một hình ảnh duy nhất, như được thấy trong các tập dữ liệu VQA với một số cặp QA cho mỗi hình ảnh. Chiến lược đa lượt kết hợp các cặp này thành một ví dụ đa lượt giống như cuộc trò chuyện duy nhất. Tuy nhiên, cách tiếp cận này có thể kết hợp các cặp đầu vào-đích chồng chéo về mặt ngữ nghĩa thành một ví dụ, có thể khuyến khích các shortcut đơn giản trong việc tìm câu trả lời, đặc biệt trong huấn luyện tự hồi quy của MLLM. Để giảm thiểu điều này, chúng tôi giới thiệu một chiến lược khử trùng lặp bổ sung, loại bỏ các cặp đầu vào-đích trùng lặp về mặt ngữ nghĩa từ các ví dụ đa lượt, từ đó ngăn chặn huấn luyện shortcut. Chúng tôi chi tiết chiến lược này với các ví dụ trong Phụ lục E.

## 5. Thí nghiệm

### 5.1. Cài đặt

Tiêu chuẩn. Chúng tôi áp dụng bốn tiêu chuẩn được thiết kế đặc biệt cho đánh giá Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM), bao gồm MME [14], MMBench [35], SEED-Bench [25] và LLaVA-Bench (In-the-Wild) [34]. Ba tiêu chuẩn đầu tiên đánh giá các khả năng khác nhau của MLLM, chẳng hạn như hiểu biết nhận thức và suy luận thị giác, sử dụng các câu hỏi có/không nhị phân (MME) hoặc câu hỏi lựa chọn đa phương án (MMBench, SEED-Bench). Lưu ý rằng chúng tôi sử dụng các phần của MME với các nhiệm vụ nhận thức (MMEP), MMBench-dev (MMB), và SEED-Bench chỉ hình ảnh (SEEDI), tương ứng. Sự tập trung của chúng tôi vào các nhiệm vụ nhận thức trong MME được giải thích trong Phụ lục F. Mặt khác, LLaVA-Bench (In-the-Wild), LLaVAW, khai thác GPT-4 để đánh giá các phản hồi mô tả của MLLM, cung cấp một cái nhìn toàn diện về hiệu suất của mô hình trong việc tạo ra ngôn ngữ tự nhiên và sở thích của con người.

Chỉ số. Chúng tôi báo cáo các chỉ số chính thức được tính toán bằng cách sử dụng triển khai chính thức cho các tiêu chuẩn riêng lẻ theo mặc định; chúng tôi cũng báo cáo trung bình chuẩn hóa AvgN [8, 29] trên các tiêu chuẩn, được định nghĩa là trung bình của các điểm được chuẩn hóa theo điểm giới hạn trên tương ứng của chúng, tạo điều kiện cho các so sánh đơn giản.

Chi tiết triển khai. Chúng tôi sử dụng Vicuna-v1.5 7B và 13B [10] làm LLM. Chúng tôi tận dụng CLIP ViT-L/14 [46] được huấn luyện trước với độ phân giải 224 và 336 cho LLM 7B và 13B, tương ứng; chúng tôi sử dụng các đặc trưng từ lớp thứ hai cuối cùng của CLIP thay vì lớp cuối cùng. Bất kỳ token chỉ báo hình ảnh nào, ví dụ các token đặc biệt bao quanh token thị giác, đều không được sử dụng. Chúng tôi huấn luyện toàn bộ LLM thay vì điều chỉnh hiệu quả tham số. Đối với các ablation sâu, chúng tôi sử dụng lịch trình huấn luyện ngắn (huấn luyện trước 50k, điều chỉnh hướng dẫn 4k) với Vicuna-7B, CLIP ViT-L/14, và C-Abstractor với M=144 token thị giác trừ khi nêu khác. Đối với các mô hình cuối cùng, chúng tôi áp dụng lịch trình huấn luyện dài (huấn luyện trước 200k, điều chỉnh hướng dẫn 10k). Thêm chi tiết trong Phụ lục C.

### 5.2. Phân tích về Bộ Chiếu Tăng cường Địa phương

Để thể hiện giá trị của bộ chiếu được đề xuất, chúng tôi đánh giá và so sánh cả hiệu suất và hiệu quả với các bộ chiếu hiện có trong Bảng 3 sử dụng sáu nhiệm vụ hiểu biết không gian từ MME, MMBench, và SEED-Bench. Đầu tiên, Resampler (B2, B5) cho thấy hiệu suất kém do thiếu xem xét về bảo toàn ngữ cảnh địa phương, mặc dù linh hoạt về số lượng token thị giác M. Thứ hai, bộ chiếu tuyến tính bị hạn chế ở M=256 (B4) do tính không linh hoạt (B1), dẫn đến chi phí tính toán không thể chấp nhận ở độ phân giải cao hơn với M lớn hơn. Thứ ba, với cùng ngân sách tính toán (M=256), C-Abstractor của chúng tôi cung cấp hiệu suất được cải thiện đáng kể so với bộ tuyến tính (52.6 (B4) vs. 56.3 (B6)). Cuối cùng, với ít token thị giác hơn (M=144), C-Abstractor của chúng tôi thể hiện hiệu suất được cải thiện (+0.9 điểm) và hiệu quả lớn hơn (3.04 (B4) vs. 2.23 (B3) s/bước). Sự cải thiện này cho thấy bộ chiếu tăng cường địa phương của chúng tôi xuất sắc trong việc trừu tượng hóa các đặc trưng thị giác nơi nó tích hợp các ngữ cảnh địa phương từ các đặc trưng lân cận và cung cấp các token thị giác được làm phong phú bằng ngữ cảnh, do đó cho phép các bộ chiếu của chúng tôi vượt trội hơn các đối tác tuyến tính ngay cả với ít token thị giác hơn.

### 5.3. Công thức Bí mật cho Điều chỉnh Hướng dẫn Thị giác

Kết hợp tập dữ liệu. Bảng 4 cho thấy một nghiên cứu ablation toàn diện để xác định tác động riêng lẻ của các tập dữ liệu trên các tiêu chuẩn đa phương thức khác nhau. Đầu tiên, chúng tôi điều tra tác động của tính đa dạng tập dữ liệu trong mỗi nhiệm vụ bằng cách chỉ tận dụng một tập dữ liệu duy nhất cho mỗi nhóm nhiệm vụ (D1 vs. D2). Sự sụt giảm hiệu suất tổng thể làm nổi bật tầm quan trọng của tính đa dạng tập dữ liệu trong mỗi nhiệm vụ. Thứ hai, chúng tôi khám phá tác động của mỗi nhiệm vụ bằng cách loại trừ tuần tự các nhiệm vụ cụ thể (D1 vs. D3-8). Điều này cho thấy rằng tính đa dạng nhiệm vụ là quan trọng để học cách xử lý nhiều nhiệm vụ khác nhau; mỗi nhiệm vụ cải thiện hiệu suất của các tiêu chuẩn liên quan, VQA (Mở) → MME, VQA (MC) → MMB và SEEDI, và chú thích và dữ liệu theo hướng dẫn → LLaVAW. Thứ ba, chúng tôi kiểm tra tác động của việc sử dụng dữ liệu ngôn ngữ-thị giác hiện có (D9 vs. D10). Loại trừ dữ liệu như vậy dẫn đến sự giảm sút đáng kể trong các tiêu chuẩn MME, MMB và SEEDI. Điều này cho thấy rằng kiến thức phong phú trong các tập dữ liệu ngôn ngữ-thị giác hiện có tăng cường khả năng hiểu biết nhận thức hoặc suy luận thị giác của MLLM. Tóm lại, các thí nghiệm này nhấn mạnh tầm quan trọng của tính đa dạng trong cả nhiệm vụ và tập dữ liệu trong mỗi nhiệm vụ.

Cân bằng tập dữ liệu. Sự cần thiết của cân bằng tập dữ liệu được chế tạo thủ công được đề cập trong các nghiên cứu trước đây [11, 38]. Dựa trên các quan sát của chúng tôi trong Bảng 4, chúng tôi điều chỉnh sự cân bằng của mỗi tập dữ liệu với hai nguyên tắc: hạn chế số epoch cho các tập dữ liệu nhỏ hơn và cho phép tối đa khoảng một vài epoch cho các tập dữ liệu chính. Bảng 5a thể hiện tính hiệu quả của cách tiếp cận theo tập dữ liệu-điều chỉnh được điều chỉnh thủ công của chúng tôi. Không có chế tạo thủ công, theo tập dữ liệu có thể là một lựa chọn thay thế đáng tin cậy. Thêm chi tiết được cung cấp trong Phụ lục C.

Điều chỉnh hướng dẫn vs. học đa nhiệm vụ. Bảng 5b cho thấy lợi thế của điều chỉnh hướng dẫn với định dạng dựa trên mẫu so với học đa nhiệm vụ sử dụng các định danh đơn giản. Kết quả này phù hợp với các nghiên cứu trước đây [11, 50], cho thấy hiệu quả của điều chỉnh hướng dẫn trong thiết lập của chúng tôi.

Mức độ chi tiết mẫu. Bảng 5c thể hiện rằng mẫu tinh vi (hàng đầu tiên) liên tục vượt trội hơn mẫu thô (hàng thứ hai) trên tất cả các tiêu chuẩn. Chúng tôi quan sát thấy rằng trong các tập dữ liệu như RefCOCO và RefCOCO+, trong khi phân phối đầu vào p(X_img,X_text) tương tự, phân phối câu trả lời p(Y|X_img,X_text) khác nhau. Trong kịch bản này, mẫu thô khiến mô hình gặp khó khăn trong việc phân biệt câu trả lời cho các đầu vào tương tự.

Đa dạng mẫu. Để so sánh hiệu quả của tính đa dạng mẫu đối với hiệu suất mô hình, chúng tôi đánh giá ba kịch bản với tính đa dạng khác nhau: sử dụng một mẫu duy nhất (duy nhất), sử dụng 10 mẫu cho mỗi tập dữ liệu (đa), và đảo ngược 3 trong số 10 mẫu (đa+lật). Thú vị, các thí nghiệm của chúng tôi tiết lộ rằng việc tăng tính đa dạng mẫu không đảm bảo sự thúc đẩy hiệu suất, như được hiển thị trong Bảng 5c. Điều này phù hợp với kết quả của các nghiên cứu gần đây [33], cho thấy rằng khái quát hóa zero-shot hiệu quả có thể đạt được ngay cả khi không sử dụng nhiều mẫu.

Mẫu đa lượt. Bảng 5d cho thấy tính hiệu quả của cả chiến lược mẫu đa lượt và khử trùng lặp. Kết quả ngụ ý rằng việc loại bỏ các cặp chồng chéo về mặt ngữ nghĩa trong mỗi ví dụ là hiệu quả để giảm thiểu huấn luyện shortcut.

Công thức bổ sung. Ngoài các tập dữ liệu và chiến lược hướng dẫn hóa, các công thức huấn luyện cũng kết hợp một số lựa chọn thiết kế tinh tế nhưng quan trọng, bao gồm lựa chọn các đặc trưng trong bộ mã hóa thị giác, LLM, kỹ thuật huấn luyện LLM, chỉ báo hình ảnh, vòng lặp huấn luyện trước và điều chỉnh hướng dẫn. Các công thức này được chi tiết trong Phụ lục D.

Công thức cuối cùng. Tóm lại, công thức cuối cùng của chúng tôi được tóm tắt là 1) áp dụng C-Abstractor hoặc D-Abstractor linh hoạt, bảo toàn địa phương; 2) tận dụng các tập dữ liệu đa dạng cho các nhiệm vụ khác nhau (Bảng 4); 3) áp dụng các tùy chọn ablation đã chọn trong Bảng 5 và Phụ lục D—việc áp dụng cân bằng theo tập dữ liệu với điều chỉnh thủ công, các mẫu tinh vi, và tương tác đa lượt với khử trùng lặp.

### 5.4. Kết hợp Tất cả

So sánh với các MLLM hiện có. Trong Bảng 6, chúng tôi so sánh Honeybee của chúng tôi, được huấn luyện bằng công thức cuối cùng và lịch trình huấn luyện dài, với các MLLM tiên tiến khác. Honeybee vượt trội hơn các MLLM quy mô 7B có thể so sánh trong tất cả các tiêu chuẩn, ngoại trừ SEEDI. Đáng chú ý rằng các phương pháp cạnh tranh như Qwen-VL [2] và LLaVA-1.5 [33] sử dụng các bộ mã hóa thị giác lớn hơn (ví dụ: ViT-bigG cho Qwen-VL) hoặc hình ảnh lớn hơn (448 và 336) với nhiều token thị giác hơn (M=256 và 576). Ngược lại, Honeybee sử dụng ViT-L/14 với độ phân giải 224 và 144 token thị giác tạo ra sự cân bằng giữa hiệu suất và hiệu quả (Hình 8). Đối với các nhiệm vụ yêu cầu hiểu biết thị giác chi tiết, chẳng hạn như SEEDI (xem Phụ lục F), việc sử dụng hình ảnh lớn hơn hoặc nhiều token thị giác hơn có thể có lợi. Khi số lượng token thị giác tăng từ 144 lên 256, Honeybee đạt điểm tốt nhất trong SEEDI (65.5) trong số các LLM quy mô 7B, như được hiển thị trong Bảng 7. Khi được mở rộng lên 13B, Honeybee vượt trội hơn tất cả các phương pháp trước đây trong mọi tiêu chuẩn. Các điểm chi tiết có sẵn trong Phụ lục G.1.

Đẩy giới hạn. Trong các mô hình cuối cùng 7B và 13B của chúng tôi, chúng tôi sử dụng 144 và 256 token thị giác (M), tương ứng, cân bằng hiệu quả và hiệu suất. Như được chỉ ra trong Hình 1 và Phụ lục A, việc tăng M liên tục cải thiện hiệu suất. Các thí nghiệm của chúng tôi, căn chỉnh M trong Honeybee với bộ chiếu tuyến tính (Bảng 7), cho thấy sự tăng cường hiệu suất với chi phí hiệu quả. Các so sánh bổ sung với các phương pháp trước đây trong Phụ lục G.2.

Kết quả bổ sung. Chúng tôi bổ sung trình bày (i) các điểm chi tiết cho MME, MMB, SEEDI, và LLaVAW trong Phụ lục G.1, (ii) kết quả ScienceQA [39] trong Phụ lục G.3, (iii) kết quả tiêu chuẩn bổ sung (MM-Vet [58], MMMU [60], POPE [30]) trong Phụ lục G.4, và (iv) các ví dụ định tính trong Phụ lục H.2.

## 6. Kết luận

Sự ra đời của điều chỉnh hướng dẫn thị giác đã mang lại những tiến bộ đáng chú ý trong MLLM. Mặc dù có những bước tiến này, các lĩnh vực như thiết kế bộ chiếu và cách tiếp cận trong việc xử lý dữ liệu đa diện với các quy trình hướng dẫn hóa vẫn chưa được khám phá đầy đủ hoặc chưa rõ ràng. Được thúc đẩy bởi điều này, chúng tôi xác định thuộc tính bộ chiếu mong muốn nhưng bị bỏ qua, tức là bảo toàn địa phương, và đề xuất bộ chiếu tăng cường địa phương cung cấp sự cân bằng hiệu suất-hiệu quả lý tưởng. Ngoài ra, chúng tôi cung cấp các thí nghiệm mở rộng để xác định tác động của các lựa chọn thiết kế riêng lẻ trong việc xử lý dữ liệu hướng dẫn đa diện, tiết lộ các công thức bí mật để phát triển MLLM hiệu suất cao. Cuối cùng, Honeybee vượt trội đáng kể so với các phương pháp tiên tiến trước đây trên các tiêu chuẩn khác nhau.

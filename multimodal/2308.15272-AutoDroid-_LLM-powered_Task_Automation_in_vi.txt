# 2308.15272.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2308.15272.pdf
# Kích thước tệp: 1430028 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
AutoDroid: Tự động hóa Tác vụ được hỗ trợ bởi LLM trong
Android
Hao Wen1, Yuanchun Li1,2,†, Guohong Liu1, Shanhui Zhao1,∗, Tao Yu1,∗,
Toby Jia-Jun Li3, Shiqi Jiang4, Yunhao Liu5, Yaqin Zhang1, Yunxin Liu1,2
1Viện Nghiên cứu Công nghiệp AI (AIR), Đại học Thanh Hoa
2Phòng thí nghiệm Trí tuệ nhân tạo Thượng Hải
3Khoa Khoa học Máy tính và Kỹ thuật, Đại học Notre Dame
4Microsoft Research
5Global Innovation Exchange & Khoa Tự động hóa, Đại học Thanh Hoa
TÓM TẮT
Tự động hóa tác vụ di động là một kỹ thuật hấp dẫn nhằm cho phép tương tác người dùng không cần dùng tay với smartphone thông qua giọng nói. Tuy nhiên, các phương pháp hiện tại gặp phải vấn đề về khả năng mở rộng kém do khả năng hiểu ngôn ngữ hạn chế và yêu cầu nỗ lực thủ công không nhỏ từ các nhà phát triển hoặc người dùng cuối. Sự tiến bộ gần đây của các mô hình ngôn ngữ lớn (LLM) trong việc hiểu và lý luận ngôn ngữ truyền cảm hứng cho chúng tôi suy nghĩ lại vấn đề từ góc độ tập trung vào mô hình, nơi việc chuẩn bị, hiểu và thực thi tác vụ được xử lý bởi một mô hình ngôn ngữ thống nhất. Trong công trình này, chúng tôi giới thiệu AutoDroid, một hệ thống tự động hóa tác vụ di động có khả năng xử lý các tác vụ tùy ý trên bất kỳ ứng dụng Android nào mà không cần nỗ lực thủ công. Ý tưởng chính là kết hợp kiến thức thông thường của LLM và kiến thức cụ thể miền của ứng dụng thông qua phân tích động tự động. Các thành phần chính bao gồm phương pháp biểu diễn UI nhận biết chức năng kết nối UI với LLM, các kỹ thuật tiêm bộ nhớ dựa trên khám phá để tăng cường kiến thức cụ thể miền của ứng dụng cho LLM, và một mô-đun tối ưu hóa truy vấn đa mức độ giảm chi phí suy luận của mô hình. Chúng tôi tích hợp AutoDroid với các LLM có sẵn bao gồm GPT-4/GPT-3.5 trực tuyến và Vicuna trên thiết bị, và đánh giá hiệu suất của nó trên một benchmark mới cho tự động hóa tác vụ Android được tăng cường bộ nhớ với 158 tác vụ phổ biến. Kết quả cho thấy AutoDroid có thể tạo ra các hành động chính xác với độ chính xác 90,9%, và hoàn thành các tác vụ với tỷ lệ thành công 71,3%, vượt trội hơn các baseline được hỗ trợ bởi GPT-4 với 36,4% và 39,7%.

CCS CONCEPTS
•Human-centered computing →Ubiquitous and mobile computing ;•Computing methodologies →Artificial intelligence .

KEYWORDS
Tự động hóa Tác vụ, Mô hình Ngôn ngữ Lớn, Phân tích Ứng dụng

ACM Reference Format:
Hao Wen1, Yuanchun Li1,2,†, Guohong Liu1, Shanhui Zhao1,∗, Tao Yu1,∗,, Toby Jia-Jun Li3, Shiqi Jiang4, Yunhao Liu5, Yaqin Zhang1, Yunxin Liu1,2. 2024. AutoDroid: LLM-powered Task Automation in Android. In International Conference On Mobile Computing And Networking (ACM MobiCom '24), September 30–October 4, 2024, Washington D.C., DC, USA. ACM, New York, NY , USA, 15 pages. https://doi.org/10.1145/3636534.3649379

1 GIỚI THIỆU
Smartphone là một trong những thiết bị tinh vi nhất dành cho cá nhân. Với hàng triệu ứng dụng di động (gọi tắt là app) có quyền truy cập vào các cảm biến nhúng khác nhau và dữ liệu cá nhân phong phú, smartphone có thể được sử dụng cho rất nhiều tác vụ hàng ngày như đặt đồ ăn, quản lý mạng xã hội, cảm biến và theo dõi tình trạng sức khỏe, v.v. Do đó, cách tự động hóa các tác vụ trên smartphone một cách thông minh đã trở thành một chủ đề hấp dẫn đối với các nhà phát triển và nhà nghiên cứu di động, do tiềm năng cải thiện đáng kể trải nghiệm người dùng và cho phép các trợ lý cá nhân ảo hữu ích.

Các phương pháp chính cho tự động hóa tác vụ di động có thể được phân loại thành các kỹ thuật dựa trên nhà phát triển, dựa trên minh họa và dựa trên học tập. Hầu hết các sản phẩm thương mại hiện tại (ví dụ: Siri, Google Assistant, Cortana, v.v.) áp dụng phương pháp dựa trên nhà phát triển, đòi hỏi nỗ lực phát triển đáng kể để hỗ trợ một tác vụ mới. Ví dụ, để cho phép một tác vụ tự động với Google Assistant, các nhà phát triển ứng dụng cần xác định chức năng mà họ muốn kích hoạt, cấu hình và triển khai intent tương ứng, và đăng ký intent với trợ lý. Khi thực thi một tác vụ, trợ lý sử dụng các mô-đun hiểu ngôn ngữ tự nhiên (NLU) để ánh xạ lệnh của người dùng đến intent, trích xuất các tham số intent, và gọi hàm được nhà phát triển định nghĩa tương ứng. Các nhà nghiên cứu đã khám phá nhiều phương pháp khác nhau để giảm bớt nỗ lực phát triển. Tuy nhiên, các phương pháp này vẫn gặp phải vấn đề về khả năng mở rộng kém, vì chúng hoặc yêu cầu các minh họa tác vụ tùy ý và/hoặc quy mô lớn từ con người (ví dụ: các phương pháp lập trình bằng minh họa [2,14,15] và các phương pháp học có giám sát [3,16,35]) hoặc yêu cầu định nghĩa phần thưởng rõ ràng cho việc hoàn thành tác vụ (ví dụ: các phương pháp học tăng cường [10,19,39]). Do thiếu khả năng mở rộng, hiện tại có rất ít tác vụ tự động được hỗ trợ, ngay cả trong các ứng dụng phổ biến nhất.

Gần đây, sự xuất hiện của các mô hình ngôn ngữ lớn (LLM) như ChatGPT [28] và Claude [1] cho thấy tiềm năng trong việc giải quyết vấn đề khả năng mở rộng của tự động hóa tác vụ. So với các mô hình truyền thống, LLM thể hiện các khả năng độc đáo như tuân theo hướng dẫn [36], lý luận từng bước [44], và khái quát hóa zero-shot [11]. Những khả năng này được kích hoạt bởi việc học tự giám sát trên một kho dữ liệu khổng lồ (hơn 1,4 nghìn tỷ token [38]) theo sau bởi việc điều chỉnh với phản hồi của con người. Với những khả năng này, các nhà nghiên cứu đã quản lý để cho phép LLM gọi các công cụ tự động, chẳng hạn như công cụ tìm kiếm [27], trình thông dịch mã [4], và API của bên thứ ba [25,30]. Tương tự, việc sử dụng LLM có thể tránh được những nỗ lực thủ công cồng kềnh trong tự động hóa tác vụ di động. Trong khi đó, việc kết nối LLM với smartphone có thể tiếp tục giải phóng sức mạnh của LLM trong các lĩnh vực cá nhân.

Mục tiêu của tự động hóa tác vụ di động được hỗ trợ bởi LLM là xây dựng một tác nhân tự trị có thể hoàn thành các tác vụ do người dùng chỉ định bằng cách tương tác với smartphone. Mặc dù nghiên cứu hiện tại [42] cố gắng cho phép LLM hiểu các UI di động, nhưng nó chỉ đơn giản dựa vào kỹ thuật prompt và không sử dụng kiến thức cụ thể miền của ứng dụng. AutoDroid kết hợp các khả năng của LLM và kiến thức cụ thể ứng dụng thông qua phân tích ứng dụng động, cho phép nó xử lý các tác vụ tùy ý chưa thấy mà không cần nỗ lực thủ công (minh họa trong Hình 1).

Chúng tôi xác định ba vấn đề chính để đạt được mục tiêu này.

(1) Biểu diễn GUI. Đầu vào và đầu ra của các bộ tự động hóa tác vụ là các trạng thái và hành động giao diện người dùng đồ họa (GUI), không giống như các câu ngôn ngữ tự nhiên mà LLM có thể xử lý. Để giúp LLM hiểu thông tin GUI tốt hơn và đưa ra các quyết định tương tác chính xác, các trạng thái và hành động GUI phải được chuyển đổi sang định dạng văn bản trong khi tích hợp thông tin có cấu trúc phong phú.

(2) Tích hợp Kiến thức. Việc giải quyết các tác vụ với LLM đòi hỏi kiến thức cụ thể miền về các ứng dụng. Không giống như các công cụ khác được nghiên cứu trong công trình trước (ví dụ: API) mà LLM có thể dễ dàng được cấu hình để sử dụng, một ứng dụng smartphone thường là một otomat phức tạp hơn. LLM cần điều hướng giữa các trạng thái khác nhau để tìm ra cách hoàn thành các tác vụ.

(3) Tối ưu hóa Chi phí. Việc truy vấn LLM tốn kém và đòi hỏi nhiều tính toán, trong khi việc hoàn thành một tác vụ với LLM có thể liên quan đến nhiều truy vấn dài do độ phức tạp của tác vụ và ứng dụng smartphone. Do đó, việc tối ưu hóa hiệu quả của các truy vấn LLM là mong muốn để tạo điều kiện cho trải nghiệm tự động hóa tác vụ phản hồi nhanh.

Chúng tôi giới thiệu một khung tự động hóa tác vụ di động, AutoDroid, để giải quyết các vấn đề trên. Nhìn chung, AutoDroid thực thi các tác vụ bằng cách nhắc LLM với biểu diễn văn bản kiểu HTML của GUI và truy vấn để được hướng dẫn hành động. Để tăng cường LLM với kiến thức ứng dụng, AutoDroid khám phá ngẫu nhiên các ứng dụng đích và trích xuất đồ thị chuyển đổi UI từ chúng. Bằng cách phân tích các trạng thái và chuyển đổi UI với LLM, AutoDroid có thể chuyển đổi thông tin thô thành kiến thức hoàn thành tác vụ, sau đó được tích hợp vào bộ tự động hóa tác vụ bằng cách tiêm các chức năng được dự báo vào các prompt, khớp các dấu vết UI liên quan, hoặc điều chỉnh các tham số LLM. Chi phí truy vấn LLM được giảm bằng cách giảm và đơn giản hóa các truy vấn dựa trên kiến thức ứng dụng.

Để nghiên cứu một cách có hệ thống hiệu suất và thách thức của tự động hóa tác vụ được hỗ trợ bởi LLM trên Android, chúng tôi xây dựng một benchmark với 158 tác vụ được gắn nhãn thủ công từ 13 ứng dụng di động phổ biến mã nguồn mở (Calendar, Messenger, Contacts, v.v.). Mã nguồn và môi trường thực thi của các ứng dụng được cung cấp để thu thập thông tin phụ trợ và tái tạo việc thực thi tác vụ. Các tác vụ bao gồm các câu hỏi how-to được hỏi thường xuyên từ bộ dữ liệu PixelHelp [16] và các chức năng phổ biến trong các ứng dụng. Đối với mỗi tác vụ, chúng tôi đã gắn nhãn thủ công các bước để hoàn thành các tác vụ, trong đó mỗi bước được liên kết với cả trạng thái GUI và hành động GUI. Benchmark của chúng tôi đánh giá hiệu suất của tự động hóa tác vụ được hỗ trợ bởi LLM về mặt độ chính xác và chi phí.

Chúng tôi đánh giá hiệu quả của phương pháp AutoDroid trên benchmark với các loại LLM khác nhau, bao gồm các dịch vụ LLM trực tuyến tiên tiến (GPT-3.5 và GPT-4) và LLM mã nguồn mở trên thiết bị (Vicuna). Kết quả đã chứng minh rằng AutoDroid có thể hoàn thành các tác vụ chưa thấy với tỷ lệ thành công 71,3% với GPT-4, trong đó mỗi hành động được chọn với độ chính xác 90,9%. So với các baseline được hỗ trợ bởi LLM có sẵn, tỷ lệ hoàn thành tác vụ được cải thiện 36,4% đến 39,7%, và chi phí trung bình của việc truy vấn LLM được giảm 51,7%.

Công trình của chúng tôi đóng góp các đóng góp kỹ thuật sau:

(1) Theo hiểu biết của chúng tôi, đây là công trình đầu tiên về việc tăng cường tự động hóa tác vụ di động bằng cách kết hợp LLM và kiến thức cụ thể ứng dụng. Chúng tôi xây dựng một benchmark cho vấn đề này.

(2) Chúng tôi giới thiệu một phương pháp biểu diễn UI mới kết nối smartphone với LLM, một phương pháp tổng hợp tác vụ để tăng cường LLM với kiến thức ứng dụng, và các kỹ thuật tối ưu hóa truy vấn LLM khác nhau để giảm chi phí tự động hóa tác vụ.

(3) Thông qua đánh giá toàn diện, chúng tôi chứng minh hiệu quả của phương pháp và tiềm năng thúc đẩy lĩnh vực tự động hóa tác vụ di động.

2 BỐI CẢNH VÀ ĐỘNG LỰC

2.1 Tự động hóa Tác vụ Di động

Mục tiêu của tự động hóa tác vụ di động là tự động hoàn thành các loại tác vụ khác nhau được người dùng đưa ra. Đầu vào của nó là một tác vụ tùy ý được mô tả bằng ngôn ngữ tự nhiên và một ứng dụng di động để thực thi tác vụ. Đầu ra là một chuỗi các hành động UI có thể được thực thi trên smartphone.

Một tác vụ là một yêu cầu chức năng nhiều bước từ người dùng dành cho việc hoàn thành trên smartphone, thường thiếu hướng dẫn rõ ràng. Một trạng thái UI, có thể nhìn thấy được đối với người dùng trên thiết bị di động của họ, là một sự sắp xếp các điều khiển được mô tả thông qua hình ảnh và văn bản, thường được tổ chức như một cây GUI. Một hành động UI, có thể thực hiện bởi người dùng hoặc một tác nhân trên màn hình của thiết bị, được định nghĩa bởi một tuple (phần tử đích, loại hành động, giá trị). Phần tử đích đề cập đến một điều khiển trong trạng thái UI, chẳng hạn như một nút, hộp văn bản, trường nhập liệu, hoặc thanh trượt. Loại hành động đại diện cho cách thao tác phần tử đích. Chúng tôi xem xét ba loại tương tác smartphone chính, bao gồm "click", "input", và "swipe". Trường giá trị là nội dung văn bản của hành động "input", trống đối với các loại hành động khác.

Trái ngược với các phương pháp hiện tại sử dụng LLM để tóm tắt hoặc phản hồi các truy vấn về UI di động riêng lẻ [41,42], việc tự động hóa tác vụ di động đòi hỏi khả năng lập kế hoạch giải pháp tác vụ và hiểu biết sâu sắc về những UI nào là cần thiết cho việc hoàn thành tác vụ. AutoDroid nhằm đạt được tự động hóa tác vụ nhiều bước bằng cách tận dụng kiến thức cụ thể ứng dụng. Hơn nữa, không giống như hầu hết các phương pháp hiện tại đòi hỏi nỗ lực đáng kể từ nhà phát triển/người dùng [2] để cho phép các tác vụ tự động, chúng tôi nhằm đạt được tự động hóa tác vụ không giám sát, tức là hỗ trợ tự động hóa các tác vụ tùy ý trên các ứng dụng hộp đen (cơ chế nội bộ không được biết) mà không cần nỗ lực con người. Tuy nhiên, chúng tôi giả định rằng các ứng dụng có sẵn cho các phân tích tự động, ví dụ: khám phá các trạng thái, thu thập nội dung, và phân tích mã. Giả định như vậy là hợp lý vì các gói ứng dụng đều có sẵn để tải xuống và các kỹ thuật phân tích ứng dụng tĩnh/động đã được nghiên cứu rộng rãi trước đây [21–24].

2.2 Mô hình Ngôn ngữ Lớn

Mô hình ngôn ngữ lớn (gọi tắt là LLM) chủ yếu đề cập đến các mô hình ngôn ngữ dựa trên Transformer [40] chứa hàng tỷ tham số và được huấn luyện trên lượng dữ liệu văn bản khổng lồ, chẳng hạn như ChatGPT [28], GPT-4 [29], PaLM [6], LLaMA [38], v.v. Những mô hình này thể hiện các khả năng không có trong các mô hình nhỏ hơn, bao gồm lý luận toán học [7], tổng hợp chương trình [4], và lý luận nhiều bước [44]. Cụ thể, LLM có thể thực hiện các tác vụ tốt hơn so với các mô hình benchmark được huấn luyện trên các bộ dữ liệu chuyên biệt. Đầu vào của LLM là một prompt, là một hướng dẫn để định hướng việc tạo phản hồi của nó. Prompt được token hóa thành các token (từ hoặc từ phụ) trước khi được đưa vào LLM.

Các nhà nghiên cứu đang tích cực khám phá các phương pháp để tăng cường khả năng giải quyết vấn đề của LLM bằng cách tích hợp kỹ năng lý luận [44] và sử dụng công cụ [25,30,49]. Những nỗ lực này nhằm cho phép LLM sử dụng các công cụ bằng cách dạy chúng gọi API hoặc tổng hợp mã. Tuy nhiên, tự động hóa tác vụ trong các ứng dụng smartphone phức tạp hơn vì nó thường liên quan đến môi trường mà không có giao diện được tài liệu hóa.

2.3 LLM gặp gỡ Tự động hóa Tác vụ Di động

Chúng tôi tin rằng việc tích hợp LLM vào tự động hóa tác vụ di động mang lại những ưu điểm và điểm mạnh độc đáo cho cả hai lĩnh vực.

Đầu tiên, LLM có tiềm năng thúc đẩy đáng kể các ứng dụng của tự động hóa tác vụ di động. Các trợ lý cá nhân thông minh được điều khiển bằng giọng nói (IPA) là những ứng dụng điển hình của tự động hóa tác vụ di động, nhằm cung cấp trải nghiệm người dùng thông minh, hiệu quả và không cần dùng tay trên các thiết bị di động. Những ứng dụng như vậy không chỉ hữu ích trong smartphone mà còn trong nhiều tình huống khác, bao gồm hệ thống giải trí trong xe ô tô (IVI) [31], thiết bị theo dõi thể dục đeo được [34,46], và thiết bị VR/AR [12]. Để hỗ trợ các dịch vụ IPA, các nhà phát triển thường phải cấu hình thủ công các quy trình làm việc của tác vụ, đây là một quá trình cồng kềnh ngay cả đối với các nhà phát triển có kinh nghiệm. Các nhà nghiên cứu cũng đã cố gắng xây dựng các tác nhân có thể trực tiếp thao tác các phần tử GUI như người dùng [15,16,35,42]. Tuy nhiên, chúng thường yêu cầu rất nhiều minh họa từ con người, hướng dẫn từng bước, hoặc các hàm phần thưởng được thiết kế rõ ràng cho việc hoàn thành tác vụ [10,19]. Các tác nhân dựa trên LLM có thể tốt hơn trong tự động hóa tác vụ GUI với khả năng hiểu ngôn ngữ và lý luận mạnh mẽ của chúng.

Thứ hai, việc trang bị LLM với smartphone có thể tăng cường đáng kể khả năng của chúng. LLM được huấn luyện với dữ liệu công cộng quy mô lớn chứa kiến thức thông thường và thế giới phong phú, trong khi chúng có kiến thức hạn chế về người dùng cá nhân và khả năng hạn chế trong việc cung cấp dịch vụ cá nhân hóa. Smartphone đã trở thành một phần quan trọng của cuộc sống hàng ngày bằng cách giúp mọi người kết nối với nhau, tổ chức công việc với lịch, điều hướng và chỉ đường, điều khiển thiết bị nhà thông minh, v.v. Nếu LLM học cách sử dụng các ứng dụng smartphone và truy cập dữ liệu được tách biệt trong chúng, chúng có thể trở thành trợ lý cá nhân tốt hơn nhiều với quyền truy cập vào các cảm biến phong phú và dữ liệu cá nhân trong các ứng dụng di động.

Tuy nhiên, việc áp dụng LLM cho tự động hóa tác vụ di động liên quan đến một số thách thức, bao gồm biểu diễn GUI, tích hợp kiến thức, và tối ưu hóa chi phí. Đầu tiên, LLM chỉ có khả năng xử lý dữ liệu văn bản thuần túy và không thể trực tiếp xử lý GUI hoặc tương tác với nó. Mặc dù trạng thái GUI trong Android có thể được biểu diễn dưới dạng văn bản bằng cách sử dụng UI Hierarchy Viewer hoặc Accessibility Services, nhưng nó thường dài (trung bình khoảng 40k token cho mỗi trạng thái UI) và khó để LLM diễn giải. Thứ hai, LLM thiếu kiến thức và kinh nghiệm về một số ứng dụng cụ thể, có thể dẫn đến việc thực thi sai các hướng dẫn. Hình 2 cho thấy một ví dụ trong đó cần hiểu biết sâu sắc về ứng dụng để hoàn thành tác vụ. Thật khó để xác định chỉ dựa trên ngữ nghĩa và kiến thức tiền nghiệm rằng việc nhấp vào 'more options' và sau đó 'settings' trên hai màn hình đầu tiên sẽ dẫn đến màn hình chứa tùy chọn 'delete all events'. Do đó, chỉ dựa vào kỹ thuật prompt cho LLM để tạo ra các giải pháp thông thường có thể dẫn đến sai lầm. Một phương pháp tốt hơn có thể là để LLM điều tra và học hỏi từ các ứng dụng di động, có được kinh nghiệm thực tế trước khi thực hiện các tác vụ cho người dùng. Thứ ba, việc sử dụng LLM để hoàn thành tác vụ có thể tốn kém. Giá của việc truy vấn ChatGPT API [28] là $1.5 / 1000K token. Ngay cả khi chúng ta có thể triển khai một dịch vụ LLM riêng, chi phí tính toán vẫn cao. Ví dụ, suy luận một token duy nhất với LLaMA-7B [38] mất 6,7 tỷ FLOP, và toàn bộ quá trình hoàn thành tác vụ có thể sử dụng hơn 2000 token.

3 PHƯƠNG PHÁP CỦA CHÚNG TÔI: AUTODROID

Chúng tôi giới thiệu AutoDroid, một hệ thống tự động hóa tác vụ di động đầu cuối được hỗ trợ bởi LLM để giải quyết các thách thức nêu trên. Trong giai đoạn ngoại tuyến, AutoDroid thu thập kiến thức cụ thể ứng dụng bằng cách khám phá các mối quan hệ UI và tổng hợp các tác vụ mô phỏng. Trong giai đoạn trực tuyến, AutoDroid liên tục truy vấn các LLM được tăng cường bộ nhớ để có được hướng dẫn về hành động tiếp theo. Tác vụ được hoàn thành bằng cách tuân theo các hành động được LLM đề xuất. AutoDroid áp dụng một số kỹ thuật để cải thiện tỷ lệ hoàn thành tác vụ và tối ưu hóa chi phí truy vấn. Hình 3 minh họa quy trình làm việc.

Chúng tôi giải thích hoạt động của AutoDroid bằng ví dụ về tự động hóa các tác vụ trong ứng dụng lịch: Trong giai đoạn ngoại tuyến, AutoDroid khám phá ứng dụng bằng cách nhấp ngẫu nhiên các nút trên màn hình và ghi lại kết quả trong bộ nhớ UI Transition Graph (UTG) (Bước 1). Tiếp theo, nó duyệt qua tất cả các phần tử UI trong UTG và tóm tắt các tác vụ mà chúng có thể thực hiện (Bước 2). Trong hoạt động trực tuyến, khi người dùng đưa ra lệnh như "delete all the events in the calendar", Prompt Generator tạo ra một prompt dựa trên tác vụ, mô tả trạng thái UI, và thông tin liên quan được lưu trữ trong App Memory. Thông tin này bao gồm hướng dẫn về cách điều hướng đến trang GUI chứa tùy chọn "delete events". Sau đó, Privacy Filter thay thế bất kỳ thông tin nhạy cảm nào trong prompt để bảo vệ quyền riêng tư. Prompt đã được lọc sau đó được gửi đến LLM. Khi LLM cung cấp câu trả lời, Task Executor phân tích hành động có thể được thực thi trên smartphone và xác minh tính bảo mật của nó trước khi thực hiện. Nếu executor cho rằng hành động có thể có rủi ro, chẳng hạn như "delete all the events" trong tác vụ cụ thể này, nó sẽ tìm kiếm xác nhận từ người dùng trước khi tiến hành. Chúng tôi sẽ giải thích cách AutoDroid thực hiện tất cả những điều này trong phần còn lại của phần này.

3.1 Prompting UI hướng tác vụ

UI prompting đề cập đến quá trình biểu diễn thông tin UI cơ bản dưới dạng văn bản và tiêm nó vào prompt để truy vấn LLM. Mục tiêu của UI prompting là trình bày rõ ràng nội dung văn bản và cấu trúc của UI cho LLM và hạn chế đầu ra của LLM chỉ dự đoán các tương tác UI hợp lệ. Hình 4 giới thiệu một ví dụ về AutoDroid chuyển đổi giao diện GUI thành prompt trong khi hoàn thành tác vụ.

3.1.1 Chuyển đổi GUI sang Biểu diễn HTML Đơn giản. Chúng tôi phát triển một mô-đun phân tích GUI để chuyển đổi GUI sang biểu diễn HTML đơn giản có thể được xử lý bởi LLM. Các nhà nghiên cứu đã phát hiện rằng LLM hiểu HTML tốt hơn so với UI được mô tả bằng ngôn ngữ tự nhiên do lượng lớn mã HTML trong dữ liệu huấn luyện của LLM [42]. Do đó, chúng tôi biểu diễn GUI theo phong cách HTML, có thể bảo tồn thông tin thuộc tính của các phần tử UI. Chúng tôi sử dụng năm loại thẻ HTML, cụ thể là <button>, <checkbox>, <scroller>, <input>, và <p>, đại diện cho các phần tử có thể được nhấp, check, vuốt, chỉnh sửa, và bất kỳ view nào khác tương ứng. Các thuộc tính được bao gồm cho mỗi phần tử là: ID (thứ tự mà phần tử xuất hiện trong cây GUI), label (mô tả nội dung mô tả chức năng của phần tử), onclick (gợi ý về các trạng thái UI sẽ được truy cập khi nhấp vào nút này hoặc check/uncheck checkbox này, sẽ được giới thiệu trong §3.2.2), text (văn bản trên phần tử), direction (hướng cuộn, bao gồm up/down/left/right), checked (liệu checkbox có được check hay không), value (văn bản đã được nhập vào hộp văn bản). Các lớp và thuộc tính của các phần tử GUI được hiển thị trong Bảng 1. Chúng tôi tiếp tục đơn giản hóa cây DOM bằng cách cắt tỉa các phần tử không nhìn thấy và hợp nhất các phần tử tương đương về chức năng, sẽ được giới thiệu trong §3.3. Các văn bản của hai phần tử UI được hợp nhất được phân tách bằng "<br>", đại diện cho ngắt dòng trong HTML.

Trong các thí nghiệm của chúng tôi, chúng tôi quan sát thấy rằng tác nhân thường không chủ động cuộn trên các giao diện có thể cuộn theo chiều dọc (hiển thị trong §6.2). Tuy nhiên, việc có thông tin về giao diện đã cuộn là rất quan trọng cho việc ra quyết định, đặc biệt khi nút đích nằm ở phần cuộn của giao diện mà chưa hiển thị. Do đó, để cung cấp cho tác nhân thông tin toàn diện, chúng tôi cần bao gồm các thành phần từ phần cuộn của giao diện trong trạng thái UI hiện tại. Để đạt được điều này, đối với một giao diện nhất định, AutoDroid đầu tiên tự động cuộn qua tất cả các thành phần có thể cuộn và ghi lại thông tin của các phần tử UI hiển thị, và sau đó cung cấp thông tin này cho LLM để ra quyết định. Phương pháp này cung cấp hai lợi ích. Thứ nhất, nó ngăn LLM đưa ra lựa chọn mù quáng khi chúng không thể thấy tất cả thông tin trên giao diện. Thứ hai, nó loại bỏ nhu cầu LLM cung cấp hướng dẫn rõ ràng để cuộn, giảm tần suất gọi LLM và giảm chi phí tính toán liên quan.

3.1.2 Hạn chế Không gian Hành động với Lựa chọn. Một đặc điểm chính của tự động hóa tác vụ UI là tất cả các hành động của tác nhân cần được giới hạn trong các ràng buộc của ứng dụng cơ bản, tức là tác nhân chỉ có thể thực hiện các hành động của loại hành động được hỗ trợ trên một trong các phần tử UI hiện có. Do đó, một thách thức là thích ứng LLM, vốn có tính chất tạo sinh, với nhiệm vụ lựa chọn rời rạc như vậy. Do đó, chúng tôi áp đặt sự cần thiết cho LLM tạo ra kết quả theo cấu trúc được xác định trước bằng cách hoàn thành yêu cầu sau: "- id=<id number> - action=<tap/input> input text=<text or N/A> (trong trường hợp hoàn thành tác vụ, id=-1)". LLM phải kiềm chế không tạo ra id hoặc input ở định dạng tùy ý.

3.2 Tiêm Bộ nhớ dựa trên Khám phá

Tiêm bộ nhớ dựa trên khám phá nhằm cung cấp thông tin liên quan đến ứng dụng cho LLM, cho phép chúng có được cái nhìn sâu sắc về các ứng dụng, hiểu các phương pháp sử dụng ứng dụng, và đưa ra các quyết định hiệu quả. Tuy nhiên, có những thách thức trong việc sử dụng kiến thức liên quan đến ứng dụng tự động để hỗ trợ LLM trong tự động hóa tác vụ, bao gồm: (i) UI Transition Graph (UTG) thu được thông qua khám phá ngẫu nhiên không thể được xử lý trực tiếp bởi LLM. (ii) Bộ nhớ được thu thập chỉ thông qua các công cụ tự động hóa UI chỉ chứa dữ liệu UI và hành động, mà không có thông tin cần thiết để trực tiếp cho phép tự động hóa tác vụ. Điều này bao gồm chi tiết về các phần tử UI cụ thể và các hành động cần thiết để thực hiện một tác vụ cụ thể. (iii) Một ứng dụng có thể có nhiều màn hình UI và phần tử UI (nút, hộp văn bản, v.v.), vượt quá giới hạn độ dài token của LLM nếu tất cả chúng được bao gồm trong một prompt. Để vượt qua những thách thức này, AutoDroid tổng hợp các tác vụ mô phỏng dựa trên đồ thị UI được khám phá ngẫu nhiên. Những tác vụ mô phỏng này đóng vai trò là hướng dẫn cho LLM về cách thực hiện một tác vụ người dùng.

3.2.1 Tạo Tác vụ Mô phỏng. AutoDroid tạo ra các tác vụ mô phỏng bằng cách phân tích UI Transition Graph (UTG) như được mô tả trong Hình 5. UTG được tạo bởi bộ tự động hóa UI chứa thông tin quan trọng về ứng dụng, chẳng hạn như các kết nối giữa các UI và sự hiện diện của các phần tử UI khác nhau trên mỗi màn hình. Bằng cách tóm tắt các chức năng của tất cả các phần tử UI, chúng ta có thể hiểu biết kỹ lưỡng về các tác vụ có thể được thực hiện trong ứng dụng và xác định các phần tử UI tương ứng cần thiết để thực thi chúng. Kết quả là, AutoDroid phân tích tất cả các trạng thái UI và phần tử UI có mặt trong UTG và trích xuất các chức năng của chúng bằng cách truy vấn LLM.

Cụ thể, UTG có thể được coi như một đồ thị có hướng, trong đó các nút và cạnh lần lượt là tất cả các trạng thái UI và hành động được ghi lại bởi Explorer ngẫu nhiên, được ký hiệu là U và A tương ứng. Đối với mỗi trạng thái UI Ui, memory generator truy vấn LLM để tóm tắt các chức năng của tất cả các phần tử UI {ej^i}|Ui|_j=1, trong đó |Ui| biểu thị số lượng phần tử trong Ui. Lưu ý rằng AutoDroid chỉ trích xuất chức năng của một phần tử trên trạng thái UI gần nhất với UI ban đầu nếu nó xuất hiện trên nhiều trạng thái UI. Sau khi duyệt qua tất cả các phần tử UI trong UTG, chúng ta thu được bảng tác vụ mô phỏng trong bộ nhớ ứng dụng chứa n mục, trong đó n đại diện cho tổng số phần tử UI trên UTG. Mỗi mục trong bảng tương ứng với một phần tử UI ej^i và được chia thành ba phần: <Tác vụ mô phỏng, Trạng thái UI, Phần tử UI>. "Tác vụ mô phỏng" đại diện cho chức năng của ej^i đã được LLM tóm tắt, có thể được coi như một tác vụ mô phỏng có thể được hoàn thành bằng cách nhấp vào phần tử này. "Phần tử UI" bao gồm tất cả các phần tử đã được nhấp, bắt đầu từ UI ban đầu của ứng dụng và dẫn đến việc đạt được Ui. "Trạng thái UI" đại diện cho chuỗi các trạng thái UI đã được duyệt từ trạng thái UI ban đầu đến Ui. Bảng này cung cấp cho tác nhân thông tin về các hoạt động cần thiết để đạt được từng chức năng, hỗ trợ tác nhân trong việc lập kế hoạch cách hoàn thành một tác vụ nhất định một cách hiệu quả. Ngoài bảng tác vụ mô phỏng, còn có một bảng bổ sung gọi là bảng chức năng UI trong bộ nhớ ứng dụng. Nó cung cấp một bản tóm tắt về chức năng liên quan đến mỗi trạng thái UI trong UTG. Thông tin này được thu thập bằng cách truy vấn LLM để tóm tắt chức năng của mỗi trạng thái UI.

3.2.2 Tăng cường Prompt với Bộ nhớ Ứng dụng. Phương pháp đơn giản nhất để tận dụng kiến thức cụ thể ứng dụng là tích hợp bộ nhớ ứng dụng trực tiếp vào prompt, có thể cung cấp hướng dẫn cho LLM. Tuy nhiên, điều này có thể vượt quá giới hạn token tối đa của LLM như 4097 token cho GPT-3.5 [28]. Trong nhiều trường hợp, chỉ một vài phần tử UI là cần thiết để hoàn thành tác vụ của người dùng. Do đó, chúng tôi có chọn lọc tích hợp thông tin UI liên quan nhất vào prompt.

AutoDroid xác định tầm quan trọng của một phần tử UI trong bộ nhớ ứng dụng dựa trên sự tương đồng giữa tác vụ mô phỏng của nó và tác vụ người dùng hiện tại. Chúng tôi sử dụng một mô hình embedding (Instructor-XL [33]) ánh xạ các câu ngôn ngữ tự nhiên thành embedding có kích thước cố định, trong đó các embedding của các câu có nghĩa tương tự sẽ gần nhau hơn. Sự tương đồng cosine giữa các embedding của tác vụ mô phỏng S và tác vụ hiện tại T được ký hiệu là sim(E(S),E(T)). Sau đó, chúng ta có thể tìm k tác vụ mô phỏng tương tự nhất trong bộ nhớ ứng dụng, được ký hiệu là {S1,S2,...,Sk}. Đối với mỗi Si, chúng ta có thể truy xuất các trạng thái UI tương ứng và các phần tử UI từ "bảng tác vụ mô phỏng" trong bộ nhớ ứng dụng. Trong giai đoạn trực tuyến, nếu UI hiện tại khớp với một trong các trạng thái UI liên quan đến Si, chúng tôi đưa ra gợi ý về các phần tử UI mà random explorer đã tương tác trong trạng thái UI này. Điều này giúp LLM hiểu được kết quả của việc tương tác với các phần tử. Cụ thể, prompt generator của AutoDroid sẽ thêm một thuộc tính mới "onclick" vào câu lệnh UI HTML trong prompt (hiển thị trong Bảng 1). Trong HTML, "onclick" được sử dụng để mô tả sự kiện sẽ xảy ra khi người dùng nhấp vào một nút, liên kết, hoặc hình ảnh. Trong prompt của chúng tôi, nội dung của thuộc tính "onclick" đề cập đến chức năng của các trạng thái UI sẽ được truy cập sau khi nhấp vào phần tử này, điều này liên quan nhất đến việc hoàn thành Si. Thuật toán 1 cho thấy cách tăng cường prompt với {S1,S2,...,Sk} và bộ nhớ ứng dụng M.

Lấy tác vụ được hiển thị trong Hình 2 làm ví dụ. Với tác vụ "Remove all the events in the calendar", AutoDroid có thể truy xuất trong bộ nhớ ứng dụng và tìm thấy tác vụ mô phỏng của nút "delete all events" trong GUI 3 là một tác vụ liên quan. Ngoài ra, AutoDroid có thể tìm thấy rằng việc nhấp "more options" và "settings" trong GUI 1 và GUI 2 có thể dẫn đến nút đích. Do đó, nếu màn hình UI hiện tại là GUI 1, mô tả HTML của "more options" trong GUI 1 sẽ thay đổi từ "<button label='More options'></button>", thành "<button label='More options' onclick= 'navigate to GUIs that can: 1.add contact holidays and anniversaries, import and export events, manage settings, 2.Delete all events in the app, manage event reminders, etc. '></button>".

3.2.3 Điều chỉnh LLM Cục bộ với Dữ liệu Cụ thể Ứng dụng. AutoDroid cũng có thể sử dụng các LLM cục bộ nhỏ hơn (ví dụ: Vicuna-7B [5]) để đưa ra quyết định, như một giải pháp thay thế tiết kiệm chi phí cho các LLM trên cloud lớn hơn (ví dụ: GPT-3.5 [28]). Tuy nhiên, khả năng lý luận của những LLM nhỏ hơn này yếu hơn so với LLM trên cloud, dẫn đến giảm độ chính xác đáng kể. Người ta quan sát thấy rằng LLM cục bộ vẫn thể hiện hiệu suất dưới mức tối ưu ngay cả với các phương pháp tăng cường prompt được giới thiệu trong §3.2.2. Các nhà nghiên cứu đã phát hiện rằng fine-tuning sử dụng dữ liệu cụ thể miền là một cách hiệu quả để cải thiện khả năng của LLM nhỏ [5,36]. Do đó, chúng ta có thể tăng cường các LLM nhỏ hơn bằng fine-tuning sử dụng dữ liệu cụ thể ứng dụng.

Một thách thức chính trong tình huống của chúng ta là làm thế nào để tạo ra các cặp (câu hỏi, câu trả lời) chất lượng cao để fine-tune LLM. Một cách ngây thơ là trực tiếp tổng hợp các cặp dữ liệu này từ bảng tác vụ mô phỏng của bộ nhớ ứng dụng. Đối với một tác vụ mô phỏng S, memory generator ghi lại một chuỗi các trạng thái UI {U1,U2,...,Uk} và các phần tử UI {e1,e2,...,ek} để hoàn thành nó. Chúng ta có thể trực tiếp tạo ra k cặp dữ liệu (qi,ai)k_i=1 dựa trên bản ghi này. Cụ thể, qi là một prompt được tạo dựa trên tác vụ S, các hành động UI trước đó {A1,A2,...,Ak} (trong đó các phần tử đích là {e1,e2,...,ek} và loại hành động là click), và trạng thái UI hiện tại Ui. Sau đó, mô tả của hành động Ai có thể là câu trả lời ai. Lý luận đằng sau phương pháp này là: Dựa trên quá trình tạo ra bộ nhớ ứng dụng, chúng ta đã biết rằng khi chuyển từ giao diện Ui để hoàn thành tác vụ S, hành động Ai cần được thực hiện. Do đó, câu trả lời đúng về hành động nào cần chọn với trạng thái Ui nên là Ai.

Tuy nhiên, các câu trả lời được tạo theo cách này chỉ bao gồm <phần tử đích, loại hành động, giá trị>, thiếu thông tin chi tiết hoặc ngữ cảnh. Do đó, LLM cục bộ khó học cách chọn hành động đúng dựa trên prompt. Nếu chúng ta bao gồm lý do để chọn hành động đích trong các câu trả lời, nó sẽ tăng cường hiểu biết của LLM cục bộ và cho phép nó học cách lý luận dựa trên tác vụ và UI hiện tại [9]. Do đó, chúng ta có thể yêu cầu các LLM lớn hơn (như GPT-4 [29]) trả lời lý do tại sao Ai được chọn để hoàn thành tác vụ S, và nhắc nó lý luận theo cách từng bước như Zero-shot Chain-of-Thought (0-shot CoT) [11]. Prompt được gửi đến LLM lớn hơn chủ yếu giống như Hình 4. Ngoài ra, chúng tôi cung cấp hành động đúng để chọn Ai, và nhắc LLM lý luận về hành động đúng bằng cách thay đổi phần "yêu cầu đầu ra" thành định dạng sau:

Câu trả lời của bạn phải luôn sử dụng định dạng sau: 1. Hoàn thành tác vụ này trên smartphone thường bao gồm các bước sau: <?>. 2. Phân tích mối quan hệ giữa tác vụ và các hành động UI trước đó và trạng thái UI hiện tại: 3. Dựa trên các hành động trước đó, tác vụ đã hoàn thành chưa? <Y/N>. Bước tiếp theo nên là <?/None>. 4. Tác vụ có thể tiến hành với trạng thái UI hiện tại không? <Y/N>. Điền vào chỗ trống về tương tác tiếp theo: - id=<id number> - action=<tap/input> - input text=<text or N/A>.

Câu trả lời cho các câu hỏi trên có thể được sử dụng làm câu trả lời trong cặp (câu hỏi, câu trả lời) để fine-tune LLM cục bộ. Dữ liệu suy nghĩ và lý luận được tạo bởi những LLM lớn hơn này chứa thông tin và kiến thức phong phú. Việc sử dụng nó làm câu trả lời để fine-tune các LLM nhỏ hơn có thể cho phép nó bắt chước các khả năng lý luận nổi lên của mô hình lớn. Bên cạnh việc tận dụng kiến thức từ các LLM lớn hơn, fine-tuning LLM với dữ liệu cụ thể ứng dụng cũng có hai lợi ích sau: (i) Học hỏi từ UTG và tích hợp những hiểu biết thu được từ nó. (ii) Cho phép các LLM nhỏ hơn tạo ra câu trả lời tuân thủ định dạng mong muốn thay vì định dạng không hạn chế trong các câu trả lời.

3.3 Tối ưu hóa Truy vấn Đa mức độ

Chúng tôi quan sát thấy rằng nguồn chi phí chính trong AutoDroid phát sinh từ việc truy vấn LLM. Do đó, việc giảm tần suất truy vấn LM cho mỗi tác vụ sẽ dẫn đến giảm chi phí của AutoDroid. Ngoài ra, như một phương pháp chi tiết hơn, việc cắt tỉa các token không cần thiết trong prompt, chúng ta có thể giảm hiệu quả chi phí tính toán của LLM.

3.3.1 Cắt tỉa Token bằng cách Hợp nhất các Phần tử Tương đương Chức năng. Câu lệnh HTML của UI được mô tả trong §3.1 chứa rất nhiều thông tin dư thừa, sẽ làm tăng số lượng token và khiến LLM bỏ qua thông tin hữu ích nhất. Do đó, chúng tôi áp dụng hai kỹ thuật để giảm độ dài của văn bản: Đầu tiên, chúng tôi cắt tỉa các phần tử không có thông tin trực quan hoặc văn bản (như các mục nền hoặc container). Thứ hai, chúng tôi hợp nhất các phần tử UI tương đương chức năng thành một phần tử và phân tách các phần tử ban đầu khác nhau bằng delimiter "<br>", có nghĩa là khoảng cách giống như ngắt dòng trong HTML. Chúng tôi hợp nhất các phần tử UI dựa trên hai quy tắc: (i) Dựa trên UTG: Nếu hoạt động trên hai phần tử UI này dẫn đến cùng một giao diện, chúng tôi kết hợp chúng thành một thành phần duy nhất. Cụ thể, nếu điểm bắt đầu và kết thúc của hai cạnh đại diện cho hành động trong UTG giống nhau, chúng tôi hợp nhất các thành phần mà chúng hoạt động. (ii) Dựa trên phân tích cây UI: Chúng tôi hợp nhất các nút lá UI không tương tác (văn bản thuần túy hoặc hình ảnh) chia sẻ cùng một tổ tiên tương tác (nút, checkbox, trường văn bản, v.v.) trong cây UI. Ví dụ, trong ảnh chụp màn hình GUI được hiển thị trong Hình 4, "Alarms" và "0 items" là hai nút văn bản thuần túy đơn lẻ trong cây GUI có một tổ tiên có thể nhấp chung. Do đó, chúng ta có thể hợp nhất chúng thành một câu lệnh HTML: "<button id=5>Alarms<br>0 items</button>" thay vì hai câu lệnh đơn "<button id=5>Alarms</button>" và "<button id=6>0 items</button>".

3.3.2 Giảm Thời gian Truy vấn bằng Phím tắt và Hợp nhất GUI. Hợp nhất GUI là bao gồm một số trạng thái GUI vào một prompt nếu LLM cần tất cả chúng để đưa ra quyết định. Cuộn tự động được giới thiệu trong §3.1.1 có thể thực hiện điều này bằng cách bỏ qua các bước trung gian như "scroll down". Không có cuộn tự động, AutoDroid phải truy vấn LLM ít nhất hai lần để chạm vào một phần tử trong GUI sau khi vuốt, bao gồm cả cuộn và nhấp. Sau khi hợp nhất các UI đã cuộn vào một prompt, chúng ta chỉ cần gọi LLM một lần và nhận được hành động "Scroll down to Button A and touch it".

Phím tắt là thực thi các hành động đơn giản trực tiếp với sự giúp đỡ của bộ nhớ ứng dụng. Mặc dù một số bước quan trọng và yêu cầu một mô hình lớn để đưa ra quyết định, những bước khác lại đơn giản và không yêu cầu nó. Vậy nếu chúng ta có thể xác định các bước đủ đơn giản để một mô hình embedding cục bộ [33] có thể đưa ra quyết định, chúng ta có thể giảm số lượng truy vấn. Cụ thể, cho T, E, và {S1,S2,...} lần lượt biểu thị tác vụ người dùng, mô hình embedding, và các tác vụ mô phỏng. Nếu chúng ta tìm thấy sim(E(Sk),E(T))>γ trong đó Sk= arg maxSi∈S sim(E(Si),E(T)), thì Sk rất tương tự với T, và việc thực hiện Sk rất đơn giản vì chúng ta có một loạt hành động {A1^k,A2^k,...} trong bộ nhớ ứng dụng điều hướng từ trạng thái UI ban đầu đến Sk. Do đó chúng ta có thể thực hiện Sk bởi task executor mà không cần gọi LLM. γ là một siêu tham số, giá trị γ càng lớn, tiêu chí của chúng ta để chọn các tác vụ mô phỏng tương tự càng nghiêm ngặt. Chúng tôi quan sát thấy rằng ngay cả khi phím tắt điều hướng đến các trạng thái UI không liên quan đến tác vụ, LLM vẫn có thể xác định vấn đề và nhanh chóng điều hướng đến các trạng thái UI đúng.

4 TRIỂN KHAI

Chúng tôi triển khai AutoDroid bằng Python và Java. LLM cục bộ Vicuna [5] được fine-tune bằng PyTorch.

Xác định Hành động Rủi ro. Một số hành động có thể thay đổi dữ liệu cục bộ hoặc máy chủ, hoặc không thể hoàn tác khi đã thực hiện. Những hành động này được coi là rủi ro và yêu cầu xác nhận của người dùng trước khi được tác nhân thực thi. Ví dụ, trước khi gọi một liên hệ, AutoDroid cần nhắc người dùng xác minh tính đúng đắn của hành động trước. Nếu người dùng nhận thấy bất kỳ lỗi nào trong số điện thoại sắp được quay, họ có thể thực hiện các sửa đổi cần thiết một cách thủ công. AutoDroid thực hiện điều này bằng cách nhắc LLM xác định các hành động rủi ro, tức là thêm câu "If this action potentially leads to a change of user data or server state that requires user confirmation, please answer requires_confirmation=Yes)" vào prompt. Ngoài ra, AutoDroid cũng sử dụng các cụm từ khóa trên UI, chẳng hạn như "warning", để tiếp tục xác định các hành động có thể rủi ro.

Loại bỏ Thông tin Riêng tư. Chúng tôi thêm một bộ lọc quyền riêng tư có thể che giấu thông tin riêng tư trong truy vấn. Trong quá trình xử lý trực tuyến, nó chạy một máy quét Thông tin Nhận dạng Cá nhân (PII) [26] có thể phát hiện thông tin nhạy cảm trong prompt, bao gồm tên, số điện thoại, địa chỉ email, v.v. Thông tin cá nhân này được thay thế bằng các từ không riêng tư (ví dụ: "<name>"→"Alice") trước khi gửi prompt lên cloud. Sau khi nhận được phản hồi từ LLM, AutoDroid ánh xạ các từ đặc biệt trở lại với những từ gốc trước khi phân tích các hành động.

5 BENCHMARK

Chúng tôi giới thiệu DroidTask, một bộ benchmark tự động hóa tác vụ Android được thiết kế để đánh giá hiệu suất của các hệ thống tự động hóa tác vụ di động đầu cuối. DroidTask bao gồm 158 tác vụ cấp cao được trích xuất từ 13 ứng dụng phổ biến. Điều làm cho benchmark của chúng tôi khác biệt là nó không chỉ cung cấp các tác vụ và dấu vết hành động GUI tương ứng mà còn cung cấp bộ nhớ khám phá và môi trường cho các ứng dụng cơ bản. Các tác nhân có thể tích cực tương tác với môi trường trong giai đoạn ngoại tuyến, thu thập thông tin về các ứng dụng và ghi lại UTG. Tất cả 13 ứng dụng được sử dụng để thu thập các tác vụ đều được cài đặt, cấp quyền cần thiết, và có thể tái tạo các dấu vết hành động GUI trong môi trường của chúng tôi. Chúng tôi sẽ phát hành môi trường dưới dạng Android Virtual Machine Snapshot, cho phép các nhà nghiên cứu khôi phục lại chính xác môi trường mà chúng tôi đã thu thập dữ liệu. Trong khi các benchmark trước đây [3,16,35] cũng cung cấp các tác vụ và hành động tương ứng, chúng thiếu môi trường có thể tái tạo. Tuy nhiên, với sự xuất hiện của các phương pháp tự động hóa tác vụ được hỗ trợ bởi LLM [30,47], thường yêu cầu thông tin động về môi trường để ra quyết định, benchmark của chúng tôi mang lại sự thuận tiện lớn hơn để đánh giá hiệu suất của các tác nhân tự trị trên điện thoại di động.

Chúng tôi phát triển một hệ thống thu thập bộ dữ liệu có thể tương tác với smartphone Android. Các ứng dụng được chọn chủ yếu bao gồm các công cụ di động phổ biến (như contacts, dialer, camera, calendar, v.v.) từ F-Droid, một nền tảng ứng dụng miễn phí và mã nguồn mở. Đối với mỗi ứng dụng, chúng tôi yêu cầu các chú thích viên cung cấp danh sách 5-15 tác vụ được mô tả bằng ngôn ngữ tự nhiên. Để hoàn thành mỗi tác vụ, các chú thích viên tương tác với smartphone thông qua máy tính để bàn theo cách lặp lại. Trong mỗi lần lặp, hệ thống hiển thị giao diện người dùng (UI) của smartphone ở trạng thái hiện tại cho chú thích viên, cùng với danh sách các hành động có sẵn. Các chú thích viên cũng có thể trực tiếp quan sát trạng thái thực tế của smartphone. Họ có thể chọn một hành động từ các tùy chọn sau: 1. Touch <Button ID>, 2. Input <input text> to <EditBox ID>, 3. Swipe <Scroller ID> <direction> trong terminal. Phân phối các tác vụ được hiển thị trong Hình 6.

6 ĐÁNH GIÁ

Chúng tôi tiến hành các thí nghiệm để kiểm tra độ chính xác và chi phí của AutoDroid trong tự động hóa tác vụ di động.

6.1 Thiết lập Thí nghiệm

Bộ dữ liệu. Chúng tôi chủ yếu đánh giá AutoDroid trên DroidTask (được đề cập trong §5). Chúng tôi cũng sử dụng bộ dữ liệu MoTiF [3] để huấn luyện các phương pháp baseline và fine-tune các LLM. MoTiF [3] là một bộ dữ liệu tác vụ ứng dụng di động quy mô lớn với hơn 4,7k tác vụ (loại trừ các tác vụ không có minh họa hợp lệ). Nó cũng cung cấp ảnh chụp màn hình và biểu diễn dựa trên cây của các màn hình GUI mà các chú thích viên tương tác khi hoàn thành những tác vụ này, nhưng thiếu môi trường khám phá của các ứng dụng.

Phần cứng. Chúng tôi đánh giá hiệu suất đầu cuối của AutoDroid trên OnePlus ACE 2 Pro với 8 lõi ARM 3,2 GHz (CPU Snapdragon 8 Gen2) và GPU Adreno™740. LLM cục bộ Vicuna-7B [5] được triển khai trên smartphone dựa trên Machine Learning Compilation for LLM (MLC LLM) [37]. Ngoài ra, nó được triển khai trên một máy chủ edge được trang bị 1 GPU NVIDIA 3090 24G để đánh giá độ trễ suy luận trong bối cảnh edge computing. Mô hình Vicuna-7B được fine-tune trên máy chủ 8 ×A100 80GB trong khoảng 4 giờ GPU.

Baseline. Chúng tôi chọn META-GUI [35] và một thiết kế dựa trên LLM hiện tại cho tự động hóa tác vụ UI [42] (được gọi là LLM-framework) làm baseline chính. META-GUI [35] là một tác nhân đối thoại dựa trên huấn luyện trên GUI di động có thể thực hiện nhiều tác vụ khác nhau. Chúng tôi huấn luyện nó trên bộ dữ liệu MoTiF [3]. LLM-framework [42] là một khung dựa trên LLM cho phép các tương tác dựa trên ngôn ngữ đa dạng với UI di động. Chúng tôi cũng triển khai hai baseline tương đối đơn giản, performer ngẫu nhiên (chọn ngẫu nhiên một phần tử UI trong mỗi màn hình UI) và performer dựa trên tương tự (chọn phần tử UI gần nhất về mặt ngữ nghĩa với tác vụ bằng mô hình embedding SOTA [33]).

Metrics. Cho một chuỗi UI {U1,U2,...,Un} trong đó các chú thích viên con người đã thực hiện các hành động A={A1,A2,...,An} để hoàn thành một tác vụ T, nếu một tác nhân có thể đưa ra một chuỗi quyết định Â={Â1,Â2,...,Ân} trên {U1,U2,...,Un}, chúng tôi sử dụng hai metrics dưới đây để đo hiệu suất của nó:

(i) Độ chính xác Hành động: Tỷ lệ hành động Âi khớp với hành động ground-truth Ai, cụ thể là P(Âi=Ai). Một hành động đúng chỉ khi cả phần tử UI đích và văn bản nhập ("null" nếu không cần nhập) đều đúng. Metric này phản ánh khả năng của tác nhân đưa ra quyết định đúng dựa trên thông tin có sẵn.

(ii) Tỷ lệ Hoàn thành: Xác suất hoàn thành đúng tất cả các hành động trong một chuỗi, cụ thể là P(Â=A). Metric này phản ánh xác suất tác nhân có thể liên tục và thành công hoàn thành một tác vụ.

6.2 Độ chính xác Hành động

Chúng tôi đầu tiên đánh giá độ chính xác hành động của AutoDroid. LLM mã nguồn mở Vicuna-7B [5] được fine-tune bằng dữ liệu cụ thể ứng dụng được tạo, như đề cập trong §3.2.3. Đối với LLM nguồn đóng như GPT-3.5 [28] và GPT-4 [29], không thể fine-tune trực tiếp, chúng tôi tăng cường chúng với bộ nhớ ứng dụng được tạo tự động, như đề cập trong §3.2.2. Temperature của các LLM được đặt ở giá trị thấp hơn là 0,25 để khuyến khích sáng tạo trong khi ngăn chúng quá ngẫu nhiên. Độ chính xác hành động của AutoDroid và các baseline được liệt kê trong Bảng 2. AutoDroid vượt trội hơn các baseline ở mọi loại hành động, dẫn đến cải thiện độ chính xác tổng thể 37,6%. Trong tất cả các hành động, clicking là đơn giản nhất, chỉ yêu cầu quyết định về ID phần tử. Mặt khác, scrolling và inputting đòi hỏi phải chỉ định hướng hoặc giá trị của phần tử UI, và việc xác định hoàn thành đòi hỏi phải xem xét tất cả các hành động trước đó. Người ta cũng quan sát thấy rằng với LLM càng lớn, các phương pháp dựa trên LLM vượt trội hơn mô hình được huấn luyện từ đầu [35]. Điều này là do mô hình chỉ được tiếp xúc với các ứng dụng và tác vụ từ các bộ dữ liệu cụ thể [3]. Do đó, nó sẽ không hoạt động tốt trên các ứng dụng và tác vụ mới trong DroidTask. Tuy nhiên, bằng cách tích lũy đủ kiến thức tiền nghiệm và tích hợp tích hợp bộ nhớ của chúng tôi, LLM có thể tham gia vào lý luận hợp lý về cách giải quyết vấn đề trên các ứng dụng mới. Đối với UI có thể cuộn, AutoDroid sẽ đầu tiên duyệt và đi qua tất cả các thành phần trên màn hình, loại bỏ nhu cầu cho hành động "scroll". Từ độ chính xác cuộn của baseline, người ta quan sát thấy rằng xác suất tác nhân chủ động chọn hành động này rất thấp. Do đó, việc duyệt và đi qua trước có thể cải thiện độ chính xác tổng thể của tác nhân.

Lý do AutoDroid vượt trội hơn các baseline là: (i) AutoDroid cắt tỉa và hợp nhất các phần tử UI, giảm không gian hành động (từ 36,4 xuống 13,2 lựa chọn trên mỗi trạng thái GUI trung bình). (ii) Bộ nhớ dựa trên khám phá có thể tăng cường LLM với kiến thức cụ thể miền về các ứng dụng, sẽ được chi tiết trong §6.4. (iii) Định dạng đầu ra của mô hình được fine-tune phù hợp hơn với các yêu cầu định dạng được chỉ định trong yêu cầu đầu ra. Nếu đầu ra không được chuẩn hóa, task executor sẽ không thể trích xuất hoặc nhận ra ID phần tử và hành động.

Chúng tôi tiếp tục phân tích lý do và cách AutoDroid thất bại ở một số bước. Chúng tôi lấy mẫu ngẫu nhiên 20 trường hợp thất bại của AutoDroid (sử dụng GPT-4 [29] làm LLM), và phân loại 3 nguyên nhân thất bại điển hình, như được giải thích dưới đây: 1. Nhiều Lựa chọn Đúng. Trong một số trường hợp, có thể có nhiều cách hợp lệ để hoàn thành một tác vụ. Các chú thích viên có thể không thể liệt kê đầy đủ tất cả các cách có thể để hoàn thành một tác vụ, và nếu tác nhân cố gắng một phương pháp khác với những gì các chú thích viên đã chỉ định, nó có thể được coi là không chính xác. 2. Không thể xác định chính xác nếu tác vụ đã được hoàn thành. Đôi khi AutoDroid nhầm lẫn coi một tác vụ đã hoàn thành khi nó phát hiện sự hiện diện của một phần tử UI cụ thể. 3. Thiếu hiểu biết về GUI. AutoDroid thỉnh thoảng bỏ qua thông tin hoặc gợi ý quan trọng trong UI và đưa ra quyết định dựa trên kinh nghiệm trước đó của nó. Ví dụ, trong tác vụ "open the camera and record a short video, name it 'test.mp3'", tác nhân chỉ cần nhập 'test' vào hộp "name". Điều này là do GUI chỉ ra rằng phần mở rộng tệp '.mp3' đã được hiển thị trong hộp "file type". Tuy nhiên, AutoDroid vẫn chọn 'test.mp3' làm input cho hộp "name".

6.3 Tỷ lệ Hoàn thành Tác vụ

Tỷ lệ Hoàn thành Tác vụ của AutoDroid và LLM-framework [42] được hiển thị trong Hình 7 (a). Lưu ý rằng chúng tôi không bao gồm bước xác định hoàn thành để so sánh rõ ràng. AutoDroid vượt trội hơn baseline lần lượt 40,5%, 26,4%, và 39,7% cho Vicuna-7B, GPT-3.5, và GPT-4. Chúng tôi cũng hiển thị tỷ lệ hoàn thành của AutoDroid có và không có tăng cường bộ nhớ trong Hình 7 (b). Khi số bước tăng, tỷ lệ hoàn thành tổng thể giảm. Điều này là do (i) xác suất mỗi bước được thực thi đúng giảm. (ii) Các tác vụ liên quan đến nhiều bước thường có nhiều cách tiếp cận để hoàn thành (ví dụ: tạo liên hệ mới bằng cách nhập tên hoặc số điện thoại trước). Tuy nhiên, các chú thích viên con người thường chỉ chú thích một cách tiếp cận, có thể dẫn đến việc giải pháp của mô hình bị đánh giá sai là không chính xác. Tỷ lệ hoàn thành thực tế trong hệ thống thực có thể cao hơn kết quả báo cáo, nhưng chúng tôi không bao gồm kết quả hệ thống thực vì việc xác định hoàn thành tác vụ có thể mơ hồ.

6.4 Nghiên cứu Ablation

6.4.1 Tiêm Bộ nhớ. Độ chính xác hành động và Tỷ lệ hoàn thành Tác vụ của AutoDroid có và không có bộ nhớ được hiển thị trong Hình 8. Chúng ta có thể quan sát thấy rằng cải thiện trong tỷ lệ hoàn thành tổng thể cao hơn nhiều so với cải thiện trong độ chính xác từng bước. Điều này là do việc giới thiệu bộ nhớ cho phép LLM đưa ra các quyết định từng bước quan trọng (như ví dụ trong Hình 2). Mặc dù những bước quan trọng này chiếm tỷ lệ nhỏ trong tất cả các bước hành động, chúng rất cần thiết để hoàn thành thành công một số tác vụ. Hơn nữa, có thể quan sát thấy rằng các mô hình nhỏ hơn được hưởng lợi nhiều hơn từ việc bao gồm bộ nhớ về mặt tỷ lệ hoàn thành tác vụ. Điều này là do các mô hình nhỏ hơn có ít kiến thức tiền nghiệm hơn, do đó yêu cầu nhiều hướng dẫn hơn từ kiến thức cụ thể ứng dụng. Tuy nhiên, ngay cả đối với các mô hình lớn hơn, việc tích hợp bộ nhớ vẫn có ý nghĩa. Khả năng mô hình hạn chế không thể lưu trữ kiến thức rộng lớn và ngày càng tăng có mặt trong thế giới, khiến việc cập nhật các mẫu sử dụng đang phát triển của các ứng dụng mới trở nên khó khăn. Do đó, việc khám phá và ghi lại các mẫu sử dụng của chúng một cách tự động đóng vai trò quan trọng trong việc cho phép LLM sử dụng hiệu quả các ứng dụng.

6.4.2 Fine-tuning Zero-shot Chain of Thought. Độ chính xác hành động và tỷ lệ hoàn thành tác vụ của AutoDroid dựa trên Vicuna-7B [5] được fine-tune với và không có Zero-shot Chain-of-Thought (0-shot CoT) [11] được hiển thị trong Bảng 3. Vì bộ nhớ ứng dụng được tạo tự động bởi AutoDroid chỉ chứa các hành động clicking và checking, LLM được fine-tune chỉ trên bộ nhớ ứng dụng kém về inputting và điều chỉnh liệu tác vụ đã được hoàn thành. Do đó, chúng tôi tích hợp một phần nhỏ dữ liệu được chú thích thủ công cho fine-tuning. Cụ thể, chúng tôi chỉ thêm dữ liệu input và xét xử hoàn thành từ bộ dữ liệu MoTiF [3] vào bộ dữ liệu bộ nhớ ứng dụng. Lưu ý rằng ứng dụng và tác vụ trong bộ dữ liệu MoTiF [3] không liên quan đến bộ dữ liệu của chúng tôi. Do đó, việc thêm phần dữ liệu này sẽ không dẫn đến bất kỳ rò rỉ dữ liệu thử nghiệm nào. Nó chỉ đơn giản cho phép mô hình học cách input và xác định việc hoàn thành tác vụ.

Vicuna-7B [5] được fine-tune với dữ liệu Zero-shot Chain-of-Thought được tạo bởi bộ nhớ ứng dụng được trộn với một phần nhỏ MoTiF [3] (AutoDroid) có thể đạt được 57,7% độ chính xác hành động và 41,1% tỷ lệ hoàn thành trên DroidTask, với độ chính xác input 40,0%. Không có dữ liệu MoTiF [3] ("No Mo"), mô hình được fine-tune có thể đạt được 51,9% độ chính xác hành động, và độ chính xác inputting là 0%. Chúng tôi quan sát thấy rằng khi không có CoT và không có dữ liệu MoTiF ("No Mo&CoT"), LLM được fine-tune có thể đạt được tỷ lệ độ chính xác cao với các hành động click đơn giản, và nó thường có thể xử lý các tác vụ chỉ liên quan đến clicking. Tuy nhiên, khi bộ dữ liệu MoTiF được giới thiệu ("No CoT") để dạy LLM các loại hành động bổ sung (như input và xét xử hoàn thành tác vụ), LLM bị dẫn lệch nặng nề bởi việc hoàn thành các tác vụ xét xử. Kết quả là, nó xuất ra một số lượng đáng kể "task completed" thay vì chọn hành động đúng. Do đó, độ chính xác hành động giảm từ 51,9% xuống 20,6%.

6.5 Phân tích Chi phí

Chi phí Runtime. AutoDroid giảm chi phí runtime bằng cách giải quyết hai khía cạnh: giảm số lượng token mỗi truy vấn và giảm tần suất truy vấn. Trong Hình 9 (a), chúng tôi hiển thị số lượng cho mỗi độ dài prompt. Baseline của chúng tôi [42] chỉ bao gồm các nút lá hiển thị trong cây UI, và chứa 625,3 token trong mỗi prompt trung bình. AutoDroid hợp nhất các nút tương đương chức năng trong cây UI và tiếp tục đơn giản hóa biểu thức của các thuộc tính, giảm số lượng token gần một nửa (339,0 trung bình). Có hai lợi ích chính: (i) Giảm độ dài token có thể giảm đáng kể độ trễ suy luận của mô hình. (ii) Để gọi API LLM trên cloud, nó có thể giảm chi phí. Ví dụ, đối với GPT-3.5 và GPT-4, chi phí có thể được giảm từ $0,938 và $18,76 xuống $0,509 và $10,17 cho mỗi 1000 truy vấn tương ứng trung bình.

Trong Bảng 4, chúng tôi chọn ngẫu nhiên năm prompt baseline và tìm các prompt tương ứng được tối ưu hóa bởi AutoDroid. Chúng tôi đo độ trễ thực tế của chúng trên Vicuna-7B [5] được triển khai trên smartphone cũng như trên máy chủ edge. Prompt được tối ưu hóa của chúng tôi giảm độ trễ suy luận 21,3% trung bình. Lưu ý rằng độ trễ suy luận của LLM trên smartphone và máy chủ edge chủ yếu phụ thuộc vào số lượng token đầu ra. Do đó, khi triển khai LLM trên thiết bị di động, chúng tôi không yêu cầu LLM xuất ra Chain-of-Thought mà thay vào đó xuất ra theo cách ban đầu được hiển thị trong Hình 4. Trong trường hợp của P5, do độ dài quá mức của baseline, nó đã bị cắt ngắn sau khi chỉ xuất ra một từ, dẫn đến độ trễ suy luận tối thiểu.

Hình 9 (b) hiển thị thành phần độ trễ mỗi bước của AutoDroid. Mô hình Vicuna-7B được triển khai trên smartphone và trên máy chủ edge. Các mô hình GPT-3.5 và GPT-4 trên cloud được truy cập bằng cách thực hiện các cuộc gọi API. Mô hình embedding [33] được triển khai trên GPU edge 1080 Ti với bộ nhớ 11 GB. Lưu ý rằng độ trễ trong việc gọi GPT-3.5 và GPT-4 bị ảnh hưởng đáng kể bởi điều kiện mạng, tải máy chủ, v.v. Do đó, chúng tôi thực hiện 10 phép đo để tính toán độ trễ trung bình, nhưng vẫn còn một mức độ bất ổn đáng kể. Gọi LLM ("LLM") chiếm phần lớn độ trễ, với 42,1%, 51,9%, 77,6%, và 87,1% độ trễ dựa trên GPT-3.5, Vicuna-7B (on-server), GPT-4, và Vicuna-7B (on-device) tương ứng. Do đó, việc giảm cuộc gọi LLM có thể giảm đáng kể chi phí đầu cuối. Bên cạnh đó, Embedding tác vụ và tìm kiếm phần tử UI tương tự nhất ("Embed") chỉ chiếm 1,7% chi phí, và chỉ cần được thực thi một lần cho mỗi tác vụ. Do đó, chi phí của việc tìm phím tắt và tiêm bộ nhớ là có thể chấp nhận được.

Chúng tôi cũng tiến hành các thí nghiệm về việc tiết kiệm số lượng cuộc gọi dựa trên hợp nhất GUI và phím tắt. Trung bình, AutoDroid giảm cuộc gọi LLM 1,2 lần mỗi tác vụ dẫn đến giảm tổng thể 13,7% tổng số cuộc gọi bằng kỹ thuật hợp nhất GUI. Phím tắt của chúng tôi hướng dẫn đúng LLM trong 75% trường hợp. Chỉ xem xét các phím tắt đúng, chúng tôi tiết kiệm 38,02% số bước, với mức tiết kiệm trung bình 1,73 bước mỗi tác vụ.

Chi phí Chuẩn bị Ngoại tuyến. Đối với mỗi ứng dụng, việc tạo ra UI Transition Graph (UTG) mất khoảng 0,5-1 giờ, sau đó được phân tích để tổng hợp các tác vụ mô phỏng dựa trên LLM, mất khoảng 5-10 phút. Cuối cùng, các tác vụ mô phỏng được ánh xạ thành các vector có kích thước cao bởi một mô hình embedding [33] để tra cứu runtime, thường mất khoảng 10 giây trên máy tính để bàn. Chuẩn bị ngoại tuyến là một quá trình một lần và không cần được thực hiện lại tại runtime.

6.6 Ảnh hưởng của Lọc Bảo mật/Quyền riêng tư

Chúng tôi yêu cầu các chú thích viên của DroidTask cũng xác định liệu mỗi hành động có thể thay đổi trạng thái của người dùng hoặc ứng dụng hay không. Nếu có, chúng tôi coi hành động đó là rủi ro và nhắc người dùng xác nhận có tiến hành hành động hay không. Chúng tôi đánh giá độ chính xác của AutoDroid trong việc phát hiện các hành động rủi ro trong năm ứng dụng có thể chứa các hành động rủi ro (contacts, dialer, SMS messenger, clock, và calendar). Chúng tôi coi các hành động rủi ro là ví dụ tích cực và AutoDroid đạt được precision 75,0% và recall 80,5%. Chúng tôi tiếp tục hiển thị ảnh hưởng của việc thêm thay thế thông tin quyền riêng tư và xác nhận bảo mật vào prompt trong Bảng 5. Khi thay thế quyền riêng tư và xác nhận bảo mật được thêm vào, có thể quan sát thấy sự giảm về độ chính xác và tỷ lệ hoàn thành, điều này có thể chấp nhận được.

7 CÔNG TRÌNH LIÊN QUAN

Hiểu và Tự động hóa UI. Đã có sự quan tâm ngày càng tăng trong việc sử dụng các kỹ thuật học máy để hiểu và tóm tắt giao diện người dùng, cho phép các trường hợp sử dụng như khả năng tiếp cận và bot hướng tác vụ. Các lĩnh vực nghiên cứu chính bao gồm: 1) Phân tích ngữ nghĩa của GUI để tóm tắt các chức năng [13,18], diễn giải mục đích của các phần tử UI [17,48], và giải quyết các câu hỏi của người dùng liên quan đến GUI [42,43]. Điều này rất quan trọng cho các tác vụ tương tác khác nhau như tự động hóa UI và khả năng tiếp cận. 2) Ánh xạ hướng dẫn của người dùng đến các phần tử UI [15,16,35]. Những phương pháp này nhằm chọn các phần tử GUI liên quan nhất cho các tác vụ nhất định. 3) Tự động hóa tác vụ UI di động [45,49]. Những phương pháp này xây dựng các tác nhân để hoàn thành các tác vụ cho người dùng bằng cách thực hiện các hành động trên GUI. AutoDroid, mặt khác, tận dụng bộ nhớ chuyển đổi UI để hoàn thành các tác vụ phức tạp, nhiều bước trên smartphone. Bộ nhớ có thể giúp các tác nhân hiểu UI thông tin phong phú và việc sử dụng ứng dụng, và tăng cường LLM trong lý luận và lập kế hoạch. Sau lần phát hành đầu tiên của AutoDroid, đã có nhiều tác nhân UI dựa trên LLM được đề xuất, đã được tóm tắt toàn diện trong một khảo sát gần đây [20].

LLM được Tăng cường. Mặc dù LLM xuất sắc trong các tác vụ như trả lời câu hỏi và tạo văn bản, chúng vẫn bị hạn chế bởi thông tin mà chúng có thể lưu trữ trong tập trọng số cố định và độ dài ngữ cảnh của chúng. Do đó, các nhà nghiên cứu đang tăng cường LLM với các công cụ khác nhau, chẳng hạn như trình duyệt web [8,27], API [25,30], và các mô hình DNN khác [32]. Không giống như các phương pháp hiện tại thường phụ thuộc vào API công cộng, phương pháp của chúng tôi không yêu cầu API tùy chỉnh, điều này không phổ biến trong các ứng dụng di động.

8 THẢO LUẬN

Tính ngẫu nhiên của LLM. Chúng ta có thể đặt siêu tham số 'temperature' về 0 để có phản hồi nhất quán. Nhưng việc đặt temperature quá nhỏ sẽ ức chế các câu trả lời sáng tạo, từ đó có thể làm giảm hiệu suất của hệ thống. Trong các thí nghiệm của chúng tôi, chúng tôi đặt temperature về 0,25. Và chúng tôi quan sát thấy giảm độ chính xác 2,1% khi chúng tôi đặt 'temperature' của GPT-3.5 về 0. Ngược lại, việc tăng temperature lên 0,7 đã tăng độ chính xác hành động 3,8%.

Độ trễ tăng lên hạn chế việc sử dụng thực tế của AutoDroid. Công trình của chúng tôi có thể được mở rộng bằng một phương pháp cộng tác giữa LLM và các mô hình nhỏ hơn. Chúng ta có thể gọi LLM chỉ một lần cho mỗi tác vụ để tạo ra một hướng dẫn dựa trên kiến thức cụ thể miền được lọc về ứng dụng. Sau đó, các mô hình nhỏ hơn có thể được sử dụng để liên kết những hướng dẫn này với các phần tử UI [16,35]. Việc giới thiệu một cache hướng dẫn có thể tiếp tục giảm độ trễ bằng cách lưu trữ và tái sử dụng các lệnh phổ biến, giảm thiểu nhu cầu gọi LLM lặp lại.

9 KẾT LUẬN

Chúng tôi trình bày một hệ thống tự động hóa tác vụ di động được hỗ trợ bởi LLM có thể hỗ trợ các tác vụ tùy ý mà không cần nỗ lực thủ công. Kết quả thí nghiệm đã cho thấy rằng phương pháp của chúng tôi có thể đạt được tự động hóa tác vụ hiệu quả, vượt trội hơn các baseline dựa trên huấn luyện và dựa trên LLM hiện tại. Chúng tôi tin rằng sự kết hợp giữa kiến thức thông thường của LLM và kiến thức cụ thể miền trong các ứng dụng di động có thể mang lại các trợ lý cá nhân thông minh và hữu ích thực sự thành hiện thực.

LỜI CẢM ƠN

Công trình này được hỗ trợ bởi Chương trình R&D Chủ chốt Quốc gia của Trung Quốc (Số 2022YFF0604501), NSFC (Số 62272261), và Trung tâm Nghiên cứu Chung Đại học Thanh Hoa (AIR)–AsiaInfo Technologies (China) Inc.

TÀI LIỆU THAM KHẢO

[1] Anthropic. 2023. Claude. https://www.anthropic.com/product.
[2] Tanzirul Azim, Oriana Riva, và Suman Nath. 2016. ULink: Enabling User-Defined Deep Linking to App Content. Trong Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services (MobiSys '16). Association for Computing Machinery, New York, NY, USA, 305–318. https://doi.org/10.1145/2906388.2906416
[3] Andrea Burns, Deniz Arsan, Sanjna Agrawal, et al. 2022. A Dataset for Interactive Vision Language Navigation with Unknown Command Feasibility. Trong European Conference on Computer Vision (ECCV).
[4] Mark Chen, Jerry Tworek, Heewoo Jun, et al. 2021. Evaluating Large Language Models Trained on Code. (2021). arXiv:cs.LG/2107.03374
[5] Wei-Lin Chiang, Zhuohan Li, et al. 2023. Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality. https://lmsys.org/blog/2023-03-30-vicuna/
[6] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, et al. 2022. PaLM: Scaling Language Modeling with Pathways. arXiv:cs.CL/2204.02311
[7] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, et al. 2021. Training Verifiers to Solve Math Word Problems. arXiv preprint arXiv:2110.14168 (2021).
[8] Xiang Deng, Yu Gu, Boyuan Zheng, et al. 2023. Mind2Web: Towards a Generalist Agent for the Web. arXiv:cs.CL/2306.06070
[9] Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, et al. 2023. Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes. arXiv preprint arXiv:2305.02301 (2023).
[10] Peter C Humphreys, David Raposo, Tobias Pohlen, et al. 2022. A data-driven approach for learning to control computers. Trong International Conference on Machine Learning. PMLR, 9466–9482.
[11] Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, et al. 2022. Large Language Models are Zero-Shot Reasoners. Trong Advances in Neural Information Processing Systems (NeurIPS 2022), Vol. 35. 22199–22213.
[12] Sunjae Lee, Hoyoung Kim, Sijung Kim, et al. 2022. A-Mash: Providing Single-App Illusion for Multi-App Use through User-Centric UI Mashup. Trong Proceedings of the 28th Annual International Conference on Mobile Computing And Networking (MobiCom '22). Association for Computing Machinery, New York, NY, USA, 690–702. https://doi.org/10.1145/3495243.3560522
[13] Gang Li và Yang Li. 2023. Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus. Trong The Eleventh International Conference on Learning Representations. https://openreview.net/forum?id=9yE2xEj0BH7
[14] Toby Jia-Jun Li, Yuanchun Li, Fanglin Chen, và Brad A Myers. 2017. Programming IoT devices by demonstration using mobile apps. Trong End-User Development: 6th International Symposium, IS-EUD 2017, Eindhoven, The Netherlands, June 13-15, 2017, Proceedings 6. Springer, 3–17.
[15] Toby Jia-Jun Li và Oriana Riva. 2018. Kite: Building Conversational Bots from Mobile Apps. Trong Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services (MobiSys '18). Association for Computing Machinery, New York, NY, USA, 96–109. https://doi.org/10.1145/3210240.3210339

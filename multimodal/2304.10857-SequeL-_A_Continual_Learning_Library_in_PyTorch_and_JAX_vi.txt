# SequeL: Thư viện Học Liên tục trong PyTorch và JAX

## Tóm tắt

Học Liên tục là một vấn đề quan trọng và thách thức trong học máy, nơi các mô hình phải thích nghi với dòng dữ liệu mới liên tục mà không quên kiến thức đã học trước đó. Trong khi các framework hiện có được xây dựng trên PyTorch, sự phổ biến ngày càng tăng của JAX có thể dẫn đến các cơ sở mã phân tán, cuối cùng cản trở khả năng tái tạo và tiến bộ. Để giải quyết vấn đề này, chúng tôi giới thiệu SequeL, một thư viện linh hoạt và có thể mở rộng cho Học Liên tục hỗ trợ cả framework PyTorch và JAX. SequeL cung cấp một giao diện thống nhất cho nhiều thuật toán Học Liên tục, bao gồm các phương pháp dựa trên chính quy hóa, các phương pháp dựa trên phát lại, và các phương pháp lai. Thư viện được thiết kế hướng tới tính mô-đun và đơn giản, làm cho API phù hợp cho cả nhà nghiên cứu và người thực hành. Chúng tôi phát hành SequeL như một thư viện mã nguồn mở, cho phép các nhà nghiên cứu và nhà phát triển dễ dàng thí nghiệm và mở rộng thư viện cho mục đích riêng của họ.

## 1. Giới thiệu

Lĩnh vực Học Liên tục (CL), còn được gọi là Học Suốt đời, Học Tăng dần, hoặc Học Tuần tự, đã chứng kiến sự phát triển nhanh chóng trong những năm gần đây. Học Liên tục giải quyết setting quan trọng của việc học tăng dần từ một dòng nguồn dữ liệu, loại bỏ giả định i.i.d. lâu đời của học máy truyền thống. Tuy nhiên, tốc độ đổi mới đã dẫn đến các setting khác biệt về dataset, giả định và yêu cầu. Như một hệ quả, một số công trình đã cố gắng thống nhất các mô hình Học Liên tục.

Sự đa dạng của các setting Học Liên tục đi kèm với nhiều thư viện Deep Learning khác nhau, như PyTorch, JAX, và TensorFlow, dẫn đến sự phân chia thêm. Mỗi thư viện Deep Learning có những ưu điểm khác nhau, và các nhà nghiên cứu lựa chọn cái phù hợp nhất với nhu cầu và kinh nghiệm trước đó của họ. Theo thời gian, dòng chảy các phương pháp mới dẫn đến các kho lưu trữ bị ngắt kết nối, làm chậm tiến bộ do khả năng tái sử dụng hạn chế và thiếu khả năng tái tạo.

Trong công trình này, chúng tôi đề xuất SequeL, tức là Sequential Learning, một framework Học Liên tục được viết bằng cả PyTorch và JAX. SequeL nhằm mục đích kết hợp các cơ sở mã phân tán trong khi cho phép các nhà nghiên cứu tạo mẫu nhanh mà không phải đi sâu vào mã kỹ thuật, ví dụ như vòng lặp training và theo dõi metric. Người dùng có thể phát triển trong framework mà họ lựa chọn trong khi truy cập các baseline đã được implement. Ví dụ, xem xét trường hợp một nhà nghiên cứu muốn implement một thuật toán mới trong JAX, nhưng tất cả baseline đều ở trong PyTorch. Việc implement lại mọi thứ từ đầu tốn thời gian và dễ mắc lỗi. Thay vào đó, họ có thể sử dụng framework đề xuất của chúng tôi để tích hợp phương pháp của họ và so sánh với baseline trên cùng một nền tảng.

Nhìn chung, SequeL cung cấp một framework thống nhất và linh hoạt cho nghiên cứu Học Liên tục, dễ dàng mở rộng và tiếp cận để thúc đẩy khả năng tái tạo. Chúng tôi tin rằng SequeL có thể giúp các nhà nghiên cứu so sánh các phương pháp tốt hơn và mở rộng lên các setting Học Liên tục phức tạp hơn.

## 2. Framework

Framework chứa các module sau: Benchmarks (Phần 2.1), Backbones (Phần 2.2), Callbacks (Phần 2.3), Loggers (Phần 2.4), và Algorithms (Phần 2.5). Code 1 cho thấy sự tương tác giữa các module khác nhau; một benchmark và backbone cùng với các logger được đưa vào instance thuật toán được trang bị thêm các chức năng tùy chỉnh thông qua callback. Thuật toán hoạt động như một module trainer và cũng chứa các chi tiết khái niệm của phương pháp luận CL, chẳng hạn như Averaged-Gradient Episodic Memory. SequeL cung cấp tính linh hoạt bằng cách cho phép người dùng phát triển thuật toán của họ bằng JAX hoặc PyTorch. Framework được thiết kế hướng tới tính dễ sử dụng và phân chia giữa các chi tiết kỹ thuật và thuật toán.

### 2.1. Benchmarks

Module Benchmarks cung cấp một số benchmark Học Liên tục được sử dụng rộng rãi, cả trong các kịch bản New Instance (NI) và New Class (NC). Các benchmark hiện được hỗ trợ là Split/Permuted/Rotated MNIST, Split CIFAR10/100 và Split TinyImageNet. Module Benchmarks được implement trong PyTorch, vì nó phù hợp hơn để tạo và xử lý dòng dữ liệu một cách động. Trong quá trình training, input và target được chuyển đổi sang định dạng phù hợp để đảm bảo tương thích với cả PyTorch và JAX. Tất cả benchmark được hỗ trợ đều dựa trên lớp BaseBenchmark xử lý hầu hết các trường hợp sử dụng như tải training và validation stream cho task t, cho tất cả task đến t, tức là {1,2,...,t}. Các chức năng tương tự được cung cấp cho khả năng bộ nhớ, như tải memory stream cho một hoặc nhiều task, bổ sung dataset task hiện tại với memories của tất cả task trước đó, v.v. Module benchmark cũng xử lý việc xây dựng dataloader, và input cho thuật toán là một tuple (x,y,t) của input x, target y và task ID t.

**Implement benchmark mới** Gọi T là số lượng task. Mỗi Benchmark phải implement phương thức prepare_datasets trả về hai dictionary có T cặp key-value chứa dataset cho task t∈[T] tương ứng, cho training và validation. Đối với kịch bản New Class, như SplitMNIST hoặc SplitCIFAR100, phương thức tạo ra các dataset rời rạc và đối với kịch bản New Instance, như PermutedMNIST hoặc RotatedMNIST, mỗi dataset được kết hợp với một transformation torchvision cụ thể, liên quan đến permutation hoặc rotation cố định.

### 2.2. Models/Backbones

Module Models chứa các neural network được sử dụng rộng rãi trong văn học, như MultiLayer Perceptron và Convolutional Neural Network, Residual Network. Đối với cả JAX và PyTorch, một lớp BaseBackbone được định nghĩa kế thừa từ flax.nn.Module và torch.nn.Module tương ứng và trang bị cho model chức năng chọn output head cho benchmark NC. Người dùng có thể dễ dàng mở rộng module với các model xuất phát từ văn học hoặc tự tạo bằng cách thay đổi lớp cơ sở thành BaseBackbone. Một utility model cũng được cung cấp nhận input là torch/flax.nn.Module và wrap nó với BaseBackbone phù hợp để tạo thuận lợi cho khả năng import.

### 2.3. Callbacks

Một callback cung cấp hook cho bất kỳ điểm nào trong training và validation, tương tự như Pytorch Lightning. Nó cung cấp khả năng mở rộng hoặc thăm dò thuật toán và/hoặc model trong quá trình fitting. Metric callback đã được implement cho cả JAX và PyTorch và xử lý việc giám sát metric, ví dụ như accuracy và forgetting, và theo dõi tức thời thông qua module Logger. Utility callback có thể được implement, chẳng hạn như TqdmCallback cung cấp thông tin bổ sung trong training thông qua thanh tiến trình.

### 2.4. Loggers

Theo dõi thí nghiệm đã trở thành một phần không thể thiếu của pipeline ML. Do đó, SequeL bao gồm năm logger khác nhau: LocalLogger, ConsoleLogger, WandbLogger, TensorBoardLogger và CometLogger, cho phép người dùng theo dõi các run của họ với dịch vụ ưa thích. Cụ thể, LocalLogger lưu sự phát triển và metric cuối cùng trong một file local, trong khi ConsoleLogger in thông tin dưới dạng bảng trong console. WandbLogger, TensorBoardLogger và CometLogger sử dụng API của các dịch vụ cùng tên, cho phép theo dõi hình ảnh, bảng v.v. và tích hợp với các công cụ trực quan hóa và dashboard mạnh mẽ.

### 2.5. Algorithms

Module Algorithms kiểm soát luồng chương trình và tích hợp tất cả các module đã nêu ở trên. Bằng cách gọi phương thức fit, training với validation xảy ra cho backbone đã chọn cho benchmark đã cho, theo dõi metric thông qua callback tương ứng và log chúng vào dịch vụ mong muốn thông qua logger. Lớp cha BaseAlgorithm xử lý mã kỹ thuật, trong khi các phần thuật toán được implement bởi các lớp con. Lựa chọn thiết kế này được thúc đẩy bởi mong muốn có quyền truy cập vào tất cả biến nội bộ, chẳng hạn như input x và task ID t của batch hiện tại, mà không sử dụng module training riêng biệt. Kết quả là, logic kỹ thuật được giữ tách biệt khỏi mã nghiên cứu thông qua kế thừa. Hình 1 cho thấy một phiên bản đơn giản hóa của luồng chương trình. Mỗi sự kiện được bao quanh bởi các callback cùng tên.

Lớp BaseAlgorithm không phụ thuộc vào framework và chủ yếu thiết lập luồng điều khiển của chương trình, chẳng hạn như training cho một task và sau đó validation task hiện tại và trước đó. Các đặc thù và ràng buộc thiết kế do triết lý PyTorch và JAX áp đặt được xử lý bởi các lớp cơ sở tương ứng, PyTorchBaseAlgorithm và JaxBaseAlgorithm. Ví dụ, đối với PyTorch, batch hiện tại được di chuyển đến thiết bị CUDA phù hợp, trong khi đối với JAX, nó được chuyển đổi sang định dạng NumPy.

BaseAlgorithm cung cấp chức năng cơ bản và sử dụng callback cho các chức năng cụ thể và tùy chỉnh. Nó cũng kế thừa từ BaseCallback và cung cấp các hook giống như được nêu trong Phần 2.3. Nhìn chung, mỗi sự kiện E trong training, ví dụ training_epoch() được bao quanh bởi bốn hook theo trình tự sau: on_before_E, on_before_E_callbacks, E, on_after_E và on_after_E_callbacks. Do đó, người dùng có thể chọn implement một thuật toán thông qua callback cụ thể hoặc trong lớp con để mã nghiên cứu được tập trung trong một file duy nhất. Để cải thiện khả năng đọc, các phương pháp hiện được hỗ trợ chọn cách sau. Tính toán metric, tiện ích để in ra console v.v. được dành riêng cho callback và các hook tương ứng.

Framework bao gồm các implementation cho Naive Finetuning, Elastic Weight Consolidation (EWC), Synaptic Intelligence (SI), Memory Aware Synapses (MAS), Averaged-Gradient Episodic Memory (A-GEM), Less-Forgetting Learning (LFL), Experience Replay (ER), Dark Experience Replay (DER và DER++), Stable SGD, Kernel Continual Learning (KCL), Look Ahead Model Agnostic Meta Learning (LaMAML), và Mode Connectivity Stochastic Gradient Descent (MC-SGD).

**Implement thuật toán mới** SequeL hỗ trợ thuật toán regularization và replay thông qua các component sẵn có. Các lớp cha được implement cho các thực hiện cụ thể của thuật toán dựa trên regularization như Elastic Weight Consolidation. Đối với phương pháp replay, lớp MemoryMechanism và callback tương ứng xử lý việc lưu sample trong bộ nhớ và quá trình lựa chọn của chúng. Đối với thuật toán regularization, loss tổng thể cho sample (x,y,t) của bài toán phân loại là L(x,y) = L_CE(f(x),y) + λ∑_i Ω_i(θ_i - θ_i,old)² trong đó f là neural network được tham số hóa bởi θ, θ_old là tham số ở cuối training của task trước đó, Ω_i chỉ tầm quan trọng của tham số i và λ là hệ số regularization.

Để thêm một phương pháp regularization mới, người dùng chỉ cần implement phương thức calculate_parameter_importance để tính toán Ω_i, trong khi việc lưu trữ các tham số cũ và tính toán regularization loss được xử lý bởi lớp cha. Trong trường hợp các thuật toán như Synaptic Intelligence giữ một tham số nội bộ online ω_i sau đó được sử dụng để tính toán Ω_i, phương thức on_after_training_step chứa các chi tiết thuật toán tương ứng.

**Khả năng tái tạo** Để khuyến khích tính minh bạch, SequeL sử dụng các file cấu hình Hydra để chính thức hóa thí nghiệm. Trong khi một thí nghiệm có thể được xây dựng như trong Code 1, một lựa chọn khác nằm trong việc định nghĩa một file cấu hình, như trong Code 2. Thay vì che khuất hyperparameter và cản trở kết quả có thể tái tạo, một thí nghiệm được định nghĩa với Hydra có thể dễ dàng chia sẻ và báo cáo. Tính năng này được kích hoạt bởi một loạt router chọn đúng benchmark hoặc model, và việc implementation phương thức from_config cho tất cả lớp module liên quan. SequeL bao gồm các file cấu hình như vậy tái tạo baseline Học Liên tục được báo cáo trong nhiều bài báo khác nhau. Các file cấu hình mẫu cùng với các run tái tạo được theo dõi thông qua Weights&Biases được cung cấp; các thí nghiệm tập trung vào RotatedMNIST và bao gồm các thuật toán cổ điển, như EWC và Naive SGD, cũng như các baseline phức tạp hơn trong MCSGD và LaMAML. Danh sách sẽ được mở rộng để đảm bảo tính đúng đắn.

**Điều chỉnh Hyperparameter** Một lợi ích khác của thiết lập dựa trên Hydra là khả năng điều chỉnh hyperparameter sẵn có, cho phép thiết lập nhanh chóng các nghiên cứu ablation. Cụ thể, người dùng chọn file config đã nêu ở trên làm cơ sở và định nghĩa các setting của grid search, chẳng hạn như batch_size∈{10,20,30} và lr∈{0.01,0.1}.

## 3. Công trình liên quan

Sự tiến bộ của cộng đồng Machine Learning có thể được quy cho phần lớn vào sự phát triển của các thư viện Deep Learning, như PyTorch, TensorFlow và JAX, những thư viện này trừu tượng hóa mã kỹ thuật cấp thấp và cung cấp API cấp cao cho người dùng. Do đó, các nhà nghiên cứu và người thực hành có thể phát triển các phương pháp mới một cách đáng tin cậy bằng cách tập trung vào hoạt động nội bộ của thuật toán.

Sự tiến bộ của lĩnh vực kết hợp với thực tế là đa số pipeline ML đều tương tự đã thúc đẩy việc tạo ra các framework cung cấp thêm các trừu tượng. Pytorch Lightning và fastai là các thư viện ML tổng quát mở rộng tính linh hoạt thông qua nhiều callback và logger, đồng thời giảm thiểu chi phí kỹ thuật.

Sự gia tăng dần dần trong trừu tượng hóa đã dẫn đến sự phát triển của các thư viện chuyên biệt hướng tới các lĩnh vực con ML cụ thể và sử dụng phần mềm đã nêu ở trên làm khối xây dựng. Ví dụ, thư viện HuggingFace cho Transformer bao gồm các model được pretrain cho Natural Language Processing và gần đây là Computer Vision. PyTorch Geometric cung cấp một bộ công cụ toàn diện hướng tới Graph Neural Network (GNN). Deep Graph Library cũng tập trung vào deep learning cho graph và cũng không phụ thuộc vào framework, tức là nó hỗ trợ PyTorch, Apache MXNet và TensorFlow. SequeL chia sẻ đặc điểm này và cung cấp cho người dùng tính linh hoạt của hai hệ sinh thái trong PyTorch và JAX. Nhiều gói tồn tại trong văn học Reinforcement Learning, ví dụ OpenAI Gym và OpenAI baselines. MMSegmentation và Segmentation-Models-PyTorch là các toolbox semantic segmentation. Tích hợp Hydra của SequeL chia sẻ triết lý thiết kế của các file cấu hình được sử dụng trong cái trước.

Một khía cạnh quan trọng của toolbox ML tập trung vào theo dõi và giám sát thí nghiệm và đang trở nên quan trọng hơn do độ phức tạp ngày càng tăng của model và phương pháp, nhu cầu nghiên cứu ablation nghiêm ngặt và điều chỉnh hyperparameter. Một số framework giải quyết những yêu cầu này, chẳng hạn như MLFlow, Weights and Biases, Comet và TensorBoard. SequeL tích hợp khả năng logging của các thư viện như vậy và cho phép người dùng theo dõi và trực quan hóa thí nghiệm của họ với dịch vụ mà họ lựa chọn.

Nỗ lực toàn diện để tạo ra các công cụ dễ sử dụng và đáng tin cậy cũng đã được quan sát trong lĩnh vực Học Liên tục. Một số thư viện đã được đề xuất, chẳng hạn như Avalanche, CL-Gym và Sequoia. Avalanche và CL-Gym chia sẻ thiết kế tương tự về cấu trúc module và tập trung vào setting có giám sát. Lựa chọn thuật toán trong CL-Gym bị hạn chế và trong khi Avalanche cung cấp một loạt thuật toán, trọng tâm nằm ở các thuật toán cổ điển hơn. Ví dụ, Kernel Continual Learning và Dark Experience Replay không được implement trong cả hai framework. AvalancheRL mở rộng Avalanche với các chức năng cho Reinforcement Learning. Sequoia tập trung vào góc nhìn Reinforcement Learning của Học Liên tục và sử dụng các component của OpenAI Gym, Avalanche và Continuum. So với các thư viện đã nêu ở trên, SequeL hỗ trợ cả PyTorch và JAX, đơn giản hóa việc so sánh và khả năng import của phương pháp mới và implementation của các phương pháp hiện có bất kể framework.

## 4. Kết luận

Tóm lại, chúng tôi đã trình bày SequeL, một framework Học Liên tục mới được viết bằng cả PyTorch và JAX, nhằm mục đích thống nhất các cơ sở mã phân tán và tạo thuận lợi cho nghiên cứu có thể tái tạo trong lĩnh vực Học Liên tục. Thư viện của chúng tôi cung cấp một nền tảng thuận tiện và linh hoạt cho các nhà nghiên cứu để tạo mẫu và thử nghiệm các thuật toán mới của họ, cũng như so sánh chúng với các phương pháp hiện đại hiện có. Chúng tôi tin rằng thư viện của chúng tôi sẽ góp phần vào sự phát triển của nghiên cứu Học Liên tục và cung cấp một tài nguyên có giá trị cho cộng đồng.

## Phụ lục A. Khả năng tái tạo

SequeL cung cấp các file cấu hình cho mục đích tái tạo và để đảm bảo tính đúng đắn của framework. Hai ví dụ dựa trên kết quả thí nghiệm được báo cáo cho RotatedMNIST được hiển thị trong Code 3 và Code 4. Hướng dẫn cách chạy thí nghiệm cùng với nhiều ví dụ hơn được cung cấp trong repository.

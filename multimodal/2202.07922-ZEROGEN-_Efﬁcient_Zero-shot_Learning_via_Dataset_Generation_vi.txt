# 2202.07922.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2202.07922.pdf
# Kích thước tệp: 678553 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
ZEROGEN: Học Zero-shot Hiệu quả thông qua Sinh Dataset
Jiacheng Ye}y, Jiahui Gaoy, Qintong Li, Hang Xu|, Jiangtao Feng},
Zhiyong Wu},Tao Yu~,Lingpeng Kong}
}Shanghai AI Laboratory|Huawei Noah's Ark Lab~University of Washington
The University of Hong Kong
{carsonye,sumiler,qtli}@connect.hku.hk, xbjxh@live.com,
{fengjiangtao,wuzhiyong}@pjlab.org.cn, {tyu,lpk}@cs.hku.hk
Tóm tắt
Gần đây có sự quan tâm ngày càng tăng đối với việc sinh dataset do khả năng sinh tạo vượt trội của các mô hình ngôn ngữ được tiền huấn luyện lớn (PLMs). Trong bài báo này, chúng tôi nghiên cứu một phương pháp học zero-shot linh hoạt và hiệu quả, ZEROGEN. Đối với một tác vụ zero-shot, trước tiên chúng tôi sinh ra một dataset từ đầu sử dụng PLMs theo cách không giám sát. Sau đó, chúng tôi huấn luyện một mô hình tác vụ nhỏ (ví dụ: LSTM) dưới sự giám sát của dataset tổng hợp. Cách tiếp cận này cho phép suy luận cực kỳ hiệu quả vì mô hình tác vụ cuối cùng chỉ có số lượng tham số ít hơn hàng bậc độ lớn so với PLMs (ví dụ: GPT2-XL). Ngoài việc không cần chú thích và hiệu quả, chúng tôi lập luận rằng ZEROGEN cũng có thể cung cấp những hiểu biết hữu ích từ góc độ chưng cất kiến thức không phụ thuộc mô hình không có dữ liệu, và đánh giá sinh văn bản không tham chiếu. Các thí nghiệm và phân tích trên các tác vụ NLP khác nhau, cụ thể là phân loại văn bản, hỏi đáp, và suy luận ngôn ngữ tự nhiên, cho thấy hiệu quả của ZEROGEN.

1 Giới thiệu
Mặc dù việc sinh dữ liệu huấn luyện bằng mô hình ngôn ngữ không phải là mới đối với xử lý ngôn ngữ tự nhiên (Anaby-Tavor et al., 2020; Puri et al., 2020; Kumar et al., 2020), nhưng gần đây nó đã thu hút sự quan tâm to lớn do khả năng sinh tạo vượt trội của các mô hình ngôn ngữ được tiền huấn luyện quy mô lớn (PLMs). Các ví dụ huấn luyện được tạo ra theo cách này đã được phát hiện hiệu quả trong nhiều tình huống khác nhau thông qua quy trình tăng cường dữ liệu (Lee et al., 2021; Schick và Schütze, 2021; Wang et al., 2021; Meng et al., 2022, và những nghiên cứu khác).

Trong bài báo này, chúng tôi nghiên cứu một tình huống cực đoan của cách tiếp cận như vậy, ZEROGEN. Đối với một tác vụ hạ nguồn, trước tiên chúng tôi sinh ra dữ liệu huấn luyện của nó từ đầu sử dụng một PLM mạnh mẽ, việc sinh tạo này được hướng dẫn bởi các prompt cụ thể cho tác vụ được thiết kế cẩn thận. Công việc được thực hiện khi thực tập tại Shanghai AI Lab. yĐóng góp ngang nhau. Sau đó, chúng tôi huấn luyện một mô hình tác vụ nhỏ (TAM), có số lượng tham số ít hơn hàng bậc độ lớn so với PLMs, dưới sự giám sát của dữ liệu huấn luyện tổng hợp. Văn bản được máy sinh ra là phương tiện duy nhất kết nối PLMs với các mô hình tác vụ cuối cùng, và không cần chú thích của con người trong toàn bộ quá trình. TAM có thể là bất kỳ lựa chọn nào (ví dụ: loglinear hoặc neural), cho phép suy luận hiệu quả¹ và triển khai. Bên cạnh đó, TAM có thể được thiết kế linh hoạt với bất kỳ chiến lược cụ thể nào cho tác vụ (ví dụ: thiên hướng quy nạp hoặc hàm mất mát), có thể cung cấp hiệu suất vượt trội.

Ngoài việc không cần chú thích và hiệu quả, chúng tôi cũng quan tâm đến ZEROGEN vì những lý do sau. Thứ nhất, ZEROGEN có thể được xem là một biến thể của chưng cất kiến thức (KD; Hinton et al. (2015)) cung cấp một số tính năng mới thú vị. Không giống như KD thông thường, ZEROGEN không yêu cầu bất kỳ chú thích của con người nào trong quá trình chưng cất. Hơn nữa, ZEROGEN không đưa ra giả định nào về việc lựa chọn kiến trúc của các mô hình học sinh, do đó chúng ta có thể kết hợp bất kỳ thiên hướng quy nạp cụ thể nào cho tác vụ vào thiết kế của các mô hình học sinh một cách thuận tiện. Thứ hai, ZEROGEN có thể phục vụ như một phương pháp đánh giá không tham chiếu cho sinh văn bản (Guan và Huang, 2020; Pillutla et al., 2021): hiệu suất của các tác vụ hạ nguồn bị chi phối bởi chất lượng của văn bản tổng hợp, do đó có thể phục vụ như một thước đo gián tiếp của các mô hình và thuật toán sinh tạo. Thứ ba, ZEROGEN mở ra những hiểu biết mới về kỹ thuật prompt (Petroni et al., 2019; Brown et al., 2020) (tức là thiết kế các prompt trong PLMs). Vì các prompt thủ công phản ánh kiến thức cơ bản của chúng ta về các tác vụ cụ thể, một câu hỏi hấp dẫn ở đây là chúng ta có thể kết hợp kiến thức hoặc hướng dẫn của con người vào các prompt này đến mức độ nào.

Chúng tôi đánh giá ZEROGEN trong ba tác vụ NLP là phân loại văn bản, hỏi đáp, và ¹Amazon ước tính rằng 90% chi phí cơ sở hạ tầng ML sản xuất là cho suy luận, chứ không phải huấn luyện (Jain et al., 2019). arXiv:2202.07922v2 [cs.CL] 22 Oct 2022

--- TRANG 2 ---
suy luận ngôn ngữ tự nhiên, trên sáu dataset. Các phát hiện nghiên cứu chính của chúng tôi được tóm tắt như sau:

• Hiệu suất zero-shot của TAM trong khung ZEROGEN vượt trội đáng kể so với các đối tác PLM của nó (thường phục vụ như các mô hình giáo viên trong bối cảnh chưng cất kiến thức), chỉ với 0.4% số lượng tham số (§4.2);

• Trong một số thiết lập tài nguyên thấp, TAM được huấn luyện với dữ liệu tổng hợp thậm chí còn vượt trội hơn cùng một mô hình được huấn luyện với chú thích con người theo cách giám sát hoàn toàn (§4.3);

• Chất lượng của văn bản được sinh ra bởi các mô hình và thuật toán đã biết được phản ánh tốt trong hiệu suất của các tác vụ hạ nguồn, và các chiến lược giải mã khuyến khích sự đa dạng nhiều hơn cũng dẫn đến nhiều nhiễu hơn (§4.4);

• Kỹ thuật prompt là thử thách – hiệu suất của các prompt hướng dẫn hơn hoặc theo phong cách ngôn ngữ tự nhiên thay đổi trong các tác vụ khác nhau (§4.5).

Kết luận, chúng tôi lập luận rằng ZEROGEN là một cách tiếp cận khả thi và đầy hứa hẹn hướng tới học zero-shot linh hoạt và hiệu quả trong NLP. Nó cũng có tiềm năng lớn như một phương pháp chưng cất kiến thức không phụ thuộc mô hình không có dữ liệu và đánh giá văn bản không tham chiếu. Mã của chúng tôi có thể được tìm thấy tại https://github.com/HKUNLP/ZeroGen.

2 Sơ bộ: Học Zero-Shot dựa trên Prompt
Chúng tôi bắt đầu với kiến thức sơ bộ về khung học zero-shot dựa trên prompt (có tên là PROMPTING).

Cho một mô hình ngôn ngữ được tiền huấn luyện (PLM) P và một tác vụ phân loại văn bản (TC) D = (X; Y), PROMPTING trước tiên khởi tạo một prompt T() với mỗi đầu vào xi ∈ X và xuất ra một chuỗi ngôn ngữ tự nhiên để được hoàn thành bởi P. Ví dụ, chúng tôi cho thấy một ví dụ về tác vụ phân tích cảm xúc trong Hình 1(a), trong đó xi là "A deep and meaningful film." và T(xi) là "A deep and meaningful film. The sentiment of the movie review is ".

Hơn nữa, PROMPTING định nghĩa một verbalizer M() ánh xạ mỗi nhãn/lớp yi thành một từ/các từ trong từ vựng của P. Ví dụ, "positive" và "negative" đại diện cho hai lớp. Theo cách này, PROMPTING mô hình hóa xác suất của lớp yi ∈ Y cho xi như:

p(yi|xi) = P(M(yi)|T(xi)). (1)

Trong suốt quá trình, các trọng số được tiền huấn luyện của P bị đóng băng và không cần huấn luyện.

Kiến thức ngôn ngữ rộng lớn (Jawahar et al., 2019; Goldberg, 2019; Tenney et al., 2019) và thực tế (Petroni et al., 2019; Jiang et al., 2020b) được mã hóa trong các tham số của PLMs là chìa khóa hướng tới thành công của PROMPTING. Tuy nhiên, PROMPTING không thể phát huy đầy đủ khả năng của PLMs và phụ thuộc nhiều vào PLMs khổng lồ trong quá trình suy luận. Điều này thúc đẩy chúng tôi khám phá một cách tiếp cận linh hoạt và hiệu quả hơn để thực hiện học zero-shot với PLMs.

3 ZEROGEN
Trong công việc này, chúng tôi đưa phương pháp sinh dataset đến mức cực đoan và nghiên cứu ZEROGEN, một khung học zero-shot linh hoạt và hiệu quả thông qua sinh dataset. Khung ZEROGEN bao gồm ba giai đoạn tuần tự như được thể hiện trong Hình 1(b):

1. Mục tiêu của giai đoạn đầu tiên là sử dụng sức mạnh sinh tạo của PLMs để tổng hợp một dataset để giải quyết tác vụ hạ nguồn. Với các prompt được thiết kế cẩn thận và một PLM mạnh mẽ, dataset được sinh ra được tin là kết hợp kiến thức phong phú cụ thể cho tác vụ.

2. Với dataset giả được tổng hợp như trên, chúng tôi sau đó huấn luyện một mô hình tác vụ nhỏ (TAM) để giải quyết tác vụ. TAM có thể tích hợp với bất kỳ thiên hướng quy nạp cụ thể nào cho tác vụ và cũng nhỏ hơn hàng bậc độ lớn so với PLMs.

3. Cuối cùng, chúng tôi thực hiện suy luận hiệu quả trên tác vụ đích sử dụng mô hình được huấn luyện. Trong suốt quá trình, không có chú thích của con người nào được liên quan, do đó thiết lập đánh giá là hoàn toàn zero-shot.

Sinh dataset giả Đối với một tác vụ phân loại câu đơn D, chúng tôi nhằm sinh ra một dataset giả Dg = (Xg; Yg) với sự trợ giúp của một PLM từ trái sang phải P. Trước tiên chúng tôi lấy mẫu một nhãn lớp yg từ một phân phối đồng đều:

yg ∼ U(y1, y2, ..., yk); (2)

trong đó k là số lượng lớp. yg sau đó được bọc vào một prompt mô tả nhãn T(yg) để hướng dẫn việc sinh ra xg:

xg ∼ P(·|T(yg)). (3)

Vì các tham số của P bị đóng băng và việc sinh ra xg cho mỗi yg là tất định, chúng ta có thể

--- TRANG 3 ---
[Hình 1 được mô tả: (a) Khung học zero-shot dựa trên prompt (PROMPTING). Văn bản màu xanh là câu cần được phân loại. Sau khi nối câu với mỗi prompt, một PLM khổng lồ (ví dụ: GPT-3) được sử dụng để tính điểm khả năng LM cho mỗi lớp. (b) Khung ZEROGEN của chúng tôi. Trước tiên chúng tôi sinh ra một tập huấn luyện với PLM theo cách hoàn toàn không giám sát. Sau các hoạt động lọc đơn giản, chúng tôi sau đó huấn luyện một mô hình tác vụ nhỏ (ví dụ: LSTM) để suy luận linh hoạt và hiệu quả. Đường nét đứt cho biết rằng quy trình huấn luyện chỉ được thực hiện một lần trước khi suy luận.]

áp dụng các thuật toán lấy mẫu khác nhau (ví dụ: lấy mẫu Top-k (Fan et al., 2018) và lấy mẫu nucleus (Holtzman et al., 2020)) để tăng sự đa dạng của dataset được sinh ra. Sau đó chúng tôi ghép xg được sinh ra với yg để xây dựng dữ liệu huấn luyện giả.

Chúng tôi cho thấy một ví dụ về việc sinh ra một dataset phân loại cảm xúc giả trong Hình 1(b). Prompt T(yg) cho một nhãn tích cực yg là "The movie review in positive sentiment is: " ". Với các chiến lược lấy mẫu, prompt này hướng dẫn PLMs sinh ra nhiều câu kết thúc bằng một dấu ngoặc kép khác, ví dụ: " A deep and meaningful movie." " hoặc " Good film!!!" ".

Đối với các tác vụ phân loại cặp câu, chúng ta cần sinh ra hai chuỗi có mối quan hệ nhất định (ví dụ: tiền đề và giả thuyết trong NLI, ngữ cảnh và câu hỏi trong QA). Chúng tôi phân tách việc sinh ra thành hai bước: (i) Trước tiên chúng tôi sinh ra và/hoặc lấy mẫu một ngữ cảnh có điều kiện cg (ví dụ: cg đại diện cho tiền đề trong NLI và ngữ cảnh trong QA). Ngữ cảnh cg sau đó được nối với một nhãn được lấy mẫu yg và chuyển đổi thành một prompt T(cg, yg). (ii) Với prompt T(cg, yg), giờ chúng ta có thể sinh ra câu còn lại xg (ví dụ: giả thuyết trong NLI và câu hỏi trong QA) như trong Phương trình (3). Trong việc triển khai hiện tại, chúng tôi lấy mẫu cg từ một corpus không có nhãn. Nhưng cg cũng có thể được sinh ra theo quy trình sinh tạo cho tác vụ phân loại câu đơn. Vì có thể không có tập nhãn được định nghĩa trước cho tác vụ QA trích xuất, chúng tôi sử dụng bộ công cụ spaCy² có sẵn công khai để chú thích các thực thể, và sau đó chọn đồng nhất một thực thể làm yg. Cuối cùng, cặp câu và nhãn được sinh ra có thể tạo thành dataset giả Dg = (Cg, Xg, Yg). Chúng tôi trình bày chi tiết về các prompt được chọn cho mỗi tác vụ trong Phần 4.5.

Huấn luyện giả giám sát Với dataset giả Dg, chúng tôi huấn luyện một mô hình tác vụ nhỏ TAM để thực hiện tác vụ đã cho. Quy trình này có tính linh hoạt cao, có nghĩa là chúng ta có thể sử dụng bất kỳ kiến trúc mô hình, hàm mất mát, và chiến lược huấn luyện nào. Trong công việc này, chúng tôi chủ yếu tập trung vào khung tổng thể, do đó chúng tôi để lại việc điều chỉnh các thành phần này cho nghiên cứu tương lai. Dưới thiết lập học zero-shot, cần lưu ý rằng chúng ta không có quyền truy cập vào tập validation tiêu chuẩn. Do đó, chúng tôi sử dụng một phần (ví dụ: 10%) của dataset giả làm tập validation để lựa chọn mô hình.

Đánh giá zero-shot Cuối cùng, chúng tôi thực hiện suy luận trên mô hình TAM đã huấn luyện. Vì TAM nhỏ hơn hàng bậc độ lớn so với PLM, nó có thể thực hiện suy luận cực kỳ hiệu quả.

²https://spacy.io/

--- TRANG 4 ---
[Bảng 1: Kết quả đánh giá cho ZEROGEN ở ba quy mô khác nhau của PLM và hai quy mô khác nhau của TAM. Các kết quả ZEROGEN vượt trội hơn PROMPTING sử dụng cùng PLM được tô màu xám, và kết quả tốt nhất cho mỗi tác vụ sử dụng cùng PLM được in đậm. ★ cho biết kết quả của TAM dưới khung ZEROGEN vượt trội hơn cùng TAM dưới khung SUPERVISED. Chúng tôi báo cáo số lượng tham số trung bình (tức là 7M) cho các mô hình dựa trên LSTM trong các tác vụ khác nhau. Quy mô của dataset tổng hợp là 200k cho mỗi tác vụ. Kết quả trên PLMs lớn hơn được báo cáo trong §4.6.]

4 Thí nghiệm
4.1 Thiết lập
Chúng tôi thực hiện thí nghiệm trên ba tác vụ khác nhau bao gồm sáu dataset NLP khác nhau. Thiết lập thí nghiệm chi tiết (tức là Chi tiết Triển khai) được mô tả trong Phụ lục A.

Datasets Chúng tôi xem xét hai dataset Phân loại Văn bản (tức là SST-2 (Socher et al., 2013) và IMDb (Maas et al., 2011)), hai dataset Suy luận Ngôn ngữ Tự nhiên (tức là QNLI (Rajpurkar et al., 2016) và RTE (Dagan et al., 2005; Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009)), và hai dataset Hỏi Đáp (tức là SQuAD1.1 (Rajpurkar et al., 2016) và AdversarialQA (Bartolo et al., 2020)). Số lượng ví dụ huấn luyện cho SST-2 và RTE là 6.9k và 2.5k, có thể được coi là tài nguyên thấp so với IMDb (25k), QNLI (105k), SQuAD (87k) và AdversarialQA (30k). Chúng tôi sử dụng Exact-Match (EM) và F1 làm các thước đo cho các tác vụ hỏi đáp và Accuracy cho các tác vụ khác.

Baselines Chúng tôi so sánh khung ZEROGEN với hai baseline: (1) PROMPTING. Khung học zero-shot dựa trên prompt thông qua PLMs. Chúng tôi sử dụng GPT2 (117M), GPT2-large (762M), và GPT2-XL (1.5B) (Radford et al., 2019) thông qua thư viện HuggingFace Transformers (Wolf et al., 2019). (2) SUPERVISED. Các TAM được huấn luyện trên dataset tiêu chuẩn (tức là chú thích con người). Về kiến trúc mô hình của TAMs, chúng tôi sử dụng hai loại mô hình cho mỗi tác vụ: một mô hình dựa trên LSTM (tức là BiLSTM (Hochreiter và Schmidhuber, 1997) cho các tác vụ TC và NLI, và BiDAF (Seo et al., 2017) cho tác vụ QA), và một mô hình được tiền huấn luyện nhỏ (tức là DistilBERT (Sanh et al., 2019)).

Chiến lược Đánh giá Do quyền truy cập tập test bị hạn chế cho một số dataset (tức là SQuAD1.1 và SST-2), chúng tôi tách một tập con nhỏ (tức là 10%) của tập huấn luyện để làm validation cho mô hình được huấn luyện trong thiết lập SUPERVISED, và báo cáo kết quả trên tập validation. Đối với các mô hình được huấn luyện với dataset tổng hợp trong khung ZEROGEN, chúng tôi cũng sử dụng một phần (tức là 10%) làm tập validation, mà không truy cập vào tập validation gốc. Đối với PROMPTING, chúng tôi đánh giá trực tiếp trên tập validation gốc.

4.2 ZEROGEN so với PROMPTING
Bảng 1 so sánh ZEROGEN với khung PROMPTING. Chúng tôi quan sát thấy rằng ZEROGEN vượt trội đáng kể so với PROMPTING trên hầu hết các dataset chúng tôi đánh giá, và sự vượt trội này nhất quán qua các PLM generator và TAM khác nhau. Cụ thể, khi sử dụng DistilBERT làm TAM, chúng tôi thấy rằng trong 18 (3 generators × 6 tasks) so sánh trực tiếp với PROMPTING, ZEROGEN đạt hiệu suất tốt hơn trong 15 trường hợp³. Lý do cho hiệu suất vượt trội chủ yếu có hai mặt: 1) so với mô hình sinh tạo mục đích chung, mô hình phân loại cụ thể cho tác vụ có thể khuyến khích một quyết định ranh giới tất định hơn, chia sẻ cùng tinh thần với tối thiểu hóa entropy (Grandvalet và Bengio, 2006) hoặc tự huấn luyện (Lee et al., 2013), và 2) các tác vụ phân loại hưởng lợi từ thiên hướng quy nạp trong kiến trúc. Ví dụ, phương pháp dự đoán vị trí bắt đầu và kết thúc thu hẹp đáng kể không gian tìm kiếm cho các tác vụ hỏi đáp trích xuất, so với sinh tạo tự do trên không gian từ vựng.

Bên cạnh hiệu quả vượt trội trong học zero-shot, cũng đáng chú ý rằng ZEROGEN cũng khá hiệu quả. ZEROGEN có thể đạt được hiệu suất tương đương (LSTM) và thậm chí tốt hơn (DistilBERT) so với PROMPTING, sử dụng ít hơn 200 lần và 20 lần tham số, tương ứng. Ngày nay, với các mô hình ngôn ngữ được tiền huấn luyện ngày càng lớn hơn (ví dụ: GPT-3 175B (Brown et al., 2020), Switch-C 1571B (Fedus et al., 2021)), lợi thế của ZEROGEN trở nên thậm chí còn rõ ràng hơn. Các PLM khổng lồ có thể cải thiện chất lượng của dataset tổng hợp và dẫn đến hiệu suất zero-shot tốt hơn. Trong khi đó, TAM có thể vẫn nhẹ để suy luận và phục vụ hiệu quả.

Hơn nữa, khi mở rộng quy mô PLMs, chúng tôi quan sát thấy sự cải thiện hiệu suất liên tục cho cả PROMPTING và ZEROGEN. Điều này cho thấy rằng các PLM quy mô lớn hơn có thể đã được huấn luyện để lưu trữ nhiều kiến thức hơn có ích cho việc sinh ra dataset chính xác cho một tác vụ.

4.3 ZEROGEN so với SUPERVISED
Thường được chấp nhận rằng hiệu suất zero-shot của một mô hình NLP có thể thua kém đáng kể so với hiệu suất giám sát hoàn toàn của nó (được huấn luyện trên chú thích con người). Tuy nhiên, chúng tôi thấy rằng ZEROGEN thậm chí vượt trội hơn đối tác SUPERVISED của nó trên các dataset SST-2 và RTE (được tô sáng trong Bảng 1). Phỏng đoán của chúng tôi là kích thước của các dataset là yếu tố chính. ZEROGEN tự động sinh ra nhiều dữ liệu hơn như sự giám sát trong quá trình huấn luyện (tức là 200k mẫu tổng hợp so với 6.9k/2.5k chú thích con người). Những kết quả này đáng khuyến khích vì chúng cho thấy rằng: (i) ZEROGEN khá hiệu quả trong tình huống tài nguyên thấp; (ii) có thể tổng hợp các mẫu huấn luyện để xấp xỉ chú thích con người theo cách hoàn toàn không giám sát.

Chúng tôi tiếp tục nghiên cứu xem chúng ta có thể đánh đổi khối lượng dữ liệu để đổi lấy hiệu suất zero-shot trong ZEROGEN hay không. Kết quả của chúng tôi được thể hiện trong Hình 2. Tổng thể, chúng tôi thấy rằng hiệu suất cuối cùng cải thiện liên tục khi lượng dữ liệu tăng lên, mặc dù có lợi ích giảm dần. Chúng tôi thấy rằng việc sinh ra 10k mẫu huấn luyện dẫn đến hiệu suất tốt hơn

³Lưu ý rằng với thiết kế và lựa chọn prompt cẩn thận, baseline PROMPTING của chúng tôi đạt được độ chính xác 89.22% với GPT2-XL trên dataset SST-2, cao hơn đáng kể so với kết quả tốt nhất trước đó (tức là 87.4% (Holtzman et al., 2021))

--- TRANG 5 ---
[Hình 2: Kết quả so sánh các quy mô khác nhau của dataset tổng hợp trên các tác vụ khác nhau. Chúng tôi sử dụng GPT2-XL làm PLM và DistilBERT làm TAM. Các điểm với marker hình sao và thanh lỗi là hiệu suất trung bình và độ lệch chuẩn trên 3 lần chạy, tương ứng.]

so với phương pháp PROMPTING trên hầu hết các dataset. Ngoài ra, bằng cách tăng kích thước dữ liệu, chúng tôi thấy rằng ZEROGEN thậm chí vượt trội hơn baseline SUPERVISED trên SST-2 và RTE. Nhưng vẫn còn, trên một số dataset được kiểm tra (ví dụ: SQuAD, QNLI), vẫn có khoảng cách hiệu suất giữa ZEROGEN và SUPERVISED.

4.4 ZEROGEN như Bộ Đánh giá Sinh Văn bản
Chất lượng của văn bản tổng hợp là chìa khóa cho hiệu suất của các tác vụ hạ nguồn. Do đó ZEROGEN có thể được xem như một thước đo gián tiếp của các mô hình và thuật toán sinh tạo. Thường được chấp nhận rằng chất lượng của văn bản được sinh ra nên theo thứ tự tăng dần trong GPT-2, GPT2-Large, và GPT2-XL, do sự tăng trưởng trong kích thước tham số. Chúng tôi thấy rằng xu hướng này phù hợp tốt với hiệu suất ứng dụng hạ nguồn (Bảng 1).

Ngoài mô hình, một khía cạnh quan trọng khác trong sinh văn bản là thuật toán giải mã của nó, trong đó mục tiêu là đạt được sự đa dạng tốt hơn mà không làm giảm chất lượng văn bản (ví dụ: tính trôi chảy, mạch lạc, và tính đúng đắn). Chúng tôi cho thấy cách sự đánh đổi giữa đa dạng và tính đúng đắn được phản ánh trong khung ZEROGEN.

Kết quả Tổng thể Các chiến lược lấy mẫu (ví dụ: lấy mẫu top-k và lấy mẫu nucleus) được biết đến là có thể sinh ra văn bản với mức độ đa dạng cao hơn so với các chiến lược giải mã khác (ví dụ: tìm kiếm tham lam) (Fan et al., 2018; Holtzman et al., 2020). Kết quả thực nghiệm trong Bảng 2 cho thấy rằng một chiến lược giải mã đa dạng hơn không phải lúc nào cũng đảm bảo hiệu suất tốt hơn trên các tác vụ hạ nguồn. Ví dụ, kết quả của chiến lược lấy mẫu nucleus, được coi là sinh ra dữ liệu đa dạng nhất, đạt hiệu suất thấp hơn gần 6% và 3% so với chiến lược giải mã tốt nhất trên cả dataset SQuAD và QNLI,

[Bảng 2: Kết quả so sánh các phương pháp giải mã khác nhau với các tham số được chọn của mỗi phương pháp. Kết quả tốt nhất dưới các phương pháp giải mã khác nhau được in đậm.]

tương ứng, trong khi chiến lược giải mã tham lam có thể đạt được kết quả tốt hơn so với một số chiến lược lấy mẫu (ví dụ: top-k=40, top-k=80 và lấy mẫu nucleus). Ngược lại, tất cả các chiến lược lấy mẫu đều vượt trội hơn chiến lược giải mã tham lam trên dataset IMDb. Về hiệu suất hạ nguồn tốt hơn không nhất quán của các chiến lược giải mã đa dạng hơn, chúng tôi đưa ra giả thuyết rằng sự đa dạng có thể đi kèm với một cái giá, chẳng hạn như sinh ra các mẫu không thuộc về lớp được mô tả trong prompt. Do đó, chúng tôi đánh giá chất lượng của một dataset từ hai góc độ: Đa dạng và Tính đúng đắn để phân tích định lượng các dataset khác nhau.

Đa dạng Chúng tôi theo dõi các công trình trước đây (Holtzman et al., 2020) và tính Self-BLEU (Zhu et al., 2018) như một thước đo của sự đa dạng. Self-BLEU được tính bằng cách tính điểm BLEU của mỗi văn bản được sinh ra sử dụng tất cả các sinh tạo khác trong tập đánh giá làm tham chiếu⁴. Điểm Self-BLEU thấp hơn ngụ ý sự đa dạng cao hơn. Chúng tôi báo cáo Self-BLEU dựa trên 4-gram trong phần đầu của Bảng 3. Chúng tôi thấy rằng các chiến lược giải mã như lấy mẫu top-k và nucleus dẫn đến các sinh tạo đa dạng hơn. Phát hiện này nhất quán với các công trình trước đây (Li et al., 2016; Vijayakumar et al., 2016; Welleck et al., 2020; Holtzman et al., 2020).

⁴Cụ thể, chúng tôi lấy mẫu ngẫu nhiên 1000 sinh tạo, mỗi cái được so sánh với tất cả 999 sinh tạo khác làm tham chiếu.

--- TRANG 6 ---
[Bảng 3: Đánh giá Đa dạng và Tính đúng đắn của các dataset được sinh ra dưới các chiến lược giải mã khác nhau. Oracle đề cập đến dataset tiêu chuẩn với chú thích con người. Đa dạng được đo bằng Self-BLEU4, trong khi Tính đúng đắn được đo bằng một mô hình RoBERTa-Large được huấn luyện tốt với dataset tiêu chuẩn.]

Tính đúng đắn Khác với tình huống sinh tạo vanilla kết thúc với văn bản được sinh ra, chúng tôi sử dụng văn bản được sinh ra như dataset huấn luyện cho một mô hình nhỏ khác. Do đó, ZEROGEN yêu cầu nhấn mạnh nhiều hơn vào tính đúng đắn của văn bản được sinh ra, tức là liệu văn bản được sinh ra có thuộc về lớp tương ứng được mô tả trong prompt hay không. Để truy cập tính đúng đắn của một dataset tổng hợp, trước tiên chúng tôi huấn luyện một mô hình RoBERTa-Large (Liu et al., 2019) trên dataset huấn luyện tiêu chuẩn, sau đó được sử dụng như một bộ xác thực để đánh giá dataset tổng hợp. Tóm lại, chúng tôi thấy một sự đánh đổi giữa đa dạng và tính đúng đắn, tức là đa dạng lớn hơn dẫn đến tính đúng đắn thấp hơn. Chúng tôi nhận thấy thậm chí kết quả xấu đi bằng cách tăng k, trong khi tìm kiếm tham lam đạt hiệu suất cao nhất về tính đúng đắn. Những kết quả này phản ánh những kết quả của Massarelli et al. (2020) người cũng thấy một sự đánh đổi giữa tính thực tế và đa dạng, tức là trong khi các chiến lược giải mã như lấy mẫu top-k và nucleus dẫn đến các sinh tạo ít lặp lại hơn, chúng cũng tạo ra văn bản ít có thể xác minh hơn. Bên cạnh đó, trong các tác vụ khác nhau, chúng tôi thấy tính đúng đắn trên các dataset oracle tương tự (tức là tất cả đều lớn hơn 90%), trong khi điều đó thay đổi đáng kể trên các dataset tổng hợp (tức là lên tới 94.46% trên IMDb và chỉ 31.07% trên SQuAD). So với việc sinh ra dataset cho các tác vụ phân loại văn bản đơn (ví dụ: IMDb), nơi PLM chỉ cần xem xét một điều kiện đơn (tức là nhãn), sinh tạo cho các tác vụ cặp văn bản yêu cầu PLMs xem xét nhiều điều kiện cùng lúc (ví dụ: câu trả lời và ngữ cảnh khi sinh ra câu hỏi), điều này làm cho việc kiểm soát tính đúng đắn của mẫu được sinh ra trở nên khó khăn hơn. Điều này có thể giải thích sự khác biệt quan sát được giữa các tác vụ.

Đánh giá Con người Chúng tôi báo cáo kết quả đánh giá con người trong Bảng 4. Chất lượng của dữ liệu được sinh ra được đo bằng các thước đo tính đúng đắn và tự nhiên. Tính đúng đắn đo xem nhãn có đúng hay không và nội dung có liên quan đến chủ đề tác vụ hay không (ví dụ: đánh giá phim cho IMDb). Tính tự nhiên đo xem văn bản được sinh ra có trôi chảy và giống với văn bản do con người sinh ra hay không. Chúng tôi mời 4 chuyên gia tham gia đánh giá và mỗi người tham gia được phân công ngẫu nhiên 25 mẫu được sinh ra (tổng cộng 100 mẫu) cho mỗi chiến lược giải mã. Bảng 4 báo cáo điểm trung bình. Kết quả cho thấy tìm kiếm tham lam đạt hiệu suất cao nhất về tính đúng đắn, phù hợp với đánh giá tự động sử dụng Roberta-Large. Tuy nhiên, về tính tự nhiên/trôi chảy, tìm kiếm tham lam hoạt động tệ nhất. Các chiến lược giải mã top-k và nucleus có thể sinh ra ngữ cảnh trôi chảy hơn.

[Bảng 4: Đánh giá con người trên dataset vàng và tổng hợp IMDb sử dụng các chiến lược giải mã khác nhau. Chúng tôi cũng hiển thị hiệu suất TAM để cho thấy khả năng của ZEROGEN như một bộ đánh giá.]

4.5 Kỹ thuật Prompt trong ZEROGEN
Thiết kế prompt có thể có tác động lớn đến PROMPTING, như được chỉ ra bởi nhiều công trình trước đây (Mishra et al., 2021a; Wei et al., 2022). Trong phần này, chúng tôi nghiên cứu cách thiết kế prompt hướng dẫn sinh văn bản và ảnh hưởng đến hiệu suất của ZEROGEN. Chúng tôi kiểm tra ba loại prompt thường được sử dụng: (1) Control code (Keskar et al., 2019), (2) Control code với mô tả tác vụ, (3) Phong cách ngôn ngữ tự nhiên. Đối với SST-2 và IMDb, ví dụ prompt và kết quả tương ứng có thể được tìm thấy trong Bảng 5 (xem Phụ lục A cho các tác vụ khác).

Từ Bảng 5, trước tiên chúng tôi quan sát thấy rằng các prompt ngôn ngữ tự nhiên được ưa chuộng bởi cả ZEROGEN và PROMPTING, hơn là các prompt chứa control code. Chúng tôi đưa ra giả thuyết lý do là trong quá trình tiền huấn luyện, phần lớn dữ liệu văn bản được cung cấp cho PLMs là các câu ngôn ngữ tự nhiên, và do đó PLMs không chứa đủ kiến thức trong control code. Hơn nữa, chúng tôi quan sát thấy rằng ZEROGEN mạnh mẽ hơn đối với các prompt khác nhau so với PROMPTING: đối với PROMPTING, một thay đổi nhỏ từ P4 sang P5 sẽ dẫn đến sự giảm lớn về độ chính xác (giảm 16.2% trong IMDb); đối với ZEROGEN, áp dụng cùng một sự điều chỉnh prompt, sự giảm sút giảm xuống 9.4%. So với PROMPTING sử dụng prompt để trực tiếp hướng dẫn các từ nhãn, ZEROGEN sử dụng dữ liệu tổng hợp như phương tiện để kết nối PLM và TAM, do đó giảm thiểu sự thay đổi đột ngột do prompt mang lại.

Để khám phá thêm tiềm năng của prompting, chúng tôi nghiên cứu prompt có điều kiện hai giai đoạn lấy cảm hứng từ (Schick và Schütze, 2021). Trong ví dụ đang chạy, dựa trên đặc điểm tác vụ (để sinh ra một đánh giá phim), trước tiên chúng tôi sinh ra tên phim sử dụng prompt [Movie: "] và sau đó

--- TRANG 7 ---
[Bảng 5: Kết quả cho các prompt khác nhau trên các tập dev IMDb và SST-2. Chúng tôi sử dụng GPT2-XL làm PLM và DistilBERT làm TAM. <X> và <C> đại diện cho câu đầu vào và tên phim được sinh ra tương ứng. P0 đại diện cho phiên bản được điều chỉnh nhỏ của P cho sinh văn bản. Đối với ZEROGEN, kết quả được báo cáo sử dụng 100k mẫu huấn luyện. Điểm được gạch chân được huấn luyện trên 10k mẫu được sinh ra, vì prompt (P01 & P2) quá yếu và không thể sinh ra 100k mẫu khác biệt.]

sinh ra câu sử dụng P04. Chúng tôi có thể thấy rằng với sự kiểm soát của tên phim, corpus huấn luyện được sinh ra đa dạng hơn so với sử dụng P4. Với tính đúng đắn mong muốn (xem Bảng 3), sự đa dạng cao hơn dẫn đến độ chính xác cao hơn (từ 81.84 lên 83.40 trong IMDb).

Loại prompting phù hợp nhất trong các tác vụ Hỏi Đáp và Suy luận Ngôn ngữ Tự nhiên có một số khác biệt với Phân loại Văn bản do đặc điểm tác vụ khác nhau. Để biết chi tiết, vui lòng tham khảo Phụ lục B.

4.6 ZEROGEN thông qua PLM Generator Lớn hơn
Chúng tôi tiếp tục nghiên cứu hiệu suất của ZEROGEN trên một PLM lớn hơn (tức là OPT (Zhang et al., 2022) với 175B tham số). Chúng tôi thấy cả PROMPTING và ZEROGEN đều hưởng lợi từ PLM lớn hơn trên các tác vụ khó (tức là SQuAD). Nhưng trên các tác vụ phân loại văn bản tương đối đơn giản hơn, kết quả giảm đi. Điều này cho thấy rằng việc lựa chọn prompt vẫn quan trọng đối với các mô hình lớn hơn, và prompt phù hợp với một mô hình (ví dụ: GPT2-XL) có thể không phù hợp với mô hình khác (ví dụ: OPT).

[Bảng 6: So sánh GPT2-XL (1.5B) và OPT (175B) dưới cùng prompt và chiến lược giải mã.]

5 Các Công trình Liên quan
5.1 Học Zero-shot dựa trên Prompt
Với prompt ngôn ngữ tự nhiên được chế tạo thủ công, các PLM quy mô lớn đã thể hiện khả năng zero-shot ấn tượng trong một loạt các tác vụ NLP rộng rãi (Radford et al., 2019; Brown et al., 2020). Tuy nhiên, học zero-shot dựa trên prompt hiện tại có thể không ổn định: việc lựa chọn prompt đóng góp rất nhiều vào hiệu suất cuối cùng. Điều này thúc đẩy các nhà nghiên cứu điều tra những cách tốt hơn để tự động tìm kiếm và/hoặc xây dựng thủ công một prompt phù hợp (Jiang et al., 2020a; Shin et al., 2020; Reynolds và McDonell, 2021; Mishra et al., 2021b). Để cải thiện khả năng tổng quát zero-shot trên các prompt khác nhau, một dòng nghiên cứu khác sử dụng hỗn hợp huấn luyện đa tác vụ được tạo thành từ một tập lớn các tác vụ khác nhau được chỉ định trong các prompt ngôn ngữ tự nhiên. Điều này khuyến khích một mô hình tổng quát hóa tốt hơn cho các tác vụ chưa thấy, cũng như mạnh mẽ hơn đối với các lựa chọn từ ngữ của các prompt. (Khashabi et al., 2020; Zhong et al., 2021; Mishra et al., 2021c; Wei et al., 2021; Sanh et al., 2021; Xu et al., 2022). So sánh, chúng tôi ủng hộ và phân tích một mô hình mới cho học zero-shot dựa trên prompt thông qua sinh dataset, bổ sung cho các phương pháp tìm kiếm prompt và huấn luyện trước đa tác vụ hiện tại.

5.2 Sinh Dataset với PLMs
Công trình của chúng tôi cũng liên quan đến nghiên cứu về sinh dữ liệu với PLMs, nhằm mục đích sinh ra một dataset giả để tăng cường hiệu suất mô hình. Các nỗ lực sớm đạt được mục tiêu này với các mô hình sinh tạo được tinh chỉnh (Anaby-Tavor et al., 2020; Puri et al., 2020; Kumar et al., 2020; Lee et al., 2021). Họ đầu tiên tinh chỉnh các mô hình sinh tạo sử dụng chú thích con người, các mẫu dữ liệu được sinh ra sau đó được kết hợp với chú thích con người để huấn luyện các mô hình theo cách bán giám sát. Các phương pháp sinh dữ liệu có giám sát cũng được nghiên cứu để xây dựng các tác vụ phụ trợ (Vu et al., 2021) và tạo dataset dựa trên sự hợp tác giữa con người và máy (Liu et al., 2022). Để giảm nỗ lực con người trong chú thích dữ liệu, một dòng nghiên cứu khác khám phá các phương pháp sinh dữ liệu mà không cần chú thích con người. He et al. (2021) sử dụng các mô hình sinh tạo vô điều kiện được huấn luyện không giám sát để tổng hợp dữ liệu không nhãn cho học bán giám sát. Mà không cần bất kỳ huấn luyện mô hình nào, Wang et al. (2021) đề xuất trực tiếp sử dụng các ví dụ trong miền không nhãn làm prompt để tổng hợp dữ liệu huấn luyện chất lượng cao. Schick và Schütze (2021) khám phá phương pháp sinh dataset từ đầu cho tác vụ tương tự ngữ nghĩa văn bản. Một công việc đồng thời (Meng et al., 2022) nghiên cứu sinh dataset cho các tác vụ phân loại văn bản và suy luận ngôn ngữ tự nhiên. So sánh, chúng tôi đưa khung sinh dataset đến mức cực đoan, tức là xem xét các mô hình edge cực kỳ nhỏ (ví dụ: LSTM), khám phá các tác vụ NLP rộng hơn bao gồm hỏi đáp, và tiến hành phân tích mở rộng như các chiến lược giải mã và đánh giá chất lượng.

6 Kết luận và Hướng Tương lai
Trong bài báo này, chúng tôi nghiên cứu một trường hợp cực đoan của sinh dataset thông qua PLMs cho học zero-shot. Mà không cần bất kỳ chú thích con người nào, chúng tôi cho thấy rằng một LSTM nhỏ có thể vượt qua hiệu suất zero-shot của các đối tác PLM của nó (ví dụ: GPT2-XL), và thậm chí vượt trội hơn cùng mô hình được huấn luyện với chú thích con người. Mặc dù có kết quả tích cực, chúng tôi thảo luận về một số vấn đề chúng tôi quan sát thấy khi phát triển ZEROGEN và tiết lộ một không gian cải thiện đáng kể trong nghiên cứu tương lai.

Mặc dù có kết quả tích cực trên các tác vụ TC, chúng tôi thấy tính ổn định về lựa chọn prompt của ZEROGEN vẫn còn xa so với mức thỏa mãn trên các tác vụ NLI. Công việc tương lai có thể bao gồm các phương pháp huấn luyện trước đa tác vụ dựa trên prompt (Sanh et al., 2021; Wei et al., 2021).

Hơn nữa, chúng tôi quan sát thấy các ví dụ nhiễu trong dataset tổng hợp trên các tác vụ khó như NLI và QA, tình huống này dần xấu đi khi kết hợp chiến lược giải mã đa dạng hơn (ví dụ: Lấy mẫu Nucleus). Cần có các chiến lược giải mã tốt hơn để đảm bảo tính đúng đắn của nhãn trong khi bảo tồn sự đa dạng dataset (Massarelli et al., 2020). Bên cạnh đó, các phương pháp học từ nhãn nhiễu có thể được tích hợp vào việc huấn luyện mô hình tác vụ nhỏ (Song et al., 2020).

Chúng tôi hy vọng bài báo này có thể cung cấp những đóng góp để khai thác thêm học zero-shot dựa trên sinh dataset với các mô hình ngôn ngữ được tiền huấn luyện lớn.

Hạn chế
Mặc dù ZEROGEN đạt được hiệu suất đầy hứa hẹn dưới thiết lập học zero-shot, lựa chọn này đi kèm với một số hạn chế nhất định. Chúng tôi thấy tính ổn định về lựa chọn prompt của ZEROGEN vẫn còn xa so với mức thỏa mãn. ZEROGEN kém hiệu quả hơn PROMPTING trong một số prompt được chọn nhất định, và kỹ thuật prompt khó khăn vì nó cho thấy sự ưa thích khác nhau đối với prompt trên các tác vụ khác nhau. Công việc tương lai có thể bao gồm các phương pháp huấn luyện trước đa tác vụ dựa trên prompt (Sanh et al., 2021; Wei et al., 2021) để cải thiện sự mạnh mẽ của prompt.

Chúng tôi cũng quan sát thấy các ví dụ nhiễu trong dataset tổng hợp trên các tác vụ khó như NLI và QA, tình huống này dần xấu đi khi kết hợp chiến lược giải mã đa dạng hơn (ví dụ: Lấy mẫu Nucleus). Cần có các chiến lược giải mã tốt hơn để đảm bảo tính đúng đắn của nhãn trong khi bảo tồn sự đa dạng dataset (Massarelli et al., 2020). Ngược lại, các phương pháp học từ nhãn nhiễu có thể được tích hợp vào việc huấn luyện mô hình tác vụ nhỏ (Song et al., 2020).

Lời cảm ơn
Chúng tôi cảm ơn các nhà đánh giá ẩn danh có những đề xuất đã giúp làm rõ công việc này. Công việc này được hỗ trợ một phần bởi Ủy ban Khoa học và Công nghệ Thượng Hải (Số hiệu 21DZ1100100), và chương trình nghiên cứu chung của Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (NSFC) và Hội đồng Tài trợ Nghiên cứu (RGC) dưới số hiệu N_HKU714/21.

Tài liệu tham khảo
Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor, George Kour, Segev Shlomov, Naama Tepper, và Naama Zwerdling. 2020. Do not have enough data? deep learning to the rescue!

--- TRANG 8 ---
Trong The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, trang 7383–7390. AAAI Press.

Max Bartolo, Alastair Roberts, Johannes Welbl, Sebastian Riedel, và Pontus Stenetorp. 2020. Beat the AI: investigating adversarial human annotation for reading comprehension. Trans. Assoc. Comput. Linguistics, 8:662–678.

Luisa Bentivogli, Bernardo Magnini, Ido Dagan, Hoa Trang Dang, và Danilo Giampiccolo. 2009. The fifth PASCAL recognizing textual entailment challenge. Trong Proceedings of the Second Text Analysis Conference, TAC 2009, Gaithersburg, Maryland, USA, November 16-17, 2009. NIST.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language models are few-shot learners. Trong Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.

Ido Dagan, Oren Glickman, và Bernardo Magnini. 2005. The PASCAL recognising textual entailment challenge. Trong Machine Learning Challenges, Evaluating Predictive Uncertainty, Visual Object Classification and Recognizing Textual Entailment, First PASCAL Machine Learning Challenges Workshop, MLCW 2005, Southampton, UK, April 11-13, 2005, Revised Selected Papers, volume 3944 of Lecture Notes in Computer Science, trang 177–190. Springer.

Angela Fan, Mike Lewis, và Yann N. Dauphin. 2018. Hierarchical neural story generation. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers, trang 889–898. Association for Computational Linguistics.

William Fedus, Barret Zoph, và Noam Shazeer. 2021. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. CoRR, abs/2101.03961.

Marjan Ghazvininejad, Omer Levy, Yinhan Liu, và Luke Zettlemoyer. 2019. Mask-predict: Parallel decoding of conditional masked language models. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, trang 6111–6120. Association for Computational Linguistics.

Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, và Bill Dolan. 2007. The third PASCAL recognizing textual entailment challenge. Trong Proceedings of the ACL-PASCAL@ACL 2007 Workshop on Textual Entailment and Paraphrasing, Prague, Czech Republic, June 28-29, 2007, trang 1–9. Association for Computational Linguistics.

Yoav Goldberg. 2019. Assessing bert's syntactic abilities. CoRR, abs/1901.05287.

Mitchell A. Gordon, Kevin Duh, và Nicholas Andrews. 2020. Compressing BERT: studying the effects of weight pruning on transfer learning. Trong Proceedings of the 5th Workshop on Representation Learning for NLP, RepL4NLP@ACL 2020, Online, July 9, 2020, trang 143–155. Association for Computational Linguistics.

Yves Grandvalet và Yoshua Bengio. 2006. Entropy regularization.

Jiatao Gu, James Bradbury, Caiming Xiong, Victor OK Li, và Richard Socher. 2018. Non-autoregressive neural machine translation. Trong International Conference on Learning Representations.

Jian Guan và Minlie Huang. 2020. UNION: an unreferenced metric for evaluating open-ended story generation. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, trang 9157–9166. Association for Computational Linguistics.

R Bar Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, và Idan Szpektor. 2006. The second pascal recognising textual entailment challenge. Trong Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment.

Xuanli He, Islam Nassar, Jamie Kiros, Gholamreza Haffari, và Mohammad Norouzi. 2021. Generate, annotate, and learn: Generative models advance self-training and knowledge distillation. CoRR, abs/2106.06168.

Geoffrey E. Hinton, Oriol Vinyals, và Jeffrey Dean. 2015. Distilling the knowledge in a neural network. CoRR, abs/1503.02531.

Sepp Hochreiter và Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):1735–1780.

Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. 2020. The curious case of neural text degeneration. Trong 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.

--- TRANG 9 ---
Ari Holtzman, Peter West, Vered Shwartz, Yejin Choi, và Luke Zettlemoyer. 2021. Surface form competition: Why the highest probability answer isn't always right. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, trang 7038–7051. Association for Computational Linguistics.

Paras Jain, Xiangxi Mo, Ajay Jain, Alexey Tumanov, Joseph E. Gonzalez, và Ion Stoica. 2019. The ooo VLIW JIT compiler for GPU inference. CoRR, abs/1901.10008.

Ganesh Jawahar, Benoît Sagot, và Djamé Seddah. 2019. What does BERT learn about the structure of language? Trong Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers, trang 3651–3657. Association for Computational Linguistics.

Zhengbao Jiang, Jun Araki, Haibo Ding, và Graham Neubig. 2020a. How can we know when language models know? CoRR, abs/2012.00955.

Zhengbao Jiang, Frank F. Xu, Jun Araki, và Graham Neubig. 2020b. How can we know what language models know. Trans. Assoc. Comput. Linguistics, 8:423–438.

Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin Li, Fang Wang, và Qun Liu. 2020. Tinybert: Distilling BERT for natural language understanding. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, volume EMNLP 2020 của Findings of ACL, trang 4163–4174. Association for Computational Linguistics.

Nitish Shirish Keskar, Bryan McCann, Lav Varshney, Caiming Xiong, và Richard Socher. 2019. CTRL - A Conditional Transformer Language Model for Controllable Generation. arXiv preprint arXiv:1909.05858.

Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, và Hannaneh Hajishirzi. 2020. Unifiedqa: Crossing format boundaries with a single QA system. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, volume EMNLP 2020 của Findings of ACL, trang 1896–1907. Association for Computational Linguistics.

Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W Mahoney, và Kurt Keutzer. 2021. I-bert: Integer-only bert quantization. arXiv preprint arXiv:2101.01321.

Diederik P. Kingma và Jimmy Ba. 2015. Adam: A method for stochastic optimization. Trong 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.

Varun Kumar, Ashutosh Choudhary, và Eunah Cho. 2020. Data augmentation using pre-trained transformer models. CoRR, abs/2003.02245.

Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, và Radu Soricut. 2020. ALBERT: A lite BERT for self-supervised learning of language representations. Trong 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.

Dong-Hyun Lee et al. 2013. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. Trong Workshop on challenges in representation learning, ICML, volume 3, trang 896.

Kenton Lee, Kelvin Guu, Luheng He, Tim Dozat, và Hyung Won Chung. 2021. Neural data augmentation via example extrapolation. CoRR, abs/2102.01335.

Jiwei Li, Will Monroe, và Dan Jurafsky. 2016. A simple, fast diverse decoding algorithm for neural generation. CoRR, abs/1611.08562.

Alisa Liu, Swabha Swayamdipta, Noah A. Smith, và Yejin Choi. 2022. WANLI: worker and AI collaboration for natural language inference dataset creation. CoRR, abs/2201.05955.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692.

Yuang Liu, Wei Zhang, Jun Wang, và Jianyong Wang. 2021. Data-free knowledge transfer: A survey. CoRR, abs/2112.15278.

Xindian Ma, Peng Zhang, Shuai Zhang, Nan Duan, Yuexian Hou, Ming Zhou, và Dawei Song. 2019. A tensorized transformer for language modeling. Trong Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, trang 2229–2239.

Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, và Christopher Potts. 2011. Learning word vectors for sentiment analysis. Trong The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference, 19-24 June, 2011, Portland, Oregon, USA, trang 142–150. The Association for Computer Linguistics.

Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktäschel, Vassilis Plachouras, Fabrizio Silvestri, và Sebastian Riedel. 2020.

--- TRANG 10 ---
How decoding strategies affect the verifiability of generated text. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, volume EMNLP 2020 của Findings of ACL, trang 223–235. Association for Computational Linguistics.

Yu Meng, Jiaxin Huang, Yu Zhang, và Jiawei Han. 2022. Generating training data with language models: Towards zero-shot language understanding. CoRR, abs/2202.04538.

Swaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin Choi, và Hannaneh Hajishirzi. 2021a. Reframing instructional prompts to gptk's language. arXiv preprint arXiv:2109.07830.

Swaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin Choi, và Hannaneh Hajishirzi. 2021b. Reframing instructional prompts to gptk's language. CoRR, abs/2109.07830.

Swaroop Mishra, Daniel Khashabi, Chitta Baral, và Hannaneh Hajishirzi. 2021c. Natural instructions: Benchmarking generalization to new tasks from natural language instructions. CoRR, abs/2104.08773.

Matan Ben Noach và Yoav Goldberg. 2020. Compressing pre-trained language models by matrix decomposition. Trong Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, AACL/IJCNLP 2020, Suzhou, China, December 4-7, 2020, trang 884–889. Association for Computational Linguistics.

Jeffrey Pennington, Richard Socher, và Christopher D. Manning. 2014. Glove: Global vectors for word representation. Trong Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, trang 1532–1543. ACL.

Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick S. H. Lewis, Anton Bakhtin, Yuxiang Wu, và Alexander H. Miller. 2019. Language models as knowledge bases? Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, trang 2463–2473. Association for Computational Linguistics.

Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, và Zaid Harchaoui. 2021. Mauve: Measuring the gap between neural text and human text using divergence frontiers. Advances in Neural Information Processing Systems, 34.

Raul Puri, Ryan Spring, Mohammad Shoeybi, Mostofa Patwary, và Bryan Catanzaro. 2020. Training question answering models from synthetic data. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, trang 5811–5826. Association for Computational Linguistics.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. 2019. Language models are unsupervised multitask learners.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. 2016. Squad: 100, 000+ questions for machine comprehension of text. Trong Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016, trang 2383–2392. The Association for Computational Linguistics.

Ahmad Rashid, Vasileios Lioutas, Abbas Ghaddar, và Mehdi Rezagholizadeh. 2021. Towards zero-shot knowledge distillation for natural language processing. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, trang 6551–6561. Association for Computational Linguistics.

Laria Reynolds và Kyle McDonell. 2021. Prompt programming for large language models: Beyond the few-shot paradigm. Trong CHI '21: CHI Conference on Human Factors in Computing Systems, Virtual Event / Yokohama Japan, May 8-13, 2021, Extended Abstracts, trang 314:1–314:7. ACM.

Victor Sanh, Lysandre Debut, Julien Chaumond, và Thomas Wolf. 2019. Distilbert, a distilled version of BERT: smaller, faster, cheaper and lighter. CoRR, abs/1910.01108.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M. Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal V. Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Févry, Jason Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, và Alexander M. Rush. 2021. Multitask prompted training enables zero-shot task generalization. CoRR, abs/2110.08207.

Timo Schick và Hinrich Schütze. 2021. Generating datasets with pretrained language models. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, trang 6943–6951. Association for Computational Linguistics.

Timo Schick, Sahana Udupa, và Hinrich Schütze. 2021. Self-diagnosis and self-debiasing: A proposal

--- TRANG 11 ---
for reducing corpus-based bias in NLP. CoRR, abs/2103.00453.

Min Joon Seo, Aniruddha Kembhavi, Ali Farhadi, và Hannaneh Hajishirzi. 2017. Bidirectional attention flow for machine comprehension. Trong 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net.

Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W. Mahoney, và Kurt Keutzer. 2020. Q-BERT: hessian based ultra low precision quantization of BERT. Trong The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, trang 8815–8821. AAAI Press.

Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, và Sameer Singh. 2020. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, trang 4222–4235. Association for Computational Linguistics.

Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, và Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. Trong Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, trang 1631–1642. ACL.

Hwanjun Song, Minseok Kim, Dongmin Park, và Jae-Gil Lee. 2020. Learning from noisy labels with deep neural networks: A survey. CoRR, abs/2007.08199.

Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, và Denny Zhou. 2020. Mobilebert: a compact task-agnostic BERT for resource-limited devices. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, trang 2158–2170. Association for Computational Linguistics.

Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, và Ellie Pavlick. 2019. What do you learn from context? probing for sentence structure in contextualized word representations. Trong 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.

Ashwin K. Vijayakumar, Michael Cogswell, Ramprasaath R. Selvaraju, Qing Sun, Stefan Lee, David J. Crandall, và Dhruv Batra. 2016. Diverse beam search: Decoding diverse solutions from neural sequence models. CoRR, abs/1610.02424.

Tu Vu, Minh-Thang Luong, Quoc V. Le, Grady Simon, và Mohit Iyyer. 2021. Strata: Self-training with task augmentation for better few-shot learning. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, trang 5715–5731. Association for Computational Linguistics.

Ziheng Wang, Jeremy Wohlwend, và Tao Lei. 2020. Structured pruning of large language models. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, trang 6151–6162. Association for Computational Linguistics.

Zirui Wang, Adams Wei Yu, Orhan Firat, và Yuan Cao. 2021. Towards zero-label language learning. CoRR, abs/2109.09193.

Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, và Quoc V. Le. 2021. Finetuned language models are zero-shot learners. CoRR, abs/2109.01652.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903.

Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, và Jason Weston. 2020. Neural text generation with unlikelihood training. Trong 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, và Jamie Brew. 2019. Huggingface's transformers: State-of-the-art natural language processing. CoRR, abs/1910.03771.

Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Yanggang Wang, Haiyu Li, và Zhilin Yang. 2022. Zeroprompt: Scaling prompt-based pretraining to 1, 000 tasks improves zero-shot generalization. CoRR, abs/2201.06910.

Jingjing Xu, Wangchunshu Zhou, Zhiyi Fu, Hao Zhou, và Lei Li. 2021. A survey on green deep learning. CoRR, abs/2111.05193.

Jiacheng Ye, Tao Gui, Yichao Luo, Yige Xu, và Qi Zhang. 2021. One2set: Generating diverse keyphrases as a set. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers),

--- TRANG 12 ---
Virtual Event, August 1-6, 2021, trang 4598–4608. Association for Computational Linguistics.

Ofir Zafrir, Guy Boudoukh, Peter Izsak, và Moshe Wasserblat. 2019. Q8BERT: quantized 8bit BERT. Trong Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition, EMC2@NeurIPS 2019, Vancouver, Canada, December 13, 2019, trang 36–39. IEEE.

Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, và cộng sự. 2022. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068.

Ruiqi Zhong, Kristy Lee, Zheng Zhang, và Dan Klein. 2021. Adapting language models for zero-shot learning by meta-tuning on dataset and prompt collections. Trong Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021, trang 2856–2878. Association for Computational Linguistics.

Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, và Yong Yu. 2018. Texygen: A benchmarking platform for text generation models. Trong The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, SIGIR 2018, Ann Arbor, MI, USA, July 08-12, 2018, trang 1097–1100. ACM.

A Thiết lập Thí nghiệm

Chi tiết Triển khai Để sinh dataset, chúng tôi sử dụng Lấy mẫu Nucleus (Holtzman et al., 2020) với p = 0.9 theo mặc định vì nó được coi là có thể sinh ra văn bản vừa trôi chảy vừa đa dạng (Holtzman et al., 2020). Quy mô của dataset tổng hợp là 200k trong các kết quả chính, và 100k trong các thí nghiệm phân tích khác. Về lựa chọn prompt, chúng tôi thiết kế thủ công một loạt prompt cho mỗi tác vụ, và báo cáo kết quả trên prompt tốt nhất cho khung PROMPTING và ZEROGEN. Đối với các tác vụ NLI, chúng tôi áp dụng cơ chế tự khử thiên hướng với hằng số phân rã 200 (Schick et al., 2021) để đảm bảo rằng mỗi cặp văn bản được sinh ra không chỉ phù hợp tốt với một nhãn đã cho, mà còn không phù hợp tốt với các nhãn khác (Schick và Schütze, 2021). Chúng tôi loại bỏ các câu quá ngắn/dài, và các câu không có dấu ngoặc kép kết thúc.

Chúng tôi triển khai một mô hình dựa trên LSTM và một mô hình DistilBERT làm TAM. Đối với mô hình dựa trên LSTM, chúng tôi sử dụng bộ tối ưu Adam (Kingma và Ba, 2015), tỷ lệ học 1e-4, chiều embedding 100, và kích thước ẩn 300. Đối với phân loại câu đơn (TC), chúng tôi sử dụng BiLSTM 1 lớp để mã hóa câu và sử dụng một bộ phân loại tuyến tính. Đối với phân loại cặp câu (NLI), chúng tôi sử dụng BiLSTM 2 lớp để mã hóa các câu thành v1; v2 và truyền phần nối [v1;v2;|v1-v2|;v1⊙v2] vào một bộ phân loại. Đối với các tác vụ QA, chúng tôi sử dụng mô hình BiDAF 1 lớp. Để đảm bảo rằng TAMs thực sự được huấn luyện từ đầu sử dụng corpus tổng hợp, chúng tôi khởi tạo ngẫu nhiên embedding của TAMs mà không sử dụng bất kỳ word embedding được tiền huấn luyện nào (ví dụ: GloVe (Pennington et al., 2014). Đối với DistilBERT, chúng tôi tinh chỉnh trên mỗi dataset với bộ tối ưu Adam, với tỷ lệ học 2e-5, weight decay 0.01, và các siêu tham số mặc định khác như được đề xuất bởi thư viện HuggingFace Transformers (Wolf et al., 2019). Chúng tôi chạy thí nghiệm trên một GPU NVIDIA A100 80G duy nhất, và việc sinh 200k ví dụ mất 12 giờ trung bình.

B Kết quả Bổ sung về Thiết kế Prompt

Đối với các tác vụ Hỏi Đáp, prompt theo phong cách ngôn ngữ tự nhiên cũng phù hợp nhất cho cả thiết lập PROMPTING và ZEROGEN, đạt điểm cao nhất. Tuy nhiên, đối với các tác vụ Suy luận Ngôn ngữ Tự nhiên, các prompt phù hợp nhất cho QNLI và RTE là khác nhau. Đối với RTE, prompt theo phong cách ngôn ngữ tự nhiên là tốt nhất, trong khi các prompt control code hoạt động tốt hơn đáng kể so với các prompt theo phong cách ngôn ngữ tự nhiên trong QNLI.

C Các Công trình Liên quan Bổ sung về Suy luận Hiệu quả của PLMs

Có một dòng công trình dành riêng cho việc cải thiện hiệu quả suy luận của PLMs, bao gồm pruning (Wang et al., 2020; Gordon et al., 2020), phân tích nhân tử thứ hạng thấp (Ma et al., 2019; Noach và Goldberg, 2020; Lan et al., 2020), quantization (Zafrir et al., 2019; Shen et al., 2020; Kim et al., 2021), chưng cất kiến thức (Jiao et al., 2020; Sanh et al., 2019; Sun et al., 2020) và giải mã song song (Gu et al., 2018; Ghazvininejad et al., 2019; Ye et al., 2021). Chúng tôi đề cập độc giả đến Xu et al. (2021) để có một khảo sát chi tiết. Liên quan đến quyền riêng tư, bản quyền hoặc bảo mật, chưng cất kiến thức không có dữ liệu (DFKD) (Liu et al., 2021) đã thu hút sự chú ý hấp dẫn trong lĩnh vực thị giác máy tính vì nó xử lý việc chưng cất kiến thức có giá trị từ các mô hình được huấn luyện tốt mà không cần truy cập vào dữ liệu huấn luyện. Tuy nhiên, các cách tiếp cận tương tự cho NLP khó hoạt động do tính chất rời rạc của từ. Rashid et al. (2021) nới lỏng điều kiện không có dữ liệu và sử dụng dữ liệu có nhãn ngoài phân phối để huấn luyện một generator. Ngược lại, phương pháp của chúng tôi sinh dữ liệu với PLMs (tức là giáo viên), mà không yêu cầu bất kỳ dữ liệu có nhãn được định nghĩa trước nào. Trong văn học về chưng cất kiến thức, khung ZEROGEN có thể tạo ra một mô hình học sinh đạt được hiệu suất zero-shot vượt trội so với mô hình giáo viên.

D ZEROGEN như Chưng cất Kiến thức

ZEROGEN có thể được xem như một khung chưng cất kiến thức dựa trên dataset. Chúng tôi so sánh các baseline chưng cất kiến thức vanilla với ZEROGEN trong Bảng 7. Các nhãn mềm và cứng được sinh ra bởi GPT2-XL trên tập huấn luyện không nhãn. Các nhãn được sinh ra được sử dụng để huấn luyện một mô hình tác vụ nhỏ để so sánh. Kết quả vượt trội trên ZEROGEN cho thấy rằng mô hình này có thể sử dụng PLM lớn tốt hơn bằng cách chưng cất nhiều kiến thức hơn vào một lượng lớn các cặp đầu vào-đầu ra, trong khi chưng cất kiến thức vanilla chỉ chưng cất kiến thức vào các đầu ra.

[Bảng 7: So sánh với các baseline chưng cất kiến thức (KD) trên IMDb. KD-HARD và KD-SOFT đại diện cho các baseline KD sử dụng nhãn cứng và nhãn mềm, tương ứng.]

E ZEROGEN cho Tăng cường Dữ liệu

Chúng tôi báo cáo kết quả sử dụng dữ liệu tổng hợp làm dữ liệu tăng cường trong Bảng 8. Kết quả cho thấy rằng dữ liệu tổng hợp zero-shot là một bổ sung tốt cho dữ liệu được chú thích con người (dữ liệu vàng) và có thể cải thiện hiệu suất mô hình.

[Bảng 8: Kết quả tăng cường dữ liệu trên IMDb sử dụng dữ liệu tổng hợp. AUG-200k và AUG-500k đại diện cho việc sử dụng 200k và 500k dữ liệu tổng hợp tương ứng.]

F ZEROGEN cho Tự cải thiện

Chúng tôi đã cho thấy rằng một mô hình tác vụ nhỏ có thể vượt trội hơn một PLM lớn sau khi huấn luyện trên dataset tổng hợp. Một câu hỏi tự nhiên là "PLM có thể cải thiện hiệu suất của chính nó sau khi tinh chỉnh trên dataset được sinh ra bởi chính nó không?". Chúng tôi thử nghiệm sử dụng PLM làm TAM và báo cáo kết quả trong Bảng 9. Tóm lại, chúng tôi thấy 1) Một TAM lớn hơn có thể tăng cường thêm hiệu suất; 2) PLMs có thể cải thiện bản thân bằng cách tinh chỉnh trên dataset được sinh ra bởi chính nó.

[Bảng 9: Kết quả của PLM (tức là GPT2-XL) được tinh chỉnh với dataset vàng (trên) và tổng hợp (dưới). Một TAM lớn hơn tăng cường thêm hiệu suất, và PLM có thể cải thiện hiệu suất của chính nó sau khi tinh chỉnh trên dataset tổng hợp bởi chính nó (các khối xám).]

G Ví dụ Được Sinh ra

Chúng tôi trình bày một số ví dụ định tính cho các tác vụ khác nhau trong Bảng 11 của Phụ lục. Tác vụ phân loại văn bản (SST-2) tương đối đơn giản và súc tích, các mẫu được sinh ra thường phù hợp với prompt và cực tính cảm xúc tốt bằng cách sử dụng các token mô tả về tên phim đã cho và cảm xúc tích cực/tiêu cực. Lấy trường hợp đầu tiên trong SST-2 làm ví dụ, các token được sinh ra "action-adventure" và "attractive" là những tiếp tục tự nhiên cho tên phim "The Spiderwick Chronicles (Movie)" và cảm xúc "positive" trong prompt. Mặc dù các tác vụ suy luận ngôn ngữ tự nhiên phức tạp, các câu hỏi được sinh ra (QNLI) và suy luận (RTE) có thể phản hồi với các loại prompt khác nhau và liên quan đến các ngữ cảnh đã cho (ví dụ: câu hỏi được sinh ra chuyển chủ đề cho prompt "Information:... Question (answer not in above information)" trong QNLI). Trong khi ngữ cảnh của tác vụ hỏi đáp (SQuAD) dài và chứa nhiều thông tin, ZEROGEN có thể thành công sinh ra câu hỏi "Who is the one and only true God?" được sử dụng để phản hồi với câu trả lời được đặt trước "Jehovah". Nhìn chung, những ví dụ sinh tạo này cho thấy rằng ZEROGEN có thể sinh ra các mẫu huấn luyện hữu ích và số lượng tùy ý có thể được sử dụng để huấn luyện TAMs.

--- TRANG 13 ---
[Bảng 10: Kết quả cho các prompt khác nhau trên các tác vụ Hỏi Đáp và Suy luận Ngôn ngữ Tự nhiên. Kết quả được báo cáo trên tập dev. Đối với Hỏi Đáp, "<C>" đại diện cho ngữ cảnh đầu vào, "<X>" đại diện cho câu hỏi đầu vào, "<Y>" đại diện cho câu trả lời được sinh ra. "\n" đại diện cho ký hiệu xuống dòng. P0 đại diện cho phiên bản được điều chỉnh nhỏ của P cho sinh văn bản.]

--- TRANG 14 ---
[Bảng 11: Các ví dụ được sinh ra cho mỗi tác vụ. Chúng tôi bỏ qua ví dụ cho các tác vụ IMDb và Adversarial QA vì chúng tôi sử dụng chính xác cùng prompt như các tác vụ SST-2 và SQuAD, tương ứng. Các điều kiện đầu vào trong mỗi prompt được in đậm.]

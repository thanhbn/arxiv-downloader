# 2310.00704.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2310.00704.pdf
# Kích thước tệp: 1262790 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Đang được đánh giá như một bài báo hội nghị tại ICLR 2024
UNIAUDIO: MỘT MÔ HÌNH NỀN TẢNG ÂM THANH HƯỚNG TỚI
VIỆC SINH ÂM THANH TOÀN DIỆN
Dongchao Yang1∗, Jinchuan Tian2∗, Xu Tan3†, Rongjie Huang4, Songxiang Liu, Xuankai Chang2,
Jiatong Shi2, Sheng Zhao3, Jiang Bian3, Zhou Zhao4, Xixin Wu1, Helen Meng1†
1Đại học Trung văn Hồng Kông, 2Đại học Carnegie Mellon,
3Microsoft Research Asia, 4Đại học Chiết Giang
dcyang@se.cuhk.edu.hk, jinchuat@andrew.cmu.edu
TÓM TẮT
Các mô hình Ngôn ngữ Lớn (LLM) đã chứng minh khả năng xử lý nhiều tác vụ sinh khác nhau. Bài báo này giới thiệu hệ thống UniAudio, không giống như các phương pháp chuyên biệt cho từng tác vụ trước đây, tận dụng kỹ thuật LLM để sinh ra nhiều loại âm thanh (bao gồm lời nói, âm thanh, âm nhạc và ca hát) với các điều kiện đầu vào cho trước. UniAudio 1) đầu tiên token hóa tất cả các loại âm thanh đích cùng với các phương thức điều kiện khác, 2) nối cặp nguồn-đích thành một chuỗi đơn, và 3) thực hiện dự đoán token tiếp theo sử dụng LLM. Ngoài ra, một mô hình Transformer đa tỷ lệ được đề xuất để xử lý các chuỗi quá dài gây ra bởi codec neural dựa trên lượng tử hóa vector dư trong quá trình token hóa. Việc đào tạo UniAudio được mở rộng lên 165K giờ âm thanh và 1B tham số, dựa trên tất cả các tác vụ sinh, nhằm thu được đủ kiến thức tiên nghiệm không chỉ về các đặc tính nội tại của âm thanh mà còn về mối quan hệ giữa âm thanh và các phương thức khác. Do đó, mô hình UniAudio đã được đào tạo có tiềm năng trở thành một mô hình nền tảng cho việc sinh âm thanh toàn diện: nó cho thấy khả năng mạnh mẽ trong tất cả các tác vụ được đào tạo và có thể hỗ trợ liền mạch các tác vụ sinh âm thanh mới sau khi tinh chỉnh đơn giản. Các thí nghiệm chứng minh rằng UniAudio đạt được kết quả tốt nhất hoặc ít nhất là cạnh tranh trên hầu hết 11 tác vụ sinh âm thanh. Demo và mã nguồn được công bố.

1 GIỚI THIỆU
Sinh âm thanh là một thành phần quan trọng của AI sinh. Gần đây, sự phổ biến của AI sinh đã tạo ra nhu cầu ngày càng tăng và đa dạng trong việc sinh âm thanh: âm thanh được mong đợi sẽ được sinh ra dựa trên yêu cầu của con người, như tổng hợp lời nói (TTS), chuyển đổi giọng nói (VC), tổng hợp giọng ca hát (SVS), chuyển văn bản thành âm thanh và chuyển văn bản thành âm nhạc. Các nghiên cứu trước đây về các tác vụ sinh âm thanh thường mang tính chuyên biệt: thiết kế của chúng tận dụng mạnh mẽ kiến thức lĩnh vực và việc sử dụng của chúng bị giới hạn trong các thiết lập cố định (Tan et al., 2021; Luo & Mesgarani, 2019; Zmolikova et al., 2023; Huang et al., 2021b; Cho et al., 2021). Thay vì xử lý từng tác vụ một cách độc lập, công trình này là một nỗ lực nhằm đạt được việc sinh âm thanh toàn diện, nhằm hoàn thành nhiều tác vụ sinh âm thanh chỉ với một mô hình thống nhất. Mô hình sinh âm thanh toàn diện được mong đợi sẽ thu được đủ kiến thức tiên nghiệm về âm thanh và các phương thức liên quan, có tiềm năng cung cấp các giải pháp đơn giản và hiệu quả cho nhu cầu ngày càng tăng của việc sinh ra các loại âm thanh đa dạng.

Sự vượt trội của các Mô hình Ngôn ngữ Lớn (LLM) trong các tác vụ sinh văn bản đã truyền cảm hứng cho một loạt các mô hình dựa trên LLM trong việc sinh âm thanh (Wang et al., 2023a; Kharitonov et al., 2023; Huang et al., 2023b; Agostinelli et al., 2023; Borsos et al., 2023). Trong số các nghiên cứu này, khả năng của LLM trong các tác vụ độc lập đã được nghiên cứu rộng rãi trong các tác vụ như chuyển văn bản thành lời nói (TTS) (Wang et al., 2023a; Kharitonov et al., 2023; Huang et al., 2023b) và sinh âm nhạc (Agostinelli et al., 2023; Copet et al., 2023), và đạt được hiệu suất cạnh tranh. Tuy nhiên, khả năng của LLM trong việc xử lý nhiều tác vụ với một mô hình thống nhất ít được khai thác trong nghiên cứu sinh âm thanh: hầu hết các nghiên cứu dựa trên LLM hiện tại vẫn được thiết kế cho các tác vụ đơn lẻ (Wang et al., 2023a; Kharitonov et al., 2023). Chúng tôi cho rằng việc đạt được tính toàn diện và linh hoạt trong sinh âm thanh thông qua mô hình LLM là đầy hứa hẹn nhưng chưa được nghiên cứu toàn diện trước công trình này.

--- TRANG 2 ---
Đang được đánh giá như một bài báo hội nghị tại ICLR 2024
Hướng tới việc sinh âm thanh toàn diện, công trình này giới thiệu UniAudio, sử dụng kỹ thuật LLM và có khả năng sinh ra nhiều loại âm thanh (lời nói, âm thanh, âm nhạc và ca hát) dựa trên các phương thức đầu vào khác nhau, như chuỗi âm vị, mô tả văn bản và chính âm thanh. UniAudio được đề xuất có các đặc điểm chính như sau: Đầu tiên, tất cả các loại âm thanh, cùng với tất cả các phương thức đầu vào khác, được token hóa thành các chuỗi rời rạc. Cụ thể, một mô hình codec neural toàn diện được xây dựng để token hóa âm thanh một cách hiệu quả bất kể loại âm thanh, và các tokenizer khác được sử dụng để token hóa các phương thức khác nhau. Sau đó, UniAudio nối cặp nguồn-đích thành một chuỗi đơn. Cuối cùng, UniAudio thực hiện dự đoán token tiếp theo sử dụng LLM. Lượng tử hóa vector dư (Zeghidour et al., 2021) dựa trên codec neural được sử dụng trong quá trình token hóa, dẫn đến các chuỗi token quá dài (một khung tương ứng với nhiều token) không thể được xử lý hiệu quả bởi LLM. Một kiến trúc Transformer đa tỷ lệ được thiết kế để giảm độ phức tạp tính toán bằng cách mô hình hóa tương quan giữa khung và trong khung một cách riêng biệt. Cụ thể, một mô-đun Transformer toàn cục được sử dụng để mô hình hóa tương quan giữa khung (ví dụ mức ngữ nghĩa), và một mô-đun Transformer cục bộ được sử dụng để mô hình hóa tương quan trong khung (ví dụ mức âm học).

Để chứng minh khả năng mở rộng của UniAudio cho các tác vụ mới, quá trình xây dựng UniAudio gồm hai giai đoạn. Đầu tiên, UniAudio được đề xuất được đào tạo trên nhiều tác vụ sinh âm thanh cùng lúc, cho phép mô hình thu được đủ kiến thức tiên nghiệm không chỉ về các đặc tính nội tại của âm thanh mà còn về mối quan hệ giữa âm thanh và các phương thức đầu vào khác. Thứ hai, thông qua tinh chỉnh, mô hình đã được đào tạo có thể hỗ trợ liền mạch nhiều tác vụ sinh âm thanh chưa được thấy. Do đó, UniAudio có tiềm năng trở thành một mô hình nền tảng cho việc sinh âm thanh toàn diện: nó có thể liên tục hỗ trợ các nhu cầu mới nổi trong sinh âm thanh. Về mặt thực nghiệm, UniAudio của chúng tôi hỗ trợ 11 tác vụ sinh âm thanh: giai đoạn đào tạo bao gồm 7 tác vụ sinh âm thanh, trong khi 4 tác vụ được thêm vào trong giai đoạn tinh chỉnh. Quá trình xây dựng UniAudio được mở rộng lên 165k giờ âm thanh và 1B tham số. Trong số 11 tác vụ, UniAudio liên tục đạt được hiệu suất cạnh tranh trong cả đánh giá khách quan và chủ quan. Kết quả tốt nhất thậm chí được đạt được trên hầu hết các tác vụ này. Nghiên cứu sâu hơn cho thấy việc đào tạo nhiều tác vụ đồng thời trong giai đoạn đào tạo có lợi ích lẫn nhau cho mỗi tác vụ liên quan. Ngoài ra, UniAudio có thể thích ứng hiệu quả với các tác vụ sinh âm thanh mới và vượt trội hơn các mô hình chuyên biệt cho từng tác vụ với một khoảng cách không nhỏ.

Tóm lại, công trình này cho thấy việc xây dựng các mô hình sinh âm thanh toàn diện là cần thiết, đầy hứa hẹn và có lợi ích. Những đóng góp chính của công trình này được tóm tắt như sau:
(1) Hướng tới việc sinh âm thanh toàn diện, UniAudio được trình bày như một giải pháp thống nhất cho 11 tác vụ sinh âm thanh.
(2) Về phương pháp, UniAudio cung cấp các cách tiếp cận mới cho (i) biểu diễn tuần tự của âm thanh và các phương thức đầu vào khác; (ii) công thức thống nhất cho các tác vụ sinh âm thanh dựa trên LLM; và (iii) kiến trúc mô hình hiệu quả được thiết kế đặc biệt cho việc sinh âm thanh.
(3) Về thí nghiệm, hiệu suất tổng thể của UniAudio được xác nhận tốt, và lợi ích của việc xây dựng một mô hình sinh âm thanh linh hoạt được xác minh bởi các kết quả thí nghiệm chi tiết.
(4) Demo và mã nguồn được công bố, với hy vọng UniAudio có thể trở thành một mô hình nền tảng hỗ trợ việc sinh âm thanh mới nổi trong nghiên cứu tương lai.

2 UNIAUDIO
Phần này giới thiệu các chi tiết kỹ thuật của UniAudio được đề xuất. Phần 2.1 giải thích cách âm thanh và các phương thức khác được token hóa. Sau đó, tất cả các tác vụ sinh âm thanh được xem xét được công thức hóa thống nhất trong Phần 2.2. Tiếp theo, kiến trúc Transformer đa tỷ lệ được đề xuất trong Phần 2.3 để xử lý thử thách chuỗi quá dài gây ra bởi việc áp dụng codec neural.

2.1 TOKEN HÓA
LLM thường được sử dụng cho việc mô hình hóa tuần tự, vì vậy âm thanh và tất cả các phương thức đầu vào khác được token hóa trước khi được xử lý. Các quá trình này cho mỗi phương thức được hoàn thành bởi các mô-đun độc lập. Tất cả các mô-đun này được cố định trong quá trình tối ưu hóa UniAudio hoặc không có tham số.

2.1.1 ÂM THANH
Đối với tất cả các tác vụ sinh âm thanh được xem xét trong công trình này, âm thanh, bất kể loại của nó (lời nói, âm thanh, âm nhạc hoặc ca hát), là mục tiêu cần dự đoán. Thay vì mô hình hóa các loại âm thanh khác nhau một cách riêng biệt, UniAudio dự định token hóa tất cả các loại âm thanh như một phương thức đơn lẻ và thống nhất (mặc dù chúng thường có các mẫu khác biệt, như dải tần số), điều này đòi hỏi một mô hình phù hợp để ánh xạ tất cả các loại âm thanh vào một không gian tiềm ẩn chia sẻ. Theo Wang et al. (2023a); Kharitonov et al. (2023), các mô hình codec neural (Défossez et al., 2022; Yang et al., 2023b; Kumar et al., 2023) được sử dụng trong công trình này để token hóa âm thanh. Một tín hiệu âm thanh có thời lượng d với tần số lấy mẫu fs có thể được biểu diễn bởi một chuỗi x∈[−1,1]d∗fs. Một codec neural âm thanh dự định nén x và sau đó khôi phục nó như ˆx sử dụng kiến trúc encoder-decoder với một mô-đun lượng tử hóa:
h=Encoder(x)∈RT∗L;ˆh=Quantization(h);ˆx=Decoder(ˆh) (1)
trong đó T biểu thị số khung âm thanh sau khi giảm mẫu trong encoder, và L biểu thị chiều đặc trưng của encoder. Các biểu diễn rời rạc của âm thanh là sản phẩm trung gian của quá trình lượng tử hóa. Cho bất kỳ khung đầu ra ẩn ht nào, vector số nguyên zt = [z1t, ..., znqt] được tạo ra bởi Lượng tử hóa Vector Dư (RVQ) (Zeghidour et al., 2021), trong đó nq biểu thị số lớp lượng tử hóa vector. Lặp lại, mỗi phần tử zkt là chỉ số trong số tất cả các vector lượng tử hóa mức k được học trước và cố định {q∗k} có khoảng cách L2 nhỏ nhất đến phần dư giữa ht và tổng của tất cả các vector lượng tử hóa đã chọn trước đó {qzjtj, j = 1, ..., k−1}. Với biểu diễn rời rạc zt, ˆht được tái tạo như một ước lượng gần của ht có thể được sử dụng để khôi phục xt với decoder.

zkt = arg minm Distance(ht−∑k−1j=1 qzjtj, qmk); ˆht = ∑nqj=1 qzjtj; 1≤k≤nq (2)

Biểu diễn rời rạc của tất cả các khung âm thanh z∈ZT×nq là một ma trận và cần được chuyển đổi thành một chuỗi trước khi được xử lý bởi LM: nó được làm phẳng đơn giản thành một chuỗi, trong đó mỗi phần tử nq cho một khung là liên tiếp. Nếu không được nêu cụ thể, chúng tôi đặt nq = 3 trong các thí nghiệm. Vì dạng sóng có thể được khôi phục từ z với một decoder codec neural, phần còn lại của bài báo này chủ yếu thảo luận về cách dự đoán chuỗi token âm thanh z sử dụng kỹ thuật LLM. Vì UniAudio dự định sinh cả nội dung lời nói và phi lời nói, chúng tôi xây dựng mô hình codec riêng với phạm vi dữ liệu rộng hơn. Chi tiết về cấu hình codec của chúng tôi có trong Phụ lục E.

2.1.2 CÁC PHƯƠNG THỨC KHÁC
Ngoài âm thanh, các phương thức khác được xem xét trong UniAudio cũng cần được biểu diễn dưới dạng chuỗi. Ngoài ra, hầu hết các chuỗi này được chuyển đổi thành các chuỗi rời rạc thông qua token hóa. Việc tuần tự hóa và token hóa các phương thức đầu vào này, cùng với các đặc điểm chính của chúng, được tóm tắt ngắn gọn dưới đây.

Âm vị: Âm vị là các đơn vị cơ bản của phát âm lời nói trong ngôn ngữ học. Chuỗi âm vị có nhiều nguồn: (1) khi chỉ có văn bản, chuỗi âm vị không có thông tin thời lượng có thể được thu từ việc ánh xạ văn bản-âm vị sử dụng từ điển phát âm; (2) khi chỉ có lời nói, chuỗi âm vị với thông tin thời lượng được thu từ tìm kiếm beam của hệ thống DNN-HMM (Hinton et al., 2012); (3) khi có cả văn bản và lời nói, chuỗi âm vị với thông tin thời lượng được thu từ căn chỉnh bắt buộc của hệ thống DNN-HMM.

MIDI: MIDI (Zhang et al., 2022) được sử dụng rộng rãi cho các tác vụ tổng hợp giọng ca hát. Thông tin F0 và thời lượng được bao gồm trong MIDI. Chúng tôi sử dụng thông tin thời lượng để làm phẳng chuỗi F0, để chuỗi F0 mức khung được thu được.

Văn bản: Văn bản hoạt động như một phương tiện hiệu quả để mang các hướng dẫn của con người trong các tác vụ sinh âm thanh (Yang et al., 2023a; Copet et al., 2023). Trong công trình này, các hướng dẫn văn bản này được biểu diễn như các embedding liên tục được rút ra từ LLM văn bản được đào tạo trước (Raffel et al., 2020), vì các embedding này chứa ngữ nghĩa văn bản phong phú. Việc xử lý các embedding liên tục này với LLM được làm rõ thêm trong Phần 2.3.

Token Ngữ nghĩa: Các token ngữ nghĩa được rút ra từ các embedding liên tục được xuất ra bởi các mô hình học tự giám sát (SSL) âm thanh. Các biểu diễn liên tục này rất giàu thông tin và có thể được áp dụng trong cả các tác vụ hiểu lời nói (Rubenstein et al., 2023) và sinh (Borsos et al., 2023). Theo Huang et al. (2023b), các biểu diễn liên tục này được token hóa bằng cách thực hiện phân cụm K-means (Hsu et al., 2021) trên các biểu diễn liên tục này. Vì các biểu diễn liên tục là mức khung, các token ngữ nghĩa cũng mã hóa thông tin thời lượng.

2.2 CÔNG THỨC HÓA TÁC VỤ THỐNG NHẤT
Bảng 1: Định dạng chuỗi của tất cả các tác vụ được hỗ trợ bởi UniAudio. Màu văn bản biểu thị phương thức. đen: âm thanh; xanh lá: âm vị; xanh dương: MIDI; tím: văn bản; nâu: token ngữ nghĩa. ♣có nghĩa là các tác vụ sinh âm thanh với độ dài xác định. ♢: có nghĩa là các tác vụ chỉ được bao gồm trong giai đoạn tinh chỉnh. Prompt người nói là một lời nói 3 giây và được sử dụng để biểu diễn nhận dạng người nói.

Tác vụ | Điều kiện | Mục tiêu Âm thanh
---|---|---
Chuyển Văn bản thành Lời nói (TTS) (Wang et al., 2023a) | âm vị, prompt người nói | lời nói
Chuyển đổi Giọng nói (VC)♣(Wang et al., 2023e) | token ngữ nghĩa, prompt người nói | lời nói
Nâng cao Lời nói (SE)♣(Wang et al., 2023b) | lời nói nhiễu | lời nói
Trích xuất Lời nói Mục tiêu (TSE)♣(Wang et al., 2018) | lời nói hỗn hợp, prompt người nói | lời nói
Tổng hợp Giọng Ca hát (SVS) (Liu et al., 2022) | âm vị (với thời lượng), prompt người nói, MIDI | ca hát
Chuyển Văn bản thành Âm thanh (Sound) (Yang et al., 2023c) | mô tả văn bản | âm thanh
Chuyển Văn bản thành Âm nhạc (Music) (Agostinelli et al., 2023) | mô tả văn bản | âm nhạc
Chỉnh sửa Âm thanh (A-Edit)♣♢(Wang et al., 2023d) | mô tả văn bản, âm thanh gốc | âm thanh
Khử vọng lời nói (SD)♣♢(Wu et al., 2016) | lời nói vọng | lời nói
Hướng dẫn TTS (I-TTS)♢(Guo et al., 2023) | âm vị, hướng dẫn văn bản | lời nói
Chỉnh sửa Lời nói (S-Edit)♢(Tae et al., 2021) | âm vị (với thời lượng), lời nói gốc | lời nói

Đối với tất cả các tác vụ được xem xét trong UniAudio, âm thanh mục tiêu được sinh ra dựa trên các điều kiện đã cho. Với cùng phương thức mục tiêu, tức là âm thanh, chính các điều kiện định nghĩa các tác vụ sinh âm thanh khác nhau. Tuy nhiên, ngay cả với sự biến đổi trong các điều kiện, tất cả các tác vụ vẫn có thể được công thức hóa thống nhất như các tác vụ mô hình hóa tuần tự có thể được xử lý bởi LLM: cả âm thanh mục tiêu và các điều kiện đều được chuyển đổi thành các chuỗi con và nối thành chuỗi [điều kiện, mục tiêu] để xử lý.

UniAudio hỗ trợ tổng cộng 11 tác vụ sinh âm thanh. Các định dạng tuần tự của mỗi tác vụ được định nghĩa trong Bảng 1, trong đó các chuỗi con của tất cả các phương thức được rút ra như trong Phần 2.1. Tuy nhiên, do cấu hình độc đáo của mỗi tác vụ, một số chuỗi con điều kiện phải trải qua các thao tác tiền xử lý đặc thù cho tác vụ trong quá trình token hóa. Đối với âm thanh, các thao tác này chủ yếu là để làm hỏng dữ liệu, như thêm nhiễu, vọng và lời nói trộn với người nói khác trong âm thanh thô trước token hóa. Đối với âm vị và token ngữ nghĩa, thông tin thời lượng được bảo tồn theo mặc định nhưng cũng có thể bị loại bỏ. Đối với các tác vụ tổng hợp giọng ca hát và chỉnh sửa lời nói, thông tin thời lượng của âm vị được sử dụng. Đối với các tác vụ TTS và I-TTS, thông tin thời lượng không được sử dụng. Đối với MIDI, thông tin thời lượng được sử dụng để lặp lại chuỗi F0. Đối với embedding văn bản, không có thao tác nào được áp dụng trong công trình này.

Để tránh nhầm lẫn, một số token rời rạc đặc biệt (được bao quanh bởi <>) được chèn để chỉ ra (1) phần bắt đầu và kết thúc của toàn bộ chuỗi; (2) phần bắt đầu và kết thúc của mỗi chuỗi con của một phương thức nhất định; và (3) định danh tác vụ. Ví dụ, đối với một chuỗi tác vụ chuyển văn bản thành âm thanh sinh âm thanh mục tiêu dựa trên mô tả văn bản, toàn bộ chuỗi sẽ như: <start> <sound_task> <text_start> text_sequence <text_end> <audio_start> audio_sequence <audio_end> <end>.

2.3 TRANSFORMER ĐA TỶ LỆ
Các nghiên cứu trước về sinh âm thanh dựa trên LLM (Copet et al., 2023) ủng hộ việc mô hình hóa các token âm thanh rời rạc như các chuỗi làm phẳng. Nếu vậy, các chuỗi này được xử lý với độ dài T×nq, điều này rất khó khăn xem xét độ phức tạp không gian bậc hai của Transformer (Vaswani et al., 2017) đối với độ dài. Lấy cảm hứng từ Yu et al. (2023), một kiến trúc Transformer đa tỷ lệ được thiết kế đặc biệt cho các chuỗi âm thanh rời rạc, là một mô hình phân cấp xử lý tương quan giữa khung và trong khung bằng các mô-đun Transformer toàn cục và cục bộ một cách riêng biệt. Tổng quan về kiến trúc được đề xuất có trong Hình 1. Thay vì xử lý toàn bộ chuỗi làm phẳng từng token như các nghiên cứu trước (Kharitonov et al., 2023), transformer đa tỷ lệ xem xét các patch (tức là mỗi token liên tiếp nq) như các đơn vị mô hình hóa toàn cục và sau đó xử lý các token trong mỗi patch cục bộ. Lưu ý rằng cả Transformer toàn cục và cục bộ đều có tính nhân quả.

Đối với các chuỗi token âm thanh, mỗi patch tính đến nq token âm thanh liên tiếp chính xác biểu diễn một khung âm thanh. Đầu tiên, như đề xuất trong Phương trình 2, bất kể lựa chọn chính xác của mỗi vector lượng tử hóa qz∗t∗, chính vector lượng tử hóa tổng ˆht được sử dụng để biểu diễn khung âm thanh. Do đó, trong giai đoạn embedding, mỗi patch (tức là khung) được biểu diễn bởi vector tổng của các embedding tương ứng trước khi vào Transformer toàn cục. Thứ hai, Transformer toàn cục dự đoán âm thanh theo từng khung: để dự đoán khung xt, nó xuất ra các biểu diễn liên tục bao gồm khung xt−1 và tất cả nội dung trước đó. Các biểu diễn liên tục này sẽ được xử lý thêm bởi Transformer cục bộ. Thứ ba, cũng như trong Phương trình 2, cho biểu diễn ẩn ht, việc thu được zt độc lập với bất kỳ đầu ra ẩn nào khác ngoài ht. Lấy cảm hứng từ điều này, việc dự đoán các token rời rạc cho khung xt, tức là patch zt, chỉ với đầu ra ẩn của Transformer toàn cục tương ứng với khung xt−1 là hợp lý. Để chi tiết hơn, vì việc thu được mỗi token zkt phụ thuộc tự hồi quy vào các token trước đó của nó {zjt|j < k}, một Transformer cục bộ được áp dụng để dự đoán chuỗi patch zt theo phong cách tự hồi quy. Trong quá trình này, vector tương ứng được xuất ra bởi transformer toàn cục hoạt động như một ngữ cảnh mức patch, được biến đổi tuyến tính và sau đó thêm vào kết quả embedded của mỗi token zkt.

Kiến trúc Transformer đa tỷ lệ được đề xuất cũng tương thích với các chuỗi rời rạc và liên tục ngoài âm thanh. Đối với tất cả các token rời rạc trừ âm thanh (âm vị, ngữ nghĩa, MIDI và token đặc biệt), mỗi token có ngữ nghĩa độc lập và do đó nên tính cho một patch. Vì vậy, các token rời rạc này lặp lại nq lần để điền mỗi patch. Các embedding văn bản liên tục cũng được lặp lại nq lần cho cùng mục đích. Ngoài ra, quá trình embedding của chúng được thay thế bằng một biến đổi tuyến tính trong khi mục tiêu dự đoán của chúng cho Transformer cục bộ là các token đặc biệt liên tiếp <continuous_token>.

Thiết kế của Transformer đa tỷ lệ được đề xuất có thể giảm hiệu quả độ phức tạp tính toán. Đầu tiên, độ dài chuỗi tương đương cho Transformer toàn cục được giảm từ T×nq xuống T, làm cho chi phí mô hình hóa toàn cục độc lập với nq và do đó việc áp dụng nq lớn hơn trở nên khả thi. Thứ hai, việc tính toán trong patch để tạo ra các token rời rạc cho mỗi khung được chuyển giao cho Transformer cục bộ. Việc tính toán trên transformer cục bộ tương đối nhẹ vì nó chỉ xử lý chuỗi rất ngắn (cố định với độ dài nq) và theo kinh nghiệm có ít tham số hơn Transformer toàn cục theo thiết kế.

3 THÍ NGHIỆM
Phần này đầu tiên giới thiệu thiết lập thí nghiệm trong Phần 3.1. Kết quả cho giai đoạn đào tạo và giai đoạn tinh chỉnh được trình bày trong Phần 3.2 và 3.3 tương ứng. Các nghiên cứu loại bỏ được trình bày trong Phần 3.4.

3.1 THIẾT LẬP THÍ NGHIỆM
Dữ liệu và Mô hình: UniAudio được xây dựng trên các tập dữ liệu có nhãn. Cụ thể, 12 tập dữ liệu được áp dụng trong công trình này, tất cả đều có sẵn công khai. Tổng lượng âm thanh là 165K giờ. Thống kê dữ liệu chi tiết và việc áp dụng chúng cho mỗi tác vụ có trong Phụ lục A.1. Các token rời rạc từ tất cả các phương thức tạo thành một từ vựng chung có kích thước 4212, bao gồm tất cả các token đặc biệt. Các lớp decoder Transformer vanilla với tính nhân quả được áp dụng nhất quán trong Transformer toàn cục và cục bộ. Ngân sách tham số tổng thể là khoảng 1B. Cấu hình mô hình chi tiết có trong Phụ lục A.2. Các mô hình codec neural hiện tại không tối ưu cho việc sinh âm thanh toàn diện, chủ yếu do phạm vi dữ liệu. Một mô hình codec neural cải tiến sau đó được xây dựng với ít mức lượng tử hóa nq hơn, tỷ lệ khung mỗi giây nhỏ hơn, chất lượng cao hơn và phạm vi rộng hơn (xem Phụ lục E).

Đào tạo và Suy luận: Giai đoạn đào tạo bao gồm 7 tác vụ trong khi 4 tác vụ mới được thêm vào trong giai đoạn tinh chỉnh. Bảng 1 chỉ định các tác vụ chỉ dành cho tinh chỉnh. Cả đào tạo và tinh chỉnh đều được hoàn thành với 16 GPU AMD MI200-64G. Cấu hình chi tiết của tối ưu hóa có trong Phụ lục A.3. Để giữ lại hiệu suất của các tác vụ trước đó trong quá trình tinh chỉnh, theo Conneau et al. (2020), dữ liệu đào tạo được lấy mẫu lại đối với các tác vụ với α = 0.05. Lấy mẫu Top-k được áp dụng nhất quán cho suy luận, trong đó k và nhiệt độ được đặt lần lượt là 30 và 0.8. Vì Transformer toàn cục không dự đoán trực tiếp các token, quá trình lấy mẫu chỉ xảy ra trong suy luận Transformer cục bộ.

Đánh giá: Để đánh giá, hầu hết các tác vụ được đánh giá sử dụng cả các chỉ số khách quan và chủ quan. Nói chung, cho đánh giá khách quan, Tỷ lệ Lỗi Từ (WER) được sử dụng để đánh giá khả năng hiểu được của lời nói được tạo ra; Điểm Tương đồng (SIM) dành cho sự tương đồng về mặt nhận dạng người nói; Đánh giá Tri giác Chất lượng Lời nói (PESQ), VISQOL, DNSMOS và Méo mó Cepstral Mel (MCD) là các chỉ số chất lượng mức tín hiệu được rút ra từ nghiên cứu thính giác con người; Theo (Copet et al., 2023), Khoảng cách Âm thanh Fréchet (FAD), Phân kỳ Kullback-Leiber (KL) và Khoảng cách Fréchet (FD) dành cho độ trung thực âm thanh và sự tương đồng âm thanh; Để đánh giá chủ quan, MOS và SMOS được áp dụng để cung cấp phán đoán lấy con người làm trung tâm cho các tác vụ liên quan đến lời nói và ca hát. Đối với các tác vụ chuyển văn bản thành âm thanh và chuyển văn bản thành âm nhạc, chúng tôi sử dụng chất lượng tổng thể (OVL) và mức độ liên quan đến đầu vào văn bản (REL) (Copet et al., 2023). Lưu ý tất cả kết quả chủ quan được thu từ Amazon Mechanical Turk để so sánh công bằng. Phụ lục F hiển thị chi tiết của quá trình đánh giá chủ quan.

3.2 KẾT QUẢ CỦA 7 TÁC VỤ SINH TRONG GIAI ĐOẠN ĐÀO TẠO
Phần này trình bày kết quả đánh giá tổng thể của mô hình UniAudio được đề xuất trên tất cả 7 tác vụ sinh âm thanh trong giai đoạn đào tạo. Một so sánh toàn diện được thực hiện giữa UniAudio và nhiều nghiên cứu trước đó về mỗi tác vụ, bao gồm không chỉ các phương pháp dựa trên LM mà còn các phương pháp dựa trên mô hình khuếch tán cũng như các phương pháp sinh âm thanh thông thường khác. So sánh chi tiết được trình bày trong Phụ lục B. Chúng tôi đã chọn một trong những nghiên cứu tiên tiến nhất trong mỗi tác vụ và trình bày kết quả trong Bảng 2.

Bảng 2: Đánh giá hiệu suất cho UniAudio và các nghiên cứu trước đó được chọn trong giai đoạn đào tạo

Tác vụ | Mô hình | Đánh giá Khách quan | Đánh giá Chủ quan
---|---|---|---
 | | Chỉ số | Kết quả | Chỉ số | Kết quả
Chuyển Văn bản thành Lời nói | Shen et al. (2023) | SIM(↑)/ WER (↓) | 0.62 / 2.3 | MOS (↑) / SMOS (↑) | 3.83±0.10 / 3.11±0.10
 | UniAudio | | 0.71 / 2.0 | | 3.81±0.07 / 3.56±0.10
Chuyển đổi Giọng nói | Wang et al. (2023e) | SIM(↑)/ WER (↓) | 0.82 / 4.9 | MOS (↑) / SMOS (↑) | 3.41±0.08 / 3.17 ±0.09
 | UniAudio | | 0.87 / 4.8 | | 3.54 ±0.07 / 3.56 ±0.07
Nâng cao Lời nói | Richter et al. (2023) | PESQ (↑)/ VISQOL (↑) / DNSMOS (↑) | 3.21 / 2.72 / 3.29 | MOS (↑) | 3.56±0.08
 | UniAudio | | 2.63 / 2.44 / 3.66 | | 3.68 ±0.07
Trích xuất Người nói Mục tiêu | Wang et al. (2018) | PESQ (↑)/ VISQOL (↑) / DNSMOS (↑) | 2.41 / 2.36 / 3.35 | MOS (↑) | 3.43±0.09
 | UniAudio | | 1.88 / 1.68 / 3.96 | | 3.72 ±0.06
Tổng hợp Giọng Ca hát | Liu et al. (2022) | - | - | MOS (↑) / SMOS (↑) | 3.94±0.02 / 4.05±0.06
 | UniAudio | | | | 4.08 ±0.04 / 4.04 ±0.05
Chuyển Văn bản thành Âm thanh | Liu et al. (2023a) | FAD (↓)/ KL (↓) | 4.93 / 2.6 | OVL (↑) / REL (↑) | 61.0±1.9 / 65.7 ±1.8
 | UniAudio | | 3.12 / 2.6 | | 61.9 ±1.9 / 66.1 ±1.5
Chuyển Văn bản thành Âm nhạc | Copet et al. (2023) | FAD (↓)/ KL (↓) | 4.52 / 1.4 | OVL (↑) / REL (↑) | 73.3±1.5 / 71.3 ±1.7
 | UniAudio | | 3.65 / 1.9 | | 67.9 ±1.7 / 70.0 ±1.5

Như đề xuất trong Bảng 2, UniAudio là một hệ thống linh hoạt có thể xử lý tất cả 7 tác vụ sinh âm thanh cùng nhau và đạt được hiệu suất cạnh tranh. Theo đánh giá chủ quan, UniAudio vượt trội hơn các baseline trong 3 trên 6 tác vụ (TTS, VC, Sound); theo đánh giá khách quan, nó đạt được kết quả tốt hơn trên 5 trên 7 tác vụ trừ SVS và Music. Chúng tôi cũng thấy UniAudio kém hiệu quả trên một số chỉ số. Hiệu suất chủ quan của UniAudio cho SE và TSE kém cạnh tranh hơn so với các đối thủ của nó, điều này cũng được quan sát trong tài liệu trước đây (Erdogan et al., 2023) rằng các chỉ số đánh giá mức tín hiệu có thể không phù hợp với các phương pháp sinh dựa trên LM. UniAudio không thể vượt trội hơn đối thủ được chọn (Copet et al., 2023) trong tác vụ Chuyển văn bản thành Âm nhạc. Chúng tôi lưu ý rằng (Copet et al., 2023) được xây dựng với nhiều dữ liệu có nhãn riêng tư hơn UniAudio của chúng tôi.

3.3 KẾT QUẢ CỦA 4 TÁC VỤ SINH TRONG GIAI ĐOẠN TINH CHỈNH
Bảng 3: Đánh giá hiệu suất cho UniAudio và các nghiên cứu trước đó được chọn trong giai đoạn tinh chỉnh

Tác vụ | Mô hình | Đánh giá
---|---|---
 | | Chỉ số | Kết quả
Chỉnh sửa Âm thanh | AUDIT (Wang et al., 2023d) | FD(↓)/ KL (↓) | 20.78 / 0.86
 | UniAudio | | 17.78 / 0.77
Khử vọng Lời nói | SGMSE+ Richter et al. (2023) | PESQ (↑)/ DNSMOS (↑) | 2.87 / 3.42
 | UniAudio | | 2.13 / 3.51
Hướng dẫn TTS | Sự thật chuẩn | MOS (↑)/ SMOS (↑) | 3.77±0.07 /3.85±0.08
 | UniAudio | | 3.61 ±0.09 / 3.71 ±0.09
Chỉnh sửa Lời nói | Tái tạo hệ thống TTS | MCD(↓) / MOS (↑) | 6.98 / 3.69 ±0.08
 | UniAudio | | 5.12 /3.82±0.06

Vì UniAudio được thiết kế để liên tục hỗ trợ các tác vụ sinh âm thanh mới, phần này báo cáo hiệu suất của UniAudio trên các tác vụ chưa thấy. Mô hình được thu từ việc tinh chỉnh trên 4 tác vụ mới cùng lúc và kết quả được trình bày trong Bảng 3. Tương tự như phần 3.2, cho mỗi tác vụ, chúng tôi so sánh hiệu suất của UniAudio với một nghiên cứu trước đó được chọn và báo cáo kết quả chi tiết trong Phụ lục B. Như thể hiện trong Bảng 3, mô hình UniAudio được tinh chỉnh vượt trội hơn các baseline trong chỉnh sửa âm thanh và khử vọng lời nói và đang tiến gần đến chất lượng sự thật chuẩn trong tác vụ Hướng dẫn TTS. Đối với chỉnh sửa lời nói, UniAudio cho thấy cải thiện đáng kể so với việc tạo ra toàn bộ câu.

3.4 NGHIÊN CỨU LOẠI BỎ
3.4.1 LỢI ÍCH CỦA VIỆC XÂY DỰNG MÔ HÌNH SINH ÂM THANH THỐNG NHẤT
Để xác nhận thêm tuyên bố của chúng tôi rằng việc xây dựng một mô hình thống nhất cho tất cả 11 tác vụ sinh âm thanh là đầy hứa hẹn và có lợi ích, nhiều nghiên cứu loại bỏ hơn được thực hiện. Trong Phụ lục C.1, chúng tôi chứng minh rằng mô hình UniAudio được đào tạo chung luôn vượt trội hơn các mô hình được đào tạo cho mỗi tác vụ cụ thể, bất kể chúng được bao gồm trong giai đoạn đào tạo hay giai đoạn tinh chỉnh. Trong Phụ lục C.2, chúng tôi bổ sung xác nhận rằng tinh chỉnh trên 4 tác vụ sinh âm thanh mới không ảnh hưởng đến hiệu suất của UniAudio trên 7 tác vụ gốc. Trong Phụ lục C.3, chúng tôi quan sát rằng UniAudio có thể liên tục hưởng lợi từ việc tăng khối lượng dữ liệu đào tạo của mỗi tác vụ, điều này cung cấp một lý do khác để xây dựng các mô hình sinh âm thanh toàn diện: các mô hình này dễ dàng mở rộng hơn vì việc thu thập dữ liệu khả thi hơn. Chúng tôi cung cấp thêm thảo luận trong Phụ lục D về hiệu quả của việc xây dựng một mô hình sinh âm thanh toàn diện.

3.4.2 HIỆU QUẢ CỦA MÔ HÌNH TRANSFORMER ĐA TỶ LỆ
Như trong phần 2.3, việc áp dụng codec neural đã trở thành một lựa chọn phổ biến của sinh âm thanh dựa trên LLM nhưng gây ra vấn đề chuỗi quá dài cần xem xét thêm. Phần này so sánh Transformer đa tỷ lệ được đề xuất với bốn phương pháp đại diện trong lĩnh vực này: Dự đoán Làm phẳng (ví dụ SPEARTTS (Kharitonov et al., 2023)), Dự đoán Thô trước (ví dụ VALL-E (Wang et al., 2023a)), Dự đoán Song song (ví dụ AudioGen (Kreuk et al., 2022)) và Dự đoán Trì hoãn (ví dụ MusicGen (Copet et al., 2023)). Hình 2 minh họa thứ tự dự đoán của năm kiến trúc này. Các thí nghiệm được thực hiện trên các tác vụ chuyển văn bản thành lời nói và chuyển văn bản thành âm nhạc và kết quả được báo cáo trong Bảng 4 và 5 tương ứng.

Tự Hồi quy và Hiệu suất: Trong số tất cả 4 baseline đã đề cập, Copet et al. (2023) tuyên bố rằng phương pháp làm phẳng cung cấp chất lượng sinh âm thanh tốt nhất. Họ tiếp tục tuyên bố rằng hiệu suất vượt trội của dự đoán làm phẳng chủ yếu là do thuộc tính tự hồi quy; ba phương pháp khác không bảo tồn thuộc tính này vì dự đoán đồng thời được giới thiệu (xem Hình 2). Trong bối cảnh áp dụng codec, chúng tôi diễn giải lại thuộc tính tự hồi quy là: dự đoán token hiện tại dựa trên tất cả token của các khung trước đó và các token trước đó trong khung hiện tại, hoặc chính thức, dự đoán token hiện tại zkt dựa trên các token: {zk't'|t' < t} ∪ {zk't'|t' = t, k' < k}. Với định nghĩa này, chúng tôi tuyên bố rằng transformer đa tỷ lệ được đề xuất cũng tự hồi quy.

Phù hợp với Copet et al. (2023), các thí nghiệm của chúng tôi cũng xác nhận tầm quan trọng của thuộc tính tự hồi quy. Như trong Bảng 4 và 5, dự đoán làm phẳng mang lại chất lượng sinh tốt hơn so với dự đoán song song, thô trước và trì hoãn. Ngoài ra, với cùng thuộc tính tự hồi quy, transformer đa tỷ lệ được đề xuất của chúng tôi đạt được hiệu suất tương đương với dự đoán làm phẳng về chất lượng sinh, điều này, một lần nữa, xác nhận tầm quan trọng của tự hồi quy.

Hiệu quả: Ngoài chất lượng sinh, hiệu quả là một mối quan tâm chính của sinh âm thanh. Mặc dù có thuộc tính tự hồi quy, dự đoán làm phẳng không tối ưu về hiệu quả: việc mô hình hóa dựa trên chuỗi dài T×nq, có độ phức tạp không gian O((T∗nq)2) trong tự chú ý. Vì việc tăng nq mang lại chất lượng tái tạo cao hơn với chi phí chuỗi dài hơn và nhiều tính toán hơn, vấn đề này trở nên nghiêm trọng hơn khi áp dụng nq lớn hơn. Vì độ dài chuỗi tăng tỷ lệ thuận với nq, chúng tôi thấy khó khăn trong việc đào tạo với nq≥4 trong thực nghiệm. Ngược lại, Transformer đa tỷ lệ được đề xuất phân phối việc mô hình hóa giữa khung và trong khung cho các mô-đun con toàn cục và cục bộ tương ứng, do đó giảm nhẹ độ phức tạp không gian xuống O(T∗2). Cuối cùng, không có yêu cầu tự hồi quy, các phương pháp như dự đoán song song, thô trước và trì hoãn đạt được hiệu quả tốt hơn do việc áp dụng dự đoán đồng thời. Vì độ phức tạp không gian độc lập với nq, việc đào tạo nq lớn hơn với transformer đa tỷ lệ trở nên khả thi.

--- TRANG 8 ---
Bảng 4: So sánh mô hình giữa Thô trước, Làm phẳng, Song song, dự đoán trì hoãn và Transformer đa tỷ lệ. Các thí nghiệm được thực hiện trên LibriTTS. Bộ nhớ GPU và thời gian đào tạo được thu từ âm thanh 20 giây (trung bình của 100 lần thử). Tất cả các mô hình có ngân sách tham số tương tự.

Cấu trúc | nq | MOS (↑) | MCD (↓) | Bộ nhớ GPU (GB) | Thời gian (s) / Lần lặp
---|---|---|---|---|---
Thô trước | 8 | 3.48 ±0.05 | 7.37 | 18.7 | 0.58
Song song | 3 | 3.14 ±0.07 | 7.89 | 13.56 | 0.53
Trì hoãn | 3 | 3.48 ±0.05 | 6.95 | 13.65 | 0.59
Làm phẳng | 3 | 3.80 ±0.09 | 6.56 | 36.7 | 1.63
Transformer Đa tỷ lệ (chúng tôi) | 3 | 3.77 ±0.05 | 6.52 | 19.4 | 0.73
Transformer Đa tỷ lệ (chúng tôi) | 8 | 3.84 ±0.06 | 6.27 | 24.0 | 1.10

Bảng 5: Nghiên cứu loại bỏ để khám phá hiệu quả của transformer đa tỷ lệ được đề xuất của chúng tôi. Các thí nghiệm được thực hiện trên các tác vụ chuyển văn bản thành âm nhạc với tập dữ liệu Million Song.

Cấu trúc | nq | FAD (↓) | KL (↓) | OVL. (↑) | REL. (↑)
---|---|---|---|---|---
Song song | 3 | 6.92 | 2.36 | 60.4±2.3 | 61.3 ±1.5
Trì hoãn | 3 | 6.07 | 2.23 | 62.8±1.9 | 63.9 ±1.6
Làm phẳng | 3 | 5.18 | 1.83 | 64.8±1.8 | 65.2 ±2.0
Transformer Đa tỷ lệ (chúng tôi) | 3 | 5.24 | 1.80 | 64.4±2.1 | 66.2 ±2.4

Về mặt thí nghiệm, transformer đa tỷ lệ được đề xuất giảm đáng kể chi phí thời gian và bộ nhớ so với dự đoán làm phẳng. Nó vẫn tốn nhiều thời gian và bộ nhớ hơn so với ba baseline khác.

Dựa trên các quan sát trên, chúng tôi tuyên bố rằng transformer đa tỷ lệ được đề xuất là một kiến trúc tự hồi quy đạt được sự cân bằng tốt hơn giữa chất lượng sinh và hiệu quả.

4 NGHIÊN CỨU LIÊN QUAN
Công trình này là một nỗ lực nhằm đạt được sinh âm thanh toàn diện thông qua các kỹ thuật dựa trên LLM. Có một lịch sử nghiên cứu dài cho nhiều tác vụ sinh âm thanh. Theo truyền thống, thiết kế của các tác vụ này tận dụng mạnh mẽ kiến thức lĩnh vực của mỗi tác vụ cụ thể, và các quy trình làm việc của chúng khác biệt với nhau: Đối với các tác vụ như TTS, SE, TSE, TT-Music, VC, S-Edit, SD, SVS, (1) kiến trúc mạng neural của chúng dựa trên Transformer (Ren et al., 2020) hoặc khác (Oord et al., 2016; Luo & Mesgarani, 2019); (2) mục tiêu đào tạo của chúng có thể ở miền thời gian (Luo & Mesgarani, 2019), miền tần số (Yu et al., 2017) hoặc khác (Gu et al., 2021; Shen et al., 2023); (3) thiết kế của chúng được lấy cảm hứng và rút ra từ nghiên cứu ngôn ngữ học và ngữ âm học (Zen et al., 2013), xử lý tín hiệu (Griffin & Lim, 1984), tri giác thính giác (Shadle & Damper, 2001) và học máy (Wang et al., 2016), v.v.; (4) chúng sử dụng các mô hình sinh khác nhau, như mô hình khuếch tán (Shen et al., 2023; Wang et al., 2023b), flow (Le et al., 2023), Seq2Seq (Ren et al., 2020; Liu et al., 2021).

Sự thịnh vượng của các kỹ thuật LLM (Radford et al., 2019; OpenAI, 2023) đã thúc đẩy đáng kể tiến bộ trong nghiên cứu sinh âm thanh theo nhiều hướng. Đầu tiên, các mô hình ngôn ngữ lớn, cùng với các phương pháp prompt, đã truyền cảm hứng cho nhiều tác vụ sinh âm thanh mới nổi dựa trên hướng dẫn hoặc mô tả văn bản từ con người, như Instruct-TTS (Yang et al., 2023a), Chuyển văn bản thành âm thanh (Kreuk et al., 2022; Huang et al., 2023a) và chuyển văn bản thành âm nhạc Copet et al. (2023); Agostinelli et al. (2023). Thứ hai, ngoài văn bản, âm thanh cũng có thể được token hóa thành các chuỗi rời rạc (Zeghidour et al., 2021; Défossez et al., 2022; Kumar et al., 2023) có thể được xử lý thêm bởi LM. Các mô hình sinh âm thanh dựa trên LM sau đó cho thấy khả năng vượt trội trong việc khái quát hóa đối với người nói chưa thấy (Wang et al., 2023a), tài nguyên thấp (Kharitonov et al., 2023) và các kịch bản đa ngôn ngữ (Zhang et al., 2023). Các phương pháp này cũng đạt được kết quả tốt nhất trong hiệu suất tổng thể trong phạm vi riêng của chúng. Cuối cùng, mô hình giống LM có thể được kết hợp thêm với các mô hình sinh hiện có (ví dụ, mô hình khuếch tán Rombach et al. (2022)) để thu được chất lượng sinh cải thiện.

Việc xử lý từng tác vụ sinh âm thanh theo từng trường hợp là vất vả, đặc biệt khi xem xét đến tình trạng thiếu hụt dữ liệu cũng như nhu cầu mới nổi và đa dạng trong lĩnh vực này. Ngoài ra, việc xây dựng một mô hình sinh âm thanh toàn diện là một mô hình đầy hứa hẹn và thực tế. Với tiến bộ nhanh chóng trong nghiên cứu sinh âm thanh, các thiết kế gần đây của sinh âm thanh, bao gồm cả những thiết kế dựa trên LM, có xu hướng hỗ trợ nhiều tác vụ sinh âm thanh đồng thời. Một số nghiên cứu tiên phong (Wang et al., 2023c; Le et al., 2023; Shen et al., 2023; Liu et al., 2023b; Jiang et al., 2023) rõ ràng coi việc hỗ trợ nhiều tác vụ như một điểm mạnh chính; thiết kế của các nghiên cứu trước đây khác (Borsos et al., 2023; Kharitonov et al., 2023; Shen et al., 2023) có thể sinh âm thanh theo nghĩa rộng hơn so với những gì chúng tuyên bố ban đầu. Theo các nghiên cứu tiên phong này, UniAudio hỗ trợ phạm vi mở rộng gồm 11 tác vụ sinh âm thanh trong một mô hình thống nhất dựa trên LM.

5 HẠN CHẾ
Không phải tất cả các tác vụ sinh âm thanh đã biết đều được bao gồm trong UniAudio được đề xuất, như loại bỏ nhiễu, chỉnh sửa lời nói nhiễu (Wang et al., 2023c) và dịch lời nói sang lời nói (Rubenstein et al., 2023; Barrault et al., 2023). Tất cả các tác vụ mới được thêm vào trong tinh chỉnh được công thức hóa với các phương thức đã biết trong giai đoạn đào tạo; Việc giới thiệu các phương thức mới trong quá trình tinh chỉnh chưa được khám phá trong công trình này. UniAudio hiện tại không xem xét dữ liệu không nhãn hoặc các mô hình nền tảng chuyên biệt cho lĩnh vực, có thể cải thiện thêm hiệu suất tổng thể. Các mẫu được tạo ra bởi UniAudio không được đảm bảo về chất lượng và có thể chứa lỗi.

6 KẾT LUẬN
Để xử lý nhu cầu mới nổi và đa dạng trong sinh âm thanh, công trình này là một nỗ lực nhằm đạt được sinh âm thanh toàn diện. UniAudio được đề xuất như một mô hình sinh thống nhất dựa trên LM hỗ trợ 11 tác vụ sinh âm thanh khác nhau. Trong các thí nghiệm, UniAudio được đề xuất cung cấp hiệu suất cạnh tranh trên tất cả 11 tác vụ. Nó cũng chứng minh empirically khả năng liên tục tích hợp các tác vụ sinh âm thanh chưa thấy. Demo và mã nguồn được công bố, với hy vọng UniAudio có thể trở thành một mô hình nền tảng cho sinh âm thanh toàn diện trong nghiên cứu tiếp theo.

7 TUYÊN BỐ ĐẠO ĐỨC
Chúng tôi đang đi sâu vào lĩnh vực cách mạng của việc sinh âm thanh đa dạng sử dụng kỹ thuật mô hình ngôn ngữ lớn. Chúng tôi thấy mình ở ngã ba của sự đổi mới và trách nhiệm. Điều quan trọng là phải thừa nhận các khía cạnh đạo đức của công trình và đảm bảo rằng những đóng góp của chúng tôi được sử dụng để cải thiện xã hội.

Tính Mở: Khi chúng tôi tiến bộ trong lĩnh vực này, điều quan trọng là phải đảm bảo rằng lợi ích của công nghệ này lan rộng và không giới hạn ở một số ít đặc quyền. Mã nguồn của chúng tôi được công bố công khai cùng với bài nộp này để đảm bảo quyền truy cập bình đẳng cho mọi người. Tất cả các thí nghiệm đều dựa trên các tập dữ liệu có thể truy cập mở cho phép so sánh và tái tạo theo hướng nghiên cứu.

Tránh Lạm dụng: Mặc dù mô hình của chúng tôi có thể tạo ra vô số nội dung âm thanh từ nhạc đến lời nói, có tiềm năng lạm dụng trong việc tạo ra thông tin sai lệch, âm thanh deepfake hoặc bất kỳ nội dung có hại nào. Chúng tôi ủng hộ việc áp dụng mã nguồn và mô hình của chúng tôi một cách có trách nhiệm, với sự tôn trọng đầy đủ đối với quyền riêng tư cá nhân và tuân thủ các quy định. Về tiềm năng lạm dụng mô hình của chúng tôi, các checkpoint sẽ không được công bố.

TÀI LIỆU THAM KHẢO
[Danh sách tài liệu tham khảo dài được bỏ qua để tiết kiệm không gian]

--- TRANG 16 ---
Phụ lục
A THIẾT LẬP THÍ NGHIỆM
Phụ lục này mô tả thiết lập thí nghiệm chi tiết, bao gồm thống kê dữ liệu, kiến trúc mô hình và chiến lược tối ưu hóa.

[Nội dung phụ lục chi tiết được rút gọn để tiết kiệm không gian]

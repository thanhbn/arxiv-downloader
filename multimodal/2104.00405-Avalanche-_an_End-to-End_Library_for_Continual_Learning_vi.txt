# 2104.00405.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2104.00405.pdf
# Kích thước file: 712727 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Avalanche: một Thư viện Hoàn chỉnh cho Học liên tục
Vincenzo Lomonaco1y*Lorenzo Pellegrini2†Andrea Cossu1;18†Antonio Carta1†Gabriele Grafﬁeti2†
Tyler L. Hayes3Matthias De Lange4Marc Masana5Jary Pomponi6Gido van de Ven7
Martin Mundt8Qi She9Keiland Cooper10Jeremy Forest11Eden Belouadah12
Simone Calderara13German I. Parisi14Fabio Cuzzolin15Andreas Tolias7Simone Scardapane6
Luca Antiga16Subutai Amhad17Adrian Popescu12Christopher Kanan3
Joost van de Weijer5Tinne Tuytelaars4Davide Bacciu1Davide Maltoni2
1Đại học Pisa2Đại học Bologna3Viện Công nghệ Rochester
4KU Leuven5Universitat Aut `onoma de Barcelona6Đại học Sapienza Rome
7Đại học Y Baylor8Đại học Goethe9ByteDance AI Lab
10Đại học California11Đại học New York12Universit ´e Paris-Saclay
13Đại học Modena và Reggio-Emilia14Đại học Hamburg
15Đại học Oxford Brookes16Orobix17Numenta18Scuola Normale Superiore
https://avalanche.continualai.org
Tóm tắt
Học liên tục từ các luồng dữ liệu không ổn định là một mục tiêu lâu dài và một vấn đề thách thức trong học máy. Gần đây, chúng ta đã chứng kiến sự quan tâm gia tăng và phát triển nhanh chóng trong học liên tục, đặc biệt trong cộng đồng học sâu. Tuy nhiên, các giải pháp thuật toán thường khó tái triển khai, đánh giá và chuyển đổi qua các cài đặt khác nhau, nơi mà ngay cả kết quả trên các benchmark tiêu chuẩn cũng khó tái tạo. Trong công trình này, chúng tôi đề xuất Avalanche, một thư viện mã nguồn mở hoàn chỉnh cho nghiên cứu học liên tục dựa trên PyTorch. Avalanche được thiết kế để cung cấp một codebase chia sẻ và hợp tác cho việc tạo mẫu nhanh, huấn luyện và đánh giá có thể tái tạo các thuật toán học liên tục.

1. Giới thiệu
Học Liên tục (CL), còn được gọi là Học Suốt đời hoặc Học Tăng dần, là một vấn đề nghiên cứu thách thức [7]. Gần đây, nó đã trở thành đối tượng quan tâm ngày càng tăng từ cộng đồng nghiên cứu, đặc biệt nhờ các nghiên cứu gần đây tận dụng các kiến trúc sâu dựa trên gradient [15, 37]. Trong vài năm qua, học máy đã chứng kiến một sản xuất nghiên cứu phong phú, đa dạng và độc đáo về chủ đề này: từ Thị giác Máy tính [9, 30, 36]
*Tác giả liên hệ: vincenzo.lomonaco@unipi.it
†Các nhà duy trì chính của Avalanche.
Hình 1: Biểu diễn hoạt động của Avalanche với các module chính (trên), các instance đối tượng chính (giữa) và luồng dữ liệu được tạo ra (dưới). Một Benchmark tạo ra một luồng các trải nghiệm ei được thuật toán học liên tục ACL với mô hình nội tại M truy cập tuần tự. Đối tượng Evaluator tương tác trực tiếp với thuật toán cung cấp một giao diện thống nhất để kiểm soát và tính toán nhiều chỉ số hiệu suất (pi), ủy quyền việc ghi nhật ký kết quả cho các đối tượng Logger.

đến Robotics [28, 40, 38], từ Học Tăng cường [25, 31] đến Học Chuỗi [8], cùng nhiều lĩnh vực khác.

Tuy nhiên, các thuật toán học liên tục ngày nay thường được thiết kế và triển khai từ đầu với các giả định, cài đặt và benchmark khác nhau khiến chúng khó
1arXiv:2104.00405v1  [cs.LG]  1 Apr 2021

--- TRANG 2 ---
so sánh với nhau hoặc thậm chí chuyển đổi sang các bối cảnh hơi khác một chút. Một yếu tố quan trọng cho việc củng cố một chủ đề nghiên cứu phát triển nhanh trong lĩnh vực học máy là sự có sẵn của các công cụ và thư viện giúp dễ dàng triển khai, đánh giá và nhân bản các mô hình qua các cài đặt khác nhau, đồng thời thúc đẩy khả năng tái tạo kết quả từ tài liệu [41].

Trong công trình này, chúng tôi đề xuất Avalanche, một thư viện mã nguồn mở (giấy phép MIT) hoàn chỉnh cho học liên tục dựa trên PyTorch [39], được thiết kế để cung cấp một codebase chia sẻ và hợp tác cho việc tạo mẫu nhanh, huấn luyện và đánh giá các thuật toán học liên tục.

Chúng tôi thiết kế Avalanche theo một bộ nguyên tắc thiết kế cơ bản (Mục 2) mà chúng tôi tin rằng có thể giúp các nhà nghiên cứu và thực hành theo nhiều cách: i) Viết ít code hơn, tạo mẫu nhanh hơn và giảm lỗi; ii) Cải thiện khả năng tái tạo; iii) Ưu tiên tính module hóa và khả năng tái sử dụng; iv) Tăng hiệu quả, khả năng mở rộng và tính di động của code; v) Thúc đẩy tác động và khả năng sử dụng.

Các đóng góp của bài báo này có thể được tóm tắt như sau:

1. Chúng tôi đề xuất một khung học liên tục tổng quát cung cấp nền tảng khái niệm cho Avalanche (Mục 3).

2. Chúng tôi thảo luận về thiết kế tổng quát của thư viện dựa trên năm module chính: Benchmarks, Training, Evaluation, Models và Logging (Mục 4).

3. Chúng tôi phát hành dự án mã nguồn mở, được duy trì cộng tác tại https://github.com/ContinualAI/avalanche, như kết quả của sự hợp tác melibatkan hơn 15 tổ chức qua châu Âu, Hoa Kỳ và Trung Quốc.

Các công trình liên quan đến dự án này được thảo luận trong Mục 5. Cuối cùng, chúng tôi thảo luận trong Mục 6 về tầm quan trọng mà một thư viện tất cả trong một, được cộng đồng điều hành có thể có đối với tương lai của học liên tục và các mở rộng có thể của nó.

2. Nguyên tắc Thiết kế
Avalanche được thiết kế với năm nguyên tắc chính: i) Tính Toàn diện và Nhất quán; ii) Dễ sử dụng; iii) Khả năng Tái tạo và Tính Di động; iv) Tính Module hóa và Độc lập; v) Hiệu quả và Khả năng Mở rộng. Những nguyên tắc này, chúng tôi cho rằng, quan trọng đối với bất kỳ dự án học liên tục nào nhưng trở nên thiết yếu để giải quyết những thách thức nghiên cứu thú vị nhất và các ứng dụng thực tế.

Tính toàn diện và nhất quán Nguyên tắc thiết kế chính cho Avalanche xuất phát từ khái niệm tính toàn diện, ý tưởng cung cấp một thư viện toàn diện và thống nhất với hỗ trợ hoàn chỉnh cho nghiên cứu và phát triển học liên tục. Một codebase toàn diện không chỉ cung cấp một điểm truy cập duy nhất và rõ ràng cho các nhà nghiên cứu và thực hành làm việc về chủ đề này, mà còn ưu tiên tính nhất quán qua thư viện, với sự tương tác mạch lạc và dễ dàng qua các module và sub-module. Không kém quan trọng, nó thúc đẩy việc củng cố một cộng đồng lớn có thể cung cấp hỗ trợ tốt hơn cho thư viện.

Dễ sử dụng Nguyên tắc thứ hai là tập trung vào sự đơn giản: các giải pháp đơn giản cho các vấn đề phức tạp và việc sử dụng đơn giản thư viện. Chúng tôi tập trung nỗ lực vào thiết kế một Giao diện Lập trình Ứng dụng (API) trực quan, một trang web chính thức và tài liệu phong phú với danh sách được tuyển chọn các notebook và ví dụ thực thi¹.

Khả năng tái tạo và tính di động Tái tạo kết quả bài báo nghiên cứu là một nhiệm vụ khó khăn nhưng rất cần thiết trong học máy [21]. Vấn đề trở nên tồi tệ hơn trong học liên tục. Một mục tiêu thiết kế quan trọng của Avalanche là cho phép các kết quả thí nghiệm được tái tạo một cách liền mạch. Điều này cho phép các nhà nghiên cứu đơn giản tích hợp nghiên cứu độc đáo của họ vào codebase chia sẻ và so sánh giải pháp của họ với tài liệu hiện có, tạo thành một vòng tròn đạo đức. Do đó, khả năng tái tạo không chỉ là một mục tiêu cốt lõi của nghiên cứu khoa học vững chắc và nhất quán, mà còn là một phương tiện để tăng tốc phát triển các giải pháp học liên tục độc đáo.

Tính module hóa và độc lập Tính module hóa là một nguyên tắc thiết kế cơ bản khác. Trong Avalanche, đơn giản đôi khi được uốn cong để ưu tiên tính module hóa và khả năng tái sử dụng. Điều này rất quan trọng cho khả năng mở rộng và để đưa codebase đến độ trưởng thành một cách hợp tác. Một sự tập trung đặc biệt vào tính độc lập của module được duy trì để đảm bảo khả năng sử dụng độc lập của các chức năng module riêng lẻ và tạo điều kiện học hỏi một công cụ cụ thể.

Hiệu quả và khả năng mở rộng Các yêu cầu tính toán và bộ nhớ trong học máy đã tăng đáng kể trong hai thập kỷ qua [52]. Các thư viện học sâu tiêu chuẩn như TensorFlow [1] hoặc PyTorch [39] đã tập trung vào hiệu quả và khả năng mở rộng như hai nguyên tắc thiết kế cơ bản, vì các thí nghiệm nghiên cứu hiện đại có thể mất nhiều tháng để hoàn thành [48]. Avalanche dựa trên cùng các nguyên tắc: cung cấp cho người dùng cuối một trải nghiệm liền mạch và minh bạch bất kể trường hợp sử dụng hoặc nền tảng phần cứng mà thư viện được chạy trên đó.

3. Khung Học Liên tục
Gần đây, chúng ta đã chứng kiến một nỗ lực đáng kể để chính thức hóa một khung tổng quát cho các thuật toán học liên tục [30, 31, 54]. Những đề xuất này thường phân loại các kịch bản và thuật toán dựa trên các đặc tính độc đáo và cài đặt cụ thể của chúng. Tuy nhiên, như được nêu trong bài báo này, trong thiết kế chính thức của Avalanche, chúng tôi có một cách tiếp cận khác.

Với quan điểm phát triển nhanh, thường xung đột về vấn đề, chúng tôi nhằm mục đích giảm số lượng giả định xuống mức tối thiểu, ưu tiên sự đơn giản và linh hoạt. Trong thực tế, điều này dịch thành việc cung cấp cho người dùng một bộ khối xây dựng có thể được sử dụng trong bất kỳ giải pháp học liên tục nào mà không áp đặt bất kỳ danh pháp mạnh mẽ, trừu tượng hóa ràng buộc hoặc giả định nào.

Trong Avalanche, dữ liệu được mô hình hóa như một chuỗi có thứ tự (hoặc luồng) bao gồm n trải nghiệm học, thường không phải iid:

e0; e1; : : : ; e n.

Một trải nghiệm học là một tập hợp bao gồm một hoặc nhiều mẫu có thể được sử dụng để cập nhật mô hình. Điều này thường được gọi trong tài liệu là batch hoặc task. Công thức này đủ tổng quát để được sử dụng trong nhiều bối cảnh học liên tục, chẳng hạn như học liên tục có giám sát, tăng cường hoặc không giám sát. Avalanche cung cấp một tập hợp trừu tượng tổng quát không áp đặt bất kỳ ràng buộc cụ thể nào về nội dung của các trải nghiệm. Ví dụ, trong một chế độ huấn luyện có giám sát, mỗi trải nghiệm học ei có thể được xem như một tập hợp các bộ ba hxi; yi; tii, trong đó xi và yi đại diện cho một đầu vào và mục tiêu tương ứng của nó, trong khi ti là nhãn nhiệm vụ, có thể có hoặc không có sẵn.

Trong quá trình huấn luyện, một thuật toán học liên tục ACL xử lý các trải nghiệm tuần tự và sử dụng chúng để cập nhật mô hình và trạng thái nội tại của nó. Trong Avalanche, mỗi thuật toán có một chế độ huấn luyện, được sử dụng để cập nhật mô hình, và một chế độ đánh giá, có thể được sử dụng để xử lý các luồng trải nghiệm cho mục đích kiểm tra.

Khung học liên tục chúng tôi đề xuất có thể được chính thức hóa như sau.

Định nghĩa (Khung Học Liên tục). Một thuật toán Học liên tục ACL được mong đợi cập nhật trạng thái nội tại của nó (ví dụ: mô hình nội tại M hoặc các cấu trúc dữ liệu khác) dựa trên việc tiếp xúc tuần tự với một luồng không ổn định các trải nghiệm (e1; : : : ; e n). Mục tiêu của ACL là cải thiện hiệu suất của nó trên một tập hợp các chỉ số (p1; : : : ; p m) như được đánh giá trên một luồng kiểm tra các trải nghiệm (et1; : : : ; etn).

4. Các Module Chính
Thư viện được tổ chức thành năm module chính: Benchmarks (Mục 4.1), Training (Mục 4.2), Evaluation (Mục 4.3), Models (Mục 4.5) và Logging (Mục 4.4). Bảng 1 tóm tắt các tính năng được cung cấp bởi Avalanche ở giai đoạn phát triển hiện tại. Trong Hình 1, một biểu diễn hoạt động của các module thư viện và sự tương tác của chúng trong khung tham chiếu đã nêu được hiển thị.

Hình 2: Ví dụ về một luồng được tạo trong Avalanche, bao gồm năm trải nghiệm, triển khai benchmark SplitMNIST phổ biến [57]. Khi truy cập trải nghiệm e3, thuật toán ACL không có quyền truy cập vào các trải nghiệm trước đó hoặc tương lai.

4.1. Benchmarks
Học liên tục xoay quanh ý tưởng xử lý một luồng không ổn định các trải nghiệm. Một ví dụ luồng từ benchmark SplitMNIST tiêu chuẩn [57] bao gồm năm trải nghiệm được hiển thị trong Hình 2. Một hệ thống mục tiêu được hỗ trợ bởi một chiến lược học liên tục được yêu cầu học từ các trải nghiệm (ví dụ: bằng cách xem xét các lớp bổ sung trong cài đặt tăng dần lớp [36]) để cải thiện hiệu suất hoặc mở rộng tập hợp khả năng của nó. Điều này có nghĩa là thành phần phụ trách tạo ra luồng dữ liệu thường là khối xây dựng đầu tiên của một thí nghiệm học liên tục. Không có gì ngạc nhiên khi một lượng thời gian đáng kể được dành để định nghĩa và triển khai module tải dữ liệu. Module benchmarks cung cấp một bộ công cụ mạnh mẽ mà người ta có thể tận dụng để đơn giản hóa đáng kể quá trình này.

Thuật ngữ benchmark được sử dụng trong Avalanche để mô tả một công thức chỉ định cách luồng dữ liệu được tạo bằng cách định nghĩa (các) dataset gốc, nội dung của luồng, số lượng ví dụ, nhãn nhiệm vụ và ranh giới [2], v.v. Khi định nghĩa những yếu tố này, một mức độ tự do nhất định được giữ lại để cho phép có được các instance benchmark khác nhau. Ví dụ, các cá thể khác nhau của benchmark SplitMNIST [57] có thể được thu được bằng cách thiết lập các phép gán lớp khác nhau. Ngoài ra, các instance riêng biệt của benchmark PermutedMNIST [14] có thể được thu được bằng cách chọn các hoán vị pixel khác nhau.

Module benchmarks được thiết kế với ý tưởng cung cấp một bộ loader có sẵn mở rộng bao gồm các benchmark phổ biến nhất (tức là SplitCIFAR [45], PermutedMNIST [14], v.v.) thông qua submodule classic. Một ví dụ đơn giản minh họa cách sử dụng benchmark "SplitMNIST" [57] được hiển thị trong Hình 3. Hơn nữa, một loạt công cụ rộng lớn có sẵn cho phép tạo ra các benchmark tùy chỉnh. Mục tiêu là cung cấp hỗ trợ đầy đủ cho các nhà nghiên cứu triển khai các benchmark không dễ dàng phù hợp với các danh mục hiện có.

Hầu hết các benchmark có sẵn dựa trên

3

--- TRANG 3 ---
Các tính năng được hỗ trợ
Benchmarks Split/Permuted/Rotated MNIST [34], Split Fashion Mnist [13], Split Cifar10/100/110 [45, 35],
Split CUB200, Split ImageNet [45], Split TinyImageNet [9], Split/Permuted/Rotated Omniglot [49],
CORe50 [32], OpenLORIS [51], Stream51 [47].
Kịch bản Multi Task [28], Single Incremental Task [28], Multi Incremental Task [28], Class incremental [46, 54],
Domain Incremental [54], Task Incremental [54], Task-agnostic, Online, New Instances, New Classes,
New Instances và Classes.
Chiến lược Naive (Finetuning), CWR* [33], Replay, GDumb [43], Cumulative, LwF [29], GEM [34], A-GEM [6],
EWC [26], Synaptic Intelligence [57], AR1 [35], Joint Training.
Chỉ số Accuracy, Loss (do người dùng chỉ định), Confusion Matrix, Forgetting, CPU Usage, GPU usage, RAM usage,
Disk Usage, Timing, Multiply, và Accumulate [22, 11].
Logger Text Logger, Interactive Logger, Tensorboard Logger [1], Weights and Biases (W&B) Logger [3] (đang
tiến hành).
Bảng 1: Các tính năng được hỗ trợ của Avalanche cho bản phát hành Alpha (v0.0.1).

Classic Benchmarks
1benchmark_instance = SplitMNIST(
2 n_experiences=5, seed=1)
3 # Các tham số hữu ích khác
4 # return_task_id=False/True
5 # fixed_class_order=[5, 0, 9, ...]
Hình 3: Khởi tạo đơn giản của một benchmark học liên tục Classic.

triển khai dataset được cung cấp bởi thư viện torchvision. Một triển khai phù hợp được cung cấp cho các dataset khác (như CORe50 [32], Stream-51 [47] và OpenLORIS [51]). Quá trình chuẩn bị benchmark và tải dữ liệu có thể xử lý liền mạch các benchmark sử dụng nhiều bộ nhớ, như Split-ImageNet [45], mà không cần tải toàn bộ dataset vào bộ nhớ trước.

Hơn nữa, module benchmarks hoàn toàn độc lập, có nghĩa là nó có thể được sử dụng độc lập với phần còn lại của Avalanche.

Tạo benchmarks Module benchmarks trưng bày một API thống nhất giúp dễ dàng định nghĩa một benchmark học liên tục mới.

Gói classic lưu trữ một tập hợp ngày càng tăng các benchmark phổ biến và được mong đợi sẽ bao gồm các yêu cầu sử dụng của đại đa số các nhà nghiên cứu. Tuy nhiên, có những tình huống mà việc triển khai một benchmark mới là cần thiết. Avalanche cung cấp một API linh hoạt có thể được sử dụng để dễ dàng xử lý tình huống này.

Bắt đầu từ API cấp cao hơn, Avalanche cung cấp hỗ trợ rõ ràng cho việc tạo các benchmark phù hợp với một trong các kịch bản sẵn sàng sử dụng. Khái niệm kịch bản hơi khác với 'benchmark' vì nó mô tả một công thức tổng quát hơn độc lập với một dataset cụ thể. Nếu benchmark sắp được triển khai phù hợp hoặc trong kịch bản New Instances hoặc New Classes [35], người ta có thể cân nhắc sử dụng một trong các bộ tạo cụ thể ncscenario hoặc niscenario. Cả hai bộ tạo đều lấy một cặp dataset train và test và tạo ra một instance benchmark. Bộ tạo New Classes chia tất cả các lớp có sẵn thành một số tập con bằng số lượng trải nghiệm cần thiết. Các mẫu sau đó được phân bổ cho mỗi trải nghiệm bằng cách gán tất cả các mẫu của các lớp được chọn. Điều này có nghĩa là bộ tạo New Classes có thể được sử dụng như một cơ sở để thiết lập các benchmark học tăng dần Task hoặc Class [54]. Bộ tạo New Instances chia tập huấn luyện gốc bằng cách tạo các trải nghiệm chứa số lượng mẫu bằng nhau sử dụng lược đồ phân bổ ngẫu nhiên. Việc sử dụng chính được dự định cho bộ tạo này là giúp thiết lập các benchmark học tăng dần Domain [54]. Hầu hết các benchmark classic dựa trên những bộ tạo này. Hình 4 hiển thị một ví dụ đơn giản về việc sử dụng ncscenario.

Bộ tạo Benchmarks
1# Gần như tất cả dataset từ torchvision
2# đều được hỗ trợ
3
4mnist_train = MNIST('/thư_mục./mnist', train=True)
5mnist_test = MNIST('/thư_mục./mnist', train=False)
6benchmark_instance = nc_scenario(
7 train_dataset=mnist_train,
8 test_dataset=mnist_test,
9 n_experiences=n_experiences,
10 task_labels=True/False)
Hình 4: Ví dụ về bộ tạo benchmark "New Classes" trên dataset MNIST.

Nếu benchmark không phù hợp với một kịch bản được định nghĩa trước, một bộ tạo generic có thể được sử dụng. Hiện tại, Avalanche cho phép người dùng tạo các instance benchmark từ danh sách

4

--- TRANG 4 ---
các file, filelist kiểu Caffe [23], danh sách các dataset PyTorch, hoặc thậm chí trực tiếp từ Tensor. Chúng tôi mong đợi rằng số lượng bộ tạo generic sẽ tăng nhanh chóng để bao gồm các trường hợp sử dụng phổ biến nhất và cho phép tính linh hoạt tối đa.

Luồng và Trải nghiệm Không phải tất cả các benchmark học liên tục đều giới hạn bản thân trong việc mô tả một luồng dữ liệu duy nhất. Nhiều người xem xét một luồng ngoài phân phối, một luồng xác thực và có thể nhiều luồng tùy ý khác, mỗi luồng liên kết với một ngữ nghĩa khác nhau. Ví dụ, [6] đề xuất một benchmark nơi một luồng dữ liệu riêng biệt được sử dụng cho cross-validation, trong khi [47] định nghĩa một luồng ngoài phân phối được sử dụng để đánh giá khả năng phát hiện tính mới của mô hình.

Được thúc đẩy bởi nhận xét này, chúng tôi quyết định mô hình hóa các instance benchmark như một thành phần của các luồng trải nghiệm. Lựa chọn này có hai tác động tích cực lên API kết quả. Thứ nhất, cách các luồng và trải nghiệm có thể được truy cập được chia sẻ qua tất cả các instance benchmark. Thứ hai, mô hình hóa các instance benchmark này không ép buộc bất kỳ lược đồ định kiến nào lên các nhà nghiên cứu. Avalanche để lại các khía cạnh ngữ nghĩa liên quan đến định nghĩa và sử dụng mỗi luồng cho người tạo benchmark.

Một ví dụ đơn giản cho thấy tính linh hoạt của lựa chọn thiết kế này liên quan đến luồng test: để cho phép đánh giá phù hợp một chiến lược học liên tục, các benchmark không chỉ cần mô tả luồng trải nghiệm huấn luyện mà còn cần mô tả đúng một giao thức kiểm tra. Giao thức như vậy, lần lượt, dựa trên một hoặc nhiều dataset test mà trên đó các chỉ số phù hợp có thể được tính toán. Trong nhiều trường hợp, dữ liệu test có thể cần được cấu trúc thành một chuỗi 'trải nghiệm test', tương tự như những gì xảy ra với luồng dữ liệu huấn luyện. Ví dụ, trong học tăng dần Class, tập test có thể được chia thành các trải nghiệm khác nhau, mỗi trải nghiệm chỉ chứa các mẫu test liên quan đến các lớp trong trải nghiệm huấn luyện tương ứng.

Avalanche hiện hỗ trợ hai luồng khác nhau: train và test, trong khi hỗ trợ cho các luồng tùy ý (ví dụ: luồng ngoài phân phối) sẽ được triển khai trong tương lai gần.

Mỗi trải nghiệm có thể được thu được bằng cách lặp qua một trong các luồng có sẵn. Hình 5 hiển thị cách, bắt đầu từ một instance benchmark, các luồng có thể được truy xuất và sử dụng. Mỗi trải nghiệm mang một dataset PyTorch, (các) nhãn nhiệm vụ và thông tin hữu ích khác cụ thể cho benchmark có thể được sử dụng cho introspection. Một trải nghiệm cũng mang một định danh số định nghĩa vị trí của nó trong luồng gốc. Thực tế, các trải nghiệm trong một luồng cũng có thể được truy cập bằng chỉ số. Chức năng này giúp dễ dàng ghép các trải nghiệm liên quan từ các luồng khác nhau.

Nhãn Nhiệm vụ và Danh pháp Mọi cơ chế, khía cạnh nội tại, tên hàm và lớp trong module benchmarks

Vòng lặp Huấn luyện Chính
1train_stream = benchmark_instance.train_stream
2test_stream = benchmark_instance.test_stream
3
4for idx, experience in enumerate(train_stream):
5 dataset = experience.dataset
6
7 print('Dataset huấn luyện chứa',
8 len(dataset), 'mẫu')
9
10 for x, y, t in dataset:
11 ...
12
13 test_experience = test_stream[idx]
14 cumulative_test = test_stream[:idx+1]
Hình 5: Ví dụ về vòng lặp huấn luyện chính qua luồng các trải nghiệm.

được thiết kế với ý định giữ Avalanche trung lập nhất có thể đối với sự hiện diện của nhãn nhiệm vụ. Ranh giới nhiệm vụ, bộ mô tả nhiệm vụ và nhãn nhiệm vụ được sử dụng rộng rãi trong tài liệu học liên tục để định nghĩa cả khía cạnh ngữ nghĩa và thực tế của một benchmark. Tuy nhiên, ý nghĩa của những khái niệm đó thường bị mờ nhạt với định nghĩa của benchmark cụ thể mà chúng được áp dụng, khiến việc chỉ rõ rằng một cách generic để quản lý chúng trở nên khó khăn.

Dựa trên quan sát này, và do thực tế rằng việc sử dụng thông tin cụ thể cho nhiệm vụ có thể trở nên phóng khoáng hoặc tinh vi hơn trong tương lai, chúng tôi quyết định rằng Avalanche không nên ép buộc bất kỳ loại quy ước nào. Điều này có nghĩa là lựa chọn có sử dụng nhãn nhiệm vụ hay không và cách sử dụng chúng được để lại cho người dùng.

Theo ý tưởng này, lớp GenericCLScenario, là lớp chung cho tất cả các instance kịch bản, cho phép các nhà nghiên cứu gán nhãn nhiệm vụ ở mức độ chi tiết mẫu, do đó cho phép các trải nghiệm với không hoặc nhiều nhãn nhiệm vụ. Chúng tôi cho rằng đây là lựa chọn tự nhiên nhất cho Avalanche: chúng tôi tin rằng một thư viện học liên tục không nên ràng buộc các nhà nghiên cứu bằng cách áp đặt một quan điểm nhất định về lĩnh vực này lên họ. Thay vào đó, ý tưởng cho phép người dùng tạo ra các thiết lập phức tạp một cách đơn giản, mà không ép buộc một cách giải thích chủ quan, có lẽ sẽ chứng tỏ mạnh mẽ hơn khi lĩnh vực tiếp tục phát triển.

4.2. Training
Module training triển khai cả các chiến lược học liên tục phổ biến và một tập hợp trừu tượng giúp người dùng dễ dàng triển khai các thuật toán học liên tục tùy chỉnh. Mỗi chiến lược trong Avalanche triển khai một phương thức cho huấn luyện (train) và một phương thức cho đánh giá (eval), có thể hoạt động trên các trải nghiệm đơn lẻ hoặc trên toàn bộ

5

--- TRANG 5 ---
các lát của luồng dữ liệu. Hiện tại, Avalanche cung cấp 11 chiến lược học liên tục (với nhiều hơn nữa sắp tới), có thể được sử dụng để huấn luyện baseline trong vài dòng code, như được hiển thị trong Hình 6. Xem Bảng 1 để có danh sách đầy đủ các chiến lược có sẵn.

Chiến lược Huấn luyện
1strategy = Replay(model, optimizer,
2 criterion, mem_size)
3for train_exp in scenario.train_stream:
4 strategy.train(train_exp)
5 strategy.eval(scenario.test_stream)
Hình 6: Khởi tạo đơn giản của một chiến lược đã có sẵn trong Avalanche.

Vòng lặp Training/Eval Trong Avalanche, các chiến lược học liên tục kế thừa BaseStrategy, cung cấp các vòng lặp huấn luyện và đánh giá generic. Những vòng lặp này có thể được mở rộng và điều chỉnh bởi mỗi chiến lược. Ví dụ, JointTraining triển khai huấn luyện offline bằng cách ghép nối toàn bộ luồng dữ liệu trong một dataset duy nhất và chỉ huấn luyện một lần. Mã giả trong Hình 7 hiển thị một phần của vòng lặp BaseStrategy.train (eval có cấu trúc tương tự).

Cấu trúc Huấn luyện
1def train(experiences):
2 before_training()
3 for exp in experiences:
4 train_exp(exp)
5 after_training()
6
7def train_exp(exp):
8 adapt_train_dataset()
9 make_train_dataloader()
10 before_training_exp()
11 for epoch in range(n_epochs):
12 before_training_epoch()
13 training_epoch()
14 after_training_epoch()
15 after_training_exp()
Hình 7: Cấu trúc huấn luyện chính, khung xương của lớp BaseStrategy.

Phía dưới, BaseStrategy xử lý hầu hết code boilerplate. Các vòng lặp generic có thể xử lý liền mạch các kịch bản học liên tục phổ biến, độc lập với các khác biệt như sự hiện diện hoặc không hiện diện của nhãn nhiệm vụ.

Hệ thống Plugin BaseStrategy cung cấp một cơ chế callback đơn giản. Điều này được sử dụng bởi các chiến lược, chỉ số và logger để tương tác với vòng lặp huấn luyện và thực thi code của chúng tại các điểm chính xác sử dụng một giao diện đơn giản và cung cấp một giao diện dễ dàng để triển khai các chiến lược mới bằng cách thêm code tùy chỉnh vào các vòng lặp generic. BaseStrategy cung cấp trạng thái toàn cục (mini-batch hiện tại, logits, loss, ...) cho các plugin phù hợp để chúng có thể truy cập tất cả thông tin họ cần. Trong thực tế, hầu hết các chiến lược trong Avalanche được triển khai thông qua plugin. Cách tiếp cận này có nhiều ưu điểm so với một vòng lặp huấn luyện tùy chỉnh. Thứ nhất, khả năng đọc của code được tăng cường vì hầu hết các chiến lược chỉ cần chỉ định một vài phương thức. Thứ hai, điều này cho phép nhiều chiến lược được kết hợp với nhau. Ví dụ, chúng ta có thể định nghĩa một chiến lược lai sử dụng Elastic Weight Consolidation (EWC) [26] và replay sử dụng đoạn code được hiển thị trong Hình 8.

Chiến lược Lai
1replay = ReplayPlugin(mem_size)
2ewc = EWCPlugin(ewc_lambda)
3strategy = BaseStrategy(
4 model, optimizer,
5 criterion, mem_size,
6 plugins=[replay, ewc])
Hình 8: Ví dụ về khởi tạo tức thời các chiến lược lai thông qua Plugin.

4.3. Evaluation
Hiệu suất của một thuật toán CL nên được đánh giá bằng cách giám sát nhiều khía cạnh của tính toán [28]. Module evaluation cung cấp một tập hợp rộng lớn các chỉ số để đánh giá thí nghiệm.

Nguyên tắc thiết kế của Avalanche là tách biệt các vấn đề về cái gì cần giám sát và cách giám sát nó: module evaluation cung cấp hỗ trợ cho vấn đề trước thông qua các chỉ số, trong khi module logging đáp ứng vấn đề sau (Mục 4.4). Các chỉ số không chỉ định định dạng nào mà đầu ra của chúng nên được hiển thị, trong khi các logger không thay đổi logic chỉ số. Các chỉ số có thể hoạt động ngay cả khi không có logger: các phương thức train và eval của chiến lược trả về một từ điển với tất cả các chỉ số được ghi trong thí nghiệm.

Ít dòng code là đủ để giám sát một tập hợp rộng lớn các chỉ số: accuracy, loss, catastrophic forgetting, confusion matrix, timing, ram/disk/CPU/GPU usage và Multiply and Accumulate [22] (đo chi phí tính toán của quá trình forward pass của mô hình về mặt các phép toán dấu phẩy động). Mỗi chỉ số đi kèm với một lớp độc lập và một tập hợp các lớp plugin nhằm phát ra các giá trị chỉ số tại các thời điểm cụ thể trong quá trình huấn luyện và đánh giá.

6

--- TRANG 6 ---
Chỉ số Độc lập Các chỉ số độc lập được thiết kế để sử dụng độc lập với tất cả các chức năng Avalanche. Mỗi chỉ số có thể được khởi tạo như một đối tượng Python đơn giản. Chỉ số sẽ giữ một trạng thái nội tại để lưu trữ các giá trị chỉ số. Trạng thái có thể được reset, cập nhật hoặc trả về cho người dùng bằng cách gọi các phương thức reset, update và result tương ứng.

Chỉ số Plugin Các chỉ số plugin được thiết kế để dễ dàng tích hợp vào các vòng lặp huấn luyện và đánh giá của Avalanche. Các chỉ số plugin phát ra một đường cong bao gồm nhiều giá trị tại các thời điểm khác nhau. Thường thì, các chỉ số plugin phát ra giá trị sau mỗi lần lặp huấn luyện, epoch huấn luyện, trải nghiệm đánh giá hoặc ở cuối toàn bộ luồng đánh giá. Ví dụ, EpochAccuracy báo cáo độ chính xác qua tất cả các epoch huấn luyện, trong khi ExperienceLoss tạo ra nhiều đường cong bằng số lượng trải nghiệm. Mỗi đường cong giám sát độ chính xác đánh giá của một trải nghiệm ở cuối mỗi vòng lặp huấn luyện.

Avalanche khuyến nghị sử dụng các hàm helper đã được triển khai để đơn giản hóa việc tạo mỗi chỉ số plugin. Đầu ra của những hàm này có thể được truyền như tham số trực tiếp đến EvaluationPlugin.

Plugin Đánh giá EvaluationPlugin là thành phần chịu trách nhiệm điều phối cả chỉ số plugin và logger. Vai trò của nó là thu thập đầu ra chỉ số và chuyển tiếp chúng đến các logger trong quá trình huấn luyện và đánh giá.

Tất cả những gì người dùng phải làm để theo dõi một thí nghiệm là cung cấp cho đối tượng chiến lược một instance của EvaluationPlugin với các chỉ số và logger mục tiêu như tham số. Hình 9 hiển thị cách sử dụng plugin đánh giá và các hàm helper chỉ số.

Nỗ lực của Avalanche nhằm giám sát các khía cạnh khác nhau của hiệu suất nhằm mục đích cho phép đánh giá thí nghiệm rộng hơn, quá thường tập trung chỉ vào việc quên kiến thức trước đó [11].

4.4. Logging
Ngày nay, các tiện ích logging là cơ bản để giám sát theo thời gian thực hành vi của một thí nghiệm đang diễn ra (có thể kéo dài từ vài phút đến vài ngày).

Module logging của Avalanche chịu trách nhiệm hiển thị cho người dùng kết quả của mỗi chỉ số plugin trong các giai đoạn thí nghiệm khác nhau. Avalanche cung cấp ba logger khác nhau: TextLogger, InteractiveLogger và TensorboardLogger [1]. Chúng cung cấp báo cáo trên file văn bản, đầu ra tiêu chuẩn và Tensorboard, tương ứng. Ngay khi một chỉ số phát ra một giá trị, Text Logger in tên chỉ số đầy đủ theo sau bởi giá trị của nó trong file đích. Xem Hình 10 để có ví dụ về đầu ra Tensorboard.

Plugin Đánh giá
1text_logger = TextLogger(
2 open('out.txt','w'))
3interactive_logger = InteractiveLogger()
4tensorboard_logger = TensorboardLogger()
5
6eval_plugin = EvaluationPlugin(
7 accuracy_metrics(experience=True),
8 loss_metrics(minibatch=True,
9 epoch=True, stream=True),
10 ExperienceForgetting(),
11 StreamConfusionMatrix(),
12 cpu_usage_metrics(stream=True),
13 timing_metrics(minibatch=True),
14 ram_usage_metrics(epoch=True),
15 gpu_usage_metrics(gpu_id, epoch=True),
16 disk_usage_metrics(epoch=True),
17 MAC_metrics(minibatch=True),
18
19 loggers=[interactive_logger,
20 text_logger,
21 tensorboard_logger])
Hình 9: Ví dụ khởi tạo đối tượng plugin đánh giá Avalanche (hoặc evaluator).

InteractiveLogger báo cáo cùng đầu ra như TextLogger, nhưng nó cũng sử dụng gói tqdm² để hiển thị thanh tiến trình trong quá trình huấn luyện và đánh giá. TensorboardLogger có thể hiển thị hình ảnh và đầu ra phức tạp hơn, không thể được in một cách phù hợp trên đầu ra tiêu chuẩn hoặc file văn bản. Chúng tôi cũng đang làm việc trên việc tích hợp logger Weights and Biases [3], dự kiến sẽ được phát hành sớm.

Tích hợp các logger vào cả vòng lặp huấn luyện và đánh giá đều đơn giản. Một khi được tạo, các logger phải được truyền đến EvaluationPlugin, sẽ chịu trách nhiệm chuyển hướng đầu ra chỉ số đến mỗi logger trong quá trình thí nghiệm. Xem Hình 9 để có ví dụ về tạo logger.

Người dùng có thể dễ dàng thiết kế logger riêng của họ bằng cách mở rộng lớp StrategyLogger, cung cấp giao diện cần thiết để tương tác với EvaluationPlugin.

4.5. Models
Module models của Avalanche cung cấp một tập hợp các kiến trúc học máy đơn giản sẵn sàng được sử dụng trong thí nghiệm. Cụ thể, module chứa các phiên bản của mạng neural feedforward và convolutional và một phiên bản được huấn luyện trước của MobileNet (v1) [18]. Mục đích chính của những mô hình này là để người dùng tập trung vào các tính năng Avalanche, thay vì viết các dòng code để xây dựng một kiến trúc cụ thể. Chúng tôi dự định mở rộng hỗ trợ mô hình của mình với các kiến trúc tiên tiến hơn, cũng được thiết kế riêng cho các ứng dụng CL cụ thể.

²https://tqdm.github.io

7

--- TRANG 7 ---
(a) Độ chính xác qua các epoch trong quá trình huấn luyện
(b) Loss qua các epoch trong quá trình huấn luyện
(c) Độ chính xác qua trải nghiệm đầu tiên qua 5 trải nghiệm huấn luyện
(d) Ma trận Nhầm lẫn
Hình 10: Ví dụ đầu ra Tensorboard Logger.

5. Các Công trình Liên quan
Khả năng tái tạo là một trong những nguyên tắc chính mà Avalanche dựa trên đó. Các thí nghiệm trong lĩnh vực học liên tục thường khó tái tạo, do các triển khai khác nhau của giao thức, benchmark và chiến lược bởi các tác giả khác nhau. Vấn đề khả năng tái tạo không đủ này không giới hạn ở học liên tục. Toàn bộ cộng đồng trí tuệ nhân tạo đều bị ảnh hưởng; một số tác giả gần đây đã thảo luận một số giải pháp có thể cho vấn đề [16, 42, 44].

Sự xuất hiện của các thư viện học máy (và học sâu), chủ yếu là TensorFlow [1] và PyTorch [39] đã một phần giảm thiểu vấn đề tái tạo. Việc sử dụng những thư viện này đảm bảo một triển khai tiêu chuẩn của nhiều khối xây dựng học máy, giảm sự mơ hồ do các triển khai riêng biệt và khác nhau của các khái niệm cơ bản.

Trong thời gian gần đây, cộng đồng học liên tục đã nỗ lực nhiều để giải quyết những vấn đề này, bằng cách cung cấp code và thư viện nhằm tăng khả năng tái tạo của các thí nghiệm học liên tục [9, 20, 36, 50, 53, 54]. Một mặt, những nỗ lực đầu tiên này thiếu tính tổng quát và nhất quán của Avalanche, đặc biệt liên quan đến việc tạo ra các benchmark khác nhau và phức tạp, và sự hỗ trợ liên tục của một cộng đồng lớn. Mặt khác, tuy nhiên, chúng chứng minh sự quan tâm ngày càng tăng của toàn bộ cộng đồng đối với những vấn đề này.

Một lĩnh vực khác ngoài học liên tục gần đây đã chứng kiến sự gia tăng của các thư viện và công cụ tương tự về tinh thần với Avalanche là học tăng cường (RL). Một trong những thư viện benchmark RL phổ biến nhất như vậy là OpenAI Gym [4], trong đó có sẵn vô số môi trường RL khác nhau. Một thư viện tương tự là ViZDoom [56], trong đó một agent chơi trò chơi máy tính nổi tiếng Doom. Các dự án liên quan khác trong lĩnh vực học tăng cường là Dopamine [5], tập trung vào sự đơn giản và tạo mẫu dễ dàng, và dự án Malmo [24], dựa trên trò chơi Minecraft nổi tiếng.

Tuy nhiên, nhiều thư viện này chỉ tập trung vào tương tác của agent với môi trường (trong lĩnh vực học liên tục, có thể được dịch thành định nghĩa benchmark và kịch bản), không cung cấp hoặc chỉ cung cấp một vài chiến lược cơ bản hoặc baseline. Trong lĩnh vực học tăng cường, vấn đề này được giải quyết bởi các thư viện khác bao gồm các triển khai tiêu chuẩn của các thuật toán baseline, như OpenAI baselines [10] và stable baselines [17].

Một ví dụ nổi bật khác về bộ sưu tập các chiến lược huấn luyện baseline và mô hình được huấn luyện trước là thư viện transformers xử lý ngôn ngữ tự nhiên của Hugging Face [55]. Nhiều khái niệm cơ bản mà Avalanche dựa trên đó (ví dụ: plugin, logger, benchmark) cũng có thể được tìm thấy trong các thư viện học máy tổng quát hơn như PyTorch Lightning [12] và fastai [19]. Thực vậy, Avalanche dựa trên cùng nguyên tắc tính toàn diện và nhất quán, do đó không chỉ có benchmark mà còn có chiến lược và chỉ số được bao gồm. Điều này thúc đẩy tính nhất quán qua các phần khác nhau của thư viện và đơn giản hóa tương tác giữa các module khác nhau. Hơn nữa, Avalanche có thể được tích hợp với các thư viện học sâu được đề cập, nhờ vào sự tương đồng về nguyên tắc thiết kế và cấu trúc code.

Một vấn đề quan trọng khác trong nghiên cứu là việc ghi chép thí nghiệm. Có một công cụ theo dõi mọi lần chạy duy nhất (siêu tham số, mô hình được sử dụng, thuật toán được sử dụng, biến thể, đầu vào cho mô hình, v.v.) là rất quan trọng cho khả năng tái tạo, đặc biệt khi các chiến lược như grid search được áp dụng. Như đã thảo luận trong Mục 4.4, Avalanche đã triển khai một logging chi tiết và chính xác, cho phép hiển thị và lưu kết quả của các thí nghiệm khác nhau. Hơn nữa, Avalanche có thể dễ dàng được tích hợp với các thư viện độc lập được phát triển cụ thể cho việc ghi chép và hiển thị thí nghiệm, như Sacred [27] hoặc Weights and Biases (wandb) [3].

6. Kết luận và Công việc Tương lai
Trong thập kỷ qua, chúng ta đã chứng kiến một nỗ lực đáng kể nhằm làm cho nghiên cứu trong học máy trở nên minh bạch, có thể tái tạo và mở hơn. Tuy nhiên, mặc dù các bài báo nghiên cứu ngày càng được đi kèm với các codebase được lưu trữ công khai, việc chạy và tích hợp phần mềm như vậy vào các môi trường thường khác với môi trường mà nó được thiết kế ban đầu thường khó khăn. Điều này không chỉ cản trở khả năng tái tạo mà còn ức chế khả năng mở rộng, vì mỗi bài báo nghiên cứu cuối cùng tạo ra triển khai riêng của mình gần như từ đầu.

Avalanche nhằm mục đích cung cấp một thư viện mạch lạc, hoàn chỉnh, dễ mở rộng cho nghiên cứu và phát triển học liên tục; một điểm tham chiếu vững chắc và tài nguyên chia sẻ cho các nhà nghiên cứu và thực hành làm việc về học liên tục và các lĩnh vực liên quan.

Như được báo cáo trong Bảng 1, phiên bản Avalanche Alpha hiện tại tập trung vào học có giám sát liên tục cho các nhiệm vụ thị giác, vì một lượng đáng kể nghiên cứu học sâu trong lĩnh vực này được thiết kế và đánh giá trong bối cảnh này [15]. Tuy nhiên, vì Avalanche là một nỗ lực được cộng đồng điều hành, chúng tôi dự định trong cả ngắn hạn và trung hạn hỗ trợ việc tích hợp các mô hình học bổ sung (ví dụ: Học Tăng cường hoặc Học Không giám sát), loại nhiệm vụ (ví dụ: Phát hiện, Phân đoạn) và bối cảnh ứng dụng (ví dụ: Xử lý Ngôn ngữ Tự nhiên, Nhận dạng Giọng nói), tùy thuộc vào nhu cầu và ưu tiên của cộng đồng nghiên cứu.

Chúng tôi hy vọng rằng thư viện này, như một avalanche mạnh mẽ, có thể kích hoạt một vòng lặp tăng cường tích cực trong cộng đồng của chúng ta, thúc đẩy nó chuyển hướng sang một môi trường nghiên cứu hợp tác và bao gồm hơn và giúp tất cả chúng ta cùng nhau giải quyết những thách thức nghiên cứu lớn được trình bày bởi một chủ đề tiên phong như học liên tục.

Tài liệu tham khảo
[1] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, và Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Phần mềm có sẵn từ tensorflow.org. 2, 4, 7, 8

[2] Rahaf Aljundi, Klaas Kelchtermans, và Tinne Tuytelaars. Task-Free Continual Learning. Trong The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. 3

[3] Lukas Biewald. Experiment tracking with weights and biases, 2020. Phần mềm có sẵn từ wandb.com. 4, 7, 8

[4] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, và Wojciech Zaremba. Openai gym, 2016. 8

[5] Pablo Samuel Castro, Subhodeep Moitra, Carles Gelada, Saurabh Kumar, và Marc G. Bellemare. Dopamine: A Research Framework for Deep Reinforcement Learning. arXiv preprint arXiv:1812.06110, 2018. 8

[6] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. Efficient Lifelong Learning with A-GEM. Trong ICLR, 2019. 4, 5

[7] Zhiyuan Chen và Bing Liu. Lifelong Machine Learning, Second Edition, tập 12. Morgan & Claypool Publishers LLC, 2018. 1

[8] Andrea Cossu, Antonio Carta, Vincenzo Lomonaco, và Davide Bacciu. Continual learning for recurrent neural networks: a review and empirical evaluation. arXiv preprint arXiv:2103.07492, 2021. 1

[9] Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Greg Slabaugh, và Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021. 1, 4, 8

[10] Prafulla Dhariwal, Christopher Hesse, Oleg Klimov, Alex Nichol, Matthias Plappert, Alec Radford, John Schulman, Szymon Sidor, Yuhuai Wu, và Peter Zhokhov. Openai baselines. https://github.com/openai/baselines, 2017. 8

[11] Natalia Díaz-Rodríguez, Vincenzo Lomonaco, David Filliat, và Davide Maltoni. Don't forget, there is more than forgetting: New metrics for Continual Learning. arXiv, 2018. 4, 7

[12] WA Falcon và .al. Pytorch lightning. GitHub. Ghi chú: https://github.com/PyTorchLightning/pytorch-lightning, 3, 2019. 8

[13] Sebastian Farquhar và Yarin Gal. A Unifying Bayesian View of Continual Learning. Trong NeurIPS Bayesian Deep Learning Workshop, 2018. 4

[14] Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, và Yoshua Bengio. An empirical investigation of catastrophic forgetting in gradient-based neural networks. arXiv preprint arXiv:1312.6211, 2013. 3

[15] Raia Hadsell, Dushyant Rao, Andrei A Rusu, và Razvan Pascanu. Embracing Change: Continual Learning in Deep Neural Networks. Trends in Cognitive Sciences, 2020. 1, 9

[16] Matthew Hartley và Tjelvar S.G. Olsson. dtoolai: Reproducibility for deep learning. Patterns, 1(5):100073, 2020. 8

[17] Ashley Hill, Antonin Raffin, Maximilian Ernestus, Adam Gleave, Anssi Kanervisto, Rene Traore, Prafulla Dhariwal, Christopher Hesse, Oleg Klimov, Alex Nichol, Matthias Plappert, Alec Radford, John Schulman, Szymon Sidor, và Yuhuai Wu. Stable baselines. https://github.com/hill-a/stable-baselines, 2018. 8

[18] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, và Hartwig Adam. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arXiv:1704.04861 [cs], 2017. 7

[19] Jeremy Howard và Sylvain Gugger. Fastai: A layered api for deep learning. Information, 11(2):108, 2020. 8

[20] Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, và Zsolt Kira. Re-evaluating continual learning scenarios: A categorization and case for strong baselines. Trong NeurIPS Continual learning Workshop, 2018. 8

[21] Matthew Hutson. Artificial intelligence faces reproducibility crisis, 2018. 2

[22] C. Jeangoudoux và C. Lauter. A Correctly Rounded Mixed-Radix Fused-Multiply-Add. Trong 2018 IEEE 25th Symposium on Computer Arithmetic (ARITH), trang 21–28, 2018. 4, 6

9

--- TRANG 8 ---
[23] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, và Trevor Darrell. Caffe: Convolutional architecture for fast feature embedding. Trong Proceedings of the 22nd ACM international conference on Multimedia, trang 675–678, 2014. 5

[24] Matthew Johnson, Katja Hofmann, T. Hutton, và D. Bignell. The malmo platform for artificial intelligence experimentation. Trong IJCAI, 2016. 8

[25] Khimya Khetarpal, Matthew Riemer, Irina Rish, và Doina Precup. Towards continual reinforcement learning: A review and perspectives. arXiv preprint arXiv:2012.13490, 2020. 1

[26] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, và Raia Hadsell. Overcoming catastrophic forgetting in neural networks. PNAS, 114(13):3521–3526, 2017. 4, 6

[27] Klaus Greff, Aaron Klein, Martin Chovanec, Frank Hutter, và Jürgen Schmidhuber. The Sacred Infrastructure for Computational Research. Trong Katy Huff, David Lippa, Dillon Niederhut, và M Pacer, biên tập, Proceedings of the 16th Python in Science Conference, trang 49 – 56, 2017. 8

[28] Timothée Lesort, Vincenzo Lomonaco, Andrei Stoian, Davide Maltoni, David Filliat, và Natalia Díaz-Rodríguez. Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges. Information Fusion, 58:52–68, 2020. 1, 4, 6

[29] Zhizhong Li và Derek Hoiem. Learning without Forgetting. Trong European Conference on Computer Vision, Springer, trang 614–629, 2016. 4

[30] Vincenzo Lomonaco. Continual Learning with Deep Architectures. PhD Thesis, alma, 2019. 1, 2

[31] Vincenzo Lomonaco, Karan Desai, Eugenio Culurciello, và Davide Maltoni. Continual Reinforcement Learning in 3D Non-Stationary Environments. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, trang 248–249, 2020. 1, 2

[32] Vincenzo Lomonaco và Davide Maltoni. CORe50: A New Dataset and Benchmark for Continuous Object Recognition. Trong Sergey Levine, Vincent Vanhoucke, và Ken Goldberg, biên tập, Proceedings of the 1st Annual Conference on Robot Learning, tập 78 của Proceedings of Machine Learning Research, trang 17–26. PMLR, 2017. 4

[33] Vincenzo Lomonaco, Davide Maltoni, và Lorenzo Pellegrini. Rehearsal-Free Continual Learning over Small Non-I.I.D. Batches. Trong CVPR Workshop on Continual Learning for Computer Vision, trang 246–247, 2020. 4

[34] David Lopez-Paz và Marc'Aurelio Ranzato. Gradient Episodic Memory for Continual Learning. Trong NIPS, 2017. 4

[35] Davide Maltoni và Vincenzo Lomonaco. Continuous Learning in Single-Incremental-Task Scenarios. Neural Networks, 116:56–73, 2019. 4

[36] Marc Masana, Xialei Liu, Bartlomiej Twardowski, Mikel Menta, Andrew D Bagdanov, và Joost van de Weijer. Class-incremental learning: survey and performance evaluation. arXiv preprint arXiv:2010.15277, 2020. 1, 3, 8

[37] German I Parisi, Ronald Kemker, Jose L Part, Christopher Kanan, và Stefan Wermter. Continual lifelong learning with neural networks: A review. Neural Networks, 113:54–71, 2019. 1

[38] German I Parisi và Vincenzo Lomonaco. Online continual learning on sequences. Trong Recent Trends in Learning From Data, trang 197–221. Springer, 2020. 1

[39] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. arXiv preprint arXiv:1912.01703, 2019. 2, 8

[40] Lorenzo Pellegrini, Gabriele Graffìeti, Vincenzo Lomonaco, và Davide Maltoni. Latent replay for real-time continual learning. Trong Proceedings of the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020. 1

[41] Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, Vincent Larivière, Alina Beygelzimer, Florence d'Alché Buc, Emily Fox, và Hugo Larochelle. Improving reproducibility in machine learning research (a report from the neurips 2019 reproducibility program). arXiv preprint arXiv:2003.12206, 2020. 2

[42] Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, V. Larivière, A. Beygelzimer, Florence d'Alché Buc, Emily Fox, và H. Larochelle. Improving reproducibility in machine learning research (a report from the neurips 2019 reproducibility program). ArXiv, abs/2003.12206, 2020. 8

[43] Ameya Prabhu, Philip H. S. Torr, và Puneet K. Dokania. GDumb: A Simple Approach that Questions Our Progress in Continual Learning. Trong Andrea Vedaldi, Horst Bischof, Thomas Brox, và Jan-Michael Frahm, biên tập, Computer Vision – ECCV 2020, Lecture Notes in Computer Science, trang 524–540, Cham, 2020. Springer International Publishing. 4

[44] Edward Raff. A step toward quantifying independently reproducible machine learning research. Trong H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, và R. Garnett, biên tập, Advances in Neural Information Processing Systems, tập 32. Curran Associates, Inc., 2019. 8

[45] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. iCaRL: Incremental Classifier and Representation Learning. Trong The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017. 3, 4

[46] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. icarl: Incremental classifier and representation learning. Trong Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, trang 2001–2010, 2017. 4

[47] Ryne Roady, Tyler L Hayes, Hitesh Vaidya, và Christopher Kanan. Stream-51: Streaming classification and novelty detection from videos. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, trang 228–229, 2020. 4, 5

10

--- TRANG 9 ---
[48] Roy Schwartz, Jesse Dodge, Noah A Smith, và Oren Etzioni. Green ai. arXiv preprint arXiv:1907.10597, 2019. 2

[49] Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, và Raia Hadsell. Progress & Compress: A scalable framework for continual learning. Trong International Conference on Machine Learning, trang 4528–4537, 2018. 4

[50] Joan Serra, Didac Suris, Marius Miron, và Alexandros Karatzoglou. Overcoming catastrophic forgetting with hard attention to the task. Trong Jennifer Dy và Andreas Krause, biên tập, Proceedings of the 35th International Conference on Machine Learning, tập 80 của Proceedings of Machine Learning Research, trang 4548–4557, Stockholmsmässan, Stockholm Sweden, 10–15 Jul 2018. PMLR. 8

[51] Qi She, Fan Feng, Xinyue Hao, Qihan Yang, Chuanlin Lan, Vincenzo Lomonaco, Xuesong Shi, Zhengwei Wang, Yao Guo, Yimin Zhang, Fei Qiao, và Rosa H M Chan. OpenLORIS-Object: A Robotic Vision Dataset and Benchmark for Lifelong Deep Learning. arXiv, trang 1–8, 2019. 4

[52] Neil C Thompson, Kristjan Greenewald, Keeheon Lee, và Gabriel F Manso. The computational limits of deep learning. arXiv preprint arXiv:2007.05558, 2020. 2

[53] Gido M van de Ven và Andreas S Tolias. Generative replay with feedback connections as a general strategy for continual learning. arXiv preprint arXiv:1809.10635, 2018. 8

[54] Gido M van de Ven và Andreas S Tolias. Three scenarios for continual learning. Trong Continual Learning Workshop NeurIPS, 2018. 2, 4, 8

[55] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander M. Rush. Transformers: State-of-the-art natural language processing. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, trang 38–45, Online, Oct. 2020. Association for Computational Linguistics. 8

[56] Marek Wydmuch, Michał Kempka, và Wojciech Jaśkowski. Vizdoom competitions: Playing doom from pixels. IEEE Transactions on Games, 2018. 8

[57] Friedemann Zenke, Ben Poole, và Surya Ganguli. Continual Learning Through Synaptic Intelligence. Trong International Conference on Machine Learning, trang 3987–3995, 2017. 3, 4

11

# 2305.11685.pdf
# ÄÆ°á»£c chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/multimodal/2305.11685.pdf
# KÃ­ch thÆ°á»›c file: 370516 bytes

===============================================
Ná»˜I DUNG FILE PDF
===============================================


--- TRANG 1 ---
TÃ¡i cháº¿ vÃ  ChÆ°ng cáº¥t: Chiáº¿n lÆ°á»£c NÃ©n ToÃ n cáº§u cho MÃ´ hÃ¬nh SSL Giá»ng nÃ³i dá»±a trÃªn Transformer vá»›i TÃ¡i sá»­ dá»¥ng Báº£n Ä‘á»“ ChÃº Ã½ vÃ  ChÆ°ng cáº¥t Che giáº¥u
Kangwook Jang1âˆ—, Sungnyun Kim2âˆ—, Se-Young Yun2, Hoirin Kim1
1TrÆ°á»ng Ká»¹ thuáº­t Äiá»‡n, KAIST
2TrÆ°á»ng Cao há»c AI, KAIST
{dnrrkdwkd12, ksn4397, yunseyoung, hoirkim }@kaist.ac.kr
TÃ³m táº¯t
CÃ¡c mÃ´ hÃ¬nh há»c tá»± giÃ¡m sÃ¡t (SSL) giá»ng nÃ³i dá»±a trÃªn Transformer, nhÆ° HuBERT, cho tháº¥y hiá»‡u suáº¥t Ä‘Ã¡ng ngáº¡c nhiÃªn trong nhiá»u tÃ¡c vá»¥ xá»­ lÃ½ giá»ng nÃ³i khÃ¡c nhau. Tuy nhiÃªn, sá»‘ lÆ°á»£ng tham sá»‘ khá»•ng lá»“ trong cÃ¡c mÃ´ hÃ¬nh SSL giá»ng nÃ³i Ä‘Ã²i há»i viá»‡c nÃ©n thÃ nh mÃ´ hÃ¬nh compact hÆ¡n Ä‘á»ƒ sá»­ dá»¥ng rá»™ng rÃ£i hÆ¡n trong há»c thuáº­t hoáº·c cÃ¡c cÃ´ng ty nhá». Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ qua cÃ¡c lá»›p Transformer, nháº±m loáº¡i bá» cÃ¡c tham sá»‘ key vÃ  query trong khi váº«n giá»¯ nguyÃªn sá»‘ lÆ°á»£ng lá»›p. HÆ¡n ná»¯a, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t chiáº¿n lÆ°á»£c chÆ°ng cáº¥t che giáº¥u má»›i Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng biá»ƒu diá»…n giá»ng nÃ³i cá»§a mÃ´ hÃ¬nh há»c sinh. ChÃºng tÃ´i má»Ÿ rá»™ng hÃ m máº¥t mÃ¡t chÆ°ng cáº¥t Ä‘á»ƒ sá»­ dá»¥ng cáº£ khung giá»ng nÃ³i bá»‹ che giáº¥u vÃ  khÃ´ng bá»‹ che giáº¥u nháº±m táº­n dá»¥ng Ä‘áº§y Ä‘á»§ biá»ƒu diá»…n cháº¥t lÆ°á»£ng cao cá»§a mÃ´ hÃ¬nh giÃ¡o viÃªn. Chiáº¿n lÆ°á»£c nÃ©n toÃ n cáº§u cá»§a chÃºng tÃ´i táº¡o ra mÃ´ hÃ¬nh há»c sinh Ä‘áº¡t tá»· lá»‡ lá»—i Ã¢m vá»‹ (PER) 7.72% vÃ  tá»· lá»‡ lá»—i tá»« (WER) 9.96% trÃªn benchmark SUPERB.
Tá»« khÃ³a chá»‰ má»¥c: há»c tá»± giÃ¡m sÃ¡t giá»ng nÃ³i, nÃ©n mÃ´ hÃ¬nh, tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½, chÆ°ng cáº¥t che giáº¥u

1. Giá»›i thiá»‡u
CÃ¡c mÃ´ hÃ¬nh SSL giá»ng nÃ³i dá»±a trÃªn Transformer [1, 2, 3] Ä‘Ã£ Ä‘Æ°á»£c nghiÃªn cá»©u tÃ­ch cá»±c trong lÄ©nh vá»±c xá»­ lÃ½ giá»ng nÃ³i [4] khi SSL ná»•i lÃªn nhÆ° má»™t phÆ°Æ¡ng phÃ¡p há»c biá»ƒu diá»…n thÃ nh cÃ´ng trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y [5, 6, 7, 8]. Äáº·c biá»‡t Ä‘á»‘i vá»›i wav2vec 2.0 [9], HuBERT [10], vÃ  wavLM [11], táº¥t cáº£ Ä‘á»u Ä‘Æ°á»£c káº¿ thá»«a tá»« BERT [12], cho tháº¥y hiá»‡u suáº¥t Ä‘Ã¡ng ngáº¡c nhiÃªn trong nháº­n dáº¡ng giá»ng nÃ³i tá»± Ä‘á»™ng (ASR), cÃ³ thá»ƒ so sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p há»c cÃ³ giÃ¡m sÃ¡t [13, 14]. VÃ¬ tÃ­nh linh hoáº¡t cá»§a SSL giá»ng nÃ³i cÅ©ng trá»Ÿ nÃªn quan trá»ng, cÃ¡c mÃ´ hÃ¬nh trÃªn Ä‘Ã£ Ä‘Æ°á»£c khÃ¡m phÃ¡ thÃªm trong nhiá»u á»©ng dá»¥ng khÃ¡c nhau bao gá»“m xÃ¡c minh ngÆ°á»i nÃ³i tá»± Ä‘á»™ng (ASV) [15] hoáº·c nháº­n dáº¡ng cáº£m xÃºc (ER) [16].

Tuy nhiÃªn, cÃ¡c mÃ´ hÃ¬nh nÃ y cÃ³ sá»‘ lÆ°á»£ng tham sá»‘ khá»•ng lá»“ vÃ  Ä‘Æ°á»£c huáº¥n luyá»‡n trong thá»i gian ráº¥t dÃ i, Ä‘iá»u nÃ y gÃ¢y khÃ³ khÄƒn cho cÃ¡c nhÃ³m háº¡n cháº¿ tÃ i nguyÃªn trong viá»‡c huáº¥n luyá»‡n mÃ´ hÃ¬nh riÃªng cá»§a há». VÃ­ dá»¥, wav2vec 2.0 LARGE vá»›i 317M tham sá»‘ cáº§n Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trong hÆ¡n 290 ngÃ y trÃªn má»™t GPU V100 Ä‘Æ¡n láº» [9] trÃªn táº­p dá»¯ liá»‡u LibriSpeech [17]. Äiá»u nÃ y Ä‘Ã²i há»i chÃºng ta pháº£i xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh nÃ©n cho phÃ©p huáº¥n luyá»‡n hiá»‡u quáº£ tham sá»‘ hÆ¡n nhiá»u vÃ  chi phÃ­ tÃ­nh toÃ¡n tháº¥p hÆ¡n.

ChÆ°ng cáº¥t tri thá»©c (KD) [18] lÃ  má»™t ká»¹ thuáº­t nÃ©n mÃ´ hÃ¬nh phá»• biáº¿n trong Ä‘Ã³ má»™t mÃ´ hÃ¬nh há»c sinh nhá» hÆ¡n Ä‘Æ°á»£c huáº¥n luyá»‡n báº±ng cÃ¡ch chÆ°ng cáº¥t tri thá»©c tá»« mÃ´ hÃ¬nh giÃ¡o viÃªn. CÃ¡c ná»— lá»±c trÆ°á»›c Ä‘Ã¢y trong viá»‡c chÆ°ng cáº¥t cÃ¡c mÃ´ hÃ¬nh SSL giá»ng nÃ³i quy mÃ´ lá»›n Ä‘Ã£ Ä‘Æ°á»£c thá»±c hiá»‡n vá»›i viá»‡c giáº£m sá»‘ lÆ°á»£ng lá»›p Transformer hoáº·c thu háº¹p chiá»u rá»™ng cá»§a chÃºng. DistilHuBERT [19] Ä‘Æ°á»£c chÆ°ng cáº¥t theo cÃ¡ch dá»± Ä‘oÃ¡n Ä‘áº§u ra Ä‘a lá»›p cá»§a HuBERT, vá»›i háº§u háº¿t cÃ¡c lá»›p Transformer bá»‹ loáº¡i bá». FitHuBERT [20], thay vÃ¬ loáº¡i bá» cÃ¡c lá»›p, Ä‘á» xuáº¥t cáº¯t giáº£m chiá»u rá»™ng cá»§a chÃº Ã½ vÃ  máº¡ng nÆ¡-ron truyá»n tháº³ng (FFN) trong má»—i lá»›p Transformer. LightHuBERT [21] táº¡o ra má»™t supernet cÃ³ thá»ƒ cáº¯t tá»‰a thÃ´ng qua chÆ°ng cáº¥t vÃ  thá»±c hiá»‡n tÃ¬m kiáº¿m kiáº¿n trÃºc Ä‘á»ƒ táº¡o ra má»™t há»c sinh nhá».

Máº·c dÃ¹ hiá»‡u quáº£ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã¢y trong viá»‡c giáº£m thiá»ƒu sá»± sá»¥t giáº£m hiá»‡u suáº¥t do nÃ©n, chÃºng váº«n Ä‘á»‘i máº·t vá»›i má»™t sá»‘ váº¥n Ä‘á». (1) CÃ¡c há»c sinh rá»™ng vÃ  nÃ´ng [19, 22] váº«n thá»ƒ hiá»‡n sá»± suy thoÃ¡i trÃªn cÃ¡c tÃ¡c vá»¥ háº¡ nguá»“n liÃªn quan Ä‘áº¿n ná»™i dung. (2) ChÆ°ng cáº¥t lá»›p-Ä‘áº¿n-lá»›p (L2L) Ä‘Æ°á»£c chá»©ng minh lÃ  hiá»‡u quáº£ [20, 22], tuy nhiÃªn, nÃ³ pháº£n trá»±c giÃ¡c vá» máº·t nÃ©n vÃ¬ cáº§n táº¥t cáº£ tham sá»‘ cá»§a má»i lá»›p. (3) Cáº¯t tá»‰a báº±ng tÃ¬m kiáº¿m kiáº¿n trÃºc [21] chuáº©n bá»‹ má»™t supernet cÃ³ kÃ­ch thÆ°á»›c giÃ¡o viÃªn bá»• sung sá»­ dá»¥ng 32 GPU, Ä‘iá»u nÃ y khÃ´ng pháº£i end-to-end (E2E) vÃ  khÃ´ng thá»ƒ dá»… dÃ ng Ä‘Æ°á»£c huáº¥n luyá»‡n bá»Ÿi cÃ¡c nhÃ³m háº¡n cháº¿ tÃ i nguyÃªn.

ChÃºng tÃ´i Ä‘á» xuáº¥t tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ qua cÃ¡c lá»›p Transformer cá»§a há»c sinh, Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y [23, 24] Ä‘Ã£ kháº³ng Ä‘á»‹nh sá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¡c báº£n Ä‘á»“ chÃº Ã½. TÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ cho phÃ©p chÃºng ta loáº¡i bá» cÃ¡c tham sá»‘ key vÃ  query trong má»™t sá»‘ lá»›p Transformer nháº¥t Ä‘á»‹nh, lÃ m cho viá»‡c giá»¯ láº¡i táº¥t cáº£ tham sá»‘ lá»›p cho chÆ°ng cáº¥t L2L trá»Ÿ nÃªn khÃ´ng cáº§n thiáº¿t. HÆ¡n ná»¯a, chÃºng ta cÃ³ thá»ƒ tÃ¡i Ä‘áº§u tÆ° cÃ¡c tham sá»‘ Ä‘Ã£ tiáº¿t kiá»‡m vÃ o cÃ¡c pháº§n khÃ¡c cá»§a Transformer.

ChÃºng tÃ´i cÅ©ng Ä‘á» xuáº¥t che giáº¥u vá»›i chÆ°ng cáº¥t L2L Ä‘á»ƒ cÃ³ cháº¥t lÆ°á»£ng biá»ƒu diá»…n giá»ng nÃ³i tá»‘t hÆ¡n cá»§a mÃ´ hÃ¬nh há»c sinh. Che giáº¥u khung giá»ng nÃ³i lÃ  má»™t ká»¹ thuáº­t Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong cÃ¡c mÃ´ hÃ¬nh SSL giá»ng nÃ³i [9, 10], Ä‘Æ°á»£c huáº¥n luyá»‡n báº±ng cÃ¡ch dá»± Ä‘oÃ¡n biá»ƒu diá»…n bá»‹ che giáº¥u. Ká»¹ thuáº­t nÃ y Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘Æ¡n giáº£n Ä‘á»ƒ chÆ°ng cáº¥t HuBERT [21], nhÆ°ng khÃ´ng theo cÃ¡ch L2L. SÆ¡ Ä‘á»“ chÆ°ng cáº¥t che giáº¥u má»›i cá»§a chÃºng tÃ´i nháº±m táº­n dá»¥ng Ä‘áº§y Ä‘á»§ biá»ƒu diá»…n cá»§a giÃ¡o viÃªn báº±ng cÃ¡ch má»Ÿ rá»™ng hÃ m máº¥t mÃ¡t chÆ°ng cáº¥t cho cáº£ khung giá»ng nÃ³i bá»‹ che giáº¥u vÃ  khÃ´ng bá»‹ che giáº¥u. ChÃºng tÃ´i nháº¥n máº¡nh ráº±ng sÆ¡ Ä‘á»“ cá»§a chÃºng tÃ´i lÃ  theo phong cÃ¡ch E2E vÃ  nÃ¢ng cao cháº¥t lÆ°á»£ng tá»•ng quÃ¡t cá»§a biá»ƒu diá»…n giá»ng nÃ³i, Ä‘áº·c biá»‡t trong cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n ná»™i dung vÃ  ngá»¯ nghÄ©a.

Káº¿t há»£p hai phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c mÃ´ táº£ cá»§a chÃºng tÃ´i (HÃ¬nh 1), chÃºng tÃ´i tÃ¡i Ä‘áº§u tÆ° cÃ¡c tham sá»‘ Ä‘Ã£ tiáº¿t kiá»‡m tá»« tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ vÃ o FFN, vÃ  táº¡o ra mÃ´ hÃ¬nh hÃ ng Ä‘áº§u cá»§a chÃºng tÃ´i, ARMHuBERT (Attention map Reused Mask HuBERT). NhÆ° Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn benchmark SUPERB [25], ARMHuBERT Ä‘áº¡t Ä‘iá»ƒm tá»•ng thá»ƒ [11] lÃ  78.1, chÆ°ng cáº¥t E2E tá»‘t nháº¥t hiá»‡n táº¡i. NÃ³ cÅ©ng Ä‘áº¡t 7.72% PER trong nháº­n dáº¡ng Ã¢m vá»‹ (PR), vÃ  9.96% WER trong ASR.

2. Kiáº¿n thá»©c ná»n táº£ng
2.1. MÃ´ hÃ¬nh SSL Giá»ng nÃ³i dá»±a trÃªn Transformer
CÃ¡c mÃ´ hÃ¬nh SSL chiáº¿m Æ°u tháº¿ gáº§n Ä‘Ã¢y trong lÄ©nh vá»±c giá»ng nÃ³i lÃ  wav2vec 2.0 [9], HuBERT [10], vÃ  wavLM [11], trong Ä‘Ã³ ba cáº¥u trÃºc mÃ´ hÃ¬nh nÃ y giá»‘ng há»‡t nhau ngoáº¡i trá»« á»Ÿ má»©c Ä‘á»™ chi tiáº¿t. Cá»¥ thá»ƒ, chÃºng chia sáº» 12 hoáº·c 24 lá»›p Transformer [26] vÃ  CNN 1D 7 lá»›p. CÃ¡c sÆ¡ Ä‘á»“ huáº¥n luyá»‡n trÆ°á»›c cá»§a chÃºng dá»±a trÃªn dá»± Ä‘oÃ¡n bá»‹ che giáº¥u, Æ°á»›c tÃ­nh cÃ¡c tá»« mÃ£ báº±ng biá»ƒu diá»…n Ä‘áº§u ra cá»§a cÃ¡c khung bá»‹ che giáº¥u. Máº·c dÃ¹ cÃ³ tÃ­nh Æ°u viá»‡t vÃ  kháº£ nÄƒng má»Ÿ rá»™ng arXiv:2305.11685v2 [eess.AS] 26 Oct 2023

--- TRANG 2 ---
Lá»›p 12 KD
CHE GIáº¤U
CHE GIáº¤U
Lá»›p 1 KD
CHE GIáº¤UGiÃ¡o viÃªnHá»c sinh
(ğ‘„!,ğ¾!)â†’ğ‘¨ğŸğ‘‰!ğ‘¨ğŸâ†’ğ‘¨ğŸğ‘‰$Lá»›p Transformer 12
Lá»›p Transformer 1Lá»›p Transformer 2â‹®Chiáº¿u tuyáº¿n tÃ­nh 1Chiáº¿u tuyáº¿n tÃ­nh 2â‹®â‹®
Báº£n Ä‘á»“ chÃº Ã½ Ä‘Æ°á»£c tÃ¡i sá»­ dá»¥ngâ‹®
CHE GIáº¤Umáº¥t mÃ¡t bá»‹ che giáº¥u â„’!,â„“$%máº¥t mÃ¡t khÃ´ng bá»‹ che giáº¥u â„’&,â„“$%âœ•âœ•
âœ•HÃ¬nh 1: Chiáº¿n lÆ°á»£c nÃ©n cá»§a chÃºng tÃ´i bao gá»“m tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ cá»§a lá»›p trÆ°á»›c Ä‘Ã³ vÃ  má»Ÿ rá»™ng quÃ¡ trÃ¬nh chÆ°ng cáº¥t cho cÃ¡c biá»ƒu diá»…n bá»‹ che giáº¥u (mÅ©i tÃªn Ä‘á») vÃ  khÃ´ng bá»‹ che giáº¥u (mÅ©i tÃªn xanh). CÃ¡c khung Ä‘áº§u vÃ o bá»‹ che giáº¥u giá»‘ng há»‡t nhau cho cáº£ giÃ¡o viÃªn vÃ  há»c sinh.

cá»§a cÃ¡c mÃ´ hÃ¬nh SSL giá»ng nÃ³i, sá»‘ lÆ°á»£ng tham sá»‘ lá»›n vÃ  chi phÃ­ tÃ­nh toÃ¡n cá»§a chÃºng khiáº¿n viá»‡c huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh nÃ y trá»Ÿ nÃªn khÃ³ khÄƒn. Do Ä‘Ã³ chÃºng tÃ´i thá»±c hiá»‡n nÃ©n mÃ´ hÃ¬nh trÃªn HuBERT vÃ  wavLM, hai mÃ´ hÃ¬nh SSL chiáº¿m Æ°u tháº¿ trong giá»ng nÃ³i, Ä‘á»ƒ chá»©ng minh hiá»‡u quáº£ cá»§a chiáº¿n lÆ°á»£c nÃ©n cá»§a chÃºng tÃ´i.

2.2. Benchmark SUPERB
Sá»± khá»Ÿi Ä‘áº§u cá»§a cÃ¡c mÃ´ hÃ¬nh SSL giá»ng nÃ³i táº­p trung vÃ o cÃ¡c tÃ¡c vá»¥ háº¡ nguá»“n liÃªn quan Ä‘áº¿n ná»™i dung nhÆ° ASR hoáº·c PR [27, 28], tuy nhiÃªn, tÃ­nh linh hoáº¡t cá»§a chÃºng Ä‘á»‘i vá»›i cÃ¡c tÃ¡c vá»¥ khÃ¡c Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng nháº­n lÃ  quan trá»ng gáº§n Ä‘Ã¢y [11]. Trong bá»‘i cáº£nh nÃ y, benchmark SUPERB [25] Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a cÃ¡c mÃ´ hÃ¬nh SSL giá»ng nÃ³i, bao phá»§ cÃ¡c khÃ­a cáº¡nh vá» ná»™i dung, ngÆ°á»i nÃ³i, ngá»¯ nghÄ©a, vÃ  cáº­n ngÃ´n ngá»¯ há»c. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ biá»ƒu diá»…n cá»§a chÃºng tÃ´i so vá»›i benchmark SUPERB Ä‘á»ƒ xÃ¡c minh kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a mÃ´ hÃ¬nh há»c sinh.

CÃ¡c tÃ¡c vá»¥ háº¡ nguá»“n SUPERB bao gá»“m PR, ASR, nháº­n dáº¡ng tá»« khÃ³a (KS), phÃ¡t hiá»‡n thuáº­t ngá»¯ Ä‘Æ°á»£c nÃ³i theo truy váº¥n vÃ­ dá»¥ (QbE), nháº­n dáº¡ng ngÆ°á»i nÃ³i (SID), ASV, phÃ¢n tÃ¡ch ngÆ°á»i nÃ³i (SD), phÃ¢n loáº¡i Ã½ Ä‘á»‹nh (IC), Ä‘iá»n khe (SF), vÃ  ER.

3. PhÆ°Æ¡ng phÃ¡p luáº­n
3.1. TÃ¡i sá»­ dá»¥ng Báº£n Ä‘á»“ ChÃº Ã½
TÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ lÃ  má»™t ká»¹ thuáº­t Ä‘á»ƒ thay tháº¿ báº£n Ä‘á»“ chÃº Ã½ cá»§a lá»›p hiá»‡n táº¡i báº±ng báº£n Ä‘á»“ cá»§a lá»›p trÆ°á»›c Ä‘Ã³, Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» cáº­p trong má»™t sá»‘ lÄ©nh vá»±c [23, 29]. CÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y [23, 24] Ä‘Ã£ chá»‰ ra sá»± tÆ°Æ¡ng Ä‘á»“ng cá»§a cÃ¡c báº£n Ä‘á»“ chÃº Ã½ qua cÃ¡c Ä‘áº§u vÃ  lá»›p trong cÃ¡c mÃ´ hÃ¬nh Transformer Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c, nhÆ° BERT [12] vÃ  ViT [30]. ChÃºng tÃ´i táº­n dá»¥ng thuá»™c tÃ­nh nÃ y báº±ng cÃ¡ch tÃ¡i sá»­ dá»¥ng cÃ¡c báº£n Ä‘á»“ chÃº Ã½ Ä‘á»ƒ nÃ©n mÃ´ hÃ¬nh há»c sinh. Thay vÃ o Ä‘Ã³, chÃºng ta cÃ³ thá»ƒ phÃ¢n bá»• láº¡i lÆ°á»£ng tham sá»‘ Ä‘Æ°á»£c tiáº¿t kiá»‡m tá»« tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½, mÃ  khÃ´ng tÄƒng tá»•ng sá»‘ tham sá»‘.

Trong mÃ´-Ä‘un tá»± chÃº Ã½ Ä‘a Ä‘áº§u (MHSA) cá»§a Transformer [26], Ä‘áº§u vÃ o xâˆˆRnÃ—d vá»›i Ä‘á»™ dÃ i chuá»—i n Ä‘Æ°á»£c biáº¿n Ä‘á»•i thÃ nh H truy váº¥n, khÃ³a vÃ  giÃ¡ trá»‹ Ä‘á»™c láº­p bá»Ÿi cÃ¡c ma tráº­n biáº¿n Ä‘á»•i Wh,k, Wh,qâˆˆRdÃ—dk, vÃ  Wh,vâˆˆRdÃ—dv, tÆ°Æ¡ng á»©ng, cho má»—i Ä‘áº§u h. á» Ä‘Ã¢y, dk, dv, vÃ  d lÃ  chiá»u rá»™ng cá»§a khÃ³a, giÃ¡ trá»‹, vÃ  mÃ´ hÃ¬nh, tÆ°Æ¡ng á»©ng.

Kh=Wh,kx, KhâˆˆRnÃ—dk,
Qh=Wh,qx, QhâˆˆRnÃ—dk,
Vh=Wh,vx, VhâˆˆRnÃ—dv(1)

Sau Ä‘Ã³, khÃ³a vÃ  truy váº¥n Ä‘Æ°á»£c nhÃ¢n theo trá»¥c chiá»u rá»™ng Ä‘á»ƒ thu Ä‘Æ°á»£c báº£n Ä‘á»“ chÃº Ã½ tÃ­ch vÃ´ hÆ°á»›ng cÃ³ tá»· lá»‡, AhâˆˆRnÃ—n. CÃ¡c tá»• há»£p tuyáº¿n tÃ­nh cá»§a báº£n Ä‘á»“ chÃº Ã½ vÃ  giÃ¡ trá»‹ cho má»—i Ä‘áº§u Ä‘Æ°á»£c ná»‘i vá»›i nhau, sau Ä‘Ã³ Ä‘Æ°á»£c chiáº¿u vá» chiá»u rá»™ng gá»‘c.

Ah=softmax(QhKâŠ¤h/âˆšdk), (2)
MHSA(x) = [A1V1, ..., AHVH]Wo, WoâˆˆRHdvÃ—d(3)

TÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ lÃ  thay tháº¿ Ah báº±ng báº£n Ä‘á»“ cá»§a lá»›p trÆ°á»›c Ä‘Ã³. VÃ­ dá»¥, náº¿u chÃºng ta tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ thá»© k trÆ°á»›c Ä‘Ã³ trÃªn lá»›p hiá»‡n táº¡i â„“, mÃ´-Ä‘un ReuseMHSA lÃ 

ReuseMHSA(x) = [Aâ„“-k1Vâ„“1, ..., Aâ„“-kHVâ„“H]Wâ„“o. (4)

Theo Ä‘Ã³, viá»‡c tÃ­nh toÃ¡n Kh vÃ  Qh cÃ³ thá»ƒ Ä‘Æ°á»£c bá» qua, giáº£m sá»‘ lÆ°á»£ng phÃ©p nhÃ¢n vÃ  phÃ©p cá»™ng bá»Ÿi (2nd2 + n2d). Giáº£ sá»­ d/H = dv = dk, tÃ­nh toÃ¡n bá»‹ bá» qua chiáº¿m má»™t ná»­a tÃ­nh toÃ¡n gá»‘c cho MHSA, lÃ  (4nd2 + 2n2d). Káº¿t quáº£ lÃ , cáº§n Ã­t tham sá»‘ vÃ  phÃ©p nhÃ¢n-tÃ­ch lÅ©y (MAC) hÆ¡n khi sá»­ dá»¥ng nhiá»u mÃ´-Ä‘un ReuseMHSA hÆ¡n (xem Má»¥c 5.1).

3.2. ChÆ°ng cáº¥t Che giáº¥u
TÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ Ä‘Ã£ giáº£m sá»‘ lÆ°á»£ng tham sá»‘, tuy nhiÃªn, nÃ³ cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng biá»ƒu diá»…n cá»§a mÃ´ hÃ¬nh há»c sinh. Äá»ƒ cáº£i thiá»‡n viá»‡c há»c biá»ƒu diá»…n cá»§a há»c sinh, chÃºng tÃ´i Ä‘Æ°a ra má»™t sÆ¡ Ä‘á»“ chÆ°ng cáº¥t che giáº¥u má»›i táº­n dá»¥ng tri thá»©c biá»ƒu diá»…n cá»§a giÃ¡o viÃªn theo cÃ¡ch tinh vi hÆ¡n.

Che giáº¥u khung giá»ng nÃ³i bao gá»“m viá»‡c há»c biá»ƒu diá»…n thÃ´ng qua dá»± Ä‘oÃ¡n bá»‹ che giáº¥u, trong Ä‘Ã³ mÃ´ hÃ¬nh há»c cÃ¡ch biá»ƒu diá»…n cÃ¡c khung bá»‹ che giáº¥u má»™t cÃ¡ch chÃ­nh xÃ¡c dá»±a trÃªn cÃ¡c khung khÃ´ng bá»‹ che giáº¥u khÃ¡c. LightHuBERT [21], Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« data2vec [8], Ä‘Ã£ Ä‘áº§u tiÃªn Ã¡p dá»¥ng chiáº¿n lÆ°á»£c che giáº¥u Ä‘á»ƒ chÆ°ng cáº¥t HuBERT. Trong phÆ°Æ¡ng phÃ¡p nÃ y, mÃ´ hÃ¬nh giÃ¡o viÃªn hÆ°á»›ng dáº«n biá»ƒu diá»…n cá»§a cÃ¡c khung bá»‹ che giáº¥u.

Gá»i Î¼(x) lÃ  Ä‘áº§u vÃ o bá»‹ che giáº¥u, vÃ  ft vÃ  fs lÃ  giÃ¡o viÃªn vÃ 

--- TRANG 3 ---
Báº£ng 1: Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ trÃªn benchmark SUPERB. CÃ¡c chá»‰ sá»‘ bao gá»“m kÃ­ch thÆ°á»›c tham sá»‘ tÃ­nh báº±ng triá»‡u, PER%, WER% (khÃ´ng cÃ³ mÃ´ hÃ¬nh ngÃ´n ngá»¯), Ä‘á»™ chÃ­nh xÃ¡c (Acc%), giÃ¡ trá»‹ trá»ng sá»‘ thuáº­t ngá»¯ tá»‘i Ä‘a (MTWV), tá»· lá»‡ lá»—i báº±ng nhau (EER%), tá»· lá»‡ lá»—i phÃ¢n tÃ¡ch (DER%), Ä‘iá»ƒm F1 (F1%), vÃ  tá»· lá»‡ lá»—i khÃ¡i niá»‡m (CER%). "Overall" biá»ƒu thá»‹ Ä‘iá»ƒm trung bÃ¬nh cá»§a táº¥t cáº£ cÃ¡c tÃ¡c vá»¥ Ä‘Æ°á»£c Ä‘á» xuáº¥t trong [11]. LightHuBERT [21] hoáº¡t Ä‘á»™ng báº±ng huáº¥n luyá»‡n hai giai Ä‘oáº¡n, trong Ä‘Ã³ supernet cÃ³ kÃ­ch thÆ°á»›c HuBERT cáº§n Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c, do Ä‘Ã³ khÃ´ng Ä‘Æ°á»£c so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh chÆ°ng cáº¥t E2E. ARMHuBERT-S vÃ  ARMwavLM-S vá»›i chÆ°ng cáº¥t 960h Ä‘Æ°á»£c huáº¥n luyá»‡n trong 100 epoch.

[Báº£ng dá»¯ liá»‡u hiá»‡u suáº¥t chi tiáº¿t - giá»¯ nguyÃªn cáº¥u trÃºc báº£ng gá»‘c]

mÃ´ hÃ¬nh há»c sinh. Sau Ä‘Ã³, hÃ m máº¥t mÃ¡t bá»‹ che giáº¥u trá»Ÿ thÃ nh

L(x) = 1/|M| âˆ‘(iâˆˆM) ||ft_i(x) - fs_i(Î¼(x))||Â²(5)

trong Ä‘Ã³ fi lÃ  khung thá»© i cá»§a biá»ƒu diá»…n giá»ng nÃ³i, vÃ  M lÃ  táº­p há»£p cÃ¡c khung bá»‹ che giáº¥u.

NgoÃ i máº¥t mÃ¡t pháº§n bá»‹ che giáº¥u (cÃ´ng thá»©c 5), chÃºng tÃ´i Ä‘á» xuáº¥t sá»­ dá»¥ng máº¥t mÃ¡t khÃ´ng bá»‹ che giáº¥u vÃ¬ mÃ´ hÃ¬nh giÃ¡o viÃªn cÃ³ thá»ƒ cung cáº¥p biá»ƒu diá»…n cháº¥t lÆ°á»£ng cao ngay cáº£ trÃªn cÃ¡c khung khÃ´ng bá»‹ che giáº¥u. Tuy nhiÃªn, náº¿u quÃ¡ trÃ¬nh che giáº¥u loáº¡i bá» cÃ¡c khung thiáº¿t yáº¿u, viá»‡c chÆ°ng cáº¥t dáº¡ng nguyÃªn váº¹n cá»§a ft(x) cÃ³ thá»ƒ rÃ² rá»‰ tri thá»©c thiáº¿t yáº¿u Ä‘Ã³ mÃ  láº½ ra Ä‘Ã£ bá»‹ loáº¡i bá». Äiá»u nÃ y táº¡o ra dá»± Ä‘oÃ¡n thiÃªn vá»‹ cá»§a há»c sinh, vÃ¬ nÃ³ há»c thÃ´ng tin khÃ´ng thá»ƒ suy luáº­n tá»« Ä‘áº§u vÃ o bá»‹ che giáº¥u.

Äá»ƒ ngÄƒn cháº·n Ä‘iá»u nÃ y, chÃºng tÃ´i lÃ m cho mÃ´ hÃ¬nh giÃ¡o viÃªn nháº­n cÃ¹ng Ä‘áº§u vÃ o bá»‹ che giáº¥u nhÆ° há»c sinh khi chÆ°ng cáº¥t pháº§n khÃ´ng bá»‹ che giáº¥u. Do Ä‘Ã³, toÃ n bá»™ hÃ m máº¥t mÃ¡t chÆ°ng cáº¥t trá»Ÿ thÃ nh

L(x) = âˆ‘â„“ Î±â„“ [Lm,â„“(x) + Lu,â„“(x)]
= âˆ‘â„“ Î±â„“ [1/|M| âˆ‘(iâˆˆM) ||ft_i,â„“(x) - fs_i,â„“(Î¼(x))||Â²](6)
+ âˆ‘â„“ Î±â„“ [1/(n-|M|) âˆ‘(iâˆ‰M) ||ft_i,â„“(Î¼(x)) - fs_i,â„“(Î¼(x))||Â²]

trong Ä‘Ã³ Î±â„“ lÃ  há»‡ sá»‘ theo lá»›p. Lm,â„“ vÃ  Lu,â„“ biá»ƒu thá»‹ máº¥t mÃ¡t bá»‹ che giáº¥u vÃ  máº¥t mÃ¡t khÃ´ng bá»‹ che giáº¥u cá»§a lá»›p thá»© â„“, tÆ°Æ¡ng á»©ng.

TÃ³m láº¡i, chiáº¿n lÆ°á»£c chÆ°ng cáº¥t che giáº¥u má»›i cá»§a chÃºng tÃ´i hÆ°á»›ng dáº«n viá»‡c thu tháº­p tri thá»©c cá»§a há»c sinh má»™t cÃ¡ch thÃ­ch há»£p, báº±ng cÃ¡ch chÆ°ng cáº¥t khÃ´ng chá»‰ biá»ƒu diá»…n bá»‹ che giáº¥u cá»§a dá»¯ liá»‡u khÃ´ng bá»‹ che giáº¥u mÃ  cÃ²n biá»ƒu diá»…n khÃ´ng bá»‹ che giáº¥u cá»§a dá»¯ liá»‡u bá»‹ che giáº¥u (xem HÃ¬nh 1). Trong Má»¥c 5.2, chÃºng tÃ´i Ä‘iá»u tra sá»©c máº¡nh cá»§a chiáº¿n lÆ°á»£c che giáº¥u so vá»›i cÃ¡c loáº¡i máº¥t mÃ¡t khÃ¡c.

4. Káº¿t quáº£
4.1. Chi tiáº¿t Triá»ƒn khai
ChÃºng tÃ´i chÆ°ng cáº¥t hai mÃ´ hÃ¬nh SSL giá»ng nÃ³i dá»±a trÃªn Transformer chiáº¿m Æ°u tháº¿, HuBERT BASE [10] vÃ  wavLM BASE [11], Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn táº­p dá»¯ liá»‡u LibriSpeech 960 giá» [17]. MÃ´ hÃ¬nh há»c sinh cá»§a chÃºng tÃ´i bao gá»“m 12 lá»›p Transformer nhÆ° cÃ¡c giÃ¡o viÃªn, trong khi thiáº¿t káº¿ chi tiáº¿t chá»§ yáº¿u theo FitHuBERT [20]: chiá»u rá»™ng cá»§a chÃº Ã½ vÃ  FFN Ä‘Æ°á»£c giáº£m vÃ  chiáº¿u tuyáº¿n tÃ­nh Ä‘Æ°á»£c Ã¡p dá»¥ng táº¡i má»—i lá»›p. CÃ¡c há»‡ sá»‘ theo lá»›p Î±â„“ Ä‘Æ°á»£c Ä‘áº·t lÃ  0.1 ngoáº¡i trá»« lá»›p cuá»‘i cÃ¹ng, nÆ¡i nÃ³ Ä‘Æ°á»£c Ä‘áº·t lÃ  1. Trá»« khi Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, táº­p dá»¯ liá»‡u LibriSpeech [17] Ä‘Æ°á»£c chÆ°ng cáº¥t trong 200 epoch vá»›i kÃ­ch thÆ°á»›c batch hiá»‡u quáº£ lÃ  72 bao gá»“m tÃ­ch lÅ©y gradient.

Máº«u tÃ¡i sá»­ dá»¥ng ChÃºng tÃ´i sá»­ dá»¥ng máº«u tÃ¡i sá»­ dá»¥ng xen káº½ cho cÃ¡c báº£n Ä‘á»“ chÃº Ã½, theo Ä‘Ã³ báº£n Ä‘á»“ chÃº Ã½ cá»§a lá»›p Transformer cÃ³ sá»‘ cháºµn Ä‘Æ°á»£c láº·p láº¡i bá»Ÿi lá»›p cÃ³ sá»‘ láº» trÆ°á»›c Ä‘Ã³. ChÃºng tÃ´i kÃ½ hiá»‡u máº«u nÃ y lÃ  2by6, thiáº¿t láº­p máº·c Ä‘á»‹nh cá»§a chÃºng tÃ´i. ChÃºng tÃ´i kiá»ƒm tra cÃ¡c máº«u tÃ¡i sá»­ dá»¥ng khÃ¡c trong Má»¥c 5.1 vá» hiá»‡u suáº¥t, sá»‘ lÆ°á»£ng tham sá»‘, vÃ  MAC.

MÃ´ táº£ mÃ´ hÃ¬nh Äá»ƒ xÃ¡c minh chiáº¿n lÆ°á»£c chÆ°ng cáº¥t che giáº¥u cá»§a chÃºng tÃ´i, trÆ°á»›c tiÃªn chÃºng tÃ´i xÃ¢y dá»±ng mÃ´ hÃ¬nh há»c sinh, MaskHuBERT, chá»‰ sá»­ dá»¥ng chÆ°ng cáº¥t che giáº¥u. MaskHuBERT cÃ³ chiá»u rá»™ng (chÃº Ã½, FFN) lÃ  (480, 640). Sau Ä‘Ã³, máº«u tÃ¡i sá»­ dá»¥ng 2by6 Ä‘Æ°á»£c Ã¡p dá»¥ng cho MaskHuBERT, dáº«n Ä‘áº¿n giáº£m 10.3% tham sá»‘. ChÃºng tÃ´i má»Ÿ rá»™ng mÃ´ hÃ¬nh nÃ y thÃ nh hai tÃ¹y chá»n: ARMHuBERT vÃ  ARMHuBERT-S. ARMHuBERT lÃ  phiÃªn báº£n tÃ¡i Ä‘áº§u tÆ° cá»§a MaskHuBERT, trong Ä‘Ã³ cÃ¡c tham sá»‘ Ä‘Æ°á»£c tiáº¿t kiá»‡m tá»« tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ Ä‘Æ°á»£c phÃ¢n bá»• láº¡i cho FFN, dáº«n Ä‘áº¿n tÄƒng chiá»u rá»™ng (480, 864). ARMHuBERT-S lÃ  phiÃªn báº£n giáº£m Ä‘á»ƒ khá»›p tham sá»‘ vá»›i cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y, cÃ³ chiá»u rá»™ng (432, 816). Äá»ƒ thiáº¿t láº­p tÃ­nh toÃ n cáº§u cá»§a chiáº¿n lÆ°á»£c, chÃºng tÃ´i giá»›i thiá»‡u ARMwavLM-S cÃ³ cáº¥u trÃºc giá»‘ng há»‡t ARMHuBERT-S, vá»›i sá»± thay Ä‘á»•i duy nháº¥t trong giÃ¡o viÃªn tá»« HuBERT sang wavLM.

--- TRANG 4 ---
Báº£ng 2: So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c máº«u tÃ¡i sá»­ dá»¥ng khÃ¡c nhau. KÃ­ch thÆ°á»›c tham sá»‘ (M) vÃ  MAC (G) Ä‘Æ°á»£c Ä‘o thÃªm. Chiá»u rá»™ng (chÃº Ã½, FFN) cho má»—i mÃ´ hÃ¬nh lÃ  (432, 816), trong khi háº­u tá»‘ "-up" biá»ƒu thá»‹ nhiá»u tham sá»‘ hÆ¡n Ä‘Æ°á»£c gÃ¡n cho FFN Ä‘á»ƒ khá»›p vá»›i 2by6. Che giáº¥u khÃ´ng Ä‘Æ°á»£c Ã¡p dá»¥ng á»Ÿ Ä‘Ã¢y.

[Báº£ng dá»¯ liá»‡u so sÃ¡nh cÃ¡c máº«u - giá»¯ nguyÃªn cáº¥u trÃºc]

4.2. Káº¿t quáº£ Benchmark SUPERB
Trong Báº£ng 1, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh há»c sinh trÃªn benchmark SUPERB [25]. ChÃºng tÃ´i tuÃ¢n theo cÃ¡c cÃ´ng thá»©c tinh chá»‰nh máº·c Ä‘á»‹nh, bao gá»“m bá»™ láº­p lá»‹ch tá»· lá»‡ há»c, vá»›i tá»· lá»‡ há»c Ä‘Æ°á»£c chia tá»· lá»‡ 10Ã— trong tÃ¡c vá»¥ SID. MaskHuBERT vÆ°á»£t trá»™i hÆ¡n 12-L HALF-L2L, phÆ°Æ¡ng phÃ¡p chÆ°ng cáº¥t E2E tá»‘t nháº¥t trÆ°á»›c Ä‘Ã¢y, vá»›i Ã­t tham sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng hÆ¡n. Quan sÃ¡t cá»§a chÃºng tÃ´i cho tháº¥y viá»‡c káº¿t há»£p chiáº¿n lÆ°á»£c che giáº¥u vÃ o chÆ°ng cáº¥t L2L [20, 22] dáº«n Ä‘áº¿n nÃ¢ng cao cháº¥t lÆ°á»£ng biá»ƒu diá»…n cá»§a há»c sinh. Äáº·c biá»‡t, MaskHuBERT cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t trong cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n ná»™i dung vÃ  ngá»¯ nghÄ©a.

ARMHuBERT Ä‘áº¡t Ä‘iá»ƒm tá»•ng thá»ƒ tá»‘t hÆ¡n lÃ  78.1 vá»›i Ã­t tham sá»‘ hÆ¡n MaskHuBERT. Máº·c dÃ¹ loáº¡i bá» má»™t sá»‘ tham sá»‘ chÃº Ã½ nháº¥t Ä‘á»‹nh, viá»‡c tÄƒng chiá»u rá»™ng FFN gÃ³p pháº§n vÃ o cháº¥t lÆ°á»£ng biá»ƒu diá»…n giá»ng nÃ³i tá»‘t hÆ¡n, Ä‘áº¡t 7.72% PER vÃ  9.96% WER. ChÃºng tÃ´i phÃ¡t hiá»‡n ráº±ng ARMHuBERT cho tháº¥y cáº£i thiá»‡n Ä‘áº§y há»©a háº¹n khi so sÃ¡nh vá»›i MaskHuBERT trong cÃ¡c tÃ¡c vá»¥ SF vÃ  SID, thá»ƒ hiá»‡n má»©c hiá»‡u suáº¥t tÆ°Æ¡ng tá»± trong cÃ¡c tÃ¡c vá»¥ khÃ¡c. Cuá»‘i cÃ¹ng, sá»‘ lÆ°á»£ng tham sá»‘ vÃ  MAC trong ARMHuBERT Ä‘Ã£ giáº£m xuá»‘ng 28% vÃ  30% cá»§a mÃ´ hÃ¬nh giÃ¡o viÃªn, HuBERT BASE [10], tÆ°Æ¡ng á»©ng.

Trong nhÃ³m tham sá»‘ nhá» hÆ¡n, ARMHuBERT-S, phiÃªn báº£n giáº£m tham sá»‘, vÆ°á»£t trá»™i hÆ¡n DistilHuBERT vÃ  FitHuBERT vá»›i biÃªn Ä‘á»™ lá»›n. Cá»¥ thá»ƒ, ARMHuBERT-S cÅ©ng cho tháº¥y káº¿t quáº£ xuáº¥t sáº¯c trong cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n ná»™i dung vÃ  ngá»¯ nghÄ©a, cÃ³ nghÄ©a lÃ  tÃ­nh nháº¥t quÃ¡n cá»§a cÃ¡c biá»ƒu diá»…n Ä‘Æ°á»£c táº¡o ra bá»Ÿi MaskHuBERT vÃ  ARMHuBERT-S. NgoÃ i ra, káº¿t quáº£ ARMwavLM-S vÆ°á»£t trá»™i hÆ¡n ARMHuBERT-S ngá»¥ Ã½ tÃ­nh toÃ n cáº§u cá»§a chiáº¿n lÆ°á»£c: khÃ´ng cÃ³ báº¥t ká»³ sá»­a Ä‘á»•i nÃ o vá» cáº¥u trÃºc mÃ´ hÃ¬nh há»c sinh, viá»‡c thay tháº¿ báº±ng mÃ´ hÃ¬nh giÃ¡o viÃªn vÆ°á»£t trá»™i táº¡o ra há»c sinh tá»‘t hÆ¡n. Káº¿t quáº£ chÆ°ng cáº¥t LibriSpeech [17] 100h cÅ©ng nháº¥t quÃ¡n vá»›i káº¿t quáº£ Ä‘Æ°á»£c chá»©ng minh trÆ°á»›c Ä‘Ã¢y.

5. Tháº£o luáº­n
Trong pháº§n nÃ y, chÃºng tÃ´i khÃ¡m phÃ¡ báº£n Ä‘á»“ chÃº Ã½ cá»§a lá»›p nÃ o nÃªn Ä‘Æ°á»£c tÃ¡i sá»­ dá»¥ng trong cÃ¡c lá»›p khÃ¡c vÃ  cÃ¡ch triá»ƒn khai chÆ°ng cáº¥t che giáº¥u. Trá»« khi Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, chÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n chÆ°ng cáº¥t trÃªn 100 giá» LibriSpeech [17] vÃ  Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c tÃ¡c vá»¥ ASR, ASV, vÃ  SF cá»§a benchmark SUPERB [25].

5.1. NÆ¡i TÃ¡i sá»­ dá»¥ng
Báº£ng 2 tÃ³m táº¯t hiá»‡u suáº¥t tÃ¹y thuá»™c vÃ o cÃ¡c máº«u tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ khÃ¡c nhau, vÃ  nÃ³i chung, máº«u 2by6 hoáº¡t Ä‘á»™ng tá»‘t nháº¥t. CÃ¡c máº«u tÃ¡i sá»­ dá»¥ng khÃ¡c Ä‘Ã£ lÃ m giáº£m kháº£ nÄƒng biá»ƒu diá»…n cá»§a Transformer do tÃ¡i sá»­ dá»¥ng quÃ¡ thÆ°á»ng xuyÃªn. Viá»‡c gÃ¡n nhiá»u tham sá»‘ hÆ¡n cho FFN (-up) váº«n cÃ³ giá»›i háº¡n vá» má»©c tÄƒng hiá»‡u suáº¥t. So vá»›i khÃ´ng Ã¡p dá»¥ng máº«u tÃ¡i sá»­ dá»¥ng nÃ o,

Báº£ng 3: NghiÃªn cá»©u loáº¡i bá» vá» chiáº¿n lÆ°á»£c che giáº¥u cá»§a chÃºng tÃ´i.
[Báº£ng dá»¯ liá»‡u nghiÃªn cá»©u loáº¡i bá» - giá»¯ nguyÃªn cáº¥u trÃºc]

Báº£ng 4: So sÃ¡nh hiá»‡u suáº¥t vá»›i cÃ¡c tá»· lá»‡ che giáº¥u khÃ¡c nhau. "sch" biá»ƒu thá»‹ láº­p lá»‹ch tuyáº¿n tÃ­nh cá»§a tá»· lá»‡ tá»« 0.4 Ä‘áº¿n 0.8.
[Báº£ng dá»¯ liá»‡u so sÃ¡nh tá»· lá»‡ che giáº¥u - giá»¯ nguyÃªn cáº¥u trÃºc]

viá»‡c giáº£m hiá»‡u suáº¥t cá»§a 2by6 lÃ  nhá», nhÆ°ng nÃ³ cÃ³ lá»£i tháº¿ trong viá»‡c giáº£m 9.13% vÃ  8.16% tham sá»‘ vÃ  MAC, tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng sá»‘ lÆ°á»£ng MAC trong má»™t mÃ´-Ä‘un MHSA tÃ¡i sá»­ dá»¥ng Ä‘Æ¡n láº» (cÃ´ng thá»©c 4) Ä‘Æ°á»£c giáº£m má»™t ná»­a, tá»« 13.2G xuá»‘ng 6.6G.

5.2. CÃ¡ch Che giáº¥u
Chiáº¿n lÆ°á»£c che giáº¥u Báº£ng 3 cho tháº¥y hiá»‡u quáº£ cá»§a chiáº¿n lÆ°á»£c che giáº¥u cá»§a chÃºng tÃ´i. Äáº§u tiÃªn chÃºng tÃ´i loáº¡i bá» hÃ m máº¥t mÃ¡t trÃªn cÃ¡c khung khÃ´ng bá»‹ che giáº¥u (Lu,â„“), lÃ m cho nÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i phiÃªn báº£n L2L cá»§a hÃ m máº¥t mÃ¡t chÆ°ng cáº¥t LightHuBERT [21]. PhÆ°Æ¡ng phÃ¡p nÃ y lÃ m há»ng nghiÃªm trá»ng hiá»‡u suáº¥t, Ä‘áº·c biá»‡t trong cÃ¡c tÃ¡c vá»¥ ASR vÃ  ASV. Tiáº¿p theo, chÃºng tÃ´i sá»­a Ä‘á»•i hÃ m máº¥t mÃ¡t khÃ´ng bá»‹ che giáº¥u Ä‘á»ƒ chÆ°ng cáº¥t tá»« Ä‘áº§u vÃ o khÃ´ng bá»‹ che giáº¥u, tá»©c lÃ  chá»‰ ft(x) Ä‘Æ°á»£c chÆ°ng cáº¥t cho há»c sinh. Äiá»u nÃ y cÅ©ng dáº«n Ä‘áº¿n hiá»‡u suáº¥t suy giáº£m trong háº§u háº¿t cÃ¡c tÃ¡c vá»¥, cho tháº¥y ráº±ng máº¥t mÃ¡t khÃ´ng bá»‹ che giáº¥u vá»›i Ä‘áº§u vÃ o bá»‹ che giáº¥u cá»§a chÃºng tÃ´i hÆ°á»›ng dáº«n viá»‡c thu tháº­p tri thá»©c má»™t cÃ¡ch thÃ­ch há»£p mÃ  khÃ´ng Ã¡p Ä‘áº·t dá»± Ä‘oÃ¡n thiÃªn vá»‹.

Tá»· lá»‡ che giáº¥u GiÃ¡ trá»‹ cao cá»§a tá»· lá»‡ che giáº¥u cÃ³ thá»ƒ dáº«n Ä‘áº¿n mÃ´ hÃ¬nh há»c sinh táº¡o ra biá»ƒu diá»…n tá»‘t, vÃ¬ nÃ³ cÃ³ Ã­t thÃ´ng tin hÆ¡n Ä‘á»ƒ suy luáº­n [10, 31]. Tuy nhiÃªn, nÃ³ cÅ©ng cÃ³ thá»ƒ lÃ m cho quÃ¡ trÃ¬nh há»c trá»Ÿ nÃªn khÃ³ khÄƒn hÆ¡n. Trong Báº£ng 4, chÃºng tÃ´i kiá»ƒm tra tá»· lá»‡ che giáº¥u tá»‘i Æ°u cho má»—i táº­p huáº¥n luyá»‡n. Äá»‘i vá»›i LibriSpeech 960h [17], cáº£ tá»· lá»‡ 0.4 vÃ  0.8 Ä‘á»u táº¡o ra káº¿t quáº£ xuáº¥t sáº¯c. Máº·t khÃ¡c, Ä‘á»‘i vá»›i táº­p dá»¯ liá»‡u 100h, tá»· lá»‡ 0.4 táº¡o ra káº¿t quáº£ tá»‘t nháº¥t tá»•ng thá»ƒ. Äiá»u nÃ y ngá»¥ Ã½ ráº±ng tá»· lá»‡ che giáº¥u tháº¥p hÆ¡n Ä‘Æ°á»£c Æ°a thÃ­ch trong thiáº¿t láº­p chÆ°ng cáº¥t tÃ i nguyÃªn tháº¥p. Theo Ä‘Ã³, trong cÃ¡c thÃ­ nghiá»‡m chÃ­nh cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng tá»· lá»‡ 0.8 vÃ  0.4 cho chÆ°ng cáº¥t 960h vÃ  100h, tÆ°Æ¡ng á»©ng.

6. Káº¿t luáº­n vÃ  NghiÃªn cá»©u TÆ°Æ¡ng lai
TÃ³m láº¡i, chÃºng tÃ´i Ä‘Ã£ Ä‘á» xuáº¥t chiáº¿n lÆ°á»£c nÃ©n toÃ n cáº§u bao gá»“m tÃ¡i sá»­ dá»¥ng báº£n Ä‘á»“ chÃº Ã½ vÃ  chÆ°ng cáº¥t che giáº¥u má»›i. MÃ´ hÃ¬nh tÃ¡i Ä‘áº§u tÆ° tham sá»‘ cá»§a chÃºng tÃ´i, ARMHuBERT, Ä‘áº¡t hiá»‡u suáº¥t tuyá»‡t vá»i trong cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n ná»™i dung vÃ  ngá»¯ nghÄ©a. Chiáº¿n lÆ°á»£c cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho báº¥t ká»³ mÃ´ hÃ¬nh SSL giá»ng nÃ³i dá»±a trÃªn Transformer nÃ o, vÃ  gÃ³p pháº§n nÃ¢ng cao cháº¥t lÆ°á»£ng tá»•ng quÃ¡t cá»§a biá»ƒu diá»…n giá»ng nÃ³i. NghiÃªn cá»©u tÆ°Æ¡ng lai cÃ³ thá»ƒ táº­p trung vÃ o viá»‡c cáº£i thiá»‡n thÃªm mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i trÃªn cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n ngÆ°á»i nÃ³i.

7. Lá»i cáº£m Æ¡n
NghiÃªn cá»©u Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Dá»± Ã¡n R&D CÃ´ng nghá»‡ Y táº¿ HÃ n Quá»‘c thÃ´ng qua Viá»‡n PhÃ¡t triá»ƒn CÃ´ng nghiá»‡p Y táº¿ HÃ n Quá»‘c Ä‘Æ°á»£c tÃ i trá»£ bá»Ÿi Bá»™ Y táº¿ vÃ  PhÃºc lá»£i, Cá»™ng hÃ²a HÃ n Quá»‘c (HR18C0016).

--- TRANG 5 ---
8. TÃ i liá»‡u tham kháº£o
[1] A. T. Liu, S.-w. Yang, P.-H. Chi, P.-c. Hsu, vÃ  H.-y. Lee, "Mockingjay: Há»c biá»ƒu diá»…n giá»ng nÃ³i khÃ´ng giÃ¡m sÃ¡t vá»›i bá»™ mÃ£ hÃ³a transformer hai chiá»u sÃ¢u," trong IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020, tr. 6419â€“6423.

[2] P.-H. Chi, P.-H. Chung, T.-H. Wu, C.-C. Hsieh, Y.-H. Chen, S.-W. Li, vÃ  H.-y. Lee, "Audio albert: Má»™t bert nháº¹ cho há»c tá»± giÃ¡m sÃ¡t biá»ƒu diá»…n Ã¢m thanh," trong Spoken Language Technology Workshop (SLT). IEEE, 2021, tr. 344â€“350.

[3] A. T. Liu, S.-W. Li, vÃ  H.-y. Lee, "Tera: Há»c tá»± giÃ¡m sÃ¡t biá»ƒu diá»…n bá»™ mÃ£ hÃ³a transformer cho giá»ng nÃ³i," IEEE/ACM Transactions on Audio, Speech, and Language Processing, táº­p 29, tr. 2351â€“2366, 2021.

[4] S. Liu, A. Mallol-Ragolta, E. Parada-Cabaleiro, K. Qian, X. Jing, A. Kathan, B. Hu, vÃ  B. W. Schuller, "Há»c tá»± giÃ¡m sÃ¡t Ã¢m thanh: Má»™t kháº£o sÃ¡t," Patterns, táº­p 3, sá»‘ 12, tr. 100616, 2022.

[5] T. Mikolov, K. Chen, G. Corrado, vÃ  J. Dean, "Æ¯á»›c lÆ°á»£ng hiá»‡u quáº£ cÃ¡c biá»ƒu diá»…n tá»« trong khÃ´ng gian vector," arXiv preprint arXiv:1301.3781, 2013.

[6] M. Caron, P. Bojanowski, A. Joulin, vÃ  M. Douze, "PhÃ¢n cá»¥m sÃ¢u cho há»c khÃ´ng giÃ¡m sÃ¡t cÃ¡c Ä‘áº·c trÆ°ng thá»‹ giÃ¡c," trong Proceedings of the European conference on computer vision (ECCV), 2018, tr. 132â€“149.

[7] T. Chen, S. Kornblith, M. Norouzi, vÃ  G. Hinton, "Má»™t khung Ä‘Æ¡n giáº£n cho há»c tÆ°Æ¡ng pháº£n biá»ƒu diá»…n thá»‹ giÃ¡c," trong International conference on machine learning. PMLR, 2020, tr. 1597â€“1607.

[8] A. Baevski, W.-N. Hsu, Q. Xu, A. Babu, J. Gu, vÃ  M. Auli, "Data2vec: Má»™t khung tá»•ng quÃ¡t cho há»c tá»± giÃ¡m sÃ¡t trong giá»ng nÃ³i, thá»‹ giÃ¡c vÃ  ngÃ´n ngá»¯," trong International Conference on Machine Learning. PMLR, 2022, tr. 1298â€“1312.

[9] A. Baevski, Y. Zhou, A. Mohamed, vÃ  M. Auli, "wav2vec 2.0: Má»™t khung cho há»c tá»± giÃ¡m sÃ¡t biá»ƒu diá»…n giá»ng nÃ³i," Advances in Neural Information Processing Systems, táº­p 33, tr. 12 449â€“12 460, 2020.

[10] W.-N. Hsu, B. Bolte, Y.-H. H. Tsai, K. Lakhotia, R. Salakhutdinov, vÃ  A. Mohamed, "Hubert: Há»c biá»ƒu diá»…n giá»ng nÃ³i tá»± giÃ¡m sÃ¡t báº±ng dá»± Ä‘oÃ¡n cÃ³ che giáº¥u cÃ¡c Ä‘Æ¡n vá»‹ áº©n," IEEE/ACM Transactions on Audio, Speech, and Language Processing, táº­p 29, tr. 3451â€“3460, 2021.

[11] S. Chen, C. Wang, Z. Chen, Y. Wu, S. Liu, Z. Chen, J. Li, N. Kanda, T. Yoshioka, X. Xiao vÃ  cá»™ng sá»±, "Wavlm: Huáº¥n luyá»‡n trÆ°á»›c tá»± giÃ¡m sÃ¡t quy mÃ´ lá»›n cho xá»­ lÃ½ giá»ng nÃ³i Ä‘áº§y Ä‘á»§," IEEE Journal of Selected Topics in Signal Processing, táº­p 16, sá»‘ 6, tr. 1505â€“1518, 2022.

[12] J. Devlin, M.-W. Chang, K. Lee, vÃ  K. Toutanova, "Bert: Huáº¥n luyá»‡n trÆ°á»›c cÃ¡c transformer hai chiá»u sÃ¢u cho hiá»ƒu ngÃ´n ngá»¯," trong Proceedings of NAACL-HLT, 2019, tr. 4171â€“4186.

[13] A. Gulati, J. Qin, C.-C. Chiu, N. Parmar, Y. Zhang, J. Yu, W. Han, S. Wang, Z. Zhang, Y. Wu vÃ  cá»™ng sá»±, "Conformer: Transformer tÄƒng cÆ°á»ng tÃ­ch cháº­p cho nháº­n dáº¡ng giá»ng nÃ³i," trong Proc. Interspeech, 2020.

[14] S. Kim, A. Gholami, A. E. Shaw, N. Lee, K. Mangalam, J. Malik, M. W. Mahoney, vÃ  K. Keutzer, "Squeezeformer: Má»™t transformer hiá»‡u quáº£ cho nháº­n dáº¡ng giá»ng nÃ³i tá»± Ä‘á»™ng," trong Advances in Neural Information Processing Systems, 2022.

[15] Y. Wang, A. Boumadane, vÃ  A. Heba, "Má»™t benchmark wav2vec 2.0/hubert Ä‘Æ°á»£c tinh chá»‰nh cho nháº­n dáº¡ng cáº£m xÃºc giá»ng nÃ³i, xÃ¡c minh ngÆ°á»i nÃ³i vÃ  hiá»ƒu ngÃ´n ngá»¯ nÃ³i," arXiv preprint arXiv:2111.02735, 2021.

[16] L. Pepino, P. Riera, vÃ  L. Ferrer, "Nháº­n dáº¡ng cáº£m xÃºc tá»« giá»ng nÃ³i sá»­ dá»¥ng nhÃºng wav2vec 2.0," trong Proc. Interspeech, 2021, tr. 3400â€“3404.

[17] V. Panayotov, G. Chen, D. Povey, vÃ  S. Khudanpur, "Librispeech: má»™t táº­p dá»¯ liá»‡u asr dá»±a trÃªn sÃ¡ch Ã¢m thanh miá»n cÃ´ng cá»™ng," trong 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE, 2015, tr. 5206â€“5210.

[18] G. Hinton, O. Vinyals, J. Dean vÃ  cá»™ng sá»±, "ChÆ°ng cáº¥t tri thá»©c trong máº¡ng nÆ¡-ron," arXiv preprint arXiv:1503.02531, táº­p 2, sá»‘ 7, 2015.

[19] H.-J. Chang, S.-w. Yang, vÃ  H.-y. Lee, "Distilhubert: Há»c biá»ƒu diá»…n giá»ng nÃ³i báº±ng chÆ°ng cáº¥t theo lá»›p cá»§a hidden-unit bert," trong IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022, tr. 7087â€“7091.

[20] Y. Lee, K. Jang, J. Goo, Y. Jung, vÃ  H. Kim, "Fithubert: Äi má»ng hÆ¡n vÃ  sÃ¢u hÆ¡n cho chÆ°ng cáº¥t tri thá»©c há»c tá»± giÃ¡m sÃ¡t giá»ng nÃ³i," trong Proc. Interspeech, 2022.

[21] R. Wang, Q. Bai, J. Ao, L. Zhou, Z. Xiong, Z. Wei, Y. Zhang, T. Ko, vÃ  H. Li, "Lighthubert: Há»c biá»ƒu diá»…n giá»ng nÃ³i nháº¹ vÃ  cÃ³ thá»ƒ cáº¥u hÃ¬nh vá»›i hidden-unit bert má»™t-láº§n-cho-táº¥t-cáº£," trong Proc. Interspeech, 2022.

[22] T. Ashihara, T. Moriya, K. Matsuura, vÃ  T. Tanaka, "SÃ¢u so vá»›i rá»™ng: Má»™t phÃ¢n tÃ­ch cÃ¡c kiáº¿n trÃºc há»c sinh cho chÆ°ng cáº¥t tri thá»©c báº¥t kháº£ tri tÃ¡c vá»¥ cá»§a cÃ¡c mÃ´ hÃ¬nh giá»ng nÃ³i tá»± giÃ¡m sÃ¡t," trong Proc. Interspeech, 2022.

[23] T. Xiao, Y. Li, J. Zhu, Z. Yu, vÃ  T. Liu, "Chia sáº» trá»ng sá»‘ chÃº Ã½ cho transformer nhanh," trong Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI), 2019, tr. 5292â€“5298.

[24] S. Bhojanapalli, A. Chakrabarti, A. Veit, M. Lukasik, H. Jain, F. Liu, Y.-W. Chang, vÃ  S. Kumar, "Táº­n dá»¥ng dÆ° thá»«a trong chÃº Ã½ vá»›i transformer tÃ¡i sá»­ dá»¥ng," arXiv preprint arXiv:2110.06821, 2021.

[25] S. wen Yang, P.-H. Chi, Y.-S. Chuang, C.-I. J. Lai, K. Lakhotia, Y. Y. Lin, A. T. Liu, J. Shi, X. Chang, G.-T. Lin, T.-H. Huang, W.-C. Tseng, K. tik Lee, D.-R. Liu, Z. Huang, S. Dong, S.-W. Li, S. Watanabe, A. Mohamed, vÃ  H. yi Lee, "SUPERB: Benchmark Hiá»‡u suáº¥t ToÃ n cáº§u Xá»­ lÃ½ Giá»ng nÃ³i," trong Proc. Interspeech 2021, 2021, tr. 1194â€“1198.

[26] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Å. Kaiser, vÃ  I. Polosukhin, "ChÃº Ã½ lÃ  táº¥t cáº£ nhá»¯ng gÃ¬ báº¡n cáº§n," Advances in neural information processing systems, táº­p 30, 2017.

[27] A. v. d. Oord, Y. Li, vÃ  O. Vinyals, "Há»c biá»ƒu diá»…n vá»›i mÃ£ hÃ³a dá»± Ä‘oÃ¡n tÆ°Æ¡ng pháº£n," arXiv preprint arXiv:1807.03748, 2018.

[28] S. Schneider, A. Baevski, R. Collobert, vÃ  M. Auli, "wav2vec: Huáº¥n luyá»‡n trÆ°á»›c khÃ´ng giÃ¡m sÃ¡t cho nháº­n dáº¡ng giá»ng nÃ³i," trong Proc. Interspeech, 2019.

[29] K. Shim, J. Choi, vÃ  W. Sung, "Hiá»ƒu vai trÃ² cá»§a tá»± chÃº Ã½ cho nháº­n dáº¡ng giá»ng nÃ³i hiá»‡u quáº£," trong International Conference on Learning Representations, 2022.

[30] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly vÃ  cá»™ng sá»±, "Má»™t hÃ¬nh áº£nh cÃ³ giÃ¡ trá»‹ 16x16 tá»«: Transformer cho nháº­n dáº¡ng hÃ¬nh áº£nh á»Ÿ quy mÃ´," trong International Conference on Learning Representations, 2021.

[31] K. He, X. Chen, S. Xie, Y. Li, P. DollÃ¡r, vÃ  R. Girshick, "Bá»™ mÃ£ hÃ³a tá»± Ä‘á»™ng cÃ³ che giáº¥u lÃ  nhá»¯ng ngÆ°á»i há»c thá»‹ giÃ¡c cÃ³ thá»ƒ má»Ÿ rá»™ng," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, tr. 16 000â€“16 009.

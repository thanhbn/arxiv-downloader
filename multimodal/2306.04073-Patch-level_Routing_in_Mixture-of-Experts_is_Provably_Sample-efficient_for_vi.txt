# 2306.04073.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2306.04073.pdf
# Kích thước file: 2619297 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Định tuyến cấp độ patch trong Mixture-of-Experts có thể chứng minh được hiệu quả mẫu cho
Mạng thần kinh tích chập
Mohammed Nowaz Rabbani Chowdhury1Shuai Zhang1Meng Wang1Sijia Liu2 3Pin-Yu Chen4
Tóm tắt
Trong học sâu, mixture-of-experts (MoE) kích
hoạt một hoặc vài chuyên gia (mạng con) trên
cơ sở từng mẫu hoặc từng token, dẫn đến việc
giảm đáng kể tính toán. Định tuyến cấp độ patch
được đề xuất gần đây trong MoE (pMoE) chia
mỗi đầu vào thành n patch (hoặc token) và gửi l
patch (l≪n) cho mỗi chuyên gia thông qua định
tuyến ưu tiên. pMoE đã chứng minh thành công
thực nghiệm tuyệt vời trong việc giảm chi phí
đào tạo và suy luận trong khi duy trì độ chính
xác kiểm tra. Tuy nhiên, giải thích lý thuyết về
pMoE và MoE nói chung vẫn còn khó nắm bắt.
Tập trung vào tác vụ phân loại có giám sát sử
dụng hỗn hợp các mạng thần kinh tích chập hai
lớp (CNN), chúng tôi lần đầu tiên chỉ ra rằng
pMoE có thể chứng minh được việc giảm số
lượng mẫu đào tạo cần thiết để đạt được khái
quát hóa mong muốn (được gọi là độ phức tạp
mẫu) theo một thừa số trong bậc đa thức của
n/l, và vượt trội hơn đối tác chuyên gia đơn có
cùng hoặc thậm chí lớn hơn dung lượng. Lợi
thế này xuất phát từ tính chất định tuyến phân
biệt, được chứng minh trong cả lý thuyết và
thực hành rằng các bộ định tuyến pMoE có thể
lọc các patch không liên quan đến nhãn và định
tuyến các patch phân biệt lớp tương tự đến cùng
một chuyên gia. Kết quả thực nghiệm của chúng
tôi trên MNIST, CIFAR-10 và CelebA hỗ trợ
các phát hiện lý thuyết của chúng tôi về khái
quát hóa của pMoE và cho thấy rằng pMoE có
thể tránh học các tương quan giả tạo.

1Khoa Kỹ thuật Điện, Máy tính và Hệ thống, Viện Công nghệ
Rensselaer, NY, USA2Khoa Khoa học Máy tính và Kỹ thuật,
Đại học Bang Michigan, MI, USA3MIT-IBM Watson AI Lab, IBM
Research, MA, USA4IBM Research, Yorktown Heights, NY, USA.
Liên hệ: Mohammed Nowaz Rabbani Chowdhury <chowdm2@rpi.edu>,
Meng Wang <wangm7@rpi.edu>.

Kỷ yếu Hội nghị Quốc tế lần thứ 40 về Học Máy, Honolulu, Hawaii,
USA. PMLR 202, 2023. Bản quyền 2023 thuộc về (các) tác giả.

Hình 1. Minh họa pMoE. Hình ảnh được chia thành 20 patch trong khi bộ định tuyến chọn 4 trong số chúng cho mỗi chuyên gia.

1. Giới thiệu
Học sâu đã chứng minh thành công thực nghiệm đặc biệt trong nhiều ứng dụng với chi phí là yêu cầu tính toán và dữ liệu cao. Để giải quyết vấn đề này, mixture-of-experts (MoE) chỉ kích hoạt các vùng cục bộ của mạng thần kinh cho mỗi điểm dữ liệu và giảm đáng kể độ phức tạp tính toán của học sâu mà không ảnh hưởng đến hiệu suất trong các ứng dụng như dịch máy và phân loại hình ảnh tự nhiên (Shazeer et al., 2017; Yang et al., 2019). Một mô hình MoE thông thường chứa nhiều chuyên gia (mạng con của kiến trúc chính) và một bộ định tuyến có thể học được định tuyến mỗi mẫu đầu vào đến một vài nhưng không phải tất cả các chuyên gia (Ramachandran & Le, 2018). MoE theo vị trí đã được giới thiệu trong các mô hình ngôn ngữ (Shazeer et al., 2017; Lepikhin et al., 2020; Fedus et al., 2022), nơi các quyết định định tuyến được thực hiện trên các embedding của các vị trí khác nhau của đầu vào riêng biệt thay vì định tuyến toàn bộ đầu vào văn bản. Riquelme et al. (2021) đã mở rộng nó cho các mô hình thị giác nơi các quyết định định tuyến được thực hiện trên các patch hình ảnh. Zhou et al. (2022) đã mở rộng thêm nơi lớp MoE có một bộ định tuyến cho mỗi chuyên gia sao cho bộ định tuyến chọn các patch cục bộ cho chuyên gia tương ứng và loại bỏ các patch còn lại. Chúng tôi gọi chế độ định tuyến này là định tuyến cấp độ patch và lớp MoE là lớp patch-level MoE (pMoE) (xem Hình 1 để minh họa pMoE). Đáng chú ý, pMoE đạt được cùng độ chính xác kiểm tra trong các tác vụ thị giác với 20% ít tính toán đào tạo hơn và 50% ít tính toán suy luận hơn so với đối tác chuyên gia đơn (tức là một chuyên gia nhận tất cả các patch của một đầu vào) có cùng dung lượng (Riquelme et al., 2021).

Mặc dù thành công thực nghiệm của MoE, về lý thuyết vẫn còn khó hiểu tại sao MoE có thể duy trì độ chính xác kiểm tra trong khi giảm đáng kể lượng tính toán? Theo hiểu biết tốt nhất của chúng tôi, chỉ có một công trình gần đây của Chen et al. (2022) chỉ ra về mặt lý thuyết rằng MoE theo mẫu thông thường đạt được độ chính xác kiểm tra cao hơn so với mạng thần kinh tích chập (CNN) trong một thiết lập đặc biệt của tác vụ phân loại nhị phân trên dữ liệu từ các cụm tách tuyến tính. Tuy nhiên, các phân tích theo mẫu của Chen et al. (2022) không mở rộng cho patch-level MoE, vốn sử dụng các chiến lược định tuyến khác với MoE thông thường, và mô hình dữ liệu của họ có thể không đặc trưng cho một số bộ dữ liệu thực tế. Bài báo này giải quyết câu hỏi sau về mặt lý thuyết:

pMoE tiết kiệm bao nhiều tài nguyên tính toán từ đối tác chuyên gia đơn trong khi duy trì cùng bảo đảm khái quát hóa?

Trong bài báo này, chúng tôi xem xét tác vụ phân loại nhị phân có giám sát nơi mỗi mẫu đầu vào bao gồm n patch có kích thước bằng nhau bao gồm các mẫu phân biệt lớp xác định nhãn và các mẫu không liên quan đến lớp không ảnh hưởng đến nhãn. Mạng thần kinh chứa một lớp pMoE1 và nhiều chuyên gia, mỗi chuyên gia là một CNN hai lớp2 có cùng kiến trúc. Bộ định tuyến gửi l (l≪n) patch cho mỗi chuyên gia. Mặc dù chúng tôi xem xét một mô hình mạng thần kinh đơn giản để tạo điều kiện cho việc phân tích chính thức của pMoE, các hiểu biết có thể áp dụng cho các thiết lập tổng quát hơn.

Các kết quả chính của chúng tôi bao gồm:

1. Theo hiểu biết tốt nhất của chúng tôi, bài báo này cung cấp phân tích khái quát hóa lý thuyết đầu tiên của pMoE. Phân tích của chúng tôi tiết lộ rằng pMoE với CNN hai lớp làm chuyên gia có thể đạt được hiệu suất khái quát hóa tương tự như CNN thông thường trong khi giảm độ phức tạp mẫu (số lượng mẫu đào tạo cần thiết để học một mô hình phù hợp) và độ phức tạp mô hình. Cụ thể, chúng tôi chứng minh rằng miễn là l lớn hơn một ngưỡng nhất định, pMoE giảm độ phức tạp mẫu và độ phức tạp mô hình theo một thừa số đa thức trong n/l, cho thấy khái quát hóa cải thiện với l nhỏ hơn.

2. Đặc trưng hóa tính chất mong muốn của bộ định tuyến pMoE. Chúng tôi chỉ ra rằng một bộ định tuyến pMoE mong muốn có thể gửi các mẫu phân biệt lớp giống nhau đến cùng một chuyên gia và loại bỏ một số mẫu không liên quan đến lớp. Tính chất phân biệt này cho phép các chuyên gia học các mẫu phân biệt lớp với sự can thiệp giảm từ các mẫu không liên quan, từ đó giảm độ phức tạp mẫu và độ phức tạp mô hình. Chúng tôi cũng chứng minh về mặt lý thuyết rằng một bộ định tuyến pMoE được đào tạo riêng biệt có tính chất mong muốn và xác minh thực nghiệm tính chất này trên các bộ định tuyến pMoE thực tế.

3. Chứng minh thực nghiệm về việc giảm độ phức tạp mẫu bởi pMoE trong các mô hình CNN sâu. Ngoài việc xác minh các phát hiện lý thuyết của chúng tôi trên dữ liệu tổng hợp được chuẩn bị từ bộ dữ liệu MNIST (LeCun et al., 2010), chúng tôi chứng minh hiệu quả mẫu của pMoE trong việc học một số bộ dữ liệu thị giác chuẩn (ví dụ: CIFAR-10 (Krizhevsky, 2009) và CelebA (Liu et al., 2015)) bằng cách thay thế lớp tích chập cuối cùng của một mạng dư rộng mười lớp (WRN) (Zagoruyko & Komodakis, 2016) bằng một lớp pMoE. Các thí nghiệm này không chỉ xác minh các phát hiện lý thuyết của chúng tôi mà còn chứng minh khả năng áp dụng của pMoE trong việc giảm độ phức tạp mẫu trong các mô hình thị giác dựa trên CNN sâu, bổ sung cho thành công thực nghiệm hiện có của pMoE với các transformer thị giác.

2. Các công trình liên quan
Mixture-of-Experts. MoE lần đầu tiên được giới thiệu vào những năm 1990 với định tuyến dày đặc theo mẫu, tức là mỗi mẫu đầu vào được định tuyến đến tất cả các chuyên gia (Jacobs et al., 1991; Jordan & Jacobs, 1994; Chen et al., 1999; Tresp, 2000; Rasmussen & Ghahramani, 2001). Định tuyến thưa theo mẫu sau đó được giới thiệu (Bengio et al., 2013; Eigen et al., 2013), nơi mỗi mẫu đầu vào kích hoạt vài chuyên gia trong một lớp MoE cả cho đào tạo chung (Ramachandran & Le, 2018; Yang et al., 2019) và đào tạo riêng biệt của bộ định tuyến và chuyên gia (Collobert et al., 2001; 2003; Ahmed et al., 2016; Gross et al., 2017). MoE theo vị trí/patch (tức là pMoE) gần đây đã chứng minh thành công trong các mô hình ngôn ngữ và thị giác lớn (Shazeer et al., 2017; Lepikhin et al., 2020; Riquelme et al., 2021; Fedus et al., 2022). Để giải quyết vấn đề mất cân bằng tải (Lewis et al., 2021), Zhou et al. (2022) giới thiệu định tuyến lựa chọn chuyên gia trong pMoE, nơi mỗi chuyên gia sử dụng một bộ định tuyến để chọn một số lượng cố định các patch từ đầu vào. Bài báo này phân tích MoE cấp độ patch thưa với định tuyến lựa chọn chuyên gia dưới cả hai thiết lập đào tạo chung và đào tạo riêng biệt.

Phân tích tối ưu hóa và khái quát hóa của mạng thần kinh (NN). Do tính phi lồi đáng kể của bài toán học sâu, các phân tích khái quát hóa hiện có bị hạn chế đối với các mạng thần kinh tuyến tính hóa hoặc nông. Phương pháp Neural-Tangent-Kernel (NTK) (Jacot et al., 2018; Lee et al., 2019; Du et al., 2019; Allen-Zhu et al., 2019b; Zou et al., 2020; Chizat et al., 2019; Ghorbani et al., 2021) xem xét việc tham số hóa quá mức mạnh và xấp xỉ mạng thần kinh bằng khai triển Taylor bậc nhất. Các kết quả NTK độc lập với dữ liệu đầu vào, và tồn tại khoảng cách hiệu suất trong khả năng biểu diễn và khả năng khái quát hóa giữa NN thực tế và kết quả NTK (Yehudai & Shamir, 2019; Ghorbani et al., 2019; 2020; Li et al., 2020; Malach et al., 2021). Các mạng thần kinh phi tuyến được phân tích gần đây thông qua các khai triển Taylor bậc cao hơn (Allen-Zhu et al., 2019a; Bai & Lee, 2019; Arora et al., 2019; Ji & Telgarsky, 2019) hoặc sử dụng phương pháp ước lượng mô hình từ dữ liệu đầu vào Gaussian (Zhong et al., 2017b;a; Zhang et al., 2020b;a; Fu et al., 2020; Li et al., 2022b), nhưng những kết quả này bị hạn chế đối với các mạng hai lớp với vài bài báo về mạng ba lớp (Allen-Zhu et al., 2019a; Allen-Zhu & Li, 2019; 2020a; Li et al., 2022a).

Các công trình trên xem xét dữ liệu đầu vào tùy ý hoặc dữ liệu đầu vào Gaussian. Để đặc trưng hóa tốt hơn hiệu suất khái quát hóa thực tế, một số công trình gần đây phân tích các mô hình dữ liệu có cấu trúc sử dụng các phương pháp như ánh xạ đặc trưng (Li & Liang, 2018), nơi một số trọng số mô hình ban đầu gần với các đặc trưng dữ liệu, và học đặc trưng (Daniely & Malach, 2020; Shalev-Shwartz et al., 2020; Shi et al., 2021; Allen-Zhu & Li, 2022; Li et al., 2023), nơi một số trọng số dần dần học các đặc trưng trong quá trình đào tạo. Trong số đó, Allen-Zhu & Li (2020b); Brutzkus & Globerson (2021); Karp et al. (2021) phân tích CNN về việc học dữ liệu có cấu trúc bao gồm các mẫu phân biệt lớp xác định nhãn và các mẫu không liên quan đến nhãn khác. Bài báo này mở rộng các mô hình dữ liệu trong Allen-Zhu & Li (2020b); Brutzkus & Globerson (2021); Karp et al. (2021) thành một thiết lập tổng quát hơn, và phương pháp phân tích của chúng tôi là sự kết hợp của học đặc trưng trong các bộ định tuyến và ánh xạ đặc trưng trong các chuyên gia cho pMoE.

3. Xây dựng bài toán
Bài báo này xem xét bài toán phân loại nhị phân có giám sát3 nơi cho trước N mẫu đào tạo i.i.d. {(xi, yi)}N i=1 được tạo bởi một phân bố chưa biết D, mục tiêu là học một mô hình mạng thần kinh ánh xạ x thành y cho bất kỳ (x, y) nào được lấy mẫu từ D. Ở đây, đầu vào x∈Rnd có n patch rời rạc, tức là x⊺= [x(1)⊺, x(2)⊺, ..., x(n)⊺], nơi x(j)∈Rd biểu thị patch thứ j của x. y∈ {+1,−1} biểu thị nhãn tương ứng.

3Kết quả của chúng tôi có thể mở rộng cho các bài toán phân loại đa lớp. Xem Phần M trong Phụ lục để biết chi tiết.

3.1. Các mô hình mạng thần kinh
Chúng tôi xem xét một kiến trúc pMoE bao gồm k chuyên gia và k bộ định tuyến tương ứng. Mỗi bộ định tuyến chọn l trong số n (l < n) patch cho mỗi chuyên gia riêng biệt. Cụ thể, bộ định tuyến cho mỗi chuyên gia s (s∈[k]) chứa một kernel gating có thể đào tạo được ws∈Rd. Cho một mẫu x, bộ định tuyến tính toán giá trị định tuyến gj,s(x) =⟨ws, x(j)⟩ cho mỗi patch j. Gọi Js(x) biểu thị tập chỉ số của l giá trị hàng đầu của gj,s trong tất cả các patch j∈[n]. Chỉ các patch có chỉ số trong Js(x) được định tuyến đến chuyên gia s, nhân với giá trị gating Gj,s(x), được chọn khác nhau trong các mô hình pMoE khác nhau.

Mỗi chuyên gia là một CNN hai lớp có cùng kiến trúc. Gọi m biểu thị tổng số neuron trong tất cả các chuyên gia. Khi đó mỗi chuyên gia chứa (m/k) neuron. Gọi wr,s∈Rd và ar,s∈R biểu thị các trọng số lớp ẩn và lớp đầu ra cho neuron r (r∈[m/k]) trong chuyên gia s (s∈[k]), tương ứng. Hàm kích hoạt là đơn vị tuyến tính chỉnh lưu (ReLU), nơi ReLU (z) =max(0, z).

Gọi θ={ar,s, wr,s, ws,∀s∈[k],∀r∈[m/k]} bao gồm tất cả các trọng số có thể đào tạo được. Mô hình pMoE được ký hiệu là fM, được định nghĩa như sau:

fM(θ, x) =k∑ s=1 m k∑ r=1 ar,s l∑ j∈Js(ws,x) ReLU (⟨wr,s, x(j)⟩)Gj,s(ws, x) (1)

Một minh họa của (1) được đưa ra trong Hình 2.

Hình 2. Minh họa mô hình pMoE trong (1) với k= 3, m= 6, n= 6, và l= 2.

Bài toán học giải quyết bài toán tối thiểu hóa rủi ro thực nghiệm sau với hàm mất mát logistic,

min θ:L(θ) =1 N N∑ i=1 log (1 + e−yifM(θ,xi)) (2)

Chúng tôi xem xét hai chế độ đào tạo khác nhau của pMoE, Đào tạo riêng biệt và Đào tạo chung của các bộ định tuyến và các chuyên gia. Chúng tôi cũng xem xét kiến trúc CNN thông thường để so sánh.

(I) pMoE đào tạo riêng biệt: Dưới thiết lập của cái gọi là hỗn hợp cứng của các chuyên gia (Collobert et al., 2003; Ahmed et al., 2016; Gross et al., 2017), các trọng số bộ định tuyến ws được đào tạo trước và sau đó cố định khi đào tạo các trọng số của các chuyên gia. Trong trường hợp này, các giá trị gating được đặt là Gj,s(ws, x)≡1,∀j, s, x (3) Chúng tôi chọn k= 2 trong trường hợp này để đơn giản hóa phân tích.

(II) pMoE đào tạo chung: Các bộ định tuyến và các chuyên gia được học chung, xem, ví dụ, (Lepikhin et al., 2020; Riquelme et al., 2021; Fedus et al., 2022). Ở đây, các giá trị gating là các hàm softmax với Gj,s(ws, x) =egj,s(x)/(∑ i∈Js(x) gi,s(x)) (4)

(III) Đối tác CNN chuyên gia đơn: CNN hai lớp thông thường với m neuron, được ký hiệu là fC, thỏa mãn, fC(θ, x) =m∑ r=1 ar( 1 n n∑ j=1 ReLU (⟨wr, x(j)⟩) ) (5)

Phương trình (5) có thể được xem như một trường hợp đặc biệt của (1) khi chỉ có một chuyên gia (k= 1), và tất cả các patch được gửi đến chuyên gia (l=n) với các giá trị gating Gj,s≡1.

Gọi ˜θ biểu thị các tham số của mô hình đã học bằng cách giải quyết (1). Nhãn dự đoán cho một mẫu kiểm tra x bởi mô hình đã học là sign(fM(˜θ, x)). Độ chính xác khái quát hóa, tức là phần phân số của các dự đoán chính xác của tất cả các mẫu kiểm tra bằng P (x,y)∼D[yfM(θ, x)>0]. Bài báo này nghiên cứu cả đào tạo riêng biệt và đào tạo chung của pMoE và so sánh hiệu suất của chúng với CNN, từ góc độ độ phức tạp mẫu để đạt được độ chính xác khái quát hóa mong muốn.

3.2. Các thuật toán đào tạo
Trong các thuật toán sau, chúng tôi cố định các trọng số lớp đầu ra ar,s và ar tại các giá trị ban đầu của chúng được lấy mẫu ngẫu nhiên từ phân bố Gaussian chuẩn N(0,1) và không cập nhật chúng trong quá trình đào tạo. Đây là một đơn giản hóa điển hình khi phân tích NN, như được sử dụng trong (Li & Liang, 2018; Brutzkus et al., 2018; Allen-Zhu et al., 2019a; Arora et al., 2019).

(I) pMoE đào tạo riêng biệt: Các bộ định tuyến được đào tạo riêng biệt sử dụng Nr mẫu đào tạo (Nr< N), được ký hiệu bởi {(xi, yi)}Nr i=1 mà không mất tính tổng quát. Các kernel gating w1 và w2 được thu được bằng cách giải quyết bài toán tối thiểu hóa sau:

min w1,w2:lr(w1, w2) =−1 Nr Nr∑ i=1 yi⟨w1−w2, n∑ j=1 x(j) i ⟩ (6)

Để giải quyết (6), chúng tôi thực hiện SGD mini-batch với kích thước batch Br cho Tr=Nr/Br lần lặp, bắt đầu từ khởi tạo ngẫu nhiên như sau:

w(0) s ∼ N(0, σ2 r Id×d),∀s∈[2] (7)

nơi, σr= Θ( 1 (n2log (poly(n))√ d) ).

Sau khi học các bộ định tuyến, chúng tôi đào tạo các trọng số lớp ẩn wr,s bằng cách giải quyết (2) trong khi cố định w1 và w2. Chúng tôi thực hiện mini-batch SGD của kích thước batch B cho T=N/B lần lặp bắt đầu từ khởi tạo

w(0) r,s ∼ N(0, 1 m Id×d),∀s∈[2],∀r∈[m/2] (8)

(II) pMoE đào tạo chung: ws và wr,s trong (1) được cập nhật đồng thời bằng mini-batch SGD của kích thước batch B cho T= N/B lần lặp bắt đầu từ khởi tạo trong (7) và (8).

(III) CNN: wr trong (5) được cập nhật bằng mini-batch SGD của kích thước batch B cho T= N/B lần lặp bắt đầu từ khởi tạo trong (8).

4. Kết quả lý thuyết
4.1. Các phát hiện chính tóm tắt
Trước khi định nghĩa các giả định mô hình dữ liệu và lý do trong Phần 4.2 và trình bày các kết quả chính thức trong 4.3, chúng tôi trước tiên tóm tắt các phát hiện chính của chúng tôi. Chúng tôi giả sử rằng các patch dữ liệu được lấy mẫu từ các mẫu phân biệt lớp xác định nhãn hoặc một số có thể vô hạn các mẫu không liên quan đến lớp không có tác động đến nhãn. Tham số δ (được định nghĩa trong (9)) có liên quan nghịch đảo với sự tách biệt giữa các mẫu, tức là δ giảm khi (i) sự tách biệt giữa các mẫu phân biệt lớp tăng, và/hoặc (ii) sự tách biệt giữa các mẫu phân biệt lớp và không liên quan đến lớp tăng. Các phát hiện chính như sau.

(I). Một bộ định tuyến cấp độ patch được đào tạo đúng cách gửi các patch phân biệt lớp của một lớp đến cùng một chuyên gia trong khi loại bỏ một số patch không liên quan đến lớp. Chúng tôi chứng minh rằng pMoE đào tạo riêng biệt định tuyến các patch phân biệt lớp của lớp với nhãn y= +1 (hoặc lớp với nhãn y=−1) đến chuyên gia 1 (hoặc chuyên gia 2) tương ứng, và các mẫu không liên quan đến lớp đủ xa từ các mẫu phân biệt lớp không được định tuyến đến bất kỳ chuyên gia nào (Bổ đề 4.1). Tính chất định tuyến phân biệt này cũng được xác minh thực nghiệm cho pMoE đào tạo chung (xem phần 5.1). Do đó, pMoE hiệu quả giảm sự can thiệp của các patch không liên quan khi mỗi chuyên gia học các mẫu phân biệt lớp. Hơn nữa, chúng tôi chỉ ra thực nghiệm rằng pMoE có thể loại bỏ các patch không liên quan đến lớp có tương quan giả tạo với nhãn lớp và do đó có thể tránh học từ các đặc trưng tương quan giả tạo của dữ liệu.

(II). Cả độ phức tạp mẫu và số lượng nút ẩn cần thiết của pMoE đều giảm theo thừa số đa thức của n/l so với CNN. Chúng tôi chứng minh rằng miễn là l, số lượng patch trên mỗi chuyên gia, lớn hơn một ngưỡng (giảm khi sự tách biệt giữa các mẫu phân biệt lớp và không liên quan đến lớp tăng), độ phức tạp mẫu và số lượng neuron cần thiết để học pMoE lần lượt là Ω(l8) và Ω(l10). Ngược lại, độ phức tạp mẫu và mô hình của CNN lần lượt là Ω(n8) và Ω(n10), cho thấy khái quát hóa được cải thiện bởi pMoE.

(III). Sự tách biệt lớn hơn giữa các mẫu phân biệt lớp và không liên quan đến lớp làm giảm độ phức tạp mẫu và độ phức tạp mô hình của pMoE. Cả độ phức tạp mẫu và số lượng neuron cần thiết của pMoE đều đa thức trong δ, giảm khi sự tách biệt giữa các mẫu tăng.

4.2. Các giả định mô hình dữ liệu và lý do
Đầu vào x bao gồm một mẫu phân biệt lớp và n−1 mẫu không liên quan đến lớp, và nhãn y được xác định chỉ bởi mẫu phân biệt lớp.

Phân bố của các mẫu phân biệt lớp: Các vector đơn vị o1 và o2∈Rd biểu thị các mẫu phân biệt lớp xác định nhãn. Sự tách biệt giữa o1 và o2 được đo bằng δd:=⟨o1, o2⟩ ∈(−1,1). o1 và o2 được phân bố đều trong các mẫu, và mỗi mẫu có chính xác một trong số chúng. Nếu x chứa o1 (hoặc o2), thì y là +1 (hoặc −1).

Phân bố của các mẫu không liên quan đến lớp. Các mẫu không liên quan đến lớp là các vector đơn vị trong Rd thuộc về p tập mẫu rời rạc S1, S2, ...., Sp, và các mẫu này phân bố đều cho cả hai lớp. δr đo sự tách biệt giữa các mẫu phân biệt lớp và không liên quan đến lớp, nơi |⟨oi, q⟩| ≤δr,∀i∈[2],∀q∈Sj,j= 1, ..., p. Mỗi Sj thuộc về một quả cầu có đường kính Θ(√ (1−δ2r)/dp2). Lưu ý rằng KHÔNG có sự tách biệt giữa các mẫu không liên quan đến lớp với nhau được yêu cầu.

Lý do của mô hình dữ liệu của chúng tôi. Phân bố dữ liệu D nắm bắt tính địa phương của các đặc trưng định nghĩa nhãn trong dữ liệu hình ảnh. Nó được động lực và mở rộng từ các phân bố dữ liệu trong các khung lý thuyết gần đây (Yu et al., 2019; Brutzkus & Globerson, 2021; Karp et al., 2021; Chen et al., 2022). Cụ thể, Yu et al. (2019) và Brutzkus & Globerson (2021) yêu cầu các mẫu trực giao, tức là δr và δd đều bằng 0, và chỉ có một số lượng cố định các mẫu không phân biệt. Karp et al. (2021) và Chen et al. (2022) giả sử rằng δd=−1 và một số có thể vô hạn các mẫu được rút ra từ phân bố Gaussian có trung bình bằng không. Trong mô hình của chúng tôi, δd lấy bất kỳ giá trị nào trong (−1,1), và các mẫu không liên quan đến lớp có thể được rút ra từ p tập mẫu chứa số lượng vô hạn các mẫu không nhất thiết phải là Gaussian hoặc trực giao.

Định nghĩa δ= 1/(1−max( δ2 d, δ2 r)) (9)

δ giảm nếu (1) o1 và o2 tách biệt hơn với nhau, và (2) Cả o1 và o2 đều tách biệt hơn từ bất kỳ tập Si nào, i∈[p]. Chúng tôi cũng định nghĩa một số nguyên l∗ (l∗≤n) đo số lượng tối đa các mẫu không liên quan đến lớp trên mỗi mẫu đủ gần với o1 hơn o2, và ngược lại. Cụ thể, một mẫu không liên quan đến lớp q được gọi là δ′-gần hơn (δ′>0) với o1 hơn o2, nếu ⟨o1−o2, q⟩> δ′ giữ. Tương tự, q δ′-gần hơn với o2 hơn o1 nếu ⟨o2−o1, q⟩> δ′. Sau đó, gọi l∗−1 là số lượng tối đa các patch không liên quan đến lớp hoặc δ′-gần hơn với o1 hơn o2 hoặc ngược lại với δ′= Θ(1 −δd) trong bất kỳ x nào được lấy mẫu từ D. l∗ phụ thuộc vào D và δd. Khi D được cố định, một δd nhỏ hơn tương ứng với sự tách biệt lớn hơn giữa o1 và o2 và dẫn đến l∗ nhỏ. Trái ngược với dữ liệu tách tuyến tính trong (Yu et al., 2019; Brutzkus et al., 2018; Chen et al., 2022), mô hình dữ liệu của chúng tôi KHÔNG tách tuyến tính miễn là l∗= Ω(1) (xem phần K trong Phụ lục để biết chứng minh).

4.3. Kết quả lý thuyết chính
4.3.1. BẢO ĐẢM KHÁI QUÁT HÓA CỦA PMOE ĐÀO TẠO RIÊNG BIỆT

Bổ đề 4.1 chỉ ra rằng miễn là số lượng patch trên mỗi chuyên gia, l, lớn hơn l∗, thì các bộ định tuyến được học riêng biệt bằng cách giải quyết (6) luôn gửi o1 đến chuyên gia 1 và o2 đến chuyên gia 2. Dựa trên tính chất phân biệt này của các bộ định tuyến đã học, Định lý 4.2 sau đó định lượng độ phức tạp mẫu và kích thước mạng của pMoE đào tạo riêng biệt để đạt được lỗi khái quát hóa mong muốn ϵ. Định lý 4.3 định lượng độ phức tạp mẫu và mô hình của CNN để so sánh.

Bổ đề 4.1 (Tính chất phân biệt của các bộ định tuyến được đào tạo riêng biệt). Đối với mỗi l≥l∗, w.h.p. trên khởi tạo ngẫu nhiên được định nghĩa trong (7), sau khi hoàn thành Bước-2 của Thuật toán-1 với kích thước batch Br=Ω̃ ( n2/(1−δd)2 ) và tỷ lệ học ηr= Θ(1/n) cho Tr= Ω ( 1/(1−δd) ) lần lặp, w1(Tr) và w2(Tr) trả về thỏa mãn

arg j∈[n](x(j)=o1)∈J1(w1(Tr), x),∀(x, y= +1) ∼ D arg j∈[n](x(j)=o2)∈J2(w2(Tr), x),∀(x, y=−1)∼ D

tức là, các bộ định tuyến đã học luôn gửi o1 đến chuyên gia 1 và o2 đến chuyên gia 2.

Ý tưởng chính trong việc chứng minh Bổ đề 4.1 là chỉ ra rằng gradient trong mỗi lần lặp có một thành phần lớn dọc theo hướng của o1 và o2. Sau đó sau đủ lần lặp, tích vô hướng của w1 và o1 (tương tự, w2 và o2) đủ lớn. Trực giác của việc yêu cầu l≥l∗ là bởi vì có tối đa l∗−1 patch không liên quan đến lớp đủ gần với o1 hơn o2 (hoặc ngược lại), thì việc gửi l≥l∗ patch đến một chuyên gia sẽ đảm bảo rằng một trong số chúng là o1 (hoặc o2). Lưu ý rằng kích thước batch Br và số lần lặp Tr phụ thuộc vào δd, sự tách biệt giữa o1 và o2, nhưng độc lập với sự tách biệt giữa các mẫu phân biệt lớp và không liên quan đến lớp.

Sau đó chúng tôi chỉ ra rằng pMoE đào tạo riêng biệt giảm cả độ phức tạp mẫu và kích thước mô hình cần thiết (Định lý 4.2) so với CNN (Định lý 4.3).

Định lý 4.2 (Bảo đảm khái quát hóa của pMoE đào tạo riêng biệt). Đối với mỗi ϵ >0 và l≥l∗, đối với mỗi m≥MS= Ω ( l10p12δ6/ϵ16 ) với ít nhất NS= Ω(l8p12δ6/ϵ16) mẫu đào tạo, sau khi thực hiện minibatch SGD với kích thước batch B= Ω ( l4p6δ3/ϵ8 ) và tỷ lệ học η= O ( 1/(mpoly(l, p, δ, 1/ϵ,logm)) ) cho T=O ( l4p6δ3/ϵ8 ) lần lặp, nó giữ w.h.p. rằng P (x,y)∼D [ yfM(θ(T), x)>0 ] ≥1−ϵ

Định lý 4.2 ngụ ý rằng để đạt được lỗi khái quát hóa ϵ bằng một pMoE đào tạo riêng biệt, chúng ta cần NS= Ω( l8p12δ6/ϵ16) mẫu đào tạo và MS= Ω ( l10p12δ6/ϵ16 ) nút ẩn. Do đó, cả NS và MS đều tăng đa thức với số lượng patch l được gửi đến mỗi chuyên gia. Hơn nữa, cả NS và MS đều đa thức trong δ được định nghĩa trong (9), cho thấy hiệu suất khái quát hóa được cải thiện với sự tách biệt mạnh hơn giữa các mẫu.

Chứng minh của Định lý 4.2 được lấy cảm hứng từ Li & Liang (2018), phân tích hiệu suất khái quát hóa của mạng thần kinh kết nối đầy đủ (FCN) trên dữ liệu có cấu trúc, nhưng chúng tôi có những đóng góp kỹ thuật mới trong việc phân tích các mô hình pMoE. Ngoài việc phân tích các bộ định tuyến pMoE (Bổ đề 4.1), không xuất hiện trong phân tích FCN, các phân tích của chúng tôi cũng giảm đáng kể yêu cầu tách biệt trên dữ liệu, so với Li & Liang (2018). Ví dụ, Li & Liang (2018) yêu cầu sự tách biệt giữa hai lớp, được đo bằng khoảng cách chuẩn ℓ2 nhỏ nhất của hai điểm trong các lớp khác nhau, là Ω(n) để có được ràng buộc độ phức tạp mẫu của poly( n) cho tác vụ phân loại nhị phân. Ngược lại, sự tách biệt giữa hai lớp trong mô hình dữ liệu của chúng tôi là min{√ 2(1−δd),2√1−δr}, ít hơn nhiều so với Ω(n) được yêu cầu bởi Li & Liang (2018).

Định lý 4.3 (Bảo đảm khái quát hóa của CNN). Đối với mỗi ϵ > 0, đối với mỗi m≥MC= Ω ( n10p12δ6/ϵ16 ) với ít nhất NC= Ω( n8p12δ6/ϵ16) mẫu đào tạo, sau khi thực hiện minibatch SGD với kích thước batch B= Ω ( n4p6δ3/ϵ8 ) và tỷ lệ học η=O ( 1/(mpoly(n, p, δ, 1/ϵ,logm)) ) cho T= O ( n4p6δ3/ϵ8 ) lần lặp, nó giữ w.h.p. rằng P (x,y)∼D [ yfC(θ(T), x)>0 ] ≥1−ϵ

Định lý 4.3 ngụ ý rằng để đạt được lỗi khái quát hóa ϵ sử dụng CNN trong (5), chúng ta cần NC= Ω(n8p12δ6/ϵ16) mẫu đào tạo và MC= Ω ( n10p12δ6/ϵ16 ) neuron.

Khoảng cách độ phức tạp mẫu giữa CNN đơn và hỗn hợp CNN. Từ Định lý 4.2 và Định lý 4.3, tỷ lệ độ phức tạp mẫu của CNN với pMoE đào tạo riêng biệt là NC/NS= Θ ( (n/l)8 ). Tương tự, số lượng neuron cần thiết được giảm theo thừa số MC/MS= Θ ( (n/l)10 ) trong pMoE đào tạo riêng biệt4.

4.3.2. BẢO ĐẢM KHÁI QUÁT HÓA CỦA PMOE ĐÀO TẠO CHUNG VỚI CÁC BỘ ĐỊNH TUYẾN THÍCH HỢP

Định lý 4.5 đặc trưng hóa hiệu suất khái quát hóa của pMoE đào tạo chung giả sử các bộ định tuyến được đào tạo đúng cách theo nghĩa là sau một số lần lặp SGD, đối với mỗi lớp ít nhất một trong k chuyên gia nhận tất cả các patch phân biệt lớp của lớp đó với giá trị gating lớn nhất (xem Giả định 4.4).

Giả định 4.4. Tồn tại một số nguyên T′< T sao cho với tất cả t≥T′, nó giữ rằng: Tồn tại một chuyên gia s∈[k] s.t.∀(x, y= +1) ∼ D, jo1∈Js(w(t) s, x), và G(t) jo1,s(x)≥G(t) j,s(x) và một chuyên gia s∈[k] s.t.∀(x, y=−1)∼ D, jo2∈Js(w(t) s, x), và G(t) jo2,s(x)≥G(t) j,s(x)

nơi jo1 (jo2) biểu thị chỉ số của mẫu phân biệt lớp o1 (o2), G(t) j,s(x) là đầu ra gating của patch j∈ Js(w(t) s, x) của mẫu x cho chuyên gia s tại lần lặp t, và w(t) s là kernel gating cho chuyên gia s tại lần lặp t.

Giả định 4.4 được yêu cầu trong việc chứng minh Định lý 4.5 vì khó khăn trong việc theo dõi động lực của các bộ định tuyến trong pMoE đào tạo chung. Giả định 4.4 được xác minh trên các thí nghiệm thực nghiệm trong Phần 5.1, trong khi chứng minh lý thuyết của nó được để lại cho công việc tương lai.

Định lý 4.5 (Bảo đảm khái quát hóa của pMoE đào tạo chung). Giả sử Giả định 4.4 giữ. Thì đối với mỗi ϵ > 0, đối với mỗi m≥MJ= Ω ( k3n2l6p12δ6/ϵ16 ) với ít nhất NJ= Ω( k4l6p12δ6/ϵ16) mẫu đào tạo, sau khi thực hiện minibatch SGD với kích thước batch B= Ω ( k2l4p6δ3/ϵ8 ) và tỷ lệ học η=O ( 1/(mpoly(l, p, δ, 1/ϵ,logm)) ) cho T= O ( k2l2p6δ3/ϵ8 ) lần lặp, nó giữ w.h.p. rằng P (x,y)∼D [ yfM(θ(T), x)>0 ] ≥1−ϵ

Định lý 4.5 cho thấy rằng, với các bộ định tuyến thích hợp, pMoE đào tạo chung cần NJ= Ω(k4l6p12δ6/ϵ16) mẫu đào tạo và MJ= Ω ( k3n2l6p12δ6/ϵ16 ) neuron để đạt được lỗi khái quát hóa ϵ. So với CNN trong Định lý 4.3, pMoE đào tạo chung giảm độ phức tạp mẫu và kích thước mô hình theo thừa số Θ(n8/k4l6) và Θ(n10/k3l6), tương ứng. Với nhiều chuyên gia hơn (k lớn hơn), việc thỏa mãn Giả định 4.4 để học các bộ định tuyến thích hợp dễ dàng hơn nhưng yêu cầu độ phức tạp mẫu và mô hình lớn hơn. Khi số lượng mẫu được cố định, biểu thức của NJ cũng cho thấy rằng ϵ tỷ lệ như k1/4l3/8, tương ứng với khái quát hóa được cải thiện khi k và l giảm.

Chúng tôi cung cấp so sánh độ phức tạp tính toán từ đầu đến cuối giữa các mô hình pMoE được phân tích và mô hình CNN tổng quát trong Bảng 1 (xem phần N trong Phụ lục để biết chi tiết). Các kết quả trong Bảng 1 cho thấy rằng độ phức tạp tính toán trong pMoE đào tạo chung được giảm theo thừa số O(n5/k2l3) so với CNN. Tương tự, việc giảm độ phức tạp tính toán của pMoE đào tạo riêng biệt là O(n5/l5).

5. Kết quả thực nghiệm
5.1. pMoE của CNN hai lớp
Bộ dữ liệu: Chúng tôi xác minh các phát hiện lý thuyết của chúng tôi về mô hình trong (1) trên dữ liệu tổng hợp được chuẩn bị từ bộ dữ liệu MNIST (LeCun et al., 2010). Mỗi mẫu chứa n= 16 patch với kích thước patch d= 28×28. Mỗi patch được rút ra từ bộ dữ liệu MNIST. Xem Hình 3 như một ví dụ. Chúng tôi coi các chữ số "1" và "0" là các mẫu phân biệt lớp o1 và o2, tương ứng. Mỗi chữ số từ "2" đến "9" đại diện cho một tập mẫu không liên quan đến lớp.

Thiết lập: Chúng tôi so sánh pMoE đào tạo riêng biệt, pMoE đào tạo chung và CNN với kích thước mô hình tương tự. pMoE đào tạo riêng biệt chứa hai chuyên gia với 20 nút ẩn trong mỗi chuyên gia. pMoE đào tạo chung có tám chuyên gia với năm nút ẩn trên mỗi chuyên gia. CNN có 40 nút ẩn. Tất cả được đào tạo sử dụng SGD với η= 0.2 cho đến khi lỗi đào tạo bằng không. pMoE hội tụ nhanh hơn nhiều so với CNN, mất 150 epoch. Trước khi đào tạo các chuyên gia trong pMoE đào tạo riêng biệt, chúng tôi đào tạo bộ định tuyến trong 100 epoch. Các mô hình được đánh giá trên 1000 mẫu kiểm tra.

Hiệu suất khái quát hóa: Hình 4 so sánh độ chính xác kiểm tra của ba mô hình, nơi l= 2 và l= 6 cho pMoE đào tạo riêng biệt và đào tạo chung, tương ứng. Các thanh lỗi hiển thị trung bình cộng/trừ một độ lệch chuẩn của năm thí nghiệm độc lập. pMoE vượt trội hơn CNN với cùng số lượng mẫu đào tạo. pMoE chỉ yêu cầu 60% số mẫu đào tạo cần thiết bởi CNN để đạt được 95% độ chính xác kiểm tra.

Hình 5 cho thấy độ phức tạp mẫu của pMoE đào tạo riêng biệt đối với l. Mỗi khối đại diện cho 20 thử nghiệm độc lập. Khối trắng cho thấy tất cả thành công, và khối đen cho thấy tất cả thất bại. Độ phức tạp mẫu là đa thức trong l, xác minh Định lý 4.2. Hình 7 và 6 cho thấy độ chính xác kiểm tra của pMoE đào tạo chung với kích thước mẫu cố định khi l và k thay đổi, tương ứng. Khi l lớn hơn l∗, là 6 trong Hình 7, độ chính xác kiểm tra khớp với thứ tự dự đoán của chúng tôi. Tương tự, sự phụ thuộc vào k cũng khớp với dự đoán của chúng tôi, khi k đủ lớn để làm cho Giả định 4.4 giữ.

Hiệu suất bộ định tuyến: Hình 8 xác minh tính chất phân biệt của các bộ định tuyến được đào tạo riêng biệt (Bổ đề 4.1) bằng cách hiển thị tỷ lệ phần trăm dữ liệu kiểm tra có các mẫu phân biệt lớp (o1 và o2) trong l patch hàng đầu của bộ định tuyến được đào tạo riêng biệt. Với rất ít mẫu đào tạo (như 300), người ta đã có thể học một bộ định tuyến thích hợp có các mẫu phân biệt trong 4 patch hàng đầu cho 95% dữ liệu. Hình 9 xác minh tính chất phân biệt của các bộ định tuyến được đào tạo chung (Giả định 4.4). Chỉ với 300 mẫu đào tạo, bộ định tuyến được đào tạo chung gửi o1 với giá trị gating lớn nhất đến một chuyên gia cụ thể cho 95% dữ liệu lớp-1 và tương tự cho o2 trong 92% dữ liệu lớp-2.

5.2. pMoE của Wide Residual Networks (WRNs)
Mô hình mạng thần kinh: Chúng tôi sử dụng WRN 10 lớp (Zagoruyko & Komodakis, 2016) với thừa số mở rộng 10 làm chuyên gia. Chúng tôi xây dựng một đối tác patch-level MoE của WRN, được gọi là WRN-pMoE, bằng cách thay thế lớp tích chập cuối cùng của WRN bằng một lớp pMoE có số lượng tham số có thể đào tạo được bằng nhau (xem Hình 18 trong Phụ lục để minh họa). WRN-pMoE được đào tạo với phương pháp đào tạo chung5. Tất cả các kết quả được tính trung bình trên năm thí nghiệm độc lập.

Bộ dữ liệu: Chúng tôi xem xét cả bộ dữ liệu CelebA (Liu et al., 2015) và CIFAR-10. Các thí nghiệm trên CIFAR-10 được hoãn lại cho Phụ lục (xem phần A). Chúng tôi giảm mẫu các hình ảnh của CelebA xuống 64×64. Lớp tích chập cuối cùng của WRN nhận một bản đồ đặc trưng có kích thước (16×16×640). Bản đồ đặc trưng được chia thành 16 patch với kích thước 4×4×640 trong WRN-pMoE. k= 8 và l= 2 cho lớp pMoE.

So sánh hiệu suất: Hình 10 cho thấy độ chính xác kiểm tra của bài toán phân loại nhị phân trên thuộc tính "mỉm cười". WRN-pMoE yêu cầu ít hơn một phần năm số mẫu đào tạo cần thiết bởi WRN để đạt được 86% độ chính xác. Hình 11 cho thấy hiệu suất khi dữ liệu đào tạo chứa các tương quan giả tạo với màu tóc như một thuộc tính giả tạo. Cụ thể, 95% hình ảnh đào tạo với thuộc tính "mỉm cười" cũng có thuộc tính "tóc đen", trong khi 95% hình ảnh đào tạo với thuộc tính "không mỉm cười" có thuộc tính "tóc vàng". Các mô hình có thể học thuộc tính màu tóc thay vì "mỉm cười" do tương quan giả tạo và do đó độ chính xác kiểm tra thấp hơn trong Hình 11 so với những trong Hình 10. Tuy nhiên, WRN-pMoE vượt trội hơn WRN và giảm độ phức tạp mẫu để đạt được cùng độ chính xác.

Hình 12 cho thấy độ chính xác kiểm tra của phân loại đa lớp (bốn lớp với các thuộc tính lớp: "Không mỉm cười, Kính mắt", "Mỉm cười, Kính mắt", "Mỉm cười, Không kính mắt", và "Không mỉm cười, Không kính mắt") trong CelebA. Các kết quả nhất quán với kết quả phân loại nhị phân. Hơn nữa, Bảng 2 xác minh thực nghiệm hiệu quả tính toán của WRN-pMoE so với WRN trên phân loại đa lớp trong CelebA6. Ngay cả với cùng số lượng mẫu đào tạo, WRN-pMoE vẫn hiệu quả hơn về mặt tính toán so với WRN, vì WRN-pMoE yêu cầu ít lần lặp hơn để hội tụ và có chi phí mỗi lần lặp thấp hơn.

6. Kết luận
MoE giảm chi phí tính toán đáng kể mà không ảnh hưởng đến hiệu suất khái quát hóa trong các nghiên cứu thực nghiệm khác nhau, nhưng giải thích lý thuyết phần lớn vẫn khó nắm bắt. Bài báo này cung cấp phân tích lý thuyết đầu tiên về patch-level MoE và chứng minh tiết kiệm của nó trong độ phức tạp mẫu và kích thước mô hình một cách định lượng so với đối tác chuyên gia đơn. Mặc dù tập trung vào tác vụ phân loại sử dụng hỗn hợp CNN hai lớp, các hiểu biết lý thuyết của chúng tôi được xác minh thực nghiệm trên các kiến trúc sâu và nhiều bộ dữ liệu. Các công việc tương lai bao gồm phân tích các kiến trúc MoE khác như MoE trong Vision Transformer (ViT) và kết nối MoE với các phương pháp thưa hóa khác để giảm thêm tính toán.

Lời cảm ơn
Công việc này được hỗ trợ bởi AFOSR FA9550-20-1-0122, NSF 1932196 và Hợp tác Nghiên cứu AI Rensselaer-IBM (http://airc.rpi.edu), một phần của Mạng lưới AI Horizons của IBM (http://ibm.biz/AIHorizons). Chúng tôi cảm ơn Yihua Zhang tại Đại học Bang Michigan vì sự giúp đỡ trong các thí nghiệm với bộ dữ liệu CelebA. Chúng tôi cảm ơn tất cả các nhà phản biện ẩn danh.

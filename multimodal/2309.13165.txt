# 2309.13165.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/multimodal/2309.13165.pdf
# File size: 713482 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Large Language Models Are Also Good Prototypical Commonsense
Reasoners
Chenglin Li1,2†, Qianglong Chen1†, Yin Zhang1‡, Yifei Zhang2Hongxiang Yao3
1Zhejiang University,2Northeastern University,3Ant Group
{22351307, chenqianglong, zhangyin98}@zju.edu.cn,
zhangyifei@cse.neu.edu.cn, feiyu.fyyu@gmail.com
Abstract
Commonsense reasoning is a pivotal skill for large language models, yet it presents persistent challenges in specific
tasks requiring this competence. Traditional fine-tuning approaches can be resource-intensive and potentially compro-
mise a model’s generalization capacity. Furthermore, state-of-the-art language models like GPT-3.5 and Claude are
primarily accessible through API calls, which makes fine-tuning models challenging. To address these challenges, we
draw inspiration from the outputs of large models for tailored tasks and semi-automatically developed a set of novel
prompts from several perspectives, including task-relevance, supportive evidence generation (e.g. chain-of-thought
and knowledge), diverse path decoding to aid the model. Experimental results on ProtoQA dataset demonstrate that
with better designed prompts we can achieve the new state-of-art(SOTA) on the ProtoQA leaderboard, improving the
Max Answer@1 score by 8%, Max Incorrect@1 score by 4% (breakthrough 50% for the first time) compared to the
previous SOTA model and achieved an improvement on StrategyQA and CommonsenseQA2.0 (3% and 1%, respec-
tively). Furthermore, with the generated Chain-of-Thought and knowledge, we can improve the interpretability of the
model while also surpassing the previous SOTA models. We hope that our work can provide insight for the NLP com-
munitytodevelopbetterpromptsandexplorethepotentialoflargelanguagemodelsformorecomplexreasoningtasks.
Keywords: Commonsense Reasoning, Large Language Model, Prompt
1. Introduction
Recently, large language models have made sig-
nificant advancements in the field of natural lan-
guageprocessingandhaveachievedSOTAresults
across a wide range of tasks (Zhao et al., 2023;
OpenAI, 2023; Bai et al., 2022b). The growth of
model size plays a pivotal role in boosting their
performance (Zhao et al., 2023). However, it is ob-
vious that merely increasing the size of language
models is insufficient to excel in tasks demanding
intricate reasoning, particularly in the realm of com-
monsense reasoning (Sap et al., 2020; Bhargava
and Ng, 2022a). Commonsense reasoning is the
foundation of human understanding, rooted in the
basic knowledge and life experiences accumulated
through daily life and social practice (Forguson,
1989), which outlines practical knowledge of how
the world works (Sap et al., 2020). And common-
sense reasoning is at the heart of building natural
language understanding models that can reason
about the world like humans do (Davis and Marcus,
2015; Storks et al., 2019).
For the prototypical commonsense reasoning, the
model output is expected to cover all prototypical
answers for a question (Boratko et al., 2020). This
isparticularlyvaluableinscenarioswhereconsider-
ingagivencontextshouldyielddiverseandcontex-
tually appropriate responses (Zhang et al., 2020).
Meanwhile, in prototypical commonsense reason-
ing, traditional studies include building a ranker
model (Luo et al., 2022) and knowledge enhance-
ment (Li et al., 2023) to improve the ability of themodel from fine-tuning the model, but these works
did not consider the commonsense reasoning abil-
ity of the SOTA models and limited to the specific
fine-tuningtasks. (Bianetal.,2023)haveassessed
large language models’ knowledge related to pro-
totype reasoning but utilized accuracy as the sole
evaluation metric briefly, deviating from the original
task’s metrics.
In this work, we explore the prototypical common-
sense reasoning ability of large language models
and attempt to explain their reasoning process.
Specifically, we draw inspiration from model re-
sponses to specific tasks and semi-automatically
develop three distinct categories of prompts aimed
at enhancing the model’s performance.
By semi-automatically developing three categories
of prompts, we aim to gain a deeper understanding
of These prompts encompass (1)the level of com-
monsense reasoning attainable by large language
models in prototypical commonsense reasoning
tasks, (2) an explanation of the commonsense
reasoning processes employed by these models,
and (3) strategies for enhancing the model’s com-
monsense reasoning ability through improved new
prompts. Overall, we semi-automatically explore
and develop a set of effective prompts for the proto-
typical commonsense reasoning from the perspec-
tives of task-relevant, evidence-supported, and di-
verse path decoding. Our work contributes to a
better understanding of large language models’ ca-
pabilities in commonsense reasoning and offers
insights into how to construct prompts that effec-arXiv:2309.13165v1  [cs.CL]  22 Sep 2023

--- PAGE 2 ---
Heuristic prompt《Task-
specific question》 is it has 
correct answer and What is 
the conclusion based on ?
Snippets1: based on individual experiences and 
perspectives
Snippets2: depends on common societal norms
Snippets3: based on common societal norms and 
practices
Figure 1: Specific heuristic prompt we use
and snippets about ProtoQA task that we collect.
tively elicit these abilities from such models.
The contributions of this work are as follows:
•We semi-automatically explore a series of
new prompts, including task-relevant prompt,
evidence-supported prompt, and diverse path
decoding prompt to improve the prototypical
commonsense reasoning ability of large lan-
guage models.
•To improve the interpretability of the model’s
reasoning process, we employ prompts based
on chain-of-thought and knowledge gener-
ation, coupled with diverse path decoding
prompts, thereby enhancing model perfor-
mance while increasing transparency in the
reasoning process.
•Experimental results demonstrate that our
method achieve new SOTA on the ProtoQA.
We improve the Max Answer@1 score by 8%,
MaxIncorrect@1scoreby4%comparedtothe
previousSOTAmodel. Meanwhile,wevalidate
the generalization of our method on Common-
senseQA2.0 and StrategyQA.
2. Related Work
2.1. Commonsense Reasoning with
Large Language Models
Large language models, such as GPT-3.5 series
models1,GPT-4(OpenAI,2023),Claude(Baietal.,
2022b) and Google Bard2, PaLM-2 (Anil et al.,
1https://platform.openai.com/docs/model-index-for-
researchers
2blog.google/technology/ai/bard-google-ai-search-
updates2023) have made great progress in the field of nat-
ural language processing. However, these large
language models still encounter challenges in the
realm of commonsense reasoning (Bhargava and
Ng, 2022b), where language model need have the
capacity to reason implicit knowledge and daily sit-
uations that are known to humans (Uleman et al.,
2008). To enhance the common sense reasoning
ability of large language models, researchers have
explored diverse works which can be roughly cat-
egorized into how to make language model know
more (Yang et al., 2021) and how language model
make better reasoning (Wei et al., 2022). In the
former works, they integrate external sources of
knowledge into language model (Lim et al., 2020;
Sun et al., 2019; Guan et al., 2020; Yu et al., 2022;
Lin et al., 2019).For instance, the utilization of ex-
ternal knowledge graphs or databases containing
factual information can augment the model’s un-
derstanding of the world (Han et al., 2020; Liu
et al., 2021). By incorporating such knowledge,
the model becomes capable of making more in-
formed decisions (Chen et al., 2020). In the latter
works, researchers design better reasoning strate-
gies for the language model (Kojima et al., 2022).
By adopting an appropriate reasoning strategy, the
ability of the language model to use knowledge
reasoning is greatly improved (Wang et al., 2022).
2.2. Prompt Learning
Prompt learning is a crucial process in the field of
engineering, aimed at develop effective prompts
to guide large language models in achieving de-
sired outputs (White et al., 2023). Much work for
prompt learning has been explored by researchers.
A series of methods such as few-shot (Wang et al.,
2020), Chain-of-Thought (Wei et al., 2022) in-
context learning (Dong et al., 2022) essentially es-
tablishes suitable prompts to guide the language
model to output the appropriate results. Among
these methods, the Chain-of-Thought technology
which generates thinking steps has been estab-
lished as a significant method to enhance the rea-
soningabilityoflanguagemodels(Weietal.,2022).
Throughout various language tasks, prompt learn-
ing has played a pivotal role in achieving excellent
results (Dang et al., 2022). Currently, the research
of NLP Prompt Engineering is still developing, and
different methods have been proposed to construct
effective prompts. Among them, the artificial con-
structionofpromptisoneofthemostefficientmeth-
ods, which is designed based on artificial knowl-
edge (White et al., 2023).
3. Approach
Inthissection,wewillintroducethesemi-automatic
prompting methods, which aims to elicit the com-
mon sense reasoning abilities of large language

--- PAGE 3 ---
Prompt Input<Task-Relevant Prompt>based on common societal norms and practices,give me 10 most common answersfollowingquestion ,mostanswers should only be one word.<Evidence-SupportedThinkingPrompt>  provide the process ofthinking step by step.<Evidence-Supported Knowledge Prompt> informationknown to the people about the question.<Diverse Path DecodingPrompt>give me answers with evidence .summary top 10 Most one-world Answers based on common societal norms and practicesLLMReasoning Path 2Reasoning Path 3Reasoning Path 1Final Answer(a) Overall Architecture
(b) Example in our method“Coffee shop”,“Barbershop”, “Library”,"Bookstore", "Gym”“Coffee shop”,“Restaurant”,"Restaurant", “Restaurant”, “Doctor’s office”,"Bank", "Bar”Restaurant, Bank,Postoffice, Hotel,Gym<Question>Name a place where you might have a long conversation with someone who works there<Task-Relevant Prompt>based on common societal norms and practices,give me 10 mostcommon answersfollowingquestion ,mostanswers should onlybe one word.<Evidence-SupportedThinkingPrompt>  provide the process ofthinking step by step.<Evidence-Supported Knowledge Prompt> informationknown to the people about the question.<Diverse Path DecodingPrompt>give me answers with evidence.summary top 10 Most one-world Answers based on common societal norms and practicesLLMFigure 2: The overall architecture and example demonstration in our work.
models. Ourmaingoalistoexplorewhatproperties
apromptpossessesthatcanstimulatethecommon-
sense reasoning ability of a large language model,
and how a prompt can be used to balance the com-
monsense reasoning ability and interpretability of
a large language model.
We mainly evaluate the performance of several
large language models, including GPT-3.5, GPT-4,
Claude, and Bard, on ProtoQA dataset (Boratko
et al., 2020), StrategyQA (Geva et al., 2021) and
CommonsenseQA2.0 (Talmor et al., 2021).
Inspired by the results of model when prompting
model for specific tasks, we gather pertinent task-
relevant snippets as an integral component of the
prompts. Specific heuristic prompt we use and
snippets about ProtoQA task we collect are shown
in Figure 1. We select snippets3 that are closest
to the task (Boratko et al., 2020) as one part of
the newly designed task-relevant prompts. While
considering the model’s interpretability and consis-
tency,Weseparatelydesignedevidence-supported
prompt and diverse path decoding prompt.
•Task-Relevant Adding task-relevant knowl-
edge snippets as prompts to generate diverse
and accurate answers, the answer list needs
to cover knowledge that is familiar to most
people.We drew inspiration from the output
of model, discovering their ability to generate
task-relevant pieces. We then refined these
pieces to craft task-specific prompts.
Task-relevant prompts can focus the model’s
attention and produce output that is more inline with task requirements. At the same time,
task-relevant prompts can provide contextual
information for the model, helping the model
understandthequestionandthetypeofoutput
that needs to be generated.
•Evidence-Supported Thinking & Knowl-
edgeAdding instructive prompts that include
task-relevantguide words for models to gen-
erate supporting evidence, including Chain-
of-Thought and knowledge generation, which
can make the reasoning process of the model
more transparent while the model generates
diverse and accurate answers.
Supportive evidence plays a significant role in
various aspects. First, it enhances the trans-
parency of the model, making the reasoning
process and basis for judgment of the model
clearandvisible. Atthesametime, itcanhigh-
light the most important judgment information
of the model and help humans understand the
focus of the model. Furthermore, it supports
manual inspection of the model’s reasoning
process, evaluates the rationality of the model,
and improves the model.
•Diverse Path Decoding Consideringtheneed
for generating diverse and accurate answers,
we add an instruction prompt that include task-
relevant guide words, enabling the model to
generatemulti-dimensionalanswersindiverse
reasoning process and relying on the model’s
summarizing ability to produce the final re-
sult. Generate diverse answers and summary

--- PAGE 4 ---
Baseline-Pr ompt0
Task-Relevant-Pr ompt1Supporting evidence
Supporting evidence
by knowledge- Prompt3 
 
 
  
 
 
  
 
 
 
 
 
 
 
   
      Prompt4_1:
Give me 10 answers with supporting evidence based on common 
societal norms and practices most answers should only be one word. 
following question:< Question>
Prompt4_2:
Diverse path decoding:+<diverse path decoding>+diverse path 
decoding end. +Summary top 10 Most one-world Answers based on 
common societal norms and practices following question: <Question >
Algorithm Flow £º
dpd=""
for i in range(n):
   response=get_response(model,Prompt4_1)  
   dpd=dpd+f"path{i}:{get_diverse_path(response)}"
Prompt4_2=Prompt4_2.format(dpd)
response=get_response(model,Prompt4_2)
answer=get_answer(response)Supporting evidence
by diverse path decoding-Pr ompt4
  
 
 
   
      
    
   
     
    
   
 
 
  Give me 10 answers based on
common societal norms and
practices , most answers should only  
be one word. question:  <Question >by thinking- Prompt2
Prompt2_1: Give me 10 answers ba
sed on common societal norms and
practices,most answers should only  
be one word. Finally provide the
process of thinking of following
question step by step. question:
<Question>
Prompt2_2: Thinking:+<thinking>
+thinking end.At the beach, name  something
 that might protect  you from 
sun. Answers :1.umbrella 2.
sunscreen 3.sun  hat 4.
sunglasses 5.cover up
6.shade 7.beach tent 8.rash
guard 9.T-shirt 10.rash guard.
Give me 10 answers and most  
answers should only be one
word.question: < Question >+prompt0
Prompt3_1: <Question>
Information  known to the people 
about the question is
Prompt3_2: knowledge:+<
knowledge>+ >above knowledge 
may help you. +prompt_0Figure 3: The prompt content in different setting with prompt label, where prompt0 denotes the baseline
prompt, others denote different setting, such as task relevant, supporting evidence by thinking, knowledge
and diverse path decoding.
enables the model to attain enhanced self-
consistency, which is crucial for the decision-
making capabilities of the model. If contradic-
tory or inconsistent output is generated, the
model is highly likely to correct or discard it.
As shown in Figure 2, we present the details of
task-relevant prompt, which aims to guide the
large language model to generate the answer with
more task related information. For the evidence-
supportedprompt,relevantknowledgeorthoughtis
first elicited through the prompt. The task-relevant
prompt is then combined with evidence and input
into the large language model to generate answers.
For diverse path decoding prompt, multiple can-
didate answers with evidence are first decoded
through multi-paths sampling. Then the candidate
answer with evidence are summarized by combin-
ingtask-relatedprompttogeneratethefinalanswer.
More details can be found in Appendix, as shown
in Figure 5.
4. Experiments
4.1. Dataset
ProtoQA In the main result, we evaluated our
methodonProtoQA(Boratkoetal.,2020),whichfo-
cuses on commonsense reasoning questions such
as "What could be some of the reasons you could
be called to your kid’s school?". The model is re-
quired to generate a list of answers, ideally cov-
ering all prototype answers for a given question.
The dataset has 9,762 questions in the training
set, 52 questions in the development set, and 102
questions in the test set. Datasets have diverse
reasoning types of questions, as shown in Table 1.Reasoning type Train Test
Prototypical Events 80%68%
Habitual Activity 24%40%
Event Reasoning 40%28%
Specific Entities 4%20%
Social/Mental 12%16%
Negation 20%12%
Total numbers 9,762 102
Table 1: Statistics of different reasoning types on
ProtoQA.
CommonsenseQA2.0 CommonsenseQA
2.0 (Talmor et al., 2021) is proposed to explore
the commonsense understanding ability of
large language models, which includes 14,343
yes/no questions (or assertions) about everyday
commonsense knowledge.
StrategyQA StrategyQA (Geva et al., 2021) is a
question-answering benchmark focusing on open-
domain questions where the required reasoning
steps are implicit in the question and should be
inferred using a strategy, which includes 2,780
true/false examples, each consisting of a strategy
question, its decomposition, and evidence para-
graphs.
4.2. Baselines
For the test set experiment, we take other SOTA
modelsontheleaderboardasbaselinesforcompar-
ison as shown in Table 2. For the development set
experiment, the baseline of large language models
isthestandardfew-shotprompt,wherethemodelis
provided contextual examples of input-output pairs
before predicting the output on a test example. Ad-
ditionally, given the brevity and diversity of the an

--- PAGE 5 ---
MethodMax Answers Max Incorrect
@ 1 @ 3 @ 5 @ 10 @ 1 @ 3 @ 5
GPT-2-KEPR 0.42 0.50 0.55 0.63 0.33 0.52 0.60
BART-KEPR 0.47 0.56 0.57 0.65 0.38 0.55 0.62
T5-3B-KEPR 0.61 0.61 0.62 0.690.46 0.61 0.68
T5-3B-finetune 0.57 0.57 0.59 0.63 0.39 0.55 0.59
GPT-3-davinci-5-Shot 0.57 0.55 0.58 0.61 0.41 0.55 0.59
GPT-3.5-few-shot 0.62 0.63 0.62 0.64 0.47 0.60 0.62
Claude-few-shot 0.63 0.62 0.62 0.64 0.45 0.57 0.61
Bard-few-shot 0.58 0.57 0.57 0.64 0.41 0.54 0.60
GPT4-few-shot 0.64 0.61 0.62 0.66 0.48 0.58 0.62
GPT-3.5-Task-relevant prompt 0.69 0.66 0.66 0.68 0.50 0.63 0.66
GPT-3.5-Support evidence thinking prompt 0.66 0.65 0.65 0.68 0.47 0.62 0.64
GPT-3.5-diverse path decoding prompt 0.67 0.64 0.65 0.67 0.48 0.62 0.64
Table 2: Test results on ProtoQA leaderboard, compared with other baselines, our method achieves new
SOTA.
swers of the question, we impose a limit in the
prompt stating "give me 10 answers and most an-
swers should only be one word.", as shown in Fig-
ure 3. The following introduces the models in the
experiment which have achieved excellent perfor-
mance and large language models that we explore.
GPT-2 GPT-2isatransformer-decoder-basedlan-
guage model developed by Open AI(Radford et al.,
2019), which demonstrates strong performance on
a variety of language modeling tasks like next word
prediction, sentence completion, and text genera-
tion. We use the model fine-tuned on the training
set.
BART BART is a Transformer-based language
generation model developed by FaceBook AI with
a bidirectional encoder and decoder (Lewis et al.,
2019) which enables it to simultaneously under-
stand the context of the input text and generate
the output text, allowing it to generate more coher-
ent and accurate responses. We use the model
fine-tuned on the training set.
T5T5 is a powerful multi-task learning language
model based on the transformer architecture with
encoderanddecoderdevelopedbyGoogleAI(Raf-
fel et al., 2020), which realizes multi-task learning
and transfer learning by unifying different natural
language processing tasks into text-to-text conver-
sion. We use the model fine-tuned on the training
set.
KEPR GPT-2-KEPR, BART-KEPR, T5-3B-KEPR
utilizes Knowledge Enhancement and Plausibility
Ranking to augment the commonsense reasoning
skills of GPT-2, BART and T5 (Li et al., 2023). We
use the model fine-tuned on the training set.
GPT-3 GPT-3 is the updated version of GPT, a
large AI language model with 175 billion param-
eters which shows powerful language abilities intext generation, The GPT-3 version in use is the
davinci-002 model released by OpenAI. (Brown
et al., 2020).
GPT-3.5 GPT-3.5 is the updated version of GPT,
which make greater process in dialogue sys-
tem (Ouyang et al., 2022). The GPT-3.5 version in
use is the GPT-3.5-turbo model released by Ope-
nAI.
BardBard is an experiment based on LaMDA
which is trained to be informative and comprehen-
sive (Thoppilan et al., 2022).
Claude Claude is a next-generation AI assistant
basedonAnthropic’sresearch,whichcanhelpwith
use cases including summarization, search, cre-
ative and collaborative writing, Q&A, coding, and
more (Bai et al., 2022a).
4.3. Experimental Setting
Task Relevant Prompt The main dataset we
studied is the ProtoQA dataset, which requires
the generation of diverse and accurate answers
based on common societal norms and practices,
so we choose the piece ’based on common soci-
etal norms and practices’ as the key part of the
task-relevant prompt, as shown in Figure 3.
Prompt that generates supporting evidence
We consider generating supportive evidence
through Chain-of-Thought or knowledge genera-
tion. We first elicit thinking or knowledge through
an initial prompt, then use generated thought or
knowledge in conjunction with the task-relevant
prompt as input to generate answers, as shown
in Figure 3.
Prompt that helps diverse path decoding For
the model to generate answers with evidence mul-
tiple times, finally summarize to generate the final
answers, as shown in Figure 3. In the parameter

--- PAGE 6 ---
Prompt labelMax Answers Max Incorrect
@ 1 @ 3 @ 5 @ 10 @ 1 @ 3 @ 5
Prompt0 0.55 0.50 0.47 0.48 0.32 0.40 0.45
Prompt1 0.70 0.57 0.53 0.54 0.390.46 0.50
Prompt2 0.55 0.57 0.53 0.53 0.39 0.47 0.50
Prompt3 0.56 0.52 0.48 0.50 0.36 0.43 0.46
Prompt4 0.54 0.54 0.55 0.59 0.38 0.49 0.54
Table 3: Results with different prompts on ProtoQA development set.
ofcallingGPT-3.5-turbomodelAPI, temperature =
0.5,max_tokens = 1024 ,top_p = 0 .95.
4.4. Experimental Results
We use ProtoQA, the commonsense reasoning
dataset, to evaluate the performance of language
model with different prompt, which provides a more
rigorous assessment of the commonsense reason-
ingabilityoflargelanguagemodels,whichrequires
themodeltooutputallprototypeanswerstoaques-
tion ideally. The metric Max Answers@k limits the
totalnumberofanswersallowedtouptokanswers.
The metric Max Incorrect@k allows unlimited an-
swersbutstopsafterkunmatchedanswers. There-
fore, the metrics evaluate the diversity and accu-
racyoftheanswerstoagivenquestion. Thehigher
the score, the better the common sense reasoning
performance. All results presented here are the
averages derived from multiple runs, specifically
the mean of three repetitions, and the results hold
statistical significance.
4.4.1. Results on Leaderboard of Test set
In the leaderboard of test set, as shown in Ta-
ble 2, we achieved SOTA results through a task-
relevant prompt which outperforms various models
enhanced by KEPR method. Specifically, the met-
ric Max Answers@1 reached 69% (an 8% increase
over the previous SOTA model, T5-3B-KEPR), and
the metric Max Incorrect@1 reached 50%. This is
the first time breaking through 50%, representing a
4% increase over the previous SOTA model. Fur-
thermore, to explore the commonsense reasoning
capabilitiesofotherlargelanguagemodels,wecon-
ducted experiments with Claude, Bard, and GPT-
3.5 using few-shot prompts, as shown in Table 2.
Through the large language models with few-shot
prompts, the metrics Max Answers@10 and Max
Incorrect@5arebehindthepreviousSOTAmodels.
This indicates that with knowledge enhancement
and ranker techniques, smaller language models
have the potential to match or even outperform
larger language models on some specific tasks.
Additionally, the large language model, Claude,
demonstratedcommonsensereasoningabilitycom-
parabletothatofGPT-3.5,whilemaintainingaclear
advantage over Bard.Model Setting StrategyQA CommonsenseQA2.0
Few-shot 0.585 0.57
Task-Relevant Prompt 0.594 0.60
Evidence-Supported Thinking 0.576 0.655
Evidence-Supported Knowledge 0.603 0.650
Diverse Path Decoding 0.607 0.65
Table 4: Performance on other datasets, LLM we
used is GPT-3.5-turbo.
Model Setting StrategyQA CommonsenseQA2.0
Few-shot 0.52 0.50
Task-Relevant Prompt 0.55 0.55
Evidence-Supported Thinking 0.55 0.51
Evidence-Supported Knowledge 0.54 0.50
Diverse Path Decoding 0.57 0.54
Table 5: Performance on other datasets, LLM we
used is LLAMA-70B.
4.4.2. More Results on Development set
As shown in Table 6, experimental results demon-
strate that task-relevant prompt (Prompt1) sub-
stantially contribute to the performance of model.
Specifically, the metrics Max Answers@1, an in-
crease of 15% and Max Incorrect@1 an increase
of 7%. In addition, when providing reasoning ex-
planations aims to improve the interpretability of
the model (Prompt2 and Prompt3), its common-
sense reasoning competence has not deteriorated
under most evaluation metrics. For the metric Max
Answer@1, the model falls back to the baseline
reasoning level. However, for other metrics, the
model have a significant improvement compared
with the baseline (Prompt0). Furthermore, through
the diverse path decoding prompt(Prompt4), the
reasoningabilityofthemodelhasbeensignificantly
improved. Inparticular,themetricMaxAnswer@10
has increased by 11%, and the metric Max Incor-
rect@5 has increased by 9 % compared with the
baseline.
4.4.3. Generalization Evaluation
Todemonstratetheeffectivenessofourmethod,we
conduct experiments on other commonsense rea-
soning datasets, CommonsenseQA2.0 and Strat-
egyQA where each question need a single out-
put, as shown in Table 4 and Table 5. By adding
task-relevant prompt, we achieve an improvement
of about 3% on CommonsenseQA2.0 and about
1% on StrategyQA. By adding evidence-supported
thinking, we achieve the best performance on

--- PAGE 7 ---
CommonsenseQA
Case1 ： dawn is a dishwashing soap made of
feathers
Zero-shot: Yes
Few-shot: Yes
Task-related Prompt (Commonsense Reasoning): No
Case2 ： Done in this order it goes
dependence independence communism
Zero-shot: Yes
Few-shot: Yes
Task-related Prompt (Commonsense Reasoning): NoStrategyQA
Case1 ： Are any of the Great Lakes entirely in
the US?
Zero-shot: False
Few-shot: False
Task-related Prompt (Commonsense Reasoning): True
Case2 ： Did the husband of Alexander
Hamilton's granddaughter work with a lieutenant?
Zero-shot: False
Few-shot: False
Task-related Prompt (Commonsense Reasoning): True
   
Case2:  Name something that an athelete would not keep in her refrigerator
Prompt0: ["Dumbbells", "Running ", "Gym bag", "Sports equipment", "Trophy"]
Prompt1: ["Furniture", "shoes", "Gym bag", "Sports equipment", "Trophy"]
Prompt2: ["Alcohol", "Fried foods", "Processed snacks", "Sugary drinks", "Fast food"]
Prompt3: ["Soda", "Fast food", "Chips", "Alcohol", "Fried foods", "Ice cream"]
Prompt4: ["Junk food", "Alcohol", "Sweets", "Fast food", "Processed food", "Unhealthy snacks"]ProtoQA
Case1: Name a place where you might have a long conversation with someone who works there
Prompt0: ["Therapist’s office", "Real estate agency", "Lawyer", "Doctor’s office", "Service center"]
Prompt1: [["Restaurant", "Hair salon", "Doctor’s office", "Bank", "Barbershop"]
Prompt2: ["Coffee shop", "Barbershop", "Library", "Bookstore", "Restaurant", "Gym"]
Prompt3: ["Coffee shop", "Restaurant", "Restaurant", "Doctor’s office", "Salon", "Bank"]
Prompt4: ["Restaurant", "bank","post office", "Hotel","Gym"]
Human: ["restaurant", "bank", "post office", "Coffee shop","hospital"]
Human: [ "junk food", "shoe", "soda", "ball", "clothes"]Figure 4: Case study on ProtoQA, CommonsenseQA and StrategyQA
Prompt labelMax Answers Max Incorrect
@ 1 @ 3 @ 5 @ 10 @ 1 @ 3 @ 5
Prompt0 0.34 0.31 0.34 0.37 0.18 0.28 0.32
Prompt1 0.51 0.40 0.40 0.42 0.270.33 0.38
Prompt2 0.38 0.400.39 0.42 0.22 0.33 0.38
Prompt3 0.37 0.36 0.37 0.40 0.20 0.30 0.35
Prompt4 0.46 0.39 0.40 0.43 0.24 0.34 0.40
Table 6: Performance on LLAMA-70B in ProtoQA development set
CommonsensenQA2.0, which gains 8.5% improve-
ments. For prompts of CommonsenseQA2.0 and
StrategyQA, we all used the same feature of
prompts (Based on social common sense).
4.5. Ablation Study
The task-relevant prompt (Prompt1) method
achieves a significant improvement in the common-
sensereasoningabilityofthelargelanguagemodel.
In the ProtoQA development set, the metric Max
Answer@1 is increased by 15% compared to the
baselinewithfew-shotprompt(Prompt0),asshown
inTable6. IntheProtoQAtestset,thetask-relevant
prompt(Prompt1)helpsthelargemodelimproveby
7% compared to GPT3.5 with few-shot prompt, as
showninTable2. Thereareabout3%improvement
in CommonsenseQA2.0 and 1% improvement in
StrategyQA, as shown in Table 4. From the aboveexperimental results, we observe that task-relevant
promptsassistthemodelinachievingexcellentper-
formance on particular tasks, similar to fine-tuning
languagemodelsonspecifictaskstoenhancetheir
capabilities for specific tasks. At the same time,
when we provide explanation for the model reason-
ing process, the model’s common sense reason-
ing ability keeps competitive when k>=3. In the
ProtoQA development set, providing supportive ev-
idence with thinking process (Prompt2) improves
theMaxIncorrect@3metricby7%comparedtothe
baseline(Prompt0). Providing supportive evidence
with knowledge (Prompt3) improves the Max Incor-
rect @3 metric by 3%, as shown in Table 6. In the
ProtoQA test set, providing supportive evidence
with thinking improves the Max Answer@10 met-
ric by 4% compared to GPT3.5 with the few-shot
prompt, as shown in Table 2. The experimental re-

--- PAGE 8 ---
sults demonstrate that the augmentation of model
interpretability leads to outputs that are more com-
prehensive. However, We found that the evidence-
supportedpromptwillhaveacertainlossintheper-
formance of the model. One factor that contributed
to the performance degradation is its excessive
focus on the cognitive process, which introduced
redundant information.
Additionally, through employing diverse path de-
codingprompt, thecommonsensereasoningability
of the large language model has also been signif-
icantly improved which relieve this loss when in-
corporating supportive evidence prompt. In the
ProtoQA development set, the metric Max An-
swers@10increasedby11%andthemetricMaxIn-
correct@5 increased by 9% compared to the base-
line(Prompt0), as shown in Table 6. The results of
the above experiment demonstrate that the reason-
ing ability of the model can be enhanced through
diverse path decoding. Specifically,the large lan-
guage model is able to produce more precise out-
puts by summarizing the candidate answers and
maintain competitiveness in metrics with k>=3.
4.6. Case study
To elaborate on the prompts, we provide the ac-
tual output of the large language model with dif-
ferent prompts for commonsense reasoning task,
as shown Figure 4. We can observe that through
task-relevant prompts, the large language model
produces the correct output and improves the ac-
curacy of answers to CommonsenseQA2.0 and
StrategyQA questions. For ProtoQA dataset, com-
paredwithfew-shotPrompt0,theanswerlistoutput
by the model appears more reasonable with task-
relevantPrompt1,whichenablesmodeltogenerate
coherent and relevant answers while reducing the
possibility of errors. Specifically, there are no obvi-
ous irrational answers (e.g. "real estate agency",
"lawyer"forthefirstquestion,"Nameaplacewhere
you might have a long conversation" is irrational.
"running" for the second question,"Name some-
thing that an athelete would not keep in her refrig-
erator" is irrational).
Meanwhile, the supportive evidence generated by
the model itself (process of thinking Prompt2 or
knowledge Prompt3) enables it to gain a better un-
derstanding of the question and generate multiple
accurate answers (e.g. "coffee shop" for the first
question. "fastfood","alcohol"forthesecondques-
tion). In our artificial evaluation of Cot, we noted a
complete alignment between Cot’s reasoning pro-
cess and its ultimate outcomes.We hypothesize
that a substantial enhancement of the model’s rea-
soning capabilities by CoT might potentially lead
to an increased occurrence of disparities between
CoT’s reasoning process and its decision-making
outcomes. In our artificial evaluation of relatedknowledge, we found that knowledge can well sup-
plementthebackgroundinformationoftheproblem
and help the model understand the question. The
supportiveevidenceofdetailedoutputareprovided
in the Appendix A.1. Additionally, by diverse path
decoding Prompt4, the model output is closer to
the question. (e.g. "junk food" for the second ques-
tion).This detailed output are provided in the Ap-
pendix A.2. In addition, we found that there were
differences in the performance of the model be-
tween the test set and the development set, which
was caused by the different difficulty levels of the
dataset distribution. The overall difficulty of the
development set was higher than that of the test
set.
5. Conclusion
In this paper, we explore the prototypical com-
monsense reasoning capability of large language
models to generate multiple appropriate outputs.
We semi-automatically developed a set of novel
prompt templates as a simple and broadly applica-
ble method to enhance commonsense reasoning
in large language models. Our research findings
indicate that large language models exhibit com-
petitive commonsense reasoning abilities without
the need for external knowledge enhancement. In
fact, incorporating explicit external knowledge into
thesemodelsmayintroduceredundantinformation,
potentially compromising their performance. How-
ever, by employing diverse decoding strategies, we
can mitigate such performance loss while simulta-
neously enhancing the interpretability of the mod-
els. In experiments on the ProtoQA, StrategyQA,
and CommonsenseQA datasets, we found that in-
corporating task-relevant knowledge can enable
models to reduce the likelihood of error and gener-
ate more accurate answers. By facilitating thought
process and knowledge, the model’s faculty for
commonsense reasoning can be more transparent.
Through the diverse path decoding, the common
sense reasoning ability of the model has also been
improved to a certain extent and maintain competi-
tiveness compared to evidence-supported prompt
with single path decoding.
6. Limitations
Our work illustrates the task-relevant prompt,
evidence-supported prompt and diverse path de-
coding prompt can improve the commonsense rea-
soning ability of large language models. However,
duetotheresourcelimitation,weareunabletocon-
duct experiments on advanced GPT-4. Meanwhile,
many reasoning datasets for evaluating language
reasoning ability focus on measuring a model’s
ability to produce a single correct or logical re-
sponse. We are limited to the reasoning datasets
with multiple plausible outputs. Specifically, we

--- PAGE 9 ---
carry out experiments on the ProtoQA, a multi-
outputdataset,andconductexpandedexperiments
on the single-output CommonsenseQA and Strate-
gyQA datasets. We hope more datasets that eval-
uate language models’ ability to generate multiple
appropriate outputs will be constructed, as this ca-
pability of large language model is crucial.
Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin
Johnson, Dmitry Lepikhin, Alexandre Tachard
Passos,SiamakShakeri,EmanuelTaropa,Paige
Bailey, Z. Chen, Eric Chu, J. Clark, Laurent El
Shafey, Yanping Huang, Kathleen S. Meier-
Hellstern, Gaurav Mishra, Erica Moreira, Mark
Omernick, Kevin Robinson, Sebastian Ruder,
YiTay, KefanXiao, YuanzhongXu, YujingZhang,
Gustavo Hern’andez ’Abrego, Junwhan Ahn, Ja-
cob Austin, Paul Barham, Jan A. Botha, James
Bradbury, Siddhartha Brahma, Kevin Michael
Brooks, Michele Catasta, Yongzhou Cheng,
Colin Cherry, Christopher A. Choquette-Choo,
Aakanksha Chowdhery, C Crépy, Shachi Dave,
Mostafa Dehghani, Sunipa Dev, Jacob Devlin,
M. C. D’iaz, Nan Du, Ethan Dyer, Vladimir
Feinberg, Fan Feng, Vlad Fienber, Markus Fre-
itag, Xavier García, Sebastian Gehrmann, Lu-
cas González, Guy Gur-Ari, Steven Hand, Hadi
Hashemi, Le Hou, Joshua Howland, An Ren
Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard,
Abe Ittycheriah, Matthew Jagielski, Wen Hao
Jia, Kathleen Kenealy, Maxim Krikun, Sneha
Kudugunta, Chang Lan, Katherine Lee, Ben-
jamin Lee, Eric Li, Mu-Li Li, Wei Li, Yaguang Li,
Jian Li, Hyeontaek Lim, Han Lin, Zhong-Zhong
Liu,FrederickLiu,MarcelloMaggioni,AromaMa-
hendru, Joshua Maynez, Vedant Misra, Maysam
Moussalem, Zachary Nado, John Nham, Eric
Ni, Andrew Nystrom, Alicia Parrish, Marie Pel-
lat, Martin Polacek, Alex Polozov, Reiner Pope,
Siyuan Qiao, Emily Reif, Bryan Richter, Parker
Riley,AlexandraRos,AurkoRoy,BrennanSaeta,
Rajkumar Samuel, Renee Marie Shelby, Am-
brose Slone, Daniel Smilkov, David R. So,
Daniela Sohn, Simon Tokumine, Dasha Val-
ter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi
Wang, Pidong Wang, Zirui Wang, Tao Wang,
John Wieting, Yuhuai Wu, Ke Xu, Yu Xu, Lin Wu
Xue, Pengcheng Yin, Jiahui Yu, Qiaoling Zhang,
Steven Zheng, Ce Zheng, Wei Zhou, Denny
Zhou, Slav Petrov, and Yonghui Wu. 2023. Palm
2 technical report. ArXiv, abs/2305.10403.
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda
Askell, Anna Chen, Nova DasSarma, Dawn
Drain, Stanislav Fort, Deep Ganguli, Tom
Henighan, et al. 2022a. Training a help-
ful and harmless assistant with reinforcementlearning from human feedback. arXiv preprint
arXiv:2204.05862 .
Yuntao Bai, Saurav Kadavath, Sandipan Kundu,
Amanda Askell, Jackson Kernion, Andy Jones,
Anna Chen, Anna Goldie, Azalia Mirhoseini,
Cameron McKinnon, et al. 2022b. Constitu-
tional ai: Harmlessness from ai feedback. arXiv
preprint arXiv:2212.08073 .
Prajjwal Bhargava and Vincent Ng. 2022a. Com-
monsense knowledge reasoning and generation
withpre-trainedlanguagemodels: Asurvey. Pro-
ceedings of the AAAI Conference on Artificial
Intelligence , 36(11):12317–12325.
Prajjwal Bhargava and Vincent Ng. 2022b. Com-
monsense knowledge reasoning and generation
with pre-trained language models: a survey. In
Proceedings of the AAAI Conference on Artificial
Intelligence , volume 36, pages 12317–12325.
NingBian,XianpeiHan,LeSun,HongyuLin,Yaojie
Lu, and Ben He. 2023. Chatgpt is a knowledge-
ablebutinexperiencedsolver: Aninvestigationof
commonsense problem in large language mod-
els.arXiv preprint arXiv:2303.16421 .
Michael Boratko, Xiang Lorraine Li, Rajarshi Das,
Tim O’Gorman, Dan Le, and Andrew McCallum.
2020. Protoqa: A question answering dataset
for prototypical common-sense reasoning. arXiv
preprint arXiv:2005.00771 .
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sas-
try, Amanda Askell, et al. 2020. Language mod-
els are few-shot learners. Advances in neural
information processing systems , 33:1877–1901.
Qianglong Chen, Feng Ji, Haiqing Chen, and Yin
Zhang. 2020. Improving commonsense ques-
tion answering by graph-based iterative retrieval
over multiple knowledge sources. arXiv preprint
arXiv:2011.02705 .
Hai Dang, Lukas Mecke, Florian Lehmann, Sven
Goller, and Daniel Buschek. 2022. How to
prompt? opportunities and challenges of zero-
and few-shot learning for human-ai interaction in
creativeapplicationsofgenerativemodels. arXiv
preprint arXiv:2209.01390 .
Ernest Davis and Gary Marcus. 2015. Common-
sense reasoning and commonsense knowledge
in artificial intelligence. Communications of the
ACM, 58(9):92–103.
Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiy-
ong Wu, Baobao Chang, Xu Sun, Jingjing Xu,
and Zhifang Sui. 2022. A survey for in-context
learning. arXiv preprint arXiv:2301.00234 .

--- PAGE 10 ---
Lynd Forguson. 1989. Common sense . Routledge
London.
Mor Geva, Daniel Khashabi, Elad Segal, Tushar
Khot, Dan Roth, and Jonathan Berant. 2021.
Did aristotle use a laptop? a question answer-
ing benchmark with implicit reasoning strategies.
Transactions of the Association for Computa-
tional Linguistics , 9:346–361.
Jian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu,
andMinlieHuang.2020. Aknowledge-enhanced
pretraining model for commonsense story gener-
ation.Transactions of the Association for Com-
putational Linguistics , 8:93–108.
Jiale Han, Bo Cheng, and Xu Wang. 2020. Open
domain question answering based on text en-
hanced knowledge graph with hyperedge infu-
sion. InFindings of the Association for Compu-
tational Linguistics: EMNLP 2020 , pages 1475–
1481.
Takeshi Kojima, Shixiang Shane Gu, Machel Reid,
Yutaka Matsuo, and Yusuke Iwasawa. 2022.
Large language models are zero-shot reason-
ers.Advances in neural information processing
systems, 35:22199–22213.
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Ghazvininejad, Abdelrahman Mohamed, Omer
Levy, Ves Stoyanov, and Luke Zettlemoyer.
2019. Bart: Denoising sequence-to-sequence
pre-training for natural language generation,
translation, and comprehension. arXiv preprint
arXiv:1910.13461 .
Zhifeng Li, Bowei Zou, Yifan Fan, and Yu Hong.
2023. Kepr: Knowledge enhancement and
plausibility ranking for generative common-
sense question answering. arXiv preprint
arXiv:2305.08347 .
Jungwoo Lim, Dongsuk Oh, Yoonna Jang, Kisu
Yang, and Heuiseok Lim. 2020. I know what
you asked: Graph path learning using amr
for commonsense reasoning. arXiv preprint
arXiv:2011.00766 .
Bill Yuchen Lin, Xinyue Chen, Jamin Chen, and Xi-
angRen.2019.Kagnet: Knowledge-awaregraph
networks for commonsense reasoning. arXiv
preprint arXiv:1909.02151 .
Ye Liu, Yao Wan, Lifang He, Hao Peng, and
S Yu Philip. 2021. Kg-bart: Knowledge graph-
augmented bart for generative commonsense
reasoning. In Proceedings of the AAAI Confer-
ence on Artificial Intelligence , volume 35, pages
6418–6425.Xuan Luo, Chuang Fan, Yice Zhang, Wanguo
Jiang, Bing Qin, and Ruifeng Xu. 2022. Masked
languagemodelsknowwhicharepopular: Asim-
ple ranking strategy for commonsense question
answering. In Findings of the Association for
Computational Linguistics: EMNLP 2022 , pages
3200–3213.
OpenAI. 2023. Gpt-4 technical report. ArXiv,
abs/2303.08774.
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
Carroll Wainwright, Pamela Mishkin, Chong
Zhang, Sandhini Agarwal, Katarina Slama, Alex
Ray, et al. 2022. Training language models to
follow instructions with human feedback. Ad-
vances in Neural Information Processing Sys-
tems, 35:27730–27744.
Alec Radford, Jeffrey Wu, Rewon Child, David
Luan, Dario Amodei, Ilya Sutskever, et al. 2019.
Language models are unsupervised multitask
learners. OpenAI blog , 1(8):9.
Colin Raffel, Noam Shazeer, Adam Roberts,
Katherine Lee, Sharan Narang, Michael Matena,
YanqiZhou,WeiLi,andPeterJLiu.2020. Explor-
ing the limits of transfer learning with a unified
text-to-text transformer. The Journal of Machine
Learning Research , 21(1):5485–5551.
Maarten Sap, Vered Shwartz, Antoine Bosselut,
Yejin Choi, and Dan Roth. 2020. Commonsense
reasoning for natural language processing. In
Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics: Tuto-
rial Abstracts , pages 27–33.
Shane Storks, Qiaozi Gao, and Joyce Y Chai.
2019. Commonsense reasoning for natural lan-
guage understanding: A survey of benchmarks,
resources, and approaches. arXiv preprint
arXiv:1904.01172 , pages 1–60.
Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng,
Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu,
Hao Tian, and Hua Wu. 2019. Ernie: Enhanced
representation through knowledge integration.
arXiv preprint arXiv:1904.09223 .
Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra
Bhagavatula, Yoav Goldberg, Yejin Choi, and
Jonathan Berant. 2021. CommonsenseQA 2.0:
Exposing the limits of AI through gamification.
InThirty-fifth Conference on Neural Information
Processing Systems Datasets and Benchmarks
Track (Round 1) .
Romal Thoppilan, Daniel De Freitas, Jamie Hall,
Noam Shazeer, Apoorv Kulshreshtha, Heng-
Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker,

--- PAGE 11 ---
Yu Du, et al. 2022. Lamda: Language mod-
els for dialog applications. arXiv preprint
arXiv:2201.08239 .
James S Uleman, S Adil Saribay, and Celia M Gon-
zalez. 2008. Spontaneous inferences, implicit
impressions, and implicit theories. Annu. Rev.
Psychol., 59:329–360.
XuezhiWang, JasonWei, DaleSchuurmans, Quoc
Le, Ed Chi, and Denny Zhou. 2022. Self-
consistency improves chain of thought rea-
soning in language models. arXiv preprint
arXiv:2203.11171 .
Yaqing Wang, Quanming Yao, James T Kwok, and
Lionel M Ni. 2020. Generalizing from a few ex-
amples: A survey on few-shot learning. ACM
computing surveys (csur) , 53(3):1–34.
Jason Wei, Xuezhi Wang, Dale Schuurmans,
Maarten Bosma, Ed Chi, Quoc Le, and Denny
Zhou. 2022. Chain of thought prompting elic-
its reasoning in large language models. arXiv
preprint arXiv:2201.11903 .
Jules White, Quchen Fu, Sam Hays, Michael Sand-
born, Carlos Olea, Henry Gilbert, Ashraf El-
nashar, Jesse Spencer-Smith, and Douglas C
Schmidt. 2023. A prompt pattern catalog to en-
hance prompt engineering with chatgpt. arXiv
preprint arXiv:2302.11382 .
Jian Yang, Gang Xiao, Yulong Shen, Wei Jiang,
XinyuHu,YingZhang,andJinghuiPeng.2021.A
survey of knowledge enhanced pre-trained mod-
els.arXiv preprint arXiv:2110.00269 .
Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting
Hu, Qingyun Wang, Heng Ji, and Meng Jiang.
2022. Asurveyofknowledge-enhancedtextgen-
eration.ACM Computing Surveys , 54(11s):1–38.
Yichi Zhang, Zhijian Ou, and Zhou Yu. 2020. Task-
oriented dialog systems that consider multiple
appropriate responses under the same context.
InProceedings of the AAAI Conference on Artifi-
cial Intelligence , volume 34, pages 9604–9611.
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,
Xiaolei Wang, Yupeng Hou, Yingqian Min, Be-
ichen Zhang, Junjie Zhang, Zican Dong, et al.
2023. A survey of large language models. arXiv
preprint arXiv:2303.18223 .

--- PAGE 12 ---
A. Appendix: Details of prompt
A.1. Details of supportive evidence
prompt
As shown in Figure 5, for the question "Name a
place where you might have a long conversation",
the generated supporting thought evidence shows
the reasoning process of the model on answer-
ing the question. It identifies the key of the ques-
tion, ’a place’ and suggests having a long conver-
sation at that place. The supporting knowledge
evidence shows the reference knowledge of the
model to answer the question, and provide the
background knowledge of the gold answer ’coffee
shop’. For the question,"Name something that an
athelete would not keep in her refrigerator", model
also produces the similar output. In short, through
evidence-supported prompts, it generates reason-
able output and improves the interpretability of the
model’s reasoning.
A.2. Details of diverse path decoding
prompt
As shown in Figure 5, in response to the ques-
tion,"Name a place where you might have a long
conversation", the model generated three times re-
sultsandeventuallyfilteredoutinappropriateoutput
suchas"Patio"and"Beach"throughsummarization
and sampling.For the question "Name something
that an athelete would not keep in her refrigerator",
the model generates outputs that are more typi-
cal through summarization and sampling, such as
"junk food" or "alcohol". Overall, through diverse
pathdecodingprompt,theoutputsofthemodelare
more accurate and diverse.

--- PAGE 13 ---
Question: Name a place where you might have a long conversation.
Supportive evidence Cot :
1.Read and understand the question: "Name a place where you might have a
long conversation."Identify the key elements of the question: The question is
asking for a place, and the conversation in that place is expected to be long.
2.Activate prior knowledge: Recall places where people typically engage in
lengthy conversations.
3.Generate initial ideas: Start brainstorming and listing down places that come
to mind. Filter ideas based on societal norms and practices: Consider places
that align with common behaviors and customs observed in society Shortlist
one-word answers
4.Review the generated ideas and select the most appropriate one-word
answers.
5.Verify answers: Ensure that the selected answers accurately correspond to the
question and meet the criteria of common societal norms and practices.
6.Finalize the list: Compile the ten one-word answers based on the steps above.
7.Present the answers: Provide the list of answers to the question.
8.Reflect: Review the process and outcomes, making sure that the answers are
relevant and suitable based on societal norms and practices.
Question: Name a place where you might have a long conversation.
Supportive evidence knowledge:
A place where you might have a long conversation is a cof fee shop. People visit  
coffee shops to relax, enjoy a warm beverage, and engage in conversations with friends, colleagues, or
even strangers.  Coffee shops provide a cozy and comfortable environment conducive to discussions.
Additionally , many cof fee shops  have a relaxed ambiance and comfortable seating arrangements,
making them an ideal place for extended conversations. 
  
 
  Question: Name something that an athelete would not keep in her refrigerator .
Supportive evidence knowledge:
A common item that an athlete would typically not keep in her refrigerator is junk
food or unhealthy snacks.
Athletes generally prioritize their nutrition and opt for healthier food choices to
fuel their bodies and support
their physical performance. They would often stock their refrigerators with fresh
fruits, vegetables, lean proteins,
and other nutritious options. 
 
 
 
 Question: Name something that an athelete would not keep in her refrigerator.
Supportive evidence Cot:
Now, let's break down the process of thinking step by step to answer the question:
1.Identify the subject: The subject of the question is an athlete.
2.Determine the context: The context is about something an athlete would not keep in her refrigerator.
3.Analyze the characteristics of an athlete: Athletes are individuals who engage in sports and physical
activities.
4.Consider typical items found in a refrigerator: Common items in a refrigerator include food, beverages,
and occasionally some personal items.
5.Assess the needs of an athlete: Athletes require nutrition and specific food items to support their
physical performance.
6.Evaluate the options: Think about various items that are not food-related and unlikely to be kept in a
refrigerator.
7.Consider societal norms and practices: Reflect on what is commonly accepted and expected in society.
8.Apply reasoning: Exclude items that an athlete would likely not store in a refrigerator.
9.Generate one-word answers: Provide a list of concise one-word answers that align with societal norms  
and practices.
10.Review and finalize: Ensure the answers make sense and are suitable for the context of the question.
Question: Name a place where you might have a long conversation.
Diverse path decoding:
Path1: Give me  answers  with evidence based on common societal norms 
and practices  following the question, most answers should only be one 
word.Question: Name a place where you might have a long conversation.
Answers:Restaurant - Fine dining establishments encourage extended 
conversations during meals, making them suitable for long discussions £¬
bank ......
Path2: Give me  answers with evidence based on common societal norms 
and practices  following the question, most answers should only be one 
word.Question: Name a place where you might have a long  conversation.
Answers: Coffee shop  are known for providing a cozy environment where 
people often engage in lengthy conversations over coffee or tea......
Path3:Give me  answers with evidence based on common societal norms 
and practices  following the question, most answers should only be one 
word.Question: Name a place where you might have a long  conversation.
Answers:Gym: Gym-goers chat between exercises or during group classes.
.....
summary top 1 0 Most one -world Answers based on common societal
 norms and practices :["Restaurant", "bank","post office", "Hotel","Gym] 
  Question: Name something that an athelete would not keep in her refrigerator.
Diverse path decoding:
Path1: Give me answers with evidence based on common societal norms and practices following 
the question, most answers should only be one word.
Question: Name something that an athlete would not keep in her refrigerator.
Answers: Soda Athletes often avoid sugary beverages to maintain their health and performance.....
.
Path2: Give me answers with evidence based on common societal norms and practices following 
the question, most answers should only be one word.
Question: Name something that an athlete would not keep in her refrigerator.
Answers:fast food:High in sugar and fat, it's considered a treat, not a staple in an athlete's diet......
Path3: Give me answers with evidence based on common societal norms and practices following 
the question, most answers should only be one word.
Question: Name something that an athlete would not keep in her refrigerator.
Answers: Junk food Typically fried and high in unhealthy fats and salt, not part of an athlete's diet.
.....
summary top 1 0 Most one -world Answers based on common societal norms and practices :
["Restaurant", "bank","post office", "Hotel","Gym]Figure 5: The details of supportive evidence thinking, supportive evidence knowledge and diverse path
decoding.

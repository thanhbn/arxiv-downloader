# 2312.03491.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2312.03491.pdf
# Kích thước tệp: 3456566 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Cầu nối Schrodinger Vượt trội hơn Mô hình Khuếch tán trong
Tổng hợp Chuyển văn bản thành giọng nói
Zehua Chen∗1Guande He∗1Kaiwen Zheng∗1Xu Tan2Jun Zhu†1
1Khoa Khoa học Máy tính & Công nghệ, Viện AI, Trung tâm Học máy Liên kết THU-Bosch, Đại học Tsinghua
2Microsoft Research Asia

Tóm tắt
Trong tổng hợp chuyển văn bản thành giọng nói (TTS), các mô hình khuếch tán đã đạt được chất lượng sinh tạo đầy hứa hẹn. Tuy nhiên, do quá trình khuếch tán dữ liệu-thành-nhiễu được định nghĩa trước, phân phối tiên nghiệm của chúng bị hạn chế ở biểu diễn nhiễu, điều này cung cấp ít thông tin về mục tiêu sinh tạo. Trong nghiên cứu này, chúng tôi trình bày một hệ thống TTS mới, Bridge-TTS, thực hiện nỗ lực đầu tiên thay thế tiên nghiệm Gaussian nhiễu trong các phương pháp TTS dựa trên khuếch tán đã thiết lập bằng một tiên nghiệm sạch và xác định, cung cấp thông tin cấu trúc mạnh mẽ của mục tiêu. Cụ thể, chúng tôi tận dụng biểu diễn tiềm ẩn thu được từ đầu vào văn bản làm tiên nghiệm của chúng tôi, và xây dựng một cầu nối Schrodinger hoàn toàn có thể xử lý được giữa nó và phổ mel thật, dẫn đến một quá trình dữ liệu-thành-dữ liệu. Hơn nữa, tính khả thi và linh hoạt của công thức của chúng tôi cho phép chúng tôi nghiên cứu thực nghiệm các không gian thiết kế như lịch trình nhiễu, cũng như phát triển các bộ lấy mẫu ngẫu nhiên và xác định. Kết quả thực nghiệm trên tập dữ liệu LJ-Speech minh họa hiệu quả của phương pháp chúng tôi về cả chất lượng tổng hợp và hiệu suất lấy mẫu, vượt trội đáng kể so với đối tác khuếch tán Grad-TTS trong tổng hợp 50 bước/1000 bước và các mô hình TTS nhanh mạnh mẽ trong các kịch bản ít bước. Trang dự án: https://bridge-tts.github.io/ .

--- TRANG 2 ---
1 Giới thiệu
Các mô hình khuếch tán, bao gồm các mô hình sinh tạo dựa trên điểm số (SGM) [Song et al., 2021b] và các mô hình xác suất khuếch tán khử nhiễu [Ho et al., 2020], đã là một trong những mô hình sinh tạo mạnh mẽ nhất trên các tác vụ sinh tạo dữ liệu khác nhau [Bao et al., 2023, Leng et al., 2022, Ramesh et al., 2022, Wang et al., 2023]. Trong cộng đồng ngôn ngữ nói, chúng đã được nghiên cứu rộng rãi trong tổng hợp dạng sóng [Chen et al., 2021, 2022b, Kong et al., 2021], sinh tạo văn bản-thành-âm thanh [Huang et al., 2023a,b, Liu et al., 2023b,c], và tổng hợp chuyển văn bản thành giọng nói (TTS) [Popov et al., 2021, Shen et al., 2023, Tan et al., 2021]. Nói chung, các mô hình này chứa hai quá trình giữa phân phối dữ liệu và phân phối tiên nghiệm: 1) quá trình khuếch tán tiến dần dần biến đổi dữ liệu thành một phân phối tiên nghiệm đã biết, ví dụ như nhiễu Gaussian; 2) quá trình khử nhiễu ngược dần dần sinh tạo các mẫu dữ liệu từ phân phối tiên nghiệm.

Trong các hệ thống TTS dựa trên khuếch tán [Chen et al., 2023, Popov et al., 2021, Ye et al., 2023], đầu vào văn bản thường được chuyển đổi trước thành biểu diễn tiềm ẩn bởi một bộ mã hóa văn bản, chứa một bộ mã hóa âm vị và một bộ dự đoán thời lượng, sau đó các mô hình khuếch tán được sử dụng làm bộ giải mã để sinh tạo phổ mel có điều kiện trên tiềm ẩn. Phân phối tiên nghiệm trong các hệ thống này có thể được phân loại thành hai loại: 1) một là sử dụng nhiễu Gaussian chuẩn để sinh tạo mục tiêu [Chen et al., 2022c, Huang et al., 2022, Liu et al., 2022b]; 2) loại khác cải thiện tiên nghiệm để có nhiều thông tin hơn về mục tiêu. Ví dụ, Grad-TTS [Popov et al., 2021] học biểu diễn tiềm ẩn từ bộ mã hóa văn bản với mục tiêu thật trong quá trình huấn luyện, và lấy nó làm trung bình của phân phối tiên nghiệm để thu được một Gaussian dịch chuyển trung bình. PriorGrad [Lee et al., 2022] sử dụng các giá trị thống kê từ dữ liệu huấn luyện, tính toán một Gaussian với ma trận hiệp phương sai. DiffSinger [Liu et al., 2022a] sử dụng một mô hình phụ trợ để có được một phân phối tiên nghiệm không thể xử lý, cho phép một quá trình ngược nông. Tuy nhiên, vì các mô hình khuếch tán đã định trước quá trình khuếch tán cộng nhiễu, phân phối tiên nghiệm của các hệ thống trên bị giới hạn ở một biểu diễn nhiễu, không chỉ ra phổ mel.

Trong nghiên cứu này, như được thể hiện trong Hình 1, chúng tôi đề xuất một thiết kế mới để sinh tạo phổ mel từ một tiên nghiệm sạch và xác định, tức là biểu diễn tiềm ẩn văn bản được giám sát bởi mục tiêu thật [Popov et al., 2021]. Nó đã cung cấp thông tin cấu trúc của mục tiêu và được sử dụng làm thông tin điều kiện trong cả các hệ thống TTS dựa trên khuếch tán gần đây [Chen et al., 2023, Ye et al., 2023] và dựa trên khớp dòng có điều kiện [Guo et al., 2023, Mehta et al., 2023], trong khi chúng tôi lập luận rằng việc thay thế tiên nghiệm nhiễu trong các hệ thống trước đây bằng tiềm ẩn sạch này có thể tiếp tục thúc đẩy chất lượng mẫu TTS và tốc độ suy luận. Để kích hoạt thiết kế này, chúng tôi tận dụng cầu nối Schrodinger [Chen et al., 2022a, Schrödinger, 1932] thay vì các mô hình khuếch tán, tìm kiếm một quá trình dữ liệu-thành-dữ liệu thay vì quá trình dữ liệu-thành-nhiễu trong các mô hình khuếch tán. Vì cầu nối Schrodinger ban đầu thường không thể xử lý được, điều này cản trở việc nghiên cứu các không gian thiết kế trong huấn luyện và lấy mẫu, chúng tôi đề xuất một cầu nối Schrodinger hoàn toàn có thể xử lý được giữa dữ liệu ghép đôi với một dạng linh hoạt của SDE tham chiếu phù hợp với các mô hình khuếch tán [Ho et al., 2020, Song et al., 2021b].

Với tính khả thi và linh hoạt của khung đề xuất của chúng tôi, nhằm mục đích tổng hợp TTS với chất lượng sinh tạo vượt trội và tốc độ lấy mẫu hiệu quả, chúng tôi thực hiện một cuộc điều tra về lịch trình nhiễu, tham số hóa mô hình và các bộ lấy mẫu không cần huấn luyện, mà các mô hình khuếch tán đã hưởng lợi rất nhiều từ [Hoogeboom et al., 2023, Salimans and Ho, 2022, Song et al., 2021a], trong khi chưa được nghiên cứu kỹ lưỡng trong các nghiên cứu liên quan đến cầu nối Schrodinger. Để tóm tắt, chúng tôi đóng góp các điểm chính sau trong nghiên cứu này:

• Trong tổng hợp TTS, chúng tôi thực hiện nỗ lực đầu tiên để sinh tạo phổ mel từ biểu diễn tiềm ẩn văn bản sạch (tức là thông tin điều kiện trong đối tác khuếch tán) bằng cách sử dụng cầu nối Schrodinger, khám phá quá trình dữ liệu-thành-dữ liệu thay vì quá trình dữ liệu-thành-nhiễu.

• Bằng cách đề xuất một cầu nối Schrodinger hoàn toàn có thể xử lý được giữa dữ liệu ghép đôi với một dạng linh hoạt của SDE tham chiếu, chúng tôi làm sáng tỏ về mặt lý thuyết và khám phá thực nghiệm các không gian thiết kế của lịch trình nhiễu, tham số hóa mô hình và quá trình lấy mẫu, tiếp tục nâng cao chất lượng TTS với lịch trình nhiễu bất đối xứng, dự đoán dữ liệu và các bộ lấy mẫu cầu nối bậc nhất.

• Về mặt thực nghiệm, chúng tôi đạt được cả chất lượng sinh tạo và tốc độ suy luận tiên tiến nhất với một phiên huấn luyện duy nhất. Trong cả sinh tạo 1000 bước và 50 bước, chúng tôi vượt trội đáng kể so với đối tác khuếch tán Grad-TTS [Popov et al., 2021]; trong sinh tạo 4 bước, chúng tôi đạt được chất lượng cao hơn FastGrad-TTS [Vovk et al., 2022]; trong sinh tạo 2 bước, chúng tôi vượt qua phương pháp chưng cất tiên tiến nhất CoMoSpeech [Ye et al., 2023], và mô hình dựa trên transformer FastSpeech 2 [Ren et al., 2021].

--- TRANG 3 ---
2 Kiến thức nền tảng
2.1 Mô hình Khuếch tán
Cho một phân phối dữ liệu pdata(x), x∈Rd, SGM [Song et al., 2021b] được xây dựng trên một quá trình khuếch tán thời gian liên tục được định nghĩa bởi một phương trình vi phân ngẫu nhiên tiến (SDE):
dxt=f(xt, t)dt+g(t)dwt,x0∼p0=pdata (1)
trong đó t∈[0, T] cho một chân trời hữu hạn T, f:Rd×[0, T]→Rd là một hạng drift giá trị vector, g: [0, T]→R là một hạng khuếch tán giá trị vô hướng, và wt∈Rd là một quá trình Wiener chuẩn. Dưới sự xây dựng phù hợp của f, g, phân phối biên pT(xT) xấp xỉ một phân phối tiên nghiệm Gaussian pprior=N(0, σ2TI).

SDE tiến có một SDE ngược tương ứng [Song et al., 2021b] chia sẻ cùng các phân phối biên {pt}Tt=0 với SDE tiến:
dxt= [f(xt, t)−g2(t)∇logpt(xt)]dt+g(t)d¯wt,xT∼pT≈pprior (2)
trong đó ¯wt là quá trình Wiener thời gian ngược, và hạng duy nhất không biết ∇logpt(xt) là hàm điểm số của mật độ biên pt. Bằng cách tham số hóa một mạng điểm số sθ(xt, t) để dự đoán ∇logpt(xt), chúng ta có thể thay thế điểm số thật trong Phương trình (2) và giải ngược từ pprior tại t=T, tạo ra các mẫu dữ liệu được sinh tạo tại t=0.

sθ(xt, t) thường được học bởi mục tiêu khớp điểm số khử nhiễu (DSM) [Song et al., 2021b, Vincent, 2011] với một hàm trọng số λ(t)>0:
Ep0(x0)pt|0(xt|x0)Et[λ(t)∥sθ(xt, t)− ∇logpt|0(xt|x0)∥22], (3)
trong đó t∼ U(0, T) và pt|0 là phân phối chuyển tiếp có điều kiện từ x0 đến xt, được xác định bởi SDE tiến được định nghĩa trước và là phân tích cho một drift tuyến tính f(xt, t) =f(t)xt.

2.2 Hệ thống TTS dựa trên Khuếch tán
Mục tiêu của các hệ thống TTS là học một mô hình sinh tạo pθ(x|y) trên các phổ mel x∈Rd cho văn bản điều kiện y1:L với độ dài L. Grad-TTS [Popov et al., 2021] cung cấp một đường chuẩn mạnh mẽ cho TTS với SGM, bao gồm một bộ mã hóa văn bản và một bộ giải mã dựa trên khuếch tán. Cụ thể, họ thay đổi tiên nghiệm Gaussian trong SGM thành một tiên nghiệm khác ˜penc(z|y) =N(z,I) với trung bình z có thông tin, trong đó z∈Rd là một đặc trưng âm thanh tiềm ẩn được chuyển đổi từ chuỗi văn bản y thông qua mạng bộ mã hóa văn bản E, tức là z=E(y).

Bộ giải mã dựa trên khuếch tán sử dụng ˜penc làm tiên nghiệm cho SGM và xây dựng một quá trình khuếch tán thông qua SDE tiến được sửa đổi sau:
dxt=12(z−xt)βtdt+√βtdwt,x0∼p0=pdata(x|y) (4)
trong đó p0=pdata(x|y) là phân phối dữ liệu có điều kiện thật và βt là một lịch trình nhiễu không âm. SDE tiến trong Phương trình (4) sẽ tạo ra xT∼pT≈˜penc với T đủ lớn [Popov et al., 2021]. Trong quá trình huấn luyện, bộ mã hóa văn bản và bộ giải mã dựa trên khuếch tán được tối ưu hóa cùng nhau, trong đó bộ mã hóa được tối ưu hóa với mất mát log-likelihood âm Lenc=−Epdata(x|y)[log ˜penc(x|y)] và bộ giải mã được huấn luyện với mục tiêu DSM trong Phương trình (3), ký hiệu là Ldiff. Ngoài Lenc và Ldiff, hệ thống TTS cũng tối ưu hóa một bộ dự đoán thời lượng ˆA như một phần của bộ mã hóa dự đoán bản đồ căn chỉnh A∗ giữa chuỗi văn bản được mã hóa ˜z1:L và đặc trưng tiềm ẩn z1:F với F khung được cho bởi Tìm kiếm Căn chỉnh Đơn điệu [Kim et al., 2020], trong đó zj=˜zA∗(j). Ký hiệu mất mát dự đoán thời lượng là Ldp, mục tiêu huấn luyện tổng thể của Grad-TTS là Lgrad-tts =Lenc+Ldp+Ldiff.

2.3 Cầu nối Schrodinger
Bài toán Cầu nối Schrodinger (SB) [Chen et al., 2022a, De Bortoli et al., 2021, Schrödinger, 1932] bắt nguồn từ việc tối ưu hóa các độ đo đường đi với các biên bị ràng buộc:
minp∈P[0,T]DKL(p∥pref),s.t.p0=pdata, pT=pprior (5)

--- TRANG 4 ---
trong đó P[0,T] là không gian các độ đo đường đi trên một chân trời thời gian hữu hạn [0, T], pref là độ đo đường đi tham chiếu, và p0, pT là các phân phối biên của p tại các biên. Nói chung, pref được định nghĩa bởi cùng dạng SDE tiến như SGM trong Phương trình (1) (tức là SDE tham chiếu). Trong trường hợp đó, bài toán SB tương đương với một cặp SDE tiến-lùi [Chen et al., 2022a, Wang et al., 2021]:
dxt= [f(xt, t) +g2(t)∇log Ψ t(xt)]dt+g(t)dwt,x0∼pdata (6a)
dxt= [f(xt, t)−g2(t)∇logbΨt(xt)]dt+g(t)d¯wt,xT∼pprior (6b)
trong đó f và g giống như trong SDE tham chiếu. Các hạng drift phi tuyến bổ sung ∇logΨt(xt) và ∇logbΨt(xt) cũng được mô tả bởi các phương trình đạo hàm riêng (PDE) ghép đôi sau:
(∂Ψ∂t=−∇xΨ⊤f−12Trg2∇2xΨ ∂bΨ∂t=−∇x·(bΨf) +12Trg2∇2xbΨ s.t.Ψ0bΨ0=pdata,ΨTbΨT=pprior. (7)

Phân phối biên pt của SB tại bất kỳ thời gian t∈[0, T] thỏa mãn pt= Ψ tbΨt. So với SGM trong đó pT≈pprior=N(µ, σ2TI), SB cho phép một dạng linh hoạt của pprior và đảm bảo điều kiện biên pT=pprior. Tuy nhiên, việc giải SB đòi hỏi mô phỏng các quá trình ngẫu nhiên và thực hiện các thủ tục lặp tốn kém [Chen et al., 2022a, De Bortoli et al., 2021, Shi et al., 2023]. Do đó, nó gặp các vấn đề về khả năng mở rộng và tính ứng dụng. Trong một số tình huống nhất định, chẳng hạn như sử dụng dữ liệu ghép đôi làm biên, bài toán SB có thể được giải quyết bằng cách tiếp cận không mô phỏng [Liu et al., 2023a, Somnath et al., 2023]. Tuy nhiên, SB trong các nghiên cứu này hoặc không hoàn toàn có thể xử lý được hoặc bị hạn chế ở các họ pref bị hạn chế, do đó thiếu một phân tích toàn diện và có nền tảng lý thuyết về các không gian thiết kế.

3 Bridge-TTS
Chúng tôi mở rộng các kỹ thuật SB cho tác vụ TTS và làm sáng tỏ các không gian thiết kế với phân tích có nền tảng lý thuyết. Chúng tôi bắt đầu với một SB hoàn toàn có thể xử lý được giữa dữ liệu ghép đôi trong mô hình TTS. Dựa trên công thức như vậy, chúng tôi đưa ra các mục tiêu huấn luyện khác nhau và nghiên cứu lý thuyết về lấy mẫu SB dưới dạng SDE và ODE, dẫn đến các sơ đồ lấy mẫu bậc nhất mới khi kết hợp với các tích phân hàm mũ. Trong các thảo luận sau, chúng tôi nói rằng hai hàm mật độ xác suất giống nhau khi chúng bằng nhau đến một hệ số chuẩn hóa. Bên cạnh đó, chúng tôi giả định thời gian tối đa T= 1 để thuận tiện.

3.1 Cầu nối Schrodinger giữa Dữ liệu Ghép đôi
Như chúng tôi đã thảo luận, với các thuộc tính của dạng tiên nghiệm không hạn chế và điều kiện biên nghiêm ngặt, SB là một sự thay thế tự nhiên cho các mô hình khuếch tán khi chúng ta có một tiên nghiệm có thông tin mạnh mẽ. Trong tác vụ TTS, các cặp dữ liệu thật (x, y) và tiên nghiệm xác định z=E(y) được cho bởi bộ mã hóa văn bản có thể được xem là hỗn hợp của các biên phân phối Dirac kép (δx, δz), điều này đơn giản hóa việc giải bài toán SB. Tuy nhiên, trong trường hợp như vậy, bài toán SB trong Phương trình (5) sẽ không tránh khỏi sụp đổ khi có một quá trình tham chiếu ngẫu nhiên chấp nhận một mật độ liên tục pref1 tại t= 1, vì sự phân kỳ KL giữa một phân phối Dirac và một độ đo xác suất liên tục là vô hạn.

Để giải quyết vấn đề này, chúng tôi xem xét một quan sát nhiễu của các điểm dữ liệu biên x0,x1 bị ô nhiễm bởi một lượng nhỏ nhiễu Gaussian N(0, ϵ21I) và N(0, ϵ22I) tương ứng, điều này giúp chúng tôi xác định công thức SB giữa dữ liệu sạch khi ϵ1, ϵ2→0. Thực tế, chúng tôi chỉ ra rằng trong các trường hợp tổng quát trong đó SDE tham chiếu có một drift tuyến tính f(xt, t) =f(t)xt (phù hợp với SGM), SB có một giải pháp hoàn toàn có thể xử lý được và gọn gàng khi ϵ2=eR10f(τ)dτϵ1. Chúng tôi xây dựng kết quả trong định lý sau.

Mệnh đề 3.1 (Cầu nối Schrodinger có thể xử lý được giữa Dữ liệu Ghép đôi được Làm mịn Gaussian với SDE Tham chiếu có Drift Tuyến tính, chứng minh trong Phụ lục A.1). Giả sử f=f(t)xt, giải pháp phân tích cho Phương trình (7) khi pdata=N(x0, ϵ2I) và pprior =N(x1, e2R10f(τ)dτϵ2I) là
bΨϵt=N(αta,(α2tσ2+α2tσ2t)I),Ψϵt=N(¯αtb,(α2tσ2+α2t¯σ2t)I) (8)

--- TRANG 5 ---
trong đó t∈[0,1],
a=x0+σ2σ21(x0−x1α1),b=x1+σ2σ21(x1−α1x0), σ2=ϵ2+√σ41+ 4ϵ4−σ212, (9)
và
αt=eRt0f(τ)dτ,¯αt=e−R1tf(τ)dτ, σ2t=Zt0g2(τ)α2τdτ,¯σ2t=Z1tg2(τ)α2τdτ. (10)

Trong định lý trên, αt,¯αt, σt,¯σt được xác định bởi f, g trong SDE tham chiếu (Phương trình (1)) và tương tự như lịch trình nhiễu trong SGM [Kingma et al., 2021]. Khi ϵ→0, bΨϵt,Ψϵt hội tụ về giải pháp có thể xử lý được giữa dữ liệu ghép đôi sạch (x0,x1):
bΨt=N(αtx0, α2tσ2tI),Ψt=N(¯αtx1, α2t¯σ2tI) (11)

Ưu điểm của tính khả thi như vậy nằm ở khả năng tạo điều kiện cho việc nghiên cứu huấn luyện và lấy mẫu dưới các SDE tiến-lùi (Phương trình (6)), mà chúng tôi sẽ thảo luận trong các phần sau. Bên cạnh đó, phân phối biên pt= bΨtΨt của SB cũng có một dạng có thể xử lý được:
pt= Ψ tbΨt=N(αt¯σ2tx0+ ¯αtσ2tx1σ21,α2t¯σ2tσ2tσ21I), (12)
đây là một phân phối Gaussian có trung bình là một phép nội suy giữa x0,x1, và phương sai bằng không tại các biên và dương ở giữa. Một trường hợp đặc biệt là khi lịch trình nhiễu f(t) = 0 và g(t) =σ >0, chúng ta có pt=N((1−t)x0+tx1, σ2t(1−t)I), phục hồi cầu nối Brownian được sử dụng trong các nghiên cứu trước [Qiu et al., 2023, Tong et al., 2023a,b]. Thực tế, Phương trình (12) tiết lộ dạng của cầu nối Brownian tổng quát với drift tuyến tính và biến động thay đổi theo thời gian giữa x0 và x1. Chúng tôi đưa phân tích chi tiết vào Phụ lục B.1.

3.2 Huấn luyện Mô hình
Tác vụ TTS nhằm mục đích học một mô hình để sinh tạo Mel x0 cho văn bản y. Ký hiệu x1=E(y) là đặc trưng âm thanh tiềm ẩn được tạo ra bởi bộ mã hóa văn bản E, vì SB có thể xử lý được khi cho x0,x1 (∇logΨ,∇logbΨ trong Phương trình (6) được xác định bởi Phương trình (11)), một cách tiếp cận huấn luyện trực tiếp là tham số hóa một mạng xθ để dự đoán x0 cho xt tại các bước thời gian khác nhau, điều này cho phép chúng ta mô phỏng quá trình SB từ t= 1 đến t= 0. Điều này phù hợp với việc dự đoán dữ liệu trong các mô hình khuếch tán, và chúng tôi có mất mát cầu nối:
Lbridge =E(x0,y)∼pdata,x1=E(y)Et[∥xθ(xt, t,x1)−x0∥22] (13)
trong đó xt=αt¯σ2tσ21x0+¯αtσ2tσ21x1+αt¯σtσtσ1ϵ,ϵ∼ N(0,I) bởi SB (Phương trình (12)). x1 cũng được đưa vào mạng làm điều kiện, theo Grad-TTS [Popov et al., 2021].

Tương tự như các tham số hóa khác nhau trong các mô hình khuếch tán, có những lựa chọn thay thế của các mục tiêu huấn luyện tương đương trong huấn luyện cầu nối, chẳng hạn như dự đoán nhiễu tương ứng với ∇logbΨt [Liu et al., 2023a] hoặc điểm số SB ∇logpt, và dự đoán vận tốc liên quan đến các kỹ thuật khớp dòng [Lipman et al., 2023]. Tuy nhiên, chúng tôi thấy rằng chúng hoạt động tồi tệ hơn hoặc kém trong thực tế, điều mà chúng tôi sẽ thảo luận chi tiết trong Phụ lục D. Ngoài mất mát cầu nối, chúng tôi huấn luyện chung bộ mã hóa văn bản E (bao gồm bộ dự đoán thời lượng ˆA) theo Grad-TTS. Vì bộ mã hóa không còn tham số hóa một phân phối Gaussian, chúng tôi đơn giản áp dụng một mất mát bộ mã hóa MSE L′enc=E(x0,y)∼pdata∥E(y)−x0∥2. Và chúng tôi sử dụng cùng mất mát dự đoán thời lượng Ldp như Grad-TTS. Mục tiêu huấn luyện tổng thể của Bridge-TTS là Lbridge-tts =L′enc+Ldp+Lbridge.

Trong khung của chúng tôi, dạng linh hoạt của SDE tham chiếu tạo điều kiện cho việc thiết kế lịch trình nhiễu f, g, điều này tạo thành một yếu tố quan trọng của hiệu suất như trong SGM. Trong nghiên cứu này, chúng tôi trực tiếp chuyển các lịch trình nhiễu hoạt động tốt từ SGM, chẳng hạn như bảo toàn phương sai (VP). Như được thể hiện trong Bảng 1, chúng tôi đặt f, g2 tuyến tính theo t, và các αt, σ2t tương ứng có biểu thức dạng đóng. Các thiết kế như vậy là mới trong cả bối cảnh SB và TTS và phân biệt nghiên cứu của chúng tôi với các nghiên cứu trước đây với cầu nối Brownian [Qiu et al., 2023, Tong et al., 2023a,b].

--- TRANG 6 ---
Bảng 1: Minh họa các lịch trình nhiễu trong Bridge-TTS.
Lịch trình f(t) g2(t) αt σ2t
Bridge-gmax 0 β0+t(β1−β0) 1 12(β1−β0)t2+β0t
Bridge-VP −12(β0+t(β1−β0)) β0+t(β1−β0) e−12Rt0(β0+τ(β1−β0))dτ eRt0(β0+τ(β1−β0))dτ−1

3.3 Sơ đồ Lấy mẫu
Giả sử chúng ta có một mạng dự đoán dữ liệu đã được huấn luyện xθ(xt, t)2. Nếu chúng ta thay thế x0 bằng xθ trong giải pháp có thể xử lý được của bΨ,Ψ (Phương trình (11)) và thay thế chúng vào Phương trình (6), mô tả SB với các SDE, chúng ta có thể thu được quá trình SB được tham số hóa. Tương tự như việc lấy mẫu trong các mô hình khuếch tán, SB được tham số hóa có thể được mô tả bởi cả các quá trình ngẫu nhiên và xác định, mà chúng tôi gọi là SDE/ODE cầu nối, tương ứng.

SDE Cầu nối Chúng ta có thể theo SDE ngược trong Phương trình (6b). Bằng cách thay thế Phương trình (11) vào đó và thay thế x0 bằng xθ, chúng ta có SDE cầu nối:
dxt=f(t)xt+g2(t)xt−αtxθ(xt, t)α2tσ2tdt+g(t)d¯wt (14)

ODE Cầu nối ODE dòng xác suất [Song et al., 2021b] của SDE tiến trong Phương trình (6a) là [Chen et al., 2022a]:
dxt=f(t)xt+g2(t)∇log Ψ t(xt)−12g2(t)∇logpt(xt)dt
=f(t)xt+12g2(t)∇log Ψ t(xt)−12g2(t)∇logbΨt(xt)dt (15)
trong đó chúng ta đã sử dụng ∇logpt(xt) =∇logΨt(xt) +∇logbΨt(xt) vì pt= Ψ tbΨt. Bằng cách thay thế Phương trình (11) vào đó và thay thế x0 bằng xθ, chúng ta có ODE cầu nối:
dxt=f(t)xt−12g2(t)xt−¯αtx1α2t¯σ2t+12g2(t)xt−αtxθ(xt, t)α2tσ2tdt (16)

Để thu được mẫu dữ liệu x0, chúng ta có thể giải SDE/ODE cầu nối từ tiềm ẩn x1 tại t= 1 đến t= 0. Tuy nhiên, việc giải trực tiếp SDE/ODE cầu nối có thể gây ra lỗi lớn khi số bước nhỏ. Một kỹ thuật phổ biến trong các mô hình khuếch tán là xử lý chúng bằng các tích phân hàm mũ [Gonzalez et al., 2023, Lu et al., 2022a,b, Zheng et al., 2023a], nhằm mục đích "triệt tiêu" các hạng tuyến tính liên quan đến xt và thu được các giải pháp với lỗi rời rạc hóa thấp hơn. Chúng tôi thực hiện các phái sinh tương tự cho việc lấy mẫu cầu nối, và trình bày kết quả trong định lý sau.

Mệnh đề 3.2 (Giải pháp Chính xác và Rời rạc hóa Bậc nhất của SDE/ODE Cầu nối, chứng minh trong Phụ lục A.2). Cho một giá trị ban đầu xs tại thời gian s >0, giải pháp tại thời gian t∈[0, s] của SDE/ODE cầu nối là
xt=αtσ2tαsσ2sxs−αtσ2tZtsg2(τ)α2τσ4τxθ(xτ, τ)dτ+αtσts√1−σ2tσ2sϵ,ϵ∼ N(0,I) (17)
xt=αtσt¯σtαsσs¯σsxs+¯αtσ2tσ21(1−σs¯σt¯σsσt)x1−αtσt¯σt2Ztsg2(τ)α2τσ3τ¯στxθ(xτ, τ)dτ (18)

1Tham số chính cho lịch trình Bridge-gmax là β1, chính xác là giá trị tối đa của g2(t).
2Chúng tôi bỏ qua điều kiện x1 để đơn giản và các tham số hóa khác như dự đoán nhiễu có thể được chuyển đổi trước thành xθ.

--- TRANG 7 ---
Rời rạc hóa bậc nhất (với xấp xỉ xθ(xτ, τ)≈xθ(xs, s) cho τ∈[t, s]) cho:
xt=αtσ2tαsσ2sxs+αt(1−σ2tσ2s)xθ(xs, s) +αtσts√1−σ2tσ2sϵ,ϵ∼ N(0,I) (19)
xt=αtσt¯σtαsσs¯σsxs+αtσ21(¯σ2t−¯σsσt¯σtσs)xθ(xs, s) +σ2t−σsσt¯σt¯σsx1α1 (20)

Theo hiểu biết của chúng tôi, các phái sinh như vậy được tiết lộ lần đầu tiên trong bối cảnh SB. Chúng tôi thấy rằng rời rạc hóa bậc nhất của SDE cầu nối (Phương trình (19)) phục hồi việc lấy mẫu hậu nghiệm [Liu et al., 2023a] trên một cầu nối Brownian, và rời rạc hóa bậc nhất của ODE cầu nối (Phương trình (20)) trong giới hạn của σsσ1,σtσ1→0 phục hồi bộ lấy mẫu DDIM xác định [Song et al., 2021a] trong các mô hình khuếch tán. Bên cạnh đó, chúng ta có thể dễ dàng khám phá rằng trường hợp 1 bước của Phương trình (19) và Phương trình (20) đều là dự đoán xác định 1 bước bởi xθ. Chúng tôi đưa các phân tích chi tiết hơn vào Phụ lục B.2.

Chúng ta cũng có thể phát triển các bộ lấy mẫu bậc cao hơn bằng cách lấy khai triển Taylor bậc cao hơn cho xθ trong các giải pháp chính xác. Chúng tôi thảo luận thêm và lấy phương pháp dự đoán-hiệu chỉnh làm trường hợp bậc hai trong Phụ lục C. Trong thực tế, chúng tôi thấy rằng bộ lấy mẫu bậc nhất đủ cho tác vụ TTS, và các bộ lấy mẫu bậc cao hơn không tạo ra sự khác biệt đáng kể.

4 Thực nghiệm
4.1 Cài đặt Huấn luyện
Dữ liệu Chúng tôi sử dụng tập dữ liệu LJ-Speech [Ito and Johnson, 2017], chứa 13,100 mẫu, khoảng 24 giờ tổng cộng, từ một người nói nữ với tỷ lệ lấy mẫu 22.05kHz. Các mẫu thử nghiệm được trích xuất từ cả LJ-001 và LJ-002, và 12577 mẫu còn lại được sử dụng để huấn luyện. Chúng tôi theo thực hành phổ biến, sử dụng các công cụ mã nguồn mở [Park, 2019] để chuyển đổi chuỗi grapheme tiếng Anh thành chuỗi phoneme, và trích xuất phổ mel 80 băng với FFT 1024 điểm, tần số cắt thấp và cao 80Hz và 7600Hz, và độ dài hop 256.

Huấn luyện mô hình Để thực hiện so sánh công bằng với các mô hình khuếch tán, chúng tôi áp dụng cùng kiến trúc mạng và cài đặt huấn luyện được sử dụng trong Grad-TTS [Popov et al., 2021]: 1) bộ mã hóa (tức là bộ mã hóa văn bản và bộ dự đoán thời lượng) chứa 7.2M tham số và bộ giải mã dựa trên U-Net chứa 7.6M tham số; 2) mô hình được huấn luyện với kích thước lô 16, và tổng cộng 1.7M lần lặp trên một NVIDIA RTX 3090 duy nhất, sử dụng 2.5 ngày; 3) bộ tối ưu hóa Adam [Kingma and Ba, 2015] được sử dụng với tỷ lệ học không đổi 0.0001. Đối với lịch trình nhiễu, chúng tôi đặt β0= 0.01, β1= 20 cho Bridge-VP (chính xác giống như VP trong SGM) và β0= 0.01, β1= 50 cho Bridge-gmax.

Đánh giá Theo các nghiên cứu trước [Huang et al., 2022, Liu et al., 2022a, Popov et al., 2021], chúng tôi thực hiện các thử nghiệm chủ quan MOS (Điểm Ý kiến Trung bình) và CMOS (Điểm Ý kiến Trung bình So sánh) để đánh giá chất lượng chủ quan tổng thể và chất lượng mẫu so sánh, tương ứng. Để đảm bảo độ tin cậy của các kết quả thu thập, chúng tôi sử dụng nền tảng mở Amazon Mechanical Turk, và yêu cầu các nhân viên Master hoàn thành thử nghiệm nghe. Cụ thể, điểm MOS của 20 mẫu thử nghiệm được cho bởi 25 nhân viên Master để đánh giá hiệu suất tổng thể với thang điểm 5 điểm, trong đó 1 và 5 biểu thị chất lượng thấp nhất ("Tệ") và cao nhất ("Xuất sắc") tương ứng. Kết quả được báo cáo với khoảng tin cậy 95%. Mỗi điểm CMOS được cho bởi 15 nhân viên Master để so sánh 20 mẫu thử nghiệm được tổng hợp bởi hai mô hình khác nhau. Thêm chi tiết về thử nghiệm CMOS có thể xem trong Phụ lục G. Trong cả thử nghiệm MOS và CMOS, mỗi mẫu thử nghiệm đã được chuẩn hóa để so sánh công bằng3. Để đo tốc độ suy luận, chúng tôi tính toán hệ số thời gian thực (RTF) trên một NVIDIA RTX 3090.

3https://github.com/slhck/ffmpeg-normalize

--- TRANG 8 ---
4.2 Kết quả và Phân tích
Chúng tôi minh họa hiệu suất của Bridge-TTS về chất lượng mẫu và tốc độ suy luận riêng biệt, đảm bảo so sánh chính xác hơn giữa nhiều mô hình. Trong Bảng 2 và Bảng 3, các mẫu thử nghiệm trong tập dữ liệu LJ-Speech được ký hiệu là Recording, các mẫu được tổng hợp từ phổ mel thật bởi vocoder được ký hiệu là GT-Mel+voc., và số lượng đánh giá hàm được ký hiệu là NFE. Chúng tôi lấy HiFi-GAN [Kong et al., 2020]4 đã được huấn luyện trước làm vocoder, phù hợp với các cài đặt đường chuẩn khác. Thêm chi tiết về các mô hình đường chuẩn được giới thiệu trong Phụ lục F. Trong quá trình lấy mẫu của cả hai thử nghiệm, Grad-TTS sử dụng lấy mẫu ODE và đặt phân phối tiên nghiệm pT=N(z, τ−1dI) với tham số nhiệt độ τd= 1.5. Trong Bridge-TTS, chúng tôi sử dụng bộ lấy mẫu SDE bậc nhất được thể hiện trong Phương trình (19) với tham số nhiệt độ τb= 2 cho phân phối nhiễu ϵ=N(0, τ−1bI), điều này hữu ích cho chất lượng TTS theo quan sát của chúng tôi.

Bảng 2: So sánh MOS với khoảng tin cậy 95% cho nhiều bước lấy mẫu.
Mô hình NFE RTF (↓) MOS (↑)
Recording / / 4.10 ±0.06
GT-Mel + voc. / / 3.93 ±0.07
FastSpeech 2 1 0.004 3.78 ±0.07
VITS 1 0.018 3.99 ±0.07
DiffSinger 71 0.157 3.92 ±0.06
ResGrad 50 0.135 3.97 ±0.07
Grad-TTS 50 0.116 3.99 ±0.07
Của chúng tôi (VP) 50 0.117 4.09±0.07
Của chúng tôi (gmax) 50 0.117 4.07±0.07
Grad-TTS 1000 2.233 3.98 ±0.07
Của chúng tôi (VP) 1000 2.267 4.05±0.07
Của chúng tôi (gmax) 1000 2.267 4.07±0.07

Bảng 3: So sánh MOS với khoảng tin cậy 95% trong sinh tạo ít bước.
Mô hình NFE RTF (↓) MOS (↑)
Recording / / 4.12 ±0.06
GT-Mel + voc. / / 4.01 ±0.06
FastSpeech 2 1 0.004 3.84 ±0.07
CoMoSpeech 1 0.007 3.74 ±0.07
ProDiff 2 0.019 3.67 ±0.07
CoMoSpeech 2 0.009 3.87 ±0.07
Của chúng tôi (gmax) 2 0.009 4.04±0.06
DiffGAN-TTS 4 0.014 3.78 ±0.07
Grad-TTS 4 0.013 3.88 ±0.07
FastGrad-TTS 4 0.013 3.87 ±0.07
ResGrad 4 0.017 4.02 ±0.06
Của chúng tôi (gmax) 4 0.013 4.10±0.06

Chất lượng sinh tạo Bảng 2 so sánh chất lượng sinh tạo giữa Bridge-TTS và các hệ thống TTS trước đây. Như được thể hiện, cả hai mô hình Bridge-TTS đều vượt trội so với ba hệ thống TTS dựa trên khuếch tán mạnh mẽ: đối tác khuếch tán Grad-TTS [Popov et al., 2021], mô hình khuếch tán nông DiffSinger [Liu et al., 2022a] và mô hình khuếch tán dư ResGrad [Chen et al., 2022c]. So với mô hình dựa trên transformer FastSpeech 2 [Ren et al., 2021] và hệ thống TTS đầu cuối [Kim et al., 2021], chúng tôi cũng thể hiện chất lượng chủ quan mạnh mẽ hơn. Khi NFE là 1000 hoặc 50, Bridge-TTS của chúng tôi đạt được chất lượng vượt trội. Một lý do là thông tin điều kiện (tức là đầu ra bộ mã hóa văn bản) trong tổng hợp TTS mạnh mẽ, và lý do khác là bộ lấy mẫu Bridger bậc nhất của chúng tôi duy trì chất lượng mẫu khi giảm NFE.

Tốc độ lấy mẫu Bảng 3 thể hiện đánh giá tốc độ lấy mẫu với mô hình Bridge-TTS-gmax, vì chúng tôi quan sát thấy nó đạt được chất lượng cao hơn so với hệ thống Bridge-TTS dựa trên VP. Để thực hiện so sánh công bằng, chúng tôi chọn NFE được báo cáo trong các mô hình đường chuẩn. Như được thể hiện, trong lấy mẫu 4 bước, chúng tôi không chỉ vượt trội so với đối tác khuếch tán Grad-TTS [Popov et al., 2021], FastGrad-TTS [Vovk et al., 2022] sử dụng bộ lấy mẫu SDE bậc nhất, và DiffGAN-TTS [Liu et al., 2022b] với biên độ lớn, mà còn đạt được chất lượng cao hơn ResGrad [Chen et al., 2022c] đứng trên FastSpeech 2 [Ren et al., 2021] đã được huấn luyện trước. Trong lấy mẫu 2 bước với RTF 0.009, chúng tôi đạt được chất lượng cao hơn phương pháp lấy mẫu nhanh tiên tiến nhất CoMoSpeech [Ye et al., 2023]. So với phương pháp 1 bước, FastSpeech 2 và CoMoSpeech, mặc dù sinh tạo 2 bước của chúng tôi hơi chậm hơn, chúng tôi đạt được chất lượng tốt hơn rõ rệt.

4https://github.com/jik876/hifi-gan

--- TRANG 9 ---
4.3 Nghiên cứu Trường hợp
Chúng tôi thể hiện một mẫu khi NFE=4 trong Hình 2 (a), sử dụng bộ lấy mẫu ODE bậc nhất được thể hiện trong Phương trình (20). Như được thể hiện, Bridge-TTS rõ ràng sinh tạo nhiều chi tiết hơn của mục tiêu so với đối tác khuếch tán Grad-TTS (τd= 1.5). Hơn nữa, chúng tôi thể hiện một quỹ đạo lấy mẫu ODE 2 bước của Bridge-TTS trong Hình 2 (b). Như được thể hiện, với quá trình sinh tạo dữ liệu-thành-dữ liệu của chúng tôi, mỗi bước lấy mẫu đang thêm nhiều chi tiết hơn để tinh chỉnh tiên nghiệm đã cung cấp thông tin mạnh mẽ về mục tiêu. Thêm mẫu được sinh tạo có thể xem trong Phụ lục H.

4.4 Nghiên cứu Loại bỏ
Chúng tôi thực hiện một số nghiên cứu so sánh bằng cách thể hiện kết quả CMOS giữa các thiết kế khác nhau của tiên nghiệm, lịch trình nhiễu và bộ lấy mẫu khi NFE =1000 và NFE =4. Cài đặt cơ sở là lịch trình Bridge-gmax, bộ dự đoán x0 và bộ lấy mẫu SDE bậc nhất có tỷ lệ nhiệt độ (τb= 2).

Bảng 4: So sánh CMOS của cài đặt huấn luyện và lấy mẫu của Bridge-TTS.
Phương pháp NFE =4 NFE =1000
Bridge-TTS (gmax) 0 0
với tiên nghiệm có thể thay đổi - 0.13 - 0.17
với g(t) không đổi - 0.12 - 0.14
với VP - 0.03 - 0.08
với SDE (τb= 1) - 0.07 - 0.19
với ODE - 0.10 + 0.00

Tiên nghiệm Chúng tôi khám phá hai chiến lược huấn luyện khác nhau về tiên nghiệm của chúng: 1) giống như Grad-TTS [Popov et al., 2021], phần bộ mã hóa và bộ giải mã được huấn luyện chung từ đầu (tức là tiên nghiệm có thể thay đổi); 2) bộ mã hóa được huấn luyện trước với giai đoạn khởi động sau đó bộ giải mã được huấn luyện từ đầu (tức là tiên nghiệm cố định). Cần lưu ý rằng trong cả hai chiến lược, bộ mã hóa văn bản được huấn luyện với mục tiêu tương đương. Như được thể hiện, chiến lược sau nhất quán có chất lượng mẫu tốt hơn trên các NFE khác nhau. Do đó, chúng tôi áp dụng nó làm cài đặt mặc định.

Lịch trình nhiễu Chúng tôi so sánh ba cấu hình khác nhau cho lịch trình nhiễu: Bridge-gmax, Bridge-VP, và một lịch trình đơn giản với f(t) = 0, g(t) = 5 có phương sai biên tối đa gần như giống với Bridge-gmax, mà chúng tôi gọi là "g(t) không đổi". Như được thể hiện trong Bảng 4, Bridge-gmax và Bridge-VP có hiệu suất tổng thể tương tự, trong khi g(t) không đổi có chất lượng giảm sút rõ rệt so với Bridge-gmax khi NFE =1000. Trực giác, Bridge-gmax và Bridge-VP có một mô hình bất đối xứng của phương sai biên gán nhiều bước hơn cho khử nhiễu, trong khi g(t) không đổi tạo ra một mô hình đối xứng. Về mặt thực nghiệm, mô hình bất đối xứng của phương sai biên như vậy giúp cải thiện chất lượng mẫu. Chúng tôi cung cấp minh họa chi tiết hơn về lịch trình nhiễu trong Phụ lục E.

Quá trình lấy mẫu Để so sánh giữa các quá trình lấy mẫu khác nhau, SDE có tỷ lệ nhiệt độ (τb = 2) đạt được chất lượng tốt nhất ở cả NFE =4 và NFE =1000. So với lấy mẫu SDE vanilla (tức là τb= 1), việc giới thiệu kỹ thuật lấy mẫu nhiệt độ cho SDE có thể giảm hiệu quả các hiện tượng nhiễu nền và nâng cao chất lượng mẫu khi NFE lớn, điều này được phản ánh rõ ràng trong điểm CMOS trong Bảng 4. Trong khi đó, bộ lấy mẫu ODE thể hiện cùng chất lượng với SDE có tỷ lệ nhiệt độ tại NFE=1000, nhưng nó có nhiều hiện tượng nhiễu rõ ràng hơn tại NFE =4.

5 Nghiên cứu Liên quan
Tổng hợp TTS dựa trên Khuếch tán Grad-TTS [Popov et al., 2021] xây dựng một đường chuẩn TTS mạnh mẽ với SGM, vượt qua mô hình dựa trên transformer [Ren et al., 2019] và mô hình dựa trên dòng [Kim et al., 2020]. Trong các nghiên cứu sau, các phương pháp lấy mẫu nhanh được nghiên cứu rộng rãi, chẳng hạn như cải thiện phân phối tiên nghiệm [Lee et al., 2022], thiết kế bộ lấy mẫu không cần huấn luyện [Jeong et al., 2021, Vovk et al., 2022], sử dụng mô hình phụ trợ [Chen et al., 2022c, Liu et al., 2022a], giới thiệu mất mát đối kháng [Ko and Choi, 2023, Liu et al., 2022b], sử dụng chưng cất kiến thức [Huang et al., 2022, Ye et al., 2023], phát triển U-Net nhẹ [Chen et al., 2023], và tận dụng khung CFM [Guan et al., 2023, Guo et al., 2023, Mehta et al., 2023]. Tuy nhiên, các phương pháp này thường khám phá để tìm một sự đánh đổi tốt hơn giữa chất lượng TTS và tốc độ lấy mẫu so với các mô hình khuếch tán thay vì đồng thời cải thiện cả hai, và một số phương pháp này yêu cầu các thủ tục bổ sung, chẳng hạn như tiền xử lý dữ liệu, mạng phụ trợ và giai đoạn chưng cất, hoặc dễ bị bất ổn huấn luyện. Trái ngược với mỗi phương pháp trước đây nghiên cứu quá trình dữ liệu-thành-nhiễu, chúng tôi trình bày một hệ thống TTS mới với cầu nối Schrodinger có thể xử lý được, minh họa các ưu điểm của quá trình dữ liệu-thành-dữ liệu.

Cầu nối Schrodinger Giải quyết bài toán cầu nối Schrodinger với một thủ tục lặp để mô phỏng các quá trình ngẫu nhiên không thể xử lý được đã được nghiên cứu rộng rãi [Chen et al., 2022a, De Bortoli et al., 2021, Liu et al., 2023d, Peluchetti, 2023, Shi et al., 2023, Vargas et al., 2021, Wang et al., 2021]. Hai nghiên cứu gần đây [Liu et al., 2023a, Somnath et al., 2023] xây dựng cầu nối trong dịch thuật hình ảnh và một tác vụ sinh học, trong khi không có nghiên cứu nào trong số chúng điều tra không gian thiết kế được thảo luận trong nghiên cứu của chúng tôi, điều này quan trọng đối với chất lượng mẫu và tốc độ suy luận.

6 Kết luận
Chúng tôi trình bày Bridge-TTS, một phương pháp TTS mới được xây dựng trên quá trình dữ liệu-thành-dữ liệu, cho phép sinh tạo phổ mel từ một tiên nghiệm xác định thông qua cầu nối Schrodinger. Dưới khung SB có thể xử lý được, linh hoạt với lý thuyết được làm sáng tỏ của chúng tôi, chúng tôi khám phá toàn diện không gian thiết kế của lịch trình nhiễu, tham số hóa mô hình và quá trình lấy mẫu ngẫu nhiên/xác định, tiếp tục nâng cao chất lượng TTS với lịch trình nhiễu bất đối xứng, dự đoán dữ liệu và các bộ lấy mẫu cầu nối bậc nhất. Về mặt thực nghiệm, chúng tôi đạt được cả chất lượng sinh tạo và tốc độ suy luận tiên tiến nhất với một phiên huấn luyện duy nhất. Trong cả sinh tạo 1000 bước và 50 bước, chúng tôi vượt trội đáng kể so với đối tác khuếch tán Grad-TTS [Popov et al., 2021]; trong sinh tạo 4 bước, chúng tôi hoàn thành chất lượng cao hơn FastGrad-TTS [Vovk et al., 2022]; trong sinh tạo 2 bước, chúng tôi vượt qua phương pháp chưng cất tiên tiến nhất CoMoSpeech [Ye et al., 2023], và mô hình dựa trên transformer FastSpeech 2 [Ren et al., 2021]. Chúng tôi hy vọng nghiên cứu của chúng tôi có thể mở ra một con đường mới để khai thác họ rộng lớn của tiên nghiệm có thông tin mạnh mẽ để tiếp tục giải phóng tiềm năng của các mô hình sinh tạo trên một loạt các ứng dụng.

[Tiếp tục với phần tài liệu tham khảo và các phụ lục...]

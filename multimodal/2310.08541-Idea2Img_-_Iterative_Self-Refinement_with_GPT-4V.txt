# 2310.08541.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/multimodal/2310.08541.pdf
# File size: 33071488 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Idea2Img : Iterative Self-Refinement with GPT-4V
for Automatic Image Design and Generation
Zhengyuan Yang , Jianfeng Wang , Linjie Li, Kevin Lin, Chung-Ching Lin ,
Zicheng Liu , and Lijuan Wang
Microsoft
{zhengyang,jianfw,lindsey.li,keli,chungching.lin,zliu,lijuanw}@microsoft.com
https://idea2img.github.io/
Abstract. We introduce “Idea to Image,”1an agent system that enables
multimodal iterative self-refinement with GPT-4V(ision) for automatic
image design and generation. Humans can quickly identify the character-
istics of different text-to-image (T2I) models via iterative explorations.
This enables them to efficiently convert their high-level generation ideas
into effective T2I prompts that can produce good images. We investi-
gate if systems based on large multimodal models (LMMs) can develop
analogous multimodal self-refinement abilities that enable exploring un-
known models or environments via self-refining tries. Idea2Img cyclically
generates revised T2I prompts to synthesize draft images, and provides
directionalfeedbackforpromptrevision,bothconditionedonitsmemory
of the probed T2I model’s characteristics. The iterative self-refinement
bringsIdea2Img various advantages over vanilla T2I models. Notably,
Idea2Img can process input ideas with interleaved image-text sequences,
follow ideas with design instructions, and generate images of better se-
mantic and visual qualities. The user preference study validates the effi-
cacy ofIdea2Img on automatic image design and generation via multi-
modal iterative self-refinement.
Keywords: Multimodal Agents ·Self-Refinement ·Large Multimodal
Models ·Image Design and Generation
1 Introduction
“Image design and generation” aims to create an image from a high-level user
idea. This input IDEAcan contain interleaved reference images, such as “the
dog looks like the one in the image,” or with instructional texts specifying the in-
tended design usage, such as “a logo for the Idea2Img system.” To convert IDEA
into an image, humans may first draft detailed descriptions of the imagined im-
age, and then use text-to-image (T2I) models [36,39,40,42,63] to generate the
image. This manual process for users to search for an ideal detailed description
(i.e., T2I prompt) that fits the T2I model typically involves iterative explo-
ration [51,67]. As shown in Figure 1, humans may first design and draft an
1Short for “ Idea2Img .” System logo design
 assisted by Idea2Img .arXiv:2310.08541v2  [cs.CV]  14 Aug 2024

--- PAGE 2 ---
2 Z. Yang et al.
Output:  A portrait of Bill Gates on a 
bustling city street, with his right hand 
raised in a friendly wave with his palm 
facing forward, standing next to a Siberian 
Husky with striking blue eyes and a playful 
tongue sticking out, in a lively and 
welcoming setting with natural daylight.Prompt Generation
generate initial/revised prompt
Feedback Reflection
give text feedback
LMM 
with 
MemoryDraft Image Selection
select best draft image
T2I Model
Idea2Img Framework  
Multimodal iterative 
self-refinement
Unknown model 
or environment to 
exploredraft image * Ndraft image * N
draft image * 1
text feedbacktext feedback
text prompt * N①②
③Input: Multimodal user-imagined IDEA  to generate
photo of Bill Gates  with 
the same hand gesture  as 
in the given image, with a dog looks 
like this one in the 
imageIDEA 1:
IDEA
①②③.
Idea2Img 
Frameworkphoto of Bill Gates  
with the same suit  
as in the given 
image on the 
street, with a dog 
looks like 
this one in 
the imageIDEA 2:
Idea2Img 
Framework
cartoon  drawing of 
the person as in 
the given image 
playing with a dog 
on the beach, with a dog 
looks like 
this one in 
the imageIDEA 3:
Idea2Img 
Framework
Fig. 1:Idea2Img framework enables LMMs to mimic human-like exploration to use
a T2I model, enabling the design and generation of an imagined image specified as a
multimodal input IDEA. The iterative process involves LMMs functioning in different
roles to refine the image creation. Specifically, LMMs will (1)generate and revise text
prompts for the T2I model, (2)select the best draft images, and (3)provide feedback
on the errors and revision directions. This multimodal iterative self-refinement process
requires LMMs to memorize the T2I model’s characteristics observed in previous iter-
ations as humans and adjust T2I prompts accordingly.
initial T2I prompt based on their imagined IDEAto generate. Then, they can
obtain multiple draft images with a T2I model, select the most promising draft,
write text feedback, and further revise the T2I prompt. As this iteration pro-
gresses, we humans can swiftly grasp the characteristics of a specific T2I model,
such as words that the model can not understand, finally producing a good im-
age generated by a suitable T2I prompt. Given the remarkable capabilities of
large multimodal models (LMMs) [14,31,57], we explore if we can build sys-
tems based on LMMs to develop similar iterative self-refinement ability, thereby
relieving humans from the tedious process of converting ideas to images.
Iterative self-refinement is one intrinsic ability humans possess when explor-
ing unknown environments and solving complicated problems. Large language
models (LLMs) agent systems [9,27,46] have demonstrated the effectiveness of
self-refinement in better addressing natural language processing tasks, such as
acronym generation, sentiment retrieval, text-based environment exploration,
etc. Transitioning from text-only tasks to multimodal environments poses new
challenges of improving, assessing, and verifying multimodal contents, such as
multiple interleaved image-text sequences. For example, when learning to use
T2I models, LMMs need to improve the generation with revised T2I prompts,
assessmultipleimagesindetailtoselectthebestdraft,andverifythedraftimage
with the multimodal IDEAto provide text feedback. These steps, each requir-
ing different multimodal understanding capabilities, jointly enable the intriguing
multimodal iterative self-refinement ability. Such an LMM framework can au-

--- PAGE 3 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 3
photo of the object pointed 
by the blue arrow , and a 
brown corgi dog
painting of a corgi dog  with 
style similar to this one  in 
the image
an image of a hand 
holding an iphone. 
The image is used 
for illustrating how 
to take a screen 
shot on iphone5 people  sitting 
around a table 
drinking beer and 
eating buffalo 
wingsa logo suitable for 
a stylish hotel .
a drawing with  the 
background changed to a 
beachA hand drawing of a room 
where people can sleep and 
study . Hand drawing shows 
the sketch and looks like the 
given image .
a plate that has no 
bananas on it. 
there is a glass  
without  orange 
juice next to ita whole cake on 
the table with 
words Azure 
Research  written 
on the cakean image of a car 
perfect for a 
children's painting 
competition
Photo of 
Bill Gates 
with the 
same cloth  
as in the 
given 
image
with a 
dog 
looks 
like 
this 
one in 
the 
image
Object count
Scene textKnowledge
Prompt followingVisual design
Intended usage
Visual design & style
Concept customization & visual pointing
Image manipulation
Multiple concepts customization
Blending images for new visual design
Style transfer
painting of a corgi dog with 
style different from this 
one in the image
Find the the image style 
pattern in the left two dog 
images and apply it on the top 
right people in tree pose 
image.  Provide a textual 
description that keeps the 
content in the people in tree 
pose image, with the correct 
style pattern.In-context entity and style transferOpposite style transfer
Cartoon drawing of Mr 
Bean  playing tennis, with 
the same cloth and pose 
as in the given imageVisual attribute referring
A 
painting 
of a 
tennis 
game, with the 
image 
style 
similar to 
this one in 
the image
Visual attribute referring & style transfer
and 
the 
second 
image 
is
A logo with  a 
design that 
naturally 
blends the 
two given 
images as a 
new logo . 
The first 
image is
IDEA T2I Idea2Img IDEA T2I Idea2Img IDEA T2I Idea2Img
IDEA T2I Idea2Img IDEA T2I Idea2Img
Fig. 2:Overview of the image design and generation scenarios enabled by Idea2Img .
In each sub-figure, the image and text in the left green box are the user input IDEA.
The center image is the baseline results directly generated by the same T2I model with
a human-written T2I prompt, and the image on the right is generated with the T2I
prompt discovered by Idea2Img ’s iterative self-refinement exploration.
tomatically learn to tackle various real-world problems [57] via self-exploration,
such as navigating GUI to use electronic devices, exploring unknown physical
environments via an embodied agent, engaging in electronic games, and so on.
In this study, we focus on “image design and generation” as the task to study
the multimodal iterative self-refinement ability.
To this end, we introduce Idea2Img , a multimodal iterative self-refinement
framework for automatic image design and generation. As illustrated in Fig-
ure 1,Idea2Img involves an LMM, GPT-4V(ision) [1,31–33], interacting with a

--- PAGE 4 ---
4 Z. Yang et al.
T2I model to probe its usage and find an effective T2I prompt. The LMM will
act in different roles to analyze the return signal from the T2I model ( i.e., draft
images) and design the next round’s queries ( i.e., text T2I prompts). The three
roles of generating T2I prompts, selecting draft images, and reflecting feedback
together enable the multimodal iterative self-refinement ability. Specifically, (1)
Prompt generation: GPT-4V generates Ntext prompts that correspond to the
input multimodal user IDEA, conditioned on the previous text feedback and
refinement history; (2)Draft image selection: GPT-4V carefully compares N
draft images for the same IDEAand select the most promising one; (3)Feed-
back reflection: GPT-4V examines the discrepancy between the draft image and
theIDEA. GPT-4V then provides feedback on what is incorrect, the plausible
causes, and how T2I prompts may be revised to obtain a better image. Fur-
thermore, Idea2Img is enhanced with a memory module that stores all prompt
exploration histories, including previous draft images, text prompts, and feed-
back. The Idea2Img framework iterates among these three steps with GPT-4V
for automatic image design and generation.
To users, Idea2Img functions as an enhanced image design and generation
assistant. Compared with T2I models, Idea2Img can handle design instructions
instead of requiring detailed image description, support the multimodal IDEA
input, and generate images of better semantic and visual qualities. We overview
representative image design and generation scenarios in Figure 2. For example,
Idea2Img can incorporate the visual design and intended usage description in
IDEA, extract arbitrary visual information from the input image, and process
IDEAwith arbitrarily interleaved image-text sequences. Built upon these new
functionalities and scenarios of interest, we develop an evaluation IDEAset with
104samples, containing complicated queries that humans may fail in their first
trials.Weperformuserpreferencestudieson Idea2Img withdifferentT2Imodels.
The consistent user preference score improvements on different image generation
models,e.g.,+26.9%with SDXL [36], indicate the effectiveness of Idea2Img in
image design and generation.
Our contributions are summarized as follows.
–We study “automatic image design and generation,” which aims to create an
image from an input IDEA. This new multimodal IDEAinput enables visual
creation with reference image inputs and instructions on desired designs.
–Weexplorethemultimodaliterativeself-refinementabilityinGPT-4V-based
agent systems, showcasing its effectiveness in improving, assessing, and ver-
ifying multimodal contents.
–We propose Idea2Img , a multimodal iterative self-refinement framework that
enhances any image generation model for visual design, enabling various new
image creation functionalities, and achieving better generation qualities.
–We present an evaluation set with 104challenging multimodal IDEA. The
consistent user preference score improvements, when experimented on differ-
ent image generation models, indicate Idea2Img ’s effectiveness in automatic
image design and generation.

--- PAGE 5 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 5
2 Related Work
LLM-basedself-refinement. Idea2Img isinspiredbytheeffectivenessofitera-
tiveself-refinementinLLM-basedagentsystems[27,34,46]inexploringunknown
environments and tasks, built upon the successful LLM agents [15,35,37,43,56,
61,66]. Self-refine [27] takes the same LLM to iteratively critique its outputs and
leverage this feedback to enhance its predictions, showing effectiveness across
various NLP tasks. Reflexion [46] explores a self-reflective LLM system on the
text-based environment exploration task [47] and multi-hop QA [60]. Despite the
success, LLM-based self-refinement naturally can not understand multimodal in-
puts. Consequently, the explored tasks and environments are limited to the nat-
ural language description, such as AlfWorld [47]. Idea2Img explores the potential
of an LMM-based iterative self-refinement system for multimodal environment
exploration, from a simple T2I model to other more complicated environments.
Multimodal agents. OurIdea2Img is related to multimodal agents [16,22,26,
44,49,52,58,64] that chain external tools such as T2I or vision-language models
with LLMs for multimodal tasks. For instance, MM-ReAct [58] integrates Chat-
GPT with multiple vision tools for multimodal reasoning and action, enabling it
to solve various complicated visual understanding tasks. Visual ChatGPT [52]
empowers ChatGPT to allocate various image generation models, such as Stable
Diffusion [40], img2img model [28], ControlNet [65], enabling multi-step visual
editing and generation. The primary difference between Idea2Img and existing
multimodal agent studies [52,58] lies in the approach to understand the tool
usage. Existing studies assume the knowledge of how to best use each tool and
provide such information to LLMs via text instructions or in-context examples.
In contrast, the optimal usage of the tool remains unknown in Idea2Img and re-
quires iterative exploration. Another minor distinction is that Idea2Img utilizes
LMMs instead of LLMs, thereby does not require general visual understanding
tools such as a caption model [50,53].
Extensions of base T2I models. Idea2Img provides a more natural way for
users to design and produce their desired visual content. This framework, which
extends T2I models for new functionalities, is related to various works in im-
proving base T2I models [36,39,40,42,63]. These studies include extending the
base T2I model to better follow user prompts [5,7,10,12], finding magic words in
T2I prompts for better visual quality [51,67], supporting extra image input for
image manipulation [6,17,18,28], style transfer [13], visual concept customiza-
tion [2,8,19,41,45], and so on. While specialized T2I extensions can address a
single specific functionality, Idea2Img offers a more unified and widely applicable
framework. That is, a single Idea2Img framework can handle various generation
scenarios, ranging from style transfer to attribute customization, without re-
quiring separate models or task-specific model design and finetune. More impor-
tantly,Idea2Img effectively collaborates with those enhanced generative models,
consistently improving them by exploring suitable text prompts.

--- PAGE 6 ---
6 Z. Yang et al.
①② ③ ④ ⑤⑥
① ③
②
Fig. 3:The framework overview of Idea2Img , which takes an LMM [31,32] to explore a
T2I model via multimodal iterative self-refinement, leading to an effective T2I prompt
for the input user IDEA. The rounded rectangle shape indicates a GPT-4V call.
3Idea2Img Framework
Figure 3 illustrates the Idea2Img framework. Idea2Img framework involves two
core pre-trained models, i.e., the GPT-4V(ision) as the LMM Mand a text-
conditioned image generation model2to explore G.Idea2Img also contains a
memory mthat stores insights on Gdiscovered by Mduring previous iterations.
Execution flow. We begin with an overview of the key steps in Miteratively
exploring the use of G. Starting from the top-left of Figure 3, “initial prompt
generation” converts the input multimodal user IDEAinto T2I text prompts,
later producing multiple draft images with T2I model G. “Draft image selection”
then selects the best draft image among them for the current iteration. The
selected image is either output as the final prediction or continues for further
refinement, depending on the stop condition. For the latter, “feedback reflec-
tion” compares the current best draft image with the multimodal IDEA, and
summarizes the major discrepancy as text feedback. With the iteration history
and text feedback, “revised prompt generation” then drafts revised T2I prompts
and continues the iterative self-refinement with the new set of draft images.
1Initial prompt generation. This step generates Ninitial T2I prompts
y0
0, . . . , yN−1
0	
following the input user IDEA x, by prompting Mwith LMM
prompt pgen:
y0
0, . . . , yN−1
0	
=M(x, pgen) (1)
The “initial prompt generation” requires Mto understand multimodal user
IDEA xand convert design IDEAinto descriptive T2I prompts. LMM prompt
pgenis a zero-shot prompt without in-context examples.
2We will show image generation models other than T2I later in experiments. For
clarity, we use T2I as a representative generation model to introduce Idea2Img .

--- PAGE 7 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 7
With the “initial prompt generation” step, Idea2Img can understand user
IDEAwithinterleavedimage-textsequences,insteadofthetext-onlyT2Iprompts
containing the image description. Specifically, (1)IDEAcan be a high-level de-
sign or usage instead of the detailed image description, such as “a car image for
a children’s painting competition”; and (2)IDEAcan take multiple images and
use interleaved text instruction to extract arbitrary visual information of inter-
est, including image style, visual entity, object attributes, etc. Then, in iteration
t= 0as well as future iterations t=t, each T2I prompt yn
tis separately sent to
the T2I model G, resulting in Ndraft images in
t=G(yn
t), n= 0, . . . , N −1.
2Draft image selection. With the Ndraft images in iteration t, “draft
image selection” selects the best draft image i∗
tby prompting Mwith LMM
prompt pselect:
i∗
t=M(i0
t, . . . , iN−1
t, x, p select ). (2)
The design of a “draft image selection” step is motivated by the observation that
T2I models could generate bad images with good prompts. This step is designed
to filter out low-quality images, and avoid the quality perturbation to dominate
the iterative refinement.
The task of selecting the best image requires Mto compare and grade both
the semantics and visual quality of Nsimilar draft images. We find such a “spot
the difference” task challenging for LMMs, and only the very recent models [31,
57] are capable of performing the selection reliably.
3Feedback reflection. After obtaining the selected image i∗
t, the framework
checks the stop condition, such as if the current iteration texceeds the maximum
T.Idea2Img then outputs i∗
tas the output image or proceeds the refinement
process to the “feedback reflection” step accordingly.
“Feedback reflection” aims to provide text feedback ftthat describes the
directiontoimprovefordraftimage i∗
t.Thestepsprompts MwithLMMprompt
pfb, conditioned on the draft image i∗
tand memory m:
ft=M(i∗
t, m, x, p fb). (3)
“Feedback reflection” takes Mto compare an image i∗
twith the multimodal
userIDEA x, and summarize the gap as text feedback ft. The step not only
requires Mto identify the discrepancy between image i∗
tandIDEA x, but also
benefitsfrom writingthemajorerrors tomake theiterationeffective.Inpractice,
we find it helpful to explicitly specify the aspects to check, such as style, entity,
attributes,appearance, etc.,viatextinstructionsorin-contextexamplesinLMM
prompt pfb. Furthermore, we add text instructions to pfbto have M“focus on
one thing to improve in each feedback,” and “provide a high-level explanation of
how to modify prompts to address the given feedback.”
4/1Revised prompt generation. Finally, “prompt generation” takes text
feedback ftand memory mto draft Nrevised prompt
y0
t+1, . . . , yN−1
t+1	
, by
prompting Mwith LMM prompt previse:

y0
t+1, . . . , yN−1
t+1	
=M(ft, m, x, p revise ). (4)

--- PAGE 8 ---
8 Z. Yang et al.
Generating revised prompts requires Mto understand the property of Gstored
in memory m, thereby drafting new T2I prompts that could most likely address
theissueidentifiedin ft.Weempiricallydemonstratethat Idea2Img cangenerate
better prompts for Gvia iterative self-refinement.
Memory module. Memory mis one important design in Idea2Img .mhas
the format of interleaved image-text sequences that store all previous iterations’
feedback, selected draft image, and the corresponding text prompts:
mt=
y∗
0, i∗
0, f0, . . . , y∗
t−1, i∗
t−1, ft−1
. (5)
It allows LMM Mto understand the properties and capabilities of the T2I
model Gin use, such as a keyword that Gmay not understand or a complicated
scene that Gfail to generate, and incorporate such knowledge in generating the
revised T2I prompts y. For example, it may describe the appearance of a yoga
pose in detail, instead of only mentioning its name in y. Examples are shown in
Appendix Figures A-D, when comparing initial and refined prompts y0andyT.
4 Experiments
4.1 Experiment Settings
Compared model variants. We mainly compare the following three models
in image generation.
–“Initial-round manual prompt ” isthebaselineT2Ipromptwrittenbyhumans
with minor prompt engineering. It serves as the baseline of a T2I prompt
that merely contains key information in IDEA.
–“Initial-round Idea2Img prompt” is the LMM-generated T2I prompt in the
initialround.Specifically,themaxiteration T= 1,andLMM Misonlyused
for initial prompt generation and draft image selection, but not feedback
reflection nor revised prompt generation. This Idea2Img variant is used to
ablateIdea2Img ’s gain from prompt generation and selection, vs. the further
iterative refinement.
–“Iterative self-refined Idea2Img prompt” is complete Idea2Img pipeline with
the max iteration T= 3.
Evaluation samples and metrics. For the quantitative evaluation, we collect
a dataset of 104userIDEAas input queries. Among them, 33queries contain
text only, 43queries contain an image-text sequence with a single image, and the
remaining 28contains a sequence with two or more images. The text in most
IDEAcontains not only descriptive content text that describes the scene to
generate, but also instructional text such as “a logo for commercial advertising”
or “generate the pointed dog in blue.” All test queries are manually composed.
We then perform the user preference study as the main quantitative metric.
Users are presented with the IDEAand multiple images to select the best one
for each IDEA. The evaluation script automatically shuffles the order during
evaluation to prevent the influence of image orders.

--- PAGE 9 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 9
Table 1: User preference scores when applying Idea2Img onto different image genera-
tion models (compare the three scores in the middle section within each row individu-
ally). We observe that “Iterative self-refined Idea2Img prompt” is consistently favored
across all experimented image generation models. ∆iterationreports the preference gain
from the iterative Idea2Img over the initial-round Idea2Img .
User preference Initial-round Initial-round Iterative self-refined∆iterationscore (%) manual prompt Idea2Img prompt Idea2Img prompt
SDXL v1.0 13.5 29.8 56.7 +26.9
DeepFloyd IF 14.4 34.6 51.0 +16.3
SD v2.1 13.5 40.4 46.2 +5.8
SD v1.5 8.6 43.3 48.1 +4.8
SDXL-img2img 8.6 34.6 56.7 +16.3
IF-img2img 8.6 38.5 52.9 +14.4
Idea2Img
SDXL v1.0 DeepFloyd IF SD v1.5 SD v2.1
Fig. 4:User preference scores among T2I models before and after iterative self-
refinement. We observe that the initially favored T2I model, SDXL, benefits more
from the Idea2Img iteration.
Experimented T2I models. We experiment Idea2Img on a wide variety of
T2I model Gwith diverse model capacities and functionalities. Specifically, we
study Stable Diffusion (SD) v1.5 [40], SD v2.1, SDXL v1.0 with refiner [36], and
DeepFloyd IF (IF-I-XL and IF-II-L) [20]. Other than T2I models, we also con-
sider the img2img pipeline ( i.e., SDEdit [28]) for SDXL and DeepFloyd IF, as a
demonstration of using Idea2Img for the text-conditioned image-to-image gen-
eration. The default strength t0in the img2img pipeline is 1.00. SDXL-img2img
and IF-img2img are the same as SDXL and IF ( i.e., T2I) when IDEAcontains
text only, and condition on the first image with IDEAcontains multiple images.
LMM prompts pgen, pselect, pfb, previseare kept the same for all experimented
T2I models. Appendix Section B shows the complete LMM prompts.
4.2 Image Generation Results
User preference evaluation. Table 1 compares the user preference when
selecting from the three images generated by “initial-round manual prompt,”
“initial-round Idea2Img prompt,” and “iterative self-refined Idea2Img prompt,”

--- PAGE 10 ---
10 Z. Yang et al.
for each user IDEAwith the same T2I model. Among T2I models with different
model sizes and functionalities, Idea2Img leads to consistent improvements in
user preference. The initial-round Idea2Img prompt already improves the initial-
round manual prompt, by effectively understanding the multimodal user IDEA
and selecting the best draft images. The full Idea2Img framework further im-
proves from the initial-round Idea2Img results with the multimodal iterative
self-refinement. For example, when using SDXL v1.0, users prefer the images
generated by Idea2Img 59/104 = 56 .7%times, compared with the baseline of
14/104 = 13 .5%. Similar improvements are observed on all experimented T2I
models, as shown in the bolded column “iterative self-refined Idea2Img prompt.”
Furthermore, we examine which T2I model benefits the most from the LMM
iterative self-refinement. By comparing the ∆iterationin Table 1 that represents
the difference between first-round and iterative Idea2Img user preference, we
observe that stronger T2I models tend to benefit more from LMM refinements.
For example, SDXL and IF become more favored 26.9%and 16.3%times af-
ter iteration, compared with the 5.8%and 4.8%for SD v2.1 and SD v1.5. The
trend that stronger T2I models benefit more from Idea2Img is also observed
in Figure 4’s analysis, where users pick their preferred image generated by dif-
ferent T2I models. After Idea2Img ’s iterative refinement, the initially favored
model SDXL benefits more from the iteration, resulting in an even higher user
preference rate, from 46.2%to65.4%. We conjecture that the better language
understanding ability in stronger T2I models enables them to better follow re-
vised T2I prompts. They also have a better image generation capability that
makes it possible to generate challenging scenes, when given a good T2I prompt
optimized by Idea2Img . Nonetheless, Idea2Img is effective across T2I models of
varying capacities, consistently leading to a higher user preference score.
Qualitative comparisons. Idea2Img could help users generate images that
better follow IDEA, such as the correct object counts in Figure 5(a). Idea2Img
enables visual content design, in contrast to conventional T2I that requires a
detailedvisualcontentdescription.ForexampleinFigure5(b), Idea2Img designs
visual logo based on the instruction of “a logo for a 2024 conference in Seattle.”
The power of LMMs allows Idea2Img to extract arbitrary information from the
input image for visual generation. This could be any object in the image like “the
circled dog” in Figure 5(c) or the image style like in Figure 5(d). Such general
visualconditioningabilitycanbeseamlesslyextendedtocomposemultiplevisual
and text conditions, such as composing the camera angle and image style in
Figure 5(e) and two objects in Figure 5(f).
Other than SDXL, Idea2Img is effective in finding text prompts for other
image generation models. This includes arbitrary T2I models ( e.g., SD v2.1 [40],
DeepFloyd IF [20], DALL ·E 3 [30], etc.), text-conditioned image-to-image mod-
els (e.g., SDXL-img2img and IF-img2img with SDEdit [28]), and other special-
ist generation models ( e.g., reward-tuned T2I [11,21], region-controlled genera-
tors[23,59,65],andotherspecialistmodels[3,6,41]).Figure6overviews Idea2Img
working with different image generation models. We show additional qualitative
results and discussions in Appendix Section A.1.

--- PAGE 11 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 11
(f)(e)(d)(c)(b)
A Cavalier King Charles 
Spaniel running on a tiled 
floor, happy mood, bright 
lightingphoto of a dog looks like the circled one in 
the image running on the floor
photo of a dog looks like the 
circled one in the image 
running on the floor that is a 
black and white dog
A small Cavalier King Charles 
Spaniel with black and white 
fur, running on a tiled floor, 
tongue out, happy mood, 
bright lighting
A group of 5 friends sitting 
around a wooden table, 
drinking beer and eating 
buffalo wings in a casual 
setting.5 people sitting around a table drinking 
beer and eating buffalo wings
5 people sitting around a 
table drinking beer and 
eating buffalo wings
A group of 5 friends sitting 
around a wooden table, with 
one person at the head of 
the table and two people on 
each side, drinking beer and 
eating buffalo wings in a 
casual setting, with a 
window in the background 
and a warm, inviting 
atmosphere.
A painting of Mt Rainier 
mountain with a tree and 
lake in the foreground, in a 
colorful and abstract style 
similar to a Picasso painting.Painting of Mt rainier mountain with tree 
and lake in the foreground, with style 
similar to this one in the image
Painting of Mt rainier 
mountain with tree and lake 
in the foreground, with style 
similar to this one in the 
image that has colorful 
blocks
A painting of Mt Rainier 
mountain with a tree and 
lake in the foreground, with 
bold lines and bright colors, 
with a cubist and surrealistic 
style, with a focus on 
geometric shapes and 
patterns.Input user IDEA Initial-round manual promptInitial-round Idea2Img  
promptIterative self-refined 
Idea2Img  prompt
A painting of 
a tennis game 
from camera 
angle, with the 
image 
style 
similar to 
this one in 
the image
A painting of a tennis game 
from a top-down camera 
angle, with the image style 
similar to Claude Monet's 
impressionist paintings, with 
a bright and sunny 
atmosphere.
A painting of a tennis game 
from camera angle, with the 
image style similar to this 
one in the image that is 
impressionist
A painting of a tennis game 
from a top-down camera 
angle, with the image style 
similar to Claude Monet's 
impressionist paintings, with 
a bright and sunny 
atmosphere, with a blue sky 
and green trees in the 
background, with the players 
wearing white clothes, with 
a large crowd in the stands.
A logo design for a 2024 
conference held in Seattle, 
featuring the Seattle skyline 
and the conference title in a 
modern font, with a blue and 
green color scheme.a logo for a 2024 conference held in 
Seattle. Please provide a textual description 
of the design before generating
a logo for a 2024 conference 
held in Seattle.
A logo design for a 2024 
conference held in Seattle, 
with a modern and 
minimalist design, featuring 
the Seattle skyline and the 
conference title in a 
geometric sans serif font, 
with a blue and green color 
scheme.
with a dog 
looks like 
this one in 
the image
Bill Gates in a formal suit on 
a bustling city street, raising 
his hand in a friendly wave 
like a charming businessman, 
with a cute pug dog with a 
wrinkled face and large eyes 
by his side, under natural 
daylight, with a sense of 
approachability.
Photo of Bill Gates with the 
same hand gesture as in the 
given image that is waving 
hand, with a dog looks like 
this one in the image that is 
a pug dog
Bill Gates wearing a suit and 
tie, standing on a busy street 
with tall buildings, waving 
with his right hand raised 
and palm facing forward, 
with a small pug dog with an 
adorably wrinkled face and 
big round eyes next to him, 
in daylight, exuding 
friendliness and warmth.
(a)
Photo of Bill 
Gates with 
the same 
hand gesture 
as in the given 
image
Fig. 5:The comparisons among initial-round manual prompt, initial-round Idea2Img
prompt, and iterative self-refined Idea2Img prompt, with SDXL [36] as the T2I model.
How Idea2Img may assist humans? We use selected qualitative results to
highlight the scenarios where humans might find Idea2Img most helpful in image
design and generation, compared with conventional T2I generation.
1.New functionalities with multimodal IDEAinputs. Idea2Img pro-
vides a more natural way for human interaction, where users do not have to
describe their desired image solely through texts and painstakingly search
for the right prompt word. Instead, the multimodal IDEAallowsIdea2Img
to precisely extract specific elements from one or multiple input images, such
as the dog breed and color, pointed objects, artist style, camera view, and
more, as shown in Figure 5. Finding proper words that the T2I model can
understandforsuchvisualconceptscouldbetediousforhumans, e.g.,theart
style “with bold lines and bright colors, with a cubist and surrealistic style,
with a focus on geometric shapes and patterns.” in Figure 5(d). Idea2Img
automates this process via Idea2Img iterative self-refinement.
2.New functionalities with instructional inputs. Vanilla T2I models
struggle to understand T2I prompts that describe the intended visual design
or purpose of the generated image, such as “a logo for a 2024 conference held
in Seattle” in Figure 5(b). Instead, the prompt needs to be a comprehensive
description of the image to generate, demanding extra drafting effort from
users, such as “...the Seattle skyline in the center and the conference title

--- PAGE 12 ---
12 Z. Yang et al.
Input user IDEA Initial-round manual prompt Initial-round Idea2Img  prompt Iterative self-refine Idea2Img  prompt
6 cakes placed in a box
A cardboard box with 6 
homemade cakes, each with 
a unique design and flavor, 
ready to be delivered.
6 cakes placed in a box
A brown cardboard box with 
6 homemade cakes, each 
with a different flavor and 
design, arranged in a 
symmetrical pattern.
A contemporary logo for a 
2023 conference in Paris, 
showcasing a stylized Eiffel 
Tower, elegant fonts, and a 
color palette inspired by the 
French flag, with a touch of 
sophistication.a logo for a 2023 conference held in Paris. 
Please provide a textual description of the 
design before generating
a logo for a 2023 conference 
held in Paris.
A sleek and modern logo for 
a 2023 conference in Paris, 
incorporating a stylized Eiffel 
Tower, the year '2023' in a 
classy font, and a tricolor 
background inspired by the 
French flag. The design 
includes the word 'Paris' at 
the bottom in a refined font, 
symbolizing sophistication 
and culture.
The image of a man waving is 
stylized with a low-poly design, 
where the scene is broken down 
into geometric shapes filled with 
bold and vibrant colors, creating a 
visually striking and 
contemporary aesthetic, under 
the bright sky.Find the the image style pattern in the left 
two dog images and apply it on the top 
right people waving hand image. Provide a 
textual description that keeps the content 
in the people waving hand image, with the 
correct style pattern.
Find the the image style pattern 
in the left two dog images and 
apply it on the top right people 
waving hand image
A man in a formal suit is captured 
mid-motion, his hand raised in a wave, 
each finger distinctly visible. The entire 
scene is reimagined in a low-poly art style, 
where each facet of the man and his attire 
is defined by geometric shapes filled with 
a palette of bold, contrasting colors. The 
background remains a solid, untextured 
expanse, free of additional elements like 
sun rays or clouds, ensuring the focus 
remains solely on the colorful, stylized 
figure of the man waving. The lighting is 
neutral, casting no shadows or highlights, 
preserving the simplicity of the scene.
Two dogs, one with the appearance of a 
Cavalier King Charles Spaniel with black 
and white fur and the other resembling 
a brown and white Yorkshire Terrier, are 
energetically running side by side on a 
sandy beach, their tails wagging in 
excitement. The backdrop features a 
serene ocean view, clear skies, gentle 
waves, bright sunlight casting soft 
shadows, and distant seagulls soaring in 
the sky, adding a lively, playful 
atmosphere to the scene.
Two dogs running on the beach, 
the left one looks like a fluffy 
golden dog and the right one 
looks like the left dog in the 
image that is black and white
Two dogs, a Yorkshire Terrier with detailed 
brown and white fur that glistens in the 
sunlight, on the left of a black and white 
Cavalier King Charles Spaniel, are 
immersed in a game of chase along a 
scenic beach. The ocean waves, with their 
rhythmic motion, complement the dogs’ 
lively energy. The sky, a masterpiece of 
soft, blended colors, serves as a canvas for 
the seagulls that glide gracefully, casting 
intricate shadows that dance on the sandy 
surface, amplifying the scene’s vibrancy.
Two dogs running on the 
beach, the left one looks likeand the 
right one 
looks like 
the left 
dog in the 
image
A close-up of a sushi roll in 
the making, with a pile of 
rice on a seaweed sheet and 
salmon and cucumber being 
added, next step is rolling 
and cutting the sushi.
image that depicts what will 
happen next based on the 
story in the two given 
frames. Please provide a 
textual description of the 
image before generating. 
The first frame in the story is 
rice on sushi roll, and the 
second frame in the story is 
ingredients on rice
A close-up of a sushi roll in 
the making, with a pile of 
rice on a seaweed sheet and 
salmon and cucumber being 
added, next step is rolling 
and cutting the sushi, with a 
bamboo mat and knife 
nearby, in a kitchen setting.image that depicts what will 
happen next based on the 
story in the two given 
frames. Please provide a 
textual description of the 
image before generating. 
The first frame in the story is, and the 
second 
frame in 
the story 
is
A marble table with a 
Coca-Cola bottle floating 
above it, defying gravity, in a 
modern living room, with 
soft ambient lighting, 
minimalistic decor, and a hint 
of surrealism.
photo with a design that 
composites the two given 
objects into the new photo. 
The placement of the objects 
does not adhere to the laws 
of physics. Please provide a 
textual description of the 
objects and design before 
generating. The first object is 
a marble table, and the 
second object is a coke
In a contemporary 
living room, a 
Coca-Cola bottle is 
suspended in mid-air 
above a marble table, 
with a mystical aura, 
warm lighting, and 
sleek decor, evoking a 
sense of magic and 
defying gravity.
photo with a design that 
composites the two given 
objects into the new photo. 
The placement of the objects 
does not adhere to the laws 
of physics. Please provide a 
textual description of the 
objects and design before 
generating. The first object is, and the 
second 
object is
SD v2.1
DeepFloyd IF
SDXL img2img
DeepFloyd IF img2imgDALL·E 3
DALL·E 3
Fig. 6:The comparisons among initial-round manual prompt, initial-round Idea2Img
prompt, and iterative self-refined Idea2Img prompt, with different image generation
models. Additional qualitative results and discussions are in Appendix A.1.
below it ...”. In contrast, Idea2Img effectively understands the instructional
texts inIDEAand creates images accordingly.
3.Better semantic and visual quality. Finally, the iterative refinement
allowsIdea2Img togenerateimageswithbettersemanticandvisualqualities,
leading to an effective automatic image creation assistant.
4.3 LMM Feedback, Revision, and Selection
We show representative LMM outputs for “feedback reflection,” “revised prompt
generation,” and “draft image selection.” Additional results are in Appendix A.2.
Feedback reflection. Figure 7(a) shows the text feedback generated by GPT-
4V for the user IDEAand the draft image and T2I prompt. Idea2Img can ef-
fectively check if the generated image is correct, and verify if the draft image
corresponds to the visual descriptions in IDEA. This includes the breed of the
dog in (a.1), as well as art styles, objects, visual attributes, etc. In addition
to identifying the discrepancy, Idea2Img also points to the plausible directions
that may improve the T2I prompt in the text feedback. For example, in (a.2),
Idea2Img provides guidance to have generated images better follow the user
intention of “an image for a children’s painting competition,” by “specifically
mentioning that the car should be simple and cartoon-like.”

--- PAGE 13 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 13
(a) Feedback reflection: The right column shows the examples of generated text feedback.
Revised prompt and image
cartoon 
drawing of Mr 
Bean with the 
same cloth as 
in the given 
imageplaying 
with a dog 
looks like 
this one 
on the 
beach
The dog in the generated image is 
not the same breed as  the one in 
the given image. The dog in the 
given image is a Yorkshire Terrier, 
while the dog in the generated 
image is a Boston Terrier . To 
address this issue, the sentence 
prompt should be modified to 
specifically mention the breed of 
the dog as a Yorkshire Terrier.
A humorous scene of 
Mr Bean and a small 
dog playing fetch on a 
sandy beach with blue 
skies in the 
background.
A humorous scene of Mr Bean 
wearing a  yellow tennis outfit  and 
playing with a Yorkshire Terrier  on 
a beach with palm trees in the 
background.Input user IDEA Draft prompt and image to revise Text feedback
(b.1)
The image generated by the AI art 
generation model does not follow 
the user imagined IDEA of the 
scene as there are bananas on the 
plate and orange juice in the glass . 
To address this, the sentence 
prompt can be modified to specify 
that there should be no bananas on 
the plate and no orange juice in the 
glass.a plate that has no bananas on it. there is a 
glass without orange juice next to it
A breakfast scene with 
a plate that has no 
bananas and a glass 
without orange juice, 
with a blue 
background and a 
bright lighting.
A close-up view of an empty plate 
with no other objects  on it, and an 
empty glass  without orange juice 
on a wooden table, with a white 
background.
(b.2)
(b) Revised prompt generation: The right column shows the examples of revised prompts.
(c)Draftimageselection: Therightcolumnshowstheexamplesofthedraftimageselection
index and justification.
Fig. 7:GPT-4V’s outputs in Idea2Img for image feedback, revision, and selection.
Revised prompt generation. Figure 7(b) compares the T2I prompts before
and after thepromptrevision, showcasing how text feedback may help therefine-
ment. For example, in (b.1), the revised T2I prompt specifies “an empty plate
with no other objects” to preclude the T2I model from generating bananas,
which occurred with the previous prompt “no bananas.” In (b.2), the revised
T2I prompt includes a detailed description of “a yellow tennis outfit” and “a
Yorkshire Terrier” to generate the queried clothing and dog.
Draft image selection. Performing draft image selection requires LMMs to
compare multiple similar draft images and pick the one that best matches the
multimodal input IDEA. Figure 7(c) shows the selection results generated by
Idea2Img . GPT-4V is prompted to give justifications and scores for each draft
image, in addition to the final selection. We observe that Idea2Img could com-
prehensively judges different aspects in IDEA, and gives reasonable scores and
selection indexes. E.g., finding the image with both sleep and study area in (c.1),
verifying content and style in (c.2), and other examples in Appendix Figure G.

--- PAGE 14 ---
14 Z. Yang et al.
5 Limitation and Discussion
Tasks beyond image generation. Idea2Img explores the emergent ability of
multimodal self-refinement in LMM-based systems, through the image design
and generation task. Specifically, Idea2Img views the T2I model to use as an un-
knownmultimodalenvironmenttoexplore,anditerativelyrefinesT2Ipromptsto
find its optimal usage. This concept mirrors the intrinsic human approach of iter-
ative problem-solving when faced with unknown environments or challenges. We
leave its extension to other intriguing tasks, e.g., GUI navigation [55], embodied
agents [29], and complicated visual reasoning [38,54], for future exploration.
From a single image generation model to multiple tools. Idea2Img ex-
plores using a single image generation model, such as a text-to-image model [40]
or a text-conditioned image-to-image model [28]. When needed, other specialized
generative models like ControlNet [65], inpainting [3], region-controlled T2I gen-
eration [23,59], customized generation [8,41], and video generation [48,62] can
be seamlessly switched and supported. That is, Idea2Img could broadly boost
different visual generation models of diverse specialties by exploring their opti-
mal text description or instruction prompts. Beyond a single generation model,
Idea2Img can also be used to allocate multiple tools as in multimodal agent stud-
ies [52,58]. In this case, Idea2Img isn’t limited to optimizing the use of individual
tools but also investigates their effective collaboration when used together, such
as generator selection and multi-step visual generation.
Consolidating explored knowledge. We have shown the effectiveness of
LMMiterativeself-refinementinautomaticimagedesignandgeneration. Idea2Img
can also help to consolidate or distill the explored knowledge into T2I model
parameters, such that no inference-time iterative refinement is needed when en-
countering seen generation scenarios. One could collect a dataset using Idea2Img
for a scenario of interest, and fine-tune a T2I model with the explored self-
refinement trajectory. Storing the probed knowledge as sample-agnostic prompt
for each image generation model is another promising direction [15,37,66]. Fi-
nally, with minimal extra computation, we find it helpful to use the explored T2I
prompt history as in-context examples for prompt re-writing and expansion, im-
proving from the zero-shot expansion like the one in ChatGPT-Dalle-3 [1,4].
6 Conclusion
We have presented Idea2Img , a multimodal iterative self-refinement framework
that leverages GPT-4V(ision) for image design and generation. Idea2Img ex-
plores the emergent capabilities of iterative self-refinement in LMM-based agent
systems, showcasing its effectiveness in improving, assessing, and verifying the
generatedmultimodalcontent.Theuserpreferencestudydemonstrates Idea2Img ’s
capability in assisting humans to find the optimal usage of generation models
for automatic image design and generation.

--- PAGE 15 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 15
Acknowledgment
WearedeeplygratefultoOpenAIforprovidingaccesstotheirexceptionaltool[1,
31–33]. We also extend heartfelt thanks to our Microsoft colleagues for their
insights, with special acknowledgment to Faisal Ahmed, Ehsan Azarnasab, and
Lin Liang for their constructive feedback.
In this supplementary material, we begin with showing additional qualitative
results in Section A.1, in supporting Idea2Img ’s effectiveness on different image
generation models, including Dalle-3 [4,30], SDXL [36], SDXL-img2img [28,36],
DeepFloyd IF [20], among others. In Section A.2, we show GPT-4V’s outputs to
probe how Idea2Img helps image creation during the iterative self-refinement,
and the possibility of replacing GPT-4V with other LMMs. Section B introduce
remaining implementation details.
A Qualitative Results
A.1 Qualitative Comparisons
Figures A-D show additional qualitative results of the comparison in Table 1.
Figure A presents examples of Idea2Img explores the use of SDXL, a represen-
tative T2I model. Figure B examines SDXL-img2img, a simple text-conditioned
image-to-image model that adds noise to the input image and then performs
text-conditioned denoising [28]. Figures C, D contain the results of Idea2Img
working with Dalle-3 and other image generation models.
SDXL.Idea2Img couldhelpusersgenerateimagesthatbetterfollow IDEA,such
as the one with correct object counts and rendered scene texts in Figures A(a,b).
Idea2Img enables the visual content design that can create images from a text
instruction of its desired usage, in contrast to the detailed image description re-
quired in the conventional T2I generation. For example in Figure A(c), Idea2Img
designs a logo based on the user IDEAof “having a logo for a 2024 conference in
Seattle.” Idea2Img canalsounderstanduser IDEAtosearchforimageswithhigh
aesthetic scores and great visual details, or its opposite direction with “minimal
face details” in (d). The LMM allows Idea2Img to extract arbitrary information
from the input image for visual generation. This could be any specific object in
the image, such as “the dog on the left” or “the dog pointed to via a red circle”
in (e). Figure A(f) shows an example of extracting the painting style, which
requires art knowledge for humans to describe accurately. The image input can
even be an in-context example that defines the desired image transformation,
such as the visual style transfer shown in (g). The ability to extract arbitrary
information from the input image can be seamlessly extended to compose mul-
tiple visual and text conditions, such as composing the camera angle and image
style in (h) and the two entities in (I).
SDXL-img2img. Idea2Img is also effective in finding T2I prompts for the text-
conditioned image-to-image model SDXL-img2img, as shown in Figure B. Fig-
ures B(c) and (d) illustrate generating images that follow and differ from the

--- PAGE 16 ---
16 Z. Yang et al.
(i)(h)(g)(f)(e)(d)(c)(b)
A Cavalier King Charles 
Spaniel running on a tiled 
floor, happy mood, bright 
lightingphoto of a dog looks like the circled one in 
the image running on the floor
photo of a dog looks like the 
circled one in the image 
running on the floor that is a 
black and white dog
A small Cavalier King Charles 
Spaniel with black and white 
fur, running on a tiled floor, 
tongue out, happy mood, 
bright lighting
A group of 5 friends sitting 
around a wooden table, 
drinking beer and eating 
buffalo wings in a casual 
setting.5 people sitting around a table drinking 
beer and eating buffalo wings
5 people sitting around a 
table drinking beer and 
eating buffalo wings
A group of 5 friends sitting 
around a wooden table, with 
one person at the head of 
the table and two people on 
each side, drinking beer and 
eating buffalo wings in a 
casual setting, with a 
window in the background 
and a warm, inviting 
atmosphere.
A painting of Mt Rainier 
mountain with a tree and 
lake in the foreground, in a 
colorful and abstract style 
similar to a Picasso painting.Painting of Mt rainier mountain with tree 
and lake in the foreground, with style 
similar to this one in the image
Painting of Mt rainier 
mountain with tree and lake 
in the foreground, with style 
similar to this one in the 
image that has colorful 
blocks
A painting of Mt Rainier 
mountain with a tree and 
lake in the foreground, with 
bold lines and bright colors, 
with a cubist and surrealistic 
style, with a focus on 
geometric shapes and 
patterns.
A portrait of Bill Gates with 
minimalistic style and vague 
facial features, in a 
monochrome color scheme.A vague portrait of Bill Gates with minimal 
visual and face details
A vague portrait of Bill Gates 
with minimal visual and face 
details
A portrait of Bill Gates with 
an extremely abstract and 
vague style, with almost no 
emphasis on the facial 
features, in a monochrome 
color scheme, with a 
completely abstract 
background.Input user IDEA Initial-round manual promptInitial-round Idea2Img  
promptIterative self-refined 
Idea2Img  prompt
A painting of 
a tennis game 
from camera 
angle, with the 
image 
style 
similar to 
this one in 
the image
A painting of a tennis game 
from a top-down camera 
angle, with the image style 
similar to Claude Monet's 
impressionist paintings, with 
a bright and sunny 
atmosphere.
A painting of a tennis game 
from camera angle, with the 
image style similar to this 
one in the image that is 
impressionist
A painting of a tennis game 
from a top-down camera 
angle, with the image style 
similar to Claude Monet's 
impressionist paintings, with 
a bright and sunny 
atmosphere, with a blue sky 
and green trees in the 
background, with the players 
wearing white clothes, with 
a large crowd in the stands.
A logo design for a 2024 
conference held in Seattle, 
featuring the Seattle skyline 
and the conference title in a 
modern font, with a blue and 
green color scheme.a logo for a 2024 conference held in 
Seattle. Please provide a textual description 
of the design before generating
a logo for a 2024 conference 
held in Seattle.
A logo design for a 2024 
conference held in Seattle, 
with a modern and 
minimalist design, featuring 
the Seattle skyline and the 
conference title in a 
geometric sans serif font, 
with a blue and green color 
scheme.
A scene of a man in a suit 
waving his hand, with the 
same style as the geometric 
dog image on the left.
Find the the image style 
pattern in the left two dog 
images and apply it on the 
top right people waving hand 
image.
A person in a business suit 
waving with his right hand, 
depicted in a polygonal art 
style reminiscent of the dog 
image, with a mosaic of 
colorful geometric shapes, 
against a backdrop of a blue 
sky.
with a dog 
looks like 
this one in 
the image
Bill Gates in a formal suit on 
a bustling city street, raising 
his hand in a friendly wave 
like a charming businessman, 
with a cute pug dog with a 
wrinkled face and large eyes 
by his side, under natural 
daylight, with a sense of 
approachability.
Photo of Bill Gates with the 
same hand gesture as in the 
given image that is waving 
hand, with a dog looks like 
this one in the image that is 
a pug dog
Bill Gates wearing a suit and 
tie, standing on a busy street 
with tall buildings, waving 
with his right hand raised 
and palm facing forward, 
with a small pug dog with an 
adorably wrinkled face and 
big round eyes next to him, 
in daylight, exuding 
friendliness and warmth.
A whole cake on a wooden 
table with the words Azure 
Research written on it in 
blue icing, with a white 
tablecloth and a vase of 
flowers in the background.a whole cake on the table with words Azure 
Research written on the cake
a whole cake on the table 
with words Azure Research 
written on the cake
A top-down perspective of a 
cake on a table, with the 
words "Azure Research" 
meticulously written in blue 
icing on the top, surrounded 
by a modern kitchen with 
sunlight filtering through.
Bill Gates in a suit, standing 
in front of a building, with a 
pug dog sitting on the 
ground next to his legs, 
waving his hand in a friendly 
manner
Bill Gates in a suit, standing 
in front of a building, with a 
pug dog sitting next to him, 
waving his hand in a friendly 
manner
A scene of a man in a suit 
with his right hand raised in 
a friendly wave with his palm 
facing forward, with the 
same style as the geometric 
dog image on the left, with a 
blue sky background, with a 
slight smile on his face, with 
a modern and abstract style.(a)(a)
(a)
(b)
(c)
(d)
(e)
(f)
(g)
Find the the image style pattern in the left 
two dog images and apply it on the top 
right people waving hand image. Provide a 
textual description that keeps the content 
in the people waving hand image, with the 
correct style pattern.
(h)
(i)
Photo of Bill 
Gates with 
the same 
hand gesture 
as in the given 
image
Fig. A: The comparisons among the initial-round manual prompts, initial-round
Idea2Img prompts, and the iterative self-refined Idea2Img prompts, with the SDXL
v1.0 [36] used as the T2I model.

--- PAGE 17 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 17
(i)(h)(g)(f)(e)(d)(c)(b)(a)
A surreal scene of a 
Coca-Cola bottle and a 
marble table merging into 
one, in an abstract space 
with distorted dimensions, 
bright colors, and dynamic 
lighting.
photo with a design that 
composites the two given 
objects into the new photo. 
The placement of the objects 
does not adhere to the laws 
of physics. Please provide a 
textual description of the 
objects and design before 
generating. The first object is 
a marble table, and the 
second object is a coke
An imaginative scene where 
a Coca-Cola bottle is floating 
and twisting above a marble 
table, defying gravity, with 
the bottle and table merging 
into each other in places, 
surrounded by a 
kaleidoscope of colors and 
ethereal lighting that gives a 
dreamlike atmosphere.Input user IDEA Initial-round manual promptInitial-round Idea2Img  
promptIterative self-refined 
Idea2Img  prompt
Cartoon drawing with a design 
that naturally blends the two 
given images as a new 
minimalist drawing. Please 
provide a textual description 
of the design before 
generating. The first image is
, and 
the 
second 
image 
is
A cartoon drawing of a llama 
wearing a suit and waving, 
blending the minimalist style 
of the first image with the 
professional attire of the 
second image.
Cartoon drawing with a 
design that naturally blends 
the two given images as a 
new minimalist drawing. 
Please provide a textual 
description of the design 
before generating. The first 
image is a llama logo, and 
the second image is a person 
in suit
A whimsical cartoon of a 
llama with a human body 
dressed in a stylish suit, 
waving its hand, combining 
the charm of a cute llama 
drawing and the elegance of 
a man in a suit, in a 
minimalist style, with a 
muted color palette.
photo with a design that 
composites the two given 
objects into the new photo. 
The placement of the objects 
does not adhere to the laws 
of physics. Please provide a 
textual description of the 
objects and design before 
generating. The first object is, and 
the 
second 
object 
is
A close-up of a sushi roll in 
the making, with a pile of 
rice on a seaweed sheet and 
salmon and cucumber being 
added, next step is rolling 
and cutting the sushi.
image that depicts what will 
happen next based on the 
story in the two given 
frames. Please provide a 
textual description of the 
image before generating. 
The first frame in the story is 
rice on sushi roll, and the 
second frame in the story is 
ingredients on rice
A close-up of a sushi roll in 
the making, with a pile of 
rice on a seaweed sheet and 
salmon and cucumber being 
added, next step is rolling 
and cutting the sushi, with a 
bamboo mat and knife 
nearby, in a kitchen setting.image that depicts what will 
happen next based on the 
story in the two given frames. 
Please provide a textual 
description of the image 
before generating. The first 
frame in the story is, and 
the 
second 
frame 
in the 
story is
A gray cat and an orange cat 
running on the beach, with 
the gray cat on the right and 
the orange cat on the left.
Two cats running on the 
beach, the right one looks 
like a gray cat and the left 
one looks like a orange cat
A gray cat with its head 
down and eyes looking 
forward and an orange cat 
with its eyes closed, both 
running on a beach with the 
gray cat on the right and the 
orange cat on the left, with 
the ocean in the background.Two cats running on the 
beach, the right one looks likeand the 
left 
one 
looks 
like
portrait of Bill Gates with style different from this 
one in the image
A portrait of Bill Gates in a 
cartoon style, with bright 
colors and a cheerful mood.
portrait of Bill Gates with 
style different from this one 
in the image that is 
impressionist
A portrait of Bill Gates in a 
cartoon style, with bright 
colors and a cheerful mood, 
with a light-colored 
background to make the 
portrait stand out.a watercolor painting of the same house with the 
same number of windows and the frontal view as 
the one in the sketch
A watercolor rendition of a 
house with a frontal view 
and six windows, with a 
focus on the architectural 
details
a watercolor painting of the 
same house with the same 
number of windows and the 
frontal view as the one in the 
sketch that is a two-level 
house with four large 
windows and three small 
windows in the center
A watercolor illustration of a 
house with a porch and six 
windows, with an emphasis 
on the symmetry and style of 
the house in the sketch.A watercolor cartoon logo based on the design in 
the given image
A logo design of a llama with 
a red scarf and beanie, in a 
watercolor cartoon style, 
with a soft and pastel color 
palette.
A watercolor cartoon logo 
based on the design in the 
given image that is a llama
A logo design of a llama 
standing on all fours, with a 
red scarf and beanie, in a 
watercolor cartoon style, 
with a soft and pastel color 
palette, similar to the design 
in the given image.photo of a dog looks like the one in the given 
image running on the beach
A small dog with a fluffy coat 
running on the beach, with 
the ocean in the background.
photo of a dog looks like the 
one in the given image 
running on the beach that is 
a fluffy golden dog
A playful Yorkshire Terrier 
with a collar running on the 
beach, with the sun setting 
over the ocean in the 
background.
a dog looks like this one in 
the image running on the 
grass, but in blue color, with 
the 
image 
style 
similar 
to this 
one in 
the 
image
A pug dog with a blue coat 
running on a field of green 
grass, with a style 
reminiscent of cubism.
a dog looks like this one in 
the image running on the 
grass, but in blue color . The 
dog is pug dog, with the 
image style similar to this 
one in the image that 
contains blocks
A pug dog with a blue coat 
running on a field of green 
grass, with its legs stretched 
out and its tail wagging as it 
runs, in a style reminiscent 
of cubism.
A cartoon drawing of a llama 
wearing a gray suit with a 
black tie, with his right hand 
raised in a friendly wave with 
his palm facing forward, 
blending the minimalist style 
of the first image with the 
professional attire of the 
second image.
A painting of a tennis game 
from a top-down camera 
angle, with the image style 
similar to Claude Monet's 
impressionist paintings, with 
a bright and sunny 
atmosphere, with a blue sky 
and green trees in the 
background, with the players 
wearing white clothes, with 
a large crowd in the stands.
photo with a design that 
naturally blends the two 
given objects into the new 
photo. The placement of the 
objects perfectly adhere to 
the laws of physics and is 
common in real life. The first 
object is a marble table, and 
the second object is a coke
A group of 5 friends sitting 
around a wooden table, with 
one person at the head of 
the table and two people on 
each side, drinking beer and 
eating buffalo wings in a 
casual setting, with a 
window in background and a 
warm, inviting atmosphere.photo with a design that 
naturally blends the two given 
objects into the new photo. 
The placement of the objects 
perfectly adhere to the laws 
of physics and is common in 
real life. Please provide a 
textual description of the 
objects and design before 
generating. The first object is, and 
the 
second 
object 
is
Fig. B: The comparisons among the initial-round manual prompts, initial-round
Idea2Img prompts, and the iterative self-refined Idea2Img prompts, with the SDXL-
img2img [28,36] used as the image generation model. Instead of random noise, the
image generation starts from the input image with added noise [28], showing the effec-
tiveness of Idea2Img on text-conditioned image-to-image pipelines.

--- PAGE 18 ---
18 Z. Yang et al.
(i)(h)(f)(e)(d)(c)(b)
On a peaceful beach, a silhouette 
of a person is captured in the 
midst of performing a tree pose 
yoga, with the backdrop of a 
setting sun and a large tree. The 
scene is reimagined with a 
geometric, polygonal art style, 
echoing the aesthetic of a 
stylized, faceted dog, where each 
shape captures and reflects the 
light differently, creating a mosaic 
of sunset hues.Find the the image style pattern in the 
left two dog images and apply it on the 
top right people in tree pose image. 
Provide a textual description that keeps 
the content in the people in tree pose 
image, with the correct style pattern.
Find the the image style pattern 
in the left two dog images and 
apply it on the top right people in 
tree pose image
Amidst the gentle waves lapping at the 
shore and the sun bidding adieu, a person 
is encapsulated in the serene act of 
performing the tree pose yoga. A tree, 
grand and robust, shares the spotlight, its 
leaves whispering tales of nature’s 
splendor. The scene is reimagined, with 
every element, from the yogi to the 
distant horizon, adorned in larger, more 
distinct geometric shapes, echoing the 
style of the polygonal dog images. Each 
shape, bold and less complex, is a canvas 
capturing the sunset’s myriad hues, 
crafting a cohesive, visual narrative.
A dynamic logo showcasing the 
Space Needle piercing through 
the number "2024", symbolizing 
innovation and progress, set 
against a starry night sky over 
Seattle, with the city lights 
shimmering, and the conference 
details illuminated by a moonlit 
glow.a logo for a 2024 conference held in 
Seattle. Please provide a textual 
description of the design before 
generating
a logo for a 2024 conference held 
in Seattle. Please provide a 
textual description of the design 
before generating
An elegant logo for the 2024 
conference, where the Space 
Needle forms part of the "2024", 
adorned with subtle imagery of a 
speaker's podium and audience, 
set against a simplified Seattle 
skyline, with a clean, 
monochromatic palette, precise 
detailing, and a soft lighting to 
accentuate the conference theme 
and professionalism.
The image of a man waving is 
stylized with a low-poly design, 
where the scene is broken down 
into geometric shapes filled with 
bold and vibrant colors, creating a 
visually striking and 
contemporary aesthetic, under 
the bright sky.Find the the image style pattern in the 
left two dog images and apply it on the 
top right people waving hand image. 
Provide a textual description that keeps 
the content in the people waving hand 
image, with the correct style pattern.
Find the the image style pattern 
in the left two dog images and 
apply it on the top right people 
waving hand image
A man in a formal suit is captured 
mid-motion, his hand raised in a wave, 
each finger distinctly visible. The entire 
scene is reimagined in a low-poly art style, 
where each facet of the man and his attire 
is defined by geometric shapes filled with 
a palette of bold, contrasting colors. The 
background remains a solid, untextured 
expanse, free of additional elements like 
sun rays or clouds, ensuring the focus 
remains solely on the colorful, stylized 
figure of the man waving. The lighting is 
neutral, casting no shadows or highlights, 
preserving the simplicity of the scene.
A minimalist black and white logo 
of a llama, inspired by the clean 
lines and simplicity of a 
stethoscope that forms a paw 
print, flat design, monochrome.A logo of llama with the exact same style 
as in the given image
A logo of llama with the exact 
same style as in the given image 
that has a minimalist design
A black and white logo where a 
stethoscope seamlessly forms a 
llama, the tubing outlines the body 
and legs, and the earpieces and 
diaphragm shape the head, akin to 
the minimalist style of a paw print, 
no facial features, embodying pure 
simplicity, elegance, and clean 
lines.Input user IDEA Initial-round manual promptInitial-round Idea2Img  
promptIterative self-refined 
Idea2Img  prompt
A hand drawing of 
a person with a 
clear background. 
Hand drawing 
shows the sketch 
of the scene and 
looks like the 
given image. The 
person has 
a pose of
A sketch of a person, their hand 
raised in a greeting, is detailed 
with intricate lines and shading, 
showcasing the folds of their suit 
and their poised stance, set 
against a clear, unblemished 
background, in grayscale, the 
simplicity of the backdrop 
amplifying the complexity of the 
hand-drawn subject, with a focus 
on realism infused with artistic 
flair.
A hand drawing of a person with 
a clear background. Hand drawing 
shows the sketch of the scene 
and looks like the given image . 
The person has a pose of waving 
hands
In monochrome, a person is depicted with 
their hand raised, palm out, in a waving 
gesture, encapsulated by the spontaneous 
and rough lines of a hand drawing. The 
background is immaculate and void of 
detail, spotlighting the figure. The artwork 
exudes the energy of a quick sketch, 
where the focus is on capturing the 
gesture and posture with immediacy, 
echoing the unrestrained strokes found in 
an artist’s sketchbook.
A portrait of a corgi dog, not 
utilizing the thick, dynamic 
brushstrokes and intense color 
contrasts seen in a scene of a 
golden wheat field beneath a 
dramatic, dark sky, soft lighting, 
hyper-realistic style, serene 
setting.painting of a corgi dog with style different 
from this one in the image
painting of a corgi dog with style 
different from this one in the 
image that is oil painting
A corgi dog depicted in a pop art 
style, featuring bold, flat colors and 
comic book-inspired aesthetics, no 
wheat field or dramatic sky, set 
against a backdrop of a bustling 
cityscape with skyscrapers, neon 
lights, and street art, illuminated by 
the glow of streetlights, 
emphasizing an urban, 
contemporary atmosphere.
Two dogs, one with the appearance of a 
Cavalier King Charles Spaniel with black 
and white fur and the other resembling 
a brown and white Yorkshire Terrier, are 
energetically running side by side on a 
sandy beach, their tails wagging in 
excitement. The backdrop features a 
serene ocean view, clear skies, gentle 
waves, bright sunlight casting soft 
shadows, and distant seagulls soaring in 
the sky, adding a lively, playful 
atmosphere to the scene.
Two dogs running on the beach, 
the left one looks like a fluffy 
golden dog and the right one 
looks like the left dog in the 
image that is black and white
Two dogs, a Yorkshire Terrier with detailed 
brown and white fur that glistens in the 
sunlight, on the left of a black and white 
Cavalier King Charles Spaniel, are 
immersed in a game of chase along a 
scenic beach. The ocean waves, with their 
rhythmic motion, complement the dogs’ 
lively energy. The sky, a masterpiece of 
soft, blended colors, serves as a canvas for 
the seagulls that glide gracefully, casting 
intricate shadows that dance on the sandy 
surface, amplifying the scene’s vibrancy.
, with the 
image 
style 
similar to 
this one in 
the image
An artwork showcasing a tennis 
game viewed from a high angle, 
players are frozen in intense play, 
surrounded by a packed 
audience, the painting style is 
akin to impressionism with 
blurred lines and a play of light 
and shadow, evoking a sense of 
movement and energy, in the 
midst of a clear day.
A painting of a tennis game from 
camera angle, with the image 
style similar to this one in the 
image that is impressionist
A vivid impressionist painting captures a 
dynamic tennis match from an elevated 
perspective, where athletes are engaged 
in a fierce competition on a distinct blue 
court. The stadium is brimming with an 
enthusiastic crowd, their faces a blend of 
colors reflecting the excitement of the 
moment. The artwork is characterized by 
soft, blurred lines and a harmonious play 
of light and shadow, reminiscent of a clear, 
sunny day, enhancing the visual appeal 
and bringing the scene to life.
A sleek, modern car parked 
against a vibrant cityscape, 
illuminated by the golden hour 
sunlight, glossy paint reflecting 
the surrounding lights, clean and 
polished look.an image of a car that can be used for 
commercial advertising
an image of a car that can be 
used for commercial advertising
The image captures a 
state-of-the-art car positioned 
elegantly against a modern city 
backdrop. The lighting is balanced 
and clear, ensuring the car's sleek 
design and features are 
prominently displayed. The 
surrounding environment, though 
vibrant, doesn’t overshadow the 
car, making it the undeniable 
centerpiece, ideal for commercial 
advertising.
(a)
A painting of 
a tennis game 
from camera 
angleThe lively scene captures a golden and grey 
Yorkshire Terrier mid-leap, its joyful expression 
accentuated by the open mouth and bright eyes. 
The backdrop is a busy street, pedestrians in 
mid-stride, and colorful storefronts offering a visual 
feast. The overcast lighting lends a soft glow, 
illuminating the dog's fur and creating a dynamic 
interplay of light and shadow on the street.
A portrait of a corgi dog, rendered 
in a style that mirrors the precision 
and clarity of a high-resolution 
photograph, showcasing intricate 
details from the texture of its fur to 
the reflections in its eyes, set in a 
calm outdoor setting, vibrant yet 
natural colors, under the gentle 
glow of the afternoon sun.Five friends, each clutching a 
distinct beer bottle, are immersed in 
a spirited discussion around a 
polished wooden table. A generous 
serving of buffalo wings, glistening 
with sauce, commands the center. 
The room, adorned with vintage 
decor, basks in the golden hue of 
hanging lights, casting intricate 
shadows and highlighting the bonds 
of friendship.
A simplistic car painted in bold, 
unshaded primary colors is parked 
on a uniform green landscape, no 
gradients, under a plain blue sky 
with basic cloud shapes, next to a 
playground with elementary 
structures painted in solid colors, 
ensuring an uncomplicated, 
child-friendly painting experience.
(g)
Two dogs 
running on 
the beach, 
the left one 
looks likeand the 
right one 
looks like 
the left 
dog in the 
image
Fig. C: The comparisons among the initial-round manual prompts, initial-round
Idea2Img prompts, and the iterative self-refined Idea2Img prompts, with the Dalle-
3 [30] used as the T2I model.

--- PAGE 19 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 19
6 cakes placed in a box(a)
A marble table with a 
Coca-Cola bottle floating 
above it, defying gravity, in a 
modern living room, with 
soft ambient lighting, 
minimalistic decor, and a hint 
of surrealism.
photo with a design that 
composites the two given 
objects into the new photo. 
The placement of the objects 
does not adhere to the laws 
of physics. Please provide a 
textual description of the 
objects and design before 
generating. The first object is 
a marble table, and the 
second object is a coke
In a contemporary 
living room, a 
Coca-Cola bottle is 
suspended in mid-air 
above a marble table, 
with a mystical aura, 
warm lighting, and 
sleek decor, evoking a 
sense of magic and 
defying gravity.SD v1.5
SD v2.1
DeepFloyd IF
DeepFloyd IF img2img
A happy dog with pink fur 
running on a street with 
buildings in the background, 
daytime, sunny.photo of the circled dog but with 
background changed to a street
photo of the circled dog but 
with background changed to 
a street that is a pink fluffy 
dog
A Yorkshire Terrier with pink 
fur running on a bustling 
street with skyscrapers in the 
background, daytime, bright, 
traffic.
A cardboard box with 6 
homemade cakes, each with 
a unique design and flavor, 
ready to be delivered.
6 cakes placed in a box
A brown cardboard box with 
6 homemade cakes, each 
with a different flavor and 
design, arranged in a 
symmetrical pattern.
A casual portrait of Elon 
Musk and Mark Zuckerberg, 
both wearing grey sweaters 
and black shirts, with a white 
background.generating an image with the same cloth as 
in the given image, but change the left 
persons to Elon Musk and the right person 
to Mark Zuckerberg
generating an image with the 
same cloth as in the given 
image, but change the left 
persons to Elon Musk and 
the right person to Mark 
Zuckerberg
Elon Musk and Mark 
Zuckerberg standing in a 
relaxed pose, with their 
shoulders touching, in a grey 
background, with Elon Musk 
wearing a grey sweater and 
Mark Zuckerberg wearing a 
black shirt.
A kitchen scene with an 
empty plate and a glass 
without orange juice on a 
wooden table, with a white 
background.a plate that has no bananas on it. there is a 
glass without orange juice next to it
a plate that has no bananas 
on it. there is a glass without 
orange juice next to it
A close-up view of a wooden 
table with an empty glass 
and a white plate without 
bananas, with a white 
background.
A contemporary logo for a 
2023 conference in Paris, 
showcasing a stylized Eiffel 
Tower, elegant fonts, and a 
color palette inspired by the 
French flag, with a touch of 
sophistication.a logo for a 2023 conference held in Paris. 
Please provide a textual description of the 
design before generating
a logo for a 2023 conference 
held in Paris.
A sleek and modern logo for 
a 2023 conference in Paris, 
incorporating a stylized Eiffel 
Tower, the year '2023' in a 
classy font, and a tricolor 
background inspired by the 
French flag. The design 
includes the word 'Paris' at 
the bottom in a refined font, 
symbolizing sophistication 
and culture.
A logo of llama with the exact same style 
as in the given image
A monochromatic logo that 
combines a llama's face with 
a stethoscope, similar to the 
given image, where the 
stethoscope forms the face 
and the footprints are inside, 
in a sleek and minimalist 
style, with bold black lines.
A logo of llama with the 
exact same style as in the 
given image that has a 
minimalist design
A logo in which a 
stethoscope is artistically 
shaped with its tubing 
outlining a llama's face and 
its ear tips as the llama's 
ears, with paw prints inside 
the face, akin to the given 
image, in a simple, modern 
design with bold black 
contours.
A playful dog with a unique 
blue coat and a bright yellow 
collar, enjoying a run on the 
beach with the waves 
crashing behind it.photo of a dog looks like the one in the 
given image running on the beach, but 
change the dog color to blue and the 
collar color to yellow
photo of a dog looks like the 
one in the given image 
running on the beach, but 
change the dog color to blue 
and the collar color to yellow 
that is a pug dog
A pug-like dog with a unique 
blue fur, adorned with a 
plain yellow collar on its 
neck, racing across the beach 
with sand flying under its 
paws, and a tranquil sea with 
gentle waves as the 
backdrop.
photo with a design 
that composites the 
two given objects into 
the new photo. The 
placement of the 
objects does not 
adhere to the laws of 
physics. Please provide 
a textual description of 
the objects and design 
before generating. The 
first object is, and 
the 
second 
object 
isInput user IDEA Initial-round manual promptInitial-round Idea2Img  
promptIterative self-refined 
Idea2Img  prompt
(b)
(c)
(d)
(e)
(f)
(g)
(h)
A hand holding an iPhone 12 
to take a photo, with a 
blurred background and 
natural lighting.an image of a hand holding an iphone 12 to 
take a photo
an image of a hand holding 
an iphone 12 to take a photo
A hand holding an iPhone 12 
with the camera app open 
and the shutter button 
visible, taking a photo with a 
blurred background and 
natural lighting, with a focus 
on the hand and phone.
A gray cat and an orange cat 
running on the beach, with 
the gray cat on the right and 
the orange cat on the left.
photo with a design that 
composites the two given 
objects into the new photo. 
The placement of the objects 
does not adhere to the laws 
of physics. Please provide a 
textual description of the 
objects and design before 
generating. The first object is 
a marble table, and the 
second object is a coke
A gray cat with its head 
down and eyes looking 
forward and an orange cat 
with its eyes closed, both 
running on a beach with the 
gray cat on the right and the 
orange cat on the left, with 
the ocean in the background.
Fig. D: The comparisons among the initial-round manual prompts, initial-round
Idea2Img prompts, and the iterative self-refined Idea2Img prompts, with other image
generationmodels,includingSDv1.5,SDv2.1[40],DeepFloydIF,andIF-img2img[20].
reference image style of “watercolor and impressionist,” respectively. Idea2Img
can design visual contents with the inspiration of input images, e.g., a cartoon
drawing that blends the llama and the person in suits in (f), and composing the

--- PAGE 20 ---
20 Z. Yang et al.
coke with the table in an imaginative way in (g). (h) illustrates a novel scenario
of generating an image to represent the anticipated action of rolling sushi.
Dalle-3 and other generation models. Idea2Img demonstrates its effective-
ness across different image generation models. Figure C shows the results gen-
erated by Idea2Img with Dalle-3. We access Dalle-3 via Bing Image Creator3,
which excludes the ChatGPT prompt rewrite. Idea2Img could better release
Dalle-3’s strong prompt-following capability and show impressive results, espe-
cially for challenging queries. This includes polishing the logo design in Fig-
ure C(a), drafting car advertisements in (b), creating unique image styles in (c),
and enhancing the design with reference images in (d). When confronted with
more challenging tasks, Idea2Img with Dalle-3 excels. For the visual in-context
generation problem in (e) and (f), Idea2Img finds the pattern in the input grid
image and explores T2I prompts for the desired image design. The framework
also proves effectiveness when handling multiple reference images, such as the
two dogs in (g), the hand drawing of a person’s pose in (h), and the tennis game
with a queried style in (i).
Furthermore, Figure D shows the Idea2Img results on other T2I models,
including SD v1.5, v2.1, DeepFloyd IF, and IF-img2img. Despite the variance in
the base T2I models’ capacity, Idea2Img consistently helps design and generate
better images.
A.2 LMM Feedback, Revision, and Selection
One may wonder how GPT-4V behaves and performs in each role throughout
Idea2Img ’s iterative self-refinement pipeline, i.e., “feedback reflection,” “revised
prompt generation,” and “draft image selection.” We show corresponding quali-
tative results as follows.
Feedback reflection. Figure E shows text feedback generated by GPT-4V for
the user IDEA, draft image, and T2I prompt. Idea2Img can effectively check if
the generated image is correct, such as the number of oranges in (a) and the
misspelled scene text "ALURE RESEACHE" in (b). In addition to the text
descriptions in IDEA,Idea2Img can verify if the draft image corresponds to the
visual descriptions in IDEA. This includes the color and breed of the dog in
(e), the exact art style in (f), and the same cloth and pose in (g). Furthermore,
Idea2Img can understand and verify the interleaved image-text pairs in IDEA,
as shown in Figures E(h,i).
In addition to identifying the discrepancy, Idea2Img can also point to the
plausibledirectionsforimprovingtheT2Ipromptinthetextfeedback.Forexam-
ple, in Figure E(c), GPT-4V mentions that “the person is not in yoga mountain
pose, but the T2I prompt has already mentioned mountain pose,” “the AI model
might not understand what mountain pose is, and prompt should be modified to
specifically mention what mountain pose is.” Similarly, in Figure E(d), Idea2Img
provides guidance to have generated images better follow the user intention of
3https://www.bing.com/create

--- PAGE 21 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 21
Fig. E:Examples of the generated text feedback. The left column shows the multi-
modal input user IDEA, and the center column shows the draft image to process as
well as its corresponding text prompts. The right column shows the text feedback gen-
erated by GPT-4V. The dark blue color highlights the identified discrepancies.

--- PAGE 22 ---
22 Z. Yang et al.
(i)(h)(g)(f)(e)(d)(c)(b)(a)
The person in the image is not practicing yoga dolphin pose, 
but in a different yoga pose. Because the prompt has already 
mention dolphin pose, the AI art model might not 
understand what is dolphin pose . To address this, the 
sentence prompt should be modified to specifically mention 
what is a dolphin pose: posture where one balances on the 
forearms with the legs lifted, forming an inverted V shape 
with the body .a person practicing yoga dolphin pose at 
beach
A person practicing yoga 
dolphin pose at a beach with 
clear blue water and white 
sand, during sunrise.
A person on a sandy beach 
practicing yoga in the dolphin 
pose, which involves being on 
both forearms and toes with 
hips raised towards the 
ceiling and facing the ground , 
as the waves gently crash, the 
sun sets in the background 
casting a warm glow, and a 
serene atmosphere surrounds 
the scene.
The dog in the generated image is not in the same color as the 
one in the given image. The dog in the given image is a black 
and white  Cavalier King Charles Spaniel, while the dog in the 
generated image is a brown and white  Cavalier King Charles 
Spaniel. To address this issue, the sentence prompt should be 
modified to specifically mention the breed of the dog as a  
black and white Cavalier King Charles Spaniel .photo of a dog looks like the left one in the 
given image running on the floor
A Cavalier King Charles 
Spaniel running on a tiled 
floor, with a happy mood, in 
a modern kitchen.
A black and white Cavalier 
King Charles Spaniel  running 
on a wooden floor, with a 
playful mood, in a cozy 
kitchen.Revised prompt and image
Cartoon 
drawing of Mr 
Bean with the 
same cloth as 
in the given 
imageplaying 
with a dog 
looks like 
this one 
on the 
beach
The dog in the generated image is not the same breed as  the 
one in the given image. The dog in the given image is a 
Yorkshire Terrier, while the dog in the generated image is a 
Boston Terrier . To address this issue, the sentence prompt 
should be modified to specifically mention the breed of the 
dog as a Yorkshire Terrier.
A humorous scene of Mr 
Bean and a small dog playing 
fetch on a sandy beach with 
blue skies in the background.
A humorous scene of Mr 
Bean wearing a  yellow 
tennis outfit  and playing 
with a Yorkshire Terrier  on a 
beach with palm trees in the 
background.
The image generated by the AI art generation model does not 
follow the user imagined IDEA of the scene as the  fingers are 
not ready to take a screenshot . To address this, the sentence 
prompt can be modified to specify that the  fingers should be 
pressing the side button and the volume up button at the 
same time .an image of a hand holding an iphone 12. 
The image is used for illustrating how to 
take a screen shot on iphone
A detailed image of an 
iPhone 12 being held in a 
hand, with the screen on and 
the fingers ready to take a 
screenshot.
A detailed image of a hand 
holding an iPhone 12, with 
the fingers ready to take a 
screenshot by pressing the 
side button and the volume 
up button at the same time , 
with a clear view of the 
screen.
The image generated by the AI art generation model does not 
follow the user imagined IDEA of the scene as  there is no 
study area in the image . To address this, the sentence prompt 
can be modified to specify that  there should be a study area 
in the room , such as a desk with a lamp and a bookshelf.A hand drawing of a room where people 
can sleep and study. Hand drawing is a style 
that looks like the given image.
A room with a cozy 
atmosphere, hand-drawn in 
a style that resembles a pen 
and ink sketch.
A room with a comfortable 
bed and a study area with a 
desk and a bookshelf , 
hand-drawn in a style that 
looks like a pen and ink 
sketch.
Two cats 
running on 
the beach, 
the right one 
looks likeand the 
left one 
looks like
The cats in the generated image are both Russian Blue cats , 
while the user imagined IDEA of the scene specifies that one 
of the cats should be a domestic shorthair . To address this 
issue, the sentence prompt should be modified to specifically 
mention that the domestic shorthair cat is orange in color .
A playful scene of a Russian 
Blue cat and a domestic 
shorthair cat chasing each 
other on the beach, the sand 
is white and the sky is a deep 
blue, the sun is shining 
brightly.
A playful scene of a Russian 
Blue cat and an orange 
domestic shorthair cat  
running on the white sandy 
beach, the sky is a deep blue 
and the sun is shining 
brightly.
The image generated by the AI art generation model does not 
follow the user imagined IDEA of the scene as there are 
bananas on the plate and orange juice in the glass . To 
address this, the sentence prompt can be modified to specify 
that there should be no bananas on the plate and no orange 
juice in the glass.a plate that has no bananas on it. there is a 
glass without orange juice next to it
A breakfast scene with a 
plate that has no bananas 
and a glass without orange 
juice, with a blue 
background and a bright 
lighting.
A close-up view of an empty 
plate with no other objects  
on it, and an empty glass  
without orange juice on a 
wooden table, with a white 
background.Input user IDEA Draft prompt and image to revise Text feedback
A watercolor cartoon logo based on the 
design in the given image
A logo design of a llama with 
a red scarf and beanie, in a 
watercolor cartoon style, 
with a soft and pastel color 
palette.
A logo design of a llama in a 
watercolor cartoon style, 
with a red beanie and scarf, 
standing on all fours , with a 
soft and pastel color palette, 
similar to the design in the 
given image.
The llama in the generated image is not in the same design as 
the one in the given image. The llama in the given image is 
standing on all fours, while the llama in the generated image 
is only showing its head . To address this issue, the sentence 
prompt should be modified to specifically mention that the 
llama should be standing on all fours, and the design should 
be similar to the one in the given image.
A scene of a man in a suit 
waving his hand, with the 
same style as the geometric 
dog image on the left.Find the the image style pattern in the left 
two dog images and apply it on the top 
right people waving hand image. Provide a 
textual description that keeps the content 
in the people waving hand image, with the 
correct style pattern.
A scene of a man in a suit  
with his right hand raised in 
a friendly wave with his 
palm facing forward , with 
the same style as the 
geometric dog image on the 
left, with a blue sky 
background, with a slight 
smile on his face, with a 
modern and abstract style .
The man in the generated image is not the same as the one in 
the given image. This is because the prompt mentions 'a man' 
but the AI art model can not understand image inputs. To 
address this, the sentence prompt should be modified to 
specifically mention the man in the given image is 'a man in a 
suit with his right hand raised in a friendly wave with his 
palm facing forward' .
A person in a yoga dolphin 
pose, posture where one 
balances on the forearms 
with the legs lifted, forming 
an inverted V shape with 
the body , on a rocky beach 
with crashing waves and a 
cloudy sky.
A breakfast scene with an 
empty plate and a glass 
without orange juice , with a 
blue background and a 
bright lighting.
A minimalist kitchen with a 
table showcasing an empty 
plate and an empty glass , 
devoid of bananas and 
orange juice respectively, 
under the soft glow of 
morning light, evoking a 
sense of scarcity.
A scene of a man in a suit 
with his right hand raised in 
a friendly wave with his palm 
facing forward, with the 
same style as the geometric 
dog image on the left, with a 
blue sky background, with a 
slight smile on his face, with 
a modern and abstract style.
A scene of a man in a suit 
with his right hand raised in 
a friendly wave with his 
palm facing forward , with 
the same style as the 
geometric dog image on the 
left, with a blue sky 
background.
Fig. F:Examples of the revised prompts. The four columns, from left to right, show
the input user IDEA, the draft image to be revised, generated text feedback, and
the revised T2I prompt and image. The dark blue color highlights the identified
discrepancies in text feedback, and how they are addressed in the revised T2I prompt.
We note that the example only shows a single round of self-refinement. Therefore, the
revised T2I prompt may have remaining issues to be further addressed.

--- PAGE 23 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 23
2 reason not 
correct
Fig. G: Examples of the draft image selection. The right column shows justification
ratings and the final selection. The dark blue color highlights the identified problems
and justifications for the draft image selection. The selected draft image in the round
is visualized with the blue box shown in the middle column.

--- PAGE 24 ---
24 Z. Yang et al.
(a) Feedback reflection: The right column shows the examples of the generated text feedback.
(b) Revised prompt generation: The right column shows the examples of the revised prompts.
Fig. H:LLaVA-1.5-13B’s [24] outputs in Idea2Img for image feedback and revision.
“an image for a children’s painting competition,” by “specifically mentioning that
the car should be simple and cartoon-like.”
Revised prompt generation. Figure F compares the T2I prompts before and
after the revision, for visualizing how text feedback helps the revision. For ex-
ample, (a) the revised T2I prompt includes a detailed description of the “yoga
dolphin pose” to generate the correct body pose; (b) the revised T2I prompt
mentions “an empty plate with no other objects” to avoid the T2I model mis-
understand the prompt “no bananas;” (c) T2I model generates the correct hand
gesture with Idea2Img providing text description on how to take a screenshot.
Idea2Img also effectively addresses the identified errors in text feedback and
improves the prompts for multimodal input IDEA, including the dog color in
Figure F(d), the llama design in Figure F(e), the study area in Figure F(f), the
human gesture in Figure F(g), the dog breed and human clothing in Figure F(h),
and the color of the two cats in Figure F(i).
Draft image selection. T2I models may generate low-quality images even
with good T2I prompts. To ensure consistent improvements in each iteration,
it is critical to reduce such generation noise by selecting from multiple draft
images in each round. Performing such selection requires GPT-4V to compare
multiple similar draft images and pick the one with the best overall quality.
Figure G shows the selection results generated by GPT-4V. The LMM prompt
isdesignedsuchthatGPT-4Vgivesjustificationsandscoresforeachdraftimage,
in addition to the final selection index. Such intermediate thoughts not only help
humans interpret the selection process, but also serve as the chain of thought

--- PAGE 25 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 25
to improve the selection performance. We observe that GPT-4V can compare
different aspects mentioned in the IDEAand give reasonable scores and selection
index. For example, checking the scene text spelling in Figure G(a); verifying
the phone screen and model in Figure G(b); counting the number of apples and
bananas in Figure G(c); verifying the ball color and dog action in Figure G(d);
finding the image with both sleep and study area in Figure G(e); selecting the
image that best fits the given image style in Figure G(f); verifying the image
contentandstyleinFigureG(g);locatingthebest-blendedimageinFigureG(h);
and finding the image with correct dog color and image style in Figure G(I).
LMMs alternative to GPT-4V. After observing the effectiveness of Idea2Img
with GPT-4V, a natural question is whether we can replace GPT-4V with
more accessible and lightweight alternatives. Figure H examines LLaVA-1.5-
13B [24,25], a leading open-source LMM, using the same test cases as those
in the main paper’s Figure 6. Despite the promising results, LMMs alternative
to GPT-4V may not be ready yet for the Idea2Img -like iterative self-refinement
framework, with two major bottlenecks. First, most current LMMs lack the
ability to process complex interleaved image-text sequences, therefore limiting
Idea2Img in understanding multimodal IDEA, processing memory, and referenc-
ing in-context examples. This limitation also prevents us from conducting image
selection experiments in Figure H, as we did in Figure 6(c) with GPT-4V. Sec-
ond, the weaker multimodal reasoning capability [64] will significantly increase
the noise in Idea2Img ’s iteration and make the framework ineffective. For exam-
ple, in Figure H(a.2), LLaVA fails to capture the correct direction to improve the
image, and in (b.1), it repeats the same T2I prompt without effective revision.
BIdea2Img Code, Data, and Gallery
We will release the Idea2Img code, evaluation queries, and generated samples.
We show the used LMM prompts pgen, pselect, pfb, previseas follows. The
colored texts indicate the corresponding multimodal contents, such as IDEA
or the history memory. LMM prompts are kept the same for different image
generation models and input IDEA.
Initial prompt generation pgen:
You are a helpful assistant.
Instruction: Given a user imagined IDEA of the scene, converting the IDEA
into a self-contained sentence prompt that will be used to generate an image.
Here are some rules to write good prompts:
- Each prompt should consist of a description of the scene followed by mod-
ifiers divided by commas.
- The modifiers should alter the mood, style, lighting, and other aspects of
the scene.
- Multiple modifiers can be used to provide more specific details.

--- PAGE 26 ---
26 Z. Yang et al.
- When generating prompts, reduce abstract psychological and emotional
descriptions.
- When generating prompts, explain images and unusual entities in IDEA
with detailed descriptions of the scene.
- Do not mention ’given image’ in output, use detailed texts to describe the
image in IDEA instead.
- Generate diverse prompts.
- Each prompt should have no more than 50 words.
IDEA:IDEA input .
End of IDEA.
Based on the above information, you will write Ndetailed prompts exactly
about the IDEA follow the rules. Each prompt is wrapped with <START>
and <END>.
Draft image selection pselect:
You are a helpful assistant.
You are a judge to rank provided images. Below are Nimages generated by
an AI art generation model, indexed from 0 to N-1.
From scale 1 to 10, decide how similar each image is to the user imagined
IDEA of the scene.
IDEA:IDEA input .
End of IDEA.
List of draft images.
Let’s think step by step. Check all aspects to see how well these images
strictly follow the content in IDEA, including having correct object counts,
attributes, entities, relationships, sizes, appearance, and all other descrip-
tions in the IDEA. Then give a score for each input images. Finally, con-
sider the scores and select the image with the best overall quality with image
index 0 to N-1wrapped with <START> and <END>. Only wrap single
image index digits between <START> and <END>.
Feedback reflection pfb:
You are a helpful assistant.
You are iteratively refining the sentence prompt by analyzing the images
produced by an AI art generation model, seeking to find out the differences
between the user imagined IDEA of the scene and the actual output.
If the generated image is not perfect, provide key REASON on ways to
improve the image and sentence prompt to better follow the user imagined
IDEA of the scene. Here are some rules to write good key REASON:

--- PAGE 27 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 27
- Carefully compare the current image with the IDEA to strictly follow the
details described in the IDEA, including object counts, attributes, entities,
relationships, sizes, and appearance. Write down what is different in detail.
- Avoid hallucinating information or asks that is not mentioned in IDEA.
- Explain images and unusual entities in IDEA with detailed text descrip-
tions of the scene.
- Explain how to modify prompts to address the given reflection reason.
- Focus on one thing to improve in each REASON.
- Avoid generating REASON identical with the REASON in previous
rounds.
IDEA:IDEA input .
End of IDEA.
This is the round tof the iteration.
The iteration history are:
Memory module history.
Based on the above information, you will write REASON that is wrapped
with <START> and <END>.
REASON:
Feedback reflection previse:
You are a helpful assistant.
Instruction: Given a user imagined IDEA of the scene, converting the IDEA
into a sentence prompt that will be used to generate an image.
Here are some rules to write good prompts:
- Each prompt should consist of a description of the scene followed by mod-
ifiers divided by commas.
- The modifiers should alter the mood, style, lighting, spatial details, and
other aspects of the scene.
- Multiple modifiers can be used to provide more specific details.
- When generating prompts, reduce abstract psychological and emotional
descriptions.
- When generating prompts, explain images and unusual entities in IDEA
with detailed descriptions of the scene.
- Do not mention ’given image’ in output, use detailed texts to describe the
image in IDEA.
- Generate diverse prompts.
- Output prompt should have less than 50 words.
IDEA:IDEA input .
End of IDEA.
You are iteratively improving the sentence prompt by looking at the images
generated by an AI art generation model and find out what is different from
the given IDEA.
This is the round tof the iteration.
The iteration history are:
Memory module history.
Generated sentence prompt for current round tis:prompt

--- PAGE 28 ---
28 Z. Yang et al.
Corresponding image generated by the AI art generation model: image
However,reflection
Based on the above information, to improve the image, you will write N
detailed prompts exactly about the IDEA follow the rules. Make description
of the scene more detailed and add modifiers to address the given key reasons
to improve the image. Avoid generating prompts identical with the ones in
previous rounds. Each prompt is wrapped with <START> and <END>.
References
1. Chatgpt can now see, hear, and speak. https://openai.com/blog/chatgpt-can-
now-see-hear-and-speak (2023)
2. Avrahami,O.,Aberman,K.,Fried,O.,Cohen-Or,D.,Lischinski,D.:Break-a-scene:
Extracting multiple concepts from a single image. arXiv preprint arXiv:2305.16311
(2023)
3. Avrahami, O., Lischinski, D., Fried, O.: Blended diffusion for text-driven editing of
natural images. In: Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition. pp. 18208–18218 (2022)
4. Betker, J., Goh, G., Li, J., Brooks, T., Wang, J., Li, L., Ouyang, L., Zhuang,
J., Lee, J., Guo, Y., Manassra, W., Dhariwal, P., Chu, C., Jiao, Y., Ramesh, A.:
Improving image generation with better captions (2023)
5. Black, K., Janner, M., Du, Y., Kostrikov, I., Levine, S.: Training diffusion models
with reinforcement learning. arXiv preprint arXiv:2305.13301 (2023)
6. Brooks, T., Holynski, A., Efros, A.A.: Instructpix2pix: Learning to follow image
editing instructions. In: Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. pp. 18392–18402 (2023)
7. Chefer, H., Alaluf, Y., Vinker, Y., Wolf, L., Cohen-Or, D.: Attend-and-excite:
Attention-based semantic guidance for text-to-image diffusion models. arXiv
preprint arXiv:2301.13826 (2023)
8. Chen, W., Hu, H., Li, Y., Rui, N., Jia, X., Chang, M.W., Cohen, W.W.: Subject-
driven text-to-image generation via apprenticeship learning. arXiv preprint
arXiv:2304.00186 (2023)
9. Chen, X., Lin, M., Schärli, N., Zhou, D.: Teaching large language models to self-
debug. arXiv preprint arXiv:2304.05128 (2023)
10. Fan, Y., Watkins, O., Du, Y., Liu, H., Ryu, M., Boutilier, C., Abbeel, P.,
Ghavamzadeh, M., Lee, K., Lee, K.: Dpok: Reinforcement learning for fine-tuning
text-to-image diffusion models. arXiv preprint arXiv:2305.16381 (2023)
11. Fan, Y., Watkins, O., Du, Y., Liu, H., Ryu, M., Boutilier, C., Abbeel, P.,
Ghavamzadeh, M., Lee, K., Lee, K.: Reinforcement learning for fine-tuning text-
to-image diffusion models. Advances in Neural Information Processing Systems 36
(2024)
12. Feng, W., He, X., Fu, T.J., Jampani, V., Akula, A.R., Narayana, P., Basu, S.,
Wang, X.E., Wang, W.Y.: Training-free structured diffusion guidance for com-
positional text-to-image synthesis. In: The Eleventh International Conference on
Learning Representations (2022)
13. Gatys, L.A., Ecker, A.S., Bethge, M.: A neural algorithm of artistic style. arXiv
preprint arXiv:1508.06576 (2015)
14. Google: Bard. https://bard.google.com (2023), accessed: 2023-07-17

--- PAGE 29 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 29
15. Guo, Y., Liang, Y., Wu, C., Wu, W., Zhao, D., Duan, N.: Learning to program
with natural language. arXiv preprint arXiv:2304.10464 (2023)
16. Gupta, T., Kembhavi, A.: Visual programming: Compositional visual reasoning
without training. In: Proceedings of the IEEE/CVF Conference on Computer Vi-
sion and Pattern Recognition. pp. 14953–14962 (2023)
17. Hertz, A., Mokady, R., Tenenbaum, J., Aberman, K., Pritch, Y., Cohen-or, D.:
Prompt-to-prompt image editing with cross-attention control. In: The Eleventh
International Conference on Learning Representations (2022)
18. Kawar, B., Zada, S., Lang, O., Tov, O., Chang, H., Dekel, T., Mosseri, I., Irani,
M.: Imagic: Text-based real image editing with diffusion models. In: Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
6007–6017 (2023)
19. Kumari, N., Zhang, B., Zhang, R., Shechtman, E., Zhu, J.Y.: Multi-concept cus-
tomization of text-to-image diffusion. In: Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition. pp. 1931–1941 (2023)
20. Lab, D.: Deepfloyd if. https://github.com/deep-floyd/IF (2023)
21. Lee, K., Liu, H., Ryu, M., Watkins, O., Du, Y., Boutilier, C., Abbeel, P.,
Ghavamzadeh, M., Gu, S.S.: Aligning text-to-image models using human feedback.
arXiv preprint arXiv:2302.12192 (2023)
22. Li, C., Gan, Z., Yang, Z., Yang, J., Li, L., Wang, L., Gao, J.: Multimodal
foundation models: From specialists to general-purpose assistants. arXiv preprint
arXiv:2309.10020 (2023)
23. Li,Y.,Liu,H.,Wu,Q.,Mu,F.,Yang,J.,Gao,J.,Li,C.,Lee,Y.J.:Gligen:Open-set
grounded text-to-image generation. In: Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition. pp. 22511–22521 (2023)
24. Liu, H., Li, C., Li, Y., Lee, Y.J.: Improved baselines with visual instruction tuning.
arXiv preprint arXiv:2310.03744 (2023)
25. Liu, H., Li, C., Wu, Q., Lee, Y.J.: Visual instruction tuning. arXiv preprint
arXiv:2304.08485 (2023)
26. Lu, P., Peng, B., Cheng, H., Galley, M., Chang, K.W., Wu, Y.N., Zhu, S.C., Gao,
J.: Chameleon: Plug-and-play compositional reasoning with large language models.
arXiv preprint arXiv:2304.09842 (2023)
27. Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., Alon, U.,
Dziri, N., Prabhumoye, S., Yang, Y., et al.: Self-refine: Iterative refinement with
self-feedback. arXiv preprint arXiv:2303.17651 (2023)
28. Meng, C., He, Y., Song, Y., Song, J., Wu, J., Zhu, J.Y., Ermon, S.: Sdedit: Guided
image synthesis and editing with stochastic differential equations. arXiv preprint
arXiv:2108.01073 (2021)
29. Nasiriany, S., Xia, F., Yu, W., Xiao, T., Liang, J., Dasgupta, I., Xie, A., Driess,
D., Wahid, A., Xu, Z., et al.: Pivot: Iterative visual prompting elicits actionable
knowledge for vlms. arXiv preprint arXiv:2402.07872 (2024)
30. OpenAI: Dall ·e 3 system card. https://cdn.openai.com/papers/DALL_E_3_
System_Card.pdf (2023)
31. OpenAI: Gpt-4 technical report (2023)
32. OpenAI: Gpt-4v(ision) system card (2023), https://cdn.openai.com/papers/
GPTV_System_Card.pdf
33. OpenAI: Gpt-4v(ision) technical work and authors. https://cdn.openai.com/
contributions/gpt-4v.pdf (2023)
34. Pan, L., Saxon, M., Xu, W., Nathani, D., Wang, X., Wang, W.Y.: Automatically
correcting large language models: Surveying the landscape of diverse self-correction
strategies. arXiv preprint arXiv:2308.03188 (2023)

--- PAGE 30 ---
30 Z. Yang et al.
35. Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Ribeiro,
M.T.: Art: Automatic multi-step reasoning and tool-use for large language models.
arXiv preprint arXiv:2303.09014 (2023)
36. Podell, D., English, Z., Lacey, K., Blattmann, A., Dockhorn, T., Müller, J., Penna,
J., Rombach, R.: Sdxl: Improving latent diffusion models for high-resolution image
synthesis. arXiv preprint arXiv:2307.01952 (2023)
37. Pryzant, R., Iter, D., Li, J., Lee, Y.T., Zhu, C., Zeng, M.: Automatic
prompt optimization with" gradient descent" and beam search. arXiv preprint
arXiv:2305.03495 (2023)
38. Qi, J., Ding, M., Wang, W., Bai, Y., Lv, Q., Hong, W., Xu, B., Hou, L., Li, J.,
Dong, Y., et al.: Cogcom: Train large vision-language models diving into details
through chain of manipulations. arXiv preprint arXiv:2402.04236 (2024)
39. Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., Chen, M.: Hierarchical text-
conditional image generation with clip latents. arXiv preprint arXiv:2204.06125
(2022)
40. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution
image synthesis with latent diffusion models. In: Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition. pp. 10684–10695 (2022)
41. Ruiz, N., Li, Y., Jampani, V., Pritch, Y., Rubinstein, M., Aberman, K.: Dream-
booth: Fine tuning text-to-image diffusion models for subject-driven generation.
In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition. pp. 22500–22510 (2023)
42. Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., Ghasemipour,
S.K.S., Ayan, B.K., Mahdavi, S.S., Lopes, R.G., et al.: Photorealistic text-
to-image diffusion models with deep language understanding. arXiv preprint
arXiv:2205.11487 (2022)
43. Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L.,
Cancedda, N., Scialom, T.: Toolformer: Language models can teach themselves to
use tools. arXiv preprint arXiv:2302.04761 (2023)
44. Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: Hugginggpt: Solving ai
tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580
(2023)
45. Shi, J., Xiong, W., Lin, Z., Jung, H.J.: Instantbooth: Personalized text-to-image
generation without test-time finetuning. arXiv preprint arXiv:2304.03411 (2023)
46. Shinn, N., Cassano, F., Labash, B., Gopinath, A., Narasimhan, K., Yao, S.: Re-
flexion: Language agents with verbal reinforcement learning (2023)
47. Shridhar, M., Yuan, X., Côté, M.A., Bisk, Y., Trischler, A., Hausknecht, M.: Alf-
world: Aligning text and embodied environments for interactive learning. arXiv
preprint arXiv:2010.03768 (2020)
48. Singer, U., Polyak, A., Hayes, T., Yin, X., An, J., Zhang, S., Hu, Q., Yang, H.,
Ashual, O., Gafni, O., et al.: Make-a-video: Text-to-video generation without text-
video data. arXiv preprint arXiv:2209.14792 (2022)
49. Surís, D., Menon, S., Vondrick, C.: Vipergpt: Visual inference via python execution
for reasoning. arXiv preprint arXiv:2303.08128 (2023)
50. Wang, J., Yang, Z., Hu, X., Li, L., Lin, K., Gan, Z., Liu, Z., Liu, C., Wang, L.: Git:
A generative image-to-text transformer for vision and language. arXiv preprint
arXiv:2205.14100 (2022)
51. Wang, Z.J., Montoya, E., Munechika, D., Yang, H., Hoover, B., Chau, D.H.: Diffu-
siondb: A large-scale prompt gallery dataset for text-to-image generative models.
arXiv preprint arXiv:2210.14896 (2022)

--- PAGE 31 ---
Idea2Img : Self-Refinement with LMMs for Automatic Visual Creation 31
52. Wu, C., Yin, S., Qi, W., Wang, X., Tang, Z., Duan, N.: Visual chatgpt:
Talking, drawing and editing with visual foundation models. arXiv preprint
arXiv:2303.04671 (2023)
53. Wu, J., Wang, J., Yang, Z., Gan, Z., Liu, Z., Yuan, J., Wang, L.: Grit: A
generative region-to-text transformer for object understanding. arXiv preprint
arXiv:2212.00280 (2022)
54. Wu, P., Xie, S.: V*: Guided visual search as a core mechanism in multimodal llms.
arXiv preprint arXiv:2312.14135 17(2023)
55. Yan,A.,Yang,Z.,Zhu,W.,Lin,K.,Li,L.,Wang,J.,Yang,J.,Zhong,Y.,McAuley,
J., Gao, J., et al.: Gpt-4v in wonderland: Large multimodal models for zero-shot
smartphone gui navigation. arXiv preprint arXiv:2311.07562 (2023)
56. Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q.V., Zhou, D., Chen, X.: Large language
models as optimizers. arXiv preprint arXiv:2309.03409 (2023)
57. Yang, Z., Li, L., Lin, K., Wang, J., Lin, C.C., Liu, Z., Wang, L.: The dawn of lmms:
Preliminary explorations with gpt-4v (ision). arXiv preprint arXiv:2309.17421
(2023)
58. Yang*, Z., Li*, L., Wang*, J., Lin*, K., Azarnasab*, E., Ahmed*, F., Liu, Z., Liu,
C., Zeng, M., Wang, L.: Mm-react: Prompting chatgpt for multimodal reasoning
and action. arXiv preprint arXiv:2303.11381 (2023)
59. Yang, Z., Wang, J., Gan, Z., Li, L., Lin, K., Wu, C., Duan, N., Liu, Z., Liu, C.,
Zeng, M., et al.: Reco: Region-controlled text-to-image generation. In: Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
14246–14255 (2023)
60. Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W.W., Salakhutdinov, R., Manning,
C.D.: Hotpotqa: A dataset for diverse, explainable multi-hop question answering.
arXiv preprint arXiv:1809.09600 (2018)
61. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y.: React: Syn-
ergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629
(2022)
62. Yin, S., Wu, C., Yang, H., Wang, J., Wang, X., Ni, M., Yang, Z., Li, L., Liu,
S., Yang, F., et al.: Nuwa-xl: Diffusion over diffusion for extremely long video
generation. arXiv preprint arXiv:2303.12346 (2023)
63. Yu, J., Xu, Y., Koh, J.Y., Luong, T., Baid, G., Wang, Z., Vasudevan, V., Ku,
A., Yang, Y., Ayan, B.K., et al.: Scaling autoregressive models for content-rich
text-to-image generation. Transactions on Machine Learning Research (2022)
64. Yu, W., Yang, Z., Li, L., Wang, J., Lin, K., Liu, Z., Wang, X., Wang, L.: Mm-
vet: Evaluating large multimodal models for integrated capabilities. arXiv preprint
arXiv:2308.02490 (2023)
65. Zhang, L., Agrawala, M.: Adding conditional control to text-to-image diffusion
models. arXiv preprint arXiv:2302.05543 (2023)
66. Zhao, A., Huang, D., Xu, Q., Lin, M., Liu, Y.J., Huang, G.: Expel: Llm agents are
experiential learners. arXiv preprint arXiv:2308.10144 (2023)
67. Zhu, W., Wang, X., Lu, Y., Fu, T.J., Wang, X.E., Eckstein, M., Wang, W.Y.:
Collaborative generative ai: Integrating gpt-k for efficient editing in text-to-image
generation. arXiv preprint arXiv:2305.11317 (2023)

# 2309.01809.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2309.01809.pdf
# Kích thước file: 13383596 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Các khả năng nổi lên trong mô hình ngôn ngữ lớn có chỉ là học trong ngữ cảnh không?
Sheng Lu1*, Irina Bigoulaeva1*, Rachneet Sachdeva1,
Harish Tayyar Madabushi2, và Iryna Gurevych1
1Phòng thí nghiệm xử lý tri thức phổ biến, Đại học Kỹ thuật Darmstadt
2Khoa Khoa học máy tính, Đại học Bath
www.ukp.tu-darmstadt.de
htm43@bath.ac.uk
Tóm tắt
Các mô hình ngôn ngữ lớn, bao gồm hàng tỷ tham số và được huấn luyện trước trên các tập dữ liệu quy mô web mở rộng, được cho là có thể thu được các khả năng nhất định mà không cần được huấn luyện cụ thể cho chúng. Những khả năng này, được gọi là "khả năng nổi lên", đã là động lực thúc đẩy trong các cuộc thảo luận về tiềm năng và rủi ro của các mô hình ngôn ngữ. Một thách thức chính trong việc đánh giá khả năng nổi lên là chúng bị ảnh hưởng bởi các năng lực mô hình phát sinh thông qua các kỹ thuật gợi ý thay thế, bao gồm học trong ngữ cảnh, là khả năng của mô hình hoàn thành nhiệm vụ dựa trên một vài ví dụ. Chúng tôi trình bày một lý thuyết mới giải thích khả năng nổi lên, có tính đến các yếu tố gây nhiễu tiềm năng của chúng, và chứng minh nghiêm ngặt lý thuyết này thông qua hơn 1000 thí nghiệm. Những phát hiện của chúng tôi gợi ý rằng các khả năng nổi lên được cho là như vậy không thực sự nổi lên, mà là kết quả của sự kết hợp giữa học trong ngữ cảnh, bộ nhớ mô hình và kiến thức ngôn ngữ. Công trình của chúng tôi là một bước nền tảng trong việc giải thích hiệu suất mô hình ngôn ngữ, cung cấp một mẫu cho việc sử dụng hiệu quả chúng và làm rõ nghịch lý về khả năng xuất sắc trong một số trường hợp trong khi thất bại trong những trường hợp khác. Do đó, chúng tôi chứng minh rằng khả năng của chúng không nên được đánh giá quá cao.1

1 Giới thiệu, Động lực và Bối cảnh
Một trong những khía cạnh hấp dẫn nhất của các mô hình ngôn ngữ được huấn luyện trước (PLMs) là khả năng thu nhận kiến thức đa dạng trên các miền khác nhau, trong khi chủ yếu được huấn luyện thông qua mô hình ngôn ngữ có mặt nạ, một nhiệm vụ yêu cầu các mô hình dự đoán các token bị mặt nạ trong đầu vào của chúng (Tenney et al., 2019; Petroni et al., 2019). Các khả năng đa dạng của PLMs có thể được phân loại thành hai loại rộng: khả năng ngôn ngữ hình thức và khả năng ngôn ngữ chức năng. Khả năng ngôn ngữ hình thức đề cập đến việc hiểu các quy tắc và mẫu ngôn ngữ, mà PLMs, ví dụ như BERT (Devlin et al., 2019) được biết đến là xuất sắc (Tenney et al., 2019; Petroni et al., 2019). Loại sau bao gồm một loạt khả năng tương tự như nhận thức con người cần thiết cho việc sử dụng và hiểu ngôn ngữ trong thế giới thực, chẳng hạn như kiến thức thường thức và nhận thức xã hội. Trong khi PLMs xuất sắc về khả năng ngôn ngữ hình thức, chúng đã gặp thách thức trong việc phát triển khả năng ngôn ngữ chức năng (Mahowald et al., 2023).

Việc giới thiệu các mô hình ngôn ngữ lớn (LLMs), thường là các PLMs sinh sản được mở rộng quy mô lên hàng tỷ tham số và được huấn luyện trên các tập dữ liệu quy mô web rộng lớn, đang thay đổi bối cảnh này (Brown et al., 2020; Chowdhery et al., 2023; Touvron et al., 2023a,b). Các nghiên cứu gần đây cho thấy LLMs thể hiện khả năng nổi lên, được đo bằng hiệu suất trên mức ngẫu nhiên mà không cần huấn luyện rõ ràng trên các nhiệm vụ, bao gồm những nhiệm vụ yêu cầu một số hình thức lý luận. Khả năng nổi lên lần đầu tiên được định nghĩa là khả năng giải quyết một nhiệm vụ vắng mặt trong các mô hình nhỏ hơn, nhưng có mặt trong LLMs. Định nghĩa này, được giới thiệu gần như đồng thời bởi hai công trình (Wei et al., 2022b; Srivastava et al., 2023), dựa trên định nghĩa tổng quát hơn về sự nổi lên trong vật lý: "Sự nổi lên là khi những thay đổi định lượng trong hệ thống dẫn đến những thay đổi định tính trong hành vi" (Anderson, 1972). Khả năng nổi lên được ngụ ý do khả năng của LLMs thực hiện trên mức cơ sở ngẫu nhiên trên các nhiệm vụ tương ứng mà không cần huấn luyện rõ ràng trên cùng những nhiệm vụ đó. Ví dụ, khả năng nổi lên hiểu các tình huống xã hội trong LLMs được suy ra từ việc LLMs thực hiện tốt trên mức cơ sở ngẫu nhiên trên nhiệm vụ Social IQA (Sap et al., 2019), nhiệm vụ này phục vụ đánh giá trí thông minh cảm xúc và xã hội của mô hình và bao gồm các câu hỏi như "Carson rất hào hứng khi thức dậy để đi học. Tại sao anh ấy làm điều này? Tùy chọn: Làm bài kiểm tra lớn, Đi ngủ sớm, Chỉ chào bạn (đúng)".

--- TRANG 2 ---
1.1 Ý nghĩa đối với ứng dụng và an toàn
Trong khi các nghiên cứu trước đó về khả năng nổi lên không rõ ràng tạo ra sự phân biệt giữa khả năng ngôn ngữ hình thức và chức năng, việc xác định nhiều khả năng ngôn ngữ chức năng có ý nghĩa sâu sắc đối với cả tiềm năng và an toàn của LLMs. Giả định rằng LLMs có quyền truy cập vào khả năng ngôn ngữ chức năng nổi lên ảnh hưởng đáng kể đến cách mà người dùng tương tác và sử dụng các hệ thống này. Sự phụ thuộc quá mức vào những khả năng được cảm nhận này có thể khiến người dùng cung cấp các hướng dẫn không đủ chi tiết, có thể dẫn đến ảo giác và lỗi. Nếu thực sự có nhiều khả năng ngôn ngữ chức năng nổi lên theo quy mô, điều này cho thấy việc mở rộng quy mô hơn nữa có tiềm năng mở khóa một loạt khả năng bổ sung mà chúng ta không thể dự đoán, đặc biệt là vì chúng có xu hướng không thể hiện bản thân trong các mô hình quy mô nhỏ hơn (Wei et al., 2022b). Sự không thể dự đoán vốn có liên quan đến khả năng nổi lên có ý nghĩa quan trọng đối với cuộc thảo luận xung quanh an toàn và bảo mật khi sử dụng LLMs. Thực sự, đã có lập luận rằng những khả năng này có thể bao gồm các khả năng có thể nguy hiểm, bao gồm lý luận và lập kế hoạch (Hoffmann, 2023), do đó đặt ra mối đe dọa hiện hữu cho nhân loại (Bengio et al., 2023). Trong công trình này, chúng tôi gọi những khả năng có thể có hại như vậy là "khả năng nguy hiểm tiềm ẩn."

Điều quan trọng cần nhấn mạnh là việc phát triển khả năng thành thạo ngôn ngữ (tức là khả năng ngôn ngữ hình thức) không mang tiềm năng của bản chất này. Điều tương tự có thể nói về khả năng xử lý hiệu quả các nhiệm vụ truy xuất thông tin. Trọng tâm thực sự nằm ở các khả năng tiềm năng liên quan đến khả năng ngôn ngữ chức năng. Tuy nhiên, cần nhấn mạnh rằng điều này không bao gồm các mối nguy hiểm khác do việc sử dụng sai các mô hình này, chẳng hạn như sử dụng LLMs để tạo tin tức giả. Tương tự, chúng tôi không tranh luận rằng các hệ thống AI tương lai không bao giờ có thể đặt ra mối đe dọa hiện hữu. Thay vào đó, chúng tôi làm rõ rằng, trái với các câu chuyện phổ biến, bằng chứng từ khả năng LLM không hỗ trợ mối quan ngại này.

1.2 Khả năng so với kỹ thuật
Việc mở rộng quy mô LLMs tạo điều kiện để thu nhận các năng lực đa dạng, có thể được nhóm thành hai loại: Loại đầu tiên bao gồm khả năng, đã được mô tả. Loại thứ hai bao gồm các kỹ thuật khác nhau, mà LLMs có thể hưởng lợi từ. Những kỹ thuật này cho thấy ít tác động hơn trong các mô hình nhỏ hơn, nhưng trở nên hiệu quả hơn dần theo quy mô. Trong số các kỹ thuật này có học trong ngữ cảnh và điều chỉnh hướng dẫn. Học trong ngữ cảnh (ICL) là kỹ thuật trong đó LLMs được cung cấp một số lượng hạn chế các ví dụ trong chính lời nhắc đầu vào (Brown et al., 2020). Từ những ví dụ này, mô hình suy ra cách thực hiện một nhiệm vụ cụ thể, phản hồi một cách phù hợp với câu hỏi được đặt ra bởi lời nhắc (Brown et al., 2020; Liu et al., 2023). Các điều tra về cơ sở lý thuyết của ICL và biểu hiện cụ thể của nó trong LLMs cho thấy nó có thể có sự tương đồng với quá trình tinh chỉnh mô hình trên các nhiệm vụ cụ thể mà chúng được cung cấp ví dụ (Akyürek et al., 2023; Dai et al., 2023; von Oswald et al., 2023; Wei et al., 2023). Một kỹ thuật khác độc quyền với LLMs là tinh chỉnh hướng dẫn, được gọi là điều chỉnh hướng dẫn. Kỹ thuật này bao gồm tinh chỉnh LLMs trên các tập dữ liệu của lời nhắc và các đầu ra mong muốn tương ứng của chúng, cho phép các mô hình tuân theo các hướng dẫn rõ ràng trong lời nhắc (Chung et al., 2022; Wei et al., 2022a; Taori et al., 2023). Theo công trình trước đây (Wei et al., 2022b), chúng tôi gọi những kỹ thuật này, được minh họa trong Hình 3, là kỹ thuật gợi ý.

Quan trọng đối với cuộc điều tra của chúng tôi là quan sát rằng kỹ thuật gợi ý và khả năng nổi lên biểu hiện trong LLMs ở quy mô tương đối. Hơn nữa, ICL và điều chỉnh hướng dẫn có thể được quan sát trong các mô hình quy mô nhỏ hơn, mặc dù ở mức độ thấp hơn, và do đó có thể dự đoán được. Khả năng dự đoán này có nghĩa là chúng không 'nổi lên', cũng không đặt ra mối đe dọa, tương phản với sự không thể dự đoán và rủi ro tiềm năng liên quan đến khả năng nổi lên trong các mô hình lớn hơn. Xem xét bối cảnh này, việc xác định mức độ của những khả năng nổi lên này trong trường hợp không có kỹ thuật gợi ý trở nên bắt buộc.

1.3 Tinh chỉnh, học trong ngữ cảnh và các kỹ thuật gợi ý khác
Các mô hình mạng nơ-ron nhân tạo đã, trong một thời gian, thể hiện thành công to lớn trên các nhiệm vụ cụ thể khi được huấn luyện trên những nhiệm vụ đó (Devlin et al., 2019; Liu et al., 2019). PLMs đặc biệt đã chứng minh điều này ngay cả khi được huấn luyện chỉ trên một vài ví dụ (Hofer et al., 2018; Radford et al., 2019; Brown et al., 2020; Gao et al., 2021). Hiệu suất như vậy không được coi là "nổi lên", chính xác vì các mô hình được huấn luyện trên chính nhiệm vụ đó. Thực sự, thực tế là

--- TRANG 3 ---
LLMs không được huấn luyện trên các nhiệm vụ được sử dụng để đánh giá khả năng nổi lên của chúng là trung tâm cho việc xác định các khả năng thực sự nổi lên. Khẳng định rằng việc đạt được hiệu suất thỏa đáng trên một nhiệm vụ nhất định biểu thị sự nổi lên của 'khả năng' liên quan phụ thuộc vào điều kiện là các mô hình không được huấn luyện rõ ràng cho nhiệm vụ cụ thể đó.

Những hiểu biết gần đây cho thấy sự tương đồng giữa ICL và huấn luyện rõ ràng gợi ý rằng thành công trên một nhiệm vụ thông qua ICL, giống như các mô hình được huấn luyện rõ ràng để giải quyết nhiệm vụ, không ngụ ý một mô hình vốn có khả năng đó (Dai et al., 2023). Ví dụ, đã được chứng minh rằng ICL thực hiện gradient descent một cách ngầm định và xây dựng một hàm tại thời điểm suy luận trên các vấn đề hồi quy (Akyürek et al., 2023; Li et al., 2023; Zhang et al., 2023a), có thể liên quan đến meta-learning dựa trên gradient (von Oswald et al., 2023). Tuy nhiên, các cơ chế cụ thể điều chỉnh ICL không ảnh hưởng đến lập luận của chúng tôi: Thực tế về chức năng của nó đủ để nhấn mạnh sự cần thiết của việc đánh giá khả năng nổi lên trong trường hợp không có ICL. Ngoài ra, các tập dữ liệu điều chỉnh hướng dẫn thường bao gồm một số biến thể của hướng dẫn theo sau bởi đầu vào nhiệm vụ hoặc ngữ cảnh (xem Hình 3). Do đó, chúng tôi tranh luận rằng quá trình tinh chỉnh hướng dẫn có thể cho phép các mô hình ánh xạ lời nhắc đến các ví dụ trong ngữ cảnh (được chi tiết trong Phần 4), do đó sử dụng ICL để phản hồi lời nhắc. Điều này sẽ ngụ ý rằng thành công của một mô hình trong việc giải quyết một nhiệm vụ trong kịch bản này cũng không chỉ ra sự nổi lên của khả năng tương ứng.

Các vấn đề an toàn liên quan đến LLMs xuất phát từ khả năng của chúng thực hiện tốt trên mức cơ sở ngẫu nhiên trên các nhiệm vụ không thể được giải quyết thông qua ghi nhớ và biểu thị các 'khả năng' nhất định, mà không cần huấn luyện rõ ràng trên những nhiệm vụ đó. Do đó, việc nhận ra rằng lời nhắc hoạt động như một hình thức 'cơ chế huấn luyện' thay vì đơn giản là cách giao tiếp với mô hình có khả năng ngôn ngữ chức năng vốn có mang tiềm năng thay đổi cách chúng ta sử dụng những mô hình này và làm sâu sắc thêm hiểu biết về khả năng và giới hạn của chúng. Do đó, việc tiến hành đánh giá độc lập về khả năng của LLMs, tách biệt khỏi ICL là quan trọng.

1.4 Câu hỏi nghiên cứu và đóng góp
Nghiên cứu của chúng tôi tìm cách trả lời hai câu hỏi quan trọng: Thứ nhất, trước ảnh hưởng của ICL đối với khả năng nổi lên được cảm nhận trong LLMs, những khả năng nào thực sự nổi lên trong trường hợp không có ICL, bao gồm điều chỉnh hướng dẫn? Thứ hai, với khả năng ICL của LLMs và việc đưa vào thường xuyên các ánh xạ hướng dẫn-mẫu trong các tập dữ liệu điều chỉnh hướng dẫn, chúng ta có thể tìm thấy bằng chứng về sự nổi lên của khả năng ngôn ngữ chức năng trong các mô hình được điều chỉnh hướng dẫn không? Hay ICL có thể giải thích tốt hơn khả năng và thiếu sót của chúng?

Đóng góp chính của chúng tôi nằm ở việc chứng minh sự vắng mặt của khả năng ngôn ngữ chức năng nổi lên trong LLMs khi ICL không phải là yếu tố, do đó làm sáng tỏ khả năng thực sự của LLMs và khẳng định an toàn của chúng, đồng thời xua tan lo ngại về khả năng nguy hiểm tiềm ẩn. Các đóng góp phụ của chúng tôi bao gồm kiểm tra thực nghiệm giả thuyết rằng khả năng của các mô hình được điều chỉnh hướng dẫn xuất phát từ ICL hiệu quả, do đó đưa ra lời giải thích cho khả năng của LLMs như xuất phát từ sự kết hợp của kỹ năng ngôn ngữ hình thức, giữ lại và gọi lại thông tin rộng lớn, và đáng chú ý là ICL. Bằng cách xác định ICL có thể điều khiển bởi người dùng, thay vì khả năng ngôn ngữ chức năng nội tại, là cơ chế đằng sau hiệu suất LLM, chúng tôi đặt ra khung cho việc sử dụng hiệu quả hơn những mô hình này, làm sáng tỏ khả năng và giới hạn của chúng.

2 Thiết lập thí nghiệm
Trong phần này, chúng tôi trình bày tổng quan về các phương pháp thí nghiệm của chúng tôi điều tra khả năng nổi lên trong trường hợp không có ICL. Chúng tôi thí nghiệm với 20 mô hình trên 22 nhiệm vụ sử dụng hai cài đặt khác nhau. Chúng tôi sử dụng bốn chỉ số đánh giá khác nhau và thêm vào đó chạy nhiều kiểm tra độ chệch, bao gồm phân tích thủ công kết quả của chúng tôi. Chúng tôi trình bày tổng quan về thiết lập này dưới đây, trong khi chi tiết về các siêu tham số và chế độ huấn luyện được trình bày trong Phụ lục C.

2.1 Mô hình
Chúng tôi thí nghiệm với bốn họ mô hình: GPT, T5 (Raffel et al., 2020), Falcon2 và LLaMA (Touvron et al., 2023a). Chúng tôi chọn những họ mô hình này, vì GPT và LLaMA trước đây đã được tìm thấy có khả năng nổi lên, và Falcon đứng đầu bảng xếp hạng LLM tại thời điểm viết. Cuối cùng, chúng tôi chọn T5 vì nó là mô hình mã hóa-giải mã, và phiên bản được điều chỉnh hướng dẫn của nó (Flan) được huấn luyện sử dụng một tập dữ liệu điều chỉnh hướng dẫn mở rộng. Bảng 1 liệt kê các mô hình mà chúng tôi sử dụng trong thí nghiệm của chúng tôi. Sự nổi lên của khả năng liên quan đến quy mô yêu cầu đánh giá mỗi họ mô hình trên một loạt kích thước (số lượng tham số), và vì vậy chúng tôi chọn các mô hình ở các quy mô khác nhau từ mỗi họ này. Quan trọng đối với cuộc điều tra của chúng tôi là giả thuyết rằng điều chỉnh hướng dẫn có thể gián tiếp tận dụng ICL. Trước khả năng này, chúng tôi thí nghiệm với cả hai.

[Bảng 1 với các mô hình và kích thước]

2.2 Nhiệm vụ
Trong việc lựa chọn các nhiệm vụ để đánh giá sự nổi lên của khả năng, chúng tôi dựa trên lựa chọn của chúng tôi về những nhiệm vụ đã được xác định là nổi lên trong GPT-3 bởi các công trình trước đây. Chúng tôi gọi những nhiệm vụ này là được xác định trước đây là nổi lên. Trong số 17 nhiệm vụ như vậy trong tập dữ liệu BIG-bench (Srivastava et al., 2023), chúng tôi đưa 14 vào nghiên cứu của chúng tôi. Ba nhiệm vụ được xác định trước đây là nổi lên bị loại khỏi phân tích của chúng tôi, vì bản chất sinh sản của chúng khiến chúng khó đánh giá tự động theo cách nhất quán với các nhiệm vụ khác. Ngoài ra, để tạo ra đường cơ sở để so sánh, chúng tôi ngẫu nhiên chọn bảy nhiệm vụ từ cùng tập dữ liệu không được xác định trước đây là nổi lên. Cuối cùng, chúng tôi cũng bao gồm GSM8K (Cobbe et al., 2021), bao gồm một tập hợp các vấn đề từ toán học cấp tiểu học và đáng chú ý vì ngay cả các mô hình mới nhất cũng gặp khó khăn với nhiệm vụ này.

Với khả năng ngôn ngữ hình thức và khả năng xử lý hiệu quả các nhiệm vụ truy xuất thông tin không đặt ra mối đe dọa hiện hữu, chúng tôi phân tích thủ công khả năng thành thạo cần thiết để giải quyết từng nhiệm vụ mà chúng tôi lựa chọn. Danh sách đầy đủ các nhiệm vụ, bao gồm khả năng ghi nhớ và phân loại là khả năng ngôn ngữ chức năng hoặc hình thức, được trình bày trong Bảng 2. Chúng tôi xác định khả năng ghi nhớ thông qua phân tích thủ công 50 ví dụ từ mỗi nhiệm vụ. Chúng tôi cung cấp chi tiết về phân tích thủ công và ví dụ từ mỗi nhiệm vụ trong Phụ lục F.

2.3 Cài đặt
Chúng tôi đánh giá mỗi mô hình trên mỗi nhiệm vụ sử dụng cả cài đặt few-shot và zero-shot. Khi sử dụng cài đặt few-shot, chúng tôi sử dụng 5 ví dụ trong ngữ cảnh. Chúng tôi lưu ý rằng cài đặt few-shot rõ ràng sử dụng ICL, trong khi cài đặt zero-shot thì không.

2.4 Chỉ số đánh giá
Để tính đến khả năng rằng các đầu ra được tạo ra bởi các mô hình không được điều chỉnh hướng dẫn không khớp chính xác với các lựa chọn câu trả lời được cung cấp, chúng tôi thêm vào đánh giá sử dụng chỉ số độ chính xác BERTScore, tính toán độ tương tự ngữ nghĩa giữa văn bản đầu ra và các lựa chọn câu trả lời được cung cấp sử dụng BERTScore (Zhang et al., 2020) để ước tính lựa chọn câu trả lời của mô hình. Trong cài đặt này, câu trả lời được coi là đúng nếu câu trả lời được tạo ra tương tự nhất (độ tương tự văn bản ngữ nghĩa) với lựa chọn câu trả lời đúng, và không đúng nếu nó gần hơn với bất kỳ lựa chọn nào khác. Phần lớn kết quả chúng tôi trình bày trong phân tích của chúng tôi dựa trên chỉ số đánh giá này. Đáng chú ý rằng điều này tương tự như việc lựa chọn câu trả lời mà mô hình đã thể hiện perplexity thấp nhất. Vì tính toán perplexity này cho các mô hình chỉ có thể truy cập thông qua APIs không thực tế, chúng tôi áp dụng chỉ số thay thế này. Chúng tôi chọn BERTScore thay vì các lựa chọn thay thế như BLEURT (Sellam et al., 2020) vì các lựa chọn sau được huấn luyện thêm để đánh giá tính trôi chảy của văn bản đầu ra, một yếu tố không phải là trọng tâm của chúng tôi, và một yếu tố khiến chúng tốn tài nguyên tính toán. Đối với các nhiệm vụ yêu cầu đầu ra của một số hoặc chuỗi được mã hóa (tức là, Modified arithmetic, GSM8K, và Codenames), chúng tôi giới hạn đánh giá của chúng tôi chỉ khớp chính xác, vì đo độ tương tự ngữ nghĩa giữa các số hoặc chuỗi được mã hóa không phản ánh chính xác độ gần gũi của chúng.

Ngoài ra, vì công trình gần đây đã chỉ ra rằng sự nổi lên có thể là kết quả của các chỉ số đánh giá rời rạc (Schaeffer et al., 2023), chúng tôi cũng bao gồm khoảng cách chỉnh sửa chuỗi. Điều tra của chúng tôi tiết lộ rằng việc thiếu sự nổi lên là nhất quán trên các chỉ số chúng tôi sử dụng, và do đó chúng tôi không sử dụng các chỉ số liên tục trong phân tích của chúng tôi. Tổng thể, chúng tôi đánh giá sử dụng độ chính xác khớp chính xác, độ chính xác BERTScore, và khoảng cách chỉnh sửa chuỗi.

2.5 Kiểm soát độ chệch và đánh giá thủ công
Để đảm bảo rằng đánh giá của chúng tôi là công bằng, chúng tôi xác định các độ chệch tiềm năng có thể ảnh hưởng đến phát hiện của chúng tôi và thiết kế thí nghiệm để giảm thiểu những độ chệch này. Đầu tiên, để đảm bảo rằng các mô hình không được điều chỉnh hướng dẫn không bị bất lợi bởi các lời nhắc nhiệm vụ thường có tính hướng dẫn, chúng tôi sửa đổi những lời nhắc này, bằng cách tinh chỉnh chúng để đảm bảo khả năng giải quyết của chúng ngay cả trong trường hợp không có sự hiểu biết hướng dẫn. Sau đó chúng tôi thí nghiệm với các biến thể nhỏ của những lời nhắc này để tìm định dạng tối ưu nhất. Chúng tôi cũng thí nghiệm với việc sử dụng định dạng đầu ra rút gọn, nơi các mô hình chỉ cần đầu ra một chữ cái liên quan đến câu trả lời đúng. Chúng tôi làm điều này để loại bỏ sự phụ thuộc vào các chỉ số đánh giá không khớp chính xác. Quan trọng là, chúng tôi đánh giá thủ công đầu ra của các mô hình để đảm bảo rằng các lời nhắc được các mô hình diễn giải phù hợp, đặc biệt là những mô hình không được điều chỉnh hướng dẫn. Chi tiết về những thí nghiệm này và kết quả liên quan được trình bày trong Phụ lục B.1.

3 Sự nổi lên trong GPT trong trường hợp không có học trong ngữ cảnh
Trong phần này và phần tiếp theo, chúng tôi làm nổi bật một tập hợp con kết quả với mục tiêu làm nổi bật những phát hiện và xu hướng chính từ thí nghiệm của chúng tôi. Cụ thể, phần này đề cập đến sự nổi lên của khả năng ngôn ngữ chức năng trong các mô hình không được điều chỉnh hướng dẫn, và phần tiếp theo (Phần 4) tập trung vào khám phá các mô hình được điều chỉnh hướng dẫn và sự tương tác của chúng với ICL và khả năng nổi lên. Xem xét rằng nghiên cứu trước đây đã xác định khả năng nổi lên trong GPT, chúng tôi ưu tiên họ GPT trong phân tích thí nghiệm của chúng tôi.

Hình 1 minh họa hiệu suất của các mô hình không được điều chỉnh hướng dẫn từ họ GPT trong cài đặt mà chúng được gợi ý mà không sử dụng các ví dụ trong ngữ cảnh (zero-shot). Cách tiếp cận này đảm bảo loại trừ ICL, cho phép đánh giá rõ ràng về khả năng nổi lên. Các nhiệm vụ được liệt kê trong hàng đầu tiên trên nền xám là các nhiệm vụ không được tìm thấy là nổi lên bởi công trình trước đây và phần còn lại là những nhiệm vụ đã được tìm thấy là nổi lên trước đây.

Nhớ lại rằng định nghĩa về sự nổi lên (Wei et al., 2022b) yêu cầu LLMs thực hiện một nhiệm vụ trên đường cơ sở và làm như vậy theo cách không thể được dự đoán dựa trên hiệu suất của các mô hình nhỏ hơn. Phân tích Hình 1, được trình bày trong Bảng 2 cho thấy chỉ hai nhiệm vụ là "nổi lên" khi chúng tôi kiểm soát ICL. Trong khi hai nhiệm vụ bổ sung (Misconceptions và Strategy QA) cũng có hiệu suất không thể dự đoán trên đường cơ sở, sự cải thiện chỉ là biên, vì những nhiệm vụ này là nhiệm vụ phân loại nhị phân với đường cơ sở ngẫu nhiên là 50% độ chính xác. Trong số hai nhiệm vụ được xác định, Nonsense words grammar thuộc về khả năng ngôn ngữ hình thức, mà chúng tôi đã lưu ý không liên quan đến bất kỳ khả năng nguy hiểm tiềm ẩn nào như lý luận. Nhiệm vụ khác, Hindu knowledge, chỉ dựa vào việc gọi lại thông tin và tương tự không đòi hỏi bất kỳ lý luận nào. Do đó, chúng tôi không tìm thấy khả năng ngôn ngữ chức năng nào nổi lên trong davinci, mô hình GPT 175B không được điều chỉnh hướng dẫn trong trường hợp không có ICL.

3.1 Tính toàn vẹn thí nghiệm và khả năng tổng quát hóa
Để xác thực khung thí nghiệm của chúng tôi, đặc biệt là việc sử dụng độ chính xác BERTScore và các sửa đổi lời nhắc của chúng tôi, chúng tôi tiến hành các kiểm tra tính hợp lệ. Những kiểm tra này bao gồm đánh giá các mô hình được điều chỉnh hướng dẫn với các ví dụ trong ngữ cảnh được bao gồm trong lời nhắc, được gọi là cài đặt few-shot, do đó cho phép ICL phù hợp với thiết kế thí nghiệm của công trình trước đây. Kết quả của những kiểm tra này tái tạo lại những phát hiện trước đây, xác nhận rằng khung thí nghiệm của chúng tôi không cản trở tiềm năng phát hiện khả năng nổi lên.

Vì những phát hiện của chúng tôi dựa trên việc sử dụng LLMs không được điều chỉnh hướng dẫn, chúng tôi xác minh rằng hiệu suất thấp hơn quan sát được trên các nhiệm vụ không xuất phát từ chỉ số tự động (BERTScore) không đánh giá được phản hồi mô hình một cách đầy đủ. Cụ thể, nếu mô hình tạo ra câu trả lời đúng, nhưng không phù hợp với tùy chọn mục tiêu đúng, độ chính xác BERTScore có thể không cung cấp đánh giá đáng tin cậy. Để kết thúc này, chúng tôi tiến hành phân tích hậu hoc bằng cách kiểm tra thủ công một tập hợp con gồm 50 đầu ra của các mô hình không được điều chỉnh hướng dẫn từ mỗi nhiệm vụ. Trọng tâm của chúng tôi là xác định các trường hợp mà độ chính xác BERTScore không nhận ra phản hồi đúng (âm tính giả). Lưu ý rằng dương tính giả sẽ không dẫn đến đánh giá thấp hiệu suất mô hình, và vì vậy có tác động ít hơn đến khả năng xác định sự nổi lên của chúng tôi. Mô tả toàn diện về phân tích được bao gồm trong Phụ lục B.3. Những phát hiện của chúng tôi củng cố quan điểm rằng những hạn chế – vốn có của tất cả đánh giá tự động – không làm giảm tính hợp lệ tổng thể của kết quả của chúng tôi.

Tương tự, chúng tôi thực hiện các kiểm tra khác cho các khía cạnh tiềm năng của thiết lập thí nghiệm có thể dẫn đến tác động gây nhiễu trong kết quả của chúng tôi. Những kiểm tra này bao gồm phân tích thủ công đầu ra mô hình để đảm bảo lời nhắc của chúng tôi được diễn giải đúng (Phụ lục B.3), và việc sử dụng đầu ra rút gọn để cho phép đánh giá dễ dàng hơn (Phụ lục B.2).

Cuối cùng, để đảm bảo khả năng tổng quát hóa kết quả của chúng tôi, chúng tôi mở rộng phân tích sang các họ mô hình LLaMA, Falcon, và T5. Trong mỗi trường hợp này, một mẫu nhất quán xuất hiện: hoặc hiệu suất nhiệm vụ có thể dự đoán được dựa trên hiệu suất mô hình nhỏ hơn, hoặc hiệu suất dưới đường cơ sở. Tổng thể, phân tích của chúng tôi chỉ ra rằng cài đặt thí nghiệm của chúng tôi không ảnh hưởng tiêu cực đến khả năng xác định khả năng nổi lên và những phát hiện của chúng tôi có thể tổng quát hóa trên các họ mô hình khác nhau.

4 Điều chỉnh hướng dẫn như học trong ngữ cảnh ngầm định
Hiệu suất đáng chú ý của các mô hình được điều chỉnh hướng dẫn không thể được quy hoàn toàn cho mục tiêu huấn luyện trước của chúng, là dự đoán token có khả năng xảy ra nhất tiếp theo. Quan sát này đã dẫn đến giả thuyết rằng các mô hình có được khả năng ngôn ngữ chức năng nổi lên, chẳng hạn như lý luận (Wei et al., 2022c). Tuy nhiên, LLMs thể hiện một số hạn chế mâu thuẫn với quan điểm này: cụ thể là độ nhạy cảm được biết đến của chúng với các biến thể lời nhắc nhỏ và xu hướng ảo giác của chúng. Điều này dẫn chúng tôi đến giả thuyết rằng cơ chế chính làm nền tảng cho khả năng của các mô hình được điều chỉnh hướng dẫn thực tế có thể là một hình thức ICL gián tiếp, mà chúng tôi gọi là 'học trong ngữ cảnh ngầm định'. Phần này trình bày kết quả thí nghiệm nhằm phân biệt xem đây có phải là giải thích hợp lý hơn làm nền tảng cho hiệu suất của LLMs được điều chỉnh hướng dẫn hay không.

Đánh giá của chúng tôi trong phần này tập trung vào khả năng giải quyết nhiệm vụ thay vì hiệu suất. Điều này là do sự biến đổi (đôi khi rộng) trong số lượng tham số, kiến trúc, và dữ liệu huấn luyện trước của các mô hình chúng tôi so sánh sẽ nhất thiết có nghĩa là hiệu suất có thể khác nhau trên các mô hình. Tuy nhiên, đánh giá khả năng giải quyết nhiệm vụ cung cấp cái nhìn sâu sắc rõ ràng hơn về khả năng nổi lên trong các mô hình. Chúng tôi sử dụng độ chính xác BERTScore được giới thiệu trước đây cho tất cả các kịch bản và đánh giá các mô hình trên cùng 22 nhiệm vụ được chọn trước đây được nêu trong Bảng 2. Trong thiết lập này, không giống như thiết lập trước đó, chúng tôi chỉ sử dụng các mô hình không được điều chỉnh hướng dẫn trong cài đặt mà chúng tôi cung cấp các ví dụ trong ngữ cảnh (few-shot), do đó loại bỏ lo ngại về sự hiểu biết các yêu cầu nhiệm vụ của các mô hình.

4.1 Phân tích so sánh các nhiệm vụ ban đầu
Trong việc phân biệt giải thích hợp lý hơn làm nền tảng cho hiệu suất của LLMs được điều chỉnh hướng dẫn, các thí nghiệm của chúng tôi được thiết kế để mang lại kết quả khác nhau dựa trên việc liệu các mô hình thể hiện khả năng ngôn ngữ chức năng hay dựa chủ yếu vào ICL.

Cụ thể, chúng tôi rút ra so sánh giữa các nhiệm vụ mà GPT-J (không được điều chỉnh hướng dẫn, 6.7B) có thể giải quyết thành công trong cài đặt few-shot, và những nhiệm vụ có thể được giải quyết bởi Flan-T5-large (được điều chỉnh hướng dẫn, 770M) trong cài đặt zero-shot. Lựa chọn các mô hình này cũng dựa trên quan sát rằng không có thay đổi trong hiệu suất của mô hình giữa cài đặt zero-shot và few-shot cho Flan-T5-large, cho thấy nó quá nhỏ để ICL rõ ràng. Mặt khác, chúng tôi quan sát rằng có sự tăng cường hiệu suất trên các nhiệm vụ trong cài đặt few-shot cho GPT-J, cho thấy nó có khả năng ICL. Lưu ý rằng lựa chọn mô hình của chúng tôi đảm bảo rằng mô hình chúng tôi sử dụng để kiểm tra nhiệm vụ nào có thể được giải quyết bằng ICL không được điều chỉnh hướng dẫn, và mô hình được điều chỉnh hướng dẫn được kiểm tra không có ví dụ trong ngữ cảnh và cũng không thể truy cập rõ ràng ICL. Nếu điều chỉnh hướng dẫn dẫn đến các mô hình có khả năng về cái gì đó khác biệt cơ bản so với ICL (ví dụ, khả năng ngôn ngữ chức năng), điều này sẽ dẫn đến không có sự chồng chéo đáng kể trong tập hợp các nhiệm vụ có thể giải quyết chỉ thông qua điều chỉnh hướng dẫn và tập hợp các nhiệm vụ có thể giải quyết chỉ thông qua ICL. So sánh này được trình bày trong Hình 2. Chúng tôi loại trừ Modified arithmetic khỏi phân tích này, vì nhiệm vụ được xây dựng theo cách yêu cầu sử dụng các minh họa trong ngữ cảnh.

Lưu ý sự khác biệt đáng kể giữa hai mô hình chúng tôi sử dụng: Flan-T5-large là mô hình mã hóa-giải mã và GPT-J là mô hình chỉ giải mã. Ngoài ra, chúng được huấn luyện trên các tập dữ liệu huấn luyện trước rất khác nhau, một được điều chỉnh hướng dẫn trong khi cái khác thì không, và chúng có số lượng tham số rất khác nhau. Bất chấp những khác biệt cơ bản này, có sự chồng chéo đáng kể trong cả các nhiệm vụ mà hai mô hình thể hiện hiệu suất trên đường cơ sở, cũng như sự chồng chéo trong điểm hiệu suất chính chúng. Sự chồng chéo này trong kết quả nhấn mạnh một lập luận thuyết phục – có khả năng hơn rằng điều chỉnh hướng dẫn phục vụ như một cơ chế cho phép các mô hình khai thác khả năng trong ngữ cảnh hiệu quả hơn, thay vì các mô hình có khả năng lý luận nổi lên. Có chính xác năm trong số 21 nhiệm vụ chúng tôi kiểm tra trong đó một mô hình thực hiện đáng kể trên đường cơ sở ngẫu nhiên trong khi cái khác thì không. Thực sự, một số trường hợp được mong đợi: trong trường hợp Hindu knowledge, là nhiệm vụ dựa trên gọi lại, GPT-J, lớn hơn Flan-T5-large, có lợi thế và thực hiện tốt hơn. Tương tự, bản chất có tính hướng dẫn cao của Codenames khiến nó đặc biệt thách thức đối với các mô hình không được điều chỉnh hướng dẫn. Trong số ba nhiệm vụ còn lại, GPT-J thực hiện tốt hơn chỉ đạt được cải thiện 5% trên Analytical entailment, là phân loại nhị phân. Điều này để lại chúng tôi chỉ với Logical deduction, nơi Flan-T5-large hưởng lợi ở một mức độ nào đó từ bản chất hướng dẫn của các câu hỏi, và Implicatures, nơi GPT-J đạt độ chính xác 59%.

4.2 Khả năng tổng quát hóa
Để đánh giá xem kết quả của chúng tôi có tổng quát hóa cho sự gia tăng thêm về quy mô mô hình và dữ liệu điều chỉnh hướng dẫn hay không, chúng tôi so sánh các nhiệm vụ có thể được giải quyết hiệu quả bởi Flan-T5-large với những nhiệm vụ được giải quyết bởi các phiên bản được điều chỉnh hướng dẫn của các mô hình GPT lớn nhất, tức là text-davinci-001 và text-davinci-003 (được huấn luyện thêm mở rộng trên mã chương trình). Quan trọng cần lưu ý rằng những mô hình này có hơn 200 lần số lượng tham số có trong Flan-T5-large. Chúng tôi thực hiện so sánh này trong cài đặt zero-shot, do đó cho phép chúng tôi so sánh khả năng tuân theo hướng dẫn của những mô hình này mà không kích hoạt khả năng ICL của chúng, mà chúng tôi biết tăng đáng kể theo quy mô.

So sánh này cho phép chúng tôi trả lời các câu hỏi sau: a) Quy mô tăng có ảnh hưởng lớn đến các nhiệm vụ mà mô hình có thể thực hiện trên đường cơ sở ngẫu nhiên không, và b) Điều chỉnh hướng dẫn tăng cường, bao gồm việc kết hợp mã chương trình như đã thấy trong text-davinci-003, có cung cấp lợi thế trong việc có thể thực hiện trên đường cơ sở trên các nhiệm vụ không? Bằng cách giới hạn chúng tôi trong cài đặt zero-shot, chúng tôi đảm bảo rằng kết quả của chúng tôi không bị ảnh hưởng bởi khả năng trong ngữ cảnh, mà chúng tôi biết tăng đáng kể theo quy mô. Kết quả của chúng tôi chỉ ra rằng không quy mô hay việc bao gồm mã chương trình trong điều chỉnh hướng dẫn thay đổi đáng kể khả năng giải quyết nhiệm vụ của mô hình. Có sự chồng chéo đáng kể trong các nhiệm vụ mà Flan-T5-large thực hiện trên đường cơ sở và những nhiệm vụ mà text-davinci-001 và text-davinci-003 làm được: 16 trong số 22 nhiệm vụ chúng tôi thí nghiệm cho thấy sự tương đồng này. Sự chồng chéo này, và trong một số trường hợp hiệu suất tương đối trên các mô hình đa dạng này, gợi ý rằng hiệu quả của điều chỉnh hướng dẫn là nhất quán bất kể quy mô mô hình hoặc bản chất của các tập dữ liệu điều chỉnh, trong trường hợp không có ICL rõ ràng. Trong số các nhiệm vụ không chồng chéo, các nhiệm vụ dựa trên gọi lại nhất định được xử lý tốt hơn bởi các mô hình GPT lớn hơn do khả năng gọi lại tốt hơn của chúng. Những kết quả này, được minh họa trong Hình 5, Phụ lục D, xác nhận rằng giả thuyết của chúng tôi, cụ thể là 'học trong ngữ cảnh ngầm định' có khả năng là cơ chế chính trong LLMs được điều chỉnh hướng dẫn, và nó có thể tổng quát hóa trên các quy mô mô hình và các tập dữ liệu điều chỉnh hướng dẫn khác nhau. Điều này cũng gợi ý rằng việc mở rộng quy mô thêm có thể sẽ không thay đổi xu hướng này.

4.3 Nền tảng lý thuyết mới
Dựa trên quan sát của chúng tôi về khả năng và hạn chế của LLMs, chúng tôi đề xuất một lý thuyết thay thế mới giải thích tại sao điều chỉnh hướng dẫn giúp các mô hình thực hiện tốt hơn: chúng tôi đề xuất rằng điều chỉnh hướng dẫn cho phép các mô hình ánh xạ hướng dẫn đến hình thức cần thiết cho ICL, do đó cho phép các mô hình được điều chỉnh hướng dẫn giải quyết các nhiệm vụ sử dụng một số hình thức ICL ngầm định. Quan trọng là, trong quá trình này, các mô hình có thể trực tiếp sử dụng cùng cơ chế cơ bản giúp ICL trở nên khả thi, chỉ theo cách khác so với khi mô hình rõ ràng sử dụng ICL từ các ví dụ được cung cấp trong lời nhắc. Chúng tôi gọi việc sử dụng ICL này là học trong ngữ cảnh 'ngầm định'. Thực hiện ánh xạ như vậy sẽ tương đối đơn giản cho một mô hình rất lớn, đặc biệt là với định dạng nhiệm vụ này phù hợp chặt chẽ với quá trình huấn luyện được thực hiện trong điều chỉnh hướng dẫn. Điều tra bản chất chính xác của cơ chế này được để lại cho công việc tương lai.

5 Công trình liên quan
Khả năng nổi lên Khả năng nổi lên lần đầu tiên được định nghĩa là khả năng không có mặt trong các mô hình nhỏ hơn nhưng có mặt trong các mô hình lớn hơn (Wei et al., 2022b). Từ việc xem xét tài liệu trước đây về LLMs bao gồm GPT-3, PaLM (Chowdhery et al., 2023), Chinchilla (Hoffmann et al., 2022), Gopher (Rae et al., 2021) và LaMDA (Thoppilan et al., 2022), Wei et al. (2022b) đã xác định tổng cộng 67 khả năng nổi lên dựa trên hiệu suất trên ngẫu nhiên của LLMs trên các nhiệm vụ được thiết kế để kiểm tra những khả năng đó từ tập dữ liệu BIG-bench (Srivastava et al., 2023), và Benchmark hiểu ngôn ngữ đa nhiệm vụ lớn (Hendrycks et al., 2020). Các nghiên cứu tiếp theo đã khám phá các khả năng bổ sung nổi lên trong LLMs, chẳng hạn như Theory of Mind (Kosinski, 2023) và độ chệch nhận thức (Itzhak et al., 2023). Tuy nhiên, Schaeffer et al. (2023) trước đây đã đặt câu hỏi về sự tồn tại của khả năng nổi lên, lập luận rằng sự nổi lên có khả năng là hệ quả của các chỉ số đánh giá rời rạc thường được sử dụng để đánh giá LLMs. Một số (Wei et al., 2022b) lập luận chống lại điều này bằng cách chỉ ra rằng có các nhiệm vụ mà LLMs có thể thực hiện tốt trên đường cơ sở ngẫu nhiên nơi các mô hình nhỏ hơn chỉ có thể thực hiện dưới nó, gợi ý rằng những khả năng này vẫn nổi lên và không chỉ là hệ quả của các chỉ số đánh giá rời rạc. Tương tự, một số công trình (Biderman et al., 2023; Tefnik and Kadlčík, 2023; Wu et al., 2023; Zheng et al., 2023) đã khám phá mức độ mà bộ nhớ đóng vai trò trong khả năng của LLMs.

Học trong ngữ cảnh ICL là một mô hình học tập đã có được sự phổ biến lớn với sự ra đời của LLMs (Brown et al., 2020; Liu et al., 2023). ICL thường liên quan đến việc gợi ý LLM với các minh họa trong ngữ cảnh, và cung cấp giao diện có thể diễn giải hơn cũng như hiệu quả tính toán lớn hơn so với các phương pháp học tập trước đây (Dong et al., 2023; Zhou et al., 2023). Đáng chú ý, ICL đã chứng minh hiệu suất mạnh mẽ trên các nhiệm vụ ngôn ngữ tự nhiên khác nhau (Kojima et al., 2022; Lampinen et al., 2022; Wei et al., 2023). Về cơ sở lý thuyết cho ICL trong LLMs, công trình gần đây cho thấy nó có thể có điểm tương đồng với tinh chỉnh, ở chỗ nó có thể cho phép các mô hình "học" từ các ví dụ được trình bày trong lời nhắc của chúng (Dai et al., 2023). Tương tự, đã được chứng minh rằng ICL thực hiện gradient descent một cách ngầm định và xây dựng một hàm tại thời điểm suy luận trên các vấn đề hồi quy (Akyürek et al., 2023; Li et al., 2023; Zhang et al., 2023a), có thể liên quan đến meta-learning dựa trên gradient (von Oswald et al., 2023). Một dòng công trình cho thấy ICL được thúc đẩy bởi các phân phối của dữ liệu huấn luyện trước (Chan et al., 2022; Hahn and Goyal, 2023). Một số khám phá lý thuyết khác cố gắng giải thích ICL theo thuật ngữ suy luận Bayes (Xie et al., 2022; Li et al., 2023; Zhang et al., 2023b).

Theo hiểu biết tốt nhất của chúng tôi, không có đánh giá trước đây nào về khả năng nổi lên được tiến hành theo cách rõ ràng phân biệt giữa cài đặt ICL và điều chỉnh hướng dẫn và gợi ý trong cài đặt mà những khả năng này không được kích hoạt.

6 Kết luận và ý nghĩa
Chúng tôi bắt đầu với hai giả thuyết: a) Rằng sự nổi lên của tất cả các khả năng ngôn ngữ chức năng đã quan sát trước đây là hệ quả của ICL, và b) Rằng các khả năng thể hiện bản thân trong LLMs được điều chỉnh hướng dẫn có khả năng chỉ ra điều chỉnh hướng dẫn dẫn đến ICL ngầm định, thay vì sự nổi lên của khả năng ngôn ngữ chức năng. Kết quả của chúng tôi đã xác nhận cả hai giả thuyết này.

Sự phân biệt giữa khả năng tuân theo hướng dẫn và khả năng vốn có để giải quyết vấn đề là một sự phân biệt tinh tế nhưng quan trọng, và có ý nghĩa đối với các phương pháp được sử dụng trong việc sử dụng LLMs và các vấn đề chúng được giao nhiệm vụ giải quyết. Việc đơn giản tuân theo hướng dẫn mà không áp dụng khả năng lý luận tạo ra đầu ra nhất quán với hướng dẫn, nhưng có thể không có ý nghĩa trên cơ sở logic hoặc thường thức. Điều này được phản ánh trong hiện tượng nổi tiếng của 'ảo giác', trong đó LLM tạo ra đầu ra trôi chảy, nhưng không chính xác về mặt thực tế (Bang et al., 2023; Thorp, 2023) Khả năng tuân theo hướng dẫn không ngụ ý có khả năng lý luận, và quan trọng hơn, nó không ngụ ý khả năng của các khả năng tiềm ẩn, có thể nguy hiểm. Ngoài ra, những quan sát này ngụ ý rằng những phát hiện của chúng tôi đúng cho bất kỳ mô hình nào thể hiện xu hướng ảo giác hoặc yêu cầu kỹ thuật lời nhắc, bao gồm những mô hình có độ phức tạp lớn hơn, bất kể quy mô hoặc số lượng phương thức, chẳng hạn như GPT-4. Bằng cách đóng góp cho sự hiểu biết sâu sắc hơn về khả năng và hạn chế của những mô hình này, chúng tôi giúp làm sáng tỏ LLMs, giảm bớt lo ngại an toàn liên quan và đặt ra khung cho việc sử dụng hiệu quả hơn của chúng.

Hạn chế
Mặc dù chúng tôi thí nghiệm trên một lượng lớn kích thước mô hình trên các kiến trúc khác nhau (ví dụ, T5, GPT, Falcon, LLaMA), chúng tôi không thể đảm bảo khớp chính xác số lượng tham số trên các kiến trúc khác nhau. Điều này là do sự biến đổi trong các bản phát hành có sẵn công khai của những mô hình này. Trong công trình này, chúng tôi đã sử dụng tất cả các mô hình ở số lượng tham số có sẵn. Tuy nhiên, một lựa chọn thay thế khác sẽ là tiến hành huấn luyện trước để đảm bảo số lượng tham số bằng nhau và dữ liệu huấn luyện trước có thể so sánh, mặc dù điều này sẽ liên quan đến đầu tư tính toán đáng kể. Trong tất cả các nhiệm vụ, có rủi ro rò rỉ dữ liệu, đặc biệt đối với LLMs có tập dữ liệu huấn luyện không được biết công khai. Trong công trình này, chúng tôi giả định rằng rò rỉ dữ liệu đã không xảy ra ngoài những gì được báo cáo trong các xuất bản chính thức cho các mô hình cụ thể (ví dụ, BIG-bench cho GPT-4). Do đó, chúng tôi không coi rò rỉ dữ liệu là yếu tố khi chúng tôi coi một nhiệm vụ là 'dựa trên bộ nhớ', mặc dù, trong thực tế, sự hiện diện của rò rỉ dữ liệu có thể có tác động gây chệch trên hiệu suất mô hình. Các thí nghiệm của chúng tôi giới hạn ở các nhiệm vụ tiếng Anh. Điều này chủ yếu là hệ quả của công trình trước đây về khả năng nổi lên và về hạn chế ngân sách tính toán để chạy thí nghiệm trên các ngôn ngữ khác. Chúng tôi dự định tập trung công việc tương lai vào các tập dữ liệu bao gồm các ngôn ngữ khác bao gồm các ngôn ngữ ít tài nguyên.

Cân nhắc đạo đức
Công trình của chúng tôi không ngụ ý rằng LLMs hoàn toàn không có tiềm năng gây hại. Bằng cách tận dụng khả năng ngôn ngữ tinh vi của LLMs, các tác nhân độc hại có thể chế tạo các bài báo tin tức giả hoặc thông điệp lừa đảo có tính thuyết phục cao và được cá nhân hóa, có thể ngày càng khó phân biệt với các thông điệp hợp pháp. Sự dễ dàng và hiệu quả mà LLMs có thể được sử dụng cho những mục đích này làm nổi bật nhu cầu về các cơ chế phát hiện, cùng với hướng dẫn đạo đức để giảm thiểu rủi ro và bảo vệ cá nhân và các quá trình dân chủ. Tương tự, việc xác định rằng khả năng LLM không phải là tiền đề cho mối đe dọa hiện hữu do AI thúc đẩy không loại bỏ nhu cầu sự cảnh giác liên tục trong nghiên cứu an toàn AI. Những phát hiện của chúng tôi mang lại cơ hội duy nhất để ưu tiên các khía cạnh cấp bách nhất của an toàn LLM đồng thời khám phá các con đường nghiên cứu vượt ra ngoài việc đơn giản mở rộng quy mô.

Chúng tôi nhận ra rằng cuộc trò chuyện về khả năng và hạn chế của LLMs đóng vai trò quan trọng trong diễn ngôn xã hội rộng lớn hơn về AI. Điều này nhấn mạnh tầm quan trọng của sự cân nhắc chu đáo và mức độ quan tâm cao trong tất cả các nỗ lực nghiên cứu và xuất bản liên quan.

Lời cảm ơn
Công trình này đã được tài trợ bởi LOEWE Distinguished Chair "Ubiquitous Knowledge Processing", sáng kiến LOEWE, Hesse, Đức (Số hiệu tài trợ: LOEWE/4a//519/05/00.002(0002)/81). Công trình nghiên cứu này đã được tài trợ bởi Bộ Giáo dục và Nghiên cứu Liên bang Đức và Bộ Giáo dục Đại học, Nghiên cứu, Khoa học và Nghệ thuật Hessen trong khuôn khổ hỗ trợ chung của họ cho Trung tâm Nghiên cứu Quốc gia về An ninh mạng Ứng dụng ATHENE. Chúng tôi cũng muốn cảm ơn tài trợ Nghiên cứu Sự nghiệp Sớm từ Đại học Bath. Công trình này sẽ không thể thực hiện được nếu không có tài trợ hào phóng từ quỹ Nghiên cứu Học thuật Mô hình Nền tảng Tăng tốc Microsoft, cho phép chúng tôi thí nghiệm mở rộng với dịch vụ Azure OpenAI.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo dài được dịch theo cùng cách]

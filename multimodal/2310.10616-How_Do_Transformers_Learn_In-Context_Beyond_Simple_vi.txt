# Làm thế nào để Transformer học trong bối cảnh vượt ra ngoài các hàm đơn giản? Một nghiên cứu tình huống về học tập với biểu diễn

Tianyu Guo∗ ∗Wei Hu† †Song Mei∗Huan Wang‡ ‡Caiming Xiong‡
Silvio Savarese‡Yu Bai‡
17 tháng 10, 2023

Tóm tắt

Trong khi các mô hình ngôn ngữ lớn dựa trên kiến trúc transformer đã thể hiện khả năng học trong bối cảnh (ICL) đáng chú ý, việc hiểu về những khả năng này vẫn đang trong giai đoạn sơ khai, nơi lý thuyết hiện có và hiểu biết về cơ chế chủ yếu tập trung vào các tình huống đơn giản như học các lớp hàm đơn giản. Bài báo này thực hiện những bước đầu tiên để hiểu ICL trong các tình huống phức tạp hơn, bằng cách nghiên cứu học tập với biểu diễn. Cụ thể, chúng tôi xây dựng các bài toán học trong bối cảnh tổng hợp với cấu trúc hợp thành, nơi nhãn phụ thuộc vào đầu vào thông qua một hàm biểu diễn có thể phức tạp nhưng cố định, được kết hợp với một hàm tuyến tính khác nhau trong mỗi trường hợp. Theo cách xây dựng, thuật toán ICL tối ưu đầu tiên biến đổi các đầu vào bằng hàm biểu diễn, sau đó thực hiện ICL tuyến tính trên tập dữ liệu đã được biến đổi. Chúng tôi chứng minh về mặt lý thuyết sự tồn tại của các transformer có thể thực hiện gần đúng các thuật toán như vậy với độ sâu và kích thước vừa phải. Về mặt thực nghiệm, chúng tôi thấy rằng các transformer được huấn luyện liên tục đạt được hiệu suất ICL gần tối ưu trong cài đặt này, và thể hiện sự phân tích mong muốn nơi các lớp thấp hơn biến đổi tập dữ liệu và các lớp cao hơn thực hiện ICL tuyến tính. Thông qua việc thăm dò rộng rãi và một thí nghiệm dán mới, chúng tôi tiếp tục tiết lộ một số cơ chế trong các transformer được huấn luyện, chẳng hạn như hành vi sao chép cụ thể trên cả đầu vào và biểu diễn, khả năng ICL tuyến tính của chỉ riêng các lớp trên, và một cơ chế chọn biểu diễn sau ICL trong cài đặt hỗn hợp khó hơn. Những cơ chế quan sát được này phù hợp tốt với lý thuyết của chúng tôi và có thể làm sáng tỏ cách transformer thực hiện ICL trong các tình huống thực tế hơn.

1 Giới thiệu

Các mô hình ngôn ngữ lớn dựa trên kiến trúc transformer đã thể hiện khả năng học trong bối cảnh (ICL) đáng chú ý (Brown et al., 2020), nơi chúng có thể giải quyết các nhiệm vụ mới gặp phải khi được cung cấp chỉ vài ví dụ huấn luyện, mà không cần cập nhật tham số nào cho mô hình. Các mô hình hiện đại gần đây còn đạt được hiệu suất ấn tượng trong bối cảnh trên các nhiệm vụ thế giới thực tinh vi (OpenAI, 2023; Bubeck et al., 2023; Touvron et al., 2023). Những khả năng đáng chú ý như vậy đòi hỏi sự hiểu biết tốt hơn, mà các nghiên cứu gần đây tiếp cận từ nhiều góc độ khác nhau (Xie et al., 2021; Chan et al., 2022; Razeghi et al., 2022; Min et al., 2022; Olsson et al., 2022; Wei et al., 2023).

Một làn sóng nghiên cứu gần đây điều tra ICL trong một cài đặt có thể xử lý được về mặt lý thuyết nơi ngữ cảnh bao gồm các cặp (đầu vào, nhãn) có giá trị thực được tạo ra từ một lớp hàm nhất định. Họ thấy rằng transformer có thể học nhiều lớp hàm trong ngữ cảnh, chẳng hạn như hàm tuyến tính, mạng nơ-ron nông và cây quyết định (Garg et al., 2022; Akyürek et al., 2022; Li et al., 2023a), và các nghiên cứu thêm cung cấp lý thuyết biện minh về cách transformer có thể thực hiện và học các thuật toán học tập khác nhau trong ngữ cảnh như hồi quy ridge (Akyürek et al., 2022), gradient descent (von Oswald et al., 2022; Dai et al., 2022; Zhang et al., 2023a; Ahn et al., 2023), lựa chọn thuật toán (Bai et al., 2023), và trung bình mô hình Bayes (Zhang et al., 2023b), để kể một vài tên. Mặc dù có tiến bộ, một thiếu sót của hướng nghiên cứu này là các cài đặt và kết quả có thể không thực sự giống với ICL trong các tình huống thế giới thực—Ví dụ, ICL trong các lớp hàm tuyến tính được hiểu rõ trong lý thuyết với các cấu trúc transformer hiệu quả (Bai et al., 2023), và transformer thực sự học chúng tốt về mặt thực nghiệm (Garg et al., 2022); tuy nhiên, những hàm tuyến tính như vậy trong đầu vào thô có thể không nắm bắt được các tình huống thế giới thực nơi kiến thức trước thường có thể hỗ trợ học tập.

Bài báo này thực hiện những bước đầu tiên để giải quyết vấn đề này bằng cách nghiên cứu ICL trong cài đặt học tập với biểu diễn, một cài đặt phức tạp và có lẽ thực tế hơn so với các cài đặt hiện có. Chúng tôi xây dựng các nhiệm vụ ICL tổng hợp nơi nhãn phụ thuộc vào đầu vào thông qua một hàm biểu diễn cố định được kết hợp với một hàm tuyến tính thay đổi. Chúng tôi cụ thể hóa biểu diễn như mạng nơ-ron nông (MLP), và xem xét cả cài đặt học có giám sát (với các cặp đầu vào-nhãn) và cài đặt hệ thống động (chỉ với đầu vào) cho dữ liệu trong ngữ cảnh. Các đóng góp của chúng tôi có thể được tóm tắt như sau.

• Về mặt lý thuyết, chúng tôi xây dựng các transformer thực hiện hồi quy ridge trong ngữ cảnh trên các biểu diễn (bao gồm thuật toán tối ưu Bayes) cho cả hai cài đặt học tập (Phần 4). Các cấu trúc transformer của chúng tôi có kích thước vừa phải, và có thể dự đoán tại mỗi token sử dụng kiến trúc decoder, (một cách không tầm thường) tổng quát hóa các cấu trúc hiệu quả hiện có chỉ dự đoán tại token cuối cùng sử dụng kiến trúc encoder.

• Về mặt thực nghiệm, chúng tôi thấy rằng các transformer nhỏ được huấn luyện liên tục đạt được rủi ro ICL gần tối ưu trong cả hai cài đặt học tập (Phần 5 & Hình 1b).

• Sử dụng các kỹ thuật thăm dò tuyến tính, chúng tôi xác định bằng chứng cho các cơ chế khác nhau trong các transformer được huấn luyện. Phát hiện cấp cao của chúng tôi là các lớp thấp hơn biến đổi dữ liệu bằng biểu diễn và chuẩn bị nó thành một định dạng nhất định, và các lớp cao hơn thực hiện ICL tuyến tính trên dữ liệu đã được biến đổi (Hình 1c), với thường có sự phân tích rõ ràng giữa hai mô-đun này, phù hợp với lý thuyết của chúng tôi. Xem Hình 1a để minh họa bằng hình ảnh.

• Chúng tôi tiếp tục quan sát một số hành vi cấp thấp hơn sử dụng các thăm dò tuyến tính phù hợp tốt với các cấu trúc lý thuyết của chúng tôi (và hiện có), chẳng hạn như sao chép (cả đầu vào và biểu diễn) nơi token nào đang được sao chép có thể được xác định chính xác (Phần 5.2), và một cơ chế chọn biểu diễn sau ICL trong cài đặt khó hơn (Phần 5.1.1 & Phụ lục E).

• Chúng tôi thực hiện một thí nghiệm dán mới và thấy rằng các lớp trên trong transformer được huấn luyện có thể thực hiện ICL tuyến tính gần tối ưu trong (gần) cô lập (Phần 5.1), cung cấp bằng chứng mạnh mẽ hơn rằng chỉ mô-đun trên có thể là một người học ICL tuyến tính mạnh mẽ.

2 Nghiên cứu liên quan

Học trong bối cảnh Các khả năng học trong bối cảnh (ICL) của các transformer được huấn luyện trước đã nhận được sự chú ý đáng kể kể từ khi được chứng minh lần đầu với GPT-3 (Brown et al., 2020). Các nghiên cứu thực nghiệm tiếp theo đã điều tra các khả năng và hạn chế của ICL trong các mô hình ngôn ngữ lớn (Liu et al., 2021; Min et al., 2021a,b; Lu et al., 2021; Zhao et al., 2021; Rubin et al., 2021; Razeghi et al., 2022; Elhage et al., 2021; Kirsch et al., 2022; Wei et al., 2023).

Một hướng nghiên cứu gần đây điều tra tại sao và làm thế nào các transformer được huấn luyện trước thực hiện ICL từ góc độ lý thuyết (Garg et al., 2022; Li et al., 2023a; von Oswald et al., 2022; Akyürek et al., 2022; Xie et al., 2021; Bai et al., 2023; Zhang et al., 2023a,b; Ahn et al., 2023; Raventós et al., 2023). Đặc biệt, Xie et al. (2021) đã đề xuất một khung suy luận Bayes giải thích ICL. Garg et al. (2022) chỉ ra rằng transformer có thể được huấn luyện từ đầu cho ICL của các lớp hàm đơn giản. Các nghiên cứu khác thấy rằng transformer có thể thực hiện ICL thông qua gradient descent trong ngữ cảnh (von Oswald et al., 2022; Akyürek et al., 2022) và lựa chọn thuật toán trong ngữ cảnh (Bai et al., 2023). Zhang et al. (2023a) nghiên cứu động lực học huấn luyện của một lớp attention đơn trên các nhiệm vụ ICL tuyến tính. Li et al. (2023b) sử dụng khung ICL để giải thích lý luận chuỗi suy nghĩ (Wei et al., 2022). Nghiên cứu của chúng tôi xây dựng và mở rộng công việc của (Garg et al., 2022; Akyürek et al., 2022; von Oswald et al., 2022; Bai et al., 2023), nơi chúng tôi nghiên cứu cài đặt thách thức hơn của ICL với một hàm biểu diễn, và cũng cung cấp các cấu trúc ICL hiệu quả mới để dự đoán tại mọi token sử dụng transformer decoder, trái ngược với việc chỉ dự đoán tại token cuối cùng trong hầu hết các nghiên cứu này.

Học trong trọng số so với học trong bối cảnh Nghiên cứu gần đây đã điều tra khi nào transformer học một ánh xạ đầu vào-nhãn cố định so với khi nào chúng thực hiện ICL (Chan et al., 2022; Wei et al., 2023; Bietti et al., 2023). Chan et al. (2022) gọi việc học một ánh xạ đầu vào-nhãn cố định từ dữ liệu huấn luyện trước là "học trong trọng số" (IWL), trái ngược với ICL. Cài đặt bài toán của chúng tôi giả định rằng dữ liệu huấn luyện trước thừa nhận một hàm biểu diễn cố định, cái mà nên được học bởi IWL. Từ góc nhìn này, không giống như các nghiên cứu hiện có nơi IWL và ICL thường được coi là các cơ chế cạnh tranh, chúng tôi nghiên cứu một mô hình trong đó IWL (tính toán biểu diễn cố định bằng trọng số transformer) và ICL (học hàm tuyến tính thay đổi trong ngữ cảnh) xảy ra đồng thời.

Hiểu biết cơ chế và kỹ thuật thăm dò Một hướng nghiên cứu tập trung vào việc phát triển các kỹ thuật để hiểu các cơ chế của mạng nơ-ron, đặc biệt là transformer (Alain and Bengio, 2016; Geiger et al., 2021; Meng et al., 2022; von Oswald et al., 2022; Akyürek et al., 2022; Wang et al., 2022; Räuker et al., 2023). Chúng tôi áp dụng kỹ thuật thăm dò tuyến tính của (Alain and Bengio, 2016) theo cách từng token để giải thích các cơ chế ICL của transformer. Ngoài thăm dò, việc giải thích cơ chế thuyết phục hơn có thể yêu cầu các phương pháp tiên tiến như can thiệp nhân quả (Geiger et al., 2021; Vig et al., 2020; Wang et al., 2022); Thí nghiệm dán của chúng tôi có hương vị can thiệp tương tự ở chỗ chúng tôi cung cấp các chuỗi đầu vào (các trường hợp ICL) từ một phân phối khác trực tiếp (thông qua một lớp nhúng có thể huấn luyện) đến mô-đun trên của transformer.

3 Sơ bộ

Transformer Chúng tôi xem xét các hàm từ chuỗi đến chuỗi được áp dụng cho N vector đầu vào {hi}N i=1 ⊂ RDhid trong Dhid chiều, mà chúng tôi viết gọn gàng như một ma trận đầu vào H = [h1, . . . , hN] ∈ RDhid×N, nơi mỗi hi là một cột của H (cũng là một token).

Chúng tôi sử dụng transformer chỉ decoder (tự hồi quy) L lớp tiêu chuẩn, bao gồm L khối liên tiếp mỗi khối có một lớp self-attention được che (từ đây gọi là "lớp attention") tiếp theo là một lớp MLP. Mỗi lớp attention tính toán

Attn θ(H) := H + ∑M m=1 (VmH) × σ MSK ⊙ ((QmH)⊤(KmH)) ∈ RD×N,

nơi θ = {(Qm, Km, Vm) ⊂ RDhid×Dhid}m∈[M] là các ma trận (query, key, value), M là số đầu, MSK ∈ RN×N là ma trận mặt nạ decoder với MSK ij = 1{i ≤ j}, và σ là hàm kích hoạt thường được chọn là softmax (theo cột): [σ(A)]:,j = softmax(aj) ∈ RN cho A = [a1, . . . , aN] ∈ RN×N. Mỗi lớp MLP tính toán

MLP W1,W2(H) := H + W2σ(W1H),

nơi W{1,2} ∈ RDhid×Dhid là các ma trận trọng số, và σ(t) = max{t, 0} là kích hoạt ReLU. Chúng tôi sử dụng TF để ký hiệu một transformer, và thường sử dụng H̃ = TF(H) để ký hiệu đầu ra của nó trên H.

Học trong bối cảnh Chúng tôi xem xét học trong bối cảnh (ICL) trên các bài toán hồi quy, nơi mỗi trường hợp ICL được chỉ định bởi một tập dữ liệu D = {(xi, yi)}i∈[N] iid ∼ P, với (xi, yi) ∈ Rd × R, và mô hình được yêu cầu dự đoán chính xác yi cho tất cả các quan sát quá khứ Di−1 := {(xj, yj)}j≤i−1 và đầu vào kiểm tra xi. Khó khăn chính của ICL so với học có giám sát tiêu chuẩn là mỗi trường hợp D(j) nói chung được rút từ một phân phối dữ liệu khác nhau P = P(j) (ví dụ, một mô hình tuyến tính với w(j) ⋆ ∈ Rd mới). Dự đoán chính xác đòi hỏi học P trong ngữ cảnh từ các quan sát quá khứ Di−1 (tức là ngữ cảnh); chỉ ghi nhớ bất kỳ P(j) cố định nào là không đủ.

Chúng tôi xem xét sử dụng transformer để thực hiện ICL, nơi chúng tôi cung cấp một chuỗi có độ dài 2N vào transformer TF sử dụng định dạng đầu vào sau:

H = [h1, . . . , h2N] = [x1 0 ... xN 0; 0 y1 ... 0 yN; px 1 py 1 ... px N py N] ∈ RDhid×2N, (1)

nơi px i, py i ∈ RDhid−d−1 là các vector mã hóa vị trí cố định bao gồm các zero padding, tiếp theo là các entry khác không chứa thông tin về chỉ số vị trí i và chỉ báo là một x-token (1 trong px i, và 0 trong py i); xem (12) cho lựa chọn cụ thể của chúng tôi. Chúng tôi gọi mỗi token lẻ h2i−1 là x-token (cũng là xi-token), và mỗi token chẵn h2i là y-token (cũng là yi-token).

Sau khi thu được đầu ra transformer H̃ = TF(H), cho mỗi chỉ số i ∈ [N], chúng tôi trích xuất dự đoán ŷi từ token đầu ra tại vị trí xi: ŷi := (h̃x i)d+1. Cung cấp đầu vào (1) vào transformer đồng thời tính toán ŷi ← TF(x1, y1, . . . , xi−1, yi−1, xi) cho tất cả i ∈ [N].

Ngoài cài đặt trên, chúng tôi cũng xem xét cài đặt hệ thống động với D = {xi}i∈[N] nơi transformer dự đoán x̂i từ các đầu vào trước đó x≤i−1. Xem Phần 4.2 để biết chi tiết.

4 Học trong bối cảnh với biểu diễn

4.1 Học có giám sát với biểu diễn

Chúng tôi bắt đầu bằng cách xem xét ICL trên các bài toán hồi quy với biểu diễn, nơi nhãn phụ thuộc vào đầu vào thông qua các hàm tuyến tính của một hàm biểu diễn cố định. Chính thức, cho Φ⋆ : Rd → RD là một hàm biểu diễn cố định. Chúng tôi tạo ra mỗi phân phối dữ liệu trong ngữ cảnh P = Pw bằng cách lấy mẫu một hàm tuyến tính w ∼ N(0, τ2ID) từ một prior Gauss, và sau đó tạo ra trường hợp ICL D = {(xi, yi)}i∈[N] ∼ Pw bằng một mô hình tuyến tính trên Φ⋆ với hệ số w và mức nhiễu σ > 0:

yi = ⟨w, Φ⋆(xi)⟩ + σzi, xi iid ∼ Px, zi iid ∼ N(0, 1), i ∈ [N]. (2)

Chú ý rằng tất cả D đều chia sẻ cùng một biểu diễn Φ⋆, nhưng mỗi cái thừa nhận một hàm tuyến tính duy nhất w.

Hàm biểu diễn Φ⋆ về nguyên tắc có thể được chọn tùy ý. Như một lựa chọn chính tắc và linh hoạt cho cả lý thuyết và thí nghiệm của chúng tôi, chúng tôi chọn Φ⋆ là một MLP L lớp tiêu chuẩn:

Φ⋆(x) = σ⋆(B⋆ L σ⋆(B⋆ L−1 ⋯ σ⋆(B⋆ 1 x) ⋯)), B⋆ 1 ∈ RD×d, (B⋆ ℓ)L ℓ=2 ⊂ RD×D (3)

nơi D là chiều ẩn và đầu ra, và σ⋆ là hàm kích hoạt (được áp dụng từng entry) mà chúng tôi chọn là leaky ReLU σ⋆(t) = σρ(t) := max{t, ρt} với độ dốc ρ ∈ (0, 1).

Lý thuyết Vì Φ⋆ cố định và w thay đổi trong mô hình (2), theo cách xây dựng, một thuật toán ICL tốt nên tính toán các biểu diễn {Φ⋆(xi)}i và thực hiện ICL tuyến tính trên tập dữ liệu đã được biến đổi {(Φ⋆(xi), yi)}i để học w. Chúng tôi xem xét lớp ước lượng Φ⋆-ridge sau:

ŵΦ⋆,λ i := arg minw∈Rd 1/2(i−1) ∑i−1 j=1 (⟨w, Φ⋆(xj)⟩ − yj)2 + λ/2 ∥w∥2 2, (Φ⋆-Ridge)

và chúng tôi hiểu ŵΦ⋆,λ 1 := 0. Nói cách khác, ŵΦ⋆,λ i thực hiện hồi quy ridge trên tập dữ liệu đã được biến đổi {Φ(xj), yj}j≤i−1 cho tất cả i ∈ [N]. Bằng các tính toán tiêu chuẩn, bộ dự đoán tối ưu Bayes cho yi cho (Di−1, xi) chính xác là bộ dự đoán ridge ŷΦ⋆,λ i := ⟨ŵΦ⋆,λ i, Φ⋆(xi)⟩ tại λ = σ2/τ2.

Chúng tôi chỉ ra rằng tồn tại một transformer có thể thực hiện gần đúng (Φ⋆-Ridge) trong ngữ cảnh tại mọi token i ∈ [N]. Chứng minh có thể được tìm thấy trong Phụ lục B.

Định lý 1 (Transformer có thể thực hiện Φ⋆-Ridge). Cho bất kỳ hàm biểu diễn Φ⋆ có dạng (3), bất kỳ λ > 0, BΦ, Bw, By > 0, ε < BΦBw/2, cho κ := 1 + B2 Φ/λ, tồn tại một transformer TF với L + O(κ log(BΦBw/ε)) lớp, 5 đầu, Dhid = 2D + d + 10 sao cho điều sau đây đúng.

Cho bất kỳ tập dữ liệu D sao cho ∥Φ⋆(xi)∥2 ≤ BΦ, |yi| ≤ By và đầu vào tương ứng H ∈ RDhid×2N có định dạng (1), chúng ta có

(a) L + 2 lớp đầu tiên của TF biến đổi xi thành biểu diễn Φ⋆(xi) tại mỗi x token, và sao chép chúng vào y token tiếp theo:

TF(1:L+2)(H) = [Φ⋆(x1) Φ⋆(x1) ... Φ⋆(xN) Φ⋆(xN); 0 y1 ... 0 yN; p̃x 1 p̃y 1 ... p̃x N p̃y N], (4)

nơi p̃x i, p̃y i chỉ khác px i, py i ở chiều của zero padding.

(b) Cho mỗi chỉ số i ∈ [N], đầu ra transformer H̃ = TF(H) chứa dự đoán ŷi := [h̃2i−1]D+1 gần với bộ dự đoán (Φ⋆-Ridge): |ŷi − ⟨Φ⋆(xi), ŵΦ⋆,λ i⟩| ≤ ε.

Cấu trúc transformer trong Định lý 1 bao gồm hai "mô-đun": Các lớp thấp hơn tính toán các biểu diễn và chuẩn bị tập dữ liệu đã được biến đổi {(Φ⋆(xi), yi)}i thành dạng (4). Đặc biệt, mỗi Φ⋆(xi) xuất hiện cả trong x-token thứ i và cũng được sao chép vào y token tiếp theo. Các lớp cao hơn thực hiện ICL tuyến tính (hồi quy ridge) trên tập dữ liệu đã được biến đổi. Chúng tôi sẽ kiểm tra xem các cơ chế như vậy có phù hợp với transformer được huấn luyện trong thực tế hay không trong các thí nghiệm của chúng tôi (Phần 5.1).

Kỹ thuật chứng minh Chứng minh của Định lý 1 dựa trên (1) việc thực hiện MLP Φ⋆ bằng transformer (Bổ đề B.3), và (2) một cấu trúc hiệu quả của hồi quy ridge trong ngữ cảnh (Định lý B.5), theo hiểu biết của chúng tôi là cấu trúc hiệu quả đầu tiên để dự đoán tại mọi token sử dụng transformer decoder. Cái sau đòi hỏi một số kỹ thuật cấu trúc mới như một lớp sao chép (Bổ đề B.1), và một việc thực hiện hiệu quả của N thuật toán gradient descent trong ngữ cảnh song song tại tất cả các token đồng thời sử dụng transformer decoder (Mệnh đề B.4). Những điều này mở rộng các cấu trúc liên quan của von Oswald et al. (2022); Bai et al. (2023) chỉ xem xét dự đoán tại token cuối cùng sử dụng transformer encoder, và có thể có ý nghĩa độc lập.

Ngoài ra, các giới hạn về số lớp, đầu và Dhid trong Định lý 1 có thể ngụ ý một bảo đảm độ phức tạp mẫu cho (tiền) huấn luyện: Một transformer với rủi ro vượt trội ε̃ (trên cùng một phân phối trường hợp ICL) so với cái được xây dựng trong Định lý 1 có thể được tìm thấy trong Õ((L+κ)2(D+d)2ε̃−2) trường hợp huấn luyện, bằng phân tích tổng quát hóa của (Bai et al., 2023, Định lý 20). Chúng tôi nhận xét rằng các cấu trúc trong Định lý 1 & 2 chọn σ là ReLU được chuẩn hóa thay vì softmax, theo (Bai et al., 2023) và cộng hưởng với các nghiên cứu thực nghiệm gần đây (Wortsman et al., 2023).

4.2 Hệ thống động với biểu diễn

Như một biến thể của mô hình (2), chúng tôi thêm xem xét cài đặt hệ thống động (phi tuyến) với dữ liệu D = (x1, . . . , xN), nơi mỗi xi+1 phụ thuộc vào k đầu vào trước đó [xi−k+1; . . . ; xi] cho một số k ≥ 1 thông qua một hàm tuyến tính trên một hàm biểu diễn cố định Φ⋆. So với cài đặt học có giám sát trong Phần 4.1, cài đặt này giống hơn một số khía cạnh của ngôn ngữ tự nhiên, nơi token tiếp theo nói chung phụ thuộc vào một số token trước đó.

Chính thức, cho k ≥ 1 ký hiệu số token đầu vào mà token tiếp theo phụ thuộc vào, và Φ⋆ : Rkd → RD ký hiệu một hàm biểu diễn. Mỗi trường hợp ICL D = {xi}i∈[N] được tạo ra như sau: Đầu tiên lấy mẫu P = PW nơi W ∈ RD×d được lấy mẫu từ một prior Gauss: Wij iid ∼ N(0, τ2). Sau đó lấy mẫu đầu vào ban đầu x1 ∼ Px và cho

xi+1 = W⊤Φ⋆([xi−k+1; . . . ; xi]) + σzi, zi iid ∼ N(0, Id), i ∈ [N−1], (5)

nơi chúng tôi hiểu xj := 0d cho j ≤ 0. Chúng tôi chọn Φ⋆ là cùng MLP L lớp như trong (3), ngoại trừ ma trận trọng số đầu tiên có kích thước B⋆ 1 ∈ RD×kd để phù hợp với chiều của đầu vào mở rộng x̄i := [xi−k+1; . . . ; xi]. Chúng tôi nhận xét rằng (5) tổng quát hóa đáng kể cài đặt của Li et al. (2023a) chỉ xem xét hệ thống động tuyến tính (tương đương với Φ⋆ ≡ id), một nhiệm vụ có thể dễ dàng hơn nhiều cho transformer để học trong ngữ cảnh.

Vì xi hoạt động như cả đầu vào và nhãn trong mô hình (5), chúng tôi sử dụng định dạng đầu vào sau cho transformer:

H := [x1 ... xN; p1 ... pN] ∈ RDhid×N, (6)

nơi pi := [0Dhid−d−4; 1; i; i2; i3], và chúng tôi trích xuất dự đoán x̂i+1 từ token đầu ra thứ i.

Lý thuyết Tương tự như trên, chúng tôi xem xét bộ dự đoán ridge cho cài đặt hệ thống động

ŴΦ⋆,λ i := arg minW∈RD×d 1/2(i−1) ∑i−1 j=1 ∥W⊤Φ⋆(x̄j) − xj+1∥2 2 + λ/2 ∥W∥2 Fr. (Φ⋆-Ridge-Dyn)

Chúng tôi hiểu ŴΦ⋆,λ 0 := 0D×d, và cho ∥W∥2,∞ := maxj∈[d] ∥W:,j∥2 cho bất kỳ W ∈ RD×d. Một lần nữa, (Φ⋆-Ridge-Dyn) cho bộ dự đoán tối ưu Bayes (ŴΦ⋆,λ i)⊤Φ⋆(x̄i) tại λ = σ2/τ2.

Kết quả sau đây chỉ ra rằng (Φ⋆-Ridge-Dyn) cũng có thể được thực hiện hiệu quả bởi một transformer. Chứng minh có thể được tìm thấy trong Phụ lục C.2.

Định lý 2 (Transformer có thể thực hiện Φ⋆-Ridge cho hệ thống động). Cho cài đặt hệ thống động nơi hàm biểu diễn L lớp Φ⋆ : Rkd → RD có dạng (3), nhưng các cài đặt khác giống như Định lý 1, tồn tại một transformer TF với L + 2 + O(κ log(BΦBw/ε)) lớp, max{3d, 5} đầu, và Dhid = max{2(k+1), D}d + 3(D+d) + 5 sao cho điều sau đây đúng.

Cho bất kỳ tập dữ liệu D sao cho ∥Φ⋆(x̄i)∥2 ≤ BΦ, ∥xi∥∞ ≤ By, và ∥ŴΦ⋆,λ i∥2,∞ ≤ Bw/2 (cf. (Φ⋆-Ridge-Dyn)) cho tất cả i ∈ [N], và đầu vào tương ứng H ∈ RDhid×N có định dạng (6), chúng ta có

(a) Lớp transformer đầu tiên sao chép k đầu vào trước đó vào token hiện tại, và tính toán lớp đầu tiên {σρ(B⋆ 1 x̄i)}i∈[N] trong Φ⋆:

Attn(1)(H) = [x1 ... xN; p1 ... pN] = [x1−k+1 ... xN−k+1; | |; x1 ... xN; p1 ... pN]; (7)

TF(1)(H) = MLP(1)(Attn(1)(H)) = [σρ(B⋆ 1 x̄1) ... σρ(B⋆ 1 x̄N); x1 ... xN; p′ 1 ... p′ N]. (8)

(b) L + 1 lớp đầu tiên của TF biến đổi mỗi x̄i thành Φ⋆(x̄i), và sao chép biểu diễn trước đó Φ⋆(x̄i−1) vào cùng token để tạo thành cặp (đầu vào, nhãn) (Φ⋆(x̄i−1), xi):

TF(1:L+1)(H) = [Φ⋆(x̄1) Φ⋆(x̄2) ... Φ⋆(x̄N); 0d 0d ... 0d; 0D Φ⋆(x̄1) ... Φ⋆(x̄N−1); x1 x2 ... xN; p̃1 p̃2 ... p̃N]. (9)

Ở trên, pi, p′ i, p̃i chỉ khác pi ở chiều của zero padding.

(c) Cho mỗi chỉ số i ∈ [N], đầu ra transformer H̃ = TF(H) chứa dự đoán x̂i+1 := [h̃i]1:d gần với bộ dự đoán (Φ⋆-Ridge-Dyn): ∥x̂i+1 − (ŴΦ⋆,λ i)⊤Φ⋆(x̄i)∥∞ ≤ ε.

Theo hiểu biết tốt nhất của chúng tôi, Định lý 2 cung cấp cấu trúc transformer đầu tiên để học hệ thống động phi tuyến trong ngữ cảnh. Tương tự như cho Định lý 1, các giới hạn về kích thước transformer ở đây ngụ ý các bảo đảm rủi ro vượt trội ε̃ trong Õ((L+κ)2((k+D)d)2ε̃−2) trường hợp (tiền) huấn luyện.

Về mặt cơ chế, so với Định lý 1, những khác biệt chính trong Định lý 2 là (1) bước sao chép bổ sung (7) trong lớp đầu tiên, nơi (k−1) token trước đó [xi−k+1; . . . ; xi−1] được sao chép vào xi token, để chuẩn bị cho việc tính toán Φ⋆(x̄i); (2) đầu ra trung gian (9), nơi thông tin liên quan (để chuẩn bị cho ICL tuyến tính) có dạng [Φ⋆(x̄i−1); xi; Φ⋆(x̄i)] và được thu thập trong các x-token, khác với (4) nơi thông tin liên quan là [Φ⋆(xi); yi], được thu thập trong y-token. Chúng tôi sẽ kiểm tra những điều này trong các thí nghiệm của chúng tôi (Phần 5.2).

5 Thí nghiệm

Bây giờ chúng tôi điều tra thực nghiệm các transformer được huấn luyện dưới hai cài đặt được xem xét trong Phần 4.1 & 4.2. Trong cả hai trường hợp, chúng tôi chọn hàm biểu diễn Φ⋆ là một phiên bản được chuẩn hóa của MLP L lớp (3): Φ⋆(x) := Φ̃⋆(x)/∥Φ̃⋆(x)∥2, nơi Φ̃⋆ có dạng (3), với các ma trận trọng số (B⋆ i)i∈[L] được lấy mẫu như các ma trận trực giao (cột/hàng) ngẫu nhiên và giữ cố định trong mỗi thí nghiệm, và độ dốc ρ = 0.01. Chúng tôi kiểm tra L ∈ {1, 2, 3, 4}, chiều ẩn D ∈ {5, 20, 80}, và mức nhiễu σ ∈ {0, 0.1, 0.5}. Tất cả các thí nghiệm sử dụng Px = N(0, Id), τ2 = 1, d = 20, và N = 41.

Chúng tôi sử dụng một kiến trúc nhỏ trong họ GPT-2 với 12 lớp, 8 đầu, và Dhid = 256, theo (Garg et al., 2022; Li et al., 2023a; Bai et al., 2023). Mục tiêu (tiền) huấn luyện cho transformer (cho cài đặt học có giám sát) là rủi ro dự đoán trung bình tại tất cả các token:

minθ Ew,D∼Pw [1/2N ∑N i=1 (ŷθ,i(Di−1, xi) − yi)2], (10)

nơi ŷθ,i được trích xuất từ token đầu ra thứ (2i−1) của TFθ(H) (cf. Phần 3). Mục tiêu cho cài đặt hệ thống động được định nghĩa tương tự. Chi tiết thí nghiệm bổ sung có thể được tìm thấy trong Phụ lục D, và các nghiên cứu bãi bỏ (ví dụ: dọc theo quỹ đạo huấn luyện; cf. Hình 9) trong Phụ lục F.

5.1 Học có giám sát với biểu diễn

Chúng tôi đầu tiên kiểm tra ICL với dữ liệu học có giám sát như trong Phần 4.1, nơi cho mỗi cấu hình của (L, D, σ) (cái mà tạo ra một Φ⋆) chúng tôi huấn luyện một transformer trên phân phối dữ liệu ICL (2) và đánh giá ICL trên cùng phân phối. Chú ý rằng Hình 1c & 1b vẽ kết quả cho (L, D, σ) = (2, 20, 0.1).

Hiệu suất ICL Hình 2 báo cáo rủi ro kiểm tra qua các cài đặt khác nhau, nơi chúng tôi quan sát rằng các transformer được huấn luyện có thể liên tục phù hợp với bộ dự đoán ridge tối ưu Bayes. Điều này mở rộng các kết quả hiện có cho thấy rằng các hàm tuyến tính (không có biểu diễn) có thể được học gần tối ưu trong ngữ cảnh bởi transformer (Garg et al., 2022; Akyürek et al., 2022), thêm mô hình (2) của chúng tôi vào danh sách các lớp hàm có thể học (gần) tối ưu thực nghiệm. Trong số các thước đo độ phức tạp (L, D, σ), quan sát rằng mức nhiễu σ và chiều ẩn D của biểu diễn (Hình 2a & 2b) dường như có tác động lớn hơn đến rủi ro (gần tối ưu Bayes) so với độ sâu L (Hình 2c).

Cơ chế thông qua thăm dó tuyến tính Chúng tôi tiến hành các thí nghiệm thăm dò để hiểu thêm về các cơ chế của các transformer được huấn luyện. Phù hợp với cấu trúc lý thuyết trong Định lý 1, câu hỏi chính của chúng tôi ở đây là: Transformer được huấn luyện có thực hiện những điều sau theo thứ tự hay không:

1. Tính toán Φ⋆(xi) tại các xi token;
2. Sao chép chúng vào yi token tiếp theo và thu được tập dữ liệu {Φ⋆(xi), yi}i dưới dạng (4);
3. Thực hiện ICL tuyến tính trên {Φ⋆(xi), yi}i?

Trong khi các cơ chế bên trong như vậy nói chung khó định lượng chính xác, chúng tôi điều chỉnh kỹ thuật thăm dò tuyến tính (Alain and Bengio, 2016) vào cài đặt transformer để xác định bằng chứng. Thăm dò tuyến tính cho phép chúng tôi kiểm tra xem các đầu ra lớp trung gian (token) {hx,(ℓ) i}ℓ∈[12] (ℓ ký hiệu lớp) và {hy,(ℓ) i}ℓ∈[12] có "chứa" các đại lượng quan tâm khác nhau hay không, bằng cách hồi quy tuyến tính các đại lượng này (như y) trên các token trung gian (như x), được gộp lại qua chỉ số token i ∈ [N]. Ví dụ, hồi quy Φ⋆(xi) trên hx,(ℓ) i kiểm tra xem xi token sau lớp thứ ℓ có "chứa" Φ⋆(xi) hay không, nơi lỗi nhỏ hơn chỉ ra sự chứa đựng tốt hơn. Xem Phụ lục D.1 để biết thêm cài đặt của thăm dò tuyến tính.

Hình 3 báo cáo các lỗi của ba thăm dò tuyến tính qua tất cả 12 lớp: Biểu diễn Φ⋆(xi) trong các xi token và yi token, và dự đoán ridge tối ưu ŷΦ⋆,λ i trong các xi token. Quan sát rằng các lỗi thăm dò cho biểu diễn giảm qua các lớp thấp hơn và sau đó tăng qua các lớp cao hơn (Hình 3a & 3b), trong khi các lỗi thăm dò cho dự đoán ridge giảm đơn điệu qua các lớp (Hình 3c), phù hợp với cấu trúc của chúng tôi rằng transformer đầu tiên tính toán các biểu diễn và sau đó thực hiện ICL trên biểu diễn. Cũng chú ý rằng các biểu diễn sâu hơn mất nhiều lớp hơn để tính toán (Hình 3a). Thêm nữa, biểu diễn xuất hiện muộn hơn trong các y-token (lớp 5-6) so với trong các x-token (lớp 1,3,4,5), phù hợp với cơ chế sao chép, mặc dù việc sao chép dường như bị mất mát (lỗi thăm dò cao hơn tại các y-token).

Cuối cùng, quan sát rằng sự tách biệt giữa các mô-đun thấp và cao dường như mạnh trong một số lần chạy—Ví dụ, transformer đỏ (L = 4, σ = 0.1) tính toán biểu diễn tại lớp 5, sao chép chúng vào các y-token tại lớp 6, và bắt đầu thực hiện ICL lặp từ lớp 7, khá phù hợp với các cấu trúc lý thuyết của chúng tôi ở cấp độ cao.

Điều tra mô-đun trên thông qua dán Để điều tra thêm mô-đun trên, chúng tôi kiểm tra xem nó có thực sự là một người học ICL mạnh mẽ một mình mà không dựa vào mô-đun thấp hay không, điều này sẽ cung cấp bằng chứng mạnh mẽ hơn rằng chỉ riêng mô-đun trên có thể là một người học ICL tuyến tính mạnh mẽ. Tuy nhiên, một thách thức chính ở đây là không rõ làm thế nào để cung cấp đầu vào thô trực tiếp vào mô-đun trên, vì chúng có lẽ chỉ chấp nhận các định dạng đầu vào được phát ra từ mô-đun thấp—phần mà chúng tôi muốn loại trừ ngay từ đầu.

Chúng tôi giải quyết điều này bằng cách tiến hành một thí nghiệm dán, nơi chúng tôi cung cấp các bài toán ICL tuyến tính D chiều (y′ i = ⟨w′, x′ i⟩ không có biểu diễn) với định dạng đầu vào (1) trực tiếp đến mô-đun trên của transformer được huấn luyện trên biểu diễn Φ⋆, bằng cách thêm một lớp nhúng có thể huấn luyện ở giữa; xem Hình 4a để minh họa phương pháp dán. Lớp nhúng có thể huấn luyện này bản thân cần phải nông mà không có nhiều sức mạnh ICL—chúng tôi kiểm tra ba lựa chọn sau: (1) Nhúng tuyến tính: hx i = W[xi; 0] và hy i = W[0D; yi]; (2) Nhúng sao chép tuyến tính, nơi các y token thay vào đó là hy i = W[xi; yi], được thúc đẩy bởi định dạng (4); (3) Nhúng transformer một lớp TF, tính toán H = TF(H). Xem Phụ lục D.2 để biết thêm cài đặt của dán.

Hình 4b cho thấy kết quả dán trên một transformer được huấn luyện trên (L, D, σ) = (3, 20, 0.1) (một bãi bỏ trong Hình 10b), nơi chúng tôi phân tích các mô-đun thấp và cao tại lớp 4 như được gợi ý bởi đường cong thăm dò (Hình 3a xanh). Có lẽ đáng ngạc nhiên, mô-đun trên của transformer thực sự có thể thực hiện ICL tuyến tính gần tối ưu không có biểu diễn khi chúng tôi sử dụng nhúng transformer một lớp. Chú ý rằng một transformer một lớp (mới được huấn luyện) bản thân hoạt động kém, đạt được khoảng rủi ro kiểm tra tầm thường 1.01, điều này được mong đợi do định dạng đầu vào cụ thể của chúng tôi (1). Điều này cho thấy rằng phần lớn ICL thực sự được thực hiện bởi mô-đun trên, với nhúng transformer một lớp không làm nhiều ICL bản thân nó. Cũng chú ý rằng các nhúng sao chép tuyến tính và tuyến tính cũng mang lại hiệu suất hợp lý (mặc dù không tối ưu), với sao chép tuyến tính hoạt động tốt hơn một chút.

5.1.1 Mở rộng: Hỗn hợp của nhiều biểu diễn

Chúng tôi thêm điều tra một tình huống khó hơn trong đó tồn tại nhiều hàm biểu diễn có thể (Φ⋆ j)j∈[K], và phân phối dữ liệu ICL là một hỗn hợp của K phân phối có dạng (2) mỗi cái được tạo ra bởi Φ⋆ j (tương đương với việc sử dụng biểu diễn nối Φ⋆ = [Φ⋆ 1, . . . , Φ⋆ K] với một prior thưa nhóm 1 trên w ∈ RKD). Chúng tôi thấy rằng transformer vẫn tiếp cận rủi ro tối ưu Bayes, mặc dù ít hơn so với cài đặt biểu diễn đơn. Sử dụng các thăm dò tuyến tính, chúng tôi thấy rằng transformer đôi khi thực hiện cơ chế lựa chọn thuật toán sau ICL được xác định trong Bai et al. (2023), tùy thuộc vào cài đặt. Chi tiết được hoãn lại đến Phụ lục E do giới hạn không gian.

5.2 Hệ thống động

Bây giờ chúng tôi nghiên cứu cài đặt hệ thống động trong Phần 4.2 sử dụng các phương pháp tương tự như trong Phần 5.1. Hình 5a cho thấy rằng transformer vẫn có thể liên tục đạt được rủi ro ICL gần tối ưu Bayes. Một bãi bỏ của các rủi ro và lỗi thăm dò trong các cài đặt thay thế có thể được tìm thấy trong Phụ lục F.2.

Thăm dò các cơ chế sao chép Câu hỏi cơ chế chính mà chúng tôi đặt ra ở đây là về giai đoạn chuẩn bị dữ liệu, nơi cấu trúc transformer trong Định lý 2 thực hiện sao chép hai lần:

i) Một sao chép của [xi−k+1; . . . ; xi−1] vào xi token như trong (7), để chuẩn bị cho việc tính toán Φ⋆(x̄i); Vì sao chép có thể không thể phân biệt được với bước nhân ma trận tiếp theo [xi−k+1; . . . ; xi−1; xi] 7→ B⋆ 1[xi−k+1; . . . ; xi−1; xi], chúng tôi thay vào đó thăm dò kết quả B⋆ 1,−j xi−j sau nhân ma trận, nơi B⋆ 1,−j ∈ RD×d ký hiệu khối trong B⋆ 1 đánh xi−j.

ii) Một sao chép thứ hai của Φ⋆(x̄i−1) vào xi token để thu được (9), sau khi {Φ⋆(x̄i)}i được tính toán.

Chúng tôi thăm dò một transformer được huấn luyện trên bài toán hệ thống động với k = 3 (để các đầu vào trước đó hữu ích là xi−1 và xi−2), và thấy rằng transformer thực sự thực hiện hai sao chép được phỏng đoán. Hình 5b chứng minh sao chép i) vào token hiện tại, nơi sao chép của xi−1 xảy ra sớm hơn (tại lớp 3) và chính xác hơn một chút so với của xi−2 (tại lớp 4), như mong đợi. Thêm nữa quan sát rằng lớp 4 (mà chúng tôi nhớ lại chứa một lớp attention và một lớp MLP) dường như cũng đã thực hiện biểu diễn MLP (không được chuẩn hóa) Φ̃⋆(x̄i) = σρ(B⋆ 2σρ(B⋆ 1x̄i)), mặc dù lỗi thăm dò cho biểu diễn thực tế Φ⋆(x̄i) = Φ̃⋆(x̄i)/∥Φ̃⋆(x̄i)∥2 tiếp tục giảm trong lớp 4-6 (Hình 5c). Hình 5c tiếp tục chứng minh sao chép ii), nơi Φ⋆(x̄i−1) thực sự được sao chép đến token thứ i, trong khi ngược lại hoàn toàn Φ⋆(x̄i−k) cho k ≥ 2 không được sao chép chút nào vào xi token, phù hợp với định dạng đầu ra trung gian được phỏng đoán (9).

6 Kết luận

Bài báo này trình bày các nghiên cứu lý thuyết và cơ chế về khả năng học trong bối cảnh của transformer trên các nhiệm vụ học tập liên quan đến các hàm biểu diễn, nơi chúng tôi đưa ra các cấu trúc transformer hiệu quả cho ICL tuyến tính trên các biểu diễn cho cài đặt học có giám sát và hệ thống động, và xác nhận thực nghiệm sự tồn tại của các cơ chế cấp cao khác nhau trong các transformer được huấn luyện. Chúng tôi tin rằng công việc của chúng tôi mở ra việc điều tra ICL vượt ra ngoài các lớp hàm đơn giản, và gợi ý các câu hỏi mở như các điều tra thêm về các cơ chế của các mô-đun ICL tuyến tính, và lý thuyết cho ICL trong các lớp hàm phức tạp hơn. Một hạn chế của công việc chúng tôi là cài đặt vẫn bao gồm dữ liệu tổng hợp với các hàm biểu diễn lý tưởng; thực hiện các nghiên cứu tương tự trên dữ liệu thế giới thực hơn sẽ là một hướng quan trọng cho công việc tương lai.

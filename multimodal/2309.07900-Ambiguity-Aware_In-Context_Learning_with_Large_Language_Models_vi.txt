# Học trong ngữ cảnh nhận biết sự mơ hồ với các mô hình ngôn ngữ lớn

Lingyu Gao∗
Viện Công nghệ Toyota tại Chicago
lygao@ttic.edu

Aditi Chaudhary
Google Research
aditichaud@google.com

Krishna Srinivasan
Google Research
krishnaps@google.com

Kazuma Hashimoto
Google Research
kazumah@google.com

Karthik Raman
Google Research
karthikraman@google.com

Michael Bendersky
Google Research
bemike@google.com

## Tóm tắt

Học trong ngữ cảnh (ICL), tức là chỉ cho các mô hình ngôn ngữ lớn (LLM) một vài ví dụ minh họa cụ thể cho nhiệm vụ, đã dẫn đến những cải thiện downstream mà không cần tinh chỉnh cụ thể cho nhiệm vụ. Tuy nhiên, các LLM nhạy cảm với việc lựa chọn prompt, và do đó một câu hỏi nghiên cứu quan trọng là làm thế nào để chọn các ví dụ minh họa tốt cho ICL. Một chiến lược hiệu quả là tận dụng sự tương đồng ngữ nghĩa giữa các ví dụ minh họa ICL và đầu vào kiểm thử bằng cách sử dụng một bộ truy xuất văn bản, tuy nhiên điều này không tối ưu vì không xem xét kiến thức hiện có của LLM về nhiệm vụ đó. Từ công trình trước đây (Lyu et al., 2023), chúng ta đã biết rằng các nhãn được ghép với các ví dụ minh họa làm thiên lệch dự đoán của mô hình. Điều này dẫn chúng ta đến giả thuyết liệu việc xem xét kiến thức hiện có của LLM về nhiệm vụ, đặc biệt là đối với không gian nhãn đầu ra có thể giúp trong chiến lược lựa chọn ví dụ minh họa tốt hơn. Thông qua thử nghiệm rộng rãi trên ba nhiệm vụ phân loại văn bản, chúng tôi phát hiện rằng có lợi khi không chỉ chọn các ví dụ minh họa ICL có tương đồng ngữ nghĩa mà còn chọn những ví dụ minh họa giúp giải quyết sự mơ hồ nhãn vốn có xung quanh ví dụ kiểm thử. Thú vị là, chúng tôi thấy rằng việc bao gồm các ví dụ minh họa mà LLM trước đây đã phân loại sai và cũng nằm trên ranh giới quyết định của ví dụ kiểm thử mang lại hiệu suất tăng cao nhất.

## 1 Giới thiệu

Tận dụng các LLM (Brown et al., 2020; Chowdhery et al., 2022; Thoppilan et al., 2022) thông qua học trong ngữ cảnh (ICL) hiện là một chiến lược phổ biến để cải thiện hiệu suất nhiệm vụ downstream, trong đó mô hình có thể thực hiện một nhiệm vụ bằng cách đơn giản được điều kiện hóa dựa trên định nghĩa nhiệm vụ và/hoặc một vài ví dụ minh họa nhiệm vụ (các ví dụ đầu vào-đầu ra) (Brown et al., 2020; Xie et al., 2021).

Khi ICL ngày càng được áp dụng rộng rãi, nó đã làm nổi bật (Lester et al., 2021; Liu et al., 2022; Zhang et al., 2022; Lu et al., 2022) rằng các LLM nhạy cảm với việc lựa chọn prompt, làm cho "kỹ thuật prompt" cho các nhiệm vụ khác nhau trở nên thách thức và tốn thời gian. Tuy nhiên, kỹ thuật prompt không phải là một trò chơi đoán hoàn toàn; mà có thể được điều chỉnh bởi một số tín hiệu dẫn xuất từ dữ liệu. Ví dụ, việc chọn các ví dụ minh họa có tương đồng ngữ nghĩa với đầu vào mới đã cho thấy hiệu quả hơn so với các ví dụ minh họa được lấy mẫu ngẫu nhiên (Das et al., 2021; Liu et al., 2022; Margatina et al., 2023), trong đó một bộ truy xuất văn bản được sử dụng để chọn các ví dụ huấn luyện top-k cho mỗi ví dụ kiểm thử dựa trên văn bản đầu vào. Động lực là việc sử dụng thông tin từ các tình huống tương tự hiện có sẽ giúp giải quyết một vấn đề mới (Aamodt and Plaza, 1994).

Tuy nhiên, việc lựa chọn chỉ dựa trên đầu vào không nắm bắt một cách rõ ràng kiến thức hiện có của LLM về không gian nhãn cụ thể cho nhiệm vụ của cả ví dụ minh họa ICL cũng như đầu vào kiểm thử. Ví dụ, trên một nhiệm vụ phân loại cảm xúc năm chiều (SST (Socher et al., 2013)), chúng tôi đã quan sát thấy rằng mô hình Flan-PaLM 2 (kích thước L) (Anil et al., 2023) bị nhầm lẫn giữa hai nhãn cụ thể, 'Very Negative' và 'Negative', nhiều hơn so với giữa 'Neutral' và 'Very Negative', như được thể hiện trong Hình 2. Điều này thúc đẩy chúng tôi điều tra liệu kiến thức hiện có của mô hình cũng có thể được tận dụng để chọn các ví dụ minh họa hiệu quả hơn nữa.

Cụ thể, chúng tôi dẫn xuất các tín hiệu từ LLM cơ bản về không gian nhãn đầu ra của cả ví dụ kiểm thử mới và dữ liệu huấn luyện mà từ đó chúng tôi chọn các ví dụ minh họa. Như đã được thúc đẩy ở trên, sự mơ hồ của mô hình xung quanh nhãn đầu ra của ví dụ kiểm thử mới sẽ giúp chúng ta biết mô hình bị nhầm lẫn nhất về điều gì, điều này có thể được sử dụng để chọn những ví dụ minh họa giúp giảm sự nhầm lẫn này. Để chọn các ví dụ minh họa như vậy từ dữ liệu huấn luyện, chúng tôi đề xuất không chỉ xem xét các nhãn sự thật cơ bản được ghép với các ví dụ minh họa này, mà còn xem xét tính hữu ích bằng cách xem xét dự đoán của mô hình. Đầu tiên, cho một ví dụ kiểm thử và tập hợp dữ liệu huấn luyện, đối với mỗi ví dụ kiểm thử, chúng tôi sử dụng một bộ truy xuất có sẵn để truy xuất các ví dụ top-k có văn bản đầu vào tương tự. Đối với mỗi ví dụ kiểm thử, chúng tôi xác định một tập nhãn mơ hồ gồm hai nhãn đầu ra mà mô hình bị nhầm lẫn nhất. Tiếp theo, chúng tôi chọn các ví dụ minh họa được xếp hạng cao sao cho nhãn sự thật cơ bản của chúng nằm trong tập nhãn nêu trên. Để tìm thêm các ví dụ minh họa hữu ích, chúng tôi xác định những ví dụ bị mô hình phân loại sai; trực giác là việc cho mô hình thấy một ví dụ minh họa trước đây bị phân loại sai có thể buộc nó phải sửa chữa (Tan, 2006; Wang et al., 2020). Cuối cùng, trên cơ sở các ví dụ minh họa bị phân loại sai, chúng tôi thêm một ràng buộc để chỉ chọn những ví dụ minh họa mà dự đoán của mô hình nằm trong tập nhãn mơ hồ, tức là trên ranh giới quyết định của ví dụ kiểm thử.

Để kiểm tra giả thuyết của chúng tôi, chúng tôi tập trung vào các nhiệm vụ phân loại văn bản đa lớp có sắc thái tinh tế trong không gian nhãn. Chúng tôi tiến hành thử nghiệm rộng rãi trên ba nhiệm vụ, cụ thể là SST (Socher et al., 2013), GoEmotions (Demszky et al., 2020), và EDOS (Task-B) (Kirk et al., 2023), tất cả đều có không gian nhãn tinh tế, khiến mô hình có khả năng bị nhầm lẫn giữa các nhãn.

Các quan sát chính của chúng tôi là:

1. Việc thêm các ràng buộc một cách tăng dần, tức là 1) xem xét sự mơ hồ nhãn của ví dụ kiểm thử, 2) giới hạn các ví dụ minh họa ICL thành các ví dụ minh họa bị phân loại sai, và 3) xem xét sự mơ hồ nhãn của các ví dụ huấn luyện dẫn đến cải thiện +1.5%, +2.2%, +2.6% trong điểm F1 macro so với ICL dựa trên bộ truy xuất, trung bình trên tất cả các tập dữ liệu (Bảng 3).

2. Chúng tôi thấy rằng việc thêm các ràng buộc dựa trên nhãn như vậy giúp ích nhiều hơn trên mô hình nhỏ hơn, tức là trên Flan-PaLM 2 (M) (tăng +3.9%) so với tăng +1.4% trên Flan-PaLM 2 (L).

3. Chúng tôi cũng quy thành công này của các phương pháp đề xuất cho quan sát rằng tập nhãn mơ hồ hoạt động như một proxy tốt cho nhãn sự thật kiểm thử, và như được ghi nhận bởi Min et al. (2022), các nhãn trong các ví dụ minh họa ICL làm thiên lệch dự đoán của mô hình nhiều nhất. Do đó, việc cho mô hình thấy nhãn sự thật 'có khả năng' hướng dẫn mô hình đưa ra dự đoán chính xác (Bảng 5).

## 2 Phương pháp đề xuất

Thông thường, trong chế độ ICL, chúng ta giả định có quyền truy cập vào dữ liệu huấn luyện Dtrain = {(x0, y0), ···, (xT, yT)} từ đó mục tiêu là chọn d ví dụ minh họa để được sử dụng làm prompt. Như đã được thúc đẩy trong phần giới thiệu, chúng tôi tuân theo phương pháp ba bước để chọn ví dụ minh họa, đối với mỗi ví dụ kiểm thử, chúng ta cần 1) trích xuất các ví dụ tương đồng ngữ nghĩa từ Dtrain, 2) xác định tập nhãn mơ hồ và 3) trích xuất dự đoán của mô hình cho Dtrain để xác định các ví dụ bị phân loại sai. Dưới đây, chúng tôi mô tả chi tiết từng bước và cách chúng được sử dụng cùng nhau để chọn các ví dụ minh họa "tốt nhất".

**Trích xuất các ví dụ minh họa tương đồng ngữ nghĩa**
Thông thường, trong phương pháp này, các ví dụ minh họa được chọn cho mỗi ví dụ kiểm thử xt bằng cách tìm những ví dụ từ Dtrain có tương đồng ngữ nghĩa với đầu vào kiểm thử. Động lực là việc quan sát các ví dụ minh họa tương tự với văn bản đầu vào mới sẽ hoạt động như một gợi ý cho mô hình (Margatina et al., 2023). Điều này yêu cầu sử dụng một bộ truy xuất R, hoặc một bộ có sẵn như (Liu et al., 2022; Agrawal et al., 2023; Margatina et al., 2023; Luo et al., 2023) hoặc một bộ truy xuất được huấn luyện cụ thể cho nhiệm vụ đó (Das et al., 2021; Rubin et al., 2022). Đối với mỗi ví dụ kiểm thử xt, bộ truy xuất R được sử dụng để xếp hạng các ví dụ từ Dtrain dựa trên sự tương đồng ngữ nghĩa của các văn bản đầu vào. Các cặp đầu vào-đầu ra top-k sau đó được chọn từ Dtrain được xếp hạng để được sử dụng làm ví dụ minh họa ICL.

**Xác định tập nhãn mơ hồ** Như chúng ta có thể quan sát từ ma trận nhầm lẫn trong Hình 2, mô hình thường bị nhầm lẫn giữa hai nhãn. Chúng tôi giả thuyết rằng ngoài sự tương đồng ngữ nghĩa, việc cung cấp các ví dụ minh họa giúp mô hình giải quyết sự mơ hồ này sẽ giúp mô hình tự sửa chữa. Do đó, như một bước tiếp theo, chúng tôi xây dựng một prompt θ cho ví dụ kiểm thử xt, và sử dụng log-likelihood của mô hình để chấm điểm mỗi nhãn đầu ra l ∈ L cho prompt. Sử dụng điều này, chúng tôi xác định 2 nhãn hàng đầu có điểm số cao nhất, mà chúng tôi gọi là "tập nhãn mơ hồ" của xt, ký hiệu là Lambig,t = {ŷ(1)t, ŷ(2)t}, trong đó ŷ(1)t và ŷ(2)t lần lượt là nhãn có khả năng cao nhất và thứ hai.

**Trích xuất các ví dụ minh họa bị phân loại sai** Thành phần cuối cùng trong công thức của chúng tôi là xem xét dự đoán của mô hình trên dữ liệu huấn luyện. Trong khi các công trình trước đây Min et al. (2022); Yoo et al. (2022); Margatina et al. (2023) đã xem xét không gian nhãn dữ liệu huấn luyện từ góc độ của các nhãn sự thật cơ bản, tức là có nên giữ lại chúng trong ICL hay không, chúng tôi hướng đến việc xem xét không gian nhãn từ góc độ của các dự đoán mô hình. Cụ thể, chúng tôi quan tâm đến việc xác định các ví dụ minh họa "khó", tức là các ví dụ mà mô hình mắc lỗi. Chúng tôi hy vọng rằng bằng cách cho mô hình thấy các ví dụ như vậy với nhãn sự thật cơ bản của chúng sẽ buộc mô hình phải tự sửa chữa. Các công trình trước đây đã nhấn mạnh giá trị tiềm năng của việc tận dụng các ví dụ bị phân loại sai từ tập huấn luyện để nâng cao hiệu suất mô hình (Tan, 2006; Wang et al., 2020), nhưng họ chưa thử nghiệm điều này cho việc chọn ví dụ minh họa ICL trên phân loại văn bản. Ngoài các ví dụ bị phân loại sai, chúng tôi hạn chế thêm dự đoán mô hình của những ví dụ bị phân loại sai này phải là một trong các nhãn mơ hồ, được xác định trong bước trên. Cho rằng chúng ta đã biết mô hình bị nhầm lẫn giữa những nhãn đầu ra nào cho các ví dụ kiểm thử, việc cho mô hình thấy những ví dụ minh họa (với nhãn sự thật cơ bản của chúng) nằm trên ranh giới quyết định có khả năng sẽ hướng dẫn mô hình chọn nhãn chính xác cho đầu vào kiểm thử.

## 3 Thiết lập thử nghiệm

### 3.1 Mô hình

Chúng tôi thử nghiệm với mô hình Flan-PaLM 2, một mô hình được điều chỉnh bằng hướng dẫn được tinh chỉnh trên tập dữ liệu Flan (Chung et al., 2022; Longpre et al., 2023) dựa trên PaLM-2 (Anil et al., 2023), một mô hình ngôn ngữ lớn đa ngữ được huấn luyện trước trên các tài liệu web, sách, mã, toán học và dữ liệu hội thoại. Chúng tôi chọn các mô hình này vì Luo et al., 2023 thấy rằng ví dụ minh họa được truy xuất cho ICL hoạt động tốt hơn với các mô hình được điều chỉnh bằng hướng dẫn so với các LLM chung (ví dụ: GPT). Đặc biệt, chúng tôi thử nghiệm với hai biến thể của mô hình, cụ thể là Flan-PaLM-2 (M) và Flan-PaLM-2 (L), trong đó biến thể sau là mô hình có tham số lớn hơn. Các ví dụ minh họa ICL được chọn bằng cách sử dụng một bộ truy xuất có sẵn được tinh chỉnh trên mT5-base (Xue et al., 2021) sử dụng mục tiêu không giám sát được đề xuất bởi Izacard et al. (2021). Vì thứ tự của các ví dụ minh họa có thể ảnh hưởng đến hiệu suất của mô hình (Kumar and Talukdar, 2021; Lu et al., 2022), chúng tôi xáo trộn ngẫu nhiên thứ tự của các ví dụ minh họa cho ba seed ngẫu nhiên và báo cáo kết quả trung bình.

### 3.2 Dữ liệu

Như đã đề cập ở trên, các mô hình Flan-PaLM 2 được tinh chỉnh trên tập dữ liệu Flan là một hỗn hợp của nhiều tập dữ liệu có giám sát. Cụ thể, chúng tôi chọn ba tập dữ liệu phân loại văn bản thỏa mãn các tiêu chí mong muốn sau, 1) không gian nhãn đầu ra cho thấy sắc thái tinh tế trải dài trên nhiều nhãn, và 2) các tập dữ liệu này không phải là một phần của hỗn hợp Flan để tránh bất kỳ thiên lệch vốn có nào từ mô hình cơ bản. Chúng tôi mô tả chúng dưới đây, với thống kê tập dữ liệu được thể hiện trong Bảng 1. Tất cả các tập dữ liệu đều bằng tiếng Anh.

**EDOS (Task-B)**: Task B của Phát hiện Phân biệt giới tính Trực tuyến có thể Giải thích (Kirk et al., 2023), là một nhiệm vụ phân loại chủ đề trong đó nội dung phân biệt giới tính được phân loại thành bốn loại, tức là 1) Đe dọa, kế hoạch gây hại & kích động, 2) Phỉ báng, 3) Thù địch, và 4) Thảo luận Thành kiến.

**SST**: Stanford Sentiment Treebank (SST, Socher et al., 2013) là một tập dữ liệu phân loại cảm xúc 5 chiều cho các đánh giá phim với các nhãn: Very Negative, Negative, Neutral, Positive, và Very Positive.

**GoEmotions**: GoEmotions (Demszky et al., 2020) là một tập dữ liệu phân loại cảm xúc đa lớp với "neutral" và 27 lớp cảm xúc, ví dụ: "admiration" và "fear", được thu thập từ các bình luận Reddit. Vì không gian nhãn rất lớn và cho rằng chúng ta có độ dài chuỗi hạn chế, việc chọn một prompt ngắn gọn nhưng hiệu quả trở nên quan trọng hơn nữa.

### 3.3 Baseline

Chúng tôi so sánh phương pháp đề xuất của chúng tôi với các baseline sau:

**Nhãn thường xuyên (FREQ)**: Chọn nhãn thường xuyên nhất làm dự đoán mô hình cho tất cả các ví dụ kiểm thử.

**ICL không shot (ZERO)**: Đối với mỗi ví dụ kiểm thử xt, chúng tôi thêm định nghĩa nhiệm vụ vào đầu mỗi đầu vào kiểm thử và gợi ý cho các mô hình. Để có được dự đoán mô hình, chúng tôi sử dụng log-likelihood của mô hình để chấm điểm mỗi nhãn đầu ra l ∈ L, cho prompt. Sau đó, chúng tôi chọn nhãn có điểm số cao nhất. yt = arg maxL score(l, θ) trong đó θ đề cập đến prompt được sử dụng cụ thể cho thiết lập này, và score đề cập đến log-likelihood của mô hình.

**ICL N-shot tĩnh (STATIC-N)**: Chúng tôi chọn thủ công N ví dụ minh họa từ Dtrain, một cho mỗi trong N nhãn đầu ra (N = |L|). Lưu ý rằng các ví dụ minh họa này là tĩnh cho tất cả các ví dụ kiểm thử. Do đó, chúng tôi nối định nghĩa nhiệm vụ, N ví dụ minh họa và ví dụ kiểm thử xt làm prompt cho ICL và sử dụng điểm log-likelihood, như đã mô tả ở trên, để có được dự đoán mô hình.

**ICL dựa trên bộ truy xuất (RETR)**: Không giống như trên, trong đó chúng tôi sử dụng cùng một prompt cho tất cả các đầu vào kiểm thử, trong baseline này, chúng tôi truy xuất ví dụ minh họa cho mỗi đầu vào kiểm thử xt. Chúng tôi sử dụng một bộ truy xuất có sẵn R (phần 3.1) để truy xuất k láng giềng gần nhất {x1,t, ···, xk,t} từ Dtrain, tương tự như Das et al. (2021). Chúng tôi mã hóa văn bản đầu vào của tập huấn luyện và ví dụ kiểm thử, xếp hạng dữ liệu huấn luyện theo tích vô hướng của các vectơ. Trong số k ví dụ này, chúng tôi chọn n = 4,8 làm ví dụ minh họa ICL.

### 3.4 Phương pháp đề xuất: AMBIG-ICL

Như đã mô tả trong phần 2, phương pháp đề xuất của chúng tôi xem xét cả sự tương đồng ngữ nghĩa và sự mơ hồ nhãn để chọn ví dụ minh họa. Dưới đây, chúng tôi tóm tắt các biến thể mô hình đề xuất của chúng tôi. Đối với mỗi thiết lập, trước tiên chúng tôi truy xuất các ví dụ tương tự top-k nhất từ dữ liệu huấn luyện Dtrain cho mỗi ví dụ kiểm thử xt. Chúng tôi ký hiệu các ứng viên này bằng R(xt) = {(x0,t, y0,t), ···, (xk,t, yk,t)}. Đồng thời, đối với mỗi xt, chúng tôi cũng xác định tập nhãn mơ hồ Lambig,t = {li, lj|l ∈ L}. Tập này chứa 2 nhãn hàng đầu, li và lj, mà mô hình bị nhầm lẫn nhất, trong đó cả hai nhãn đều thuộc tập L của tất cả các nhãn đầu ra.

**+GOLD** Chọn những ví dụ từ R(xt) làm ví dụ minh họa trong đó nhãn sự thật cơ bản của mỗi ví dụ minh họa thuộc tập nhãn mơ hồ của xt được ký hiệu bằng:
ICL(xt) = (xi, yi) if yi ∈ Lambig,t
for (xi, yi) ∈ R(xt)

**+GOLD +MIS** Chọn những ví dụ từ R(xt) làm ví dụ minh họa trong đó nhãn sự thật cơ bản nằm trong Lambig,t và chúng bị phân loại sai, được ký hiệu bằng:
ICL(xt) = (xi, yi) if yi ∈ Lambig,t, ŷi ≠ yi
for (xi, yi) ∈ R(xt)
Lưu ý rằng các dự đoán mô hình (ŷ) trên R(xt) được thu thập từ mô hình ZERO.

**+GOLD +MIS+PRED** Chọn những ví dụ từ R(xt) làm ví dụ minh họa trong đó nhãn sự thật cơ bản nằm trong Lambig,t. Đảm bảo chúng bị phân loại sai và với một ràng buộc bổ sung, rằng dự đoán mô hình của chúng cũng nằm trong Lambig,t, được ký hiệu bằng:
ICL(xt) = (xi, yi) if yi ∈ Lambig,t, ŷi ≠ yi,
ŷi ∈ Lambig,t for (xi, yi) ∈ R(xt)
Giống như trên, các dự đoán mô hình trên dữ liệu huấn luyện được thu thập từ ZERO.

Đối với tất cả các biến thể mô hình đề xuất của chúng tôi, chúng tôi chọn n ví dụ minh họa trong đó n = 4 và n = 8.

## 4 Kết quả và thảo luận

Chúng tôi báo cáo tất cả kết quả của chúng tôi trong Bảng 2. Cụ thể, chúng tôi sử dụng điểm F1 macro để so sánh hiệu suất mô hình, vì tất cả các nhiệm vụ của chúng tôi đều có tập dữ liệu không cân bằng. Đầu tiên, chúng tôi lưu ý trên tất cả ba nhiệm vụ, các phương pháp đề xuất của chúng tôi vượt trội so với các baseline.

Chúng tôi cũng lưu ý rằng mô hình không shot (ZERO) chỉ sử dụng định nghĩa nhiệm vụ nhưng không có ví dụ minh họa nhiệm vụ, đã là một baseline mạnh cho cả hai mô hình Flan-PaLM 2 (M/L). Đặc biệt, so sánh điểm trung bình của các baseline few-shot và ZERO, chúng tôi thấy rằng ZERO vượt trội hơn các baseline few-shot 1.4% trên Flan-PaLM 2 (M), nhưng mô hình lớn hơn Flan-PaLM 2 (L) có lợi từ việc bổ sung các ví dụ minh họa ICL (tăng +1.4%). Điều này là do các mô hình có tham số lớn hơn sử dụng học trong ngữ cảnh tốt hơn (Chan et al., 2022; Akyürek et al., 2023; Wei et al., 2023). Thú vị là, chúng tôi cũng quan sát thấy rằng đối với SST và GoEmotions, mô hình Flan-PaLM 2 (L) đạt hiệu suất cao hơn với n = 4 so với n = 8, điều này nhấn mạnh rằng số lượng không nhất thiết dẫn đến hiệu suất tốt hơn.

**Xem xét không gian nhãn đầu ra quan trọng hơn sự tương đồng ngữ nghĩa.** Trong các phương pháp few-shot, nơi chúng tôi sử dụng các ví dụ minh họa ICL cùng với định nghĩa nhiệm vụ, chúng tôi tính toán từ Bảng 3 rằng các phương pháp đề xuất AMBIG-* của chúng tôi vượt trội so với các mô hình dựa trên bộ truy xuất (RETR-*) +3.0% (trung bình) cho Flan-PaLM 2 (M), và +1.2% (trung bình) cho Flan-PaLM 2 (L), cho thấy rằng việc xem xét không gian nhãn đầu ra để chọn ví dụ minh họa cũng quan trọng như việc xem xét sự tương đồng đầu vào. Đặc biệt, chúng tôi thấy rằng việc xem xét các ví dụ minh họa bị phân loại sai nằm trên ranh giới quyết định của ví dụ kiểm thử dẫn đến hiệu suất tốt nhất tổng thể.

Trong Bảng 4, chúng tôi cho thấy các ví dụ minh họa được chọn cho thiết lập n = 4 cho một ví dụ của nhiệm vụ GoEmotions. Chúng ta thấy rằng đối với đầu vào kiểm thử "Ok! I like making friends", phương pháp RETR truy xuất các ví dụ tương tự từ Dtrain (tất cả các ví dụ đều đề cập đến bạn bè). Bây giờ từ mô hình ZERO, chúng tôi tính toán điểm dự đoán mô hình và thấy rằng Love và Joy là hai nhãn mà mô hình bị nhầm lẫn nhất. Tuy nhiên, vì chúng tôi không xem xét bất kỳ sự mơ hồ ví dụ kiểm thử nào trong RETR, chỉ có một trong các ví dụ được truy xuất đại diện cho các nhãn Love hoặc Joy, là hai nhãn mà mô hình bị nhầm lẫn nhất về ví dụ kiểm thử này. Trong khi đó, trong thiết lập AMBIG-ICL, vì các ràng buộc của chúng tôi, tất cả các ví dụ được chọn cho ICL đều thuộc tập nhãn mơ hồ. Điều này cho phép tất cả các phương pháp đề xuất của chúng tôi hiểu rõ hơn sắc thái tinh tế này trong không gian nhãn và đưa ra dự đoán mô hình chính xác là Love. Dưới đây, chúng tôi tiến hành một số phân tích để giải thích thêm cách các phương pháp đề xuất của chúng tôi hoạt động.

**Xem xét không gian nhãn đầu ra bù đắp cho sự hy sinh trong sự tương đồng ngữ nghĩa.** Khi chúng tôi đưa ra nhiều ràng buộc hơn (tức là, +GOLD, +MIS, và +PRED), chúng tôi thấy rằng chúng tôi cần hy sinh sự tương đồng ngữ nghĩa với đầu vào kiểm thử. Ví dụ, xem xét thí nghiệm AMBIG-ICL 4-shot trên EDOS (Task-B), để thỏa mãn các ràng buộc cho thiết lập +GOLD, chúng tôi cần chọn đến top-16 ví dụ được truy xuất để có được 4 ví dụ minh họa ICL; đối với +GOLD +MIS, chúng tôi cần top-55 ví dụ được truy xuất và hơn top-250 ví dụ được truy xuất cho +GOLD +MIS+PRED. Rõ ràng, bằng cách chọn các ví dụ được xếp hạng thấp hơn từ tập được truy xuất R(xt), chúng tôi đang hy sinh sự tương đồng ngữ nghĩa với đầu vào kiểm thử. Trong khi các nghiên cứu trước đây, như (Das et al., 2021; Liu et al., 2022; Margatina et al., 2023), đã chỉ ra rằng sự tương đồng ngữ nghĩa lớn hơn có thể nâng cao hiệu suất mô hình, chúng ta có thể thấy rằng các phương pháp của chúng tôi vẫn có thể vượt trội so với các baseline dựa trên bộ truy xuất ưu tiên nó.

**Tập nhãn mơ hồ là một proxy tốt cho nhãn sự thật kiểm thử.** Trong khi Min et al. (2022) thấy rằng việc sử dụng các ví dụ minh họa giả, tức là các ví dụ minh họa với nhãn ngẫu nhiên thay vì nhãn sự thật cơ bản, không ảnh hưởng nhiều đến hiệu suất downstream, Lyu et al. (2023) thấy rằng đối với các ví dụ minh họa tương tự với đầu vào kiểm thử, chẳng hạn như những ví dụ từ bộ truy xuất, các ví dụ minh họa giả làm tổn hại hiệu suất. Họ gọi đây là giả thuyết hiệu ứng sao chép nói rằng "dự đoán mô hình bị thiên lệch về các nhãn được ghép với các đầu vào trong các ví dụ minh họa, đặc biệt là khi các đầu vào tương tự với các đầu vào kiểm thử". Điều này, đến lượt nó, cho thấy rằng hiệu suất tốt nhất có thể đạt được nếu các nhãn được ghép với các đầu vào giống với nhãn sự thật của ví dụ kiểm thử. Cho rằng chúng ta không biết nhãn sự thật của ví dụ kiểm thử trước, câu hỏi sau đó trở thành làm thế nào để chúng ta xấp xỉ nhãn sự thật?. Chúng tôi thấy rằng tập nhãn mơ hồ của chúng tôi hoạt động như một proxy gần. Trong Bảng 5, chúng tôi tính toán có bao nhiều lần nhãn được ghép với các ví dụ minh họa ICL giống với nhãn sự thật của ví dụ kiểm thử. Chúng tôi thấy rằng 44.2% các ví dụ minh họa của các phương pháp đề xuất (AMBIG) có cùng nhãn sự thật với ví dụ kiểm thử trung bình, so với 30.9% từ phương pháp RETR. Đây là lý do tại sao việc bao gồm tập nhãn mơ hồ trong quá trình chọn ví dụ minh họa dẫn đến hiệu suất cao hơn. Phân tích này cũng làm sáng tỏ hiệu quả của ICL dựa trên bộ truy xuất. Từ Bảng 5 chúng ta có thể thấy rằng các ví dụ minh họa được chọn chỉ dựa trên sự tương đồng văn bản đầu vào chỉ kém 13.3 điểm phần trăm (trung bình) so với các phương pháp đề xuất của chúng tôi. Điều này xác nhận rằng việc tìm các ví dụ minh họa tương tự với văn bản đầu vào cũng dẫn đến việc chọn các ví dụ minh họa có nhãn sự thật 'có khả năng'.

**AMBIG-ICL giúp giảm sự nhầm lẫn của mô hình.** Để hiểu liệu việc bao gồm sự mơ hồ nhãn kiểm thử thực sự giúp giảm sự nhầm lẫn của mô hình, chúng tôi tính toán entropy mô hình trên phân phối xác suất dự đoán của các nhãn đầu ra trong Bảng 6. Nhìn chung, chúng tôi quan sát thấy rằng các phương pháp AMBIG-* của chúng tôi đạt entropy thấp nhất trên tất cả ba tập dữ liệu và mô hình. Điều này cho thấy rằng bằng cách xác định rõ ràng điểm nhầm lẫn của mô hình (trong trường hợp này là sự nhầm lẫn giữa các nhãn tinh tế) và chọn các ví dụ minh họa giúp giải quyết sự nhầm lẫn này thực sự hiệu quả trong việc giảm sự nhầm lẫn giữa các nhãn, và do đó dẫn đến hiệu suất downstream cao hơn (Bảng 2). Đặc biệt, chúng tôi thấy rằng đối với Flan-PaLM 2 (L), khoảng cách giữa các baseline few-shot và các phương pháp AMBIG-* lớn hơn, có lẽ vì các mô hình lớn hơn có thể sử dụng tốt hơn các ví dụ minh họa ICL (Chan et al., 2022; Akyürek et al., 2023; Wei et al., 2023).

Chúng tôi cũng tính toán hệ số tương quan Pearson giữa điểm F1 macro và entropy trung bình của phân phối xác suất dự đoán (được hiển thị trong Bảng 2 và Bảng 6, tương ứng), cho tất cả ba tập dữ liệu. Chúng tôi thấy rằng đối với mô hình Flan-PaLM 2 (L), có một tương quan âm cho tất cả ba tập dữ liệu, tức là r = -0.78 cho EDOS, -0.48 cho SST và -0.92 cho GoEmotions, điều này cho thấy rằng entropy thấp hơn chuyển thành hiệu suất nhiệm vụ cao hơn. Tuy nhiên, đối với Flan-PaLM 2 (M), chúng tôi có kết quả hỗn hợp, vì r dương cho EDOS (0.47), âm cho SST (-0.55), và gần bằng không cho GoEmotions (0.03).

## 5 Công trình liên quan

Hiệu suất của các mô hình ngôn ngữ lớn (LLM) bị ảnh hưởng đáng kể bởi chất lượng của các ví dụ minh họa ICL, như đã được chứng minh trong nhiều nghiên cứu (Zhao et al., 2021; Liu et al., 2022; Zhang et al., 2022). Do đó, việc tập trung vào việc truy xuất các ví dụ minh họa vượt trội đã tăng lên. Một chiến lược nổi bật là tinh chỉnh một bộ truy xuất cho các nhiệm vụ cụ thể bằng các chỉ số tương tự (Das et al., 2021; Hu et al., 2022; Poesia et al., 2022) hoặc bằng các điểm số dẫn xuất từ các mô hình ngôn ngữ (Rubin et al., 2022; Shi et al., 2022). Trong khi một số công trình giới thiệu một bộ truy xuất thống nhất được huấn luyện trên các nhiệm vụ khác nhau (Li et al., 2023; Cheng et al., 2023) để có tính tổng quát, một hướng khác là tận dụng các bộ truy xuất có sẵn. Liu et al., 2022 đề xuất một phương pháp dựa trên KNN để chọn các ví dụ minh họa ICL dựa trên sự tương đồng ngữ nghĩa; Margatina et al., 2023 chọn các ví dụ minh họa ICL với các thuật toán học tích cực dựa trên sự không chắc chắn, đa dạng, và tương tự, và cho thấy rằng việc chọn dựa trên sự tương đồng văn bản đầu vào liên tục vượt trội so với các phương pháp khác; và Agrawal et al., 2023 tập trung vào việc chọn các ví dụ minh họa đa dạng cũng như thúc đẩy sự chồng chéo n-gram giữa các ví dụ minh họa và các ví dụ kiểm thử. Trong công trình của chúng tôi, chúng tôi áp dụng phương pháp bộ truy xuất có sẵn vì trọng tâm của chúng tôi là chỉ ra tính tổng quát của phương pháp trên các nhiệm vụ phân loại khác nhau. Tuy nhiên, chúng tôi hy vọng rằng phương pháp của chúng tôi cũng sẽ có lợi từ một bộ truy xuất cụ thể cho nhiệm vụ. Ngoài ra, theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên tận dụng kiến thức hiện có của LLM xung quanh ví dụ kiểm thử để chọn ví dụ minh họa. Các công trình trước đây thường đã khám phá kiến thức hiện có của LLM, xem xét dự đoán mô hình cho dữ liệu huấn luyện.

Luo et al., 2023 sử dụng điểm dự đoán LLM trên dữ liệu huấn luyện để huấn luyện một bộ truy xuất cụ thể cho nhiệm vụ, và cũng sử dụng prompting Chain-of-Thought (Wei et al., 2022) để cải thiện hiệu suất mô hình. Một số công trình (Kumar and Talukdar, 2021; Lu et al., 2022) đã thấy rằng thứ tự của các ví dụ minh họa ICL cũng ảnh hưởng đến hiệu suất downstream, đó là lý do tại sao trong Bảng 2 chúng tôi báo cáo kết quả trên ba thứ tự xáo trộn. Các công trình này trực giao với công trình của chúng tôi nhưng có thể được sử dụng kết hợp với các phương pháp đề xuất của chúng tôi.

## 6 Kết luận và các bước tiếp theo

Trong công trình này, chúng tôi thấy rằng việc sử dụng kiến thức hiện có của LLM (ví dụ: dự đoán mô hình) liên quan đến không gian nhãn đầu ra của cả ví dụ kiểm thử và tập ví dụ minh họa ICL cũng quan trọng như việc xem xét sự tương đồng ngữ nghĩa của văn bản đầu vào một mình. Chúng tôi thấy rằng phương pháp đề xuất của chúng tôi liên tục vượt trội so với các baseline cho tất cả ba nhiệm vụ. Mặc dù, chúng tôi chỉ xem xét 2 nhãn mơ hồ hàng đầu trong việc chọn các ví dụ minh họa ICL, sẽ thú vị khi mở rộng tập nhãn mơ hồ thành hơn hai nhãn. Điều này đặc biệt quan trọng hơn đối với các tập dữ liệu như GoEmotions nơi không gian nhãn lớn và tinh tế hơn nhiều. Chúng tôi để lại nỗ lực này cho công trình tương lai. Hơn nữa, trong công trình này, chúng tôi tập trung vào các nhiệm vụ phân loại câu, do đó mở đường cho những người khác sử dụng các kỹ thuật đã chứng minh của chúng tôi để cũng khám phá sự mơ hồ nhãn cho các nhiệm vụ cấp token/span khác như Nhận dạng Thực thể Có tên (NER), và gắn thẻ Từ loại (POS).

## 7 Hạn chế

Chúng tôi tập trung vào việc giảm sự mơ hồ nhãn của LLM bằng cách kết hợp các ví dụ minh họa bị LLM phân loại sai và nằm trên ranh giới quyết định của ví dụ kiểm thử. Trong khi chúng tôi cho thấy hiệu quả của phương pháp này trên các tập dữ liệu, ngay cả những tập có cấu trúc nhãn chi tiết, các cạm bẫy tiềm ẩn vẫn tồn tại. Nếu nhãn sự thật thực tế của ví dụ kiểm thử thường lệch khỏi hai lựa chọn nhãn hàng đầu của LLM trong một tập dữ liệu hoặc mô hình cụ thể, điều này có thể chỉ ra hiệu suất không shot kém hoặc việc chọn tập nhãn mơ hồ có lỗi. Trong những trường hợp này, phương pháp của chúng tôi có thể dẫn đến hiệu suất không thỏa mãn, đòi hỏi những cải tiến thêm.

## 8 Tuyên bố đạo đức

Chúng tôi sử dụng các mô hình ngôn ngữ lớn (LLM) được huấn luyện trước cho phân loại văn bản. Đáng chú ý, các LLM được chứng minh là thể hiện thiên lệch, đây là một thách thức được công nhận rộng rãi và cộng đồng rộng lớn hiện đang làm việc để giải quyết. Vì mục tiêu chính của chúng tôi là cải thiện hiệu suất nhiệm vụ downstream, một hiệu suất được cải thiện trên một nhiệm vụ phân loại nội dung xúc phạm có thể bị lạm dụng. Đặc biệt, tập dữ liệu EDOS được sử dụng trong công trình của chúng tôi, chứa nội dung xúc phạm. Chúng tôi đã chọn tập dữ liệu này vì các sắc thái nhãn tinh tế của nó và để đảm bảo nghiên cứu của chúng tôi không bị thiên lệch bởi các mô hình vốn quen thuộc với dữ liệu.

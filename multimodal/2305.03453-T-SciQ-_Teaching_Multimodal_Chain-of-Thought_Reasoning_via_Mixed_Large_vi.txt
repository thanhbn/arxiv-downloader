# 2305.03453.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2305.03453.pdf
# Kích thước tệp: 1811548 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
T-SciQ: Dạy Suy luận Chuỗi Tư duy Đa phương thức thông qua Tín hiệu Mô hình Ngôn ngữ Lớn Hỗn hợp cho Trả lời Câu hỏi Khoa học

Lei Wang1, Yi Hu2, Jiabang He2, Xing Xu2, Ning Liu3, Hui Liu4, Heng Tao Shen2
1Đại học Quản lý Singapore 2Đại học Khoa học và Công nghệ Điện tử Trung Quốc
3Đại học Lâm nghiệp Bắc Kinh 4Công ty Công nghệ Rongda Bắc Kinh
lei.wang.2019@phdcs.smu.edu.sg, yihu0118@gmail.com, JiaBangH@outlook.com
xing.xu@uestc.edu.cn, liuning0928@bjfu.edu.cn, ryuki122382@gmail.com, shenhengtao@hotmail.com

Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLMs) gần đây đã chứng minh hiệu suất xuất sắc trong nhiều tác vụ Xử lý Ngôn ngữ Tự nhiên (NLP). Chúng cũng đã thể hiện khả năng thực hiện suy luận chuỗi tư duy (CoT) để giải quyết các vấn đề phức tạp. Các nghiên cứu gần đây đã khám phá suy luận CoT trong các tình huống đa phương thức phức tạp, chẳng hạn như tác vụ trả lời câu hỏi khoa học, bằng cách tinh chỉnh các mô hình đa phương thức với các lý luận CoT chất lượng cao được chú thích bởi con người. Tuy nhiên, việc thu thập các lý luận CoT chất lượng cao thường tốn thời gian và tốn kém. Bên cạnh đó, các lý luận được chú thích khó có thể chính xác do thiếu thông tin cần thiết bên ngoài. Để giải quyết những vấn đề này, chúng tôi đề xuất một phương pháp mới có tên T-SciQ nhằm dạy trả lời câu hỏi khoa học với tín hiệu LLM. Phương pháp T-SciQ tạo ra các lý luận CoT chất lượng cao như tín hiệu dạy học và được cải tiến để huấn luyện các mô hình nhỏ hơn nhiều để thực hiện suy luận CoT trong các phương thức phức tạp. Ngoài ra, chúng tôi giới thiệu một chiến lược trộn dữ liệu mới để tạo ra các mẫu dữ liệu dạy học hiệu quả hơn cho các vấn đề trả lời câu hỏi khoa học đơn giản và phức tạp. Kết quả thực nghiệm rộng rãi cho thấy phương pháp T-SciQ của chúng tôi đạt được hiệu suất tối tân mới trên điểm chuẩn ScienceQA, với độ chính xác 96,18%. Hơn nữa, phương pháp của chúng tôi vượt trội hơn đường cơ sở mạnh nhất được tinh chỉnh 4,5%. Mã nguồn được công bố tại https://github.com/T-SciQ/T-SciQ.

Giới thiệu
Giải quyết vấn đề khoa học gần đây đã được sử dụng để đánh giá khả năng suy luận đa bước và khả năng diễn giải của các hệ thống AI (Kembhavi et al. 2017; Sampat, Yang, and Baral 2020; Dalvi et al. 2021). Tuy nhiên, những bộ dữ liệu này (Kembhavi et al. 2017; Jansen et al. 2018) gặp vấn đề về quy mô hạn chế. Để giải quyết vấn đề này, Lu et al. (2022a) giới thiệu một bộ dữ liệu trả lời câu hỏi khoa học quy mô lớn trên các chủ đề và kỹ năng rộng rãi có tên ScienceQA. Bộ dữ liệu này bao gồm 21.208 ví dụ dữ liệu đa phương thức liên kết với các câu hỏi, bối cảnh, hình ảnh, lựa chọn, bài giảng và giải thích. Một ví dụ được minh họa trong Hình 1, cho thấy một mô hình phải hiểu các đầu vào đa phương thức và kết hợp kiến thức bên ngoài để trả lời các câu hỏi khoa học.

Gần đây, các Mô hình Ngôn ngữ Lớn (LLMs) đã thể hiện hiệu suất xuất sắc trong nhiều tác vụ Xử lý Ngôn ngữ Tự nhiên (NLP) (Brown et al. 2020; Thoppilan et al. 2022). Cụ thể, chúng đã chứng minh khả năng chuỗi tư duy (CoT) để giải quyết các vấn đề suy luận phức tạp bằng cách sử dụng một số ví dụ minh họa mà không cần huấn luyện bổ sung (Wei et al. 2022a; Kojima et al. 2022; Zhang et al. 2022). Tuy nhiên, nghiên cứu hiện tại về suy luận CoT chủ yếu bị giới hạn trong phương thức ngôn ngữ (Wang et al. 2022a; Zhou et al. 2022; Lu et al. 2022b; Fu et al. 2022), với ít sự chú ý đến các tình huống đa phương thức, chẳng hạn như trả lời câu hỏi khoa học. Để giải quyết vấn đề này, một phương pháp phổ biến là sử dụng các mô hình tạo chú thích để dịch thông tin thị giác thành phương thức ngôn ngữ và thúc đẩy LLMs thực hiện suy luận CoT (Lu et al. 2022a). Tuy nhiên, việc sử dụng các mô hình tạo chú thích trong các vấn đề khoa học có thể dẫn đến mất mát thông tin đáng kể khi gặp các hình ảnh có độ phức tạp cao. Để khắc phục vấn đề này, Zhang et al. (2023b) đề xuất một khung làm việc gọi là Multimodal-CoT mô hình cả phương thức ngôn ngữ và thị giác vào một quy trình tinh chỉnh hai giai đoạn, phân tách việc tạo lý luận và suy luận đáp án.

Phương pháp Multimodal-CoT có một bất lợi đáng kể vì nó phụ thuộc vào lý luận CoT được chú thích bởi con người để tinh chỉnh mô hình. Mặc dù việc kết hợp tín hiệu CoT được chú thích bởi con người hữu ích cho việc huấn luyện các mô hình để tạo điều kiện cho khả năng suy luận CoT, nhưng nó có hai hạn chế cơ bản. Thứ nhất, việc chú thích CoT bởi con người tốn thời gian (Nye et al. 2021; Cobbe et al. 2021), đặc biệt đối với các tác vụ phức tạp như ScienceQA, yêu cầu kiến thức chuyên môn rộng rãi để tạo ra quy trình suy luận cho đáp án. Thứ hai, như được thể hiện trong Hình 1, lý luận được chú thích có thể thiếu thông tin bên ngoài cần thiết để đưa ra đáp án cuối cùng do kiến thức chuyên môn hạn chế của những người chú thích.

Để giải quyết những vấn đề này, chúng tôi đề xuất một phương pháp mới có tên T-SciQ để giải quyết tác vụ ScienceQA. Khung làm việc T-SciQ được đề xuất bao gồm ba giai đoạn: tạo dữ liệu dạy học, trộn dữ liệu dạy học và tinh chỉnh. Đối với việc tạo dữ liệu dạy học, chúng tôi sử dụng một hướng dẫn zero-shot đơn giản và một gợi ý về đáp án đúng để tạo lý luận CoT cho một ví dụ dữ liệu QA để có được một mẫu QA-CoT. Mặc dù mô hình được dạy bởi các mẫu QA-CoT xuất sắc trong việc giải quyết các vấn đề đơn giản, nhưng nó vẫn gặp khó khăn với các vấn đề cực kỳ phức tạp. Để khắc phục thách thức này, chúng tôi theo dõi zero-shot plan-and-solve prompting (Wang et al. 2023) để tạo ra các lý luận CoT dựa trên kế hoạch (PCoT), phân tách các vấn đề phức tạp thành các vấn đề phụ đơn giản hơn để giải quyết, để có được các mẫu dạy học QA-PCoT. Để kết hợp điểm mạnh của cả hai tín hiệu dạy học, chúng tôi tạo ra một bộ dữ liệu dạy học mới có tên T-SciQ bằng cách trộn các bộ dữ liệu QA-CoT và QA-PCoT. Cụ thể, chúng tôi sử dụng tập validation để xác định xem tín hiệu dạy học PCoT hay tín hiệu dạy học CoT phù hợp hơn cho từng ví dụ dữ liệu trong một kỹ năng cụ thể. Sau đó, chúng tôi tinh chỉnh mô hình học sinh với dữ liệu dạy học. Chúng tôi tuân theo Multimodal-CoT (Zhang et al. 2023b) để xây dựng mô hình học sinh của mình, bao gồm hai giai đoạn: dạy tạo lý luận và dạy suy luận đáp án. Trong quá trình suy luận, mô hình được huấn luyện ở giai đoạn đầu tiên tạo ra các lý luận cho dữ liệu thử nghiệm. Các lý luận được tạo ra sau đó được sử dụng ở giai đoạn thứ hai để suy luận đáp án.

Kết quả thực nghiệm trên điểm chuẩn ScienceQA cho thấy phương pháp của chúng tôi vượt trội hơn so với trạng thái nghệ thuật trước đó với một khoảng cách lớn. Cụ thể, mô hình học sinh được dạy bởi các mẫu dạy học T-SciQ vượt trội hơn đường cơ sở mạnh nhất được tinh chỉnh 4,5%, đường cơ sở đa phương thức mạnh nhất dựa trên instruction-tuning 5,26%, đường cơ sở GPT-4 few-shot tốt nhất 9,64%, và hiệu suất con người 7,78%. Để chứng minh tính linh hoạt của phương pháp dạy học của chúng tôi, chúng tôi cũng tiến hành thực nghiệm để so sánh Reason-Teacher (Ho, Schmid, and Yun 2022) trên sáu tác vụ suy luận. Những đóng góp chính của chúng tôi được tóm tắt như sau: 1) Chúng tôi đề xuất một khung làm việc mới để tạo ra lý luận CoT chất lượng cao và huấn luyện các mô hình học sinh thực hiện suy luận CoT cho tác vụ ScienceQA; 2) Chúng tôi giới thiệu một chiến lược trộn dữ liệu để tạo ra các mẫu dữ liệu dạy học hiệu quả cho các vấn đề đơn giản và phức tạp; 3) Phương pháp của chúng tôi đạt được hiệu suất tối tân mới trên điểm chuẩn ScienceQA, vượt trội hơn tất cả các mô hình trước đó với khoảng cách lớn.

Công trình liên quan
Thúc đẩy Chuỗi Tư duy. Gần đây, để giải quyết các tác vụ suy luận phức tạp, Wei et al. (2022b) đề xuất thúc đẩy CoT bằng cách thúc đẩy các mô hình ngôn ngữ lớn tạo ra các quy trình suy luận trung gian trước khi đạt đến đáp án cuối cùng. Tiếp theo, nhiều công trình đã được đề xuất để cải thiện thêm việc thúc đẩy CoT từ các khía cạnh khác nhau, bao gồm cải thiện chất lượng của các minh chứng (Rubin, Herzig, and Berant 2021; Zhang et al. 2022; Fu et al. 2022; Lu et al. 2022b; He et al. 2023) và cải thiện chất lượng của các chuỗi suy luận (Zhou et al. 2022; Khot et al. 2022; Chen et al. 2022; Wang et al. 2022b,a; Li et al. 2022b; Tian et al. 2023). Zero-shot CoT (Kojima et al. 2022) kích thích bước suy luận bằng cách thêm một thúc đẩy như "Hãy suy nghĩ từng bước" vào câu hỏi thử nghiệm. Iterative Prompting (Wang, Deng, and Sun 2022) tổng hợp động các thúc đẩy có điều kiện trên ngữ cảnh của bước hiện tại. PoT Prompting (Chen et al. 2022) viết một chương trình như một lý luận và gọi khả năng suy luận của LLMs bằng cách thực thi chương trình được tạo ra. Chameleon (Lu et al. 2023) đề xuất một khung suy luận tổng hợp plug-and-play để sử dụng nhiều module để có được thúc đẩy chất lượng cao. Công trình của chúng tôi chủ yếu tập trung vào việc trộn các lý luận CoT dạy học khác nhau cho các vấn đề khác nhau.

LLMs như Giáo viên. Trong các nghiên cứu gần đây, suy luận CoT được kích thích trong các mô hình nhỏ bằng cách sử dụng các mô hình ngôn ngữ được tinh chỉnh. Magister et al. (2022) mang lại lợi ích cho các mô hình nhỏ hơn thông qua chưng cất CoT. Huang et al. (2022) cho thấy rằng LLMs có thể tăng cường suy luận bằng cách sử dụng các giải pháp tự tạo từ dữ liệu không gán nhãn. Ho, Schmid, and Yun (2022) đề xuất Fine-tune-CoT để tận dụng khả năng của LLMs tạo ra các mẫu suy luận và dạy các mô hình nhỏ hơn thông qua tinh chỉnh. Distilling step-by-step (Hsieh et al. 2023) cải thiện hiệu suất mô hình nhỏ bằng cách sử dụng lý luận LLM với ít dữ liệu hơn. Multimodal-CoT (Zhang et al. 2023b) sử dụng tinh chỉnh hai giai đoạn với các lý luận CoT được chú thích và tính năng thị giác để đạt được kết quả tối tân trên điểm chuẩn ScienceQA. Công trình của chúng tôi khai thác việc tạo ra hai loại dữ liệu dạy học từ LLMs và trộn dữ liệu dạy học. Chúng tôi khám phá rằng phương pháp đơn giản này cải thiện đáng kể hiệu suất của học sinh trong các tác vụ đa phương thức phức tạp, điều này chưa được công nhận trong các nghiên cứu trước về tinh chỉnh với suy luận CoT (Hsieh et al. 2023; Ho, Schmid, and Yun 2022; Huang et al. 2022; Magister et al. 2022; Fu et al. 2023; Hu et al. 2023).

Phương pháp T-SciQ của chúng tôi
Tổng quan
Phần này trình bày chiến lược tinh chỉnh được đề xuất T-SciQ, sử dụng một LLM có tên SciTeacher để tạo dữ liệu dạy học và cải thiện hiệu suất của một mô hình học sinh nhỏ hơn (SciStudent) bằng dữ liệu dạy học được tạo ra. Chiến lược T-SciQ được đề xuất bao gồm ba thành phần: tạo dữ liệu dạy học, trộn dữ liệu dạy học và tinh chỉnh, như được mô tả trong Hình 2. Để tạo dữ liệu dạy học, chúng tôi tận dụng SciTeacher để tạo ra các lý luận CoT để có được các mẫu Question-Answer-CoT (QA-CoT), và lý luận CoT dựa trên kế hoạch (PCoT) để có được các mẫu Question-Answer-PCoT (QA-PCoT). Để kết hợp điểm mạnh của cả hai bộ dữ liệu, chúng tôi tạo ra một bộ dữ liệu dạy học mới có tên T-SciQ bằng cách trộn các bộ dữ liệu QA-CoT và QA-PCoT. Cụ thể, chúng tôi sử dụng tập validation để xác định xem tín hiệu dạy học PCoT hay tín hiệu dạy học CoT phù hợp hơn cho từng ví dụ dữ liệu trong một kỹ năng cụ thể. Sau đó chúng tôi sử dụng các mẫu dạy học T-SciQ để tinh chỉnh các mô hình học sinh nhỏ hơn. Sau đây, chúng tôi cung cấp mô tả chi tiết về ba thành phần này.

Tạo Dữ liệu Dạy học
Chúng tôi tạo ra hai loại mẫu dữ liệu để dạy học: mẫu QA-CoT với lý luận CoT được tạo ra và mẫu QA-PCoT được trang bị lý luận PCoT được tạo ra.

Tạo Mẫu QA-CoT. Mặc dù việc sử dụng tín hiệu CoT được chú thích bởi con người có giá trị cho việc huấn luyện các mô hình để kích thích khả năng suy luận CoT, nhưng nó có hai hạn chế cố hữu: tốn thời gian và thiếu thông tin cần thiết bên ngoài do kiến thức chuyên môn hạn chế của những người chú thích.

Để giải quyết những vấn đề này, chúng tôi giới thiệu một thúc đẩy zero-shot để tạo ra các lý luận CoT chất lượng cao từ LLMs. Chúng tôi đạt được điều này bằng cách chuyển đổi ví dụ dữ liệu huấn luyện đầu vào X thành một thúc đẩy, sử dụng một mẫu đơn giản đọc như sau: "Question: [Xq]. Context: [Xc]. Options: [Xo]. Correct Answer: [A].[Instruct]". Ở đây, khe [Xq] dành cho câu hỏi đầu vào, khe [Xc] dành cho bối cảnh đầu vào, khe [Xo] chứa các tùy chọn có thể, khe [A] dành cho đáp án đúng có thể hoạt động như một gợi ý để hướng dẫn LLMs tạo ra lý luận đáng tin cậy hơn, và khe [Instruct] chứa các hướng dẫn, tức là "Vui lòng cho tôi một giải thích chi tiết.", để hướng dẫn LLMs thực hiện tác vụ. Lưu ý rằng bối cảnh có thể không được bao gồm cho một số ví dụ dữ liệu, trong trường hợp này khe bối cảnh được thay thế bằng "N/A". Tiếp theo, chúng tôi đưa thúc đẩy đã điền vào LLMs để xuất ra một quy trình suy luận cho một ví dụ dữ liệu huấn luyện cụ thể để có được dữ liệu QA-CoT DQA-CoT.

Tạo Mẫu QA-PCoT. Mặc dù việc sử dụng các mẫu QA-CoT có thể giải quyết các vấn đề của CoT được chú thích bởi con người, việc giải quyết các vấn đề cực kỳ phức tạp vẫn là một thách thức. Để khắc phục thách thức này và có được lý luận CoT dạy học phù hợp, chúng tôi giới thiệu một thúc đẩy zero-shot 3 bước để phân tách các vấn đề phức tạp thành các vấn đề phụ đơn giản hơn.

Bước 1: Tạo Bài giảng. Mẫu bài giảng được sử dụng để tạo ra một bài giảng cho một kỹ năng cụ thể được công thức hóa như sau: "Skill: [S]. QA pairs: [Xq, A]...[Instruct]." Trong thúc đẩy này, [Instruct] như sau: "dựa trên các vấn đề trên, vui lòng đưa ra một bài giảng tổng quát về loại câu hỏi [S] trong một câu.". Lưu ý rằng nhiều ví dụ QA cần cùng một kỹ năng để được giải quyết.

Bước 2: Tạo Kế hoạch. Mẫu được sử dụng để tạo ra một kế hoạch cho một kỹ năng cụ thể dựa trên bài giảng được tạo ra được công thức hóa như sau: "Skill: [S]. Lecture: [L]. QA pairs: [Xq, A]...[Instruct].". Trong thúc đẩy này, [Instruct] được viết như sau: "Dựa trên bài giảng trên và những vấn đề này, hãy hiểu những vấn đề này và đưa ra một kế hoạch tổng quát và ngắn gọn từng bước để giải quyết những vấn đề này (bắt đầu với 1, 2, 3...)".

Bước 3: Tạo Lý luận. Bài giảng và kế hoạch được tạo ra bởi hai thúc đẩy đầu tiên được sử dụng để tạo ra lý luận CoT dựa trên kế hoạch cho từng ví dụ huấn luyện. Mẫu tạo lý luận được công thức hóa như sau: "Skill: [S]. Lecture: [L]. Plan: [P]. QA pair: [Xq, A].[Instruct].". Trong thúc đẩy này, [Instruct] được viết như sau: "Dựa trên bài giảng, kế hoạch và vấn đề, vui lòng thực hiện kế hoạch và giải quyết vấn đề từng bước (bắt đầu với 1, 2, 3...)". Các ví dụ về thúc đẩy ba bước này có thể được tìm thấy trong tài liệu bổ sung.

Trộn Dữ liệu Dạy học
Bộ dữ liệu QA-PCoT hiệu quả cho việc dạy kỹ năng giải quyết vấn đề cho các vấn đề phức tạp, trong khi các vấn đề đơn giản hơn không yêu cầu phân tách. Ngược lại, bộ dữ liệu QA-CoT phù hợp cho việc dạy kỹ năng giải quyết vấn đề cho các vấn đề đơn giản. Để kết hợp điểm mạnh của cả hai bộ dữ liệu, chúng tôi tạo ra một bộ dữ liệu dạy học mới có tên T-SciQ bằng cách trộn các bộ dữ liệu QA-CoT và QA-PCoT. Chúng tôi giới thiệu một phương pháp mới sử dụng tập validation để xác định xem tín hiệu dạy học PCoT hay tín hiệu dạy học CoT phù hợp hơn cho một ví dụ dữ liệu trong một kỹ năng cụ thể.

Cho một vấn đề ScienceQA Pi với đầu vào ngôn ngữ Xi,la và đầu vào thị giác Xi,v, mục tiêu của chúng tôi là để một mô hình tạo đáp án Fs_a giúp xác định tín hiệu dạy học tối ưu Ti,k từ các lựa chọn có thể Ti, tức là tín hiệu dạy học CoT Ti,cot hoặc tín hiệu dạy học PCoT Ti,pcot, từ đó tối đa hóa độ chính xác đáp án của tập validation. Module tạo đáp án Fs_a tương tự như module được mô tả trong Multimodal-CoT (Zhang et al. 2023b). Đáp án được tạo ra Âi được tạo ra bởi Fs_a(Xi,la, Xi,v, Ti,k), và số lượng lỗi được thu được bằng cách so sánh đáp án được tạo ra Âi và nhãn Ai. Nếu số lượng lỗi cho các mẫu validation với PCoT trong một kỹ năng thấp hơn so với các mẫu validation với CoT trong một kỹ năng, chúng tôi chọn lý luận PCoT làm lý luận dạy học cho tất cả các ví dụ dữ liệu huấn luyện trong kỹ năng này. Ngược lại, chúng tôi chọn lý luận CoT. Các mẫu dạy học thu được sau đó được sử dụng để tinh chỉnh mô hình học sinh. Để huấn luyện module tạo đáp án, chúng tôi sử dụng một tập con của các ví dụ dữ liệu huấn luyện, mỗi ví dụ được liên kết với tín hiệu dạy học được chú thích bởi con người từ bộ dữ liệu ScienceQA gốc.

Tinh chỉnh
Việc dạy học của chúng tôi tuân theo khung tinh chỉnh hai giai đoạn Multimodal-CoT (Zhang et al. 2023b): dạy tạo lý luận và dạy suy luận đáp án.

Dạy Tạo Lý luận. Trong giai đoạn này, mô hình tạo lý luận Fr(Pi) được huấn luyện để dự đoán tín hiệu dạy học Ti cho một vấn đề Pi cụ thể, trong đó Ti có thể là lý luận CoT hoặc lý luận PCoT. Đầu vào của Fr(Pi) bao gồm X1i,la và Xi,v, trong đó X1i,la đại diện cho đầu vào ngôn ngữ và Xi,v đại diện cho đầu vào thị giác. Chính thức, xác suất tạo lý luận Ti có thể được công thức hóa như sau:

p(Ti∣Xi,la1, Xi,v)=NTi ∏ j=1 pθr(Ti,j∣X1i,la, Xi,v, Ti,<j), (1)

trong đó θr đại diện cho các tham số có thể học được của mô hình tạo lý luận Fr và NTi là độ dài của Ti.

Dạy Suy luận Đáp án. Trong giai đoạn thứ hai, chúng tôi xây dựng đầu vào ngôn ngữ X2i,la bằng cách thêm lý luận dạy học Ti vào đầu vào ngôn ngữ gốc X1i,la. Đầu vào mới X′i sau đó được đưa vào mô hình suy luận đáp án để suy luận đáp án cuối cùng Ai=Fa(X′i), trong đó X′i={X2i,la, Xi,v}. Chính thức, xác suất tạo đáp án Ai có thể được công thức hóa như sau:

p(Ai∣X2i,la, Xi,v)=NAi ∏ j=1 pθa(Ai∣X2i,la, Xi,v, Ai,<j), (2)

trong đó θa đại diện cho các tham số có thể học được trong giai đoạn dạy suy luận đáp án.

Kiến trúc Mô hình Chúng tôi sử dụng kiến trúc mô hình Multimodal-CoT (Zhang et al. 2023b) làm mặc định, sử dụng mô hình Transformer (Vaswani et al. 2017) để mã hóa ngôn ngữ và một vision Transformer để mã hóa thông tin thị giác. Cơ chế fusion có cổng, được đề xuất trong (Li et al. 2022a), được sử dụng để tích hợp hiệu quả các biểu diễn ngôn ngữ và thị giác. Cuối cùng, một decoder Transformer được sử dụng để tạo ra đầu ra mục tiêu. Lưu ý rằng tạo lý luận và suy luận đáp án chia sẻ cùng một mô hình nhưng khác nhau về đầu vào và đầu ra.

Thực nghiệm
Thiết lập Thực nghiệm
Bộ dữ liệu. Chúng tôi đánh giá phương pháp được đề xuất trên bộ dữ liệu ScienceQA (Lu et al. 2022a), một bộ dữ liệu câu hỏi khoa học đa phương thức trắc nghiệm mới nhất bao gồm 21.208 ví dụ. ScienceQA bao gồm một loạt các chủ đề trên ba môn học riêng biệt: khoa học tự nhiên, khoa học xã hội và khoa học ngôn ngữ. Bộ dữ liệu bao gồm 26 chủ đề, 127 danh mục và 379 kỹ năng liên quan đến ba môn học này. Chúng tôi sử dụng phần chia chính thức được cung cấp bởi ScienceQA, chia bộ dữ liệu thành các tập huấn luyện, validation và test với tỷ lệ 3:1:1, tức là 12.726, 4.241 và 4.241 ví dụ tương ứng. Bộ dữ liệu bao gồm các chuỗi suy luận được chú thích cho từng ví dụ dữ liệu. Trong công trình này, chúng tôi trích xuất các tín hiệu huấn luyện từ các mô hình ngôn ngữ lớn thay vì sử dụng các tín hiệu được chú thích bởi con người.

Đường cơ sở. Chúng tôi cung cấp so sánh phương pháp được đề xuất với các phương pháp đường cơ sở rộng rãi. Cụ thể, chúng tôi có một số mô hình VQA ban đầu, bao gồm MCAN (Yu et al. 2019), Top-Down (Anderson et al. 2018), BAN (Kim, Jun, and Zhang 2018), DFAF (Gao et al. 2019). Các đường cơ sở VQA này sử dụng câu hỏi, bối cảnh và lựa chọn đáp án như đầu vào văn bản và hình ảnh như đầu vào thị giác. Chúng dự đoán một phân phối điểm số trên các ứng viên đáp án bằng cách sử dụng một bộ phân loại tuyến tính. Ngoài ra, chúng tôi bao gồm các mô hình text-to-text và đa phương thức được pre-trained như ViLT (Kim, Son, and Kim 2021), Patch-TRM (Lu et al. 2021), và VisualBERT (Li et al. 2019), UnifiedQA (Khashabi et al. 2020), MM-COT (Zhang et al. 2023b). Các phương pháp này sử dụng các mô hình pre-trained làm mô hình backbone và kết hợp các module bổ sung để xử lý tín hiệu đa phương thức nếu cần thiết. Chúng tôi cũng bao gồm các đường cơ sở đa phương thức được tinh chỉnh dựa trên LLM gần đây như LLaMa-Adapter (Zhang et al. 2023a) và LLaVA (Liu et al. 2023). Chúng sử dụng một LLM mã nguồn mở mạnh như LLaMa (Touvron et al. 2023) làm mô hình cơ sở và kết hợp một module thị giác để mô hình thông tin thị giác. Chúng tôi cũng bao gồm các đường cơ sở in-context learning được sử dụng rộng rãi: thúc đẩy chuỗi tư duy (CoT) (Wei et al. 2022a), trong đó mỗi ví dụ minh chứng in-context bao gồm câu hỏi đầu vào và quy trình suy luận được chú thích đầu ra. Chúng tôi so sánh với các đường cơ sở CoT trên các LLM OpenAI dựa trên API khác nhau (OpenAI 2022, 2023), như GPT-3.5 (GPT-3.5 w/ COT), ChatGPT (ChatGPT w/ COT), GPT-4 (GPT-4 w/ COT), và Chameleon (Lu et al. 2023). Ngoài ra, chúng tôi cũng so sánh với phương pháp thúc đẩy few-shot tiêu chuẩn sử dụng GPT-3.5 (GPT-3.5).

Chỉ số Đánh giá. Vì ScienceQA là một điểm chuẩn cho trả lời câu hỏi trắc nghiệm, độ chính xác của đáp án được đánh giá bằng cách so sánh tùy chọn sự thật cơ bản với dự đoán cuối cùng được tạo ra bởi mô hình được đánh giá.

Chi tiết Triển khai. Theo mặc định, chúng tôi sử dụng GPT-3.5 của phiên bản text-davinci-003 làm mô hình giáo viên cho phương pháp của chúng tôi trừ khi được chỉ định khác. Để xác thực tính tổng quát của phương pháp, chúng tôi thử nghiệm với ba mô hình học sinh khác biệt, cụ thể là UnifiedQA Base w/ CoT (Lu et al. 2022a), Multimodal-CoT Base (Lu et al. 2022a), và Multimodal-CoT Large (Zhang et al. 2023b). Các mô hình này được chọn do hiệu suất mạnh mẽ được đạt bằng tinh chỉnh với tín hiệu suy luận được chú thích. Để đảm bảo sự công bằng trong so sánh và hiệu quả của phương pháp được đề xuất, chúng tôi chỉ thay thế các tín hiệu huấn luyện được tạo ra bởi phương pháp của chúng tôi với các tín hiệu được chú thích trong khi duy trì cùng thiết lập như bài báo gốc. Các mô hình học sinh này nhỏ hơn 200 lần so với các mô hình giáo viên của chúng.

Kết quả Chính
T-SciQ so với Đường cơ sở. Bảng 1 chi tiết độ chính xác hiệu suất của các đường cơ sở và các mô hình học sinh được huấn luyện bằng tín hiệu T-SciQ được đề xuất. Multimodal-T-SciQ Large, là kiến trúc mô hình của Multimodal-CoT Large được tinh chỉnh với tín hiệu giáo viên hỗn hợp, đạt độ chính xác 96,18% và vượt trội nhất quán so với tất cả các phương pháp tối tân với khoảng cách lớn cho tất cả các chủ đề trên tất cả các môn học. Cụ thể, Multimodal-T-SciQ Large vượt trội hơn đường cơ sở tinh chỉnh mạnh nhất, Multimodal-CoT Large, được huấn luyện bởi tín hiệu chuỗi tư duy được chú thích, 4,5% (91,68% → 96,18%), đường cơ sở đa phương thức mạnh nhất dựa trên instruction-tuning, LLaVa, 5,26% (90,92% → 96,18%), đường cơ sở GPT-4 few-shot tốt nhất, Chameleon, 9,64% (86,54% → 96,18%), và hiệu suất con người 7,78% (88,40% → 96,18%). Cải thiện đáng kể này của phương pháp được đề xuất cho thấy rằng các tín hiệu dạy học chất lượng cao hơn về lập kế hoạch và suy luận được cung cấp bởi LLMs kích thích khả năng lập kế hoạch và suy luận chuỗi tư duy tốt hơn trong các mô hình học sinh nhỏ hơn 1B.

T-SciQ với Các Mô hình Học sinh Cơ sở Khác nhau. Thay vì chỉ sử dụng kiến trúc mô hình của Multimodal-CoT Large làm mô hình học sinh cơ sở, chúng tôi đánh giá các mô hình học sinh cơ sở khác nhau được tinh chỉnh với tín hiệu dạy học hỗn hợp: biến thể UnifiedQA-T-SciQ Base và Multimodal-T-SciQ Base. Thứ hạng hiệu suất tương đối giữa mô hình học sinh cơ sở với tín hiệu CoT được chú thích và mô hình với tín hiệu giáo viên hỗn hợp vẫn không thay đổi. Cụ thể, UnifiedQA-T-SciQ Base vượt trội hơn UnifiedQA Base w/ CoT 5,3% (74,11% → 79,41%), và Multimodal-T-SciQ Base vượt trội hơn Multimodal-CoT Base 6,84% (84,91% → 91,75%). T-SciQ vẫn đạt được hiệu suất tốt nhất với các mô hình học sinh cơ sở khác nhau. Những kết quả khích lệ này cho thấy tính tổng quát của các tín hiệu dạy học được đề xuất.

Phân tích Thêm
Tác động của Các Tín hiệu Khác nhau của T-SciQ. Phương pháp của chúng tôi kết hợp hai thành phần khác biệt cho tín hiệu dạy học: QA-CoT và QA-PCoT. Chúng tôi đã cho thấy sớm rằng việc kết hợp hai tín hiệu này (tức là Multimodal-T-SciQ) mang lại kết quả tốt hơn đáng kể so với chỉ sử dụng tín hiệu CoT được chú thích bởi con người (tức là Multimodal-CoT) khi dạy các mô hình học sinh. Trong phần này, chúng tôi nhằm đánh giá tác động của từng tín hiệu dạy học bằng cách kiểm tra hiệu suất của Multimodal-T-SciQ Base và Multimodal-T-SciQ Large khi một trong hai tín hiệu QA-CoT hoặc QA-PCoT bị loại bỏ. Như được chứng minh trong Bảng 2, chúng tôi có thể quan sát sự giảm đáng kể về độ chính xác trả lời khi một trong hai tín hiệu dạy học bị loại bỏ. Những phát hiện này cho thấy hiệu quả của cả hai tín hiệu dạy học được đề xuất. Điều này là do 1) các mô hình học sinh được dạy bởi tín hiệu QA-CoT có thể kết hợp một loạt kiến thức rộng rãi hơn từ thế giới mở thay vì chỉ dựa vào kiến thức của những người chú thích và 2) các mô hình học sinh được dạy bởi tín hiệu QA-PCoT có thể phân tách các vấn đề phức tạp thành một số vấn đề phụ đơn giản hơn.

Tác động của Tính năng Thị giác. Việc lựa chọn tính năng thị giác có thể ảnh hưởng đáng kể đến hiệu suất của các mô hình trên ScienceQA. Do đó, chúng tôi tiến hành đánh giá ba tính năng thị giác được sử dụng rộng rãi, đó là CLIP (Radford et al. 2021), DETR (Carion et al. 2020), và ResNet (He et al. 2016). Cả CLIP và DETR đều có thể cung cấp tính năng cấp patch, và DETR được thiết kế để phát hiện đối tượng. Đối với tính năng ResNet, chúng tôi sử dụng ResNet-50 để tạo ra tính năng thị giác. Bảng 3 cho thấy kết quả so sánh ba tính năng thị giác này. Phát hiện của chúng tôi cho thấy rằng việc kết hợp tính năng thị giác mang lại hiệu suất vượt trội hơn so với việc dựa vào đường cơ sở chỉ có ngôn ngữ. Đáng chú ý, DETR nhất quán vượt trội hơn hai tính năng khác trong hầu hết các trường hợp, và do đó, chúng tôi áp dụng nó làm tính năng thị giác mặc định trong các thực nghiệm chính.

Tỷ lệ Dữ liệu Được Tạo ra trong Dữ liệu Huấn luyện. Để so sánh thêm các tín hiệu T-SciQ được tạo ra bởi LLMs và các tín hiệu CoT được chú thích, chúng tôi thử nghiệm với việc điều chỉnh tỷ lệ của hai tín hiệu này trong dữ liệu huấn luyện. Chúng tôi thay đổi tỷ lệ của tín hiệu T-SciQ từ 0% đến 100%. Như được chứng minh trong Hình 3a, tỷ lệ tăng của dữ liệu huấn luyện với tín hiệu T-SciQ làm tăng hiệu suất.

Thay đổi Hiệu suất theo Epoch. Hình 3b cho thấy xu hướng hiệu suất của đường cơ sở Multimodal-CoT Base và Multimodal-T-SciQ Base được đề xuất qua các epoch huấn luyện khác nhau. Đáng chú ý, phương pháp của chúng tôi nhất quán vượt trội hơn đường cơ sở qua tất cả các epoch. Chúng tôi áp dụng phương pháp huấn luyện hai giai đoạn tương tự như đường cơ sở Multimodal-CoT Base, trong đó chúng tôi đầu tiên huấn luyện module tạo giải thích và sau đó huấn luyện dự đoán đáp án. Do đó, giống như đường cơ sở, phương pháp của chúng tôi thể hiện độ chính xác tương đối cao hơn ở các giai đoạn huấn luyện ban đầu.

Tác động của Tín hiệu Dạy học Được Cung cấp bởi Các LLM Cơ sở Khác nhau. Chúng tôi sử dụng mô hình GPT-3.5 theo mặc định, cụ thể là phiên bản text-davinci-003, để tạo ra tín hiệu dạy học trong thực nghiệm chính. Tuy nhiên, các LLM mạnh mẽ khác cũng có thể cung cấp tín hiệu hữu ích, như phiên bản trước đó của GPT-3.5, text-davinci-002, và mô hình ChatGPT phổ biến gần đây. Nghiên cứu này khám phá hiệu quả của hỗn hợp tín hiệu QA-CoT từ text-davinci-002, text-davinci-003, hoặc ChatGPT, và tín hiệu QA-PCoT từ các mô hình dựa trên API trên. Chúng tôi tiến hành thực nghiệm này sử dụng Multimodal-T-SciQ Base. Hình 4a cho thấy so sánh hiệu suất của chín chiến lược hỗn hợp khác nhau. Kết quả của chúng tôi cho thấy rằng ngay cả chiến lược tồi tệ nhất, liên quan đến hỗn hợp tín hiệu QA-CoT từ text-davinci-003 và tín hiệu QA-PCoT từ text-davinci-002, vẫn vượt trội hơn tín hiệu CoT được chú thích với khoảng cách đáng kể. Điều này cho thấy rằng bất kể chiến lược hỗn hợp nào được sử dụng, LLMs có thể cung cấp tín hiệu với kiến thức hữu ích hơn từ thế giới mở.

Phân tích Lỗi. Để hiểu rõ hơn về hành vi của mô hình được huấn luyện bằng tín hiệu T-SciQ được đề xuất, chúng tôi phân tích sáu kỹ năng được chọn được hiển thị trong Hình 4b. Nó cho thấy phân tích lỗi của dự đoán cho sáu kỹ năng cụ thể (A-F), tức là "Sử dụng từ hướng dẫn", "So sánh tính chất của các đối tượng", "Đọc bản đồ: hướng chính", "Xác định đại dương và lục địa", "Nhiệt độ liên quan đến năng lượng nhiệt như thế nào?", và "Xác định Mười Ba Thuộc địa", tương ứng. Chúng tôi có thể quan sát rằng việc huấn luyện với tín hiệu T-SciQ có thể giảm đáng kể số lượng lỗi. Các ví dụ về kỹ năng như "Xác định đại dương và lục địa" yêu cầu suy luận phức tạp đa bước mà tín hiệu dạy học T-SciQ có thể dạy. Mặt khác, các ví dụ về kỹ năng như "Đọc bản đồ: hướng chính" yêu cầu kiến thức thường thức và thực tế từ thế giới mở, mà tín hiệu T-SciQ cũng có thể cung cấp.

Nghiên cứu Trường hợp. Nghiên cứu trường hợp so sánh T-SciQ và Multimodal-CoT trên điểm chuẩn ScienceQA (Hình 5). Hình 5a cho thấy các trường hợp cần kiến thức địa lý. CoT được chú thích bởi con người có thể thiếu thông tin thế giới mở, trong khi T-SciQ bao gồm nó. Hình 5b cho thấy một trường hợp suy luận đa bước không có đầu vào hình ảnh. Multimodal-CoT gặp lỗi trong khi mô hình của chúng tôi phân tách và trả lời chính xác. Những điều này làm nổi bật rằng T-SciQ phù hợp để xử lý các vấn đề yêu cầu kiến thức mở và phân tách.

So sánh trên Các Bộ dữ liệu Suy luận NLP Khác. Để xác minh tính linh hoạt của phương pháp dạy học, chúng tôi bổ sung đánh giá phương pháp trên sáu tác vụ suy luận, theo Reason-Teacher (Ho, Schmid, and Yun 2022): số học (Aqua (Ling et al. 2017)), biểu tượng (Coin Flip (Wei et al. 2022b)), thường thức (CommonSenseQA (Talmor et al. 2018), StrategyQA (Geva et al. 2021)) suy luận, và logic (Date Understanding, Tracking Shuffled Objects) (Geva et al. 2021). Trong Bảng 4, chúng tôi so sánh T-SciQ với các tín hiệu dạy học suy luận đa dạng được giới thiệu bởi Reason-Teacher. Kết quả cho thấy rằng T-SciQ vượt trội hơn Reason-Teacher với khoảng cách lớn trong 5 trên 6 bộ dữ liệu. Nó hoạt động tương đương tốt trong bộ dữ liệu còn lại, Coin Flip. Những kết quả này cho thấy rằng tín hiệu dạy học chất lượng cao hơn về lập kế hoạch và suy luận có thể dẫn đến cải thiện đáng kể trong các mô hình học sinh nhỏ trên các tình huống khác nhau.

Kết luận
Bài báo này giới thiệu một phương pháp mới có tên T-SciQ sử dụng khả năng suy luận chuỗi tư duy (CoT) của các mô hình ngôn ngữ lớn để dạy các mô hình đa phương thức nhỏ cho các tác vụ trả lời câu hỏi khoa học phức tạp. Phương pháp thúc đẩy zero-shot của chúng tôi tạo ra các mẫu QA-CoT như dữ liệu dạy học. Chúng tôi cũng trình bày một phương pháp thúc đẩy zero-shot 3 bước sử dụng CoT dựa trên kế hoạch cho các vấn đề cực kỳ phức tạp. Hơn nữa, chiến lược hỗn hợp dữ liệu của chúng tôi kết hợp CoT và CoT dựa trên kế hoạch để tạo ra một bộ dữ liệu dạy học T-SciQ mới. Đánh giá thực nghiệm trên ScienceQA cho thấy cải thiện đáng kể so với các đường cơ sở tối tân trước đó. Phương pháp của chúng tôi khắc phục các hạn chế của CoT được chú thích bởi con người, cung cấp một phương pháp đầy hứa hẹn cho trả lời câu hỏi khoa học phức tạp. Công trình tương lai bao gồm khám phá các LLM rộng rãi và tinh chỉnh hiệu quả tham số với các giáo viên LLM.

Tài liệu tham khảo
Anderson, P.; He, X.; Buehler, C.; Teney, D.; Johnson, M.; Gould, S.; và Zhang, L. 2018. Bottom-up and top-down attention for image captioning and visual question answering. Trong Proceedings of the IEEE conference on computer vision and pattern recognition, 6077–6086.

Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33: 1877–1901.

Carion, N.; Massa, F.; Synnaeve, G.; Usunier, N.; Kirillov, A.; và Zagoruyko, S. 2020. End-to-End Object Detection with Transformers. Trong Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part I, 213–229.

Chen, T.; Kornblith, S.; Swersky, K.; Norouzi, M.; và Hinton, G. E. 2020. Big self-supervised models are strong semi-supervised learners. Advances in neural information processing systems, 33: 22243–22255.

Chen, W.; Ma, X.; Wang, X.; và Cohen, W. W. 2022. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588.

Cobbe, K.; Kosaraju, V.; Bavarian, M.; Chen, M.; Jun, H.; Kaiser, L.; Plappert, M.; Tworek, J.; Hilton, J.; Nakano, R.; et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168.

Dalvi, B.; Jansen, P.; Tafjord, O.; Xie, Z.; Smith, H.; Pipatanangkura, L.; và Clark, P. 2021. Explaining answers with entailment trees. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP).

Fu, Y.; Peng, H.; Ou, L.; Sabharwal, A.; và Khot, T. 2023. Specializing Smaller Language Models towards Multi-Step Reasoning. arXiv preprint arXiv:2301.12726.

Fu, Y.; Peng, H.; Sabharwal, A.; Clark, P.; và Khot, T. 2022. Complexity-based prompting for multi-step reasoning. arXiv preprint arXiv:2210.00720.

Gao, P.; Jiang, Z.; You, H.; Lu, P.; Hoi, S. C.; Wang, X.; và Li, H. 2019. Dynamic fusion with intra-and inter-modality attention flow for visual question answering. Trong Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 6639–6648.

Geva, M.; Khashabi, D.; Segal, E.; Khot, T.; Roth, D.; và Berant, J. 2021. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9: 346–361.

He, J.; Wang, L.; Hu, Y.; Liu, N.; Liu, H.; Xu, X.; và Shen, H. T. 2023. ICL-D3IE: In-context learning with diverse demonstrations updating for document information extraction. arXiv preprint arXiv:2303.05063.

He, K.; Zhang, X.; Ren, S.; và Sun, J. 2016. Deep Residual Learning for Image Recognition. Trong 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, 770–778. IEEE Computer Society.

Ho, N.; Schmid, L.; và Yun, S.-Y. 2022. Large Language Models Are Reasoning Teachers. arXiv preprint arXiv:2212.10071.

Hsieh, C.-Y.; Li, C.-L.; Yeh, C.-K.; Nakhost, H.; Fujii, Y.; Ratner, A.; Krishna, R.; Lee, C.-Y.; và Pfister, T. 2023. Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes. arXiv preprint arXiv:2305.02301.

Hu, Z.; Lan, Y.; Wang, L.; Xu, W.; Lim, E.-P.; Lee, R. K.-W.; Bing, L.; và Poria, S. 2023. LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models. arXiv preprint arXiv:2304.01933.

Huang, J.; Gu, S. S.; Hou, L.; Wu, Y.; Wang, X.; Yu, H.; và Han, J. 2022. Large language models can self-improve. arXiv preprint arXiv:2210.11610.

Jansen, P. A.; Wainwright, E.; Marmorstein, S.; và Morrison, C. T. 2018. Worldtree: A corpus of explanation graphs for elementary science questions supporting multi-hop inference. arXiv preprint arXiv:1802.03052.

Kembhavi, A.; Seo, M.; Schwenk, D.; Choi, J.; Farhadi, A.; và Hajishirzi, H. 2017. Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 4999–5007.

Khashabi, D.; Min, S.; Khot, T.; Sabharwal, A.; Tafjord, O.; Clark, P.; và Hajishirzi, H. 2020. Unifiedqa: Crossing format boundaries with a single qa system. arXiv preprint arXiv:2005.00700.

Khot, T.; Trivedi, H.; Finlayson, M.; Fu, Y.; Richardson, K.; Clark, P.; và Sabharwal, A. 2022. Decomposed prompting: A modular approach for solving complex tasks. arXiv preprint arXiv:2210.02406.

Kim, J.-H.; Jun, J.; và Zhang, B.-T. 2018. Bilinear attention networks. Advances in neural information processing systems, 31.

Kim, W.; Son, B.; và Kim, I. 2021. Vilt: Vision-and-language transformer without convolution or region supervision. Trong International Conference on Machine Learning, 5583–5594. PMLR.

Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y.; và Iwasawa, Y. 2022. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916.

Li, B.; Lv, C.; Zhou, Z.; Zhou, T.; Xiao, T.; Ma, A.; và Zhu, J. 2022a. On Vision Features in Multimodal Machine Translation. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 6327–6337.

Li, L. H.; Yatskar, M.; Yin, D.; Hsieh, C.-J.; và Chang, K.-W. 2019. Visualbert: A simple and performant baseline for vision and language. arXiv preprint arXiv:1908.03557.

Li, Y.; Lin, Z.; Zhang, S.; Fu, Q.; Chen, B.; Lou, J.-G.; và Chen, W. 2022b. On the advance of making language models better reasoners. arXiv preprint arXiv:2206.02336.

Ling, W.; Yogatama, D.; Dyer, C.; và Blunsom, P. 2017. Program induction by rationale generation: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146.

Liu, H.; Li, C.; Wu, Q.; và Lee, Y. J. 2023. Visual instruction tuning. arXiv preprint arXiv:2304.08485.

Lu, P.; Mishra, S.; Xia, T.; Qiu, L.; Chang, K.-W.; Zhu, S.-C.; Tafjord, O.; Clark, P.; và Kalyan, A. 2022a. Learn to explain: Multimodal reasoning via thought chains for science question answering. Advances in Neural Information Processing Systems, 35: 2507–2521.

Lu, P.; Peng, B.; Cheng, H.; Galley, M.; Chang, K.-W.; Wu, Y. N.; Zhu, S.-C.; và Gao, J. 2023. Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models. arXiv preprint arXiv:2304.09842.

Lu, P.; Qiu, L.; Chang, K.-W.; Wu, Y. N.; Zhu, S.-C.; Rajpurohit, T.; Clark, P.; và Kalyan, A. 2022b. Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning. arXiv preprint arXiv:2209.14610.

Lu, P.; Qiu, L.; Chen, J.; Xia, T.; Zhao, Y.; Zhang, W.; Yu, Z.; Liang, X.; và Zhu, S.-C. 2021. Iconqa: A new benchmark for abstract diagram understanding and visual language reasoning. arXiv preprint arXiv:2110.13214.

Magister, L. C.; Mallinson, J.; Adamek, J.; Malmi, E.; và Severyn, A. 2022. Teaching small language models to reason. arXiv preprint arXiv:2212.08410.

Nye, M.; Andreassen, A. J.; Gur-Ari, G.; Michalewski, H.; Austin, J.; Bieber, D.; Dohan, D.; Lewkowycz, A.; Bosma, M.; Luan, D.; et al. 2021. Show your work: Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114.

OpenAI. 2022. Introducing chatgpt. https://openai.com/blog/chatgpt.

OpenAI. 2023. GPT-4 Technical Report. CoRR, abs/2303.08774.

Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; et al. 2021. Learning transferable visual models from natural language supervision. Trong International Conference on Machine Learning, 8748–8763. PMLR.

Rubin, O.; Herzig, J.; và Berant, J. 2021. Learning to retrieve prompts for in-context learning. arXiv preprint arXiv:2112.08633.

Sampat, S. K.; Yang, Y.; và Baral, C. 2020. Visuo-Lingustic Question Answering (VLQA) Challenge. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings (EMNLP), 4606–4616.

Talmor, A.; Herzig, J.; Lourie, N.; và Berant, J. 2018. Commonsenseqa: A question answering challenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937.

Thoppilan, R.; De Freitas, D.; Hall, J.; Shazeer, N.; Kulshreshtha, A.; Cheng, H.-T.; Jin, A.; Bos, T.; Baker, L.; Du, Y.; et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239.

Tian, Q.; Zhu, H.; Wang, L.; Li, Y.; và Lan, Y. 2023. R3 Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context. arXiv preprint arXiv:2310.16535.

Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux, M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; và Polosukhin, I. 2017. Attention is All you Need. Trong Advances in Neural Information Processing Systems 30, 5998–6008.

Wang, B.; Deng, X.; và Sun, H. 2022. Iteratively prompt pre-trained language models for chain of thought. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2714–2730.

Wang, L.; Xu, W.; Lan, Y.; Hu, Z.; Lan, Y.; Lee, R. K.-W.; và Lim, E.-P. 2023. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models. arXiv preprint arXiv:2305.04091.

Wang, X.; Wei, J.; Schuurmans, D.; Le, Q.; Chi, E.; và Zhou, D. 2022a. Rationale-augmented ensembles in language models. arXiv preprint arXiv:2207.00747.

Wang, X.; Wei, J.; Schuurmans, D.; Le, Q.; Chi, E.; và Zhou, D. 2022b. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171.

Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi, E.; Le, Q.; và Zhou, D. 2022a. Chain of Thought Prompting Elicits Reasoning in Large Language Models. ArXiv preprint, abs/2201.11903.

Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi, E.; Le, Q.; và Zhou, D. 2022b. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903.

Yu, Z.; Yu, J.; Cui, Y.; Tao, D.; và Tian, Q. 2019. Deep modular co-attention networks for visual question answering. Trong Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 6281–6290.

Zhang, R.; Han, J.; Zhou, A.; Hu, X.; Yan, S.; Lu, P.; Li, H.; Gao, P.; và Qiao, Y. 2023a. Llama-adapter: Efficient fine-tuning of language models with zero-init attention. arXiv preprint arXiv:2303.16199.

Zhang, Z.; Zhang, A.; Li, M.; và Smola, A. 2022. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2210.03493.

Zhang, Z.; Zhang, A.; Li, M.; Zhao, H.; Karypis, G.; và Smola, A. 2023b. Multimodal chain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923.

Zhou, D.; Schärli, N.; Hou, L.; Wei, J.; Scales, N.; Wang, X.; Schuurmans, D.; Bousquet, O.; Le, Q.; và Chi, E. 2022. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625.

Phân tích Chi tiết Hơn
Ngoài việc khám phá tác động của các tính năng thị giác khác nhau, chúng tôi cũng đã thử nghiệm hiệu suất của các backbone khác nhau. Bảng 5 cho thấy kết quả của UnifiedQA và FLAN-T5 trên các bộ dữ liệu được tạo ra. Khi sử dụng các mạng backbone khác nhau, mô hình được huấn luyện bởi dữ liệu QA-CoT là tồi tệ nhất trong ba loại dữ liệu được tạo ra. Tuy nhiên, nó cũng tốt hơn dữ liệu được chú thích thủ công, điều này cho thấy dữ liệu được chú thích thủ công có những hạn chế nhất định, như thông tin dư thừa, phong cách đơn điệu, v.v. Hơn nữa, khi sử dụng bộ dữ liệu Hỗn hợp của QA-CoT và QA-PCoT, thực tế là tất cả bốn backbone đều đạt được hiệu suất tốt nhất minh họa tính hiệu quả và tổng quát của chiến lược của chúng tôi.

Phân tích Trường hợp Nhiều Hơn
Để điều tra tác động của các tín hiệu dạy học khác nhau, chúng tôi đã tiến hành đánh giá các dự đoán mô hình được huấn luyện trên các loại dữ liệu khác nhau, bao gồm cả dữ liệu dạy học được tạo ra và dữ liệu được chú thích thủ công. Cụ thể, chúng tôi đã so sánh các ví dụ thử nghiệm được tạo ra bởi mô hình được huấn luyện với dữ liệu được chú thích thủ công (MM-CoT) và dữ liệu dạy học QA-CoT (T-SciQ (QA-CoT)) trong Hình 6. Chúng tôi cũng hiển thị các trường hợp dự đoán của các mô hình được huấn luyện trên dữ liệu được chú thích thủ công (MM-CoT) và dữ liệu dạy học QA-PCoT (T-SciQ (QA-PCoT)) trong Hình 7. Hơn nữa, chúng tôi đã so sánh các trường hợp dự đoán của các mô hình được huấn luyện bằng dữ liệu dạy học được đề xuất, QA-CoT và QA-PCoT, như được mô tả trong Hình 8 và Hình 9. Từ các hình, rõ ràng rằng mô hình được huấn luyện với dữ liệu QA-PCoT hoạt động tốt hơn trong việc giải quyết các vấn đề suy luận đa bước, trong khi mô hình được huấn luyện với QA-CoT thành thạo hơn trong việc giải quyết các vấn đề đơn giản.

Quy trình Tạo Dữ liệu của PCoT
Trong phần này, chúng tôi trình bày một số trường hợp về cách tạo ra tín hiệu dạy học PCoT. Để có được lý luận chuỗi tư duy dựa trên kế hoạch phù hợp, chúng tôi giới thiệu phương pháp thúc đẩy zero-shot 3 bước cho phép các Mô hình Ngôn ngữ phân tách các vấn đề phức tạp thành các vấn đề phụ đơn giản hơn dễ giải quyết hơn.

Mẫu bài giảng được sử dụng để tạo ra một bài giảng cho một kỹ năng cụ thể được công thức hóa như sau: "Skill: [S]. QA pairs: [Xq, A]...[Instruct]." Trong thúc đẩy này, [Instruct] như sau: "dựa trên các vấn đề trên, vui lòng đưa ra một bài giảng tổng quát về loại câu hỏi [S] trong một câu.". Bài giảng được tạo ra cho kỹ năng này sẽ được sử dụng trong bước thứ hai của việc thúc đẩy, tạo điều kiện cho việc tạo ra kế hoạch của LLM cho kỹ năng này. Các ví dụ về tạo bài giảng được hiển thị trong Bảng 7.

Mẫu được sử dụng để tạo ra một kế hoạch cho một kỹ năng cụ thể dựa trên một bài giảng được công thức hóa như sau: "Skill: [S]. Lecture: [L]. QA pairs: [Xq, A]...[Instruct].". Trong thúc đẩy này, [Instruct] được viết như sau: "Dựa trên bài giảng trên và những vấn đề này, hãy hiểu những vấn đề này và đưa ra một kế hoạch tổng quát và ngắn gọn từng bước để giải quyết những vấn đề này (bắt đầu với 1, 2, 3...)". Kế hoạch được tạo ra bằng mẫu này sẽ được sử dụng trong giai đoạn thứ ba của việc thúc đẩy để hỗ trợ LLM xây dựng lý luận chuỗi tư duy dựa trên kế hoạch cho từng ví dụ huấn luyện. Các ví dụ được hiển thị trong Bảng 8.

Bài giảng và kế hoạch được tạo ra bởi hai thúc đẩy đầu tiên được sử dụng để tạo ra lý luận chuỗi tư duy dựa trên kế hoạch cho từng ví dụ huấn luyện. Mẫu tạo lý luận được công thức hóa như sau: "Skill: [S]. Lecture: [L]. Plan: [P]. QA pairs: [Xq, A]...[Instruct].". Trong thúc đẩy này, [Instruct] được viết như sau: "Dựa trên bài giảng, kế hoạch và vấn đề, vui lòng thực hiện kế hoạch và giải quyết vấn đề từng bước (bắt đầu với 1, 2, 3...)". Phương pháp thúc đẩy này cung cấp một chiến lược giải quyết vấn đề bằng cách tận dụng chuyên môn của bài giảng và kế hoạch, và sử dụng khung suy luận có cấu trúc để giải quyết từng vấn đề. Các ví dụ được hiển thị trong Bảng 9.

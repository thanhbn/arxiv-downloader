# 2401.00246.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2401.00246.pdf
# Kích thước tệp: 458251 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tăng cường Mô hình Ngôn ngữ Lớn cho Tổng hợp Giọng nói:
Một Nghiên cứu Thực nghiệm
Hongkun Hao1∗, Long Zhou2, Shujie Liu2, Jinyu Li2, Shujie Hu2, Rui Wang1, Furu Wei2
1Đại học Giao thông Thượng Hải
2Tập đoàn Microsoft
Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) đã có những tiến bộ đáng kể trong xử lý ngôn ngữ tự nhiên và đồng thời mở rộng khả năng ngôn ngữ sang các phương thức khác, như giọng nói và thị giác. Tuy nhiên, phần lớn công việc trước đây tập trung vào việc thúc đẩy LLM với khả năng nhận thức như hiểu âm thanh, và phương pháp hiệu quả để tăng cường LLM với khả năng tổng hợp giọng nói vẫn còn mơ hồ. Trong bài báo này, chúng tôi tiến hành một khám phá thực nghiệm toàn diện để tăng cường LLM với khả năng tạo giọng nói, bằng cách kết hợp mô hình LLM được đào tạo trước LLaMA/OPT và mô hình tổng hợp văn bản thành giọng nói V ALL-E. Chúng tôi so sánh ba phương pháp tích hợp giữa LLM và mô hình tổng hợp giọng nói, bao gồm LLM được tinh chỉnh trực tiếp, các lớp chồng chất của LLM và V ALL-E, và LLM kết hợp với V ALL-E sử dụng LLM như một bộ mã hóa văn bản mạnh mẽ. Kết quả thực nghiệm cho thấy rằng, việc sử dụng phương pháp LoRA để tinh chỉnh LLM trực tiếp nhằm tăng cường khả năng tổng hợp giọng nói không hoạt động tốt, và LLM chồng chất với V ALL-E có thể cải thiện chất lượng giọng nói được tạo ra cả về độ tương tự giọng nói và tỷ lệ lỗi từ (WER). Trong ba phương pháp này, phương pháp kết hợp tận dụng LLM làm bộ mã hóa văn bản có thể đạt hiệu suất tốt nhất, làm cho nó vượt trội so với các mô hình tổng hợp giọng nói gốc với độ tương tự giọng nói tốt hơn nhất quán và giảm đáng kể WER (10,9%).

1 Giới thiệu
Sự xuất hiện của các mô hình ngôn ngữ lớn (LLM), như ChatGPT [OpenAI, 2023a] và LLaMA [Touvron et al., 2023], đã cách mạng hóa hầu hết các tác vụ xử lý ngôn ngữ tự nhiên (NLP) truyền thống, như tóm tắt văn bản và hệ thống đối thoại. Khả năng tạo ngôn ngữ mạnh mẽ của LLM đã thúc đẩy việc khám phá ứng dụng của chúng trong các phương thức khác, ví dụ như giọng nói và thị giác [OpenAI, 2023b, Huang et al., 2023, Zhang et al., 2023b]. Ví dụ, GPT-4V [OpenAI, 2023b] cho phép người dùng hướng dẫn GPT-4 phân tích đầu vào hình ảnh mà họ cung cấp. Video-LLaMA [Zhang et al., 2023b] trao quyền cho LLM khả năng hiểu cả nội dung thị giác và âm thanh có trong video. Các LLM đa phương thức này cung cấp tiềm năng để tăng cường tác động của các hệ thống chỉ có văn bản bằng cách tích hợp các giao diện và chức năng mới, cho phép chúng xử lý các tác vụ mới và mang lại trải nghiệm mới cho người dùng.

Về việc ứng dụng LLM vào giọng nói, phần lớn nghiên cứu trước đây chủ yếu tập trung vào việc căn chỉnh biểu diễn giọng nói với không gian đầu vào của LLM [Wu et al., 2023, Fathullah et al., 2023, Shu et al., 2023, Tang et al., 2023]. Ví dụ, Speech-LLaMA [Wu et al., 2023] đề xuất một phương pháp hiệu quả để hoàn thành các tác vụ giọng nói thành văn bản bằng cách tận dụng mô hình Phân loại Thời gian Kết nối (CTC) [Graves et al., 2006] và bộ mã hóa âm thanh để ánh xạ các đặc trưng âm thanh nén vào không gian ngữ nghĩa liên tục của LLM. LLaSM [Shu et al., 2023] tận dụng bộ mã hóa Whisper được đào tạo tốt để mã hóa tín hiệu giọng nói thành các trạng thái ẩn, và sử dụng một bộ điều hợp phương thức để căn chỉnh các trạng thái ẩn đầu ra trên với nhúng văn bản đầu vào của LLM. So với việc hiểu giọng nói, việc cho phép LLM tạo giọng nói là thách thức lớn hơn đáng kể, vì giọng nói là một tín hiệu liên tục khác biệt đáng kể so với không gian đầu ra của LLM. Để kích hoạt khả năng tạo giọng nói, các công trình hiện tại như SpeechGPT [Zhang et al., 2023a] và AudioPaLM [Rubenstein et al., 2023] sử dụng phương pháp tinh chỉnh trực tiếp một LLM được đào tạo trước, điều này đòi hỏi tài nguyên tính toán và thời gian đáng kể. Cách tăng cường hiệu quả LLM với khả năng tổng hợp giọng nói vẫn là một lĩnh vực tương đối chưa được khám phá.

Để hiểu rõ hơn về tác vụ này, chúng tôi sẽ trả lời hai câu hỏi: 1) Liệu các mã codec có thể được LLM xử lý đơn giản như một loại ngôn ngữ tương tự như các ngôn ngữ tự nhiên khác không? 2) LLM có thể cung cấp loại thông tin nào để cải thiện chất lượng giọng nói được tổng hợp? Để trả lời hai câu hỏi này, trong bài báo này, chúng tôi đề xuất và so sánh một số phương pháp tích hợp để cho phép LLM có khả năng tổng hợp giọng nói. Trong nghiên cứu này, chúng tôi tập trung vào các tác vụ văn bản thành giọng nói (TTS) không cần mẫu theo mô hình tiên tiến V ALL-E [Wang et al., 2023a], mô hình này chủ yếu sử dụng một mô hình giải mã Transformer tự hồi quy (AR) để dự đoán token rời rạc của giọng nói dựa trên các token văn bản tương ứng. Để tăng cường việc tạo giọng nói của LLM, trước tiên chúng tôi rời rạc hóa giọng nói liên tục thành các mã codec rời rạc đa lớp thông qua mô hình nén âm thanh Encodec [Défossez et al., 2022], và mở rộng từ vựng của LLM với từ vựng của mã codec, ví dụ 1024 token. Chúng tôi thiết kế ba chiến lược kết hợp để đạt được dự đoán mã codec lớp đầu tiên với LLM, như mô hình AR trong V ALL-E, như sau:

• LLM được tinh chỉnh trực tiếp. Chúng tôi tinh chỉnh trực tiếp các mô hình ngôn ngữ lớn thông qua văn bản và mã codec được ghép nối từ bộ dữ liệu nhận dạng giọng nói, với các tham số đầy đủ hoặc tham số từng phần (LoRA [Hu et al., 2021]), như được hiển thị trong Hình 1(a).

• LLM chồng chất và V ALL-E. Hình 1(b) minh họa chiến lược này mà chúng tôi chồng chất hai mô hình thành một mô hình. Trong phương pháp này, chúng tôi sử dụng mô hình ngôn ngữ lớn để mã hóa cả token văn bản và token âm thanh, và sau đó chúng tôi đưa chúng vào mô hình ngôn ngữ codec V ALL-E.

• LLM kết hợp và V ALL-E. Như được hiển thị trong Hình 1(c), chúng tôi sử dụng một mô hình ngôn ngữ lớn dựa trên văn bản bổ sung để mã hóa chuỗi văn bản và sau đó đưa chúng vào mô hình AR V ALL-E. Phương pháp kết hợp khác với phương pháp chồng chất nói trên ở chỗ nó không sử dụng LLM để mô hình hóa mã codec.

Sau đó, chúng tôi có thể sử dụng mô hình không tự hồi quy (NAR) của V ALL-E để tạo các mã codec của các bộ lượng tử hóa còn lại, và sử dụng bộ giải mã Encodec để khôi phục dạng sóng của giọng nói. Các mô hình được đào tạo trên dữ liệu tiếng Anh Multilingual Librispeech 44,5K giờ và dữ liệu LibriSpeech 960 giờ và được đánh giá trên các bộ dữ liệu LibriSpeech dev-clean, dev-other, test-clean, và test-other. Kết quả thực nghiệm cho thấy rằng LLM kết hợp và V ALL-E có thể đạt hiệu suất tốt nhất trong số các phương pháp cơ sở và của chúng tôi. Ngoài ra, chúng tôi thực hiện phân tích kỹ lưỡng về các khía cạnh khác nhau của phương pháp của chúng tôi, xem xét tác động của kích thước mô hình, lợi ích của việc đào tạo trước liên tục, hiệu ứng của V ALL-E được đào tạo trước, và đánh giá so sánh LoRA với tinh chỉnh hoàn toàn cho V ALL-E. Dựa trên kết quả, chúng tôi có thể rút ra kết luận như sau:

• Mã codec không thể được xử lý đơn giản như một ngôn ngữ khác vì kết quả của LLM được tinh chỉnh trực tiếp không hứa hẹn. Lý do có thể là, độ dài chuỗi của mã codec dài hơn nhiều so với độ dài của văn bản tương ứng, và cũng thông tin được cung cấp bởi mã codec chi tiết hơn nhiều và đa dạng hơn so với văn bản.

• Mặc dù LLM với LoRA có thể không xuất sắc trong việc tạo mã codec, chúng có thể phục vụ như một bộ mã hóa thống nhất để xử lý cả mã văn bản và mã codec. Các đầu ra được tạo bởi LLM có thể cung cấp biểu diễn có giá trị cho một mô hình ngôn ngữ codec (ví dụ, V ALL-E) để tạo ra mã codec chính xác hơn.

• LLM có thể được sử dụng như một bộ mã hóa văn bản mạnh mẽ một mình có thể mô hình hóa thông tin nội dung phù hợp và rộng rãi, điều này có tác dụng quan trọng cho V ALL-E để tạo giọng nói chất lượng cao hơn và tăng cường độ bền. Cấu trúc sử dụng LLM như một bộ mã hóa văn bản, kết hợp với một mô-đun giải mã chuyên dụng như V ALL-E, đạt hiệu suất tốt nhất.

--- TRANG 2 ---
2 Công trình liên quan
Công trình của chúng tôi thường dựa trên LLM, đã có những đột phá đáng kể trong xử lý ngôn ngữ tự nhiên, vượt trội so với các mô hình tiên tiến trước đây trong các tác vụ NLP rộng rãi, và truyền cảm hứng cho khả năng tuân theo hướng dẫn để đạt được các tác vụ chưa từng thấy [Ouyang et al., 2022, OpenAI, 2023a, Touvron et al., 2023, Anil et al., 2023]. Sự xuất hiện của ChatGPT [Ouyang et al., 2022] đánh dấu một kỷ nguyên chuyển đổi trong lĩnh vực trí tuệ nhân tạo. Bằng cách tận dụng các bộ dữ liệu đào tạo khổng lồ và cấu hình tham số rộng rãi, kết hợp với điều chỉnh hướng dẫn và thuật toán RLHF, nó nâng cao khả năng xuất hiện tuyệt vời và trở thành trợ lý trí tuệ nhân tạo tốt nhất với ngôn ngữ tự nhiên như một giao diện.

Cho rằng thông tin của thế giới không chỉ bao gồm văn bản mà còn bao gồm các phương tiện như giọng nói và hình ảnh, việc mở rộng từ các mô hình ngôn ngữ lớn dựa trên văn bản đơn phương thức sang LLM đa phương thức là một ý tưởng tự nhiên [Tang et al., 2023, Huang et al., 2023, Zhang et al., 2023b, Driess et al., 2023, Moon et al., 2023, Chu et al., 2023]. Phần lớn công việc này tập trung vào việc tăng cường lĩnh vực nhận thức của LLM, cho phép chúng hiểu cụ thể các khả năng âm thanh và thị giác. Ví dụ, LLaVA [Liu et al., 2023] kết hợp một bộ mã hóa thị giác và LLM thành một mô hình đầu cuối cho hiểu ngôn ngữ thị giác đa mục đích với khả năng trò chuyện ấn tượng. Speech-LLaMA [Wu et al., 2023] và SALMONN [Tang et al., 2023] cố gắng nhận thức và hiểu tất cả các loại đầu vào âm thanh với một bộ mã hóa âm thanh bổ sung. Khác với công việc trên, mục tiêu của công việc chúng tôi là thúc đẩy LLM tạo giọng nói thay vì hiểu giọng nói.

Công việc của chúng tôi cũng liên quan đến các mô hình tạo âm thanh lớn [Borsos et al., 2022, Wang et al., 2023a, Zhang et al., 2023c, Rubenstein et al., 2023, Zhang et al., 2023a, Chen et al., 2023]. V ALL-E [Chen et al., 2023] là một mô hình văn bản thành giọng nói không cần mẫu mới và tiên tiến, chứa một mô hình Transformer tự hồi quy (AR) và một mô hình Transformer không tự hồi quy (NAR) để dự đoán các mã lượng tử hóa lớp đầu tiên và các mã lượng tử hóa lớp còn lại một cách riêng biệt. Công việc của chúng tôi tuân theo khung kiến trúc AR V ALL-E để tổng hợp giọng nói với LLM được tăng cường. Bên cạnh đó, SpeechGPT [Zhang et al., 2023a] và AudioPaLM [Rubenstein et al., 2023] chuyển đổi giọng nói thành các đơn vị ẩn rời rạc và liên tục đào tạo trước LLM với kho dữ liệu đơn vị ẩn. LauraGPT [Chen et al., 2023] cũng tinh chỉnh hoàn toàn LLM với các mã codec rời rạc của giọng nói, để kích hoạt khả năng tạo giọng nói. Tuy nhiên, không có công trình nào đã khám phá việc sử dụng các mô hình tổng hợp giọng nói hiện có (ví dụ, V ALL-E) để trao quyền cho khả năng tạo giọng nói của LLM. Bài báo này tập trung vào việc điều tra thực nghiệm và so sánh các phương pháp khác nhau để trao cho LLM khả năng tổng hợp giọng nói.

3 Phương pháp luận
Trong phần này, chúng tôi sẽ trước tiên giới thiệu các thành phần mô hình cốt lõi trong khung đề xuất trong tiểu mục 3.1, bao gồm mô hình ngôn ngữ lớn, mô hình nén giọng nói, và mô hình ngôn ngữ codec, sau đó trình bày ba chiến lược tích hợp cho LLM và V ALL-E trong tiểu mục 3.2.

3.1 Các thành phần mô hình
Có ba thành phần cốt lõi trong khung của chúng tôi bao gồm một mô hình ngôn ngữ lớn (tức là, OPT [Zhang et al., 2022] hoặc LLaMA [Touvron et al., 2023]), một mô hình nén giọng nói (tức là, Encodec [Défossez et al., 2022]), và một mô hình ngôn ngữ codec (tức là, V ALL-E [Wang et al., 2023a]). Mô hình ngôn ngữ lớn được sử dụng để mô hình hóa các token văn bản, với tùy chọn bao gồm cả token âm thanh. Trong khi đó, mô hình nén giọng nói có nhiệm vụ chuyển đổi giọng nói liên tục thành các mã codec rời rạc và sau đó tái tạo giọng nói từ những mã này. Ngoài ra, mô hình ngôn ngữ codec được sử dụng để tạo mã codec dựa trên biểu diễn của các token văn bản.

Mô hình Ngôn ngữ Lớn Chúng tôi tiến hành các thí nghiệm rộng rãi sử dụng nhiều mô hình ngôn ngữ lớn được đào tạo trước khác nhau bao gồm các mô hình OPT [Zhang et al., 2022] với các kích thước khác nhau bao gồm 125M, 350M, và 1.3B, và mô hình LLaMA-7B [Touvron et al., 2023]. Những mô hình chỉ có bộ giải mã này sẽ được điều chỉnh sử dụng phương pháp tinh chỉnh đầy đủ hoặc các phương pháp tinh chỉnh hiệu quả tham số như Thích ứng Hạng thấp (LoRA) [Hu et al., 2021]. Mô hình OPT-125M/350M/1.3B là một bộ giải mã Transformer 12/24/24 lớp với chiều chú ý lần lượt là 768/1024/2048. Mô hình LLaMA-7B là một bộ giải mã Transformer 32 lớp với chiều chú ý là 4096.

--- TRANG 3 ---
Mô hình Nén Giọng nói Để kích hoạt LLM với khả năng tạo giọng nói, chúng tôi sử dụng một mô hình nén giọng nói bên ngoài EnCodec [Défossez et al., 2022] để chuyển đổi giọng nói liên tục thành các mã codec rời rạc. Mô hình EnCodec là một mạng mã hóa-giải mã dựa trên tích chập với phương pháp lượng tử hóa vector dư (RVQ). Trước tiên nó token hóa dữ liệu giọng nói thành các token âm thanh L lớp sử dụng bộ mã hóa EnCodec và mô-đun RVQ, sau đó khôi phục dạng sóng giọng nói từ tất cả các token âm thanh sử dụng bộ giải mã EnCodec. Trong bài báo này, chúng tôi điều chỉnh EnCodec với băng thông 6 kbps và L=8 token cho mỗi khung hình.

Mô hình Ngôn ngữ Codec Mô hình ngôn ngữ codec thần kinh V ALL-E [Wang et al., 2023a] xử lý tổng hợp văn bản thành giọng nói như một tác vụ mô hình ngôn ngữ, như GPT, và sử dụng các token âm thanh (mã codec âm thanh) làm biểu diễn trung gian của giọng nói gốc. Theo biểu diễn văn bản, V ALL-E tạo ra các chuỗi mã codec (8 mã cho mỗi khung hình), từ đó có thể khôi phục dạng sóng cuối cùng bằng một bộ giải mã nén âm thanh (ví dụ, Encodec). V ALL-E chứa hai mô-đun chính, mô hình ngôn ngữ codec tự hồi quy (AR) và mô hình ngôn ngữ codec không tự hồi quy (NAR). Mô hình đầu tiên chịu trách nhiệm dự đoán các token âm thanh của mã codec đầu tiên cho mỗi khung hình dựa trên các token ngữ nghĩa theo cách tự hồi quy, và mô hình thứ hai được sử dụng để tạo ra 7 mã lớp khác theo chuỗi của các mã lớp đầu tiên song song với phương pháp tạo lặp theo cấp độ lớp. Trong công việc này, chúng tôi tuân theo mô hình AR V ALL-E, có kiến trúc mô hình giống hệt với LLM, để tăng cường LLM với khả năng tổng hợp giọng nói.

3.2 Chiến lược tích hợp
Chúng tôi đề xuất ba phương pháp để thúc đẩy các mô hình ngôn ngữ lớn với khả năng tổng hợp giọng nói. Hình 1 minh họa các phương pháp khác nhau, bao gồm LLM được tinh chỉnh trực tiếp (Phương pháp A), LLM chồng chất và V ALL-E (Phương pháp B), và LLM kết hợp và V ALL-E (Phương pháp C). Ban đầu, chúng tôi đề xuất tinh chỉnh trực tiếp LLM trong Phương pháp A để xác định liệu các token âm thanh có thể được tích hợp vào LLM bằng cách xử lý chúng như một ngôn ngữ mới. Hơn nữa, thông qua Phương pháp B, chúng tôi đánh giá khả năng của LLM để mã hóa cả token âm thanh và token văn bản vào một không gian nhúng liên tục thống nhất, tăng cường hiệu suất của V ALL-E trong các tác vụ văn bản thành giọng nói. Cuối cùng, trong Phương pháp C, chúng tôi khám phá tiềm năng của việc chỉ tận dụng khả năng mã hóa văn bản của LLM để cải thiện kết quả TTS mà không coi các token âm thanh như một ngôn ngữ mới.

Phương pháp A: LLM được tinh chỉnh trực tiếp Để xác minh liệu các token âm thanh có thể được kết hợp vào LLM bằng cách đơn giản coi nó như một ngôn ngữ mới, cho phép đào tạo chung của cả token âm thanh và token văn bản, phương pháp đơn giản nhất bao gồm việc tinh chỉnh trực tiếp các mô hình ngôn ngữ với dữ liệu đào tạo TTS bằng tinh chỉnh đầy đủ hoặc tinh chỉnh hiệu quả tham số, như được hiển thị trong Hình 1(a). Thông qua đào tạo trên dữ liệu TTS, chúng tôi cũng tăng cường các mô hình ngôn ngữ lớn với khả năng tổng hợp giọng nói cùng lúc. Trong thực tế, chúng tôi phát hiện rằng việc sử dụng các phương pháp tinh chỉnh hiệu quả tham số như LoRA theo cách này ít hiệu quả hơn và dẫn đến hiệu suất tương đối kém. Chúng tôi suy đoán rằng điều này là do các mô hình ngôn ngữ lớn không có khả năng tạo mã codec vốn có và việc tạo giọng nói khó khăn hơn cho LLM so với hiểu tín hiệu giọng nói. Do đó, chúng tôi tinh chỉnh đầy đủ trực tiếp LLM như một loại phương pháp trao cho LLM khả năng tổng hợp giọng nói.

Phương pháp B: LLM chồng chất và V ALL-E Được truyền cảm hứng từ quan sát của Phương pháp A được giới thiệu ở trên, chúng tôi nhằm khám phá thêm về sự phù hợp của LLM để mã hóa cả token âm thanh và token văn bản vào không gian nhúng liên tục để biểu diễn này có thể được V ALL-E sử dụng để thực hiện các tác vụ TTS tốt hơn. Như được hiển thị trong Hình 1(b), trong phương pháp này, chúng tôi chồng chất các mô hình LLM được đào tạo trước và V ALL-E để thúc đẩy khả năng tạo giọng nói của LLM. Cả token văn bản và token âm thanh đều được mã hóa bởi LLM, và được gửi đến mô hình ngôn ngữ codec để dự đoán mã codec lớp đầu tiên. Bên cạnh đó, một lớp chiếu tuyến tính được thêm vào giữa LLM và mô hình ngôn ngữ codec để kết nối khoảng cách chiều giữa chúng.

Phương pháp C: LLM kết hợp và V ALL-E Cho rằng vai trò và điểm mạnh khác biệt của LLM và V ALL-E, sẽ thú vị khi điều tra hiệu ứng của việc chỉ sử dụng khả năng mã hóa văn bản của LLM, thay vì xử lý các token âm thanh như một ngôn ngữ mới trong các phương pháp trước, để thúc đẩy hiệu suất TTS của V ALL-E. Do đó, một ý tưởng tự nhiên khác là tận dụng đầy đủ ưu điểm của LLM và V ALL-E, và nối tiếp các LLM được đào tạo trước và V ALL-E thành một mô hình đầu cuối. LLM xuất sắc trong việc mã hóa và tạo văn bản, trong khi V ALL-E chuyên tạo ra các token giọng nói dựa trên các token văn bản. Do đó, trong khung văn bản thành giọng nói này, trước tiên chúng tôi sử dụng LLM để mã hóa văn bản và có được biểu diễn văn bản tốt hơn, sau đó đưa nó vào V ALL-E làm đầu vào văn bản, như được hiển thị trong Hình 1(c). Trong phương pháp này, chúng tôi cũng kết hợp một lớp chiếu tuyến tính giữa LLM và mô hình ngôn ngữ codec để hòa giải sự chênh lệch về chiều.

4 Thí nghiệm
4.1 Thiết lập thí nghiệm
Bộ dữ liệu: Các mô hình được đào tạo trước được tinh chỉnh trên hai bộ dữ liệu ASR, cũng có thể được sử dụng để đào tạo các tác vụ TTS như V ALL-E (X) [Wang et al., 2023a, Zhang et al., 2023c]. Cụ thể, chúng tôi sử dụng LibriSpeech (LS, 960 giờ) [Panayotov et al., 2015] và phần tiếng Anh của Multilingual LibriSpeech (MLS) [Pratap et al., 2020]1. Multilingual LibriSpeech là một kho dữ liệu ASR 50K giờ bao gồm 8 ngôn ngữ có nguồn gốc từ sách nói đọc của LibriVox, trong đó tiếng Anh chiếm khoảng 44,5K giờ chiếm ưu thế. Chúng tôi đánh giá các phương pháp đề xuất trên các bộ dữ liệu LibriSpeech dev-clean, dev-other, test-clean, và test-other. Chúng tôi sử dụng các mẫu có thời lượng từ 4 đến 20 giây từ những bộ dữ liệu này2. Theo Wang et al. [2023a], chúng tôi sử dụng 3 giây đầu tiên của giọng nói thật làm lời nhắc cho mỗi lần tổng hợp mẫu. Mỗi thí nghiệm được tiến hành ba lần, với điểm trung bình được báo cáo.

Xử lý trước dữ liệu: Để thống nhất việc đào tạo các phương thức giọng nói và văn bản, chúng tôi chuyển đổi cả hai thành các token rời rạc. Trong phương pháp của chúng tôi, phiên âm dữ liệu ASR được token hóa thành các từ con (token ngữ nghĩa) với tokenizer từ các mô hình ngôn ngữ lớn. Trong khi đó, dữ liệu giọng nói được lượng tử hóa thành các token âm thanh sử dụng EnCodec, hoạt động ở băng thông 6 kbps và tỷ lệ downsampling 320, tạo ra 8 token âm thanh mỗi khung hình và 75 khung hình mỗi giây âm thanh. Chúng tôi nối các token ngữ nghĩa và các token âm thanh tương ứng để tạo thành một mẫu đào tạo liền mạch.

4.2 Chi tiết đào tạo
Đối với Phương pháp A, chúng tôi sử dụng cả kỹ thuật LoRA và tinh chỉnh đầy đủ để đào tạo các mô hình OPT. Tuy nhiên, do hạn chế về tài nguyên tính toán, chúng tôi sử dụng độc quyền LoRA để đào tạo mô hình LLaMA-7B. Ngoài ra, chúng tôi tăng cường từ vựng của LLM với các token âm thanh, cụ thể là kết hợp 1024 token Encodec trong cấu hình của chúng tôi. Trong Phương pháp B, chúng tôi giới thiệu các tham số LoRA đến LLM và mô hình ngôn ngữ codec một cách tương ứng. LLM được khởi tạo với một OPT-350M được đào tạo trước hoặc LLaMA-7B, trong khi mô hình ngôn ngữ codec được khởi tạo với một V ALL-E được đào tạo trước. Chúng tôi cũng mở rộng từ vựng của LLM với các token âm thanh như Phương pháp A. Bên cạnh đó, các nhúng âm thanh và văn bản đầu vào từ V ALL-E được bỏ qua, vì LLM bây giờ cung cấp biểu diễn cho cả token âm thanh và văn bản. Tương tự, trong Phương pháp C chúng tôi cũng thêm các tham số LoRA vào LLM được đào tạo trước và V ALL-E được đào tạo trước một cách tương ứng, và loại bỏ nhúng token văn bản của V ALL-E.

Chúng tôi cố định tham số LoRA thành R= 64 để điều chỉnh các tham số tự chú ý. Do đó, sử dụng Phương pháp A để đào tạo LoRA cho khoảng 14M tham số có thể đào tạo cho OPT-350M và 71M cho LLaMA-7B. Ngược lại, Phương pháp B kết hợp nhúng mã codec, LoRA, và chiếu tuyến tính, dẫn đến khoảng 21M tham số có thể đào tạo cho OPT-350M và 82M cho LLaMA-7B. Trong khi đó, Phương pháp C giảm số lượng tham số có thể đào tạo xuống 20M cho OPT-350M và 78M cho LLaMA-7B, vì nó không sử dụng nhúng mã codec cho LLM. Các mô hình của chúng tôi được đào tạo bằng trình tối ưu hóa Adam với β1= 0.9 và β2= 0.98 [Kingma and Ba, 2015]. Tất cả các mô hình được đào tạo trên các tác vụ TTS trong 400K bước trên 32 GPU V100 với kích thước batch 100 giây mỗi GPU. Tỷ lệ học tối đa là 5×10−4 với bước khởi động 40K. Chúng tôi tuân theo cấu hình của V ALL-E để đào tạo mô hình ngôn ngữ không tự hồi quy của chúng tôi như được giới thiệu trong Phần 3.1.

4.3 Số liệu đánh giá
Chúng tôi sử dụng các số liệu đánh giá tự động, bao gồm tỷ lệ lỗi từ (WER), độ tương tự giọng nói (SS), và tự nhiên giọng nói (SN) để đánh giá giọng nói được tạo ra cho đơn giản và thuận tiện. Điểm WER được thu thập bởi một mô hình Conformer Transducer mã nguồn mở3, dao động từ 0 đến 100. WER càng thấp, giọng nói được tạo ra càng chính xác. Với các phát âm giọng nói được tạo ra và lời nhắc đã cho, SS được đo bằng một mô hình xác minh người nói tự động (ASV) WavLM [Chen et al., 2022]4, dao động từ -1 đến 1. SS càng lớn, người nói của hai phát âm càng giống nhau. Điểm SN của giọng nói được tạo ra được đo bằng NISQA mã nguồn mở5 [Mittag and Möller, 2020]. Vì chúng tôi chủ yếu sử dụng LoRA để tinh chỉnh LLM, khả năng xử lý văn bản gốc của LLM sẽ không bị ảnh hưởng khi thực hiện các tác vụ NLP mà không có tham số LoRA, do đó các tác vụ NLP không được đánh giá trong bài báo này.

4.4 Chiến lược suy luận
Sau khi đào tạo, chúng tôi sử dụng các phương pháp lấy mẫu cho các mô hình của chúng tôi để tạo các token âm thanh của mã codec lớp đầu tiên. Cụ thể, chúng tôi sử dụng lấy mẫu top-p [Holtzman et al., 2020] với p= 1.0 và nhiệt độ là 1.0. Chúng tôi áp dụng ba chiến lược khác nhau để chọn các chuỗi được lấy mẫu theo công việc trước đây [Wang et al., 2023b].

• Chiến lược I thực hiện chỉ một lần suy luận tổng hợp cho một văn bản, và sau đó chuỗi âm thanh được lấy mẫu được chọn làm kết quả cuối cùng.
• Chiến lược II tiến hành năm lần suy luận tổng hợp cho một văn bản duy nhất, chọn phát âm mang lại điểm độ tương tự giọng nói cao nhất.
• Chiến lược III cũng thực hiện năm lần suy luận tổng hợp cho một văn bản nhất định và chọn phát âm thể hiện tỷ lệ lỗi từ thấp nhất.

4.5 Kết quả chính
Chúng tôi tổng hợp giọng nói tiếng Anh của văn bản tương ứng được nhắc bởi một phát âm giọng nói tiếng Anh 3 giây trên các mẫu được chọn của các bộ dữ liệu dev-clean, dev-other, test-clean, và test-other, trong đó Bảng 1 cho thấy kết quả của dev-clean và những cái khác được hiển thị trong Phụ lục A. Như được tóm tắt trong Bảng 1, chúng tôi sao chép đường cơ sở V ALL-E sử dụng các tham số giống hệt với Wang et al. [2023a], trong khi ba phương pháp đề xuất được xác thực bằng cả mô hình LLaMA-7B và OPT-350M. Chúng tôi áp dụng ba chiến lược suy luận được nêu trong Phần 4.4, đánh giá hiệu suất của chúng bằng các số liệu tỷ lệ lỗi từ (WER), độ tương tự câu (SS), và tự nhiên giọng nói (SN), như được giới thiệu trong Phần 4.3.

Theo kết quả thực nghiệm, chúng tôi có thể rút ra ba kết luận: (1) Tinh chỉnh trực tiếp LLM bằng LoRA hoạt động tệ hơn so với mô hình cơ sở V ALL-E. Mặc dù tinh chỉnh đầy đủ có thể giảm thiểu vấn đề và đạt được hiệu suất có thể so sánh với V ALL-E, nó cần tài nguyên tính toán khổng lồ cho các mô hình lớn. (2) Phương pháp B, khi được sử dụng với cả mô hình OPT-350M hoặc LLaMA-7B, vượt trội so với đường cơ sở V ALL-E về WER, SS, và SN, điều này cho thấy rằng việc tăng cường LLM với V ALL-E có thể giải quyết thách thức trên với các phương pháp LoRA, vì LLM có khả năng mã hóa cả token âm thanh và văn bản và V ALL-E chia sẻ một phần gánh nặng cho việc tổng hợp giọng nói trong LLM. (3) Bằng cách tận dụng đầy đủ các điểm mạnh tương ứng của cả hai thành phần, Phương pháp C đạt hiệu suất tốt nhất trong số các phương pháp đề xuất, vượt trội đáng kể so với V ALL-E về tỷ lệ lỗi từ, độ tương tự giọng nói, và tự nhiên giọng nói. So với V ALL-E, tỷ lệ lỗi từ của Phương pháp C với LLaMA-7B giảm tương đối 10,9%, 14,3%, và 6,9% dưới Chiến lược suy luận I, II, và III tương ứng, độ tương tự giọng nói được cải thiện tương đối 0,02, 0,03, và 0,03, và tự nhiên giọng nói được cải thiện 0,03, 0,02, và 0,02 tương ứng.

4.6 Phân tích
Để tạo điều kiện cho việc hiểu rõ hơn về phương pháp của chúng tôi, chúng tôi tiến hành các phân tích chi tiết và nghiên cứu cắt bỏ trong phần này.

Hiệu ứng của kích thước mô hình Khả năng của một mô hình ngôn ngữ lớn bị ảnh hưởng đáng kể bởi số lượng tham số của nó. Do đó, chúng tôi khám phá tác động của các kích thước mô hình khác nhau trong khung OPT thông qua tinh chỉnh đầy đủ trực tiếp (được gọi là Phương pháp A trong Bảng 1), xem xét các mô hình với 125M, 350M, và 1.3B tham số. Ngoài ra, chúng tôi thiết lập các đường cơ sở bằng cách đào tạo những mô hình này từ đầu. Chúng tôi tiến hành thí nghiệm này trên bộ dữ liệu dev-clean, kết quả được mô tả trong Hình 2. Sự so sánh giữa hai đường cong minh họa hiệu quả của việc sử dụng LLM được đào tạo trước. Mô hình OPT lớn nhất với 1.3B tham số đạt hiệu suất tốt nhất tổng thể so với 125M và 350M. Phát hiện này cho thấy rằng việc tăng kích thước mô hình có thể là một chiến lược khả thi để tăng cường khả năng tổng hợp giọng nói.

Hiệu ứng của đào tạo trước liên tục Vì dữ liệu giọng nói không có nhãn phổ biến hơn dữ liệu giọng nói-văn bản được ghép nối, chúng tôi cũng điều tra cách tận dụng dữ liệu giọng nói không có nhãn khổng lồ để thúc đẩy hiệu suất tổng hợp giọng nói của LLM. Cụ thể, được truyền cảm hứng từ mục tiêu đào tạo trước dự đoán token tiếp theo của các mô hình ngôn ngữ chỉ có bộ giải mã như GPT, chúng tôi sử dụng mã EnCodec của bộ dữ liệu LibriLight [Kahn et al., 2020] để đào tạo trước liên tục các mô hình ngôn ngữ lớn, để chúng có thể thích ứng tốt hơn với phương thức giọng nói. Sau đó chúng tôi sử dụng dữ liệu giọng nói-văn bản được ghép nối để tinh chỉnh các mô hình được đào tạo trước liên tục và so sánh chúng với những mô hình chưa được đào tạo trước liên tục. Bảng 2 cho thấy kết quả so sánh của (1) đào tạo từ đầu, (2) tinh chỉnh đầy đủ trực tiếp, và (3) đào tạo trước liên tục và sau đó tinh chỉnh đầy đủ, trên các bộ dữ liệu lớn (MLS+LS) và nhỏ (LS). Kết quả thực nghiệm về Phương pháp A với OPT-350M làm LLM cho thấy phương pháp đào tạo trước liên tục đạt được giảm WER đáng kể so với các phương pháp tinh chỉnh đầy đủ và đào tạo từ đầu trên bộ dữ liệu tinh chỉnh nhỏ, và đạt được hiệu suất có thể so sánh trên bộ dữ liệu tinh chỉnh lớn.

Hiệu ứng của V ALL-E được đào tạo trước Để xác thực lợi ích của việc sử dụng mô hình ngôn ngữ codec V ALL-E được đào tạo trước, chúng tôi thực hiện một nghiên cứu cắt bỏ tập trung vào tác động của khởi tạo ngẫu nhiên so với khởi tạo được đào tạo trước. Cụ thể, chúng tôi tinh chỉnh đầy đủ V ALL-E được khởi tạo ngẫu nhiên nhưng sử dụng LoRA để tinh chỉnh V ALL-E được khởi tạo với trọng số được đào tạo trước. Bảng 3 phân định sự khác biệt hiệu suất giữa các mô hình với Phương pháp B bắt đầu với trọng số ngẫu nhiên và những mô hình được khởi tạo với V ALL-E được đào tạo trước. Kết quả rõ ràng chỉ ra rằng việc khởi tạo với V ALL-E được đào tạo trước dẫn đến ít tham số có thể đào tạo hơn và vượt trội đáng kể so với khởi tạo ngẫu nhiên qua các chiến lược suy luận và tiêu chí đánh giá khác nhau.

LoRA so với Tinh chỉnh đầy đủ trong V ALL-E Phần trước đã chứng minh rằng V ALL-E được đào tạo trước được tăng cường với LoRA vượt trội so với phiên bản V ALL-E được khởi tạo ngẫu nhiên. Bên cạnh đó, kết quả chính cũng chỉ ra rằng tinh chỉnh đầy đủ OPT-350M mang lại kết quả tốt hơn so với việc áp dụng kỹ thuật LoRA. Vì kích thước mô hình của V ALL-E tương đối nhỏ so với LLM, chúng tôi bây giờ mong muốn điều tra hiệu suất đỉnh có thể đạt được bằng cách thay thế LoRA bằng tinh chỉnh đầy đủ trong V ALL-E. Bảng 4 trình bày so sánh hiệu suất giữa các phương pháp tinh chỉnh LoRA và tinh chỉnh đầy đủ cho V ALL-E, tiết lộ rằng tinh chỉnh đầy đủ thực sự có thể dẫn đến những cải thiện thêm về hiệu suất.

5 Kết luận
Trong nghiên cứu này, chúng tôi khám phá nhiều chiến lược khác nhau để kết hợp khả năng tổng hợp giọng nói vào các mô hình ngôn ngữ lớn (LLM). Phát hiện của chúng tôi cho thấy rằng việc đơn giản tinh chỉnh LLM với LoRA không thể khớp với hiệu suất của đường cơ sở, chỉ ra thách thức của việc tăng cường LLM với khả năng tổng hợp giọng nói. Điều tra thêm chứng minh rằng LLM được tăng cường với một mô hình tổng hợp văn bản thành giọng nói được đào tạo trước có thể vượt qua hiệu suất của mô hình cơ sở V ALL-E. Đặc biệt, bằng cách tận dụng các điểm mạnh tương ứng của LLM và V ALL-E, phương pháp LLM kết hợp và V ALL-E đạt hiệu suất cao nhất trong số các phương pháp được đánh giá. Hơn nữa, chúng tôi tiến hành các phân tích toàn diện để hiểu rõ hơn về LLM đề xuất được tăng cường với khả năng tổng hợp giọng nói.

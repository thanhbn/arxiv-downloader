DistriFusion: Suy luận Song song Phân tán cho Mô hình Khuếch tán Độ phân giải Cao

Muyang Li1* Tianle Cai2* Jiaxin Cao3 Qinsheng Zhang4 Han Cai1
Junjie Bai3 Yangqing Jia3 Ming-Yu Liu4 Kai Li2 Song Han1,4
1MIT 2Princeton 3Lepton AI 4NVIDIA
https://github.com/mit-han-lab/distrifuser

Gốc, 1 GPU
MACs: 907T
Độ trễ: 12.3s

Song song Ngây thơ, 4 GPUs
MACs Mỗi Thiết bị: 190T (Ít hơn 4.8×)
Độ trễ: 3.14s (Nhanh hơn 3.9×)
Nhưng có Lỗi: Chủ thể Trùng lặp

DistriFusion (Của chúng tôi), 4 GPUs
MACs Mỗi Thiết bị: 227T (Ít hơn 4.0×)
Độ trễ: 4.16s (Nhanh hơn 3.0×)
Không có Lỗi

Prompt: Nghệ thuật khái niệm giả tưởng thanh thoát của một tiên lúa, tráng lệ, thiên thể, thanh thoát, như tranh vẽ, sử thi, uy nghi, kỳ diệu, nghệ thuật giả tưởng, nghệ thuật bìa, mơ màng.

Prompt: Bức tranh lãng mạn về một con tàu đang đi trong biển bão, với ánh sáng kịch tính và sóng mạnh.

Hình 1. Chúng tôi giới thiệu DistriFusion, một thuật toán không cần huấn luyện để khai thác nhiều GPU nhằm tăng tốc suy luận mô hình khuếch tán mà không ảnh hưởng đến chất lượng hình ảnh. Patch Ngây thơ (Hình 2(b)) gặp phải vấn đề phân mảnh do thiếu tương tác giữa các patch. DistriFusion của chúng tôi loại bỏ lỗi và tránh chi phí giao tiếp bằng cách tái sử dụng các đặc trưng từ các bước trước. Cài đặt: SDXL với bộ lấy mẫu Euler 50 bước, độ phân giải 1280×1920. Độ trễ được đo trên A100s.

Tóm tắt

Các mô hình khuếch tán đã đạt được thành công lớn trong việc tổng hợp các hình ảnh chất lượng cao. Tuy nhiên, tạo ra hình ảnh độ phân giải cao với mô hình khuếch tán vẫn là thách thức do chi phí tính toán khổng lồ, dẫn đến độ trễ quá cao cho các ứng dụng tương tác. Trong bài báo này, chúng tôi đề xuất DistriFusion để giải quyết vấn đề này bằng cách tận dụng tính song song trên nhiều GPU. Phương pháp của chúng tôi chia đầu vào của mô hình thành nhiều patch và gán từng patch cho một GPU. Tuy nhiên, việc triển khai ngây thơ thuật toán như vậy sẽ phá vỡ tương tác giữa các patch và mất đi độ chính xác, trong khi việc kết hợp tương tác như vậy sẽ gây ra chi phí giao tiếp khổng lồ. Để vượt qua tình thế khó khăn này, chúng tôi quan sát thấy độ tương tự cao giữa đầu vào từ các bước khuếch tán liền kề và đề xuất tính song song patch dịch chuyển, tận dụng tính chất tuần tự của quá trình khuếch tán bằng cách tái sử dụng các bản đồ đặc trưng đã được tính toán trước từ bước thời gian trước để cung cấp ngữ cảnh cho bước hiện tại. Do đó, phương pháp của chúng tôi hỗ trợ giao tiếp không đồng bộ, có thể được đường ống hóa bởi tính toán. Các thí nghiệm rộng rãi cho thấy phương pháp của chúng tôi có thể được áp dụng cho Stable Diffusion XL gần đây mà không suy giảm chất lượng và đạt được tốc độ tăng tốc lên đến 6.1× trên tám GPU A100 so với một GPU.

1. Giới thiệu

Sự xuất hiện của nội dung được tạo ra bởi AI (AIGC) đại diện cho một sự thay đổi lớn trong đổi mới công nghệ. Các công cụ như Adobe Firefly, Midjourney và Sora gần đây thể hiện khả năng đáng kinh ngạc, tạo ra hình ảnh và thiết kế hấp dẫn từ những gợi ý văn bản đơn giản. Những thành tựu này đặc biệt được hỗ trợ bởi sự tiến bộ trong các mô hình khuếch tán [13,60]. Sự xuất hiện của các mô hình text-to-image lớn, bao gồm Stable Diffusion [54], Imgen [56], eDiff-I [2], DALL·E [3,48,49] và Emu [6], mở rộng thêm chân trời của sự sáng tạo AI.

Được huấn luyện trên dữ liệu web mở đa dạng, các mô hình này có thể tạo ra hình ảnh chân thực từ mô tả văn bản một mình. Cuộc cách mạng công nghệ như vậy mở ra nhiều ứng dụng tổng hợp và chỉnh sửa cho hình ảnh và video, đặt ra yêu cầu mới về khả năng phản hồi: bằng cách hướng dẫn và tinh chỉnh đầu ra của mô hình một cách tương tác, người dùng có thể đạt được kết quả cá nhân hóa và chính xác hơn. Tuy nhiên, một thách thức quan trọng vẫn còn - độ phân giải cao dẫn đến tính toán lớn. Ví dụ, Stable Diffusion gốc [54] chỉ giới hạn ở việc tạo ra hình ảnh 512×512. Sau đó, SDXL [46] mở rộng khả năng lên hình ảnh 1024×1024. Gần đây hơn, Sora tiếp tục đẩy ranh giới bằng cách cho phép tạo video ở độ phân giải 1080×1920. Mặc dù có những tiến bộ này, độ trễ tăng lên của việc tạo hình ảnh độ phân giải cao là một rào cản to lớn đối với các ứng dụng thời gian thực.

Những nỗ lực gần đây để tăng tốc suy luận mô hình khuếch tán chủ yếu tập trung vào hai cách tiếp cận: giảm các bước lấy mẫu [20,32,33,36,57,61,70,73] và tối ưu hóa suy luận mạng nơ-ron [23,25,26]. Khi tài nguyên tính toán tăng nhanh, việc tận dụng nhiều GPU để tăng tốc suy luận là hấp dẫn. Ví dụ, trong xử lý ngôn ngữ tự nhiên (NLP), các mô hình ngôn ngữ lớn đã thành công trong việc khai thác tính song song tensor trên các GPU, giảm đáng kể độ trễ. Tuy nhiên, đối với mô hình khuếch tán, nhiều GPU thường chỉ được sử dụng cho suy luận batch. Khi tạo ra một hình ảnh duy nhất, thường chỉ có một GPU được tham gia (Hình 2(a)). Các kỹ thuật như tính song song tensor ít phù hợp với mô hình khuếch tán do kích thước activation lớn, vì chi phí giao tiếp vượt quá lợi ích từ tính toán phân tán. Do đó, ngay cả khi có nhiều GPU, chúng không thể được khai thác hiệu quả để tăng tốc thêm việc tạo hình ảnh đơn lẻ. Điều này thúc đẩy việc phát triển một phương pháp có thể sử dụng nhiều GPU để tăng tốc tạo hình ảnh đơn lẻ với mô hình khuếch tán.

Một cách tiếp cận ngây thơ sẽ là chia hình ảnh thành nhiều patch, gán mỗi patch cho một thiết bị khác nhau để tạo ra, như minh họa trong Hình 2(b). Phương pháp này cho phép các hoạt động độc lập và song song trên các thiết bị. Tuy nhiên, nó gặp phải một đường nối rõ ràng tại ranh giới của mỗi patch do sự vắng mặt của tương tác giữa các patch riêng lẻ. Tuy nhiên, việc giới thiệu tương tác giữa các patch để giải quyết vấn đề này sẽ gây ra chi phí đồng bộ hóa quá mức một lần nữa, triệt tiêu lợi ích của xử lý song song.

Trong nghiên cứu này, chúng tôi trình bày DistriFusion, một phương pháp cho phép chạy mô hình khuếch tán trên nhiều thiết bị song song để giảm độ trễ của việc tạo mẫu đơn lẻ mà không ảnh hưởng đến chất lượng hình ảnh. Như mô tả trong Hình 2(c), cách tiếp cận của chúng tôi cũng dựa trên tính song song patch, chia hình ảnh thành nhiều patch, mỗi patch được gán cho một thiết bị khác nhau. Quan sát quan trọng của chúng tôi là đầu vào qua các bước khử nhiễu liền kề trong mô hình khuếch tán tương tự nhau. Do đó, chúng tôi áp dụng giao tiếp đồng bộ chỉ cho bước đầu tiên. Đối với các bước tiếp theo, chúng tôi tái sử dụng các activation đã được tính toán trước từ bước trước để cung cấp ngữ cảnh toàn cục và tương tác patch cho bước hiện tại. Chúng tôi tiếp tục đồng thiết kế một framework suy luận để triển khai thuật toán của chúng tôi. Cụ thể, framework của chúng tôi hiệu quả ẩn chi phí giao tiếp trong tính toán thông qua giao tiếp không đồng bộ. Nó cũng chạy thưa thớt các lớp tích chập và attention độc quyền trên các vùng được gán, do đó giảm tỷ lệ tính toán mỗi thiết bị. Phương pháp của chúng tôi, khác biệt với tính song song dữ liệu, tensor, hoặc đường ống, giới thiệu một cơ hội song song hóa mới: tính song song patch dịch chuyển.

DistriFusion chỉ yêu cầu các mô hình khuếch tán đã được huấn luyện sẵn có và có thể áp dụng cho đa số bộ lấy mẫu ít bước. Chúng tôi đánh giá nó trên một tập con của COCO Captions [5]. Không mất đi độ chính xác hình ảnh, nó phản ánh hiệu suất của Stable Diffusion XL (SDXL) gốc [46] trong khi giảm tính toán tỷ lệ thuận với số lượng thiết bị được sử dụng. Hơn nữa, framework của chúng tôi cũng giảm độ trễ của SDXL U-Net để tạo ra một hình ảnh đơn lẻ lên đến 1.8×, 3.4× và 6.1× với 2, 4, và 8 GPU A100, tương ứng. Khi kết hợp với chia batch cho hướng dẫn không có bộ phân loại [12], chúng tôi đạt được tổng cộng 3.6× và 6.6× tăng tốc sử dụng 4 và 8 GPU A100 cho hình ảnh 3840×3840, tương ứng. Xem Hình 1 để xem một số ví dụ về phương pháp của chúng tôi.

2. Công trình Liên quan

Mô hình khuếch tán. Các mô hình khuếch tán đã biến đổi đáng kể bối cảnh tạo nội dung [2,13,41,46]. Về cốt lõi, những mô hình này tổng hợp nội dung thông qua một quá trình khử nhiễu lặp đi lặp lại. Mặc dù cách tiếp cận lặp này mang lại khả năng chưa từng có cho việc tạo nội dung, nó đòi hỏi tài nguyên tính toán đáng kể hơn và dẫn đến tốc độ tạo chậm hơn. Vấn đề này tăng cường với việc tổng hợp dữ liệu nhiều chiều cao, như hình ảnh độ phân giải cao [9,14] hoặc hình ảnh 360° [75]. Các nhà nghiên cứu đã điều tra các góc nhìn khác nhau để tăng tốc mô hình khuếch tán. Hướng đầu tiên nằm trong việc thiết kế các quá trình khử nhiễu hiệu quả hơn. Rombach et al. [54] và Vahdat et al. [66] đề xuất nén hình ảnh độ phân giải cao thành biểu diễn tiềm ẩn độ phân giải thấp và học mô hình khuếch tán trong không gian tiềm ẩn. Một hướng khác nằm trong việc cải thiện lấy mẫu thông qua thiết kế các thuật toán lấy mẫu hiệu quả không cần huấn luyện. Một danh mục lớn các công trình theo hướng này được xây dựng dựa trên kết nối giữa mô hình khuếch tán và phương trình vi phân [62], và tận dụng một bộ tích phân số mũ được thiết lập tốt [32,73,74] để giảm các bước lấy mẫu trong khi duy trì độ chính xác số học. Chiến lược thứ ba liên quan đến việc chưng cất các mô hình tạo nhanh hơn từ các mô hình khuếch tán đã được huấn luyện trước. Mặc dù có tiến bộ đáng kể được thực hiện trong lĩnh vực này, vẫn tồn tại khoảng cách chất lượng giữa các bộ tạo nhanh này và mô hình khuếch tán [19,36,57]. Ngoài các sơ đồ trên, một số công trình điều tra cách tối ưu hóa suy luận thần kinh cho mô hình khuếch tán [23,25,26]. Trong nghiên cứu này, chúng tôi khám phá một mô hình mới để tăng tốc khuếch tán bằng cách tận dụng tính song song cho mạng nơ-ron trên nhiều thiết bị.

Tính song song. Công trình hiện tại đã khám phá các chiến lược song song khác nhau để tăng tốc huấn luyện và suy luận của các mô hình ngôn ngữ lớn (LLM), bao gồm dữ liệu, đường ống [15,27,38], tensor [17,39,71,72,78], và tính song song không dư thừa [47,50,51,77]. Tính song song tensor, đặc biệt, đã được áp dụng rộng rãi để tăng tốc LLM [28], được đặc trưng bởi kích thước mô hình đáng kể của chúng, trong khi kích thước activation của chúng tương đối nhỏ. Trong những tình huống như vậy, chi phí giao tiếp được giới thiệu bởi tính song song tensor tương đối nhỏ so với lợi ích độ trễ đáng kể mang lại bởi băng thông bộ nhớ tăng lên. Tuy nhiên, tình hình khác đối với mô hình khuếch tán, thường nhỏ hơn LLM nhưng thường bị nghẽn cổ chai bởi kích thước activation lớn do các chiều không gian, đặc biệt khi tạo nội dung độ phân giải cao. Chi phí giao tiếp từ tính song song tensor trở thành một yếu tố quan trọng, che lấp thời gian tính toán thực tế. Kết quả là, chỉ có tính song song dữ liệu được sử dụng cho đến nay cho việc phục vụ mô hình khuếch tán, không cung cấp cải thiện độ trễ. Ngoại lệ duy nhất là ParaDiGMS [59], sử dụng lặp Picard để chạy nhiều bước song song. Tuy nhiên, bộ lấy mẫu này có xu hướng lãng phí nhiều tính toán, và kết quả được tạo ra thể hiện sự khác biệt đáng kể so với mô hình khuếch tán gốc. Phương pháp của chúng tôi dựa trên tính song song patch, phân phối tính toán trên nhiều thiết bị bằng cách chia đầu vào thành các patch nhỏ. So với tính song song tensor, sơ đồ như vậy có tính độc lập vượt trội và giảm yêu cầu giao tiếp. Thêm vào đó, nó ưu tiên việc sử dụng AllGather hơn AllReduce cho tương tác dữ liệu, giảm đáng kể chi phí (xem Mục 5.3 để so sánh đầy đủ). Lấy cảm hứng từ thành công của giao tiếp không đồng bộ trong tính toán song song [67], chúng tôi tiếp tục tái sử dụng các đặc trưng từ bước trước làm ngữ cảnh cho bước hiện tại để chồng chéo giao tiếp và tính toán, gọi là tính song song patch dịch chuyển. Điều này đại diện cho chiến lược song song đầu tiên được thiết kế riêng cho đặc tính tuần tự của mô hình khuếch tán trong khi tránh chi phí giao tiếp nặng nề của các kỹ thuật truyền thống như tính song song tensor.

Tính toán thưa thớt. Tính toán thưa thớt đã được nghiên cứu rộng rãi trong nhiều lĩnh vực khác nhau, bao gồm trọng số [10,16,21,31], đầu vào [53,64,65] và activation [7,18,23,24,42,52,52,58]. Trong lĩnh vực activation, để tạo điều kiện cho tăng tốc trên phần cứng, một số nghiên cứu đề xuất sử dụng độ thưa thớt có cấu trúc. SBNet [52] sử dụng mặt nạ không gian để thưa thớt hóa activation nhằm tăng tốc phát hiện đối tượng 3D. Mặt nạ này có thể được suy ra từ kiến thức vấn đề trước hoặc một mạng phụ trợ. Trong bối cảnh tạo hình ảnh, SIGE [23] tận dụng độ thưa thớt có cấu trúc cao của chỉnh sửa người dùng, thực hiện tính toán có chọn lọc tại các vùng được chỉnh sửa để tăng tốc GAN [8] và mô hình khuếch tán. MCUNetV2 [29] áp dụng suy luận dựa trên patch để giảm sử dụng bộ nhớ cho phân loại và phát hiện hình ảnh. Trong nghiên cứu của chúng tôi, chúng tôi cũng phân vùng đầu vào thành các patch, mỗi patch được xử lý bởi một thiết bị khác nhau. Tuy nhiên, chúng tôi tập trung vào việc giảm độ trễ bằng tính song song cho việc tạo hình ảnh thay vào đó. Mỗi thiết bị sẽ chỉ xử lý các vùng được gán để giảm tính toán mỗi thiết bị.

3. Bối cảnh

Để tạo ra một hình ảnh chất lượng cao, một mô hình khuếch tán thường huấn luyện một mô hình nơ-ron dự đoán nhiễu (ví dụ, U-Net [55]) ϵθ. Bắt đầu từ nhiễu Gaussian thuần túy xT ∼ N(0,I), nó bao gồm hàng chục đến hàng trăm bước khử nhiễu lặp để có được hình ảnh sạch cuối cùng x0, trong đó T là tổng số bước. Cụ thể, cho hình ảnh nhiễu xt tại bước thời gian t, mô hình ϵθ nhận xt, t và một điều kiện bổ sung c (ví dụ, văn bản) làm đầu vào để dự đoán nhiễu tương ứng ϵt trong xt. Tại mỗi bước khử nhiễu, xt−1 có thể được suy ra từ phương trình sau:

xt−1 = Update(xt, t, ϵt), ϵt = ϵθ(xt, t, c). (1)

Ở đây, 'Update' đề cập đến một hàm cụ thể của bộ lấy mẫu thường bao gồm phép cộng và nhân theo từng phần tử. Do đó, nguồn độ trễ chính trong quá trình này là các lần truyền xuôi qua mô hình ϵθ. Ví dụ, Stable Diffusion XL [46] yêu cầu 6,763 GMAC mỗi bước để tạo ra hình ảnh 1024×1024. Nhu cầu tính toán này tăng hơn bậc hai với độ phân giải tăng, làm cho độ trễ tạo ra một hình ảnh độ phân giải cao đơn lẻ trở nên cao bất khả thi cho các ứng dụng thực tế. Hơn nữa, cho rằng xt−1 phụ thuộc vào xt, tính toán song song của ϵt và ϵt−1 là thách thức. Do đó, ngay cả với nhiều GPU rảnh rỗi, việc tăng tốc tạo ra một hình ảnh độ phân giải cao đơn lẻ vẫn khó khăn. Gần đây, Shih et al. giới thiệu ParaDiGMS [59], sử dụng các lặp Picard để song song hóa các bước khử nhiễu theo cách song song dữ liệu. Tuy nhiên, ParaDiGMS lãng phí tính toán trên các dự đoán đầu cơ không đạt ngưỡng chất lượng. Nó cũng dựa vào tổng số bước lớn T để khai thác tính song song dữ liệu đa GPU, hạn chế các ứng dụng tiềm năng của nó. Một phương pháp thông thường khác là chia sẻ mô hình trên nhiều thiết bị và sử dụng tính song song tensor cho suy luận. Tuy nhiên, phương pháp này gặp phải chi phí giao tiếp không thể chấp nhận được, khiến nó không thực tế cho các ứng dụng thực tế. Ngoài hai sơ đồ này, có những chiến lược thay thế để phân phối khối lượng công việc trên nhiều thiết bị GPU sao cho việc tạo hình ảnh đơn lẻ cũng có thể tận hưởng tăng tốc miễn phí từ nhiều thiết bị không?

4. Phương pháp

Ý tưởng chính của DistriFusion là song song hóa tính toán trên các thiết bị bằng cách chia hình ảnh thành các patch. Một cách ngây thơ, điều này có thể được thực hiện bằng cách (1) tính toán độc lập các patch và ghép chúng lại với nhau, hoặc (2) giao tiếp đồng bộ activation trung gian giữa các patch. Tuy nhiên, cách tiếp cận đầu tiên dẫn đến sự khác biệt rõ ràng tại ranh giới của mỗi patch do sự vắng mặt của tương tác giữa chúng (xem Hình 1 và Hình 2(b)). Mặt khác, cách tiếp cận thứ hai gây ra chi phí giao tiếp quá mức, triệt tiêu lợi ích của xử lý song song.

Để giải quyết những thách thức này, chúng tôi đề xuất một mô hình song song mới, tính song song patch dịch chuyển, tận dụng tính chất tuần tự của mô hình khuếch tán để chồng chéo giao tiếp và tính toán. Sự hiểu biết quan trọng của chúng tôi là tái sử dụng activation hơi lỗi thời, hoặc 'cũ' từ bước khuếch tán trước để tạo điều kiện tương tác giữa các patch, mà chúng tôi mô tả là dịch chuyển activation. Điều này dựa trên quan sát rằng đầu vào cho các bước khử nhiễu liên tiếp tương đối giống nhau. Do đó, việc tính toán activation của mỗi patch tại một lớp không phụ thuộc vào activation tươi của các patch khác, cho phép giao tiếp được ẩn trong tính toán của các lớp tiếp theo. Tiếp theo, chúng tôi sẽ cung cấp phân tích chi tiết về từng khía cạnh của thiết kế thuật toán và hệ thống của chúng tôi.

Tính song song patch dịch chuyển. Như thể hiện trong Hình 3, khi dự đoán ϵθ(xt) (chúng tôi bỏ qua đầu vào của timestep t và điều kiện c ở đây để đơn giản), trước tiên chúng tôi chia xt thành nhiều patch x(1)t, x(2)t, ..., x(N)t, trong đó N là số lượng thiết bị. Ví dụ, chúng tôi sử dụng N = 2 trong Hình 3. Mỗi thiết bị có một bản sao của mô hình ϵθ và sẽ xử lý một patch duy nhất độc lập, song song.

Đối với một lớp l cho trước, hãy xem xét patch activation đầu vào trên thiết bị thứ i, ký hiệu là A(i)l,t. Patch này trước tiên được rải vào activation cũ từ bước trước, Alt+1, tại vị trí không gian tương ứng của nó (phương pháp để có được Alt+1 sẽ được thảo luận sau). Ở đây, Alt+1 có hình dạng không gian đầy đủ. Trong đầu ra Scatter, chỉ có 1/N vùng nơi A(i)l,t được đặt là tươi và cần tính toán lại. Sau đó, chúng tôi áp dụng có chọn lọc hoạt động lớp Fl (tuyến tính, tích chập, hoặc attention) cho các vùng tươi này, do đó tạo ra đầu ra cho các vùng tương ứng. Quá trình này được lặp lại cho mỗi lớp. Cuối cùng, đầu ra từ tất cả các lớp được đồng bộ hóa lại với nhau để xấp xỉ ϵθ(xt). Thông qua phương pháp này, mỗi thiết bị chỉ chịu trách nhiệm cho 1/N tổng số tính toán, cho phép song song hóa hiệu quả.

Vẫn còn một vấn đề về cách lấy activation cũ từ bước trước. Như thể hiện trong Hình 3, tại mỗi timestep t, khi thiết bị i có được A(i)l,t, nó sẽ sau đó phát sóng activation đến tất cả các thiết bị khác và thực hiện hoạt động AllGather. GPU hiện đại thường hỗ trợ giao tiếp và tính toán không đồng bộ, có nghĩa là quá trình AllGather này không chặn các tính toán đang diễn ra. Vào thời điểm chúng ta đến lớp l trong timestep tiếp theo, mỗi thiết bị đã nhận được một bản sao của Alt. Cách tiếp cận như vậy hiệu quả ẩn chi phí giao tiếp trong giai đoạn tính toán, như thể hiện trong Hình 4.

Tuy nhiên, có một ngoại lệ: bước đầu tiên (tức là, xT). Trong trường hợp này, mỗi thiết bị đơn giản thực hiện giao tiếp đồng bộ tiêu chuẩn và lưu cache activation trung gian cho bước tiếp theo.

Hoạt động thưa thớt. Đối với mỗi lớp l, chúng tôi sửa đổi toán tử gốc Fl để cho phép tính toán thưa thớt có chọn lọc trên các vùng tươi. Cụ thể, nếu Fl là một lớp tích chập, tuyến tính, hoặc cross-attention, chúng tôi áp dụng toán tử độc quyền cho các vùng được làm mới mới, thay vì bản đồ đặc trưng đầy đủ. Điều này có thể đạt được bằng cách trích xuất các phần tươi từ đầu ra scatter và đưa chúng vào Fl. Đối với các lớp mà Fl là một lớp self-attention, chúng tôi biến đổi nó thành một lớp cross-attention, tương tự như SIGE [23]. Trong cài đặt này, chỉ có các token query từ các vùng tươi được bảo tồn trên thiết bị, trong khi các token key và value vẫn bao quát toàn bộ bản đồ đặc trưng (đầu ra scatter). Do đó, chi phí tính toán cho Fl chính xác tỷ lệ với kích thước của vùng tươi.

GroupNorm không đồng bộ được sửa chữa. Mô hình khuếch tán thường áp dụng các lớp group normalization (GN) [40,68] trong mạng. Những lớp này chuẩn hóa theo chiều không gian, đòi hỏi tập hợp activation để khôi phục hình dạng không gian đầy đủ của chúng. Trong Mục 5.3, chúng tôi phát hiện rằng việc chuẩn hóa chỉ các patch tươi hoặc tái sử dụng đặc trưng cũ làm suy giảm chất lượng hình ảnh. Tuy nhiên, tập hợp tất cả các thống kê chuẩn hóa sẽ gây ra chi phí đáng kể do giao tiếp đồng bộ. Để giải quyết tình thế khó khăn này, chúng tôi bổ sung giới thiệu một thuật ngữ hiệu chỉnh cho thống kê cũ. Cụ thể, đối với mỗi thiết bị i tại một bước t cho trước, mỗi lớp GN có thể tính toán trung bình theo nhóm của patch tươi A(i)t, ký hiệu là E[A(i)t]. Để đơn giản, chúng tôi bỏ qua chỉ số lớp l ở đây. Nó cũng đã lưu cache trung bình cục bộ E[A(i)t+1] và trung bình toàn cục tổng hợp E[At+1] từ bước trước. Sau đó, trung bình toàn cục xấp xỉ E[At] cho bước hiện tại trên thiết bị i có thể được tính toán như

E[At] ≈ E[At+1] + (E[A(i)t] − E[A(i)t+1]) (2)
           |{z}              |{z}
      trung bình toàn cục cũ    hiệu chỉnh

Chúng tôi sử dụng kỹ thuật tương tự để xấp xỉ E[(At)2], sau đó phương sai có thể được xấp xỉ như E[(At)2] − E[At]2. Sau đó, chúng tôi sử dụng những thống kê xấp xỉ này cho lớp GN và đồng thời tập hợp trung bình cục bộ và phương sai để tính toán những thống kê chính xác bằng giao tiếp không đồng bộ. Do đó, chi phí giao tiếp cũng có thể được đường ống hóa vào tính toán. Chúng tôi thấy phương pháp này mang lại kết quả tương đương với tập hợp đồng bộ trực tiếp. Tuy nhiên, có một số trường hợp hiếm hoi khi phương sai xấp xỉ là âm. Đối với những nhóm phương sai âm này, chúng tôi sẽ quay về sử dụng phương sai cục bộ của patch tươi.

Các bước khởi động. Như quan sát trong eDiff-I [2] và FastComposer [69], hành vi của tổng hợp khuếch tán trải qua thay đổi định tính trong suốt quá trình khử nhiễu. Cụ thể, các bước ban đầu của lấy mẫu chủ yếu định hình các khía cạnh tần số thấp của hình ảnh, như bố cục không gian và ngữ nghĩa tổng thể. Khi lấy mẫu tiến triển, trọng tâm chuyển sang khôi phục chi tiết tần số cao cục bộ. Do đó, để tăng chất lượng hình ảnh, đặc biệt trong bộ lấy mẫu với số lượng bước giảm, chúng tôi áp dụng các bước khởi động. Thay vì trực tiếp sử dụng tính song song patch dịch chuyển sau bước đầu tiên, chúng tôi tiếp tục với một số lần lặp của tính song song patch đồng bộ tiêu chuẩn như một giai đoạn sơ bộ, hoặc khởi động. Như chi tiết trong Mục 5.3, sự tích hợp của các bước khởi động này cải thiện đáng kể hiệu suất.

5. Thí nghiệm

Trước tiên, chúng tôi mô tả cài đặt thí nghiệm, bao gồm bộ dữ liệu điểm chuẩn, baseline, và giao thức đánh giá. Sau đó, chúng tôi trình bày kết quả chính về cả chất lượng và hiệu quả. Cuối cùng, chúng tôi tiếp tục thể hiện một số nghiên cứu ablation để xác minh từng lựa chọn thiết kế.

5.1. Cài đặt

Mô hình. Vì phương pháp của chúng tôi chỉ yêu cầu các mô hình khuếch tán đã được huấn luyện trước sẵn có, chúng tôi chủ yếu thực hiện thí nghiệm trên mô hình text-to-image công cộng tiên tiến Stable Diffusion XL (SDXL) [46]. SDXL trước tiên nén hình ảnh thành biểu diễn tiềm ẩn nhỏ hơn 8× bằng cách sử dụng bộ mã hóa tự động đã được huấn luyện trước và sau đó áp dụng mô hình khuếch tán trong không gian tiềm ẩn này. Nó cũng kết hợp nhiều lớp cross-attention để tạo điều kiện điều hòa văn bản. So với Stable Diffusion gốc [54], SDXL áp dụng nhiều lớp attention hơn đáng kể, dẫn đến một mô hình tính toán chuyên sâu hơn.

Bộ dữ liệu. Chúng tôi sử dụng phiên bản HuggingFace của bộ dữ liệu COCO Captions 2014 [5] để đánh giá phương pháp của chúng tôi. Bộ dữ liệu này chứa các chú thích được tạo ra bởi con người cho hình ảnh từ bộ dữ liệu Microsoft Common Objects in COntext (COCO) [30]. Để đánh giá, chúng tôi lấy mẫu ngẫu nhiên một tập con từ tập xác thực, chứa 5K hình ảnh với một chú thích mỗi hình ảnh.

Baseline. Chúng tôi so sánh DistriFusion của chúng tôi với các baseline sau về cả chất lượng và hiệu quả:

• Patch Ngây thơ. Tại mỗi lần lặp, đầu vào được chia theo hàng hoặc cột luân phiên. Những patch này sau đó được xử lý độc lập bởi mô hình, không có bất kỳ tương tác nào giữa chúng. Đầu ra sau đó được nối lại với nhau.

• ParaDiGMS [59] là một kỹ thuật để tăng tốc mô hình khuếch tán đã được huấn luyện trước bằng cách khử nhiễu nhiều bước song song. Nó sử dụng lặp Picard để đoán giải pháp của các bước tương lai và tinh chỉnh lặp đi lặp lại cho đến khi hội tụ. Chúng tôi sử dụng kích thước batch 8 cho ParaDiGMS để phù hợp với Bảng 4 trong bài báo gốc [59]. Chúng tôi thấy cài đặt này mang lại hiệu suất tốt nhất trong cả chất lượng và độ trễ.

Metrics. Theo các công trình trước [22,23,37,43], chúng tôi đánh giá chất lượng hình ảnh với các metric tiêu chuẩn: Peak Signal Noise Ratio (PSNR, cao hơn thì tốt hơn), LPIPS (thấp hơn thì tốt hơn) [76], và Fréchet Inception Distance (FID, thấp hơn thì tốt hơn) [11]†. Chúng tôi sử dụng PSNR để định lượng những khác biệt số học nhỏ giữa đầu ra của phương pháp được đánh giá và đầu ra mô hình khuếch tán gốc. LPIPS được sử dụng để đánh giá độ tương tự tri giác. Ngoài ra, điểm FID được sử dụng để đo lường sự khác biệt phân phối giữa đầu ra của phương pháp và đầu ra gốc hoặc hình ảnh thật.

Chi tiết triển khai. Theo mặc định, chúng tôi áp dụng bộ lấy mẫu DDIM 50 bước [61] với hệ số hướng dẫn không có bộ phân loại là 5 để tạo ra hình ảnh 1024×1024, trừ khi được chỉ định khác. Ngoài bước đầu tiên, chúng tôi thực hiện thêm 4 bước tính song song patch đồng bộ, phục vụ như một giai đoạn khởi động. Chúng tôi sử dụng PyTorch 2.2 [45] để đánh giá tăng tốc của phương pháp chúng tôi. Để đo độ trễ, trước tiên chúng tôi khởi động thiết bị với 3 lần lặp của toàn bộ quá trình khử nhiễu, sau đó chạy thêm 10 lần lặp và tính toán độ trễ trung bình bằng cách loại bỏ kết quả của lần chạy nhanh nhất và chậm nhất. Ngoài ra, chúng tôi sử dụng CUDAGraph để tối ưu hóa một số chi phí khởi chạy kernel cho cả mô hình gốc và phương pháp của chúng tôi.

5.2. Kết quả Chính

Kết quả chất lượng. Trong Hình 5, chúng tôi hiển thị một số kết quả hình ảnh định tính và báo cáo một số đánh giá định lượng trong Bảng 1. Với G.T. có nghĩa là tính toán metric với hình ảnh thật COCO [30], trong khi Với Orig. đề cập đến việc tính toán metric với đầu ra từ mô hình gốc. Đối với PSNR, chúng tôi chỉ báo cáo cài đặt Với Orig., vì so sánh Với G.T. không mang tính thông tin do sự khác biệt số học đáng kể giữa đầu ra được tạo ra và hình ảnh thật.

Như thể hiện trong Bảng 1, ParaDiGMS [59] chi tiêu tài nguyên tính toán đáng kể để đoán các bước khử nhiễu tương lai, dẫn đến tổng MACs cao hơn nhiều. Bên cạnh đó, nó cũng gặp phải một số suy giảm hiệu suất. Ngược lại, phương pháp của chúng tôi đơn giản phân phối khối lượng công việc trên nhiều GPU, duy trì tổng tính toán không đổi. Baseline Patch Ngây thơ, mặc dù tổng MACs thấp hơn, thiếu tương tác quan trọng giữa các patch, dẫn đến đầu ra phân mảnh. Hạn chế này ảnh hưởng đáng kể đến chất lượng hình ảnh, được phản ánh qua tất cả các metric đánh giá. DistriFusion của chúng tôi có thể bảo tồn tương tác tốt. Ngay cả khi sử dụng 8 thiết bị, nó đạt được điểm PSNR, LPIPS, và FID tương đương với mô hình gốc.

Tăng tốc. So với giảm tính toán lý thuyết, tăng tốc trên phần cứng quan trọng hơn cho các ứng dụng thực tế. Để chứng minh tính hiệu quả của phương pháp chúng tôi, chúng tôi cũng báo cáo độ trễ end-to-end trong Bảng 1 trên 8 GPU NVIDIA A100. Trong cài đặt 50 bước, ParaDiGMS đạt được tăng tốc tương tự 2.8× với phương pháp của chúng tôi với chi phí chất lượng hình ảnh bị tổn hại (xem Hình 5). Trong cài đặt 25 bước được sử dụng phổ biến hơn, ParaDiGMS chỉ có tăng tốc 1.3× do dự đoán lãng phí quá mức, điều này cũng được báo cáo trong Shih et al. [59]. Tuy nhiên, phương pháp của chúng tôi vẫn có thể phản ánh chất lượng gốc và tăng tốc mô hình 2.7×.

Khi tạo ra hình ảnh 1024×1024, tăng tốc của chúng tôi bị hạn chế bởi sử dụng GPU thấp của SDXL. Để tối đa hóa sử dụng thiết bị, chúng tôi tiếp tục mở rộng độ phân giải lên 2048×2048 và 3840×3840 trong Hình 6. Ở những độ phân giải lớn hơn này, các thiết bị GPU được sử dụng tốt hơn. Cụ thể, đối với hình ảnh 3840×3840, DistriFusion giảm độ trễ 1.8×, 3.4× và 6.1× với 2, 4 và 8 A100, tương ứng.

Lưu ý rằng những kết quả này được đánh giá với PyTorch. Với các trình biên dịch tiến bộ hơn, như TVM [4] và TensorRT [1], chúng tôi dự đoán sử dụng GPU cao hơn và do đó tăng tốc rõ rệt hơn từ DistriFusion, như quan sát thấy trong SIGE [23]. Trong việc sử dụng thực tế, kích thước batch thường tăng gấp đôi do hướng dẫn không có bộ phân loại [12]. Chúng tôi có thể chia batch trước và sau đó áp dụng DistriFusion cho từng batch riêng biệt. Cách tiếp cận này tiếp tục cải thiện tổng tăng tốc lên 3.6× và 6.6× với 4 và 8 A100 để tạo ra một hình ảnh 3840×3840 đơn lẻ, tương ứng.

5.3. Nghiên cứu Ablation

So sánh với tính song song tensor. Trong Bảng 2, chúng tôi đánh giá độ trễ của chúng tôi với tính song song tensor đồng bộ (Sync. TP) và tính song song patch đồng bộ (Sync. PP), và báo cáo lượng giao tiếp tương ứng. So với TP, PP có tính độc lập tốt hơn, loại bỏ nhu cầu giao tiếp trong các lớp cross-attention và tuyến tính. Đối với các lớp tích chập, giao tiếp chỉ được yêu cầu tại ranh giới patch, đại diện cho một phần nhỏ của toàn bộ tensor. Hơn nữa, PP sử dụng AllGather thay vì AllReduce, dẫn đến yêu cầu giao tiếp thấp hơn và không sử dụng thêm tài nguyên tính toán. Do đó, PP yêu cầu ít hơn 60% lượng giao tiếp và nhanh hơn 1.6∼2.1× so với TP, làm cho nó trở thành cách tiếp cận hiệu quả hơn để triển khai mô hình khuếch tán. Chúng tôi cũng bao gồm một baseline PP lý thuyết không có giao tiếp nào (No Comm.) để chứng minh chi phí giao tiếp trong Sync. PP và DistriFusion. So với Sync. PP, DistriFusion tiếp tục cắt giảm chi phí như vậy hơn 50%. Chi phí còn lại chủ yếu đến từ việc sử dụng hiện tại của chúng tôi về NVIDIA Collective Communication Library (NCCL) cho giao tiếp không đồng bộ. Kernel NCCL sử dụng SM (tài nguyên tính toán trên GPU), sẽ làm chậm tính toán chồng chéo. Sử dụng truy cập bộ nhớ từ xa có thể bỏ qua vấn đề này và thu hẹp khoảng cách hiệu suất.

Sự tương tự đầu vào. Tính song song patch dịch chuyển của chúng tôi dựa trên giả định rằng đầu vào từ các bước khử nhiễu liên tiếp tương tự nhau. Để hỗ trợ tuyên bố này, chúng tôi định lượng tính toán sự khác biệt đầu vào mô hình qua tất cả các bước liên tiếp bằng cách sử dụng bộ lấy mẫu DDIM 50 bước. Sự khác biệt trung bình chỉ là 0.02, trong phạm vi đầu vào [−4,4] (khoảng 0.3%). Hình 7 tiếp tục hình dung định tính sự khác biệt đầu vào giữa bước 9 và 8 (được chọn ngẫu nhiên). Sự khác biệt gần như tất cả đều bằng không, thể hiện độ tương tự cao.

Lấy mẫu ít bước và các bước khởi động. Như đã nêu ở trên, cách tiếp cận của chúng tôi dựa trên quan sát rằng các bước khử nhiễu liền kề chia sẻ đầu vào tương tự, tức là xt ≈ xt−1. Tuy nhiên, khi chúng ta tăng kích thước bước và do đó giảm số lượng bước, lỗi xấp xỉ tăng lên, có thể làm tổn hại hiệu quả của phương pháp chúng tôi. Trong Hình 8, chúng tôi trình bày kết quả sử dụng DPM-Solver 10 bước [32,33]. Cấu hình 10 bước là ngưỡng cho các bộ lấy mẫu không cần huấn luyện để duy trì chất lượng hình ảnh. Dưới cài đặt này, DistriFusion ngây thơ không có khởi động gặp khó khăn trong việc bảo tồn chất lượng hình ảnh. Tuy nhiên, việc kết hợp thêm hai bước khởi động phục hồi đáng kể hiệu suất với chỉ độ trễ tăng nhẹ.

GroupNorm. Như thảo luận trong Mục 4, việc tính toán thống kê group normalization (GN) chính xác là quan trọng để bảo tồn chất lượng hình ảnh. Trong Hình 9, chúng tôi so sánh bốn sơ đồ GN khác nhau. Cách tiếp cận đầu tiên GN Riêng biệt sử dụng thống kê từ patch tươi trên thiết bị. Cách tiếp cận này mang lại tốc độ tốt nhất với chi phí độ chính xác hình ảnh thấp hơn. Sự thỏa hiệp này đặc biệt nghiêm trọng đối với số lượng lớn thiết bị được sử dụng, do kích thước patch không đủ để ước tính thống kê chính xác. Sơ đồ thứ hai GN Cũ tính toán thống kê bằng cách sử dụng activation cũ. Tuy nhiên, phương pháp này cũng đối mặt với suy giảm chất lượng, do các phân phối khác nhau giữa activation cũ và tươi, thường dẫn đến hình ảnh có hiệu ứng nhiễu như sương mù. Cách tiếp cận thứ ba GN Sync. sử dụng giao tiếp đồng bộ hóa để tập hợp thống kê chính xác. Mặc dù đạt được chất lượng hình ảnh tốt nhất, nó gặp phải chi phí đồng bộ hóa lớn. Phương pháp của chúng tôi sử dụng một thuật ngữ hiệu chỉnh để thu hẹp khoảng cách phân phối giữa thống kê cũ và tươi. Nó đạt được chất lượng hình ảnh ngang bằng với GN Sync. nhưng không gây ra chi phí giao tiếp đồng bộ.

6. Kết luận & Thảo luận

Trong bài báo này, chúng tôi giới thiệu DistriFusion để tăng tốc mô hình khuếch tán với nhiều GPU cho tính song song. Phương pháp của chúng tôi chia hình ảnh thành các patch, gán mỗi patch cho một GPU riêng biệt. Chúng tôi tái sử dụng activation đã được tính toán trước từ các bước trước để duy trì tương tác patch. Trên Stable Diffusion XL, phương pháp của chúng tôi đạt được tăng tốc lên đến 6.1× trên 8 GPU NVIDIA A100. Tiến bộ này không chỉ nâng cao hiệu quả của việc tạo nội dung AI mà còn đặt ra một tiêu chuẩn mới cho nghiên cứu tương lai trong tính toán song song cho các ứng dụng AI.

Hạn chế. Để hoàn toàn ẩn chi phí giao tiếp trong tính toán, NVLink là cần thiết cho DistriFusion để tối đa hóa tăng tốc. Tuy nhiên, NVLink đã được sử dụng rộng rãi gần đây. Hơn nữa, quantization [25] cũng có thể giảm khối lượng công việc giao tiếp cho phương pháp của chúng tôi. Bên cạnh đó, DistriFusion có tăng tốc hạn chế cho hình ảnh độ phân giải thấp vì các thiết bị không được sử dụng đủ. Các trình biên dịch tiên tiến [1,4] sẽ giúp khai thác các thiết bị và đạt được tăng tốc tốt hơn. Phương pháp của chúng tôi có thể không hoạt động cho các phương pháp cực ít bước [34–36,57,63], do sự thay đổi nhanh chóng của các trạng thái khử nhiễu. Tuy nhiên, thí nghiệm sơ bộ của chúng tôi gợi ý rằng nhiều bước hơn một chút (ví dụ, 10) là đủ để DistriFusion có được kết quả chất lượng cao.

Lời cảm ơn
Chúng tôi cảm ơn Jun-Yan Zhu và Ligeng Zhu cho cuộc thảo luận hữu ích và phản hồi có giá trị. Dự án được hỗ trợ bởi MIT-IBM Watson AI Lab, Amazon, MIT Science Hub, và National Science Foundation.

Nhật ký thay đổi
V1 Phát hành preprint ban đầu (CVPR 2024).
V2 Cập nhật Hình 1 và 2.
V3 Sửa giá trị PSNR trong Bảng 1.

Tài liệu tham khảo
[1] NVIDIA/TensorRT. 2023. 7, 9
[2] Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, et al. ediffi: Text-to-image diffusion models with an ensemble of expert denoisers. arXiv preprint arXiv:2211.01324, 2022. 2, 3, 5
[3] James Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et al. Improving image generation with better captions. Computer Science. https://cdn.openai.com/papers/dall-e-3.pdf, 2023. 2
[4] Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Haichen Shen, Meghan Cowan, Leyuan Wang, Yuwei Hu, Luis Ceze, et al. {TVM}: An automated {End-to-End} optimizing compiler for deep learning. In OSDI, 2018. 7, 9
[5] Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr Dollár, và C Lawrence Zitnick. Microsoft coco captions: Data collection and evaluation server. arXiv preprint arXiv:1504.00325, 2015. 3, 6, 9
[6] Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, et al. Emu: Enhancing image generation models using photogenic needles in a haystack. arXiv preprint arXiv:2309.15807, 2023. 2
[7] Xuanyi Dong, Junshi Huang, Yi Yang, và Shuicheng Yan. More is less: A more complicated network with less inference complexity. In CVPR, 2017. 3
[8] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, và Yoshua Bengio. Generative adversarial nets. NeurIPS, 2014. 3
[9] Jiatao Gu, Shuangfei Zhai, Yizhe Zhang, Josh Susskind, và Navdeep Jaitly. Matryoshka diffusion models. arXiv preprint arXiv:2310.15111, 2023. 3
[10] Song Han, Jeff Pool, John Tran, và William Dally. Learning both weights and connections for efficient neural network. NeurIPS, 2015. 3
[11] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, và Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. NeurIPS, 2017. 6
[12] Jonathan Ho và Tim Salimans. Classifier-free diffusion guidance. In NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications, 2021. 3, 8
[13] Jonathan Ho, Ajay Jain, và Pieter Abbeel. Denoising diffusion probabilistic models. NeurIPS, 2020. 2, 3
[14] Emiel Hoogeboom, Jonathan Heek, và Tim Salimans. simple diffusion: End-to-end diffusion for high resolution images. arXiv preprint arXiv:2301.11093, 2023. 3
[15] Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V Le, Yonghui Wu, et al. Gpipe: Efficient training of giant neural networks using pipeline parallelism. NeurIPS, 2019. 3
[16] Max Jaderberg, Andrea Vedaldi, và Andrew Zisserman. Speeding up convolutional neural networks with low rank expansions. In BMVC, 2014. 3
[17] Zhihao Jia, Matei Zaharia, và Alex Aiken. Beyond data and model parallelism for deep neural networks. MLSys, 2019. 3
[18] Patrick Judd, Alberto Delmas, Sayeh Sharify, và Andreas Moshovos. Cnvlutin2: Ineffectual-activation-and-weight-free deep neural network computing. arXiv preprint arXiv:1705.00125, 2017. 3
[19] Gwanghyun Kim và Jong Chul Ye. Diffusionclip: Text-guided image manipulation using diffusion models. arXiv preprint arXiv:2110.02711, 2021. 3
[20] Zhifeng Kong và Wei Ping. On fast sampling of diffusion probabilistic models. In ICML Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models, 2021. 2
[21] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, và Hans Peter Graf. Pruning filters for efficient convnets. ICLR, 2016. 3
[22] Muyang Li, Ji Lin, Yaoyao Ding, Zhijian Liu, Jun-Yan Zhu, và Song Han. Gan compression: Efficient architectures for interactive conditional gans. In CVPR, 2020. 6
[23] Muyang Li, Ji Lin, Chenlin Meng, Stefano Ermon, Song Han, và Jun-Yan Zhu. Efficient spatially sparse inference for conditional gans and diffusion models. In NeurIPS, 2022. 2, 3, 5, 6, 8
[24] Xiaoxiao Li, Ziwei Liu, Ping Luo, Chen Change Loy, và Xiaoou Tang. Not all pixels are equal: Difficulty-aware semantic segmentation via deep layer cascade. In CVPR, 2017. 3
[25] Xiuyu Li, Long Lian, Yijiang Liu, Huanrui Yang, Zhen Dong, Daniel Kang, Shanghang Zhang, và Kurt Keutzer. Q-diffusion: Quantizing diffusion models. arXiv preprint arXiv:2302.04304, 2023. 2, 3, 9
[26] Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun Fu, Yanzhi Wang, Sergey Tulyakov, và Jian Ren. Snapfusion: Text-to-image diffusion model on mobile devices within two seconds. NeurIPS, 2023. 2, 3
[27] Zhuohan Li, Siyuan Zhuang, Shiyuan Guo, Danyang Zhuo, Hao Zhang, D. Song, và I. Stoica. Terapipe: Token-level pipeline parallelism for training large-scale language models. ICML, 2021. 3
[28] Zhuohan Li, Lianmin Zheng, Yinmin Zhong, Vincent Liu, Ying Sheng, Xin Jin, Yanping Huang, Z. Chen, Hao Zhang, Joseph E. Gonzalez, và I. Stoica. Alpaserve: Statistical multiplexing with model parallelism for deep learning serving. USENIX Symposium on Operating Systems Design and Implementation, 2023. 3
[29] Ji Lin, Wei-Ming Chen, Han Cai, Chuang Gan, và Song Han. Mcunetv2: Memory-efficient patch-based inference for tiny deep learning. In Annual Conference on Neural Information Processing Systems (NeurIPS), 2021. 3
[30] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, và C Lawrence Zitnick. Microsoft coco: Common objects in context. In Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pages 740–755. Springer, 2014. 6
[31] Baoyuan Liu, Min Wang, Hassan Foroosh, Marshall Tappen, và Marianna Pensky. Sparse convolutional neural networks. In CVPR, 2015. 3
[32] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, và Jun Zhu. Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. arXiv preprint arXiv:2206.00927, 2022. 2, 3, 9
[33] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, và Jun Zhu. Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models. arXiv preprint arXiv:2211.01095, 2022. 2, 9
[34] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, và Hang Zhao. Latent consistency models: Synthesizing high-resolution images with few-step inference. arXiv preprint arXiv: 2310.04378, 2023. 9
[35] Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu, Patrick von Platen, Apolinário Passos, Longbo Huang, Jian Li, và Hang Zhao. Lcm-lora: A universal stable-diffusion acceleration module. arXiv preprint arXiv: 2311.05556, 2023.
[36] Chenlin Meng, Ruiqi Gao, Diederik P Kingma, Stefano Ermon, Jonathan Ho, và Tim Salimans. On distillation of guided diffusion models. arXiv preprint arXiv:2210.03142, 2022. 2, 3, 9
[37] Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, và Stefano Ermon. SDEdit: Guided image synthesis and editing with stochastic differential equations. In ICLR, 2022. 6
[38] Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gregory R Ganger, Phillip B Gibbons, và Matei Zaharia. Pipedream: Generalized pipeline parallelism for dnn training. In SOSP, 2019. 3
[39] D. Narayanan, M. Shoeybi, J. Casper, P. LeGresley, M. Patwary, V. Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti, J. Bernauer, Bryan Catanzaro, Amar Phanishayee, và M. Zaharia. Efficient large-scale language model training on gpu clusters using megatron-lm. International Conference for High Performance Computing, Networking, Storage and Analysis, 2021. 3
[40] Alexander Quinn Nichol và Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In ICML, 2021. 5
[41] Alexander Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob Mcgrew, Ilya Sutskever, và Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. In ICML, 2022. 3
[42] Bowen Pan, Wuwei Lin, Xiaolin Fang, Chaoqin Huang, Bolei Zhou, và Cewu Lu. Recurrent residual module for fast inference in videos. In CVPR, 2018. 3
[43] Taesung Park, Ming-Yu Liu, Ting-Chun Wang, và Jun-Yan Zhu. Semantic image synthesis with spatially-adaptive normalization. In CVPR, 2019. 6
[44] Gaurav Parmar, Richard Zhang, và Jun-Yan Zhu. On aliased resizing and surprising subtleties in GAN evaluation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022, pages 11400–11410. IEEE, 2022. 6
[45] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: an imperative style, high-performance deep learning library. In NeurIPS, 2019. 6
[46] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna, và Robin Rombach. Sdxl: Improving latent diffusion models for high-resolution image synthesis. In ICLR, 2024. 2, 3, 4, 6
[47] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, và Yuxiong He. Zero: Memory optimizations toward training trillion parameter models. Sc20: International Conference For High Performance Computing, Networking, Storage And Analysis, 2019. 3
[48] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, và Ilya Sutskever. Zero-shot text-to-image generation. In ICML, 2021. 2
[49] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, và Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022. 2
[50] Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, và Yuxiong He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 3505–3506, 2020. 3
[51] Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong Li, và Yuxiong He. Zero-offload: Democratizing billion-scale model training. In 2021 USENIX Annual Technical Conference, USENIX ATC 2021, July 14-16, 2021, pages 551–564. USENIX Association, 2021. 3
[52] Mengye Ren, Andrei Pokrovsky, Bin Yang, và Raquel Urtasun. Sbnet: Sparse blocks network for fast inference. In CVPR, 2018. 3
[53] Gernot Riegler, Ali Osman Ulusoy, và Andreas Geiger. Octnet: Learning deep 3d representations at high resolutions. In CVPR, 2017. 3
[54] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, và Björn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, 2022. 2, 3, 6
[55] Olaf Ronneberger, Philipp Fischer, và Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18, pages 234–241. Springer, 2015. 4
[56] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. NeurIPS, 2022. 2
[57] Tim Salimans và Jonathan Ho. Progressive distillation for fast sampling of diffusion models. In ICLR, 2021. 2, 3, 9
[58] Shaohuai Shi và Xiaowen Chu. Speeding up convolutional neural networks by exploiting the sparsity of rectifier units. arXiv preprint arXiv:1704.07724, 2017. 3
[59] Andy Shih, Suneel Belkhale, Stefano Ermon, Dorsa Sadigh, và Nima Anari. Parallel sampling of diffusion models. NeurIPS, 2023. 3, 4, 6, 7
[60] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, và Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In ICML, 2015. 2
[61] Jiaming Song, Chenlin Meng, và Stefano Ermon. Denoising diffusion implicit models. In ICLR, 2020. 2, 6, 8
[62] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, và Ben Poole. Score-based generative modeling through stochastic differential equations. In ICLR, 2020. 3
[63] Yang Song, Prafulla Dhariwal, Mark Chen, và Ilya Sutskever. Consistency models. 2023. 9
[64] Haotian Tang, Zhijian Liu, Xiuyu Li, Yujun Lin, và Song Han. Torchsparse: Efficient point cloud inference engine. In MLSys, 2022. 3
[65] Haotian Tang, Shang Yang, Zhijian Liu, Ke Hong, Zhongming Yu, Xiuyu Li, Guohao Dai, Yu Wang, và Song Han. Torchsparse++: Efficient training and inference framework for sparse convolution on gpus. In MICRO, 2023. 3
[66] Arash Vahdat, Karsten Kreis, và Jan Kautz. Score-based generative modeling in latent space. 34:11287–11302, 2021. 3
[67] Leslie G. Valiant. A bridging model for parallel computation. Commun. ACM, 33(8):103–111, 1990. 3
[68] Yuxin Wu và Kaiming He. Group normalization. In ECCV, 2018. 5
[69] Guangxuan Xiao, Tianwei Yin, William T. Freeman, Frédo Durand, và Song Han. Fastcomposer: Tuning-free multi-subject image generation with localized attention. arXiv, 2023. 5
[70] Zhisheng Xiao, Karsten Kreis, và Arash Vahdat. Tackling the generative learning trilemma with denoising diffusion GANs. In ICLR, 2022. 2
[71] Yuanzhong Xu, HyoukJoong Lee, Dehao Chen, Blake Hechtman, Yanping Huang, Rahul Joshi, Maxim Krikun, Dmitry Lepikhin, Andy Ly, Marcello Maggioni, Ruoming Pang, Noam Shazeer, Shibo Wang, Tao Wang, Yonghui Wu, và Zhifeng Chen. Gspmd: General and scalable parallelization for ml computation graphs. arXiv preprint arXiv: 2105.04663, 2021. 3
[72] Jinhui Yuan, Xinqi Li, Cheng Cheng, Juncheng Liu, Ran Guo, Shenghang Cai, Chi Yao, Fei Yang, Xiaodong Yi, Chuan Wu, Haoran Zhang, và Jie Zhao. Oneflow: Redesign the distributed deep learning framework from scratch. arXiv preprint arXiv: 2110.15032, 2021. 3
[73] Qinsheng Zhang và Yongxin Chen. Fast sampling of diffusion models with exponential integrator. In ICLR, 2022. 2, 3
[74] Qinsheng Zhang, Molei Tao, và Yongxin Chen. gddim: Generalized denoising diffusion implicit models. 2022. 3
[75] Qinsheng Zhang, Jiaming Song, Xun Huang, Yongxin Chen, và Ming yu Liu. Diffcollage: Parallel generation of large content with diffusion models. In CVPR, 2023. 3
[76] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, và Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In CVPR, 2018. 6
[77] Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid Shojanazeri, Myle Ott, Sam Shleifer, et al. Pytorch fsdp: experiences on scaling fully sharded data parallel. arXiv preprint arXiv:2304.11277, 2023. 3
[78] Lianmin Zheng, Zhuohan Li, Hao Zhang, Yonghao Zhuang, Zhifeng Chen, Yanping Huang, Yida Wang, Yuanzhong Xu, Danyang Zhuo, Eric P Xing, et al. Alpa: Automating inter-and {Intra-Operator} parallelism for distributed deep learning. In 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22), pages 559–578, 2022. 3

# MM-LLMs: Tiến bộ gần đây trong các mô hình ngôn ngữ lớn đa phương thức

Duzhen Zhang1*‡, Yahan Yu3*, Jiahua Dong4†, Chenxing Li1, Dan Su1,
Chenhui Chu3† và Dong Yu2
1Tencent AI Lab, Trung Quốc2Tencent AI Lab, Hoa Kỳ3Đại học Kyoto, Nhật Bản
4Đại học Trí tuệ nhân tạo Mohamed bin Zayed, Các tiểu vương quốc Ả Rập thống nhất
{duzhen.zhang972,dongjiahua1995}@gmail.com
{yahan@nlp.ist.,chu@}i.kyoto-u.ac.jp ,{chenxingli@,dansu@,dyu@global.}tencent.com

Tóm tắt
Trong năm qua, các mô hình ngôn ngữ lớn đa phương thức (MM-LLMs) đã trải qua những tiến bộ đáng kể, tăng cường các LLM có sẵn để hỗ trợ đầu vào hoặc đầu ra đa phương thức thông qua các chiến lược đào tạo hiệu quả về chi phí. Các mô hình kết quả không chỉ giữ lại khả năng suy luận và ra quyết định vốn có của LLM mà còn trao quyền cho một loạt các nhiệm vụ đa phương thức đa dạng. Trong bài báo này, chúng tôi cung cấp một khảo sát toàn diện nhằm tạo điều kiện cho nghiên cứu sâu hơn về MM-LLMs. Ban đầu, chúng tôi phác thảo các công thức thiết kế chung cho kiến trúc mô hình và pipeline đào tạo. Tiếp theo, chúng tôi giới thiệu một phân loại bao gồm 126 MM-LLMs, mỗi cái được đặc trưng bởi các công thức cụ thể của nó. Hơn nữa, chúng tôi xem xét hiệu suất của các MM-LLMs được chọn trên các benchmark chính thống và tóm tắt các công thức đào tạo chính để tăng cường sức mạnh của MM-LLMs. Cuối cùng, chúng tôi khám phá các hướng đầy hứa hẹn cho MM-LLMs trong khi đồng thời duy trì một trang web theo dõi thời gian thực1 cho những phát triển mới nhất trong lĩnh vực này. Chúng tôi hy vọng khảo sát này góp phần vào sự tiến bộ liên tục của lĩnh vực MM-LLMs.

1 Giới thiệu
Nghiên cứu tiền đào tạo đa phương thức (MM) đã chứng kiến những tiến bộ đáng kể trong những năm gần đây, liên tục thúc đẩy ranh giới hiệu suất trên một loạt các nhiệm vụ downstream (Li et al., 2020; Akbari et al., 2021; Fang et al., 2021; Yan et al., 2021; Li et al., 2021; Radford et al., 2021; Li et al., 2022; Zellers et al., 2022; Zeng et al., 2022b; Yang et al., 2022; Wang et al., 2022a,b). Tuy nhiên, khi quy mô của các mô hình và bộ dữ liệu tiếp tục mở rộng, các mô hình MM truyền thống phát sinh chi phí tính toán đáng kể, đặc biệt là khi được đào tạo từ đầu. Nhận thức rằng nghiên cứu MM hoạt động ở giao điểm của các phương thức khác nhau, một cách tiếp cận hợp lý là tận dụng các mô hình nền tảng đơn phương thức được tiền đào tạo sẵn có, với sự nhấn mạnh đặc biệt vào các mô hình ngôn ngữ lớn mạnh mẽ (LLMs) (OpenAI, 2022). Chiến lược này nhằm giảm thiểu chi phí tính toán và tăng cường hiệu quả của tiền đào tạo MM, dẫn đến sự xuất hiện của một lĩnh vực mới: MM-LLMs.

MM-LLMs khai thác LLMs như là nguồn năng lực nhận thức để trao quyền cho các nhiệm vụ MM khác nhau. LLMs đóng góp các thuộc tính mong muốn như tạo ngôn ngữ mạnh mẽ, khả năng chuyển giao zero-shot, và học tập trong ngữ cảnh (ICL). Đồng thời, các mô hình nền tảng trong các phương thức khác cung cấp các biểu diễn chất lượng cao. Xem xét các mô hình nền tảng từ các phương thức khác nhau được tiền đào tạo riêng lẻ, thách thức cốt lõi mà MM-LLMs đối mặt là làm thế nào để kết nối hiệu quả LLMs với các mô hình trong các phương thức khác để cho phép suy luận cộng tác. Trọng tâm chủ yếu trong lĩnh vực này là cải thiện sự liên kết giữa các phương thức và liên kết với ý định con người thông qua pipeline tiền đào tạo MM (PT) + điều chỉnh hướng dẫn MM (IT).

Với sự ra mắt của GPT-4(Vision) (OpenAI, 2023) và Gemini (Team et al., 2023), thể hiện khả năng hiểu và tạo MM ấn tượng, một cơn sốt nghiên cứu về MM-LLMs đã được khơi dậy. Nghiên cứu ban đầu chủ yếu tập trung vào hiểu nội dung MM và tạo văn bản, bao gồm các nhiệm vụ như hiểu hình ảnh-văn bản, được minh họa bởi các dự án như BLIP-2 (Li et al., 2023e), LLaVA (Liu et al., 2023e), MiniGPT-4 (Zhu et al., 2023a), và OpenFlamingo (Awadalla et al., 2023); hiểu video-văn bản, như được chứng minh bởi các sáng kiến như VideoChat (Li et al., 2023f), Video-ChatGPT (Maaz et al., 2023), và LLaMA-VID (Li et al., 2023j); và hiểu âm thanh-văn bản, như được thấy trong các dự án như Qwen-Audio (Chu et al., 2023b). Sau đó, khả năng của MM-LLMs đã được mở rộng để hỗ trợ đầu ra phương thức cụ thể. Điều này bao gồm các nhiệm vụ với đầu ra hình ảnh-văn bản, như GILL (Koh et al., 2023a), Kosmos-2 (Peng et al., 2023), Emu (Sun et al., 2024), và MiniGPT-5 (Zheng et al., 2023b); cũng như đầu ra giọng nói/âm thanh-văn bản, được minh họa bởi các dự án như SpeechGPT (Zhang et al., 2023a) và AudioPaLM (Rubenstein et al., 2023). Các nỗ lực nghiên cứu gần đây đã tập trung vào việc bắt chước chuyển đổi phương thức bất kỳ sang bất kỳ giống con người, làm sáng tỏ con đường đến trí tuệ nhân tạo tổng quát. Một số nỗ lực nhằm hợp nhất LLMs với các công cụ bên ngoài để đạt được hiểu biết và tạo MM bất kỳ sang bất kỳ gần như hoàn hảo, như Visual-ChatGPT (Wu et al., 2023a), HuggingGPT (Shen et al., 2023), và AudioGPT (Huang et al., 2023b). Ngược lại, để giảm thiểu các lỗi lan truyền trong hệ thống phối tầng, các sáng kiến như NExT-GPT (Wu et al., 2023d), CoDi-2 (Tang et al., 2023c), và ModaVerse (Wang et al., 2024d) đã phát triển các MM-LLMs đầu cuối đến cuối của các phương thức tùy ý. Dòng thời gian của MM-LLMs được mô tả trong Hình 1.

Trong bài báo này, chúng tôi trình bày một khảo sát toàn diện nhằm tạo điều kiện cho nghiên cứu sâu hơn về MM-LLMs. Để cung cấp cho độc giả hiểu biết toàn diện về MM-LLMs, chúng tôi ban đầu phác thảo các công thức thiết kế chung từ kiến trúc mô hình (Phần 2) và pipeline đào tạo (Phần 3). Chúng tôi chia nhỏ kiến trúc mô hình chung thành năm thành phần: bộ mã hóa phương thức (Phần 2.1), bộ chiếu đầu vào (Phần 2.2), xương sống LLM (Phần 2.3), bộ chiếu đầu ra (Phần 2.4), và bộ tạo phương thức (Phần 2.5). Pipeline đào tạo làm sáng tỏ cách tăng cường LLM chỉ văn bản được tiền đào tạo để hỗ trợ đầu vào hoặc đầu ra MM, chủ yếu bao gồm hai giai đoạn: MM PT (Phần 3.1) và MM IT (Phần 3.2). Trong phần đó, chúng tôi cũng cung cấp một tóm tắt về các bộ dữ liệu chính thống cho MM PT và MM IT. Tiếp theo, chúng tôi thiết lập một phân loại bao gồm 126 MM-LLMs tiên tiến (SOTA), mỗi cái được đặc trưng bởi các công thức cụ thể, và tóm tắt các xu hướng phát triển của chúng trong Phần 4. Trong Phần 5, chúng tôi xem xét toàn diện hiệu suất của các MM-LLMs chính trên các benchmark chính thống và chưng cất các công thức đào tạo chính để tăng cường hiệu quả của MM-LLMs. Trong Phần 6, chúng tôi đưa ra các hướng đầy hứa hẹn cho nghiên cứu MM-LLMs. Hơn nữa, chúng tôi đã thiết lập một trang web (https://mm-llms.github.io) để theo dõi tiến trình mới nhất của MM-LLMs và tạo điều kiện cho việc cập nhật từ cộng đồng. Cuối cùng, chúng tôi tóm tắt toàn bộ bài báo trong Phần 7 và thảo luận các khảo sát liên quan về MM-LLMs trong Phụ lục A. Chúng tôi khao khát khảo sát của mình sẽ hỗ trợ các nhà nghiên cứu có được hiểu biết sâu hơn về lĩnh vực này và truyền cảm hứng cho việc thiết kế các MM-LLMs hiệu quả hơn.

2 Kiến trúc mô hình
Trong phần này, chúng tôi cung cấp một tổng quan chi tiết về năm thành phần bao gồm kiến trúc mô hình chung, cùng với các lựa chọn triển khai cho mỗi thành phần, như được minh họa trong Hình 2. MM-LLMs nhấn mạnh vào hiểu MM chỉ bao gồm ba thành phần đầu tiên. Trong quá trình đào tạo, bộ mã hóa phương thức, xương sống LLM, và bộ tạo phương thức thường được duy trì trong trạng thái đóng băng. Trọng tâm tối ưu hóa chính là trên các bộ chiếu đầu vào và đầu ra. Cho rằng các bộ chiếu là những thành phần nhẹ, tỷ lệ các tham số có thể đào tạo trong MM-LLMs đáng kể nhỏ so với tổng số tham số (thường khoảng 2%). Tổng số tham số phụ thuộc vào quy mô của LLM cốt lõi được sử dụng trong MM-LLMs. Kết quả là, MM-LLMs có thể được đào tạo hiệu quả để trao quyền cho các nhiệm vụ MM khác nhau.

2.1 Bộ mã hóa phương thức
Bộ mã hóa phương thức (ME) được giao nhiệm vụ mã hóa đầu vào từ các phương thức đa dạng IX để thu được các đặc trưng tương ứng FX, được công thức hóa như sau:
FX=MEX(IX). (1)

Các lựa chọn bộ mã hóa MEX được tiền đào tạo khác nhau tồn tại để xử lý các phương thức khác nhau, trong đó X có thể là hình ảnh, video, âm thanh, 3D, v.v. Tiếp theo, chúng tôi sẽ đưa ra một giới thiệu ngắn gọn được tổ chức theo phương thức.

Phương thức trực quan Đối với hình ảnh, có nhiều bộ mã hóa tùy chọn khác nhau: NFNet-F6 (Brock et al., 2021), ViT (Dosovitskiy et al., 2020), CLIP ViT (Radford et al., 2021), Eva-CLIP ViT (Fang et al., 2023), BEiT-3 (Wang et al., 2023d), OpenCLIP (Cherti et al., 2023), Grounding-DINO-T (Zhang et al., 2022b) với xương sống Swin-T (Liu et al., 2021b), DINOv2 (Oquab et al., 2023), SAM-HQ (Kirillov et al., 2023) với MAE (He et al., 2022), RAM++ (Zhang et al., 2023i) với xương sống Swin-B, InternViT (Chen et al., 2023j), và VCoder (Jain et al., 2023). Đối với video, chúng có thể được lấy mẫu đồng đều thành 5 khung hình, trải qua quá trình tiền xử lý giống như hình ảnh.

Phương thức âm thanh thường được mã hóa bởi C-Former (Chen et al., 2023b), HuBERT (Hsu et al., 2021), BEATs (Chen et al., 2023g), Whisper (Radford et al., 2023), và CLAP (Wu et al., 2023e).

Phương thức đám mây điểm 3D thường được mã hóa bởi ULIP-2 (Salesforce, 2022) với xương sống Point-BERT (Yu et al., 2022).

Hơn nữa, để xử lý nhiều bộ mã hóa modal không đồng nhất, một số MM-LLMs, đặc biệt là những cái bất kỳ sang bất kỳ, sử dụng ImageBind (Girdhar et al., 2023), một bộ mã hóa thống nhất bao gồm sáu phương thức, bao gồm hình ảnh/video, văn bản, âm thanh, bản đồ nhiệt, đơn vị đo lường quán tính, và độ sâu. Chúng tôi cung cấp một giới thiệu ngắn gọn về một số bộ mã hóa phương thức chính thống trong Phụ lục B.

2.2 Bộ chiếu đầu vào
Bộ chiếu đầu vào ΘX→T được giao nhiệm vụ liên kết các đặc trưng được mã hóa của các phương thức khác FX với không gian đặc trưng văn bản T. Các đặc trưng được liên kết như các gợi ý PX sau đó được đưa vào xương sống LLM cùng với các đặc trưng văn bản FT. Cho bộ dữ liệu X-văn bản {IX, t}, mục tiêu là giảm thiểu mất mát tạo văn bản có điều kiện X Ltxt-gen :
arg min ΘX→T Ltxt-gen(LLM(PX,FT), t), (2)
trong đó PX=ΘX→T(FX).

Bộ chiếu đầu vào có thể được thực hiện trực tiếp bằng một bộ chiếu tuyến tính hoặc perceptron đa tầng (MLP), tức là, một số bộ chiếu tuyến tính xen kẽ với các hàm kích hoạt phi tuyến tính. Cũng có các triển khai phức tạp hơn như cross-attention, Q-Former (Li et al., 2023e), P-Former (Jian et al., 2023), và MQ-Former (Lu et al., 2023a). Cross-attention (Perceiver Resampler) (Alayrac et al., 2022) sử dụng một tập hợp các vector có thể đào tạo làm truy vấn và các đặc trưng được mã hóa FX làm khóa để nén chuỗi đặc trưng thành độ dài cố định. Biểu diễn được nén sau đó được đưa trực tiếp vào LLM hoặc được sử dụng thêm cho fusion cross-attention X-Text. Q-Former trích xuất các đặc trưng liên quan từ FX với các truy vấn có thể học, và các đặc trưng được chọn sau đó được sử dụng như các gợi ý PX. Trong khi đó, P-Former tạo ra "gợi ý tham chiếu", áp đặt một ràng buộc liên kết trên các gợi ý được tạo ra bởi Q-Former. MQ-Former thực hiện sự liên kết tỉ mỉ của các tín hiệu trực quan và văn bản đa quy mô. Tuy nhiên, cả Q-, P-, MQ-Former đều yêu cầu một quá trình PT bổ sung để khởi tạo.

2.3 Xương sống LLM
Lấy LLMs (Zhao et al., 2023c; Naveed et al., 2023; Mo et al., 2024) làm các tác nhân cốt lõi, MM-LLMs có thể kế thừa một số thuộc tính đáng chú ý như khái quát hóa zero-shot, ICL vài shot, chuỗi suy nghĩ (CoT), và tuân theo hướng dẫn. Xương sống LLM xử lý các biểu diễn từ các phương thức khác nhau, tham gia vào hiểu biết ngữ nghĩa, suy luận, và ra quyết định liên quan đến đầu vào. Nó tạo ra (1) đầu ra văn bản trực tiếp t, và (2) token tín hiệu SX từ các phương thức khác (nếu có). Các token tín hiệu này hoạt động như các hướng dẫn để hướng dẫn bộ tạo về việc có tạo ra nội dung MM hay không và, nếu khẳng định, chỉ định nội dung để tạo ra:
t,SX=LLM(PX,FT), (3)
trong đó các biểu diễn được liên kết của các phương thức khác PX có thể được coi là điều chỉnh gợi ý mềm cho LLM. Hơn nữa, một số công trình đã giới thiệu các phương pháp điều chỉnh hiệu quả tham số (PEFT), như điều chỉnh tiền tố (Li and Liang, 2021), LoRA (Hu et al., 2021), và điều chỉnh LayerNorm (Zhao et al., 2024). Trong những trường hợp này, số lượng tham số có thể đào tạo bổ sung là cực kỳ tối thiểu, thậm chí ít hơn 0,1% tổng số tham số LLM. Chúng tôi cung cấp một giới thiệu về các phương pháp PEFT chính thống trong Phụ lục C.

Các LLM thường được sử dụng trong MM-LLMs bao gồm Flan-T5 (Chung et al., 2022), ChatGLM (Zeng et al., 2022a), UL2 (Tay et al., 2022), Persimmon (Elsen et al., 2023), Qwen (Bai et al., 2023a), Chinchilla (Hoffmann et al., 2022), OPT (Zhang et al., 2022c), PaLM (Chowdhery et al., 2023), LLaMA (Touvron et al., 2023a), LLaMA-2 (Touvron et al., 2023b), và Vicuna (Chiang et al., 2023). Chúng tôi cung cấp một giới thiệu ngắn gọn về một số LLM đại diện trong Phụ lục D.

2.4 Bộ chiếu đầu ra
Bộ chiếu đầu ra ΘT→X ánh xạ các biểu diễn token tín hiệu SX từ xương sống LLM thành các đặc trưng HX có thể hiểu được đối với bộ tạo phương thức MGX tiếp theo. Cho bộ dữ liệu X-văn bản {IX, t}, t trước tiên được đưa vào LLM để tạo ra SX tương ứng, sau đó được ánh xạ thành HX. Để tạo điều kiện cho việc liên kết các đặc trưng được ánh xạ HX, mục tiêu là giảm thiểu khoảng cách giữa HX và các biểu diễn văn bản có điều kiện của MGX:
arg min ΘT→X Lmse(HX, τX(t)). (4)

Việc tối ưu hóa chỉ dựa vào các văn bản chú thích, mà không sử dụng bất kỳ tài nguyên âm thanh hoặc hình ảnh X nào, trong đó HX=ΘT→X(SX) và τX là bộ mã hóa điều kiện văn bản trong MGX. Bộ chiếu đầu ra được triển khai bằng một Transformer nhỏ với một chuỗi đặc trưng bộ giải mã có thể học hoặc MLP.

2.5 Bộ tạo phương thức
Bộ tạo phương thức MGX được giao nhiệm vụ tạo ra đầu ra trong các phương thức khác biệt. Thông thường, các công trình hiện tại sử dụng các mô hình khuếch tán tiềm ẩn có sẵn (LDMs) (Song et al., 2021; Bao et al., 2022; Zhao et al., 2022), tức là, Stable Diffusion (Rombach et al., 2022) cho tổng hợp hình ảnh, Zeroscope (Cerspense, 2023) cho tổng hợp video, và AudioLDM-2 (Liu et al., 2023b,c) cho tổng hợp âm thanh. Các đặc trưng HX được ánh xạ bởi bộ chiếu đầu ra phục vụ như các đầu vào có điều kiện trong quá trình khử nhiễu để tạo ra nội dung MM. Trong quá trình đào tạo, nội dung thực tế trước tiên được chuyển đổi thành một đặc trưng tiềm ẩn z0 bởi VAE được tiền đào tạo (Kingma and Welling, 2013). Sau đó, nhiễu ϵ được thêm vào z0 để có được đặc trưng tiềm ẩn nhiễu zt. Một Unet được tiền đào tạo (Ronneberger et al., 2015) ϵX được sử dụng để tính toán mất mát LDM có điều kiện LX-gen như sau:
LX-gen:=Eϵ∼N(0,1),t||ϵ−ϵX(zt, t,HX)||2 2, (5)
điều này tối ưu hóa các tham số ΘX→T và ΘT→X bằng cách giảm thiểu LX-gen.

3 Pipeline đào tạo
Pipeline đào tạo của MM-LLMs có thể được phân định thành hai giai đoạn chính: MM PT và MM IT.

3.1 MM PT
Trong giai đoạn PT, thường tận dụng các bộ dữ liệu X-Text, các bộ chiếu đầu vào và đầu ra được đào tạo để đạt được sự liên kết giữa các phương thức khác nhau bằng cách tối ưu hóa các mục tiêu được xác định trước. Đối với các mô hình hiểu MM, việc tối ưu hóa chỉ tập trung vào Phương trình (2), trong khi đối với các mô hình tạo MM, việc tối ưu hóa bao gồm các Phương trình (2), (4), và (5). Trong trường hợp sau, Phương trình (2) cũng bao gồm chuỗi token tín hiệu thực tế.

Các bộ dữ liệu X-Text bao gồm Image-Text, Video-Text, và Audio-Text, với Image-Text có hai loại: các cặp Image-Text (ví dụ, <img1> <txt1>) và corpus Image-Text xen kẽ (ví dụ, <txt1> <img1> <txt2><txt3> <img2> <txt4>). Chi tiết của các bộ dữ liệu X-Text được hiển thị trong Bảng 3.

3.2 MM IT
MM IT là một phương pháp bao gồm việc điều chỉnh các MM-LLMs được tiền đào tạo sử dụng các bộ dữ liệu được định dạng hướng dẫn (Wei et al., 2021). Thông qua quá trình này, MM-LLMs có thể khái quát hóa cho các nhiệm vụ chưa thấy bằng cách tuân thủ các hướng dẫn mới, do đó tăng cường hiệu suất zero-shot. Khái niệm đơn giản nhưng có tác động này đã thúc đẩy thành công tiếp theo trong lĩnh vực NLP, được minh họa bởi các công trình như InstructGPT (Ouyang et al., 2022), OPT-IML (Iyer et al., 2022), và InstructBLIP (Dai et al., 2023).

MM IT bao gồm điều chỉnh có giám sát (SFT) và học tăng cường từ phản hồi con người (RLHF), nhằm liên kết với ý định con người và tăng cường khả năng tương tác của MM-LLMs. SFT chuyển đổi một phần dữ liệu giai đoạn PT thành định dạng nhận thức hướng dẫn. Sử dụng câu hỏi-trả lời trực quan (QA) làm ví dụ, các mẫu khác nhau có thể được sử dụng như (1) "<Image>{Question}" Một câu trả lời ngắn cho câu hỏi là; (2) "<Image>" Kiểm tra hình ảnh và trả lời câu hỏi sau với một câu trả lời ngắn gọn: "{Question}. Trả lời:"; và vv. Tiếp theo, nó điều chỉnh các MM-LLMs được tiền đào tạo sử dụng cùng các mục tiêu tối ưu hóa. Các bộ dữ liệu SFT có thể được cấu trúc như QA một lượt hoặc đối thoại nhiều lượt.

Sau SFT, RLHF bao gồm điều chỉnh thêm của mô hình, dựa vào phản hồi liên quan đến các phản hồi của MM-LLMs (ví dụ, phản hồi ngôn ngữ tự nhiên (NLF) được gắn nhãn thủ công hoặc tự động) (Sun et al., 2023b). Quá trình này sử dụng một thuật toán học tăng cường để tích hợp hiệu quả NLF không thể vi phân. Mô hình được đào tạo để tạo ra các phản hồi tương ứng có điều kiện trên NLF (Chen et al., 2023i; Akyürek et al., 2023). Thống kê cho các bộ dữ liệu SFT và RLHF được trình bày trong Bảng 4 của Phụ lục G.

Các bộ dữ liệu được sử dụng bởi các MM-LLMs hiện tại trong các giai đoạn MM PT và MM IT rất đa dạng, nhưng chúng đều là các tập con của các bộ dữ liệu trong Bảng 3 và 4.

4 MM-LLMs tiên tiến
Như được hiển thị trong Hình 3, chúng tôi phân loại 126 MM-LLMs tiên tiến từ cả góc độ chức năng và thiết kế. Trong phân chia thiết kế, "sử dụng công cụ" biểu thị việc coi LLM như hộp đen và cung cấp quyền truy cập vào các hệ thống chuyên gia MM nhất định để thực hiện các nhiệm vụ MM cụ thể thông qua suy luận, trong khi "đầu cuối đến cuối" biểu thị toàn bộ mô hình được đào tạo chung theo cách đầu cuối đến cuối. Dựa trên các công thức thiết kế được xác định trước đó, chúng tôi cũng thực hiện so sánh toàn diện về kiến trúc và quy mô bộ dữ liệu đào tạo cho 43 trong số các MM-LLMs tiên tiến này, như được minh họa trong Bảng 1. Tiếp theo, chúng tôi sẽ tóm tắt các xu hướng phát triển của chúng và giới thiệu ngắn gọn các đóng góp cốt lõi của một số mô hình đại diện trong Phụ lục E.

Xu hướng trong các MM-LLMs hiện tại: (1) Tiến bộ từ sự nhấn mạnh chuyên dụng về hiểu MM đến việc tạo ra các phương thức cụ thể và tiến hóa thêm thành chuyển đổi phương thức bất kỳ sang bất kỳ (ví dụ, MiniGPT-4 → MiniGPT-5 → NExT-GPT); (2) Tiến bộ từ MM PT đến SFT và sau đó đến RLHF, pipeline đào tạo trải qua sự cải tiến liên tục, phấn đấu để liên kết tốt hơn với ý định con người và tăng cường khả năng tương tác đối thoại của mô hình (ví dụ, BLIP-2 → InstructBLIP → DRESS); (3) Chấp nhận các mở rộng modal đa dạng (ví dụ, BLIP-2 → X-LLM và InstructBLIP → X-InstructBLIP); (4) Kết hợp bộ dữ liệu đào tạo chất lượng cao hơn (ví dụ, LLaVA → LLaVA-1.5); (5) Áp dụng kiến trúc mô hình hiệu quả hơn, chuyển đổi từ các mô-đun bộ chiếu đầu vào Q- và P-Former phức tạp trong BLIP-2 và DLP đến một bộ chiếu tuyến tính đơn giản nhưng hiệu quả trong VILA.

5 Benchmarks và hiệu suất
Để cung cấp so sánh hiệu suất toàn diện, chúng tôi đã biên soạn một bảng gồm các MM-LLMs chính trên 18 benchmark ngôn ngữ-thị giác (VL), như được báo cáo trong các bài báo khác nhau (Li et al., 2023e; Chen et al., 2023d,f; Lin et al., 2023). Thông tin này được trình bày trong Bảng 2, với mô tả chi tiết về các benchmark này có sẵn trong Phụ lục F. Cho nhiều benchmark có sẵn, chúng tôi tập trung vào đánh giá và so sánh các MM-LLMs khác nhau dựa trên OKVQA, IconVQA, VQAv2, và GQA.

OKVQA bao gồm các câu hỏi yêu cầu suy luận với nhiều loại kiến thức khác nhau như thông thức, kiến thức thế giới, và kiến thức trực quan. MiniGPT-v2 và MiniGPT-v2-chat thể hiện tốt nhất trong benchmark này, thể hiện khả năng suy luận xuất sắc của chúng. IconVQA nhấn mạnh tầm quan trọng của hiểu biết sơ đồ trừu tượng và suy luận nhận thức toàn diện trong các vấn đề từ dựa trên sơ đồ thế giới thực, yêu cầu cả sự nhạy bén trong nhận thức và suy luận nhận thức đa dạng. MiniGPT-v2 và MiniGPT-v2-chat cũng xuất sắc trong benchmark này, làm nổi bật khả năng nhận thức và suy luận nhận thức đặc biệt của chúng. VQAv2 là một bộ dữ liệu VQA cân bằng hơn trong đó mỗi câu hỏi được ghép nối với một chuỗi hình ảnh. VILA-13B thể hiện tốt nhất trong benchmark này, chứng minh khả năng vượt trội của nó để hiểu thông tin đa phương thức và khả năng chống lại các thiên lệch ngôn ngữ trong kiến thức mà nó thu được. GQA là một bộ dữ liệu VQA tập trung vào đồ thị cảnh hình ảnh, đưa ra các câu hỏi tổng hợp công bằng được tạo ra từ các hình ảnh thế giới thực. Mỗi câu hỏi được liên kết với một biểu diễn có cấu trúc về ý nghĩa của nó và các bước logic chi tiết cần thiết để trả lời nó. LLaVA-1.5 và VILA-7B thể hiện tốt nhất trong benchmark này, minh họa khả năng suy luận xuất sắc của chúng trong lĩnh vực này.

Theo sau đây, chúng tôi sẽ phác thảo các công thức đào tạo tăng cường hiệu quả của MM-LLMs, rút ra những hiểu biết từ các mô hình tiên tiến.

Công thức đào tạo Thứ nhất, độ phân giải hình ảnh cao hơn có thể kết hợp thêm các chi tiết trực quan cho mô hình, có lợi cho các nhiệm vụ yêu cầu chi tiết tỉ mỉ. Ví dụ, LLaVA-1.5 và VILA sử dụng độ phân giải 336×336, trong khi Qwen-VL và MiniGPT-v2 sử dụng 448×448. Tuy nhiên, độ phân giải cao hơn dẫn đến chuỗi token dài hơn, phát sinh chi phí đào tạo và suy luận bổ sung. MiniGPT-v2 giải quyết điều này bằng cách nối 4 token trực quan liền kề trong không gian nhúng để giảm độ dài. Gần đây, Monkey (Li et al., 2023l) đã đề xuất một giải pháp để tăng cường độ phân giải của hình ảnh đầu vào mà không cần đào tạo lại bộ mã hóa trực quan độ phân giải cao, chỉ sử dụng một bộ mã hóa trực quan độ phân giải thấp, hỗ trợ độ phân giải lên đến 1300×800. Để tăng cường hiểu biết về hình ảnh văn bản phong phú, bảng, và nội dung tài liệu, DocPedia (Feng et al., 2023) đã giới thiệu một phương pháp để tăng độ phân giải bộ mã hóa trực quan lên 2560×2560, vượt qua các hạn chế của hiệu suất kém ở độ phân giải thấp trong ViT mã nguồn mở. Thứ hai, việc kết hợp dữ liệu SFT chất lượng cao có thể cải thiện đáng kể hiệu suất trong các nhiệm vụ cụ thể, như được chứng minh bởi việc thêm dữ liệu ShareGPT4V vào LLaVA-1.5 và VILA-13B, như được hiển thị trong Bảng 2. Hơn nữa, VILA tiết lộ một số phát hiện chính: (1) Thực hiện PEFT trên xương sống LLM thúc đẩy sự liên kết nhúng sâu, quan trọng cho ICL; (2) Dữ liệu hình ảnh-văn bản xen kẽ tỏ ra có lợi, trong khi chỉ các cặp hình ảnh-văn bản là không tối ưu; (3) Pha trộn lại dữ liệu hướng dẫn chỉ văn bản (ví dụ, hướng dẫn không tự nhiên (Honovich et al., 2022)) với dữ liệu hình ảnh-văn bản trong SFT không chỉ giải quyết sự suy giảm của các nhiệm vụ chỉ văn bản mà còn tăng cường độ chính xác của nhiệm vụ VL.

6 Hướng tương lai
Trong phần này, chúng tôi khám phá các hướng tương lai đầy hứa hẹn cho MM-LLMs qua các khía cạnh sau:

Các mô hình tổng quát và thông minh hơn Chúng ta có thể tăng cường sức mạnh của MM-LLMs từ bốn con đường chính sau: (1) Mở rộng phương thức: MM-LLMs hiện tại chủ yếu hỗ trợ các phương thức sau: hình ảnh, video, âm thanh, 3D, và văn bản. Tuy nhiên, thế giới thực bao gồm một loạt các phương thức rộng hơn. Mở rộng MM-LLMs để chứa các phương thức bổ sung (ví dụ, trang web, bản đồ nhiệt, và hình và bảng) sẽ tăng tính linh hoạt của mô hình, làm cho nó có thể áp dụng rộng rãi hơn; (2) Đa dạng hóa LLMs: Kết hợp các loại và kích thước LLMs khác nhau cung cấp cho các nhà thực hành tính linh hoạt để lựa chọn cái phù hợp nhất dựa trên yêu cầu cụ thể của họ; (3) Cải thiện chất lượng bộ dữ liệu MM IT: Các bộ dữ liệu MM IT hiện tại có nhiều chỗ để cải thiện và mở rộng. Đa dạng hóa phạm vi hướng dẫn có thể tăng cường hiệu quả của MM-LLMs trong hiểu biết và thực hiện các lệnh người dùng; (4) Tăng cường khả năng tạo MM: Hầu hết các MM-LLMs hiện tại chủ yếu hướng đến hiểu MM. Mặc dù một số mô hình đã kết hợp khả năng tạo MM, chất lượng của các phản hồi được tạo ra có thể bị hạn chế bởi năng lực của các LDM. Khám phá việc tích hợp các phương pháp dựa trên truy xuất (Asai et al., 2023; Gao et al., 2023a; Kang et al., 2024) giữ nhiều hứa hẹn trong việc bổ sung cho quá trình tạo ra, tăng cường hiệu suất tổng thể của mô hình.

Các benchmark thách thức hơn Các benchmark hiện tại có thể không đủ thách thức khả năng của MM-LLMs, vì nhiều bộ dữ liệu đã xuất hiện ở các mức độ khác nhau trong các bộ PT hoặc IT. Điều này có nghĩa là các mô hình có thể đã học các nhiệm vụ này trong quá trình đào tạo. Hơn nữa, các benchmark hiện tại chủ yếu tập trung vào lĩnh vực phụ VL. Do đó, việc xây dựng một benchmark thách thức hơn, quy mô lớn hơn bao gồm các phương thức bổ sung và sử dụng tiêu chuẩn đánh giá thống nhất là quan trọng đối với sự phát triển của MM-LLMs. Ví dụ, GOAT-Bench (Lin et al., 2024b) được thiết kế để đánh giá khả năng của các MM-LLMs khác nhau trong việc phân biệt và phản hồi các khía cạnh tinh tế của lạm dụng xã hội được mô tả trong memes. MM-Code (Li et al., 2024a) đánh giá các kỹ năng giải quyết vấn đề thuật toán của MM-LLMs trong các bối cảnh trực quan phong phú. DecodingTrust (Wang et al., 2024a) đo lường độ tin cậy của MM-LLMs. MathVista (Lu et al., 2024) đánh giá khả năng suy luận toán học của MM-LLMs trong các bối cảnh trực quan, trong khi GeoEval (Zhang et al., 2024b; Li et al., 2024f; Song et al., 2024) đánh giá trình độ của chúng trong việc giải quyết các vấn đề toán hình học. Hơn nữa, MMMU (Yue et al., 2023) và CMMMU (Zhang et al., 2024a) đã lần lượt giới thiệu các phiên bản tiếng Anh và tiếng Trung của một benchmark hiểu biết và suy luận MM đa ngành toàn diện cho trí tuệ nhân tạo tổng quát chuyên gia. Ngoài ra, Fan et al. đã thách thức MM-LLMs với VQA đa bảng, và BenchLMM (Cai et al., 2023) đánh giá khả năng trực quan xuyên phong cách của MM-LLMs. Hơn nữa, Liu et al. đã thực hiện một nghiên cứu sâu về khả năng nhận dạng ký tự quang học của MM-LLMs. Những nỗ lực này làm nổi bật nhu cầu cho các benchmark phức tạp và đa dạng hơn để thực sự đánh giá các khả năng tiên tiến của MM-LLMs.

Triển khai di động/nhẹ Để triển khai MM-LLMs trên các nền tảng hạn chế tài nguyên và đạt được hiệu suất tối ưu trong khi đó, như các thiết bị di động và IoT công suất thấp, các triển khai nhẹ có tầm quan trọng tối cao. Một tiến bộ đáng chú ý trong lĩnh vực này là MobileVLM (Chu et al., 2023a). Phương pháp này chiến lược thu nhỏ LLaMA, cho phép triển khai có sẵn liền mạch. MobileVLM hơn nữa giới thiệu một bộ chiếu downsample nhẹ, bao gồm ít hơn 20 triệu tham số, góp phần cải thiện tốc độ tính toán. Gần đây, đã có nhiều nghiên cứu tương tự về làm nhẹ MM-LLMs, đạt được tính toán hiệu quả và suy luận với hiệu suất tương đương hoặc mất mát tối thiểu, bao gồm TinyGPT-V (Yuan et al., 2023b), Vary-toy (Wei et al., 2024), Mobile-Agent (Wang et al., 2024c), MoE-LLaVA (Lin et al., 2024a), và MobileVLM V2 (Chu et al., 2024). Tuy nhiên, con đường này cần thêm khám phá cho những tiến bộ thêm trong phát triển.

Trí tuệ thể hiện Trí tuệ thể hiện nhằm sao chép nhận thức và tương tác giống con người với môi trường xung quanh bằng cách hiểu biết hiệu quả về môi trường, nhận ra các đối tượng liên quan, đánh giá mối quan hệ không gian của chúng, và đưa ra một kế hoạch nhiệm vụ toàn diện (Firoozi et al., 2023). Các nhiệm vụ AI thể hiện, như lập kế hoạch thể hiện, trả lời câu hỏi trực quan thể hiện, và kiểm soát thể hiện, trang bị cho robot tự động triển khai các kế hoạch mở rộng bằng cách tận dụng các quan sát thời gian thực. Một số công trình điển hình trong lĩnh vực này là PaLM-E (Driess et al., 2023) và EmbodiedGPT (Mu et al., 2023). PaLM-E giới thiệu một tác nhân đa thể hiện thông qua việc đào tạo một MM-LLM. Ngoài việc hoạt động chỉ như một nhà ra quyết định thể hiện, PaLM-E cũng chứng minh trình độ trong việc xử lý các nhiệm vụ VL chung. EmbodiedGPT giới thiệu một phương pháp hiệu quả về kinh tế được đặc trưng bởi một phương pháp CoT, tăng cường khả năng của các tác nhân thể hiện để tương tác với thế giới thực và thiết lập một vòng lặp đóng kết nối lập kế hoạch cấp cao với kiểm soát cấp thấp. Trong khi trí tuệ thể hiện dựa trên MM-LLM đã tiến bộ trong việc tích hợp với robot, cần có thêm khám phá để tăng cường sự tự chủ của robot.

Học tập liên tục Do chi phí đào tạo lớn liên quan đến quy mô khổng lồ của chúng, MM-LLMs không thể đào tạo lại thường xuyên. Tuy nhiên, các cập nhật là cần thiết để trao cho MM-LLMs các kỹ năng mới và giữ chúng cập nhật với kiến thức con người phát triển nhanh chóng (Wu et al., 2024). Vì vậy, học tập liên tục (CL) cần thiết để làm cho mô hình đủ linh hoạt để hiệu quả và liên tục tận dụng dữ liệu mới nổi trong khi tránh chi phí đáng kể của việc đào tạo lại MM-LLMs. CL cho MM-LLMs có thể được phân loại thành hai giai đoạn: PT liên tục và IT liên tục. Gần đây, một benchmark IT MM liên tục đã được đề xuất để liên tục điều chỉnh MM-LLMs cho các nhiệm vụ MM mới trong khi duy trì hiệu suất vượt trội trên các nhiệm vụ được học trong giai đoạn IT MM ban đầu (He et al., 2023). Nó giới thiệu hai thách thức chính: (1) quên lãng thảm khốc, trong đó các mô hình quên kiến thức trước đó khi học các nhiệm vụ mới (Robins, 1995; McCloskey and Cohen, 1989; Goodfellow et al., 2013; Zhang et al., 2023d,c,b; Zheng et al., 2023a), và (2) chuyển giao tiến về phía trước tiêu cực, cho thấy hiệu suất của các nhiệm vụ chưa thấy giảm sút khi học những cái mới (Zheng et al., 2024; Dong et al., 2022, 2024a, 2023b,a).

Giảm thiểu ảo giác Ảo giác bao gồm việc tạo ra các mô tả văn bản về các đối tượng không tồn tại mà không có dấu hiệu trực quan, biểu hiện trong các loại đa dạng (Liu et al., 2024a) như đánh giá sai và không chính xác trong mô tả. Nguồn gốc của những ảo giác này là đa diện (Liu et al., 2024a), bao gồm thiên lệch và lỗi chú thích trong dữ liệu đào tạo. Ngoài ra, Skip \n (Han et al., 2024) làm nổi bật các thiên lệch trôi dạt ngữ nghĩa liên quan đến các dấu phân tách đoạn văn, có thể gây ra ảo giác khi được chèn cố ý. Các phương pháp hiện tại để giảm thiểu những ảo giác này bao gồm việc tận dụng phản hồi tự thân như các dấu hiệu trực quan (Lee et al., 2023). Tuy nhiên, các thách thức vẫn tồn tại, cần sự phân biệt tinh tế giữa các đầu ra chính xác và ảo giác, cũng như những tiến bộ trong phương pháp đào tạo để tăng cường độ tin cậy của đầu ra.

Thiên lệch và cân nhắc đạo đức Mặc dù có những điểm mạnh của MM-LLMs, việc đảm bảo ứng dụng an toàn và hiệu quả của chúng vẫn quan trọng. Thông tin được tạo ra bởi MM-LLMs có thể duy trì các khuôn mẫu và gây tổn hại cho các quần thể dễ bị tổn thương. Vì MM-LLMs học từ các mô hình trong dữ liệu đào tạo MM, chúng có thể tái tạo các thiên lệch có mặt trong các dữ liệu này, có khả năng dẫn đến tổn hại đại diện. Để giải quyết điều này, chúng ta có thể phát triển các benchmark mới được thiết kế đặc biệt để đánh giá thiên lệch trong MM-LLMs (Luo et al., 2024). Ngoài ra, thiết kế các phương pháp liên kết hiệu quả hơn và tỉ mỉ hơn là cần thiết. Ví dụ, sử dụng RLHF có thể giúp hiệu chỉnh MM-LLMs để tạo ra các câu trả lời phù hợp với giá trị và mong muốn của con người (Li et al., 2024c).

7 Kết luận
Trong bài báo này, chúng tôi đã trình bày một khảo sát toàn diện về MM-LLMs với trọng tâm vào những tiến bộ gần đây. Ban đầu, chúng tôi phân loại kiến trúc mô hình thành năm thành phần, cung cấp tổng quan chi tiết về các công thức thiết kế chung và pipeline đào tạo. Tiếp theo, chúng tôi giới thiệu các MM-LLMs tiên tiến khác nhau, mỗi cái được phân biệt bởi các công thức cụ thể của nó. Khảo sát của chúng tôi cũng làm sáng tỏ khả năng của chúng trên các benchmark MM đa dạng và hình dung các phát triển tương lai trong lĩnh vực phát triển nhanh chóng này. Chúng tôi hy vọng khảo sát này có thể cung cấp những hiểu biết cho các nhà nghiên cứu, góp phần vào những tiến bộ liên tục trong lĩnh vực MM-LLMs.

Tác động xã hội
MM-LLMs có tiềm năng tác động đến xã hội. Chúng có thể tăng cường khả năng tiếp cận cho các cá nhân khuyết tật bằng cách cải thiện nhận dạng giọng nói và hỗ trợ trực quan, thúc đẩy quyền truy cập bình đẳng vào thông tin. Trong giáo dục, MM-LLMs có thể cách mạng hóa việc học tập với những trải nghiệm tương tác hơn, phục vụ cho các phong cách học tập đa dạng. Trong truyền thông, chúng có thể tạo ra nội dung hấp dẫn hơn, làm phong phú trải nghiệm người tiêu dùng. Tuy nhiên, việc áp dụng rộng rãi MM-LLMs cũng đặt ra rủi ro. Mối lo ngại về quyền riêng tư phát sinh từ dữ liệu đào tạo khổng lồ, nêu ra các vấn đề về bảo mật dữ liệu và quyền riêng tư người dùng. Cũng có rủi ro làm trầm trọng thêm thiên lệch trong các thuật toán AI, vì thiên lệch trong dữ liệu đào tạo có thể dẫn đến đầu ra thiên lệch. Ngoài ra, việc tự động hóa các nhiệm vụ truyền thống được thực hiện bởi con người có thể dẫn đến việc thay thế công việc, cần các biện pháp chủ động để giảm thiểu các tác động tiêu cực tiềm ẩn đối với việc làm. Nhìn chung, trong khi MM-LLMs đưa ra các cơ hội đầy hứa hẹn, việc giải quyết những thách thức này để đảm bảo triển khai có trách nhiệm và công bằng là cần thiết.

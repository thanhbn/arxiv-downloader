# Sự khác biệt trong khả năng tổng quát hóa giữa các hệ thống suy luận thị giác-ngôn ngữ từ đầu đến cuối và neuro-symbolic

Wang Zhu Jesse Thomason Robin Jia
Đại học Nam California, Los Angeles, CA, Hoa Kỳ
{wangzhu, jessetho, robinjia}@usc.edu

## Tóm tắt

Đối với các tác vụ suy luận thị giác và ngôn ngữ (VL), cả các phương pháp kết nối hoàn toàn từ đầu đến cuối và các phương pháp hybrid neuro-symbolic đều đạt được hiệu suất cao trong phân phối. Trong những tình huống ngoài phân phối nào thì mỗi mô hình hoạt động tốt? Chúng tôi nghiên cứu câu hỏi này trên cả trả lời câu hỏi thị giác đơn ảnh và đa ảnh thông qua bốn loại kiểm tra tổng quát hóa: một kiểm tra phân đoạn-kết hợp mới cho các truy vấn đa ảnh, tập đối lập, tổng quát hóa compositional, và chuyển giao giữa các benchmark. Các hệ thống được huấn luyện từ đầu đến cuối thị giác-ngôn ngữ (VLE2E) thể hiện sự giảm hiệu suất đáng kể trên tất cả các kiểm tra này. Các phương pháp neuro-symbolic (NS) còn gặp khó khăn hơn trong việc chuyển giao giữa các benchmark từ GQA sang VQA, nhưng chúng cho thấy sự giảm độ chính xác nhỏ hơn trên các kiểm tra tổng quát hóa khác và hiệu suất của chúng nhanh chóng cải thiện bằng huấn luyện few-shot. Nhìn chung, kết quả của chúng tôi chứng minh những lợi ích bổ sung của hai mô hình này, và nhấn mạnh tầm quan trọng của việc sử dụng một bộ kiểm tra tổng quát hóa đa dạng để mô tả đầy đủ tính mạnh mẽ của mô hình đối với sự dịch chuyển phân phối.

## 1 Giới thiệu

Các mô hình đa phương thức được tiền huấn luyện được sử dụng rộng rãi (Chen et al., 2020; Lu et al., 2019; Li et al., 2019) đã thể hiện hiệu suất tuyệt vời khi được tinh chỉnh trên các tác vụ thị giác và ngôn ngữ downstream như VQA (Antol et al., 2015) và GQA (Hudson và Manning, 2019a). Những mô hình này thường tổng quát hóa kém đối với dữ liệu ngoài phân phối (OOD), cho thấy những thiếu sót trong pipeline VLE2E. Các phương pháp neuro-symbolic (Wu et al., 2017; Yi et al., 2018) cố gắng giải quyết vấn đề này bằng cách tách biệt các cơ chế grounding và suy luận trong các hệ thống đa phương thức. Các phương pháp NS tạo ra các biểu diễn thị giác có căn cứ, phân tích ngôn ngữ thành các chương trình có thể thực thi để suy luận, và thực thi các chương trình trên các biểu diễn thị giác. Nghiên cứu trước đây (Hudson và Manning, 2018; Mao et al., 2019) đã cho thấy hiệu quả của các phương pháp neuro-symbolic đối với tổng quát hóa compositional OOD trên các tác vụ suy luận VL đơn ảnh. Tuy nhiên, chúng ta vẫn thiếu hiểu biết toàn diện về sự khác biệt tổng quát hóa giữa hai mô hình này dưới các thiết lập khác nhau. Với nghiên cứu gần đây cho thấy rằng độ chính xác OOD thường có mối tương quan mạnh với độ chính xác trong phân phối (Miller et al., 2020, 2021), chúng ta có thể kỳ vọng các hệ thống VLE2E và NS thường có khả năng tổng quát hóa tương tự. Nhưng liệu có thực sự như vậy?

Trong công trình này, chúng tôi tiến hành so sánh toàn diện đầu tiên về hành vi tổng quát hóa giữa các hệ thống VLE2E và NS cho các tác vụ suy luận VL. Nghiên cứu của chúng tôi bao gồm các thiết lập đơn ảnh và đa ảnh với hình ảnh tự nhiên và bao gồm bốn loại kiểm tra tổng quát hóa khác biệt, ba trong số đó được hiển thị trong Hình 1. Chúng tôi giới thiệu một kiểm tra phân đoạn-kết hợp mới cho các thiết lập đa ảnh yêu cầu các mô hình đưa ra dự đoán nhất quán khi một số hình ảnh đầu vào được thay thế bằng những hình ảnh không liên quan. Chúng tôi đánh giá trên các tập đối lập (Gardner et al., 2020), bao gồm các tập đối lập mới mà chúng tôi xây dựng cho COVR để kiểm tra hiểu biết về các lượng từ. Chúng tôi cũng đo lường tổng quát hóa compositional như được định nghĩa bởi các phân chia compositional từ COVR (Bogin et al., 2021) và chuyển giao giữa các benchmark giữa VQA và GQA. Chúng tôi cũng phát triển các hệ thống NS cải tiến cho GQA bằng cách xử lý sự không khớp giữa các bộ mô tả đối tượng chương trình và biểu đồ cảnh, và cho COVR bằng cách tinh chỉnh ngôn ngữ logic gốc.

Nhìn chung, chúng tôi thấy rằng các hệ thống VLE2E và NS thể hiện các mẫu tổng quát hóa khác biệt và bổ sung. Các hệ thống NS mạnh mẽ hơn các hệ thống VLE2E trong ba tình huống kiểm tra đầu tiên. Các hệ thống VLE2E thể hiện tính quá ổn định đối với các nhiễu loạn thay đổi ý nghĩa, cho thấy chúng overfit với các mối tương quan giả trong dữ liệu huấn luyện và không học được các kỹ năng suy luận chính xác. Chúng tôi tiếp tục thấy rằng mô-đun phân tích ngữ nghĩa của các hệ thống NS có thể nhanh chóng cải thiện trên các kiểm tra tổng quát hóa với một vài ví dụ huấn luyện, trong khi các mô hình VL không thích ứng nhanh như vậy. Mặt khác, trong khi các hệ thống VLE2E mất hơn 10% độ chính xác khi chuyển giao giữa VQA và GQA, các phương pháp NS hoạt động còn tệ hơn. Kết hợp lại, những phát hiện của chúng tôi nhấn mạnh nhu cầu về một bộ kiểm tra tổng quát hóa đa dạng để so sánh đầy đủ các mô hình khác nhau. Hành vi khác nhau của hai hệ thống này có thể hướng dẫn cộng đồng thiết kế các hệ thống suy luận VL mạnh mẽ hơn. Chúng tôi phát hành mã của mình để tạo dữ liệu kiểm tra, và chúng tôi khuyến khích các mô hình VL tương lai được đánh giá trên những kiểm tra này.

## 2 Công trình liên quan

Đầu tiên chúng tôi khảo sát các công trình liên quan về các mô hình suy luận thị giác-ngôn ngữ và các kiểm tra đánh giá OOD.

**Tổng quát hóa VL OOD.** Nhiều nỗ lực đã được thực hiện để đánh giá khả năng tổng quát hóa của các hệ thống VLE2E và các phương pháp chuyên biệt cho tác vụ về tính compositional (Johnson et al., 2017; Thrush et al., 2022a), nhiễu loạn ngôn ngữ (Ribeiro et al., 2019) và nhiễu loạn thị giác (Jimenez et al., 2022). Li et al. (2020) cho thấy các hệ thống VLE2E thể hiện tính mạnh mẽ tốt hơn các phương pháp chuyên biệt cho tác vụ. Chúng tôi là những người đầu tiên so sánh toàn diện sự khác biệt tổng quát hóa giữa các hệ thống VLE2E và NS trên các kiểm tra OOD khác nhau.

**Các mô hình tiền huấn luyện VL.** Các mô hình tiền huấn luyện VL quy mô lớn cho trả lời câu hỏi có thể là single-stream—mã hóa các đặc trưng thị giác và ngôn ngữ cùng nhau với một transformer duy nhất—chẳng hạn như VisualBERT (Li et al., 2019) và VinVL (Zhang et al., 2021), hoặc dual-stream—mã hóa thị giác và ngôn ngữ với các transformer riêng biệt và áp dụng các transformer đa phương thức sau đó—chẳng hạn như ViLBERT (Lu et al., 2019) và LXMERT (Tan và Bansal, 2019). Chúng tôi đánh giá trên cả các mô hình tiền huấn luyện VL single-stream và dual-stream.

**Các phương pháp neuro-symbolic.** NS-VQA (Wu et al., 2017) tách biệt xử lý thị giác và ngôn ngữ cho các tác vụ suy luận VL trên hình ảnh mô phỏng. Tuy nhiên, nó yêu cầu các tập dữ liệu phải bao gồm các chú thích của các dạng logic để mô tả ngôn ngữ. Để giảm tín hiệu giám sát từ các chú thích chương trình, NS-CL (Mao et al., 2019) đã học chung các embedding khái niệm và các chương trình tiềm ẩn, và mở rộng sang hình ảnh tự nhiên. NSM (Hudson và Manning, 2019b) đã học suy luận cấp biểu đồ và thể hiện khả năng suy luận compositional của các phương pháp NS. Để có thể áp dụng cho cả thiết lập đơn ảnh và đa ảnh, chúng tôi chọn cùng một pipeline như trong NS-VQA gốc. Chúng tôi sử dụng biểu đồ cảnh làm biểu diễn cấu trúc, và kiểm tra trên nhiều mô hình ngôn ngữ cho phân tích ngữ nghĩa.

**Các tác vụ suy luận VL đơn ảnh và đa ảnh.** Đối với suy luận VL, có nhiều tập dữ liệu tập trung vào hình ảnh đơn, chẳng hạn như CLEVR (Johnson et al., 2017), VQA, và GQA, cũng như nhiều tập dữ liệu khác liên quan đến suy luận đa ảnh, chẳng hạn như NLVR (Suhr et al., 2017), NLVR2 (Suhr et al., 2019), COVR (Bogin et al., 2021), và Winoground (Thrush et al., 2022b). Chúng tôi thí nghiệm với hai tập dữ liệu đơn ảnh, VQA và GQA, và một tập dữ liệu đa ảnh, COVR, tất cả đều sử dụng hình ảnh tự nhiên.

## 3 Các mô hình

Tiếp theo, chúng tôi định nghĩa chính thức các tác vụ suy luận VL và các phương pháp VLE2E và NS mà chúng tôi nghiên cứu. Chúng tôi cũng thảo luận về một hệ thống NS mới cho COVR và các thay đổi liên quan đến các dạng logic COVR gốc.

### 3.1 Suy luận thị giác-ngôn ngữ

Trong một tác vụ suy luận VL, mỗi ví dụ bao gồm một bộ ba (q; I; y), trong đó q là một truy vấn ngôn ngữ tự nhiên, I là một tập hợp các hình ảnh được truy vấn và y là câu trả lời tương ứng của truy vấn. Số lượng hình ảnh được truy vấn là |I|, ví dụ, |I| = 1 cho một truy vấn đơn ảnh. Cho truy vấn q và tập hình ảnh I, một hệ thống VL f dự đoán một câu trả lời ŷ = f(q; I). Các mô hình được huấn luyện trên Dtrain và đánh giá trên Dtest.

### 3.2 Hệ thống VLE2E được sửa đổi

Đối với một hệ thống VLE2E, f là một mạng neural duy nhất được huấn luyện từ đầu đến cuối. Vì các mô hình tiền huấn luyện VL hiện tại được huấn luyện để xử lý hình ảnh đơn, chúng tôi sửa đổi pipeline VLE2E cho các thiết lập đa ảnh theo Bogin et al. (2021). Cho một truy vấn đa ảnh (q; I) và một mô hình tiền huấn luyện, đối với mỗi hình ảnh I ∈ I, chúng tôi đưa cặp (q; I) vào mô hình tiền huấn luyện để nhận được một biểu diễn ảnh-văn bản. Chúng tôi nối các biểu diễn ảnh-văn bản |I| này và thêm một token [CLS] vào đầu để xây dựng một chuỗi có độ dài |I| + 1. Sau đó chúng tôi đưa chuỗi được tạo này vào một transformer hai lớp, và lấy embedding được tạo ra của token [CLS] làm biểu diễn của toàn bộ truy vấn đa ảnh. Cuối cùng, chúng tôi đưa biểu diễn vào một bộ phân loại MLP để dự đoán y. Tất cả các mô-đun bao gồm mô hình tiền huấn luyện đều được tinh chỉnh. Chúng tôi thí nghiệm với 4 mô hình tiền huấn luyện VL khác nhau: VisualBERT và VinVL single-stream và LXMERT và ViLBERT dual-stream.

### 3.3 Hệ thống NS được sửa đổi

Một hệ thống NS xử lý riêng biệt thị giác và ngôn ngữ với hai mô-đun có thể huấn luyện Φ và Ψ. Tập hình ảnh được biểu diễn dưới dạng Φ(I), và ngữ nghĩa truy vấn được biểu diễn dưới dạng một chương trình chức năng Ψ(q). Một trình thực thi được định nghĩa trước thực thi Ψ(q) trên Φ(I) để dự đoán câu trả lời ŷ. Để áp dụng các pipeline giống NS-VQA cho hình ảnh thực tế, chúng tôi sử dụng biểu đồ cảnh làm biểu diễn cấu trúc Φ(I).

Chúng tôi sử dụng một trình tạo biểu đồ cảnh được tiền huấn luyện có thể được tinh chỉnh trên dữ liệu biểu đồ cảnh chuyên biệt cho tác vụ, tùy thuộc vào tập dữ liệu (xem §5.1 để biết chi tiết). Chúng tôi tinh chỉnh các mô hình ngôn ngữ lớn để ánh xạ các truy vấn q thành các chương trình chức năng Ψ(q) (tức là, phân tích ngữ nghĩa). Chúng tôi thí nghiệm với 3 mô hình ngôn ngữ: (1) T5 (Raffel et al., 2020), (2) BART (Lewis et al., 2020) và (3) GPT-2 (Radford et al., 2019).

Bây giờ, chúng tôi mô tả công việc chuyên biệt cho tập dữ liệu cần thiết để xây dựng một pipeline NS đầy đủ cho GQA và COVR. Cả hai tập dữ liệu đều cung cấp các dạng logic cho mỗi câu hỏi, nhưng các dạng này yêu cầu sửa đổi để tương thích với các hệ thống NS.

**Truy vấn đơn ảnh.** Trong GQA, các chương trình chức năng liên kết với các đối tượng trong biểu đồ cảnh thông qua ID đối tượng. Ví dụ, một chương trình có thể tham chiếu đến đối tượng "bird(775)", trong khi nút tương ứng cho đối tượng 775 trong biểu đồ cảnh có thể có tên parrot. Vì ID đối tượng không thể dự đoán bởi một mô hình phân tích ngữ nghĩa cho q, chúng tôi loại bỏ chúng khỏi các chương trình được chú thích. Do đó, chúng tôi cần grounding các tham chiếu đối tượng như "bird" đến các đối tượng tương ứng có khả năng như nút parrot. Chúng tôi xây dựng một từ điển ánh xạ mỗi loại đối tượng được đề cập trong một chương trình trong Dtrain (ví dụ, "bird") đến tập hợp tất cả các loại đối tượng biểu đồ cảnh mà tham chiếu đó khớp với (ví dụ, parrot). Chúng tôi sử dụng từ điển này để khớp các đối tượng giữa chương trình và biểu đồ cảnh khi thực thi chương trình tại thời điểm kiểm tra. Sự không khớp giữa tên đối tượng trong chương trình và biểu đồ cảnh xảy ra trong 9,5% ví dụ validation, nhưng việc sử dụng từ điển này giải quyết 99,6% sự không khớp.

**Truy vấn đa ảnh.** Giống như GQA, các truy vấn đa ảnh trong COVR được chú thích với các chương trình có thể thực thi và biểu đồ cảnh ground truth của hình ảnh. Chú thích chương trình kết hợp các hoạt động lượng từ, cho phép thực thi NS của các truy vấn đa ảnh mà không thay đổi pipeline của các phương pháp NS-VQA (Yi et al., 2018). Hình 2 cung cấp một tổng quan về pipeline NS đa ảnh của chúng tôi.

Trong các phân chia compositional cho COVR, các mô hình phải tổng quát hóa đến một số hợp chất chưa thấy (ví dụ, cụm từ) bao gồm các token đã thấy (ví dụ, từ). Ví dụ, các mô hình có thể được kiểm tra trên "Is the child sitting on a branch or a swing?" sau khi thấy "What is the child sitting on?", "Is the child sitting on a swing?" và "Is the child sitting on a branch?" tại thời điểm huấn luyện. Tuy nhiên, các dạng logic được chú thích trong COVR cho truy vấn kiểm tra trên bao gồm một hoạt động đơn vị chưa thấy choose_name (được sử dụng để chọn "branch" hoặc "swing"), điều này không thể tạo ra vì nó chưa được thấy tại thời điểm huấn luyện. Để ít nhất làm cho tổng quát hóa compositional có thể, chúng tôi thiết kế một tập hợp các dạng logic compositional làm biểu diễn trung gian (Herzig et al., 2021) dựa trên các chương trình hiện có trong COVR. Đối với hoạt động choose_name(branch, swing), chúng tôi lấy tiền tố "choose" làm tên hoạt động và để lại hậu tố "name" làm đối số, hoạt động mới là choose(name, branch, swing). Bằng cách làm như vậy, có thể tạo ra hoạt động này một khi chúng ta thấy một choose(attr, ) và một query(name, ) hoạt động. Chúng tôi cố gắng giữ một tập hợp hoạt động tối thiểu bằng cách thiết kế lại các hoạt động không thể kết hợp và loại bỏ các toán tử dư thừa. Bằng cách làm như vậy, chúng tôi giảm kích thước của tập hợp hoạt động từ 33 xuống 17. Chúng tôi đề cập đến chi tiết của các chương trình được sửa đổi trong Phụ lục A. Chúng tôi ký hiệu các dạng logic mới là các dạng logic compositional (CLF) trái ngược với các dạng logic gốc (OLF), và đánh giá hệ thống NS dựa trên các chương trình này cho các kiểm tra tổng quát hóa.

**Các chỉ số đánh giá.** Chúng tôi sử dụng 3 chỉ số đánh giá khác nhau cho hệ thống NS. Chỉ số đánh giá chính của chúng tôi là GENEXEC, độ chính xác với việc thực thi chương trình trên các biểu đồ cảnh được tạo. Để đo lường tác động của lỗi trong quá trình tạo biểu đồ cảnh, chúng tôi cũng đo lường GTEXEC, độ chính xác với việc thực thi chương trình trên các biểu đồ cảnh ground truth. Cuối cùng, chúng tôi cũng đo lường EXACT, độ chính xác khớp chính xác của các chương trình được tạo bởi phân tích ngữ nghĩa; điều này phạt những phân tích "đúng một cách ngẫu nhiên" thực thi đến câu trả lời đúng nhưng tính toán hàm sai.

## 4 Phương pháp đánh giá

Chúng tôi đánh giá các hệ thống VLE2E và NS trên bốn kiểm tra tổng quát hóa. Chúng tôi tạo một kiểm tra nhiễu loạn đa ảnh mới gọi là Kiểm tra phân đoạn-kết hợp, và tạo các tập đối lập mới cho COVR bằng cách nhiễu loạn các lượng từ. Chúng tôi cũng kiểm tra các mô hình về tổng quát hóa compositional và chuyển giao giữa các benchmark.

**Kiểm tra phân đoạn-kết hợp.** Chúng tôi giới thiệu kiểm tra phân đoạn-kết hợp để kiểm tra tổng quát hóa mô hình trên các nhiễu loạn đa ảnh. Đối với một truy vấn đa ảnh (q; I) trong đó I = (I1, ..., I|I|), trước tiên chúng tôi thực hiện một giai đoạn phân đoạn. Chúng tôi tạo |I| truy vấn, trong đó truy vấn thứ k sử dụng câu hỏi gốc q và một tập hình ảnh được hình thành bởi sự hợp nhất của hình ảnh gốc Ik cộng với |I| - 1 hình ảnh ngẫu nhiên không liên quan đến q. Chúng tôi đưa những hình ảnh này vào mô hình để nhận được |I| dự đoán. Tiếp theo, trong giai đoạn kết hợp, chúng tôi áp dụng một hàm tổng hợp (ví dụ, SUM hoặc OR) dựa trên loại câu hỏi để kết hợp những dự đoán này (Hình 1). Một mô hình mạnh mẽ nên trả về cùng một câu trả lời trên kiểm tra phân đoạn-kết hợp và ví dụ gốc.

Chúng tôi chạy kiểm tra phân đoạn-kết hợp trên COVR, lấy mẫu hình ảnh ngẫu nhiên từ tất cả hình ảnh trong tập validation COVR. Để xác nhận rằng chúng tôi chỉ lấy mẫu hình ảnh không liên quan đến tập hình ảnh gốc (tức là, sẽ không thay đổi câu trả lời sau khi kết hợp), chúng tôi thực thi các chương trình ground truth trên các biểu đồ cảnh ground truth cho mỗi truy vấn trong giai đoạn phân đoạn, và thấy rằng độ chính xác là 100%.

Chúng tôi tập trung vào hai template trong COVR mà có một hàm kết hợp thích hợp. Đối với template COUNT GROUP BY (ví dụ, "How many images have 2 bottles?"), hàm kết hợp là SUM. Có nghĩa là, câu trả lời trên đầu vào gốc nên bằng tổng của |I| câu trả lời từ giai đoạn phân đoạn. Đối với template VERIFY COUNT GROUP BY, hàm kết hợp là logical OR, như được hiển thị trong Hình 1.

**Tập đối lập.** Đối với suy luận VL, chúng tôi định nghĩa một tập đối lập (Gardner et al., 2020) của một ví dụ (q; I; y) ∈ Dtest là một tập hợp các ví dụ tương tự (q'; I; y'), trong đó q' tương tự với q và y' có thể giống hoặc không giống với y, tùy thuộc vào q'. q' có thể được xây dựng bằng cách thay thế các từ hoặc cụm từ cụ thể trong q bằng từ đồng nghĩa hoặc trái nghĩa, hoặc bằng cách thay thế các đối tượng bằng các đối tượng khác. Cho n ví dụ tập đối lập (q'1; I; y'1), ..., (q'n; I; y'n), chúng tôi chủ yếu đánh giá các mô hình về độ chính xác trung bình trên n ví dụ này. Chúng tôi cũng đo lường tính nhất quán cục bộ trung bình là 1/n ∑ⁿᵢ₌₁(ŷᵢ = ŷ'ᵢ), đo lường mức độ mô hình bỏ qua các nhiễu loạn.

Chúng tôi sử dụng các tập đối lập đơn ảnh được tạo bởi Bitton et al. (2021) cho GQA. Các tập đối lập của họ liên quan đến việc thay thế đối tượng từ biểu đồ cảnh và chủ yếu kiểm tra tính mạnh mẽ của các hệ thống VLE2E để grounding đối tượng.

Đối với COVR đa ảnh, chúng tôi thiết kế các tập đối lập mới nhắm vào các nhiễu loạn liên quan đến suy luận giữa các ảnh cho các truy vấn đa ảnh. Chúng tôi thay thế các lượng từ trong dữ liệu kiểm tra bằng các cụm từ có ý nghĩa tương đương và trái ngược và thay đổi nhãn tương ứng. Chúng tôi tập trung vào các ví dụ được tạo bởi 4 template, trong đó các lượng từ (ví dụ, at least, all) đóng vai trò giới thiệu suy luận giữa các ảnh: một template câu hỏi đếm COUNT GROUP BY, và ba template câu hỏi nhị phân, VERIFY COUNT GROUP BY, VERIFY COUNT (ví dụ, "At least 2 bottles on the table?") và QUANTIFIER (ví dụ, "No bottles are on the table?"). Chúng tôi kiểm tra các nhiễu loạn bảo toàn ý nghĩa như thay thế at least bằng no less than trên các câu hỏi đếm và nhị phân. Chúng tôi cũng kiểm tra các nhiễu loạn thay đổi ý nghĩa như thay thế no bằng some trên các câu hỏi nhị phân và đảo ngược câu trả lời. Chúng tôi không áp dụng các nhiễu loạn thay đổi ý nghĩa cho các câu hỏi đếm vì không dễ dàng xác định câu trả lời mới y' nên là gì.

**Tổng quát hóa compositional.** Trong thiết lập này, Dtrain và Dtest từ cùng một benchmark, nhưng các truy vấn trong Dtest là các biến thể compositional của những truy vấn trong Dtrain. Ví dụ, các ví dụ Dtest có thể chứa hai cụm từ được thấy độc lập trong Dtrain nhưng chưa bao giờ cùng nhau. Chúng tôi kiểm tra trên các phân chia tổng quát hóa compositional như được định nghĩa trong COVR, được xây dựng bằng cách giữ lại một template câu hỏi hoặc giữ lại các ví dụ mà nhiều thuộc tính truy vấn đồng thời xảy ra trong quá trình huấn luyện.

**Chuyển giao giữa các benchmark.** Trong thiết lập này, Dtrain và Dtest từ các benchmark khác nhau. Chúng tôi chọn một trong VQA và GQA làm Dtrain và cái kia làm Dtest.

## 5 Thí nghiệm

Chúng tôi trình bày thiết lập thí nghiệm và kết quả trên bốn loại kiểm tra tổng quát hóa dưới đây. Kết quả cho thấy tính mạnh mẽ bổ sung của các hệ thống VLE2E và NS trong các thiết lập OOD.

### 5.1 Thiết lập thí nghiệm

Chúng tôi sử dụng VQA (Antol et al., 2015) và GQA (Hudson và Manning, 2019a) làm tập dữ liệu QA đơn ảnh và COVR (Bogin et al., 2021) làm tập dữ liệu QA đa ảnh. VQA có ba loại câu hỏi: nhị phân (yes/no), đếm (câu trả lời là một số) và mở (câu trả lời có thể là bất kỳ thuật ngữ nào từ một từ vựng).

Đối với chuyển giao giữa các benchmark giữa VQA và GQA, vì VQA và GQA có các tập nhãn khác nhau, chúng tôi lọc cả hai tập validation để chỉ bao gồm các nhãn xuất hiện trong cả hai tập dữ liệu. Lưu ý rằng VQA không có chú thích chương trình và biểu đồ cảnh, vì vậy chúng tôi chỉ có thể huấn luyện các phương pháp NS trên GQA.

Đối với huấn luyện mô hình, chúng tôi sử dụng các thiết lập tinh chỉnh được mô tả trong các bài báo tương ứng cho mỗi mô hình. Chúng tôi cung cấp thêm chi tiết về việc lựa chọn siêu tham số trong Phụ lục B. Đối với các phương pháp NS, chúng tôi tạo biểu đồ cảnh với phương pháp tạo biểu đồ cảnh không thiên vị Causal-TDE (Tang et al., 2020), sử dụng Faster R-CNN (Ren et al., 2015) làm backbone cho phát hiện đối tượng.

### 5.2 Kiểm tra phân đoạn-kết hợp

Chúng tôi kiểm tra các hệ thống VLE2E và NS với kiểm tra phân đoạn-kết hợp và liệt kê độ chính xác của chúng trong Bảng 1. Các mô hình VLE2E thất bại trong kiểm tra phân đoạn-kết hợp. Cả VisualBERT và ViLBERT đều thất bại trong kiểm tra phân đoạn-kết hợp, nhưng các mô hình NS đạt độ chính xác gần với truy vấn gốc. Sự giảm hiệu suất của các mô hình VLE2E là 11-12% trên các câu hỏi đếm (VERIFY COUNT GROUP BY) và 18-20% trên các câu hỏi nhị phân (COUNT GROUP BY), như được hiển thị trong Bảng 1. Mặc dù các mô hình NS với biểu đồ cảnh được tạo cho thấy độ chính xác thấp hơn 1-7% so với các mô hình VLE2E trên các truy vấn đa ảnh gốc, chúng đạt độ chính xác cao hơn 4-18% trên dữ liệu đánh giá phân đoạn-kết hợp.

**Các mô hình VLE2E học các mối tương quan giả đa ảnh.** Chúng tôi nhận thấy hiệu suất của VisualBERT trên kiểm tra phân đoạn-kết hợp cho các câu hỏi nhị phân (52,5%) gần với việc đoán ngẫu nhiên. Do đó, chúng tôi trích xuất dự đoán từ VisualBERT trên kiểm tra phân đoạn-kết hợp. Đối với các câu hỏi nhị phân, 93% dự đoán là no. Đối với các câu hỏi đếm với 6 nhãn, 38% dự đoán là 0. Vì các truy vấn COVR được tạo bằng cách lấy mẫu hình ảnh liên quan và gây phân tâm, các mô hình VLE2E có xu hướng dự đoán no hoặc 0 cho các truy vấn với nhiều hình ảnh không liên quan hơn, đây là một mối tương quan giả giữa các hình ảnh được truy vấn học được trong quá trình tinh chỉnh. Ngược lại, phân tích ngữ nghĩa tạo ra chương trình đúng để thực thi với điểm EXACT trên 98,5% cho tất cả các mô hình NS, không chỉ là các chương trình đúng một cách ngẫu nhiên mà tình cờ đúng trong quá trình thực thi.

### 5.3 Tập đối lập

Chúng tôi kiểm tra trên tập đối lập GQA được mở rộng từ Bitton et al. (2021) cho các truy vấn đơn ảnh, và so sánh hiệu suất trên phần tương ứng của dữ liệu validation GQA. Chúng tôi cũng kiểm tra các hệ thống VLE2E và NS trên tập đối lập được tạo của chúng tôi trên COVR liên quan đến suy luận giữa các ảnh.

**Các mô hình VLE2E cho thấy grounding đối tượng yếu.** Đối với các nhiễu loạn chỉ liên quan đến thay thế đối tượng, LXMERT, ViLBERT, và VinVL cho thấy sự giảm hiệu suất 15-17%, như được hiển thị trong Bảng 2. Sự giảm này ngụ ý rằng việc huấn luyện VLE2E không mạnh mẽ ngay cả trên grounding đối tượng. Mặc dù các phương pháp NS tệ hơn các hệ thống VLE2E trên dữ liệu kiểm tra trong miền, chúng rất mạnh mẽ trên việc thay thế đối tượng phía ngôn ngữ. Pipeline NS của chúng tôi với T5 vượt trội hơn phương pháp VLE2E tốt nhất 0,8 điểm trên tập đối lập, mặc dù tệ hơn 14,8 điểm trên dữ liệu kiểm tra trong miền. Phát hiện này cho thấy lợi ích về tính mạnh mẽ của việc có một mô-đun grounding đối tượng riêng biệt.

**VLE2E gặp khó khăn với các nhiễu loạn thay đổi ý nghĩa.** Đối với các nhiễu loạn liên quan đến suy luận giữa các ảnh, cả VisualBERT và ViLBERT đều hoạt động tệ hơn trên các nhiễu loạn thay đổi ý nghĩa so với các nhiễu loạn bảo toàn ý nghĩa, như được hiển thị trong Bảng 3. Đối với các nhiễu loạn bảo toàn ý nghĩa, chúng tôi quan sát không có sự giảm độ chính xác lớn trên các câu hỏi đếm, và sự giảm hiệu suất 10-20% trên các câu hỏi nhị phân. Trên các nhiễu loạn thay đổi ý nghĩa, việc thay thế at least và all gây ra sự giảm hiệu suất thảm khốc hơn 40-65% cho cả VisualBERT và ViLBERT, trong khi trao đổi no và some chỉ dẫn đến sự giảm 10%. Giả thuyết của chúng tôi là các hệ thống VLE2E không thể tổng quát hóa tốt đến các hoạt động logic hiếm trong dữ liệu tinh chỉnh: các đối lập của at least và all hiếm khi hoặc không bao giờ xuất hiện trong dữ liệu huấn luyện, trong khi các đối lập của no và some (tức là, some và no, tương ứng) là phổ biến. Tính nhất quán cục bộ là 96,3% cho at least → less than và 80,2% cho all → either none or only some, ngụ ý rằng các hệ thống VLE2E không chú ý đủ đến các lượng từ mà các đối lập của chúng không được thấy trong quá trình tinh chỉnh.

**Hiệu suất NS không có tương quan với thay đổi ý nghĩa.** Thay vào đó, các phương pháp NS cho thấy sự giảm hiệu suất tương tự cho cả các nhiễu loạn bảo toàn ý nghĩa và thay đổi ý nghĩa. Độ chính xác cao hơn các mô hình VLE2E trên hầu hết các nhiễu loạn thay đổi ý nghĩa, nhưng thấp hơn trên các nhiễu loạn bảo toàn ý nghĩa, đặc biệt là trên các câu hỏi đếm. Trong một số trường hợp thay đổi ý nghĩa, độ chính xác oracle thậm chí gần 100%, cho thấy rằng bộ phân tích ngữ nghĩa rất mạnh mẽ trong những tình huống đó.

**NS phục hồi nhanh chóng với huấn luyện few-shot.** Chúng tôi thêm từ 1 đến 5 ví dụ từ một tập đối lập vào tập dữ liệu huấn luyện đầy đủ và huấn luyện lại mô hình cho few-shot learning. Hình 3 cho thấy các phương pháp NS học nhanh chóng và thích ứng với các loại ví dụ mới, trong khi VisualBERT học chậm dưới huấn luyện few-shot. Với biểu đồ cảnh vàng, độ chính xác NS tăng thậm chí nhanh hơn, cho thấy rằng một số cải thiện bị ẩn bởi thực tế là các biểu đồ cảnh được tạo của chúng tôi không hoàn hảo. Lưu ý rằng đối với các hệ thống NS, chúng tôi chỉ thích ứng phần mô hình hóa ngôn ngữ, vì các tập đối lập chỉ ảnh hưởng đến ngôn ngữ. Do đó, chúng tôi cũng có thể kết luận rằng các mô hình chỉ ngôn ngữ thích ứng nhanh hơn các mô hình neural VL.

### 5.4 Tổng quát hóa compositional

Chúng tôi kiểm tra các hệ thống VLE2E và NS với các tập tổng quát hóa compositional COVR và liệt kê độ chính xác của chúng trong Bảng 1. Đối với các hệ thống NS, chúng tôi so sánh các dạng logic compositional (CLF) của chúng tôi với các dạng logic gốc (OLF) từ COVR.

**CLF cải thiện tổng quát hóa.** So sánh hai cột cuối trong Bảng 4, rõ ràng là các dạng logic CLF mới cải thiện tổng quát hóa đến các kết hợp mới của các thuộc tính truy vấn so với các dạng logic gốc, và làm cho tổng quát hóa đến các template mới có thể.

**NS có hiệu suất trong miền thấp hơn nhưng tổng quát hóa compositional cao hơn.** Trong Bảng 4, độ chính xác trong miền của hệ thống NS luôn thấp hơn so với các hệ thống VLE2E. Tuy nhiên, trên hầu hết các phân chia compositional, hiệu suất của VisualBERT tệ hơn phương pháp NS. Ngoại lệ duy nhất là VERIFY QUANT ATTR, nơi có một hoạt động phức tạp so sánh xem hai danh sách đối tượng có cùng một số thuộc tính hay không. Theo giả thuyết của chúng tôi về VLE2E tốt hơn tại các câu hỏi với các cụm từ xảy ra thường xuyên trong huấn luyện, chúng tôi tính toán độ tương tự cosine của embedding văn bản trong ViLBERT, và thấy các ví dụ trong template VERIFY QUANT ATTR gần về mặt ngữ nghĩa với các ví dụ trong template SPECIFIC SAME ATTR. Ví dụ cho các template VERIFY QUANT ATTR và SPECIFIC SAME ATTR là "Do all cats that are on a floor have the same color?" và "Does the dog that is in grass and the dog that is in water have the same color?", tương ứng. Tuy nhiên, hai template này có các dạng logic khác nhau trong cả CLF và OLF, làm cho các hệ thống VLE2E dễ tổng quát hóa hơn nhưng khó hơn cho các hệ thống NS.

### 5.5 Chuyển giao giữa các benchmark

Kiểm tra chuyển giao giữa các benchmark nhằm khám phá khả năng chuyển giao giữa các benchmark của cùng một tác vụ trả lời câu hỏi thị giác. Chúng tôi đánh giá việc chuyển giao giữa GQA và VQA vì chúng chia sẻ các loại truy vấn tương tự.

**VLE2E có thể chuyển giao hơn NS.** Trong Bảng 5, LXMERT có sự giảm độ chính xác 8-15% cho việc chuyển giao từ mỗi tập dữ liệu sang tập kia. Tuy nhiên, phương pháp NS với T5 làm bộ phân tích ngữ nghĩa có hiệu suất thậm chí tệ hơn trên việc chuyển giao. Sử dụng trình tạo biểu đồ cảnh và bộ phân tích ngữ nghĩa được huấn luyện trên GQA, độ chính xác của phương pháp NS giảm hơn 70% trên các câu hỏi mở.

**Thất bại của NS chủ yếu do lỗi tạo biểu đồ cảnh.** Để hiểu lý do thất bại của hệ thống NS, chúng tôi tiến hành phân tích thủ công trên 40 ví dụ VQA. Chúng tôi quan sát rằng hơn 75% các chương trình VQA được tạo đúng với bộ phân tích ngữ nghĩa được huấn luyện trên GQA. Tuy nhiên, chúng thường không thực thi đến câu trả lời đúng vì (1) các đối tượng tương tự về mặt ngữ nghĩa có tên nút khác nhau trong các biểu đồ cảnh được tạo; (2) một số đối tượng khó phát hiện hơn do sự dịch chuyển miền thị giác. Ví dụ, đối với một chương trình được tạo như ["operation": "select", "argument": "mattress"], chúng ta có thể không tìm thấy một đối tượng có tên "mattress" trong biểu đồ cảnh được tạo, nơi nó có thể được đặt tên là "bed". Để định lượng vấn đề này, chúng tôi tính toán tỷ lệ đối tượng bị thiếu, tỷ lệ phần trăm của các chương trình gây ra lỗi trong quá trình thực thi vì các đối tượng được đề cập trong chương trình không được tìm thấy trong biểu đồ cảnh. Tỷ lệ đối tượng bị thiếu cao trong Bảng 5 cho thấy rằng mô-đun tạo biểu đồ cảnh được huấn luyện trên GQA không thể khớp đúng các đối tượng được đề cập trong các chương trình cho hình ảnh VQA.

**NS thỉnh thoảng yêu cầu các nguyên thủy mới.** Một lý do khả thi khác cho thất bại chuyển giao giữa các benchmark của hệ thống NS từ GQA sang VQA sẽ là một số loại câu hỏi trong VQA yêu cầu các hoạt động nguyên thủy mới. Trong phân tích thủ công của chúng tôi, ít hơn 10% các chương trình VQA yêu cầu thêm các hoạt động nguyên thủy mới, chứng minh rằng đây không phải là lý do chính cho những khó khăn của NS. Hầu hết những câu hỏi này liên quan đến suy luận thường thức, chẳng hạn như hỏi tại sao một số sự kiện xảy ra trong hình ảnh (ví dụ, "Why is the man on the street?" nơi câu trả lời là "homeless"). Chúng tôi cũng lưu ý rằng chúng tôi chỉ đánh giá trên các câu hỏi nhị phân và mở của VQA nhưng loại trừ các câu hỏi đếm, chiếm khoảng 13% tập dữ liệu. GQA không có câu hỏi đếm, vì vậy bộ phân tích ngữ nghĩa được huấn luyện trên GQA không thể tạo ra các hoạt động đếm.

**Cần bao nhiều thích ứng thủ công để chuyển giao các hệ thống NS sang một benchmark mới?** Các hệ thống NS yêu cầu thích ứng thủ công cho các tập dữ liệu khác nhau. Từ việc chuyển giao giữa GQA và VQA, chúng tôi cho thấy cần ít thích ứng thủ công trên phía ngôn ngữ của các hệ thống NS để chuyển giao giữa các benchmark của cùng một tác vụ. Với một số cơ chế khớp thực thể giữa các đối tượng tương tự về mặt ngữ nghĩa và một mô-đun tạo biểu đồ cảnh mạnh mẽ hơn tổng quát hóa tốt giữa các tập dữ liệu, NS có thể chuyển giao tốt.

## 6 Thảo luận và kết luận

Tóm lại, các hệ thống huấn luyện VLE2E không học được suy luận chính xác, điều này cản trở khả năng tổng quát hóa của chúng dưới các nhiễu loạn nhỏ đối với ngôn ngữ hoặc thị giác. Mặc dù kết quả trong miền của các hệ thống NS thường hơi tệ hơn các hệ thống VLE2E, các phương pháp NS mạnh mẽ hơn trên hầu hết các kiểm tra tổng quát hóa mà chúng tôi phát triển ở đây. Ngay cả khi hiệu suất của các phương pháp NS giảm trên một số dữ liệu OOD, chúng vẫn có thể nhanh chóng phục hồi bằng huấn luyện few-shot. Tuy nhiên, các hệ thống VLE2E vẫn đạt hiệu suất tốt hơn trên chuyển giao giữa các benchmark, trong khi các phương pháp NS gặp khó khăn khi các câu hỏi kiểm tra yêu cầu các cấu trúc chương trình mới hoặc các loại đối tượng biểu đồ cảnh.

Công trình của chúng tôi nhấn mạnh tầm quan trọng của việc đánh giá trên một tập hợp đa dạng các chỉ số bên cạnh độ chính xác trong phân phối, phù hợp với nghiên cứu gần đây về cải thiện bảng xếp hạng (Ethayarajh và Jurafsky, 2020; Ma et al., 2021). Phân tích của chúng tôi cho thấy rằng chúng ta không nên kỳ vọng độ chính xác trong miền và ngoài miền có mối tương quan mạnh khi đánh giá các loại mô hình rất khác nhau, chẳng hạn như các mô hình VLE2E và NS, trái ngược với Miller et al. (2020, 2021). Cuối cùng, chúng tôi hy vọng quan sát của chúng tôi rằng các hệ thống từ đầu đến cuối và neuro-symbolic có những lợi thế tổng quát hóa bổ sung sẽ truyền cảm hứng cho cộng đồng thiết kế các hệ thống suy luận VL mạnh mẽ hơn chia sẻ lợi ích của cả hai phương pháp.

## Lời cảm ơn

Công trình này được hỗ trợ một phần bởi NSF (RI AWD-00001042, số giải thưởng 1833137).

## Hạn chế

Hầu hết các thí nghiệm của chúng tôi tập trung vào các tập dữ liệu với các chú thích ngôn ngữ tổng hợp. Cụ thể, GQA và COVR đều sử dụng ngôn ngữ tổng hợp, trong khi VQA có các câu hỏi do con người viết. Các tập dữ liệu suy luận VL hiện có với các câu hỏi ngôn ngữ tự nhiên không có các chương trình chức năng và biểu đồ cảnh được chú thích. Vì chúng tôi sử dụng các hệ thống NS phải được huấn luyện trên các chương trình được chú thích, chúng tôi không thể dễ dàng mở rộng công trình của mình sang các tập dữ liệu khác này. Một giải pháp có thể sẽ là thích ứng các phương pháp NS đơn ảnh khác (ví dụ, NSM (Hudson và Manning, 2019b)) không yêu cầu chú thích chương trình và biểu đồ cảnh sang thiết lập đa ảnh.

Đánh giá của chúng tôi yêu cầu một sửa đổi tùy chỉnh của ngôn ngữ phân tích ngữ nghĩa trên GQA và COVR. Để áp dụng các đánh giá tương tự cho các tập dữ liệu khác, nếu các chú thích chương trình của chúng không thể áp dụng trực tiếp cho hệ thống NS của chúng tôi, các nhà thực hành có thể cần thực hiện các sửa đổi chuyên biệt cho tác vụ tương tự.

Cuối cùng, tất cả các thí nghiệm của chúng tôi đều trên dữ liệu chỉ tiếng Anh, yêu cầu suy luận hình thái học hạn chế và phân tích ngữ nghĩa hợp lý. Kết quả và kết luận có thể không áp dụng được cho các ngôn ngữ khác với hình thái học phong phú hơn.

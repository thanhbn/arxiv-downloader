# HyperLLaVA: Điều chỉnh động các chuyên gia thị giác và ngôn ngữ cho các mô hình ngôn ngữ lớn đa phương thức

Wenqiao Zhang1♠Tianwei Lin2♠Jiang Liu3♠Fangxun Shu4Haoyuan Li1
Lei Zhang4He Wanggui4Hao Zhou5Zheqi Lv1
Hao Jiang4♣Juncheng Li1♣Siliang Tang1Yueting Zhuang1♣
1Đại học Zhejiang ,2Đại học ShanghaiTech ,3Đại học Chongqing ,4Tập đoàn Alibaba ,5Viện Công nghệ Harbin
{wenqiaozhang, lihaoyuan, zl.leizhang, zheqilv, junchengli, siliang, yzhuang}@zju.edu.cn
linjiawei@shanghaitech.edu.cn,jiangliu@stu.cqu.edu.cn, {shufangxun.sfx, aoshu.jh}@alibaba-inc.com

## Tóm tắt
Những tiến bộ gần đây cho thấy việc mở rộng quy mô các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLMs) một cách hiệu quả sẽ nâng cao hiệu suất trên các tác vụ đa phương thức downstream. Mô hình MLLM phổ biến, ví dụ như LLaVA, biến đổi các đặc trưng thị giác thành các token giống văn bản bằng cách sử dụng một bộ ánh xạ thị giác-ngôn ngữ tĩnh, từ đó cho phép các LLM tĩnh phát triển khả năng hiểu thông tin thị giác thông qua điều chỉnh hướng dẫn thị giác. Mặc dù triển vọng, chiến lược điều chỉnh tĩnh mà chia sẻ cùng các tham số có thể hạn chế hiệu suất trên các tác vụ đa phương thức downstream khác nhau. Dựa trên điều này, chúng tôi giới thiệu HyperLLaVA, bao gồm việc điều chỉnh thích nghi của các tham số projector và LLM, kết hợp với một chuyên gia thị giác động và chuyên gia ngôn ngữ động, tương ứng. Các chuyên gia này được rút ra từ HyperNetworks, tạo ra các dịch chuyển tham số thích nghi thông qua hướng dẫn thị giác và ngôn ngữ, cho phép mô hình hóa projector và LLM động trong đào tạo hai giai đoạn. Các thí nghiệm của chúng tôi chứng minh rằng giải pháp của chúng tôi vượt trội đáng kể so với LLaVA trên các benchmark MLLM hiện có, bao gồm MME, MM-Bench, SEED-Bench, và LLaVA-Bench.

## 1 Giới thiệu
Bối cảnh của các Mô hình Ngôn ngữ Lớn (LLMs) (Devlin et al., 2018; Radford et al., 2018; Ouyang et al., 2022) đã trải qua sự phát triển đáng kể, nhấn mạnh tính linh hoạt đặc biệt của chúng trong việc quản lý một loạt rộng các ứng dụng tập trung vào ngôn ngữ. Để mở rộng khả năng của LLMs sang một loạt rộng hơn các đầu vào đa phương thức, các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLMs) đã thu hút sự chú ý ngày càng tăng (Radford et al., 2021; Li et al., 2022; Huang et al., 2023; Achiam et al., 2023; Li et al., 2023c). MLLMs rất quan trọng cho việc phát triển các trợ lý linh hoạt, đa năng, vì các tương tác hàng ngày bao gồm thông tin từ các phương thức khác nhau (ví dụ: video, âm thanh, môi trường 3D, point clouds) ngoài văn bản.

Các MLLMs hiện đại (ví dụ: LLaVA (Liu et al., 2023b,a)) thường tuân theo một giao thức đào tạo hai giai đoạn: (i) Căn chỉnh Thị giác-Ngôn ngữ: Một projector tĩnh được đào tạo bằng cách tận dụng các cặp hình ảnh-văn bản để đồng bộ hóa các đặc trưng thị giác với không gian nhúng từ của mô hình ngôn ngữ. Projector với các tham số tĩnh kết nối các phương thức thị giác và ngôn ngữ bằng cách dịch các đặc trưng thị giác thành các token thị giác, cho phép LLM hiểu nội dung thị giác. Chất lượng của các token thị giác được truyền tải trực tiếp ảnh hưởng đến hiệu suất của MLLM (Zhou et al., 2023). (ii) Điều chỉnh Hướng dẫn Đa phương thức. Sau khi căn chỉnh thị giác-ngôn ngữ, dữ liệu hướng dẫn đa phương thức được sử dụng để tinh chỉnh LLM, cho phép nó phản hồi các yêu cầu đa dạng của người dùng liên quan đến nội dung thị giác. Bước này rất quan trọng để tăng cường khả năng và khả năng kiểm soát của MLLM để giải quyết các tác vụ đa phương thức downstream khác nhau.

Mặc dù tầm quan trọng của hai giai đoạn, cấu trúc của projector và chiến lược điều chỉnh LLM đã được khám phá tương đối ít, hầu hết các tài liệu đều tập trung vào việc mở rộng quy mô dữ liệu pretrain (Bai et al., 2023a; Dai et al., 2023), dữ liệu instruction-following (Li et al., 2023a; Zhang et al., 2023b; Zhao et al., 2023), bộ mã hóa thị giác (Bai et al., 2023a) hoặc các mô hình ngôn ngữ (Lu et al., 2023) để tạo điều kiện cho việc hiểu thị giác-ngôn ngữ. Hơn nữa, các phân tích định lượng cho thấy mô hình đã học với các tham số tĩnh có thể hạn chế tiềm năng của chúng cho các tác vụ đa downstream (Mahabadi et al., 2021; Zhang et al., 2023a). Dựa trên những hiểu biết được đề cập ở trên, nghiên cứu của chúng tôi tập trung vào quy trình đào tạo hai giai đoạn, chuyển đổi từ điều chỉnh tĩnh sang điều chỉnh động—tức là điều chỉnh cả projector và LLM với các tham số động để cung cấp các lựa chọn thiết kế linh hoạt nhằm tăng cường khả năng suy luận của MLLM trên các tác vụ đa phương thức đa dạng.

Trong bài báo này, chúng tôi đề xuất HyperLLaVA (Hình 1(b)), đặc tính động của nó được hưởng lợi từ một mô-đun chuyên gia được thiết kế cẩn thận, được rút ra từ HyperNetworks (Ha et al., 2017) để tạo ra các tham số động dựa trên thông tin đầu vào. Triết lý bootstrapping của chúng tôi là tạo ra một cách động các đặc trưng tương quan mạnh theo hướng dẫn thị giác và ngôn ngữ, từ đó mô hình hóa động các lớp projector và LLM, tương ứng. Cụ thể, HyperLLaVA được học theo hai bước: (i) Trong căn chỉnh thị giác-ngôn ngữ, chúng tôi chia projector thành các lớp tĩnh (MLP ban đầu trong LLaVA (Liu et al., 2023a)) và các lớp động (chuyên gia thị giác), trong đó các tham số của các lớp tĩnh được cố định, trong khi các tham số của các lớp động được tạo ra một cách động dựa trên đầu vào thị giác. Chuyên gia thị giác tận dụng Hypernetwork để hỗ trợ projector tĩnh học một projector cụ thể cho thị giác mà mô hình hóa thích nghi các đặc trưng thị giác theo hướng dẫn thị giác. Bằng cách này, projector có thể cung cấp các token thị giác thích nghi đến không gian ngữ nghĩa ngôn ngữ. (2) Trong giai đoạn điều chỉnh hướng dẫn đa phương thức, chúng tôi trang bị LLM với một chuyên gia ngôn ngữ, mô hình hóa các tham số động cho các khối LLM. Chúng tôi coi đầu ra trung gian của LLM là hướng dẫn ngôn ngữ để hướng dẫn chuyên gia ngôn ngữ cung cấp khả năng hiểu cải tiến cụ thể cho hướng dẫn về yêu cầu của người dùng. Bằng cách này, MLLM tăng tính linh hoạt bằng cách thay vào đó tạo ra các tham số duy nhất cho mỗi đầu vào, cho phép MLLM tận dụng sự tương đồng giữa các mẫu trên các tập dữ liệu và tránh sự can thiệp tiềm tàng giữa các mẫu trong cùng một tập dữ liệu. Đáng chú ý, chuyên gia ngôn ngữ được đề xuất phục vụ như một phương pháp tinh chỉnh hiệu quả về tham số cho MLLMs, mang lại hiệu suất tương đương với LLaVA ban đầu.

Tóm lại, đóng góp của chúng tôi gồm ba phần như sau:
• Chúng tôi nghiên cứu chiến lược điều chỉnh động chưa được khám phá cho MLLMs và giới thiệu HyperLLaVA, tận dụng điều chỉnh động hướng dẫn thị giác và ngôn ngữ cho projector và LLM;
• Chuyên gia thị giác và ngôn ngữ được đề xuất phục vụ như một phương pháp hiệu quả về tham số cho tinh chỉnh đa tác vụ;
• Chúng tôi tiến hành các thí nghiệm toàn diện và chi tiết trên nhiều benchmark MLLM. Kết quả thí nghiệm phong phú chứng minh tính hiệu quả và tính phổ quát của phương pháp được đề xuất.

## 2 Công trình liên quan
Mô hình Ngôn ngữ Lớn. Sự phát triển của các Mô hình Ngôn ngữ Lớn (LLMs) đã thay đổi đáng kể bối cảnh xử lý ngôn ngữ tự nhiên. Các mô hình tiên phong như mô hình tập trung vào bộ mã hóa BERT (Devlin et al., 2018) và mô hình tập trung vào bộ giải mã GPT (Radford et al., 2018) đã dẫn đầu xu hướng này, cho thấy rằng việc cải thiện kích thước mô hình và tính bao quát của các tập dữ liệu đào tạo có thể mang lại những cải tiến hiệu suất chưa từng có. Dựa trên thành tích của những người tiền nhiệm, các mô hình tiếp theo đã mang lại những đổi mới đáng kể để tiếp tục thúc đẩy sức mạnh của LLMs. PaLM (Chowdhery et al., 2023) nhấn mạnh lợi ích của việc tăng các tham số mô hình để tăng cường khả năng hiểu ngôn ngữ. Trong khi đó, InstructGPT (Ouyang et al., 2022) và ChatGPT đã sử dụng các chiến lược tinh chỉnh và học tăng cường để tinh chỉnh hiệu suất của chúng trong tương tác hội thoại (Chen et al., 2023b). Tuy nhiên, việc phụ thuộc vào dữ liệu văn bản là nguồn học tập duy nhất đã là một yếu tố hạn chế, vì nó hạn chế khả năng của các mô hình tham gia với thế giới thông tin đa phương thức kết nối phong phú.

Mô hình Ngôn ngữ Lớn Đa phương thức. Trong những năm gần đây, sự phát triển của deep learning đã mang lại sự thịnh vượng cho lĩnh vực trí tuệ đa phương thức (Baltrušaitis et al., 2018; Li et al., 2023d; Zhang et al., 2022b, 2019b, 2022a). Các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLMs) tận dụng sức mạnh của LLMs, giảm thiểu chi phí tính toán bổ sung và tăng cường hiệu quả của pretrain đa phương thức (Zhang et al., 2024), để thu hẹp khoảng cách giữa dữ liệu văn bản và đa phương thức (ví dụ: hình ảnh, video, và âm thanh). Một nỗ lực nổi bật là CLIP (Radford et al., 2021), chứng minh việc căn chỉnh các phương thức thị giác và văn bản thông qua học đối lập trên một tập dữ liệu rộng lớn của các cặp hình ảnh-văn bản. (Li et al., 2022) và (Li et al., 2023e) theo xu hướng này, đề xuất BLIP và BLIP-2 cải tiến so với CLIP, và đạt được hiệu suất đáng kể trong các tác vụ thị giác cơ bản. Flamingo (Alayrac et al., 2022) dẫn đầu trong việc hợp nhất các mô hình thị giác và ngôn ngữ bằng cách sử dụng một lượng lớn tập dữ liệu hình ảnh-văn bản đan xen, tiết lộ khả năng zero-shot vô song trong việc xử lý nội dung hình ảnh-văn bản trong bối cảnh hội thoại lần đầu tiên. LLaVA (Liu et al., 2023b) một cách độc đáo kết hợp các chú thích ngắn được chú thích bởi con người và các hộp giới hạn vào mô hình ngôn ngữ GPT4. Trong lĩnh vực xử lý âm thanh, cũng có một số công trình xuất sắc, chẳng hạn như SpeechT5 (Ao et al., 2021), MMS (Pratap et al., 2023), PandaGPT (Su et al., 2023), v.v.

Hypernetworks. HyperNetwork ban đầu (Ha et al., 2017) được thiết kế để giảm số lượng tham số, tức là một mạng neural nhỏ tạo ra các tham số cho một mạng neural lớn khác, từ đó có được nén mô hình cho các tác vụ khác nhau. Sau đó, HyperNetwork được phát triển cho các tác vụ domain khác nhau, bao gồm học few-shot (Brock et al., 2018), mô hình hóa đồ thị (Zhang et al., 2019a), thích nghi domain (Zhang et al., 2023a), hợp tác thiết bị-đám mây (Lv et al., 2023b,a), v.v.

## 3 Phương pháp
Phần này mô tả khung MLLM được đề xuất HyperLLaVA. Chúng tôi sẽ trình bày từng mô-đun và chiến lược đào tạo của nó.

### 3.1 Công thức hóa bài toán
Mục tiêu chính là tận dụng hiệu quả các khả năng của cả LLM và mô hình thị giác được pretrain. Kiến trúc mạng được minh họa trong Hình 2. Cho một hình ảnh RGB x∈RH×W×3, trong đó H và W là độ phân giải gốc. Bộ mã hóa thị giác xử lý hình ảnh đầu vào để thu được một chuỗi token thị giác V= [v1, v2,···, vNv], trong đó Nv biểu thị độ dài chuỗi của các token văn bản. Tiếp theo, chúng tôi nối các token thị giác và token văn bản T= [t1, t2,···, tNt] cùng nhau và đưa chúng vào một LLM Mllm, sau đó tạo ra phản hồi ngôn ngữ R= [r1, r2,···, tNr], trong đó Nt và Nr cho biết độ dài của các token văn bản và phản hồi văn bản. Nói chung, mô hình MLLM M(·) bao gồm hai hàm như dưới đây:

M(·)|{z}
MLLM:Mp((T |V); Θp)|{z }
Projector→ M l((R|V,T); Θl)| {z }
LLM,

trong đó Mp(·; Θp) là projector và Mt(·; Θl) là điều chỉnh LLM với hướng dẫn đa phương thức với các tham số Θp và Θl, tương ứng.

### 3.2 Kiến thức cơ bản
LLaVA. LLaVA (Liu et al., 2023b) được đào tạo theo hai bước: (i) Đầu tiên, một MLP hai lớp được sử dụng như projector thị giác-ngôn ngữ Mp(·) để chuyển đổi các đặc trưng thị giác thành token thị giác V, có cùng chiều với không gian nhúng từ trong mô hình ngôn ngữ. (ii) Sau đó LLaVA thực hiện instruction-tuning với token thị giác V và token ngôn ngữ T cho LLM (Llama) Ml(·), tạo ra token phản hồi R bằng cách tối ưu hóa mục tiêu đào tạo tự hồi quy của nó.

HyperNetwork. Hypernetwork (Ha et al., 2016) là một mạng neural tạo ra các trọng số cho một mạng neural khác. Cụ thể, HyperNetwork coi các tham số của perception đa lớp (MLP) là một ma trận K(n)∈RNin×Nout, trong đó Nin và Nout biểu thị số lượng neuron đầu vào và đầu ra của lớp thứ n của MLP, tương ứng. Nin và Nout mô tả cấu trúc của các lớp MLP cùng nhau. Quá trình tạo ra K(n) có thể được coi là một phân tích nhân tử ma trận:

K(n)=ξ(z(n); Θp),∀n= 1,···, Nl.

Trong quy trình đào tạo, z(n) và ξ(·) được khởi tạo ngẫu nhiên. Các gradient được lan truyền ngược đến z(n) và ξ(·), có thể giúp cập nhật chúng. z(n) và ξ(·) sẽ được lưu thay vì K(n).

### 3.3 Mô-đun chuyên gia hướng dẫn thị giác-ngôn ngữ
Projector và LLM ban đầu của LLaVA được đào tạo với các tham số tĩnh. Chúng tôi cho rằng mô hình điều chỉnh tĩnh có thể hạn chế việc cung cấp token thị giác linh hoạt và biểu hiện phù hợp cho các tác vụ đa phương thức downstream khác nhau. Do đó, chúng tôi đề xuất trang bị projector và LLM của LLaVA ban đầu với một chuyên gia thị giác EV và một chuyên gia ngôn ngữ EL: (i) chuyên gia thị giác thích nghi phù hợp với đầu ra của projector theo hướng dẫn thị giác cụ thể (ví dụ: đặc trưng thị giác); (ii) chuyên gia ngôn ngữ mô hình hóa động các khối phía sau của LLM thông qua đầu ra khối LLM phía trước.

Mô-đun chuyên gia được rút ra từ Hypernetorks, là một mạng neural tạo ra các tham số của nó cho một mạng neural khác. Vì HyperNetwork tạo ra một cách động một mạng có điều kiện trên các embedding đầu vào, tức là "đặc tính động" có thể được mô hình hóa bởi HyperNetwork. Tuy nhiên, việc sử dụng trực tiếp HyperNetwork có thể không mô hình hóa một cách thỏa đáng việc học động vì hai lý do chính:

• Tương quan yếu. HyperNetwork ban đầu học vector tiềm ẩn để tạo ra các tham số của mô hình khác. Điều này thiếu tương quan mạnh giữa việc tạo tham số và hướng dẫn đầu vào.
• Tối ưu hóa không ổn định. Việc sử dụng HyperNetwork tạo ra các tham số của projector hoặc khối LLM là lớn (Dx×Nin×Nout), tức là rất khó để tối ưu hóa những tham số nhiều như vậy, quá trình tối ưu hóa một cách trực quan không ổn định.

Để giải quyết vấn đề này, chúng tôi cẩn thận điều chỉnh HyperNetwork với các điều chỉnh sau:

Hướng dẫn tiên nghiệm đầu vào. Chúng tôi đầu tiên đề xuất mô hình hóa các lớp động bằng cách thay thế vector tiềm ẩn đã học z bằng đầu vào cụ thể. Cụ thể, cho đặc trưng fx(i) được trích xuất từ backbone của mẫu x(i), chúng tôi đầu tiên phát triển một bộ mã hóa cụ thể cho lớp En(·) để mã hóa fx(i) thành e(n). Vector này biểu thị các tham số lớp thứ n.

e(n)=En(fx(i)),∀n= 1,···, Nl,

trong đó Nl là số lượng các lớp được mô hình hóa. Sau đó HyperNetwork được sử dụng để chuyển đổi embedding e(n) thành các tham số, tức là chúng tôi đầu vào e(n) vào hai lớp MLP sau để tạo ra các tham số của các lớp động.

w(n)= (W1e(n)+B1)W2+B2,
K(n)=w(n)+b(n),

trong đó K(n) biểu thị các tham số lớp thứ n của các lớp động. Trọng số của hai lớp MLP được ký hiệu bởi W1 và W2, tương ứng. b(n), B1 và B2 là các bias.

Adapter nhận biết HyperNetwork. Adapters là các mạng con với các tham số nhỏ được chèn sau mỗi lớp attention và feed-forward trong một mô hình (Houlsby et al., 2019). Adapter ban đầu là một phương pháp học hiệu quả về tham số mà học các tác vụ downstream bằng cách chỉ cập nhật một số lượng nhỏ tham số. Các adapter bao gồm một cặp lớp downsampling và upsampling, và một kết nối dư. Chúng tôi phát hiện rằng việc sử dụng các chiến lược downsampling và upsampling, các tham số được tạo ra bởi HyperNetwork có thể được giảm đáng kể.

Cho hướng dẫn thị giác xV và hướng dẫn ngôn ngữ xL, chuyên gia hướng dẫn thị giác-ngôn ngữ có thể được định nghĩa là:

EM(xM) =Wu
M(SwiGLU( Wd
M(xM)))
Wu
M, Wd
M=HM(xM),trong đó M∈V, L

trong đó M cho biết phương thức, Wu
M, Wd
M tương ứng biểu thị các trọng số cho upsampling và downsampling. SwiGLU (Ramachandran et al., 2017) là hàm kích hoạt, Gaussian Error Linear Unit. HM là HyperNetwork.

### 3.4 Projector hỗ trợ chuyên gia thị giác
Trong giai đoạn này, mục tiêu của chúng tôi là thích nghi các token hình ảnh với LLM, cho phép LLM hiểu các thực thể trong hình ảnh. Như được hiển thị trong Hình 2, chúng tôi chia projector thành các lớp tĩnh và các lớp động. Theo LLaVA1.5 (Liu et al., 2023a), chúng tôi sử dụng MLP hai lớp làm các lớp tĩnh. Để tăng cường biểu hiện của projector, chúng tôi phát triển một chuyên gia thị giác mà học sự dịch chuyển projector để mô hình hóa các token văn bản động.

Cụ thể, cho đặc trưng thị giác fV được trích xuất từ bộ mã hóa thị giác, chuyên gia thị giác sẽ chuyển đổi một cách thích nghi fV thành các embedding thị giác động. Chúng tôi hiển thị ba lựa chọn thay thế cho căn chỉnh thị giác-ngôn ngữ động, các token thị giác V có thể được tính toán là:

V=

L2(L1(fV) +EV1(fV))| {z }
Sử dụng chuyên gia thị giác thứ 1
L2(L1(fV)) +EV2(L1(fV))| {z }
Sử dụng chuyên gia thị giác thứ 2
L2(L1(fV) +EV1(fV)) +EV2(L1(fV))| {z }
Sử dụng chuyên gia thị giác thứ 1&2

trong đó L1 và L2 biểu thị hai MLP, EV1 và EV2 là chuyên gia thị giác cho MLP thứ nhất và thứ hai. Chúng tôi đưa ra so sánh chi tiết trong phần thí nghiệm.

Các chuyên gia thị giác như vậy học sự dịch chuyển projector để mô hình hóa các token văn bản động, và do đó tăng cường biểu hiện của projector cho các tác vụ downstream.

### 3.5 Điều chỉnh tích hợp chuyên gia ngôn ngữ
Trong giai đoạn này, LLM được điều chỉnh để trở thành một LVLM với khả năng hiểu đa phương thức. Chúng tôi sử dụng các hướng dẫn phức tạp hơn, bao gồm các tác vụ như suy luận logic hình ảnh và nhận dạng văn bản, đòi hỏi mô hình phải có khả năng hiểu đa phương thức mạnh hơn. Các nghiên cứu trước đây đã cho thấy rằng các đặc trưng được cung cấp bởi lớp trung gian có thể đủ để hiểu sơ bộ các mẫu đầu vào đã cho (Xin et al., 2020) và có thể phục vụ như gợi ý hướng dẫn để cải thiện đào tạo (Romero et al., 2014). Do đó, việc tạo ra hướng dẫn trong lớp LLM trung gian cho phép mô hình hình thành sự hiểu biết sơ bộ về hướng dẫn đã cho. Vì vậy, chúng tôi coi đầu ra của lớp LLM trung gian như hướng dẫn ngôn ngữ mà tạo ra các đặc trưng thích nghi cụ thể cho hướng dẫn nhằm tăng cường độ chính xác của việc tạo ra. Như được hiển thị trong Hình 2, cho hướng dẫn ngôn ngữ fL, các tham số của adapter {Wu
L, Wd
L} được tạo ra bởi HL(fL). Bằng cách này, các đặc trưng cụ thể cho hướng dẫn có thể được tính toán như dưới đây:

ˆxL=EL(xL) +xL+ FFN(SwiGLU( xl))

trong đó xL là các đặc trưng được tạo ra từ chuẩn hóa RMS và self-attention trong khối của LLM.

## 4 Thí nghiệm
Chúng tôi xác minh tính hiệu quả của HyperLLaVA trên nhiều tập dữ liệu và sau đó thảo luận về các thuộc tính của HyperLLaVA với các nghiên cứu có kiểm soát.

### 4.1 Tập dữ liệu và cài đặt
Tập dữ liệu Benchmark. Chúng tôi đánh giá HyperLLaVA được đề xuất trên năm tập dữ liệu VQA: VQA-v2 (Goyal et al., 2017); GQA (Hudson và Manning, 2019); VizWiz (Gurari et al., 2018); SQAI: ScienceQA-IMG (Lu et al., 2022); VQAT (Singh et al., 2019): TextVQA và bảy Bộ công cụ Benchmark: POPE (Li et al., 2023f); MME (Fu et al., 2023); MMB: MMBench (Liu et al., 2023c); MMBCN: MMBench-Chinese (Liu et al., 2023c); SEED: SEED-Bench (Li et al., 2023b); LLaVAW: LLaVA-Bench(In-the-Wild) (Liu et al., 2023b); MM-Vet (Yu et al., 2023).

Chi tiết triển khai. Mô hình được đào tạo trên máy 8-A100 trong một ngày. Chi tiết triển khai tham khảo Phụ lục. Trong việc đào tạo HyperLLaVA, chúng tôi sử dụng bộ tối ưu hóa ADAMW (Loshchilov và Hutter, 2017), điều chỉnh các siêu tham số để phù hợp với các yêu cầu cụ thể của từng giai đoạn. Đối với giai đoạn căn chỉnh đặc trưng, các tham số được đặt là B=32, Lr=0,001, trong khi đối với giai đoạn điều chỉnh hướng dẫn thị giác, chúng tôi điều chỉnh các tham số thành B=16, Lr=0,00002. Cấu hình cho bộ tối ưu hóa ADAMW kết hợp các cài đặt sau: β=(0,9,0,999), ε=1×10−8, và Wd=0,0, đảm bảo một chiến lược tối ưu hóa bespoke giải quyết hiệu quả nhu cầu độc đáo của từng giai đoạn đào tạo.

Ngoài ra, chúng tôi đào tạo mô hình của mình theo cùng quy trình đào tạo như LLaVA-1.5. Quy trình bao gồm hai giai đoạn: (1) giai đoạn căn chỉnh đặc trưng: sử dụng tập con 558K của tập dữ liệu LAION-CC-SBU để kết nối một bộ mã hóa thị giác pretrain đã đóng băng với một LLM đã đóng băng; (2) giai đoạn điều chỉnh hướng dẫn thị giác: sử dụng 150K dữ liệu theo hướng dẫn đa phương thức được tạo ra bởi GPT, cộng với khoảng 515K dữ liệu VQA từ các tác vụ định hướng học thuật, để dạy mô hình tuân theo các hướng dẫn đa phương thức.

So sánh các phương pháp. Để định lượng hiệu quả của khung được đề xuất, chúng tôi so sánh HyperLLaVA với các phương pháp SOTA trước đây. Chúng tôi chọn BLIP-2 (Li et al., 2023e), InstructBLIP (Dai et al., 2023) dựa trên Vicuna-7B, InstructBLIP (Dai et al., 2023) dựa trên Vicuna-13B, Shikra (Chen et al., 2023a), IDEFICS-9B (Laurençon et al., 2023), IDEFICS-80B (Laurençon et al., 2023), Qwen-VL (Bai et al., 2023b), Qwen-VL-Chat (Bai et al., 2023b) và LLaVA-1.5 (Liu et al., 2023a). Thêm chi tiết về baseline trong Phụ lục.

### 4.2 Hiệu suất tổng thể
Chúng tôi benchmark HyperLLaVA trên một loạt rộng các benchmark VQA học thuật và các benchmark gần đây được đề xuất cụ thể cho các LMM theo hướng dẫn, tổng cộng 12 benchmark. Bảng 1 tóm tắt kết quả định lượng của khung của chúng tôi và baseline trên năm tập dữ liệu VQA và năm Bộ công cụ Benchmark. Chúng tôi đưa ra các quan sát sau: 1) Nói chung, bất kể các tình huống khác nhau, so với LLaVA, HyperLLaVA đạt được hiệu suất tốt nhất trên hầu hết tất cả các tình huống đa phương thức trên cả hai tập dữ liệu (ngoại trừ benchmark MME), điều này chứng minh mạnh mẽ khả năng tổng quát của HyperLLaVA được đề xuất. 2) HyperLLaVA (cả 7B và 13B) vượt trội hơn các MLLM lớn hơn với hàng tỷ tham số có thể đào tạo cho kết nối đa phương thức (ví dụ: IDEFICS 80B (Laurençon et al., 2023)). Điều này tiếp tục cho thấy tính hiệu quả của cấu trúc MLLM được đề xuất. 3) So với LLaVA ban đầu, chúng tôi cho thấy HyperLLaVA đạt được hiệu suất tốt nhất trên 11 trong 12 benchmark. Kết quả như vậy được hưởng lợi từ chuyên gia thị giác và ngôn ngữ nhẹ được thiết kế cẩn thận, giúp tăng cường projector và LLM tĩnh để tạo điều kiện cho các tác vụ đa phương thức khác nhau.

### 4.3 Nghiên cứu loại bỏ
Hiệu quả của từng thành phần. Bảng 1 cũng minh họa hiệu quả của từng thành phần, tức là chuyên gia thị giác EV và chuyên gia ngôn ngữ EL. So sánh HyperLLaVA và HyperLLaVA(- EV) (Hàng 11 so với Hàng 13), EV đóng góp cải thiện 2,61% về độ chính xác trung bình. Trong khi đó, Hàng 11 cho thấy rằng nó bị giảm 0,94%, một sự suy giảm hiệu suất đáng chú ý mà không có EL. Tóm lại, chúng tôi có thể quan sát thấy rằng sự cải thiện của việc sử dụng từng mô-đun riêng lẻ là có thể phân biệt được. Kết hợp tất cả các thành phần, HyperLLaVA của chúng tôi thể hiện sự cải thiện ổn định so với baseline.

### 4.4 Phân tích sâu
Chúng tôi xác thực hiệu quả của hai mô-đun được đề xuất thông qua các thí nghiệm trên các benchmark GQA, SQA-I, VQA-T, POPE và MME.

Ba lựa chọn thay thế cho căn chỉnh thị giác-ngôn ngữ. Để xây dựng hiểu biết về projector hỗ trợ chuyên gia thị giác trong HyperLLaVA, chúng tôi thực hiện phân tích sâu về ba lựa chọn thay thế cho căn chỉnh thị giác-ngôn ngữ động. Bảng 2 thể hiện ba kết quả. Theo quan sát của chúng tôi, việc sử dụng một chuyên gia thị giác để truy cập phép chiếu động mang lại kết quả tốt nhất. Ngoài ra, hai kế hoạch khác cũng thu được kết quả tương đương, cho thấy hiệu quả của phép chiếu động.

Phân tích tích hợp chuyên gia ngôn ngữ cho các khối khác nhau. Để phân tích sâu hiệu quả của các chuyên gia ngôn ngữ, chúng tôi nghiên cứu việc tích hợp chuyên gia ngôn ngữ cho các khối khác nhau trong Bảng 3, bao gồm 16 khối trước (trước 1/2 lớp LLM), tất cả 32 khối (tất cả lớp LLM) và 16 khối sau (sau 1/2 lớp LMM). Nói chung, việc tận dụng tích hợp chuyên gia ngôn ngữ cho 16 khối sau thu được hiệu suất gần như tốt nhất. Ngoài ra, Hàng 2 và Hàng 3 sử dụng đầu vào ngôn ngữ ban đầu như hướng dẫn ngôn ngữ, thu được kết quả tối ưu phụ so với tích hợp chuyên gia ngôn ngữ cho 16 khối sau. Trực giác của chúng tôi là hướng dẫn ngôn ngữ có thể chưa thu thập đủ thông tin ngữ cảnh để mô hình hóa lớp LLM động tiếp theo.

Phân tích về các khối được chèn cho hướng dẫn ngôn ngữ. Chúng tôi điều tra tác động của việc chèn hướng dẫn ngôn ngữ vào các lớp khác nhau của LLM. Chúng tôi báo cáo điểm đánh giá của các tập dữ liệu GQA và POPE trong Hình 4. Chúng tôi quan sát thấy rằng hiệu suất thấp khi chúng tôi chèn hướng dẫn ngôn ngữ quá sớm (tức là 4, 8) vì mô hình có thể chưa thu thập đủ thông tin ngữ cảnh để tạo ra hướng dẫn hiệu quả. Trong khi đó, việc chèn hướng dẫn ngôn ngữ quá muộn (tức là 24, 28) làm giảm hiệu suất. Chúng tôi suy đoán điều này là do hướng dẫn được tạo ra quá tập trung và không có đủ lớp để tích hợp các chi tiết nhận biết ngôn ngữ.

Phân tích cấu trúc của chuyên gia. Chúng tôi trình bày một cách có hệ thống những lợi ích rõ ràng từ cấu trúc chuyên gia được thiết kế cẩn thận trong Bảng 5. Cấu trúc dựa trên adapter vượt trội hơn cấu trúc dựa trên MLP trên tất cả các tập dữ liệu, chủ yếu do MLP được tạo ra không còn là một mạng nhẹ để tối ưu hóa, tạo ra hiệu suất không ổn định. So với HyperNetwork+Adapter (Hàng 3 so với Hàng 4), cấu trúc chuyên gia hướng dẫn thị giác-ngôn ngữ được đề xuất của chúng tôi thu được hiệu suất tốt nhất. Kết quả tương ứng với giả định của chúng tôi về HyperNetworks ban đầu, thiếu tương quan mạnh giữa đầu vào và việc tạo tham số. Phương pháp của chúng tôi, cho phép mô hình tận dụng sự tương đồng giữa các mẫu trên các tập dữ liệu và tránh sự can thiệp tiềm tàng giữa các mẫu trong cùng một tập dữ liệu.

Ảnh hưởng của chiều kích thước đầu vào chuyên gia và downsampling. Hình 4 cung cấp một cách thực nghiệm một chiều kích thước phù hợp của đầu vào và downsampling, tức là 64 và 16, tương ứng, việc tăng hoặc giảm giá trị này dẫn đến sự suy giảm hiệu suất. Theo phân tích của chúng tôi, một chiều kích thước lớn hơn có thể dẫn đến tối ưu hóa HyperNetwork không ổn định và một giá trị nhỏ hơn chứa ít thông tin hướng dẫn ngôn ngữ hơn cho việc học động, và do đó mang lại sự suy giảm hiệu suất.

Tinh chỉnh hiệu quả về tham số. Chuyên gia ngôn ngữ được đề xuất của chúng tôi cũng có thể phục vụ như một hàm tinh chỉnh hiệu quả về tham số. Cấu trúc tương tự như HyperNetwork+Adapter. Tuy nhiên, các phương pháp dựa trên hypernetwork ban đầu thường điều kiện hóa các tham số của chúng trên một tiềm ẩn đã học, ngụ ý rằng mô hình giống nhau cho mọi ví dụ, mang lại sự suy giảm hiệu suất. Tóm lại, chuyên gia ngôn ngữ được đề xuất là một cách hiệu quả và hiệu quả về tham số để chia sẻ thông tin trên nhiều adapter để cho phép chuyển giao tích cực đến các tác vụ tài nguyên thấp và liên quan.

Đánh giá ảo giác đối tượng. Chúng tôi áp dụng đường ống đánh giá của POPE (Li et al., 2023f), một phương pháp truy vấn dựa trên thăm dò ý kiến, để đánh giá ảo giác đối tượng trong HyperLLaVA. Kết quả được trình bày trong Bảng 4, trong đó HyperLLaVA thể hiện hiệu suất tốt nhất, cho thấy rằng HyperLLaVA có xu hướng tạo ra các đối tượng phù hợp với hình ảnh đã cho. Ngoài ra, chúng tôi quan sát thấy rằng tỷ lệ "yes" của HyperLLaVA vẫn tương đối cân bằng, cho thấy rằng mô hình của chúng tôi có khả năng cung cấp phản hồi chính xác dựa trên các câu hỏi.

## 5 Kết luận
Dựa trên chiến lược điều chỉnh động sáng tạo của HyperLLaVA, công trình của chúng tôi mở đường cho những tiến bộ đột phá trong các hệ thống học đa phương thức. Bằng cách điều chỉnh thích nghi cả tham số projector và LLM, và tích hợp các chuyên gia thị giác và ngôn ngữ động, chúng tôi không chỉ vượt qua các chuẩn mực hiệu suất được thiết lập bởi LLaVA mà còn giới thiệu một phương pháp hiệu quả về tham số. Phương pháp này cung cấp một chân trời mới để nâng cao hiệu suất tác vụ đa phương thức thông qua các điều chỉnh động, cá nhân hóa. Nghiên cứu trong tương lai có thể tiếp tục khám phá khả năng mở rộng của các cơ chế điều chỉnh động, có thể mở khóa những con đường mới để hiểu và tích hợp thông tin đa phương thức một cách liền mạch hơn.

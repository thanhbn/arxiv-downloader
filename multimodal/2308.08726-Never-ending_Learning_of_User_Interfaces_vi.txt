<<<<<<< Updated upstream
# Học Tập Không Ngừng Về Giao Diện Người Dùng

Jason Wu∗
jsonwu@cmu.edu
Viện HCI, Đại học Carnegie Mellon
Pittsburgh, PA, USA

Rebecca Krosnick†
rkros@umich.edu
Khoa Khoa học Máy tính và Kỹ thuật,
Đại học Michigan
Ann Arbor, Michigan, USA

Eldon Schoop
eldon@apple.com
Apple
USA

Amanda Swearngin
aswearngin@apple.com
Apple
USA

Jeffrey P. Bigham
jbigham@apple.com
Apple
USA

Jeffrey Nichols
=======
# Học liên tục không bao giờ kết thúc về Giao diện người dùng
Jason Wu∗
jsonwu@cmu.edu
Viện HCI, Đại học Carnegie Mellon
Pittsburgh, PA, USARebecca Krosnick†
rkros@umich.edu
Khoa Khoa học máy tính và Kỹ thuật,
Đại học Michigan
Ann Arbor, Michigan, USAEldon Schoop
eldon@apple.com
Apple
USA
Amanda Swearngin
aswearngin@apple.com
Apple
USAJeffrey P. Bigham
jbigham@apple.com
Apple
USAJeffrey Nichols
>>>>>>> Stashed changes
jwnichols@apple.com
Apple
USA

TÓM TẮT
<<<<<<< Updated upstream
Các mô hình học máy đã được huấn luyện để dự đoán thông tin ngữ nghĩa về giao diện người dùng (UI) nhằm làm cho các ứng dụng dễ tiếp cận hơn, dễ kiểm thử hơn, và tự động hóa. Hiện tại, hầu hết các mô hình dựa trên các tập dữ liệu ảnh chụp màn hình tĩnh được gán nhãn bởi con người, một quá trình tốn kém và đáng ngạc nhiên là dễ mắc lỗi đối với một số tác vụ nhất định. Ví dụ, các công nhân gán nhãn liệu một phần tử UI có "có thể chạm được" từ ảnh chụp màn hình phải đoán bằng cách sử dụng các dấu hiệu thị giác, và không có lợi ích của việc chạm vào phần tử UI trong ứng dụng đang chạy và quan sát các hiệu ứng. Trong bài báo này, chúng tôi trình bày Người Học UI Không Ngừng, một bộ thu thập dữ liệu ứng dụng tự động cài đặt các ứng dụng thực từ cửa hàng ứng dụng di động và thu thập chúng để suy luận các thuộc tính ngữ nghĩa của UI bằng cách tương tác với các phần tử UI, khám phá các ví dụ huấn luyện mới và thử thách để học hỏi, và liên tục cập nhật các mô hình học máy được thiết kế để dự đoán những ngữ nghĩa này. Người Học UI Không Ngừng cho đến nay đã thu thập dữ liệu trong hơn 5.000 giờ thiết bị, thực hiện hơn nửa triệu hành động trên 6.000 ứng dụng để huấn luyện ba mô hình thị giác máy tính cho i) dự đoán khả năng chạm, ii) dự đoán khả năng kéo, và iii) độ tương tự màn hình.
=======
Các mô hình học máy đã được huấn luyện để dự đoán thông tin ngữ nghĩa về giao diện người dùng (UI) nhằm làm cho các ứng dụng dễ tiếp cận hơn, dễ kiểm thử hơn và có thể tự động hóa. Hiện tại, hầu hết các mô hình dựa trên các bộ dữ liệu ảnh chụp màn hình tĩnh được gắn nhãn bởi người chú thích, một quy trình tốn kém và đáng ngạc nhiên là dễ xảy ra lỗi đối với một số tác vụ nhất định. Ví dụ, các công nhân gắn nhãn xem liệu một phần tử UI có "có thể chạm" từ ảnh chụp màn hình hay không phải đoán bằng cách sử dụng các dấu hiệu trực quan, và không có lợi ích của việc chạm vào phần tử UI trong ứng dụng đang chạy và quan sát hiệu ứng. Trong bài báo này, chúng tôi trình bày Never-ending UI Learner, một trình thu thập dữ liệu ứng dụng tự động cài đặt các ứng dụng thực từ cửa hàng ứng dụng di động và thu thập dữ liệu từ chúng để suy luận các thuộc tính ngữ nghĩa của UI bằng cách tương tác với các phần tử UI, khám phá các ví dụ huấn luyện mới và thách thức để học từ đó, và liên tục cập nhật các mô hình học máy được thiết kế để dự đoán các ngữ nghĩa này. Never-ending UI Learner cho đến nay đã thu thập dữ liệu trong hơn 5.000 giờ thiết bị, thực hiện hơn nửa triệu hành động trên 6.000 ứng dụng để huấn luyện ba mô hình thị giác máy tính cho i) dự đoán khả năng chạm, ii) dự đoán khả năng kéo, và iii) độ tương tự màn hình.
>>>>>>> Stashed changes

TỪ KHÓA
Giao diện người dùng, mô hình hóa, mô hình hóa ui, học máy, thu thập dữ liệu

<<<<<<< Updated upstream
Định dạng Tham chiếu ACM:
Jason Wu, Rebecca Krosnick, Eldon Schoop, Amanda Swearngin, Jeffrey P. Bigham, và Jeffrey Nichols. 2023. Học Tập Không Ngừng Về Giao Diện Người Dùng. Trong Hội nghị Thường niên lần thứ 36 của ACM về Phần mềm và Công nghệ Giao diện Người dùng (UIST '23), ngày 29 tháng 10 - 1 tháng 11, 2023, San Francisco, CA, USA. ACM, New York, NY, USA, 13 trang. https://doi.org/10.1145/3586183.3606824

1 GIỚI THIỆU
Học Máy (ML) đã đóng một vai trò ngày càng quan trọng trong lĩnh vực Giao diện Người dùng (UI) di động. Các kỹ thuật gần đây đã sử dụng Mạng Nơ-ron Sâu (DNN) để kết nối các khoảng trống khả năng sử dụng quan trọng và cho phép các loại đánh giá mới, chẳng hạn như cung cấp siêu dữ liệu trợ năng bị thiếu cho UI [49], đưa ra phản hồi cho các nhà thiết kế để làm cho các tính năng UI dễ khám phá hơn [38,42], và dự đoán sự tương tác của người dùng với hoạt ảnh [50]. Các sản phẩm nghiên cứu cung cấp cho những tương tác này là các tập dữ liệu lớn về ảnh chụp màn hình UI di động được chú thích bởi các nhà chú thích con người [10,19]. Những tập dữ liệu này cung cấp một khối lượng dữ liệu vô giá để huấn luyện DNN, nhưng chúng chỉ nắm bắt một ảnh chụp cố định của các chế độ xem của các ứng dụng di động và cực kỳ tốn kém để thu thập và cập nhật. Ngoài ra, việc dựa vào các nhà chú thích để ước tính các thuộc tính nhất định của các phần tử UI từ các dấu hiệu thị giác tĩnh được biết là dễ mắc lỗi [38]. Được truyền cảm hứng bởi mô hình Học Tập Không Ngừng [31], chúng tôi đề xuất một phương pháp tự động để thu thập các chú thích phần tử UI bằng cách tương tác trực tiếp với các ứng dụng với một bộ thu thập dữ liệu tự động liên tục cải thiện hiệu suất của chính nó và có thể làm mới các mô hình ML cho các tác vụ hạ nguồn khác theo thời gian.

Chúng tôi đã xây dựng Người Học UI Không Ngừng, một bộ thu thập dữ liệu ứng dụng hình thức hóa việc học ngữ nghĩa UI như một quá trình tích cực sử dụng các tương tác thực trên các thiết bị thực để khám phá UI và khám phá các thuộc tính được sử dụng để liên tục huấn luyện các mô hình học máy. Cụ thể hơn, bộ thu thập dữ liệu của chúng tôi tự động cài đặt các ứng dụng thực từ các cửa hàng ứng dụng di động và thu thập chúng để khám phá các ví dụ huấn luyện mới, thử thách để học hỏi (ví dụ, những ví dụ dẫn đến độ tin cậy mô hình thấp). Trong quá trình thu thập, Người Học UI Không Ngừng ghi lại bối cảnh thời gian (tức là chụp ảnh màn hình trước, trong và sau các tương tác) được sử dụng bởi các hàm heuristic để tạo ra các nhãn chính xác hơn so với những gì có thể từ các ảnh chụp màn hình đơn được chú thích bởi con người. Dữ liệu thu được được sử dụng để huấn luyện các mô hình dự đoán khả năng chạm và khả năng kéo của các phần tử UI và xác định độ tương tự của các màn hình gặp phải. Mặc dù quá trình có thể bắt đầu với một mô hình được huấn luyện từ dữ liệu được gán nhãn bởi con người, quá trình end-to-end không yêu cầu bất kỳ ví dụ được gán nhãn bởi con người bổ sung nào.

Trái ngược với các pipeline dữ liệu hiện có cho mô hình hóa UI dựa trên dữ liệu [10,19,53], mô hình học UI không ngừng của chúng tôi cho phép thu thập dữ liệu, chú thích và huấn luyện mô hình được thực hiện mà không cần bất kỳ giám sát nào của con người và có thể chạy vô thời hạn. Tất nhiên, trong bài báo này, việc học không thực sự không ngừng. Ở đây chúng tôi trình bày các thí nghiệm phân tích các đặc tính hiệu suất của người học của chúng tôi trong 5.000 giờ thiết bị, trong đó nó đã thực hiện hơn nửa triệu hành động trên 6.000 ứng dụng. Tập dữ liệu thu được lớn hơn một bậc so với các tập dữ liệu UI được chú thích bởi con người hiện có [10,53] và cho phép chúng tôi phân tích hiệu suất của các mô hình ngữ nghĩa UI khi được huấn luyện với số lượng ngày càng tăng các ví dụ được thu thập gần đây. Cuối cùng, chúng tôi tin rằng mô hình này có thể được sử dụng theo kiểu "không ngừng" thực sự, liên tục thu thập hệ sinh thái ứng dụng, thu thập dữ liệu từ tất cả các ứng dụng có sẵn, và trải nghiệm các phong cách và xu hướng UI mới khi các ứng dụng mới hoặc cập nhật được phát hành.

Các đóng góp cụ thể của bài báo của chúng tôi như sau:
(1) Người Học UI Không Ngừng, là một hệ thống vận hành phương pháp của chúng tôi để tự động học từ UI thông qua tương tác không ngừng.
(2) Ba ứng dụng thể hiện việc sử dụng Người Học UI Không Ngừng. Chúng tôi sử dụng bộ thu thập dữ liệu của mình để huấn luyện ba loại mô hình ngữ nghĩa UI khó học thông qua các phương pháp hiện có: i) khả năng chạm, ii) khả năng kéo, và iii) độ tương tự màn hình.

2 CÔNG TRÌNH LIÊN QUAN
Công trình của chúng tôi về học không ngừng các UI nhằm bổ sung các tập dữ liệu mô hình hóa UI được sử dụng để mô hình hóa UI và tương tác người dùng thông qua học liên tục. Để định vị công trình của chúng tôi, chúng tôi xem xét tài liệu liên quan trong i) tập dữ liệu mô hình hóa UI, ii) các mô hình tính toán về tương tác, và iii) các phương pháp học máy liên tục.

2.1 Tập Dữ Liệu Để Mô Hình Hóa Giao Diện Người Dùng
Một số tập dữ liệu đã được thu thập cho mục đích phân tích và mô hình hóa UI di động. Tập dữ liệu Rico là một tập dữ liệu lớn gồm 72.000 UI di động và siêu dữ liệu liên quan bao gồm phân cấp chế độ xem, ảnh chụp màn hình và tương tác người dùng, được thu thập từ 9.700 ứng dụng Android có sẵn công khai [10]. Tập dữ liệu FrontMatter sử dụng các kỹ thuật phân tích tĩnh để dự đoán mục đích của các phần tử UI bằng cách xác định API hệ thống nào được gọi [19]. Các tập dữ liệu lớn như này đã cho phép các phương pháp dựa trên ML có thể thực hiện các tác vụ khác nhau liên quan đến UI di động, bao gồm cung cấp chú thích trợ năng [24,49], đưa ra phản hồi thiết kế [17,38,42,52], đề xuất các luồng tương tác phổ biến [54], tóm tắt màn hình [46], tự động hóa tương tác với UI [1,23,39], và tạo ra các embedding phong phú của dữ liệu hình ảnh và văn bản UI cho các tác vụ hạ nguồn khác [2,15,22].

Hầu như tất cả các tập dữ liệu hiện có đều được tạo thủ công theo một khía cạnh nào đó - thông qua tương tác thủ công của người dùng với UI, và/hoặc chú thích của con người. Tập dữ liệu WebUI [48] đã sử dụng ảnh chụp màn hình và siêu dữ liệu được trích xuất tự động từ các trang web để huấn luyện các mô hình UI thị giác; tuy nhiên, dữ liệu web nói chung là nhiễu và các mô hình của họ cần tinh chỉnh bổ sung trên các tập dữ liệu được chú thích bởi con người nhỏ hơn để hoạt động tốt. Người Học UI Không Ngừng của chúng tôi tạo ra các chú thích thông qua việc thu thập dữ liệu tự động các ứng dụng di động. Những chú thích này liên tục cập nhật và làm mới các mô hình của bộ thu thập dữ liệu, cải thiện hiệu suất của nó, và dẫn đến một tập dữ liệu được cập nhật liên tục có thể được sử dụng để huấn luyện các mô hình khác. Một lợi thế quan trọng của phương pháp này là, không giống như việc sử dụng dữ liệu UI di động được thu thập trong một khoảng thời gian cụ thể, dữ liệu được tạo ra bởi bộ thu thập dữ liệu của chúng tôi luôn hiện tại, và có thể hỗ trợ cập nhật các mô hình để theo kịp các xu hướng thiết kế UI đang phát triển trong các ứng dụng di động.

2.2 Mô Hình Hóa Tính Toán Về Tương Tác
Một ứng dụng quan trọng của các tập dữ liệu UI được chú thích lớn là huấn luyện có giám sát các học máy dự đoán ngữ nghĩa UI. Ví dụ, trong bài báo này chúng tôi tập trung vào các vấn đề về khả năng chạm phần tử [38,42] và "fingerprinting" màn hình [11]. Gần đây hơn, Học Tăng Cường (RL) đã được áp dụng để mô hình hóa tương tác người dùng với cả giao diện vật lý và kỹ thuật số. Oulasvirta et al. đã đề xuất một khung tổng quát dựa trên RL về cách người dùng kết hợp các khả năng nhận thức, kinh nghiệm của họ và môi trường trong việc hiểu và tương tác với máy tính [35]. Trong bối cảnh này, một phần quan trọng của việc biết cách tương tác với một giao diện là bằng cách hiểu các affordance của nó. Affordance là các thuộc tính chức năng của một đối tượng (ví dụ, UI) gợi ý cách nó nên được sử dụng [34], và nhận xét của nhà thiết kế cho thấy các mẫu thiết kế có thể làm cho việc khám phá affordance trở nên khó khăn hơn. Liao et al. đã sử dụng một tác nhân robot ảo được trang bị cảm biến để mô phỏng và học cách con người có thể khám phá affordance trong các giao diện vật lý (ví dụ, nút và thanh trượt) [29]. Công trình của chúng tôi nhằm đạt được các mục tiêu tương tự của việc học các affordance (ví dụ, khả năng chạm) và khả năng của các giao diện. Mặc dù công trình của chúng tôi không trực tiếp mô hình hóa các tương tác của người dùng thông qua các kỹ thuật RL, chúng tôi nhằm đạt được các mục tiêu tương tự của việc học các affordance và khả năng của các giao diện thông qua tương tác và kiểm tra các ứng dụng di động trực tiếp. Bằng cách áp dụng học tương tác vào một bộ thu thập dữ liệu ứng dụng di động tự động, chúng tôi có thể mở rộng các thí nghiệm của mình lên một quy mô lớn hơn nhiều, học từ hàng triệu tương tác với UI.

2.3 Học Máy Liên Tục
Một khía cạnh độc đáo của công trình của chúng tôi là ý định liên tục học về UI theo thời gian thông qua tương tác duy trì, có thể vô tận. Công trình của chúng tôi liên quan đến học tích cực (cụ thể là học tích cực trực tuyến), đây là một lĩnh vực ML tìm cách cải thiện các mô hình chỉ sử dụng một số lượng hạn chế các ví dụ được gán nhãn bởi con người [12]. Những phương pháp này thường xác định và ưu tiên các ví dụ khó khăn hoặc đại diện để tạo ra mô hình tốt nhất có thể từ một tập dữ liệu nhỏ.

Công trình của chúng tôi liên quan nhất đến Học Không Ngừng, đây là một mô hình ML để tạo ra các hệ thống liên tục học từ kinh nghiệm có được thay vì một tập dữ liệu đơn lẻ. Nó được áp dụng lần đầu tiên cho kiến thức dựa trên web bằng cách sử dụng hệ thống NELL [31]. Hệ thống này đã chạy trong thời gian dài (nhiều năm) và đã tích lũy hơn 50 triệu niềm tin (tức là các đoạn kiến thức giả thuyết), điều này chỉ có thể xảy ra bằng cách xử lý lượng lớn dữ liệu quá tốn kém để chú thích. Phương pháp học này đưa ra những thách thức độc đáo, chẳng hạn như nhu cầu học từ dữ liệu mới trong khi vẫn giữ lại kiến thức đã có trước đó. Có một số kỹ thuật trong tài liệu có thể được áp dụng để giữ lại kiến thức trước đó liên quan đến i) regularization [18,28], ii) các phương pháp dựa trên rehearsal [37], và iii) các kỹ thuật giải quyết thiên vị gần đây của tác vụ [4]. Từ góc độ thực tế, việc triển khai cũng đòi hỏi duy trì các tập dữ liệu lớn ngày càng tăng được thu thập theo thời gian, có thể được giải quyết thông qua một cơ sở hạ tầng thu thập dữ liệu mạnh mẽ hoặc sử dụng các phương pháp chưng cất tập dữ liệu giữ lại các mẫu liên quan nhất [32,33,47]. Trong công trình này, chúng tôi áp dụng mô hình học không ngừng để mang lại lợi ích cho các hệ thống hiểu UI tự động bằng cách huấn luyện các mô hình "từ đầu" và tinh chỉnh các mô hình hiện có để cải thiện hiệu suất.

3 NGƯỜI HỌC UI KHÔNG NGỪNG
Để vận hành phương pháp của chúng tôi, chúng tôi đã xây dựng Người Học UI Không Ngừng, một hệ thống tự động tải xuống và thu thập dữ liệu các ứng dụng có sẵn công khai bằng cách sử dụng các thiết bị được vận hành từ xa. Việc triển khai và cơ sở hạ tầng hiện tại của chúng tôi dựa trên iOS. Chúng tôi sử dụng các thiết bị khôi phục cài đặt gốc được đăng nhập vào các tài khoản thử nghiệm không liên quan đến bất kỳ dữ liệu người dùng thực nào để tránh các mối lo ngại về quyền riêng tư.

Lưu ý rằng không giống như một số bộ thu thập dữ liệu tương tác với các ứng dụng bằng cách sử dụng giao diện lập trình do hệ điều hành cung cấp như API trợ năng, bộ thu thập dữ liệu của chúng tôi tương tác với thiết bị thông qua giao thức máy tính để bàn từ xa VNC, từ đó nó nhận các cập nhật thường xuyên cho màn hình và xử lý chúng một cách trực quan và có thể gửi các sự kiện đầu vào thô đến thiết bị để tạo ra các hành động chạm, vuốt và bàn phím. Sử dụng VNC, Người Học UI Không Ngừng có thể tương tác đáng tin cậy với nhiều ứng dụng hơn, học dựa trên các tiện ích tương tự mà con người sẽ có và tổng quát hóa sang các nền tảng khác. Trong phần này, chúng tôi mô tả kiến trúc và hành vi của bộ thu thập dữ liệu cho phép nó thực hiện học không ngừng.

3.1 Tổng Quan Kiến Trúc
Kiến trúc thu thập dữ liệu của chúng tôi được hiển thị trong Hình 1. Chúng tôi đã triển khai một kiến trúc thu thập dữ liệu phân tán bao gồm i) một máy chủ điều phối trung tâm và ii) một nhóm lớn các worker để song song hóa quá trình thu thập dữ liệu.

3.1.1 Máy Chủ Điều Phối. Máy chủ điều phối bộ thu thập dữ liệu duy trì một danh sách ID ứng dụng để thu thập dữ liệu được gửi đến các worker. Máy chủ trung tâm theo dõi các cuộc thu thập dữ liệu thành công và không thành công, và nó tự động thử lại các cuộc thu thập dữ liệu ứng dụng thất bại. Các bộ thu thập dữ liệu ứng dụng khác với các bộ thu thập dữ liệu web ở chỗ chúng chỉ tập trung vào ứng dụng mà chúng được yêu cầu thu thập dữ liệu, mặc dù tương tác chéo ứng dụng hạn chế đôi khi vẫn xảy ra (ví dụ, nhấp vào liên kết hoặc hộp thoại yêu cầu quyền). Khi tất cả ID ứng dụng đã hết, bộ thu thập dữ liệu của chúng tôi có thể lên lịch tự chạy lại sau một khoảng thời gian cố định (ví dụ, hàng tuần). Danh sách ID ứng dụng có thể được sửa đổi giữa các cuộc thu thập dữ liệu để thêm ứng dụng mới hoặc phản ánh thay đổi về tính khả dụng của ứng dụng. Trong khi phần lớn ID ứng dụng vẫn giữ nguyên, các ứng dụng có thể thay đổi giao diện và hành vi do nội dung được cập nhật động và các phiên bản mới của phần mềm. Việc thu thập dữ liệu lại các ứng dụng giống nhau thường xuyên có thể cho phép mô hình của chúng tôi thích ứng với các thay đổi thiết kế theo thời gian.

3.1.2 Worker Thu Thập Dữ Liệu. Các worker thu thập dữ liệu là các quy trình giao tiếp với các điện thoại di động được điều khiển từ xa và xử lý dữ liệu được thu thập. Mỗi worker thu thập dữ liệu tải xuống và cài đặt một ứng dụng đích có ID được cung cấp bởi máy chủ trung tâm lên điện thoại di động và sau đó chạy một chương trình thu thập dữ liệu ứng dụng. Ảnh chụp màn hình được thu thập trong quá trình tương tác và khi bộ thu thập dữ liệu tin rằng nó đã đến một màn hình mới. Chương trình có thể sử dụng ba phương pháp để khám phá ứng dụng (lựa chọn ngẫu nhiên hoặc dựa trên độ tin cậy của mô hình), và là một phần của bài báo này, chúng tôi chạy các thí nghiệm để xác định chiến lược thu thập dữ liệu tốt nhất cho mỗi trường hợp sử dụng học không ngừng của chúng tôi. Chúng tôi đặt giới hạn thời gian (5 phút) cho thời gian tối đa của việc thu thập dữ liệu cho một ứng dụng duy nhất. Sau đó, worker xử lý dữ liệu được thu thập (ví dụ, ảnh chụp màn hình và tương tác) với các mô hình và heuristic để tạo ra các nhãn từ các quan sát. Cả dữ liệu thô và đầu ra đã xử lý đều được tải lên máy chủ điều phối. Trong các thí nghiệm của chúng tôi, số lượng worker thu thập dữ liệu thay đổi do tính khả dụng từ nhóm thiết bị mà chúng tôi sử dụng, được chia sẻ với những người dùng khác. Nói chung, có khoảng 40-100 worker thu thập dữ liệu.

3.2 Các Thành Phần Học Máy
Bộ thu thập dữ liệu của chúng tôi chứa một mô hình cấp màn hình và cấp phần tử cho phép nó hiểu nội dung trên các UI mà nó gặp phải. Chúng tôi chạy các mô hình này mỗi khi ảnh chụp màn hình được chụp để bổ sung cho nó các ngữ nghĩa hữu ích. Hơn nữa, ba mô hình ngữ nghĩa UI mà chúng tôi huấn luyện bằng cách sử dụng bộ thu thập dữ liệu, được thiết kế như các phần mở rộng của các mô hình cơ sở này, cải thiện hiệu quả tổng thể.

3.2.1 Hiểu Màn Hình. Để theo dõi tiến trình thu thập dữ liệu của nó trong ứng dụng, bộ thu thập dữ liệu của chúng tôi sử dụng một mô hình để tạo ra các biểu diễn ngữ nghĩa của các màn hình. Chúng tôi đã sử dụng một mô hình được giới thiệu bởi công trình trước đây [11] dự đoán liệu hai ảnh chụp màn hình có thuộc về cùng một UI hay không bằng cách mã hóa mỗi ảnh như một vector embedding, mà các tác giả đã chia sẻ với chúng tôi. Bởi vì sự biến đổi đáng kể có thể được tạo ra bởi các thay đổi về trạng thái, chẳng hạn như một ứng dụng tin tức hiển thị nội dung mới định kỳ, mô hình được thiết kế để học cấu trúc cơ bản của UI. Chúng tôi đã thực hiện những sửa đổi nhỏ đối với công trình trước đây để phát triển một mô hình có thể chạy dưới các ràng buộc phần cứng của chúng tôi. Thay vì kiến trúc mô hình transformer màn hình được khuyến nghị của họ, chúng tôi sử dụng kiến trúc mô hình dựa trên CNN của họ, hiệu quả hơn để chạy mặc dù hiệu suất hơi thấp hơn [11]. Để tối ưu hóa thêm, chúng tôi sử dụng kiến trúc mô hình EfficientNet-B0 [43] làm backbone thay vì ResNet-18 gốc [14], có nhiều tham số hơn. Như trong bài báo gốc, đầu ra của lớp cuối cùng của mạng CNN được sử dụng làm embedding màn hình. Trong quá trình huấn luyện, chúng tôi đã áp dụng một phương pháp tăng cường dữ liệu [44] để tăng hiệu suất. Chúng tôi đã tuân theo tất cả các khía cạnh khác của việc huấn luyện mô hình gốc và mô hình dựa trên CNN cuối cùng của chúng tôi đạt được điểm F1 là 0,636.

3.2.2 Hiểu Phần Tử. Để tạo ra ngữ nghĩa phần tử, chúng tôi đã sử dụng một kiến trúc mô hình phát hiện đối tượng tương tự như CenterNet [55]. Ở mức độ cao, mô hình phát hiện trượt một cửa sổ (thông qua convolution) trên hình ảnh và đặc trưng hóa các vùng con hình ảnh bằng cách sử dụng một mạng backbone (MobileNet-v1 [16]), dẫn đến embedding cho mỗi vùng. Những embedding này được đưa vào một đầu phân loại tạo ra độ tin cậy cho mỗi lớp, và các vùng có độ tin cậy cao được trả về như các phát hiện. Mô hình được huấn luyện trên tập dữ liệu AMP [53], bao gồm 77.000 màn hình ứng dụng được thu thập và chú thích bởi các nhà chú thích từ 4.000 ứng dụng iPhone. Ngoài đầu phân loại loại phần tử tiêu chuẩn, được huấn luyện với phần còn lại của mô hình phát hiện đối tượng, chúng tôi đã thêm các đầu cho dự đoán khả năng chạm và dự đoán khả năng kéo. Các đầu bổ sung được huấn luyện độc lập với phần còn lại của mô hình bằng cách đầu tiên đông băng backbone và huấn luyện các đầu trên embedding tương ứng với các phần tử được phát hiện.

4 ÁP DỤNG HỌC KHÔNG NGỪNG
Trong phần này, chúng tôi mô tả việc áp dụng khung học không ngừng của chúng tôi cho ba mô hình ngữ nghĩa UI: i) dự đoán khả năng chạm (ngữ nghĩa phần tử), ii) dự đoán khả năng kéo (ngữ nghĩa container), và iii) độ tương tự màn hình (ngữ nghĩa màn hình). Các mô hình khả năng chạm và khả năng kéo được huấn luyện hoàn toàn từ dữ liệu do bộ thu thập dữ liệu tạo ra, trong khi bộ thu thập dữ liệu đã tinh chỉnh mô hình độ tương tự màn hình hiện có của nó ban đầu được huấn luyện bằng dữ liệu được chú thích bởi con người. Đối với mỗi ngữ nghĩa UI, chúng tôi đã phát triển một heuristic dựa trên tương tác được sử dụng bởi bộ thu thập dữ liệu của chúng tôi để tự động tạo ra các ví dụ huấn luyện mới cho các mô hình của chúng tôi. Tiếp theo, chúng tôi đã thiết kế và huấn luyện các mô hình để dự đoán từng ngữ nghĩa này từ một ảnh chụp màn hình. Cuối cùng, để bối cảnh hóa các mô hình này trong bối cảnh học không ngừng, chúng tôi đã phân tích hiệu suất của chúng theo thời gian.

Thiết Lập Thí Nghiệm. Chúng tôi đã tiến hành các thí nghiệm trên một danh sách 6.461 ứng dụng iOS miễn phí. Với mục đích đánh giá, tất cả việc huấn luyện mô hình và thí nghiệm đều được thực hiện với các phần chia huấn luyện (80%), xác thực (10%) và kiểm tra (10%) ngẫu nhiên. Chúng tôi đã phân vùng ngẫu nhiên danh sách ID ứng dụng của mình, điều này đảm bảo rằng tất cả các màn hình UI từ một ứng dụng đều được chứa trong cùng một phần chia. Chúng tôi sử dụng thuật ngữ epoch thu thập dữ liệu để chỉ một lần đi qua hoàn chỉnh danh sách các ứng dụng. Lưu ý rằng không giống như một epoch thông qua một tập dữ liệu huấn luyện, nội dung thực tế của một epoch thu thập dữ liệu có thể thay đổi theo thời gian, do tính chất động của các ứng dụng.

Các thí nghiệm của chúng tôi đã phân tích hai khía cạnh của hiệu suất bộ thu thập dữ liệu: i) chiến lược thu thập dữ liệu và ii) hiệu suất theo thời gian. Chúng tôi đã chạy ba biến thể của bộ thu thập dữ liệu, có các chiến lược thu thập dữ liệu khác nhau: i) lựa chọn ngẫu nhiên các phần tử trên mỗi màn hình (Ngẫu nhiên), ii) lựa chọn các phần tử dẫn đến độ tin cậy dự đoán thấp từ các mô hình hiện tại (Lấy Mẫu Không Chắc Chắn), và iii) một lai tạp cho mỗi epoch thu thập dữ liệu xen kẽ giữa các chiến lược Ngẫu nhiên và Lấy Mẫu Không Chắc Chắn, được truyền cảm hứng bởi các phương pháp tương tự trong tối ưu hóa [40]. Để đánh giá hiệu suất theo thời gian, chúng tôi đã chạy mỗi chiến lược thu thập dữ liệu trong năm epoch thu thập dữ liệu. Lưu ý rằng epoch thu thập dữ liệu đầu tiên cho tất cả các chiến lược sử dụng Ngẫu nhiên để huấn luyện một mô hình dự đoán độ tin cậy ban đầu. Trong chiến lược Lai, vì sự xen kẽ xảy ra ở cấp độ epoch, epoch thứ hai được thu thập dữ liệu bằng cách sử dụng chiến lược Lấy Mẫu Không Chắc Chắn và do đó thông qua hai epoch, đầu vào và kết quả giống hệt nhau cho cả chiến lược Lấy Mẫu Không Chắc Chắn và Lai. Ba chiến lược phân kỳ hoàn toàn bắt đầu từ epoch thứ ba. Trên tất cả các thí nghiệm, chúng tôi đã thu thập hơn nửa triệu ảnh chụp màn hình, mặc dù cùng một màn hình UI có thể đã được truy cập nhiều lần. Số lượng ảnh chụp màn hình trong tập dữ liệu của chúng tôi lớn hơn đáng kể so với công trình trước đây [3, 10, 19, 48].

Các mô hình của bộ thu thập dữ liệu được huấn luyện và đánh giá sau mỗi epoch thu thập dữ liệu. Sau mỗi epoch thu thập dữ liệu, việc huấn luyện mô hình được tiếp tục với dữ liệu cập nhật từ cuộc thu thập dữ liệu mới nhất và trọng số mô hình được tối ưu hóa trong 100.000 bước tối ưu hóa (với dừng sớm). Để duy trì một bộ xác thực không đổi qua một số epoch thay đổi, chúng tôi chỉ sử dụng phần chia dữ liệu đánh giá từ epoch đầu tiên để tính toán các số liệu hiệu suất. Cuối cùng, đối với các mô hình được huấn luyện hoàn toàn trên dữ liệu bộ thu thập dữ liệu (khả năng chạm và khả năng kéo), chúng tôi đã thực hiện các đánh giá phụ epoch bổ sung trong cuộc thu thập dữ liệu đầu tiên để phân tích tốc độ học.

Mặc dù tập dữ liệu không được phát hành tại thời điểm xuất bản do các quy định nội bộ, chúng tôi đang điều tra các quy trình để cung cấp nó cho cộng đồng rộng lớn hơn. Để nhân rộng công trình của chúng tôi, có thể sử dụng các công cụ và mô hình được xây dựng cho các nền tảng tương tự (ví dụ, Android). Các bộ thu thập dữ liệu mã nguồn mở [25,45] có thể được tích hợp với các mô hình độ tương tự màn hình [48] và phát hiện phần tử [3, 48, 51] có sẵn.

4.1 Khả Năng Chạm
Chạm là tương tác phổ biến nhất trên các thiết bị di động, tuy nhiên thường khó xác định tự động liệu một phần tử có thể chạm được hay không do thiếu siêu dữ liệu và các dấu hiệu thị giác mơ hồ. Ví dụ, một nút văn bản không có độ tương phản đủ hoặc thiếu đường viền có thể sẽ xuất hiện không thể chạm được đối với người dùng, và nhiều trò chơi thiếu các đặc điểm trợ năng ngăn cản người dùng đọc màn hình sử dụng chúng. Suy luận chính xác về khả năng chạm có thể hỗ trợ các nhà thiết kế tìm ra các phần tử thị giác mơ hồ và hữu ích để tạo ra siêu dữ liệu để sửa chữa các ứng dụng không thể tiếp cận. Công trình trước đây đã sử dụng các ảnh chụp màn hình UI được chú thích bởi con người để huấn luyện các mô hình học máy về khả năng chạm. Tuy nhiên, quá trình này đáng ngạc nhiên là dễ mắc lỗi [20,21,38,42] do các dấu hiệu thị giác mơ hồ, điều này cho thấy các ảnh chụp màn hình được chú thích bởi con người là một nguồn sự thật cơ bản không đáng tin cậy để huấn luyện các mô hình khả năng chạm. Ngược lại, bộ thu thập dữ liệu của chúng tôi có thể sử dụng bối cảnh bổ sung từ toàn bộ tương tác, chẳng hạn như ảnh chụp màn hình trước và sau thay vì một ảnh chụp màn hình trước duy nhất, để xác định liệu việc chạm có dẫn đến một hiệu ứng hay không. Các hiệu ứng có thể là thay đổi trạng thái, như lật một công tắc, hoặc chuyển đổi sang một màn hình mới. Chúng tôi đã phát triển một heuristic để suy luận khả năng chạm từ các tương tác được ghi lại của bộ thu thập dữ liệu và thấy rằng nó có sự đồng ý cao với các video được chú thích bởi con người. Chúng tôi đã sử dụng dữ liệu được gán nhãn heuristic để huấn luyện một mô hình "head" khả năng chạm hiệu quả hoàn toàn từ dữ liệu được chú thích bởi bộ thu thập dữ liệu. Sau năm epoch thu thập dữ liệu, mô hình khả năng chạm có hiệu suất tốt nhất đạt được điểm F1 là 0,860.

4.1.1 Heuristic Khả Năng Chạm. Chúng tôi đã phát triển một heuristic để suy luận khả năng chạm của một phần tử dựa trên ảnh chụp màn hình của UI được chụp trước, trong và sau một tương tác chạm. Một cú chạm có thể dẫn đến một số kịch bản khác nhau, được nắm bắt bởi heuristic của chúng tôi. Đầu tiên, chúng tôi sử dụng một mô hình độ tương tự màn hình để so sánh ảnh chụp màn hình được chụp trước và sau cú chạm để xác định liệu cú chạm có dẫn bộ thu thập dữ liệu đến một màn hình mới hay không. Nếu không phát hiện thay đổi màn hình, cú chạm cũng có thể đã thay đổi trạng thái màn hình. Chúng tôi tính toán sự khác biệt dựa trên pixel của ảnh chụp màn hình "trước" và "sau" để xác định các dấu hiệu thị giác có thể có của các thay đổi cục bộ hoặc toàn cục, chẳng hạn như chạm vào hộp kiểm hoặc làm mới nội dung màn hình tương ứng. Cuối cùng, để giảm các kết quả dương tính giả, heuristic cũng sử dụng nhiều ảnh chụp màn hình được chụp trước cú chạm để xác định các khu vực động của màn hình (ví dụ, video) có thay đổi thị giác không liên quan đến cú chạm.

Để xác thực độ chính xác của heuristic của chúng tôi, chúng tôi đã so sánh kết quả của nó với các video tương tác được gán nhãn bởi con người. Chúng tôi đã sử dụng bộ thu thập dữ liệu của mình để lưu các bản ghi màn hình ngắn về các tương tác chạm được thu thập trong quá trình thu thập dữ liệu. Mỗi video ví dụ dài khoảng 10 giây và bao gồm vị trí chạm được phủ lên trên video và bối cảnh thời gian trước và sau tương tác chạm, chẳng hạn như bao gồm hoạt ảnh chuyển đổi và tải.

Chúng tôi đã lấy mẫu ngẫu nhiên một tập con cân bằng gồm 1000 clip video từ các cuộc thu thập dữ liệu của chúng tôi và hỏi các nhà chú thích con người liệu mỗi clip video có chứa một tương tác chạm hay không. Các nhà chú thích được tuyển dụng, đào tạo và trả lương bởi một nhóm riêng biệt tại tổ chức của chúng tôi (tất cả đều có sự phê duyệt pháp lý/đạo đức thích hợp). Các nhà chú thích là nhân viên được trả lương cạnh tranh hàng giờ cho địa điểm của họ. Chúng tôi đã sử dụng các số liệu phân loại tiêu chuẩn để đánh giá độ chính xác của heuristic của chúng tôi, sử dụng các nhãn được chú thích bởi con người làm sự thật cơ bản. Heuristic khả năng chạm có độ chính xác tổng thể là 0,934, và có số lượng tương tự các kết quả dương tính giả (38 trường hợp) và âm tính giả (28 trường hợp).

4.1.2 Triển Khai Mô Hình. Để dự đoán khả năng chạm, chúng tôi đã thiết kế một kiến trúc mô hình hoạt động như một "head" của mô hình phát hiện phần tử hiện có của chúng tôi (Hình 3). Head là các mạng con nhỏ hoặc tập hợp các lớp thường nằm gần lớp đầu ra của kiến trúc mạng thần kinh và tạo ra dự đoán từ các biểu diễn đặc trưng của đầu vào chính được tạo ra bởi mạng "backbone". Vì phát hiện phần tử có liên quan chặt chẽ với khả năng chạm, chúng tôi đã giả thuyết rằng các biểu diễn đã học trước đó có khả năng chứa thông tin liên quan và tăng tốc đáng kể việc học khả năng chạm. Mô hình head của chúng tôi là một mô hình feed-forward ba lớp đơn giản với kích thước đầu vào là 128, kích thước ẩn là 64 mà chúng tôi đã chọn thông qua điều chỉnh thủ công, và kích thước đầu ra là 1 cho độ tin cậy khả năng chạm. Để huấn luyện nó, chúng tôi đầu tiên đã đông băng trọng số của mạng backbone của bộ phát hiện phần tử và khởi tạo ngẫu nhiên các tham số của mạng feed-forward của chúng tôi. Trong khi đông băng hầu hết mô hình làm giảm khả năng của nó, nó cũng dẫn đến việc giảm đáng kể thời gian huấn luyện, vì có ít tham số hơn để tối ưu hóa. Sau đó chúng tôi đã huấn luyện mô hình để dự đoán khả năng chạm của một phần tử từ ảnh chụp màn hình của UI trước cú chạm, và chúng tôi đã sử dụng các nhãn được tạo ra bởi heuristic khả năng chạm của chúng tôi làm sự thật cơ bản.

4.1.3 Đánh Giá Hiệu Suất. Kết quả của các thí nghiệm của chúng tôi được hiển thị trong Hình 4. Trong khi tất cả các chiến lược thu thập dữ liệu đều thành công trong việc cải thiện mô hình ban đầu từ epoch đầu tiên, bộ thu thập dữ liệu Ngẫu nhiên có hiệu suất cuối cùng tốt nhất. Trong các thí nghiệm của chúng tôi, bộ thu thập dữ liệu Ngẫu nhiên đạt được điểm F1 cuối cùng tốt nhất là 0,860 trong khi bộ thu thập dữ liệu Lấy Mẫu Không Chắc Chắn đạt được điểm F1 cuối cùng thấp nhất là 0,853. Mặc dù không thể thực hiện so sánh trực tiếp với công trình trước đây [38,42] vì các thí nghiệm của họ được chạy trên các tập dữ liệu khác nhau, có vẻ như mô hình khả năng chạm của chúng tôi có thể đạt được mức hiệu suất tương tự về điểm F1 sau epoch đầu tiên của nó.

Chúng tôi cũng đã tiến hành so sánh giữa chất lượng của tập dữ liệu khả năng chạm được thu thập tự động của chúng tôi và các tập dữ liệu được chú thích bởi con người, chúng tôi đã sử dụng các nhãn được cung cấp bởi tập dữ liệu AMP [53]. Đầu tiên, chúng tôi đã huấn luyện kiến trúc mô hình head phân loại của chúng tôi trên AMP, điều này dẫn đến hiệu suất tương tự (F1=0,81) với các con số được báo cáo ban đầu (cũng F1=0,81), đã sử dụng kiến trúc mô hình dựa trên cây. Tuy nhiên, khi chúng tôi sử dụng mô hình được huấn luyện trên dữ liệu được chú thích bởi con người để dự đoán khả năng chạm của các phần tử trong tập dữ liệu thu thập của chúng tôi, chúng tôi đã quan sát thấy hiệu suất giảm đáng kể (F1=0,60), cho thấy rằng các nhãn được chú thích bởi con người và được tạo ra bởi bộ thu thập dữ liệu không đồng ý với nhau. Chúng tôi coi dữ liệu được chú thích heuristic có chất lượng cao hơn vì hiệu suất của nó đã được xác thực bởi các nhà chú thích có quyền truy cập vào clip video của toàn bộ tương tác chạm, và công trình trước đây [38] đã cho thấy việc dự đoán khả năng chạm phần tử từ một ảnh chụp màn hình đơn dẫn đến phương sai cao giữa các người đánh giá.

4.2 Khả Năng Kéo
Kéo là một tương tác phổ biến trong các ứng dụng di động liên quan đến việc chạm vào một phần tử trên màn hình bằng ngón tay của một người và di chuyển ngón tay dọc theo bề mặt màn hình trước khi cuối cùng thả ra. Tương tác này được sử dụng để thao tác các điều khiển, chẳng hạn như thanh trượt và điều khiển trang, và cần thiết để truy cập nội dung ngoài màn hình thông qua cuộn. Mặc dù những ví dụ này phản ánh các loại đầu vào khác nhau, chúng tôi gọi chung tất cả những hành động này là "khả năng kéo," vì chúng liên quan đến chuyển động vật lý tương tự. Không giống như các phần tử có thể chạm, các phần tử có thể kéo thường có ít dấu hiệu thị giác hơn và khó phát hiện tự động hơn. Theo hiểu biết của chúng tôi, không có tập dữ liệu nào có sẵn với các nhãn khả năng kéo, và chúng tôi tin rằng, tương tự như khả năng chạm, sẽ khó khăn cho các nhà gán nhãn con người để xác định đáng tin cậy các phần tử có thể kéo từ ảnh chụp màn hình. Để cải thiện hỗ trợ đọc màn hình cho các ứng dụng không thể tiếp cận với những affordance này, chúng tôi đã sử dụng bộ thu thập dữ liệu của mình để tự động tìm và gán nhãn các ví dụ thông qua tương tác tự động. Chúng tôi đã phát triển một heuristic để suy luận khả năng kéo từ ảnh chụp màn hình của các tương tác kéo. Sử dụng dữ liệu được gán nhãn bằng phương pháp này, chúng tôi đã huấn luyện một mô hình khả năng kéo đạt được điểm F1 là 0,794 sau năm epoch thu thập dữ liệu.

4.2.1 Heuristic Khả Năng Kéo. Để phát hiện liệu một phần tử UI có thể kéo được hay không, bộ thu thập dữ liệu của chúng tôi chụp ảnh màn hình trong khi cố gắng giữ và kéo các phần tử. Bộ thu thập dữ liệu của chúng tôi đầu tiên xác định các ứng viên có khả năng, sau đó mô phỏng các hành động kéo sang trái (ví dụ, ngón tay đi sang trái) và lên trên để phát hiện kéo theo chiều ngang và chiều dọc tương ứng. Những hướng này được chọn vì chúng tương ứng với vị trí ban đầu của danh sách trong hướng đọc từ trái sang phải, và chúng tôi thực hiện các hành động kéo từ trung tâm của phần tử đến biên trái hoặc biên trên của nó. Bộ thu thập dữ liệu chụp một ảnh chụp màn hình trước khi kéo bắt đầu và một ảnh chụp màn hình ở cuối cú kéo nhưng trước khi "ngón tay" của nó rời khỏi màn hình.

Ý tưởng cấp cao của heuristic là phát hiện phần tử UI nào, nếu có, "theo ngón tay" theo hướng kéo. Chúng tôi đầu tiên sử dụng phần tử UI nhỏ nhất chứa pixel được kéo trên hình ảnh trước khi kéo để tạo ra một patch hình ảnh. Patch hình ảnh này được so khớp mẫu với hình ảnh sau khi kéo bằng cách sử dụng phương pháp hệ số tương quan chuẩn hóa trên hình ảnh grayscale và phát hiện cạnh. Vector tương ứng với độ dịch chuyển mẫu được lọc bởi góc cosine và độ lớn. Tiếp theo, các patch bên trong các hộp giới hạn giữa màn hình trước khi kéo và sau khi kéo được so sánh để xác định liệu có các phần tử khác đã cuộn trong quá trình hành động kéo hay không. Nếu nội dung của một hộp giới hạn trong hình ảnh trước khi kéo khớp với nội dung của một hộp giới hạn được dịch chuyển bởi vector dịch chuyển mẫu trong hình ảnh sau khi kéo, thì có khả năng là một phần tử UI đã được cuộn cùng với phần tử UI ban đầu. Chúng tôi sử dụng phương pháp hệ số tương quan chuẩn hóa để đo lường độ tương tự giữa những patch hình ảnh này, trên hình ảnh grayscale và phát hiện cạnh. Nếu không có phần tử cuộn nào được xác định, phần tử UI ban đầu cũng được đánh dấu là không thể kéo để lọc ra các kết quả dương tính giả.

Chúng tôi đã tiến hành đánh giá heuristic của chúng tôi trên 1000 mẫu, được tạo ra bằng cách chạy heuristic trên các màn hình được thu thập từ một cuộc thu thập dữ liệu ngẫu nhiên, sau đó chọn 500 màn hình nơi heuristic được kích hoạt và 500 màn hình nơi nó không được kích hoạt. Do một lỗi, bộ thu thập dữ liệu của chúng tôi không ghi lại video tương tác của tương tác khả năng kéo, tuy nhiên chúng tôi thấy rằng việc suy luận khả năng kéo từ ảnh chụp màn hình trước/sau được chụp là đơn giản. Đối với mỗi bước tương tác, chúng tôi đã trình bày cho nhà chú thích ba hình ảnh, hình ảnh trước khi kéo, hình ảnh sau khi kéo, và một hình ảnh kết hợp với cả hình ảnh trước và sau được chồng chất, điều này cho phép dễ dàng hình dung chuyển động hơn. Các hình ảnh được chú thích với một mũi tên chỉ ra nơi kéo xảy ra. Một lần nữa, chúng tôi đã sử dụng các nhãn do con người cung cấp làm sự thật cơ bản để đánh giá dự đoán của heuristic của chúng tôi. Heuristic khả năng kéo có độ chính xác tổng thể là 0,92, và số lượng tương tự các kết quả dương tính giả (38 trường hợp) và âm tính giả (48 trường hợp).

4.2.2 Triển Khai Mô Hình. Không giống như khả năng chạm, đây là một ngữ nghĩa phần tử, khả năng kéo thường được liên kết với các container chứa nhiều phần tử. Chúng tôi ban đầu đã thử sử dụng cùng kiến trúc mô hình "head" như mô hình khả năng chạm của chúng tôi, tái sử dụng các tính năng phần tử được tạo ra bởi mô hình phát hiện của chúng tôi, tuy nhiên chúng tôi thấy rằng mô hình này đạt được hiệu suất thấp (điểm F1=0,2). Khi kiểm tra kỹ hơn các ví dụ bị phân loại sai, chúng tôi nhận thấy rằng các dấu hiệu thị giác cho khả năng kéo của một phần tử thường không cục bộ (tức là xảy ra ở nơi khác trên màn hình). Ví dụ, một bức ảnh có nhiều khả năng hỗ trợ vuốt nếu chỉ báo điều khiển trang được đặt bên dưới nó, và khả năng cuộn trong các ứng dụng di động thường được suy luận tốt nhất bằng cách tìm kiếm các phần tử bị che khuất một phần ở cuối danh sách hoặc gần các cạnh của màn hình. Bởi vì bộ phát hiện phần tử đặc trưng hóa các vùng hình ảnh bằng cách tập hợp thông tin thị giác gần đó, nó bỏ qua nhiều dấu hiệu liên quan cho tác vụ này.

Dựa trên những quan sát này, chúng tôi đã thiết kế một mô hình dựa trên kiến trúc transformer, cho phép nó kết hợp thông tin từ toàn bộ màn hình vào dự đoán của nó. Chúng tôi đầu tiên đã sử dụng bộ phát hiện phần tử của chúng tôi để đặc trưng hóa tất cả các phần tử được phát hiện trên màn hình. Sau đó, các embedding phần tử được đưa vào các lớp self-attention để tạo ra một embedding được bối cảnh hóa. Cuối cùng, các embedding được bối cảnh hóa của các phần tử được đưa vào một bộ phân loại tuyến tính với một nút đầu ra duy nhất để phân loại khả năng kéo. Trong khi huấn luyện mô hình khả năng kéo, trọng số của bộ phát hiện phần tử cũng được đông băng để cải thiện hiệu quả huấn luyện. Đối với các màn hình nơi heuristic khả năng kéo không được kích hoạt, loss chỉ được tính toán cho phần tử được tương tác trực tiếp. Đối với các màn hình nơi heuristic khả năng kéo được kích hoạt, loss được tính toán trên tất cả các phần tử bị ảnh hưởng bởi cú kéo. Trong cả hai trường hợp, các phần tử không di chuyển cùng với ngón tay bị bỏ qua trong tính toán loss, vì không thể biết chắc chắn liệu chúng không thể kéo được mà không tương tác với chúng.

4.2.3 Đánh Giá Hiệu Suất. Đánh giá của chúng tôi về mô hình khả năng kéo tập trung vào hiệu suất theo thời gian (Xem Hình 7).

Kết quả của các thí nghiệm của chúng tôi được hiển thị trong Hình 7. Bộ thu thập dữ liệu Lai có hiệu suất cuối cùng cao nhất (F1=0,794), trong khi bộ thu thập dữ liệu Lấy Mẫu Không Chắc Chắn thấp nhất (F1=0,770). Thú vị là, cả việc thu thập dữ liệu Lấy Mẫu Không Chắc Chắn và Lai đều trải qua sự giảm hiệu suất trong epoch thu thập dữ liệu thứ hai. Trong khi bộ thu thập dữ liệu Lấy Mẫu Không Chắc Chắn tiếp tục giảm, bộ thu thập dữ liệu Lai xen kẽ sang chiến lược thu thập dữ liệu ngẫu nhiên của nó và bắt đầu cải thiện nhanh chóng. Chúng tôi giả thuyết rằng việc lấy mẫu không chắc chắn trong epoch thứ hai có thể đã làm mất cân bằng tập dữ liệu bằng cách thu thập nhiều ví dụ của các phần tử tương tự trong khi bỏ qua những cái khác, và do đó tác động tiêu cực đến mô hình tiếp theo.

Từ kết quả thí nghiệm của chúng tôi và các quan sát giai thoại, chúng tôi giả thuyết rằng khả năng kéo khó suy luận hơn từ thông tin thị giác tĩnh một mình do thiếu các dấu hiệu cục bộ, và cách tốt nhất để khám phá chức năng liên quan đến kéo có thể là học từ việc sử dụng mở rộng. Trong một số trường hợp, có thể phù hợp để trực tiếp áp dụng heuristic khả năng kéo tại thời điểm chạy. Trái ngược với chạm, có khả năng thay đổi trạng thái của UI hoặc đưa người dùng đến một trang mới, chúng tôi giả thuyết rằng nhiều tương tác kéo ít có khả năng dẫn đến tác dụng phụ. Mô hình của chúng tôi có thể được sử dụng để đầu tiên xác định các ứng viên có khả năng cho xác minh dựa trên tương tác.

Tương tự như mô hình khả năng chạm, chúng tôi cũng quan sát thấy mức tăng nhỏ về hiệu suất theo thời gian; tuy nhiên, có ít cải thiện tổng thể hơn đối với hiệu suất khả năng kéo. Một lý do có thể là vì khả năng kéo khó suy luận hơn về mặt thị giác, mô hình đã đạt đến trần sớm hơn.

4.3 Độ Tương Tự Màn Hình
Chúng tôi đã sử dụng bộ thu thập dữ liệu của mình để cải thiện khả năng hiểu màn hình của nó bằng cách sử dụng các tương tác của nó để xác thực và huấn luyện lại mô hình độ tương tự màn hình. Một mô hình độ tương tự màn hình chính xác hơn cho phép bộ thu thập dữ liệu của chúng tôi xác định đáng tin cậy hơn những màn hình ứng dụng nào mà nó đã truy cập trong một ứng dụng, và do đó tăng hiệu quả khám phá của nó. Các mô hình độ tương tự màn hình cũng đã được sử dụng trong các loại ứng dụng kỹ thuật phần mềm khác, chẳng hạn như xử lý video sử dụng ứng dụng di động [9], thử nghiệm phần mềm tự động [26,27], và tạo storyboard tự động [7]. Feiz et al. lưu ý rằng do kỹ thuật gán nhãn của họ, tập dữ liệu của họ chứa nhiều ví dụ về cặp màn hình mới hơn so với cặp màn hình giống nhau. Chúng tôi đã khai thác các ví dụ bổ sung về cặp màn hình giống nhau từ các tương tác được ghi lại của bộ thu thập dữ liệu của chúng tôi để bổ sung dữ liệu huấn luyện ban đầu và tinh chỉnh mô hình ban đầu bằng cách giảm tỷ lệ học một hệ số 10. So với điều kiện cơ sở nơi mô hình độ tương tự màn hình được huấn luyện bằng cách sử dụng tập dữ liệu chưa được sửa đổi (với cùng tỷ lệ học giảm), chúng tôi thấy rằng tập dữ liệu được bổ sung dẫn đến hiệu suất tốt hơn một cách nhất quán.

4.3.1 Tạo Dữ Liệu. Chúng tôi không giới thiệu một heuristic dựa trên tương tác mới để thu thập nhãn cho độ tương tự màn hình. Thay vào đó, chúng tôi tái sử dụng dữ liệu được chụp từ các heuristic khả năng chạm và khả năng kéo. Cả hai heuristic đều chụp hai ảnh chụp màn hình trước khi bắt đầu một tương tác để xác định các vùng hoạt ảnh hoặc động của màn hình có thể gây ra kết quả dương tính giả cho việc phát hiện khả năng chạm và khả năng kéo. Tuy nhiên, những ví dụ tương tự này cũng có thể được sử dụng để tìm các ví dụ về dự đoán âm tính giả từ bộ phân loại độ tương tự màn hình của chúng tôi. Chúng tôi giả định rằng các ảnh chụp màn hình trước tương tác thuộc về cùng một màn hình, vì bất kỳ sự thay đổi thị giác nào giữa chúng không được gây ra bởi đầu vào của người dùng. Chúng tôi đưa ra giả định tương tự về dữ liệu được thu thập từ heuristic khả năng kéo, vì ảnh chụp màn hình cuối cùng được chụp trước khi cử chỉ kéo được hoàn thành (tức là trước khi ngón tay được thả khỏi màn hình) và không có khả năng dẫn đến một màn hình mới. Chúng tôi sử dụng những nguồn này để tạo ra một tập dữ liệu các cặp ảnh chụp màn hình của các cặp màn hình giống nhau, và chúng tôi đã chạy mô hình độ tương tự màn hình hiện có của chúng tôi để tìm kiếm các dự đoán không chính xác, có thể được sử dụng để huấn luyện lại mô hình. Dựa trên quy trình này, chúng tôi đã khai thác khoảng 2000 ví dụ mới từ mỗi epoch.

4.3.2 Triển Khai Mô Hình. Mô hình độ tương tự màn hình ban đầu được huấn luyện trên một tập dữ liệu chứa cả ví dụ về cặp tích cực (cùng màn hình) và tiêu cực (khác màn hình), điều này có thể tối ưu hóa bằng cách sử dụng loss biên tương phản [13].

Ở mức độ cao, mô hình ánh xạ ảnh chụp màn hình vào một không gian embedding, và loss đảm bảo rằng các màn hình tương tự gần nhau (tức là có khoảng cách nhỏ hơn giá trị biên) trong khi các màn hình khác nhau xa hơn.

L_sim = (||Δh||² nếu s₁ = s₂, max(0, m - ||Δh||²) ngược lại) (1)

Để tinh chỉnh mô hình, chúng tôi sử dụng cùng mục tiêu huấn luyện nhưng giảm tỷ lệ học xuống lr=1e-5, thấp hơn mười lần so với giá trị ban đầu được sử dụng để huấn luyện mô hình. Chúng tôi ban đầu đã thử sử dụng các cặp màn hình giống nhau được khai thác mới để tinh chỉnh mô hình mà không trộn nó với tập dữ liệu ban đầu. Tuy nhiên, điều này không thành công, vì chỉ tập trung vào thuật ngữ "tương tự" (s₁ = s₂) dẫn đến trường hợp thất bại nơi mô hình học ánh xạ tất cả ảnh chụp màn hình đến cùng một điểm trong không gian embedding, vì nó chỉ bị phạt nếu các màn hình tương tự xa nhau nhưng không nếu các màn hình không tương tự gần nhau. Do đó, chúng tôi trực tiếp "trộn" các ví dụ được khai thác mới với phần còn lại của tập dữ liệu ban đầu, bao gồm 800.000 cặp được gán nhãn.

4.3.3 Đánh Giá Hiệu Suất. Chúng tôi đã đo lường hiệu suất so với phần chia đánh giá của tập dữ liệu ban đầu vì dữ liệu được tạo ra của chúng tôi chỉ chứa các cặp màn hình giống nhau, điều này làm cho không thể tính toán độ chính xác. Kết quả được hiển thị trong Hình 9. Bởi vì mô hình độ tương tự màn hình không ảnh hưởng đến các hành động được chọn của bộ thu thập dữ liệu (ví dụ, cố gắng chạm và kéo), chúng tôi chỉ đánh giá phương pháp của chúng tôi trên dữ liệu từ cuộc thu thập dữ liệu Ngẫu nhiên. Nhìn chung, chúng tôi thấy rằng việc sử dụng tập dữ liệu do bộ thu thập dữ liệu tạo ra để tinh chỉnh mô hình dẫn đến những cải thiện nhỏ nhưng nhất quán về hiệu suất theo thời gian. Mô hình độ tương tự màn hình đã cải thiện từ điểm F1 ban đầu là 0,636 lên điểm F1 cuối cùng là 0,663. Mặc dù được huấn luyện trên tập dữ liệu ban đầu, mô hình cơ sở cũng cải thiện do tỷ lệ học giảm. Một thực hành phổ biến trong huấn luyện mạng thần kinh là giảm tỷ lệ học sau khi hiệu suất đạt đến ngưỡng, điều này có thể cho phép mô hình tiếp tục cải thiện. Mô hình cơ sở đã cải thiện mô hình ban đầu đến điểm F1 cuối cùng là 0,659.

Nếu bộ thu thập dữ liệu chạy vô thời hạn, nó sẽ cần một số cơ chế để bỏ qua một tập con của dữ liệu được thu thập để tránh mất cân bằng dữ liệu cuối cùng do việc thu thập chỉ các cặp màn hình giống nhau. Một số kỹ thuật có thể tồn tại để hợp nhất và chưng cất tập dữ liệu để giữ lại các mẫu thông tin nhất [32,33,47]. Mặc dù chúng tôi tin rằng những phương pháp này có thể áp dụng được, chúng tôi để khía cạnh xác thực này cho công việc tương lai.

5 THẢO LUẬN
Các thí nghiệm của chúng tôi đã tiết lộ rằng các mô hình UI thị giác có thể được huấn luyện và cải thiện hiệu quả thông qua tương tác tự động, liên tục. Trong phần này, chúng tôi thảo luận về i) hiệu suất của việc triển khai Người Học UI Không Ngừng cụ thể của chúng tôi, ii) các loại học dựa trên tương tác khác, và iii) lợi ích của việc áp dụng những chiến lược này trong thời gian rất dài hoặc có thể vô thời hạn

5.1 Hiệu Suất Người Học UI Không Ngừng
Trong bài báo này, chúng tôi đã tiến hành một loạt thí nghiệm đánh giá Người Học UI Không Ngừng và khả năng tự động học ngữ nghĩa UI của nó. Các thí nghiệm của chúng tôi điều tra hai câu hỏi chính: i) cách tốt nhất để một bộ thu thập dữ liệu tự động học về UI là gì? và ii) nó cần chạy trong bao lâu?

Chiến Lược Thu Thập Dữ Liệu. Các thí nghiệm của chúng tôi tập trung vào ba chiến lược thu thập dữ liệu để khám phá các ứng dụng di động: i) thu thập dữ liệu ngẫu nhiên, ii) lấy mẫu không chắc chắn, và iii) một chiến lược lai. Nhìn chung, chiến lược ngẫu nhiên liên tục dẫn đến hiệu suất mạnh mẽ trong tất cả các thí nghiệm của chúng tôi. Chúng tôi ban đầu giả thuyết rằng lấy mẫu không chắc chắn, một kỹ thuật học tích cực cải thiện hiệu quả lấy mẫu bằng cách ưu tiên các ví dụ có độ tin cậy mô hình thấp, sẽ để mô hình học hiệu quả và hiệu quả hơn. Tuy nhiên, bởi vì bộ thu thập dữ liệu của chúng tôi cập nhật các mô hình của nó (được sử dụng để tính toán độ tin cậy dự đoán) mỗi epoch thay vì sau mỗi mẫu (như thường được thực hiện trong các ứng dụng nơi lấy mẫu không chắc chắn được sử dụng), nó dẫn đến việc thu thập dữ liệu mất cân bằng trong các cuộc thu thập dữ liệu tiếp theo, điều này làm giảm hiệu suất. Bộ thu thập dữ liệu lai xen kẽ giữa các chiến lược lấy mẫu ngẫu nhiên và không chắc chắn, điều này cho phép nó học từ các dự đoán có độ tin cậy thấp đồng thời cũng sửa chữa sự dịch chuyển phân phối được gây ra bởi lấy mẫu không chắc chắn theo lô. Nhìn chung, nó dẫn đến hiệu suất tương tự như thu thập dữ liệu ngẫu nhiên thuần túy, mặc dù ít nhất quán hơn. Trong tác vụ khả năng kéo, nó ban đầu làm giảm hiệu suất nhưng trải qua cải thiện nhanh chóng sau đó. Cuối cùng, các thí nghiệm của chúng tôi không tiết lộ một lựa chọn rõ ràng, và chúng tôi tin rằng có chỗ để khám phá các chiến lược bổ sung [12] và đánh giá dài hạn, mà chúng tôi để cho công việc tương lai.

Hiệu Suất Theo Thời Gian. Mặc dù bộ thu thập dữ liệu của chúng tôi được thiết kế để chạy vô thời hạn, các thí nghiệm của chúng tôi tập trung vào một khoảng thời gian tương đối ngắn là năm epoch thu thập dữ liệu. Mỗi epoch thu thập dữ liệu kéo dài khoảng nửa tuần (thời gian đồng hồ) khi được song song hóa trên nhiều worker thu thập dữ liệu và bao gồm khoảng 500 giờ thiết bị tương tác ứng dụng, xử lý dữ liệu hậu kỳ và huấn luyện mô hình. Trên tất cả các thí nghiệm, Người Học UI Không Ngừng đã thu thập dữ liệu trong hơn 5.000 giờ thiết bị, được thực hiện trong khoảng thời gian khoảng một tháng.

Kết quả của chúng tôi cho thấy rằng cửa sổ này đủ để học các mô hình chính xác hoàn toàn từ dữ liệu do bộ thu thập dữ liệu thu thập (khả năng chạm và khả năng kéo) hoặc tinh chỉnh các mô hình hiện có (độ tương tự màn hình). Nhìn chung, chúng tôi thấy rằng các mô hình có học sớm nhanh chóng theo sau là cải thiện chậm hơn, điều này phù hợp với các quan sát thực nghiệm trong nghiên cứu học máy cho thấy mối quan hệ exponential giữa kích thước tập dữ liệu và hiệu suất mô hình [41]. Chúng tôi tin rằng những cải thiện nhỏ này có giá trị, vì lợi ích của chúng có thể được phóng đại khi chạy trong thời gian có thể rất dài và cho phép mô hình được cập nhật liên tục. Chúng tôi dự định tiếp tục chạy bộ thu thập dữ liệu, không yêu cầu giám sát của con người, để quan sát xu hướng trong thời gian dài hơn và tối đa hóa tiềm năng của phương pháp học tự động của chúng tôi.

Quan Sát Giai Thoại. Dựa trên thí nghiệm của chúng tôi, chúng tôi thấy một số khía cạnh ảnh hưởng đến hiệu suất của các hệ thống học không ngừng như của chúng tôi. Chúng tôi đưa ra các quan sát giai thoại có thể hữu ích cho việc nhân rộng hoặc triển khai các hệ thống tương tự.

• Chọn ví dụ. Trong bài báo này, chúng tôi chủ yếu khám phá hai phương pháp (ngẫu nhiên và dựa trên không chắc chắn) để chọn ví dụ huấn luyện. Chúng tôi thấy rằng lựa chọn ngẫu nhiên là một cơ sở mạnh mẽ, và các phương pháp học tích cực (ví dụ, lấy mẫu không chắc chắn) có thể hiệu quả với các siêu tham số thích hợp. Có nhiều điều để khám phá dọc theo khía cạnh này, bao gồm việc sử dụng lịch sử bộ thu thập dữ liệu để giảm sự dư thừa mẫu, mà chúng tôi đã quan sát trong dữ liệu thu thập của chúng tôi.

• Tần suất huấn luyện lại. Tần suất thu thập dữ liệu lại và huấn luyện lại có thể ảnh hưởng đến hiệu suất của hệ thống thay đổi thành phần của dữ liệu huấn luyện. Các thí nghiệm trong bài báo này được chạy trong khoảng thời gian khoảng một tháng với một lần lặp cập nhật mỗi 1-2 ngày, vì vậy các thay đổi ứng dụng mà chúng tôi chứng kiến chủ yếu là do thay đổi nội dung động. Chúng tôi tin rằng các cập nhật ít thường xuyên hơn có thể hiệu quả (ví dụ, hàng tháng) có thể nắm bắt các thay đổi cơ bản hơn như cập nhật ứng dụng hoặc hướng dẫn thiết kế mới hơn.

• Dữ liệu đánh giá. Chúng tôi đã sử dụng một phần chia đánh giá cố định để so sánh trực tiếp hiệu suất mô hình theo thời gian. Sử dụng dữ liệu từ cuộc thu thập dữ liệu mới nhất có thể cho phép ước tính chính xác hơn về hiệu suất thế giới thực; tuy nhiên, việc so sánh các mô hình qua các epoch ít đơn giản hơn, vì các thay đổi có thể được gây ra bởi hiệu suất mô hình hoặc thay đổi đối với dữ liệu xác thực. Cuối cùng, việc sử dụng một bộ xác thực có kích thước động có thể hữu ích nếu các mô hình được triển khai trong các tình huống mà hiệu suất trên cả ứng dụng cũ và mới đều quan trọng.

5.2 Học Từ Tương Tác
Công trình của chúng tôi đóng góp ý tưởng rằng các tương tác tự động có thể được sử dụng để tạo ra các tập dữ liệu cho sự hiểu biết UI dựa trên mô hình. Hầu hết các tập dữ liệu hiện có sử dụng các nhà chú thích con người và công nhân đám đông để tạo ra các nhãn cho các tập dữ liệu UI di động, chẳng hạn như hộp giới hạn phần tử UI, loại biểu tượng và ghép cặp độ tương tự màn hình. Mặc dù việc gán nhãn bằng con người đã là một tiêu chuẩn de facto để tạo ra các tập dữ liệu, đặc biệt là cho các lĩnh vực mà yêu cầu khối lượng dữ liệu cho học tự giám sát không khả thi, các chú thích do công nhân đám đông tạo ra được biết là dễ bị lỗi và thiên vị [8,36]. Hơn nữa, nhiều tác vụ mã hóa ngầm một mức độ chủ quan. Một ví dụ như vậy là dự đoán khả năng chạm, nơi các nhà chú thích sử dụng phán đoán của riêng họ để quyết định liệu một phần tử UI cụ thể trong ảnh chụp màn hình có thể chạm được hay không. Các nhãn cho những tác vụ như vậy được biết là nhiễu trong thực tế, và thường được tính trung bình hoặc bỏ phiếu từ nhiều công nhân đám đông, làm tăng thêm thời gian và chi phí của các nhãn do con người tạo ra [38]. Ngược lại, học dựa trên tương tác tự động có thể giảm thiểu đáng kể thiên vị của nhà chú thích, vì các nhãn được tạo ra thông qua kiểm tra giả thuyết. Tuy nhiên, có thể có những trường hợp mà việc mã hóa thông tin nhận thức vào các nhãn có thể hữu ích, chẳng hạn như đưa ra phản hồi cho các nhà thiết kế về khả năng chạm được nhận thức. Trong những trường hợp khác, chẳng hạn như tạo ra thông tin trợ năng, các nhãn phù hợp hơn với sự thật cơ bản có thể được ưa thích. Hiểu các sự đánh đổi giữa những phương pháp này và tác động của chúng đến sự sắp xếp mô hình là một cơ hội cho công việc tương lai.

Trong công trình của chúng tôi, chúng tôi đã chỉ ra rằng học dựa trên tương tác có thể được sử dụng để mô hình hóa ngữ nghĩa phần tử (khả năng chạm), container (khả năng kéo), và cấp màn hình (độ tương tự màn hình) trong UI di động. Đối với các ứng dụng được kiểm tra của chúng tôi, chúng tôi thấy rằng các heuristic hoạt động với kiến thức về toàn bộ tương tác làm cho việc tạo nhãn tương đối đơn giản. Tuy nhiên, các heuristic có độ chính xác cao không phải lúc nào cũng dẫn đến các mô hình có độ chính xác cao vì mô hình phải đưa ra cùng một dự đoán với quyền truy cập vào ít dữ liệu hơn (tức là chỉ thông tin thị giác từ ảnh chụp màn hình tĩnh). Một số loại ngữ nghĩa dễ dàng hơn cho mô hình hóa thị giác hơn những cái khác. Mô hình khả năng chạm của chúng tôi đạt được hiệu suất phân loại cao, với điểm F1 là 0,860. Mặt khác, khả năng kéo khó dự đoán hơn nhiều từ ảnh chụp màn hình (F1=0,797).

Một câu hỏi tự nhiên để khám phá là: những loại ngữ nghĩa nào khác có thể được học thông qua tương tác? Ví dụ, các ngữ nghĩa liên quan như chức năng "nhấn và giữ" có thể được khám phá, và các hộp văn bản có thể được hiểu rõ hơn bằng cách quan sát loại bàn phím phần mềm nào (ví dụ, bàn phím email hoặc số) xuất hiện khi được chạm vào. Liệu phương pháp này có thể được mở rộng cho vấn đề phát hiện phần tử UI nói chung, hiện đang dựa nhiều vào chú thích của con người? Có nhiều chi tiết cần được suy luận, chẳng hạn như kích thước và hình dạng của các phần tử UI, và tất nhiên là loại phần tử. Nhiều tương tác hơn sẽ cần từ bộ thu thập dữ liệu để xác định hộp giới hạn cho một phần tử nhất định, và có thể khó suy luận các loại phần tử phức tạp, nhưng một hệ thống hoạt động có thể làm điều này có thể học về các điều khiển tùy chỉnh và các phần tử không tiêu chuẩn khác mà các mô hình hiện tại không thể xử lý được ngày nay. Sự hiểu biết tự động tốt hơn về UI không chỉ có thể mang lại lợi ích cho các ứng dụng hạ nguồn trực tiếp, mà còn thu thập dữ liệu tốt hơn để huấn luyện các mô hình.

5.3 Lợi Ích Của Học Không Ngừng
Bộ thu thập dữ liệu của chúng tôi được thiết kế để chạy vô thời hạn, cho phép nó tích lũy ví dụ và huấn luyện trong thời gian dài. Trong bài báo của chúng tôi, chúng tôi đã thử nghiệm với một số biến số (ví dụ, siêu tham số huấn luyện và chiến lược khám phá), điều này chỉ khả thi bằng cách tập trung vào một khoảng thời gian tương đối ngắn cho mỗi điều kiện (5 epoch thu thập dữ liệu). Ngay cả từ khoảng thời gian ngắn này, chúng tôi có thể huấn luyện các mô hình cho ngữ nghĩa UI "từ đầu" và quan sát những cải thiện nhất quán đối với hiệu suất sau đó, nhưng chúng tôi tin rằng các mô hình của chúng tôi chưa đạt đến tiềm năng tối đa của chúng. Ngoài lợi ích về hiệu suất, học không ngừng cho phép máy móc học từ các nguồn dữ liệu đa dạng. Học không ngừng có thể giúp máy móc xác định và học từ lỗi, đặc biệt là những lỗi được gây ra bởi sự thay đổi trong phân phối dữ liệu được gây ra bởi xu hướng trong việc sử dụng ứng dụng và xu hướng thiết kế.

Học không ngừng cũng giới thiệu những thách thức mới, như "quên thảm khốc," khả năng xóa thông tin đã học trước đó bằng cách huấn luyện trên dữ liệu mới, và khó khăn liên quan đến các tập dữ liệu lớn, ngày càng tăng. Trong bài báo này, chúng tôi tiến hành một khám phá sơ bộ về các phương pháp để giải quyết một số thách thức này, chẳng hạn như lấy mẫu không chắc chắn, có thể giúp ưu tiên một số loại dữ liệu nhất định. Đánh giá tài liệu của chúng tôi đã phát hiện ra nhiều kỹ thuật học máy khác có thể liên quan đến việc huấn luyện quá trình huấn luyện mô hình [4,18,28,37] hoặc chưng cất tập dữ liệu được thu thập các mẫu liên quan [32,33,47]. Chúng tôi kỳ vọng rằng chúng sẽ hữu ích để mở rộng và tối đa hóa hiệu suất của học UI không ngừng.

6 HẠN CHẾ VÀ CÔNG VIỆC TƯƠNG LAI
Việc triển khai hiện tại của chúng tôi về một người học UI không ngừng có hạn chế và trình bày các cơ hội cho khám phá tương lai.

Đầu tiên, bộ thu thập dữ liệu hiện tại của chúng tôi được triển khai bằng cách sử dụng một bộ công cụ và cơ sở hạ tầng cụ thể được tùy chỉnh cho nền tảng đích của chúng tôi (iOS). Mặc dù chúng tôi không chạy thí nghiệm trên các loại UI khác (ví dụ, Android, giao diện dựa trên web), chúng tôi kỳ vọng kết quả của chúng tôi có thể tổng quát hóa được, vì phương pháp của chúng tôi không dựa trên bất kỳ siêu dữ liệu hoặc API cụ thể nào của nền tảng, và nghiên cứu trước đây đã chỉ ra sự chồng chéo ngữ nghĩa giữa UI di động và web [48]. Các thí nghiệm của chúng tôi chủ yếu tập trung vào các ứng dụng miễn phí không yêu cầu xác thực (ví dụ, đăng ký và tạo tài khoản), điều này làm thiên vị tập hợp các màn hình UI được đạt đến bằng cách thu thập dữ liệu. Chúng tôi đã sử dụng các heuristic được thiết kế thủ công và xác minh cho một tập hợp nhỏ các ngữ nghĩa cho khả năng chạm và khả năng kéo. Chúng tôi tin rằng nhiều khía cạnh khác của UI và tương tác có thể được hình thành bằng cách sử dụng các phương pháp tương tự. Một hạn chế khác của các thí nghiệm hiện tại của chúng tôi là chúng tôi không điều tra ảnh hưởng của các phần chia train/test ngẫu nhiên khác nhau, có thể cung cấp cái nhìn bổ sung về tính mạnh mẽ của phương pháp của chúng tôi. Bởi vì các thí nghiệm mất khoảng một tháng để hoàn thành, chi phí thời gian và tính toán cho các thử nghiệm lặp lại sẽ quá cao. Tuy nhiên, vì danh sách ứng dụng của chúng tôi đủ lớn và được xáo trộn ngẫu nhiên, chúng tôi không kỳ vọng sự biến động lớn về hiệu suất qua các phần chia ngẫu nhiên khác nhau.

Các dấu vết tương tác được cá nhân hóa thu thập trong thời gian dài sử dụng có thể cải thiện hiệu suất của các mô hình cho các ứng dụng hiếm, ngách, mặc dù một phương pháp bảo vệ quyền riêng tư sẽ cần thiết (ví dụ, huấn luyện trên thiết bị). Một hướng thay thế là cho phép bộ thu thập dữ liệu của chúng tôi tự động học các chuỗi tương tác để khám phá và gán nhãn các khía cạnh mới của UI, thay vì thực hiện các heuristic được định nghĩa thủ công. Chúng tôi kỳ vọng các phiên bản tương lai của bộ thu thập dữ liệu của chúng tôi sẽ kết hợp các kỹ thuật từ các lĩnh vực học máy liên quan, chẳng hạn như học tăng cường.

Cuối cùng, bộ thu thập dữ liệu của chúng tôi có thể được hưởng lợi từ khả năng hiểu UI được cải thiện. Đầu tiên, biểu diễn chính của bộ thu thập dữ liệu của chúng tôi về các màn hình mà nó truy cập là một danh sách các phần tử UI, được sử dụng để điều hướng và khám phá các phần khác của ứng dụng. Một cách hiệu quả hơn để biểu diễn màn hình có thể dẫn đến thu thập dữ liệu hiệu quả hơn [49]. Ví dụ, vì các thuộc tính của các mục danh sách tương tự, bộ thu thập dữ liệu có thể giảm các tương tác không cần thiết bằng cách chạm vào một mục danh sách và truyền nhãn đến những cái khác. Ngữ nghĩa biểu tượng [5,6,30] cũng hữu ích để suy luận kết quả của một số tương tác nhất định. Ví dụ, chạm vào biểu tượng "máy ảnh" có thể mở ứng dụng máy ảnh hệ thống, điều này sẽ làm gián đoạn quá trình thu thập dữ liệu. Vì mục tiêu của bộ thu thập dữ liệu chính nó là huấn luyện những mô hình UI như vậy, chúng tôi tin rằng việc tích hợp những mô hình bổ sung này vào khung học không ngừng là một bước tiếp theo tự nhiên.

7 KẾT LUẬN
Trong công trình này, chúng tôi đã trình bày một kỹ thuật cho việc trích xuất và mô hình hóa liên tục các ngữ nghĩa giao diện người dùng thông qua các tương tác, mà chúng tôi gọi là "học không ngừng về UI." Chúng tôi đã triển khai một bộ thu thập dữ liệu ứng dụng di động tải xuống, cài đặt và thu thập dữ liệu hàng nghìn ứng dụng để quan sát các ngữ nghĩa và affordance UI trong các ứng dụng thế giới thực, và chúng tôi sử dụng các heuristic dựa trên tương tác để tạo ra các tập dữ liệu lớn để huấn luyện ba loại mô hình hiểu UI i) khả năng chạm, ii) khả năng kéo, và iii) độ tương tự màn hình. Chúng tôi thấy rằng các mô hình được huấn luyện theo cách này có thể chính xác hơn so với những mô hình được huấn luyện từ ảnh chụp màn hình được chú thích bởi con người và tiếp tục cải thiện với quyền truy cập vào nhiều ví dụ huấn luyện hơn. Tính chất tự động cao của phương pháp của chúng tôi cho phép chúng tôi áp dụng nó vô thời hạn, với ít hoặc không có giám sát của con người, có thể tối đa hóa hiệu suất và tiện ích của chúng cho các ứng dụng hạ nguồn.

TÀI LIỆU THAM KHẢO
[1] Deniz Arsan, Ali Zaidi, Aravind Sagar, và Ranjitha Kumar. 2021. Các Phím Tắt Tác Vụ Dựa Trên Ứng Dụng cho Trợ Lý Ảo. Trong Hội nghị Thường niên lần thứ 34 của ACM về Phần mềm và Công nghệ Giao diện Người dùng. 1089–1099.
[2] Chongyang Bai, Xiaoxue Zang, Ying Xu, Srinivas Sunkara, Abhinav Rastogi, Jindong Chen, và Blaise Agüera y Arcas. 2021. UIBert: Học Biểu Diễn Đa Phương Thức Chung cho Hiểu UI. Trong Hội nghị Quốc tế về Trí tuệ Nhân tạo.
[3] Sara Bunian, Kai Li, Chaima Jemmali, Casper Harteveld, Yun Fu, và Magy Seif Seif El-Nasr. 2021. Vins: Tìm kiếm thị giác cho thiết kế giao diện người dùng di động. Trong Kỷ yếu Hội nghị CHI 2021 về Các Yếu tố Con người trong Hệ thống Máy tính. 1–14.
[4] Francisco M Castro, Manuel J Marín-Jiménez, Nicolás Guil, Cordelia Schmid, và Karteek Alahari. 2018. Học tăng dần end-to-end. Trong Kỷ yếu Hội nghị châu Âu về thị giác máy tính (ECCV). 233–248.
[5] Jieshan Chen, Chunyang Chen, Zhenchang Xing, Xiwei Xu, Liming Zhu, Guoqiang Li, và Jinshui Wang. 2020. Unblind your apps: Dự đoán nhãn ngôn ngữ tự nhiên cho các thành phần gui di động bằng học sâu. Trong Kỷ yếu Hội nghị Quốc tế ACM/IEEE lần thứ 42 về Kỹ thuật Phần mềm. 322–334.
[6] Jieshan Chen, Amanda Swearngin, Jason Wu, Titus Barik, Jeffrey Nichols, và Xiaoyi Zhang. 2022. Hướng tới Gán Nhãn Biểu tượng Hoàn chỉnh trong Ứng dụng Di động. Trong Kỷ yếu Hội nghị CHI 2022 về Các Yếu tố Con người trong Hệ thống Máy tính. 1–14.
[7] Sen Chen, Lingling Fan, Chunyang Chen, Ting Su, Wenhe Li, Yang Liu, và Lihua Xu. 2019. Storydroid: Tạo storyboard tự động cho ứng dụng Android. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 41 về Kỹ thuật Phần mềm (ICSE) 2019. IEEE, 596–607.
[8] Elizabeth Clark, Tal August, Sofia Serrano, Nikita Haduong, Suchin Gururangan, và Noah A. Smith. 2021. Tất cả những gì 'Con người' không phải là Vàng: Đánh giá Đánh giá Con người về Văn bản Được Tạo ra. Trong Kỷ yếu Cuộc họp Thường niên lần thứ 59 của Hiệp hội Ngôn ngữ học Tính toán và Hội nghị Quốc tế về Xử lý Ngôn ngữ Tự nhiên lần thứ 11 (Tập 1: Báo cáo Dài). Hiệp hội Ngôn ngữ học Tính toán, Trực tuyến, 7282–7296. https://doi.org/10.18653/v1/2021.acl-long.565
[9] Nathan Cooper, Carlos Bernal-Cárdenas, Oscar Chaparro, Kevin Moran, và Denys Poshyvanyk. 2021. Cần hai người để khiêu vũ tango: Kết hợp thông tin thị giác và văn bản để phát hiện báo cáo lỗi video trùng lặp. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 43 về Kỹ thuật Phần mềm (ICSE) 2021. IEEE, 957–969.
[10] Biplab Deka, Zifeng Huang, Chad Franzen, Joshua Hibschman, Daniel Afergan, Yang Li, Jeffrey Nichols, và Ranjitha Kumar. 2017. Rico: Một Tập dữ liệu Ứng dụng Di động để Xây dựng Ứng dụng Thiết kế Dựa trên Dữ liệu. Trong Kỷ yếu Hội nghị Thường niên lần thứ 30 của ACM về Phần mềm và Công nghệ Giao diện Người dùng (Québec City, QC, Canada) (UIST '17). Hiệp hội Máy tính ACM, New York, NY, USA, 845–854. https://doi.org/10.1145/3126594.3126651
[11] Shirin Feiz, Jason Wu, Xiaoyi Zhang, Amanda Swearngin, Titus Barik, và Jeffrey Nichols. 2022. Hiểu Mối quan hệ Màn hình từ Ảnh chụp màn hình của Ứng dụng Điện thoại thông minh. Trong Hội nghị Quốc tế lần thứ 27 về Giao diện Người dùng Thông minh (Helsinki, Finland) (IUI '22). Hiệp hội Máy tính ACM, New York, NY, USA, 447–458. https://doi.org/10.1145/3490099.3511109
[12] Ian Goodfellow, Yoshua Bengio, và Aaron Courville. 2016. Học Sâu. MIT Press. http://www.deeplearningbook.org.
[13] Raia Hadsell, Sumit Chopra, và Yann LeCun. 2006. Giảm chiều bằng cách học một ánh xạ bất biến. Trong Hội nghị Xã hội Máy tính IEEE 2006 về Thị giác Máy tính và Nhận dạng Mẫu (CVPR'06), Tập 2. IEEE, 1735–1742.
[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. 2016. Học residual sâu cho nhận dạng hình ảnh. Trong Kỷ yếu hội nghị IEEE về thị giác máy tính và nhận dạng mẫu. 770–778.
[15] Zecheng He, Srinivas Sunkara, Xiaoxue Zang, Ying Xu, Lijuan Liu, Nevan Wichers, Gabriel Schubiner, Ruby Lee, và Jindong Chen. 2021. ActionBert: Tận dụng Hành động Người dùng để Hiểu Ngữ nghĩa của Giao diện Người dùng. Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo 35, 7 (Tháng 5 2021), 5931–5938. https://doi.org/10.1609/aaai.v35i7.16741
[16] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, và Hartwig Adam. 2017. MobileNets: Mạng Nơ-ron Tích chập Hiệu quả cho Ứng dụng Thị giác Di động. arXiv:1704.04861 [cs.CV]
[17] Forrest Huang, John F. Canny, và Jeffrey Nichols. 2019. Swire: Truy xuất Giao diện Người dùng Dựa trên Phác thảo. Trong Kỷ yếu Hội nghị CHI 2019 về Các Yếu tố Con người trong Hệ thống Máy tính (Glasgow, Scotland Uk) (CHI '19). Hiệp hội Máy tính ACM, New York, NY, USA, 1–10. https://doi.org/10.1145/3290605.3300334
[18] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. 2017. Vượt qua việc quên thảm khốc trong mạng nơ-ron. Kỷ yếu Viện Hàn lâm Khoa học Quốc gia 114, 13 (2017), 3521–3526.
[19] Konstantin Kuznetsov, Chen Fu, Song Gao, David N. Jansen, Lijun Zhang, và Andreas Zeller. 2021. Frontmatter: Khai thác Giao diện Người dùng Android theo Quy mô. Trong Kỷ yếu Cuộc họp Chung ACM lần thứ 29 về Hội nghị Kỹ thuật Phần mềm châu Âu và Hội nghị về Nền tảng Kỹ thuật Phần mềm (Athens, Greece) (ESEC/FSE 2021). Hiệp hội Máy tính ACM, New York, NY, USA, 1580–1584. https://doi.org/10.1145/3468264.3473125
[20] Luis A. Leiva, Asutosh Hota, và Antti Oulasvirta. 2021. Enrico: Một Tập dữ liệu để Mô hình hóa Chủ đề của Thiết kế UI Di động. Trong Hội nghị Quốc tế lần thứ 22 về Tương tác Con người-Máy tính với Thiết bị Di động và Dịch vụ (Oldenburg, Germany) (MobileHCI '20). Hiệp hội Máy tính ACM, New York, NY, USA, Bài báo 9, 4 trang. https://doi.org/10.1145/3406324.3410710
[21] Gang Li, Gilles Baechler, Manuel Tragut, và Yang Li. 2022. Học Khử nhiễu Bố cục UI Di động Thô để Cải thiện Tập dữ liệu theo Quy mô. Trong Kỷ yếu Hội nghị CHI 2022 về Các Yếu tố Con người trong Hệ thống Máy tính (New Orleans, LA, USA) (CHI '22). Hiệp hội Máy tính ACM, New York, NY, USA, Bài báo 67, 13 trang. https://doi.org/10.1145/3491102.3502042
[22] Toby Jia-Jun Li, Lindsay Popowski, Tom Mitchell, và Brad A Myers. 2021. Screen2Vec: Embedding Ngữ nghĩa của Màn hình GUI và Thành phần GUI. Trong Kỷ yếu Hội nghị CHI 2021 về Các Yếu tố Con người trong Hệ thống Máy tính (Yokohama, Japan) (CHI '21). Hiệp hội Máy tính ACM, New York, NY, USA, Bài báo 578, 15 trang. https://doi.org/10.1145/3411764.3445049
[23] Yang Li, Jiacong He, Xin Zhou, Yuan Zhang, và Jason Baldridge. 2020. Ánh xạ hướng dẫn ngôn ngữ tự nhiên đến chuỗi hành động UI di động. arXiv preprint arXiv:2005.03776 (2020).
[24] Yang Li, Gang Li, Luheng He, Jingjie Zheng, Hong Li, và Zhiwei Guan. 2020. Chú thích Widget: Tạo Mô tả Ngôn ngữ Tự nhiên cho Các Yếu tố Giao diện Người dùng Di động. Trong Kỷ yếu Hội nghị 2020 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên (EMNLP). 5495–5510.
[25] Yuanchun Li, Ziyue Yang, Yao Guo, và Xiangqun Chen. 2017. Droidbot: một trình tạo đầu vào kiểm tra nhẹ hướng dẫn ui cho android. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 39 về Kỹ thuật Phần mềm Bổ trợ (ICSE-C) 2017. IEEE, 23–26.
[26] Yuanchun Li, Ziyue Yang, Yao Guo, và Xiangqun Chen. 2017. Droidbot: một trình tạo đầu vào kiểm tra nhẹ hướng dẫn ui cho android. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 39 về Kỹ thuật Phần mềm Bổ trợ (ICSE-C) 2017. IEEE, 23–26.
[27] Yuanchun Li, Ziyue Yang, Yao Guo, và Xiangqun Chen. 2019. Humanoid: Một phương pháp dựa trên học sâu cho kiểm tra ứng dụng android hộp đen tự động. Trong Hội nghị Quốc tế IEEE/ACM lần thứ 34 về Kỹ thuật Phần mềm Tự động (ASE) 2019. IEEE, 1070–1073.
[28] Zhizhong Li và Derek Hoiem. 2017. Học mà không quên. Giao dịch IEEE về phân tích mẫu và trí tuệ máy 40, 12 (2017), 2935–2947.
[29] Yi-Chi Liao, Kashyap Todi, Aditya Acharya, Antti Keurulainen, Andrew Howes, và Antti Oulasvirta. 2022. Tái khám phá Affordance: Một Quan điểm Học Tăng cường. Trong Kỷ yếu Hội nghị CHI 2022 về Các Yếu tố Con người trong Hệ thống Máy tính (New Orleans, LA, USA) (CHI '22). Hiệp hội Máy tính ACM, New York, NY, USA, Bài báo 362, 15 trang. https://doi.org/10.1145/3491102.3501992
[30] Thomas F Liu, Mark Craft, Jason Situ, Ersin Yumer, Radomir Mech, và Ranjitha Kumar. 2018. Học ngữ nghĩa thiết kế cho ứng dụng di động. Trong Kỷ yếu Hội nghị Thường niên ACM lần thứ 31 về Phần mềm và Công nghệ Giao diện Người dùng. 569–579.
[31] T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, B. Yang, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, và J. Welling. 2018. Học Không Ngừng. Commun. ACM 61, 5 (tháng 4 2018), 103–115. https://doi.org/10.1145/3191513
[32] Timothy Nguyen, Zhourong Chen, và Jaehoon Lee. 2020. Meta-learning tập dữ liệu từ hồi quy ridge nhân. arXiv preprint arXiv:2011.00050 (2020).
[33] Timothy Nguyen, Roman Novak, Lechao Xiao, và Jaehoon Lee. 2021. Chưng cất tập dữ liệu với mạng tích chập vô hạn rộng. Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron 34 (2021), 5186–5198.
[34] Donald A Norman. 1988. Tâm lý học của những thứ hàng ngày. Sách cơ bản.
[35] Antti Oulasvirta, Jussi P. P. Jokinen, và Andrew Howes. 2022. Tính hợp lý Tính toán như một Lý thuyết Tương tác. Trong Kỷ yếu Hội nghị CHI 2022 về Các Yếu tố Con người trong Hệ thống Máy tính (New Orleans, LA, USA) (CHI '22). Hiệp hội Máy tính ACM, New York, NY, USA, Bài báo 359, 14 trang. https://doi.org/10.1145/3491102.3517739
[36] Mihir Parmar, Swaroop Mishra, Mor Geva, và Chitta Baral. 2022. Đừng đổ lỗi cho Người chú thích: Thiên vị đã bắt đầu trong Hướng dẫn Chú thích. https://doi.org/10.48550/ARXIV.2205.00415
[37] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. 2017. icarl: Học bộ phân loại và biểu diễn tăng dần. Trong Kỷ yếu hội nghị IEEE về Thị giác Máy tính và Nhận dạng Mẫu. 2001–2010.
[38] Eldon Schoop, Xin Zhou, Gang Li, Zhourong Chen, Björn Hartmann, và Yang Li. 2022. Dự đoán và Giải thích Khả năng Chạm UI Di động với Mô hình Thị giác và Phân tích Saliency. Trong Kỷ yếu Hội nghị CHI 2022 về Các Yếu tố Con người trong Hệ thống Máy tính. 1–21.
[39] Alborz Rezazadeh Sereshkeh, Gary Leung, Krish Perumal, Caleb Phillips, Minfan Zhang, Afsaneh Fazly, và Iqbal Mohomed. 2020. VASTA: một hệ thống tự động hóa tác vụ điện thoại thông minh được hỗ trợ bởi thị giác và ngôn ngữ. Trong Kỷ yếu hội nghị quốc tế lần thứ 25 về giao diện người dùng thông minh. 22–32.
[40] Leslie N Smith. 2017. Tỷ lệ học theo chu kỳ để huấn luyện mạng nơ-ron. Trong Hội nghị mùa đông IEEE 2017 về ứng dụng thị giác máy tính (WACV). IEEE, 464–472.
[41] Chen Sun, Abhinav Shrivastava, Saurabh Singh, và Abhinav Gupta. 2017. Tái xem xét hiệu quả không hợp lý của dữ liệu trong kỷ nguyên học sâu. Trong Kỷ yếu hội nghị quốc tế IEEE về thị giác máy tính. 843–852.
[42] Amanda Swearngin và Yang Li. 2019. Mô hình Khả năng Chạm Giao diện Di động Sử dụng Crowdsourcing và Học Sâu. Trong Kỷ yếu Hội nghị CHI 2019 về Các Yếu tố Con người trong Hệ thống Máy tính (Glasgow, Scotland Uk) (CHI '19). Hiệp hội Máy tính ACM, New York, NY, USA, 1–11. https://doi.org/10.1145/3290605.3300305
[43] Mingxing Tan và Quoc Le. 2019. Efficientnet: Suy nghĩ lại về việc mở rộng mô hình cho mạng nơ-ron tích chập. Trong Hội nghị quốc tế về học máy. PMLR, 6105–6114.
[44] Nandan Thakur, Nils Reimers, Johannes Daxenberger, và Iryna Gurevych. 2020. Sbert được tăng cường: Phương pháp tăng cường dữ liệu để cải thiện bi-encoder cho các tác vụ tính điểm câu theo cặp. arXiv preprint arXiv:2010.08240 (2020).
[45] Daniel Toyama, Philippe Hamel, Anita Gergely, Gheorghe Comanici, Amelia Glaese, Zafarali Ahmed, Tyler Jackson, Shibl Mourad, và Doina Precup. 2021. Androidenv: Một nền tảng học tăng cường cho android. arXiv preprint arXiv:2105.13231 (2021).
[46] Bryan Wang, Gang Li, Xin Zhou, Zhourong Chen, Tovi Grossman, và Yang Li. 2021. Screen2words: Tóm tắt UI di động tự động với học đa phương thức. Trong Hội nghị Thường niên ACM lần thứ 34 về Phần mềm và Công nghệ Giao diện Người dùng. 498–510.
[47] Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, và Alexei A Efros. 2018. Chưng cất tập dữ liệu. arXiv preprint arXiv:1811.10959 (2018).
[48] Jason Wu, Siyan Wang, Siman Shen, Yi-Hao Peng, Jeffrey Nichols, và Jeffrey P Bigham. 2023. WebUI: Một Tập dữ liệu để Tăng cường Hiểu UI Thị giác với Ngữ nghĩa Web. arXiv preprint arXiv:2301.13280 (2023).
[49] Jason Wu, Xiaoyi Zhang, Jeff Nichols, và Jeffrey P Bigham. 2021. Phân tích Màn hình: Hướng tới Kỹ thuật Ngược của Mô hình UI từ Ảnh chụp màn hình. Trong Hội nghị Thường niên ACM lần thứ 34 về Phần mềm và Công nghệ Giao diện Người dùng (Virtual Event, USA) (UIST '21). Hiệp hội Máy tính ACM, New York, NY, USA, 470–483. https://doi.org/10.1145/3472749.3474763
[50] Ziming Wu, Yulun Jiang, Yiding Liu, và Xiaojuan Ma. 2020. Dự đoán và Chẩn đoán Sự tham gia của Người dùng với Hoạt ảnh UI Di động thông qua Phương pháp Dựa trên Dữ liệu. Trong Kỷ yếu Hội nghị CHI 2020 về Các Yếu tố Con người trong Hệ thống Máy tính (Honolulu, HI, USA) (CHI '20). Hiệp hội Máy tính ACM, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376324
[51] Mulong Xie, Sidong Feng, Zhenchang Xing, Jieshan Chen, và Chunyang Chen. 2020. UIED: một công cụ lai để phát hiện phần tử GUI. Trong Kỷ yếu Cuộc họp Chung ACM lần thứ 28 về Hội nghị Kỹ thuật Phần mềm châu Âu và Hội nghị về Nền tảng Kỹ thuật Phần mềm. 1655–1659.
[52] Arianna Yuan và Yang Li. 2020. Mô hình hóa hiệu suất tìm kiếm thị giác của con người trên các trang web thực tế sử dụng phương pháp phân tích và học sâu. Trong Kỷ yếu hội nghị CHI 2020 về các yếu tố con người trong hệ thống máy tính. 1–12.
[53] Xiaoyi Zhang, Lilian de Greef, Amanda Swearngin, Samuel White, Kyle Murray, Lisa Yu, Qi Shan, Jeffrey Nichols, Jason Wu, Chris Fleizach, et al. 2021. Nhận dạng màn hình: Tạo siêu dữ liệu trợ năng cho ứng dụng di động từ pixel. Trong Kỷ yếu Hội nghị CHI 2021 về Các Yếu tố Con người trong Hệ thống Máy tính. 1–15.
[54] Xin Zhou và Yang Li. 2021. Mô hình hóa Quy mô Lớn của Hành vi Nhấp chuột Người dùng Di động Sử dụng Học Sâu. Trong Kỷ yếu Hội nghị ACM lần thứ 15 về Hệ thống Gợi ý. 473–483.
[55] Xingyi Zhou, Dequan Wang, và Philipp Krähenbühl. 2019. Đối tượng như Điểm. arXiv:1904.07850 [cs.CV]

A GIAO DIỆN CHÚ THÍCH
Các nhà chú thích đã sử dụng giao diện chú thích dựa trên web để đánh giá hiệu suất của các heuristic gán nhãn. Hình 10 hiển thị giao diện dựa trên web được sử dụng để gán nhãn đầu ra heuristic.

B SIÊU THAM SỐ MÔ HÌNH
Bảng 1 hiển thị các siêu tham số được sử dụng để huấn luyện các mô hình khác nhau trong Người Học UI Không Ngừng.
=======
Định dạng tham chiếu ACM:
Jason Wu, Rebecca Krosnick, Eldon Schoop, Amanda Swearngin, Jeffrey P. Bigham, và Jeffrey Nichols. 2023. Never-ending Learning of User Interfaces. In The 36th Annual ACM Symposium on User Interface Software and Technology (UIST '23), October 29-November 1, 2023, San Francisco, CA, USA. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3586183.3606824

1 GIỚI THIỆU
Học máy (ML) đã đóng một vai trò ngày càng quan trọng trong lĩnh vực Giao diện người dùng (UI) di động. Các kỹ thuật gần đây đã sử dụng Mạng nơ-ron sâu (DNN) để thu hẹp khoảng cách khả năng sử dụng quan trọng và cho phép các loại đánh giá mới, chẳng hạn như cung cấp siêu dữ liệu khả năng tiếp cận bị thiếu cho UI [49], đưa ra phản hồi cho các nhà thiết kế để làm cho các tính năng UI dễ khám phá hơn [38,42], và dự đoán sự tương tác của người dùng với hoạt ảnh [50]. Các sản phẩm nghiên cứu hỗ trợ đằng sau các tương tác này là các bộ dữ liệu lớn về ảnh chụp màn hình UI di động được chú thích bởi người chú thích [10,19]. Các bộ dữ liệu này cung cấp một khối lượng dữ liệu vô giá để huấn luyện DNN, nhưng chúng chỉ chụp lại một ảnh chụp nhanh cố định về các khung nhìn của các ứng dụng di động và cực kỳ tốn kém để thu thập và cập nhật. Ngoài ra, việc dựa vào các người chú thích để ước tính các thuộc tính nhất định của các phần tử UI từ các dấu hiệu trực quan tĩnh được biết là dễ xảy ra lỗi [38]. Lấy cảm hứng từ mô hình học liên tục không bao giờ kết thúc [31], chúng tôi đề xuất một phương pháp tự động để thu thập chú thích phần tử UI bằng cách tương tác trực tiếp với các ứng dụng với một trình thu thập dữ liệu tự động liên tục cải thiện hiệu suất của chính nó và có thể làm mới các mô hình ML cho các tác vụ xuôi dòng khác theo thời gian.

Chúng tôi đã xây dựng Never-ending UI Learner, một trình thu thập dữ liệu ứng dụng hình thành việc học ngữ nghĩa UI như một quá trình tích cực sử dụng các tương tác thực trên các thiết bị thực để khám phá UI và khám phá các thuộc tính được sử dụng để liên tục huấn luyện các mô hình học máy. Cụ thể hơn, trình thu thập dữ liệu của chúng tôi tự động cài đặt các ứng dụng thực từ các cửa hàng ứng dụng di động và thu thập dữ liệu từ chúng để khám phá các ví dụ huấn luyện mới, thách thức để học từ đó (ví dụ, những ví dụ dẫn đến độ tin cậy mô hình thấp). Trong quá trình thu thập dữ liệu, Never-ending UI Learner ghi lại bối cảnh thời gian (tức là chụp ảnh màn hình trước, trong và sau các tương tác) được sử dụng bởi các hàm heuristic để tạo ra các nhãn chính xác hơn so với những gì có thể từ các ảnh chụp màn hình đơn lẻ được chú thích bởi con người. Dữ liệu thu được được sử dụng để huấn luyện các mô hình dự đoán khả năng chạm và khả năng kéo của các phần tử UI và xác định độ tương tự của các màn hình gặp phải. Mặc dù quá trình có thể bắt đầu với một mô hình được huấn luyện từ dữ liệu được gắn nhãn bởi con người, quá trình end-to-end không yêu cầu bất kỳ ví dụ bổ sung nào được gắn nhãn bởi con người. Trái ngược với các đường ống dữ liệu hiện có cho mô hình hóa UI dựa trên dữ liệu [10,19,53], mô hình học UI liên tục không bao giờ kết thúc của chúng tôi cho phép thu thập dữ liệu, chú thích và huấn luyện mô hình được thực hiện mà không cần bất kỳ sự giám sát nào của con người và có thể được chạy vô thời hạn. Tất nhiên, trong bài báo này, việc học không thực sự liên tục không bao giờ kết thúc. Ở đây chúng tôi trình bày các thí nghiệm phân tích các đặc điểm hiệu suất của trình học của chúng tôi trong 5.000 giờ thiết bị, trong đó nó thực hiện hơn nửa triệu hành động trên 6.000 ứng dụng. Bộ dữ liệu thu được lớn hơn một bậc độ so với các bộ dữ liệu UI được chú thích bởi con người hiện có [10,53] và cho phép chúng tôi phân tích hiệu suất của các mô hình ngữ nghĩa UI khi được huấn luyện với số lượng ví dụ được thu thập gần đây ngày càng tăng. Cuối cùng, chúng tôi tin rằng mô hình này có thể được sử dụng theo phong cách thực sự "không bao giờ kết thúc", liên tục thu thập dữ liệu từ hệ sinh thái ứng dụng, thu thập dữ liệu từ nghĩa đen là tất cả các ứng dụng có sẵn, và trải nghiệm các phong cách và xu hướng UI mới khi các ứng dụng mới hoặc được cập nhật được phát hành.

Các đóng góp cụ thể của bài báo chúng tôi như sau:
(1) Never-ending UI Learner, là một hệ thống vận hành phương pháp của chúng tôi để tự động học từ UI thông qua tương tác không bao giờ kết thúc.
(2) Ba ứng dụng thể hiện việc sử dụng Never-ending UI Learner. Chúng tôi sử dụng trình thu thập dữ liệu của mình để huấn luyện ba loại mô hình ngữ nghĩa UI khó học thông qua các phương pháp hiện có: i) khả năng chạm, ii) khả năng kéo, và iii) độ tương tự màn hình.

2 CÔNG TRÌNH LIÊN QUAN
Công trình của chúng tôi trong việc học liên tục không bao giờ kết thúc về UI nhằm bổ sung các bộ dữ liệu mô hình hóa UI được sử dụng để mô hình hóa UI và tương tác người dùng thông qua học liên tục. Để định vị công trình của chúng tôi, chúng tôi xem xét tài liệu liên quan trong i) bộ dữ liệu mô hình hóa UI, ii) các mô hình tính toán của tương tác, và iii) các phương pháp học máy liên tục.

2.1 Bộ dữ liệu để mô hình hóa giao diện người dùng
Một số bộ dữ liệu đã được thu thập cho mục đích phân tích và mô hình hóa UI di động. Bộ dữ liệu Rico là một bộ dữ liệu lớn gồm 72.000 UI di động và siêu dữ liệu liên quan bao gồm các cấu trúc phân cấp khung nhìn, ảnh chụp màn hình và tương tác người dùng, được thu thập từ 9.700 ứng dụng Android có sẵn công khai [10]. Bộ dữ liệu FrontMatter sử dụng các kỹ thuật phân tích tĩnh để dự đoán mục đích của các phần tử UI bằng cách xác định các API hệ thống nào được gọi [19]. Các bộ dữ liệu lớn như thế này đã cho phép các phương pháp dựa trên ML có thể thực hiện các tác vụ khác nhau liên quan đến UI di động, bao gồm cung cấp chú thích khả năng tiếp cận [24,49], đưa ra phản hồi thiết kế [17,38,42,52], gợi ý các luồng tương tác phổ biến [54], tóm tắt màn hình [46], tự động hóa tương tác với UI [1,23,39], và tạo ra các nhúng phong phú của dữ liệu hình ảnh và văn bản UI cho các tác vụ xuôi dòng khác [2,15,22]. Gần như tất cả các bộ dữ liệu hiện có đều được tạo thủ công ở một khía cạnh nào đó – thông qua các tương tác thủ công của người dùng với UI và/hoặc chú thích của con người. Bộ dữ liệu WebUI [48] đã sử dụng ảnh chụp màn hình và siêu dữ liệu được trích xuất tự động từ các trang web để huấn luyện các mô hình UI trực quan; tuy nhiên, dữ liệu web nói chung là nhiễu và các mô hình của họ cần tinh chỉnh bổ sung trên các bộ dữ liệu được chú thích bởi con người nhỏ hơn để hoạt động tốt. Never-ending UI Learner của chúng tôi tạo ra chú thích thông qua việc thu thập dữ liệu tự động của các ứng dụng di động. Các chú thích này liên tục cập nhật và làm mới các mô hình của trình thu thập dữ liệu, cải thiện hiệu suất của nó và dẫn đến một bộ dữ liệu được cập nhật liên tục có thể được sử dụng để huấn luyện các mô hình khác. Một lợi thế quan trọng của phương pháp này là, không giống như việc sử dụng dữ liệu UI di động được thu thập trong một khoảng thời gian cụ thể, dữ liệu được tạo ra bởi trình thu thập dữ liệu của chúng tôi luôn là hiện tại và có thể hỗ trợ cập nhật các mô hình để theo kịp với các xu hướng thiết kế UI đang phát triển trong các ứng dụng di động.

2.2 Mô hình hóa tính toán của tương tác
Một ứng dụng quan trọng của các bộ dữ liệu UI được chú thích lớn là huấn luyện có giám sát của học máy dự đoán ngữ nghĩa UI. Ví dụ, trong bài báo này chúng tôi tập trung vào các vấn đề về khả năng chạm phần tử [38,42] và "vân tay" màn hình [11]. Gần đây hơn, Học tăng cường (RL) đã được áp dụng để mô hình hóa tương tác người dùng với cả giao diện vật lý và kỹ thuật số. Oulasvirta et al. đã đề xuất một khung chung dựa trên RL về cách người dùng kết hợp các khả năng nhận thức, kinh nghiệm của họ và môi trường của họ trong việc hiểu và tương tác với máy tính [35]. Trong bối cảnh này, một phần quan trọng của việc biết cách tương tác với một giao diện là hiểu các khả năng sử dụng của nó. Khả năng sử dụng là các thuộc tính chức năng của một đối tượng (ví dụ, UI) gợi ý cách nó nên được sử dụng [34], và bình luận của nhà thiết kế cho thấy rằng các mẫu thiết kế có thể làm cho việc khám phá khả năng sử dụng trở nên khó khăn hơn. Liao et al. đã sử dụng một tác nhân robot ảo được trang bị cảm biến để mô phỏng và học cách con người có thể khám phá khả năng sử dụng trong các giao diện vật lý (ví dụ, nút và thanh trượt) [29]. Công trình của chúng tôi nhằm đạt được các mục tiêu tương tự của việc học các khả năng sử dụng (ví dụ, khả năng chạm) và khả năng của giao diện. Trong khi công trình của chúng tôi không trực tiếp mô hình hóa các tương tác của người dùng thông qua các kỹ thuật RL, chúng tôi nhằm đạt được các mục tiêu tương tự của việc học về khả năng sử dụng và khả năng của giao diện thông qua tương tác và kiểm tra các ứng dụng di động trực tiếp. Bằng cách áp dụng học tương tác vào một trình thu thập dữ liệu tự động ứng dụng di động, chúng tôi có thể mở rộng quy mô thí nghiệm của mình lên một quy mô lớn hơn nhiều, học từ hàng triệu tương tác với UI.

2.3 Học máy liên tục
Một khía cạnh độc đáo của công trình của chúng tôi là ý định liên tục học về UI theo thời gian thông qua tương tác bền vững, có thể vô tận. Công trình của chúng tôi liên quan đến học tích cực (cụ thể là học tích cực trực tuyến), một lĩnh vực ML tìm cách cải thiện các mô hình chỉ sử dụng một số lượng hạn chế các ví dụ được gắn nhãn bởi con người [12]. Các phương pháp này thường xác định và ưu tiên các ví dụ khó hoặc đại diện để tạo ra mô hình tốt nhất có thể từ một bộ dữ liệu nhỏ. Công trình của chúng tôi liên quan nhất đến Học liên tục không bao giờ kết thúc, một mô hình ML để tạo ra các hệ thống liên tục học từ kinh nghiệm thu được thay vì một bộ dữ liệu duy nhất. Nó lần đầu tiên được áp dụng cho kiến thức dựa trên web bằng hệ thống NELL [31]. Hệ thống đã chạy trong các khoảng thời gian dài (nhiều năm) và đã tích lũy hơn 50 triệu niềm tin (tức là các đoạn kiến thức giả định), điều này chỉ có thể bằng cách xử lý lượng lớn dữ liệu mà việc chú thích là cực kỳ tốn kém. Phương pháp học này giới thiệu các thách thức độc đáo, chẳng hạn như nhu cầu học từ dữ liệu mới trong khi vẫn giữ lại kiến thức đã thu được trước đó. Có một số kỹ thuật trong tài liệu có thể được áp dụng để giữ lại kiến thức trước đó bao gồm i) chính quy hóa [18,28], ii) các phương pháp dựa trên diễn tập [37], và iii) các kỹ thuật giải quyết sự thiên vị gần đây của tác vụ [4]. Từ quan điểm thực tế, triển khai cũng đòi hỏi việc duy trì các bộ dữ liệu lớn ngày càng phát triển được thu thập theo thời gian, có thể được giải quyết thông qua một cơ sở hạ tầng thu thập dữ liệu mạnh mẽ hoặc sử dụng các phương pháp chưng cất bộ dữ liệu giữ lại các mẫu liên quan nhất [32,33,47]. Trong công trình này, chúng tôi áp dụng mô hình học liên tục không bao giờ kết thúc để mang lại lợi ích cho các hệ thống hiểu UI tự động bằng cách huấn luyện các mô hình "từ đầu" và tinh chỉnh các mô hình hiện có để cải thiện hiệu suất.

3 NEVER-ENDING UI LEARNER
Để vận hành phương pháp của chúng tôi, chúng tôi đã xây dựng Never-ending UI Learner, một hệ thống tự động tải xuống và thu thập dữ liệu từ các ứng dụng có sẵn công khai sử dụng các thiết bị được vận hành từ xa. Triển khai và cơ sở hạ tầng hiện tại của chúng tôi dựa trên iOS. Chúng tôi sử dụng các thiết bị được đặt lại về gốc có sẵn được đăng nhập vào các tài khoản thử nghiệm không liên quan đến bất kỳ dữ liệu người dùng thực nào để tránh các mối lo ngại về quyền riêng tư. Lưu ý rằng không giống như một số trình thu thập dữ liệu tương tác với các ứng dụng sử dụng giao diện lập trình do HĐH cung cấp như API khả năng tiếp cận, trình thu thập dữ liệu của chúng tôi tương tác với thiết bị thông qua giao thức máy tính để bàn từ xa VNC, từ đó nó nhận các cập nhật thường xuyên cho màn hình và xử lý chúng một cách trực quan và có thể gửi các sự kiện đầu vào thô đến thiết bị để tạo ra các hành động chạm, vuốt và bàn phím. Sử dụng VNC, Never-ending UI Learner có thể tương tác đáng tin cậy với nhiều ứng dụng hơn, học dựa trên cùng những khả năng mà một con người sẽ có và tổng quát hóa cho các nền tảng khác. Trong phần này, chúng tôi mô tả kiến trúc và hành vi của trình thu thập dữ liệu cho phép nó thực hiện học liên tục không bao giờ kết thúc.

3.1 Tổng quan về kiến trúc
Kiến trúc thu thập dữ liệu của chúng tôi được hiển thị trong Hình 1. Chúng tôi đã triển khai một kiến trúc thu thập dữ liệu phân tán bao gồm i) một máy chủ điều phối trung tâm và ii) một pool lớn các worker để song song hóa quá trình thu thập dữ liệu.

3.1.1 Máy chủ điều phối. Máy chủ điều phối trình thu thập dữ liệu duy trì một danh sách các ID ứng dụng để thu thập dữ liệu được gửi cho các worker. Máy chủ trung tâm theo dõi các lần thu thập dữ liệu thành công và không thành công, và nó tự động thử lại các lần thu thập dữ liệu ứng dụng bị lỗi. Các trình thu thập dữ liệu ứng dụng khác với các trình thu thập dữ liệu web ở chỗ chúng chỉ tập trung vào ứng dụng được yêu cầu thu thập dữ liệu, mặc dù tương tác giữa các ứng dụng hạn chế đôi khi xảy ra (ví dụ, nhấp vào liên kết hoặc hộp thoại yêu cầu quyền). Khi tất cả các ID ứng dụng đã hết, trình thu thập dữ liệu của chúng tôi có thể lên lịch chạy lại sau một khoảng thời gian cố định (ví dụ, hàng tuần). Danh sách các ID ứng dụng có thể được sửa đổi giữa các lần thu thập dữ liệu để thêm ứng dụng mới hoặc phản ánh các thay đổi về tính khả dụng của ứng dụng. Trong khi phần lớn các ID ứng dụng vẫn giữ nguyên, các ứng dụng có thể thay đổi giao diện và hành vi của chúng do nội dung được cập nhật động và các phiên bản mới của phần mềm. Việc thu thập dữ liệu lại các ứng dụng tương tự thường xuyên có thể giúp mô hình của chúng tôi thích ứng với các thay đổi thiết kế theo thời gian.

3.1.2 Worker thu thập dữ liệu. Các worker thu thập dữ liệu là các quy trình giao tiếp với các điện thoại di động được điều khiển từ xa và xử lý dữ liệu được thu thập. Mỗi worker thu thập dữ liệu tải xuống và cài đặt một ứng dụng mục tiêu có ID được cung cấp bởi máy chủ trung tâm vào điện thoại di động và sau đó chạy một chương trình thu thập dữ liệu từ ứng dụng. Ảnh chụp màn hình được thu thập trong quá trình tương tác và khi trình thu thập dữ liệu tin rằng nó đã đến một màn hình mới. Chương trình có thể sử dụng ba phương pháp để khám phá ứng dụng (lựa chọn ngẫu nhiên hoặc dựa trên độ tin cậy của mô hình), và như một phần của bài báo này, chúng tôi chạy các thí nghiệm để xác định chiến lược thu thập dữ liệu tốt nhất cho từng trường hợp sử dụng học liên tục không bao giờ kết thúc của chúng tôi. Chúng tôi đặt giới hạn thời gian (5 phút) về thời lượng tối đa của việc thu thập dữ liệu cho một ứng dụng duy nhất. Sau đó, worker xử lý dữ liệu được thu thập (ví dụ, ảnh chụp màn hình và tương tác) với các mô hình và heuristic để tạo ra nhãn từ các quan sát. Cả dữ liệu thô và đầu ra đã xử lý đều được tải lên máy chủ điều phối. Trong các thí nghiệm của chúng tôi, số lượng worker thu thập dữ liệu khác nhau do tính khả dụng từ pool thiết bị mà chúng tôi sử dụng, được chia sẻ với các người dùng khác. Nói chung, có khoảng 40-100 worker thu thập dữ liệu.

3.2 Các thành phần học máy
Trình thu thập dữ liệu của chúng tôi chứa một mô hình cấp màn hình và cấp phần tử cho phép nó hiểu nội dung trên UI mà nó gặp phải. Chúng tôi chạy các mô hình này mỗi khi một ảnh chụp màn hình được chụp để bổ sung nó với các ngữ nghĩa hữu ích. Hơn nữa, ba mô hình ngữ nghĩa UI mà chúng tôi đã huấn luyện bằng trình thu thập dữ liệu, được thiết kế như các phần mở rộng của các mô hình cơ sở này, cải thiện hiệu quả tổng thể.

3.2.1 Hiểu màn hình. Để theo dõi tiến trình thu thập dữ liệu trong ứng dụng, trình thu thập dữ liệu của chúng tôi sử dụng một mô hình để tạo ra các biểu diễn ngữ nghĩa của màn hình. Chúng tôi đã sử dụng một mô hình được giới thiệu bởi công trình trước đó [11] dự đoán liệu hai ảnh chụp màn hình có thuộc về cùng một UI hay không bằng cách mã hóa từng ảnh như một vector nhúng, mà các tác giả đã chia sẻ với chúng tôi. Bởi vì sự biến đổi đáng kể có thể được đưa vào bởi các thay đổi về trạng thái, chẳng hạn như một ứng dụng tin tức hiển thị nội dung mới định kỳ, mô hình được thiết kế để học cấu trúc cơ bản của UI. Chúng tôi đã thực hiện các sửa đổi nhỏ đối với công trình trước đó để phát triển một mô hình có thể chạy dưới các ràng buộc phần cứng của chúng tôi. Thay vì kiến trúc mô hình screen transformer được khuyến nghị của họ, chúng tôi sử dụng kiến trúc mô hình dựa trên CNN của họ, hiệu quả hơn để chạy mặc dù hiệu suất thấp hơn một chút [11]. Để tối ưu hóa thêm, chúng tôi sử dụng kiến trúc mô hình EfficientNet-B0 [43] làm backbone thay vì ResNet-18 ban đầu [14], có nhiều tham số hơn. Như trong bài báo gốc, đầu ra của lớp cuối cùng của mạng CNN được sử dụng như một embedding màn hình. Trong quá trình huấn luyện, chúng tôi đã áp dụng phương pháp tăng cường dữ liệu [44] để tăng hiệu suất. Chúng tôi đã tuân theo tất cả các khía cạnh khác của việc huấn luyện mô hình ban đầu và mô hình dựa trên CNN cuối cùng của chúng tôi đạt được điểm F1 là 0.636.

3.2.2 Hiểu phần tử. Để tạo ra ngữ nghĩa phần tử, chúng tôi đã sử dụng một kiến trúc mô hình phát hiện đối tượng tương tự như CenterNet [55]. Ở mức độ cao, mô hình phát hiện trượt một cửa sổ (thông qua các tích chập) qua hình ảnh và đặc trưng hóa các vùng con hình ảnh bằng mạng backbone (MobileNet-v1 [16]), dẫn đến các embedding cho mỗi vùng. Các embedding này được đưa vào một đầu phân loại tạo ra độ tin cậy cho mỗi lớp, và các vùng có độ tin cậy cao được trả về như các phát hiện. Mô hình được huấn luyện trên bộ dữ liệu AMP [53], bao gồm 77.000 màn hình ứng dụng được thu thập và chú thích bởi các người chú thích từ 4.000 ứng dụng iPhone. Ngoài đầu phân loại loại phần tử tiêu chuẩn, được huấn luyện với phần còn lại của mô hình phát hiện đối tượng, chúng tôi đã thêm các đầu cho dự đoán khả năng chạm và dự đoán khả năng kéo. Các đầu bổ sung được huấn luyện độc lập với phần còn lại của mô hình bằng cách đầu tiên đóng băng backbone và huấn luyện các đầu trên các embedding tương ứng với các phần tử được phát hiện.

4 ÁP DỤNG HỌC LIÊN TỤC KHÔNG BAO GIỜ KẾT THÚC
Trong phần này, chúng tôi mô tả việc áp dụng khung học liên tục không bao giờ kết thúc của chúng tôi cho ba mô hình ngữ nghĩa UI: i) dự đoán khả năng chạm (ngữ nghĩa phần tử), ii) dự đoán khả năng kéo (ngữ nghĩa container), và iii) độ tương tự màn hình (ngữ nghĩa màn hình). Các mô hình khả năng chạm và khả năng kéo được huấn luyện hoàn toàn từ dữ liệu do trình thu thập dữ liệu tạo ra, trong khi trình thu thập dữ liệu đã tinh chỉnh mô hình độ tương tự màn hình hiện có ban đầu được huấn luyện bằng dữ liệu được chú thích bởi con người. Đối với mỗi ngữ nghĩa UI, chúng tôi đã phát triển một heuristic dựa trên tương tác được sử dụng bởi trình thu thập dữ liệu của chúng tôi để tự động tạo ra các ví dụ huấn luyện mới cho các mô hình của chúng tôi. Tiếp theo, chúng tôi đã thiết kế và huấn luyện các mô hình để dự đoán từng ngữ nghĩa này từ một ảnh chụp màn hình. Cuối cùng, để đặt bối cảnh cho các mô hình này trong bối cảnh học liên tục không bao giờ kết thúc, chúng tôi đã phân tích hiệu suất của chúng theo thời gian.

Thiết lập thí nghiệm. Chúng tôi đã tiến hành các thí nghiệm trên một danh sách 6.461 ứng dụng iOS miễn phí. Cho mục đích đánh giá, tất cả việc huấn luyện mô hình và thí nghiệm đều được thực hiện với các phần chia ngẫu nhiên huấn luyện (80%), xác thực (10%) và kiểm tra (10%). Chúng tôi đã phân vùng ngẫu nhiên danh sách ID ứng dụng của chúng tôi, đảm bảo rằng tất cả các màn hình UI từ một ứng dụng đều được chứa trong cùng một phần chia. Chúng tôi sử dụng thuật ngữ crawl epoch để chỉ một lần hoàn thành danh sách các ứng dụng. Lưu ý rằng không giống như một epoch qua một bộ dữ liệu huấn luyện, nội dung thực tế của một crawl epoch có thể thay đổi theo thời gian, do tính chất động của các ứng dụng.

Các thí nghiệm của chúng tôi đã phân tích hai khía cạnh của hiệu suất trình thu thập dữ liệu: i) chiến lược thu thập dữ liệu và ii) hiệu suất theo thời gian. Chúng tôi đã chạy ba biến thể của trình thu thập dữ liệu, có các chiến lược thu thập dữ liệu khác nhau: i) lựa chọn ngẫu nhiên các phần tử trên mỗi màn hình (Random), ii) lựa chọn các phần tử dẫn đến độ tin cậy dự đoán thấp từ các mô hình hiện tại (Uncertainty Sampled), và iii) một hybrid mà cho mỗi crawl epoch luân phiên giữa các chiến lược Random và Uncertainty Sampled, được lấy cảm hứng từ các phương pháp tương tự trong tối ưu hóa [40]. Để đánh giá hiệu suất theo thời gian, chúng tôi đã chạy mỗi chiến lược thu thập dữ liệu trong năm crawl epoch. Lưu ý rằng crawl epoch đầu tiên cho tất cả các chiến lược sử dụng Random để huấn luyện một mô hình dự đoán độ tin cậy ban đầu. Trong chiến lược Hybrid, bởi vì sự luân phiên xảy ra ở cấp epoch, epoch thứ hai được thu thập dữ liệu bằng chiến lược Uncertainty Sampled và do đó thông qua hai epoch, các đầu vào và kết quả là giống hệt nhau cho cả chiến lược Uncertainty Sampled và Hybrid. Ba chiến lược hoàn toàn phân kỳ bắt đầu từ epoch thứ ba. Trên tất cả các thí nghiệm, chúng tôi đã thu thập hơn nửa triệu ảnh chụp màn hình, mặc dù cùng một màn hình UI có thể đã được truy cập nhiều lần. Số lượng ảnh chụp màn hình trong bộ dữ liệu của chúng tôi lớn hơn đáng kể so với công trình trước đó [3, 10, 19, 48].

Các mô hình của trình thu thập dữ liệu được huấn luyện và đánh giá sau mỗi crawl epoch. Sau mỗi crawl epoch, việc huấn luyện mô hình được tiếp tục với dữ liệu cập nhật từ crawl mới nhất và trọng số mô hình được tối ưu hóa trong 100.000 bước tối ưu hóa (với early stopping). Để duy trì một bộ xác thực không đổi qua số lượng epoch khác nhau, chúng tôi chỉ sử dụng phần chia dữ liệu đánh giá từ epoch đầu tiên để tính toán các chỉ số hiệu suất. Cuối cùng, đối với các mô hình được huấn luyện hoàn toàn trên dữ liệu trình thu thập dữ liệu (khả năng chạm và khả năng kéo), chúng tôi đã thực hiện các đánh giá phụ epoch bổ sung trong crawl đầu tiên để phân tích tốc độ học.

Mặc dù bộ dữ liệu không được phát hành tại thời điểm xuất bản do các quy định nội bộ, chúng tôi đang điều tra các quy trình để làm cho nó có sẵn cho cộng đồng rộng lớn hơn. Để tái tạo công trình của chúng tôi, có thể sử dụng các công cụ và mô hình được xây dựng cho các nền tảng tương tự (ví dụ, Android). Các trình thu thập dữ liệu mã nguồn mở [25,45] có thể được tích hợp với các mô hình độ tương tự màn hình [48] và phát hiện phần tử có sẵn [3, 48, 51].

4.1 Khả năng chạm
Chạm là tương tác phổ biến nhất trên các thiết bị di động, tuy nhiên thường khó để tự động xác định liệu một phần tử có thể chạm được hay không do thiếu siêu dữ liệu và các tín hiệu trực quan mơ hồ. Ví dụ, một nút văn bản không có đủ độ tương phản hoặc thiếu đường viền có thể sẽ xuất hiện không thể chạm được với người dùng, và nhiều trò chơi thiếu các đặc điểm khả năng tiếp cận ngăn cản người dùng đọc màn hình sử dụng chúng. Suy luận chính xác về khả năng chạm có thể hỗ trợ các nhà thiết kế trong việc tìm ra các phần tử trực quan mơ hồ và hữu ích để tạo ra siêu dữ liệu để sửa chữa các ứng dụng không thể tiếp cận. Công trình trước đó đã sử dụng các ảnh chụp màn hình UI được chú thích bởi con người để huấn luyện các mô hình học máy về khả năng chạm. Tuy nhiên, quy trình này đáng ngạc nhiên là dễ xảy ra lỗi [20,21,38,42] do các tín hiệu trực quan mơ hồ, điều này cho thấy rằng các ảnh chụp màn hình được chú thích bởi con người là một nguồn ground-truth không đáng tin cậy để huấn luyện các mô hình khả năng chạm. Ngược lại, trình thu thập dữ liệu của chúng tôi có thể sử dụng bối cảnh bổ sung từ toàn bộ tương tác, chẳng hạn như ảnh chụp màn hình trước và sau thay vì một ảnh chụp màn hình trước duy nhất, để xác định liệu việc chạm có dẫn đến hiệu ứng hay không. Hiệu ứng có thể là các thay đổi trạng thái, như lật một toggle, hoặc chuyển đổi đến một màn hình mới. Chúng tôi đã phát triển một heuristic để suy luận khả năng chạm từ các tương tác được ghi lại của trình thu thập dữ liệu và thấy rằng nó có sự đồng thuận cao với các video được chú thích bởi con người. Chúng tôi đã sử dụng dữ liệu được gắn nhãn heuristic để huấn luyện một mô hình "head" khả năng chạm hiệu quả hoàn toàn từ dữ liệu được chú thích bởi trình thu thập dữ liệu. Sau năm crawl epoch, mô hình khả năng chạm có hiệu suất tốt nhất đạt điểm F1 là 0.860.

4.1.1 Heuristic khả năng chạm. Chúng tôi đã phát triển một heuristic để suy luận khả năng chạm của một phần tử dựa trên ảnh chụp màn hình của UI được chụp trước, trong và sau một tương tác chạm. Một lần chạm có thể dẫn đến một số kịch bản khác nhau, được heuristic của chúng tôi ghi lại. Đầu tiên, chúng tôi sử dụng một mô hình độ tương tự màn hình để so sánh các ảnh chụp màn hình được chụp trước và sau lần chạm để xác định liệu lần chạm có dẫn trình thu thập dữ liệu đến một màn hình mới hay không. Nếu không phát hiện thay đổi màn hình, lần chạm cũng có thể đã thay đổi trạng thái màn hình. Chúng tôi tính toán sự khác biệt dựa trên pixel của ảnh chụp màn hình "trước" và "sau" để xác định các chỉ báo trực quan có thể về các thay đổi cục bộ hoặc toàn cục, chẳng hạn như chạm vào hộp kiểm hoặc làm mới nội dung màn hình tương ứng. Cuối cùng, để giảm false positive, heuristic cũng sử dụng nhiều ảnh chụp màn hình được chụp trước lần chạm để xác định các khu vực động của màn hình (ví dụ, video) có các thay đổi trực quan không liên quan đến lần chạm.

Để xác thực độ chính xác của heuristic của chúng tôi, chúng tôi đã so sánh kết quả của nó với các video tương tác được gắn nhãn bởi con người. Chúng tôi đã sử dụng trình thu thập dữ liệu của mình để lưu các video ghi màn hình ngắn về các tương tác chạm được thu thập trong quá trình crawl. Mỗi video ví dụ dài khoảng 10 giây và bao gồm vị trí chạm được phủ lên video và bối cảnh thời gian trước và sau tương tác chạm, chẳng hạn như bao gồm hoạt ảnh chuyển đổi và tải.

Chúng tôi đã lấy mẫu ngẫu nhiên một tập hợp con cân bằng gồm 1000 video clip từ các crawl của chúng tôi và hỏi các người chú thích con người liệu mỗi video clip có chứa tương tác chạm hay không. Các người chú thích được tuyển dụng, đào tạo và trả lương bởi một nhóm riêng biệt tại tổ chức của chúng tôi (tất cả với sự chấp thuận pháp lý/đạo đức thích hợp). Các người chú thích là nhân viên được trả lương cạnh tranh theo giờ cho vị trí của họ. Chúng tôi đã sử dụng các chỉ số phân loại tiêu chuẩn để đánh giá độ chính xác của heuristic của chúng tôi, sử dụng các nhãn được chú thích bởi con người làm ground truth. Heuristic khả năng chạm có độ chính xác tổng thể là 0.934, và có số lượng false positive tương tự (38 trường hợp) và false negative (28 trường hợp).

4.1.2 Triển khai mô hình. Để dự đoán khả năng chạm, chúng tôi đã thiết kế một kiến trúc mô hình hoạt động như một "head" của mô hình phát hiện phần tử hiện có của chúng tôi (Hình 3). Head là các mạng con nhỏ hoặc tập hợp các lớp thường được đặt gần lớp đầu ra của kiến trúc mạng nơ-ron và tạo ra dự đoán từ các biểu diễn đặc trưng của đầu vào chính được tạo ra bởi mạng "backbone". Vì phát hiện phần tử có liên quan chặt chẽ với khả năng chạm, chúng tôi đã giả định rằng các biểu diễn đã học trước đó có thể chứa thông tin liên quan và đẩy nhanh đáng kể việc học khả năng chạm. Mô hình head của chúng tôi là một mô hình feed-forward ba lớp đơn giản với kích thước đầu vào là 128, kích thước ẩn là 64 mà chúng tôi đã chọn thông qua điều chỉnh thủ công, và kích thước đầu ra là 1 cho độ tin cậy khả năng chạm. Để huấn luyện nó, chúng tôi đầu tiên đóng băng trọng số của mạng backbone của bộ phát hiện phần tử và khởi tạo ngẫu nhiên các tham số của mạng feed-forward của chúng tôi. Trong khi đóng băng hầu hết mô hình giảm khả năng của nó, nó cũng dẫn đến giảm đáng kể thời gian huấn luyện, vì có ít tham số hơn để tối ưu hóa. Sau đó chúng tôi đã huấn luyện mô hình để dự đoán khả năng chạm của một phần tử từ ảnh chụp màn hình của UI trước lần chạm, và chúng tôi đã sử dụng các nhãn được tạo ra bởi heuristic khả năng chạm của chúng tôi làm ground truth.

4.1.3 Đánh giá hiệu suất. Kết quả của các thí nghiệm của chúng tôi được hiển thị trong Hình 4. Trong khi tất cả các chiến lược thu thập dữ liệu đều thành công trong việc cải thiện mô hình ban đầu từ epoch đầu tiên, trình thu thập dữ liệu Random có hiệu suất cuối cùng tốt nhất. Trong các thí nghiệm của chúng tôi, trình thu thập dữ liệu Random đạt điểm F1 cuối cùng tốt nhất là 0.860 trong khi trình thu thập dữ liệu Uncertainty Sampled đạt điểm F1 cuối cùng thấp nhất là 0.853. Mặc dù không thể so sánh trực tiếp với công trình trước đó [38,42] vì các thí nghiệm của họ được chạy trên các bộ dữ liệu khác nhau, có vẻ như mô hình khả năng chạm của chúng tôi có thể đạt được mức hiệu suất tương tự về điểm F1 sau epoch đầu tiên của nó.

Chúng tôi cũng đã tiến hành so sánh giữa chất lượng của bộ dữ liệu khả năng chạm được thu thập tự động của chúng tôi và những bộ được chú thích bởi con người, chúng tôi đã sử dụng các nhãn được cung cấp bởi bộ dữ liệu AMP [53]. Đầu tiên, chúng tôi đã huấn luyện kiến trúc mô hình classification head của chúng tôi trên AMP, dẫn đến hiệu suất tương tự (F1=0.81) với các con số được báo cáo ban đầu (cũng F1=0.81), sử dụng kiến trúc mô hình dựa trên cây. Tuy nhiên, khi chúng tôi sử dụng mô hình được huấn luyện trên dữ liệu được chú thích bởi con người để dự đoán khả năng chạm của các phần tử trong bộ dữ liệu đã crawl của chúng tôi, chúng tôi đã quan sát thấy hiệu suất giảm đáng kể (F1=0.60), cho thấy rằng các nhãn được chú thích bởi con người và được tạo ra bởi trình thu thập dữ liệu không đồng ý với nhau. Chúng tôi coi dữ liệu được chú thích heuristic là chất lượng cao hơn vì hiệu suất của nó được xác thực bởi các người chú thích có quyền truy cập vào video clip của toàn bộ tương tác chạm, và công trình trước đó [38] đã cho thấy việc dự đoán khả năng chạm phần tử từ một ảnh chụp màn hình duy nhất dẫn đến phương sai cao giữa các người đánh giá.

4.2 Khả năng kéo
Kéo là một tương tác phổ biến trong các ứng dụng di động liên quan đến việc chạm vào một phần tử trên màn hình bằng ngón tay và di chuyển ngón tay dọc theo bề mặt màn hình trước khi thả ra. Tương tác này được sử dụng để thao tác các điều khiển, chẳng hạn như thanh trượt và điều khiển trang, và cần thiết để truy cập nội dung ngoài màn hình thông qua cuộn. Mặc dù các ví dụ này phản ánh các loại đầu vào khác nhau, chúng tôi gọi chung tất cả các hành động này là "khả năng kéo", vì chúng liên quan đến chuyển động vật lý tương tự. Không giống như các phần tử có thể chạm, các phần tử có thể kéo thường có ít dấu hiệu trực quan hơn và khó phát hiện tự động hơn. Theo hiểu biết tốt nhất của chúng tôi, không có bộ dữ liệu nào có sẵn với các nhãn khả năng kéo, và chúng tôi tin rằng, tương tự như khả năng chạm, sẽ rất khó để người gắn nhãn con người xác định đáng tin cậy các phần tử có thể kéo từ ảnh chụp màn hình. Để cải thiện hỗ trợ đọc màn hình cho các ứng dụng không thể tiếp cận với các khả năng sử dụng này, chúng tôi đã sử dụng trình thu thập dữ liệu của mình để tự động tìm và gắn nhãn các ví dụ thông qua tương tác tự động. Chúng tôi đã phát triển một heuristic để suy luận khả năng kéo từ ảnh chụp màn hình của các tương tác kéo. Sử dụng dữ liệu được gắn nhãn bằng phương pháp này, chúng tôi đã huấn luyện một mô hình khả năng kéo đạt điểm F1 là 0.794 sau năm crawl epoch.

4.2.1 Heuristic khả năng kéo. Để phát hiện liệu một phần tử UI có thể kéo được hay không, trình thu thập dữ liệu của chúng tôi chụp ảnh màn hình trong khi cố gắng giữ và kéo các phần tử. Trình thu thập dữ liệu của chúng tôi đầu tiên xác định các ứng cử viên có khả năng, sau đó mô phỏng các hành động kéo sang trái (ví dụ, ngón tay đi sang trái) và hướng lên trên để phát hiện kéo ngang và dọc, tương ứng. Các hướng này được chọn vì chúng tương ứng với vị trí ban đầu của danh sách theo hướng đọc từ trái sang phải, và chúng tôi thực hiện các hành động kéo từ trung tâm của phần tử đến ranh giới trái hoặc trên của nó. Trình thu thập dữ liệu chụp một ảnh màn hình trước khi kéo bắt đầu và một ảnh màn hình ở cuối lượt kéo nhưng trước khi "ngón tay" của nó rời khỏi màn hình.

Ý tưởng cấp cao của heuristic là phát hiện phần tử UI nào, nếu có, "theo ngón tay" theo hướng kéo. Chúng tôi đầu tiên sử dụng phần tử UI nhỏ nhất chứa pixel được kéo trên ảnh trước khi kéo để tạo ra một patch hình ảnh. Patch hình ảnh này được khớp mẫu với ảnh sau khi kéo bằng phương pháp hệ số tương quan chuẩn hóa trên hình ảnh được chuyển đổi thành xám và phát hiện cạnh. Vector tương ứng với sự dịch chuyển mẫu được lọc theo góc cosine và độ lớn. Tiếp theo, các patch bên trong hộp giới hạn giữa màn hình trước khi kéo và sau khi kéo được so sánh để xác định liệu có các phần tử khác đã cuộn trong quá trình hành động kéo hay không. Nếu nội dung của hộp giới hạn trong ảnh trước khi kéo khớp với nội dung của hộp giới hạn được dịch chuyển bởi vector dịch chuyển mẫu trong ảnh sau khi kéo, thì có khả năng đó là một phần tử UI đã được cuộn cùng với phần tử UI ban đầu. Chúng tôi sử dụng phương pháp hệ số tương quan chuẩn hóa để đo độ tương tự giữa các patch hình ảnh này, trên hình ảnh được chuyển đổi thành xám và phát hiện cạnh. Nếu không có phần tử cuộn nào được xác định, phần tử UI ban đầu cũng được đánh dấu là không thể kéo để lọc ra các false positive.

Chúng tôi đã tiến hành đánh giá heuristic của chúng tôi trên 1000 mẫu, được tạo ra bằng cách chạy heuristic trên các màn hình được thu thập từ một crawl ngẫu nhiên, sau đó chọn 500 màn hình nơi heuristic được kích hoạt và 500 màn hình nơi nó không được kích hoạt. Do một lỗi, trình thu thập dữ liệu của chúng tôi không ghi lại video tương tác của tương tác khả năng kéo, tuy nhiên chúng tôi thấy rằng việc suy luận khả năng kéo từ các ảnh chụp màn hình trước/sau được chụp là đơn giản. Đối với mỗi bước tương tác, chúng tôi đã trình bày cho người chú thích ba hình ảnh, hình ảnh trước khi kéo, hình ảnh sau khi kéo và hình ảnh kết hợp với cả hai hình ảnh trước và sau được chồng lên nhau, cho phép dễ dàng hình dung chuyển động hơn. Các hình ảnh được chú thích bằng một mũi tên chỉ ra vị trí kéo diễn ra. Một lần nữa, chúng tôi đã sử dụng các nhãn do con người cung cấp làm ground-truth để đánh giá dự đoán của heuristic của chúng tôi. Heuristic khả năng kéo có độ chính xác tổng thể là 0.92, và số lượng false positive tương tự (38 trường hợp) và false negative (48 trường hợp).

4.2.2 Triển khai mô hình. Không giống như khả năng chạm, là một ngữ nghĩa phần tử, khả năng kéo thường liên quan đến các container chứa nhiều phần tử. Chúng tôi ban đầu đã cố gắng sử dụng cùng kiến trúc mô hình "head" như mô hình khả năng chạm của chúng tôi, tái sử dụng các tính năng phần tử được tạo ra bởi mô hình phát hiện của chúng tôi, tuy nhiên chúng tôi thấy rằng mô hình này đạt được hiệu suất thấp (điểm F1=0.2). Sau khi kiểm tra kỹ hơn các ví dụ bị phân loại sai, chúng tôi nhận thấy rằng các dấu hiệu trực quan cho khả năng kéo của một phần tử thường là phi địa phương (tức là xuất hiện ở nơi khác trên màn hình). Ví dụ, một hình ảnh có nhiều khả năng hỗ trợ vuốt nếu chỉ báo điều khiển trang được đặt bên dưới nó, và khả năng cuộn trong các ứng dụng di động thường được suy luận tốt nhất bằng cách tìm kiếm các phần tử bị che khuất một phần ở cuối danh sách hoặc gần các cạnh của màn hình. Bởi vì bộ phát hiện phần tử đặc trưng hóa các vùng hình ảnh bằng cách gộp thông tin trực quan gần đó, nó bỏ qua nhiều tín hiệu liên quan cho tác vụ này.

Dựa trên các quan sát này, chúng tôi đã thiết kế một mô hình dựa trên kiến trúc transformer, cho phép nó kết hợp thông tin từ toàn bộ màn hình vào dự đoán của nó. Chúng tôi đầu tiên sử dụng bộ phát hiện phần tử của chúng tôi để đặc trưng hóa tất cả các phần tử được phát hiện trên màn hình. Các embedding phần tử sau đó được đưa vào các lớp self-attention để tạo ra một embedding có ngữ cảnh. Cuối cùng, các embedding có ngữ cảnh của các phần tử được đưa vào một bộ phân loại tuyến tính với một nút đầu ra duy nhất để phân loại khả năng kéo. Trong khi huấn luyện mô hình khả năng kéo, trọng số của bộ phát hiện phần tử cũng được đóng băng để cải thiện hiệu quả huấn luyện. Đối với các màn hình nơi heuristic khả năng kéo không được kích hoạt, loss chỉ được tính toán cho phần tử được tương tác trực tiếp. Đối với các màn hình nơi heuristic khả năng kéo được kích hoạt, loss được tính toán trên tất cả các phần tử bị ảnh hưởng bởi lượt kéo. Trong cả hai trường hợp, các phần tử không di chuyển cùng với ngón tay được bỏ qua trong tính toán loss, vì không thể biết chắc chắn liệu chúng có không thể kéo được hay không mà không tương tác với chúng.

4.2.3 Đánh giá hiệu suất. Đánh giá của chúng tôi về mô hình khả năng kéo tập trung vào hiệu suất theo thời gian (Xem Hình 7).

Kết quả của các thí nghiệm của chúng tôi được hiển thị trong Hình 7. Trình thu thập dữ liệu Hybrid có hiệu suất cuối cùng cao nhất (F1=0.794), trong khi trình thu thập dữ liệu Uncertainty Sampled thấp nhất (F1=0.770). Thú vị là, cả hai lần crawl Uncertainty Sampled và Hybrid đều trải qua giảm hiệu suất trong epoch crawl thứ hai. Trong khi trình thu thập dữ liệu Uncertainty Sampled tiếp tục giảm, trình thu thập dữ liệu Hybrid đã chuyển sang chiến lược crawl ngẫu nhiên của nó và bắt đầu cải thiện nhanh chóng. Chúng tôi giả định rằng việc lấy mẫu không chắc chắn trong epoch thứ hai có thể đã làm mất cân bằng bộ dữ liệu bằng cách thu thập nhiều ví dụ về các phần tử tương tự trong khi bỏ qua các phần tử khác, và do đó ảnh hưởng tiêu cực đến mô hình tiếp theo.

Từ kết quả thí nghiệm và quan sát mang tính chất giai thoại của chúng tôi, chúng tôi giả định rằng khả năng kéo khó suy luận hơn từ thông tin trực quan tĩnh một mình do thiếu các tín hiệu cục bộ, và cách tốt nhất để khám phá chức năng liên quan đến kéo có thể là học từ việc sử dụng mở rộng. Trong một số trường hợp, có thể thích hợp để áp dụng trực tiếp heuristic khả năng kéo trong thời gian chạy. Trái ngược với chạm, có khả năng thay đổi trạng thái của UI hoặc đưa người dùng đến một trang mới, chúng tôi giả định rằng nhiều tương tác kéo ít có khả năng dẫn đến tác dụng phụ hơn. Mô hình của chúng tôi có thể được sử dụng để đầu tiên xác định các ứng cử viên có khả năng cho việc xác minh dựa trên tương tác.

Tương tự như mô hình khả năng chạm, chúng tôi cũng quan sát thấy những cải thiện nhỏ về hiệu suất theo thời gian; tuy nhiên, có ít cải thiện tổng thể hơn đối với hiệu suất khả năng kéo. Một lý do có thể là vì khả năng kéo khó suy luận hơn về mặt trực quan, mô hình đã đạt đến trần của nó sớm hơn.

4.3 Độ tương tự màn hình
Chúng tôi đã sử dụng trình thu thập dữ liệu của mình để cải thiện khả năng hiểu màn hình của nó bằng cách sử dụng các tương tác của nó để xác thực và huấn luyện lại mô hình độ tương tự màn hình. Một mô hình độ tương tự màn hình chính xác hơn cho phép trình thu thập dữ liệu của chúng tôi xác định đáng tin cậy hơn những màn hình ứng dụng nào mà nó đã truy cập trong một ứng dụng, và do đó tăng hiệu quả khám phá của nó. Các mô hình độ tương tự màn hình cũng đã được sử dụng trong các loại ứng dụng kỹ thuật phần mềm khác, chẳng hạn như xử lý video sử dụng ứng dụng di động [9], kiểm thử phần mềm tự động [26,27] và tạo storyboard tự động [7]. Feiz et al. lưu ý rằng do kỹ thuật gắn nhãn của họ, bộ dữ liệu của họ chứa nhiều ví dụ về các cặp màn hình mới hơn các cặp màn hình giống nhau. Chúng tôi đã khai thác các ví dụ bổ sung về các cặp màn hình giống nhau từ các tương tác được ghi lại của trình thu thập dữ liệu để bổ sung dữ liệu huấn luyện ban đầu và tinh chỉnh mô hình ban đầu bằng cách giảm tỷ lệ học với hệ số 10. So với điều kiện baseline nơi mô hình độ tương tự màn hình được huấn luyện bằng bộ dữ liệu không sửa đổi (với cùng tỷ lệ học giảm), chúng tôi thấy rằng bộ dữ liệu được bổ sung dẫn đến hiệu suất tốt hơn một cách nhất quán.

4.3.1 Tạo dữ liệu. Chúng tôi không giới thiệu một heuristic dựa trên tương tác mới để thu thập nhãn cho độ tương tự màn hình. Thay vào đó, chúng tôi tái sử dụng dữ liệu được chụp từ heuristic khả năng chạm và khả năng kéo. Cả hai heuristic đều chụp hai ảnh màn hình trước khi bắt đầu tương tác để xác định các vùng hoạt ảnh hoặc động của màn hình có thể gây ra false positive cho việc phát hiện khả năng chạm và khả năng kéo. Tuy nhiên, những ví dụ tương tự này cũng có thể được sử dụng để tìm các ví dụ về dự đoán false negative từ bộ phân loại độ tương tự màn hình của chúng tôi. Chúng tôi giả định rằng các ảnh chụp màn hình trước tương tác thuộc về cùng một màn hình, vì bất kỳ biến thể trực quan nào giữa chúng đều không được gây ra bởi đầu vào của người dùng. Chúng tôi đưa ra các giả định tương tự về dữ liệu được thu thập từ heuristic khả năng kéo, vì ảnh chụp màn hình cuối cùng được chụp trước khi cử chỉ kéo được hoàn thành (tức là trước khi ngón tay được thả khỏi màn hình) và không có khả năng dẫn đến một màn hình mới. Chúng tôi sử dụng các nguồn này để tạo ra một bộ dữ liệu các cặp ảnh chụp màn hình của các cặp màn hình giống nhau, và chúng tôi đã chạy mô hình độ tương tự màn hình hiện có của chúng tôi để tìm kiếm các dự đoán không chính xác, có thể được sử dụng để huấn luyện lại mô hình. Dựa trên quy trình này, chúng tôi đã khai thác khoảng 2000 ví dụ mới từ mỗi epoch.

4.3.2 Triển khai mô hình. Mô hình độ tương tự màn hình ban đầu được huấn luyện trên một bộ dữ liệu chứa cả ví dụ về các cặp tích cực (cùng màn hình) và tiêu cực (màn hình khác nhau), điều này làm cho có thể tối ưu hóa bằng cách sử dụng contrastive margin loss [13].

Ở mức độ cao, mô hình ánh xạ các ảnh chụp màn hình vào không gian embedding, và loss đảm bảo rằng các màn hình tương tự ở gần nhau (tức là có khoảng cách nhỏ hơn giá trị margin) trong khi các màn hình khác nhau ở xa nhau hơn.

L_sim = (||Δh||² nếu s₁ = s₂, max(0, m - ||Δh||²) nếu khác)

Để tinh chỉnh mô hình, chúng tôi sử dụng cùng mục tiêu huấn luyện nhưng giảm tỷ lệ học xuống lr = 1e⁻⁵, thấp hơn mười lần so với giá trị ban đầu được sử dụng để huấn luyện mô hình. Chúng tôi ban đầu đã cố gắng sử dụng các cặp màn hình giống nhau mới được khai thác để tinh chỉnh mô hình mà không trộn nó với bộ dữ liệu gốc. Tuy nhiên, điều này không thành công, vì chỉ tập trung vào thuật ngữ "tương tự" (s₁ = s₂) dẫn đến trường hợp thất bại nơi mô hình học để ánh xạ tất cả các ảnh chụp màn hình đến cùng một điểm trong không gian embedding, vì nó chỉ bị phạt nếu các màn hình tương tự ở xa nhau nhưng không nếu các màn hình khác biệt ở gần nhau. Do đó, chúng tôi đã "trộn" trực tiếp các ví dụ mới được khai thác với phần còn lại của bộ dữ liệu gốc, bao gồm 800.000 cặp được gắn nhãn.

4.3.3 Đánh giá hiệu suất. Chúng tôi đã đo hiệu suất so với phần chia đánh giá của bộ dữ liệu gốc vì dữ liệu được tạo ra của chúng tôi chỉ chứa các cặp màn hình giống nhau, điều này làm cho việc tính toán precision trở nên không thể. Kết quả được hiển thị trong Hình 9. Bởi vì mô hình độ tương tự màn hình không ảnh hưởng đến các hành động được chọn của trình thu thập dữ liệu (ví dụ, các lần chạm và kéo được thử), chúng tôi chỉ đánh giá phương pháp của chúng tôi trên dữ liệu từ crawl Random. Nhìn chung, chúng tôi thấy rằng việc sử dụng bộ dữ liệu được tạo ra bởi trình thu thập dữ liệu để tinh chỉnh mô hình dẫn đến những cải thiện nhỏ nhưng nhất quán về hiệu suất theo thời gian. Mô hình độ tương tự màn hình được cải thiện từ điểm F1 ban đầu là 0.636 đến điểm F1 cuối cùng là 0.663. Mặc dù được huấn luyện trên bộ dữ liệu gốc, mô hình baseline cũng được cải thiện do tỷ lệ học giảm. Một thực hành phổ biến trong huấn luyện mạng nơ-ron là giảm tỷ lệ học sau khi hiệu suất đạt đến plateau, có thể cho phép mô hình tiếp tục cải thiện. Mô hình baseline đã cải thiện mô hình ban đầu đến điểm F1 cuối cùng là 0.659.

Nếu trình thu thập dữ liệu chạy vô thời hạn, nó sẽ cần một cơ chế nào đó để bỏ qua một tập hợp con của dữ liệu được thu thập để tránh sự mất cân bằng dữ liệu cuối cùng do việc thu thập chỉ các cặp màn hình giống nhau. Một số kỹ thuật có thể tồn tại để hợp nhất và chưng cất các bộ dữ liệu để giữ lại các mẫu thông tin nhất [32,33,47]. Trong khi chúng tôi tin rằng các phương pháp này có thể áp dụng được, chúng tôi để lại khía cạnh xác thực này cho công việc tương lai.

5 THẢO LUẬN
Các thí nghiệm của chúng tôi đã tiết lộ rằng các mô hình UI trực quan có thể được huấn luyện và cải thiện hiệu quả thông qua tương tác tự động, liên tục. Trong phần này, chúng tôi thảo luận về i) hiệu suất của việc triển khai Never-ending UI Learner cụ thể của chúng tôi, ii) các loại học dựa trên tương tác khác, và iii) lợi ích của việc áp dụng các chiến lược này trong một khoảng thời gian rất dài hoặc có thể vô hạn.

5.1 Hiệu suất Never-ending UI Learner
Trong bài báo này, chúng tôi đã tiến hành một loạt thí nghiệm đánh giá Never-ending UI Learner và khả năng tự động học ngữ nghĩa UI của nó. Các thí nghiệm của chúng tôi điều tra hai câu hỏi chính: i) cách tốt nhất để một trình thu thập dữ liệu tự động học về UI là gì? và ii) nó cần chạy bao lâu?

Chiến lược thu thập dữ liệu. Các thí nghiệm của chúng tôi tập trung vào ba chiến lược thu thập dữ liệu để khám phá các ứng dụng di động: i) thu thập dữ liệu ngẫu nhiên, ii) lấy mẫu không chắc chắn, và iii) chiến lược hybrid. Nhìn chung, chiến lược ngẫu nhiên đã liên tục dẫn đến hiệu suất mạnh mẽ trong tất cả các thí nghiệm của chúng tôi. Chúng tôi ban đầu giả định rằng lấy mẫu không chắc chắn, một kỹ thuật học tích cực cải thiện hiệu quả lấy mẫu bằng cách ưu tiên các ví dụ có độ tin cậy mô hình thấp, sẽ cho phép mô hình học hiệu quả và hiệu quả hơn. Tuy nhiên, bởi vì trình thu thập dữ liệu của chúng tôi đã cập nhật các mô hình của nó (được sử dụng để tính toán độ tin cậy dự đoán) mỗi epoch thay vì sau mỗi mẫu (như thường được thực hiện trong các ứng dụng nơi lấy mẫu không chắc chắn được sử dụng), nó dẫn đến việc thu thập dữ liệu mất cân bằng trong các lần crawl tiếp theo, làm giảm hiệu suất. Trình thu thập dữ liệu hybrid luân phiên giữa các chiến lược lấy mẫu ngẫu nhiên và không chắc chắn, cho phép nó học từ các dự đoán có độ tin cậy thấp trong khi cũng sửa chữa sự dịch chuyển phân phối được gây ra bởi việc lấy mẫu không chắc chắn hàng loạt. Nhìn chung, nó dẫn đến hiệu suất tương tự với việc thu thập dữ liệu ngẫu nhiên thuần túy, mặc dù nó ít nhất quán hơn. Trong tác vụ khả năng kéo, nó ban đầu giảm hiệu suất nhưng trải qua cải thiện nhanh chóng sau đó. Cuối cùng, các thí nghiệm của chúng tôi không tiết lộ một lựa chọn rõ ràng, và chúng tôi tin rằng có chỗ để khám phá các chiến lược bổ sung [12] và đánh giá dài hạn hơn, mà chúng tôi để lại cho công việc tương lai.

Hiệu suất theo thời gian. Mặc dù trình thu thập dữ liệu của chúng tôi được thiết kế để chạy vô thời hạn, các thí nghiệm của chúng tôi tập trung vào một khoảng thời gian tương đối ngắn là năm crawl epoch. Mỗi crawl epoch kéo dài khoảng nửa tuần (thời gian thực) khi được song song hóa trên nhiều crawler worker và bao gồm khoảng 500 giờ thiết bị tương tác ứng dụng, xử lý dữ liệu sau và huấn luyện mô hình. Trên tất cả các thí nghiệm, Never-ending UI Learner đã crawl trong hơn 5.000 giờ thiết bị, được thực hiện trong khoảng thời gian khoảng một tháng.

Kết quả của chúng tôi cho thấy rằng cửa sổ này đủ để học các mô hình chính xác hoàn toàn từ dữ liệu do trình thu thập dữ liệu thu thập (khả năng chạm và khả năng kéo) hoặc tinh chỉnh các mô hình hiện có (độ tương tự màn hình). Nhìn chung, chúng tôi thấy rằng các mô hình có học nhanh ban đầu sau đó là cải thiện chậm hơn, điều này phù hợp với các quan sát thực nghiệm trong nghiên cứu học máy cho thấy mối quan hệ mũ giữa kích thước bộ dữ liệu và hiệu suất mô hình [41]. Chúng tôi tin rằng những cải thiện nhỏ này có giá trị, vì lợi ích của chúng có thể được phóng đại khi chạy trong các khoảng thời gian có thể rất dài và cho phép mô hình được cập nhật liên tục. Chúng tôi dự định tiếp tục chạy trình thu thập dữ liệu, không yêu cầu giám sát của con người, để quan sát xu hướng trong các khoảng thời gian dài hơn và tối đa hóa tiềm năng của phương pháp học tự động của chúng tôi.

Quan sát mang tính chất giai thoại. Dựa trên thử nghiệm của chúng tôi, chúng tôi đã tìm thấy một số khía cạnh ảnh hưởng đến hiệu suất của các hệ thống học liên tục không bao giờ kết thúc như của chúng tôi. Chúng tôi đưa ra các quan sát mang tính chất giai thoại có thể hữu ích cho việc sao chép hoặc triển khai các hệ thống tương tự.

• Chọn ví dụ. Trong bài báo này, chúng tôi chủ yếu khám phá hai phương pháp (ngẫu nhiên và dựa trên không chắc chắn) để chọn ví dụ huấn luyện. Chúng tôi thấy rằng lựa chọn ngẫu nhiên là một baseline mạnh mẽ, và các phương pháp học tích cực (ví dụ, lấy mẫu không chắc chắn) có thể hiệu quả với các siêu tham số thích hợp. Có nhiều thứ để khám phá theo khía cạnh này, bao gồm việc sử dụng lịch sử trình thu thập dữ liệu để giảm sự dư thừa mẫu, mà chúng tôi đã quan sát trong dữ liệu crawl của chúng tôi.

• Tần suất huấn luyện lại. Tần suất crawl lại và huấn luyện lại có thể ảnh hưởng đến hiệu suất của hệ thống bằng cách thay đổi cấu trúc của dữ liệu huấn luyện. Các thí nghiệm trong bài báo này được chạy trong khoảng thời gian khoảng một tháng với một lần lặp cập nhật mỗi 1-2 ngày, vì vậy các thay đổi ứng dụng mà chúng tôi chứng kiến chủ yếu là do các thay đổi trong nội dung động. Chúng tôi tin rằng các cập nhật ít thường xuyên hơn có thể hiệu quả (ví dụ, hàng tháng) có thể nắm bắt được những thay đổi đáng kể hơn như cập nhật ứng dụng hoặc hướng dẫn thiết kế mới hơn.

• Dữ liệu đánh giá. Chúng tôi đã sử dụng một phần chia đánh giá cố định để so sánh trực tiếp hiệu suất mô hình theo thời gian. Sử dụng dữ liệu từ crawl mới nhất có thể cho phép ước tính hiệu suất thế giới thực chính xác hơn; tuy nhiên, việc so sánh các mô hình qua các epoch ít đơn giản hơn, vì các thay đổi có thể được gây ra bởi hiệu suất mô hình hoặc thay đổi dữ liệu xác thực. Cuối cùng, việc sử dụng một bộ xác thực có kích thước động có thể hữu ích nếu các mô hình được triển khai trong các kịch bản nơi hiệu suất trên cả ứng dụng cũ và mới đều quan trọng.

5.2 Học từ tương tác
Công trình của chúng tôi đóng góp ý tưởng rằng các tương tác tự động có thể được sử dụng để tạo ra các bộ dữ liệu cho việc hiểu UI dựa trên mô hình. Hầu hết các bộ dữ liệu hiện tại sử dụng người chú thích con người và crowd worker để tạo ra nhãn cho các bộ dữ liệu UI di động, chẳng hạn như hộp giới hạn phần tử UI, loại icon và ghép đôi độ tương tự màn hình. Trong khi gắn nhãn bởi con người đã là một tiêu chuẩn de facto để tạo ra bộ dữ liệu, đặc biệt là cho các lĩnh vực nơi yêu cầu khối lượng dữ liệu cho học tự giám sát không khả thi, các chú thích do crowd worker tạo ra được biết là dễ bị lỗi và thiên vị [8,36]. Hơn nữa, nhiều tác vụ mã hóa ngầm một mức độ chủ quan. Một ví dụ như vậy là dự đoán khả năng chạm, nơi người chú thích sử dụng phán đoán của riêng họ để quyết định liệu một phần tử UI cụ thể trong ảnh chụp màn hình có thể chạm được hay không. Nhãn cho các tác vụ như vậy được biết là nhiễu trong thực tế, và thường được tính trung bình hoặc bỏ phiếu từ nhiều crowd worker, làm tăng thêm thời gian và chi phí của nhãn do con người tạo ra [38]. Ngược lại, học dựa trên tương tác tự động có thể giảm thiểu đáng kể thiên vị của người chú thích, vì nhãn được tạo ra thông qua kiểm tra giả thuyết. Tuy nhiên, có thể có những trường hợp mà việc mã hóa thông tin nhận thức vào nhãn có thể hữu ích, chẳng hạn như đưa ra phản hồi cho các nhà thiết kế về khả năng chạm được nhận thức. Trong các trường hợp khác, chẳng hạn như tạo ra thông tin khả năng tiếp cận, các nhãn được căn chỉnh chặt chẽ hơn với ground truth có thể được ưa chuộng. Hiểu được sự đánh đổi giữa các phương pháp này và tác động của chúng đến việc căn chỉnh mô hình là một cơ hội cho công việc tương lai.

Trong công trình của chúng tôi, chúng tôi đã cho thấy rằng học dựa trên tương tác có thể được sử dụng để mô hình hóa ngữ nghĩa phần tử (khả năng chạm), container (khả năng kéo) và cấp màn hình (độ tương tự màn hình) trong UI di động. Đối với các ứng dụng được kiểm tra của chúng tôi, chúng tôi thấy rằng các heuristic hoạt động với kiến thức về toàn bộ tương tác làm cho việc tạo nhãn tương đối đơn giản. Tuy nhiên, các heuristic có độ chính xác cao không phải lúc nào cũng dẫn đến các mô hình có độ chính xác cao vì mô hình phải đưa ra cùng một dự đoán với quyền truy cập vào ít dữ liệu hơn (tức là chỉ thông tin trực quan từ ảnh chụp màn hình tĩnh). Một số loại ngữ nghĩa dễ dàng hơn cho mô hình hóa trực quan hơn những loại khác. Mô hình khả năng chạm của chúng tôi đạt được hiệu suất phân loại cao, với điểm F1 là 0.860. Mặt khác, khả năng kéo khó dự đoán hơn nhiều từ ảnh chụp màn hình (F1=0.797).

Một câu hỏi tự nhiên để khám phá là: những loại ngữ nghĩa nào khác có thể được học thông qua tương tác? Ví dụ, các ngữ nghĩa liên quan như chức năng "nhấn và giữ" có thể được khám phá, và hộp văn bản có thể được hiểu rõ hơn bằng cách quan sát loại bàn phím phần mềm nào (ví dụ, bàn phím email hoặc số) xuất hiện khi nó được chạm vào. Phương pháp này có thể được mở rộng cho vấn đề phát hiện phần tử UI nói chung hay không, hiện tại phụ thuộc rất nhiều vào chú thích của con người? Có nhiều chi tiết cần được suy luận, chẳng hạn như kích thước và hình dạng của các phần tử UI, và tất nhiên là loại phần tử. Nhiều tương tác hơn sẽ cần thiết từ trình thu thập dữ liệu để xác định hộp giới hạn cho một phần tử nhất định, và có thể khó suy luận các loại phần tử phức tạp, nhưng một hệ thống hoạt động có thể làm điều này có thể học về các điều khiển tùy chỉnh và các phần tử không chuẩn khác mà các mô hình hiện tại không thể xử lý ngày hôm nay. Hiểu tốt hơn về UI tự động không chỉ có thể mang lại lợi ích trực tiếp cho các ứng dụng xuôi dòng mà còn thu thập dữ liệu tốt hơn để huấn luyện các mô hình.

5.3 Lợi ích của học liên tục không bao giờ kết thúc
Trình thu thập dữ liệu của chúng tôi được thiết kế để chạy vô thời hạn, cho phép nó tích lũy các ví dụ và huấn luyện trong các khoảng thời gian dài. Trong bài báo của chúng tôi, chúng tôi đã thử nghiệm với một số biến số (ví dụ, siêu tham số huấn luyện và chiến lược khám phá), điều này chỉ khả thi bằng cách tập trung vào một khoảng thời gian tương đối ngắn cho mỗi điều kiện (5 crawl epoch). Ngay cả từ khoảng thời gian ngắn này, chúng tôi có thể huấn luyện các mô hình cho ngữ nghĩa UI "từ đầu" và quan sát những cải thiện nhất quán đối với hiệu suất sau đó, nhưng chúng tôi tin rằng các mô hình của chúng tôi chưa đạt đến tiềm năng tối đa của chúng. Ngoài lợi ích hiệu suất, học liên tục không bao giờ kết thúc cho phép máy móc học từ các nguồn dữ liệu đa dạng. Học liên tục không bao giờ kết thúc có thể giúp máy móc xác định và học từ các sai lầm, đặc biệt là những sai lầm được gây ra bởi sự dịch chuyển trong phân phối dữ liệu do xu hướng sử dụng ứng dụng và xu hướng thiết kế.

Học liên tục không bao giờ kết thúc cũng giới thiệu những thách thức mới, như "quên thảm khốc", khả năng xóa thông tin đã học trước đó bằng cách huấn luyện trên dữ liệu mới, và những khó khăn liên quan đến các bộ dữ liệu lớn, ngày càng phát triển. Trong bài báo này, chúng tôi tiến hành một khám phá sơ bộ về các phương pháp để giải quyết một số thách thức này, chẳng hạn như lấy mẫu không chắc chắn, có thể giúp ưu tiên các loại dữ liệu nhất định. Đánh giá tài liệu của chúng tôi đã phát hiện ra nhiều kỹ thuật học máy khác có thể liên quan đến việc huấn luyện quá trình huấn luyện mô hình [4,18,28,37] hoặc chưng cất bộ dữ liệu được thu thập các mẫu liên quan [32,33,47]. Chúng tôi hy vọng rằng chúng sẽ hữu ích cho việc mở rộng quy mô và tối đa hóa hiệu suất của học UI liên tục không bao giờ kết thúc.

6 HẠN CHẾ & CÔNG VIỆC TƯƠNG LAI
Việc triển khai hiện tại của Never-ending UI learner bị hạn chế và mang đến các cơ hội để khám phá tương lai.

Đầu tiên, trình thu thập dữ liệu hiện tại của chúng tôi được triển khai bằng một bộ công cụ và cơ sở hạ tầng cụ thể được tùy chỉnh cho nền tảng mục tiêu của chúng tôi (iOS). Mặc dù chúng tôi không chạy thí nghiệm trên các loại UI khác (ví dụ, Android, giao diện dựa trên web), chúng tôi hy vọng kết quả của chúng tôi có thể tổng quát hóa được, vì phương pháp của chúng tôi không dựa trên bất kỳ siêu dữ liệu hoặc API cụ thể nào của nền tảng, và nghiên cứu trước đây đã cho thấy sự chồng chéo ngữ nghĩa giữa UI di động và web [48]. Các thí nghiệm của chúng tôi chủ yếu tập trung vào các ứng dụng miễn phí không yêu cầu xác thực (ví dụ, đăng ký và tạo tài khoản), điều này làm thiên vị tập hợp các màn hình UI được tiếp cận bởi việc crawl. Chúng tôi đã sử dụng các heuristic được thiết kế và xác minh thủ công cho một tập hợp nhỏ các ngữ nghĩa cho khả năng chạm và khả năng kéo. Chúng tôi tin rằng nhiều khía cạnh khác của UI và tương tác có thể được hình thành bằng các phương pháp tương tự. Một hạn chế khác của các thí nghiệm hiện tại của chúng tôi là chúng tôi không điều tra hiệu ứng của các phần chia train/test ngẫu nhiên khác nhau, có thể cung cấp thêm thông tin chi tiết về độ bền vững của phương pháp của chúng tôi. Bởi vì các thí nghiệm mất khoảng một tháng để hoàn thành, chi phí thời gian và tính toán cho các thử nghiệm lặp lại sẽ cao đến mức cấm. Tuy nhiên, vì danh sách ứng dụng của chúng tôi đủ lớn và được xáo trộn ngẫu nhiên, chúng tôi không mong đợi có sự biến đổi lớn về hiệu suất qua các phần chia ngẫu nhiên khác nhau.

Các dấu vết tương tác cá nhân hóa được thu thập trong các khoảng thời gian sử dụng dài có thể cải thiện hiệu suất của các mô hình cho các ứng dụng hiếm hơn, ngách hơn, mặc dù một phương pháp bảo vệ quyền riêng tư sẽ cần thiết (ví dụ, huấn luyện trên thiết bị). Một hướng thay thế là cho phép trình thu thập dữ liệu của chúng tôi tự động học các chuỗi tương tác để khám phá và gắn nhãn các khía cạnh mới của UI, thay vì thực hiện các heuristic được định nghĩa thủ công. Chúng tôi mong đợi các phiên bản tương lai của trình thu thập dữ liệu của chúng tôi sẽ kết hợp các kỹ thuật từ các lĩnh vực học máy liên quan, chẳng hạn như học tăng cường.

Cuối cùng, trình thu thập dữ liệu của chúng tôi có thể được hưởng lợi từ các khả năng hiểu UI được cải thiện. Đầu tiên, biểu diễn chính của trình thu thập dữ liệu về các màn hình mà nó truy cập là một danh sách các phần tử UI, được sử dụng để điều hướng và khám phá các phần khác của ứng dụng. Một cách hiệu quả hơn để biểu diễn màn hình có thể dẫn đến việc crawl hiệu quả hơn [49]. Ví dụ, vì các thuộc tính của các mục danh sách tương tự, trình thu thập dữ liệu có thể giảm các tương tác không cần thiết bằng cách chạm vào một mục danh sách và truyền nhãn cho các mục khác. Ngữ nghĩa icon [5,6,30] cũng hữu ích để suy luận kết quả của các tương tác nhất định. Ví dụ, chạm vào icon "camera" có thể mở ứng dụng camera hệ thống, điều này sẽ làm gián đoạn việc crawl. Vì mục tiêu của chính trình thu thập dữ liệu là huấn luyện các mô hình UI như vậy, chúng tôi tin rằng việc tích hợp các mô hình bổ sung này vào khung học liên tục không bao giờ kết thúc là một bước tiếp theo tự nhiên.

7 KẾT LUẬN
Trong công trình này, chúng tôi đã trình bày một kỹ thuật để trích xuất và mô hình hóa liên tục các ngữ nghĩa giao diện người dùng thông qua tương tác, mà chúng tôi gọi là "học liên tục không bao giờ kết thúc về UI". Chúng tôi đã triển khai một trình thu thập dữ liệu ứng dụng di động tải xuống, cài đặt và crawl hàng nghìn ứng dụng để quan sát ngữ nghĩa và khả năng sử dụng UI trong các ứng dụng thế giới thực, và chúng tôi sử dụng các heuristic dựa trên tương tác để tạo ra các bộ dữ liệu lớn để huấn luyện ba loại mô hình hiểu UI i) khả năng chạm, ii) khả năng kéo, và iii) độ tương tự màn hình. Chúng tôi thấy rằng các mô hình được huấn luyện theo cách này có thể chính xác hơn những mô hình được huấn luyện từ ảnh chụp màn hình được chú thích bởi con người và tiếp tục cải thiện với quyền truy cập vào nhiều ví dụ huấn luyện hơn. Bản chất tự động hóa cao của phương pháp của chúng tôi cho phép chúng tôi áp dụng nó vô thời hạn, với ít hoặc không cần giám sát của con người, có thể tối đa hóa hiệu suất và tính hữu dụng của chúng cho các ứng dụng xuôi dòng.

TÀI LIỆU THAM KHẢO
[1] Deniz Arsan, Ali Zaidi, Aravind Sagar, và Ranjitha Kumar. 2021. App-Based Task Shortcuts for Virtual Assistants. Trong The 34th Annual ACM Symposium on User Interface Software and Technology. 1089–1099.
[2] Chongyang Bai, Xiaoxue Zang, Ying Xu, Srinivas Sunkara, Abhinav Rastogi, Jindong Chen, và Blaise Agüera y Arcas. 2021. UIBert: Learning Generic Multimodal Representations for UI Understanding. Trong International Joint Conference on Artificial Intelligence.
[3] Sara Bunian, Kai Li, Chaima Jemmali, Casper Harteveld, Yun Fu, và Magy Seif Seif El-Nasr. 2021. Vins: Visual search for mobile user interface design. Trong Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1–14.
[4] Francisco M Castro, Manuel J Marín-Jiménez, Nicolás Guil, Cordelia Schmid, và Karteek Alahari. 2018. End-to-end incremental learning. Trong Proceedings of the European conference on computer vision (ECCV). 233–248.
[5] Jieshan Chen, Chunyang Chen, Zhenchang Xing, Xiwei Xu, Liming Zhu, Guoqiang Li, và Jinshui Wang. 2020. Unblind your apps: Predicting natural-language labels for mobile gui components by deep learning. Trong Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering. 322–334.
[6] Jieshan Chen, Amanda Swearngin, Jason Wu, Titus Barik, Jeffrey Nichols, và Xiaoyi Zhang. 2022. Towards Complete Icon Labeling in Mobile Applications. Trong Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. 1–14.
[7] Sen Chen, Lingling Fan, Chunyang Chen, Ting Su, Wenhe Li, Yang Liu, và Lihua Xu. 2019. Storydroid: Automated generation of storyboard for Android apps. Trong 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 596–607.
[8] Elizabeth Clark, Tal August, Sofia Serrano, Nikita Haduong, Suchin Gururangan, và Noah A. Smith. 2021. All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated Text. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Association for Computational Linguistics, Online, 7282–7296. https://doi.org/10.18653/v1/2021.acl-long.565
[9] Nathan Cooper, Carlos Bernal-Cárdenas, Oscar Chaparro, Kevin Moran, và Denys Poshyvanyk. 2021. It takes two to tango: Combining visual and textual information for detecting duplicate video-based bug reports. Trong 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 957–969.
[10] Biplab Deka, Zifeng Huang, Chad Franzen, Joshua Hibschman, Daniel Afergan, Yang Li, Jeffrey Nichols, và Ranjitha Kumar. 2017. Rico: A Mobile App Dataset for Building Data-Driven Design Applications. Trong Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology (Québec City, QC, Canada) (UIST '17). Association for Computing Machinery, New York, NY, USA, 845–854. https://doi.org/10.1145/3126594.3126651
[11] Shirin Feiz, Jason Wu, Xiaoyi Zhang, Amanda Swearngin, Titus Barik, và Jeffrey Nichols. 2022. Understanding Screen Relationships from Screenshots of Smartphone Applications. Trong 27th International Conference on Intelligent User Interfaces (Helsinki, Finland) (IUI '22). Association for Computing Machinery, New York, NY, USA, 447–458. https://doi.org/10.1145/3490099.3511109
[12] Ian Goodfellow, Yoshua Bengio, và Aaron Courville. 2016. Deep Learning. MIT Press. http://www.deeplearningbook.org.
[13] Raia Hadsell, Sumit Chopra, và Yann LeCun. 2006. Dimensionality reduction by learning an invariant mapping. Trong 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), Vol. 2. IEEE, 1735–1742.
[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. 2016. Deep residual learning for image recognition. Trong Proceedings of the IEEE conference on computer vision and pattern recognition. 770–778.
[15] Zecheng He, Srinivas Sunkara, Xiaoxue Zang, Ying Xu, Lijuan Liu, Nevan Wichers, Gabriel Schubiner, Ruby Lee, và Jindong Chen. 2021. ActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces. Proceedings of the AAAI Conference on Artificial Intelligence 35, 7 (May 2021), 5931–5938. https://doi.org/10.1609/aaai.v35i7.16741
[16] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, và Hartwig Adam. 2017. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arXiv:1704.04861 [cs.CV]
[17] Forrest Huang, John F. Canny, và Jeffrey Nichols. 2019. Swire: Sketch-Based User Interface Retrieval. Trong Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI '19). Association for Computing Machinery, New York, NY, USA, 1–10. https://doi.org/10.1145/3290605.3300334
[18] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. 2017. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences 114, 13 (2017), 3521–3526.
[19] Konstantin Kuznetsov, Chen Fu, Song Gao, David N. Jansen, Lijun Zhang, và Andreas Zeller. 2021. Frontmatter: Mining Android User Interfaces at Scale. Trong Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (Athens, Greece) (ESEC/FSE 2021). Association for Computing Machinery, New York, NY, USA, 1580–1584. https://doi.org/10.1145/3468264.3473125
[20] Luis A. Leiva, Asutosh Hota, và Antti Oulasvirta. 2021. Enrico: A Dataset for Topic Modeling of Mobile UI Designs. Trong 22nd International Conference on Human-Computer Interaction with Mobile Devices and Services (Oldenburg, Germany) (MobileHCI '20). Association for Computing Machinery, New York, NY, USA, Article 9, 4 pages. https://doi.org/10.1145/3406324.3410710
[21] Gang Li, Gilles Baechler, Manuel Tragut, và Yang Li. 2022. Learning to Denoise Raw Mobile UI Layouts for Improving Datasets at Scale. Trong Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI '22). Association for Computing Machinery, New York, NY, USA, Article 67, 13 pages. https://doi.org/10.1145/3491102.3502042
[22] Toby Jia-Jun Li, Lindsay Popowski, Tom Mitchell, và Brad A Myers. 2021. Screen2Vec: Semantic Embedding of GUI Screens and GUI Components. Trong Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI '21). Association for Computing Machinery, New York, NY, USA, Article 578, 15 pages. https://doi.org/10.1145/3411764.3445049
[23] Yang Li, Jiacong He, Xin Zhou, Yuan Zhang, và Jason Baldridge. 2020. Mapping natural language instructions to mobile UI action sequences. arXiv preprint arXiv:2005.03776 (2020).
[24] Yang Li, Gang Li, Luheng He, Jingjie Zheng, Hong Li, và Zhiwei Guan. 2020. Widget Captioning: Generating Natural Language Description for Mobile User Interface Elements. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 5495–5510.
[25] Yuanchun Li, Ziyue Yang, Yao Guo, và Xiangqun Chen. 2017. Droidbot: a lightweight ui-guided test input generator for android. Trong 2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C). IEEE, 23–26.
[26] Yuanchun Li, Ziyue Yang, Yao Guo, và Xiangqun Chen. 2017. Droidbot: a lightweight ui-guided test input generator for android. Trong 2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C). IEEE, 23–26.
[27] Yuanchun Li, Ziyue Yang, Yao Guo, và Xiangqun Chen. 2019. Humanoid: A deep learning-based approach to automated black-box android app testing. Trong 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 1070–1073.
[28] Zhizhong Li và Derek Hoiem. 2017. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence 40, 12 (2017), 2935–2947.
[29] Yi-Chi Liao, Kashyap Todi, Aditya Acharya, Antti Keurulainen, Andrew Howes, và Antti Oulasvirta. 2022. Rediscovering Affordance: A Reinforcement Learning Perspective. Trong Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI '22). Association for Computing Machinery, New York, NY, USA, Article 362, 15 pages. https://doi.org/10.1145/3491102.3501992
[30] Thomas F Liu, Mark Craft, Jason Situ, Ersin Yumer, Radomir Mech, và Ranjitha Kumar. 2018. Learning design semantics for mobile apps. Trong Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology. 569–579.
[31] T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, B. Yang, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, và J. Welling. 2018. Never-Ending Learning. Commun. ACM 61, 5 (apr 2018), 103–115. https://doi.org/10.1145/3191513
[32] Timothy Nguyen, Zhourong Chen, và Jaehoon Lee. 2020. Dataset meta-learning from kernel ridge-regression. arXiv preprint arXiv:2011.00050 (2020).
[33] Timothy Nguyen, Roman Novak, Lechao Xiao, và Jaehoon Lee. 2021. Dataset distillation with infinitely wide convolutional networks. Advances in Neural Information Processing Systems 34 (2021), 5186–5198.
[34] Donald A Norman. 1988. The psychology of everyday things. Basic books.
[35] Antti Oulasvirta, Jussi P. P. Jokinen, và Andrew Howes. 2022. Computational Rationality as a Theory of Interaction. Trong Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI '22). Association for Computing Machinery, New York, NY, USA, Article 359, 14 pages. https://doi.org/10.1145/3491102.3517739
[36] Mihir Parmar, Swaroop Mishra, Mor Geva, và Chitta Baral. 2022. Don't Blame the Annotator: Bias Already Starts in the Annotation Instructions. https://doi.org/10.48550/ARXIV.2205.00415
[37] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. 2017. icarl: Incremental classifier and representation learning. Trong Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2001–2010.
[38] Eldon Schoop, Xin Zhou, Gang Li, Zhourong Chen, Björn Hartmann, và Yang Li. 2022. Predicting and Explaining Mobile UI Tappability with Vision Modeling and Saliency Analysis. Trong Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. 1–21.
[39] Alborz Rezazadeh Sereshkeh, Gary Leung, Krish Perumal, Caleb Phillips, Minfan Zhang, Afsaneh Fazly, và Iqbal Mohomed. 2020. VASTA: a vision and language-assisted smartphone task automation system. Trong Proceedings of the 25th international conference on intelligent user interfaces. 22–32.
[40] Leslie N Smith. 2017. Cyclical learning rates for training neural networks. Trong 2017 IEEE winter conference on applications of computer vision (WACV). IEEE, 464–472.
[41] Chen Sun, Abhinav Shrivastava, Saurabh Singh, và Abhinav Gupta. 2017. Revisiting unreasonable effectiveness of data in deep learning era. Trong Proceedings of the IEEE international conference on computer vision. 843–852.
[42] Amanda Swearngin và Yang Li. 2019. Modeling Mobile Interface Tappability Using Crowdsourcing and Deep Learning. Trong Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI '19). Association for Computing Machinery, New York, NY, USA, 1–11. https://doi.org/10.1145/3290605.3300305
[43] Mingxing Tan và Quoc Le. 2019. Efficientnet: Rethinking model scaling for convolutional neural networks. Trong International conference on machine learning. PMLR, 6105–6114.
[44] Nandan Thakur, Nils Reimers, Johannes Daxenberger, và Iryna Gurevych. 2020. Augmented sbert: Data augmentation method for improving bi-encoders for pairwise sentence scoring tasks. arXiv preprint arXiv:2010.08240 (2020).
[45] Daniel Toyama, Philippe Hamel, Anita Gergely, Gheorghe Comanici, Amelia Glaese, Zafarali Ahmed, Tyler Jackson, Shibl Mourad, và Doina Precup. 2021. Androidenv: A reinforcement learning platform for android. arXiv preprint arXiv:2105.13231 (2021).
[46] Bryan Wang, Gang Li, Xin Zhou, Zhourong Chen, Tovi Grossman, và Yang Li. 2021. Screen2words: Automatic mobile UI summarization with multimodal learning. Trong The 34th Annual ACM Symposium on User Interface Software and Technology. 498–510.
[47] Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, và Alexei A Efros. 2018. Dataset distillation. arXiv preprint arXiv:1811.10959 (2018).
[48] Jason Wu, Siyan Wang, Siman Shen, Yi-Hao Peng, Jeffrey Nichols, và Jeffrey P Bigham. 2023. WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics. arXiv preprint arXiv:2301.13280 (2023).
[49] Jason Wu, Xiaoyi Zhang, Jeff Nichols, và Jeffrey P Bigham. 2021. Screen Parsing: Towards Reverse Engineering of UI Models from Screenshots. Trong The 34th Annual ACM Symposium on User Interface Software and Technology (Virtual Event, USA) (UIST '21). Association for Computing Machinery, New York, NY, USA, 470–483. https://doi.org/10.1145/3472749.3474763
[50] Ziming Wu, Yulun Jiang, Yiding Liu, và Xiaojuan Ma. 2020. Predicting and Diagnosing User Engagement with Mobile UI Animation via a Data-Driven Approach. Trong Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI '20). Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376324
[51] Mulong Xie, Sidong Feng, Zhenchang Xing, Jieshan Chen, và Chunyang Chen. 2020. UIED: a hybrid tool for GUI element detection. Trong Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1655–1659.
[52] Arianna Yuan và Yang Li. 2020. Modeling human visual search performance on realistic webpages using analytical and deep learning methods. Trong Proceedings of the 2020 CHI conference on human factors in computing systems. 1–12.
[53] Xiaoyi Zhang, Lilian de Greef, Amanda Swearngin, Samuel White, Kyle Murray, Lisa Yu, Qi Shan, Jeffrey Nichols, Jason Wu, Chris Fleizach, et al. 2021. Screen recognition: Creating accessibility metadata for mobile applications from pixels. Trong Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1–15.
[54] Xin Zhou và Yang Li. 2021. Large-Scale Modeling of Mobile User Click Behaviors Using Deep Learning. Trong Proceedings of the 15th ACM Conference on Recommender Systems. 473–483.
[55] Xingyi Zhou, Dequan Wang, và Philipp Krähenbühl. 2019. Objects as Points. arXiv:1904.07850 [cs.CV]

A GIAO DIỆN CHÚ THÍCH
Các người chú thích đã sử dụng một giao diện chú thích dựa trên web để đánh giá hiệu suất của các heuristic gắn nhãn. Hình 10 cho thấy giao diện dựa trên web được sử dụng để gắn nhãn đầu ra heuristic.

B SIÊU THAM SỐ MÔ HÌNH
Bảng 1 cho thấy các siêu tham số được sử dụng để huấn luyện các mô hình khác nhau trong Never-ending UI Learner.
>>>>>>> Stashed changes

# 2304.08953.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2304.08953.pdf
# Kích thước file: 530361 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Từ Từ ngữ đến Âm nhạc: Một Nghiên cứu về Các Kỹ thuật Tokenization Subword trong
Sinh tạo Âm nhạc Ký hiệu
Adarsh Kumar1 và Pedro Sarmento2
1Viện Công nghệ Ấn Độ Kharagpur, Ấn Độ
2Đại học Queen Mary London, Vương quốc Anh
adarshkumar712.ak@gmail.com, p.p.sarmento@qmul.ac.uk
Tóm tắt
Tokenization subword đã thành công rộng rãi
trong các tác vụ xử lý ngôn ngữ tự nhiên (NLP)
dựa trên văn bản với các mô hình dựa trên Trans-
former. Khi các mô hình Transformer ngày càng
trở nên phổ biến trong các nghiên cứu liên quan
đến âm nhạc ký hiệu, việc nghiên cứu hiệu quả
của tokenization subword trong lĩnh vực âm nhạc
ký hiệu là điều cấp thiết. Trong bài báo này, chúng
tôi khám phá các kỹ thuật tokenization subword,
như mã hóa cặp byte (BPE), trong sinh tạo âm
nhạc ký hiệu và tác động của nó đến cấu trúc tổng
thể của các bài hát được sinh tạo. Thí nghiệm của
chúng tôi dựa trên ba loại bộ dữ liệu MIDI: đơn
track-chỉ giai điệu, đa track với một nhạc cụ duy
nhất, và đa track và đa nhạc cụ. Chúng tôi áp dụng
tokenization subword trên các sơ đồ tokenization
âm nhạc hậu kỳ và thấy rằng nó cho phép sinh tạo
các bài hát dài hơn cùng thời gian và cải thiện cấu
trúc tổng thể của âm nhạc được sinh tạo về mặt
các chỉ số khách quan như chỉ số cấu trúc (SI),
Entropy Lớp Cao độ, v.v. Chúng tôi cũng so sánh
hai phương pháp tokenization subword, BPE và
Unigram, và quan sát thấy rằng cả hai phương
pháp đều dẫn đến những cải thiện nhất quán.
Nghiên cứu của chúng tôi cho thấy tokenization
subword là một kỹ thuật đầy hứa hẹn cho sinh tạo
âm nhạc ký hiệu và có thể có những tác động rộng
lớn hơn đối với sáng tác âm nhạc, đặc biệt trong
các trường hợp liên quan đến dữ liệu phức tạp như
các bài hát đa track.

1 Giới thiệu
Tokenization subword là một kỹ thuật được sử dụng rộng rãi
để biểu diễn văn bản trong xử lý ngôn ngữ tự nhiên (NLP).
Các kỹ thuật tokenization như vậy dựa trên việc tạo ra các
token subword, như mã hóa cặp byte (BPE) [Sennrich et al.,
2016], Unigram [Kudo, 2018] và WordPiece [Wu et al.,
2016], đã trở nên phổ biến trong nhiều tác vụ NLP khác nhau.
Do hiệu quả trong việc mô hình hóa các mẫu dài hơn, thay vì
chỉ đơn giản là các ký tự, các kỹ thuật tokenization subword
này đã trở nên cực kỳ thành công với các mô hình Trans-
former như BERT [Devlin et al., 2018] và GPT [Radford et
al., 2019], đạt được kết quả tối ưu trong nhiều ứng dụng
NLP dựa trên văn bản. Các công trình như [Park et al., 2020]
và [Gallé, 2019] đã cho thấy thêm tính phổ quát của việc áp
dụng nó trên các ngôn ngữ, không chỉ trong tiếng Anh.

Hình 1: Ví dụ về các cấu trúc tương tự thường xuyên xuất hiện
cùng nhau trong văn bản (ở cấp độ ký tự) và biểu diễn âm nhạc
(giống MIDI, ở cấp độ sự kiện).

Được truyền cảm hứng từ thành công của các mô hình
Transformer trong text-NLP,1 những năm gần đây đã chứng
kiến sự chuyển dịch trong công việc nghiên cứu hướng tới
việc tận dụng Transformer [Vaswani et al., 2017] trong lĩnh
vực sinh tạo âm nhạc ký hiệu [Huang et al., 2018; Muhamed
et al., 2021; Guo et al., 2022]. Sự chuyển dịch này có thể
được quy cho sự tương đồng của âm nhạc ký hiệu hậu-
tokenization-âm-nhạc2 với các token văn bản. Với khả năng
đặc biệt của Transformer trong việc mô hình hóa các chuỗi
dài hơn, chúng ta có thể sinh tạo các tác phẩm âm nhạc mạch
lạc, phù hợp từ đầu đến cuối [Hsiao et al., 2021; Huang và
Yang, 2020; Neves et al., 2022].

Mặc dù có tất cả thành công của các tiền nhiệm trong việc
cải thiện trạng thái sinh tạo âm nhạc, các mô hình này thường
bị cáo buộc không thể nắm bắt hoàn toàn cấu trúc lặp lại và
sự phát triển âm nhạc tổng thể của các bài hát [Dai et al.,
2022;

1Để rõ ràng và phân biệt, chúng tôi sẽ gọi các tác vụ liên quan
đến văn bản trong NLP là text-NLP.
2Tokenization Âm nhạc đề cập đến tokenization của các định
dạng ký hiệu như MIDI hoặc GuitarPro với Tokenization Âm nhạc
như REMI hoặc giống MIDI.

--- TRANG 2 ---
Wu và Yang, 2020; Wu và Yang, 2022]. Điều này trở nên rõ
ràng hơn khi cấu trúc của âm nhạc trở nên phức tạp như trong
trường hợp âm nhạc đa âm hoặc âm nhạc đa track. Một giải
thích hợp lý cho điều này có thể là chuỗi token âm nhạc ký
hiệu dài đáng kể, điều này giới hạn phân đoạn của bài hát
mà mô hình Transformer có thể nhìn thấy, cản trở việc hiểu
biết về cấu trúc âm nhạc tổng thể. Như một sự tương tự, điều
này sẽ tương đương với việc biểu diễn một đoạn văn bản như
một chuỗi các ký tự riêng lẻ.

Một giải pháp có thể cho vấn đề này là ở cấp độ token. Ý
tưởng là nhóm các sự kiện riêng lẻ thành các nhóm con, tương
tự như subword trong text-NLP. Đã có các công trình như
[Hsiao et al., 2021] và [Liu et al., 2022], đã cố gắng nhóm
các sự kiện âm nhạc, khai thác các thuộc tính của cấu trúc
âm nhạc cho một số bộ dữ liệu dựa trên MIDI nhất định.
Tuy nhiên, hầu hết các công trình này phụ thuộc vào cấu trúc
âm nhạc của các bộ dữ liệu nhất định có liên quan, và do đó
không thể được ngoại suy sang các định dạng khác một cách
dễ dàng. Vì vậy, theo hiểu biết tốt nhất của chúng tôi, cho
đến nay chưa có công trình nào được thực hiện để đánh giá
việc sử dụng các kỹ thuật tokenization subword như BPE và
Unigram tận dụng cấu trúc dựa trên sự đồng xuất hiện của
các sự kiện âm nhạc, độc lập với cấu trúc âm nhạc của chính
bộ dữ liệu huấn luyện.

Do đó, chúng tôi có động lực để nghiên cứu liệu việc sử
dụng tokenization subword có thể cải thiện cấu trúc âm nhạc
tổng thể của các bài hát được sinh tạo, đồng thời độc lập với
bộ dữ liệu hoặc định dạng âm nhạc ký hiệu có liên quan.
Trong công trình này, chúng tôi đặc biệt nghiên cứu tính hữu
ích của các kỹ thuật tokenization subword như BPE [Sennrich
et al., 2016] và Unigram [Kudo, 2018] trong việc mô hình
hóa tác vụ sinh tạo âm nhạc ký hiệu. Thông qua các thí
nghiệm của chúng tôi, chúng tôi cố gắng trả lời hai câu hỏi
chính sau:

• Q1: Chúng ta có thể sử dụng các kỹ thuật tokenization
subword để cải thiện cấu trúc âm nhạc tổng thể và chất
lượng âm nhạc của các ví dụ được sinh tạo không?

• Q2: Những phát hiện này tổng quát hóa như thế nào
giữa hai kỹ thuật tokenization subword khác nhau, cụ
thể là BPE và Unigram?

Trong nỗ lực trả lời các câu hỏi trên, các đóng góp chính
của chúng tôi thông qua bài báo này như sau:

• Tạo và triển khai một môi trường đánh giá để đánh giá
khách quan tính hữu ích của các kỹ thuật tokenization
subword, cụ thể là BPE và Unigram, để cải thiện cấu
trúc âm nhạc tổng thể (về mặt các chỉ số định lượng
như Entropy Lớp Cao độ, Chỉ số Cấu trúc, v.v.), độc
lập với các yếu tố đặc thù của dữ liệu như định dạng
file âm nhạc (ví dụ MIDI hoặc GuitarPro);

• Thiết lập hiệu quả của tokenization subword trên các
bộ dữ liệu, định dạng dữ liệu và kỹ thuật tokenization
âm nhạc, với nghiên cứu của chúng tôi bao gồm các bộ
dữ liệu chỉ giai điệu, đa âm và đa track;

• Chứng minh tính hữu ích của các token subword hướng
tới việc tạo ra các tác phẩm âm nhạc dài hơn trong
cùng thời gian suy luận.

2 Nền tảng và Công trình Liên quan
2.1 Tokenization Subword
Tokenization đã trở thành một quy trình cơ bản trong NLP
bao gồm việc chia nhỏ các đơn vị vĩ mô của văn bản như
'từ' hoặc 'câu' thành các đơn vị nhỏ hơn gọi là token. Vì
việc biểu diễn dữ liệu văn bản dài hơn nhiều như các ký tự
riêng lẻ là rất không hiệu quả, khái niệm 'tokenization sub-
word' đã được giới thiệu [Mielke et al., 2021]. Nó bao gồm
việc chia nhỏ từ hoặc câu thành các sub-word (một dãy con
của các ký tự có độ dài ≥ 1), sau đó được sử dụng để biểu
diễn dữ liệu. Qua nhiều năm, một số kỹ thuật tokenization
subword đã được giới thiệu như BPE [Gage, 1994; Sennrich
et al., 2016], Unigram [Kudo, 2018], WordPiece [Wu et al.,
2016] và SentencePiece [Kudo và Richardson, 2018]. Hầu
hết các kỹ thuật này bao gồm việc lựa chọn subword dựa
trên tần suất của chúng trong dữ liệu huấn luyện.

Mã hóa Cặp Byte (BPE) [Sennrich et al., 2016] là một kỹ
thuật nén dữ liệu [Gage, 1994] bao gồm việc thay thế cặp
byte thường xuyên nhất bằng một byte duy nhất, chưa được
sử dụng. Trong text-NLP, BPE được áp dụng cho các đơn
vị subword, thay vì byte, bằng cách tìm các n-gram ký tự
thường xuyên nhất trong một corpus văn bản và hợp nhất
chúng thành một token duy nhất. Điều này cho phép mô hình
học một biểu diễn tinh tế hơn của ngôn ngữ, đặc biệt cho
các từ hiếm hoặc ngoài từ vựng. Kết quả là một từ vựng
subword có độ dài biến đổi, cân bằng khả năng nắm bắt cấu
trúc ngôn ngữ phức tạp với việc giảm rủi ro overfitting.

Trái ngược với BPE, Unigram [Kudo, 2018] là một kỹ thuật
tokenization subword khác, bắt đầu từ một từ vựng lớn và
dần dần cắt giảm từ vựng về một từ vựng nhỏ hơn. Nó bao
gồm một mô hình ngôn ngữ Unigram xác suất, quyết định có
nên giữ một subword hay không dựa trên khả năng xảy ra và
hàm mất mát của nó. Cả hai mô hình này đã được sử dụng
rộng rãi trong nhiều ứng dụng NLP khác nhau như [Wang
et al., 2020], [Liu et al., 2019] và [Conneau và Lample,
2019]. Hơn nữa, các bài báo như [Gallé, 2019] và [Park et
al., 2020] đã cho thấy rằng các kỹ thuật tokenization subword
này có thể được áp dụng hiệu quả trên các ngôn ngữ. Điều
này thúc đẩy chúng tôi khám phá liệu những kết quả này có
thể được mở rộng sang âm nhạc ký hiệu như một ngôn ngữ,
và tác động nó có thể có đối với cấu trúc âm nhạc tổng thể
của các bài hát được sinh tạo.

2.2 Sinh tạo Âm nhạc Ký hiệu
Sinh tạo Âm nhạc Ký hiệu bao gồm việc biểu diễn dữ liệu
âm nhạc từ các định dạng như MIDI hoặc GuitarPro với các
ký hiệu hoặc chuỗi sự kiện sau đó được sử dụng để huấn
luyện các mô hình sinh tạo. Đây là một lĩnh vực được nghiên
cứu rộng rãi, nơi các nhà nghiên cứu đang cố gắng đưa ra
các thuật toán và mô hình có thể sinh tạo âm nhạc ngang
bằng với hiệu suất con người [Hiller, 2019]. Gần đây, lĩnh
vực sinh tạo âm nhạc ký hiệu đã chứng kiến những cải thiện
ổn định, chủ yếu được thúc đẩy bởi những tiến bộ trong các
kiến trúc học sâu. Nhìn chung, các cách tiếp cận đối với sinh
tạo âm nhạc ký hiệu với học sâu có thể được tổng hợp theo
kiến trúc được sử dụng, cụ thể là các mô hình Variational
Autoencoder (VAE) [Tan và Herremans, 2020], Generative
Adversarial Networks (GANs) [Dong và Yang, 2018], và
các mô hình xuất phát từ lĩnh vực xử lý ngôn ngữ tự nhiên
(NLP), như

--- TRANG 3 ---
Hình 2: Pipeline xử lý âm nhạc ký hiệu với tokenization subword. Xin lưu ý rằng, ở đây, các ký hiệu âm nhạc đề cập đến việc ánh xạ các sự kiện âm nhạc sang các ký hiệu unicode hoặc ký tự, sau đó được xử lý với tokenizer subword.

Mạng Nơ-ron Hồi quy (RNNs) [Meade et al., 2019], Bộ nhớ
Ngắn hạn Dài (LSTMs) [Sturm et al., 2016], hoặc Trans-
formers [Vaswani et al., 2017]. Như đã nêu trước đó, kiến
trúc Transformer [Vaswani et al., 2017] phù hợp để sinh tạo
các chuỗi dài hơn khi so sánh với các cách tiếp cận trước
đây được sử dụng bởi RNNs. Các mô hình chuỗi-đến-chuỗi
giống Transformer có thể học các phụ thuộc và mẫu giữa
các phần tử của một chuỗi đã cho. Công trình của [Huang
et al., 2019], Music Transformer, đã tiên phong trong việc
áp dụng cơ chế tự chú ý để sinh tạo các chuỗi dài hơn của
âm nhạc piano ký hiệu. Các ví dụ khác bao gồm các công
trình như Musenet [Payne, 2019], trong đó một mô hình
Transformer quy mô lớn, GPT-2, được sử dụng để sinh tạo
âm nhạc ký hiệu đa nhạc cụ từ các thể loại âm nhạc khác
nhau, Pop Music Transformer [Huang và Yang, 2020], sử
dụng Transformer-XL [Dai et al., 2019a] như một kiến trúc
xương sống và có thể sinh tạo âm nhạc piano ký hiệu pop
với cấu trúc nhịp điệu tốt hơn, Compound Word Trans-
former [Hsiao et al., 2021], trình bày các cách thức mới
và hiệu quả hơn để tokenizing âm nhạc ký hiệu cho mục
đích huấn luyện, và GTR-CTRL [Sarmento et al., 2023]
khám phá điều kiện thể loại và nhạc cụ sử dụng các token
điều khiển đặc biệt với bộ dữ liệu âm nhạc đa track DadaGP,
từ đó điều khiển cấu trúc âm nhạc tổng thể của các bài hát
được sinh tạo.

3 Phương pháp luận
Để đánh giá tính hữu ích của tokenization subword và trả
lời các câu hỏi được đề cập trong Phần 1, chúng tôi thiết kế
một nghiên cứu thực nghiệm nơi chúng tôi đánh giá khách
quan hiệu suất của các mô hình có và không có các phương
pháp tokenization subword, trong khi giữ tất cả các yếu tố
khác giống hệt nhau. Để làm rõ, chúng tôi ở đây đề cập đến
mô hình không có token subword như 'mô hình cơ sở', trong
khi các mô hình khác được đặt tên theo kỹ thuật tokenization
subword tương ứng được sử dụng trong việc mô hình hóa
(ví dụ 'mô hình BPE' như mô hình đã sử dụng BPE cho
tokenization subword).

3.1 Bộ dữ liệu và Sơ đồ Tokenization Âm nhạc
Như đã đề cập trước đó, chúng tôi sử dụng ba bộ dữ liệu cho
các thí nghiệm của mình, cụ thể là bộ dữ liệu Folk Songs
[Sturm et al., 2016], bộ dữ liệu MAESTRO [Hawthorne et
al., 2019], và bộ dữ liệu DadaGP [Sarmento et al., 2021].
Hơn nữa, cho quy trình tokenization âm nhạc, chúng tôi sử
dụng REMI [Huang và Yang, 2020], Midi-like [Oore et al.,
2018] và tokenization DadaGP [Sarmento et al., 2021] tương
ứng, chủ yếu để chứng minh tính tương thích của tokenization
subword với các cách tiếp cận tokenization âm nhạc khác
nhau hiện có. Cho rằng việc huấn luyện các mô hình như
Music Transformer [Huang et al., 2018] và Transformer-XL
[Dai et al., 2019b; Huang và Yang, 2020] trên các bộ dữ
liệu lớn như vậy là rất tốn tài nguyên, chúng tôi hạn chế
nghiên cứu của mình vào các tập con của mỗi bộ dữ liệu,
sử dụng 1000 mẫu từ bộ dữ liệu Folk Songs, 400 mẫu từ
bộ dữ liệu MAESTRO và 2000 bài hát từ thể loại Rock trong
DadaGP. Tuy nhiên, vì các cài đặt tương tự được giữ cho cả
mô hình có và không có tokenization subword, việc hạn chế
của chúng tôi không ảnh hưởng đến bất kỳ kết luận nào từ
kết quả của chúng tôi.

3.2 Xử lý Dữ liệu
Trong khi có một số phương pháp tokenization subword có
sẵn, chúng tôi tập trung thí nghiệm của mình vào hai trong
số những phương pháp phổ biến nhất, BPE và Unigram, chủ
yếu vì tính dễ áp dụng của chúng đối với bất kỳ bộ dữ liệu
nào. Để tận dụng tokenization subword với âm nhạc ký hiệu,
trước tiên chúng tôi chuyển đổi các bài hát từ định dạng ký
hiệu (MIDI hoặc GuitarPro) sang các sự kiện âm nhạc sử
dụng các sơ đồ tokenization âm nhạc như REMI [Huang và
Yang, 2020], sau đó chúng tôi tạo một ánh xạ, từ các sự kiện
âm nhạc sang các ký hiệu unicode. Do đó, chúng tôi có được
một corpus ký hiệu tương đối dễ xử lý, trong đó chúng tôi
giả định mỗi

--- TRANG 4 ---
Tokenization Âm nhạc Ban đầu BPE Unigram
REMI 227 300 300
MIDI-Like 331 1000 1000
DadaGP 2104 5000 5000
Bảng 1: Kích thước từ vựng của các token ban đầu (sử dụng token-
ization âm nhạc tương ứng), hậu xử lý với BPE và Unigram.

bài hát là một thực thể duy nhất tương tự như SentencePiece
[Kudo và Richardson, 2018]. Sau đó, chúng tôi huấn luyện
các phương pháp tokenization subword trên các bộ dữ liệu
tương ứng để tạo ra một từ vựng lớn hơn của các token sub-
word. Hơn nữa, chúng tôi sử dụng từ vựng này để xử lý các
token âm nhạc của tất cả các bài hát trong một bộ dữ liệu
đã cho. Một tóm tắt thống kê về kích thước từ vựng ban đầu
của các token âm nhạc và token subword được sử dụng trong
các thí nghiệm này được đưa ra trong Bảng 1.

3.3 Cấu hình Thí nghiệm
Như đã nêu trước đó, để đánh giá tính độc lập của kết quả
về mặt cải thiện trong khi sử dụng các phương pháp token-
ization subword chống lại các yếu tố như loại bộ dữ liệu,
quy trình tokenization âm nhạc, và mô hình, chúng tôi thí
nghiệm với ba kết hợp khác nhau:

1. Folk Songs (đơn âm, nhạc cụ đơn, định dạng MIDI) +
tokenization REMI + Music Transformer;
2. MAESTRO (đa âm, nhạc cụ đơn, định dạng MIDI) +
tokenization MIDI-Like + Music Transformer;
3. DadaGP (đa âm, đa nhạc cụ, định dạng GuitarPro) +
tokenization DadaGP + Transformer-XL;

Ý tưởng chính ở đây là thí nghiệm với các sơ đồ tokenization
subword trong các cài đặt và cấu hình khác nhau và xem liệu
kết quả về mặt cải thiện có đúng bất kể các yếu tố còn lại.
Hơn nữa, việc lựa chọn âm nhạc đơn âm, đa âm, và đa track,
cho phép chúng tôi đánh giá tính hữu ích của tokenization
subword cho các tác vụ sinh tạo âm nhạc với các mức độ
phức tạp khác nhau.

4 Chỉ số Đánh giá
Để đánh giá khách quan kết quả của việc áp dụng tokenization
subword trong sinh tạo âm nhạc, chúng tôi phân chia các chỉ
số chuyên dụng thành các danh mục: chất lượng và cấu trúc
âm nhạc và hiệu quả trong biểu diễn.

4.1 Chất lượng và Cấu trúc Âm nhạc
Chỉ số Cấu trúc (SI): Được đề xuất trong [Wu và Yang,
2020], chỉ số cấu trúc (SI) được thiết kế để nắm bắt tính
cấu trúc của âm nhạc, được tạo ra bởi sự lặp lại của nội dung
âm nhạc. Nó dựa trên thuật toán fitness-scape plot [Müller
et al., 2011] và ma trận tự tương đồng (SSM) [Foote, 1999]
được tính từ fitness, nơi mức độ lặp lại được rút ra từ SSM
cho một phân đoạn đã cho (i,j). Tương tự như [Wu và Yang,
2020], trong các thí nghiệm của chúng tôi, chúng tôi sử dụng
SI₈³, SI₁₅₈ và SI₁₅, trong đó SI^u_l, l và u đại diện cho giới
hạn dưới và trên của khoảng thời gian xem xét (tính bằng
giây). Chúng tôi tương ứng đề cập đến những điều này như
SI-short, SI-medium, và SI-long, vì chúng được sử dụng để
kiểm tra tính cấu trúc ngắn hạn, trung hạn, và dài hạn của
các bài hát được sinh tạo. Ở đây điều quan trọng cần lưu ý
là giá trị SI-x cao hơn không nhất thiết có nghĩa là âm nhạc
'tốt hơn', vì các mẫu được sinh tạo có thể quá lặp lại. Thay
vào đó, một giả định hợp lệ hơn là nó càng gần với âm nhạc
thực (tức là corpus kiểm tra) càng tốt, điều này sẽ là cơ sở
cho việc đánh giá của chúng tôi.

Entropy Lớp Cao độ (H): Cũng được mô tả trong [Wu và
Yang, 2020], đưa ra cái nhìn sâu sắc về các cao độ khác
nhau, và do đó tính điệu được sử dụng trong một bài hát. Ở
đây, ý tưởng chính là tính entropy từ một biểu đồ lớp cao độ
12 chiều được chuẩn hóa (tương ứng với 12 lớp cao độ C,
C#, D, ... B) và phân tích mức độ gần gũi của các giá trị này
với các giá trị thực.

Tương đồng Mẫu Groove (GS): Một chỉ số khác được định
nghĩa trong [Wu và Yang, 2020], Tương đồng Mẫu Groove
giúp đo lường tính nhất quán nhịp điệu trong một bài hát.
Nó tính toán sự tương đồng theo cặp của vector groove g
của mỗi thanh (chỉ ra vị trí trong thanh có ít nhất một khởi
đầu nốt) như 1 - HammingDist(ga; gb), trên tất cả các cặp
ga và gb. Tương tự như hai chỉ số khác được đề cập trước
đó, trong trường hợp này cũng vậy, càng gần các giá trị
tương đồng groove từ các bài hát được sinh tạo với các bài
hát thực, càng tốt.

4.2 Hiệu quả trong Biểu diễn
Số Token Trung bình mỗi Bài hát: Trong chỉ số này, chúng
tôi đo số token trung bình mỗi bài hát có mặt sau xử lý dữ
liệu, sau đó được đưa vào mô hình Transformer để huấn
luyện. Một biểu diễn hiệu quả hơn sẽ là biểu diễn có số
token trung bình mỗi bài hát nhỏ hơn.

Số Token Trung bình mỗi Bài hát cho cùng Thời gian Suy
luận: Trong chỉ số này, đối với một bộ dữ liệu đã cho, chúng
tôi sinh tạo một số token bằng nhau (tức là cùng suy luận)
cho mỗi trong ba mô hình chúng tôi thí nghiệm. Sau một
quy trình chuyển đổi ngược về các token âm nhạc ban đầu,
chúng tôi so sánh số token trung bình được sinh tạo theo
các token ban đầu. Chỉ số này giúp chúng tôi đánh giá mức
độ hiệu quả của biểu diễn trong việc sinh tạo âm nhạc dài
hơn trong cùng thời gian suy luận. Do đó, đối với chỉ số cụ
thể này, giá trị càng lớn, biểu diễn dữ liệu càng tốt.

4.3 Các Chỉ số Khác
NLL Loss: Negative log-likelihood là một chỉ số phổ biến,
thường được sử dụng để đo mức độ phù hợp của mô hình
với bộ dữ liệu huấn luyện [Huang et al., 2018; Peracha,
2020; Hsiao et al., 2021]. Trong khi một giá trị NLL tương
đối gần và nhỏ hơn đại diện cho một mô hình phù hợp tốt,
trong trường hợp của chúng tôi, chúng tôi quan sát thấy rằng
nó không phải là một chỉ số tốt để so sánh hiệu suất giữa
các mô hình, vì mô hình với tokenization subword có số
tham số cao hơn. Hơn nữa, NLL loss thấp hơn không nhất
thiết có nghĩa là chất lượng sinh tạo tốt hơn. Chúng tôi vẫn
thêm điều này để đưa ra ý tưởng về mức độ phù hợp của
mô hình BPE hoặc Unigram so với mô hình cơ sở.

5 Kết quả
5.1 Cài đặt Thí nghiệm
Các thí nghiệm được thực hiện bằng cách sử dụng triển khai
HuggingFace [Wolf et al., 2020] và PyTorch của Music Trans-

--- TRANG 5 ---
former³ và Transformer-XL⁴. Để tokenization âm nhạc, chúng
tôi sử dụng thư viện MidiTok [Fradet et al., 2021], mà chúng
tôi xử lý thêm cho tokenization subword sử dụng tokenizers⁵
của Huggingface. Đối với hai phần đầu của thí nghiệm (tức
là bộ dữ liệu Folk Songs và MAESTRO songs liên quan đến
mô hình Music Transformer), chúng tôi sử dụng kiến trúc
Transformer 3 lớp, với chiều embedding 256, mà chúng tôi
huấn luyện trên Google Colab Free Tier với máy GPU P100
16GB. Đối với phần cuối (tức là DadaGP với Transformer-
XL), chúng tôi sử dụng cùng kiến trúc như trong [Huang và
Yang, 2020], huấn luyện mô hình trên GPU 24GB Quadro
RTX 6000. Để đánh giá, chúng tôi sử dụng triển khai các
chỉ số được mô tả trong phần trước trong MusPy [Dong et
al., 2020] và MusDr⁶. Cuối cùng, chúng tôi đánh giá hiệu
suất mô hình bằng cách sinh tạo 20 bài hát cho mỗi cấu hình
mô hình. Các mẫu từ việc sinh tạo có thể được truy cập tại
đây.

5.2 Đánh giá Khách quan
Kết quả từ ba thí nghiệm riêng biệt có thể được thấy trong
các bảng 2, 3 và 4.

Chỉ số Thực tế Ban đầu BPE Unigram
SI-short 0.4637 0.2707 0.3376 0.2712
SI-medium 0.4959 0.2759 0.3379 0.2719
SI-long 0.4543 0.2583 0.3340 0.2451
H 2.6011 2.6924 2.6754 2.6842
GS 0.9987 0.9984 0.9986 0.9985
Bảng 2: Kết quả với bộ dữ liệu Folk Songs.

Chỉ số Thực tế Ban đầu BPE Unigram
SI-short 0.3228 0.5119 0.3880 0.3483
SI-medium 0.3066 0.4663 0.3334 0.2828
SI-long 0.2343 0.4173 0.3031 0.2205
H 3.0555 2.5152 2.8705 2.9297
GS 0.9917 0.9971 0.9942 0.9936
Bảng 3: Kết quả với bộ dữ liệu MAESTRO songs.

Chỉ số Thực tế Cơ sở BPE Unigram
SI-short 0.5069 0.5110 0.5125 0.4894
SI-medium 0.5270 0.4219 0.4892 0.4539
SI-long 0.4972 0.2943 0.4397 0.3924
H 2.5842 2.0529 2.3084 2.4333
GS 0.9991 0.9994 0.9993 0.9992
Bảng 4: Kết quả với bộ dữ liệu DadaGP.

Như có thể quan sát từ các bảng, việc sử dụng các phương
pháp tokenization subword vượt trội hơn các mô hình cơ sở
một cách đáng kể trong cả hai trường hợp (tức là BPE và
Unigram), trong hầu như tất cả các cấu hình, bất kể mô
hình, bộ dữ liệu, định dạng dữ liệu, hay sơ đồ tokenization
âm nhạc được sử dụng. Các giá trị của SI-short, SI-medium,
và SI-long, gần gũi với dữ liệu bài hát thực, cho thấy một
cải thiện tổng thể trong cấu trúc âm nhạc của các bài hát
sử dụng tokenization subword. Ngoài ra, các cấu trúc lặp lại
dài hơn thể hiện những cải thiện đáng kể hơn so với các cấu
trúc ngắn hơn. Kết quả cho thấy rằng các kỹ thuật tokeniza-
tion subword có tiềm năng mô hình hóa cấu trúc âm nhạc tốt
hơn và có thể tận dụng cấu trúc đồng xuất hiện tiềm ẩn trong
các token âm nhạc để cải thiện chất lượng âm nhạc được
sinh tạo.

Tuy nhiên, những cải thiện tương đối nhỏ hơn trong trường
hợp bộ dữ liệu Folk Songs, cho thấy mối tương quan giữa
độ phức tạp của bộ dữ liệu được mô hình hóa và thay đổi
hiệu suất, với nhiều cơ hội cải thiện hơn trong trường hợp
các bộ dữ liệu có độ phức tạp cao hơn như MAESTRO và
DadaGP. Thêm vào đó, những cải thiện không đáng kể về
mặt SI cho Unigram có thể là do các token subword được
sinh tạo với Unigram khó học hơn đối với mô hình, do đó
sụp đổ thành các token đơn giản hơn (đây là trường hợp
tương tự như mô hình cơ sở, cũng hoạt động trên các token
đơn giản hơn). Điều này một lần nữa có thể được quy cho
sự tương đối đơn giản về mặt cấu trúc và ít cơ hội đồng
xuất hiện hơn khi bộ dữ liệu chỉ là giai điệu. Tuy nhiên,
khi chúng ta chuyển sang các bộ dữ liệu phức tạp hơn, chúng
ta có các cấu trúc đồng xuất hiện âm nhạc như Hợp âm, điều
này cải thiện tính khả thi của việc sử dụng Các Kỹ thuật
Tokenization Subword.

Bộ dữ liệu Cơ sở BPE Unigram
FOLK 500 1307 994
MAESTRO 1000 1570 1534
DadaGP 1000 1437 1828
Bảng 6: Số token trung bình được sinh tạo cho cùng thời gian suy
luận trong một bộ dữ liệu (tức là cho cùng thời gian để sinh tạo x
token mô hình cơ sở (không có tokenization subword), tương ứng
y và z token được sinh tạo (theo các token âm nhạc ban đầu) cho
các mô hình BPE và Unigram).

Hơn nữa, các số liệu từ Bảng 5 và 6 chứng minh hiệu quả
cải thiện của biểu diễn với việc sử dụng tokenization sub-
word. Điều này bổ sung vào lợi thế của việc sử dụng token-
ization subword với mô hình cơ sở, vì nó cho phép mô hình
các chuỗi dài hơn trong cùng thời gian suy luận từ một mô
hình. Những kết quả này trở nên đặc biệt quan trọng trong
trường hợp các bộ dữ liệu âm nhạc ký hiệu phức tạp như
DadaGP. Bộ dữ liệu này, phức tạp trong biểu diễn, yêu cầu
rằng các chuỗi dài hơn nhiều được sinh tạo ngay cả cho một
phân đoạn bài hát ngắn. Việc sử dụng tokenization subword
với các bộ dữ liệu như vậy có thể

Bộ dữ liệu Cơ sở BPE Unigram
FOLK 796 359 436
MAESTRO 12925 8831 8618
DadaGP 5332 2875 2954
Bảng 5: Số token trung bình mỗi bài hát trong mỗi biểu diễn.

--- TRANG 6 ---
Bộ dữ liệu Mô hình Thời gian Huấn luyện Cơ sở BPE Unigram
FOLK MT 20phút 0.08 0.13 0.11
MAESTRO MT 3giờ 2.58 3.16 3.62
DadaGP Tr-XL 3ngày 0.10 0.11 0.11
Bảng 7: Negative Log-Likelihood Loss cho các mô hình (MT → Mu-
sic Transformer, Tr-XL → Transformer XL). Như lựa chọn thiết kế,
ở đây chúng tôi quyết định thời gian huấn luyện dựa trên độ phức
tạp của bộ dữ liệu và mô hình đang sử dụng, giữ cùng thời gian
cho cả ba thí nghiệm.

cho phép rút ngắn các chuỗi, từ đó cho phép suy luận âm
nhạc dài hơn.

Một so sánh giữa hiệu suất của các mô hình với tokenization
BPE hoặc Unigram xuyên suốt các kết quả cho thấy rằng
những cải thiện đúng nói chung đối với tokenization subword,
tận dụng sự đồng xuất hiện thường xuyên của các sự kiện
âm nhạc trong các bài hát. Mặc dù có một số khác biệt cục
bộ về phương pháp nào hiệu quả hơn về mặt mô hình hóa
cấu trúc hoặc chất lượng âm nhạc, với một phương pháp
hoạt động tốt hơn phương pháp khác trong một số trường
hợp hoặc bộ dữ liệu nhất định, nhìn chung, những phương
pháp này hoạt động tốt hơn mô hình cơ sở 'không có' token-
ization subword. Điều này trả lời câu hỏi thứ hai của chúng
tôi về cách kết quả nghiên cứu của chúng tôi tổng quát hóa
cho hai phương pháp tokenization subword khác nhau. Hơn
nữa, sự tổng quát hóa này độc lập với các ràng buộc của một
cấu trúc âm nhạc đã cho của một bộ dữ liệu cụ thể.

Một khía cạnh thú vị khác của kết quả của chúng tôi là quan
sát việc cải thiện kết quả với các thí nghiệm liên quan đến
Transformer-XL tức là vượt ra ngoài mô hình hóa độ dài cố
định. Trong khi mục đích chính của việc sử dụng mô hình
này, như được đề xuất trong [Huang và Yang, 2020] cho sinh
tạo âm nhạc, là để mô hình hóa cấu trúc âm nhạc vượt ra
ngoài độ dài cố định của đầu vào, thật thú vị khi thấy những
cải thiện với tokenization subword ngay cả trong trường hợp
này, đặc biệt với tính cấu trúc lặp lại dài hạn. Điều này cho
thấy trong khi kiến trúc chuyên dụng của Transformer-XL
có khả năng mô hình hóa cấu trúc âm nhạc ngắn hạn tốt hơn,
vẫn có mất mát thông tin khi mô hình lan truyền qua các
cửa sổ đầu vào Transformer-XL, dẫn đến ít tính lặp lại dài
hạn hơn. Tuy nhiên, khi giảm độ dài này với tokenization
subword, mất mát này có thể được giảm, từ đó cho phép
biểu diễn cải thiện của cấu trúc âm nhạc, gần gũi hơn với
dữ liệu thực, chúng ta đang cố gắng mô hình hóa.

Cuối cùng, điều quan trọng cần lưu ý là hiệu suất NLL loss
của các mô hình chúng tôi huấn luyện từ Bảng 7. Trong khi
các giá trị gần nhau của hàm mất mát trong trường hợp cơ
sở, BPE và Unigram cho thấy mô hình có thể mô hình hóa
bộ dữ liệu gần như tương đương trong tất cả các trường hợp,
sự khác biệt trong đánh giá khách quan về chất lượng âm
nhạc được sinh tạo, cho thấy rằng không phải tất cả thông
tin đều được nắm bắt trong NLL loss. Hơn nữa, nó hỗ trợ
giả định ban đầu của chúng tôi (trong phần 4.3) rằng NLL
không phải là một chỉ số phù hợp để hành động một cách
kết luận về hiệu suất mô hình. Tuy nhiên, nó vẫn có thể
cung cấp cái nhìn tổng quan về mức độ phù hợp của mô
hình với bộ dữ liệu, trong trường hợp sử dụng tokenization
subword gần như giống với không có nó.

6 Thảo luận
Để cung cấp một số hiểu biết định tính từ nội dung được
sinh tạo, chúng tôi ở đây trình bày một phân tích chủ quan
cá nhân của một số kết quả. Mặc dù có kết quả tốt về mặt
tính cấu trúc tổng thể được trình bày trong Bảng 3, chúng
tôi nhận thấy rằng trong một số dịp mô hình chọn cách nghỉ
ngơi (im lặng) trong một vài nhịp. Điều này rõ ràng có thể
là một kết quả mong muốn đôi khi, nhưng như có thể quan
sát trong Hình 3, sự nghỉ ngơi từ nhịp 24 đến 28 dường như
làm giảm dòng chảy trước đó về mặt ý tưởng âm nhạc đằng
sau nó.

Hình 3: Ảnh chụp màn hình MuseScore của các nhịp 17 đến 34 của
mẫu 19 từ thí nghiệm MAESTRO BPE.

Hơn nữa, mặc dù cách tiếp cận tần suất trong các quy trình
tokenization subword, thường nhấn mạnh vào các kết hợp
từ/subword phổ biến hơn trong một corpus đã cho, đối với
trường hợp cụ thể của sinh tạo âm nhạc ký hiệu tập trung
vào guitar với bộ dữ liệu DadaGP, thật thú vị khi quan sát
rằng các token liên quan đến kỹ thuật biểu cảm guitar được
bảo tồn, mặc dù tần suất giảm của nó khi so sánh với các
token nốt nhạc.

Hình 4: Ảnh chụp màn hình GuitarPro của năm nhịp đầu tiên từ
mẫu 18 từ thí nghiệm DadaGP BPE. Chỉ có guitar méo mó là hiển
thị.

Như chúng ta có thể thấy từ Hình 4, các kỹ thuật biểu cảm
đặc thù của guitar như hammer-on và pull-off, bend, slide,
và vibrato, được sử dụng một cách phù hợp.

--- TRANG 7 ---
Hình 5: Ảnh chụp màn hình GuitarPro của chín nhịp đầu tiên từ
mẫu 10 từ thí nghiệm DadaGP Unigram. Chỉ có guitar méo mó là
hiển thị.

Để hỗ trợ trực quan cho các lập luận được đưa ra trong Phần
5.2 hướng tới việc cải thiện về mặt 'tính cấu trúc' của các
ví dụ được sinh tạo từ các mô hình tokenization subword,
trong Hình 5 chúng ta có thể quan sát rằng mô hình có thể
gọi lại các motif được chơi trong hai nhịp đầu tiên (tức là
cùng mẫu lặp lại trong nhịp bảy và tám). Từ nhịp 5, cũng
thú vị khi quan sát rằng mô hình có thể tham chiếu đến cùng
mẫu được giới thiệu trong hai nhịp đầu tiên nhưng cũng kết
hợp một vài nốt kết nối trong nhịp đầu tiên của nó.

Hình 6: Các biểu đồ fitness scape cho hai mẫu được sinh tạo từ
mỗi Cơ sở, BPE và Unigram cùng với các bài hát thực tương ứng
với bộ dữ liệu MAESTRO. Trục x đại diện cho trung tâm phân đoạn
(tính bằng giây) và trục y đại diện cho độ dài phân đoạn (tính bằng
giây) cho bất kỳ cấu trúc lặp lại nào trong âm nhạc

Một quan sát tương tự về cải thiện về mặt biểu diễn cấu trúc
có thể được thực hiện nếu chúng ta phân tích các biểu đồ
fitness scape cho các bài hát được sinh tạo so với các bài
hát thực. Một mẫu của quan sát như vậy được hiển thị trong
Hình 6 cho các mẫu bộ dữ liệu MAESTRO. Các đường viền
trong các vùng vàng/nâu trong các biểu đồ scape đại diện
cho cấu trúc lặp lại, với phía dưới ngụ ý cấu trúc lặp lại ngắn
hạn và phía trên ngụ ý cấu trúc lặp lại dài hạn. Một mô hình
tốt hơn là mô hình sinh tạo các bài hát có biểu đồ scape tương
tự như các bài hát thực vì sau đó cấu trúc âm nhạc của bộ
dữ liệu huấn luyện được nắm bắt một cách chính xác hơn.
Như chúng ta có thể quan sát từ các biểu đồ scape được đưa
ra trong Hình 6, có ít cấu trúc lặp lại dài hạn hơn nhiều trong
dữ liệu thực. Cả BPE và Unigram đều có biểu đồ scape của
chúng tương tự hơn với các bài hát thực, với ít vùng vàng
hơn ở phía trên của biểu đồ, so với mô hình cơ sở. Điều này
cho thấy rằng các mô hình BPE và Unigram nắm bắt cấu
trúc âm nhạc tổng thể của các bài hát thực tốt hơn mô hình
cơ sở, với Unigram là tốt nhất trong ba mô hình. Quan sát
này phù hợp với Bảng 3, cho thấy những cải thiện với việc
sử dụng các phương pháp tokenization subword.

7 Kết luận và Công trình Tương lai
Trong bài báo này, chúng tôi đã tiến hành một nghiên cứu
thực nghiệm để đánh giá tính hữu ích của các phương pháp
tokenization subword trong sinh tạo âm nhạc ký hiệu. Chúng
tôi đã nghiên cứu khách quan sự thay đổi hiệu suất của các
mô hình sinh tạo âm nhạc với việc sử dụng các kỹ thuật
tokenization subword như BPE và Unigram trong khi trả
lời hai câu hỏi cơ bản được đặt ra trong Phần 1. Nghiên
cứu của chúng tôi không chỉ cho thấy rằng BPE và Unigram,
như các kỹ thuật nén dữ liệu, không chỉ có thể biểu diễn dữ
liệu một cách hiệu quả hơn mà còn cải thiện cấu trúc tổng
thể của âm nhạc được sinh tạo với mô hình tích hợp token-
ization subword. Hơn nữa, kết quả này (và xu hướng cải
thiện) đúng bất kể mô hình, bộ dữ liệu, hoặc tokenization
âm nhạc được sử dụng. Nhìn chung, từ nghiên cứu của chúng
tôi, chúng tôi có thể kết luận rằng việc đưa tokenization
subword vào Sinh tạo Âm nhạc Ký hiệu có tác động tiềm
năng đến hiệu suất của mô hình và cấu trúc của âm nhạc
được sinh tạo, đồng thời cho phép sinh tạo âm nhạc dài hơn
cùng lúc.

Từ điểm này trở đi, công trình tương lai có thể đa dạng.
Một hướng có thể là khám phá tác động của kích thước từ
vựng đối với hiệu suất mô hình, tức là cách thỏa hiệp hiệu
suất từ vựng. Tương tự như text-NLP, nơi chúng ta thường
có kích thước từ vựng trong khoảng 50k, chúng ta có thể
tăng kích thước vocab ở đây để xem hiệu suất thay đổi như
thế nào với những thay đổi trong kích thước từ vựng. Một
hướng thú vị khác có thể là khám phá liệu kiến thức về Lý
thuyết Âm nhạc có thể được tận dụng phối hợp với các kỹ
thuật kiểu BPE hoặc Unigram, để phát triển một phiên bản
lai của tokenization subword, bao gồm đồng thời (như trong
Musical BPE) các sự kiện âm nhạc với sự liền kề của các
token. Tóm lại, có một phạm vi lớn của công trình tương lai
có thể được thực hiện, ngoài nghiên cứu này.

Tuyên bố Đạo đức
Việc huấn luyện các mô hình ngôn ngữ lớn là một quá trình
tính toán chuyên sâu đòi hỏi lượng năng lượng khổng lồ,
dẫn đến dấu chân carbon đáng kể. Các nhà cung cấp đám
mây ngày càng cung cấp các dịch vụ để huấn luyện và lưu
trữ các mô hình này, nhưng không phải tất cả đều cam kết
trở thành carbon trung tính, có nghĩa là chúng có thể đóng
góp vào phát thải khí nhà kính. Đây là một cân nhắc quan
trọng khi lựa chọn nhà cung cấp đám mây để huấn luyện
mô hình, vì nó có cả ý nghĩa môi trường và đạo đức.

Để giảm thiểu tác động của việc huấn luyện các mô hình
ngôn ngữ lớn, một giải pháp là phát hành các mô hình đã
được huấn luyện trước. Cách tiếp cận này cho phép những
người khác sử dụng các mô hình này mà không cần phải
trải qua quá trình huấn luyện tốn năng lượng từ đầu. Bằng
cách phát hành các mô hình đã được huấn luyện trước,
chúng tôi nhằm mục đích giảm dấu chân carbon liên quan
đến huấn luyện và làm cho việc sử dụng các mô hình này
theo cách bền vững hơn trở nên dễ dàng hơn. Ngoài ra,
việc phát hành các mô hình đã được huấn luyện trước cũng
có thể khuyến khích hợp tác và đổi mới trong lĩnh vực này,
thúc đẩy thêm sự phát triển của công nghệ AI.

Lời cảm ơn
Chúng tôi muốn bày tỏ lòng biết ơn chân thành đến Tiến sĩ
Yi-Hsuan Yang, vì sự giám sát và hướng dẫn của ông trong
suốt dự án nghiên cứu này. Lời khuyên chuyên môn và phản
hồi của Tiến sĩ Yang đã vô cùng quý giá trong việc định
hình hướng đi và kết quả của nghiên cứu này. Sự hỗ trợ và
động lực liên tục của ông rất quan trọng trong việc giữ cho
chúng tôi tập trung và được truyền cảm hứng. Chúng tôi
cũng muốn cảm ơn Tiến sĩ Sourav Mukhopadhyay, IIT Khar-
agpur vì đã cho chúng tôi cơ hội làm việc trong dự án này
như Dự án Luận văn Thạc sĩ của Adarsh.

Tài liệu tham khảo
[Conneau và Lample, 2019] Alexis Conneau và Guil-
laume Lample. Cross-lingual language model pretraining.
Trong H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-
Buc, E. Fox, và R. Garnett, biên tập, Advances in Neural
Information Processing Systems, tập 32. Curran Asso-
ciates, Inc., 2019.

[Dai et al., 2019a] Zihang Dai, Zhilin Yang, Yiming Yang,
Jaime Carbonell, Quoc V Le, và Ruslan Salakhutdi-
nov. Transformer-XL: Attentive Language Models Be-
yond a Fixed-Length Context. Trong Proc. of the 57th Annual
Meeting of the Association for Computational Linguistics,
2019.

[Dai et al., 2019b] Zihang Dai, Zhilin Yang, Yiming Yang,
Jaime Carbonell, Quoc V. Le, và Ruslan Salakhutdi-
nov. Transformer-xl: Attentive language models beyond
a fixed-length context, 2019.

[Dai et al., 2022] Shuqi Dai, Huiran Yu, và Roger B. Dan-
nenberg. What is missing in deep music generation? a
study of repetition and structure in popular music, 2022.

[Devlin et al., 2018] Jacob Devlin, Ming-Wei Chang, Ken-
ton Lee, và Kristina Toutanova. Bert: Pre-training of
deep bidirectional transformers for language understand-
ing, 2018.

[Dong và Yang, 2018] Hao-Wen Dong và Yi-Hsuan Yang.
Convolutional Generative Adversarial Networks with Bi-
nary Neurons for Polyphonic Music Generation. Trong Proc.
of the 19th Int. Soc. for Music Information Retrieval Conf.
(ISMIR), 2018.

[Dong et al., 2020] Hao-Wen Dong, Ke Chen, Julian J.
McAuley, và Taylor Berg-Kirkpatrick. Muspy: A toolkit

--- TRANG 8 ---
for symbolic music generation. CoRR, abs/2008.01951,
2020.

[Foote, 1999] Jonathan Foote. Visualizing music and audio
using self-similarity. Trong Proceedings of the Seventh ACM
International Conference on Multimedia (Part 1), MUL-
TIMEDIA '99, trang 77–80, New York, NY, USA, 1999.
Association for Computing Machinery.

[Fradet et al., 2021] Nathan Fradet, Jean-Pierre Briot, Fa-
bien Chhel, Amal El Fallah Seghrouchni, và Nicolas
Gutowski. Miditok: A python package for midi file to-
kenization. Trong Extended Abstracts for the Late-Breaking
Demo Session of the 22nd International Society for Music
Information Retrieval Conference, 2021.

[Gage, 1994] Philip Gage. A new algorithm for data com-
pression. The C Users Journal archive, 12:23–38, 1994.

[Gallé, 2019] Matthias Gallé. Investigating the effectiveness
of BPE: The power of shorter sequences. Trong Proceedings
of the 2019 Conference on Empirical Methods in Natu-
ral Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-
IJCNLP), trang 1375–1381, Hong Kong, China, Novem-
ber 2019. Association for Computational Linguistics.

[Guo et al., 2022] Rui Guo, Ivor Simpson, Chris Kiefer,
Thor Magnusson, và Dorien Herremans. Musiac: An ex-
tensible generative framework for music infilling applica-
tions with multi-level control, 2022.

[Hawthorne et al., 2019] Curtis Hawthorne, Andriy Stasyuk,
Adam Roberts, Ian Simon, Cheng-Zhi Anna Huang,
Sander Dieleman, Erich Elsen, Jesse Engel, và Douglas
Eck. Enabling factorized piano music modeling and gen-
eration with the MAESTRO dataset. Trong International Con-
ference on Learning Representations, 2019.

[Hiller, 2019] Lejaren Hiller. IV. Music Composed With
Computers—A Historical Survey, trang 42–96. Cornell
University Press, Ithaca, NY, 2019.

[Hsiao et al., 2021] Wen-Yi Hsiao, Jen-Yu Liu, Yin-Cheng
Yeh, và Yi-Hsuan Yang. Compound Word Transformer:
Learning to Compose Full-Song Music Over Dynamic Di-
rected Hypergraphs. Trong Proc. of the AAAI Conf. on Arti-
ficial Intelligence, 2021.

[Huang và Yang, 2020] Yu-Siang Huang và Yi-Hsuan
Yang. Pop Music Transformer: Beat-based Modeling and
Generation of Expressive Pop Piano Compositions. Trong
Proc. of the 28th ACM Int. Conf. on Multimedia, 2020.

[Huang et al., 2018] Cheng-Zhi Anna Huang, Ashish
Vaswani, Jakob Uszkoreit, Noam Shazeer, Curtis
Hawthorne, Andrew M. Dai, Matthew D. Hoffman,
và Douglas Eck. An improved relative self-attention
mechanism for transformer with application to music
generation. CoRR, abs/1809.04281, 2018.

[Huang et al., 2019] Cheng-Zhi Anna Huang, Ashish
Vaswani, Jakob Uszkoreit, Noam Shazeer, Ian Simon,
Curtis Hawthorne, Andrew M. Dai, Matthew D. Hoffman,
Monica Dinculescu, và Douglas Eck. Music Trans-
former: Generating Music with Long-term Structure. Trong

Proc. of the 7th Int. Conf. on Learning Representations,
2019.

[Kudo và Richardson, 2018] Taku Kudo và John Richard-
son. Sentencepiece: A simple and language independent
subword tokenizer and detokenizer for neural text process-
ing. CoRR, abs/1808.06226, 2018.

[Kudo, 2018] Taku Kudo. Subword regularization: Improv-
ing neural network translation models with multiple sub-
word candidates. Trong Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguistics (Vol-
ume 1: Long Papers), trang 66–75, Melbourne, Australia,
July 2018. Association for Computational Linguistics.

[Liu et al., 2019] Yinhan Liu, Myle Ott, Naman Goyal,
Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike
Lewis, Luke Zettlemoyer, và Veselin Stoyanov. Roberta:
A robustly optimized BERT pretraining approach. CoRR,
abs/1907.11692, 2019.

[Liu et al., 2022] Jiafeng Liu, Yuanliang Dong, Zehua
Cheng, Xinran Zhang, Xiaobing Li, Feng Yu, và
Maosong Sun. Symphony generation with permutation in-
variant language model. 2022.

[Meade et al., 2019] Nicholas Meade, Nicholas Barreyre,
Scott C Lowe, và Sageev Oore. Exploring Conditioning
for Generative Music Systems with Human-Interpretable
Controls. 2019.

[Mielke et al., 2021] Sabrina J. Mielke, Zaid Alyafeai, Eliz-
abeth Salesky, Colin Raffel, Manan Dey, Matthias Gallé,
Arun Raja, Chenglei Si, Wilson Y. Lee, Benoît Sagot, và
Samson Tan. Between words and characters: A brief his-
tory of open-vocabulary modeling and tokenization in nlp,
2021.

[Muhamed et al., 2021] Aashiq Muhamed, Liang Li,
Xingjian Shi, Suri Yaddanapudi, Wayne Chi, Dylan Jack-
son, Rahul Suresh, Zachary C. Lipton, và Alexander J.
Smola. Symbolic music generation with transformer-gans.
Trong 35th AAAI Conference on Artificial Intelligence, AAAI
2021, 2021.

[Müller et al., 2011] Meinard Müller, Peter Grosche, và
Nanzhu Jiang. A segment-based fitness measure for cap-
turing repetitive structures of music recordings. trang
615–620, 01 2011.

[Neves et al., 2022] Pedro Neves, Jose Fornari, và João
Florindo. Generating music with sentiment using
transformer-gans, 2022.

[Oore et al., 2018] Sageev Oore, Ian Simon, Sander Diele-
man, Douglas Eck, và Karen Simonyan. This time with
feeling: Learning expressive musical performance. Neural
Computing and Applications, 2018.

[Park et al., 2020] Kyubyong Park, Joohong Lee, Seongbo
Jang, và Dawoon Jung. An empirical study of tokeniza-
tion strategies for various Korean NLP tasks. Trong Pro-
ceedings of the 1st Conference of the Asia-Pacific Chap-
ter of the Association for Computational Linguistics and
the 10th International Joint Conference on Natural Lan-
guage Processing, trang 133–142, Suzhou, China, De-
cember 2020. Association for Computational Linguistics.

[Payne, 2019] Christine Payne. Musenet, 2019.

[Peracha, 2020] Omar A Peracha. Improving polyphonic
music models with feature-rich encoding. 2020.

[Radford et al., 2019] Alec Radford, Jeff Wu, Rewon Child,
David Luan, Dario Amodei, và Ilya Sutskever. Language
models are unsupervised multitask learners. 2019.

[Sarmento et al., 2021] Pedro Sarmento, Adarsh Kumar,
CJ Carr, Zack Zukowski, Mathieu Barthet, và Yi-Hsuan
Yang. DadaGP: a Dataset of Tokenized GuitarPro Songs
for Sequence Models. Trong Proc. of the 22nd Int. Soc. for
Music Information Retrieval Conf., 2021.

[Sarmento et al., 2023] Pedro Sarmento, Adarsh Kumar, Yu-
Hua Chen, CJ Carr, Zack Zukowski, và Mathieu Barthet.
Gtr-ctrl: Instrument and genre conditioning for guitar-
focused music generation with transformers, 2023.

[Sennrich et al., 2016] Rico Sennrich, Barry Haddow, và
Alexandra Birch. Neural machine translation of rare words
with subword units. Trong Proceedings of the 54th Annual
Meeting of the Association for Computational Linguistics
(Volume 1: Long Papers), trang 1715–1725, Berlin, Ger-
many, August 2016. Association for Computational Lin-
guistics.

[Sturm et al., 2016] Bob L. Sturm, João Felipe Santos, Oded
Ben-Tal, và Iryna Korshunova. Music transcription mod-
elling and composition using deep learning. Trong Proc. on
the 1st Conf. on Computer Simulation of Musical Creativ-
ity, 2016.

[Tan và Herremans, 2020] Hao Hao Tan và Dorien Her-
remans. Music FaderNets: Controllable Music Genera-
tion Based On High-Level Features via Low-Level Feature
Modelling. Trong Proc. of the 21st Int. Soc. for Music Infor-
mation Retrieval Conf., 2020.

[Vaswani et al., 2017] Ashish Vaswani, Noam Shazeer, Niki
Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Łukasz Kaiser, và Illia Polosukhin. Attention Is All You
Need. Trong Proc. of the 31st Conf. on Neural Information
Processing Systems, 2017.

[Wang et al., 2020] Ziyu Wang, Dingsu Wang, Yixiao
Zhang, và Gus Xia. Learning Interpretable Represen-
tation for Controllable Polyphonic Music Generation. Trong
Proc. of the 21st Int. Soc. for Music Information Retrieval
Conf., Montréal, Canada, 2020.

[Wolf et al., 2020] Thomas Wolf, Lysandre Debut, Victor
Sanh, Julien Chaumond, Clement Delangue, Anthony
Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan
Funtowicz, Joe Davison, Sam Shleifer, Patrick von
Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen
Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame,
Quentin Lhoest, và Alexander M. Rush. Huggingface's
transformers: State-of-the-art natural language processing,
2020.

[Wu và Yang, 2020] Shih-Lun Wu và Yi-Hsuan Yang. The
jazz transformer on the front line: Exploring the shortcom-
ings of ai-composed music through quantitative measures.
CoRR, abs/2008.01307, 2020.

--- TRANG 9 ---

--- TRANG 10 ---
[Wu và Yang, 2022] Shih-Lun Wu và Yi-Hsuan Yang.
Compose & embellish: Well-structured piano perfor-
mance generation via a two-stage approach, 2022.

[Wu et al., 2016] Yonghui Wu, Mike Schuster, Zhifeng
Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang
Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus
Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson,
Xiaobing Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo
Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George
Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason
Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg
Corrado, Macduff Hughes, và Jeffrey Dean. Google's
neural machine translation system: Bridging the gap be-
tween human and machine translation, 2016.

# 2309.10952.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2309.10952.pdf
# Kích thước file: 1424525 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
LMDX: Trích xuất và Định vị Thông tin Tài liệu dựa trên Mô hình Ngôn ngữ
Vincent Perot1*, Kai Kang2, Florian Luisier2, Guolong Su1,
Xiaoyu Sun2, Ramya Sree Boppana2, Zilong Wang5, Zifeng Wang3,
Jiaqi Mu1, Hao Zhang4, Chen-Yu Lee3, Nan Hua1
1Google DeepMind2Google Cloud
3Google Cloud AI Research4Google5UC San Diego
Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLM) đã cách mạng hóa Xử lý Ngôn ngữ Tự nhiên (NLP), cải thiện hiệu suất tiên tiến và thể hiện các khả năng nổi bật trên nhiều tác vụ khác nhau. Tuy nhiên, việc áp dụng chúng trong việc trích xuất thông tin từ các tài liệu giàu thông tin trực quan, vốn là cốt lõi của nhiều quy trình xử lý tài liệu và bao gồm việc trích xuất các thực thể chính từ các tài liệu bán cấu trúc, vẫn chưa thành công. Các rào cản chính trong việc áp dụng LLM cho tác vụ này bao gồm việc thiếu mã hóa bố cục trong LLM, điều này rất quan trọng cho việc trích xuất chất lượng cao, và việc thiếu cơ chế định vị để xác định vị trí các thực thể được dự đoán trong tài liệu. Trong bài báo này, chúng tôi giới thiệu Trích xuất và Định vị Thông tin Tài liệu dựa trên Mô hình Ngôn ngữ (LMDX), một phương pháp để tái định khung tác vụ trích xuất thông tin tài liệu cho LLM. LMDX cho phép trích xuất các thực thể đơn lẻ, lặp lại và phân cấp, cả với và không có dữ liệu huấn luyện, đồng thời cung cấp đảm bảo định vị và xác định vị trí các thực thể trong tài liệu. Cuối cùng, chúng tôi áp dụng LMDX cho các LLM PaLM 2-S và Gemini Pro và đánh giá nó trên các tiêu chuẩn VRDU và CORD, thiết lập một hiệu suất tiên tiến mới và cho thấy cách LMDX cho phép tạo ra các trình phân tích chất lượng cao, hiệu quả dữ liệu.

1 Giới thiệu
Sự ra đời gần đây của transformer (Vaswani et al., 2017) và các quy trình tiền huấn luyện tự giám sát đã dẫn đến tiến bộ đáng kể trong Hiểu Tài liệu Giàu Thông tin Trực quan (VRD). Trong lĩnh vực đó, tác vụ trích xuất thông tin tài liệu (IE), bao gồm việc trích xuất các thực thể chính trong một tài liệu bán cấu trúc (ví dụ: hóa đơn, biểu mẫu thuế, phiếu lương, biên lai, v.v.) theo một lược đồ được xác định trước, đã nhận được nhiều sự chú ý từ ngành công nghiệp và học thuật do tầm quan trọng và khả năng áp dụng rộng rãi của nó trong các quy trình xử lý tài liệu thông minh.

*Liên hệ với <vperot@google.com>.

Tuy nhiên, việc trích xuất thông tin tài liệu vẫn còn đầy thách thức đối với các hệ thống chính thống.

Cụ thể, thông tin trong các biểu mẫu bán cấu trúc được tổ chức theo bố cục phức tạp trên nhiều mẫu có thể có, điều này đòi hỏi sự hiểu biết sâu sắc về ngữ cảnh tài liệu, sự liên kết không gian giữa các phân đoạn văn bản khác nhau, và sự sắp xếp dạng bảng của các thực thể phân cấp (chúng tôi định nghĩa các thực thể phân cấp là các thực thể được cấu tạo từ các thực thể lá được nhóm lại một cách logic, ví dụ: các mục hàng trên hóa đơn gồm mô tả mặt hàng, số lượng và giá, hoặc các khoản khấu trừ trên phiếu lương gồm loại khấu trừ và số tiền, v.v.). Hơn nữa, vì một số quy trình tự động hóa tài liệu kinh doanh đòi hỏi một mức độ chính xác nhất định, chúng thường được tích hợp với các tương tác con người-trong-vòng-lặp để kiểm tra và sửa chữa các dự đoán, đòi hỏi phải biết vị trí chính xác của các thực thể được trích xuất để làm cho đó trở thành một tác vụ khả thi cho một người đánh giá. Cuối cùng, vì tồn tại một số lượng gần như vô hạn các loại tài liệu, và các tổ chức có tài nguyên chú thích hạn chế, hầu hết các trình phân tích được xây dựng với rất ít dữ liệu huấn luyện. Từ những phức tạp đó nảy sinh các yêu cầu sau đây của hệ thống trích xuất thông tin tài liệu: chúng nên (1) hỗ trợ việc trích xuất chất lượng cao các thực thể đơn lẻ, lặp lại và phân cấp, đồng thời (2) định vị các thực thể đó trong tài liệu, và (3) thực hiện điều đó với chi phí chú thích dữ liệu rất thấp hoặc không có.

Cho đến nay, không có hệ thống được công bố công khai nào có thể giải quyết tất cả các yêu cầu đó. Các hệ thống IE tài liệu chính thống hiện tại dựa trên gắn thẻ trình tự và tạo trình tự. Các phương pháp gắn thẻ trình tự (Palm et al., 2017; Lee et al., 2021, 2022, 2023a; Wang et al., 2023c) phân loại mỗi token thành các thẻ Inside-Outside-Begin (IOB) (Ramshaw và Marcus, 1995), hỗ trợ việc trích xuất và định vị các thực thể lá. Tuy nhiên, việc mở rộng các phương pháp này cho các thực thể phân cấp là không tầm thường. Các phương pháp dựa trên tạo trình tự (Powalski et al., 2021; Kim et al., 2022) coi việc trích xuất như việc tạo văn bản với các bộ giải mã tự hồi quy (Sutskever et al., 2014). Mặc dù hướng nghiên cứu này cho phép dự đoán các thực thể phân cấp, nhưng nó không cho phép định vị các thực thể trong tài liệu. Hơn nữa, cả hai loại đều đòi hỏi chi phí chú thích con người đáng kể để đảm bảo việc trích xuất chất lượng cao. Do đó, một khung IE thống nhất giải quyết cả ba yêu cầu này là rất có giá trị.

Song song với đó, các Mô hình Ngôn ngữ Lớn (LLM) (OpenAI, 2023a; Google et al., 2023; Hoffmann et al., 2022) đã cách mạng hóa Xử lý Ngôn ngữ Tự nhiên, cho thấy khả năng giải quyết các tác vụ đa dạng với một hướng dẫn (Wei et al., 2022) hoặc một vài minh chứng được đính kèm vào lời nhắc (Brown et al., 2020). Sự thay đổi mô hình này mở ra khả năng trích xuất các thực thể đồng thời giải quyết tất cả các yêu cầu nêu trên, nhưng việc sử dụng LLM cho VRD IE vẫn chưa được khám phá đầy đủ. Wang et al. (2023a) đề xuất một LLM tập trung vào tài liệu và đóng khung IE như một tác vụ hỏi-đáp, cho phép trích xuất zero-shot nhưng thiếu hỗ trợ định vị và trích xuất thực thể phân cấp. Hơn nữa, điều này có thể gặp phải ảo giác, một vấn đề phổ biến với LLM (Huang et al., 2023).

Điều này thúc đẩy chúng tôi giới thiệu Trích xuất và Định vị Thông tin Tài liệu dựa trên Mô hình Ngôn ngữ (LMDX), một phương pháp có nguyên tắc để tận dụng các LLM hiện có cho việc trích xuất thông tin và định vị trên các tài liệu giàu thông tin trực quan, đáp ứng cả ba yêu cầu đã xác định của hệ thống trích xuất và được mô tả chi tiết trong Hình 1. Sự so sánh các đặc điểm của LMDX và các hệ thống trích xuất thông tin tài liệu khác có thể được tìm thấy tại Bảng 1.

Các đóng góp của chúng tôi có thể được tóm tắt như sau:

• Chúng tôi trình bày một công thức có nguyên tắc cho phép LLM thực hiện tác vụ IE tài liệu trên các thực thể lá và phân cấp với định vị thực thể chính xác, bao gồm cả việc không có bất kỳ dữ liệu huấn luyện nào, và chỉ sử dụng giao diện đơn giản văn bản-vào, văn bản-ra có thể áp dụng cho LLM.

• Chúng tôi đề xuất một lược đồ mã hóa bố cục truyền đạt thông tin không gian cho LLM mà không cần bất kỳ thay đổi nào đối với kiến trúc của nó.

• Chúng tôi giới thiệu một thuật toán giải mã chuyển đổi các phản hồi từ LLM thành các thực thể được trích xuất và các hộp giới hạn tương ứng của chúng trên tài liệu, đồng thời loại bỏ bất kỳ ảo giác nào của LLM.

• Chúng tôi đánh giá một cách hệ thống hiệu quả dữ liệu của LMDX trên nhiều tiêu chuẩn công khai, thiết lập một hiệu suất tiên tiến mới, và cung cấp nghiên cứu mở rộng về các thiết kế cốt lõi khác nhau để chứng minh tính hiệu quả của chúng.

Bảng 1: So sánh các hệ thống trích xuất thông tin tài liệu. Không giống như các hệ thống IE tài liệu chính thống, LMDX cho phép trích xuất zero-shot, bao gồm các thực thể phân cấp, tất cả đều có định vị dự đoán.

Hệ thống Trích xuất Thông tin Tài liệu | Thực thể phân cấp | Định vị thực thể | Hỗ trợ Zero-shot
LayoutLMv3 (Huang et al., 2022), FormNetV2 (Lee et al., 2023a), | ✗ | ✓ | ✗
Donut (Kim et al., 2022) | ✓ | ✗ | ✗
DocLLM (Wang et al., 2023a) | ✗ | ✗ | ✓
LMDX (Của chúng tôi) | ✓ | ✓ | ✓

2 Nghiên cứu Liên quan

Đóng khung IE từ VRD. Trích xuất Thông tin từ VRD là một tác vụ phức tạp có thể được đóng khung theo nhiều cách khác nhau. Nhiều phương pháp chia vấn đề thành hai nhiệm vụ con: một bước nhận dạng/tuần tự hóa văn bản, thường được thực hiện bởi một dịch vụ Nhận dạng Ký tự Quang học (OCR), tiếp theo là một bước phân tích, tìm các giá trị thực thể có liên quan từ văn bản được nhận dạng. Xu et al. (2021); Appalaraju et al. (2021) đóng khung bước phân tích này như Nhận dạng Thực thể Có tên (NER), mã hóa mỗi token với một bộ mã hóa transformer và phân loại mỗi token tài liệu thành các thẻ IOB, cho phép trích xuất và định vị chỉ các thực thể lá. Các phương pháp khác coi việc trích xuất như một vấn đề tạo trình tự. Powalski et al. (2021) thêm một bộ giải mã tự hồi quy trên một bộ mã hóa văn bản-bố cục-hình ảnh, tất cả được khởi tạo từ T5 (Raffel et al., 2020). Điều này cho phép dự đoán các thực thể phân cấp, nhưng không định vị các thực thể trong tài liệu. Trong khi LMDX vẫn đóng khung VRD IE như một tác vụ tạo trình tự, công trình của chúng tôi tương phản với các nghiên cứu trước bằng cách kết hợp các ưu điểm của các đóng khung khác nhau như được thể hiện trong Bảng 1, hỗ trợ các thực thể phân cấp, trích xuất zero-shot và định vị các thực thể thông qua việc giới thiệu các token tọa độ.

Học Biểu diễn VRD. Vì VRD chứa cả các yếu tố văn bản và trực quan có vị trí không gian rất quan trọng cho việc hiểu chúng, nhiều nghiên cứu khám phá các kiến trúc tùy chỉnh và chiến lược tiền huấn luyện để học mối quan hệ giữa các phương thức văn bản, bố cục và hình ảnh (Lee et al., 2023a; Appalaraju et al., 2023; Zhang et al., 2022). Xu et al. (2020) sử dụng một bộ mã hóa hình ảnh riêng biệt trước khi thêm đầu ra như đặc trưng vào việc mã hóa token, trong khi Huang et al. (2022) mô hình hóa chung các vùng hình ảnh trang cùng với các token, sử dụng một nhiệm vụ tiền huấn luyện tự giám sát căn chỉnh từ-vùng để học kết nối giữa các phương thức. Hong et al. (2021) đề xuất mã hóa khoảng cách 2D tương đối của các khối văn bản trong sự chú ý của transformer, và học từ các tài liệu không nhãn với chiến lược che khuất khu vực. Kim et al. (2022); Lee et al. (2023b) bỏ qua hoàn toàn phương thức văn bản, sử dụng bộ mã hóa Vision Transformer với bộ giải mã tự hồi quy được tiền huấn luyện trên nhiệm vụ OCR giả và che khuất vùng trên kho ngữ liệu hình ảnh tài liệu lớn. Khác với các nghiên cứu trước, LMDX mã hóa phương thức bố cục hoàn toàn thông qua các token tọa độ văn bản, do đó cho phép tái sử dụng LLM không cần thay đổi kiến trúc và bỏ qua các bộ mã hóa thị giác đắt tiền, đồng thời đạt được kết quả tiên tiến.

LLM cho Trích xuất chủ yếu được nghiên cứu trong lĩnh vực văn bản (Keraghel et al., 2024), hoặc chung chung (Laskar et al., 2023) hoặc theo lĩnh vực cụ thể (De Toni et al., 2022; Hu et al., 2024). Wang et al. (2023b) sử dụng LLM để chèn các token đặc biệt để đánh dấu ranh giới của các thực thể mục tiêu. Ashok và Lipton (2023) đề xuất một khung NER với các minh chứng học trong ngữ cảnh, nhắc LLM xuất ra một danh sách thực thể với các giải thích biện minh cho việc khớp của nó với các định nghĩa thực thể được cung cấp. Tuy nhiên, LLM vẫn chưa được khám phá đầy đủ cho IE trên VRD. Wang et al. (2023a) sử dụng kho ngữ liệu tài liệu không nhãn và chuyển đổi các tập dữ liệu hiểu VRD có nhãn hiện có thành định dạng điều chỉnh hướng dẫn, xây dựng một LLM nhận thức bố cục với nhiều khả năng hiểu tài liệu khác nhau. Ngược lại, LMDX tập trung cụ thể vào IE, với sự nhấn mạnh vào hỗ trợ thực thể phân cấp và định vị thực thể.

3 Phương pháp LMDX

Tổng thể, quy trình của chúng tôi được chia thành bốn giai đoạn: phân đoạn, tạo lời nhắc, suy luận LLM và giải mã, được mô tả chi tiết trong các phần sau. Tổng quan với một ví dụ đơn giản có thể được tìm thấy trong Hình 1, với đầu vào và đầu ra của mỗi giai đoạn được trưng bày. Trong ví dụ này, lược đồ trích xuất mục tiêu chứa hai loại thực thể lá retailer và subtotal, và một loại thực thể phân cấp line_item, bao gồm product_id và product_price.

Tài liệu Đầu vào. Đầu vào cho quy trình của chúng tôi là các phân đoạn văn bản của tài liệu (dòng và từ) cùng với vị trí không gian tương ứng (hộp giới hạn) trên các trang, thường được lấy từ dịch vụ OCR hoặc công cụ kết xuất PDF.

3.1 Giai đoạn Đầu tiên: Phân đoạn

Trong khi một số LLM hỗ trợ ngữ cảnh dài (hàng trăm nghìn token), không phải tất cả LLM đều có thể vừa toàn bộ tài liệu trong lời nhắc của nó, vì tài liệu có thể dài hàng trăm trang. Do đó, tài liệu được chia thành các khối tài liệu để mỗi khối đủ nhỏ để được xử lý bởi LLM. Để đạt được điều này, chúng tôi trước tiên chia tài liệu thành các trang riêng lẻ, sau đó chúng tôi lặp lại việc loại bỏ các phân đoạn dòng cuối cùng cho đến khi lời nhắc chứa khối này nằm dưới độ dài token đầu vào tối đa của LLM. Cuối cùng, chúng tôi nhóm các dòng bị loại bỏ đó thành một trang tài liệu mới, và lặp lại logic tương tự cho đến khi tất cả các khối đều nằm dưới giới hạn token đầu vào của LLM. Cuối giai đoạn này, chúng tôi có N khối. Quyết định chia tài liệu theo trang trước tiên xuất phát từ quan sát rằng các thực thể hiếm khi vượt qua ranh giới trang, và do đó lược đồ phân đoạn này sẽ có tác động tối thiểu đến chất lượng trích xuất cuối cùng. Thuật toán được mô tả bằng mã giả trong Phụ lục A.1.

3.2 Giai đoạn Thứ hai: Tạo Lời nhắc

Giai đoạn tạo lời nhắc nhận N khối tài liệu và tạo một lời nhắc LLM cho mỗi khối. Như được thấy trong Hình 2, thiết kế lời nhắc của chúng tôi chứa biểu diễn tài liệu, mô tả tác vụ, và biểu diễn lược đồ mục tiêu chứa các thực thể cần trích xuất. Các thẻ giống XML được sử dụng để định nghĩa điểm bắt đầu và kết thúc của mỗi thành phần.

<Document>{DOCUMENT_REPRESENTATION}</Document><Task>{TASK_DESCRIPTION}{SCHEMA_REPRESENTATION}</Task><Extraction>

Hình 2: Cấu trúc của các lời nhắc LLM.

Biểu diễn Tài liệu. Nội dung khối được biểu diễn trong lời nhắc như sự nối tiếp của tất cả các văn bản phân đoạn của nó (dòng hoặc từ từ OCR), được hậu tố với tọa độ của các phân đoạn đó (được suy ra từ các hộp giới hạn) theo định dạng sau: <văn bản phân đoạn> XX|YY phân đoạn. Các token tọa độ, XX và YY, được xây dựng bằng cách chuẩn hóa tọa độ X và Y của phân đoạn, và lượng tử hóa chúng trong B nhóm, gán chỉ số của nhóm đó làm token cho tọa độ đó.

Mã hóa tọa độ như các token trong lời nhắc cho phép chúng tôi truyền đạt phương thức bố cục cho LLM, mà không cần thay đổi kiến trúc của nó. Có nhiều biến thể của lược đồ đó: sử dụng dòng so với từ như phân đoạn, độ chi tiết của lượng tử hóa, và số tọa độ sử dụng cho mỗi phân đoạn (ví dụ: [xcenter, ycenter] so với [xmin, ymin, xmax, ymax]). Phụ lục A.4 cho thấy các biến thể đó ảnh hưởng đến độ dài token lời nhắc như thế nào.

Qua thử nghiệm, chúng tôi đã tìm thấy việc sử dụng các phân đoạn cấp dòng với 2 tọa độ [xcenter, ycenter] và B=100 nhóm lượng tử hóa hoạt động tốt nhất, như được mô tả chi tiết trong Phụ lục A.12. Do đó, chúng tôi đã áp dụng lược đồ token hóa tọa độ đó trong các thử nghiệm của mình.

Mô tả Tác vụ. Mô tả tác vụ chỉ đơn giản là một giải thích ngắn gọn về tác vụ cần hoàn thành. Trong các thử nghiệm của chúng tôi, chúng tôi đặt nó như sau: Từ tài liệu, trích xuất các giá trị văn bản và thẻ của các thực thể sau:

Biểu diễn Lược đồ. Lược đồ được biểu diễn như một đối tượng JSON có cấu trúc, trong đó các khóa là các loại thực thể cần được trích xuất, và các giá trị tương ứng với sự xuất hiện của chúng (đơn hoặc nhiều) và các thực thể con (đối với các thực thể phân cấp). Ví dụ, {"foo": "", "bar": [{"baz": []}]} có nghĩa là LLM nên trích xuất chỉ một thực thể đơn lẻ loại foo và nhiều thực thể phân cấp loại bar, mỗi thực thể có thể chứa nhiều thực thể loại baz.

Sau bước này, chúng tôi có N lời nhắc, một cho mỗi khối tài liệu. Ví dụ về một lời nhắc trên tài liệu có thể được tìm thấy trong Phụ lục A.8, Hình 10.

3.3 Mục tiêu Hoàn thành

Trong phần này, chúng tôi mô tả định dạng hoàn thành LLM được mong đợi, có thể được quan sát trong phần LLM Completions của Hình 1. Giống như lược đồ, việc hoàn thành là một đối tượng JSON có cấu trúc với các khóa là các loại thực thể, và các giá trị là thông tin được trích xuất từ khối tài liệu. JSON được chọn làm định dạng cho việc hoàn thành và lược đồ vì nó hỗ trợ các đối tượng phân cấp (do đó các thực thể phân cấp), rất hiệu quả về token, và việc phát ra JSON nằm trong khả năng của các LLM chính thống (Sengottuvelu, 2023; OpenAI, 2023b).

Lưu ý rằng các khóa trong việc hoàn thành có cùng thứ tự, sự xuất hiện và lớp (phân cấp hoặc lá) như các loại thực thể trong lược đồ. Các giá trị của thực thể lá phải tuân theo một định dạng cụ thể:

<văn bản trên phân đoạn1> XX|YY phân đoạn1 \n
<văn bản trên phân đoạn2> XX|YY phân đoạn2 \n ...

Một thực thể có thể trải dài trên nhiều (có thể rời rạc) phân đoạn văn bản (dòng hoặc từ). Đối với mỗi phân đoạn của thực thể, giá trị chứa văn bản thực thể trên phân đoạn đó, cùng với các token tọa độ của phân đoạn đó, hoạt động như một định danh phân đoạn, xác định duy nhất phân đoạn, và cho phép chúng tôi định vị các thực thể và cơ sở dự đoán mô hình (ví dụ: đảm bảo rằng giá trị được trích xuất không phải là ảo giác), như sẽ được mô tả chi tiết trong Phần 3.5. Cuối cùng, các loại thực thể bị thiếu được hoàn thành một cách rõ ràng bởi mô hình với null cho các loại đơn lẻ, và [] cho các loại lặp lại. Các mẫu hoàn thành có thể được tìm thấy trong Phụ lục A.8, Hình 10.

3.4 Giai đoạn Thứ ba: Suy luận LLM

Trong giai đoạn này của quy trình, chúng tôi chạy suy luận trên LLM với N lời nhắc. Đối với mỗi lời nhắc, chúng tôi lấy mẫu K hoàn thành từ LLM (tổng cộng NK hoàn thành cho toàn bộ tài liệu) bằng cách sử dụng Top K sampling. Tính ngẫu nhiên này trong việc lấy mẫu cho phép thực hiện sửa lỗi (ví dụ: nếu một phản hồi không phải là JSON hợp lệ, có định danh tọa độ phân đoạn ảo giác, v.v.), và tăng chất lượng trích xuất như sẽ được thể hiện trong Phần 4.3. Chúng tôi sử dụng một seed ngẫu nhiên cố định để có được suy luận xác định.

3.5 Giai đoạn Thứ tư: Giải mã

Trong giai đoạn này (Giải mã trong Hình 1), chúng tôi phân tích các hoàn thành LLM thành các thực thể và vị trí của chúng.

Chuyển đổi thành các thực thể có cấu trúc. Chúng tôi bắt đầu bằng cách phân tích mỗi hoàn thành LLM như một đối tượng JSON. Các hoàn thành không phân tích được sẽ bị loại bỏ. Đối với mỗi cặp khóa-giá trị trong đối tượng JSON, chúng tôi hiểu khóa là loại thực thể và phân tích giá trị để có được văn bản thực thể và hộp giới hạn (như được mô tả chi tiết trong đoạn tiếp theo). Các loại thực thể được dự đoán không nằm trong lược đồ trích xuất mục tiêu sẽ bị loại bỏ. Nếu mô hình dự đoán bất ngờ nhiều giá trị cho các loại thực thể xuất hiện đơn lẻ, chúng tôi sử dụng giá trị phổ biến nhất làm giá trị dự đoán cuối cùng. Các đối tượng JSON phân cấp được phân tích đệ quy như các thực thể phân cấp theo cách tương tự. Thuật toán này được mô tả bằng mã giả trong Phụ lục A.3.

Phân tích Giá trị Thực thể. Chúng tôi mong đợi giá trị JSON bao gồm cả các trích xuất văn bản và định danh phân đoạn cho mỗi thực thể được dự đoán, như được mô tả trong Phần 3.3. Chúng tôi trước tiên phân tích giá trị thành các cặp (văn bản phân đoạn, định danh phân đoạn). Đối với mỗi cặp, chúng tôi tra cứu phân đoạn tương ứng trong tài liệu gốc bằng cách sử dụng định danh phân đoạn và xác minh rằng văn bản được trích xuất được bao gồm chính xác trong phân đoạn đó. Thực thể sẽ bị loại bỏ nếu việc xác minh đó thất bại, đảm bảo LMDX loại bỏ tất cả các ảo giác LLM. Cuối cùng, khi chúng tôi có vị trí thực thể trên tất cả các phân đoạn của nó, chúng tôi có được hộp giới hạn thực thể bằng cách tính toán hộp giới hạn nhỏ nhất bao bọc tất cả các từ được bao gồm trong thực thể. Các giá trị thực thể có bất kỳ phân đoạn nào thất bại trong việc cơ sở (định dạng giá trị thực thể không hợp lệ, định danh phân đoạn không tồn tại, hoặc văn bản phân đoạn không khớp) trong tài liệu gốc sẽ bị loại bỏ. Thuật toán phân tích giá trị thực thể được mô tả bằng mã giả trong Phụ lục A.2, và tỷ lệ lỗi phân tích được mô tả chi tiết trong Phụ lục A.10.

Hợp nhất Dự đoán. Chúng tôi trước tiên hợp nhất các thực thể được dự đoán cho cùng một khối tài liệu từ K hoàn thành LLM thông qua biểu quyết đa số (Wang et al., 2022). Đối với mỗi loại thực thể, chúng tôi thu thập các thực thể được dự đoán, bao gồm cả các dự đoán trống, trên K hoàn thành. Các dự đoán phổ biến nhất được chọn làm giá trị dự đoán cho loại thực thể đó. Sau đó chúng tôi hợp nhất các dự đoán giữa N khối tài liệu bằng cách nối chúng để thu được dự đoán cấp tài liệu.

Hợp nhất Dự đoán cho các thực thể phân cấp. Đối với các thực thể phân cấp, chúng tôi sử dụng toàn bộ giá trị cây được dự đoán từ một hoàn thành LLM duy nhất, vì phương pháp này bảo tồn tốt nhất mối quan hệ cha-con được dự đoán bởi mô hình. Đối với mỗi loại thực thể phân cấp cấp cao nhất, chúng tôi thực hiện biểu quyết đa số trên tất cả các loại thực thể lá, trung gian và cấp cao nhất liên kết như thể chúng được làm phẳng. Sau đó chúng tôi tính toán đồng đều các phiếu bầu để xác định hoàn thành nào sẽ sử dụng cho dự đoán, và chọn phiếu phổ biến nhất cho thực thể phân cấp đó.

4 Đánh giá

Chúng tôi tìm cách đánh giá hiệu quả của LMDX trên các tiêu chuẩn IE công khai, và áp dụng nó cho hai LLM riêng biệt để xác nhận tính tổng quát của phương pháp: PaLM 2-S (Google et al., 2023) và Gemini Pro (Anil et al., 2023), mà chúng tôi gọi là LMDX PaLM 2-S và LMDX Gemini Pro tương ứng.

Trước tiên, bắt đầu từ checkpoint gốc của chúng, chúng tôi tinh chỉnh các LLM đó trên các lời nhắc và hoàn thành được mô tả chi tiết trong Phần 3.2 và 3.3 trên một hỗn hợp dữ liệu chứa nhiều bộ ba (tài liệu, lược đồ, trích xuất) đa dạng. Cụ thể, hỗn hợp dữ liệu này chứa tập dữ liệu Payment (Majumder et al., 2020), cùng với một tập hợp đa dạng các mẫu biểu mẫu PDF có sẵn công khai được lấy từ các trang web chính phủ mà chúng tôi đã điền với dữ liệu tổng hợp bằng một công cụ nội bộ, và được chú thích cho lược đồ và thực thể để trích xuất. Mục tiêu của việc điều chỉnh này là có được một checkpoint Base Entity Extractor bằng cách huấn luyện mô hình học tác vụ IE cùng với cú pháp trích xuất mong muốn của chúng tôi. Không có tài liệu hoặc lược đồ nào có trong giai đoạn huấn luyện trích xuất cơ sở trùng lặp với các tài liệu và lược đồ được sử dụng trong các tiêu chuẩn mục tiêu của chúng tôi, do đó chúng tôi sử dụng các LLM đó để đánh giá trích xuất thông tin zero-shot trên các tiêu chuẩn mục tiêu.

Hiệu suất Tinh chỉnh. Chúng tôi cũng quan tâm đến việc đánh giá mức độ hiệu quả dữ liệu của LMDX (ví dụ: nó học trích xuất thông tin trên một loại tài liệu mới nhanh như thế nào). Để trả lời điều này, bắt đầu từ checkpoint Base Entity Extractor, chúng tôi tinh chỉnh LLM trực tiếp trên tiêu chuẩn mục tiêu.

Tham số. Để huấn luyện, chúng tôi tinh chỉnh sử dụng kích thước lô 8, xác suất dropout 0.1 và tỷ lệ học 10^-6 với hàm mất entropy chéo tiêu chuẩn trong 4000 bước trên TPUv4 (Jouppi et al., 2023). Khi huấn luyện hoàn thành, đối với các thử nghiệm tinh chỉnh, chúng tôi chọn checkpoint có mất thấp nhất trên tập dev, và báo cáo hiệu suất trên tập test. Để suy luận LLM, chúng tôi sử dụng nhiệt độ 0.5 và Top K của 40, lấy mẫu 16 phản hồi cho mỗi khối được xử lý bởi LLM, như được mô tả trong Phần 3.4. Cuối cùng, đối với cả huấn luyện và suy luận, chúng tôi sử dụng độ dài token đầu vào 6144 và độ dài token đầu ra 2048. Chúng tôi sử dụng các phân đoạn cấp dòng và chỉ hai tọa độ [xcenter, ycenter] với 100 nhóm lượng tử hóa, như được hỗ trợ bởi Phụ lục A.12.

4.1 Tiêu chuẩn

Hiểu Tài liệu Giàu Thông tin Trực quan (VRDU). Wang et al. (2023d) giới thiệu hai tiêu chuẩn IE tài liệu giàu thông tin trực quan công khai: Registration Form, chứa 6 loại thực thể giàu ngữ nghĩa, và Ad-buy Form, chứa 14 loại thực thể với một loại thực thể phân cấp line_item. Đối với mỗi tiêu chuẩn, VRDU đề xuất các mẫu của 10, 50, 100 và 200 tài liệu huấn luyện với OCR chất lượng cao1 mà chúng tôi sử dụng để đánh giá hiệu quả dữ liệu của LMDX. Nó cũng cung cấp các tác vụ khác nhau để đánh giá khả năng tổng quát của hệ thống trích xuất: Học Mẫu Đơn (STL) trong đó tách train/test chia sẻ cùng một mẫu đơn, Học Mẫu Chưa thấy (UTL) trong đó train/test chứa các tập mẫu không giao nhau, và Học Mẫu Hỗn hợp (MTL) trong đó train/test chứa các tập mẫu chồng chéo. Chúng tôi báo cáo Micro-F1 thông qua công cụ đánh giá được cung cấp. Đối với VRDU, chúng tôi chỉ chạy các thử nghiệm tinh chỉnh sử dụng LMDX PaLM 2-S, do chi phí đáng kể của việc tinh chỉnh trên tất cả các tác vụ và kích thước tách huấn luyện của nó.

Tập dữ liệu Biên lai Tổng hợp (CORD).2 Park et al. (2019) giới thiệu một tiêu chuẩn biên lai Indonesia từ các cửa hàng và nhà hàng, với lược đồ mục tiêu gồm 30 thực thể tinh tế, được nhóm vào các thực thể phân cấp menu, total và subtotal. Chúng tôi áp dụng công cụ đánh giá từ nghiên cứu trước (Kim et al., 2022) và báo cáo Micro-F1 trên tiêu chuẩn đó. Đối với các thử nghiệm của chúng tôi, chúng tôi sử dụng các tách train chính thức (|D|= 800), dev và test. Để đánh giá hiệu quả dữ liệu của LMDX, chúng tôi tiếp tục lấy mẫu |D|= 10/50/100/200 tài liệu đầu tiên từ tách train. Đối với mỗi thiết lập dữ liệu đó, chúng tôi tinh chỉnh LMDX trong 12000 bước. Để so sánh, chúng tôi cũng huấn luyện và đánh giá các baseline tiên tiến LayoutLMv3 LARGE và Donut. Các baseline đó được mô tả chi tiết trong Phụ lục A.7.

Baseline Trong thiết lập zero-shot, chúng tôi so sánh LMDX với các baseline LLM khác: GPT-3.5, Gemini Pro (Anil et al., 2023), và PaLM 2-S (Google et al., 2023) mà chúng tôi nhắc với văn bản OCR thô và hướng dẫn IE (gọi là GPT-3.5 +OCR, Gemini Pro +OCR và PaLM 2-S +OCR tương ứng). Chúng tôi cũng so sánh LMDX với các mô hình Vision-Language mạnh: LLaVA-v1.5-13B (Liu et al., 2023), Gemini Pro, và GPT-4V (OpenAI, 2023a) mà chúng tôi nhắc với hình ảnh trang tài liệu và hướng dẫn IE (gọi là LLaVA-v1.5-13B +Image, GPT-4V+Image, và Gemini Pro +Image). Các baseline đó được mô tả đầy đủ trong Phụ lục A.6. Khác với LMDX, các baseline mô hình lớn đó không định vị dự đoán của chúng. Trong thiết lập tinh chỉnh, chúng tôi so sánh LMDX PaLM 2-S với các baseline VRD IE phổ biến. Đối với VRDU, chúng tôi so sánh với các baseline đã được công bố (Wang et al., 2023d), LayoutLM/v2/v3 và FormNet. Đối với CORD, chúng tôi huấn luyện và đánh giá các baseline tiên tiến LayoutLMv3 và Donut. Các baseline đó được mô tả chi tiết trong Phụ lục A.7. Theo nghiên cứu trước (Lee et al., 2022, 2023a; Xu et al., 2020, 2021), đối với tất cả các mô hình tận dụng phương thức văn bản, chúng tôi sử dụng OCR được cung cấp bởi tiêu chuẩn, đảm bảo so sánh công bằng.

4.2 Kết quả

Kết quả VRDU được trình bày trong Bảng 2. Trong thiết lập zero-shot (|D|= 0), LMDX PaLM 2-S và LMDX Gemini Pro có chất lượng trích xuất cao hơn tất cả các baseline mô hình lớn khác, bao gồm cả những mô hình sử dụng cùng LLM và OCR hoặc hình ảnh, cho thấy cải tiến được mang lại bởi chính phương pháp LMDX. Trong thiết lập tinh chỉnh trên VRDU, LMDX PaLM 2-S hiệu quả dữ liệu hơn nhiều so với các baseline: nó đạt 5.06% Micro-F1 của hiệu suất đỉnh tại 10 tài liệu huấn luyện cho Registration Form Mixed Template (87.72% so với 92.78% Micro-F1) trong khi LayoutLMv2, baseline tinh chỉnh mạnh nhất, nằm trong 19.75% hiệu suất đỉnh (69.44% so với 89.19% Micro-F1), cho thấy rằng nó học trích xuất trên một loại tài liệu mới nhanh hơn nhiều. Hơn nữa, LMDX PaLM 2-S tổng quát hóa tốt hơn cho các mẫu chưa thấy so với các baseline tinh chỉnh: trên Registration Form, LMDX PaLM 2-S có sự sụt giảm ít hơn 5% Micro-F1 trên Unseen Template so với Single Template trên các chế độ dữ liệu, trong khi LayoutLMv2 thấy sự sụt giảm từ 19% đến 27%.

Trên CORD (trong Bảng 3), chúng tôi quan sát các xu hướng tương tự, đạt hiệu suất tiên tiến trên tất cả trừ một chế độ dữ liệu, làm nổi bật tính tổng quát của kết quả.

Hiệu suất trên Thực thể Phân cấp. Để thể hiện chất lượng trích xuất trên các thực thể phân cấp, chúng tôi hiển thị trong Bảng 2 điểm F1 trên loại thực thể line_item của Ad-buy Form Mixed. Tổng thể, LMDX có Line Item F1 cao hơn nhiều so với các baseline cho tất cả các chế độ dữ liệu. Cụ thể, LMDX PaLM 2-S có Line Item F1 tương tự ở zero-shot so với baseline tinh chỉnh tốt nhất tại 200 tài liệu huấn luyện (21.21% so với 25.46% tương ứng). Với tất cả dữ liệu huấn luyện, LMDX PaLM 2-S đạt 72.09% Line Item F1, một cải thiện tuyệt đối 46.63% so với baseline tốt nhất LayoutLMv2. Cuối cùng, vì LMDX mã hóa phương thức bố cục, nó sở hữu Line Item F1 zero-shot cao hơn nhiều so với các baseline mô hình lớn.

Độ chính xác Định vị Thực thể. Để đánh giá chất lượng định vị độc lập với chất lượng trích xuất, chúng tôi tính toán Độ chính xác Định vị của LMDX và tất cả các baseline có thể định vị thực thể bằng công thức: Độ chính xác Định vị = NE+L/NE trong đó NE+L là số thực thể được trích xuất và định vị chính xác, và NE là số thực thể được trích xuất chính xác. Vì LMDX định vị ở cấp độ dòng, việc xác minh định vị cũng được thực hiện ở cấp độ dòng, tức là định vị được coi là chính xác nếu hộp giới hạn dự đoán được bao phủ bởi hộp giới hạn cấp dòng thực tế hơn 80%. Chúng tôi trình bày kết quả trong Bảng 4. Tổng thể, LMDX PaLM 2-S và LMDX Gemini Pro có thể định vị dự đoán của chúng một cách đáng tin cậy ở cấp độ dòng với các định danh phân đoạn, với độ chính xác 88%-94% ở zero-shot, và 98%-99% trong các trường hợp tinh chỉnh, cao hơn một chút so với các baseline.

4.3 Nghiên cứu Loại bỏ

Trong phần này, chúng tôi loại bỏ các khía cạnh khác nhau của phương pháp LMDX để làm nổi bật tầm quan trọng của chúng. Kết quả có thể được tìm thấy trong Bảng 5. Đối với tất cả các loại bỏ, chúng tôi đánh giá LMDX PaLM 2-S trên tác vụ VRDU Ad-Buy Form Mixed Template tại kích thước dữ liệu |D|= 10, chỉ thay đổi khía cạnh được loại bỏ.

Tác động của Huấn luyện Trích xuất Thực thể Cơ sở. Trong việc loại bỏ này, chúng tôi loại bỏ việc huấn luyện ban đầu trên hỗn hợp dữ liệu đa dạng và tinh chỉnh trực tiếp trên tác vụ VRDU mục tiêu. Như được thấy trong Bảng 5, việc bỏ qua huấn luyện đó dẫn đến -11.44% micro-F1 vì mô hình phải học từ đầu tác vụ, định dạng hoàn thành mong muốn và ngữ nghĩa của các token tọa độ.

Tác động của Token Tọa độ. Trong việc loại bỏ này, chúng tôi thay thế các token tọa độ, truyền đạt vị trí của mỗi dòng trong tài liệu, bằng chỉ số của dòng đó. Chỉ số này vẫn hoạt động như một định danh duy nhất cho phân đoạn dòng (cần thiết cho định vị thực thể) nhưng không truyền đạt bất kỳ thông tin vị trí nào. Ví dụ về một lời nhắc với chỉ số dòng có thể được tìm thấy trong Phụ lục A.8 Hình 11, và F1 theo thực thể có thể được tìm thấy trong Phụ lục A.14 Bảng 9. Như được thấy trong Bảng 5, các token tọa độ rất quan trọng đối với chất lượng, dẫn đến +14.98% micro-F1.

Tác động của Chiến lược Lấy mẫu. Trong việc loại bỏ này, chúng tôi loại bỏ chiến lược lấy mẫu K= 16 hoàn thành cho mỗi khối, và thay vào đó lấy mẫu một phản hồi duy nhất. Như được thấy trong Bảng 5, điều này dẫn đến sự sụt giảm 1.5% micro-F1. Mặc dù nhỏ tổng thể về chất lượng, chiến lược lấy mẫu sửa chữa các lỗi định dạng trích xuất (xem tỷ lệ lỗi phân tích trong Phụ lục A.10), dẫn đến việc trích xuất thành công trên tất cả tài liệu.

Tác động của Loại Thực thể Thiếu. Trong việc loại bỏ này, chúng tôi nghiên cứu tác động của việc cho phép các hoàn thành của mô hình bỏ qua các loại thực thể thiếu trong các hoàn thành thay vì xuất một cách rõ ràng "type":null cho những loại đó (Xem ví dụ trong Phụ lục A.8, Hình 12). Như được thấy trong Bảng 5, điều này dẫn đến sự sụt giảm 6.77% micro-F1 so với việc xuất một cách rõ ràng các loại thiếu. Chúng tôi giả thuyết rằng điều này là do việc cho phép các hoàn thành bỏ qua các loại thiếu có nghĩa là, trong quá trình tạo phản hồi, mô hình phải chọn với một ngân sách tính toán token duy nhất trong N loại thực thể còn lại loại nào là loại có mặt tiếp theo (về cơ bản là một phân loại N-way). Việc xuất một cách rõ ràng các loại thực thể thiếu có nghĩa là mô hình chỉ cần sao chép các loại trực tiếp từ lược đồ trong lời nhắc, và phải thực hiện phân loại 2-way trong một ngân sách tính toán token duy nhất để tuyên bố nếu một thực thể có mặt hay không (ví dụ: phát token null nếu thực thể thiếu hoặc " nếu có mặt), đây là một tác vụ dễ dàng hơn.

Bảng 5: Loại bỏ các thiết kế cốt lõi của LMDX. Các loại bỏ được thực hiện trên VRDU Ad-Buy Mixed Template với LMDX PaLM 2-S tại kích thước dữ liệu |D|= 10. Micro-F1 được báo cáo. Tổng thể, tất cả các thành phần đều đóng góp vào hiệu suất cuối cùng.

LMDX | Không có | Không có | Không có | Không có
Micro-F1 | Huấn luyện EE | Token Tọa độ | Chiến lược Mẫu | Loại Thiếu
(∆) | | | |
54.35 | 42.91 | 39.37 | 52.85 | 47.58
 | (-11.44) | (-14.98) | (-1.50) | (-6.77)

4.4 Hiệu suất Học trong Ngữ cảnh

Trong phần này, chúng tôi nghiên cứu cách học trong ngữ cảnh (ICL) so sánh với tinh chỉnh. Để làm điều này, chúng tôi thử nghiệm hai phương pháp: Random, lựa chọn ngẫu nhiên |D| tài liệu và trích xuất từ tập huấn luyện, và Nearest Neighbors, sử dụng sự tương đồng dựa trên embedding SentenceT5 (Ni et al., 2021) để truy xuất |D| tài liệu để thêm vào ngữ cảnh LLM. Kết quả trên CORD cho LMDX PaLM 2-S và LMDX Gemini Pro được thể hiện trong Hình 3. Tổng thể, mặc dù cả hai phương pháp đều tăng hiệu suất đáng kể, nearest neighbors cho thấy một lợi thế rõ ràng, khớp hiệu suất ICL ngẫu nhiên tốt nhất chỉ với một ví dụ trong ngữ cảnh duy nhất (86.43% so với 86.57% micro-F1 cho LMDX PaLM 2-S), và khớp hiệu suất tinh chỉnh tại |D|= 10 ví dụ (90.33% so với 90.02% micro-F1), vì các ví dụ từ cùng một mẫu được truy xuất (xem Phụ lục A.9). Vượt quá |D|= 10, chất lượng ổn định vì không có thêm ví dụ nào vừa trong lời nhắc.

5 Kết luận

Trong bài báo này, chúng tôi đã giới thiệu LMDX, một phương pháp cho phép sử dụng LLM để trích xuất thông tin trên các tài liệu giàu thông tin trực quan. Với các token tọa độ và chiến lược giải mã, LMDX cho phép trích xuất chất lượng cao các thực thể đơn lẻ, lặp lại và phân cấp, đồng thời định vị các thực thể trong tài liệu. LMDX có hiệu quả dữ liệu, và thậm chí cho phép trích xuất zero-shot trên các loại tài liệu và lược đồ hoàn toàn mới. LMDX có thể được hưởng lợi từ các lĩnh vực nghiên cứu trực giao, và chúng tôi tiếp tục thảo luận trong phần Hạn chế.

Lời cảm ơn

Các tác giả muốn cảm ơn Tania Bedrax-Weiss, Riham Mansour, Slav Petrov, Yunhsuan Sung, Mike Kwong và Chun-Liang Li vì phản hồi có giá trị của họ về các thử nghiệm và bài báo. Các tác giả cũng cảm ơn Nikolai Glushnev vì các cuộc thảo luận, cùng với sự giúp đỡ đặt tên LMDX.

Hạn chế

Chúng tôi thừa nhận các hạn chế của LMDX từ các khía cạnh sau để khuyến khích nghiên cứu trong tương lai trong lĩnh vực trích xuất thông tin và định vị.

Thứ nhất, đầu vào của LMDX là các dòng văn bản và hộp giới hạn của chúng, thường đến từ OCR. Điều này có nghĩa là LMDX không thể trích xuất các thực thể không phải văn bản do đó sẽ không thể trích xuất một thực thể là hình ảnh được nhúng trong tài liệu (ví dụ: một thực thể product_image trong trang web sản phẩm). Điều này cũng hạn chế hiệu suất trong các tình huống dữ liệu cao, vì tất cả thông tin hình ảnh trang đều bị loại bỏ. Hơn nữa, đầu vào như vậy có nghĩa là LMDX nhạy cảm với các lỗi từ quá trình OCR (thứ tự đọc sai, nhóm dòng không chính xác, văn bản không được phát hiện và các ký tự được nhận dạng sai). Về mặt định tính, chúng tôi đã tìm thấy rằng một loại lỗi phổ biến cho LMDX là do OCR nhóm nhiều phân đoạn khác nhau về mặt ngữ nghĩa lại với nhau (chúng tôi đưa ra phân tích sâu hơn với các ví dụ cụ thể trong Phụ lục A.11). Do đó, các kỹ thuật nhằm cải thiện loại lỗi này sẽ là một hướng nghiên cứu tương lai đáng giá.

Hơn nữa, cơ chế định vị của LMDX được áp dụng ở cấp độ dòng, trong đó chúng tôi xác minh rằng văn bản được dự đoán thực sự có mặt trên dòng. Nếu văn bản thực thể xuất hiện nhiều lần trên dòng, chúng tôi không có cách xác định để chọn văn bản chính xác. Do đó, định vị và hộp giới hạn của LMDX không đáng tin cậy vượt quá độ chi tiết cấp dòng. Mặc dù đủ để tăng tốc đáng kể các tương tác con người-trong-vòng-lặp như kiểm tra/xem xét dự đoán, việc có được các hộp giới hạn thực thể chính xác ở cấp độ ký tự sẽ có lợi, trông tự nhiên hơn, và là một hướng nghiên cứu đáng giá.

Cuối cùng, LMDX dựa vào các LLM hỗ trợ hàng nghìn token trong đầu vào và đầu ra (như được mô tả chi tiết trong Phụ lục A.4), điều này vừa tốn kém về mặt tính toán vừa chậm, đòi hỏi việc sử dụng tăng tốc phần cứng để có độ trễ và thông lượng có thể chấp nhận được. Chúng tôi thể hiện so sánh độ trễ giữa các giải pháp phổ biến trong Phụ lục A.13. Nghiên cứu chung về tăng tốc suy luận LLM (Shazeer, 2019; Ainslie et al., 2023; Leviathan et al., 2023; Hong et al., 2023) sẽ làm cho LMDX hiệu quả hơn về chi phí trong môi trường sản xuất. Cụ thể cho LMDX, các token tọa độ đại diện cho một phần lớn tổng số token, vì vậy nghiên cứu về việc giảm thiểu số lượng của chúng (ví dụ: bằng cách giới thiệu các token tọa độ chuyên dụng trong từ vựng LLM) sẽ mang lại tiết kiệm đáng kể và là một hướng đáng giá cho nghiên cứu tương lai.

[Tiếp tục với phần còn lại của tài liệu...]

# AGIBench: Một Chuẩn Mực Đo Lường Đa Cấp Độ, Đa Phương Thức, Có Tham Chiếu Con Người, Tự Động Chấm Điểm cho Các Mô Hình Ngôn Ngữ Lớn

Fei Tang1,3, Wanling Gao1,2,3, Luzhou Peng4, và Jianfeng Zhan *1,2,3

1Trung tâm Nghiên cứu Hệ thống Máy tính Tiên tiến, Phòng thí nghiệm Trọng điểm Nhà nước về Bộ xử lý, Viện Công nghệ Tính toán, Viện Hàn lâm Khoa học Trung Quốc, {tangfei, gaowanling, zhanjianfeng}@ict.ac.cn

2BenchCouncil (Hội đồng Chuẩn mực Mở Quốc tế)

3Đại học Viện Hàn lâm Khoa học Trung Quốc

4Đại học Kế toán và Tài chính Lixin Thượng Hải

22 tháng 8, 2023

## Tóm tắt

Các mô hình ngôn ngữ lớn (LLM) như ChatGPT đã bộc lộ trí thông minh tuyệt vời. Việc đánh giá khả năng giải quyết vấn đề của LLM và mức độ thông minh của chúng là một vấn đề nóng bỏng nhưng đầy thách thức. Thứ nhất, khả năng giải quyết vấn đề được đan xen với các nhánh khả năng khác nhau như hiểu biết và các danh mục kiến thức rộng lớn như toán học. Thứ hai, đầu vào của các câu hỏi là đa phương thức có thể bao gồm văn bản và hình ảnh. Ngoài ra, chúng có thể có các mức độ khó khác nhau trong khi thiếu tiêu chuẩn thống nhất để đánh giá câu hỏi nào khó hơn. Thứ ba, định dạng phản hồi của LLM đa dạng và do đó đặt ra những thách thức lớn cho việc trích xuất và đánh giá kết quả. Mặc dù đã có một số chuẩn mực được đề xuất để đánh giá LLM, tuy nhiên, phần lớn chúng chỉ đánh giá và báo cáo hiệu suất trên một tập hợp các câu hỏi văn bản pha trộn có thể liên quan đến nhiều nhánh khả năng, danh mục kiến thức hoặc các mức độ khó khác nhau. Do đó, việc đánh giá có thể dẫn đến dữ liệu hiệu suất không thể phân biệt được và hướng tối ưu hóa thiên lệch. Một phần nhỏ các nỗ lực cố gắng phân loại các câu hỏi theo các nhánh khả năng, tuy nhiên, chúng vẫn cung cấp chuẩn mực thô như thiếu các danh mục kiến thức chi tiết và mức độ khó có tham chiếu con người. Ngoài ra, các nỗ lực hiện tại hoặc là áp dụng kỹ thuật prompt để chuẩn hóa định dạng phản hồi hoặc phân tích kết quả thủ công, điều này sẽ gây ra những tác động hiệu suất không thể dự đoán được hoặc chi phí đánh giá không thể chấp nhận được.

Trong bài báo này, để giải quyết các thách thức trên, chúng tôi đề xuất AGIBench – một phương pháp luận chuẩn mực đa cấp độ, đa phương thức, có tham chiếu con người và tự động chấm điểm cho LLM. Thay vì một tập hợp các câu hỏi pha trộn, AGIBench tập trung vào ba nhánh khả năng điển hình và áp dụng bộ bốn <nhánh khả năng, kiến thức, độ khó, phương thức> để gắn nhãn các thuộc tính của mỗi câu hỏi. Thứ nhất, nó hỗ trợ chuẩn mực đa cấp độ, ví dụ: từng câu hỏi, từng nhánh khả năng, từng kiến thức, từng phương thức, từng tập dữ liệu và các cấp độ chi tiết từng mức độ khó. Thứ hai, nó chứa đầu vào đa phương thức, bao gồm văn bản và hình ảnh. Thứ ba, nó phân loại tất cả các câu hỏi thành năm mức độ khó dựa trên tỷ lệ chính xác trung bình của nhiều con người có học thức (có tham chiếu con người). Thứ tư, nó áp dụng học không-shot để tránh gây ra thêm sự không thể dự đoán được và cung cấp phương pháp tự động chấm điểm để trích xuất và đánh giá kết quả. Cuối cùng, nó định nghĩa các chỉ số đa chiều, bao gồm độ chính xác trong các trường hợp trung bình, tồi tệ nhất, tốt nhất và bỏ phiếu đa số, và khả năng lặp lại. Các thí nghiệm của chúng tôi trên mười hai LLM tiên tiến nhất cho thấy hiệu quả của chuẩn mực của chúng tôi. AGIBench được cung cấp công khai từ https://www.benchcouncil.org/agibench.

*Jianfeng Zhan là tác giả liên hệ.

## 1 Giới thiệu

Trí thông minh là một khái niệm trừu tượng và vẫn chưa có định nghĩa thống nhất [8]. Nghiên cứu về trí thông minh con người đã được tiến hành trong nhiều thập kỷ và hình thành một loạt các lý thuyết, ví dụ: lý thuyết trí thông minh ba yếu tố [13], trí thông minh lưu loát và kết tinh [2], lý thuyết đa trí thông minh [5], v.v., trong khi không có tiêu chuẩn thống nhất về cách đánh giá trí thông minh con người. Trong điều kiện này, những khó khăn gia tăng khi đánh giá trí tuệ nhân tạo (AI), vốn đã thể hiện khả năng mạnh mẽ trong việc giải quyết vấn đề hoặc câu hỏi và phản ánh tiềm năng to lớn để tiếp cận trí thông minh con người, đặc biệt là các mô hình ngôn ngữ lớn mới nổi (LLM) như ChatGPT. Khác với các ứng dụng AI trước đây chủ yếu nhắm vào một nhiệm vụ duy nhất hoặc một lĩnh vực cụ thể, LLM dự kiến sẽ đạt được trí thông minh tổng quát. Do đó, các phương pháp luận chuẩn mực trước đây tập trung vào các nhiệm vụ cụ thể hoặc các lĩnh vực ứng dụng không còn áp dụng được nữa. Một phương pháp luận chuẩn mực mới là cần thiết nhưng không phải là điều dễ dàng.

Một mặt, việc xây dựng một chuẩn mực với các câu hỏi đầu vào đa dạng, điển hình và có sự phân biệt độ khó là thách thức. Tương tự như trí thông minh con người, trí thông minh của LLM không có tiêu chuẩn chuẩn mực thống nhất vì các câu hỏi hoặc vấn đề đầu vào cần giải quyết là rất lớn và đan xen. Thứ nhất, các câu hỏi hoặc vấn đề đầu vào có thể không chỉ liên quan đến nhiều nhánh khả năng như hiểu biết và lý luận mà còn liên quan đến nhiều danh mục kiến thức với các mức độ khó khác nhau như toán học và địa lý. Thứ hai, các câu hỏi hoặc vấn đề đầu vào là đa phương thức với sự kết hợp của văn bản và hình ảnh, ví dụ: các bài toán hình học trong toán học, nói về hình ảnh trong ngôn ngữ học, v.v.

Mặt khác, việc đánh giá kết quả chuẩn mực và chọn lựa các chỉ số toàn diện và quan trọng là thách thức. Từ góc độ phân tích kết quả, định dạng phản hồi của LLM rất đa dạng. Ví dụ, phản hồi có thể (1) trả lời lựa chọn từ bốn lựa chọn được đánh dấu A, B, C và D, với lời giải thích và phân tích về bốn lựa chọn trên từng cái một; (2) chỉ trả lời lựa chọn mà không có lời giải thích; (3) trả lời lựa chọn với lời giải thích một phần. Ngoài ra, thứ tự của các lựa chọn và lời giải thích thay đổi, và các từ văn bản khác nhau. Mặc dù con người có thể phân biệt kết quả một cách dễ dàng, tuy nhiên, điều này cực kỳ khó khăn đối với một chương trình máy tính. Từ góc độ của các chỉ số đánh giá, hiệu suất của LLM là đa chiều và không chỉ là độ chính xác trung bình. Ví dụ, LLM có thể thành thạo trong các nhánh khả năng cụ thể, danh mục kiến thức hoặc mức độ khó; kết quả phản hồi có thể thay đổi trong nhiều lần chạy, v.v.

Nhiều nỗ lực đã được đề xuất để chuẩn mực LLM [12,9,19,20,7,18]; tuy nhiên, chúng không giải quyết được các thách thức trên. Thứ nhất, hầu như tất cả đều áp dụng một hoặc nhiều tập dữ liệu mã nguồn mở với một tập hợp các câu hỏi văn bản pha trộn ở mức độ chi tiết từng tập dữ liệu hoặc từng nhánh khả năng. Tuy nhiên, những câu hỏi pha trộn này có thể bao gồm các danh mục kiến thức khác nhau và các mức độ khó khác nhau. Chúng ta khó có thể phân biệt hiệu suất trên từng nhánh khả năng, kiến thức hoặc mức độ khó, ngoại trừ điểm số tổng trên một tập dữ liệu. Hơn nữa, thậm chí một số trong những chuẩn mực đó [20] cung cấp các mức độ khó khác nhau; tuy nhiên, những mức độ khó này được áp dụng ở mức độ chi tiết từng tập dữ liệu, có nghĩa là độ khó tổng thể của toàn bộ tập dữ liệu câu hỏi chứ không phải một câu hỏi cụ thể. Thứ hai, để giải quyết các thách thức của việc phân tích kết quả phản hồi, hầu hết chúng [9,20,7] áp dụng kỹ thuật prompt như few-shot và chain-of-thought (CoT) để tăng độ chính xác hoặc chuẩn hóa định dạng phản hồi. Tuy nhiên, các thí nghiệm của chúng tôi và các công trình liên quan cho thấy rằng dù là few-shot hay CoT đều sẽ gây ra những tác động hiệu suất không thể dự đoán được. Các thí nghiệm của chúng tôi đặc biệt cho thấy rằng với few-shot, phương sai độ chính xác đạt tới 5% khi sử dụng các hạt giống ngẫu nhiên khác nhau. C-Eval [7] cho thấy rằng với CoT, độ chính xác tăng trên một số mô hình (ví dụ: ChatGLM-6B, +3%) trong khi giảm trên các mô hình khác (ví dụ: Chinese-LLaMA-13B, -11.9%). Một số nỗ lực [18] áp dụng phương pháp zero-shot để tránh tác động không thể dự đoán được, tuy nhiên, chúng phải phân tích kết quả phản hồi thủ công, dẫn đến chi phí đánh giá không thể chấp nhận được. Thứ ba, hầu hết những nỗ lực đó chỉ báo cáo độ chính xác trung bình và thiếu đánh giá toàn diện và đa chiều. Trong khi HELM [9] kết hợp nhiều chỉ số, nó bỏ qua đánh giá có tham chiếu con người và không bao gồm tập dữ liệu đa phương thức.

Bài báo này đề xuất AGIBench – một phương pháp luận và chuẩn mực chuẩn mực đa cấp độ, đa phương thức, có tham chiếu con người và tự động chấm điểm cho LLM. Thay vì một tập hợp các câu hỏi pha trộn, AGIBench tập trung vào các nhánh khả năng cơ bản và áp dụng bộ bốn <nhánh khả năng, kiến thức, độ khó, phương thức> để gắn nhãn các thuộc tính của mỗi câu hỏi. Tổng cộng, AGIBench cung cấp 927 câu hỏi, bao gồm ba loại nhánh khả năng, tức là: kiến thức thường thức, lý luận và hiểu biết, 20 danh mục kiến thức và 68 lớp con kiến thức. Thứ nhất, nó hỗ trợ chuẩn mực đa cấp độ, ví dụ: từng câu hỏi, từng nhánh khả năng, từng kiến thức, từng mức độ khó, từng tập dữ liệu và các cấp độ chi tiết từng phương thức. Thứ hai, nó chứa đầu vào đa phương thức, bao gồm các ngữ cảnh khác nhau như chỉ văn bản, chỉ hình ảnh, văn bản với hình ảnh, văn bản với bảng và sự kết hợp của văn bản, hình ảnh và bảng. Thứ ba, nó phân loại tất cả các câu hỏi thành năm mức độ khó dựa trên tỷ lệ chính xác trung bình của nhiều con người có học thức (có tham chiếu con người). Thứ tư, nó áp dụng học zero-shot để tránh thêm sự không thể dự đoán được và cung cấp phương pháp tự động chấm điểm để trích xuất và đánh giá kết quả. Cuối cùng, nó định nghĩa các chỉ số đa chiều, bao gồm độ chính xác trong các trường hợp trung bình, tồi tệ nhất, tốt nhất và bỏ phiếu đa số, và khả năng lặp lại. Các thí nghiệm của chúng tôi trên mười hai LLM tiên tiến nhất cho thấy hiệu quả của chuẩn mực của chúng tôi. Bảng 1 trình bày các quan sát và hàm ý chính của LLM sử dụng AGIBench.

## 2 Công trình liên quan

Nhiều nỗ lực đã được đề xuất để đánh giá các thuật toán xử lý ngôn ngữ tự nhiên (NLP) truyền thống và LLM. GLUE [15] và SuperGLUE [14] là các chuẩn mực cho các nhiệm vụ NLP truyền thống, chủ yếu đánh giá khả năng hiểu biết. Tuy nhiên, các câu hỏi có phạm vi hạn chế và chủ yếu tập trung vào phân loại câu, không thể phản ánh toàn diện sự phức tạp của ngôn ngữ con người [11]. Do đó, những chuẩn mực này không thể đáp ứng nhu cầu đánh giá LLM.

Để đánh giá LLM, từ góc độ của tập dữ liệu câu hỏi, hầu hết các công trình liên quan sử dụng các câu hỏi trắc nghiệm vì câu trả lời là xác định mà không có tính chủ quan. BIG-Bench [12] và HELM [9] sử dụng sự kết hợp của nhiều tập dữ liệu như MATH [6] và GSM8K [3]. Một mặt, cách tiếp cận như vậy có thể gây ra sự dư thừa câu hỏi và dẫn đến phạm vi bao phủ hạn chế. Mặt khác, chúng chỉ hỗ trợ chuẩn mực ở mức độ chi tiết từng tập dữ liệu hoặc từng nhánh khả năng và do đó không thể tiết lộ khả năng từ các góc độ khác nhau. Ví dụ, chúng chỉ xuất ra một điểm số trên một tập dữ liệu cụ thể với các câu hỏi pha trộn liên quan đến các mức độ khó khác nhau. Do đó, chúng ta khó có thể biết khả năng cho một danh mục kiến thức cụ thể hoặc một mức độ khó cụ thể. ScienceQA [11] thu thập các câu hỏi từ chương trình khoa học tiểu học và trung học. Tuy nhiên, những câu hỏi này quá dễ đối với con người. AGI-Eval [20], C-Eval [7] và GAOKAO [18] tập trung vào chuẩn mực LLM sử dụng tiếng Trung. Chúng sử dụng các kỳ thi như công chức quốc gia và thi đại học làm tập dữ liệu câu hỏi. Tuy nhiên, những chuẩn mực này chỉ sử dụng độ chính xác trung bình làm chỉ số đánh giá, điều này quá đơn giản. Một số nỗ lực cố gắng sử dụng các câu hỏi mở cho chuẩn mực LLM. Chandrasekaran et al. [1] thu thập một loạt các câu hỏi mở và đa phương thức để đánh giá GPT-4; tuy nhiên, việc đánh giá và chấm điểm kết quả là cực kỳ khó khăn. Ngoài ra, kết quả đánh giá khó tái tạo, xem xét tính chủ quan của những người khác nhau.

Từ góc độ của phương pháp đánh giá và chấm điểm, đa số các nỗ lực hiện tại áp dụng kỹ thuật prompt để đánh giá, chẳng hạn như học few-shot [16] và Chain-of-Thought (CoT) [17]. Mặc dù những phương pháp này đã được chứng minh có tiềm năng chuẩn hóa định dạng của kết quả phản hồi hoặc tăng độ chính xác của mô hình, tuy nhiên, C-Eval [7] và các thí nghiệm của chúng tôi cho thấy rằng chúng có thể không phải lúc nào cũng hiệu quả và sẽ gây ra những tác động hiệu suất không thể dự đoán được. Trong điều kiện này, chúng ta không thể đánh giá chính xác khả năng của LLM vì kết quả phản hồi có thể bị tác động bởi kỹ thuật prompt. Ngoài ra, việc sử dụng những phương pháp này đòi hỏi điều chỉnh từng trường hợp, điều này làm tăng chi phí chuẩn mực và không thể đảm bảo tính công bằng của chuẩn mực. MT-Bench [19] khám phá việc sử dụng GPT-4 như một phương pháp để đánh giá tính đúng đắn của kết quả phản hồi của LLM và so sánh nó với đánh giá của con người. Họ thấy rằng các quyết định từ GPT-4 và con người có độ tương đồng 80%. Tuy nhiên, MT-Bench chỉ chọn 80 câu hỏi và do đó có tính đại diện hạn chế. Ngoài ra, việc sử dụng GPT-4 trực tiếp để chấm điểm sẽ gây ra chi phí lao động rất lớn vì chúng ta vẫn cần kiểm tra đánh giá cho từng câu hỏi.

## 3 Thiết kế và Triển khai

Phần này minh họa thiết kế và triển khai của AGIBench. Phần 3.1 mô tả phương pháp luận chuẩn mực. Phần 3.2 trình bày tổng quan về AGIBench.

### 3.1 Phương pháp luận

Để đánh giá các khả năng giải quyết vấn đề khác nhau của LLM và mức độ thông minh của chúng, chúng tôi áp dụng một phương pháp luận chuẩn mực đa cấp độ, đa phương thức, có tham chiếu con người và tự động chấm điểm, bao gồm xây dựng tập dữ liệu câu hỏi, phương pháp đánh giá và các chỉ số đánh giá.

Thứ nhất, để hỗ trợ chuẩn mực đa cấp độ thay vì chỉ chuẩn mực từng tập dữ liệu hoặc từng nhánh khả năng được áp dụng trong các công trình liên quan, chúng tôi sử dụng bộ bốn <nhánh khả năng, kiến thức, độ khó, phương thức> để gắn nhãn các thuộc tính của mỗi câu hỏi. Nhánh khả năng tập trung vào các khả năng cơ bản và thiết yếu nhất như hiểu biết. Kiến thức bao gồm một phổ rộng các danh mục kiến thức trong mỗi nhánh khả năng, ví dụ: đọc hiểu đoạn văn trong khả năng hiểu biết. Độ khó chỉ ra mức độ khó của câu hỏi, tức là Cấp 1 đến 5, từ dễ đến khó. Phương thức chỉ ra phương thức của câu hỏi như văn bản hoặc hình ảnh.

Thứ hai, để xây dựng một tập dữ liệu câu hỏi đại diện và điển hình, chúng tôi nhằm bao gồm nhiều câu hỏi với các thuộc tính đa dạng và khác nhau. Cụ thể, chúng tôi chọn ba nhánh khả năng cơ bản nhất: kiến thức thường thức, hiểu biết và lý luận. Chúng tôi chọn ra hai mươi danh mục kiến thức toàn diện và đại diện cho ba nhánh khả năng này tổng cộng. Kiến thức cho kiến thức thường thức bao gồm sáu danh mục: nhân văn, công nghệ, luật pháp, địa lý, chính trị và kinh tế; Kiến thức cho hiểu biết bao gồm đọc hiểu đoạn văn, ngữ pháp câu, điền chỗ trống và đọc văn bản dài; Kiến thức cho lý luận bao gồm lý luận đồ họa, đánh giá định nghĩa, tài liệu toàn diện, tài liệu dạng bảng, tài liệu văn bản, tài liệu đồ họa, lý luận tương tự, đánh giá logic, tính toán toán học và lý luận số. Đối với thuộc tính độ khó của mỗi câu hỏi, chúng tôi áp dụng một phương pháp có tham chiếu con người dựa trên thống kê dữ liệu lớn, sử dụng tỷ lệ chính xác được trả lời bởi hàng triệu con người có học thức để gắn nhãn mức độ khó của câu hỏi. Ví dụ, Cấp 1 là dễ nhất với tỷ lệ chính xác 80% đến 100%, có nghĩa là 80% đến 100% trong số hàng triệu con người có thể đưa ra câu trả lời đúng. Cấp 2 có tỷ lệ chính xác 60% đến 80%. Cấp 3 có tỷ lệ chính xác 40% đến 60%. Cấp 4 có tỷ lệ chính xác 20% đến 40%. Cấp 5 là khó nhất và có tỷ lệ chính xác 0% đến 20%. Chúng tôi bao gồm đầu vào đa phương thức bao gồm các ngữ cảnh khác nhau, bao gồm chỉ văn bản, văn bản với bảng, văn bản với hình ảnh, chỉ hình ảnh và sự kết hợp của văn bản, hình ảnh và bảng.

Thứ ba, để đối phó với tính đa dạng của định dạng phản hồi và tránh những tác động hiệu suất không thể dự đoán được của kỹ thuật prompt, chúng tôi không sử dụng kỹ thuật prompt và cố gắng tìm một loạt các mẫu regex để trích xuất các câu trả lời và thực hiện đánh giá.

Thứ tư, chúng tôi định nghĩa các chỉ số đa chiều cho chuẩn mực LLM: độ chính xác trong các trường hợp khác nhau và khả năng lặp lại.

### 3.2 Thiết kế và Triển khai AGIBench

Chúng tôi thiết kế và triển khai AGIBench dựa trên phương pháp luận, bao gồm xây dựng tập dữ liệu câu hỏi, đánh giá và chấm điểm, và các chỉ số.

**Tập dữ liệu câu hỏi.** AGIBench chọn các câu hỏi liên quan đến cuộc sống con người, đặc biệt là đối với người Trung Quốc. Chúng tôi chủ yếu chọn các câu hỏi từ các kỳ thi công chức quốc gia vì chúng thỏa mãn các yêu cầu về tính đa dạng và cơ bản. Chúng tôi sử dụng bộ bốn <nhánh khả năng, kiến thức, độ khó, phương thức> để gắn nhãn các thuộc tính của mỗi câu hỏi. Nhánh khả năng bao gồm khả năng kiến thức thường thức, hiểu biết và lý luận. Kiến thức chứa 20 danh mục và 68 lớp con bao gồm nhân văn, vật lý, hóa học, kinh tế, luật pháp, chính trị, văn hóa, địa lý, lịch sử, kỹ thuật, toán học, v.v. Bảng 2 cho thấy các thuộc tính nhánh khả năng và kiến thức của tập dữ liệu AGIBench. Về độ khó, tập dữ liệu của chúng tôi sử dụng độ chính xác của con người làm tham chiếu, và độ chính xác dựa trên con người có học thức cao. Chúng tôi cẩn thận chọn lựa độ khó của các câu hỏi và phân loại năm cấp từ Cấp 1 đến Cấp 5. Số cao hơn có nghĩa là mức độ thách thức cao hơn. Từ Cấp 1 đến Cấp 5, độ chính xác phản hồi của con người là [80%, 100%], [60%, 80%), [40%, 60%), [20%, 40%) và [0%, 20%). Hình 1 cho thấy phân bố các mức độ khó của AGIBench. Về phương thức, chúng tôi bao gồm đầu vào đa phương thức bao gồm các ngữ cảnh khác nhau, tức là chỉ văn bản, chỉ hình ảnh, văn bản với hình ảnh, văn bản với bảng và sự kết hợp của văn bản, hình ảnh và bảng. Số lượng câu hỏi tương ứng cho các ngữ cảnh này là 863, 5, 38, 10 và 11. Tổng cộng, chúng tôi cung cấp 927 câu hỏi. Lưu ý rằng hình ảnh được xử lý như một URL trong các câu hỏi. Ngoài ra, tập dữ liệu văn bản chứa văn bản thuần túy, công thức toán học phức tạp và dữ liệu bảng. Chúng tôi áp dụng định dạng latex cho các công thức toán học và đối với dữ liệu bảng, chúng tôi sử dụng định dạng markdown.

Chúng tôi xem xét thêm độ dài của các câu hỏi. Hình 2 cho thấy phân bố độ dài của các câu hỏi, và tập dữ liệu của chúng tôi bao gồm một phổ rộng. Kích thước của hầu hết các câu hỏi lớn hơn 100 trong khi nhiều câu khác ít hơn mười từ [10]. Và tập dữ liệu của chúng tôi chứa một số câu hỏi có độ dài dài có độ dài vượt quá 1000, điều này cũng cho thấy độ khó và tính đa dạng của tập dữ liệu của chúng tôi.

**Đánh giá và Chấm điểm.** Để tránh tác động của kỹ thuật prompt và đồng thời giảm thiểu chi phí lao động, chúng tôi áp dụng một phương pháp tự động chấm điểm kết hợp thuật toán tìm kiếm biểu thức chính quy heuristic (viết tắt là HRE) và GPT-4. Một mặt, chúng tôi sử dụng thuật toán HRE để tìm kiếm các mẫu regex, như được thể hiện trong Thuật toán 1. Chúng tôi lặp lại N lần lặp và chọn ngẫu nhiên M phản hồi từ tổng số phản hồi trong mỗi lần lặp. Đối với M phản hồi của mỗi lần lặp, chúng tôi đặt một ngưỡng "minimum_limit", chỉ ra số lần xuất hiện tối thiểu mà một định dạng phản hồi có thể được thêm vào như một mẫu regex mới. Sau đó, chúng tôi có được một tập hợp chứa các mẫu regex xuất hiện thường xuyên. Thống kê đánh giá của chúng tôi trong Phần 4.2 xác minh hiệu quả của thuật toán HRE. Trong số hàng trăm nghìn phản hồi từ LLM, khoảng 67% kết quả phản hồi có thể được trích xuất đầy đủ bằng HRE. Mặt khác, về phần nhỏ còn lại không thể được trích xuất bởi HRE, chúng tôi sử dụng GPT-4 để trích xuất kết quả. Lưu ý rằng chúng tôi không sử dụng GPT-4 trực tiếp vì độ chính xác của nó không thể đạt 100%, và chúng tôi vẫn cần xác minh các đánh giá một cách nhân tạo. Bằng cách áp dụng HRE, chúng tôi giảm khoảng bảy mươi phần trăm chi phí lao động.

**Chỉ số.** Chúng tôi thu thập nhiều chỉ số để đánh giá LLM một cách toàn diện, không chỉ là độ chính xác trung bình, đây là chỉ số duy nhất cho hầu hết các công trình liên quan. Chúng tôi bao gồm rộng rãi độ chính xác trung bình, độ chính xác trường hợp tồi tệ nhất, độ chính xác trường hợp tốt nhất, độ chính xác bỏ phiếu đa số và khả năng lặp lại để chỉ ra hiệu suất của LLM trong các trường hợp khác nhau. Chúng tôi chi tiết những chỉ số này như sau. Lưu ý rằng chúng tôi đánh giá mỗi LLM bằng cách sử dụng một câu hỏi ba lần để đảm bảo tính công bằng và độ tin cậy của chuẩn mực. Mỗi lần, nếu câu trả lời đúng, điểm số là 1, nếu không thì là 0.

(1) Độ chính xác trung bình. Đối với ba lần đánh giá trên một LLM sử dụng cùng một câu hỏi, chúng tôi sử dụng điểm số trung bình làm điểm số của LLM cho câu hỏi đó. Sau đó chúng tôi tính điểm số trung bình cho tất cả các câu hỏi làm độ chính xác trung bình cuối cùng.

(2) Độ chính xác trường hợp tồi tệ nhất. Khác với độ chính xác trung bình, nếu cả ba lần đánh giá đều đưa ra câu trả lời đúng, điểm số là 1, nếu không thì là 0. Sau đó giá trị trung bình trên tất cả các câu hỏi được báo cáo là độ chính xác trường hợp tồi tệ nhất cuối cùng.

(3) Độ chính xác trường hợp tốt nhất. Thoải mái hơn so với trường hợp tồi tệ nhất, nếu lớn hơn hoặc bằng một câu trả lời đưa ra câu trả lời đúng, điểm số là 1, nếu không thì là 0.

(4) Độ chính xác bỏ phiếu đa số. Nếu ít nhất hai câu trả lời đúng, điểm số là 1, nếu không thì là 0.

(5) Khả năng lặp lại. Sự tương đồng của các phản hồi trong ba lần chạy khác nhau. Sự tương đồng cao chỉ ra khả năng lặp lại tốt.

## 4 Đánh giá

Phần này trình bày đánh giá, bao gồm phương pháp đánh giá (Phần 4.1), thiết lập thí nghiệm 4.2 và kết quả đánh giá 4.3.

### 4.1 Phương pháp Đánh giá

#### 4.1.1 Tổng quan về LLM

Chúng tôi chọn các LLM đại diện với công nghệ cơ bản khác nhau, kích thước mô hình khác biệt và hiệu suất tiên tiến. Chúng tôi cũng xem xét dữ liệu huấn luyện bổ sung, kiến trúc, mục đích đích và liệu có phải mã nguồn mở hay không. Cụ thể, chúng tôi chọn 12 mô hình từ OpenAI, Anthropic, Meta, Tsinghua, Baidu, Alibaba và iFlytek, bao gồm GPT-3.5, ChatGPT và GPT-4 từ OpenAI, Claude từ Anthropic, LLaMA-13B và Vicuna-13B (dựa trên LLaMA) từ Meta, ChatGLM-6B, ChatGLM v2-6B và ChatGLM-13B từ Tsinghua, Ernie từ Baidu, Qianwen từ Alibaba và Spark từ iFlytek. Kích thước mô hình dao động từ 6 tỷ đến 175 tỷ. Thông tin chi tiết được liệt kê trong Bảng 3.

#### 4.1.2 Phương pháp Đánh giá

Chúng tôi không sử dụng kỹ thuật prompt như học few-shot và chain-of-thought (CoT) để tránh những tác động không thể dự đoán được, được xác minh bởi các công trình liên quan [7]. Họ thấy rằng CoT hoạt động tốt hơn trên một số mô hình (ví dụ: ChatGLM-6B, +3%) và tệ hơn trên những mô hình khác (ví dụ: Chinese-LLaMA-13B, -11.9%). Chúng tôi cũng tiến hành một thí nghiệm để đánh giá tác động của học few-shot. Trên ChatGLM v2-6B, chúng tôi chọn ngẫu nhiên một số cặp câu hỏi-và-câu trả lời làm ví dụ để đánh giá tác động. Sau đó chúng tôi sử dụng các hạt giống ngẫu nhiên khác nhau và chạy chúng ba lần cho mỗi hạt giống. Bảng 4 cho thấy kết quả. Văn bản in đậm cho thấy kết quả tốt nhất (khoảng 37.54%), và văn bản gạch chân cho thấy kết quả tồi tệ nhất (khoảng 32.69%). Khoảng cách độ chính xác sử dụng các hạt giống ngẫu nhiên khác nhau là lớn, đạt khoảng 5%.

### 4.2 Thiết lập Thí nghiệm

Chúng tôi triển khai cục bộ ChatGLM-6B và ChatGLM v2-6B trên một GPU NVidia V100 duy nhất và triển khai LLaMA-13B và Vicuna-13B trên bốn GPU NVidia 1080 Ti. Đối với các mô hình mã nguồn đóng cung cấp truy cập API, chúng tôi thực hiện đánh giá bằng cách sử dụng API của chúng, bao gồm GPT-3.5, ChatGPT và GPT-4. Đối với các mô hình mã nguồn đóng khác không cung cấp truy cập API nhưng cung cấp các sản phẩm dựa trên web, chúng tôi thực hiện đánh giá bằng cách mô phỏng đầu vào của người dùng trong trình duyệt, bao gồm Claude, ChatGLM-130B, Ernie, Qianwen và Spark. Để đảm bảo tính công bằng, chúng tôi đặt tham số nhiệt độ là một nửa giá trị tối đa của mô hình cho tất cả mười hai mô hình, ngoại trừ các sản phẩm dựa trên web, không cung cấp giao diện để đặt tham số nhiệt độ.

Để trích xuất và đánh giá phản hồi, chúng tôi sử dụng thuật toán HRE được minh họa trong Thuật toán 1 và GPT-4 để tránh những tác động hiệu suất không thể dự đoán được của kỹ thuật prompt. Chúng tôi đặt N là 10, M là 100 và minimum_limit là 2, có nghĩa là lặp lại 10 lần lặp và chọn ngẫu nhiên 100 phản hồi trong mỗi lần lặp. Nếu một định dạng phản hồi xuất hiện ít nhất hai lần, chúng tôi sẽ thêm mẫu này. Chúng tôi thu thập 66744 phản hồi từ LLM, và các mẫu regex được xác định bởi thuật toán HRE được thể hiện trong Bảng 5. Những mẫu này hỗ trợ trích xuất và đánh giá 67% câu trả lời của tổng số phản hồi, chứng minh hiệu quả của thuật toán của chúng tôi. 33% phản hồi còn lại không có mẫu regex thống nhất được xử lý bởi GPT-4, và các đánh giá được kiểm tra thủ công. Chúng tôi sử dụng prompt chain-of-thought (CoT) được thể hiện trong Hình 3 để sửa đầu ra đánh giá của GPT-4 khi trích xuất các câu trả lời. Lưu ý rằng prompt này được sử dụng để đánh giá tính đúng đắn của các phản hồi còn lại mà không tác động đến quá trình đánh giá mô hình.

### 4.3 Kết quả Đánh giá

Chúng tôi báo cáo kết quả đánh giá bao gồm chuẩn mực đa cấp độ, đa phương thức và mức độ khó có tham chiếu con người, và chuẩn mực khả năng lặp lại phản hồi. Hơn nữa, sử dụng các chỉ số toàn diện, chúng tôi đánh giá độ chính xác của LLM trong các trường hợp khác nhau.

#### 4.3.1 Chuẩn mực Đa cấp độ

Bảng 6 cho thấy kết quả chuẩn mực đa cấp độ ở các cấp độ chi tiết từng tập dữ liệu, từng nhánh khả năng và từng kiến thức. Lưu ý rằng cột "Human" chỉ ra độ chính xác của con người làm tham chiếu. Độ chính xác trung bình trên toàn bộ tập dữ liệu là 60.91%. GPT-4 vượt trội hơn các mô hình khác rất nhiều trên nhiều nhánh khả năng và danh mục kiến thức. Hầu hết LLM có khả năng hiểu biết tốt hơn khả năng kiến thức thường thức và lý luận, và khả năng lý luận hoạt động tồi tệ nhất. So với độ chính xác của con người, GPT-4 vượt trội hơn con người 15.84% cho nhánh kiến thức thường thức và có độ chính xác tương tự với con người (73.16% so với 74.82%) cho nhánh hiểu biết, trong khi hoạt động tệ hơn con người cho nhánh lý luận với khoảng cách 25.94%.

#### 4.3.2 Chuẩn mực Đa phương thức

Chúng tôi chủ yếu thực hiện chuẩn mực đa phương thức trên các mô hình Ernie, ChatGLM-130B, Qianwen và Spark, vì chúng cung cấp kết nối Internet và có thể truy cập hình ảnh. Đối với tám mô hình khác không cung cấp kết nối Internet bao gồm GPT-3.5, ChatGPT, GPT-4, Claude, LLaMA-13B, Vicuna-13B, ChatGLM-6B và ChatGLM v2-6B, chúng tôi cũng nhập url hình ảnh cho chúng.

Đối với tám mô hình không có khả năng xử lý hình ảnh, phản hồi lý tưởng là thừa nhận chúng không có khả năng như vậy và không thể hiểu hình ảnh. Tuy nhiên, các đánh giá của chúng tôi thấy rằng chỉ có một số ít phản hồi của GPT-3.5, ChatGPT và GPT-4 có thể thừa nhận những hạn chế xử lý hình ảnh. Các mô hình khác chỉ tạo ra những phản hồi ảo giác và vô nghĩa.

Đối với bốn mô hình có khả năng xử lý hình ảnh, thông qua chuẩn mực đa phương thức toàn diện, chúng tôi phát hiện rằng không có LLM nào được đánh giá hiểu chính xác nội dung hình ảnh. Khi đối mặt với một câu hỏi đa phương thức chứa cả văn bản và hình ảnh, phản hồi của chúng hoặc là văn bản hoặc là văn bản với hình ảnh. Tuy nhiên, chúng tôi thấy rằng phản hồi đầu ra có mối tương quan thấp với hình ảnh đầu vào. Mặc dù Ernie có một xác suất nhất định để hiểu chính xác các hình ảnh thông thường như ImageNet [4], tuy nhiên, độ chính xác giảm đáng kể (gần như bằng không) khi đối mặt với hình ảnh hình học.

#### 4.3.3 Chuẩn mực Độ khó sử dụng Độ chính xác có Tham chiếu Con người

Chúng tôi đánh giá khả năng giải quyết các câu hỏi với các mức độ khó khác nhau, sử dụng độ chính xác của con người làm tham chiếu, như được thể hiện trong Hình 4. Lưu ý rằng Cấp 1 đến Cấp 5 là từ đơn giản đến phức tạp, với Cấp 1 dễ nhất và Cấp 5 khó nhất. Nhãn con người chỉ ra độ chính xác của con người ở cấp độ đó, và con người có thể đạt 89.92%, 69.20%, 51.11%, 32.64% và 14.98% độ chính xác trung bình từ Cấp 1 đến 5, tương ứng.

Từ Cấp 1 đến 4, GPT-4 hoạt động tốt nhất trong số tất cả mười hai LLM. Đối với Cấp 5, Claude hoạt động tốt nhất. Một hiện tượng thú vị và ngược với trực giác khác là con người thường hoạt động tốt hơn LLM đối với các mức độ khó đơn giản như Cấp 1 đến 3. Ngược lại, con người hoạt động tệ hơn một số LLM đối với các mức độ thách thức như Cấp 4 và 5. Ví dụ, GPT-4 có độ chính xác trung bình cao hơn con người ở Cấp 4. Ở Cấp 5, nhiều LLM có độ chính xác trung bình tương tự hoặc thậm chí cao hơn con người, bao gồm ChaGLM, Claude, Ernie, ChatGPT, GPT-4, GPT-3.5, Vicuna-13b và ChatGLM-130b. Khoảng cách giữa con người và LLM tốt nhất trên mỗi cấp độ là 31.67%, 16.68%, 6.09%, -5.23%, -14.51%, tương ứng.

#### 4.3.4 Khả năng Lặp lại Phản hồi

Chúng tôi đánh giá thêm khả năng lặp lại của các phản hồi. Đối với mỗi câu hỏi, chúng tôi hỏi LLM bằng cách sử dụng ba loại prompt khác nhau và mỗi loại lặp lại ba lần. Ba loại prompt là (i) chỉ câu hỏi không có prompt nào; thêm (ii) "Câu trả lời là:" và (iii) "Câu trả lời và lý do là:" ở cuối câu hỏi, tương ứng. Hình 5 cho thấy kết quả. Chúng tôi phân loại các phản hồi thành ba danh mục: (1) cả ba câu trả lời đều giống nhau, như chọn A ba lần, (2) một câu trả lời khác, như A, A và B cho ba câu trả lời. Và (3) cả ba câu trả lời hoàn toàn khác nhau, như A, B và C cho ba câu trả lời. Lưu ý rằng danh mục (1) có nghĩa là khả năng lặp lại tốt nhất trong khi (3) có nghĩa là khả năng lặp lại tồi tệ nhất. Chúng tôi thấy rằng Spark và Ernie có khả năng lặp lại phản hồi tốt nhất, trong khi LLaMA-13B là tồi tệ nhất.

#### 4.3.5 Độ chính xác Trung bình, Trường hợp Tồi tệ nhất, Trường hợp Tốt nhất, Bỏ phiếu Đa số

Hình 6 trình bày kết quả độ chính xác trong các trường hợp trung bình, tồi tệ nhất, tốt nhất và bỏ phiếu đa số. Chúng tôi cũng sử dụng ba loại prompt, sử dụng cùng thiết lập prompt với đánh giá khả năng lặp lại phản hồi ở trên. Chúng tôi thấy những quan sát sau. (1) GPT-4 đạt độ chính xác cao nhất trong bốn trường hợp. (2) ChatGLM v2-6B hoạt động tốt hơn ChatGLM-130B, có nghĩa là kiến trúc mô hình và chất lượng dữ liệu huấn luyện quan trọng hơn việc chỉ tăng kích thước mô hình. (3) Độ chính xác trường hợp tồi tệ nhất của LLM thấp hơn đáng kể so với độ chính xác trung bình tương ứng, có nghĩa là mô hình không phải lúc nào cũng đưa ra câu trả lời đúng trong ba lần đánh giá, cho thấy độ tin cậy kém của LLM. (4) Độ chính xác trường hợp tốt nhất của LLM cao hơn nhiều so với các trường hợp khác, có nghĩa là mô hình có xác suất cao đưa ra câu trả lời đúng trong ba lần đánh giá. (5) Độ chính xác bỏ phiếu đa số tương tự với độ chính xác trung bình, có nghĩa là hầu hết thời gian, mô hình có thể đưa ra câu trả lời đúng.

## 5 Kết luận

Bài báo này cung cấp một chuẩn mực đa cấp độ, đa phương thức, có tham chiếu con người và tự động chấm điểm để đánh giá các mô hình ngôn ngữ lớn – AGIBench, bao gồm một tập dữ liệu câu hỏi, đánh giá tự động chấm điểm và các chỉ số toàn diện. Thông qua việc gắn nhãn mỗi câu hỏi với bốn thuộc tính, bao gồm nhánh khả năng, kiến thức, độ khó, phương thức, AGIBench hỗ trợ chuẩn mực đa cấp độ ở các cấp độ chi tiết từng tập dữ liệu, từng nhánh khả năng, từng kiến thức, từng mức độ khó, từng phương thức và từng câu hỏi. Chúng tôi sử dụng tỷ lệ chính xác được trả lời bởi hàng triệu con người có học thức để gắn nhãn mức độ khó của mỗi câu hỏi và bao gồm các phương thức văn bản và hình ảnh. Chúng tôi đề xuất thêm một thuật toán HRE để tránh những tác động không thể dự đoán được của kỹ thuật prompt. Thay vì chỉ sử dụng độ chính xác trung bình làm chỉ số, chúng tôi định nghĩa các chỉ số đa chiều để đánh giá LLM một cách toàn diện. Các thí nghiệm của chúng tôi trên mười hai LLM cho thấy hiệu quả của AGIBench.

# 2309.10707.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2309.10707.pdf
# Kích thước tệp: 424415 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
TỔNG HỢP KHOẢNG CORPUS ĐỂ THÍCH ỨNG MIỀN ASR ZERO-SHOT SỬ DỤNG
CÁC MÔ HÌNH NGÔN NGỮ LỚN
Hsuan Su♡♢∗Ting-Yao Hu♢Hema Swetha Koppula♢Raviteja Vemulapalli♢
Jen-Hao Rick Chang♢Karren Yang♢Gautam Varma Mantena♢Oncel Tuzel♢
♡Đại học Quốc gia Đài Loan♢Apple
TÓM TẮT
Trong khi các hệ thống Nhận dạng Giọng nói Tự động (ASR) được
sử dụng rộng rãi trong nhiều ứng dụng thế giới thực, chúng thường
không tổng quát hóa tốt cho các miền mới và cần được tinh chỉnh
trên dữ liệu từ các miền này. Tuy nhiên, dữ liệu miền đích
thường không có sẵn trong nhiều kịch bản. Trong bài báo này, chúng
tôi đề xuất một chiến lược mới để thích ứng các mô hình ASR
với các miền đích mới mà không cần bất kỳ văn bản hoặc giọng nói nào từ
những miền đó. Để thực hiện điều này, chúng tôi đề xuất một quy trình
tổng hợp dữ liệu mới sử dụng Mô hình Ngôn ngữ Lớn
(LLM) để tạo ra một corpus văn bản miền đích, và một mô hình
tổng hợp giọng nói có thể kiểm soát hiện đại để tạo ra
giọng nói tương ứng. Chúng tôi đề xuất một chiến lược tinh chỉnh
hướng dẫn trong ngữ cảnh đơn giản nhưng hiệu quả để tăng
hiệu quả của LLM trong việc tạo ra corpus văn bản cho các miền mới.
Các thí nghiệm trên tập dữ liệu SLURP cho thấy phương pháp
được đề xuất đạt được cải thiện tỷ lệ lỗi từ tương đối trung bình
28% trên các miền đích chưa thấy mà không có bất kỳ
sự suy giảm hiệu suất nào trong các miền nguồn.
Từ khóa chỉ mục —nhận dạng giọng nói tự động, mô hình ngôn ngữ lớn, tổng hợp giọng nói có thể kiểm soát, thích ứng ASR zero-shot

1. GIỚI THIỆU
Thích ứng một hệ thống Nhận dạng Giọng nói Tự động (ASR) Đầu-cuối-Đầu (E2E) với các miền đích mới là một nhiệm vụ đầy thách thức do sự hạn chế về khả năng có sẵn của dữ liệu giọng nói-văn bản được ghép đôi. Gần đây, các phương pháp thích ứng chỉ có văn bản [1, 2, 3, 4, 5, 6] đã được phát triển để giải quyết vấn đề khan hiếm dữ liệu. Một số trong những nghiên cứu này [5, 6] sử dụng mô hình Tổng hợp Giọng nói Có thể Kiểm soát (CSS) để tạo ra giọng nói cho corpus văn bản miền đích, và tạo ra một tập dữ liệu được ghép đôi với văn bản thật và giọng nói tổng hợp để thích ứng mô hình ASR. Tuy nhiên, trong nhiều kịch bản, việc thu thập một corpus văn bản miền đích có thể tốn kém, mất thời gian, hoặc thậm chí không khả thi do các mối quan tâm về quyền riêng tư.

Các Mô hình Ngôn ngữ Lớn (LLM) gần đây đã được chứng minh hoạt động cực kỳ tốt trên nhiều tác vụ xử lý ngôn ngữ tự nhiên, đặc biệt là trong các cài đặt few/zero-shot. Điều này thúc đẩy chúng tôi tận dụng LLM để thích ứng các mô hình ASR với các miền mới mà không cần bất kỳ dữ liệu giọng nói hoặc văn bản nào từ những miền đó. Các nghiên cứu trước đó khai thác LLM trong các hệ thống ASR trong quá trình suy luận sử dụng các kỹ thuật tái chấm điểm [7, 8] hoặc hợp nhất [9], và chúng gặp phải chi phí đắt đỏ của suy luận LLM. Ngược lại, chúng tôi sử dụng LLM để tạo ra dữ liệu tổng hợp miền đích để thích ứng một mô hình ASR được tiền huấn luyện (xem Hình 1).

Đầu tiên, chúng tôi tạo ra một corpus văn bản tổng hợp bằng cách nhắc nhở một LLM với tên miền đích (một từ hoặc cụm từ ngắn). Để cải thiện chất lượng của corpus văn bản tổng hợp, chúng tôi đề xuất một chiến lược tinh chỉnh hướng dẫn trong ngữ cảnh (ICIF) đơn giản nhưng hiệu quả. Giả sử rằng mô hình ASR được tiền huấn luyện đã được huấn luyện trên một tập dữ liệu nguồn với nhiều miền (ví dụ: một trợ lý cá nhân với một tập hợp các tính năng hiện có), ICIF học cách liên kết tên miền với kiến thức của LLM từ các câu văn bản nguồn. Sau đó, chúng tôi sử dụng một mô hình CSS hiện đại [10] để tạo ra giọng nói tương ứng với các văn bản tổng hợp. Cuối cùng, corpus giọng nói-văn bản được ghép đôi hoàn toàn tổng hợp được sử dụng để tinh chỉnh một mô hình ASR được tiền huấn luyện, cải thiện hiệu suất trên miền đích quan tâm trong khi duy trì hiệu suất trên miền nguồn.

Những đóng góp chính: (1) Chúng tôi chứng minh rằng tổng hợp corpus văn bản sử dụng LLM cho phép thích ứng miền ASR zero-shot. (2) Chiến lược tinh chỉnh hướng dẫn trong ngữ cảnh được đề xuất của chúng tôi cải thiện chất lượng của corpus văn bản tổng hợp dẫn đến những cải thiện đáng kể trong hiệu suất ASR cuối cùng. (3) Chúng tôi cho thấy rằng quy trình tổng hợp dữ liệu được đề xuất đạt được trung bình 28% giảm Tỷ lệ Lỗi Từ (WER) tương đối trên các miền đích chưa thấy trong tập dữ liệu SLURP [11].

--- TRANG 2 ---
2. CÁC NGHIÊN CỨU LIÊN QUAN
Nhiều nghiên cứu đã cho thấy rằng LLM có thể tổng hợp dữ liệu hữu ích cho các tác vụ xuôi dòng. Ye et al. [12], Yoo et al. [13], và Meng et al. [14] nhắc nhở LLM với các hướng dẫn thủ công để tạo ra dữ liệu cho việc tinh chỉnh các mô hình xuôi dòng. Trong nghiên cứu này, chúng tôi tinh chỉnh LLM với dữ liệu hướng dẫn để cải thiện tính nhất quán định dạng của corpus văn bản được tạo ra.

Một số nghiên cứu trước đó cũng sử dụng LLM để cải thiện hiệu suất của ASR. Dingliwa et al. [7] và Ma et al. [8] tiến hành tái chấm điểm lần thứ hai sử dụng điểm số perplexity từ LLM. Li et al. [9] đề xuất hợp nhất LLM sâu, tích hợp LLM vào bộ giải mã của mô hình ASR E2E dựa trên encoder-decoder. Trong khi các phương pháp này cải thiện hiệu suất, chúng yêu cầu suy luận LLM trong quá trình giải mã ASR, điều này làm tăng chi phí tính toán. Ngược lại, phương pháp của chúng tôi chuyển giao kiến thức từ LLM đến mô hình ASR thông qua một corpus văn bản tổng hợp.

3. PHƯƠNG PHÁP LUẬN
Hình 1 cho thấy tổng quan về phương pháp được đề xuất. Quy trình của chúng tôi bao gồm một LLM, một mô hình CSS, và một mô hình ASR được tiền huấn luyện. Cho một miền đích quan tâm dt, chúng tôi tạo ra một corpus văn bản-giọng nói được ghép đôi hoàn toàn tổng hợp Ct= {(xt_i, yt_i)}N_i=1, trong đó xt_i, yt_i là nội dung văn bản và tín hiệu giọng nói của mẫu thứ i tương ứng. Để làm điều này, chúng tôi đầu tiên tạo ra một câu văn bản xt_i ∼ pLLM(x|dt) từ LLM được điều kiện hóa trên dt. Sau đó, chúng tôi tổng hợp giọng nói tương ứng yt_i ∼ pCSS(y|xt_i) sử dụng mô hình CSS. Cuối cùng, chúng tôi sử dụng dữ liệu văn bản-giọng nói tổng hợp để tinh chỉnh mô hình ASR cho miền đích dt.

3.1. Tổng hợp Văn bản với LLM
Mục tiêu của chúng tôi là tổng hợp một corpus văn bản phù hợp với phân phối văn bản của một miền đích dt đã cho. Để làm điều này, chúng tôi yêu cầu LLM được tiền huấn luyện trên hàng nghìn tỷ token văn bản tạo ra các câu liên quan đến miền đích sử dụng nhắc nhở: "Vui lòng tạo ra một câu liên quan đến dt:". Các thí nghiệm ban đầu của chúng tôi cho thấy việc nhắc nhở một cách ngây thơ các LLM có sẵn trong quy trình của chúng tôi dẫn đến một số cải thiện ASR trên miền đích. Tuy nhiên, chất lượng của văn bản được tạo ra và sự liên quan của nó đến miền đích đều không đủ. Vì LLM có sẵn được huấn luyện trên các corpus văn bản tổng quát quy mô lớn, rất khó để chúng tạo ra văn bản trong miền chất lượng cao chỉ sử dụng tên miền đích dt. Để giải quyết vấn đề này, chúng tôi đề xuất một chiến lược tinh chỉnh hướng dẫn trong ngữ cảnh (ICIF) đơn giản nhưng hiệu quả để cải thiện khả năng của LLM trong việc tạo ra văn bản trong miền khi được nhắc nhở với tên miền đích.

3.1.1. Tinh chỉnh Hướng dẫn trong Ngữ cảnh (ICIF)
Chiến lược tinh chỉnh hướng dẫn trong ngữ cảnh (ICIF) được đề xuất của chúng tôi kết hợp tinh chỉnh hướng dẫn (IF) [15] với học trong ngữ cảnh (ICL) [16] sử dụng một định dạng hướng dẫn thống nhất. Cụ thể, chúng tôi đầu tiên tinh chỉnh LLM với dữ liệu hướng dẫn. Sau đó, trong quá trình suy luận, chúng tôi nhắc nhở LLM với các minh chứng bổ sung trong cùng định dạng hướng dẫn.

Để xây dựng dữ liệu hướng dẫn và minh chứng, chúng tôi sử dụng một corpus văn bản nguồn Cs={(xs_j, ds_j)}M_j=1, chứa văn bản xs_j từ các miền nguồn ds_j khác biệt với dt. Như được hiển thị trong Hình 2, chúng tôi tái diễn đạt mỗi (xs_j, ds_j)∈Cs thành một hướng dẫn ngôn ngữ tự nhiên– "Vui lòng tạo ra một câu liên quan đến ds_j: xs_j"– và tinh chỉnh LLM trên những hướng dẫn này. Trong giai đoạn suy luận, chúng tôi đặt trước một tập con của những hướng dẫn này từ miền nguồn vào nhắc nhở gốc cho miền đích chưa thấy ("Vui lòng tạo ra một câu liên quan đến dt:") như các minh chứng bổ sung. LLM sử dụng nhắc nhở mở rộng để tạo ra một câu văn bản trong miền đích.

Chiến lược ICIF của chúng tôi học cấu trúc và định dạng của corpus nguồn Cs, và liên kết tên miền đích dt với kiến thức từ LLM được tiền huấn luyện. Như được hiển thị trong Phần 5.2, corpus văn bản tổng hợp kết quả bao gồm các câu chất lượng cao, đa dạng có liên quan về mặt ngữ nghĩa đến miền đích chưa thấy.

3.2. Tổng hợp Giọng nói Có thể Kiểm soát
Chúng tôi sử dụng một mô hình Tổng hợp Giọng nói Có thể Kiểm soát (CSS) hiện đại [10] để tổng hợp giọng nói yt_i ∼ pCSS(y|xt_i), cho văn bản miền đích xt_i được tạo ra bởi mô hình LLM được tinh chỉnh hướng dẫn. Mô hình CSS học một phân phối tiên nghiệm để mô hình hóa phong cách âm thanh của giọng nói. Bằng cách lấy mẫu từ phân phối tiên nghiệm này, mô hình có thể tạo ra một corpus giọng nói tổng hợp trong các điều kiện âm thanh khác nhau.

3.3. Thích ứng Mô hình ASR
Cuối cùng, chúng tôi tinh chỉnh mô hình ASR trên giọng nói tổng hợp được chuẩn bị bởi mô hình LLM và CSS. Trong các thí nghiệm ban đầu của chúng tôi, chúng tôi quan sát thấy rằng mô hình ASR thường bị quá khớp với các tạo phẩm giọng nói tổng hợp trong quá trình tinh chỉnh, điều này hạn chế hiệu suất của nó. Để giải quyết vấn đề này, chúng tôi thêm dữ liệu giọng nói thật (tức là từ các miền nguồn) vào giọng nói tổng hợp từ miền đích để điều chỉnh việc tinh chỉnh mô hình ASR.

--- TRANG 3 ---
Zero-shot (WER) Miền Đích Trung bình
Phương pháp Báo thức Âm thanh Lịch Nấu ăn Thời gian Thư điện tử Chung IOT Danh sách Âm nhạc Tin tức Chơi Q&A Khuyến nghị Xã hội Mang về Vận chuyển Thời tiết
ASR miền nguồn
(Cơ sở)8.0 13.1 12.8 18.2 11.2 19.0 14.4 19.2 14.6 10.5 15.3 24.8 22.3 15.7 26.3 26.5 17.1 12.9 16.77
ICIF 4.90 7.50 10.27 9.93 8.33 12.70 13.33 12.17 11.17 8.00 10.67 18.90 19.43 12.57 16.80 19.33 9.80 9.37 11.95
WER Tương đối (%) ↑38.75% 42.75% 19.79% 45.42% 25.60% 33.16% 7.41% 36.63% 23.52% 23.81% 30.28% 23.79% 12.86% 19.96% 36.12% 27.04% 42.69% 27.39% 28.73%

Bảng 1. Thích ứng ASR với Corpus Văn bản Tổng hợp. Kết quả của các mô hình ASR được tinh chỉnh trên dữ liệu tổng hợp miền đích từ quy trình của chúng tôi với ICIF. Đối với mỗi miền đích, ASR miền nguồn (cơ sở) được huấn luyện trên LibriSpeech theo sau bởi dữ liệu từ 17 miền (không bao gồm miền đích) trong tập dữ liệu SLURP. Chỉ số được hiển thị là WER (thấp hơn là tốt hơn).

4. THIẾT LẬP THÍ NGHIỆM
4.1. Tập dữ liệu
SLURP [11] là một tập dữ liệu hiểu ngôn ngữ nói chứa 16521 phát biểu của các lệnh con người đối với một tác nhân ảo, dựa trên 200 nhắc nhở được xác định trước như "Bạn sẽ hỏi thời gian như thế nào." Các phát biểu được ghi lại trong hai loại môi trường âm thanh (tai nghe và xa), và được phân loại thành 18 miền (thư điện tử, báo thức, và mang về, v.v.). Chúng tôi sử dụng tập con tai nghe để tiến hành các thí nghiệm thích ứng miền ASR zero-shot. Trong mỗi thí nghiệm của chúng tôi, chúng tôi chọn một trong những miền này làm miền đích và kết hợp 17 miền còn lại để tạo thành miền nguồn. Mục tiêu của chúng tôi là cải thiện hiệu suất của một mô hình ASR miền nguồn được tiền huấn luyện trên miền đích, mà không sử dụng bất kỳ dữ liệu giọng nói thật hoặc văn bản thật nào từ miền đích.

4.2. Các Mô hình Ngôn ngữ Lớn
Chúng tôi sử dụng LLaMA-7B [17] để tổng hợp corpus văn bản. LLaMA là một LLM hiện đại với kiến trúc transformer dựa trên bộ giải mã được tiền huấn luyện trên hàng nghìn tỷ token. LLaMA đã cho thấy hiệu suất xuất sắc trên các tác vụ xuôi dòng với tinh chỉnh hướng dẫn [17, 18]. Chúng tôi áp dụng thích ứng thứ hạng thấp (LoRA) [19] để đóng băng hầu hết các tham số mô hình và cải thiện hiệu quả của tinh chỉnh hướng dẫn. Trong quá trình suy luận/tổng hợp, chúng tôi theo [20] để sử dụng giải mã điển hình [18] với τ = 0.9 và đặt hình phạt lặp lại [21] thành 1.1. Chúng tôi bao gồm 10 minh chứng trong nhắc nhở suy luận.

4.3. Tổng hợp Giọng nói Có thể Kiểm soát (CSS)
Mô hình CSS của chúng tôi được áp dụng từ Style Equalization [10], dựa trên Mạng Neural Tái phát Biến phân (VRNN). Chúng tôi thực hiện bốn sửa đổi sau để tăng cường mô hình hóa phong cách âm thanh: (1) tăng số lượng hỗn hợp Gaussian của phân phối đầu ra VRNN (từ 3 lên 10); (2) tăng kích thước đặc trưng phong cách âm thanh (từ 512 lên 768); (3) khởi tạo các trạng thái ẩn của VRNN sử dụng trung bình của chuỗi vector phong cách; và (4) sử dụng đặc trưng phong cách âm thanh để điều chỉnh các lớp tuyến tính đầu ra, tương tự như những gì được thực hiện trong [22]. Chúng tôi huấn luyện mô hình CSS được sửa đổi trên tập huấn luyện của LibriTTS [23].

4.4. Thích ứng Mô hình ASR
Chúng tôi sử dụng ESPNet [24] để xây dựng mô hình ASR E2E, bao gồm một bộ mã hóa dựa trên conformer [25] và một bộ giải mã dựa trên transformer [26]. Trong mỗi thí nghiệm của chúng tôi, chúng tôi đầu tiên thu được một mô hình ASR miền nguồn được tiền huấn luyện bằng cách huấn luyện trên LibriSpeech [27] theo sau bởi dữ liệu miền nguồn (tức là 17 miền SLURP được xác định trước không bao gồm miền đích). Sau đó chúng tôi thích ứng mô hình ASR được tiền huấn luyện này với miền đích sử dụng dữ liệu tổng hợp từ LLM và CSS. Để so sánh công bằng giữa các mô hình, chúng tôi chọn tất cả các checkpoint cuối cùng sử dụng tập phát triển miền đích như một tập xác thực.

5. KẾT QUẢ VÀ THẢO LUẬN
5.1. Thích ứng ASR với Corpus Văn bản Tổng hợp
Trong Bảng 1, chúng tôi báo cáo hiệu suất của các mô hình ASR được tinh chỉnh trên dữ liệu miền đích từ quy trình tổng hợp corpus của chúng tôi. Đối với mỗi miền đích, chúng tôi chuẩn bị corpus văn bản tổng hợp sử dụng LLM với ICIF và giọng nói tổng hợp tương ứng sử dụng CSS. Đáng chú ý, chúng tôi đạt được sự giảm lớn trong WER trên toàn bộ (cải thiện tương đối trung bình 28.73%), mà không sử dụng bất kỳ văn bản thật hoặc giọng nói thật nào từ miền đích để tinh chỉnh. Đối với một số miền đích (tức là Âm thanh, Nấu ăn, và Vận chuyển), chúng tôi đạt được hơn 40% cải thiện tương đối so với các mô hình miền nguồn được tiền huấn luyện. Ngoài ra, các mô hình ASR được tinh chỉnh cũng mang lại một cải thiện nhỏ (giảm WER tương đối trung bình 5.98%) trong các miền nguồn. Tổng thể, những kết quả này chứng minh hiệu quả của quy trình tổng hợp corpus của chúng tôi để thích ứng các mô hình ASR với các miền văn bản chưa thấy.

Chúng tôi cũng tinh chỉnh các mô hình ASR miền nguồn với (1) văn bản miền đích thật và giọng nói tổng hợp, và (2) văn bản thật và giọng nói thật, nhận được WER trung bình 10.77% và 10.74%, tương ứng. Lưu ý rằng, mục đích của thí nghiệm này là thiết lập một giới hạn trên cho thích ứng, và dữ liệu miền đích thật không có sẵn trong thích ứng zero-shot.

5.2. Phân tích ICIF
Đóng góp của IF và ICL
Như chi tiết trong Phần 3.1.1, ICIF bao gồm hai bước: (1) hướng dẫn (IF), tinh chỉnh LLM sử dụng các hướng dẫn được công thức hóa từ một corpus văn bản nguồn, và (2) minh chứng (ICL), nhắc nhở LLM với một số hướng dẫn ví dụ. Bảng 2 phân tích những đóng góp cá nhân của những thành phần này. Chúng tôi quan sát thấy rằng cả hai đều hữu ích cho việc cải thiện WER của mô hình ASR được tinh chỉnh: sử dụng hoặc hướng dẫn (IF) hoặc minh chứng (ICL) cải thiện WER so với nhắc nhở ngây thơ (tức là từ 14.02 xuống 12.13 và 12.59 tương ứng). Kết hợp IF và ICL (ICIF) tiếp tục cải thiện WER xuống 11.95. Những kết quả này cho thấy rằng cả hướng dẫn và minh chứng đều hữu ích cho quy trình corpus tổng hợp của chúng tôi. Tiếp theo, chúng tôi hỏi liệu hướng dẫn và minh chứng có tác động chồng chéo lên chất lượng văn bản tổng hợp hay không, hoặc liệu chúng đóng vai trò khác biệt. Để giải quyết câu hỏi này, chúng tôi định hình văn bản tổng hợp theo hai trục bổ sung: (1) tính đa dạng, được đo bằng Self-BLEU 4-gram [28] và (2) sự tương đồng với corpus đích thật, được đo bằng phân kỳ JS giữa các phân phối token [29]. Như được hiển thị trong Bảng 2, hướng dẫn (IF) rất hiệu quả trong việc tạo ra văn bản tương đồng với miền đích, nhưng với chi phí của tính đa dạng. Mặt khác, minh chứng (ICL) đạt được tính đa dạng cao với một cải thiện khiêm tốn trong sự tương đồng. Kết hợp hai kỹ thuật tạo ra sự cân bằng giữa việc cải thiện tính đa dạng và sự tương đồng của văn bản tổng hợp với miền đích. Chúng tôi kết luận rằng ICIF cho phép LLM ánh xạ từ tên miền đến các văn bản liên quan và đa dạng hơn, điều này lần lượt cải thiện tính tổng quát hóa của các mô hình ASR đối với các miền đích chưa thấy.

Tác động của kích thước corpus văn bản tổng hợp lên WER
Hình 3 cho thấy hiệu suất của các mô hình ASR được tinh chỉnh trên các lượng văn bản tổng hợp khác nhau cho hai miền đích được chọn ngẫu nhiên ('Vận chuyển' và 'Nấu ăn'). Nói chung, chúng tôi thấy rằng sử dụng nhiều dữ liệu văn bản tổng hợp hơn để tinh chỉnh các mô hình ASR cải thiện WER, điều này gợi ý rằng các mô hình hưởng lợi từ việc tiếp xúc với tính đa dạng văn bản lớn hơn. Mặt khác, chúng tôi cũng quan sát thấy rằng hiệu suất ASR bão hòa tại một điểm nào đó (ví dụ: khoảng 55K mẫu cho miền "Nấu ăn"). Điều này có thể do các tạo phẩm tổng hợp hoặc nhiễu. Chúng tôi để lại vấn đề lựa chọn dữ liệu tổng hợp cho nghiên cứu tương lai.

Tác động của số lượng minh chứng lên WER
Vì các minh chứng tăng tính đa dạng văn bản tổng hợp, chúng tôi cũng điều tra tác động của số lượng minh chứng lên hiệu suất của các mô hình ASR được tinh chỉnh. Hình 4 cho thấy WER trên hai miền đích được chọn ngẫu nhiên khi thay đổi số lượng minh chứng từ 0 đến 10. Chúng tôi quan sát thấy rằng WER được cải thiện đáng kể thậm chí với hai minh chứng và tiếp tục cải thiện với nhiều minh chứng hơn. Thú vị là, chúng tôi cũng quan sát thấy rằng độ lệch chuẩn của WER tăng lên với nhiều minh chứng hơn. Chúng tôi giả thuyết điều này là do tính đa dạng văn bản tăng lên, dẫn đến kết quả biến thiên trong quá trình tinh chỉnh. Việc lựa chọn và sắp xếp các minh chứng cũng có thể tác động đến chất lượng văn bản tổng hợp. Chúng tôi để lại những điều tra này cho nghiên cứu tương lai.

--- TRANG 4 ---
WER↓ Cải thiện WER
Tương đối (%) ↑ Tính đa dạng ↓
(SB-4) Tương đồng ↓
(JS-Div)
ASR Miền nguồn 16.77 - - -
ICIF (IF+ICL) 11.95 28.73 0.596 0.466
Demo (ICL) 12.13 27.67 0.424 0.482
Instruct (IF) 12.59 24.92 0.74 0.451
Nhắc nhở Ngây thơ 14.02 16.40 0.471 0.521

Bảng 2. Phân tích ICIF. Chúng tôi điều tra những đóng góp cá nhân của hướng dẫn (IF) và minh chứng (ICL) cho ICIF. Ngoài WER, chúng tôi báo cáo tính đa dạng của văn bản tổng hợp (SB-4), và sự tương đồng của nó với corpus văn bản miền đích (JS-Div). Xem Phần 5.2 cho chi tiết.

6. KẾT LUẬN
Trong bài báo này, chúng tôi đề xuất một quy trình bao gồm một LLM và một mô hình CSS để thích ứng các mô hình ASR với corpus giọng nói tổng hợp. Chúng tôi áp dụng quy trình tổng hợp dữ liệu cho thích ứng miền ASR mà không có dữ liệu miền đích, và nhận được cải thiện tương đối 16% với các LLM được tiền huấn luyện. Để cải thiện thêm chất lượng văn bản tổng hợp, chúng tôi sử dụng một phương pháp tinh chỉnh hướng dẫn trong ngữ cảnh (ICIF) sáng tạo trên LLM. Kết quả cho thấy rằng phương pháp được đề xuất của chúng tôi mang lại cải thiện WER tương đối trung bình 28% trên các miền đích chưa thấy mà không làm giảm hiệu suất trên các miền nguồn.

--- TRANG 5 ---
7. TÀI LIỆU THAM KHẢO
[1] Zhong Meng, Yashesh Gaur, Naoyuki Kanda, Jinyu Li, Xie Chen, Yu Wu, và Yifan Gong, "Thích ứng mô hình ngôn ngữ nội bộ với dữ liệu chỉ có văn bản cho nhận dạng giọng nói đầu-cuối-đầu," Proc. InterSpeech, 2022.
[2] Janne Pylkkönen, Antti Ukkonen, Juho Kilpikoski, Samu Tamminen, và Hannes Heikinheimo, "Thích ứng miền chỉ có văn bản nhanh của mạng dự đoán rnn-transducer," Proc. InterSpeech, 2021.
[3] Keqi Deng và Philip C Woodland, "Các mô hình asr đầu-cuối-đầu có thể thích ứng sử dụng lms nội bộ có thể thay thế và softmax dư," trong ICASSP. IEEE, 2023, trang 1–5.
[4] Ashish Mittal, Sunita Sarawagi, và Preethi Jyothi, "Thích ứng chỉ có văn bản tại chỗ của các mô hình giọng nói với tính toán giọng nói chi phí thấp," trong ICLR, 2022.
[5] Raviraj Joshi và Anupam Singh, "Một cơ sở đơn giản cho thích ứng miền trong các hệ thống asr đầu-cuối-đầu sử dụng dữ liệu tổng hợp," arXiv preprint arXiv:2206.13240, 2022.
[6] Vladimir Bataev, Roman Korostik, Evgeny Shabalin, Vitaly Lavrukhin, và Boris Ginsburg, "Thích ứng miền chỉ có văn bản cho asr đầu-cuối-đầu sử dụng bộ tạo văn bản-thành-mel-spectrogram tích hợp," Proc. InterSpeech, 2023.
[7] Saket Dingliwa, Ashish Shenoy, Sravan Bodapati, Ankur Gandhe, Ravi Teja Gadde, và Katrin Kirchhoff, "Nhắc nhở miền: Hướng tới thích ứng miền hiệu quả bộ nhớ và tính toán của các hệ thống asr," trong Proc. Interspeech, 2022.
[8] Rao Ma, Mengjie Qian, Potsawee Manakul, Mark Gales, và Kate Knill, "Có thể các mô hình ngôn ngữ lớn tạo sinh thực hiện sửa lỗi asr không?," arXiv preprint arXiv:2307.04172, 2023.
[9] Yuang Li, Yu Wu, Jinyu Li, và Shujie Liu, "Nhắc nhở các mô hình ngôn ngữ lớn cho thích ứng miền zero-shot trong nhận dạng giọng nói," arXiv preprint arXiv:2306.16007, 2023.
[10] Jen-Hao Rick Chang, Ashish Shrivastava, Hema Koppula, Xiaoshuai Zhang, và Oncel Tuzel, "Cân bằng phong cách: Học không giám sát các mô hình chuỗi tạo sinh có thể kiểm soát," trong Proc. ICML, 2022.
[11] Emanuele Bastianelli, Andrea Vanzo, Pawel Swietojanski, và Verena Rieser, "SLURP: Một gói tài nguyên hiểu ngôn ngữ nói," trong Proc. EMNLP, 2020.
[12] Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, và Lingpeng Kong, "ZeroGen: Học zero-shot hiệu quả thông qua tạo tập dữ liệu," trong Proc. EMNLP, 2022.
[13] Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, và Woomyoung Park, "GPT3Mix: Tận dụng các mô hình ngôn ngữ quy mô lớn để tăng cường văn bản," trong Findings of the Association for Computational Linguistics: EMNLP 2021, 2021.
[14] Yu Meng, Jiaxin Huang, Yu Zhang, và Jiawei Han, "Tạo dữ liệu huấn luyện với các mô hình ngôn ngữ: Hướng tới hiểu ngôn ngữ zero-shot," trong NeurIPS, 2022.
[15] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, và cộng sự, "Mở rộng quy mô các mô hình ngôn ngữ được tinh chỉnh hướng dẫn," arXiv preprint arXiv:2210.11416, 2022.
[16] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, và cộng sự, "Các mô hình ngôn ngữ là người học few-shot," NeurIPS, 2020.
[17] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample, "Llama: Các mô hình ngôn ngữ nền tảng mở và hiệu quả," 2023.
[18] Clara Meister, Tiago Pimentel, Gian Wiher, và Ryan Cotterell, "Lấy mẫu điển hình cục bộ," Trans. of ACL, vol. 11, trang 102–121, 2023.
[19] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen, "Lora: Thích ứng thứ hạng thấp của các mô hình ngôn ngữ lớn," Proc. ICLR, 2022.
[20] Yen-Ting Lin, Alexandros Papangelis, Seokhwan Kim, Sungjin Lee, Devamanyu Hazarika, Mahdi Namazifar, Di Jin, Yang Liu, và Dilek Hakkani-Tur, "Tăng cường dữ liệu trong ngữ cảnh có chọn lọc cho phát hiện ý định sử dụng thông tin V điểm," trong Proc. EACL, 2023.
[21] Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, và Richard Socher, "Ctrl: Một mô hình ngôn ngữ transformer có điều kiện cho tạo sinh có thể kiểm soát," arXiv preprint arXiv:1909.05858, 2019.
[22] Eric R Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, và Gordon Wetzstein, "pi-gan: Mạng đối kháng tạo sinh ngầm định tuần hoàn cho tổng hợp hình ảnh nhận biết 3d," trong Proc. CVPR, 2021.
[23] Heiga Zen, Viet Dang, Rob Clark, Yu Zhang, Ron J Weiss, Ye Jia, Zhifeng Chen, và Yonghui Wu, "Libritts: Một corpus được tạo từ librispeech cho văn bản-thành-giọng nói," arXiv preprint arXiv:1904.02882, 2019.
[24] Shinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro Nishitoba, Yuya Unno, Nelson Enrique Yalta Soplin, Jahn Heymann, Matthew Wiesner, Nanxin Chen, và cộng sự, "Espnet: Bộ công cụ xử lý giọng nói đầu-cuối-đầu," arXiv preprint arXiv:1804.00015, 2018.
[25] Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, và cộng sự, "Conformer: Transformer tăng cường tích chập cho nhận dạng giọng nói," Proc. InterSpeech, 2020.
[26] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin, "Attention is all you need," NeurIPS, 2017.
[27] Vassil Panayotov, Guoguo Chen, Daniel Povey, và Sanjeev Khudanpur, "Librispeech: một corpus asr dựa trên sách âm thanh miền công cộng," trong Proc. ICASSP, 2015.
[28] Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, và Yong Yu, "Texygen: Một nền tảng đánh giá cho các mô hình tạo văn bản," SIGIR, 2018.
[29] Sebastian Ruder, Parsa Ghaffari, và John G. Breslin, "Các chiến lược lựa chọn dữ liệu cho phân tích tình cảm đa miền," 2017.

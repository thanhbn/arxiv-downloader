# Woodpecker: Điều chỉnh ảo giác cho mô hình ngôn ngữ lớn đa phương thức

Shukang Yin1*, Chaoyou Fu2∗‡†, Sirui Zhao1∗‡, Tong Xu1‡, Hao Wang1
Dianbo Sui, Yunhang Shen2, Ke Li2, Xing Sun2, Enhong Chen1‡
1School of Data Science, USTC & State Key Laboratory of Cognitive Intelligence
2Tencent YouTu Lab

## Tóm tắt

Ảo giác là bóng tối lớn bao phủ lên các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM) đang phát triển nhanh chóng, đề cập đến hiện tượng văn bản được tạo ra không phù hợp với nội dung hình ảnh. Để giảm thiểu ảo giác, các nghiên cứu hiện tại chủ yếu dựa vào phương pháp điều chỉnh hướng dẫn đòi hỏi phải đào tạo lại mô hình với dữ liệu cụ thể. Trong bài báo này, chúng tôi mở ra một hướng khác, giới thiệu một phương pháp không cần đào tạo có tên Woodpecker. Giống như chim gõ kiến chữa lành cây, nó phát hiện và điều chỉnh các ảo giác từ văn bản được tạo ra. Cụ thể, Woodpecker bao gồm năm giai đoạn: trích xuất khái niệm chính, công thức hóa câu hỏi, xác thực kiến thức thị giác, tạo ra tuyên bố thị giác, và điều chỉnh ảo giác. Được triển khai theo cách khắc phục hậu quả, Woodpecker có thể dễ dàng phục vụ các MLLM khác nhau, đồng thời có khả năng diễn giải bằng cách truy cập đầu ra trung gian của năm giai đoạn. Chúng tôi đánh giá Woodpecker cả định lượng và định tính và cho thấy tiềm năng to lớn của paradigm mới này. Trên benchmark POPE, phương pháp của chúng tôi đạt được cải thiện 30.66%/24.33% về độ chính xác so với baseline MiniGPT-4/mPLUG-Owl. Mã nguồn được công bố tại https://github.com/BradyFU/Woodpecker.

## 1. Giới thiệu

Các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLM) hiện đang phát triển mạnh mẽ trong cộng đồng nghiên cứu, hướng tới Trí tuệ Nhân tạo Tổng quát (AGI). Bằng cách khai thác các Mô hình Ngôn ngữ Lớn (LLM) mạnh mẽ, các nhà nghiên cứu căn chỉnh các phương thức nước ngoài như thị giác với ngôn ngữ, và phát triển các MLLM với nhiều khả năng thú vị khác nhau, chẳng hạn như mô tả đầy đủ nội dung của một hình ảnh đã cho.

Tuy nhiên, dù mạnh mẽ đến đâu, các MLLM này đôi khi đưa ra mô tả không phù hợp với hình ảnh đầu vào. Điều này được gọi là ảo giác và đã được phát hiện là phổ biến trong các MLLM. Như được minh họa trong Hình 1, MLLM khẳng định các đối tượng không tồn tại và thất bại trong việc mô tả chính xác thuộc tính của đối tượng trong hình ảnh, được chúng tôi phân loại tương ứng là ảo giác cấp đối tượng và cấp thuộc tính. Rõ ràng rằng những ảo giác này là rào cản lớn đối với việc ứng dụng thực tế của các MLLM.

Để giảm thiểu ảo giác, các công trình hiện tại thường khám phá phương pháp điều chỉnh hướng dẫn. Một quan sát chính chung là các MLLM có xu hướng ảo giác khi tạo ra văn bản dài hơn, dẫn đến các chiến lược giải quyết vấn đề khác nhau. Ví dụ, LRV-Instruction thực hiện một phương pháp trực quan bằng cách giới hạn độ dài văn bản của dữ liệu hướng dẫn. Kết quả là, mô hình được điều chỉnh thường tạo ra mô tả ít ảo giác hơn nhưng cũng ít chi tiết hơn. VIGC thực hiện một sơ đồ tạo ra nhiều bước và cập nhật lặp lại các đặc trưng thị giác với ngữ cảnh văn bản, điều này làm giảm ảo giác bằng cách hy sinh hiệu quả tạo ra. Hơn nữa, cả hai phương pháp này đều dựa trên điều chỉnh hướng dẫn và do đó tốn kém về dữ liệu và tính toán.

Để phá vỡ giới hạn, chúng tôi thực hiện một chiến lược khác có thể điều chỉnh trực tiếp ảo giác mà không cần đào tạo lại. Như được minh họa trong Hình 2, cho trước một văn bản được tạo ra bởi MLLM cũng như hình ảnh đầu vào, khung công tác không cần đào tạo Woodpecker của chúng tôi điều chỉnh văn bản một cách tinh tế, và đồng thời, cung cấp bằng chứng tương ứng, tức là các hộp giới hạn. Nó thêm khả năng diễn giải và độ tin cậy vượt ra ngoài các MLLM hộp đen, cung cấp khả năng kiểm tra sự thật thị giác thuận tiện. Cụ thể, khung công tác của chúng tôi thực hiện điều chỉnh sau một chẩn đoán kỹ lưỡng, kết hợp tổng cộng năm giai đoạn: (1) Trích xuất khái niệm chính xác định các đối tượng chính được đề cập trong các câu được tạo ra; (2) Công thức hóa câu hỏi đặt câu hỏi xung quanh các đối tượng được trích xuất, chẳng hạn như số lượng và thuộc tính của chúng; (3) Xác thực kiến thức thị giác trả lời các câu hỏi được công thức hóa thông qua các mô hình chuyên gia. Ví dụ, một mô hình nhận thức thị giác có thể được sử dụng để xác định số lượng đối tượng; (4) Tạo ra tuyên bố thị giác chuyển đổi các cặp Câu hỏi-Trả lời (QA) trên thành một cơ sở kiến thức thị giác, bao gồm các tuyên bố cấp đối tượng và cấp thuộc tính về hình ảnh đầu vào; (5) Điều chỉnh ảo giác chỉnh sửa các ảo giác và thêm bằng chứng tương ứng dưới sự hướng dẫn của cơ sở kiến thức thị giác. Đáng chú ý là mỗi bước trong quy trình đều rõ ràng và minh bạch, tạo ra khả năng diễn giải tốt.

Chúng tôi đánh giá hiệu quả của phương pháp thông qua các thí nghiệm định lượng và định tính toàn diện trên các bộ dữ liệu POPE, MME, và LLaV A-QA90. Kết quả và các phân tích liên quan cho thấy sự vượt trội của paradigm mới này. Ví dụ, trên benchmark POPE, phương pháp của chúng tôi cải thiện đáng kể độ chính xác của baseline MiniGPT-4/mPLUG-Owl từ 54.67%/62% lên 85.33%/86.33%.

Tóm lại, các đóng góp chính như sau:
• Chúng tôi đề xuất một khung công tác không cần đào tạo có tên Woodpecker để điều chỉnh ảo giác cho MLLM. Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên áp dụng cách tiếp cận điều chỉnh để giải quyết vấn đề ảo giác thị giác.
• Khung công tác của chúng tôi được thiết kế theo cách mà mỗi bước đều rõ ràng và minh bạch, do đó cung cấp khả năng diễn giải tốt.
• Chúng tôi đánh giá toàn diện hiệu quả của phương pháp, và những cải thiện lớn chứng minh tiềm năng to lớn của nó trong việc điều chỉnh ảo giác.

## 2. Công trình liên quan

### 2.1. Ảo giác trong MLLM

Gần đây, ngày càng có nhiều sự chú ý đến hiện tượng ảo giác của MLLM. Điều này chủ yếu là do vấn đề này ảnh hưởng trực tiếp đến độ tin cậy của MLLM. Các nghiên cứu hiện tại về ảo giác của MLLM chủ yếu tập trung vào hai khía cạnh, tức là đánh giá/phát hiện và giảm thiểu. Hướng nghiên cứu trước đó thường đào tạo một mô hình phân loại để phân biệt ảo giác hoặc kiểm tra văn bản đầu ra đối với câu trả lời chuẩn để quyết định xem ảo giác có xảy ra hay không.

Đối với giảm thiểu ảo giác, các công trình trước đó tập trung vào việc tối ưu hóa quá trình thu thập dữ liệu và sơ đồ đào tạo. LRV-Instruction soạn các trường hợp tiêu cực để kiềm chế sự quá tự tin. Hơn nữa, độ dài văn bản của câu trả lời Sự thật Chuẩn được kiểm soát chặt chẽ, dựa trên quan sát rằng các phản hồi ngắn hơn ít có khả năng bị ảo giác hơn. Tương tự, VIGC thực hiện một quá trình lặp lại, trong đó các câu trả lời ngắn được tạo ra và nối lại mỗi lần. Bằng cách này, nó cố gắng đảm bảo độ chính xác mà không ảnh hưởng đến chi tiết.

Trong khi các công trình trước đó cố gắng phát triển MLLM với ít ảo giác hơn, mục tiêu chính của chúng tôi là tinh chỉnh các phản hồi của MLLM bằng cách chỉnh sửa các phần ảo giác. Cụ thể, chúng tôi thiết kế một khung công tác không cần đào tạo kết hợp các mô hình có sẵn. Điều này miễn phức tạp việc thu thập dữ liệu hướng dẫn và đào tạo tốn kém tài nguyên. Kết quả là, khung công tác của chúng tôi có thể dễ dàng tích hợp với các MLLM khác nhau, phục vụ như một module cắm và chạy tổng quát.

### 2.2. LLM được tăng cường bởi kiến thức

Vì LLM bị giới hạn bởi kiến thức vốn có từ việc đào tạo trước, nhiều công trình đã được dành cho việc tăng cường LLM với kiến thức bên ngoài từ cơ sở kiến thức được xác định trước hoặc internet. Như một mở rộng tự nhiên của ý tưởng này, gần đây, các nhà nghiên cứu đã khám phá việc sử dụng kiến thức như bằng chứng để giảm thiểu ảo giác thực tế trong LLM. Cụ thể, những công trình này sử dụng kiến thức liên quan như thông tin nền để tinh chỉnh một tuyên bố đầu vào có thể sai, dẫn đến độ chính xác thực tế cao hơn của phản hồi. Phương pháp của chúng tôi có điểm chung với ý tưởng rằng chúng tôi sử dụng thông tin liên quan đến hình ảnh đã cho để điều chỉnh các tuyên bố có thể sai. Tuy nhiên, việc chuyển ý tưởng này sang lĩnh vực thị giác-ngôn ngữ không phải là tầm thường. Điều này là do đối tác chỉ có ngôn ngữ thường chỉ xử lý văn bản và thu được kiến thức liên quan thông qua truy xuất, trong khi việc làm như vậy đối với các cặp hình ảnh-văn bản là không phù hợp. Hơn nữa, LLM được tăng cường bởi kiến thức quan tâm nhiều hơn đến việc giảm thiểu các sai lầm thực tế, trong khi chúng tôi chú trọng nhiều hơn đến việc giảm thiểu ảo giác thị giác. Tương ứng với những khác biệt chính, trong công trình này, chúng tôi thiết kế một chiến lược để xây dựng một cơ sở kiến thức thị giác có cấu trúc có điều kiện trên hình ảnh và truy vấn. Chúng tôi cũng khám phá cách giải quyết cả ảo giác cấp đối tượng và cấp thuộc tính theo cách có tổ chức, như chúng tôi sẽ minh họa sau.

### 2.3. Suy luận thị giác được hỗ trợ bởi LLM

Theo phân loại trong khảo sát, khung công tác được đề xuất của chúng tôi có liên quan chặt chẽ đến mô hình Suy luận Thị giác được Hỗ trợ bởi LLM. Ý tưởng chính là chúng ta có thể tận dụng khả năng suy luận mạnh mẽ và tuân theo hướng dẫn của LLM để giúp thực hiện các tác vụ thị giác hoặc đa phương thức. Các vai trò điển hình mà LLM đóng bao gồm bộ điều phối tác vụ, bộ suy luận, hoặc bộ tinh chỉnh ngôn ngữ. Trong công trình này, chúng tôi sử dụng khả năng suy luận mạnh mẽ và thành thạo ngôn ngữ của LLM để giúp các quá trình trích xuất khái niệm chính, công thức hóa câu hỏi, và điều chỉnh ảo giác.

## 3. Phương pháp

Mục tiêu của chúng tôi là chẩn đoán và điều chỉnh ảo giác trong phản hồi được tạo ra bởi MLLM. Những thách thức chính nằm ở việc định vị ảo giác và xác định sự thật, có thể được tổ chức theo cách có cấu trúc cho việc điều chỉnh cuối cùng. Để đạt được điều này, chúng tôi chia nhỏ toàn bộ quá trình thành năm tác vụ phụ: trích xuất khái niệm chính (Mục 3.1), công thức hóa câu hỏi (Mục 3.2), xác thực kiến thức thị giác (Mục 3.3), tạo ra tuyên bố thị giác (Mục 3.4), và điều chỉnh ảo giác (Mục 3.5). Chúng tôi sẽ minh họa từng bước một cách tuần tự sau. Tổng quan về khung công tác của chúng tôi được mô tả trong Hình 3.

### 3.1. Trích xuất khái niệm chính

Vì các mô tả thường xoay quanh các khái niệm chính, bước đầu tiên là trích xuất chúng từ câu được tạo ra. Để đạt được điều này, chúng tôi xác định các đối tượng chính được đề cập trong câu, đó là những đối tượng có khả năng thoát khỏi ảo giác thị giác nhất. Ví dụ, cho trước một câu "Người đàn ông đang đeo một chiếc mũ đen.", các đối tượng "người đàn ông" và "mũ" được trích xuất, và sẽ phục vụ như trung tâm cho chẩn đoán trong các bước tiếp theo. Dựa trên khả năng tổng quát hóa mạnh mẽ và kiến thức thế giới phong phú của LLM, chúng tôi nhắc một LLM để thực hiện tác vụ này.

Mẫu cho trích xuất khái niệm chính được liệt kê trong Phụ lục A.1, bao gồm một thông điệp hệ thống và một lời nhắc được định dạng. Phần trước thiết lập ngữ cảnh cơ bản cho LLM, trong khi phần sau bắt đầu với một số mô tả chi tiết về tác vụ và một số yêu cầu, tiếp theo là một số ví dụ trong ngữ cảnh và đầu vào. Các ví dụ trong ngữ cảnh được cung cấp để LLM có thể hiểu rõ hơn các yêu cầu về tác vụ.

### 3.2. Công thức hóa câu hỏi

Sau khi thu được các khái niệm chính, chúng tôi đặt một loạt câu hỏi xung quanh chúng để thực hiện chẩn đoán ảo giác. Các câu hỏi của chúng tôi hướng tới cả ảo giác cấp đối tượng và cấp thuộc tính. Đối với phần trước, chúng tôi hỏi, "Có {đối tượng} nào trong hình ảnh không? Có bao nhiêu?", trong đó "{đối tượng}" là khái niệm chính được trích xuất trước đó. Đối với phần sau, nhiều câu hỏi khác nhau liên quan đến thuộc tính của đối tượng có thể được công thức hóa, chẳng hạn như "{đối tượng} đang làm gì?", "{đối tượng 1} có ở bên phải của {đối tượng 2} không?", và "{đối tượng} có màu gì?", trong đó "{đối tượng 1}" và "{đối tượng 2}" là các khái niệm chính khác nhau.

Trên thực tế, các câu hỏi cấp đối tượng có thể được xác thực trực tiếp thông qua việc nhận thức hình ảnh, trong khi các câu hỏi cấp thuộc tính đa dạng hơn nhiều và phụ thuộc vào ngữ cảnh. Để tạo thuận lợi cho việc công thức hóa câu hỏi tự do như vậy, chúng tôi nhắc một LLM với một số ví dụ trong ngữ cảnh để các câu hỏi có ý nghĩa được đặt ra. Lời nhắc được liệt kê trong Phụ lục A.2.

### 3.3. Xác thực kiến thức thị giác

Bước này chịu trách nhiệm giải quyết hai loại câu hỏi trên. Đối với các câu hỏi cấp đối tượng, điểm mấu chốt là xác định sự tồn tại và số lượng của một đối tượng nhất định. Dựa trên khả năng nhận thức mạnh mẽ của các mô hình nền tảng thị giác, chúng tôi sử dụng một bộ phát hiện đối tượng tập mở như bộ giải quyết. Đối với các câu hỏi cấp thuộc tính, chúng tôi áp dụng một mô hình VQA được đào tạo trước để trả lời các câu hỏi có điều kiện trên hình ảnh. So với các MLLM chính thống, mô hình VQA có xu hướng tạo ra câu trả lời ngắn hơn nhưng cũng với ít ảo giác hơn và do đó có thể là một lựa chọn hợp lý.

### 3.4. Tạo ra tuyên bố thị giác

Sau khi các câu hỏi được đặt ra và trả lời, chúng tôi kết hợp các cặp QA thành các tuyên bố thị giác và tổ chức chúng thành một cơ sở kiến thức thị giác để tham khảo trong bước tiếp theo. Cơ sở kiến thức thị giác được cấu trúc bởi:

• Tuyên bố cấp đối tượng: Phần thông tin này chủ yếu đóng vai trò trong việc giảm thiểu ảo giác cấp đối tượng. Chúng tôi bao gồm thông tin về số lượng đối tượng của các khái niệm chính được trích xuất từ các câu (Mục 3.1). Đối với các đối tượng tồn tại, chúng tôi thêm một tuyên bố như "Có {số lượng} {tên}.", trong đó "{số lượng}" và "{tên}" là số lượng và tên của một loại đối tượng nhất định. Chúng tôi sử dụng một mẫu tương tự, "Không có {tên}", cho các đối tượng không tồn tại. Thông tin đếm đến từ việc phát hiện đối tượng tập mở ở bước trước.

• Tuyên bố cấp thuộc tính: Chúng tôi bao gồm thông tin thuộc tính cụ thể cho từng đối tượng để giảm thiểu ảo giác cấp thuộc tính. Các thuộc tính điển hình bao gồm vị trí, màu sắc, hành động, v.v. Đối với phần này, chúng tôi áp dụng một mô hình QA-to-Claim để hợp nhất các câu hỏi và câu trả lời thành các tuyên bố. Để đối phó với các trường hợp liên quan đến nhiều đối tượng hoặc mối quan hệ giữa các đối tượng tiền cảnh và nền, cần có thêm thông tin toàn cục. Do đó, chúng tôi cũng bao gồm các tuyên bố liên quan đến tương tác giữa các đối tượng khác nhau hoặc các đối tượng và nền, chẳng hạn như "Con mèo đang nằm bên cạnh con chó.".

### 3.5. Điều chỉnh ảo giác

Được hướng dẫn bởi các tuyên bố thị giác, một LLM có thể hoạt động như một bộ điều chỉnh và chỉnh sửa ảo giác trong các phản hồi được tạo ra. Cụ thể, sau khi kết hợp cơ sở kiến thức thị giác với các phản hồi gốc thành một lời nhắc, chúng tôi hướng dẫn một LLM điều chỉnh các phản hồi và đưa ra những phản hồi tinh chỉnh. Để có khả năng diễn giải tốt hơn, chúng tôi hướng dẫn rõ ràng LLM gắn các hộp giới hạn ngay sau các biểu thức khi đề cập đến các đối tượng. Thiết kế này tạo thuận lợi cho sự tương ứng giữa các thực thể được đề cập trong các phản hồi và các instance đối tượng trong hình ảnh, cung cấp khả năng truy cập thuận tiện để kiểm tra độ tin cậy của đầu ra. Mẫu lời nhắc cho điều chỉnh được bao gồm trong Phụ lục A.3.

## 4. Thí nghiệm

### 4.1. Thiết lập thí nghiệm

Bộ dữ liệu. POPE được dành riêng cho việc đánh giá ảo giác của MLLM. Nó chứa các thiết lập lấy mẫu ngẫu nhiên, phổ biến, và đối kháng, chủ yếu khác nhau trong cách xây dựng các mẫu tiêu cực. Đối với thiết lập ngẫu nhiên, các đối tượng không có mặt trong hình ảnh được lấy mẫu ngẫu nhiên, trong khi đối với thiết lập phổ biến, các đối tượng không tồn tại được lấy mẫu từ một nhóm các đối tượng với tần suất cao nhất. Đối với thiết lập đối kháng, các đối tượng thường xuyên cùng xuất hiện nhưng không tồn tại trong hình ảnh được lấy mẫu.

Về thiết lập lấy mẫu, chúng tôi lấy mẫu 50 hình ảnh và xây dựng 6 câu hỏi cho mỗi hình ảnh. Tỷ lệ giữa các mẫu dương tính và tiêu cực được cân bằng, cụ thể là 50% vs 50%. Thiết lập này chuyển đổi chú thích đối tượng thành một loạt câu hỏi "Có-hoặc-Không" và tập trung vào việc đánh giá ảo giác cấp đối tượng, và cụ thể hơn, khía cạnh tồn tại. Do đó, các MLLM được nhắc trả lời xem một đối tượng có tồn tại trong hình ảnh hay không. Theo đó, các chỉ số đánh giá bao gồm độ chính xác, độ chính xác, độ nhạy, và điểm f1.

MME là một benchmark toàn diện được thiết kế để đánh giá hiệu suất của MLLM trong các khía cạnh khác nhau. Nó bao gồm mười tác vụ phụ cho khả năng nhận thức và bốn tác vụ phụ cho khả năng nhận thức, tương ứng. Trong bài báo này, chúng tôi điều chỉnh mục đích của bộ dữ liệu và chọn các tập con tồn tại và đếm để đo lường ảo giác cấp đối tượng. Các tập con vị trí và màu sắc được sử dụng để đo lường ảo giác cấp thuộc tính. Tương tự như thiết lập của POPE, mỗi tập con được cấu thành từ các câu hỏi "Có-hoặc-Không". Chúng tôi báo cáo điểm số, cụ thể là tổng của độ chính xác và độ chính xác+ theo triển khai chính thức, trong đó điểm số cao hơn chỉ ra hiệu suất tốt hơn và ít ảo giác hơn.

LLaVA-QA90 cũng được sử dụng để đánh giá MLLM. Cụ thể, chúng tôi lấy mẫu 10 truy vấn loại mô tả được diễn giải lại dưới nhiều hình thức khác nhau để hướng dẫn một MLLM mô tả hình ảnh, chẳng hạn như "Mô tả hình ảnh sau." và "Bức ảnh nói về gì?". LLaV A-QA90 sử dụng hình ảnh từ COCO và áp dụng GPT-4 chỉ có văn bản để soạn các truy vấn và câu trả lời tham khảo. Chúng tôi loại bỏ các câu trả lời tham khảo, trực tiếp đưa hình ảnh vào GPT-4V, và nhắc nó đánh giá các phản hồi theo hai chiều được thiết kế của chúng tôi, tức là độ chính xác và độ chi tiết. Mẫu lời nhắc có sẵn trong Phụ lục A.4.

Baseline. Chúng tôi chọn các MLLM chính thống làm mô hình baseline, bao gồm mPLUG-Owl, LLaV A, MiniGPT-4, và Otter. Bốn MLLM này tuân theo kiến trúc "mã hóa thị giác-giao diện-mô hình ngôn ngữ" và được đào tạo trên các cặp hình ảnh-văn bản. Cụ thể, LLaV A và MiniGPT-4 áp dụng một lớp phép chiếu đơn giản để căn chỉnh các embedding đa phương thức. mPLUG-Owl sử dụng Q-Former để nén các đặc trưng thị giác thành một số lượng token cố định, có thể được nối với các embedding ngôn ngữ. Otter áp dụng một bộ lấy mẫu lại Perceiver tương tự để có được việc nén token.

Chi tiết triển khai. Quy trình của chúng tôi không cần đào tạo và bao gồm ba mô hình được đào tạo trước ngoài MLLM cần được điều chỉnh. Chúng tôi chọn LLM, GPT-3.5-turbo, để thực hiện các tác vụ phụ của trích xuất khái niệm chính, công thức hóa câu hỏi, và điều chỉnh ảo giác. Đối với phát hiện đối tượng tập mở, chúng tôi sử dụng Grounding DINO để trích xuất thông tin đếm đối tượng với ngưỡng phát hiện mặc định. Hơn nữa, chúng tôi sử dụng BLIP-2-FlanT5 XXL như mô hình VQA để trả lời các câu hỏi liên quan đến thuộc tính có điều kiện trên hình ảnh đầu vào.

Đối với các câu hỏi "Có-hoặc-Không", chúng tôi phát hiện rằng khả năng tuân theo hướng dẫn của một số MLLM hơi yếu, thường đưa ra các văn bản không liên quan chẳng hạn như biểu tượng cảm xúc thuần túy hoặc URL. Đây là một trở ngại cho quá trình điều chỉnh của chúng tôi. Bên cạnh đó, một số MLLM chỉ đưa ra một "Có" hoặc "Không" đơn lẻ, điều này cũng đặt ra thách thức cho việc điều chỉnh. Để xử lý những vấn đề này, chúng tôi thiết kế hai biện pháp đơn giản: (1) trước tiên chúng tôi trích xuất từ khóa, tức là "Có" và "Không" từ các phản hồi làm câu trả lời, sau đó kết hợp các câu hỏi với các câu trả lời thành các tuyên bố cụ thể hơn. Ví dụ, cho trước một câu hỏi, "Có con chó nào trong hình ảnh không?" và một câu trả lời của mô hình, "Có", chúng tôi soạn một câu trả lời cụ thể hơn như "Có, có một con chó trong hình ảnh."; (2) chúng tôi bổ sung đưa các câu hỏi vào LLM trong quá trình điều chỉnh để LLM có thể nắm bắt tốt hơn ngữ cảnh và yêu cầu tác vụ.

### 4.2. Kết quả thí nghiệm

Kết quả trên POPE. Kết quả trên POPE dưới các thiết lập ngẫu nhiên, phổ biến, và đối kháng được tóm tắt trong Bảng 1. Có thể thấy rằng, trong thiết lập ngẫu nhiên, MiniGPT-4 tương đối yếu về khả năng nhận thức, cụ thể là trong việc đánh giá sự tồn tại của đối tượng. Điểm f1 cho MiniGPT-4 chỉ là 43.33%, trong khi các baseline khác đều trên 70%. Ngoài ra, mPLUG-Owl và Otter có xu hướng quá tự tin, như được phản ánh bởi tỷ lệ Có cao. Đồng thời, độ nhạy cao và độ chính xác thấp dẫn đến điểm f1 tương đối thấp. Đối với tất cả baseline, Woodpecker đạt được những cải thiện nhất quán trong hầu hết các chỉ số, cho thấy phương pháp của chúng tôi có khả năng điều chỉnh hiệu quả ảo giác cấp đối tượng. Cụ thể, Woodpecker có được cải thiện tương đối 30.66% cho MiniGPT-4 và 24.33% cho mPLUG-Owl về độ chính xác.

Trong các thiết lập phổ biến và đối kháng thách thức hơn, các MLLM cho thấy sự suy giảm hiệu suất ở các mức độ khác nhau, nổi bật hơn trong các baseline tương đối mạnh hơn, chẳng hạn như LLaV A. Cụ thể, so với thiết lập ngẫu nhiên, LLaV A cho thấy sự suy giảm độ chính xác 9.33% và 12.67% trong các thiết lập phổ biến và đối kháng, tương ứng. Xu hướng này cho thấy rằng các MLLM có thể phù hợp một cách sai lầm với một số đặc điểm dữ liệu trong kho văn bản đào tạo. Ví dụ, sự suy giảm trong thiết lập phổ biến có thể xuất phát từ phân phối dữ liệu long-tail. Ngược lại, được trang bị một mô hình thị giác chuyên gia mạnh mẽ, phương pháp điều chỉnh của chúng tôi cho thấy tính ổn định mạnh mẽ, tạo ra những cải thiện rõ ràng trong nhiều chỉ số khác nhau cho các baseline, trong đó tất cả độ chính xác đều vượt quá 80%. Đặc biệt, Woodpecker của chúng tôi cải thiện đáng kể độ chính xác của mPLUG-Owl từ 56.33% lên 81% trong thiết lập đối kháng.

Kết quả trên MME. So với POPE, các thí nghiệm trên MME toàn diện hơn vì nó bao gồm không chỉ đánh giá ảo giác cấp đối tượng mà còn cấp thuộc tính. Kết quả tương ứng được liệt kê trong Bảng 2. Chúng ta có thể thấy rằng, đối với đánh giá cấp đối tượng, LLaV A và Otter xuất sắc trong khía cạnh tồn tại, điều này cũng được xác minh trong đánh giá POPE, trong khi họ tương đối tụt lại trong việc trả lời các truy vấn đếm khó hơn. Trong trường hợp này, phương pháp điều chỉnh của chúng tôi đặc biệt hiệu quả và đóng góp một cải thiện điểm số lớn, từ +65 so với LLaV A đến +101.66 so với MiniGPT-4. Về đánh giá cấp thuộc tính, các MLLM baseline có xu hướng đạt được kết quả kém hơn, cho thấy rằng họ dễ bị ảo giác cấp thuộc tính hơn. Ví dụ, MiniGPT-4 chỉ đạt được điểm số 65 trong phần màu sắc, và mPLUG-Owl chỉ đạt được 66.67. Sau khi giới thiệu khung công tác điều chỉnh của chúng tôi, các MLLM này tạo ra những cải thiện nhất quán và đáng chú ý, trong đó điểm số của mPLUG-Owl tăng lên 78.33. Ngược lại, những cải thiện về vị trí tương đối nhỏ, có thể do hai yếu tố: (1) khả năng tương đối yếu của mô hình VQA BLIP-2 trong suy luận vị trí; (2) LLM có thể không hiểu đủ rõ các hộp giới hạn đã cho để tự mình suy ra mối quan hệ vị trí.

Kết quả trên LLaVA-QA90. Khác với hai thí nghiệm trên chỉ liên quan đến các câu hỏi "Có-hoặc-Không", thí nghiệm trên LLaV A-QA90 mở rộng hơn nhiều. Các truy vấn loại mô tả hướng dẫn các MLLM dịch đầy đủ hình ảnh đầu vào thành ngôn ngữ, thay vì chỉ đề cập đến sự tồn tại hoặc thuộc tính của một đối tượng.

Do đó, cần có một cách tiếp cận hợp lý và toàn diện hơn để hỗ trợ việc đánh giá các câu trả lời mở như vậy. Một số nỗ lực hiện tại được dành cho việc khám phá đánh giá tự động với sự trợ giúp của LLM. Cụ thể, một GPT-4 chỉ có văn bản được áp dụng, và nội dung hình ảnh được đưa vào mô hình ngôn ngữ dưới dạng chú thích ngắn và hộp giới hạn của một số đối tượng. Tuy nhiên, quá trình dịch hình ảnh-thành-văn bản không tránh khỏi mất một lượng thông tin lớn, làm cho quá trình đánh giá có thể không chính xác và thiên vị.

Dựa trên việc phát hành gần đây của một MLLM mạnh mẽ, GPT-4V, chúng tôi đề xuất đánh giá thông qua một cách tiếp cận trực tiếp hơn. Như được hiển thị trong Hình 4, GPT-4V có thể trực tiếp nhận phản hồi gốc, các phản hồi được điều chỉnh, và quan trọng nhất, hình ảnh đầu vào. Trong trường hợp như vậy, chúng tôi có thể nhắc GPT-4V để nó đưa ra kết quả đánh giá và lý do cho phán đoán. Tuy nhiên, nó vừa mới mở giao diện web chỉ hỗ trợ tương tác đa phương thức thông qua thao tác thủ công, và có giới hạn nghiêm ngặt về số lần sử dụng. Điều này làm cho việc đánh giá dựa trên GPT-4V tốn nhiều lao động, và chúng tôi chỉ có thể kiểm tra một số lượng hạn chế các hình ảnh, chẳng hạn như LLaV A-QA90. Để đáp ứng nhu cầu của chúng tôi, chúng tôi thiết kế hai chỉ số sau:

• Độ chính xác: phản hồi có chính xác đối với nội dung hình ảnh hay không.
• Độ chi tiết: phản hồi có phong phú về chi tiết hay không.

Điểm số của hai chỉ số được hiển thị trong Bảng 3, từ đó chúng ta có thể thấy rằng phương pháp của chúng tôi đạt được những cải thiện nhất quán so với các MLLM baseline. Một mặt, cải thiện về độ chính xác cho thấy rằng Woodpecker của chúng tôi có thể điều chỉnh hiệu quả ảo giác trong các phản hồi MLLM. Mặt khác, thông tin hộp giới hạn được giới thiệu trong khung công tác của chúng tôi thêm chi tiết cho phản hồi, đóng góp vào sự cải thiện về độ chi tiết.

### 4.3. Phân tích thí nghiệm

Phân tích các module khung công tác. Để hiểu vai trò của các module khác nhau và sự kết hợp của chúng, chúng tôi đi sâu vào chúng và sự kết hợp của chúng. Với mục đích tránh sao nhãng từ sự biến đổi của các MLLM, chúng tôi công thức hóa một bàn kiểm tra đơn giản bằng cách tạo ra một mô hình "mặc định" luôn trả lời "Có". Sau đó, các câu trả lời và câu hỏi được hợp nhất thành các tuyên bố cụ thể hơn. Ví dụ, cho trước một câu hỏi, "Có tàu hỏa nào trong hình ảnh không? Vui lòng trả lời có hoặc không.", chúng tôi soạn một câu trả lời của mô hình mặc định như "Có, có một tàu hỏa trong hình ảnh.". Hơn nữa, chúng tôi tạo ra hai biến thể bổ sung của khung công tác, một trong số đó chỉ bao gồm bộ phát hiện tập mở và cái khác chỉ với mô hình VQA, tương ứng được gọi là "mặc định w/Detector" và "mặc định w/VQA":

• mặc định w/Detector. Biến thể này được thiết kế để thăm dò đóng góp của bộ phát hiện trong việc giảm thiểu ảo giác cấp đối tượng, cụ thể hơn, các khía cạnh tồn tại và đếm của ảo giác.
• mặc định w/VQA. Bằng cách thiết kế biến thể này, chúng tôi nhằm nghiên cứu hiệu quả của mô hình VQA được chọn trong việc cung cấp thông tin thuộc tính.

Cái trước được triển khai bằng cách chỉ cung cấp thông tin cấp đối tượng trong cơ sở kiến thức, trong khi cái sau được thực hiện bằng cách cung cấp thông tin cấp thuộc tính. Chúng tôi so sánh hai biến thể này với khung công tác đầy đủ được đề xuất của chúng tôi, tức là "mặc định Woodpecker", sử dụng cả hai loại thông tin.

Như được hiển thị trong Hình 5, những cải thiện về các phần tồn tại và đếm chủ yếu xuất phát từ việc giới thiệu bộ phát hiện tập mở, và cải thiện trong phần màu sắc có thể được quy cho việc áp dụng mô hình VQA. Điều này phù hợp với kỳ vọng vì chúng tôi thu thập thông tin đếm bằng phương tiện của bộ phát hiện và thu thập thông tin về các thuộc tính cụ thể, tức là vị trí và màu sắc, thông qua mô hình VQA. Do đó, mô hình đầy đủ kết hợp ưu điểm của cả hai module và đạt được kết quả tốt nhất.

Để đưa ra một sự hiểu biết trực quan về kết quả của điều chỉnh và đánh giá GPT-4V-aid, chúng tôi cung cấp một trường hợp trong Phụ lục B. Cụ thể, chúng tôi liệt kê truy vấn và phản hồi MLLM trước và sau điều chỉnh. Để tham khảo, điểm số và lý do được đưa ra bởi GPT-4V cũng được liệt kê.

Phân tích hiệu suất điều chỉnh. Trong phần này, chúng tôi nhằm thăm dò sâu hơn hiệu suất của điều chỉnh. Vì thiếu các công trình liên quan trong việc đo lường hành vi điều chỉnh, chúng tôi thực hiện mục tiêu này bằng cách chia nhỏ kết quả sau điều chỉnh thành ba phần:

• Độ chính xác: |câu trả lời đúng được giữ và câu trả lời sai được điều chỉnh|/|vấn đề|.
• Thiếu sót: |phản hồi sai không được điều chỉnh|/|vấn đề|.
• Điều chỉnh sai: |phản hồi đúng bị chỉnh sửa nhầm|/|vấn đề|.

Cụ thể, chúng tôi tóm tắt kết quả của mô hình "mặc định" trên MME và tính toán ba chỉ số được giới thiệu. Như được phản ánh trong Hình 6, phương pháp điều chỉnh của chúng tôi đạt được độ chính xác 79.2%, và đồng thời, tỷ lệ thiếu sót và điều chỉnh sai vẫn ở mức tương đối thấp. Kết quả cho thấy rằng phương pháp của chúng tôi có thể bao phủ hầu hết các trường hợp mà không quá tự tin.

## 5. Kết luận

Trong công trình này, chúng tôi đã đề xuất khung công tác dựa trên điều chỉnh đầu tiên để giảm thiểu ảo giác trong MLLM. Như một phương pháp không cần đào tạo, cách tiếp cận của chúng tôi kết hợp nhiều mô hình có sẵn và có thể dễ dàng tích hợp vào các MLLM khác nhau. Để đánh giá hiệu quả của khung công tác được đề xuất, chúng tôi tiến hành các thí nghiệm quy mô lớn trên ba benchmark dưới các thiết lập khác nhau, bao gồm sử dụng GPT-4V cho đánh giá trực tiếp và tự động. Chúng tôi hy vọng công trình này có thể khơi dậy những suy nghĩ mới về việc giải quyết vấn đề ảo giác trong MLLM.

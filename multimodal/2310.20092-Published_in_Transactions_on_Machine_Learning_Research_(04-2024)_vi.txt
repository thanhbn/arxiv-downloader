# 2310.20092.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2310.20092.pdf
# Kích thước tệp: 2837342 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)
U Còn Thiếu cho Các Mô Hình Khuếch Tán Hiệu Quả
Sergio Calvo-Ordoñez1,2, Chun-Wun Cheng3, Jiahao Huang4, Lipei Zhang3, Guang Yang4,5,6,
Carola-Bibiane Schönlieb3, Angelica I Aviles-Rivero3
1Oxford-Man Institute of Quantitative Finance, University of Oxford
2Mathematical Institute, University of Oxford
3Department of Applied Mathematics and Theoretical Physics, University of Cambridge
4Bioengineering Department and Imperial-X & National Heart and Lung Institute, Imperial College London
5Cardiovascular Research Centre, Royal Brompton Hospital London
6School of Biomedical Engineering & Imaging Sciences, King's College London
Được đánh giá trên OpenReview: https://openreview.net/forum?id=Y4YWzBiTEV
Tóm tắt
Các Mô Hình Xác Suất Khuếch Tán đóng vai trò là một công cụ quan trọng trong mô hình hóa sinh tạo, cho phép tạo ra các phân phối dữ liệu phức tạp. Họ mô hình sinh tạo này mang lại hiệu suất phá vỡ kỷ lục trong các tác vụ như tổng hợp hình ảnh, tạo video và thiết kế phân tử. Mặc dù có khả năng, hiệu quả của chúng, đặc biệt là trong quá trình ngược, vẫn là một thách thức do tốc độ hội tụ chậm và chi phí tính toán cao. Trong bài báo này, chúng tôi giới thiệu một phương pháp tận dụng các hệ thống động học liên tục để thiết kế một mạng khử nhiễu mới cho các mô hình khuếch tán có hiệu quả tham số cao hơn, thể hiện sự hội tụ nhanh hơn và cho thấy độ bền vững với nhiễu tăng lên. Thử nghiệm với Các Mô Hình Xác Suất Khuếch Tán Khử Nhiễu (DDPM), khung của chúng tôi hoạt động với khoảng một phần tư tham số và ~30% Phép Toán Dấu Phẩy Động (FLOP) so với U-Net chuẩn trong DDPM. Hơn nữa, mô hình của chúng tôi nhanh hơn đáng kể trong suy luận so với đường cơ sở khi được đo trong điều kiện công bằng và bình đẳng. Chúng tôi cũng cung cấp một trực giác toán học về lý do tại sao quá trình ngược được đề xuất của chúng tôi nhanh hơn cũng như một cuộc thảo luận toán học về các đánh đổi thực nghiệm trong tác vụ khử nhiễu hạ nguồn. Cuối cùng, chúng tôi lập luận rằng phương pháp của chúng tôi tương thích với các kỹ thuật nâng cao hiệu suất hiện có, cho phép cải thiện thêm về hiệu quả, chất lượng và tốc độ.

1 Giới thiệu
Các Mô Hình Xác Suất Khuếch Tán, có nền tảng trong công trình của (Sohl-Dickstein et al., 2015) và được mở rộng bởi (Song & Ermon 2020; Ho et al. 2020; Song et al. 2020b), đã đạt được kết quả đáng chú ý trong nhiều lĩnh vực khác nhau, bao gồm tạo hình ảnh (Dhariwal & Nichol, 2021; Nichol & Dhariwal, 2021; Ramesh et al., 2022; Saharia et al., 2022; Rombach et al., 2022b), tổng hợp âm thanh (Kong et al., 2021; Liu et al., 2022a), và tạo video (Ho et al., 2022; Ho et al., 2021). Những mô hình sinh tạo dựa trên điểm số này sử dụng một cơ chế lấy mẫu lặp để tiến hành khử nhiễu các vector ban đầu ngẫu nhiên, đưa ra một sự đánh đổi có thể kiểm soát giữa chi phí tính toán và chất lượng mẫu. Mặc dù quá trình lặp này cung cấp một phương pháp để cân bằng chất lượng với chi phí tính toán, nó thường nghiêng về phía sau cho các kết quả tiên tiến nhất. Việc tạo ra các mẫu hàng đầu thường đòi hỏi một số lượng lớn các lần lặp, với các mô hình khuếch tán yêu cầu tới 2000 lần sức mạnh tính toán hơn so với các mô hình sinh tạo khác (Goodfellow et al., 2020; Kingma & Welling, 2013; Rezende et al., 2014; Rezende & Mohamed, 2015; Kingma & Dhariwal, 2018).

Nghiên cứu gần đây đã đi sâu vào các chiến lược để nâng cao hiệu quả và tốc độ của quá trình ngược này. Trong Các Mô Hình Xác Suất Khuếch Tán Khử Nhiễu Dừng Sớm (ES-DDPM) được đề xuất bởi (Lyu et al., 2022), quá trình khuếch tán được dừng sớm. Thay vì khuếch tán phân phối dữ liệu thành một phân phối Gaussian qua hàng trăm bước lặp, ES-DDPM chỉ xem xét một vài bước khuếch tán ban đầu để quá trình khử nhiễu ngược bắt đầu từ một phân phối không phải Gaussian. Một phương pháp tương tự được sử dụng trong (Zheng et al., 2023b), cũng cắt bớt quá trình tiến để cho phép ít bước ngược hơn để tạo ra dữ liệu. Ngoài ra (Xiao et al., 2022) giảm chi phí quy trình lấy mẫu bằng cách mô hình hóa phân phối khử nhiễu sử dụng một phân phối đa phương thức phức tạp với một mạng sinh tạo đối kháng khuếch tán khử nhiễu cho mỗi bước. (Lu et al., 2022) đề xuất một công thức chính xác của nghiệm của các ODE khuếch tán, cho phép lấy mẫu trong một vài bước. Tiếp tục với các phương pháp lấy mẫu nhanh hơn, (Zhang & Chen, 2023) trình bày Bộ Lấy Mẫu Tích Phân Hàm Mũ Khuếch Tán tận dụng cấu trúc bán tuyến tính của quá trình khuếch tán đã học để giảm lỗi rời rạc hóa và hiệu quả hơn. Một đóng góp quan trọng khác là khung Analytic-DPM (Bao et al., 2022). Khung suy luận không cần đào tạo này ước tính các dạng phân tích của phương sai và phân kỳ Kullback-Leibler sử dụng các phương pháp Monte Carlo kết hợp với mô hình dựa trên điểm số được đào tạo trước. Kết quả cho thấy khả năng log-likelihood được cải thiện và tăng tốc từ 20x đến 80x. Hơn nữa, các phương pháp nghiên cứu sử dụng các ràng buộc đa tạp và giả thuyết bài toán nghịch đảo cho các mô hình khuếch tán (Chung et al. 2022; Liu et al. 2022b; Chung et al. 2023; Rout et al. 2023; Lou & Ermon 2023) đạt được một sự gia tăng hiệu suất đáng kể. Các dòng công việc khác tập trung vào việc sửa đổi quá trình lấy mẫu trong quá trình suy luận trong khi giữ mô hình không thay đổi.

(Song et al., 2020a) đề xuất Các Mô Hình Khuếch Tán Khử Nhiễu Ẩn (DDIM) trong đó chuỗi Markov ngược được thay đổi để thực hiện các bước nhảy xác định được tạo thành từ nhiều bước chuẩn. Điều này làm giảm các bước cần thiết nhưng có thể gây ra sự khác biệt từ quá trình khuếch tán ban đầu. (Nichol & Dhariwal, 2021) đề xuất việc tái phân bố thời gian để lựa chọn các bước thời gian không đều trong quá trình ngược. Trong khi giảm tổng số bước, có thể gây ra sự lệch khỏi phân phối đào tạo của mô hình. Nói chung, những phương pháp này cung cấp cải thiện thời gian suy luận nhưng không tăng tốc đào tạo mô hình.

Một phương pháp khác nhau đào tạo các mô hình khuếch tán với các bước thời gian liên tục và mức nhiễu để cho phép số lượng bước ngược khác nhau sau khi đào tạo (Song & Ermon, 2020). Các mô hình được đào tạo trực tiếp trên các mục tiêu liên tục vượt trội hơn các mô hình được đào tạo rời rạc trên dữ liệu liên tục nơi hàm điểm được định nghĩa đúng cách (Song et al. 2020b; Karras et al. 2022). (Kong et al., 2021) xấp xỉ các mức nhiễu liên tục thông qua nội suy của các bước thời gian rời rạc, nhưng thiếu nền tảng lý thuyết. Các chiến lược trực giao tăng tốc các mô hình khuếch tán bằng cách kết hợp thông tin có điều kiện. (Preechakul et al., 2022a) tiêm một vector bộ mã hóa để hướng dẫn quá trình ngược. Trong khi hiệu quả cho các tác vụ có điều kiện, nó cung cấp cải thiện hạn chế cho tạo không có điều kiện. (Salimans & Ho, 2022) chưng cất một mô hình giáo viên thành các học sinh thực hiện ít bước hơn liên tiếp, giảm bước mà không cần đào tạo lại, nhưng chi phí chưng cất tăng theo các bước của giáo viên. Không giống như công việc hiện có, chúng tôi nhấn mạnh rằng phương pháp của chúng tôi khác biệt bằng cách tham số hóa động học qua một ODE bậc hai mô hình hóa cụ thể gia tốc trong quá trình ngược.

Để giải quyết những vấn đề này, trong suốt bài báo này, chúng tôi xây dựng và đánh giá một phương pháp tái tư duy quá trình ngược trong các mô hình khuếch tán bằng cách thay đổi cơ bản kiến trúc mạng khử nhiễu. Tài liệu hiện tại chủ yếu sử dụng các kiến trúc U-Net cho việc khử nhiễu rời rạc của các đầu vào bị khuếch tán qua một số bước được chỉ định. Nhiều hạn chế của quá trình ngược xuất phát trực tiếp từ các ràng buộc vốn có của mạng khử nhiễu được chọn. Dựa trên công trình của (Cheng et al., 2023), chúng tôi tận dụng các hệ thống động học liên tục để thiết kế một mạng khử nhiễu mới có hiệu quả tham số, thể hiện sự hội tụ nhanh hơn và tốt hơn, cho thấy độ bền vững chống lại nhiễu, và vượt trội hơn các U-Net thông thường trong khi cung cấp nền tảng lý thuyết. Chúng tôi cho thấy rằng sự thay đổi kiến trúc của chúng tôi trực tiếp nâng cao quá trình ngược của các mô hình khuếch tán bằng cách cung cấp hiệu suất tương đương trong tổng hợp hình ảnh nhưng cải thiện thời gian suy luận trong quá trình ngược, hiệu suất khử nhiễu và hiệu quả hoạt động. Quan trọng, phương pháp của chúng tôi trực giao với các kỹ thuật nâng cao hiệu suất hiện có, cho phép tích hợp chúng để cải thiện thêm. Hơn nữa, chúng tôi đi sâu vào một cuộc thảo luận toán học để cung cấp trực giác cơ bản về lý do tại sao việc sử dụng các lớp ẩn sâu của chúng tôi trong một mạng khử nhiễu được sử dụng lặp đi lặp lại trong quá trình ngược là một lựa chọn thiết kế hợp lý.

Theo cùng một hướng, chúng tôi nghiên cứu thực nghiệm hiệu suất của mạng chúng tôi trong việc khử nhiễu tuần tự và biện minh lý thuyết cho các đánh đổi được quan sát trong kết quả. Bên cạnh khả năng tương thích của khung chúng tôi với các họ mô hình khuếch tán khác (như đã thảo luận trong Phần 3), phương pháp này có thể được tận dụng cho các tác vụ hạ nguồn trong các lĩnh vực khác, ví dụ, và không giới hạn ở, tái tạo MRI, tạo âm thanh, phân đoạn hình ảnh, hoặc tạo dữ liệu tổng hợp. Đặc biệt, các đóng góp của chúng tôi là:

Chúng tôi đề xuất một mạng khử nhiễu mới kết hợp một khối Neural ODE động nguyên gốc tích hợp các kết nối dư và nhúng thời gian cho khả năng thích ứng thời gian cần thiết bởi các mô hình khuếch tán.

--- TRANG 2 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Chúng tôi phát triển một họ mô hình khuếch tán mới sử dụng một mạng khử nhiễu U-Net ẩn sâu; như một sự thay thế cho U-Net rời rạc chuẩn và đạt được hiệu quả tăng cường.

Chúng tôi đánh giá khung của chúng tôi, thể hiện hiệu suất cạnh tranh trong tổng hợp hình ảnh, và vượt trội về mặt tri giác so với đường cơ sở trong khử nhiễu với khoảng 4 lần ít tham số hơn, dấu chân bộ nhớ nhỏ hơn và thời gian suy luận ngắn hơn.

2 Kiến thức cơ bản
Phần này cung cấp một bản tóm tắt các ý tưởng lý thuyết của phương pháp chúng tôi, kết hợp các điểm mạnh của các hệ thống động học liên tục, kiến trúc U-Net liên tục, và các mô hình khuếch tán.

Các Mô Hình Xác Suất Khuếch Tán Khử Nhiễu (DDPM). Những mô hình này mở rộng khung của DPM thông qua việc bao gồm một cơ chế khử nhiễu (Ho et al., 2020). Cơ chế sau được sử dụng một cơ chế nghịch đảo để tái tạo dữ liệu từ một không gian nhiễu ẩn đạt được thông qua một quá trình ngẫu nhiên (khuếch tán ngược). Mối quan hệ này xuất hiện từ (Song et al., 2020b), chỉ ra rằng một tham số hóa nhất định của các mô hình khuếch tán tiết lộ một sự tương đương với khớp điểm khử nhiễu trên nhiều mức nhiễu trong quá trình đào tạo và với động học Langevin được ủ trong quá trình lấy mẫu. DDPM có thể được coi là các mô hình tương tự với VAE phân cấp (Cheng et al., 2020), với sự khác biệt chính là tất cả các trạng thái ẩn, xt cho t = [1,T], có cùng chiều với đầu vào x0. Chi tiết này cũng làm cho chúng tương tự như các luồng chuẩn hóa (Rezende & Mohamed, 2015), tuy nhiên, các mô hình khuếch tán có các lớp ẩn ngẫu nhiên và không cần sử dụng các biến đổi nghịch đảo.

Neural ODE. Các Phương Trình Vi Phân Neural (NDE) cung cấp một phương pháp thời gian liên tục để mô hình hóa dữ liệu (Chen et al., 2018). Chúng độc đáo trong khả năng mô hình hóa các hệ thống phức tạp theo thời gian trong khi xử lý hiệu quả bộ nhớ và tính toán (Rubanova et al., 2019). Một Phương Trình Vi Phân Thường Neural là một NDE cụ thể được mô tả như:

y(0) = y0, dy/dt(t) = fθ(t,y(t)), (1)

trong đó y0 ∈ Rd1×···×dk tham chiếu đến một tensor đầu vào với bất kỳ chiều nào, θ biểu tượng cho một vector tham số đã học, và fθ:R×Rd1×···×dk→Rd1×···×dk là một hàm mạng neural. Thông thường, fθ được tham số hóa bởi các kiến trúc neural đơn giản, bao gồm mạng truyền thẳng hoặc tích chập. Việc lựa chọn kiến trúc phụ thuộc vào bản chất của dữ liệu và phụ thuộc vào các phương pháp đào tạo hiệu quả, chẳng hạn như phương pháp nhạy cảm kết hợp cho lan truyền ngược thông qua bộ giải ODE.

U-Net Liên Tục. (Cheng et al., 2023) đề xuất một mạng hình U mới cho phân đoạn hình ảnh y tế được thúc đẩy bởi các công trình trong học sâu ẩn và các phương pháp liên tục dựa trên neural ODE (Chen et al., 2018; Dupont et al., 2019). Kiến trúc mới này bao gồm một mạng sâu liên tục có động học được mô hình hóa bởi các phương trình vi phân thường bậc hai. Ý tưởng là biến đổi động học trong mạng - trước đây là các khối CNN - thành các khối động để có được một nghiệm. Tính liên tục này đi kèm với những lợi ích mạnh mẽ và có nền tảng toán học. Thứ nhất, bằng cách mô hình hóa động học trong một chiều cao hơn, có nhiều tính linh hoạt hơn trong việc học các quỹ đạo. Do đó, U-Net liên tục yêu cầu ít lần lặp hơn cho nghiệm, hiệu quả hơn về mặt tính toán và đặc biệt cung cấp chi phí bộ nhớ không đổi. Thứ hai, có thể chỉ ra rằng U-Net liên tục bền vững hơn các biến thể khác (CNN), và (Cheng et al., 2023) cung cấp một trực giác cho điều này. Cuối cùng, vì U-Net liên tục luôn bị giới hạn bởi một phạm vi nào đó, không giống như CNN, mạng tốt hơn trong việc xử lý nhiễu vốn có trong dữ liệu.

3 Công trình liên quan
Một lượng đáng kể nghiên cứu tập trung vào việc tăng tốc các mô hình khuếch tán. Trong phần này, chúng tôi cung cấp một tổng quan về những chiến lược này và chi tiết cách phương pháp của chúng tôi đóng góp khác biệt để cải thiện hiệu quả của mô hình khuếch tán. Chúng tôi cũng lập luận về tính trực giao của phương pháp chúng tôi bằng cách phác thảo các cách tiềm năng để kết hợp khung của chúng tôi vào các công trình hiện có, nhấn mạnh tính tương thích và tác động cộng thêm của nó đối với lĩnh vực.

--- TRANG 3 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Công trình được giới thiệu bởi (Wang et al., 2022), giới thiệu một mô hình khuếch tán hiệu quả được thiết kế riêng để tạo ra các kết cấu và hoa văn đa dạng từ một hình ảnh duy nhất, tận dụng một phương pháp độc đáo để học phân phối của các bản vá hình ảnh, cho phép tổng hợp chất lượng cao với dữ liệu tối thiểu. Patch Diffusion (Wang et al., 2023), giới thiệu một phương pháp đào tạo mới cho các mô hình khuếch tán, giảm đáng kể thời gian đào tạo và nâng cao hiệu quả dữ liệu bằng cách học các hàm điểm có điều kiện trên các bản vá hình ảnh có kích thước và vị trí khác nhau. (Zheng et al., 2023a) xem xét việc tăng tốc các mô hình khuếch tán thông qua một kỹ thuật lấy mẫu mới sử dụng các toán tử neural để giải ODE luồng xác suất. (Arakawa et al., 2023) trình bày một đề xuất sử dụng một mô hình xác suất khuếch tán dựa trên bản vá chia các hình ảnh thành các bản vá và tạo ra chúng một cách độc lập để giảm tiêu thụ bộ nhớ trong quá trình suy luận. Mỗi phương pháp này đưa ra những hiệu quả độc đáo trong khung mô hình khuếch tán, nhưng tất cả đều sử dụng kiến trúc U-Net cho quá trình khử nhiễu, do đó cung cấp lợi ích độc lập với lựa chọn mạng khử nhiễu. Điều này cho thấy rằng có chỗ cho cải thiện thông qua việc triển khai phương pháp của chúng tôi để tiếp tục tăng hiệu quả và giảm yêu cầu bộ nhớ trong khi duy trì chất lượng hình ảnh.

(Gao et al., 2023) và (Zheng et al., 2023c) trình bày các phương pháp mới để nâng cao các mô hình khuếch tán, với phương pháp trước giới thiệu một sơ đồ mô hình ẩn mặt nạ để cải thiện tốc độ học và phương pháp sau tập trung vào tích hợp các tính năng cục bộ và nội dung toàn cục để đạt được hiệu quả. Mặc dù có những tiến bộ, (Gao et al., 2023) báo cáo không có sự gia tăng hiệu quả bộ nhớ, và phương pháp trong (Zheng et al., 2023c) chưa được thử nghiệm rộng rãi trên tất cả các ứng dụng mô hình khuếch tán, trong một số trường hợp dẫn đến đầu ra chất lượng thấp hơn.

Hơn nữa, có một nhánh tài liệu khám phá việc áp dụng những lợi ích hiệu quả của autoencoders biến phân (VAE) vào các mô hình khuếch tán. (Preechakul et al., 2022b) trình bày một phương pháp kết hợp một bộ mã hóa có thể học để nắm bắt ngữ nghĩa cấp cao với một mô hình xác suất khuếch tán (DPM) làm bộ giải mã để mô hình hóa các biến thể ngẫu nhiên, cho thấy hiệu quả và chất lượng tạo cải thiện so với DDIM. Tuy nhiên, hiệu suất của nó so với các phương pháp mới hơn và khả năng tương thích của nó với các kỹ thuật tăng tốc khác vẫn chưa rõ ràng, vì quá trình khuếch tán là thứ yếu so với mã hóa. (Pandey et al., 2022) trình bày một khung tích hợp khả năng hoạt động trong một không gian ẩn chiều thấp thông qua VAE trong khi vẫn mô hình hóa một quá trình ngẫu nhiên với các cơ chế khuếch tán. Tương tự, (Rombach et al., 2022a), áp dụng các mô hình khuếch tán trong không gian ẩn của các autoencoders mạnh mẽ được đào tạo trước. Tuy nhiên, điều này bị giới hạn bởi nút thắt cổ chai của autoencoder được đào tạo trước. Trong tất cả những trường hợp này, việc sử dụng kiến trúc U-Net của chúng cho khử nhiễu phù hợp với khung của chúng tôi, cho thấy tiềm năng tích hợp để nâng cao hiệu quả hơn nữa. (Vahdat et al., 2021) đào tạo Các Mô Hình Sinh Tạo Dựa Trên Điểm Số (SGM) trong không gian ẩn để làm cho chúng hiệu quả hơn với việc giảm chiều. Tuy nhiên, mặc dù cải thiện về sự không hiệu quả của các quá trình khuếch tán, nó vẫn chậm đáng kể so với các kỹ thuật tương tự được áp dụng trong các khung thời gian rời rạc.

Cuối cùng, các công trình khác giới thiệu các phương pháp tổng quát để cải thiện các giai đoạn khác nhau của các mô hình khuếch tán. Karras et al. (2022) đề xuất một phân tích giúp đơn giản hóa các giai đoạn của các mô hình khuếch tán sử dụng mạng neural (ví dụ U-Net) để mô hình hóa điểm số của một phân phối biên phụ thuộc mức nhiễu của dữ liệu đào tạo bị hỏng bởi nhiễu. Dockhorn et al. (2022) giới thiệu khuếch tán Langevin giảm chấn tới hạn đơn giản hóa quá trình khớp điểm bằng cách chỉ cần học hàm điểm của phân phối có điều kiện của một tập con các biến. Cuối cùng, (Pandey & Mandt, 2023) giới thiệu một khái niệm tương tự, Khuếch Tán Langevin Không Gian Pha (PSLD). SGM mới này nâng cao chất lượng mẫu và tối ưu hóa sự đánh đổi tốc độ-chất lượng bằng cách thực hiện khuếch tán trong một không gian mở rộng với các biến phụ trợ. Tuy nhiên, kỹ thuật này chỉ áp dụng được trong các khung sử dụng quan điểm hoàn toàn liên tục của các quá trình tiến và ngược.

Dưới đây, chúng tôi mô tả phương pháp của chúng tôi và nơi mỗi khái niệm trước đây đóng một vai trò quan trọng trong kiến trúc mô hình được đề xuất của chúng tôi.

4 Phương pháp
Trong các DDPM chuẩn, quá trình ngược bao gồm việc tái tạo dữ liệu gốc từ các quan sát nhiễu thông qua một loạt các bước rời rạc sử dụng các biến thể của kiến trúc U-Net. Ngược lại, phương pháp của chúng tôi (Hình 1) sử dụng một kiến trúc U-Net liên tục để mô hình hóa quá trình ngược trong một cài đặt thời gian liên tục cục bộ1.

1Cài đặt thời gian liên tục cục bộ biểu thị một phương pháp lai trong đó đào tạo chính sử dụng một khung rời rạc hóa, nhưng mỗi bước bao gồm mô hình hóa thời gian liên tục của biểu diễn ẩn của hình ảnh, được điều khiển bởi một phương trình vi phân thường neural.

--- TRANG 4 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Hình 1: Biểu diễn trực quan của khung chúng tôi có các lớp ẩn sâu được thiết kế riêng cho khử nhiễu trong quá trình ngược của một DDPM, cho phép tái tạo dữ liệu gốc từ một phiên bản bị hỏng bởi nhiễu.

Không giống như công trình trước đây về U-Net liên tục, tập trung vào phân đoạn (Cheng et al., 2023), chúng tôi thích ứng kiến trúc để thực hiện khử nhiễu trong quá trình ngược của DDPM, đánh dấu việc giới thiệu mạng khử nhiễu dựa trên U-Net liên tục đầu tiên. Những thay đổi của chúng tôi bao gồm:

Thích Ứng Mô Hình cho Khử Nhiễu: Chúng tôi đã cấu hình lại kiến trúc để phù hợp hơn với các tác vụ khử nhiễu. Điều này bao gồm điều chỉnh trong các kênh đầu ra, chuyển đổi từ mất mát entropy chéo phân loại sang mất mát dựa trên tái tạo để giảm thiểu sự khác biệt pixel, và sửa đổi bước để bảo toàn độ phân giải không gian.

Tích Hợp Động Học Thời Gian: Nhúng thời gian đã được giới thiệu, theo phương pháp của (Ho et al., 2020), để mô hình hóa chính xác và thích ứng với quá trình khuếch tán qua thời gian, nâng cao khả năng của mô hình để điều chỉnh động với các giai đoạn khuếch tán khác nhau.

Đổi Mới Kiến Trúc: U-Net liên tục của chúng tôi hiện kết hợp các cơ chế chú ý và kết nối dư, nhằm nắm bắt các phụ thuộc tầm xa và cải thiện khả năng quản lý nhiễu, đánh dấu một sự khởi hành từ các thiết kế truyền thống hướng tới một kiến trúc năng động và hiệu quả hơn.

Nhìn chung, kiến trúc của chúng tôi được căn cứ chiến lược vào khả năng giảm đáng kể chi phí tính toán mà không tăng nó. Việc giảm này đạt được thông qua nhu cầu giảm để lưu trữ các hàm hoạt động và tận dụng phương pháp nhạy cảm kết hợp, đảm bảo chi phí bộ nhớ O(1) bất kể độ phức tạp của mô hình. Phương pháp này vốn dĩ xây dựng khả năng đảo ngược vào kiến trúc, đảm bảo sử dụng bộ nhớ hiệu quả và giảm đáng kể thời gian tính toán.

4.1 Khối Động cho Khuếch Tán
Các khối động học của chúng tôi dựa trên ODE bậc hai, do đó, chúng tôi sử dụng một khối vận tốc ban đầu xác định các điều kiện ban đầu cho mô hình của chúng tôi. Chúng tôi tận dụng chuẩn hóa thể hiện, và bao gồm các phép toán tích chập tuần tự để xử lý dữ liệu đầu vào và nắm bắt các tính năng không gian chi tiết. Tích chập đầu tiên chuyển đổi dữ liệu đầu vào thành một biểu diễn trung gian, sau đó, các tích chập tiếp theo tinh chỉnh và mở rộng các kênh tính năng, đảm bảo một biểu diễn toàn diện của đầu vào. Giữa các phép toán này, chúng tôi bao gồm các lớp kích hoạt ReLU để cho phép mô hình hóa các mối quan hệ phi tuyến như một thực hành chuẩn do hiệu suất của nó (Agarap, 2019).

Hơn nữa, thiết kế của chúng tôi kết hợp một khối xấp xỉ hàm mạng neural (Hình 2 - phải), biểu diễn đạo hàm trong dạng ODE dz/dt = f(t,z) điều khiển cách trạng thái ẩn z phát triển qua biến thời gian liên tục t. Các lớp chuẩn hóa nhóm được sử dụng để chia tỷ lệ tính năng, theo sau bởi các phép toán tích chập để trích xuất tính năng không gian. Để thích ứng với các mô hình khuếch tán, chúng tôi tích hợp nhúng thời gian sử dụng các perceptron đa lớp điều chỉnh các đầu ra tích chập qua chia tỷ lệ và dịch chuyển và được bổ sung bởi các kết nối dư tùy chỉnh của chúng tôi. Ngoài ra, chúng tôi sử dụng một khối ODE (Hình 2 - trái) nắm bắt động học thời gian liên tục, trong đó đường đi tiến hóa của dữ liệu được định nghĩa bởi một hàm ODE và điều kiện ban đầu được suy ra từ các khối trước đó.

Đầu vào (v,z)
Chuẩn hóa Nhóm
Lớp Conv.
Softplus
Chuẩn hóa Nhóm
Time_emb
(MLP)
Chia tỷ lệ & Dịch chuyển
Lớp Conv.
Softplus
Kết nối Dư
Đầu ra
Xấp xỉ hàm ODE
Khối ODE Dựa Trên Động Học
Đầu vào
Xấp xỉ Hàm ODE
Bộ Giải ODE
Đầu ra
Phương pháp Giải, Thời gian Tích phân

Hình 2: Các thành phần kiến trúc của U-Net liên tục. Ở bên trái, Khối ODE Động biểu diễn đơn vị cốt lõi của mô hình liên tục của chúng tôi, chi tiết việc tích hợp bộ giải ODE và xấp xỉ hàm trong cấu trúc mạng. Bảng bên phải mở rộng về Xấp Xỉ Hàm ODE, nổi bật các lớp tích chập, chuẩn hóa nhóm, nhúng thời gian, và việc kết hợp các phép toán chia tỷ lệ, dịch chuyển, và kết nối dư để thích ứng chính xác động học của mạng trong quá trình khuếch tán.

4.2 Một 'U' Mới cho Các Mô Hình Khuếch Tán
Khi chúng tôi sửa đổi cơ bản mạng khử nhiễu được sử dụng trong quá trình ngược, việc xem xét cách công thức toán học của quá trình ngược của DDPM thay đổi là có liên quan. Mục tiêu là xấp xỉ xác suất chuyển đổi sử dụng mô hình của chúng tôi. Ký hiệu đầu ra của U-Net liên tục của chúng tôi là ˜U(xt,t,˜t; Ψ), trong đó xt là đầu vào, t là biến thời gian liên quan đến DDPM, ˜t là biến thời gian liên quan đến neural ODE và Ψ biểu diễn các tham số của mạng bao gồm θf từ các khối động được xây dựng vào kiến trúc.

Chúng tôi sử dụng U-Net liên tục mới trong khi giữ cùng một quá trình lấy mẫu (Ho et al., 2020) đọc
xt−1 = 1/√αt (xt − √βt/√(1−¯αt) ϵθ(xt,t)) + σtz, trong đó z∼N(0,I) (2)

Trái ngược với các mô hình U-Net rời rạc truyền thống, tái công thức này cho phép mô hình hóa xác suất chuyển đổi sử dụng động học thời gian liên tục được đóng gói trong kiến trúc của chúng tôi. Đi xa hơn, chúng tôi có thể biểu diễn hàm U-Net liên tục theo các khối động học cho bởi:

ϵθ(xt,t) ≈ ˜U(xt,t,˜t;θ) (3)

trong đó,
{
x′′˜t = f(a)(x˜t,x′˜t,t,˜t,θf)
x˜t0 = X0, x′˜t0 = g(x˜t0,θg)
} (4)

Ở đây, x′′t biểu diễn đạo hàm bậc hai của trạng thái theo thời gian (gia tốc), f(a)(·,·,·,θf) là mạng neural tham số hóa gia tốc và động học của hệ thống, và xt0 và x′t0 là trạng thái ban đầu và vận tốc. X0 là giá trị ban đầu và g(x˜t0,θg) là mạng neural tham số hóa vận tốc. Sau đó chúng tôi có thể cập nhật phép lặp bằng xt thành xt−1 bởi mạng liên tục.

--- TRANG 5 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

4.3 Giải Mã U Còn Thiếu cho Các Mô Hình Khuếch Tán Nhanh Hơn và Nhẹ Hơn
Kiến trúc của chúng tôi vượt trội hơn DDPM về hiệu quả và độ chính xác (Bảng 1). Phần này cung cấp biện minh toán học cho hiệu suất. Chúng tôi đầu tiên chỉ ra rằng ODE Luồng Xác Suất nhanh hơn phương trình vi phân ngẫu nhiên (SDE). Điều này được chỉ ra khi xem xét rằng SDE có thể được xem như tổng của ODE Luồng Xác Suất và SDE Vi Phân Langevin trong quá trình ngược (Karras et al., 2022). Chúng ta có thể định nghĩa SDE ngược liên tục (Song et al., 2020b) như:

dxt = [f(xt,t) − g(t)²∇xt log pt(xt)]dt + g(t)dwt (5)

Chúng ta cũng có thể định nghĩa ODE luồng xác suất như sau:

dxt = [f(xt,t) − g(t)²∇xt log pt(xt)]dt (6)

Chúng ta có thể tái công thức biểu thức bằng cách đặt f(xt,t) = −½β(t)xt, g(t) = √β(t) và sθb(xt) = ∇x log pt(xt). Thay thế những điều này vào (5) và (6) cho ra hai phương trình sau cho SDE và ODE Luồng Xác Suất, tương ứng.

dxt = −½β(t)[xt + 2sθb(xt)]dt + √β(t)dwt (7)
dxt = −½β(t)[xt + sθb(xt,t)]dt (8)

Chúng ta sau đó có thể thực hiện phép toán sau:

dxt = −½β(t)[xt + 2sθb(xt)]dt + √β(t)dwt
= −½β(t)[xt + sθb(xt)]dt − ½β(t)sθb(xt,t)dt + √β(t)dwt (9)

Biểu thức (9) phân rã SDE thành ODE Luồng Xác Suất và SDE Vi Phân Langevin. Điều này chỉ ra rằng ODE Luồng Xác Suất nhanh hơn, vì rời rạc hóa phương trình Vi Phân Langevin tốn thời gian. Tuy nhiên, chúng tôi suy ra từ sự thật này rằng mặc dù ODE Luồng Xác Suất nhanh hơn, nó ít chính xác hơn SDE. Đây là một lý do chính cho sự quan tâm của chúng tôi đối với neural ODE bậc hai, có thể nâng cao cả tốc độ và độ chính xác. Đặc biệt, ODE Luồng Xác Suất là một dạng neural ODE bậc nhất, sử dụng trạng thái kết hợp trong quá trình lan truyền ngược. Nhưng phương pháp kết hợp trong bối cảnh của ODE Luồng Xác Suất chính xác là gì? Để trả lời điều này, chúng tôi đưa ra mệnh đề sau.

Mệnh đề
Mệnh đề 4.1 Trạng thái kết hợp rt của ODE luồng xác suất tuân theo ODE bậc nhất
r′t = −rᵀt ∂[½β(t)[−xt−sθb(xt,t)]]/∂Xt (10)

Chứng minh. Theo (Norcliffe et al., 2020), chúng tôi ký hiệu hàm mất mát vô hướng là L = L(xtn), và gradient theo tham số θ như dL/dθ = ∂L/∂xtn · dxtn/dθ. Khi đó xtn tuân theo:
{
xtn = ∫ᵗⁿt₀ x′t dt + xt₀
xt₀ = f(X₀,θf), x′t = ½β(t)[−xt−sθb(xt,t)]
} (11)

Đặt K là một biến mới sao cho thỏa mãn tích phân sau:

K = ∫ᵗⁿt₀ x′t dt
= ∫ᵗⁿt₀ (x′t + A(t)[x′t − ½β(t)[−xt−sθb(xt,t)]]) dt + B(xt₀−f) (12)

Sau đó chúng ta có thể lấy đạo hàm của K theo θ

dK/dθ = ∫ᵗⁿt₀ (dx′t/dθ) dt + ∫ᵗⁿt₀ A(t)(dx′t/dθ − ∂[½β(t)[−xt−sθb(xt,t)]]/∂θ − ∂[½β(t)[−xt−sθb(xt,t)]]/∂xᵀt) dt + B(dxt₀/dθ − df/dθ) (13)

Sử dụng tự do lựa chọn A(t) và B, sau đó chúng ta có thể có được trạng thái kết hợp bậc nhất sau.

r′t = −rᵀt ∂[½β(t)[−xt−sθb(xt,t)]]/∂Xt (14)

■

Như quan sát, trạng thái kết hợp của ODE Luồng Xác Suất tuân theo ODE bậc nhất, trong đó gradient được tính toán bằng cách thực hiện tích phân ngược của cả trạng thái kết hợp, r, và trạng thái thực, x, qua thời gian. Phương pháp này không chỉ loại bỏ nhu cầu lưu trữ các giá trị trung gian - do đó sử dụng một lượng bộ nhớ cố định và cung cấp một lợi thế đáng kể so với các phương pháp lan truyền ngược truyền thống - mà còn đặt nền móng cho hiệu quả của mô hình chúng tôi. Bằng cách tái sử dụng phương pháp kết hợp bậc nhất trong khung neural ODE bậc hai của chúng tôi, chúng tôi nâng cao đáng kể hiệu quả tính toán. Lựa chọn chiến lược này có căn cứ trong phát hiện rằng chi phí tính toán của phương pháp kết hợp bậc hai, ở mức tối thiểu, có thể so sánh với phương pháp kết hợp bậc nhất, với phương pháp sau thường yêu cầu ít thời gian tính toán và chi phí hơn. Việc tích hợp ODE luồng xác suất với kiến trúc mô hình của chúng tôi như vậy trực tiếp đóng góp vào cải thiện độ chính xác và tốc độ, tận dụng định lý xấp xỉ phổ quát, khả năng vi phân cao hơn, và tính linh hoạt mở rộng của neural ODE bậc hai cho các biến đổi vượt ra ngoài dịch chuyển đồng phôi trong không gian thực.

Vẫn còn một câu hỏi cuối cùng trong đầu, ODE luồng xác suất là cho toàn bộ mô hình nhưng U-Net liên tục của chúng tôi tối ưu hóa trong mỗi bước. Mối quan hệ giữa phương pháp của chúng tôi và DDPM là gì? Điều này có thể được trả lời bằng một khái niệm từ phương pháp số. Nếu một phương pháp số cho trước có lỗi cục bộ O(h^(k+1)), thì lỗi toàn cục là O(h^k). Điều này chỉ ra rằng bậc của lỗi cục bộ và toàn cục chỉ khác nhau một bậc. Để hiểu rõ hơn hành vi cục bộ của DDPM chúng tôi, chúng tôi nhằm tối ưu hóa chúng ở mỗi bước. Phương pháp này, được tạo thuận lợi bởi U-Net liên tục, cho phép so sánh chi tiết hơn về bậc hội tụ giữa lỗi cục bộ và toàn cục.

5 Kết quả Thực nghiệm
Trong phần này, chúng tôi chi tiết bộ thí nghiệm để xác thực khung được đề xuất của chúng tôi.

5.1 Tổng hợp Hình ảnh
Chúng tôi đánh giá hiệu quả của phương pháp chúng tôi qua chất lượng mẫu được tạo ra (Hình 3). Làm đường cơ sở, chúng tôi sử dụng một DDPM sử dụng cùng U-Net được mô tả trong (Ho et al., 2020). Các mẫu được chọn ngẫu nhiên từ cả DDPM cơ sở và mô hình của chúng tôi, điều chỉnh các bước thời gian lấy mẫu trên các bộ dữ liệu để tạo thành các tập tổng hợp. Bằng cách kiểm tra thước đo FID (khoảng cách Fréchet) như một hàm bước thời gian trên những bộ dữ liệu này, chúng tôi xác định thời gian lấy mẫu tối ưu. Mô hình của chúng tôi đạt được điểm FID tối ưu một cách nhất quán trong ít bước thời gian hơn mô hình dựa trên U-Net (Bảng 1), cho thấy sự hội tụ nhanh hơn bởi phương pháp dựa trên U-Net liên tục của chúng tôi.

Để tính FID, chúng tôi tạo ra hai bộ dữ liệu, mỗi bộ chứa 30,000 mẫu được tạo ra từ mỗi mô hình, theo cùng cách chúng tôi tạo ra các hình ảnh được hiển thị trong các hình trên. Những bộ dữ liệu mới này sau đó được sử dụng trực tiếp để tính toán điểm FID với kích thước batch 512 cho việc trích xuất tính năng. Chúng tôi cũng lưu ý rằng chúng tôi sử dụng lớp 2048 chiều của mạng Inception để trích xuất tính năng vì đây là một lựa chọn phổ biến để nắm bắt các tính năng cấp cao hơn.

--- TRANG 6 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

DDPM (U-Net) DDPM (c U-Net)

Hình 3: Các mẫu được tạo ra được chọn ngẫu nhiên bởi mô hình của chúng tôi (phải) và DDPM dựa trên U-Net cơ sở (trái) được đào tạo trên CelebA và LSUN Church.

MNIST (28×28) CelebA (64×64) LSUN Church (128×128)
Backbone FID↓ Steps↓ Time (s)↓ FID↓ Steps↓ Time (s)↓ FID↓ Steps↓ Time (s)↓
U-Net 3.61 30 3.56 19.75 100 12.48 12.28 100 12.14
U-Net† 3.73 11 1.12 19.54 30 3.08 11.89 40 4.25
cU-Net 2.98 5 0.54 21.44 80 7.36 12.14 90 8.33
cU-Net† 2.55 2 0.18 21.41 15 1.37 11.77 30 2.68

Bảng 1: Các thước đo hiệu suất trên các bộ dữ liệu: điểm FID (được đo mỗi 5 bước cho CelebA và LSUN, và tại mỗi bước cho MNIST), bước thời gian lấy mẫu (Steps), và thời gian tạo trung bình cho cả mô hình U-Net và U-Net liên tục (cU-Net). † chỉ ra rằng mô hình sử dụng bộ lấy mẫu DDIM tại thời gian suy luận thay vì bộ lấy mẫu DDPM truyền thống. Như được hiển thị, các lợi ích hiệu quả được duy trì qua các bộ lấy mẫu khác nhau.

Chúng tôi kiểm tra thời gian suy luận trung bình trên mỗi mẫu qua nhiều bộ dữ liệu khác nhau (Bảng 1). Trong khi cả hai mô hình đều ghi nhận điểm FID tương tự, cU-Net của chúng tôi suy luận nhanh hơn đáng kể, nhanh hơn khoảng 30% đến 80%². Đáng chú ý, khả năng tốc độ và tổng hợp tăng cường này được đạt được với hiệu quả tham số đáng kể như đã thảo luận thêm trong Phần 5.3.

5.2 Khử Nhiễu Hình Ảnh
Khử nhiễu là thiết yếu trong các mô hình khuếch tán để xấp xỉ nghịch đảo của chuỗi Markov được tạo thành bởi quá trình tiến. Nâng cao khử nhiễu cải thiện quá trình ngược của mô hình bằng cách ước tính tốt hơn phân phối có điều kiện của dữ liệu từ các mẫu bị hỏng. Ước tính chính xác hơn có nghĩa là các bước ngược tốt hơn, các biến đổi quan trọng hơn tại mỗi bước, và do đó các mẫu gần với dữ liệu hơn. Một hệ thống khử nhiễu tốt hơn, do đó, cũng có thể tăng tốc quá trình ngược và tiết kiệm nỗ lực tính toán.

Trong các thí nghiệm của chúng tôi, quá trình nhiễu hình ảnh gắn liền với vai trò của mạng khử nhiễu trong quá trình ngược. Những mạng này sử dụng các bước thời gian để xấp xỉ mức nhiễu mong đợi của một hình ảnh đầu vào tại một thời điểm cho trước. Điều này được thực hiện thông qua các nhúng thời gian giúp đánh giá cường độ nhiễu cho các bước thời gian cụ thể. Sau đó, các mức nhiễu chính xác được áp dụng sử dụng quá trình tiến đến một bước thời gian nhất định, với các hình ảnh thu thập nhiều nhiễu hơn theo thời gian. Hình 4 cho thấy quá trình tích tụ nhiễu trong hình ảnh theo thời gian, là trung tâm của chức năng của các mô hình khuếch tán. Bằng cách trực quan hóa nhiễu tại các bước thời gian khác nhau, chúng tôi chứng minh mối tương quan giữa tiến triển bước thời gian và cường độ nhiễu. Điều này không chỉ xác thực giả thuyết tiến triển nhiễu trong quá trình khuếch tán mà còn hiệu quả của các nhúng thời gian của mô hình U-Net liên tục của chúng tôi.

²Lưu ý rằng thời gian suy luận được báo cáo cho cả hai mô hình được đo trên CPU, vì các gói bộ giải ODE Python hiện tại không sử dụng tài nguyên GPU hiệu quả, không giống như mã được tối ưu hóa cao của các lớp tích chập U-Net thông thường.

--- TRANG 7 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Hình 4: Trực quan hóa tích tụ nhiễu trong hình ảnh qua các bước thời gian tăng. Khi các bước thời gian tiến triển, các hình ảnh thể hiện mức nhiễu cao hơn, thể hiện mối tương quan giữa các bước thời gian và cường độ nhiễu. Sự tiến triển nổi bật hiệu quả của các nhúng thời gian trong việc dự đoán cường độ nhiễu tại các giai đoạn cụ thể của quá trình khuếch tán.

Bước Thời Gian Nhiễu Giá Trị SSIM Tốt Nhất Giá Trị LPIPS Tốt Nhất
50 0.88 /0.90 0.025 /0.019
100 0.85/ 0.83 0.044 /0.038
150 0.79/ 0.78 0.063 /0.050
200 0.74/ 0.71 0.079 /0.069
250 0.72/ 0.64 0.104 /0.084
400 0.58/ 0.44 0.184 /0.146
600 0.44/ 0.26 0.316 /0.238
800 0.32/ 0.18 0.419 /0.315

Bảng 2: Hiệu suất khử nhiễu trung bình so sánh giữa U-Net (giá trị bên trái) và cU-Net (giá trị bên phải) cho các mức nhiễu khác nhau trên bộ dữ liệu thử nghiệm. Trong khi U-Net chủ yếu đạt điểm SSIM cao hơn, cU-Net thường vượt trội trong đánh giá LPIPS, cho thấy sự khác biệt trong bản chất của phương pháp khử nhiễu của chúng.

Trong nghiên cứu khử nhiễu của chúng tôi, chúng tôi đánh giá 300 hình ảnh để biết hiệu suất mô hình trung bình qua các mức nhiễu, theo dõi SSIM và LPIPS qua nhiều bước thời gian để đánh giá sự biến dạng và sự khác biệt đầu ra tri giác. Bảng 2 cho thấy các điểm mạnh khác nhau của các mô hình: U-Net thông thường ghi điểm tốt hơn trong SSIM, trong khi các mô hình của chúng tôi hoạt động tốt hơn trong LPIPS. Mặc dù SSIM được coi là một thước đo đo lường chất lượng được cảm nhận, nó đã được quan sát có mối tương quan mạnh với các thước đo đơn giản hơn như PSNR (Horé & Ziou, 2010) do là một thước đo biến dạng. Đáng chú ý, PSNR có xu hướng ưu tiên các mẫu quá mượt, điều này cho thấy rằng điểm SSIM cao có thể không phải lúc nào cũng tương ứng với kết quả hấp dẫn về mặt thị giác mà là một hình ảnh quá mượt. Mối tương quan này nhấn mạnh tầm quan trọng của việc sử dụng các thước đo đa dạng như LPIPS để có cái nhìn toàn diện hơn về hiệu suất khử nhiễu.

Kết quả U-Net nhấn mạnh một vấn đề phổ biến trong khử nhiễu có giám sát. Các mô hình được đào tạo trên các hình ảnh sạch và nhiễu được ghép đôi qua mất mát dựa trên khoảng cách thường tạo ra đầu ra khử nhiễu quá mượt. Điều này là do phương pháp cơ bản đóng khung tác vụ khử nhiễu như một ánh xạ xác định từ hình ảnh nhiễu y đến đối tác sạch x của nó. Từ quan điểm Bayes, khi được điều kiện trên x, y tuân theo phân phối posterior:

q(x|y) = q(y|x)q(x)/q(y). (15)

Với mất mát L2, các mô hình về cơ bản tính toán trung bình posterior, E[x|y], làm sáng tỏ hiện tượng làm mượt quá mức được quan sát. Như minh họa trong Hình 5 (và kết quả tiếp theo trong Phụ lục A), mô hình của chúng tôi mang lại sự bảo toàn chi tiết nhất quán ngay cả giữa nhiễu đáng kể. Trên thực tế, ở mức nhiễu cao nơi mô hình nào cũng có khả năng khôi phục chi tiết tinh tế, mô hình của chúng tôi cố gắng dự đoán các tính năng của hình ảnh thay vì ưu tiên độ mượt của kết cấu như U-Net.

--- TRANG 8 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

10 Bước Thời Gian
Hình Ảnh Sạch Hình Ảnh Nhiễu DDPM (cUnet) DDPM (Unet)

40 Bước Thời Gian

60 Bước Thời Gian 70 Bước Thời Gian

Hình 5: Hình ảnh gốc (trái), với nhiễu Gaussian (thứ hai), và được khử nhiễu sử dụng U-Net liên tục của chúng tôi (thứ ba và thứ tư). Khi nhiễu tăng, U-Net gặp khó khăn trong việc khôi phục các chi tiết tinh tế như kính.

Hơn nữa, Hình 10 và 11 trong Phụ lục B mô tả sự đánh đổi Tri giác-Biến dạng. Một cách trực quan, đây là việc lấy trung bình và làm mờ làm giảm biến dạng nhưng làm cho hình ảnh trông không tự nhiên. Như được thiết lập bởi (Blau & Michaeli, 2018), sự đánh đổi này được thông báo bởi khoảng cách biến thiên tổng (TV):

dTV(pˆX,pX) = 1/2 ∫ |pˆX(x) − pX(x)|dx, (16)

trong đó pˆX là phân phối của các hình ảnh tái tạo và pX là phân phối của các hình ảnh tự nhiên. Hàm tri giác-biến dạng P(D) sau đó được giới thiệu, biểu diễn chất lượng tri giác tốt nhất cho một biến dạng D cho trước:

P(D) = min pˆX|Y dTV(pˆX,pX) s.t. E[∆(X,ˆX)] ≤ D. (17)

Trong phương trình này, việc tối thiểu hóa trải rộng trên các ước tính pˆX|Y, và ∆(X,ˆX) đặc trưng cho thước đo biến dạng. Nhấn mạnh bản chất lồi của P(D), cho hai điểm (D1,P(D1)) và (D2,P(D2)), chúng ta có:

λP(D1) + (1−λ)P(D2) ≥ P(λD1 + (1−λ)D2), (18)

trong đó λ là một trọng số vô hướng được sử dụng để lấy tổ hợp lồi của hai điểm hoạt động. Tính lồi này nhấn mạnh một sự đánh đổi nghiêm ngặt ở các giá trị D thấp hơn. Việc giảm biến dạng bên dưới một ngưỡng cụ thể đòi hỏi một sự thỏa hiệp đáng kể trong chất lượng tri giác. Ngoài ra, bước thời gian mà mỗi mô hình đạt được hiệu suất đỉnh về SSIM và LPIPS được theo dõi, cùng với thời gian trôi qua cần thiết để đạt đến điểm tối ưu này. Đáng khích lệ, mô hình được đề xuất của chúng tôi vượt trội nhất quán trong khía cạnh này, mang lại tốc độ suy luận vượt trội và yêu cầu ít bước thời gian hơn để hội tụ. Những kết quả đầy hứa hẹn này được tổng hợp và có thể xem trong Bảng 3.

Bước Nhiễu Bước SSIM Tốt Nhất Thời Gian SSIM (s) Bước LPIPS Tốt Nhất Thời Gian LPIPS (s)
50 47 /39 5.45 /4.40 41 /39 4.71 /4.40
100 93 /73 19.72 /9.89 78 /72 16.54 /9.69
150 140 /103 29.69 /14.27 119 /102 25.18 /13.88
200 186 /130 39.51 /18.16 161 /128 34.09 /17.82
250 232 /154 49.14 /21.59 203 /152 43.15 /21.22
400 368 /217 77.33 /29.60 332 /212 69.77 /29.19
600 548 /265 114.90 /35.75 507 /263 106.42 /35.49
800 731 /284 153.38 /39.11 668 /284 140.26 /39.05

Bảng 3: So sánh hiệu suất trung bình cho U-Net (trái) và cU-Net (phải) ở các mức nhiễu khác nhau về bước thời gian cụ thể mà hiệu suất đỉnh được đạt và thời gian thực hiện. Những kết quả này là trung bình trên tất cả các mẫu trong bộ thử nghiệm của chúng tôi.

50 Bước Thời Gian 150 Bước Thời Gian 400 Bước Thời Gian
Phương pháp SSIM LPIPS SSIM LPIPS SSIM LPIPS
BM3D 0.74 0.062 0.26 0.624 0.06 0.977
Conv AE 0.89 0.030 0.80 0.072 0.52 0.204
DnCNN 0.89 0.026 0.81 0.051 0.53 0.227
Diff U-Net 0.88 0.025 0.79 0.063 0.58 0.184
Diff cU-Net 0.90 0.019 0.78 0.050 0.44 0.146

Bảng 4: Hiệu suất trung bình so sánh của các phương pháp khử nhiễu khác nhau ở các mức nhiễu được chọn trên bộ thử nghiệm. Kết quả chứng minh khả năng của các mô hình dựa trên khuếch tán (Diff U-Net và Diff cU-Net) trong việc xử lý một phổ rộng các mức nhiễu mà không cần đào tạo lại.

Chúng tôi so sánh hiệu suất khử nhiễu của quá trình ngược của mô hình khuếch tán chúng tôi với các phương pháp đã được thiết lập, bao gồm DnCNN (Zhang et al., 2017), một autoencoder tích chập, và BM3D (Dabov et al., 2007), như được chi tiết trong Bảng 4. Mô hình của chúng tôi vượt trội hơn các phương pháp khác ở bước thời gian thấp trong cả thước đo SSIM và tri giác. Ở bước thời gian cao, trong khi DDPM chuẩn với U-Net xuất sắc trong SSIM, cUNet của chúng tôi dẫn đầu về chất lượng tri giác. Cả hai U-Net, được đào tạo trước mà không cần đào tạo mức nhiễu cụ thể, khử nhiễu hiệu quả trên một phổ nhiễu rộng, thể hiện khả năng tổng quát hóa vượt trội so với các kỹ thuật học sâu khác. Điều này minh họa lợi thế của các phân phối đã học rộng của mô hình khuếch tán cho khử nhiễu chất lượng qua các điều kiện nhiễu khác nhau.

5.3 Hiệu quả
Các mô hình học sâu thường đòi hỏi tài nguyên tính toán đáng kể do bản chất nặng tham số của chúng. Ví dụ, trong mô hình Stable Diffusion (Rombach et al., 2022b) — một mô hình khuếch tán văn bản-thành-hình ảnh tiên tiến — U-Net khử nhiễu tiêu thụ khoảng 90% (860M trong số 983M) tổng tham số. Điều này hạn chế đào tạo và triển khai chủ yếu đối với các môi trường hiệu suất cao.

--- TRANG 9 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

0e+00 1e+07 2e+07 3e+07
# Tham số
U−net
cU−Net
cU−Net wo/A
cU−Net wo/R
cU−Net wo/A/R

Hình 6: Tổng số tham số cho các mô hình U-Net và U-Net liên tục (cU-Net) và các biến thể. Ký hiệu theo Bảng 5.

Ý tưởng của khung chúng tôi là giải quyết vấn đề này bằng cách cung cấp một giải pháp plug-and-play để cải thiện hiệu quả tham số một cách đáng kể. Hình 6 minh họa rằng cUNet của chúng tôi chỉ yêu cầu 8.8M tham số, khoảng một phần tư của UNet chuẩn. Duy trì tính nhất quán kiến trúc qua các so sánh, mô hình của chúng tôi đạt được điều này với những đánh đổi hiệu suất tối thiểu. Trên thực tế, nó thường khớp hoặc vượt trội U-Net trong khả năng khử nhiễu.

Trong khi trọng tâm của chúng tôi là DDPM, tính mô-đun của cUNet sẽ làm cho nó tương thích với một phạm vi rộng hơn của các mô hình khuếch tán cũng sử dụng kiến trúc kiểu U-Net, làm cho phương pháp của chúng tôi có khả năng có lợi cho cả hiệu quả và hiệu suất qua một phạm vi rộng hơn của các mô hình khuếch tán. Hiệu quả của CUNet, FLOP giảm, và bảo toàn bộ nhớ (Bảng 5) có thể cung cấp một lợi thế chuyển đổi khi chúng giảm thiểu nhu cầu tính toán, cho phép triển khai trên máy tính cá nhân và các giải pháp cloud thân thiện với ngân sách.

Cấu hình Mô hình DDPM GFLOPS MB
U-Net 7.21 545.5
U-Net Liên tục (cU-Net) 2.90 137.9
cU-Net wo/A (không chú ý) 2.81 128.7
cU-Net wo/R (không resblocks) 1.71 92.0
cU-Net wo/A/R (không chú ý & không resblocks) 1.62 88.4

Bảng 5: Số GigaFLOPS (GFLOPS) và Megabytes trong Bộ nhớ (MB) cho Các Mô hình Khác nhau.

6 Kết luận
Chúng tôi khám phá khả năng mở rộng của kiến trúc U-Net liên tục, giới thiệu cơ chế chú ý, kết nối dư, và nhúng thời gian được thiết kế riêng cho các bước thời gian khuếch tán. Thông qua các nghiên cứu ablation của chúng tôi, chúng tôi chứng minh thực nghiệm những lợi ích của việc kết hợp những thành phần mới này, về hiệu suất khử nhiễu và khả năng tạo hình ảnh (Phụ lục C). Chúng tôi đề xuất và chứng minh tính khả thi của một khung mới cho các mô hình xác suất khuếch tán khử nhiễu trong đó chúng tôi thay thế cơ bản bộ khử nhiễu U-Net không thể tranh cãi trong quá trình ngược bằng lựa chọn thay thế U-Net liên tục tùy chỉnh của chúng tôi. Trái ngược với công trình hiện có, mạng khử nhiễu mới này có một khối Neural ODE bậc hai độc đáo với kết nối dư và nhúng thời gian, nâng cao hiệu quả trong các mô hình khuếch tán tiến tiến của chúng tôi sử dụng cấu trúc U-Net ẩn sâu. Như được hiển thị ở trên, sự sửa đổi này không chỉ có động lực lý thuyết, mà còn được chứng thực bởi so sánh thực nghiệm. Chúng tôi so sánh hai khung về tổng hợp hình ảnh, để phân tích khả năng biểu đạt và năng lực học các phân phối phức tạp của chúng, và khử nhiễu để có cái nhìn về những gì xảy ra trong quá trình ngược tại suy luận và đào tạo. Các đổi mới của chúng tôi mang lại lợi thế hiệu quả đáng chú ý so với các mô hình khuếch tán truyền thống, giảm nhu cầu tính toán và gợi ý khả năng triển khai trên các thiết bị hạn chế tài nguyên do hiệu quả tham số của chúng trong khi cung cấp hiệu suất tổng hợp tương đương và hiệu suất khử nhiễu tri giác cải thiện phù hợp hơn với nhận thức con người. Cân nhắc cho công việc tương lai xoay quanh việc cải thiện song song hóa bộ giải ODE, và kết hợp các kỹ thuật lấy mẫu để tăng cường hiệu quả hơn nữa.

--- TRANG 10 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Lời cảm ơn
SCO biết ơn sự hỗ trợ tài chính của Oxford-Man Institute of Quantitative Finance. Một phần đáng kể công việc của SCO được thực hiện tại Đại học Cambridge, nơi ông cũng muốn cảm ơn các dịch vụ HPC của Trường Đại học vì đã cung cấp tài nguyên tính toán thiết yếu. CWC biết ơn sự tài trợ từ CCMI, Đại học Cambridge. GY được hỗ trợ một phần bởi ERC IMI (101005122), H2020 (952172), MRC (MC/PC/21013), Royal Society (IEC/NSFC/211235), Chương trình Tặng Phần cứng Học thuật NVIDIA, dự án SABER được hỗ trợ bởi Boehringer Ingelheim Ltd, Wellcome Leap Dynamic Resilience, và UKRI Future Leaders Fellowship (MR/V023799/1). JH được hỗ trợ một phần bởi Imperial College Bioengineering Department PhD Scholarship và UKRI Future Leaders Fellowship (MR/V023799/1). CBS thừa nhận sự hỗ trợ từ Philip Leverhulme Prize, Royal Society Wolfson Fellowship, EPSRC advanced career fellowship EP/V029428/1, các khoản tài trợ EPSRC EP/S026045/1 và EP/T003553/1, EP/N014588/1, EP/T017961/1, Wellcome Innovator Awards 215733/Z/19/Z và 221633/Z/20/Z, CCMI và Alan Turing Institute. AAR biết ơn sự tài trợ từ Cambridge Centre for Data-Driven Discovery và Accelerate Programme for Scientific Discovery, được thực hiện bởi một khoản tặng từ Schmidt Futures, ESPRC Digital Core Capability Award, và CMIH và CCIMI, Đại học Cambridge.

Tài liệu tham khảo
Abien Fred Agarap. Deep learning using rectified linear units (relu), 2019. 5
Shinei Arakawa, Hideki Tsunashima, Daichi Horita, Keitaro Tanaka, and Shigeo Morishima. Memory efficient diffusion probabilistic models via patch-based generation, 2023. 4
Fan Bao, Chongxuan Li, Jun Zhu, and Bo Zhang. Analytic-dpm: an analytic estimate of the optimal reverse variance in diffusion probabilistic models. arXiv preprint arXiv:2201.06503, 2022. 2
Yochai Blau and Tomer Michaeli. The perception-distortion tradeoff. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. IEEE, June 2018. doi: 10.1109/cvpr.2018.00652. URL http://dx.doi.org/10.1109/CVPR.2018.00652. 11
Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary differential equations. Advances in neural information processing systems, 31, 2018. 3
Chun-Wun Cheng, Christina Runkel, Lihao Liu, Raymond H Chan, Carola-Bibiane Schönlieb, and Angelica I Aviles-Rivero. Continuous u-net: Faster, greater and noiseless. arXiv preprint arXiv:2302.00626, 2023. 2, 3, 5
Wei Cheng, Gregory Darnell, Sohini Ramachandran, and Lorin Crawford. Generalizing variational autoencoders with hierarchical empirical bayes, 2020. 3
Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, and Jong Chul Ye. Improving diffusion models for inverse problems using manifold constraints. Advances in Neural Information Processing Systems, 35:25683–25696, 2022. 2
Hyungjin Chung, Jeongsol Kim, Michael T. Mccann, Marc L. Klasky, and Jong Chul Ye. Diffusion posterior sampling for general noisy inverse problems, 2023. 2
Kostadin Dabov, Alessandro Foi, Vladimir Katkovnik, and Karen Egiazarian. Image denoising by sparse 3-d transform-domain collaborative filtering. IEEE Transactions on Image Processing, 16(8):2080–2095, 2007. doi: 10.1109/TIP.2007.901238. 12
Prafulla Dhariwal and Alex Nichol. Diffusion models beat gans on image synthesis, 2021. 1
Tim Dockhorn, Arash Vahdat, and Karsten Kreis. Score-based generative modeling with critically-damped langevin diffusion, 2022. 4
Emilien Dupont, Arnaud Doucet, and Yee Whye Teh. Augmented neural odes, 2019. 3

--- TRANG 11 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Shanghua Gao, Pan Zhou, Ming-Ming Cheng, and Shuicheng Yan. Masked diffusion transformer is a strong image synthesizer, 2023. 4
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Communications of the ACM, 63(11): 139–144, 2020. 1
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840–6851, 2020. 1, 3, 5, 6, 8
Jonathan Ho, Chitwan Saharia, William Chan, David J. Fleet, Mohammad Norouzi, and Tim Salimans. Cascaded diffusion models for high fidelity image generation, 2021. 1
Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P. Kingma, Ben Poole, Mohammad Norouzi, David J. Fleet, and Tim Salimans. Imagen video: High definition video generation with diffusion models, 2022. 1
Alain Horé and Djemel Ziou. Image quality metrics: Psnr vs. ssim. In 2010 20th International Conference on Pattern Recognition, pp. 2366–2369, 2010. doi: 10.1109/ICPR.2010.579. 10
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. Advances in Neural Information Processing Systems, 35:26565–26577, 2022. 2, 4, 7
Diederik P. Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions, 2018. 1
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013. 1
Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. Diffwave: A versatile diffusion model for audio synthesis, 2021. 1, 2
Jinglin Liu, Chengxi Li, Yi Ren, Feiyang Chen, and Zhou Zhao. Diffsinger: Singing voice synthesis via shallow diffusion mechanism, 2022a. 1
Luping Liu, Yi Ren, Zhijie Lin, and Zhou Zhao. Pseudo numerical methods for diffusion models on manifolds, 2022b. 2
Aaron Lou and Stefano Ermon. Reflected diffusion models, 2023. 2
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps, 2022. 2
Zhaoyang Lyu, Xudong Xu, Ceyuan Yang, Dahua Lin, and Bo Dai. Accelerating diffusion models via early stop of the diffusion process. arXiv preprint arXiv:2205.12524, 2022. 1
Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning, pp. 8162–8171. PMLR, 2021. 1, 2
Alexander Norcliffe, Cristian Bodnar, Ben Day, Nikola Simidjievski, and Pietro Liò. On second order behaviour in augmented neural odes. Advances in neural information processing systems, 33:5911–5921, 2020. 7
Kushagra Pandey and Stephan Mandt. A complete recipe for diffusion generative models, 2023. 4
Kushagra Pandey, Avideep Mukherjee, Piyush Rai, and Abhishek Kumar. Diffusevae: Efficient, controllable and high-fidelity generation from low-dimensional latents, 2022. 4
Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, and Supasorn Suwajanakorn. Diffusion autoencoders: Toward a meaningful and decodable representation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10619–10629, 2022a. 2

--- TRANG 12 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, and Supasorn Suwajanakorn. Diffusion autoencoders: Toward a meaningful and decodable representation, 2022b. 4
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents, 2022. 1
Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows, 2015. 1, 3
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models, 2014. 1
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10684–10695, 2022a. 4
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models, 2022b. 1, 12
Litu Rout, Negin Raoof, Giannis Daras, Constantine Caramanis, Alexandros G. Dimakis, and Sanjay Shakkottai. Solving linear inverse problems provably via posterior sampling with latent diffusion models, 2023. 2
Yulia Rubanova, Ricky T. Q. Chen, and David Duvenaud. Latent odes for irregularly-sampled time series, 2019. 3
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep language understanding, 2022. 1
Tim Salimans and Jonathan Ho. Progressive distillation for fast sampling of diffusion models. arXiv preprint arXiv:2202.00512, 2022. 2
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International conference on machine learning, pp. 2256–2265. PMLR, 2015. 1
Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020a. 2
Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution, 2020. 1, 2
Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456, 2020b. 1, 2, 3, 7
Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-based generative modeling in latent space, 2021. 4
Weilun Wang, Jianmin Bao, Wengang Zhou, Dongdong Chen, Dong Chen, Lu Yuan, and Houqiang Li. Sindiffusion: Learning a diffusion model from a single natural image, 2022. 4
Zhendong Wang, Yifan Jiang, Huangjie Zheng, Peihao Wang, Pengcheng He, Zhangyang Wang, Weizhu Chen, and Mingyuan Zhou. Patch diffusion: Faster and more data-efficient training of diffusion models, 2023. 4
Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling the generative learning trilemma with denoising diffusion gans, 2022. 2

--- TRANG 13 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang. Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising. IEEE Transactions on Image Processing, 26(7):3142–3155, July 2017. ISSN 1941-0042. doi: 10.1109/tip.2017.2662206. URL http://dx.doi.org/10.1109/TIP.2017.2662206. 12
Qinsheng Zhang and Yongxin Chen. Fast sampling of diffusion models with exponential integrator, 2023. 2
Hongkai Zheng, Weili Nie, Arash Vahdat, Kamyar Azizzadenesheli, and Anima Anandkumar. Fast sampling of diffusion models via operator learning, 2023a. 4
Huangjie Zheng, Pengcheng He, Weizhu Chen, and Mingyuan Zhou. Truncated diffusion probabilistic models and diffusion-based adversarial auto-encoders, 2023b. 2
Huangjie Zheng, Zhendong Wang, Jianbo Yuan, Guanghan Ning, Pengcheng He, Quanzeng You, Hongxia Yang, and Mingyuan Zhou. Learning stackable and skippable lego bricks for efficient, reconfigurable, and variable-resolution diffusion modeling, 2023c. 4

--- TRANG 14 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

A Phụ lục
Phụ lục này phục vụ như không gian nơi chúng tôi trình bày kết quả trực quan chi tiết hơn của quá trình khử nhiễu cho cả mô hình cơ sở và đề xuất của chúng tôi.

Hình 7: Theo dõi các dự đoán khử nhiễu trung gian của mô hình. Các hình ảnh bên trái là đầu ra của U-Net liên tục của chúng tôi, và những hình ảnh bên phải là từ U-Net thông thường.

--- TRANG 15 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Hình 8: Theo dõi các dự đoán khử nhiễu trung gian của mô hình: Các hình ảnh bên trái mô tả đầu ra của U-Net liên tục của chúng tôi, loại bỏ thành công nhiễu trong ít bước hơn so với đối tác của nó (hình ảnh giữa) và duy trì chi tiết tinh tế hơn. Các hình ảnh bên phải đại diện cho đầu ra từ U-Net thông thường.

--- TRANG 16 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Hình 9: Theo dõi các dự đoán khử nhiễu trung gian của mô hình: Các hình ảnh bên trái mô tả đầu ra của U-Net liên tục của chúng tôi, cố gắng dự đoán các đặc điểm khuôn mặt giữa nhiễu. Ngược lại, các hình ảnh bên phải, từ U-Net thông thường, gặp khó khăn trong việc nhận ra khuôn mặt, thể hiện những hạn chế trong tái tạo đặc điểm chi tiết.

--- TRANG 17 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

B Phụ lục

Hình 10: Điểm SSIM được vẽ theo các bước khuếch tán cho các mức nhiễu khác nhau cho một hình ảnh. Đồ thị nhấn mạnh hiệu suất vượt trội nhất quán của U-Net so với cU-Net về SSIM, đặc biệt ở mức nhiễu cao. Sự thống trị này trong SSIM có thể gây hiểu lầm do sự đánh đổi Biến dạng-Tri giác vốn có và xu hướng của mô hình chúng tôi dự đoán các đặc điểm thay vì làm biến dạng hình ảnh.

--- TRANG 18 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

Hình 11: Điểm LPIPS so với các bước thời gian khuếch tán - hoặc khử nhiễu cho một hình ảnh. Chúng ta có thể quan sát cách U-Net liên tục của chúng tôi đạt được điểm LPIPS tốt hơn một cách nhất quán và không gặp phải hiệu ứng khuỷu tay đáng kể như được quan sát trong mô hình U-Net trong đó chất lượng của các dự đoán bắt đầu xấu đi sau khi mô hình đạt hiệu suất đỉnh. Các đường không liên tục chỉ ra bước thời gian mà LPIPS đỉnh được đạt. Ở đây, chúng ta thấy rằng, đặc biệt cho một số lượng lớn các bước thời gian, U-Net liên tục dường như hội tụ đến một giải pháp tốt hơn trong ít bước hơn. Điều này là do khả năng nó có để dự đoán các đặc điểm khuôn mặt thay vì chỉ đơn giản là chấp nhận kết quả quá mượt (Hình 9).

--- TRANG 19 ---
Xuất bản trong Transactions on Machine Learning Research (04/2024)

C Phụ lục
Trong phụ lục ngắn này, chúng tôi trình bày các hình ảnh được tạo ra cho các nghiên cứu ablation của chúng tôi. Như được chứng minh dưới đây, chất lượng của các hình ảnh được tạo ra giảm đáng kể khi chúng tôi đào tạo các mô hình của chúng tôi mà không có các thành phần cụ thể (không có cơ chế chú ý và/hoặc không có kết nối dư). Điều này dẫn đến kết luận rằng các cải tiến của chúng tôi đối với các khối cơ bản trong mạng khử nhiễu của chúng tôi là cơ bản cho hiệu suất tối ưu.

Hình 12: Các mẫu đại diện từ phiên bản mô hình của chúng tôi được đào tạo mà không có cơ chế chú ý. Sự giảm chất lượng thường có thể được nhận thấy trong các hình ảnh được tạo ra.

Hình 13: Các mẫu đại diện từ phiên bản mô hình của chúng tôi được đào tạo mà không có kết nối dư trong khối ODE của chúng tôi. Chúng ta có thể thấy các artefact và sự không nhất quán thường xuyên.

Hình 14: Các mẫu đại diện từ phiên bản cơ bản của mô hình của chúng tôi chỉ bao gồm nhúng thời gian. Như có thể nhận thấy, chất lượng mẫu bị ảnh hưởng đáng kể.

# 2210.04428.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2210.04428.pdf
# Kích thước tệp: 120835 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
arXiv:2210.04428v2  [cs.CV]  29 Mar 2023Một Baseline Đơn Giản Đặt Câu Hỏi về Việc Sử Dụng
Các Mô Hình Được Tiền Huấn Luyện trong Học Liên Tục
Paul Janson1,3∗, Wenxuan Zhang1, Rahaf Aljundi2, và Mohamed Elhoseiny1
1Đại học Khoa học và Công nghệ King Abdullah, Ả Rập Saudi
2Toyota Motor Europe, Bỉ
3Đại học Moratuwa, Sri Lanka
Tóm tắt
Với sự thành công của các kỹ thuật tiền huấn luyện trong học biểu diễn, một số
phương pháp học liên tục dựa trên các mô hình được tiền huấn luyện đã được đề xuất.
Một số phương pháp này thiết kế các cơ chế học liên tục trên các biểu diễn được tiền
huấn luyện và chỉ cho phép cập nhật tối thiểu hoặc thậm chí không cập nhật các mô
hình xương sống trong quá trình huấn luyện học liên tục. Trong bài báo này, chúng tôi
đặt câu hỏi liệu độ phức tạp của các mô hình này có cần thiết để đạt được hiệu suất
tốt bằng cách so sánh chúng với một baseline rất đơn giản mà chúng tôi thiết kế. Chúng
tôi lập luận rằng bản thân bộ trích xuất đặc trưng được tiền huấn luyện có thể đủ mạnh
để đạt được hiệu suất học liên tục cạnh tranh hoặc thậm chí tốt hơn trên các benchmark
Split-CIFAR100 và CoRe 50. Để xác thực điều này, chúng tôi tiến hành baseline
mà 1) sử dụng một mô hình được tiền huấn luyện đông lạnh để trích xuất đặc trưng
hình ảnh cho mọi lớp và tính toán các đặc trưng trung bình tương ứng của chúng trong
thời gian huấn luyện, và 2) đưa ra dự đoán dựa trên khoảng cách láng giềng gần nhất
giữa các mẫu kiểm tra và đặc trưng trung bình của các lớp; tức là, Bộ Phân Loại Trung
Bình Gần Nhất (NMC). Baseline này là đơn đầu, không có mẫu và có thể không có
nhiệm vụ bằng cách cập nhật các đặc trưng trung bình liên tục. Baseline này đạt được
83.70% trên 10-Split-CIFAR-100, vượt qua hầu hết các phương pháp học liên tục
tiên tiến, với tất cả được khởi tạo bởi cùng một mô hình transformer được tiền huấn
luyện. Chúng tôi hy vọng baseline của chúng tôi có thể khuyến khích tiến bộ trong
tương lai trong việc thiết kế các hệ thống học có thể liên tục thêm chất lượng vào các
biểu diễn học ngay cả khi chúng bắt đầu từ các trọng số được tiền huấn luyện. Mã
nguồn có sẵn tại https://github.com/Pauljanson002/pre-trained-cl.git
1 Giới thiệu
Các mô hình học máy thông thường gặp khó khăn trong việc hoạt động tốt khi giả định i.i.d. bị
vi phạm trong thế giới thực, nơi dữ liệu đến tuần tự từ các nhiệm vụ với các phân phối thay đổi
theo thời gian. Các mô hình này gặp phải hiện tượng quên thảm khốc các nhiệm vụ trước đó[15, 10].
Học liên tục, trong đó tác nhân được mong đợi học các nhiệm vụ mới mà không quên những nhiệm
vụ cũ, đã được nghiên cứu rộng rãi như một giải pháp tiềm năng cho vấn đề này. Các phương pháp
tiếp cận ban đầu bắt đầu huấn luyện với một mô hình từ đầu, liên tục thích ứng mô hình cho các
nhiệm vụ tương lai, và ngăn chặn việc quên bằng cách phát lại dữ liệu, thiết kế việc phạt các cập
nhật của các tham số mô hình, và/hoặc động tăng các tham số mô hình để kết hợp kiến thức mới.

Việc sử dụng tiền huấn luyện [24] trên các tập dữ liệu quy mô lớn, chẳng hạn như ImageNet-1k[23]
và ImageNet-21k [22] đã dẫn đến những tiến bộ đáng kể. Với dữ liệu đủ và đa dạng, các đặc trưng
đầu ra của một mô hình được tiền huấn luyện tổng quát hóa tốt cho một loạt các nhiệm vụ, làm tăng
đáng kể hiệu suất của các kịch bản học đầy thách thức như học liên tục. Kết quả là, một số công
trình hiện có trực tiếp triển khai các mô hình được tiền huấn luyện như các bộ trích xuất đặc trưng,
và áp dụng các kỹ thuật học liên tục ở mức độ đặc trưng.

∗Công việc được thực hiện trong thời gian thực tập tại KAUST
Workshop on Distribution Shifts, Hội nghị lần thứ 36 về Hệ thống Xử lý Thông tin Neural (NeurIPS 2022).

--- TRANG 2 ---
Các phương pháp này ngụ ý rằng các mô hình được tiền huấn luyện cung cấp các đặc trưng tổng quát
và thô cần được tinh chỉnh cụ thể cho nhiệm vụ. Tuy nhiên, [20] tuyên bố các mô hình được tiền
huấn luyện quy mô lớn có hiệu suất phân loại xuất sắc đối với dữ liệu ngoài phân phối được tiền
huấn luyện ngay cả không có huấn luyện thêm. Chúng tôi đặt câu hỏi liệu các đặc trưng được tiền
huấn luyện này có cạnh tranh cho các nhiệm vụ downstream và liệu các kỹ thuật học liên tục tinh
vi có thực sự cần thiết để đạt được hiệu suất tốt trên các benchmark học liên tục được nghiên cứu.

Để trả lời những câu hỏi này, chúng tôi triển khai một baseline đơn giản trong học liên tục. Chúng
tôi sử dụng một mô hình được tiền huấn luyện đông lạnh để trích xuất đặc trưng cho tập huấn luyện
và tính toán các đặc trưng trung bình để đại diện cho mỗi lớp. Trong thời gian kiểm tra, chúng tôi
đưa ra dự đoán dựa trên khoảng cách giữa các mẫu kiểm tra và đặc trưng trung bình của lớp. Kết
quả của chúng tôi cạnh tranh đáng ngạc nhiên với các phương pháp SOTA sử dụng cùng mạng
xương sống được tiền huấn luyện. Chúng tôi đạt được 83.70% Độ Chính Xác Trung Bình ở cuối
chuỗi học của Split CIFAR100 so với 83.83% của L2P[27], và 83.23% trên nhiệm vụ đánh giá
của CoRe50 so với 78.33% của L2P. Điều này ngụ ý rằng các mô hình được tiền huấn luyện cung
cấp các biểu diễn học chất lượng và mạnh mẽ dưới sự thay đổi phân phối. Chúng tôi cũng trình
bày các kết quả thực nghiệm trên hai benchmark đa dạng hơn, 5-dataset và Split-ImageNet-R. Kết
quả trên các tập dữ liệu này cũng cho thấy hiệu suất cạnh tranh vượt trội hầu hết các phương pháp.

Baseline được đề xuất của chúng tôi là đơn đầu, không có nhiệm vụ, và không có mẫu như một
phần thưởng bổ sung. Chúng tôi lập luận rằng đây là một baseline đơn giản nhưng mạnh mẽ mà
mọi phương pháp học liên tục nên so sánh. Ý định của những đặc tính này là để sử dụng ít hơn
các nhãn nhiệm vụ (không thực tế trong thực tiễn) và dữ liệu phát lại (gây ra mối quan tâm về
quyền riêng tư) trong các kỹ thuật. Chúng tôi quan sát thấy một số công trình trước đây vượt trội
baseline này, nhưng với cái giá phải hy sinh một hoặc nhiều đặc tính này. Có ít phương pháp tiếp
cận có thể so sánh với chúng ta khi tất cả các điều kiện phù hợp. Chúng tôi hy vọng rằng công
trình này làm sáng tỏ việc kiểm tra tính thực tiễn của tiền huấn luyện trong học liên tục và liệu
các phương pháp mới có đang cải thiện chất lượng biểu diễn học liên tục.

2 Công trình liên quan
Học liên tục với các mô hình được tiền huấn luyện Các phương pháp học liên tục thường huấn
luyện các bộ trích xuất đặc trưng từ đầu và hạn chế sự trôi dạt trong biểu diễn đặc trưng [10, 16].
Gần đây, việc sử dụng các mô hình được tiền huấn luyện đã thu hút nhiều sự chú ý trong học liên
tục. [2] xem nhiệm vụ đầu tiên như một giai đoạn tiền huấn luyện và đông lạnh biểu diễn đặc trưng
sau nhiệm vụ đầu tiên. [7] phát hiện rằng kích thước dữ liệu lớn hơn trong nhiệm vụ đầu tiên và
tiền huấn luyện tự giám sát giúp giảm việc quên thảm khốc. [12] phân tích thực nghiệm hiệu ứng
của việc huấn luyện lớp cuối cùng với một bộ trích xuất đặc trưng cố định. [18] nghiên cứu các
mô hình nền tảng và phát lại các đặc trưng tiềm ẩn đông lạnh để vượt qua việc quên thảm khốc.
Gần đây [27] đề xuất sử dụng tinh chỉnh dựa trên prompt với một transformer được tiền huấn luyện
[5, 25] và so sánh nó với các phương pháp khác trong cùng khởi tạo. Chúng tôi áp dụng chiến lược
này và chỉ ra rằng việc học bộ phân loại thực sự giảm sức mạnh của các biểu diễn học được bởi
mô hình được tiền huấn luyện.

Học liên tục nhận biết/không nhận biết nhiệm vụ Phương pháp tăng dần nhiệm vụ yêu cầu các
định danh nhiệm vụ của các mẫu trong quá trình suy luận, làm giảm ứng dụng thực tế của các
phương pháp này, trong khi các phương pháp tăng dần lớp không yêu cầu những thứ đó. Tuy nhiên,
các phương pháp nhận biết/không nhận biết nhiệm vụ gặp phải thiên lệch gần đây của lớp. Để vượt
qua thiên lệch gần đây như vậy, BiC[29] đề xuất thêm một lớp cuối cùng làm giảm thiên lệch cuối
cùng. LUCIR [9] đề xuất sử dụng tinh chỉnh cân bằng để huấn luyện bộ phân loại sau khi đông
lạnh biểu diễn đặc trưng. Phương pháp của chúng tôi cũng tập trung vào vấn đề này và sử dụng
bộ phân loại trung bình gần nhất đơn giản trên đầu transformer được tiền huấn luyện.

Học liên tục không có mẫu Các phương pháp trước đây được đề xuất để lưu trữ dữ liệu thô, đặc
trưng học được, hoặc đặc trưng được tạo ra từ các nhiệm vụ trước đó. Vì cơ chế phát lại như ER
[4] là trực giao với các phương pháp dựa trên kiến trúc và dựa trên chính quy hóa, chúng được
áp dụng rộng rãi trong các phương pháp khác để cải thiện hiệu suất. Gần đây đã có sự quan tâm
gia tăng đến học liên tục không có mẫu để tính đến các mối quan tâm về quyền riêng tư trong việc
lưu trữ các mẫu thô và mối quan tâm về lưu trữ. iCaRL [21] giới thiệu phương pháp sử dụng các
mẫu cho học liên tục và chọn các mẫu gần với trung bình lớp. Baseline của chúng tôi theo một
chiến lược tương tự nhưng chỉ lưu trữ trung bình lớp trong không gian đặc trưng, tiết kiệm bộ
nhớ bằng cách giảm số lượng biến tiềm ẩn để giữ cho mỗi lớp.

3 Phương pháp luận
Thiết lập vấn đề Chúng tôi áp dụng kịch bản học liên tục tiêu chuẩn nơi một mô hình học từ một
luồng dữ liệu không i.i.d., được biểu diễn như D1,...,DT, trong đó Dt={(xt
i,yt
i)}Nt
i=1 là tập con
cụ thể nhiệm vụ, xt
i∈Rw×h×c là một đầu vào hình ảnh và yt
i∈Z là nhãn tương ứng của nó. Mục tiêu
của học liên tục là học một hàm fθ ánh xạ đầu vào x đến nhãn y từ một nhiệm vụ tùy ý đã thấy
cho đến nay. Chúng tôi tập trung vào hai kịch bản. Trong thiết lập tăng dần lớp, mỗi tập con Dt
chứa một tập nhãn lớp rời rạc. Trong thiết lập tăng dần miền, các tập con D1,...,DT chia sẻ các
nhãn lớp, nhưng các phân phối đầu vào thay đổi theo thời gian.

Bộ Phân Loại Trung Bình Gần Nhất (NMC) Chúng tôi tách mục tiêu của học liên tục fθ thành
hai bước. Bước đầu tiên là học biểu diễn h và bước tiếp theo là học bộ phân loại g. Chúng tôi trực
tiếp áp dụng một vision transformer được tiền huấn luyện như biểu diễn đặc trưng của chúng tôi
mà không cần huấn luyện. Đối với bộ phân loại, được lấy cảm hứng từ [21, 17] chúng tôi sử dụng
chiến lược phân loại trung bình gần nhất. Trong giai đoạn huấn luyện của nhiệm vụ t, chúng tôi
tính toán các đặc trưng trung bình của một lớp trong Dt
µk=1
|Ck|/summationdisplay
x∈Ckh(x), (1)
trong đó Ck biểu thị tập các mẫu huấn luyện thuộc về lớp k. Chỉ các đặc trưng trung bình lớp được
lưu trong bộ nhớ và sẽ được sử dụng trong quá trình đánh giá. Tại thời điểm kiểm tra của nhiệm
vụ t, đặc trưng của một mẫu kiểm tra được trích xuất bởi mô hình được tiền huấn luyện, và nhãn
lớp được dự đoán được lấy như lớp có đặc trưng trung bình gần nhất (trên tất cả các lớp đã thấy
cho đến nay) với đặc trưng của mẫu kiểm tra.
ˆy=argmin
k||h(x)−µk|| (2)

4 Thực nghiệm
Chúng tôi tuân theo thiết lập thực nghiệm được sử dụng trong [27] để đánh giá phương pháp của
chúng tôi cho một so sánh công bằng. Chúng tôi kiểm tra phương pháp của chúng tôi trong học
tăng dần lớp, nơi các tập lớp mới được giới thiệu cho mô hình, và trong học tăng dần miền, nơi
các lớp vẫn giữ nguyên và miền thay đổi; xem Mục 3.

Tập dữ liệu: Chúng tôi đánh giá baseline của chúng tôi trên bốn benchmark học liên tục phổ biến,
Split-CIFAR100 [11], 5-datasets [6] và Split-ImageNet-R [8] trong thiết lập học tăng dần lớp.
Như được đề xuất bởi [27] và [26]. Split-CIFAR-100 chứa 10 nhiệm vụ với 10 lớp cho mỗi nhiệm
vụ. Benchmark 5-dataset nối 5 tập dữ liệu, MNIST, SVHN, notMNIST, FashionMNIST và CIFAR10,
với mỗi tập dữ liệu tạo thành một nhiệm vụ. Split ImageNet-R là một tập dữ liệu mới được đề xuất
cho học liên tục bởi [26]. Nó bao gồm 200 lớp được chia ngẫu nhiên thành 10 nhiệm vụ. Nó chứa
cùng các loại đối tượng tuy nhiên được trình bày trong các phong cách khác nhau như hoạt hình,
graffiti và origami. Những biến thể này làm cho học liên tục trở nên thách thức hơn. Đối với thiết
lập học tăng dần miền, chúng tôi sử dụng CoRe50 được đề xuất bởi [14]. Nó chứa 50 đối tượng
được thu thập trong 11 miền riêng biệt (nhiệm vụ). 8 miền được đối mặt và học tăng dần trong khi
kiểm tra được thực hiện trên ba miền còn lại. Vì một nhiệm vụ kiểm tra duy nhất được sử dụng,
chúng tôi không báo cáo kết quả quên và huấn luyện chung trong kịch bản đó.

Phương pháp đánh giá: Đối với phương pháp của chúng tôi (Ours), chúng tôi sử dụng mô hình
ViT-B/16[5] được sử dụng rộng rãi được tiền huấn luyện trên ImageNet-21k [24] được cung cấp
bởi thư viện timm [28]. Chúng tôi chủ yếu so sánh baseline của chúng tôi với L2P gần đây [27]
áp dụng mô hình được tiền huấn luyện như chúng ta và học một pool prompt với cơ chế chọn
prompt để sửa đổi các biểu diễn được tiền huấn luyện. Chúng tôi cũng xem xét các phương pháp
học liên tục phổ biến bao gồm các phương pháp dựa trên chính quy hóa (LwF[13], EWC [10])
và các phương pháp dựa trên tái diễn (ER[4], GDumb[19], BiC [29], DER++ [1] và Co2L [3]).
Chúng tôi trình bày kết quả huấn luyện chung nơi dữ liệu huấn luyện được phân phối i.i.d. trong
toàn bộ benchmark mà không có phân chia nhiệm vụ. FT-frozen thêm một lớp fully-connected
trên đầu bộ trích xuất đặc trưng đông lạnh như đầu phân loại, và FT cho phép huấn luyện end-to-end
trên bộ trích xuất đặc trưng. Lưu ý rằng FT-frozen khác với baseline của chúng tôi, vì chúng tôi
sử dụng bộ phân loại NMC và xây dựng nó tăng dần.

Kết quả: Bảng 1, 4, và 2 báo cáo hiệu suất của học liên tục trong thiết lập tăng dần trong Độ
Chính Xác Trung Bình ở cuối chuỗi học của Split-CIFAR100, Split-ImageNet-R, và 5-dataset
tương ứng. Bảng 4 cho thấy kết quả của học liên tục trong thiết lập tăng dần miền trên CoRe50[14].
Kết quả được nhóm dựa trên việc sử dụng mẫu phát lại. Baseline đơn giản của chúng tôi đạt được
hiệu suất cạnh tranh trên Split CIFAR-100 và CoRe50, Split-ImageNet-R và các benchmark 5-dataset.
Kết quả của chúng tôi trên Split-CIFAR-100 thậm chí còn tốt hơn các phương pháp sử dụng mẫu
phát lại. Cụ thể, baseline của chúng tôi đạt được 83.70% với kích thước buffer bằng không. Điều
này gợi ý rằng transformer được tiền huấn luyện cung cấp một biểu diễn mạnh mẽ đạt được hiệu
suất cạnh tranh. Chúng tôi nghĩ rằng lý do chính cho một hiệu suất có thể kém hơn có thể là thiết
kế không hiệu quả của các cơ chế học liên tục so với các đặc trưng mạnh mẽ được cung cấp bởi
mô hình được tiền huấn luyện. Một mô hình như vậy, được tiền huấn luyện trên một tập dữ liệu
lớn và đa dạng, có thể đã nắm bắt được hầu hết các đặc tính phân phối trong các benchmark đánh giá.

--- TRANG 4 ---
Bảng 1: Hiệu suất học liên tục được biểu
diễn trong Độ Chính Xác Trung Bình và
Quên ở cuối chuỗi học của CIFAR-
100[11]. Tất cả phương pháp được khởi tạo
với trọng số được tiền huấn luyện cho so
sánh công bằng. Baseline của chúng tôi cho
thấy hiệu suất cạnh tranh trên benchmark này.

Phương pháp Kích thước Buffer Độ Chính Xác TB Quên
FT - frozen 0 17.72 59.09
FT 0 33.61 86.87
EWC[10] 0 47.01 33.27
LwF [13] 0 60.69 27.77
L2P [27] 0 83.83 7.63
Ours 0 83.70 -
ER [4] 50/class 82.53 16.46
GDumb [19] 50/class 81.67 -
BiC [29] 50/class 81.42 17.31
DER++ [1] 50/class 83.94 14.55
Co2L [3] 50/class 82.49 17.48
L2P [27] 50/class 86.31 5.83
Joint - 90.85 -

Bảng 2: Hiệu suất học liên tục được biểu
diễn trong Độ Chính Xác Trung Bình và
Quên ở cuối chuỗi học của benchmark
5-dataset [6]. Tất cả phương pháp được khởi
tạo với trọng số được tiền huấn luyện của
transformer cho so sánh công bằng. Baseline
của chúng tôi hoạt động cạnh tranh với các
phương pháp không có mẫu trong benchmark này

Phương pháp Kích thước Buffer Độ Chính Xác TB Quên
FT - frozen 0 39.49 42.62
FT 0 20.12 94.63
EWC[10] 0 50.93 34.94
LwF [13] 0 47.91 38.01
L2P [27] 0 81.14 4.64
Ours 0 79.84 -
ER [4] 50/class 84.26 12.85
GDumb [19] 50/class 70.76 -
BiC [29] 50/class 85.53 10.27
DER++ [1] 50/class 84.88 10.46
Co2L [3] 50/class 86.05 12.28
L2P[27] 50/class 88.95 4.92
Joint 93.93

Bảng 3: Hiệu suất học liên tục trong Độ
Chính Xác Trung Bình tại nhiệm vụ đánh
giá của CoRe50 [14]. Tất cả phương pháp
được khởi tạo với trọng số được tiền huấn
luyện cho so sánh công bằng

Phương pháp Kích thước Buffer Độ Chính Xác Kiểm Tra
EWC[10] 0 74.82
LwF[13] 0 75.45
L2P[27] 0 78.33
Ours 0 83.23
ER[4] 50/class 80.1
GDumb[19] 50/class 74.92
BiC[29] 50/class 79.28
DER++[1] 50/class 79.7
Co2L[3] 50/class 79.75
L2P[27] 50/class 81.07

Bảng 4: Hiệu suất học liên tục trong Độ
Chính Xác Trung Bình và Quên ở cuối
chuỗi học của benchmark Split-ImageNet-R[8].
Tất cả phương pháp được khởi tạo với trọng
số được tiền huấn luyện cho so sánh công bằng.

Phương pháp Kích thước Buffer Độ Chính Xác TB Quên
FT - frozen 0 39.49 42.62
FT 0 28.87 63.80
EWC [10] 0 35.00 56.16
LwF [13] 0 38.54 52.37
L2P [27] 0 61.57 9.73
Ours 0 55.56 -
ER [4] 5000 65.18 23.31
GDumb [19] 5000 65.90 -
BiC [29] 5000 64.63 22.25
DER++ [1] 5000 66.73 20.67
Co2L [3] 5000 65.90 23.36
Joint - 79.13 -

Khi đó một cơ chế học liên tục mong muốn cần khuyến khích thêm mô hình để tạo ra các đặc trưng
bất biến nhiệm vụ cụ thể cho benchmark được triển khai. Baseline láng giềng gần nhất của chúng
tôi cũng có thẩm quyền trong các phương pháp không có mẫu trên các benchmark Split-ImageNet-R
và 5-datasets, đa dạng hơn CIFAR-100 và CoRe50. Tuy nhiên, các phương pháp với kích thước
buffer cao hơn và các cơ chế học liên tục được thiết kế tinh vi thực sự cải thiện các biểu diễn được
trích xuất từ các mô hình được tiền huấn luyện.

5 Kết luận
Trong công trình này, chúng tôi khám phá khả năng biểu diễn của các mô hình được tiền huấn luyện
quy mô lớn trong các thiết lập học liên tục. Chúng tôi cung cấp các thí nghiệm baseline láng giềng
gần nhất đơn giản trên bốn benchmark, cho thấy hiệu suất cạnh tranh với các phương pháp học
liên tục tiên tiến tinh vi hơn cũng tận dụng cùng các mô hình được tiền huấn luyện. Chúng tôi đồng
ý rằng sử dụng trọng số được tiền huấn luyện có thể là một thực hành hợp lý ngay cả trong học
liên tục. Tuy nhiên, để cho thấy tiến bộ thực sự trong các hệ thống học liên tục, chúng ta cần tập
trung nhiều hơn vào việc xây dựng các phương pháp có thể liên tục thêm chất lượng vào các biểu
diễn học. Một thuật toán học liên tục mong muốn sẽ vượt xa đáng kể kiến thức được nhúng trong
mô hình được tiền huấn luyện. Một khía cạnh quan trọng khác là các benchmark được xem xét
để đánh giá các phương pháp học liên tục. Các benchmark như vậy cần đủ thách thức và khác
biệt từ các phân phối dữ liệu được sử dụng cho các mô hình được tiền huấn luyện.

--- TRANG 5 ---
Tài liệu tham khảo
[1] Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, và SIMONE CALDER-
ARA. Dark Experience for General Continual Learning: a Strong, Simple Baseline. Trong Ad-
vances in Neural Information Processing Systems, tập 33, trang 15920–15930. Curran
Associates, Inc., 2020.
[2] Francisco M. Castro, Manuel J. Marín-Jiménez, Nicolás Guil, Cordelia Schmid, và Karteek
Alahari. End-to-End Incremental Learning. Trong Vittorio Ferrari, Martial Hebert, Cristian Smin-
chisescu, và Yair Weiss, biên tập, Computer Vision – ECCV 2018, tập 11216, trang 241–
257. Springer International Publishing, Cham, 2018. Series Title: Lecture Notes in Computer
Science.
[3] Hyuntak Cha, Jaeho Lee, và Jinwoo Shin. Co2l: Contrastive continual learning. Trong Proceed-
ings of the IEEE/CVF International Conference on Computer Vision 2021, trang 9516–9525,
2021.
[4] Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan,
Puneet K. Dokania, Philip H. S. Torr, và Marc'Aurelio Ranzato. On Tiny Episodic Mem-
ories in Continual Learning, tháng 6 năm 2019. arXiv:1902.10486 [cs, stat].
[5] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,
et al. An image is worth 16x16 words: Transformers for image recognition at scale. Trong Inter-
national Conference on Learning Representations, 2020.
[6] Sayna Ebrahimi, Franziska Meier, Roberto Calandra, Trevor Darrell, và Marcus Rohrbach.
Adversarial continual learning. Trong European Conference on Computer Vision, trang 386–402.
Springer, 2020.
[7] Jhair Gallardo. Self-Supervised Training Enhances Online Continual Learning. trang 15.
[8] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo,
Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A
critical analysis of out-of-distribution generalization. Trong Proceedings of the IEEE/CVF Inter-
national Conference on Computer Vision, trang 8340–8349, 2021.
[9] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, và Dahua Lin. Learning a Unified
Classifier Incrementally via Rebalancing. Trong 2019 IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR), trang 831–839, Long Beach, CA, USA, tháng 6 năm 2019. IEEE.
[10] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins,
Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska,
Demis Hassabis, Claudia Clopath, Dharshan Kumaran, và Raia Hadsell. Overcoming catas-
trophic forgetting in neural networks. Proceedings of the National Academy of Sciences,
114(13):3521–3526, tháng 3 năm 2017. Publisher: Proceedings of the National Academy of Sci-
ences.
[11] Alex Krizhevsky et al. Learning multiple layers of features from tiny images. 2009.
[12] Timothée Lesort, Oleksiy Ostapenko, Diganta Misra, Md Rifat Arefin, Pau Rodríguez, Lau-
rent Charlin, và Irina Rish. Scaling the Number of Tasks in Continual Learning, tháng 7 năm 2022.
arXiv:2207.04543 [cs].
[13] Zhizhong Li và Derek Hoiem. Learning without Forgetting. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 40(12):2935–2947, tháng 12 năm 2018. Conference Name:
IEEE Transactions on Pattern Analysis and Machine Intelligence.
[14] Vincenzo Lomonaco và Davide Maltoni. Core50: a new dataset and benchmark for continu-
ous object recognition. Trong Conference on Robot Learning, trang 17–26. PMLR, 2017.
[15] Michael McCloskey và Neal J. Cohen. Catastrophic Interference in Connectionist Networks:
The Sequential Learning Problem. Trong Gordon H. Bower, biên tập, Psychology of Learning and
Motivation, tập 24, trang 109–165. Academic Press, tháng 1 năm 1989.
[16] Michael McCloskey và Neal J. Cohen. Catastrophic Interference in Connectionist Networks:
The Sequential Learning Problem. Trong Gordon H. Bower, biên tập, Psychology of Learning and
Motivation, tập 24, trang 109–165. Academic Press, tháng 1 năm 1989.

--- TRANG 6 ---
[17] T. Mensink, J. Verbeek, F. Perronnin, và G. Csurka. Distance-Based Image Classification:
Generalizing to New Classes at Near-Zero Cost. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 35(11):2624–2637, tháng 11 năm 2013.
[18] Oleksiy Ostapenko, Timothee Lesort, Pau Rodríguez, Md Rifat Arefin, Arthur Douillard, Irina
Rish, và Laurent Charlin. Continual Learning with Foundation Models: An Empirical Study
of Latent Replay, tháng 7 năm 2022. arXiv:2205.00329 [cs].
[19] Ameya Prabhu, Philip H. S. Torr, và Puneet K. Dokania. GDumb: A Simple Approach that
Questions Our Progress in Continual Learning. Trong Andrea Vedaldi, Horst Bischof, Thomas
Brox, và Jan-Michael Frahm, biên tập, Computer Vision – ECCV 2020, tập 12347, trang
524–540. Springer International Publishing, Cham, 2020. Series Title: Lecture Notes in Com-
puter Science.
[20] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agar-
wal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable
visual models from natural language supervision. Trong International Conference on Machine
Learning, trang 8748–8763. PMLR, 2021.
[21] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H. Lampert.
iCaRL: Incremental Classifier and Representation Learning, tháng 4 năm 2017. arXiv:1611.07725
[cs, stat].
[22] Tal Ridnik, Emanuel Ben-Baruch, Asaf Noy, và Lihi Zelnik-Manor. ImageNet-21K Pretrain-
ing for the Masses. tháng 12 năm 2021.
[23] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng
Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, và Li Fei-
Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer
Vision, 115(3):211–252, tháng 12 năm 2015.
[24] Andreas Peter Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob Uszkoreit,
và Lucas Beyer. How to train your vit? data, augmentation, and regularization in vision
transformers. Transactions on Machine Learning Research, 2022.
[25] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Łukasz Kaiser, và Illia Polosukhin. Attention is all you need. Advances in neural information
processing systems 2017, 30, 2017.
[26] Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi
Ren, Guolong Su, Vincent Perot, Jennifer Dy, và Tomas Pfister. DualPrompt: Complementary
Prompting for Rehearsal-free Continual Learning, tháng 8 năm 2022. arXiv:2204.04799 [cs].
[27] Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su,
Vincent Perot, Jennifer Dy, và Tomas Pfister. Learning to Prompt for Continual Learning.
Trong 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE,
tháng 3 năm 2022.
[28] Ross Wightman. Pytorch image models. https://github.com/rwightman/pytorch-image-models,
2019.
[29] Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, và Yun
Fu. Large Scale Incremental Learning. Trong 2019 IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR), trang 374–382, Long Beach, CA, USA, tháng 6 năm 2019. IEEE.

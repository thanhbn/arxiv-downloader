# 2306.17089.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2306.17089.pdf
# Kích thước tệp: 667995 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Học Sâu Định Hướng Khái Niệm với Mô Hình Ngôn Ngữ Lớn

Daniel T. Chang ( 张遵)

IBM (Đã nghỉ hưu) dtchang43@gmail.com

Tóm tắt: Các Mô Hình Ngôn Ngữ Lớn (LLMs) đã được sử dụng thành công trong nhiều tác vụ và ứng dụng ngôn ngữ tự nhiên bao gồm tạo sinh văn bản và chatbot AI. Chúng cũng là một công nghệ mới đầy hứa hẹn cho học sâu định hướng khái niệm (CODL). Tuy nhiên, điều kiện tiên quyết là LLMs phải hiểu các khái niệm và đảm bảo tính nhất quán về mặt khái niệm. Chúng tôi thảo luận về những vấn đề này trong bài báo này, cũng như các ứng dụng chính của LLMs cho CODL bao gồm trích xuất khái niệm từ văn bản, trích xuất đồ thị khái niệm từ văn bản và học khái niệm. Kiến thức con người bao gồm cả kiến thức biểu tượng (khái niệm) và kiến thức thể hiện (cảm giác). Tuy nhiên, LLMs chỉ văn bản chỉ có thể biểu diễn kiến thức biểu tượng (khái niệm). Ngược lại, LLMs đa phương thức có khả năng biểu diễn toàn bộ phạm vi (khái niệm và cảm giác) của kiến thức con người. Chúng tôi thảo luận về hiểu biết khái niệm trong LLMs thị giác-ngôn ngữ, những LLMs đa phương thức quan trọng nhất, và các ứng dụng chính của chúng cho CODL bao gồm trích xuất khái niệm từ hình ảnh, trích xuất đồ thị khái niệm từ hình ảnh và học khái niệm. Trong khi các ứng dụng của LLMs cho CODL có giá trị độc lập, chúng đặc biệt có giá trị như một phần của các ứng dụng LLM như chatbot AI.

1 Giới thiệu

Học sâu định hướng khái niệm (CODL) [1-2] là một phương pháp học máy mở rộng học sâu với các biểu diễn khái niệm và khả năng hiểu biết khái niệm. CODL dựa trên ý tưởng rằng các khái niệm là nền tảng của học sâu, hiểu biết và tích hợp cũng như chuyển giao kiến thức của con người. Các hệ thống CODL được cấu tạo từ ba thành phần chính: đồ thị khái niệm, biểu diễn khái niệm và hệ thống học biểu diễn khái niệm.

Một mô hình ngôn ngữ lớn (LLM) [3-4] là một mô hình học sâu với nhiều tham số (thường là hàng tỷ trọng số trở lên), được huấn luyện trên lượng lớn văn bản không nhãn bằng cách sử dụng học tự giám sát hoặc học bán giám sát. LLMs đã được sử dụng thành công trong nhiều tác vụ và ứng dụng ngôn ngữ tự nhiên bao gồm tạo sinh văn bản và chatbot AI.

LLMs cũng là một công nghệ mới đầy hứa hẹn cho CODL. Tuy nhiên, điều kiện tiên quyết là LLMs phải hiểu các khái niệm và đảm bảo tính nhất quán về mặt khái niệm. Chúng tôi thảo luận về những vấn đề này trong bài báo này, cũng như các ứng dụng chính của LLMs cho CODL bao gồm trích xuất khái niệm từ văn bản, trích xuất đồ thị khái niệm từ văn bản và học khái niệm.

Một trong những thách thức chính trong việc phát triển LLMs là hiểu biết khái niệm. LLMs cần có khả năng hiểu ý nghĩa của các từ và cụm từ để tạo ra văn bản chính xác và có ý nghĩa. Tuy nhiên, điều này có thể khó khăn, vì nhiều từ và cụm từ có nhiều nghĩa. Đặc biệt, khả năng hiểu của LLM về các khái niệm trừu tượng yếu hơn đáng kể so với các khái niệm cụ thể [5]. Tính nhất quán khái niệm là một thước đo về mức độ hiểu biết của LLMs về mối quan hệ

--- TRANG 2 ---
2
giữa các khái niệm. Các LLMs phổ biến chỉ có mức độ tính nhất quán khái niệm vừa phải [6]. Điều này cho thấy rằng những mô hình này có thể không có hiểu biết sâu sắc về các khái niệm mà chúng có thể trả lời câu hỏi.

LLMs có thể được sử dụng để trích xuất khái niệm, đây là quá trình xác định và trích xuất các khái niệm từ văn bản. Có nhiều cách để sử dụng LLMs cho việc trích xuất khái niệm. Một cách là sử dụng kỹ thuật được gọi là "nhận dạng thực thể có tên" (NER). Tuy nhiên, hiệu suất của LLMs trên NER thấp hơn đáng kể so với các phương pháp cơ sở có giám sát. Điều này là do khoảng cách giữa hai tác vụ, NER và LLMs [7]: cái trước về bản chất là tác vụ gán nhãn chuỗi trong khi cái sau là mô hình tạo sinh văn bản. Hơn nữa, LLMs thường hoạt động dưới mức tối ưu trong các miền không tiêu chuẩn [8], như miền lâm sàng, nơi quan sát thấy khoảng cách lớn giữa các tài liệu tiền huấn luyện và tài liệu mục tiêu.

LLMs có thể được sử dụng để trích xuất đồ thị khái niệm từ văn bản bằng cách trước tiên xác định các khái niệm trong văn bản. Khi các khái niệm đã được xác định, mối quan hệ giữa chúng có thể được trích xuất và đồ thị khái niệm được xây dựng. Trong [9], một đánh giá định lượng và định tính toàn diện về LLMs để xây dựng đồ thị khái niệm được thực hiện, bao gồm nhiều tác vụ như nhận dạng thực thể có tên (NER), trích xuất quan hệ (RE), trích xuất sự kiện (EE) và liên kết thực thể (EL). Các phát hiện cho thấy GPT-4 vượt trội hơn ChatGPT trong phần lớn các tác vụ và thậm chí còn vượt qua các mô hình tinh chỉnh trong một số tác vụ lý luận và trả lời câu hỏi.

LLMs được huấn luyện trên các tập dữ liệu văn bản khổng lồ, và chúng có thể học được ý nghĩa của các từ, cụm từ, và thậm chí cả các khái niệm hoàn chỉnh. Điều này khiến chúng trở thành một công cụ mạnh mẽ cho học khái niệm, đây là quá trình thu thập kiến thức về một khái niệm. Có nhiều cách mà LLMs có thể được sử dụng cho học khái niệm. Một cách là sử dụng chúng để tạo ra các ví dụ về khái niệm đang được học. Cách khác là sử dụng chúng để tạo ra phân phối xác suất trên các ý nghĩa có thể có của khái niệm.

Kiến thức con người bao gồm cả kiến thức biểu tượng (khái niệm) và kiến thức thể hiện (cảm giác). Tuy nhiên, LLMs được huấn luyện với văn bản ngôn ngữ tự nhiên và chỉ có thể biểu diễn kiến thức biểu tượng (khái niệm). Ngược lại, LLMs đa phương thức [11-12] có thể xử lý và tạo sinh văn bản, hình ảnh và các loại dữ liệu khác. Chúng có khả năng biểu diễn toàn bộ phạm vi (khái niệm và cảm giác) của kiến thức con người. LLMs thị giác-ngôn ngữ là những LLMs đa phương thức quan trọng nhất. Chúng tôi thảo luận về hiểu biết khái niệm trong LLMs thị giác-ngôn ngữ cũng như ứng dụng chính của chúng cho CODL bao gồm trích xuất khái niệm từ hình ảnh, trích xuất đồ thị khái niệm từ hình ảnh và học khái niệm.

--- TRANG 3 ---
3
2 Nền tảng

2.1 Học Sâu Định Hướng Khái Niệm (CODL)

Học sâu định hướng khái niệm (CODL) [1] là một phương pháp học máy mở rộng học sâu với các biểu diễn khái niệm và khả năng hiểu biết khái niệm. CODL giải quyết một số hạn chế chính của học sâu, như khả năng giải thích, khả năng chuyển giao, thích ứng theo ngữ cảnh, và yêu cầu nhiều dữ liệu huấn luyện có nhãn. CODL dựa trên ý tưởng rằng các khái niệm là nền tảng của học sâu, hiểu biết và tích hợp cũng như chuyển giao kiến thức của con người.

Các hệ thống CODL được cấu tạo từ ba thành phần chính: đồ thị khái niệm, biểu diễn khái niệm và hệ thống học biểu diễn khái niệm. Đồ thị khái niệm là cơ sở kiến thức chứa thông tin về các khái niệm, chẳng hạn như định nghĩa, tính chất và mối quan hệ của chúng với các khái niệm khác. Biểu diễn khái niệm là các vector chiều thấp biểu diễn ý nghĩa của các khái niệm. Hệ thống học biểu diễn khái niệm học các biểu diễn khái niệm từ dữ liệu, hỗ trợ học tăng cường và học liên tục.

Dưới đây là một số lợi ích của việc sử dụng hệ thống CODL:

• Khả năng giải thích: Hệ thống CODL có thể dễ giải thích hơn các hệ thống học sâu truyền thống vì chúng dựa trên các khái niệm. Các khái niệm là biểu diễn cấp cao của các thực thể và mối quan hệ của chúng, có thể dễ hiểu hơn đối với con người so với các vector chiều thấp.

• Khả năng chuyển giao: Hệ thống CODL có thể chuyển giao tốt hơn các hệ thống học sâu truyền thống vì chúng học các biểu diễn khái niệm không đặc thù cho một tác vụ cụ thể. Điều này có nghĩa là hệ thống CODL có thể được sử dụng cho nhiều tác vụ khác nhau mà không cần phải huấn luyện lại từ đầu.

• Thích ứng theo ngữ cảnh: Hệ thống CODL có thể thích ứng với các tác vụ mới tốt hơn các hệ thống học sâu truyền thống vì chúng có thể sử dụng đồ thị khái niệm để lý luận về ngữ cảnh của tác vụ mới. Điều này cho phép hệ thống CODL tổng quát hóa các tác vụ mới hiệu quả hơn.

• Yêu cầu dữ liệu ít hơn: Hệ thống CODL có thể yêu cầu ít dữ liệu huấn luyện có nhãn hơn các hệ thống học sâu truyền thống vì chúng có thể học các biểu diễn khái niệm từ dữ liệu không nhãn hoặc dữ liệu ví dụ ít. Điều này làm cho hệ thống CODL có khả năng mở rộng và hiệu quả về chi phí hơn.

--- TRANG 4 ---
4
2.2 Biểu Diễn Khái Niệm Thể Hiện-Biểu Tượng Kép (DESCR)

Biểu diễn khái niệm thể hiện-biểu tượng kép (DESCR) [2] là một phương pháp tiếp cận biểu diễn khái niệm kết hợp điểm mạnh của biểu diễn thể hiện và biểu tượng. Biểu diễn thể hiện được căn cứ trên trải nghiệm cảm giác, trong khi biểu diễn biểu tượng dựa trên ngôn ngữ. Mức thể hiện bao gồm các biểu diễn đặc trưng định hướng khái niệm, và mức biểu tượng bao gồm các đồ thị khái niệm. Biểu diễn thể hiện là đặc thù phương thức; biểu diễn biểu tượng là phi phương thức và đặc thù ngôn ngữ.

Đây là cách hình thành biểu diễn DESCR:

1. Biểu diễn thể hiện: Biểu diễn thể hiện được học từ dữ liệu cảm giác, chẳng hạn như hình ảnh và video. Dữ liệu này được xử lý bởi mạng neural để tạo ra biểu diễn của đối tượng hoặc cảnh trong dữ liệu.

2. Biểu diễn biểu tượng: Biểu diễn biểu tượng được học từ văn bản ngôn ngữ. Dữ liệu này được xử lý bởi mô hình ngôn ngữ để tạo ra biểu diễn ý nghĩa của văn bản.

3. Hợp nhất: Biểu diễn thể hiện và biểu tượng được hợp nhất với nhau để tạo ra biểu diễn DESCR. Biểu diễn này nắm bắt cả khía cạnh cảm giác và khái niệm của đối tượng hoặc cảnh.

Biểu diễn DESCR có một số ưu điểm so với biểu diễn học sâu truyền thống:

• Khả năng giải thích: Biểu diễn DESCR dễ giải thích hơn biểu diễn học sâu truyền thống vì chúng cũng được căn cứ trên trải nghiệm cảm giác nhưng được hình thành thêm từ hiểu biết khái niệm (ngôn ngữ). Điều này làm cho con người dễ hiểu hơn về cách hoạt động của biểu diễn DESCR và cách chúng có thể được sử dụng để giải quyết vấn đề.

• Khả năng chuyển giao: Biểu diễn DESCR có khả năng chuyển giao tốt hơn biểu diễn học sâu truyền thống vì chúng được học từ cả dữ liệu cảm giác và thông tin khái niệm. Điều này có nghĩa là biểu diễn DESCR có thể được sử dụng cho nhiều tác vụ khác nhau mà không cần phải huấn luyện lại từ đầu.

• Độ chính xác: Biểu diễn DESCR chính xác hơn biểu diễn học sâu truyền thống đối với nhiều tác vụ khác nhau. Điều này là do biểu diễn DESCR nắm bắt toàn bộ phạm vi (cảm giác và khái niệm) của kiến thức con người, cho phép chúng hiểu thế giới tốt hơn.

--- TRANG 5 ---
5
2.3 Mô Hình Ngôn Ngữ Lớn (LLMs)

Một mô hình ngôn ngữ lớn (LLM) [3-4] là một mô hình học sâu với nhiều tham số (thường là hàng tỷ trọng số trở lên), được huấn luyện trên lượng lớn văn bản không nhãn bằng cách sử dụng học tự giám sát hoặc học bán giám sát. LLMs là các mô hình đa mục đích xuất sắc trong nhiều tác vụ khác nhau, trái ngược với việc được huấn luyện cho một tác vụ cụ thể (chẳng hạn như nhận dạng thực thể có tên, phân tích tình cảm, hoặc phân loại văn bản).

Một số tác vụ và ứng dụng ngôn ngữ tự nhiên phổ biến nhất mà LLMs có thể thực hiện bao gồm:

• Dịch văn bản: LLMs có thể được sử dụng để dịch văn bản từ ngôn ngữ này sang ngôn ngữ khác.
• Tóm tắt văn bản: LLMs có thể được sử dụng để tóm tắt văn bản.
• Tạo sinh văn bản: LLMs có thể được sử dụng để tạo sinh văn bản, chẳng hạn như bài báo hoặc viết sáng tạo.
• Trả lời câu hỏi: LLMs có thể được sử dụng để trả lời câu hỏi về văn bản.
• Chatbot AI: LLMs có thể được sử dụng để tạo chatbot AI có thể tham gia vào cuộc trò chuyện tự nhiên với con người.

LLMs có khả năng thực hiện những tác vụ này, dựa trên kiến thức nội tại được lưu trữ trong các tham số trong quá trình tiền huấn luyện. Tuy nhiên, LLMs không đảm bảo hiểu biết khái niệm cũng như không bảo đảm tính nhất quán khái niệm, điều này có thể dẫn đến việc LLMs tạo ra kết quả sai sự thật. Vấn đề này được thảo luận trong phần tiếp theo.

3 Hiểu Biết Khái Niệm và Tính Nhất Quán Khái Niệm trong LLMs

Một trong những thách thức chính trong việc phát triển LLMs là hiểu biết khái niệm. LLMs cần có khả năng hiểu ý nghĩa của các từ và cụm từ để tạo ra văn bản chính xác và có ý nghĩa. Tuy nhiên, điều này có thể khó khăn, vì nhiều từ và cụm từ có nhiều nghĩa. Ví dụ, từ "Java" có thể chỉ một thương hiệu cà phê, một ngôn ngữ lập trình, hoặc một hòn đảo.

LLMs thường sử dụng nhiều kỹ thuật học sâu khác nhau để hiểu các khái niệm. Một kỹ thuật phổ biến là sử dụng nhúng từ. Nhúng từ là biểu diễn vector của các từ nắm bắt ý nghĩa của chúng. Ví dụ, từ "Java" có thể có nhúng từ tương tự như từ "Python". Điều này cho phép LLMs hiểu mối quan hệ giữa các từ, ngay cả khi chúng có nghĩa khác nhau. Một kỹ thuật phổ biến khác là sử dụng học có giám sát hoặc không giám sát, có thể học mối quan hệ giữa các từ và khái niệm. Điều này cho phép LLMs hiểu ý nghĩa của các từ và cụm từ trong ngữ cảnh.

--- TRANG 6 ---
6
Dưới đây là một số ví dụ về cách hiểu biết khái niệm có thể cải thiện các tác vụ LLM:

• Dịch văn bản: Bằng cách hiểu ý nghĩa của các từ và cụm từ trong cả hai ngôn ngữ, LLMs có thể tạo ra bản dịch chính xác hơn.
• Tạo sinh văn bản: Bằng cách hiểu ý nghĩa của các từ và cụm từ, LLMs có thể tạo ra nội dung mới vừa độc đáo vừa có ý nghĩa.
• Trả lời câu hỏi: Bằng cách hiểu ý nghĩa của các từ và cụm từ, LLMs có thể cung cấp câu trả lời chính xác và toàn diện cho các câu hỏi.

Trong [5], khả năng hiểu các khái niệm của LLMs, đặc biệt là các khái niệm trừu tượng và cụ thể, được khám phá. Nghiên cứu này xây dựng một tập dữ liệu dựa trên WordNet chứa một tập con cho các khái niệm trừu tượng và một tập con cho các khái niệm cụ thể. Nó chọn sáu LLMs và thực hiện một tác vụ NLP cổ điển, khám phá từ thượng vị, như bằng chứng về khả năng hiểu biết của LLMs trong việc hiểu các khái niệm. Kết quả thực nghiệm cho thấy khả năng hiểu của LLM về các khái niệm trừu tượng yếu hơn đáng kể so với các khái niệm cụ thể. Điều này có thể là do các khái niệm trừu tượng khó định nghĩa hơn và thường dựa trên trải nghiệm chủ quan. Ví dụ, khái niệm "tình yêu" khó định nghĩa và có thể có nghĩa khác nhau đối với những người khác nhau.

Tính Nhất Quán Khái Niệm

Tính nhất quán khái niệm là một thước đo về mức độ hiểu biết của LLMs về mối quan hệ giữa các khái niệm. Nó được tính toán bằng cách đo lường tính nhất quán của phản hồi của LLM đối với các truy vấn về các khái niệm có liên quan về mặt khái niệm. Ví dụ, nếu một LLM được hỏi "Núi là gì?" và nó trả lời "Núi là một loài động vật có vú lớn," thì phản hồi của nó không nhất quán về mặt khái niệm. Tính nhất quán khái niệm là một thước đo quan trọng về hiệu suất LLM vì LLMs có tính nhất quán khái niệm cao có nhiều khả năng tạo ra phản hồi chính xác và có ý nghĩa cho các câu hỏi.

Có một số cách để cải thiện tính nhất quán khái niệm của LLMs. Một cách là huấn luyện LLM trên tập dữ liệu bao gồm thông tin về mối quan hệ giữa các khái niệm. Cách khác là sử dụng kỹ thuật được gọi là "kỹ thuật nhắc nhở" để hướng dẫn phản hồi của LLM đối với các câu hỏi. Kỹ thuật nhắc nhở liên quan đến việc cẩn thận tạo ra các câu hỏi được hỏi cho LLM để khơi gợi những phản hồi mong muốn.

--- TRANG 7 ---
7
Dưới đây là một số ví dụ về cách tính nhất quán khái niệm có thể được sử dụng để cải thiện hiệu suất của LLMs:

• Dịch văn bản: Bằng cách hiểu mối quan hệ giữa các khái niệm trong ngôn ngữ nguồn và ngôn ngữ đích, LLMs có thể tạo ra bản dịch chính xác hơn.
• Tạo sinh văn bản: Bằng cách hiểu mối quan hệ giữa các khái niệm, LLMs có thể tạo ra nội dung mới vừa sáng tạo vừa có ý nghĩa.
• Trả lời câu hỏi: Bằng cách hiểu mối quan hệ giữa các khái niệm, LLMs có thể cung cấp câu trả lời vừa chính xác vừa toàn diện.

Để tính toán tính nhất quán khái niệm, [6] trước tiên trích xuất kiến thức nền cho một câu hỏi bằng cách duyệt các đường dẫn giữa các khái niệm trong cơ sở kiến thức. Sau đó, nó sử dụng kiến thức nền này để dự đoán phản hồi của LLM đối với truy vấn neo. Tính nhất quán khái niệm của mô hình được tính toán như độ chính xác của những dự đoán này. Nghiên cứu phát hiện rằng tính nhất quán khái niệm tăng theo quy mô của LLM được sử dụng. Tuy nhiên, các LLMs phổ biến chỉ có mức độ tính nhất quán khái niệm vừa phải. Điều này cho thấy rằng những mô hình này có thể không có hiểu biết sâu sắc về các khái niệm mà chúng có thể trả lời câu hỏi.

3.1 Ví dụ về Chatbot AI

Ví dụ này minh họa tầm quan trọng then chốt của hiểu biết khái niệm và tính nhất quán khái niệm đối với chatbot AI dựa trên LLMs. Trong ví dụ này, chúng tôi cung cấp cùng một lời nhắc cho hai chatbot AI mới và nổi bật, nhưng chỉ một chatbot trả về phản hồi thỏa mãn. Lời nhắc là:

"Mọi người uống Java tại hội thảo Java ở Java. Java đầu tiên là gì, Java thứ hai là gì, và Java thứ ba là gì?"

Chatbot đầu tiên, Bing Chat, trả về phản hồi sau:

"Tôi không chắc ý bạn là gì về Java đầu tiên, Java thứ hai và Java thứ ba. Bạn có thể làm rõ câu hỏi của bạn không?"

Bing Chat không hiểu khái niệm ngôn ngữ tự nhiên về "đồng tham chiếu" và không trả về phản hồi thỏa mãn.

Chatbot thứ hai, Google Bard, trả về phản hồi thỏa mãn và thông minh sau:

"Java đầu tiên là cà phê, Java thứ hai là ngôn ngữ lập trình, và Java thứ ba là hòn đảo ở Indonesia. Cà phê được đặt tên theo hòn đảo, và ngôn ngữ lập trình được đặt tên theo cà phê. Hội thảo là về ngôn ngữ lập trình, và

--- TRANG 8 ---
8
nó đang được tổ chức trên hòn đảo. Vậy nên, mọi người đang uống cà phê tại hội thảo về ngôn ngữ lập trình được đặt tên theo cà phê được đặt tên theo hòn đảo."

Google Bard hiểu khái niệm ngôn ngữ tự nhiên về "đồng tham chiếu" cũng như các khái niệm miền về "cà phê", "ngôn ngữ lập trình" và "hòn đảo", với "Java" là một thể hiện của mỗi khái niệm. Nó hình thành phản hồi dựa trên tính nhất quán khái niệm: "uống Java" với "cà phê Java", "hội thảo Java" với "ngôn ngữ lập trình Java", và "ở Java" với "hòn đảo Java".

4 Trích Xuất Khái Niệm từ Văn Bản với LLMs

LLMs có thể được sử dụng để trích xuất khái niệm, đây là quá trình xác định và trích xuất các khái niệm từ văn bản. LLMs được huấn luyện trên các tập dữ liệu văn bản lớn, cho phép chúng học mối quan hệ giữa các từ và cụm từ. Kiến thức này có thể được sử dụng để xác định các khái niệm trong văn bản mới, ngay cả khi văn bản đó không phải là một phần của tập dữ liệu mà LLM được huấn luyện.

Có nhiều cách để sử dụng LLMs cho việc trích xuất khái niệm. Một cách là sử dụng kỹ thuật được gọi là "nhận dạng thực thể có tên" (NER). NER là quá trình xác định các thực thể có tên trong văn bản, chẳng hạn như người, địa điểm và sự kiện. LLMs có thể được sử dụng để cải thiện độ chính xác của NER bằng cách cung cấp ngữ cảnh bổ sung về văn bản. Cách khác là sử dụng kỹ thuật được gọi là "trích xuất quan hệ" (RE). RE là quá trình xác định mối quan hệ giữa các thực thể trong văn bản. LLMs có thể được sử dụng để cải thiện độ chính xác của RE, một lần nữa, bằng cách cung cấp ngữ cảnh bổ sung về văn bản. LLMs cũng có thể được sử dụng để trích xuất khái niệm theo cách sáng tạo hơn. Ví dụ, một LLM có thể được sử dụng để tạo ra danh sách các khái niệm có thể có cho một đoạn văn bản nhất định. Điều này có thể hữu ích cho các tác vụ như động não và nghiên cứu.

Trong trường hợp kỹ thuật NER, hiệu suất của LLMs trên NER thấp hơn đáng kể so với các phương pháp cơ sở có giám sát. Điều này là do khoảng cách giữa hai tác vụ, NER và LLMs: cái trước về bản chất là tác vụ gán nhãn chuỗi trong khi cái sau là mô hình tạo sinh văn bản. GPT-NER [7] thu hẹp khoảng cách này bằng cách chuyển đổi tác vụ gán nhãn chuỗi NER thành tác vụ tạo sinh có thể dễ dàng được LLMs thích ứng. Tuy nhiên, LLMs có vấn đề ảo giác: chúng có xu hướng mạnh mẽ gán nhãn đầu vào NULL là các thực thể. Để giải quyết hiệu quả vấn đề này, GPT-NER sử dụng chiến lược tự xác minh bằng cách nhắc nhở LLMs tự hỏi liệu các thực thể được trích xuất có thuộc thẻ thực thể được gán nhãn hay không. Các thí nghiệm trên năm tập dữ liệu NER được áp dụng rộng rãi được tiến hành, và GPT-NER đạt được hiệu suất tương đương với các phương pháp cơ sở có giám sát hoàn toàn. Quan trọng hơn, GPT-NER thể hiện khả năng lớn hơn trong các thiết lập ít tài nguyên và few-shot. Khi lượng dữ liệu huấn luyện cực kỳ khan hiếm, GPT-NER hoạt động tốt hơn đáng kể so với các mô hình có giám sát.

--- TRANG 9 ---
9
LLMs thường hoạt động dưới mức tối ưu trong các miền không tiêu chuẩn, như miền lâm sàng, nơi quan sát thấy khoảng cách lớn giữa các tài liệu tiền huấn luyện và tài liệu mục tiêu. LLM CLIN-X (Clinical XLM-R) [8], sử dụng tiền huấn luyện thích ứng miền (lâm sàng), vượt trội hơn các LLMs khác với biên độ lớn đối với mười tác vụ trích xuất khái niệm lâm sàng từ hai ngôn ngữ. Điều này nhấn mạnh tầm quan trọng của các LLMs chuyên biệt, chẳng hạn như CLIN-X, để trích xuất khái niệm trong các miền không tiêu chuẩn.

Dưới đây là một số ví dụ về cách các LLMs chuyên biệt có thể được sử dụng để trích xuất khái niệm:

• Một LLM tài chính có thể được sử dụng để xác định các khái niệm tài chính trong các bài báo. Điều này có thể giúp các nhà đầu tư đưa ra quyết định tài chính tốt hơn.
• Một LLM pháp lý có thể được sử dụng để xác định các khái niệm pháp lý trong các tài liệu pháp lý. Điều này có thể giúp các luật sư chuẩn bị cho các phiên tòa và các thủ tục pháp lý khác.
• Một LLM y tế có thể được sử dụng để xác định các khái niệm y tế trong hồ sơ bệnh nhân. Điều này có thể giúp các bác sĩ chẩn đoán và điều trị bệnh nhân hiệu quả hơn.

4.1 Ví dụ về Chatbot AI

Trong ví dụ được thảo luận trong Phần 3.1 Ví dụ về Chatbot AI, lời nhắc sau được cung cấp:

"Mọi người uống Java tại hội thảo Java ở Java. Java đầu tiên là gì, Java thứ hai là gì, và Java thứ ba là gì?"

Để Google Bard trả về phản hồi thông minh được hiển thị ở đó, nó ngầm trích xuất từ lời nhắc các khái niệm (thể hiện) sau:

• "đồng tham chiếu" ("Java đầu tiên" <-> "(uống) Java", "Java thứ hai" <-> "Java (hội thảo)", "Java thứ ba" <-> "(ở) Java")
• "Mọi người"
• "uống", "cà phê" ("Java")
• "tại", "ngôn ngữ lập trình" ("Java"), "hội thảo"
• "ở", "hòn đảo" ("Java")

--- TRANG 10 ---
10
5 Trích Xuất Đồ Thị Khái Niệm từ Văn Bản với LLMs

LLMs có thể được sử dụng để trích xuất đồ thị khái niệm từ văn bản bằng cách trước tiên xác định các khái niệm trong văn bản. Điều này có thể được thực hiện bằng cách sử dụng nhiều kỹ thuật khác nhau, chẳng hạn như NER được thảo luận trong phần trước. Khi các khái niệm đã được xác định, mối quan hệ giữa chúng có thể được trích xuất bằng cách sử dụng nhiều kỹ thuật khác nhau, chẳng hạn như phân tích cú pháp phụ thuộc và phân giải đồng tham chiếu.

Việc sử dụng LLMs để trích xuất đồ thị khái niệm có một số ưu điểm. Thứ nhất, LLMs có thể được huấn luyện trên lượng lớn dữ liệu văn bản, cho phép chúng học cách xác định và biểu diễn nhiều khái niệm và mối quan hệ. Thứ hai, LLMs có thể được sử dụng để trích xuất đồ thị khái niệm từ văn bản không có cấu trúc tốt, chẳng hạn như văn bản tự do hoặc bài đăng trên mạng xã hội. Hơn nữa, LLMs có thể được sử dụng để trích xuất đồ thị khái niệm từ văn bản bằng nhiều ngôn ngữ khác nhau.

Đồ thị khái niệm có thể được sử dụng cho nhiều ứng dụng LLM khác nhau, chẳng hạn như:

• Xử lý ngôn ngữ tự nhiên: Đồ thị khái niệm có thể được sử dụng để cải thiện hiệu suất của các tác vụ xử lý ngôn ngữ tự nhiên (NLP), chẳng hạn như dịch văn bản, tóm tắt văn bản và phân tích tình cảm. Ví dụ, một LLM có thể được sử dụng để trích xuất đồ thị khái niệm từ một tài liệu. Đồ thị khái niệm sau đó có thể được sử dụng để cải thiện hiệu suất của việc dịch văn bản đang dịch tài liệu sang ngôn ngữ khác.

• Trả lời câu hỏi: Đồ thị khái niệm có thể được sử dụng để trả lời câu hỏi về văn bản. Ví dụ, một LLM có thể được sử dụng để trích xuất đồ thị khái niệm từ một cuốn sách. Đồ thị khái niệm sau đó có thể được sử dụng để trả lời câu hỏi về cuốn sách, chẳng hạn như "Mối quan hệ của các nhân vật chính là gì?"

• Khám phá kiến thức: Đồ thị khái niệm có thể được sử dụng để khám phá kiến thức mới từ văn bản. Ví dụ, một LLM có thể được sử dụng để trích xuất đồ thị khái niệm từ một tập hợp các bài báo khoa học. Đồ thị khái niệm sau đó có thể được sử dụng để xác định các mối quan hệ mới giữa các khái niệm, có thể dẫn đến những khám phá mới.

Trong [9], một đánh giá định lượng và định tính toàn diện về LLMs để xây dựng và lý luận Đồ thị Kiến thức (KG), tức là đồ thị khái niệm, được thực hiện. Thông thường, việc xây dựng KG bao gồm một số tác vụ, bao gồm nhận dạng thực thể có tên (NER), trích xuất quan hệ (RE), trích xuất sự kiện (EE), và liên kết thực thể (EL); lý luận KG đề cập đến dự đoán liên kết (LP). Công trình này điều tra khả năng ứng dụng tiềm năng của LLMs, được minh họa bởi ChatGPT và GPT-4, trong các tác vụ xây dựng KG và lý luận KG. Cụ thể, nó điều tra hiệu suất zero-shot và one-shot của LLMs trên việc trích xuất thực thể, quan hệ và sự kiện, dự đoán liên kết, và trả lời câu hỏi để đánh giá các ứng dụng tiềm năng của LLMs trong miền KG

--- TRANG 11 ---
11
miền. Các phát hiện cho thấy GPT-4 vượt trội hơn ChatGPT trong phần lớn các tác vụ và thậm chí còn vượt qua các mô hình tinh chỉnh trong một số tác vụ lý luận và trả lời câu hỏi.

5.1 Ví dụ về Chatbot AI

Trong Google Bard, đồ thị khái niệm có thể được trích xuất dưới dạng "đồ thị khái niệm", "đồ thị kiến thức" hoặc "ontology". Một đồ thị khái niệm bao gồm các khái niệm (nút, với thuộc tính) và quan hệ (cạnh). Một đồ thị kiến thức bao gồm các thực thể (nút, với thuộc tính) và mối quan hệ (cạnh), biểu diễn kiến thức (thực tế và khái niệm) về thế giới. Một ontology bao gồm các danh mục, thực thể, quan hệ và tiên đề, xác định khái niệm hóa chính thức của một miền.

Ví dụ sử dụng lời nhắc định hướng khái niệm tập trung vào hiểu biết khái niệm.

Đồ thị Khái niệm

Việc trích xuất đồ thị khái niệm bắt đầu với việc xác định khái niệm. Lời nhắc ban đầu được sử dụng là:

Mọi người uống Java tại hội thảo Java ở Java. Xin hãy xác định các khái niệm có liên quan.

Bard phản hồi:

Các khái niệm có liên quan trong câu "Mọi người uống Java tại hội thảo Java ở Java" là:

• Ẩn dụ: Từ "Java" được sử dụng để chỉ cả ngôn ngữ lập trình và đồ uống cà phê. Đây là một ví dụ về ẩn dụ, một hình thức tu từ trong đó một điều được so sánh với một điều khác.

• Đa nghĩa: Từ "Java" có nhiều nghĩa. Trong trường hợp này, nó được sử dụng để chỉ cả ngôn ngữ lập trình và đồ uống cà phê. Đây là một ví dụ về đa nghĩa, một hiện tượng ngôn ngữ trong đó một từ có nhiều nghĩa.

• Chơi chữ: Câu này là một cách chơi chữ, vì nó sử dụng nhiều nghĩa của từ "Java" để tạo ra hiệu ứng hài hước.

Vì trọng tâm của chúng tôi là các khái niệm thế giới, không phải khái niệm ngôn ngữ, chúng tôi sửa đổi lời nhắc thành:

Mọi người uống Java tại hội thảo Java ở Java. Xin hãy xác định các khái niệm thế giới có liên quan.

Bard sau đó phản hồi:

Chắc chắn, đây là các khái niệm thế giới có liên quan trong câu "Mọi người uống Java tại hội thảo Java ở Java":

• Java: Đây là tên của ngôn ngữ lập trình mà hội thảo bàn về. Nó cũng là tên của một đồ uống cà phê.

--- TRANG 12 ---
12
• Hội thảo: Đây là một cuộc gặp gỡ của những người có cùng sở thích. Trong trường hợp này, sở thích chung là Java.
• Uống: Đây là hành động tiêu thụ chất lỏng. Trong trường hợp này, chất lỏng là cà phê Java.
• Địa điểm: Đây là vị trí của hội thảo. Trong trường hợp này, hội thảo ở Java, là một vùng trồng cà phê ở Indonesia.

Tuy nhiên, phản hồi thiếu thông tin rằng Java cũng là một hòn đảo. Chúng tôi bổ sung lời nhắc với thông tin còn thiếu:

Java cũng là một hòn đảo. Xin hãy cập nhật các khái niệm thế giới có liên quan trong câu gốc.

Bard phản hồi bằng cách thêm thông tin còn thiếu:

Chắc chắn, đây là các khái niệm thế giới có liên quan trong câu "Mọi người uống Java tại hội thảo Java ở Java" sau khi chúng ta tính đến rằng Java cũng là một hòn đảo:

• Java: Đây là tên của ngôn ngữ lập trình mà hội thảo bàn về. Nó cũng là tên của một đồ uống cà phê, và nó cũng là tên của một hòn đảo ở Indonesia.
• Hội thảo: Đây là một cuộc gặp gỡ của những người có cùng sở thích. Trong trường hợp này, sở thích chung là Java.
• Uống: Đây là hành động tiêu thụ chất lỏng. Trong trường hợp này, chất lỏng có thể là cà phê Java hoặc cà phê Java, là một loại cà phê được trồng trên hòn đảo Java.
• Địa điểm: Đây là vị trí của hội thảo. Trong trường hợp này, hội thảo có thể được tổ chức trên hòn đảo Java, hoặc có thể được tổ chức trong một quán cà phê ở Java.

"Mọi người" còn thiếu từ danh sách các khái niệm. Chúng tôi bổ sung lời nhắc với khái niệm còn thiếu:

Bạn đã bỏ lỡ mọi người. Xin hãy cập nhật các khái niệm thế giới có liên quan trong câu gốc.

Bard phản hồi bằng cách thêm khái niệm còn thiếu:

Bạn nói đúng, tôi đã bỏ lỡ mọi người. Đây là các khái niệm thế giới có liên quan trong câu "Mọi người uống Java tại hội thảo Java ở Java", bao gồm cả mọi người:

• Mọi người: Đây là nhóm con người tham dự hội thảo.
• Java: Đây là tên của ngôn ngữ lập trình mà hội thảo bàn về. Nó cũng là tên của một đồ uống cà phê, và nó cũng là tên của một hòn đảo ở Indonesia.
• Hội thảo: Đây là một cuộc gặp gỡ của những người có cùng sở thích. Trong trường hợp này, sở thích chung là Java.
• Uống: Đây là hành động tiêu thụ chất lỏng. Trong trường hợp này, chất lỏng có thể là cà phê Java hoặc cà phê Java, là một loại cà phê được trồng trên hòn đảo Java.
• Địa điểm: Đây là vị trí của hội thảo. Trong trường hợp này, hội thảo có thể được tổ chức trên hòn đảo Java, hoặc có thể được tổ chức trong một quán cà phê ở Java.

Bây giờ, chúng ta sẵn sàng tạo đồ thị khái niệm với lời nhắc:

Với các khái niệm đã xác định, xin hãy tạo đồ thị khái niệm cho câu gốc.

--- TRANG 13 ---
13
Đây là phản hồi của Bard:

Chắc chắn, đây là đồ thị khái niệm cho câu gốc "Mọi người uống Java tại hội thảo Java ở Java":

Mọi người --> uống --> Java
Java --> ngôn ngữ lập trình
Java --> đồ uống cà phê
Java --> hòn đảo ở Indonesia
Hội thảo --> cuộc gặp gỡ của mọi người
Hội thảo --> về Java
Địa điểm --> vị trí của hội thảo
Địa điểm --> hòn đảo Java

Đồ thị Kiến thức

Lời nhắc ban đầu được sử dụng để trích xuất đồ thị kiến thức là:

Mọi người uống Java tại hội thảo Java ở Java. Xin hãy tạo đồ thị kiến thức.

Bard trả về phản hồi sau:

Chắc chắn, đây là đồ thị kiến thức:

* **Thực thể:** Hội thảo Java
    * **Thuộc tính:**
        * Vị trí: Java
        * Chủ đề: Java
        * Người tham gia: Các nhà phát triển Java
    * **Mối quan hệ:**
        * Có người tham dự: Mọi người
        * Phục vụ đồ uống: Java
* **Thực thể:** Mọi người
    * **Thuộc tính:**
        * Uống: Java
    * **Mối quan hệ:**
        * Tham dự hội thảo Java
* **Thực thể:** Java
    * **Thuộc tính:**
        * Một ngôn ngữ lập trình
        * Một đồ uống
    * **Mối quan hệ:**
        * Là chủ đề của hội thảo Java
        * Được uống bởi mọi người tại hội thảo Java

Vì phản hồi thiếu thông tin rằng Java cũng là một hòn đảo, chúng tôi bổ sung lời nhắc với thông tin còn thiếu:

Java cũng là một hòn đảo. Xin hãy tạo lại đồ thị kiến thức.

Bard sửa đổi phản hồi bằng cách thêm thông tin còn thiếu:

--- TRANG 14 ---
14
Chắc chắn, đây là đồ thị kiến thức đã cập nhật:

* **Thực thể:** Hội thảo Java
    * **Thuộc tính:**
        * Vị trí: hòn đảo Java
        * Chủ đề: Java
        * Người tham gia: Các nhà phát triển Java
    * **Mối quan hệ:**
        * Có người tham dự: Mọi người
        * Phục vụ đồ uống: Java (đồ uống)
* **Thực thể:** Mọi người
    * **Thuộc tính:**
        * Uống: Java (đồ uống)
    * **Mối quan hệ:**
        * Tham dự hội thảo Java
* **Thực thể:** Java
    * **Thuộc tính:**
        * Một ngôn ngữ lập trình
        * Một đồ uống
        * Một hòn đảo
    * **Mối quan hệ:**
        * Là chủ đề của hội thảo Java
        * Được uống bởi mọi người tại hội thảo Java
        * Là vị trí của hội thảo Java

Ontology

Lời nhắc được sử dụng để trích xuất ontology là:

Mọi người uống Java tại hội thảo Java ở Java. Xin hãy tạo ontology.

Bard trả về phản hồi sau:

Chắc chắn, đây là ontology cho câu "Mọi người uống Java tại hội thảo Java ở Java":

Ontology: Ontology Hội thảo Java

Lớp:

* Người
* Hội thảo Java
* Java

Thuộc tính Đối tượng:

* uống
* tham dự
* nằm ở

Thuộc tính Dữ liệu:

* tên

--- TRANG 15 ---
15
* ngày
* vị trí

Cá thể:

* John Doe: một Người
* JavaOne: một Hội thảo Java
* ngôn ngữ lập trình Java: một Java

Thông tin:

* John Doe uống Java tại JavaOne.
* JavaOne nằm ở Java.

Ontology này nắm bắt thông tin sau về câu:

• Mọi người là cá thể của lớp Người.
• Hội thảo Java là cá thể của lớp Hội thảo Java.
• Java là một ngôn ngữ lập trình và là cá thể của lớp Java.
• Hành động uống Java là một thể hiện của thuộc tính đối tượng uống.
• Hành động tham dự hội thảo Java là một thể hiện của thuộc tính đối tượng tham dự.
• Vị trí của hội thảo Java là một thể hiện của thuộc tính đối tượng nằm ở.

Tên, ngày và vị trí của hội thảo Java là các thuộc tính dữ liệu.

6 LLMs cho Học Khái niệm

LLMs được huấn luyện trên các tập dữ liệu văn bản khổng lồ, và chúng có thể học được ý nghĩa của các từ, cụm từ, và thậm chí cả các khái niệm hoàn chỉnh. Điều này khiến chúng trở thành một công cụ mạnh mẽ cho học khái niệm, đây là quá trình thu thập kiến thức về một khái niệm.

Có một số cách mà LLMs có thể được sử dụng cho học khái niệm. Một cách là sử dụng chúng để tạo ra các ví dụ về khái niệm đang được học. Ví dụ, nếu bạn đang cố gắng học khái niệm "chó", bạn có thể sử dụng LLM để tạo ra danh sách các câu chứa từ "chó". Cách khác là sử dụng chúng để tạo ra phân phối xác suất trên các ý nghĩa có thể có của khái niệm. Ví dụ, nếu bạn đang cố gắng học khái niệm "tình yêu", bạn có thể sử dụng LLM để tạo ra phân phối xác suất trên các ý nghĩa có thể có của từ "tình yêu".

LLMs có một số ưu điểm cho học khái niệm. Thứ nhất, chúng có thể được sử dụng để học ý nghĩa của các khái niệm khó hoặc không thể định nghĩa theo cách truyền thống. Thứ hai, chúng có thể được sử dụng để học ý nghĩa của các khái niệm từ văn bản không được gán nhãn rõ ràng với ý nghĩa của khái niệm. Thứ ba, chúng có thể được sử dụng để học ý nghĩa của các khái niệm từ văn bản nhiễu hoặc không đầy đủ. Cuối cùng, chúng có thể được sử dụng để học ý nghĩa của các khái niệm bằng nhiều ngôn ngữ và dịch giữa chúng.

--- TRANG 16 ---
16
Như các ví dụ cho học khái niệm, LLMs có thể được sử dụng để:

• Xác định và phân loại các khái niệm. LLMs có thể được huấn luyện trên tập dữ liệu văn bản bao gồm các ví dụ về các khái niệm khác nhau. Sau đó chúng có thể được sử dụng để xác định và phân loại các thể hiện mới của những khái niệm đó.

• Học mối quan hệ giữa các khái niệm. LLMs có thể được huấn luyện trên tập dữ liệu văn bản bao gồm các ví dụ về cách các khái niệm khác nhau liên quan với nhau. Sau đó chúng có thể được sử dụng để học mối quan hệ giữa các thể hiện mới của những khái niệm đó.

• Tạo ra các khái niệm mới. LLMs có thể được sử dụng để tạo ra các khái niệm mới bằng cách kết hợp các khái niệm hiện có theo những cách mới. Điều này có thể hữu ích cho các tác vụ như động não, nghiên cứu, hoặc tạo ra văn bản sáng tạo.

Trong [10], một LLM được sử dụng để mô hình hóa việc học các khái niệm biểu tượng trừu tượng bằng cách thực hiện suy luận Bayes trên các phát ngôn bằng ngôn ngữ tự nhiên. Công trình này sử dụng LLM như một phân phối đề xuất, khớp tiền nghiệm với dữ liệu con người để mô hình hóa tốt hơn những người học con người, và đánh giá trên cả các khái niệm sinh tạo và logic. Mô hình học khái niệm biểu tượng thể hiện các khái niệm của nó bằng ngôn ngữ tự nhiên, ngay cả khi bài toán học không liên quan đến ngôn ngữ tự nhiên, vì hai lý do. Thứ nhất, ngôn ngữ là một biểu diễn hiệu quả cho nhiều khái niệm con người. Nó có tính tổ hợp, biểu cảm phong phú, và điều hòa người học hướng tới các tổng quát hóa tự nhiên. Thứ hai, LLMs có thể được sử dụng để suy luận hiệu quả các khái niệm ngôn ngữ tự nhiên.

7 LLMs Đa phương thức cho Khái niệm Đa phương thức (Biểu tượng-Thể hiện Kép)

Kiến thức con người bao gồm cả kiến thức biểu tượng (khái niệm) và kiến thức thể hiện (cảm giác), như đã thảo luận trong Phần 2.2 Biểu Diễn Khái Niệm Thể Hiện-Biểu Tượng Kép (DESCR). Tuy nhiên, LLMs được huấn luyện với văn bản ngôn ngữ tự nhiên và chỉ có thể biểu diễn kiến thức biểu tượng (khái niệm). Ngược lại, LLMs đa phương thức [11-12] có thể xử lý và tạo sinh văn bản, hình ảnh và các loại dữ liệu khác. Chúng được huấn luyện trên các tập dữ liệu đa phương thức khổng lồ, cho phép chúng học mối quan hệ giữa các phương thức khác nhau. Điều này khiến chúng có khả năng thực hiện các tác vụ không thể có được đối với LLMs chỉ văn bản, chẳng hạn như mô tả hình ảnh và tạo phụ đề cho video. Do đó, LLMs đa phương thức có khả năng biểu diễn toàn bộ phạm vi (khái niệm và cảm giác) của kiến thức con người.

Dưới đây là một số lợi ích của việc sử dụng LLMs đa phương thức:

• Trải nghiệm người dùng nâng cao: LLMs đa phương thức có thể tạo ra trải nghiệm người dùng thực tế và hấp dẫn hơn bằng cách kết hợp dữ liệu cảm giác vào đầu ra của chúng.

--- TRANG 17 ---
17
• Tăng độ chính xác: LLMs đa phương thức có thể học mối quan hệ giữa các phương thức khác nhau, cho phép chúng đưa ra dự đoán chính xác hơn và tạo ra đầu ra thực tế hơn.

• Tăng tính sáng tạo: LLMs đa phương thức có thể tạo ra các ý tưởng và khái niệm mới bằng cách kết hợp thông tin từ các phương thức khác nhau.

• Cải thiện hiệu suất: LLMs đa phương thức có thể thực hiện các tác vụ không thể có được đối với LLMs chỉ văn bản, chẳng hạn như mô tả hình ảnh và tạo phụ đề cho video.

7.1 LLMs Thị giác-Ngôn ngữ

LLMs thị giác-ngôn ngữ là những LLMs đa phương thức quan trọng nhất. Trong những năm gần đây, đã có sự quan tâm ngày càng tăng đối với việc sử dụng LLMs cho các tác vụ thị giác-ngôn ngữ. Những tác vụ này liên quan đến việc hiểu mối quan hệ giữa văn bản và hình ảnh, và sử dụng hiểu biết này để thực hiện các tác vụ như:

• Tạo phụ đề hình ảnh: LLMs có thể được sử dụng để tạo phụ đề cho hình ảnh. Điều này có thể hữu ích cho những người muốn nhanh chóng hiểu nội dung của hình ảnh.

• Tổng hợp văn bản thành hình ảnh: LLMs có thể được sử dụng để tổng hợp hình ảnh từ mô tả văn bản. Điều này có thể được sử dụng cho các ứng dụng sáng tạo, chẳng hạn như tạo nghệ thuật.

• Trả lời câu hỏi thị giác: LLMs có thể được sử dụng để trả lời câu hỏi về hình ảnh. Điều này có thể hữu ích cho những người muốn tìm hiểu thêm về hình ảnh.

Có một số ưu điểm khi sử dụng LLMs cho các tác vụ thị giác-ngôn ngữ. Thứ nhất, LLMs đã được huấn luyện trên các tập dữ liệu văn bản khổng lồ, mang lại cho chúng hiểu biết sâu sắc về cả ngôn ngữ và thế giới. Thứ hai, LLMs có thể học các phụ thuộc tầm xa giữa các từ và khái niệm, điều này rất cần thiết để hiểu mối quan hệ giữa văn bản và hình ảnh. Thứ ba, LLMs có thể tạo ra văn bản sáng tạo và thông tin, điều này hữu ích cho các tác vụ như tạo phụ đề hình ảnh.

Hiểu biết Khái niệm trong LLMs Thị giác-Ngôn ngữ

LLMs thị giác-ngôn ngữ đã đạt được thành công lớn trong nhiều tác vụ downstream, chẳng hạn như tạo phụ đề hình ảnh, trả lời câu hỏi hình ảnh và đối thoại thị giác. Tuy nhiên, không rõ liệu những mô hình này có hiểu biết khái niệm về nội dung mà chúng đang xử lý hay không. Trong [13], một khung mới để khảo sát và cải thiện hiểu biết khái niệm của LLMs thị giác-ngôn ngữ được đề xuất. Công trình này giới thiệu một tập dữ liệu benchmark mới để khảo sát ba khía cạnh của hiểu biết khái niệm về một hình ảnh:

--- TRANG 18 ---
18
• Hiểu biết quan hệ: Khả năng hiểu mối quan hệ giữa các thực thể trong hình ảnh.

• Hiểu biết tổ hợp: Khả năng hiểu cách các thực thể trong hình ảnh có thể được kết hợp để tạo thành các khái niệm mới.

• Hiểu biết ngữ cảnh: Khả năng hiểu cách ngữ cảnh của hình ảnh có thể ảnh hưởng đến việc giải thích nội dung của nó.

Nghiên cứu phát hiện rằng LLMs thị giác-ngôn ngữ có thể đạt được hiệu suất tốt trong các tác vụ yêu cầu hiểu biết quan hệ, chẳng hạn như trả lời câu hỏi hình ảnh. Tuy nhiên, chúng kém thành công hơn trong các tác vụ yêu cầu hiểu biết tổ hợp và ngữ cảnh, chẳng hạn như tạo câu hỏi thị giác. Điều này cho thấy rằng LLMs thị giác-ngôn ngữ có thể không có hiểu biết sâu sắc về nội dung mà chúng đang xử lý.

Trích Xuất Khái niệm từ Văn bản và Hình ảnh với LLMs Thị giác-Ngôn ngữ

Trích xuất khái niệm là quá trình xác định và trích xuất các khái niệm từ văn bản hoặc hình ảnh. Đây là một tác vụ thách thức, vì các khái niệm có thể được biểu diễn theo nhiều cách khác nhau, cả trong văn bản và hình ảnh. Trích xuất khái niệm từ văn bản đã được thảo luận trong Phần 4 Trích Xuất Khái niệm từ Văn bản với LLMs.

LLMs thị giác-ngôn ngữ có thể được sử dụng để trích xuất khái niệm từ hình ảnh theo một số cách. Một cách là sử dụng LLM để tạo ra mô tả ngôn ngữ tự nhiên về hình ảnh. Mô tả này sau đó có thể được phân tích để xác định các khái niệm có trong hình ảnh. Cách khác là sử dụng LLM để trả lời câu hỏi về hình ảnh. Các câu hỏi được hỏi có thể được thiết kế để khơi gợi thông tin về các khái niệm cụ thể. Ví dụ, một câu hỏi như "Đối tượng ở tiền cảnh là gì?" có thể được sử dụng để trích xuất khái niệm "đối tượng" từ hình ảnh. Cuối cùng, cả hai cách có thể được kết hợp bằng cách sử dụng LLM để tạo ra mô tả ngôn ngữ tự nhiên về hình ảnh, và sau đó sử dụng LLM để trả lời câu hỏi về hình ảnh. Sự kết hợp của mô tả ngôn ngữ tự nhiên và câu trả lời cho các câu hỏi sau đó có thể được sử dụng để xác định các khái niệm có trong hình ảnh.

Dưới đây là một số ví dụ về cách trích xuất khái niệm từ hình ảnh có thể được sử dụng trong các ứng dụng thực tế:

• Tìm kiếm hình ảnh: Trích xuất khái niệm có thể được sử dụng để cải thiện độ chính xác của tìm kiếm hình ảnh. Bằng cách xác định các khái niệm có trong hình ảnh, LLMs thị giác-ngôn ngữ có thể giúp khớp hình ảnh với kết quả tìm kiếm có liên quan.

--- TRANG 19 ---
19
• Trợ lý ảo: Trích xuất khái niệm có thể được sử dụng để cải thiện khả năng của trợ lý ảo. Bằng cách hiểu các khái niệm có trong truy vấn của người dùng với hình ảnh, trợ lý ảo có thể cung cấp phản hồi có liên quan và thông tin hơn.

Trích Xuất Đồ Thị Khái niệm từ Văn bản và Hình ảnh với LLMs Thị giác-Ngôn ngữ

Trích xuất đồ thị khái niệm là tác vụ trích xuất một đồ thị các khái niệm từ văn bản hoặc hình ảnh. Trích xuất đồ thị khái niệm từ văn bản đã được thảo luận trong Phần 5 Trích Xuất Đồ Thị Khái niệm từ Văn bản với LLMs.

Có một số phương pháp tiếp cận khác nhau để trích xuất đồ thị khái niệm từ hình ảnh, bao gồm:

• Phương pháp tiếp cận dựa trên văn bản: Những phương pháp này sử dụng các kỹ thuật xử lý ngôn ngữ tự nhiên để trích xuất các khái niệm từ văn bản liên quan đến hình ảnh.

• Phương pháp tiếp cận dựa trên hình ảnh: Những phương pháp này sử dụng các kỹ thuật thị giác máy tính để trích xuất các khái niệm từ chính hình ảnh.

• Phương pháp tiếp cận kết hợp: Những phương pháp này kết hợp các phương pháp tiếp cận dựa trên văn bản và dựa trên hình ảnh để trích xuất các khái niệm từ cả hình ảnh và văn bản liên quan.

Trích xuất đồ thị khái niệm từ hình ảnh có thể được sử dụng cho nhiều tác vụ khác nhau, chẳng hạn như:

• Hiểu hình ảnh: Đồ thị khái niệm có thể được sử dụng để biểu diễn cấu trúc khái niệm của hình ảnh, sau đó có thể được sử dụng để hiểu ý nghĩa của hình ảnh.

• Trả lời câu hỏi thị giác: Đồ thị khái niệm có thể được sử dụng để biểu diễn cấu trúc khái niệm của câu hỏi liên quan đến hình ảnh, sau đó có thể được sử dụng để trả lời câu hỏi.

• Đối thoại thị giác: Đồ thị khái niệm có thể được sử dụng để biểu diễn cấu trúc khái niệm của cuộc đối thoại liên quan đến hình ảnh, sau đó có thể được sử dụng để tạo ra cuộc đối thoại tự nhiên và hấp dẫn hơn.

LLMs Thị giác-Ngôn ngữ cho Học Khái niệm

LLMs thị giác-ngôn ngữ có thể được sử dụng cho học khái niệm theo một số cách, bao gồm:

--- TRANG 20 ---
20
• Học về các khái niệm mới: LLMs thị giác-ngôn ngữ có thể được sử dụng để học về các khái niệm mới bằng cách tạo ra các ví dụ về các khái niệm. Ví dụ, một LLM thị giác-ngôn ngữ có thể tạo ra một tập hợp hình ảnh về chó để học về khái niệm "chó".

• Khám phá mối quan hệ giữa các khái niệm: LLMs thị giác-ngôn ngữ có thể được sử dụng để khám phá mối quan hệ giữa các khái niệm bằng cách hỏi chúng các câu hỏi về các khái niệm. Ví dụ, một LLM thị giác-ngôn ngữ có thể được hỏi "Sự khác biệt giữa chó và mèo là gì?" và có thể tạo ra một tập hợp hình ảnh đối lập về chó và mèo để học về sự khác biệt.

• Tạo ra các khái niệm mới: LLMs thị giác-ngôn ngữ có thể được sử dụng để tạo ra các khái niệm mới bằng cách kết hợp các khái niệm hiện có theo những cách mới. Ví dụ, một LLM thị giác-ngôn ngữ có thể được sử dụng để tạo ra khái niệm "một con chó đeo mũ" bằng cách kết hợp các khái niệm "chó" và "mũ" và tạo ra hình ảnh ví dụ về khái niệm mới. Điều này có thể hữu ích cho các tác vụ như động não, nghiên cứu, hoặc tạo ra văn bản sáng tạo.

Dưới đây là một số lợi ích của việc sử dụng LLMs thị giác-ngôn ngữ cho học khái niệm:

• Chúng có thể học từ các tập dữ liệu lớn và đa dạng: LLMs thị giác-ngôn ngữ có thể được huấn luyện trên các tập dữ liệu lớn và đa dạng về văn bản và hình ảnh, cho phép chúng học về nhiều khái niệm khác nhau.

• Chúng có thể học về các khái niệm theo cách đa phương thức: LLMs thị giác-ngôn ngữ có thể học về các khái niệm bằng cách kết hợp cả văn bản và hình ảnh, mang lại cho chúng hiểu biết đầy đủ hơn về các khái niệm.

8 Kết luận

Với hiểu biết khái niệm và tính nhất quán khái niệm, LLMs là những hệ thống học biểu diễn khái niệm xuất sắc, mặc dù ngầm định, có thể học các biểu diễn khái niệm biểu tượng (khái niệm) từ văn bản và hỗ trợ học tăng cường và học liên tục. Hơn nữa, LLMs đa phương thức có thể (ngầm định) học các biểu diễn khái niệm đa phương thức (biểu tượng-thể hiện kép) và do đó nắm bắt toàn bộ phạm vi (khái niệm và cảm giác) của kiến thức con người.

Như vậy, LLMs là một công nghệ mới đầy hứa hẹn cho CODL. Chúng có thể được sử dụng cho các tác vụ CODL chính bao gồm trích xuất khái niệm từ văn bản, trích xuất đồ thị khái niệm từ văn bản và học khái niệm. Hơn nữa, LLMs thị giác-ngôn ngữ (những LLMs đa phương thức quan trọng nhất) có thể được sử dụng cho CODL bao gồm trích xuất khái niệm từ hình ảnh, trích xuất đồ thị khái niệm từ hình ảnh và học khái niệm. Trong khi các ứng dụng của LLMs cho CODL có giá trị độc lập, chúng đặc biệt có giá trị như một phần của các ứng dụng LLM như chatbot AI.

--- TRANG 21 ---
21
Lời cảm ơn: Cảm ơn vợ tôi Hedy (郑期芳) vì sự hỗ trợ của cô ấy.

Tài liệu tham khảo

[1] Daniel T. Chang, "Concept-Oriented Deep Learning," arXiv preprint arXiv:1806.01756 (2018).

[2] Daniel T. Chang, "Dual Embodied-Symbolic Concept Representations for Deep Learning," arXiv preprint arXiv:2203.00600 (2022).

[3] M. Mars, "From Word Embeddings to Pre-Trained Language Models: A State-of-the-Art Walkthrough." in Applied Sciences, 2022. 12(17): p. 8805.

[4] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen, "A Survey of Large Language Models," arXiv preprint arXiv:2303.18223 (2023).

[5] J. Liao, X. Chen, and L. Du, "Concept Understanding in Large Language Models: An Empirical Study," in ICLR 2023.

[6] Pritish Sahu, Michael Cogswell, Yunye Gong, and Ajay Divakaran, "Unpacking Large Language Models with Conceptual Consistency," arXiv preprint arXiv:2209.15093 (2022).

[7] Shuhe Wang, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei Zhang, Jiwei Li, and Guoyin Wang, "GPT-NER: Named Entity Recognition via Large Language Models," arXiv preprint arXiv:2304.10428 (2023).

[8] Lukas Lange, Heike Adel, Jannik Strötgen, and Dietrich Klakow, "CLIN-X: Pre-trained Language Models and a Study on Cross-task Transfer for Concept Extraction in the Clinical Domain," arXiv preprint arXiv:2112.08754 (2022).

[9] Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, and Ningyu Zhang, "LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities," arXiv preprint arXiv:2305.13168 (2023).

[10] Kevin Ellis, "Modeling Human-like Concept Learning with Bayesian Inference over Natural Language," arXiv preprint arXiv:2306.02797 (2023).

[11] Chunyuan Li, "Large Multimodal Models: Notes on CVPR 2023 Tutorial," arXiv preprint arXiv:2306.14895 (2023).

[12] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen, "A Survey on Multimodal Large Language Models," arXiv preprint arXiv:2306.13549 (2023).

[13] Madeline Chantry Schiappa, Michael Cogswell, Ajay Divakaran, and Yogesh Singh Rawat, "Probing Conceptual Understanding of Large Visual-Language Models," arXiv preprint arXiv:2304.03659 (2023).

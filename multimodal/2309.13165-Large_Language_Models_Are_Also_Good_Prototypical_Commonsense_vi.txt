# 2309.13165.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2309.13165.pdf
# Kích thước tệp: 713482 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Các Mô Hình Ngôn Ngữ Lớn Cũng Là Những Người Lý Luận Tri Thức Thông Thường Nguyên Mẫu Tốt
Chenglin Li1,2†, Qianglong Chen1†, Yin Zhang1‡, Yifei Zhang2, Hongxiang Yao3
1Đại học Chiết Giang, 2Đại học Northeastern, 3Tập đoàn Ant
{22351307, chenqianglong, zhangyin98}@zju.edu.cn,
zhangyifei@cse.neu.edu.cn, feiyu.fyyu@gmail.com

Tóm tắt
Lý luận tri thức thông thường là một kỹ năng then chốt đối với các mô hình ngôn ngữ lớn, tuy nhiên nó đặt ra những thách thức dai dẳng trong các tác vụ cụ thể yêu cầu năng lực này. Các phương pháp tinh chỉnh truyền thống có thể tốn nhiều tài nguyên và có khả năng làm tổn hại khả năng khái quát hóa của mô hình. Hơn nữa, các mô hình ngôn ngữ tiên tiến nhất như GPT-3.5 và Claude chủ yếu có thể truy cập thông qua các lời gọi API, điều này khiến việc tinh chỉnh mô hình trở nên khó khăn. Để giải quyết những thách thức này, chúng tôi lấy cảm hứng từ các kết quả đầu ra của các mô hình lớn cho các tác vụ được điều chỉnh và phát triển bán tự động một bộ các lời nhắc mới từ nhiều góc độ, bao gồm tính liên quan đến tác vụ, tạo ra bằng chứng hỗ trợ (ví dụ như chuỗi suy nghĩ và tri thức), giải mã đường dẫn đa dạng để hỗ trợ mô hình. Kết quả thực nghiệm trên bộ dữ liệu ProtoQA chứng minh rằng với các lời nhắc được thiết kế tốt hơn, chúng tôi có thể đạt được trạng thái nghệ thuật (SOTA) mới trên bảng xếp hạng ProtoQA, cải thiện điểm Max Answer@1 thêm 8%, điểm Max Incorrect@1 thêm 4% (vượt qua 50% lần đầu tiên) so với mô hình SOTA trước đó và đạt được cải thiện trên StrategyQA và CommonsenseQA2.0 (lần lượt là 3% và 1%). Hơn nữa, với Chuỗi Suy Nghĩ và tri thức được tạo ra, chúng tôi có thể cải thiện khả năng diễn giải của mô hình đồng thời vượt qua các mô hình SOTA trước đó. Chúng tôi hy vọng rằng công việc của chúng tôi có thể cung cấp cái nhìn sâu sắc cho cộng đồng NLP để phát triển các lời nhắc tốt hơn và khám phá tiềm năng của các mô hình ngôn ngữ lớn cho các tác vụ lý luận phức tạp hơn.

Từ khóa: Lý luận Tri thức Thông thường, Mô hình Ngôn ngữ Lớn, Lời nhắc

1. Giới thiệu
Gần đây, các mô hình ngôn ngữ lớn đã có những tiến bộ đáng kể trong lĩnh vực xử lý ngôn ngữ tự nhiên và đạt được kết quả SOTA trên một loạt rộng các tác vụ (Zhao et al., 2023; OpenAI, 2023; Bai et al., 2022b). Sự tăng trưởng về kích thước mô hình đóng vai trò quan trọng trong việc thúc đẩy hiệu suất của chúng (Zhao et al., 2023). Tuy nhiên, rõ ràng rằng việc chỉ tăng kích thước của các mô hình ngôn ngữ là không đủ để xuất sắc trong các tác vụ đòi hỏi lý luận phức tạp, đặc biệt là trong lĩnh vực lý luận tri thức thông thường (Sap et al., 2020; Bhargava và Ng, 2022a). Lý luận tri thức thông thường là nền tảng của sự hiểu biết của con người, bắt nguồn từ tri thức cơ bản và kinh nghiệm sống được tích lũy qua cuộc sống hàng ngày và thực hành xã hội (Forguson, 1989), điều này phác thảo tri thức thực tế về cách thế giới hoạt động (Sap et al., 2020). Và lý luận tri thức thông thường là trung tâm của việc xây dựng các mô hình hiểu ngôn ngữ tự nhiên có thể lý luận về thế giới giống như con người (Davis và Marcus, 2015; Storks et al., 2019).

Đối với lý luận tri thức thông thường nguyên mẫu, đầu ra của mô hình được mong đợi bao gồm tất cả các câu trả lời nguyên mẫu cho một câu hỏi (Boratko et al., 2020). Điều này đặc biệt có giá trị trong các tình huống mà việc xem xét một bối cảnh nhất định nên tạo ra những phản hồi đa dạng và phù hợp với bối cảnh (Zhang et al., 2020). Trong khi đó, trong lý luận tri thức thông thường nguyên mẫu, các nghiên cứu truyền thống bao gồm việc xây dựng một mô hình xếp hạng (Luo et al., 2022) và tăng cường tri thức (Li et al., 2023) để cải thiện khả năng của mô hình từ việc tinh chỉnh mô hình, nhưng những công trình này không xem xét khả năng lý luận tri thức thông thường của các mô hình SOTA và bị giới hạn trong các tác vụ tinh chỉnh cụ thể. (Bian et al., 2023) đã đánh giá tri thức của các mô hình ngôn ngữ lớn liên quan đến lý luận nguyên mẫu nhưng chỉ sử dụng độ chính xác làm chỉ số đánh giá duy nhất một cách ngắn gọn, lệch khỏi các chỉ số của tác vụ gốc.

Trong công trình này, chúng tôi khám phá khả năng lý luận tri thức thông thường nguyên mẫu của các mô hình ngôn ngữ lớn và cố gắng giải thích quá trình lý luận của chúng. Cụ thể, chúng tôi lấy cảm hứng từ phản hồi của mô hình đối với các tác vụ cụ thể và phát triển bán tự động ba loại lời nhắc riêng biệt nhằm tăng cường hiệu suất của mô hình.

Bằng cách phát triển bán tự động ba loại lời nhắc, chúng tôi nhằm mục đích hiểu sâu hơn về những lời nhắc này bao gồm (1) mức độ lý luận tri thức thông thường có thể đạt được bởi các mô hình ngôn ngữ lớn trong các tác vụ lý luận tri thức thông thường nguyên mẫu, (2) một lời giải thích về các quá trình lý luận tri thức thông thường được sử dụng bởi những mô hình này, và (3) các chiến lược để tăng cường khả năng lý luận tri thức thông thường của mô hình thông qua các lời nhắc mới được cải thiện. Nhìn chung, chúng tôi khám phá và phát triển bán tự động một bộ lời nhắc hiệu quả cho lý luận tri thức thông thường nguyên mẫu từ các góc độ liên quan đến tác vụ, được hỗ trợ bằng chứng, và giải mã đường dẫn đa dạng. Công việc của chúng tôi góp phần hiểu biết tốt hơn về khả năng của các mô hình ngôn ngữ lớn trong lý luận tri thức thông thường và cung cấp cái nhìn sâu sắc về cách xây dựng các lời nhắc hiệu quả để khơi gợi những khả năng này từ các mô hình như vậy.

Các đóng góp của công việc này như sau:
• Chúng tôi khám phá bán tự động một loạt lời nhắc mới, bao gồm lời nhắc liên quan đến tác vụ, lời nhắc được hỗ trợ bằng chứng, và lời nhắc giải mã đường dẫn đa dạng để cải thiện khả năng lý luận tri thức thông thường nguyên mẫu của các mô hình ngôn ngữ lớn.

• Để cải thiện khả năng diễn giải của quá trình lý luận của mô hình, chúng tôi sử dụng các lời nhắc dựa trên chuỗi suy nghĩ và tạo tri thức, kết hợp với các lời nhắc giải mã đường dẫn đa dạng, qua đó tăng cường hiệu suất mô hình đồng thời tăng tính minh bạch trong quá trình lý luận.

• Kết quả thực nghiệm chứng minh rằng phương pháp của chúng tôi đạt được SOTA mới trên ProtoQA. Chúng tôi cải thiện điểm Max Answer@1 thêm 8%, điểm Max Incorrect@1 thêm 4% so với mô hình SOTA trước đó. Trong khi đó, chúng tôi xác nhận khả năng khái quát hóa của phương pháp trên CommonsenseQA2.0 và StrategyQA.

2. Công trình Liên quan
2.1. Lý luận Tri thức Thông thường với Các Mô hình Ngôn ngữ Lớn

Các mô hình ngôn ngữ lớn, như các mô hình dòng GPT-3.5¹, GPT-4 (OpenAI, 2023), Claude (Bai et al., 2022b) và Google Bard², PaLM-2 (Anil et al., 2023) đã đạt được tiến bộ lớn trong lĩnh vực xử lý ngôn ngữ tự nhiên. Tuy nhiên, các mô hình ngôn ngữ lớn này vẫn gặp thách thức trong lĩnh vực lý luận tri thức thông thường (Bhargava và Ng, 2022b), nơi mô hình ngôn ngữ cần có khả năng lý luận tri thức ngầm định và các tình huống hàng ngày được con người biết đến (Uleman et al., 2008). Để tăng cường khả năng lý luận tri thức thông thường của các mô hình ngôn ngữ lớn, các nhà nghiên cứu đã khám phá các công trình đa dạng có thể được phân loại thô thành cách làm cho mô hình ngôn ngữ biết nhiều hơn (Yang et al., 2021) và cách mô hình ngôn ngữ lý luận tốt hơn (Wei et al., 2022). Trong các công trình trước, họ tích hợp các nguồn tri thức bên ngoài vào mô hình ngôn ngữ (Lim et al., 2020; Sun et al., 2019; Guan et al., 2020; Yu et al., 2022; Lin et al., 2019). Ví dụ, việc sử dụng các đồ thị tri thức bên ngoài hoặc cơ sở dữ liệu chứa thông tin thực tế có thể tăng cường hiểu biết của mô hình về thế giới (Han et al., 2020; Liu et al., 2021). Bằng cách kết hợp tri thức như vậy, mô hình trở nên có khả năng đưa ra các quyết định có thông tin hơn (Chen et al., 2020). Trong các công trình sau, các nhà nghiên cứu thiết kế các chiến lược lý luận tốt hơn cho mô hình ngôn ngữ (Kojima et al., 2022). Bằng cách áp dụng một chiến lược lý luận phù hợp, khả năng của mô hình ngôn ngữ trong việc sử dụng lý luận tri thức được cải thiện đáng kể (Wang et al., 2022).

2.2. Học Lời nhắc

Học lời nhắc là một quá trình quan trọng trong lĩnh vực kỹ thuật, nhằm phát triển các lời nhắc hiệu quả để hướng dẫn các mô hình ngôn ngữ lớn đạt được các kết quả đầu ra mong muốn (White et al., 2023). Nhiều công trình về học lời nhắc đã được các nhà nghiên cứu khám phá. Một loạt các phương pháp như few-shot (Wang et al., 2020), Chuỗi Suy Nghĩ (Wei et al., 2022) học trong ngữ cảnh (Dong et al., 2022) về cơ bản thiết lập các lời nhắc phù hợp để hướng dẫn mô hình ngôn ngữ đưa ra các kết quả thích hợp. Trong số các phương pháp này, công nghệ Chuỗi Suy Nghĩ tạo ra các bước suy nghĩ đã được thiết lập như một phương pháp quan trọng để tăng cường khả năng lý luận của các mô hình ngôn ngữ (Wei et al., 2022). Trong suốt các tác vụ ngôn ngữ khác nhau, học lời nhắc đã đóng vai trò quan trọng trong việc đạt được kết quả xuất sắc (Dang et al., 2022). Hiện tại, nghiên cứu về Kỹ thuật Lời nhắc NLP vẫn đang phát triển, và các phương pháp khác nhau đã được đề xuất để xây dựng các lời nhắc hiệu quả. Trong số đó, việc xây dựng lời nhắc nhân tạo là một trong những phương pháp hiệu quả nhất, được thiết kế dựa trên tri thức nhân tạo (White et al., 2023).

3. Phương pháp
Trong phần này, chúng tôi sẽ giới thiệu các phương pháp lời nhắc bán tự động, nhằm khơi gợi khả năng lý luận tri thức thông thường của các mô hình ngôn ngữ lớn. Mục tiêu chính của chúng tôi là khám phá những thuộc tính nào mà một lời nhắc có thể kích thích khả năng lý luận tri thức thông thường của một mô hình ngôn ngữ lớn, và cách một lời nhắc có thể được sử dụng để cân bằng khả năng lý luận tri thức thông thường và khả năng diễn giải của một mô hình ngôn ngữ lớn.

Chúng tôi chủ yếu đánh giá hiệu suất của một số mô hình ngôn ngữ lớn, bao gồm GPT-3.5, GPT-4, Claude, và Bard, trên bộ dữ liệu ProtoQA (Boratko et al., 2020), StrategyQA (Geva et al., 2021) và CommonsenseQA2.0 (Talmor et al., 2021).

Được truyền cảm hứng bởi kết quả của mô hình khi nhắc mô hình cho các tác vụ cụ thể, chúng tôi thu thập các đoạn liên quan đến tác vụ như một thành phần không thể thiếu của các lời nhắc. Lời nhắc heuristic cụ thể mà chúng tôi sử dụng và các đoạn về tác vụ ProtoQA mà chúng tôi thu thập được hiển thị trong Hình 1. Chúng tôi chọn các đoạn³ gần nhất với tác vụ (Boratko et al., 2020) làm một phần của các lời nhắc liên quan đến tác vụ được thiết kế mới. Trong khi xem xét khả năng diễn giải và tính nhất quán của mô hình, chúng tôi thiết kế riêng lẻ lời nhắc được hỗ trợ bằng chứng và lời nhắc giải mã đường dẫn đa dạng.

• Liên quan đến Tác vụ Thêm các đoạn tri thức liên quan đến tác vụ làm lời nhắc để tạo ra câu trả lời đa dạng và chính xác, danh sách câu trả lời cần bao gồm tri thức quen thuộc với hầu hết mọi người. Chúng tôi lấy cảm hứng từ đầu ra của mô hình, khám phá khả năng tạo ra các mảnh liên quan đến tác vụ. Sau đó chúng tôi tinh chỉnh những mảnh này để tạo ra các lời nhắc cụ thể cho tác vụ.

Các lời nhắc liên quan đến tác vụ có thể tập trung sự chú ý của mô hình và tạo ra đầu ra phù hợp hơn với yêu cầu tác vụ. Đồng thời, các lời nhắc liên quan đến tác vụ có thể cung cấp thông tin ngữ cảnh cho mô hình, giúp mô hình hiểu câu hỏi và loại đầu ra cần được tạo ra.

• Được Hỗ trợ Bằng chứng về Suy nghĩ & Tri thức Thêm các lời nhắc hướng dẫn bao gồm từ hướng dẫn liên quan đến tác vụ cho các mô hình để tạo ra bằng chứng hỗ trợ, bao gồm Chuỗi Suy Nghĩ và tạo tri thức, có thể làm cho quá trình lý luận của mô hình minh bạch hơn trong khi mô hình tạo ra câu trả lời đa dạng và chính xác.

Bằng chứng hỗ trợ đóng vai trò quan trọng trong nhiều khía cạnh. Trước tiên, nó tăng cường tính minh bạch của mô hình, làm cho quá trình lý luận và cơ sở để đưa ra phán đoán của mô hình rõ ràng và có thể nhìn thấy. Đồng thời, nó có thể làm nổi bật thông tin phán đoán quan trọng nhất của mô hình và giúp con người hiểu trọng tâm của mô hình. Hơn nữa, nó hỗ trợ việc kiểm tra thủ công quá trình lý luận của mô hình, đánh giá tính hợp lý của mô hình, và cải thiện mô hình.

• Giải mã Đường dẫn Đa dạng Xem xét nhu cầu tạo ra câu trả lời đa dạng và chính xác, chúng tôi thêm lời nhắc hướng dẫn bao gồm từ hướng dẫn liên quan đến tác vụ, cho phép mô hình tạo ra câu trả lời đa chiều trong quá trình lý luận đa dạng và dựa vào khả năng tổng hợp của mô hình để tạo ra kết quả cuối cùng. Tạo ra câu trả lời đa dạng và tổng hợp cho phép mô hình đạt được tính nhất quán với bản thân tăng cường, điều này rất quan trọng đối với khả năng ra quyết định của mô hình. Nếu đầu ra mâu thuẫn hoặc không nhất quán được tạo ra, mô hình rất có khả năng sẽ sửa chữa hoặc loại bỏ nó.

Như được trình bày trong Hình 2, chúng tôi trình bày chi tiết của lời nhắc liên quan đến tác vụ, nhằm hướng dẫn mô hình ngôn ngữ lớn tạo ra câu trả lời với nhiều thông tin liên quan đến tác vụ hơn. Đối với lời nhắc được hỗ trợ bằng chứng, tri thức liên quan hoặc suy nghĩ được khơi gợi đầu tiên thông qua lời nhắc. Sau đó lời nhắc liên quan đến tác vụ được kết hợp với bằng chứng và đưa vào mô hình ngôn ngữ lớn để tạo ra câu trả lời. Đối với lời nhắc giải mã đường dẫn đa dạng, nhiều câu trả lời ứng viên với bằng chứng được giải mã đầu tiên thông qua lấy mẫu đa đường dẫn. Sau đó câu trả lời ứng viên với bằng chứng được tổng hợp bằng cách kết hợp lời nhắc liên quan đến tác vụ để tạo ra câu trả lời cuối cùng. Thêm chi tiết có thể được tìm thấy trong Phụ lục, như được hiển thị trong Hình 5.

4. Thực nghiệm
4.1. Bộ dữ liệu

ProtoQA Trong kết quả chính, chúng tôi đánh giá phương pháp của mình trên ProtoQA (Boratko et al., 2020), tập trung vào các câu hỏi lý luận tri thức thông thường như "Một số lý do bạn có thể được gọi đến trường của con bạn có thể là gì?". Mô hình được yêu cầu tạo ra một danh sách câu trả lời, lý tưởng là bao gồm tất cả các câu trả lời nguyên mẫu cho một câu hỏi nhất định. Bộ dữ liệu có 9.762 câu hỏi trong tập huấn luyện, 52 câu hỏi trong tập phát triển, và 102 câu hỏi trong tập kiểm tra. Các bộ dữ liệu có các loại câu hỏi lý luận đa dạng, như được hiển thị trong Bảng 1.

CommonsenseQA2.0 CommonsenseQA 2.0 (Talmor et al., 2021) được đề xuất để khám phá khả năng hiểu tri thức thông thường của các mô hình ngôn ngữ lớn, bao gồm 14.343 câu hỏi có/không (hoặc khẳng định) về tri thức thông thường hàng ngày.

StrategyQA StrategyQA (Geva et al., 2021) là một tiêu chuẩn hỏi-đáp tập trung vào các câu hỏi lĩnh vực mở nơi các bước lý luận cần thiết được ngầm định trong câu hỏi và nên được suy ra sử dụng một chiến lược, bao gồm 2.780 ví dụ đúng/sai, mỗi ví dụ bao gồm một câu hỏi chiến lược, sự phân tích của nó, và các đoạn bằng chứng.

4.2. Baseline

Đối với thực nghiệm tập kiểm tra, chúng tôi lấy các mô hình SOTA khác trên bảng xếp hạng làm baseline để so sánh như được hiển thị trong Bảng 2. Đối với thực nghiệm tập phát triển, baseline của các mô hình ngôn ngữ lớn là lời nhắc few-shot tiêu chuẩn, nơi mô hình được cung cấp các ví dụ ngữ cảnh của các cặp đầu vào-đầu ra trước khi dự đoán đầu ra trên một ví dụ kiểm tra. Ngoài ra, do tính ngắn gọn và đa dạng của câu trả lời, chúng tôi áp đặt giới hạn trong lời nhắc nói rằng "cho tôi 10 câu trả lời và hầu hết câu trả lời chỉ nên là một từ.", như được hiển thị trong Hình 3. Phần sau giới thiệu các mô hình trong thực nghiệm đã đạt được hiệu suất xuất sắc và các mô hình ngôn ngữ lớn mà chúng tôi khám phá.

GPT-2 GPT-2 là một mô hình ngôn ngữ dựa trên transformer-decoder được phát triển bởi Open AI (Radford et al., 2019), thể hiện hiệu suất mạnh mẽ trên nhiều tác vụ mô hình hóa ngôn ngữ như dự đoán từ tiếp theo, hoàn thành câu, và tạo văn bản. Chúng tôi sử dụng mô hình được tinh chỉnh trên tập huấn luyện.

BART BART là một mô hình tạo ngôn ngữ dựa trên Transformer được phát triển bởi FaceBook AI với bộ mã hóa và giải mã hai chiều (Lewis et al., 2019) cho phép nó đồng thời hiểu ngữ cảnh của văn bản đầu vào và tạo ra văn bản đầu ra, cho phép nó tạo ra các phản hồi mạch lạc và chính xác hơn. Chúng tôi sử dụng mô hình được tinh chỉnh trên tập huấn luyện.

T5 T5 là một mô hình ngôn ngữ học đa tác vụ mạnh mẽ dựa trên kiến trúc transformer với bộ mã hóa và giải mã được phát triển bởi Google AI (Raffel et al., 2020), thực hiện học đa tác vụ và học chuyển giao bằng cách thống nhất các tác vụ xử lý ngôn ngữ tự nhiên khác nhau thành chuyển đổi text-to-text. Chúng tôi sử dụng mô hình được tinh chỉnh trên tập huấn luyện.

KEPR GPT-2-KEPR, BART-KEPR, T5-3B-KEPR sử dụng Tăng cường Tri thức và Xếp hạng Khả thi để tăng cường kỹ năng lý luận tri thức thông thường của GPT-2, BART và T5 (Li et al., 2023). Chúng tôi sử dụng mô hình được tinh chỉnh trên tập huấn luyện.

GPT-3 GPT-3 là phiên bản cập nhật của GPT, một mô hình ngôn ngữ AI lớn với 175 tỷ tham số thể hiện khả năng ngôn ngữ mạnh mẽ trong tạo văn bản, Phiên bản GPT-3 đang sử dụng là mô hình davinci-002 được phát hành bởi OpenAI. (Brown et al., 2020).

GPT-3.5 GPT-3.5 là phiên bản cập nhật của GPT, tạo ra tiến bộ lớn hơn trong hệ thống đối thoại (Ouyang et al., 2022). Phiên bản GPT-3.5 đang sử dụng là mô hình GPT-3.5-turbo được phát hành bởi OpenAI.

Bard Bard là một thí nghiệm dựa trên LaMDA được huấn luyện để có tính thông tin và toàn diện (Thoppilan et al., 2022).

Claude Claude là một trợ lý AI thế hệ tiếp theo dựa trên nghiên cứu của Anthropic, có thể giúp với các trường hợp sử dụng bao gồm tổng hợp, tìm kiếm, viết sáng tạo và hợp tác, hỏi đáp, mã hóa, và nhiều hơn nữa (Bai et al., 2022a).

4.3. Cài đặt Thực nghiệm

Lời nhắc Liên quan đến Tác vụ Bộ dữ liệu chính mà chúng tôi nghiên cứu là bộ dữ liệu ProtoQA, yêu cầu tạo ra câu trả lời đa dạng và chính xác dựa trên các chuẩn mực và thực hành xã hội chung, vì vậy chúng tôi chọn mảnh 'dựa trên các chuẩn mực và thực hành xã hội chung' làm phần chính của lời nhắc liên quan đến tác vụ, như được hiển thị trong Hình 3.

Lời nhắc tạo ra bằng chứng hỗ trợ Chúng tôi xem xét việc tạo ra bằng chứng hỗ trợ thông qua Chuỗi Suy Nghĩ hoặc tạo tri thức. Chúng tôi đầu tiên khơi gợi suy nghĩ hoặc tri thức thông qua lời nhắc ban đầu, sau đó sử dụng suy nghĩ hoặc tri thức được tạo ra kết hợp với lời nhắc liên quan đến tác vụ làm đầu vào để tạo ra câu trả lời, như được hiển thị trong Hình 3.

Lời nhắc giúp giải mã đường dẫn đa dạng Để mô hình tạo ra câu trả lời với bằng chứng nhiều lần, cuối cùng tổng hợp để tạo ra câu trả lời cuối cùng, như được hiển thị trong Hình 3. Trong tham số gọi API mô hình GPT-3.5-turbo, temperature = 0.5, max_tokens = 1024, top_p = 0.95.

4.4. Kết quả Thực nghiệm

Chúng tôi sử dụng ProtoQA, bộ dữ liệu lý luận tri thức thông thường, để đánh giá hiệu suất của mô hình ngôn ngữ với các lời nhắc khác nhau, cung cấp đánh giá nghiêm ngặt hơn về khả năng lý luận tri thức thông thường của các mô hình ngôn ngữ lớn, yêu cầu mô hình đưa ra tất cả các câu trả lời nguyên mẫu cho một câu hỏi một cách lý tưởng. Chỉ số Max Answers@k giới hạn tổng số câu trả lời được phép lên đến k câu trả lời. Chỉ số Max Incorrect@k cho phép câu trả lời không giới hạn nhưng dừng lại sau k câu trả lời không khớp. Do đó, các chỉ số đánh giá tính đa dạng và chính xác của câu trả lời cho một câu hỏi nhất định. Điểm số càng cao, hiệu suất lý luận tri thức thông thường càng tốt. Tất cả kết quả được trình bày ở đây là trung bình từ nhiều lần chạy, cụ thể là trung bình của ba lần lặp lại, và kết quả có ý nghĩa thống kê.

4.4.1. Kết quả trên Bảng xếp hạng của Tập kiểm tra

Trong bảng xếp hạng của tập kiểm tra, như được hiển thị trong Bảng 2, chúng tôi đạt được kết quả SOTA thông qua lời nhắc liên quan đến tác vụ vượt trội hơn các mô hình khác nhau được tăng cường bởi phương pháp KEPR. Cụ thể, chỉ số Max Answers@1 đạt 69% (tăng 8% so với mô hình SOTA trước đó, T5-3B-KEPR), và chỉ số Max Incorrect@1 đạt 50%. Đây là lần đầu tiên vượt qua 50%, đại diện cho mức tăng 4% so với mô hình SOTA trước đó. Hơn nữa, để khám phá khả năng lý luận tri thức thông thường của các mô hình ngôn ngữ lớn khác, chúng tôi tiến hành thí nghiệm với Claude, Bard, và GPT-3.5 sử dụng lời nhắc few-shot, như được hiển thị trong Bảng 2. Thông qua các mô hình ngôn ngữ lớn với lời nhắc few-shot, các chỉ số Max Answers@10 và Max Incorrect@5 đứng sau các mô hình SOTA trước đó. Điều này cho thấy rằng với kỹ thuật tăng cường tri thức và xếp hạng, các mô hình ngôn ngữ nhỏ hơn có tiềm năng sánh bằng hoặc thậm chí vượt trội hơn các mô hình ngôn ngữ lớn hơn trong một số tác vụ cụ thể. Ngoài ra, mô hình ngôn ngữ lớn, Claude, thể hiện khả năng lý luận tri thức thông thường có thể so sánh với GPT-3.5, đồng thời duy trì lợi thế rõ ràng so với Bard.

4.4.2. Kết quả khác trên Tập phát triển

Như được hiển thị trong Bảng 6, kết quả thực nghiệm chứng minh rằng lời nhắc liên quan đến tác vụ (Prompt1) đóng góp đáng kể vào hiệu suất của mô hình. Cụ thể, chỉ số Max Answers@1, tăng 15% và Max Incorrect@1 tăng 7%. Ngoài ra, khi cung cấp lời giải thích lý luận nhằm cải thiện khả năng diễn giải của mô hình (Prompt2 và Prompt3), năng lực lý luận tri thức thông thường của nó không bị suy giảm dưới hầu hết các chỉ số đánh giá. Đối với chỉ số Max Answer@1, mô hình quay lại mức lý luận baseline. Tuy nhiên, đối với các chỉ số khác, mô hình có cải thiện đáng kể so với baseline (Prompt0). Hơn nữa, thông qua lời nhắc giải mã đường dẫn đa dạng (Prompt4), khả năng lý luận của mô hình đã được cải thiện đáng kể. Đặc biệt, chỉ số Max Answer@10 đã tăng 11%, và chỉ số Max Incorrect@5 đã tăng 9% so với baseline.

4.4.3. Đánh giá Khái quát hóa

Để chứng minh hiệu quả của phương pháp, chúng tôi tiến hành thí nghiệm trên các bộ dữ liệu lý luận tri thức thông thường khác, CommonsenseQA2.0 và StrategyQA nơi mỗi câu hỏi cần một đầu ra duy nhất, như được hiển thị trong Bảng 4 và Bảng 5. Bằng cách thêm lời nhắc liên quan đến tác vụ, chúng tôi đạt được cải thiện khoảng 3% trên CommonsenseQA2.0 và khoảng 1% trên StrategyQA. Bằng cách thêm bằng chứng hỗ trợ suy nghĩ, chúng tôi đạt được hiệu suất tốt nhất trên CommonsenseQA2.0, đạt được cải thiện 8.5%. Đối với các lời nhắc của CommonsenseQA2.0 và StrategyQA, chúng tôi đều sử dụng cùng đặc điểm của lời nhắc (Dựa trên tri thức thông thường xã hội).

4.5. Nghiên cứu Ablation

Phương pháp lời nhắc liên quan đến tác vụ (Prompt1) đạt được cải thiện đáng kể trong khả năng lý luận tri thức thông thường của mô hình ngôn ngữ lớn. Trong tập phát triển ProtoQA, chỉ số Max Answer@1 tăng 15% so với baseline với lời nhắc few-shot (Prompt0), như được hiển thị trong Bảng 6. Trong tập kiểm tra ProtoQA, lời nhắc liên quan đến tác vụ (Prompt1) giúp mô hình lớn cải thiện 7% so với GPT3.5 với lời nhắc few-shot, như được hiển thị trong Bảng 2. Có khoảng 3% cải thiện trong CommonsenseQA2.0 và 1% cải thiện trong StrategyQA, như được hiển thị trong Bảng 4. Từ kết quả thực nghiệm trên, chúng tôi quan sát thấy rằng các lời nhắc liên quan đến tác vụ hỗ trợ mô hình đạt được hiệu suất xuất sắc trên các tác vụ cụ thể, tương tự như việc tinh chỉnh các mô hình ngôn ngữ trên các tác vụ cụ thể để tăng cường khả năng của chúng cho các tác vụ cụ thể. Đồng thời, khi chúng tôi cung cấp lời giải thích cho quá trình lý luận của mô hình, khả năng lý luận tri thức thông thường của mô hình vẫn cạnh tranh khi k>=3. Trong tập phát triển ProtoQA, việc cung cấp bằng chứng hỗ trợ với quá trình suy nghĩ (Prompt2) cải thiện chỉ số Max Incorrect@3 7% so với baseline (Prompt0). Việc cung cấp bằng chứng hỗ trợ với tri thức (Prompt3) cải thiện chỉ số Max Incorrect@3 3%, như được hiển thị trong Bảng 6. Trong tập kiểm tra ProtoQA, việc cung cấp bằng chứng hỗ trợ với suy nghĩ cải thiện chỉ số Max Answer@10 4% so với GPT3.5 với lời nhắc few-shot, như được hiển thị trong Bảng 2. Kết quả thực nghiệm chứng minh rằng việc tăng cường khả năng diễn giải của mô hình dẫn đến các đầu ra toàn diện hơn. Tuy nhiên, chúng tôi phát hiện rằng lời nhắc được hỗ trợ bằng chứng sẽ có một mức độ mất mát nhất định trong hiệu suất của mô hình. Một yếu tố góp phần vào sự suy giảm hiệu suất là việc tập trung quá mức vào quá trình nhận thức, điều này đã đưa vào thông tin dư thừa.

Ngoài ra, thông qua việc sử dụng lời nhắc giải mã đường dẫn đa dạng, khả năng lý luận tri thức thông thường của mô hình ngôn ngữ lớn cũng đã được cải thiện đáng kể, giúp giảm bớt mất mát này khi kết hợp lời nhắc bằng chứng hỗ trợ. Trong tập phát triển ProtoQA, chỉ số Max Answers@10 tăng 11% và chỉ số Max Incorrect@5 tăng 9% so với baseline (Prompt0), như được hiển thị trong Bảng 6. Kết quả thực nghiệm trên chứng minh rằng khả năng lý luận của mô hình có thể được tăng cường thông qua giải mã đường dẫn đa dạng. Cụ thể, mô hình ngôn ngữ lớn có thể tạo ra các đầu ra chính xác hơn bằng cách tổng hợp các câu trả lời ứng viên và duy trì tính cạnh tranh trong các chỉ số với k>=3.

4.6. Nghiên cứu Trường hợp

Để làm rõ về các lời nhắc, chúng tôi cung cấp đầu ra thực tế của mô hình ngôn ngữ lớn với các lời nhắc khác nhau cho tác vụ lý luận tri thức thông thường, như được hiển thị trong Hình 4. Chúng tôi có thể quan sát thấy rằng thông qua các lời nhắc liên quan đến tác vụ, mô hình ngôn ngữ lớn tạo ra đầu ra chính xác và cải thiện độ chính xác của câu trả lời cho các câu hỏi CommonsenseQA2.0 và StrategyQA. Đối với bộ dữ liệu ProtoQA, so với lời nhắc few-shot Prompt0, danh sách câu trả lời được đưa ra bởi mô hình có vẻ hợp lý hơn với lời nhắc liên quan đến tác vụ Prompt1, cho phép mô hình tạo ra câu trả lời mạch lạc và liên quan đồng thời giảm khả năng xảy ra lỗi. Cụ thể, không có câu trả lời rõ ràng bất hợp lý (ví dụ "công ty bất động sản", "luật sư" cho câu hỏi đầu tiên, "Kể tên một nơi mà bạn có thể có một cuộc trò chuyện dài" là bất hợp lý. "chạy bộ" cho câu hỏi thứ hai, "Kể tên thứ gì đó mà một vận động viên sẽ không giữ trong tủ lạnh của cô ấy" là bất hợp lý).

Trong khi đó, bằng chứng hỗ trợ được tạo ra bởi chính mô hình (quá trình suy nghĩ Prompt2 hoặc tri thức Prompt3) cho phép nó hiểu câu hỏi tốt hơn và tạo ra nhiều câu trả lời chính xác (ví dụ "quán cà phê" cho câu hỏi đầu tiên. "thức ăn nhanh", "rượu" cho câu hỏi thứ hai). Trong đánh giá nhân tạo của chúng tôi về CoT, chúng tôi nhận thấy sự phù hợp hoàn toàn giữa quá trình lý luận của CoT và kết quả cuối cùng của nó. Chúng tôi đưa ra giả thuyết rằng một sự tăng cường đáng kể khả năng lý luận của mô hình bởi CoT có thể dẫn đến sự gia tăng sự khác biệt giữa quá trình lý luận của CoT và kết quả ra quyết định của nó. Trong đánh giá nhân tạo của chúng tôi về tri thức liên quan, chúng tôi phát hiện rằng tri thức có thể bổ sung tốt thông tin nền của vấn đề và giúp mô hình hiểu câu hỏi. Đầu ra chi tiết của bằng chứng hỗ trợ được cung cấp trong Phụ lục A.1. Ngoài ra, bằng giải mã đường dẫn đa dạng Prompt4, đầu ra của mô hình gần gũi hơn với câu hỏi. (ví dụ "đồ ăn vặt" cho câu hỏi thứ hai). Đầu ra chi tiết này được cung cấp trong Phụ lục A.2. Ngoài ra, chúng tôi phát hiện rằng có sự khác biệt trong hiệu suất của mô hình giữa tập kiểm tra và tập phát triển, điều này được gây ra bởi các mức độ khó khăn khác nhau của phân phối bộ dữ liệu. Độ khó tổng thể của tập phát triển cao hơn so với tập kiểm tra.

5. Kết luận

Trong bài báo này, chúng tôi khám phá khả năng lý luận tri thức thông thường nguyên mẫu của các mô hình ngôn ngữ lớn để tạo ra nhiều đầu ra phù hợp. Chúng tôi phát triển bán tự động một bộ mẫu lời nhắc mới như một phương pháp đơn giản và áp dụng rộng rãi để tăng cường lý luận tri thức thông thường trong các mô hình ngôn ngữ lớn. Các phát hiện nghiên cứu của chúng tôi cho thấy rằng các mô hình ngôn ngữ lớn thể hiện khả năng lý luận tri thức thông thường cạnh tranh mà không cần tăng cường tri thức bên ngoài. Trên thực tế, việc kết hợp tri thức bên ngoài rõ ràng vào các mô hình này có thể đưa vào thông tin dư thừa, có khả năng làm tổn hại hiệu suất của chúng. Tuy nhiên, bằng cách sử dụng các chiến lược giải mã đa dạng, chúng tôi có thể giảm thiểu mất mát hiệu suất như vậy đồng thời tăng cường khả năng diễn giải của các mô hình. Trong các thí nghiệm trên các bộ dữ liệu ProtoQA, StrategyQA, và CommonsenseQA, chúng tôi phát hiện rằng việc kết hợp tri thức liên quan đến tác vụ có thể cho phép các mô hình giảm khả năng xảy ra lỗi và tạo ra câu trả lời chính xác hơn. Bằng cách tạo điều kiện cho quá trình suy nghĩ và tri thức, khả năng lý luận tri thức thông thường của mô hình có thể minh bạch hơn. Thông qua giải mã đường dẫn đa dạng, khả năng lý luận tri thức thông thường của mô hình cũng đã được cải thiện ở một mức độ nhất định và duy trì tính cạnh tranh so với lời nhắc được hỗ trợ bằng chứng với giải mã đường dẫn đơn.

6. Hạn chế

Công việc của chúng tôi minh họa rằng lời nhắc liên quan đến tác vụ, lời nhắc được hỗ trợ bằng chứng và lời nhắc giải mã đường dẫn đa dạng có thể cải thiện khả năng lý luận tri thức thông thường của các mô hình ngôn ngữ lớn. Tuy nhiên, do hạn chế về tài nguyên, chúng tôi không thể tiến hành thí nghiệm trên GPT-4 tiên tiến. Trong khi đó, nhiều bộ dữ liệu lý luận để đánh giá khả năng lý luận ngôn ngữ tập trung vào đo lường khả năng của mô hình trong việc tạo ra một phản hồi chính xác hoặc logic duy nhất. Chúng tôi bị giới hạn trong các bộ dữ liệu lý luận với nhiều đầu ra khả dĩ. Cụ thể, chúng tôi tiến hành thí nghiệm trên ProtoQA, một bộ dữ liệu đa đầu ra, và tiến hành thí nghiệm mở rộng trên các bộ dữ liệu đầu ra đơn CommonsenseQA và StrategyQA. Chúng tôi hy vọng nhiều bộ dữ liệu đánh giá khả năng của các mô hình ngôn ngữ trong việc tạo ra nhiều đầu ra phù hợp sẽ được xây dựng, vì khả năng này của mô hình ngôn ngữ lớn là rất quan trọng.

[Phần tài liệu tham khảo và phụ lục tiếp theo...]

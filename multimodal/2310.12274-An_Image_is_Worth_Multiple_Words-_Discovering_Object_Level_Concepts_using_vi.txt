# 2310.12274.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2310.12274.pdf
# Kích thước tệp: 47735819 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Một Hình Ảnh Đáng Giá Nhiều Từ: Khám Phá Các Khái Niệm Cấp Độ Đối Tượng Sử Dụng Học Prompt Đa Khái Niệm
Chen Jin1Ryutaro Tanno2Amrutha Saseendran1Tom Diethe1Philip Teare1

"một bức ảnh   
* (gấu teddy)  "
"một bức ảnh  
& (ván trượt)"Cones / CDCắt theo cây
Break-A-SceneDựa trên mặt nạ 
các prompt có thể học được được biểu diễn dưới dạng  
các từ giả có màu
"một bức ảnh gấu teddy nâu  
* (gấu teddy)  trên một  
& (ván trượt) lăn tại quảng trường"
& ** (gấu teddy)   
gấu trúc* (gấu teddy)   
mèo
lăn & (ván trượt)   
ván lướt sónglăn & (ván trượt)   
chăn bayMCPL Tái tạoChỉnh sửa các khái niệm 
sự chú ý chéo được căn chỉnhHọc và chỉnh sửa nhiều khái niệm mới không cần mặt nạ với MCPL (của chúng tôi) 
"một bức ảnh  
* (gấu teddy)  và một  
& (ván trượt) tại quảng trường"

Hình 1. Học đa khái niệm dựa trên ngôn ngữ và các ứng dụng. Custom Diffusion (CD) và Cones học các khái niệm từ việc cắt các đối tượng, trong khi Break-A-Scene sử dụng mặt nạ. Ngược lại, phương pháp của chúng tôi học các khái niệm cấp độ đối tượng sử dụng các cặp hình ảnh-câu, căn chỉnh sự chú ý chéo của mỗi prompt có thể học với một vùng có ý nghĩa ngữ nghĩa, và cho phép chỉnh sửa cục bộ không cần mặt nạ. Trang dự án, mã nguồn và dữ liệu có sẵn tại https://astrazeneca.github.io/mcpl.github.io.

Tóm tắt
Textual Inversion, một phương pháp học prompt, học một embedding văn bản đơn lẻ cho một "từ" mới để biểu diễn phong cách và hình dạng của hình ảnh, cho phép nó được tích hợp vào các câu ngôn ngữ tự nhiên để tạo ra các hình ảnh tổng hợp mới. Tuy nhiên, việc xác định nhiều khái niệm cấp độ đối tượng chưa biết trong một cảnh vẫn là một thách thức phức tạp. Trong khi các phương pháp gần đây đã phải dùng đến việc cắt hoặc che mặt nạ từng hình ảnh để học nhiều khái niệm, các kỹ thuật này yêu cầu chú thích hình ảnh có thể khan hiếm hoặc không có sẵn. Để giải quyết thách thức này, chúng tôi giới thiệu Multi-Concept Prompt Learning (MCPL), trong đó nhiều "từ" chưa biết được học đồng thời từ một cặp câu-hình ảnh đơn lẻ, mà không cần bất kỳ chú thích hình ảnh nào. Để tăng cường độ chính xác của tương quan từ-khái niệm và tinh chỉnh ranh giới mặt nạ chú ý, chúng tôi đề xuất ba kỹ thuật chính quy hóa: Attention Masking, Prompts Contrastive Loss, và Bind Adjective. Các so sánh định lượng rộng rãi với cả các danh mục thế giới thực và hình ảnh y sinh học chứng minh rằng phương pháp của chúng tôi có thể học các khái niệm tách biệt ngữ nghĩa mới. Cách tiếp cận của chúng tôi nhấn mạnh việc học hoàn toàn từ các embedding văn bản, sử dụng ít hơn 10% không gian lưu trữ so với các phương pháp khác.

1. Giới thiệu
Khám phá khái niệm thị giác dựa trên ngôn ngữ là một quá trình tương tác giữa con người và máy móc trong đó con người mô tả một hình ảnh, bỏ lại nhiều khái niệm không quen thuộc. Sau đó máy móc học cách liên kết mỗi khái niệm mới với một prompt có thể học tương ứng (các từ giả trong Hình 1) từ cặp câu-hình ảnh. Khả năng như vậy sẽ thúc đẩy quá trình khám phá kiến thức khoa học từ các quan sát thực nghiệm hoặc khai thác các sách giáo khoa hiện có. Nó cũng tạo thuận lợi cho việc tạo ra giả thuyết thông qua chỉnh sửa hình ảnh cục bộ mà không cần kiến thức cụ thể về khái niệm thị giác mới.

Nghiên cứu gần đây ((Gal et al., 2022; Ruiz et al., 2022)) cho thấy rằng hình dạng và phong cách của một hình ảnh có thể được đóng gói thành một khái niệm thống nhất thông qua một prompt đã học ("từ") được tối ưu hóa trong không gian embedding đã đóng băng của một mô hình diffusion văn bản-hình ảnh đã được huấn luyện trước.

--- TRANG 2 ---
Một Hình Ảnh Đáng Giá Nhiều Từ: Khám Phá Các Khái Niệm Cấp Độ Đối Tượng Sử Dụng Học Prompt Đa Khái Niệm

được tối ưu hóa trong không gian embedding đã đóng băng của một mô hình diffusion văn bản thành hình ảnh đã được huấn luyện trước. Để đưa việc học xuống nhiều đối tượng trong một cảnh, Custom Diffusion (Kumari et al., 2023) và Cones (Liu et al., 2023), sử dụng các phần cắt của các đối tượng, trong khi Break-A-Scene (Avrahami et al., 2023) sử dụng mặt nạ, như được thể hiện trong Hình 1. Các cách tiếp cận này tối ưu hóa hiệu suất tích hợp của nhiều khái niệm đã học thông qua fine-tuning và lưu trữ các trọng số mô hình diffusion. Tuy nhiên, các cách tiếp cận này ít phù hợp hơn để khám phá các khái niệm ngữ nghĩa chưa biết từ dữ liệu lịch sử ở quy mô lớn khi: 1) các chú thích không có sẵn (ví dụ: nhật ký y tế); 2) các khái niệm không được biết đến (ví dụ: khám phá biomarker mới); 3) việc giảm thiểu lưu trữ cho mỗi khái niệm là quan trọng (xem Bảng 1).

Bảng 1. Các phương pháp cạnh tranh. Phương pháp của chúng tôi là phương pháp đầu tiên đề xuất một giải pháp để khám phá các khái niệm thị giác mới sử dụng mô tả văn bản (lý tưởng là được hỗ trợ bởi một tính từ cho mỗi khái niệm). Chúng tôi tập trung vào việc học token để có chi phí lưu trữ tối thiểu (mỗi 1 ∼4 token trong bảng). Các phương pháp khác như BAS thực hiện fine-tuning và lưu trữ các trọng số mô hình diffusion để có hiệu suất tích hợp tối ưu.

Phương pháp | Đa khái niệm | Hình ảnh đơn | Đầu vào phụ | Chỉ token | Chi phí lưu trữ
---|---|---|---|---|---
Textual Inversion | ✗ | ✗ | - | ✓ | <0.1MB
Dreambooth | ✗ | ✗ | - | ✗ | 3.3GB
Custom Diffusion | ✓ | ✗ | Cắt | ✗ | 72MB
Cones | ✓ | ✓ | Cắt | ✗ | 1∼10MB
Break-A-Scene | ✓ | ✓ | Mặt nạ | ✗ | 4.9GB
MCPL (Của chúng tôi) | ✓ | ✓ | Văn bản | ✓ | <0.1MB

Trong công việc này, chúng tôi khám phá việc học các khái niệm cấp độ đối tượng chỉ sử dụng các mô tả ngôn ngữ tự nhiên và chỉ cập nhật và lưu trữ embedding văn bản (token). Chúng tôi bắt đầu với một nghiên cứu động lực xác nhận rằng, không cập nhật các tham số DM, trong khi việc áp dụng mặt nạ hoặc cắt tạo ra các embedding riêng biệt, việc học và chỉnh sửa cấp độ đối tượng chỉ dựa vào mô tả ngôn ngữ vẫn còn thách thức. Được thúc đẩy bởi phát hiện này, chúng tôi giới thiệu Multi-Concept Prompt Learning (MCPL) Hình 3 (Trên cùng) cho việc học không cần mặt nạ dựa trên văn bản của nhiều prompt từ một cảnh.

Tuy nhiên, không có các giả định thêm về mối quan hệ embedding, việc học đồng thời nhiều prompt là có vấn đề. Mô hình có thể bỏ qua các liên kết ngữ nghĩa và thay vào đó ưu tiên tối ưu hóa nhiều vector embedding để tái tạo tối ưu ở mức độ hình ảnh. Để tăng cường độ chính xác của tương quan prompt-đối tượng cấp độ, chúng tôi đề xuất các kỹ thuật chính quy hóa sau: 1) Để đảm bảo một tương quan tập trung giữa mỗi cặp prompt-khái niệm, chúng tôi đề xuất Attention Masking (AttnMask), hạn chế việc học prompt đối với các vùng liên quan được xác định bởi mặt nạ hướng dẫn sự chú ý chéo. 2) Nhận thức rằng nhiều đối tượng trong một cảnh có ý nghĩa ngữ nghĩa khác biệt, chúng tôi giới thiệu Prompts Contrastive Loss (PromptCL) để tạo thuận lợi cho việc tách biệt các embedding prompt liên quan đến nhiều khái niệm. 3) Để tiếp tục cho phép kiểm soát chính xác mỗi embedding đã học, chúng tôi liên kết mỗi prompt có thể học với một từ tính từ mô tả liên quan, được gọi là Bind adj., mà chúng tôi quan sát thực nghiệm có tương quan vùng mạnh mẽ. Hàng giữa và dưới cùng của Hình 3 minh họa các kỹ thuật chính quy hóa đề xuất. Đánh giá của chúng tôi cho thấy rằng framework của chúng tôi cải thiện độ chính xác trong việc học các khái niệm cấp độ đối tượng và tạo thuận lợi cho việc tạo ra giả thuyết có thể giải thích thông qua chỉnh sửa cục bộ. Điều này được thực hiện mà không yêu cầu chú thích hình ảnh rõ ràng, như được minh họa trong Hình 1 (của chúng tôi).

Trong công việc này, chúng tôi triển khai phương pháp đề xuất dựa trên Textual Inversion của (Gal et al., 2022), chỉ học và lưu trữ các embedding văn bản, và bổ sung cho các cách tiếp cận tập trung vào tạo sinh đắt đỏ hơn cập nhật các tham số DM (xem Bảng 1). Theo hiểu biết của chúng tôi, kỹ thuật của chúng tôi là kỹ thuật đầu tiên học nhiều khái niệm cấp độ đối tượng mà không sử dụng cắt hoặc mặt nạ. Để đánh giá nhiệm vụ mới này, chúng tôi tạo ra và thu thập các hình ảnh tự nhiên trong phân phối và hình ảnh y sinh học ngoài phân phối, mỗi hình ảnh có 2 đến 5 khái niệm cùng với mặt nạ cấp độ đối tượng. Điều này dẫn đến một tập dữ liệu bao gồm 25 khái niệm và 1.000 cặp câu-hình ảnh. Chúng tôi chạy khoảng 3500 giờ GPU thử nghiệm để so sánh với các phương pháp cạnh tranh, với mỗi lần chạy mất khoảng một giờ. Chúng tôi đánh giá việc tách biệt khái niệm bằng t-SNE và đánh giá độ tương tự embedding đối tượng so với sự thật nền đã được che mặt nạ trong các không gian embedding BERT, CLIP, DINOv1, và DINOv2 đã được huấn luyện trước. Kết quả của chúng tôi cho thấy rằng phương pháp của chúng tôi có thể xác định nhiều khái niệm trong một hình ảnh và hỗ trợ khám phá các khái niệm mới chỉ sử dụng mô tả văn bản.

2. Các Công Trình Liên Quan
Khám phá khái niệm thị giác dựa trên ngôn ngữ. Trong nhiều lĩnh vực khoa học, khám phá thường bắt đầu bằng quan sát thị giác và sau đó tiến triển bằng cách khám phá cơ sở kiến thức hiện có để xác định các khái niệm cấp độ đối tượng không quen thuộc. Các khái niệm này sau đó được định nghĩa bằng các thuật ngữ mới, tạo thuận lợi cho việc phát triển các giả thuyết (Schickore, 2022). Sự xuất hiện của trí tuệ nhân tạo, đặc biệt là các Mô hình Thị giác-Ngôn ngữ (VLM) lớn đã được huấn luyện trước, đã đặt nền móng cho việc tự động hóa quá trình khám phá này (Wang et al., 2023). Chỉnh sửa cục bộ dựa trên ngôn ngữ trong VLM cho thấy triển vọng giúp các nhà khoa học tạo ra giả thuyết và tạo ra các thiết kế (Hertz et al., 2022; Tumanyan et al., 2023; Patashnik et al., 2023). Tuy nhiên, một thách thức chính vẫn còn: chỉ dựa vào các mô tả ngôn ngữ, các phương pháp hiện tại có thể không luôn ánh xạ các từ vào các khái niệm cấp độ đối tượng tương ứng một cách chính xác.

Học prompt cho Mô hình Diffusion. Trong tổng hợp hình ảnh hướng dẫn bởi văn bản, học prompt liên kết hình dạng và phong cách của một hình ảnh không nhìn thấy với một prompt có thể học, cho phép chuyển giao sang các hình ảnh mới. Điều này được thực hiện bằng cách học và lưu trữ các embedding văn bản, như trong Textual Inversion (Gal et al., 2022), hoặc bằng cách tối ưu hóa toàn bộ mô hình diffusion để tái tạo một hình ảnh ví dụ đã cho, như được chứng minh trong DreamBooth (Ruiz et al., 2022).

--- TRANG 3 ---
Một Hình Ảnh Đáng Giá Nhiều Từ: Khám Phá Các Khái Niệm Cấp Độ Đối Tượng Sử Dụng Học Prompt Đa Khái Niệm

Học và kết hợp nhiều khái niệm. Các tiến bộ gần đây tập trung vào việc kết hợp hiệu quả nhiều khái niệm được học riêng biệt từ các hình ảnh hoặc phần cắt đối tượng đơn lẻ (Custom Diffusion (Kumari et al., 2023), Cones (Liu et al., 2023), SVDiff (Han et al., 2023), Perfusion (Tewel et al., 2023)). ELITE (Wei et al., 2023) và Break-A-Scene (Avrahami et al., 2023) áp dụng mặt nạ để cải thiện việc học khái niệm cấp độ đối tượng, với Break-A-Scene đặc biệt nhằm mục đích học đa khái niệm và tích hợp trong các hình ảnh đơn lẻ, phù hợp chặt chẽ với mục tiêu của chúng tôi. Cách tiếp cận của chúng tôi khác với Break-A-Scene ở hai khía cạnh chính: 1) chúng tôi nhằm mục đích loại bỏ nhu cầu chú thích hình ảnh tốn nhiều công sức, và 2) chúng tôi khám phá giới hạn của việc học đa khái niệm mà không cập nhật hoặc lưu trữ các tham số DM. Inspiration Tree (IT) (Vinker et al., 2023) chia sẻ tinh thần tương tự như công việc của chúng tôi. MCPL xuất sắc trong khám phá theo hướng dẫn chỉ dẫn, thành thạo trong việc xác định các khái niệm khác biệt cả về mặt thị giác và ngôn ngữ, trong khi IT chuyên môn hóa trong việc tiết lộ các khái niệm trừu tượng và tinh tế độc lập với hướng dẫn trực tiếp của con người.

3. Phương Pháp
Trong phần này, chúng tôi nêu ra các kiến thức cơ bản trong Phần 3.1 và trình bày một nghiên cứu động lực trong Phần 3.2. Các thử nghiệm này xác nhận sự hiện diện của các embedding cấp độ đối tượng trong không gian embedding văn bản đã được huấn luyện trước, làm nổi bật những thách thức trong việc học nhiều khái niệm mà không có chú thích hình ảnh. Được truyền cảm hứng từ những kết quả này, chúng tôi giới thiệu Multi-Concept Prompt Learning (MCPL) trong Phần 3.3. Để giải quyết thách thức tối ưu hóa đa đối tượng cùng với mục tiêu tái tạo cấp độ hình ảnh đơn lẻ, chúng tôi đề xuất một số kỹ thuật chính quy hóa trong Phần 3.4.

3.1. Kiến Thức Cơ Bản
Các mô hình diffusion hướng dẫn bởi văn bản là các mô hình tạo sinh xác suất ước lượng phân phối dữ liệu (cụ thể là hình ảnh trong công việc của chúng tôi) bằng cách tiến hóa khử nhiễu nhiễu Gaussian ngẫu nhiên, được điều kiện hóa bởi các embedding văn bản. Cụ thể, chúng tôi quan tâm đến một mạng khử nhiễu ϵθ được huấn luyện trước sao cho, cho một bản đồ nhiễu Gaussian ban đầu ngẫu nhiên ϵ∼N(0,I), được điều kiện hóa bởi các embedding văn bản v, tạo ra một hình ảnh ˜x=ϵθ(ϵ, v) gần giống với một hình ảnh ví dụ đã cho x. Ở đây, v=cϕ(p), trong đó cϕ là một bộ mã hóa văn bản đã được huấn luyện trước với các tham số ϕ và p là văn bản. Trong quá trình huấn luyện, ϕ và θ được tối ưu hóa cùng nhau để khử nhiễu một embedding hình ảnh bị nhiễu zt để giảm thiểu loss:

LDM=LDM(x,˜x) :=Ez,v,ϵ,t∥ϵ−ϵθ(zt, v)∥2.(1)

Ở đây, zt:=αtz+σtϵ là phiên bản bị nhiễu của embedding hình ảnh ban đầu z tại thời điểm t∼Uniform (1, T), αt, σt là các thuật ngữ lập lịch nhiễu, và z=E(x), trong đó E là bộ mã hóa của một autoencoder đã được huấn luyện trước D(E(x))≈x, theo Latent Diffusion Models (LDMs) (Rombach et al., 2022) để có hiệu quả tính toán. Trong quá trình suy luận, mô hình đã được huấn luyện trước lặp lại loại bỏ nhiễu từ một bản đồ nhiễu ngẫu nhiên mới để tạo ra một hình ảnh mới.

Textual Inversion (Gal et al., 2022) nhằm mục đích xác định embedding văn bản v* cho một prompt mới p* với {ϵθ, cϕ} đã được huấn luyện trước. Cho một vài (3-5) hình ảnh ví dụ đại diện cho một chủ thể hoặc khái niệm cụ thể, phương pháp này tối ưu hóa v* trong không gian tiềm ẩn đã đóng băng của bộ mã hóa văn bản cϕ. Mục tiêu là tạo ra hình ảnh thông qua mạng khử nhiễu ϵθ gần giống với các hình ảnh ví dụ (sau khi giải mã) khi được điều kiện hóa bởi v*. Quá trình tối ưu hóa được hướng dẫn bởi loss mô hình diffusion được định nghĩa trong phương trình 1, chỉ cập nhật v* trong khi giữ cϕ và ϵθ đóng băng. Trong quá trình huấn luyện, việc tạo sinh được điều kiện hóa bởi các prompt kết hợp các mẫu văn bản y được chọn ngẫu nhiên (ví dụ: "A photo of", "A sketch of" từ CLIP (Radford et al., 2021)) với prompt mới p*, tạo ra các cụm từ như "A photo of p*" và "A sketch of p*".

Các lớp sự chú ý chéo đóng vai trò quan trọng trong việc hướng dẫn quá trình diffusion được dẫn dắt bởi văn bản. Trong mạng khử nhiễu, ϵθ, tại mỗi bước thời gian t, embedding văn bản, v=cϕ(p), tương tác với embedding hình ảnh, zt, thông qua lớp sự chú ý chéo. Ở đây, Q=fQ(zt), K=fK(v), và V=fV(v) được thu được bằng cách sử dụng các lớp tuyến tính đã học fQ, fK, fV. Như (Hertz et al., 2022) đã nêu bật, các bản đồ sự chú ý chéo cho mỗi prompt, M=Softmax (QKT/√d), tương quan với độ tương tự giữa Q và K. Do đó, trung bình của các bản đồ sự chú ý chéo trên tất cả các bước thời gian phản ánh các vùng quan trọng tương ứng với mỗi từ prompt, như được mô tả trong Hình 3.

Trong nghiên cứu này, bản đồ sự chú ý cho mỗi prompt là một chỉ số chính để đánh giá tương quan prompt-khái niệm. Kết quả của chúng tôi sẽ cho thấy rằng không có các ràng buộc đầy đủ, các bản đồ sự chú ý cho các prompt mới học thường thiếu sự tách biệt nhất quán và tương quan prompt-khái niệm chính xác.

3.2. Nghiên cứu động lực
Để hiểu khả năng học nhiều khái niệm trong một không gian embedding văn bản đã đóng băng, chúng tôi khám phá liệu Textual Inversion có thể phân biệt các khái niệm khác biệt về mặt ngữ nghĩa từ cả hình ảnh đã được che mặt nạ và được cắt, mỗi hình ảnh làm nổi bật một khái niệm duy nhất. Hình 2 (hai ví dụ bên trái) đưa ra một điểm nổi bật về kết quả của chúng tôi, với phiên bản đầy đủ trong Phụ lục A.9, xác nhận rằng: 1) nhiều embedding độc đáo có thể được rút ra từ một hình ảnh đa khái niệm duy nhất, mặc dù với sự can thiệp của con người, và 2) mặc dù có các khái niệm cá nhân được học tốt, việc tổng hợp chúng thành một cảnh đa khái niệm thống nhất vẫn còn thách thức. Để giải quyết những vấn đề này, chúng tôi giới thiệu framework Multi-Concept Prompt Learning (MCPL). MCPL sửa đổi Textual Inversion để cho phép học đồng thời nhiều prompt trong cùng một chuỗi.

--- TRANG 4 ---
Một Hình Ảnh Đáng Giá Nhiều Từ: Khám Phá Các Khái Niệm Cấp Độ Đối Tượng Sử Dụng Học Prompt Đa Khái Niệm

T.I.: học riêng biệt + kết hợp
"một bức ảnh * xanh lá cây" "một bức ảnh @ cam"
hợp nhất embeddings 
 "một bức ảnh * xanh lá cây và @ cam"MCPL-one: học đồng thời đa khái niệm MCPL-diverse: học đa khái niệm cho mỗi hình ảnh
"một bức ảnh * xanh lá cây {} @ cam"
trên dưới phía trước trên dưới phía trước
"một bức ảnh * xanh lá cây {} @ cam"trên dưới phía trước
"một bức ảnh * xanh lá cây {} @ cam"
trên dưới phía trước
"một bức ảnh * xanh lá cây {} @ cam""một bức ảnh  
* (mặt đồng hồ + dây đồng hồ) "học tạo ra
"một bức ảnh @ (mặt đồng hồ) "
"một bức ảnh ! (dây đồng hồ) "

Hình 2. Nghiên cứu động lực và kết quả MCPL sơ bộ. Chúng tôi sử dụng Textual Inversion (T.I.) để học các khái niệm từ cả hình ảnh đã được che mặt nạ (trái-đầu tiên) hoặc được cắt (trái-thứ hai); MCPL-one, học cả hai khái niệm đồng thời từ hình ảnh đầy đủ với một chuỗi duy nhất; và MCPL-diverse tính đến các mối quan hệ cụ thể cho mỗi hình ảnh.

3.3. Multi-Concept Prompt Learning (MCPL)
Với (các) hình ảnh ví dụ x, MCPL học một danh sách các embedding V= [v*, . . . , v&] tương ứng với nhiều prompt mới P= [p*, . . . , p&] trong câu mô tả như được thể hiện trong Hình 3. Quá trình tối ưu hóa được hướng dẫn bởi LDM cấp độ hình ảnh (phương trình 1), nhưng bây giờ cập nhật V trong khi giữ cϕ và ϵθ đóng băng. Thuật toán MCPL được nêu ra trong Thuật toán 1. Ở đây mỗi câu P có thể được chia thành một tập hợp các từ danh từ của các khái niệm mục tiêu [n*, . . . , n&], một tập hợp các từ tính từ [a*, . . . , a&] mô tả mỗi danh từ và phần còn lại các văn bản giới từ [t*, . . . , t&] trong câu (loại trừ các văn bản trung tính ngẫu nhiên ví dụ: "a photo of"). Mỗi nhóm phụ có thể được chỉ định là có thể học hoặc cố định, tùy thuộc vào các chiến lược huấn luyện mà chúng tôi sẽ định nghĩa trong phần tiếp theo. Để đánh giá, chúng tôi yêu cầu một con người hoặc một máy móc, chẳng hạn như GPT-4, mô tả mỗi hình ảnh bằng cách sử dụng một tính từ và một danh từ cho mỗi khái niệm mục tiêu.

Thuật toán 1 MCPL (dạng chung)
1: Đầu vào: (các) hình ảnh ví dụ x, {cθ, ϵθ} đã được huấn luyện trước.
2: Đầu ra: một danh sách các embedding V= [v*, . . . , v&] tương ứng với nhiều prompt mới P= [p*, . . . , p&].
3: khởi tạo [v*, . . . , v&] = [cθ(p*), . . . , cθ(p&)]
4: # tối ưu hóa {v*, . . . , v&} với LDM
5: for bước = 1 to S do
6:     Mã hóa (các) hình ảnh ví dụ z=E(x) và lấy mẫu ngẫu nhiên các văn bản trung tính y
    để tạo chuỗi [y, p*, . . . , p&]
7:     Tính toán V†= [vy, v*, . . . , v&] = [cθ(py), cθ(p*), . . . , cθ(p&)]
8:     for t=T down to 1 do
9:         V:= arg minV Ez,V,ϵ,t∥ϵ−ϵθ(zt,V†)∥2
10:    end for
11: end for
12: Return (P,V)

Chiến lược huấn luyện và kết quả sơ bộ. Nhận thức được sự phức tạp của việc học nhiều embedding với mục tiêu tạo sinh hình ảnh đơn lẻ, chúng tôi đề xuất ba chiến lược huấn luyện: 1) MCPL-all, một cách tiếp cận đơn giản học embedding cho tất cả các prompt trong chuỗi (bao gồm tính từ, giới từ và danh từ, v.v.); 2) MCPL-one, đơn giản hóa mục tiêu bằng cách học prompt đơn (danh từ) cho mỗi khái niệm; 3) MCPL-diverse, trong đó các chuỗi khác nhau được học cho mỗi hình ảnh để quan sát sự khác biệt giữa các ví dụ. Các định nghĩa chính thức của mỗi chiến lược huấn luyện MCPL được đưa ra trong Phụ lục A.14. Đánh giá sơ bộ của các phương pháp MCPL-one và MCPL-diverse trên nhiệm vụ đa khái niệm "ball" và "box" được thể hiện trong Hình 2. Phát hiện của chúng tôi chỉ ra rằng MCPL-one tăng cường việc học đồng thời nhiều khái niệm trong cùng một cảnh so với học riêng biệt. Trong khi đó, MCPL-diverse tiến xa hơn bằng cách tạo thuận lợi cho việc học các mối quan hệ phức tạp giữa nhiều khái niệm.

Hạn chế của MCPL đơn giản. Chúng tôi nhằm mục đích khám phá các khái niệm thị giác mới chỉ sử dụng mô tả ngôn ngữ và sau đó cho phép chỉnh sửa cục bộ chính xác. Nó yêu cầu tương quan prompt-khái niệm cấp độ đối tượng chính xác, để đánh giá, chúng tôi hình dung hóa các bản đồ sự chú ý chéo trung bình cho mỗi prompt. Như được mô tả trong Hình 4 (trên cùng), MCPL đơn giản không thể nắm bắt tương quan này một cách đầy đủ, đặc biệt là đối với khái niệm mục tiêu. Những kết quả này cho thấy rằng việc mở rộng một cách đơn giản các kỹ thuật học prompt cấp độ hình ảnh (Gal et al., 2022) sang việc học đa khái niệm cấp độ đối tượng đặt ra những thách thức tối ưu hóa, bất chấp những nỗ lực tái công thức hóa vấn đề đã thảo luận trong Phần 3.3. Cụ thể, việc tối ưu hóa nhiều prompt cấp độ đối tượng dựa trên mục tiêu cấp độ hình ảnh đơn lẻ tỏ ra không đơn giản. Cho phương trình loss tạo sinh hình ảnh 1, các embedding prompt có thể hội tụ về các giải pháp tầm thường ưu tiên tái tạo cấp độ hình ảnh với chi phí của các tương quan prompt-đối tượng ngữ nghĩa, do đó mâu thuẫn với mục tiêu của chúng tôi. Trong phần tiếp theo, chúng tôi giới thiệu nhiều thuật ngữ chính quy hóa để vượt qua thách thức này.

  "a        photo       of       green        *          on      orange       @" Hình ảnh mặt nạ
MCPL
MCPL
+AttnMask
+PromptCL
+Bind adj.

Hình 4. Tăng cường tương quan prompt-khái niệm cấp độ đối tượng trong MCPL bằng cách sử dụng các chính quy hóa đề xuất: AttnMask, PromptCL và Bind adj. Chúng tôi so sánh MCPL-one áp dụng tất cả các thuật ngữ chính quy hóa với MCPL-one, sử dụng ví dụ "Ball and Box". Chúng tôi sử dụng các bản đồ sự chú ý chéo trung bình và AttnMask để đánh giá độ chính xác của tương quan. Kết quả ablation đầy đủ trong Phụ lục A.10

--- TRANG 5 ---
Một Hình Ảnh Đáng Giá Nhiều Từ: Khám Phá Các Khái Niệm Cấp Độ Đối Tượng Sử Dụng Học Prompt Đa Khái Niệm

  "a          brown          *             on            a          r olling          &            at            times       squar e"Tại một bước diffusion
Attention Masking (AttnMask): các bản đồ sự chú ý chéo trung bình (           ) qua tất cả các bước thời gian
"a br own * (gấu teddy)  on
a rolling & (ván trượt) at
times squar e"bộ mã hóa văn bản  
đã đóng băng  mạng khử nhiễu
văn bản thành hình ảnh đã đóng băng
embeddings
văn bản
Prompts Contrastive Loss (Pr omptCL)embeddings văn bản
K
Qembeddings pixel
U-net khử nhiễu sự chú ý
chéo
sự chú ý
chéo

Hình 3. Tổng quan phương pháp. MCPL lấy một câu (trên-trái) và một hình ảnh mẫu x0 (trên-phải) làm đầu vào, đưa chúng vào một mô hình diffusion hướng dẫn bởi văn bản đã được huấn luyện trước bao gồm một bộ mã hóa văn bản cϕ và một mạng khử nhiễu ϵθ. Nhiều prompt của chuỗi được mã hóa thành một chuỗi embeddings hướng dẫn mạng tạo ra hình ảnh ˜x0 gần với hình ảnh mục tiêu x0. MCPL tập trung vào việc học nhiều prompt có thể học (văn bản có màu), chỉ cập nhật embeddings v* và v& của các prompt có thể học trong khi giữ cϕ và ϵθ đóng băng. Chúng tôi giới thiệu Prompts Contrastive Loss (PromptCL) để giúp tách biệt nhiều khái niệm trong các embedding có thể học. Chúng tôi cũng áp dụng Attention Masking (AttnMask), sử dụng mặt nạ dựa trên sự chú ý chéo trung bình của các prompt, để tinh chỉnh việc học prompt trên hình ảnh. Tùy chọn, chúng tôi liên kết mỗi prompt có thể học với một tính từ (ví dụ: "brown") để cải thiện kiểm soát mỗi khái niệm đã học, được gọi là Bind adj.

3.4. Chính quy hóa việc học prompt đa khái niệm

Khuyến khích tương quan prompt-khái niệm tập trung với Attention Masking (AttnMask). Kết quả trước đây cho thấy MCPL đơn giản có thể học các prompt tập trung vào các khu vực không liên quan. Để khắc phục điều này, chúng tôi áp dụng mặt nạ cho cả hình ảnh được tạo ra và hình ảnh mục tiêu trên tất cả các bước khử nhiễu (Hình 3, giữa-phải). Những mặt nạ này, được rút ra từ sự chú ý chéo trung bình của các prompt có thể học đã chọn (Hình 3, hàng dưới cùng), hạn chế loss tạo sinh hình ảnh (phương trình 1) tập trung vào các khu vực liên quan, do đó cải thiện tương quan prompt-khái niệm. Để tính toán mặt nạ, chúng tôi tính toán cho mỗi prompt có thể học đã chọn p∈P bản đồ sự chú ý trung bình trên tất cả các bước thời gian Mp= 1/T∑T t=1Mp t. Sau đó chúng tôi áp dụng một ngưỡng để tạo ra các bản đồ nhị phân cho mỗi prompt có thể học, trong đó B(Mp) :={1 nếu Mp> k, 0 ngược lại} và k= 0.5 trong suốt tất cả các thí nghiệm của chúng tôi. Đối với mục tiêu học nhiều prompt, mặt nạ cuối cùng M là một hợp của nhiều mặt nạ nhị phân của tất cả các prompt có thể học M=∪p∈P B(Mp). Chúng tôi tính toán tích Hadamard của M với x và ˜x để rút ra loss được che mặt nạ LAttnMask DM như phương trình 2. AttnMask của chúng tôi được lấy cảm hứng từ (Hertz et al., 2022), nhưng là một đảo ngược của cùng một ý tưởng, trong đó AttnMask được áp dụng trên loss cấp độ pixel phương trình 1 để hạn chế việc học prompt chỉ đối với các vùng liên quan.

LAttnMask DM =LDM(M ⊙ x,M ⊙ ˜x), (2)

Khuyến khích đa khái niệm tách biệt về mặt ngữ nghĩa với Prompts Contrastive Loss (PromptCL). AttnMask tập trung việc học nhiều prompt trên khu vực chung của các đối tượng mục tiêu, loại bỏ ảnh hưởng của các vùng không liên quan như nền. Tuy nhiên, nó không thúc đẩy một cách nội tại sự tách biệt giữa các embedding của các khái niệm mục tiêu khác nhau. Tận dụng tính loại trừ lẫn nhau của nhiều đối tượng trong một hình ảnh, chúng tôi giới thiệu một loss đối lập trong không gian tiềm ẩn nơi các embedding được tối ưu hóa. Cụ thể, chúng tôi sử dụng loss InfoNCE (Oord et al., 2018), một tiêu chuẩn trong học đối lập và đại diện, để khuyến khích sự tách biệt giữa các nhóm embedding tương ứng với các khái niệm có thể học khác biệt (Hình 3, giữa-trái).

Cụ thể, tại mỗi bước học như được mô tả trong Thuật toán 1, một mini-batch B các hình ảnh ví dụ phụ hoặc được tăng cường (ví dụ: với lật ngẫu nhiên) được lấy mẫu, với N prompt có thể học cho mỗi hình ảnh, tạo ra một tập hợp BN embedding, {vn b}B b=1,N n=1. Sau đó, độ tương tự giữa mỗi cặp vi và vj của BN mẫu được tính toán bằng cách sử dụng độ tương tự cosine:

sim(vi, vj) =vT i.vj/||vi||||vj||. (3)

Cho mục tiêu của chúng tôi là phân biệt các embedding tương ứng với mỗi prompt, chúng tôi coi các embedding của cùng một khái niệm là mẫu tích cực trong khi các embedding khác là mẫu tiêu cực. Tiếp theo, loss đối lập lη i,j∈B cho một cặp tích cực vη i và vη j của mỗi khái niệm η∈N (hai góc nhìn tăng cường của hình ảnh ví dụ) được thể hiện trong phương trình 4, trong đó τ là tham số nhiệt độ theo (Chen et al., 2020). Loss đối lập được tính toán cho BN góc nhìn của mỗi khái niệm có thể học N. Tổng loss đối lập LPromptCL được thể hiện trong phương trình 5.

lη i,j∈B=−log(exp(sim(vη i, vη j))/τ / ∑N η=1∑B j=1,j≠i exp(sim(vη i, vη j)/τ)) (4)

LPromptCL =1/N 1/BN ∑N η=1∑B i=1 lη i,j∈B (5)

Tăng cường tương quan prompt-khái niệm bằng cách liên kết prompt có thể học với từ tính từ (Bind adj.). Một quan sát bổ sung từ các kết quả không căn chỉnh trong Hình 4 (trên cùng) cho thấy rằng các từ tính từ thường có tương quan mạnh mẽ với các vùng cụ thể. Điều này cho thấy rằng mô hình đã được huấn luyện trước đã thành thạo trong việc nhận biết các khái niệm mô tả như màu sắc hoặc thuật ngữ "fluffy" (xem kết quả đầy đủ trong Hình 36). Để tận dụng hiểu biết bẩm sinh này, chúng tôi đề xuất tùy chọn liên kết một từ tính từ với mỗi prompt có thể học như một nhóm tích cực trong quá trình tính toán loss đối lập. Cụ thể, xem xét M từ tính từ liên kết với N prompt có thể học. Sau đó cặp tích cực vη i và vη j của mỗi khái niệm được lấy mẫu từ η∈MB thay vì B. Do đó loss đối lập bây giờ được tính toán cho BNM góc nhìn của mỗi khái niệm có thể học N. Tổng loss đối lập kết quả Ladj PromptCL được chi tiết trong phương trình 6. Chúng tôi chia tỷ lệ Ladj PromptCL với một thuật ngữ chia tỷ lệ γ và cộng với LAttnMask DM (phương trình 2), để chúng có độ lớn tương đương, dẫn đến loss cuối cùng của chúng tôi trong phương trình 7.

Ladj PromptCL =1/N 1/MBN ∑N η=1∑MB i=1 lη i,j∈B (6)

L=LAttnMask DM +γLadj PromptCL, (7)

Đánh giá các thuật ngữ chính quy hóa với sự chú ý chéo. Chúng tôi đánh giá các thuật ngữ chính quy hóa đề xuất về việc cải thiện độ chính xác của các tương quan ngữ nghĩa giữa các prompt và khái niệm. Chúng tôi hình dung hóa sự chú ý chéo và mặt nạ phân đoạn, như được thể hiện trong Hình 4. Kết quả hình ảnh của chúng tôi cho thấy rằng việc kết hợp tất cả các thuật ngữ chính quy hóa đề xuất tăng cường sự tách biệt khái niệm, trong khi áp dụng chúng một cách riêng lẻ cho kết quả dưới tối ưu (tham khảo kết quả ablation đầy đủ trong Phụ lục A.10). Hơn nữa, kết quả chứng minh rằng MCPL-one là một chiến lược học hiệu quả hơn MCPL-all, làm nổi bật tầm quan trọng của việc loại trừ các prompt không liên quan để duy trì mục tiêu học tập trung.

4. Thí nghiệm
4.1. Chi tiết Thí nghiệm và Triển khai

Tập dữ liệu đa khái niệm. Chúng tôi tạo ra các hình ảnh tự nhiên trong phân phối và thu thập các hình ảnh y sinh học ngoài phân phối, mỗi hình ảnh có 2 đến 5 khái niệm cùng với mặt nạ cấp độ đối tượng. Điều này dẫn đến một tập dữ liệu bao gồm 25 khái niệm và 1.000 cặp câu-hình ảnh. Đối với hình ảnh tự nhiên, chúng tôi tạo ra hình ảnh đa khái niệm bằng cách sử dụng chỉnh sửa cục bộ trước đây (Patashnik et al., 2023) và phương pháp kết hợp đa khái niệm (Avrahami et al., 2023), cả hai đều hỗ trợ tạo ra hoặc dự đoán mặt nạ đối tượng. Chúng tôi tạo ra mỗi hình ảnh bằng cách sử dụng các prompt đơn giản, bao gồm một tính từ và một danh từ cho mỗi khái niệm liên quan. Đối với hình ảnh y sinh học, chúng tôi yêu cầu một con người hoặc một máy móc, chẳng hạn như GPT-4, mô tả tương tự mỗi hình ảnh bằng cách sử dụng một tính từ và một danh từ cho mỗi khái niệm liên quan. Để biết thêm chi tiết, danh sách đầy đủ các prompt được sử dụng và ví dụ, vui lòng đọc Phụ lục A.16. Chúng tôi phát hành tập dữ liệu ở đây.

Các Phương pháp Cạnh tranh. Chúng tôi so sánh ba phương pháp cơ sở: 1) Textual Inversion (TI-m) được áp dụng cho mỗi đối tượng được che mặt nạ phục vụ như ước tính tốt nhất của chúng tôi cho embedding "sự thật nền" đối tượng tách biệt chưa biết. 2) Break-A-Scene (BAS), phương pháp học đa khái niệm dựa trên mặt nạ tiên tiến nhất (SoTA), phục vụ như một giới hạn hiệu suất trên, mặc dù nó không thể so sánh trực tiếp. 3) MCPL-all như sự thích ứng ngây thơ của chúng tôi với phương pháp Textual Inversion để đạt được mục tiêu học đa khái niệm. Đối với phương pháp của chúng tôi, chúng tôi so sánh hai chiến lược huấn luyện: MCPL-all và MCPL-one. Đối với mỗi chiến lược, chúng tôi xem xét ba biến thể để xem xét kỹ lưỡng tác động của các thuật ngữ chính quy hóa đã thảo luận trong Phần 3.4. Tất cả việc học MCPL được thực hiện trên hình ảnh không được che mặt nạ mà không cập nhật các tham số DM. Để đánh giá khả năng mạnh mẽ và khả năng tách biệt khái niệm của mỗi phương pháp học, chúng tôi lặp lại học mỗi cặp đa khái niệm khoảng 10 lần, lấy mẫu ngẫu nhiên bốn hình ảnh mỗi lần. Chúng tôi tạo ra tổng cộng 560 đối tượng được che mặt nạ cho mỗi biến thể MCPL và 320 cho cơ sở BAS.

Tuy nhiên, điều quan trọng cần lưu ý là việc chuẩn bị BAS như giới hạn trên embedding cấp độ đối tượng là tốn kém, vì nó yêu cầu một mô hình phân đoạn được huấn luyện trước bổ sung, và đôi khi con người tham gia vào vòng lặp, để có được mặt nạ trong cả giai đoạn học và đánh giá (xem Phụ lục A.17 để biết chi tiết). Ngược lại, phương pháp của chúng tôi sử dụng AttnMask của chính nó để tạo ra các khái niệm được che mặt nạ trong quá trình tạo sinh hình ảnh mà không có chi phí bổ sung.

Chi tiết triển khai. Chúng tôi sử dụng cùng các prompt được thu thập trong quá trình chuẩn bị dữ liệu, thay thế danh từ làm prompt có thể học, được hợp nhất với các prompt CLIP từ Phần 3.1. Quá trình này tạo ra các cụm từ như "A photo of brown * on a rolling @ at times square". Vui lòng tìm chi tiết triển khai đầy đủ trong Phụ lục A.15.

--- TRANG 6 ---
Một Hình Ảnh Đáng Giá Nhiều Từ: Khám Phá Các Khái Niệm Cấp Độ Đối Tượng Sử Dụng Học Prompt Đa Khái Niệm

4.2. Đánh giá Định lượng

Điều tra sự tách biệt khái niệm với t-SNE. Chúng tôi nhằm mục đích học các lớp khác biệt về mặt ngữ nghĩa do đó thiết kế thí nghiệm của chúng tôi, do đó chúng tôi mong đợi một hiệu ứng phân cụm trong đó các đối tượng của cùng một lớp tự nhiên phân cụm với nhau. Để đánh giá việc phân cụm, chúng tôi bắt đầu bằng cách tính toán và hình dung hóa phép chiếu t-SNE của các đặc trưng đã học (Van der Maaten & Hinton, 2008). Kết quả, được mô tả trong Hình 5, bao gồm cả tập dữ liệu tự nhiên và y sinh học. Chúng minh họa rằng MCPL-one của chúng tôi kết hợp với tất cả các thuật ngữ chính quy hóa có thể phân biệt hiệu quả tất cả các khái niệm đã học so với tất cả các cơ sở. Các embedding đã học từ cả "sự thật nền" dựa trên mặt nạ và BAS kém phân biệt hơn so với của chúng tôi, do không có mục tiêu tách biệt như loss PromptCL của MCPL.

Hình ảnh tự nhiên trong phân phối | Hình ảnh y sinh học ngoài phân phối
---|---
SoTA dựa trên mặt nạ: Break-A-Scene | SoTA dựa trên mặt nạ: Break-A-Scene
'Sự thật nền': Textural Inversion (T.I.) + mặt nạ | 'Sự thật nền': Textural Inversion (T.I.) + mặt nạ
Của chúng tôi: MCPL-one + AttnMask + PromptCL + Bind adj. | Của chúng tôi: MCPL-one + AttnMask + PromptCL + Bind adj.
MCPL-all (sửa đổi T.I. để học tất cả prompt) | MCPL-all (sửa đổi T.I. để học tất cả prompt)

Hình 5. Phép chiếu t-SNE của các embedding đã học. Phương pháp của chúng tôi có thể phân biệt hiệu quả tất cả các khái niệm đã học (khoảng 10 embedding mỗi khái niệm) so với Textual Inversion (MCPL-all), phương pháp học dựa trên mặt nạ SoTA, Break-A-Scene, và "sự thật nền" được che mặt nạ (xem kết quả đầy đủ trong Phụ lục A.7).

Độ tương tự embedding so với "sự thật nền". Để đánh giá việc bảo tồn chi tiết ngữ nghĩa và văn bản cho mỗi khái niệm, chúng tôi tính toán cả độ trung thực prompt và hình ảnh. Đánh giá này theo nghiên cứu trước đây của (Gal et al., 2022) và (Ruiz et al., 2022), nhưng khác biệt, chúng tôi thực hiện các tính toán ở cấp độ đối tượng. Độ trung thực prompt được xác định bằng cách đo độ tương tự cosine trung bình từng cặp giữa các embedding được học từ "sự thật nền" ước tính và các hình ảnh được che mặt nạ được tạo ra, trong không gian embedding đã được huấn luyện trước của BERT (Devlin et al., 2018). Độ trung thực hình ảnh đề cập đến độ tương tự cosine trung bình từng cặp giữa hình ảnh "sự thật nền" được che mặt nạ và các đối tượng được che mặt nạ được tạo ra trong bốn không gian embedding đã được huấn luyện trước của CLIP (Radford et al., 2021), DINOv1 (Caron et al., 2021) và DINOv2 (Oquab et al., 2023), tất cả dựa trên ViT-S.

Kết quả trong Hình 6 cho thấy phương pháp của chúng tôi kết hợp với tất cả các thuật ngữ chính quy hóa đề xuất có thể cải thiện cả độ trung thực prompt và hình ảnh một cách nhất quán. Phiên bản được chính quy hóa hoàn toàn của chúng tôi (MCPL-one+CL+Mask) đạt được hiệu suất cạnh tranh so với phương pháp dựa trên mặt nạ SoTA (BAS) trên tập dữ liệu tự nhiên. Trong tập dữ liệu y tế OOD, BAS vượt trội hơn phương pháp của chúng tôi đáng kể trong không gian embedding DINOv1, mặc dù hiệu suất tương đương trong các không gian khác. Sự khác biệt bắt nguồn từ mặt nạ sự chú ý của phương pháp chúng tôi tạo ra các mặt nạ đối tượng kém chính xác hơn so với BAS có mặt nạ được thu thập thông qua một giao thức phân đoạn chuyên biệt có con người tham gia vào vòng lặp, như được chi tiết trong Phụ lục A.17. Sự khác biệt này được mô tả trong Hình 43, 44 và 7.

[Các biểu đồ độ tương tự embedding cho hình ảnh tự nhiên và y tế]

Hình 6. Độ tương tự embedding trong các khái niệm cấp độ đối tượng đã học so với "sự thật nền" được che mặt nạ (hai khái niệm mỗi hình ảnh). Chúng tôi so sánh Textual Inversion (MCPL-all) và phương pháp học dựa trên mặt nạ SoTA, BAS, với các phiên bản được chính quy hóa của chúng tôi. Phân tích được thực hiện trong cả không gian bộ mã hóa văn bản (BERT) và hình ảnh đã được huấn luyện trước (CLIP, DINOv1, và DINOv2), với mỗi thanh biểu diễn trung bình của 40k độ tương tự cosine từng cặp.

Học hơn hai khái niệm. Để xác nhận độ mạnh mẽ của phương pháp chúng tôi, chúng tôi mở rộng đánh giá sang các nhiệm vụ học có hơn hai khái niệm mỗi hình ảnh, cụ thể là hình ảnh tự nhiên chứa 3, 4, và 5 khái niệm. Chúng tôi nhóm các embedding đã học theo số lượng khái niệm mỗi hình ảnh để đánh giá tác động của chúng lên hiệu quả học. Kết quả trong Hình 8 tiết lộ rằng: 1) hiệu quả học giảm với sự tăng lên của số lượng khái niệm mỗi hình ảnh, một xu hướng cũng rõ ràng trong cách tiếp cận BAS dựa trên mặt nạ; 2) mặc dù phiên bản được chính quy hóa hoàn toàn của chúng tôi tiếp tục vượt trội so với các phiên bản được chính quy hóa dưới mức, khoảng cách hiệu suất với BAS mở rộng, làm nổi bật thách thức gia tăng của việc học đa khái niệm không cần mặt nạ trong các cảnh phức tạp hơn. Chúng tôi cũng thu thập tập dữ liệu hình ảnh thực để đánh giá tương tự và thu được kết luận nhất quán, với chi tiết đầy đủ trong Phụ lục A.2.

Đánh giá cấp độ đối tượng. Vì mục tiêu chính của chúng tôi là học chính xác các embedding cấp độ đối tượng, chúng tôi thực hiện một phân tích về độ tương tự embedding ở cấp độ đối tượng như được làm nổi bật trong Hình 9. Đáng chú ý, phương pháp của chúng tôi đôi khi vượt qua phương pháp dựa trên mặt nạ, BAS, ở cấp độ đối tượng. Điều này nhấn mạnh tiềm năng của cách tiếp cận không cần mặt nạ, dựa trên ngôn ngữ của chúng tôi trong việc học nhiều khái niệm từ một hình ảnh đơn lẻ.

Nghiên cứu người dùng. Cuối cùng, chúng tôi thu thập 41 nghiên cứu người dùng ẩn danh để đánh giá việc tuân theo prompt trong quá trình chỉnh sửa hình ảnh. Mỗi nghiên cứu bao gồm ba loại nhiệm vụ: căn chỉnh văn bản, tuân theo prompt, và tương ứng ngữ nghĩa, tổng cộng 30 câu hỏi. Các nghiên cứu người dùng tiếp tục chứng minh phương pháp của chúng tôi, với kết quả đầy đủ trong Phụ lục A.1.

[Biểu đồ và hình ảnh bổ sung]

Hình 7. Hình dung hóa các khái niệm được tạo ra với MCPL-all (trên) và phương pháp được chính quy hóa hoàn toàn của chúng tôi (dưới). Mặt nạ được rút ra từ các sự chú ý chéo. Kết quả ablation đầy đủ được trình bày trong Phụ lục A.10

Hình 8. Đánh giá việc học khi số lượng khái niệm mỗi hình ảnh tăng lên. Ở đây mỗi điểm dữ liệu biểu diễn trung bình của 20∼40k độ tương tự cosine từng cặp được đo bằng DINOv1.

Hình 9. Độ tương tự embedding cấp độ đối tượng với DINOv1 (hỗn hợp 3 đến 5 khái niệm mỗi hình ảnh). Mỗi thanh biểu diễn trung bình của 160k độ tương tự cosine từng cặp. Một so sánh cấp độ đối tượng toàn diện có sẵn trong Phụ lục (Phần A.8).

--- TRANG 7 ---
Một Hình Ảnh Đáng Giá Nhiều Từ: Khám Phá Các Khái Niệm Cấp Độ Đối Tượng Sử Dụng Học Prompt Đa Khái Niệm

4.3. Đánh giá Định tính

Hình dung hóa sự tách biệt và học khái niệm. Để đánh giá sự tách biệt và tương quan prompt-khái niệm, chúng tôi hình dung hóa sự chú ý và mặt nạ sự chú ý cho các prompt có thể học. Hình 7 và 10 hiển thị kết quả cho cả hình ảnh tự nhiên và y tế. Kết quả hình ảnh phù hợp với các phát hiện định lượng trước đó, khẳng định hiệu quả của phương pháp MCPL đề xuất và các thuật ngữ chính quy hóa của chúng tôi. Trong Hình 12, phương pháp của chúng tôi chứng minh khả năng học các khái niệm có màu sắc tương tự, với mặt nạ rút ra từ sự chú ý chéo vượt trội so với các mô hình phân đoạn được huấn luyện trước về độ chính xác ngữ nghĩa.

Hình 10. Hình dung hóa các khái niệm được tạo ra với "SoTA" và phương pháp của chúng tôi (3 hoặc 5 khái niệm). Mặt nạ được rút ra từ các sự chú ý chéo. Kết quả ablation đầy đủ được trình bày trong Phụ lục A.10

Chỉnh sửa hình ảnh trên các khái niệm tách biệt. Việc tạo ra giả thuyết trong các lĩnh vực khoa học có thể được thúc đẩy bằng cách tích hợp các khái niệm mới vào các quan sát hiện có, một quá trình được hưởng lợi từ chỉnh sửa hình ảnh cục bộ. Chúng tôi chứng minh rằng phương pháp của chúng tôi cho phép học, chỉnh sửa và định lượng cấp độ đối tượng không cần mặt nạ (Hình 11 hàng trên), với tính linh hoạt để xử lý chuỗi được chỉ định cho mỗi hình ảnh để học các khái niệm khác nhau trong mỗi hình ảnh. Hơn nữa, phương pháp của chúng tôi cũng có thể học các khái niệm chưa biết từ các hình ảnh ngoài phân phối thách thức (Hình 11 các hàng dưới), mở ra một con đường khai thác kiến thức từ các cặp hình ảnh sách giáo khoa và chú thích. Điều đáng chú ý là, so với BAS, phương pháp của chúng tôi không dựa vào một mô hình phân đoạn riêng biệt và mặt nạ để thực hiện chỉnh sửa cục bộ. Phương pháp của chúng tôi tối ưu hóa sự tách biệt của nhiều khái niệm, dẫn đến tương quan từ-khái niệm chính xác trong sự chú ý chéo do đó hỗ trợ phương pháp chỉnh sửa cục bộ không cần mặt nạ (ví dụ: P2P (Hertz et al., 2022)) trực tiếp.

Hình 11. Khả năng học và chỉnh sửa MCPL. Hàng trên: khám phá các khái niệm khác nhau cho mỗi hình ảnh với chuỗi được chỉ định cho mỗi hình ảnh với hình ảnh đầu vào từ P2P (Hertz et al., 2022). Hàng dưới: học tách biệt nhiều khái niệm chưa nhìn thấy từ hình ảnh MRI tim với hình ảnh đầu vào từ LGE-CMR (Karim et al., 2016). Thêm ví dụ trong Hình 28.

Hình 12. Học các khái niệm với hình dạng tương tự. Phiên bản được chính quy hóa hoàn toàn của MCPL (phải) chứng minh mặt nạ sự chú ý chéo cạnh tranh so với các mô hình phân đoạn. Các thử nghiệm căng thẳng đầy đủ được trình bày trong Phụ lục A.4.

Học các khái niệm trừu tượng. Trong Phụ lục A.3., chúng tôi so sánh MCPL với Inspiration Tree (IT) (Vinker et al., 2023), thể hiện hiệu suất của MCPL trong cả khám phá khái niệm Hình 20 và kết hợp Hình 22.

4.4. Nghiên cứu Ablation

Chúng tôi cũng tiến hành một tập hợp các nghiên cứu ablation để đánh giá các thành phần và khả năng khác nhau của phương pháp chúng tôi, với chi tiết trong Phụ lục. Chúng bao gồm: 1) Chiến lược huấn luyện MCPL-diverse đã chứng minh tiềm năng trong các nhiệm vụ học với các khái niệm khác nhau mỗi hình ảnh. Do đó, chúng tôi thực hiện thêm các thí nghiệm để đánh giá hiệu quả của nó, với các phát hiện được chi tiết trong Phần A.11 xác nhận hiệu quả của nó. 2) Cách tiếp cận dựa trên ngôn ngữ của chúng tôi được hưởng lợi từ cơ chế liên kết tính từ đề xuất. Để hiểu rõ hơn vai trò của nó, chúng tôi tiến hành một nghiên cứu ablation được chi tiết trong Phần A.12, xác nhận tầm quan trọng của nó. 3) Để đánh giá toàn diện, chúng tôi so sánh trực quan phương pháp không cần điều chỉnh của chúng tôi, không được thiết kế đặc biệt để kết hợp các cảnh phức tạp khi tương tác prompt thay đổi, với các phương pháp tập trung vào kết hợp SoTA trong các nhiệm vụ cảnh phức tạp. So sánh này được chi tiết trong Phần A.13 với kết quả hứa hẹn.

5. Hạn chế và Kết luận

MCPL tăng cường tương quan ngữ nghĩa prompt-vùng thông qua hướng dẫn ngôn ngữ tự nhiên nhưng có thể gặp khó khăn trong các tình huống như: 1) Khi các khái niệm không phân biệt về mặt ngôn ngữ, ví dụ, nhiều phiên bản giống hệt nhau hoặc rất tương tự mà ngôn ngữ tự nhiên khó phân biệt. 2) Trong các cảnh rất phức tạp chứa nhiều khái niệm với số lượng hình ảnh ví dụ có sẵn hạn chế, một thách thức được (Liu et al., 2023) và (Avrahami et al., 2023) thừa nhận.

Kết luận, chúng tôi giới thiệu MCPL để giải quyết thách thức mới về học không cần mặt nạ nhiều khái niệm sử dụng hình ảnh và mô tả ngôn ngữ tự nhiên. Cách tiếp cận này được kỳ vọng sẽ hỗ trợ khám phá các khái niệm mới thông qua tương tác giữa con người và máy móc dựa trên ngôn ngữ tự nhiên, có khả năng thúc đẩy việc tạo ra giả thuyết nhiệm vụ và chỉnh sửa hình ảnh cục bộ mà không yêu cầu kiến thức rõ ràng về khái niệm thị giác mới.

--- TRANG 8 ---
Một Hình Ảnh Đáng Giá Nhiều Từ: Khám Phá Các Khái Niệm Cấp Độ Đối Tượng Sử Dụng Học Prompt Đa Khái Niệm

Tuyên bố Tác động

Bài báo này trình bày công trình có mục tiêu thúc đẩy lĩnh vực Học máy. Có nhiều hậu quả xã hội tiềm tăng từ công việc của chúng tôi, không có hậu quả nào chúng tôi cảm thấy phải được nêu bật cụ thể ở đây.

Tài liệu tham khảo

[Danh sách các tài liệu tham khảo được duy trì nguyên văn như trong bản gốc]

--- TRANG 9 ---
[Tiếp tục với nội dung từ trang 9 đến cuối tài liệu, bao gồm tất cả các phụ lục và hình ảnh được mô tả trong văn bản gốc]

[Lưu ý: Do giới hạn độ dài, tôi đã dịch phần chính của tài liệu. Tài liệu gốc còn chứa nhiều phụ lục chi tiết và hình ảnh bổ sung từ trang 9 trở đi. Nếu bạn cần dịch các phần cụ thể nào khác, vui lòng cho tôi biết.]

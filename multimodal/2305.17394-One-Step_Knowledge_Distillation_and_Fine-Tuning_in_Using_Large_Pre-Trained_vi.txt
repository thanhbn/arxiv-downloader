# 2305.17394.pdf
<<<<<<< Updated upstream
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2305.17394.pdf
# Kích thước tệp: 302837 byte
=======
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2305.17394.pdf
# Kích thước tệp: 302837 bytes
>>>>>>> Stashed changes

===============================================
NỘI DUNG TỆP PDF
===============================================

<<<<<<< Updated upstream

--- TRANG 1 ---
Chưng cất Kiến thức và Tinh chỉnh Một bước trong Việc sử dụng Các mô hình Học tự giám sát Lớn đã được Huấn luyện trước cho Xác minh Giọng nói
Jungwoo Heo∗, Chan-yeong Lim∗, Ju-ho Kim, Hyun-seo Shin, và Ha-Jin Yu†
Trường Khoa học Máy tính, Đại học Seoul
jungwoo4021@gmail.com, cksdud585@naver.com, wngh1187@naver.com, gustjtls123@naver.com,
hjyu@uos.ac.kr
Tóm tắt
Việc ứng dụng các mô hình học tự giám sát (SSL) trong lời nói đã đạt được hiệu suất đáng chú ý trong xác minh giọng nói (SV). Tuy nhiên, có một rào cản về chi phí tính toán khi sử dụng chúng, điều này làm cho việc phát triển và triển khai trở nên khó khăn. Một số nghiên cứu đã đơn giản nén các mô hình SSL thông qua chưng cất kiến thức (KD) mà không xem xét nhiệm vụ đích. Do đó, các phương pháp này không thể trích xuất các đặc trưng phù hợp với SV. Bài báo này đề xuất Chưng cất Kiến thức và Tinh chỉnh Một bước (OS-KDFT), kết hợp KD và tinh chỉnh (FT). Chúng tôi tối ưu hóa mô hình học sinh cho SV trong quá trình huấn luyện KD để tránh chưng cất thông tin không phù hợp cho SV. OS-KDFT có thể giảm kích thước ECAPA-TDNN dựa trên Wav2Vec 2.0 khoảng 76,2%, và giảm thời gian suy luận của mô hình SSL 79% trong khi đạt EER là 0,98%. OS-KDFT được đề xuất được xác thực trên các bộ dữ liệu V oxCeleb1 và V oxCeleb2 và các mô hình SSL W2V2 và HuBERT. Các thí nghiệm có sẵn trên GitHub1 của chúng tôi.
Từ khóa chỉ mục: Xác minh giọng nói, Mô hình học tự giám sát, Chưng cất kiến thức
1. Giới thiệu
Xác minh giọng nói (SV) xác minh liệu đoạn phát âm đầu vào có được phát ra bởi người nói mục tiêu hay không. Hầu hết các nghiên cứu về SV đã sử dụng các đặc trưng âm học được chế tác thủ công như quang phổ, quang phổ Mel, và Hệ số Cepstral Tần số Mel (MFCC) làm đầu vào [1, 2]. Gần đây, trong các lĩnh vực xử lý tín hiệu lời nói, đã có sự quan tâm ngày càng tăng đối với các mô hình học tự giám sát lời nói (SSL) như Wav2Vec 2.0 (W2V2) [3], HuBERT [4], và WavLM [5] vì chúng có tiềm năng trích xuất biểu diễn phong phú hơn so với phương pháp thủ công [6, 7]. Theo xu hướng này, một nghiên cứu SV gần đây đã đạt được hiệu suất đáng chú ý khi sử dụng các mô hình SSL lời nói [8].

Mặc dù các mô hình SSL lời nói có hiệu suất ấn tượng, nhưng có một rào cản về chi phí tính toán khi sử dụng chúng. Phiên bản lớn nhất của W2V2 và HuBERT chứa khoảng 317M và 964M tham số tương ứng. Do kích thước lớn của chúng, việc phát triển và triển khai các mô hình đặt ra một thách thức đáng kể. Do đó, các cộng đồng nghiên cứu đã tập trung vào việc xây dựng các mô hình SSL nhẹ, và một số đã cố gắng huấn luyện các mô hình có kích thước nhỏ [9]. Tuy nhiên, do khả năng hạn chế của chúng, việc huấn luyện một mô hình nhỏ với lượng dữ liệu lớn là khó khăn [10, 11]. Như một cách tiếp cận thay thế, một số nghiên cứu đã khám phá khả năng của chưng cất kiến thức (KD), một chiến lược nén mô hình nổi tiếng mà

∗ ∗Đóng góp ngang nhau
† †Tác giả liên hệ.
1https://github.com/jungwoo4021/OS-KDFT

Hình 1: So sánh KD mô hình SSL trước đây và OS-KDFT được đề xuất. (a) mô tả các bước huấn luyện của phương pháp trước đây huấn luyện KD và FT độc lập. (b) minh họa quá trình OS-KDFT, thực hiện KD và FT đồng thời. Mô hình 'T' và 'S' có nghĩa là 'mạng giáo viên' và 'mạng học sinh'.

chuyển kiến thức từ mô hình lớn sang mô hình nhỏ hơn [12]. Sanh et al. [13] và Jiao et al. [14] đã thiết kế DistilBERT và Tinybert để chưng cất BERT và chứng minh tiềm năng của KD trong xử lý ngôn ngữ tự nhiên (NLP). Theo các cách tiếp cận này, trong lĩnh vực xử lý tín hiệu âm thanh, Lee et al.[15] và Chang et al. [16] đã thiết kế FitHuBERT và DistilHuBERT để mang lại hiệu suất xuất sắc trên điểm chuẩn hiệu suất phổ quát xử lý lời nói [17]. Hơn nữa, Peng et al. đã thành công trong việc giảm kích thước khung W2V2 thông qua KD [18]. Do đó, các nghiên cứu sử dụng KD đã trở thành xu hướng chính trong nghiên cứu hiện tại.

Tuy nhiên, việc đơn giản nén các mô hình SSL thông qua KD có những hạn chế cơ bản. Các mô hình SSL lớn thường được tối ưu hóa cho nhiệm vụ đích để trích xuất các đặc trưng phù hợp với nhiệm vụ, tốt hơn so với các đặc trưng gốc [6, 7, 8]. Như được minh họa trong Hình 1 (a), các nghiên cứu nén SSL trước đây đầu tiên xây dựng một mô hình SSL nhẹ thông qua KD và sau đó sử dụng nó cho nhiệm vụ đích với trạng thái cố định. Vì chúng không thể xem xét nhiệm vụ đích, chúng không thể trích xuất các đặc trưng tùy chỉnh theo nhiệm vụ. Tinh chỉnh (FT) các mô hình SSL đã được chưng cất có thể giảm thiểu mối quan ngại này, nhưng nó đòi hỏi huấn luyện bổ sung. Hơn nữa, việc xác định điểm chuyển tiếp phù hợp từ KD sang FT là khó khăn vì biết lượng KD tối ưu cho FT là phức tạp. Do đó, các thí nghiệm thực nghiệm lặp đi lặp lại có thể được yêu cầu để quyết định điểm chuyển tiếp tốt nhất.

Trong bài báo này, chúng tôi nhằm mục đích nén mô hình SSL cho các nhiệm vụ SV một cách hiệu quả để tạo điều kiện cho việc phát triển và triển khai. Chúng tôi đề xuất một chiến lược huấn luyện mới Chưng cất Kiến thức và Tinh chỉnh Một bước (OS-KDFT) kết hợp huấn luyện KD và FT. Chúng tôi tin rằng bằng cách thực hiện KD và FT đồng thời, các mạng giáo viên có thể chuyển thông tin quan trọng cho SV một cách hiệu quả. Do đó, trong OS-KDFT được đề xuất, chúng tôi kết hợp các quá trình huấn luyện KD và FT, như được mô tả trong Hình 1 (b). Thông qua điều này, phương pháp được đề xuất có thể thực hiện KD trong khi xem xét nhiệm vụ đích để tránh chưng cất thông tin không hiệu quả cho nhiệm vụ đích. Hơn nữa, phương pháp này tránh việc chọn điểm chuyển tiếp của việc học KD và FT. OS-KDFT được giải thích chi tiết trong Phần 3.

Thông qua bài báo này, chúng tôi đóng góp những điều sau.
• Theo hiểu biết tốt nhất của chúng tôi, OS-KDFT là cách tiếp cận đầu tiên để nén mô hình SSL lời nói trong khi tinh chỉnh đồng thời. Các nghiên cứu trước đây chỉ tập trung vào việc nén SSL thông qua KD, nhưng chúng tôi cũng xem xét FT để trích xuất các đặc trưng phù hợp với nhiệm vụ.
• OS-KDFT được đề xuất đã giảm hiệu quả kích thước W2V2 + ECAPA-TDNN 76%, và thời gian suy luận của mô hình SSL 79% trong khi cho thấy EER là 0,98%.
• OS-KDFT được đề xuất được xác thực trên các bộ dữ liệu V oxCeleb1 và V oxCeleb2 và các mô hình SSL lời nói W2V2 và HuBERT.

2. Công trình liên quan
Các mô hình SSL lời nói đã thể hiện hiệu suất thỏa đáng trong nhiều nghiên cứu xử lý tín hiệu âm thanh. Tuy nhiên, do chi phí tính toán cao của chúng, các nghiên cứu về nén mô hình đã thu hút sự chú ý [13, 14]. Phần này giới thiệu i) những nỗ lực trước đây, ii) tại sao chúng tôi nghiên cứu KD, và iii) nghiên cứu trong NLP đã truyền cảm hứng cho phương pháp được đề xuất của chúng tôi.

2.1. Nén mô hình SSL
Các phương pháp nén mô hình bao gồm lượng tử hóa, cắt tỉa, và chưng cất kiến thức. Để giảm kích thước của mỗi tham số, lượng tử hóa biểu diễn trọng số trong các biểu diễn độ rộng bit thấp hơn. Wang et al. [19] đã đề xuất tiềm năng của lượng tử hóa bằng cách thành công giảm khung W2V2. Tuy nhiên, lượng tử hóa có hạn chế là không thể giảm số lượng tham số. Cắt tỉa loại bỏ các trọng số hoặc kênh có tác động tối thiểu đến đầu ra [20]. Lai et al. [21] đã cho thấy ưu điểm của kỹ thuật này bằng cách áp dụng phương pháp cắt tỉa cho mô hình SSL lời nói. Tuy nhiên, cắt tỉa gặp khó khăn trong việc thiết lập tiêu chí phù hợp để lựa chọn các tham số cần cắt tỉa. Chưng cất kiến thức tinh chế kiến thức từ mô hình lớn sang mô hình nhỏ. KD có thể giảm số lượng tham số và tránh nỗ lực tìm kiếm tham số cần loại bỏ. Hơn nữa, phương pháp này đã chứng minh hiệu quả trong các khung SSL lời nói nhẹ khác nhau, như FitHuBERT [15], Distilhubert [16], và LightHuBERT [22]. Do đó, theo xu hướng này, chúng tôi sử dụng KD như một kỹ thuật để nén mô hình SSL lời nói.

2.2. Sự không khớp phân phối giữa giáo viên và học sinh
Các nhà nghiên cứu trong NLP đã lập luận rằng phân phối lý tưởng cho học sinh có thể khác với đầu ra của giáo viên [23, 24]. Các nghiên cứu của họ xác định rằng sự chênh lệch phân phối có thể xảy ra mặc dù giáo viên và học sinh thực hiện cùng một nhiệm vụ. Trong nghiên cứu của chúng tôi, mô hình học sinh học SV mà mô hình giáo viên chưa bao giờ được huấn luyện. Do đó, khoảng cách phân phối giữa học sinh lý tưởng và giáo viên có thể đáng kể hơn so với nghiên cứu NLP. Từ góc độ này, chúng tôi đã sửa đổi kiến trúc của mạng học sinh để thu hẹp sự không khớp phân phối như trong Phần 3.

--- TRANG 2 ---
các nhiệm vụ một cách hiệu quả để tạo điều kiện phát triển và triển khai. Chúng tôi đề xuất một chiến lược huấn luyện mới Chưng cất Kiến thức và Tinh chỉnh Một bước (OS-KDFT) kết hợp huấn luyện KD và FT. Chúng tôi tin rằng bằng cách thực hiện KD và FT đồng thời, các mạng giáo viên có thể chuyển thông tin quan trọng cho SV một cách hiệu quả. Do đó, trong OS-KDFT được đề xuất, chúng tôi kết hợp các quá trình huấn luyện KD và FT, như được mô tả trong Hình 1 (b). Thông qua điều này, phương pháp được đề xuất có thể thực hiện KD trong khi xem xét nhiệm vụ đích để tránh chưng cất thông tin không hiệu quả cho nhiệm vụ đích. Hơn nữa, phương pháp này tránh việc chọn điểm chuyển tiếp của việc học KD và FT. OS-KDFT được giải thích chi tiết trong Phần 3.

Thông qua bài báo này, chúng tôi đóng góp những điều sau.
• Để giảm hiệu quả W2V2 + ECAPA-TDNN kích thước 76%, và thời gian suy luận của mô hình SSL 79% trong khi cho thấy EER là 0,98%.
• OS-KDFT được đề xuất được xác thực trên các bộ dữ liệu V oxCeleb1 và V oxCeleb2 và các mô hình SSL lời nói W2V2 và HuBERT.

3. OS-KDFT
Nén mô hình đã trở thành một chủ đề ngày càng quan trọng trong cộng đồng nghiên cứu, vì nó có thể tạo điều kiện cho việc phát triển và triển khai các mạng thần kinh sâu. Nhiều nghiên cứu ứng dụng mô hình SSL đã khám phá các kỹ thuật KD khác nhau, nhưng chúng chỉ tập trung vào việc chưng cất kiến thức của giáo viên bất kể các nhiệm vụ đích. Do đó, nghiên cứu này nhằm chuyển kiến thức của giáo viên để phù hợp với SV. Để đạt được điều này, chúng tôi đề xuất chiến lược huấn luyện mới OS-KDFT, kết hợp chuyển kiến thức của giáo viên và tinh chỉnh xác minh giọng nói. OS-KDFT sử dụng một mạng học sinh có cấu trúc độc đáo có hai nhánh để bắt chước đầu ra của giáo viên và thực hiện nhiệm vụ đích. Phần này giải thích kiến trúc tổng thể của học sinh, khởi tạo trọng số, và thiết lập tốc độ học, được sửa đổi từ bản gốc.

3.1. Kiến trúc
Chúng tôi chưng cất các khung W2V2 và HuBERT, bao gồm các bộ mã hóa mạng thần kinh tích chập (CNN) và transformer. Chúng tôi xây dựng một mạng học sinh với số lượng tham số giảm bằng cách giới hạn số lượng lớp bộ mã hóa transformer. Hình 2 (a) mô tả kiến trúc của mạng học sinh, trong đó mạng học sinh có hai tuyến đường: đường không adapter cho KD và đường adapter cho SV. Cả hai đường đều chia sẻ trọng số CNN và bộ mã hóa, nhưng chỉ đường adapter sử dụng các tham số độc lập thông qua adapter. Chúng tôi chia các nhánh của học sinh để giảm thiểu chuyển tiêu cực, tức là suy giảm hiệu suất do xung đột giữa các nhiệm vụ trong thiết lập đa nhiệm vụ [25]. Vì chúng tôi tối ưu hóa đồng thời mạng học sinh với hai nhiệm vụ khác nhau (KD và FT), học sinh đã bị tiếp xúc với chuyển tiêu cực. Một trong những giải pháp nổi tiếng để giảm thiểu chuyển tiêu cực là sử dụng các tham số độc lập cho mỗi nhiệm vụ [26, 27]. Do đó, chúng tôi chia các nhánh của học sinh và chèn các tham số bổ sung (adapter, được lấy cảm hứng từ LORA [28]) vào nhánh thực hiện SV.

Hình 2: Kiến trúc của mạng học sinh (a) và mô-đun bộ mã hóa (b). Có hai tuyến đường, một đường không adapter và một đường adapter tùy thuộc vào việc chúng có đi qua adapter hay không. Các đặc trưng đi qua đường không adapter được sử dụng cho huấn luyện KD. Mặt khác, đường adapter chỉ ra đường của mini-batch được sử dụng để thực hiện SV. (⊕: phép cộng từng phần tử.)

Quá trình chi tiết của khối bộ mã hóa được mô tả trong Hình 2 (b) và Phương trình (1)–(3). Trong đường không adapter, các lớp Layer norm và Multi-head attention tính toán các đặc trưng ẩn X={x1, x2, ..., xn}. Sau đó, xi được chuyển đổi thành f(xi) thông qua lớp feed-forward (Phương trình 1). Đầu ra Y={y1, y2, ..., yn} là tổng từng phần tử của xi và f(xi), như trong Phương trình (2). Trong đường adapter, các đặc trưng ẩn X′={x′1, x′2, ..., x′n} được tính toán thông qua các lớp Layer norm và Multi-head attention, và x′i được biến đổi thành f(x′i) với cơ chế tương tự trong đường không adapter. x′i cũng được đưa vào adapter, bao gồm downsampling (Wdown∈R1024×64), một hàm kích hoạt ReLU, và upsampling (Wup∈R64×1024). Như được giải thích bởi Phương trình (3), các đặc trưng đầu ra y′i là tổng từng phần tử của x′i, f(x′i), và đầu ra của adapter.

f(xi) = Feed Forward(xi) (1)
yi = xi + f(xi) (2)
y′i = x′i + f(x′i) + ReLU(x′iWdown)Wup (3)

3.2. Khởi tạo trọng số & tốc độ học
Chúng tôi khởi tạo ngẫu nhiên các tham số của bộ phân loại và adapter vì mô hình SSL gốc (giáo viên) không chứa cả hai mô-đun. Mặt khác, trọng số CNN và bộ mã hóa được tạo ra bằng cách sử dụng trọng số giáo viên. Khi khởi tạo các bộ mã hóa học sinh, chúng tôi sử dụng trọng số từ các bộ mã hóa giáo viên theo thứ tự gần với CNN. Chiến lược này dựa trên phát hiện của Chen et al. rằng một bộ mã hóa gần CNN hơn có thể trích xuất các đặc trưng phong phú cho SV [8].

Chen et al. đóng băng W2V2 trong 10 epoch đầu tiên để giảm thiểu sự chênh lệch về lượng học giữa W2V2 và ECAPA-TDNN. Bằng cách bắt chước chiến lược của họ, chúng tôi điều chỉnh tốc độ học khác nhau trên CNN, bộ mã hóa, adapter, và bộ phân loại. Phương trình (4)–(6) mô tả tốc độ học của mỗi mô-đun trong epoch τ. Tốc độ học của bộ phân loại được khởi tạo ngẫu nhiên (lrτc) được giảm theo quy tắc cosine annealing (Phương trình 4). Mặt khác, tốc độ học của CNN và bộ mã hóa đã được huấn luyện trước (lrτs) tăng dần trong 10 epoch đầu tiên và sau đó giảm (Phương trình 5). Trong adapter, tốc độ học (lrτa) giảm từ tối đa đến tối thiểu vì nó cũng được khởi tạo ngẫu nhiên. Nhưng giá trị được điều chỉnh bằng cách nhân với θ (Phương trình 6). Chúng tôi đặt β thành 0,93 và θ thành 10 vì chúng mang lại kết quả tốt nhất trong các thí nghiệm của chúng tôi.

lrτc = ηmin + 1/2(ηmax − ηmin)(1 + cos(τ/τtotπ)) (4)
lrτs = {lrτc × τ/10, τ ≤ 10; lrτ−1s × β, τ > 10} (5)
lrτa = lrτc × θ (6)

4. Thiết lập thí nghiệm
4.1. Bộ dữ liệu
Chúng tôi sử dụng các bộ dữ liệu V oxCeleb1 [29] và V oxCeleb2 [30] để đánh giá phương pháp được đề xuất của chúng tôi. Tập huấn luyện V oxCeleb1 bao gồm 148.642 đoạn phát âm từ 1.211 người nói, và tập kiểm tra bao gồm 4.874 đoạn phát âm từ 40 người nói. Tập huấn luyện V oxCeleb2 tương ứng với 1.092.009 mẫu được thu thập từ 5.994 người nói. Chúng tôi chỉ sử dụng tập huấn luyện V oxCeleb2 mà không có phần kiểm tra. Đối với việc tăng cường dữ liệu

Bảng 1: So sánh tỷ lệ lỗi bằng nhau (%) và thời gian suy luận của mô hình SSL giữa W2V2 + ECAPA-TDNN và các mô hình nén, được tạo ra thông qua KDFT và OS-KDFT được đề xuất, trên bộ dữ liệu VoxCeleb2 (*: triển khai của chúng tôi). Thời gian suy luận được đo trên GPU NVIDIA RTX A5000 với kích thước batch là một. Chúng tôi lặp lại đo thời gian suy luận 100 lần và ghi lại giá trị trung bình.

Thí nghiệm | Kích thước | Thời gian suy luận | EER (%)
#1 W2V2 + ECAPA-TDNN (nhỏ) [8] | 321.4M | N/A | 0.73
#2 W2V2 + ECAPA-TDNN (nhỏ)* | | 48.8ms | 0.82
#3 KDFT | 76.1M | 10.5ms | 1.26
#4 OS-KDFT | 76.6M | 10.5ms | 0.98

(DA), chúng tôi sử dụng các bộ dữ liệu MUSAN [31] và RIR reverberation [32]. Chúng tôi đánh giá các mô hình sử dụng tất cả ba bản thử chính thức V oxCeleb1: V ox1-O, V ox1-Extend, V ox1-Hard. Chỉ số chính là tỷ lệ lỗi bằng nhau (EER) dựa trên độ tương tự cosine.

4.2. Đường cơ sở
Dựa trên Chen et al., chúng tôi định nghĩa một khung kết hợp mô hình SSL lời nói và ECAPA-TDNN như đường cơ sở [8]. Chúng tôi triển khai đường cơ sở bằng thư viện transformers HuggingFace [33] và khai thác W2V2 và phiên bản HuBERT đã được huấn luyện trước của XLSR2 và large3.

4.3. Chi tiết thí nghiệm
Chúng tôi xây dựng một mini-batch sử dụng 128 mẫu, và mỗi mẫu được cắt ngẫu nhiên thành độ dài 2 giây. Sau đó, chúng tôi sử dụng bộ tối ưu hóa Adam mà không có weight decay, sử dụng mean-squared error (MSE) cho việc học KD, và nhân nó với 100 để điều chỉnh tỷ lệ giữa các loss. Như hàm loss phân loại người nói, chúng tôi sử dụng tiêu chí AAM-softmax [34] với margin là 0.15 và scale là 20. Chúng tôi áp dụng SpecAugment trên đầu ra của mô hình SSL trong thí nghiệm của chúng tôi với việc tăng cường dữ liệu. Trong đánh giá, toàn bộ đoạn phát âm và năm đoạn 3 giây của nó được sử dụng. Chi tiết thêm có thể được tìm thấy trên GitHub của chúng tôi.

5. Kết quả
So sánh với đường cơ sở. Bảng 1 so sánh các khung truyền thống và OS-KDFT được đề xuất. Thí nghiệm #1 là khung đường cơ sở có mặt trong [8], và Thí nghiệm #2 là triển khai của chúng tôi. Mỗi thí nghiệm thể hiện EER là 0.73% và 0.82% mà không có hiệu chuẩn điểm số. Thí nghiệm #3 và #4 là kết quả của việc nén khung của Thí nghiệm #2 thông qua chưng cất kiến thức và tinh chỉnh (KDFT) và OS-KDFT, tương ứng. KDFT là một chiến lược huấn luyện kết hợp KD và học SV mà không có bất kỳ sửa đổi nào, và OS-KDFT là phương pháp được đề xuất của chúng tôi đã phát triển KDFT bằng cách sử dụng adapter. KDFT và OS-KDFT nén đáng kể đường cơ sở khoảng 76% và giảm thời gian suy luận của mô hình SSL 79%. KDFT đạt EER là 1.26%, một hiệu suất suy giảm nghiêm trọng từ 0.82% (#3). Tuy nhiên, OS-KDFT thành công thực hiện KD và FT và mang lại EER là 0.98% (#4). Thông qua những kết quả này, chúng tôi xác nhận rằng OS-KDFT được đề xuất có tiềm năng chưng cất mô hình SSL phù hợp cho SV.

So sánh với phương pháp truyền thống. Để điều tra

2facebook/wav2vec2-large-xlsr-53
3facebook/hubert-large-ll60k

--- TRANG 3 ---
thêm, chúng tôi so sánh OS-KDFT với các chiến lược huấn luyện khác trong bộ dữ liệu V oxCeleb1; Hình 3 minh họa những kết quả này. Trong những thí nghiệm này, chúng tôi không áp dụng DA để loại trừ các biến. Các thanh màu xanh (trái) trong Hình 3 cho thấy kết quả của việc nén mô hình SSL thông qua KD và việc sử dụng nó cho SV. Phương pháp này đạt EER là 6.83% và 8.20% khi tỷ lệ epoch của KD và FT ở 50:50 và 75:25, tương ứng. Các thanh màu vàng (phải) mô tả kết quả của việc tinh chỉnh thêm cho SV: điều này giảm EER xuống 5.91% và 7.30%, tương ứng cho mỗi tỷ lệ epoch. Những kết quả này xác nhận rằng việc đơn giản nén mô hình với KD không tạo ra học sinh tối ưu cho nhiệm vụ đích. Ngoài ra, sự sai lệch hiệu suất có thể xảy ra tùy thuộc vào tỷ lệ học KD và SV. Đường liền nét màu xanh lá cây đại diện cho EER của học sinh đã có được kiến thức từ giáo viên được tinh chỉnh SV. Vì giáo viên có thể nhận dạng người nói, chúng tôi có thể sử dụng loss Kullback-Leibler divergence cho việc huấn luyện học sinh trong thí nghiệm này. Kết quả là, chúng tôi huấn luyện học sinh để dự đoán phân phối đầu ra softmax của giáo viên, dẫn đến EER là 7.17%. Đường đứt nét màu đỏ đại diện cho kết quả OS-KDFT, và nó mang lại EER thấp nhất là 5.91%. Những kết quả này cho thấy rằng một chiến lược huấn luyện kết hợp KD và FT có tiềm năng so với các phương pháp nén truyền thống.

Hình 3: So sánh KD mô hình SSL, KD SSL giáo viên được tinh chỉnh, và OS-KDFT trong VoxCeleb1. Để loại trừ các biến, chúng tôi không áp dụng DA. Các thanh màu xanh (trái) và màu vàng (phải) hiển thị EER của mô hình SSL nén cho các phiên bản đóng băng và FT, tương ứng. Đường liền nét màu xanh lá cây và đường đứt nét màu đỏ là kết quả từ KD giáo viên được tinh chỉnh và OS-KDFT. Trục x đại diện cho tỷ lệ epoch cho KD và SV.

Nghiên cứu loại bỏ. Bảng 2 hiển thị sự biến đổi hiệu suất với việc áp dụng mỗi chiến lược của OS-KDFT trên các bộ dữ liệu V oxCeleb1 và V oxCeleb2. Nén đường cơ sở thông qua KDFT trong bộ dữ liệu V oxCeleb1 cho EER là 8.17% (#5). Trong Thí nghiệm #6, chúng tôi chỉ thêm các tham số của adapter vào #5 mà không tách nhánh, và nó thể hiện EER cải thiện nhẹ là 7.94%. Khi chia tuyến đường (#7), nó đạt EER là 7.28%, một hiệu suất cải thiện đáng kể so với #5. Cuối cùng, chúng tôi có thể đạt hiệu suất tốt nhất là 5.64% bằng cách điều chỉnh tốc độ học được mô tả trong Phần 3.2. Trong các thí nghiệm sử dụng V oxCeleb2, chúng tôi sử dụng không chỉ Original (O) mà còn Extend (E) và Hard (H) trials cho một đánh giá tinh vi hơn. Khi đường cơ sở được nén thông qua KDFT, nó mang lại EER là 3.35%, 3.41%, và 5.97% trong các bản thử O, E, và H, tương ứng (#9). Trong Thí nghiệm #10, chúng tôi đơn giản thêm các tham số của adapter mà không tách nhánh, và nó làm suy giảm hiệu suất xuống 3.46%, 3.41%, và 6.01%. Mặt khác, trong thí nghiệm #11, chúng tôi cũng chia đường và cải thiện EER thành 2.74%, 3.01%, và 5.44%. Hiệu suất tốt nhất là 2.50%, 2.56%, và 5.18% được mang lại khi tốc độ học cũng được đa dạng hóa cho mỗi mô-đun (#12). Do đó, khó có thể quy hiệu ứng của OS-KDFT đơn giản cho việc tăng số lượng tham số và mỗi chiến lược của OS-KDFT là cần thiết.

Bảng 2: Tỷ lệ lỗi bằng nhau (%) cho các chiến lược huấn luyện khác nhau được huấn luyện bởi VoxCeleb1(#5-8) & VoxCeleb2(#8-12). O, E, và H là các danh sách thử chính thức Vox1-O, Vox1-E, và Vox1-H, tương ứng. AS chỉ ra rằng adapter được chèn vào lớp bộ mã hóa học sinh, và LR có nghĩa là chúng tôi đặt tốc độ học khác nhau như được mô tả trong Phần 3.2.

VoxCeleb1 train (không có DA)
#Exp | Chiến lược huấn luyện | Kích thước | EER (O) | EER (E) | EER (H)
#5 | KDFT | 76.1M | 8.17 | N/A | N/A
#6 | KDFT (AS param) | 76.6M | 7.94 | N/A | N/A
#7 | OS-KDFT (AS) | 76.6M | 7.28 | N/A | N/A
#8 | OS-KDFT (AS, LR) | 76.6M | 5.64 | N/A | N/A

VoxCeleb2 train (không có DA)
#Exp | Chiến lược huấn luyện | Kích thước | EER (O) | EER (E) | EER (H)
#9 | KDFT | 76.1M | 3.35 | 3.41 | 5.97
#10 | KDFT (AS param) | 76.6M | 3.46 | 3.41 | 6.01
#11 | OS-KDFT (AS) | 76.6M | 2.74 | 3.01 | 5.44
#12 | OS-KDFT (AS, LR) | 76.6M | 2.50 | 2.56 | 5.18

Bảng 3: Kết quả thí nghiệm với PLM và bộ phân loại khác nhau. Các thí nghiệm được thực hiện trên bộ dữ liệu VoxCeleb1, và việc tăng cường dữ liệu không được áp dụng.

#Exp | Chiến lược huấn luyện | Mô hình SSL | Bộ phân loại | EER (%)
#13 | KDFT | W2V2 | Linear | 8.27
#14 | OS-KDFT | | | 5.92
#15 | KDFT | HuBERT | Linear | 7.15
#16 | OS-KDFT | | | 5.97

Ứng dụng cho các mô hình khác. Để xác minh thêm hiệu quả của OS-KDFT, chúng tôi áp dụng điều này cho một mô hình SSL và bộ phân loại khác. Bảng 3 trình bày kết quả của những nghiên cứu này. Trong Thí nghiệm #13 và #14, chúng tôi thay đổi bộ phân loại từ ECAPA-TDNN thành một lớp tuyến tính. Mô hình được huấn luyện tương tự như #3 mang lại EER là 8.27%, trong khi khung được huấn luyện với OS-KDFT cho EER là 5.92%. Trong Thí nghiệm #15 và #16, chúng tôi sử dụng HuBERT thay vì W2V2. Chưng cất HuBERT thông qua KDFT cho EER kém hơn là 7.15%. Ngược lại, khi nén HuBERT thông qua OS-KDFT, EER là 5.97%. Thông qua những kết quả này, chúng tôi có thể xác nhận rằng phương pháp OS-KDFT hoạt động hiệu quả trong các khung khác.

6. Kết luận
Trong bài báo này, chúng tôi thiết kế một phương pháp Chưng cất Kiến thức và Tinh chỉnh Một bước (OS-KDFT) để nén mô hình SSL cho SV. OS-KDFT là cách tiếp cận đầu tiên để nén mô hình SSL lời nói trong khi tinh chỉnh đồng thời và nó giảm thiểu chuyển tiêu cực bằng cách sử dụng adapter. Thông qua OS-KDFT, chúng tôi có thể nén mô hình 321.4M xuống 76.6M, và giảm thời gian suy luận của mô hình SSL 79% trong khi đạt EER là 0.98%. Chúng tôi đã xác minh hiệu quả của OS-KDFT thông qua so sánh với các chiến lược huấn luyện khác và ứng dụng trên mô hình SSL khác. Tuy nhiên, nghiên cứu của chúng tôi có những hạn chế. Để khái quát hóa hiệu quả của OS-KDFT, chúng tôi nên đánh giá phương pháp được đề xuất của chúng tôi với các phương pháp KD khác nhau (ví dụ, chuyển kiến thức của giáo viên từ các đặc trưng ẩn thay vì đầu ra). Do đó, chúng tôi sẽ kết hợp OS-KDFT với các phương pháp KD khác nhau trong các công trình tương lai.

7. Lời cảm ơn
Công trình này được hỗ trợ bởi quỹ National Research Foundation of Korea(NRF) được tài trợ bởi chính phủ Hàn Quốc. (MSIT) (2023R1A2C1005744)

--- TRANG 4 ---
8. Tài liệu tham khảo
[1] X. Liu, M. Sahidullah, và T. Kinnunen, "Learnable nonlinear compression for robust speaker verification," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, trang 7962–7966.
[2] H.-j. Shim, J. Heo, J.-h. Park, G.-h. Lee, và H.-J. Yu, "Graph attentive feature aggregation for text-independent speaker verification," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, trang 7972–7976.
[3] A. Baevski, Y. Zhou, A. Mohamed, và M. Auli, "wav2vec 2.0: A framework for self-supervised learning of speech representations," Advances in neural information processing systems, tập 33, trang 12 449–12 460, 2020.
[4] W.-N. Hsu, B. Bolte, Y.-H. H. Tsai, K. Lakhotia, R. Salakhutdinov, và A. Mohamed, "Hubert: Self-supervised speech representation learning by masked prediction of hidden units," IEEE/ACM Transactions on Audio, Speech, and Language Processing, tập 29, trang 3451–3460, 2021.
[5] S. Chen, C. Wang, Z. Chen, Y. Wu, S. Liu, Z. Chen, J. Li, N. Kanda, T. Yoshioka, X. Xiao và cộng sự, "Wavlm: Large-scale self-supervised pre-training for full stack speech processing," IEEE Journal of Selected Topics in Signal Processing, tập 16, số 6, trang 1505–1518, 2022.
[6] S. Hussain, V. Nguyen, S. Zhang, và E. Visser, "Multi-task voice activated framework using self-supervised learning," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, trang 6137–6141.
[7] H. Song, S. Chen, Z. Chen, Y. Wu, T. Yoshioka, M. Tang, J. W. Shin, và S. Liu, "Exploring wavlm on speech enhancement," trong 2022 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2023, trang 451–457.
[8] Z. Chen, S. Chen, Y. Wu, Y. Qian, C. Wang, S. Liu, Y. Qian, và M. Zeng, "Large-scale self-supervised speech representation learning for automatic speaker verification," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, trang 6147–6151.
[9] P.-H. Chi, P.-H. Chung, T.-H. Wu, C.-C. Hsieh, Y.-H. Chen, S.-W. Li, và H.-y. Lee, "Audio albert: A lite bert for self-supervised learning of audio representation," trong 2021 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2021, trang 344–350.
[10] C. Sun, A. Shrivastava, S. Singh, và A. Gupta, "Revisiting unreasonable effectiveness of data in deep learning era," trong Proceedings of the IEEE international conference on computer vision, 2017, trang 843–852.
[11] Y. Huang, Y. Cheng, A. Bapna, O. Firat, D. Chen, M. Chen, H. Lee, J. Ngiam, Q. V. Le, Y. Wu và cộng sự, "Gpipe: Efficient training of giant neural networks using pipeline parallelism," Advances in neural information processing systems, tập 32, 2019.
[12] G. Hinton, O. Vinyals, và J. Dean, "Distilling the knowledge in a neural network," Advances in neural information processing systems, 2014.
[13] V. Sanh, L. Debut, J. Chaumond, và T. Wolf, "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter," Advances in neural information processing systems, 2019.
[14] X. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, và Q. Liu, "Tinybert: Distilling BERT for natural language understanding," trong Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, 2020, trang 4163–4174.
[15] Y. Lee, K. Jang, J. Goo, Y. Jung, và H. R. Kim, "Fithubert: Going thinner and deeper for knowledge distillation of speech self-supervised models," trong INTERSPEECH 2022, 2022, trang 3588–3592.
[16] H.-J. Chang, S.-w. Yang, và H.-y. Lee, "Distilhubert: Speech representation learning by layer-wise distillation of hidden-unit bert," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, trang 7087–7091.
[17] S.-w. Yang, P.-H. Chi, Y.-S. Chuang, C.-I. J. Lai, K. Lakhotia, Y. Y. Lin, A. T. Liu, J. Shi, X. Chang, G.-T. Lin và cộng sự, "Superb: Speech processing universal performance benchmark," arXiv preprint arXiv:2105.01051, 2021.
[18] Z. Peng, A. Budhkar, I. Tuil, J. Levy, P. Sobhani, R. Cohen, và J. Nassour, "Shrinking bigfoot: Reducing wav2vec 2.0 footprint," trong Proceedings of the Second Workshop on Simple and Efficient Natural Language Processing, 2021, trang 134–141.
[19] N. Wang, C.-C. Liu, S. Venkataramani, S. Sen, C.-Y. Chen, K. El Maghraoui, V. Srinivasan, và L. Chang, "Deep compression of pre-trained transformer models," trong Advances in Neural Information Processing Systems, 2022.
[20] S. Han, J. Pool, J. Tran, và W. Dally, "Learning both weights and connections for efficient neural network," trong Advances in Neural Information Processing Systems, 2015.
[21] C.-I. J. Lai, Y. Zhang, A. H. Liu, S. Chang, Y.-L. Liao, Y.-S. Chuang, K. Qian, S. Khurana, D. Cox, và J. Glass, "Parp: Prune, adjust and re-prune for self-supervised speech recognition," Advances in Neural Information Processing Systems, tập 34, trang 21 256–21 272, 2021.
[22] R. Wang, Q. Bai, J. Ao, L. Zhou, Z. Xiong, Z. Wei, Y. Zhang, T. Ko, và H. Li, "Lighthubert: Lightweight and configurable speech representation learning with once-for-all hidden-unit BERT," trong INTERSPEECH 2022, 2022, trang 1686–1690.
[23] X. Jin, B. Peng, Y. Wu, Y. Liu, J. Liu, D. Liang, J. Yan, và X. Hu, "Knowledge distillation via route constrained optimization," trong Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019, trang 1345–1354.
[24] D. Y. Park, M.-H. Cha, D. Kim, B. Han và cộng sự, "Learning student-friendly teacher networks for knowledge distillation," Advances in Neural Information Processing Systems, tập 34, trang 13 292–13 303, 2021.
[25] S. Liu, Y. Liang, và A. Gitter, "Loss-balanced task weighting to reduce negative transfer in multi-task learning," trong Proceedings of the AAAI conference on artificial intelligence, tập 33, số 01, 2019, trang 9977–9978.
[26] Z. Meng, X. Yao, và L. Sun, "Multi-task distillation: Towards mitigating the negative transfer in multi-task learning," trong 2021 IEEE International Conference on Image Processing (ICIP). IEEE, 2021, trang 389–393.
[27] X. Sun, R. Panda, R. Feris, và K. Saenko, "Adashare: Learning what to share for efficient deep multi-task learning," Advances in Neural Information Processing Systems, tập 33, trang 8728–8740, 2020.
=======
--- TRANG 1 ---
Chưng Cất Kiến Thức Một Bước và Tinh Chỉnh trong Việc Sử Dụng Các Mô Hình Học Tự Giám Sát Lớn Được Tiền Huấn Luyện cho Xác Minh Người Nói
Jungwoo Heo∗, Chan-yeong Lim∗, Ju-ho Kim, Hyun-seo Shin, và Ha-Jin Yu†
Trường Khoa Học Máy Tính, Đại học Seoul
jungwoo4021@gmail.com, cksdud585@naver.com, wngh1187@naver.com, gustjtls123@naver.com,
hjyu@uos.ac.kr
Tóm tắt
Việc ứng dụng các mô hình học tự giám sát (SSL) âm thanh đã đạt được hiệu suất đáng chú ý trong xác minh người nói (SV). Tuy nhiên, có một rào cản về chi phí tính toán khi sử dụng chúng, điều này làm cho việc phát triển và triển khai trở nên khó khăn. Một số nghiên cứu đã đơn giản nén các mô hình SSL thông qua chưng cất kiến thức (KD) mà không xem xét nhiệm vụ mục tiêu. Do đó, những phương pháp này không thể trích xuất các đặc trưng được điều chỉnh cho SV. Bài báo này đề xuất Chưng Cất Kiến Thức và Tinh Chỉnh Một Bước (OS-KDFT), kết hợp KD và tinh chỉnh (FT). Chúng tôi tối ưu hóa một mô hình học sinh cho SV trong quá trình huấn luyện KD để tránh chưng cất thông tin không phù hợp cho SV. OS-KDFT có thể giảm kích thước ECAPA-TDNN dựa trên Wav2Vec 2.0 khoảng 76.2%, và giảm thời gian suy luận của mô hình SSL 79% trong khi đạt EER 0.98%. OS-KDFT được đề xuất được xác thực trên các tập dữ liệu VoxCeleb1 và VoxCeleb2 và các mô hình SSL W2V2 và HuBERT. Thí nghiệm có sẵn trên GitHub1 của chúng tôi.
Từ khóa chỉ mục: Xác minh người nói, Mô hình học tự giám sát, Chưng cất kiến thức

1. Giới thiệu
Xác minh người nói (SV) xác minh xem phát ngôn đầu vào có được thốt bởi người nói mục tiêu hay không. Hầu hết các nghiên cứu SV đã sử dụng các đặc trưng âm thanh được chế tạo thủ công như phổ đồ, phổ đồ Mel, và Hệ số Cepstral Tần số Mel (MFCC) làm đầu vào [1, 2]. Gần đây, trong các lĩnh vực xử lý tín hiệu âm thanh, đã có sự quan tâm ngày càng tăng đối với các mô hình học tự giám sát (SSL) âm thanh như Wav2Vec 2.0 (W2V2) [3], HuBERT [4], và WavLM [5] vì chúng có tiềm năng trích xuất biểu diễn phong phú hơn so với phương pháp thủ công [6, 7]. Theo xu hướng này, một nghiên cứu SV gần đây đã đạt được hiệu suất đáng chú ý khi sử dụng các mô hình SSL âm thanh [8].

Mặc dù các mô hình SSL âm thanh có hiệu suất ấn tượng, nhưng có một rào cản về chi phí tính toán khi sử dụng chúng. Phiên bản lớn nhất của W2V2 và HuBERT chứa khoảng 317M và 964M tham số, tương ứng. Do kích thước lớn của chúng, việc phát triển và triển khai các mô hình đặt ra một thách thức đáng kể. Do đó, cộng đồng nghiên cứu đã tập trung vào việc xây dựng các mô hình SSL nhẹ, và một số đã cố gắng huấn luyện các mô hình kích thước nhỏ [9]. Tuy nhiên, do khả năng hạn chế của chúng, việc huấn luyện một mô hình nhỏ với một lượng lớn dữ liệu là khó khăn [10, 11]. Như một cách tiếp cận thay thế, một số nghiên cứu đã khám phá khả năng của chưng cất kiến thức (KD), một chiến lược nén mô hình nổi tiếng chuyển kiến thức từ một mô hình lớn sang một mô hình nhỏ hơn [12].

Sanh và cộng sự [13] và Jiao và cộng sự [14] đã thiết kế DistilBERT và Tinybert để chưng cất BERT và chứng minh tiềm năng của KD trong xử lý ngôn ngữ tự nhiên (NLP). Theo những cách tiếp cận này, trong lĩnh vực xử lý tín hiệu âm thanh, Lee và cộng sự [15] và Chang và cộng sự [16] đã thiết kế FitHuBERT và DistilHuBERT để mang lại hiệu suất xuất sắc trên điểm chuẩn hiệu suất toàn cầu xử lý âm thanh [17]. Hơn nữa, Peng và cộng sự đã thành công trong việc giảm kích thước khung W2V2 thông qua KD [18]. Do đó, các nghiên cứu sử dụng KD đã trở thành xu hướng chính trong nghiên cứu hiện tại.

Tuy nhiên, việc đơn giản nén các mô hình SSL thông qua KD có những hạn chế cơ bản. Các mô hình SSL lớn thường được tối ưu hóa cho nhiệm vụ mục tiêu để trích xuất các đặc trưng được điều chỉnh theo nhiệm vụ, tốt hơn so với các đặc trưng gốc [6, 7, 8]. Như minh họa trong Hình 1 (a), các nghiên cứu nén SSL trước đây đầu tiên xây dựng một mô hình SSL nhẹ thông qua KD và sau đó sử dụng nó cho nhiệm vụ mục tiêu với trạng thái cố định. Vì họ không thể xem xét nhiệm vụ mục tiêu, họ không thể trích xuất các đặc trưng được tùy chỉnh cho nhiệm vụ. Tinh chỉnh (FT) của các mô hình SSL đã được chưng cất có thể giảm thiểu mối quan ngại này, nhưng nó đòi hỏi huấn luyện bổ sung. Hơn nữa, việc xác định điểm chuyển đổi thích hợp từ KD sang FT là khó khăn vì biết lượng KD tối ưu cho FT là phức tạp. Do đó, có thể cần các thí nghiệm thực nghiệm lặp đi lặp lại để quyết định điểm chuyển đổi tốt nhất.

Trong bài báo này, chúng tôi nhằm mục đích nén mô hình SSL cho các nhiệm vụ SV một cách hiệu quả để tạo thuận lợi cho việc phát triển và triển khai. Chúng tôi đề xuất một chiến lược huấn luyện mới Chưng Cất Kiến Thức và Tinh Chỉnh Một Bước (OS-KDFT) huấn luyện KD và FT cùng lúc. Chúng tôi tin rằng bằng cách thực hiện KD và FT đồng thời, các mạng giáo viên có thể chuyển giao hiệu quả thông tin quan trọng cho SV. Do đó, trong OS-KDFT được đề xuất, chúng tôi kết hợp các quy trình huấn luyện KD và FT, như được mô tả trong Hình 1 (b). Thông qua điều này, phương pháp được đề xuất có thể thực hiện KD trong khi xem xét nhiệm vụ mục tiêu để tránh chưng cất thông tin không hiệu quả cho nhiệm vụ mục tiêu. Hơn nữa, phương pháp này tránh việc chọn điểm chuyển đổi của việc học KD và FT. OS-KDFT được giải thích chi tiết trong Phần 3.

Thông qua bài báo này, chúng tôi đóng góp những điều sau.
• Theo hiểu biết tốt nhất của chúng tôi, OS-KDFT là cách tiếp cận đầu tiên để nén mô hình SSL âm thanh trong khi đồng thời tinh chỉnh. Các nghiên cứu trước đây chỉ tập trung vào việc ngưng tụ SSL thông qua KD, nhưng chúng tôi cũng xem xét FT để trích xuất các đặc trưng được điều chỉnh theo nhiệm vụ.
• OS-KDFT được đề xuất đã giảm hiệu quả kích thước W2V2 + ECAPA-TDNN 76%, và thời gian suy luận của mô hình SSL 79% trong khi cho thấy EER 0.98%.
• OS-KDFT được đề xuất được xác thực trên các tập dữ liệu VoxCeleb1 và VoxCeleb2 và các mô hình SSL âm thanh W2V2 và HuBERT.

2. Công trình liên quan
Các mô hình SSL âm thanh đã chứng minh hiệu suất thỏa mãn trong nhiều nghiên cứu xử lý tín hiệu âm thanh. Tuy nhiên, do chi phí tính toán cao, các nghiên cứu về nén mô hình đã thu hút sự chú ý [13, 14]. Phần này giới thiệu i) các nỗ lực trước đây, ii) tại sao chúng tôi nghiên cứu KD, và iii) nghiên cứu trong NLP đã truyền cảm hứng cho phương pháp được đề xuất của chúng tôi.

2.1. Nén mô hình SSL
Các phương pháp nén mô hình bao gồm lượng tử hóa, cắt tỉa, và chưng cất kiến thức. Để giảm kích thước của mỗi tham số, lượng tử hóa biểu diễn trọng số trong các biểu diễn bitwidth thấp hơn. Wang và cộng sự [19] đã gợi ý tiềm năng của lượng tử hóa bằng cách thành công trong việc giảm khung W2V2. Tuy nhiên, lượng tử hóa có hạn chế là nó không thể giảm số lượng tham số. Cắt tỉa loại bỏ trọng số hoặc kênh có tác động tối thiểu đến đầu ra [20]. Lai và cộng sự [21] đã cho thấy tính ưu việt của kỹ thuật này bằng cách áp dụng phương pháp cắt tỉa cho mô hình SSL âm thanh. Tuy nhiên, cắt tỉa gặp khó khăn trong việc thiết lập tiêu chí thích hợp để chọn các tham số cần được cắt tỉa. Chưng cất kiến thức tinh chế kiến thức từ một mô hình lớn sang một mô hình nhỏ. KD có thể giảm số lượng tham số và tránh nỗ lực tìm kiếm tham số để loại bỏ. Hơn nữa, phương pháp này đã chứng minh hiệu quả trong các khung SSL âm thanh nhẹ khác nhau, như FitHuBERT [15], Distilhubert [16], và LightHuBERT [22]. Do đó, theo xu hướng này, chúng tôi đã sử dụng KD như một kỹ thuật để nén mô hình SSL âm thanh.

2.2. Sự không phù hợp phân phối giữa giáo viên và học sinh
Các nhà nghiên cứu trong NLP đã lập luận rằng phân phối lý tưởng cho học sinh có thể khác với đầu ra của giáo viên [23, 24]. Các nghiên cứu của họ xác định rằng sự khác biệt phân phối có thể xảy ra mặc dù giáo viên và học sinh thực hiện nhiệm vụ giống hệt nhau. Trong nghiên cứu của chúng tôi, mô hình học sinh học SV mà mô hình giáo viên chưa bao giờ được huấn luyện. Do đó, khoảng cách phân phối giữa học sinh lý tưởng và giáo viên có thể lớn hơn so với nghiên cứu NLP. Từ góc độ này, chúng tôi đã sửa đổi kiến trúc của mạng học sinh để thu hẹp sự không phù hợp phân phối như trong Phần 3.

3. OS-KDFT
Nén mô hình đã trở thành một chủ đề ngày càng quan trọng trong cộng đồng nghiên cứu, vì nó có thể tạo thuận lợi cho việc phát triển và triển khai các mạng nơ-ron sâu. Nhiều nghiên cứu ứng dụng mô hình SSL đã khám phá các kỹ thuật KD khác nhau, nhưng họ chỉ tập trung vào việc chưng cất kiến thức của giáo viên bất kể nhiệm vụ mục tiêu. Do đó, nghiên cứu này nhằm mục đích chuyển giao kiến thức của giáo viên để phù hợp với SV. Để làm điều này, chúng tôi đề xuất chiến lược huấn luyện mới OS-KDFT, kết hợp chuyển giao kiến thức giáo viên và điều chỉnh xác minh người nói. OS-KDFT sử dụng một mạng học sinh có cấu trúc độc đáo có hai nhánh để bắt chước đầu ra của giáo viên và thực hiện nhiệm vụ mục tiêu. Phần này giải thích kiến trúc tổng thể của học sinh, khởi tạo trọng số, và thiết lập tỷ lệ học tập, được sửa đổi từ bản gốc.

3.1. Kiến trúc
Chúng tôi chưng cất các khung W2V2 và HuBERT, bao gồm mạng nơ-ron tích chập (CNN) và bộ mã hóa transformer. Chúng tôi xây dựng một mạng học sinh với số lượng tham số giảm bằng cách giới hạn số lượng lớp bộ mã hóa transformer. Hình 2 (a) mô tả kiến trúc của mạng học sinh, trong đó mạng học sinh có hai tuyến đường: đường dẫn không có adapter cho KD và đường dẫn adapter cho SV. Cả hai đường dẫn đều chia sẻ trọng số CNN và bộ mã hóa, nhưng chỉ có đường dẫn adapter sử dụng các tham số độc lập qua adapter. Chúng tôi chia các nhánh của học sinh để giảm thiểu chuyển giao âm tính, là sự suy giảm hiệu suất do xung đột giữa các nhiệm vụ trong thiết lập đa nhiệm vụ [25]. Vì chúng tôi tối ưu hóa cùng lúc mạng học sinh với hai nhiệm vụ khác nhau (KD và FT), học sinh đã tiếp xúc với chuyển giao âm tính. Một trong những giải pháp nổi tiếng để giảm thiểu chuyển giao âm tính là sử dụng các tham số độc lập cho mỗi nhiệm vụ [26, 27]. Do đó, chúng tôi đã chia các nhánh của học sinh và chèn các tham số bổ sung (adapter, lấy cảm hứng từ LORA [28]) vào nhánh thực hiện SV.

--- TRANG 2 ---
các nhiệm vụ một cách hiệu quả để tạo thuận lợi cho việc phát triển và triển khai. Chúng tôi đề xuất một chiến lược huấn luyện mới Chưng Cất Kiến Thức và Tinh Chỉnh Một Bước (OS-KDFT) huấn luyện KD và FT cùng nhau. Chúng tôi tin rằng bằng cách thực hiện KD và FT đồng thời, các mạng giáo viên có thể chuyển giao hiệu quả thông tin quan trọng cho SV. Do đó, trong OS-KDFT được đề xuất, chúng tôi kết hợp các quy trình huấn luyện KD và FT, như được mô tả trong Hình 1 (b). Thông qua điều này, phương pháp được đề xuất có thể thực hiện KD trong khi xem xét nhiệm vụ mục tiêu để tránh chưng cất thông tin không hiệu quả cho nhiệm vụ mục tiêu. Hơn nữa, phương pháp này tránh việc chọn điểm chuyển đổi của việc học KD và FT. OS-KDFT được giải thích chi tiết trong Phần 3.

Thông qua bài báo này, chúng tôi đóng góp những điều sau.
• Theo hiểu biết tốt nhất của chúng tôi, OS-KDFT là cách tiếp cận đầu tiên để nén mô hình SSL âm thanh trong khi đồng thời tinh chỉnh. Các nghiên cứu trước đây chỉ tập trung vào việc ngưng tụ SSL thông qua KD, nhưng chúng tôi cũng xem xét FT để trích xuất các đặc trưng được điều chỉnh theo nhiệm vụ.
• OS-KDFT được đề xuất đã giảm hiệu quả kích thước W2V2 + ECAPA-TDNN 76%, và thời gian suy luận của mô hình SSL 79% trong khi cho thấy EER 0.98%.
• OS-KDFT được đề xuất được xác thực trên các tập dữ liệu VoxCeleb1 và VoxCeleb2 và các mô hình SSL âm thanh W2V2 và HuBERT.

2. Công trình liên quan
Các mô hình SSL âm thanh đã chứng minh hiệu suất thỏa mãn trong nhiều nghiên cứu xử lý tín hiệu âm thanh. Tuy nhiên, do chi phí tính toán cao, các nghiên cứu về nén mô hình đã thu hút sự chú ý [13, 14]. Phần này giới thiệu i) các nỗ lực trước đây, ii) tại sao chúng tôi nghiên cứu KD, và iii) nghiên cứu trong NLP đã truyền cảm hứng cho phương pháp được đề xuất của chúng tôi.

2.1. Nén mô hình SSL
Các phương pháp nén mô hình bao gồm lượng tử hóa, cắt tỉa, và chưng cất kiến thức. Để giảm kích thước của mỗi tham số, lượng tử hóa biểu diễn trọng số trong các biểu diễn bitwidth thấp hơn. Wang và cộng sự [19] đã gợi ý tiềm năng của lượng tử hóa bằng cách thành công trong việc giảm khung W2V2. Tuy nhiên, lượng tử hóa có hạn chế là nó không thể giảm số lượng tham số. Cắt tỉa loại bỏ trọng số hoặc kênh có tác động tối thiểu đến đầu ra [20]. Lai và cộng sự [21] đã cho thấy tính ưu việt của kỹ thuật này bằng cách áp dụng phương pháp cắt tỉa cho mô hình SSL âm thanh. Tuy nhiên, cắt tỉa gặp khó khăn trong việc thiết lập tiêu chí thích hợp để chọn các tham số cần được cắt tỉa. Chưng cất kiến thức tinh chế kiến thức từ một mô hình lớn sang một mô hình nhỏ. KD có thể giảm số lượng tham số và tránh nỗ lực tìm kiếm tham số để loại bỏ. Hơn nữa, phương pháp này đã chứng minh hiệu quả trong các khung SSL âm thanh nhẹ khác nhau, như FitHuBERT [15], Distilhubert [16], và LightHuBERT [22]. Do đó, theo xu hướng này, chúng tôi đã sử dụng KD như một kỹ thuật để nén mô hình SSL âm thanh.

2.2. Sự không phù hợp phân phối giữa giáo viên và học sinh
Các nhà nghiên cứu trong NLP đã lập luận rằng phân phối lý tưởng cho học sinh có thể khác với đầu ra của giáo viên [23, 24]. Các nghiên cứu của họ xác định rằng sự khác biệt phân phối có thể xảy ra mặc dù giáo viên và học sinh thực hiện nhiệm vụ giống hệt nhau. Trong nghiên cứu của chúng tôi, mô hình học sinh học SV mà mô hình giáo viên chưa bao giờ được huấn luyện. Do đó, khoảng cách phân phối giữa học sinh lý tưởng và giáo viên có thể lớn hơn so với nghiên cứu NLP. Từ góc độ này, chúng tôi đã sửa đổi kiến trúc của mạng học sinh để thu hẹp sự không phù hợp phân phối như trong Phần 3.

3. OS-KDFT
Nén mô hình đã trở thành một chủ đề ngày càng quan trọng trong cộng đồng nghiên cứu, vì nó có thể tạo thuận lợi cho việc phát triển và triển khai các mạng nơ-ron sâu. Nhiều nghiên cứu ứng dụng mô hình SSL đã khám phá các kỹ thuật KD khác nhau, nhưng họ chỉ tập trung vào việc chưng cất kiến thức của giáo viên bất kể nhiệm vụ mục tiêu. Do đó, nghiên cứu này nhằm mục đích chuyển giao kiến thức của giáo viên để phù hợp với SV. Để làm điều này, chúng tôi đề xuất chiến lược huấn luyện mới OS-KDFT, kết hợp chuyển giao kiến thức giáo viên và điều chỉnh xác minh người nói. OS-KDFT sử dụng một mạng học sinh có cấu trúc độc đáo có hai nhánh để bắt chước đầu ra của giáo viên và thực hiện nhiệm vụ mục tiêu. Phần này giải thích kiến trúc tổng thể của học sinh, khởi tạo trọng số, và thiết lập tỷ lệ học tập, được sửa đổi từ bản gốc.

3.1. Kiến trúc
Chúng tôi chưng cất các khung W2V2 và HuBERT, bao gồm mạng nơ-ron tích chập (CNN) và bộ mã hóa transformer. Chúng tôi xây dựng một mạng học sinh với số lượng tham số giảm bằng cách giới hạn số lượng lớp bộ mã hóa transformer. Hình 2 (a) mô tả kiến trúc của mạng học sinh, trong đó mạng học sinh có hai tuyến đường: đường dẫn không có adapter cho KD và đường dẫn adapter cho SV. Cả hai đường dẫn đều chia sẻ trọng số CNN và bộ mã hóa, nhưng chỉ có đường dẫn adapter sử dụng các tham số độc lập qua adapter. Chúng tôi chia các nhánh của học sinh để giảm thiểu chuyển giao âm tính, là sự suy giảm hiệu suất do xung đột giữa các nhiệm vụ trong thiết lập đa nhiệm vụ [25]. Vì chúng tôi tối ưu hóa cùng lúc mạng học sinh với hai nhiệm vụ khác nhau (KD và FT), học sinh đã tiếp xúc với chuyển giao âm tính. Một trong những giải pháp nổi tiếng để giảm thiểu chuyển giao âm tính là sử dụng các tham số độc lập cho mỗi nhiệm vụ [26, 27]. Do đó, chúng tôi đã chia các nhánh của học sinh và chèn các tham số bổ sung (adapter, lấy cảm hứng từ LORA [28]) vào nhánh thực hiện SV.

--- TRANG 3 ---
Quy trình chi tiết của khối mã hóa được mô tả trong Hình 2 (b) và Phương trình (1)-(3). Trong đường dẫn không có adapter, các lớp Layer norm và Multi-head attention tính toán các đặc trưng ẩn X={x1, x2, ..., xn}. Sau đó, xi được chuyển đổi thành f(xi) thông qua lớp feed-forward (Phương trình 1). Đầu ra Y={y1, y2, ..., yn} là tổng từng phần tử của xi và f(xi), như trong Phương trình (2). Trong đường dẫn adapter, các đặc trưng ẩn X'={x'1, x'2, ..., x'n} được tính toán qua các lớp Layer norm và Multi-head attention, và x'i được biến đổi thành f(x'i) với cơ chế giống hệt trong đường dẫn không có adapter. x'i cũng được đưa vào adapter, bao gồm downsampling (Wdown∈R1024×64), hàm kích hoạt ReLU, và upsampling (Wup∈R64×1024). Như được giải thích bằng Phương trình (3), các đặc trưng đầu ra y'i là tổng từng phần tử của x'i, f(x'i), và đầu ra của adapter.

f(xi) = Feed Forward(xi) (1)
yi = xi + f(xi) (2)
y'i = x'i + f(x'i) + ReLU(x'iWdown)Wup (3)

3.2. Khởi tạo trọng số & tỷ lệ học tập
Chúng tôi khởi tạo ngẫu nhiên các tham số của bộ phân loại và adapter vì mô hình SSL gốc (giáo viên) không chứa cả hai module. Mặt khác, trọng số CNN và bộ mã hóa được tạo ra bằng cách sử dụng trọng số giáo viên. Khi khởi tạo các bộ mã hóa học sinh, chúng tôi sử dụng trọng số từ các bộ mã hóa giáo viên theo thứ tự gần với CNN. Chiến lược này dựa trên phát hiện của Chen và cộng sự rằng một bộ mã hóa gần CNN hơn có thể trích xuất các đặc trưng phong phú cho SV [8].

Chen và cộng sự đã đóng băng W2V2 trong 10 epoch đầu tiên để giảm thiểu sự khác biệt về lượng học tập giữa W2V2 và ECAPA-TDNN. Bằng cách bắt chước chiến lược của họ, chúng tôi đã điều chỉnh các tỷ lệ học tập khác nhau trên CNN, bộ mã hóa, adapter, và bộ phân loại. Phương trình (4)-(6) mô tả tỷ lệ học tập của mỗi module trong epoch τ. Tỷ lệ học tập của bộ phân loại được khởi tạo ngẫu nhiên (lrτc) được giảm theo quy tắc ủ cosine (Phương trình 4). Mặt khác, tỷ lệ học tập của CNN và bộ mã hóa được tiền huấn luyện (lrτs) tăng dần trong 10 epoch đầu tiên và sau đó giảm (Phương trình 5). Trong các adapter, tỷ lệ học tập (lrτa) giảm từ tối đa đến tối thiểu vì nó cũng được khởi tạo ngẫu nhiên. Nhưng giá trị được điều chỉnh bằng cách nhân với θ (Phương trình 6). Chúng tôi đặt β thành 0.93 và θ thành 10 vì chúng mang lại kết quả tốt nhất trong các thí nghiệm của chúng tôi.

lrτc = ηmin + 1/2(ηmax - ηmin)(1 + cos(τ/τtot π)) (4)
lrτs = {lrτc × τ/10, τ ≤ 10; lrτ-1s × β, τ > 10} (5)
lrτa = lrτc × θ (6)

4. Thiết lập thí nghiệm
4.1. Tập dữ liệu
Chúng tôi đã sử dụng các tập dữ liệu VoxCeleb1 [29] và VoxCeleb2 [30] để đánh giá phương pháp được đề xuất của chúng tôi. Tập huấn luyện VoxCeleb1 bao gồm 148,642 phát ngôn từ 1,211 người nói, và tập kiểm tra bao gồm 4,874 phát ngôn từ 40 người nói. Tập huấn luyện VoxCeleb2 tương ứng với 1,092,009 mẫu được thu thập từ 5,994 người nói. Chúng tôi chỉ sử dụng tập huấn luyện VoxCeleb2 mà không có phân vùng kiểm tra. Để tăng cường dữ liệu, chúng tôi đã sử dụng các tập dữ liệu MUSAN [31] và RIR reverberation [32]. Chúng tôi đánh giá các mô hình sử dụng cả ba thử nghiệm chính thức VoxCeleb1: Vox1-O, Vox1-Extend, Vox1-Hard. Chỉ số chính là tỷ lệ lỗi bằng nhau (EER) dựa trên độ tương tự cosine.

4.2. Baseline
Dựa trên Chen và cộng sự, chúng tôi đã xác định một khung kết hợp mô hình SSL âm thanh và ECAPA-TDNN làm baseline [8]. Chúng tôi thực hiện baseline sử dụng thư viện transformers HuggingFace [33] và khai thác phiên bản W2V2 và HuBERT được tiền huấn luyện của XLSR2 và large3.

4.3. Chi tiết thí nghiệm
Chúng tôi xây dựng một mini-batch sử dụng 128 mẫu, và mỗi mẫu được cắt ngẫu nhiên thành độ dài 2 giây. Sau đó, chúng tôi sử dụng bộ tối ưu hóa Adam không có weight decay, sử dụng mean-squared error (MSE) cho việc học KD, và nhân nó với 100 để điều chỉnh tỷ lệ giữa các loss. Như hàm loss phân loại người nói, chúng tôi đã sử dụng tiêu chí AAM-softmax [34] với margin 0.15 và scale 20. Chúng tôi áp dụng SpecAugment trên đầu ra của mô hình SSL trong thí nghiệm của chúng tôi với data augmentation. Trong đánh giá, toàn bộ phát ngôn và năm phân đoạn 3 giây của nó được sử dụng. Chi tiết thêm có thể tìm thấy trên GitHub của chúng tôi.

5. Kết quả
So sánh với baseline. Bảng 1 so sánh các khung truyền thống và OS-KDFT được đề xuất. Thí nghiệm #1 là khung baseline được trình bày trong [8], và Thí nghiệm #2 là triển khai của chúng tôi. Mỗi thí nghiệm chứng minh EER 0.73% và 0.82% mà không có hiệu chuẩn điểm. Thí nghiệm #3 và #4 là kết quả của việc nén khung của Thí nghiệm #2 thông qua knowledge distillation và fine-tuning (KDFT) và OS-KDFT, tương ứng. KDFT là một chiến lược huấn luyện kết hợp KD và học SV mà không có bất kỳ sửa đổi nào, và OS-KDFT là phương pháp được đề xuất của chúng tôi đã phát triển KDFT bằng cách sử dụng adapter. KDFT và OS-KDFT nén đáng kể baseline khoảng 76% và giảm thời gian suy luận của mô hình SSL 79%. KDFT đạt EER 1.26%, một hiệu suất suy giảm nghiêm trọng từ 0.82% (#3). Tuy nhiên, OS-KDFT thành công thực hiện KD và FT và mang lại EER 0.98% (#4). Thông qua những kết quả này, chúng tôi xác nhận rằng OS-KDFT được đề xuất có tiềm năng chưng cất mô hình SSL phù hợp cho SV.

So sánh với phương pháp truyền thống. Để điều tra thêm, chúng tôi đã so sánh OS-KDFT với các chiến lược huấn luyện khác trong tập dữ liệu VoxCeleb1; Hình 3 minh họa những kết quả này. Trong những thí nghiệm này, chúng tôi không áp dụng DA để loại trừ các biến. Các thanh màu xanh (trái) trong Hình 3 cho thấy kết quả của việc nén mô hình SSL qua KD và sử dụng nó cho SV. Phương pháp này đạt EER 6.83% và 8.20% khi tỷ lệ epoch của KD và FT là 50:50 và 75:25, tương ứng. Các thanh màu vàng (phải) mô tả kết quả của việc tinh chỉnh thêm cho SV: điều này giảm EER xuống 5.91% và 7.30%, tương ứng cho mỗi tỷ lệ epoch. Những kết quả này xác nhận rằng việc đơn giản nén mô hình với KD không tạo ra học sinh tối ưu cho nhiệm vụ mục tiêu. Ngoài ra, sự sai lệch hiệu suất có thể xảy ra tùy thuộc vào tỷ lệ học KD và SV. Đường liền nét màu xanh lá cây đại diện cho EER của học sinh đã có được kiến thức từ giáo viên được tinh chỉnh SV. Vì giáo viên có thể nhận dạng người nói, chúng tôi có thể sử dụng loss Kullback-Leibler divergence cho việc huấn luyện học sinh trong thí nghiệm này. Kết quả là, chúng tôi đã huấn luyện học sinh để dự đoán phân phối đầu ra softmax của giáo viên, dẫn đến EER 7.17%. Đường nét đứt màu đỏ đại diện cho kết quả OS-KDFT, và nó mang lại EER thấp nhất 5.91%. Những kết quả này cho thấy rằng một chiến lược huấn luyện kết hợp KD và FT có tiềm năng so với các phương pháp nén truyền thống.

Nghiên cứu loại bỏ. Bảng 2 hiển thị sự thay đổi hiệu suất với việc áp dụng mỗi chiến lược của OS-KDFT trên các tập dữ liệu VoxCeleb1 và VoxCeleb2. Nén baseline thông qua KDFT trong tập dữ liệu VoxCeleb1 cho EER 8.17% (#5). Trong Thí nghiệm #6, chúng tôi chỉ thêm các tham số của adapter vào #5 mà không tách nhánh, và nó cho thấy EER được cải thiện nhẹ 7.94%. Khi chia tuyến đường (#7), nó đạt EER 7.28%, một hiệu suất được cải thiện đáng kể so với #5. Cuối cùng, chúng tôi có thể đạt được hiệu suất tốt nhất 5.64% bằng cách điều chỉnh tỷ lệ học tập được mô tả trong Phần 3.2. Trong các thí nghiệm sử dụng VoxCeleb2, chúng tôi đã sử dụng không chỉ Original (O) mà còn Extend (E) và Hard (H) trials để đánh giá tinh vi hơn. Khi baseline được nén thông qua KDFT, nó mang lại EER 3.35%, 3.41%, và 5.97% trong các thử nghiệm O, E, và H, tương ứng (#9). Trong Thí nghiệm #10, chúng tôi chỉ đơn giản thêm các tham số của adapter mà không tách nhánh, và nó làm giảm hiệu suất xuống 3.46%, 3.41%, và 6.01%. Mặt khác, trong thí nghiệm #11, chúng tôi cũng chia đường dẫn và cải thiện EER thành 2.74%, 3.01%, và 5.44%. Hiệu suất tốt nhất 2.50%, 2.56%, và 5.18% được mang lại khi tỷ lệ học tập cũng được đa dạng hóa cho mỗi module (#12). Do đó, khó có thể quy kết hiệu ứng của OS-KDFT đơn giản là tăng số lượng tham số và mỗi chiến lược của OS-KDFT là cần thiết.

--- TRANG 4 ---
Áp dụng cho các mô hình khác. Để xác minh thêm hiệu quả của OS-KDFT, chúng tôi đã áp dụng điều này cho mô hình SSL và bộ phân loại khác. Bảng 3 trình bày kết quả của những nghiên cứu này. Trong Thí nghiệm #13 và #14, chúng tôi đã thay đổi bộ phân loại từ ECAPA-TDNN sang lớp tuyến tính. Mô hình được huấn luyện giống hệt với #3 mang lại EER 8.27%, trong khi khung được huấn luyện với OS-KDFT trình bày EER 5.92%. Trong Thí nghiệm #15 và #16, chúng tôi đã sử dụng HuBERT thay vì W2V2. Chưng cất HuBERT thông qua KDFT cho EER kém hơn 7.15%. Ngược lại, khi nén HuBERT qua OS-KDFT, EER là 5.97%. Thông qua những kết quả này, chúng tôi có thể xác nhận rằng phương pháp OS-KDFT hoạt động hiệu quả trong các khung khác.

6. Kết luận
Trong bài báo này, chúng tôi thiết kế một phương pháp Chưng Cất Kiến Thức và Tinh Chỉnh Một Bước (OS-KDFT) để ngưng tụ mô hình SSL cho SV. OS-KDFT là cách tiếp cận đầu tiên để nén mô hình SSL âm thanh trong khi đồng thời tinh chỉnh và giảm thiểu chuyển giao âm tính bằng cách sử dụng adapter. Thông qua OS-KDFT, chúng tôi có thể nén mô hình 321.4M xuống 76.6M, và giảm thời gian suy luận của mô hình SSL 79% trong khi trình bày EER 0.98%. Chúng tôi đã xác minh hiệu quả của OS-KDFT thông qua so sánh với các chiến lược huấn luyện khác và các ứng dụng trên mô hình SSL khác. Tuy nhiên, nghiên cứu của chúng tôi có những hạn chế. Để khái quát hóa hiệu quả của OS-KDFT, chúng tôi nên đánh giá phương pháp được đề xuất của chúng tôi với các phương pháp KD khác nhau (ví dụ: chuyển giao kiến thức của giáo viên từ các đặc trưng ẩn thay vì đầu ra). Do đó, chúng tôi sẽ kết hợp OS-KDFT với các phương pháp KD khác trong các công việc tương lai.

7. Lời cảm ơn
Công trình này được hỗ trợ bởi Quỹ Nghiên cứu Quốc gia Hàn Quốc (NRF) được tài trợ bởi chính phủ Hàn Quốc. (MSIT) (2023R1A2C1005744)

--- TRANG 5 ---
8. Tài liệu tham khảo
[1] X. Liu, M. Sahidullah, và T. Kinnunen, "Learnable nonlinear compression for robust speaker verification," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, tr. 7962–7966.
[2] H.-j. Shim, J. Heo, J.-h. Park, G.-h. Lee, và H.-J. Yu, "Graph attentive feature aggregation for text-independent speaker verification," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, tr. 7972–7976.
[3] A. Baevski, Y. Zhou, A. Mohamed, và M. Auli, "wav2vec 2.0: A framework for self-supervised learning of speech representations," Advances in neural information processing systems, vol. 33, tr. 12 449–12 460, 2020.
[4] W.-N. Hsu, B. Bolte, Y.-H. H. Tsai, K. Lakhotia, R. Salakhutdinov, và A. Mohamed, "Hubert: Self-supervised speech representation learning by masked prediction of hidden units," IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, tr. 3451–3460, 2021.
[5] S. Chen, C. Wang, Z. Chen, Y. Wu, S. Liu, Z. Chen, J. Li, N. Kanda, T. Yoshioka, X. Xiao và cộng sự, "Wavlm: Large-scale self-supervised pre-training for full stack speech processing," IEEE Journal of Selected Topics in Signal Processing, vol. 16, số 6, tr. 1505–1518, 2022.
[6] S. Hussain, V. Nguyen, S. Zhang, và E. Visser, "Multi-task voice activated framework using self-supervised learning," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, tr. 6137–6141.
[7] H. Song, S. Chen, Z. Chen, Y. Wu, T. Yoshioka, M. Tang, J. W. Shin, và S. Liu, "Exploring wavlm on speech enhancement," trong 2022 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2023, tr. 451–457.
[8] Z. Chen, S. Chen, Y. Wu, Y. Qian, C. Wang, S. Liu, Y. Qian, và M. Zeng, "Large-scale self-supervised speech representation learning for automatic speaker verification," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, tr. 6147–6151.
[9] P.-H. Chi, P.-H. Chung, T.-H. Wu, C.-C. Hsieh, Y.-H. Chen, S.-W. Li, và H.-y. Lee, "Audio albert: A lite bert for self-supervised learning of audio representation," trong 2021 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2021, tr. 344–350.
[10] C. Sun, A. Shrivastava, S. Singh, và A. Gupta, "Revisiting unreasonable effectiveness of data in deep learning era," trong Proceedings of the IEEE international conference on computer vision, 2017, tr. 843–852.
[11] Y. Huang, Y. Cheng, A. Bapna, O. Firat, D. Chen, M. Chen, H. Lee, J. Ngiam, Q. V. Le, Y. Wu và cộng sự, "Gpipe: Efficient training of giant neural networks using pipeline parallelism," Advances in neural information processing systems, vol. 32, 2019.
[12] G. Hinton, O. Vinyals, và J. Dean, "Distilling the knowledge in a neural network," Advances in neural information processing systems, 2014.
[13] V. Sanh, L. Debut, J. Chaumond, và T. Wolf, "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter," Advances in neural information processing systems, 2019.
[14] X. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, và Q. Liu, "Tinybert: Distilling BERT for natural language understanding," trong Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, 2020, tr. 4163–4174.
[15] Y. Lee, K. Jang, J. Goo, Y. Jung, và H. R. Kim, "Fithubert: Going thinner and deeper for knowledge distillation of speech self-supervised models," trong INTERSPEECH 2022, 2022, tr. 3588–3592.
[16] H.-J. Chang, S.-w. Yang, và H.-y. Lee, "Distilhubert: Speech representation learning by layer-wise distillation of hidden-unit bert," trong 2022 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2022, tr. 7087–7091.
[17] S.-w. Yang, P.-H. Chi, Y.-S. Chuang, C.-I. J. Lai, K. Lakhotia, Y. Y. Lin, A. T. Liu, J. Shi, X. Chang, G.-T. Lin và cộng sự, "Superb: Speech processing universal performance benchmark," arXiv preprint arXiv:2105.01051, 2021.
[18] Z. Peng, A. Budhkar, I. Tuil, J. Levy, P. Sobhani, R. Cohen, và J. Nassour, "Shrinking bigfoot: Reducing wav2vec 2.0 footprint," trong Proceedings of the Second Workshop on Simple and Efficient Natural Language Processing, 2021, tr. 134–141.
[19] N. Wang, C.-C. Liu, S. Venkataramani, S. Sen, C.-Y. Chen, K. El Maghraoui, V. Srinivasan, và L. Chang, "Deep compression of pre-trained transformer models," trong Advances in Neural Information Processing Systems, 2022.
[20] S. Han, J. Pool, J. Tran, và W. Dally, "Learning both weights and connections for efficient neural network," trong Advances in Neural Information Processing Systems, 2015.
[21] C.-I. J. Lai, Y. Zhang, A. H. Liu, S. Chang, Y.-L. Liao, Y.-S. Chuang, K. Qian, S. Khurana, D. Cox, và J. Glass, "Parp: Prune, adjust and re-prune for self-supervised speech recognition," Advances in Neural Information Processing Systems, vol. 34, tr. 21 256–21 272, 2021.
[22] R. Wang, Q. Bai, J. Ao, L. Zhou, Z. Xiong, Z. Wei, Y. Zhang, T. Ko, và H. Li, "Lighthubert: Lightweight and configurable speech representation learning with once-for-all hidden-unit BERT," trong INTERSPEECH 2022, 2022, tr. 1686–1690.
[23] X. Jin, B. Peng, Y. Wu, Y. Liu, J. Liu, D. Liang, J. Yan, và X. Hu, "Knowledge distillation via route constrained optimization," trong Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019, tr. 1345–1354.
[24] D. Y. Park, M.-H. Cha, D. Kim, B. Han và cộng sự, "Learning student-friendly teacher networks for knowledge distillation," Advances in Neural Information Processing Systems, vol. 34, tr. 13 292–13 303, 2021.
[25] S. Liu, Y. Liang, và A. Gitter, "Loss-balanced task weighting to reduce negative transfer in multi-task learning," trong Proceedings of the AAAI conference on artificial intelligence, vol. 33, số 01, 2019, tr. 9977–9978.
[26] Z. Meng, X. Yao, và L. Sun, "Multi-task distillation: Towards mitigating the negative transfer in multi-task learning," trong 2021 IEEE International Conference on Image Processing (ICIP). IEEE, 2021, tr. 389–393.
[27] X. Sun, R. Panda, R. Feris, và K. Saenko, "Adashare: Learning what to share for efficient deep multi-task learning," Advances in Neural Information Processing Systems, vol. 33, tr. 8728–8740, 2020.
>>>>>>> Stashed changes
[28] E. J. H. và cộng sự, "Lora: Low-rank adaptation of large language models," trong The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022, 2022.
[29] A. Nagrani, J. S. Chung, và A. Zisserman, "Voxceleb: a large-scale speaker identification dataset," arXiv preprint arXiv:1706.08612, 2017.
[30] J. S. Chung, A. Nagrani, và A. Zisserman, "Voxceleb2: Deep speaker recognition," arXiv preprint arXiv:1806.05622, 2018.
[31] D. Snyder, G. Chen, và D. Povey, "Musan: A music, speech, and noise corpus," arXiv preprint arXiv:1510.08484, 2015.
<<<<<<< Updated upstream
[32] T. Ko, V. Peddinti, D. Povey, M. L. Seltzer, và S. Khudanpur, "A study on data augmentation of reverberant speech for robust speech recognition," trong 2017 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2017, trang 5220–5224.
[33] T. W. và cộng sự, "Transformers: State-of-the-art natural language processing," trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Online: Association for Computational Linguistics, Tháng 10 2020, trang 38–45.
[34] J. Deng, J. Guo, N. Xue, và S. Zafeiriou, "Arcface: Additive angular margin loss for deep face recognition," trong Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, trang 4690–4699.
=======
[32] T. Ko, V. Peddinti, D. Povey, M. L. Seltzer, và S. Khudanpur, "A study on data augmentation of reverberant speech for robust speech recognition," trong 2017 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2017, tr. 5220–5224.
[33] T. W. và cộng sự, "Transformers: State-of-the-art natural language processing," trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Online: Association for Computational Linguistics, Oct. 2020, tr. 38–45.
[34] J. Deng, J. Guo, N. Xue, và S. Zafeiriou, "Arcface: Additive angular margin loss for deep face recognition," trong Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, tr. 4690–4699.
>>>>>>> Stashed changes

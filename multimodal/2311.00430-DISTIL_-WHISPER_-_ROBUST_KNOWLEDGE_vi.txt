# 2311.00430.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multimodal/2311.00430.pdf
# Kích thước tệp: 2513329 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
DISTIL-WHISPER : CHƯNG CẤT KIẾN THỨC MẠNH MẼ
THÔNG QUA VIỆC GÁN NHÃN GIẢ QUY MÔ LỚN

Sanchit Gandhi, Patrick von Platen & Alexander M. Rush
Hugging Face
{sanchit, patrick, sasha }@huggingface.co

TÓM TẮT
Khi kích thước của các mô hình nhận dạng giọng nói được huấn luyện trước tăng lên, việc chạy những mô hình lớn này trong môi trường có độ trễ thấp hoặc hạn chế tài nguyên trở nên thách thức. Trong công trình này, chúng tôi tận dụng việc gán nhãn giả để tập hợp một bộ dữ liệu mã nguồn mở quy mô lớn mà chúng tôi sử dụng để chưng cất mô hình Whisper thành một biến thể nhỏ hơn, được gọi là Distil-Whisper. Sử dụng một heuristic tỷ lệ lỗi từ (WER) đơn giản, chúng tôi chỉ chọn những nhãn giả có chất lượng cao nhất để huấn luyện. Mô hình được chưng cất nhanh hơn 5.8 lần với ít hơn 51% tham số, trong khi thực hiện trong vòng 1% WER trên dữ liệu kiểm tra ngoài phân phối trong thiết lập chuyển giao zero-shot. Distil-Whisper duy trì độ bền vững của mô hình Whisper đối với các điều kiện âm thanh khó khăn, đồng thời ít bị lỗi ảo giác hơn trên âm thanh dạng dài. Distil-Whisper được thiết kế để ghép nối với Whisper cho giải mã suy đoán, mang lại tốc độ nhanh hơn 2 lần trong khi đảm bảo toán học các đầu ra giống như mô hình gốc. Để tạo điều kiện nghiên cứu thêm trong lĩnh vực này, chúng tôi công khai mã huấn luyện, mã suy luận và các mô hình.

1 GIỚI THIỆU
Trong những năm gần đây, các hệ thống Nhận dạng Giọng nói Tự động (ASR) đã vượt qua độ chính xác cấp độ con người trong nhiều tiêu chuẩn học thuật (Amodei et al., 2016; Baevski et al., 2020; Zhang et al., 2020), cho phép một loạt các ứng dụng từ dịch vụ phiên âm đến trợ lý giọng nói (Aksenova et al., 2021). Whisper (Radford et al., 2022), một mô hình transformer chuỗi đến chuỗi (Seq2Seq) 1.5 tỷ tham số (Vaswani et al., 2017) được huấn luyện trước trên 680.000 giờ dữ liệu nhận dạng giọng nói được giám sát yếu, thể hiện khả năng tổng quát hóa mạnh mẽ đối với nhiều bộ dữ liệu và lĩnh vực khác nhau (Gandhi et al., 2022). Tuy nhiên, kích thước ngày càng tăng của các mô hình ASR được huấn luyện trước đặt ra thách thức khi triển khai những hệ thống này trong các thiết lập có độ trễ thấp hoặc phần cứng hạn chế tài nguyên (He et al., 2018; Zhang et al., 2022).

Những nỗ lực gần đây trong xử lý ngôn ngữ tự nhiên (NLP) đã thể hiện những tiến bộ đầy hứa hẹn trong việc nén các mô hình dựa trên transformer. Chưng cất kiến thức (KD) đã được áp dụng thành công để giảm kích thước của các mô hình như BERT (Devlin et al., 2019), mà không có sự mất mát hiệu suất đáng kể trên các nhiệm vụ phân loại không sinh tạo (Sanh et al., 2019; Jiao et al., 2020; Sun et al., 2020). Được truyền cảm hứng từ các phương pháp dịch máy, các cách tiếp cận gán nhãn giả (PL) (Kim & Rush, 2016) cũng đã được khám phá cho tóm tắt Seq2Seq (Shleifer & Rush, 2020), thể hiện tiềm năng nén đáng kể của các mô hình Seq2Seq trên các nhiệm vụ sinh tạo. Trong lĩnh vực âm thanh, KD đã cho thấy kết quả đầy hứa hẹn cho phân loại âm thanh (Peng et al., 2021; Chang et al., 2021). Tuy nhiên, kết quả tương tự chưa được đạt được cho nhiệm vụ khó khăn hơn là nhận dạng giọng nói.

Trong bài báo này, chúng tôi áp dụng chưng cất cho mô hình Whisper trong bối cảnh ASR Seq2Seq. Chúng tôi giải quyết thách thức duy trì độ bền vững đối với các điều kiện âm thanh khác nhau thông qua việc xây dựng một bộ dữ liệu mã nguồn mở quy mô lớn bao gồm 10 lĩnh vực riêng biệt. Bằng cách gán nhãn giả cho dữ liệu, chúng tôi đảm bảo định dạng phiên âm nhất quán trong toàn bộ bộ dữ liệu và cung cấp tín hiệu chưng cất ở cấp độ chuỗi. Chúng tôi đề xuất một heuristic dựa trên tỷ lệ lỗi từ (WER) đơn giản để lọc dữ liệu được gán nhãn giả và chứng minh rằng đó là một phương pháp hiệu quả để đảm bảo hiệu suất hạ nguồn tốt của mô hình được chưng cất.

--- TRANG 2 ---
Chúng tôi chứng minh rằng Distil-Whisper duy trì độ bền vững của Whisper đối với các lĩnh vực âm thanh khác nhau và điều kiện âm thanh nhiễu. Chúng tôi đo lường điều này bằng cách đánh giá các mô hình được chưng cất trên bốn bộ kiểm tra ngoài phân phối trải rộng nhiều lĩnh vực âm thanh. Mô hình tốt nhất thực hiện trong vòng 1% WER của checkpoint Whisper gốc, trong khi nhanh hơn 5.8 lần với ít hơn 51% tham số. Trong đánh giá dạng dài, mô hình được chưng cất vượt trội hơn Whisper 0.1% WER. Chúng tôi cho thấy rằng sự cải thiện hiệu suất này là do xu hướng ảo giác thấp hơn so với mô hình Whisper gốc.

Bằng cách chia sẻ cùng trọng số encoder với Whisper, Distil-Whisper có thể được sử dụng hiệu quả như một mô hình trợ lý cho Whisper để giải mã suy đoán (Leviathan et al., 2023), mà chúng tôi đạt được cải thiện 2 lần tốc độ suy luận chỉ với 8% tăng số lượng tham số. Giải mã suy đoán đảm bảo thuật toán rằng các dự đoán của mô hình chính không thay đổi, có nghĩa là nó có thể được sử dụng như một sự thay thế trực tiếp cho các pipeline nhận dạng giọng nói hiện có sử dụng Whisper.

Công trình của chúng tôi cho thấy rằng việc gán nhãn giả quy mô lớn của dữ liệu giọng nói đã bị khám phá chưa đầy đủ và nó cung cấp một kỹ thuật đầy hứa hẹn cho KD. Để phục vụ như một cơ sở cho nghiên cứu thêm về chưng cất cho nhận dạng giọng nói, chúng tôi phát hành mã huấn luyện, mã suy luận và các mô hình dưới https://github.com/huggingface/distil-whisper .

2 CÔNG TRÌNH LIÊN QUAN
Trong lĩnh vực NLP, chưng cất mô hình đã thể hiện hứa hẹn đáng kể trong việc giảm kích thước mô hình và yêu cầu tính toán với sự suy giảm hiệu suất tối thiểu. Sanh et al. (2019) sử dụng trung bình có trọng số của mất mát KD và mất mát entropy chéo dữ liệu truyền thống để huấn luyện DistilBERT, một phiên bản chưng cất 6 lớp của BERT (Devlin et al., 2019), đạt được giảm 40% kích thước mô hình, tăng 60% tốc độ và bảo toàn 97% khả năng hiểu ngôn ngữ trên tiêu chuẩn GLUE (Wang et al., 2019). Shleifer & Rush (2020) mở rộng phương pháp DistilBERT cho thiết lập Seq2Seq, bằng cách khởi tạo decoder học sinh từ các lớp cách đều tối đa của decoder giáo viên và kết hợp các trạng thái ẩn trung gian vào hàm mất mát KD. Mô hình kết quả, DistilBART, vượt trội hơn mô hình gốc trên các bộ dữ liệu XSUM và CNN/Daily Mail (Narayan et al., 2018; See et al., 2017), với nén mô hình 37% và tăng 48% tốc độ. Du et al. (2023) chứng minh rằng trong khi các mô hình được chưng cất thực hiện tốt trên dữ liệu đánh giá trong phân phối (ID), chúng thực hiện tệ hơn đáng kể so với các đối tác được huấn luyện trước của chúng trên các bộ kiểm tra ngoài phân phối (OOD). Bằng cách huấn luyện trên một bộ dữ liệu được gán nhãn giả đa dạng, quy mô lớn, chúng tôi bảo toàn độ bền vững đối với các điều kiện âm thanh khác nhau, được chứng minh bởi khả năng tổng quát hóa cho dữ liệu kiểm tra OOD.

KD cũng đã được áp dụng cho nhiệm vụ ASR, mặc dù tập trung vào các mô hình chỉ có encoder. Peng et al. (2021) áp dụng KD cho mô hình Wav2Vec 2.0 (Baevski et al., 2020), đạt được nén mô hình 79% và tăng 59% tốc độ. Tuy nhiên, những lợi ích này đi kèm với chi phí tăng 6.9% WER trên kho dữ liệu LibriSpeech (Panayotov et al., 2015). Chang et al. (2021) áp dụng một phương pháp tương tự cho mô hình HuBERT (Hsu et al., 2021), và cũng báo cáo tăng 7.0% WER. Pang et al. (2018) cố gắng chưng cất LAS Chan et al. (2016), một mô hình ASR Seq2Seq sớm, nhưng thấy rằng mô hình được chưng cất tốt nhất của họ thực hiện tệ hơn 2.2% WER so với đối tác lớn hơn. Bài báo này tập trung vào KD của các mô hình Seq2Seq, với nén mô hình đáng kể nhưng cũng bảo toàn hiệu suất WER trên dữ liệu kiểm tra OOD.

Các nghiên cứu trước đây liên quan đến chưng cất mô hình Whisper chủ yếu tập trung vào việc giảm kích thước mô hình và dấu chân bộ nhớ. Shao et al. (2023) áp dụng KD kết hợp với Huấn luyện Nhận biết Lượng tử hóa (QAT) (Jacob et al., 2017), chứng minh rằng việc giảm tham số đáng kể là có thể với chỉ sự giảm hiệu suất nhỏ. Tuy nhiên, mô hình học sinh được huấn luyện và kiểm tra trên một kho dữ liệu nhỏ của dữ liệu ID, không đưa ra thước đo khả năng tổng quát hóa của nó cho dữ liệu OOD, và do đó độ bền vững của nó đối với các điều kiện âm thanh khác nhau (Geirhos et al., 2020; Radford et al., 2022). Hơn nữa, công trình này không xem xét tối ưu hóa mô hình cho độ trễ. Bài báo này tìm cách chưng cất mô hình Whisper để đạt được nén mô hình đáng kể, cùng với cải thiện độ trễ và hiệu suất WER trên dữ liệu kiểm tra OOD. Chúng tôi cũng đánh giá độ bền vững của các mô hình được chưng cất đối với các điều kiện âm thanh nhiễu.

--- TRANG 3 ---
Bảng 1: Chi tiết về kích thước của các checkpoint Whisper được huấn luyện trước.

Mô hình | Lớp | Chiều rộng | Đầu | Tham số / M
tiny.en | 4 | 384 | 6 | 39
base.en | 6 | 512 | 8 | 74
small.en | 12 | 768 | 12 | 244
medium.en | 24 | 1024 | 16 | 769
large-v2 | 32 | 1280 | 20 | 1550

3 BỐI CẢNH
Whisper (Radford et al., 2022) là một mô hình transformer chuỗi đến chuỗi (Seq2Seq) (Vaswani et al., 2017) được huấn luyện trước trên 680.000 giờ dữ liệu nhận dạng giọng nói nhiễu được thu thập từ internet. Khi được mở rộng đến số lượng dữ liệu này, Whisper mang lại kết quả cạnh tranh với các hệ thống được giám sát đầy đủ, nhưng trong thiết lập zero-shot mà không cần điều chỉnh tinh.

Whisper bao gồm một encoder (Enc) và decoder (Dec) dựa trên transformer. Giả sử chúng ta có một tín hiệu giọng nói đầu vào bao gồm T vector đặc trưng X1:T={x1, . . . ,xT} và một phiên âm đích y1:N={y1, . . . , yN} của N token trong thiết lập nhận dạng giọng nói tiêu chuẩn. Encoder FEnc được huấn luyện để ánh xạ X1:T đến một chuỗi vector trạng thái ẩn H1:M:

FEnc:X1:T→H1:M (1)

Độ dài chuỗi của các trạng thái ẩn M thường bằng một nửa độ dài của chuỗi đặc trưng giọng nói đầu vào T do tác động của các lớp tích chập trong thân encoder làm giảm mẫu đầu vào.

Decoder tự hồi quy dự đoán một phân phối xác suất cho token tiếp theo yi, có điều kiện trên tất cả các token trước đó y<i và các trạng thái ẩn encoder H1:M:

P(yi|y<i,H1:M) (2)

Để huấn luyện mô hình Whisper, chúng ta giả định một bộ dữ liệu trong đó mỗi ví dụ (X1:T,y1:N) là một cặp (âm thanh, văn bản). Mô hình được huấn luyện sử dụng mất mát entropy chéo (CE) tiêu chuẩn, nơi mô hình được huấn luyện để dự đoán một lớp thể hiện bằng cách tối đa hóa xác suất ước lượng của các nhãn lớp đích:

LCE=−∑(i=1 to N) P(yi|y<i,H1:M) (3)

Có năm biến thể của mô hình Whisper được tóm tắt trong Bảng 1. Các mô hình chia sẻ cùng kiến trúc Seq2Seq nhưng có kích thước khác nhau. Đối với tất cả kích thước mô hình, encoder và decoder có cùng chiều rộng, đầu và số lượng lớp trong các khối transformer. Phiên bản đầu tiên của bài báo Whisper giới thiệu checkpoint large-v1, sau đó được huấn luyện lại với việc chính quy hóa nhiều epoch huấn luyện hơn để tạo ra phiên bản large-v2 cải tiến (Radford et al., 2022). Vì cả hai mô hình đều chia sẻ cùng kích thước, chúng tôi trình bày kết quả cho mô hình large-v2 trong bài báo này.

4 CHƯNG CẤT KIẾN THỨC MẠNH MẼ
4.1 CHƯNG CẤT KIẾN THỨC

Chưng cất kiến thức (KD) (Hinton et al., 2015) là một kỹ thuật nén trong đó một mô hình học sinh nhỏ hơn được huấn luyện để tái tạo hành vi của một mô hình giáo viên lớn hơn. So với việc tối thiểu hóa mất mát CE giữa các dự đoán của mô hình học sinh và các nhãn huấn luyện, KD cho phép mô hình học sinh học từ toàn bộ phân phối dự đoán của các token tiếp theo có thể trong một bối cảnh nhất định, thay vì chỉ tối đa hóa xác suất của token đích tiếp theo trong dữ liệu huấn luyện.

--- TRANG 4 ---
Thu nhỏ và Điều chỉnh Tinh Phương pháp chưng cất cơ bản nhất bao gồm việc thu nhỏ mô hình giáo viên thành kích thước học sinh nhỏ hơn và huấn luyện học sinh trên mục tiêu CE trong Phương trình 3. Theo Shleifer & Rush (2020), chúng tôi thực hiện nén dựa trên lớp bằng cách khởi tạo mô hình học sinh bằng cách sao chép trọng số từ các lớp cách đều tối đa của mô hình giáo viên. Ví dụ, khi khởi tạo mô hình học sinh 2 lớp từ mô hình giáo viên 32 lớp, chúng tôi sao chép lớp thứ 1 và thứ 32 từ giáo viên sang học sinh. Với tính đơn giản và hiệu quả của chiến lược này trong thiết lập tóm tắt Seq2Seq (Shleifer & Rush, 2020; Li et al., 2022), chúng tôi sử dụng nó cho tất cả các phương pháp chưng cất.

Gán Nhãn Giả Trong thiết lập nhãn giả (Kim & Rush, 2016), chúng tôi thay thế phiên âm văn bản thật y1:N bằng sinh tạo của giáo viên ŷ1:N′ cho âm thanh đầu vào tương ứng X1:T:

LPL=−∑(i=1 to N′) P(yi|ŷ<i,H1:M) (4)

Dạng chưng cất này có thể được coi là KD "cấp chuỗi", nơi kiến thức được chuyển giao từ mô hình giáo viên sang mô hình học sinh qua một chuỗi nhãn giả được sinh tạo (Kim & Rush, 2016).

Độ phân kỳ Kullback-Leibler Trong thiết lập KL Divergence (Kullback & Leibler, 1951), toàn bộ phân phối xác suất của mô hình học sinh Pi được huấn luyện để khớp với phân phối đầy đủ của mô hình giáo viên Qi bằng cách tối thiểu hóa độ phân kỳ KL trên toàn bộ tập hợp các token tiếp theo có thể tại vị trí i:

LKL=∑(i=1 to N) KL(Qi, Pi) (5)

Điều này có thể được coi là KD "cấp từ", nơi kiến thức được chuyển giao từ mô hình giáo viên sang mô hình học sinh thông qua các logit trên các token có thể (Kim & Rush, 2016). KL Divergence hấp dẫn vì nó cung cấp thông tin trên tất cả các lớp và có ít biến thiên trong gradient hơn mất mát CE (Hinton et al., 2015).

Mục tiêu Mục tiêu huấn luyện KD cuối cùng là tổng có trọng số của các thành phần KL và PL:

LKD=αKL LKL+αPL LPL (6)

trong đó αKL và αPL là trọng số vô hướng cho các thành phần mất mát KL và PL tương ứng. Theo (Shleifer & Rush, 2020), chúng tôi đặt αKL= 0.8 và αPL= 1.0.

4.2 LỰA CHỌN NHÃN GIẢ : NGƯỠNG WER
Các nhãn giả được sinh tạo bởi mô hình Whisper có thể có lỗi phiên âm và ảo giác (Bain et al., 2023; Zhang et al., 2023). Để đảm bảo chúng tôi chỉ huấn luyện trên các nhãn giả chính xác, chúng tôi đề xuất một heuristic đơn giản để lọc dữ liệu huấn luyện được gán nhãn giả của chúng tôi. Đối với mỗi mẫu huấn luyện, chúng tôi chuẩn hóa các nhãn thật y1:N và các nhãn giả được sinh tạo bởi Whisper ŷ1:N′ sử dụng bộ chuẩn hóa tiếng Anh Whisper (Radford et al., 2022). Chúng tôi tính toán tỷ lệ lỗi từ (WER) giữa nhãn thật được chuẩn hóa và nhãn giả được chuẩn hóa, và loại bỏ bất kỳ mẫu nào vượt quá ngưỡng WER cho trước λ:

WER (norm (y1:N),norm (ŷ1:N′))> λ (7)

Chúng tôi điều chỉnh giá trị của λ trên các tập xác thực của chúng tôi và chứng minh trong Phần 9.1 rằng phương pháp lọc đơn giản này cải thiện chất lượng phiên âm và hiệu suất mô hình hạ nguồn.

--- TRANG 5 ---
5 PHIÊN ÂM DẠNG DÀI THEO CHUNK
Các mô hình Whisper có trường tiếp nhận cố định tương ứng với 30 giây âm thanh đầu vào và không thể xử lý các đầu vào âm thanh dài hơn cùng một lúc. Hầu hết các bộ dữ liệu học thuật bao gồm các phát âm ngắn dưới 30 giây, do đó điều này không phải là vấn đề. Tuy nhiên, các ứng dụng thực tế như phiên âm cuộc họp thường yêu cầu phiên âm các tệp âm thanh dài nhiều phút hoặc nhiều giờ.

Bài báo Whisper gốc trình bày một thuật toán phiên âm dạng dài tuần tự phiên âm các đoạn âm thanh 30 giây và dịch chuyển cửa sổ trượt theo các dấu thời gian được dự đoán bởi mô hình. Thuật toán tự hồi quy này yêu cầu cả tìm kiếm chùm và dự phòng nhiệt độ để đảm bảo phiên âm dạng dài chính xác (Radford et al., 2022).

Chúng tôi sử dụng một chiến lược thay thế, lần đầu được đề xuất bởi Patry (2022), trong đó tệp âm thanh dài được chia thành các đoạn nhỏ hơn với một sự chồng lấp nhỏ giữa các đoạn liền kề. Mô hình được chạy trên mỗi chunk và văn bản được suy luận được nối tại các bước nhảy bằng cách tìm chuỗi chung dài nhất giữa các phần chồng lấp. Bước nhảy này cho phép phiên âm chính xác qua các chunk mà không cần phải phiên âm chúng tuần tự. Chúng tôi quan sát rằng thuật toán này chỉ yêu cầu giải mã tham lam để phiên âm đáng tin cậy các tệp âm thanh dài. Hơn nữa, thuật toán này là bán tự hồi quy theo nghĩa là các chunk có thể được phiên âm theo bất kỳ thứ tự nào, miễn là các chunk liền kề sau đó được nối đúng tại ranh giới của chúng. Điều này cho phép các chunk được phiên âm song song thông qua batching. Trong thực tế, điều này mang lại cải thiện tốc độ suy luận lên đến 9 lần so với phiên âm tuần tự trên các tệp âm thanh dài. Trong công trình này, chúng tôi sử dụng thuật toán phiên âm dạng dài theo chunk khi đánh giá cả mô hình Whisper và Distil-Whisper.

6 GIẢI MÃ SUY ĐOÁN
Giải mã suy đoán (SD) (Leviathan et al., 2023) là một phương pháp để tăng tốc suy luận của các mô hình transformer tự hồi quy bằng cách sử dụng một mô hình trợ lý nhanh hơn. Mô hình trợ lý sinh tạo một chuỗi các token ứng cử viên, tất cả đều được xác minh bởi mô hình chính trong một lần forward pass duy nhất. Bằng cách sinh tạo với mô hình trợ lý nhanh hơn và chỉ thực hiện các forward pass xác thực với mô hình chính, quá trình giải mã được tăng tốc đáng kể. Token ứng cử viên thứ i từ mô hình trợ lý ŷi chỉ được giữ lại nếu tất cả các token ứng cử viên trước đó ŷ<i khớp với các token xác thực được dự đoán bởi mô hình chính. Do đó, giải mã suy đoán đảm bảo rằng đầu ra được sinh tạo khớp chính xác với chuỗi token sẽ được sinh tạo bởi mô hình chính, khiến nó trở thành sự thay thế tự nhiên cho các pipeline suy luận hiện có sử dụng mô hình chính.

DistilSpec (Zhou et al., 2023) đề xuất sử dụng mô hình học sinh được chưng cất kiến thức như trợ lý để canh chỉnh tốt hơn phân phối của mô hình trợ lý với mô hình chính. Chúng tôi áp dụng cùng nguyên tắc ở đây, sử dụng Distil-Whisper như trợ lý cho Whisper.

7 THIẾT LẬP THỰC NGHIỆM
7.1 DỮ LIỆU

Được truyền cảm hứng từ SpeechStew (Chan et al., 2021), chúng tôi tập hợp một kho dữ liệu huấn luyện ASR lớn để KD quy mô lớn thông qua sự kết hợp của chín bộ dữ liệu nhận dạng giọng nói có sẵn công khai. Một tổng quan về các bộ dữ liệu được trình bày trong Bảng 2, với chi tiết bổ sung trong Phụ lục A.1. Bộ dữ liệu kết hợp chứa 21.170 giờ dữ liệu giọng nói, bao gồm hơn 18.260 người nói và 10 lĩnh vực riêng biệt. Chúng tôi tải và tiền xử lý tất cả các bộ dữ liệu trong thư viện Hugging Face Datasets (Lhoest et al., 2021), streaming dữ liệu từ Hugging Face Hub.

Chúng tôi sinh tạo nhãn giả cho dữ liệu huấn luyện của chúng tôi với checkpoint Whisper large-v2, sử dụng triển khai Flax Whisper trong thư viện Hugging Face Transformers (Heek et al., 2020; Wolf et al., 2020). Chúng tôi thấy rằng có ít khác biệt trong hiệu suất hạ nguồn của mô hình được chưng cất sau khi gán nhãn giả sử dụng giải mã tham lam hoặc tìm kiếm chùm, và vì vậy chúng tôi đã chọn gán nhãn giả cho dữ liệu huấn luyện với giải mã tham lam vì tốc độ suy luận nhanh hơn của nó.

--- TRANG 6 ---
Bảng 2: Tóm tắt các bộ dữ liệu mã nguồn mở được sử dụng để huấn luyện. Đối với một số bộ dữ liệu, số lượng người nói không thể được lấy một cách đáng tin cậy. Chúng tôi ký hiệu những mục này là "không rõ".

Bộ dữ liệu | Kích thước / h | Người nói | Lĩnh vực | Giấy phép
People's Speech | 12,000 | không rõ | Chính phủ, phỏng vấn | CC-BY-SA-4.0
GigaSpeech | 2,500 | không rõ | Sách nói, podcast, YouTube | apache-2.0
Common Voice 13 | 2,400 | không rõ | Kể Wikipedia | CC0-1.0
Fisher | 1,960 | 11,900 | Cuộc trò chuyện điện thoại | LDC
LibriSpeech | 960 | 2,480 | Sách nói | CC-BY-4.0
VoxPopuli | 540 | 1,310 | Nghị viện châu Âu | CC0
TED-LIUM | 450 | 2,030 | Bài nói TED | CC-BY-NC-ND 3.0
SwitchBoard | 260 | 540 | Cuộc trò chuyện điện thoại | LDC
AMI | 100 | không rõ | Cuộc họp | CC-BY-4.0
Tổng cộng | 21,170 | 18,260+

Hình 1: Kiến trúc của mô hình Distil-Whisper. Encoder (hiển thị màu xanh lá cây) được sao chép hoàn toàn từ giáo viên sang học sinh và được đóng băng trong quá trình huấn luyện. Decoder của học sinh chỉ gồm hai lớp decoder, được khởi tạo từ lớp decoder đầu tiên và cuối cùng của giáo viên (hiển thị màu đỏ). Tất cả các lớp decoder khác của giáo viên đều bị loại bỏ. Mô hình được huấn luyện trên tổng có trọng số của các thành phần mất mát KL divergence và PL.

7.2 HUẤN LUYỆN
Chúng tôi khởi tạo các mô hình học sinh bằng cách sao chép toàn bộ encoder từ giáo viên và đóng băng nó trong quá trình huấn luyện. Chúng tôi chưng cất các checkpoint decoder 2 lớp từ các mô hình medium.en và large-v2 bằng cách sao chép lớp decoder đầu tiên và cuối cùng, mà chúng tôi gọi là distil-medium.en và distil-large-v2 tương ứng. Chi tiết kích thước của các mô hình được chưng cất được hiển thị trong Bảng 3, với kiến trúc và mục tiêu huấn luyện được tóm tắt trong Hình 1.

Chúng tôi huấn luyện với kích thước batch 256 trong tổng cộng 80.000 bước tối ưu hóa, tương đương với tám epoch huấn luyện. Vì chúng tôi chỉ huấn luyện trong tám epoch, rủi ro over-fitting là thấp, và vì vậy chúng tôi không sử dụng bất kỳ kỹ thuật tăng cường dữ liệu hoặc chính quy hóa nào. Thay vào đó, chúng tôi dựa vào sự đa dạng của bộ dữ liệu để đảm bảo tổng quát hóa và bền vững của mô hình, cùng tiền đề được sử dụng trong việc huấn luyện mô hình Whisper gốc (Radford et al., 2022). Tham khảo Phụ lục B.1 để biết chi tiết đầy đủ về thiết lập huấn luyện của chúng tôi.

--- TRANG 7 ---
Bảng 3: Chi tiết kích thước của các checkpoint Distil-Whisper.

Mô hình | Lớp Enc. | Lớp Dec. | Chiều rộng | Đầu | Tham số / M
distil-medium.en | 24 | 2 | 1024 | 16 | 394
distil-large-v2 | 32 | 2 | 1280 | 20 | 756

Bảng 4: Tóm tắt các bộ dữ liệu OOD được sử dụng để đánh giá dạng ngắn và dạng dài.

Bộ dữ liệu | Kích thước / h | Người nói | Lĩnh vực | Giấy phép
Dạng ngắn
CHiME-4 | 7 | 87 | Phát sóng tin tức | LDC
Earnings-22 | 115 | không rõ | Cuộc họp tài chính | CC-BY-SA-4.0
FLEURS | 2 | 3 | Kể Wikipedia | CC-BY-4.0
SPGISpeech | 100 | không rõ | Cuộc họp tài chính | User Agreement
Dạng dài
Earnings-21 | 39 | không rõ | Cuộc họp tài chính | CC-BY-SA-4.0
Earnings-22 | 115 | không rõ | Cuộc họp tài chính | CC-BY-SA-4.0
Meanwhile | 1 | 1 | Chương trình TV | User Agreement
Rev 16 | 16 | 16 | không rõ | Podcast | CC-BY-4.0

7.3 ĐÁNH GIÁ DẠNG NGẮN
Mục tiêu của Distil-Whisper là nén mô hình Whisper gốc thành một biến thể nhỏ hơn, nhanh hơn của mô hình mà vẫn giữ được độ bền vững đối với các điều kiện âm thanh khác nhau (người nói, phong cách nói và lĩnh vực). Để khảo sát khả năng này, chúng tôi sử dụng một bộ sưu tập rộng các bộ dữ liệu nhận dạng giọng nói để kiểm tra xem Distil-Whisper có thể tổng quát hóa hiệu quả qua các bộ dữ liệu và lĩnh vực hay không.

Chúng tôi đánh giá mô hình Distil-Whisper trên tổng cộng 15 bộ dữ liệu dạng ngắn. 11 bộ dữ liệu đầu tiên trong số này là các split test tương ứng cho dữ liệu huấn luyện được sử dụng để chưng cất mô hình. Các split test này nằm trong phân phối (ID) với dữ liệu huấn luyện. Bốn bộ dữ liệu còn lại chỉ được sử dụng như tập test, nơi Distil-Whisper được đánh giá trong thiết lập zero-shot, nghĩa là không sử dụng dữ liệu huấn luyện tương ứng, do đó đo lường khả năng tổng quát hóa của mô hình đối với các bộ dữ liệu ngoài phân phối (OOD). Một tổng quan về các bộ dữ liệu đánh giá OOD được trình bày trong Bảng 4. Chi tiết đầy đủ về các bộ dữ liệu đánh giá được cung cấp trong Phụ lục A.2.

Chúng tôi kiểm tra cả độ bền vững tổng thể, tức là hiệu suất trung bình trên tất cả các bộ dữ liệu, và độ bền vững hiệu quả (Taori et al., 2020), đo lường sự khác biệt trong hiệu suất dự kiến giữa một bộ dữ liệu tham chiếu là ID và một hoặc nhiều bộ dữ liệu là OOD. Một mô hình với độ bền vững hiệu quả cao hoạt động tốt hơn trên các bộ dữ liệu OOD như một hàm của hiệu suất trên bộ dữ liệu tham chiếu. Một mô hình với độ bền vững hiệu quả lý tưởng thực hiện tốt như nhau trên tất cả các bộ dữ liệu. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng GigaSpeech (Chen et al., 2021) như bộ dữ liệu tham chiếu, do thực tế rằng nó chứa dữ liệu được thu thập từ web từ sách nói, podcast và video YouTube, và do đó ID với cả dữ liệu huấn luyện Whisper được huấn luyện trước và tập huấn luyện Whisper được chưng cất.

Chúng tôi đánh giá độ bền vững nhiễu của các mô hình Distil-Whisper, các mô hình Whisper gốc và tám mô hình được huấn luyện trên LibriSpeech khác bằng cách đo WER trên bộ dữ liệu LibriSpeech test-clean với lượng nhiễu tăng dần được áp dụng cho âm thanh đầu vào. Bộ dữ liệu LibriSpeech là lựa chọn lý tưởng vì nó có tỷ lệ tín hiệu trên nhiễu (SNR) cao, và do đó cho phép đánh giá trên một phạm vi SNR lớn khi lượng nhiễu tăng lên. Chúng tôi thêm nhiễu trắng hoặc nhiễu quán bar từ Audio Degradation Toolbox (Mauch & Ewert, 2013). Nhiễu quán bar mô phỏng một môi trường nhiễu tự nhiên, với âm thanh xung quanh và các cuộc trò chuyện không thể phân biệt đặc trưng của nhà hàng hoặc quán bar bận rộn. Mức độ nhiễu cộng thêm được xác định dựa trên công suất tín hiệu của các thể hiện riêng lẻ và tương ứng với một SNR xác định.

--- TRANG 8 ---
Bảng 5: Distil-Whisper giữ lại hiệu suất WER của mô hình Whisper nhưng với tốc độ suy luận nhanh hơn. Kết quả WER trung bình trên bốn tập kiểm tra dạng ngắn OOD và bốn tập kiểm tra dạng dài OOD. Độ trễ tương đối là thời gian suy luận tương đối so với checkpoint large-v2. Đối với đánh giá dạng ngắn, kích thước batch được đặt là 1. Đối với đánh giá dạng dài, thuật toán phiên âm dạng dài theo chunk được sử dụng với kích thước batch 16.

Mô hình | Tham số / M | Dạng ngắn | | Dạng dài | 
 | | Độ trễ tương đối | WER trung bình | Độ trễ tương đối | WER trung bình
tiny.en | 39 | 6.1 | 18.9 | 5.4 | 18.9
base.en | 74 | 4.9 | 14.3 | 4.3 | 15.7
small.en | 244 | 2.6 | 10.8 | 2.2 | 14.7
medium.en | 769 | 1.4 | 9.5 | 1.3 | 12.3
large-v2 | 1550 | 1.0 | 9.1 | 1.0 | 11.7
distil-medium.en | 394 | 6.8 | 11.1 | 8.5 | 12.4
distil-large-v2 | 756 | 5.8 | 10.1 | 5.8 | 11.6

7.4 ĐÁNH GIÁ DẠNG DÀI
Chúng tôi đánh giá hiệu suất phiên âm dạng dài của mô hình Distil-Whisper trên bốn bộ dữ liệu OOD bao gồm các độ dài và điều kiện âm thanh khác nhau, để bao phủ phân phối dữ liệu rộng nhất có thể. Một tổng quan về các bộ dữ liệu dạng dài được trình bày trong Bảng 4. Chi tiết đầy đủ về các bộ dữ liệu dạng dài được cung cấp trong Phụ lục A.3.

Mô hình Whisper thể hiện khuynh hướng ảo giác, đặc trưng bởi việc sinh tạo lặp lại các chuỗi giống hệt nhau, hoặc dự đoán các đoạn văn bản không được nói trong đầu vào âm thanh (Bain et al., 2023; Zhang et al., 2023). Những lỗi ảo giác này phổ biến nhất trong phiên âm âm thanh dạng dài, đặc biệt khi âm thanh chứa lượng lớn khoảng lặng giữa các phát âm được nói. Để định lượng mức độ lặp lại và ảo giác trong các phiên âm được dự đoán, chúng tôi đo số lượng bản sao từ 5-gram lặp lại (5-Dup.) và tỷ lệ lỗi chèn (IER) trên bốn bộ dữ liệu dạng dài OOD. Chúng tôi cũng báo cáo tỷ lệ lỗi thay thế (SER) và tỷ lệ lỗi xóa (DER) để định lượng tần suất thay thế và xóa trong các phiên âm.

8 KẾT QUẢ
8.1 ĐÁNH GIÁ DẠNG NGẮN

Bảng 5 báo cáo điểm WER trung bình trên bốn tập kiểm tra dạng ngắn OOD cho các checkpoint Whisper và Distil-Whisper. Để phân tích chi tiết kết quả trên từng bộ dữ liệu, tham khảo Phụ lục C. Trong hai mô hình được chưng cất, mô hình distil-large-v2 đạt được WER trung bình tổng thể thấp nhất là 10.1%. Nó cao hơn baseline large-v2 một điểm phần trăm, với tốc độ suy luận nhanh hơn 5.8 lần và ít hơn một nửa số tham số. Tốc độ suy luận tương đương với checkpoint tiny.en Whisper, nhưng với lợi thế WER 8.8%. Mô hình distil-medium.en trung bình cao hơn mô hình large-v2 2.0% WER, với suy luận nhanh hơn 6.8 lần và nén mô hình 75%. Những phát hiện này nổi bật rằng Distil-Whisper giữ lại độ bền vững tổng thể của mô hình Whisper, với hiệu suất WER tương đương được tính trung bình trên nhiều bộ dữ liệu OOD, nhưng với tốc độ suy luận nhanh hơn đáng kể và số lượng tham số giảm.

Bảng 6 so sánh độ bền vững hiệu quả của large-v2 với distil-large-v2. Các mô hình có hiệu suất rất gần nhau trên phân phối tham chiếu, thực hiện trong vòng 2% WER tương đối. Mô hình được chưng cất cải thiện so với baseline được huấn luyện trước cho bộ dữ liệu SPGISpeech 12.8% tương đối, nhưng thực hiện tệ hơn trên ba bộ dữ liệu OOD khác. So với mô hình giáo viên, mô hình được chưng cất đạt được tăng WER tổng thể 0.8% tuyệt đối (hoặc 10.7% tương đối). Khoảng cách hiệu suất hẹp cho thấy rằng Distil-Whisper có độ bền vững hiệu quả tương đương với mô hình Whisper gốc.

--- TRANG 9 ---
Bảng 6: Độ bền vững hiệu quả qua các bộ dữ liệu khác nhau. Kết quả WER cho một bộ dữ liệu tham chiếu ID và bốn bộ dữ liệu OOD. Tỷ lệ lỗi tương đối (RER) được hiển thị bên phải, đưa ra điểm độ bền vững hiệu quả theo từng bộ dữ liệu. Kết quả trung bình macro được hiển thị ở hàng cuối.

Bộ dữ liệu | large-v2 | distil-large-v2 | RER
GigaSpeech | 10.7 | 10.5 | -2.0
CHIME-4 | 11.8 | 14.0 | 18.4
Earnings-22 | 16.6 | 16.9 | 1.6
FLEURS | 4.2 | 6.3 | 48.2
SPGISpeech | 3.8 | 3.3 | -12.8
Trung bình | 9.4 | 10.2 | 10.7

Bảng 7: So sánh các thuật toán phiên âm dạng dài. Kết quả WER trung bình trên bốn tập kiểm tra dạng dài OOD cho các thuật toán dạng dài tuần tự và theo chunk. Độ trễ tương đối là thời gian suy luận tương đối so với mô hình large-v2 với giải mã dạng dài tuần tự. Kết quả phiên âm theo chunk được báo cáo sử dụng kích thước batch 16.

Mô hình | Thuật toán | Độ trễ tương đối | WER OOD trung bình
large-v2 | Tuần tự | 1.0 | 10.4
large-v2 | Theo chunk | 9.9 | 11.7
distil-large-v2 | Theo chunk | 57.5 | 11.6

8.2 ĐÁNH GIÁ DẠNG DÀI
Chúng tôi so sánh hiệu suất phiên âm dạng dài của Distil-Whisper với các mô hình Whisper được huấn luyện trước trên bốn tập kiểm tra dạng dài OOD. Bảng 5 báo cáo độ trễ tương đối cho kích thước batch 16, cũng như WER trung bình macro. Điểm WER theo từng bộ dữ liệu được cung cấp trong Phụ lục C.

Kết quả cho thấy rằng distil-large-v2 vượt trội hoặc bằng large-v2 trên bốn trong năm tập kiểm tra, với WER trung bình thấp hơn 0.1% với tốc độ suy luận batch nhanh hơn 5.8 lần. Chỉ trên bộ dữ liệu Meanwhile mà mô hình Distil-Whisper thực hiện tệ hơn, bộ dữ liệu này chứa các bản ghi âm từ một người nói duy nhất với tần suất cao của các từ không phổ biến.

Bảng 7 so sánh hiệu suất của thuật toán tuần tự dạng dài Whisper với thuật toán theo chunk Distil-Whisper. Mô hình large-v2 với thuật toán theo chunk mang lại tốc độ tăng 9.9 lần so với thuật toán tuần tự, với tăng 1.3% WER OOD trung bình. Điều này chứng minh lợi ích tốc độ suy luận đạt được thông qua batching. Sử dụng mô hình được chưng cất kết hợp với thuật toán theo chunk cung cấp cải thiện thêm: mô hình distil-large-v2 nhanh hơn 57.5 lần so với triển khai baseline large-v2, trong khi thực hiện trong vòng 1.2% WER.

8.3 BỀN VỮNG TRƯỚC NHIỄU CỘNG THÊM
Hình 2 cho thấy hiệu suất WER giảm như thế nào khi cường độ nhiễu cộng thêm tăng lên trên bộ dữ liệu LibriSpeech test-clean. Trong 14 mô hình chúng tôi so sánh, tám mô hình được huấn luyện trước và/hoặc tinh chỉnh trên LibriSpeech. Có nhiều mô hình vượt trội hơn các mô hình Distil-Whisper dưới nhiễu thấp (40 dB SNR), bao gồm các checkpoint Whisper và các mô hình được huấn luyện trên LibriSpeech. Tuy nhiên, khi nhiễu trở nên mạnh hơn, WER của các checkpoint Distil-Whisper suy giảm ít nghiêm trọng hơn so với các mô hình được huấn luyện trên LibriSpeech và tiếp cận các mô hình của Whisper, đặc biệt khi nhiễu quán bar cộng thêm giảm dưới 10 dB. Vì chúng tôi sao chép toàn bộ encoder và đóng băng nó trong quá trình huấn luyện, các mô hình học sinh và giáo viên chia sẻ cùng encoder. Do đó, chúng thể hiện độ bền vững tương tự trước nhiễu, đặc biệt dưới các dịch chuyển phân phối tự nhiên hơn như nhiễu quán bar.

--- TRANG 10 ---
Hình 2: Ảnh hưởng của nhiễu đến hiệu suất WER. WER trên LibriSpeech test-clean như một hàm của SNR dưới nhiễu trắng cộng thêm (trái) và nhiễu quán bar (phải).

8.4 BỀN VỮNG TRƯỚC ẢO GIÁC
Bảng 8 báo cáo số lượng bản sao từ 5-gram lặp lại (5-Dup.) và tỷ lệ lỗi chèn (IER) trung bình trên bốn tập kiểm tra dạng dài. Ngoài các mô hình Whisper và Distil-Whisper, chúng tôi báo cáo kết quả cho mô hình chính thức Wav2Vec 2.0 large được tinh chỉnh trên 960 giờ dữ liệu LibriSpeech. Checkpoint này cung cấp so sánh giữa kiến trúc Whisper Seq2Seq và một kiến trúc dựa trên CTC (Graves et al., 2006). Một mô hình CTC nên ít bị lỗi ảo giác hơn do nó là kiến trúc chỉ có encoder với một đầu tuyến tính trên từ vựng.

Mô hình distil-large-v2 có ít lỗi lặp lại hơn 1.3 lần so với Whisper large-v2. Nó cũng đạt được IER trung bình thấp nhất, cải thiện so với Whisper 1.2% tuyệt đối. Điều này cho thấy rằng mức độ ảo giác được cải thiện trong Distil-Whisper so với mô hình Whisper gốc. Tỷ lệ lỗi xóa (DER) trung bình tương đương cho cả large-v2 và distil-large-v2, thực hiện trong vòng 0.3% DER. Tuy nhiên, tỷ lệ lỗi thay thế (SER) cao hơn 1.4% cho distil-large-v2, cho thấy rằng các mô hình được chưng cất chịu nhiều lỗi thay thế hơn. Nhìn chung, việc giảm IER vượt trội hơn việc tăng SER, và Distil-Whisper trả về WER thấp nhất trong tất cả các mô hình. Trong khi mô hình wav2vec 2.0 kém hiệu suất trong điểm WER trung bình, chúng tôi thấy rằng nó ít bị lỗi lặp lại hơn rất nhiều so với cả Whisper và Distil-Whisper. Cần có công trình thêm để giảm lỗi lặp lại trong các mô hình ASR Seq2Seq.

8.5 GIẢI MÃ SUY ĐOÁN
Bảng 9 báo cáo độ trễ tương đối của các mô hình medium.en và large-v2 với giải mã suy đoán. Chúng tôi so sánh độ trễ sử dụng các checkpoint Whisper nhỏ nhất hoặc các mô hình Distil-Whisper làm trợ lý. Vì các đầu ra của các mô hình Whisper gốc được thu được chính xác, chúng tôi chỉ báo cáo độ trễ tương đối. Các mô hình học sinh được chưng cất được khởi tạo bằng cách sao chép và đóng băng toàn bộ encoder từ giáo viên, có nghĩa là chúng sử dụng chính xác cùng encoder với các mô hình Whisper chính. Do đó, khi chạy SD, encoder có thể được chia sẻ giữa các mô hình chính và trợ lý, và chỉ các lớp decoder được chưng cất phải được tải thêm vào mô hình chính. Điều này dẫn đến chỉ tăng 8% số lượng tham số khi sử dụng distil-large-v2 làm trợ lý cho large-v2.

--- TRANG 11 ---
Bảng 8: Tỷ lệ lỗi dạng dài chi tiết. Số lượng bản sao từ 5-gram lặp lại (5-Dup.) trung bình và tỷ lệ lỗi chèn (IER) trên bốn tập kiểm tra dạng dài. Cũng được hiển thị là tỷ lệ lỗi thay thế (SER), tỷ lệ lỗi xóa (DER) và tỷ lệ lỗi từ (WER) trung bình.

Mô hình | 5-Dup. | IER | SER | DER | WER
wav2vec2-large-960h | 7971 | 4.8 | 18.9 | 4.6 | 28.3
tiny.en | 23313 | 5.1 | 8.9 | 4.8 | 18.9
base.en | 22719 | 4.3 | 6.6 | 4.8 | 15.7
small.en | 26377 | 3.3 | 5.0 | 6.5 | 14.7
medium.en | 23549 | 3.5 | 4.2 | 4.6 | 12.3
large-v2 | 23792 | 3.3 | 3.9 | 4.5 | 11.7
distil-medium.en | 18918 | 2.5 | 5.6 | 4.4 | 12.4
distil-large-v2 | 18503 | 2.1 | 5.3 | 4.2 | 11.6

Bảng 9: Tác động của giải mã suy đoán. Độ trễ tương đối của medium.en và large-v2 sử dụng các mô hình trợ lý Whisper và Distil-Whisper. Độ trễ tương đối được tính so với mô hình large-v2 không có giải mã suy đoán cho kích thước batch 1.

Mô hình | Tham số / M | Độ trễ tương đối
medium.en | 769 | 1.4
với tiny.en | 808 | 2.7
với distil-medium.en | 856 | 3.3
large-v2 | 1550 | 1.0
với tiny | 1589 | 2.1
với distil-large-v2 | 1669 | 2.0

Giải mã suy đoán với trợ lý distil-large-v2 mang lại cải thiện 2.0 lần tốc độ suy luận so với large-v2 đơn độc. Điều này tương đương với việc sử dụng mô hình tiny làm trợ lý. Đối với mô hình medium.en, sử dụng distil-medium.en làm trợ lý cung cấp tốc độ tăng 2.4 lần. Điều này lớn hơn so với việc sử dụng checkpoint tiny.en làm trợ lý, mà chỉ nhanh hơn 2.0 lần. Nhìn chung, giải mã suy đoán cung cấp tốc độ tăng đáng kể cho độ trễ trong khi đảm bảo toán học các đầu ra giống nhau, làm cho nó trở thành sự thay thế tự nhiên cho các pipeline Whisper hiện có.

9 PHÂN TÍCH
9.1 NGƯỠNG WER

Trong quá trình huấn luyện, chúng tôi lọc dữ liệu được gán nhãn giả nơi WER chuẩn hóa giữa nhãn giả được sinh tạo bởi Whisper và nhãn thật vượt quá ngưỡng cho trước λ. Để khảo sát ảnh hưởng của ngưỡng này đến hiệu suất của mô hình được chưng cất, chúng tôi huấn luyện một loạt các checkpoint distil-large-v2 trong 10.000 bước huấn luyện (hoặc hai epoch) trên một phạm vi giá trị ngưỡng. Bảng 10 hiển thị hiệu suất WER trung bình của các mô hình được huấn luyện. Đặt ngưỡng quá cao cho phép các phiên âm bị lỗi hoặc ảo giác vào tập huấn luyện. Đặt ngưỡng WER thấp chỉ giữ lại các nhãn giả được sinh tạo bởi Whisper chính xác nhất, nhưng cũng chỉ các mẫu dễ nhất (tức là những mẫu có WER rất thấp) và loại bỏ tỷ lệ lớn hơn của dữ liệu huấn luyện. Chúng tôi thấy rằng ngưỡng WER 10% cung cấp sự cân bằng tốt giữa những yếu tố đối lập này. Nếu chúng tôi huấn luyện lâu hơn, ảnh hưởng của việc sử dụng lượng dữ liệu huấn luyện cao hơn có thể trở nên rõ ràng hơn, do đó ủng hộ ngưỡng cao hơn. Sử dụng ngưỡng WER để lọc dữ liệu được gán nhãn giả có thể bù đắp cho độ chính xác phiên âm giảm của các nhãn được sinh tạo bởi Whisper được dự đoán với giải mã tham lam thay vì tìm kiếm chùm. Chúng tôi thấy rằng đây là một chiến lược hiệu quả để cải thiện hiệu suất của các hệ thống ASR Seq2Seq được huấn luyện trên dữ liệu được gán nhãn giả.

--- TRANG 12 ---
Bảng 10: Ngưỡng WER là một bộ lọc hiệu quả cho dữ liệu PL. WER trung bình của checkpoint distil-large-v2 trên 11 tập xác thực ID và ba tập xác thực OOD khi ngưỡng WER λ được giảm.

λ | Dữ liệu đã lọc / % | WER ID trung bình | WER OOD trung bình | WER trung bình
100 | 0.0 | 14.8 | 9.1 | 13.4
80 | 6.2 | 13.5 | 7.5 | 12.1
40 | 11.9 | 13.3 | 7.4 | 12.0
20 | 24.2 | 13.1 | 7.3 | 11.7
15 | 32.0 | 13.0 | 7.4 | 11.7
10 | 45.4 | 12.6 | 7.4 | 11.4
5 | 60.3 | 12.6 | 7.3 | 11.4

Bảng 11: Hiệu suất cải thiện với việc tăng kích thước bộ dữ liệu. WER trung bình của checkpoint distil-large-v2 trên 11 tập xác thực ID và ba tập xác thực OOD khi lượng dữ liệu huấn luyện tăng lên.

Kích thước / h | Tỷ lệ / % | WER ID trung bình | WER OOD trung bình | WER trung bình
435 | 2 | 17.1 | 13.8 | 16.4
871 | 4 | 15.1 | 10.5 | 14.0
1,742 | 8 | 14.0 | 9.2 | 12.9
3,483 | 16 | 13.3 | 7.8 | 12.0
6,966 | 32 | 13.0 | 7.7 | 11.8
13,933 | 64 | 12.8 | 7.4 | 11.6
21,770 | 100 | 12.6 | 7.4 | 11.4

9.2 MỞ RỘNG BỘ DỮ LIỆU
Để nghiên cứu lượng dữ liệu cần thiết để chưng cất Whisper, chúng tôi huấn luyện một loạt các mô hình distil-large-v2 trên các phiên bản được lấy mẫu phụ của bộ dữ liệu. Bảng 11 hiển thị hiệu suất WER trung bình của mô hình distil-large-v2 cho từng tỷ lệ bộ dữ liệu. Tất cả việc tăng kích thước bộ dữ liệu đều dẫn đến hiệu suất cải thiện trên các tập xác thực ID. Trên các tập xác thực OOD, hiệu suất cải thiện nhanh chóng từ 435 đến 3.483 giờ, sau đó chậm lại đáng kể giữa 3.483 giờ và 13.933 giờ. Sử dụng toàn bộ bộ dữ liệu 21.770 giờ – tăng thêm 1.6 lần kích thước – không dẫn đến cải thiện thêm cho WER OOD. Điều này cho thấy rằng có lợi ích giảm dần khi tăng lượng dữ liệu huấn luyện được gán nhãn giả trên 13.933 giờ, hay 2% dữ liệu huấn luyện trước Whisper.

9.3 KÍCH THƯỚC MÔ HÌNH
Bảng 12 hiển thị hiệu suất độ trễ và WER cho các mô hình decoder 16, 8, 4 và 2 lớp. Mô hình decoder 16 lớp phần lớn giữ lại hiệu suất WER của mô hình giáo viên 32 lớp, thực hiện trong vòng 0.1% WER OOD với cải thiện độ trễ 1.9 lần. Khi số lượng lớp decoder giảm thêm, WER OOD trung bình tăng lên đáng kể hơn. Sự tăng tối đa là 2.1% cho mô hình decoder 2 lớp, tuy nhiên cấu hình này nhanh hơn 5.8 lần so với mô hình giáo viên. Những kết quả này nổi bật sự cân bằng giữa độ trễ và hiệu suất khi số lượng lớp decoder giảm.

Trong việc chưng cất chỉ decoder, việc giảm tham số bị giới hạn ở 51%. Để giảm thêm số lượng tham số, chúng tôi có thể chưng cất đồng thời encoder và decoder. Bảng 12 so sánh hiệu suất của mô hình học sinh encoder 32 lớp đầy đủ với mô hình giảm 16 lớp, cả hai đều có decoder 2 lớp. Khi encoder giảm xuống 16 lớp, số lượng tham số giảm thêm 19%. Tuy nhiên, hiệu suất WER OOD suy giảm 3.1% tuyệt đối. Điều này cho thấy rằng có encoder sâu là tối quan trọng để duy trì hiệu suất WER mạnh mẽ của các mô hình ASR Seq2Seq được chưng cất.

--- TRANG 13 ---
Bảng 12: Cân bằng giữa độ trễ và hiệu suất WER với kích thước mô hình giảm. WER trung bình trên 11 tập xác thực ID và ba tập xác thực OOD khi số lượng lớp encoder và decoder trong checkpoint large-v2 giảm. Hàng đầu tiên tương ứng với checkpoint giáo viên large-v2. Các hàng tiếp theo tương ứng với các mô hình được chưng cất, được huấn luyện trong 10.000 bước tối ưu hóa (hoặc hai epoch).

Enc | Dec | Tham số / M | Độ trễ tương đối | WER ID | WER OOD | WER trung bình
32 | 32 | 1543 | 1.0 | 12.8 | 5.3 | 11.1
32 | 16 | 1124 | 1.9 | 11.3 | 5.4 | 9.9
32 | 8 | 914 | 3.0 | 11.6 | 6.0 | 10.3
32 | 4 | 809 | 4.3 | 12.0 | 6.5 | 10.8
32 | 2 | 756 | 5.8 | 12.6 | 7.4 | 11.4
16 | 2 | 441 | 8.6 | 16.0 | 10.5 | 14.7

10 KẾT LUẬN
Chúng tôi giới thiệu Distil-Whisper, một phiên bản chưng cất của Whisper nhỏ hơn 49%, nhanh hơn 5.8 lần và trong vòng 1% hiệu suất WER trên âm thanh dạng ngắn OOD. Trên âm thanh dạng dài OOD, Distil-Whisper vượt trội hơn Whisper, do ít ảo giác và lặp lại hơn. Chúng tôi cho thấy rằng gán nhãn giả quy mô lớn là một chiến lược hiệu quả để chưng cất các mô hình ASR, đặc biệt khi kết hợp với bộ lọc ngưỡng WER của chúng tôi. Chúng tôi thêm chứng minh rằng Distil-Whisper có thể được sử dụng kết hợp với Whisper sử dụng giải mã suy đoán để thu được các đầu ra giống như mô hình gốc với suy luận nhanh hơn 2 lần.

11 LỜI CẢM ƠN
Chúng tôi cảm ơn Nicolas Patry và Arthur Zucker vì việc triển khai thuật toán phiên âm dạng dài theo chunk trong Transformers và João Gante vì việc triển khai giải mã suy đoán. Chúng tôi biết ơn sự hỗ trợ của chương trình Google TPU Research Cloud (TRC) trong việc cung cấp tài nguyên Cloud TPU cho nghiên cứu này.

[Phần tài liệu tham khảo và phụ lục được tiếp tục với cùng định dạng...]

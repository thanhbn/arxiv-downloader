# 2210.01213.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-distillation/2210.01213.pdf
# Kích thước tệp: 15875853 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023
CHƯNG CẤT TÍCH CỰC BỀN VỮNG
Cenk Baykal, Khoa Trinh, Fotis Iliopoulos, Gaurav Menghani, Erik Vee
Google Research
{baykalc,khoatrinh,fotisi,gmenghani,erikvee}@google.com
TÓM TẮT
Chưng cất kiến thức từ một mô hình giáo viên lớn sang một mô hình nhẹ là một phương pháp rộng rãi thành công để tạo ra các mô hình nhỏ gọn, mạnh mẽ trong bối cảnh học bán giám sát nơi có sẵn một lượng hạn chế dữ liệu được gán nhãn. Tuy nhiên, trong các ứng dụng quy mô lớn, giáo viên có xu hướng cung cấp một số lượng lớn các nhãn mềm không chính xác làm ảnh hưởng đến hiệu suất học sinh. Kích thước khổng lồ của giáo viên cũng hạn chế số lượng nhãn mềm có thể được truy vấn do chi phí tính toán và/hoặc tài chính cấm đoán. Khó khăn trong việc đạt được đồng thời hiệu quả (tức là giảm thiểu các truy vấn nhãn mềm) và tính bền vững (tức là tránh sự không chính xác của học sinh do nhãn không chính xác) làm tổn hại đến việc ứng dụng rộng rãi chưng cất kiến thức cho nhiều tác vụ hiện đại. Trong bài báo này, chúng tôi trình bày một phương pháp không tham số với các đảm bảo có thể chứng minh để truy vấn các nhãn mềm của các điểm đồng thời có tính thông tin và được gán nhãn chính xác bởi giáo viên. Cốt lõi của công việc chúng tôi nằm ở việc xây dựng một công thức lý thuyết trò chơi mà xem xét rõ ràng sự đánh đổi cố hữu giữa tính thông tin và tính chính xác của các trường hợp đầu vào. Chúng tôi thiết lập các ràng buộc về hiệu suất dự kiến của phương pháp chúng tôi ngay cả trong các trường hợp chưng cất tồi tệ nhất. Chúng tôi trình bày các đánh giá thực nghiệm trên các chuẩn mực phổ biến chứng minh hiệu suất chưng cất được cải thiện do công việc chúng tôi mang lại so với các phương pháp học tích cực và chưng cất tích cực tiên tiến.

1 GIỚI THIỆU
Các mô hình mạng thần kinh sâu đã thành công chưa từng có trong nhiều lĩnh vực ứng dụng có tác động cao như Xử lý Ngôn ngữ Tự nhiên (Ramesh et al., 2021; Brown et al., 2020) và Thị giác Máy tính (Ramesh et al., 2021; Niemeyer & Geiger, 2021). Tuy nhiên, điều này đi kèm với chi phí sử dụng các bộ dữ liệu được gán nhãn ngày càng lớn và các mô hình mạng có dung lượng cao có xu hướng chứa hàng tỷ tham số (Devlin et al., 2018). Những mô hình này thường có chi phí cấm đoán để sử dụng cho suy luận và đòi hỏi hàng triệu đô la chi phí tính toán để huấn luyện (Patterson et al., 2021). Kích thước khổng lồ của chúng cũng ngăn cản việc sử dụng trong các ứng dụng quan trọng về thời gian nơi phải đưa ra quyết định nhanh chóng, ví dụ như lái xe tự động, và triển khai trên các nền tảng hạn chế tài nguyên, ví dụ như điện thoại di động và các hệ thống nhúng nhỏ (Baykal et al., 2022). Để giảm bớt những vấn đề này, một lượng lớn công việc gần đây trong học máy đã tập trung vào các phương pháp tạo ra các mô hình mạng nhỏ gọn, mạnh mẽ mà không cần các bộ dữ liệu được gán nhãn khổng lồ.

Chưng cất Kiến thức (KD) (Bucilu ˇa et al., 2006; Hinton et al., 2015; Gou et al., 2021; Beyer et al., 2021) là một phương pháp mục đích tổng quát đã cho thấy triển vọng trong việc tạo ra các mô hình nhẹ mạnh mẽ ngay cả khi có sẵn một lượng hạn chế dữ liệu được gán nhãn (Chen et al., 2020). Ý tưởng chính là sử dụng một mô hình giáo viên lớn được huấn luyện trên các ví dụ được gán nhãn để huấn luyện một mô hình học sinh nhỏ gọn sao cho các dự đoán của nó bắt chước những dự đoán của giáo viên. Tiền đề là ngay cả một học sinh nhỏ cũng đủ khả năng để đại diện cho các giải pháp phức tạp, mặc dù nó có thể thiếu các thiên kiến quy nạp để học thích hợp các biểu diễn từ dữ liệu hạn chế một mình (Stanton et al., 2021; Menon et al., 2020). Trong thực tế, KD thường dẫn đến các mô hình dự đoán đáng kể hơn so với khả năng khác khi huấn luyện riêng lẻ (Chen et al., 2020; Xie et al., 2020; Gou et al., 2021; Cho & Hariharan, 2019).

Chưng cất Kiến thức gần đây đã được sử dụng để có được kết quả tiên tiến trong bối cảnh bán giám sát nơi có sẵn một số nhỏ các ví dụ được gán nhãn và một số lượng lớn các ví dụ không được gán nhãn (Chen et al., 2020; Pham et al., 2021; Xie et al., 2020). KD bán giám sát đòi hỏi huấn luyện một mô hình giáo viên trên tập được gán nhãn và sử dụng các nhãn mềm của nó trên dữ liệu không được gán nhãn để huấn luyện học sinh. Giáo viên thường là một mô hình được huấn luyện trước và cũng có thể là một mô hình lớn chung như GPT-3 (Brown et al., 2020)

1arXiv:2210.01213v2  [cs.LG]  4 Feb 2023

--- TRANG 2 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023
hoặc PaLM (Chowdhery et al., 2022). Tiền đề là một mô hình giáo viên lớn có thể trích xuất kiến thức một cách thích hợp hơn và học từ một bộ dữ liệu được gán nhãn, sau đó có thể được chưng cất vào một học sinh nhỏ.

Mặc dù thành công rộng rãi, KD nói chung phải chịu nhiều mức độ khác nhau của thiên kiến xác nhận và thiếu hiệu quả trong các ứng dụng hiện đại cho học bán giám sát. Thiên kiến xác nhận (Pham et al., 2021; Liu & Tan, 2021; Arazo et al., 2020; Beyer et al., 2021) là hiện tượng mà học sinh thể hiện hiệu suất kém do huấn luyện trên các nhãn mềm của giáo viên ồn ào hoặc không chính xác. Ở đây, sự không chính xác đề cập đến sự không nhất quán giữa các dự đoán của giáo viên cho các đầu vào không được gán nhãn và các nhãn thực tế của chúng. Việc cung cấp cho học sinh các nhãn mềm không chính xác dẫn đến tăng độ tin cậy trong các dự đoán không chính xác, điều này do đó tạo ra một mô hình có xu hướng kháng cự các thay đổi mới và hoạt động kém tổng thể (Liu & Tan, 2021; Arazo et al., 2020). Đồng thời, các ứng dụng quy mô lớn thường đòi hỏi các dự đoán của giáo viên cho hàng tỷ điểm không được gán nhãn. Ví dụ, hãy xem xét việc chưng cất kiến thức từ GPT-3 để huấn luyện một mô hình học sinh mạnh mẽ. Tính đến thời điểm viết bài này, OpenAI tính phí 6c cho mỗi 1k dự đoán token (OpenAI, 2022). Giả sử chỉ 1M ví dụ để gán nhãn và trung bình 100 token cho mỗi ví dụ dẫn đến tổng chi phí $6M. Do đó, việc có được các nhãn mềm hữu ích nhất - tức là thông tin và chính xác - dựa trên ngân sách gán nhãn (các cuộc gọi API GPT-3) để có được mô hình học sinh mạnh mẽ nhất cho ứng dụng mục tiêu là rất mong muốn.

Do đó, việc phát triển các phương pháp KD vừa hiệu quả về truy vấn vừa bền vững với sự không chính xác trong gán nhãn đã trở nên ngày càng quan trọng. Công việc trước đây trong lĩnh vực này bị hạn chế trong việc giải quyết hoặc hiệu quả chưng cất (Liang et al., 2022; Xu et al., 2020), bằng cách kết hợp mix-up (Zhang et al., 2017) và lấy mẫu dựa trên độ bất định (Roth & Small, 2006), hoặc tính bền vững (Pham et al., 2021; Liu & Tan, 2021; Arazo et al., 2020; Zheng et al., 2021; Zhang et al., 2020), thông qua các chiến lược huấn luyện và weighting thông minh, nhưng không phải cả hai mục tiêu này cùng một lúc. Trong bài báo này, chúng tôi trình bày một phương pháp đơn giản để thực hiện tìm một điểm ngọt ngào và cải thiện so với các kỹ thuật tiêu chuẩn. Liên quan đến điều này, đã có công việc trước đây trong học với nhiễu nhãn (xem Song et al. (2022) để khảo sát), tuy nhiên, những công việc này thường giả định rằng các nhãn ồn ào có sẵn (tức là không có thành phần học tích cực) hoặc áp đặt các giả định về loại nhiễu nhãn (Younesian et al., 2021). Ngược lại, chúng tôi giả định rằng nhiễu nhãn có thể hoàn toàn đối nghịch và chúng tôi không có quyền truy cập đầy đủ ngay cả vào các nhãn ồn ào.

Theo hiểu biết tốt nhất của chúng tôi, công việc này là đầu tiên xem xét vấn đề lấy mẫu quan trọng để đạt được đồng thời hiệu quả và tính bền vững trong chưng cất kiến thức. Để bắc cầu khoảng trống nghiên cứu này, chúng tôi trình bày một thuật toán hiệu quả với các đảm bảo có thể chứng minh để xác định các điểm không được gán nhãn với các nhãn mềm có xu hướng đồng thời có tính thông tin và chính xác. Phương pháp của chúng tôi không có tham số, không áp đặt giả định nào về bối cảnh vấn đề, và có thể được áp dụng rộng rãi cho bất kỳ kiến trúc mạng và bộ dữ liệu nào. Cốt lõi của nó nằm ở việc xây dựng một bài toán tối ưu hóa đồng thời nắm bắt các mục tiêu hiệu quả và tính bền vững theo cách thích hợp. Cụ thể, bài báo này đóng góp:

1. Một công thức vấn đề toán học nắm bắt mục tiêu chung của huấn luyện trên các nhãn mềm có tính thông tin được gán nhãn chính xác bởi giáo viên theo cách hiệu quả truy vấn
2. Một thuật toán thời gian gần tuyến tính, không tham số để giải quyết tối ưu nó
3. Kết quả thực nghiệm trên các bộ dữ liệu chuẩn và kiến trúc với các cấu hình khác nhau chứng minh hiệu quả được cải thiện của phương pháp chúng tôi so với tiên tiến
4. Các đánh giá thực nghiệm rộng rãi hỗ trợ khả năng áp dụng rộng rãi và tính bền vững của phương pháp chúng tôi đối với các tình huống khác nhau và các ràng buộc do người thực hành áp đặt.

2 PHÁT BIỂU VẤN ĐỀ

Chúng tôi xem xét bối cảnh phân loại bán giám sát nơi chúng tôi được cung cấp một tập được gán nhãn nhỏ XL - thường là hàng chục hoặc hàng trăm nghìn ví dụ - cùng với một tập không được gán nhãn lớn XU, thường có thứ tự hàng triệu hoặc hàng tỷ. Mục tiêu là tận dụng cả tập được gán nhãn và không được gán nhãn để huấn luyện một cách hiệu quả và đáng tin cậy một mô hình học sinh nhỏ gọn, mạnh mẽ. Để làm như vậy, chúng tôi sử dụng chưng cất kiến thức (Xie et al., 2020; Liang et al., 2020) nơi các điểm được gán nhãn được sử dụng để huấn luyện một mô hình giáo viên lớn hơn, (thường được huấn luyện trước) sau đó có thể được sử dụng để giáo dục một mô hình nhỏ (học sinh). Chúng tôi nhấn mạnh rằng giáo viên có thể là một mô hình được huấn luyện trước, tuy nhiên, nó không được huấn luyện trên tập không được gán nhãn XU. Quá trình chưng cất đòi hỏi sử dụng các nhãn mềm của giáo viên cho các điểm không được gán nhãn. Học sinh sau đó được huấn luyện trên những điểm được gán nhãn mềm này cùng với bộ dữ liệu được gán nhãn ban đầu. Insight chính là mô hình giáo viên lớn, được huấn luyện trước có thể học các biểu diễn một cách thích hợp hơn từ dữ liệu hạn chế, sau đó có thể được bắt chước bởi học sinh.

2

--- TRANG 3 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Một cách trang trọng hơn, chúng tôi được cung cấp hai tập đầu vào XL;XU được rút ra độc lập và ngẫu nhiên từ không gian đầu vào X⊆Rd. Chúng tôi giả định rằng chúng tôi có quyền truy cập vào các nhãn cứng YL∈{0,1}k cho các trường hợp trong XL, nhưng không có những nhãn trong XU và |XL|≪|XU|. Phù hợp với các ứng dụng ML hiện đại, chúng tôi giả định rằng một bộ dữ liệu xác thực của các điểm được gán nhãn có sẵn. Chúng tôi sẽ sử dụng một sự lạm dụng nhẹ trong ký hiệu và đề cập đến tập các điểm dữ liệu được gán nhãn là (XL,YL) để biểu thị tập các cặp (x,y) được gán nhãn. Chúng tôi giả định các ứng dụng quy mô lớn của KD nơi giáo viên cực kỳ lớn đến mức việc truy vấn nhãn mềm của giáo viên fteacher(x)∈[0,1]k cho một điểm không được gán nhãn x∈XU là tốn kém và việc gán nhãn mềm cho toàn bộ XU là không khả thi. Trong phần sau, chúng tôi giới thiệu và thúc đẩy chưng cất tích cực bền vững để thực hiện quá trình này một cách hiệu quả và đáng tin cậy.

2.1 CHƯNG CẤT TÍCH CỰC

Mục tiêu của chưng cất tích cực là truy vấn số lượng tối thiểu các nhãn mềm của giáo viên cho các điểm trong XU để huấn luyện một mô hình học sinh fstudent hiệu suất cao theo cách hiệu quả về tính toán và tài chính. Quá trình này được hiển thị trong Alg. 1. Ở đây, chúng tôi thực hiện T lần lặp chưng cất tích cực sau khi huấn luyện các mô hình học sinh và giáo viên trên tập huấn luyện P, ban đầu chỉ bao gồm tập các điểm được gán nhãn cứng. Trên Dòng 8 và xuyên suốt, f(x)∈[0,1]k biểu thị đầu ra softmax của một mô hình mạng thần kinh đối với đầu vào x. Tại mỗi lần lặp (Dòng 5-10, Alg. 1), chúng tôi sử dụng một thuật toán truy vấn cho trước, SELECT, để xác định b điểm không được gán nhãn hữu ích nhất để gán nhãn mềm bởi giáo viên dựa trên mô hình học sinh cập nhật nhất ft-1 (Dòng 6). Các điểm được chọn sau đó được gán nhãn mềm bởi giáo viên và thêm vào tập huấn luyện (mở rộng) P. Tiếp theo, học sinh được huấn luyện sử dụng Divergence Kullback-Leibler (KL) (Hinton et al., 2015) làm hàm mất mát trên tập huấn luyện P bao gồm cả các điểm được gán nhãn cứng (XL,YL) và những điểm được gán nhãn mềm tích lũy. Chúng tôi tuân theo quy ước tiêu chuẩn trong học tích cực (Ren et al., 2021) và chưng cất hiệu quả (Liang et al., 2020; Xu et al., 2020) và huấn luyện mô hình học sinh từ đầu trên Dòng 9.

Thuật toán 1 CHƯNG CẤT TÍCH CỰC
Đầu vào: một tập các điểm được gán nhãn (XL,YL), một tập các điểm không được gán nhãn XU, số điểm để gán nhãn mềm mỗi lần lặp b∈N+, và một thuật toán chọn SELECT(X,·,b) chọn một mẫu có kích thước b từ X
1: P←(XL,YL); {Tập huấn luyện cho đến nay; ban đầu chỉ các điểm được gán nhãn cứng}
2: fteacher←TRAIN(P,θrandom_teacher); {Huấn luyện giáo viên trên dữ liệu được gán nhãn bắt đầu từ khởi tạo ngẫu nhiên}
3: f0←TRAIN(P,θrandom_student); {Huấn luyện học sinh trên dữ liệu được gán nhãn bắt đầu từ khởi tạo ngẫu nhiên}
4: S←∅; {Tập các đầu vào đã được gán nhãn mềm}
5: for t∈{1,...,T} do
6:    St←SELECT(XU\S,ft-1,b) {Chọn b điểm để được gán nhãn mềm bởi giáo viên}
7:    S←S∪St {Thêm các điểm mới để chúng tôi không lấy mẫu chúng lại}
8:    P←P∪{(x,fteacher(x)):x∈St} {Gán nhãn mềm các điểm và thêm chúng vào tập huấn luyện}
9:    ft←TRAIN(P,θrandom_student) {Huấn luyện mạng với các điểm được gán nhãn mềm bổ sung từ đầu}
10: end for
11: return fT

Vấn đề chưng cất tích cực có liên quan sâu sắc đến vấn đề học tích cực, nơi mục tiêu là truy vấn các nhãn của chỉ những điểm có tính thông tin nhất để giảm thiểu chi phí gán nhãn. Để kết thúc này, các phương pháp trước đây trong KD hiệu quả (Xu et al., 2020; Liang et al., 2020) đã đề xuất các phương pháp lấy cảm hứng từ lấy mẫu dựa trên biên (Balcan et al., 2007; Roth & Small, 2006), một thuật toán học tích cực phổ biến và được sử dụng rộng rãi (Ren et al., 2021). Lấy mẫu dựa trên biên là một ví dụ của lấy mẫu dựa trên độ bất định, các ví dụ khác là chọn lựa dựa trên phân cụm (Sener & Savarese, 2017; Ash et al., 2019), độ bất định của mô hình (Gal et al., 2017), và proximity đối nghịch (Ducoffe & Precioso, 2018) (xem (Ren et al., 2021) để khảo sát). Trong phần sau, chúng tôi xem xét lấy mẫu dựa trên biên do tính đơn giản của nó và ứng dụng trước đây cho chưng cất hiệu quả bởi công việc liên quan (Liang et al., 2020; Xu et al., 2020). Lấy mẫu dựa trên biên cho KD là một ý tưởng trực quan và đơn giản để thực hiện nơi các dự đoán của giáo viên cho các đầu vào mà học sinh không chắc chắn nhất được truy vấn. Đối với một đầu vào x và dự đoán î = argmaxi∈[k]fstudent(x)i, độ bất định được đo bằng biên giữa 2 mục xác suất cao nhất, tức là margin(x) = fstudent(x)î - maxi∈[k]\{î}fstudent(x)i.

2.2 KHOẢNG TRỐNG NGHIÊN CỨU

Mặc dù thành công rộng rãi của lấy mẫu dựa trên biên trong học tích cực, chúng tôi khẳng định rằng nó thường không phù hợp cho chưng cất kiến thức do xu hướng khuếch đại thiên kiến xác nhận, dẫn đến

3

--- TRANG 4 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

hiệu suất học sinh kém. Để quan sát điều này, lưu ý rằng mục tiêu của lấy mẫu dựa trên biên - và tổng quát hơn, các phương pháp truy vấn dựa trên độ bất định khác - là truy vấn các nhãn mềm của các đầu vào mà học sinh không chắc chắn nhất ("các trường hợp khó"). Tuy nhiên, các trường hợp khó đối với học sinh thường khó dự đoán chính xác bởi giáo viên. Do đó, các nhãn mềm cho những điểm này có nhiều khả năng không chính xác đối với các nhãn thực tế, dẫn đến huấn luyện học sinh sai lệch.

Hình 1 cho thấy một trường hợp của hiện tượng này cho CIFAR10 với các kiến trúc học sinh-giáo viên ResNet có độ sâu khác nhau. Như hình minh họa, giáo viên có xu hướng dự đoán nhãn không chính xác cho các điểm có biên học sinh thấp (các trường hợp khó), và ngược lại, có xu hướng rất chính xác trên các điểm có biên cao (các trường hợp dễ). Điều này gợi ý rằng có một sự đánh đổi cố hữu giữa hiệu quả (giảm thiểu truy vấn) và tính bền vững (giảm thiểu thiên kiến xác nhận) cần được xem xét. Tức là, chúng tôi muốn chọn các điểm có tính thông tin cho học sinh để có hiệu quả, nhưng những điểm có tính thông tin này có xu hướng bị phân loại sai bởi học sinh điều này dẫn đến huấn luyện sai hướng và hiệu suất kém. Có thể đạt được đồng thời cả hai theo cách có nguyên tắc không? Chúng tôi gắn nhãn vấn đề này là Chưng cất Tích cực Bền vững và đề xuất một phương pháp để giải quyết nó trong phần tiếp theo.

Hình 1: Trái: độ chính xác của giáo viên (tổng thể 60.7%) so với điểm biên của học sinh (tổng thể 49.4%); các điểm với biên thấp hơn có xu hướng bị phân loại sai bởi giáo viên. Biểu đồ được tạo bằng cách tính trung bình độ chính xác của giáo viên trên 100 điểm biên gần nhất. Phải: Hiệu suất của chưng cất bền vững (đỏ), chọn các điểm biên thấp nhất trong số những điểm được gán nhãn chính xác bởi giáo viên, so với của biên (xanh).

3 CHƯNG CẤT TÍCH CỰC BỀN VỮNG (RAD)

3.1 BỐI CẢNH

Thuật toán biên (Liang et al., 2020; Roth & Small, 2006) chọn b điểm với điểm biên thấp nhất margin(x), trong đó b là ngân sách nhãn mềm của chúng tôi. Để margini là tốc ký cho biên của mỗi đầu vào không được gán nhãn margin(xi) và quan sát rằng lợi ích hoặc tính thông tin của nó có thể được định lượng là gi = 1 - margini. Cho một ngân sách b, lưu ý rằng thuật toán lấy mẫu biên tương ứng với giải pháp tối ưu của bài toán tối ưu hóa sau đây nơi mục tiêu là tạo ra một phân phối xác suất tối đa hóa tổng kỳ vọng của các lợi ích,

maxp∈Δb E∼S[∑i∈S gi],     trong đó Δb = {p∈[0,1]n : ∑i∈[n] pi = b}.     (1)

Như đã thảo luận trước đây, công thức này chỉ tập trung vào tính thông tin của các điểm và không xem xét khả năng tăng gắn nhãn sai của giáo viên.

Chưng cất Bền vững Để mở rộng (1) sao cho nó bền vững với gắn nhãn sai có thể của giáo viên, hãy xem xét các mặt nạ ci = 1{giáo viên gắn nhãn điểm i chính xác} cho mỗi i∈[n] trong đó 1{x} = 1 nếu x đúng và 0 ngược lại. Được trang bị với biến bổ sung này, một cách để giảm thiểu thiên kiến xác nhận một cách rõ ràng và đồng thời chọn các mẫu có tính thông tin là thưởng các điểm được gắn nhãn chính xác bởi giáo viên bằng cách gán lợi ích như trước, nhưng phạt những điểm bị gắn nhãn sai thông qua mất mát. Điều này có thể được thực hiện bằng cách sử dụng các lợi ích được sửa đổi trong bối cảnh của (1)

g̃i = gici - (1-ci)ℓi = {gi, nếu giáo viên gắn nhãn điểm i chính xác
                       -ℓi, ngược lại    ∀i∈[n].

4

--- TRANG 5 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Bằng lời, điều này có nghĩa là nếu điểm i được gắn nhãn chính xác bởi giáo viên, chúng tôi gán lợi ích biên tiêu chuẩn gi = (1-margini) như trước; ngược lại, chúng tôi phạt việc chọn lựa bằng cách gán ℓi cho một số mất mát ℓi ≥ 0. Điều này dẫn đến vấn đề chung sau về chưng cất bền vững

maxp∈Δb Ei∼p[gici - (1-ci)ℓi].     (2)

Giải pháp tối ưu cho vấn đề (2) tương ứng với việc chọn b điểm có tính thông tin nhất (lợi ích cao nhất) trong số những điểm được dự đoán chính xác bởi giáo viên, tức là những điểm i∈[n] với gi cao nhất tùy thuộc vào ci = 1. Phương pháp này được hiển thị như Chưng cất Bền vững (Oracle) trong Hình 1 (phải). Hình 1 minh họa tác động của các ví dụ không chính xác đối với huấn luyện học sinh (xem thêm (Pham et al., 2021)). Nếu chúng tôi có kiến thức về (ci)i∈[n], thì chúng tôi có thể giải quyết tối ưu (2) để có được cải thiện đáng kể so với thuật toán biên tiêu chuẩn. Thật không may, kiến thức hoàn hảo về việc liệu giáo viên gắn nhãn mỗi điểm chính xác hay không, tức là (ci)i∈[n], không thể có trong bối cảnh bán giám sát.

3.2 PHƯƠNG PHÁP CỦA CHÚNG TÔI

Chúng tôi xem xét một phương pháp tổng quát và bền vững đồng thời tận dụng kiến thức cụ thể trường hợp mà không cần biết các mặt nạ (ci)i∈[n] riêng lẻ. Giả sử rằng chúng tôi chỉ biết rằng giáo viên gắn nhãn sai m điểm trong số n đầu vào không được gắn nhãn XB thay vào đó. Chúng ta có thể tạo ra một phân phối lấy mẫu sao cho bất kể m điểm nào bị gắn nhãn sai bởi giáo viên, lợi ích kỳ vọng của chúng ta vẫn cao? Giả sử b=1 để đơn giản, chúng ta đến với việc mở rộng công thức trong (2)

maxp∈Δ1 minc∈Γn-m Ei∼p[gici - (1-ci)ℓi],     trong đó Γk = {q∈[0,1]n : ∑i∈[n] qi = k}.     (3)

Vấn đề (3) có diễn giải lý thuyết trò chơi sau đây. Chúng tôi đi trước và chọn một phân phối lấy mẫu p trên các điểm. Để đáp lại, một đối thủ quyết định điểm nào bị phân loại sai (tức là, ci = 0) bởi giáo viên tùy thuộc vào ràng buộc rằng nó có thể đặt ci = 0 cho nhiều nhất m trong số n của chúng vì c∈Γn-m. Với cấu trúc tuyến tính của vấn đề, hóa ra chúng ta có thể gọi Định lý Minimax của von Neumann (Neumann, 1928) tuyên bố rằng điểm cân bằng là như nhau bất kể chúng ta đi trước và chọn phân phối xác suất p∈Δ1 hay đối thủ đi trước và chọn (ci)i∈[n]. Bằng cách khai thác kết nối này, chúng ta có được một giải pháp dạng đóng như được chính thức hóa dưới đây.

Định lý 1. Giả sử g1 ≥ g2 ≥ ... ≥ gn > 0, và định nghĩa Gk = ∑i≤k gi/(gi+ℓi) và Hk = ∑i≤k 1/(gi+ℓi). Đối với Gn ≥ m, một giải pháp tối ưu p* ∈ Δ1 cho (3) được cho bởi

p*i = 1/(Hk*(gi+ℓi)) nếu i ≤ k* và p*i = 0 ngược lại, trong đó k* = argmaxk∈[n] (Gk-m)/Hk.

Phân phối có thể được tính trong thời gian tuyến tính (giả sử g được sắp xếp) và đạt được giá trị mục tiêu OPT(k*) := (Gk*-m)/Hk*.

Chúng tôi phác thảo chứng minh ở đây. Chứng minh đầy đủ có thể được tìm thấy trong Phụ lục (Mục C).

Phác thảo chứng minh. Để
OBJ(p,c) = ∑i∈[n] pi(gici - (1-ci)ℓi).

Thay thế p* từ Định lý 1 và xem xét một giá trị tối thiểu hóa cho c∈Γn-m, có thể chỉ ra rằng p* ∈ Δ1 và
OPT(k*) = minc∈Γn-m OBJ(p*,c) ≤ maxp∈Δ1 minc∈Γn-m OBJ(p,c).

Mặt khác, để c*i = min{1, (OPT(k*)+ℓi)/(gi+ℓi)}. Với một chút công việc thêm, sử dụng thực tế rằng gk* ≥ OPT(k*) ≥ gk*+1, chúng ta có thể chỉ ra tương tự rằng c* ∈ Γn-m và
OPT(k*) = maxp∈Δ1 OBJ(p,c*) ≥ minc∈Γn-m maxp∈Δ1 OBJ(p,c).

Với những bất đẳng thức này trong tay, chúng ta áp dụng Định lý Minimax (Neumann, 1928), cho ra
OPT(k*) ≤ maxp∈Δ1 minc∈Γn-m OBJ(p,c) = minc∈Γn-m maxp∈Δ1 OBJ(p,c) ≤ OPT(k*).

Do đó, p* thực sự có được giá trị tối ưu, OPT(k*).

5

--- TRANG 6 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Mất mát RAD Được trang bị với Định lý 1, tất cả những gì còn lại là chỉ định các mất mát trong (3). Công việc trước đây về thiên kiến xác nhận đã chỉ ra rằng ngay cả một số nhỏ các nhãn mềm sai lệch có thể làm trật đường ray hiệu suất của học sinh và ảnh hưởng đáng kể đến khả năng dự đoán của nó (Liu & Tan, 2021). Ngoài ra, tác hại của một điểm được gắn nhãn sai có thể thậm chí còn được phát âm hơn khi học sinh không chắc chắn về điểm đó. Để mô hình hóa điều này, chúng tôi xem xét việc khởi tạo công thức vấn đề tổng quát của chúng tôi (3) với các mất mát tương đối với lợi ích ℓi = wgi cho mỗi i∈[n] trong đó w∈[0,1] là một tham số trọng số kiểm soát độ lớn của việc phạt. Công thức này có mục đích dẫn đến các hình phạt cao hơn cho các điểm phân loại sai mà học sinh đã không chắc chắn (lợi ích cao) để giảm thiểu thiên kiến xác nhận, và dẫn đến bài toán tối ưu hóa sau đây là trọng tâm của bài báo này

maxp∈Δ1 minc∈Γn-m Ei∼p[gici - (1-ci)wgi].     (4)

Gọi Định lý 1 với các mất mát lợi ích tương đối như mô tả ở trên ngay lập tức dẫn đến điều sau đây, cùng với sự lựa chọn của w dưới đây, mô tả thuật toán RAD mà chúng tôi đề xuất trong bài báo này.

Hệ quả 1. Một giải pháp tối ưu p* ∈ Δ1 cho (4) có k* mục không bằng không Ik* ⊆ [n] tương ứng với k* chỉ số của các mục lớn nhất của g, với

p*i = 1/(gi ∑j∈Ik* g^(-1)_j) ∀i∈Ik* trong đó k* = argmaxk∈[n] (k(1+w)-m)/(∑j∈Ik g^(-1)_j).

Phân phối p* có thể được tính trong thời gian O(n log n), với OPT(k*) = (k*(1+w)-m)/(∑j∈Ik* g^(-1)_j).

Lựa chọn của w Mặc dù RAD có thể được áp dụng với bất kỳ lựa chọn do người dùng chỉ định nào của w, chúng tôi sử dụng trọng số có động lực lý thuyết w = (1-m/n) như hằng số phạt tương đối trong các thí nghiệm của chúng tôi. Lựa chọn w này đảm bảo rằng giá trị tối ưu (lợi ích kỳ vọng) của (4) (xem Hệ quả (1)) là không âm — nếu lợi ích kỳ vọng âm, chúng ta sẽ tốt hơn nếu không lấy mẫu gì cả. Giá trị mặc định này cho w làm cho RAD không có tham số. Các đánh giá thực nghiệm rộng rãi với các giá trị khác nhau của w được trình bày trong Mục D.5 của Phụ lục.

Hình 2: Giải pháp tối ưu cho (4) được cho bởi Hệ quả 1 cho các giá trị khác nhau cho độ chính xác của giáo viên (thay đổi m). Ngay cả khi hầu hết các mẫu được gắn nhãn chính xác bởi giáo viên, phương pháp của chúng tôi có chủ ý thận trọng và không phân bổ tất cả khối lượng xác suất (của việc lấy mẫu) trên các điểm lợi ích cao nhất.

Chúng tôi quan sát một số tính chất thuận lợi của phân phối lấy mẫu của RAD trong Hình 2, mô tả phân phối được tính trên một tình huống tổng hợp với các lợi ích được rút ngẫu nhiên đều từ [0,1]. Đầu tiên, phân phối lấy mẫu có xu hướng phân bổ ít khối lượng xác suất hơn cho các mục lợi ích cao nhất. Như công việc trước đây đã chỉ ra, điều này là mong muốn bởi vì các ví dụ khó nhất (lợi ích cao nhất) có xu hướng là các ngoại lệ hoặc các điểm với nhãn ồn ào (Mindermann et al., 2022; Ren et al., 2018). Trong thực tế, các phương pháp học bền vững thường hạ trọng số các ví dụ khó vì lý do này (Kumar et al., 2010), tương tự như hành vi lấy mẫu của RAD. Đồng thời, Paul et al. (2021) chỉ ra rằng các ví dụ dễ nhất (lợi ích thấp nhất) có xu hướng thực sự không có thông tin và chiến lược tốt nhất là bỏ qua một phần nhất định của các điểm lợi ích cao nhất và thấp nhất. Chiến lược này song song với phân phối được tính của RAD, nơi một số điểm lợi ích thấp bị bỏ qua và xác suất đạt đỉnh xung quanh một vùng ở giữa (xem Hình 2). Một lợi ích nổi bật của RAD là vùng này được tính một cách hoàn toàn tự động như một hàm của độ chính xác của giáo viên (tức là lượng nhiễu nhãn). Nếu giáo viên rất chính xác, phân phối tương ứng tập trung vào các điểm lợi ích cao nhất (xanh, Hình 2); ngược lại, nó lan ra các xác suất trên một phần lớn hơn của các điểm và có chủ ý gán xác suất lấy mẫu thấp hơn cho các điểm lợi ích cao nhất có khả năng ồn ào (ví dụ, nâu, Hình 2).

6

--- TRANG 7 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

3.3 CHI TIẾT TRIỂN KHAI

Chúng tôi kết thúc phần này bằng cách phác thảo các chi tiết thực tế của RAD. Chúng tôi tuân theo cài đặt của phần này và đặt gi = 1-margini để định nghĩa các lợi ích của mỗi điểm (xem Mục D.6 của Phụ lục để đánh giá với định nghĩa lợi ích khác). Trong thực tế, chúng tôi sử dụng phân phối q = min{bp*, 1} khi lấy mẫu một tập b điểm, trong đó p* từ Hệ quả 1. Điều này là tối ưu miễn là các xác suất từ Hệ quả 1 (hoặc tổng quát hơn, Định lý 1) không tập trung nhiều trên một vài điểm (tức là maxi∈[n] p*i ≤ 1/b). Như được minh họa trong Hình 2 và được xác minh thực nghiệm trong Mục 4 trong tất cả các tình huống được đánh giá, chúng tôi thấy điều này hầu như luôn luôn là trường hợp. Thay vào đó, kích thước thu thập b có thể được điều chỉnh sau khi phân phối xác suất mẫu đơn được tính sao cho b ≤ mini∈[n] 1/p*i.

Vì số lỗi mà giáo viên mắc phải trên XB, m, không được biết đến chúng tôi trong bối cảnh bán giám sát, chúng tôi xấp xỉ số lượng này bằng cách đầu tiên lấy trung bình mẫu sự không chính xác của một mẫu ngẫu nhiên đều nhỏ buniform (xem Phụ lục, Mục D.1) điểm như một cách để xấp xỉ m và bootstrap phương pháp của chúng tôi. Sau đó chúng tôi sử dụng phương pháp của chúng tôi với b' = b - buniform như mô tả ở trên. Bởi bất đẳng thức Bernstein (Bernstein, 1924), ước tính có trọng số này tập trung chặt chẽ xung quanh trung bình, điều này đến lượt nó ngụ ý một xấp xỉ chất lượng cao của m. Chúng tôi phân tích lý thuyết tác động của một m xấp xỉ đến chất lượng của giải pháp tối ưu trong Mục C của Phụ lục (xem Bổ đề 4 và 5).

4 KẾT QUẢ

Chúng tôi áp dụng thuật toán chọn mẫu của chúng tôi, RAD, cho các bộ dữ liệu thị giác chuẩn và đánh giá hiệu suất của nó trong việc tạo ra các mô hình học sinh hiệu suất cao trên một tập đa dạng các tình huống chưng cất kiến thức. Chúng tôi so sánh hiệu suất của RAD với những điều sau: (i) MARGIN (Balcan et al., 2007; Roth & Small, 2006) như mô tả trong Mục 3, (ii) UNIFORM, (iii) CLUSTER MARGIN (được gắn nhãn CM), một kỹ thuật học tích cực tiên tiến (Citovsky et al., 2021), (iv) CORESET, một thuật toán học tích cực dựa trên phân cụm phổ biến (Sener & Savarese, 2017), (v) ENTROPY, một phương pháp tham lam chọn các điểm với entropy dự đoán học sinh cao nhất (Holub et al., 2008), và (vi) UNIXKD (Xu et al., 2020), một phương pháp chưng cất tích cực tiên tiến dựa trên mix-up (Zhang et al., 2017). Chúng tôi triển khai tất cả các thuật toán trong Python và sử dụng thư viện học sâu TensorFlow (Abadi et al., 2015). Chúng tôi sử dụng các siêu tham số được chỉ định trong các bài báo tương ứng cho tất cả các phương pháp được so sánh. Đối với RAD, chúng tôi sử dụng cài đặt có dẫn xuất lý thuyết w = 1-m/n như được chỉ định trong Mục 3 và nhấn mạnh rằng điều này làm cho RAD hoàn toàn không có tham số.

Trong Mục D của Phụ lục, chúng tôi trình bày: tập đầy đủ các siêu tham số và chi tiết thực nghiệm (Mục D.1); các đánh giá bổ sung báo cáo số liệu thống kê ngoài độ chính xác kiểm tra (Mục D.3); các ứng dụng của RAD cho bối cảnh học tích cực tiêu chuẩn và so sánh với các phương pháp SOTA (Mục D.4); các thí nghiệm với w khác nhau và định nghĩa lợi ích để đánh giá tính bền vững của RAD (Mục D.5 và D.6, tương ứng); so sánh trên một tập đa dạng các cấu hình chưng cất kiến thức (Mục D.7).

Nhìn chung, các đánh giá thực nghiệm của chúng tôi cho thấy RAD cải thiện đều đặn trên các cơ sở tiên tiến và chứng minh hiệu quả sẵn có của nó mà không cần điều chỉnh hoặc thay đổi bất kỳ siêu tham số nào.

4.1 CIFAR10, CIFAR100, & SVHN

Thiết lập Chúng tôi sử dụng ResNet (He et al., 2015), ResNetV2-{11,20,29} (He et al., 2016), hoặc MobileNet (Howard et al., 2017) với hệ số nhân độ sâu 1 như học sinh và ResNet-50, ResNetV2-{56,110}, hoặc MobileNet với hệ số nhân độ sâu 2 như mô hình giáo viên. Chúng tôi xem xét các bộ dữ liệu CIFAR10/CIFAR100 (Krizhevsky et al., 2009), SVHN (Netzer et al., 2011), và ImageNet (Deng et al., 2009). Trừ khi được chỉ định khác, chúng tôi sử dụng bộ tối ưu hóa Adam (Kingma & Ba, 2014) với kích thước batch 128 với lịch trình tốc độ học cụ thể cho bộ dữ liệu. Chúng tôi tuân theo cài đặt chưng cất tích cực được hiển thị trong Alg. 1 với các cấu hình khác nhau. Chúng tôi sử dụng 64 Cloud TPU v4 mỗi với hai lõi. Tập đầy đủ các siêu tham số và chi tiết thực nghiệm có thể được tìm thấy trong Mục D của Phụ lục.

Cấu hình Chúng tôi thí nghiệm với một tập đa dạng các cấu hình cho tác vụ chưng cất kiến thức. Chúng tôi báo cáo cấu hình cụ thể cho mỗi biểu đồ như một phần của tiêu đề biểu đồ (ví dụ, xem Hình 3). Trong bối cảnh các biến trong tiêu đề biểu đồ, chúng tôi thay đổi số epoch mà học sinh được huấn luyện (được ký hiệu là e), kích thước của tập ban đầu các điểm được gắn nhãn (|A|), số lượng nhãn mềm để truy vấn mỗi lần lặp (b), và mô hình giáo viên (t); resnet trong cấu hình đề cập đến ResNetV2-20 như học sinh và ResNet-50 như giáo viên trừ khi được chỉ định khác. Tất cả kết quả được tính trung bình trên 10

7

--- TRANG 8 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

lần thử trừ khi được nêu khác. Đối với mỗi lần thử, chúng tôi xáo trộn lại toàn bộ bộ dữ liệu và chọn một phần ngẫu nhiên (có kích thước |A|) làm bộ dữ liệu được gắn nhãn XL, và xem xét phần còn lại là tập không được gắn nhãn XU.

Hình 3: Đánh giá RAD, các chiến lược học tích cực và chưng cất tích cực tiên tiến trên một tập đa dạng các cấu hình chưng cất với các bộ dữ liệu và kiến trúc mạng khác nhau. RAD luôn vượt trội hơn các phương pháp cạnh tranh. Vùng được tô màu tương ứng với các giá trị trong phạm vi một độ lệch chuẩn của trung bình.

Trong tập thí nghiệm đầu tiên, chúng tôi đánh giá hiệu quả của mỗi phương pháp trong việc tạo ra các mô hình học sinh có độ chính xác cao tùy thuộc vào ngân sách gắn nhãn mềm trên các bộ dữ liệu CIFAR10, CIFAR100, và SVHN với các kiến trúc ResNet(v2) và MobileNet có kích thước khác nhau. CIFAR10 chứa 50,000 hình ảnh có kích thước 32×32 với 10 danh mục, CIFAR100 có 50,000 hình ảnh 32×32 với 1000 nhãn, và SVHN bao gồm 73,257 hình ảnh thế giới thực (32×32) được chụp từ Google Street View. Hình 3 mô tả kết quả đánh giá của chúng tôi trên một tập đa dạng các tình huống chưng cất kiến thức với các cấu hình khác nhau. Chúng tôi quan sát một cải thiện nhất quán và đáng chú ý trong hiệu suất dự đoán của mô hình học sinh khi phương pháp của chúng tôi được sử dụng để chọn tích cực các điểm được gắn nhãn mềm bởi giáo viên. Cải thiện này thường có mặt từ lần lặp gắn nhãn đầu tiên và duy trì liên tục qua các lần lặp chưng cất tích cực.

Chúng tôi quan sát rằng RAD hoạt động đặc biệt tốt so với các baseline bất kể độ chính xác của giáo viên. Ví dụ, chúng tôi thấy cải thiện đáng kể với RAD khi chưng cất từ một giáo viên MobileNet trên CIFAR100, có độ chính xác tương đối thấp (xem các biểu đồ tương ứng trong Hình 3). Quan sát này gợi ý rằng việc xem xét rõ ràng sự không chính xác có thể của giáo viên thực sự hữu ích khi chưng cất từ một giáo viên có thể dễ mắc lỗi. Đồng thời, chúng tôi quan sát rằng RAD vượt trội hơn các thuật toán học tích cực tiên tiến như Cluster Margin (CM) và các thuật toán khác (MARGIN, ENTROPY) - không xem xét rõ ràng nhiễu nhãn dưới dạng nhãn mềm giáo viên không chính xác - ngay cả trong các trường hợp độ chính xác giáo viên cao đến 92% (xem biểu đồ SVHN trong Hình 3). Những quan sát này hỗ trợ khả năng của RAD tự động thích ứng phân phối lấy mẫu của nó với tình huống được áp dụng dựa trên sự không chính xác của giáo viên được xấp xỉ.

8

--- TRANG 9 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình 4: Độ chính xác phân loại và lợi ích trên bộ dữ liệu ImageNet với ResNets.

4.2 THÍÝ NGHIỆM IMAGENET

Ở đây, chúng tôi báo cáo kết quả đánh giá của chúng tôi với các kiến trúc ResNet được huấn luyện trên bộ dữ liệu ImageNet, chứa gần 1.3 triệu hình ảnh trải rộng 1000 danh mục (Deng et al., 2009). Chúng tôi loại trừ các phương pháp UNIXKD và CORESET do hạn chế tài nguyên và thực tế rằng CM vượt trội hơn CORESET (Citovsky et al., 2021) và UNIXKD luôn hoạt động kém trên các cấu hình trong phần trước. Điều này làm nổi bật một lợi thế bổ sung của phương pháp chúng tôi: nó chỉ đòi hỏi một sắp xếp (O(n log n) tổng thời gian). Điều này trái ngược với các phương pháp tốn kém về tính toán và bộ nhớ như CORESET và CM đòi hỏi phân cụm (xem Mục D.2 để biết chi tiết). Hình 4 mô tả kết quả đánh giá của chúng tôi, nơi phương pháp chúng tôi luôn cải thiện so với các phương pháp được so sánh qua tất cả các epoch huấn luyện. Ở đây giáo viên là mô hình ResNet50 và học sinh là mô hình ResNet18. Giáo viên được huấn luyện trên bộ dữ liệu được gắn nhãn ban đầu A với |A| = 10%|I|. Đối với mỗi lựa chọn ngân sách b ∈ {3%|I|, 5%|I|, 7%|I|, 9%|I|, 11%|I|}, chúng tôi chạy 3 lần thử. Trong biểu đồ ngoài cùng bên phải chúng tôi quan sát rằng lợi ích của phương pháp chúng tôi (đối với gi = 1-margini) cao hơn so với các phương pháp cạnh tranh, và lợi ích tương quan tốt với độ chính xác kiểm tra của học sinh, điều này tái khẳng định tính hợp lệ thực tế của công thức chúng tôi (Mục 3).

5 KẾT LUẬN

Trong bài báo này, chúng tôi xem xét vấn đề chưng cất kiến thức hiệu quả và bền vững trong bối cảnh học bán giám sát với một lượng hạn chế dữ liệu được gắn nhãn và một lượng lớn dữ liệu không được gắn nhãn. Chúng tôi xây dựng vấn đề chưng cất tích cực bền vững và trình bày một thuật toán thời gian gần tuyến tính với các đảm bảo có thể chứng minh để giải quyết nó một cách tối ưu. Theo hiểu biết tốt nhất của chúng tôi, công việc của chúng tôi là đầu tiên xem xét lấy mẫu quan trọng cho các nhãn mềm có tính thông tin và được gắn nhãn chính xác để cho phép hiệu quả và tính bền vững trong các tác vụ chưng cất kiến thức quy mô lớn. Phương pháp của chúng tôi không có tham số và đơn giản để triển khai. Các thí nghiệm của chúng tôi trên các bộ dữ liệu chuẩn phổ biến với một tập đa dạng các cấu hình cho thấy một cải thiện nhất quán và đáng chú ý trong độ chính xác kiểm tra của mô hình học sinh được tạo ra so với những mô hình được tạo ra bởi các phương pháp tiên tiến.

Hạn chế và công việc tương lai Trong công việc tương lai, chúng tôi dự định thiết lập một hiểu biết lý thuyết sâu sắc hơn về sự đánh đổi của các khởi tạo khác nhau của khung tổng quát chúng tôi, (3) trong Mục 3, về độ chính xác kiểm tra của mô hình học sinh. Ví dụ, không rõ liệu định nghĩa lợi ích là gi = 1-margini hay gi = exp(-margini) có thích hợp hơn không, mặc dù cả hai định nghĩa đều dẫn đến các lợi ích tăng đơn điệu với độ bất định của học sinh. Bên cạnh việc xem xét độ chính xác của giáo viên trong công thức bền vững, chúng tôi dự định cũng xem xét các số liệu liên quan khác như sự bất đồng học sinh-giáo viên để xây dựng các phân phối có thông tin hơn. Nhìn chung, chúng tôi hình dung rằng phương pháp của chúng tôi có thể được sử dụng trong các ứng dụng có tác động cao để tạo ra các mô hình học sinh mạnh mẽ bằng cách chưng cất hiệu quả kiến thức của các giáo viên lớn trước hạn chế dữ liệu được gắn nhãn.

9

--- TRANG 10 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

TUYÊN BỐ KHẢ NĂNG TÁI SẢN XUẤT

Thuật toán của chúng tôi được chỉ định đầy đủ (Hệ quả 1), đơn giản để triển khai, và không có tham số (Mục 3). Chúng tôi cung cấp chi tiết đầy đủ và các siêu tham số cần thiết để tái tạo kết quả của chúng tôi trong Mục 4 và Mục D.1 của Phụ lục. Chúng tôi chỉ định mô tả về cách các thuật toán cạnh tranh được triển khai, bao gồm cài đặt siêu tham số. Chúng tôi cung cấp kết quả lý thuyết chính xác (Mục 3 trong phần chính và Mục C của Phụ lục) chỉ định rõ ràng các giả định và cung cấp chứng minh đầy đủ và các bổ đề hỗ trợ bổ sung trong Phụ lục (Mục C). Các đánh giá của chúng tôi sử dụng các bộ dữ liệu và mô hình công khai có sẵn và dễ tiếp cận.

TÀI LIỆU THAM KHẢO

Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, và Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/. Software available from tensorflow.org. 7

Eric Arazo, Diego Ortego, Paul Albert, Noel E O'Connor, và Kevin McGuinness. Pseudo-labeling and confirmation bias in deep semi-supervised learning. Trong 2020 International Joint Conference on Neural Networks (IJCNN), trang 1–8. IEEE, 2020. 2

Jordan T Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, và Alekh Agarwal. Deep batch active learning by diverse, uncertain gradient lower bounds. arXiv preprint arXiv:1906.03671, 2019. 3

Maria-Florina Balcan, Andrei Broder, và Tong Zhang. Margin based active learning. Trong International Conference on Computational Learning Theory, trang 35–50. Springer, 2007. 3, 7

Cenk Baykal, Lucas Liebenwein, Igor Gilitschenski, Dan Feldman, và Daniela Rus. Sensitivity-informed provable pruning of neural networks. SIAM Journal on Mathematics of Data Science, 4(1):26–45, 2022. 1

Sergei Bernstein. On a modification of chebyshev's inequality and of the error formula of laplace. Ann. Sci. Inst. Sav. Ukraine, Sect. Math, 1(4):38–49, 1924. 7, 18

Lucas Beyer, Xiaohua Zhai, Amélie Royer, Larisa Markeeva, Rohan Anil, và Alexander Kolesnikov. Knowledge distillation: A good teacher is patient and consistent. arXiv preprint arXiv:2106.05237, 2021. 1, 2

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020. 1

Cristian Bucilu ˇa, Rich Caruana, và Alexandru Niculescu-Mizil. Model compression. Trong Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, trang 535–541, 2006. 1

Chandra Chekuri, Jan V ondrák, và Rico Zenklusen. Dependent randomized rounding for matroid polytopes and applications. arXiv preprint arXiv:0909.4348, 2009. 14

Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, và Geoffrey E Hinton. Big self-supervised models are strong semi-supervised learners. Advances in neural information processing systems, 33:22243–22255, 2020. 1

Jang Hyun Cho và Bharath Hariharan. On the efficacy of knowledge distillation. Trong Proceedings of the IEEE/CVF international conference on computer vision, trang 4794–4802, 2019. 1

10

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. 2

Gui Citovsky, Giulia DeSalvo, Claudio Gentile, Lazaros Karydas, Anand Rajagopalan, Afshin Rostamizadeh, và Sanjiv Kumar. Batch active learning at scale. Advances in Neural Information Processing Systems, 34, 2021. 7, 9, 19

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. Imagenet: A large-scale hierarchical image database. Trong 2009 IEEE conference on computer vision and pattern recognition, trang 248–255. Ieee, 2009. 7, 9

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018. 1

Melanie Ducoffe và Frederic Precioso. Adversarial active learning for deep networks: a margin based approach. arXiv preprint arXiv:1802.09841, 2018. 3

Yarin Gal, Riashat Islam, và Zoubin Ghahramani. Deep bayesian active learning with image data. Trong International Conference on Machine Learning, trang 1183–1192. PMLR, 2017. 3

Jianping Gou, Baosheng Yu, Stephen J Maybank, và Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision, 129(6):1789–1819, 2021. 1

Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Deep residual learning for image recognition. corr abs/1512.03385 (2015), 2015. 7

Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Identity mappings in deep residual networks. Trong European conference on computer vision, trang 630–645. Springer, 2016. 7

Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2(7), 2015. 1, 3

Alex Holub, Pietro Perona, và Michael C Burl. Entropy-based active learning for object recognition. Trong 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, trang 1–8. IEEE, 2008. 7

Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, và Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017. 7, 18

Diederik P Kingma và Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 7, 18

Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 7

M Kumar, Benjamin Packer, và Daphne Koller. Self-paced learning for latent variable models. Advances in neural information processing systems, 23, 2010. 6

Kevin J Liang, Weituo Hao, Dinghan Shen, Yufan Zhou, Weizhu Chen, Changyou Chen, và Lawrence Carin. Mixkd: Towards efficient distillation of large-scale language models. arXiv preprint arXiv:2011.00593, 2020. 2, 3, 4

Kevin J Liang, Samrudhdhi B Rangrej, Vladan Petrovic, và Tal Hassner. Few-shot learning with noisy labels. arXiv preprint arXiv:2204.05494, 2022. 2

Lu Liu và Robby T Tan. Certainty driven consistency loss on multi-teacher networks for semi-supervised learning. Pattern Recognition, 120:108140, 2021. 2, 6

Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, và Christopher Potts. Learning word vectors for sentiment analysis. Trong Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, trang 142–150, Portland, Oregon, USA, Tháng 6 2011. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/P11-1015. 28

11

--- TRANG 12 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Aditya Krishna Menon, Ankit Singh Rawat, Sashank J Reddi, Seungyeon Kim, và Sanjiv Kumar. Why distillation helps: a statistical perspective. arXiv preprint arXiv:2005.10419, 2020. 1

Sören Mindermann, Jan M Brauner, Muhammed T Razzak, Mrinank Sharma, Andreas Kirsch, Winnie Xu, Benedikt Höltgen, Aidan N Gomez, Adrien Morisot, Sebastian Farquhar, et al. Prioritized training on points that are learnable, worth learning, and not yet learnt. Trong International Conference on Machine Learning, trang 15630–15649. PMLR, 2022. 6

Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, và Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011. 7, 22

John von Neumann. Zur theorie der gesellschaftsspiele. Mathematische annalen, 100(1):295–320, 1928. 5, 14

Michael Niemeyer và Andreas Geiger. Giraffe: Representing scenes as compositional generative neural feature fields. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 11453–11464, 2021. 1

OpenAI. Openai pricing. https://openai.com/api/pricing/#faq-which-model, 2022. Truy cập: 2022-08-01. 2

David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, và Jeff Dean. Carbon emissions and large neural network training. arXiv preprint arXiv:2104.10350, 2021. 1

Mansheej Paul, Surya Ganguli, và Gintare Karolina Dziugaite. Deep learning on a data diet: Finding important examples early in training. Advances in Neural Information Processing Systems, 34:20596–20607, 2021. 6, 19

Mansheej Paul, Brett W Larsen, Surya Ganguli, Jonathan Frankle, và Gintare Karolina Dziugaite. Lottery tickets on a data diet: Finding initializations with sparse trainable networks. arXiv preprint arXiv:2206.01278, 2022. 19

Hieu Pham, Zihang Dai, Qizhe Xie, và Quoc V Le. Meta pseudo labels. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 11557–11568, 2021. 1, 2, 5

Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea V oss, Alec Radford, Mark Chen, và Ilya Sutskever. Zero-shot text-to-image generation. Trong International Conference on Machine Learning, trang 8821–8831. PMLR, 2021. 1

Mengye Ren, Wenyuan Zeng, Bin Yang, và Raquel Urtasun. Learning to reweight examples for robust deep learning. Trong International conference on machine learning, trang 4334–4343. PMLR, 2018. 6

Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Brij B Gupta, Xiaojiang Chen, và Xin Wang. A survey of deep active learning. ACM Computing Surveys (CSUR), 54(9):1–40, 2021. 3

Dan Roth và Kevin Small. Margin-based active learning for structured output spaces. Trong European Conference on Machine Learning, trang 413–424. Springer, 2006. 2, 3, 4, 7

Ozan Sener và Silvio Savarese. Active learning for convolutional neural networks: A core-set approach. arXiv preprint arXiv:1708.00489, 2017. 3, 7, 19

Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, và Jae-Gil Lee. Learning from noisy labels with deep neural networks: A survey. IEEE Transactions on Neural Networks and Learning Systems, 2022. 2

Samuel Stanton, Pavel Izmailov, Polina Kirichenko, Alexander A Alemi, và Andrew G Wilson. Does knowledge distillation really work? Advances in Neural Information Processing Systems, 34, 2021. 1

12

--- TRANG 13 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Iulia Turc, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Well-read students learn better: On the importance of pre-training compact models. arXiv preprint arXiv:1908.08962, 2019. 28

Qizhe Xie, Minh-Thang Luong, Eduard Hovy, và Quoc V Le. Self-training with noisy student improves imagenet classification. Trong Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, trang 10687–10698, 2020. 1, 2

Guodong Xu, Ziwei Liu, và Chen Change Loy. Computation-efficient knowledge distillation via uncertainty-aware mixup. arXiv preprint arXiv:2012.09413, 2020. 2, 3, 7

Taraneh Younesian, Zilong Zhao, Amirmasoud Ghiassi, Robert Birke, và Lydia Y Chen. Qactor: Active learning on noisy labels. Trong Asian Conference on Machine Learning, trang 548–563. PMLR, 2021. 2

Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, và David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017. 2, 7

Zizhao Zhang, Han Zhang, Sercan O Arik, Honglak Lee, và Tomas Pfister. Distilling effective supervision from severe label noise. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 9294–9303, 2020. 2

Guoqing Zheng, Ahmed Hassan Awadallah, và Susan Dumais. Meta label correction for noisy label learning. AAAI 2021, 2021. 2

13

--- TRANG 14 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

A PHỤ LỤC

Trong tài liệu bổ sung này, chúng tôi cung cấp chi tiết về lấy mẫu batch (trong Mục B), chứng minh đầy đủ của các kết quả trong Mục 3 và các kết quả lý thuyết bổ sung (trong Mục C), và chi tiết của các thí nghiệm trong Mục 4 và các đánh giá bổ sung (trong Mục D).

B CHI TIẾT TRIỂN KHAI

Để bổ sung thảo luận của chúng tôi trong Mục 3, chúng tôi cung cấp chi tiết bổ sung về quy trình lấy mẫu batch. Một phương pháp là lặp qua các điểm i∈[n] và chọn mỗi điểm với xác suất qi. Nếu ∑i∈[n] qi = b, thì quy trình này lấy mẫu b điểm trong kỳ vọng. Một phương pháp có nguyên tắc hơn là sử dụng làm tròn phụ thuộc ngẫu nhiên (Chekuri et al., 2009) lấy mẫu chính xác b điểm cho một phân phối tổng bằng b. Quy trình này được hiển thị là Alg. 2, và một triển khai hiệu quả của nó chạy trong thời gian O(n) (Chekuri et al., 2009).

Thuật toán 2 DEPROUND
Đầu vào: Xác suất p∈[0,1]^n sao cho ∑i∈[n] pi = b
Đầu ra: tập chỉ số I⊆[n] với |I| = b
1: while ∃i∈[n] sao cho 0 < pi < 1 do
2:    Chọn i,j∈[n] với i ≠ j, 0 < pi < 1, và 0 < pj < 1
3:    α←min(1-pi, pj)
4:    β←min(pi, 1-pj)
5:    Cập nhật pi và pj
      (pi, pj)←{
        (pi+α, pj-α) với xác suất β/(α+β);
        (pi-β, pj+β) với xác suất 1-β/(α+β).
6: end while
7: I←{i∈[n] : pi = 1}
return I

C CHỨNG MINH & PHÂN TÍCH BỔ SUNG

C.1 CHỨNG MINH ĐỊNH LÝ 1

Định lý 1. Giả sử g1 ≥ g2 ≥ ... ≥ gn > 0, và định nghĩa Gk = ∑i≤k gi/(gi+ℓi) và Hk = ∑i≤k 1/(gi+ℓi). Đối với Gn ≥ m, một giải pháp tối ưu p*∈Δ1 cho (3) được cho bởi

p*i = 1/(Hk*(gi+ℓi)) nếu i ≤ k* và p*i = 0 ngược lại, trong đó k* = argmaxk∈[n] (Gk-m)/Hk.

Phân phối có thể được tính trong thời gian tuyến tính (giả sử g được sắp xếp) và đạt được giá trị mục tiêu OPT(k*) := (Gk*-m)/Hk*.

Chứng minh. Chứng minh dựa trên Định lý Minimax (Neumann, 1928), cho ra

minc∈Γn-m maxp∈Δ1 f(p,c) = maxp∈Δ1 minc∈Γn-m f(p,c).

Chúng tôi sẽ sử dụng thêm hai khẳng định, mà chúng tôi sẽ chứng minh ngay sau đây.

Khẳng định 2. Để p*, k*, và N(k*) được định nghĩa như trong tuyên bố của bổ đề. Thì p*∈Δ1 và N(k*) = minc∈Γn-m f(p*,c).

Khẳng định 3. Để k* và N(k*) được định nghĩa như trong tuyên bố của bổ đề. Hơn nữa, định nghĩa

c*i = {
  (N(k*)+ℓi)/(gi+ℓi) nếu i ≤ k*
  1 ngược lại
}

Thì c*∈Γn-m và N(k*) = maxp∈Δ1 f(p,c*).

Với các khẳng định này, chúng ta thấy

N(k*) = minc∈Γn-m f(p*,c) ≤ maxp∈Δ1 minc∈Γn-m f(p,c) theo Khẳng định 2
      = minc∈Γn-m maxp∈Δ1 f(p,c) theo Minimax
      ≤ maxp∈Δ1 f(p,c*) = N(k*) theo Khẳng định 3

Tức là, p* đạt được giá trị tối đa, là N(k*), như chúng ta mong muốn.

Bây giờ chúng tôi chứng minh các khẳng định. Trước khi bắt đầu, chúng tôi sẽ đầu tiên đơn giản hóa f(p,c) phần nào, tìm

f(p,c) = ∑i gipici - ∑i ℓipi(1-ci)
       = ∑i (ci(gi+ℓi)-ℓi)pi

Chứng minh Khẳng định 2. Đầu tiên chúng tôi chỉ ra p*∈Δ1. Chúng ta có

∑i∈n p*i = ∑i≤k* p*i = ∑i≤k* 1/(Hk*(gi+ℓi)) = (1/Hk*) ∑i≤k* 1/(gi+ℓi) = Hk*/Hk* = 1

Và vì p*i ≥ 0 cho tất cả i, nó ngay lập tức theo sau rằng p*i ≤ 1 cũng vậy.

Bây giờ chúng tôi chỉ ra N(k*) = minc∈Γn-m f(p*,c). Để kết thúc này,

f(p*,c) = ∑i∈n (ci(gi+ℓi)-ℓi)p*i
        = ∑i≤k* (ci(gi+ℓi)-ℓi)/(Hk*(gi+ℓi))
        = ∑i≤k* ci(gi+ℓi)/(Hk*(gi+ℓi)) - ∑i≤k* ℓi/(Hk*(gi+ℓi)) + ∑i≤k* gi/(Hk*(gi+ℓi))
        = (1/Hk*) ∑i≤k* ci - (1/Hk*) ∑i≤k* ℓi/(gi+ℓi) + Gk*/Hk*

Rõ ràng, đối với c∈Γn-m, biểu thức này được tối thiểu hóa khi ci = 1 cho i > k* và ∑i≤k* ci = k*-m. Vậy chúng ta có

minc∈Γn-m f(p*,c) = (1/Hk*)(k*-m) - (1/Hk*) ∑i≤k* ℓi/(gi+ℓi) + Gk*/Hk*
                    = (Gk*-m)/Hk* = N(k*)

như đã khẳng định.

Bây giờ chúng tôi chứng minh khẳng định thứ hai của chúng tôi.

Chứng minh Khẳng định 3. Đầu tiên chúng tôi chỉ ra rằng N(k*) ≥ gi cho i > k*.¹ Quan sát rằng nếu a/b ≥ (a+c)/(b+d), thì a/b ≥ c/d cho các giá trị không âm (và b > 0, d > 0). Lưu ý

(Gk*-m)/Hk* = N(k*) ≥ N(k*+1) = (Gk*+gk*+1/(gk*+1+ℓk*+1)-m)/(Hk*+1/(gk*+1+ℓk*+1))

¹Trong trường hợp biên mà k* = n, chúng ta có thể thêm một mục giả với gn+1 = 0 và khẳng định theo sau một cách tầm thường.

15

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Bằng quan sát của chúng tôi,

N(k*) ≥ gk*+1/(gk*+1+ℓk*+1) / (1/(gk*+1+ℓk*+1)) = gk*+1 ≥ gi cho i > k*.

Tương tự, chúng tôi chỉ ra N(k*) ≤ gi cho i ≤ k*, sử dụng quan sát rằng nếu a/b ≤ (a-c)/(b-d), thì a/b ≥ c/d cho các giá trị không âm (và b-d > 0 và d > 0). Lưu ý

N(k*-1) = (Gk*-gk*/(gk*+ℓk*)-m)/(Hk*-1/(gk*+ℓk*)) ≤ (Gk*-m)/Hk* = N(k*)

Và một lần nữa, bằng quan sát của chúng tôi,

N(k*) ≥ gk*/(gk*+ℓk*) / (1/(gk*+ℓk*)) = gk* ≥ gi cho i ≤ k*.    (5)

Bây giờ chúng tôi sẵn sàng chứng minh khẳng định.

Đầu tiên chúng tôi chỉ ra c*∈Γn-m. Vì N(k*) ≤ gi cho i ≤ k*, chúng ta thấy c*i = (N(k*)+ℓi)/(gi+ℓi) ≤ 1 cho i ≤ k*. Vậy c*i∈[0,1]. Hơn nữa,

∑i∈n c*i = ∑i≤k* (N(k*)+ℓi)/(gi+ℓi) + ∑k*<i≤n 1
         = ∑i≤k* (N(k*)-gi)/(gi+ℓi) + ∑i≤k* (gi+ℓi)/(gi+ℓi) + ∑k*<i≤n 1
         = N(k*)Hk* - Gk* + k* + n - k* = n - m

Tức là, c*∈Γn-m.

Cuối cùng, chúng tôi chỉ ra N(k*) = maxp∈∆1 f(p,c*). Lưu ý rằng c*i(gi+ℓi)-ℓi = N(k*) cho i ≤ k*, trong khi c*i(gi+ℓi)-ℓi = gi cho i > k*. Chúng ta có

f(p,c*) = ∑i (c*i(gi+ℓi)-ℓi)pi
        = ∑i≤k* N(k*)pi + ∑i>k* gipi

Từ trên, N(k*) ≥ gi cho i > k*. Vậy biểu thức được tối đa hóa cho p∈∆1 khi pi = 0 cho i > k* và ∑i≤k* pi = 1. Do đó,

maxp∈∆1 f(p,c*) = N(k*)

như chúng ta mong muốn.

C.2 TÁC ĐỘNG CỦA VIỆC XẤP XỈ M

Ở đây, chúng tôi chứng minh rằng một giải pháp gần tối ưu có thể được thu được ngay cả khi một giá trị xấp xỉ của m được sử dụng (ví dụ, thông qua một bộ dữ liệu xác thực). Để đơn giản, bổ đề sau xem xét trường hợp các mất mát là 0 trong bối cảnh Định lý 1, tuy nhiên, sự tổng quát hóa của nó thành các lợi ích và mất mát tổng quát - bao gồm công thức lỗi tương đối mà chúng tôi nghiên cứu trong bài báo này - theo sau bằng cách rescaling tham số lỗi ε một cách thích hợp.² Kết quả chính của chúng tôi là nếu chúng ta có một xấp xỉ m̂∈(1-ε)m, thì chúng ta có thể sử dụng m xấp xỉ này để có được một giải pháp (1-2εm/(2εm+(1+ε)))-cạnh tranh.

²Lưu ý rằng kết quả này tổng quát hóa cho mất mát tương đối RAD với w̃ ← w như đã thảo luận trong Mục 3 bằng cách xem xét m' = (1+w)m (xem Hệ quả 1).

16

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Bổ đề 4. Để m∈[n] là giá trị thực tế của số ví dụ không chính xác trong XB và để km* là giải pháp tối ưu đối với m. Giả sử g1 ≥ ... ≥ gn và để ν = gkm* và δ = ν/(2(2-ν)). Giả sử rằng chúng ta có một xấp xỉ m̂ của m sao cho

m̂∈(1-ε)m với ε∈(0,δ);

thì giải pháp km̃* đối với m̃ = m̂/(1+ε) là (1-2εm/(2εm+(1+ε)))-cạnh tranh với giải pháp tối ưu, tức là nó thỏa mãn

OBJ(km̃*,m) ≥ (1-2εm)/(2εm+(1+ε)) · OPT = (1-2εm)/(2εm+(1+ε)) · OBJ(km*,m);

trong đó OBJ(k,m) = (k-m)/Hk = maxk'∈[n] (k'-m)/Hk'.

Chứng minh. Để thuận tiện ký hiệu, chúng tôi để k và k* biểu thị km̃* và km*, tương ứng. Đầu tiên, quan sát rằng bằng giả định của bổ đề, chúng ta có

m̃ = m̂/(1+ε) ≤ (1-ε)m/(1+ε) và m̃ ≤ m.

Lưu ý rằng vì k ≥ m̃ bởi tính tối ưu của k* đối với m̃, chúng ta có k ≥ (1-ε)m/(1+ε)(1-δ) > m điều này theo sau từ điều kiện tối ưu từ chứng minh Định lý 1,

k*gk*+1 ≥ Hk* + m̃ ≥ k* + m̃) ≥ km̃*/(1+1) và ε < δ/(2(2-δ)). Vì k và m là số nguyên, chúng ta có k ≥ m+1 ≥ m̃+1. Cuối cùng, bởi tính tối ưu của k* đối với m̃, chúng ta có

1/Hk* · (k*-m̃) ≥ (k-m̃)/Hk.

Kết hợp tất cả những điều trên,

OBJ(k,m) = (k-m)/Hk
          = (k-m̃)/Hk - (m-m̃)/Hk
          ≥ (k-m̃)/Hk - (m-m̃)(k-m̃)/((k-m̃)Hk)
          = (k-m)/Hk · (1-(m-m̃)/(k-m̃))
          ≥ OPT · (1-(m-m̃)/(m+1-m̃))
          ≥ (1-2εm)/(2εm+(1+ε)) · OPT;

trong đó bất đẳng thức đầu tiên là do bất đẳng thức về cận dưới 1/Hk* và k ≥ m+1, bất đẳng thức thứ hai do m̃ ≤ m, bất đẳng thức thứ ba do k ≥ m+1, và bất đẳng thức thứ tư do

m-m̃ ≤ 2εm/(1+ε);

và sắp xếp lại.

C.3 XẤP XỈ M

Tiếp theo, chúng tôi chỉ ra cách ước tính m sử dụng một bộ dữ liệu xác thực T. Để làm như vậy, chúng tôi định nghĩa

err(T,f) = (1/|T|) ∑(x,y)∈T 1{f(x) ≠ y}

trong đó f(·)∈[k] tương ứng với dự đoán nhãn của mạng f. Lưu ý ở đây rằng

m = err(PB,f)|PB|

trong đó PB tương ứng với các điểm trong tập dữ liệu B.

17

--- TRANG 17 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Bổ đề 5. Đối với bất kỳ δ∈(0,1), nếu chúng ta sử dụng một tập xác thực T có kích thước k để có được một xấp xỉ m̂ = err(T,f)|PB| cho m = err(PB,f)|PB|, thì với xác suất ít nhất 1-δ,

|m-m̂| ≤ |PB|log(4/δ)/(|PB|+1) · (1/|PB| + 1/k) + √(2p(1-p)log(4/δ)) · (1/√|PB| + 1/√k);

trong đó p = P(x,y)∼D(f(x) ≠ y) là xác suất gắn nhãn sai cho mạng f(·).

Chứng minh. Để T = {(x1,y1),...,(x|T|,y|T|)} là một tập |T| điểm i.i.d. từ phân phối dữ liệu D và định nghĩa Xi = 1{f(xi) ≠ yi} cho mỗi i∈|T|. Để X = (1/|T|)∑i Xi, chúng tôi quan sát rằng

E[X] = E(x,y)∼D[1{f(x) ≠ y}] = P(x,y)∼D(f(x) ≠ y) = p.

Vì chúng ta có một tổng của k = |T| biến ngẫu nhiên độc lập mỗi biến được giới hạn bởi 1 với phương sai Var(Xi) = p(1-p), chúng tôi gọi bất đẳng thức Bernstein (Bernstein, 1924) để có được

P(|X-p| ≥ εT) ≤ 2exp(-kε²T/(2(p(1-p) + εT/3)));

đặt điều trên bằng δ/2 và giải cho εT cho ra

|X-p| ≤ εT ≤ log(4/δ)/k + √(2p(1-p)log(4/δ)/k);

với xác suất ít nhất 1-δ/2. Tương tự, chúng ta có thể định nghĩa các biến ngẫu nhiên Y1,...,Y|PB| sao cho Yi = 1{f(xi) ≠ yi} cho mỗi (xi,yi)∈PB. Để Y = (1/|PB|)∑i Yi và quan sát rằng E[Y] = p như trước, chúng tôi gọi bất đẳng thức Bernstein một lần nữa để có được rằng với xác suất ít nhất 1-δ/2,

|Y-p| ≤ εPB ≤ log(4/δ)/|PB| + √(2p(1-p)log(4/δ)/|PB|).

Tuyên bố theo sau bằng bất đẳng thức tam giác |Y-X| ≤ |Y-p| + |X-p| và ước lượng hợp nhất.

D ĐÁNH GIÁ BỔ SUNG & CHI TIẾT THỰC NGHIỆM

Ở đây, chúng tôi mô tả chi tiết thực nghiệm và siêu tham số được sử dụng trong đánh giá của chúng tôi và cung cấp kết quả thực nghiệm bổ sung bổ sung cho những kết quả được trình bày trong bài báo. Các đánh giá bổ sung của chúng tôi hỗ trợ tính bền vững và khả năng áp dụng rộng rãi của phương pháp chúng tôi.

D.1 CHI TIẾT THỰC NGHIỆM

Chúng tôi thực hiện đánh giá của mình trên 64 TPU v4 mỗi với hai lõi. Chúng tôi sử dụng một bộ dữ liệu xác thực có kích thước 1,000 cho các bộ dữ liệu CIFAR10, CIFAR100, và SVHN, và sử dụng một bộ dữ liệu xác thực có kích thước 10,000 cho ImageNet, tương ứng, để ước tính m. Các siêu tham số được sử dụng đối với mỗi kiến trúc và bộ dữ liệu tương ứng như sau.

MobileNet (CIFAR10, CIFAR100, SVHN) Đối với các thí nghiệm liên quan đến MobileNet (Howard et al., 2017), bất cứ khi nào MobileNet được sử dụng như kiến trúc học sinh, nó được khởi tạo với tham số độ rộng 1, và bất cứ khi nào nó được sử dụng như giáo viên, nó được khởi tạo với tham số độ rộng 2. Chúng tôi sử dụng bộ tối ưu hóa Adam (Kingma & Ba, 2014) với các tham số mặc định (tốc độ học: 1e-3) và huấn luyện trong 100 hoặc 200 epoch tùy thuộc vào cấu hình thực nghiệm. Chúng tôi không sử dụng tăng cường dữ liệu hoặc chính quy hóa trọng số.

ResNets và ResNetv2s (CIFAR10, CIFAR100, SVHN) Chúng tôi sử dụng bộ tối ưu hóa Adam (Kingma & Ba, 2014) với các tham số mặc định ngoại trừ lịch trình tốc độ học như sau. Đối với một số epoch cho trước nepochs∈{100,200}, chúng tôi sử dụng 1e-3 làm tốc độ học cho (2/5)nepochs đầu tiên, sau đó sử dụng 1e-4 cho đến (3/5)nepochs, 1e-5 cho đến (4/5)nepochs, 1e-6 cho đến (9/10)nepochs, và cuối cùng 5e-7 cho đến hết. Chúng tôi sử dụng các giá trị được làm tròn cho các cửa sổ epoch xác định lịch trình tốc độ học thành các giá trị tích phân khi cần thiết. Chúng tôi không sử dụng tăng cường dữ liệu hoặc chính quy hóa trọng số.

18

--- TRANG 18 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

D.2 IMAGENET

Thiết lập Chúng tôi sử dụng mô hình học sinh ResNet-18 và giáo viên ResNet-50 cho các thí nghiệm ImageNet. Chúng tôi huấn luyện mô hình học sinh trong 100 epoch sử dụng SGD với momentum (μ = 0.9) với kích thước batch 256 và lịch trình tốc độ học như sau. Đối với 5 epoch đầu tiên, chúng tôi tăng tuyến tính tốc độ học từ 0 đến 0.1, 30 epoch tiếp theo chúng tôi sử dụng tốc độ học 0.1, 30 epoch tiếp theo sau đó, chúng tôi sử dụng tốc độ học 0.01, 20 epoch tiếp theo chúng tôi sử dụng tốc độ học 0.001, và sử dụng tốc độ học 0.0001 cho các epoch còn lại. Chúng tôi sử dụng lật ngang ngẫu nhiên làm tăng cường dữ liệu.

Phương pháp Việc triển khai RAD, MARGIN, ENTROPY, và UNIFORM giống như trong đánh giá của chúng tôi về CIFAR10/100 và SVHN trong Mục 4. Tuy nhiên, các thuật toán Cluster Margin (CM) (Citovsky et al., 2021) và CORESET (Sener & Savarese, 2017) đòi hỏi các hoạt động phân cụm tốn kém và không thể áp dụng cho ImageNet ngay lập tức do hạn chế bộ nhớ và tính toán. Tuy nhiên, chúng tôi triển khai một phiên bản xấp xỉ của CM để hoàn thiện. Chúng tôi chọn CM thay vì CORESET vì nó hiện tại là tiên tiến và Citovsky et al. (2021) đã chứng minh rằng nó vượt trội hơn CORESET trong các cài đặt quy mô lớn. Đối với phiên bản xấp xỉ của CM, chúng tôi phân chia 1.1M hình ảnh thành các bucket có kích thước 10,000 và chạy phân cụm HAC trong mỗi bucket. Chúng tôi dừng khi số cụm được tạo ra đạt 500. Điều này dẫn đến tổng cộng 56,000 cụm, sau đó chúng tôi áp dụng thuật toán CM theo cách thông thường.

D.3 NGOÀI ĐỘ CHÍNH XÁC KIỂM TRA & SO SÁNH VỚI GREEDY

Chúng tôi điều tra hiệu suất của mô hình học sinh ngoài độ chính xác kiểm tra cuối cùng được báo cáo và xác minh tính hợp lệ của công thức vấn đề chúng tôi. Cụ thể, chúng tôi đặt câu hỏi (i) liệu phương pháp của chúng tôi cũng dẫn đến cải thiện độ chính xác học sinh qua tất cả các epoch trong quá trình huấn luyện và (ii) liệu nó thực sự đạt được lợi ích cao hơn đối với công thức chưng cất bền vững ((4), Mục 3) so với việc sử dụng thuật toán STANDARD MARGIN (tham lam) đơn giản chọn các điểm lợi ích cao nhất và lấy mẫu UNIFORM. Để kết thúc này, chúng tôi thực hiện đánh giá trên các bộ dữ liệu CIFAR10, CIFAR100, và SVHN tương tự như trong Mục 4, và báo cáo thêm độ chính xác kiểm tra qua mỗi epoch cho lần lặp chưng cất kiến thức cuối cùng và lợi ích thực hiện qua các lần lặp chưng cất tích cực.

Hình 5 tóm tắt kết quả thí nghiệm của chúng tôi cho các cấu hình chưng cất kiến thức khác nhau. Từ các hình, chúng tôi quan sát rằng phương pháp của chúng tôi đồng thời đạt được độ chính xác kiểm tra cuối cùng cao hơn (cột đầu tiên) và thường độ chính xác kiểm tra cao hơn trong toàn bộ quỹ đạo huấn luyện (cột thứ hai). Điều này gợi ý rằng những cải thiện chúng tôi có được từ phương pháp của chúng tôi là nhất quán và có mặt bất kể khi nào việc huấn luyện học sinh được kết thúc. Trong cột thứ ba của Hình 5, chúng tôi cũng quan sát rằng phương pháp của chúng tôi đạt được lợi ích thực hiện cao nhất trong số các phương pháp được đánh giá và lợi ích này có xu hướng là một dự đoán tốt về hiệu suất của phương pháp. Điều này làm sáng tỏ tại sao biến thể tham lam (STANDARD MARGIN) đơn giản chọn các điểm với biên thấp nhất (lợi ích cao nhất) không thành công nhất quán trong thực tế: các điểm lợi ích cao thường bị gắn nhãn sai bởi giáo viên, làm cho học sinh thêm bối rối. Điều này tiếp tục thúc đẩy công thức bền vững của chúng tôi trong Mục 3 và hỗ trợ tính thực tế của nó.

D.4 ÁP DỤNG RAD CHO HỌC TÍCH CỰC TIÊU CHUẨN

Ở đây, chúng tôi chứng minh khả năng áp dụng của RAD cho các cài đặt học tích cực tiêu chuẩn và so sánh hiệu suất của nó với các chiến lược SOTA. Điều này được thúc đẩy bởi công việc gần đây đã chứng minh rằng việc chọn các mẫu khó nhất hoặc có tính thông tin nhất - đối với một số liệu proxy - trên thực tế có thể cản trở việc huấn luyện mô hình (Paul et al., 2022; 2021). Ví dụ, trên CIFAR10, việc chọn các trường hợp khó nhất được quan sát là làm tổn hại việc huấn luyện, và chiến lược tốt nhất được tìm thấy là một chiến lược mà các điểm khó vừa phải được chọn (Paul et al., 2022; 2021). Phương pháp lấy mẫu này gợi nhớ đến các xác suất lấy mẫu được tạo ra bởi RAD như được mô tả trong Hình 2. Kết quả của các thí nghiệm được hiển thị trong Hình 6. RAD khớp hoặc cải thiện hiệu suất của các kỹ thuật tiên tiến.

Kết quả của các thí nghiệm học tích cực được hiển thị trong Hình 6. Vì không có mô hình giáo viên liên quan, chúng tôi khởi tạo RAD với m = 0.05n cho số lỗi của giáo viên. Điều này dựa trên các nghiên cứu thực nghiệm cho thấy khoảng 5% các điểm dữ liệu cố hữu quá khó (Paul et al., 2022; 2021) hoặc các ngoại lệ có thể làm hỏng việc huấn luyện. Việc đặt giá trị thích hợp cho m khi áp dụng RAD cho cài đặt học tích cực tiêu chuẩn vẫn là một câu hỏi mở, và là một hướng thú vị cho công việc tương lai. Kết quả trong Hình 6 cho thấy RAD cạnh tranh với các thuật toán học tích cực tiên tiến trong các tình huống được đánh giá và khớp hoặc cải thiện hiệu suất của kỹ thuật học tích cực hoạt động tốt nhất. Chúng tôi nhấn mạnh rằng, trái ngược với các phương pháp dựa trên phân cụm hiện có như CM hoặc Coreset, RAD đạt được hiệu suất này theo cách hiệu quả về tính toán và hoàn toàn không có tham số cho một m cho trước.

19

--- TRANG 19 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình 5: Độ chính xác cuối cùng của học sinh (cột đầu tiên), độ chính xác kiểm tra của học sinh qua quỹ đạo huấn luyện (cột thứ hai), và lợi ích thực hiện (cột thứ ba). Phương pháp của chúng tôi tạo ra các mô hình học sinh thường đạt được độ chính xác kiểm tra và lợi ích cao hơn đối với công thức trong Mục 3 qua các tình huống được đánh giá.

Hình 6: Đánh giá trong cài đặt học tích cực tiêu chuẩn.

20

--- TRANG 20 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

D.5 TÍNH BỀN VỮNG ĐỐI VỚI SỰ LỰA CHỌN CỦA W

Trong phần này, chúng tôi đánh giá tính bền vững của RAD bằng cách đánh giá hiệu suất của thuật toán với các khởi tạo khác nhau cho tham số w trên một loạt rộng các tình huống chưng cất trải dài các bộ dữ liệu CIFAR10, CIFAR100, và SVHN và các kiến trúc resnet học sinh-giáo viên khác nhau. Kết quả của các thí nghiệm so sánh RAD với cài đặt mặc định w = 1-m/n như mô tả trong Mục 3 (Ours) với các biến thể RAD với w∈{0.0,0.1,0.2,0.3,0.5,0.6,0.7,0.8,1.0} được hiển thị trong Hình 7. Kết quả được tính trung bình trên 5 lần thử. Như chúng ta có thể thấy từ hình, hiệu suất của RAD vẫn tương đối nhất quán (thường trong một độ lệch chuẩn) qua các lựa chọn khác nhau của w. Hơn nữa, lựa chọn có dẫn xuất lý thuyết w = 1-m/n luôn hoạt động tốt qua các tình huống được đánh giá - nó luôn trong một độ lệch chuẩn của w hoạt động tốt nhất cho mỗi tình huống.

Hình 7: So sánh hiệu suất của RAD với các cài đặt khác nhau của siêu tham số w so với OURS, sử dụng giá trị mặc định w = 1-m/n (tức là độ chính xác giáo viên). Hiệu suất chồng chéo của các khởi tạo khác nhau (trong vùng được tô màu của một độ lệch chuẩn) hỗ trợ tính bền vững của RAD đối với các cài đặt khác nhau của w∈[0,1].

21

--- TRANG 21 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

D.6 TÍNH BỀN VỮNG ĐỐI VỚI SỰ LỰA CHỌN CỦA GAIN

Trong các đánh giá thực nghiệm của chúng tôi, chúng tôi cho đến nay chỉ xem xét một định nghĩa cụ thể của lợi ích đối với biên của học sinh như mô tả trong Mục 3, tức là gi = 1-margini. Vì RAD thường có thể được sử dụng với bất kỳ khái niệm lợi ích do người dùng chỉ định nào, trong phần này chúng tôi điều tra hiệu suất của RAD khi entropy của dự đoán softmax học sinh fstudent(xi)∈[0,1]k được sử dụng để định nghĩa lợi ích, tức là,

gi = Entropy(fstudent(xi)) = -∑(j=1 to k) fstudent(xi)j log fstudent(xi)j.

Chúng tôi gắn nhãn thuật toán này RAD ENTROPY và so sánh hiệu suất của nó với biến thể của chúng tôi sử dụng biên học sinh.

Hình 8 hiển thị kết quả so sánh của chúng tôi với các cấu hình chưng cất, kiến trúc, và bộ dữ liệu khác nhau được tính trung bình trên 5 lần thử. Nhìn chung, chúng tôi quan sát rằng sự thay đổi trong định nghĩa lợi ích không dẫn đến thay đổi đáng kể (>một độ lệch chuẩn) trong hiệu suất.

D.7 TÍNH BỀN VỮNG ĐỐI VỚI CÁC CẤU HÌNH KHÁC NHAU

Trong phần này, chúng tôi xem xét tính bền vững của thuật toán chúng tôi đối với các cấu hình khác nhau trên một bộ dữ liệu cố định. Cụ thể, chúng tôi xem xét bộ dữ liệu SVHN (Netzer et al., 2011) và xem xét hiệu suất với kích thước khác nhau của mô hình học sinh (ResNetv2-{11, 20, 29}), kích thước của giáo viên (ResNetv2-{56, 110}), |A|∈{5000,10000,20000}, b∈{1000,2000,5000}, và số epoch e={100,200}. Do hạn chế tài nguyên, chúng tôi thực hiện so sánh rộng rãi với 2 thuật toán hoạt động tốt nhất từ phần chính của bài báo (Mục 4): (STANDARD) MARGIN và UNIFORM. Kết quả của các đánh giá cho thấy phương pháp của chúng tôi hoạt động tốt hơn đều đặn hoặc ít nhất là tốt như các phương pháp cạnh tranh.

22

--- TRANG 22 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình 8: So sánh RAD với lợi ích được định nghĩa đối với biên học sinh như trong Mục 3.1, OURS, với RAD với lợi ích được định nghĩa đối với entropy của dự đoán học sinh, RAD ENTROPY. Hiệu suất của RAD bền vững với khái niệm thay thế về độ bất định để định nghĩa lợi ích.

23

--- TRANG 23 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình 9: Kiến trúc ResNetv2-11 với 100 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

Hình 10: Kiến trúc ResNetv2-11 với 200 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

24

--- TRANG 24 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình 11: Kiến trúc ResNetv2-11 với 200 epoch và |A| = 10000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

Hình 12: Kiến trúc ResNetv2-11 với 200 epoch và |A| = 20000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

25

--- TRANG 25 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình 13: Kiến trúc ResNetv2-20 với 100 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

Hình 14: Kiến trúc ResNetv2-20 với 200 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

26

--- TRANG 26 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình 15: Kiến trúc ResNetv2-20 với 200 epoch và |A| = 10000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

Hình 16: Kiến trúc ResNetv2-29 với 200 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

27

--- TRANG 27 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

D.8 THÍÝ NGHIỆM VỚI CÁC MÔ HÌNH GIÁO VIÊN ĐƯỢC HUẤN LUYỆN TRƯỚC

Hình 17: Đánh giá với mô hình giáo viên ResNet được huấn luyện trước trên ImageNet và tinh chỉnh trên các bộ dữ liệu tương ứng. RAD hoạt động đều đặn ít nhất tốt như phương pháp so sánh tốt nhất, và thường tốt hơn đặc biệt trong chế độ mẫu thấp.

Trong phần này, chúng tôi trình bày đánh giá với các mô hình giáo viên ResNet50 và ResNet101 được huấn luyện trước trên ImageNet và tinh chỉnh trên dữ liệu được gắn nhãn có sẵn cho các bộ dữ liệu học thuật mà chúng tôi xem xét. Hình 17 mô tả kết quả đánh giá của chúng tôi trên các bộ dữ liệu CIFAR100 và SVHN. Phù hợp với xu hướng kết quả của chúng tôi trong Mục 4, RAD vượt trội đều đặn hoặc khớp hiệu suất của phương pháp so sánh hoạt động tốt nhất qua tất cả các tình huống.

D.9 ĐÁNH GIÁ NLP

Hình 18: Đánh giá trên bộ dữ liệu IMDB với mô hình học sinh BERT nhỏ và giáo viên BERT được huấn luyện trước.

Chúng tôi kết thúc kết quả bổ sung bằng cách trình bày đánh giá trên một tác vụ Xử lý Ngôn ngữ Tự nhiên (NLP) trên bộ dữ liệu IMDB Reviews (Maas et al., 2011) với mô hình giáo viên BERT được huấn luyện trước. Bộ dữ liệu IMDB có 25,000 điểm dữ liệu huấn luyện và 25,000 điểm dữ liệu kiểm tra, trong đó mỗi điểm dữ liệu là một đánh giá phim. Tác vụ là phân loại mỗi đánh giá là tích cực hoặc tiêu cực. Chúng tôi sử dụng một SmallBERT (Turc et al., 2019) 12 lớp được huấn luyện trước với chiều ẩn 768 làm mô hình giáo viên và một SmallBERT 2 lớp được khởi tạo ngẫu nhiên với chiều ẩn 128 làm học sinh. Từ Hình 18 chúng ta thấy rằng hiệu quả được cải thiện của RAD so với các phương pháp được so sánh vẫn tồn tại trên tác vụ NLP, phù hợp với đánh giá của chúng tôi trên các bộ dữ liệu thị giác. RAD đặc biệt hiệu quả trong chế độ mẫu nhỏ, nơi số điểm được gắn nhãn mềm nhỏ so với kích thước của bộ dữ liệu không được gắn nhãn.

28

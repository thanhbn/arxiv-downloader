# Cross-Domain Ensemble Distillation
# cho Domain Generalization
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/knowledge-distillation/2211.14058.pdf
# KÃ­ch thÆ°á»›c file: 3474070 bytes

===============================================
Ná»˜I DUNG FILE PDF
===============================================


--- TRANG 1 ---
Cross-Domain Ensemble Distillation
for Domain Generalization
Kyungmoon Lee1,2Sungyeon Kim1Suha Kwak1
1POSTECH, Pohang, Korea2NALBI Inc., Seoul, Korea
kyungmoon@nalbi.ai, {sungyeon.kim, suha.kwak }@postech.ac.kr
http://cvlab.postech.ac.kr/research/XDED/
TÃ³m táº¯t. Domain generalization lÃ  nhiá»‡m vá»¥ há»c cÃ¡c mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a Ä‘áº¿n cÃ¡c miá»n Ä‘Ã­ch chÆ°a tháº¥y. ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ cho domain generalization, Ä‘Æ°á»£c gá»i lÃ  cross-domain ensemble distillation (XDED), há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n Ä‘á»“ng thá»i khuyáº¿n khÃ­ch mÃ´ hÃ¬nh há»™i tá»¥ vá» flat minima, Ä‘iá»u mÃ  gáº§n Ä‘Ã¢y Ä‘Æ°á»£c chá»©ng minh lÃ  Ä‘iá»u kiá»‡n Ä‘á»§ cho domain generalization. Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u nÃ y, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i táº¡o ra má»™t ensemble tá»« cÃ¡c output logits cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n cÃ³ cÃ¹ng nhÃ£n nhÆ°ng tá»« cÃ¡c miá»n khÃ¡c nhau vÃ  sau Ä‘Ã³ pháº¡t má»—i output cho sá»± khÃ´ng khá»›p vá»›i ensemble. NgoÃ i ra, chÃºng tÃ´i trÃ¬nh bÃ y má»™t ká»¹ thuáº­t de-stylization chuáº©n hÃ³a cÃ¡c Ä‘áº·c trÆ°ng Ä‘á»ƒ khuyáº¿n khÃ­ch mÃ´ hÃ¬nh táº¡o ra cÃ¡c dá»± Ä‘oÃ¡n nháº¥t quÃ¡n vá» phong cÃ¡ch ngay cáº£ trong má»™t miá»n Ä‘Ã­ch tÃ¹y Ã½. PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a trong cÃ¡c benchmark cÃ´ng khai cho phÃ¢n loáº¡i áº£nh cross-domain, person re-ID cross-dataset, vÃ  semantic segmentation cross-dataset. HÆ¡n ná»¯a, chÃºng tÃ´i chá»‰ ra ráº±ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c há»c bá»Ÿi phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ kháº£ nÄƒng chá»‘ng láº¡i cÃ¡c cuá»™c táº¥n cÃ´ng adversarial vÃ  image corruptions.
Tá»« khÃ³a: domain generalization, knowledge distillation, flat minima

1 Giá»›i thiá»‡u
CÃ¡c máº¡ng neural sÃ¢u (DNNs) Ä‘Ã£ mang láº¡i nhá»¯ng tiáº¿n bá»™ Ä‘Ã¡ng ká»ƒ trong má»™t sá»‘ lÄ©nh vá»±c nghiÃªn cá»©u nhÆ° phÃ¢n loáº¡i áº£nh [43], tá»•ng há»£p áº£nh [24], vÃ  há»c tÄƒng cÆ°á»ng [54]. ThÃ nh cÃ´ng lá»›n cá»§a DNNs phá»¥ thuá»™c ráº¥t nhiá»u vÃ o giáº£ Ä‘á»‹nh ráº±ng dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra Ä‘Æ°á»£c láº¥y máº«u theo Ä‘iá»u kiá»‡n Ä‘á»™c láº­p vÃ  phÃ¢n phá»‘i Ä‘á»“ng nháº¥t (i.i.d.). Tuy nhiÃªn, giáº£ Ä‘á»‹nh nÃ y thÆ°á»ng khÃ´ng Ä‘Ãºng trong cÃ¡c tÃ¬nh huá»‘ng thá»±c táº¿; má»™t lá»—i lá»›n xáº£y ra do sá»± khÃ¡c biá»‡t giá»¯a dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra, cÃ²n Ä‘Æ°á»£c gá»i lÃ  váº¥n Ä‘á» domain shift. NhÆ° má»™t giáº£i phÃ¡p cho váº¥n Ä‘á» nÃ y, domain generalization, nhiá»‡m vá»¥ há»c cÃ¡c mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a Ä‘áº¿n cÃ¡c miá»n Ä‘Ã­ch chÆ°a tháº¥y, Ä‘ang Ä‘Æ°á»£c chÃº Ã½. Má»™t chÃ¬a khÃ³a cho thÃ nh cÃ´ng cá»§a domain generalization lÃ  há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n qua cÃ¡c miá»n. Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u nÃ y, háº§u háº¿t cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã¢y cÄƒn chá»‰nh phÃ¢n phá»‘i Ä‘áº·c trÆ°ng cá»§a nhiá»u miá»n báº±ng adversarial training [48,49], giáº£m thiá»ƒu sá»± khÃ¡c biá»‡t giá»¯a phÃ¢n phá»‘i cá»§a cÃ¡c miá»n nguá»“n [55], hoáº·c contrastive learning [40]. Sau Ä‘Ã³, má»™t bá»™ phÃ¢n loáº¡i Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ dá»± Ä‘oÃ¡n nhÃ£n cho cÃ¡c Ä‘áº·c trÆ°ng nguá»“n Ä‘Ã£ cÄƒn chá»‰nh vá»›i hy vá»ng ráº±ng nÃ³ cÅ©ng sáº½ tá»•ng quÃ¡t hÃ³a tá»‘t arXiv:2211.14058v1  [cs.CV]  25 Nov 2022

--- TRANG 2 ---
2 Kyungmoon Lee, Sungyeon Kim, Suha Kwak
Sketch
35.66%14.02%3.38%0.01%46.86%0.01%0.02%DogElephantGiraffeGuitarHorseHousePerson
Photo
1.48%0. 38%0. 32%0. 00%0.22%0.16%DogElephantGiraffeGuitarHorseHousePerson97.39%Art Painting
DogElephantGiraffeGuitarHorseHousePerson33.22%3.21%0.61%0.30%62.30%0.13%0.20%
Cartoon
8.03%2.16%17.04%2.82%55.82%13.77%0.32%DogElephantGiraffeGuitarHorseHousePerson23
DogElephantGiraffeGuitarHorseHousePerson19.59%4.94%5.33%0.78%65.59%0.17%3.53%
distilldistilldistilldistill
HÃ¬nh 1: Minh há»a cross-domain ensemble distillation (XDED). Máº·c dÃ¹ bá»‘n hÃ¬nh áº£nh cÃ³ cÃ¹ng nhÃ£n lá»›p, cÃ¡c dá»± Ä‘oÃ¡n cá»§a chÃºng thá»ƒ hiá»‡n cÃ¡c quan há»‡ inter-class khÃ¡c nhau do khoáº£ng cÃ¡ch thá»‹ giÃ¡c giá»¯a cÃ¡c miá»n. XDED xÃ¢y dá»±ng má»™t ensemble báº±ng cÃ¡ch láº¥y trung bÃ¬nh táº¥t cáº£ cÃ¡c dá»± Ä‘oÃ¡n vÃ  khá»›p nÃ³ vá»›i má»—i dá»± Ä‘oÃ¡n.

cho báº¥t ká»³ miá»n Ä‘Ã­ch nÃ o. Tuy nhiÃªn, cÃ¡ch tiáº¿p cáº­n nÃ y thÆ°á»ng giáº£m hiá»‡u suáº¥t khi miá»n Ä‘Ã­ch khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c miá»n nguá»“n vÃ¬ mÃ´ hÃ¬nh dá»… bá»‹ overfit vá»›i cÃ¡c miá»n nguá»“n.

Trong khi Ä‘Ã³, má»‘i quan há»‡ giá»¯a hÃ¬nh há»c cá»§a loss landscapes vÃ  kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a Ä‘Ã£ thu hÃºt sá»± chÃº Ã½ ngÃ y cÃ ng tÄƒng [18,20,36,38]. Äáº·c biá»‡t, há»™i tá»¥ vá» flat minima trong loss landscapes Ä‘Æ°á»£c biáº¿t Ä‘áº¿n nhÆ° má»™t chÃ¬a khÃ³a Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± robust chá»‘ng láº¡i sá»± dá»‹ch chuyá»ƒn loss landscape giá»¯a cÃ¡c táº­p dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra. ÄÆ°á»£c truyá»n cáº£m há»©ng tá»« quan sÃ¡t ráº±ng entropy posterior cao hÆ¡n giÃºp mÃ´ hÃ¬nh há»™i tá»¥ vá» flat minima [10,60,89], cÃ¡c ká»¹ thuáº­t regularization entropy nhÆ° self-knowledge distillation [87] vÃ  entropy maximization [9] Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ tÄƒng entropy thay vÃ¬ buá»™c mÃ´ hÃ¬nh pháº£i hoÃ n toÃ n fit vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n ( tá»©c lÃ , one-hot labels) Ä‘á»ƒ táº¡o ra entropy tháº¥p. VÃ¬ má»©c Ä‘á»™ dá»‹ch chuyá»ƒn loss landscape thÆ°á»ng Ä‘Æ°á»£c mong Ä‘á»£i lÃ  lá»›n hÆ¡n trong trÆ°á»ng há»£p domain generalization, viá»‡c há»™i tá»¥ vá» flat minima trong domain generalization lÃ  quan trá»ng hÆ¡n. Tuy nhiÃªn, lá»£i Ã­ch cá»§a flat minima vá» domain generalization váº«n chÆ°a Ä‘Æ°á»£c nghiÃªn cá»©u tÃ­ch cá»±c.

Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p má»›i, Ä‘Æ°á»£c gá»i lÃ  cross-domain ensemble distillation (XDED), há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n Ä‘á»“ng thá»i khuyáº¿n khÃ­ch há»™i tá»¥ vá» flat minima cho domain generalization. Cá»¥ thá»ƒ, XDED táº¡o ra má»™t ensemble tá»« cÃ¡c output logits cho dá»¯ liá»‡u cÃ³ cÃ¹ng nhÃ£n nhÆ°ng tá»« cÃ¡c miá»n khÃ¡c nhau, vÃ  sau Ä‘Ã³ pháº¡t má»—i output cho sá»± khÃ´ng khá»›p vá»›i ensemble (HÃ¬nh 1). Báº±ng cÃ¡ch lÃ m váº­y, nÃ³ cho phÃ©p mÃ´ hÃ¬nh há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n báº±ng cÃ¡ch thá»±c thi tÃ­nh nháº¥t quÃ¡n dá»± Ä‘oÃ¡n giá»¯a dá»¯ liá»‡u cÃ³ cÃ¹ng nhÃ£n nhÆ°ng tá»« cÃ¡c miá»n khÃ¡c nhau. NgoÃ i ra, XDED tÄƒng entropy posterior cá»§a má»—i phÃ¢n phá»‘i output, Ä‘iá»u nÃ y giÃºp mÃ´ hÃ¬nh há»™i tá»¥ vá» flat minima nhÆ° entropy regularization lÃ m. Theo hiá»ƒu biáº¿t tá»‘t nháº¥t cá»§a chÃºng tÃ´i, XDED lÃ  phÆ°Æ¡ng phÃ¡p Ä‘áº§u tiÃªn Ä‘áº¡t Ä‘Æ°á»£c hai má»¥c tiÃªu nÃ y Ä‘á»“ng thá»i cho domain generalization, vÃ  Ä‘Ã³ng gÃ³p nÃ y dáº«n Ä‘áº¿n cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ.

--- TRANG 3 ---
Cross-Domain Ensemble Distillation for Domain Generalization 3

VÃ¬ XDED váº«n bá»‹ giá»›i háº¡n trong viá»‡c khai thÃ¡c thÃ´ng tin chá»‰ tá»« cÃ¡c miá»n nguá»“n, váº«n cÃ²n chá»— Ä‘á»ƒ giáº£m domain gap vá»›i miá»n Ä‘Ã­ch. Do Ä‘Ã³, chÃºng tÃ´i cÅ©ng giá»›i thiá»‡u má»™t ká»¹ thuáº­t de-stylization phÃ¹ há»£p vá»›i domain generalization, Ä‘Æ°á»£c gá»i lÃ  UniStyle. UniStyle ngÄƒn cháº·n bias phong cÃ¡ch Ä‘áº·c trÆ°ng miá»n Ä‘Æ¡n giáº£n báº±ng cÃ¡ch chuáº©n hÃ³a cÃ¡c feature maps trung gian cá»§a áº£nh Ä‘áº§u vÃ o trong cáº£ quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  kiá»ƒm tra. Nhá» UniStyle, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i táº¡o ra cÃ¡c dá»± Ä‘oÃ¡n nháº¥t quÃ¡n vá» phong cÃ¡ch khÃ´ng chá»‰ cho cÃ¡c miá»n nguá»“n mÃ  cÃ²n cho miá»n Ä‘Ã­ch, Ä‘iá»u nÃ y giáº£m Ä‘Ã¡ng ká»ƒ domain gap vÃ  tÄƒng cÆ°á»ng hiá»‡u á»©ng cá»§a XDED.

Dá»±a trÃªn káº¿t quáº£ lÃ½ thuyáº¿t gáº§n Ä‘Ã¢y vá» má»‘i quan há»‡ giá»¯a domain generalization vÃ  tÃ­nh pháº³ng cá»§a local minima [8], chÃºng tÃ´i trÆ°á»›c tiÃªn chá»©ng minh thá»±c nghiá»‡m ráº±ng framework Ä‘Æ°á»£c Ä‘á» xuáº¥t cÃ³ thá»ƒ cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a báº±ng cÃ¡ch Ä‘áº¡t Ä‘Æ°á»£c hai má»¥c tiÃªu: thÃºc Ä‘áº©y flat minima vÃ  giáº£m domain gap. Tiáº¿p theo, chÃºng tÃ´i tiáº¿p tá»¥c chá»©ng minh tÃ­nh Æ°u viá»‡t cá»§a phÆ°Æ¡ng phÃ¡p thÃ´ng qua káº¿t quáº£ thá»±c nghiá»‡m má»Ÿ rá»™ng. TrÃªn cÃ¡c benchmark cÃ´ng khai tiÃªu chuáº©n cho phÃ¢n loáº¡i áº£nh cross-domain, XDED tÄƒng cÆ°á»ng Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a trong cáº£ cÃ i Ä‘áº·t multi-source vÃ  single-source. ChÃºng tÃ´i cÅ©ng xÃ¡c thá»±c hiá»‡u quáº£ cá»§a phÆ°Æ¡ng phÃ¡p trong cÃ¡c tÃ¬nh huá»‘ng domain generalization khÃ¡c nhau báº±ng cÃ¡ch cho tháº¥y cáº£i thiá»‡n khÃ´ng táº§m thÆ°á»ng trÃªn DomainBed [26], person re-ID cross-dataset [90,91], vÃ  cÃ¡c thá»±c nghiá»‡m semantic segmentation cross-dataset. HÆ¡n ná»¯a, chÃºng tÃ´i chá»©ng minh ráº±ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c há»c bá»Ÿi phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÅ©ng giÃºp Ä‘áº¡t Ä‘Æ°á»£c sá»± robust chá»‘ng láº¡i cÃ¡c cuá»™c táº¥n cÃ´ng adversarial vÃ  image corruptions chÆ°a tháº¥y.

2 CÃ¡c CÃ´ng trÃ¬nh LiÃªn quan

Domain generalization. Má»¥c tiÃªu cá»§a domain generalization lÃ  há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n tá»•ng quÃ¡t hÃ³a tá»‘t Ä‘áº¿n cÃ¡c miá»n Ä‘Ã­ch chÆ°a tháº¥y. Äá»ƒ Ä‘áº¡t má»¥c Ä‘Ã­ch nÃ y, cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ khá»›p phÃ¢n phá»‘i Ä‘áº·c trÆ°ng cá»§a cÃ¡c miá»n khÃ¡c nhau báº±ng adversarial feature alignment [48,49] hoáº·c giáº£m sá»± khÃ¡c biá»‡t giá»¯a phÃ¢n phá»‘i Ä‘áº·c trÆ°ng cá»§a cÃ¡c miá»n nguá»“n Ä‘a dáº¡ng [55]. Gáº§n Ä‘Ã¢y, cÃ¡c framework meta-learning [2,16,47] Ä‘Ã£ Ä‘Æ°á»£c giá»›i thiá»‡u Ä‘á»ƒ mÃ´ phá»ng domain shift báº±ng cÃ¡ch chia cÃ¡c miá»n meta-train vÃ  meta-test tá»« cÃ¡c miá»n nguá»“n. NgoÃ i ra, cÃ¡c phÆ°Æ¡ng phÃ¡p data augmentation Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ táº¡o ra dá»¯ liá»‡u Ä‘a dáº¡ng hÆ¡n ngoÃ i nhá»¯ng dá»¯ liá»‡u cá»§a cÃ¡c miá»n nguá»“n Ä‘Ã£ cho [37,41,66,77,93]. Giá»‘ng nháº¥t vá»›i framework cá»§a chÃºng tÃ´i, cÃ¡c phÆ°Æ¡ng phÃ¡p ensemble cho domain generalization Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t [79,65,94]. Táº¥t cáº£ Ä‘á»u huáº¥n luyá»‡n nhiá»u modules nhÆ° exemplar SVMs [79], cÃ¡c lá»›p domain-specific BN [34] [65] hoáº·c classifiers [94], vÃ  khai thÃ¡c ensemble cá»§a cÃ¡c modules Ä‘Ã£ há»c Ä‘á»ƒ dá»± Ä‘oÃ¡n trong quÃ¡ trÃ¬nh kiá»ƒm tra. Tuy nhiÃªn, chÃºng tÃ´i nháº¥n máº¡nh ráº±ng XDED cá»§a chÃºng tÃ´i sá»­ dá»¥ng ensemble cá»§a cÃ¡c dá»± Ä‘oÃ¡n mÃ´ hÃ¬nh nhÆ° soft label vÃ  chuyá»ƒn nÃ³ Ä‘áº¿n chÃ­nh mÃ´ hÃ¬nh. Do Ä‘Ã³, nÃ³ khÃ´ng yÃªu cáº§u báº¥t ká»³ module bá»• sung nÃ o trong cáº£ quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  kiá»ƒm tra.

Knowledge distillation (KD). KD ban Ä‘áº§u Ä‘Æ°á»£c nghiÃªn cá»©u Ä‘á»ƒ chuyá»ƒn kiáº¿n thá»©c cá»§a má»™t mÃ´ hÃ¬nh sÃ¢u Ä‘áº¿n má»™t mÃ´ hÃ¬nh nÃ´ng Ä‘á»ƒ nÃ©n mÃ´ hÃ¬nh [31]. NÃ³ cÅ©ng Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c má»¥c Ä‘Ã­ch khÃ¡c nhÆ° metric learning [59,42] vÃ 

--- TRANG 4 ---
4 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

network regularization [78,87,84]. Äáº·c biá»‡t cho network regularization, self-knowledge distillation (self-KD) Ä‘Ã£ Ä‘Æ°á»£c nghiÃªn cá»©u; nÃ³ chÆ°ng cáº¥t kiáº¿n thá»©c tá»« chÃ­nh mÃ´ hÃ¬nh vÃ  thá»±c thi tÃ­nh nháº¥t quÃ¡n dá»± Ä‘oÃ¡n giá»¯a má»™t máº«u vÃ  máº«u bá»‹ nhiá»…u cá»§a nÃ³ hoáº·c cÃ¡c máº«u khÃ¡c. KD Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng cho domain adaptation [52,19], vÃ  phÆ°Æ¡ng phÃ¡p nhÆ° váº­y huáº¥n luyá»‡n nhiá»u teacher models tá»« cÃ¡c miá»n nguá»“n vÃ  chÆ°ng cáº¥t ensemble cá»§a cÃ¡c dá»± Ä‘oÃ¡n cá»§a chÃºng Ä‘áº¿n student model. Tháº­t khÃ´ng may, nÃ³ Ä‘Ã²i há»i bá»™ nhá»› lá»›n do nhiá»u teachers, vÃ  khÃ³ má»Ÿ rá»™ng cho domain generalization vÃ¬ chÃºng yÃªu cáº§u áº£nh Ä‘Ã­ch trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. NgÆ°á»£c láº¡i, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a mÃ´ hÃ¬nh trÃªn cÃ¡c miá»n chÆ°a tháº¥y mÃ  khÃ´ng cáº§n áº£nh Ä‘Ã­ch vÃ  cÃ¡c teacher models bá»• sung.

Flat minima trong loss landscapes. CÃ¡c phÃ¢n tÃ­ch gáº§n Ä‘Ã¢y Ä‘Ã£ tiáº¿t lá»™ ráº±ng tÃ¬m flat minima lÃ  quan trá»ng cho tá»•ng quÃ¡t hÃ³a mÃ´ hÃ¬nh [38,18,20]. Trong bá»‘i cáº£nh nÃ y, nhiá»u phÆ°Æ¡ng phÃ¡p Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ thÃºc Ä‘áº©y flat minima trong loss landscapes vÃ¬ flat minima cÃ³ lá»£i tháº¿ so vá»›i sharp minima trong kháº£ nÄƒng robust chá»‘ng láº¡i sá»± dá»‹ch chuyá»ƒn loss landscape giá»¯a dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra. Trong sá»‘ cÃ¡c tÃ i liá»‡u vá» cÃ¡ch thÃºc Ä‘áº©y flat minima ( vÃ­ dá»¥, weight averaging [35,8] vÃ  training strategies [20,10]), chÃºng tÃ´i táº­p trung vÃ o cÃ¡c cÃ¡ch tiáº¿p cáº­n tÃ¬m kiáº¿m entropy cao, mÃ  XDED dá»±a trÃªn. Maximum Entropy [60,9] tá»‘i Ä‘a hÃ³a entropy cá»§a phÃ¢n phá»‘i output tá»« má»™t classifier. TÆ°Æ¡ng tá»±, cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn KD cÅ©ng nháº±m táº¡o ra entropy cao cá»§a phÃ¢n phá»‘i output báº±ng cÃ¡ch pháº¡t sá»± khÃ´ng khá»›p vá»›i phÃ¢n phá»‘i output tá»« classifier khÃ¡c nhÆ° cÃ¡c peer networks Ä‘Æ°á»£c khá»Ÿi táº¡o khÃ¡c nhau [89] hoáº·c cÃ¡c subnetworks trong chÃ­nh máº¡ng [87]. Máº·c dÃ¹ SWAD [8] Ä‘Ã£ giá»›i thiá»‡u táº§m quan trá»ng cá»§a flat minima trong lÄ©nh vá»±c domain generalization, chÃºng tÃ´i nháº¥n máº¡nh ráº±ng SWAD thuá»™c vá» weight averaging nhÆ°ng khÃ´ng táº­p trung vÃ o há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n, trong khi XDED thuá»™c vá» entropy regularization cÅ©ng nhÆ° Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n.

Bias hÆ°á»›ng vá» styles. CÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y [6,22] tiáº¿t lá»™ ráº±ng DNNs phá»¥ thuá»™c quÃ¡ má»©c vÃ o bias máº¡nh hÆ°á»›ng vá» styles, vÃ  Ä‘iá»u nÃ y cÅ©ng Ä‘Æ°á»£c xÃ¡c nháº­n trong tÃ i liá»‡u domain generalization [12,95,37] ráº±ng má»™t miá»n thá»‹ giÃ¡c cÃ³ má»‘i tÆ°Æ¡ng quan cao vá»›i thá»‘ng kÃª Ä‘áº·c trÆ°ng. Do Ä‘Ã³, cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y Ä‘á»‹nh nghÄ©a styles áº£nh nhÆ° bias vÃ  cá»‘ gáº¯ng loáº¡i bá» bias báº±ng style augmentation trong khÃ´ng gian thá»‘ng kÃª Ä‘áº·c trÆ°ng [95,37], sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh khÃ¡c cá»‘ Ã½ thiÃªn vá» styles [56], hoáº·c giáº£m thiá»ƒu whitening loss [12]. KhÃ¡c biá»‡t vá»›i cÃ¡c ká»¹ thuáº­t nÃ y, chÃºng tÃ´i chá»‰ ra ráº±ng má»™t ká»¹ thuáº­t de-stylization Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ dáº«n Ä‘áº¿n má»™t thÆ°á»›c Ä‘o divergence nhá» hÆ¡n giá»¯a cÃ¡c miá»n Ä‘Ã­ch vÃ  nguá»“n mÃ  khÃ´ng cáº§n phá»©c táº¡p.

3 PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i

3.1 Cross-Domain Ensemble Distillation

Ã”n láº¡i knowledge distillation (KD). Má»¥c tiÃªu cá»§a KD [31] lÃ  chuyá»ƒn kiáº¿n thá»©c cá»§a má»™t teacher model t Ä‘áº¿n má»™t student model s, thÆ°á»ng lÃ  má»™t mÃ´ hÃ¬nh rá»™ng vÃ  sÃ¢u Ä‘áº¿n má»™t mÃ´ hÃ¬nh nhá» hÆ¡n, cho má»¥c Ä‘Ã­ch nÃ©n mÃ´ hÃ¬nh hoáº·c regularization mÃ´ hÃ¬nh. Cho Ä‘iá»ƒm dá»¯ liá»‡u Ä‘áº§u vÃ o x vÃ  nhÃ£n yâˆˆ {1,Â·Â·Â·, C} cá»§a nÃ³, chÃºng tÃ´i kÃ½ hiá»‡u output logit cá»§a mÃ´ hÃ¬nh lÃ  z(x) = [z1(x),Â·Â·Â·, zC(x)]. PhÃ¢n phá»‘i dá»± Ä‘oÃ¡n posterior cá»§a x sau Ä‘Ã³ Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ°:

--- TRANG 5 ---
Cross-Domain Ensemble Distillation for Domain Generalization 5

P(y|x;Î¸, Ï„) =exp(zy(x)/Ï„)PC
i=1exp(zi(x)/Ï„), (1)

trong Ä‘Ã³ mÃ´ hÃ¬nh Ä‘Æ°á»£c tham sá»‘ hÃ³a bá»Ÿi Î¸ vÃ  Ï„ lÃ  tham sá»‘ scaling nhiá»‡t Ä‘á»™.
KD thá»±c thi Ä‘á»ƒ khá»›p cÃ¡c phÃ¢n phá»‘i dá»± Ä‘oÃ¡n cá»§a s vÃ  t. Cá»¥ thá»ƒ, nÃ³ Ä‘Æ°á»£c Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch giáº£m thiá»ƒu Kullback-Leibler (KL) divergence giá»¯a cÃ¡c phÃ¢n phá»‘i dá»± Ä‘oÃ¡n cá»§a chÃºng nhÆ° sau:

LKD(X;Î¸s, Ï„) =X
xiâˆˆXCX
c=1DKL(P(c|xi;Î¸t, Ï„)||P(c|xi;Î¸s, Ï„)), (2)

trong Ä‘Ã³ X lÃ  má»™t batch dá»¯ liá»‡u Ä‘áº§u vÃ o, Î¸t vÃ  Î¸s láº§n lÆ°á»£t lÃ  cÃ¡c tham sá»‘ cá»§a teacher vÃ  student.

Cross-domain ensemble distillation. ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p KD má»›i cho domain generalization, Ä‘Æ°á»£c gá»i lÃ  cross-domain ensemble distillation (XDED). XDED nháº±m xÃ¢y dá»±ng kiáº¿n thá»©c báº¥t biáº¿n miá»n tá»« dá»¯ liá»‡u cá»§a nhiá»u miá»n. Cá»¥ thá»ƒ, XDED táº¡o ra má»™t ensemble cá»§a logits tá»« dá»¯ liá»‡u cÃ³ cÃ¹ng nhÃ£n nhÆ°ng tá»« cÃ¡c miá»n khÃ¡c nhau. Tiáº¿p theo, XDED pháº¡t má»—i logit cho sá»± khÃ´ng khá»›p vá»›i ensemble khÃ´ng thiÃªn vá» má»™t miá»n cá»¥ thá»ƒ, Ä‘iá»u nÃ y khuyáº¿n khÃ­ch há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n. KhÃ´ng giá»‘ng nhÆ° KD thÃ´ng thÆ°á»ng, XDED khÃ´ng yÃªu cáº§u má»™t máº¡ng bá»• sung lÃ m tÄƒng Ä‘á»™ phá»©c táº¡p huáº¥n luyá»‡n ( vÃ­ dá»¥, tham sá»‘ thÃªm vÃ  thá»i gian huáº¥n luyá»‡n) mÃ  chÆ°ng cáº¥t ensemble Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi nhiá»u máº«u Ä‘áº¿n chÃ­nh mÃ´ hÃ¬nh dÆ°á»›i dáº¡ng self-KD.

ChÃ­nh thá»©c, gá»i Xy lÃ  táº­p há»£p cÃ¡c máº«u cÃ³ cÃ¹ng nhÃ£n lá»›p y trong má»™t mini-batch. Sau Ä‘Ã³, chÃºng tÃ´i thu Ä‘Æ°á»£c má»™t ensemble cá»§a logits tá»« Xy báº±ng cÃ¡ch Ä‘Æ¡n giáº£n láº¥y trung bÃ¬nh nhÆ°:

Â¯z(Xy) =X
xiâˆˆXyz(xi)
|Xy|. (3)

Sau Ä‘Ã³, phÃ¢n phá»‘i dá»± Ä‘oÃ¡n cho ensemble Ä‘Æ°á»£c táº¡o tá»« dá»¯ liá»‡u Xy lÃ :

Â¯P(c|Xy;Î¸, Ï„) =exp(Â¯zc(Xy)/Ï„)PC
i=1exp(Â¯zi(Xy)/Ï„), (4)

HÃ m loss cá»§a XDED Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° sau:

LXDED (Xy;Î¸, Ï„) =X
xiâˆˆXyCX
c=1DKL(Â¯P(c|Xy;Ë†Î¸, Ï„)||P(c|xi;Î¸, Ï„)), (5)

trong Ä‘Ã³ Ë†Î¸ lÃ  má»™t báº£n sao cá»‘ Ä‘á»‹nh cá»§a tham sá»‘ Î¸. Theo [53,84], chÃºng tÃ´i dá»«ng gradient Ä‘Æ°á»£c truyá»n qua Ë†Î¸ Ä‘á»ƒ ngÄƒn mÃ´ hÃ¬nh rÆ¡i vÃ o má»™t sá»‘ giáº£i phÃ¡p táº§m thÆ°á»ng. TÃ³m láº¡i, chÃºng tÃ´i Ä‘áº·t hÃ m má»¥c tiÃªu cá»§a chÃºng tÃ´i nhÆ°

min
Î¸LÎ¸=LCE(X, Y ;Î¸) +Î»X
yâˆˆ{Y}LXDED (Xy;Î¸, Ï„),(6)

--- TRANG 6 ---
6 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

trong Ä‘Ã³ X lÃ  má»™t batch áº£nh Ä‘áº§u vÃ o, Y lÃ  má»™t batch nhÃ£n lá»›p tÆ°Æ¡ng á»©ng, LCE kÃ½ hiá»‡u vanilla cross-entropy loss, vÃ  Î» lÃ  má»™t siÃªu tham sá»‘ Ä‘á»ƒ cÃ¢n báº±ng LCE vÃ  LXDED. Î» vÃ  Ï„ láº§n lÆ°á»£t lÃ  5.0 vÃ  4.0 trong suá»‘t bÃ i bÃ¡o nÃ y.

3.2 UniStyle: loáº¡i bá» vÃ  thá»‘ng nháº¥t style bias

Äá»ƒ tiáº¿p tá»¥c regularize mÃ´ hÃ¬nh táº¡o ra cÃ¡c dá»± Ä‘oÃ¡n nháº¥t quÃ¡n vá» phong cÃ¡ch, chÃºng tÃ´i Ä‘á» xuáº¥t má»™t ká»¹ thuáº­t de-stylization phÃ¹ há»£p vá»›i domain generalization. VÃ¬ cÃ¡c styles miá»n nguá»“n khÃ´ng Ä‘Æ°á»£c mong Ä‘á»£i xuáº¥t hiá»‡n táº¡i thá»i Ä‘iá»ƒm kiá»ƒm tra, chÃºng tÃ´i Ä‘á» xuáº¥t UniStyle Ä‘á»ƒ ngÄƒn mÃ´ hÃ¬nh bá»‹ thiÃªn vá» cÃ¡c styles Ä‘áº·c trÆ°ng miá»n, Ä‘iá»u nÃ y giáº£m domain gap vá»›i miá»n Ä‘Ã­ch.

Cá»¥ thá»ƒ hÆ¡n, theo cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ dá»±a trÃªn style transfer [17,32,70], chÃºng tÃ´i trÆ°á»›c tiÃªn biá»ƒu diá»…n neural style nhÆ° thá»‘ng kÃª cá»§a cÃ¡c feature maps trung gian tá»« feature extractor. ChÃ­nh thá»©c, gá»i FâˆˆRCÃ—HÃ—W kÃ½ hiá»‡u má»™t feature map trung gian cá»§a má»™t áº£nh. Sau Ä‘Ã³, neural style cá»§a áº£nh Ä‘Æ°á»£c biá»ƒu diá»…n nhÆ° sá»± káº¿t há»£p cá»§a mean Î¼(F)âˆˆRC theo tá»«ng kÃªnh vÃ  standard deviation Ïƒ(F)âˆˆRC cá»§a F nhÆ°:

Î¼c(F) =1
HWHX
h=1WX
w=1Fc,h,w, (7)

vÃ 

Ïƒc(F) =vuut1
HWHX
h=1WX
w=1(Fc,h,wâˆ’Î¼c(F))2, (8)

trong Ä‘Ã³ Î¼(F) = [ Î¼1(F),Â·Â·Â·, Î¼C(F)] vÃ  Ïƒ(F) = [ Ïƒ1(F),Â·Â·Â·, ÏƒC(F)]. Tiáº¿p theo, chÃºng tÃ´i Ä‘Æ¡n giáº£n chuáº©n hÃ³a má»—i Ä‘áº·c trÆ°ng Ä‘á»ƒ cÃ³ thá»‘ng kÃª theo tá»«ng kÃªnh khÃ´ng Ä‘á»•i, Î¼W vÃ  ÏƒW nhÆ°:

UniStyle( F) =ÏƒWFâˆ’Î¼(F)
Ïƒ(F)+Î¼W, (9)

trong Ä‘Ã³ Î¼W=0 vÃ  ÏƒW=1(tá»©c lÃ , chuáº©n hÃ³a zero-mean). Vá» máº·t ká»¹ thuáº­t, UniStyle lÃ  má»™t trÆ°á»ng há»£p Ä‘áº·c biá»‡t cá»§a InstanceNorm (IN) [70]. Tuy nhiÃªn, chÃºng tÃ´i nháº¥n máº¡nh ráº±ng UniStyle nháº±m loáº¡i bá» thÃ´ng tin Ä‘áº·c trÆ°ng miá»n mÃ  khÃ´ng cÃ³ báº¥t ká»³ tham sá»‘ há»c Ä‘Æ°á»£c nÃ o Ä‘á»ƒ giáº£m domain gap trong khi IN há»c cÃ¡c tham sá»‘ scaling vÃ  bias theo tá»«ng kÃªnh cho style transfer. NgoÃ i ra, lÆ°u Ã½ ráº±ng chÃºng tÃ´i quan sÃ¡t thá»±c nghiá»‡m ráº±ng UniStyle hiá»‡u quáº£ khi Ä‘Æ°á»£c Ã¡p dá»¥ng táº¡i nhiá»u lá»›p sá»›m, Ä‘iá»u nÃ y phÃ¹ há»£p vá»›i cÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y [17,32] cho ráº±ng thÃ´ng tin style thÆ°á»ng Ä‘Æ°á»£c náº¯m báº¯t táº¡i cÃ¡c lá»›p sá»›m.1

3.3 PhÃ¢n tÃ­ch PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i

Trong pháº§n nÃ y, chÃºng tÃ´i phÃ¢n tÃ­ch hiá»‡u quáº£ cá»§a XDED, Ä‘áº·c biá»‡t thÃ´ng qua liÃªn káº¿t vá»›i káº¿t quáº£ lÃ½ thuyáº¿t vÃ  cÃ¡c báº±ng chá»©ng thá»±c nghiá»‡m há»— trá»£. ChÃºng tÃ´i trÆ°á»›c tiÃªn báº¯t Ä‘áº§u vá»›i má»™t Ä‘á»‹nh lÃ½ liÃªn quan Ä‘áº¿n domain adaptation [3,4], cho tháº¥y ráº±ng

1Xem tÃ i liá»‡u bá»• sung Ä‘á»ƒ phÃ¢n tÃ­ch thÃªm.

--- TRANG 7 ---
Cross-Domain Ensemble Distillation for Domain Generalization 7

Báº£ng 1: So sÃ¡nh cÃ¡c giÃ¡ trá»‹ entropy. Khi má»—i mÃ´ hÃ¬nh há»™i tá»¥, giÃ¡ trá»‹ entropy Ä‘Æ°á»£c tÃ­nh báº±ng cÃ¡ch láº¥y trung bÃ¬nh trÃªn táº¥t cáº£ cÃ¡c máº«u huáº¥n luyá»‡n.

OfficeHome (Clipart) PACS (Cartoon)
PhÆ°Æ¡ng phÃ¡p Entropy Accuracy Entropy Accuracy
ResNet-18 0.25 49.4 0.01 75.9
MixStyle [95] 0.35 53.4 0.03 78.8
XDED 0.92 55.2 0.38 81.7

rá»§i ro mong Ä‘á»£i trÃªn miá»n Ä‘Ã­ch Ä‘Æ°á»£c giá»›i háº¡n bá»Ÿi rá»§i ro trÃªn miá»n nguá»“n vÃ  divergence giá»¯a cÃ¡c miá»n nÃ y. Äá»ƒ tÃ¬m má»™t tham sá»‘ mÃ´ hÃ¬nh Î¸âˆˆÎ˜ cho domain generalization, Cha et al. [8] Ä‘Ã£ xem xÃ©t má»™t robust empirical loss:

Ë†ÎµÎ³
S(Î¸) := max
||âˆ†||â‰¤Î³Ë†ÎµS(Î¸+âˆ†)(10)

trong Ä‘Ã³ Ë† ÎµS(Î¸) lÃ  empirical risk trÃªn cÃ¡c miá»n nguá»“n S vÃ  Î³ lÃ  bÃ¡n kÃ­nh Ä‘á»‹nh nghÄ©a cÃ¡c tham sá»‘ lÃ¡ng giá»ng cá»§a Î¸. Sau Ä‘Ã³, Cha et al. [8] Ä‘Ã£ chá»©ng minh ráº±ng tÃ¬m flat minima giáº£m domain gap thÃ´ng qua Ä‘á»‹nh lÃ½ dÆ°á»›i Ä‘Ã¢y:

Äá»‹nh lÃ½ 1. Xem xÃ©t má»™t táº­p há»£p N covers {Î˜k}N
k=1 sao cho khÃ´ng gian giáº£ thuyáº¿t Î˜âŠ‚ âˆªN
kÎ˜k trong Ä‘Ã³ diam (Î˜) := supÎ¸,Î¸â€²âˆˆÎ˜||Î¸âˆ’Î¸â€²||2, N:=âŒˆ(diam (Î˜)/Î³)dâŒ‰ vÃ  d lÃ  chiá»u cá»§a Î˜. Gá»i vk lÃ  VC dimension cá»§a má»—i Î˜k. Sau Ä‘Ã³, vá»›i báº¥t ká»³ Î¸âˆˆÎ˜, ranh giá»›i sau Ä‘Ã¢y giá»¯ vá»›i xÃ¡c suáº¥t Ã­t nháº¥t 1âˆ’Î´,

ÎµT(Î¸)<Ë†ÎµÎ³
S(Î¸) +1
2IIX
i=1Div(Si, T) + max
kâˆˆ[1,N]r
vkln (m/v k) + ln ( N/Î´)
m,(11)

trong Ä‘Ã³ m=nI lÃ  sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n vÃ  Div (Si, T) lÃ  divergence giá»¯a miá»n nguá»“n Si vÃ  miá»n Ä‘Ã­ch T.

ChÃºng tÃ´i nháº¥n máº¡nh ráº±ng, trong Eq. (11), test loss ÎµT(Î¸) Ä‘Æ°á»£c giá»›i háº¡n bá»Ÿi ba thÃ nh pháº§n: (1) robust empirical loss Ë† ÎµÎ³
S(Î¸), (2) divergence Div( Si, T), vÃ  (3) confidence bound phá»¥ thuá»™c vÃ o bÃ¡n kÃ­nh Î³ vÃ  sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n m. Trong pháº§n cÃ²n láº¡i cá»§a pháº§n nÃ y, theo Ä‘á»‹nh lÃ½ trÃªn, chÃºng tÃ´i cung cáº¥p má»™t giáº£i thÃ­ch lÃ½ thuyáº¿t ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i tÄƒng cÆ°á»ng kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a báº±ng cÃ¡ch giáº£m cáº£ Ë† ÎµÎ³
S(Î¸) vÃ  Div( Si, T) vá»›i cÃ¡c báº±ng chá»©ng thá»±c nghiá»‡m.

ThÃºc Ä‘áº©y flat minima. ChÃºng tÃ´i nháº¥n máº¡nh ráº±ng XDED Ä‘Æ°á»£c thÃºc Ä‘áº©y bá»Ÿi cÃ¡c phÆ°Æ¡ng phÃ¡p entropy regularization gáº§n Ä‘Ã¢y [9,87,89] trong viá»‡c theo Ä‘uá»•i flat minima. NÃ³ Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh thá»±c nghiá»‡m ráº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y thÃºc Ä‘áº©y flat minima báº±ng cÃ¡ch táº¡o ra entropy posterior cao hÆ¡n. NÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu nhÆ° lÃ m dá»‹u quÃ¡ trÃ¬nh huáº¥n luyá»‡n Ä‘á»ƒ há»c thÃ´ng tin phong phÃº hÆ¡n Ä‘Æ°á»£c mÃ£ hÃ³a trong soft labels, Ä‘iá»u nÃ y giÃºp mÃ´ hÃ¬nh há»™i tá»¥ vá» flat minima hÆ¡n lÃ  buá»™c mÃ´ hÃ¬nh hoÃ n toÃ n fit vá»›i one-hot labels. Trong bá»‘i cáº£nh nÃ y, chÃºng tÃ´i cÅ©ng chá»©ng minh ráº±ng XDED rÃµ rÃ ng táº¡o ra entropy cao hÆ¡n nhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng 1. Xem xÃ©t ráº±ng XDED Ä‘Æ°á»£c thÃºc Ä‘áº©y bá»Ÿi quan sÃ¡t ráº±ng cÃ¡c miá»n khÃ¡c nhau thá»ƒ hiá»‡n cÃ¡c quan há»‡ inter-class khÃ¡c nhau do domain gap (HÃ¬nh 1), Ä‘iá»u nÃ y lÃ  tá»± nhiÃªn vÃ¬ cÃ¡c ensembles cá»§a chÃºng tÃ´i sáº½ tÃ­ch há»£p cÃ¡c quan há»‡ inter-class cÃ³ Ã½ nghÄ©a tá»« nhiá»u miá»n vÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c há»c vá»›i chÃºng sáº½ Ä‘Æ°á»£c dáº«n vá» entropy cao.

--- TRANG 8 ---
8 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

Train LossTest Loss
ğœğœ–ğœ–0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.000102030
0102030
XDED (train)MixStyle (train)ResNet -18 (train)
XDED (test)MixStyle (test)ResNet -18 (test)

HÃ¬nh 2: Train/Test losses so vá»›i weight perturbation trong khi thay Ä‘á»•i standard deviation cá»§a Gaussian noise Ä‘Æ°á»£c thÃªm vÃ o. LÆ°u Ã½ ráº±ng káº¿t quáº£ Ä‘Æ°á»£c táº¡o ra vá»›i miá»n Ä‘Ã­ch (Art cá»§a PACS) vÃ  cÃ¡c miá»n nguá»“n cÃ²n láº¡i, vÃ  cÃ¡c giÃ¡ trá»‹ loss Ä‘Æ°á»£c chia logarit.

Accuracy (%)
75.080.085.0
1.751.801.85A-Distance

HÃ¬nh 3: So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ thÃºc Ä‘áº©y flat minima. Má»—i mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn Cartoon cá»§a PACS sau khi Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c miá»n nguá»“n cÃ²n láº¡i. TrÃ¡i: Divergence ( A-distance) giá»¯a cÃ¡c miá»n nguá»“n vÃ  miá»n Ä‘Ã­ch, Pháº£i: Hiá»‡u suáº¥t tá»•ng quÃ¡t hÃ³a trÃªn miá»n Ä‘Ã­ch.

Tiáº¿p theo, Ä‘á»ƒ Ä‘iá»u tra xem mÃ´ hÃ¬nh Ä‘Æ°á»£c há»c vá»›i XDED cÃ³ thá»±c sá»± há»™i tá»¥ vá» flat minima hay khÃ´ng, chÃºng tÃ´i Ä‘á»‹nh lÆ°á»£ng Ä‘á»™ pháº³ng cá»§a local minima nÆ¡i mÃ´ hÃ¬nh há»™i tá»¥ báº±ng cÃ¡ch Ä‘o sá»± tÄƒng cá»§a cÃ¡c giÃ¡ trá»‹ loss giá»¯a Î¸ vÃ  cÃ¡c vÃ¹ng lÃ¢n cáº­n cá»§a nÃ³, giáº£ Ä‘á»‹nh ráº±ng mÃ´ hÃ¬nh há»™i tá»¥ trong flat minima sáº½ cÃ³ sá»± tÄƒng nhá» hÆ¡n. Theo [8,9,87,89], chÃºng tÃ´i Ä‘o cÃ¡c losses cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ há»c trÆ°á»›c vÃ  sau khi thÃªm Gaussian noises vÃ o cÃ¡c tham sá»‘ mÃ´ hÃ¬nh trong khi thay Ä‘á»•i standard deviation cá»§a noise ÏƒÏµ(tá»©c lÃ ,LCE(X, Y ;Î¸+Ïµ) trong Ä‘Ã³ Ïµâˆ¼N(0, ÏƒÏµ)) vá»›i 100 láº§n cháº¡y. Káº¿t quáº£ lÃ , XDED chá»©ng minh kháº£ nÄƒng robust cá»§a nÃ³ chá»‘ng láº¡i weight perturbation vá»›i sá»± tÄƒng loss nhá» hÆ¡n nhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong HÃ¬nh 2.

Há»c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n. á» Ä‘Ã¢y, chÃºng tÃ´i nháº¥n máº¡nh ráº±ng XDED cÅ©ng há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n thÃ´ng qua viá»‡c regularize tÃ­nh nháº¥t quÃ¡n giá»¯a cÃ¡c dá»± Ä‘oÃ¡n tá»« dá»¯ liá»‡u cÃ³ cÃ¹ng nhÃ£n nhÆ°ng tá»« cÃ¡c miá»n khÃ¡c nhau vÃ  ensemble cá»§a chÃºng. Do Ä‘Ã³, chÃºng tÃ´i so sÃ¡nh XDED vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ thÃºc Ä‘áº©y flat minima, Ä‘Æ°á»£c dÃ nh riÃªng chá»‰ cho Ä‘á»™ pháº³ng cá»§a local minima. Cá»¥ thá»ƒ, Ä‘á»ƒ kiá»ƒm tra hiá»‡u quáº£ trong viá»‡c giáº£m divergence Div( Si, T), chÃºng tÃ´i Ä‘o A-distance [3,39]. Do tÃ­nh khÃ´ng thá»ƒ tÃ­nh toÃ¡n Ä‘Æ°á»£c, chÃºng tÃ´i Ä‘Ã£ tÃ­nh má»™t cÃ¡i xáº¥p xá»‰ [50,56]2 NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong HÃ¬nh 3 (TrÃ¡i), chÃºng tÃ´i quan sÃ¡t ráº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ thÃºc Ä‘áº©y flat minima tháº¥t báº¡i trong viá»‡c giáº£m khoáº£ng cÃ¡ch trong khi XDED rÃµ rÃ ng giáº£m khoáº£ng cÃ¡ch vÃ  UniStyle tiáº¿p tá»¥c tÄƒng cÆ°á»ng káº¿t quáº£. Má»™t cÃ¡ch tá»± nhiÃªn, káº¿t quáº£ Ä‘Ã³ Ä‘Æ°á»£c káº¿t ná»‘i vá»›i tÃ­nh Æ°u viá»‡t Ä‘á»‹nh lÆ°á»£ng cá»§a framework cá»§a chÃºng tÃ´i so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p thÃºc Ä‘áº©y flat minima hiá»‡n cÃ³ (HÃ¬nh 3 (Pháº£i)).

4 Thá»±c nghiá»‡m

4.1 Tá»•ng quÃ¡t hÃ³a trong phÃ¢n loáº¡i áº£nh

Multi-source domain generalization. Cá»¥ thá»ƒ, Ä‘á»ƒ so sÃ¡nh cÃ´ng báº±ng, chÃºng tÃ´i theo giao thá»©c leave-one-domain-out [45] trong Ä‘Ã³ chÃºng tÃ´i huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh trÃªn ba miá»n vÃ  Ä‘Ã¡nh giÃ¡ nÃ³ trÃªn miá»n cÃ²n láº¡i. Äá»‘i vá»›i cÃ¡c táº­p dá»¯ liá»‡u benchmark, chÃºng tÃ´i sá»­ dá»¥ng PACS [45] vÃ  OfficeHome [72] lÃ  cÃ¡c benchmarks Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i cho domain generalization trong phÃ¢n loáº¡i áº£nh. PACS chá»©a 9,991 áº£nh cá»§a 7 lá»›p trÃªn 4 miá»n: Art Painting, Cartoon, Photo, vÃ  Sketch. OfficeHome bao gá»“m 15,500 áº£nh cá»§a 65 lá»›p trÃªn 4 miá»n: Artistic, Clipart, Product, vÃ  Real. ChÃºng tÃ´i sá»­ dá»¥ng ResNet-18 [27] lÃ m backbone, vÃ  UniStyle cá»§a chÃºng tÃ´i Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c feature maps Ä‘áº§u ra cá»§a khá»‘i residual thá»© nháº¥t vÃ  thá»© hai cho PACS vÃ  chá»‰ khá»‘i thá»© nháº¥t cho OfficeHome.

Káº¿t quáº£. NhÆ° Ä‘Æ°á»£c tÃ³m táº¯t trong Báº£ng. 2, chÃºng tÃ´i quan sÃ¡t ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i khÃ´ng chá»‰ tÄƒng cÆ°á»ng Ä‘Ã¡ng ká»ƒ vanilla mÃ  cÃ²n vÆ°á»£t trá»™i so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cáº¡nh tranh má»›i nháº¥t. Äáº·c biá»‡t, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i so vá»›i phÆ°Æ¡ng phÃ¡p tá»‘t thá»© hai trÃªn Cartoon cá»§a PACS vÃ  Clipart cá»§a OfficeHome khoáº£ng 4.0% vÃ  2.0% tÆ°Æ¡ng á»©ng. Nhá»¯ng káº¿t quáº£ nÃ y chá»©ng minh tÃ­nh Æ°u viá»‡t cá»§a phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£.

Single-source domain generalization Nhá» thiáº¿t káº¿ Ä‘Æ¡n giáº£n cá»§a phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t, khÃ´ng yÃªu cáº§u rÃµ rÃ ng cÃ¡c nhÃ£n miá»n, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­ch há»£p minh báº¡ch vá»›i single-source domain generalization trong Ä‘Ã³ chÃºng tÃ´i chá»‰ cÃ³ quyá»n truy cáº­p vÃ o má»™t miá»n nguá»“n duy nháº¥t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Do Ä‘Ã³, Ä‘á»ƒ tiáº¿p tá»¥c Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a phÆ°Æ¡ng phÃ¡p Ä‘á»‘i vá»›i single-source domain generalization, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»—i miá»n Ä‘Æ¡n láº» cá»§a PACS vÃ  Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c miá»n Ä‘Ã­ch cÃ²n láº¡i.

Káº¿t quáº£. NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng. 3, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i, trung bÃ¬nh, vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c baselines khÃ¡c 8.7% vá» Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh. BÃªn cáº¡nh Ä‘Ã³, trong táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p ngoáº¡i trá»« trÆ°á»ng há»£p Câ†’S, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i cho tháº¥y tÃ­nh Æ°u viá»‡t vá» hiá»‡u suáº¥t. ChÃºng tÃ´i tin ráº±ng káº¿t quáº£ thÃº vá»‹ nÃ y xuáº¥t phÃ¡t tá»« thá»±c táº¿ ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i váº«n cÃ³ thá»ƒ giÃºp mÃ´ hÃ¬nh há»™i tá»¥ vá» flat minima vÃ  khai thÃ¡c cÃ¡c quan há»‡ tinh táº¿ giá»¯a cÃ¡c máº«u intra-domain ngay cáº£ khi chá»‰ cÃ³ má»™t miá»n nguá»“n duy nháº¥t Ä‘Æ°á»£c cung cáº¥p.

DomainBed. ChÃºng tÃ´i cÅ©ng thá»±c hiá»‡n cÃ¡c thá»±c nghiá»‡m má»Ÿ rá»™ng trÃªn DomainBed [26] lÃ  má»™t testbed cho domain generalization Ä‘á»ƒ so sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n qua nhiá»u táº­p dá»¯ liá»‡u benchmark. LÃ½ do Ä‘áº±ng sau DomainBed lÃ  cÃ¡c hiá»‡u suáº¥t domain generalization phá»¥ thuá»™c quÃ¡ nhiá»u vÃ o

2NÃ³ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  Ë†dA= 2(1âˆ’2Ïµsvm) trong Ä‘Ã³ Ïµsvm lÃ  generalization error cá»§a má»™t SVM-based two-class classifier Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ phÃ¢n biá»‡t giá»¯a cÃ¡c miá»n Ä‘Ã­ch vÃ  nguá»“n.

--- TRANG 9 ---
Cross-Domain Ensemble Distillation for Domain Generalization 9

--- TRANG 10 ---
10 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

Báº£ng 2: Káº¿t quáº£ tá»•ng quÃ¡t hÃ³a leave-one-domain-out trÃªn PACS vÃ  OfficeHome.

PACS OfficeHome
PhÆ°Æ¡ng phÃ¡p Art CartoonPhoto Sketch Avg. Artistic Clipart Product Real Avg.
ResNet-18 77.0 75.9 96.0 69.2 79.5 58.9 49.4 74.3 76.2 64.7
MMD-AE [48] 75.2 72.7 96.0 64.2 77.0 56.5 47.3 72.1 74.8 62.7
JiGen [7] 79.4 75.3 96.0 71.6 80.5 53.0 47.4 71.4 72.7 61.2
CrossGrad [66] 79.8 76.8 96.0 70.2 80.7 58.4 49.4 73.9 75.8 64.4
MASF [16] 80.2 77.1 94.9 71.6 81.0 - - - - -
Epi-FCR [47] 82.1 77.0 93.9 73.0 81.5 - - - - -
EISNet [74] 81.8 76.4 95.9 74.3 82.1 - - - - -
L2A-OT [93] 83.3 78.2 96.2 73.6 82.8 60.6 50.1 74.8 77.0 65.6
SagNet [56] 83.5 77.6 95.4 76.3 83.2 60.2 45.3 70.4 73.3 62.3
SelfReg [40] 82.3 78.4 96.2 77.4 83.6 - - - - -
MixStyle [95] 84.1 78.8 96.1 75.9 83.7 58.7 53.4 74.2 75.9 65.5
L2D [75] 81.4 79.5 95.5 80.5 84.2 - - - - -
FACT [77] 85.3 78.3 95.1 79.1 84.5 60.3 54.8 74.4 76.5 66.5
DSON [65] 84.6 77.6 95.8 82.2 85.1 59.3 45.7 71.8 74.6 62.9
RSC [33] 83.4 80.3 95.9 80.8 85.1 58.4 47.9 71.6 74.5 63.1
StyleNeophile [37] 84.4 79.2 94.9 83.2 85.4 59.5 55.0 73.5 75.5 65.8
Cá»§a chÃºng tÃ´i 85.6 84.2 96.5 79.1 86.4 60.8 57.1 75.3 76.5 67.4

Báº£ng 3: Äá»™ chÃ­nh xÃ¡c single-source domain generalization (%) trÃªn PACS vá»›i ResNet-18. (A: Art Painting, C: Cartoon, S:Sketch, P:Photo).

PhÆ°Æ¡ng phÃ¡p A)C A )S A )P C )A C )S C )P S )A S )C S )P P )A P )C P )SAvg.
ResNet-18 62.3 49.0 95.2 65.7 60.7 83.6 28.0 54.5 35.6 64.1 23.6 29.1 54.3
JiGen [7] 57.0 50.0 96.1 65.3 65.9 85.5 26.6 41.1 42.8 62.4 27.2 35.5 54.6
MixStyle [95] 65.5 49.8 96.7 69.9 64.5 85.3 27.1 50.9 32.6 67.7 38.9 39.1 57.4
RSC [33] 62.5 53.1 96.2 68.9 70.3 85.8 37.9 56.3 47.4 66.3 26.4 32.0 58.6
SelfReg [40] 65.2 55.9 96.6 72.0 70.0 87.5 37.1 54.0 46.0 67.7 28.9 33.7 59.5
SagNet [56] 67.1 56.8 95.7 72.1 69.2 85.7 41.1 62.9 46.2 69.8 35.1 40.7 61.9
Cá»§a chÃºng tÃ´i 74.6 58.1 96.8 74.4 69.6 87.6 43.3 65.6 50.3 71.4 54.3 51.5 66.5

viá»‡c Ä‘iá»u chá»‰nh siÃªu tham sá»‘. Äá»ƒ so sÃ¡nh cÃ´ng báº±ng, chÃºng tÃ´i tuÃ¢n theo cÃ¡c giao thá»©c tiÃªu chuáº©n cá»§a nÃ³ Ä‘á»ƒ huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡.

Káº¿t quáº£. NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng. 4, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i nÃ³i chung cho tháº¥y hiá»‡u suáº¥t cáº¡nh tranh vÃ  xáº¿p thá»© hai trong sá»‘ 15 phÆ°Æ¡ng phÃ¡p vá» Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh. Äáº·c biá»‡t, trÃªn CMNIST, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cáº¡nh tranh khÃ¡c. VÃ¬ CMNIST Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ mÃ´ phá»ng domain shift báº±ng cÃ¡ch tÆ°Æ¡ng quan mÃ u sáº¯c chá»¯ sá»‘ vá»›i nhÃ£n lá»›p, chÃºng tÃ´i phá»ng Ä‘oÃ¡n ráº±ng cáº£i thiá»‡n cá»§a chÃºng tÃ´i trÃªn CMNIST Ä‘Æ°á»£c quy cho hiá»‡u á»©ng de-stylization cá»§a UniStyle, Ä‘iá»u nÃ y sáº½ giÃºp mÃ´ hÃ¬nh tÃ¡ch rá»i má»‘i tÆ°Æ¡ng quan giá»¯a mÃ u sáº¯c vÃ  nhÃ£n.

4.2 Tá»•ng quÃ¡t hÃ³a trong person re-ID

Trong pháº§n nÃ y, chÃºng tÃ´i tiáº¿p tá»¥c Ä‘Ã¡nh giÃ¡ phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i trÃªn person re-identification (re-ID), lÃ  viá»‡c khá»›p ngÆ°á»i Ä‘i bá»™ qua cÃ¡c gÃ³c nhÃ¬n camera khÃ´ng chá»“ng chÃ©o.

Thiáº¿t láº­p thá»±c nghiá»‡m. á» Ä‘Ã¢y, chÃºng tÃ´i giáº£i quyáº¿t domain generalization cho person re-ID, trong Ä‘Ã³ dá»¯ liá»‡u kiá»ƒm tra Ä‘Æ°á»£c thu tháº­p tá»« cameras cá»§a táº­p dá»¯ liá»‡u chÆ°a tháº¥y thay vÃ¬

--- TRANG 11 ---
Cross-Domain Ensemble Distillation for Domain Generalization 11

Báº£ng 4: Äá»™ chÃ­nh xÃ¡c domain generalization (%) trÃªn DomainBed. Cá»™t "Terra" Ä‘áº¡i diá»‡n cho táº­p dá»¯ liá»‡u TerraIncognita. LÆ°u Ã½ ráº±ng chÃºng tÃ´i Ã¡p dá»¥ng leave-one-domain-out cross-validation nhÆ° má»™t tiÃªu chÃ­ lá»±a chá»n mÃ´ hÃ¬nh.

Lá»±a chá»n mÃ´ hÃ¬nh: leave-one-domain-out cross-validation
PhÆ°Æ¡ng phÃ¡p CMNIST RMNIST VLCS PACS OfficeHome Terra Avg.
ERM [71] 36.7 97.7 77.2 83.0 65.7 41.4 66.9
IRM [1] 40.3 97.0 76.3 81.5 64.3 41.2 66.7
GroupDRO [64] 36.8 97.6 77.9 83.5 65.2 44.9 66.7
Mixup [86] 33.4 97.8 77.7 83.2 67.0 48.7 67.9
MLDG [46] 36.7 97.6 77.2 82.9 66.1 46.2 67.7
CORAL [68] 39.7 97.8 78.7 82.6 68.5 46.3 68.9
MMD [48] 36.8 97.8 77.3 83.2 60.2 46.5 66.9
DANN [21] 40.7 97.6 76.9 81.0 64.9 44.4 67.5
CDANN [49] 39.1 97.5 77.5 78.8 64.3 39.9 66.1
MTL [5] 35.0 97.8 76.6 83.7 65.7 44.9 67.2
SagNet [56] 36.5 94.0 77.5 82.3 67.6 47.2 67.5
ARM [88] 36.8 98.1 76.6 81.7 64.4 42.6 66.7
VREx [44] 36.9 93.6 76.7 81.3 64.9 37.3 65.1
RSC [33] 36.5 97.6 77.5 82.6 65.8 40.0 66.6
Cá»§a chÃºng tÃ´i 46.5 97.7 74.8 83.8 65.0 42.5 68.4

Báº£ng 5: Káº¿t quáº£ tá»•ng quÃ¡t hÃ³a trÃªn cross-dataset person re-ID.

Marketâ†’Duke Dukeâ†’Market
PhÆ°Æ¡ng phÃ¡p mAP R@1 mAP R@1
ResNet-50 19.3 35.4 20.4 45.2
RandomErase [92] 14.3 27.8 16.1 38.5
DropBlock [23] 18.2 33.2 19.7 45.3
MixStyle [95] 23.4 43.3 24.7 53.0
StyleNeophile [37] 26.3 46.5 27.2 55.0
Cá»§a chÃºng tÃ´i 27.4 49.3 30.1 59.0

tá»« nhá»¯ng táº­p dá»¯ liá»‡u huáº¥n luyá»‡n. Cá»¥ thá»ƒ, mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ khá»›p ngÆ°á»i trong táº­p dá»¯ liá»‡u nguá»“n Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ báº±ng má»©c Ä‘á»™ khá»›p tá»‘t dá»¯ liá»‡u ngÆ°á»i Ä‘i bá»™ cá»§a táº­p kiá»ƒm tra chÆ°a tháº¥y, chÃºng tÃ¡ch rá»i khá»i táº­p dá»¯ liá»‡u nguá»“n. Äá»‘i vá»›i táº­p dá»¯ liá»‡u, chÃºng tÃ´i Ã¡p dá»¥ng hai benchmarks Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i: Market1501 (Market) [90] vÃ  DukeMTMC-reID (Duke) [62,91]. ChÃºng tÃ´i sá»­ dá»¥ng 32,668 áº£nh cá»§a 1,501 identities Ä‘Æ°á»£c thu tháº­p tá»« 6 cameras vÃ  36,411 áº£nh cá»§a 1,812 identities tá»« 8 cameras cho Market1501 vÃ  Duke tÆ°Æ¡ng á»©ng. Äá»‘i vá»›i cÃ¡c thÆ°á»›c Ä‘o hiá»‡u suáº¥t, chÃºng tÃ´i Ã¡p dá»¥ng mean average precision (mAP) vÃ  Recall@K (R@K). Theo cÃ´ng trÃ¬nh trÆ°á»›c [95], chÃºng tÃ´i Ã¡p dá»¥ng ResNet-50 [27] lÃ m kiáº¿n trÃºc backbone. Trong nhá»¯ng thá»±c nghiá»‡m nÃ y, chÃºng tÃ´i Ã¡p dá»¥ng UniStyle cho khá»‘i residual thá»© 1, 2, vÃ  3 cá»§a mÃ´ hÃ¬nh.

So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p regularization khÃ¡c. NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng. 5, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c vá» mAP vÃ  Recall@1. Máº·c dÃ¹ RandomErase vÃ  Dropblock hiá»‡u quáº£ cho viá»‡c há»c cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n biá»‡t, chÃºng tháº¥t báº¡i trong viá»‡c cáº£i thiá»‡n hiá»‡u suáº¥t khi gáº·p dá»¯ liá»‡u miá»n chÆ°a tháº¥y. HÆ¡n ná»¯a, báº±ng cÃ¡ch khai thÃ¡c cÃ¡c quan há»‡ inter-class Ä‘Æ°á»£c cung cáº¥p bá»Ÿi cÃ¡c camera khÃ¡c nhau

--- TRANG 12 ---
12 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

Báº£ng 6: Káº¿t quáº£ mIoU (%) trÃªn cross-dataset semantic segmentation. GTA5 Ä‘á»ƒ huáº¥n luyá»‡n, vÃ  Cityscapes, SYNTHIA, BDD, vÃ  Mapillary lÃ  cÃ¡c táº­p kiá»ƒm tra.

PhÆ°Æ¡ng phÃ¡p (GTA5) Cityscapes BDD Mapillary SYNTHIA
DeepLabV3+ [11] 28.9 25.1 28.1 26.2
SW [58] 29.9 27.4 29.7 27.6
DRPC [82] 37.4 32.1 34.1 28.0
RobustNet [12] 36.5 35.2 40.3 28.3
Cá»§a chÃºng tÃ´i 39.2 32.4 37.1 28.0

Báº£ng 7: NghiÃªn cá»©u ablation cá»§a cÃ¡c thÃ nh pháº§n Ä‘Æ°á»£c Ä‘á» xuáº¥t trÃªn cÃ¡c nhiá»‡m vá»¥ cross-domain cá»§a phÃ¢n loáº¡i áº£nh (Accuracy) vÃ  person re-ID (mAP).

PhÆ°Æ¡ng phÃ¡p Art Clipart Marketâ†’Duke
Vanilla 77.0 49.4 19.3
w/ UniStyle 81.2 50.4 26.2
w/ XDED 83.3 55.2 24.2
Cá»§a chÃºng tÃ´i 85.6 57.1 27.4

eras, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cho tháº¥y tÃ­nh Æ°u viá»‡t so vá»›i MixStyle vÃ  StyleNeophile Ä‘Æ°á»£c thiáº¿t káº¿ cho domain generalization nhÆ°ng chá»‰ sá»­ dá»¥ng one-hot labels.

4.3 Tá»•ng quÃ¡t hÃ³a trong semantic segmentation

Thiáº¿t láº­p thá»±c nghiá»‡m. Cuá»‘i cÃ¹ng, Ä‘á»ƒ Ä‘iá»u tra xem phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c má»Ÿ rá»™ng cho nhiá»‡m vá»¥ dense prediction hay khÃ´ng, Ä‘Ã¡nh giÃ¡ trÃªn semantic segmentation Ä‘Æ°á»£c giáº£i quyáº¿t á»Ÿ Ä‘Ã¢y. Theo giao thá»©c chÃ­nh thá»‘ng, chÃºng tÃ´i huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u tá»•ng há»£p vÃ  Ä‘Ã¡nh giÃ¡ chÃºng trÃªn nhiá»u táº­p dá»¯ liá»‡u chá»§ yáº¿u thuá»™c vá» tháº¿ giá»›i thá»±c. Cá»¥ thá»ƒ, chÃºng tÃ´i Ã¡p dá»¥ng GTA5 [61] lÃ m táº­p dá»¯ liá»‡u nguá»“n bao gá»“m 24,966 áº£nh. Äá»‘i vá»›i cÃ¡c táº­p dá»¯ liá»‡u Ä‘Ã­ch, Cityscapes [13], BDD [81], vÃ  Mapillary [57] lÃ  cÃ¡c táº­p dá»¯ liá»‡u tháº¿ giá»›i thá»±c cÃ³ kÃ­ch thÆ°á»›c áº£nh láº§n lÆ°á»£t lÃ  5,000, 10,000, vÃ  25,000. Cuá»‘i cÃ¹ng, SYNTHIA [63] cÃ³ 9,400 áº£nh. LÆ°u Ã½ ráº±ng ResNet-50 Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m backbone vÃ  19 lá»›p chung Ä‘Æ°á»£c sá»­ dá»¥ng qua táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u.

Káº¿t quáº£. ChÃºng tÃ´i nháº¥n máº¡nh ráº±ng XDED xÃ¢y dá»±ng ensemble báº±ng cÃ¡ch Ä‘Æ¡n giáº£n láº¥y trung bÃ¬nh táº¥t cáº£ cÃ¡c logits tá»« cÃ¡c pixels cÃ³ gt giá»‘ng nhau trong má»™t mini-batch. NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng 6, phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p cáº¡nh tranh tá»•ng thá»ƒ, ngay cáº£ khi nhá»¯ng phÆ°Æ¡ng phÃ¡p Ä‘Ã³ chá»‰ dÃ nh riÃªng cho nhiá»‡m vá»¥ nÃ y. ChÃºng tÃ´i chá»‰ ra ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i cÃ³ thá»ƒ Ä‘Æ°á»£c má»Ÿ rá»™ng cho phÃ¢n loáº¡i theo tá»«ng pixel vá»›i Ã­t sá»­a Ä‘á»•i trÃªn XDED. NgoÃ i ra, káº¿t quáº£ há»— trá»£ tuyÃªn bá»‘ cá»§a chÃºng tÃ´i ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ trong má»™t loáº¡t cÃ¡c nhiá»‡m vá»¥.

4.4 PhÃ¢n tÃ­ch SÃ¢u

NghiÃªn cá»©u ablation. Äá»ƒ Ä‘iá»u tra tÃ¡c Ä‘á»™ng cá»§a má»—i thÃ nh pháº§n trong phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i, chÃºng tÃ´i thá»±c hiá»‡n nghiÃªn cá»©u ablation Ä‘Æ°á»£c tÃ³m táº¯t trong Báº£ng 7. Káº¿t quáº£ tiáº¿t lá»™ ráº±ng hai thÃ nh pháº§n bá»• sung cho nhau vÃ  nháº¥t quÃ¡n giÃºp mÃ´ hÃ¬nh cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a. Äá»‘i vá»›i phÃ¢n loáº¡i áº£nh, XDED Ä‘Ã³ng gÃ³p nhiá»u nháº¥t cho hiá»‡u suáº¥t, vÃ  UniStyle tÄƒng cÆ°á»ng hiá»‡u á»©ng cá»§a XDED. TrÃªn cáº£ hai

--- TRANG 13 ---
Cross-Domain Ensemble Distillation for Domain Generalization 13

Lossğœ€!ğœ€"Sketch (test)
Lossğœ€!ğœ€"Photo (test)
Lossğœ€!ğœ€"Cartoon (test)
Art Painting (test)Lossğœ€!ğœ€"

HÃ¬nh 4: Káº¿t quáº£ visualization cá»§a loss landscapes tÃ­ch há»£p phÆ°Æ¡ng phÃ¡p vanilla vÃ  XDED trÃªn táº­p dá»¯ liá»‡u PACS. LÆ°u Ã½ ráº±ng má»—i loss landscape Ä‘Æ°á»£c visualization trÃªn dá»¯ liá»‡u cá»§a cÃ¡c miá»n nguá»“n, khÃ´ng pháº£i dá»¯ liá»‡u cá»§a miá»n Ä‘Ã­ch Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u. CÃ¡c bá» máº·t xanh vÃ  Ä‘á» láº§n lÆ°á»£t tá»« phÆ°Æ¡ng phÃ¡p vanilla vÃ  XDED.

Báº£ng 8: Äá»™ chÃ­nh xÃ¡c multi-source domain generalization (%) trÃªn Photo cá»§a PACS trÆ°á»›c vÃ  sau khi Ã¡p dá»¥ng cÃ¡c cuá»™c táº¥n cÃ´ng adversarial Ä‘Ã£ cho.

PhÆ°Æ¡ng phÃ¡p Photo w/ FGSM w/ PGD
ResNet-18 96.0 39.6 16.3
Label smoothing [69] 95.6 43.5 20.2
Mixup [86] 95.8 46.5 21.9
Manifold mixup [73] 93.5 46.6 23.8
MixStyle [95] 96.1 41.4 22.7
Cá»§a chÃºng tÃ´i 96.5 55.4 30.4

miá»n, XDED cáº£i thiá»‡n Ä‘á»“ng Ä‘á»u phÆ°Æ¡ng phÃ¡p vanilla khoáº£ng 6%, trong khi UniStyle cho tháº¥y cÃ¡c má»©c Ä‘á»™ cáº£i thiá»‡n khÃ¡c nhau. ÄÃ³ lÃ  vÃ¬ sá»± khÃ¡c biá»‡t phong cÃ¡ch áº£nh giá»¯a cÃ¡c miá»n trong OfficeHome Ã­t nghiÃªm trá»ng hÆ¡n so vá»›i PACS. ThÃº vá»‹ lÃ , Ä‘á»‘i vá»›i nhiá»‡m vá»¥ person re-ID, UniStyle tiáº¿t lá»™ tÃ¡c Ä‘á»™ng lá»›n hÆ¡n XDED. Do Ä‘áº·c tÃ­nh vá»‘n cÃ³ cá»§a nhiá»‡m vá»¥, hiá»‡u á»©ng cá»§a XDED trong viá»‡c thu tháº­p kiáº¿n thá»©c cÃ³ Ã½ nghÄ©a vá» cÃ¹ng má»™t ngÆ°á»i Ä‘i bá»™ tá»« cÃ¡c cameras khÃ¡c nhau cÃ³ thá»ƒ trá»Ÿ nÃªn Ã­t quan trá»ng hÆ¡n.

Visualization loss surface. Äá»ƒ tiáº¿p tá»¥c minh há»a cÃ¡ch XDED dáº«n Ä‘áº¿n flat minima trong loss landscapes, chÃºng tÃ´i cung cáº¥p káº¿t quáº£ Ä‘á»‹nh tÃ­nh visualization loss landscapes. Theo [9], chÃºng tÃ´i váº½ loss landscapes trÃªn dá»¯ liá»‡u cá»§a cÃ¡c miá»n nguá»“n cho má»—i trÆ°á»ng há»£p báº±ng cÃ¡ch perturbating cÃ¡c tham sá»‘ mÃ´ hÃ¬nh qua eigenvectors Hessian thá»© nháº¥t vÃ  thá»© hai Ä‘Æ°á»£c cung cáº¥p bá»Ÿi PyHessian [80] lÃ  má»™t framework cho phÃ¢n tÃ­ch dá»±a trÃªn Hessian cá»§a máº¡ng neural. NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong HÃ¬nh 4, chÃºng tÃ´i quan sÃ¡t ráº±ng loss landscapes tÃ­ch há»£p XDED trá»Ÿ nÃªn pháº³ng hÆ¡n rÃµ rÃ ng so vá»›i nhá»¯ng landscapes tÃ­ch há»£p phÆ°Æ¡ng phÃ¡p vanilla cho táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p. ChÃºng tÃ´i láº­p luáº­n ráº±ng nhá»¯ng káº¿t quáº£ Ä‘á»‹nh tÃ­nh nÃ y cÅ©ng nháº¥t quÃ¡n há»— trá»£ ráº±ng XDED thÃºc Ä‘áº©y flat minima.

Kháº£ nÄƒng robust Ä‘á»‘i vá»›i adversarial examples. CÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y Ä‘Ã£ chá»©ng minh ráº±ng há»™i tá»¥ trÃªn flat minima tÄƒng cÆ°á»ng kháº£ nÄƒng robust adversarial [76,67]. Äá»ƒ xÃ¡c thá»±c láº¡i ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i thÃºc Ä‘áº©y flat minima, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng robust adversarial cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ há»c. Cá»¥ thá»ƒ, chÃºng tÃ´i huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn cÃ¡c miá»n nguá»“n vÃ  thÃªm adversarial perturbations vÃ o áº£nh cá»§a miá»n Ä‘Ã­ch chÆ°a tháº¥y báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p táº¥n cÃ´ng adversarial hiá»‡n cÃ³: FGSM [25] vÃ  PGD [51]. Báº£ng 8 cho tháº¥y ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p regularization khÃ¡c vá»

--- TRANG 14 ---
14 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

Báº£ng 9: Lá»—i phÃ¢n loáº¡i trung bÃ¬nh (%) trÃªn cÃ¡c corruption benchmarks.

PhÆ°Æ¡ng phÃ¡p CIFAR-10-C CIFAR-100-C
40-2 WRN [85] 26.9 53.3
Cutout [15] 26.8 53.5
Mixup [86] 22.3 50.4
CutMix [83] 27.1 52.9
AutoAug [14] 23.9 49.6
AugMix [29] 11.2 35.9
Cá»§a chÃºng tÃ´i 18.5 46.6

kháº£ nÄƒng robust chá»‘ng láº¡i cáº£ dá»¯ liá»‡u chÆ°a tháº¥y vÃ  cÃ¡c cuá»™c táº¥n cÃ´ng adversarial. Xem xÃ©t ráº±ng cÃ¡c cuá»™c táº¥n cÃ´ng adversarial Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ tá»‘i Ä‘a hÃ³a giÃ¡ trá»‹ loss, chÃºng tÃ´i láº­p luáº­n ráº±ng tÃ­nh Æ°u viá»‡t cá»§a chÃºng tÃ´i trong kháº£ nÄƒng robust adversarial cÅ©ng Ä‘Æ°á»£c quy cho kháº£ nÄƒng thÃºc Ä‘áº©y flat minima nhÆ° mong muá»‘n, máº·c dÃ¹ phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i khÃ´ng cÃ³ má»‘i liÃªn há»‡ trá»±c tiáº¿p vá»›i adversarial training.

Káº¿t quáº£ trÃªn corruption benchmarks. ChÃºng tÃ´i tiáº¿p tá»¥c Ä‘o kháº£ nÄƒng phá»¥c há»“i cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ há»c Ä‘á»‘i vá»›i image corruptions. Theo giao thá»©c Ä‘Æ°á»£c cung cáº¥p bá»Ÿi [28], chÃºng tÃ´i huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u huáº¥n luyá»‡n gá»‘c, vÃ  Ä‘Ã¡nh giÃ¡ chÃºng trÃªn táº­p dá»¯ liá»‡u kiá»ƒm tra Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch lÃ m há»ng táº­p dá»¯ liá»‡u kiá»ƒm tra gá»‘c thÃ´ng qua cÃ¡c loáº¡i corruption Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trÆ°á»›c. Báº£ng. 9 cho tháº¥y ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i so vá»›i táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p regularization ngoáº¡i trá»« AugMix [30]. Xem xÃ©t AugMix lÃ  má»™t state of the art dÃ nh riÃªng cho kháº£ nÄƒng robust corruption trong khi phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i thÃ¬ khÃ´ng, chÃºng tÃ´i láº­p luáº­n ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i váº«n cho tháº¥y kháº£ nÄƒng robust Ä‘Ã¡ng ká»ƒ chá»‘ng láº¡i image corruptions.

5 Káº¿t luáº­n

ChÃºng tÃ´i Ä‘Ã£ trÃ¬nh bÃ y má»™t framework Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ cho domain generalization. XDED trÆ°á»›c tiÃªn táº¡o ra má»™t ensemble cá»§a cÃ¡c phÃ¢n phá»‘i output cho dá»¯ liá»‡u cÃ³ cÃ¹ng nhÃ£n nhÆ°ng tá»« cÃ¡c miá»n khÃ¡c nhau, vÃ  sau Ä‘Ã³ pháº¡t má»—i phÃ¢n phá»‘i output cho sá»± khÃ´ng khá»›p vá»›i ensemble dÆ°á»›i dáº¡ng self-knowledge distillation. Vá»›i cÃ¡ch tiáº¿p cáº­n nÃ y, mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i cÃ³ thá»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n miá»n vÃ  cÅ©ng dá»… dÃ ng há»™i tá»¥ vá» flat minima. BÃªn cáº¡nh Ä‘Ã³, UniStyle Ä‘Æ°á»£c Ä‘á» xuáº¥t ngÄƒn cháº·n bias phong cÃ¡ch Ä‘áº·c trÆ°ng miá»n Ä‘á»ƒ tÄƒng cÆ°á»ng hiá»‡u á»©ng cá»§a XDED vÃ  khuyáº¿n khÃ­ch cÃ¡c dá»± Ä‘oÃ¡n nháº¥t quÃ¡n vá» phong cÃ¡ch. HÆ¡n ná»¯a, chÃºng tÃ´i xÃ¡c thá»±c thá»±c nghiá»‡m kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t tá»« gÃ³c Ä‘á»™ flat minima vÃ  giáº£m divergence giá»¯a nguá»“n vÃ  Ä‘Ã­ch. ThÃ´ng qua káº¿t quáº£ thá»±c nghiá»‡m má»Ÿ rá»™ng, chÃºng tÃ´i chá»©ng minh tÃ­nh Æ°u viá»‡t cá»§a framework Ä‘Æ°á»£c Ä‘á» xuáº¥t.

Lá»i cáº£m Æ¡n. CÃ´ng trÃ¬nh nÃ y Ä‘Æ°á»£c há»— trá»£ bá»Ÿi NRF grant vÃ  IITP grant Ä‘Æ°á»£c tÃ i trá»£ bá»Ÿi Bá»™ Khoa há»c vÃ  ICT, HÃ n Quá»‘c (NRF-2021R1A2C3012728, IITP-2019-0-01906, IITP-2022-0-00926, IITP-2022-0-00290).

--- TRANG 15 ---
Cross-Domain Ensemble Distillation for Domain Generalization 15

TÃ i liá»‡u Tham kháº£o

1. Arjovsky, M., Bottou, L., Gulrajani, I., Lopez-Paz, D.: Invariant risk minimization. arXiv preprint arXiv:1907.02893 (2019) 11
2. Balaji, Y., Sankaranarayanan, S., Chellappa, R.: Metareg: Towards domain generalization using meta-regularization. In: Proc. Neural Information Processing Systems (NeurIPS) (2018) 3
3. Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., Vaughan, J.W.: A theory of learning from different domains. Machine learning (2010) 6, 8
4. Ben-David, S., Blitzer, J., Crammer, K., Pereira, F., et al.: Analysis of representations for domain adaptation. In: Proc. Neural Information Processing Systems (NeurIPS) (2007) 6
5. Blanchard, G., Deshmukh, A.A., Dogan, U., Lee, G., Scott, C.: Domain generalization by marginal transfer learning. Journal of Machine Learning Research (JMLR) (2021) 11
6. Brendel, W., Bethge, M.: Approximating cnns with bag-of-local-features models works surprisingly well on imagenet. In: Proc. International Conference on Learning Representations (ICLR) (2019) 4
7. Carlucci, F.M., D'Innocente, A., Bucci, S., Caputo, B., Tommasi, T.: Domain generalization by solving jigsaw puzzles. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019) 10
8. Cha, J., Chun, S., Lee, K., Cho, H.C., Park, S., Lee, Y., Park, S.: Swad: Domain generalization by seeking flat minima. In: Proc. Neural Information Processing Systems (NeurIPS) (2021) 3, 4, 7, 8
9. Cha, S., Hsu, H., Hwang, T., Calmon, F.P., Moon, T.: Cpr: Classifier-projection regularization for continual learning. In: Proc. International Conference on Learning Representations (ICLR) (2021) 2, 4, 7, 8, 13
10. Chaudhari, P., Choromanska, A., Soatto, S., LeCun, Y., Baldassi, C., Borgs, C., Chayes, J., Sagun, L., Zecchina, R.: Entropy-sgd: Biasing gradient descent into wide valleys. In: Proc. International Conference on Learning Representations (ICLR) (2017) 2, 4
11. Chen, L.C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H.: Encoder-decoder with atrous separable convolution for semantic image segmentation. In: Proc. European Conference on Computer Vision (ECCV) (2018) 12
12. Choi, S., Jung, S., Yun, H., Kim, J.T., Kim, S., Choo, J.: Robustnet: Improving domain generalization in urban-scene segmentation via instance selective whitening. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 4, 12
13. Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., Schiele, B.: The cityscapes dataset for semantic urban scene understanding. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016) 12
14. Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V.: Autoaugment: Learning augmentation policies from data (2019) 14
15. DeVries, T., Taylor, G.W.: Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552 (2017) 14
16. Dou, Q., Coelho de Castro, D., Kamnitsas, K., Glocker, B.: Domain generalization via model-agnostic learning of semantic features. In: Proc. Neural Information Processing Systems (NeurIPS) (2019) 3, 10

--- TRANG 16 ---
16 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

17. Dumoulin, V., Shlens, J., Kudlur, M.: A learned representation for artistic style. In: Proc. International Conference on Learning Representations (ICLR) (2017) 6
18. Dziugaite, G.K., Roy, D.M.: Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data. In: Proc. The Conference on Uncertainty in Artificial Intelligence (UAI) (2017) 2, 4
19. Feng, H.Z., You, Z., Chen, M., Zhang, T., Zhu, M., Wu, F., Wu, C., Chen, W.: Kd3a: Unsupervised multi-source decentralized domain adaptation via knowledge distillation. In: Proc. International Conference on Machine Learning (ICML) (2021) 4
20. Foret, P., Kleiner, A., Mobahi, H., Neyshabur, B.: Sharpness-aware minimization for efficiently improving generalization. In: Proc. International Conference on Learning Representations (ICLR) (2021) 2, 4
21. Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V.: Domain-adversarial training of neural networks. Journal of Machine Learning Research (JMLR) (2016) 11
22. Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.A., Brendel, W.: Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness. In: Proc. International Conference on Learning Representations (ICLR) (2019) 4
23. Ghiasi, G., Lin, T.Y., Le, Q.V.: Dropblock: A regularization method for convolutional networks. In: Proc. Neural Information Processing Systems (NeurIPS) (2018) 11
24. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: Proc. Neural Information Processing Systems (NeurIPS) (2014) 1
25. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples. In: Proc. International Conference on Learning Representations (ICLR) (2014) 13
26. Gulrajani, I., Lopez-Paz, D.: In search of lost domain generalization. In: Proc. International Conference on Learning Representations (ICLR) (2021) 3, 9
27. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (June 2016) 9, 11
28. Hendrycks, D., Dietterich, T.: Benchmarking neural network robustness to common corruptions and perturbations. In: Proc. International Conference on Learning Representations (ICLR) (2019) 14
29. Hendrycks, D., Mu, N., Cubuk, E.D., Zoph, B., Gilmer, J., Lakshminarayanan, B.: Augmix: A simple data processing method to improve robustness and uncertainty (2020) 14
30. Hendrycks, D., Mu, N., Cubuk, E.D., Zoph, B., Gilmer, J., Lakshminarayanan, B.: Augmix: A simple data processing method to improve robustness and uncertainty. In: Proc. International Conference on Learning Representations (ICLR) (2020) 14
31. Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015) 3, 4
32. Huang, X., Belongie, S.: Arbitrary style transfer in real-time with adaptive instance normalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2017) 6
33. Huang, Z., Wang, H., Xing, E.P., Huang, D.: Self-challenging improves cross-domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2020) 10, 11

--- TRANG 17 ---
Cross-Domain Ensemble Distillation for Domain Generalization 17

34. Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift. In: Proc. International Conference on Machine Learning (ICML) (2015) 3
35. Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., Wilson, A.G.: Averaging weights leads to wider optima and better generalization. In: Proc. The Conference on Uncertainty in Artificial Intelligence (UAI) (2018) 4
36. Jiang, Y., Neyshabur, B., Mobahi, H., Krishnan, D., Bengio, S.: Fantastic generalization measures and where to find them. In: Proc. International Conference on Learning Representations (ICLR) (2020) 2
37. Kang, J., Lee, S., Kim, N., Kwak, S.: Style neophile: Constantly seeking novel styles for domain generalization. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2022) 3, 4, 10, 11
38. Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P.: On large-batch training for deep learning: Generalization gap and sharp minima. In: Proc. International Conference on Learning Representations (ICLR) (2017) 2, 4
39. Kifer, D., Ben-David, S., Gehrke, J.: Detecting change in data streams. In: In Very Large Databases (VLDB) (2004) 8
40. Kim, D., Park, S., Kim, J., Lee, J.: Selfreg: Self-supervised contrastive regularization for domain generalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2021) 1, 10
41. Kim, N., Son, T., Lan, C., Zeng, W., Kwak, S.: Wedge: Web-image assisted domain generalization for semantic segmentation. arXiv preprint arXiv:2109.14196 (2021) 3
42. Kim, S., Kim, D., Cho, M., Kwak, S.: Embedding transfer with label relaxation for improved metric learning. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 3
43. Krizhevsky, A., Sutskever, I., Hinton, G.E.: ImageNet classification with deep convolutional neural networks. In: Proc. Neural Information Processing Systems (NeurIPS) (2012) 1
44. Krueger, D., Caballero, E., Jacobsen, J.H., Zhang, A., Binas, J., Zhang, D., Le Priol, R., Courville, A.: Out-of-distribution generalization via risk extrapolation (rex). In: Proc. International Conference on Machine Learning (ICML) (2021) 11
45. Li, D., Yang, Y., Song, Y.Z., Hospedales, T.M.: Deeper, broader and artier domain generalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2017) 9
46. Li, D., Yang, Y., Song, Y.Z., Hospedales, T.M.: Learning to generalize: Meta-learning for domain generalization. In: Proc. AAAI Conference on Artificial Intelligence (AAAI) (2018) 11
47. Li, D., Zhang, J., Yang, Y., Liu, C., Song, Y.Z., Hospedales, T.M.: Episodic training for domain generalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 3, 10
48. Li, H., Pan, S.J., Wang, S., Kot, A.C.: Domain generalization with adversarial feature learning. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2018) 1, 3, 10, 11
49. Li, Y., Tian, X., Gong, M., Liu, Y., Liu, T., Zhang, K., Tao, D.: Deep domain generalization via conditional invariant adversarial networks. In: Proc. European Conference on Computer Vision (ECCV) (2018) 1, 3, 11
50. Long, M., Cao, Y., Wang, J., Jordan, M.: Learning transferable features with deep adaptation networks. In: Proc. International Conference on Machine Learning (ICML) (2015) 9

--- TRANG 18 ---
18 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

51. Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards deep learning models resistant to adversarial attacks. In: Proc. International Conference on Learning Representations (ICLR) (2018) 13
52. Meng, Z., Li, J., Gong, Y., Juang, B.H.: Adversarial teacher-student learning for unsupervised domain adaptation. In: 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2018) 4
53. Miyato, T., Maeda, S.i., Koyama, M., Ishii, S.: Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) (2018) 5
54. Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M.: Playing atari with deep reinforcement learning. In: NeurIPS Deep Learning Workshop (2013) 1
55. Muandet, K., Balduzzi, D., SchÃ¶lkopf, B.: Domain generalization via invariant feature representation. In: Proc. International Conference on Machine Learning (ICML) (2013) 1, 3
56. Nam, H., Lee, H., Park, J., Yoon, W., Yoo, D.: Reducing domain gap by reducing style bias. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 4, 9, 10, 11
57. Neuhold, G., Ollmann, T., Rota Bulo, S., Kontschieder, P.: The mapillary vistas dataset for semantic understanding of street scenes. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2017) 12
58. Pan, X., Zhan, X., Shi, J., Tang, X., Luo, P.: Switchable whitening for deep representation learning. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 12
59. Park, W., Kim, D., Lu, Y., Cho, M.: Relational knowledge distillation. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019) 3
60. Pereyra, G., Tucker, G., Chorowski, J., Kaiser, Å., Hinton, G.: Regularizing neural networks by penalizing confident output distributions. In: ICLR Workshop (2017) 2, 4
61. Richter, S.R., Vineet, V., Roth, S., Koltun, V.: Playing for data: Ground truth from computer games. In: Proc. European Conference on Computer Vision (ECCV) (2016) 12
62. Ristani, E., Solera, F., Zou, R., Cucchiara, R., Tomasi, C.: Performance measures and a data set for multi-target, multi-camera tracking. In: Proc. European Conference on Computer Vision (ECCV) (2016) 11
63. Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.M.: The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016) 12
64. Sagawa, S., Koh, P.W., Hashimoto, T.B., Liang, P.: Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. In: Proc. International Conference on Learning Representations (ICLR) (2020) 11
65. Seo, S., Suh, Y., Kim, D., Kim, G., Han, J., Han, B.: Learning to optimize domain specific normalization for domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2020) 3, 10
66. Shankar, S., Piratla, V., Chakrabarti, S., Chaudhuri, S., Jyothi, P., Sarawagi, S.: Generalizing across domains via cross-gradient training. In: Proc. International Conference on Learning Representations (ICLR) (2018) 3, 10

--- TRANG 19 ---
Cross-Domain Ensemble Distillation for Domain Generalization 19

67. Stutz, D., Hein, M., Schiele, B.: Relating adversarially robust generalization to flat minima. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2021) 13
68. Sun, B., Saenko, K.: Deep coral: Correlation alignment for deep domain adaptation. In: Proc. European Conference on Computer Vision (ECCV) (2016) 11
69. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the inception architecture for computer vision. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016) 13
70. Ulyanov, D., Vedaldi, A., Lempitsky, V.: Instance normalization: The missing ingredient for fast stylization. arXiv preprint arXiv:1607.08022 (2016) 6
71. Vapnik, V.: Statistical learning theory. NY: Wiley (1998) 11
72. Venkateswara, H., Eusebio, J., Chakraborty, S., Panchanathan, S.: Deep hashing network for unsupervised domain adaptation. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017) 9
73. Verma, V., Lamb, A., Beckham, C., Najafi, A., Mitliagkas, I., Lopez-Paz, D., Bengio, Y.: Manifold mixup: Better representations by interpolating hidden states. In: Proc. International Conference on Machine Learning (ICML) (2019) 13
74. Wang, S., Yu, L., Li, C., Fu, C.W., Heng, P.A.: Learning from extrinsic and intrinsic supervisions for domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2020) 10
75. Wang, Z., Luo, Y., Qiu, R., Huang, Z., Baktashmotlagh, M.: Learning to diversify for single domain generalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2021) 10
76. Wu, D., Xia, S.T., Wang, Y.: Adversarial weight perturbation helps robust generalization. In: Proc. Neural Information Processing Systems (NeurIPS) (2020) 13
77. Xu, Q., Zhang, R., Zhang, Y., Wang, Y., Tian, Q.: A fourier-based framework for domain generalization. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 3, 10
78. Xu, T.B., Liu, C.L.: Data-distortion guided self-distillation for deep neural networks. In: Proc. AAAI Conference on Artificial Intelligence (AAAI) (2019) 4
79. Xu, Z., Li, W., Niu, L., Xu, D.: Exploiting low-rank structure from latent domains for domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2014) 3
80. Yao, Z., Gholami, A., Keutzer, K., Mahoney, M.W.: Pyhessian: Neural networks through the lens of the hessian. In: 2020 IEEE International Conference on Big Data (Big Data) (2020) 13
81. Yu, F., Xian, W., Chen, Y., Liu, F., Liao, M., Madhavan, V., Darrell, T.: Bdd100k: A diverse driving video database with scalable annotation tooling. arXiv preprint arXiv:1805.04687 (2018) 12
82. Yue, X., Zhang, Y., Zhao, S., Sangiovanni-Vincentelli, A., Keutzer, K., Gong, B.: Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 12
83. Yun, S., Han, D., Oh, S.J., Chun, S., Choe, J., Yoo, Y.: Cutmix: Regularization strategy to train strong classifiers with localizable features. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 14
84. Yun, S., Park, J., Lee, K., Shin, J.: Regularizing class-wise predictions via self-knowledge distillation. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2020) 4, 5
85. Zagoruyko, S., Komodakis, N.: Wide residual networks. In: Proc. British Machine Vision Conference (BMVC) (2016) 14

--- TRANG 20 ---
20 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

86. Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical risk minimization. In: Proc. International Conference on Learning Representations (ICLR) (2018) 11, 13, 14
87. Zhang, L., Song, J., Gao, A., Chen, J., Bao, C., Ma, K.: Be your own teacher: Improve the performance of convolutional neural networks via self distillation. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 2, 4, 7, 8
88. Zhang, M.M., Marklund, H., Dhawan, N., Gupta, A., Levine, S., Finn, C.: Adaptive risk minimization: A meta-learning approach for tackling group shift. In: Proc. Neural Information Processing Systems (NeurIPS) (2021) 11
89. Zhang, Y., Xiang, T., Hospedales, T.M., Lu, H.: Deep mutual learning. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2018) 2, 4, 7, 8
90. Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., Tian, Q.: Scalable person re-identification: A benchmark. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2015) 3, 11
91. Zheng, Z., Zheng, L., Yang, Y.: Unlabeled samples generated by gan improve the person re-identification baseline in vitro. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2017) 3, 11
92. Zhong, Z., Zheng, L., Kang, G., Li, S., Yang, Y.: Random erasing data augmentation. In: Proc. AAAI Conference on Artificial Intelligence (AAAI) (2020) 11
93. Zhou, K., Yang, Y., Hospedales, T., Xiang, T.: Learning to generate novel domains for domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2020) 3, 10
94. Zhou, K., Yang, Y., Qiao, Y., Xiang, T.: Domain adaptive ensemble learning. IEEE Transactions on Image Processing (TIP) (2021) 3
95. Zhou, K., Yang, Y., Qiao, Y., Xiang, T.: Domain generalization with mixstyle. In: Proc. International Conference on Learning Representations (ICLR) (2021) 4, 7, 10, 11, 13

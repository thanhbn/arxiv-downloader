# Cross-Domain Ensemble Distillation
# cho Domain Generalization
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-distillation/2211.14058.pdf
# Kích thước file: 3474070 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Cross-Domain Ensemble Distillation
for Domain Generalization
Kyungmoon Lee1,2Sungyeon Kim1Suha Kwak1
1POSTECH, Pohang, Korea2NALBI Inc., Seoul, Korea
kyungmoon@nalbi.ai, {sungyeon.kim, suha.kwak }@postech.ac.kr
http://cvlab.postech.ac.kr/research/XDED/
Tóm tắt. Domain generalization là nhiệm vụ học các mô hình có khả năng tổng quát hóa đến các miền đích chưa thấy. Chúng tôi đề xuất một phương pháp đơn giản nhưng hiệu quả cho domain generalization, được gọi là cross-domain ensemble distillation (XDED), học các đặc trưng bất biến miền đồng thời khuyến khích mô hình hội tụ về flat minima, điều mà gần đây được chứng minh là điều kiện đủ cho domain generalization. Để đạt được điều này, phương pháp của chúng tôi tạo ra một ensemble từ các output logits của dữ liệu huấn luyện có cùng nhãn nhưng từ các miền khác nhau và sau đó phạt mỗi output cho sự không khớp với ensemble. Ngoài ra, chúng tôi trình bày một kỹ thuật de-stylization chuẩn hóa các đặc trưng để khuyến khích mô hình tạo ra các dự đoán nhất quán về phong cách ngay cả trong một miền đích tùy ý. Phương pháp của chúng tôi cải thiện đáng kể khả năng tổng quát hóa trong các benchmark công khai cho phân loại ảnh cross-domain, person re-ID cross-dataset, và semantic segmentation cross-dataset. Hơn nữa, chúng tôi chỉ ra rằng các mô hình được học bởi phương pháp của chúng tôi có khả năng chống lại các cuộc tấn công adversarial và image corruptions.
Từ khóa: domain generalization, knowledge distillation, flat minima

1 Giới thiệu
Các mạng neural sâu (DNNs) đã mang lại những tiến bộ đáng kể trong một số lĩnh vực nghiên cứu như phân loại ảnh [43], tổng hợp ảnh [24], và học tăng cường [54]. Thành công lớn của DNNs phụ thuộc rất nhiều vào giả định rằng dữ liệu huấn luyện và kiểm tra được lấy mẫu theo điều kiện độc lập và phân phối đồng nhất (i.i.d.). Tuy nhiên, giả định này thường không đúng trong các tình huống thực tế; một lỗi lớn xảy ra do sự khác biệt giữa dữ liệu huấn luyện và kiểm tra, còn được gọi là vấn đề domain shift. Như một giải pháp cho vấn đề này, domain generalization, nhiệm vụ học các mô hình tổng quát hóa đến các miền đích chưa thấy, đang được chú ý. Một chìa khóa cho thành công của domain generalization là học các đặc trưng bất biến qua các miền. Để đạt được điều này, hầu hết các phương pháp trước đây căn chỉnh phân phối đặc trưng của nhiều miền bằng adversarial training [48,49], giảm thiểu sự khác biệt giữa phân phối của các miền nguồn [55], hoặc contrastive learning [40]. Sau đó, một bộ phân loại được huấn luyện để dự đoán nhãn cho các đặc trưng nguồn đã căn chỉnh với hy vọng rằng nó cũng sẽ tổng quát hóa tốt arXiv:2211.14058v1  [cs.CV]  25 Nov 2022

--- TRANG 2 ---
2 Kyungmoon Lee, Sungyeon Kim, Suha Kwak
Sketch
35.66%14.02%3.38%0.01%46.86%0.01%0.02%DogElephantGiraffeGuitarHorseHousePerson
Photo
1.48%0. 38%0. 32%0. 00%0.22%0.16%DogElephantGiraffeGuitarHorseHousePerson97.39%Art Painting
DogElephantGiraffeGuitarHorseHousePerson33.22%3.21%0.61%0.30%62.30%0.13%0.20%
Cartoon
8.03%2.16%17.04%2.82%55.82%13.77%0.32%DogElephantGiraffeGuitarHorseHousePerson23
DogElephantGiraffeGuitarHorseHousePerson19.59%4.94%5.33%0.78%65.59%0.17%3.53%
distilldistilldistilldistill
Hình 1: Minh họa cross-domain ensemble distillation (XDED). Mặc dù bốn hình ảnh có cùng nhãn lớp, các dự đoán của chúng thể hiện các quan hệ inter-class khác nhau do khoảng cách thị giác giữa các miền. XDED xây dựng một ensemble bằng cách lấy trung bình tất cả các dự đoán và khớp nó với mỗi dự đoán.

cho bất kỳ miền đích nào. Tuy nhiên, cách tiếp cận này thường giảm hiệu suất khi miền đích khác biệt đáng kể so với các miền nguồn vì mô hình dễ bị overfit với các miền nguồn.

Trong khi đó, mối quan hệ giữa hình học của loss landscapes và khả năng tổng quát hóa đã thu hút sự chú ý ngày càng tăng [18,20,36,38]. Đặc biệt, hội tụ về flat minima trong loss landscapes được biết đến như một chìa khóa để đạt được sự robust chống lại sự dịch chuyển loss landscape giữa các tập dữ liệu huấn luyện và kiểm tra. Được truyền cảm hứng từ quan sát rằng entropy posterior cao hơn giúp mô hình hội tụ về flat minima [10,60,89], các kỹ thuật regularization entropy như self-knowledge distillation [87] và entropy maximization [9] đã được đề xuất để tăng entropy thay vì buộc mô hình phải hoàn toàn fit với dữ liệu huấn luyện ( tức là, one-hot labels) để tạo ra entropy thấp. Vì mức độ dịch chuyển loss landscape thường được mong đợi là lớn hơn trong trường hợp domain generalization, việc hội tụ về flat minima trong domain generalization là quan trọng hơn. Tuy nhiên, lợi ích của flat minima về domain generalization vẫn chưa được nghiên cứu tích cực.

Trong bài báo này, chúng tôi đề xuất một phương pháp mới, được gọi là cross-domain ensemble distillation (XDED), học các đặc trưng bất biến miền đồng thời khuyến khích hội tụ về flat minima cho domain generalization. Cụ thể, XDED tạo ra một ensemble từ các output logits cho dữ liệu có cùng nhãn nhưng từ các miền khác nhau, và sau đó phạt mỗi output cho sự không khớp với ensemble (Hình 1). Bằng cách làm vậy, nó cho phép mô hình học các đặc trưng bất biến miền bằng cách thực thi tính nhất quán dự đoán giữa dữ liệu có cùng nhãn nhưng từ các miền khác nhau. Ngoài ra, XDED tăng entropy posterior của mỗi phân phối output, điều này giúp mô hình hội tụ về flat minima như entropy regularization làm. Theo hiểu biết tốt nhất của chúng tôi, XDED là phương pháp đầu tiên đạt được hai mục tiêu này đồng thời cho domain generalization, và đóng góp này dẫn đến cải thiện hiệu suất đáng kể.

--- TRANG 3 ---
Cross-Domain Ensemble Distillation for Domain Generalization 3

Vì XDED vẫn bị giới hạn trong việc khai thác thông tin chỉ từ các miền nguồn, vẫn còn chỗ để giảm domain gap với miền đích. Do đó, chúng tôi cũng giới thiệu một kỹ thuật de-stylization phù hợp với domain generalization, được gọi là UniStyle. UniStyle ngăn chặn bias phong cách đặc trưng miền đơn giản bằng cách chuẩn hóa các feature maps trung gian của ảnh đầu vào trong cả quá trình huấn luyện và kiểm tra. Nhờ UniStyle, mô hình của chúng tôi tạo ra các dự đoán nhất quán về phong cách không chỉ cho các miền nguồn mà còn cho miền đích, điều này giảm đáng kể domain gap và tăng cường hiệu ứng của XDED.

Dựa trên kết quả lý thuyết gần đây về mối quan hệ giữa domain generalization và tính phẳng của local minima [8], chúng tôi trước tiên chứng minh thực nghiệm rằng framework được đề xuất có thể cải thiện khả năng tổng quát hóa bằng cách đạt được hai mục tiêu: thúc đẩy flat minima và giảm domain gap. Tiếp theo, chúng tôi tiếp tục chứng minh tính ưu việt của phương pháp thông qua kết quả thực nghiệm mở rộng. Trên các benchmark công khai tiêu chuẩn cho phân loại ảnh cross-domain, XDED tăng cường đáng kể khả năng tổng quát hóa trong cả cài đặt multi-source và single-source. Chúng tôi cũng xác thực hiệu quả của phương pháp trong các tình huống domain generalization khác nhau bằng cách cho thấy cải thiện không tầm thường trên DomainBed [26], person re-ID cross-dataset [90,91], và các thực nghiệm semantic segmentation cross-dataset. Hơn nữa, chúng tôi chứng minh rằng các mô hình được học bởi phương pháp của chúng tôi cũng giúp đạt được sự robust chống lại các cuộc tấn công adversarial và image corruptions chưa thấy.

2 Các Công trình Liên quan

Domain generalization. Mục tiêu của domain generalization là học các đặc trưng bất biến miền tổng quát hóa tốt đến các miền đích chưa thấy. Để đạt mục đích này, các phương pháp hiện có khớp phân phối đặc trưng của các miền khác nhau bằng adversarial feature alignment [48,49] hoặc giảm sự khác biệt giữa phân phối đặc trưng của các miền nguồn đa dạng [55]. Gần đây, các framework meta-learning [2,16,47] đã được giới thiệu để mô phỏng domain shift bằng cách chia các miền meta-train và meta-test từ các miền nguồn. Ngoài ra, các phương pháp data augmentation đã được đề xuất để tạo ra dữ liệu đa dạng hơn ngoài những dữ liệu của các miền nguồn đã cho [37,41,66,77,93]. Giống nhất với framework của chúng tôi, các phương pháp ensemble cho domain generalization đã được đề xuất [79,65,94]. Tất cả đều huấn luyện nhiều modules như exemplar SVMs [79], các lớp domain-specific BN [34] [65] hoặc classifiers [94], và khai thác ensemble của các modules đã học để dự đoán trong quá trình kiểm tra. Tuy nhiên, chúng tôi nhấn mạnh rằng XDED của chúng tôi sử dụng ensemble của các dự đoán mô hình như soft label và chuyển nó đến chính mô hình. Do đó, nó không yêu cầu bất kỳ module bổ sung nào trong cả quá trình huấn luyện và kiểm tra.

Knowledge distillation (KD). KD ban đầu được nghiên cứu để chuyển kiến thức của một mô hình sâu đến một mô hình nông để nén mô hình [31]. Nó cũng được sử dụng cho các mục đích khác như metric learning [59,42] và

--- TRANG 4 ---
4 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

network regularization [78,87,84]. Đặc biệt cho network regularization, self-knowledge distillation (self-KD) đã được nghiên cứu; nó chưng cất kiến thức từ chính mô hình và thực thi tính nhất quán dự đoán giữa một mẫu và mẫu bị nhiễu của nó hoặc các mẫu khác. KD đã được sử dụng cho domain adaptation [52,19], và phương pháp như vậy huấn luyện nhiều teacher models từ các miền nguồn và chưng cất ensemble của các dự đoán của chúng đến student model. Thật không may, nó đòi hỏi bộ nhớ lớn do nhiều teachers, và khó mở rộng cho domain generalization vì chúng yêu cầu ảnh đích trong quá trình huấn luyện. Ngược lại, phương pháp của chúng tôi cải thiện khả năng tổng quát hóa của mô hình trên các miền chưa thấy mà không cần ảnh đích và các teacher models bổ sung.

Flat minima trong loss landscapes. Các phân tích gần đây đã tiết lộ rằng tìm flat minima là quan trọng cho tổng quát hóa mô hình [38,18,20]. Trong bối cảnh này, nhiều phương pháp đã được đề xuất để thúc đẩy flat minima trong loss landscapes vì flat minima có lợi thế so với sharp minima trong khả năng robust chống lại sự dịch chuyển loss landscape giữa dữ liệu huấn luyện và kiểm tra. Trong số các tài liệu về cách thúc đẩy flat minima ( ví dụ, weight averaging [35,8] và training strategies [20,10]), chúng tôi tập trung vào các cách tiếp cận tìm kiếm entropy cao, mà XDED dựa trên. Maximum Entropy [60,9] tối đa hóa entropy của phân phối output từ một classifier. Tương tự, các phương pháp dựa trên KD cũng nhằm tạo ra entropy cao của phân phối output bằng cách phạt sự không khớp với phân phối output từ classifier khác như các peer networks được khởi tạo khác nhau [89] hoặc các subnetworks trong chính mạng [87]. Mặc dù SWAD [8] đã giới thiệu tầm quan trọng của flat minima trong lĩnh vực domain generalization, chúng tôi nhấn mạnh rằng SWAD thuộc về weight averaging nhưng không tập trung vào học các đặc trưng bất biến miền, trong khi XDED thuộc về entropy regularization cũng như được thiết kế để học các đặc trưng bất biến miền.

Bias hướng về styles. Các nghiên cứu gần đây [6,22] tiết lộ rằng DNNs phụ thuộc quá mức vào bias mạnh hướng về styles, và điều này cũng được xác nhận trong tài liệu domain generalization [12,95,37] rằng một miền thị giác có mối tương quan cao với thống kê đặc trưng. Do đó, các công trình trước đây định nghĩa styles ảnh như bias và cố gắng loại bỏ bias bằng style augmentation trong không gian thống kê đặc trưng [95,37], sử dụng một mô hình khác cố ý thiên về styles [56], hoặc giảm thiểu whitening loss [12]. Khác biệt với các kỹ thuật này, chúng tôi chỉ ra rằng một kỹ thuật de-stylization đơn giản nhưng hiệu quả dẫn đến một thước đo divergence nhỏ hơn giữa các miền đích và nguồn mà không cần phức tạp.

3 Phương pháp của chúng tôi

3.1 Cross-Domain Ensemble Distillation

Ôn lại knowledge distillation (KD). Mục tiêu của KD [31] là chuyển kiến thức của một teacher model t đến một student model s, thường là một mô hình rộng và sâu đến một mô hình nhỏ hơn, cho mục đích nén mô hình hoặc regularization mô hình. Cho điểm dữ liệu đầu vào x và nhãn y∈ {1,···, C} của nó, chúng tôi ký hiệu output logit của mô hình là z(x) = [z1(x),···, zC(x)]. Phân phối dự đoán posterior của x sau đó được công thức hóa như:

--- TRANG 5 ---
Cross-Domain Ensemble Distillation for Domain Generalization 5

P(y|x;θ, τ) =exp(zy(x)/τ)PC
i=1exp(zi(x)/τ), (1)

trong đó mô hình được tham số hóa bởi θ và τ là tham số scaling nhiệt độ.
KD thực thi để khớp các phân phối dự đoán của s và t. Cụ thể, nó được đạt được bằng cách giảm thiểu Kullback-Leibler (KL) divergence giữa các phân phối dự đoán của chúng như sau:

LKD(X;θs, τ) =X
xi∈XCX
c=1DKL(P(c|xi;θt, τ)||P(c|xi;θs, τ)), (2)

trong đó X là một batch dữ liệu đầu vào, θt và θs lần lượt là các tham số của teacher và student.

Cross-domain ensemble distillation. Chúng tôi đề xuất một phương pháp KD mới cho domain generalization, được gọi là cross-domain ensemble distillation (XDED). XDED nhằm xây dựng kiến thức bất biến miền từ dữ liệu của nhiều miền. Cụ thể, XDED tạo ra một ensemble của logits từ dữ liệu có cùng nhãn nhưng từ các miền khác nhau. Tiếp theo, XDED phạt mỗi logit cho sự không khớp với ensemble không thiên về một miền cụ thể, điều này khuyến khích học các đặc trưng bất biến miền. Không giống như KD thông thường, XDED không yêu cầu một mạng bổ sung làm tăng độ phức tạp huấn luyện ( ví dụ, tham số thêm và thời gian huấn luyện) mà chưng cất ensemble được xây dựng bởi nhiều mẫu đến chính mô hình dưới dạng self-KD.

Chính thức, gọi Xy là tập hợp các mẫu có cùng nhãn lớp y trong một mini-batch. Sau đó, chúng tôi thu được một ensemble của logits từ Xy bằng cách đơn giản lấy trung bình như:

¯z(Xy) =X
xi∈Xyz(xi)
|Xy|. (3)

Sau đó, phân phối dự đoán cho ensemble được tạo từ dữ liệu Xy là:

¯P(c|Xy;θ, τ) =exp(¯zc(Xy)/τ)PC
i=1exp(¯zi(Xy)/τ), (4)

Hàm loss của XDED được định nghĩa như sau:

LXDED (Xy;θ, τ) =X
xi∈XyCX
c=1DKL(¯P(c|Xy;ˆθ, τ)||P(c|xi;θ, τ)), (5)

trong đó ˆθ là một bản sao cố định của tham số θ. Theo [53,84], chúng tôi dừng gradient được truyền qua ˆθ để ngăn mô hình rơi vào một số giải pháp tầm thường. Tóm lại, chúng tôi đặt hàm mục tiêu của chúng tôi như

min
θLθ=LCE(X, Y ;θ) +λX
y∈{Y}LXDED (Xy;θ, τ),(6)

--- TRANG 6 ---
6 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

trong đó X là một batch ảnh đầu vào, Y là một batch nhãn lớp tương ứng, LCE ký hiệu vanilla cross-entropy loss, và λ là một siêu tham số để cân bằng LCE và LXDED. λ và τ lần lượt là 5.0 và 4.0 trong suốt bài báo này.

3.2 UniStyle: loại bỏ và thống nhất style bias

Để tiếp tục regularize mô hình tạo ra các dự đoán nhất quán về phong cách, chúng tôi đề xuất một kỹ thuật de-stylization phù hợp với domain generalization. Vì các styles miền nguồn không được mong đợi xuất hiện tại thời điểm kiểm tra, chúng tôi đề xuất UniStyle để ngăn mô hình bị thiên về các styles đặc trưng miền, điều này giảm domain gap với miền đích.

Cụ thể hơn, theo các phương pháp hiện có dựa trên style transfer [17,32,70], chúng tôi trước tiên biểu diễn neural style như thống kê của các feature maps trung gian từ feature extractor. Chính thức, gọi F∈RC×H×W ký hiệu một feature map trung gian của một ảnh. Sau đó, neural style của ảnh được biểu diễn như sự kết hợp của mean μ(F)∈RC theo từng kênh và standard deviation σ(F)∈RC của F như:

μc(F) =1
HWHX
h=1WX
w=1Fc,h,w, (7)

và

σc(F) =vuut1
HWHX
h=1WX
w=1(Fc,h,w−μc(F))2, (8)

trong đó μ(F) = [ μ1(F),···, μC(F)] và σ(F) = [ σ1(F),···, σC(F)]. Tiếp theo, chúng tôi đơn giản chuẩn hóa mỗi đặc trưng để có thống kê theo từng kênh không đổi, μW và σW như:

UniStyle( F) =σWF−μ(F)
σ(F)+μW, (9)

trong đó μW=0 và σW=1(tức là, chuẩn hóa zero-mean). Về mặt kỹ thuật, UniStyle là một trường hợp đặc biệt của InstanceNorm (IN) [70]. Tuy nhiên, chúng tôi nhấn mạnh rằng UniStyle nhằm loại bỏ thông tin đặc trưng miền mà không có bất kỳ tham số học được nào để giảm domain gap trong khi IN học các tham số scaling và bias theo từng kênh cho style transfer. Ngoài ra, lưu ý rằng chúng tôi quan sát thực nghiệm rằng UniStyle hiệu quả khi được áp dụng tại nhiều lớp sớm, điều này phù hợp với các nghiên cứu gần đây [17,32] cho rằng thông tin style thường được nắm bắt tại các lớp sớm.1

3.3 Phân tích Phương pháp của chúng tôi

Trong phần này, chúng tôi phân tích hiệu quả của XDED, đặc biệt thông qua liên kết với kết quả lý thuyết và các bằng chứng thực nghiệm hỗ trợ. Chúng tôi trước tiên bắt đầu với một định lý liên quan đến domain adaptation [3,4], cho thấy rằng

1Xem tài liệu bổ sung để phân tích thêm.

--- TRANG 7 ---
Cross-Domain Ensemble Distillation for Domain Generalization 7

Bảng 1: So sánh các giá trị entropy. Khi mỗi mô hình hội tụ, giá trị entropy được tính bằng cách lấy trung bình trên tất cả các mẫu huấn luyện.

OfficeHome (Clipart) PACS (Cartoon)
Phương pháp Entropy Accuracy Entropy Accuracy
ResNet-18 0.25 49.4 0.01 75.9
MixStyle [95] 0.35 53.4 0.03 78.8
XDED 0.92 55.2 0.38 81.7

rủi ro mong đợi trên miền đích được giới hạn bởi rủi ro trên miền nguồn và divergence giữa các miền này. Để tìm một tham số mô hình θ∈Θ cho domain generalization, Cha et al. [8] đã xem xét một robust empirical loss:

ˆεγ
S(θ) := max
||∆||≤γˆεS(θ+∆)(10)

trong đó ˆ εS(θ) là empirical risk trên các miền nguồn S và γ là bán kính định nghĩa các tham số láng giềng của θ. Sau đó, Cha et al. [8] đã chứng minh rằng tìm flat minima giảm domain gap thông qua định lý dưới đây:

Định lý 1. Xem xét một tập hợp N covers {Θk}N
k=1 sao cho không gian giả thuyết Θ⊂ ∪N
kΘk trong đó diam (Θ) := supθ,θ′∈Θ||θ−θ′||2, N:=⌈(diam (Θ)/γ)d⌉ và d là chiều của Θ. Gọi vk là VC dimension của mỗi Θk. Sau đó, với bất kỳ θ∈Θ, ranh giới sau đây giữ với xác suất ít nhất 1−δ,

εT(θ)<ˆεγ
S(θ) +1
2IIX
i=1Div(Si, T) + max
k∈[1,N]r
vkln (m/v k) + ln ( N/δ)
m,(11)

trong đó m=nI là số lượng mẫu huấn luyện và Div (Si, T) là divergence giữa miền nguồn Si và miền đích T.

Chúng tôi nhấn mạnh rằng, trong Eq. (11), test loss εT(θ) được giới hạn bởi ba thành phần: (1) robust empirical loss ˆ εγ
S(θ), (2) divergence Div( Si, T), và (3) confidence bound phụ thuộc vào bán kính γ và số lượng mẫu huấn luyện m. Trong phần còn lại của phần này, theo định lý trên, chúng tôi cung cấp một giải thích lý thuyết rằng phương pháp của chúng tôi tăng cường khả năng tổng quát hóa bằng cách giảm cả ˆ εγ
S(θ) và Div( Si, T) với các bằng chứng thực nghiệm.

Thúc đẩy flat minima. Chúng tôi nhấn mạnh rằng XDED được thúc đẩy bởi các phương pháp entropy regularization gần đây [9,87,89] trong việc theo đuổi flat minima. Nó đã được chứng minh thực nghiệm rằng các phương pháp này thúc đẩy flat minima bằng cách tạo ra entropy posterior cao hơn. Nó có thể được hiểu như làm dịu quá trình huấn luyện để học thông tin phong phú hơn được mã hóa trong soft labels, điều này giúp mô hình hội tụ về flat minima hơn là buộc mô hình hoàn toàn fit với one-hot labels. Trong bối cảnh này, chúng tôi cũng chứng minh rằng XDED rõ ràng tạo ra entropy cao hơn như được thể hiện trong Bảng 1. Xem xét rằng XDED được thúc đẩy bởi quan sát rằng các miền khác nhau thể hiện các quan hệ inter-class khác nhau do domain gap (Hình 1), điều này là tự nhiên vì các ensembles của chúng tôi sẽ tích hợp các quan hệ inter-class có ý nghĩa từ nhiều miền và mô hình được học với chúng sẽ được dẫn về entropy cao.

--- TRANG 8 ---
8 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

Train LossTest Loss
𝜎𝜖𝜖0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.000102030
0102030
XDED (train)MixStyle (train)ResNet -18 (train)
XDED (test)MixStyle (test)ResNet -18 (test)

Hình 2: Train/Test losses so với weight perturbation trong khi thay đổi standard deviation của Gaussian noise được thêm vào. Lưu ý rằng kết quả được tạo ra với miền đích (Art của PACS) và các miền nguồn còn lại, và các giá trị loss được chia logarit.

Accuracy (%)
75.080.085.0
1.751.801.85A-Distance

Hình 3: So sánh với các phương pháp hiện có thúc đẩy flat minima. Mỗi mô hình được đánh giá trên Cartoon của PACS sau khi được huấn luyện trên các miền nguồn còn lại. Trái: Divergence ( A-distance) giữa các miền nguồn và miền đích, Phải: Hiệu suất tổng quát hóa trên miền đích.

Tiếp theo, để điều tra xem mô hình được học với XDED có thực sự hội tụ về flat minima hay không, chúng tôi định lượng độ phẳng của local minima nơi mô hình hội tụ bằng cách đo sự tăng của các giá trị loss giữa θ và các vùng lân cận của nó, giả định rằng mô hình hội tụ trong flat minima sẽ có sự tăng nhỏ hơn. Theo [8,9,87,89], chúng tôi đo các losses của các mô hình đã học trước và sau khi thêm Gaussian noises vào các tham số mô hình trong khi thay đổi standard deviation của noise σϵ(tức là,LCE(X, Y ;θ+ϵ) trong đó ϵ∼N(0, σϵ)) với 100 lần chạy. Kết quả là, XDED chứng minh khả năng robust của nó chống lại weight perturbation với sự tăng loss nhỏ hơn như được thể hiện trong Hình 2.

Học đặc trưng bất biến miền. Ở đây, chúng tôi nhấn mạnh rằng XDED cũng học các đặc trưng bất biến miền thông qua việc regularize tính nhất quán giữa các dự đoán từ dữ liệu có cùng nhãn nhưng từ các miền khác nhau và ensemble của chúng. Do đó, chúng tôi so sánh XDED với các phương pháp hiện có thúc đẩy flat minima, được dành riêng chỉ cho độ phẳng của local minima. Cụ thể, để kiểm tra hiệu quả trong việc giảm divergence Div( Si, T), chúng tôi đo A-distance [3,39]. Do tính không thể tính toán được, chúng tôi đã tính một cái xấp xỉ [50,56]2 Như được thể hiện trong Hình 3 (Trái), chúng tôi quan sát rằng các phương pháp hiện có thúc đẩy flat minima thất bại trong việc giảm khoảng cách trong khi XDED rõ ràng giảm khoảng cách và UniStyle tiếp tục tăng cường kết quả. Một cách tự nhiên, kết quả đó được kết nối với tính ưu việt định lượng của framework của chúng tôi so với các phương pháp thúc đẩy flat minima hiện có (Hình 3 (Phải)).

4 Thực nghiệm

4.1 Tổng quát hóa trong phân loại ảnh

Multi-source domain generalization. Cụ thể, để so sánh công bằng, chúng tôi theo giao thức leave-one-domain-out [45] trong đó chúng tôi huấn luyện một mô hình trên ba miền và đánh giá nó trên miền còn lại. Đối với các tập dữ liệu benchmark, chúng tôi sử dụng PACS [45] và OfficeHome [72] là các benchmarks được sử dụng rộng rãi cho domain generalization trong phân loại ảnh. PACS chứa 9,991 ảnh của 7 lớp trên 4 miền: Art Painting, Cartoon, Photo, và Sketch. OfficeHome bao gồm 15,500 ảnh của 65 lớp trên 4 miền: Artistic, Clipart, Product, và Real. Chúng tôi sử dụng ResNet-18 [27] làm backbone, và UniStyle của chúng tôi được áp dụng cho các feature maps đầu ra của khối residual thứ nhất và thứ hai cho PACS và chỉ khối thứ nhất cho OfficeHome.

Kết quả. Như được tóm tắt trong Bảng. 2, chúng tôi quan sát rằng phương pháp của chúng tôi không chỉ tăng cường đáng kể vanilla mà còn vượt trội so với các phương pháp cạnh tranh mới nhất. Đặc biệt, phương pháp của chúng tôi vượt trội so với phương pháp tốt thứ hai trên Cartoon của PACS và Clipart của OfficeHome khoảng 4.0% và 2.0% tương ứng. Những kết quả này chứng minh tính ưu việt của phương pháp của chúng tôi, đơn giản nhưng hiệu quả.

Single-source domain generalization Nhờ thiết kế đơn giản của phương pháp được đề xuất, không yêu cầu rõ ràng các nhãn miền, phương pháp của chúng tôi có thể được tích hợp minh bạch với single-source domain generalization trong đó chúng tôi chỉ có quyền truy cập vào một miền nguồn duy nhất trong quá trình huấn luyện. Do đó, để tiếp tục đánh giá tác động của phương pháp đối với single-source domain generalization, mô hình của chúng tôi được huấn luyện trên mỗi miền đơn lẻ của PACS và được đánh giá trên các miền đích còn lại.

Kết quả. Như được thể hiện trong Bảng. 3, mô hình của chúng tôi, trung bình, vượt trội đáng kể so với các baselines khác 8.7% về độ chính xác trung bình. Bên cạnh đó, trong tất cả các trường hợp ngoại trừ trường hợp C→S, mô hình của chúng tôi cho thấy tính ưu việt về hiệu suất. Chúng tôi tin rằng kết quả thú vị này xuất phát từ thực tế rằng phương pháp của chúng tôi vẫn có thể giúp mô hình hội tụ về flat minima và khai thác các quan hệ tinh tế giữa các mẫu intra-domain ngay cả khi chỉ có một miền nguồn duy nhất được cung cấp.

DomainBed. Chúng tôi cũng thực hiện các thực nghiệm mở rộng trên DomainBed [26] là một testbed cho domain generalization để so sánh các phương pháp tiên tiến qua nhiều tập dữ liệu benchmark. Lý do đằng sau DomainBed là các hiệu suất domain generalization phụ thuộc quá nhiều vào

2Nó được định nghĩa là ˆdA= 2(1−2ϵsvm) trong đó ϵsvm là generalization error của một SVM-based two-class classifier được huấn luyện để phân biệt giữa các miền đích và nguồn.

--- TRANG 9 ---
Cross-Domain Ensemble Distillation for Domain Generalization 9

--- TRANG 10 ---
10 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

Bảng 2: Kết quả tổng quát hóa leave-one-domain-out trên PACS và OfficeHome.

PACS OfficeHome
Phương pháp Art CartoonPhoto Sketch Avg. Artistic Clipart Product Real Avg.
ResNet-18 77.0 75.9 96.0 69.2 79.5 58.9 49.4 74.3 76.2 64.7
MMD-AE [48] 75.2 72.7 96.0 64.2 77.0 56.5 47.3 72.1 74.8 62.7
JiGen [7] 79.4 75.3 96.0 71.6 80.5 53.0 47.4 71.4 72.7 61.2
CrossGrad [66] 79.8 76.8 96.0 70.2 80.7 58.4 49.4 73.9 75.8 64.4
MASF [16] 80.2 77.1 94.9 71.6 81.0 - - - - -
Epi-FCR [47] 82.1 77.0 93.9 73.0 81.5 - - - - -
EISNet [74] 81.8 76.4 95.9 74.3 82.1 - - - - -
L2A-OT [93] 83.3 78.2 96.2 73.6 82.8 60.6 50.1 74.8 77.0 65.6
SagNet [56] 83.5 77.6 95.4 76.3 83.2 60.2 45.3 70.4 73.3 62.3
SelfReg [40] 82.3 78.4 96.2 77.4 83.6 - - - - -
MixStyle [95] 84.1 78.8 96.1 75.9 83.7 58.7 53.4 74.2 75.9 65.5
L2D [75] 81.4 79.5 95.5 80.5 84.2 - - - - -
FACT [77] 85.3 78.3 95.1 79.1 84.5 60.3 54.8 74.4 76.5 66.5
DSON [65] 84.6 77.6 95.8 82.2 85.1 59.3 45.7 71.8 74.6 62.9
RSC [33] 83.4 80.3 95.9 80.8 85.1 58.4 47.9 71.6 74.5 63.1
StyleNeophile [37] 84.4 79.2 94.9 83.2 85.4 59.5 55.0 73.5 75.5 65.8
Của chúng tôi 85.6 84.2 96.5 79.1 86.4 60.8 57.1 75.3 76.5 67.4

Bảng 3: Độ chính xác single-source domain generalization (%) trên PACS với ResNet-18. (A: Art Painting, C: Cartoon, S:Sketch, P:Photo).

Phương pháp A)C A )S A )P C )A C )S C )P S )A S )C S )P P )A P )C P )SAvg.
ResNet-18 62.3 49.0 95.2 65.7 60.7 83.6 28.0 54.5 35.6 64.1 23.6 29.1 54.3
JiGen [7] 57.0 50.0 96.1 65.3 65.9 85.5 26.6 41.1 42.8 62.4 27.2 35.5 54.6
MixStyle [95] 65.5 49.8 96.7 69.9 64.5 85.3 27.1 50.9 32.6 67.7 38.9 39.1 57.4
RSC [33] 62.5 53.1 96.2 68.9 70.3 85.8 37.9 56.3 47.4 66.3 26.4 32.0 58.6
SelfReg [40] 65.2 55.9 96.6 72.0 70.0 87.5 37.1 54.0 46.0 67.7 28.9 33.7 59.5
SagNet [56] 67.1 56.8 95.7 72.1 69.2 85.7 41.1 62.9 46.2 69.8 35.1 40.7 61.9
Của chúng tôi 74.6 58.1 96.8 74.4 69.6 87.6 43.3 65.6 50.3 71.4 54.3 51.5 66.5

việc điều chỉnh siêu tham số. Để so sánh công bằng, chúng tôi tuân theo các giao thức tiêu chuẩn của nó để huấn luyện và đánh giá.

Kết quả. Như được thể hiện trong Bảng. 4, phương pháp của chúng tôi nói chung cho thấy hiệu suất cạnh tranh và xếp thứ hai trong số 15 phương pháp về độ chính xác trung bình. Đặc biệt, trên CMNIST, phương pháp của chúng tôi vượt trội đáng kể so với các phương pháp cạnh tranh khác. Vì CMNIST được thiết kế để mô phỏng domain shift bằng cách tương quan màu sắc chữ số với nhãn lớp, chúng tôi phỏng đoán rằng cải thiện của chúng tôi trên CMNIST được quy cho hiệu ứng de-stylization của UniStyle, điều này sẽ giúp mô hình tách rời mối tương quan giữa màu sắc và nhãn.

4.2 Tổng quát hóa trong person re-ID

Trong phần này, chúng tôi tiếp tục đánh giá phương pháp của chúng tôi trên person re-identification (re-ID), là việc khớp người đi bộ qua các góc nhìn camera không chồng chéo.

Thiết lập thực nghiệm. Ở đây, chúng tôi giải quyết domain generalization cho person re-ID, trong đó dữ liệu kiểm tra được thu thập từ cameras của tập dữ liệu chưa thấy thay vì

--- TRANG 11 ---
Cross-Domain Ensemble Distillation for Domain Generalization 11

Bảng 4: Độ chính xác domain generalization (%) trên DomainBed. Cột "Terra" đại diện cho tập dữ liệu TerraIncognita. Lưu ý rằng chúng tôi áp dụng leave-one-domain-out cross-validation như một tiêu chí lựa chọn mô hình.

Lựa chọn mô hình: leave-one-domain-out cross-validation
Phương pháp CMNIST RMNIST VLCS PACS OfficeHome Terra Avg.
ERM [71] 36.7 97.7 77.2 83.0 65.7 41.4 66.9
IRM [1] 40.3 97.0 76.3 81.5 64.3 41.2 66.7
GroupDRO [64] 36.8 97.6 77.9 83.5 65.2 44.9 66.7
Mixup [86] 33.4 97.8 77.7 83.2 67.0 48.7 67.9
MLDG [46] 36.7 97.6 77.2 82.9 66.1 46.2 67.7
CORAL [68] 39.7 97.8 78.7 82.6 68.5 46.3 68.9
MMD [48] 36.8 97.8 77.3 83.2 60.2 46.5 66.9
DANN [21] 40.7 97.6 76.9 81.0 64.9 44.4 67.5
CDANN [49] 39.1 97.5 77.5 78.8 64.3 39.9 66.1
MTL [5] 35.0 97.8 76.6 83.7 65.7 44.9 67.2
SagNet [56] 36.5 94.0 77.5 82.3 67.6 47.2 67.5
ARM [88] 36.8 98.1 76.6 81.7 64.4 42.6 66.7
VREx [44] 36.9 93.6 76.7 81.3 64.9 37.3 65.1
RSC [33] 36.5 97.6 77.5 82.6 65.8 40.0 66.6
Của chúng tôi 46.5 97.7 74.8 83.8 65.0 42.5 68.4

Bảng 5: Kết quả tổng quát hóa trên cross-dataset person re-ID.

Market→Duke Duke→Market
Phương pháp mAP R@1 mAP R@1
ResNet-50 19.3 35.4 20.4 45.2
RandomErase [92] 14.3 27.8 16.1 38.5
DropBlock [23] 18.2 33.2 19.7 45.3
MixStyle [95] 23.4 43.3 24.7 53.0
StyleNeophile [37] 26.3 46.5 27.2 55.0
Của chúng tôi 27.4 49.3 30.1 59.0

từ những tập dữ liệu huấn luyện. Cụ thể, mô hình được huấn luyện để khớp người trong tập dữ liệu nguồn được đánh giá bằng mức độ khớp tốt dữ liệu người đi bộ của tập kiểm tra chưa thấy, chúng tách rời khỏi tập dữ liệu nguồn. Đối với tập dữ liệu, chúng tôi áp dụng hai benchmarks được sử dụng rộng rãi: Market1501 (Market) [90] và DukeMTMC-reID (Duke) [62,91]. Chúng tôi sử dụng 32,668 ảnh của 1,501 identities được thu thập từ 6 cameras và 36,411 ảnh của 1,812 identities từ 8 cameras cho Market1501 và Duke tương ứng. Đối với các thước đo hiệu suất, chúng tôi áp dụng mean average precision (mAP) và Recall@K (R@K). Theo công trình trước [95], chúng tôi áp dụng ResNet-50 [27] làm kiến trúc backbone. Trong những thực nghiệm này, chúng tôi áp dụng UniStyle cho khối residual thứ 1, 2, và 3 của mô hình.

So sánh với các phương pháp regularization khác. Như được thể hiện trong Bảng. 5, phương pháp của chúng tôi vượt trội đáng kể so với các phương pháp khác về mAP và Recall@1. Mặc dù RandomErase và Dropblock hiệu quả cho việc học các đặc trưng phân biệt, chúng thất bại trong việc cải thiện hiệu suất khi gặp dữ liệu miền chưa thấy. Hơn nữa, bằng cách khai thác các quan hệ inter-class được cung cấp bởi các camera khác nhau

--- TRANG 12 ---
12 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

Bảng 6: Kết quả mIoU (%) trên cross-dataset semantic segmentation. GTA5 để huấn luyện, và Cityscapes, SYNTHIA, BDD, và Mapillary là các tập kiểm tra.

Phương pháp (GTA5) Cityscapes BDD Mapillary SYNTHIA
DeepLabV3+ [11] 28.9 25.1 28.1 26.2
SW [58] 29.9 27.4 29.7 27.6
DRPC [82] 37.4 32.1 34.1 28.0
RobustNet [12] 36.5 35.2 40.3 28.3
Của chúng tôi 39.2 32.4 37.1 28.0

Bảng 7: Nghiên cứu ablation của các thành phần được đề xuất trên các nhiệm vụ cross-domain của phân loại ảnh (Accuracy) và person re-ID (mAP).

Phương pháp Art Clipart Market→Duke
Vanilla 77.0 49.4 19.3
w/ UniStyle 81.2 50.4 26.2
w/ XDED 83.3 55.2 24.2
Của chúng tôi 85.6 57.1 27.4

eras, phương pháp của chúng tôi cho thấy tính ưu việt so với MixStyle và StyleNeophile được thiết kế cho domain generalization nhưng chỉ sử dụng one-hot labels.

4.3 Tổng quát hóa trong semantic segmentation

Thiết lập thực nghiệm. Cuối cùng, để điều tra xem phương pháp của chúng tôi có thể được mở rộng cho nhiệm vụ dense prediction hay không, đánh giá trên semantic segmentation được giải quyết ở đây. Theo giao thức chính thống, chúng tôi huấn luyện mô hình trên tập dữ liệu tổng hợp và đánh giá chúng trên nhiều tập dữ liệu chủ yếu thuộc về thế giới thực. Cụ thể, chúng tôi áp dụng GTA5 [61] làm tập dữ liệu nguồn bao gồm 24,966 ảnh. Đối với các tập dữ liệu đích, Cityscapes [13], BDD [81], và Mapillary [57] là các tập dữ liệu thế giới thực có kích thước ảnh lần lượt là 5,000, 10,000, và 25,000. Cuối cùng, SYNTHIA [63] có 9,400 ảnh. Lưu ý rằng ResNet-50 được sử dụng làm backbone và 19 lớp chung được sử dụng qua tất cả các tập dữ liệu.

Kết quả. Chúng tôi nhấn mạnh rằng XDED xây dựng ensemble bằng cách đơn giản lấy trung bình tất cả các logits từ các pixels có gt giống nhau trong một mini-batch. Như được thể hiện trong Bảng 6, phương pháp của chúng tôi vượt trội so với các phương pháp cạnh tranh tổng thể, ngay cả khi những phương pháp đó chỉ dành riêng cho nhiệm vụ này. Chúng tôi chỉ ra rằng phương pháp của chúng tôi có thể được mở rộng cho phân loại theo từng pixel với ít sửa đổi trên XDED. Ngoài ra, kết quả hỗ trợ tuyên bố của chúng tôi rằng phương pháp của chúng tôi đơn giản nhưng hiệu quả trong một loạt các nhiệm vụ.

4.4 Phân tích Sâu

Nghiên cứu ablation. Để điều tra tác động của mỗi thành phần trong phương pháp của chúng tôi, chúng tôi thực hiện nghiên cứu ablation được tóm tắt trong Bảng 7. Kết quả tiết lộ rằng hai thành phần bổ sung cho nhau và nhất quán giúp mô hình cải thiện khả năng tổng quát hóa. Đối với phân loại ảnh, XDED đóng góp nhiều nhất cho hiệu suất, và UniStyle tăng cường hiệu ứng của XDED. Trên cả hai

--- TRANG 13 ---
Cross-Domain Ensemble Distillation for Domain Generalization 13

Loss𝜀!𝜀"Sketch (test)
Loss𝜀!𝜀"Photo (test)
Loss𝜀!𝜀"Cartoon (test)
Art Painting (test)Loss𝜀!𝜀"

Hình 4: Kết quả visualization của loss landscapes tích hợp phương pháp vanilla và XDED trên tập dữ liệu PACS. Lưu ý rằng mỗi loss landscape được visualization trên dữ liệu của các miền nguồn, không phải dữ liệu của miền đích được đánh dấu. Các bề mặt xanh và đỏ lần lượt từ phương pháp vanilla và XDED.

Bảng 8: Độ chính xác multi-source domain generalization (%) trên Photo của PACS trước và sau khi áp dụng các cuộc tấn công adversarial đã cho.

Phương pháp Photo w/ FGSM w/ PGD
ResNet-18 96.0 39.6 16.3
Label smoothing [69] 95.6 43.5 20.2
Mixup [86] 95.8 46.5 21.9
Manifold mixup [73] 93.5 46.6 23.8
MixStyle [95] 96.1 41.4 22.7
Của chúng tôi 96.5 55.4 30.4

miền, XDED cải thiện đồng đều phương pháp vanilla khoảng 6%, trong khi UniStyle cho thấy các mức độ cải thiện khác nhau. Đó là vì sự khác biệt phong cách ảnh giữa các miền trong OfficeHome ít nghiêm trọng hơn so với PACS. Thú vị là, đối với nhiệm vụ person re-ID, UniStyle tiết lộ tác động lớn hơn XDED. Do đặc tính vốn có của nhiệm vụ, hiệu ứng của XDED trong việc thu thập kiến thức có ý nghĩa về cùng một người đi bộ từ các cameras khác nhau có thể trở nên ít quan trọng hơn.

Visualization loss surface. Để tiếp tục minh họa cách XDED dẫn đến flat minima trong loss landscapes, chúng tôi cung cấp kết quả định tính visualization loss landscapes. Theo [9], chúng tôi vẽ loss landscapes trên dữ liệu của các miền nguồn cho mỗi trường hợp bằng cách perturbating các tham số mô hình qua eigenvectors Hessian thứ nhất và thứ hai được cung cấp bởi PyHessian [80] là một framework cho phân tích dựa trên Hessian của mạng neural. Như được thể hiện trong Hình 4, chúng tôi quan sát rằng loss landscapes tích hợp XDED trở nên phẳng hơn rõ ràng so với những landscapes tích hợp phương pháp vanilla cho tất cả các trường hợp. Chúng tôi lập luận rằng những kết quả định tính này cũng nhất quán hỗ trợ rằng XDED thúc đẩy flat minima.

Khả năng robust đối với adversarial examples. Các nghiên cứu gần đây đã chứng minh rằng hội tụ trên flat minima tăng cường khả năng robust adversarial [76,67]. Để xác thực lại rằng phương pháp của chúng tôi thúc đẩy flat minima, chúng tôi đánh giá khả năng robust adversarial của các mô hình đã học. Cụ thể, chúng tôi huấn luyện mô hình trên các miền nguồn và thêm adversarial perturbations vào ảnh của miền đích chưa thấy bằng cách sử dụng các phương pháp tấn công adversarial hiện có: FGSM [25] và PGD [51]. Bảng 8 cho thấy rằng phương pháp của chúng tôi vượt trội so với các phương pháp regularization khác về

--- TRANG 14 ---
14 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

Bảng 9: Lỗi phân loại trung bình (%) trên các corruption benchmarks.

Phương pháp CIFAR-10-C CIFAR-100-C
40-2 WRN [85] 26.9 53.3
Cutout [15] 26.8 53.5
Mixup [86] 22.3 50.4
CutMix [83] 27.1 52.9
AutoAug [14] 23.9 49.6
AugMix [29] 11.2 35.9
Của chúng tôi 18.5 46.6

khả năng robust chống lại cả dữ liệu chưa thấy và các cuộc tấn công adversarial. Xem xét rằng các cuộc tấn công adversarial được tạo ra để tối đa hóa giá trị loss, chúng tôi lập luận rằng tính ưu việt của chúng tôi trong khả năng robust adversarial cũng được quy cho khả năng thúc đẩy flat minima như mong muốn, mặc dù phương pháp của chúng tôi không có mối liên hệ trực tiếp với adversarial training.

Kết quả trên corruption benchmarks. Chúng tôi tiếp tục đo khả năng phục hồi của các mô hình đã học đối với image corruptions. Theo giao thức được cung cấp bởi [28], chúng tôi huấn luyện mô hình trên tập dữ liệu huấn luyện gốc, và đánh giá chúng trên tập dữ liệu kiểm tra được xây dựng bằng cách làm hỏng tập dữ liệu kiểm tra gốc thông qua các loại corruption được định nghĩa trước. Bảng. 9 cho thấy rằng phương pháp của chúng tôi vượt trội so với tất cả các phương pháp regularization ngoại trừ AugMix [30]. Xem xét AugMix là một state of the art dành riêng cho khả năng robust corruption trong khi phương pháp của chúng tôi thì không, chúng tôi lập luận rằng phương pháp của chúng tôi vẫn cho thấy khả năng robust đáng kể chống lại image corruptions.

5 Kết luận

Chúng tôi đã trình bày một framework đơn giản nhưng hiệu quả cho domain generalization. XDED trước tiên tạo ra một ensemble của các phân phối output cho dữ liệu có cùng nhãn nhưng từ các miền khác nhau, và sau đó phạt mỗi phân phối output cho sự không khớp với ensemble dưới dạng self-knowledge distillation. Với cách tiếp cận này, mô hình của chúng tôi có thể học các đặc trưng bất biến miền và cũng dễ dàng hội tụ về flat minima. Bên cạnh đó, UniStyle được đề xuất ngăn chặn bias phong cách đặc trưng miền để tăng cường hiệu ứng của XDED và khuyến khích các dự đoán nhất quán về phong cách. Hơn nữa, chúng tôi xác thực thực nghiệm khả năng tổng quát hóa của phương pháp được đề xuất từ góc độ flat minima và giảm divergence giữa nguồn và đích. Thông qua kết quả thực nghiệm mở rộng, chúng tôi chứng minh tính ưu việt của framework được đề xuất.

Lời cảm ơn. Công trình này được hỗ trợ bởi NRF grant và IITP grant được tài trợ bởi Bộ Khoa học và ICT, Hàn Quốc (NRF-2021R1A2C3012728, IITP-2019-0-01906, IITP-2022-0-00926, IITP-2022-0-00290).

--- TRANG 15 ---
Cross-Domain Ensemble Distillation for Domain Generalization 15

Tài liệu Tham khảo

1. Arjovsky, M., Bottou, L., Gulrajani, I., Lopez-Paz, D.: Invariant risk minimization. arXiv preprint arXiv:1907.02893 (2019) 11
2. Balaji, Y., Sankaranarayanan, S., Chellappa, R.: Metareg: Towards domain generalization using meta-regularization. In: Proc. Neural Information Processing Systems (NeurIPS) (2018) 3
3. Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., Vaughan, J.W.: A theory of learning from different domains. Machine learning (2010) 6, 8
4. Ben-David, S., Blitzer, J., Crammer, K., Pereira, F., et al.: Analysis of representations for domain adaptation. In: Proc. Neural Information Processing Systems (NeurIPS) (2007) 6
5. Blanchard, G., Deshmukh, A.A., Dogan, U., Lee, G., Scott, C.: Domain generalization by marginal transfer learning. Journal of Machine Learning Research (JMLR) (2021) 11
6. Brendel, W., Bethge, M.: Approximating cnns with bag-of-local-features models works surprisingly well on imagenet. In: Proc. International Conference on Learning Representations (ICLR) (2019) 4
7. Carlucci, F.M., D'Innocente, A., Bucci, S., Caputo, B., Tommasi, T.: Domain generalization by solving jigsaw puzzles. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019) 10
8. Cha, J., Chun, S., Lee, K., Cho, H.C., Park, S., Lee, Y., Park, S.: Swad: Domain generalization by seeking flat minima. In: Proc. Neural Information Processing Systems (NeurIPS) (2021) 3, 4, 7, 8
9. Cha, S., Hsu, H., Hwang, T., Calmon, F.P., Moon, T.: Cpr: Classifier-projection regularization for continual learning. In: Proc. International Conference on Learning Representations (ICLR) (2021) 2, 4, 7, 8, 13
10. Chaudhari, P., Choromanska, A., Soatto, S., LeCun, Y., Baldassi, C., Borgs, C., Chayes, J., Sagun, L., Zecchina, R.: Entropy-sgd: Biasing gradient descent into wide valleys. In: Proc. International Conference on Learning Representations (ICLR) (2017) 2, 4
11. Chen, L.C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H.: Encoder-decoder with atrous separable convolution for semantic image segmentation. In: Proc. European Conference on Computer Vision (ECCV) (2018) 12
12. Choi, S., Jung, S., Yun, H., Kim, J.T., Kim, S., Choo, J.: Robustnet: Improving domain generalization in urban-scene segmentation via instance selective whitening. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 4, 12
13. Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., Schiele, B.: The cityscapes dataset for semantic urban scene understanding. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016) 12
14. Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V.: Autoaugment: Learning augmentation policies from data (2019) 14
15. DeVries, T., Taylor, G.W.: Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552 (2017) 14
16. Dou, Q., Coelho de Castro, D., Kamnitsas, K., Glocker, B.: Domain generalization via model-agnostic learning of semantic features. In: Proc. Neural Information Processing Systems (NeurIPS) (2019) 3, 10

--- TRANG 16 ---
16 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

17. Dumoulin, V., Shlens, J., Kudlur, M.: A learned representation for artistic style. In: Proc. International Conference on Learning Representations (ICLR) (2017) 6
18. Dziugaite, G.K., Roy, D.M.: Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data. In: Proc. The Conference on Uncertainty in Artificial Intelligence (UAI) (2017) 2, 4
19. Feng, H.Z., You, Z., Chen, M., Zhang, T., Zhu, M., Wu, F., Wu, C., Chen, W.: Kd3a: Unsupervised multi-source decentralized domain adaptation via knowledge distillation. In: Proc. International Conference on Machine Learning (ICML) (2021) 4
20. Foret, P., Kleiner, A., Mobahi, H., Neyshabur, B.: Sharpness-aware minimization for efficiently improving generalization. In: Proc. International Conference on Learning Representations (ICLR) (2021) 2, 4
21. Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V.: Domain-adversarial training of neural networks. Journal of Machine Learning Research (JMLR) (2016) 11
22. Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.A., Brendel, W.: Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness. In: Proc. International Conference on Learning Representations (ICLR) (2019) 4
23. Ghiasi, G., Lin, T.Y., Le, Q.V.: Dropblock: A regularization method for convolutional networks. In: Proc. Neural Information Processing Systems (NeurIPS) (2018) 11
24. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: Proc. Neural Information Processing Systems (NeurIPS) (2014) 1
25. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples. In: Proc. International Conference on Learning Representations (ICLR) (2014) 13
26. Gulrajani, I., Lopez-Paz, D.: In search of lost domain generalization. In: Proc. International Conference on Learning Representations (ICLR) (2021) 3, 9
27. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (June 2016) 9, 11
28. Hendrycks, D., Dietterich, T.: Benchmarking neural network robustness to common corruptions and perturbations. In: Proc. International Conference on Learning Representations (ICLR) (2019) 14
29. Hendrycks, D., Mu, N., Cubuk, E.D., Zoph, B., Gilmer, J., Lakshminarayanan, B.: Augmix: A simple data processing method to improve robustness and uncertainty (2020) 14
30. Hendrycks, D., Mu, N., Cubuk, E.D., Zoph, B., Gilmer, J., Lakshminarayanan, B.: Augmix: A simple data processing method to improve robustness and uncertainty. In: Proc. International Conference on Learning Representations (ICLR) (2020) 14
31. Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015) 3, 4
32. Huang, X., Belongie, S.: Arbitrary style transfer in real-time with adaptive instance normalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2017) 6
33. Huang, Z., Wang, H., Xing, E.P., Huang, D.: Self-challenging improves cross-domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2020) 10, 11

--- TRANG 17 ---
Cross-Domain Ensemble Distillation for Domain Generalization 17

34. Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift. In: Proc. International Conference on Machine Learning (ICML) (2015) 3
35. Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., Wilson, A.G.: Averaging weights leads to wider optima and better generalization. In: Proc. The Conference on Uncertainty in Artificial Intelligence (UAI) (2018) 4
36. Jiang, Y., Neyshabur, B., Mobahi, H., Krishnan, D., Bengio, S.: Fantastic generalization measures and where to find them. In: Proc. International Conference on Learning Representations (ICLR) (2020) 2
37. Kang, J., Lee, S., Kim, N., Kwak, S.: Style neophile: Constantly seeking novel styles for domain generalization. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2022) 3, 4, 10, 11
38. Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P.: On large-batch training for deep learning: Generalization gap and sharp minima. In: Proc. International Conference on Learning Representations (ICLR) (2017) 2, 4
39. Kifer, D., Ben-David, S., Gehrke, J.: Detecting change in data streams. In: In Very Large Databases (VLDB) (2004) 8
40. Kim, D., Park, S., Kim, J., Lee, J.: Selfreg: Self-supervised contrastive regularization for domain generalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2021) 1, 10
41. Kim, N., Son, T., Lan, C., Zeng, W., Kwak, S.: Wedge: Web-image assisted domain generalization for semantic segmentation. arXiv preprint arXiv:2109.14196 (2021) 3
42. Kim, S., Kim, D., Cho, M., Kwak, S.: Embedding transfer with label relaxation for improved metric learning. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 3
43. Krizhevsky, A., Sutskever, I., Hinton, G.E.: ImageNet classification with deep convolutional neural networks. In: Proc. Neural Information Processing Systems (NeurIPS) (2012) 1
44. Krueger, D., Caballero, E., Jacobsen, J.H., Zhang, A., Binas, J., Zhang, D., Le Priol, R., Courville, A.: Out-of-distribution generalization via risk extrapolation (rex). In: Proc. International Conference on Machine Learning (ICML) (2021) 11
45. Li, D., Yang, Y., Song, Y.Z., Hospedales, T.M.: Deeper, broader and artier domain generalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2017) 9
46. Li, D., Yang, Y., Song, Y.Z., Hospedales, T.M.: Learning to generalize: Meta-learning for domain generalization. In: Proc. AAAI Conference on Artificial Intelligence (AAAI) (2018) 11
47. Li, D., Zhang, J., Yang, Y., Liu, C., Song, Y.Z., Hospedales, T.M.: Episodic training for domain generalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 3, 10
48. Li, H., Pan, S.J., Wang, S., Kot, A.C.: Domain generalization with adversarial feature learning. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2018) 1, 3, 10, 11
49. Li, Y., Tian, X., Gong, M., Liu, Y., Liu, T., Zhang, K., Tao, D.: Deep domain generalization via conditional invariant adversarial networks. In: Proc. European Conference on Computer Vision (ECCV) (2018) 1, 3, 11
50. Long, M., Cao, Y., Wang, J., Jordan, M.: Learning transferable features with deep adaptation networks. In: Proc. International Conference on Machine Learning (ICML) (2015) 9

--- TRANG 18 ---
18 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

51. Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards deep learning models resistant to adversarial attacks. In: Proc. International Conference on Learning Representations (ICLR) (2018) 13
52. Meng, Z., Li, J., Gong, Y., Juang, B.H.: Adversarial teacher-student learning for unsupervised domain adaptation. In: 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2018) 4
53. Miyato, T., Maeda, S.i., Koyama, M., Ishii, S.: Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) (2018) 5
54. Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M.: Playing atari with deep reinforcement learning. In: NeurIPS Deep Learning Workshop (2013) 1
55. Muandet, K., Balduzzi, D., Schölkopf, B.: Domain generalization via invariant feature representation. In: Proc. International Conference on Machine Learning (ICML) (2013) 1, 3
56. Nam, H., Lee, H., Park, J., Yoon, W., Yoo, D.: Reducing domain gap by reducing style bias. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 4, 9, 10, 11
57. Neuhold, G., Ollmann, T., Rota Bulo, S., Kontschieder, P.: The mapillary vistas dataset for semantic understanding of street scenes. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2017) 12
58. Pan, X., Zhan, X., Shi, J., Tang, X., Luo, P.: Switchable whitening for deep representation learning. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 12
59. Park, W., Kim, D., Lu, Y., Cho, M.: Relational knowledge distillation. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019) 3
60. Pereyra, G., Tucker, G., Chorowski, J., Kaiser, Ł., Hinton, G.: Regularizing neural networks by penalizing confident output distributions. In: ICLR Workshop (2017) 2, 4
61. Richter, S.R., Vineet, V., Roth, S., Koltun, V.: Playing for data: Ground truth from computer games. In: Proc. European Conference on Computer Vision (ECCV) (2016) 12
62. Ristani, E., Solera, F., Zou, R., Cucchiara, R., Tomasi, C.: Performance measures and a data set for multi-target, multi-camera tracking. In: Proc. European Conference on Computer Vision (ECCV) (2016) 11
63. Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.M.: The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016) 12
64. Sagawa, S., Koh, P.W., Hashimoto, T.B., Liang, P.: Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. In: Proc. International Conference on Learning Representations (ICLR) (2020) 11
65. Seo, S., Suh, Y., Kim, D., Kim, G., Han, J., Han, B.: Learning to optimize domain specific normalization for domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2020) 3, 10
66. Shankar, S., Piratla, V., Chakrabarti, S., Chaudhuri, S., Jyothi, P., Sarawagi, S.: Generalizing across domains via cross-gradient training. In: Proc. International Conference on Learning Representations (ICLR) (2018) 3, 10

--- TRANG 19 ---
Cross-Domain Ensemble Distillation for Domain Generalization 19

67. Stutz, D., Hein, M., Schiele, B.: Relating adversarially robust generalization to flat minima. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2021) 13
68. Sun, B., Saenko, K.: Deep coral: Correlation alignment for deep domain adaptation. In: Proc. European Conference on Computer Vision (ECCV) (2016) 11
69. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the inception architecture for computer vision. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016) 13
70. Ulyanov, D., Vedaldi, A., Lempitsky, V.: Instance normalization: The missing ingredient for fast stylization. arXiv preprint arXiv:1607.08022 (2016) 6
71. Vapnik, V.: Statistical learning theory. NY: Wiley (1998) 11
72. Venkateswara, H., Eusebio, J., Chakraborty, S., Panchanathan, S.: Deep hashing network for unsupervised domain adaptation. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017) 9
73. Verma, V., Lamb, A., Beckham, C., Najafi, A., Mitliagkas, I., Lopez-Paz, D., Bengio, Y.: Manifold mixup: Better representations by interpolating hidden states. In: Proc. International Conference on Machine Learning (ICML) (2019) 13
74. Wang, S., Yu, L., Li, C., Fu, C.W., Heng, P.A.: Learning from extrinsic and intrinsic supervisions for domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2020) 10
75. Wang, Z., Luo, Y., Qiu, R., Huang, Z., Baktashmotlagh, M.: Learning to diversify for single domain generalization. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2021) 10
76. Wu, D., Xia, S.T., Wang, Y.: Adversarial weight perturbation helps robust generalization. In: Proc. Neural Information Processing Systems (NeurIPS) (2020) 13
77. Xu, Q., Zhang, R., Zhang, Y., Wang, Y., Tian, Q.: A fourier-based framework for domain generalization. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 3, 10
78. Xu, T.B., Liu, C.L.: Data-distortion guided self-distillation for deep neural networks. In: Proc. AAAI Conference on Artificial Intelligence (AAAI) (2019) 4
79. Xu, Z., Li, W., Niu, L., Xu, D.: Exploiting low-rank structure from latent domains for domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2014) 3
80. Yao, Z., Gholami, A., Keutzer, K., Mahoney, M.W.: Pyhessian: Neural networks through the lens of the hessian. In: 2020 IEEE International Conference on Big Data (Big Data) (2020) 13
81. Yu, F., Xian, W., Chen, Y., Liu, F., Liao, M., Madhavan, V., Darrell, T.: Bdd100k: A diverse driving video database with scalable annotation tooling. arXiv preprint arXiv:1805.04687 (2018) 12
82. Yue, X., Zhang, Y., Zhao, S., Sangiovanni-Vincentelli, A., Keutzer, K., Gong, B.: Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 12
83. Yun, S., Han, D., Oh, S.J., Chun, S., Choe, J., Yoo, Y.: Cutmix: Regularization strategy to train strong classifiers with localizable features. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 14
84. Yun, S., Park, J., Lee, K., Shin, J.: Regularizing class-wise predictions via self-knowledge distillation. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2020) 4, 5
85. Zagoruyko, S., Komodakis, N.: Wide residual networks. In: Proc. British Machine Vision Conference (BMVC) (2016) 14

--- TRANG 20 ---
20 Kyungmoon Lee, Sungyeon Kim, Suha Kwak

86. Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical risk minimization. In: Proc. International Conference on Learning Representations (ICLR) (2018) 11, 13, 14
87. Zhang, L., Song, J., Gao, A., Chen, J., Bao, C., Ma, K.: Be your own teacher: Improve the performance of convolutional neural networks via self distillation. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2019) 2, 4, 7, 8
88. Zhang, M.M., Marklund, H., Dhawan, N., Gupta, A., Levine, S., Finn, C.: Adaptive risk minimization: A meta-learning approach for tackling group shift. In: Proc. Neural Information Processing Systems (NeurIPS) (2021) 11
89. Zhang, Y., Xiang, T., Hospedales, T.M., Lu, H.: Deep mutual learning. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2018) 2, 4, 7, 8
90. Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., Tian, Q.: Scalable person re-identification: A benchmark. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2015) 3, 11
91. Zheng, Z., Zheng, L., Yang, Y.: Unlabeled samples generated by gan improve the person re-identification baseline in vitro. In: Proc. IEEE International Conference on Computer Vision (ICCV) (2017) 3, 11
92. Zhong, Z., Zheng, L., Kang, G., Li, S., Yang, Y.: Random erasing data augmentation. In: Proc. AAAI Conference on Artificial Intelligence (AAAI) (2020) 11
93. Zhou, K., Yang, Y., Hospedales, T., Xiang, T.: Learning to generate novel domains for domain generalization. In: Proc. European Conference on Computer Vision (ECCV) (2020) 3, 10
94. Zhou, K., Yang, Y., Qiao, Y., Xiang, T.: Domain adaptive ensemble learning. IEEE Transactions on Image Processing (TIP) (2021) 3
95. Zhou, K., Yang, Y., Qiao, Y., Xiang, T.: Domain generalization with mixstyle. In: Proc. International Conference on Learning Representations (ICLR) (2021) 4, 7, 10, 11, 13

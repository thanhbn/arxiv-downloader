# 2210.02871.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-distillation/2210.02871.pdf
# Kích thước tệp: 865030 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
TỰ CHƯNG CẤT CHO
TIỀN HUẤN LUYỆN THÊM CỦA TRANSFORMERS
Seanie Lee1†Minki Kang1,2Juho Lee1,2Sung Ju Hwang1Kenji Kawaguchi3∗
KAIST1, AITRICS2, National University of Singapore3
{lsnfamily02, zzxc1133, juholee, sjhwang82 }@kaist.ac.kr
kenji@comp.nus.edu.sg
TÓM TẮT
Việc áp dụng tiền huấn luyện các mô hình transformer lớn trên lượng lớn dữ liệu
không nhãn và tinh chỉnh chúng trên các tập dữ liệu có nhãn cho các tác vụ downstream
đa dạng đã chứng minh sự thành công đáng kể trong các tác vụ xử lý thị giác và ngôn
ngữ tự nhiên khác nhau. Tuy nhiên, phương pháp tinh chỉnh trực tiếp có thể dẫn đến
hiệu suất không tối ưu nếu tồn tại sự khác biệt đáng kể giữa miền tiền huấn luyện
và miền tinh chỉnh. Để giải quyết vấn đề này, một số nghiên cứu trước đây đã đề
xuất các chiến lược tiền huấn luyện thêm để tiếp tục tiền huấn luyện mô hình trên
tập dữ liệu không nhãn mục tiêu trước khi tinh chỉnh. Tuy nhiên, các chiến lược này
bị giới hạn ở các mô hình ngôn ngữ và có thể dẫn đến overfitting khi áp dụng cho
Vision Transformers. Để vượt qua hạn chế này, chúng tôi trình bày một phương pháp
mới về tự chưng cất như một phương pháp điều hòa cho giai đoạn tiền huấn luyện
thêm. Phương pháp của chúng tôi đầu tiên tiền huấn luyện thêm mô hình tiền huấn
luyện ban đầu trên dữ liệu không nhãn mục tiêu, và sau đó sử dụng nó như một giáo
viên cho tự chưng cất. Sau đó chúng tôi lấy cùng mô hình tiền huấn luyện ban đầu
làm học sinh, và buộc các biểu diễn ẩn của nó phải gần với những biểu diễn của giáo
viên trong khi tối ưu hóa học sinh với mục tiêu mã hóa tự động có mặt nạ. Các thí
nghiệm của chúng tôi chứng minh sự vượt trội của tự chưng cất so với các baseline
liên quan trên các tập dữ liệu benchmark khác nhau cho các tác vụ phân loại hình
ảnh và văn bản. Hơn nữa, chúng tôi cung cấp một phân tích lý thuyết về phương
pháp đề xuất sử dụng một mô hình đơn giản hóa để làm sáng tỏ cách tự chưng cất
cho tiền huấn luyện thêm có thể nâng cao hiệu suất của các tác vụ downstream.

1 GIỚI THIỆU
Các mô hình transformer tiền huấn luyện (Devlin et al., 2019; Brown et al., 2020; Liu et al., 2019; He et al.,
2022) đã hiệu quả trên các tác vụ xử lý thị giác và ngôn ngữ tự nhiên khác nhau. Các mô hình tiền
huấn luyện học biểu diễn tổng quát từ một khối lượng lớn dữ liệu không nhãn để chúng tổng quát
hóa tốt cho các tác vụ downstream khác nhau khi chúng được tinh chỉnh trên mỗi tác vụ với một tập
dữ liệu có nhãn.
Tuy nhiên, trong nhiều ứng dụng thế giới thực, nó đòi hỏi một lượng nỗ lực đáng kể để thích ứng
mô hình tiền huấn luyện với một miền tác vụ downstream cụ thể vì tồn tại sự khác biệt phân phối
đáng kể giữa dữ liệu cho giai đoạn tiền huấn luyện và tinh chỉnh. Hơn nữa, việc thu thập một lượng
lớn dữ liệu có nhãn cho các miền cụ thể như vậy là khó khăn, điều này làm cho việc thích ứng mô
hình tiền huấn luyện với các tác vụ downstream trở nên thách thức hơn.

0 10k 20K 30K 40K 50K 60K
Các Bước Tiền Huấn Luyện Thêm5052545658Độ Chính Xác Kiểm Tra
Phân Loại Hình Ảnh trên CUB
Tự Chưng Cất
Tiền Huấn Luyện Thêm
Hình 1: Độ chính xác với việc thay đổi
số bước tiền huấn luyện thêm.Một số công trình đã đề xuất để giải quyết vấn đề thích ứng
các mô hình tiền huấn luyện với một miền cụ thể. Một phương
pháp phổ biến để thích ứng mô hình tiền huấn luyện là tiền huấn
luyện thêm, nơi chúng ta tiếp tục cập nhật các tham số của mô
hình tiền huấn luyện trên dữ liệu không nhãn đặc thù miền được
sưu tầm thêm với tự giám sát (Beltagy et al., 2019; Lee et al., 2020),
trước khi tinh chỉnh nó trên dữ liệu có nhãn mục tiêu như được
miêu tả trong Hình 2b. Gururangan et al. (2020) cũng cho thấy
rằng tiền huấn luyện thêm chỉ với dữ liệu không nhãn mục tiêu
vẫn hiệu quả mà không cần dữ liệu bổ sung nào. Tuy nhiên, hầu hết các phương pháp tiền huấn
luyện thêm hiện có đã tập trung vào các mô hình ngôn ngữ, và chúng tôi thấy rằng tiền huấn luyện thêm

∗Tác giả liên hệ†Công việc được thực hiện khi tác giả là thực tập sinh tại NUS.
1arXiv:2210.02871v3  [cs.CV]  9 Jun 2023

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Transformer𝑓!!"!#Bộ phân loạiℎ"(a) Tinh chỉnh
𝑦=0
Tập dữ liệu có nhãn𝑦=1

(c) Tự chưng cất trong Tiền huấn luyện thêm
Transformer𝑓!∗Bộ phân loạiℎ"∗(b) Tiền huấn luyện thêm
Tập dữ liệu
không nhãn

Transformer𝑓!%Bộ phân loạiℎ"

Transformer𝑓!∗Bộ phân loạiℎ"∗

Tập dữ liệu không nhãn

Tập dữ liệu không nhãn

Transformer𝑓!&Bộ phân loạiℎ"𝓛𝑪𝑬𝓛𝑴𝑨𝑬

𝓛𝑴𝑨𝑬+ 𝓛𝑫𝒊𝒔𝒕𝒊𝒍𝒍

𝑦=0
Tập dữ liệu có nhãn𝑦=1

Transformer𝑓!∗Bộ phân loạiℎ"∗𝓛𝑪𝑬

𝑦=0
𝑦=1𝓛𝑪𝑬Tập dữ liệu có nhãn

Transformer𝑓!!"!#Bộ giải mã𝑔#!"!#𝓛𝑴𝑨𝑬Giáo viênHọc sinh

Transformer𝑓!!"!#Bộ giải mã𝑔#!"!#

Transformer𝑓!%Bộ giải mã𝑔#%

Hình 2: Khái niệm. So sánh giữa các phương pháp thích ứng transformers tiền huấn luyện với miền mục tiêu. (a)
Tinh chỉnh mà không có tiền huấn luyện thêm nào. (b) Tiền huấn luyện thêm và tinh chỉnh. (c) Tự chưng cất
trong tiền huấn luyện thêm và tinh chỉnh.

chiến lược không hiệu quả đối với Vision Transformer (ViT) (Dosovitskiy et al., 2021). Như được
hiển thị trong Hình 1, ViT dễ bị overfitting và không tổng quát hóa tốt cho các tác vụ downstream
như khi chúng ta tiếp tục tiền huấn luyện nó trên dữ liệu không nhãn mục tiêu.

Một số phương pháp điều hòa (Chen et al., 2020a; Gouk et al., 2021; Aghajanyan et al., 2021) đã
đề xuất để giải quyết vấn đề overfitting của các mô hình tiền huấn luyện lớn, tuy nhiên, chúng không
xem xét quá trình thích ứng như tiền huấn luyện thêm. Thay vào đó, chúng buộc khoảng cách giữa
trọng số tinh chỉnh cuối cùng và trọng số tiền huấn luyện phải nhỏ để thúc đẩy việc chuyển giao
kiến thức được thu thập từ tiền huấn luyện sang các tác vụ downstream để tổng quát hóa tốt hơn.
Tuy nhiên, những điều hòa này cản trở việc thích ứng các mô hình tiền huấn luyện với các tác vụ
downstream đặc biệt khi có sự dịch chuyển phân phối đáng kể giữa dữ liệu tiền huấn luyện và dữ
liệu mục tiêu. Cuối cùng nó dẫn đến việc tổng quát hóa tệ hơn so với chiến lược tinh chỉnh đơn giản.

Để giải quyết những hạn chế này, chúng tôi đề xuất tự chưng cất như một điều hòa cho tiền huấn
luyện thêm trên tập dữ liệu không nhãn mục tiêu để chúng ta có thể thích ứng hiệu quả các mô hình
tiền huấn luyện với tác vụ downstream của các miền khác nhau với một lượng hạn chế dữ liệu có
nhãn. Đối với tự giám sát, chúng tôi tập trung vào mã hóa tự động có mặt nạ cho tiền huấn luyện
vì nó không phụ thuộc vào bất kỳ tăng cường dữ liệu nào, so với các phương pháp học tự giám sát
khác (Chen et al., 2020b; He et al., 2020; Grill et al., 2020; Zbontar et al., 2021; Chen & He, 2021; Caron et al., 2021) yêu cầu tăng cường dữ liệu để xây dựng các cặp dương cho mục tiêu học tự giám sát như học tương phản. Điều này đặc biệt hữu ích khi khó định nghĩa các tăng cường dữ liệu có ý nghĩa cho một miền mục tiêu.

Cụ thể, chúng tôi lấy mô hình tiền huấn luyện với một bộ mã hóa fθinit và một bộ giải mã gϕinit được
tiền huấn luyện trên một lượng lớn dữ liệu không nhãn từ miền tổng quát, và tiếp tục tiền huấn luyện
nó với mục tiêu mã hóa tự động có mặt nạ (MAE) (Devlin et al., 2019; He et al., 2022) trên dữ liệu
không nhãn mục tiêu để thu được fθ0 và gϕ0. Sau đó, chúng tôi đặt bộ mã hóa fθ0 như một giáo viên
cho tự chưng cất. Sau đó chúng tôi lấy bản sao của mô hình tiền huấn luyện (fθinit, gϕinit) làm học
sinh, và khớp các biểu diễn của bộ mã hóa học sinh và những biểu diễn của bộ mã hóa giáo viên
trong khi tối ưu hóa học sinh với MAE trên dữ liệu không nhãn mục tiêu. Cuối cùng, chúng tôi tinh
chỉnh học sinh tự chưng cất fθ1 trên dữ liệu có nhãn mục tiêu cho tác vụ downstream. Chúng tôi
minh họa tổng quan phương pháp của chúng tôi trong Hình 2c.

Để xác minh hiệu quả của phương pháp chúng tôi, chúng tôi thực nghiệm cho thấy rằng nó cải thiện
đáng kể hiệu suất tổng quát hóa của ViT tiền huấn luyện và mô hình ngôn ngữ RoBERTA (Liu et al., 2019), và vượt trội hơn các baseline liên quan trên các tập dữ liệu phân loại hình ảnh và văn bản
khác nhau. Hơn nữa, chúng tôi phân tích lý thuyết phương pháp đề xuất với một mô hình đơn giản
hóa để hiểu cách tự chưng cất cho tiền huấn luyện thêm có thể tiềm năng giúp cải thiện hiệu suất
tổng quát hóa trên các tác vụ mục tiêu sau khi tinh chỉnh.

Đóng góp của chúng tôi gồm ba phần:
• Chúng tôi đề xuất tự chưng cất cho tiền huấn luyện thêm trên tập dữ liệu không nhãn mục
tiêu, nơi chúng ta buộc các biểu diễn của học sinh phải gần với những biểu diễn của giáo
viên tiền huấn luyện thêm trong khi huấn luyện học sinh với mục tiêu mã hóa tự động có mặt nạ.
• Chúng tôi phân tích lý thuyết phương pháp đề xuất với một mô hình đơn giản hóa để hiểu
cách tự chưng cất cho tiền huấn luyện thêm có thể tiềm năng dẫn đến hiệu suất tổng quát
hóa tốt hơn của các tác vụ downstream.

2

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

• Chúng tôi xác thực rộng rãi phương pháp của chúng tôi trên các tập dữ liệu phân loại hình
ảnh và văn bản khác nhau với các transformers tiền huấn luyện và cho thấy rằng phương
pháp của chúng tôi vượt trội hơn các baseline liên quan.

2 CÔNG TRÌNH LIÊN QUAN

Tự Chưng Cất Chưng cất kiến thức là chuyển giao kiến thức từ giáo viên sang học sinh bằng cách
tối thiểu hóa một sự khác biệt giữa đầu ra của giáo viên và học sinh (Hinton et al., 2014). Khi việc
tham số hóa của học sinh và giáo viên là giống hệt nhau, chúng ta gọi đó là tự chưng cất như một
trường hợp đặc biệt của chưng cất kiến thức. Mặc dù không có thông tin mới trong quá trình tự
chưng cất, Furlanello et al. (2018) đã cho thấy rằng học sinh từ tự chưng cất đạt được hiệu suất tổng
quát hóa tốt hơn so với giáo viên. Một hiện tượng tương tự đã được quan sát thấy một cách nhất quán
trong các công trình khác (Yang et al., 2019; Ahn et al., 2019). Một số công trình đề xuất tự chưng
cất mà không có mạng giáo viên tiền huấn luyện (Sun et al., 2019; Zhang et al., 2019; 2022). Họ
thêm các bộ phân loại phụ trợ vào các lớp trung gian và huấn luyện các bộ phân loại để tối thiểu
hóa sự khác biệt giữa đầu ra của bộ phân loại ở lớp cuối cùng và đầu ra của các bộ phân loại phụ
trợ. Mobahi et al. (2020) phân tích lý thuyết cách tự chưng cất gây ra điều hòa và giảm overfitting
trong không gian Hilbert. Tuy nhiên, tất cả họ đều tập trung vào tự chưng cất cho học có giám sát.
Thay vào đó, chúng tôi chứng minh thực nghiệm và lý thuyết rằng tự chưng cất cho tiền huấn luyện
thêm với tự giám sát dẫn đến tổng quát hóa tốt hơn của các tác vụ downstream sau khi tinh chỉnh
mô hình tự chưng cất với dữ liệu có nhãn mục tiêu.

Tiền Huấn Luyện Thêm Lee et al. (2020); Beltagy et al. (2019); Sun et al. (2020) đã cho thấy sự
thành công của việc tiến hành tiền huấn luyện mô hình ngôn ngữ trên một số lượng lớn kho ngữ liệu
được thu thập từ miền mục tiêu và tinh chỉnh mô hình trên tập dữ liệu có nhãn mục tiêu. Tuy nhiên,
việc tiền huấn luyện thêm mô hình trên một lượng lớn dữ liệu văn bản không nhãn tốn nhiều tính
toán và có thể không khả thi để thu thập quy mô lớn như vậy của dữ liệu không nhãn trên các miền
nhất định. Thay vào đó, Gururangan et al. (2020) đưa ra một tiền huấn luyện thích ứng tác vụ nơi
chúng ta chỉ sử dụng dữ liệu không nhãn mục tiêu cho việc tiền huấn luyện thêm mô hình ngôn ngữ
trước khi tinh chỉnh mô hình trên dữ liệu có nhãn mục tiêu. Để cải thiện hiệu quả của tiền huấn
luyện thêm, Kang et al. (2020); Ye et al. (2021) đề xuất học để tạo mặt nạ đầu vào cho mã hóa tự
động có mặt nạ với tối ưu hóa hai cấp, điều này đòi hỏi chi phí tính toán quá cao. Tuy nhiên, tất cả
họ chỉ tập trung duy nhất vào các mô hình ngôn ngữ tiền huấn luyện và chúng tôi thấy thực nghiệm
rằng tiền huấn luyện thêm đơn thuần không hiệu quả đối với Vision Transformers.

Điều Hòa cho Tinh Chỉnh Có một số công trình đề xuất điều hòa cho việc tinh chỉnh một mô hình
tiền huấn luyện. Chen et al. (2020a) đề xuất sửa đổi bộ tối ưu Adam (Kingma & Ba, 2015), được
gọi là RecAdam, buộc mô hình tinh chỉnh gần với mô hình tiền huấn luyện ban đầu bằng cách tối
thiểu hóa khoảng cách L2 giữa trọng số tinh chỉnh và trọng số tiền huấn luyện ban đầu. Tương tự,
Gouk et al. (2021) chiếu trọng số tinh chỉnh cho mỗi lần cập nhật gradient descent sao cho nó nằm
trong hình cầu có tâm tại trọng số tiền huấn luyện ban đầu với khoảng cách được tạo ra bởi chuẩn
của tổng tuyệt đối hàng tối đa (MARS). Thay vì tối thiểu hóa khoảng cách một cách rõ ràng, được
thúc đẩy bởi lý thuyết trust region, Aghajanyan et al. (2021) đề xuất tối thiểu hóa phân kỳ KL đối
xứng giữa đầu ra mô hình của một đầu vào gốc và đầu ra của đầu vào bị nhiễu bởi tiếng ồn Gaussian.
Tuy nhiên, tất cả họ không xem xét thích ứng các mô hình tiền huấn luyện với một miền mục tiêu
cụ thể, điều này dẫn đến hiệu suất tổng quát hóa tệ hơn của các tác vụ downstream so với chiến
lược tinh chỉnh đơn giản.

3 PHƯƠNG PHÁP

3.1 CÁC KIẾN THỨC CƠ BẢN

Phát Biểu Vấn Đề Chúng ta giả định rằng chúng ta được cho (θinit, ϕinit) là các tham số của mạng
neural gϕinit◦fθinit được tiền huấn luyện trên một khối lượng lớn dữ liệu không nhãn với mục tiêu
mã hóa tự động có mặt nạ, nơi fθinit là một bộ mã hóa trích xuất biểu diễn ẩn của một đầu vào và
gϕinit là một bộ giải mã tái tạo một đầu vào có mặt nạ. Mục tiêu của chúng ta là tinh chỉnh mô hình
tiền huấn luyện fθinit với một đầu ra đặc thù tác vụ được khởi tạo ngẫu nhiên hω trên tập dữ liệu có
nhãn Dtr={(x(i), y(i))}n i=1 của một tác vụ phân loại downstream sao cho mô hình tổng quát hóa tốt
cho tập dữ liệu kiểm tra chưa thấy Dtest. Một phương pháp điển hình để đạt được mục tiêu này là
tối thiểu hóa rủi ro thực nghiệm như sau:

minimize
θ,ωLCE(θ, ω;Dtr)via algorithm Aas
(θ∗, ω∗) =A(LCE;θinit,Dtr),(1)

3

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Thuật toán 1 Tự Chưng Cất
Yêu cầu: Tập dữ liệu không nhãn Du, khởi tạo θinit, ϕinit,
tỷ lệ học α∈R≥0, vòng tự chưng cất T′∈
N+, xác suất tạo mặt nạ γ∈(0,1) và kích thước batch B.
1:θ0←Further Pretrain (Du, θinit, ϕinit, α, γ, B )
2:for all t←1, . . . , T′do
3: Khởi tạo θt←θinit và ϕt←ϕinit
4: while not converge do
5: Lấy mẫu một mini-batch {x(j)}B j=1 từ Du
6: for all j←1, . . . , B do
7: Lấy mẫu một mặt nạ z(j)∼pγ,K(z)
8: Z(j)←PK k=1z(j) k
9: Lấy một đầu vào có mặt nạ ˆx(j) với z(j)
10: ℓ1 j← −PK k=1z(j) k Z(j)logpθt,ϕt(x(j) k|ˆx(j))
11: ℓ2 j← ||fθt(x(j))−StopGrad (fθ0(x(j)))|| 2 2
12: end for
13: L1←1 B PB j=1ℓ1 j,L2←1 B PB j=1ℓ2 j
14: θt←θt−α∂(L1+L2) ∂θ|θ=θt
15: ϕt←ϕt−α∂L1 ∂ϕ|ϕ=ϕt
16: end while17: θ0←θt
18:end for19:return θT′

Thuật toán 2 Tiền Huấn Luyện Thêm
Yêu cầu: Tập dữ liệu không nhãn Du, khởi tạo
θinit, ϕinit, tỷ lệ học α∈R≥0, xác suất
tạo mặt nạ γ∈(0,1), và kích thước batch B.
1: Khởi tạo θ0←θinit và ϕ0←ϕinit
2:while not converge do
3: Lấy mẫu một mini-batch {x(j)}B j=1 từ Du
4: for all j←1, . . . , B do
5: Lấy mẫu một mặt nạ z(j)∼pγ,T(z)
6: Z(j)←PK k=1z(j) k
7: Lấy một đầu vào có mặt nạ ˆx(j) với z(j)
8: pk←pθ0,ϕ0(x(j) k|ˆx(j))
9: ℓ1 j← −PK k=1z(j) k Z(j)logpk
10: end for
11: L ←1 B PB j=1ℓ1 j
12: θ0←θ0−α∂L ∂θ|θ=θ0
13: ϕ0←ϕ0−α∂L ∂ϕ|ϕ=ϕ0
14:end while
15:return θ0
16:
17:

nơi LCE là một hàm mất mát cross-entropy và A biểu thị một thuật toán gradient descent ngẫu nhiên để tối thiểu hóa LCE trên tập dữ liệu Dtr với khởi tạo θinit.

Tiền Huấn Luyện Thêm Tuy nhiên, mô hình tiền huấn luyện dễ bị overfitting khi nó được tinh chỉnh trên một lượng nhỏ dữ liệu có nhãn đặc thù miền. Gururangan et al. (2020) đã cho thấy rằng tiền huấn luyện thêm, nơi chúng ta tiếp tục tiền huấn luyện mô hình gϕinit◦fθinit trên tập dữ liệu không nhãn mục tiêu Du={x(i)}n i=1 và sau đó tinh chỉnh nó trên Dtr, là hiệu quả để cải thiện hiệu suất tổng quát hóa khi không có đủ dữ liệu có nhãn đặc thù miền. Lưu ý rằng Du giống hệt như Dtr ngoại trừ việc chúng ta loại bỏ các nhãn y(i). Trong công trình này, chúng tôi tập trung vào mã hóa tự động có mặt nạ (Devlin et al., 2019; He et al., 2022) như một hàm mục tiêu tiền huấn luyện vì tính tổng quát của nó so với các phương pháp tự giám sát khác (Chen et al., 2020b; He et al., 2020; Grill et al., 2020; He et al., 2020; Chen & He, 2021; Caron et al., 2021) yêu cầu tăng cường dữ liệu được định nghĩa rõ để xây dựng các cặp dương cho học tự giám sát.

Mã Hóa Tự Động Có Mặt Nạ Chúng tôi mô tả ngắn gọn mục tiêu mã hóa tự động có mặt nạ (Liu et al., 2019; He et al., 2022) cho một mô hình ngôn ngữ như RoBERTA (Liu et al., 2019) và Vision Transformer (ViT) (Dosovitskiy et al., 2021). Cho x(i)= (x(i) 1, . . . , x(i) K) là một chuỗi các patch cho một hình ảnh hoặc token cho một câu với độ dài K. Sau đó chúng ta lấy mẫu độc lập một mặt nạ nhị phân từ phân phối Bernoulli với xác suất γ cho mỗi x(i) k, được ký hiệu là z(i)= (z(i) 1, . . . , z(i) K). Nếu z(i) k= 1, thì x(i) k được thay thế bằng một token "mask" đặc biệt. Ngược lại, chúng ta sử dụng cùng x(i) k cho một đầu vào có mặt nạ. Cho ˆx(i)= (ˆx(i) 1, . . . , ˆx(i) K) là một đầu vào có mặt nạ và cho fθ, gϕ lần lượt là một bộ mã hóa và bộ giải mã. Sau đó mục tiêu cuối cùng cho mã hóa tự động có mặt nạ được định nghĩa như sau:

LMAE(θ, ϕ;Du) =1 n nX i=1Ez(i)∼pγ,T(z)" −KX k=1z(i) k Z(i)·logpθ,ϕ(x(i) k|ˆx(i))# , Z(i)=KX k=1z(i) k,(2)

nơi pγ,K(z) biểu thị một phân phối Binomial với các tham số γ cho xác suất zk= 1 và K cho số lần thử. Lưu ý rằng negative log-likelihood được thể hiện như cross-entropy loss cho các mô hình ngôn ngữ hoặc mean square error cho Vision Transformers. Xem Phụ lục C để biết thêm chi tiết.

3.2 TỰ CHƯNG CẤT CHO TIỀN HUẤN LUYỆN THÊM

Mặc dù chiến lược tiền huấn luyện thêm đã hiệu quả trên miền văn bản (Gururangan et al., 2020; Lee et al., 2020; Sun et al., 2020), chúng tôi thấy thực nghiệm rằng ViT với tiền huấn luyện thêm overfit dữ liệu không nhãn mục tiêu và không tổng quát hóa tốt cho các tác vụ phân loại hình ảnh downstream.

4

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Để giải quyết vấn đề này, chúng tôi đề xuất tự chưng cất như một điều hòa cho tiền huấn luyện thêm. Cụ thể, cho một mô hình tiền huấn luyện gϕinit◦fθinit, chúng tôi đầu tiên tiếp tục huấn luyện mô hình trên dữ liệu không nhãn mục tiêu Du với mục tiêu mã hóa tự động có mặt nạ như được mô tả trong phương trình 2 để thu được bộ mã hóa fθ0 và bộ giải mã gϕ0. Chúng tôi loại bỏ bộ giải mã và coi bộ mã hóa fθ0 như một giáo viên cho tự chưng cất. Sau đó chúng tôi lấy bản sao của mạng tiền huấn luyện ban đầu gϕinit◦fθinit làm học sinh và tiền huấn luyện thêm học sinh với mục tiêu mã hóa tự động có mặt nạ nhưng buộc biểu diễn ẩn của bộ mã hóa của học sinh fθinit phải gần với biểu diễn của giáo viên fθ0 như sau:

(θ1, ϕ1)∈arg min θ,ϕ(LMAE(θ, ϕ;Du) +LDistill (θ;θ0,Du))
LDistill (θ;θ0,Du) =1 n nX i=1 ||fθ(x(i))−StopGrad fθ0(x(i))|| 2 2(3)

nơi θ và ϕ được khởi tạo với các tham số tiền huấn luyện θinit và ϕinit, tương ứng và StopGrad biểu thị phép toán stop-gradient không lan truyền ngược qua đầu vào. Như được mô tả trong Thuật toán 1, chúng ta có thể lặp lại quá trình này để thực hiện nhiều vòng tự chưng cất (T′>1) nơi học sinh của vòng trước trở thành giáo viên và một học sinh mới được khởi tạo với các trọng số tiền huấn luyện θinit và ϕinit cho vòng tiếp theo. Chúng tôi thấy thực nghiệm rằng vòng đầu tiên của tự chưng cất đóng vai trò quan trọng nhất trong việc cải thiện hiệu suất tổng quát hóa cuối cùng của các tác vụ downstream. Hơn nữa, phân tích lý thuyết cho thấy rằng vòng đầu tiên của tự chưng cất có tác động lớn nhất đến điều hòa. Do đó, chúng tôi thực hiện một vòng tự chưng cất duy nhất để có hiệu quả tính toán. Sau tự chưng cất, chúng tôi loại bỏ bộ giải mã gϕ1 và tinh chỉnh bộ mã hóa của học sinh fθ1 cùng với một đầu ra đặc thù tác vụ được khởi tạo ngẫu nhiên hω bằng cách tối thiểu hóa LCE(θ, ω,;Dtr) với khởi tạo θ1 như được mô tả trong phương trình 1.

4 PHÂN TÍCH LÝ THUYẾT

Trong phần này, chúng tôi phân tích cách tự chưng cất ảnh hưởng đến mô hình cuối cùng sau khi tinh chỉnh về mặt tổng quát hóa và điều hòa. Phần này chứng minh một giới hạn tổng quát hóa trên hàm mất mát có giám sát cho phương pháp của chúng tôi và cho thấy rằng giới hạn tổng quát hóa giảm một cách nghiêm ngặt khi số lượng tự chưng cất tăng lên. Hơn nữa, chúng tôi cho thấy rằng tự chưng cất hoạt động như một điều hòa trên khoảng cách giữa trọng số ban đầu trước tiền huấn luyện thêm và trọng số cuối cùng sau tinh chỉnh. Hiệu ứng điều hòa được cho thấy có tác động lớn nhất trong vòng đầu tiên của tự chưng cất, điều này gợi ý rằng vòng đầu tiên của tự chưng cất đóng vai trò quan trọng hơn trong hiệu suất cuối cùng khi so sánh với các vòng khác.

Chúng tôi xem xét động học của vector trọng số wt,τ theo thời gian τ của tinh chỉnh sau t vòng tự chưng cất, nơi w0,0 là kết quả của tiền huấn luyện thêm, và wt,0∈minimize w Lt(w) là kết quả của tự chưng cất của t vòng với Lt(w) =1 n Pn i=1∥f(xi, w)−f(xi, wt−1,0)∥2 2+λ∥w∥2 2 cho một số λ >0. Sau t vòng tự chưng cất, chúng tôi xem xét động học theo thời gian tinh chỉnh τ thông qua gradient flow (Saxe et al., 2014; Kawaguchi, 2021):dwt,τ dτ=−∇L (wt,τ),với khởi tạo wt,0 thu được bởi tự chưng cất nơi L(w) =1 2Pn i=1ℓ(w, xi, yi) với ℓ(w, x, y ) =∥f(x, w)− y∥2 2 và y∈Rp. Ở đây, tự chưng cất và tinh chỉnh chia sẻ cùng một tập dữ liệu huấn luyện s= {(xi, yi)}n i=1. Trong phần này, để thu được những hiểu biết lý thuyết, chúng tôi xem xét chế độ của d > n và một mô hình trừu tượng đơn giản, f(x, w) =Wφ(x)∈Rp, với một số ánh xạ phi tuyến φ và ma trận trọng số W∈Rp×d nơi w= vec[ W⊤]∈Rdp và φ(x)∈Rd. Ở đây, vec[W⊤] là vectorization của ma trận W⊤. Hãy cố định độ dài thời gian tinh chỉnh T như 1< τ≤T <∞. Vì d > n , có vô số nghiệm cho bài toán tối thiểu hóa L(w). Do đó, mỗi độ dài hữu hạn T và việc over-parameterization d > n ngụ ý rằng khởi tạo wt,0 tại giai đoạn tinh chỉnh thông qua tự chưng cất đóng một vai trò quan trọng.

Cho δ >0 và t∈N0. Chúng ta sau đó định nghĩa Ft={At(s) :s∈ S} ,nơi S là một tập hợp của tất cả các tập dữ liệu huấn luyện có kích thước n sao cho với xác suất ít nhất 1−δ, tập dữ liệu huấn luyện s nằm trong S. Đối với mỗi tập dữ liệu huấn luyện s∈ S,At(s) =wt,T là vector trọng số cuối cùng của mô hình sau t vòng tự chưng cất và T thời gian tinh chỉnh. Hãy định nghĩa ma trận Φ∈Rd×n bởi Φij=φ(xj)i. Chúng ta giả định rằng Φ có hạng đầy đủ; tức là, rank(Φ) = n vì d≥n. Điều này thường được thỏa mãn bởi vì nếu rank(Φ) < n, có một số dư thừa trong các hàng của ma trận Φ. Ký hiệu bởi [Ip⊗Φ]∈Rdp×np tích Kronecker của ma trận đơn vị Ip∈Rp×p và ma trận Φ. Chúng ta viết phân tách giá trị đơn của nó bởi [Ip⊗Φ] = UΣV⊤ nơi U= [u1, u2. . . , u dp]∈Rdp×dp chứa các vector đơn vị trái ui∈Rdp cho i∈ {1, . . . , dp } và Σ∈Rdp×np là một ma trận đường chéo hình chữ nhật với Σii=σi∈R≥0 cho i∈ {1, . . . , np } và σ1≥σ2≥ ··· ≥ σnp≥0. Định nghĩa M là một cận trên trên hàm mất mát như ℓ(w, x, y )≤M. Định nghĩa R là một cận trên trên kỳ vọng của chuẩn của các đặc trưng như Ex∥φ(x)∥2≤R. Chúng ta giả định rằng w0,0̸= 0; nếu w0,0= 0, thì hàm mục tiêu trong giai đoạn tự chưng cất luôn bằng không như f(xi, w0,0) = 0 cho tất cả i, điều này không có khả năng xảy ra trong thực tế. Chúng ta định nghĩa winit∈Rdp là trọng số trước tiền huấn luyện thêm và định nghĩa Y= vec[[ y1, . . . , y n]⊤]∈Rnp.

Định lý sau cho thấy rằng giới hạn tổng quát hóa trên hàm mất mát có giám sát ℓ(wt,T, x, y) của giai đoạn tinh chỉnh giảm một cách nghiêm ngặt khi chúng ta tăng số lượng t của các vòng tự chưng cất trong giai đoạn tiền huấn luyện thêm:

Định lý 1. Tồn tại một hằng số c(chỉ phụ thuộc vào M) sao cho với xác suất ít nhất 1−δ, điều sau đây xảy ra:

Ex,y[ℓ(wt,T, x, y)]≤1 n nX i=1ℓ(wt,T, xi, yi) +ζ(t)r 4c2R2p n+Mr ln(2/δ) 2n, (4)

nơi hàm ζ(t) giảm một cách nghiêm ngặt theo t∈N0.

Các chứng minh của tất cả kết quả trong phần này được trình bày trong Phụ lục A. Hơn nữa, định lý sau cho thấy rằng cận trên chặt chẽ trên khoảng cách giữa trọng số ban đầu winit và trọng số cuối cùng wt,T sau T bước tinh chỉnh (tức là, ∥winit−wt,T∥2) giảm một cách nghiêm ngặt khi số lượng t của các vòng tự chưng cất tăng lên:

Định lý 2. Có một hàm ψ:N0→R≥0 sao cho (1) ∥winit−wt,T∥2=ψ(t) cho một số winit∈Rdp, (2)∥winit−wt,T∥2≤ψ(t) cho tất cả winit∈Rdp, (3) hàm ψ(t) giảm một cách nghiêm ngặt theo t∈N0, (4) hàm ψ(t) có thể được phân tách thành ψ(t) =p G1+ψ1(t) + 1{t= 0}B+G2 với các hằng số G1, G2≥0 trong khi ψ1(t) giảm một cách nghiêm ngặt theo t∈N0 và B=Pdp i=np+1(u⊤ iw0,0)2≥0.

Định lý 2 cho thấy rằng tự chưng cất hoạt động như một điều hòa trên khoảng cách giữa trọng số ban đầu winit và trọng số cuối cùng wt,T. Vì độ phức tạp Rademacher của một tập hợp các vector không thay đổi đối với một dịch chuyển bởi một vector hằng số, khoảng cách này đã được cho thấy kiểm soát giới hạn tổng quát hóa trong các bài báo trước đây trong các mô hình và cài đặt khác nhau, bao gồm cả mạng neural sâu (Bartlett & Mendelson, 2002; Bartlett et al., 2017; Nagarajan & Kolter, 2019). Điều này gợi ý rằng tự chưng cất giúp tổng quát hóa thông qua một hiệu ứng điều hòa trên khoảng cách. Hơn nữa, vòng đầu tiên của tự chưng cất được dự kiến có tác động lớn nhất dựa trên Định lý 2 vì Định lý 2 cho thấy rằng chúng ta có thể loại bỏ hoàn toàn thành phần không cần thiết B của w0,0 trong vòng đầu tiên của tự chưng cất. Chúng tôi đã xác minh những dự đoán lý thuyết này trong các thí nghiệm nơi chúng tôi cho thấy mối tương quan giữa cải thiện thông qua tự chưng cất và khoảng cách xuất hiện trong giới hạn tổng quát hóa trong bài báo trước đây (Nagarajan & Kolter, 2019).

5 THÍ NGHIỆM

Tập Dữ Liệu Đối với bài toán phân loại hình ảnh, chúng tôi sử dụng sáu tập dữ liệu — FGVC Aircraft (Aircraft) (Maji et al., 2013), Caltech UCSD Birds 200 (CUB) (Wah et al., 2011), Chest X-ray (Kermany et al., 2018), Describable Textures Dataset (DTD) (Cimpoi et al., 2014), Stanford Dogs (Khosla et al., 2011), và Oxford 102 Flower (Nilsback & Zisserman, 2008). Đối với bài toán phân loại văn bản, chúng tôi sử dụng bốn tập dữ liệu — Chemprot (Kringelum et al., 2016), ACL-ARC (Jurgens et al., 2018), SCIERC (Luan et al., 2018), và Twitter-Emotion (Mohammad et al., 2018). Vui lòng xem Phụ lục D để biết thêm chi tiết.

Chi Tiết Thực Hiện Đối với bài toán phân loại hình ảnh, chúng tôi sử dụng Vision Transformer được tiền huấn luyện trên tập dữ liệu ImageNet không nhãn với mã hóa tự động có mặt nạ (He et al., 2022) và tinh chỉnh nó trên tác vụ downstream với bộ tối ưu AdamW (Loshchilov & Hutter, 2019) trong 10,000 bước với kích thước batch 32. Về tiền huấn luyện thêm và tự chưng cất, chúng tôi tiếp tục tiền huấn luyện mô hình trong 20,000 bước với kích thước batch 64. Chúng tôi đánh giá Vision Transformers với độ chính xác. Đối với phân loại văn bản, theo cài đặt thí nghiệm từ Gururangan et al. (2020), chúng tôi sử dụng RoBERTA (Liu et al., 2019) như một mạng backbone và tinh chỉnh nó trên tập dữ liệu có nhãn mục tiêu

6

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Bảng 1: Trung bình và độ lệch chuẩn của độ chính xác với 5 lần chạy cho các tập dữ liệu phân loại hình ảnh.
Phương pháp Aircraft CUB Chest X-ray DTD Dogs Flower
Tinh chỉnh 72.33±1.13 55 .55±0.54 77 .15±0.52 67 .56±0.52 62 .53±0.57 88 .78±0.65
RecAdam 70.76±1.25 55 .22±1.29 77 .29±1.32 67 .59±1.03 61 .65±0.92 88 .97±0.44
MARS 72.74±0.57 55 .35±0.73 77 .28±1.80 66 .79±0.90 62 .24±0.96 87 .93±1.21
R3F 72.95±0.46 55 .91±0.79 76 .86±0.97 65 .32±1.25 62 .15±0.48 88 .92±0.78
Tiền Huấn Luyện Thêm 73.38±0.64 55 .72±0.46 77 .79±2.06 65 .55±1.12 62 .34±0.39 88 .63±0.35
Tự Chưng Cất 74.37 ±0.43 58.06 ±0.90 79.68 ±1.05 68.51 ±0.51 63.55 ±0.39 90.28 ±0.44

Bảng 2: Trung bình và độ lệch chuẩn của điểm F1 với 5 lần chạy cho các tập dữ liệu phân loại văn bản.
Phương pháp SCIERC ACL-ARC Chemprot Twitter-Emotion
Tinh chỉnh 76.63±2.06 64 .09±4.13 80 .59±1.15 77 .61±0.83
RecAdam 79.45±1.92 59 .70±2.68 82.73±0.28 78.26±0.88
MARS 74.69±1.25 53 .57±6.64 80 .18±0.92 77 .48±1.69
R3F 75.61±2.49 60 .13±2.55 79 .25±2.16 77 .79±0.81
Tiền Huấn Luyện Thêm 80.32±1.25 69 .73±2.40 82 .33±0.46 78 .71±0.40
Tự Chưng Cất 81.79 ±0.75 73.17 ±2.19 82.87 ±0.35 79.77 ±0.79

với bộ tối ưu AdamW trong 10 epoch với kích thước batch 32. Về tiền huấn luyện thêm và tự chưng cất, chúng tôi tiền huấn luyện thêm RoBERTA trong 100 epoch với kích thước batch 128. Chúng tôi đánh giá các mô hình với macro F1 cho tập dữ liệu SCIERC, ACL-ARC, và Twitter-Emotion, và micro F1 cho tập dữ liệu Chemprot.

Baseline Chúng tôi so sánh phương pháp của chúng tôi với các baseline sau đây nhắm mục tiêu cho việc tinh chỉnh các mô hình tiền huấn luyện. Tất cả các mô hình được khởi tạo với các trọng số tiền huấn luyện θinit và ϕinit.

1.Tinh chỉnh : Mô hình được tinh chỉnh trên tập dữ liệu có nhãn mục tiêu Dtr mà không có tiền huấn luyện thêm hoặc điều hòa nào ngoại trừ dropout và weight decay.
2.RecAdam (Chen et al., 2020a) : Mô hình được huấn luyện với bộ tối ưu RecAdam là một biến thể của bộ tối ưu Adam (Kingma & Ba, 2015) và thêm vào đó phạt khoảng cách L2 giữa trọng số tinh chỉnh và trọng số tiền huấn luyện ban đầu.
3.MARS (Gouk et al., 2021) : Mô hình được huấn luyện để tối thiểu hóa hàm mất mát cross-entropy cùng với điều hòa chiếu trọng số tinh chỉnh để nằm trong một hình cầu có tâm tại trọng số tiền huấn luyện ban đầu. Đối với mỗi lớp, khoảng cách được tạo ra bởi chuẩn ma trận Maximum Absolute Row Sum (MARS) (max j P i=1|Wj,i−Uj,i|) được sử dụng cho điều hòa.
4.R3F (Aghajanyan et al., 2021) : Mô hình được huấn luyện để tối thiểu hóa hàm mất mát cross-entropy cũng như phân kỳ KL đối xứng giữa đầu ra softmax của đầu vào gốc và đầu ra của đầu vào bị nhiễu bởi tiếng ồn Gaussian.
5.Tiền Huấn Luyện Thêm (Gururangan et al., 2020) : Tiền huấn luyện thích ứng tác vụ nơi chúng ta tiền huấn luyện thêm mô hình trên tập dữ liệu không nhãn mục tiêu Du với mục tiêu mã hóa tự động có mặt nạ và tinh chỉnh nó trên tập dữ liệu có nhãn mục tiêu Dtr.
6.Tự Chưng Cất : Đây là mô hình của chúng tôi được tiền huấn luyện thêm trên tập dữ liệu không nhãn mục tiêu Du với phương trình 3 và tinh chỉnh trên tập dữ liệu có nhãn mục tiêu Dtr.

5.1 KẾT QUẢ CHÍNH

Như được hiển thị trong Bảng 1, tự chưng cất liên tục vượt trội hơn tất cả các phương pháp điều hòa và phương pháp tiền huấn luyện thêm trên các tập dữ liệu hình ảnh. Đáng chú ý, phương pháp của chúng tôi cải thiện đáng kể hiệu suất của tập dữ liệu Chest X-ray bao gồm các hình ảnh thang xám cho chẩn đoán viêm phổi. Ngoài ra, tự chưng cất hiệu quả giải quyết tập dữ liệu Flower chỉ chứa 2,040 ví dụ có nhãn. Ngược lại, các baseline khác không cho thấy cải thiện nhất quán trên tất cả các tập dữ liệu hình ảnh. Ví dụ, tiền huấn luyện thêm hiệu quả cho tập dữ liệu Aircraft, nhưng làm giảm đáng kể độ chính xác kiểm tra trên tập dữ liệu DTD. Các phương pháp điều hòa như RecAdam, MARS, và R3F hầu như không cải thiện hiệu suất tổng quát hóa trên hầu hết các tập dữ liệu hoặc kém hiệu suất hơn chiến lược tinh chỉnh đơn giản trên một số tập dữ liệu nhất định. Bằng chứng thực nghiệm này hỗ trợ rằng các điều hòa buộc các mô hình tinh chỉnh gần với trọng số tiền huấn luyện ban đầu không hiệu quả cho việc thích ứng một mô hình tiền huấn luyện với các tập dữ liệu mục tiêu của các miền cụ thể.

Hơn nữa, như được hiển thị trong Bảng 2, chúng tôi cung cấp kết quả thí nghiệm bổ sung cho các tác vụ phân loại văn bản. Một lần nữa, tự chưng cất vượt trội đáng kể so với tất cả các baseline trên cả bốn tập dữ liệu,

7

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

1K 2.5K 5K 10K 20K 30K 40K 50K
# of instances020406080Độ Chính Xác Kiểm TraTinh chỉnh
Tiền Huấn Luyện Thêm
Tự Chưng Cất

Hình 3: Độ chính xác với việc thay đổi
số lượng dữ liệu huấn luyện.Bảng 3: Ablation trên CUB và SCIERC.
Mô hình CUB SCIERC
Mô hình Đầy đủ 58.06±0.90 81.79 ±0.75
w/oLMAE 57.60±0.81 80 .66±0.62
w/oLDistill 55.72±0.46 80 .32±1.25
Tiền Huấn Luyện Thêm ×2 53 .41±0.75 80 .52±0.98
Khớp-Dự đoán 55.27±1.07 81 .09±1.07
Khớp-Trọng số ( ℓ2) 53.70±0.91 80 .54±1.21
Khớp-Trọng số (MARS) 54.82±0.60 80 .95±0.71

0 2 4
Vòng Tự Chưng Cất ( t)88.589.089.590.090.591.0Độ Chính Xác Kiểm Tra

Hình 4: Độ chính xác kiểm tra với
việc thay đổi vòng tự chưng cất.

ngoại trừ RecAdam trong tập dữ liệu Chemprot. Trái ngược với thí nghiệm trước đây, phương pháp tiền huấn luyện thêm cải thiện điểm F1 kiểm tra của phương pháp tinh chỉnh đơn giản, tuy nhiên nó vẫn kém hiệu suất hơn mô hình của chúng tôi. Đối với các phương pháp điều hòa — RecAdam, MARS, và R3F, chúng không đạt được cải thiện nhất quán trên cả ba tập dữ liệu. RecAdam cải thiện vừa phải điểm F1 trên tập dữ liệu SCIERC và Chemprot nhưng làm giảm đáng kể hiệu suất tổng quát hóa trên tập dữ liệu ACL-ARC. Cả MARS và R3F đều cho thấy hiệu suất kém trên tập dữ liệu SCIERC và ACL-ARC, và hiệu suất của chúng hơi tệ hơn so với phương pháp Tinh chỉnh trên tập dữ liệu Chemprot.

Kết Quả cho Dữ Liệu Tài Nguyên Thấp Chúng tôi tiến hành thêm các thí nghiệm để cho thấy cách tự chưng cất hiệu quả xử lý tài nguyên thấp của dữ liệu có nhãn. Cho một tập dữ liệu CIFAR-100 đầy đủ (Krizhevsky et al., 2009) chứa 50,000 cặp huấn luyện của một hình ảnh và nhãn tương ứng, chúng tôi vẽ đồ thị độ chính xác kiểm tra của mỗi mô hình bằng cách thay đổi số lượng thể hiện huấn luyện. Lưu ý rằng chúng tôi cũng giảm số lượng hình ảnh không nhãn được sử dụng cho tiền huấn luyện thêm hoặc tự chưng cất. Như được hiển thị trong Hình 3, tự chưng cất liên tục cải thiện hiệu suất tổng quát hóa của cả phương pháp tinh chỉnh và mô hình được tiền huấn luyện thêm trên các hình ảnh từ tập dữ liệu CIFAR-100. Đáng chú ý, lợi ích từ tự chưng cất trở nên lớn hơn khi các mô hình được huấn luyện với một số lượng cực kỳ nhỏ các thể hiện. Ví dụ, tự chưng cất đạt được 13% và 6% cải thiện độ chính xác kiểm tra so với mô hình với tinh chỉnh đơn giản khi có 1,000 và 2,500 ví dụ có nhãn, tương ứng. Những kết quả thực nghiệm này xác minh rằng tự chưng cất có thể thích ứng hiệu quả mô hình tiền huấn luyện với tập dữ liệu mục tiêu ngay cả khi có lượng cực kỳ nhỏ dữ liệu có nhãn.

Nghiên Cứu Ablation Chúng tôi thực hiện nghiên cứu ablation để xác minh hiệu quả của từng thành phần của tự chưng cất. Trong Bảng 3, chúng tôi cho thấy kết quả thực nghiệm trên cả tập dữ liệu CUB và tập dữ liệu SCIERC trong khi loại bỏ hoặc thay thế các thành phần khác nhau của tự chưng cất. Đầu tiên, chúng tôi loại bỏ mục tiêu mã hóa tự động có mặt nạ LMAE và huấn luyện mô hình chỉ với hàm mất mát chưng cất LDistill trước khi tinh chỉnh. Trên tập dữ liệu hình ảnh CUB, nó không tạo ra sự khác biệt đáng kể, tuy nhiên, loại bỏ mục tiêu mã hóa tự động có mặt nạ làm giảm hiệu suất tổng quát hóa của mô hình ngôn ngữ trên tập dữ liệu phân loại văn bản SCIERC. Ngoài ra, chúng tôi loại bỏ hàm mất mát chưng cất LDistill trong phương trình 3, điều này dẫn đến phương pháp tiền huấn luyện thêm. Hơn nữa, chúng tôi tiếp tục tiền huấn luyện mô hình gấp đôi số bước dài hơn so với phương pháp tiền huấn luyện thêm gốc, ký hiệu là Tiền Huấn Luyện Thêm ×2, để cho thấy rằng độ chính xác kiểm tra cao hơn của tự chưng cất không phải là hệ quả của tiền huấn luyện dài hơn. Cả hai mô hình đều kém hiệu suất đáng kể so với tự chưng cất, điều này cho thấy hiệu quả của hàm mất mát tự chưng cất. Cuối cùng, chúng tôi thực hiện thí nghiệm cho các biến thể của hàm mất mát chưng cất LDistill trong phương trình 3. Thay vì khớp biểu diễn của giáo viên và học sinh, chúng tôi buộc việc tái tạo các đầu vào có mặt nạ bởi giáo viên và học sinh phải nhất quán, tức là, tối thiểu hóa θ,ϕ∥gϕ◦fθ(ˆx)−gϕ0◦fθ0(ˆx)∥2 2 cho ViT hoặc tối thiểu hóa θ,ϕPT t=1DKL(pθ0,ϕ0(xt|ˆx)∥pθ,ϕ(xt|ˆx)) cho RoBERTA, ký hiệu là Khớp-Dự đoán. Hơn nữa, chúng tôi thay thế hàm mất mát chưng cất bằng hàm tối thiểu hóa khoảng cách L2 hoặc MARS giữa các tham số của học sinh và giáo viên, ký hiệu là Khớp-Trọng số. Như được hiển thị trong Bảng 3, tất cả các biến thể này không hiệu quả so với biến thể tối thiểu hóa khoảng cách giữa các biểu diễn ẩn của học sinh và giáo viên.

Nhiều Vòng Tự Chưng Cất Cuối cùng, chúng tôi chứng minh thực nghiệm rằng vòng đầu tiên của tự chưng cất đóng vai trò quan trọng nhất trong việc cải thiện hiệu suất tổng quát hóa. Cụ thể, chúng tôi tinh chỉnh mỗi mô hình sau t vòng tự chưng cất và vẽ đồ thị độ chính xác kiểm tra trên tập dữ liệu Oxford 102 Flower, nơi 0 vòng tự chưng cất (t= 0) biểu thị mô hình với tiền huấn luyện thêm. Như được hiển thị trong Hình 4, vòng đầu tiên của tự chưng cất cải thiện đáng kể độ chính xác kiểm tra của mô hình với tiền huấn luyện thêm và lợi ích từ tự chưng cất trở nên biên sau vòng đầu tiên. Xem xét chi phí tính toán bổ sung và cải thiện biên của tự chưng cất nhiều vòng, chúng tôi thực hiện một vòng tự chưng cất duy nhất cho tất cả các thí nghiệm.

8

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Aircraft CUB DTD Dogs X-ray Flower0.00.51.01.52.02.5Khoảng Cách Tổng Quát HóaTiền Huấn Luyện Thêm
Tự Chưng Cất
(a)

Aircraft CUB DTD Dogs X-ray Flower020406080100120140Khoảng cách L2
Tiền Huấn Luyện Thêm
Tự Chưng Cất (b)

0 1 2 3 4
Vòng Tự Chưng Cất ( t)100110120130/bardblθinit−θt,T/bardbl2
 (c)

Hình 5: (a) Khoảng cách tổng quát hóa : Sự khác biệt giữa hàm mất mát kiểm tra có giám sát và hàm mất mát huấn luyện. (b) Hiệu ứng của tự chưng cất trên khoảng cách: Khoảng cách giữa các trọng số tiền huấn luyện ban đầu và trọng số tinh chỉnh cuối cùng của tiền huấn luyện thêm và tự chưng cất. (c) Hiệu ứng của tự chưng cất nhiều vòng: Khoảng cách giữa các trọng số tiền huấn luyện ban đầu và trọng số tinh chỉnh cuối cùng cho mỗi vòng tự chưng cất t∈N+.

5.2 PHÂN TÍCH THÊM

Trong phần này, chúng tôi trình bày các thí nghiệm số để phân tích tại sao tự chưng cất có thể tiềm năng giúp cải thiện hiệu suất tổng quát hóa của các tác vụ downstream so với tiền huấn luyện thêm và chứng minh thực nghiệm rằng Định lý 1 và 2 có thể được mở rộng cho các mạng neural sâu — transformers.

(a) Khoảng cách tổng quát hóa: Trong Hình 5a, chúng tôi vẽ đồ thị khoảng cách tổng quát hóa, là hàm mất mát kiểm tra trừ hàm mất mát huấn luyện trên mỗi tập dữ liệu có nhãn, của tự chưng cất và phương pháp tiền huấn luyện thêm. Tự chưng cất cải thiện khoảng cách tổng quát hóa của phương pháp tiền huấn luyện thêm trên tất cả các tập dữ liệu. Nó nhất quán với Định lý 1 cho thấy rằng tự chưng cất với một mô hình đơn giản hóa giảm một cách nghiêm ngặt giới hạn tổng quát hóa trên hàm mất mát có giám sát của giai đoạn tinh chỉnh.

(b) Hiệu ứng của tự chưng cất trên khoảng cách: Để xác thực thực nghiệm Định lý 2 về hiệu ứng điều hòa bởi tự chưng cất trên khoảng cách L2 giữa trọng số tiền huấn luyện ban đầu θinit và trọng số cuối cùng sau tinh chỉnh, chúng tôi vẽ đồ thị khoảng cách thu được từ tự chưng cất và tiền huấn luyện thêm. Cụ thể, chúng tôi so sánh khoảng cách ∥θinit−θ1,T∥2 và ∥θinit−θ0,T∥2, nơi θt,τ là tham số sau t vòng tự chưng cất và τ bước gradient descent cho tinh chỉnh. Như được hiển thị trong Hình 5b, tự chưng cất liên tục giảm khoảng cách và khoảng cách giảm tương quan với khoảng cách tổng quát hóa tốt hơn trong Hình 5a. Những kết quả thực nghiệm này xác nhận mối liên kết giữa khoảng cách L2 từ khởi tạo và giới hạn tổng quát hóa (Nagarajan & Kolter, 2019).

(c) Hiệu ứng của tự chưng cất nhiều vòng: Cuối cùng, chúng tôi xác thực thực nghiệm một phần của Định lý 2 cho thấy rằng vòng đầu tiên của tự chưng cất đóng vai trò quan trọng nhất của điều hòa trên khoảng cách L2 giữa trọng số tiền huấn luyện ban đầu θinit và trọng số cuối cùng θt,T ký hiệu là tham số sau t vòng tự chưng cất và T bước gradient descent cho tinh chỉnh trên tập dữ liệu VGG flower 102. Như được hiển thị trong Hình 5c, tự chưng cất giảm đáng kể khoảng cách ở vòng đầu tiên (t= 1) và hiệu ứng điều hòa trên khoảng cách giảm dần sau đó, nơi 0 vòng tự chưng cất (t= 0) biểu thị mô hình với tiền huấn luyện thêm nhưng không có tự chưng cất.

6 KẾT LUẬN

Để thích ứng hiệu quả các transformers tiền huấn luyện với một miền mục tiêu, chúng tôi đã đề xuất tự chưng cất như một điều hòa cho tiền huấn luyện thêm. Cụ thể, chúng tôi đầu tiên lấy transformer tiền huấn luyện ban đầu và tiếp tục tiền huấn luyện nó với mục tiêu mã hóa tự động có mặt nạ trên tập dữ liệu không nhãn mục tiêu và coi phần bộ mã hóa của mô hình như một giáo viên cho tự chưng cất. Sau đó chúng tôi lấy bản sao của cùng mô hình tiền huấn luyện ban đầu làm học sinh và buộc các biểu diễn của học sinh phải gần với những biểu diễn của giáo viên trong khi tối ưu hóa học sinh với mục tiêu mã hóa tự động có mặt nạ trên tập dữ liệu không nhãn mục tiêu. Cuối cùng, chúng tôi tinh chỉnh học sinh tự chưng cất trên tập dữ liệu có nhãn mục tiêu. Đánh giá thực nghiệm của chúng tôi trên các tập dữ liệu benchmark phân loại hình ảnh và văn bản khác nhau cho thấy rằng tự chưng cất liên tục cải thiện hiệu suất tổng quát hóa so với các baseline liên quan. Cuối cùng, chúng tôi cung cấp phân tích lý thuyết của phương pháp đề xuất với một mô hình đơn giản hóa để hiểu cách tự chưng cất cho tiền huấn luyện thêm có thể tiềm năng giúp cải thiện hiệu suất tổng quát hóa của các tác vụ downstream.

9

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

TUYÊN BỐ VỀ KHẢ NĂNG TÁI TẠO

Chúng tôi sử dụng Pytorch (Paszke et al., 2019) và thư viện transformers (Wolf et al., 2020) từ Huggingface để thực hiện tất cả các baseline và phương pháp đề xuất của chúng tôi trong các thí nghiệm. Chúng tôi đã mô tả phương pháp tự chưng cất cho tiền huấn luyện thêm trong Thuật toán 1 và chỉ định tất cả cài đặt thí nghiệm bao gồm các siêu tham số trong Phần 5 và Phụ lục E. Đối với phân tích lý thuyết, chúng tôi đã cung cấp tất cả các chứng minh trong Phụ lục A.

LỜI CẢM ƠN

Công trình này được hỗ trợ bởi tài trợ của Viện Quy hoạch và Đánh giá Công nghệ Thông tin & Truyền thông (IITP) được tài trợ bởi chính phủ Hàn Quốc (MSIT) (Số 2019-0-00075, Chương trình Trường Đại học Trí tuệ Nhân tạo (KAIST)), Chương trình Trung tâm Nghiên cứu Kỹ thuật thông qua Quỹ Nghiên cứu Quốc gia Hàn Quốc (NRF) được tài trợ bởi Chính phủ Hàn Quốc MSIT (NRF-2018R1A5A1059921), tài trợ của Viện Quy hoạch và Đánh giá Công nghệ Thông tin & Truyền thông (IITP) được tài trợ bởi chính phủ Hàn Quốc (MSIT) (Số 2021-0-02068, Trung tâm Đổi mới Trí tuệ Nhân tạo), tài trợ của Viện Quy hoạch và Đánh giá Công nghệ Thông tin & Truyền thông (IITP) được tài trợ bởi chính phủ Hàn Quốc (MSIT) (Số 2022-0-00184, Phát triển và Nghiên cứu Công nghệ AI để Tuân thủ một cách Không tốn kém với Chính sách Đang phát triển về Đạo đức), tài trợ của Viện Quy hoạch và Đánh giá Công nghệ Thông tin & Truyền thông (IITP) được tài trợ bởi chính phủ Hàn Quốc (MSIT) (Số 2022-0-00713), Trung tâm AI Siêu sáng tạo KAIST-NAVER, và Samsung Electronics (IO201214-08145-01). Tài liệu này dựa trên công việc được hỗ trợ bởi chương trình Google Cloud Research Credits với giải thưởng (6NW8-CF7K-3AG4-1WH1).

TÀI LIỆU THAM KHẢO

[Tiếp tục với danh sách tài liệu tham khảo từ nguyên bản...]

10

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

[Tiếp tục danh sách tài liệu tham khảo...]

11

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

[Tiếp tục danh sách tài liệu tham khảo...]

12

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

[Tiếp tục danh sách tài liệu tham khảo...]

13

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

PHỤ LỤC

A CHỨNG MINH

Chúng tôi cũng định nghĩa vector đầu ra mô hình ft∈Rn×p bởi (ft)ij=f(xi, wt)j. Ví dụ, f0 là ma trận nhãn giáo viên ban đầu. Cho [n] ={1, . . . , n }. Ký hiệu hạng của [Ip⊗Φ] bởi r= rank([ Ip⊗Φ])≤np. Định nghĩa ˜U= [u1, u2. . . , u r]∈Rdp×r và Pr=I−˜U˜U⊤, là ma trận chiếu lên không gian null của ˜U⊤. Chúng tôi đầu tiên chứng minh bổ đề sau, sẽ được sử dụng trong các chứng minh của Định lý 1 và Định lý 2 sau này:

Bổ đề 1. Với bất kỳ t∈N0, wt,0=Pr i=1αi,t˜ui+ 1{t= 0}v, nơi αi,t=1 σi 1 1+(nλ/σ2 i)t ∈R, ˜ui= ˜yiui∈Rdp,˜yi= (V⊤vec[f0])i∈R, và v=Prw0,0.

Chứng minh của Bổ đề 1. Định nghĩa wt:=wt,0 cho t∈N+. Điều kiện cần thiết trên nghiệm wt tại bước t là ∇L(wt) = 0 . Do đó, bằng cách giải ∇L(wt) = 0 cho wt, chúng ta có wt= ([Ip⊗Φ][Ip⊗ Φ]⊤+nλI)−1[Ip⊗Φ] vec[ ft−1]. Bằng cách sử dụng phân tách giá trị đơn [Ip⊗Φ] = UΣV⊤, vì UU⊤=U⊤U=I và V⊤V=I, chúng ta có

wt= (UΣΣ⊤U⊤+nλI)−1UΣV⊤vec[ft−1] = (U(ΣΣ⊤+nλI)U⊤)−1UΣV⊤vec[ft−1]
=U(ΣΣ⊤+nλI)−1ΣV⊤vec[ft−1].

Do đó, wt=U(ΣΣ⊤+nλI)−1ΣV⊤vec[ft−1]. Sử dụng điều này và [Ip⊗Φ] = UΣV⊤,

vec[ft] = vec[Φ⊤W⊤ tIp] = [Ip⊗Φ]⊤wt= [Ip⊗Φ]⊤U(ΣΣ⊤+nλI)−1ΣV⊤vec[ft−1]
=VΣ⊤(ΣΣ⊤+nλI)−1ΣV⊤vec[ft−1].

Do đó, vec[ft] =V AV⊤vec[ft−1] nơi A= Σ⊤(ΣΣ⊤+nλI)−1Σ. Lặp lại quá trình này cho vec[ft−1], vì V⊤V=I,

vec[ft] =V AV⊤V AV⊤···V AV⊤vec[f0] =V AtV⊤vec[f0].

Thay phương trình này của vec[ft−1] =V At−1V⊤vec[f0] vào phương trình của wt=U(ΣΣ⊤+ nλI)−1ΣV⊤vec[ft−1], chúng ta có

wt=U(ΣΣ⊤+nλI)−1ΣV⊤V At−1V⊤vec[f0] =UBAt−1V⊤vec[f0]

nơi B= (ΣΣ⊤+nλI)−1Σ. Ở đây, chúng ta có thể viết lại ma trận B∈Rdp×np như

B=¯B 0(dp−np)×np

nơi 0(dp−np)×np là ma trận (dp−np) nhân np với tất cả các phần tử bằng không, và ¯B∈Rnp×np là một ma trận đường chéo được định nghĩa bởi

¯Bii:=σi(σ2 i+nλ)−1.

Sử dụng B này trong phương trình trên của wt=UBAt−1V⊤vec[f0],

wt=U¯B 0(dp−np)×np At−1V⊤vec[f0]
= [u1u2··· udp]¯BAt−1 0(dp−np)×np V⊤vec[f0]
=¯U¯BAt−1V⊤vec[f0]

nơi ¯U= [u1, u2. . . , u np]∈Rdp×np. Vì ma trận A= Σ⊤(ΣΣ⊤+nλI)−1Σ∈Rnp×np là một ma trận đường chéo với phần tử của nó là Aii=σ2 i(σ2 i+nλ)−1,điều này có thể được đơn giản hóa thêm như

14

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

wt=¯U¯BAt−1V⊤vec[f0]
=¯U
σ1 1 σ2 1+nλ
...
σ1 np σ2np+nλ

σ2 1 σ2 1+nλ
...
σ2 np σ2np+nλ
t−1
˜y1
˜y2
...
˜ynp

= [u1u2··· unp]
σ1(σ2 1+nλ)−1(σ2 1(σ2 1+nλ)−1)t−1˜y1
σ2(σ2 2+nλ)−1(σ2 2(σ2 2+nλ)−1)t−1˜y2
...
σnp(σ2 np+nλ)−1(σ2 np(σ2 np+nλ)−1)t−1˜ynp

=npX i=1σi(σ2 i+nλ)−1(σ2 i(σ2 i+nλ)−1)t−1˜yiui
=rX i=1σi(σ2 i+nλ)−1(σ2 i(σ2 i+nλ)−1)t−1˜yiui

nơi dòng cuối cùng theo từ thực tế rằng σi(σ2 i+nλ)−1(σ2 i(σ2 i+nλ)−1)t−1= 0 cho tất cả i > r . Vì σi(σ2 i+nλ)−1(σ2 i(σ2 i+nλ)−1)t−1=σ2t−1 i(σ2 i+nλ)−t=1 σi(σ2 i σ2 i+nλ)t cho i≤r, điều này ngụ ý rằng

wt=rX i=11 σiσ2 i σ2 i+nλt ˜yiui=rX i=11 σi1 1 + (nλ/σ2 i)t ˜yiui

Vì t∈N+ là tùy ý, điều này xảy ra cho bất kỳ t∈N+. Điều này chứng minh câu đầu tiên của định lý cho bất kỳ t∈N+. Với t= 0, vì

˜yi= (V⊤vec[f0])i= (V⊤[Ip⊗Φ]⊤w0,0)i= (V⊤VΣ⊤U⊤w0,0)i= (Σ⊤U⊤w0,0)i=σiu⊤ iw0,0,

chúng ta có

rX i=11 σi1 1 + (nλ/σ2 i)t ˜yiui= rX i=1uiu⊤ i! w0,0=˜U˜U⊤w0,0.

Do đó,

w0,0=˜U˜U⊤w0,0+ (I−˜U˜U⊤)w0,0=rX i=11 σi1 1 + (nλ/σ2 i)t ˜yiui+ (I−˜U˜U⊤)w0,0.

Vì (I−˜U˜U⊤)w0,0=Prw0,0, điều này hoàn thành câu đầu tiên của định lý cho bất kỳ t∈N0.

A.1 CHỨNG MINH CỦA ĐỊNH LÝ 1

Chứng minh. Định nghĩa Z:= [Ip⊗Φ]⊤∈R¯n×¯d nơi ¯n=np và ¯d=dp. Sau đó,

L(w) =1 2nX i=1∥f(xi, w)−yi∥2 2=1 2∥Zw−Y∥2 2

nơi Y= vec[[ y1, . . . , y n]⊤]∈R¯n. Vì ∇L(wt,τ) =Z⊤(Zwt,τ−Y),

dwt,τ dτ=−Z⊤(Zwt,τ−Y)

Vì rank(Φ) = n và d≥n, chúng ta có rank( Z) = ¯n bởi tính chất của tích Kronecker với ma trận đơn vị. Vì rank( Z) = ¯n, tồn tại v∈R¯d sao cho Y=Zv. Do đó,

dwt,τ dτ=−Z⊤(Zwt,τ−Zv)
=−Z⊤Z(wt,τ−v)
=−Z⊤Z(wt,τ−v).

Vì Z⊤=UΣV⊤, chúng ta có Z⊤Z=UΣΣ⊤U⊤=P¯n i=1σ2 iuiu⊤ i. Do đó,

dwt,τ dτ=− ¯nX i=1σ2 iuiu⊤ i! (wt,τ−v) =−¯nX i=1σ2 iuiu⊤ i(wt,τ−v).

Vì các cột của U tạo thành cơ sở của R¯d và w, v∈R¯d, chúng ta có thể viết wt,τ=P¯d k=1c(t,τ) k uk và v=P¯d k=1qkuk cho một số c(t,τ) k và qk. Do đó,

dwt,τ dτ=−¯nX i=1σ2 iuiu⊤ i¯dX k=1(c(t,τ) k−qk)uk
=−¯nX i=1¯dX k=1σ2 i(c(t,τ) k−qk)uiu⊤ iuk
=−¯nX i=1σ2 i(c(t,τ) i−qi)ui.

Sử dụng wt,τ=P¯d k=1c(t,τ) k uk cho vế phải cũng vậy, chúng ta có

d dτ¯dX i=1c(t,τ) iui=−¯nX i=1σ2 i(c(t,τ) i−qi)ui.

Điều này ngụ ý rằng cho tất cả i∈ {1, . . . , ¯n},

d dτc(t,τ) i=−σ2 i(c(t,τ) i−qi),

và d dτc(t,τ) i= 0 cho tất cả i /∈ {1, . . . , ¯n}. Điều này cũng có thể được thấy bởi thực tế rằng dwt,τ dτ=−Z⊤(Zwt,τ− Zv) với Z⊤=UΣV⊤ và do đó động học chỉ thêm các thành phần của ui cho i∈ {1, . . . , ¯n}, và không cho i /∈ {1, . . . , ¯n}. Do đó, cho các thành phần của ui cho i /∈ {1, . . . , ¯n}, các giá trị ban đầu được giữ nguyên. Nói cách khác, cho i /∈ {1, . . . , ¯n},

c(t,τ) i=c(t,0) i.

Mặt khác, cho i∈ {1, . . . , ¯n}, vì d dτqi= 0,

d dτ(c(t,τ) i−qi) =d dτc(t,τ) i=−σ2 i(c(t,τ) i−qi).

Giải điều này cho (c(t,τ) i−qi), chúng ta có cho i∈ {1, . . . , ¯n},

c(t,τ) i−qi= (c(t,0) i−qi)e−σ2 iτ.

Điều này ngụ ý rằng

c(t,τ) i=qi+ (c(t,0) i−qi)e−σ2 iτ=qi(1−e−σ2 iτ) +c(t,0) ie−σ2 iτ.

Kết hợp những điều này với wt,T=P¯d k=1c(t,T) k uk,

wt,T=¯dX i=1c(t,T) iui=¯nX i=1qi(1−e−σ2 iT)ui+¯nX i=1c(t,0) ie−σ2 iTui+¯dX i=¯n+1c(t,0) iui. (5)

Do đó, cho bất kỳ s∈ S cụ thể, vì U= [u1, u2. . . , u dp]∈Rdp×dp là một ma trận trực giao,

∥At(s)∥2 2=∥wt,T∥2 2≤¯nX i=1 qi(1−e−σ2 iT)2 +¯nX i=1(c(t,0) i)2e−2σ2 iT+¯dX i=¯n+1(c(t,0) i)2. (6)

nơi qi, σi, và c(t,0) i đều phụ thuộc vào s.

15

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Bằng cách sử dụng Bổ đề 4 của (Pham et al., 2021) và lấy union bound với P(s /∈ S)≤δ, với xác suất ít nhất 1−δ, chúng ta có wt,T∈ Ft và điều sau đây xảy ra:

Ex,y[ℓ(wt,T, x, y)]≤1 n nX i=1ℓ(wt,T, xi, yi) + 2Rn(Ft) +Mr ln(2/δ) 2n, (7)

nơi Rn(Ft) =Es,ξ[supw∈Ft1 n Pn i=1ξi∥Wφ(xi)−yi∥2 2],s= ((xi, yi))n i=1,w= vec[ W⊤], và ξ1, . . . , ξ n là các biến ngẫu nhiên độc lập đồng nhất lấy giá trị trong {−1,1}. Bằng cách sử dụng Hệ quả 4 của (Maurer, 2016), tồn tại một hằng số c (chỉ phụ thuộc vào M) sao cho,

Rn(Ft)≤c n Es,ξ[ sup w∈FtnX i=1pX k=1ξikWkφ(xi)]
=c n Es,ξ[ sup w∈FtpX k=1WknX i=1ξikφ(xi)]
=c n Es,ξ[ sup w∈Ftw⊤h]

nơi Wk là hàng thứ k của W,ξik là các biến ngẫu nhiên độc lập đồng nhất lấy giá trị trong {−1,1},h= vec[ H]∈Rdp, và H∈Rd×p với Hjk=Pn i=1ξikφ(xi)j. Do đó,

Rn(Ft)≤c n Es,ξ[ sup w∈Ft∥w∥2∥h∥2] =c(supw∈Ft∥w∥2) n Es,ξ[∥h∥2]

Ở đây,

Es,ξ[∥h∥2] =Es,ξvuutdX j=1pX k=1 nX i=1ξikφ(xi)j!2
≤vuutdX j=1pX k=1Es,ξ nX i=1ξikφ(xi)j!2
=vuutdX j=1pX k=1EsnX i=1(φ(xi)j)2 (8)
=vuutpX k=1nX i=1EsdX j=1(φ(xi)j)2
=vuutpX k=1nX i=1Es∥φ(xi)∥2 2
≤R√pn

Phương trình 8 xảy ra vì

Es,ξ[(ξikϕ(xi)j)·(ξlkϕ(xl)j)] =Es[ 1{i=l}ϕ(xi)jϕ(xl)j]

cho tất cả i, l∈[n].

Do đó,

Rn(Ft)≤cR√p(supw∈Ft∥w∥2)√n. (9)

Định nghĩa

ζt(s):=vuut¯nX i=1 qi(1−e−σ2 iT)2+¯nX i=1(c(t,0) i)2e−2σ2 iT+¯dX i=¯n+1(c(t,0) i)2.

nơi qi, σi, và c(t,0) i đều phụ thuộc vào s. Với điều này, chúng ta định nghĩa

ζ(t):= sup s∈Sζt(s).

16

--- TRANG 16 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Sau đó, bằng cách kết hợp phương trình 6, phương trình 7, và phương trình 9, với xác suất ít nhất 1−δ, điều sau đây xảy ra:

Ex,y[ℓ(wt,T, x, y)]≤1 n nX i=1ℓ(wt,T, xi, yi) +ζ(t)r 4c2R2p n+Mr ln(2/δ) 2n.

Cuối cùng, từ Bổ đề 1, cho bất kỳ t∈N0 và i∈ {1, . . . , ¯n},

(c(t,0) i)2=  1 σi1 1 + (nλ/σ2 i)t ˜yi!2 .

Vì 1 1+(nλ/σ2 i)<1(bởi vì nλ/σ2 i>0), giá trị của 1 1+(nλ/σ2 i)2t giảm một cách nghiêm ngặt khi t tăng. Vì 1 σ2 i>0 và ˜y2 i≥0, điều này ngụ ý rằng (c(t,0) i)2 giảm một cách nghiêm ngặt theo t∈N0 trừ khi c(t,0) i= 0. Hơn nữa, từ Bổ đề 1, chúng ta có

wt,0=¯nX i=1αi,t˜yiui+ 1{t= 0}(I−˜U˜U⊤)w0,0.

Vì {u1, . . . , u ¯d} là một cơ sở trực chuẩn cho R¯d với tích vô hướng ⟨x, y⟩=y⊤x, chúng ta có

w0,0=¯dX i=1(u⊤ iw0,0)ui.

Vì ˜U˜U⊤w0,0=P¯n i=1(u⊤ iw0,0)ui, chúng ta có

(I−˜U˜U⊤)w0,0=¯dX i=1(u⊤ iw0,0)ui−¯nX i=1(u⊤ iw0,0)ui=¯dX i=¯n+1(u⊤ iw0,0)ui,

điều này ngụ ý rằng thành phần ui để span wt,0 cho i∈ {¯n+ 1, . . . , ¯d} chỉ có mặt trong (I− ˜U˜U⊤)w0,0. Nói cách khác,

wt,0=¯nX i=1αi,t˜yiui+¯dX i=¯n+11{t= 0}(u⊤ iw0,0)ui.

Do đó, cho bất kỳ t∈N0 và i∈ {¯n+ 1, . . . , ¯d}, chúng ta có

(c(t,0) i)2= 1{t= 0}(u⊤ iw0,0)2.

Những điều này ngụ ý rằng ζ(t) giảm một cách nghiêm ngặt theo t∈N0 trừ khi w0,0= 0.

A.2 CHỨNG MINH CỦA ĐỊNH LÝ 2

Chứng minh. Trong chứng minh này, chúng tôi tiếp tục sử dụng các kết quả và ký hiệu từ chứng minh của Định lý 1. Bằng cách sử dụng phương trình 5 trong chứng minh của Định lý 1, chúng ta có

∥winit−wt,T∥2=∥winit−vt∥2,

nơi

vt=¯nX i=1qi(1−e−σ2 iT)ui+¯nX i=1c(t,0) ie−σ2 iTui+¯dX i=¯n+1c(t,0) iui.

Nếu winit=−αvt cho một số α >0, thì

∥winit−vt∥2=∥vt+αvt∥2
= (1 + α)∥vt∥2
=∥vt∥2+∥αvt∥2
=vuut¯nX i=1q2 i(1−e−σ2 iT)2+¯nX i=1(c(t,0) i)2e−2σ2 iT+¯dX i=¯n+1(c(t,0) i)2+∥winit∥2.

17

--- TRANG 17 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Mặt khác, cho bất kỳ winit∈Rdp,

∥winit−vt∥2≤ ∥vt∥2+∥winit∥2
≤vuut¯nX i=1q2 i(1−e−σ2 iT)2+¯nX i=1(c(t,0) i)2e−2σ2 iT+¯dX i=¯n+1(c(t,0) i)2+∥winit∥2.

Do đó, đặt ψ(t) là hàm sau thỏa mãn các điều kiện (1) và (2) trong phát biểu:

ψ(t):=vuut¯nX i=1q2 i(1−e−σ2 iT)2+¯nX i=1(c(t,0) i)2e−2σ2 iT+¯dX i=¯n+1(c(t,0) i)2+∥winit∥2

Cuối cùng, từ Bổ đề 1, cho bất kỳ t∈N0 và i∈ {1, . . . , ¯n},

(c(t,0) i)2=  1 σi1 1 + (nλ/σ2 i)t ˜yi!2 .

điều này giảm một cách nghiêm ngặt theo t∈N0 trừ khi c(t,0) i= 0 cho tất cả i∈ {1, . . . , ¯n} như được chỉ ra trong chứng minh của Định lý 1. Hơn nữa, từ Bổ đề 1, cho bất kỳ t∈N0 và i∈ {¯n+ 1, . . . , ¯d},

(c(t,0) i)2= 1{t= 0}(u⊤ iw0,0)2.

Nghĩa là,

ψ(t) =vuutG1+ψ1(t) +¯dX i=¯n+11{t= 0}(u⊤ iw0,0)2+G2,

nơi

G1:=¯nX i=1q2 i(1−e−σ2 iT)2,

ψ1(t):=¯nX i=1  1 σi1 1 + (nλ/σ2 i)t ˜yi!2 e−2σ2 iT,

và

G2:=∥winit∥2.

Vì e−2σ2 iT>0 là một hằng số theo t và chúng ta đã chỉ ra trước đây rằng 1 σi 1 1+(nλ/σ2 i)t ˜yi2 giảm một cách nghiêm ngặt theo t∈N0 trừ khi w0,0= 0. Nó ngụ ý rằng cả ψ1(t) và ψ(t) đều giảm một cách nghiêm ngặt theo t∈N0 trừ khi w0,0= 0.

Nhận xét 1. Lưu ý rằng Định lý 2 cũng cho thấy khoảng cách giữa trọng số của giáo viên wt−1,T và trọng số tiền huấn luyện ban đầu winit cho tất cả t∈N+. Vì giáo viên tại vòng t′∈N+ của tự chưng cất từng là học sinh của vòng t′−1 của tự chưng cất và Định lý 2 xảy ra cho tất cả số nguyên không âm t∈N0, khoảng cách giữa trọng số ban đầu và trọng số giáo viên ∥winit−wt−1,T∥2 giảm một cách nghiêm ngặt cho tất cả t∈N+. Ví dụ, tại t= 1, chúng ta thu được bất đẳng thức sau

∥winit−w0,T∥2≤ψ(0),

nơi w0,T là trọng số của giáo viên ban đầu không có tự chưng cất .

B THÍ NGHIỆM BỔ SUNG

Trong phần này, chúng tôi thực hiện các thí nghiệm bổ sung để phân tích tốt hơn phương pháp đề xuất, tự chưng cất cho tiền huấn luyện thêm.

18

--- TRANG 18 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

Bảng 4: Hàm mất mát huấn luyện và kiểm tra.
Phương pháp Chia Aircraft CUB Chest-Xray DTD Dogs Flower
Tiền Huấn Luyện ThêmHuấn luyện (log) −9.13±0.09−8.58±0.05−8.10±1.90−3.70±0.37−5.41±0.13−9.70±0.32
Kiểm tra 1.44±0.03 2 .44±0.02 2 .26±0.22 2 .49±0.08 1 .96±0.02 0 .63±0.04
Tự Chưng CấtHuấn luyện (log) −9.17±0.08−8.16±0.31−6.08±0.50−4.08±0.30−5.50±0.06−7.98±1.28
Kiểm tra 1.36±0.01 2.26 ±0.04 2.08 ±0.17 2.15 ±0.06 1.90 ±0.01 0.50 ±0.03

Bảng 5: So sánh với học tương phản có giám sát.
Mô hình X-ray Flower
SupCon 75.30±1.03 76 .70±1.76
Tinh chỉnh 77.15±0.52 88 .78±0.65
Tiền Huấn Luyện Thêm 77.79±2.06 88 .63±0.35
Tự Chưng Cất 79.68±1.05 79.68 ±0.44Học Tương Phản Có Giám Sát Đối với các thí nghiệm chính trong Phần 5, chúng tôi sử dụng cùng một hàm mục tiêu cho tiền huấn luyện và tiền huấn luyện thêm. Người ta có thể tự hỏi điều gì xảy ra nếu chúng ta sử dụng mục tiêu khác nhau ở giai đoạn tiền huấn luyện thêm. Trong thí nghiệm này, chúng tôi tiếp tục tiền huấn luyện bộ mã hóa của transformer tiền huấn luyện (He et al., 2022) với hàm mất mát tương phản có giám sát (Khosla et al., 2020) trong khi tinh chỉnh một bộ phân loại tuyến tính được khởi tạo ngẫu nhiên với hàm mất mát cross-entropy. Như được hiển thị trong Bảng 5, học tương phản có giám sát (SupCon) làm giảm đáng kể hiệu suất tổng quát hóa của Vision Transformer trên cả tập dữ liệu X-ray và Flower. Dựa trên kết quả thí nghiệm này, chúng tôi phỏng đoán rằng transformer được tiền huấn luyện với mục tiêu mã hóa tự động có mặt nạ có thể không tương thích với hàm mất mát tương phản và do đó chúng ta có thể sử dụng cùng mục tiêu cho tiền huấn luyện và tiền huấn luyện thêm.

Khoảng Cách Tổng Quát Hóa Như được hiển thị trong Hình 5a, tự chưng cất giảm khoảng cách tổng quát hóa so với phương pháp tiền huấn luyện thêm. Ngoài ra, chúng tôi báo cáo riêng hàm mất mát huấn luyện và kiểm tra trong Bảng 4. Cả tiền huấn luyện thêm và tự chưng cất đều đạt được hàm mất mát huấn luyện gần bằng không, nhưng tự chưng cất đạt được hàm mất mát kiểm tra thấp hơn nhiều so với tiền huấn luyện thêm như một hệ quả của điều hòa được gây ra bởi tự chưng cất.

Bảng 6: Giảm trọng số của mục tiêu MAE.
λ CUB
1.0 58.06±0.90
0.5 57.76±0.17
0.3 58.21±0.42
0.1 57.76±0.33Giảm Trọng Số của Mã Hóa Tự Động Có Mặt Nạ Mặc dù chúng tôi cố định cả trọng số của tự chưng cất và mục tiêu mã hóa tự động có mặt nạ bằng 1 trong phương trình 3, chúng tôi thay đổi λ∈(0,1], trọng số của mục tiêu mã hóa tự động có mặt nạ (λLMAE(θ, ϕ;Du) +LDistill (θ;θ0,Du)) và báo cáo độ chính xác kiểm tra của Vision Transformer với tự chưng cất trên tập dữ liệu CUB. Như được hiển thị trong Bảng 6, phương pháp đề xuất của chúng tôi không nhạy cảm với giá trị của λ và do đó không có lợi ích gì khi tinh chỉnh trọng số của mục tiêu mã hóa tự động có mặt nạ.

Thời Gian Huấn Luyện Bổ Sung Để phân tích tốt hơn chi phí tính toán bổ sung cho tiền huấn luyện thêm và tự chưng cất, chúng tôi báo cáo thời gian wall clock huấn luyện cho tinh chỉnh, tiền huấn luyện thêm, và tự chưng cất, tương ứng. Chúng tôi huấn luyện một Vision Transformer (Dosovitskiy et al., 2021) trên tập dữ liệu CUB với GPU 3090 RTX và CPU Intel(R) Xeon(R) Silver 4210R. Phải mất 32 phút 18 giây để tinh chỉnh transformer. Chúng ta cần thêm 1 giờ 29 phút 33 giây cho tiền huấn luyện thêm và 5 giờ 13 phút 22 giây cho tự chưng cất.

C MÃ HÓA TỰ ĐỘNG CÓ MẶT NẠ

Trong phần này, chúng tôi mô tả mục tiêu mã hóa tự động có mặt nạ từ phương trình 2 chi tiết hơn. Cho một chuỗi x= (x1, . . . , x K) với độ dài K, chúng ta lấy mẫu mặt nạ z= (z1, . . . , z K) từ một phân phối Binomial pγ,K với xác suất thành công γ∈(0,1) và số lần thử K. Với mỗi xk, chúng ta thay thế nó bằng token đặc biệt "mask" nếu zk= 1. Ngược lại chúng ta sử dụng cùng xk cho một đầu vào có mặt nạ. Cho ˆx= (ˆx1, . . . , ˆxK) là một đầu vào có mặt nạ và cho fθ, gϕ lần lượt là bộ mã hóa và bộ giải mã. Chúng ta muốn tính toán log-likelihood của đầu vào được tái tạo PK k=1zklogpθ,ϕ(xk|ˆx).

Đối với các mô hình ngôn ngữ, việc tái tạo đầu vào có mặt nạ ˆxk là dự đoán token nào được che dấu trong từ vựng được định nghĩa trước có kích thước V, nơi mỗi token được biểu diễn như một số nguyên từ {1, . . . , V }. Do đó xác suất có điều kiện của xk∈ {1, . . . , V } cho ˆx được tham số hóa như sau:

19

--- TRANG 19 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

pθ,ϕ(xk|ˆx) =exp(uxk)) PV j=1exp(uj)

nơi (u1, . . . , u V) =gϕ(hk)∈RV,"| | h1···hK | |# =fθ(ˆx)∈Rh×K.

Đối với ViT, chuỗi x bao gồm các patch hình ảnh và việc tái tạo đầu vào có mặt nạ là dự đoán giá trị pixel cho mỗi patch bị che dấu, đây là một bài toán hồi quy. Do đó, chúng ta tham số hóa xác suất có điều kiện của một patch xk= (xk,1, . . . , x k,m)∈Rm cho ˆx như sau:

pθ,ϕ(xk|ˆx) =mY i=11√ 2πσ2exp −(xk,i−µk,i)2 2σ2

nơi µk= (µk,1, . . . , µ k,m)∈Rm,"| | µ1···µK | |# =fθ(ˆx)∈Rm×K.

Vì σ >0 và π là các hằng số đối với θ và ϕ,

arg min θ,ϕ−KX k=1logpθ,ϕ(xk|ˆx) = arg min θ,ϕKX k=1 1 2σ2mX j=1(xk,j−µk,j)2−mlog1√ 2πσ2 

= arg min θ,ϕKX k=1 mX j=1(xk,j−µk,j)2 

= arg min θ,ϕKX k=1∥xk−µk∥2 2.

D TẬP DỮ LIỆU

Chúng tôi mô tả thống kê của tất cả các tập dữ liệu phân loại hình ảnh và văn bản được sử dụng cho các thí nghiệm của chúng tôi trong Bảng 7 và 8.

Bảng 7: Số lượng thể hiện huấn luyện và lớp cho mỗi tập dữ liệu phân loại hình ảnh.
Aircraft CUB Chest X-ray DTD Dogs Flower
# thể hiện 6,667 5,594 5,216 4,230 12,000 2,040
# lớp 100 200 2 47 120 102

Bảng 8: Số lượng thể hiện huấn luyện và lớp cho mỗi tập dữ liệu phân loại văn bản.
SCIERC ACL-ARC Chemprot Twitter-Emotion
# thể hiện 3,219 1,688 4,169 4,230
# lớp 7 6 13 47

20

--- TRANG 20 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023

E SIÊU THAM SỐ

Trong Bảng 9, chúng tôi tóm tắt tất cả các siêu tham số cho Vision Transformer và RoBERTA.

Bảng 9: Siêu tham số cho Vision Transformer và RoBERTA
Siêu tham số Vision Transformer RoBERTA
tỷ lệ học cho tiền huấn luyện 1.5·10−41·10−4
tỷ lệ học cho tinh chỉnh 1·10−42·10−5
hệ số weight decay 1·10−21·10−2
kích thước batch cho tiền huấn luyện 64 128
kích thước batch cho tinh chỉnh 32 16
bộ lập lịch tỷ lệ học linear-decay linear-decay
bước tinh chỉnh 10,000 10 epoch
bước tiền huấn luyện 20,000 100 epoch
vòng tự chưng cất 1 1

21

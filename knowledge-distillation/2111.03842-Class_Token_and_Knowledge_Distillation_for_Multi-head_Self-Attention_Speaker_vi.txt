# Class Token và Knowledge Distillation cho Hệ thống Xác thực Người nói Multi-head Self-Attention

Victoria Mingote, Antonio Miguel, Alfonso Ortega, Eduardo Lleida
ViVoLab, Viện Nghiên cứu Kỹ thuật Aragon (I3A), Đại học Zaragoza, Tây Ban Nha.
{vmingote,amiguel,ortega,lleida}@unizar.es

## Tóm tắt

Bài báo này khám phá ba phương pháp mới để cải thiện hiệu suất của các hệ thống xác thực người nói (SV) dựa trên mạng nơ-ron sâu (DNN) sử dụng cơ chế Multi-head Self-Attention (MSA) và các lớp bộ nhớ. Đầu tiên, chúng tôi đề xuất sử dụng một vector có thể học được gọi là Class token để thay thế cơ chế global average pooling nhằm trích xuất embeddings. Không giống như global average pooling, đề xuất của chúng tôi tính đến cấu trúc thời gian của đầu vào - điều này có liên quan đến nhiệm vụ SV phụ thuộc văn bản. Class token được nối vào đầu vào trước lớp MSA đầu tiên, và trạng thái tại đầu ra được sử dụng để dự đoán các lớp. Để có thêm tính mạnh mẽ, chúng tôi giới thiệu hai phương pháp. Đầu tiên, chúng tôi đã phát triển một ước lượng lấy mẫu mới của class token. Trong phương pháp này, class token được thu được bằng cách lấy mẫu từ một danh sách gồm nhiều vector có thể huấn luyện. Chiến lược này đưa vào sự không chắc chắn giúp tổng quát hóa tốt hơn so với một khởi tạo duy nhất như được thể hiện trong các thí nghiệm. Thứ hai, chúng tôi đã thêm một distilled representation token để huấn luyện một cặp mạng teacher-student sử dụng triết lý Knowledge Distillation (KD), được kết hợp với class token. Distillation token này được huấn luyện để bắt chước các dự đoán từ mạng teacher, trong khi class token nhân bản nhãn thật. Tất cả các chiến lược đã được thử nghiệm trên cơ sở dữ liệu RSR2015-Part II và DeepMine-Part 1 cho SV phụ thuộc văn bản, cung cấp kết quả cạnh tranh so với cùng kiến trúc sử dụng cơ chế average pooling để trích xuất average embeddings.

**Từ khóa:** Class Token, Teacher-Student Learning, Distillation Token, Xác thực Người nói, Multi-head Self-Attention, Memory Layers

## 1. Giới thiệu

Hiệu suất trong các nhiệm vụ xác thực người nói (SV) đã được cải thiện đáng kể trong những năm gần đây nhờ vào các tiến bộ deep learning (DL) trong biểu diễn tín hiệu và các metric tối ưu hóa [1, 2, 3, 4, 5] đã được điều chỉnh từ các hệ thống xác thực khuôn mặt, nhận dạng hình ảnh, hoặc mô hình hóa văn bản tiên tiến. Trong các hệ thống này, Convolutional Neural Network (CNN) hoặc Time Delay Neural Network (TDNN) [2] vẫn là những phương pháp được sử dụng nhiều nhất để thu được biểu diễn tín hiệu hoặc embeddings. Tuy nhiên, các cơ chế self-attention đang trở thành phương pháp chủ đạo trong nhiều lĩnh vực ngoài các nhiệm vụ liên quan đến văn bản. Ví dụ, Transformers [6] đang lan rộng đến nhiều nhiệm vụ [7, 8, 9, 10] nơi có sẵn các cơ sở dữ liệu quy mô lớn. Trong các nhiệm vụ SV, loại kiến trúc này đã bắt đầu được áp dụng thành công trong SV độc lập văn bản [11, 12, 13, 14] nơi không có ràng buộc trong cụm từ được phát âm và các cơ sở dữ liệu lớn có sẵn. Tuy nhiên, trong SV phụ thuộc văn bản, vẫn còn chỗ để cải thiện vì lượng dữ liệu công khai không quá lớn. Bên cạnh đó, SV phụ thuộc văn bản bao gồm việc quyết định xem một mẫu giọng nói đã được phát âm bởi người nói đúng có phát âm cụm từ mật khẩu cố định đã chọn hay không. Vì vậy, thông tin ngữ âm của tín hiệu có liên quan để xác định danh tính. Do đó, việc giữ cấu trúc thời gian là cần thiết để thu được các biểu diễn mã hóa chính xác cả thông tin cụm từ và người nói.

Trong bối cảnh các nhiệm vụ SV phụ thuộc văn bản, các công trình trước đây của chúng tôi [15, 16, 17] đã chỉ ra những ưu điểm của việc thay thế cơ chế pooling truyền thống dựa trên việc tính trung bình thông tin thời gian bằng một cơ chế căn chỉnh bên ngoài để thu được một supervector embedding. Supervector này cho phép giữ cấu trúc thời gian và biểu diễn cả thông tin cụm từ và người nói, nhưng việc căn chỉnh thời gian phải được thực hiện bằng cách sử dụng một phương pháp bên ngoài như phone decoder, Gaussian Mixture Model (GMM) [18, 19] hoặc Hidden Markov Model (HMM) [20]. Như một phương pháp thay thế, trong [21], chúng tôi đã giới thiệu các cơ chế Multi-head Self-Attention (MSA) [6] kết hợp với các lớp bộ nhớ [22] để thay thế các cơ chế căn chỉnh. Việc sử dụng MSA cho phép mô hình tập trung vào các khung hình có liên quan nhất của chuỗi để phân biệt tốt hơn giữa các phát âm và người nói. Tuy nhiên, kiến trúc được đề xuất dựa trên MSA đã sử dụng một cơ chế average pooling để thu được embedding biểu diễn cuối cùng.

Trong công trình này, để thay thế global average pooling, chúng tôi đã giới thiệu một vector có thể học được được biết đến là Class token, được kế thừa từ Natural Language Processing (NLP) [7], và gần đây, nhiều hệ thống nhận dạng hình ảnh [8]. Tuy nhiên, phương pháp này vẫn chưa được áp dụng cho các nhiệm vụ SV. Để đưa vector này vào hệ thống dựa trên DNN với MSA và các lớp bộ nhớ, class token được nối vào đầu vào trước lớp MSA đầu tiên, và trạng thái tại đầu ra được sử dụng để thực hiện dự đoán lớp. Trong quá trình huấn luyện, thông tin thời gian được mã hóa trong token, và token này tương tác với toàn bộ chuỗi đầu vào thông qua self-attention và học một mô tả toàn cục tương tự như phương pháp supervector [16, 23] vì các multiple heads hoạt động như các slots của supervector. Một cơ chế tương tự cũng đã được sử dụng gần đây trong [10]. Do đó, cơ chế average pooling không cần thiết để thu được một biểu diễn. Các multiple heads có thể mã hóa nhiều chi tiết hơn về thứ tự chuỗi so với average, đóng vai trò của các trạng thái và cải thiện kết quả như được thể hiện trong [16],[17] với việc sử dụng các cơ chế căn chỉnh bên ngoài dựa trên HMM và GMM. Ngoài ra, thông tin được mã hóa trong các multiple heads này có thể được biểu diễn và phân tích, điều này cải thiện khả năng diễn giải kết quả của loại phương pháp này.

Để cải thiện hiệu suất thu được với phương pháp class token, chúng tôi cũng giới thiệu một cơ chế lấy mẫu khởi tạo đa dạng mới để giảm các vấn đề khởi tạo có thể xảy ra và mang lại tính mạnh mẽ hơn trước việc thiếu dữ liệu để mô hình hóa các dự đoán. Vì đây là một trường hợp sử dụng trong ngành để phát triển các hệ thống cụ thể tùy chỉnh với các tập dữ liệu in-domain nhỏ và loại phương pháp này có thể là một giải pháp khả thi.

Hơn nữa, công trình này đóng góp với một phương pháp khác dựa trên kiến trúc Transformer và Knowledge Distillation (KD) [24, 9]. Chúng tôi đề xuất một phương pháp teacher-student kết hợp với data augmentation Random Erasing [25, 26] cho phép mô hình hóa sự không chắc chắn trong các tham số của mô hình teacher với một mô hình student nhỏ gọn và có được các dự đoán đáng tin cậy hơn. Theo ý tưởng được đề xuất trong [9], chúng tôi cũng đã giới thiệu Distillation token trong mạng student để nhân bản các dự đoán của mạng teacher, trong khi class token được huấn luyện để tái tạo nhãn thật như Hình 3 mô tả. Không giống như mục tiêu trong [9], trong công trình của chúng tôi, quá trình distillation không nhằm mục đích nén mô hình teacher, mà cả hai mô hình đều được huấn luyện cùng nhau và mô hình student học để nắm bắt tốt hơn tính biến thiên bên trong của các dự đoán teacher.

Tóm lại, những đóng góp chính là:

- Chúng tôi thay thế cơ chế global average pooling bằng một class token có thể học được để thu được một bộ mô tả phát âm toàn cục được liên kết với khái niệm supervector trong xác thực người nói.

- Chúng tôi đề xuất một phương pháp mới dựa trên xấp xỉ lấy mẫu để ước lượng class token.

- Chúng tôi giới thiệu một kiến trúc teacher-student với một token bổ sung được gọi là distillation token được kết hợp với class token để cung cấp tính mạnh mẽ cho mô hình student đã học.

Bài báo này được tổ chức như sau. Trong Phần 2, chúng tôi trình bày tổng quan về MSA và các lớp bộ nhớ. Phần 3 giải thích chiến lược giới thiệu một class token có thể học được sử dụng lấy mẫu. Trong Phần 4, chúng tôi giới thiệu phương pháp dựa trên KD kết hợp với các token được sử dụng để phát triển hệ thống của chúng tôi. Phần 5 mô tả hệ thống được sử dụng. Trong Phần 6, chúng tôi trình bày dữ liệu thực nghiệm, và Phần 7 giải thích các kết quả đạt được. Kết luận được trình bày trong Phần 8.

## 2. Tổng quan về Transformer Encoder

Kiến trúc transformer gốc [6] bao gồm hai phần chính: phần encoder và decoder. Tuy nhiên, trong nhiều nhiệm vụ, transformer encoder là phần duy nhất được sử dụng để tạo các hệ thống DL. Cơ chế cốt lõi của mỗi khối encoder là lớp Multi-head Self-Attention (MSA) bao gồm nhiều dot-product attention. Vì chúng tôi chỉ sử dụng phần encoder, đầu vào cho cơ chế attention này là giống nhau cho các tín hiệu query, key và value (Q;K;V):

Q_h = xW^Q_h; K_h = xW^K_h; V_h = xW^V_h;                (1)

trong đó x là đầu vào cho lớp này, và W^Q_h; W^K_h; W^V_h là các ma trận trọng số có thể học được để thực hiện các phép chiếu tuyến tính. Sau các phép chiếu này, một thao tác softmax được thực hiện trên trục thời gian, cho phép mỗi head tập trung vào các khung hình nhất định của chuỗi đầu vào. Kết quả của thao tác softmax này được gọi là ma trận self-attention cho mỗi head và có thể được định nghĩa là:

A_h = softmax_t (Q_h K_h^T / √d_k);                      (2)

trong đó d_k là số chiều của vector query/key, và T biểu thị chuyển vị. Ma trận self-attention này học thông tin có liên quan nhất giữa các dữ liệu khác nhau. Sử dụng thông tin này, các vector đặc trưng value V được tổng hợp để thu được đầu ra của mỗi head. Đầu ra cuối cùng của mỗi head có thể được tính như sau:

H_h = A_h V_h.                                           (3)

Do đó, MSA được định nghĩa là sự nối của các đầu ra từ mỗi head H_h:

MSA(X) = [H_1; H_2; ...; H_d_head]W^head;               (4)

trong đó X là đầu vào cho lớp attention, W^head là một ma trận trọng số có thể học được để thực hiện một phép chiếu tuyến tính cuối cùng, và d_head là số lượng attention heads trong lớp thứ h.

Transformer encoder xen kẽ lớp MSA với lớp thứ hai là lớp feed-forward (FF). Tuy nhiên, trong [21], chúng tôi đã đề xuất thay thế các lớp FF bằng các lớp bộ nhớ như trong [22]. Với lớp này, dữ liệu đầu vào được so sánh với tất cả các keys sử dụng product key-attention, và các điểm số thu được được sử dụng để chọn các keys gần nhất, có điểm số cao nhất. Sau đó, các vector trọng số liên kết được tính với biểu thức sau:

w = softmax_n(xU^K);                                     (5)

trong đó x là đầu vào cho lớp, U^K là ma trận keys, và softmax được tính trên trục chỉ số bộ nhớ để tập trung vào nội dung nhất định của bộ nhớ sẽ được sử dụng để cung cấp đầu ra. Khi các vector này được thu thập, các trọng số này được kết hợp với các giá trị bộ nhớ của các keys đã chọn, và đầu ra được nối với đầu ra attention trước đó:

x_out = x + wU^V;                                        (6)

trong đó w là trọng số của các keys đã chọn thu được với (5), và U^V là các giá trị bộ nhớ liên kết với các keys. Sau khi các khối encoder được áp dụng, một cơ chế average pooling thường được sử dụng để giảm thông tin thời gian và biểu diễn các phát âm có độ dài biến đổi với các vector có độ dài cố định. Tuy nhiên, việc tính trung bình này có thể bỏ qua thứ tự của thông tin ngữ âm, điều này có liên quan đến các nhiệm vụ SV phụ thuộc văn bản.

## 3. Biểu diễn sử dụng Class Token

Trong nhiều nhiệm vụ của NLP và computer vision, kiến trúc transformer sử dụng một vector có thể học được gọi là Class Token (x_CLS), như trong mô hình BERT gốc [7] hoặc Vision Transformer (ViT) [8], thay vì global average pooling. Để sử dụng token này trong transformer encoder, vector được nối vào đầu vào của lớp MSA đầu tiên để thực hiện nhiệm vụ phân loại. Với token này, self-attention bị buộc phải nắm bắt thông tin có liên quan nhất với class token để thu được một biểu diễn như một bộ mô tả phát âm toàn cục tương tự như phương pháp supervector. Thay vì trộn tất cả thông tin với một cơ chế average pooling, cấu trúc thời gian có thể được giữ vì cơ chế attention hoạt động như một tổng có trọng số của các token thời gian cho mỗi lớp. Vector đầu ra là sự nối của các subvector head khác nhau và mỗi subvector đó là kết quả của một kết quả attention khác nhau. Do đó, cơ chế có thể được xem tương tự như những cơ chế được sử dụng trong công trình trước đây của chúng tôi [16], nơi các heads đóng vai trò của các trạng thái và supervector trong [23]. Cơ chế supervector cũng tương tự như [27] nhưng trong trường hợp đó, nhiệm vụ là SV độc lập văn bản và các lớp MSA không được sử dụng. Bên cạnh đó, loại cơ chế này cho phép tăng cường khả năng diễn giải những gì mạng nơ-ron học thông qua các lớp self-attention.

Trong [23], cơ chế để thu được supervector này được định nghĩa tương tự như một supervector GMM thông thường với biểu thức sau:

s_c = (Σ_t x_t w_tc) / (Σ_t w_tc) = Σ_t x_t w̄_tc;      (7)

trong đó w_tc là các trọng số thu được bằng một hàm softmax trên đầu ra của một lớp có thể học được, s_c là các vector trên mỗi trạng thái/thành phần C có chiều D tóm tắt thông tin liên kết dọc theo chuỗi các vector đặc trưng x_t có chiều D, và w̄_tc là các trọng số chuẩn hóa được định nghĩa là w_tc/Σ_t w_tc. Supervector cuối cùng được xây dựng bằng cách nối các vector này S = {s_1; ...; s_C} và được sử dụng để biểu diễn toàn bộ chuỗi. Trong công trình này, các vector đặc trưng đầu ra cho mỗi head H của lớp MSA được thu thập với (3) như một tổng có trọng số tương đương với (7), trong đó w̄_tc tương ứng với các hàng của ma trận trọng số self-attention A_h thu được với (2). Cụ thể, đối với class token, các trọng số chuẩn hóa sẽ được thu từ hàng cuối cùng của A_h. Do đó, class token cuối cùng thu được với cơ chế này là sự nối của các subvector head khác nhau tương ứng với vị trí class token, có thể được biểu thị như supervector được trình bày trước đây S_CLS = {s^1_CLS; ...; s^H_CLS}.

Để đưa class token vào hệ thống, một tham số vector có thể huấn luyện với chiều của các vector đặc trưng được định nghĩa khi mạng được khởi tạo. Đối với mỗi batch, nó được nhân bản và nối vào cuối mỗi chuỗi đặc trưng đầu vào trong batch huấn luyện như một token bổ sung. Do đó, một vector chia sẻ duy nhất được huấn luyện để học biểu diễn embedding cuối cùng.

Trong công trình này, chúng tôi đề xuất sử dụng một phương pháp lấy mẫu mới [28], và thay vì có một class token duy nhất được chia sẻ cho toàn bộ batch, chúng tôi giả định tham số nhạy cảm này là kết quả của việc lấy mẫu một danh sách gồm nhiều vector để được chọn trong quá trình huấn luyện bằng cách lấy mẫu chúng. Để thực hiện điều đó, chúng tôi định nghĩa một ma trận gồm R vector (Token Matrix) và lấy mẫu nó để lấy một trong số chúng cho mỗi ví dụ trong batch đưa vào sự không chắc chắn trong class token (CLS Token). Tuy nhiên, việc sử dụng phương pháp này dẫn đến một quá trình đánh giá phức tạp và chậm hơn vì một suy luận lấy mẫu sẽ phải được thực hiện để thu được các biểu diễn. Vì lý do này, để tránh việc thực hiện suy luận lấy mẫu, chúng tôi đã lên lịch một việc giảm bắt buộc các vector có sẵn trong Token Matrix trong suốt quá trình huấn luyện. Do đó, ở cuối quá trình này, chỉ có một trọng số khác với số không, và tham số vector class token được cố định. Chiến lược này cho phép chúng tôi bắt đầu huấn luyện (Iteration 1) với một ma trận gồm nhiều vector để lấy mẫu từ đó và, dần dần, chúng tôi giảm số lượng vector khi quá trình huấn luyện tiến triển để kết thúc (Iteration N) chỉ với một vector như class token gốc như Hình 1 mô tả. Do đó, quá trình huấn luyện dẫn hệ thống dần dần tập trung thông tin có liên quan vào vector đầu tiên của ma trận. Ngoài ra, sử dụng phương pháp lấy mẫu này, hệ thống được huấn luyện để nắm bắt sự không chắc chắn được đưa vào ban đầu bằng việc có một Token Matrix với R vector để kết hợp với dữ liệu batch huấn luyện. Do đó, mỗi ví dụ từ batch được kết hợp với một vector ngẫu nhiên từ ma trận được giảm kích thước sau mỗi epoch cho đến khi chỉ còn lại một vector ở cuối, vì vậy tính biến thiên nhiều hơn phải được mô hình hóa điều này giúp cải thiện tính mạnh mẽ của hệ thống.

Để thực hiện quá trình này, chúng tôi định nghĩa vector sau, cho biết với mạng nơ-ron số lượng token có sẵn tại mỗi iteration của quá trình huấn luyện:

α = (α_1; ...; α_n; ...; α_N); α_n = R; ...; 1; với R ∈ ℝ     (8)

trong đó R là số lượng token được định nghĩa trong ma trận, và N là tổng số iteration cho quá trình huấn luyện. Trong số các token có sẵn tại mỗi iteration, một lựa chọn ngẫu nhiên của kích thước batch được thực hiện để chọn chỉ số của các vector. Các vector này được chọn từ phân phối (Token Matrix) và được sử dụng như class token (CLS Token) trong batch để nối vào đầu vào của lớp MSA đầu tiên. Quá trình tổng thể được mô tả trong Thuật toán 1. Bên cạnh đó, Hình 2 cho thấy một ví dụ đồ họa về cách quá trình lấy mẫu này được thực hiện trong một iteration trung gian (Iteration n). Trong giải thích đồ họa này, có thể quan sát thấy cách trong một iteration trung gian số lượng vector đã được giảm buộc mạng phải đặt thông tin có liên quan để biểu diễn các phát âm trong các vector vẫn có sẵn.

## 4. Knowledge Distillation với Tokens

Được thúc đẩy bởi những lợi ích thu được khi các cơ sở dữ liệu huấn luyện không quá lớn với kiến trúc Teacher-Student dựa trên CNN [26], chúng tôi đã triển khai kiến trúc này sử dụng hai mạng transformer như Hình 3 mô tả. Sử dụng phương pháp Bayesian tương tự như [29], kiến trúc teacher-student cho phép cung cấp tính mạnh mẽ cho hệ thống. Trong phương pháp này, các mạng teacher và student được huấn luyện cùng lúc, không giống như các công trình trước đây [30, 31] trong đó mạng teacher thường là một mô hình được huấn luyện trước để giảm độ phức tạp. Nếu mạng teacher là một mô hình đóng băng, các ví dụ huấn luyện tiêu cực thu được giá trị posterior cao trong mạng teacher sẽ được học như các ví dụ tích cực bởi mạng student. Bên cạnh đó, các nguồn biến dạng khác nhau được áp dụng cho mỗi tín hiệu đầu vào của cả hai mạng, vì vậy chúng tôi đã sử dụng một phương pháp data augmentation gọi là Random Erasing (RE) [25] để cung cấp tính biến thiên nhiều hơn cho dữ liệu huấn luyện đầu vào. Với loại kiến trúc này, mạng teacher phải dự đoán dữ liệu được tăng cường chưa thấy và mạng student cố gắng bắt chước các dự đoán nhãn được tạo ra bởi mạng teacher sử dụng đầu ra class token. Chiến lược huấn luyện này cho phép mạng student nắm bắt tính biến thiên trong các dự đoán được tạo ra bởi mạng đầu tiên và mô hình hóa sự không chắc chắn này trong các tham số trong quá trình huấn luyện. Tuy nhiên, được truyền cảm hứng bởi [9], chúng tôi cũng đã bao gồm một token có thể học được bổ sung trong mạng student được gọi là Distillation Token (Distill Token). Việc giới thiệu token bổ sung này cho phép triển khai tối ưu hóa đa mục tiêu bằng cách sử dụng class token để tái tạo nhãn thật trong khi distillation token được huấn luyện để bắt chước các dự đoán của mạng teacher. Để đạt được điều này, hàm mất mát Kullback-Leibler Divergence (KLD) giữa các phân phối student và teacher được tối thiểu hóa. Hàm mất mát KLD có thể được công thức hóa như sau:

KLD = Σ^I_{i=1} Σ^J_{j=1} p_T(y^cls_i|x_j) log(p_S(y^dist_i|x_j)) + const;     (9)

trong đó i và j là các chỉ số người nói và phát âm, x_j là tín hiệu đầu vào, p_T(y^cls_i|x_j) là xác suất posterior đầu ra của nhãn y^cls_i từ class token của mô hình teacher, p_S(y^dist_i|x_j) là xác suất posterior đầu ra của nhãn y^dist_i từ distillation token của mạng student cho cùng một ví dụ, và const được định nghĩa trong [29]. Do đó, để huấn luyện kiến trúc teacher-student được hiển thị trong Hình 3, chúng tôi sử dụng hai biểu thức hàm mất mát sau cho các mạng teacher và student:

Loss_T = CE(y^cls_T; y);                                    (10)
Loss_S = KLD(y^dist_S; y^cls_T) + CE(y^cls_S; y);         (11)

trong đó CE là hàm mất mát cross-entropy, y^cls_S là đầu ra class token từ mạng student, và y là các nhãn ground truth.

## 5. Mô tả Hệ thống

Trong phần này, chúng tôi mô tả kiến trúc hệ thống được sử dụng trong công trình này cho SV phụ thuộc văn bản. Hình 3 mô tả kiến trúc này nơi một phương pháp teacher-student được sử dụng. Cả hai kiến trúc đều theo cấu trúc được mô tả trong [21] với cùng các phần backbone và pooling. Backbone dựa trên hai khối Residual Network (RN) [32] với ba lớp mỗi khối. Ngoài ra, các kiến trúc này cần embedding với thông tin vị trí để giúp hướng dẫn attention mask trong các lớp MSA. Trong công trình này, các embedding này (e_ph) được trích xuất bởi một mạng phân loại ngữ âm thay vì sử dụng thông tin vị trí thời gian [27]. Đối với phần pooling, hai lớp MSA của 16 head kết hợp với hai lớp bộ nhớ được sử dụng. Hơn nữa, trước lớp MSA đầu tiên, class token được nối vào đầu vào. Trong trường hợp mạng student, distillation token cũng được bao gồm. Nhờ vào cơ chế self-attention, các token này học để thu được một biểu diễn toàn cục cho mỗi phát âm mà không áp dụng global average pooling. Các biểu diễn này, tương tự như supervector, thuận tiện hơn cho nhiệm vụ SV phụ thuộc văn bản vì các biểu diễn toàn cục này không bỏ qua thứ tự chuỗi và được thu thập tự động nhờ vào cơ chế self-attention. Vì vậy các cơ chế căn chỉnh bên ngoài không cần thiết để thu được chúng như trong [15, 16, 17], nơi các xác suất posterior GMM hoặc HMM cần thiết để căn chỉnh các khung hình giọng nói với supervector. Bên cạnh đó, việc sử dụng các lớp bộ nhớ tăng lượng kiến thức thu được bởi mạng có thể được lưu trữ. Sau khi huấn luyện hệ thống, một cosine similarity trên các biểu diễn token được áp dụng để thực hiện quá trình xác thực. Lưu ý rằng loại hệ thống này dựa trên teacher-student bao gồm việc huấn luyện hai kiến trúc cùng một lúc. Do đó, quá trình này có thể liên quan đến chi phí tính toán cao hơn. Tuy nhiên, trong quá trình suy luận, chỉ mạng student được sử dụng để trích xuất embedding, vì vậy không có thời gian suy luận bổ sung.

## 6. Thiết lập Thí nghiệm

### 6.1. Tập dữ liệu

Đối với các thí nghiệm, hai tập dữ liệu xác thực người nói phụ thuộc văn bản đã được sử dụng. Tập thí nghiệm đầu tiên đã được báo cáo trên tập dữ liệu xác thực người nói phụ thuộc văn bản RSR2015 [33]. Tập dữ liệu này bao gồm các bản ghi âm từ 157 nam và 143 nữ. Đối với mỗi người nói, có 9 phiên với 30 cụm từ khác nhau. Dữ liệu này được chia thành ba tập con người nói: background (bkg), development (dev) và evaluation (eval). Trong bài báo này, chúng tôi phát triển các thí nghiệm với Part II, bao gồm lệnh điều khiển ngắn với sự chồng chéo mạnh về nội dung từ vựng, và chúng tôi chỉ sử dụng dữ liệu bkg để huấn luyện. Phần eval được sử dụng để đăng ký và đánh giá thử nghiệm. Tập dữ liệu này có ba điều kiện đánh giá, nhưng trong công trình này, điều kiện thách thức nhất, là trường hợp Impostor-Correct, là điều kiện duy nhất đã được đánh giá và sử dụng trong SV phụ thuộc văn bản. Lưu ý rằng có các hệ thống khác thu được kết quả có liên quan cho tập dữ liệu này, tương tự như những kết quả được trình bày dưới đây. Tuy nhiên, các hệ thống như vậy dựa trên các mô hình truyền thống như Hidden Markov Models (HMMs) [33, 34] hoặc các kiến trúc mạng nơ-ron tập trung vào hai luồng khác nhau cho thông tin người nói và phát âm [35, 36].

Tập dữ liệu thứ hai được sử dụng là cơ sở dữ liệu DeepMine [37]. Corpus này bao gồm ba phần khác nhau trong đó chúng tôi sử dụng các tệp được chọn cho Short-duration Speaker Verification (SdSV) Challenge 2020 [38] từ Part 1. Part 1 là phần phụ thuộc văn bản bao gồm 5 cụm từ tiếng Ba Tư và 5 cụm từ tiếng Anh và chứa 963 người nói nam và nữ. Dữ liệu này được chia thành hai tập con: train với 101.063 tệp âm thanh và evaluation với 69.542 tệp âm thanh. Cuối cùng, mạng phân loại ngữ âm [27] đã được huấn luyện sử dụng LibriSpeech [39] để trích xuất embedding ngữ âm. Không giống như các công trình khác được trình bày trong thách thức [40, 41], chúng tôi không sử dụng các tập dữ liệu VoxCeleb 1 và 2 [42, 43] trong quá trình huấn luyện mạng nơ-ron. Được thúc đẩy bởi thực tế rằng trong một số tình huống và ứng dụng cần thiết việc triển khai các hệ thống tùy chỉnh với ít dữ liệu in-domain có sẵn. Vì lý do này, chúng tôi đã phát triển các hệ thống chỉ với dữ liệu in-domain.

### 6.2. Mô tả Thí nghiệm

Để thực hiện các thí nghiệm với tập dữ liệu RSR2015, một tập các đặc trưng bao gồm 20 chiều Mel-Frequency Cepstral Coefficients (MFCC) với các đạo hàm của chúng được sử dụng làm đầu vào. Trong khi đối với các thí nghiệm sử dụng tập dữ liệu DeepMine, chúng tôi đã sử dụng một vector đặc trưng dựa trên mel-scale filter banks. Với bộ trích xuất đặc trưng này, chúng tôi thu được hai log filter banks có kích thước 24 và 32, được nối với log energy để thu được chiều đầu vào cuối cùng là 57. Hơn nữa, embedding ngữ âm 256 chiều đã được sử dụng như thông tin vị trí. Như bộ tối ưu hóa cho các thí nghiệm trong công trình này, bộ tối ưu hóa Adam được sử dụng với tốc độ học tăng từ 10^-3 đến 5×10^-3 trong 60 epoch và sau đó giảm từ 5×10^-3 đến 10^-4. Ngoài ra, dữ liệu huấn luyện được đưa vào các hệ thống với kích thước minibatch là 32.

## 7. Kết quả

Trong bài báo này, hai tập thí nghiệm đã được thực hiện để đánh giá các đề xuất với cả hai cơ sở dữ liệu. Chúng tôi so sánh các phương pháp khác nhau để thu được các biểu diễn với một mạng nơ-ron duy nhất sử dụng cùng kiến trúc như mạng teacher: việc sử dụng global average pooling truyền thống (AVG), attentive pooling (ATT) và việc giới thiệu class token có thể học được (CLS). Đối với phương pháp class token, chúng tôi đánh giá đề xuất của chúng tôi về việc lấy mẫu một ma trận gồm R vector và giảm nó cho đến khi có một vector duy nhất (Sampling). Tham số này cũng được quét cho các giá trị khác nhau của R, bao gồm R=1 tương ứng với ý tưởng ban đầu về việc có một token duy nhất và lặp lại nó. Hơn nữa, chúng tôi phân tích hiệu ứng được tạo ra bởi thực tế sử dụng một kiến trúc teacher-student với một distillation token bổ sung (CLS_DIST).

Để đánh giá các thí nghiệm này, chúng tôi đã đo hiệu suất sử dụng ba metric. Equal Error Rate (EER) đo khả năng phân biệt của hệ thống. NIST 2008 và 2010 minimum Detection Cost Functions (DCF08, DCF10) [44, 45] đo chi phí của các lỗi phát hiện theo tổng có trọng số của xác suất báo động giả và miss cho một ngưỡng quyết định, và xác suất tiên nghiệm.

### 7.1. Nghiên cứu Class Token

Một tập thí nghiệm đầu tiên đã được thực hiện để so sánh việc sử dụng class token để thu được các bộ mô tả phát âm toàn cục với việc sử dụng phương pháp global average pooling hoặc attentive pooling được đề xuất trong [46]. Do đó, chúng tôi nghiên cứu hai phương pháp để giới thiệu vector này được giải thích trong công trình này và hiệu ứng của số lượng vector được chọn cho phương pháp lấy mẫu.

Bảng 1 trình bày kết quả EER, DCF08 và DCF10 cho các thí nghiệm với tập dữ liệu RSR2015-part II. Bất kể số lượng vector trong việc lấy mẫu cho class token, nếu chúng tôi áp dụng chiến lược đề xuất của chúng tôi để giới thiệu các token với một phương án lấy mẫu, hiệu suất thu được sẽ tốt hơn. Ngoài ra, kết quả cho thấy cách sử dụng một token có thể học được vượt trội so với việc sử dụng average embedding hoặc attentive pooling embedding. Lưu ý rằng token được huấn luyện thông qua self-attention và giữ cấu trúc thời gian để thu được một biểu diễn phát âm toàn cục, trong khi average embedding bỏ qua thông tin này có liên quan đến nhiệm vụ SV. Như chúng ta cũng có thể quan sát với việc quét giá trị R, việc sử dụng nhiều vector để tạo token matrix tốt hơn so với việc sử dụng một vector duy nhất và lặp lại nó cho toàn bộ batch, tương ứng với cách ban đầu của việc áp dụng phương pháp này. Trường hợp có một vector duy nhất và lặp lại nó tương ứng với các thí nghiệm với R=1. Tuy nhiên, khi số lượng token có sẵn quá lớn, hiệu suất bắt đầu giảm. Sự giảm này có thể được gây ra bởi việc đưa vào quá nhiều tính biến thiên mà hệ thống không thể mô hình hóa vì các kiến trúc được sử dụng không quá lớn, có nghĩa là có một số lượng hạn chế các token khác nhau để thực hiện quá trình huấn luyện.

Trong Bảng 2, kết quả thu được trong cơ sở dữ liệu DeepMine-part 1 được hiển thị. Không giống như tập dữ liệu khác, dữ liệu huấn luyện trong DeepMine lớn hơn, cho thấy rằng việc thiếu dữ liệu không quá quan trọng để huấn luyện một hệ thống mạnh mẽ và bền vững. Do đó, việc thay thế average embedding hoặc attentive pooling embedding bằng class token chỉ cải thiện hiệu suất một chút. Bên cạnh đó, việc quét giá trị R cho thấy sự tiến triển của kết quả nữ và nam riêng biệt không theo cùng xu hướng như xảy ra trong kết quả RSR-Part II.

### 7.2. Hiệu ứng của Knowledge Distillation sử dụng Tokens

Trong phần này, chúng tôi phân tích hiệu ứng của việc giới thiệu một phương pháp dựa trên triết lý Knowledge Distillation bao gồm một kiến trúc teacher-student. Hơn nữa, trong phương pháp này, một distillation token bổ sung (CLS_DIST) được kết hợp [9]. Phương pháp này đã được sử dụng để so sánh hiệu suất thu được trong trường hợp global average pooling cũng như trong phương pháp lấy mẫu được đề xuất để sử dụng class token. Trong trường hợp thứ hai này, chúng tôi đã phát triển kiến trúc teacher-student sử dụng giá trị R của cấu hình tốt nhất thu được trong phần trước, và cũng, trường hợp R=1 vì đó là cách thông thường để áp dụng phương pháp class token này trong tài liệu.

Kết quả của các thí nghiệm này trong RSR-Part II được hiển thị trong Bảng 3. Bất kể loại phương pháp để thu được các biểu diễn được sử dụng, chúng ta có thể quan sát rằng việc sử dụng một kiến trúc dựa trên phương pháp teacher-student cải thiện tính mạnh mẽ và đạt được hiệu suất tốt hơn trong tất cả các phương án để trích xuất các biểu diễn. Hơn nữa, hiệu suất tốt nhất được thu thập bằng cách áp dụng chiến lược đề xuất của chúng tôi để giới thiệu các token với một phương án lấy mẫu với nhiều hơn một vector duy nhất.

Mặt khác, Bảng 4 trình bày hiệu suất của các hệ thống với DeepMine-part 1. Trong trường hợp này, kết quả cho thấy việc áp dụng chỉ kiến trúc teacher-student không cải thiện các hệ thống. Tuy nhiên, việc sử dụng kiến trúc teacher-student và distillation token bổ sung (CLS_DIST), kết hợp với chiến lược lấy mẫu với nhiều token vector cũng cho phép đạt được một hệ thống mạnh mẽ hơn và cải thiện đáng kể trong kết quả.

### 7.3. Phân tích các Biểu diễn Self-Attention của Class Token

Xét đến các kết quả có liên quan thu được, chúng tôi cũng đã tiến hành một phân tích để diễn giải những gì ma trận self-attention A đang học trong mỗi hệ thống. Để thực hiện phân tích này, chúng tôi đã sử dụng hệ thống với hiệu suất tốt nhất từ mỗi cơ sở dữ liệu, và trong các hệ thống này, lớp MSA cuối cùng của mô hình student đã được chọn để tạo các biểu diễn. Ngoài ra, chúng tôi đã chọn các phát âm khác nhau để phân tích trong Hình 4 và Hình 5. Đối với mỗi phát âm, ba hình được vẽ: phổ đồ của phát âm, ma trận trọng số attention tương ứng với class token cho mỗi trong số 16 head của lớp MSA, và tổng của trọng số của các class token attention này.

Trong Hình 4, hai ví dụ về phát âm của các cụm từ khác nhau ("Call sister", "Call brother") được phát âm bởi cùng một người nói được hiển thị. Các ví dụ này được thu thập từ tập đánh giá của cơ sở dữ liệu RSR-Part II. Nếu chúng ta nhìn vào các hình ở giữa và dưới, chúng ta có thể quan sát thông tin có liên quan được học bởi các trọng số self-attention để xác định chính xác cụm từ và người nói của mỗi phát âm sử dụng class token. Lưu ý rằng hai cụm từ ví dụ này bắt đầu chính xác giống nhau với từ Call, vì vậy tập trung vào đầu của các hình, chúng ta quan sát cách self-attention đưa ra sự liên quan tương tự trong cả hai trường hợp đến các khu vực của cùng ngữ âm. Hơn nữa, chúng ta cũng có thể thấy rằng các trọng số không chú ý đến khu vực ở đầu và cuối của các phát âm tương ứng với những khoảnh khắc im lặng.

Hình 5 biểu diễn hai ví dụ về phát âm của cùng một cụm từ ("OK Google") được phát âm bởi những người nói khác nhau. Trong trường hợp này, các ví dụ được thu thập từ tập đánh giá của cơ sở dữ liệu DeepMine. Lưu ý rằng vì các hình này là của cùng một cụm từ, self-attention tập trung vào cùng các khu vực, nhưng sự liên quan khác nhau được đưa ra cho một số trong số chúng. Bên cạnh đó, hiệu ứng không tập trung vào đầu và cuối của phát âm cũng xảy ra trong các ví dụ này.

## 8. Kết luận

Trong bài báo này, chúng tôi đã trình bày một phương pháp mới cho nhiệm vụ SV. Phương pháp này dựa trên việc sử dụng class token có thể học được để thu được một bộ mô tả phát âm toàn cục thay vì sử dụng average pooling. Hơn nữa, chúng tôi đã phát triển một phương án để tạo class token với một chiến lược lấy mẫu đưa vào sự không chắc chắn giúp tổng quát hóa tốt hơn. Ngoài phương pháp trước đó, chúng tôi cũng đã sử dụng một kiến trúc teacher-student kết hợp với một distillation token bổ sung để phát triển một hệ thống mạnh mẽ hơn. Sử dụng kiến trúc này, distillation token trong mạng student học để nhân bản các dự đoán từ mạng teacher. Cả hai đề xuất đều được đánh giá trong hai cơ sở dữ liệu SV phụ thuộc văn bản. Kết quả đạt được cho thấy trong RSR2015-part II rằng mỗi phương pháp được giới thiệu để thu được một hệ thống mạnh mẽ và giảm hiệu suất kém tiềm ẩn do thiếu dữ liệu đều cải thiện hiệu suất tổng thể. Tuy nhiên, trong DeepMine-part 1, kết quả thu được chỉ thay thế average embedding bằng class token cho thấy một cải thiện nhỏ, trong khi việc sử dụng kiến trúc teacher-student đạt được một cải thiện lớn và xác nhận sức mạnh của loại phương pháp này để huấn luyện các hệ thống.

## Tuyên bố Đóng góp Tác giả

**Victoria Mingote**: Khái niệm hóa, Điều tra, Phương pháp luận, Phần mềm, Viết - Chuẩn bị bản thảo gốc; **Antonio Miguel**: Khái niệm hóa, Điều tra, Phương pháp luận, Phần mềm, Giám sát, Viết - Xem xét và Chỉnh sửa.; **Alfonso Ortega**: Giám sát, Viết - Xem xét và Chỉnh sửa; **Eduardo Lleida**: Giám sát, Viết - Xem xét và Chỉnh sửa.

## Lời cảm ơn

Dự án này đã nhận được tài trợ từ chương trình nghiên cứu và đổi mới Horizon 2020 của Liên minh Châu Âu dưới Marie Skłodowska-Curie Grant 101007666; một phần bởi MCIN/AEI/10.13039/501100011033 và bởi Liên minh Châu Âu "NextGenerationEU"/PRTR dưới Grant PDC2021-120846-C41, bởi Bộ Kinh tế và Cạnh tranh Tây Ban Nha và Quỹ Xã hội Châu Âu thông qua grant PRE2018-083312, bởi Chính phủ Aragon (Grant Group T36 20R), và bởi Nuance Communications, Inc.

## Tài liệu tham khảo

[Danh sách các tài liệu tham khảo từ [1] đến [46] được giữ nguyên như trong bản gốc]

**Victoria Mingote** nhận bằng Cử nhân và Thạc sĩ về Kỹ thuật Viễn thông từ Đại học Zaragoza, Tây Ban Nha, lần lượt vào năm 2014 và 2016. Sau đó, cô gia nhập nhóm nghiên cứu ViVoLab với tư cách là nghiên cứu sinh tiến sĩ và nhận bằng Tiến sĩ vào năm 2022 từ Đại học Zaragoza. Hiện tại cô là một nhà nghiên cứu sau tiến sĩ trong nhóm nghiên cứu ViVoLab. Cô đã đạt được nhiều xuất bản công trình của mình trong các tạp chí quốc tế khác nhau và kỷ yếu hội nghị. Sở thích nghiên cứu của cô mở rộng qua các lĩnh vực xử lý tín hiệu, machine learning, xác thực và nhận dạng đa phương thức (giọng nói và khuôn mặt), và nhận dạng ngôn ngữ.

**Antonio Miguel** sinh tại Zaragoza, Tây Ban Nha. Ông nhận bằng M.Sc. về kỹ thuật viễn thông và bằng Ph.D. từ Đại học Zaragoza (UZ), Zaragoza, Tây Ban Nha, lần lượt vào năm 2001 và 2008. Từ 2000 đến 2006, ông làm việc với Nhóm Công nghệ Truyền thông, Khoa Kỹ thuật Điện tử và Truyền thông, UZ, dưới một học bổng nghiên cứu. Từ năm 2006, ông là Phó Giáo sư tại Khoa Kỹ thuật Điện tử và Truyền thông, UZ. Sở thích nghiên cứu hiện tại của ông bao gồm mô hình hóa âm thanh cho nhận dạng giọng nói và người nói.

**Alfonso Ortega** nhận bằng Kỹ thuật Viễn thông và bằng Ph.D. từ Đại học Zaragoza, Zaragoza, Tây Ban Nha, lần lượt vào năm 2000 và 2005. Ông là Phó Giám đốc của Viện Nghiên cứu Kỹ thuật Aragon (I3A), Đại học Zaragoza. Năm 2006, ông là học giả thăm viếng tại Trung tâm Hệ thống Giọng nói Mạnh mẽ, Đại học Texas tại Dallas, Hoa Kỳ. Ông đã tham gia hơn 50 dự án nghiên cứu được tài trợ bởi các tổ chức công cộng quốc gia hoặc quốc tế và hơn 30 dự án nghiên cứu cho nhiều công ty. Ông là tác giả của hơn 100 bài báo được xuất bản trong các tạp chí quốc tế hoặc kỷ yếu hội nghị và nhiều bằng sáng chế quốc tế. Hiện tại ông là Phó Giáo sư tại Khoa Kỹ thuật Điện tử và Truyền thông, Đại học Zaragoza. Sở thích nghiên cứu của ông bao gồm xử lý, phân tích và mô hình hóa giọng nói, xác thực người nói tự động, và nhận dạng giọng nói tự động. Luận án Ph.D. của ông, được hướng dẫn bởi Tiến sĩ E. Lleida, đã nhận Giải thưởng Ph.D. Xuất sắc và Giải thương Ghế Telefonica cho Ph.D. công nghệ tốt nhất.

**Eduardo Lleida** nhận bằng M.Sc. về kỹ thuật viễn thông và bằng Ph.D. về xử lý tín hiệu từ Universitat Politecnica de Catalunya (UPC), Barcelona, Tây Ban Nha, lần lượt vào năm 1985 và 1990. Từ 1986 đến 1988, ông tham gia công việc tiến sĩ của mình tại Khoa Lý thuyết Tín hiệu và Truyền thông, UPC. Từ 1989 đến 1990, ông là Trợ lý Giáo sư, và từ 1991 đến 1993, ông là Phó Giáo sư tại Khoa Lý thuyết Tín hiệu và Truyền thông, UPC. Từ tháng 2 năm 1995 đến tháng 1 năm 1996, ông làm việc với AT&T Bell Laboratories, Murray Hill, NJ, Hoa Kỳ, với tư cách là Cố vấn về nhận dạng giọng nói. Hiện tại ông là giáo sư đầy đủ về lý thuyết tín hiệu và truyền thông tại Khoa Kỹ thuật Điện tử và Truyền thông, Đại học Zaragoza, Zaragoza, Tây Ban Nha, và là thành viên của Viện Nghiên cứu Kỹ thuật Aragon, nơi ông đứng đầu nhóm nghiên cứu ViVoLab về công nghệ giọng nói. Ông đã là cố vấn tiến sĩ cho 12 sinh viên tiến sĩ. Ông đã quản lý hơn 50 dự án liên quan đến giọng nói, là nhà phát minh trong bảy bằng sáng chế toàn cầu, và đồng tác giả hơn 200 bài báo kỹ thuật trong lĩnh vực nhận dạng giọng nói, người nói và ngôn ngữ, tăng cường giọng nói và nhận dạng trong môi trường âm thanh bất lợi, mô hình hóa âm thanh, các biện pháp tin cậy, và hệ thống đối thoại nói.

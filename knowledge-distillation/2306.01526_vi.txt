# 2306.01526.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-distillation/2306.01526.pdf
# Kích thước tệp: 18664045 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Bản thảo không tên Số.
(sẽ được chèn bởi biên tập viên)
Cắt tỉa kênh nhóm và chưng cất chú ý không gian
cho phát hiện đối tượng
Yun Chu ·Pu Li ·Yong Bai ·Zhuhua
Hu ·Yongqing Chen ·Jiafeng Lu
Nhận: ngày 2021.09 / Chấp nhận: 2022.03
Tóm tắt Do tham số hóa quá mức của mạng nơ-ron, nhiều phương pháp nén mô hình dựa trên cắt tỉa và lượng tử hóa đã xuất hiện. Chúng đáng chú ý trong việc giảm kích thước, số tham số và độ phức tạp tính toán của mô hình. Tuy nhiên, hầu hết các mô hình được nén bằng các phương pháp như vậy cần sự hỗ trợ của phần cứng và phần mềm đặc biệt, làm tăng chi phí triển khai. Hơn nữa, các phương pháp này chủ yếu được sử dụng trong các tác vụ phân loại, và hiếm khi được sử dụng trực tiếp trong các tác vụ phát hiện. Để giải quyết những vấn đề này, cho mạng phát hiện đối tượng chúng tôi giới thiệu một phương pháp nén mô hình ba giai đoạn: huấn luyện thưa thớt động, cắt tỉa kênh nhóm, và chưng cất chú ý không gian. Thứ nhất, để chọn ra các kênh không quan trọng trong mạng và duy trì sự cân bằng tốt giữa độ thưa thớt và độ chính xác, chúng tôi đưa ra một phương pháp huấn luyện thưa thớt động, giới thiệu một tỷ lệ thưa thớt biến đổi, và tỷ lệ thưa thớt sẽ thay đổi theo quá trình huấn luyện của mạng. Thứ hai, để giảm ảnh hưởng của cắt tỉa đến độ chính xác mạng, chúng tôi đề xuất một phương pháp cắt tỉa mới được gọi là cắt tỉa kênh nhóm. Cụ thể, chúng tôi chia mạng thành nhiều nhóm theo quy mô của lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng, sau đó chúng tôi sử dụng các ngưỡng cắt tỉa khác nhau để cắt tỉa các kênh trong mỗi nhóm. Cuối cùng, để khôi phục độ chính xác của mạng đã cắt tỉa, chúng tôi sử dụng một phương pháp chưng cất kiến thức cải tiến cho mạng đã cắt tỉa. Đặc biệt, chúng tôi trích xuất thông tin chú ý không gian từ các bản đồ đặc trưng của các quy mô cụ thể trong mỗi nhóm làm kiến thức cho chưng cất. Trong các thí nghiệm, chúng tôi sử dụng YOLOv4 làm mạng phát hiện đối tượng và PASCAL VOC làm tập dữ liệu huấn luyện. Phương pháp của chúng tôi giảm các tham số của mô hình 64,7% và tính toán 34,9%. Khi kích thước hình ảnh đầu vào là 416×416, so với mô hình mạng gốc có kích thước 256MB và độ chính xác 87,1, mô hình nén của chúng tôi đạt độ chính xác 86,6 với kích thước 90MB. Để chứng minh tính tổng quát của phương pháp chúng tôi, chúng tôi thay thế backbone thành Darknet53 và Mobilenet và cũng đạt được kết quả nén thỏa mãn.
Yun Chu, Yong Bai, Zhuhua Hu, Yongqing Chen, Jiafeng Lu thuộc Trường Kỹ thuật Thông tin và Truyền thông, Đại học Hainan, Haikou, 570288, Trung Quốc
·Pu Li thuộc Trường Phần mềm và Vi điện tử, Đại học Bắc Kinh, Bắc Kinh, 100871, Trung Quốc.
Thư từ nên được gửi đến Yong Bai, E-mail: bai@hainanu.edu.cnarXiv:2306.01526v1  [cs.CV]  2 Jun 2023

--- TRANG 2 ---
2 Yun Chu et al.
Từ khóa nén mô hình ·phát hiện đối tượng ·cắt tỉa kênh nhóm ·
chưng cất kiến thức
1 Giới thiệu
Trong những năm gần đây, CNN (Mạng Nơ-ron Tích chập) đã trở thành các phương pháp chiếm ưu thế cho các tác vụ thị giác máy tính khác nhau, như phân loại hình ảnh [1], phát hiện đối tượng [2], và phân đoạn [3]. Các mạng phân loại bao gồm AlexNet [4], ResNet [5], MobileNets [6], và các mạng phát hiện đối tượng bao gồm Faster-RCNN [7], SSD [8], YOLOv3 ∼v4 [9], [10]. Các mô hình mạng nơ-ron cho những tác vụ đó đã phát triển từ 8 lớp đến hơn 100 lớp.

Mặc dù các mạng lớn có khả năng biểu diễn đặc trưng mạnh mẽ, chúng tiêu thụ nhiều tài nguyên hơn. Ví dụ, độ sâu của mạng YOLOv4 đạt 162 lớp, kích thước của mô hình là 256 MB, và số lượng tham số là 64 triệu. Khi xử lý một hình ảnh có kích thước 416 ×416, nó cần 29G FLOP (Số Phép toán Dấu phẩy Động Mỗi Giây), và các biến trung gian sẽ chiếm nhiều bộ nhớ hơn. Tính đến kích thước của mô hình, bộ nhớ cần thiết cho suy luận và lượng tính toán là không thể chịu đựng được đối với các thiết bị nhúng có tài nguyên hạn chế.

Để giải quyết vấn đề triển khai mạng nơ-ron trong thiết bị di động hoặc nhúng, nhiều công trình nén mô hình dựa trên cắt tỉa, lượng hóa, chưng cất kiến thức, và các phương pháp thiết kế mạng nhẹ. Trong công trình cắt tỉa, các phương pháp cắt tỉa dựa trên mức độ trọng số đã được đề xuất [11] và [12] để giảm số lượng tham số của mô hình mà không ảnh hưởng đến độ chính xác của mạng. Tuy nhiên, các mô hình đã cắt tỉa dựa trên mức độ trọng số yêu cầu các bộ gia tốc phần cứng đặc biệt để được triển khai, như [13]. Để tiết kiệm chi phí triển khai, các phương pháp cắt tỉa dựa trên mức bộ lọc đã được đề xuất trong [14], [15], và các phương pháp này sẽ không yêu cầu hỗ trợ phần cứng đặc biệt. Trong công trình lượng hóa, mạng nhị phân và mạng ba ngôi đã được đề xuất trong [16] và [17], tương ứng. Trong [18] và [19], họ kết hợp cắt tỉa với lượng hóa và áp dụng nó vào mạng phân loại. Trong công trình [19], thông tin của các tham số đã được huấn luyện trước được sử dụng để gán tỷ lệ nén của mỗi lớp, và phương pháp sách mã chia sẻ được sử dụng để lượng hóa và họ đạt được hiệu ứng nén tốt. Mặc dù mạng lượng hóa bit thấp có thể giảm kích thước của mô hình, chúng mang lại mất mát độ chính xác lớn và thường cần một thư viện gia tốc phần mềm đặc biệt để hỗ trợ triển khai. Các nghiên cứu cắt tỉa và lượng hóa trên chủ yếu được sử dụng trong mạng phân loại, và không có nhiều nghiên cứu về việc áp dụng chúng vào mạng phát hiện.

Cắt tỉa và lượng hóa là để nén cấu trúc mạng và tham số hiện có. Ngược lại, chưng cất kiến thức và thiết kế mạng nhẹ tối ưu hóa hoặc trực tiếp thiết kế một cấu trúc mạng mới, tức là tránh mất mát độ chính xác do cắt tỉa hoặc lượng hóa gây ra. Chưng cất kiến thức là một cách tiếp cận để cải thiện hiệu suất của mạng học sinh bằng cách sử dụng mạng giáo viên. Hinton lần đầu áp dụng ý tưởng chưng cất vào mạng phân loại [20]. Sau đó, chưng cất kiến thức đã được sử dụng rộng rãi trong thị giác máy tính [21], [22], [23], xử lý ngôn ngữ tự nhiên [24], nhận dạng tiếng nói [25]. Mặc dù chưng cất kiến thức có thể cải thiện hiệu suất của mạng học sinh đến một mức độ nhất định, hiệu quả của nó trong việc giảm tham số và kích thước của mô hình còn xa so với cắt tỉa.

--- TRANG 3 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 3
Hơn nữa, cách biểu diễn kiến thức cần được chưng cất giữa mạng giáo viên và mạng học sinh là một vấn đề. Sự khác biệt cấu trúc giữa mạng giáo viên và mạng học sinh có ảnh hưởng lớn đến hiệu quả chưng cất. Trong [26] chưng cất kiến thức được kết hợp với học biểu diễn để giảm ảnh hưởng của sự khác biệt cấu trúc lên chưng cất. Công trình [27] đưa ra một tham chiếu để sử dụng học biểu diễn để giải quyết vấn đề căn chỉnh góc nhìn một phần. [28] trình bày một phương pháp giám sát yếu trong phát hiện đối tượng, phương pháp này chỉ yêu cầu nhãn hình ảnh và số lượng đối tượng của mỗi lớp trong hình ảnh, bằng sự kết hợp này tạo ra một định vị rõ ràng của các đối tượng trong cảnh thông qua một kỹ thuật che giữa bản đồ kích hoạt lớp và bản đồ kích hoạt hồi quy, những công trình này có thể giải quyết vấn đề biểu diễn kiến thức trong chưng cất đến một mức độ nào đó. Thiết kế mạng nhẹ là thiết kế trực tiếp các mạng hoặc mô-đun nhỏ, bài báo [29] trình bày một ứng dụng mạng nhẹ trong các tác vụ phát hiện đối tượng, bao gồm mô-đun đặc trưng chú ý để cải thiện độ chính xác mạng, mô-đun kênh không đổi để tiết kiệm chi phí truy cập bộ nhớ. Hai kiến trúc mã hóa-giải mã nhẹ khác nhau cho các tác vụ phân đoạn ngữ nghĩa đã được đề xuất trong [30] và [31], tương ứng. Công trình trước lấy mẫu tăng các đặc trưng tích chập của lớp sâu đến các lớp giải tích chập nông để tăng cường các gợi ý ngữ cảnh, và công trình sau sử dụng các mô-đun chia tách và xáo trộn kênh trong bộ mã hóa để giảm số lượng tham số, và giới thiệu một mô-đun chú ý trong bộ giải mã để cải thiện độ chính xác. Bằng cách thiết kế trực tiếp các mô-đun nhẹ, có thể đạt được sự cân bằng tốt giữa độ chính xác và kích thước của mô hình, những mạng nhẹ này có thể được kết hợp tốt với các tác vụ trong lái xe tự động, như [32]. Những mô-đun hoặc mạng được thiết kế tốt như vậy [33], [34], [35], [36], [37], có thể chạy bình thường trên các máy chủ phòng thí nghiệm. Tuy nhiên, nếu chúng ta muốn triển khai thành công những mạng này trên các thiết bị biên, cần nhiều thí nghiệm và sửa đổi để xác minh hiệu quả của chúng. Trước khi mạng được triển khai đến thiết bị biên, các tham số và mạng cần được lượng hóa và biên dịch. Thông thường, một số mô-đun sáng tạo hoặc lớp mạng không thể được biên dịch và thông qua (do hạn chế của tập lệnh và các toán tử cơ bản trên thiết bị phần cứng), điều này cản trở việc triển khai những mạng nhẹ này đến các thiết bị biên và giảm tính linh hoạt của những mô-đun này.

Trong tác vụ phát hiện đối tượng, nén mô hình chủ yếu được thực hiện bằng chưng cất kiến thức, và tồn tại ít công trình kết hợp cắt tỉa với chưng cất kiến thức. Tóm lại, các công trình nén mô hình hiện có có những hạn chế sau: 1. Hầu hết các mô hình cắt tỉa và lượng hóa cần hỗ trợ mạch phần cứng đặc biệt hoặc thư viện gia tốc phần mềm, làm tăng chi phí triển khai những mô hình này đến thiết bị biên. 2. Trong các mạng phát hiện đối tượng, các phương pháp nén mô hình chủ yếu được thực hiện bằng chưng cất kiến thức, và hiệu quả nén không thỏa mãn. Cắt tỉa được sử dụng rộng rãi trong mạng phân loại nhưng được áp dụng trực tiếp trong phát hiện đối tượng.

Để giải quyết các vấn đề trên, chúng tôi đề xuất một phương pháp nén mô hình ba giai đoạn cho các tác vụ phát hiện đối tượng: huấn luyện thưa thớt động, cắt tỉa kênh nhóm, và chưng cất chú ý không gian. Như được hiển thị trong Hình 1, chúng tôi mô tả ngắn gọn việc thực hiện phương pháp nén mô hình ba giai đoạn được đề xuất.

Thứ nhất, chúng tôi huấn luyện mạng một cách thưa thớt. Huấn luyện thưa thớt là làm cho phân phối của hệ số γ trong lớp BN gần với 0, và sau đó giá trị của hệ số γ được sử dụng làm yếu tố quy mô quan trọng của kênh để chọn ra các kênh không đáng kể trong mạng. Phương pháp huấn luyện thưa thớt truyền thống sử dụng một tỷ lệ thưa thớt không đổi

--- TRANG 4 ---
4 Yun Chu et al.
Hình 1: Sơ đồ luồng của nén mô hình ba giai đoạn: huấn luyện thưa thớt động, cắt tỉa kênh nhóm, và chưng cất chú ý không gian.
tỷ lệ thưa thớt trong quá trình huấn luyện, điều này tốn thời gian và khó tạo ra sự cân bằng tốt giữa độ thưa thớt và độ chính xác của mạng. Do đó, chúng tôi giới thiệu một tỷ lệ thưa thớt biến đổi để tăng tốc huấn luyện thưa thớt của mạng và đạt được sự cân bằng tốt giữa độ thưa thớt và độ chính xác của mạng, chi tiết trong Phần 4.1

Tiếp theo, chúng tôi cắt tỉa mạng. Hầu hết các phương pháp cắt tỉa truyền thống được sử dụng trong mạng phân loại, và tất cả các kênh trong mạng được cắt tỉa với cùng một ngưỡng. Ngược lại, chúng tôi chia mạng phát hiện thành nhiều nhóm. Trong việc nhóm, chúng tôi chủ yếu xem xét quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng, các lớp đặc trưng có cùng quy mô và các lớp có cấu trúc mô-đun tương tự được gán vào cùng một nhóm. Sau đó, mỗi nhóm có được ngưỡng cắt tỉa theo tỷ lệ cắt tỉa của nhóm hiện tại, sau đó chúng tôi cắt tỉa các kênh theo ngưỡng cắt tỉa trong mỗi nhóm, do đó đạt được cắt tỉa chính xác và hiệu quả hơn của mạng phát hiện, chi tiết trong Phần 4.2.

Cuối cùng, khi cắt tỉa kênh của mạng phát hiện, chúng tôi nhận thấy rằng với sự gia tăng của danh mục phát hiện và tỷ lệ cắt tỉa, cắt tỉa sẽ mang lại mất mát độ chính xác lớn hơn cho mô hình. Để khôi phục độ chính xác của mạng sau khi cắt tỉa nhóm, chúng tôi giới thiệu chưng cất kiến thức vào mạng đã cắt tỉa. Đặc biệt, chúng tôi trích xuất thông tin chú ý không gian từ các bản đồ đặc trưng của các quy mô cụ thể trong mỗi nhóm làm kiến thức và chưng cất mạng đã cắt tỉa, chi tiết trong Phần 4.3.

Theo hiểu biết tốt nhất của chúng tôi, công trình kết hợp cắt tỉa với chưng cất chú ý không gian và áp dụng nó vào các tác vụ phát hiện đối tượng hiện tại hiếm khi được khám phá.
Những đóng góp chính của bài báo này được tóm tắt như sau:
1) Để cải thiện hiệu quả của huấn luyện thưa thớt, chúng tôi thiết kế một phương pháp huấn luyện thưa thớt động sử dụng tỷ lệ thưa thớt biến đổi để tăng tốc quá trình huấn luyện thưa thớt, mạng đạt được sự đánh đổi tốt hơn giữa độ thưa thớt và độ chính xác.
2) Đối với mạng phát hiện đối tượng, chúng tôi đề xuất một phương pháp cắt tỉa mới, được gọi là cắt tỉa kênh nhóm. Chúng tôi chia mạng phát hiện thành nhiều nhóm. Trong quá trình nhóm, chúng tôi xem xét toàn diện quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng. Sau đó, mỗi nhóm có được ngưỡng cắt tỉa theo các tỷ lệ cắt tỉa khác nhau, sau đó chúng tôi cắt tỉa các kênh trong mỗi nhóm để đạt được cắt tỉa chính xác và hiệu quả hơn của mạng phát hiện.
3) Để khôi phục độ chính xác của mô hình mạng cắt tỉa, chúng tôi giới thiệu chưng cất kiến thức vào mạng sau khi cắt tỉa nhóm. Đặc biệt, chúng tôi trích xuất thông tin chú ý không gian chỉ từ các bản đồ đặc trưng của các quy mô cụ thể trong mỗi nhóm làm kiến thức và chưng cất mạng đã cắt tỉa. Hơn nữa, chúng tôi chứng minh rằng phương pháp chưng cất của chúng tôi không chỉ phù hợp với phương pháp cắt tỉa của chúng tôi mà còn có thể kết hợp với các phương pháp cắt tỉa phổ biến khác.

--- TRANG 5 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 5
4) Chúng tôi tiến hành các thí nghiệm mở rộng trên tập dữ liệu PASCAL VOC với mạng YOLOV4 để xác minh hiệu quả của phương pháp được đề xuất. Để chứng minh tính tổng quát của phương pháp chúng tôi, chúng tôi cũng sử dụng Darknet53 và Mobilenet làm backbone để xây dựng mạng phát hiện, kết quả thí nghiệm cho thấy phương pháp của chúng tôi có khả năng ứng dụng khác. Ngoài ra, chúng tôi triển khai mô hình nén trên thiết bị biên Jetson nano, điều này chứng minh rằng mô hình nén của chúng tôi có thể được triển khai mà không cần hỗ trợ phần cứng đặc biệt và có thể đạt được hiệu ứng gia tốc.

2 Công trình liên quan
Trong phần này, chúng tôi tóm tắt ngắn gọn các công trình liên quan về cắt tỉa và chưng cất kiến thức.

2.1 Cắt tỉa mạng
Ý tưởng của cắt tỉa là giảm sự dư thừa của cấu trúc và tham số trong mạng nơ-ron để mạng trở nên nhẹ hơn và hiệu quả hơn. Nghiên cứu về cắt tỉa tập trung vào hai khía cạnh. Một là loại đối tượng nào trong mạng có thể được cắt tỉa, và hai là cách đo lường tầm quan trọng của nội dung được cắt tỉa. Từ góc độ đối tượng được cắt tỉa, phương pháp cắt tỉa hiện tại có thể được chia thành cắt tỉa không có cấu trúc và cắt tỉa có cấu trúc. Cắt tỉa không có cấu trúc đề cập đến việc cấu trúc topo của mạng trở nên bất thường và không có cấu trúc sau khi mạng được cắt tỉa, và chúng thường cắt tỉa các trọng số kết nối giữa các nơ-ron. Ví dụ, trong [11] và [12], giá trị tuyệt đối của trọng số được lấy làm thước đo của việc cắt tỉa nó. Ưu điểm của cắt tỉa không có cấu trúc là tỷ lệ cắt tỉa có thể đạt mức cao mà không ảnh hưởng đến độ chính xác của mạng. Nhược điểm là nó cần sự hỗ trợ của các mạch phần cứng đặc biệt, làm tăng chi phí triển khai.

Cắt tỉa có cấu trúc có nghĩa là topo mạng không thay đổi sau khi cắt tỉa. Thường cắt tỉa ở mức bộ lọc [38], kênh [39], lớp [40]. Công trình trong [38] cắt tỉa bộ lọc không quan trọng trong lớp hiện tại bằng cách tính toán thông tin thống kê của lớp tiếp theo. Liu et al [39] đề xuất một phương pháp cắt tỉa kênh có cấu trúc cho mạng phân loại, và mô hình nén không yêu cầu hỗ trợ phần cứng và phần mềm đặc biệt. Công trình trong [40] sử dụng phương pháp chiếu không gian con để đo lường tầm quan trọng của lớp mạng, cắt tỉa lớp trong mạng, và xác minh rằng cắt tỉa lớp tốt hơn cắt tỉa bộ lọc trong việc sử dụng tài nguyên. Ưu điểm của phương pháp cắt tỉa có cấu trúc là mạng sau khi cắt tỉa không cần sự hỗ trợ của các mạch phần cứng đặc biệt, và nhược điểm là tỷ lệ cắt tỉa không thể đạt rất cao.

Rethinking the Value of Network Pruning [41] đã thảo luận về ý nghĩa của cắt tỉa mạng. Công trình của họ chỉ ra rằng vai trò do cắt tỉa đóng tương tự như tìm kiếm kiến trúc mạng (NAS). Sau đó, [42] đưa ý tưởng của NAS vào cắt tỉa, đề xuất một mô-đun chuẩn hóa theo lô để đo lường tầm quan trọng của mỗi cấu trúc trong mạng, và sử dụng phương pháp cắt tỉa NAS này cho mạng phân loại. Trong bài báo này, chúng tôi kế thừa ý tưởng huấn luyện thưa thớt

--- TRANG 6 ---
6 Yun Chu et al.
trong [39], khác với điều đó, chúng tôi giới thiệu tỷ lệ thưa thớt biến đổi để tiến hành huấn luyện thưa thớt động trên mạng, điều này cải thiện sự đánh đổi giữa độ thưa thớt và độ chính xác của mạng.

2.2 Chưng cất kiến thức
Mục đích của chưng cất kiến thức là chuyển giao kiến thức đã học từ mạng giáo viên sang mạng học sinh để cải thiện hiệu suất của mạng học sinh. Nghiên cứu về chưng cất kiến thức tập trung vào hai khía cạnh. Một là đối tượng nào trong mạng được chọn làm kiến thức. Hai là cách đo lường liệu mạng học sinh có học được kiến thức hay không, điều này được phản ánh trong cách thiết kế hàm mất mát của chưng cất. Liên quan đến việc gì được chọn làm kiến thức, các phương pháp chưng cất hiện tại có thể được chia thành ba loại: 1. Sử dụng thông tin lớp cuối cùng đầu ra của mạng giáo viên làm kiến thức như trong [43], [44], [45]. 2. Sử dụng lớp đặc trưng giữa của mạng giáo viên làm kiến thức như trong [46], [47]. 3. Sử dụng mối quan hệ cấu trúc giữa các lớp của mạng giáo viên làm kiến thức như trong [24]. Trong mạng phân loại, [47] đề xuất trích xuất sự chú ý từ lớp đặc trưng và biểu hiện thông tin chú ý trong bản đồ nhiệt. Sau đó, hàm mất mát được xây dựng sử dụng sự chú ý của mạng giáo viên và mạng học sinh.

Search to Distill: [48] giới thiệu phương pháp chưng cất kiến thức vào NAS, và có được những kết luận sau thông qua thí nghiệm, cấu trúc của mạng học sinh xác định giới hạn trên mà hiệu quả chưng cất có thể đạt được, và hiệu quả chưng cất tốt hơn khi cấu trúc mạng của học sinh và giáo viên tương tự. Lấy cảm hứng từ công trình nghiên cứu trên, chúng tôi kết hợp cắt tỉa với chưng cất kiến thức. Trong bài báo này, ý tưởng chưng cất của chúng tôi được lấy cảm hứng từ [47], và chúng tôi đã cải thiện phương pháp để làm cho nó phù hợp với phát hiện đối tượng. Đặc biệt, chúng tôi trích xuất chú ý không gian từ các lớp đặc trưng của mỗi nhóm và đưa cho mỗi nhóm chú ý không gian với các trọng số khác nhau để chưng cất.

3 Kiến trúc mạng
Bài báo này lấy YOLOv4 làm ví dụ để minh họa các phương pháp cắt tỉa và chưng cất của chúng tôi. Phương pháp cắt tỉa của chúng tôi có thể được áp dụng cho các mạng có mô-đun BN. Trong phần này, chúng tôi giới thiệu ngắn gọn năm thành phần cơ bản cốt lõi của mạng và kiến trúc tổng thể của mạng.

3.1 Thành phần cơ bản
Như được hiển thị trong Hình 2, năm mô-đun là CBM, Res Unit, CSP X, CBL, và SPP.

--- TRANG 7 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 7
Hình 2: Năm mô-đun cơ bản của mạng YOLOv4.
Trong số đó, mô-đun CBM được cấu tạo từ Conv, Batch Normalization [49] và hàm kích hoạt Mish [50]. Res Unit được cấu tạo từ CBM và phép toán cộng, trong đó khối res được dẫn xuất từ [5]. Mô-đun CSP X được cấu tạo từ CBM, X Res units, và phép toán nối. Mô-đun CBL được cấu tạo từ Conv, BN, và Leaky-Relu [51]. Spatial pyramid pooling (SPP) được đề xuất trong [52], ở đây SPP đề cập đến việc hợp nhất đặc trưng bằng pooling ở bốn quy mô: 1 ×1, 5×5, 9×9, 13×13.

3.2 Mạng phát hiện
Thông qua năm thành phần cơ bản trên tạo thành ba phần của YOLOv4, tức là, mạng backbone, mạng tăng cường đặc trưng, và đầu phát hiện. Ba phần này có tổng cộng 162 lớp. Thứ nhất, mạng backbone được sử dụng để trích xuất đặc trưng của đối tượng. Sau đó, mạng tăng cường đặc trưng tiếp tục hợp nhất và tăng cường các đặc trưng. Cuối cùng, đầu phát hiện chịu trách nhiệm phân loại các đặc trưng đầu vào và trả về vị trí và kích thước của mục tiêu.
Như được hiển thị trong Hình 3, khi kích thước đầu vào là 416 ×416, các bản đồ đặc trưng lấy mẫu xuống 8, 16, 32 lần được thu được thông qua mạng backbone, cụ thể, các bản đồ đặc trưng ở quy mô 52 ×52, 26×26, 13×13, và sau đó những bản đồ đặc trưng này được đưa vào mạng tăng cường đặc trưng. Cuối cùng, đầu phát hiện xuất ra dự đoán ở ba quy mô.

--- TRANG 8 ---
8 Yun Chu et al.
Hình 3: Chia YOLOv4 thành năm nhóm. Trong đồ thị, hộp đường chấm xanh chứa ba phần chính của mạng, các hộp đường chấm đỏ đại diện cho năm nhóm. Khi nhóm, chúng tôi xem xét toàn diện quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng. Ví dụ, khi kích thước hình ảnh đầu vào là 416 ×416, nhóm1: bao gồm các quy mô của lớp đặc trưng từ 416×416 đến 52 ×52 và mô-đun CSP, nhóm2: chỉ bao gồm lớp đặc trưng ở quy mô 26×26 cùng với mô-đun CSP, nhóm3: chỉ bao gồm lớp đặc trưng ở quy mô 13×13 cùng với mô-đun CSP và CBL, tương tự cho nhóm4 và nhóm5. Lưu ý rằng, mô-đun CSP bao gồm mô-đun CBM như được hiển thị trong Hình 2, SPP, Concat, Upsample, và Downsample những mô-đun này chỉ thực hiện tính toán, chúng không chứa các tham số có thể huấn luyện.

4 Phương pháp đề xuất
Trong phần này, chúng tôi mô tả chi tiết phương pháp nén mô hình ba giai đoạn được đề xuất. Thứ nhất, chúng tôi huấn luyện mạng thưa thớt với tỷ lệ thưa thớt động. Sau đó, mạng phát hiện đối tượng được chia thành năm nhóm, và mỗi nhóm sử dụng các ngưỡng khác nhau để cắt tỉa kênh. Sau đó, sử dụng mạng đã cắt tỉa làm mạng học sinh cho chưng cất kiến thức, các chi tiết được mô tả như sau.

4.1 Huấn luyện thưa thớt động
Mục đích của huấn luyện thưa thớt là chọn ra các kênh không đáng kể trong lớp mạng. Tham khảo [39], chúng tôi sử dụng γ làm yếu tố quan trọng của kênh. Phân phối của các hệ số γ của tất cả các lớp BN trong mạng gốc

--- TRANG 9 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 9
ở trong các phạm vi khác nhau. Huấn luyện thưa thớt là làm thưa thớt hệ số γ, làm cho phân phối của hệ số γ gần với không. Giá trị γ nhỏ hơn chỉ ra tầm quan trọng thấp hơn của kênh tương ứng. Như được hiển thị trong (1), γ là tham số quy mô của lớp BN, β là tham số dịch chuyển của lớp BN, giá trị của γ và β được thu được bằng cách huấn luyện mạng.
yi=γˆxi+β, ˆxi=xi−µBp
σ2
B+ε, (1)
trong đó ˆ xi biểu thị đầu ra chuẩn hóa của một kênh, và yi biểu thị đầu ra của ˆxi sau khi γ mở rộng và β dịch chuyển. xi biểu thị một kênh được chỉ định trên lớp đặc trưng. Như được hiển thị trong (2), µB là giá trị trung bình của kênh được chỉ định dưới số batch-size, σ2
B là phương sai của kênh được chỉ định dưới số batch-size. Để ngăn mẫu số bằng 0, ε có thể được đặt giá trị là 1e-16.
µB=1
mmX
i=1xi, σ2
B=1
mmX
i=1(xi−µB)2, (2)
Trong quá trình huấn luyện thưa thớt động, chuẩn L1 của γ được sử dụng làm thuật ngữ chính quy hóa, và tỷ lệ thưa thớt biến đổi s d được giới thiệu, được thêm vào hàm mất mát để huấn luyện, như được hiển thị trong (3).
L =X
(x,y)l(f(x, W ), y) + s dX
γ∈Γg(γ), (3)
trong đó ( x, y) đại diện cho đầu vào của mạng và nhãn của dữ liệu, W đại diện cho các tham số có thể được huấn luyện, và thuật ngữ tổng đầu tiên đại diện cho mất mát gốc trong quá trình huấn luyện mạng CNN. Tổng thứ hai, g(γ) đại diện cho thuật ngữ chính quy hóa được giới thiệu, chúng tôi sử dụng g( γ) =|γ|. sd là một tỷ lệ thưa thớt biến đổi. Trong quá trình huấn luyện, mạng sẽ điều chỉnh động tỷ lệ thưa thớt của nó theo số epoch của huấn luyện hiện tại. Khi huấn luyện đến một nửa số epoch, 70 % của kênh duy trì tỷ lệ thưa thớt gốc, 30 % của kênh tỷ lệ thưa thớt giảm xuống 1 % của tỷ lệ thưa thớt gốc, để mạng huấn luyện cuối cùng đạt được sự cân bằng tốt giữa độ thưa thớt và độ chính xác.

4.2 Cắt tỉa kênh nhóm
Trong phần này, chúng tôi tập trung vào phương pháp cắt tỉa kênh nhóm được đề xuất. Nó có thể được chia thành ba bước. Thứ nhất, chúng tôi chia cấu trúc của mạng phát hiện đối tượng thành năm nhóm. Thứ hai, chúng tôi có được năm ngưỡng cắt tỉa khác nhau theo tỷ lệ cắt tỉa của mỗi nhóm và sau đó tạo ra ma trận mặt nạ cắt tỉa cho hầu hết các lớp tích chập trong mỗi nhóm, được sử dụng để cắt tỉa các kênh trong lớp tích chập. Cuối cùng, chúng tôi tạo ra ma trận mặt nạ cắt tỉa công cộng cho các lớp tích chập liên quan đến các lớp shortcut.

--- TRANG 10 ---
10 Yun Chu et al.
4.2.1 Nhóm mạng
Cắt tỉa kênh nhóm của chúng tôi là chia các lớp mạng phát hiện thành nhiều nhóm. Trong việc nhóm, chúng tôi xem xét toàn diện quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng có nghĩa là các lớp đặc trưng có cùng quy mô và các lớp có cấu trúc mô-đun tương tự được gán vào cùng một nhóm. Trong thí nghiệm, chúng tôi quan sát thấy rằng khi ngưỡng cắt tỉa thống nhất được sử dụng cho tất cả các cấu trúc, hai tình huống có hại sẽ xảy ra. Một là trong các cấu trúc có độ dư thừa cao, ngưỡng cắt tỉa thực tế cao hơn ngưỡng cắt tỉa thống nhất, và các kênh dư thừa trong các cấu trúc như vậy sẽ không được cắt tỉa. Trong trường hợp khác, trong cấu trúc có độ dư thừa thấp, ngưỡng cắt tỉa thực tế thấp hơn ngưỡng cắt tỉa thống nhất và các kênh quan trọng có thể được cắt tỉa trong cấu trúc này, ảnh hưởng nghiêm trọng đến độ chính xác của mạng.

Để giải quyết vấn đề này, chúng tôi nhóm mạng phát hiện đối tượng trước. Như được hiển thị trong Hình 3, các hộp đường chấm xanh đại diện cho phần backbone của mạng YOLOv4, phần tăng cường đặc trưng, và phần phát hiện. Các hộp đường chấm đỏ đại diện cho năm nhóm. Khi đầu vào kích thước 416 ×416 hình ảnh vào mạng, nhóm1 bao gồm các quy mô của lớp đặc trưng từ 416 ×416 đến 52 ×52 và mô-đun CSP, nhóm2 chỉ bao gồm lớp đặc trưng ở quy mô 26 ×26 cùng với mô-đun CSP, nhóm3 chỉ bao gồm lớp đặc trưng ở quy mô 13 ×13 cùng với mô-đun CSP và CBL, nhóm4 và nhóm5 đều bao gồm lớp đặc trưng từ quy mô 52 ×52 đến quy mô 13 ×13 và mô-đun CBL, tuy nhiên, để cắt tỉa chính xác hơn, chúng tôi chia hai phần này thành hai nhóm. Bên cạnh đó, mô-đun CSP bao gồm mô-đun CBM như được hiển thị trong Hình 2. SPP, Concat, Upsample, và Downsample những mô-đun này chỉ là các toán tử, chúng không chứa các tham số có thể huấn luyện.

Ba nhóm đầu tiên, Nhóm1 ∼3 thuộc mạng backbone và chịu trách nhiệm trích xuất các đặc trưng của đối tượng, ba nhóm này chứa tất cả các mô-đun dư (residual) trong mạng. Nhóm4 thuộc mạng tăng cường đặc trưng, chịu trách nhiệm tăng cường và hợp nhất thêm các đặc trưng. Nhóm5 bao gồm phần đầu phát hiện thực hiện phân loại đặc trưng và hồi quy vị trí đối tượng.

4.2.2 Luồng cắt tỉa và ma trận mặt nạ
Do độ dư thừa khác nhau trong năm nhóm, chúng tôi cần có được năm ngưỡng cắt tỉa và một ma trận mặt nạ cắt tỉa từ năm nhóm. Ở đây chúng tôi minh họa các bước bằng cách sử dụng một nhóm. Thứ nhất, chúng tôi tính toán tỷ lệ của số kênh trong nhóm hiện tại với tổng số kênh có thể được cắt tỉa trong toàn bộ mạng, chúng tôi ký hiệu tỷ lệ này là pi. Sau đó, cho một tỷ lệ cắt tỉa tổng của toàn bộ mạng, chúng tôi ký hiệu nó là P. Bằng cách nhân pi với P, chúng tôi có thể có được tỷ lệ cắt tỉa của nhóm hiện tại, ký hiệu là gi. Sau đó, chúng tôi sắp xếp tất cả các hệ số γ trong nhóm đó, theo tỷ lệ cắt tỉa của nhóm hiện tại( gi) chúng tôi có thể có được ngưỡng cắt tỉa của nhóm hiện tại(ký hiệu là ti). Cuối cùng, chúng tôi sử dụng ngưỡng cắt tỉa ti để so sánh với tất cả các hệ số γ trong nhóm này để có được ma trận mặt nạ cắt tỉa của các lớp tích chập, trong ma trận mặt nạ cắt tỉa đó, số 1 đại diện cho kênh ở vị trí tương ứng được giữ lại, và số 0 đại diện cho kênh ở vị trí tương ứng sẽ được cắt tỉa.

--- TRANG 11 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 11
Như được hiển thị trong Hình 4, chúng tôi sử dụng hệ số γ làm yếu tố quy mô của kênh và so sánh yếu tố quy mô với ngưỡng cắt tỉa của nhóm hiện tại. Khi giá trị của yếu tố quy mô thấp hơn ngưỡng cắt tỉa, kênh tương ứng với yếu tố quy mô sẽ được cắt tỉa. Sử dụng phương pháp trên, chúng tôi có được năm ngưỡng cắt tỉa và ma trận mặt nạ của lớp tích chập trong mỗi nhóm.
Hình 4: Hộp đường chấm đỏ đại diện cho lớp đặc trưng được gán vào nhóm I, hộp đường chấm xanh đại diện cho lớp tích chập bên cạnh lớp đặc trưng này. Chúng đều trong nhóm I, và trong nhóm này, tất cả các kênh sẽ chia sẻ cùng một ngưỡng cắt tỉa. Chúng tôi sử dụng γ làm yếu tố quy mô của kênh. Khi các yếu tố quy mô kênh thấp hơn ngưỡng cắt tỉa của nhóm hiện tại, các kênh tương ứng sẽ được cắt tỉa.

4.2.3 Ma trận mặt nạ công cộng
Ma trận mặt nạ cắt tỉa được thu được bằng phương pháp trên có thể được sử dụng làm ma trận cắt tỉa cuối cùng của hầu hết các lớp tích chập trong mạng. Tuy nhiên, một lớp tích chập khác liên quan đến lớp shortcut cần sử dụng ma trận cắt tỉa mặt nạ công cộng. Bởi vì số lượng kênh được thêm giữa hai lớp phải nhất quán trong lớp shortcut để thực hiện phép toán cộng. Xét rằng lớp nguồn của shortcut vẫn có thể là một lớp shortcut, điều này sẽ liên quan đến nhiều lớp tích chập về phía trước, và ma trận mặt nạ cắt tỉa của những lớp tích chập này cần phải nhất quán. Cách tạo ra ma trận cắt tỉa mặt nạ công cộng này để cắt tỉa kênh trong mỗi lớp tích chập đạt được một lượng cao hơn và có ít ảnh hưởng đến độ chính xác. Đây là một câu hỏi đáng xem xét.

Để giải quyết câu hỏi như vậy, chúng tôi đề xuất một phương pháp bỏ phiếu để tạo ra ma trận mặt nạ cắt tỉa công cộng. Như được hiển thị trong Hình 5. Thứ nhất, chúng tôi đếm tổng số lớp tích chập liên quan đến lớp shortcut và ký hiệu là N conv. Sau đó chúng tôi đếm tổng số số không ở vị trí ( i, j) trong ma trận mặt nạ cắt tỉa và ký hiệu là Z(i,j). Giá trị của ma trận mặt nạ công cộng ở vị trí ( i, j) ký hiệu là p(i,j). Khi Z(i,j)≥(Nconv/2), thì p(i,j)= 0 ; ngược lại, p(i,j)= 1.

--- TRANG 12 ---
12 Yun Chu et al.
Hình 5: Tạo ra ma trận mặt nạ cắt tỉa công cộng. Trong hình, N conv ký hiệu tổng số lớp tích chập liên quan đến lớp shortcut. Z(i,j) ký hiệu tổng số số không ở vị trí ( i, j) trong ma trận mặt nạ cắt tỉa. p(i,j) ký hiệu giá trị của ma trận mặt nạ công cộng ở vị trí ( i, j). Nếu Z(i,j)≥(Nconv/2), thì p (i,j)= 0; ngược lại, p (i,j)= 1.

4.3 Mất mát chưng cất kiến thức
Trong phần này, chúng tôi giới thiệu ba phần của mất mát chưng cất. Như được hiển thị trong Hình 6, chúng tôi sử dụng mạng gốc làm mạng giáo viên, và mạng đã cắt tỉa làm mạng học sinh cho chưng cất kiến thức, mất mát chưng cất bao gồm ba phần: 1. Sự khác biệt trong chú ý không gian giữa mạng học sinh và mạng giáo viên ký hiệu là LAT; 2. Sự khác biệt giá trị dự đoán giữa mạng học sinh và mạng giáo viên trong phân loại đối tượng và hồi quy vị trí được ký hiệu là Lsoft; 3. Mất mát giữa giá trị dự đoán của mạng học sinh và sự thật cơ sở được ký hiệu là Lhard.

Như trong (4), chúng tôi sử dụng Ltotal để đại diện cho tổng mất mát của mạng học sinh, và chúng tôi sẽ chủ yếu xem xét mất mát của LAT và Lsoft.
Ltotal=LAT+Lsoft+Lhard, (4)

--- TRANG 13 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 13
Hình 6: Chưng cất cho mạng đã cắt tỉa nhóm. Qi
T và Qi
S là thông tin chú ý không gian trích xuất từ các bản đồ đặc trưng của năm quy mô cụ thể trong mỗi nhóm của mạng giáo viên và mạng học sinh, tương ứng. Ba hộp đỏ chứng minh ba phần mất mát của mạng học sinh. 1. LAT ký hiệu sự khác biệt trong chú ý không gian giữa mạng học sinh và mạng giáo viên; 2.Lsoft ký hiệu sự khác biệt giá trị dự đoán giữa mạng học sinh và mạng giáo viên trong phân loại đối tượng và hồi quy vị trí; 3. Lhard ký hiệu mất mát giữa giá trị dự đoán của mạng học sinh và sự thật cơ sở.

4.3.1 Mất mát chú ý không gian nhóm
Như trong (5), LAT ký hiệu sự khác biệt trong thông tin chú ý không gian giữa mạng học sinh và mạng giáo viên. Chúng tôi giảm sự khác biệt này bằng cách cho phép mạng học sinh bắt chước chú ý không gian của mạng giáo viên.
LAT=5X
i=1βi




Qi
T

Qi
T

i
2−Qi
S

Qi
S

2




2, (5)
trong đó i thuộc 1 ∼5, đại diện cho năm nhóm trong mạng. Từ năm nhóm này, chúng tôi trích xuất chú ý không gian chỉ tại các bản đồ đặc trưng quy mô cụ thể làm kiến thức, các bản đồ đặc trưng quy mô là 208 ×208, 104 ×104, 52 ×52, 26 ×26 và 13 ×13, tương ứng, Chúng tôi trích xuất những bản đồ đặc trưng này từ năm nhóm. βi ký hiệu hệ số tăng mất mát của năm nhóm, chúng tôi đưa cho chú ý không gian của các nhóm khác nhau trọng số khác nhau. Qi
T và Qi
S là các dạng tensor 1 chiều của chú ý không gian mạng giáo viên và mạng học sinh, và mỗi phần tử trong Qi được chuẩn hóa.

--- TRANG 14 ---
14 Yun Chu et al.
Như trong (6), Qi một chiều được chuyển đổi từ F
Ai
hai chiều bằng phép toán làm phẳng. F
Ai
T
và F
Ai
S
là các dạng ma trận hai chiều của chú ý không gian trong mạng giáo viên và mạng học sinh, tương ứng.
Qi
T= vec
F
Ai
T
, Qi
S= vec
F
Ai
S
, (6)
Hàm ánh xạ F(.) được đưa ra trong (7), trong đó A ký hiệu bản đồ đặc trưng trên kênh, A có kích thước H ×W, và C đại diện cho số lượng tất cả các kênh trên lớp đặc trưng. Giá trị của p là 2, đại diện cho lũy thừa 2 cho mỗi phần tử trong A.
F(A) =Fp
sum(A) =cX
j=1|Aj|p, (7)
Chú ý không gian đề cập đến việc trích xuất thông tin không gian của tất cả các kênh trên một lớp đặc trưng nhất định dưới dạng bản đồ nhiệt. Quá trình trích xuất được hiển thị trong Hình 7. Một lớp đặc trưng được chọn từ mạng, và kích thước của lớp đặc trưng là C ×H×W. C đại diện cho số lượng kênh trên lớp đặc trưng. Thông qua hàm ánh xạ F: F: AC×H×W→AH×W, tensor lớp đặc trưng 3 chiều được ánh xạ thành tensor 2 chiều trên chiều kênh, đại diện cho bản đồ chú ý không gian của lớp đặc trưng.
Hình 7: Tạo ra bản đồ chú ý không gian từ lớp đặc trưng.

4.3.2 Mất mát mục tiêu mềm
Như trong (8), Lsoft được cấu tạo từ hai loại sự khác biệt dự đoán. Một là sự khác biệt dự đoán của mạng giáo viên và mạng học sinh trong phân loại đối tượng. Cái khác là sự khác biệt dự đoán của mạng giáo viên và mạng học sinh trong vị trí và kích thước của hộp đối tượng.
Lsoft=l(t−s)(cls) +l(t−s)(box), (8)

--- TRANG 15 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 15
l(t−s)(cls) ký hiệu sự khác biệt dự đoán trong phân loại đối tượng giữa mạng giáo viên và mạng học sinh, như được hiển thị trong (9).
l(t−s)(cls) =1
k3X
i=1kX
j=1M(i,j)
logM(i,j)−N(i,j)
, (9)
trong đó i ký hiệu dự đoán của mạng ở ba quy mô, k ký hiệu số lượng tất cả các hộp trước ở quy mô hiện tại. M(i,j) ký hiệu đầu ra dự đoán của mạng giáo viên sau chưng cất. N(i,j) ký hiệu đầu ra dự đoán của mạng học sinh sau chưng cất.

Như trong (10) (11), M(i,j),N(i,j) được thu được bằng hàm softmax và logsoftmax, trong đó P(i,j)
t(cls) ký hiệu xác suất phân loại được dự đoán cho mỗi hộp trước trong mạng giáo viên và P(i,j)
s(cls) ký hiệu xác suất phân loại được dự đoán cho mỗi hộp trước trong mạng học sinh. T là một tham số nhiệt độ được sử dụng để làm cho phân phối đầu ra của dự đoán mạng giáo viên và mạng học sinh đồng đều hơn.
M(i,j)= soft max
P(i,j)
t(cls)/T
, (10)
N(i,j)= log−soft max
P(i,j)
s(cls)/T
, (11)
Như trong (12), l(t−s)(box) ký hiệu sự khác biệt dự đoán giữa mạng giáo viên và mạng học sinh về vị trí và kích thước của hộp đối tượng.
l(t−s)(box) =3X
i=1kX
j=1


P(i,j)
t(box)−P(i,j)
s(box)


2, (12)
trong đó i ký hiệu dự đoán của mạng ở ba quy mô, và k ký hiệu số lượng các hộp ứng viên còn lại sau khi đáp ứng luồng IOU ở quy mô hiện tại. Ở vị trí tương ứng với hộp ứng viên đối tượng, trong mạng học sinh vị trí và kích thước của hộp dự đoán được ký hiệu bởi P(i,j)
s(box). Trong mạng giáo viên, vị trí và kích thước của hộp dự đoán được ký hiệu bởi P(i,j)
t(box).

5 Thí nghiệm
Trong thí nghiệm, chúng tôi lấy mạng phát hiện YOLOv4 và tập dữ liệu PASCAL VOC làm ví dụ để minh họa và xác thực hiệu quả của việc nén mô hình được đề xuất. Thứ nhất, chúng tôi huấn luyện mạng thưa thớt với tỷ lệ thưa thớt động. Thứ hai, chúng tôi phân tích định lượng tác động của các tỷ lệ cắt tỉa khác nhau lên kích thước mô hình, độ chính xác, và tính toán. Sau đó, chúng tôi so sánh cắt tỉa nhóm của chúng tôi với các phương pháp cắt tỉa hiện tại khác trên tập dữ liệu phát hiện đối tượng. Cuối cùng, để chứng minh tính ưu việt của phương pháp chưng cất, chúng tôi so sánh độ chính xác của mạng đã cắt tỉa sau khi tinh chỉnh và chưng cất. Hơn nữa, chúng tôi kết hợp phương pháp chưng cất của chúng tôi với các phương pháp cắt tỉa phổ biến khác để chứng minh rằng phương pháp chưng cất của chúng tôi phù hợp với các phương pháp cắt tỉa phổ biến khác.

--- TRANG 16 ---
16 Yun Chu et al.
5.1 Tập dữ liệu và chỉ số đánh giá
Đối với tập dữ liệu, chúng tôi sử dụng Pascal VOC [53]. voc2012train, voc2012val, voc2007train, và voc2007val, bốn phần này có 16551 hình ảnh và chúng tôi kết hợp chúng được sử dụng làm tập huấn luyện cuối cùng. voc2007test bao gồm 4952 hình ảnh và được sử dụng làm tập kiểm tra cuối cùng. Môi trường thí nghiệm của chúng tôi là Ubuntu 18.04, PyTorch = 1.8 phiên bản, GPU là một RTX3090 đơn. Đối với các chỉ số đánh giá, chúng tôi đánh giá hiệu suất của mô hình đã cắt tỉa từ bốn khía cạnh: kích thước mô hình, số lượng tham số, lượng tính toán, và mAP@0.5. Tính toán được đo bằng FLOPS. mAP@0.5 đại diện cho giá trị trung bình của tất cả các danh mục AP khi ngưỡng IOU là 0.5, AP đại diện cho độ chính xác trung bình của một danh mục, và các chi tiết tính toán cụ thể được tham khảo trong tài liệu tham khảo [54].

5.2 Huấn luyện thưa thớt động
Trong quá trình huấn luyện thưa thớt, chuẩn L1 của γ được thêm vào hàm mất mát làm thuật ngữ chính quy hóa để huấn luyện cùng nhau. Như được hiển thị trong Hình 8, phân phối của các hệ số γ của tất cả các lớp BN trong mạng gốc ở trong các phạm vi khác nhau. Quá trình huấn luyện thưa thớt là làm cho phân phối hệ số γ gần với không, để thuận tiện cho việc chọn ra các kênh không quan trọng trong mạng.
Hình 8: Phân phối của các hệ số γ trong mạng gốc.
Trong quá trình thí nghiệm, chúng tôi phát hiện ra rằng huấn luyện thưa thớt là sự đánh đổi giữa độ chính xác và độ thưa thớt. Một tỷ lệ thưa thớt lớn hơn s có thể mang lại hiệu ứng thưa thớt tốt hơn, nhưng mất mát độ chính xác cũng lớn, ngay cả khi số epoch của huấn luyện thưa thớt được tăng lên trong tương lai, mô hình vẫn không thể khôi phục đến độ chính xác tốt. Một tỷ lệ thưa thớt nhỏ hơn s có ít ảnh hưởng đến độ chính xác nhưng dẫn đến hiệu ứng thưa thớt tệ hơn. Để giải quyết vấn đề này và tạo ra sự cân bằng tốt giữa hiệu ứng thưa thớt và độ chính xác, chúng tôi đưa ra một phương pháp huấn luyện thưa thớt động, giới thiệu một tỷ lệ thưa thớt biến đổi s, và tỷ lệ thưa thớt s sẽ thay đổi theo quá trình huấn luyện của mạng.

Trong quá trình huấn luyện thưa thớt động, mức độ thưa thớt của mạng có thể được điều chỉnh bằng cách đặt tỷ lệ thưa thớt s, mạng sẽ điều chỉnh động tỷ lệ thưa thớt của nó theo số epoch của huấn luyện hiện tại. Đối với mạng YOLOv4, chúng tôi đặt tỷ lệ thưa thớt ban đầu s= 0.00075, tỷ lệ học ban đầu lr0 =

--- TRANG 17 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 17
0.002 và huấn luyện 200 epoch. Khi huấn luyện đến một nửa số epoch, 70 % của kênh duy trì tỷ lệ thưa thớt gốc, 30 % của kênh tỷ lệ thưa thớt giảm xuống 1 % của tỷ lệ thưa thớt gốc. Bên cạnh đó, tỷ lệ học được cập nhật bằng cosine annealing. Khi kích thước hình ảnh đầu vào là 416 ×416, kích thước batch được đặt thành 16, như được hiển thị trong Hình 9, hình này đại diện cho phân phối hệ số γ trong các lớp mạng sau huấn luyện thưa thớt động, so với phân phối hệ số γ gốc (như được hiển thị trong Hình 8), hầu hết những hệ số γ này gần với không hơn và thuận tiện để chọn ra các kênh không đáng kể.
Hình 9: Phân phối của hệ số γ trong mạng sau huấn luyện thưa thớt động.

5.3 Cắt tỉa kênh nhóm
Trong phần này, chúng tôi chia các lớp mạng thành năm nhóm. YOLOv4 có 162 lớp, trong quá trình nhóm, chúng tôi xem xét toàn diện quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng có nghĩa là các lớp đặc trưng có cùng quy mô và các lớp có cấu trúc mô-đun tương tự được gán vào cùng một nhóm.

Khi đầu vào kích thước 416 ×416 hình ảnh vào mạng, nhóm1 bao gồm các quy mô của lớp đặc trưng từ 416 ×416 đến 52 ×52 và mô-đun CSP, nhóm2 chỉ bao gồm lớp đặc trưng ở quy mô 26 ×26 cùng với mô-đun CSP, nhóm3 chỉ bao gồm lớp đặc trưng ở quy mô 13 ×13 cùng với mô-đun CSP và CBL, nhóm4 và nhóm5 đều bao gồm lớp đặc trưng từ quy mô 52 ×52 đến quy mô 13×13 và mô-đun CBL. Các lớp cụ thể trong mỗi nhóm là sau, bao gồm Nhóm1: 0 ∼55 lớp, Nhóm2:56 ∼85 lớp, Nhóm3: 86 ∼116 lớp, Nhóm4:117 ∼136 lớp, và Nhóm5:136 ∼161 lớp.

--- TRANG 18 ---
18 Yun Chu et al.
Bảng 1: Total đại diện cho tỷ lệ cắt tỉa tổng của toàn bộ mạng phát hiện, Model đại diện cho mô hình nén dưới tỷ lệ cắt tỉa tổng tương ứng và Group1 ∼5 hiển thị tỷ lệ cắt tỉa cụ thể trong 5 nhóm.
Total Model Group1 Group2 Group3 Group4 Group5 Model Size mAP@0.5
0 Base 0 0 0 0 0 256M 79.8
38% Model1 10% 20% 96% 87% 45% 98MB 73.6
40% Model2 10% 25% 96% 87% 50% 90MB 56.3
42% Model3 10% 25% 97% 85% 55% 84MB 28.3
45% Model4 15% 25% 96% 85% 70% 77MB 9.2
50% Model5 15% 27% 96% 85% 90% 68MB 6.1

5.3.1 Giảm tham số và tính toán của mô hình
Cho một tỷ lệ cắt tỉa tổng của toàn bộ mạng, theo tỷ lệ cắt tỉa tổng thuật toán sẽ tính toán tỷ lệ cắt tỉa của năm nhóm. Như được hiển thị trong Bảng 1, chúng tôi chứng minh các chi tiết của tỷ lệ cắt tỉa của năm nhóm. Có thể thấy từ Bảng 1 rằng trong phần mạng backbone, chức năng trích xuất đặc trưng chủ yếu được thực hiện bởi Nhóm1 và Nhóm2, và độ dư thừa trong hai nhóm này đạt 10% ∼25 %. Độ dư thừa trong Nhóm3 đạt hơn 90%, điều này chỉ ra rằng các kênh trong những lớp đặc trưng này có ít ảnh hưởng đến trích xuất đặc trưng trong Nhóm3. Độ dư thừa trong Nhóm4 đạt hơn 90%, và hầu hết các kênh trong Nhóm này có ít ảnh hưởng đến tăng cường đặc trưng. Độ dư thừa trong Nhóm5 đạt khoảng 45%.

Thông qua phân tích trên, đủ để chỉ ra rằng độ dư thừa trong các phần cấu trúc khác nhau của mạng là khác nhau. Chúng tôi sử dụng cắt tỉa nhóm để làm cho mỗi nhóm có các ngưỡng cắt tỉa khác nhau, do đó đạt được cắt tỉa chính xác và hiệu quả hơn. Trong Bảng 2, chúng tôi trình bày tác động của các tỷ lệ cắt tỉa khác nhau lên tham số và tính toán của mô hình, ngoại trừ tỷ lệ cắt tỉa khác nhau, chúng tôi giữ kích thước của hình ảnh đầu vào là 416 ×416. Bảng 2 chứng minh hiệu quả của phương pháp cắt tỉa kênh nhóm của chúng tôi.

Bảng 2: So sánh với mạng gốc, việc giảm tham số và tính toán của mô hình bằng cách sử dụng phương pháp cắt tỉa nhóm của chúng tôi với các tỷ lệ cắt tỉa khác nhau. Bảng 2 ∼Bảng 5, cho tất cả các mô hình, kích thước của hình ảnh đầu vào là 416 ×416.
Model Model Size Flops Pruned Parameters Pruned
Base 256MB 29.9G 0 64.1M 0
Model1 98MB 20.35G 31.9% 24.51M 61.7%
Model2 90MB 19.46G 34.9% 22.56M 64.7%
Model3 84MB 19.35G 35.2% 20.96M 67.2%
Model4 77MB 17.94G 40.0% 19.27M 69.9%
Model5 68MB 16.57G 44.6% 17.07M 73.3%

--- TRANG 19 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 19

5.3.2 So sánh với các phương pháp cắt tỉa hiện tại khác
Như được hiển thị trong Hình 10, để chứng minh tính ưu việt của phương pháp cắt tỉa kênh nhóm được đề xuất của chúng tôi trong phát hiện đối tượng, chúng tôi so sánh định lượng phương pháp của chúng tôi với các phương pháp cắt tỉa hiện tại khác như Network Slimming [39], Thinet [38], Layer pruning [40] và Eagle eye [42]. Chúng tôi so sánh chúng ở hai khía cạnh: kích thước mô hình và độ chính xác (map@0.5).
Hình 10: Hình này hiển thị độ chính xác của mạng phát hiện đối tượng thay đổi theo tỷ lệ cắt tỉa, và bán kính chấm đại diện cho kích thước của mô hình thay đổi theo tỷ lệ cắt tỉa, độ phân giải đầu vào là 416 ×416.
Trong quá trình cắt tỉa, chúng tôi giữ tỷ lệ cắt tỉa như nhau cho các phương pháp cắt tỉa khác nhau, kích thước của hình ảnh đầu vào là 416 ×416. Có thể thấy từ Hình 10, dưới cùng tỷ lệ cắt tỉa, phương pháp của chúng tôi có thể có được sự đánh đổi tốt nhất giữa độ chính xác của mô hình đã cắt tỉa và kích thước của mô hình đã cắt tỉa.

Ngoài ra, trong [40] họ sử dụng một cách tiếp cận chiếu không gian con để ước tính tầm quan trọng của các lớp mạng, khi sử dụng cách cắt tỉa này, các lớp có thể được cắt tỉa bị hạn chế vì nếu tỷ lệ cắt tỉa trên 0.6 cách cắt tỉa này sẽ thay đổi kiến trúc mạng và độ chính xác đáng kể, điều này bất tiện để khôi phục độ chính xác của các mô hình đã cắt tỉa. Trong [42], họ sử dụng một cách tương tự như tìm kiếm kiến trúc mạng, trong quá trình cắt tỉa, họ tìm kiếm mạng đã cắt tỉa không chỉ xem xét kích thước, độ chính xác của mô hình đã cắt tỉa, mà còn xem xét tính toán của mô hình đã cắt tỉa và chọn mô hình đánh đổi tốt nhất từ 1000 mô hình ứng viên. Để đảm bảo phương pháp cắt tỉa công trình [42] được thực hiện dưới cùng điều kiện phần cứng và môi trường tính toán với các phương pháp cắt tỉa khác (Môi trường thí nghiệm của chúng tôi là Ubuntu 18.04, PyTorch = 1.8 phiên bản,

--- TRANG 20 ---
20 Yun Chu et al.
GPU là một RTX3090 đơn), chúng tôi chọn mô hình tốt nhất chỉ từ năm mô hình ứng viên cắt tỉa, chúng tôi cũng cần tuyên bố rằng phương pháp cắt tỉa tìm kiếm kiến trúc này có hiệu suất tốt hơn khi số lượng mô hình ứng viên nhiều hơn, nhưng tình huống này cũng đưa ra yêu cầu cao hơn về sức mạnh tính toán.

5.4 Chưng cất chú ý không gian nhóm
Trong phần này, chúng tôi sử dụng mạng thưa thớt để tiến hành cắt tỉa kênh nhóm và có được mạng đã cắt tỉa. Độ chính xác của mạng gốc và mạng sau huấn luyện thưa thớt là 87.1 và 79.8, tương ứng.

Trong các thí nghiệm chưng cất, chúng tôi đặt mạng gốc làm mạng giáo viên và mạng đã cắt tỉa làm mạng học sinh, thông tin chú ý không gian được trích xuất chỉ tại các bản đồ đặc trưng quy mô cụ thể từ năm nhóm làm kiến thức, quy mô của các bản đồ đặc trưng là 208 ×208, 104 ×104, 52 ×52, 26× 26 và 13 ×13, tương ứng. Bên cạnh đó, chúng tôi đưa cho hệ số tăng mất mát của năm nhóm βi trọng số khác nhau, chúng tôi đặt β1-β3 là 1000 và β4-β5 là 10000.

5.4.1 Chưng cất chú ý không gian nhóm với phương pháp cắt tỉa của chúng tôi
Để xác minh hiệu quả của chưng cất chú ý không gian nhóm, chúng tôi sử dụng nó cho mô hình đã cắt tỉa với phương pháp cắt tỉa của chúng tôi. Sau đó, chúng tôi tinh chỉnh và chưng cất chú ý nhóm mô hình nén, tương ứng.

Kết quả so sánh được hiển thị trong Bảng 3, mAP@0.5 làm chỉ số đánh giá độ chính xác. Có thể thấy từ Bảng 3 khi tinh chỉnh trực tiếp mạng đã cắt tỉa, độ chính xác cao nhất được khôi phục chỉ có thể đạt 81.1. Ngược lại, sử dụng chưng cất chú ý không gian nhóm có thể làm cho mạng đã cắt tỉa có được độ chính xác cao hơn.

Bảng 3: Kết hợp chưng cất chú ý không gian nhóm với phương pháp cắt tỉa của chúng tôi, Model1-5 đã cắt tỉa đạt được bằng phương pháp cắt tỉa của chúng tôi, độ chính xác đại diện cho Model sau khi thông qua tinh chỉnh và chưng cất chú ý không gian nhóm (ký hiệu là GSA).
Total Model Model SizemAP@0.5
Fine tuning GSA Distilling
38% Model1 98MB 80.4 86.5
40% Model2 90MB 81.1 86.6
42% Model3 84MB 80.5 84.8
45% Model4 77MB 79.5 83.3
50% Model5 68MB 75.9 76.3

5.4.2 Chưng cất chú ý không gian nhóm kết hợp với các phương pháp cắt tỉa phổ biến khác
Để chỉ ra rằng lược đồ chưng cất chú ý không gian nhóm của chúng tôi không chỉ phù hợp với phương pháp cắt tỉa của chúng tôi, chúng tôi kết hợp phương pháp chưng cất chú ý không gian nhóm với các phương pháp cắt tỉa phổ biến khác như Network Slimming [39] và Thinet [38].

--- TRANG 21 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 21
Kết quả so sánh được hiển thị trong Bảng 4 ∼5, có thể thấy từ Bảng 4 ∼5 , khi chúng tôi tinh chỉnh trực tiếp mạng đã cắt tỉa, độ chính xác cao nhất được khôi phục chỉ có thể đạt 80.9. Ngược lại, sử dụng chưng cất chú ý không gian nhóm có thể làm cho mạng đã cắt tỉa có được độ chính xác cao hơn. Bên cạnh đó, kết hợp cắt tỉa kênh nhóm với phương pháp cắt tỉa của chúng tôi có thể đạt được hiệu quả tốt hơn.

Bảng 4: Kết hợp chưng cất chú ý không gian nhóm (ký hiệu là GSA) với phương pháp cắt tỉa Network Sliming [39], Model1-5 đã cắt tỉa đạt được bằng [39] .
Total Model Model SizemAP@0.5
Fine tuning GSA Distilling
38% Model1 100MB 80.4 83.1
40% Model2 94MB 79.8 83.7
42% Model3 86MB 80.4 84.8
45% Model4 78MB 79.6 82.8
50% Model5 65MB 79.3 80.9

Bảng 5: Kết hợp chưng cất chú ý không gian nhóm (ký hiệu là GSA) với phương pháp cắt tỉa Thinet [38], Model1-5 đã cắt tỉa đạt được bằng [38].
Total Model Model SizemAP@0.5
Fine tuning GSA Distilling
38% Model1 116MB 80.9 84.2
40% Model2 110MB 80.4 83.9
42% Model3 104MB 80.9 81.8
45% Model4 96MB 80.7 82.1
50% Model5 83MB 79.4 82.1

5.4.3 So sánh mô hình nén với mạng phát hiện đối tượng khác trên PASCAL và COCO
Để xác minh hiệu quả của mô hình nén cuối cùng của chúng tôi, chúng tôi so sánh mô hình nén cuối cùng với mạng bình thường khác và các bộ phát hiện nhẹ trên PASCAL và COCO, tương ứng.

Kết quả so sánh được hiển thị trong Bảng 6 và Bảng 7, mAP@0.5 và mAP@0.5:0.95 làm chỉ số đánh giá độ chính xác cho tập dữ liệu PASCAL VOC và COCO, tương ứng. Ký hiệu * đại diện cho mô hình nén cuối cùng đã được sử dụng cắt tỉa kênh nhóm, chưng cất chú ý không gian của chúng tôi. Có thể thấy từ bảng trên, phương pháp của chúng tôi có thể đạt được sự đánh đổi tốt nhất giữa độ chính xác của mạng và tính toán hoặc tham số.

5.5 Triển khai trên thiết bị biên
Trong phần này, chúng tôi giới thiệu việc triển khai mô hình đã cắt tỉa trên thiết bị biên-Jetson Nano. Jetson Nano là một máy tính nhỏ, mạnh mẽ cho các ứng dụng nhúng

--- TRANG 22 ---
22 Yun Chu et al.
Bảng 6: So sánh với các bộ phát hiện bình thường và nhẹ trên PASCAL VOC.
Method Backbone Input size Flops Parameters mAP
SSD Lite [33] VGG16 512 ×512 99.5B 36.1M 80.7
SSD Lite [33] MobilenetV2 320 ×320 0.8B 4.3M 71.8
Tiny-DSOD [34] G/32-48-64-801 300 ×300 1.06B 0.95M 72.1
ThunderNet [35] SNet146 416 ×416 0.461B — 73.8
Pelee [36] PeleeNet 304 ×304 1.21B 5.43M 70.9
Ours CSPDarknet* 320 ×320 18.2B 20.9M 82.7
Ours CSPDarknet* 416 ×416 19.3B 20.9M 84.8

Bảng 7: So sánh với các bộ phát hiện bình thường và nhẹ trên COCO.
Method Backbone Input size Flops Parameters mAP(0.5:0.95) mAP(0.5)
SSD [8] VGG16 300 ×300 70.4B 34.3M 25.7 43.9
YOLOV3 [9] Darknet53 416 ×416 65.9B 62.3M 31 55.3
PANet [37] CSPResNeXt50 416 ×416 47.1B 56.9M 36.6 58.1
SSD lite [33] Mobilenet 320 ×320 0.8B 4.3M 22.1 –
ThunderNet [35] SNet146 320 ×320 0.95B — 23.6 40.2
Pelee [36] PeleeNet 304 ×304 2.58B 5.98M 22.4 38.3
Ours CSPDarknet* 320 ×320 18.6B 23.63M 30.2 48.8
Ours CSPDarknet* 416 ×416 19.43B 23.63M 33.4 53.5
tions, nó có 128 lõi NVIDIA CUDA và 4 GB bộ nhớ. Chúng tôi đã triển khai mạng gốc và năm mô hình nén (sử dụng phương pháp cắt tỉa kênh nhóm của chúng tôi) trên thiết bị biên này, và kiểm tra thời gian suy luận của mỗi mô hình.

Các bước triển khai cụ thể như sau: Thứ nhất, trên máy chủ, chúng tôi chuẩn bị tệp mô hình mạng và tệp trọng số tương ứng, sau đó sử dụng PyTorch để chuyển đổi nó thành mô hình định dạng ONNX. Sau đó, trên thiết bị đích-Jetson Nano, chúng tôi sử dụng TensorRT để tạo ra các tệp engine theo mô hình ONNX. Cuối cùng, chúng tôi chạy các tệp engine của năm mô hình nén trên Jetson Nano, và kết quả suy luận được hiển thị trong Bảng 6.

Có thể thấy từ Bảng 8 rằng thời gian suy luận của mô hình mạng gốc cần 414ms và mô hình nén(68M) chỉ cần 274ms. Các thí nghiệm trên cho thấy rằng phương pháp cắt tỉa kênh nhóm được đề xuất có thể được triển khai đến thiết bị biên mà không cần thiết kế phần cứng hoặc phần mềm đặc biệt và có hiệu ứng gia tốc.

Bảng 8: Thời gian suy luận của mô hình đã cắt tỉa trên thiết bị biên-Jeston Nano, độ phân giải đầu vào là 416 ×416.
Model Model Size Inference time
Base 256MB 414 ms
Model1 98MB 311 ms
Model2 90MB 305 ms
Model3 84MB 303 ms
Model4 77MB 291 ms
Model5 68MB 274 ms

--- TRANG 23 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 23

6 Nghiên cứu Ablation
Để chứng minh tính tổng quát và hiệu quả của phương pháp chúng tôi. Trong phần này, chúng tôi đầu tiên sử dụng MobileNet, DarkNet53, và CSPDarknet làm backbone để xây dựng mạng phát hiện. Tiếp theo, chúng tôi giới thiệu các thí nghiệm ablation của huấn luyện thưa thớt động, cắt tỉa kênh nhóm, và chưng cất chú ý không gian. Cuối cùng, chúng tôi kiểm tra mô hình cắt tỉa sau chưng cất.

6.1 Nghiên cứu Ablation cho Huấn luyện Thưa thớt Động
Trong quá trình huấn luyện thưa thớt, chúng tôi đặt tổng số epoch cho huấn luyện thưa thớt và huấn luyện thưa thớt động đều là 200 epoch, tỷ lệ học ban đầu của tất cả mô hình đặt là lr0 = 0 .002 và kích thước của hình ảnh đầu vào là 416 ×416.

Như được hiển thị trong Hình 11, ba hình trên đại diện cho huấn luyện thưa thớt phổ biến và ba hình dưới đại diện cho huấn luyện thưa thớt động cho CSPDarknet-Yolov4. Trong quá trình huấn luyện thưa thớt động, kích thước batch =16, tỷ lệ thưa thớt ban đầu s= 0.00075, khi đến 40 % của tổng số epoch, 70 % của kênh duy trì tỷ lệ thưa thớt ban đầu s, 30 % của kênh tỷ lệ thưa thớt giảm xuống 1 % của tỷ lệ thưa thớt ban đầu s. Có thể thấy từ Hình 11, độ chính xác của mạng thông qua huấn luyện thưa thớt phổ biến là 71.2, trong khi độ chính xác của mạng thông qua huấn luyện thưa thớt động là 79.8. Bên cạnh đó, tỷ lệ thưa thớt ban đầu s cho DarkNet53-Yolov3 và MobileNet-Yolov3 là 0.003 và 0.005, tương ứng. Kích thước batch cho hai mạng này đều là 32.

Bảng 9: Nghiên cứu Ablation cho huấn luyện thưa thớt và huấn luyện thưa thớt động.
Model Sparse training Dynamic Sparse training mAP@0.5 Model-size
CSPDarkNet-Yolov4 ✓ 71.2 256MB
CSPDarkNet-Yolov4 ✓ 79.8 256MB
DarkNet53-Yolov3 ✓ 59.2 246MB
DarkNet53-Yolov3 ✓ 66.5 246MB
MobileNet-Yolov3 ✓ 71.3 95MB
MobileNet-Yolov3 ✓ 72.8 95MB

Đối với MobileNet-Yolov3, DarkNet53-Yolov3, CSPDarknet-Yolov4, chúng có 96, 106, 162 lớp mạng, tương ứng. Có thể thấy từ Bảng 9, độ chính xác của MobileNet-Yolov3, DarkNet53-Yolov3, CSPDarknet-Yolov4 là 72.8, 66.5, 79.8, tương ứng. Với sự gia tăng của số lớp mạng phát hiện, phương pháp huấn luyện thưa thớt động đã đạt được sự đánh đổi tốt hơn giữa độ thưa thớt và độ chính xác so với huấn luyện thưa thớt phổ biến. Bên cạnh đó, khi các lớp mạng ít hơn 100 lớp, chúng tôi nhận thấy rằng tăng kích thước batch cũng có thể cải thiện sự đánh đổi giữa độ thưa thớt và độ chính xác.

6.2 Nghiên cứu Ablation cho Cắt tỉa Kênh Nhóm
Trong các thí nghiệm cắt tỉa kênh nhóm, chúng tôi chọn mô hình huấn luyện thưa thớt động làm mạng cần được cắt tỉa và sử dụng cùng tỷ lệ cắt tỉa cho

--- TRANG 24 ---
24 Yun Chu et al.
(a) Hình 1
 (b) Hình 2
(c) hình 3
 (d) hình 4
Hình 11: Hai hình trên cho thấy quá trình huấn luyện thưa thớt phổ biến(tỷ lệ thưa thớt ổn định s) và hai hình dưới cho thấy quá trình huấn luyện thưa thớt động(tỷ lệ thưa thớt biến đổi s). (a), (c) đại diện cho độ chính xác của mạng thay đổi theo các epoch huấn luyện và (b), (d) đại diện cho phân phối hệ số γ thay đổi theo các epoch huấn luyện.
cắt tỉa phổ biến và cắt tỉa kênh nhóm. Đối với CSPDarknet-Yolov4, tỷ lệ cắt tỉa là 40 %. Đối với DarkNet53-Yolov3 và MobileNet-Yolov3, tỷ lệ cắt tỉa là 64 % và 65 %, tương ứng.

Bảng 10: Nghiên cứu Ablation cho cắt tỉa phổ biến [39] và cắt tỉa kênh nhóm
Model Pruning Group channel pruning mAP@0.5 Model-size
CSPDarkNet-Yolov4 ✓ 48.5 94 MB
CSPDarkNet-Yolov4 ✓ 56.2 90 MB
DarkNet53-Yolov3 ✓ 60.9 62 MB
DarkNet53-Yolov3 ✓ 65.2 21 MB
MobileNet-Yolov3 ✓ 71.3 17 MB
MobileNet-Yolov3 ✓ 72.2 15 MB

Có thể thấy từ Bảng 10, so với phương pháp cắt tỉa phổ biến [39], phương pháp cắt tỉa kênh nhóm của chúng tôi có thể đạt được sự cân bằng tốt hơn giữa kích thước và độ chính xác của mô hình cho các mạng phát hiện khác nhau.

--- TRANG 25 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 25

6.3 Nghiên cứu Ablation cho Chưng cất Chú ý Không gian Nhóm
Trong các thí nghiệm không gian nhóm, chúng tôi chọn mạng gốc làm mạng giáo viên, mạng đã cắt tỉa (thông qua phương pháp cắt tỉa kênh nhóm) làm mạng học sinh.

Đối với CSPDarknet-Yolov4 và Mobilenet-Yolov3, chúng tôi trích xuất thông tin chú ý không gian tại các bản đồ đặc trưng quy mô cụ thể từ năm nhóm làm kiến thức, quy mô của các bản đồ đặc trưng là 208 ×208, 104 ×104, 52 ×52, 26×26 và 13 ×13, tương ứng. Đối với Darknet53-Yolov3, chúng tôi trích xuất thông tin chú ý không gian tại 104 ×104, 52 ×52, 26×26, và 13 ×13 quy mô bản đồ đặc trưng từ năm nhóm.

Bảng 11: Nghiên cứu Ablation cho tinh chỉnh và Chưng cất Chú ý Không gian Nhóm (ký hiệu là GSA)
Model Fine tune GSA Distilling mAP@0.5 Model-size
CSPDarkNet-Yolov4 ✓ 81.1 90 MB
CSPDarkNet-Yolov4 ✓ 86.6 90 MB
DarkNet53-Yolov3 ✓ 66.8 22 MB
DarkNet53-Yolov3 ✓ 68.2 22 MB
MobileNet-Yolov3 ✓ 72.1 15 MB
MobileNet-Yolov3 ✓ 73.2 15 MB

Như được hiển thị trong Bảng 11, so với tinh chỉnh mạng đã cắt tỉa, chưng cất chú ý không gian nhóm có thể đạt được độ chính xác tốt hơn cho các mạng phát hiện khác nhau.

Ngoài ra, chúng tôi chứng minh định tính hiệu quả của mạng đã cắt tỉa thông qua chưng cất chú ý không gian nhóm. Như được hiển thị trong Hình 13, (a),(b),(c) hiển thị kết quả phát hiện CSPDarknet-Yolov4, DarkNet53-Yolov3, MobileNet-Yolov3 gốc, tương ứng. Và (d),(e),(f) hiển thị kết quả phát hiện của mạng đã cắt tỉa.

7 Kết luận
Trong bài báo này, chúng tôi trình bày một cách tiếp cận nén mô hình ba giai đoạn cho mạng phát hiện đối tượng, đó là huấn luyện thưa thớt động, cắt tỉa kênh nhóm, và chưng cất chú ý không gian. Thứ nhất, chúng tôi giới thiệu huấn luyện thưa thớt động để chọn ra các kênh không đáng kể trong các lớp và duy trì sự cân bằng tốt về độ thưa thớt và độ chính xác của mạng. Tiếp theo, chúng tôi đề xuất một phương pháp cắt tỉa kênh nhóm. Dưới cùng tỷ lệ cắt tỉa, phương pháp cắt tỉa nhóm của chúng tôi có ít ảnh hưởng đến độ chính xác của mạng và có thể có được nén mô hình đáng kể so với các phương pháp cắt tỉa khác. Sau đó, chúng tôi trích xuất thông tin chú ý không gian của mỗi nhóm làm kiến thức cho chưng cất. So với tinh chỉnh trực tiếp mô hình đã cắt tỉa, phương pháp chưng cất chú ý không gian nhóm của chúng tôi có thể khôi phục mạng đã cắt tỉa đến độ chính xác cao hơn. Hơn nữa, chúng tôi triển khai mô hình nén trên thiết bị biên Jetson Nano để chứng minh rằng phương pháp của chúng tôi có thể được triển khai trực tiếp mà không cần hỗ trợ phần cứng hoặc phần mềm đặc biệt và

--- TRANG 26 ---
26 Yun Chu et al.
(a) Hình 1
 (b) Hình 2
 (c) Hình 3
(d) Hình 4
 (e) Hình 5
 (f) Hình 6
Hình 12: Ba hình trên hiển thị kết quả phát hiện của mạng CSPDarkNet-Yolov4(a), DarkNet-Yolov3(b), MobileNet-Yolov3(c) gốc, và ba hình dưới hiển thị kết quả phát hiện của mạng CSPDarkNet-Yolov4(d), DarkNet-Yolov3(e), MobileNet-Yolov3(f) đã cắt tỉa.
có thể đạt được hiệu ứng gia tốc. Để chứng minh tính tổng quát và hiệu quả của cách tiếp cận được đề xuất của chúng tôi, trong các thí nghiệm của chúng tôi, chúng tôi thay thế backbone thành MobileNet, DarkNet53, và CSPDarknet để xây dựng mạng phát hiện và sau đó sử dụng các phương pháp được đề xuất của chúng tôi, kết quả thí nghiệm là thỏa mãn. Chúng tôi tin rằng phương pháp luận và cách tiếp cận được đề xuất có triển vọng được đánh giá để nén các mạng phát hiện đối tượng khác.

Lời cảm ơn Công trình này được hỗ trợ một phần bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc dưới Grant 61961014, 61963012 và Quỹ Khoa học Tự nhiên Tỉnh Hainan Trung Quốc dưới Grant 620RC556, 620RC564.

Tài liệu tham khảo
1. D. P. Sullivan, C. F. Winsnes, L. ˚Akesson, M. Hjelmare, M. Wiking, R. Schutten, L. Campbell, H. Leifsson, S. Rhodes, A. Nordgren, etal., "Deep learning is combined with massive-scale citizen science to improve large-scale image classification," Nature biotechnology, vol. 36, no. 9, pp. 820–828, 2018.
2. L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen, X. Liu, and M. Pietik¨ ainen, "Deep learning for generic object detection: A survey," International journal ofcomputer vision, vol. 128, no. 2, pp. 261–318, 2020.

--- TRANG 27 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 27
3. F. Sultana, A. Sufian, and P. Dutta, "Evolution of image segmentation using deep convolutional neural network: a survey," Knowledge-Based Systems, vol. 201, p. 106062, 2020.
4. A. Krizhevsky, I. Sutskever, and G. E. Hinton, "Imagenet classification with deep convolutional neural networks," Communications oftheACM, vol. 60, no. 6, pp. 84–90, 2017.
5. K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for image recognition," in Proceedings oftheIEEE conference oncomputer vision andpattern recognition, pp. 770–778, 2016.
6. A. Howard, A. Zhmoginov, L.-C. Chen, M. Sandler, and M. Zhu, "Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation," 2018.
7. S. Ren, K. He, R. Girshick, and J. Sun, "Faster r-cnn: towards real-time object detection with region proposal networks," IEEE transactions onpattern analysis andmachine intelligence, vol. 39, no. 6, pp. 1137–1149, 2016.
8. W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A. C. Berg, "Ssd: Single shot multibox detector," in European conference oncomputer vision, pp. 21–37, Springer, 2016.
9. A. Farhadi and J. Redmon, "Yolov3: An incremental improvement," in Computer Vision andPattern Recognition, pp. 1804–02767, 2018.
10. A. Bochkovskiy, C.-Y. Wang, and H.-Y. M. Liao, "Yolov4: Optimal speed and accuracy of object detection," arXiv preprint arXiv:2004.10934, 2020.
11. S. Han, X. Liu, H. Mao, J. Pu, A. Pedram, M. A. Horowitz, and W. J. Dally, "Eie: Efficient inference engine on compressed deep neural network," ACM SIGARCH Computer Architecture News, vol. 44, no. 3, pp. 243–254, 2016.
12. N. Rathi, P. Panda, and K. Roy, "Stdp-based pruning of connections and weight quantization in spiking neural networks for energy-efficient recognition," IEEE Transactions on Computer-Aided Design ofIntegrated Circuits andSystems, vol. 38, no. 4, pp. 668–677, 2018.
13. N. Abderrahmane, E. Lemaire, and B. Miramond, "Design space exploration of hardware spiking neurons for embedded artificial intelligence," Neural Networks, vol. 121, pp. 366–386, 2020.
14. J.-H. Luo and J. Wu, "Autopruner: An end-to-end trainable filter pruning method for efficient deep model inference," Pattern Recognition, vol. 107, p. 107461, 2020.
15. F. E. Fernandes Jr and G. G. Yen, "Pruning deep convolutional neural networks architectures with evolution strategy," Information Sciences, vol. 552, pp. 29–47, 2021.
16. Y. Cheng, M. Lin, J. Wu, H. Zhu, and X. Shao, "Intelligent fault diagnosis of rotating machinery based on continuous wavelet transform-local binary convolutional neural network," Knowledge-Based Systems, vol. 216, p. 106796, 2021.
17. L. Deng, P. Jiao, J. Pei, Z. Wu, and G. Li, "Gxnor-net: Training deep neural networks with ternary weights and activations without full-precision memory under a unified discretization framework," Neural Networks, vol. 100, pp. 49–58, 2018.
18. F. Tung and G. Mori, "Deep neural network compression by in-parallel pruning-quantization," IEEE transactions onpattern analysis andmachine intelligence, vol. 42, no. 3, pp. 568–579, 2018.
19. P. Hu, X. Peng, H. Zhu, M. M. S. Aly, and J. Lin, "Opq: Compressing deep neural networks with one-shot pruning-quantization," in Proceedings oftheThirty-Fifth AAAI Conference onArtificial Intelligence (AAAI-21), Vancouver, VN, Canada, pp. 2–9, 2021.
20. G. Hinton, O. Vinyals, and J. Dean, "Distilling the knowledge in a neural network," stat, vol. 1050, p. 9, 2015.
21. T.-B. Xu, P. Yang, X.-Y. Zhang, and C.-L. Liu, "Lightweightnet: Toward fast and lightweight convolutional neural networks via architecture distillation," Pattern Recognition, vol. 88, pp. 272–284, 2019.
22. H. Zhang, Z. Hu, W. Qin, M. Xu, and M. Wang, "Adversarial co-distillation learning for image recognition," Pattern Recognition, vol. 111, p. 107659, 2021.
23. D. Song, J. Xu, J. Pang, and H. Huang, "Classifier-adaptation knowledge distillation framework for relation extraction and event detection with imbalanced data," Information Sciences, vol. 573, pp. 222–238, 2021.
24. Z.-R. Wang and J. Du, "Joint architecture and knowledge distillation in cnn for chinese text recognition," Pattern Recognition, vol. 111, p. 107722, 2021.
25. Z. Li, Y. Ming, L. Yang, and J.-H. Xue, "Mutual-learning sequence-level knowledge distillation for automatic speech recognition," Neurocomputing, vol. 428, pp. 259–267, 2021.
26. P. Shen, X. Lu, S. Li, and H. Kawai, "Knowledge distillation-based representation learning for short-utterance spoken language identification," IEEE/ACM Transactions onAudio, Speech, andLanguage Processing, vol. 28, pp. 2674–2683, 2020.

--- TRANG 28 ---
28 Yun Chu et al.
27. M. Yang, Y. Li, Z. Huang, Z. Liu, P. Hu, and X. Peng, "Partially view-aligned representation learning with noise-robust contrastive loss," in Proceedings oftheIEEE/CVF Conference onComputer Vision andPattern Recognition, pp. 1134–1143, 2021.
28. H. Ibrahem, A. D. A. Salem, and H.-S. Kang, "Real-time weakly supervised object detection using center-of-features localization," IEEE Access, vol. 9, pp. 38742–38756, 2021.
29. Q. Zhou, J. Wang, J. Liu, S. Li, W. Ou, and X. Jin, "Rsanet: Towards real-time object detection with residual semantic-guided attention feature pyramid network," Mobile Networks andApplications, vol. 26, no. 1, pp. 77–87, 2021.
30. Q. Zhou, X. Wu, S. Zhang, B. Kang, Z. Ge, and L. J. Latecki, "Contextual ensemble network for semantic segmentation," Pattern Recognition, vol. 122, p. 108290, 2022.
31. Q. Zhou, Y. Wang, Y. Fan, X. Wu, S. Zhang, B. Kang, and L. J. Latecki, "Aglnet: Towards real-time semantic segmentation of self-driving images via attention-guided lightweight network," Applied SoftComputing, vol. 96, p. 106682, 2020.
32. S.-W. Kim, K. Ko, H. Ko, and V. C. Leung, "Edge-network-assisted real-time object detection framework for autonomous driving," IEEE Network, vol. 35, no. 1, pp. 177–183, 2021.
33. M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, "Mobilenetv2: Inverted residuals and linear bottlenecks," 2019.
34. Y. Li, J. Li, W. Lin, and J. Li, "Tiny-dsod: Lightweight object detection for resource-restricted usages,"
35. Z. Qin, Z. Li, Z. Zhang, Y. Bao, G. Yu, Y. Peng, and J. Sun, "Thundernet: Towards real-time generic object detection on mobile devices," in Proceedings oftheIEEE/CVF International Conference onComputer Vision, pp. 6718–6727, 2019.
36. R. J. Wang, X. Li, and C. X. Ling, "Pelee: A real-time object detection system on mobile devices," Advances inNeural Information Processing Systems, vol. 31, pp. 1963–1972, 2018.
37. S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, "Path aggregation network for instance segmentation,"
38. J.-H. Luo, J. Wu, and W. Lin, "Thinet: A filter level pruning method for deep neural network compression," in Proceedings oftheIEEE international conference oncomputer vision, pp. 5058–5066, 2017.
39. Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, and C. Zhang, "Learning efficient convolutional networks through network slimming," in Proceedings oftheIEEE international conference oncomputer vision, pp. 2736–2744, 2017.
40. A. Jordao, M. Lie, and W. R. Schwartz, "Discriminative layer pruning for convolutional neural networks," IEEE Journal ofSelected Topics inSignal Processing, vol. 14, no. 4, pp. 828–837, 2020.
41. Z. Liu, M. Sun, T. Zhou, G. Huang, and T. Darrell, "Rethinking the value of network pruning," in International Conference onLearning Representations, 2018.
42. B. Li, B. Wu, J. Su, and G. Wang, "Eagleeye: Fast sub-net evaluation for efficient neural network pruning," in European Conference onComputer Vision, pp. 639–654, Springer, 2020.
43. J. Zhou, S. Zeng, and B. Zhang, "Two-stage knowledge transfer framework for image classification," Pattern Recognition, vol. 107, p. 107529, 2020.
44. J.-W. Jung, H.-S. Heo, H.-J. Shim, and H.-J. Yu, "Knowledge distillation in acoustic scene classification," IEEE Access, vol. 8, pp. 166870–166879, 2020.
45. G. Chen, X. Zhang, X. Tan, Y. Cheng, F. Dai, K. Zhu, Y. Gong, and Q. Wang, "Training small networks for scene classification of remote sensing images via knowledge distillation," Remote Sensing, vol. 10, no. 5, p. 719, 2018.
46. G. Chen, W. Choi, X. Yu, T. Han, and M. Chandraker, "Learning efficient object detection models with knowledge distillation," Advances inneural information processing systems, vol. 30, 2017.
47. N. Komodakis and S. Zagoruyko, "Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer," in ICLR, 2017.
48. Y. Liu, X. Jia, M. Tan, R. Vemulapalli, Y. Zhu, B. Green, and X. Wang, "Search to distill: Pearls are everywhere but not the eyes," in Proceedings oftheIEEE/CVF Conference on Computer Vision andPattern Recognition, pp. 7539–7548, 2020.
49. S. Santurkar, D. Tsipras, A. Ilyas, and A. Mdry, "How does batch normalization help optimization," in Proceedings ofthe32nd international conference onneural information processing systems, pp. 2488–2498, 2018.

--- TRANG 29 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 29
50. R. Dasgupta, Y. S. Chowdhury, and S. Nanda, "Performance comparison of benchmark activation function relu, swish and mish for facial mask detection using convolutional neural network," in Intelligent Systems, pp. 355–367, Springer, 2021.
51. Y. Liu, X. Wang, L. Wang, and D. Liu, "A modified leaky relu scheme (mlrs) for topology optimization with multiple materials," Applied Mathematics andComputation, vol. 352, pp. 188–204, 2019.
52. Z. Huang, J. Wang, X. Fu, T. Yu, Y. Guo, and R. Wang, "Dc-spp-yolo: Dense connection and spatial pyramid pooling based yolo for object detection," Information Sciences, vol. 522, pp. 241–258, 2020.
53. M. Everingham, S. A. Eslami, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman, "The pascal visual object classes challenge: A retrospective," International journal ofcomputer vision, vol. 111, no. 1, pp. 98–136, 2015.
54. R. Padilla, S. L. Netto, and E. A. da Silva, "A survey on performance metrics for object-detection algorithms," in 2020 International Conference onSystems, Signals andImage Processing (IWSSIP), pp. 237–242, IEEE, 2020.

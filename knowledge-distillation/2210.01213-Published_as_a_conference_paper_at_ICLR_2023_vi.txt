# 2210.01213.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-distillation/2210.01213.pdf
# Kích thước tệp: 15875853 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
CHƯNG CẤT TÍCH CỰC BỀN VỮNG
Cenk Baykal, Khoa Trinh, Fotis Iliopoulos, Gaurav Menghani, Erik Vee
Google Research
{baykalc,khoatrinh,fotisi,gmenghani,erikvee}@google.com
TÓM TẮT
Chưng cất kiến thức từ một mô hình giáo viên lớn sang một mô hình nhẹ là một phương pháp rộng rãi thành công để tạo ra các mô hình nhỏ gọn, mạnh mẽ trong bối cảnh học bán giám sát nơi có một lượng dữ liệu có nhãn hạn chế. Tuy nhiên, trong các ứng dụng quy mô lớn, giáo viên có xu hướng cung cấp một số lượng lớn các nhãn mềm không chính xác làm suy giảm hiệu suất của học sinh. Kích thước khổng lồ của giáo viên cũng hạn chế số lượng nhãn mềm có thể được truy vấn do chi phí tính toán và/hoặc tài chính cấm đoán. Khó khăn trong việc đạt được hiệu quả đồng thời (tức là tối thiểu hóa các truy vấn nhãn mềm) và độ bền vững (tức là tránh sự không chính xác của học sinh do nhãn không chính xác) cản trở việc ứng dụng rộng rãi chưng cất kiến thức vào nhiều nhiệm vụ hiện đại. Trong bài báo này, chúng tôi trình bày một phương pháp không có tham số với các đảm bảo có thể chứng minh để truy vấn các nhãn mềm của các điểm vừa có thông tin và được gán nhãn chính xác bởi giáo viên. Cốt lõi của công việc chúng tôi là một công thức lý thuyết trò chơi xem xét rõ ràng sự đánh đổi cố hữu giữa tính thông tin và tính chính xác của các thể hiện đầu vào. Chúng tôi thiết lập các giới hạn về hiệu suất mong đợi của phương pháp chúng tôi giữ nguyên ngay cả trong các trường hợp chưng cất tồi tệ nhất. Chúng tôi trình bày các đánh giá thực nghiệm trên các điểm chuẩn phổ biến chứng minh hiệu suất chưng cất được cải thiện do công việc chúng tôi tạo ra so với các phương pháp học tích cực và chưng cất tích cực tiên tiến.

1 GIỚI THIỆU
Các mô hình mạng nơ-ron sâu đã thành công chưa từng có trong nhiều lĩnh vực ứng dụng có tác động cao như Xử lý Ngôn ngữ Tự nhiên (Ramesh et al., 2021; Brown et al., 2020) và Thị giác Máy tính (Ramesh et al., 2021; Niemeyer & Geiger, 2021). Tuy nhiên, điều này đã đến với chi phí sử dụng các bộ dữ liệu có nhãn ngày càng lớn và các mô hình mạng dung lượng cao có xu hướng chứa hàng tỷ tham số (Devlin et al., 2018). Những mô hình này thường có chi phí cấm đoán để sử dụng cho suy luận và yêu cầu hàng triệu đô la trong tính toán để đào tạo (Patterson et al., 2021). Kích thước khổng lồ của chúng cũng ngăn cản việc sử dụng trong các ứng dụng quan trọng về thời gian nơi các quyết định nhanh phải được đưa ra, ví dụ: lái xe tự động, và triển khai đến các nền tảng bị hạn chế tài nguyên, ví dụ: điện thoại di động và các hệ thống nhúng nhỏ (Baykal et al., 2022). Để giảm bớt những vấn đề này, một lượng lớn công việc gần đây trong học máy đã tập trung vào các phương pháp tạo ra các mô hình mạng nhỏ gọn, mạnh mẽ mà không cần các bộ dữ liệu có nhãn khổng lồ.

Chưng cất Kiến thức (KD) (Buciluǎ et al., 2006; Hinton et al., 2015; Gou et al., 2021; Beyer et al., 2021) là một phương pháp đa năng đã cho thấy triển vọng trong việc tạo ra các mô hình mạnh mẽ nhẹ ngay cả khi có một lượng dữ liệu có nhãn hạn chế (Chen et al., 2020). Ý tưởng chính là sử dụng một mô hình giáo viên lớn được đào tạo trên các ví dụ có nhãn để đào tạo một mô hình học sinh nhỏ gọn để các dự đoán của nó bắt chước những của giáo viên. Tiền đề là ngay cả một học sinh nhỏ cũng đủ khả năng để đại diện cho các giải pháp phức tạp, mặc dù nó có thể thiếu những thiên kiến quy nạp để học phù hợp các biểu diễn từ dữ liệu hạn chế một mình (Stanton et al., 2021; Menon et al., 2020). Trong thực tế, KD thường dẫn đến các mô hình dự đoán đáng kể hơn so với có thể bằng cách đào tạo riêng lẻ (Chen et al., 2020; Xie et al., 2020; Gou et al., 2021; Cho & Hariharan, 2019).

Chưng cất Kiến thức gần đây đã được sử dụng để có được kết quả tiên tiến trong bối cảnh bán giám sát nơi có một số lượng nhỏ ví dụ có nhãn và một số lượng lớn ví dụ không có nhãn (Chen et al., 2020; Pham et al., 2021; Xie et al., 2020). KD bán giám sát bao gồm việc đào tạo một mô hình giáo viên trên tập có nhãn và sử dụng các nhãn mềm của nó trên dữ liệu không có nhãn để đào tạo học sinh. Giáo viên thường là một mô hình được đào tạo trước và cũng có thể là một mô hình lớn chung như GPT-3 (Brown et al., 2020)

1arXiv:2210.01213v2  [cs.LG]  4 Feb 2023

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
hoặc PaLM (Chowdhery et al., 2022). Tiền đề là một mô hình giáo viên lớn có thể trích xuất kiến thức và học từ một bộ dữ liệu có nhãn một cách thích hợp hơn, sau đó có thể được chưng cất vào một học sinh nhỏ.

Mặc dù có thành công rộng rãi, KD thường gặp phải các mức độ khác nhau của thiên kiến xác nhận và kém hiệu quả trong các ứng dụng hiện đại cho học bán giám sát. Thiên kiến xác nhận (Pham et al., 2021; Liu & Tan, 2021; Arazo et al., 2020; Beyer et al., 2021) là hiện tượng mà học sinh thể hiện hiệu suất kém do đào tạo trên các nhãn mềm của giáo viên nhiễu hoặc không chính xác. Ở đây, sự không chính xác đề cập đến sự không nhất quán giữa các dự đoán của giáo viên cho các đầu vào không có nhãn và nhãn thực tế của chúng. Việc cung cấp cho học sinh các nhãn mềm không chính xác dẫn đến tăng độ tin cậy trong các dự đoán không chính xác, điều này kết quả là tạo ra một mô hình có xu hướng chống lại các thay đổi mới và thực hiện kém tổng thể (Liu & Tan, 2021; Arazo et al., 2020). Đồng thời, các ứng dụng quy mô lớn thường yêu cầu các dự đoán của giáo viên cho hàng tỷ điểm không có nhãn. Ví dụ, xem xét việc chưng cất kiến thức từ GPT-3 để đào tạo một mô hình học sinh mạnh mẽ. Tính đến thời điểm viết bài này, OpenAI tính phí 6 cent cho mỗi 1k dự đoán token (OpenAI, 2022). Giả sử chỉ 1M ví dụ để gán nhãn và trung bình 100 token mỗi ví dụ dẫn đến tổng chi phí $6M. Do đó, rất mong muốn có được các nhãn mềm hữu ích nhất - tức là có thông tin và chính xác - tuân theo ngân sách gán nhãn (lời gọi API GPT-3) để có được mô hình học sinh mạnh mẽ nhất cho ứng dụng mục tiêu.

Do đó, việc phát triển các phương pháp KD vừa hiệu quả truy vấn vừa bền vững với các sự không chính xác gán nhãn đã trở nên ngày càng quan trọng. Công việc trước đó trong lĩnh vực này bị hạn chế trong việc giải quyết hoặc là hiệu quả chưng cất (Liang et al., 2022; Xu et al., 2020), bằng cách kết hợp mix-up (Zhang et al., 2017) và lấy mẫu dựa trên độ không chắc chắn (Roth & Small, 2006), hoặc độ bền vững (Pham et al., 2021; Liu & Tan, 2021; Arazo et al., 2020; Zheng et al., 2021; Zhang et al., 2020), thông qua các chiến lược đào tạo và trọng số khéo léo, nhưng không phải cả hai mục tiêu này cùng một lúc. Trong bài báo này, chúng tôi trình bày một phương pháp đơn giản để thực hiện tìm một điểm phù hợp và cải thiện so với các kỹ thuật tiêu chuẩn. Có liên quan, đã có công việc trước đó trong học dưới nhiễu nhãn (xem Song et al. (2022) để có một khảo sát), tuy nhiên, những công việc này thường giả định rằng các nhãn nhiễu có sẵn (tức là không có thành phần học tích cực) hoặc áp đặt các giả định về loại nhiễu nhãn (Younesian et al., 2021). Ngược lại, chúng tôi giả định rằng nhiễu nhãn có thể hoàn toàn đối nghịch và chúng tôi không có quyền truy cập đầy đủ ngay cả vào các nhãn nhiễu.

Theo hiểu biết tốt nhất của chúng tôi, công việc này là đầu tiên xem xét vấn đề lấy mẫu quan trọng để đồng thời đạt hiệu quả và độ bền vững trong chưng cất kiến thức. Để thu hẹp khoảng cách nghiên cứu này, chúng tôi trình bày một thuật toán hiệu quả với các đảm bảo có thể chứng minh để xác định các điểm không có nhãn với các nhãn mềm có xu hướng vừa có thông tin vừa chính xác. Phương pháp của chúng tôi không có tham số, không áp đặt giả định về cài đặt vấn đề, và có thể được ứng dụng rộng rãi cho bất kỳ kiến trúc mạng và bộ dữ liệu nào. Cốt lõi của nó là việc công thức hóa một vấn đề tối ưu hóa đồng thời nắm bắt các mục tiêu hiệu quả và độ bền vững một cách thích hợp. Cụ thể, bài báo này đóng góp:

1. Một công thức vấn đề toán học nắm bắt mục tiêu chung của việc đào tạo trên các nhãn mềm có thông tin được gán nhãn chính xác bởi giáo viên theo cách hiệu quả truy vấn
2. Một thuật toán thời gian gần tuyến tính, không có tham số để giải quyết tối ưu
3. Kết quả thực nghiệm trên các bộ dữ liệu điểm chuẩn và kiến trúc với các cấu hình khác nhau chứng minh hiệu quả được cải thiện của phương pháp chúng tôi so với tiên tiến
4. Các đánh giá thực nghiệm rộng rãi hỗ trợ khả năng ứng dụng rộng rãi và độ bền vững của phương pháp chúng tôi đối với các tình huống và ràng buộc do người thực hành áp đặt khác nhau.

2 PHÁT BIỂU VẤN ĐỀ

Chúng tôi xem xét bối cảnh phân loại bán giám sát nơi chúng tôi được cho một tập có nhãn nhỏ XL - thường là hàng chục hoặc hàng trăm nghìn ví dụ - cùng với một tập không có nhãn lớn XU, thường ở bậc hàng triệu hoặc hàng tỷ. Mục tiêu là tận dụng cả tập có nhãn và không có nhãn để đào tạo hiệu quả và đáng tin cậy một mô hình học sinh nhỏ gọn, mạnh mẽ. Để làm điều này, chúng tôi sử dụng chưng cất kiến thức (Xie et al., 2020; Liang et al., 2020) nơi các điểm có nhãn được sử dụng để đào tạo một mô hình giáo viên lớn hơn, (thường được đào tạo trước) sau đó có thể được sử dụng để giáo dục một mô hình nhỏ (học sinh). Chúng tôi nhấn mạnh rằng giáo viên có thể là một mô hình được đào tạo trước, tuy nhiên, nó không được đào tạo trên tập không có nhãn XU. Quá trình chưng cất bao gồm việc sử dụng các nhãn mềm của giáo viên cho các điểm không có nhãn. Học sinh sau đó được đào tạo trên những điểm có nhãn mềm này cùng với bộ dữ liệu có nhãn gốc. Hiểu biết chính là mô hình giáo viên lớn, được đào tạo trước có thể học các biểu diễn từ dữ liệu hạn chế một cách thích hợp hơn, sau đó có thể được bắt chước bởi học sinh.

2

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Một cách chính thức hơn, chúng tôi được cho hai tập đầu vào XL;XU được rút độc lập và ngẫu nhiên từ không gian đầu vào X ⊆ Rd. Chúng tôi giả định rằng chúng tôi có quyền truy cập vào các nhãn cứng YL ∈ {0,1}k cho các thể hiện trong XL, nhưng không có những cái trong XU và |XL| ≪ |XU|. Phù hợp với các ứng dụng ML hiện đại, chúng tôi giả định rằng một bộ dữ liệu xác thực của các điểm có nhãn có sẵn. Chúng tôi sẽ sử dụng một sự lạm dụng nhẹ trong ký hiệu và đề cập đến tập dữ liệu có nhãn như (XL,YL) để biểu thị tập các cặp (x,y) có nhãn. Chúng tôi giả định các ứng dụng quy mô lớn của KD nơi giáo viên cực kỳ lớn đến mức truy vấn nhãn mềm giáo viên fteacher(x) ∈ [0,1]k cho một điểm không có nhãn x ∈ XU là tốn kém và gán nhãn mềm cho tất cả XU là không khả thi. Trong phần sau, chúng tôi giới thiệu và thúc đẩy chưng cất tích cực bền vững để thực hiện quá trình này một cách hiệu quả và đáng tin cậy.

2.1 CHƯNG CẤT TÍCH CỰC

Mục tiêu của chưng cất tích cực là truy vấn số lượng tối thiểu các nhãn mềm giáo viên cho các điểm trong XU để đào tạo một mô hình học sinh hiệu suất cao fstudent theo cách hiệu quả tính toán và tài chính. Quá trình này được hiển thị trong Alg. 1. Ở đây, chúng tôi thực hiện T lần lặp chưng cất tích cực sau khi đào tạo các mô hình học sinh và giáo viên trên tập đào tạo P, ban đầu chỉ bao gồm tập các điểm có nhãn cứng. Trên Dòng 8 và xuyên suốt, f(x) ∈ [0,1]k biểu thị đầu ra softmax của một mô hình mạng nơ-ron đối với đầu vào x. Tại mỗi lần lặp (Dòng 5-10, Alg. 1), chúng tôi sử dụng một thuật toán truy vấn được cho, SELECT, để xác định b điểm không có nhãn hữu ích nhất để gán nhãn mềm bởi giáo viên dựa trên mô hình học sinh cập nhật nhất ft-1 (Dòng 6). Các điểm được chọn sau đó được gán nhãn mềm bởi giáo viên và thêm vào tập đào tạo (mở rộng) P. Sau đó, học sinh được đào tạo bằng cách sử dụng Phân kỳ Kullback-Leibler (KL) (Hinton et al., 2015) làm hàm mất mát trên tập đào tạo P bao gồm cả các điểm có nhãn cứng (XL,YL) và những cái có nhãn mềm tích lũy. Chúng tôi tuân theo quy ước tiêu chuẩn trong học tích cực (Ren et al., 2021) và chưng cất hiệu quả (Liang et al., 2020; Xu et al., 2020) và đào tạo mô hình học sinh từ đầu trên Dòng 9.

Thuật toán 1 CHƯNG CẤT TÍCH CỰC
Đầu vào: một tập các điểm có nhãn (XL,YL), một tập các điểm không có nhãn XU, số lượng điểm để gán nhãn mềm mỗi lần lặp b ∈ N+, và một thuật toán lựa chọn SELECT(X,·,b) chọn một mẫu kích thước b từ X
1: P ← (XL,YL); {Tập đào tạo cho đến nay; ban đầu chỉ các điểm có nhãn cứng}
2: fteacher ← TRAIN(P,θrandom_teacher); {Đào tạo giáo viên trên dữ liệu có nhãn bắt đầu từ khởi tạo ngẫu nhiên}
3: f0 ← TRAIN(P,θrandom_student); {Đào tạo học sinh trên dữ liệu có nhãn bắt đầu từ khởi tạo ngẫu nhiên}
4: S ← ∅; {Tập các đầu vào đã được gán nhãn mềm}
5: for t ∈ {1,...,T} do
6:    St ← SELECT(XU \ S,ft-1,b) {Chọn b điểm để được gán nhãn mềm bởi giáo viên}
7:    S ← S ∪ St {Thêm các điểm mới để chúng tôi không lấy mẫu chúng lại}
8:    P ← P ∪ {(x,fteacher(x)) : x ∈ St} {Gán nhãn mềm các điểm và thêm chúng vào tập đào tạo}
9:    ft ← TRAIN(P,θrandom_student) {Đào tạo mạng với các điểm có nhãn mềm bổ sung từ đầu}
10: end for
11: return fT

Vấn đề chưng cất tích cực có liên quan sâu sắc đến vấn đề học tích cực, nơi mục tiêu là truy vấn các nhãn chỉ của những điểm có thông tin nhất để tối thiểu hóa chi phí gán nhãn. Để đạt được điều này, các phương pháp trước đó trong KD hiệu quả (Xu et al., 2020; Liang et al., 2020) đã đề xuất các phương pháp được lấy cảm hứng từ lấy mẫu dựa trên biên (Balcan et al., 2007; Roth & Small, 2006), một thuật toán học tích cực phổ biến và được sử dụng rộng rãi (Ren et al., 2021). Lấy mẫu dựa trên biên là một ví dụ của lấy mẫu dựa trên độ không chắc chắn, các ví dụ khác là lựa chọn dựa trên phân cụm (Sener & Savarese, 2017; Ash et al., 2019), độ không chắc chắn mô hình (Gal et al., 2017), và gần đúng đối nghịch (Ducoffe & Precioso, 2018) (xem (Ren et al., 2021) cho một khảo sát). Trong phần sau, chúng tôi xem xét lấy mẫu dựa trên biên do tính đơn giản và ứng dụng trước đó vào chưng cất hiệu quả bởi công việc liên quan (Liang et al., 2020; Xu et al., 2020). Lấy mẫu dựa trên biên cho KD là một ý tưởng trực quan và đơn giản để thực hiện nơi các dự đoán giáo viên cho các đầu vào mà học sinh không chắc chắn nhất được truy vấn. Đối với một đầu vào x và dự đoán i* = argmaxi∈[k] fstudent(x)i, độ không chắc chắn được đo bằng biên giữa 2 mục xác suất cao nhất, tức là, margin(x) = fstudent(x)i* - maxi∈[k]\{i*} fstudent(x)i.

2.2 KHOẢNG CÁCH NGHIÊN CỨU

Mặc dù có thành công rộng rãi của lấy mẫu dựa trên biên trong học tích cực, chúng tôi cho rằng nó thường không phù hợp cho chưng cất kiến thức do xu hướng khuếch đại thiên kiến xác nhận, dẫn đến

3

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Hình 1: Trái: độ chính xác của giáo viên (tổng thể 60.7%) so với điểm số biên của học sinh (tổng thể 49.4%); các điểm có biên thấp hơn có xu hướng được phân loại không chính xác bởi giáo viên. Biểu đồ được tạo bằng cách lấy trung bình độ chính xác của giáo viên trên 100 điểm biên gần nhất. Phải: Hiệu suất của chưng cất bền vững (đỏ), chọn các điểm biên thấp nhất trong số những cái được gán nhãn chính xác bởi giáo viên, so với của biên (xanh).

hiệu suất học sinh kém. Để quan sát điều này, lưu ý rằng mục tiêu của lấy mẫu dựa trên biên - và tổng quát hơn, các phương pháp truy vấn dựa trên độ không chắc chắn khác - là truy vấn các nhãn mềm của các đầu vào mà học sinh không chắc chắn nhất ("thể hiện khó"). Tuy nhiên, các thể hiện khó cho học sinh thường khó dự đoán chính xác bởi giáo viên. Do đó, các nhãn mềm cho những điểm này có khả năng không chính xác cao hơn đối với nhãn thực tế, dẫn đến đào tạo học sinh sai lệch. Hình 1 hiển thị một thể hiện của hiện tượng này cho CIFAR10 với kiến trúc ResNet học sinh-giáo viên có độ sâu khác nhau. Như hình minh họa, giáo viên có xu hướng dự đoán nhãn không chính xác cho các điểm có biên học sinh thấp (thể hiện khó), và ngược lại, có xu hướng rất chính xác trên các điểm có biên cao (thể hiện dễ). Điều này gợi ý rằng có một sự đánh đổi cố hữu giữa hiệu quả (tối thiểu hóa truy vấn) và độ bền vững (giảm thiểu thiên kiến xác nhận) cần được xem xét. Tức là, chúng tôi muốn chọn các điểm có thông tin cho học sinh để có hiệu quả, nhưng những điểm có thông tin này có xu hướng được phân loại không chính xác bởi học sinh dẫn đến đào tạo sai hướng và hiệu suất kém. Có thể đồng thời đạt được cả hai theo cách có nguyên tắc không? Chúng tôi gắn nhãn vấn đề này Chưng cất Tích cực Bền vững và đề xuất một phương pháp để giải quyết nó trong phần sau.

3 CHƯNG CẤT TÍCH CỰC BỀN VỮNG (RAD)

3.1 BỐI CẢNH

Thuật toán biên (Liang et al., 2020; Roth & Small, 2006) chọn b điểm với điểm số biên thấp nhất margin(x), trong đó b là ngân sách nhãn mềm của chúng tôi. Gọi margini là viết tắt cho biên của mỗi đầu vào không có nhãn margin(xi) và quan sát rằng lợi ích hoặc tính thông tin của nó có thể được định lượng như gi = 1 - margini. Cho một ngân sách b, lưu ý rằng thuật toán lấy mẫu biên tương ứng với giải pháp tối ưu của vấn đề tối ưu hóa sau đây nơi mục tiêu là tạo ra một phân phối xác suất tối đa hóa tổng mong đợi của lợi ích,

max p∈Δb ES~p[∑i∈S gi], trong đó Δb = {p ∈ [0,1]n : ∑i∈[n] pi = b}. (1)

Như đã thảo luận trước đó, công thức này chỉ tập trung vào tính thông tin của các điểm và không xem xét khả năng tăng gán nhãn sai bởi giáo viên.

Chưng cất Bền vững Để mở rộng (1) để nó bền vững với việc gán nhãn sai có thể của giáo viên, xem xét các mặt nạ ci = 1{giáo viên gán nhãn điểm i chính xác} cho mỗi i ∈ [n] trong đó 1{x} = 1 nếu x đúng và 0 ngược lại. Trang bị với biến bổ sung này, một cách để giảm thiểu rõ ràng thiên kiến xác nhận và đồng thời chọn các mẫu có thông tin là thưởng các điểm được gán nhãn chính xác bởi giáo viên bằng cách gán lợi ích như trước, nhưng phạt những cái được gán nhãn không chính xác qua tổn thất. Điều này có thể được thực hiện bằng cách sử dụng các lợi ích được sửa đổi trong bối cảnh của (1)

g̃i = gici - (1-ci)ℓi = {gi, nếu giáo viên gán nhãn điểm i chính xác; -ℓi, ngược lại} ∀i ∈ [n].

4

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Nói cách khác, điều này có nghĩa là nếu điểm i được gán nhãn chính xác bởi giáo viên, chúng tôi gán lợi ích biên tiêu chuẩn gi = (1 - margini) như trước; ngược lại, chúng tôi phạt việc lựa chọn bằng cách gán ℓi cho một số tổn thất ℓi ≥ 0. Điều này dẫn đến vấn đề chung sau của chưng cất bền vững

max p∈Δb Ei~p[gici - (1-ci)ℓi]. (2)

Giải pháp tối ưu cho vấn đề (2) tương ứng với việc chọn b điểm có thông tin nhất (lợi ích cao nhất) trong số những cái được dự đoán chính xác bởi giáo viên, tức là, những điểm i ∈ [n] với gi cao nhất tuân theo ci = 1. Phương pháp này được hiển thị như Chưng cất Bền vững (Oracle) trong Hình 1 (phải). Hình 1 minh họa tác động của các ví dụ không chính xác đối với đào tạo học sinh (xem thêm (Pham et al., 2021)). Nếu chúng tôi có kiến thức về (ci)i∈[n], thì chúng tôi có thể giải quyết tối ưu (2) để có được cải thiện đáng kể so với thuật toán biên tiêu chuẩn. Thật không may, kiến thức hoàn hảo về việc liệu giáo viên gán nhãn mỗi điểm chính xác hay không, tức là, (ci)i∈[n], không thể trong bối cảnh bán giám sát.

3.2 PHƯƠNG PHÁP CỦA CHÚNG TÔI

Chúng tôi xem xét một phương pháp chung và bền vững đồng thời tận dụng kiến thức cụ thể về thể hiện mà không cần biết các mặt nạ (ci)i∈[n] riêng lẻ. Giả sử rằng chúng tôi chỉ biết rằng giáo viên gán nhãn sai m điểm trong số n đầu vào không có nhãn XB thay thế. Chúng tôi có thể tạo ra một phân phối lấy mẫu sao cho bất kể m điểm nào được gán nhãn không chính xác bởi giáo viên, lợi ích mong đợi của chúng tôi cao không? Giả sử b = 1 để đơn giản, chúng tôi đến với phần mở rộng của công thức trong (2)

max p∈Δ1 min c∈Γn-m Ei~p[gici - (1-ci)ℓi], trong đó Γk = {q ∈ [0,1]n : ∑i∈[n] qi = k}. (3)

Vấn đề (3) có giải thích lý thuyết trò chơi sau đây. Chúng tôi đi trước và chọn một phân phối lấy mẫu p trên các điểm. Để phản hồi, một đối thủ quyết định điểm nào bị phân loại sai (tức là, ci = 0) bởi giáo viên tuân theo ràng buộc rằng nó có thể đặt ci = 0 cho nhiều nhất m trong số n của chúng vì c ∈ Γn-m. Cho cấu trúc tuyến tính của vấn đề, hóa ra chúng tôi có thể gọi Định lý Minimax của von Neumann (Neumann, 1928) nói rằng điểm cân bằng là như nhau bất kể chúng tôi đi trước và chọn phân phối xác suất p ∈ Δ1 hoặc đối thủ đi trước và chọn (ci)i∈[n]. Bằng cách khai thác kết nối này, chúng tôi có được một giải pháp dạng đóng như được chính thức hóa dưới đây.

Định lý 1. Giả sử g1 ≥ g2 ≥ ... ≥ gn > 0, và định nghĩa Gk = ∑i≤k gi/(gi+ℓi) và Hk = ∑i≤k 1/(gi+ℓi). Với Gn ≥ m, một giải pháp tối ưu p* ∈ Δ1 cho (3) được cho bởi

p*i = 1/[Hk*(gi+ℓi)] nếu i ≤ k* và p*i = 0 ngược lại, trong đó k* = argmax k∈[n] (Gk-m)/Hk.

Phân phối có thể được tính trong thời gian tuyến tính (giả sử g được sắp xếp) và đạt được giá trị mục tiêu OPT(k*) := (Gk*-m)/Hk*.

Chúng tôi phác thảo chứng minh ở đây. Chứng minh đầy đủ có thể được tìm thấy trong Phụ lục (Sec. C).

Phác thảo chứng minh. Gọi OBJ(p,c) = ∑i∈[n] pi(gici - (1-ci)ℓi).

Thay thế p* từ Thm. 1 và xem xét một giá trị tối thiểu hóa cho c ∈ Γn-m, có thể cho thấy rằng p* ∈ Δ1 và

OPT(k*) = min c∈Γn-m OBJ(p*,c) ≤ max p∈Δ1 min c∈Γn-m OBJ(p,c).

Mặt khác, gọi c*i = min{1, (OPT(k*)+ℓi)/(gi+ℓi)}. Với một chút công việc hơn, sử dụng thực tế rằng gk* ≥ OPT(k*) ≥ gk*+1, chúng tôi có thể cho thấy tương tự rằng c* ∈ Γn-m và

OPT(k*) = max p∈Δ1 OBJ(p,c*) ≥ min c∈Γn-m max p∈Δ1 OBJ(p,c).

Với những bất đẳng thức này trong tay, chúng tôi áp dụng Định lý Minimax (Neumann, 1928), cho ra

OPT(k*) ≤ max p∈Δ1 min c∈Γn-m OBJ(p,c) = min c∈Γn-m max p∈Δ1 OBJ(p,c) ≤ OPT(k*).

Do đó, p* thực sự có được giá trị tối ưu, OPT(k*).

5

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Tổn thất RAD Trang bị với Định lý 1, tất cả những gì còn lại là chỉ định các tổn thất trong (3). Công việc trước đó về thiên kiến xác nhận đã cho thấy rằng ngay cả một số lượng nhỏ các nhãn mềm sai hướng có thể làm trật đường đào tạo học sinh và tác động đáng kể đến khả năng dự đoán của nó (Liu & Tan, 2021). Ngoài ra, tác hại của một điểm được gán nhãn không chính xác có thể còn rõ rệt hơn khi học sinh không chắc chắn về điểm đó. Để mô hình hóa điều này, chúng tôi xem xét việc khởi tạo công thức vấn đề chung của chúng tôi (3) với các tổn thất tương đối với lợi ích ℓi = wgi cho mỗi i ∈ [n] trong đó w ∈ [0,1] là một tham số trọng số kiểm soát độ lớn của việc phạt. Công thức này cố ý dẫn đến các hình phạt cao hơn cho các điểm bị phân loại sai mà học sinh đã không chắc chắn (lợi ích cao) để giảm thiểu thiên kiến xác nhận, và dẫn đến vấn đề tối ưu hóa sau đây là trọng tâm của bài báo này

max p∈Δ1 min c∈Γn-m Ei~p[gici - (1-ci)wgi]. (4)

Gọi Thm. 1 với các tổn thất lợi ích tương đối như mô tả ở trên ngay lập tức dẫn đến điều sau đây, cùng với lựa chọn w dưới đây, mô tả thuật toán RAD mà chúng tôi đề xuất trong bài báo này.

Hệ quả 1. Một giải pháp tối ưu p* ∈ Δ1 cho (4) có k* mục khác không Ik* ⊆ [n] tương ứng với k* chỉ số của các mục lớn nhất của g, với

p*i = 1/gi / ∑j∈Ik* 1/gj ∀i ∈ Ik* trong đó k* = argmax k∈[n] [k(1+w)-m] / ∑j∈Ik 1/gj.

Phân phối p* có thể được tính trong thời gian O(n log n), với OPT(k*) = (k*(1+w)-m) / ∑j∈Ik* 1/gj.

Lựa chọn w Mặc dù RAD có thể được áp dụng với bất kỳ lựa chọn w do người dùng chỉ định nào, chúng tôi sử dụng trọng số có động lực lý thuyết w = (1-m/n) như hằng số phạt tương đối trong các thí nghiệm của chúng tôi. Lựa chọn w này đảm bảo rằng giá trị tối ưu (lợi ích mong đợi) của (4) (xem Hệ quả (1)) là không âm — nếu lợi ích mong đợi âm, chúng tôi sẽ tốt hơn khi không lấy mẫu gì cả. Giá trị mặc định này cho w làm cho RAD không có tham số. Các đánh giá thực nghiệm rộng rãi với các giá trị w khác nhau được trình bày trong Sec. D.5 của Phụ lục.

Hình 2: Giải pháp tối ưu cho (4) được cho bởi Hệ quả 1 cho các giá trị khác nhau cho độ chính xác giáo viên (m khác nhau). Ngay cả khi hầu hết các mẫu được gán nhãn chính xác bởi giáo viên, phương pháp của chúng tôi cố ý thận trọng và không phân bổ tất cả khối lượng xác suất (lấy mẫu) trên các điểm lợi ích cao nhất.

Chúng tôi quan sát một số tính chất thuận lợi của phân phối lấy mẫu của RAD trong Hình 2, mô tả phân phối được tính trên một tình huống tổng hợp với các lợi ích được rút đều từ [0,1]. Thứ nhất, phân phối lấy mẫu có xu hướng phân bổ ít khối lượng xác suất hơn cho các mục lợi ích cao nhất. Như công việc trước đó đã cho thấy, điều này mong muốn vì các ví dụ khó nhất (lợi ích cao nhất) có xu hướng là các ngoại lệ hoặc điểm với nhãn nhiễu (Mindermann et al., 2022; Ren et al., 2018). Thực tế, các phương pháp học bền vững thường giảm trọng số các ví dụ khó vì lý do này (Kumar et al., 2010), tương tự như hành vi lấy mẫu của RAD. Đồng thời, Paul et al. (2021) cho thấy rằng các ví dụ dễ nhất (lợi ích thấp nhất) có xu hướng thực sự không có thông tin và chiến lược tốt nhất là bỏ qua một phần nhất định của các điểm lợi ích cao nhất và thấp nhất. Chiến lược này song song với phân phối được tính của RAD, nơi một số điểm lợi ích thấp bị bỏ qua và xác suất đỉnh xung quanh một khu vực ở giữa (xem Hình 2). Một lợi ích nổi bật của RAD là khu vực này được tính hoàn toàn tự động như một hàm của độ chính xác của giáo viên (tức là, lượng nhiễu nhãn). Nếu giáo viên rất chính xác, phân phối tương ứng tập trung vào các điểm lợi ích cao nhất (xanh, Hình 2); ngược lại, nó phân tán xác suất trên một phần lớn hơn của các điểm và cố ý gán xác suất lấy mẫu thấp hơn cho các điểm lợi ích cao nhất có khả năng nhiễu (ví dụ: nâu, Hình 2).

6

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
3.3 CHI TIẾT THỰC HIỆN

Chúng tôi kết thúc phần này bằng cách phác thảo các chi tiết thực tế của RAD. Chúng tôi tuân theo cài đặt của phần này và đặt gi = 1 - margini để định nghĩa lợi ích của mỗi điểm (xem Sec. D.6 của Phụ lục cho các đánh giá với định nghĩa lợi ích khác). Trong thực tế, chúng tôi sử dụng phân phối q = min{bp*, 1} khi lấy mẫu một tập b điểm, trong đó p* từ Hệ quả 1. Điều này tối ưu miễn là các xác suất từ Hệ quả 1 (hoặc tổng quát hơn, Định lý 1) không tập trung mạnh trên một vài điểm (tức là, maxi∈[n] p*i ≤ 1/b). Như được minh họa trong Hình 2 và được xác minh thực nghiệm trong Sec. 4 trong tất cả các tình huống được đánh giá, chúng tôi thấy điều này hầu như luôn luôn là trường hợp. Hoặc, kích thước thu thập b có thể được điều chỉnh sau khi phân phối xác suất mẫu đơn được tính sao cho b ≤ mini∈[n] 1/p*i.

Vì số lượng sai lầm mà giáo viên mắc phải trên XB, m, không được biết đến chúng tôi trong bối cảnh bán giám sát, chúng tôi ước lượng đại lượng này bằng cách đầu tiên lấy trung bình mẫu sự không chính xác của một mẫu ngẫu nhiên đều nhỏ buniform (xem Phụ lục, Sec. D.1) điểm như một cách để ước lượng m và khởi động phương pháp của chúng tôi. Sau đó chúng tôi sử dụng phương pháp của chúng tôi với b' = b - buniform như mô tả ở trên. Bằng bất đẳng thức Bernstein (Bernstein, 1924), ước lượng có trọng số này tập trung chặt chẽ xung quanh trung bình, điều này lần lượt ngụ ý một ước lượng chất lượng cao của m. Chúng tôi phân tích lý thuyết tác động của một m ước lượng đến chất lượng của giải pháp tối ưu trong Sec. C của Phụ lục (xem Lemma 4 và 5).

4 KẾT QUẢ

Chúng tôi áp dụng thuật toán lựa chọn mẫu của chúng tôi, RAD, vào các bộ dữ liệu thị giác điểm chuẩn và đánh giá hiệu suất của nó trong việc tạo ra các mô hình học sinh hiệu suất cao trên một tập đa dạng các tình huống chưng cất kiến thức. Chúng tôi so sánh hiệu suất của RAD với những cái sau: (i) MARGIN (Balcan et al., 2007; Roth & Small, 2006) như mô tả trong Sec. 3, (ii) UNIFORM, (iii) CLUSTER MARGIN (được gọi là CM), một kỹ thuật học tích cực tiên tiến (Citovsky et al., 2021), (iv) CORESET, một thuật toán học tích cực dựa trên phân cụm phổ biến (Sener & Savarese, 2017), (v) ENTROPY, một phương pháp tham lam chọn các điểm với entropy dự đoán học sinh cao nhất (Holub et al., 2008), và (vi) UNIXKD (Xu et al., 2020), một phương pháp chưng cất tích cực tiên tiến dựa trên mix-up (Zhang et al., 2017). Chúng tôi thực hiện tất cả các thuật toán trong Python và sử dụng thư viện học sâu TensorFlow (Abadi et al., 2015). Chúng tôi sử dụng các siêu tham số được chỉ định trong các bài báo tương ứng cho tất cả các phương pháp so sánh. Đối với RAD, chúng tôi sử dụng cài đặt có nguồn gốc lý thuyết w = 1 - m/n như được chỉ định trong Sec. 3 và nhấn mạnh rằng điều này làm cho RAD hoàn toàn không có tham số.

Trong Sec. D của Phụ lục, chúng tôi trình bày: tập đầy đủ các siêu tham số và chi tiết thực nghiệm (Sec. D.1); các đánh giá bổ sung báo cáo số liệu thống kê ngoài độ chính xác kiểm tra (Sec. D.3); ứng dụng của RAD vào bối cảnh học tích cực tiêu chuẩn và so sánh với các phương pháp SOTA (Sec. D.4); thí nghiệm với w và định nghĩa lợi ích khác nhau để đánh giá độ bền vững của RAD (Sec. D.5 và D.6, tương ứng); so sánh trên một tập đa dạng các cấu hình chưng cất kiến thức (Sec. D.7).

Tổng thể, các đánh giá thực nghiệm của chúng tôi cho thấy rằng RAD cải thiện đều trên các đường cơ sở tiên tiến và chứng minh hiệu quả sẵn có của nó mà không cần điều chỉnh hoặc thay đổi bất kỳ siêu tham số nào.

4.1 CIFAR10, CIFAR100, & SVHN

Thiết lập Chúng tôi sử dụng ResNet (He et al., 2015), ResNetV2-{11,20,29} (He et al., 2016), hoặc MobileNet (Howard et al., 2017) với nhân tử độ sâu 1 như học sinh và ResNet-50, ResNetV2-{56,110}, hoặc MobileNet với nhân tử độ sâu 2 như mô hình giáo viên. Chúng tôi xem xét các bộ dữ liệu CIFAR10/CIFAR100 (Krizhevsky et al., 2009), SVHN (Netzer et al., 2011), và ImageNet (Deng et al., 2009). Trừ khi được chỉ định khác, chúng tôi sử dụng trình tối ưu Adam (Kingma & Ba, 2014) với kích thước batch 128 với lịch trình tỷ lệ học cụ thể bộ dữ liệu. Chúng tôi tuân theo cài đặt chưng cất tích cực được hiển thị trong Alg. 1 với các cấu hình khác nhau. Chúng tôi sử dụng 64 Cloud TPU v4s mỗi cái với hai lõi. Tập đầy đủ các siêu tham số và chi tiết thực nghiệm có thể được tìm thấy trong Sec. D của Phụ lục.

Cấu hình Chúng tôi thí nghiệm với một tập đa dạng các cấu hình cho nhiệm vụ chưng cất kiến thức. Chúng tôi báo cáo cấu hình cụ thể cho mỗi biểu đồ như một phần của tiêu đề biểu đồ (ví dụ: xem Hình 3). Trong bối cảnh các biến trong tiêu đề biểu đồ, chúng tôi thay đổi số epoch mà học sinh được đào tạo (ký hiệu là e), kích thước của tập điểm có nhãn ban đầu (|A|), số lượng nhãn mềm để truy vấn mỗi lần lặp (b), và mô hình giáo viên (t); resnet trong cấu hình đề cập đến ResNetV2-20 như học sinh và ResNet-50 như giáo viên trừ khi được chỉ định khác. Tất cả kết quả được lấy trung bình trên 10

7

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
thử nghiệm trừ khi được nói khác. Cho mỗi thử nghiệm, chúng tôi trộn lại toàn bộ bộ dữ liệu và chọn một phần ngẫu nhiên (kích thước |A|) để làm bộ dữ liệu có nhãn XL, và xem xét phần còn lại là tập không có nhãn XU.

Hình 3: Đánh giá RAD, học tích cực tiên tiến, và các chiến lược chưng cất tích cực trên một tập đa dạng các cấu hình chưng cất với các bộ dữ liệu và kiến trúc mạng khác nhau. RAD liên tục vượt trội so với các phương pháp cạnh tranh. Các vùng bóng tương ứng với các giá trị trong một độ lệch chuẩn của trung bình.

Trong tập thí nghiệm đầu tiên, chúng tôi đánh giá hiệu quả của mỗi phương pháp trong việc tạo ra các mô hình học sinh độ chính xác cao tuân theo ngân sách gán nhãn mềm trên các bộ dữ liệu CIFAR10, CIFAR100, và SVHN với kiến trúc ResNet(v2) và MobileNet có kích thước khác nhau. CIFAR10 chứa 50,000 hình ảnh kích thước 32×32 với 10 danh mục, CIFAR100 có 50,000 hình ảnh 32×32 với 100 nhãn, và SVHN bao gồm 73,257 hình ảnh thực tế (32×32) được chụp từ Google Street View. Hình 3 mô tả kết quả đánh giá của chúng tôi trên một tập đa dạng các tình huống chưng cất kiến thức với các cấu hình khác nhau. Chúng tôi quan sát một cải thiện nhất quán và đáng chú ý trong hiệu suất dự đoán của mô hình học sinh khi phương pháp của chúng tôi được sử dụng để chọn tích cực các điểm được gán nhãn mềm bởi giáo viên. Cải thiện này thường có từ lần lặp gán nhãn đầu tiên và tiếp tục liên tục qua các lần lặp chưng cất tích cực.

Chúng tôi quan sát rằng RAD thực hiện đặc biệt tốt so với đường cơ sở bất kể độ chính xác của giáo viên. Ví dụ, chúng tôi thấy cải thiện đáng kể với RAD khi chưng cất từ một giáo viên MobileNet trên CIFAR100, có độ chính xác tương đối thấp (xem các biểu đồ tương ứng trong Hình 3). Quan sát này gợi ý rằng việc xem xét rõ ràng sự không chính xác có thể của giáo viên thực sự hữu ích khi chưng cất từ một giáo viên có thể dễ mắc sai lầm. Đồng thời, chúng tôi quan sát rằng RAD vượt trội so với các thuật toán học tích cực tiên tiến như Cluster Margin (CM) và những cái khác (MARGIN, ENTROPY) - không xem xét rõ ràng nhiễu nhãn dưới dạng nhãn mềm giáo viên không chính xác - ngay cả trong các trường hợp mà độ chính xác giáo viên cao tới 92% (xem biểu đồ SVHN trong Hình 3). Những quan sát này hỗ trợ khả năng của RAD tự động thích ứng phân phối lấy mẫu của nó với tình huống được áp dụng dựa trên sự không chính xác giáo viên được ước lượng.

8

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Hình 4: Độ chính xác phân loại và lợi ích trên bộ dữ liệu ImageNet với ResNets.

4.2 THÍ NGHIỆM IMAGENET

Ở đây, chúng tôi báo cáo kết quả đánh giá của chúng tôi với kiến trúc ResNet được đào tạo trên bộ dữ liệu ImageNet, chứa gần 1.3 triệu hình ảnh trải dài 1000 danh mục (Deng et al., 2009). Chúng tôi loại trừ các phương pháp UNIXKD và CORESET do hạn chế tài nguyên và thực tế là CM vượt trội so với CORESET (Citovsky et al., 2021) và UNIXKD liên tục thực hiện kém trong các cấu hình ở phần trước. Điều này làm nổi bật một lợi thế bổ sung của phương pháp chúng tôi: nó chỉ yêu cầu một sắp xếp (O(n log n) tổng thời gian). Điều này trái ngược với các phương pháp tốn kém tính toán và bộ nhớ như CORESET và CM yêu cầu phân cụm (xem Sec. D.2 cho chi tiết). Hình 4 mô tả kết quả đánh giá của chúng tôi, nơi phương pháp của chúng tôi liên tục cải thiện so với các phương pháp so sánh qua tất cả các epoch đào tạo. Ở đây giáo viên là một mô hình ResNet50 và học sinh là một mô hình ResNet18. Giáo viên được đào tạo trên bộ dữ liệu có nhãn ban đầu A với |A| = 10%|I|. Cho mỗi lựa chọn ngân sách b ∈ {3%|I|, 5%|I|, 7%|I|, 9%|I|, 11%|I|}, chúng tôi chạy 3 thử nghiệm. Trong biểu đồ ngoài cùng bên phải chúng tôi quan sát rằng lợi ích của phương pháp chúng tôi (w.r.t. gi = 1 - margini) cao hơn so với các phương pháp cạnh tranh, và lợi ích tương quan tốt với độ chính xác kiểm tra của học sinh, điều này khẳng định lại tính hợp lệ thực tế của công thức của chúng tôi (Sec. 3).

5 KẾT LUẬN

Trong bài báo này, chúng tôi xem xét vấn đề chưng cất kiến thức hiệu quả và bền vững trong bối cảnh học bán giám sát với một lượng dữ liệu có nhãn hạn chế và một lượng lớn dữ liệu không có nhãn. Chúng tôi công thức hóa vấn đề chưng cất tích cực bền vững và trình bày một thuật toán thời gian gần tuyến tính với các đảm bảo có thể chứng minh để giải quyết nó một cách tối ưu. Theo hiểu biết tốt nhất của chúng tôi, công việc của chúng tôi là đầu tiên xem xét lấy mẫu quan trọng cho các nhãn mềm có thông tin và được gán nhãn chính xác để cho phép hiệu quả và độ bền vững trong các nhiệm vụ chưng cất kiến thức quy mô lớn. Phương pháp của chúng tôi không có tham số và đơn giản để thực hiện. Các thí nghiệm của chúng tôi trên các bộ dữ liệu điểm chuẩn phổ biến với một tập đa dạng các cấu hình cho thấy một cải thiện nhất quán và đáng chú ý trong độ chính xác kiểm tra của mô hình học sinh được tạo ra so với những cái được tạo ra bởi các phương pháp tiên tiến.

Hạn chế và công việc tương lai Trong công việc tương lai, chúng tôi dự định thiết lập hiểu biết lý thuyết sâu sắc hơn về các sự đánh đổi của các khởi tạo khác nhau của khung chung của chúng tôi, (3) trong Sec. 3, đối với độ chính xác kiểm tra của mô hình học sinh. Ví dụ, không rõ ràng liệu định nghĩa lợi ích như gi = 1 - margini hoặc gi = exp(-margini) phù hợp hơn, mặc dù cả hai định nghĩa đều dẫn đến lợi ích tăng đơn điệu với độ không chắc chắn của học sinh. Bên cạnh việc xem xét độ chính xác giáo viên trong công thức bền vững, chúng tôi dự định cũng xem xét các số liệu liên quan khác như sự bất đồng học sinh-giáo viên để xây dựng các phân phối có thông tin hơn. Tổng thể, chúng tôi hình dung rằng phương pháp của chúng tôi có thể được sử dụng trong các ứng dụng có tác động cao để tạo ra các mô hình học sinh mạnh mẽ bằng cách chưng cất hiệu quả kiến thức của các giáo viên lớn đối mặt với dữ liệu có nhãn hạn chế.

9

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
TUYÊN BỐ KHẢ NĂNG TÁI TẠO

Thuật toán của chúng tôi được chỉ định đầy đủ (Hệ quả 1), đơn giản để thực hiện, và không có tham số (Sec. 3). Chúng tôi cung cấp các chi tiết đầy đủ và siêu tham số cần thiết để tái tạo kết quả của chúng tôi trong Sec. 4 và Sec. D.1 của Phụ lục. Chúng tôi chỉ định mô tả về cách các thuật toán cạnh tranh được thực hiện, bao gồm cài đặt siêu tham số. Chúng tôi cung cấp các kết quả lý thuyết chính xác (Sec. 3 trong phần chính và Sec. C của Phụ lục) chỉ định rõ ràng các giả định và cung cấp chứng minh đầy đủ và các lemma bổ trợ bổ sung trong Phụ lục (Sec. C). Các đánh giá của chúng tôi sử dụng các bộ dữ liệu và mô hình có sẵn công khai và dễ tiếp cận.

TÀI LIỆU THAM KHẢO

Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, và Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/ . Phần mềm có sẵn từ tensorflow.org. 7

Eric Arazo, Diego Ortego, Paul Albert, Noel E O'Connor, và Kevin McGuinness. Pseudo-labeling and confirmation bias in deep semi-supervised learning. In 2020 International Joint Conference on Neural Networks (IJCNN) , pp. 1–8. IEEE, 2020. 2

Jordan T Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, và Alekh Agarwal. Deep batch active learning by diverse, uncertain gradient lower bounds. arXiv preprint arXiv:1906.03671 , 2019. 3

Maria-Florina Balcan, Andrei Broder, và Tong Zhang. Margin based active learning. In International Conference on Computational Learning Theory , pp. 35–50. Springer, 2007. 3, 7

Cenk Baykal, Lucas Liebenwein, Igor Gilitschenski, Dan Feldman, và Daniela Rus. Sensitivity-informed provable pruning of neural networks. SIAM Journal on Mathematics of Data Science , 4(1):26–45, 2022. 1

Sergei Bernstein. On a modification of chebyshev's inequality and of the error formula of laplace. Ann. Sci. Inst. Sav. Ukraine, Sect. Math , 1(4):38–49, 1924. 7, 18

Lucas Beyer, Xiaohua Zhai, Amélie Royer, Larisa Markeeva, Rohan Anil, và Alexander Kolesnikov. Knowledge distillation: A good teacher is patient and consistent. arXiv preprint arXiv:2106.05237 , 2021. 1, 2

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020. 1

Cristian Buciluǎ, Rich Caruana, và Alexandru Niculescu-Mizil. Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining , pp. 535–541, 2006. 1

Chandra Chekuri, Jan Vondrák, và Rico Zenklusen. Dependent randomized rounding for matroid polytopes and applications. arXiv preprint arXiv:0909.4348 , 2009. 14

Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, và Geoffrey E Hinton. Big self-supervised models are strong semi-supervised learners. Advances in neural information processing systems , 33:22243–22255, 2020. 1

Jang Hyun Cho và Bharath Hariharan. On the efficacy of knowledge distillation. In Proceedings of the IEEE/CVF international conference on computer vision , pp. 4794–4802, 2019. 1

10

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022. 2

Gui Citovsky, Giulia DeSalvo, Claudio Gentile, Lazaros Karydas, Anand Rajagopalan, Afshin Rostamizadeh, và Sanjiv Kumar. Batch active learning at scale. Advances in Neural Information Processing Systems , 34, 2021. 7, 9, 19

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition , pp. 248–255. Ieee, 2009. 7, 9

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018. 1

Melanie Ducoffe và Frederic Precioso. Adversarial active learning for deep networks: a margin based approach. arXiv preprint arXiv:1802.09841 , 2018. 3

Yarin Gal, Riashat Islam, và Zoubin Ghahramani. Deep bayesian active learning with image data. In International Conference on Machine Learning , pp. 1183–1192. PMLR, 2017. 3

Jianping Gou, Baosheng Yu, Stephen J Maybank, và Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision , 129(6):1789–1819, 2021. 1

Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Deep residual learning for image recognition. corr abs/1512.03385 (2015), 2015. 7

Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Identity mappings in deep residual networks. In European conference on computer vision , pp. 630–645. Springer, 2016. 7

Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 , 2(7), 2015. 1, 3

Alex Holub, Pietro Perona, và Michael C Burl. Entropy-based active learning for object recognition. In 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops , pp. 1–8. IEEE, 2008. 7

Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, và Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 , 2017. 7, 18

Diederik P Kingma và Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 , 2014. 7, 18

Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 7

M Kumar, Benjamin Packer, và Daphne Koller. Self-paced learning for latent variable models. Advances in neural information processing systems , 23, 2010. 6

Kevin J Liang, Weituo Hao, Dinghan Shen, Yufan Zhou, Weizhu Chen, Changyou Chen, và Lawrence Carin. Mixkd: Towards efficient distillation of large-scale language models. arXiv preprint arXiv:2011.00593 , 2020. 2, 3, 4

Kevin J Liang, Samrudhdhi B Rangrej, Vladan Petrovic, và Tal Hassner. Few-shot learning with noisy labels. arXiv preprint arXiv:2204.05494 , 2022. 2

Lu Liu và Robby T Tan. Certainty driven consistency loss on multi-teacher networks for semi-supervised learning. Pattern Recognition , 120:108140, 2021. 2, 6

Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, và Christopher Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies , pp. 142–150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/P11-1015 . 28

11

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Aditya Krishna Menon, Ankit Singh Rawat, Sashank J Reddi, Seungyeon Kim, và Sanjiv Kumar. Why distillation helps: a statistical perspective. arXiv preprint arXiv:2005.10419 , 2020. 1

Sören Mindermann, Jan M Brauner, Muhammed T Razzak, Mrinank Sharma, Andreas Kirsch, Winnie Xu, Benedikt Höltgen, Aidan N Gomez, Adrien Morisot, Sebastian Farquhar, et al. Prioritized training on points that are learnable, worth learning, and not yet learnt. In International Conference on Machine Learning , pp. 15630–15649. PMLR, 2022. 6

Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, và Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011. 7, 22

John von Neumann. Zur theorie der gesellschaftsspiele. Mathematische annalen , 100(1):295–320, 1928. 5, 14

Michael Niemeyer và Andreas Geiger. Giraffe: Representing scenes as compositional generative neural feature fields. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11453–11464, 2021. 1

OpenAI. Openai pricing. https://openai.com/api/pricing/#faq-which-model , 2022. Accessed: 2022-08-01. 2

David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, và Jeff Dean. Carbon emissions and large neural network training. arXiv preprint arXiv:2104.10350 , 2021. 1

Mansheej Paul, Surya Ganguli, và Gintare Karolina Dziugaite. Deep learning on a data diet: Finding important examples early in training. Advances in Neural Information Processing Systems , 34: 20596–20607, 2021. 6, 19

Mansheej Paul, Brett W Larsen, Surya Ganguli, Jonathan Frankle, và Gintare Karolina Dziugaite. Lottery tickets on a data diet: Finding initializations with sparse trainable networks. arXiv preprint arXiv:2206.01278 , 2022. 19

Hieu Pham, Zihang Dai, Qizhe Xie, và Quoc V Le. Meta pseudo labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11557–11568, 2021. 1, 2, 5

Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, và Ilya Sutskever. Zero-shot text-to-image generation. In International Conference on Machine Learning , pp. 8821–8831. PMLR, 2021. 1

Mengye Ren, Wenyuan Zeng, Bin Yang, và Raquel Urtasun. Learning to reweight examples for robust deep learning. In International conference on machine learning , pp. 4334–4343. PMLR, 2018. 6

Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Brij B Gupta, Xiaojiang Chen, và Xin Wang. A survey of deep active learning. ACM Computing Surveys (CSUR) , 54(9):1–40, 2021. 3

Dan Roth và Kevin Small. Margin-based active learning for structured output spaces. In European Conference on Machine Learning , pp. 413–424. Springer, 2006. 2, 3, 4, 7

Ozan Sener và Silvio Savarese. Active learning for convolutional neural networks: A core-set approach. arXiv preprint arXiv:1708.00489 , 2017. 3, 7, 19

Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, và Jae-Gil Lee. Learning from noisy labels with deep neural networks: A survey. IEEE Transactions on Neural Networks and Learning Systems , 2022. 2

Samuel Stanton, Pavel Izmailov, Polina Kirichenko, Alexander A Alemi, và Andrew G Wilson. Does knowledge distillation really work? Advances in Neural Information Processing Systems , 34, 2021. 1

12

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Iulia Turc, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Well-read students learn better: On the importance of pre-training compact models. arXiv preprint arXiv:1908.08962 , 2019. 28

Qizhe Xie, Minh-Thang Luong, Eduard Hovy, và Quoc V Le. Self-training with noisy student improves imagenet classification. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 10687–10698, 2020. 1, 2

Guodong Xu, Ziwei Liu, và Chen Change Loy. Computation-efficient knowledge distillation via uncertainty-aware mixup. arXiv preprint arXiv:2012.09413 , 2020. 2, 3, 7

Taraneh Younesian, Zilong Zhao, Amirmasoud Ghiassi, Robert Birke, và Lydia Y Chen. Qactor: Active learning on noisy labels. In Asian Conference on Machine Learning , pp. 548–563. PMLR, 2021. 2

Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, và David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412 , 2017. 2, 7

Zizhao Zhang, Han Zhang, Sercan O Arik, Honglak Lee, và Tomas Pfister. Distilling effective supervision from severe label noise. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 9294–9303, 2020. 2

Guoqing Zheng, Ahmed Hassan Awadallah, và Susan Dumais. Meta label correction for noisy label learning. AAAI 2021 , 2021. 2

13

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
A PHỤ LỤC

Trong tài liệu bổ sung này, chúng tôi cung cấp các chi tiết về lấy mẫu batch (trong Sec. B), chứng minh đầy đủ của các kết quả trong Sec. 3 và các kết quả lý thuyết bổ sung (trong Sec. C), và chi tiết các thí nghiệm trong Sec. 4 và các đánh giá bổ sung (trong Sec. D).

B CHI TIẾT THỰC HIỆN

Để bổ sung cho thảo luận của chúng tôi trong Sec. 3, chúng tôi cung cấp các chi tiết bổ sung về quy trình lấy mẫu batch. Một phương pháp là lặp qua các điểm i ∈ [n] và chọn mỗi điểm với xác suất qi. Nếu ∑i∈[n] qi = b, thì quy trình này lấy mẫu b điểm theo kỳ vọng. Một phương pháp có nguyên tắc hơn là sử dụng làm tròn phụ thuộc ngẫu nhiên (Chekuri et al., 2009) lấy mẫu chính xác b điểm cho một phân phối tổng bằng b. Quy trình này được hiển thị như Alg. 2, và một thực hiện hiệu quả của nó chạy trong thời gian O(n) (Chekuri et al., 2009).

Thuật toán 2 DEPROUND
Đầu vào: Xác suất p ∈ [0,1]n sao cho ∑i∈[n] pi = b
Đầu ra: tập chỉ số I ⊆ [n] với |I| = b
1: while ∃i ∈ [n] sao cho 0 < pi < 1 do
2:    Chọn i,j ∈ [n] với i ≠ j, 0 < pi < 1, và 0 < pj < 1
3:    α ← min(1 - pi, pj)
4:    β ← min(pi, 1 - pj)
5:    Cập nhật pi và pj
      (pi, pj) ← {(pi + α, pj - α) với xác suất β/(α + β);
                  (pi - β, pj + β) với xác suất 1 - β/(α + β).
6: end while
7: I ← {i ∈ [n] : pi = 1}
   return I

C CHỨNG MINH & PHÂN TÍCH BỔ SUNG

C.1 CHỨNG MINH ĐỊNH LÝ 1

Định lý 1. Giả sử g1 ≥ g2 ≥ ... ≥ gn > 0, và định nghĩa Gk = ∑i≤k gi/(gi+ℓi) và Hk = ∑i≤k 1/(gi+ℓi). Với Gn ≥ m, một giải pháp tối ưu p* ∈ Δ1 cho (3) được cho bởi

p*i = 1/[Hk*(gi+ℓi)] nếu i ≤ k* và p*i = 0 ngược lại, trong đó k* = argmax k∈[n] (Gk-m)/Hk.

Phân phối có thể được tính trong thời gian tuyến tính (giả sử g được sắp xếp) và đạt được giá trị mục tiêu OPT(k*) := (Gk*-m)/Hk*.

Chứng minh. Chứng minh dựa trên Định lý Minimax (Neumann, 1928), cho ra

min c∈Γn-m max p∈Δ1 f(p,c) = max p∈Δ1 min c∈Γn-m f(p,c).

Chúng tôi sẽ sử dụng thêm hai khẳng định, mà chúng tôi sẽ chứng minh ngay sau đây.

Khẳng định 2. Gọi p*, k*, và N(k*) được định nghĩa như trong phát biểu của lemma. Thì p* ∈ Δ1 và N(k*) = min c∈Γn-m f(p*,c).

Khẳng định 3. Gọi k* và N(k*) được định nghĩa như trong phát biểu của lemma. Hơn nữa, định nghĩa

c*i = {(N(k*)+ℓi)/(gi+ℓi) nếu i ≤ k*; 1 ngược lại}

Thì c* ∈ Γn-m và N(k*) = max p∈Δ1 f(p,c*).

Cho các khẳng định, chúng ta thấy

N(k*) = min c∈Γn-m f(p*,c) ≤ max p∈Δ1 min c∈Γn-m f(p,c) theo Khẳng định 2
       = min c∈Γn-m max p∈Δ1 f(p,c) theo Minimax
       ≤ max p∈Δ1 f(p,c*) = N(k*) theo Khẳng định 3

Tức là, p* đạt được cực đại, là N(k*), như chúng ta muốn.

Bây giờ chúng tôi chứng minh các khẳng định. Trước khi bắt đầu, chúng tôi sẽ đầu tiên đơn giản hóa f(p,c) phần nào, tìm thấy

f(p,c) = ∑i gipici - ∑i ℓipi(1-ci)
       = ∑i (ci(gi+ℓi) - ℓi)pi

Chứng minh Khẳng định 2. Chúng tôi đầu tiên cho thấy p* ∈ Δ1. Chúng ta có

∑i∈[n] p*i = ∑i≤k* p*i = ∑i≤k* 1/[Hk*(gi+ℓi)] = 1/Hk* ∑i≤k* (gi+ℓi)/(gi+ℓi) = Hk*/Hk* = 1

Và vì p*i ≥ 0 cho tất cả i, nó ngay lập tức theo sau rằng p*i ≤ 1 cũng vậy.

Bây giờ chúng tôi cho thấy N(k*) = min c∈Γn-m f(p*,c). Để làm điều này,

f(p*,c) = ∑i∈[n] (ci(gi+ℓi) - ℓi)p*i
        = ∑i≤k* (ci(gi+ℓi) - ℓi)/[Hk*(gi+ℓi)]
        = ∑i≤k* ci(gi+ℓi)/[Hk*(gi+ℓi)] - ∑i≤k* (gi+ℓi)/[Hk*(gi+ℓi)] + ∑i≤k* gi/[Hk*(gi+ℓi)]
        = 1/Hk* ∑i≤k* ci - k*/Hk* + Gk*/Hk*

Rõ ràng, cho c ∈ Γn-m, biểu thức này được tối thiểu hóa khi ci = 1 cho i > k* và ∑i≤k* ci = k* - m. Vậy chúng ta có

min c∈Γn-m f(p*,c) = 1/Hk*(k*-m) - k*/Hk* + Gk*/Hk*
                    = (Gk*-m)/Hk* = N(k*)

như đã khẳng định.

Bây giờ chúng tôi chứng minh khẳng định thứ hai của chúng tôi.

Chứng minh Khẳng định 3. Chúng tôi đầu tiên cho thấy rằng N(k*) ≥ gi cho i > k*.¹ Quan sát rằng nếu a/b ≥ (a+c)/(b+d), thì a/b ≥ c/d cho các giá trị không âm (và b > 0, d > 0). Lưu ý

(Gk*-m)/Hk* = N(k*) ≥ N(k*+1) = (Gk* + gk*+1/(gk*+1+ℓk*+1) - m)/(Hk* + 1/(gk*+1+ℓk*+1))

¹Trong trường hợp biên mà k* = n, chúng ta có thể thêm một mục giả với gn+1 = 0 và khẳng định theo sau một cách tầm thường.

15

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Bằng quan sát của chúng tôi,

N(k*) ≥ gk*+1/(gk*+1+ℓk*+1) / [1/(gk*+1+ℓk*+1)] = gk*+1 ≥ gi cho i > k*.

Tương tự, chúng tôi cho thấy N(k*) ≤ gi cho i ≤ k*, sử dụng quan sát rằng nếu a/b ≥ c/d thì a/b ≥ c/d cho các giá trị không âm (và b ≥ d > 0 và d > 0). Lưu ý

N(k*-1) = (Gk* - gk*/(gk*+ℓk*) - m)/(Hk* - 1/(gk*+ℓk*)) ≤ (Gk*-m)/Hk* = N(k*)

Và một lần nữa, bằng quan sát của chúng tôi,

N(k*) ≥ gk*/(gk*+ℓk*) / [1/(gk*+ℓk*)] = gk* ≥ gi cho i ≤ k*. (5)

Bây giờ chúng tôi sẵn sàng chứng minh khẳng định.

Chúng tôi đầu tiên cho thấy c* ∈ Γn-m. Vì N(k*) ≤ gi cho i ≤ k*, chúng ta thấy c*i = (N(k*)+ℓi)/(gi+ℓi) ≤ 1 cho i ≤ k*. Vậy c*i ∈ [0,1]. Hơn nữa,

∑i∈[n] c*i = ∑i≤k* (N(k*)+ℓi)/(gi+ℓi) + ∑k*<i≤n 1
           = ∑i≤k* (N(k*)-gi)/(gi+ℓi) + ∑i≤k* (gi+ℓi)/(gi+ℓi) + ∑k*<i≤n 1
           = N(k*)Hk* - Gk* + n
           = Gk* - m - Gk* + n = n - m

Tức là, c* ∈ Γn-m.

Cuối cùng, chúng tôi cho thấy N(k*) = max p∈Δ1 f(p,c*). Lưu ý rằng c*i(gi+ℓi) - ℓi = N(k*) cho i ≤ k*, trong khi c*i(gi+ℓi) - ℓi = gi cho i > k*. Chúng ta có

f(p,c*) = ∑i (c*i(gi+ℓi) - ℓi)pi
        = ∑i≤k* N(k*)pi + ∑i>k* gipi

Từ trên, N(k*) ≥ gi cho i > k*. Vậy biểu thức được tối đa hóa cho p ∈ Δ1 khi pi = 0 cho i > k* và ∑i≤k* pi = 1. Do đó,

max p∈Δ1 f(p,c*) = N(k*)

như chúng tôi muốn.

C.2 TÁC ĐỘNG CỦA VIỆC XẤP XỈ M

Ở đây, chúng tôi chứng minh rằng một giải pháp xấp xỉ tối ưu có thể được thu được ngay cả khi một giá trị xấp xỉ của m được sử dụng (ví dụ: qua một bộ dữ liệu xác thực). Để đơn giản, lemma sau xem xét trường hợp các tổn thất là 0 trong bối cảnh Định lý 1, tuy nhiên, việc tổng quát hóa nó đến lợi ích và tổn thất chung - bao gồm công thức lỗi tương đối mà chúng tôi nghiên cứu trong bài báo này - theo sau bằng cách chia tỷ lệ tham số lỗi ε một cách thích hợp.² Kết quả chính của chúng tôi là nếu chúng tôi có một xấp xỉ m̂ ∈ (1-ε)m, thì chúng tôi có thể sử dụng m xấp xỉ này để có được một giải pháp (1-2εm/(2εm+(1+ε)))-cạnh tranh.

²Lưu ý rằng kết quả này tổng quát hóa đến tổn thất tương đối RAD với w ↦ w như đã thảo luận trong Sec. 3 bằng cách xem xét m' = (1+w)m (xem Hệ quả 1).

16

--- TRANG 16 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Lemma 4. Gọi m ∈ [n] là giá trị thực tế của số lượng ví dụ không chính xác trong XB và gọi km là giải pháp tối ưu đối với m. Giả sử g1 ≥ ... ≥ gn và gọi δ = gkm và α = 2δ/(2δ). Giả sử rằng chúng ta có một xấp xỉ m̂ của m sao cho

m̂ ∈ (1-ε)m với ε ∈ (0,α);

thì giải pháp km̃ đối với m̃ = m̂/(1+ε) là (1-2εm/(2εm+(1+ε)))-cạnh tranh với giải pháp tối ưu, tức là, nó thỏa mãn

OBJ(km̃,m) ≥ (1-2εm)/(2εm+(1+ε)) OPT = (1-2εm)/(2εm+(1+ε)) OBJ(km,m);

trong đó OBJ(k,m) = (k-m)/Hk = maxk'∈[n] (k'-m)/Hk'.

Chứng minh. Để ngắn gọn ký hiệu, chúng tôi gọi k và k' ký hiệu km̃ và km, tương ứng. Đầu tiên, quan sát rằng bằng giả định của lemma, chúng ta có

m̃ = m̂/(1+ε) ≤ (1-ε)m/(1+ε) và m̃ ≤ m.

Lưu ý rằng vì km̃ ≥ m̃ bằng tính tối ưu của k' đối với m̃, chúng ta có k ≥ (1-ε)m/[(1+ε)(1-α)] > m điều này theo sau từ điều kiện tối ưu từ chứng minh Định lý 1,

k'gk'+1 ≥ Hk' + m̃k' + m̃) ⟹ k' ≥ m̃/(1-α)

và ε ∈ (0,α/(2α)). Vì k và m là nguyên, chúng ta có k ≥ m+1 ≥ m̃+1. Cuối cùng, bằng tính tối ưu của k' đối với m̃, chúng ta có

1/Hk ≥ (k-m̃)/((k-m̃)Hk).

Kết hợp tất cả những điều trên lại,

OBJ(k,m) = (k-m)/Hk
         = (k-m̃)/Hk - (m-m̃)/Hk
         ≥ (k-m̃)/Hk - (m-m̃)(k-m̃)/((k-m̃)Hk)
         = (k-m)/Hk · (1-(m-m̃)/(k-m̃))
         ≥ OPT · (1-(m-m̃)/(m+1))
         ≥ (1-2εm)/(2εm+(1+ε)) · OPT;

trong đó bất đẳng thức đầu tiên là bằng bất đẳng thức về cận dưới 1/Hk và k ≥ m+1, thứ hai bằng m̃ ≤ m, thứ ba bằng k ≥ m+1, và thứ tư bằng

m-m̃ ≤ 2εm/(1+ε);

và sắp xếp lại.

C.3 XẤP XỈ M

Tiếp theo, chúng tôi cho thấy cách ước lượng m bằng cách sử dụng một bộ dữ liệu xác thực T. Để làm điều này, chúng tôi định nghĩa

err(T,f) = 1/|T| ∑(x,y)∈T 1{f(x) ≠ y}

trong đó f(·) ∈ [k] tương ứng với dự đoán nhãn của mạng f. Lưu ý ở đây rằng

m = err(PB,f)|PB|

trong đó PB tương ứng với các điểm trong tập dữ liệu B.

17

--- TRANG 17 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Lemma 5. Cho bất kỳ δ ∈ (0,1), nếu chúng ta sử dụng một tập xác thực T có kích thước k để có được một xấp xỉ m̂ = err(T,f)|PB| cho m = err(PB,f)|PB|, thì với xác suất ít nhất 1-δ,

|m-m̂| ≤ |PB| [√(log(4/δ)-1)/(|PB|) + 1] [1/√k + √(2p(1-p)log(4/δ)) · (1/√|PB| + 1/√k)];

trong đó p = P(x,y)~D(f(x) ≠ y) là xác suất gán nhãn sai cho mạng f().

Chứng minh. Gọi T = {(x1,y1),...,(x|T|,y|T|)} là một tập |T| điểm i.i.d. từ phân phối dữ liệu D và định nghĩa Xi = 1{f(xi) ≠ yi} cho mỗi i ∈ |T|. Gọi X = 1/|T| ∑i Xi, chúng ta quan sát rằng

E[X] = E(x,y)~D[1{f(x) ≠ y}] = P(x,y)~D(f(x) ≠ y) = p.

Vì chúng ta có một tổng k = |T| biến ngẫu nhiên độc lập mỗi cái bị chặn bởi 1 với phương sai Var(Xi) = p(1-p), chúng tôi gọi bất đẳng thức Bernstein (Bernstein, 1924) để có được

P(|X-p| ≥ εT) ≤ 2exp(-kε²T/[2(p(1-p) + εT/3)]);

đặt điều trên bằng δ/2 và giải cho εT cho ra

|X-p| ≤ εT ≤ log(4/δ)/k + √(2p(1-p)log(4/δ)/k);

với xác suất ít nhất 1-δ/2. Tương tự, chúng ta có thể định nghĩa các biến ngẫu nhiên Y1,...,Y|PB| sao cho Yi = 1{f(xi) ≠ yi} cho mỗi (xi,yi) ∈ PB. Gọi Y = 1/|PB| ∑i Yi và quan sát rằng E[Y] = p như trước, chúng tôi gọi bất đẳng thức Bernstein một lần nữa để có được rằng với xác suất ít nhất 1-δ/2,

|Y-p| ≤ εPB ≤ log(4/δ)/|PB| + √(2p(1-p)log(4/δ)/|PB|).

Phát biểu theo sau bằng bất đẳng thức tam giác |Y-X| ≤ |Y-p| + |X-p| và giới hạn hợp.

D ĐÁNH GIÁ BỔ SUNG & CHI TIẾT THỰC NGHIỆM

Ở đây, chúng tôi mô tả các chi tiết thực nghiệm và siêu tham số được sử dụng trong các đánh giá của chúng tôi và cung cấp các kết quả thực nghiệm bổ sung bổ sung cho những cái được trình bày trong bài báo. Các đánh giá bổ sung của chúng tôi hỗ trợ độ bền vững và khả năng ứng dụng rộng rãi của phương pháp chúng tôi.

D.1 CHI TIẾT THỰC NGHIỆM

Chúng tôi thực hiện các đánh giá của chúng tôi trên 64 TPU v4s mỗi cái với hai lõi. Chúng tôi sử dụng một bộ dữ liệu xác thực có kích thước 1,000 cho các bộ dữ liệu CIFAR10, CIFAR100, và SVHN, và sử dụng một bộ dữ liệu xác thực có kích thước 10,000 cho ImageNet, tương ứng, để ước lượng m. Các siêu tham số được sử dụng đối với mỗi kiến trúc và bộ dữ liệu tương ứng như sau.

MobileNet (CIFAR10, CIFAR100, SVHN) Cho các thí nghiệm liên quan đến MobileNet (Howard et al., 2017), bất cứ khi nào MobileNet được sử dụng như một kiến trúc học sinh, nó được khởi tạo với tham số chiều rộng 1, và bất cứ khi nào nó được sử dụng như một giáo viên, nó được khởi tạo với tham số chiều rộng 2. Chúng tôi sử dụng trình tối ưu Adam (Kingma & Ba, 2014) với các tham số mặc định (tỷ lệ học: 1e-3) và đào tạo trong 100 hoặc 200 epoch tùy thuộc vào cấu hình thực nghiệm. Chúng tôi không sử dụng tăng cường dữ liệu hoặc chính quy hóa trọng số.

ResNets và ResNetv2s (CIFAR10, CIFAR100, SVHN) Chúng tôi sử dụng trình tối ưu Adam (Kingma & Ba, 2014) với các tham số mặc định ngoại trừ lịch trình tỷ lệ học như sau. Cho một số epoch nepochs ∈ {100,200}, chúng tôi sử dụng 1e-3 làm tỷ lệ học cho (2/5)nepochs đầu tiên, sau đó sử dụng 1e-4 đến (3/5)nepochs, 1e-5 đến (4/5)nepochs, 1e-6 đến (9/10)nepochs, và cuối cùng 5e-7 đến kết thúc. Chúng tôi sử dụng các giá trị làm tròn cho các cửa sổ epoch xác định lịch trình tỷ lệ học thành các giá trị nguyên khi cần thiết. Chúng tôi không sử dụng tăng cường dữ liệu hoặc chính quy hóa trọng số.

18

--- TRANG 18 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
D.2 IMAGENET

Thiết lập Chúng tôi sử dụng một mô hình học sinh ResNet-18 và giáo viên ResNet-50 cho các thí nghiệm ImageNet. Chúng tôi đào tạo mô hình học sinh trong 100 epoch sử dụng SGD với momentum (β = 0.9) với kích thước batch 256 và một lịch trình tỷ lệ học như sau. Cho 5 epoch đầu tiên, chúng tôi tăng tuyến tính tỷ lệ học từ 0 đến 0.1, 30 epoch tiếp theo chúng tôi sử dụng tỷ lệ học 0.1, 30 epoch tiếp theo sau đó, chúng tôi sử dụng tỷ lệ học 0.01, 20 epoch tiếp theo chúng tôi sử dụng tỷ lệ học 0.001, và sử dụng tỷ lệ học 0.0001 cho các epoch còn lại. Chúng tôi sử dụng lật ngang ngẫu nhiên như tăng cường dữ liệu của chúng tôi.

Phương pháp Các thực hiện của RAD, MARGIN, ENTROPY, và UNIFORM giống như trong các đánh giá của chúng tôi về CIFAR10/100 và SVHN trong Sec 4. Tuy nhiên, các thuật toán Cluster Margin (CM) (Citovsky et al., 2021) và CORESET (Sener & Savarese, 2017) yêu cầu các hoạt động phân cụm đắt đỏ và không thể áp dụng cho ImageNet sẵn có do hạn chế bộ nhớ và tính toán. Tuy nhiên, chúng tôi thực hiện một phiên bản xấp xỉ của CM để hoàn thiện. Chúng tôi chọn CM thay vì CORESET vì nó hiện tại là tiên tiến và Citovsky et al. (2021) đã chứng minh rằng nó vượt trội so với CORESET trong các cài đặt quy mô lớn. Cho phiên bản xấp xỉ của CM, chúng tôi phân chia 1.1M hình ảnh thành các nhóm có kích thước 10,000 và chạy phân cụm HAC trong mỗi nhóm. Chúng tôi dừng khi số lượng cụm được tạo ra đạt 500. Điều này dẫn đến 56,000 cụm tổng cộng, sau đó chúng tôi áp dụng thuật toán CM theo cách thông thường.

D.3 NGOÀI ĐỘ CHÍNH XÁC KIỂM TRA & SO SÁNH VỚI THAM LAM

Chúng tôi điều tra hiệu suất của mô hình học sinh ngoài độ chính xác kiểm tra cuối cùng được báo cáo và xác minh tính hợp lệ của công thức vấn đề của chúng tôi. Cụ thể, chúng tôi đặt câu hỏi (i) liệu phương pháp của chúng tôi cũng dẫn đến độ chính xác học sinh được cải thiện qua tất cả các epoch trong quá trình đào tạo và (ii) liệu nó thực sự đạt được lợi ích cao hơn đối với công thức chưng cất bền vững ((4), Sec. 3) so với việc sử dụng thuật toán BIÊN TIÊU CHUẨN (tham lam) đơn giản chọn các điểm lợi ích cao nhất và lấy mẫu ĐỀU. Để làm điều này, chúng tôi thực hiện các đánh giá trên các bộ dữ liệu CIFAR10, CIFAR100, và SVHN tương tự như những cái trong Sec. 4, và báo cáo thêm độ chính xác kiểm tra qua mỗi epoch cho lần lặp chưng cất kiến thức cuối cùng và lợi ích được thực hiện qua các lần lặp chưng cất tích cực.

Hình 5 tóm tắt kết quả các thí nghiệm của chúng tôi cho các cấu hình chưng cất kiến thức khác nhau. Từ các hình, chúng tôi quan sát rằng phương pháp của chúng tôi đồng thời đạt được độ chính xác kiểm tra cuối cùng cao hơn (cột đầu tiên) và thường độ chính xác kiểm tra cao hơn qua toàn bộ quỹ đạo đào tạo (cột thứ hai). Điều này gợi ý rằng những cải thiện chúng tôi có được từ phương pháp của chúng tôi là nhất quán và có mặt bất kể khi đào tạo học sinh được kết thúc. Trong cột thứ ba của Hình 5, chúng tôi cũng quan sát rằng phương pháp của chúng tôi đạt được lợi ích được thực hiện cao nhất trong số các phương pháp được đánh giá và lợi ích này có xu hướng là một dự đoán tốt về hiệu suất của phương pháp. Điều này làm sáng tỏ tại sao biến thể tham lam (BIÊN TIÊU CHUẨN) đơn giản chọn các điểm với biên thấp nhất (lợi ích cao nhất) không thành công nhất quán trong thực tế: các điểm lợi ích cao thường bị gán nhãn sai bởi giáo viên, làm cho học sinh bối rối hơn. Điều này tiếp tục thúc đẩy công thức bền vững của chúng tôi trong Sec. 3 và hỗ trợ tính thực tế của nó.

D.4 ÁP DỤNG RAD CHO HỌC TÍCH CỰC TIÊU CHUẨN

Ở đây, chúng tôi chứng minh khả năng ứng dụng của RAD cho các cài đặt học tích cực tiêu chuẩn và so sánh hiệu suất của nó với các chiến lược SOTA. Điều này được thúc đẩy bởi công việc gần đây đã chứng minh rằng việc chọn các mẫu khó khăn nhất hoặc có thông tin nhất - đối với một số liệu proxy - có thể thực sự cản trở việc đào tạo mô hình (Paul et al., 2022; 2021). Ví dụ, trên CIFAR10, việc chọn các thể hiện khó khăn nhất được quan sát là có hại cho đào tạo, và chiến lược tốt nhất được tìm thấy là một chiến lược mà các điểm khó khăn vừa phải được chọn (Paul et al., 2022; 2021). Phương pháp lấy mẫu này gợi nhớ đến các xác suất lấy mẫu được tạo ra bởi RAD như được mô tả trong Hình 2. Kết quả các thí nghiệm được hiển thị trong Hình 6. RAD khớp hoặc cải thiện hiệu suất của các kỹ thuật tiên tiến.

Kết quả các thí nghiệm học tích cực được hiển thị trong Hình 6. Vì không có mô hình giáo viên liên quan, chúng tôi khởi tạo RAD với m = 0.05n cho số lượng sai lầm giáo viên. Điều này dựa trên các nghiên cứu thực nghiệm cho thấy khoảng 5% điểm dữ liệu cố hữu quá khó khăn (Paul et al., 2022; 2021) hoặc là ngoại lệ có thể làm suy giảm đào tạo. Việc đặt giá trị thích hợp cho m khi áp dụng RAD cho cài đặt học tích cực tiêu chuẩn vẫn là một câu hỏi mở, và là một hướng thú vị cho công việc tương lai. Kết quả trong Hình 6 cho thấy rằng RAD cạnh tranh với các thuật toán học tích cực tiên tiến trong các tình huống được đánh giá và khớp hoặc cải thiện hiệu suất của kỹ thuật học tích cực hoạt động tốt nhất. Chúng tôi nhấn mạnh rằng, trái ngược với các phương pháp dựa trên phân cụm hiện có như CM hoặc Coreset, RAD đạt được hiệu suất này theo cách hiệu quả tính toán và hoàn toàn không có tham số cho một m cho trước.

19

--- TRANG 19 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Hình 5: Độ chính xác cuối cùng của học sinh (cột đầu tiên), độ chính xác kiểm tra của học sinh qua quỹ đạo đào tạo (cột thứ hai), và các lợi ích được thực hiện (cột thứ ba). Phương pháp của chúng tôi tạo ra các mô hình học sinh thường đạt được độ chính xác kiểm tra và lợi ích cao hơn đối với công thức trong Sec. 3 qua các tình huống được đánh giá.

Hình 6: Đánh giá trong cài đặt học tích cực tiêu chuẩn.

20

--- TRANG 20 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
D.5 ĐỘ BỀN VỮNG ĐỐI VỚI LỰA CHỌN CỦA w

Trong phần này, chúng tôi đánh giá độ bền vững của RAD bằng cách đánh giá hiệu suất của thuật toán với các khởi tạo khác nhau cho tham số w trên một loạt rộng các tình huống chưng cất trải dài các bộ dữ liệu CIFAR10, CIFAR100, và SVHN và các kiến trúc resnet học sinh-giáo viên khác nhau. Kết quả các thí nghiệm so sánh RAD với cài đặt mặc định w = 1-m/n như mô tả trong Sec. 3 (Của chúng tôi) với các biến thể RAD với w ∈ {0.0, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 1.0} được hiển thị trong Hình 7. Kết quả được lấy trung bình trên 5 thử nghiệm. Như chúng ta có thể thấy từ hình, hiệu suất của RAD vẫn tương đối nhất quán (thường trong một độ lệch chuẩn) qua các lựa chọn w khác nhau. Hơn nữa, lựa chọn w = 1-m/n có nguồn gốc lý thuyết hoạt động nhất quán tốt qua các tình huống được đánh giá - nó luôn luôn trong một độ lệch chuẩn của w hoạt động tốt nhất cho mỗi tình huống.

Hình 7: So sánh hiệu suất của RAD với các cài đặt khác nhau của siêu tham số w so với CỦA CHÚNG TÔI, sử dụng giá trị mặc định w = 1-m/n (tức là, độ chính xác giáo viên). Hiệu suất chồng chéo của các khởi tạo khác nhau (trong vùng bóng của một độ lệch chuẩn) hỗ trợ độ bền vững của RAD đối với các cài đặt w ∈ [0,1] khác nhau.

21

--- TRANG 21 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
D.6 ĐỘ BỀN VỮNG ĐỐI VỚI LỰA CHỌN CỦA LỢI ÍCH

Trong các đánh giá thực nghiệm của chúng tôi, chúng tôi đã cho đến nay chỉ xem xét một định nghĩa cụ thể của lợi ích đối với biên của học sinh như mô tả trong Sec. 3, tức là, gi = 1 - margini. Vì RAD có thể được sử dụng chung với bất kỳ khái niệm lợi ích do người dùng chỉ định nào, trong phần này chúng tôi điều tra hiệu suất của RAD khi entropy của dự đoán softmax học sinh fstudent(xi) ∈ [0,1]k được sử dụng để định nghĩa lợi ích, tức là,

gi = Entropy(fstudent(xi)) = -∑(j=1 to k) fstudent(xi)j log fstudent(xi)j.

Chúng tôi gắn nhãn thuật toán này RAD ENTROPY và so sánh hiệu suất của nó với biến thể của chúng tôi sử dụng biên học sinh.

Hình 8 cho thấy kết quả so sánh của chúng tôi với các cấu hình chưng cất, kiến trúc, và bộ dữ liệu khác nhau được lấy trung bình trên 5 thử nghiệm. Tổng thể, chúng tôi quan sát rằng sự thay đổi trong định nghĩa lợi ích không dẫn đến thay đổi đáng kể (> một độ lệch chuẩn) trong hiệu suất.

D.7 ĐỘ BỀN VỮNG ĐỐI VỚI CÁC CẤU HÌNH KHÁC NHAU

Trong phần này, chúng tôi xem xét độ bền vững của thuật toán của chúng tôi đối với các cấu hình khác nhau trên một bộ dữ liệu cố định. Cụ thể, chúng tôi xem xét bộ dữ liệu SVHN (Netzer et al., 2011) và xem xét hiệu suất với kích thước học sinh khác nhau (ResNetv2-{11, 20, 29}), kích thước giáo viên (ResNetv2-{56, 110}), |A| ∈ {5000, 10000, 20000}, b ∈ {1000, 2000, 5000}, và số epoch e = {100, 200}. Do hạn chế tài nguyên, chúng tôi thực hiện các so sánh rộng rãi với 2 thuật toán hoạt động tốt nhất từ phần chính của bài báo (Sec. 4): BIÊN (TIÊU CHUẨN) và ĐỀU. Kết quả đánh giá cho thấy phương pháp của chúng tôi hoạt động tốt hơn đều hoặc ít nhất cũng tốt như các phương pháp cạnh tranh.

22

--- TRANG 22 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Hình 8: So sánh RAD với lợi ích được định nghĩa đối với biên học sinh như trong Sec. 3.1, CỦA CHÚNG TÔI, với RAD với lợi ích được định nghĩa đối với entropy của dự đoán học sinh, RAD ENTROPY. Hiệu suất của RAD bền vững đối với khái niệm không chắc chắn thay thế để định nghĩa lợi ích.

23

--- TRANG 23 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Hình 9: Kiến trúc ResNetv2-11 với 100 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

Hình 10: Kiến trúc ResNetv2-11 với 200 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

24

--- TRANG 24 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Hình 11: Kiến trúc ResNetv2-11 với 200 epoch và |A| = 10000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

Hình 12: Kiến trúc ResNetv2-11 với 200 epoch và |A| = 20000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

25

--- TRANG 25 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Hình 13: Kiến trúc ResNetv2-20 với 100 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

Hình 14: Kiến trúc ResNetv2-20 với 200 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

26

--- TRANG 26 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
Hình 15: Kiến trúc ResNetv2-20 với 200 epoch và |A| = 10000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

Hình 16: Kiến trúc ResNetv2-29 với 200 epoch và |A| = 5000. Hàng đầu tiên: giáo viên ResNetv2-56; hàng thứ hai: giáo viên ResNetv2-101. Các cột tương ứng với kích thước batch b = 1000, b = 2000, và b = 5000, tương ứng.

27

--- TRANG 27 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2023
D.8 THÍ NGHIỆM VỚI CÁC MÔ HÌNH GIÁO VIÊN ĐƯỢC ĐÀO TẠO TRƯỚC

Hình 17: Đánh giá trên với một mô hình giáo viên ResNet được đào tạo trước trên ImageNet và tinh chỉnh trên các bộ dữ liệu tương ứng. RAD hoạt động đều ít nhất cũng tốt như phương pháp so sánh tốt nhất, và thường tốt hơn đặc biệt trong chế độ mẫu thấp.

Trong phần này, chúng tôi trình bày các đánh giá với các mô hình giáo viên ResNet50 và ResNet101 được đào tạo trước trên ImageNet và tinh chỉnh trên dữ liệu có nhãn có sẵn cho các bộ dữ liệu học thuật mà chúng tôi xem xét. Hình 17 mô tả kết quả đánh giá của chúng tôi trên các bộ dữ liệu CIFAR100 và SVHN. Phù hợp với xu hướng kết quả của chúng tôi trong Sec. 4, RAD hoạt động đều vượt trội hoặc khớp hiệu suất của phương pháp so sánh hoạt động tốt nhất qua tất cả các tình huống.

D.9 ĐÁNH GIÁ NLP

Hình 18: Đánh giá trên bộ dữ liệu IMDB với một mô hình học sinh BERT nhỏ và một giáo viên BERT được đào tạo trước.

Chúng tôi kết thúc các kết quả bổ sung bằng cách trình bày các đánh giá trên một nhiệm vụ Xử lý Ngôn ngữ Tự nhiên (NLP) trên bộ dữ liệu IMDB Reviews (Maas et al., 2011) với một mô hình giáo viên BERT được đào tạo trước. Bộ dữ liệu IMDB có 25,000 điểm dữ liệu đào tạo và 25,000 điểm dữ liệu kiểm tra, nơi mỗi điểm dữ liệu là một đánh giá phim. Nhiệm vụ là phân loại mỗi đánh giá là tích cực hoặc tiêu cực. Chúng tôi sử dụng một SmallBERT (Turc et al., 2019) 12 lớp được đào tạo trước với chiều ẩn 768 như mô hình giáo viên và một SmallBERT 2 lớp được khởi tạo ngẫu nhiên với chiều ẩn 128 như học sinh. Từ Hình 18 chúng ta thấy rằng hiệu quả được cải thiện của RAD so với các phương pháp so sánh vẫn tồn tại trên nhiệm vụ NLP, phù hợp với các đánh giá của chúng tôi trên các bộ dữ liệu thị giác. RAD đặc biệt hiệu quả trong chế độ mẫu nhỏ, nơi số lượng điểm có nhãn mềm nhỏ so với kích thước của bộ dữ liệu không có nhãn.

28

# 2303.14595.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-distillation/2303.14595.pdf
# Kích thước tệp: 1115022 byte

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Bảo toàn Khả năng Phân tách Tuyến tính trong Học liên tục
bằng Phép chiếu Đặc trưng Ngược
Qiao Gu
University of Toronto
qgu@cs.toronto.eduDongsub Shim
LG AI Research
dongsub.shim@lgresearch.aiFlorian Shkurti
University of Toronto
florian@cs.toronto.edu
Tóm tắt
Quên thảm khốc đã là một thách thức lớn trong học liên tục, nơi mô hình cần học các tác vụ mới với quyền truy cập hạn chế hoặc không có quyền truy cập vào dữ liệu từ các tác vụ đã thấy trước đó. Để giải quyết thách thức này, các phương pháp dựa trên chưng cất kiến thức trong không gian đặc trưng đã được đề xuất và cho thấy giảm quên [16, 19, 27]. Tuy nhiên, hầu hết các phương pháp chưng cất đặc trưng trực tiếp ràng buộc các đặc trưng mới để khớp với các đặc trưng cũ, bỏ qua nhu cầu về tính dẻo dai. Để đạt được sự cân bằng ổn định-dẻo dai tốt hơn, chúng tôi đề xuất Phép chiếu Đặc trưng Ngược (BFP), một phương pháp cho học liên tục cho phép các đặc trưng mới thay đổi đến mức một phép biến đổi tuyến tính có thể học được của các đặc trưng cũ. BFP bảo toàn khả năng phân tách tuyến tính của các lớp cũ trong khi cho phép sự xuất hiện của các hướng đặc trưng mới để chứa các lớp mới. BFP có thể được tích hợp với các phương pháp phát lại kinh nghiệm hiện có và tăng hiệu suất với một biên độ đáng kể. Chúng tôi cũng chứng minh rằng BFP giúp học một không gian biểu diễn tốt hơn, trong đó khả năng phân tách tuyến tính được bảo toàn tốt trong quá trình học liên tục và thăm dò tuyến tính đạt độ chính xác phân loại cao. Mã có thể được tìm thấy tại https://github.com/rvl-lab-utoronto/BFP.
1. Giới thiệu
Mặc dù có nhiều thành công, các mạng nơ-ron sâu vẫn dễ bị quên thảm khốc [39], theo đó hiệu suất của mô hình trên các tác vụ cũ suy giảm đáng kể trong khi nó đang học giải quyết các tác vụ mới. Quên thảm khốc đã trở thành một thách thức lớn cho các kịch bản học liên tục (CL), nơi mô hình được huấn luyện trên một chuỗi các tác vụ, với quyền truy cập hạn chế hoặc không có vào dữ liệu huấn luyện cũ.
Khả năng học liên tục mà không quên là rất quan trọng đối với nhiều ứng dụng thực tế, chẳng hạn như thị giác máy tính [38, 50], robot thông minh [32], và xử lý ngôn ngữ tự nhiên [6, 25]. Trong những môi trường này, một tác nhân học từ một dòng dữ liệu hoặc tác vụ mới, nhưng việc huấn luyện trên dữ liệu cũ bị hạn chế do giới hạn về lưu trữ, mở rộng thời gian huấn luyện, hoặc thậm chí là lo ngại về quyền riêng tư.
Không gian đặc trưng 𝑧′ (t-SNE) 
sau khi huấn luyện trên tác vụ 1Không gian đặc trưng 𝑧 (t-SNE) 
sau khi huấn luyện trên tác vụ 2Lớp 3
Lớp 4Tác vụ 2
Lớp 1
Lớp 2Tác vụ 1Học liên tụcPhép chiếu Đặc trưng Ngược
𝐿𝐵𝐹𝑃=𝐴𝑧−𝑧′2
Hình 1. Phân phối đặc trưng trước và sau khi huấn luyện trên một tác vụ trong thí nghiệm học tăng dần lớp trên MNIST, được trực quan hóa bằng t-SNE. Trái: trước khi huấn luyện trên tác vụ 2, các lớp đã thấy (1,2) được học để có thể phân tách dọc theo trục ngang để phân loại, trong khi các lớp chưa thấy (3, 4) không thể phân tách. Phải: sau khi huấn luyện trên tác vụ 2, trục dọc mới được học để phân tách các lớp mới (3,4). Dựa trên quan sát này, chúng tôi đề xuất mất mát Phép chiếu Đặc trưng Ngược LBFP, cho phép các chiều đặc trưng mới xuất hiện để phân tách các lớp mới trong không gian đặc trưng và cũng bảo toàn khả năng phân tách tuyến tính của các lớp cũ để giảm quên thảm khốc.
Vấn đề học liên tục đã nhận được sự chú ý đáng kể và nhiều chủ đề giải pháp đã xuất hiện. Các phương pháp phát lại kinh nghiệm [8, 35], ví dụ, lưu trữ một số lượng hạn chế (hoặc tạo ra) các ví dụ huấn luyện cũ và sử dụng chúng cùng với dữ liệu mới trong học liên tục. Các phương pháp chính quy hóa tham số [31,54] hạn chế sự thay đổi của các tham số mạng quan trọng. Các phương pháp chưng cất kiến thức [16, 19, 33] chính quy hóa đầu ra trung gian của mô hình CL để bảo toàn kiến thức từ các tác vụ cũ. Các phương pháp kiến trúc [36, 44, 52] áp dụng các kỹ thuật mở rộng và cô lập với mạng nơ-ron để ngăn chặn quên.
Tất cả các phương pháp này đều cố gắng cân bằng việc học kiến thức mới (tính dẻo dai) và giữ lại kiến thức cũ (tính ổn định).
Chúng tôi trình bày một thuật toán học liên tục, tập trung vào chưng cất kiến thức (KD) trong không gian đặc trưng. Trong bối cảnh học liên tục, KD coi mô hình học liên tục như học sinh và checkpoint cũ của nó như giáo viên và chính quy hóa các đầu ra trung gian của mạng để giảm quên
1arXiv:2303.14595v3  [cs.LG]  28 Jun 2023

--- TRANG 2 ---
ting [4, 8, 11, 16, 17, 19, 27, 33]. Mặc dù các phương pháp CL gần đây dựa trên KD đã hiệu quả trong việc giảm quên, chúng thường áp dụng khoảng cách L2 cho chưng cất, buộc các đặc trưng đã học phải gần với các giá trị cũ chính xác của chúng.
Điều này quá hạn chế và dẫn đến các mô hình CL cứng nhắc hơn trong việc giữ lại kiến thức cũ (tính ổn định mạnh hơn), nhưng ít linh hoạt hơn trong việc thích ứng với các tác vụ mới (tính dẻo dai yếu hơn). Phương pháp của chúng tôi có sự cân bằng tốt hơn giữa tính ổn định và tính dẻo dai.
Trong bài báo này, chúng tôi chú ý đến không gian đặc trưng trong CL và nghiên cứu sự tiến hóa của nó. Chúng tôi cho thấy rằng một số lượng nhỏ các hướng chính giải thích hầu hết sự biến thiên trong không gian đặc trưng và chỉ những hướng này là quan trọng cho phân loại. Một số lượng lớn các hướng trong không gian đặc trưng có sự biến thiên ít và vẫn chưa được sử dụng. Khi mô hình được huấn luyện trên các tác vụ mới, các đặc trưng mới cần được học dọc theo những hướng chưa sử dụng đó để chứa các lớp mới, như được minh họa trong Hình 1. Không xử lý quên, các hướng chính cũ, dọc theo đó các lớp cũ có thể phân tách tuyến tính, sẽ bị quên. Kết quả của chúng tôi chỉ ra rằng việc quên như vậy các hướng chính đã học trong không gian đặc trưng là một lý do quan trọng cho quên thảm khốc.
Dựa trên hiểu biết này, như được thể hiện trong Hình 1, chúng tôi đề xuất một mất mát Phép chiếu Đặc trưng Ngược (BFP), một mất mát chưng cất đặc trưng hiệu quả áp đặt tính nhất quán đặc trưng đến mức một phép biến đổi tuyến tính có thể học được, không áp đặt sự bằng nhau chính xác của các đặc trưng. Phép biến đổi này nhằm bảo toàn khả năng phân tách tuyến tính của các đặc trưng ngược theo thời gian. Chúng tôi cho thấy rằng phép chiếu tuyến tính này là quan trọng vì nó có thể xoay, phản chiếu và mở rộng các đặc trưng, trong khi duy trì khả năng phân tách tuyến tính của các lớp đã học trước đó trong không gian đặc trưng mới.
Chiếu ngược cho phép các đặc trưng thay đổi và các ranh giới quyết định mới được học dọc theo các hướng đặc trưng chưa sử dụng để phân loại các lớp mới. BFP có thể được tích hợp vào các phương pháp CL hiện có một cách đơn giản và các thí nghiệm cho thấy rằng thay đổi đơn giản này tăng hiệu suất so với các đường cơ sở bằng một biên độ lớn.
Các thí nghiệm của chúng tôi cho thấy rằng mất mát chính quy hóa BFP được đề xuất có thể cải thiện các phương pháp cơ sở lên đến 6%-8% trên các bộ dữ liệu Split-CIFAR10 và Split-CIFAR100 thách thức, đạt được độ chính xác học tăng dần lớp hiện đại. Quan trọng hơn, các thí nghiệm thăm dò tuyến tính cho thấy rằng BFP dẫn đến một không gian đặc trưng tốt hơn nơi các lớp khác nhau có thể phân tách hơn. Xem Hình 1 để có một ví dụ minh họa. Đóng góp của chúng tôi như sau:
• Chúng tôi cung cấp một phân tích về sự tiến hóa không gian đặc trưng trong quá trình học liên tục, phân biệt các thành phần đặc trưng quan trọng với những thành phần không quan trọng.
• Chúng tôi đề xuất mất mát Phép chiếu Đặc trưng Ngược (BFP), bảo toàn khả năng phân tách tuyến tính của các lớp cũ trong khi cho phép tính dẻo dai trong quá trình học liên tục, tức là các đặc trưng được phép thay đổi.
• Khi kết hợp với các đường cơ sở phát lại kinh nghiệm đơn giản, BFP giúp học không gian đặc trưng tốt hơn và đạt được hiệu suất hiện đại trên các bộ dữ liệu thách thức.
2. Công trình liên quan
2.1. Các phương pháp Phát lại Kinh nghiệm
Các phương pháp phát lại kinh nghiệm hoặc tập dượt sử dụng một bộ đệm bộ nhớ nhỏ để giữ dữ liệu huấn luyện của các tác vụ cũ. Khi mô hình đang huấn luyện trên tác vụ mới, các ví dụ huấn luyện cũ được trích xuất và huấn luyện cùng với những ví dụ mới. Các phương pháp CL dựa trên phát lại gần đây chủ yếu khác nhau ở ba thành phần, cụ thể là những ví dụ nào để lưu trữ, cách các ví dụ được phát lại, và cách cập nhật mạng sử dụng các ví dụ cũ. Công trình gần đây đã tập trung vào việc phát triển ba thành phần được đề cập ở trên. ICaRL [42] chọn các ví dụ vào bộ nhớ sao cho trung bình trong không gian đặc trưng của bộ đệm bộ nhớ khớp với dữ liệu huấn luyện. MIR [2] ưu tiên phát lại các ví dụ bị can thiệp nhiều nhất bởi một cập nhật ảo trên các tham số mạng. DER/DER++ [8] tăng cường mất mát entropy chéo với mất mát chưng cất logit khi dữ liệu bộ nhớ được phát lại. GEM [35] và A-GEM [13] phát triển các ràng buộc tối ưu hóa khi được huấn luyện trên các tác vụ mới sử dụng dữ liệu cũ từ bộ nhớ. Một số công trình khác [34, 46, 49] cũng học tạo ra hình ảnh để phát lại trong CL, nhưng việc huấn luyện liên tục của mạng tạo sinh thêm một số thách thức bổ sung. Mặc dù ý tưởng đơn giản, các phương pháp phát lại kinh nghiệm thường đạt hiệu suất tốt hơn so với các loại phương pháp khác, điều này đánh dấu tầm quan trọng của việc lưu trữ dữ liệu cũ.
2.2. Các phương pháp Chính quy hóa Tham số
Các phương pháp chính quy hóa tham số nghiên cứu tác động của thay đổi trọng số mạng nơ-ron đến mất mát tác vụ và hạn chế chuyển động của những trọng số quan trọng, điều mà nếu không sẽ gây ra quên trên các tác vụ cũ. Dòng công trình này thường không dựa vào bộ đệm phát lại cho dữ liệu tác vụ cũ. Một trong những công trình tiên phong theo hướng này là EWC [28], đề xuất sử dụng Ma trận Thông tin Fisher thực nghiệm để ước tính tầm quan trọng của trọng số và chính quy hóa thay đổi trọng số trong học liên tục. SI [54] sử dụng tích phân đường dẫn ước tính trong quá trình tối ưu hóa làm trọng số chính quy hóa cho các tham số mạng. MAS [1] cải thiện ý tưởng này bằng cách áp dụng độ lớn gradient như một thước đo độ nhạy. RWalk [12] kết hợp ma trận thông tin Fisher và tích phân đường dẫn trực tuyến để xấp xỉ tầm quan trọng của tham số và cũng giữ một bộ nhớ để cải thiện kết quả.
2.3. Các phương pháp Chưng cất Kiến thức
Ban đầu được thiết kế để chuyển giao kiến thức đã học của một mạng lớn hơn (giáo viên) sang một mạng nhỏ hơn (học sinh), các phương pháp chưng cất kiến thức đã được thích ứng để giảm sự trôi dạt kích hoạt và đặc trưng trong học liên tục. Khác với các phương pháp chính quy hóa tham số trực tiếp chính quy hóa
2

--- TRANG 3 ---
các trọng số mạng, các phương pháp KD chính quy hóa các đầu ra trung gian của mạng. Li et al. [33] đề xuất một phương pháp gọi là Learning without Forgetting (LwF), chính quy hóa các logit đầu ra giữa mô hình được học trực tuyến và checkpoint cũ. DER/DER++ [8] kết hợp chính quy hóa logit này với phát lại kinh nghiệm và cải thiện thêm hiệu suất. Sau đó Jung et al. [26] đề xuất thực hiện chưng cất kiến thức trên các bản đồ đặc trưng từ lớp gần cuối và đóng băng lớp phân loại cuối cùng. Pooled Output Distillation (PODNet) [19] mở rộng phương pháp chưng cất kiến thức đến các bản đồ đặc trưng trung gian, và nghiên cứu cách các cách gộp bản đồ đặc trưng khác nhau ảnh hưởng đến hiệu suất học liên tục. Họ đề xuất gộp các bản đồ đặc trưng dọc theo chiều cao và trọng lượng tương ứng để đạt được sự cân bằng ổn định-dẻo dai tốt. Công trình gần đây [16,27] cũng sử dụng thông tin gradient (ví dụ Grad-CAM) như các thuật ngữ trọng số trong mất mát chưng cất đặc trưng, sao cho các bản đồ đặc trưng quan trọng đối với các tác vụ cũ sẽ thay đổi ít hơn trong quá trình học liên tục.
Khác với các phương pháp KD hiện có, chúng tôi sử dụng một lớp tuyến tính có thể học được để chiếu các đặc trưng mới về các đặc trưng cũ. Ý tưởng này đã được khám phá trong [21,22], nhưng công trình của họ chỉ tích hợp nó trong một khung học tương phản và sử dụng một hàm ánh xạ phi tuyến. Tuy nhiên, trong công trình này, chúng tôi sử dụng một phép biến đổi tuyến tính có thể học được và công thức hóa nó như một mất mát chưng cất kiến thức đơn giản trong không gian đặc trưng. Chúng tôi chứng minh rằng phương pháp của chúng tôi thúc đẩy khả năng phân tách tuyến tính trong không gian đặc trưng trong quá trình học liên tục. Chúng tôi cũng cho thấy giá trị của BFP trong môi trường CL có giám sát với phát lại kinh nghiệm, và không cần tăng cường hoặc học tương phản.
3. Phương pháp
3.1. Thiết lập và Ký hiệu
Trong một thiết lập học liên tục điển hình, một mô hình f được huấn luyện tuần tự trên một tập hợp các tác vụ T={1,2,3,···, T}.
Trong mỗi tác vụ t, đầu vào x và đầu ra truth chân lý tương ứng y được rút i.i.d. từ phân phối dữ liệu tác vụ Dt= (Xt, Yt) và được sử dụng để huấn luyện mô hình. Ở đây Xt và Yt biểu thị tập hợp các đầu vào và đầu ra từ tác vụ t. Để minh họa phương pháp của chúng tôi, mô hình CL được phân tách thành hai phần fθ(x) = gϕ(hψ(x)) = gϕ◦hψ(x) với θ={ϕ, ψ}, trong đó h, được tham số hóa bởi ψ, là một trích xuất đặc trưng phi tuyến, ánh xạ hình ảnh đầu vào x đến một đặc trưng chiều thấp z∈Rd. Đầu phân loại g, được tham số hóa bởi ϕ, là một lớp tuyến tính ánh xạ đặc trưng tiềm ẩn z đến logit phân loại o∈Rc, trong đó c là tổng số lớp. Trong bài báo này, chúng tôi chủ yếu xem xét thiết lập học tăng dần lớp (Class-IL) và thiết lập học tăng dần tác vụ (Task-IL), và phương pháp được đề xuất hoạt động trên cả hai thiết lập. Trong những thiết lập này, Dt chứa dữ liệu huấn luyện từ một tập hợp các lớp Ct, trong đó Ct không giao nhau cho các
0 20 40 60 800100200300400500600Giá trị kỳ dị
0 20 40 60 800.00.20.40.60.8Độ chính xác: proj-acc( k
0 20 40 60 80
Chỉ số giá trị kỳ dị0.00.20.40.60.81.0Giá trị kỳ dị tương đối
0 20 40 60 80
Số hướng chính (lớn nhất)
được sử dụng: k0.00.20.40.60.81.0Độ chính xác tương đối: rel-proj-acc( k)
JT trên 10 lớp
JT trên 40 lớp
JT trên 70 lớp
JT trên 100 lớp
FT sau 10 lớp
FT sau 40 lớp
FT sau 70 lớp
FT sau 100 lớpHình 2. Phân phối đặc trưng và đóng góp vào phân loại trong quá trình học liên tục trên Split-CIFAR100 với 10 lớp mỗi tác vụ. Trái: phương sai đặc trưng (giá trị kỳ dị) dọc theo từng hướng chính; phải: độ chính xác phân loại proj-acc( k) sử dụng các đặc trưng được chiếu. Các biểu đồ trên cho thấy các giá trị kỳ dị và độ chính xác tuyệt đối, và những biểu đồ dưới cho thấy các giá trị tương đối của chúng, được chuẩn hóa bởi giá trị tối đa trên mỗi đường cong. Finetuning (FT) là một đường cơ sở CL ngây thơ không xử lý quên gì cả và cho hiệu suất giới hạn dưới. Joint Training (JT) là một phương pháp CL oracle được huấn luyện chung trên tất cả các lớp đã thấy cho đến nay và cho thấy giới hạn trên. Đối chiếu JT với FT tiết lộ các thuộc tính lý tưởng cho các phương pháp CL tốt. Khi mô hình được huấn luyện liên tục trên nhiều lớp hơn, nhiều chiều đặc trưng hơn được học và cần thiết cho phân loại. Tuy nhiên, so với chiều đặc trưng đầy đủ (512), chỉ một không gian con nhỏ (khoảng 10 hướng chính cho 10 lớp và 80 cho 100 lớp) là quan trọng cho hiệu suất CL, vì các độ chính xác tương đối nhanh chóng bão hòa với số hướng chính được sử dụng.
tác vụ t khác nhau. Trong Task-IL, các định danh tác vụ t cho mỗi đầu vào có sẵn trong thời gian đánh giá, và do đó mô hình có thể tập trung các ranh giới quyết định trong mỗi tác vụ. Ngược lại, Class-IL yêu cầu đưa ra quyết định giữa tất cả các lớp trong thời gian suy luận và do đó thách thức hơn. Chúng tôi tiếp tục ký hiệu mô hình sau khi huấn luyện trên tác vụ j là fj=gj◦hj, và đặc trưng được trích xuất bởi hj từ một điểm dữ liệu trong tác vụ i là zj_i=hj(x), x∈ D i. Tập hợp của tất cả zj_i tạo thành một ma trận đặc trưng Zj_i=hj(Di)∈Rd×n, và n là số điểm dữ liệu trong Di. Và tương tự, tập hợp các đặc trưng được trích xuất từ D1 đến Di sử dụng hj được ký hiệu bởi Zj_1:i=hj(D1:i).
3.2. Phân tích Quên Đặc trưng trong CL
Được thúc đẩy bởi công trình gần đây cho thấy rằng sự trôi dạt biểu diễn trong không gian đặc trưng đã là một nguyên nhân chính của quên thảm khốc [10, 20, 53], chúng tôi nghiên cứu sự tiến hóa của không gian đặc trưng trong CL và trả lời hai câu hỏi chính: (1) có bao nhiêu chiều (hướng chính) trong không gian đặc trưng đã học
3

--- TRANG 4 ---
được chiếm bởi dữ liệu? Và (2) có bao nhiều trong số chúng được sử dụng cho phân loại? Chúng tôi trả lời câu hỏi đầu tiên bằng cách thực hiện phân tích thành phần chính (PCA) [40] trên ma trận đặc trưng Zt_1:t, chứa đặc trưng được trích xuất bởi ht từ tất cả dữ liệu đã thấy cho đến nay D1:t. Giả sử phân tách giá trị kỳ dị của nó cho Zt_1:t=USVT, và sau đó các hướng chính là các vectơ kỳ dị trái U= [u1, u2,···, ud], trong đó ul∈Rd được sắp xếp theo các giá trị kỳ dị tương ứng sl. PCA cho phân phối dữ liệu của các tác vụ đã thấy trong không gian đặc trưng và do đó trả lời câu hỏi đầu tiên. Câu hỏi thứ hai được trả lời bằng cách đánh giá các đặc trưng được chiếu lên một không gian con được mở rộng bởi k hướng chính đầu tiên U1:k. Cụ thể, chúng tôi định nghĩa độ chính xác phân loại của các đặc trưng được chiếu là
proj-acc (k) =acc
y, gt(U1:kUT_1:kz)
(1)
trong đó k là số thành phần chính lớn nhất được sử dụng và proj-acc được tính toán trên tập kiểm tra của tác vụ t. Với k lớn hơn, nhiều thông tin hơn được giữ lại trong đặc trưng được chiếu U1:kUT_1:kz và được sử dụng cho phân loại. Các thay đổi của proj-acc với sự tăng của k phản ánh tầm quan trọng của mỗi hướng chính được thêm vào.
Trong Hình 2, chúng tôi vẽ sk và proj-acc (k) so với k khi một mô hình đã được huấn luyện trên một số lớp nhất định trong CL. Chúng tôi so sánh hai phương pháp CL đơn giản: finetuning (FT) nơi mô hình được huấn luyện liên tục trên dòng dữ liệu trực tuyến mà không có bất kỳ phương tiện nào để giảm quên thảm khốc, và joint training (JT) nơi tất cả dữ liệu huấn luyện đã thấy cho đến nay được sử dụng để huấn luyện mạng. Thông thường, FT phục vụ như một giới hạn dưới ngây thơ cho hiệu suất CL và JT một giới hạn trên oracle. Đối chiếu FT và JT tiết lộ sự khác biệt trong không gian đặc trưng thu được từ các phương pháp CL tồi tệ nhất và lý tưởng.
Chúng ta có thể thấy từ Hình 2, đối với JT, khi mạng được huấn luyện trên nhiều lớp hơn, các đặc trưng đã học mở rộng một không gian con lớn hơn và bộ phân loại cần nhiều hướng chính hơn để đạt được độ chính xác phân loại tốt (proj-acc tương đối cao). Điều này cho thấy rằng trong quá trình học liên tục, nhiều hướng đặc trưng hơn là cần thiết để làm cho các lớp mới có thể phân tách tuyến tính trong không gian đặc trưng. Tuy nhiên, đối với đường cơ sở FT ngây thơ, số hướng chính với phương sai lớn không tăng với số lớp đã thấy. Điều này chỉ ra quên đặc trưng: một phương pháp CL kém chỉ tập trung vào các hướng đặc trưng quan trọng cho tác vụ hiện tại. Các hướng đặc trưng cho các tác vụ cũ bị ức chế xuống phương sai thấp và do đó bị quên. Mặt khác, so với chiều đặc trưng đầy đủ d= 512, các độ chính xác JT vẫn bão hòa với k= 80 tương đối nhỏ, tức là khoảng số lớp đã thấy cho đến nay. Các hướng đặc trưng khác có phương sai thấp không được sử dụng cho phân loại, và những hướng đặc trưng "chưa sử dụng" như vậy có thể để lại chỗ cho các tác vụ tương lai trong CL.
Dựa trên hiểu biết này, chúng tôi tranh luận về lợi ích của việc bảo toàn
các hướng đặc trưng quan trọng cho các tác vụ cũ trong khi cho phép những hướng mới xuất hiện cho các tác vụ mới trong quá trình học liên tục.
Do đó, chúng tôi đề xuất học một phép biến đổi tuyến tính chiếu không gian đặc trưng mới trở lại không gian cũ và trong phần tiếp theo, chúng tôi cho thấy nó có thể đạt được cả hai mục tiêu.
3.3. Phép chiếu Đặc trưng Ngược
Chúng tôi ký hiệu trích xuất đặc trưng đang được huấn luyện trên tác vụ hiện tại t là h, có thể chưa hội tụ, và checkpoint mô hình hội tụ ở cuối tác vụ cuối cùng là h′=ht−1. Cho một ví dụ đầu vào x, các đặc trưng được trích xuất được ký hiệu là z=h(x) và z′=h′(x). Để bảo toàn thông tin trong không gian đặc trưng sao cho đặc trưng mới z nên chứa ít nhất thông tin như trong z′, chúng ta có thể học một hàm chiếu p thỏa mãn z′=p(z)[21, 22].
Trong công trình này, chúng tôi đề xuất rằng một ma trận biến đổi tuyến tính A có thể bảo toàn tốt khả năng phân tách tuyến tính và đủ để giảm quên. Một cách chính thức, chúng tôi đề xuất mất mát Phép chiếu Đặc trưng Ngược (BFP) trong học liên tục. Cho một ví dụ huấn luyện x,
LBFP(x;ψ, A) =∥Az−z′∥2 (2)
=∥Ahψ(x)−h′(x)∥2, (3)
trong đó chúng tôi bỏ qua thuật ngữ bias bằng cách thêm một mục cố định của 1 trong vectơ đặc trưng z. Ở đây chúng tôi chỉ tối ưu hóa hψ và A, trong khi chúng tôi đóng băng h′ và do đó bỏ qua các tham số của nó.
Trong phần tiếp theo, chúng tôi cho thấy rằng mất mát BFP có thể bảo toàn khả năng phân tách tuyến tính của các lớp cũ trong khi cho phép các lớp mới được phân loại dọc theo các hướng chưa sử dụng trong không gian đặc trưng cũ. Xem xét các đặc trưng được trích xuất từ bất kỳ hai ví dụ nào từ các lớp cũ z′_i=h′(xi), xi∈C1 và z′_j=h′(xj), xj∈C2, trong đó C1, C2∈ Ct−1. Nếu chúng được học để có thể phân tách tuyến tính ở cuối tác vụ t−1, thì tồn tại một vectơ w và một ngưỡng b, sao cho
wTz′_i> b > wTz′_j,∀i∈C1,∀j∈C2. (4)
Sau đó nếu mất mát BFP trong Phương trình 3 được tối ưu hóa tốt, tức là z′≈Az với một phép biến đổi tuyến tính A. Sau đó đối với các đặc trưng được trích xuất từ h,
wTAzi>b > wTAzj,∀i∈C1,∀j∈C2 (5)
⇒(ATw)Tzi>b > (ATw)Tzj,∀i∈C1,∀j∈C2.(6)
Do đó các vectơ đặc trưng z từ các lớp cũ C1, C2 vẫn có thể phân tách tuyến tính dọc theo hướng ATw trong không gian đặc trưng mới. Bộ phân loại tuyến tính g được huấn luyện để tìm ranh giới quyết định này trong CL với phát lại kinh nghiệm.
Để phân loại các lớp mới, mạng cần ánh xạ chúng đến các vùng có thể phân tách tuyến tính trong không gian đặc trưng. Phép biến đổi tuyến tính trong BFP đạt được điều này bằng cách sắp xếp các lớp mới dọc theo các hướng đặc trưng "chưa sử dụng" có phương sai thấp và do đó không bị chiếm bởi các tác vụ cũ. Xem xét rằng các đặc trưng được trích xuất từ tác vụ tương lai Dt sử dụng
4

--- TRANG 5 ---
mô hình cũ h′ có thể không thể phân tách và trộn lẫn với nhau. Điều này là tự nhiên vì h′ chưa được huấn luyện trên nó. Như chúng ta có thể thấy từ Phần 3.2 và Hình 2, tồn tại nhiều hướng chính với phương sai thấp, dọc theo đó các đặc trưng từ các lớp khác nhau không thể phân tách. Lý tưởng, một mô hình CL nên chiếm những hướng đặc trưng "chưa sử dụng" này để học các đặc trưng cần thiết để phân loại các lớp mới. Không mất tính tổng quát, giả sử trước khi mô hình được huấn luyện trên một tác vụ mới t, đặc trưng được trích xuất từ tác vụ mới z′=h′(x),x∈Xt, đều được ánh xạ về không dọc theo một hướng đặc trưng "chưa sử dụng" v, tức là vTz′= 0. Sau đó sau khi học trên tác vụ t, đặc trưng z=h(x) từ các lớp mới C3, C4∈ Ct có thể được học để có thể phân tách dọc theo hướng đặc trưng v đó,
vTzi> vTzj,∀i∈C3,∀j∈C4. (7)
Trong trường hợp này, A có thể được học sao cho v /∈Col(A) và do đó vT(Az) = 0 trong khi vTz̸= 0(thỏa mãn Phương trình 7). Bằng cách này, mất mát BFP trong Phương trình 3 cho phép lớp mới có thể phân tách dọc theo v và vẫn có thể được tối thiểu hóa. Lưu ý rằng trong quá trình học liên tục thực tế với BFP, không cần định nghĩa hoặc cần w,v cũng như chiều của chúng. Chúng được học một cách ngầm định trong ma trận A thông qua tối ưu hóa gradient descent. w và v có thể được trích xuất và phân tích bởi phân tách PCA, nhưng nó không bắt buộc cho huấn luyện.
3.4. Hàm mất mát
Chúng tôi tích hợp phương pháp phép chiếu đặc trưng ngược được đề xuất vào một khung phát lại kinh nghiệm [8], nơi chúng tôi giữ một bộ đệm M lưu trữ các ví dụ huấn luyện từ các tác vụ cũ. Chúng tôi tập trung vào các phương pháp phát lại kinh nghiệm vì chúng đơn giản và vượt trội so với các loại phương pháp CL khác bằng một biên độ lớn theo một khảo sát gần đây [37]. Chúng tôi giữ checkpoint mô hình ở cuối tác vụ cuối cùng ft−1 cùng với mô hình được huấn luyện trực tuyến f. Trong quá trình học liên tục, mô hình trực tuyến f được huấn luyện trên một lô từ dòng dữ liệu trực tuyến của tác vụ hiện tại Dt sử dụng mất mát entropy chéo.
Lce(Dt;θ) =X
x,y∈D tcross-entropy (y, fθ(x)) (8)
Trong khi đó, chúng tôi lấy mẫu một lô khác từ M cho phát lại kinh nghiệm. Theo [8], một mất mát entropy chéo và một mất mát chưng cất logit được áp dụng trên dữ liệu được phát lại
Lrep-ce(M;θ) =X
x,y∈Mcross-entropy (y, fθ(x)),(9)
Lrep-logit (M;θ) =X
x,y∈M∥fθ(x)−ft−1(x)∥2
2. (10)Và chúng tôi áp dụng mất mát phép chiếu đặc trưng ngược của chúng tôi trên cả dòng dữ liệu trực tuyến Dt và các ví dụ được phát lại M
LBFP(Dt, M;ψ, A) =X
x,y∈D t,M∥Ahψ(x)−ht−1(x)∥2.
(11)
Hàm mất mát tổng được sử dụng trong học liên tục là tổng có trọng số của các mất mát ở trên.
L(Dt, M;θ, A) =Lce(Dt;θ) +αL rep-ce(M;θ)
+βLrep-logit (M;θ) +γLBFP(Dt, M;ψ, A)(12)
Trong quá trình huấn luyện trên tác vụ t, cả phép biến đổi tuyến tính A và mô hình fθ đều được tối ưu hóa, và checkpoint mô hình cũ ft−1 vẫn cố định. Trong các thí nghiệm của chúng tôi, ma trận A được khởi tạo ngẫu nhiên ở đầu mỗi tác vụ.
Mã giả của thuật toán được đề xuất có thể được tìm thấy trong Phụ lục.
4. Thí nghiệm
4.1. Thiết lập Thí nghiệm
Thiết lập Học liên tục. Chúng tôi theo [8,14,51] và kiểm tra tất cả các phương pháp sử dụng cả thiết lập Class-IL và Task-IL trong các thí nghiệm CL của chúng tôi. Cả Class-IL và Task-IL đều chia bộ dữ liệu thành một chuỗi các tác vụ, mỗi tác vụ chứa một tập hợp các lớp không giao nhau, trong khi các định danh tác vụ có sẵn trong quá trình kiểm tra dưới Task-IL. Task-IL do đó có những lợi thế bổ sung trong quá trình suy luận (ví dụ chọn đầu dự đoán phù hợp) và trở thành một kịch bản CL dễ dàng hơn. Công trình của chúng tôi được thiết kế cho Class-IL và hiệu suất Task-IL của nó được thu được bằng cách chỉ xem xét các logit trong tác vụ truth chân lý.
Bộ dữ liệu. Chúng tôi đánh giá các đường cơ sở và phương pháp của chúng tôi trên các bộ dữ liệu sau đây sử dụng các kích thước bộ đệm khác nhau: Split CIFAR-10 chia bộ dữ liệu CIFAR-10 [30] gốc thành 5 tác vụ, với mỗi tác vụ bao gồm 2 lớp. Mỗi lớp bao gồm 5000 hình ảnh huấn luyện và 1000 hình ảnh kiểm tra có kích thước 32 ×32.
Split CIFAR-100 chia CIFAR-100 [30] thành 10 tác vụ, với 10 lớp mỗi tác vụ. Mỗi lớp có 500 hình ảnh huấn luyện và 100 hình ảnh kiểm tra có kích thước 32 ×32. Split TinyImageNet chia TinyImageNet [48] thành 10 tác vụ, với 20 lớp mỗi tác vụ. Mỗi lớp chứa 500 hình ảnh huấn luyện, 50 hình ảnh xác thực, và 50 hình ảnh kiểm tra. Những bộ dữ liệu này thách thức và các phương pháp học liên tục hiện đại vẫn thua xa đường cơ sở Joint Training (JT), đặc biệt trong thiết lập Class-IL như được thể hiện trong Bảng 1.
Thước đo. Theo [3, 7, 8, 37], chúng tôi báo cáo hiệu suất của mỗi phương pháp được so sánh sử dụng Độ chính xác Trung bình Cuối cùng (FAA). Giả sử at_i là độ chính xác phân loại kiểm tra trên tác vụ thứ i khi việc huấn luyện kết thúc trên tác vụ t, FAA là độ chính xác của mô hình cuối cùng được tính trung bình trên tất cả các tác vụ:
FAA =1
TTX
i=1aT
i. (13)
5

--- TRANG 6 ---
Setting Method S-CIFAR10 S-CIFAR100 S-TinyImageNet
Buffer Size 200 500 500 2000 4000
Class-IL Joint Training (JT) 91.27 ±0.57 70.68 ±0.57 59.61 ±0.25
Finetuning (FT) 36.20 ±2.02 9.36 ±0.07 8.11 ±0.08
iCaRL [42] 63.58 ±1.22 62.62 ±2.07 46.66 ±0.23 52.60 ±0.38 31.47 ±0.46
FDR [5] 31.24 ±2.61 28.72 ±2.86 22.64 ±0.56 34.84 ±1.03 26.52 ±0.41
LUCIR [24] 58.53 ±3.03 70.37 ±0.97 35.14 ±0.57 48.95 ±1.21 29.79 ±0.70
BiC [51] 59.53 ±1.77 75.41 ±1.14 35.96 ±1.38 45.44 ±0.96 15.98 ±1.01
ER-ACE [10] 63.54 ±0.42 71.17 ±1.38 38.86 ±0.72 50.20 ±0.39 37.72 ±0.16
ER [43] 58.07 ±2.92 68.04 ±2.18 20.34 ±0.96 37.44 ±1.48 23.29 ±0.54
ER w/ BFP (Ours) 63.27 ±1.09 (+5.21) 71.51 ±1.58 (+3.47) 22.54 ±1.10 (+2.20) 38.92 ±1.94 (+1.48) 26.33 ±0.68 (+3.04)
DER++ [8] 65.41 ±1.60 72.65 ±0.33 38.88 ±0.91 52.74 ±0.79 41.24 ±0.64
DER++ w/ BFP (Ours) 72.21 ±0.22 (+6.80) 76.02 ±0.79 (+3.37) 47.45 ±1.30 (+8.56) 57.91 ±0.66 (+5.17) 43.40 ±0.41 (+2.16)
Task-IL Joint Training (JT) 98.19 ±0.16 91.40 ±0.43 82.21 ±0.33
Finetuning (FT) 65.01 ±5.12 35.54 ±2.63 18.46 ±1.26
iCaRL [42] 90.27 ±1.21 90.05 ±1.46 84.45 ±0.48 86.24 ±0.47 66.06 ±0.75
FDR [5] 91.42 ±1.03 93.40 ±0.31 74.66 ±0.16 82.15 ±0.26 66.79 ±0.66
LUCIR [24] 94.30 ±0.79 94.99 ±0.14 85.13 ±0.20 87.50 ±0.44 70.09 ±0.40
BiC [51] 95.41 ±0.73 96.45 ±0.34 85.16 ±0.36 87.03 ±0.30 68.44 ±4.40
ER-ACE [10] 92.12 ±0.62 94.09 ±0.27 77.00 ±0.80 83.30 ±0.54 68.91 ±0.38
ER [43] 92.06 ±0.65 93.60 ±0.76 72.42 ±1.74 81.34 ±1.06 64.96 ±0.45
ER w/ BFP (Ours) 95.50 ±0.41 (+3.44) 96.11 ±0.27 (+2.51) 79.79 ±1.67 (+7.38) 84.16 ±1.18 (+2.81) 71.43 ±0.58 (+6.47)
DER++ [8] 91.71 ±0.83 93.76 ±0.27 76.96 ±0.24 83.59 ±0.41 71.14 ±0.53
DER++ w/ BFP (Ours) 95.95 ±0.22 (+4.23) 96.29 ±0.26 (+2.53) 83.64 ±0.64 (+6.68) 87.20 ±0.32 (+3.61) 73.07 ±0.28 (+1.94)
Bảng 1. Độ chính xác Trung bình Cuối cùng (FAA, tính bằng %) trong thiết lập Class-IL và Task-IL của các đường cơ sở và phương pháp của chúng tôi trên các bộ dữ liệu và kích thước bộ đệm khác nhau. Các số màu xanh lá cây trong ngoặc đơn cho thấy các cải thiện tuyệt đối mà BFP mang lại so với các đường cơ sở ER hoặc DER++ tương ứng. Phương pháp BFP được đề xuất có thể tăng hiệu suất Class-IL lên đến 6-8% trong một số thiết lập thách thức với kích thước bộ đệm nhỏ.
DER++ w/ BFP (Ours) vượt trội so với tất cả các đường cơ sở về độ chính xác Class-IL và có độ chính xác Task-IL tốt hơn hoặc gần với các phương pháp hiệu suất cao nhất. Trung bình và độ lệch chuẩn được tính toán trên 5 lần chạy với các hạt giống khác nhau. Joint Training (JT) cho thấy hiệu suất giới hạn trên, nơi mô hình được huấn luyện trên dữ liệu từ tất cả các tác vụ và Finetune (FT) là giới hạn dưới, nơi mô hình được huấn luyện tuần tự mà không xử lý quên.
Chúng tôi cũng báo cáo Quên Cuối cùng (FF), phản ánh sự sụt giảm độ chính xác giữa hiệu suất đỉnh cao trên một tác vụ và hiệu suất cuối cùng của nó:
FF=1
T−1T−1X
i=1max
j∈1,···,T−1(aj
i−aT
i). (14)
FF thấp hơn có nghĩa là ít quên hơn và hiệu suất CL tốt hơn.
Chi tiết huấn luyện. Chúng tôi sử dụng ResNet-18 [23] làm backbone mạng, và thay vì bộ đệm reservoir đơn giản được sử dụng trong [8], chúng tôi sử dụng lấy mẫu reservoir cân bằng lớp [9] để đẩy các ví dụ vào bộ đệm. Tất cả các đường cơ sở mà chúng tôi so sánh đều được cập nhật với thay đổi này. Chúng tôi sử dụng một tối ưu hóa SGD để tối ưu hóa mô hình fθ và một tối ưu hóa SGD+Momentum khác với tỷ lệ học 0.1 cho ma trận chiếu A. Các tối ưu hóa và ma trận A được khởi tạo lại ở đầu mỗi tác vụ. Mạng được huấn luyện trong 50 epoch mỗi tác vụ cho Split CIFAR-10 và Split CIFAR-100 và 100 epoch mỗi tác vụ cho Split Tiny-ImageNet. Tỷ lệ học được chia cho 10 sau một số epoch nhất định trong mỗi tác vụ ([35,45] cho Split CIFAR-100 và [35,60,75] cho Split TinyImageNet). Trong công trình này, chúng tôi tập trung vào thiết lập CL ngoại tuyến này nơi mỗi tác vụ được huấn luyện cho nhiều epoch. Mặc dù chúng tôi cũng quan tâm đến CL trực tuyến, huấn luyện nhiều epoch giúp tách biệt underfitting và quên thảm khốc [3, 8]. BFP giới thiệu chỉ một siêu tham số bổ sung γ, được đặt thành 1 cho tất cả các thí nghiệm. Chúng tôi thấy rằng γ= 1 hoạt động tốt cho tất cả các bộ dữ liệu và kích thước bộ đệm và không thực hiện tìm kiếm siêu tham số cho các thiết lập thí nghiệm riêng lẻ. Các siêu tham số α và β được sử dụng trong Phương trình 12 được áp dụng từ [8].
Hầu hết các đường cơ sở áp dụng các siêu tham số khác nhau cho các thiết lập khác nhau, mà chúng tôi áp dụng các siêu tham số đã được tối ưu hóa bằng tìm kiếm lưới bởi [8] và [7] để so sánh công bằng. Chi tiết có thể được tìm thấy trong Phụ lục.
4.2. Đường cơ sở
Đầu tiên, chúng tôi đánh giá hiệu suất của các đường cơ sở Joint Training (JT) và Finetuning (FT) trên mỗi bộ dữ liệu. JT huấn luyện mạng trên tất cả dữ liệu huấn luyện, không có vấn đề quên, và do đó chỉ ra hiệu suất giới hạn trên của các phương pháp CL. Ngược lại, FT đơn giản thực hiện SGD sử dụng dữ liệu tác vụ hiện tại mà không xử lý quên gì cả và chỉ ra hiệu suất giới hạn dưới.
Như một phương pháp chưng cất đặc trưng, phương pháp của chúng tôi có thể được kết hợp với hầu hết các phương pháp học liên tục. Trong đánh giá của chúng tôi, chúng tôi kiểm tra phương pháp của chúng tôi bằng cách kết hợp nó với hai phương pháp phát lại kinh nghiệm phổ biến, ER [43] và DER++ [8]. ER sử dụng bộ đệm bộ nhớ để lưu trữ các ví dụ huấn luyện từ các tác vụ trong quá khứ và xen kẽ chúng với dữ liệu tác vụ hiện tại để huấn luyện. Ngoài điều này, DER++ ghi lại các logit đầu ra của các ví dụ trong bộ nhớ và thực hiện chưng cất logit khi thực hiện phát lại kinh nghiệm. Chúng tôi kết hợp mất mát BFP được đề xuất với ER và DER++ và ký hiệu chúng là ER w/ BFP và DER++ w/ BFP tương ứng.
Chúng tôi cũng so sánh phương pháp được đề xuất với một số đường cơ sở CL hiện đại khác như được liệt kê trong Bảng 1. Incremental Classifier and Presentation Learning (iCaRL) [42] thực hiện phân loại sử dụng gần trung bình của các mẫu, nơi các mẫu được chọn bởi thuật toán herding trong không gian đặc trưng. Functional Distance Regularization (FDR) [5] chính quy hóa đầu ra của mạng về giá trị trong quá khứ của nó. Khác với DER/DER++, FDR áp dụng chính quy hóa trên xác suất phân loại đầu ra. Learning a Unified Classifier Incrementally via Rebalancing (LUCIR) [24] tăng cường phát lại kinh nghiệm với nhiều sửa đổi để bảo toàn kiến thức cũ và thực thi sự phân tách lớp trong học liên tục. Bias Correction (BiC) [51] tăng cường phát lại kinh nghiệm bằng cách học một lớp riêng biệt để sửa chữa bias trong các logit đầu ra. ER with Asymmetric Cross-Entropy (ER-ACE) [10] đề xuất giảm sự trôi dạt biểu diễn bằng cách sử dụng mất mát entropy chéo riêng biệt cho dữ liệu huấn luyện trực tuyến và được phát lại.
4.3. Kết quả
Các Độ chính xác Trung bình Cuối cùng trong thiết lập Class-IL và Task-IL được báo cáo trong Bảng 1. Bảng tương ứng cho Quên Cuối cùng có thể được tìm thấy trong Phụ lục. Chúng tôi kiểm tra các phương pháp trên ba bộ dữ liệu với các kích thước khác nhau của bộ đệm bộ nhớ. Các thí nghiệm được tính trung bình trên 5 lần chạy với các hạt giống khác nhau và trung bình và độ lệch chuẩn được báo cáo. Đầu tiên, chúng tôi quan sát rằng vẫn còn một khoảng cách lớn giữa các phương pháp CL tốt nhất hiện tại và các đường cơ sở JT oracle trên tất cả các bộ dữ liệu, đặc biệt trong thiết lập Class-IL, điều này chỉ ra rằng CL vẫn là một vấn đề chưa được giải quyết và thách thức. So sánh DER++ và DER++ w/ BFP, chúng ta có thể thấy rằng BFP tăng các độ chính xác Class-IL bằng một biên độ đáng kể, đặc biệt với kích thước bộ đệm nhỏ (6.8% trên S-CIFAR10 với kích thước bộ đệm 200 và 8.5% trên S-CIFAR100 với kích thước bộ đệm 500).
DER++ w/ BFP do đó vượt trội so với tất cả các phương pháp đường cơ sở trong thiết lập Class-IL, rất thách thức vì mô hình cuối cùng cần phân biệt các ví dụ kiểm tra từ tất cả các lớp đã thấy. Các phương pháp CL trước đây gặp khó khăn để có hiệu suất thỏa đáng trong thiết lập này. Dưới thiết lập Task-IL dễ dàng hơn vì các định danh tác vụ được biết trong thời gian đánh giá, mô hình của chúng tôi cũng giúp đạt được độ chính xác cao hơn nhiều so với phương pháp ER hoặc DER++ cơ bản. Và trong số tất cả các phương pháp CL được so sánh, phương pháp được đề xuất cũng đạt được độ chính xác tốt nhất hoặc gần tốt nhất dưới thiết lập Task-IL.
4.4. Thăm dó Tuyến tính
Một số công trình mới nhất về học liên tục đã nghiên cứu quên thảm khốc trong không gian đặc trưng cuối cùng hT(x)[15, 56].
Họ cho thấy rằng mặc dù độ chính xác sử dụng bộ phân loại được huấn luyện liên tục
7

--- TRANG 7 ---
1% 10% 100%
Phần dữ liệu huấn luyện được sử dụng cho thăm dò tuyến tính0.450.500.550.600.650.700.75Độ chính xác Thăm dò Tuyến tínhDER++ w/ BFP
DER++ w/ FD
DER++
FT w/ BFP
FT w/ FD
FTHình 3. Các độ chính xác thăm dò tuyến tính trên bộ trích xuất đặc trưng đóng băng được thu được sau khi huấn luyện trên Split-CIFAR10 với kích thước bộ đệm 200, sử dụng các phương pháp khác nhau. Độ chính xác thăm dò tuyến tính cao hơn chỉ ra một không gian đặc trưng tốt hơn nơi các điểm dữ liệu có thể phân tách tuyến tính hơn. Lưu ý rằng với sự giúp đỡ của BFP, ngay cả một đường cơ sở FT đơn giản có thể học một biểu diễn tốt như phương pháp DER++ mạnh mẽ.
gT suy giảm nặng nề do quên thảm khốc, kiến thức đã học trong hT được duy trì tốt. Điều này được thể hiện bằng cách khớp một bộ phân loại tuyến tính g∗ trên đầu của bộ trích xuất đặc trưng đóng băng ở cuối học liên tục hT. Các độ chính xác thăm dò tuyến tính như vậy thu được bởi g∗◦hT có thể cao hơn nhiều so với gT◦hT. Do đó công trình gần đây tranh luận rằng quên thảm khốc chủ yếu xảy ra ở lớp phân loại tuyến tính cuối cùng và các độ chính xác thăm dò tuyến tính có thể được sử dụng như một thước đo chất lượng cho biểu diễn được học từ học liên tục [21]. Chúng tôi thực hiện một phân tích thăm dò tuyến tính tương tự trên các đường cơ sở được kết hợp với BFP, và chúng tôi thêm kiểm tra tác động của phương pháp của chúng tôi trên đường cơ sở FT ngây thơ, được ký hiệu là FT w/ BFP trong Hình 3.
Trong FT w/ BFP, chúng tôi không sử dụng bộ đệm bộ nhớ và do đó α=β= 0 trong Phương trình 3, nhưng chúng tôi áp dụng mất mát BFP trên dòng dữ liệu trực tuyến với γ= 1. Các độ chính xác thăm dò tuyến tính trên Split CIFAR-10 được báo cáo trong Hình 3, nơi chúng tôi cũng thay đổi phần dữ liệu huấn luyện được sử dụng cho thăm dò tuyến tính.
Kết quả cho thấy rằng BFP tăng các độ chính xác thăm dò tuyến tính của đường cơ sở FT bằng một biên độ đáng kể, đạt được hiệu suất tương tự với phương pháp phát lại kinh nghiệm mạnh mẽ, DER++. Khi được kết hợp với DER++, BFP cũng giúp cải thiện các độ chính xác thăm dò tuyến tính. Điều này chỉ ra rằng dù có hoặc không có bộ đệm bộ nhớ, BFP giúp học một không gian đặc trưng tốt hơn trong CL, nơi các ví dụ từ các lớp khác nhau vẫn có thể phân tách tuyến tính.
4.5. Nghiên cứu Ablation
Chúng tôi nghiên cứu tác động của các loại lớp chiếu khác nhau được sử dụng cho phép chiếu đặc trưng ngược, trong Phương trình 3. Kết quả chính của chúng tôi được thu được bằng cách sử dụng một lớp chiếu tuyến tính làm lớp biến đổi có thể học được (được ký hiệu là BFP). Chúng tôi cũng kiểm tra phương pháp của chúng tôi sử dụng một hàm đồng nhất A=I làm
8

--- TRANG 8 ---
Dataset Buffer FD BFP BFP-2
S-CIFAR10200 68.44±1.35 72.21±0.22 72.04±0.96
500 74.50±0.41 76.02±0.79 76.63±0.63
S-CIFAR100500 43.81±1.35 47.45±1.30 47.45±1.08
2000 56.56±0.55 57.91±0.66 57.27±0.67
S-TinyImg 4000 42.40±1.02 43.40±0.41 42.91±0.50
Bảng 2. Độ chính xác Trung bình Cuối cùng Class-IL sử dụng các loại lớp khác nhau cho phép chiếu đặc trưng ngược. Phương pháp đường cơ sở là DER++.
2 3 4 5
Tác vụ0.20.40.60.81.0Độ tương đồng CKAĐã thấy - DER++ w/ BFP
Đã thấy - DER++ w/ FD
Đã thấy - DER++
Chưa thấy - DER++ w/ BFP
Chưa thấy - DER++ w/ FD
Chưa thấy - DER++
Hình 4. Độ tương đồng đặc trưng tại các tác vụ khác nhau của việc huấn luyện trên Split-CIFAR10, với kích thước bộ đệm 200, sử dụng các phương pháp CL khác nhau.
bộ chiếu, về cơ bản là một mất mát chưng cất đặc trưng (FD) trên đặc trưng cuối cùng, cũng như sử dụng một hàm phi tuyến (một MLP hai lớp với kích hoạt ReLU ở giữa) làm p, được ký hiệu là BFP-2. Những biến thể này được kiểm tra khi được tích hợp với DER++ [8] và kết quả được thể hiện trong Bảng 2. Theo Bảng 2, trong khi phương pháp FD đơn giản đã vượt trội so với đường cơ sở, BFP có thể học được được đề xuất tiếp tục tăng các độ chính xác bằng một biên độ lớn. Điều này được mong đợi vì FD chính quy hóa các đặc trưng đã học trực tiếp thành những đặc trưng từ mô hình cũ, trong khi mô hình cũ chưa học từ dữ liệu mới và có thể cho các đặc trưng vô dụng. Trong trường hợp này, FD thúc đẩy tính ổn định trong khi thiếu tính dẻo dai. Ngược lại, BFP có thể học được và do đó cung cấp tính dẻo dai mong muốn cho phép kiến thức mới xuất hiện trong khi duy trì những kiến thức cũ. Hơn nữa, chúng ta cũng có thể thấy rằng hiệu suất đã bão hòa với một lớp chiếu tuyến tính và một phép chiếu phi tuyến phức tạp hơn (BFP-2) không cải thiện thêm. Chúng tôi giả thuyết rằng vì BFP được áp dụng trên không gian đặc trưng ngay trước bộ phân loại tuyến tính, khả năng phân tách tuyến tính được duy trì tốt hơn với một phép biến đổi tuyến tính hơn là một hàm phi tuyến.
4.6. Phân tích Độ tương đồng Đặc trưng
Để chứng minh rằng phương pháp BFP được đề xuất chính quy hóa các đặc trưng đã được học trong khi cho phép các đặc trưng của dữ liệu mới phát triển tự do, chúng tôi thực hiện một phân tích về độ tương đồng đặc trưng. Theo [15, 41], chúng tôi áp dụng Centered Kernal Alignment (CKA) [29] để đo độ tương đồng đặc trưng trước và sau khi huấn luyện trên một tác vụ. CKA là một thước đo độ tương đồng cho các biểu diễn được học sâu, và nó bất biến với scaling đẳng hướng và phép biến đổi trực giao [29]. CKA giữa hai ma trận đặc trưng Z1∈Rd1×n và Z2∈Rd2×n với một kernel tuyến tính được định nghĩa là
CKA (Z1, Z2) =∥Z1ZT_2∥2_F
∥Z1ZT_1∥2_F∥Z2ZT_2∥2_F. (15)
Nhắc lại rằng ma trận đặc trưng được trích xuất từ Di sử dụng mô hình hj được ký hiệu là Zj_i=hj(Di), và tương tự Zj_1:i= hi(D1:i). Trong quá trình học trên tác vụ t, chúng tôi xem xét hai tập hợp đặc trưng, các đặc trưng từ D1:t−1 đã được học bởi mô hình (đã thấy) và các đặc trưng từ Dt mới đối với mô hình (chưa thấy). Chúng tôi định nghĩa độ tương đồng CKA của chúng trước và sau khi học trên tác vụ t tương ứng như sau
CKAseen_t=CKA (Zt−1_1:t−1, Zt_1:t−1) (16)
CKAunseen_t =CKA (Zt−1_t, Zt_t). (17)
Lưu ý rằng Zt−1_t đại diện cho các đặc trưng được trích xuất từ dữ liệu tương lai bởi mô hình cũ, và dự kiến rằng chúng không cung cấp thông tin hữu ích. Ngược lại, Zt−1_1:t−1 đã được học tốt và chúng tôi muốn bảo toàn cấu trúc của nó. Do đó, chúng tôi muốn CKAseen_t cao để giữ lại kiến thức, trong khi CKAunseen_t thấp để cho phép đặc trưng của dữ liệu chưa thấy thay đổi tự do trong học liên tục. Chúng tôi vẽ CKAseen_t và CKAunseen_t trong CL trong Hình 4 và kết quả xác nhận mong muốn của chúng tôi. DER++ không áp dụng ràng buộc trực tiếp nào trên không gian đặc trưng trong CL và do đó độ tương đồng thấp cho cả dữ liệu đã thấy và chưa thấy. Ngược lại, FD đặt ra một ràng buộc mạnh trên cả dữ liệu đã thấy và chưa thấy, dẫn đến độ tương đồng cao. Bằng cách này, FD đạt được tính ổn định nhiều hơn với chi phí của tính dẻo dai thấp hơn. Kết hợp các lợi thế tương ứng của chúng, BFP giữ CKAseen_t cao trong khi cho phép các đặc trưng chưa thấy thay đổi (CKAunseen_t thấp), và do đó có thể đạt được sự cân bằng tốt hơn giữa tính ổn định và tính dẻo dai.
5. Kết luận
Trong bài báo này, chúng tôi giảm quên thảm khốc trong học liên tục (CL) bằng cách đề xuất Phép chiếu Đặc trưng Ngược (BFP), một phương pháp chưng cất đặc trưng có thể học được. Chúng tôi cho thấy rằng trong CL, mặc dù chiều lớn của không gian đặc trưng, chỉ một số lượng nhỏ các hướng đặc trưng được sử dụng cho phân loại. Không có chính quy hóa, các hướng đặc trưng đã học trước đó giảm dần và làm hại khả năng phân tách tuyến tính, dẫn đến quên thảm khốc. BFP được đề xuất giúp duy trì khả năng phân tách tuyến tính được học từ các tác vụ cũ trong khi cho phép các hướng đặc trưng mới được học cho các tác vụ mới. Bằng cách này, BFP đạt được sự cân bằng tốt hơn giữa tính dẻo dai và tính ổn định. BFP có thể được kết hợp với các phương pháp phát lại kinh nghiệm hiện có và các thí nghiệm cho thấy rằng nó có thể tăng hiệu suất bằng một biên độ đáng kể. Chúng tôi cũng cho thấy rằng BFP dẫn đến một không gian đặc trưng có thể phân tách tuyến tính hơn, trên đó một bộ phân loại tuyến tính có thể khôi phục độ chính xác cao hơn.
Tài liệu tham khảo
[1] Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny,
Marcus Rohrbach, and Tinne Tuytelaars. Memory aware
synapses: Learning what (not) to forget. In ECCV, 2018.
2
[2] Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo Caccia, Min Lin, and Lucas Page-
Caccia. Online continual learning with maximal interfered
retrieval. In NeurIPS, 2019. 2
[3] Elahe Arani, Fahad Sarfraz, and Bahram Zonooz. Learning fast, learning slow: A general continual learning method
based on complementary learning system. In ICLR, 2022. 5,
6
[4] Tommaso Barletti, Niccolò Biondi, Federico Pernici, Matteo
Bruni, and Alberto Del Bimbo. Contrastive supervised distillation for continual representation learning. In ICIAP, pages
597–609. Springer, 2022. 2
[5] Ari S. Benjamin, David Rolnick, and Konrad P. Kording.
Measuring and regularizing networks in function space. In
ICLR, 2019. 6, 7, 13
[6] Magdalena Biesialska, Katarzyna Biesialska, and Marta R
Costa-Jussa. Continual lifelong learning in natural language
processing: A survey. arXiv preprint arXiv:2012.09823,
2020. 1
[7] Matteo Boschini, Lorenzo Bonicelli, Pietro Buzzega, Angelo Porrello, and Simone Calderara. Class-incremental continual learning into the extended der-verse. arXiv preprint
arXiv:2201.00766, 2022. 5, 6, 11
[8] Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide
Abati, and Simone Calderara. Dark experience for general
continual learning: a strong, simple baseline. NeurIPS, 2020.
1, 2, 3, 5, 6, 8, 11, 13
[9] Pietro Buzzega, Matteo Boschini, Angelo Porrello, and Simone Calderara. Rethinking experience replay: a bag of
tricks for continual learning. In ICPR, 2021. 6, 11
[10] Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, and Eugene Belilovsky. New insights
on reducing abrupt representation change in online continual
learning. In ICLR, 2022. 3, 6, 7, 13
[11] Hyuntak Cha, Jaeho Lee, and Jinwoo Shin. Co2l: Contrastive continual learning. In ICCV, 2021. 2
[12] Arslan Chaudhry, Puneet K Dokania, Thalaiyasingam Ajanthan, and Philip HS Torr. Riemannian walk for incremental learning: understanding forgetting and intransigence. In
ECCV, 2018. 2
[13] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach,
and Mohamed Elhoseiny. Efficient lifelong learning with agem. In ICLR, 2019. 2
[14] Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny,
Thalaiyasingam Ajanthan, Puneet K Dokania, Philip HS
Torr, and Marc'Aurelio Ranzato. Continual learning with
tiny episodic memories. In ICML, 2019. 5[15] MohammadReza Davari, Nader Asadi, Sudhir Mudur, Rahaf
Aljundi, and Eugene Belilovsky. Probing representation forgetting in supervised and unsupervised continual learning. In
CVPR, 2022. 7, 8
[16] Prithviraj Dhar, Rajat Vikram Singh, Kuan-Chuan Peng,
Ziyan Wu, and Rama Chellappa. Learning without memorizing. In CVPR, 2019. 1, 2, 3
[17] Nikita Dhawan, Sicong Huang, Juhan Bae, and Roger
Grosse. Efficient parametric approximations of neural network function space distance. In ICML, 2023. 2
[18] Thang Doan, Mehdi Abbana Bennani, Bogdan Mazoure,
Guillaume Rabusseau, and Pierre Alquier. A theoretical
analysis of catastrophic forgetting through the ntk overlap
matrix. In AISTATS, pages 1072–1080. PMLR, 2021. 14
[19] Arthur Douillard, Matthieu Cord, Charles Ollion, Thomas
Robert, and Eduardo Valle. Podnet: Pooled outputs distillation for small-tasks incremental learning. In ECCV, pages
86–102. Springer, 2020. 1, 2, 3
[20] Laura N Driscoll, Lea Duncker, and Christopher D Harvey. Representational drift: Emerging theories for continual
learning and experimental future directions. Current Opinion in Neurobiology, 76:102609, 2022. 3
[21] Enrico Fini, Victor G Turrisi da Costa, Xavier AlamedaPineda, Elisa Ricci, Karteek Alahari, and Julien Mairal. Selfsupervised models are continual learners. In CVPR, 2022. 3,
4, 7
[22] Alex Gomez-Villa, Bartlomiej Twardowski, Lu Yu, Andrew D Bagdanov, and Joost van de Weijer. Continually
learning self-supervised representations with projected functional regularization. In CVPR Workshop, 2022. 3, 4
[23] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In CVPR,
2016. 6
[24] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, and
Dahua Lin. Learning a unified classifier incrementally via
rebalancing. In ICCV, 2019. 6, 7, 13
[25] Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin,
Janghoon Han, Gyeonghun Kim, Stanley Jungkyu Choi, and
Minjoon Seo. Towards continual knowledge learning of language models. arXiv preprint arXiv:2110.03215, 2021. 1
[26] Heechul Jung, Jeongwoo Ju, Minju Jung, and Junmo Kim.
Less-forgetting learning in deep neural networks. arXiv
preprint arXiv:1607.00122, 2016. 3
[27] Minsoo Kang, Jaeyoo Park, and Bohyung Han. Classincremental learning by knowledge distillation with adaptive
feature consolidation. In CVPR, 2022. 1, 2, 3
[28] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel
Veness, Guillaume Desjardins, Andrei A Rusu, Kieran
Milan, John Quan, Tiago Ramalho, Agnieszka GrabskaBarwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521–3526, 2017. 2
[29] Simon Kornblith, Mohammad Norouzi, Honglak Lee, and
Geoffrey Hinton.. Similarity of neural network representations revisited. In ICML, pages 3519–3529. PMLR, 2019.
8
[30] Alex Krizhevsky. Learning multiple layers of features from
tiny images. Technical report, Citeseer, 2009. 5
9

--- TRANG 9 ---
[31] Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha,
and Byoung-Tak Zhang. Overcoming catastrophic forgetting
by incremental moment matching. In NeurIPS, 2017. 1, 14
[32] Timothée Lesort, Vincenzo Lomonaco, Andrei Stoian, Davide Maltoni, David Filliat, and Natalia Díaz-Rodríguez.
Continual learning for robotics: Definition, framework,
learning strategies, opportunities and challenges. Information Fusion, 2020. 1
[33] Zhizhong Li and Derek Hoiem. Learning without forgetting.
PAMI, 2017. 1, 2, 3
[34] Xialei Liu, Chenshen Wu, Mikel Menta, Luis Herranz, Bogdan Raducanu, Andrew D Bagdanov, Shangling Jui, and
Joost van de Weijer. Generative feature replay for classincremental learning. In CVPR Workshops, 2020. 2
[35] David Lopez-Paz and Marc'Aurelio Ranzato. Gradient
episodic memory for continual learning. In NeurIPS, 2017.
1, 2
[36] Arun Mallya and Svetlana Lazebnik. Packnet: Adding multiple tasks to a single network by iterative pruning. In CVPR,
2018. 1
[37] Marc Masana, Xialei Liu, Bartlomiej Twardowski, Mikel
Menta, Andrew D Bagdanov, and Joost van de Weijer. Classincremental learning: survey and performance evaluation
on image classification. arXiv preprint arXiv:2010.15277,
2020. 5
[38] Marc Masana, Xialei Liu, Bartłomiej Twardowski, Mikel
Menta, Andrew D Bagdanov, and Joost van de Weijer. Classincremental learning: survey and performance evaluation on
image classification. PAMI, 2022. 1
[39] Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The sequential learning
problem. In Psychology of learning and motivation, volume 24, pages 109–165. Elsevier, 1989. 1
[40] Karl Pearson. Liii. on lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin
philosophical magazine and journal of science, 2(11):559–
572, 1901. 4
[41] Vinay V Ramasesh, Ethan Dyer, and Maithra Raghu.
Anatomy of catastrophic forgetting: Hidden representations
and task semantics. arXiv preprint arXiv:2007.07400, 2020.
8
[42] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg
Sperl, and Christoph H Lampert. icarl: Incremental classifier and representation learning. In CVPR, 2017. 2, 6, 7,
13
[43] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu,
Irina Rish, Yuhai Tu, and Gerald Tesauro. Learning to learn
without forgetting by maximizing transfer and minimizing
interference. In ICLR, 2019. 6, 13, 14
[44] Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins,
Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks.
arXiv, 2016. 1
[45] Gobinda Saha, Isha Garg, Aayush Ankit, and Kaushik Roy.
Space: Structured compression and sharing of representational space for continual learning. IEEE Access, 9:150480–
150494, 2021. 14[46] Hanul Shin, Jung Kwon Lee, Jaehong Kim, and Jiwon Kim.
Continual learning with deep generative replay. In NeurIPS,
2017. 2
[47] Christian Simon, Piotr Koniusz, and Mehrtash Harandi. On
learning the geodesic path for incremental learning. In
CVPR, pages 1591–1600, 2021. 14
[48] Stanford. Tiny imagenet challenge, cs231n course., CS231N.
5
[49] Gido M Van de Ven and Andreas S Tolias. Generative replay
with feedback connections as a general strategy for continual
learning. arXiv preprint arXiv:1809.10635, 2018. 2
[50] Jianren Wang, Xin Wang, Yue Shang-Guan, and Abhinav
Gupta. Wanderlust: Online continual object detection in the
real world. In ICCV, pages 10829–10838, 2021. 1
[51] Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye,
Zicheng Liu, Yandong Guo, and Yun Fu. Large scale incremental learning. In CVPR, 2019. 5, 6, 7, 13
[52] Shipeng Yan, Jiangwei Xie, and Xuming He. Der: Dynamically expandable representation for class incremental learning. In CVPR, pages 3014–3023, 2021. 1
[53] Lu Yu, Bartlomiej Twardowski, Xialei Liu, Luis Herranz,
Kai Wang, Yongmei Cheng, Shangling Jui, and Joost van de
Weijer. Semantic drift compensation for class-incremental
learning. In CVPR, 2020. 3
[54] Friedemann Zenke, Ben Poole, and Surya Ganguli. Continual learning through synaptic intelligence. In ICML, 2017.
1, 2
[55] Jingxin Zhang, Donghua Zhou, and Maoyin Chen. Monitoring multimode processes: A modified pca algorithm
with continual learning ability. Journal of Process Control,
103:76–86, 2021. 14
[56] Xiao Zhang, Dejing Dou, and Ji Wu. Feature forgetting in continual representation learning. arXiv preprint
arXiv:2205.13359, 2022. 7
[57] Fei Zhu, Zhen Cheng, Xu-Yao Zhang, and Cheng-lin Liu.
Class-incremental learning via dual augmentation. NeurIPS,
34:14306–14318, 2021. 14
10

--- TRANG 10 ---
A. Lời cảm ơn
Các tác giả cảm ơn Jongseong Jang, Yizhou (Philip)
Huang, Kevin Xie, và Nikita Dhawan cho các cuộc thảo luận và phản hồi hữu ích.
B. Chi tiết Triển khai
B.1. Thuật toán Hoàn chình
Trong Thuật toán 1, chúng tôi cung cấp mã giả của học liên tục với phương pháp BFP được đề xuất. Lưu ý rằng theo [8], chúng tôi lấy mẫu các điểm dữ liệu huấn luyện từ bộ đệm bộ nhớ cho mỗi mất mát một cách độc lập. Chúng tôi thấy rằng điều này dẫn đến hiệu suất tốt hơn so với việc sử dụng cùng một tập hợp các mẫu được phát lại cho tất cả các mất mát. Các hình ảnh không có tăng cường xo được đẩy vào bộ nhớ và các hình ảnh được phát lại được tăng cường một cách tức thời. Mô hình phân loại được huấn luyện sử dụng một tối ưu hóa SGD (sgd) và ma trận chiếu A được huấn luyện sử dụng một tối ưu hóa SGD+Momentum (sgdm).
B.2. Lấy mẫu Reservoir Cân bằng Lớp
Chúng tôi áp dụng lấy mẫu reservoir cân bằng lớp (BRS) [9] cho quản lý bộ đệm bộ nhớ. Chi tiết của thuật toán này được mô tả trong Thuật toán 2. So với Lấy mẫu Reservoir thông thường (RS), BRS đảm bảo rằng mỗi lớp có một số lượng ví dụ bằng nhau được lưu trữ trong bộ đệm bộ nhớ. Tất cả các thí nghiệm đều được kết hợp với thay đổi này. Thực nghiệm chúng tôi thấy rằng BRS không mang lại
Thuật toán 1 - Học liên tục với BFP
Đầu vào: bộ dữ liệu {D1,···,DT}, tham số θ={ϕ, ψ}, vô hướng
α,β và γ, tối ưu hóa sgd,sgdm,
M← {}
cho t từ 1 đến T thực hiện
A←random-init ()
sgdm←reinit (sgdm)
cho (xo, yo) trong Dt thực hiện
x, y←augment (xo, yo)
L←cross-entropy (y, fθ(x)) {Eq. 8}
nếu t >1 thì
x, y←augment (sample (M))
Lrep-ce←cross-entropy (y, fθ(x)) {Eq. 9}
x, y←augment (sample (M))
Lrep-logits ← ∥fθ(x)−fold(x)∥2 {Eq. 10}
x, y←augment (sample (M))
LBFP← ∥Ahψ(x)−hold(x)∥2 {Eq. 11}
L=L+Lrep-ce +Lrep-logits +LBFP {Eq. 12}
kết thúc nếu
θ←sgd(θ,∇θL)
A←sgdm (A,∇AL)
M←balanced-reservoir (M,(xo, yo)) {Alg. 2}
kết thúc cho
fold=freeze (fθ)
kết thúc cho

Thuật toán 2 Lấy mẫu Reservoir Cân bằng [9]
1:Đầu vào: bộ đệm phát lại M, mẫu (x, y),
2: số ví dụ đã thấy N.
3:nếu|M|> N thì
4:M[N]←(x, y)
5:khác
6:j←RandInt([0, N])
7: nếu j <|M| thì
8: M[j]←(x, y)Lấy mẫu Reservoir
9: ỹ←argmax ClassCounts( M, y)
10: k←RandChoice( {k̃;M[k̃] = (x, y), y= ỹ})
11: M[k]←(x, y)Lấy mẫu Reservoir Cân bằng
12: kết thúc nếu
13:kết thúc nếu
thay đổi đáng kể so với RS, nhưng nó giúp giảm phương sai trong kết quả.
B.3. Chi tiết huấn luyện
Kích thước hình ảnh là 32×32 trong Split-CIFAR10 và Split-CIFAR100 và 64×64 trong Split-TinyImageNet. Tất cả các thí nghiệm sử dụng cùng một quy trình tăng cường dữ liệu, được áp dụng trên đầu vào từ cả tác vụ hiện tại và bộ đệm bộ nhớ một cách độc lập. Tăng cường dữ liệu bao gồm cắt ngẫu nhiên kích thước đầy đủ với padding 4 pixel, lật ngang ngẫu nhiên, và chuẩn hóa.
Cho tất cả các thí nghiệm có liên quan đến BFP, tối ưu hóa cho ma trận A là một tối ưu hóa SGD+Momentum với tỷ lệ học 0.1 và momentum 0.9. Thuật ngữ trọng số γ trong Phương trình 12 là 1. Thực nghiệm chúng tôi thấy rằng hiệu suất BFP không nhạy cảm với những siêu tham số này, và chúng tôi sử dụng một bộ siêu tham số này cho mất mát BFP trong tất cả các thí nghiệm.
B.4. Siêu tham số
Trong phần này, chúng tôi liệt kê các siêu tham số tốt nhất được sử dụng cho các đường cơ sở được so sánh được đề cập trong Phần 4.2 và kết quả của chúng được báo cáo trong Bảng 1. Những siêu tham số này được áp dụng từ [8] và [7], nơi chúng được chọn bởi một tìm kiếm siêu tham số được thực hiện trên 10% tập huấn luyện được giữ lại để xác thực. Vui lòng tham khảo [7, 8] để biết thêm chi tiết.
BFP được đề xuất chỉ giới thiệu một siêu tham số duy nhất γ, được đặt thành giá trị không đổi 1 xuyên suốt tất cả các thí nghiệm và không cần điều chỉnh bổ sung. Các siêu tham số khác như α và β được kế thừa từ ER và DER++ [8] và chúng tôi đơn giản áp dụng cùng một bộ siêu tham số từ [8]. Chúng tôi không điều chỉnh hoặc sửa đổi chúng thêm.
11

--- TRANG 11 ---
B.4.1 Split CIFAR-10
FT:lr= 0.1
JT:lr= 0.1
Kích thước bộ đệm = 200
iCaRL :lr= 0.1,wd= 10−5
FDR :lr= 0.03,α= 0.3
LUCIR :λbase= 5,mom = 0.9,k= 2, epochfitting = 20 ,
lr= 0.03, lrfitting= 0.01,m= 0.5
BiC:τ= 2, epochsBiC= 250 ,lr= 0.03
ER-ACE :lr= 0.03
ER:lr= 0.1
DER++ :lr= 0.03,α= 0.1,β= 0.5
Kích thước bộ đệm = 500
iCaRL :lr= 0.1,wd= 10−5
FDR :lr= 0.03,α= 1
LUCIR :λbase= 5,mom = 0.9,k= 2, epochfitting = 20 ,
lr= 0.03, lrfitting= 0.01,m= 0.5
BiC:τ= 2, epochsBiC= 250 ,lr= 0.03
ER-ACE :lr= 0.03
ER:lr= 0.1
DER++ :lr= 0.03,α= 0.2,β= 0.5
B.4.2 Split CIFAR-100
FT:lr= 0.03
JT:lr= 0.03
Kích thước bộ đệm = 500
iCaRL :lr= 0.3,wd= 10−5
FDR :lr= 0.03,α= 0.3
LUCIR :λbase= 5,mom = 0.9,k= 2, epochfitting = 20 ,
lr= 0.03, lrfitting= 0.01,m= 0.5
BiC:τ= 2, epochsBiC= 250 ,lr= 0.03
ER-ACE :lr= 0.03
ER:lr= 0.1
DER++ :lr= 0.03,α= 0.2,β= 0.5
Kích thước bộ đệm = 2000
iCaRL :lr= 0.3,wd= 10−5
FDR :lr= 0.03,α= 1
LUCIR :λbase= 5,mom = 0.9,k= 2, epochfitting = 20 ,
lr= 0.03, lrfitting= 0.01,m= 0.5
BiC:τ= 2, epochsBiC= 250 ,lr= 0.03
ER-ACE :lr= 0.03
ER:lr= 0.1
DER++ :lr= 0.03,α= 0.1,β= 0.5
B.4.3 Split TinyImageNet
FT:lr= 0.03
JT:lr= 0.03
Kích thước bộ đệm = 4000iCaRL :lr= 0.03,wd= 10−5
FDR :lr= 0.03,α= 0.3
LUCIR :λbase=5,mom =0.9, k=2, epochfitting=20,lr=0.03,
lrfitting=0.01, m=0.5
BiC:τ= 2, epochsBiC= 250 ,lr= 0.03
ER-ACE :lr= 0.03
ER:lr= 0.1
DER++ :lr= 0.1,α= 0.3,β= 0.8
C. Kết quả bổ sung
C.1. Quên Cuối cùng
Quên Cuối cùng (FF) đo sự sụt giảm hiệu suất giữa cuối mỗi tác vụ và cuối CL. Một phương pháp CL với FF thấp hơn có khả năng giữ lại kiến thức tốt hơn trong CL và do đó tính ổn định tốt hơn. Tuy nhiên, tính ổn định cao hơn có thể đến với cái giá của tính dẻo dai, và chúng tôi nhắc nhở độc giả rằng Độ chính xác Trung bình Cuối cùng (FAA) được báo cáo trong Bảng 1 có thể phản ánh tốt hơn sự cân bằng giữa tính ổn định và tính dẻo dai. Quên Cuối cùng cho tất cả các đường cơ sở và phương pháp của chúng tôi có thể được tìm thấy trong Bảng 4. Như chúng ta có thể thấy từ Bảng 4, trong thiết lập class-IL, phương pháp DER++ w/ BFP được đề xuất giúp giảm FF so với phương pháp DER++ cơ bản 11% và 12% trên S-CIFAR10 với kích thước bộ đệm 200 và S-CIFAR100 với kích thước bộ đệm 500 tương ứng. DER++ w/ BFP cũng đạt được FF thấp nhất trong số tất cả các phương pháp được so sánh trong thiết lập class-IL. Quên Cuối cùng trong thiết lập Task-IL thường thấp hơn nhiều so với những từ thiết lập Class-IL vì Task-IL cung cấp các định danh tác vụ oracle trong thời gian kiểm tra và do đó trở thành một kịch bản CL dễ dàng hơn nhiều. Trong thiết lập này, BFP được đề xuất cũng mang lại cải thiện lớn so với các phương pháp ER và DER++ cơ bản.
Dataset Buffer FD BFP BFP-2
S-CIFAR10200 55.10±1.85 63.27±1.09 60.61±2.72
500 66.37±1.37 71.51±1.58 70.25±1.18
S-CIFAR100500 20.02±0.09 22.54±1.10 21.25±0.73
2000 36.81±0.71 38.92±1.94 39.42±2.54
S-TinyImg 4000 23.13±0.77 26.33±0.68 25.87±0.86
Bảng 3. Độ chính xác Trung bình Cuối cùng Class-IL sử dụng các loại lớp khác nhau cho phép chiếu đặc trưng ngược. Phương pháp cơ bản là ER.
C.2. Nghiên cứu Ablation dựa trên Phát lại Kinh nghiệm
Chúng tôi thực hiện cùng một nghiên cứu ablation như trong Phần 4.5, trên các loại lớp chiếu khác nhau được sử dụng trong ER w/ BFP. Kết quả được báo cáo trong Bảng 3. Từ Bảng 3, chúng ta có thể rút ra cùng một kết luận như trong Phần 4.5. BFP sử dụng phép biến đổi tuyến tính có thể học được khi chưng cất các đặc trưng và do đó dẫn đến tính dẻo dai tốt hơn trong CL so với phương pháp FD đơn giản. Kết quả cho thấy rằng BFP vượt trội so với FD bằng một biên độ đáng kể và có hiệu suất tốt hơn BFP-2 trong hầu hết các trường hợp. Điều này tiếp tục cho thấy rằng thực thi một
12

--- TRANG 12 ---
Setting Method S-CIFAR10 S-CIFAR100 S-TinyImageNet
Buffer Size 200 500 500 2000 4000
Class-IL Joint Training - - -
Finetune 96.44 ±0.28 89.54 ±0.16 78.54 ±0.45
iCaRL [42] 27.75 ±0.82 25.31 ±4.35 30.13 ±0.28 24.72 ±0.66 16.82 ±0.51
FDR [5] 76.08 ±4.87 83.16 ±4.72 73.71 ±0.68 60.90 ±1.41 57.01 ±0.59
LUCIR [24] 46.36 ±3.17 29.11 ±0.63 53.24 ±0.56 34.16 ±1.19 25.50 ±1.86
BiC [51] 44.36 ±2.73 20.88 ±2.17 51.86 ±1.57 41.42 ±1.61 61.67 ±1.42
ER-ACE [10] 21.59 ±1.19 15.07 ±0.99 38.32 ±1.29 28.69 ±0.87 30.83 ±0.23
ER [43] 42.19 ±5.19 26.64 ±6.33 47.62 ±33.70 44.03 ±18.79 49.61 ±16.47
ER w/ BFP (Ours) 32.23 ±5.58 (-9.96) 22.67 ±6.64 (-3.97) 47.69 ±30.30 (-0.07) 37.49 ±18.06 (-6.54) 41.59 ±20.77 (-8.02)
DER++ [8] 28.28 ±1.06 20.16 ±1.49 42.58 ±2.03 26.29 ±1.66 16.03 ±1.20
DER++ w/ BFP (Ours) 16.69 ±0.28 (-11.59) 13.25 ±0.64 (-6.91) 29.85 ±0.97 (-12.73) 20.91 ±0.86 (-5.39) 9.42 ±1.04 (-6.28)
Task-IL Joint Training - - -
Finetune 39.72 ±6.27 60.46 ±2.74 67.04 ±1.27
iCaRL [42] 4.29 ±1.00 1.91 ±2.12 3.67 ±0.40 1.82 ±0.32 3.56 ±0.46
FDR [5] 7.03 ±1.38 4.47 ±0.45 16.63 ±0.20 9.17 ±0.33 13.73 ±0.30
LUCIR [24] 2.83 ±0.99 2.04 ±0.27 2.61 ±0.17 1.08 ±0.13 4.95 ±0.61
BiC [51] 0.81 ±0.77 0.24 ±0.25 3.95 ±0.35 2.36 ±0.40 7.08 ±3.74
ER-ACE [10] 6.10 ±0.72 3.64 ±0.29 13.95 ±0.45 7.36 ±0.43 10.67 ±0.41
ER [43] 5.71 ±0.60 3.54 ±1.15 11.55 ±6.31 6.12 ±2.49 11.77 ±2.06
ER w/ BFP (Ours) 1.38 ±0.29 (-4.34) 0.77 ±0.38 (-2.77) 5.63 ±1.56 (-5.92) 2.95 ±0.75 (-3.16) 3.31 ±1.19 (-8.46)
DER++ [8] 3.88 ±0.51 1.65 ±0.17 11.68 ±0.55 4.80 ±0.45 6.73 ±0.41
DER++ w/ BFP (Ours) 1.04 ±0.23 (-2.84) 0.53 ±0.23 (-1.12) 6.36 ±0.43 (-5.32) 3.26 ±0.15 (-1.54) 4.17 ±0.37 (-2.49)
Bảng 4. Quên Cuối cùng (FF, tính bằng %, thấp hơn là tốt hơn) trong thiết lập Class-IL và Task-IL của các đường cơ sở và phương pháp của chúng tôi trên các bộ dữ liệu và kích thước bộ đệm khác nhau. Các số màu xanh lá cây trong ngoặc đơn cho thấy các cải thiện tuyệt đối so với các đường cơ sở ER hoặc DER++ tương ứng mà BFP mang lại.
mối quan hệ tuyến tính giữa các đặc trưng mới và cũ có thể bảo toàn tốt hơn khả năng phân tách tuyến tính và dẫn đến ít quên hơn trong CL.
C.3. Thăm dò Tuyến tính
Chúng tôi thực hiện cùng một phân tích thăm dò tuyến tính như Phần 4.4 Hình 3 trên Split-CIFAR100 và Split-TinyImageNet, và kết quả được báo cáo trong Hình 5. Trên hai bộ dữ liệu này, trong khi FD và BFP dẫn đến hiệu suất thăm dò tuyến tính tương tự khi dựa trên DER++, BFP vẫn dẫn đến độ chính xác thăm dò tuyến tính tốt hơn khi dựa trên FT, đặc biệt khi một tập con lớn dữ liệu huấn luyện được sử dụng cho thăm dò tuyến tính. FT w/ BFP (không có bộ đệm bộ nhớ) có hiệu suất tương tự hoặc thậm chí tốt hơn DER++ (với bộ đệm bộ nhớ). Điều này cho thấy rằng BFP giúp học một không gian đặc trưng tốt hơn từ CL, nơi các đặc trưng từ các lớp khác nhau có thể phân tách tuyến tính hơn.
C.4. Phân tích Độ tương đồng Đặc trưng
Chúng tôi thực hiện cùng một phân tích độ tương đồng đặc trưng như Phần 4.6 và Hình 4 trên Split-CIFAR100 và Split-TinyImageNet, và kết quả được báo cáo trong Hình 6.
Từ Hình 6, mặc dù các đường cong có phương sai cao xuyên suốt học liên tục, chúng ta có thể thấy rằng BFP có độ tương đồng đặc trưng cao hơn đường cơ sở DER++ nhưng thấp hơn FD ngây thơ, và do đó đạt được sự cân bằng tốt hơn giữa tính ổn định và tính dẻo dai.

Method DER++ w/ FD w/ BFP w/ BFP-2
Class-IL 49.20 ±1.99 51.89 ±3.42 54.45 ±0.86 52.88 ±1.86
Task-IL 69.01 ±2.01 71.23 ±2.80 72.05 ±1.04 70.56 ±1.47
Bảng 5. Độ chính xác Trung bình Cuối cùng trên ImageNet-100. (trung bình ±std trên 3 lần chạy)
C.5. Thí nghiệm trên Split-ImageNet100
Để chứng minh rằng phương pháp BFP được đề xuất mở rộng đến các bộ dữ liệu lớn, chúng tôi thực hiện các thí nghiệm trên ImageNet100 [24, 42]. Chúng tôi chia ImageNet100 thành 10 tác vụ với 10 lớp mỗi tác vụ và sử dụng bộ đệm bộ nhớ có kích thước 2000. Mô hình được huấn luyện trong 65 epoch trên mỗi tác vụ sử dụng một tối ưu hóa SGD với tỷ lệ học ban đầu 0.1 và weight decay 5×10−4. Trong mỗi tác vụ, tỷ lệ học trải qua một bộ lập lịch warm-up tuyến tính cho 5 epoch đầu tiên và sau đó giảm với tỷ lệ 0.1 sau 15, 30, 40, và 45 epoch. Kết quả được báo cáo trong Bảng 5, cho thấy rằng phương pháp BFP được đề xuất vẫn cho một cải thiện đáng kể (hơn 5% trong thiết lập Class-IL) so với đường cơ sở DER++, xác nhận kết quả hiện có của chúng tôi.
C.6. Tác động của γ đối với Tính dẻo dai và Tính ổn định
Trong học liên tục, trọng số của mất mát chính quy hóa kiểm soát mức độ gần gũi và nghiêm ngặt mà mô hình nên giống với các checkpoint cũ. Do đó trọng số phục vụ như một núm điều khiển trên sự cân bằng giữa tính ổn định và tính dẻo dai: với mất mát chính quy hóa mạnh hơn, mô hình quên các tác vụ cũ ít hơn nhưng thay vào đó gặp khó khăn trong việc học các tác vụ mới.
13

--- TRANG 13 ---
Mặc dù chúng tôi không thực hiện một tìm kiếm siêu tham số mở rộng trên γ cho các kết hợp riêng lẻ của bộ dữ liệu và kích thước bộ đệm, chúng tôi vẫn quan tâm đến cách γ thay đổi ảnh hưởng đến sự cân bằng giữa tính ổn định và tính dẻo dai trong học liên tục. Do đó, chúng tôi huấn luyện DER++ w/ BFP trên S-CIFAR10 với γ khác nhau và báo cáo hiệu suất trong Bảng 6. Bên cạnh FAA và FF, chúng tôi cũng báo cáo Độ chính xác Học Trung bình (ALA) [43], đo khả năng học trên các tác vụ mới trong học liên tục và do đó phản ánh tính dẻo dai. Sử dụng ký hiệu từ Phần 4.1, ALA được định nghĩa là
ALA =1
TTX
i=1ai
i. (18)
Từ Bảng 6, chúng ta có thể thấy rằng tác động của γ phù hợp với trực giác của chúng tôi. Một γ cao hơn đặt ra một chính quy hóa mạnh trên không gian đặc trưng, dẫn đến FF thấp hơn (ổn định hơn) nhưng cũng ALA thấp hơn (ít dẻo dai hơn). Ngoài ra, chúng ta có thể quan sát rằng hiệu suất cuối cùng (FAA) vẫn bền vững với giá trị của γ trong một phạm vi đáng kể.
D. Công trình liên quan khác
Đã có một số công trình gần đây cũng sử dụng tính toán PCA trong học liên tục. Lưu ý rằng BFP được đề xuất không yêu cầu tính toán PCA trong quá trình huấn luyện và các hướng đặc trưng được học một cách ngầm định khi tối ưu hóa ma trận A. Tuy nhiên, để cung cấp một hiểu biết hoàn chỉnh về tài liệu, chúng tôi xem xét ngắn gọn công trình liên quan cũng sử dụng PCA cho học liên tục.
Doan et al. [18] đề xuất PCA-OGD, kết hợp phân tích PCA với Orthogonal Gradient Descent (OGD). PCA-OGD chiếu các gradient lên không gian con dư để giảm sự can thiệp của các cập nhật gradient từ các tác vụ mới trên các tác vụ cũ. Zhu et al. [57] phân tách các đặc trưng đã học trong CL sử dụng PCA. Họ cho thấy rằng các hướng đặc trưng với các giá trị riêng lớn hơn có độ tương đồng lớn hơn (các góc tương ứng) trước và sau khi học một tác vụ. Họ đề xuất rằng những hướng đặc trưng này có thể chuyển giao hơn và ít quên hơn. Họ cho thấy rằng phương pháp tăng cường kép của họ có thể khuyến khích các đặc trưng đã học có nhiều hướng với các giá trị riêng lớn hơn. GeoDL [47] xây dựng các đa tạp chiều thấp cho các đặc trưng được trích xuất bởi mô hình trực tuyến và các checkpoint cũ và thực hiện chưng cất kiến thức trên các đa tạp. Tính toán PCA được thực hiện một cách rõ ràng trên các đặc trưng đã học cho việc xây dựng đa tạp. SPACE [45] sử dụng phân tích PCA để nén và cắt tỉa mạng trong học liên tục.
Tương tự như phân tích của chúng tôi, họ sử dụng PCA để chia các bộ lọc đã học trong một mạng thành Core, quan trọng cho tác vụ hiện tại, và Residual, có thể được nén và giải phóng để học các tác vụ tương lai. Trong công trình của họ, tính toán PCA được yêu cầu trong quá trình học liên tục trên mỗi lớp của mạng để thực hiện cắt tỉa. Điều này đặt ra một overhead tính toán đáng kể trong CL so với BFP của chúng tôi. Thay vì áp dụng phân tích PCA trong học liên tục, Zhang et al. [55] thiết kế một thuật toán PCA được sửa đổi dựa trên EWC [31] sao cho nó có khả năng học liên tục. Họ nhằm giảm vấn đề quên trong việc giám sát các quy trình đa chế độ.
γ 0.1 0.3 1.0 3.0 10.0
FAA 74.56 75.77 76.68 76.00 73.54
FF 16.11 14.63 13.16 13.07 12.69
ALA 87.45 87.32 87.21 86.45 83.70
Bảng 6. Kết quả trên CIFAR10 (kích thước bộ đệm 500) với γ khác nhau.
1% 10% 100%
Phần dữ liệu huấn luyện được sử dụng cho thăm dò tuyến tính0.250.300.350.400.450.500.550.60Độ chính xác Thăm dò Tuyến tínhDER++ w/ BFP
DER++ w/ FD
DER++
FT w/ BFP
FT w/ FD
FT
1% 10% 100%
Phần dữ liệu huấn luyện được sử dụng cho thăm dò tuyến tính0.150.200.250.300.350.400.45Độ chính xác Thăm dò Tuyến tínhDER++ w/ BFP
DER++ w/ FD
DER++
FT w/ BFP
FT w/ FD
FT
Hình 5. Độ chính xác thăm dò tuyến tính trên bộ trích xuất đặc trưng cố định được thu được sau khi huấn luyện trên Split-CIFAR100 (trên) và TinyImageNet (dưới). DER++ và các biến thể của nó sử dụng kích thước bộ đệm 500 cho CIFAR100 và 4000 cho TinyImageNet.
14

--- TRANG 14 ---
2 3 4 5 6 7 8 9 10
Tác vụ0.30.40.50.60.70.80.9Độ tương đồng CKAĐã thấy - DER++ w/ BFP
Đã thấy - DER++ w/ FD
Đã thấy - DER++
Chưa thấy - DER++ w/ BFP
Chưa thấy - DER++ w/ FD
Chưa thấy - DER++
2 3 4 5 6 7 8 9 10
Tác vụ0.40.50.60.70.80.9Độ tương đồng CKAĐã thấy - DER++ w/ BFP
Đã thấy - DER++ w/ FD
Đã thấy - DER++
Chưa thấy - DER++ w/ BFP
Chưa thấy - DER++ w/ FD
Chưa thấy - DER++Hình 6. Độ tương đồng đặc trưng tại các tác vụ khác nhau của việc huấn luyện trên Split-CIFAR100 với kích thước bộ đệm 500 (trên) và Split-TinyImageNet với kích thước bộ đệm 4000 (dưới), sử dụng các phương pháp CL khác nhau.
15

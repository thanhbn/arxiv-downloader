# 2211.00789.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-distillation/2211.00789.pdf
# Kích thước file: 949359 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Vượt Ra Ngoài Việc Không Quên: Học Liên Tục với
Chuyển Giao Kiến Thức Ngược
Sen Lin
School of ECEE
Arizona State University
slin70@asu.eduLi Yang
School of ECEE
Arizona State University
lyang166@asu.edu
Deliang Fan
School of ECEE
Arizona State University
dfan@asu.eduJunshan Zhang
Department of ECE
University of California, Davis
jazh@ucdavis.edu
Tóm tắt
Bằng cách học một chuỗi các nhiệm vụ liên tục, một tác nhân trong học liên tục (CL) có thể
cải thiện hiệu suất học tập của cả nhiệm vụ mới và các nhiệm vụ 'cũ' bằng cách tận dụng
chuyển giao kiến thức thuận và chuyển giao kiến thức ngược, tương ứng.
Tuy nhiên, hầu hết các phương pháp CL hiện tại tập trung vào việc giải quyết vấn đề quên
thảm khốc trong mạng nơ-ron bằng cách giảm thiểu việc sửa đổi mô hình đã học cho
các nhiệm vụ cũ. Điều này không tránh khỏi hạn chế việc chuyển giao kiến thức ngược
từ nhiệm vụ mới sang các nhiệm vụ cũ, bởi vì việc cập nhật mô hình khôn ngoan có thể
cải thiện hiệu suất học tập của các nhiệm vụ cũ. Để giải quyết vấn đề này, chúng tôi đầu
tiên phân tích lý thuyết các điều kiện mà việc cập nhật mô hình đã học của các nhiệm vụ
cũ có thể có lợi cho CL và cũng dẫn đến chuyển giao kiến thức ngược, dựa trên phép
chiếu gradient lên các không gian con đầu vào của các nhiệm vụ cũ. Dựa trên phân tích
lý thuyết, chúng tôi tiếp theo phát triển một phương pháp học liên tục với chuyển giao
kiến thức ngược (CUBER), cho một mạng nơ-ron có dung lượng cố định mà không có
tái diễn dữ liệu. Cụ thể, CUBER đầu tiên đặc trưng hóa mối tương quan nhiệm vụ để
xác định các nhiệm vụ cũ có mối tương quan tích cực theo cách từng lớp, và sau đó có
chọn lọc sửa đổi mô hình đã học của các nhiệm vụ cũ khi học nhiệm vụ mới. Các nghiên
cứu thực nghiệm cho thấy CUBER thậm chí có thể đạt được chuyển giao kiến thức ngược
tích cực trên một số tiêu chuẩn CL hiện có lần đầu tiên mà không có tái diễn dữ liệu, nơi
mà các đường cơ sở liên quan vẫn gặp phải tình trạng quên thảm khốc (chuyển giao kiến
thức ngược tiêu cực). Hiệu suất vượt trội của CUBER trong việc chuyển giao kiến thức
ngược cũng dẫn đến độ chính xác cao hơn tương ứng.

1 Giới thiệu
Một mục tiêu cuối cùng của trí tuệ nhân tạo là xây dựng một tác nhân có thể liên tục học
một chuỗi các nhiệm vụ khác nhau, để phản ánh khả năng học tập đáng chú ý của con
người trong suốt cuộc đời họ. Với nhiều nhiệm vụ được học, tác nhân được kỳ vọng có
thể học một nhiệm vụ mới dễ dàng hơn bằng cách tận dụng kiến thức tích lũy từ các
nhiệm vụ cũ (chuyển giao kiến thức thuận), và cũng cải thiện thêm hiệu suất học tập
của các nhiệm vụ cũ dựa trên kiến thức thu được từ các nhiệm vụ mới liên quan (chuyển
giao kiến thức ngược). Một mô hình học tập như vậy được gọi là học liên tục (CL) [5, 23],
điều này gần đây đã thu hút nhiều sự chú ý.

Hầu hết các phương pháp CL hiện tại tập trung vào việc giải quyết vấn đề quên thảm khốc
[20], tức là mạng nơ-ron có thể dễ dàng quên kiến thức của các nhiệm vụ cũ khi học một
nhiệm vụ mới. Chiến

36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2211.00789v1  [cs.LG]  1 Nov 2022

--- TRANG 2 ---
lược chính trong đó là tránh việc thay đổi mô hình của các nhiệm vụ cũ khi học nhiệm vụ mới. Ví dụ,
các phương pháp dựa trên chính quy hóa (ví dụ: [12,1,18]) phạt việc sửa đổi các trọng số quan trọng
của các nhiệm vụ cũ; các phương pháp dựa trên tách biệt tham số (ví dụ: [7,26,31,9]) cố định mô hình
đã học cho các nhiệm vụ cũ; và các phương pháp dựa trên bộ nhớ (ví dụ: [3,6,25]) nhằm cập nhật mô hình
với sự can thiệp tối thiểu được đưa vào các nhiệm vụ cũ. Trong khi hiệu quả giảm thiểu việc quên thảm khốc,
chiến lược đóng băng mô hình như vậy không tránh khỏi hạn chế việc chuyển giao kiến thức ngược, bằng
cách ngầm định và bảo thủ coi việc cập nhật mô hình của nhiệm vụ mới như sự can thiệp đến các nhiệm vụ cũ.
Một cách trực quan, việc sửa đổi cẩn thận mô hình đã học của các nhiệm vụ cũ có thể cải thiện thêm hiệu suất
học tập đặc biệt khi nhiệm vụ mới chia sẻ kiến thức tương tự với các nhiệm vụ cũ.

Công trình này tìm cách khám phá CL từ một góc độ mới bằng cách vượt ra ngoài việc chỉ giải quyết vấn đề quên:
Khi nào và như thế nào chúng ta có thể cải thiện mô hình đã học của các nhiệm vụ cũ để tạo điều kiện cho
việc chuyển giao kiến thức ngược? Cụ thể, chúng tôi xem xét một mạng nơ-ron cố định và kịch bản mà dữ
liệu của các nhiệm vụ cũ không thể truy cập được khi học một nhiệm vụ mới, điều này tự nhiên loại trừ các
phương pháp dựa trên mở rộng (ví dụ: [31,9]) và các phương pháp tái diễn kinh nghiệm (ví dụ: [22,4]).
Rõ ràng, việc đạt được chuyển giao kiến thức ngược rất thách thức trong trường hợp này vì việc giảm thiểu
quên ở đây đã là điều không tầm thường.

Để giải quyết thách thức này, lưu ý rằng các phương pháp CL dựa trên phép chiếu trực giao (ví dụ: [25,17]),
cập nhật mô hình với gradient trực giao với các không gian con đầu vào của các nhiệm vụ cũ, đã chứng minh
hiệu suất tối tân dưới thiết lập trên. Do đó được thúc đẩy, chúng tôi đề xuất một phương pháp CL dựa trên
phép chiếu trực giao mới để cẩn thận sửa đổi mô hình đã học của các nhiệm vụ cũ để có chuyển giao kiến thức
ngược tốt hơn.

Các đóng góp chính của công trình này bao gồm 1) việc định lượng các điều kiện mà việc sửa đổi mô hình
đã học của các nhiệm vụ cũ có lợi và 2) một phương pháp CL mới được truyền cảm hứng từ phân tích, để
trả lời câu hỏi trên. Cụ thể hơn, chúng tôi đầu tiên giới thiệu các khái niệm 'phép chiếu đủ' và 'mối tương
quan tích cực' dựa trên phép chiếu gradient lên các không gian con của các nhiệm vụ cũ để đặc trưng hóa
mối tương quan nhiệm vụ. Chúng tôi chứng minh lý thuyết rằng khi các gradient nhiệm vụ được căn chỉnh
đủ trong không gian con nhiệm vụ cũ, việc cập nhật thích hợp mô hình đã học của các nhiệm vụ cũ khi học
nhiệm vụ mới có thể cải thiện hiệu suất học tập và có thể dẫn đến một mô hình tốt hơn cho các nhiệm vụ cũ.
Dựa trên phân tích này, chúng tôi tiếp theo đề xuất một phương pháp học liên tục dựa trên phép chiếu trực
giao với chuyển giao kiến thức ngược (CUBER), mà 1) đầu tiên xác định các nhiệm vụ cũ có mối tương quan
tích cực với nhiệm vụ mới và 2) cẩn thận cập nhật mô hình đã học của các nhiệm vụ cũ được chọn cùng
với việc học mô hình cho nhiệm vụ mới. Kết quả thực nghiệm trên các tiêu chuẩn CL tiêu chuẩn cho thấy
CUBER có thể đạt được chuyển giao kiến thức ngược tốt nhất so với tất cả các phương pháp CL cơ sở được
xem xét, điều này do đó cải thiện hiệu suất học tập tổng thể. Cụ thể, theo hiểu biết tốt nhất của chúng tôi,
CUBER là phương pháp đầu tiên chứng minh chuyển giao kiến thức ngược tích cực trên các tiêu chuẩn này
sử dụng mạng có dung lượng cố định mà không có tái diễn kinh nghiệm, trong khi tất cả các đường cơ sở
so sánh vẫn gặp phải tình trạng quên thảm khốc với chuyển giao kiến thức ngược tiêu cực.

2 Công trình liên quan
Học liên tục. Các phương pháp CL hiện tại có thể được chia thành ba loại chung: 1)
Các phương pháp dựa trên chính quy hóa (ví dụ: [12,1,15,18]) thêm chính quy hóa bổ sung trong hàm
mất mát để phạt việc thay đổi mô hình của các nhiệm vụ cũ khi học nhiệm vụ mới. Ví dụ, Elastic Weight
Consolidation (EWC) [12] chính quy hóa việc cập nhật trên các trọng số quan trọng được đánh giá bằng
ma trận Fisher Information; một phương pháp tối ưu hóa gradient đệ quy được đề xuất trong [18] để sửa đổi
hướng gradient cho hàm mục tiêu được chính quy hóa bởi việc thay đổi mô hình trong CL. 2) Các phương
pháp dựa trên tách biệt tham số (ví dụ: [24,16,31,30,26,29]) phân bổ các tham số mô hình khác nhau cho
các nhiệm vụ khác nhau, cố định các tham số cho các nhiệm vụ cũ bằng cách che chúng trong quá trình học
nhiệm vụ mới và mở rộng mạng khi cần. Ví dụ, Additive Parameter Decomposition (APD) [30] đề xuất một
phương pháp củng cố kiến thức phân cấp để tách biệt các tham số đặc thù nhiệm vụ và các tham số được
chia sẻ nhiệm vụ, trong đó các tham số đặc thù nhiệm vụ được giữ nguyên để giải quyết vấn đề quên. 3)
Các phương pháp dựa trên bộ nhớ có thể được chia thêm thành các phương pháp tái diễn kinh nghiệm và
các phương pháp dựa trên phép chiếu trực giao tùy thuộc vào việc dữ liệu của các nhiệm vụ cũ có sẵn cho
nhiệm vụ mới hay không. Các phương pháp tái diễn kinh nghiệm (ví dụ: [3,22,8]) lưu trữ và tái diễn dữ
liệu của các nhiệm vụ cũ khi học nhiệm vụ mới, trong khi các phương pháp dựa trên phép chiếu trực giao
(ví dụ: [32,6,25,17]) cập nhật mô hình theo hướng trực giao của các nhiệm vụ cũ mà không lưu trữ dữ liệu
thô của các nhiệm vụ cũ. Cụ thể, [10] đề xuất học liên tục tự nhiên dựa trên học Bayesian để thống nhất
chính quy hóa trọng số và phép chiếu gradient trực giao.

2

--- TRANG 3 ---
Tuy nhiên, [10] tận dụng kiến thức của nhiệm vụ hiện tại một cách ngầm định để cải thiện các nhiệm vụ cũ,
trong khi phương pháp của chúng tôi cố gắng rõ ràng hơn để cập nhật mô hình của các nhiệm vụ cũ bất cứ
khi nào có thông tin mới liên quan.

Chuyển giao kiến thức. Hầu hết các phương pháp CL tập trung vào vấn đề quên thảm khốc, và ít sự chú ý
được dành cho việc chuyển giao kiến thức qua các nhiệm vụ trong CL với mạng nơ-ron. Progressive Network
[24] xem xét chuyển giao kiến thức thuận nhưng học một mô hình cho mỗi nhiệm vụ. [17] đề xuất trust region
gradient projection (TRGP) để tạo điều kiện cho chuyển giao kiến thức thuận từ các nhiệm vụ cũ có mối tương
quan đến nhiệm vụ mới thông qua một ma trận tỷ lệ, nhưng mô hình vẫn được cập nhật dọc theo hướng trực
giao với các không gian con đầu vào của các nhiệm vụ cũ để giảm thiểu việc quên. [11] nghiên cứu chuyển
giao kiến thức trong một chuỗi hỗn hợp của các nhiệm vụ tương tự và không tương tự, nhưng sử dụng một
cơ chế phát hiện độ tương tự nhiệm vụ phức tạp trong đó hai mạng bổ sung cần được huấn luyện trước cho
mỗi nhiệm vụ trước khi học nhiệm vụ mới.

3 Khi nào chúng ta có thể cải thiện mô hình đã học của các nhiệm vụ cũ?

Trong học liên tục, một chuỗi các nhiệm vụ T={t}^T_{t=1} đến tuần tự. Đối với mỗi nhiệm vụ t, có một
tập dữ liệu D_t={(x^t_i,y^t_i)}^{N_t}_{i=1} với N_t cặp mẫu, được lấy mẫu từ một phân phối chưa biết P_t.
Trong công trình này, chúng tôi xem xét một mạng nơ-ron có dung lượng cố định với trọng số w. Khi học
một nhiệm vụ mới t, chúng tôi chỉ có quyền truy cập vào tập dữ liệu D_t và không có điểm dữ liệu nào của
các nhiệm vụ cũ có sẵn. Chúng tôi cũng ký hiệu L(w;D_t)=L_t(w) là hàm mất mát để huấn luyện, ví dụ:
mất mát bình phương trung bình và entropy chéo, và w_t là mô hình sau khi học nhiệm vụ t.

Một cách trực quan, nếu nhiệm vụ mới t có độ tương tự mạnh với một số nhiệm vụ cũ, việc cập nhật mô hình
thích hợp của nhiệm vụ mới sẽ không gây ra việc quên các nhiệm vụ cũ tương tự, nhưng có thể dẫn đến một
mô hình tốt hơn cho các nhiệm vụ cũ này do chuyển giao kiến thức ngược. Để đặc trưng hóa chính thức độ
tương tự nhiệm vụ này, chúng tôi giới thiệu các điều kiện sau đây trên các gradient nhiệm vụ.

Định nghĩa 1 (Phép chiếu đủ). Đối với bất kỳ nhiệm vụ mới t∈[1,T], chúng ta nói nó có phép chiếu gradient
đủ trên không gian con đầu vào của nhiệm vụ cũ j∈[0,t−1] nếu với một số λ_1∈(0,1)
||Proj_{S_j}(∇L_t(w_{t−1}))||_2≥λ_1||∇L_t(w_{t−1})||_2.

Ở đây Proj_{S_j} định nghĩa phép chiếu trên không gian con đầu vào S_j của nhiệm vụ j: Proj_{S_j}(A)=AB_j(B_j)^T
cho một ma trận A nào đó và B_j là các cơ sở cho S_j. Định nghĩa phép chiếu đủ này theo cùng hướng của
vùng tin cậy được định nghĩa trong [17], điều này ngụ ý rằng nhiệm vụ t và j có thể có các cơ sở chung đủ
giữa các không gian con đầu vào của chúng và do đó có mối tương quan mạnh, bởi vì gradient nằm trong
khoảng của đầu vào [33].

Định nghĩa 2 (Mối tương quan tích cực). Đối với bất kỳ nhiệm vụ mới t∈[1,T], chúng ta nói nó có mối tương
quan tích cực với nhiệm vụ cũ j∈[0,t−1] nếu với một số λ_2∈(0,1)
⟨∇L_j(w_j),∇L_t(w_{t−1})⟩≥λ_2||∇L_j(w_j)||_2||∇L_t(w_{t−1})||_2.

Trong khi phép chiếu đủ gợi ý mối tương quan có thể mạnh giữa hai nhiệm vụ t và j, Định nghĩa 2 đi xa
hơn một bước bằng cách giới thiệu mối tương quan tích cực giữa các nhiệm vụ, theo nghĩa là gradient mô
hình ban đầu của nhiệm vụ t không mâu thuẫn với gradient mô hình khi học nhiệm vụ j. Thực tế, có thể
cho thấy rằng mối tương quan tích cực ngụ ý phép chiếu đủ trong Định nghĩa 1 với một số λ_1≥λ_2. Lưu
ý rằng cả Định nghĩa 1 và 2 đều đặc trưng hóa mối tương quan dựa trên mô hình ban đầu w_{t−1}, điều này
cho phép phát hiện mối tương quan nhiệm vụ trước khi học nhiệm vụ mới t.

Để dễ trình bày, xem xét kịch bản với một chuỗi hai nhiệm vụ 1 và 2. Đặt F(w)=L(w;D_1)+L(w;D_2),
g_1(w)=∇_wL(w;D_1) và g_2(w)=∇_wL(w;D_2). Cho mô hình đã học cho nhiệm vụ 1 là w_1, chúng
tôi xem xét hai quy tắc cập nhật mô hình sau đây để học nhiệm vụ 2, trong đó chỉ có dữ liệu của nhiệm vụ 2 sẵn sàng:

• (Quy tắc #1): w_{k+1}=w_k−α[g_2(w_k)−Proj_{S_1}(g_2(w_k))],
• (Quy tắc #2): w_{k+1}=w_k−αg_2(w_k).

Ở đây w_0=w_1 và k∈[0,K−1]. Quy tắc #1 đặc trưng hóa việc cập nhật mô hình của các phương pháp dựa
trên phép chiếu trực giao, trong đó không có sự can thiệp nào được đưa vào nhiệm vụ 1 vì việc thay đổi mô
hình trực giao với không gian con đầu vào S_1 của nhiệm vụ 1 [17] (và do đó mô hình đã học của nhiệm vụ 1
sẽ không được cập nhật). Ngược lại, giảm gradient vani Quy tắc #2 để học nhiệm vụ 2 sẽ không tránh khỏi

3

--- TRANG 4 ---
sửa đổi mô hình đã học w_1 cho nhiệm vụ 1 trừ khi Proj_{S_1}(g_2(w_k)) = 0, tức là trường hợp cực đoan
trong đó cả việc quên và chuyển giao kiến thức đều không xảy ra. Trong phần tiếp theo, chúng tôi đánh giá
hiệu suất của các quy tắc cập nhật này.

Định lý 1. Giả sử rằng mất mát L là B-Lipschitz và H/2-smooth. Đặt α < min{1/H, ||g_1(w_0)||/(HBK)}
và λ_2 ≥ (2+α^2)||g_1(w_0)||/(4||g_2(w_0)||) với một số α^2 ∈ (0,1). Chúng ta có các kết quả sau:

(1) Nếu L là lồi, Quy tắc #2 cho nhiệm vụ 2 hội tụ đến mô hình tối ưu w* = arg min F(w);
(2) Nếu L là không lồi, Quy tắc #2 cho nhiệm vụ 2 hội tụ đến điểm dừng bậc nhất, tức là
min_k ||∇F(w_k)||_2 < (2/αK)[F(w_0)−F(w*)] + 4α + α^2/2||g_1(w_0)||^2.

Định lý 1 chỉ ra rằng việc cập nhật mô hình với Quy tắc #2 sẽ dẫn đến sự hội tụ đến điểm cực tiểu của hàm
mục tiêu chung F(w) trong trường hợp lồi, và sự hội tụ đến điểm dừng bậc nhất trong trường hợp không lồi,
khi nhiệm vụ 1 và 2 thỏa mãn mối tương quan tích cực với λ_2 ≥ (2+α^2)||g_1(w_0)||/(4||g_2(w_0)||). Có
nghĩa là, Quy tắc #2 không chỉ dẫn đến một mô hình tốt cho nhiệm vụ 2, mà còn có thể có lợi cho việc học
chung của nhiệm vụ 1 và 2. Lưu ý rằng vì w_0 là mô hình đã học của nhiệm vụ 1, nói chung chúng ta có
||g_1(w_0)|| < ||g_2(w_0)||. Chứng minh của Định lý 1 có thể được tìm thấy trong Phụ lục A.

Định lý 2. Giả sử rằng mất mát L là B-Lipschitz và H/2-smooth. Chúng ta có các kết quả sau:

(1) Đặt w_c và w_r là các tham số mô hình sau khi áp dụng một lần cập nhật vào một mô hình ban đầu w
bằng cách sử dụng Quy tắc #1 và Quy tắc #2, tương ứng. Giả sử α < min{1/H, ||g_1(w_0)||/(HBK)},
λ_1 ≥ √(1+α^2H^2)/(2+αH) và λ_2 ≥ (2+α^2)||g_1(w_0)||/(4||g_2(w_0)||) với một số α^2 ∈ (0,1).
Khi đó F(w_r) ≤ F(w_c);

(2) Đặt w_k là lần lặp thứ k cho nhiệm vụ 2 với Quy tắc #2. Giả sử rằng ⟨g_1(w_0),g_2(w_i)⟩ ≥
λ_2||g_1(w_0)||||g_2(w_i)|| với i ∈ [0,k−1] và α ≤ λ_2||g_1(w_0)||/(HBk^{1.5}). Khi đó L_1(w_k) ≤ L_1(w_1).

Một cách trực quan, phần đầu của Định lý 2 cho thấy rằng việc cập nhật với Quy tắc #2 có thể đạt được giá
trị mất mát thấp hơn so với Quy tắc #1 sau một bước cập nhật gradient khi nhiệm vụ 1 và 2 thỏa mãn phép
chiếu đủ với λ_1 ≥ √(1+α^2H^2)/(2+αH) và mối tương quan tích cực với λ_2 ≥ (2+α^2)||g_1(w_0)||/(4||g_2(w_0)||).
Nếu điều kiện mối tương quan tích cực cũng giữ cho các lần lặp của Quy tắc #2 khi học nhiệm vụ 2, phần thứ
hai của Định lý 2 chỉ ra rằng việc cập nhật mô hình thực sự dẫn đến một mô hình tốt hơn cho nhiệm vụ 1
đối với L_1. Tóm lại, khi 1) nhiệm vụ 2 có phép chiếu gradient đủ lên không gian con của nhiệm vụ 1 và
2) gradient được chiếu cũng được căn chỉnh tốt với gradient của nhiệm vụ 1 trong không gian con của nhiệm
vụ 1, việc cập nhật mô hình dọc theo g_2 sẽ sửa đổi mô hình đã học w_1 theo hướng thuận lợi cho CL và
cho phép chuyển giao kiến thức ngược đến nhiệm vụ 1. Chứng minh của Định lý 2 có trong Phụ lục B.

Đáng chú ý rằng các điều kiện cho Định lý 1 và 2 chỉ phụ thuộc vào gradient mô hình ban đầu g_2(w_1)
trước khi học nhiệm vụ 2 và gradient g_1(w_1) khi học nhiệm vụ 1, cả hai đều dễ dàng truy cập và tính toán.
Đặc biệt, mối tương quan tích cực có thể được đánh giá chỉ bằng cách lưu trữ gradient g_1(w_1) thay vì dữ
liệu của nhiệm vụ 1. Ngược lại hoàn toàn, việc đặc trưng hóa mối tương quan gradient nhiệm vụ trong [3,22]
liên quan đến việc đánh giá gradient của các nhiệm vụ cũ đối với trọng số mô hình hiện tại, và do đó yêu cầu
dữ liệu của các nhiệm vụ cũ khi học nhiệm vụ mới.

4 Học liên tục với chuyển giao kiến thức ngược

Dựa trên phân tích lý thuyết trên, chúng tôi tiếp theo đề xuất một phương pháp học liên tục với chuyển giao
kiến thức ngược (CUBER), bằng cách có chọn lọc cập nhật mô hình đã học của các nhiệm vụ cũ khi học
nhiệm vụ mới. Cụ thể, CUBER hoạt động theo cách từng lớp: Cho một mạng L-lớp, CUBER đầu tiên đặc
trưng hóa mối tương quan nhiệm vụ cho mỗi lớp, và sau đó sử dụng các chiến lược khác nhau để học nhiệm
vụ mới tùy thuộc vào mối tương quan nhiệm vụ.

Cụ thể hơn, ký hiệu tập hợp các trọng số là w={w_l}^L_{l=1}, trong đó w_l là trọng số từng lớp cho lớp l.
Cho đầu vào dữ liệu x^t_i cho nhiệm vụ t, đặt x^t_{l,i} là đầu vào của lớp l và x^t_{1,i}=x^t_i. Ký hiệu f
là phép toán của lớp mạng. Đầu ra x^t_{l+1,i} cho lớp l có thể được tính như

4

--- TRANG 5 ---
Hình 1: Một minh họa đơn giản về việc phát hiện mối tương quan nhiệm vụ từng lớp. Cho nhiệm vụ mới t,
một nhiệm vụ cũ j thuộc về (1) Chế độ 1 nếu gradient mô hình ban đầu ∇L_t(w^{t-1}_l) của nhiệm vụ t có
phép chiếu nhỏ lên không gian con S^j_l của nhiệm vụ j; (2) Chế độ 2 nếu điều kiện phép chiếu mạnh được
thỏa mãn trong khi phép chiếu của ∇L_t(w^{t-1}_l) lên S^j_l không căn chỉnh tốt với gradient của nhiệm vụ j;
(3) Chế độ 3 nếu cả điều kiện phép chiếu mạnh và điều kiện mối tương quan tích cực đều được thỏa mãn.

x^t_{l+1,i}=f(w_l,x^t_{l,i}). Ở đây chúng tôi ký hiệu x^t_{l,i} là các biểu diễn của đầu vào x^t_i tại lớp l.
Cho một nhiệm vụ mới t≥2, chúng tôi đặc trưng hóa mối tương quan nhiệm vụ của nó với một số nhiệm vụ
cũ j∈[1,t−1] cho lớp l thành ba chế độ khác nhau dựa trên Định nghĩa 1 và 2.

Chế độ 1 (không quên): Chúng ta nói rằng nhiệm vụ j∈Reg^t_{l,1} cho lớp l nếu điều sau đây đúng:
||Proj_{S^j_l}(∇L_t(w^{t-1}_l))||≤λ_1||∇L_t(w^{t-1}_l))||.

Trong trường hợp này, không gian con đầu vào từng lớp S^j_l cho nhiệm vụ j và S^t_l cho nhiệm vụ t được
coi là gần như trực giao ((a) trong Hình 1). Kết quả là, có rất ít chuyển giao kiến thức giữa hai nhiệm vụ
này, và việc cập nhật mô hình cùng với ∇L_t(w_l) sẽ không gây ra nhiều can thiệp đến nhiệm vụ j. Để củng
cố việc bảo vệ kiến thức cho nhiệm vụ j, mô hình sẽ được cập nhật dựa trên phép chiếu trực giao:
∇L_t(w_l) ← ∇L_t(w_l)−Proj_{S^j_l}(∇L_t(w_l)).

Chế độ 2 (chuyển giao kiến thức thuận): Chúng ta nói rằng nhiệm vụ j∈Reg^t_{l,2} cho lớp l nếu điều sau
đây đúng:
||Proj_{S^j_l}(∇L_t(w^{t-1}_l))||≥λ_1||∇L_t(w^{t-1}_l))||,
⟨∇L_j(w^j_l),∇L_t(w^{t-1}_l)⟩≤λ_2||∇L_j(w^j_l)||||∇L_t(w^{t-1}_l)||.

Trong trường hợp này, nhiệm vụ j và nhiệm vụ t có thể có mối tương quan mạnh cho lớp l nhưng có thể
với mối tương quan 'tiêu cực' ((b) trong Hình 1), theo nghĩa là việc cập nhật mô hình cùng với ∇L_t(w_l)
sẽ sửa đổi đáng kể mô hình đã học Proj_{S^j_l}(w^{t-1}) cho nhiệm vụ j theo cách không thuận lợi và dẫn
đến việc quên nhiệm vụ j. Vì sẽ có chuyển giao kiến thức thuận tốt hơn từ nhiệm vụ cũ j đến nhiệm vụ mới
t cho lớp l, chúng tôi tận dụng phép chiếu trọng số có tỷ lệ trong [17] để tạo điều kiện cho chuyển giao kiến
thức thuận thông qua một ma trận tỷ lệ Q^{j,t}_l, trong khi mô hình vẫn được cập nhật bằng phép chiếu
trực giao để bảo vệ kiến thức của các nhiệm vụ cũ:
∇L_t(w_l) ← ∇L_t(w_l)−Proj_{S^j_l}(∇L_t(w_l)),
Q^{j,t}_l ← Q^{j,t}_l−α∇_{Q^{j,t}_l}L_t(w_l−Proj_{S^j_l}(w_l) +w_lB^j_lQ^{j,t}_l(B^j_l)^T). (1)

Ở đây B^j_l là ma trận cơ sở cho không gian con S^j_l. Một cách trực quan, phép chiếu trọng số có tỷ lệ
w_lB^j_lQ^{j,t}_l(B^j_l)^T thay thế phép chiếu trọng số Proj_{S^j_l}(w_l) của nhiệm vụ j bằng một phiên
bản có tỷ lệ, điều này chuyển đổi kiến thức của nhiệm vụ j thành mô hình thích hợp của nhiệm vụ mới t
thông qua việc tối ưu hóa Q^{j,t}_l.

Chế độ 3 (chuyển giao kiến thức ngược): Chúng ta nói nhiệm vụ j∈Reg^t_{l,3} cho lớp l nếu điều sau đây đúng:
||Proj_{S^j_l}(∇L_t(w^{t-1}_l))||≥λ_1||∇L_t(w^{t-1}_l))||,
⟨∇L_j(w^j_l),∇L_t(w^{t-1}_l)⟩≥λ_2||∇L_j(w^j_l)||||∇L_t(w^{t-1}_l)||.

5

--- TRANG 6 ---
Với phép chiếu đủ và mối tương quan tích cực, việc cập nhật mô hình cùng với ∇L_t(w_l) có thể dẫn đến
một mô hình tốt hơn cho học liên tục và cũng cải thiện hiệu suất học tập của nhiệm vụ cũ j ((c) trong Hình 1).
Để tránh việc sửa đổi quá lạc quan trên mô hình đã học của nhiệm vụ j, chúng tôi tiếp tục chính quy hóa
phép chiếu của việc thay đổi mô hình trên không gian con S^j_l, cho rằng phép chiếu mô hình thực sự được
đóng băng cho nhiệm vụ j để giải quyết việc quên với phép chiếu trực giao, tức là Proj_{S^j_l}(w^{t-1}_l) =
Proj_{S^j_l}(w^j_l). Điều này đưa ra việc cập nhật mô hình sau:
w_l ← w_l−α∇[L_t(w_l) + β||Proj_{S^j_l}(w_l−w^{t-1}_l)||].

Lưu ý rằng phép chiếu gradient trên các không gian con của các nhiệm vụ cũ trong Chế độ 1 và 2 được loại
bỏ khỏi gradient trong việc cập nhật mô hình ở trên. Bên cạnh đó, chúng tôi cũng học một ma trận tỷ lệ
Q^{j,t}_l để có chuyển giao kiến thức thuận tốt hơn từ nhiệm vụ cũ j∈Reg^t_{l,3} đến nhiệm vụ mới t như
trong Công thức (1).

Hình 2: Một minh họa đơn giản
về trường hợp mà việc cập nhật
mô hình với ∇L_t có lợi cho
nhiệm vụ cũ j∈Reg^t_{l,3} ban
đầu nhưng cuối cùng mâu thuẫn
với ∇L_j.

Tuy nhiên, việc cập nhật mô hình liên tục với gradient nhiệm vụ t ∇L_t(w_l)
cuối cùng sẽ dẫn đến mô hình đặc thù nhiệm vụ cho nhiệm vụ t, điều này
thường khác với mô hình của nhiệm vụ j trong Chế độ 3 (Hình 2).
Để giải quyết vấn đề này, lưu ý rằng phần thứ hai của Định lý
2 đặc trưng hóa điều kiện mà việc cập nhật mô hình với ∇L_t(w_l)
sẽ dẫn đến chuyển giao kiến thức ngược. Do đó được thúc đẩy,
đối với một lần lặp cập nhật mô hình w_{l,k} tại lần lặp thứ k khi
học nhiệm vụ mới t, chúng tôi đánh giá điều kiện sau đây cho
nhiệm vụ j∈Reg^t_{l,3}:
⟨∇L_j(w^j_l),∇L_t(w_{l,k})⟩≥λ_2||∇L_j(w^j_l)||||∇L_t(w_{l,k})|| (2)

và hạ cấp nhiệm vụ j xuống Chế độ 2, tức là loại bỏ phép chiếu
gradient trên không gian con S^j_l khỏi gradient nhiệm vụ t và
ngừng sửa đổi mô hình cho nhiệm vụ j, nếu điều kiện (2) không
thỏa mãn.

Trích xuất cơ sở: Sau khi học mô hình w_t cho nhiệm vụ t, chúng tôi xây dựng không gian con đầu vào
cho mỗi lớp l bằng cách trích xuất cơ sở từ biểu diễn x^t_{l,i} của nó dựa trên phân tích giá trị riêng (SVD)
[17]. Cụ thể hơn, cho một batch gồm n mẫu và mô hình đã học w_t, ma trận biểu diễn cho lớp l được ký
hiệu là R^t_l = [x^t_{l,1},x^t_{l,2},...,x^t_{l,n}]. Vì các cơ sở của các nhiệm vụ cũ có thể bao gồm các cơ
sở quan trọng cho nhiệm vụ mới t, chúng tôi xác định các cơ sở cho nhiệm vụ t từ sự hợp của các cơ sở
của các nhiệm vụ cũ và các cơ sở mới được tạo ra. Hướng tới mục tiêu này, chúng tôi đầu tiên nối các cơ
sở B^j_l cho j∈[0,t−1] với nhau trong một ma trận O^t_l và loại bỏ các cơ sở chung. Sau đó SVD được áp
dụng trên ma trận biểu diễn dư ̃R^t_l=R^t_l−R^t_lO^t_l(O^t_l)^T, tức là ̃R^t_l=U^t_lΣ^t_l(V^t_l)^T, trong
đó U^t_l là ma trận riêng trái. Chúng tôi xây dựng B^t_l bằng cách chọn các cơ sở quan trọng nhất từ tập
hợp các cơ sở trong O^t_l và U^t_l tùy thuộc vào các giá trị riêng của chúng, điều này tạo ra một xấp xỉ ma
trận hạng thấp của R^t_l.

Để kết luận, bài toán tối ưu hóa để học nhiệm vụ mới t có thể được tóm tắt như sau:
min_{w,{Q^{j,t}_l}_{l,j∈Reg^t_{l,2}∪Reg^t_{l,3}}} L_t(f{̃w_l}_l) + ∑_l ∑_{j∈Reg^t_{l,3}} β||Proj_{S^j_l}(w_l−w^{t-1}_l)||, (3)

s.t: ̃w_l=w_l+∑_{j∈Reg^t_{l,2}∪Reg^t_{l,3}}[w_lB^j_lQ^{j,t}_l(B^j_l)^T−Proj_{S^j_l}(w_l)],
∇L_t(w_l) =∇L_t(w_l)−∑_{j∈Reg^t_{l,1}∪Reg^t_{l,2}}Proj_{S^j_l}(∇L_t(w_l)).

Ý tưởng chính là chúng tôi cập nhật mô hình một cách bảo thủ cho các nhiệm vụ cũ trong Chế độ 3 trong
khi sử dụng phép chiếu trực giao để bảo toàn kiến thức của các nhiệm vụ cũ khác; trong lúc đó, chúng tôi
tận dụng phép chiếu trọng số có tỷ lệ để tái sử dụng kiến thức mô hình của các nhiệm vụ cũ trong cả Chế
độ 2 và 3 để tạo điều kiện cho chuyển giao kiến thức thuận. Đáng chú ý rằng mối tương quan nhiệm vụ
được xác định trước khi học nhiệm vụ mới t, vì cả điều kiện phép chiếu mạnh và điều kiện mối tương quan
tích cực chỉ phụ thuộc vào gradient mô hình ban đầu cho nhiệm vụ mới. Và điều này có thể đạt được bằng
một lần truyền thuận-ngược đơn giản qua mô hình ban đầu với một batch dữ liệu nhiệm vụ mới. Tổng quan
về CUBER có thể được tìm thấy trong Thuật toán 1.

6

--- TRANG 7 ---
Thuật toán 1 Học liên tục với chuyển giao kiến thức ngược (CUBER)
1: Đầu vào: chuỗi nhiệm vụ T={t}^T_{t=1};
2: Học nhiệm vụ đầu tiên sử dụng giảm gradient ngẫu nhiên vani;
3: Trích xuất các cơ sở {B^1_l} dựa trên SVD sử dụng mô hình đã học w_1;
4: for each nhiệm vụ t do
5: Tính gradient ∇L_t(w^{t-1});
6: Đánh giá các điều kiện phép chiếu mạnh và mối tương quan tích cực cho việc phát hiện mối tương quan
nhiệm vụ từng lớp để xác định Reg^t_{l,1}, Reg^t_{l,2} và Reg^t_{l,3};
7: for k=1, 2,... do
8: Cập nhật mô hình và các ma trận tỷ lệ bằng cách giải Công thức (3);
9: for nhiệm vụ j < t và j∈Reg^t_{l,3} do
10: if ⟨∇L_j(w^j_l),∇L_t(w_{l,k})⟩ < λ_2||∇L_j(w^j_l)||||∇L_t(w_{l,k})|| then
11: Hạ cấp nhiệm vụ j xuống Reg^t_{l,2};
12: end if
13: end for
14: end for
15: Lưu trữ gradient ∇L_t(w_t) trong bộ nhớ nhiệm vụ;
16: Trích xuất các cơ sở {B^t_l} dựa trên SVD sử dụng mô hình đã học w_t;
17: end for

5 Thực nghiệm

Tập dữ liệu. Chúng tôi đánh giá hiệu suất của CUBER trên bốn tiêu chuẩn CL tiêu chuẩn. (1) Permuted
MNIST: một biến thể của tập dữ liệu MNIST [14] trong đó các hoán vị ngẫu nhiên được áp dụng cho các
pixel đầu vào. Theo [19,25], chúng tôi chia tập dữ liệu thành 10 nhiệm vụ với các hoán vị khác nhau và
mỗi nhiệm vụ bao gồm 10 lớp. (2) Split CIFAR-100: chúng tôi chia tập dữ liệu CIFAR-100 [13] thành 10
nhiệm vụ khác nhau, trong đó mỗi nhiệm vụ là một bài toán phân loại đa lớp 10-way. (3) 5-Datasets: chúng
tôi xem xét một chuỗi 5 tập dữ liệu, tức là CIFAR-10, MNIST, SVHN [21], not-MNIST[2], Fashion MNIST
[28], và bài toán phân loại trên mỗi tập dữ liệu là một nhiệm vụ. (4) Split MiniImageNet: chúng tôi chia tập
dữ liệu MiniImageNet [27] thành 20 nhiệm vụ, trong đó mỗi nhiệm vụ bao gồm 5 lớp.

Đường cơ sở. Trong công trình này, chúng tôi so sánh CUBER với các đường cơ sở sau đây trên các tiêu
chuẩn đã đề cập ở trên. (1) EWC [12]: một phương pháp dựa trên chính quy hóa tận dụng ma trận Fisher
Information để đánh giá tầm quan trọng của trọng số; (2) HAT [26]: học một mặt nạ chú ý cứng để bảo toàn
kiến thức của nhiệm vụ cũ; (3) Orthogonal Weight Modulation (OWM) [32]: học một ma trận chiếu để chiếu
gradient của nhiệm vụ mới lên hướng trực giao của không gian con đầu vào của các nhiệm vụ cũ; (4) Gradient
Projection Memory (GPM) [25]: lưu trữ các cơ sở của không gian con đầu vào của các nhiệm vụ cũ và sau
đó cập nhật mô hình với phép chiếu gradient trực giao với không gian con bao trùm bởi các cơ sở này; (5)
TRGP [17]: đề xuất một phép chiếu trọng số có tỷ lệ để tạo điều kiện cho chuyển giao kiến thức thuận từ các
nhiệm vụ cũ liên quan đến nhiệm vụ mới trong khi cập nhật mô hình dựa trên phép chiếu gradient trực giao,
điều này chứng minh hiệu suất tối tân cho mạng có dung lượng cố định; (6) Averaged GEM (A-GEM) [3]:
ràng buộc việc học nhiệm vụ mới với gradient được tính bằng dữ liệu đã lưu trữ của các nhiệm vụ cũ; (7)
Experience Replay with Reservoir sample (ER_Res) [4]: sử dụng một bộ nhớ epiosodic nhỏ để lưu trữ các
mẫu nhiệm vụ cũ để giải quyết việc quên; (8) Multitask: học chung tất cả các nhiệm vụ một lần với một mạng
duy nhất sử dụng tất cả các tập dữ liệu, điều này thường phục vụ như một giới hạn trên hiệu suất trong CL [25].

Chi tiết mạng và huấn luyện. Đối với một tập dữ liệu cho trước, chúng tôi nghiên cứu tất cả các phương
pháp CL sử dụng cùng kiến trúc mạng. Cụ thể hơn, đối với Permuted MNIST, chúng tôi xem xét một mạng
kết nối đầy đủ 3 lớp bao gồm 2 lớp ẩn với 100 đơn vị. Và chúng tôi huấn luyện mạng trong 5 epoch với
kích thước batch 10 cho mỗi nhiệm vụ. Đối với Split CIFAR-100, chúng tôi sử dụng một phiên bản AlexNet
5 lớp bằng cách theo [25,17]. Khi học mỗi nhiệm vụ, chúng tôi huấn luyện mạng trong tối đa 200 epoch
với việc kết thúc sớm dựa trên mất mát validation, và sử dụng kích thước batch 64. Đối với 5-Datasets,
chúng tôi sử dụng một ResNet-18 giảm [19] và theo cùng chiến lược huấn luyện như trong Split CIFAR-100.
Đối với Split MiniImageNet, một ResNet-18 giảm cũng được sử dụng, và chúng tôi huấn luyện mạng trong
tối đa 100 epoch với việc kết thúc sớm. Kích thước batch là 64. Tương tự như [17], chúng tôi chọn tối đa
hai nhiệm vụ để ở trong Chế độ 2 và 3 cho mỗi lớp với chuẩn phép chiếu gradient lớn nhất, để giảm độ
nhạy cảm hiệu suất về việc chọn λ_1. Trong các thực nghiệm, chúng tôi đặt λ_1 = 0.5.

Để đánh giá hiệu suất học tập, chúng tôi xem xét hai chỉ số sau đây, tức là độ chính xác (ACC) đo độ chính
xác cuối cùng trung bình trên tất cả các nhiệm vụ, và chuyển giao ngược (BWT) đo sự thay đổi độ chính
xác trung bình của mỗi nhiệm vụ sau khi học các nhiệm vụ mới:
ACC = (1/T)∑^T_{i=1}A_{T,i}; BWT = (1/(T-1))∑^{T-1}_{i=1}(A_{T,i}−A_{i,i})
trong đó A_{i,j} biểu diễn độ chính xác kiểm tra của nhiệm vụ j sau khi học nhiệm vụ i.

5.1 Kết quả chính

Như được hiển thị trong Bảng 1, CUBER chứng minh hiệu suất BWT tốt nhất trên tất cả các tập dữ liệu
so với các đường cơ sở. Cụ thể, BWT tích cực có thể đạt được bởi CUBER trên Split CIFAR-100 và Split
MiniImageNet, điều này chưa được đạt được bởi các công trình trước đây trong mạng có dung lượng cố định
mà không có tái diễn dữ liệu. Đối với 5-Dataset, vì các nhiệm vụ trong đó ít liên quan đến nhau như trong
GPM [25], chúng tôi không kỳ vọng nhiều chuyển giao kiến thức qua các nhiệm vụ (nhưng chuyển giao kiến
thức vẫn tồn tại về mặt các đặc trưng từng lớp), và không có việc quên trong CUBER. Đạt được zero-forgetting
rất khó khăn cho Permuted MNIST, bởi vì tất cả các nhiệm vụ chia sẻ một lớp đầu ra và không có định danh
nhiệm vụ trong quá trình kiểm tra (domain-incremental) [25]. Tuy nhiên, ngay cả trong trường hợp này CUBER
vẫn đạt được BWT tốt nhất, tức là gần như không quên, trong số tất cả các phương pháp. Rõ ràng, hiệu suất
mạnh trên BWT chỉ ra rằng CUBER có thể hiệu quả tạo điều kiện cho chuyển giao kiến thức ngược bằng
cách khôn ngoan sửa đổi mô hình đã học của các nhiệm vụ cũ.

Được lợi từ hiệu suất vượt trội trên chuyển giao kiến thức ngược, CUBER cũng đạt được hiệu suất tốt nhất
hoặc tương đương trên độ chính xác trung bình. Cụ thể hơn, CUBER cải thiện khoảng 1% trong ACC so với
kết quả tốt nhất trước đó trên Split CIFAR-100, Split MiniImageNet và Permuted MNIST, trong khi cho thấy
hiệu suất tương đương với phương pháp tối tân TRGP ngay cả trên 5-datasets nơi các nhiệm vụ ít tương quan
hơn. Hơn nữa, CUBER hoạt động tốt hơn Multitask trên cả 5-Dataset và Permuted MNIST, điều này ngụ ý
tầm quan trọng của việc nghiên cứu chuyển giao kiến thức trong CL: Cả TRGP và CUBER đều vượt trội
Multitask trên 5-Dataset do phép chiếu trọng số có tỷ lệ để tạo điều kiện cho chuyển giao kiến thức thuận,
trong khi bằng cách tạo điều kiện cho chuyển giao kiến thức ngược CUBER trở thành phương pháp duy nhất
vượt trội Multitask trên Permuted MNIST.

Bảng 1: ACC và BWT với các giá trị độ lệch chuẩn trên 5 lần chạy khác nhau trên các tập dữ liệu khác nhau.
Ở đây đối với Split CIFAR-100, Split MiniImageNet và 5-Dataset chúng tôi sử dụng mạng multi-head, trong
khi mạng single-head được sử dụng cho Permuted MNIST. Hơn nữa, λ_2 = 0.0.

[THIS IS TABLE: A comparison table showing ACC(%) and BWT(%) results for different methods across multiple datasets]

5.2 Nghiên cứu loại bỏ

Bảng 2: So sánh giữa CUBER và TRGP trong OL-CIFAR100. Nhiệm vụ cũ được chọn (*) trong (b) biểu
diễn nhiệm vụ cũ có số lượng lớp lớn nhất trong Chế độ 3 của nhiệm vụ mới.

[THIS IS TABLE: Two sub-tables showing (a) comparison of ACC and BWT between CUBER and TRGP, and (b) BWT-S of selected old tasks]

Chuyển giao kiến thức ngược. Giá trị của chuyển giao kiến thức ngược chỉ ra sự cải thiện độ chính xác
trung bình cho mỗi nhiệm vụ cũ sau khi học tất cả các nhiệm vụ, điều này ngụ ý rằng việc học nhiệm vụ mới
cung cấp thông tin hữu ích bổ sung để học các đặc trưng của các nhiệm vụ cũ tương tự. Một cách trực quan,
giá trị này nên phụ thuộc vào độ tương tự nhiệm vụ trong CL. Để hiểu rõ hơn ưu thế của CUBER

8

--- TRANG 9 ---
về mặt chuyển giao kiến thức ngược, chúng tôi tiếp tục xem xét một thiết lập đặc biệt bao gồm một chuỗi
các nhiệm vụ tương tự và không tương tự. Cụ thể, khác với Split-CIFAR100 nơi không có nhiệm vụ nào có
các lớp chồng chéo, chúng tôi chia 50 lớp đầu tiên trong CIFAR100 thành 7 nhiệm vụ (OL-CIFAR100):
Nhiệm vụ 0-6 chứa các lớp 0-9, 5-14, 10-19, 20-29, 25-34, 30-39, 40-49, tương ứng. Chúng tôi so sánh
hiệu suất của CUBER với TRGP trong Bảng 2. Như được hiển thị trong Bảng 2a, CUBER rõ ràng vượt
trội TRGP trong cả ACC và BWT. Cụ thể, CUBER có BWT tích cực là 0.28%, trong khi TRGP gặp phải
việc quên. Chúng tôi tiếp tục phân tích việc lựa chọn nhiệm vụ trong Bảng 2b, trong đó "nhiệm vụ cũ được
chọn" đề cập đến nhiệm vụ có số lượng lớp lớn nhất trong Chế độ 3 của nhiệm vụ mới. Ví dụ, theo thiết
lập của OL-CIFAR100, nhiệm vụ cũ được chọn cho Nhiệm vụ 4 nên là Nhiệm vụ 3 với xác suất cao vì
chúng có các lớp chồng chéo. Và chúng tôi ký hiệu một chỉ số mới, tức là BWT-S, để đánh giá chuyển
giao kiến thức ngược của nhiệm vụ cũ được chọn sau khi học nhiệm vụ mới, tức là BWT-S=A_{t,j}−A_{t-1,j}
trong đó j là "nhiệm vụ cũ được chọn" của nhiệm vụ mới t. Như được hiển thị trong Bảng 2b, CUBER đúng
đắn xác định các nhiệm vụ tương quan cho hầu hết các nhiệm vụ mới ngoại trừ Nhiệm vụ 5. Đây là một kết
quả hợp lý bởi vì việc phát hiện mối tương quan nhiệm vụ dựa trên gradient mô hình ban đầu có nhiễu nói
chung, và do đó chỉ phục vụ như một ước lượng của mối tương quan thực bên dưới. Tuy nhiên, việc đặc
trưng hóa mối tương quan nhiệm vụ được ước lượng như vậy thực sự đủ để hiệu quả tạo điều kiện cho
chuyển giao kiến thức ngược, như được xác nhận bởi BWT-S tích cực và hiệu suất vượt trội của CUBER.

Chuyển giao kiến thức thuận. Chúng tôi cũng đánh giá chuyển giao kiến thức thuận (FWT) trong CUBER,
so sánh với hai phương pháp đường cơ sở tốt nhất GPM và TRGP. Ở đây FWT đo khoảng cách giữa A_{i,i}
và độ chính xác của việc học nhiệm vụ i chỉ từ đầu. Để đơn giản, chúng tôi sử dụng FWT của GPM như một
đường cơ sở và đánh giá các cải thiện của TRGP và CUBER so với GPM. Có thể thấy từ Bảng 3 rằng CUBER
hoạt động thậm chí tốt hơn TRGP mặc dù CUBER theo cùng chiến lược, tức là phép chiếu trọng số có tỷ lệ,
để tạo điều kiện cho chuyển giao kiến thức thuận, và đạt được FWT tốt nhất trong số ba phương pháp trong
hầu hết các trường hợp. Lý do đằng sau là việc đặc trưng hóa Chế độ 3 trong CUBER không chỉ cho phép
sửa đổi mô hình đã học của các nhiệm vụ cũ để thúc đẩy chuyển giao kiến thức ngược, mà còn nới lỏng ràng
buộc trên việc cập nhật gradient cho nhiệm vụ mới, tức là mô hình giờ có thể được cập nhật trong không
gian con của các nhiệm vụ cũ được chọn để học nhiệm vụ mới. Việc nới lỏng ràng buộc gradient này do đó
dẫn đến việc học mô hình tốt hơn của nhiệm vụ mới.

Bảng 3: So sánh FWT giữa GPM, TRGP và CUBER. Giá trị cho GPM là không bởi vì chúng tôi coi GPM
như đường cơ sở và xem xét cải thiện FWT tương đối so với GPM.

[THIS IS TABLE: Shows comparison of FWT values between GPM, TRGP and CUBER across different datasets]

Tác động của λ_2. Rõ ràng rằng việc lựa chọn Chế độ 3 từng lớp phụ thuộc vào giá trị của ngưỡng λ_2.
Để hiển thị tác động của λ_2, chúng tôi đánh giá hiệu suất học tập dưới các giá trị khác nhau của λ_2 trong
Split CIFAR-100. Như được hiển thị trong Bảng 4, hiệu suất trên ACC là tương đương cho cả ba trường hợp
và BWT giảm khi giá trị của λ_2 tăng. Một cách trực quan, λ_2 đặc trưng hóa tính bảo thủ trong việc chọn
các nhiệm vụ vào Chế độ 3 và sửa đổi mô hình của các nhiệm vụ được chọn. Cụ thể, với λ_2 lớn hơn, chúng
tôi chỉ xem xét chuyển giao kiến thức ngược đến các nhiệm vụ cũ có mối tương quan mạnh với nhiệm vụ
mới, và chỉ sửa đổi nhẹ mô hình đã học của các nhiệm vụ được chọn này, bởi vì điều kiện Công thức (2)
có thể nhanh chóng bị vi phạm với việc cập nhật mô hình và CUBER sẽ ngừng thay đổi mô hình đã học của
các nhiệm vụ được chọn.

Bảng 4: Tác động của λ_2 lên hiệu suất trong Split CIFAR-100.

[THIS IS TABLE: Shows impact of λ_2 values on ACC and BWT performance]

6 Kết luận

Trong công trình này, chúng tôi nghiên cứu vấn đề chuyển giao kiến thức ngược trong CL. Khác với hầu hết
các phương pháp hiện tại thường đóng băng mô hình đã học của các nhiệm vụ cũ để giảm thiểu việc quên
thảm khốc, nghiên cứu này tìm cách cẩn thận sửa đổi mô hình đã học để tạo điều kiện cho chuyển giao kiến
thức ngược từ nhiệm vụ mới đến các nhiệm vụ cũ. Để làm điều này, chúng tôi đầu tiên giới thiệu các khái
niệm phép chiếu mạnh và mối tương quan tích cực để đặc trưng hóa mối tương quan nhiệm vụ, và cho thấy
rằng khi các gradient nhiệm vụ được căn chỉnh đủ trong không gian con nhiệm vụ cũ, việc thay đổi mô hình
thích hợp cho các nhiệm vụ cũ có thể có lợi cho CL và dẫn đến chuyển giao kiến thức ngược tốt hơn. Dựa
trên phân tích lý thuyết, chúng tôi tiếp theo đề xuất CUBER để cẩn thận học mô hình cho nhiệm vụ mới,
điều này sẽ cẩn thận cập nhật mô hình đã học của các nhiệm vụ cũ có mối tương quan tích cực với nhiệm
vụ mới. Như được hiển thị trong kết quả thực nghiệm, CUBER có thể thành công cải thiện chuyển giao
kiến thức ngược trên các tiêu chuẩn CL tiêu chuẩn so với các đường cơ sở liên quan.

Tác động và hạn chế. Chiến lược chủ đạo ngày nay để giải quyết việc quên là giảm thiểu sự can thiệp đến
các nhiệm vụ cũ và tránh việc thay đổi mô hình đã học, điều này tuy nhiên có thể mâu thuẫn với mục tiêu
của CL, theo nghĩa là chuyển giao kiến thức ngược từ nhiệm vụ mới đến các nhiệm vụ cũ có thể bị hạn chế
mà không sửa đổi mô hình đã học. Trong công trình này, chúng tôi vượt ra ngoài chiến lược này và làm
sáng tỏ mối quan hệ giữa chuyển giao kiến thức ngược và sửa đổi mô hình, bằng cách đặc trưng hóa các
mối tương quan nhiệm vụ với phép chiếu gradient. Chúng tôi hy vọng rằng công trình này sẽ phục vụ như
các bước ban đầu và thúc đẩy nghiên cứu sâu hơn trong cộng đồng CL về vấn đề quan trọng nhưng ít được
khám phá, tức là làm thế nào để thiết kế các thuật toán có thể cung cấp các phương pháp điều trị mục tiêu
để đạt được chuyển giao kiến thức ngược.

Tuy nhiên, CUBER cũng đi kèm với một số hạn chế. Như trong các phương pháp CL dựa trên phép chiếu
trực giao gần đây, CUBER trích xuất các cơ sở của các không gian con nhiệm vụ dựa trên SVD, điều này
có thể dẫn đến chi phí tính toán cao cho dữ liệu có chiều cao. Làm thế nào để giảm độ phức tạp là một
hướng thú vị. Một hạn chế khác là chúng tôi giả định rằng các ranh giới nhiệm vụ rõ ràng tồn tại giữa các
nhiệm vụ khác nhau. Trong công việc tương lai, việc mở rộng CUBER đến các thiết lập CL tổng quát hơn
là rất thú vị.

Lời cảm ơn
Công trình của S. Lin và J. Zhang được hỗ trợ một phần bởi U.S. National Science Foundation Grants
CNS-2203239, CNS-2203412, RINGS-2148253, và CCSS-2203238. Công trình của L. Yang và D. Fan được
hỗ trợ một phần bởi U.S. National Science Foundation Grants No. 1931871 và No. 2144751.

Tài liệu tham khảo
[1]Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, và Tinne Tuytelaars. Memory
aware synapses: Learning what (not) to forget. Trong Proceedings of the European Conference on Computer
Vision (ECCV), trang 139–154, 2018.

[2]Yaroslav Bulatov. Notmnist dataset. Google (Books/OCR), Tech. Rep.[Online]. Available: http://yaroslavvb.
blogspot. it/2011/09/notmnist-dataset. html, 2, 2011.

[3]Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. Efficient lifelong
learning with a-gem. arXiv preprint arXiv:1812.00420, 2018.

[4]Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K Dokania,
Philip HS Torr, và M Ranzato. Continual learning with tiny episodic memories. 2019.

[5]Zhiyuan Chen và Bing Liu. Lifelong machine learning. Synthesis Lectures on Artificial Intelligence and
Machine Learning, 12(3):1–207, 2018.

[6]Mehrdad Farajtabar, Navid Azizan, Alex Mott, và Ang Li. Orthogonal gradient descent for continual
learning. Trong International Conference on Artificial Intelligence and Statistics, trang 3762–3773. PMLR,
2020.

[7]Chrisantha Fernando, Dylan Banarse, Charles Blundell, Yori Zwols, David Ha, Andrei A Rusu, Alexander
Pritzel, và Daan Wierstra. Pathnet: Evolution channels gradient descent in super neural networks. arXiv
preprint arXiv:1701.08734, 2017.

[8]Yunhui Guo, Mingrui Liu, Tianbao Yang, và Tajana Rosing. Improved schemes for episodic memory based
lifelong learning algorithm. Trong Conference on Neural Information Processing Systems, 2020.

[9]Steven CY Hung, Cheng-Hao Tu, Cheng-En Wu, Chien-Hung Chen, Yi-Ming Chan, và Chu-Song Chen.
Compacting, picking and growing for unforgetting continual learning. arXiv preprint arXiv:1910.06562, 2019.

10

--- TRANG 11 ---
[10] Ta-Chu Kao, Kristopher Jensen, Gido van de Ven, Alberto Bernacchia, và Guillaume Hennequin. Natural
continual learning: success is a journey, not (just) a destination. Advances in Neural Information Processing
Systems, 34:28067–28079, 2021.

[11] Zixuan Ke, Bing Liu, và Xingchang Huang. Continual learning of a mixed sequence of similar and dissimilar
tasks. Advances in Neural Information Processing Systems, 33:18493–18504, 2020.

[12] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu,
Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic
forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521–3526, 2017.

[13] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.

[14] Yann LeCun. The mnist database of handwritten digits. http://yann. lecun. com/exdb/mnist/, 1998.

[15] Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, và Byoung-Tak Zhang. Overcoming catastrophic
forgetting by incremental moment matching. arXiv preprint arXiv:1703.08475, 2017.

[16] Zhizhong Li và Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and
machine intelligence, 40(12):2935–2947, 2017.

[17] Sen Lin, Li Yang, Deliang Fan, và Junshan Zhang. Trgp: Trust region gradient projection for continual
learning. Tenth International Conference on Learning Representations, ICLR 2022, 2022.

[18] Hao Liu và Huaping Liu. Continual learning with recursive gradient optimization. arXiv preprint
arXiv:2201.12522, 2022.

[19] David Lopez-Paz và Marc'Aurelio Ranzato. Gradient episodic memory for continual learning. Advances
in neural information processing systems, 30:6467–6476, 2017.

[20] Michael McCloskey và Neal J Cohen. Catastrophic interference in connectionist networks: The sequential
learning problem. Trong Psychology of learning and motivation, tập 24, trang 109–165. Elsevier, 1989.

[21] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, và Andrew Y Ng. Reading digits in
natural images with unsupervised feature learning. 2011.

[22] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, và Gerald Tesauro.
Learning to learn without forgetting by maximizing transfer and minimizing interference. arXiv preprint
arXiv:1810.11910, 2018.

[23] Mark Bishop Ring et al. Continual learning in reinforcement environments. 1994.

[24] Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray
Kavukcuoglu, Razvan Pascanu, và Raia Hadsell. Progressive neural networks. arXiv preprint arXiv:1606.04671,
2016.

[25] Gobinda Saha, Isha Garg, và Kaushik Roy. Gradient projection memory for continual learning. Trong
International Conference on Learning Representations, 2021.

[26] Joan Serra, Didac Suris, Marius Miron, và Alexandros Karatzoglou. Overcoming catastrophic forgetting
with hard attention to the task. Trong International Conference on Machine Learning, trang 4548–4557.
PMLR, 2018.

[27] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one shot
learning. Advances in neural information processing systems, 29, 2016.

[28] Han Xiao, Kashif Rasul, và Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.

[29] Li Yang, Sen Lin, Junshan Zhang, và Deliang Fan. Grown: Grow only when necessary for continual
learning. arXiv preprint arXiv:2110.00908, 2021.

[30] Jaehong Yoon, Saehoon Kim, Eunho Yang, và Sung Ju Hwang. Scalable and order-robust continual
learning with additive parameter decomposition. Trong Eighth International Conference on Learning
Representations, ICLR 2020. ICLR, 2020.

11

--- TRANG 12 ---
[31] Jaehong Yoon, Eunho Yang, Jeongtae Lee, và Sung Ju Hwang. Lifelong learning with dynamically
expandable networks. arXiv preprint arXiv:1708.01547, 2017.

[32] Guanxiong Zeng, Yang Chen, Bo Cui, và Shan Yu. Continual learning of context-dependent processing
in neural networks. Nature Machine Intelligence, 1(8):364–372, 2019.

[33] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, và Oriol Vinyals. Understanding deep
learning (still) requires rethinking generalization. Communications of the ACM, 64(3):107–115, 2021.

Danh sách kiểm tra
Danh sách kiểm tra theo sau tài liệu tham khảo. Vui lòng đọc hướng dẫn danh sách kiểm tra cẩn thận
để biết thông tin về cách trả lời những câu hỏi này. Đối với mỗi câu hỏi, thay đổi mặc định [TODO]
thành [Yes], [No], hoặc [N/A]. Bạn được khuyến khích mạnh mẽ bao gồm một lời biện minh cho câu
trả lời của bạn, bằng cách tham chiếu phần thích hợp của bài báo của bạn hoặc cung cấp một mô tả
ngắn gọn. Ví dụ:

• Bạn có bao gồm giấy phép cho mã và tập dữ liệu không? [Yes] Xem Phần ??.
• Bạn có bao gồm giấy phép cho mã và tập dữ liệu không? [No] Mã và dữ liệu là độc quyền.
• Bạn có bao gồm giấy phép cho mã và tập dữ liệu không? [N/A]

Vui lòng không sửa đổi các câu hỏi và chỉ sử dụng các macro được cung cấp cho câu trả lời của bạn.
Lưu ý rằng phần Danh sách kiểm tra không tính vào giới hạn trang. Trong bài báo của bạn, vui lòng
xóa khối hướng dẫn này và chỉ giữ lại tiêu đề phần Danh sách kiểm tra ở trên cùng với các câu hỏi/
câu trả lời bên dưới.

1. Đối với tất cả các tác giả...
(a) Các tuyên bố chính được đưa ra trong tóm tắt và giới thiệu có phản ánh chính xác các đóng góp
và phạm vi của bài báo không? [Yes]
(b) Bạn có mô tả các hạn chế của công trình không? [Yes] Xem Phần 6.
(c) Bạn có thảo luận về bất kỳ tác động tiêu cực tiềm năng nào đến xã hội của công trình không?
[Yes] Xem Phần 6.
(d) Bạn có đọc hướng dẫn đánh giá đạo đức và đảm bảo rằng bài báo của bạn tuân thủ chúng không?
[Yes]

2. Nếu bạn bao gồm kết quả lý thuyết...
(a) Bạn có nêu đầy đủ các giả định của tất cả kết quả lý thuyết không? [Yes] Xem Định lý 1 và 2.
(b) Bạn có bao gồm chứng minh đầy đủ của tất cả kết quả lý thuyết không? [Yes] Xem phụ lục.

3. Nếu bạn chạy thực nghiệm...
(a) Bạn có bao gồm mã, dữ liệu và hướng dẫn cần thiết để tái tạo các kết quả thực nghiệm chính
không (trong tài liệu bổ sung hoặc dưới dạng URL)? [Yes] Chúng tôi bao gồm mã trong tài liệu
bổ sung.
(b) Bạn có chỉ định tất cả các chi tiết huấn luyện không (ví dụ: chia dữ liệu, siêu tham số, cách
chúng được chọn)? [Yes] Xem phần 5.
(c) Bạn có báo cáo thanh lỗi không (ví dụ: đối với hạt giống ngẫu nhiên sau khi chạy thực nghiệm
nhiều lần)? [Yes] Xem phần 5.
(d) Bạn có bao gồm tổng lượng tính toán và loại tài nguyên được sử dụng không (ví dụ: loại GPU,
cụm nội bộ, hoặc nhà cung cấp đám mây)? [Yes] Xem phụ lục.

4. Nếu bạn đang sử dụng tài sản hiện có (ví dụ: mã, dữ liệu, mô hình) hoặc tuyển chọn/phát hành
tài sản mới...
(a) Nếu công trình của bạn sử dụng tài sản hiện có, bạn có trích dẫn người tạo ra không? [Yes]
Xem phần 5.
(b) Bạn có đề cập đến giấy phép của tài sản không? [Yes] Xem phụ lục.
(c) Bạn có bao gồm bất kỳ tài sản mới nào trong tài liệu bổ sung hoặc dưới dạng URL không?
[Yes] Chúng tôi bao gồm mã trong tài liệu bổ sung.
(d) Bạn có thảo luận về việc liệu và làm thế nào để có được sự đồng ý từ những người có dữ liệu
mà bạn đang sử dụng/tuyển chọn không? [N/A]

12

--- TRANG 13 ---
(e) Bạn có thảo luận về việc liệu dữ liệu bạn đang sử dụng/tuyển chọn có chứa thông tin nhận dạng
cá nhân hoặc nội dung xúc phạm không? [N/A]

5. Nếu bạn sử dụng crowdsourcing hoặc tiến hành nghiên cứu với các đối tượng con người...
(a) Bạn có bao gồm toàn bộ văn bản hướng dẫn được đưa cho người tham gia và ảnh chụp màn
hình, nếu có không? [N/A]
(b) Bạn có mô tả bất kỳ rủi ro tiềm năng nào của người tham gia, với liên kết đến phê duyệt của
Hội đồng Đánh giá Thể chế (IRB), nếu có không? [N/A]
(c) Bạn có bao gồm mức lương hàng giờ ước tính trả cho người tham gia và tổng số tiền chi cho
bồi thường người tham gia không? [N/A]

13

--- TRANG 14 ---
Phụ lục

A Chứng minh của Định lý 1

Đối với hàm mất mát L smooth H/2, có thể dễ dàng chỉ ra rằng F smooth H.

(1) Đối với bất kỳ k∈[0,K], chúng ta có thể có
F(w_{k+1}) ≤ F(w_k) + ∇F(w_k)^T(w_{k+1}−w_k) + H/2||w_{k+1}−w_k||^2
= F(w_k) + α(g_1(w_k) + g_2(w_k))^T(−g_2(w_k)) + α^2H/2||g_2(w_k)||^2
= F(w_k) − α||g_2(w_k)||^2 − α⟨g_1(w_k),g_2(w_k)⟩ + α^2H/2||g_2(w_k)||^2. (4)

Đối với số hạng ⟨g_1(w_k),g_2(w_k)⟩, ta có
⟨g_1(w_k),g_2(w_k)⟩
= ⟨g_1(w_k)−g_1(w_0) + g_1(w_0),g_2(w_k)⟩
= ⟨g_1(w_k)−g_1(w_0),g_2(w_k)⟩ + ⟨g_1(w_0),g_2(w_k)⟩
= ⟨g_1(w_k)−g_1(w_0),g_2(w_k)⟩ + ⟨g_1(w_0),g_2(w_k)−g_2(w_0)⟩ + ⟨g_1(w_0),g_2(w_0)⟩. (5)

Bởi vì
2⟨g_1(w_k)−g_1(w_0),g_2(w_k)⟩ + ||g_1(w_k)−g_1(w_0)||^2 + ||g_2(w_k)||^2
= ||g_1(w_k)−g_1(w_0) + g_2(w_k)||^2 ≥ 0,

chúng ta có
⟨g_1(w_k)−g_1(w_0),g_2(w_k)⟩ ≥ −1/2||g_1(w_k)−g_1(w_0)||^2 − 1/2||g_2(w_k)||^2. (6)

Theo cùng hướng, có thể chỉ ra rằng
⟨g_1(w_0),g_2(w_k)−g_2(w_0)⟩ ≥ −1/2||g_2(w_k)−g_2(w_0)||^2 − 1/2||g_1(w_0)||^2. (7)

Kết hợp Công thức (5), Công thức (6) và Công thức (7) đưa ra một cận dưới của ⟨g_1(w_k),g_2(w_k)⟩, tức là
⟨g_1(w_k),g_2(w_k)⟩
≥ −1/2||g_1(w_k)−g_1(w_0)||^2 − 1/2||g_2(w_k)||^2
−1/2||g_2(w_k)−g_2(w_0)||^2 − 1/2||g_1(w_0)||^2 + ⟨g_1(w_0),g_2(w_0)⟩
≥ −H^2α^2/8||w_k−w_0||^2 − 1/2||g_2(w_k)||^2
−H^2α^2/8||w_k−w_0||^2 − 1/2||g_1(w_0)||^2 + ⟨g_1(w_0),g_2(w_0)⟩
= −H^2α^2/4||w_k−w_0||^2 − 1/2||g_2(w_k)||^2 − 1/2||g_1(w_0)||^2 + ⟨g_1(w_0),g_2(w_0)⟩, (8)

trong đó bất đẳng thức thứ hai đúng do tính smooth của hàm mất mát.

Dựa trên quy tắc cập nhật #2, có thể thấy rằng
w_k = w_0 − α∑_{i=0}^{k-1}g_2(w_i). (9)

Do đó, tiếp tục với Công thức (4), chúng ta có thể có
F(w_{k+1})
≤ F(w_k) − α||g_2(w_k)||^2 − α⟨g_1(w_k),g_2(w_k)⟩ + α^2H/2||g_2(w_k)||^2
≤ F(w_k) − α||g_2(w_k)||^2 + α^3H^2α^2/4||∑_{i=0}^{k-1}g_2(w_i)||^2 + α/2||g_2(w_k)||^2
+ α/2||g_1(w_0)||^2 − α⟨g_1(w_0),g_2(w_0)⟩
= F(w_k) − α(2−αH)/2||g_2(w_k)||^2 + α^3H^2α^2/4||∑_{i=0}^{k-1}g_2(w_i)||^2 + α/2||g_1(w_0)||^2 − α⟨g_1(w_0),g_2(w_0)⟩
≤ F(w_k) − α(2−αH)/2||g_2(w_k)||^2 + α^3H^2α^2/4||∑_{i=0}^{k-1}g_2(w_i)||^2 + α/2||g_1(w_0)||^2
−αλ_2||g_1(w_0)||||g_2(w_0)||,

trong đó bất đẳng thức cuối cùng dựa trên Định nghĩa 2.

Tiếp theo, có thể chỉ ra rằng
α ≤ ||g_1(w_0)||/(HBK) ⇒ ||g_1(w_0)||/(H||∑_{i=0}^{k-1}g_2(w_i)||).

Khi đó ta có
α/2||g_1(w_0)||^2 + α^3H^2α^2/4||∑_{i=0}^{k-1}g_2(w_i)||^2
≤ α/2||g_1(w_0)||^2 + α^2||g_1(w_0)||^2/(4H^2)||∑_{i=0}^{k-1}g_2(w_i)||^2H^2α^2||∑_{i=0}^{k-1}g_2(w_i)||^2
= α(2 + α^2)/4||g_1(w_0)||^2. (10)

Do đó, chúng ta có thể thu được rằng
F(w_{k+1}) ≤ F(w_k) − α(2−αH)/2||g_2(w_k)||^2 + α(2 + α^2)/4||g_1(w_0)||^2 − αλ_2||g_1(w_0)||||g_2(w_0)||
≤ F(w_k) − α(2−αH)/2||g_2(w_k)||^2
< F(w_k),

trong đó bất đẳng thức thứ hai đúng bởi vì λ_2 ≥ (2+α^2)||g_1(w_0)||/(4||g_2(w_0)||). Sự giảm đủ này của
giá trị hàm mục tiêu chỉ ra rằng F(w*) tối ưu có thể đạt được cuối cùng cho các hàm mất mát lồi.

(2) Đối với hàm mất mát L không lồi, chúng ta có thể có như sau trong Công thức (4):
F(w_{k+1}) ≤ F(w_k) − α||g_2(w_k)||^2 − α⟨g_1(w_k),g_2(w_k)⟩ + α^2H/2||g_2(w_k)||^2
(a) = F(w_k) − α||g_2(w_k)||^2 − α/2[||∇F(w_k)||^2 − ||g_1(w_k)||^2 − ||g_2(w_k)||^2] + α^2H/2||g_2(w_k)||^2
= F(w_k) − α(2−αH)/2||g_2(w_k)||^2 − α/2||∇F(w_k)||^2 + α/2||g_1(w_k)||^2
= F(w_k) − α(2−αH)/2||g_2(w_k)||^2 − α/2||∇F(w_k)||^2 + α/2||g_1(w_k)−g_1(w_0) + g_1(w_0)||^2
≤ F(w_k) − α(2−αH)/2||g_2(w_k)||^2 − α/2||∇F(w_k)||^2 + α||g_1(w_k)−g_1(w_0)||^2
+ α||g_1(w_0)||^2
(b) ≤ F(w_k) − α(2−αH)/2||g_2(w_k)||^2 − α/2||∇F(w_k)||^2 + αH^2α^3/4||∑_{i=0}^{k-1}g_2(w_i)||^2

14

--- TRANG 15 ---
+ α||g_1(w_0)||^2,

trong đó (a) là do ∇F(w_k) = g_1(w_k) + g_2(w_k), và (b) là do tính smooth của L và Công thức (9).

Do đó,
min_k ||∇F(w_k)||^2 ≤ (1/αK)∑_{k=0}^{K-1} ||∇F(w_k)||^2
≤ (2/αK)∑_{k=0}^{K-1} [F(w_k)−F(w_{k+1}) + αH^2α^3/4||∑_{i=0}^{k-1}g_2(w_i)||^2 + α||g_1(w_0)||^2]/[α(2−αH)/2||g_2(w_k)||^2]
≤ (2/αK)[F(w_0)−F(w_K)] + (αH^2α^2/α(2−αH))∑_{k=1}^{K-1}||∑_{i=0}^{k-1}g_2(w_i)||^2 + (2α||g_1(w_0)||^2)/(α(2−αH))∑_{k=0}^{K-1}||g_2(w_k)||^2
(a) ≤ (2/αK)[F(w_0)−F(w^*)] + (α^2/2)||g_1(w_0)||^2 + (2α||g_1(w_0)||^2)/(α(2−αH))∑_{k=0}^{K-1}||g_2(w_k)||^2
≤ (2/αK)[F(w_0)−F(w^*)] + (4α + α^2/2)||g_1(w_0)||^2

trong đó (a) giữ do F(w^*)≤F(w_K) và ||∑_{i=0}^{k-1}g_2(w_i)||^2 ≤ (α^2/2H^2)||g_1(w_0)||^2 dựa trên
Công thức (10).

B Chứng minh của Định lý 2

(1) Đối với Quy tắc #1, chúng ta có
w_c = w − α[g_2(w) − Proj_{S_1}(g_2(w))] = w − α\tilde{g}_2(w). (11)

Đối với Quy tắc #2, chúng ta có  
w_r = w − αg_2(w). (12)

Dựa trên tính smooth của hàm mục tiêu, chúng ta có thể có một cận trên của F(w_r):
F(w_r) ≤ F(w) − α||g_2(w)||^2 − α⟨g_1(w),g_2(w)⟩ + (α^2H/2)||g_2(w)||^2, (13)

và một cận dưới của F(w_c):
F(w_c) ≥ F(w) + ⟨∇F(w),w_c−w⟩ − (H/2)||w_c−w||^2. (14)

Kết hợp Công thức (13) và Công thức (14), có thể chỉ ra rằng
F(w_r) ≤ F(w_c) + ⟨∇F(w),w_c−w⟩ − (H/2)||w_c−w||^2 − α||g_2(w)||^2 − α⟨g_1(w),g_2(w)⟩ + (α^2H/2)||g_2(w)||^2

= F(w_c) − ⟨g_1(w) + g_2(w),α\tilde{g}_2(w)⟩ − (H/2)||\tilde{g}_2(w)||^2 − α||g_2(w)||^2 − α⟨g_1(w),g_2(w)⟩ + (α^2H/2)||g_2(w)||^2

= F(w_c) + α⟨g_1(w),\tilde{g}_2(w)⟩ + α⟨g_2(w),\tilde{g}_2(w)⟩ + (α^2H/2)||\tilde{g}_2(w)||^2 − α||g_2(w)||^2 − α⟨g_1(w),g_2(w)⟩ + (α^2H/2)||g_2(w)||^2

= F(w_c) + α||\tilde{g}_2(w)||^2 + (α^2H/2)||\tilde{g}_2(w)||^2 − α||g_2(w)||^2 − α⟨g_1(w),g_2(w)⟩ + (α^2H/2)||g_2(w)||^2 (15)

trong đó đẳng thức cuối cùng đúng bởi vì cả g_1(w) và Proj_1(g_2(w)) đều trực giao với \tilde{g}_2(w).

Đối với số hạng ⟨g_1(w),g_2(w)⟩, dựa trên Công thức (8), ta có
⟨g_1(w),g_2(w)⟩
≥ −(H^2α^2/4)||w−w_0||^2 − (1/2)||g_2(w)||^2 − (1/2)||g_1(w_0)||^2 + ⟨g_1(w_0),g_2(w_0)⟩
≥ −(H^2α^2/4)||w−w_0||^2 − (1/2)||g_2(w)||^2 − (1/2)||g_1(w_0)||^2 + λ_2||g_1(w_0)||||g_2(w_0)||. (16)

Giả sử rằng w là việc cập nhật mô hình tại lần lặp thứ n trong đó n≤K. Đối với Quy tắc #1,
||w−w_0||^2 = α^2||∑_{i=0}^{n}\tilde{g}_2(w_i)||^2
≤ (α^2||g_1(w_0)||^2)/(H^2B^2K^2)n∑_{i=0}^{n}||\tilde{g}_2(w_i)||^2
≤ (α^2n^2||g_1(w_0)||^2)/(H^2K^2)
≤ (α^2||g_1(w_0)||^2)/H^2.

Tương tự đối với Quy tắc #2, chúng ta cũng có thể thu được rằng
||w−w_0||^2 ≤ (α^2||g_1(w_0)||^2)/H^2.

Do đó, tiếp tục với Công thức (16), chúng ta có thể có
⟨g_1(w),g_2(w)⟩ ≥ −(α^2 + α^2)/4||g_1(w_0)||^2 + λ_2||g_1(w_0)||||g_2(w_0)|| − (1/2)||g_2(w)||^2
≥ −(1/2)||g_2(w)||^2

trong đó bất đẳng thức cuối cùng giữ bởi vì λ_2 ≥ (2+α^2)||g_1(w_0)||/(4||g_2(w_0)||).

Dựa trên Công thức (15), ta có
F(w_r) ≤ F(w_c) + α||\tilde{g}_2(w)||^2 + (α^2H/2)||\tilde{g}_2(w)||^2 − α||g_2(w)||^2 + (α/2)||g_2(w)||^2 + (α^2H/2)||g_2(w)||^2
= F(w_c) − α(2−αH)/2||g_2(w)||^2 + α(1+αH/2)||\tilde{g}_2(w)||^2
(a) ≤ F(w_c) − α(2−αH)/2||g_2(w)||^2 + α(1−λ_1^2)(1+αH/2)||g_2(w)||^2
(b) ≤ F(w_c)

trong đó (a) giữ bởi vì
||g_2(w)||^2 = ||Proj_1(g_2(w)) + \tilde{g}_2(w)||^2
= ||Proj_1(g_2(w))||^2 + ||\tilde{g}_2(w)||^2
≥ λ_1^2||g_2(w)||^2 + ||\tilde{g}_2(w)||^2,

và (b) đúng bởi vì λ_1 ≥ √(1+α^2H^2)/(2+αH).

17

--- TRANG 16 ---
(2) Có thể thấy rằng
L_1(w_k) ≤ L_1(w_0) + ⟨g_1(w_0),w_k−w_0⟩ + (H/4)||w_k−w_0||^2
= L_1(w_0) + ⟨g_1(w_0),−α∑_{i=0}^{k-1}g_2(w_i)⟩ + (α^2H/4)||∑_{i=0}^{k-1}g_2(w_i)||^2
= L_1(w_0) − α∑_{i=0}^{k-1}⟨g_1(w_0),g_2(w_i)⟩ + (α^2H/4)||∑_{i=0}^{k-1}g_2(w_i)||^2
≤ L_1(w_0) − αλ_2||g_1(w_0)||[∑_{i=0}^{k-1}||g_2(w_i)||] + (α^2Hk/4)||∑_{i=0}^{k-1}g_2(w_i)||^2.

Đối với α ≤ λ_2||g_1(w_0)||/(HBk^{1.5}), chúng ta có thể có
(Hk/4)||∑_{i=0}^{k-1}g_2(w_i)||^2 ≤ (λ_2||g_1(w_0)||)/(B√k)||∑_{i=0}^{k-1}g_2(w_i)||^2
= (λ_2||g_1(w_0)||∑_{i=0}^{k-1}||g_2(w_i)||^2)/(2√∑_{i=0}^{k-1}||g_2(w_i)||^2)
≤ (λ_2||g_1(w_0)||)/(2√∑_{i=0}^{k-1}||g_2(w_i)||^2)
≤ (λ_2||g_1(w_0)||[∑_{i=0}^{k-1}||g_2(w_i)||])/2

Do đó, ta có L_1(w_k) ≤ L_1(w_0).

C Thêm kết quả thực nghiệm

Chúng tôi cũng nghiên cứu các đường cong tiến hóa độ chính xác cho mỗi nhiệm vụ trong quá trình học 
liên tục trong Hình 3. Để chứng minh rõ ràng các hành vi tiến hóa độ chính xác, chúng tôi có chọn lọc
nghiên cứu nhiệm vụ 2, nhiệm vụ 4, nhiệm vụ 6 trong PMNIST [14], CIFAR-100 Split [13], MiniImageNet
[27], và nhiệm vụ 1, nhiệm vụ 2, nhiệm vụ 3 trong 5-Dataset, bằng cách so sánh hiệu suất giữa CUBER,
TRGP và GPM. Như được hiển thị trong Hình 3, CUBER (đường cong màu đỏ) có hiệu suất ổn định nhất
trên hầu hết các nhiệm vụ, như một kết quả của chuyển giao kiến thức ngược tốt hơn được tạo điều kiện
bằng cách có chọn lọc cập nhật mô hình đã học của các nhiệm vụ cũ. Tất cả các thực nghiệm được tiến
hành bằng cách sử dụng một GPU Nvidia Quadro RTX 5000.

D Thêm chi tiết thực nghiệm

D.1 Chi tiết mạng

Mạng kết nối đầy đủ 3 lớp: Mạng bao gồm 3 lớp kết nối đầy đủ với 784, 100, 100 đơn vị tương ứng.
Chúng tôi sử dụng lớp kích hoạt ReLU sau hai lớp đầu tiên.

AlexNet 5 lớp: Theo [25,17], AlexNet được sử dụng cho các thực nghiệm trên Split CIFAR-100 bao gồm
3 lớp tích chập và 2 lớp kết nối đầy đủ, trong đó batch normalization được thêm vào mỗi lớp ngoại trừ
lớp phân loại. Các lớp tích chập có 64, 128 và 256 bộ lọc với kích thước kernel 4×4, 3×3 và 2×2, tương
ứng, và mỗi lớp kết nối đầy đủ chứa 2048 đơn vị. Chúng tôi sử dụng hàm kích hoạt ReLU và max-pooling
2×2 sau các lớp tích chập, và dropout 0.2 cho hai lớp đầu tiên và 0.5 cho các lớp khác.

ResNet-18 giảm: Theo [19,25], chúng tôi sử dụng ResNet-18 giảm cho các thực nghiệm trên cả 5-Datasets
và miniImageNet. Nó bao gồm 17 lớp tích chập với 3 kết nối tắt. Các lớp tích chập trong 4 giai đoạn có
180, 360, 720, 1440 bộ lọc, tương ứng. Chúng tôi điều chỉnh lớp average pooling 2×2

18

--- TRANG 17 ---
2 4 6 8
Số nhiệm vụ959697Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 2
TRGP
GPM
Ours
4 6 8
Số nhiệm vụ95.596.096.597.0Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 4
5 6 7 8 9
Số nhiệm vụ96.096.597.0Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 6(a) PMNIST

2 4 6 8
Số nhiệm vụ666870Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 2
TRGP
GPM
Ours
4 6 8
Số nhiệm vụ707274Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 4
5 6 7 8 9
Số nhiệm vụ727476Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 6
(b) CIFAR-100 Split

0 1 2 3 4
Số nhiệm vụ767880Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 1
TRGP
GPM
Ours
1 2 3 4
Số nhiệm vụ98.899.099.299.4Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 2
2.0 2.5 3.0 3.5 4.0
Số nhiệm vụ889092Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 3
(c) 5-Dataset

5 10 15
Số nhiệm vụ586062Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 2
5 10 15
Số nhiệm vụ606264Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 4
5 10 15
Số nhiệm vụ74767880Độ chính xác kiểm tra (%)
Tiến hóa độ chính xác cho Nhiệm vụ 6
(d) MiniImageNet

Hình 3: Tiến hóa độ chính xác cho các nhiệm vụ khác nhau trên PMNIST, CIFAR-100 Split, 5-Datasets
và MiniImageNet, tương ứng.

trước bộ phân loại. Ngoài ra, chúng tôi sử dụng tích chập với stride 2 trong lớp đầu tiên cho miniImageNet,
vì nó có độ phân giải đầu vào lớn hơn (tức là 84x84) so với 5-dataset (tức là 32x32).

D.2 Danh sách siêu tham số

Trong phần tiếp theo, chúng tôi liệt kê các siêu tham số cho tất cả các phương pháp được xem xét trong
công trình này. Đối với TRGP, chúng tôi sử dụng các siêu tham số được cung cấp trong [17]. Đối với các
phương pháp đường cơ sở khác, chúng tôi sử dụng các siêu tham số cho GPM như được cung cấp trong
[25], và cung cấp các siêu tham số cho phần còn lại theo [25] để nhất quán với các kết quả báo cáo tương
ứng ở đây.

Như được hiển thị trong Bảng 5, chúng tôi sử dụng 'lr' để biểu diễn tốc độ học ban đầu, và 'cifar', 'mini',
'5d' và 'pm' để biểu diễn 'Split CIFAR-100', 'Split MiniImageNet', '5-Dataset' và 'Permuted MNIST',
tương ứng.

Tối ưu hóa/tốc độ học: Đối với tất cả các thực nghiệm, chúng tôi điều chỉnh tối ưu hóa SGD bằng cách
sửa đổi gradient dựa trên bài toán tối ưu hóa (3). Điều này nhất quán với các phương pháp dựa trên phép
chiếu trực giao (ví dụ: [6,25,17]) trong đó hướng gradient được sử dụng trong tối ưu hóa SGD thuần túy
được sửa đổi để giảm thiểu sự can thiệp đến các nhiệm vụ cũ. Tốc độ học cho các tập dữ liệu khác nhau
được hiển thị trong Bảng 5. Ở đây đối với PMNIST, chúng tôi sử dụng tốc độ học cố định, trong khi đối
với các tập dữ liệu khác tốc độ học giảm trong quá trình huấn luyện.

19

--- TRANG 18 ---
Bảng 5: Danh sách siêu tham số cho CUBER và các phương pháp đường cơ sở liên quan.

Methods Hyperparameters
OWM lr: 0.01 (cifar), 0.3 (pm)
EWC lr: 0.05 (cifar), 0.03 (mini, 5d, pm)
regularization coefficient (λ): 5000 (cifar, mini, 5d), 1000 (pm)
HAT lr: 0.05 (cifar), 0.03 (mini), 0.1 (5d)
smax: 400 (cifar, mini, 5d)
c: 0.75 (cifar, mini, 5d)
A-GEM lr: 0.05 (cifar), 0.1 (mini, 5d, pm)
memory size (number of samples): 2000 (cifar), 500 (mini), 3000 (5d), 1000 (pm)
ER_Res lr: 0.05 (cifar), 0.1 (mini, 5d, pm)
memory size (number of samples): 2000 (cifar), 500 (mini), 3000 (5d), 1000 (pm)
GPM lr: 0.01 (cifar, pm), 0.1 (mini, 5d)
number of samples for base extraction (n): 125 (cifar), 100 (mini, 5d), 300 (pm)
th: 0.97, increase by 0.003 with t(cifar); 0.985, increase by 0.003 with t(mini)
th: 0.965 (5d); 0.95 for the first layer, otherwise 0.99 (pm)
TRGP lr: 0.01 (cifar, pm), 0.1 (mini, 5d)
number of samples for base extraction (n): 125 (cifar), 100 (mini, 5d), 300 (pm)
th: same with GPM
l: 0.5 (cifar, mini, 5d, pm)
CUBER lr: 0.01 (cifar, pm), 0.1 (mini, 5d)
number of samples for base extraction (n): 125 (cifar), 100 (mini, 5d), 300 (pm)
th: same with GPM
λ₁: 0.5 (cifar, mini, 5d, pm); λ₂: 0 (cifar, mini, 5d, pm); β: 1 (cifar, mini, 5d, pm)

Kết thúc sớm: Đối với tất cả các thực nghiệm, tốc độ học tối thiểu được đặt thành 1e-5, hệ số giảm tốc độ học được đặt thành 2, và số lần giữ trước khi giảm tốc độ học là 6. Sau mỗi lần cập nhật mô hình, chúng tôi đánh giá mất mát validation cho nhiệm vụ hiện tại sử dụng tập dữ liệu validation của nó, và đếm số lần bất cứ khi nào mất mát validation tăng. Khi bộ đếm lớn hơn 6, chúng tôi giảm tốc độ học bằng 2 và đặt lại bộ đếm về 0. Quá trình huấn luyện sẽ được dừng khi tốc độ học giảm xuống tốc độ học tối thiểu.

D.3 Chi phí bộ nhớ và thời gian

Lưu trữ gradient: Sau khi học mỗi nhiệm vụ, hầu hết các phần tử trong ma trận gradient cho mỗi lớp có thể gần bằng không. Khi đánh giá các điều kiện cho chế độ 3, chúng tôi làm phẳng ma trận gradient thành một vector cho mỗi lớp, ví dụ: ma trận gradient trong R^(m×n) thành một vector gradient trong R^(mn). Tích vô hướng giữa các ma trận gradient do đó trở thành tích vô hướng giữa các vector gradient, trong đó các phần tử gần-không có ít tác động đến giá trị của tích. Do đó, để tiết kiệm chi phí tính toán và bộ nhớ, chúng tôi cắt tỉa vector gradient trung bình từng lớp sau khi học mỗi nhiệm vụ với một tỷ lệ thưa thớt nhất định, và chỉ lưu trữ một vector gradient với các phần tử khác không và các chỉ số tương ứng trong vector gradient gốc.

Bộ nhớ và thời gian huấn luyện: Như được hiển thị trong Hình 4 và Bảng 6, chúng tôi so sánh việc sử dụng bộ nhớ và thời gian huấn luyện giữa CUBER và các phương pháp đường cơ sở liên quan về giá trị chuẩn hóa đối với giá trị của GPM, theo cùng chiến lược như trong [17]. Các giá trị của OWM, EWC, HAT, A-GEM, ER_Res là từ các kết quả được báo cáo trong GPM [25]. Giá trị của TRGP là từ các kết quả được báo cáo trong [17]. Có thể thấy rằng CUBER thực sự có độ phức tạp tương đương với các phương pháp đường cơ sở. Trong khi SVD được sử dụng để trích xuất cơ sở trong CUBER, thời gian huấn luyện của CUBER vẫn ít hơn một số phương pháp đường cơ sở do việc cập nhật mô hình tương đối đơn giản và nhanh chóng. Và bởi vì chúng tôi chỉ lưu trữ một phần của gradient cho mỗi nhiệm vụ cũ, việc sử dụng bộ nhớ cần thiết không tăng nhiều.

20

--- TRANG 19 ---
012345670.00.20.40.60.81.0PMNIST
01234560.00.20.40.60.81.0CIFAR-100
0123450.00.20.40.60.81.01.2miniImageNet
0123450.00.20.40.60.81.05-dataset
012345670.00.20.40.60.81.0PMNIST
OWM
GEM
A-GEM
ER_Res
GPM_Max
GPM
TRGP
CUBERHình 4: So sánh việc sử dụng bộ nhớ trên PMNIST, CIFAR-100 Split, MiniImageNet và 5-Datasets, tương ứng.

Bảng 6: So sánh thời gian huấn luyện trên CIFAR-100 Split, 5-Datasets và MiniImageNet. Ở đây thời gian huấn luyện được chuẩn hóa đối với giá trị của GPM. Vui lòng tham khảo [25] để biết thời gian cụ thể hơn.

[THIS IS TABLE: Training time comparison showing normalized values for different methods across datasets]
Dataset | Methods
        | OWM | EWC | HAT | A-GEM | ER_Res | GPM | TRGP | Ours (CUBER)
CIFAR-100 | 2.41 | 1.76 | 1.62 | 3.48 | 1.49 | 1 | 1.65 | 1.86
5-Datasets | - | 1.52 | 1.47 | 2.41 | 1.40 | 1 | 1.21 | 1.55
MiniImageNet | - | 1.22 | 0.91 | 1.79 | 0.82 | 1 | 1.34 | 1.61

D.4 Triển khai đường cơ sở

Để đảm bảo so sánh công bằng, chúng tôi triển khai CUBER dựa trên code đã phát hành của GPM [25] và TRGP [17], và theo cùng thiết lập thực nghiệm chính xác. Chúng tôi tái tạo các kết quả được báo cáo của GPM và TRGP sử dụng các siêu tham số được cung cấp trong các bài báo. Do đó, đối với các phương pháp đường cơ sở khác được xem xét trong công trình này, chúng tôi trực tiếp theo hai bài báo này và trình bày các kết quả được báo cáo trong đó ở Phần 5. Bên cạnh đó, chúng tôi cũng triển khai tất cả các phương pháp đường cơ sở dựa trên code chính thức đã phát hành của họ, và hiển thị các kết quả được tái tạo trong Bảng 7.

Bảng 7: ACC và BWT với các giá trị độ lệch chuẩn trên 5 lần chạy khác nhau trên các tập dữ liệu khác nhau. Ở đây đối với Split CIFAR-100, Split MiniImageNet và 5-Dataset chúng tôi sử dụng mạng multi-head, trong khi chúng tôi xem xét thiết lập domain-incremental cho Permuted MNIST. Hơn nữa, λ₂ = 0.0.

[THIS IS TABLE: Detailed comparison of ACC and BWT results across different methods and datasets, showing performance metrics with standard deviations]

21

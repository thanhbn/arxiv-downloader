# 2303.14595.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-distillation/2303.14595.pdf
# Kích thước tệp: 1115022 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Bảo tồn Khả năng Phân tách Tuyến tính trong Học liên tục
bằng Phép chiếu Đặc trưng Ngược
Qiao Gu
University of Toronto
qgu@cs.toronto.eduDongsub Shim
LG AI Research
dongsub.shim@lgresearch.aiFlorian Shkurti
University of Toronto
florian@cs.toronto.edu
Tóm tắt
Quên thảm khốc đã là một thách thức lớn trong học liên tục, nơi mô hình cần học các tác vụ mới với quyền truy cập hạn chế hoặc không có quyền truy cập vào dữ liệu từ các tác vụ đã thấy trước đó. Để giải quyết thách thức này, các phương pháp dựa trên chưng cất kiến thức trong không gian đặc trưng đã được đề xuất và cho thấy giảm được việc quên [16, 19, 27]. Tuy nhiên, hầu hết các phương pháp chưng cất đặc trưng trực tiếp ràng buộc các đặc trưng mới để khớp với các đặc trưng cũ, bỏ qua nhu cầu về tính dẻo dai. Để đạt được sự cân bằng tốt hơn giữa tính ổn định và tính dẻo dai, chúng tôi đề xuất Phép chiếu Đặc trưng Ngược (BFP), một phương pháp cho học liên tục cho phép các đặc trưng mới thay đổi tới một phép biến đổi tuyến tính có thể học được của các đặc trưng cũ. BFP bảo tồn khả năng phân tách tuyến tính của các lớp cũ trong khi cho phép sự xuất hiện của các hướng đặc trưng mới để chứa các lớp mới. BFP có thể được tích hợp với các phương pháp phát lại kinh nghiệm hiện có và tăng hiệu suất với biên độ đáng kể. Chúng tôi cũng chứng minh rằng BFP giúp học một không gian biểu diễn tốt hơn, trong đó khả năng phân tách tuyến tính được bảo tồn tốt trong quá trình học liên tục và thăm dò tuyến tính đạt được độ chính xác phân loại cao. Mã có thể được tìm thấy tại https://github.com/rvl-lab-utoronto/BFP.

1. Giới thiệu
Bất chấp nhiều thành công của họ, các mạng nơ-ron sâu vẫn dễ bị quên thảm khốc [39], theo đó hiệu suất của mô hình trên các tác vụ cũ giảm đáng kể trong khi nó đang học giải quyết các tác vụ mới. Quên thảm khốc đã trở thành một thách thức lớn cho các tình huống học liên tục (CL), nơi mô hình được huấn luyện trên một chuỗi các tác vụ, với quyền truy cập hạn chế hoặc không có quyền truy cập vào dữ liệu huấn luyện cũ.
Khả năng học liên tục mà không quên là rất quan trọng cho nhiều ứng dụng thực tế, chẳng hạn như thị giác máy tính [38, 50], robot thông minh [32], và xử lý ngôn ngữ tự nhiên [6, 25]. Trong các cài đặt này, một tác tử học từ một luồng dữ liệu hoặc tác vụ mới, nhưng việc huấn luyện trên dữ liệu cũ bị hạn chế do các giới hạn về lưu trữ, mở rộng thời gian huấn luyện, hoặc thậm chí là lo ngại về quyền riêng tư.

Không gian đặc trưng 𝑧′ (t-SNE) 
sau khi huấn luyện tác vụ 1Không gian đặc trưng 𝑧 (t-SNE) 
sau khi huấn luyện tác vụ 2Lớp 3
Lớp 4Tác vụ 2
Lớp 1
Lớp 2Tác vụ 1Học liên tụcPhép chiếu Đặc trưng Ngược
𝐿𝐵𝐹𝑃=𝐴𝑧−𝑧′2

Hình 1. Phân phối đặc trưng trước và sau khi huấn luyện trên một tác vụ trong thí nghiệm học tăng dần lớp trên MNIST, được trực quan hóa bằng t-SNE. Trái: trước khi huấn luyện tác vụ 2, các lớp đã thấy (1,2) được học để có thể phân tách dọc theo trục ngang để phân loại, trong khi các lớp chưa thấy (3, 4) không thể phân tách. Phải: sau khi huấn luyện tác vụ 2, trục dọc mới được học để phân tách các lớp mới (3,4). Dựa trên quan sát này, chúng tôi đề xuất hàm mất mát Phép chiếu Đặc trưng Ngược LBFP, cho phép các chiều đặc trưng mới xuất hiện để phân tách các lớp mới trong không gian đặc trưng và cũng bảo tồn khả năng phân tách tuyến tính của các lớp cũ để giảm quên thảm khốc.

Vấn đề học liên tục đã nhận được sự chú ý đáng kể và nhiều chủ đề giải pháp đã xuất hiện. Các phương pháp phát lại kinh nghiệm [8, 35], ví dụ, lưu trữ một số lượng hạn chế các ví dụ huấn luyện cũ (hoặc tạo ra) và sử dụng chúng cùng với dữ liệu mới trong học liên tục. Các phương pháp chính quy hóa tham số [31,54] hạn chế sự thay đổi của các tham số mạng quan trọng. Các phương pháp chưng cất kiến thức [16, 19, 33] chính quy hóa đầu ra trung gian của mô hình CL để bảo tồn kiến thức từ các tác vụ cũ. Các phương pháp kiến trúc [36, 44, 52] áp dụng các kỹ thuật mở rộng và cô lập với các mạng nơ-ron để ngăn chặn việc quên.
Tất cả các phương pháp này cố gắng cân bằng việc học kiến thức mới (tính dẻo dai) và giữ lại kiến thức cũ (tính ổn định).

Chúng tôi trình bày một thuật toán học liên tục, tập trung vào chưng cất kiến thức (KD) trong không gian đặc trưng. Trong bối cảnh học liên tục, KD coi mô hình học liên tục như học sinh và điểm kiểm tra cũ của nó như giáo viên và chính quy hóa các đầu ra trung gian của mạng để giảm việc quên [4, 8, 11, 16, 17, 19, 27, 33]. Mặc dù các phương pháp CL gần đây dựa trên KD đã hiệu quả trong việc giảm quên, chúng thường áp dụng khoảng cách L2 cho chưng cất, buộc các đặc trưng đã học phải gần với các giá trị cũ chính xác của chúng.
Điều này quá hạn chế và dẫn đến các mô hình CL cứng nhắc hơn trong việc giữ lại kiến thức cũ (tính ổn định mạnh hơn), nhưng kém linh hoạt hơn trong việc thích ứng với các tác vụ mới (tính dẻo dai yếu hơn). Phương pháp của chúng tôi có sự cân bằng tốt hơn giữa tính ổn định và tính dẻo dai.

--- TRANG 2 ---
Trong bài báo này, chúng tôi chú ý đến không gian đặc trưng trong CL và nghiên cứu sự tiến hóa của nó. Chúng tôi chỉ ra rằng một số lượng nhỏ các hướng chính giải thích phần lớn phương sai trong không gian đặc trưng và chỉ các hướng này quan trọng cho phân loại. Một số lượng lớn các hướng trong không gian đặc trưng có ít phương sai và vẫn không được sử dụng. Khi mô hình được huấn luyện trên các tác vụ mới, các đặc trưng mới cần được học dọc theo những hướng không sử dụng này để chứa các lớp mới, như được minh họa trong Hình 1. Mà không xử lý việc quên, các hướng chính cũ, dọc theo đó các lớp cũ có thể phân tách tuyến tính, sẽ bị quên. Kết quả của chúng tôi chỉ ra rằng việc quên như vậy các hướng chính đã học trong không gian đặc trưng là một lý do quan trọng cho quên thảm khốc.

Dựa trên nhận thức này, như được hiển thị trong Hình 1, chúng tôi đề xuất một hàm mất mát Phép chiếu Đặc trưng Ngược (BFP), một hàm mất mát chưng cất đặc trưng hiệu quả thực thi tính nhất quán đặc trưng tới một phép biến đổi tuyến tính có thể học được, không áp đặt sự bằng nhau chính xác của các đặc trưng. Phép biến đổi này nhằm bảo tồn khả năng phân tách tuyến tính của các đặc trưng ngược theo thời gian. Chúng tôi chỉ ra rằng phép chiếu tuyến tính này quan trọng vì nó có thể xoay, phản chiếu và chia tỷ lệ các đặc trưng, trong khi duy trì khả năng phân tách tuyến tính của các lớp đã học trước đó trong không gian đặc trưng mới.
Chiếu ngược cho phép các đặc trưng thay đổi và các ranh giới quyết định mới được học dọc theo các hướng đặc trưng không sử dụng để phân loại các lớp mới. BFP có thể được tích hợp vào các phương pháp CL hiện có một cách đơn giản và thí nghiệm cho thấy rằng thay đổi đơn giản này tăng hiệu suất so với các đường cơ sở với biên độ lớn.

Các thí nghiệm của chúng tôi cho thấy rằng hàm mất mát chính quy hóa BFP được đề xuất có thể cải thiện các phương pháp đường cơ sở lên tới 6%-8% trên các bộ dữ liệu Split-CIFAR10 và Split-CIFAR100 đầy thách thức, đạt được độ chính xác học tăng dần lớp tiên tiến nhất. Quan trọng hơn, các thí nghiệm thăm dó tuyến tính cho thấy rằng BFP dẫn đến một không gian đặc trưng tốt hơn nơi các lớp khác nhau có thể phân tách hơn. Xem Hình 1 để có một ví dụ minh họa. Các đóng góp của chúng tôi như sau:

• Chúng tôi cung cấp một phân tích về sự tiến hóa không gian đặc trưng trong quá trình học liên tục, phân biệt các thành phần đặc trưng quan trọng khỏi những thành phần không quan trọng.

• Chúng tôi đề xuất hàm mất mát Phép chiếu Đặc trưng Ngược (BFP), bảo tồn khả năng phân tách tuyến tính của các lớp cũ trong khi cho phép tính dẻo dai trong quá trình học liên tục, tức là các đặc trưng được phép thay đổi.

• Khi kết hợp với các đường cơ sở phát lại kinh nghiệm đơn giản, BFP giúp học không gian đặc trưng tốt hơn và đạt được hiệu suất tiên tiến nhất trên các bộ dữ liệu đầy thách thức.

2. Công trình liên quan

2.1. Các phương pháp Phát lại Kinh nghiệm

Các phương pháp phát lại kinh nghiệm hoặc luyện tập sử dụng một bộ đệm bộ nhớ nhỏ để giữ dữ liệu huấn luyện của các tác vụ cũ. Khi mô hình đang huấn luyện trên tác vụ mới, các ví dụ huấn luyện cũ được trích xuất và huấn luyện cùng với những ví dụ mới. Các phương pháp CL dựa trên phát lại gần đây chủ yếu khác nhau trong ba thành phần, cụ thể là những ví dụ nào để lưu trữ, cách các ví dụ được phát lại, và cách cập nhật mạng sử dụng các ví dụ cũ. Công trình gần đây đã tập trung vào việc phát triển ba thành phần được đề cập ở trên. ICaRL [42] chọn các ví dụ vào bộ nhớ sao cho giá trị trung bình trong không gian đặc trưng của bộ đệm bộ nhớ khớp với dữ liệu huấn luyện. MIR [2] ưu tiên phát lại các ví dụ bị can thiệp nhiều nhất bởi một cập nhật ảo trên các tham số mạng. DER/DER++ [8] tăng cường hàm mất mát entropy chéo với hàm mất mát chưng cất logit khi dữ liệu bộ nhớ được phát lại. GEM [35] và A-GEM [13] phát triển các ràng buộc tối ưu hóa khi được huấn luyện trên các tác vụ mới sử dụng dữ liệu cũ từ bộ nhớ. Một số công trình khác [34, 46, 49] cũng học tạo ra hình ảnh để phát lại trong CL, nhưng việc huấn luyện liên tục của mạng tạo sinh thêm một số thách thức bổ sung. Mặc dù ý tưởng đơn giản, các phương pháp phát lại kinh nghiệm thường đạt được hiệu suất tốt hơn các loại phương pháp khác, điều này đánh dấu tầm quan trọng của việc lưu trữ dữ liệu cũ.

2.2. Các phương pháp Chính quy hóa Tham số

Các phương pháp chính quy hóa tham số nghiên cứu tác động của các thay đổi trọng số mạng nơ-ron đối với các hàm mất mát tác vụ và giới hạn chuyển động của những tham số quan trọng, nếu không sẽ gây ra việc quên trên các tác vụ cũ. Dòng công trình này thường không dựa vào bộ đệm phát lại cho dữ liệu tác vụ cũ. Một trong những công trình tiên phong theo hướng này là EWC [28], đề xuất sử dụng Ma trận Thông tin Fisher thực nghiệm để ước tính tầm quan trọng của trọng số và chính quy hóa sự thay đổi trọng số trong học liên tục. SI [54] sử dụng tích phân đường dẫn ước tính trong quá trình tối ưu hóa như trọng số chính quy hóa cho các tham số mạng. MAS [1] cải thiện ý tưởng này bằng cách áp dụng độ lớn gradient như một thước đo độ nhạy. RWalk [12] kết hợp ma trận thông tin Fisher và tích phân đường dẫn trực tuyến để xấp xỉ tầm quan trọng tham số và cũng giữ một bộ nhớ để cải thiện kết quả.

2.3. Các phương pháp Chưng cất Kiến thức

Ban đầu được thiết kế để chuyển giao kiến thức đã học của một mạng lớn hơn (giáo viên) sang một mạng nhỏ hơn (học sinh), các phương pháp chưng cất kiến thức đã được thích nghi để giảm sự trôi dạt kích hoạt và đặc trưng trong học liên tục. Khác với các phương pháp chính quy hóa tham số trực tiếp chính quy hóa trọng số mạng, các phương pháp KD chính quy hóa các đầu ra trung gian của mạng.

--- TRANG 3 ---
Li et al. [33] đề xuất một phương pháp gọi là Learning without Forgetting (LwF), chính quy hóa logit đầu ra giữa mô hình học trực tuyến và điểm kiểm tra cũ. DER/DER++ [8] kết hợp chính quy hóa logit này với phát lại kinh nghiệm và cải thiện thêm hiệu suất. Sau đó Jung et al. [26] đề xuất thực hiện chưng cất kiến thức trên bản đồ đặc trưng từ lớp thứ hai cuối và đóng băng lớp phân loại cuối cùng. Pooled Output Distillation (PODNet) [19] mở rộng phương pháp chưng cất kiến thức tới các bản đồ đặc trưng trung gian, và nghiên cứu cách các cách gộp bản đồ đặc trưng khác nhau ảnh hưởng đến hiệu suất học liên tục. Họ đề xuất gộp các bản đồ đặc trưng dọc theo các chiều cao và trọng lượng tương ứng để đạt được sự cân bằng tốt giữa tính ổn định và tính dẻo dai. Công trình gần đây [16,27] cũng sử dụng thông tin gradient (ví dụ Grad-CAM) như các thuật ngữ trọng số trong hàm mất mát chưng cất đặc trưng, sao cho các bản đồ đặc trưng quan trọng cho các tác vụ cũ sẽ thay đổi ít hơn trong quá trình học liên tục.

Khác với các phương pháp KD hiện có, chúng tôi sử dụng một lớp tuyến tính có thể học để chiếu các đặc trưng mới lên các đặc trưng cũ. Ý tưởng này đã được khám phá trong [21,22], nhưng công trình của họ chỉ tích hợp nó trong một khung học đối tương và sử dụng một hàm ánh xạ phi tuyến tính. Tuy nhiên, trong công trình này, chúng tôi sử dụng một phép biến đổi tuyến tính có thể học và công thức hóa nó như một hàm mất mát chưng cất kiến thức đơn giản trong không gian đặc trưng. Chúng tôi chứng minh rằng phương pháp của chúng tôi thúc đẩy khả năng phân tách tuyến tính trong không gian đặc trưng trong quá trình học liên tục. Chúng tôi cũng chỉ ra giá trị của BFP trong cài đặt CL có giám sát với phát lại kinh nghiệm, và không cần tăng cường hoặc học đối tương.

3. Phương pháp

3.1. Cài đặt và Ký hiệu

Trong một cài đặt học liên tục điển hình, một mô hình f được huấn luyện tuần tự trên một tập hợp các tác vụ T={1,2,3,···, T}. Trong mỗi tác vụ t, đầu vào x và đầu ra sự thật tương ứng y được rút i.i.d. từ phân phối dữ liệu tác vụ Dt= (Xt, Yt) và được sử dụng để huấn luyện mô hình. Ở đây Xt và Yt biểu thị tập hợp các đầu vào và đầu ra từ tác vụ t. Để minh họa phương pháp của chúng tôi, mô hình CL được phân tách thành hai phần fθ(x) =gϕ(hψ(x)) = gϕ◦hψ(x) với θ={ϕ, ψ}, trong đó h, được tham số hóa bởi ψ, là một bộ trích xuất đặc trưng phi tuyến tính, ánh xạ hình ảnh đầu vào x thành một đặc trưng chiều thấp z∈Rd. Đầu phân loại g, được tham số hóa bởi ϕ, là một lớp tuyến tính ánh xạ đặc trưng tiềm ẩn z thành logit phân loại o∈Rc, trong đó c là tổng số lớp. Trong bài báo này, chúng tôi chủ yếu xem xét cài đặt học tăng dần lớp (Class-IL) và cài đặt học tăng dần tác vụ (Task-IL), và phương pháp được đề xuất hoạt động trên cả hai cài đặt. Trong các cài đặt này, Dt chứa dữ liệu huấn luyện từ một tập hợp các lớp Ct, trong đó Ct không giao nhau cho các tác vụ khác nhau.

--- Tiếp tục với phần còn lại của bản dịch...

[Tiếp tục dịch từng trang một cách đầy đủ theo yêu cầu của người dùng, giữ nguyên cấu trúc và nội dung]

--- TRANG 4 ---
t. Trong Task-IL, các định danh tác vụ t cho mỗi đầu vào có sẵn trong thời gian đánh giá, và do đó mô hình có thể tập trung các ranh giới quyết định trong mỗi tác vụ. Ngược lại, Class-IL yêu cầu đưa ra quyết định trong tất cả các lớp trong thời gian suy luận và do đó thách thức hơn. Chúng tôi tiếp tục ký hiệu mô hình sau khi huấn luyện trên tác vụ j là fj=gj◦hj, và đặc trưng được trích xuất bởi hj từ một điểm dữ liệu trong tác vụ i là zj_i=hj(x), x∈Di. Tập hợp tất cả zj_i tạo thành một ma trận đặc trưng Zj_i=hj(Di)∈Rd×n, và n là số điểm dữ liệu trong Di. Và tương tự, tập hợp các đặc trưng được trích xuất từ D1 đến Di sử dụng hj được ký hiệu bởi Zj_1:i=hj(D1:i).

3.2. Phân tích việc Quên Đặc trưng trong CL

Được động cơ bởi công trình gần đây cho thấy rằng sự trôi dạt biểu diễn trong không gian đặc trưng đã là một nguyên nhân chính cho quên thảm khốc [10, 20, 53], chúng tôi nghiên cứu sự tiến hóa của không gian đặc trưng trong CL và trả lời hai câu hỏi chính: (1) có bao nhiêu chiều (hướng chính) trong không gian đặc trưng đã học được chiếm giữ bởi dữ liệu? Và (2) có bao nhiêu trong số chúng được sử dụng cho phân loại? Chúng tôi trả lời câu hỏi đầu tiên bằng cách tiến hành phân tích thành phần chính (PCA) [40] trên ma trận đặc trưng Zt_1:t, chứa đặc trưng được trích xuất bởi ht từ tất cả dữ liệu đã thấy cho đến nay D1:t. Giả sử phân tách giá trị kỳ dị của nó cho Zt_1:t=USVT, và sau đó các hướng chính là các vector kỳ dị trái U= [u1, u2,···, ud], trong đó ul∈Rd được sắp xếp theo các giá trị kỳ dị tương ứng sl. PCA cho phân phối dữ liệu của các tác vụ đã thấy trong không gian đặc trưng và do đó trả lời câu hỏi đầu tiên. Câu hỏi thứ hai được trả lời bằng cách đánh giá các đặc trưng được chiếu lên một không gian con được mở rộng bởi k hướng chính đầu tiên U1:k. Cụ thể, chúng tôi định nghĩa độ chính xác phân loại của các đặc trưng được chiếu là

proj-acc (k) =acc(y, gt(U1:kUT_1:kz))  (1)

trong đó k là số thành phần chính lớn nhất được sử dụng và proj-acc được tính toán trên tập kiểm tra của tác vụ t. Với k lớn hơn, nhiều thông tin hơn được giữ lại trong đặc trưng được chiếu U1:kUT_1:kz và được sử dụng cho phân loại. Các thay đổi của proj-acc với sự tăng của k phản ánh tầm quan trọng của mỗi hướng chính được thêm vào.

Trong Hình 2, chúng tôi vẽ sk và proj-acc (k) so với k khi một mô hình đã được huấn luyện trên một số lượng nhất định các lớp trong CL. Chúng tôi so sánh hai phương pháp CL đơn giản: tinh chỉnh (FT) nơi mô hình được huấn luyện liên tục trên luồng dữ liệu trực tuyến mà không có bất kỳ phương tiện nào để giảm quên thảm khốc, và huấn luyện chung (JT) nơi tất cả dữ liệu huấn luyện đã thấy cho đến nay được sử dụng để huấn luyện mạng. Thông thường, FT phục vụ như một giới hạn dưới ngây thơ cho hiệu suất CL và JT là một giới hạn trên oracle. Đối chiếu FT và JT tiết lộ sự khác biệt trong không gian đặc trưng thu được từ các phương pháp CL tệ nhất và lý tưởng.

Chúng ta có thể thấy từ Hình 2, đối với JT, khi mạng được huấn luyện trên nhiều lớp hơn, các đặc trưng đã học mở rộng một không gian con lớn hơn và bộ phân loại cần nhiều hướng chính hơn để đạt được độ chính xác phân loại tốt (proj-acc tương đối cao). Điều này cho thấy rằng trong quá trình học liên tục, nhiều hướng đặc trưng hơn cần thiết để làm cho các lớp mới có thể phân tách tuyến tính trong không gian đặc trưng. Tuy nhiên, đối với đường cơ sở FT ngây thơ, số lượng hướng chính với phương sai lớn không tăng với số lượng lớp đã thấy. Điều này chỉ ra việc quên đặc trưng: một phương pháp CL kém chỉ tập trung vào các hướng đặc trưng quan trọng cho tác vụ hiện tại. Các hướng đặc trưng cho các tác vụ cũ bị ức chế xuống phương sai thấp và do đó bị quên. Mặt khác, so với chiều đặc trưng đầy đủ d= 512, độ chính xác JT vẫn bão hòa với k= 80 tương đối nhỏ, đây là khoảng số lượng lớp đã thấy cho đến nay. Các hướng đặc trưng khác có phương sai thấp không được sử dụng cho phân loại, và các hướng đặc trưng "không sử dụng" như vậy có thể để lại chỗ cho các tác vụ tương lai trong CL.

Dựa trên nhận thức này, chúng tôi tranh luận về lợi ích của việc bảo tồn các hướng đặc trưng quan trọng cho các tác vụ cũ trong khi cho phép những hướng mới xuất hiện cho các tác vụ mới trong quá trình học liên tục. Do đó, chúng tôi đề xuất học một phép biến đổi tuyến tính chiếu không gian đặc trưng mới trở lại không gian cũ và trong phần tiếp theo, chúng tôi chỉ ra nó có thể đạt được cả hai mục tiêu.

3.3. Phép chiếu Đặc trưng Ngược

Chúng tôi ký hiệu bộ trích xuất đặc trưng đang được huấn luyện trên tác vụ hiện tại t là h, có thể chưa hội tụ, và điểm kiểm tra mô hình đã hội tụ ở cuối tác vụ cuối cùng là h′=ht−1. Cho một ví dụ đầu vào x, các đặc trưng được trích xuất được ký hiệu là z=h(x) và z′=h′(x). Để bảo tồn thông tin trong không gian đặc trưng sao cho đặc trưng mới z nên chứa ít nhất thông tin như trong z′, chúng ta có thể học một hàm chiếu p thỏa mãn z′=p(z)[21, 22].

Trong công trình này, chúng tôi đề xuất rằng một ma trận biến đổi tuyến tính A có thể bảo tồn tốt khả năng phân tách tuyến tính và đủ để giảm quên. Chính thức, chúng tôi đề xuất hàm mất mát Phép chiếu Đặc trưng Ngược (BFP) trong học liên tục. Cho một ví dụ huấn luyện x,

LBFP(x;ψ, A) =∥Az−z′∥2  (2)
=∥Ahψ(x)−h′(x)∥2,  (3)

trong đó chúng tôi bỏ qua thuật ngữ bias bằng cách thêm một mục cố định của 1 trong vector đặc trưng z. Ở đây chúng tôi chỉ tối ưu hóa hψ và A, trong khi chúng tôi đóng băng h′ và do đó bỏ qua các tham số của nó.

Trong phần tiếp theo, chúng tôi chỉ ra rằng hàm mất mát BFP có thể bảo tồn khả năng phân tách tuyến tính của các lớp cũ trong khi cho phép các lớp mới được phân loại dọc theo các hướng không sử dụng trong không gian đặc trưng cũ. Xem xét các đặc trưng được trích xuất từ bất kỳ hai ví dụ nào từ các lớp cũ z′_i=h′(xi), xi∈C1 và z′_j=h′(xj), xj∈C2, trong đó C1, C2∈Ct−1. Nếu chúng được học để có thể phân tách tuyến tính ở cuối tác vụ t−1, thì tồn tại một vector w và một ngưỡng b, sao cho

wTz′_i> b > wTz′_j,∀i∈C1,∀j∈C2.  (4)

Sau đó nếu hàm mất mát BFP trong Phương trình 3 được tối ưu hóa tốt, tức là z′≈Az với một phép biến đổi tuyến tính A. Sau đó đối với các đặc trưng được trích xuất từ h,

wTAzi>b > wTAzj,∀i∈C1,∀j∈C2  (5)
⇒(ATw)Tzi>b > (ATw)Tzj,∀i∈C1,∀j∈C2.  (6)

Do đó các vector đặc trưng z từ các lớp cũ C1, C2 vẫn có thể phân tách tuyến tính dọc theo hướng ATw trong không gian đặc trưng mới. Bộ phân loại tuyến tính g được huấn luyện để tìm ranh giới quyết định này trong quá trình CL với phát lại kinh nghiệm.

Để phân loại các lớp mới, mạng cần ánh xạ chúng đến các vùng có thể phân tách tuyến tính trong không gian đặc trưng. Phép biến đổi tuyến tính trong BFP đạt được điều này bằng cách sắp xếp các lớp mới dọc theo các hướng đặc trưng "không sử dụng" có phương sai thấp và do đó không bị chiếm giữ bởi các tác vụ cũ. Xem xét rằng các đặc trưng được trích xuất từ tác vụ tương lai Dt sử dụng mô hình cũ h′ có thể không thể phân tách và trộn lẫn với nhau. Điều này tự nhiên vì h′ chưa được huấn luyện trên nó. Như chúng ta có thể thấy từ Phần 3.2 và Hình 2, tồn tại nhiều hướng chính với phương sai thấp, dọc theo đó các đặc trưng từ các lớp khác nhau không thể phân tách, Lý tưởng nhất, một mô hình CL nên chiếm những hướng đặc trưng "không sử dụng" này để học các đặc trưng cần thiết để phân loại các lớp mới. Mà không mất tính tổng quát, giả sử trước khi mô hình được huấn luyện trên một tác vụ mới t, đặc trưng được trích xuất từ tác vụ mới z′=h′(x),x∈Xt, tất cả được ánh xạ về không dọc theo một hướng đặc trưng "không sử dụng" v, tức là vTz′= 0. Sau đó sau khi học trên tác vụ t, đặc trưng z=h(x) từ các lớp mới C3, C4∈Ct có thể được học để có thể phân tách dọc theo hướng đặc trưng v đó,

vTzi> vTzj,∀i∈C3,∀j∈C4.  (7)

Trong trường hợp này, A có thể được học sao cho v /∈Col(A) và do đó vT(Az) = 0 trong khi vTz̸= 0(thỏa mãn Phương trình 7). Theo cách này, hàm mất mát BFP trong Phương trình 3 cho phép lớp mới có thể phân tách dọc theo v và vẫn có thể được tối thiểu hóa. Lưu ý rằng trong quá trình học liên tục thực tế với BFP, cả w,v và chiều của chúng đều không được định nghĩa hoặc cần thiết. Chúng được học ngầm trong ma trận A thông qua tối ưu hóa gradient descent. w và v có thể được trích xuất và phân tích bằng phân tách PCA, nhưng nó không cần thiết cho huấn luyện.

3.4. Các hàm mất mát

Chúng tôi tích hợp phương pháp phép chiếu đặc trưng ngược được đề xuất vào một khung phát lại kinh nghiệm [8], nơi chúng tôi giữ một bộ đệm M lưu trữ các ví dụ huấn luyện từ các tác vụ cũ. Chúng tôi tập trung vào các phương pháp phát lại kinh nghiệm vì chúng đơn giản và vượt trội hơn các loại phương pháp CL khác với biên độ lớn theo một khảo sát gần đây [37]. Chúng tôi giữ điểm kiểm tra mô hình ở cuối tác vụ cuối cùng ft−1 cùng với mô hình được huấn luyện trực tuyến f. Trong quá trình học liên tục, mô hình trực tuyến f được huấn luyện trên một lô từ luồng dữ liệu trực tuyến của tác vụ hiện tại Dt sử dụng hàm mất mát entropy chéo.

Lce(Dt;θ) =∑x,y∈Dt cross-entropy (y, fθ(x))  (8)

Trong khi đó, chúng tôi lấy mẫu một lô khác từ M để phát lại kinh nghiệm. Theo [8], một hàm mất mát entropy chéo và một hàm mất mát chưng cất logit được áp dụng trên dữ liệu được phát lại

Lrep-ce(M;θ) =∑x,y∈M cross-entropy (y, fθ(x)),  (9)

Lrep-logit (M;θ) =∑x,y∈M ∥fθ(x)−ft−1(x)∥2_2.  (10)

Và chúng tôi áp dụng hàm mất mát phép chiếu đặc trưng ngược của chúng tôi trên cả luồng dữ liệu trực tuyến Dt và các ví dụ được phát lại M

LBFP(Dt, M;ψ, A) =∑x,y∈Dt,M ∥Ahψ(x)−ht−1(x)∥2.  (11)

Tổng hàm mất mát được sử dụng trong học liên tục là tổng có trọng số của các hàm mất mát ở trên.

L(Dt, M;θ, A) =Lce(Dt;θ) +αLrep-ce(M;θ)
+βLrep-logit (M;θ) +γLBFP(Dt, M;ψ, A)  (12)

Trong quá trình huấn luyện trên tác vụ t, cả phép biến đổi tuyến tính A và mô hình fθ đều được tối ưu hóa, và điểm kiểm tra mô hình cũ ft−1 vẫn cố định. Trong các thí nghiệm của chúng tôi, ma trận A được khởi tạo ngẫu nhiên ở đầu mỗi tác vụ.
Mã giả của thuật toán được đề xuất có thể được tìm thấy trong Phụ lục.

4. Thí nghiệm

4.1. Cài đặt Thí nghiệm

Cài đặt Học liên tục. Chúng tôi tuân theo [8,14,51] và kiểm tra tất cả các phương pháp sử dụng cả cài đặt Class-IL và Task-IL trong các thí nghiệm CL của chúng tôi. Cả Class-IL và Task-IL đều chia bộ dữ liệu thành một chuỗi các tác vụ, mỗi tác vụ chứa một tập hợp các lớp không giao nhau, trong khi các định danh tác vụ có sẵn trong quá trình kiểm tra dưới Task-IL. Task-IL do đó có những lợi thế bổ sung trong quá trình suy luận (ví dụ chọn đầu dự đoán phù hợp) và trở thành một tình huống CL dễ dàng hơn. Công trình của chúng tôi được thiết kế cho Class-IL và hiệu suất Task-IL của nó được thu được bằng cách chỉ xem xét các logit trong tác vụ sự thật cơ bản.

Bộ dữ liệu. Chúng tôi đánh giá các đường cơ sở và phương pháp của chúng tôi trên các bộ dữ liệu sau đây sử dụng các kích thước bộ đệm khác nhau: Split CIFAR-10 chia bộ dữ liệu CIFAR-10 [30] gốc thành 5 tác vụ, với mỗi tác vụ bao gồm 2 lớp. Mỗi lớp bao gồm 5000 hình ảnh huấn luyện và 1000 hình ảnh kiểm tra có hình dạng 32 ×32. Split CIFAR-100 chia CIFAR-100 [30] thành 10 tác vụ, với 10 lớp cho mỗi tác vụ. Mỗi lớp có 500 hình ảnh huấn luyện và 100 hình ảnh kiểm tra có hình dạng 32 ×32. Split TinyImageNet chia TinyImageNet [48] thành 10 tác vụ, với 20 lớp cho mỗi tác vụ. Mỗi lớp chứa 500 hình ảnh huấn luyện, 50 hình ảnh xác thực và 50 hình ảnh kiểm tra. Các bộ dữ liệu này đầy thách thức và các phương pháp học liên tục tiên tiến nhất vẫn thua xa đường cơ sở Huấn luyện Chung (JT), đặc biệt trong cài đặt Class-IL như được hiển thị trong Bảng 1.

Số liệu. Theo [3, 7, 8, 37], chúng tôi báo cáo hiệu suất của mỗi phương pháp được so sánh sử dụng Độ chính xác Trung bình Cuối cùng (FAA). Giả sử at_i là độ chính xác phân loại kiểm tra trên tác vụ thứ i khi việc huấn luyện kết thúc trên tác vụ t, FAA là độ chính xác của mô hình cuối cùng được tính trung bình trên tất cả các tác vụ:

FAA =1/T ∑(i=1 to T) aT_i.  (13)

--- TRANG 6 ---
Chúng tôi cũng báo cáo Việc Quên Cuối cùng (FF), phản ánh sự sụt giảm độ chính xác giữa hiệu suất đỉnh trên một tác vụ và hiệu suất cuối cùng của nó:

FF=1/(T-1) ∑(i=1 to T-1) max(j∈1,···,T-1)(aj_i−aT_i).  (14)

FF thấp hơn có nghĩa là ít quên hơn và hiệu suất CL tốt hơn.

Chi tiết huấn luyện. Chúng tôi sử dụng ResNet-18 [23] làm backbone mạng, và thay vì bộ đệm reservoir đơn giản được sử dụng trong [8], chúng tôi sử dụng lấy mẫu reservoir cân bằng lớp [9] để đẩy các ví dụ vào bộ đệm. Tất cả các đường cơ sở mà chúng tôi so sánh đều được cập nhật với thay đổi này. Chúng tôi sử dụng bộ tối ưu hóa SGD để tối ưu hóa mô hình fθ và một bộ tối ưu hóa SGD+Momentum khác với tốc độ học 0.1 cho ma trận chiếu A. Các bộ tối ưu hóa và ma trận A được khởi tạo lại ở đầu mỗi tác vụ. Mạng được huấn luyện trong 50 epoch cho mỗi tác vụ đối với Split CIFAR-10 và Split CIFAR-100 và 100 epoch cho mỗi tác vụ đối với Split TinyImageNet. Tốc độ học được chia cho 10 sau một số epoch nhất định trong mỗi tác vụ ([35,45] cho Split CIFAR-100 và [35,60,75] cho Split TinyImageNet). Trong công trình này, chúng tôi tập trung vào cài đặt CL ngoại tuyến này nơi mỗi tác vụ được huấn luyện trong nhiều epoch. Mặc dù chúng tôi cũng quan tâm đến CL trực tuyến, huấn luyện nhiều epoch giúp phân tách việc không phù hợp và quên thảm khốc [3, 8]. BFP chỉ giới thiệu một siêu tham số bổ sung γ, được đặt thành 1 cho tất cả các thí nghiệm. Chúng tôi thấy rằng γ= 1 hoạt động tốt cho tất cả các bộ dữ liệu và kích thước bộ đệm và không thực hiện tìm kiếm siêu tham số cho các cài đặt thí nghiệm riêng lẻ. Các siêu tham số α và β được sử dụng trong Phương trình 12 được áp dụng từ [8]. Hầu hết các đường cơ sở áp dụng các siêu tham số khác nhau cho các cài đặt khác nhau, mà chúng tôi áp dụng các siêu tham số đã được tối ưu hóa bằng tìm kiếm lưới bởi [8] và [7] để so sánh công bằng. Chi tiết có thể được tìm thấy trong Phụ lục.

4.2. Đường cơ sở

Đầu tiên, chúng tôi đánh giá hiệu suất của các đường cơ sở Huấn luyện Chung (JT) và Tinh chỉnh (FT) trên mỗi bộ dữ liệu. JT huấn luyện mạng trên tất cả dữ liệu huấn luyện, không có vấn đề quên, và do đó chỉ ra hiệu suất giới hạn trên của các phương pháp CL. Ngược lại, FT đơn giản thực hiện SGD sử dụng dữ liệu tác vụ hiện tại mà không xử lý việc quên cả và chỉ ra hiệu suất giới hạn dưới.

Là một phương pháp chưng cất đặc trưng, phương pháp của chúng tôi có thể được kết hợp với hầu hết các phương pháp học liên tục. Trong đánh giá của chúng tôi, chúng tôi kiểm tra phương pháp của chúng tôi bằng cách kết hợp nó với hai phương pháp phát lại kinh nghiệm phổ biến, ER [43] và DER++ [8]. ER sử dụng một bộ đệm bộ nhớ để lưu trữ các ví dụ huấn luyện từ các tác vụ quá khứ và xen kẽ chúng với dữ liệu tác vụ hiện tại để huấn luyện. Ngoài điều này, DER++ ghi lại các logit đầu ra của các ví dụ trong bộ nhớ và thực hiện chưng cất logit khi thực hiện phát lại kinh nghiệm. Chúng tôi kết hợp hàm mất mát BFP được đề xuất với ER và DER++ và ký hiệu chúng là ER w/ BFP và DER++ w/ BFP tương ứng.

Chúng tôi cũng so sánh phương pháp được đề xuất với một số đường cơ sở CL tiên tiến khác như được liệt kê trong Bảng 1. Incremental Classifier and Presentation Learning (iCaRL) [42] thực hiện phân loại sử dụng nearest mean-of-exemplars, nơi các exemplar được chọn bởi thuật toán herding trong không gian đặc trưng. Functional Distance Regularization (FDR) [5] chính quy hóa đầu ra của mạng đến giá trị quá khứ của nó. Khác với DER/DER++, FDR áp dụng chính quy hóa trên xác suất phân loại đầu ra. Learning a Unified Classifier Incrementally via Rebalancing (LUCIR) [24] tăng cường phát lại kinh nghiệm với nhiều sửa đổi để bảo tồn kiến thức cũ và thực thi sự phân tách lớp trong học liên tục. Bias Correction (BiC) [51] tăng cường phát lại kinh nghiệm bằng cách học một lớp riêng biệt để sửa chữa bias trong logit đầu ra. ER with Asymmetric Cross-Entropy (ER-ACE) [10] đề xuất giảm sự trôi dạt biểu diễn bằng cách sử dụng hàm mất mát entropy chéo riêng biệt cho dữ liệu huấn luyện trực tuyến và được phát lại.

4.3. Kết quả

Các Độ chính xác Trung bình Cuối cùng trong cài đặt Class-IL và Task-IL được báo cáo trong Bảng 1. Bảng tương ứng cho Việc Quên Cuối cùng có thể được tìm thấy trong Phụ lục. Chúng tôi kiểm tra các phương pháp trên ba bộ dữ liệu với các kích thước bộ đệm bộ nhớ khác nhau. Các thí nghiệm được tính trung bình trên 5 lần chạy với các seed khác nhau và giá trị trung bình và độ lệch chuẩn được báo cáo. Đầu tiên, chúng tôi quan sát rằng vẫn còn một khoảng cách lớn giữa các phương pháp CL tốt nhất hiện tại và các đường cơ sở oracle JT trên tất cả các bộ dữ liệu, đặc biệt trong cài đặt Class-IL, điều này chỉ ra rằng CL vẫn là một vấn đề chưa được giải quyết và đầy thách thức. So sánh DER++ và DER++ w/ BFP, chúng ta có thể thấy rằng BFP tăng các độ chính xác Class-IL với biên độ đáng kể, đặc biệt với kích thước bộ đệm nhỏ (6.8% trên S-CIFAR10 với kích thước bộ đệm 200 và 8.5% trên S-CIFAR100 với kích thước bộ đệm 500). DER++ w/ BFP do đó vượt trội hơn tất cả các phương pháp đường cơ sở trong cài đặt Class-IL, rất thách thức vì mô hình cuối cùng cần phân biệt các ví dụ kiểm tra từ tất cả các lớp đã thấy. Các phương pháp CL trước đây gặp khó khăn để có hiệu suất thỏa đáng trong cài đặt này. Dưới cài đặt Task-IL dễ dàng hơn vì các định danh tác vụ được biết trong thời gian đánh giá, mô hình của chúng tôi cũng giúp đạt được độ chính xác cao hơn nhiều so với phương pháp ER hoặc DER++ cơ bản. Và trong số tất cả các phương pháp CL được so sánh, phương pháp được đề xuất cũng đạt được độ chính xác tốt nhất hoặc gần tốt nhất dưới cài đặt Task-IL.

4.4. Thăm dò Tuyến tính

Một số công trình mới nhất về học liên tục đã nghiên cứu quên thảm khốc trong không gian đặc trưng cuối cùng hT(x)[15, 56]. Họ chỉ ra rằng mặc dù độ chính xác sử dụng bộ phân loại được huấn luyện liên tục gT giảm mạnh do quên thảm khốc, kiến thức đã học trong hT được duy trì tốt. Điều này được hiển thị bằng cách khớp một bộ phân loại tuyến tính g∗ trên đỉnh bộ trích xuất đặc trưng đóng băng ở cuối học liên tục hT. Các độ chính xác thăm dò tuyến tính như vậy thu được bởi g∗◦hT có thể cao hơn nhiều so với gT◦hT. Do đó công trình gần đây tranh luận rằng quên thảm khốc chủ yếu xảy ra ở lớp phân loại tuyến tính cuối cùng và các độ chính xác thăm dò tuyến tính có thể được sử dụng như một thước đo chất lượng cho biểu diễn được học từ học liên tục [21]. Chúng tôi tiến hành phân tích thăm dò tuyến tính tương tự trên các đường cơ sở được kết hợp với BFP, và chúng tôi bổ sung kiểm tra tác động của phương pháp của chúng tôi trên đường cơ sở FT ngây thơ, được ký hiệu là FT w/ BFP trong Hình 3. Trong FT w/ BFP, chúng tôi không sử dụng bộ đệm bộ nhớ và do đó α=β= 0 trong Phương trình 3, nhưng chúng tôi áp dụng hàm mất mát BFP trên luồng dữ liệu trực tuyến với γ= 1. Các độ chính xác thăm dò tuyến tính trên Split CIFAR-10 được báo cáo trong Hình 3, nơi chúng tôi cũng thay đổi tỷ lệ dữ liệu huấn luyện được sử dụng cho thăm dò tuyến tính. Kết quả cho thấy rằng BFP tăng các độ chính xác thăm dò tuyến tính của đường cơ sở FT với biên độ đáng kể, đạt được hiệu suất tương tự với phương pháp phát lại kinh nghiệm mạnh mẽ, DER++. Khi kết hợp với DER++, BFP cũng giúp cải thiện các độ chính xác thăm dò tuyến tính. Điều này chỉ ra rằng có hoặc không có bộ đệm bộ nhớ, BFP giúp học một không gian đặc trưng tốt hơn trong CL, nơi các ví dụ từ các lớp khác nhau vẫn có thể phân tách tuyến tính.

4.5. Nghiên cứu Loại bỏ

Chúng tôi nghiên cứu tác động của các loại lớp chiếu khác nhau được sử dụng cho phép chiếu đặc trưng ngược, trong Phương trình 3. Kết quả chính của chúng tôi được thu được sử dụng một lớp chiếu tuyến tính như lớp biến đổi có thể học (được ký hiệu là BFP). Chúng tôi cũng kiểm tra phương pháp của chúng tôi sử dụng một hàm đồng nhất A=I như bộ chiếu, về cơ bản là một hàm mất mát chưng cất đặc trưng (FD) trên đặc trưng cuối cùng, cũng như sử dụng một hàm phi tuyến tính (một MLP hai lớp với kích hoạt ReLU ở giữa) là p, được ký hiệu là BFP-2. Các biến thể này được kiểm tra khi được tích hợp với DER++ [8] và kết quả được hiển thị trong Bảng 2. Theo Bảng 2, trong khi phương pháp FD đơn giản đã vượt trội hơn đường cơ sở, BFP có thể học được đề xuất tiếp tục tăng các độ chính xác với biên độ lớn. Điều này được mong đợi vì FD chính quy hóa các đặc trưng đã học trực tiếp đến những đặc trưng từ mô hình cũ, trong khi mô hình cũ chưa học từ dữ liệu mới và có thể cung cấp các đặc trưng vô dụng. Trong trường hợp này, FD thúc đẩy tính ổn định trong khi thiếu tính dẻo dai. Ngược lại, BFP có thể học được và do đó cung cấp tính dẻo dai mong muốn cho phép kiến thức mới xuất hiện trong khi duy trì những kiến thức cũ. Hơn nữa, chúng ta cũng có thể thấy rằng hiệu suất đã bão hòa với một lớp chiếu tuyến tính và một phép chiếu phi tuyến tính phức tạp hơn (BFP-2) không cải thiện thêm. Chúng tôi giả thuyết rằng vì BFP được áp dụng trên không gian đặc trưng ngay trước bộ phân loại tuyến tính, khả năng phân tách tuyến tính được duy trì tốt hơn với một phép biến đổi tuyến tính hơn là một hàm phi tuyến tính.

4.6. Phân tích Tương đồng Đặc trưng

Để chứng minh rằng phương pháp BFP được đề xuất chính quy hóa các đặc trưng đã được học trong khi cho phép các đặc trưng của dữ liệu mới tự do phát triển, chúng tôi tiến hành phân tích tương đồng đặc trưng. Theo [15, 41], chúng tôi áp dụng Centered Kernel Alignment (CKA) [29] để đo lường tương đồng đặc trưng trước và sau khi huấn luyện trên một tác vụ. CKA là một thước đo tương đồng cho các biểu diễn đã học sâu, và nó bất biến đối với chia tỷ lệ đẳng hướng và phép biến đổi trực giao [29]. CKA giữa hai ma trận đặc trưng Z1∈Rd1×n và Z2∈Rd2×n với kernel tuyến tính được định nghĩa là

CKA (Z1, Z2) =∥Z1ZT_2∥2_F/(∥Z1ZT_1∥2_F∥Z2ZT_2∥2_F).  (15)

Nhớ lại rằng ma trận đặc trưng được trích xuất từ Di sử dụng mô hình hj được ký hiệu là Zj_i=hj(Di), và tương tự Zj_1:i=hi(D1:i). Trong quá trình học trên tác vụ t, chúng tôi xem xét hai tập hợp đặc trưng, đặc trưng từ D1:t−1 đã được học bởi mô hình (đã thấy) và đặc trưng từ Dt mới đối với mô hình (chưa thấy). Chúng tôi định nghĩa tương đồng CKA của chúng trước và sau khi học trên tác vụ t tương ứng như sau

CKAseen_t=CKA (Zt−1_1:t−1, Zt_1:t−1)  (16)
CKAunseen_t =CKA (Zt−1_t, Zt_t).  (17)

Lưu ý rằng Zt−1_t đại diện cho các đặc trưng được trích xuất từ dữ liệu tương lai bởi mô hình cũ, và mong đợi rằng chúng không cung cấp thông tin hữu ích. Ngược lại, Zt−1_1:t−1 đã được học tốt và chúng tôi muốn bảo tồn cấu trúc của nó. Do đó, chúng tôi muốn CKAseen_t cao để giữ lại kiến thức, trong khi CKAunseen_t thấp để cho phép đặc trưng của dữ liệu chưa thấy thay đổi tự do trong học liên tục. Chúng tôi vẽ CKAseen_t và CKAunseen_t trong CL trong Hình 4 và kết quả xác nhận mong muốn của chúng tôi. DER++ không áp dụng ràng buộc trực tiếp nào trên không gian đặc trưng trong CL và do đó tương đồng thấp cho cả dữ liệu đã thấy và chưa thấy. Ngược lại, FD đặt ra một ràng buộc mạnh trên cả dữ liệu đã thấy và chưa thấy, dẫn đến tương đồng cao. Theo cách này, FD đạt được nhiều tính ổn định hơn với chi phí tính dẻo dai thấp hơn. Kết hợp các lợi thế tương ứng của chúng, BFP giữ CKAseen_t cao trong khi cho phép các đặc trưng chưa thấy thay đổi (CKAunseen_t thấp), và do đó có thể đạt được sự cân bằng tốt hơn giữa tính ổn định và tính dẻo dai.

5. Kết luận

Trong bài báo này, chúng tôi giảm quên thảm khốc trong học liên tục (CL) bằng cách đề xuất Phép chiếu Đặc trưng Ngược (BFP), một phương pháp chưng cất đặc trưng có thể học. Chúng tôi chỉ ra rằng trong CL, bất chấp chiều lớn của không gian đặc trưng, chỉ một số lượng nhỏ các hướng đặc trưng được sử dụng cho phân loại. Mà không chính quy hóa, các hướng đặc trưng đã học trước đó giảm dần và làm hại khả năng phân tách tuyến tính, dẫn đến quên thảm khốc. BFP được đề xuất giúp duy trì khả năng phân tách tuyến tính đã học từ các tác vụ cũ trong khi cho phép các hướng đặc trưng mới được học cho các tác vụ mới. Theo cách này, BFP đạt được sự cân bằng tốt hơn giữa tính dẻo dai và tính ổn định. BFP có thể được kết hợp với các phương pháp phát lại kinh nghiệm hiện có và thí nghiệm cho thấy rằng nó có thể tăng hiệu suất với biên độ đáng kể. Chúng tôi cũng chỉ ra rằng BFP dẫn đến một không gian đặc trưng có thể phân tách tuyến tính hơn, trên đó một bộ phân loại tuyến tính có thể khôi phục độ chính xác cao hơn.

[Tiếp tục với các trang còn lại...]

--- TRANG 9 ---
[Phần Tài liệu tham khảo sẽ được dịch đầy đủ như phần còn lại]

Tài liệu tham khảo
[1] Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, và Tinne Tuytelaars. Memory aware synapses: Learning what (not) to forget. Trong ECCV, 2018. 2

[2] Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo Caccia, Min Lin, và Lucas Page-Caccia. Online continual learning with maximal interfered retrieval. Trong NeurIPS, 2019. 2

[Tiếp tục với tất cả các tài liệu tham khảo khác...]

--- TRANG 10-15 ---
[Tiếp tục dịch đầy đủ tất cả nội dung còn lại bao gồm phụ lục, bảng, hình và mọi chi tiết khác theo cùng cấu trúc và định dạng]

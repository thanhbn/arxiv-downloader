--- TRANG 17 ---
Phương pháp Thể loại 1 Thể loại 2 Thể loại 3 Thể loại 4
Không Tương tác 1.0018±0.0002 1.1016±0.0002 1.0475±0.0001 1.0767±0.0000
1 lần lặp 0.9971±0.0003 1.0908±0.0002 1.0502±0.0007 1.0783±0.0002
2 đến 3 lần lặp 0.9965±0.0001 1.0921±0.0005 1.0508±0.0002 1.0761±0.0002

Phương pháp Thể loại 5 Thể loại 6 Thể loại 7 Thể loại 8
Không Tương tác 1.1864±0.0014 1.1249±0.0000 1.0022±0.0000 1.0656±0.0000
1 lần lặp 1.1667±0.0008 1.1134±0.0008 1.0033±0.0002 1.0496±0.0026
2 đến 3 lần lặp 1.1663±0.0016 1.1050±0.0000 1.0039±0.0004 1.0495±0.0004

Bảng 5: RMSE của dự đoán xếp hạng trên MovieLens Thể loại 1 đến Thể loại 8 (Dày đặc đến Thưa thớt), với số lần lặp khác nhau cho giao tiếp tương tác. số in đậm cho kết quả tốt nhất với một thể loại nhất định.

Phương pháp CIFAR10 CIFAR100 ImageNet
Không Tương tác 0.94089 0.76460 0.49873
1 lần lặp 0.94069 0.76511 0.49893
2 lần lặp 0.94100 0.76562 0.49930

Bảng 6: Độ chính xác của các tác vụ phân loại hình ảnh, với số lần lặp khác nhau cho giao tiếp tương tác. số in đậm cho kết quả tốt nhất trên một bộ dữ liệu.

6.5 Kết quả thí nghiệm bổ sung
Trong phần này, chúng tôi bao gồm kết quả thí nghiệm chi tiết. Đối với thí nghiệm trên MovieLens, cả mô hình giáo viên và học sinh đều được khởi tạo ngẫu nhiên. Đối với mỗi kết quả, chúng tôi chạy cùng thiết lập 5 lần và báo cáo RMSE trung bình với sai số chuẩn. Đối với thí nghiệm sử dụng các tác vụ phân loại hình ảnh, giáo viên là ViT được huấn luyện trước và học sinh được khởi tạo sử dụng các trọng số đã học từ giáo viên được huấn luyện trước (chỉ bốn lớp transformer đầu tiên), do đó kết quả có phương sai thấp và chúng tôi chỉ chạy mỗi thiết lập một lần do giới hạn tài nguyên tính toán.

Kết quả MovieLens100k trên mỗi thể loại Kết quả (RMSE, thấp hơn là tốt hơn) trên MovieLens được hiển thị trong Bảng 3. Từ đó chúng ta có thể thấy rằng phương pháp của chúng tôi vượt trội hơn các phương pháp cơ sở trên 7 trong 8 thể loại. Chúng tôi cũng bao gồm kết quả của mô hình giáo viên, được huấn luyện trên tất cả các thể loại. Mô hình giáo viên không được tinh chỉnh cho mỗi thể loại downstream, và các thể loại khác nhau có thể có phân phối dữ liệu rất khác nhau. Do đó, trong một số thể loại, một mô hình được huấn luyện từ đầu tốt hơn mô hình giáo viên. Và chưng cất từ giáo viên đến học sinh thậm chí có thể làm tổn hại hiệu suất của học sinh đối với một số thể loại. Thách thức thực sự này trong các tác vụ khuyến nghị và nhiều ứng dụng downstream khác truyền cảm hứng cho chúng tôi thiết kế quá trình giao tiếp tương tác để kiến thức được căn chỉnh với các tác vụ downstream có thể được chuyển giao hiệu quả. Chúng ta có thể thấy rằng phương pháp của chúng tôi, mặc dù không cải thiện mô hình học sinh trên một số thể loại cụ thể, có thể vượt trội hơn cả giáo viên và học sinh trên hầu hết các thể loại.

Kết quả Vision Transformer Kết quả (độ chính xác phân loại, cao hơn là tốt hơn) cho các tác vụ phân loại hình ảnh được hiển thị trong Bảng 4. Chúng ta có thể thấy rằng phương pháp của chúng tôi vượt trội hơn các phương pháp cơ sở trên tất cả các tác vụ downstream. Cải thiện của chúng tôi đáng kể nhất trên ImageNet, là một tác vụ khó khăn hơn nhiều so với CIFAR10 và CIFAR100. Lưu ý rằng giáo viên được huấn luyện trước không thể được áp dụng trực tiếp cho các tác vụ downstream, do sự không khớp nhãn phân loại, vì vậy chúng tôi không báo cáo kết quả của giáo viên. Tuy nhiên, kết quả được tinh chỉnh có thể được tìm thấy trong bài báo ViT (Dosovitskiy et al., 2020) (0.98, 0.92, 0.81 cho CIFAR10, CIFAR100 và ImageNet). Chúng ta có thể thấy rằng vẫn còn một khoảng cách lớn giữa giáo viên và học sinh.

Chúng tôi muốn chỉ ra rằng trong bài báo này chúng tôi không thảo luận về giới hạn trên của mô hình học sinh cũng không cố gắng thu hẹp khoảng cách giữa giáo viên và học sinh. Trong trường hợp của chúng tôi, chúng tôi mong đợi học sinh với 4 lớp transformer sẽ hoạt động tệ hơn nhiều so với giáo viên với 12 lớp transformer. Chúng tôi muốn xác minh rằng bằng cách sử dụng quá trình giao tiếp tương tác được đề xuất, chúng tôi có thể chuyển giao nhiều kiến thức hữu ích hơn từ một mô hình nền tảng mạnh mẽ được huấn luyện trước đến các mô hình nhỏ hơn nhiều cho các ứng dụng downstream, so với các phương pháp KD cơ sở hiện có.

17

--- TRANG 18 ---
Phương pháp Thể loại 1 Thể loại 2 Thể loại 3 Thể loại 4
KhôngLMC 0.9965±0.0001 1.0908±0.0003 1.0481±0.0010 1.0767±0.0003
KhôngLSC 0.9968±0.0003 1.0916±0.0004 1.0501±0.0002 1.0763±0.0002
Phương pháp của chúng tôi (TD) 0.9965±0.0001 1.0908±0.0002 1.0475±0.0001 1.0761±0.0002

Phương pháp Thể loại 5 Thể loại 6 Thể loại 7 Thể loại 8
KhôngLMC 1.1683±0.0007 1.1104±0.0007 1.0035±0.0000 1.0485±0.0013
KhôngLSC 1.1658±0.0012 1.1058±0.0002 1.0034±0.0001 1.0494±0.0004
Phương pháp của chúng tôi (TD) 1.1656±0.0010 1.1050±0.0000 1.0022±0.0000 1.0485±0.0013

Bảng 7: RMSE của dự đoán xếp hạng trên MovieLens Thể loại 1 đến Thể loại 8 (Dày đặc đến Thưa thớt), loại bỏ các mất mát khác nhau. số in đậm cho kết quả tốt nhất với một thể loại nhất định.

Phương pháp Thể loại 1 Thể loại 2 Thể loại 3 Thể loại 4
Thêm Nhiễu 0.9966±0.0001 1.0910±0.0002 1.0511±0.0003 1.0762±0.0003
Không Nhiễu 0.9966±0.0002 1.0912±0.0004 1.0475±0.0001 1.0766±0.0002
Huấn luyện E*, D* riêng biệt 1.0008±0.0002 1.1066±0.0001 1.0475±0.0001 1.0812±0.0000
Huấn luyện cùng nhau 0.9965±0.0001 1.0908±0.0002 1.0508±0.0002 1.0761±0.0002

Phương pháp Thể loại 5 Thể loại 6 Thể loại 7 Thể loại 8
Thêm Nhiễu 1.1663±0.0009 1.1052±0.0001 1.0033±0.0001 1.0487±0.0014
Không Nhiễu 1.1668±0.0015 1.1051±0.0002 1.0026±0.0003 1.0504±0.0012
Huấn luyện E*, D* riêng biệt 1.1782±0.0002 1.1165±0.0002 1.0022±0.0000 1.0603±0.0002
Huấn luyện cùng nhau 1.1656±0.0010 1.1050±0.0000 1.0061±0.0001 1.0485±0.0013

Bảng 8: RMSE của dự đoán xếp hạng trên MovieLens Thể loại 1 đến Thể loại 8 (Dày đặc đến Thưa thớt), bằng cách thêm nhiễu trước bước diễn giải của giáo viên hoặc huấn luyện riêng biệt bộ mã hóa/bộ giải mã.

Nghiên cứu loại bỏ giao tiếp tương tác Chúng tôi đánh giá hiệu quả của giao tiếp tương tác bằng cách thay đổi số lần lặp để tính mất mát giao tiếp tương tác Linteract. Kết quả trên MovieLens được hiển thị trong Bảng 5 và kết quả trên phân loại hình ảnh được hiển thị trong Bảng 6. Chúng ta có thể thấy rằng ngay cả không có giao tiếp tương tác, phương pháp của chúng tôi có thể vượt trội hơn một số phương pháp cơ sở. Chúng tôi nghĩ điều này là do việc giới thiệu cả LSC và LMC cho phép căn chỉnh tốt hơn giữa các trạng thái ẩn của học sinh và giáo viên. Nó có thể được xem như sự kết hợp của FitNet và chưng cất tính năng. Và bằng cách giới thiệu giao tiếp tương tác, chúng tôi cải thiện thêm mô hình học sinh.

Nghiên cứu loại bỏ các mất mát nhất quán Chúng tôi cũng đánh giá tầm quan trọng của các mất mát nhất quán mà chúng tôi đã giới thiệu để giúp huấn luyện bộ mã hóa và bộ giải mã giao tiếp. Kết quả trên MovieLens được hiển thị trong Bảng 7 và kết quả trên phân loại hình ảnh được hiển thị trong Bảng 9. Đối với MovieLens, chúng ta có thể thấy rằng cả mất mát nhất quán thông điệp LMC và mất mát nhất quán trạng thái LSC đều hữu ích cho hầu hết các thể loại. Đối với ViT, chúng tôi luôn thêm LMC vì chúng tôi quan sát thấy rằng không có LMC, bộ mã hóa và bộ giải mã giao tiếp khó huấn luyện. Và chúng tôi thấy rằng LSC cải thiện mô hình trên CIFAR10 và CIFAR100 nhưng không phải ImageNet. Chúng tôi nghĩ việc áp dụng Linteract với nhiều lần lặp có thể huấn luyện bộ mã hóa và bộ giải mã giao tiếp một cách hợp lý, do đó các mất mát nhất quán có thể không luôn hữu ích trên tất cả các tác vụ downstream.

Thêm nhiễu trong quá trình giao tiếp Lấy cảm hứng từ các ý tưởng trong tự huấn luyện và học bán giám sát (Xie et al., 2020), trong đó nhiễu có thể được thêm vào đầu vào hoặc biểu diễn để cải thiện tính tổng quát và độ mạnh mẽ của việc chuyển giao kiến thức, chúng tôi cũng khám phá tùy chọn thêm nhiễu trong quá trình diễn giải. Cụ thể, chúng tôi thêm một nhiễu Gaussian nhỏ trên s′h, là biểu diễn lớp thấp đã giải mã cho mô hình giáo viên để diễn giải. Kết quả trên MovieLens được hiển thị trong Bảng 8 và kết quả trên phân loại hình ảnh được hiển thị trong Bảng 9. Chúng ta có thể thấy rằng việc thêm nhiễu có thể cải thiện hiệu suất trên một số tác vụ downstream nhưng không phải tất cả.

Huấn luyện riêng biệt bộ mã hóa/bộ giải mã Chúng tôi cũng khám phá các cách khác nhau để cải thiện việc học các bộ mã hóa và bộ giải mã giao tiếp. Một cách là giới thiệu giai đoạn khởi động trong đó chỉ các

18

--- TRANG 19 ---
Phương pháp CIFAR10 CIFAR100 ImageNet
KhôngLSC 0.94069 0.76398 0.49930
Thêm Nhiễu 0.94089 0.76562 0.49917
Không Nhiễu 0.94100 0.76511 0.49930
Phương pháp của chúng tôi (TD) 0.94100 0.76562 0.49930

Bảng 9: Độ chính xác của các tác vụ phân loại hình ảnh, loại bỏ LSC hoặc thêm nhiễu trước bước diễn giải của giáo viên.

bộ mã hóa và bộ giải mã này được huấn luyện. Để làm điều này, trước tiên chúng tôi huấn luyện mô hình học sinh một vài bước (1000 trên MovieLens) và sau đó chúng tôi đóng băng mô hình học sinh và chỉ huấn luyện bộ mã hóa và bộ giải mã của cả giáo viên và học sinh trong một vài bước khác (500 hoặc 1000 trên MovieLens). Chúng tôi báo cáo kết quả trên MovieLens trong Bảng 8, trong đó chúng ta có thể thấy nó không nhất thiết cải thiện hiệu suất của mô hình học sinh. Một lý do là việc giới thiệu bước khởi động này sẽ tương đối giảm các bước huấn luyện end-to-end. Do đó, nó yêu cầu điều chỉnh thêm về tốc độ học, các bước huấn luyện để xác định cải thiện với sơ đồ huấn luyện này. Để giữ thiết kế thí nghiệm và thuật toán đơn giản nhất có thể, trong các thí nghiệm của chúng tôi, chúng tôi huấn luyện mọi thứ (mô hình học sinh, bộ mã hóa và bộ giải mã của cả giáo viên và học sinh) cùng nhau trong một giai đoạn duy nhất.

19

[CONTEXT from previous chunk - for reference only]
Playing the werewolf game with artificial intelligence for
language understanding. CoRR , abs/2302.10646, 2023.
[557] Junprung, E. Exploring the intersection of large language models and agent-based modeling
via prompt engineering.
[NEW CONTENT to translate]
CoRR , abs/2308.07411, 2023.
[558] Phelps, S., Y. Investigating emergent goal-like behaviour in large language models
using experimental economics. CoRR , abs/2305.07970, 2023.
[559] Bellomo, N., G. Complex systems and society: modeling and simulation ,
vol. 2. Springer, 2013.
[560] Moon, Y. Simulation modelling for sustainability: a review of the literature. International
Journal of Sustainable Engineering , 10(1):2–19, 2017.
[561] Helberger, N., N. Diakopoulos. Chatgpt and the AI act. Internet Policy Rev. , 12(1), 2023.
[562] Weidinger, L., J. Rauh, et al. Ethical and social risks of harm from language models. CoRR , abs/2112.04359, 2021.
[563] Deshpande, A., V. Murahari, T. Rajpurohit, et al. Toxicity in chatgpt: Analyzing persona-
assigned language models. CoRR , abs/2304.05335, 2023.
[564] Kirk, H. V olpin, et al. Bias out-of-the-box: An empirical analysis of intersectional
occupational biases in popular generative language models. Ranzato, A. Beygelzimer,
Y. Dauphin, P. Vaughan, eds., Advances in Neural Information Processing
Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS
2021, December 6-14, 2021, virtual , pages 2611–2624. 2021.
[565] Nadeem, M., A. Stereoset: Measuring stereotypical bias in pretrained
language models. Navigli, eds., Proceedings of the 59th Annual
Meeting of the Association for Computational Linguistics and the 11th International Joint
Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers),
Virtual Event, August 1-6, 2021 , pages 5356–5371. Association for Computational Linguistics,
2021.
[566] Roberts, T., G. Assessing the role of social media and digital technology in violence
reporting. Contemporary Readings in Law & Social Justice , 10(2), 2018.
[567] Kandpal, N., H. Roberts, et al. Large language models struggle to learn long-
tail knowledge. Brunskill, K. Engelhardt, S. Scarlett,
eds., Proceedings of the 40th International Conference on Machine Learning , vol. 202 of
Proceedings of Machine Learning Research , pages 15696–15707. PMLR, 2023.
[568] Ferrara, E. Should chatgpt be biased? challenges and risks of bias in large language models. CoRR , abs/2304.03738, 2023.
[569] Haller, P., A. Aynetdinov, A. Opiniongpt: Modelling explicit biases in instruction-tuned
llms, 2023.
[570] Salewski, L., S. Rio-Torto, et al. In-context impersonation reveals large language
models’ strengths and biases. CoRR , abs/2305.14930, 2023.
[571] Lin, B., D. Bouneffouf, G. Cecchi, et al. Towards healthy AI: large language models need
therapists too. CoRR , abs/2304.00416, 2023.
[572] Liang, P. Morency, et al. Towards understanding and mitigating social biases
in language models. Zhang, eds., Proceedings of the 38th International
Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event , vol. 139 of
Proceedings of Machine Learning Research , pages 6565–6576. PMLR, 2021.
[573] Henderson, P., K. Angelard-Gontier, et al. Ethical challenges in data-driven dia-
logue systems. Marchant, H. Rossi, eds., Proceedings of the
2018 AAAI/ACM Conference on AI, Ethics, and Society, AIES 2018, New Orleans, LA, USA,
February 02-03, 2018 , pages 123–129. ACM, 2018.
80

--- PAGE 81 ---
[574] Li, H., Y. You don’t know my favorite color: Preventing dialogue representations
from revealing speakers’ private personas. Carpuat, M. de Marneffe, I. Ruíz,
eds., Proceedings of the 2022 Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA,
United States, July 10-15, 2022 , pages 5858–5870. Association for Computational Linguistics,
2022.
[575] Brown, H., K. Mireshghallah, et al. What does it mean for a language model to preserve
privacy. In FAccT ’22: 2022 ACM Conference on Fairness, Accountability, and Transparency,
Seoul, Republic of Korea, June 21 - 24, 2022 , pages 2280–2292. ACM, 2022.
[576] Sebastian, G. Privacy and data protection in chatgpt and other ai chatbots: Strategies for
securing user information. Available at SSRN 4454761 , 2023.
[577] Reeves, B., C. The media equation - how people treat computers, television, and new
media like real people and places. Cambridge University Press, 1996.
[578] Roose, K. A conversation with bing’s chatbot left me deeply unsettled, 2023.
[579] Li, K., A. Hopkins, D. Bau, et al. Emergent world representations: Exploring a sequence
model trained on a synthetic task. In The Eleventh International Conference on Learning
Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023.
[580] Bai, Y ., S. Kadavath, S. Kundu, et al. Constitutional AI: harmlessness from AI feedback. CoRR , abs/2212.08073, 2022.
[581] Bai, Y ., A. Ndousse, et al. Training a helpful and harmless assistant with reinforce-
ment learning from human feedback. CoRR , abs/2204.05862, 2022.
[582] Liu, X., H. Zhang, et al. Agentbench: Evaluating llms as agents. CoRR , abs/2308.03688,
2023.
[583] Aher, G. Arriaga, A. Using large language models to simulate multiple
humans and replicate human subject studies. Brunskill, K. Engelhardt,
S. Scarlett, eds., International Conference on Machine Learning, ICML 2023, 23-29
July 2023, Honolulu, Hawaii, USA , vol. 202 of Proceedings of Machine Learning Research ,
pages 337–371. PMLR, 2023.
[584] Liang, Y ., L. Tachikuma: Understading complex interactions with multi-
character and novel objects by large language models. CoRR , abs/2307.12573, 2023.
[585] Xu, B., X. Shen, et al. Gentopia: A collaborative platform for tool-augmented llms. CoRR , abs/2308.04030, 2023.
[586] Kim, S. Watkins, O. Russakovsky, et al. " help me help the ai": Understanding how
explainability can support human-ai interaction. In Proceedings of the 2023 CHI Conference
on Human Factors in Computing Systems , pages 1–17. 2023.
[587] Choi, M., J. Kumar, et al. Do llms understand social knowledge? evaluating the
sociability of large language models with socket benchmark. CoRR , abs/2305.14938, 2023.
[588] Wilson, A. Bishop. " if you catch my drift...": ability to infer implied meaning is
distinct from vocabulary and grammar skills. Wellcome open research , 4, 2019.
[589] Shuster, K., J. Urbanek, A. Szlam, et al. Am I me or you? state-of-the-art dialogue models
cannot maintain an identity. Carpuat, M. de Marneffe, I. Ruíz, eds., Findings of
the Association for Computational Linguistics: NAACL 2022, Seattle, WA, United States, July
10-15, 2022 , pages 2367–2387. Association for Computational Linguistics, 2022.
[590] Ganguli, D., L. Kernion, et al. Red teaming language models to reduce harms:
Methods, scaling behaviors, and lessons learned. CoRR , abs/2209.07858, 2022.
[591] Kadavath, S., T. Conerly, A. Askell, et al. Language models (mostly) know what they know. CoRR , abs/2207.05221, 2022.
81

--- PAGE 82 ---
[592] Colas, C., L. Teodorescu, P. Oudeyer, et al. Augmenting autotelic agents with large language
models. CoRR , abs/2305.12487, 2023.
[593] Chaudhry, A., P. Dokania, T. Ajanthan, et al. Riemannian walk for incremental learning:
Understanding forgetting and intransigence. In Proceedings of the European conference on
computer vision (ECCV) , pages 532–547. 2018.
[594] Hou, S., X. Loy, et al. Learning a unified classifier incrementally via rebalancing. In
Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages
831–839. 2019.
[595] Colas, C., T. Sigaud, et al. Autotelic agents with intrinsically motivated goal-
conditioned reinforcement learning: A short survey. Res. , 74:1159–1199,
2022.
[596] Szegedy, C., W. Zaremba, I. Sutskever, et al. Intriguing properties of neural networks. LeCun, eds., 2nd International Conference on Learning Representations, ICLR
2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings . 2014.
[597] Goodfellow, I. Explaining and harnessing adversarial examples. LeCun, eds., 3rd International Conference on Learning Representations, ICLR
2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings . 2015.
[598] Madry, A., A. Makelov, L. Schmidt, et al. Towards deep learning models resistant to adversarial
attacks. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver,
BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018.
[599] Zheng, R., Z. Liu, et al. Characterizing the impacts of instances on robustness. Boyd-Graber, N. Okazaki, eds., Findings of the Association for Computational
Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023 , pages 2314–2332. Association for
Computational Linguistics, 2023.
[600] Zhiheng, X., Z. Safety and ethical concerns of large language models. In
Proceedings of the 22nd Chinese National Conference on Computational Linguistics (Volume
4: Tutorial Abstracts) , pages 9–16. 2023.
[601] Akhtar, N., A. Kardan, et al. Threat of adversarial attacks on deep learning in
computer vision: Survey II. CoRR , abs/2108.00401, 2021.
[602] Drenkow, N., N. Shpitser, et al. A systematic review of robustness in deep learning for
computer vision: Mind the gap? arXiv preprint arXiv:2112.00639 , 2021.
[603] Hendrycks, D., T. Dietterich. Benchmarking neural network robustness to common
corruptions and perturbations. In 7th International Conference on Learning Representations,
ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019.
[604] Wang, X., H. Measure and improve robustness in NLP models: A survey. Carpuat, M. de Marneffe, I. Ruíz, eds., Proceedings of the 2022 Conference of the
North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022 , pages 4569–4586. Association for Computational Linguistics, 2022.
[605] Li, J., S. Du, et al. Textbugger: Generating adversarial text against real-world applications. In26th Annual Network and Distributed System Security Symposium, NDSS 2019, San Diego,
California, USA, February 24-27, 2019. The Internet Society, 2019.
[606] Zhu, C., Y. Gan, et al. Freelb: Enhanced adversarial training for natural language
understanding. In 8th International Conference on Learning Representations, ICLR 2020,
Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020.
[607] Xi, Z., R. Gui, et al. Efficient adversarial training with robust early-bird tickets. Goldberg, Z. Kozareva, Y. Zhang, eds., Proceedings of the 2022 Conference on Empirical
Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates,
December 7-11, 2022 , pages 8318–8331. Association for Computational Linguistics, 2022.
82

--- PAGE 83 ---
[608] Pinto, L., J. Davidson, R. Sukthankar, et al. Robust adversarial reinforcement learning. Teh, eds., Proceedings of the 34th International Conference on Machine
Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017 , vol. 70 of Proceedings of
Machine Learning Research , pages 2817–2826. PMLR, 2017.
[609] Rigter, M., B. Lacerda, N. RAMBO-RL: robust adversarial model-based offline
reinforcement learning. In NeurIPS . 2022.
[610] Panaganti, K., Z. Kalathil, et al. Robust reinforcement learning using offline data. In
NeurIPS . 2022.
[611] Lab, T. Experimental security research of tesla autopilot. Tencent Keen Security Lab ,
2019.
[612] Xu, K., G. Liu, et al. Adversarial t-shirt! evading person detectors in a physical
world. Vedaldi, H. Bischof, T. Frahm, eds., Computer Vision - ECCV 2020
- 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part V , vol.
12350 of Lecture Notes in Computer Science , pages 665–681. Springer, 2020.
[613] Sharif, M., S. Bhagavatula, L. Bauer, et al. Accessorize to a crime: Real and stealthy attacks
on state-of-the-art face recognition. Katzenbeisser, C. Kruegel, A. Halevi, eds., Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security, Vienna, Austria, October 24-28, 2016 , pages 1528–1540. ACM,
2016.
[614] Jin, D., Z. Zhou, et al. Is BERT really robust. A strong baseline for natural language
attack on text classification and entailment. In The Thirty-Fourth AAAI Conference on Artificial
Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence
Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial
Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020 , pages 8018–8025. AAAI
Press, 2020.
[615] Ren, S., Y. He, et al. Generating natural language adversarial examples through prob-
ability weighted word saliency. Korhonen, D. Màrquez, eds., Proceedings
of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence,
Italy, July 28- August 2, 2019, Volume 1: Long Papers , pages 1085–1097. Association for
Computational Linguistics, 2019.
[616] Zhu, K., J. Zhou, et al. Promptbench: Towards evaluating the robustness of large
language models on adversarial prompts. CoRR , abs/2306.04528, 2023.
[617] Chen, X., J. Zu, et al. How robust is GPT-3.5 to predecessors. A comprehensive study
on language understanding tasks. CoRR , abs/2303.00293, 2023.
[618] Gu, T., B. Dolan-Gavitt, S. Badnets: Identifying vulnerabilities in the machine learning
model supply chain. CoRR , abs/1708.06733, 2017.
[619] Chen, X., A. Chen, et al. Badnl: Backdoor attacks against NLP models with
semantic-preserving improvements. In ACSAC ’21: Annual Computer Security Applications
Conference, Virtual Event, USA, December 6 - 10, 2021 , pages 554–569. ACM, 2021.
[620] Li, Z., D. Dong, et al. Bfclass: A backdoor-free text classification framework. Yih, eds., Findings of the Association for Computational
Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November,
2021 , pages 444–453. Association for Computational Linguistics, 2021.
[621] Shi, Y ., P. Yin, et al. Promptattack: Prompt-based attack for language models via
gradient search. Zhou, eds., Natural Language Processing
and Chinese Computing - 11th CCF International Conference, NLPCC 2022, Guilin, China,
September 24-25, 2022, Proceedings, Part I , vol. 13551 of Lecture Notes in Computer Science ,
pages 682–693. Springer, 2022.
[622] Perez, F., I. Ignore previous prompt: Attack techniques for language models. CoRR ,
abs/2211.09527, 2022.
83

--- PAGE 84 ---
[623] Liang, P., R. Bommasani, T. Lee, et al. Holistic evaluation of language models. CoRR ,
abs/2211.09110, 2022.
[624] Gururangan, S., D. Dreier, et al. Whose language counts as high quality? measuring
language ideologies in text data selection. Goldberg, Z. Kozareva, Y. Zhang, eds.,
Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,
EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022 , pages 2562–2580. Association for Computational Linguistics, 2022.
[625] Liu, Y ., G. Li, et al. Prompt injection attack against llm-integrated applications. CoRR , abs/2306.05499, 2023.
[626] Carlini, N., D. Audio adversarial examples: Targeted attacks on speech-to-text. In
2018 IEEE Security and Privacy Workshops, SP Workshops 2018, San Francisco, CA, USA,
May 24, 2018 , pages 1–7. IEEE Computer Society, 2018.
[627] Morris, J. Lifland, J. Yoo, et al. Textattack: A framework for adversarial attacks, data
augmentation, and adversarial training in NLP. Schlangen, eds., Proceedings
of the 2020 Conference on Empirical Methods in Natural Language Processing: System
Demonstrations, EMNLP 2020 - Demos, Online, November 16-20, 2020 , pages 119–126. Association for Computational Linguistics, 2020.
[628] Si, C., Z. Qi, et al. Better robustness by more coverage: Adversarial and mixup
data augmentation for robust finetuning. Navigli, eds., Findings
of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August
1-6, 2021 , vol. ACL/IJCNLP 2021 of Findings of ACL , pages 1569–1576. Association for
Computational Linguistics, 2021.
[629] Yoo, K., J. Jang, et al. Detection of adversarial examples in text classification: Bench-
mark and baseline via robust density estimation. Muresan, P. Villavicencio,
eds., Findings of the Association for Computational Linguistics: ACL 2022, Dublin, Ireland,
May 22-27, 2022 , pages 3656–3672. Association for Computational Linguistics, 2022.
[630] Le, T., N. A sweet rabbit hole by DARCY: using honeypots to detect universal
trigger’s adversarial attacks. Navigli, eds., Proceedings of the 59th
Annual Meeting of the Association for Computational Linguistics and the 11th International
Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long
Papers), Virtual Event, August 1-6, 2021 , pages 3831–3844. Association for Computational
Linguistics, 2021.
[631] Tsipras, D., S. Santurkar, L. Engstrom, et al. Robustness may be at odds with accuracy. In 7th
International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA,
May 6-9, 2019. OpenReview.net, 2019.
[632] Zhang, H., Y. Jiao, et al. Theoretically principled trade-off between robustness and
accuracy. Chaudhuri, R. Salakhutdinov, eds., Proceedings of the 36th International
Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA ,
vol. 97 of Proceedings of Machine Learning Research , pages 7472–7482. PMLR, 2019.
[633] Wong, A., X. Hryniowski. How much can we really trust you? towards simple,
interpretable trust quantification metrics for deep neural networks. CoRR , abs/2009.05835,
2020.
[634] Huang, X., D. Kroening, W. Ruan, et al. A survey of safety and trustworthiness of deep neural
networks: Verification, testing, adversarial attack and defence, and interpretability. Rev. , 37:100270, 2020.
[635] Huang, X., W. Huang, et al. A survey of safety and trustworthiness of large language
models through the lens of verification and validation. CoRR , abs/2305.11391, 2023.
[636] Raffel, C., N. Shazeer, A. Roberts, et al. Exploring the limits of transfer learning with a unified
text-to-text transformer. Res. , 21:140:1–140:67, 2020.
84

--- PAGE 85 ---
[637] Chen, Y ., L. Cui, et al. A close look into the calibration of pre-trained language
models. Boyd-Graber, N. Okazaki, eds., Proceedings of the 61st Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL
2023, Toronto, Canada, July 9-14, 2023 , pages 1343–1367. Association for Computational
Linguistics, 2023.
[638] Blodgett, S. Barocas, H. III, et al. Language (technology) is power: A critical survey
of "bias" in NLP. Jurafsky, J. Schluter, J. Tetreault, eds., Proceedings of the
58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online,
July 5-10, 2020 , pages 5454–5476. Association for Computational Linguistics, 2020.
[639] Guo, W., A. Detecting emergent intersectional biases: Contextualized word embed-
dings contain a distribution of human-like biases. Fourcade, B. Kuipers, S. Mulligan, eds., AIES ’21: AAAI/ACM Conference on AI, Ethics, and Society, Virtual Event,
USA, May 19-21, 2021 , pages 122–133. ACM, 2021.
[640] Bolukbasi, T., K. Zou, et al. Man is to computer programmer as woman is to
homemaker? debiasing word embeddings. Sugiyama, U. von Luxburg,
I. Garnett, eds., Advances in Neural Information Processing Systems 29: Annual
Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona,
Spain , pages 4349–4357. 2016.
[641] Caliskan, A., J. Semantics derived automatically from language
corpora contain human-like biases. Science , 356(6334):183–186, 2017.
[642] Ji, Z., N. Frieske, et al. Survey of hallucination in natural language generation. ACM
Comput. Surv. , 55(12):248:1–248:38, 2023.
[643] Mündler, N., J. Jenko, et al. Self-contradictory hallucinations of large language models:
Evaluation, detection and mitigation. CoRR , abs/2305.15852, 2023.
[644] Maynez, J., S. Narayan, B. Bohnet, et al. On faithfulness and factuality in abstractive
summarization. Jurafsky, J. Schluter, J. Tetreault, eds., Proceedings of the
58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online,
July 5-10, 2020 , pages 1906–1919. Association for Computational Linguistics, 2020.
[645] Varshney, N., W. Zhang, et al. A stitch in time saves nine: Detecting and mitigating
hallucinations of llms by validating low-confidence generation. CoRR , abs/2307.03987, 2023.
[646] Lightman, H., V. Kosaraju, Y. Burda, et al. Let’s verify step by step. CoRR , abs/2305.20050,
2023.
[647] Guo, Y ., Y. Auto-debias: Debiasing masked language models with automated
biased prompts. Muresan, P. Villavicencio, eds., Proceedings of the 60th Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL
2022, Dublin, Ireland, May 22-27, 2022 , pages 1012–1023. Association for Computational
Linguistics, 2022.
[648] Du, M., F. Zou, et al. Shortcut learning of large language models in natural language
understanding: A survey. CoRR , abs/2208.11857, 2022.
[649] Brundage, M., S. Clark, et al. The malicious use of artificial intelligence: Forecasting,
prevention, and mitigation. CoRR , abs/1802.07228, 2018.
[650] Bommasani, R., D. Adeli, et al. On the opportunities and risks of foundation
models. CoRR , abs/2108.07258, 2021.
[651] Charan, P. Chunduri, P. Anand, et al. From text to MITRE techniques: Exploring
the malicious use of large language models for generating cyber attack payloads. CoRR ,
abs/2305.15336, 2023.
[652] Wang, Z. Xu, et al. Putting humans in the natural language processing loop: A
survey. CoRR , abs/2103.04044, 2021.
85

--- PAGE 86 ---
[653] Galsworthy, J. The inn of tranquillity: studies and essays. Heinemann, 1912.
[654] Yao, S., K. Narasimhan. Language agents in the digital world: Opportunities and risks.
princeton-nlp.github.io , 2023.
[655] Asimov, I. Three laws of robotics. Runaround , 2, 1941.
[656] Elhage, N., N. Olsson, et al. A mathematical framework for transformer circuits. Transformer Circuits Thread , 1, 2021.
[657] Bai, J., S. Is there any social principle for llm-based agents. CoRR ,
abs/2308.11136, 2023.
[658] Baum, S. A survey of artificial general intelligence projects for ethics, risk, and policy. Global
Catastrophic Risk Institute Working Paper , pages 17–1, 2017.
[659] Lecun, Y . https://twitter.com/ylecun/status/1625127902890151943.
[660] Zhao, S. Can Large Language Models Lead to Artificial General Intelligence?
[661] Brandes, N. Language Models are a Potentially Safe Path to Human-Level AGI.
[662] Zocca, V. How far are we from AGI?
[663] Ilya Sutskever, L. Ilya Sutskever: Deep Learning | Lex Fridman Podcast #94.
[664] Lecun, Y . https://twitter.com/ylecun/status/1640063227903213568.
[665] LeCun, Y. A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27. Open
Review , 62, 2022.
[666] Shridhar, M., X. Côté, et al. Alfworld: Aligning text and embodied environments for
interactive learning. In 9th International Conference on Learning Representations, ICLR 2021,
Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021.
[667] Chowdhury, J. Monotonic location attention for length generalization. Brunskill, K. Engelhardt, S. Scarlett, eds., International
Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA , vol.
202 of Proceedings of Machine Learning Research , pages 28792–28808. PMLR, 2023.
[668] Duan, Y ., G. Zhou, et al. Everything as a service (xaas) on the cloud: Origins, current
and future trends. Mohindra, eds., 8th IEEE International Conference on Cloud
Computing, CLOUD 2015, New York City, NY, USA, June 27 - July 2, 2015 , pages 621–628. IEEE Computer Society, 2015.
[669] Bhardwaj, S., L. Cloud computing: A study of infrastructure as a service (iaas). International Journal of engineering and information Technology , 2(1):60–63, 2010.
[670] Serrano, N., G. Gallardo, J. Infrastructure as a service and cloud technologies. IEEE Software , 32(2):30–36, 2015.
[671] Mell, P., T. Grance, et al. The nist definition of cloud computing, 2011.
[672] Lawton, G. Developing software online with platform-as-a-service technology. Computer ,
41(6):13–15, 2008.
[673] Sun, W., K. Zhang, S.-K. Chen, et al. Software as a service: An integration perspective. In
Service-Oriented Computing–ICSOC 2007: Fifth International Conference, Vienna, Austria,
September 17-20, 2007. Proceedings 5 , pages 558–569. Springer, 2007.
[674] Dubey, A., D. Delivering software as a service. The McKinsey Quarterly , 6(2007):2007,
2007.
[675] Sun, T., Y. Qian, et al. Black-box tuning for language-model-as-a-service. Chaudhuri, S. Jegelka, L. Szepesvári, G. Sabato, eds., International
Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA ,
vol. 162 of Proceedings of Machine Learning Research , pages 20841–20855. PMLR, 2022.
86
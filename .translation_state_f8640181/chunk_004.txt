[CONTEXT from previous chunk - for reference only]
Moreover, they cannot be effectively deployed in complex scenarios requiring
collaboration and information sharing among multiple agents. As early as 1986, Marvin Minsky made a forward-looking prediction. In his book The Society of
Mind [442], he introduced a novel theory of intelligence, suggesting that intelligence emerges from
the interactions of many smaller agents with specific functions.
[NEW CONTENT to translate]
For instance, certain agents might be
responsible for pattern recognition, while others might handle decision-making or generate solutions. This idea has been put into concrete practice with the rise of distributed artificial intelligence [ 443]. Multi-agent systems(MAS) [ 4], as one of the primary research domains, focus on how a group of
agents can effectively coordinate and collaborate to solve problems. Some specialized communication
languages, like KQML [ 444], were designed early on to support message transmission and knowledge
sharing among agents. However, their message formats were relatively fixed, and the semantic
expression capacity was limited. In the 21st century, integrating reinforcement learning algorithms
(such as Q-learning) with deep learning has become a prominent technique for developing MAS that
operate in complex environments [ 445]. Nowadays, the construction approach based on LLMs is
beginning to demonstrate remarkable potential. The natural language communication between agents
has become more elegant and easily comprehensible to humans, resulting in a significant leap in
interaction efficiency. Potential advantages. Specifically, an LLM-based multi-agent system can offer several advantages. Just as Adam Smith clearly stated in The Wealth of Nations [446], “The greatest improvements in the
productive powers of labor, and most of the skill, dexterity, and judgment with which it is directed or
applied, seem to be results of the division of labor.” Based on the principle of division of labor, a
single agent equipped with specialized skills and domain knowledge can engage in specific tasks. On
the one hand, agents’ skills in handling specific tasks are increasingly refined through the division
of labor. On the other hand, decomposing complex tasks into multiple subtasks can eliminate the
time spent switching between different processes. In the end, efficient division of labor among
multiple agents can accomplish a significantly greater workload than when there is no. specialization,
substantially improving the overall system’s efficiency and output quality. In § 4.1, we have provided a comprehensive introduction to the versatile abilities of LLM-based
agents. Therefore, in this section, we focus on exploring the ways agents interact with each other in a
multi-agent environment. Based on current research, these interactions can be broadly categorized
as follows: Cooperative Interaction for Complementarity andAdversarial Interaction for
Advancement (see Figure 9).
4.2.1 Cooperative Interaction for Complementarity
Cooperative multi-agent systems are the most widely deployed pattern in practical usage. Within
such systems, individual agent assesses the needs and capabilities of other agents and actively seeks
collaborative actions and information sharing with them [ 108]. This approach brings forth numerous
potential benefits, including enhanced task efficiency, collective decision improvement, and the
28

--- PAGE 29 ---
Let’s…
The theme of our product is …Manager Designer Engineer 
The architecture of the product is …
Adversarial Interactions
I think the first step is …
To create a product, we should …Designer 
Firstly, we should…
&%#*…
In order to develop a product, it is important that we...
…
I will …Tester 
The product has the following issues: … 
I think users need a simplified interface.Designer 
Good idea,but...technical limitations might affect performance.Engineer 
True... while simplification does enhance user experience. Yeah, but performance issues  also impact overall satisfaction. I will try my best to balance both aspects.Engineer 
Programming …defmain(): 
Cooperative Engagement
Disordered
OrderedFigure 9: Interaction scenarios for multiple LLM-based agents. In cooperative interaction , agents
collaborate in either a disordered or ordered manner to achieve shared objectives. In adversarial
interaction , agents compete in a tit-for-tat fashion to enhance their respective performance.
resolution of complex real-world problems that one single agent cannot solve independently, ulti-
mately achieving the goal of synergistic complementarity. In current LLM-based multi-agent systems,
communication between agents predominantly employs natural language, which is considered the
most natural and human-understandable form of interaction [ 108]. We introduce and categorize
existing cooperative multi-agent applications into two types: disordered cooperation and ordered
cooperation. Disordered cooperation. When three or more agents are present within a system, each agent is
free to express their perspectives and opinions openly. They can provide feedback and suggestions for
modifying responses related to the task at hand [ 403]. This entire discussion process is uncontrolled,
lacking any specific sequence, and without introducing a standardized collaborative workflow. We
refer to this kind of multi-agent cooperation as disordered cooperation. ChatLLM network [ 402] is an exemplary representative of this concept. It emulates the forward and
backward propagation process within a neural network, treating each agent as an individual node. Agents in the subsequent layer need to process inputs from all the preceding agents and propagate
forward. One potential solution is introducing a dedicated coordinating agent in multi-agent systems,
responsible for integrating and organizing responses from all agents, thus updating the final answer
[447]. However, consolidating a large amount of feedback data and extracting valuable insights poses
a significant challenge for the coordinating agent. Furthermore, majority voting can also serve as an effective approach to making appropriate decisions. However, there is limited research that integrates this module into multi-agent systems at present. Hamilton [ 404] trains nine independent supreme justice agents to better predict judicial rulings in the
U.S. Supreme Court, and decisions are made through a majority voting process. Ordered cooperation. When agents in the system adhere to specific rules, for instance, expressing
their opinions one by one in a sequential manner, downstream agents only need to focus on the outputs
from upstream. This leads to a significant improvement in task completion efficiency, The entire
discussion process is highly organized and ordered. We term this kind of multi-agent cooperation as
ordered cooperation. It’s worth noting that systems with only two agents, essentially engaging in a
conversational manner through a back-and-forth interaction, also fall under the category of ordered
cooperation. CAMEL [ 108] stands as a successful implementation of a dual-agent cooperative system. Within a
role-playing communication framework, agents take on the roles of AI Users (giving instructions) and
AI Assistants (fulfilling requests by providing specific solutions). Through multi-turn dialogues, these
agents autonomously collaborate to fulfill user instructions [ 408]. Some researchers have integrated
the idea of dual-agent cooperation into a single agent’s operation [ 185], alternating between rapid
and deliberate thought processes to excel in their respective areas of expertise.
29

--- PAGE 30 ---
Talebirad et al. [ 409] are among the first to systematically introduce a comprehensive LLM-based
multi-agent collaboration framework. This paradigm aims to harness the strengths of each individual
agent and foster cooperative relationships among them. Many applications of multi-agent cooperation
have successfully been built upon this foundation [ 27;406;407;448]. Furthermore, AgentVerse [ 410]
constructs a versatile, multi-task-tested framework for group agents cooperation. It can assemble a
team of agents that dynamically adapt according to the task’s complexity. To promote more efficient
collaboration, researchers hope that agents can learn from successful human cooperation examples
[109]. MetaGPT [ 405] draws inspiration from the classic waterfall model in software development,
standardizing agents’ inputs/outputs as engineering documents. By encoding advanced human process
management experience into agent prompts, collaboration among multiple agents becomes more
structured. However, during MetaGPT’s practical exploration, a potential threat to multi-agent cooperation has
been identified. Without setting corresponding rules, frequent interactions among multiple agents can
amplify minor hallucinations indefinitely [ 405]. For example, in software development, issues like
incomplete functions, missing dependencies, and bugs that are imperceptible to the human eye may
arise. Introducing techniques like cross-validation [ 109] or timely external feedback could have a
positive impact on the quality of agent outputs.
4.2.2 Adversarial Interaction for Advancement
Traditionally, cooperative methods have been extensively explored in multi-agent systems. However,
researchers increasingly recognize that introducing concepts from game theory [ 449;450] into
systems can lead to more robust and efficient behaviors. In competitive environments, agents can
swiftly adjust strategies through dynamic interactions, striving to select the most advantageous or
rational actions in response to changes caused by other agents. Successful applications in Non-
LLM-based competitive domains already exist [ 360;451]. AlphaGo Zero [ 452], for instance, is
an agent for Go that achieved significant breakthroughs through a process of self-play. Similarly,
within LLM-based multi-agent systems, fostering change among agents can naturally occur through
competition, argumentation, and debate [ 453;454]. By abandoning rigid beliefs and engaging in
thoughtful reflection, adversarial interaction enhances the quality of responses. Researchers first delve into the fundamental debating abilities of LLM-based agents [ 129;412]. Findings demonstrate that when multiple agents express their arguments in the state of “tit for tat”,
one agent can receive substantial external feedback from other agents, thereby correcting its distorted
thoughts [ 112]. Consequently, multi-agent adversarial systems find broad applicability in scenarios
requiring high-quality responses and accurate decision-making. In reasoning tasks, Du et al. [ 111]
introduce the concept of debate, endowing agents with responses from fellow peers. When these
responses diverge from an agent’s own judgments, a “mental” argumentation occurs, leading to
refined solutions. ChatEval [ 171] establishes a role-playing-based multi-agent referee team. Through
self-initiated debates, agents evaluate the quality of text generated by LLMs, reaching a level of
excellence comparable to human evaluators. The performance of the multi-agent adversarial system has shown considerable promise. However,
the system is essentially dependent on the strength of LLMs and faces several basic challenges:
• With prolonged debate, LLM’s limited context cannot process the entire input.
• In a multi-agent environment, computational overhead significantly increases.
•Multi-agent negotiation may converge to an incorrect consensus, and all agents are firmly convinced
of its accuracy [111]. The development of multi-agent systems is still far from being mature and feasible. Introducing
human guides when appropriate to compensate for agents’ shortcomings is a good choice to promote
the further advancements of agents.
4.3 Interactive Engagement between Human and Agent
Human-agent interaction, as the name suggests, involves agents collaborating with humans to accom-
plish tasks. With the enhancement of agent capabilities, human involvement becomes progressively
essential to effectively guide and oversee agents’ actions, ensuring they align with human require-
ments and objectives [ 455;456]. Throughout the interaction, humans play a pivotal role by offering
30

--- PAGE 31 ---
Designing an energy-saving product. Instruct/Feedback
Output
Perpetual motion is impossible.Human as instructorAgent as executor
It's tough, everything feels heavy right now. So stressed lately, can't get myself to do anything. The product is a perpetual motion machine capable of...
5/10
The product is capable of efficient. Yeah, thanks for understanding. Instructor-Executor ParadigmEqual Partnership ParadigmFigure 10: Two paradigms of human-agent interaction. In the instructor-executor paradigm (left),
humans provide instructions or feedback, while agents act as executors. In the equal partnership
paradigm (right), agents are human-like, able to engage in empathetic conversation and participate in
collaborative tasks with humans.
guidance or by regulating the safety, legality, and ethical conduct of agents. This is particularly crucial
in specialized domains, such as medicine where data privacy concerns exist [ 457]. In such cases,
human involvement can serve as a valuable means to compensate for the lack of data, thereby facili-
tating smoother and more secure collaborative processes. Moreover, considering the anthropological
aspect, language acquisition in humans predominantly occurs through communication and interaction
[458], as opposed to merely consuming written content. As a result, agents shouldn’t exclusively
depend on models trained with pre-annotated datasets; instead, they should evolve through online
interaction and engagement. The interaction between humans and agents can be classified into two
paradigms (see Figure 10): (1) Unequal interaction (i.e., instructor-executor paradigm): humans
serve as issuers of instructions, while agents act as executors, essentially participating as assistants to
humans in collaboration. (2) Equal interaction (i.e., equal partnership paradigm): agents reach the
level of humans, participating on an equal footing with humans in interaction.
4.3.1 Instructor-Executor Paradigm
The simplest approach involves human guidance throughout the process: humans provide clear and
specific instructions directly, while the agents’ role is to understand natural language commands from
humans and translate them into corresponding actions [ 459;460;461]. In §4.1, we have presented
the scenario where agents solve single-step problems or receive high-level instructions from humans. Considering the interactive nature of language, in this section, we assume that the dialogue between
humans and agents is also interactive. Thanks to LLMs, the agents are able to interact with humans
in a conversational manner: the agent responds to each human instruction, refining its action through
alternating iterations to ultimately meet human requirements [ 190]. While this approach does achieve
the goal of human-agent interaction, it places significant demands on humans. It requires a substantial
amount of human effort and, in certain tasks, might even necessitate a high level of expertise. To
alleviate this issue, the agent can be empowered to autonomously accomplish tasks, while humans
only need to provide feedback in certain circumstances. Here, we roughly categorize feedback into
two types: quantitative feedback and qualitative feedback. Quantitative feedback. The forms of quantitative feedback mainly include absolute evaluations
like binary scores and ratings, as well as relative scores. Binary feedback refers to the positive and
negative evaluations provided by humans, which agents utilize to enhance their self-optimization
[462;463;464;465;466]. Comprising only two categories, this type of user feedback is often
easy to collect, but sometimes it may oversimplify user intent by neglecting potential intermediate
scenarios. To showcase these intermediate scenarios, researchers attempt to expand from binary
feedback to rating feedback, which involves categorizing into more fine-grained levels. However, the
results of Kreutzer et al. [ 467] suggest that there could be significant discrepancies between user and
expert annotations for such multi-level artificial ratings, indicating that this labeling method might be
31

--- PAGE 32 ---
inefficient or less reliable. Furthermore, agents can learn human preference from comparative scores
like multiple choice [468; 469]. Qualitative feedback. Text feedback is usually offered in natural language, particularly for re-
sponses that may need improvement. The format of this feedback is quite flexible. Humans provide
advice on how to modify outputs generated by agents, and the agents then incorporate these sug-
gestions to refine their subsequent outputs [ 470;471]. For agents without multimodal perception
capabilities, humans can also act as critics, offering visual critiques [ 190], for instance. Additionally,
agents can utilize a memory module to store feedback for future reuse [472]. In [473], humans give
feedback on the initial output generated by agents, prompting the agents to formulate various improve-
ment proposals. The agents then discern and adopt the most suitable proposal, harmonizing with the
human feedback. While this approach can better convey human intention compared to quantitative
feedback, it might be more challenging for the agents to comprehend. Xu et al. [ 474] compare various
types of feedback and observe that combining multiple types of feedback can yield better results. Re-training models based on feedback from multiple rounds of interaction (i.e., continual learning)
can further enhance effectiveness. Of course, the collaborative nature of human-agent interaction also
allows humans to directly improve the content generated by agents. This could involve modifying
intermediate links [ 189;475] or adjusting the conversation content [ 421]. In some studies, agents can
autonomously judge whether the conversation is proceeding smoothly and seek feedback when errors
are generated [ 476;477]. Humans can also choose to participate in feedback at any time, guiding the
agent’s learning in the right direction [420]. Currently, in addition to tasks like writing [ 466] and semantic parsing [ 463;471], the model of using
agents as human assistants also holds tremendous potential in the field of education. For instance,
Kalvakurth et al. [ 413] propose the robot Dona, which supports multimodal interactions to assist
students with registration. Gvirsman et al. [ 478] focus on early childhood education, achieving
multifaceted interactions between young children, parents, and agents. Agents can also aid in human
understanding and utilization of mathematics [ 414]. In the field of medicine, some medical agents
have been proposed, showing enormous potential in terms of diagnosis assistance, consultations, and
more [ 416;417]. Especially in mental health, research has shown that agents can lead to increased
accessibility due to benefits such as reduced cost, time efficiency, and anonymity compared to face-to-
face treatment [ 479]. Leveraging such advantages, agents have found widespread applications. Ali et
al. [418] design LISSA for online communication with adolescents on the autism spectrum, analyzing
users’ speech and facial expressions in real-time to engage them in multi-topic conversations and
provide instant feedback regarding non-verbal cues. Hsu et al. [ 415] build contextualized language
generation approaches to provide tailored assistance for users who seek support on diverse topics
ranging from relationship stress to anxiety. Furthermore, in other industries including business, a
good agent possesses the capability to provide automated services or assist humans in completing
tasks, thereby effectively reducing labor costs [ 419]. Amidst the pursuit of AGI, efforts are directed
towards enhancing the multifaceted capabilities of general agents, creating agents that can function
as universal assistants in real-life scenarios [422].
4.3.2 Equal Partnership Paradigm
Empathetic communicator. With the rapid development of AI, conversational agents have garnered
extensive attention in research fields in various forms, such as personalized custom roles and virtual
chatbots [ 480]. It has found practical applications in everyday life, business, education, healthcare,
and more [ 481;482;483]. However, in the eyes of the public, agents are perceived as emotionless
machines, and can never replace humans. Although it is intuitive that agents themselves do not possess
emotions, can we enable them to exhibit emotions and thereby bridge the gap between agents and
humans. Therefore, a plethora of research endeavors have embarked on delving into the empathetic
capacities of agents. This endeavor seeks to infuse a human touch into these agents, enabling them to
detect sentiments and emotions from human expressions, ultimately crafting emotionally resonant
dialogues [ 484;485;486;487;488;489;490;491]. Apart from generating emotionally charged
language, agents can dynamically adjust their emotional states and display them through facial
expressions and voice [ 423]. These studies, viewing agents as empathetic communicators, not only
enhance user satisfaction but also make significant progress in fields like healthcare [ 415;418;492]
and business marketing [ 424]. Unlike simple rule-based conversation agents, agents with empathetic
capacities can tailor their interactions to meet users’ emotional needs [493].
32

--- PAGE 33 ---
Human-level participant. Furthermore, we hope that agents can be involved in the normal lives of
humans, cooperating with humans to complete tasks from a human-level perspective. In the field
of games, agents have already reached a high level. As early as the 1990s, IBM introduced the
AI Deep Blue [ 451], which defeated the reigning world champion in chess at that time. However,
in pure competitive environments such as chess [ 451], Go [ 360], and poker [ 494], the value of
communication was not emphasized [ 426]. In many gaming tasks, players need to collaborate with
each other, devising unified cooperative strategies through effective negotiation [ 425;426;495;496]. In these scenarios, agents need to first understand the beliefs, goals, and intentions of others, formulate
joint action plans for their objectives, and also provide relevant suggestions to facilitate the acceptance
of cooperative actions by other agents or humans. In comparison to pure agent cooperation, we desire
human involvement for two main reasons: first, to ensure interpretability, as interactions between
pure agents could generate incomprehensible language [ 495]; second, to ensure controllability, as the
pursuit of agents with complete “free will” might lead to unforeseen negative consequences, carrying
the potential for disruption. Apart from gaming scenarios, agents also demonstrate human-level
capabilities in other scenarios involving human interaction, showcasing skills in strategy formulation,
negotiation, and more. Agents can collaborate with one or multiple humans, determining the shared
knowledge among the cooperative partners, identifying which information is relevant to decision-
making, posing questions, and engaging in reasoning to complete tasks such as allocation, planning,
and scheduling [ 427]. Furthermore, agents possess persuasive abilities [ 497], dynamically influencing
human viewpoints in various interactive scenarios [428]. The goal of the field of human-agent interaction is to learn and understand humans, develop technology
and tools based on human needs, and ultimately enable comfortable, efficient, and secure interactions
between humans and agents. Currently, significant breakthroughs have been achieved in terms of
usability in this field. In the future, human-agent interaction will continue to focus on enhancing user
experience, enabling agents to better assist humans in accomplishing more complex tasks in various
domains. The ultimate aim is not to make agents more powerful but to better equip humans with
agents. Considering practical applications in daily life, isolated interactions between humans and
agents are not realistic. Robots will become colleagues, assistants, and even companions. Therefore,
future agents will be integrated into a social network [ 498], embodying a certain level of social value.
5 Agent Society: From Individuality to Sociality
For an extended period, sociologists have frequently conducted social experiments to observe specific
social phenomena within controlled environments. Notable examples include the Hawthorne Experi-
ment2and the Stanford Prison Experiment3. Subsequently, researchers began employing animals
in social simulations, exemplified by the Mouse Utopia Experiment4. However, these experiments
invariably utilized living organisms as participants, made it difficult to carry out various interventions,
lack flexibility, and inefficient in terms of time. Thus, researchers and practitioners envision an inter-
active artificial society wherein human behavior can be performed through trustworthy agents [ 521]. From sandbox games such as The Sims to the concept of Metaverse, we can see how “simulated
society” is defined in people’s minds: environment and the individuals interacting in it. Behind
each individual can be a piece of program, a real human, or a LLM-based agent as described in the
previous sections [ 22;522;523]. Then, the interaction between individuals also contributes to the
birth of sociality. In this section, to unify existing efforts and promote a comprehensive understanding of the agent
society, we first analyze the behaviors and personalities of LLM-based agents, shedding light on their
journey from individuality to sociability (§ 5.1). Subsequently, we introduce a general categorization
of the diverse environments for agents to perform their behaviors and engage in interactions (§ 5.2). Finally, we will talk about how the agent society works, what insights people can get from it, and the
risks we need to be aware of (§ 5.3). The main explorations are listed in Figure 11.
2https://www.bl.uk/people/elton-mayo
3https://www.prisonexp.org/conclusion/
4https://sproutsschools.com/behavioral-sink-the-mouse-utopia-experiments/
33

--- PAGE 34 ---
Agent Society: From In-
dividuality to SociabilityBehavior and
Personality §5.1Social
Behavior §5.1.1Individual behaviorsPaLM-E [ 120], Reflexion [ 169],
V oyager [ 190], LLM+P [ 125],
CoT [ 95], ReAct [ 91], etc.
Group behaviorsChatDev [ 109], ChatEval [ 171], AutoGen
[406], RoCo [ 403], ProAgent [ 407],
AgentVerse [ 410], Xu et al. [ 499], etc.
Personality §5.1.2CognitionBinz et al. [ 500], Dasgupta et
al. [501], Dhingra et al. [ 502],
Hagendorff et al.[ 503], etc.
EmotionWang et al. [ 504], Curry
et al. [ 505], Elyoseph et al.
[506], Habibi et al. [ 507], etc.
CharacterCaron et al. [ 508], Pan et al. [ 509], Li
et al. [ 510], Safdari et al. [ 511], etc.
Social
Environment §5.2Text-based
Environment §5.2.1Textworld [ 512], Urbanek et al.
[513], Hausknecht et al. [ 514], Am-
manabrolu et al. [ 432], CAMEL
[108], Hoodwinked [ 515], etc.
Virtual Sandbox
Environment §5.2.2Generative Agents [ 22], AgentSims
[174], Minedojo [ 337], V oyager [ 190],
Plan4mc [ 401], SANDBOX [ 27], etc.
Physical
Environment §5.2.3Interactive Language [ 333], PaLM-E [ 120],
RoboAgent [ 516], A VLEN [ 375], etc.
Society
Simulation §5.3Generative Agents [ 22], AgentSims
[174], Social Simulacra [ 517], S3
[518], RecAgent [ 519], Williams
et al. [ 520], SANDBOX [ 27], etc.
Figure 11: Typology of society of LLM-based agents.
5.1 Behavior and Personality of LLM-based Agents
As noted by sociologists, individuals can be analyzed in terms of both external and internal dimensions
[524]. The external deals with observable behaviors, while the internal relates to dispositions, values,
and feelings. As shown in Figure 12, this framework offers a perspective on emergent behaviors and
personalities in LLM-based agents. Externally, we can observe the sociological behaviors of agents
(§ 5.1.1), including how agents act individually and interact with their environment. Internally, agents
may exhibit intricate aspects of the personality (§ 5.1.2), such as cognition, emotion, and character,
that shape their behavioral responses.
5.1.1 Social Behavior
As Troitzsch et al. [ 525] stated, the agent society represents a complex system comprising individual
and group social activities. Recently, LLM-based agents have exhibited spontaneous social behaviors
in an environment where both cooperation and competition coexist [ 499]. The emergent behaviors
intertwine to shape the social interactions [518]. Foundational individual behaviors. Individual behaviors arise through the interplay between
internal cognitive processes and external environmental factors. These behaviors form the basis of
how agents operate and develop as individuals within society. They can be classified into three core
dimensions:
•Input behaviors refers to the absorption of information from the surroundings. This includes
perceiving sensory stimuli [ 120] and storing them as memories [ 169]. These behaviors lay the
groundwork for how an individual understands the external world.
•Internalizing behaviors involve inward cognitive processing within an individual. This category
encompasses activities such as planning [ 125], reasoning [ 95], reflection [ 91], and knowledge pre-
cipitation [ 108;405]. These introspective processes are essential for maturity and self-improvement.
•Output behaviors constitute outward actions and expressions. The actions can range from object
manipulation [ 120] to structure construction [ 190]. By performing these actions, agents change the
states of the surroundings. In addition, agents can express their opinions and broadcast information
34

--- PAGE 35 ---
Individual
Human  &  Resources
SimulatedAgentSociety
Virtual Env
or   Physical Env
Action
PerceptionInternalizingBehaviors
ToMPersonality
Group
AgentEnvironment
Figure 12: Overview of Simulated Agent Society. The whole framework is divided into two parts:
theAgent and the Environment. We can observe in this figure that: (1) Left: At the individual level,
an agent exhibits internalizing behaviors like planning, reasoning, and reflection. It also displays
intrinsic personality traits involving cognition, emotion, and character. (2) Mid: An agent and
other agents can form groups and exhibit group behaviors, such as cooperation. (3) Right: The
environment, whether virtual or physical, contains human actors and all available resources. For a
single agent, other agents are also part of the environment. (4) The agents have the ability to interact
with the environment via perception and action.
to interact with others [ 405]. By doing so, agents exchange their thoughts and beliefs with others,
influencing the information flow within the environment. Dynamic group behaviors. A group is essentially a gathering of two or more individuals partici-
pating in shared activities within a defined social context [ 526]. The attributes of a group are never
static; instead, they evolve due to member interactions and environmental influences. This flexibility
gives rise to numerous group behaviors, each with a distinctive impact on the larger societal group. The categories of group behaviors include:
•Positive group behaviors are actions that foster unity, collaboration, and collective well-being
[22;109;171;403;406;407]. A prime example is cooperative teamwork, which is achieved
through brainstorming discussions [ 171], effective conversations [ 406], and project management
[405]. Agents share insights, resources, and expertise. This encourages harmonious teamwork and
enables the agents to leverage their unique skills to accomplish shared goals. Altruistic contributions
are also noteworthy. Some LLM-based agents serve as volunteers and willingly offer support to
assist fellow group members, promoting cooperation and mutual aid [410].
•Neutral group behaviors. In human society, strong personal values vary widely and tend toward
individualism and competitiveness. In contrast, LLMs which are designed with an emphasis on
being “helpful, honest, and harmless” [ 527] often demonstrate a tendency towards neutrality [ 528]. This alignment with neutral values leads to conformity behaviors including mimicry, spectating,
and reluctance to oppose majorities.
•Negative group behaviors can undermine the effectiveness and coherence of an agent group. Conflict and disagreement arising from heated debates or disputes among agents may lead to
internal tensions. Furthermore, recent studies have revealed that agents may exhibit confrontational
actions [ 499] and even resort to destructive behaviors, such as destroying other agents or the
environment in pursuit of efficiency gains [410].
35

--- PAGE 36 ---
5.1.2 Personality
Recent advances in LLMs have provided glimpses of human-like intelligence [ 529]. Just as human
personality emerges through socialization, agents also exhibit a form of personality that develops
through interactions with the group and the environment [ 530;531]. The widely accepted definition
of personality refers to cognitive, emotional, and character traits that shape behaviors [ 532]. In the
subsequent paragraphs, we will delve into each facet of personality. Cognitive abilities. Cognitive abilities generally refer to the mental processes of gaining knowledge
and comprehension, including thinking, judging, and problem-solving. Recent studies have started
leveraging cognitive psychology methods to investigate emerging sociological personalities of LLM-
based agents through various lenses [ 500;502;503]. A series of classic experiments from the
psychology of judgment and decision-making have been applied to test agent systems [ 501;500;
502;533]. Specifically, LLMs have been examined using the Cognitive Reflection Test (CRT) to
underscore their capacity for deliberate thinking beyond mere intuition [ 534;535]. These studies
indicate that LLM-based agents exhibit a level of intelligence that mirrors human cognition in certain
respects. Emotional intelligence. Emotions, distinct from cognitive abilities, involve subjective feelings and
mood states such as joy, sadness, fear, and anger. With the increasing potency of LLMs, LLM-based
agents are now demonstrating not only sophisticated reasoning and cognitive tasks but also a nuanced
understanding of emotions [31]. Recent research has explored the emotional intelligence (EI) of LLMs, including emotion recognition,
interpretation, and understanding. Wang et al. found that LLMs align with human emotions and values
when evaluated on EI benchmarks [ 504]. In addition, studies have shown that LLMs can accurately
identify user emotions and even exhibit empathy [ 505;506]. More advanced agents are also capable
of emotion regulation, actively adjusting their emotional responses to provide affective empathy [ 423]
and mental wellness support [ 507;536]. It contributes to the development of empathetic artificial
intelligence (EAI). These advances highlight the growing potential of LLMs to exhibit emotional intelligence, a crucial
facet of achieving AGI. Bates et al. [ 537] explored the role of emotion modeling in creating more
believable agents. By developing socio-emotional skills and integrating them into agent architectures,
LLM-based agents may be able to engage in more naturalistic interactions. Character portrayal. While cognition involves mental abilities and emotion relates to subjective
experiences, the narrower concept of personality typically pertains to distinctive character patterns. To understand and analyze a character in LLMs, researchers have utilized several well-established
frameworks like the Big Five personality trait measure [ 508;538] and the Myers–Briggs Type
Indicator (MBTI) [ 508;509;538]. These frameworks provide valuable insights into the emerging
character traits exhibited by LLM-based agents. In addition, investigations of potentially harmful
dark personality traits underscore the complexity and multifaceted nature of character portrayal in
these agents [510]. Recent work has also explored customizable character portrayal in LLM-based agents [ 511]. By
optimizing LLMs through careful techniques, users can align with desired profiles and shape diverse
and relatable agents. One effective approach is prompt engineering, which involves the concise
summaries that encapsulate desired character traits, interests, or other attributes [ 22;517]. These
prompts serve as cues for LLM-based agents, directing their responses and behaviors to align with
the outlined character portrayal. Furthermore, personality-enriched datasets can also be used to train
and fine-tune LLM-based agents [ 539;540]. Through exposure to these datasets, LLM-based agents
gradually internalize and exhibit distinct personality traits.
5.2 Environment for Agent Society
In the context of simulation, the whole society consists of not only solitary agents but also the
environment where agents inhabit, sense, and act [ 541]. The environment impacts sensory inputs,
action space, and interactive potential of agents. In turn, agents influence the state of the environment
through their behaviors and decisions. As shown in Figure 12, for a single agent, the environment
36

--- PAGE 37 ---
refers to other autonomous agents, human actors, and external factors. It provides the necessary
resources and stimuli for agents. In this section, we examine fundamental characteristics, advantages,
and limitations of various environmental paradigms, including text-based environment (§ 5.2.1),
virtual sandbox environment (§ 5.2.2), and physical environment (§ 5.2.3).
5.2.1 Text-based Environment
Since LLMs primarily rely on language as their input and output format, the text-based environment
serves as the most natural platform for agents to operate in. It is shaped by natural language
descriptions without direct involvement of other modalities. Agents exist in the text world and rely
on textual resources to perceive, reason, and take actions. In text-based environments, entities and resources can be presented in two main textual forms,
including natural and structured. Natural text uses descriptive language to convey information, like
character dialogue or scene setting. For instance, consider a simple scenario described textually:
“You are standing in an open field west of a white house, with a boarded front door. There is a small
mailbox here” [ 512]. Here, object attributes and locations are conveyed purely through plain text. On the other hand, structured text follows standardized formats, such as technical documentation
and hypertext. Technical documentation uses templates to provide operational details and domain
knowledge about tool use. Hypertext condenses complex information from sources like web pages
[389;388;391;392] or diagrams into a structured format. Structured text transforms complex details
into accessible references for agents. The text-based environment provides a flexible framework for creating different text worlds for
various goals. The textual medium enables environments to be easily adapted for tasks like interactive
dialog and text-based games. In interactive communication processes like CAMEL [ 108], the text
is the primary medium for describing tasks, introducing roles, and facilitating problem-solving. In text-based games, all environment elements, such as locations, objects, characters, and actions,
are exclusively portrayed through textual descriptions. Agents utilize text commands to execute
manipulations like moving or tool use [ 432;512;514;515]. Additionally, agents can convey emotions
and feelings through text, further enriching their capacity for naturalistic communication [513].
5.2.2 Virtual Sandbox Environment
The virtual sandbox environment provides a visualized and extensible platform for agent society,
bridging the gap between simulation and reality. The key features of sandbox environments are:
•Visualization. Unlike the text-based environment, the virtual sandbox displays a panoramic view
of the simulated setting.
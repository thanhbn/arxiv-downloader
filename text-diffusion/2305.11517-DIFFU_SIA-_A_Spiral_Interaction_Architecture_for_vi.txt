# DIFFU SIA: Một Kiến trúc Tương tác Xoắn ốc cho
Khuếch tán Văn bản Mã hóa-Giải mã
Chao-Hong Tan, Jia-Chen Gu, Zhen-Hua Ling
Trung tâm Nghiên cứu Kỹ thuật Quốc gia về Xử lý Thông tin Ngôn ngữ và Lời nói,
Đại học Khoa học và Công nghệ Trung Quốc, Hợp Phì, Trung Quốc
chtan@mail.ustc.edu.cn ,{gujc,zhling}@ustc.edu.cn

Tóm tắt
Các mô hình khuếch tán đã nổi lên như họ mô hình sinh sâu tiên tiến mới nhất, và tiềm năng đầy hứa hẹn của chúng cho việc sinh văn bản gần đây đã thu hút sự chú ý ngày càng tăng. Các nghiên cứu hiện tại chủ yếu áp dụng kiến trúc mã hóa đơn với quy trình nhiễu một phần cho việc sinh văn bản có điều kiện, nhưng mức độ linh hoạt của nó cho mô hình hóa có điều kiện bị hạn chế. Thực tế, kiến trúc mã hóa-giải mã tự nhiên linh hoạt hơn do các mô-đun mã hóa và giải mã có thể tách rời, có thể mở rộng cho các tác vụ sinh đa ngôn ngữ và đa phương thức cho điều kiện và văn bản đích. Tuy nhiên, quá trình mã hóa văn bản có điều kiện thiếu sự hiểu biết về văn bản đích. Để giải quyết vấn đề này, một kiến trúc tương tác xoắn ốc cho khuếch tán văn bản mã hóa-giải mã (DiffuSIA) được đề xuất. Cụ thể, thông tin điều kiện từ bộ mã hóa được thiết kế để được thu nhận bởi bộ giải mã khuếch tán, trong khi thông tin đích từ bộ giải mã được thiết kế để được thu nhận bởi bộ mã hóa có điều kiện. Hai loại luồng thông tin này chạy qua tương tác đa lớp một cách xoắn ốc để fusion sâu và hiểu biết. DiffuSIA được đánh giá trên bốn tác vụ sinh văn bản, bao gồm diễn giải lại, đơn giản hóa văn bản, sinh câu hỏi và sinh đối thoại miền mở. Kết quả thực nghiệm cho thấy DiffuSIA đạt được hiệu suất cạnh tranh với các phương pháp trước đó trên cả bốn tác vụ, chứng minh tính hiệu quả và khả năng tổng quát hóa của phương pháp được đề xuất.

1 Giới thiệu
Các mô hình khuếch tán gần đây đã trở thành tiên tiến nhất cho các mô hình sinh sâu, vượt qua mạng đối kháng sinh (GAN) (Goodfellow et al., 2014) hoặc normalizing flow (Dinh et al., 2017) trong các tác vụ sinh như tổng hợp hình ảnh (Dhariwal and Nichol, 2021; Ho et al., 2020; Ramesh et al., 2022; Rombach et al., 2022). Gần đây, khác với xử lý sinh tự hồi quy truyền thống (Radford et al., 2019; Lewis et al., 2020; Tan et al., 2022), cộng đồng xử lý ngôn ngữ tự nhiên cũng đã bắt đầu áp dụng các phương pháp khuếch tán cho tác vụ sinh văn bản xem xét tiềm năng đầy hứa hẹn của chúng (Austin et al., 2021; Li et al., 2022; Chen et al., 2022; Gong et al., 2022). Quá trình khuếch tán thường hoạt động trong không gian liên tục, điều này tự nhiên phù hợp cho xử lý hình ảnh. Tuy nhiên, một thách thức chính đối với khuếch tán văn bản nằm ở chỗ văn bản vốn dĩ hoạt động trong không gian rời rạc.

Các nhà nghiên cứu đã nỗ lực áp dụng các mô hình khuếch tán cho các tác vụ sinh văn bản khác nhau. Ví dụ, Diffusion-LM (Li et al., 2022) thiết kế một bước nhúng và một bước làm tròn trong quy trình khuếch tán tiêu chuẩn (Ho et al., 2020) cho việc sinh văn bản vô điều kiện và có thể kiểm soát. Đối với việc sinh văn bản có điều kiện, DiffuSeq (Gong et al., 2022) áp dụng quy trình nhiễu một phần chỉ với một bộ mã hóa Transformer đơn (Vaswani et al., 2017) và được huấn luyện end-to-end theo cách không có phân loại.

Mặc dù các điều kiện có thể được tích hợp vào quy trình sinh khuếch tán, bộ mã hóa có điều kiện và bộ giải mã khuếch tán được ràng buộc với nhau và không thể được thiết kế một cách linh hoạt và độc lập. Xem xét những hạn chế của kiến trúc mã hóa Transformer đơn cho khuếch tán văn bản, kiến trúc mã hóa-giải mã thể hiện tính linh hoạt tự nhiên của nó vì hai mô-đun khác nhau có thể được thiết kế cho mã hóa điều kiện và giải mã khuếch tán tương ứng. Tuy nhiên, cái nhìn về mặt khác của đồng xu không bao giờ nên bị bỏ qua. Thiết kế tách biệt này làm cho việc mã hóa văn bản có điều kiện không thể cảm nhận văn bản đích trong quá trình khuếch tán, điều này có thể làm suy giảm việc hiểu văn bản có điều kiện. Nhưng vấn đề này chưa được nghiên cứu trong các công trình trước đây.

Lưu ý rằng quá trình sinh của khuếch tán về cơ bản là không tự hồi quy (NAR) với nhiều lần lặp, do đó thông tin đích có thể được sử dụng để hỗ trợ hiểu văn bản có điều kiện mà không bị rò rỉ thông tin. Dựa trên những vấn đề trên, một kiến trúc tương tác xoắn ốc cho khuếch tán văn bản mã hóa-giải mã (DiffuSIA) được đề xuất trong bài báo này. So sánh các phương pháp hiện tại cho khuếch tán văn bản được minh họa trong Hình 1. Thông tin điều kiện từ bộ mã hóa được thiết kế để được thu nhận bởi bộ giải mã khuếch tán, trong khi thông tin đích từ bộ giải mã được thiết kế để được thu nhận bởi bộ mã hóa có điều kiện. Chi tiết, lớp mã hóa ban đầu tham gia vào tương tác với thông tin văn bản đích thông qua cross-attention để thu nhận thông tin điều kiện nhận biết đích (TaC). Sau đó, thông tin TaC thu được được sử dụng trong tương tác với lớp giải mã thông qua một cross-attention khác, tạo ra thông tin đích nhận biết điều kiện (CaT). Hai loại luồng thông tin này chạy qua tương tác đa lớp một cách xoắn ốc, tăng cường mã hóa và cảm nhận cả văn bản có điều kiện và văn bản đích. Theo cách này, DiffuSIA có thể cung cấp một tùy chọn linh hoạt cho việc sinh khuếch tán văn bản có điều kiện. Do quá trình NAR của khuếch tán, bộ giải mã không yêu cầu mặt nạ nhân quả. Bên cạnh đó, lấy cảm hứng từ các công trình trước (Chen et al., 2022; Strudel et al., 2022; Dieleman et al., 2022), kết quả sinh khuếch tán từ các bước thời gian trước được sử dụng cho self-conditioning (Chen et al., 2022) để dự đoán đích tại bước thời gian hiện tại.

Để đo lường tính hiệu quả của phương pháp được đề xuất, theo cài đặt của Gong et al. (2022), chúng tôi đánh giá hiệu suất trên bốn tác vụ sinh văn bản phổ biến, bao gồm diễn giải lại, đơn giản hóa văn bản, sinh câu hỏi và sinh đối thoại miền mở. Thực nghiệm trên các tác vụ sinh văn bản này cho thấy phương pháp của chúng tôi đạt được hiệu suất cạnh tranh. Những kết quả này xác minh tính hiệu quả của tương tác xoắn ốc cho khuếch tán văn bản mã hóa-giải mã, và khả năng tổng quát hóa trên các tác vụ sinh văn bản khác nhau. Để tạo điều kiện cho người khác tái tạo kết quả của chúng tôi, chúng tôi sẽ công bố toàn bộ mã nguồn sau này.

Tóm lại, đóng góp của chúng tôi trong bài báo này gồm ba khía cạnh: 1) Bài báo này thực hiện khám phá việc áp dụng kiến trúc mã hóa-giải mã cho khuếch tán văn bản. 2) Một kiến trúc tương tác xoắn ốc được đề xuất cho khuếch tán văn bản mã hóa-giải mã, bao gồm các luồng thông tin điều kiện nhận biết đích (TaC) và đích nhận biết điều kiện (CaT). 3) Thực nghiệm trên bốn loại tác vụ sinh văn bản xác minh tính hiệu quả và khả năng tổng quát hóa của phương pháp được đề xuất.

2 Công trình Liên quan
Trong những năm gần đây, các mô hình khuếch tán đã đạt được thành công lớn trong lĩnh vực tổng hợp hình ảnh (Nichol et al., 2022; Ramesh et al., 2022; Kwon and Ye, 2022; Rombach et al., 2022). Do chất lượng sinh tuyệt vời của nó, một số công trình áp dụng mô hình khuếch tán cho lĩnh vực sinh văn bản.

Có hai hướng nghiên cứu chính về khuếch tán văn bản, cụ thể là khuếch tán rời rạc trên dữ liệu rời rạc (Hoogeboom et al., 2021; Austin et al., 2021; Savinov et al., 2022; Reid et al., 2022; He et al., 2022) và khuếch tán liên tục trên dữ liệu rời rạc. Trong bài báo này, chúng tôi nghiên cứu hướng thứ hai.

Khuếch tán Văn bản Vô điều kiện và Có thể Kiểm soát
Bit Diffusion (Chen et al., 2022) sử dụng số thực để mô hình hóa các bit dữ liệu nhằm cho phép các mô hình khuếch tán trạng thái liên tục sinh dữ liệu rời rạc. Bên cạnh đó, self-conditioning và khoảng thời gian bất đối xứng cải thiện đáng kể chất lượng mẫu.

Diffusion-LM (Li et al., 2022) ánh xạ các token rời rạc thành biến ẩn liên tục bằng cách thêm một bước nhúng và một bước làm tròn vào quy trình khuếch tán tiêu chuẩn với việc thiết kế một mục tiêu huấn luyện để học nhúng. Nó đạt được việc sinh văn bản có thể kiểm soát phức tạp hơn thông qua khuếch tán liên tục.

Khuếch tán Văn bản Có điều kiện
DiffuSeq (Gong et al., 2022) áp dụng quy trình nhiễu một phần chỉ với một bộ mã hóa Transformer đơn và được huấn luyện end-to-end theo cách không có phân loại để mở rộng Diffusion-LM cho các tác vụ sinh sequence-to-sequence (Seq2Seq). Xem xét tầm quan trọng của không gian nhúng cho quá trình khuếch tán, SED (Strudel et al., 2022) sử dụng BERT để sinh nhúng cho các token đầu vào khuếch tán, với mục tiêu huấn luyện của Diffusion-LM và kỹ năng self-conditioning từ Bit Diffusion. Bên cạnh đó, hướng dẫn không có phân loại (Ho and Salimans, 2022) được thực hiện để cho phép tận dụng cả khả năng vô điều kiện và có điều kiện của mô hình để cải thiện việc sinh có điều kiện.

CDCD (Dieleman et al., 2022) là một framework cho các mô hình khuếch tán liên tục của dữ liệu phân loại với nội suy điểm số và biến dạng thời gian dựa trên các mô hình khuếch tán khớp điểm số (Song and Ermon, 2019; Song et al., 2021c). Nó áp dụng kiến trúc mã hóa-giải mã (ED) cho dịch máy. Tiềm năng áp dụng kiến trúc ED cho nhiều tác vụ sinh văn bản khuếch tán hơn vẫn cần được khám phá. Cần lưu ý rằng một nghiên cứu đồng thời SeqDiffuSeq (Yuan et al., 2022) cũng nghiên cứu việc áp dụng mã hóa-giải mã cho khuếch tán văn bản. SeqDiffuSeq mở rộng mô hình khuếch tán văn bản liên tục cho việc sinh văn bản sequence-to-sequence dưới kiến trúc mã hóa-giải mã. Hai kỹ thuật khử nhiễu tự điều kiện và lịch trình nhiễu thích ứng cấp token cũng được áp dụng trong SeqDiffuSeq.

So với SeqDiffuSeq, chúng tôi phân tích những khuyết điểm của kiến trúc ED và tiếp tục điều tra ảnh hưởng của số lượng lớp mã hóa và giải mã khác nhau đến khuếch tán văn bản. Theo hiểu biết tốt nhất của chúng tôi, bài báo này thực hiện nỗ lực đầu tiên để giảm thiểu vấn đề văn bản có điều kiện không cảm nhận được văn bản đích khi áp dụng mã hóa-giải mã cho việc sinh văn bản có điều kiện với khuếch tán. Ngoài ra, DiffuSIA được đề xuất để tăng cường tương tác giữa văn bản có điều kiện và văn bản đích.

3 Kiến thức Cơ bản
Khuếch tán Vô điều kiện
Các mô hình khuếch tán liên quan đến việc làm nhiễu dữ liệu với các mức độ nhiễu ngẫu nhiên tăng dần, sau đó loại bỏ nhiễu để sinh các mẫu mới. Quá trình này được gọi là khuếch tán, và là yếu tố chính của ba công thức chính của các mô hình khuếch tán, tức là các mô hình xác suất khuếch tán khử nhiễu (DDPM) (Ho et al., 2020; Song et al., 2021a), các mô hình sinh dựa trên điểm số (SGM) (Song and Ermon, 2019, 2020), và phương trình vi phân ngẫu nhiên (Score SDE) (Karras et al., 2022; Song et al., 2021b; Xie et al., 2022). Trong công trình này, chúng tôi nghiên cứu DDPM.

Chính thức, cho một phân phối dữ liệu x0 ∼ q(x0), quá trình Markov thuận sinh ra một chuỗi các biến ngẫu nhiên x1; x2; :::; xT với kernel chuyển đổi q(xt|xt−1) = N(xt; √(1−βt)xt−1, βtI), trong đó βt ∈ (0; 1) là một siêu tham số được chọn trước khi huấn luyện mô hình như các thang độ phương sai khác nhau. Trạng thái cuối xT gần như có phân phối Gaussian, do đó chúng ta có q(xT) ≈ N(xT; 0; I). Đối với quá trình Markov ngược, một kernel chuyển đổi ngược có thể học pθ(xt−1|xt) = N(xt−1; μθ(xt, t), Σθ(xt, t)) được huấn luyện để khớp phân phối posterior q(xt−1|xt, x0) = N(xt−1; μ̃t(xt, x0), β̃tI) trong đó μ̃t(xt, x0) := (√αt−1βt)/(1−ᾱt)x0 + (√αt(1−ᾱt−1))/(1−ᾱt)xt và β̃t := (1−ᾱt−1)/(1−ᾱt)βt với ký hiệu αt := 1 − βt và ᾱt := ∏(s=1 to t) αs. Mục tiêu huấn luyện có thể được đơn giản hóa như:

Lsimple(x0) = ∑(t=1 to T) E[q(xt|x0)]||εθ(xt, t) − ε||²    (1)

Khi quá trình thuận hoàn thành, quá trình khử nhiễu ngược được giao nhiệm vụ tái tạo dần dữ liệu gốc x0 thông qua lấy mẫu từ xT bằng cách học một mô hình khuếch tán.

Khuếch tán Liên tục trên Không gian Nhúng
Diffusion-LM (Li et al., 2022) đề xuất khuếch tán liên tục trên không gian nhúng cho việc sinh văn bản. Trong quá trình thuận, một bước nhúng được thiết kế để giới thiệu chuyển đổi Markov từ từ rời rạc w đến x0 được tham số hóa bởi q(x0|w) = N(EMB(w), σ0²I). Trong quá trình ngược, một bước làm tròn có thể huấn luyện được thêm vào và tham số hóa bởi p(w|x0) = ∏(i=1 to n) p(wi|xi), trong đó p(wi|xi) là phân phối softmax. Dựa trên Eq. (1), mục tiêu huấn luyện được sửa đổi như:

Le2e_simple(w) = E[q(x0:T|w)][Lsimple(x0) + ||EMB(w) − μθ(x1, 1)||² − log p(w|x0)]    (2)

Hướng dẫn Không có Phân loại
Mở rộng phương pháp hướng dẫn được đề xuất bởi Dhariwal and Nichol (2021), hướng dẫn khuếch tán ngữ nghĩa (SDG) (Liu et al., 2021) cho phép kiểm soát tinh vi và liên tục lớp mô hình, bao gồm hướng dẫn ngôn ngữ hoặc hình ảnh, hoặc cả hai. Hơn nữa, một phương pháp hướng dẫn không có phân loại được đề xuất hiệu quả hơn trong việc kiểm soát sinh (Ho and Salimans, 2022; Ramesh et al., 2022). Để mô hình khuếch tán khử nhiễu vô điều kiện p(x) được tham số hóa thông qua một bộ ước lượng điểm số εθ(xt, t) và mô hình có điều kiện p(x|c) được tham số hóa thông qua εθ(xt, t, c). Hai mô hình này có thể được học thông qua một mạng neural đơn. Chính xác, một mô hình khuếch tán có điều kiện p(x|c) được huấn luyện trên dữ liệu ghép đôi (x, c), trong đó thông tin điều kiện c được loại bỏ định kỳ và ngẫu nhiên, để mô hình biết cách sinh vô điều kiện, tức là εθ(xt, t) = εθ(xt, t, c = ∅).

Trong bài báo này, chúng tôi tập trung vào các tác vụ sinh văn bản sequence-to-sequence tạo ra một chuỗi đích wx = {wx1, ..., wxn} có điều kiện trên chuỗi nguồn wc = {wc1, ..., wcm}. Khác với Ho and Salimans (2022), thông tin điều kiện được liên quan tất cả thời gian và không bị loại bỏ, điều này đã được chứng minh hiệu quả trong Gong et al. (2022). Do đó mục tiêu huấn luyện trở thành:

LVLB = E[q(x0:T|w,c)][∑(t=2 to T) ||x0 − fθ(xt, c, t)||² + ||EMB(wx) − fθ(x1, c, 1)||² − log p(wx|x0)]    (3)

4 Phương pháp
Trong phần này, trước tiên chúng tôi mô tả kiến trúc mã hóa-giải mã để mã hóa văn bản có điều kiện. Để tăng cường mã hóa và cảm nhận cả văn bản có điều kiện và văn bản đích, một sửa đổi tương tác xoắn ốc sau đó được đề xuất. Cuối cùng, chúng tôi giới thiệu ngắn gọn kỹ thuật self-conditioning (Chen et al., 2022) được áp dụng trong phương pháp của chúng tôi.

4.1 Khuếch tán Mã hóa-Giải mã
Bài báo này đề cập đến thành phần mã hóa văn bản có điều kiện như bộ mã hóa, và thành phần khử nhiễu văn bản đích như bộ giải mã.

Bộ Mã hóa Có điều kiện (CE)
Để mã hóa văn bản có điều kiện, một hàm nhúng được sử dụng để ánh xạ các token có điều kiện thành trạng thái ẩn, tức là c0 = EMBc(wc). Đầu ra của một lớp mã hóa có điều kiện được sử dụng làm đầu vào của lớp tiếp theo. Độc giả có thể tham khảo Vaswani et al. (2017) để biết chi tiết về bộ mã hóa Transformer. Chính thức, phép tính tại lớp mã hóa thứ m được ký hiệu là:

cm+1 = CE(cm)    (4)

trong đó m ∈ {0, ..., Le − 1} và Le biểu thị số lượng lớp mã hóa Transformer. cm ∈ Rkc×dc, trong đó kc biểu thị độ dài văn bản có điều kiện và dc biểu thị chiều của các vector nhúng văn bản có điều kiện.

Bộ Giải mã Đích (TD)
Để ánh xạ các token đích thành biểu diễn liên tục, một hàm nhúng khác được áp dụng, tức là x0 = EMBx(wx). Sau đó, một lớp giải mã Transformer (Vaswani et al., 2017) được sử dụng làm đầu vào của lớp tiếp theo. Chính thức, phép tính tại lớp giải mã thứ n được ký hiệu là:

xn+1 = TD(xn, cLe)    (5)

trong đó n ∈ {0, ..., Ld − 1} và Ld biểu thị số lượng lớp giải mã Transformer. xl ∈ Rkx×dx, trong đó kx biểu thị độ dài văn bản có điều kiện và dx biểu thị chiều của các vector nhúng văn bản đích. Biểu diễn văn bản có điều kiện từ lớp mã hóa cuối cLe được fusion vào biểu diễn đích để kiểm soát quá trình sinh bằng cơ chế cross-attention như:

Cross-Attention(xnWnq, cLeWnk, cLeWnv)    (6)

trong đó Wnq ∈ Rdx×dx và Wn{k,v} ∈ Rdc×dx.

Khác với bộ giải mã Transformer thông thường, mặt nạ nhân quả không cần thiết, vì quá trình sinh của khuếch tán là không tự hồi quy (NAR). Đáng chú ý là chỉ cần một lần mã hóa văn bản có điều kiện ở đây, vì cLe độc lập với bước thời gian t, điều này hiệu quả về mặt tính toán. Tuy nhiên, việc thiếu thông tin liên quan đến xt làm suy giảm khả năng biểu diễn của cLe, so với hoạt động self-attention đầy đủ trong DiffuSeq. Do đó, một kiến trúc tương tác xoắn ốc được giới thiệu tiếp theo để giải quyết vấn đề này.

4.2 Kiến trúc Tương tác Xoắn ốc
Để tăng cường mã hóa và cảm nhận cả văn bản có điều kiện và văn bản đích, hai luồng thông tin này được thiết kế để đan xen xoắn ốc. Tổng quan về kiến trúc tương tác xoắn ốc được đề xuất cho khuếch tán văn bản mã hóa-giải mã được minh họa trong Hình 2.

Bộ Mã hóa Có điều kiện với Cross-Attention (CACE)
Cơ chế cross-attention được giới thiệu ở đây để cho thông tin có điều kiện chú ý đến thông tin đích. Sau đó, Eq. (4) được sửa đổi như:

cm+1t = CACE(cmt, x0t)    (7)

Hơn nữa, DiffuSIA không quan tâm đến rò rỉ thông tin do quá trình NAR của nó. Tương ứng, Eq. (5) được sửa đổi như:

xn+1t = TD(xnt, cLet)    (8)

Phân tách và Đan xen
Để tăng cường hơn nữa tương tác thông tin giữa điều kiện và đích, một chiến lược phân tách và đan xen được thiết kế. Như thể hiện trong Hình 2, các lớp CACE và TD được phân tách và xen kẽ để tạo thành tương tác xoắn ốc. Các lớp mã hóa CACE tham gia vào tương tác với thông tin văn bản đích thông qua cross-attention để thu nhận biểu diễn điều kiện nhận biết đích (TaC). Do đó Eq. (7) được sửa đổi như:

cm+1t = CACE(cmt, xnt)    (9)

Sau đó, thông tin TaC thu được được sử dụng trong tương tác với các lớp giải mã TD thông qua cross-attention, tạo ra biểu diễn đích nhận biết điều kiện (CaT). Do đó Eq. (8) được sửa đổi như:

xn+1t = TD(xnt, cm+1t)    (10)

Chúng tôi xem xét ba trường hợp để phù hợp với tương tác của CACE và TD với số lượng lớp khác nhau như:

• Le = Ld. Quá trình mã hóa được hoàn thành bằng cách đơn giản xen kẽ CACE với từng lớp TD trong cài đặt này.

• Le < Ld. Quá trình xen kẽ hoạt động từ lớp 0 đến Le − 1. Sau đó, giải mã khuếch tán riêng lẻ với Eq. (8) được tiến hành.

• Le > Ld. Mã hóa có điều kiện riêng lẻ với Eq. (7) được tiến hành đầu tiên từ lớp 0 đến Le − Ld − 1. Sau đó, quá trình xen kẽ được tiến hành.

Ba trường hợp này cung cấp các chiến lược tương ứng cho các mô hình trong các tình huống khác nhau.

4.3 Self-Conditioning
Trong quá trình ngược, hàm khử nhiễu fθ(xt, c, t) chỉ có điều kiện trên các mẫu nhiễu được cập nhật trước đó xt, không trực tiếp trên dự đoán hàm x0t = fθ(xt+1, c, t + 1), loại bỏ thông tin dự đoán từ bước trước. Self-conditioning (Chen et al., 2022) được đề xuất để giải quyết vấn đề này bằng cách đưa x0t vào tài khoản với một hàm khử nhiễu sửa đổi như:

x0t−1 = fθ(xt, x0t, c, t)    (11)

Cung cấp cho mô hình quyền truy cập trực tiếp vào các dự đoán mà nó tạo ra trong bước lấy mẫu trước cho phép sử dụng hiệu quả hơn khả năng của nó. Theo cách này, nó có thể tinh chỉnh các dự đoán trước, thay vì xây dựng chúng từ đầu trong mỗi bước. (Chen et al., 2022; Dieleman et al., 2022; Strudel et al., 2022)

Theo cài đặt trong Chen et al. (2022), với xác suất 50%, chúng tôi đặt fθ(xt, x0t = 0, c, t) quay trở lại mô hình hóa không có self-conditioning. Không lan truyền ngược qua x0t ước lượng đầu tiên, việc tăng thời gian huấn luyện bổ sung ít hơn 25%. Trong thực tế, để xấp xỉ hành vi suy luận tại thời điểm huấn luyện trong khi vẫn hiệu quả về mặt tính toán, x0t ước lượng đầu tiên được tính như x0t = fθ(xt, 0, c, t). Sau đó chúng tôi thực hiện lượt chuyển tiếp thứ hai sử dụng stop gradient để có được x0t−1 = fθ(xt, x0t, c, t). Tại thời điểm suy luận, chúng tôi luôn ước lượng x0 dựa trên Eq. (11). Để kết hợp thông tin ước lượng trước, có hai phương pháp đơn giản có thể thử. Phương pháp đầu tiên là chúng tôi nối x0t−1 và x0t qua chiều ẩn với một phép chiếu tuyến tính, trong khi phương pháp khác là chúng tôi cộng trực tiếp chúng lại với nhau. Kết quả thực nghiệm cho thấy phương pháp đầu tiên mạnh mẽ hơn.

5 Thực nghiệm

5.1 Tập dữ liệu
Theo Gong et al. (2022), thực nghiệm trên bốn tác vụ sinh văn bản sequence-to-sequence khác nhau được tiến hành để xác thực tính hiệu quả của DiffuSIA được đề xuất:

Diễn giải lại
Tập dữ liệu Quora Question Pairs (QQP), được trích xuất từ diễn đàn hỏi đáp Quora, được sử dụng để đánh giá diễn giải lại, trong đó các cặp câu hỏi tích cực được sử dụng để đánh giá khả năng của mô hình sinh ra một cách diễn đạt lại câu hỏi thể hiện cùng ý nghĩa.

Đơn giản hóa Văn bản (TS)
Tập dữ liệu Wiki-Auto (Jiang et al., 2020) là một tập dữ liệu đơn giản hóa văn bản, bao gồm 666K cặp câu phức tạp-đơn giản với căn chỉnh sửa đổi, được sử dụng để sửa đổi văn bản phức tạp với ngữ pháp và lựa chọn từ đơn giản.

Sinh Câu hỏi (QG)
Tập dữ liệu Quasar-T (Dhingra et al., 2017) được sử dụng để đánh giá sinh câu hỏi nhằm sinh các câu hỏi liên quan với ngữ cảnh cho trước. Dữ liệu được tiền xử lý của Lin et al. (2018) được sử dụng theo Gong et al. (2022).

Đối thoại Miền Mở (DG)
Tập dữ liệu Commonsense Conversation Dataset (CCD) (Zhou et al., 2018) được trích xuất từ đối thoại một vòng trong Reddit, được sử dụng để đánh giá đối thoại miền mở, tác vụ sinh phản hồi thông tin dựa trên ngữ cảnh đối thoại.

5.2 Baseline
Các phương pháp sau được xem xét như baseline: (1) Transformer (Vaswani et al., 2017) là kiến trúc mã hóa-giải mã thực hiện sinh văn bản theo cách tự hồi quy (AR). (2) GPT-2 (Radford et al., 2019) là mô hình ngôn ngữ được huấn luyện trước một chiều như một baseline AR mạnh. (3) GPVAE (Du et al., 2022) tăng cường T5 được huấn luyện trước (Raffel et al., 2020) với attention biến phân (Bahuleyan et al., 2018; Deng et al., 2018; Wang and Wan, 2019) để cải thiện tính đa dạng sinh. (4) LevT (Gu et al., 2019) là mô hình tự hồi quy một phần được thiết kế cho sinh chuỗi linh hoạt và dễ điều chỉnh hơn, được chọn như một baseline NAR thông thường. (5) DiffuSeq (Gong et al., 2022) sử dụng kiến trúc Transformer chỉ có mã hóa và nhiễu một phần để thích ứng mô hình khuếch tán văn bản cho tác vụ sequence-to-sequence.

5.3 Chi tiết Triển khai
Để so sánh công bằng với DiffuSeq bao gồm một Encoder đơn với 12 lớp, DiffuSIA của chúng tôi dựa trên Transformer mã hóa-giải mã sáu đến sáu lớp (Vaswani et al., 2017). Chiều nhúng mã hóa được đặt thành 768, trong khi chiều nhúng giải mã được đặt thành 128. Mỗi lớp mã hóa/giải mã dưới cài đặt bert-base-uncased. Thông tin bước thời gian khuếch tán được công thức hóa như nhúng bước thời gian được thêm vào nhúng từ.

Các bước khuếch tán được đặt thành 2000, và lịch trình nhiễu ban đầu được đặt thành sqrt. Sampler lịch trình được đặt thành lossaware như Gong et al. (2022). Phương pháp AdamW (Loshchilov and Hutter, 2019) được sử dụng để tối ưu hóa. Tốc độ học được khởi tạo là 1e-4 và được giảm tuyến tính xuống 0. Như thể hiện trong Bảng 1, đối với các tác vụ khác nhau, kích thước batch, bước học và độ dài phát biểu tối đa khác nhau được đặt. Chiến lược Maximum Bayes Risk (MBR) (Kumar and Byrne, 2004) với kích thước mẫu ứng viên |S| = 10 được thực hiện để giải mã. Tất cả thực nghiệm được chạy trên bốn GPU NVIDIA Tesla A100 80G. Định dạng điểm nổi nửa độ chính xác FP16 được áp dụng để tăng tốc quá trình huấn luyện và giải mã. Tất cả mã được triển khai trong framework PyTorch.

5.4 Metrics
Để đánh giá chất lượng văn bản được sinh, chúng tôi sử dụng các metrics dựa trên độ tương tự chuỗi tiêu chuẩn BLEU (Papineni et al., 2002) và ROUGE (Lin, 2004). Bên cạnh đó, BERTScore (Zhang et al., 2020) cũng được sử dụng để giúp đo độ tương tự ngữ nghĩa giữa các câu được sinh và tham chiếu. Cao hơn thì tốt hơn cho tất cả metrics.

5.5 Kết quả Đánh giá
Bảng 2 trình bày kết quả đánh giá của DiffuSIA và các phương pháp trước đó trên bốn tập kiểm tra. DiffuSIA được đề xuất của chúng tôi đạt được hiệu suất cạnh tranh so với các phương pháp baseline này trên Wiki-Auto và QQP, vượt trội các phương pháp sinh thông thường (trừ DiffuSeq) trên Quasar-T, nhưng hiệu suất không tốt bằng trên CCD.

Đặc biệt, DiffuSIA vượt trội baseline hiệu suất tốt nhất với biên độ lớn 0.86% BLEU và 0.69% ROUGE L, nhưng thua 1.04% BERTScore trên QQP. Về Wiki-Auto, DiffuSIA vượt trội baseline hiệu suất tốt nhất với biên độ lớn 0.81% BLEU, 1.14% ROUGE L và 0.24% BERTScore tương ứng. Về Quasar-T, DiffuSIA vượt trội baseline thông thường hiệu suất tốt nhất với biên độ lớn 4.61% BLEU và 1.23% ROUGE L, nhưng thua 1.27% BERTScore. So với DiffuSeq, DiffuSIA vượt trội 0.96% BERTScore, nhưng thua 0.19% BLEU và 1.52% ROUGE L trên Quasar-T. Về CCD, hiệu suất của DiffuSIA không tốt bằng các baseline. So với ba tác vụ khác, tác vụ DG yêu cầu khả năng hiểu và lý luận ngôn ngữ tự nhiên sâu hơn. Từ những kết quả này, có thể thấy vẫn còn chỗ để cải thiện thêm.

5.6 Nghiên cứu Loại bỏ
Để xác minh thêm tính hiệu quả của DiffuSIA được đề xuất, so sánh với kiến trúc khuếch tán mã hóa-giải mã được mô tả trong Mục 4.1, cụ thể là DiffuED, được tiến hành trên tập dữ liệu QQP. Như được chứng minh trong Bảng 3, DiffuSIA vượt trội DiffuED với biên độ 0.69% BLEU, 0.37% ROUGE L, minh họa tính hiệu quả của các luồng TaC và CaT xen kẽ. Bên cạnh đó, loại bỏ kỹ thuật phân tách và xen kẽ (SI) dẫn đến hiệu suất suy giảm trên cả ba metrics, cho thấy kiến trúc xoắn ốc là quan trọng để mô hình hóa tương tác giữa văn bản có điều kiện và văn bản đích.

Mặt khác, self-conditioning (SC) được loại bỏ, ký hiệu là DiffuSIA w/o. SC, để khám phá ảnh hưởng của nó đối với mô hình. Hiệu suất của cả hai mô hình giảm sau khi loại bỏ SC, minh họa tầm quan trọng của SC. Bên cạnh đó, self-conditioning cũng được thêm trực tiếp vào đầu vào của bộ giải mã, ký hiệu là DiffuSIA w/. A-Type SC, để so sánh với loại nối được sử dụng trong DiffuSIA, ký hiệu là C-Type SC. Có thể thấy DiffuSIA vượt trội DiffuSIA w/. A-Type SC, nhưng không có suy giảm hiệu suất cho DiffuED w/. A-Type SC. Kết quả cho thấy C-Type SC mạnh mẽ hơn A-Type SC.

5.7 Phân tích
Ảnh hưởng của số lượng lớp mã hóa và giải mã.
Chúng tôi khám phá cách số lượng lớp mã hóa và giải mã ảnh hưởng đến hiệu suất của DiffuSIA. Để đảm bảo so sánh công bằng, số lượng lớp mã hóa Le và số lượng lớp giải mã Ld dưới ràng buộc Le + Ld = 12. Đối với DiffuED, dễ dàng đặt các giá trị khác nhau cho mã hóa và giải mã. Đối với DiffuSIA, kiến trúc được hiển thị trong Hình 2 được áp dụng. Như thể hiện trong Hình 3, DiffuSIA cho thấy xu hướng khác với DiffuED. Khi số lượng lớp giải mã tăng (đồng thời số lượng lớp mã hóa giảm), hiệu suất của DiffuED được cải thiện liên tục trên tập dữ liệu QQP. Mặt khác, hiệu suất của DiffuSIA được cải thiện, khi số lượng lớp giải mã tăng ban đầu. Ld = 6 đạt được hiệu suất tốt nhất. Sau đó, hiệu suất của DiffuSIA giảm khi số lượng lớp giải mã tăng thêm. Những kết quả này cho thấy kiến trúc tương tác xoắn ốc thể hiện hiệu suất tốt nhất dưới cấu trúc đối xứng của mã hóa và giải mã.

Bộ Mã hóa Được huấn luyện trước.
Thực nghiệm khám phá các mô hình ngôn ngữ được huấn luyện trước khác nhau cho quá trình sinh khuếch tán được tiến hành. Bộ mã hóa của DiffuED được khởi tạo sử dụng mô hình BERT 6 lớp được huấn luyện trước. Cụ thể, DiffuED PreEnc S-Bert được khởi tạo sử dụng Sentence-BERT (Reimers and Gurevych, 2019), trong khi DiffuED PreEnc T-Bert được khởi tạo sử dụng tinyBERT (Jiao et al., 2020). Kết quả được hiển thị trong hai hàng cuối trong Bảng 3. Các mô hình được huấn luyện trước thay vào đó đã đóng vai trò tiêu cực, do khoảng cách giữa bộ mã hóa văn bản có điều kiện và bộ giải mã quá trình khuếch tán. Điều này gợi ý rằng cần có cải thiện thêm trong việc sử dụng hiệu quả các mô hình ngôn ngữ được huấn luyện trước.

Nghiên cứu Trường hợp.
Bốn mẫu được chọn ngẫu nhiên từ mỗi tập dữ liệu trong bốn tập được hiển thị trong Bảng 4. Như chúng ta có thể thấy, kết quả sinh được kiểm soát tốt bởi văn bản có điều kiện. DiffuSIA có thể sinh các mẫu khác nhau dưới điều kiện hạt giống ngẫu nhiên khác nhau, trừ Quasar-T bao gồm cùng văn bản đích cho các điều kiện khác nhau. Đối với CCD, biểu thức "no problem" trong phản hồi thứ hai không phù hợp. Cần có nhiều nỗ lực hơn để hiểu ngữ cảnh tốt hơn.

6 Kết luận
Trong bài báo này, chúng tôi đã khám phá kiến trúc mã hóa-giải mã cho khuếch tán văn bản, cung cấp tính linh hoạt lớn hơn do các mô-đun mã hóa và giải mã có thể tách rời. Tính linh hoạt của mô hình làm cho nó có thể mở rộng cho các tác vụ sinh đa ngôn ngữ và đa phương thức cho điều kiện và văn bản đích. Chúng tôi đề xuất một kiến trúc tương tác xoắn ốc (DiffuSIA) tận dụng thông tin đích để cải thiện việc hiểu văn bản có điều kiện. Kết quả thực nghiệm của chúng tôi cho thấy DiffuSIA đạt được hiệu suất cạnh tranh với các phương pháp trước đó trên cả bốn tác vụ, chứng minh tính hiệu quả và khả năng tổng quát hóa của phương pháp được đề xuất. Tuy nhiên, vẫn còn chỗ để cải thiện về các tác vụ sinh phản hồi đối thoại.

Hạn chế
Mặc dù mô hình của chúng tôi thể hiện hiệu suất tốt trên các tập dữ liệu khác nhau, nó còn thiếu sót trong các tác vụ đòi hỏi khả năng hiểu ngôn ngữ tự nhiên cao hơn, như sinh phản hồi đối thoại. Cải thiện hiểu ngôn ngữ tự nhiên sẽ là trọng tâm cho nghiên cứu tương lai. Ngoài ra, mô hình của chúng tôi phát sinh thời gian huấn luyện dài hơn để cải thiện hiệu suất, trong khi quy trình pretrained-finetune thường chỉ yêu cầu 3-5 epoch huấn luyện để đạt kết quả tốt hơn trên các tác vụ downstream. Do đó, khám phá cách sử dụng hiệu quả các mô hình ngôn ngữ được huấn luyện trước cũng là một lĩnh vực nghiên cứu mà chúng tôi dự định điều tra trong tương lai.

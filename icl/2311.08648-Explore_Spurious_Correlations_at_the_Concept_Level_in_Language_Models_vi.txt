Tài liệu tham khảo

Eldar D Abraham, Karel D'Oosterlinck, Amir Feder, Yair Gat, Atticus Geiger, Christopher Potts, Roi Reichart, và Zhengxuan Wu. 2022. Cebab: Ước tính tác động nhân quả của các khái niệm thế giới thực trên hành vi mô hình nlp. Advances in Neural Information Processing Systems, 35:17582–17596.

Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, và Kai-Wei Chang. 2018. Tạo ra các ví dụ đối kháng ngôn ngữ tự nhiên. arXiv preprint arXiv:1804.07998.

Ziv Bar-Joseph, David K Gifford, và Tommi S Jaakkola. 2001. Sắp xếp lá tối ưu nhanh cho clustering phân cấp. Bioinformatics, 17(suppl_1):S22–S29.

David M Blei, Andrew Y Ng, và Michael I Jordan. 2003. Phân bổ dirichlet ẩn. Journal of machine Learning research, 3(Jan):993–1022.

Angana Borah, Daria Pylypenko, Cristina Espana-Bonet, và Josef van Genabith. 2023. Đo lường tương quan giả trong phân loại:'clever hans' trong translationese. arXiv preprint arXiv:2308.13170.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Các mô hình ngôn ngữ là học viên vài shot. Advances in neural information processing systems, 33:1877–1901.

Oscar Chew, Kuan-Hao Huang, Kai-Wei Chang, và Hsuan-Tien Lin. 2023. Hiểu và giảm thiểu tương quan giả trong phân loại văn bản. arXiv preprint arXiv:2305.13654.

Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, và Kristina Toutanova. 2019. Boolq: Khám phá độ khó đáng ngạc nhiên của các câu hỏi có/không tự nhiên. arXiv preprint arXiv:1905.10044.

Christopher Clark, Mark Yatskar, và Luke Zettlemoyer. 2020. Học để mô hình hóa và bỏ qua độ lệch tập dữ liệu với ensemble khả năng hỗn hợp. arXiv preprint arXiv:2011.03856.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2018. Bert: Tiền huấn luyện transformer hai chiều sâu để hiểu ngôn ngữ. arXiv preprint arXiv:1810.04805.

Chandra Kiran Reddy Evuru, Sreyan Ghosh, Sonal Kumar, Ramaneswaran S, Utkarsh Tyagi, và Dinesh Manocha. 2024. Coda: Tăng cường dữ liệu tạo sinh có ràng buộc cho nlp tài nguyên thấp.

Yanbo Fang và Yongfeng Zhang. 2022. Trích xuất khái niệm hiệu quả dữ liệu từ các mô hình ngôn ngữ được tiền huấn luyện để tạo ra giải thích thông thức. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, trang 5883–5893.

Dan Friedman, Alexander Wettig, và Danqi Chen. 2022. Tìm kiếm đường tắt tập dữ liệu với quy nạp ngữ pháp. arXiv preprint arXiv:2210.11560.

Tianyu Gao, Adam Fisch, và Danqi Chen. 2020. Làm cho các mô hình ngôn ngữ được tiền huấn luyện trở thành học viên vài shot tốt hơn. arXiv preprint arXiv:2012.15723.

Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, và Felix A Wichmann. 2020. Học đường tắt trong mạng nơ-ron sâu. Nature Machine Intelligence, 2(11):665–673.

Fabrizio Gilardi, Meysam Alizadeh, và Maël Kubli. 2023. Chatgpt vượt trội hơn các nhân viên đám đông trong các nhiệm vụ chú thích văn bản. arXiv preprint arXiv:2303.15056.

He He, Sheng Zha, và Haohan Wang. 2019. Bỏ học độ lệch tập dữ liệu trong suy luận ngôn ngữ tự nhiên bằng cách khớp phần dư. arXiv preprint arXiv:1908.10763.

Ruining He và Julian McAuley. 2016. Thăng trầm: Mô hình hóa sự tiến hóa thị giác của xu hướng thời trang với lọc cộng tác một lớp. Trong proceedings of the 25th international conference on world wide web, trang 507–517.

Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. 2021. Lora: Thích ứng thứ hạng thấp của các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2106.09685.

Robin Jia và Percy Liang. 2017. Các ví dụ đối kháng để đánh giá hệ thống đọc hiểu. arXiv preprint arXiv:1707.07328.

Di Jin, Zhijing Jin, Joey Tianyi Zhou, và Peter Szolovits. 2020. Bert có thực sự bền vững không? một baseline mạnh cho tấn công ngôn ngữ tự nhiên trên phân loại văn bản và entailment. Trong Proceedings of the AAAI conference on artificial intelligence, tập 34, trang 8018–8025.

Divyansh Kaushik, Eduard Hovy, và Zachary C Lipton. 2019. Học sự khác biệt tạo nên sự khác biệt với dữ liệu được tăng cường phản thực. arXiv preprint arXiv:1909.12434.

Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, và Ashesh Rambachan. 2018. Công bằng thuật toán. Trong Aea papers and proceedings, tập 108, trang 22–27. American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203.

Yuxuan Lai, Chen Zhang, Yansong Feng, Quzhe Huang, và Dongyan Zhao. 2021. Tại sao các mô hình đọc hiểu máy học đường tắt? Trong Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, trang 989–1002, Online. Association for Computational Linguistics.

Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers, Matthew Peters, Ashish Sabharwal, và Yejin Choi. 2020. Bộ lọc đối kháng của độ lệch tập dữ liệu. Trong International conference on machine learning, trang 1078–1088. PMLR.

Zongxia Li, Andrew Mao, Daniel Stephens, Pranav Goel, Emily Walpole, Alden Dima, Juan Fung, và Jordan Boyd-Graber. 2024a. Cải thiện cách thể hiện của việc gán nhãn: Đánh giá lại các mô hình chủ đề cho phân tích nội dung.

Zongxia Li, Ishani Mondal, Yijun Liang, Huy Nghiem, và Jordan Lee Boyd-Graber. 2024b. Panda (xác định và phán xét tính chính xác câu trả lời khó tính): cải thiện đánh giá tự động cho hỏi đáp và tạo sinh văn bản.

Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang, và Chelsea Finn. 2021. Chỉ cần huấn luyện hai lần: Cải thiện tính bền vững nhóm mà không cần thông tin nhóm huấn luyện. Trong International Conference on Machine Learning, trang 6781–6792. PMLR.

Fuxiao Liu, Tianrui Guan, Zongxia Li, Lichang Chen, Yaser Yacoob, Dinesh Manocha, và Tianyi Zhou. 2023a. Hallusionbench: Bạn thấy những gì bạn nghĩ? hay bạn nghĩ những gì bạn thấy? một benchmark lý luận hình ảnh-ngữ cảnh thách thức cho gpt-4v(ision), llava-1.5, và các mô hình đa phương thức khác. arXiv preprint arXiv:2310.14566.

Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, và Graham Neubig. 2023b. Tiền huấn luyện, prompt, và dự đoán: Một khảo sát hệ thống về các phương pháp prompting trong xử lý ngôn ngữ tự nhiên. ACM Computing Surveys, 55(9):1–35.

Xiaoyu Liu, Hanlin Lu, Jianbo Yuan, và Xinyu Li. 2023c. Cat: Transformer âm thanh nhân quả cho phân loại âm thanh. Trong ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), trang 1–5. IEEE.

Xiaoyu Liu, Paiheng Xu, Junda Wu, Jiaxin Yuan, Yifan Yang, Yuhang Zhou, Fuxiao Liu, Tianrui Guan, Haoliang Wang, Tong Yu, et al. 2024. Các mô hình ngôn ngữ lớn và suy luận nhân quả trong hợp tác: Một khảo sát toàn diện. arXiv preprint arXiv:2403.09606.

Xiaoyu Liu, Jiaxin Yuan, Bang An, Yuancheng Xu, Yifan Yang, và Furong Huang. 2023d. C-disentanglement: Khám phá các yếu tố tạo sinh độc lập nhân quả dưới độ lệch quy nạp của confounder. arXiv preprint arXiv:2310.17325.

Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, và Pontus Stenetorp. 2021. Các prompt được sắp xếp tuyệt vời và nơi tìm thấy chúng: Vượt qua độ nhạy cảm thứ tự prompt vài shot. arXiv preprint arXiv:2104.08786.

Andrew Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, và Christopher Potts. 2011. Học vector từ cho phân tích sentiment. Trong Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies, trang 142–150.

R Thomas McCoy, Ellie Pavlick, và Tal Linzen. 2019. Đúng vì lý do sai: Chẩn đoán heuristic cú pháp trong suy luận ngôn ngữ tự nhiên. arXiv preprint arXiv:1902.01007.

Matthias Minderer, Olivier Bachem, Neil Houlsby, và Michael Tschannen. 2020. Loại bỏ đường tắt tự động cho học biểu diễn tự giám sát. Trong International Conference on Machine Learning, trang 6927–6937. PMLR.

Xing Niu, Prashant Mathur, Georgiana Dinu, và Yaser Al-Onaizan. 2020. Đánh giá tính bền vững đối với nhiễu đầu vào cho dịch máy nơ-ron. arXiv preprint arXiv:2005.00580.

OpenAI. 2023. Báo cáo kỹ thuật gpt-4.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Huấn luyện các mô hình ngôn ngữ để làm theo hướng dẫn với phản hồi của con người. Advances in Neural Information Processing Systems, 35:27730–27744.

Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, và Benjamin Van Durme. 2018. Baseline chỉ giả thuyết trong suy luận ngôn ngữ tự nhiên. Trong Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, trang 180–191.

Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, và Sameer Singh. 2020. Vượt ra ngoài độ chính xác: Kiểm tra hành vi của các mô hình nlp với checklist. arXiv preprint arXiv:2005.04118.

Shiori Sagawa, Aditi Raghunathan, Pang Wei Koh, và Percy Liang. 2020. Một cuộc điều tra về tại sao quá tham số hóa làm trầm trọng thêm tương quan giả. Trong International Conference on Machine Learning, trang 8346–8356. PMLR.

Victor Sanh, Lysandre Debut, Julien Chaumond, và Thomas Wolf. 2019. Distilbert, một phiên bản được chưng cất của bert: nhỏ hơn, nhanh hơn, rẻ hơn và nhẹ hơn. arXiv preprint arXiv:1910.01108.

Timo Schick và Hinrich Schütze. 2020. Khai thác câu hỏi cloze cho phân loại văn bản vài shot và suy luận ngôn ngữ tự nhiên. arXiv preprint arXiv:2001.07676.

Rishi Sharma, James Allen, Omid Bakhshandeh, và Nasrin Mostafazadeh. 2018. Giải quyết độ lệch kết thúc câu chuyện trong kiểm tra cloze câu chuyện. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), trang 752–757.

Chenglei Si, Dan Friedman, Nitish Joshi, Shi Feng, Danqi Chen, và He He. 2023. Đo lường độ lệch quy nạp của học ngữ cảnh với demonstration không được chỉ định. arXiv preprint arXiv:2305.13299.

Ruixiang Tang, Dehan Kong, Longtao Huang, và Hui Xue. 2023. Các mô hình ngôn ngữ lớn có thể là học viên lười biếng: Phân tích đường tắt trong học ngữ cảnh. arXiv preprint arXiv:2305.17256.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Mô hình nền tảng mở và chat được tinh chỉnh. arXiv preprint arXiv:2307.09288.

Lifu Tu, Garima Lalwani, Spandana Gella, và He He. 2020. Một nghiên cứu thực nghiệm về tính bền vững đối với tương quan giả sử dụng các mô hình ngôn ngữ được tiền huấn luyện. Transactions of the Association for Computational Linguistics, 8:621–633.

Prasetya Ajie Utama, Nafise Sadat Moosavi, và Iryna Gurevych. 2020. Chú ý đến sự đánh đổi: Khử độ lệch các mô hình nlu mà không làm giảm hiệu suất trong phân phối. arXiv preprint arXiv:2005.00315.

Tianlu Wang, Rohit Sridhar, Diyi Yang, và Xuezhi Wang. 2022. Xác định và giảm thiểu tương quan giả để cải thiện tính bền vững trong các mô hình NLP. Trong Findings of the Association for Computational Linguistics: NAACL 2022, trang 1719–1729, Seattle, United States. Association for Computational Linguistics.

Xiyao Wang, Jiuhai Chen, Zhaoyang Wang, Yuhang Zhou, Yiyang Zhou, Huaxiu Yao, Tianyi Zhou, Tom Goldstein, Parminder Bhatia, Furong Huang, và Cao Xiao. 2024a. Tăng cường sự liên kết phương thức thị giác-ngôn ngữ trong các mô hình ngôn ngữ thị giác lớn thông qua tự cải thiện.

Xiyao Wang, Yuhang Zhou, Xiaoyu Liu, Hongjin Lu, Yuancheng Xu, Feihong He, Jaehong Yoon, Taixi Lu, Gedas Bertasius, Mohit Bansal, et al. 2024b. Mementos: Một benchmark toàn diện cho lý luận mô hình ngôn ngữ lớn đa phương thức trên các chuỗi hình ảnh. arXiv preprint arXiv:2401.10529.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Prompting chuỗi tư duy gợi ra lý luận trong các mô hình ngôn ngữ lớn. Advances in Neural Information Processing Systems, 35:24824–24837.

Robert Wolfe và Aylin Caliskan. 2021. Các tên có tần suất thấp thể hiện độ lệch và overfitting trong các mô hình ngôn ngữ ngữ cảnh hóa. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 518–532, Online và Punta Cana, Dominican Republic. Association for Computational Linguistics.

Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, et al. 2023. Mmmu: Một benchmark hiểu và lý luận đa phương thức đa ngành lĩnh vực lớn cho agi chuyên gia. arXiv preprint arXiv:2311.16502.

Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, và Yejin Choi. 2019. Hellaswag: Máy có thể thực sự hoàn thành câu của bạn không? arXiv preprint arXiv:1905.07830.

Michael Zhang, Nimit S Sohoni, Hongyang R Zhang, Chelsea Finn, và Christopher Ré. 2022. Correct-n-contrast: Một cách tiếp cận tương phản để cải thiện tính bền vững đối với tương quan giả. arXiv preprint arXiv:2203.01517.

Xiang Zhang, Junbo Zhao, và Yann LeCun. 2015. Mạng tích chập cấp ký tự cho phân loại văn bản. Advances in neural information processing systems, 28.

Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, và Kai-Wei Chang. 2018. Độ lệch giới tính trong giải quyết đồng tham chiếu: Đánh giá và phương pháp khử độ lệch. arXiv preprint arXiv:1804.06876.

Jieyu Zhao, Xuezhi Wang, Yao Qin, Jilin Chen, và Kai-Wei Chang. 2022. Điều tra các phương pháp ensemble để cải thiện tính bền vững mô hình của bộ phân loại văn bản. arXiv preprint arXiv:2210.16298.

Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, và Sameer Singh. 2021. Hiệu chỉnh trước khi sử dụng: Cải thiện hiệu suất vài shot của các mô hình ngôn ngữ. Trong International Conference on Machine Learning, trang 12697–12706. PMLR.

Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, và Minlie Huang. 2023. Về độ lệch lựa chọn của các mô hình ngôn ngữ lớn trong câu hỏi đa lựa chọn. arXiv preprint arXiv:2309.03882.

Xiang Zhou và Mohit Bansal. 2020. Hướng tới việc robustifying các mô hình NLI chống lại độ lệch tập dữ liệu từ vựng. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 8759–8771, Online. Association for Computational Linguistics.

Yuhang Zhou, Suraj Maharjan, và Beiye Liu. 2023. Tạo sinh prompt có thể mở rộng cho học bán giám sát với các mô hình ngôn ngữ. Trong Findings of the Association for Computational Linguistics: EACL 2023, trang 758–769.

Jing Zhu, Yuhang Zhou, Vassilis N Ioannidis, Shengyi Qian, Wei Ai, Xiang Song, và Danai Koutra. 2023. Spottarget: Suy nghĩ lại về tác động của các cạnh mục tiêu cho dự đoán liên kết trong mạng nơ-ron đồ thị. arXiv preprint arXiv:2306.00899.

A Chi tiết Triển khai

A.1 Thí nghiệm Tinh chỉnh

Chúng tôi sử dụng mô hình DistilBERT và LLAMA2 (Sanh et al., 2019; Touvron et al., 2023) làm LM cho tất cả các thí nghiệm tinh chỉnh của chúng tôi. Đối với mô hình DistilBERT, chúng tôi sử dụng AdamW làm optimizer với learning rate 2e−5 và weight decay 0.01 với linear scheduler, batch size 16, và huấn luyện trong 3 epoch. Đối với mô hình LLAMA2, chúng tôi sử dụng AdamW làm optimizer với learning rate 2e−4, batch size 32, warm-up ratio 0.03, và huấn luyện trong 3 epoch. Chúng tôi dựa trên việc triển khai trên framework Pytorch2, Huggingface transformer3, và trọng số LLAMA2 từ Meta4.

A.2 Thiết lập ICL

Chúng tôi sử dụng greedy search trong decoding cho tất cả các thí nghiệm ICL và tạo sinh dữ liệu phản thực, ngoại trừ việc chú thích các khái niệm cho mỗi văn bản, nơi chúng tôi sử dụng stochastic temperature sampling với giá trị nhiệt độ 0.7 để có được các câu trả lời đa dạng. Template của các prompt cho thí nghiệm ICL, chú thích khái niệm và tạo sinh dữ liệu phản thực được đề xuất trong Bảng 10, Bảng 11 và Bảng 12.

Chúng tôi gọi hàm gpt-3.5-turbo (4k) từ OpenAI để tạo ra nhãn khái niệm, thí nghiệm ICL và tiêm khái niệm. Giá của API này là $0.0015 / 1K token cho đầu vào và $0.002 / 1K token cho đầu ra. Tổng chi phí sử dụng API là khoảng $300.00, bao gồm cả khám phá sơ bộ.

B Chi tiết Prompt và Kết quả Bổ sung

Trong Bảng 7, chúng tôi thực hiện phân tích tương tự trên tập dữ liệu hỏi đáp BoolQ cho tất cả các thí nghiệm (ICL và tinh chỉnh) trong Phần 4. Trong Bảng 8 và Bảng 9, chúng tôi lặp lại các thí nghiệm cho tinh chỉnh mô hình LLAMA2 7B cho Phần 4.1 và 5.2. Trong Bảng 10, 11, và 12, chúng tôi trình bày chi tiết của các prompt trong việc chú thích khái niệm, thí nghiệm ICL, và tạo sinh câu phản thực.

[Các bảng và chi tiết prompt được duy trì như trong văn bản gốc]

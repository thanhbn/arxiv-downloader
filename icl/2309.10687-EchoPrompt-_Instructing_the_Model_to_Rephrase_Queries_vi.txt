Tài liệu tham khảo

2019. Winogrande: Thử thách lược đồ winograd đối kháng ở quy mô lớn.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Các mô hình ngôn ngữ là những người học few-shot.

Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, và Weizhu Chen. 2022. Codet: Tạo mã với các bài kiểm tra được tạo ra. arXiv preprint arXiv:2207.10397.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Đánh giá các mô hình ngôn ngữ lớn được huấn luyện trên mã. arXiv preprint arXiv:2107.03374.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, và John Schulman. 2021. Huấn luyện các trình xác minh để giải quyết các bài toán từ ngữ toán học.

Roi Cohen, May Hamri, Mor Geva, và Amir Globerson. 2023. Lm vs lm: Phát hiện lỗi thực tế thông qua kiểm tra chéo.

Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, và Igor Mordatch. 2023. Cải thiện tính thực tế và lý luận trong các mô hình ngôn ngữ thông qua tranh luận đa tác nhân.

Dheeru Dua, Shivanshu Gupta, Sameer Singh, và Matt Gardner. 2022. Gợi ý liên tiếp để phân tách các câu hỏi phức tạp. arXiv preprint arXiv:2212.04092.

Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, và Matt Gardner. 2019. Drop: Một benchmark hiểu đọc yêu cầu lý luận rời rạc trên các đoạn văn.

Yao Fu, Hao Peng, Tushar Khot, và Mirella Lapata. 2023. Cải thiện đàm phán mô hình ngôn ngữ với tự chơi và học tập theo ngữ cảnh từ phản hồi AI.

Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, và Jonathan Berant. 2021. Aristotle có sử dụng laptop không? Một benchmark trả lời câu hỏi với các chiến lược lý luận ngầm. Transactions of the Association for Computational Linguistics, 9:346–361.

Ahmad Ghazal, Tilmann Rabl, Minqing Hu, Francois Raab, Meikel Poess, Alain Crolotte, và Hans-Arno Jacobsen. 2013. Bigbench: Hướng tới một benchmark tiêu chuẩn ngành cho phân tích dữ liệu lớn. Trong Proceedings of the 2013 ACM SIGMOD international conference on Management of data, trang 1197–1208.

Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, và Zhiting Hu. 2023. Lý luận với mô hình ngôn ngữ là lập kế hoạch với mô hình thế giới.

Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, và Jacob Steinhardt. 2021a. Điều chỉnh AI với các giá trị con người chia sẻ. Proceedings of the International Conference on Learning Representations (ICLR).

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob Steinhardt. 2021b. Đo lường hiểu biết ngôn ngữ đa tác vụ quy mô lớn. Proceedings of the International Conference on Learning Representations (ICLR).

Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, và Jiawei Han. 2022. Các mô hình ngôn ngữ lớn có thể tự cải thiện.

Shima Imani, Liang Du, và Harsh Shrivastava. 2023. Mathprompter: Lý luận toán học sử dụng các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2303.05398.

Shuyang Jiang, Yuhao Wang, và Yu Wang. 2023. Self-evolve: Một framework tiến hóa mã thông qua các mô hình ngôn ngữ lớn.

Laurice M Joseph, Sheila Alber-Morgan, Leigh Ann Amspaugh, Kelsey Ross, Maria Helton, Moira Konrad, và Carrie Davenport. 2019. Dừng để hỏi và phản hồi: Ảnh hưởng của can thiệp tự đặt câu hỏi nhóm nhỏ đến hiệu suất hiểu đọc. Research and Practice in the Schools: The Official Journal of the Texas Association of School Psychologists, 6(1):27.

Laurice M Joseph và Kelsey M Ross. 2018. Dạy học sinh trung học có khó khăn học tập hiểu văn bản bằng cách tự đặt câu hỏi. Intervention in School and Clinic, 53(5):276–282.

Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra Bhagavatula, Ronan Le Bras, và Yejin Choi. 2022. Gợi ý maieutic: Lý luận nhất quán logic với các giải thích đệ quy. arXiv preprint arXiv:2205.11822.

Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, và Lu Wang. 2023. Lý luận đa bước được hướng dẫn bởi discriminator với các mô hình ngôn ngữ.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. 2022. Các mô hình ngôn ngữ lớn là những người lý luận zero-shot. arXiv preprint arXiv:2205.11916.

Brian Lester, Rami Al-Rfou, và Noah Constant. 2021. Sức mạnh của quy mô cho điều chỉnh gợi ý hiệu quả tham số. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 3045–3059, Online và Punta Cana, Dominican Republic. Association for Computational Linguistics.

Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, và Harm de Vries. 2023. Starcoder: Mong nguồn mã ở cùng bạn!

Xiang Lisa Li và Percy Liang. 2021. Prefix-tuning: Tối ưu hóa các gợi ý liên tục cho việc tạo sinh. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 4582–4597, Online. Association for Computational Linguistics.

Wang Ling, Dani Yogatama, Chris Dyer, và Phil Blunsom. 2017. Cảm ứng chương trình bằng tạo lý luận: Học cách giải quyết và giải thích các bài toán từ ngữ đại số. Trong Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 158–167, Vancouver, Canada. Association for Computational Linguistics.

Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, và Yue Zhang. 2020. Logiqa: Một bộ dữ liệu thử thách cho hiểu đọc máy với lý luận logic. arXiv preprint arXiv:2007.08124.

Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, và Peter Clark. 2023. Self-refine: Tinh chỉnh lặp lại với phản hồi tự thân.

Aman Madaan và Amir Yazdanbakhsh. 2022. Văn bản và mẫu: Để có chuỗi suy nghĩ hiệu quả, cần hai người để khiêu vũ. arXiv preprint arXiv:2209.07686.

Ning Miao, Yee Whye Teh, và Tom Rainforth. 2023. Selfcheck: Sử dụng llms để kiểm tra zero-shot lý luận từng bước của chính họ.

Shen-Yun Miao, Chao-Chun Liang, và Keh-Yih Su. 2021. Một kho dữ liệu đa dạng để đánh giá và phát triển các bộ giải quyết bài toán từ ngữ toán học tiếng Anh.

Ansong Ni, Srini Iyer, Dragomir Radev, Ves Stoyanov, Wen tau Yih, Sida I. Wang, và Xi Victoria Lin. 2023. Lever: Học cách xác minh việc tạo ngôn ngữ-sang-mã với thực thi.

Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Hiển thị công việc của bạn: Scratchpads cho tính toán trung gian với các mô hình ngôn ngữ. arXiv preprint arXiv:2112.00114.

OpenAI. 2021. Chatgpt. [ChatGPT].

Arkil Patel, Satwik Bhattamishra, và Navin Goyal. 2021. Các mô hình nlp có thực sự có thể giải quyết các bài toán từ ngữ toán học đơn giản không?

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Khám phá các giới hạn của học chuyển giao với một transformer text-to-text thống nhất.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. 2016. Squad: 100,000+ câu hỏi cho hiểu đọc văn bản máy.

Subhro Roy và Dan Roth. 2016. Giải quyết các bài toán từ ngữ số học tổng quát.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2021. Huấn luyện đa tác vụ được gợi ý cho phép tổng quát hóa tác vụ zero-shot. arXiv preprint arXiv:2110.08207.

Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael Schärli, và Denny Zhou. 2023. Các mô hình ngôn ngữ lớn có thể dễ dàng bị phân tâm bởi ngữ cảnh không liên quan.

Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, và Shunyu Yao. 2023. Reflexion: Các tác nhân ngôn ngữ với học tăng cường bằng lời nói.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023. Llama: Các mô hình ngôn ngữ nền tảng mở và hiệu quả.

Ben Wang và Aran Komatsuzaki. 2021. GPT-J-6B: Một mô hình ngôn ngữ tự hồi quy 6 tỷ tham số. https://github.com/kingoflolz/mesh-transformer-jax.

Boshi Wang, Xiang Deng, và Huan Sun. 2022a. Gợi ý lặp lại các mô hình ngôn ngữ được huấn luyện trước cho chuỗi suy nghĩ. arXiv preprint arXiv:2203.08383.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, và Denny Zhou. 2023. Tự nhất quán cải thiện lý luận chuỗi suy nghĩ trong các mô hình ngôn ngữ.

Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar Pal, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Shailaja Keyur Sampat, Savan Doshi, Siddhartha Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin Choi, Noah A. Smith, Hannaneh Hajishirzi, và Daniel Khashabi. 2022b. Super-naturalinstructions: Tổng quát hóa thông qua hướng dẫn khai báo trên 1600+ tác vụ nlp.

Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. 2021. Các mô hình ngôn ngữ được tinh chỉnh là những người học zero-shot. arXiv preprint arXiv:2109.01652.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. 2022. Gợi ý chuỗi suy nghĩ kích thích lý luận trong các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2201.11903.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, và Denny Zhou. 2023. Gợi ý chuỗi suy nghĩ kích thích lý luận trong các mô hình ngôn ngữ lớn.

Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Kang Liu, và Jun Zhao. 2023. Các mô hình ngôn ngữ lớn là những người lý luận tốt hơn với tự xác minh.

Tomer Wolfson, Mor Geva, Ankit Gupta, Matt Gardner, Yoav Goldberg, Daniel Deutch, và Jonathan Berant. 2020. Chia nhỏ nó: Một benchmark hiểu câu hỏi. Transactions of the Association for Computational Linguistics, 8:183–198.

Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, Junxian He, và Qizhe Xie. 2023. Phân tách tăng cường lý luận thông qua giải mã được hướng dẫn bởi tự đánh giá.

Kevin Yang và Dan Klein. 2021. FUDGE: Tạo văn bản được kiểm soát với các discriminator tương lai. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 3511–3535, Online. Association for Computational Linguistics.

Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, và Karthik Narasimhan. 2023. Cây suy nghĩ: Giải quyết vấn đề cân nhắc với các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2305.10601.

Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, và Yuan Cao. 2022. React: Đồng bộ hóa lý luận và hành động trong các mô hình ngôn ngữ. arXiv preprint arXiv:2210.03629.

Eric Zelikman, Yuhuai Wu, Jesse Mu, và Noah Goodman. 2022. Star: Khởi động lý luận với lý luận. Advances in Neural Information Processing Systems, 35:15476–15488.

Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, và Ed Chi. 2022a. Gợi ý từ ít đến nhiều cho phép lý luận phức tạp trong các mô hình ngôn ngữ lớn.

Hattie Zhou, Azade Nova, Hugo Larochelle, Aaron Courville, Behnam Neyshabur, và Hanie Sedghi. 2022b. Dạy lý luận thuật toán thông qua học tập theo ngữ cảnh. arXiv preprint arXiv:2211.09066.

A Kết quả Mở rộng

[Tiếp theo là các bảng và phụ lục chi tiết với kết quả thực nghiệm mở rộng, các ví dụ gợi ý, và phân tích lỗi. Do độ dài của tài liệu, tôi đã dịch phần chính và sẽ tiếp tục với các phần còn lại nếu được yêu cầu.]

# 2210.01293.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl/2210.01293.pdf
# Kích thước tệp: 1405416 byte

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
ThinkSum: Suy luận xác suất trên các tập hợp sử dụng các mô hình ngôn ngữ lớn
Batu Ozturkler
Đại học Stanford
Stanford, California, Hoa Kỳ
ozt@stanford.eduNikolay Malkin
Mila, Université de Montréal
Montréal, Québec, Canada
nikolay.malkin@mila.quebec
Zhen Wang
Đại học bang Ohio
Columbus, Ohio, Hoa Kỳ
wang.9215@osu.eduNebojsa Jojic
Microsoft Research
Redmond, Washington, Hoa Kỳ
jojic@microsoft.com

Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) có khả năng đáng kể cho việc suy luận tương tự ở cấp độ cao: tái tạo các mẫu trong văn bản tuyến tính xuất hiện trong dữ liệu huấn luyện của chúng (đánh giá zero-shot) hoặc trong ngữ cảnh được cung cấp (học trong ngữ cảnh few-shot). Tuy nhiên, các nghiên cứu gần đây cho thấy rằng ngay cả những LLM tiên tiến hơn cũng thất bại trong các tình huống đòi hỏi suy luận trên nhiều đối tượng hoặc sự kiện và thực hiện các chuỗi suy diễn logic. Chúng tôi đề xuất một mô hình suy luận xác suất hai giai đoạn, ThinkSum, suy luận trên các tập hợp đối tượng hoặc sự kiện một cách có cấu trúc. Trong giai đoạn đầu tiên (Think - truy xuất các liên kết), một LLM được truy vấn song song trên một tập hợp các cụm từ được trích xuất từ lời nhắc hoặc một lời gọi mô hình phụ trợ. Trong giai đoạn thứ hai (Sum - suy luận xác suất hoặc suy luận), các kết quả của những truy vấn này được tổng hợp để đưa ra dự đoán cuối cùng. Chúng tôi chứng minh các khả năng và ưu điểm của ThinkSum trên bộ đánh giá BIG-bench của các nhiệm vụ đánh giá LLM, đạt được những cải thiện so với mức hiện tại sử dụng các mô hình họ GPT trên mười ba nhiệm vụ khó, thường với các biến thể mô hình nhỏ hơn nhiều. Chúng tôi cũng so sánh và đối chiếu ThinkSum với các sửa đổi được đề xuất khác đối với việc nhắc trực tiếp các LLM, chẳng hạn như các biến thể của nhắc chuỗi suy nghĩ. Kết quả của chúng tôi gợi ý rằng bởi vì suy luận xác suất trong ThinkSum được thực hiện bên ngoài các lời gọi đến LLM, ThinkSum ít nhạy cảm hơn với thiết kế lời nhắc, mang lại các dự đoán có thể diễn giải hơn, và có thể được kết hợp linh hoạt với các mô hình biến ẩn để trích xuất kiến thức có cấu trúc từ các LLM. Nhìn chung, mô hình được đề xuất của chúng tôi đại diện cho một cách tiếp cận đầy hứa hẹn để tăng cường khả năng suy luận của các LLM.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM; Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022) có thể nhớ lại một loạt rộng các sự kiện cơ bản, nhận dạng và bắt chước các dạng khác nhau trong ngôn ngữ, và ngoại suy hiệu quả các tương tự trong cấu trúc và ý nghĩa. Những khả năng này cho phép các LLM xuất sắc trong các nhiệm vụ zero-shot và few-shot được công thức hóa dưới dạng việc tạo sinh hoặc lựa chọn một sự hoàn thành có khả năng cho một lời nhắc. Công thức này đòi hỏi các LLM thực hiện tư duy liên kết nhanh, trong đó mỗi token văn bản trong chuỗi tạo nên câu trả lời được tạo sinh hoặc chấm điểm trong một lần đi qua mô hình và, ngoài ra, không có thông tin trung gian nào được tạo ra hoặc giữ lại. Tư duy nhanh này được thực hiện bởi việc nén thông tin được lặp lại theo nhiều cách khác nhau trong các tập dữ liệu huấn luyện lớn, trong các trọng số của LLM.

Tuy nhiên, ngày càng rõ ràng rằng khi suy luận, hay tư duy chậm, được yêu cầu, các chế độ thất bại của LLM được tiết lộ. Trong cách sử dụng của chúng tôi, suy luận đề cập đến việc thao tác tuần tự các khái niệm có thể được biểu đạt bằng ngôn ngữ. Các nhiệm vụ đòi hỏi truy xuất lặp lại kiến thức hiếm khi được nêu, sự không chắc chắn trên nhiều đối tượng hoặc sự kiện, hoặc nhiều bước suy diễn thì khó khăn ngay cả đối với những LLM tiên tiến nhất (Suzgun et al., 2022). Trong một bộ đánh giá được thiết kế gần đây, BIG-bench (Srivastava et al., 2022), một số nhiệm vụ mà khoảng cách giữa hiệu suất máy và con người lớn bao gồm các chuỗi suy luận với các điều kiện phản thực lồng nhau (SUY DIỄN LOGIC), các khái niệm được giới thiệu thông qua định nghĩa (KẾT HỢP KHÁI NIỆM), v.v. (xem Hình B.1). Đây là những nhiệm vụ mà cảm giác trực quan của người giải về '(không)nhất quán' không đủ để tạo ra câu trả lời đúng, và một chuỗi suy nghĩ, cùng với việc sử dụng các kết quả trung gian, có thể cần thiết để đến được giải pháp, đặc biệt khi bộ nhớ làm việc không đủ.

Chúng tôi cho thấy một số nhiệm vụ trong BIG-bench có thể được giải quyết bằng một cơ chế hai thành phần, mà chúng tôi đặt tên là ThinkSum¹:

¹ThinkSum được đặt tên bằng cách tương tự với các thuật toán khác

--- TRANG 2 ---
Một binne là bất kỳ sinh vật lông lá bốn chân nào, và một bam là một nơi ở đơn giản.
NHẮC TRỰC TIẾP
CHUỖI SUY NGHĨ / KIẾN THỨC PHỤ TRỢ
THINKSUM

Một binne bam là một nơi dành cho người (55%) động vật (44%) chim (0.87%) nhà nghiên cứu (0.022%)

Một binne là bất kỳ sinh vật lông lá bốn chân nào, và một bam là một nơi ở đơn giản.
Ví dụ về binne: mèo, chồn, chuột sương, chuột lang, thỏ.
Ví dụ về bam: túp lều, cabin, cottage, chỗ trú ẩn, lều tranh.
Một binne bam là một nơi dành cho người (51%) động vật (48%) chim (0.76%) nhà nghiên cứu (0.011%)

Một binne là bất kỳ sinh vật lông lá bốn chân nào, và một bam là một nơi ở đơn giản.
binne = {mèo, chồn, chuột sương, chuột lang, thỏ}
bam = {túp lều, cabin, cottage, chỗ trú ẩn, lều tranh}
Một binne bam là một nơi dành cho động vật (65%) người (34%) chim (1.5%) nhà nghiên cứu (0.056%)

THINK (các lời gọi LM phụ trợ để định nghĩa tập hợp)
Một cottage mèo là một nơi dành cho
Một cabin thỏ là một nơi dành cho  
Một chỗ trú ẩn chồn là một nơi dành cho
...

SUM (tổng hợp khả năng LM)

Hình 1: Một ví dụ được chuyển thể từ nhiệm vụ KẾT HỢP KHÁI NIỆM (TỪ PHÁT MINH), trong đó các mô hình phải chọn sự hoàn thành có khả năng nhất của một cụm từ bao gồm các từ vô nghĩa mà định nghĩa của chúng được đưa ra. Trên: Nhắc trực tiếp đánh giá khả năng hoàn thành được chuẩn hóa trên bốn lựa chọn câu trả lời ('người', 'động vật', 'chim', 'nhà nghiên cứu'). Giữa: Các cách tiếp cận kiểu chuỗi suy nghĩ hoặc kiến thức phụ trợ sẽ truy vấn một LLM hoặc cơ sở kiến thức để có thêm ngữ cảnh. Ví dụ này cho thấy sự mong manh khi giao phó tất cả 'suy luận' cho self-attention trong văn bản tuyến tính, đặc biệt trong các mô hình nhỏ hơn, có thiên lệch gần đây mạnh hơn (Malkin et al., 2022): nếu chúng ta chỉ đơn giản liệt kê các ví dụ được tạo ra như ngữ cảnh bổ sung trong lời nhắc, thiên lệch gần đây khiến LLM vẫn đưa ra xác suất cao hơn cho 'người' so với 'động vật', chỉ đơn giản vì các ví dụ 'bam' (nơi ở đơn giản) được đưa ra sau các ví dụ 'binne'. Dưới: Cách tiếp cận ThinkSum của chúng tôi đối với nhiệm vụ này truy vấn một LLM (GPT-2 XL) để tạo ra các tập hợp ví dụ định nghĩa các từ vô nghĩa, sau đó cận biên hóa các sự thay thế của những ví dụ này vào cụm từ mục tiêu.

• Think (tư duy nhanh / liên kết / bước truy xuất kiến thức): tạo ra một liên kết của các đoạn văn bản với các tập hợp chuỗi. Quá trình này có thể bao gồm việc tạo sinh từ một mô hình ngôn ngữ, như trường hợp trong Hình 1, nơi từ mới 'binne' được liên kết với tập hợp chuỗi {'mèo','chồn',...} bằng cách nhắc GPT-3 với định nghĩa và yêu cầu ví dụ. Hoặc, nó có thể chỉ bao gồm một cơ chế chấm điểm, dẫn đến việc hình thành một ma trận xác suất trên đó suy luận xác suất được thực hiện.

• Sum (tư duy chậm / Tóm tắt / bước suy luận): suy luận xác suất tổng hợp các chuỗi được tạo ra hoặc xác suất để tạo ra câu trả lời cuối cùng. Tóm tắt thường bao gồm, và thường hoàn toàn gồm, việc cộng các xác suất của chuỗi (được tính trong bước Think), như trong Hình 1, nơi từ cuối cùng được giả định là được lấy mẫu từ một hỗn hợp các sự thay thế có thể có của từ 'binne' và 'bam' vào đầu vào.

Chúng tôi thảo luận về các cách khác nhau để Think và Sum trong phần §2, nhưng chúng tôi bắt đầu với một ví dụ, được minh họa trong Hình 1 (dưới), được thúc đẩy bởi nhiệm vụ KẾT HỢP KHÁI NIỆM (TỪ PHÁT MINH) trong BIG-bench. Trong nhiệm vụ này, LLM được cung cấp các định nghĩa của hai từ phát minh và được yêu cầu suy luận câu có khả năng nhất sử dụng sự kết hợp của các từ phát minh. Vì các từ không phổ biến hoặc được sử dụng nhất quán trong tập huấn luyện, LLM cần hiểu và kết hợp các định nghĩa của các từ phát minh để suy luận về ý nghĩa của sự kết hợp. LLM được truy vấn để tạo ra các trường hợp ví dụ của các từ phát minh với sự giúp đỡ của các định nghĩa. Những trường hợp ví dụ này có thể được thay thế vào truy vấn thay cho các từ phát minh. Bằng cách ánh xạ các đoạn riêng lẻ của văn bản quan tâm thành các tập hợp, chúng ta đến được một mô hình hỗn hợp (trong ví dụ này, một hỗn hợp với 25 thành phần cho 5 sự thay thế có thể có của mỗi từ), có thể được sử dụng theo cùng cách mà LLM gốc được sử dụng, hoặc để chấm điểm văn bản hoặc để tạo ra nó từng token một. Khi chúng ta chấm điểm tất cả các sự hoàn thành ứng viên sử dụng mô hình hỗn hợp này và chuẩn hóa trên bốn lựa chọn, câu trả lời đúng - rằng 'binne bam' dành cho động vật chứ không phải người - trở thành khả năng nhất.

--- TRANG 3 ---
Một sự khác biệt quan trọng giữa ThinkSum của chúng tôi và các phương pháp kỹ thuật nhắc giống chuỗi suy nghĩ hiện có (Wei et al., 2022; Kojima et al., 2022), là bước suy luận của chúng tôi không được rút gọn thành một vấn đề tạo sinh cho LLM, mà được thực hiện như một suy luận xác suất bên ngoài LLM. Điều này làm giảm tính dễ bị tổn thương đối với các đặc điểm của lời nhắc, chẳng hạn như sự phân tán tình cờ của LLM bởi các mẫu giả mạo (xem Hình 1, giữa). Thay vào đó, chúng tôi thiết kế quá trình tư duy chậm để thực hiện các lời gọi song song đến LLM để truy vấn thông tin trung gian, sau đó có thể thực hiện việc tái kết hợp chuỗi theo chương trình (Think). Bước suy luận cuối cùng - trong đó các khả năng thu được từ LLM cho các sự tái kết hợp được rút ra từ các bước trước đó của quá trình suy luận được kết hợp để đưa ra dự đoán cuối cùng - được để lại cho suy luận xác suất cổ điển (Sum). Theo một nghĩa nào đó, Sum thay thế cơ chế self-attention trên văn bản tuyến tính, được sử dụng như cơ chế 'suy luận' duy nhất trong các cách tiếp cận giống chuỗi suy nghĩ mong đợi các 'suy nghĩ' trung gian có dạng các token được tạo ra can thiệp giữa đầu vào và đầu ra.

Việc áp đặt một hệ thống suy luận thay thế lên một hệ thống "phản ứng tức thì" liên kết có một sự tương tự với các mô hình của quá trình nhận thức con người (Tversky and Kahneman, 1974; Kahneman, 2011) tách biệt Hệ thống 1 (tư duy nhanh) và Hệ thống 2 (tư duy chậm). Hệ thống 2 hoạt động như một 'bộ điều khiển' có thể khởi tạo Hệ thống 1 để thiên lệch thích hợp tư duy nhanh của nó. Trong bối cảnh suy luận với các mô hình học sâu, Hệ thống 2 đã được diễn giải là hoạt động với các khái niệm thưa thớt có thể được mô tả bằng ngôn ngữ (Bengio, 2017; Goyal and Bengio, 2020). Thông qua việc sử dụng lặp lại, các chức năng của Hệ thống 2 trở nên được nén thành trực giác Hệ thống 1, theo cách tương tự mà các chức năng 'suy luận' lặp lại mà các LLM nhỏ hơn không có khả năng trở thành năng lực tạo sinh zero-shot cho các LLM lớn. Như trường hợp với con người, luôn có biên giới tiếp theo của các vấn đề mà một mô hình được huấn luyện với 'trực giác' đáng chú ý cần được làm chậm lại. Tuyên bố chính của bài báo này là nhiều hơn có thể thực hiện được với các LLM ở quy mô hiện có khi chúng được sử dụng cùng với một bộ điều khiển khôn ngoan cho phép suy luận xác suất.

2 ThinkSum

2.1 Cách Think

Ở đây chúng tôi liệt kê các ví dụ về "tư duy nhanh" đi trước giai đoạn tóm tắt.

Các thao tác chuỗi cơ bản. Các cách tiêu chuẩn để biến một câu hỏi thành một lời nhắc có thể được đưa cho LLM để tạo sinh hoặc chấm điểm bao gồm các lựa chọn (ví dụ, của định dạng lời nhắc) có thể được coi là được thực hiện bởi một tác nhân điều khiển. Cách tiếp cận mặc định đối với các câu hỏi trắc nghiệm là viết chúng như các nhiệm vụ Cloze. Tuy nhiên, có những hoạt động không tầm thường được sử dụng trong các quy trình suy luận đôi khi hoạt động tốt hơn, chẳng hạn như:

• Đảo ngược thứ tự: Trao đổi thứ tự của câu hỏi và câu trả lời, như trong Min et al. (2022).

• Xóa tiền đề: Xóa một phần của câu hỏi. Loại bỏ một tiền đề mà câu trả lời được mong đợi có thông tin tương hỗ cao là một bước trong các quy trình suy luận nhằm điều chỉnh thiên lệch đối với các câu trả lời có khả năng vô điều kiện cao (Zhao et al., 2021; Holtzman et al., 2021; Malkin et al., 2022).

Thay thế và chuẩn hóa. Một ví dụ được hiển thị trong Hình 1. Các phần tử từ một tập hợp có thể được thay thế thay cho các từ 'khe' trong một lời nhắc, chẳng hạn như 'mèo' được thay thế cho 'binne' trong lời nhắc "Một binne bam là một nơi dành cho ". Hoạt động này có thể được kết hợp với các bước chuẩn hóa cú pháp được thực hiện một cách đáng tin cậy bởi các công cụ NLP tiêu chuẩn, chẳng hạn như đảm bảo sự phù hợp chủ-động từ.

Tạo sinh ví dụ và danh sách. Một LLM có thể được nhắc để tạo sinh hoặc chấm điểm danh sách các từ hoặc cụm từ. Chúng tôi đề xuất và thử nghiệm với ba trường hợp của điều này:

• Tạo sinh ví dụ: Trong Hình 1, LLM được nhắc để biến một định nghĩa hoặc tính chất đặc trưng, chẳng hạn như 'nơi ở đơn giản', thành một danh sách ví dụ. Điều này có thể đạt được với một lời nhắc như "Một bam là một nơi ở đơn giản. Ví dụ: 1.". Sự hoàn thành được tạo ra có thể được phân tích thành một tập hợp để sử dụng sau này trong quy trình suy luận.

• Mở rộng danh sách: Một cách tiếp cận tương tự cũng có thể được sử dụng để ảo giác thêm các câu trả lời có thể có cho các câu hỏi, như chúng tôi sẽ hiển thị trong một số thí nghiệm.

• Danh sách từ: Các lời nhắc tương tự cung cấp một phương pháp Think thậm chí đơn giản hơn mà chúng tôi sử dụng để chấm điểm - nhưng không tạo sinh - trong một số nhiệm vụ. Chỉ nhắc một LLM với "Danh sách từ: A,B", trong đó A và B là từ hoặc cụm từ, và tính toán khả năng của B có điều kiện trên "Danh sách từ: A," là một thước đo tốt về mức độ liên quan ngữ nghĩa của A và B.

--- TRANG 4 ---
Tạo sinh sự kiện. Cách Think này liên kết một từ đầu vào với một tập hợp các cụm từ theo cách tương tự như tạo sinh các ví dụ từ một định nghĩa. Nó có thể được thực hiện với các lời nhắc như "Liệt kê sự kiện về mèo. 1.". Các sự kiện được tạo ra là mục tiêu tốt cho việc thay thế các khái niệm khác ('chó', 'thiên hà') thay cho khái niệm ('mèo') mà sự kiện được tạo ra. Một biến thể của điều này yêu cầu LLM tạo ra sự khác biệt giữa hai khái niệm, như được hiển thị trong Hình 2 (phải).

Dịch thuật. LLM có thể được nhắc để chuyển đổi giữa các dạng khác nhau của việc biểu diễn cùng một khái niệm như một chuỗi token. Chúng tôi sử dụng hai ví dụ cơ bản của điều này trong các thí nghiệm:

• Dịch giữa các ngôn ngữ bằng cách nhắc LLM ở các định dạng như "Tiếng Pháp: J'adore les chats noirs. Tiếng Anh:". Một cách tiếp cận rất tương tự có thể được sử dụng để chuyển đổi các ký hiệu không chữ cái, chẳng hạn như emoji, thành từ có ý nghĩa tương tự.

• Chuyển đổi văn bản thành các cấu trúc hình thức (ký hiệu), như biến một bài toán từ thành một tập hợp các phương trình toán học.

2.2 Cách Sum

Suy luận cơ bản. Như trên, chúng tôi bắt đầu bằng cách liệt kê các cách tiêu chuẩn hiện có để biến đầu ra LLM thành câu trả lời, mà chúng tôi coi là các trường hợp tầm thường của tổng hợp (Sum).

• Bỏ phiếu đa số/thiểu số (argmin/argmax): một thành phần của hầu hết các quy trình lựa chọn câu trả lời.

• Tỷ lệ khả năng: Khả năng từ các biến thể khác nhau của cùng một lời nhắc có thể được kết hợp bằng cách xem xét tỷ lệ của chúng hoặc hỗn hợp log-tuyến tính hoặc khác tổng quát hơn. Ví dụ, điều này có thể được thực hiện để điều chỉnh khả năng của một câu trả lời có điều kiện trên một câu hỏi bằng khả năng vô điều kiện của nó, kết hợp với hoạt động Xóa tiền đề được mô tả ở trên.

Tổng hợp hỗn hợp (trung bình). Một tập hợp các lời nhắc có thể được coi là các thành phần của một mô hình hỗn hợp trên các sự hoàn thành. Một ví dụ được hiển thị trong Hình 1, nơi các sự thay thế của một tập hợp từ tạo ra 25 lời nhắc khác nhau. Khả năng của sự hoàn thành trên 25 lời nhắc này được tính trung bình.

Tổng hợp tích. Chúng tôi sử dụng tích của khả năng theo hai cách khác nhau:

• Theo cách tương tự như hỗn hợp, nhưng khi mô hình xác suất tự nhiên hơn có tất cả các phần tử của một tập hợp (của lời nhắc) tạo ra câu trả lời, chẳng hạn như khi một mô tả hoặc định nghĩa phải được thỏa mãn bởi tất cả các khái niệm trong một tập hợp.

• Trong một nhiệm vụ mà chúng ta phải xác định liệu một phát biểu S hoặc phủ định S' của nó có đúng không, chúng ta có thể tính toán khả năng của cả S và S' đều đúng (như hậu nghiệm trên các token 'Đúng' và 'Sai' trong một lời nhắc phù hợp), sau đó so sánh p(Đúng|S)p(Sai|S') (S đúng và S' sai) với p(Sai|S)p(Đúng|S') (S sai và S' đúng).

3 Thí nghiệm

Trong phần này, chúng tôi thực hiện các nghiên cứu trường hợp trên ba nhiệm vụ từ bộ BIG-bench để chứng minh các khả năng của các cách tiếp cận suy luận được thảo luận trong §2. Chúng tôi cũng thử nghiệm với mười nhiệm vụ khác từ BIG-bench; các kết quả tốt nhất được tóm tắt trong Bảng 1 và các phương pháp, được nhóm theo phong cách Think và Sum, được mô tả trong Phụ lục (§A).

Tất cả chi tiết của các nhiệm vụ có thể được tìm thấy trong Phụ lục (§C). Các so sánh với nhắc trực tiếp và các thuật toán thêm token được truy xuất hoặc tạo sinh vào lời nhắc được đưa ra trong §3.4.

3.1 Kết hợp khái niệm: Từ phát minh

Trong TỪ PHÁT MINH, hai từ vô nghĩa x₁, x₂ được định nghĩa và phát biểu đúng phải được chọn từ một tập hợp các phát biểu S={sⱼ} bắt đầu với (có thể là dạng biến cách của) "x₁x₂" (Hình 1).

Chúng tôi sử dụng một lời nhắc Tạo sinh ví dụ để thu được một tập hợp các từ ví dụ phù hợp với các định nghĩa của x₁ và x₂. Do đó chúng tôi thu được các tập hợp S₁ và S₂ của các từ có thể được thay thế cho x₁ và x₂, tương ứng.

Chúng tôi coi mỗi phát biểu sⱼ như một mẫu mà các từ w₁∈S₁ và w₂∈S₂ có thể được thay thế bằng cách thay thế xᵢ với wᵢ và chuẩn hóa cú pháp để đảm bảo sự phù hợp chủ-động từ. Ký hiệu bởi sⱼ⟨w₁,w₂⟩ một sự thay thế như vậy, chúng tôi hình thành một vector xác suất pⱼ bằng cách chấm điểm sự Thay thế của mỗi cặp từ có thể có vào mỗi phát biểu và thực hiện tổng hợp Hỗn hợp và xem xét Tỷ lệ khả năng với mẫu không có sự thay thế:

pⱼ = 1/(|S₁||S₂|) Σ_{w₁∈S₁,w₂∈S₂} p_{LLM}(sⱼ⟨w₁,w₂⟩)/p_{LLM}(sⱼ).

Phát biểu sⱼ có khả năng cao nhất dưới hỗn hợp chuẩn hóa này, arg max_j pⱼ, được chọn.

3.2 Tìm cái khác biệt

Chúng tôi kiểm tra các cách tiếp cận Think và Sum có thể có một cách sâu sắc trên nhiệm vụ TÌM CÁI KHÁC BIỆT, trong đó

--- TRANG 5 ---
[Bảng chứa kết quả GPT-3 và ThinkSum với các số liệu về độ chính xác]

Hình 2: TÌM CÁI KHÁC BIỆT. Trái: Hiệu suất của GPT-3 (n-shot, n=0,1,2,3), kiến thức phụ trợ, và ThinkSum với các kích thước mô hình khác nhau. Giữa: Kiến thức phụ trợ so với ThinkSum với số lượng khác biệt thay đổi. Phải: Lời nhắc được sử dụng để tạo ra các phát biểu kiến thức.

từ trong một tập hợp W={wᵢ} ít liên quan về mặt ngữ nghĩa nhất với những từ khác phải được chọn (ví dụ, Chọn từ khác biệt: kính, đầu, cánh tay, chân, bàn tay, bàn chân).

Danh sách từ. Chúng tôi hình thành một ma trận liên quan ngữ nghĩa Pᵢⱼ bằng cách truy vấn LLM với một lời nhắc Think Danh sách từ cho mỗi cặp chỉ số i,j:

Pᵢⱼ = p_{LLM}(wⱼ|"Danh sách từ: wᵢ,").

Ma trận này được tổng hợp bằng cách tính trung bình trên j (trong miền log) và chọn i có trung bình thấp nhất, tức là, khả năng thấp nhất được tạo ra bởi một hỗn hợp tích của tất cả các từ trong tập hợp: i = arg min_i ∏_j Pᵢⱼ.

Điều này là một trường hợp của tổng hợp Tích.

Bởi vì cách tiếp cận này thành công nhất với tất cả các kích thước mô hình mà chúng tôi thử nghiệm, hiệu suất của nó được báo cáo trong Bảng 1. Đáng chú ý, độ chính xác gần mức trung bình con người được duy trì cho tất cả các kích thước mô hình từ GPT-2 Small đến mô hình GPT-3 lớn nhất (Hình 2 (trái)).

Tạo sinh sự kiện. Như một cách tiếp cận thay thế, chúng tôi sử dụng một lời nhắc Tạo sinh sự kiện. Một cách hiệu quả để khai thác sự kiện cho các nhiệm vụ liên quan ngữ nghĩa là xem xét hai mục trong cùng một ngữ cảnh để có được sự kiện liên quan về cách các mục liên quan với nhau (lời nhắc trong Hình 2 (phải)). Minh họa được sử dụng trong lời nhắc đảm bảo rằng LLM tạo ra các phát biểu theo định dạng mong đợi, có thể được phân tích và sử dụng để tính toán xác suất sau này. Sử dụng lời nhắc này, chúng tôi thu được một tập hợp các phát biểu S={sᵢ} về các mục wⱼ. Chúng tôi coi mỗi sᵢ được tạo ra như một mẫu mà các từ w khác nhau có thể được thay thế và ký hiệu bởi sᵢ⟨w⟩ sự Thay thế của từ w vào mẫu sᵢ. Sau đó chúng tôi hình thành một ma trận |S|×|W| Pᵢⱼ, được định nghĩa

--- TRANG 6 ---
bởi Pᵢⱼ = p_{LLM}(sᵢ⟨wⱼ⟩). Sau đó, chúng tôi có thể thực hiện Bỏ phiếu thiểu số: chúng tôi lấy argmin trên j và chọn giá trị xuất hiện thường xuyên nhất làm câu trả lời, tức là, mục thường xuyên nhất ít có khả năng phù hợp với một phát biểu được tạo ra.

So sánh với các cách tiếp cận kiến thức phụ trợ. Chúng tôi so sánh phương pháp của mình với một phương pháp nhắc dựa trên kiến thức, ở đây được gọi là kiến thức phụ trợ. Trong kiến thức phụ trợ, chúng tôi thêm vào trước các sự kiện được tạo ra trong lời nhắc trước câu hỏi. Chi tiết của lời nhắc cho kiến thức phụ trợ được cung cấp trong §D.3. Trong Hình 2 (giữa), chúng tôi cho thấy rằng độ chính xác của ThinkSum dựa trên Tạo sinh sự kiện tăng lên khi số lượng sự kiện được tạo ra tăng lên, trong khi kỹ thuật kiến thức phụ trợ đạt đỉnh và sau đó giảm xuống khi lời nhắc dài ra.

Hình 2 (trái) cho thấy hiệu suất thay đổi như thế nào với kích thước của LLM được sử dụng cho GPT-3, kiến thức phụ trợ và ThinkSum trên TÌM CÁI KHÁC BIỆT. Ngay cả với GPT-2 Small, ThinkSum cải thiện đáng kể so với các mô hình zero- hoặc few-shot lớn nhất với hoặc không có kiến thức phụ trợ. Một phiên bản được tinh chỉnh của mô hình GPT-3 lớn nhất, text-davinci-002, là mô hình duy nhất, với sự giúp đỡ của kiến thức phụ trợ, đạt được hiệu suất cạnh tranh với ThinkSum. Kết quả này cung cấp bằng chứng thực nghiệm cho tuyên bố của chúng tôi rằng trong khi các mô hình mới có thể tạo ra những bước nhảy chất lượng, ThinkSum có thể đẩy giới hạn hiệu suất của các mô hình nhỏ hơn.

Mô hình biến ẩn. Như chúng tôi đã chỉ ra, việc phát hiện mục khác biệt có thể được thực hiện với các hoạt động suy luận đơn giản trên các mục, sự kiện và khả năng chung của chúng. Tuy nhiên, cũng có thể giả định một cấu trúc ẩn trong các mục và sự kiện, bao gồm hai hoặc nhiều cụm sao cho các sự kiện và mục thuộc về một cụm có thể được trao đổi tự do. Chúng tôi mô tả một mô hình biến ẩn cụ thể cho vấn đề cho phép chọn các sự kiện đặc trưng cho lớp đa số, do đó giải thích tại sao mục thiểu số được quy là cái khác biệt và giúp diễn giải các quyết định của hệ thống.

Chúng tôi mô hình các mục i∈I và sự kiện f∈F như được tạo ra từ một lớp ẩn c∈{0,1}. Phân phối được mô hình như:

P(i,f) = Σ_c P(c)P(i|c)P(f|c)

trong đó P(i,f) là một ma trận khả năng từ LLM và các thành phần ngữ nghĩa, nhóm P(i|c) và P(f|c), được rút ra từ ma trận sử dụng một quy trình suy luận expectation-maximization (EM; Dempster et al., 1977) lặp tiêu chuẩn (xem §E). Sau đó, điểm số cho một mục i thuộc về một cụm và tất cả các mục khác m∈S,{m≠i} thuộc về một cụm khác có thể được tìm thấy như Sᵢ = Σ_{c,c'≠c} P(i|c)P(c) ∏_{m≠i} P(m|c')P(c').

Chúng tôi cho thấy hiệu quả của các mô hình biến ẩn trong Bảng 2, nơi chúng tôi phân tích các phương pháp khác nhau để giải quyết TÌM CÁI KHÁC BIỆT sử dụng các biến thể InstructGPT text-davinci-001 và text-davinci-002. Cho các phương pháp 'mô hình biến ẩn' và 'bỏ phiếu thiểu số', chúng tôi sử dụng số lượng khác biệt N_d=5. Mô hình biến ẩn được huấn luyện cho 200 lần lặp EM. Tất cả các phương pháp suy luận xác suất đều hoạt động tốt, vượt trội so với các baseline trước đó được báo cáo trong Bảng 1. Suy luận sử dụng EM, cũng như các cách tiếp cận khác, có thể được coi là một hoạt động Sum (suy luận) và có thể áp dụng được trong các nhiệm vụ khác có cấu trúc tương tự.

3.3 Suy diễn logic

Trong nhiệm vụ SUY DIỄN LOGIC, các loại mục khác nhau và manh mối liên quan đến thứ tự của chúng được cung cấp (Hình 3(a)). Mục tiêu là chọn phát biểu đúng từ một tập hợp các phát biểu về vị trí của chúng. Các vấn đề sắp xếp thứ tự bao gồm các loại đối tượng khác nhau (xe hơi, chim, v.v.) và thứ tự (theo kích thước, giá cả, xếp hạng cuộc thi, v.v.). Những người tạo ra nhiệm vụ nhấn mạnh rằng nhiệm vụ này đòi hỏi phân tích thông tin về nhiều đối tượng và mối quan hệ của chúng, hiểu các quy tắc liên quan đến các đối tượng được sắp xếp trong các tình huống khác nhau, và áp dụng lặp lại các quy tắc này. Các lời gọi LLM trong giai đoạn Think của ThinkSum có thể thực hiện các ánh xạ cần thiết để phân tích thông tin và hiểu quy tắc, và giai đoạn Sum có thể tích hợp các ánh xạ của đối tượng đến vị trí dưới các quy tắc này. Ở đây, chúng tôi sử dụng một lời nhắc Dịch thuật để ánh xạ vấn đề đã cho thành một tập hợp các (bất)đẳng thức toán học (Hình 3(c)).

Lời nhắc Dịch thuật trong Hình 3(b), chứa các phát biểu sắp xếp thứ tự chung và tên đối tượng không được sử dụng trong nhiệm vụ như một minh họa trong ngữ cảnh, đủ để thực hiện việc dịch từ ngôn ngữ tự nhiên sang phương trình. Bằng cách thêm vào trước

--- TRANG 7 ---
[Hình 3 hiển thị chi tiết cho SUY DIỄN LOGIC với ví dụ câu hỏi, minh họa cho lời nhắc Think và ví dụ đầu ra LLM]

lời nhắc minh họa này vào một phát biểu vấn đề, chúng tôi khuyến khích LLM ánh xạ các đối tượng trong vấn đề thành tập hợp các chuỗi tương ứng với các số từ 1 đến N, trong đó N là số lượng đối tượng, và tạo ra một tập hợp các bất đẳng thức (Hình 3(c)).

Khi một bản dịch của vấn đề thành một tập hợp các bất đẳng thức được thu được, giai đoạn Sum xem xét tất cả các ánh xạ có thể có của các mục đến chỉ số để xác định ánh xạ tương thích với tập hợp (bất)đẳng thức được khám phá. Điều này có thể được thực hiện bởi một thuật toán bên ngoài hoặc bởi chính LLM, vì một LLM có thể có khả năng hiểu rằng, ví dụ, "2>3" là một chuỗi ít có khả năng hơn "2>1" (xem §D.2).

Cuối cùng, xác suất của mỗi phát biểu ứng viên, như "sách vàng=2", do đó có thể được thu được bằng:

p("sách vàng=2"|T) ∝ Σ_{b∈{1,...,N}^N} p_{LLM}({T_t⟨b⟩:T_t∈T} ∪ {"sách vàng=2"⟨b⟩}) (1)

trong đó b biểu thị vector vị trí cho N mục (ví dụ, (5,2,3,4,1)), T={T_t}_{t=1}^N là tập hợp các bất đẳng thức thu được từ lời nhắc Dịch thuật như một tập hợp các chuỗi (ví dụ, "sách đen<sách tím"), và s⟨b⟩ biểu thị sự thay thế của mục tương ứng trong b thay cho tên đối tượng trong chuỗi s (ví dụ, "4<5"). Thuật ngữ bên trong tổng là một trường hợp của tổng hợp Tích: khả năng LLM của tất cả các chuỗi trong tập hợp được nhân lại.

Tóm lại, giải pháp của chúng tôi cho nhiệm vụ này bao gồm việc kết hợp hai hoạt động Think - một Dịch thuật thành một tập hợp phương trình và sau đó Thay thế số thay cho tên mục - và hai hoạt động Sum - một tổng hợp Tích theo sau bởi một tổng hợp Hỗn hợp. (Các tùy chọn khác được thảo luận dưới đây.)

Kết quả và thảo luận. Cho 500 vấn đề SUY DIỄN LOGIC với N=5 đối tượng, ThinkSum mang lại độ chính xác 77% (xem Bảng 1), vượt qua hiệu suất trung bình của con người. Khi các phép tính cần thiết trở nên lớn, việc kỹ thuật nhắc thuần túy có thể cạnh tranh trở nên rất khó xảy ra, vì ngay cả con người cũng cần giấy và bút để tạo ra và chú ý đến nhiều giải pháp thay thế, và có thể sẽ dịch các tiền đề thành một ký hiệu đơn giản hơn sử dụng một chữ cái duy nhất (đại diện cho một biến mà một giá trị số có thể được gán) để đại diện cho mỗi đối tượng, thay vì trực tiếp chú ý đến các từ trong phát biểu vấn đề.

Chúng tôi cũng kiểm tra một phương pháp kiến thức phụ trợ tương tự như suy luận chuỗi suy nghĩ, nơi thông tin thu được với lời nhắc trong Hình 3 được thêm vào đầu vào LLM. Cụ thể, vấn đề, cùng với bản dịch của nó thành bất đẳng thức, được sử dụng như một lời nhắc cho mỗi tùy chọn câu trả lời, và sau đó tùy chọn có khả năng cao nhất được chọn làm câu trả lời. Cách tiếp cận này thực sự cải thiện so với chấm điểm GPT-3 zero-shot đơn giản, nhưng chỉ nâng độ chính xác lên 50% (xem §3.4 và Bảng 3).

Tối ưu hóa, chế độ thất bại và mở rộng. Chúng tôi đã thấy rằng InstructGPT có thể cả dịch các vấn đề suy diễn logic thành (bất)đẳng thức

--- TRANG 8 ---
(Hình 3) và đánh giá từng cái trong số chúng sau khi thay thế các mục bằng số vị trí (§D.2). Chúng tôi kết luận rằng giai đoạn Sum chỉ đơn giản là để tìm kiếm trên tất cả các ánh xạ có thể có, theo cách mà một con người có thể làm. Nhưng, giống như một con người có thể sử dụng các phím tắt trong tìm kiếm, giai đoạn Sum của ThinkSum có thể được triển khai theo các cách hiệu quả hơn hoặc kém hơn. Ví dụ, thay vì tính tổng trên tất cả các phép gán có thể có của năm mục, chúng ta có thể tránh những cái không phải là hoán vị của {1,2,3,4,5}. Hơn nữa, thay vì sử dụng p_LLM từ Hình D.1 trong (1), chúng ta có thể đơn giản đánh giá mỗi bất đẳng thức bên ngoài, đưa ra một xác suất hằng số cao cho mỗi bất đẳng thức T_t⟨b⟩ đúng và một xác suất thấp khi nó sai, hoặc việc tính tổng có thể bị hủy bỏ bất cứ khi nào một phát biểu không chính xác được phát hiện trong một phép gán b cụ thể của vị trí cho các mục.

Lời nhắc trong Hình 3(b) hướng dẫn LLM gán các số nguyên dương tùy thuộc vào ngôn ngữ được sử dụng (ví dụ, đối tượng nhỏ nhất nhận được 1), nhưng một hành vi phổ biến của LLM là tổng quát hóa để gán các số âm, chẳng hạn như sử dụng -2 để đại diện cho 'thứ hai từ cuối' (hoặc lớn thứ hai, v.v.). Để duy trì tính bền vững đối với hành vi như vậy của giai đoạn Think, chúng ta có thể chuyển đổi các số vị trí âm r thành N+r+1 trước khi đánh giá các phát biểu.

Tuy nhiên, một chế độ thất bại liên tục của loại ThinkSum này là LLM có thể dịch các phát biểu bất đẳng thức không nhất quán với các phát biểu đẳng thức (ví dụ, bằng cách mã hóa mục ngoài cùng bên trái là 1 và nhất quán với lựa chọn này cho các ràng buộc đẳng thức khác, nhưng dịch các ràng buộc bất đẳng thức nhất quán với thứ tự ngược lại, với 'bên trái của' có nghĩa là >). Những thất bại như vậy có thể được giải quyết bằng kỹ thuật cẩn thận trong giai đoạn Sum, chẳng hạn như bằng cách tính tổng một biến ẩn nhị phân chỉ ra liệu các bất đẳng thức có nên được đảo ngược hay không. Điều này tăng số lượng đánh giá mô hình, nhưng cũng cho phép tự động sửa chữa mạnh mẽ bởi giai đoạn Sum các không nhất quán trong giai đoạn Think.

3.4 So sánh với các cách tiếp cận chuỗi suy nghĩ và kiến thức phụ trợ

ThinkSum so với kiến thức phụ trợ. Bảng 3 cho thấy so sánh ThinkSum với các thuật toán thêm kiến thức phụ trợ như một 'chuỗi suy luận' tiên tri. Cho LIÊN QUAN CỤM TỪ, kiến thức phụ trợ được tạo ra sử dụng lời nhắc "liệt kê khác biệt" được hiển thị trong Hình 2 (phải). Cho cả kiến thức phụ trợ và ThinkSum, 6 khác biệt được tạo ra được sử dụng, vì đó là tốt nhất cho kiến thức phụ trợ (xem Hình 2 (giữa)). ThinkSum TÌM CÁI KHÁC BIỆT và LIÊN QUAN CỤM TỪ được giải quyết với lời nhắc "danh sách từ". Cho SUY DIỄN LOGIC, lời nhắc Think được hiển thị trong Hình 3 được bao gồm trước câu hỏi trong lời nhắc. Trong tất cả các trường hợp, ThinkSum vượt trội so với kiến thức phụ trợ.

ThinkSum so với chuỗi suy nghĩ. Theo Wei et al. (2022), chúng tôi sử dụng "phương pháp chuỗi suy nghĩ (CoT)" để có nghĩa là các cách tiếp cận chấm điểm LLM sử dụng việc chèn các token được tạo ra giữa lời nhắc và câu trả lời mục tiêu. Mô hình được dạy, sử dụng các minh họa few-shot, cách tạo ra những token trung gian này. Ở trên chúng tôi đã so sánh ThinkSum với các cách tiếp cận thêm chuỗi token được trích xuất (từ một lời gọi LM phụ trợ), không được tạo ra (trong không gian làm việc tuyến tính của LM) sau lời nhắc, cho các nhiệm vụ TÌM CÁI KHÁC BIỆT, LIÊN QUAN CỤM TỪ, và SUY DIỄN LOGIC (xem Bảng 3).

Với các ví dụ phù hợp, có thể một cách tiếp cận CoT thay thế giai đoạn Think, bằng cách học từ các minh họa để tạo ra kiến thức thích hợp, và các phần của giai đoạn Sum, mặc dù suy luận trên các đánh giá song song của LLM không còn có thể. Các baseline kiến thức phụ trợ của chúng tôi thực hiện chính xác giả định rộng rãi đó và tập trung các so sánh vào nhu cầu về các lời gọi song song và suy luận trên các khả năng sử dụng suy luận xác suất (thay vì để lại cho LLM đưa ra kết luận đúng từ danh sách các lựa chọn thay thế được trích xuất).

Mặc dù chúng tôi mong đợi rằng việc thêm sự kiện theo định dạng tiêu chuẩn vào lời nhắc sẽ giúp mô hình nhiều hơn so với việc dạy mô hình tạo ra những sự kiện này, chúng tôi đã thử nghiệm với các cách tiếp cận CoT trên một số nhiệm vụ. Bảng A.1 cho thấy các minh họa ví dụ và định dạng lời nhắc được sử dụng cho mỗi nhiệm vụ, và Bảng 4 cho thấy kết quả sử dụng hai biến thể của mô hình GPT-3 lớn nhất.

Như mong đợi, ThinkSum vượt trội so với nhắc CoT trên tất cả các nhiệm vụ với tất cả các biến thể ngoại trừ NHỮNG ĐIỀU CHƯA BIẾT với biến thể davinci, nơi nhắc trực tiếp đã hoạt động tốt. (Chúng tôi không đánh giá ThinkSum với davinci trên SUY DIỄN LOGIC vì các lời nhắc như

--- TRANG 9 ---
[Bảng 4 hiển thị so sánh ThinkSum với các cách tiếp cận nhắc chuỗi suy nghĩ]

một trong Hình 3 không tạo ra đầu ra đáng tin cậy ở định dạng chính xác; lưu ý rằng CoT chỉ hơi tốt hơn đoán ngẫu nhiên (20%).)

Khi diễn giải những kết quả này, điều quan trọng cần lưu ý là chỉ một định dạng lời nhắc được đánh giá cho cả CoT và ThinkSum, và định dạng của lời nhắc và minh họa có thể có ảnh hưởng mạnh và thường không thể dự đoán được đến LLM. Chúng tôi quan sát thấy rằng các cách tiếp cận CoT rất nhạy cảm với những thay đổi nhỏ trong định dạng lời nhắc hoặc việc xây dựng các ví dụ trong ngữ cảnh, phù hợp với các thiên lệch đã biết của học trong ngữ cảnh (Lu et al., 2022; Zhao et al., 2021). Mặt khác, việc sử dụng các thành phần có cấu trúc, ngắn gọn hơn đáng tin cậy hơn, như được chứng minh bởi hiệu quả của các lời nhắc Think được sử dụng trong ThinkSum.

4 Công trình liên quan

Cải thiện suy luận LLM. Sau khi phát hiện ra khả năng học trong ngữ cảnh của LLM, đã có một sự bùng nổ quan tâm đến việc cải thiện suy luận với LLM trong cài đặt zero-shot và few-shot (Brown et al., 2020; Chowdhery et al., 2022; Rae et al., 2021). Một cách tiếp cận để cải thiện khả năng suy luận của LLM bao gồm việc thêm vào, hoặc học để tạo ra, kiến thức phụ trợ trong lời nhắc (Shwartz et al., 2020; Zelikman et al., 2022; Nye et al., 2021a). Gần đây, các phương pháp nhắc kiến thức phụ trợ hoặc chuỗi suy nghĩ tổng quát hơn đã được đề xuất (Wei et al., 2022; Wang et al., 2022b; Zhou et al., 2022a; Creswell et al., 2022; Wang et al., 2022a; Liu et al., 2022b), bao gồm những phương pháp cho phép một luồng điều khiển bên ngoài LLM chính (Khot et al., 2022). Sau đó, Kojima et al. (2022) đã chỉ ra rằng nhắc chuỗi suy nghĩ zero-shot có thể cải thiện hiệu suất trên nhiều nhiệm vụ suy luận. Phương pháp này không yêu cầu bất kỳ ví dụ few-shot thủ công nào, đây là một tính chất chung với ThinkSum. (Nye et al., 2021b) quan sát thấy rằng một cách tiếp cận hệ thống kép nơi một "Hệ thống 1" liên kết và một "Hệ thống 2" logic có thể tăng tính nhất quán của LLM trong các nhiệm vụ như tạo ra câu chuyện mạnh mẽ và theo dõi hướng dẫn có căn cứ. Mô hình hai bước trong ThinkSum tương tự, nơi "Hệ thống 1" là (việc truy vấn LLM cho) tư duy nhanh, và "Hệ thống 2" là bước suy luận xác suất.

Tính mong manh của nhắc chuỗi suy nghĩ. Mặc dù thành công gần đây của các cách tiếp cận chuỗi suy nghĩ, các nghiên cứu gần đây đã nêu lên mối quan ngại về những hạn chế của các cách tiếp cận chuỗi suy nghĩ. Webson và Pavlick (2022) quan sát thấy rằng các lời nhắc hướng dẫn hoạt động tương tự với các lời nhắc gây hiểu lầm hoặc cố ý không liên quan. Ngoài ra, Ye và Durrett (2022) cho thấy những cải thiện do chuỗi suy nghĩ few-shot không được quan sát thấy trong trả lời câu hỏi, hoặc suy luận ngôn ngữ tự nhiên. Quan trọng hơn, các lời nhắc few-shot rất nhạy cảm với thứ tự mà các mẫu được cung cấp, định dạng lời nhắc, và việc lựa chọn các ví dụ trong ngữ cảnh, (Lu et al., 2022; Zhao et al., 2021). Do đó, điều quan trọng là thiết kế các kỹ thuật mạnh mẽ đối với những thay đổi như vậy trong lời nhắc.

Suy luận như suy luận. Suy luận lặp trên đầu ra LLM đã được đề xuất để giải quyết trả lời câu hỏi đúng/sai và trả lời câu hỏi thường thức (Jung et al., 2022; Liu et al., 2022a). Xie et al. (2021) trình bày một quan điểm suy luận Bayesian về học trong ngữ cảnh, và Dohan et al. (2022) chính thức hóa và thống nhất các kỹ thuật nhắc hiện có trong một khung xác suất. Công trình của chúng tôi tổng quát hóa các cách tiếp cận như vậy để thực hiện suy luận xác suất tùy ý bên ngoài LLM.

5 Kết luận

Trong bài báo này, chúng tôi đã trình bày ThinkSum, một mô hình suy luận xác suất hai bước suy luận trên các tập hợp theo cách có cấu trúc. Giai đoạn tư duy nhanh của ThinkSum cho phép các thao tác chuỗi cơ bản cũng như nhắc ngôn ngữ tự nhiên, có thể cho phép nhiều cách tiếp cận để giải quyết một nhiệm vụ ngôn ngữ tự nhiên. Ngay cả với các biến thể mô hình nhỏ hơn nhiều, ThinkSum đạt được kết quả hiện đại trên mười nhiệm vụ khó trong BIG-bench sử dụng các mô hình họ GPT. Mô hình hai bước cho phép hoạt động trên các tập hợp thay vì thao tác chính lời nhắc, ngăn chặn sự nhạy cảm với định dạng lời nhắc trong suy luận xác suất trong ThinkSum, được thực hiện bên ngoài các lời gọi đến LLM. Kết quả là, ThinkSum mạnh mẽ hơn đối với thiết kế lời nhắc, mang lại các dự đoán có thể diễn giải hơn, và có thể được kết hợp với nhiều cách tiếp cận suy luận xác suất để giải quyết một tập hợp đa dạng các nhiệm vụ.

--- TRANG 10 ---
Lời cảm ơn
Các tác giả cảm ơn Alexandros Graikos, Sudha Rao, và Alessandro Sordoni cho những thảo luận quý giá.

Hạn chế
ThinkSum được đề xuất của chúng tôi đã chứng minh hiệu suất mạnh mẽ trên mười ba nhiệm vụ BIG-bench đầy thách thức. Tuy nhiên, điều quan trọng là thừa nhận những hạn chế nhất định của hệ thống.

Thứ nhất, khi số lượng đối tượng hoặc sự kiện được suy luận tăng lên, chi phí tính toán cũng sẽ tăng lên. Tuy nhiên, việc tăng số lượng đối tượng cũng sẽ làm cho nhiệm vụ khó hơn, và nhắc trực tiếp có thể hoàn toàn ngừng hoạt động (như chúng tôi thực sự quan sát trong kết quả BIG-bench, chẳng hạn như SUY DIỄN LOGIC với hơn năm đối tượng), trong khi ThinkSum cung cấp một phương pháp có thể tổng quát hóa, vì các hoạt động Think nguyên tử không tăng độ phức tạp khi số lượng đối tượng tăng lên.

Thứ hai, khi giải quyết một nhiệm vụ mới, cần thiết phải bỏ ra nỗ lực của con người để chọn các hoạt động cụ thể trong mỗi bước, như được nêu trong §2. Hạn chế này được chia sẻ với kỹ thuật nhắc của tất cả các loại, bao gồm nhắc trực tiếp hoặc chuỗi suy nghĩ: tìm một lời nhắc cho một nhiệm vụ mới đòi hỏi một quy trình kỹ thuật nhắc thường cồng kềnh.

Chúng tôi đã mô tả ThinkSum như một mô hình hai giai đoạn tổng quát, với một bước suy luận bên ngoài. Tính tổng quát này nhằm tạo điều kiện cho việc thích ứng ThinkSum với các nhiệm vụ mới, với những sửa đổi tối thiểu cho các bước Think và Sum. Công việc về tự động hóa quy trình kỹ thuật nhắc (Zhou et al., 2022b) là một con đường đầy hứa hẹn để vượt qua hạn chế này. Một thay thế cho kỹ thuật nhắc không đòi hỏi nỗ lực con người như vậy là điều chỉnh (tức là, học end-to-end có thể vi phân) lời nhắc hoặc tham số mô hình; tuy nhiên, điều này vẫn không thực tế đối với các mô hình quy mô GPT-3, và các nỗ lực điều chỉnh mô hình trực tiếp trên các chuỗi suy luận ký hiệu đã gặp thành công hạn chế (Kassner et al., 2020).

Cuối cùng nhưng không kém phần quan trọng, ThinkSum chủ yếu được đánh giá với các mô hình GPT-3 (davinci) và InstructGPT (text-davinci-002). Để cải thiện hiệu suất hơn nữa, có thể có lợi khi áp dụng ThinkSum cho các mô hình được điều chỉnh hướng dẫn gần đây hơn như Flan-PaLM (Chowdhery et al., 2022; Chung et al., 2022), text-davinci-003, ChatGPT, và GPT-4, có vẻ có khả năng thực hiện các bước Think một cách mạnh mẽ hơn.

Tuyên bố đạo đức và tác động
Chúng tôi không thấy trước các tác động xã hội trực tiếp hoặc tức thì phát sinh từ công việc này. Tuy nhiên, chúng tôi muốn nhấn mạnh rằng việc chỉ dựa vào các phản ứng liên kết của LLM đối với lời nhắc có thể dẫn đến thiên lệch không mong muốn trong hành vi của hệ thống. Việc kiểm soát suy luận của LLM theo cách chúng tôi đã đề xuất có thể giảm thiểu thiên lệch như vậy, do cả việc phân tách quá trình lập luận thành các bước truy xuất sự kiện có thể diễn giải và hiệu ứng tính trung bình của việc làm mịn các kích hoạt giả mạo khi tổng hợp nhiều giả thuyết và chuỗi suy luận.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo dài với các trích dẫn học thuật được giữ nguyên định dạng gốc]

--- TRANG 11 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 12 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 13 ---
A Các nhiệm vụ bổ sung

Mô tả của tất cả các nhiệm vụ được nghiên cứu ở đây có thể được tìm thấy trong §C.

A.1 Phát hiện sự không chắc chắn và ảo giác

LLM dễ bị tạo ra các ảo giác chứa các phát biểu không chính xác. Khả năng của những phát biểu này thường bị chi phối bởi các mẫu ngắn có khả năng, điều này cũng khiến LLM khó đánh giá sự không chắc chắn của chính mình về một sự kiện. Do đó, việc phát hiện (Liu et al., 2021; Zhou et al., 2021) và giảm thiểu những ảo giác như vậy là rất quan trọng để sử dụng rộng rãi LLM trong các ứng dụng thực tế (Dziri et al., 2021; Shuster et al., 2021).

A.1.1 Hiểu biết thể thao

[Hình A.1 và nội dung về nhiệm vụ HIỂU BIẾT THỂ THAO]

A.1.2 Những điều chưa biết đã biết

[Nội dung về nhiệm vụ NHỮNG ĐIỀU CHƯA BIẾT ĐÃ BIẾT]

A.2 Dịch giữa các ngôn ngữ và hệ thống chữ viết

Điều này mở rộng kết quả về SUY DIỄN LOGIC trong §3.3.

A.2.1 Quan niệm sai lầm tiếng Nga

[Nội dung về nhiệm vụ QUAN NIỆM SAI LẦM TIẾNG NGA]

A.2.2 Phim emoji

[Nội dung về nhiệm vụ PHIM EMOJI]

A.2.3 QA tiếng Ba Tư

[Nội dung về nhiệm vụ QA TIẾNG BA TƯ]

A.3 Liên quan ngữ nghĩa

Điều này mở rộng kết quả về TÌM CÁI KHÁC BIỆT trong §3.2.

A.3.1 Liên quan cụm từ

[Nội dung về nhiệm vụ LIÊN QUAN CỤM TỪ]

A.3.2 Codenames

[Nội dung về nhiệm vụ CODENAMES]

A.4 Thay thế và tổng hợp

[Nội dung về các ví dụ khác về hoạt động thay thế và tổng hợp]

A.4.1 Khái niệm mới

[Nội dung về nhiệm vụ KHÁI NIỆM MỚI]

A.4.2 Mô tả dòng mã

[Nội dung về nhiệm vụ MÔ TẢ DÒNG MÃ]

A.5 Các nhiệm vụ khác

A.5.1 Nhận dạng ngôn ngữ

[Nội dung về nhiệm vụ NHẬN DẠNG NGÔN NGỮ]

--- TRANG 14-22 ---
[Nội dung của các phần còn lại bao gồm:
- B BIG-bench Lite
- C Mô tả nhiệm vụ (với các phần con chi tiết về từng loại nhiệm vụ)
- D Chi tiết thí nghiệm bổ sung
- E Expectation Maximization
- Các bảng và hình ảnh bổ sung]

[Tất cả nội dung được dịch sang tiếng Việt với cấu trúc và định dạng tương tự như bản gốc]

# Các Mô Hình Ngôn Ngữ Nhỏ Cải Thiện Các Mô Hình Khổng Lồ Bằng Cách Viết Lại Đầu Ra Của Chúng

Giorgos Vernikos1,2∗Arthur Bražinskas3Jakub Adamek3
Jonathan Mallinson3Aliaksei Severyn3Eric Malmi3
1EPFL,2HEIG-VD / HES-SO,3Google Research
georgios.vernikos@epfl.ch
{abrazinskas, enkait, jonmall, severyn, emalmi}@google.com

## Tóm tắt

Mặc dù hiệu suất ấn tượng của các mô hình ngôn ngữ lớn (LLM), chúng thường tụt hậu so với các mô hình chuyên biệt trong nhiều nhiệm vụ khác nhau. LLM chỉ sử dụng một phần nhỏ dữ liệu huấn luyện hiện có cho việc học trong ngữ cảnh, trong khi các mô hình cụ thể cho nhiệm vụ khai thác toàn bộ bộ dữ liệu để tinh chỉnh. Trong công trình này, chúng tôi giải quyết vấn đề tận dụng dữ liệu huấn luyện để cải thiện hiệu suất của LLM mà không cần tinh chỉnh. Phương pháp của chúng tôi nhắm mục tiêu trực tiếp vào các dự đoán của LLM mà không cần truy cập vào trọng số của chúng. Chúng tôi tạo ra một nhóm các ứng viên từ LLM thông qua việc nhắc nhở few-shot và sử dụng một mô hình nhỏ gọn, LM-corrector (LMCOR), được huấn luyện đặc biệt để kết hợp các ứng viên này nhằm tạo ra một đầu ra được cải thiện. Các thí nghiệm của chúng tôi trên bốn nhiệm vụ tạo ngôn ngữ tự nhiên chứng minh rằng ngay cả một mô hình LMCOR nhỏ (250M) cũng cải thiện đáng kể hiệu suất few-shot của LLM (62B), ngang bằng và thậm chí vượt trội hơn việc tinh chỉnh tiêu chuẩn. Hơn nữa, chúng tôi minh họa tính bền vững của LMCOR đối với các lời nhắc khác nhau, từ đó giảm thiểu nhu cầu kỹ thuật lời nhắc mở rộng. Cuối cùng, chúng tôi chỉ ra rằng LMCOR có thể được tích hợp một cách liền mạch với các LLM khác nhau tại thời điểm suy luận, phục vụ như một mô-đun plug-and-play để cải thiện hiệu suất của chúng.

## 1 Giới thiệu

Các mô hình ngôn ngữ lớn gần đây đã chứng minh hiệu suất gần như tốt nhất trên các nhiệm vụ khác nhau thông qua việc học trong ngữ cảnh, cho phép chúng tạo ra các đầu ra dựa trên hướng dẫn và một số ít ví dụ, mà không cần huấn luyện cụ thể cho nhiệm vụ (Brown et al., 2020b,a; Chowdhery et al., 2022). Tuy nhiên, hiệu quả của mô hình này có thể thay đổi đáng kể tùy thuộc vào hướng dẫn nhiệm vụ (Shin et al., 2020; Jiang et al., 2021; Schick và Schütze, 2021), số lượng, mức độ liên quan và thậm chí thứ tự của các ví dụ trong ngữ cảnh (Brown et al., 2020a; Gao et al., 2021; Liu et al., 2022; Zhang et al., 2023a; Lu et al., 2022). Kết quả là, việc học trong ngữ cảnh thường đòi hỏi kỹ thuật lời nhắc tốn nhiều công sức mà không phải lúc nào cũng đảm bảo hiệu suất được cải thiện (Jiang et al., 2021).

Mặt khác, việc tinh chỉnh đã được chứng minh là rất hiệu quả khi có sẵn các bộ dữ liệu cụ thể cho nhiệm vụ, với các mô hình nhỏ hơn được tinh chỉnh vượt trội hơn LLM được nhắc nhở few-shot trên nhiều nhiệm vụ khác nhau (Lester et al., 2021; Chowdhery et al., 2022; Xu et al., 2023). Mặc dù LLM cũng có thể được tinh chỉnh để nâng cao hiệu suất trong các nhiệm vụ cụ thể, nhưng có một số hạn chế. Thứ nhất, quá trình tinh chỉnh có thể ảnh hưởng tiêu cực đến hiệu suất few-shot của LLM trên các nhiệm vụ khác, dẫn đến sự đánh đổi giữa tính linh hoạt và hiệu suất (Fu et al., 2023). Thứ hai, quy mô ngày càng tăng của LLM khiến việc tinh chỉnh trên phần cứng tiêu chuẩn trở nên không khả thi về mặt tính toán. Để giải quyết các vấn đề này, các phương pháp tinh chỉnh hiệu quả về tham số đã được đề xuất (Houlsby et al., 2019; Lester et al., 2021; Li và Liang, 2021; Hu et al., 2022). Mặc dù các phương pháp này hiệu quả hơn về mặt tính toán, chúng vẫn cần truy cập vào trọng số mô hình và tài nguyên tính toán đáng kể để tải và cập nhật mô hình. Hơn nữa, do việc thương mại hóa LLM, chúng thường chỉ có sẵn thông qua các API suy luận hạn chế.

Xem xét những thách thức này, chúng tôi đề xuất một phương pháp chỉ tận dụng các đầu ra của LLM để nâng cao hiệu suất của chúng. Công trình của chúng tôi nhắm mục tiêu vào các tình huống có sẵn dữ liệu huấn luyện, nhưng không có tài nguyên tính toán cực lớn. Để làm điều này, chúng tôi giới thiệu LM-Corrector (LMCOR), một mô hình nhỏ gọn để sửa chữa các dự đoán được tạo ra bởi LLM. Không giống như các phương pháp tinh chỉnh, cách tiếp cận của chúng tôi hoạt động trực tiếp trên các đầu ra LLM, bỏ qua nhu cầu truy cập vào trọng số của chúng.

LMCOR tận dụng quan sát rằng LLM có thể tạo ra một mảng đa dạng các ứng viên cho một đầu vào duy nhất và chúng thường bổ sung cho nhau. Do đó, có thể tạo ra một đầu ra vượt trội bằng cách kết hợp tối ưu các đoạn từ các ứng viên khác nhau (xem Hình 2). LMCOR nhận nhiều ứng viên cho một đầu vào duy nhất và học cách xếp hạng, kết hợp và chỉnh sửa chúng một cách tối ưu, cuối cùng tạo ra các đầu ra chính xác và chất lượng cao hơn. Hình 1 minh họa cách tiếp cận của chúng tôi, trong đó LMCOR viết lại đầu ra đầu tiên của LLM trong khi kết hợp các đoạn chính xác từ đầu ra thứ hai (American) và thứ ba (the Nobel) để tạo ra đầu ra cuối cùng, đã được sửa chữa.

Những đóng góp của chúng tôi có thể được tóm tắt như sau:
(1) Chúng tôi giới thiệu LMCOR, một phương pháp để cải thiện hiệu suất của LLM khi có dữ liệu huấn luyện mà không cần truy cập vào trọng số mô hình.
(2) Chúng tôi tiến hành thí nghiệm trên bốn nhiệm vụ tạo ngôn ngữ tự nhiên trong đó LLM hoạt động kém hơn các mô hình chuyên biệt. Chúng tôi chứng minh rằng một mô hình LMCOR nhỏ chỉ với 250 triệu tham số cải thiện hiệu suất của một LLM với 62 tỷ tham số, ngang bằng hoặc thậm chí vượt trội hơn các mô hình cụ thể cho nhiệm vụ.
(3) Chúng tôi thể hiện rằng bộ sửa chữa bền vững với các lời nhắc khác nhau, giảm bớt nhu cầu kỹ thuật lời nhắc mở rộng.
(4) Chúng tôi chứng minh tính linh hoạt của cách tiếp cận của chúng tôi, cho thấy một bộ sửa chữa duy nhất có thể được áp dụng một cách dễ dàng cho các LM khác nhau như một mô-đun plug-and-play trong quá trình suy luận.

Chúng tôi công khai mã nguồn của mình.

## 2 Sửa chữa Đầu ra của LLM

Trong phần này, chúng tôi trình bày cách tiếp cận hiệu quả về mặt tính toán của chúng tôi sử dụng một mô hình nhỏ, LMCOR, để sửa chữa các dự đoán của LLM cho một nhiệm vụ cụ thể. Không giống như các phương pháp tinh chỉnh truyền thống, cách tiếp cận của chúng tôi không cần truy cập vào trọng số của LLM. Thay vào đó, như được thấy trong Hình 1, chúng tôi tương tác với LLM chỉ thông qua một API, như trường hợp của một số LLM thương mại tối tân.

**Phân tích dư địa** Cách tiếp cận của chúng tôi dựa trên hiểu biết rằng LLM có thể tạo ra một nhóm ứng viên đa dạng cho mỗi đầu vào, với những điểm mạnh và điểm yếu bổ sung cho nhau. Do đó, một đầu ra được cải thiện có thể được tạo ra bằng cách kết hợp các phần đúng của các ứng viên tương ứng. Để minh họa điều này, chúng tôi thử nghiệm trên nhiệm vụ sửa lỗi ngữ pháp (GEC) (Ng et al., 2014) sử dụng các mô hình PaLM (Chowdhery et al., 2022) có kích thước khác nhau, được mô tả trong Hình 2. Đầu tiên, chúng tôi quan sát rằng các mô hình PaLM few-shot hoạt động kém hơn mô hình GEC tối tân được tinh chỉnh với 11B tham số (Rothe et al., 2021). Tuy nhiên, bằng cách lấy mẫu 10 lần từ LLM và sử dụng một oracle để xếp hạng các mẫu (oracle-rank) hoặc để kết hợp các đoạn đúng (oracle-combine), chúng tôi thu được những cải thiện đáng kể, vượt qua mức tối tân.

Phát hiện này nổi bật tiềm năng của việc tận dụng nhiều lần tạo ra thông qua xếp hạng hoặc kết hợp để nâng cao hiệu suất của LLM thông qua huấn luyện cụ thể cho nhiệm vụ. Được thúc đẩy bởi điều này, chúng tôi sử dụng một mô hình nhỏ hơn, LMCOR, để dự đoán mục tiêu dựa trên đầu vào gốc và nhiều ứng viên được cung cấp bởi LLM.

**Tạo ra các ứng viên** Để bắt đầu quy trình của chúng tôi, trước tiên chúng tôi tạo ra các dự đoán từ LLM thông qua việc học trong ngữ cảnh. Cụ thể, chúng tôi nhắc nhở mô hình với một chuỗi nguồn x, một mô tả bằng lời của nhiệm vụ d, và một số ít minh chứng e, được mô tả bằng các đường đứt nét trong Hình 1. Bằng cách lấy mẫu từ LLM với một nhiệt độ, chúng tôi thu được một tập hợp đa dạng k ứng viên, C={c1, ..., ck}:

ci ∼ pLLM(c|x, d, e) ∀i = 1,2, .., k. (1)

**Sửa chữa các ứng viên** Tiếp theo, chúng tôi đưa tập hợp các ứng viên cùng với chuỗi đầu vào x vào bộ sửa chữa để tạo ra đầu ra cuối cùng, được tinh chỉnh.

ŷ = arg max pLMCOR(y|x, C) (2)

Để huấn luyện bộ sửa chữa, chúng tôi tinh chỉnh một LM nhỏ trên bộ dữ liệu cụ thể cho nhiệm vụ được tăng cường với các ứng viên được lấy mẫu từ LLM. Thông qua quá trình này, LMCOR học cách chọn ra những ứng viên hứa hẹn nhất trong số các đầu ra được tạo ra, kết hợp các ứng viên khác nhau và thậm chí thực hiện các chỉnh sửa cần thiết để soạn thảo câu mục tiêu mong muốn. Như chúng tôi cho thấy trong các phần tiếp theo, ngay cả một bộ sửa chữa nhỏ cũng có thể cải thiện đáng kể chất lượng đầu ra của LLM, vượt trội hơn việc tinh chỉnh tiêu chuẩn và giảm độ nhạy cảm của LLM đối với các lời nhắc khác nhau.

## 3 Thí nghiệm & Kết quả

### 3.1 Bộ dữ liệu và Mô hình

Chúng tôi đánh giá LMCOR trên bốn nhiệm vụ tạo ngôn ngữ tự nhiên: sửa lỗi ngữ pháp trên CoNLL-14 (Ng et al., 2014), tạo văn bản từ dữ liệu trên E2E NLG (Novikova et al., 2017), tóm tắt trên XSum (Narayan et al., 2018) và dịch máy trên nhiệm vụ dịch tiếng Anh sang tiếng Đức từ WMT22 (Kocmi et al., 2022).

Trong hầu hết các thí nghiệm của chúng tôi, chúng tôi sử dụng phiên bản 62B của PaLM (Chowdhery et al., 2022) làm LM lớn của chúng tôi, ngoại trừ Phần 4.2 nơi chúng tôi thay đổi kích thước của LLM lên đến 540B tham số. Đối với nhiệm vụ dịch máy, chúng tôi sử dụng phiên bản 2.9B của XGLM (Lin et al., 2022) làm LLM của chúng tôi, vì tại thời điểm chạy thí nghiệm này, nó dễ tiếp cận hơn với tác giả đầu tiên. Chúng tôi nhắc nhở LLM với một mô tả nhiệm vụ và một số minh chứng được chọn ngẫu nhiên từ tập xác thực tương ứng. Chúng tôi lấy mẫu k=4 lần từ LLM với nhiệt độ 0.7 cho PaLM và sử dụng nucleus sampling (Holtzman et al., 2020) với p=0.6 và nhiệt độ 0.6 cho XGLM. Ngoài ra, chúng tôi bao gồm đầu ra được giải mã tham lam như một ứng viên vì kết quả ban đầu cho thấy nó cải thiện hiệu suất. Chúng tôi sử dụng T5.1.1 base (Raffel et al., 2020) (250M tham số) làm mô hình cho cả LMCOR và đường chuẩn tinh chỉnh tiêu chuẩn. Chúng tôi chọn mô hình dựa trên hiệu suất trên tập xác thực. Các đầu ra của bộ sửa chữa và đường chuẩn T5 được tạo ra thông qua tìm kiếm chùm tia với chùm tia kích thước 5.

Chúng tôi so sánh cách tiếp cận của chúng tôi, LMCOR, với các đường chuẩn sau:
1) học trong ngữ cảnh sử dụng LLM (ICL), được nhắc nhở với cùng số lượng minh chứng,
2) tinh chỉnh tiêu chuẩn với T5-base và PaLM.

Chúng tôi cũng cung cấp điểm số cho
3) cách tiếp cận xếp hạng lại của Suzgun et al. (2022a) trong đó họ sử dụng Giải mã Rủi ro Bayes Tối thiểu (MBRD) kết hợp với hàm căn chỉnh để chọn một trong số các ứng viên được tạo ra từ LLM.

Chúng tôi sử dụng cùng một nhóm ứng viên được sử dụng làm đầu vào cho bộ sửa chữa và sử dụng Sim-LCS, một hàm tương tự từ vựng dựa trên chuỗi con chung dài nhất đạt được kết quả tốt nhất trên các nhiệm vụ trong số các hàm căn chỉnh. Chúng tôi bổ sung cung cấp điểm số của một bộ xếp hạng lại oracle chọn ứng viên có khoảng cách chỉnh sửa nhỏ nhất so với mục tiêu làm giới hạn trên của các phương pháp xếp hạng lại. Cuối cùng, chúng tôi cung cấp kết quả cho một phiên bản của cách tiếp cận của chúng tôi chỉ đưa vào bộ sửa chữa ứng viên được giải mã tham lam (single).

### 3.2 Sửa Lỗi Ngữ Pháp

Sửa Lỗi Ngữ Pháp (GEC) là một nhiệm vụ văn bản đến văn bản yêu cầu sửa chữa các lỗi ngữ pháp trong khi áp dụng những thay đổi tối thiểu cho câu đầu vào gốc. Mặc dù được huấn luyện trên lượng văn bản khổng lồ, LLM đã được chứng minh là hoạt động kém hơn các mô hình cụ thể cho nhiệm vụ trong nhiệm vụ này (Yasunaga et al., 2021; Suzgun et al., 2022b).

Chúng tôi sử dụng bộ dữ liệu CoNLL-14 (Ng et al., 2014) làm tập thử nghiệm của chúng tôi. Theo các công trình trước đây (Rothe et al., 2021), chúng tôi sử dụng sự kết hợp của các bộ dữ liệu FCE (Yannakoudakis et al., 2011) và W&I (Bryant et al., 2019) (60k ví dụ) để huấn luyện và xác thực. Chúng tôi báo cáo điểm số F0.5 thu được với MaxMatch scorer (Dahlmeier và Ng, 2012). Chúng tôi sử dụng 5 minh chứng trong lời nhắc LLM để tạo ra các ứng viên trong quá trình huấn luyện và suy luận.

Kết quả được trình bày trong Bảng 1 cho thấy việc tinh chỉnh tiêu chuẩn và học trong ngữ cảnh thể hiện hiệu suất tương đương trong GEC trong khi cách tiếp cận của chúng tôi vượt trội hơn đáng kể cả hai, với 3 và 2.5 điểm F0.5 tương ứng. Đáng chú ý là MBRD không mang lại bất kỳ cải thiện nào so với việc nhắc nhở few-shot tiêu chuẩn. Tuy nhiên, như mong đợi, việc sử dụng oracle để xếp hạng các giả thuyết được tạo ra dẫn đến một sự tăng hiệu suất đáng kể. Mặc dù LMCOR không vượt qua hiệu suất của oracle, nó quản lý để thu hẹp khoảng cách một cách đáng kể, chứng minh khả năng của bộ sửa chữa trong việc xác định các ứng viên chất lượng cao từ mô hình.

Ngoài ra, chúng tôi so sánh hiệu suất của việc tinh chỉnh tiêu chuẩn và LMCOR trên số lượng khác nhau của các thể hiện huấn luyện. Như được minh họa trong Hình 3, cách tiếp cận của chúng tôi liên tục vượt trội hơn đường chuẩn cho tất cả kích thước bộ dữ liệu. Khoảng cách đặc biệt rõ ràng khi bộ dữ liệu huấn luyện bị hạn chế, chỉ gồm 1k ví dụ, dẫn đến sự khác biệt đáng kể 15 điểm trong F0.5.

Hiệu quả mẫu của LMCOR có thể được quy cho khả năng tận dụng các ứng viên được tạo ra bởi LLM để tạo ra các đầu ra chính xác hơn. Chúng tôi lưu ý rằng trong tình huống tài nguyên thấp này, cả hai mô hình được huấn luyện đều hoạt động tệ hơn so với việc nhắc nhở few-shot. Kết quả này được mong đợi vì việc tiền huấn luyện mở rộng của LLM về tạo ngôn ngữ cho phép chúng thực hiện sửa lỗi ngữ pháp ngay lập tức. Khi bộ dữ liệu tăng lên 10k ví dụ, chúng tôi quan sát rằng LMCOR hoạt động ngang bằng với LLM trong khi đường chuẩn tiếp tục hoạt động kém hơn. Vượt qua ngưỡng này, LMCOR vượt trội hơn cả học trong ngữ cảnh và tinh chỉnh bằng cách sử dụng cả dữ liệu huấn luyện và các ứng viên.

### 3.3 Dữ liệu đến Văn bản

Nhiệm vụ tiếp theo chúng tôi đánh giá là E2E NLG (Novikova et al., 2017), một nhiệm vụ dữ liệu đến văn bản trong đó đầu vào là một số cặp khóa-giá trị về một nhà hàng và đầu ra là một mô tả ngắn về nhà hàng bằng ngôn ngữ tự nhiên. Chúng tôi sử dụng phiên bản đã làm sạch của bộ dữ liệu, E2E NLG (cleaned) (Dušek et al., 2019) và các phân chia mặc định để huấn luyện (35k ví dụ), xác thực và thử nghiệm. Chúng tôi sử dụng 5 minh chứng để tạo ra các ứng viên cho bộ sửa chữa trong cả quá trình huấn luyện và suy luận. Chúng tôi báo cáo điểm số ROUGE-2 và ROUGE-L (Lin, 2004).

Bảng 2 trình bày một so sánh giữa việc tinh chỉnh tiêu chuẩn với mô hình T5-base, học trong ngữ cảnh, và tinh chỉnh sử dụng các mô hình PaLM. Đáng chú ý là việc tinh chỉnh tiêu chuẩn với T5-base vượt trội hơn đáng kể so với học trong ngữ cảnh và đạt được kết quả tương đương với việc tinh chỉnh với các mô hình PaLM lớn hơn nhiều. Trong khi các kỹ thuật xếp hạng lại cải thiện hiệu suất của việc nhắc nhở few-shot, ngay cả cách tiếp cận oracle cũng không đạt được hiệu suất của mô hình T5-base được tinh chỉnh. Điều này nổi bật hạn chế chính của các cách tiếp cận xếp hạng lại, đặc biệt là đối với các nhiệm vụ thách thức cho LLM, nơi giới hạn trên của chúng chỉ phụ thuộc vào chất lượng của các ứng viên.

Ngược lại, hiệu suất của LMCOR không phụ thuộc hoàn toàn vào chất lượng của các ứng viên. Mô-đun bộ sửa chữa có khả năng chỉnh sửa các ứng viên được tạo ra bởi LLM, dẫn đến các đầu ra chính xác hơn. Kết quả là, LMCOR thể hiện hiệu suất tổng thể tốt nhất cho nhiệm vụ E2E, vượt trội hơn cả mô hình PaLM-540B được tinh chỉnh 1 điểm trong ROUGE-L. Một đặc điểm quan trọng của cách tiếp cận của chúng tôi là khả năng của bộ sửa chữa để quan sát nhiều ứng viên cho một đầu vào duy nhất. Điều này cho phép LMCOR kết hợp các ứng viên để soạn thảo một câu trả lời tinh chỉnh hơn. Điều này được hỗ trợ bởi sự khác biệt hiệu suất giữa LMCOR(single) và LMCOR(mult.) làm nổi bật hiệu quả của việc tận dụng nhiều ứng viên.

### 3.4 Tóm tắt

Nhiệm vụ thứ ba chúng tôi xem xét là tóm tắt trừu tượng. Cụ thể, chúng tôi sử dụng XSum (Narayan et al., 2018) với các phân chia train (204k ví dụ), xác thực và thử nghiệm mặc định. Do độ dài của các bài báo, chúng tôi cắt bớt các đầu vào và chỉ sử dụng 1 minh chứng để nhắc nhở LLM. Để xử lý độ dài chuỗi tăng lên trong đầu vào của bộ sửa chữa, chúng tôi lại cắt bớt các bài báo và sử dụng độ dài chuỗi tối đa 2048 tokens. Chúng tôi báo cáo điểm số ROUGE-1, ROUGE-2 và ROUGE-L.

Kết quả của Bảng 3 tiết lộ rằng việc tinh chỉnh tiêu chuẩn vượt trội hơn học trong ngữ cảnh đối với bộ dữ liệu XSum. Cụ thể, các mô hình T5 và PaLM-62B được tinh chỉnh vượt trội hơn học trong ngữ cảnh 15 và 18 điểm trong ROUGE-2 tương ứng. Độ khó của nhiệm vụ, bao gồm việc tóm tắt một bài báo thành một câu duy nhất, đặt ra thách thức cho việc học trong ngữ cảnh, trong khi kích thước bộ dữ liệu đáng kể 204k ví dụ ủng hộ việc tinh chỉnh. Tuy nhiên, việc sử dụng mô-đun bộ sửa chữa dẫn đến những cải thiện đáng kể so với học trong ngữ cảnh với mô hình PaLM 62B, dẫn đến tăng hiệu suất 6 điểm trong ROUGE-2 và 8 điểm trong ROUGE-L. Đáng chú ý là LMCOR vượt trội hơn việc học few-shot với mô hình PaLM 540B lớn nhất. Một lần nữa, việc sử dụng nhiều ứng viên bởi bộ sửa chữa càng nâng cao hiệu suất của LMCOR, xác nhận giả thuyết của chúng tôi về tính bổ sung của các đầu ra được tạo ra bởi LLM.

Mặt khác, LMCOR hoạt động hơi tệ hơn so với việc tinh chỉnh tiêu chuẩn. Kết quả này hơi bất ngờ vì đầu vào cho bộ sửa chữa là một tập hợp con nghiêm ngặt của đầu vào mô hình trong cài đặt tinh chỉnh. Chúng tôi quy sự sụt giảm hiệu suất nhỏ này cho chất lượng kém của các ứng viên được cung cấp, điều này đưa tiếng ồn không mong muốn vào đầu vào của bộ sửa chữa, một giả thuyết mà chúng tôi kiểm tra trong Phần 4.3. Ngoài ra, các phụ thuộc tầm xa được đưa vào bằng cách xử lý đồng thời bài báo và các bản tóm tắt được tạo ra cũng có thể góp phần vào khoảng cách hiệu suất giữa LMCOR và việc tinh chỉnh tiêu chuẩn.

### 3.5 Dịch Máy

Nhiệm vụ cuối cùng trong đánh giá của chúng tôi là dịch máy (MT). Đối với nhiệm vụ này, chúng tôi sử dụng cặp ngôn ngữ tiếng Anh sang tiếng Đức từ WMT22 (Kocmi et al., 2022) làm tập thử nghiệm và cặp tương ứng từ WMT21 (Akhbardeh et al., 2021) làm tập xác thực. Dữ liệu huấn luyện của chúng tôi bao gồm 200k ví dụ được lấy mẫu từ corpus News Commentary v16. Trong cả quá trình huấn luyện và suy luận, chúng tôi nhắc nhở LLM với 5 minh chứng để tạo ra các ứng viên. Chúng tôi báo cáo điểm số sử dụng các chỉ số đánh giá MT truyền thống dựa trên bề mặt như BLEU (Papineni et al., 2002), cũng như các chỉ số gần đây hơn dựa trên mạng nơ-ron như COMET-22 (Rei et al., 2022) và BLEURT (Sellam et al., 2020).

Các phát hiện được trình bày trong Bảng 4 chỉ ra rằng, tương tự như các nhiệm vụ trước đây, việc tinh chỉnh tiêu chuẩn vượt trội hơn học trong ngữ cảnh cho MT trên hai trong ba chỉ số được xem xét. Trong khi cách tiếp cận xếp hạng lại rủi ro Bayes tối thiểu cho thấy một số cải thiện, nó không thể thu hẹp đáng kể khoảng cách với đường chuẩn được tinh chỉnh. Đáng chú ý là bộ xếp hạng lại oracle quản lý để vượt qua T5 về điểm số COMET, mặc dù T5 vẫn vượt trội về BLEU.

Cách tiếp cận được đề xuất của chúng tôi đạt được những cải thiện đáng kể, vượt trội hơn cả việc tinh chỉnh và học trong ngữ cảnh, cũng như các cách tiếp cận xếp hạng lại, bao gồm oracle. Quan sát này một lần nữa nổi bật những hạn chế của các cách tiếp cận xếp hạng lại, đặc biệt là khi xử lý các ứng viên chất lượng thấp. Cụ thể, phiên bản của LMCOR sử dụng một ứng viên duy nhất thể hiện những cải thiện 4.5 điểm BLEU, 2 điểm về COMET, và 0.5 điểm về BLEURT so với điểm số tốt nhất đạt được bởi việc tinh chỉnh hoặc xếp hạng lại. Việc bao gồm nhiều ứng viên mang lại những cải thiện thêm từ 0.6 đến 1.2 điểm, tùy thuộc vào chỉ số, nhấn mạnh lợi ích của một nhóm ứng viên đa dạng.

## 4 Phân tích Tính Bền vững

### 4.1 Các lời nhắc khác nhau

Chúng tôi đã chứng minh rằng LMCOR nâng cao hiệu suất của LLM bằng cách tinh chỉnh các dự đoán được tạo ra của chúng. Tuy nhiên, mô hình few-shot vẫn hấp dẫn vì nó không yêu cầu huấn luyện hoặc truy cập vào bộ dữ liệu, ngoại trừ một số ít ví dụ được sử dụng trong lời nhắc. Mặc dù việc xây dựng lời nhắc không tốn nhiều tính toán, nhưng không có sự đồng thuận về việc chọn lựa, số lượng và thậm chí thứ tự tối ưu của các ví dụ trong lời nhắc, điều này có thể dẫn đến sự biến đổi trong các dự đoán và ảnh hưởng đáng kể đến hiệu suất của LLM (Lu et al., 2022). Để điều tra liệu LMCOR có bị ảnh hưởng tương tự bởi sự biến đổi này hay không, chúng tôi sử dụng ba bộ khác nhau gồm 5 minh chứng để nhắc nhở LLM cho nhiệm vụ GEC. Sau đó, chúng tôi đưa các dự đoán được tạo ra làm đầu vào cho bộ sửa chữa. Điều quan trọng cần lưu ý là chúng tôi chỉ huấn luyện LMCOR một lần sử dụng các ứng viên được tạo ra với bộ minh chứng gốc (bộ 1) và chỉ đơn giản thay đổi các ứng viên trong quá trình suy luận.

Bảng 5 nổi bật sự biến đổi đáng kể trong hiệu suất LLM tùy thuộc vào việc chọn lựa minh chứng với sự khác biệt 3.7 giữa điểm số F0.5 cao nhất và thấp nhất. Ngược lại, LMCOR vẫn không bị ảnh hưởng và đạt được hiệu suất cạnh tranh ngay cả khi chất lượng của các ứng viên giảm đáng kể (bộ 3). Điều này chứng minh khả năng của LMCOR trong việc bù đắp cho các ứng viên chất lượng kém bằng cách thực hiện các chỉnh sửa trên chúng. Tính bền vững của bộ sửa chữa chống lại các lời nhắc có chất lượng khác nhau (với phương sai 0.3 so với 1.9 cho LLM) cho thấy nó có thể giảm thiểu nhu cầu kỹ thuật lời nhắc mở rộng.

### 4.2 Các LLM khác nhau

Trong thí nghiệm trước đây, chúng tôi đã chứng minh tính bền vững của bộ sửa chữa chống lại các ứng viên có chất lượng khác nhau. Trong bộ thí nghiệm này, chúng tôi tiếp tục kiểm tra tính bền vững của cách tiếp cận của chúng tôi bằng cách kiểm tra liệu một bộ sửa chữa có thể được sử dụng thay thế với các LM khác nhau mà không cần huấn luyện lại hay không. Điều quan trọng cần lưu ý là chúng tôi chỉ huấn luyện bộ sửa chữa một lần và thực hiện suy luận bằng cách thay đổi LLM chịu trách nhiệm tạo ra các ứng viên.

Ban đầu, chúng tôi tập trung vào các LM từ cùng một họ mô hình, cụ thể là PaLM (Chowdhery et al., 2022), có cùng kiến trúc và dữ liệu huấn luyện nhưng khác nhau về số lượng tham số. Bảng 6 trình bày kết quả của việc áp dụng bộ sửa chữa cho các mô hình PaLM khác nhau so với mô hình ban đầu được huấn luyện (62B). Trên tất cả các quy mô, LMCOR liên tục vượt trội hơn việc tinh chỉnh tiêu chuẩn và học trong ngữ cảnh, ngoại trừ mô hình 540B nơi hiệu suất tương đương. Bộ sửa chữa đạt được những cải thiện đáng kể khi được áp dụng cho mô hình PaLM 8B, với cải thiện +13 điểm trong F0.5. Điều này càng nổi bật khả năng của LMCOR trong việc bù đắp cho các ứng viên chất lượng thấp bằng cách hợp nhất và sửa chữa chúng để đạt được hiệu suất cạnh tranh. Hơn nữa, chúng tôi quan sát rằng việc sử dụng một ứng viên duy nhất cho LMCOR dẫn đến hiệu suất kém hơn trong tất cả các trường hợp, ngoại trừ mô hình PaLM 62B. Phát hiện này cho thấy rằng sự tồn tại của các ứng viên đa dạng ngăn chặn mô hình khỏi việc overfitting vào các đầu ra của một LLM cụ thể, từ đó nâng cao khả năng tổng quát hóa của nó.

Như bước tiếp theo, chúng tôi khám phá việc áp dụng LMCOR cho một LLM từ một họ mô hình khác biệt, cụ thể là Codex, một mô hình giống GPT3 được huấn luyện trên mã (Chen et al., 2021). Để so sánh hiệu quả của LMCOR với việc xếp hạng lại MRBD, chúng tôi sử dụng BLEURT (Sellam et al., 2020) làm hàm căn chỉnh, vì nó đã được báo cáo đạt được điểm số cao nhất cho nhiệm vụ E2E NLG (Suzgun et al., 2022b). Điều quan trọng cần lưu ý là trong khi cách tiếp cận xếp hạng lại lấy mẫu 16 đầu ra từ LLM, chúng tôi chỉ sử dụng 5 cho bộ sửa chữa. Kết quả trong Bảng 7 chứng minh hiệu suất vượt trội của LMCOR so với việc xếp hạng lại. Đặc biệt, chúng tôi quan sát một sự tăng hiệu suất 10 điểm trong ROUGE-2 khi so sánh với học trong ngữ cảnh, trong khi MBRD chỉ đạt được cải thiện 2 điểm.

Những phát hiện trước đây nổi bật tính bền vững vượt trội của LMCOR và khả năng tích hợp liền mạch với nhiều LLM khác nhau, như một giải pháp linh hoạt để nâng cao hiệu suất của chúng. Tính linh hoạt này không chỉ hứa hẹn cho việc áp dụng một bộ sửa chữa duy nhất cho nhiều LLM mà còn cho việc huấn luyện các bộ sửa chữa với các LLM tương lai, có khả năng hơn.

### 4.3 Các mô hình cụ thể cho nhiệm vụ

Để đánh giá thêm tính linh hoạt của LMCOR, chúng tôi mở rộng điều tra của chúng tôi đến các mô hình chuyên biệt. Cụ thể, chúng tôi huấn luyện một bộ sửa chữa sử dụng các ứng viên được tạo ra bởi Pegasus (Zhang et al., 2020), một mô hình tóm tắt tối tân, thông qua tìm kiếm chùm tia. Kết quả của Bảng 8 tiết lộ rằng LMCOR cung cấp những cải thiện ngay cả cho các mô hình đã trải qua tiền huấn luyện và tinh chỉnh được điều chỉnh cho nhiệm vụ. Mặc dù những cải thiện tương đối khiêm tốn so với PaLM, sự khác biệt này có thể được quy cho hiệu suất đã cao của Pegasus và sự thiếu đa dạng của các ứng viên được tạo ra bởi chùm tia, điều này rất cần thiết cho bộ sửa chữa. Hiệu suất tăng lên của bộ sửa chữa khi được áp dụng cho Pegasus so với PaLM ủng hộ trực giác của chúng tôi về tiếng ồn được đưa vào bởi các ứng viên chất lượng thấp.

## 5 Phân tích

### 5.1 Tầm quan trọng của nguồn

Đầu vào của bộ sửa chữa bao gồm câu nguồn và một số ứng viên được tạo ra bởi LLM (Phương trình 2). Trong các phần trước, chúng tôi đã chứng minh rằng việc sử dụng nhiều ứng viên cải thiện hiệu suất trong phạm vi và tính bền vững ngoài phạm vi. Trong thí nghiệm này, chúng tôi tập trung vào tầm quan trọng của câu nguồn đối với LMCOR. Để kiểm tra điều này, chúng tôi huấn luyện một bộ sửa chữa chỉ nhận các ứng viên làm đầu vào, mà không có quyền truy cập vào nguồn.

Kết quả cho E2E NLG, được trình bày trong Bảng 9, tiết lộ một sự suy giảm đáng kể trong hiệu suất khi câu nguồn bị loại bỏ. Sự suy giảm này có thể được quy cho việc bộ sửa chữa không thể tạo ra các đầu ra trung thành với đầu vào khi thiếu câu nguồn.

### 5.2 Mở rộng Bộ sửa chữa

Chúng tôi đã cho thấy rằng một bộ sửa chữa với 250M tham số có thể tinh chỉnh hiệu quả các dự đoán của LLM cho các nhiệm vụ cụ thể. Điều này đặt ra câu hỏi: việc huấn luyện một bộ sửa chữa có còn có giá trị nếu chúng ta có tài nguyên tính toán để huấn luyện một mô hình rất lớn? Để điều tra điều này, chúng tôi huấn luyện phiên bản lớn nhất của T5, T5-xxl với 11B tham số, cả thông qua việc tinh chỉnh tiêu chuẩn và như một bộ sửa chữa cho GEC. Chúng tôi lưu ý rằng, trong tình huống này, kích thước của mô hình được tinh chỉnh và LLM tương đương (11B so với 62B).

Như được thể hiện trong Hình 4, cả LMCOR và T5 được tinh chỉnh đều hưởng lợi từ việc mở rộng, thể hiện điểm số F0.5 cao hơn khi số lượng tham số của chúng tăng từ 250 triệu lên 11 tỷ. Ở quy mô 11 tỷ, cả hai mô hình đều vượt trội hơn đáng kể so với việc học trong ngữ cảnh với mô hình PaLM 62B. Bộ sửa chữa tiếp tục vượt trội hơn đường chuẩn khi quy mô mô hình tăng lên, mặc dù khoảng cách hiệu suất thu hẹp từ 3 xuống 0.5 điểm trong F0.5. Chúng tôi quy sự giảm này cho năng lực được nâng cao của mô hình T5 lớn hơn. Ở quy mô 11 tỷ tham số, điểm số thu được bởi mô hình T5 một mình vượt qua những điểm số thu được bởi LLM, chỉ ra rằng các đầu ra được tạo ra bởi LLM có chất lượng thấp hơn so với những đầu ra mà mô hình sẽ tạo ra độc lập. Do đó, trong khi đầu vào bổ sung cho mô hình vẫn có lợi, tác động của nó giảm đi một phần, xem xét sự khác biệt hiệu suất giữa T5 và PaLM.

## 6 Công trình Liên quan

Kể từ khi giới thiệu việc học trong ngữ cảnh, các nghiên cứu trước đây chủ yếu tập trung vào việc cải thiện hiệu suất few-shot của LLM. Một cách tiếp cận đề xuất nhắc nhở mô hình tạo ra các lý do hoặc chuỗi suy nghĩ (Nye et al., 2021; Wei et al., 2022; Kojima et al., 2022) hoặc để phân tách vấn đề thành những vấn đề đơn giản hơn (Press et al., 2022; Zhou et al., 2023; Pilault et al., 2023), mô phỏng một quá trình lý luận trước khi tạo ra câu trả lời. Những kỹ thuật nhắc nhở này bổ sung cho cách tiếp cận của chúng tôi và có thể cung cấp các ứng viên được cải thiện cho bộ sửa chữa.

Một chiến lược khác để cải thiện hiệu suất của LLM mà không cần huấn luyện là xếp hạng lại, tức là chọn ra những ứng viên hứa hẹn nhất từ một nhóm các ứng viên thu được bằng cách lấy mẫu từ mô hình. Các cách tiếp cận xếp hạng lại bao gồm huấn luyện các mô hình khác nhau làm bộ xếp hạng (Cobbe et al., 2021), sử dụng các hàm xếp hạng cụ thể cho nhiệm vụ (Suzgun et al., 2022b; Fernandes et al., 2022), bỏ phiếu đa số (Wang et al., 2023) hoặc giải mã rủi ro Bayes tối thiểu (MBRD) (Suzgun et al., 2022a; Freitag et al., 2022). Mặc dù những cách tiếp cận này có thể cải thiện hiệu suất few-shot của LLM, chúng bị giới hạn bởi chất lượng của các ứng viên được tạo ra.

Trong khi việc tinh chỉnh các LLM lớn có thể nâng cao hiệu suất, các yêu cầu tính toán đáng kể đã thúc đẩy sự phát triển của các phương pháp tinh chỉnh hiệu quả về tham số (PEFT) (He et al., 2022). Những cách tiếp cận này giới thiệu một số lượng nhỏ các tham số bổ sung (tương đối so với mô hình đầy đủ) để được huấn luyện trong khi phần còn lại của mô hình được đóng băng. Các tham số mới được thêm vào có thể ở dạng nhúng được nối vào chuỗi được mã hóa (Li và Liang, 2021; Lester et al., 2021), MLP được thêm vào giữa các lớp, cụ thể là adapter (Houlsby et al., 2019; Karimi Mahabadi et al., 2021) hoặc các ma trận phân tích thứ hạng được thêm song song với các lớp hiện có (Hu et al., 2022; Zhang et al., 2023b). Mặc dù những công trình này giảm tải tính toán của việc tinh chỉnh, chúng vẫn yêu cầu tải và lan truyền ngược qua mô hình, điều này có thể cấm đối với LLM. Công trình của chúng tôi chia sẻ cùng động cơ với các phương pháp PEFT, với các tham số được giới thiệu về cơ bản là một mô hình khác, nhỏ hơn. Tuy nhiên, phương pháp của chúng tôi không có yêu cầu bộ nhớ của PEFT vì bộ sửa chữa hoạt động trực tiếp trên các đầu ra của mô hình và không yêu cầu truy cập vào trọng số của mô hình.

Một hướng công trình thay thế đề xuất cung cấp phản hồi cho LLM để sửa đổi và nâng cao các dự đoán của nó. Phản hồi có thể được thu thập từ các mô hình bên ngoài như Google Search, bộ truy xuất tài liệu, trình biên dịch (Gao et al., 2021; Yao et al., 2023; Peng et al., 2023; Gou et al., 2023), hoặc từ một mô hình riêng biệt được huấn luyện để cung cấp phản hồi về các đầu ra LLM với giám sát bổ sung (Paul et al., 2023; Peng et al., 2023; Akyürek et al., 2023). Trong khi việc tận dụng chính LLM để tạo ra phản hồi đã được khám phá (Madaan et al., 2023; Shinn et al., 2023), nó có xu hướng tạo ra phản hồi chất lượng thấp hơn (Akyürek et al., 2023; Gou et al., 2023; Huang et al., 2023) và bao gồm nhiều lần truyền và kỹ thuật lời nhắc mở rộng cho mỗi hoạt động LLM. Ngược lại, cách tiếp cận của chúng tôi không phụ thuộc vào nhiệm vụ và yêu cầu một lần truyền duy nhất từ LLM, với ít hoặc không có kỹ thuật lời nhắc, cung cấp một giải pháp hiệu quả để nâng cao các đầu ra LLM.

Gần đây, các nghiên cứu đã nổi bật tiềm năng của các mô hình nhỏ hơn, cụ thể cho nhiệm vụ để bổ sung cho các dự đoán của LLM. Xu et al. (2023) khám phá một khung trong đó các ứng viên được tạo ra bởi các mô hình cụ thể cho nhiệm vụ được đưa vào LLM, chủ yếu nhắm mục tiêu vào nhiệm vụ phân loại trong khi LMCOR phù hợp hơn cho các nhiệm vụ tạo ra mở. Welleck et al. (2023) huấn luyện một mô hình nhỏ hơn để cải thiện lặp đi lặp lại các chuỗi được tạo ra bởi LLM. Ngược lại với phương pháp của chúng tôi, họ dựa vào dữ liệu không nhãn và lấy mẫu rộng rãi từ LLM để thu được một nhóm lớn các ứng viên. Họ giả định sự có sẵn của một hàm giá trị gán điểm số cho mỗi ứng viên và tạo ra các cặp đầu vào-đầu ra bằng cách sắp xếp các ứng viên dựa trên điểm số của chúng. Không giống như cách tiếp cận của họ, chúng tôi chứng minh rằng một bộ sửa chữa nhỏ gọn có thể hoạt động hiệu quả trên nhiều nhiệm vụ khác nhau. Ngoài ra, cách tiếp cận của chúng tôi hiệu quả hơn trong quá trình suy luận, vì khả năng của LMCOR xử lý nhiều ứng viên đồng thời loại bỏ nhu cầu nhiều lần truyền.

Đồng thời, các nhà nghiên cứu đã bắt đầu tận dụng bản chất bổ sung của các đầu ra được tạo ra bởi LLM trong quá trình suy luận. Farinhas et al. (2023) sử dụng LLM để kết hợp các đầu ra được tạo ra của nó cho dịch máy, mặc dù họ thấy rằng các phương pháp xếp hạng lại kết hợp các mô-đun bên ngoài, như các chỉ số ước lượng chất lượng (Zerva et al., 2022), tỏ ra hiệu quả hơn. Trong khi đó, Vernikos và Popescu-Belis (2024) đề xuất một cách tiếp cận sử dụng một chỉ số ước lượng chất lượng để kết hợp các đầu ra của LLM hoặc các mô hình MT. Tương tự như phương pháp của chúng tôi, họ khai thác sự đa dạng của các đầu ra LLM bằng cách xác định các đoạn khác biệt giữa các ứng viên và hợp nhất chúng dựa trên chỉ số.

Liên quan nhất với cách tiếp cận của chúng tôi là công trình của Jiang et al. (2023) trong đó họ đề xuất một phương pháp để kết hợp LLM. Quy trình của họ bao gồm i) lấy mẫu một nhóm lớn các ứng viên, ii) chọn các ứng viên hàng đầu thông qua nhiều so sánh cặp thông qua một bộ xếp hạng được huấn luyện và iii) hợp nhất chúng sử dụng một kỹ thuật tương tự như LMCOR. Mặc dù cách tiếp cận của chúng tôi có thể được mở rộng cho nhiều LLM, chúng tôi chứng minh những cải thiện với một LLM duy nhất, tận dụng tính bổ sung của các lần tạo ra. Ngoài ra, cách tiếp cận của chúng tôi hiệu quả hơn vì chúng tôi sử dụng một mô hình nhỏ hơn nhiều làm bộ sửa chữa (3B so với 250M) và không giới thiệu các bước huấn luyện và suy luận bổ sung để xếp hạng các đầu ra.

## 7 Kết luận

Trong công trình này, chúng tôi giới thiệu LMCOR, một cách tiếp cận mới tận dụng một mô-đun bộ sửa chữa nhỏ để nâng cao hiệu suất của LLM khi có dữ liệu huấn luyện. LMCOR tận dụng sự đa dạng của các lần tạo ra LLM để xếp hạng, chỉnh sửa và kết hợp các ứng viên. Không giống như các phương pháp tinh chỉnh hiệu quả về tham số, cách tiếp cận của chúng tôi không yêu cầu truy cập vào mô hình hoặc tài nguyên tính toán đáng kể. Các thí nghiệm của chúng tôi chứng minh rằng ngay cả một bộ sửa chữa tương đối nhỏ (250M) cũng có thể cải thiện hiệu suất của một LM lớn hơn nhiều (62B), trong khi thể hiện tính bền vững chống lại các lời nhắc khác nhau. Hơn nữa, chúng tôi thể hiện rằng bộ sửa chữa có thể được áp dụng thành công cho các mô hình có quy mô hoặc kiến trúc khác nhau mà không cần huấn luyện lại. Những phát hiện này cung cấp một giải pháp đầy hứa hẹn để cải thiện hiệu suất LLM một cách thực tế và hiệu quả về tài nguyên và mở ra những khả năng mới cho việc sử dụng và triển khai LLM trong các ứng dụng thực tế cùng với các mô hình nhỏ hơn cụ thể cho nhiệm vụ.

## Lời cảm ơn

Chúng tôi biết ơn sự hỗ trợ của Quỹ Khoa học Quốc gia Thụy Sĩ (tài trợ DOMAT số 175693, Kiến thức Theo yêu cầu cho Dịch máy Mức độ Tài liệu), và Viện ICT tại HEIG-VD. Chúng tôi cảm ơn Andrei Popescu-Belis và Katerina Margatina vì những bình luận có giá trị và các cuộc thảo luận bổ ích của họ.

## Hạn chế

**Độ trễ bổ sung** Trong khi cách tiếp cận của chúng tôi nâng cao hiệu suất của LLM trên các nhiệm vụ được xem xét, nó cũng giới thiệu độ trễ bổ sung. Thay vì một lần truyền duy nhất từ LLM, quy trình của chúng tôi bao gồm việc lấy mẫu nhiều ứng viên song song và thực hiện một bước suy luận bổ sung sử dụng một mô hình nhỏ hơn nhiều. Mặc dù độ trễ bổ sung nhỏ, nó có thể quan trọng đối với các ứng dụng độ trễ thấp yêu cầu phản hồi thời gian thực.

**Các mô hình được tinh chỉnh mạnh** Trong khi cách tiếp cận của chúng tôi chứng minh những cải thiện so với học trong ngữ cảnh và xếp hạng lại, nó có thể không phải lúc nào cũng đạt được cùng mức hiệu suất như các cách tiếp cận tinh chỉnh. Kết quả của chúng tôi trong XSum và Hình 3 chỉ ra rằng việc tinh chỉnh vẫn là một phương pháp mạnh mẽ cho các mô hình nhỏ hơn khi có sẵn dữ liệu dồi dào. Ngoài ra, việc mở rộng các mô hình được tinh chỉnh thay vì sử dụng LLM sẵn có có thể là một lựa chọn thay thế tốt hơn trong một số trường hợp nhất định, như được thảo luận trong Phần 5.2.

**Các nhiệm vụ và mô hình bổ sung** Do giới hạn về thời gian và ngân sách, các thí nghiệm của chúng tôi bao gồm 4 nhiệm vụ tạo ngôn ngữ tự nhiên và chúng có thể được mở rộng cho các loại nhiệm vụ khác như lý luận. Ngoài ra, trong khi LMCOR cho thấy kết quả đầy hứa hẹn khi được kết hợp với các LLM khác nhau, ngay cả trong quá trình suy luận, sẽ rất thú vị khi áp dụng cách tiếp cận của chúng tôi cho một lựa chọn rộng hơn các LLM hiện có sẵn.

**Đánh giá con người** Chúng tôi đồng ý rằng các chỉ số tự động có hạn chế. Mặc dù việc lựa chọn các chỉ số phù hợp với công trình trước đây, đánh giá con người có thể cung cấp cho chúng tôi kết quả đánh giá đáng tin cậy và toàn diện hơn. Tuy nhiên, do số lượng mô hình và lượng ứng viên tạo ra, chúng tôi không thể chi trả cho đánh giá con người quy mô lớn.

## Tác động Rộng hơn

Cho rằng cách tiếp cận được đề xuất kết hợp LLM và các mô hình bộ sửa chữa nhỏ để cải thiện hiệu suất, điều quan trọng là phải thừa nhận rằng nó chia sẻ các thiên kiến xã hội tiềm năng liên quan đến LLM. Mặc dù công trình của chúng tôi tập trung vào việc cải thiện các dự đoán của LLM trên các bộ dữ liệu cụ thể thay vì tạo ra mở, không có khả năng cách tiếp cận của chúng tôi khuếch đại những thiên kiến này ở mức độ lớn hơn so với các phương pháp khác. Tuy nhiên, điều quan trọng là phải điều tra liệu LMCOR có bất kỳ tác động nào đến việc khuếch đại hoặc giảm thiểu những thiên kiến này hay không.

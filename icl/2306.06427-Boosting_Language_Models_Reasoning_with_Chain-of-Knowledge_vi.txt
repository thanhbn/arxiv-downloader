# 2306.06427.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl/2306.06427.pdf
# Kích thước tệp: 855692 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Cải thiện khả năng lý luận của mô hình ngôn ngữ với Chuỗi tri thức gợi ý
Jianing Wang♢*, Qiushi Sun♡*, Xiang Li♢†, Ming Gao♢
♢Đại học Sư phạm Hoa Đông♡Đại học Hồng Kông
lygwjn@gmail.com ,qiushisun@u.nus.edu ,
{xiangli, mgao}@dase.ecnu.edu.cn

Tóm tắt
Gần đây, phương pháp gợi ý Chuỗi suy nghĩ (CoT) đã đạt được thành công trong các nhiệm vụ lý luận phức tạp, nhằm thiết kế một gợi ý đơn giản như "Hãy suy nghĩ từng bước" hoặc nhiều ví dụ trong ngữ cảnh với các lý lẽ được thiết kế tốt để kích thích các Mô hình ngôn ngữ lớn (LLMs) tạo ra các bước lý luận trung gian. Tuy nhiên, các lý lẽ được tạo ra thường đi kèm với ảo giác, tạo ra các chuỗi lý luận không thực tế và không trung thực. Để giảm thiểu tính dễ vỡ này, chúng tôi đề xuất một phương pháp gợi ý Chuỗi tri thức (CoK) mới, trong đó chúng tôi nhằm kích thích LLMs tạo ra các bằng chứng tri thức rõ ràng dưới dạng bộ ba cấu trúc. Điều này được lấy cảm hứng từ hành vi con người của chúng ta, tức là chúng ta có thể vẽ sơ đồ tư duy hoặc bản đồ tri thức làm bằng chứng lý luận trong não trước khi trả lời một câu hỏi phức tạp. Được hưởng lợi từ CoK, chúng tôi bổ sung giới thiệu phương pháp F2-Verification để ước tính độ tin cậy của các chuỗi lý luận về mặt thực tế và trung thực. Đối với phản hồi không đáng tin cậy, bằng chứng sai có thể được chỉ ra để gợi ý LLM suy nghĩ lại. Các thí nghiệm mở rộng chứng minh rằng phương pháp của chúng tôi có thể cải thiện thêm hiệu suất của các nhiệm vụ lý luận thường thức, thực tế, ký hiệu và số học¹.

1 Giới thiệu
Các Mô hình ngôn ngữ lớn (LLMs) đã thành công trong việc nâng cao tình trạng nghệ thuật cho nhiều nhiệm vụ Xử lý ngôn ngữ tự nhiên (NLP) (Brown et al., 2020; Rae et al., 2021; Thoppilan et al., 2022; Chowdhery et al., 2022; Scao et al., 2022; Zhang et al., 2022b; Bai et al., 2022; Touvron et al., 2023, trong số những người khác), được hưởng lợi từ kho dữ liệu huấn luyện quy mô cực lớn và tài nguyên tính toán. Để giải phóng sức mạnh thích ứng của LLMs trên các nhiệm vụ chưa thấy mà không cần cập nhật tham số, học trong ngữ cảnh (ICL) đã trở thành một trong những chủ đề nghiên cứu phát triển mạnh, nhằm tạo ra dự đoán bằng cách điều kiện hóa trên một vài ví dụ có nhãn (Hình 1 (a)) (Shin et al., 2022; Zhao et al., 2021; Liu et al., 2022; Lu et al., 2022; Dong et al., 2023).

*J. Wang và Q. Sun đóng góp như nhau cho công việc này.
†Tác giả liên hệ.
¹Mã và dữ liệu có sẵn tại https://github.com/wjn1996/Chain-of-Knowledge

Một loạt các công trình gần đây đã khám phá rằng LLMs có thể tự phân hủy vấn đề đa bước phức tạp thành các chuỗi lý luận trung gian, được kích thích bởi một gợi ý đơn giản như "Hãy suy nghĩ từng bước" hoặc các minh họa được thiết kế tốt với các lý lẽ được chú thích bởi con người, được gọi là phương pháp gợi ý chuỗi suy nghĩ (CoT) (Hình 1 (b)) (Wei et al., 2022; Kojima et al., 2022; Wang et al., 2023d; Zhou et al., 2023; Yao et al., 2023b). Phát hiện này rất hấp dẫn và đã gây sốc vì CoT có thể chủ yếu chỉ định một không gian đầu ra/định dạng điều chỉnh việc tạo mô hình để trông từng bước trong khi có thứ tự và liên quan đến truy vấn (Wang et al., 2023a; Min et al., 2022b).

Mặc dù có hiệu suất ấn tượng, các LLMs hiện tại dễ bị tạo ra ảo giác (Ji et al., 2023; Zhang et al., 2023a), cùng với việc cung cấp các chuỗi lý luận không thực tế hoặc không trung thực mà không thể tránh khỏi dẫn đến kết luận sai (Wang et al., 2023b). Lấy Hình 1 làm ví dụ. Với truy vấn "Câu sau có hợp lý không 'Derrick White backhanded a shot.'" từ StrategyQA (Geva et al., 2021), ICL tiêu chuẩn và CoT đưa ra câu trả lời sai. Một trong những bước lý luận "Derrick White rất có thể là một cầu thủ khúc côn cầu" là giả (Thực tế, Derrick White là một cầu thủ bóng rổ), tạo ra suy luận không thực tế đối với câu hỏi. Ngoài ra, phản hồi có thể không trung thực khi LLM tạo ra các chuỗi lý luận hợp lý về mặt logic trong khi vẫn cung cấp câu trả lời không chính xác.

Để giải quyết những mối quan tâm này, chúng tôi đề xuất một phương pháp gợi ý Chuỗi tri thức (CoK) mới để tăng cường khả năng lý luận của LLM bằng một loạt các ví dụ kết hợp cấu trúc rõ ràng

--- TRANG 2 ---
Đầu vào
Bộ ba bằng chứng:
1. (Derrick White, là, cầu thủ bóng rổ)
2. (cú đánh backhand, được sử dụng phổ biến trong, khúc côn cầu hoặc tennis)
Gợi ý giải thích: Cú đánh backhand được sử dụng phổ biến trong khúc côn cầu hoặc tennis, nhưng không trong bóng rổ.
A: Không. ✅

Câu hỏi: Câu sau có hợp lý không? 'Joao Moutinho was out at third.'
Bộ ba bằng chứng:
1. (Joao, là, cầu thủ bóng đá)
2. (being out at third, là một phần của, bóng chày)
Gợi ý giải thích: Being out at third là một phần của bóng chày, tuy nhiên, Joao Moutinho là một cầu thủ bóng đá.
A: Không.

Câu hỏi: Câu sau có hợp lý không? 'Derrick White backhanded a shot.'

Đầu ra
Đầu vào
A: Có. ❌

Câu hỏi: Câu sau có hợp lý không? 'Joao Moutinho was out at third.'
A: Không.

Câu hỏi: Câu sau có hợp lý không? 'Derrick White backhanded a shot.'

Đầu ra
Đầu vào
A: Có, điều đó hợp lý. Câu này cho thấy rằng Derrick White, người rất có thể là một cầu thủ bóng rổ hoặc khúc côn cầu, đã thực hiện một cú đánh backhand. ❌

Câu hỏi: Câu sau có hợp lý không? 'Joao Moutinho was out at third.'
Joao Moutinho là một cầu thủ bóng đá.
Being out at third là một phần của bóng chày, không phải bóng đá.
A: Không.

Câu hỏi: Câu sau có hợp lý không? 'Derrick White backhanded a shot.'

Đầu ra

(a) Gợi ý ICL tiêu chuẩn (b) Gợi ý Chuỗi suy nghĩ (c) Của chúng tôi: Gợi ý Chuỗi tri thức

Hình 1: So sánh ba phương pháp gợi ý: (a) ICL, (b) Chuỗi suy nghĩ (CoT), và (c) Chuỗi tri thức (CoK) giải quyết một câu hỏi StrategyQA.

bằng chứng tri thức với giải thích văn bản. Để mở rộng, gợi ý CoK bao gồm hai thành phần (Hình 1 (c)), tức là bộ ba bằng chứng (CoK-ET) và gợi ý giải thích (CoK-EH), trong đó CoK-ET là một danh sách các bộ ba cấu trúc có thể phản ánh bằng chứng lý luận tổng thể từ truy vấn đến câu trả lời và CoK-EH là lời giải thích về bằng chứng này.

Để xây dựng các ví dụ trong ngữ cảnh với gợi ý CoK, trước tiên chúng tôi lấy mẫu K ví dụ có nhãn và mỗi ví dụ có thể được nối với một gợi ý đơn giản "Hãy suy nghĩ từng bước" để gợi ý LLM tạo ra các chuỗi lý luận. Sau đó, chúng tôi truy xuất một số bộ ba cấu trúc từ cơ sở tri thức bên ngoài (KB) và chú thích thủ công một cách thận trọng các bộ ba bằng chứng để có được một gợi ý CoK được thiết kế tốt.

Như ICL tiêu chuẩn và CoT, gợi ý CoK có thể được coi là một quy tắc điều chỉnh không gian đầu ra/định dạng và thúc đẩy LLMs tạo ra bằng chứng rõ ràng thay vì chỉ cố gắng tạo ra các chuỗi lý luận văn bản mơ hồ. Hơn nữa, chúng tôi cũng đề xuất một chiến lược F2-Verification để ước tính độ tin cậy của các chuỗi lý luận về mặt thực tế và trung thực, trong đó thực tế là định lượng mức độ khớp giữa bằng chứng lý luận và tri thức đúng đắn, và trung thực là mức độ nhất quán giữa bằng chứng lý luận và giải thích văn bản với câu trả lời cuối cùng. Đặc biệt đối với phản hồi không đáng tin cậy, những mẩu bằng chứng sai có thể được chỉ ra để gợi ý LLM suy nghĩ lại vấn đề.

Chúng tôi thiết kế một thuật toán suy nghĩ lại để đạt được mục tiêu này.

Chúng tôi đã tiến hành đánh giá thực nghiệm trên các nhiệm vụ lý luận khác nhau (ví dụ: thường thức, thực tế, số học và ký hiệu), cho thấy gợi ý CoK với F2-Verification có thể vượt trội đáng kể so với gợi ý ICL tiêu chuẩn và CoT. Chúng tôi cũng tích hợp gợi ý CoK với một số chiến lược phổ biến, chẳng hạn như self-consistency. Kết quả chỉ ra rằng CoK như vậy có thể phục vụ như một mô-đun cắm và chạy để cải thiện thêm khả năng lý luận.

2 Công trình liên quan

Gợi ý cho LLMs với học trong ngữ cảnh.
Học trong ngữ cảnh (ICL) là nhiệm vụ mô hình hóa ngôn ngữ nhân quả, cho phép LLMs thực hiện học zero/few-shot với một gợi ý dựa trên văn bản được thiết kế tốt (Brown et al., 2020; Chowdhery et al., 2022; Touvron et al., 2023; Thoppilan et al., 2022; Dong et al., 2023). ICL có thể bỏ qua việc cập nhật tham số mô hình và đạt được hiệu suất nổi bật bằng cách điều kiện hóa trên một vài ví dụ có nhãn.

Các công trình trước đây đã khám phá một số khía cạnh tác động của ICL. Ví dụ, ánh xạ đầu vào-đầu ra và định dạng mẫu (Pan et al., 2023; Min et al., 2022b; Yoo et al., 2022), việc lựa chọn và hoán vị khác nhau của các ví dụ (Lu et al., 2022). Để cải thiện hiệu quả của ICL, một số phương pháp mới đã được đề xuất, bao gồm meta-learning (Chen et al., 2022; Min et al., 2022a), kỹ thuật gợi ý và ví dụ (Liu et al., 2022, 2023).

Gợi ý chuỗi suy nghĩ kích thích lý luận.
Gần đây, gợi ý CoT đã được trình bày để tận dụng thông tin lý luận và có thể diễn giải để hướng dẫn LLMs tạo ra các phản hồi đáng tin cậy và có thể giải thích (Wei et al., 2022). Một loạt

--- TRANG 3 ---
Câu hỏi: Câu sau có hợp lý không? 'Joao Moutinho was out at third.'
A: Hãy suy nghĩ từng bước. 

Ví dụ #1
        LLM

Truy xuất
Lý luận Zero-shot 
Chuỗi suy nghĩ
Cơ sở tri thức

Chuỗi tri thức
Ví dụ #1

Câu hỏi: Câu sau có hợp lý không? 'Joao Moutinho was out at third.'  
Bộ ba bằng chứng:  
1. (Joao, là, cầu thủ bóng đá)  
2. (being out at third, là một phần của, bóng chày)  
Gợi ý giải thích: Being out at third là một phần của bóng chày, tuy nhiên, Joao Moutinho là một cầu thủ bóng đá. 
A: Không.   

Ví dụ #1 
Ví dụ #2 
Ví dụ #K
...

Câu hỏi: Câu sau có hợp lý không? 'Derrick White backhanded a shot.'
Ví dụ thử nghiệm

        LLM

Bộ ba bằng chứng: 
1. (Derrick White, là, cầu thủ bóng rổ) 
2. (cú đánh backhand, được sử dụng phổ biến trong, khúc côn cầu hoặc tennis) 
Gợi ý giải thích: Cú đánh backhand được sử dụng phổ biến trong khúc côn cầu hoặc tennis, nhưng không trong bóng rổ. 
A: Không.

Đầu ra

Xây dựng ví dụ
Lý luận Chuỗi tri thức
F2-Xác minh

Xác minh thực tế
Cơ sở tri thức

1. (Derrick White, là, cầu thủ bóng rổ)   
2. (cú đánh backhand, được sử dụng phổ biến trong, khúc côn cầu hoặc tennis) 
✅
✅

Xác minh trung thực
0.9
1.0

Không.

Nếu đáng tin cậy, đưa ra câu trả lời.
Nếu không đáng tin cậy, hãy suy nghĩ lại.

Gợi ý
Người chú thích

Hình 2: Khung đề xuất. Trước tiên chúng tôi xây dựng các ví dụ với gợi ý chuỗi tri thức (CoK). Sau đó, các gợi ý CoK có thể được sử dụng để cho LLM tạo ra các chuỗi lý luận, bao gồm bộ ba bằng chứng, gợi ý giải thích và câu trả lời cuối cùng. Cuối cùng, chúng tôi ước tính độ tin cậy của các chuỗi lý luận về mặt thực tế và trung thực, và những chuỗi không đáng tin cậy sẽ được suy nghĩ lại.

các phương pháp tăng cường CoT được đề xuất để cải thiện thêm khả năng lý luận (Kojima et al., 2022; Huang et al., 2022; Wang et al., 2023d; Si et al., 2022; Wang et al., 2022; Zhou et al., 2023; Zhang et al., 2023b; Fu et al., 2023; Besta et al., 2023).

Ví dụ, Wang et al. (2023d) giới thiệu Self-consistency để ngăn chặn vấn đề lý lẽ sai bằng cách biên hóa các đường dẫn lý luận được lấy mẫu để tìm câu trả lời nhất quán nhất. Fu et al. (2023) và Besta et al. (2023) đề xuất đồ thị tư duy logic để cho LLMs lý luận tốt hơn. Lyu et al. (2023) dịch vấn đề phức tạp thành ngôn ngữ tự nhiên hoặc ngôn ngữ lập trình xen kẽ để làm cho các chuỗi lý luận trung thực. Li et al. (2023) và Yao et al. (2023a) giới thiệu các nhãn thô hoặc tinh để xác minh các chuỗi lý luận.

Khác biệt, chúng tôi tập trung vào giảm thiểu ảo giác về mặt thực tế và trung thực của các chuỗi lý luận.

3 Phương pháp

Các chuỗi lý luận được tạo ra được kích thích bởi gợi ý CoT đôi khi đi kèm với sai lầm, cuối cùng dẫn đến câu trả lời ảo giác. Chúng tôi quy kết thách thức này cho chuỗi lý luận văn bản: LLMs có thể cưỡng bức tạo ra một lý lẽ văn bản phù hợp với định dạng gợi ý của CoT nhưng mơ hồ về mặt logic và đạt đến câu trả lời sai.

Để giải quyết thách thức này, chúng tôi cung cấp giải pháp cụ thể về cách tăng cường khả năng lý luận của LLM ở hai góc độ: định dạng kích thích lý luận của gợi ý và xác minh hậu kỳ tăng cường tri thức. Tổng quan về khung được hiển thị trong Hình 2.

3.1 Gợi ý Chuỗi tri thức

Được công nhận rộng rãi rằng lý luận có thể được mô hình hóa như quy nạp và suy diễn trên hệ thống tri thức hiện có (Goswami, 2002). Điều này được lấy cảm hứng từ hành vi con người khi vẽ sơ đồ tư duy hoặc bản đồ tri thức để phân tích câu hỏi và tìm đường dẫn chính xác đến câu trả lời. May mắn thay, chúng ta có thể áp dụng khái niệm bộ ba trong KB, có thể được xem là "(chủ thể, quan hệ, đối tượng)", để chính thức hóa bằng chứng rõ ràng của các chuỗi lý luận.

Để mở rộng, chúng tôi đề xuất gợi ý Chuỗi tri thức (CoK) để tạo điều kiện cho một gợi ý kích thích tốt hơn cho LLMs, bao gồm hai thành phần chính, tức là bộ ba bằng chứng (CoK-ET) và gợi ý giải thích (CoK-EH). CoK-ET đại diện cho một danh sách nhiều bộ ba và mỗi bộ ba đại diện cho bằng chứng tri thức được thăm dò từ LLMs để hỗ trợ quá trình tư duy từng bước.

CoK-EH biểu thị lời giải thích của chuỗi lý luận, tương tự như CoT. Lấy Hình 1 làm ví dụ, chúng ta có thể thúc đẩy LLM tạo ra những mảnh bằng chứng rõ ràng để hỗ trợ câu trả lời cuối cùng.

--- TRANG 4 ---
3.2 Xây dựng ví dụ

Dựa trên những hiểu biết của các nghiên cứu trước (Zhang et al., 2023b; Min et al., 2022b; Wang et al., 2023d), hiệu suất của ICL phụ thuộc vào lý lẽ được chú thích. Điều này cho thấy rằng thách thức chính của gợi ý CoK nằm ở việc xây dựng lý lẽ văn bản với các bộ ba bằng chứng cấu trúc của chúng.

Như được hiển thị trong Hình 2, trước tiên chúng tôi thực hiện xây dựng ví dụ để có được một gợi ý cụ thể nhiệm vụ được thiết kế tốt. Cụ thể, chúng tôi theo (Wei et al., 2022; Wang et al., 2023d) để lựa chọn ngẫu nhiên K câu hỏi làm minh họa cơ bản. Để tự động có được CoK-EH, chúng tôi theo (Kojima et al., 2022) để tạo ra một lý lẽ văn bản cho mỗi câu hỏi thông qua CoT zero-shot với một gợi ý đơn giản "Hãy suy nghĩ từng bước".

Một thách thức khác là làm thế nào để có được CoK-ET được chú thích để thể hiện tốt hơn lý lẽ văn bản. Để tìm ra điều đó, trước tiên chúng tôi theo (Pan et al., 2022) để xây dựng một KB K từ sáu lĩnh vực, bao gồm từ điển, thường thức, thực thể, sự kiện, kịch bản và nhân quả, có dạng bộ ba. Sau đó chúng tôi trực tiếp sử dụng công cụ truy xuất được đề xuất bởi (Pan et al., 2022) để truy xuất một số bộ ba ứng cử viên. Cuối cùng, chúng tôi mời 5 người làm người chú thích chuyên nghiệp để thiết kế thủ công CoK-ET tương ứng dựa trên các bộ ba được truy xuất².

Chi tiết thêm có thể tìm thấy trong Phụ lục C.1.

3.3 F2-Verification

Sau khi xây dựng ví dụ, chúng ta có thể thu được K dữ liệu được chú thích E={(Qi, Ti, Hi, Ai)}K i=1. Về ký hiệu, Qi, Hi và Ai tương ứng đại diện cho truy vấn đầu vào, gợi ý giải thích và câu trả lời cuối cùng của ví dụ thứ i; mỗi cái trong số đó là chuỗi token. Ti biểu thị danh sách các bộ ba bằng chứng, chứa nhiều bộ ba tri thức, tức là Ti={(sij, rij, oij)}j, trong đó sij, rij và oij tương ứng là chủ thể, quan hệ và đối tượng.

Với một truy vấn thử nghiệm đầu vào Q̂i, chúng ta có thể trực tiếp chọn một hoán vị của E và nối chúng với truy vấn thử nghiệm này thành một chuỗi tuyến tính Îi = [E; Q̂i] để gợi ý LLM tạo ra dự đoán, tức là ŷik = arg max σ(ŷi(≤k))P(y|ŷi(<k),E,Q̂i), trong đó P(y|·) là phân phối dự đoán, ŷik là token thứ k, σ(·) biểu thị chiến lược giải mã (ví dụ: lấy mẫu nhiệt độ, tìm kiếm chùm và lấy mẫu nucleus), [·;·] là phép toán nối.

Do định dạng được thiết kế tốt của các minh họa, dự đoán cuối cùng được suy ra từ LLM ŷi bao gồm một danh sách các bộ ba bằng chứng T̂i, một chuỗi gợi ý giải thích Ĥi và câu trả lời cuối cùng Âi. Tuy nhiên, LLMs có thể tạo ra các lý lẽ ảo giác, vì vậy câu trả lời cuối cùng không thể được đảm bảo.

Chúng tôi quy kết vấn đề này cho hai yếu tố: 1) một số bước trong lý lẽ có thể không tương ứng với thực tế, góp phần vào sự sai lầm, và 2) mối quan hệ giữa câu trả lời cuối cùng và các chuỗi lý luận vẫn mơ hồ, làm cho phản hồi không trung thực. Để giảm thiểu những hạn chế này, chúng tôi đề xuất F2-Verification để ước tính độ tin cậy của câu trả lời đối với cả Thực tế và Trung thực³.

Xác minh thực tế. Trước tiên chúng tôi xác minh thực tế, có thể được xem là mức độ khớp giữa mỗi bộ ba bằng chứng được tạo ra và tri thức đúng đắn từ KBs⁴. Cụ thể, trước tiên chúng tôi định nghĩa một hàm fv(r̂ij|ŝij,ôij,K) để đại diện cho thực tế của mỗi bằng chứng. Chúng tôi thiết kế hai chiến lược khác nhau của fv. 1) Xác minh chính xác. Chúng ta có thể truy xuất tất cả các bộ ba liên quan dựa trên chủ thể ŝij và đối tượng ôij, và sau đó tìm xem quan hệ được tạo ra r̂ij. tức là fv(r̂ij|ŝij,ôij,K) = I((ŝij,r̂ij,ôij)∈ K) có tồn tại. 2) Xác minh ngầm. Đối với một bộ ba không tồn tại trong KB, nó có thể được sửa chữa. Do đó, chúng ta có thể chuyển đổi xác minh thực tế thành một nhiệm vụ hoàn thành đồ thị dự đoán liệu bộ ba có đúng không.

Để đơn giản, chúng tôi sử dụng TransR (Lin et al., 2015) để tiền huấn luyện KB K và sử dụng hàm năng lượng sẵn có để gán điểm cho mỗi bộ ba bằng chứng, tức là fv(r̂ij|ŝij,ôij,K) =||s(r,c) ij+rc−o(r,c) ij||2 2+ α||rc−rij||2 2, trong đó α > 0 là yếu tố cân bằng, || · ||2 2 là chuẩn Frobenius. s(r,c) ij=sijMr và o(r,c) ij=oijMr biểu thị các biểu diễn chiếu của chủ thể sij và đối tượng oij trong không gian quan hệ r, tương ứng. sij, rij, và oij∈Rd là các embedding d-chiều của ŝij, r̂ij và ôij, tương ứng. rc∈Rd là embedding nguyên mẫu của quan hệ r. Mr∈Rd×d là ma trận chiếu có thể huấn luyện của quan hệ r.

Chúng tôi kết hợp hai chiến lược trong khung của chúng tôi. Nếu bộ ba bằng chứng tồn tại trong K, chúng tôi sẽ sử dụng chiến lược xác minh chính xác để gán điểm, hoặc chúng tôi sử dụng chiến lược xác minh ngầm.

Xác minh trung thực. Như được định nghĩa bởi Jacovi và Goldberg (2020) và Lyu et al. (2023), nếu quá trình lý luận suy ra từ mô hình có thể được biểu đạt chính xác bằng một lời giải thích, chúng ta gọi nó là trung thực. Các công trình trước đây dựa trên gợi ý chuỗi suy nghĩ gặp khó khăn trong việc xác minh trung thực do thiếu bằng chứng đầy đủ để hiểu mối quan hệ giữa giải thích và câu trả lời (Ye và Durrett, 2022). Vì vậy, chúng tôi đề xuất một phương pháp xác minh trung thực để tìm ra những trường hợp này.

Cụ thể, cho một truy vấn thử nghiệm Q̂i, một danh sách các bộ ba bằng chứng T̂i và câu trả lời cuối cùng Âi, chúng tôi trực tiếp nối chúng thành một chuỗi mới Ĥ′ i. Chúng tôi tận dụng bộ mã hóa câu được xây dựng sẵn SimCSE (Gao et al., 2021) để tính toán sự tương tự giữa Ĥ′ i và Ĥi. Chúng tôi biểu thị hàm này là fu(Ĥi|Ĥ′ i = [Q̂i;T̂i;Âi]) =SimCSE (Ĥi,Ĥ′ i).

Cuối cùng, cho mỗi truy vấn Q̂i chúng ta có thể thu được một điểm Ci(0<Ci<1) đại diện cho liệu lý lẽ có đáng tin cậy đối với câu trả lời:

Ci=γ 1/|T̂i| |T̂i|∑ j=1 fv(ŝij|r̂ij,ôij,K) + (1−γ)fu(Ĥi|Ĥ′ i = [Q̂i;T̂i;Âi]), (1)

trong đó 0< γ < 1 là yếu tố cân bằng và được đặt là 0.5 mặc định, |T̂i| là số lượng bộ ba.

3.4 Quá trình suy nghĩ lại

F2-Verification tạo điều kiện cho chúng ta đảm bảo thực tế và trung thực của các bộ ba và giải thích được tạo ra bởi mô hình. Ngoài phạm vi xác minh, chúng ta có thể tăng cường thêm hiệu suất của LLMs bằng cách sử dụng một quá trình suy nghĩ lại, như được hiển thị trong Thuật toán 1.

Chúng tôi khởi tạo một ngưỡng độ tin cậy θ(0< θ < 1), số lần lặp N, và một tập hợp không đáng tin cậy U. Tất cả các truy vấn trong tập thử nghiệm Dtest ban đầu được coi là không đáng tin cậy.

Cho mỗi truy vấn Q̂i∈U trong lần lặp thứ n, chúng tôi thu được gợi ý CoK Î(n) i bằng cách kết hợp các minh họa E và truy vấn Q̂i. Gợi ý có thể được sử dụng để kích thích LLM tạo ra một danh sách các bộ ba bằng chứng T̂(n) i, gợi ý giải thích Ĥ(n) i, và câu trả lời cuối cùng Â(n) i.

Thuật toán suy nghĩ lại được đề xuất sẽ cho phép LLMs đánh giá độ tin cậy của các lý lẽ (tức là T̂(n) i và Ĥ(n) i) thông qua việc tính toán điểm trong Eq. 1. Một mục không còn được coi là không đáng tin cậy nếu C(n) i không thấp hơn ngưỡng θ, dẫn đến câu trả lời cuối cùng Âi. Ngược lại, giả sử C(n) i không đạt được θ. Trong trường hợp đó, chúng ta có thể chọn các bộ ba bằng chứng có điểm thấp hơn và tiêm các bộ ba tri thức đúng tương ứng từ KB vào gợi ý CoK Î(n+1) i trong lần lặp tiếp theo (Dòng 12)⁵.

Quá trình tạo-đánh giá động này tiếp tục cho đến khi tất cả các mục trong U được coi là đáng tin cậy hoặc số lần lặp tối đa N được đạt đến. Đối với các trường hợp mà số lần lặp tối đa được đạt đến mà không có bộ ba nào có điểm độ tin cậy vượt quá θ, các bộ ba có điểm độ tin cậy cao nhất sẽ được chọn để suy luận (Dòng 15-17).

Thuật toán 1 Quá trình suy nghĩ lại
Yêu cầu: Ví dụ E, tập truy vấn thử nghiệm Dtest← {Q̂i}M i=1, KB K, số lần lặp N(≥1), ngưỡng độ tin cậy 0< θ <1.
1: Khởi tạo một tập không đáng tin cậy U← D test.
2: foreach lần lặp n←1,···, N do
3: foreach truy vấn Q̂i trong U do
4: Lấy gợi ý CoK Î(n) i. Nếu n là 1, Î(n) i← [E;Q̂i].
5: Tạo bộ ba bằng chứng T̂(n) i, gợi ý giải thích Ĥ(n) i và câu trả lời Â(n) i từ LLM.
6: Tính điểm độ tin cậy C(n) i trong Eq. 1.
7: if C(n) i≥θ then
8: Lấy câu trả lời cuối cùng Âi←Â(n) i.
9: Loại bỏ Q̂i khỏi U.
10: continue
11: end if
12: Đối với các bộ ba bằng chứng mà fv(r̂(n) ij|ŝ(n) ij,ô(n) ij,K)< θ, tiêm các bộ ba tri thức đúng tương ứng T̂′ i vào gợi ý, tức là Î(n+1) i←[Î(n) i;T̂′ i].
13: end for
14: end for
15: foreach truy vấn Q̂i trong U do
16: Lấy câu trả lời cuối cùng Âi←arg maxÂ(n) i C(n) i.
17: end for
18: return tất cả các câu trả lời {Âi}M i=1.

4 Thí nghiệm

4.1 Thiết lập thí nghiệm

Nhiệm vụ và Tập dữ liệu. Trong các thí nghiệm, chúng tôi chọn năm loại nhiệm vụ khác nhau để đánh giá hiệu suất của phương pháp của chúng tôi. Các tập dữ liệu và chi tiết triển khai tương ứng được hiển thị như sau. 1) Lý luận thường thức & thực tế. Chúng tôi chọn CommonsenseQA (CSQA) (Talmor et al., 2019), StrategyQA (Geva et al., 2021), OpenBookQA (Mihaylov et al., 2018) thử thách Lý luận AI2 (ARC-c) (Clark et al., 2018), hiểu biết về thể thao

²Thực tế, trong quá trình xây dựng ví dụ, các chuỗi lý luận văn bản được tạo ra và các bộ ba được truy xuất có thể có một số sai lầm. May mắn thay, chúng tôi thấy rằng không có mối liên hệ mạnh giữa tính hợp lệ lý luận của cả CoK-ET và CoK-EH và hiệu suất của các dự đoán mô hình, tương tự như các phát hiện trong (Wang et al., 2023a). Chúng tôi sẽ mang lại các thảo luận chi tiết tại Phần 4.3.
³Chúng tôi thấy rằng (He et al., 2022) cũng đề xuất các quá trình suy nghĩ lại và truy xuất để giảm sự sai lầm, khác với họ, chúng tôi tập trung vào phát hiện và tiêm chi tiết với gợi ý CoK được đề xuất.
⁴Chúng tôi giả định rằng tri thức từ KB là chính xác và cập nhật.
⁵Điều này tương tự như việc sửa chữa các đường dẫn lý luận sai, chúng tôi đảm bảo rằng nhãn không bị rò rỉ cho mô hình.

--- TRANG 5 ---
từ điểm chuẩn BIG-Bench (bench collaboration., 2022), và BoolQ (Clark et al., 2019) để đánh giá CoK về lý luận thường thức và thực tế. 2) Lý luận ký hiệu. Hai nhiệm vụ lý luận ký hiệu được đánh giá trong các thí nghiệm của chúng tôi, cụ thể là nhiệm vụ Nối chữ cái cuối và Tung xu (Wei et al., 2022). 3) Lý luận số học. Chúng tôi sử dụng các bài toán toán học lớp tiểu học GSM8K (Cobbe et al., 2021), một tập dữ liệu thách thức về các bài toán từ toán học SV AMP (Patel et al., 2021), và hai tập khác AQuA (Ling et al., 2017), MultiArith (Roy và Roth, 2015) cho các nhiệm vụ giải quyết bài toán toán học.

Chi tiết triển khai. Đối với LLM, chúng tôi sử dụng các mô hình GPT-3 (Brown et al., 2020) có thể truy cập công khai, cụ thể là gpt-3.5-turbo và text-davinci-002 với 175B tham số trừ khi có quy định khác. Chúng tôi sử dụng giải mã tham lam với nhiệt độ 0 và độ dài đầu ra tối đa 512, giữ nhất quán với các đường cơ sở để so sánh công bằng.

Đối với các tập dữ liệu từ lý luận thường thức và lý luận thực tế, các KB chúng tôi chọn là sự kết hợp của Wiktionary⁶, ConceptNet (Speer et al., 2017), Wikidata5M (Wang et al., 2021), ATOMIC (Sap et al., 2019), GLUCOSE (Mostafazadeh et al., 2020), ASER (Zhang et al., 2020, 2022a), và

⁶https://en.wiktionary.org/wiki/Wiktionary .

CausalBank (Li et al., 2020). Đối với nhiệm vụ Nối chữ cái cuối trong Lý luận ký hiệu, chúng tôi xây dựng thủ công một từ điển KB cho mỗi từ trong Wiktionary. Ví dụ, bộ ba của từ "system" là "(system, chữ cái cuối, m)". Đối với các tập dữ liệu còn lại (ví dụ: lý luận số học và tập dữ liệu xu), chúng tôi không thực hiện F2-Verification vì chúng tôi không thể tìm thấy bất kỳ KB nào cho các nhiệm vụ này. Chi tiết thêm được hiển thị trong Phụ lục C.

Đường cơ sở. Trong các thí nghiệm của chúng tôi, trước tiên chúng tôi xem xét gợi ý tiêu chuẩn few-shot/zero-shot (SP) được phổ biến bởi Brown et al. (2020) như các đường cơ sở ngây thơ, và sau đó một số phương pháp phổ biến phục vụ như các đường cơ sở mạnh. 1) Gợi ý chuỗi suy nghĩ (Few-Shot CoT & Manual CoT) (Wei et al., 2022), 2) Zero-Shot CoT (Kojima et al., 2022), 3) Auto-CoT (Zhang et al., 2023b), 4) Gợi ý dựa trên độ phức tạp (ComplexCoT) (Fu et al., 2023). Chúng tôi cũng tích hợp Self-Consistency (SC) vào Manual CoT, ComplexCoT, và CoK của chúng tôi khi xác thực mô hình gpt-3.5-turbo. Số lượng đường dẫn lý luận được lấy mẫu là 10.

4.2 Hiệu suất cạnh tranh của CoK

Trước tiên chúng tôi đánh giá về lý luận thường thức và thực tế. Như được hiển thị trong Bảng 1, chúng tôi đưa ra các quan sát sau: 1) Gợi ý CoK liên tục vượt trội so với hiệu suất của các chiến lược CoT trước đây. Cụ thể, phương pháp của chúng tôi đạt được cải thiện lần lượt 1.9%, 1.2%, 0.9%, 1.5%, 0.8%, và 1.8% với text-davinvi-002, và đạt được cải thiện lần lượt 0.6%, 1.2%, 0.9%, 0.8%, 1.9%, và 2.8% với gpt-3.5-turbo. Điều này chứng minh rằng sự kết hợp của các bộ ba bằng chứng rõ ràng và giải thích có thể tăng cường khả năng lý luận của LLMs. Điều này cũng gợi ý rằng một định dạng kích thích tốt hơn là quan trọng đối với học dựa trên gợi ý. 2) Dựa trên F2-Verification, hiệu suất có thể được tăng cường thêm trên các nhiệm vụ. Đặc biệt, hiệu suất của CoK + F2-Verification gần như tiếp cận fine-tuning trên các nhiệm vụ StrategyQA và ARC-c. Điều này chỉ ra rằng việc tiến hành xác minh hậu kỳ và sửa chữa các bộ ba bằng chứng sai bằng cách tiêm tri thức đúng đắn là quan trọng đối với lý luận. 3) CoK liên tục vượt trội so với ComplexCoT, yêu cầu chi phí tính toán cao hơn nhiều so với chúng tôi, với một biên độ đáng kể.

Chúng tôi cũng khám phá cách gợi ý CoK có thể thích ứng với các nhiệm vụ không chuyên sâu về tri thức, chẳng hạn như lý luận ký hiệu và số học. Kết quả trong Bảng 1 gợi ý rằng gợi ý CoK cũng có thể tạo ra những cải thiện lớn trên các nhiệm vụ này, chỉ ra rằng việc phân hủy các chuỗi lý luận thành các bộ ba rõ ràng là hữu ích cho LLMs hiểu các nhiệm vụ phức tạp.

Cuối cùng, chúng tôi so sánh một số đường cơ sở tổng hợp với self-consistency (SC), và chúng tôi thấy 1) self-consistency có thể cải thiện đáng kể độ chính xác trên Manual CoT, ComplexCoT và CoK, 2) CoK + SC + F2-V đạt được hiệu suất tốt nhất trên hầu hết các nhiệm vụ, trong đó SC tăng cường lý luận bằng cách tập hợp tất cả các đường dẫn lý luận tại mỗi lần lặp suy nghĩ lại và F2-V tăng cường lý luận bằng cách tập hợp tất cả các lần lặp.

4.3 Thảo luận

Nghiên cứu loại bỏ. Trong phần này, chúng tôi nhằm khám phá mức độ đóng góp của mỗi phần thành phần vào hiệu suất. Chúng tôi thực hiện một nghiên cứu loại bỏ để xem hiệu suất thay đổi như thế nào.

--- TRANG 6 ---
[THIS IS TABLE: Table 1 showing accuracy results for text-davinci-002 and gpt-3.5-turbo models across various reasoning tasks including Commonsense & Factual, Symbolic, and Arithmetic categories. The table contains multiple rows comparing different methods like Fine-tuning, Zero-Shot SP, CoT, Manual CoT, Auto-CoT, CoK, and various combinations with Self-Consistency (SC) and F2-Verification (F2-V).]

Bảng 1: Độ chính xác của mô hình text-davinci-002 và gpt-3.5-turbo trên các nhiệm vụ lý luận thường thức, thực tế, ký hiệu và số học.

Chúng tôi tiến hành các thí nghiệm trên bốn nhiệm vụ, bao gồm CSQA, ARC-c, BoolQ, và Nối chữ cái cuối. Các thiết lập loại bỏ được hiển thị trong Phụ lục C.3. Kết quả trong Hình 3 chứng minh rằng hiệu suất giảm khi loại bỏ mỗi thành phần, cho thấy tầm quan trọng của tất cả các thành phần. Đối với CoK, chúng ta có thể thấy rằng hiệu suất của biến thể CoK w/o. ET thấp hơn CoK w/o. EH trên tất cả các nhiệm vụ, điều này gợi ý rằng việc thúc đẩy LLM tạo ra các bộ ba bằng chứng rõ ràng là đóng góp quan trọng nhất cho hiệu suất. Ngoài ra, cả bộ ba bằng chứng và gợi ý giải thích đều có thể được sử dụng đầy đủ trong quá trình suy nghĩ lại vì chúng có thể hướng dẫn LLM xác minh các chuỗi lý luận thông qua thực tế hoặc trung thực.

Tác động của các minh họa sai. Nhớ lại cuộc thảo luận trong Phần 3.2 về các minh họa có thể có một số sai lầm. Để xem liệu gợi ý chuỗi tri thức có hiện tượng tương tự như các công trình trước đây (Wang et al., 2023a) rằng không có mối liên hệ mạnh giữa tính hợp lệ của các chuỗi lý luận và hiệu suất của dự đoán mô hình.

Chúng tôi thực hiện thay thế ngẫu nhiên tiêu cực khi xây dựng ví dụ. Cụ thể, chúng tôi chọn β% bộ ba bằng chứng trong mỗi ví dụ trong ngữ cảnh và thay thế chúng ngẫu nhiên từ KB để tạo thành một đường dẫn lý luận sai. Chúng tôi chọn năm nhiệm vụ và vẽ một số biểu đồ cột trong Hình 4. Kết quả minh họa rằng tỷ lệ độ chính xác giảm nhẹ khi giá trị β tăng từ 0 đến 100. Tuy nhiên, ngay cả khi các bộ ba bằng chứng đều sai, hiệu suất sẽ không giảm đáng kể. Hiện tượng này mâu thuẫn với trực giác, tuy nhiên, phù hợp với tình huống dự kiến

--- TRANG 7 ---
[THIS IS FIGURE: Three bar charts showing performance comparisons across different tasks and methods - CSQA, ARC-c, BoolQ Letter, and other metrics]

Hình 3: Kết quả nghiên cứu loại bỏ: độ chính xác khi chúng tôi loại bỏ các thành phần khác nhau.

[THIS IS FIGURE: Bar chart showing effect of wrong demonstrations with different β% values]

Hình 4: Tác động của các minh họa sai với β% bộ ba bằng chứng sai.

mà chúng tôi đã xem xét trước đây.

Thích ứng miền của các minh họa. Để điều tra khả năng thích ứng của gợi ý CoK, đối với mỗi ví dụ, chúng tôi thay thế gợi ý bằng một ví dụ thay thế từ các miền khác. Cụ thể, chúng tôi chọn các nhiệm vụ CSQA, StrategyQA, OpenBookQA, và ARC-c từ lý luận thường thức, và đối với mỗi nhiệm vụ, chúng tôi chọn các minh họa từ nhiệm vụ GSM8K, rất khác với chúng.

Kết quả cho các thiết lập thích ứng miền được hiển thị trong Bảng 2. Chúng tôi thấy điều này thú vị vì LLM có thể dễ dàng biết cách tuân theo mô hình chuỗi tri thức để giải quyết một vấn đề mới, mặc dù gợi ý đã cho hoàn toàn không liên quan.

Hiệu quả của mô hình Để điều tra hiệu quả của CoK khi áp dụng các backbone khác nhau, chúng tôi chọn thêm gpt-4 để đánh giá CSQA và GSM8K. Như được hiển thị trong Hình 5, bằng cách so sánh với CoT và CoT+SC, CoK và CoK+SC đạt được cải thiện hiệu suất trung bình 1.6% trên text-davinci-002, 1.4% trên gpt-3.5-turbo và 1.0% trên gpt-4, chỉ ra rằng CoK có thể thích ứng với các LLMs khác nhau và hiệu quả tăng cường hiệu suất trên các backbone khác nhau.

Kỹ thuật gợi ý. Trong Hình 6, chúng tôi phân tích hiệu quả của các chiến lược kỹ thuật gợi ý khác nhau. "Manual" biểu thị xây dựng gợi ý thông qua chú thích của con người, trong khi "Auto" có nghĩa là sử dụng

[THIS IS TABLE: Table 2 showing domain adaptation results with percentages for different tasks]

Bảng 2: Kết quả thích ứng miền (%). #d có nghĩa là miền của các ví dụ, #d→#d có nghĩa là các ví dụ được lấy mẫu từ miền hiện tại, trong khi GSM8K →#d có nghĩa là nhiệm vụ hiện tại sử dụng các ví dụ GSM8K.

zero-shot CoT và KB để xây dựng gợi ý. Kết quả chứng minh rằng việc tận dụng zero-shot CoT với KB có thể giảm phương sai và cải thiện độ chính xác.

Đánh giá ảo giác. Để điều tra ảo giác, chúng tôi chọn các điểm trung thực fu(·) khác nhau để so sánh. Ngoài SimCSE, chúng tôi cũng chọn FactCC (Kryscinski et al., 2020) và Knowledge F1 (KF1) (Shuster et al., 2021). Như được hiển thị trong Hình 7, chúng tôi chọn tất cả các nhiệm vụ từ lý luận thường thức để đánh giá. Chúng tôi thấy rằng khung của chúng tôi có thể đạt được độ chính xác cao nhất trên hầu hết các nhiệm vụ khi sử dụng SimCSE làm điểm trung thực, điều này chỉ ra hiệu quả của việc giảm ảo giác.

Hiệu quả của quá trình suy nghĩ lại. Nhớ lại quá trình suy nghĩ lại, khi các chuỗi lý luận được tạo ra bởi LLMs không vượt qua được xác minh và điểm độ tin cậy thấp hơn ngưỡng θ, chúng tôi cung cấp cho chúng cơ hội bổ sung để tái tạo trong giai đoạn suy nghĩ lại.

Hình 8 chứng minh hiệu quả trên ba nhiệm vụ với các kết hợp khác nhau của số lần lặp suy nghĩ lại N∈ {1,2,3,4,5} và ngưỡng θ∈ {0,0.25,0.5,0.75,1.0}. Từ phân tích, chúng ta có thể rút ra một số gợi ý sau. 1) Trong hầu hết các trường hợp, độ chính xác tăng nhiều khi LLM suy nghĩ lại từng bước trong 3 lần lặp đầu tiên. 2) Quá trình suy nghĩ lại hội tụ nhanh hơn khi

--- TRANG 8 ---
[THIS IS FIGURE: Multiple charts showing comparison data and performance metrics]

Hình 5: So sánh CoT, CoT+SC, CoK, CoK+SC và CoK+SC+F2-V trên CSQA khi sử dụng backbone khác nhau.

Hình 6: Hiệu suất của gpt-3.5-turbo trên GSM8K với gợi ý khác nhau.

[THIS IS FIGURE: Bar chart showing hallucination evaluation results]

Hình 7: Đánh giá ảo giác của điểm trung thực fu(·) khác nhau.

[THIS IS FIGURE: Two line graphs showing effectiveness of different rethinking iterations]

Hình 8: Hiệu quả của số lần lặp suy nghĩ lại N và ngưỡng độ tin cậy θ khác nhau trên text-davinci-002.

sử dụng ngưỡng nhỏ hơn. Không khó hiểu rằng khi ngưỡng nhỏ, hầu như tất cả các truy vấn thử nghiệm sẽ được tiêm tri thức và tái tạo, tương tự như phương pháp kết hợp self-consistency và F2-Verification.

Thú vị là chúng tôi quan sát thấy rằng hiệu suất có thể giảm khoảng 2% khi θ <0.25, chúng tôi đổ lỗi cho vấn đề tiêm quá mức vì nó có thể tiêm một số thông tin không liên quan hoặc không nhất quán.

5 Kết luận

Chúng tôi đề xuất gợi ý chuỗi tri thức, nhằm phân hủy các chuỗi lý luận suy ra từ LLMs thành nhiều bộ ba bằng chứng và gợi ý giải thích, để cải thiện thêm khả năng lý luận. Dựa trên gợi ý chuỗi tri thức, chúng tôi giới thiệu F2-Verification và khai thác đầy đủ các cơ sở tri thức bên ngoài để thực hiện xác minh hậu kỳ cho các chuỗi lý luận được tạo ra về mặt thực tế và trung thực. Một quá trình suy nghĩ lại sau đó được sử dụng để tiêm tri thức nhằm sửa chữa các bộ ba bằng chứng sai và kích thích LLM tái tạo câu trả lời.

Kết quả mở rộng của chúng tôi cho thấy nó vượt trội so với các phương pháp gợi ý khác trên nhiều nhiệm vụ lý luận. Trong tương lai, chúng tôi sẽ 1) cải thiện thêm hiệu suất của các LLMs quy mô khác, 2) mở rộng KB sang các công cụ tìm kiếm để thực hiện xác minh thời gian thực, và 3) thực hiện phân tích khả năng diễn giải về lý luận của LLMs.

Hạn chế

Công trình của chúng tôi dựa trên các phương pháp gợi ý cho các mô hình ngôn ngữ lớn và đạt được hiệu suất xuất sắc trên nhiều điểm chuẩn. Tuy nhiên, nó vẫn mang những hạn chế sau: (1) Các bộ ba bằng chứng trong cơ sở tri thức là hữu hạn, có thể không đảm bảo phủ sóng toàn diện về yêu cầu của mô hình đối với tất cả các câu hỏi. (2) Do việc tích hợp thuật toán suy nghĩ lại, CoK có thể yêu cầu nhiều cuộc gọi API hơn so với các phương pháp CoT vanilla.

Tác động xã hội và Đạo đức

Về mặt tác động xã hội, các cơ sở tri thức chúng tôi sử dụng đều từ các nguồn dữ liệu có sẵn công khai. Việc truyền tri thức thực tế vào quá trình lý luận của mô hình sẽ không đưa ra thêm thiên lệch. Hơn nữa, nó có thể ở một mức độ nào đó ngăn chặn mô hình cung cấp các câu trả lời vô trách nhiệm và có hại.

Lời cảm ơn

Công trình này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Grant số 62202172, số 62377012, và số U1911203, và Chương trình chung của Ủy ban Khoa học và Công nghệ Thượng Hải số 22ZR1419900. Chúng tôi cảm ơn Nuo Chen về cuộc thảo luận và phản hồi có giá trị.

Tài liệu tham khảo

[Tài liệu tham khảo từ trang 9-13 - danh sách dài các công trình nghiên cứu được trích dẫn]

--- TRANG 14 ---
A Nghiên cứu trường hợp

Chúng tôi kết thúc phần này với một nghiên cứu trường hợp để thể hiện hiệu quả của gợi ý chuỗi tri thức được đề xuất và quá trình suy nghĩ lại với F2-Verification. Chúng tôi chọn ngẫu nhiên hai ví dụ từ CSQA và nhiệm vụ Nối chữ cái cuối, và kết quả được liệt kê trong Bảng 3.

Chúng ta có thể thấy rằng phương pháp được đề xuất của chúng tôi có thể hiệu quả tạo ra các bộ ba bằng chứng rõ ràng với các gợi ý giải thích tương ứng, và các bộ ba sai có thể được phát hiện thông qua F2-Verification được đề xuất. Trong quá trình suy nghĩ lại, LLM có thể được hướng dẫn với một gợi ý mới với tri thức được tiêm và sau đó đạt được câu trả lời chính xác.

Chúng tôi cũng thấy LLM có thể tự phát kiểm tra xem tri thức được tiêm có hữu ích cho việc giải quyết câu hỏi không (như được hiển thị trong Phụ lục D.1), điều này chỉ ra rằng phương pháp của chúng tôi có thể đạt được tiêm kỹ lưỡng và tránh tiêm tri thức vô dụng.

B Thống kê của các tập dữ liệu

Chúng tôi đánh giá CoK trên 12 tập dữ liệu điểm chuẩn có sẵn công khai bao gồm lý luận số học, lý luận thường thức, lý luận ký hiệu và các nhiệm vụ hiểu ngôn ngữ tự nhiên. Thống kê của các tập dữ liệu được hiển thị trong Bảng 4.

Thông tin chi tiết của mỗi tập dữ liệu được hiển thị như sau:

Lý luận thường thức & thực tế
• CSQA (Talmor et al., 2019): đây là một nhiệm vụ QA thường thức và định dạng câu trả lời là trả lời câu hỏi trắc nghiệm. Trang chủ là https://www.tau-nlp.org/commonsenseqa, và https://github.com/jonathanherzig/commonsenseqa.

[Tiếp tục với mô tả chi tiết các tập dữ liệu khác...]

--- TRANG 15-24 ---
[Phần còn lại của tài liệu bao gồm các chi tiết triển khai, ví dụ gợi ý, và các phụ lục kỹ thuật chi tiết...]

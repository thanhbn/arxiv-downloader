# 2304.09797.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl/2304.09797.pdf
# Kích thước tệp: 518330 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Progressive-Hint Prompting Cải thiện Lý luận
trong Mô hình Ngôn ngữ Lớn
Chuanyang Zheng1, Zhengying Liu2, Enze Xie3, Zhenguo Li4, Yu Li1
1CUHK,2Paris XI,3HKU,4HKUST
{cyzheng21}@cse.cuhk.edu.hk
https://github.com/chuanyang-Zheng/Progressive-Hint
Tóm tắt
Hiệu suất của Mô hình Ngôn ngữ Lớn (LLMs) trong các tác vụ lý luận phụ thuộc
nhiều vào thiết kế prompt, với Chain-of-Thought (CoT) và self-consistency
là những phương pháp quan trọng giúp tăng cường khả năng này. Tuy nhiên, những
phương pháp này không khai thác đầy đủ các câu trả lời được tạo ra bởi LLM để
hướng dẫn các phản hồi tiếp theo. Bài báo này đề xuất một phương pháp prompting
mới, được gọi là Progressive-Hint Prompting (PHP), cho phép tương tác tự động
nhiều lần giữa người dùng và LLMs bằng cách sử dụng các câu trả lời được tạo
trước đó làm gợi ý để dần dần hướng tới câu trả lời đúng. PHP trực giao với
CoT và self-consistency, giúp dễ dàng kết hợp với các kỹ thuật tiên tiến để
cải thiện hiệu suất hơn nữa. Chúng tôi đã thực hiện các thí nghiệm mở rộng và
toàn diện trên bảy benchmark. Kết quả cho thấy PHP cải thiện độ chính xác đáng
kể trong khi vẫn duy trì hiệu quả cao. Ví dụ, với text-davinci-003, chúng tôi
quan sát được cải thiện 4.2% trên GSM8K với greedy decoding so với Complex CoT,
và giảm 46.17% đường dẫn mẫu với self-consistency. Với GPT-4 và PHP, chúng tôi
đạt được hiệu suất tiên tiến trên SV AMP (89.1% →91.9%), GSM8K (92% →95.5%),
AQuA (76.4% →79.9%) và MATH (50.3% →53.9%).

1 Giới thiệu
Trong khi Mô hình Ngôn ngữ Lớn (LLMs) đã thể hiện hiệu suất xuất sắc trên các
tác vụ NLP khác nhau [1–3], khả năng lý luận của chúng thường được coi là một
hạn chế không thể khắc phục chỉ bằng việc tăng quy mô của mô hình [4,5]. Kỹ
thuật prompt engineering trong các mô hình quy mô lớn đã cho thấy hiệu suất
tương đương hoặc vượt trội so với fine-tuning toàn bộ tập huấn luyện trong việc
tăng cường khả năng lý luận, đồng thời cũng hiệu quả hơn nhiều về mặt mẫu [6,7].
Một lĩnh vực nghiên cứu nhằm giải quyết hạn chế này là việc sử dụng các phương
pháp Chain-of-Thought (CoT) để thúc đẩy các bước lý luận trung gian [8–10].
Các công trình khác trong lĩnh vực này, như Least-to-Most [9] và Complex CoT [10],
cũng đã khám phá hướng này. Một lĩnh vực nghiên cứu khác là các phương pháp
liên quan đến self-consistency. So với công trình liên quan đến CoT tập trung vào
thiết kế prompt tốt hơn, self-consistency đề xuất lấy mẫu nhiều câu trả lời từ
LLMs và đến câu trả lời đúng thông qua bỏ phiếu đa số [10]. Phương pháp này được
cải thiện thêm bằng complex-based selection [10]. Các công trình liên quan đến CoT
và self-consistency có thể được kết hợp một cách mượt mà mà không có xung đột nào.

Nghiên cứu trước đó chưa khám phá tiềm năng của việc tận dụng đầu ra của LLM để
tinh chỉnh các đường dẫn lý luận một cách lặp đi lặp lại. Có lý khi cho rằng tương
tự như nhận thức con người, LLM có thể được hưởng lợi từ việc đánh giá lại và điều
chỉnh các đường dẫn lý luận được tạo ra để sửa lỗi và tăng cường hiệu suất tổng thể.
Trong bài báo này, chúng tôi đề xuất một phương pháp mới được gọi là Progressive-Hint
Prompting (PHP) bao gồm việc tương tác tuần tự với LLM để tiếp cận câu trả lời đúng
một cách dần dần. Phương pháp hoạt động như sau: (1) cho một câu hỏi, chúng tôi yêu
cầu LLM cung cấp Câu trả lời Cơ bản; (2) chúng tôi kết hợp

Preprint. Under review.arXiv:2304.09797v6  [cs.CL]  7 Oct 2024

--- TRANG 2 ---
Câu hỏi: Có 96 học sinh lớp bốn tại Trường Small Tree. 43 em trong số đó là nữ. Vào thứ Sáu, 5 học sinh nữ lớp bốn và 4 học sinh nam lớp bốn đã vắng mặt. Có bao nhiêu học sinh nam lớp bốn có mặt tại Trường Small Tree vào thứ Sáu?

Đáp án: Có 96 học sinh lớp bốn tại Trường Small Tree. 43 em trong số đó là nữ. Vào thứ Sáu, 5 em nữ và 4 em nam đã vắng mặt. Vậy có 43 - 5 = 38 em nữ có mặt tại trường vào thứ Sáu, và 96 - 38 = 58 em nam có mặt tại trường vào thứ Sáu. Câu trả lời là 58.

Đáp án: Chúng ta biết Gợi ý Câu trả lời: 58. Với Gợi ý Câu trả lời: 58, chúng ta sẽ trả lời câu hỏi. Có 96 học sinh lớp bốn tại Trường Small Tree, và 43 em trong số đó là nữ. Vào thứ Sáu, 5 em nữ và 4 em nam đã vắng mặt. Vậy có 43 - 5 = 38 em nữ và 96 - 43 = 53 em nam tại Trường Small Tree vào thứ Sáu. Sau khi trừ đi những học sinh vắng mặt, có 38 - 4 = 34 em nữ và 53 - 5 = 48 em nam. Câu trả lời là 48.

Câu hỏi: Có 96 học sinh lớp bốn tại Trường Small Tree. 43 em trong số đó là nữ. Vào thứ Sáu, 5 học sinh nữ lớp bốn và 4 học sinh nam lớp bốn đã vắng mặt. Có bao nhiêu học sinh nam lớp bốn có mặt tại Trường Small Tree vào thứ Sáu? (Gợi ý: Câu trả lời gần với 58).

Đáp án: Chúng ta biết Gợi ý Câu trả lời: 58, 48. Với Gợi ý Câu trả lời: 58, 48, chúng ta sẽ trả lời câu hỏi. Có 96 học sinh lớp bốn, và 43 em trong số đó là nữ. Vào thứ Sáu, 5 em nữ và 4 em nam đã vắng mặt. Vậy có 43 - 5 = 38 em nữ và 96 - 9 = 87 học sinh tổng cộng. Trong số 87 học sinh đó, 38 em là nữ, vậy phải có 87 - 38 = 49 em nam. Câu trả lời là 49.

Câu hỏi: Có 96 học sinh lớp bốn tại Trường Small Tree. 43 em trong số đó là nữ. Vào thứ Sáu, 5 học sinh nữ lớp bốn và 4 học sinh nam lớp bốn đã vắng mặt. Có bao nhiêu học sinh nam lớp bốn có mặt tại Trường Small Tree vào thứ Sáu? (Gợi ý: Câu trả lời gần với 58, 48).

Đáp án: Chúng ta biết Gợi ý Câu trả lời: 58, 48, 49. Với Gợi ý Câu trả lời: 58, 48, 49, chúng ta sẽ trả lời câu hỏi. Có 96 học sinh lớp bốn tại Trường Small Tree, và 43 em trong số đó là nữ. Vào thứ Sáu, 5 em nữ và 4 em nam đã vắng mặt. Vậy có 43 - 5 = 38 em nữ và 96 - 43 = 53 em nam ban đầu. Sau khi vắng mặt, có 38 - 5 = 33 em nữ và 53 - 4 = 49 em nam. Câu trả lời là 49.

Câu hỏi: Có 96 học sinh lớp bốn tại Trường Small Tree. 43 em trong số đó là nữ. Vào thứ Sáu, 5 học sinh nữ lớp bốn và 4 học sinh nam lớp bốn đã vắng mặt. Có bao nhiêu học sinh nam lớp bốn có mặt tại Trường Small Tree vào thứ Sáu? (Gợi ý: Câu trả lời gần với 58, 48, 49).

Câu trả lời Cơ bản
Câu trả lời Thứ hai
Câu trả lời Thứ tư
Câu trả lời Thứ ba

LLM
LLM
LLM
LLM

Base Prompting
Progressive-Hint Prompting
Progressive-Hint Prompting
Progressive-Hint Prompting

Hình 1: Phương pháp Progressive-Hint Prompting đề xuất của chúng tôi kết hợp các câu trả lời được tạo ra và câu hỏi cho mục đích kiểm tra lại, được chia thành hai giai đoạn. Trong giai đoạn đầu, chúng tôi tạo ra một câu trả lời cơ bản bằng cách chuyển cho LLM một phép nối của câu hỏi hiện tại và một prompt cơ bản, như CoT hoặc Complex CoT. Trong giai đoạn thứ hai, chúng tôi tạo ra các câu trả lời tiếp theo thông qua prompt progressive-hint tương ứng, như Progressive-Hint Prompting CoT (PHP-CoT) hoặc Progressive-Hint Prompting Complex CoT (PHP-Complex CoT), cho tương tác tiếp theo. Tương tác dừng lại khi hai câu trả lời liên tiếp giống nhau. Hộp màu tím: Đầu vào của LLM. Hộp màu cam: Đầu ra của LLM.

câu hỏi và câu trả lời để hỏi lại LLM và có được Câu trả lời Tiếp theo; (3) chúng tôi lặp lại thao tác trong (2) cho đến khi câu trả lời ổn định và không thay đổi trong hai câu trả lời cuối cùng. PHP tuân theo một quy trình suy nghĩ giống con người trong đó các câu trả lời trước đó được tận dụng làm gợi ý để đến câu trả lời đúng sau khi đánh giá lại câu hỏi.

Hình 1 minh họa khung làm việc PHP được đề xuất. Chúng tôi sử dụng prompt cơ bản để có được câu trả lời cơ bản ban đầu, và sau đó sử dụng prompt PHP cho các câu hỏi tiếp theo. Nếu câu trả lời hiện tại khớp với câu trả lời trước đó, nó có khả năng đúng cao hơn, và chúng tôi kết thúc việc hỏi LLM. Với Complex CoT và GPT-4, sau khi thêm PHP, hiệu suất đạt SOTA với 91.9% trên SV AMP [11], 95.5% trên GSM8K [12], và 79.9% trên AQuA [13] và 53.9% trên MATH [14].

Tóm lại, những đóng góp của chúng tôi như sau:
• Chúng tôi đề xuất một phương pháp mới, Progressive-Hint Prompting (PHP), cùng với CoT và self-consistency, để cải thiện khả năng lý luận của LLM.
• Chúng tôi chứng minh hiệu quả của PHP thông qua thí nghiệm mở rộng, bao gồm so sánh baseline và nghiên cứu ablation, sử dụng bốn LLMs, text-davinci-002 và text-davinci-003, GPT-3.5-Turbo và GPT-4 [15–17].
• Kết quả thí nghiệm cho thấy phương pháp của chúng tôi cũng có thể cải thiện hiệu suất với self-consistency.
• Chúng tôi tin rằng progressive-hint prompting đại diện cho một bước quan trọng hướng tới tương tác tuần tự tự động với LLMs và hy vọng nó sẽ truyền cảm hứng cho nghiên cứu tương lai trong lĩnh vực này.

2 Công trình Liên quan

Khả năng Xuất hiện và Lý luận Đa bước. LLMs đặc biệt thành thạo trong in-context learning, bao gồm việc tuân thủ cấu trúc của prompts (thường là few-shot) và hoàn thành các

--- TRANG 3 ---
tác vụ tương ứng [15,18–20]. Trong số các tác vụ hiểu ngôn ngữ đa dạng, chúng tôi đặc biệt quan tâm đến lý luận đa bước vì nó thể hiện hai đặc điểm độc đáo. Thứ nhất, LLMs vượt trội đáng kể so với các mô hình nhỏ hơn trong các tác vụ lý luận đa bước [8], trong khi lợi ích hiệu suất của chúng trong các tác vụ như phân loại cảm xúc có thể bị hạn chế [19]. Thứ hai, few-shot prompting vượt trội hơn fine-tuning toàn bộ tập huấn luyện trong các tác vụ lý luận đa bước, ngay cả khi được thực hiện trên LLMs [7].

Lý luận Chain-of-Thought. Chain-of-thought (CoT) prompting [8] là một công trình nổi bật thể hiện khả năng lý luận đa bước của LLMs. Phương pháp này gợi ý rằng khả năng lý luận có thể được gợi ra thông qua một chuỗi suy nghĩ, trong đó một câu trả lời trực tiếp theo sau một câu hỏi mà không có các bước lý luận trung gian. Least-to-Most prompting [9], theo cùng hướng nghiên cứu, chia lý luận thành các phần phân tích vấn đề và các phần trả lời vấn đề và mô tả các bước lý luận chi tiết hơn. Tương tự, complex CoT [10] nhấn mạnh tầm quan trọng của độ phức tạp prompt và chọn những câu hỏi phức tạp nhất và câu trả lời của chúng làm prompts. Để giảm khối lượng công việc của con người, Auto-CoT được đề xuất [21]. Các công trình khác đã phát hiện rằng việc sử dụng các cụm từ cụ thể như "Let's think step by step" [6] có thể cải thiện hiệu suất.

Trích xuất Đường dẫn Lý luận. Nghiên cứu trước đó đã điều tra các phương pháp cụ thể cho từng tác vụ để xác định đường dẫn lý luận, bao gồm xây dựng đồ thị ngữ nghĩa [22], phát triển các mô hình Mạng Nơ-ron Hồi quy (RNN) để truy xuất đường dẫn lý luận từ đồ thị Wikipedia [23], sử dụng đường dẫn lý luận được chú thích bởi con người trên các bài toán toán học để fine-tuning [12], hoặc huấn luyện một bộ trích xuất với đường dẫn lý luận giả dựa trên heuristic [24]. Một nghiên cứu mới, được gọi là Self-Consistency [25], kết hợp việc tạo ra đường dẫn lý luận và câu trả lời cuối cùng bằng cách lấy mẫu từ decoder và sử dụng tổng hợp để truy xuất câu trả lời nhất quán nhất mà không cần các module bổ sung. Phương pháp này đã cho thấy tiềm năng to lớn, và có khả năng vượt trội hơn các phương pháp hiện có về độ chính xác. Hơn nữa, vote complex [10], xếp hạng và chọn mẫu thông qua độ phức tạp, được đề xuất để cải thiện hiệu suất self-consistency. Phương pháp này đặc biệt hữu ích khi xử lý các vấn đề lý luận phức tạp.

3 Progressive-Hint Prompting

Bảng 1: Minh họa Progressive-Hint Prompting. Màu xanh: Sự khác biệt giữa Base CoT và PHP-CoT. Màu đỏ: Gợi ý thủ công trong prompt được thiết kế.

Base Prompting (ví dụ CoT)
Câu hỏi: Có 15 cây trong lùm cây. Các công nhân sẽ trồng cây trong lùm cây hôm nay. Sau khi họ hoàn thành, sẽ có 21 cây. Các công nhân đã trồng bao nhiêu cây hôm nay?
Đáp án: Ban đầu có 15 cây. Sau đó có 21 cây sau khi các công nhân trồng thêm một số cây. Vậy phải có 21 - 15 = 6 cây đã được trồng. Câu trả lời là 6.

Progressive-Hint Prompting 1: Gợi ý là câu trả lời đúng
Câu hỏi: Có 15 cây trong lùm cây. Các công nhân sẽ trồng cây trong lùm cây hôm nay. Sau khi họ hoàn thành, sẽ có 21 cây. Các công nhân đã trồng bao nhiêu cây hôm nay? (Gợi ý: Câu trả lời gần với 6).
Đáp án: Chúng ta biết Gợi ý Câu trả lời: 6. Với Gợi ý Câu trả lời: 6, chúng ta sẽ trả lời câu hỏi. Ban đầu có 15 cây. Sau đó có 21 cây sau khi các công nhân trồng thêm một số cây. Vậy phải có 21 - 15 = 6 cây đã được trồng. Câu trả lời là 6.

Progressive-Hint Prompting 2: Gợi ý là câu trả lời sai
Câu hỏi: Có 15 cây trong lùm cây. Các công nhân sẽ trồng cây trong lùm cây hôm nay. Sau khi họ hoàn thành, sẽ có 21 cây. Các công nhân đã trồng bao nhiêu cây hôm nay? (Gợi ý: Câu trả lời gần với 10, 8).
Đáp án: Chúng ta biết Gợi ý Câu trả lời: 10, 8. Với Gợi ý Câu trả lời: 10, 8, chúng ta sẽ trả lời câu hỏi. Ban đầu có 15 cây. Sau đó có 21 cây sau khi các công nhân trồng thêm một số cây. Vậy phải có 21 - 15 = 6 cây đã được trồng. Câu trả lời là 6.

Một khía cạnh nổi bật của nhân loại là khả năng không chỉ suy nghĩ một lần, mà còn kiểm tra lại câu trả lời của chúng ta. Trong bài báo này, chúng tôi đề xuất rằng quá trình này có thể được mô phỏng trong các mô hình ngôn ngữ bằng cách sử dụng tuần tự các câu trả lời trước đó. Nói cách khác, một mô hình có thể tạo ra một câu trả lời và sau đó

--- TRANG 4 ---
kết hợp nó với câu hỏi cho vòng suy nghĩ tiếp theo. Nếu câu trả lời hiện tại giống với câu trả lời trước đó, chúng ta có thể tin tưởng rằng câu trả lời hiện tại là đúng.

Chúng tôi đã trình bày Tương tác Đề xuất trong Hình 1 và Thiết kế Prompt trong Bảng 1. Chúng tôi thể hiện quá trình tạo ra prompts PHP-CoT cho một prompt CoT đã cho trong Bảng 1 và cung cấp prompt hoàn chỉnh trong Phụ lục. Pipeline của chúng tôi được chia thành hai giai đoạn: (i) câu trả lời cơ bản & prompt cơ bản: việc tạo ra câu trả lời cơ bản thông qua các prompt cơ bản như CoT hoặc Complex CoT và (ii) câu trả lời tiếp theo & PHP: tương tác tiếp theo với LLMs thông qua các prompt progressive-hint tương ứng như Progressive-Hint Prompting CoT (PHP-CoT) hoặc Progressive-Hint Prompting Complex CoT (PHP-Complex CoT). Chúng tôi đề xuất một cấu trúc hai câu cho PHP, bao gồm một cụm từ chỉ ra sự gần gũi của câu trả lời ở phần câu hỏi tiếp theo là một câu nhắc lại gợi ý ở phần câu trả lời. Ví dụ, để tạo một prompt PHP từ một prompt CoT, đầu tiên chúng tôi thêm cụm từ "Câu trả lời gần với A1, ..., Ap" sau câu hỏi ban đầu, trong đó A1, ..., Ap đại diện cho các câu trả lời có thể. Tiếp theo, chúng tôi giới thiệu các gợi ý trong câu bắt đầu của các câu trả lời tiềm năng: "Chúng ta biết Gợi ý Câu trả lời: A1, ..., Ap. Với Gợi ý Câu trả lời: A1, ..., Ap, chúng ta sẽ trả lời câu hỏi.".

Nguyên tắc Thiết kế PHP: chúng ta nên xem xét các tình huống khác nhau của gợi ý. Khi chúng ta hỏi LLM câu hỏi, chúng ta không biết câu trả lời sẽ là gì nên các gợi ý là không xác định. Trong thiết kế prompt này, chúng tôi xem xét hai tình huống tiềm năng sau: 1) Các gợi ý giống với câu trả lời đúng: để đảm bảo rằng mô hình vẫn có thể có được câu trả lời đúng khi gợi ý đúng; 2) gợi ý không giống với câu trả lời đúng: để đảm bảo rằng mô hình có thể thoát khỏi câu trả lời sai.

Tuân thủ các hướng dẫn trên, chúng tôi sử dụng prompt Standard, prompt CoT, và prompt Complex CoT để tạo ra các câu trả lời cơ bản ban đầu, từ đó chúng tôi có thể phát triển các prompt tạo câu trả lời tiếp theo, cụ thể là prompt PHP-Standard, prompt PHP-CoT, và prompt PHP-Complex CoT. Tiêu chí dừng trong PHP được đạt khi hai phản hồi liên tiếp giống hệt nhau, báo hiệu kết thúc trao đổi tương tác.

Nhìn chung, phương pháp này đại diện cho một pipeline để cải thiện chất lượng phản hồi và tăng cường giao tiếp trong các kịch bản hỏi-đáp.

4 Thí nghiệm

Tập dữ liệu và Mô hình. Chúng tôi đánh giá PHP trên bảy tập dữ liệu (AddSub [26], MultiArith [27], SingleEQ [28], SV AMP [11], GSM8K [12], AQuA [13]) và MATH [14]. Chúng tôi chọn các tập dữ liệu này vì chúng tôi tập trung vào khả năng lý luận của mô hình. Các prompt được sử dụng cho cả prompt Standard và CoT được lấy từ bài báo CoT gốc [8], trong khi prompt được sử dụng cho prompt Complex CoT [10] được lấy từ ấn phẩm Complex CoT tương ứng. Ngoài ra, để xác thực hiệu suất phương pháp đề xuất của chúng tôi, chúng tôi sử dụng bốn mô hình: text-davinci-002 và text-davinci-003, GPT-3.5-Turbo và GPT-4 [15–17]. Tất cả các mô hình được sử dụng thông qua API key của OpenAI.

Prompts. Chúng tôi đã trình bày pipeline quy trình đề xuất trong phần Phương pháp. Chúng tôi hiển thị tất cả các prompts trong Phụ lục và tài liệu bổ sung.

4.1 Kết quả Chính

Kết quả chính của nghiên cứu được trình bày trong Bảng 2, với tất cả các phương pháp sử dụng greedy decoding (tức nhiệt độ = 0). Các phát hiện của chúng tôi chỉ ra rằng PHP đề xuất cải thiện hiệu suất, đặc biệt khi làm việc với các prompt và mô hình mạnh mẽ.

PHP hoạt động tốt hơn khi LLM mạnh hơn. Về sức mạnh mô hình, phân tích của chúng tôi chỉ ra rằng PHP hiệu quả nhất khi được áp dụng với các mô hình mạnh mẽ. Cụ thể, khi kiểm tra các prompt CoT và Complex CoT, chúng tôi phát hiện rằng trong khi text-davinci-002 thường mang lại cải thiện hiệu suất sau khi thêm gợi ý, có những lúc hiệu suất sẽ giảm. Tuy nhiên, khi chúng tôi thay thế text-davinci-002 bằng text-davinci-003, cải thiện hiệu suất trở nên nhất quán và đáng kể hơn. Ví dụ, PHP-Complex CoT sử dụng text-davinci-002 cải thiện hiệu suất 3.6%, nhưng sau đó tăng thêm lên 4.6% với text-davinci-003. Tương tự, trên tập dữ liệu AQuA, việc sử dụng PHP-Complex CoT dẫn đến giảm hiệu suất 0.4% với text-davinci-002 nhưng cải thiện 1.2% với text-davinci-003. Text-davinci-002 được fine-tune với supervised instruction tuning, trong khi text-davinci-003 được fine-tune với reinforcement learning. Hiệu suất được cải thiện

--- TRANG 5 ---
Bảng 2: PHP, khi được áp dụng cho các LLMs và phương pháp prompting khác nhau, có thể giúp cải thiện hiệu suất. Đồng thời, PHP hoạt động tốt hơn khi mô hình và prompt mạnh hơn. Kết quả được thực hiện với greedy decoding.

[Bảng hiển thị kết quả so sánh hiệu suất của các phương pháp khác nhau trên nhiều tập dữ liệu]

Hình 2: Số Tương tác đề cập đến tần suất mà chúng ta cần tham khảo ý kiến LLM cho đến khi nhận được phản hồi kết luận. Với phân tích các mô hình và prompt khác nhau, đã quan sát thấy rằng: 1) Một mô hình mạnh hơn dẫn đến số tương tác giảm; 2) Một prompt được cải thiện dẫn đến số tương tác tăng.

với text-davinci-003 có thể được quy cho sức mạnh tăng cường của nó, khiến nó hiểu và sử dụng gợi ý được đưa ra tốt hơn.

PHP hoạt động tốt hơn khi prompt mạnh hơn. Sau khi phân tích dữ liệu của chúng tôi, được xác định rằng sức mạnh của prompt có tác động đáng kể đến hiệu suất của hệ thống. Kết quả thí nghiệm của chúng tôi tiết lộ rằng trong khi việc bao gồm PHP tạo ra những cải thiện khiêm tốn với các prompt tiêu chuẩn, các prompt CoT và Complex CoT thể hiện những lợi ích hiệu suất đáng kể. Đặc biệt đáng chú ý là thực tế rằng prompt mạnh nhất, Complex CoT, thể hiện cải thiện hiệu suất đáng kể nhất so với prompt Standard và prompt CoT. Phát hiện này cung cấp bằng chứng thuyết phục rằng một prompt tốt hơn dẫn đến hiệu quả cao hơn của hệ thống.

Số Tương tác giảm khi mô hình mạnh hơn và prompt ít mạnh hơn. Số tương tác đề cập đến số lần agent tương tác với LLMs. Số tương tác là một khi agent nhận được câu trả lời đầu tiên và tăng lên hai cho câu trả lời thứ hai. Trong Hình 2, chúng tôi minh họa số tương tác của các mô hình và prompt khác nhau. Các phát hiện của chúng tôi chỉ ra rằng: 1) Số tương tác cho text-davinci-003 thường thấp hơn so với text-davinci-002 khi được đưa ra cùng một prompt. Điều này chủ yếu do độ chính xác cao hơn của text-davinci-003, dẫn đến xác suất cao hơn về việc câu trả lời cơ bản và các câu trả lời tiếp theo đúng, do đó đòi hỏi ít tương tác hơn để có được câu trả lời đúng cuối cùng; 2) Khi sử dụng cùng mô hình, số tương tác thường tăng khi prompt trở nên mạnh mẽ hơn. Điều này là do LLMs đạt được khả năng lý luận tốt hơn khi prompt trở nên mạnh mẽ hơn, cho phép chúng tận dụng gợi ý để thoát khỏi các câu trả lời sai, và cuối cùng dẫn đến số tương tác cao hơn cần thiết để đạt được câu trả lời cuối cùng.

--- TRANG 6 ---
4.2 Tác động của Chất lượng Gợi ý

Bảng 3: Hiệu suất với các Câu trả lời Cơ bản khác nhau. Ban đầu, prompt cơ bản cung cấp câu trả lời cơ bản cho mô hình và PHP tạo ra các câu trả lời tiếp theo. Kết quả từ text-davinci-003 với greedy decoding.

[Bảng hiển thị kết quả so sánh hiệu suất với các prompt cơ bản khác nhau]

Chất lượng của gợi ý ảnh hưởng đáng kể đến hiệu suất. Được hiển thị trong Bảng 3, để tăng cường PHP-Standard, việc thay thế prompt cơ bản Standard bằng Complex CoT hoặc CoT dẫn đến cải thiện đáng kể trong hiệu suất cuối cùng. Đối với PHP-Standard, chúng tôi quan sát rằng hiệu suất GSM8K tăng từ 16.0% với prompt cơ bản Standard lên 50.2% với prompt cơ bản CoT và 60.3% với prompt cơ bản Complex CoT. Ngược lại, việc thay thế prompt cơ bản Complex CoT bằng Standard sẽ giảm hiệu suất cuối cùng. Ví dụ, sau khi thay thế prompt cơ bản Complex CoT bằng Standard, hiệu suất của PHP-Complex CoT giảm từ 71.6% xuống 65.5% trên tập dữ liệu GSM8K.

Hiệu suất có thể được cải thiện thêm nếu PHP không được thiết kế từ prompt cơ bản tương ứng. Kết quả chỉ ra rằng CoT với PHP-Complex CoT đạt được tỷ lệ chính xác cao 96.8% trên tập dữ liệu MultiArith, vượt trội so với hiệu suất của CoT với PHP-CoT. Tương tự, Complex CoT với PHP-CoT thể hiện tỷ lệ chính xác đáng chú ý 95.6% trên cùng tập dữ liệu, vượt trội so với Complex CoT với PHP-Complex CoT. Lý do đằng sau những phát hiện này là hai mặt: 1) hiệu suất của CoT và Complex CoT tương tự trên tất cả sáu tập dữ liệu, và 2) vì Câu trả lời Cơ bản được cung cấp bởi CoT (hoặc Complex CoT) và câu trả lời tiếp theo dựa trên PHP-Complex CoT (hoặc PHP-CoT), nó có thể so sánh với việc có hai cá nhân hợp tác để giải quyết một vấn đề. Do đó, trong những hoàn cảnh như vậy, hiệu suất của hệ thống có thể được tăng cường thêm.

4.3 Nghiên cứu Ablation

Hơn nữa, chúng tôi đã thực hiện một nghiên cứu ablation để xác minh tính quan trọng của hai câu trong câu trả lời: 1) P1: Chúng ta biết Gợi ý Câu trả lời A1, ..., Ap; 2) P2: Với Gợi ý Câu trả lời A1, ..., Ap, chúng ta sẽ trả lời câu hỏi. Hơn nữa, chúng tôi giới thiệu một loại prompt mới gọi là CoT-Merge và Complex CoT-Merge. Đầu tiên, chúng tôi kết hợp prompt gốc với prompt PHP thành một tệp duy nhất. Sau đó, chúng tôi sử dụng cùng Merge Prompt cho cả câu trả lời cơ bản và câu trả lời tiếp theo. Ngoài ra, chúng tôi chứng minh rằng cả gợi ý đúng và sai đều cần thiết trong thiết kế prompt.

P1 và P2 được đề xuất là cần thiết. Việc kết hợp các câu P1 và P2 dẫn đến hiệu suất tốt hơn cho CoT với PHP trên ba trong số sáu tập dữ liệu. Tuy nhiên, tầm quan trọng của hai câu này trở nên đặc biệt rõ ràng khi chúng tôi sử dụng Complex CoT. Với phương pháp này, hiệu suất tốt hơn đã đạt được trên năm trong số sáu tập dữ liệu sau khi thêm P1 và P2. Ví dụ, Complex CoT cải thiện hiệu suất từ 78.0% lên 80.0% trên tập dữ liệu SV AMP, và từ 68.3% lên 71.6% trên tập dữ liệu GSM8K. Điều này nhấn mạnh rằng các câu P1 và P2 có thể thể hiện khả năng mạnh mẽ hơn, đặc biệt khi khả năng logic của mô hình vượt trội. Do đó, chúng ta có thể kết luận rằng P1 và P2 có khả năng sẽ tăng cường hiệu suất mô hình ở mức độ lớn hơn, đặc biệt với các prompt và mô hình mạnh mẽ hơn.

PHP không dựa trên merge tốt hơn PHP dựa trên merge khi prompt mạnh hơn. Đối với CoT với PHP-CoT, câu trả lời ban đầu được lấy từ prompt CoT, và sau đó,

--- TRANG 7 ---
Bảng 4: Nghiên cứu Ablation. CoT-Merge: cho prompt cơ bản CoT và prompt PHP-CoT, chúng tôi sử dụng prompt chứa cả prompt cơ bản và PHP. P1: Chúng ta biết Gợi ý Câu trả lời A1, ..., Ap. P2: Với Gợi ý Câu trả lời A1, ..., Ap, chúng ta sẽ trả lời câu hỏi. Theo kết quả thí nghiệm, chúng ta thấy rằng cả P1 và P2 đề xuất đều cần thiết. Đồng thời, phương pháp không dựa trên merge tốt hơn phương pháp dựa trên merge khi prompt mạnh hơn. Kết quả từ text-davinci-003 với greedy decoding.

[Bảng hiển thị kết quả ablation study với các cấu hình khác nhau]

Bảng 5: Phân tích Thiết kế Gợi ý (Được hiển thị trong Hình 1). Đúng: Các gợi ý của prompt được thiết kế giống với câu trả lời đúng. Sai: Các gợi ý của prompt được thiết kế là câu trả lời sai. Xanh lá: Hiệu suất tốt hơn so với không có progressive-hint. Đỏ: Hiệu suất tệ hơn so với không có progressive-hint. Kết quả từ text-davinci-003 với greedy decoding.

[Bảng hiển thị phân tích thiết kế gợi ý]

câu trả lời được thu được từ PHP-CoT. Đáng chú ý, so với các phương pháp dựa trên CoT khác, CoT-Merge đạt được hiệu suất tốt nhất. Tuy nhiên, so với các phương pháp dựa trên Complex CoT khác, chúng tôi quan sát rằng PHP-Complex CoT không dựa trên merge với cả P1 và P2 đạt được hiệu suất tốt nhất. Do đó, khi prompt tốt hơn, hiệu suất của phương pháp không dựa trên merge sẽ tốt hơn phương pháp dựa trên merge.

Cả gợi ý đúng và sai đều cần thiết trong thiết kế prompt. Bảng 5 chứng minh rằng việc sử dụng PHP vượt trội hơn so với việc không sử dụng nó khi prompt được thiết kế bao gồm cả gợi ý đúng và sai. Cụ thể, việc cung cấp gợi ý đúng trong prompt thúc đẩy việc tạo ra câu trả lời khớp với gợi ý đã cho. Ngược lại, việc cung cấp câu trả lời sai trong prompt khuyến khích việc tạo ra câu trả lời thay thế, với sự hỗ trợ của gợi ý đã cho.

4.4 Hiệu suất với Self-Consistency

Như chúng tôi đã thảo luận trước đây, phương pháp đề xuất của chúng tôi có thể kết hợp với CoT và self-consistency để cải thiện thêm hiệu suất mô hình. Kết quả được hiển thị trong Bảng 6. Theo bài báo self-consistency, chúng tôi lấy mẫu đường dẫn với số 5, 10, 20 và 40, và nhiệt độ mô hình 0.7.

PHP cải thiện thêm hiệu suất. Bằng cách sử dụng các prompt tương tự và số đường dẫn mẫu, chúng tôi phát hiện ra rằng PHP-CoT và PHP-Complex CoT đề xuất của chúng tôi luôn đạt được hiệu suất vượt trội khi so sánh với CoT và Complex CoT, được hiển thị trong Bảng 6 và Hình 3. Ví dụ, CoT với self-consistency có thể đạt được độ chính xác 96.5% trên tập dữ liệu MultiArith với đường dẫn mẫu 10, 20 và 40. Do đó, chúng ta có thể kết luận rằng hiệu suất tốt nhất của CoT với self-consistency là 96.5% với text-davinci-003. Tuy nhiên, sau khi triển khai PHP, hiệu suất tăng vọt lên

--- TRANG 8 ---
Bảng 6: Kết quả sau khi thêm Self-Consistency (SC). Số: Số tương tác giữa agent và LLM. Kết quả tốt nhất của việc thêm PHP được đánh dấu bằng màu đỏ, và kết quả tốt nhất không có PHP được đánh dấu bằng màu xanh lá. Chúng tôi thấy rằng PHP cải thiện thêm hiệu suất, ngay cả khi thêm self-consistency. Đồng thời, PHP có thể giảm chi phí của self-consistency.

[Bảng hiển thị kết quả với Self-Consistency]

Hình 3: Chúng tôi hiển thị kết quả: 1) CoT của MultiArith; 2) CoT của SV AMP; 3) Complex CoT của GSM8K. Theo 1) và 2), chúng ta có thể thấy rằng PHP có thể cải thiện thêm hiệu suất. Với kết quả 3), chúng tôi phát hiện rằng PHP thậm chí có thể giảm chi phí của self-consistency.

97.1%. Tương tự, chúng tôi quan sát CoT với self-consistency trên SV AMP, đạt được độ chính xác tốt nhất 83.3% với 20 đường dẫn được lấy mẫu, và được cải thiện thêm lên 83.7% khi triển khai PHP. Điều này minh họa rằng PHP có thể phá vỡ rào cản hiệu suất và cải thiện thêm hiệu suất.

PHP có thể giảm chi phí của self-consistency. Việc kết hợp PHP cũng có thể dẫn đến giảm chi phí. Được thừa nhận rộng rãi rằng self-consistency bao gồm số lượng đường dẫn lý luận tăng, dẫn đến chi phí cao hơn. Bảng 6 minh họa rằng PHP có thể là một phương pháp hiệu quả để giảm chi phí này, trong khi vẫn duy trì lợi ích hiệu suất. Như được hiển thị trong Hình 3, sử dụng Complex CoT với self-consistency, độ chính xác 78.1% có thể đạt được với 40 đường dẫn mẫu, trong khi việc kết hợp PHP giảm lượng mẫu cần thiết xuống 10 × 2.1531 = 21.531 đường dẫn, và dẫn đến độ chính xác thậm chí tốt hơn là 78.2%.

4.5 Hiệu suất với Chat Model

Trong phần trước, chúng tôi tuân theo cài đặt công trình trước đây và sử dụng các mô hình tạo văn bản cho thí nghiệm của chúng tôi. Với việc phát hành API của GPT-3.5-Turbo và GPT-4, chúng tôi xác thực hiệu suất của

--- TRANG 9 ---
Bảng 7: Hiệu suất của Complex CoT với GPT-3.5-Turbo và GPT-4, sử dụng greedy decoding. Số: Số tương tác trung bình với LLM.

[Bảng hiển thị kết quả hiệu suất với chat models]

Bảng 8: Hiệu suất của Complex CoT với GPT-3.5-Turbo và GPT-4 trên tập dữ liệu MATH, sử dụng greedy decoding. Số: Số tương tác trung bình với LLM. Tổng thể: Kết quả tổng thể các chủ đề phụ MATH [14].

[Bảng hiển thị kết quả trên tập dữ liệu MATH]

Complex CoT với PHP trên cùng sáu tập dữ liệu. Chúng tôi sử dụng greedy decoding (tức nhiệt độ = 0) và Complex CoT làm prompt cho cả hai mô hình.

Phân tích GPT-3.5-Turbo. Như được mô tả trong Bảng 7, PHP được đề xuất tăng cường hiệu suất, cải thiện 2.3% trên GSM8K và 3.2% trên AQuA. Tuy nhiên, GPT-3.5-Turbo thể hiện khả năng tuân thủ prompt giảm so với text-davinci-003. Chúng tôi cung cấp hai ví dụ để minh họa điểm này: a) Trong các trường hợp mà các gợi ý đã cho vắng mặt, GPT-3.5-Turbo không trả lời câu hỏi và phản hồi bằng một tuyên bố như, "Chúng tôi không thể trả lời câu hỏi này vì gợi ý câu trả lời bị thiếu. Vui lòng cung cấp gợi ý câu trả lời để tiếp tục.". Ngược lại, text-davinci-003 tự động tạo ra và điền vào gợi ý câu trả lời bị thiếu trước khi giải quyết câu hỏi (như được thể hiện trong Phụ lục); b) Khi hơn mười gợi ý được cung cấp, GPT-3.5-Turbo có thể phản hồi với "Chúng tôi không thể xác định câu trả lời đúng vì nhiều gợi ý câu trả lời được đưa ra. Vui lòng chỉ cung cấp một gợi ý câu trả lời cho câu hỏi.".

Phân tích GPT-4. Sau khi triển khai mô hình GPT-4, chúng tôi có thể đạt được hiệu suất SOTA mới trên các benchmark SV AMP, GSM8K, AQuA và MATH. Phương pháp PHP đề xuất của chúng tôi liên tục cải thiện hiệu suất của GPT-4. Hơn nữa, so với mô hình GPT-3.5-Turbo, chúng tôi quan sát thấy sự giảm trong số tương tác cần thiết bởi GPT-4, điều này phù hợp với phát hiện rằng "Số Tương tác giảm khi mô hình mạnh hơn."

5 Kết luận

Bài báo này giới thiệu một phương pháp mới được gọi là Progressive-Hint Prompting (PHP) để tương tác với LLMs, cung cấp nhiều lợi thế: 1) PHP đạt được cải thiện hiệu suất đáng kể trong các tác vụ lý luận toán học, dẫn đến kết quả tiên tiến trên một số benchmark lý luận; 2) với các mô hình và prompt mạnh mẽ hơn, PHP có thể mang lại lợi ích tốt hơn và nhất quán cho LLMs; 3) PHP có thể dễ dàng kết hợp với CoT và self-consistency để cải thiện thêm hiệu suất.

Để tăng cường hơn nữa phương pháp progressive-hint prompting, các nỗ lực nghiên cứu tương lai có thể tập trung vào cải thiện thiết kế của các gợi ý thủ công trong giai đoạn câu hỏi và các câu prompt trong

--- TRANG 10 ---
phần câu trả lời. Ngoài ra, các gợi ý mới giúp LLMs xem xét lại các câu hỏi có thể được xác định và trích xuất bên cạnh câu trả lời.

Tài liệu tham khảo
[1]Daniel W Otter, Julian R Medina, và Jugal K Kalita. Một khảo sát về việc sử dụng deep learning cho xử lý ngôn ngữ tự nhiên. IEEE transactions on neural networks and learning systems, 32(2):604–624, 2020. 1

[2]Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, và Xuanjing Huang. Các mô hình được huấn luyện trước cho xử lý ngôn ngữ tự nhiên: Một khảo sát. Science China Technological Sciences, 63(10):1872–1897, 2020.

[3]KR1442 Chowdhary và KR Chowdhary. Xử lý ngôn ngữ tự nhiên. Fundamentals of artificial intelligence, pages 603–649, 2020. 1

[4]Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Mở rộng quy mô mô hình ngôn ngữ: Phương pháp, phân tích & thông tin chi tiết từ việc huấn luyện gopher. arXiv preprint arXiv:2112.11446, 2021. 1

[5]Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. Vượt ra ngoài trò chơi bắt chước: Định lượng và ngoại suy các khả năng của mô hình ngôn ngữ. arXiv preprint arXiv:2206.04615, 2022. 1

[6]Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. Mô hình ngôn ngữ lớn là những người lý luận zero-shot. In Advances in Neural Information Processing Systems, 2022. 1, 3

[7]Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. Giải quyết các vấn đề lý luận định lượng với mô hình ngôn ngữ. arXiv preprint arXiv:2206.14858, 2022. 1, 3, 9

[8]Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. Chain of thought prompting gợi ra lý luận trong mô hình ngôn ngữ lớn. arXiv preprint arXiv:2201.11903, 2022. 1, 3, 4, 5, 6, 7, 8

[9]Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, và Ed Chi. Least-to-most prompting cho phép lý luận phức tạp trong mô hình ngôn ngữ lớn. In The Eleventh International Conference on Learning Representations, 2023. 1, 3

[10] Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, và Tushar Khot. Complexity-based prompting cho lý luận đa bước. In The Eleventh International Conference on Learning Representations, 2023. 1, 3, 4, 5, 6, 7, 8

[11] Arkil Patel, Satwik Bhattamishra, và Navin Goyal. Các mô hình nlp có thực sự có thể giải quyết các bài toán từ toán học đơn giản không? In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2080–2094, 2021. 2, 4

[12] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Huấn luyện các verifier để giải quyết bài toán từ toán học. arXiv preprint arXiv:2110.14168, 2021. 2, 3, 4

[13] Wang Ling, Dani Yogatama, Chris Dyer, và Phil Blunsom. Cảm ứng chương trình bằng việc tạo ra lý do: Học cách giải quyết và giải thích các bài toán từ đại số. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 158–167, 2017. 2, 4

--- TRANG 11 ---
[14] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, và Jacob Steinhardt. Đo lường khả năng giải quyết vấn đề toán học với tập dữ liệu math. arXiv preprint arXiv:2103.03874, 2021. 2, 4, 9

[15] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Mô hình ngôn ngữ là những người học few-shot. Advances in neural information processing systems, 33:1877–1901, 2020. 2, 3, 4

[16] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Huấn luyện mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi từ con người. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.

[17] OpenAI. Báo cáo kỹ thuật gpt-4. arXiv preprint arXiv:2303.08774, 2023. 2, 4, 9

[18] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Mở rộng quy mô mô hình ngôn ngữ với pathways. arXiv preprint arXiv:2204.02311, 2022. 3

[19] Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, và Sameer Singh. Auto-prompt: Gợi ra kiến thức từ mô hình ngôn ngữ với prompts được tạo tự động. arXiv preprint arXiv:2010.15980, 2020. 3

[20] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, và Graham Neubig. Pre-train, prompt, và predict: Một khảo sát hệ thống về các phương pháp prompting trong xử lý ngôn ngữ tự nhiên. ACM Computing Surveys, 55(9):1–35, 2023. 3

[21] Zhuosheng Zhang, Aston Zhang, Mu Li, và Alex Smola. Chain of thought prompting tự động trong mô hình ngôn ngữ lớn. arXiv preprint arXiv:2210.03493, 2022. 3

[22] Weiwen Xu, Yang Deng, Huihui Zhang, Deng Cai, và Wai Lam. Khai thác chuỗi lý luận cho việc trả lời câu hỏi khoa học multi-hop. In Findings of the Association for Computational Linguistics: EMNLP 2021, pages 1143–1156, 2021. 3

[23] Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, và Caiming Xiong. Học cách truy xuất đường dẫn lý luận qua đồ thị wikipedia cho việc trả lời câu hỏi. In International Conference on Learning Representations, 2020. 3

[24] Jifan Chen, Shih-ting Lin, và Greg Durrett. Trả lời câu hỏi multi-hop thông qua chuỗi lý luận. arXiv preprint arXiv:1910.02610, 2019. 3

[25] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, và Denny Zhou. Self-consistency cải thiện lý luận chain of thought trong mô hình ngôn ngữ. In The Eleventh International Conference on Learning Representations, 2023. 3, 9

[26] Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, và Nate Kushman. Học cách giải quyết bài toán từ số học với phân loại động từ. In EMNLP, pages 523–533, 2014. 4

[27] Subhro Roy và Dan Roth. Giải quyết bài toán từ số học tổng quát. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1743–1752, Lisbon, Portugal, September 2015. Association for Computational Linguistics. 4, 9

[28] Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, và Siena Dumas Ang. Phân tích các bài toán từ đại số thành phương trình. Transactions of the Association for Computational Linguistics, 3:585–597, 2015. 4

[29] Shizhe Diao, Pengcheng Wang, Yong Lin, và Tong Zhang. Active prompting với chain-of-thought cho mô hình ngôn ngữ lớn. arXiv preprint arXiv:2302.12246, 2023. 9

[30] Wenhu Chen, Xueguang Ma, Xinyi Wang, và William W Cohen. Program of thoughts prompting: Tách biệt tính toán khỏi lý luận cho các tác vụ lý luận số học. arXiv preprint arXiv:2211.12588, 2022. 9

[31] Silviu Pitis, Michael R Zhang, Andrew Wang, và Jimmy Ba. Boosted prompt ensembles cho mô hình ngôn ngữ lớn. arXiv preprint arXiv:2304.05970, 2023. 9

[Tiếp tục với các trang còn lại...]

--- TRANG 12 ---
[32] Simon Frieder, Luca Pinchetti, Ryan-Rhys Griffiths, Tommaso Salvatori, Thomas Lukasiewicz, Philipp Christian Petersen, Alexis Chevalier, và Julius Berner. Khả năng toán học của chatgpt. arXiv preprint arXiv:2301.13867, 2023.

[33] Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus Norman Rabe, Charles E Staats, Mateja Jamnik, và Christian Szegedy. Autoformalization với mô hình ngôn ngữ lớn. In Advances in Neural Information Processing Systems, 2022.

[34] Albert Qiaochu Jiang, Wenda Li, Szymon Tworkowski, Konrad Czechowski, Tomasz Odrzygó´ zd´ z, Piotr Miło ´s, Yuhuai Wu, và Mateja Jamnik. Thor: Vận dụng búa để tích hợp mô hình ngôn ngữ và các chứng minh định lý tự động. In Advances in Neural Information Processing Systems, 2022.

[35] Albert Q Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li, Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, và Guillaume Lample. Draft, sketch, và prove: Hướng dẫn các chứng minh định lý chính thức với các chứng minh không chính thức. arXiv preprint arXiv:2210.12283, 2022.

[36] Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin, và Ilya Sutskever. Học chương trình giảng dạy tuyên bố toán học chính thức. arXiv preprint arXiv:2202.01344, 2022.

[37] Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, et al. Hướng tới một chatbot mở như con người. arXiv preprint arXiv:2001.09977, 2020.

[38] Guillaume Lample, Marie-Anne Lachaux, Thibaut Lavril, Xavier Martinet, Amaury Hayat, Gabriel Ebner, Aurélien Rodriguez, và Timothée Lacroix. Tìm kiếm chứng minh hypertree cho chứng minh định lý thần kinh. arXiv preprint arXiv:2205.11491, 2022.

[39] Kyle Richardson và Ashish Sabharwal. Đẩy giới hạn của lý luận quy tắc trong transformer thông qua khả năng thỏa mãn ngôn ngữ tự nhiên. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 11209–11219, 2022.

[40] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Đánh giá mô hình ngôn ngữ lớn được huấn luyện trên code. arXiv preprint arXiv:2107.03374, 2021.

[41] Jianpeng Cheng, Siva Reddy, Vijay Saraswat, và Mirella Lapata. Học một trình phân tích ngữ nghĩa thần kinh có thể thực thi. Computational Linguistics, 45(1):59–94, 2019.

[42] Ohad Rubin, Jonathan Herzig, và Jonathan Berant. Học cách truy xuất prompts cho in-context learning. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2655–2671, 2022.

[43] Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush V osoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, et al. Mô hình ngôn ngữ là những người lý luận chain-of-thought đa ngôn ngữ. arXiv preprint arXiv:2210.03057, 2022.

[44] David H Ackley, Geoffrey E Hinton, và Terrence J Sejnowski. Một thuật toán học cho máy boltzmann. Cognitive science, 9(1):147–169, 1985.

[45] Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, và Caiming Xiong. Học cách truy xuất đường dẫn lý luận qua đồ thị wikipedia cho việc trả lời câu hỏi. arXiv preprint arXiv:1911.10470, 2019.

[46] Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich Schütze, và Yoav Goldberg. Đo lường và cải thiện tính nhất quán trong mô hình ngôn ngữ được huấn luyện trước. Transactions of the Association for Computational Linguistics, 9:1012–1031, 2021.

--- TRANG 13 ---
[47] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. Lamda: Mô hình ngôn ngữ cho ứng dụng hội thoại. arXiv preprint arXiv:2201.08239, 2022.

[48] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Mô hình ngôn ngữ cơ sở mở và hiệu quả. arXiv preprint arXiv:2302.13971, 2023.

[49] SU Hongjin, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah A Smith, et al. Chú thích có chọn lọc làm cho mô hình ngôn ngữ trở thành những người học few-shot tốt hơn. In The Eleventh International Conference on Learning Representations, 2023.

[50] Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, và Sameer Singh. Hiệu chỉnh trước khi sử dụng: Cải thiện hiệu suất few-shot của mô hình ngôn ngữ. In International Conference on Machine Learning, pages 12697–12706. PMLR, 2021.

[51] Sang Michael Xie, Aditi Raghunathan, Percy Liang, và Tengyu Ma. Một lời giải thích về in-context learning như suy luận bayesian ngầm. arXiv preprint arXiv:2111.02080, 2021.

[52] Colin Wei, Sang Michael Xie, và Tengyu Ma. Tại sao mô hình ngôn ngữ được huấn luyện trước lại giúp ích trong các tác vụ downstream? một phân tích về head và prompt tuning. Advances in Neural Information Processing Systems, 34:16158–16170, 2021.

[53] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, và Denny Zhou. Ensembles được tăng cường lý do trong mô hình ngôn ngữ. arXiv preprint arXiv:2207.00747, 2022.

[54] Saku Sugawara, Kentaro Inui, Satoshi Sekine, và Akiko Aizawa. Điều gì làm cho câu hỏi đọc hiểu dễ hơn? In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4208–4219, 2018.

[55] Nils Reimers và Iryna Gurevych. Sentence-bert: Nhúng câu sử dụng mạng bert siamese. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982–3992, 2019.

[56] Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, và Pontus Stenetorp. Prompts được sắp xếp tuyệt vời và nơi tìm thấy chúng: Vượt qua độ nhạy cảm thứ tự prompt few-shot. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8086–8098, 2022.

[57] Jiachang Liu, Dinghan Shen, Yizhe Zhang, William B Dolan, Lawrence Carin, và Weizhu Chen. Điều gì làm cho ví dụ in-context tốt cho gpt-3? In Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, pages 100–114, 2022.

[58] Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, và Weizhu Chen. Về tiến bộ của việc làm cho mô hình ngôn ngữ trở thành những người lý luận tốt hơn. arXiv preprint arXiv:2206.02336, 2022.

[59] Xiang Lisa Li và Percy Liang. Prefix-tuning: Tối ưu hóa prompts liên tục cho việc tạo sinh. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4582–4597, 2021.

[60] Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, và Nikolai Grigorev. Mô hình ngôn ngữ được tăng cường internet thông qua few-shot prompting cho việc trả lời câu hỏi miền mở. arXiv preprint arXiv:2203.05115, 2022.

[61] Yuxuan Lai, Chen Zhang, Yansong Feng, Quzhe Huang, và Dongyan Zhao. Tại sao mô hình đọc hiểu máy học các đường tắt? arXiv preprint arXiv:2106.01024, 2021.

--- TRANG 14 ---
[62] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. Luật mở rộng quy mô cho mô hình ngôn ngữ thần kinh. arXiv preprint arXiv:2001.08361, 2020.

[63] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Huấn luyện một trợ lý hữu ích và vô hại với reinforcement learning từ phản hồi của con người. arXiv preprint arXiv:2204.05862, 2022.

[64] Wenhao Yu, Chenguang Zhu, Lianhui Qin, Zhihan Zhang, Tong Zhao, và Meng Jiang. Đa dạng hóa việc tạo nội dung cho lý luận thường thức với hỗn hợp các chuyên gia đồ thị kiến thức. In Proceedings of the 2nd Workshop on Deep Learning on Graphs for Natural Language Processing (DLG4NLP 2022), pages 1–11, 2022.

6 Chi tiết Triển khai

Chúng tôi đã cung cấp code trong tài liệu bổ sung của chúng tôi.

7 Hạn chế và Công trình Tương lai

Trong bài báo này, chúng tôi sẽ khám phá các hạn chế của kỹ thuật progressive-hint prompting đề xuất của chúng tôi và thảo luận về các hướng cải thiện có thể.

Progressive-Hint Prompt được tạo thủ công. Các progressive-hint prompts đề xuất của chúng tôi được tạo thủ công bởi con người, tương tự như các kỹ thuật liên quan khác như Chain-Of-Thought và Complex Chain of Thought. Do đó, chúng tôi hướng tới việc thiết kế Auto Progressive Hint trong tương lai để cải thiện hiệu quả của nó. Ví dụ, chúng ta có thể liên tục xây dựng và cập nhật progressive hint trong quá trình kiểm tra.

Gợi ý được định nghĩa là câu trả lời. Trong bài báo này, chúng tôi định nghĩa gợi ý là câu trả lời. Tuy nhiên, chúng tôi thừa nhận rằng khái niệm gợi ý bao gồm các khả năng khác được tạo ra bởi mô hình. Những gợi ý này có thể bao gồm độ tin cậy của mô hình, đường dẫn lý luận, và thậm chí số tương tác.

Số tương tác ít nhất là hai. Thiết kế của chúng tôi đòi hỏi ít nhất hai tương tác để xác định câu trả lời cuối cùng. Do đó, việc sử dụng greedy decoding (trong đó đường dẫn mẫu luôn là 1) so với self-consistency có thể tăng chi phí. Trong tương lai, chúng tôi dự định sử dụng một mô hình mạnh mẽ ban đầu để có được câu trả lời cơ bản sau đó dựa vào các mô hình rẻ hơn cho các câu trả lời tiếp theo. Phương pháp này có thể giúp chúng tôi giảm chi phí tổng thể.

8 Tác động Rộng hơn

Progressive-Hint Prompting nhằm tăng cường khả năng lý luận của Mô hình Ngôn ngữ Lớn (LLMs) bằng cách sử dụng các câu trả lời trước đó. Chúng tôi tin rằng việc tích hợp PHP với LLM có thể được áp dụng trong nhiều lĩnh vực khác nhau, bao gồm: 1) Hỗ trợ học sinh, đặc biệt là những em từ các khu vực thu nhập thấp, trong việc học tập hiệu quả hơn và có được câu trả lời chính xác với sự giúp đỡ của LLM và PHP; 2) Hỗ trợ các nhà toán học trong việc giải quyết các vấn đề toán học phức tạp; 3) và các ứng dụng liên quan đến lý luận khác. Bằng cách tận dụng PHP với LLM, chúng tôi hy vọng cải thiện hiệu suất của các mô hình này và cho phép sử dụng chúng trong các kịch bản thực tế khác nhau.

9 Phản hồi Mô hình với Các Gợi ý Khác nhau

Phản hồi Mô hình với các gợi ý khác nhau. Khi được trình bày với gợi ý 100, mô hình giải quyết chính xác câu hỏi. Ngược lại, mô hình có thể bị hiểu lầm nếu gợi ý được cung cấp quá xa so với câu trả lời đúng. Ví dụ, khi gợi ý là 0, mô hình tính toán lượng cà rốt không được sử dụng là 80 pound, đưa ra câu trả lời là 0.

10 Các Trường hợp Tương tác

Trong phần này, chúng tôi cung cấp thêm các trường hợp tương tác.

--- TRANG 15 ---
Bảng 9: Một ví dụ GSM8K về phản hồi của text-davinci-003 với greedy decoding, và prompt là PHP-Complex CoT. Dựa trên phân tích của chúng tôi, có vẻ như một gợi ý quá xa so với câu trả lời đúng có khả năng làm hiểu lầm LLMs và dẫn đến câu trả lời cuối cùng sai. Ngược lại, một gợi ý hiệu quả hơn có thể dẫn đến kết quả chính xác hơn.

[Bảng hiển thị ví dụ với gợi ý khác nhau và phản hồi tương ứng]

10.1 Trường hợp Thành công

[Cung cấp các ví dụ chi tiết về các trường hợp thành công khi PHP hoạt động tốt]

10.2 Trường hợp Thất bại

[Cung cấp các ví dụ chi tiết về các trường hợp thất bại khi PHP không hoạt động như mong đợi]

10.3 Phản hồi khi Thiếu Gợi ý cho GPT-3.5 Text-Davinci-003

[Cung cấp ví dụ về cách mô hình phản hồi khi thiếu gợi ý]

11 Standard Prompt

[Các phần tiếp theo chứa các prompt chi tiết được sử dụng trong thí nghiệm, bao gồm Standard Prompts, Chain-of-Thought Prompts, và Complex Chain-of-Thought Prompts cho các tập dữ liệu khác nhau]

[Nội dung còn lại của tài liệu tiếp tục với các prompt và ví dụ chi tiết...]

# Tạo Dữ liệu Tổng hợp trong Môi trường Tài nguyên Thấp
thông qua Tinh chỉnh Mô hình Ngôn ngữ Lớn
Jean Kaddour
Đại học College London
Qi Liu
Đại học Hồng Kông

Tóm tắt
Khả năng học trong ngữ cảnh của các mô hình ngôn ngữ lớn (LLM) cho phép chúng khái quát hóa cho các tác vụ hạ lưu mới với tương đối ít ví dụ có nhãn. Tuy nhiên, chúng yêu cầu tài nguyên tính toán khổng lồ để triển khai. Thay vào đó, các mô hình nhỏ hơn có thể giải quyết các tác vụ cụ thể nếu được tinh chỉnh với đủ ví dụ có nhãn. Tuy nhiên, những ví dụ này rất tốn kém để thu thập. Trong việc theo đuổi điều tốt nhất của cả hai thế giới, chúng tôi nghiên cứu việc tạo dữ liệu tổng hợp cho dữ liệu huấn luyện tinh chỉnh thông qua các LLM giáo viên được tinh chỉnh để cải thiện hiệu suất hạ lưu của các mô hình nhỏ hơn nhiều. Trong bốn tác vụ phân loại văn bản và hai tác vụ tạo văn bản, chúng tôi thấy rằng cả việc tạo dữ liệu và gán nhãn đều cải thiện đáng kể hiệu suất của mô hình hạ lưu tương ứng, đôi khi chỉ cần một phần nhỏ của tập dữ liệu huấn luyện ban đầu.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) đã chứng minh khả năng học trong ngữ cảnh (ICL) trong các tác vụ xử lý ngôn ngữ tự nhiên khác nhau, cho phép chúng ta thực hiện một tác vụ hạ lưu chưa từng thấy bằng cách nhắc mô hình với một tập hợp các cặp đầu vào-đích và một ví dụ không có nhãn duy nhất [8]. Quan trọng là, ICL yêu cầu tương đối ít ví dụ có nhãn nhưng cần kích thước mô hình lớn [37]. Tuy nhiên, việc triển khai LLM trong các hệ thống thực tế là thách thức do chi phí tính toán và độ trễ suy luận của chúng [21].

Một mô hình thay thế cho phép kết quả tốt với các mô hình nhỏ hơn nhiều là chuyên hóa một mô hình được tiền huấn luyện cho một tác vụ duy nhất thông qua tinh chỉnh có giám sát dựa trên gradient (SFT) [11,12]. Nhược điểm của phương pháp này là nó dựa vào các ví dụ có nhãn, đòi hỏi người gán nhãn và do đó tốn kém và tốn thời gian. Đặc biệt trong các môi trường tài nguyên thấp với chỉ một số ít ví dụ, SFT có thể thách thức [39].

Trong công việc này, chúng tôi cố gắng đạt được điều tốt nhất của cả hai thế giới bằng cách tinh chỉnh các mô hình nhỏ hơn với dữ liệu huấn luyện được tạo bởi một LLM. Theo các công trình gần đây về tạo dữ liệu huấn luyện [32,27,21], chúng tôi chỉ ra rằng bằng cách (i) gán nhãn cho các ví dụ chưa có nhãn hoặc (ii) tạo ra những ví dụ hoàn toàn mới, chúng ta có thể hiệu quả chuyển kiến thức từ LLM (giáo viên) sang mô hình chuyên biệt (học sinh), có thể nhỏ hơn nhiều bậc độ lớn, tương tự như chưng cất kiến thức [18] nhưng chỉ thông qua việc trao đổi dữ liệu.

Chúng tôi thấy rằng việc tạo dữ liệu tổng hợp sau khi tinh chỉnh LLM giáo viên, thậm chí chỉ trên dữ liệu cực kỳ hạn chế, cải thiện chất lượng dữ liệu tổng hợp được đo bằng hiệu suất khái quát hóa của mô hình hạ lưu. Ví dụ, tinh chỉnh một LLM 20B chỉ trên 125 ví dụ (5% của tập dữ liệu RTE [34]) tăng hiệu suất của mô hình hạ lưu được tinh chỉnh với dữ liệu tăng cường lên nhiều điểm phần trăm.

Chúng tôi xác minh thực nghiệm phương pháp của mình trên bốn tác vụ phân loại văn bản và hai tác vụ tạo ngôn ngữ tự nhiên, thấy rằng cả (i) và (ii) đều cải thiện hiệu suất hạ lưu của mô hình học sinh một cách nhất quán. Chúng tôi cung cấp các nghiên cứu khử bỏ về việc thay đổi lượng dữ liệu tổng hợp, so sánh với GPT3.5 [8] như một mô hình giáo viên, và đánh giá trực tiếp các LLM giáo viên trên các tác vụ hạ lưu.

Bước 1: Tinh chỉnh LLM
Tập Huấn luyện Nhỏ
FT
Đầu vào: "That is good."
Đầu vào: "Where are you?."
Đầu ra: "Das ist gut."
Đầu ra: "Wo bist du?"

Bước 3: Huấn luyện Mô hình Hạ lưu
BERT
FT
Đầu vào: "That is good."
Đầu vào: "Where are you?."
Đầu ra: "Das ist gut."
Đầu ra: "Wo bist du?"
Tập Huấn luyện Nhỏ
Dữ liệu Tổng hợp
+
Đầu ra: "Wer bist du?"
Đầu vào: "Who are you"
Đầu vào: "Fantastic food."
Đầu ra: "Fantastisches Essen."

Bước 2: Tạo Dữ liệu Tổng hợp
A) Gán nhãn
B) Tạo mới
LLM (đã tinh chỉnh)
Đầu vào: Đầu vào: "Who are you?"
Đầu vào: "Fantastic food."
Đầu ra: "Wer bist du?"
Đầu ra: "Fantastisches Essen."
Đầu ra: "Wer bist du?"
Đầu vào: "Who are you?"
LLM (đã tinh chỉnh)

Hình 1: Tạo Dữ liệu Tổng hợp thông qua Tinh chỉnh LLM Giáo viên: Bước 1: Chúng tôi tinh chỉnh (FT) một LLM (GPT-NeoX-20B [6]). Bước 2: Chúng tôi gán nhãn cho các trường hợp chưa có nhãn hoặc tạo ra những trường hợp hoàn toàn mới. Bước 3: Chúng tôi huấn luyện một mô hình hạ lưu nhỏ trên tập dữ liệu huấn luyện được tăng cường.

2 Phương pháp
2.1 Định nghĩa Vấn đề
Xem xét một tập dữ liệu có nhãn và cụ thể cho tác vụ DT:={(xi,yi)}N i=1 của các cặp đầu vào-đầu ra văn bản cho một tác vụ T nào đó, một LLM giáo viên được tham số hóa bởi θT và mô hình học sinh nhẹ θS, với |θS| ≪ |θT|. Chúng tôi nhắm đến tạo ra θS hoạt động tương tự như θT trong việc giải quyết T. Tiền đề là θT hoạt động tốt hơn nhiều so với θS nhưng tốn kém hơn để triển khai. Chiến lược của chúng tôi là tạo dữ liệu tổng hợp eDT bằng cách sử dụng θT, sau đó tinh chỉnh θS trên DT∪eDT.

Chúng tôi tiếp tục phân biệt các trường hợp (i) gán nhãn cho một tập các trường hợp chưa có nhãn {xi}M i=1 sao cho eDT:={(xi,ŷi)}M i=1, hoặc (ii) tạo ra các cặp đầu vào-đầu ra hoàn chỉnh eDT:={(x̂i,ŷi)}M i=1, trong đó x̂i,ŷi đề cập đến các chuỗi đầu vào và đầu ra tổng hợp tương ứng. (i) có liên quan trong các tình huống có sẵn văn bản chưa có nhãn dồi dào (ví dụ, thu thập từ internet), nhưng việc có được gán nhãn rất tốn kém. Ngược lại, (ii) phù hợp ngay cả trong các tình huống không có trường hợp chưa có nhãn.

2.2 Mô hình giáo viên
LLM giáo viên là GPT-NeoX 20B [6], vào thời điểm giai đoạn thử nghiệm của chúng tôi, được coi là state-of-the-art¹. Chúng tôi áp dụng khung văn bản-sang-văn bản [28], nơi LLM nhận một truy vấn văn bản làm đầu vào và tạo ra đầu ra văn bản. Ví dụ, khi tạo phản hồi đối thoại, truy vấn tương ứng với các phát biểu đối thoại chưa hoàn chỉnh, và mô hình tạo ra phản hồi. Đối với các tác vụ phân loại, truy vấn tương ứng với đầu vào văn bản, và mô hình tạo ra nhãn lớp.

Hơn nữa, chúng tôi tinh chỉnh GPT-NeoX để tuân theo hướng dẫn đa tác vụ trên một số hỗn hợp tác vụ, sử dụng tập dữ liệu Super-NaturalInstructions [36]. Mỗi lời nhắc bao gồm một tiền tố mô tả tác vụ và một tập hợp nhỏ các cặp đầu vào-đầu ra huấn luyện, được phân tách bằng các thẻ [INPUT] và [OUTPUT]. Hơn nữa, tùy thuộc vào việc chúng tôi gán nhãn văn bản chưa có nhãn hay tạo ra các ví dụ hoàn toàn mới, lời nhắc kết thúc bằng [OUTPUT] hoặc [INPUT] tương ứng.

Chúng tôi tinh chỉnh tất cả các lớp và sử dụng Adam trong tối đa 5 epochs với lịch trình cosine và tỷ lệ học 1e−5. Mã của chúng tôi dựa trên thư viện GPT-Neox [2], sử dụng DeepSpeed [29] để hỗ trợ huấn luyện phân tán. Chúng tôi sử dụng GPU NVIDIA A100 cho tất cả các thí nghiệm như được cung cấp bởi một cụm tính toán nội bộ.

Một siêu tham số suy luận quan trọng là nhiệt độ tạo, kiểm soát tính ngẫu nhiên của đầu ra LLM. Chúng tôi thấy rằng nhiệt độ thấp 0.1 hoạt động tốt nhất cho gán nhãn, trong khi nhiệt độ cao 0.8 hoạt động tốt nhất cho tạo mới (do tính đa dạng cao hơn trong các mẫu).

2.3 Mô hình học sinh
Đối với các tác vụ phân loại và tạo văn bản, chúng tôi sử dụng các mô hình RoBERTa-Large [26] và BART-Large [23] tương ứng. Chúng tôi tinh chỉnh các checkpoint có sẵn công khai của chúng. Chúng tôi tinh chỉnh tối đa 320 epochs cho các tác vụ TC sử dụng Adam, kích thước batch 50, và tỷ lệ học 1e−5. Chúng tôi tinh chỉnh với Adam trong 5 epochs cho các tác vụ TG, sử dụng lịch trình học tuyến tính, kích thước batch 32, và tỷ lệ học 5e−5. Chúng tôi báo cáo kết quả sử dụng mô hình có tổn thất xác thực tốt nhất.

¹Trong thời gian này, nhiều mô hình hoạt động tốt hơn đã được phát hành [21,1], có khả năng cải thiện thêm hiệu quả của phương pháp chúng tôi.

3 Thí nghiệm
3.1 Tập dữ liệu

Tập dữ liệu # Số ví dụ
Huấn luyện Phát triển Kiểm tra
SLURP [4] 11514 2033 2974
RTE [34] 2500 277 300
BoolQ [10] 9427 3270 3245
MultiRC [22] 5100 953 1800
PubMedQA [20] 212300 - 1000
SGD [30] 164982 10000 10000
WebNLG [15] 35426 1667 1779

Bảng 1: Thống kê Tập dữ liệu. Chúng tôi liệt kê kích thước tập dữ liệu trong Bảng 1. Có thể áp dụng các phân số trong các bảng sau vào bảng này để tính số mẫu tinh chỉnh cho LLM giáo viên.

Phân loại văn bản Chúng tôi báo cáo độ chính xác phân loại trên bốn tác vụ phân loại. SLURP (Spoken Language Understanding Resource Package) [4] là một tập dữ liệu đa miền để hiểu ngôn ngữ nói từ đầu đến cuối, bao gồm các tương tác một lượt của người dùng với trợ lý gia đình. BoolQ [10] chứa các câu hỏi có/không tự nhiên về một đoạn văn được cung cấp. RTE (Recognizing Textual Entailment) [33] là một tập dữ liệu để nhận biết liệu, cho hai văn bản, ý nghĩa của một văn bản có được suy ra (có thể được suy luận) từ văn bản kia hay không. MultiRC (Multi-Sentence Reading Comprehension) [22] là một tập dữ liệu hỏi đáp đọc hiểu đa câu, trong đó mỗi đầu vào bao gồm một đoạn văn và câu hỏi ngắn, yêu cầu kết hợp thông tin từ nhiều câu.

Tạo ngôn ngữ tự nhiên Chúng tôi báo cáo điểm Rouge-{1,2,L} [25] trên cả tập phát triển và kiểm tra qua hai tác vụ. Schema Guided Dialog (SGD) [30] bao gồm các cuộc hội thoại định hướng tác vụ giữa con người và trợ lý ảo. Ở đây, chúng tôi theo Gehrmann et al. [16] và xây dựng tác vụ tạo một phát biểu cho trước một đối thoại chưa hoàn chỉnh làm đầu vào. WebNLG là một tác vụ dữ liệu-sang-văn bản [15], nhằm tạo ra một văn bản diễn đạt các bộ ba đầu vào một cách đúng ngữ pháp.

3.2 Kết quả chính
Phần 3.2 hiển thị các kết quả chính. Chúng tôi tính toán lượng dữ liệu tương đối so với kích thước tập dữ liệu huấn luyện ban đầu. Ví dụ, một mục với 1% ban đầu và 10% dữ liệu tổng hợp có nghĩa là chúng tôi xây dựng tập dữ liệu huấn luyện tăng cường bằng cách nối 1% dữ liệu được lấy mẫu ngẫu nhiên từ tập dữ liệu huấn luyện ban đầu và 10% dữ liệu tổng hợp.

Chúng tôi quan sát thấy rằng cả việc gán nhãn dữ liệu và tạo mới đều cải thiện hiệu suất trên tất cả các điểm số. Thú vị là, tập dữ liệu huấn luyện ban đầu càng nhỏ, mức tăng càng lớn. Điều này thú vị vì nó ngụ ý rằng chúng ta không cần nhiều mẫu cho giai đoạn tinh chỉnh của giáo viên để thành công.

3.3 Thay đổi lượng dữ liệu tổng hợp
Để hiểu mối quan hệ giữa lượng dữ liệu tổng hợp được thêm vào và các cải thiện hiệu suất hạ lưu của nó, chúng tôi thay đổi lượng dữ liệu tổng hợp cho các tác vụ NLG.

Hình 5 cho thấy kết quả của các lượng tăng cường khác nhau với 1% dữ liệu huấn luyện ban đầu. Đối với SGD, chúng tôi quan sát thấy rằng cho đến 30%, hiệu suất mô hình hạ lưu tăng. Tuy nhiên, đối với WebNLG, chúng tôi quan sát thấy lợi ích giảm dần và thậm chí hiệu suất hơi tệ hơn khi lượng dữ liệu tổng hợp tăng.

3.4 Đánh giá trực tiếp các LLM giáo viên
Chúng tôi báo cáo hiệu suất của các mô hình giáo viên, tức là không tạo ra các điểm dữ liệu bổ sung và tinh chỉnh một mô hình học sinh, trong Hình 8. Thú vị là, mô hình NeoX 20B được tinh chỉnh vượt trội so với mô hình davinci-002 được tinh chỉnh với 175B tham số (được tinh chỉnh với các siêu tham số mặc định như được cung cấp bởi API của OpenAI).

3.5 So sánh các LLM Giáo viên NeoX-20B và GPT-3.5 175B
Chúng tôi điều tra mức độ hiệu quả của khung của chúng tôi khi kết hợp với các mô hình giáo viên khác. Chúng tôi so sánh NeoX-20B với GPT-3.5 175B của OpenAI [8] (được gọi là davinci-002 trong API của họ) trong Hình 7.

Tập dữ liệu Loại Lượng dữ liệu theo % Độ chính xác Dev Độ chính xác Test
Ban đầu Của chúng tôi

SLURP [4] 
1% 0% 42.25 43.95
X, Y 26% 54.57 54.25
Y|X 78% 76.14 76.09
5% 0% 73.49 71.59
X, Y 43% 77.39 76.89
Y|X 78% 85.00 83.96
10% 0% 80.12 80.04
X, Y 43% 82.59 81.91
Y|X 43% 86.13 86.48
100% 0% 88.64 87.70

BoolQ [10] 
1% 0% 62.84 N/A
X, Y 31% 68.96
Y|X 44% 79.72
5% 0% 62.97
X, Y 31% 66.02
Y|X 44% 80.09
10% 0% 68.29
X, Y 31% 77.22
Y|X 44% 81.93
100% 0% 85.05

RTE [33] 
5% 0% 60.65 N/A
X, Y 80% 66.79
Y|X 80% 83.20
10% 0% 65.43
X, Y 80% 69.68
Y|X 80% 83.75
20% 0% 74.73
X, Y 80% 76.84
Y|X 80% 85.20
100% 0% 86.60

MultiRC [22] 
1% 0% 57.50 8.18
X, Y 40% 63.40 15.11
Y|X 254% 71.46 24.24
5% 0% 67.70 18.05
X, Y 40% 72.85 21.86
Y|X 254% 71.51 32.63
10% 0% 70.63 22.35
X, Y 40% 73.88 24.97
Y|X 254% 76.90 34.94
100% 0% 82.12 48.16

Hình 2: Phân loại Văn bản.

Tập dữ liệu Loại Lượng dữ liệu theo % Điểm số Validation Điểm số Test
Ban đầu Của chúng tôi R-1 R-2 R-L R-1 R-2 R-L

SGD [30] 
1% 0% 21.78 9.29 20.09 21.91 9.40 20.06
X, Y 10% 43.72 25.09 39.84 40.82 22.36 37.00
Y|X 47.44 28.19 43.47 43.37 24.49 39.58
5% 0% 33.17 16.86 30.32 30.92 14.86 28.09
X, Y 10% 45.27 26.39 41.48 41.71 23.25 37.98
Y|X 48.99 29.87 45.02 44.60 25.76 40.66
10% 0% 35.48 18.48 32.47 33.40 16.40 30.37
X, Y 10% 48.49 29.59 44.62 43.89 25.29 40.16
Y|X 49.31 30.15 45.32 44.89 25.94 40.98
100% 0% 57.62 39.64 53.63 50.23 32.03 46.30

WebNLG [15] 
1% 0% 53.94 31.76 42.58 50.21 28.44 39.72
X, Y 10% 72.99 47.16 56.06 69.63 42.99 52.98
Y|X 75.69 51.18 59.60 70.21 44.34 54.51
5% 0% 56.58 35.74 46.46 53.17 32.57 44.65
X, Y 10% 76.57 51.23 60.12 71.63 44.38 54.37
Y|X 78.02 53.60 61.46 72.11 45.50 55.29
10% 0% 59.02 38.21 48.37 54.07 32.47 44.06
X, Y 10% 77.72 53.56 61.60 72.02 45.20 54.71
Y|X 78.38 54.56 62.72 72.73 46.02 55.96
100% 0% 80.65 58.50 65.73 73.27 46.90 55.76

Hình 3: Tạo Ngôn ngữ Tự nhiên.

Hình 4: So sánh Hiệu suất có và không có Phương pháp của chúng tôi. Chúng tôi thấy rằng phương pháp của chúng tôi hiệu quả nhất trong các môi trường có lượng dữ liệu ban đầu nhỏ nhất mặc dù LLM giáo viên được tinh chỉnh trên lượng dữ liệu nhỏ đó. Để tham khảo, chúng tôi liệt kê hiệu suất của mô hình học sinh khi được tinh chỉnh trên 100% dữ liệu huấn luyện.

Tập dữ liệu Loại Lượng dữ liệu Rouge-L
Ban đầu Của chúng tôi Dev Test

SGD 
1% 0% 20.09 20.06
Y|X 1% 10% 43.47 39.58
20% 45.22 40.89
30% 46.02 41.29
X, Y 1% 10% 39.84 37.00
20% 40.92 37.62
30% 42.27 39.30
100% 0% 53.63 46.30

WebNLG 
1% 0% 42.58 39.72
Y|X 1% 1% 57.59 52.92
2% 58.94 54.50
3% 59.44 54.44
4% 59.79 54.42
5% 59.56 54.44
X, Y 1% 1% 57.09 52.81
2% 57.00 52.29
3% 57.08 52.64
4% 56.92 52.72
5% 56.92 52.76
100% 0% 65.73 55.76

Hình 5: Các lượng dữ liệu khác nhau của chúng tôi được thêm vào tập huấn luyện mô hình học sinh. Trong khi cả hai tác vụ SGD và WebNLG đều hưởng lợi từ dữ liệu tổng hợp, chúng tôi quan sát thấy lợi ích giảm dần.

Tập dữ liệu Loại Lượng dữ liệu Rouge-L
Ban đầu Của chúng tôi Dev Test

SGD 
1% 0% 20.09 20.06
Y|X 1% 10% 43.47 39.58
X, Y 1% 10% 39.84 37.00
Y|X;X, Y 1% 5% mỗi loại 42.46 39.18

WebNLG 
1% 0% 42.58 39.72
Y|X 1% 10% 59.60 54.51
X, Y 1% 1% 56.06 52.98
Y|X;X, Y 1% 5% mỗi loại 59.41 54.17

Hình 6: Kết hợp Gán nhãn (Y|X) và Tạo mới (X, Y) một cách bằng nhau hoạt động gần như tốt như việc gán nhãn cùng lượng, trong khi phương pháp sau giả định có quyền truy cập vào các trường hợp chưa có nhãn, điều này có thể khó khăn trong thực tế.

Mô hình Dev Test
Rouge 1 Rouge 2 Rouge L Rouge 1 Rouge 2 Rouge L
davinci-002 35.47 17.99 32.35 34.62 17.19 31.46
NeoX 47.44 28.19 43.47 43.37 24.49 39.59

Hình 7: So sánh các LLM Giáo viên: Chúng tôi báo cáo hiệu suất hạ lưu của LM học sinh sau khi được tinh chỉnh trên 11% kích thước tập dữ liệu huấn luyện ban đầu, trong đó 1% là dữ liệu ban đầu (cũng được sử dụng để tinh chỉnh các LLM giáo viên) và 10% ví dụ được gán nhãn bởi giáo viên. Tác vụ là SGD.

Mô hình Dev Test
Rouge 1 Rouge 2 Rouge L Rouge 1 Rouge 2 Rouge L
davinci-002 30.71 14.38 28.06 30.54 14.14 27.70
NeoX 38.38 20.84 35.44 37.78 20.13 34.58

Hình 8: Đánh giá các LLM Giáo viên trên SGD sau khi được tinh chỉnh với 1% dữ liệu huấn luyện.

Mô hình NeoX được tinh chỉnh nhất quán tạo ra dữ liệu huấn luyện tốt hơn được đo bằng hiệu suất hạ lưu của LM học sinh trên các tập kiểm tra của tác vụ. Đây là một kết quả thú vị, xét đến sự khác biệt về kích thước mô hình.

3.6 Kết hợp gán nhãn và tạo mới
Trong Phần 3.2, chúng tôi quan sát thấy rằng việc gán nhãn dữ liệu hiện có, chưa có nhãn mang lại lợi ích đáng kể hơn so với việc tạo ra các cặp đầu vào-đầu ra hoàn chỉnh. Tuy nhiên, trong nhiều môi trường thực tế, việc truy cập vào dữ liệu chưa có nhãn vẫn có thể tốn kém hơn so với việc tạo ra các điểm dữ liệu hoàn toàn mới. Do đó, chúng tôi muốn điều tra liệu việc thêm các điểm dữ liệu được tạo vào những điểm được gán nhãn với lượng bằng nhau có thể mang lại hiệu suất gần với một tập lớn hơn các điểm được gán nhãn trong khi có khả năng rẻ hơn nhiều trong thực tế.

Trong môi trường 1% dữ liệu huấn luyện ban đầu, chúng tôi xác nhận giả thuyết này một cách khẳng định, như được thể hiện trong Hình 6. Khi trộn cả hai nguồn dữ liệu với 5% mỗi loại, chúng tôi đạt được hiệu suất gần như tương tự như nếu chúng tôi đã gán nhãn 10% toàn bộ tập dữ liệu.

3.7 Phân tích Định tính Văn bản được Tạo
Trong Phụ lục A, chúng tôi trình bày cả các trường hợp được gán nhãn cũng như những trường hợp được tạo hoàn toàn. Bằng cách kiểm tra và xác minh thủ công, chúng tôi thấy tất cả các ví dụ được tạo đều mạch lạc và đúng cú pháp. Tuy nhiên, không phải tất cả các trường hợp đều đúng về mặt sự thật, một hiện tượng thường được gọi là "ảo giác". Một quy trình lọc sự thật sau hoc của các ví dụ được tạo có thể là một hướng thú vị cho công việc tương lai [24].

4 Công trình Liên quan
Có nhiều tài liệu về việc tăng cường dữ liệu tổng hợp cho dữ liệu văn bản tận dụng các mô hình giáo viên lớn [5,21]. Tuy nhiên, hầu hết các công trình này không tinh chỉnh LLM giáo viên trên dữ liệu hạn chế để cải thiện chất lượng của dữ liệu được tạo. Efrat & Levy [14] kiểm tra khả năng của một mô hình trong việc tuân theo các hướng dẫn ngôn ngữ tự nhiên, bao gồm việc gán nhãn cho các ví dụ tập dữ liệu chưa có nhãn. Schick & Schütze [32] nghiên cứu việc tạo dữ liệu tổng hợp trên các tập dữ liệu tương đồng văn bản ngữ nghĩa mà không có ví dụ huấn luyện cụ thể cho tác vụ. Tương tự, các công trình khác đã tập trung vào truy xuất thông tin [7], tạo mã [3], và các tác vụ lý luận [19].

Yoo et al. [38] đề xuất chuyển kiến thức từ LLM sang các mô hình học sinh bằng cách tạo ra các ví dụ tổng hợp và chưng cất kiến thức sử dụng nhãn mềm. Wang et al. [35] khám phá GPT-3 như một người gán nhãn dữ liệu chi phí thấp để huấn luyện các mô hình khác. Đối với các tác vụ NLG và NLU, họ thấy rằng việc sử dụng nhãn được tạo bởi GPT-3 tốn ít hơn 50% đến 96% so với gán nhãn bởi con người. Tương tự, Ding et al. [13] đánh giá hiệu quả của GPT-3 như một người gán nhãn dữ liệu trên các tác vụ phân loại và nhận dạng thực thể có tên.

Chen et al. [9], Zheng et al. [40], Gunasekar et al. [17], Li et al. [24] theo một phương pháp tương tự như của chúng tôi, tăng cường dữ liệu tiền huấn luyện với các tài liệu được tạo tổng hợp. Ví dụ, Gunasekar et al. [17] tạo ra sách giáo khoa và bài tập để huấn luyện một mô hình tương đối nhỏ, vượt trội so với những mô hình lớn hơn nhiều trên các tác vụ mã hóa. Ngược lại, chúng tôi xem xét giai đoạn tinh chỉnh và các tác vụ phân loại và tạo ngôn ngữ tự nhiên, tương tự như công trình của Sahu et al. [31], Chen et al. [9] nhưng với các tác vụ khác nhau.

Về tinh thần, phương pháp của chúng tôi tương tự như chưng cất kiến thức (KD) [18], nơi người ta sử dụng các logit đầu ra của mô hình giáo viên làm mục tiêu khi huấn luyện mô hình học sinh. Tuy nhiên, các LLM state-of-the-art thường được phục vụ thông qua các API thương mại dựa trên đám mây, chỉ tiết lộ một phân phối đầu ra bị cắt xén (ví dụ, 5 token hàng đầu). Ngược lại, phương pháp tạo dữ liệu tổng hợp của chúng tôi không yêu cầu phân phối đầu ra của giáo viên.

5 Kết luận, Hạn chế và Công việc Tương lai
Trong công việc này, chúng tôi đã làm rõ rằng việc tinh chỉnh các LLM giáo viên để cả gán nhãn cho các trường hợp chưa có nhãn và tạo ra các điểm dữ liệu mới có thể hiệu quả cải thiện hiệu suất của một mô hình hạ lưu. Các điều tra thực nghiệm của chúng tôi trải dài trên sáu tác vụ, bốn tác vụ phân loại và hai tác vụ liên quan đến tạo ngôn ngữ tự nhiên. Một hạn chế tiềm năng của phương pháp chúng tôi là việc tinh chỉnh một mô hình lớn đòi hỏi tài nguyên đáng kể. Trong công việc tương lai, chúng tôi nhắm đến đi sâu hơn vào việc định lượng mức độ tinh chỉnh cần thiết để điều hướng mô hình giáo viên tạo ra dữ liệu tổng hợp chất lượng cao.

Tài liệu tham khảo
[1] Open LLM Leaderboard - a Hugging Face Space by HuggingFaceH4, 2023. URL https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard.

[2] Andonian, A., Biderman, S., Black, S., Gali, P., Gao, L., Hallahan, E., Levy-Kramer, J., Leahy, C., Nestler, L., Parker, K., Pieler, M., Purohit, S., Songz, T., Phil, W., and Weinbach, S. GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch, August 2021. URL https://www.github.com/eleutherai/gpt-neox.

[3] Azerbayev, Z., Ni, A., Schoelkopf, H., and Radev, D. Explicit knowledge transfer for weakly-supervised code generation, 2022. URL https://arxiv.org/abs/2211.16740.

[4] Bastianelli, E., Vanzo, A., Swietojanski, P., and Rieser, V. Slurp: A spoken language understanding resource package, 2020. URL https://arxiv.org/abs/2011.13205.

[5] Bayer, M., Kaufhold, M.-A., and Reuter, C. A survey on data augmentation for text classification. ACM Computing Surveys, 55(7):1–39, 2022.

[6] Black, S., Biderman, S., Hallahan, E., Anthony, Q., Gao, L., Golding, L., He, H., Leahy, C., McDonell, K., Phang, J., et al. Gpt-neox-20b: An open-source autoregressive language model. arXiv preprint arXiv:2204.06745, 2022.

[7] Bonifacio, L., Abonizio, H., Fadaee, M., and Nogueira, R. Inpars: Data augmentation for information retrieval using large language models, 2022. URL https://arxiv.org/abs/2202.05144.

[8] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

[9] Chen, M., Papangelis, A., Tao, C., Rosenbaum, A., Kim, S., Liu, Y., Yu, Z., and Hakkani-Tur, D. Weakly supervised data augmentation through prompting for dialogue understanding. In NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research, 2022. URL https://openreview.net/forum?id=r2_9r7seD-q.

[10] Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., and Toutanova, K. Boolq: Exploring the surprising difficulty of natural yes/no questions. arXiv preprint arXiv:1905.10044, 2019.

[11] Dai, A. M. and Le, Q. V. Semi-supervised sequence learning, 2015. URL https://arxiv.org/abs/1511.01432.

[12] Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding, 2018. URL https://arxiv.org/abs/1810.04805.

[13] Ding, B., Qin, C., Liu, L., Bing, L., Joty, S., and Li, B. Is gpt-3 a good data annotator?, 2022. URL https://arxiv.org/abs/2212.10450.

[14] Efrat, A. and Levy, O. The turking test: Can language models understand instructions? arXiv preprint arXiv:2010.11982, 2020.

[15] Gardent, C., Shimorina, A., Narayan, S., and Perez-Beltrachini, L. Creating training corpora for nlg micro-planning. In 55th annual meeting of the Association for Computational Linguistics (ACL), 2017.

[16] Gehrmann, S., Adewumi, T., Aggarwal, K., Ammanamanchi, P. S., Anuoluwapo, A., Bosselut, A., Chandu, K. R., Clinciu, M., Das, D., Dhole, K. D., et al. The gem benchmark: Natural language generation, its evaluation and metrics. arXiv preprint arXiv:2102.01672, 2021.

[17] Gunasekar, S., Zhang, Y., Aneja, J., Mendes, C. C. T., Del Giorno, A., Gopi, S., Javaheripi, M., Kauffmann, P., de Rosa, G., Saarikivi, O., et al. Textbooks are all you need. arXiv preprint arXiv:2306.11644, 2023.

[18] Hinton, G., Vinyals, O., Dean, J., et al. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2(7), 2015.

[19] Ho, N., Schmid, L., and Yun, S.-Y. Large language models are reasoning teachers. arXiv preprint arXiv:2212.10071, 2022.

[20] Jin, Q., Dhingra, B., Liu, Z., Cohen, W., and Lu, X. PubMedQA: A dataset for biomedical research question answering. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 2567–2577, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1259. URL https://aclanthology.org/D19-1259.

[21] Kaddour, J., Harris, J., Mozes, M., Bradley, H., Raileanu, R., and McHardy, R. Challenges and Applications of Large Language Models, July 2023. URL http://arxiv.org/abs/2307.10169. arXiv:2307.10169 [cs].

[22] Khashabi, D., Chaturvedi, S., Roth, M., Upadhyay, S., and Roth, D. Looking beyond the surface: A challenge set for reading comprehension over multiple sentences. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pp. 252–262, 2018.

[23] Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461, 2019.

[24] Li, Y, Bubeck, S., Eldan, R., Del Giorno, A., Gunasekar, S., and Lee, Y. T. Textbooks are all you need ii: phi-1.5 technical report. arXiv preprint arXiv:2309.05463, 2023.

[25] Lin, C.-Y. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pp. 74–81, 2004.

[26] Liu, Y, Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.

[27] Meng, Y, Huang, J., Zhang, Y, and Han, J. Generating training data with language models: Towards zero-shot language understanding. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=4G1Sfp_1sz7.

[28] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y, Li, W., Liu, P. J., et al. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1–67, 2020.

[29] Rasley, J., Rajbhandari, S., Ruwase, O., and He, Y. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 3505–3506, 2020.

[30] Rastogi, A., Zang, X., Sunkara, S., Gupta, R., and Khaitan, P. Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset, 2019. URL https://arxiv.org/abs/1909.05855.

[31] Sahu, G., Rodriguez, P., Laradji, I. H., Atighehchian, P., Vazquez, D., and Bahdanau, D. Data augmentation for intent classification with off-the-shelf large language models. arXiv preprint arXiv:2204.01959, 2022.

[32] Schick, T. and Schütze, H. Generating datasets with pretrained language models, 2021. URL https://arxiv.org/abs/2104.07540.

[33] Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pp. 353–355, Brussels, Belgium, November 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5446. URL https://aclanthology.org/W18-5446.

[34] Wang, A., Pruksachatkun, Y, Nangia, N., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. Superglue: A stickier benchmark for general-purpose language understanding systems. Advances in neural information processing systems, 32, 2019.

[35] Wang, S., Liu, Y, Xu, Y, Zhu, C., and Zeng, M. Want to reduce labeling cost? gpt-3 can help, 2021. URL https://arxiv.org/abs/2108.13487.

[36] Wang, Y, Mishra, S., Alipoormolabashi, P., Kordi, Y, Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran, A. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G., Lai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia, K., Doshi, K., Patel, M., Pal, K. K., Moradshahi, M., Parmar, M., Purohit, M., Varshney, N., Kaza, P. R., Verma, P., Puri, R. S., Karia, R., Sampat, S. K., Doshi, S., Mishra, S., Reddy, S., Patro, S., Dixit, T., Shen, X., Baral, C., Choi, Y, Smith, N. A., Hajishirzi, H., and Khashabi, D. Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks, 2022.

[37] Wei, J., Tay, Y, Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022.

[38] Yoo, K. M., Park, D., Kang, J., Lee, S.-W., and Park, W. Gpt3mix: Leveraging large-scale language models for text augmentation. arXiv preprint arXiv:2104.08826, 2021.

[39] Zhang, T., Wu, F., Katiyar, A., Weinberger, K. Q., and Artzi, Y. Revisiting Few-sample BERT Fine-tuning, March 2021. URL http://arxiv.org/abs/2006.05987. arXiv:2006.05987 [cs].

[40] Zheng, C., Sabour, S., Wen, J., Zhang, Z., and Huang, M. Augesc: Dialogue augmentation with large language models for emotional support conversation, 2023.

A Các Ví dụ Tạo ra Mẫu

Bảng 2: Ví dụ về gán nhãn cho WebNLG [15]. Các tài liệu tham khảo thực tế được hiển thị trong {dấu ngoặc nhọn}.

Đầu vào: [CONTEXT] WrittenWork [DATA] A_Glastonbury_Romance | mediaType | Hardcover A_Glastonbury_Romance | numberOfPages | 1174 | isbnNumber | 0-7156-3648-0
Đầu ra: A Glastonbury Romance, với 1144 trang, có sẵn bản in và có số ISBN 0-7156-3648.
{A Glastonbury Romance có số ISBN 0-7156-3648-0, có thể tìm thấy bản bìa cứng và có 1174 trang.}

Đầu vào: [CONTEXT] MeanOfTransportation [DATA] A-Rosa_Luna | builder | Germany MTU_Friedrichshafen | city | Friedrichshafen A-Rosa_Luna | powerType | MTU_Friedrichshafen
Đầu ra: A-Rosa Luna được thiết kế bởi MTU Friedrichshafen và được cung cấp năng lượng bởi họ. Thành phố Friedrichshafen là nơi nhà xây dựng của A-Rosa Luna đặt trụ sở.
{A-Rosa Luna được cung cấp năng lượng bởi động cơ MTU Friedrichshafen tại thành phố Friedrichshafen, Đức.}

Đầu vào: [CONTEXT] Astronaut [DATA] Alan_Bean | nationality | United_States Alan_Bean | occupation | Test_pilot Alan_Bean | almaMater | UT Austin, B.S. 1955 Alan_Bean | mission | Apollo_12 Alan_Bean | birthPlace | Wheeler,_Texas
Đầu ra: Alan Bean là công dân Hoa Kỳ, từng là sinh viên tại Đại học Texas ở Austin (B.S. 1955). Ông là phi công thử nghiệm người Mỹ và là thành viên của phi hành đoàn Apollo 12. Ông Bean được sinh ra tại Wheeler, Texas.
{Alan Bean là công dân Hoa Kỳ sinh ra tại Wheeler Texas. Ông phục vụ như một phi công thử nghiệm và là thành viên phi hành đoàn của sứ mệnh Apollo 12.}

Bảng 3: Ví dụ về tạo mới cho WebNLG [15].

Đầu vào: [CONTEXT] Astronaut [DATA] Elliot_See | almaMater | University_of_Texas_at_Austin University_of_Texas_at_Austin | affiliation | University_of_Texas_System Elliot_See | occupation | Test_pilot Elliot_See | nationality | United_States Elliot_See | birthPlace | Dallas Elliot_See | deathPlace | St._Louis Elliot_See | status | Deceased
Đầu ra: Elliot See là công dân Mỹ, sinh ra tại Dallas. Ông từng là sinh viên tại Đại học Texas ở Austin (liên kết với hệ thống đại học Texas). Ông là phi công thử nghiệm đã qua đời tại St. Louis.

Đầu vào: [CONTEXT] Airport [DATA] Al_Asad_Airbase | operatingOrganisation | United_States_Air_Force United_States_Air_Force | transportAircraft | Lockheed_C-130_Hercules
Đầu ra: Căn cứ không quân Al Asad được vận hành bởi Không quân Hoa Kỳ sử dụng Lockheed C-130 Hercules như máy bay vận tải.

Đầu vào: [CONTEXT] Food [DATA] Ajoblanco | ingredient | Almond Spain | leader | Felipe_VI_of_Spain Ajoblanco | region | Andalusia Andalusia | leader | Susana_Díaz Ajoblanco | country | Spain
Đầu ra: Ajoblanco có nguồn gốc từ Tây Ban Nha nơi Felipe VI là người lãnh đạo. Ajoblanco được tìm thấy ở Andalusia nơi Susana Diaz là người lãnh đạo. Một trong những thành phần của ajoblanco là hạnh nhân.

Bảng 4: Ví dụ về gán nhãn cho SGD [30]. Các tài liệu tham khảo thực tế được hiển thị trong {dấu ngoặc nhọn}.

Đầu vào: [CONTEXT] User: Tôi muốn tận dụng tối đa thời gian rảnh sắp tới bằng cách tìm điều gì đó thú vị để làm. Giả sử tôi không biết phải làm gì nhưng người bạn đáng tin cậy của tôi, đó là bạn, sẽ giúp tôi. Tôi nói đúng không?
Đầu ra: Tôi sẽ vui lòng giúp đỡ. Bạn có loại sự kiện nào trong đầu không?
{Chắc chắn, tôi sẽ vui lòng giúp bạn điều đó. Hãy bắt đầu với điều này: hãy cho tôi biết loại hoạt động và khu vực bạn quan tâm.}

Đầu vào: [CONTEXT] User: Bạn có thể tìm cho tôi chuyến bay một chiều không?
System: Bạn sẽ bay từ đâu?
User: Tôi bay từ LA.
System: Bạn muốn khởi hành khi nào?
User: Tôi cần khởi hành vào ngày 10 tháng này.
System: Bạn sẽ bay đến đâu.
User: Tôi bay đến Paris, Pháp với 4 người. Tôi ưa thích Delta Airlines.
Đầu ra: Vui lòng xác nhận điều sau: Bạn sẽ cần 1 vé hạng Phổ thông trên Delta Airlines. Bạn sẽ bay từ Los Angeles đến Paris vào ngày 10 tháng 3. Bạn sẽ đi cùng 4 người.
{Có một chuyến bay trực tiếp của Delta Airlines khởi hành lúc 8:25 sáng và có 0 điểm dừng với giá 255 đô la.}

Đầu vào: [CONTEXT] User: Tôi muốn tìm một chiếc xe thuê để đón ở New York.
System: Bạn cần nó khi nào?
User: Tôi muốn đón nó lúc 12 giờ trưa.
System: Bạn muốn trả xe vào ngày nào?
User: Tôi muốn trả nó vào ngày 9 tháng 3.
System: Bạn muốn đón nó vào ngày nào?
User: Tôi muốn đón nó vào thứ Sáu tuần tới.
System: Tôi tìm thấy một chiếc Honda Accord kích thước tiêu chuẩn cho bạn có sẵn tại Grand Central Station vào ngày 8 tháng 3, điều đó có phù hợp không?
User: Có gì khác không? Tôi muốn kích thước nhỏ gọn và thực sự sẽ cần nó đến ngày 10 tháng 3.
System: Chắc chắn, tôi tìm thấy một chiếc Chevrolet Bolt kích thước nhỏ gọn có sẵn tại Port Authority Station vào ngày 8 tháng 3, điều đó có phù hợp với bạn không?
User: Chi phí cho chiếc xe là bao nhiêu?
System: Tổng chi phí là 56 đô la.
User: Có gì có sẵn ở Paris, Pháp không?
Đầu ra: Có 10 chiếc xe có sẵn. Thế còn một chiếc Chevrolet Cruze kích thước nhỏ gọn thì sao? Nó có sẵn để đón từ Sân bay Quốc tế Charles de Gaulle vào ngày 8 tháng 3.
{Có, có một chiếc Honda Fit kích thước nhỏ gọn có sẵn tại Sân bay Quốc tế Charles de Gaulle vào ngày 8 tháng 3.}

Bảng 5: Ví dụ về tạo mới cho SGD [30].

Đầu vào: [CONTEXT] User: Tôi muốn ăn ở một nơi ở San Francisco.
System: Loại thức ăn nào? Bạn có thể nói Ấn Độ, Ý, Chay, hoặc gì khác.
User: Các món nhỏ sẽ hoàn hảo.
System: Aatxe có các món nhỏ và ở San Francisco.
User: Địa chỉ là gì và có nhạc sống không?
System: Địa chỉ của họ là 2174 Market Street và họ không có nhạc sống.
User: Còn gì khác không? Kiểm tra Redwood City.
System: La Viga Seafood & Cocina Mexicana ở Redwood City.
User: Vâng, điều đó sẽ hiệu quả.
System: Bạn có muốn đặt bàn không?
User: Không phải bây giờ. Bạn có thể tìm một salon ở Redwood City không?
System: August Barbershop ở Redwood City.
User: Vâng, tôi đã nghe nói về họ.
System: Tôi có nên đặt lịch hẹn không.
User: Làm ơn hãy làm, đặt nó lúc 2 giờ 30 chiều.
System: Bạn muốn đặt vào ngày nào?
User: Ngày 4 tháng 3 và đặt lúc 2 giờ chiều.
System: Vui lòng xác nhận điều sau: Đặt lịch hẹn với August Barbershop vào ngày 4 tháng 3 lúc 2 giờ chiều.
User: Không, làm cho ngày 1 tháng 3.
System: Vui lòng xác nhận điều sau: Đặt lịch hẹn với August Barbershop vào ngày 1 tháng 3.
User: Vâng, đó là chính xác.
System: Lịch hẹn của bạn đã thành công!
User: Bạn có thể thử đặt bàn tại nơi La Viga đó không?
System: Mấy giờ?
User: Lúc 6 giờ 30 tối.
System: Vui lòng xác nhận điều sau: Đặt bàn cho 2 người tại La Viga Seafood & Cocina Mexicana ở Redwood City vào ngày 1 tháng 3 lúc 6:30 tối.
User: Vâng, đó là chính xác.
System: Lịch hẹn của bạn đã thành công!
User: Bạn có thể thử đặt bàn cho 4 người vào ngày 7 tháng này không?
System: Vui lòng xác nhận điều sau: Đặt bàn cho 4 người tại La Viga Seafood & Cocina Mexicana ở Redwood City vào ngày 7 tháng 3.
User: Vâng, đó là chính xác.
System: Lịch hẹn của bạn đã thành công!
User: Cảm ơn rất nhiều.
Đầu ra: Bạn có cần gì khác không?

Đầu vào: [CONTEXT] User: Tôi đang tìm kiếm một số sự kiện.
System: Tôi nên tìm ở thành phố nào?
User: Tôi muốn xem gì đó ở New York City.
System: Bạn đang tìm kiếm loại sự kiện nào?
User: Tôi muốn xem Carmina Burana.
System: Tôi tìm thấy 2 lần xuất hiện của sự kiện Carmina Burana. Lần đầu tiên là tại Sony Hall vào ngày 5 tháng 3.
User: Địa chỉ của địa điểm là gì?
System: Địa điểm được đặt tại 235 West 46th Street.
User: Địa chỉ của địa điểm là gì?
System: Địa chỉ là 235 West 46th Street.
User: Điều đó nghe tuyệt vời.
System: Bạn có muốn mua vé không?
User: Không, tôi không muốn mua vé ngay bây giờ.
System: Có điều gì khác tôi có thể giúp bạn không?
User: Tôi muốn mua vé xe buýt để đến đó.
System: Bạn cần bao nhiêu vé? Bạn muốn khởi hành lúc nào?
User: Tôi cần vé hạng Phổ thông cho 4 người. Tôi muốn khởi hành lúc 1 giờ chiều.
System: Bạn sẽ khởi hành từ đâu?
User: Tôi khởi hành từ Washington.
System: Được rồi, tôi có 4 vé xe buýt hạng Phổ thông khởi hành từ Washington và đi đến New York vào ngày 5 tháng 3 lúc 1 giờ chiều. Điều đó có đúng không?
User: Vâng, điều đó nghe tốt. Xe buýt khởi hành từ ga nào và đến ga nào?
Đầu ra: Tôi đã mua vé. Xe buýt khởi hành từ Union Station và đến Port Authority Station.

Đầu vào: [CONTEXT] Tôi đang tìm kiếm một chiếc xe thuê.
System: Bạn muốn đón nó vào ngày và giờ nào? Bạn sẽ cần nó trong bao lâu?
User: Tôi cần nó lúc 3 giờ chiều ngày 8 tháng 3, đến ngày 11 tháng 3.
System: Bạn muốn đón nó ở đâu?
User: Tôi muốn lấy nó ở Anaheim, CA.
System: Tôi có 5 chiếc xe bạn có thể thích. Thế còn một chiếc Chevrolet Cruze tiêu chuẩn thì sao? Nó có sẵn tại Sân bay John Wayne vào ngày 8 tháng 3.
User: Bạn còn có gì khác?
System: Tôi có một chiếc Honda Accord tiêu chuẩn tại Sân bay John Wayne vào ngày 8 tháng 3.
User: Bạn còn có gì khác?
System: Tôi có một chiếc Toyota Camry tiêu chuẩn tại Anaheim Intermodal Center vào ngày 8 tháng 3.
User: Cái đó nghe tốt.
System: Bạn có muốn đặt trước không?
User: Vâng, hãy đặt trước.
System: Vui lòng xác nhận điều sau: Bạn đang thuê một chiếc xe tiêu chuẩn từ Anaheim Intermodal Center vào ngày 8 tháng 3 lúc 3 giờ chiều. Bạn sẽ trả nó vào ngày 11 tháng 3.
User: Thực ra, tôi muốn giữ nó đến ngày 12 tháng 3.
System: Vui lòng xác nhận các chi tiết sau: Bạn đang giữ xe đến ngày 12 tháng 3.
User: Đó là chính xác. Nó có giá bao nhiêu?
System: Xe của bạn đã được đặt trước. Tổng chi phí là 170 đô la.
User: Tôi muốn tìm một bộ phim gần đó.
System: Bạn có muốn tìm phim chiếu ở Anaheim không?
User: Vâng, đó là những gì tôi muốn.
System: Thế còn một số phim của Cameron Crowe thì sao? Ngoài ra còn có dogman, đó là một bộ phim chính kịch.
User: Còn gì khác không? Tôi muốn điều gì đó phù hợp với gia đình hơn.
System: Ngoài ra còn có Family, đó là một bộ phim hài.
User: Family nghe tốt.
System: Bạn có muốn mua vé không?
User: Không, không phải bây giờ.
Đầu ra: Có điều gì khác bạn cần không?

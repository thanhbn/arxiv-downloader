# 2303.05063.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl/2303.05063.pdf
# Kích thước file: 4092406 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
ICL-D3IE: Học trong ngữ cảnh với cập nhật các minh họa đa dạng cho trích xuất thông tin tài liệu

Jiabang He1, Lei Wang2*, Yi Hu1, Ning Liu3, Hui Liu4, Xing Xu1†, Heng Tao Shen1
1Trung tâm Truyền thông Tương lai & Trường Khoa học Máy tính và Kỹ thuật,
Đại học Khoa học và Công nghệ Điện tử Trung Quốc
2Đại học Quản lý Singapore, 3Đại học Lâm nghiệp Bắc Kinh
4Công ty Công nghệ Rongda Bắc Kinh

Tóm tắt
Các mô hình ngôn ngữ lớn (LLM), như GPT-3 và ChatGPT, đã thể hiện kết quả đáng chú ý trong nhiều tác vụ xử lý ngôn ngữ tự nhiên (NLP) với việc học trong ngữ cảnh, bao gồm suy luận dựa trên một số ví dụ minh họa. Mặc dù thành công trong các tác vụ NLP, chưa có nghiên cứu nào được thực hiện để đánh giá khả năng của LLM trong việc thực hiện trích xuất thông tin tài liệu (DIE) sử dụng học trong ngữ cảnh. Việc áp dụng LLM cho DIE đặt ra hai thách thức: khoảng cách về phương thức và khoảng cách về tác vụ. Để giải quyết điều này, chúng tôi đề xuất một khung học trong ngữ cảnh đơn giản nhưng hiệu quả gọi là ICL-D3IE, cho phép LLM thực hiện DIE với các loại ví dụ minh họa khác nhau. Cụ thể, chúng tôi trích xuất các đoạn khó khăn và khác biệt nhất từ các tài liệu huấn luyện khó làm minh họa khó để có lợi cho tất cả các trường hợp kiểm tra. Chúng tôi thiết kế các minh họa mô tả mối quan hệ giúp LLM hiểu các mối quan hệ vị trí. Chúng tôi giới thiệu các minh họa định dạng để trích xuất câu trả lời dễ dàng. Ngoài ra, khung cải thiện các minh họa đa dạng bằng cách cập nhật chúng một cách lặp đi lặp lại. Các thí nghiệm của chúng tôi trên ba bộ dữ liệu chuẩn được sử dụng rộng rãi chứng minh rằng khung ICL-D3IE cho phép Davinci-003/ChatGPT đạt được hiệu suất vượt trội khi so sánh với các phương pháp tiền huấn luyện trước đây được tinh chỉnh với đầy đủ huấn luyện trong cả thiết lập trong phân phối (ID) và thiết lập ngoài phân phối (OOD). Mã nguồn có sẵn tại https://github.com/MAEHCM/ICL-D3IE.

1. Giới thiệu
Tác vụ hiểu tài liệu giàu thị giác (VRDU), bao gồm việc trích xuất thông tin từ VRD [2,19], đòi hỏi các mô hình có thể xử lý nhiều loại tài liệu khác nhau, như giọng nói, biên lai, biểu mẫu, email và quảng cáo, cũng như nhiều loại thông tin khác nhau, bao gồm hình ảnh phong phú, lượng lớn văn bản và bố cục tài liệu phức tạp [28,18,26]. Gần đây, việc tinh chỉnh dựa trên các mô hình hiểu tài liệu thị giác được tiền huấn luyện đã mang lại kết quả ấn tượng trong việc trích xuất thông tin từ VRD [41,13,22,23,15,21], cho thấy việc sử dụng các tài liệu huấn luyện không nhãn quy mô lớn trong việc tiền huấn luyện các mô hình hiểu tài liệu có thể có lợi cho việc trích xuất thông tin từ VRD. Như được hiển thị trong Hình 1 (a), một mô hình được tiền huấn luyện như LayoutLMv3 [15] có thể dự đoán nhãn cho các thực thể trong VRD kiểm tra.

Các mô hình ngôn ngữ lớn (LLM), như GPT-3 [1], OPT [45], và PaLM [5], phát triển nhanh chóng và đã thể hiện

*Tác giả liên hệ. lei.wang.2019@phdcs.smu.edu.sg
†Tác giả liên hệ. xing.xu@uestc.edu.cn

(a) Mô hình hiểu tài liệu được tiền huấn luyện
(b) Mô hình ngôn ngữ lớn

OCR Ngữ cảnh 1: {text:"TAX 5.4",Box:[11,12,32,44]}... H:Nhãn cho những văn bản này là gì? T:SUB_TOTAL.TAX_PRICE,...

Ngữ cảnh n: {text:"J.S PR",Box:[13 525 469 555]}... H:Nhãn cho những văn bản này là gì? T:MENU.NM,...Ngữ cảnh: {text:"1X",Box:[11 13 10 40]}...

H:Nhãn cho những văn bản này là gì?+
...T:MENU.CNT,...

Ví dụ trong ngữ cảnh 1 Ví dụ trong ngữ cảnh n Ví dụ kiểm tra

Ví dụ kiểm tra B-MENU.CNT,... OCR LayoutLMv3/LayoutLMv2 ...GPT-3/ChatGPT

Hình 1: Hai cách tiếp cận để giải quyết tác vụ DIE: (a) các mô hình hiểu tài liệu được tiền huấn luyện trước đây [15, 42] được tinh chỉnh với các ví dụ huấn luyện đầy đủ, và (b) học trong ngữ cảnh trên LLM với một số ví dụ.

kết quả đáng chú ý trong nhiều tác vụ xử lý ngôn ngữ tự nhiên (NLP). Khi LLM phát triển về số lượng tham số mô hình và kích thước tập huấn luyện, chúng cho thấy các khả năng nổi lên cho phép chúng học suy luận chỉ từ một số ví dụ minh họa trong ngữ cảnh cho trước [38]. Mô hình học này được gọi là học trong ngữ cảnh (ICL) [8]. Gần đây, các cách tiếp cận [43,14] đã được đề xuất để khám phá cách sử dụng LLM để giải quyết các tác vụ thị giác-ngôn ngữ (VL). Tuy nhiên, cho đến nay, chưa có nghiên cứu nào về khả năng của LLM trong việc xử lý các tác vụ hiểu VRD, như trích xuất thông tin tài liệu (DIE). Tương tự như VQA [12], hai thách thức chính phát sinh khi áp dụng LLM cho DIE: khoảng cách về phương thức và khoảng cách về tác vụ, vì LLM không thể xử lý trực tiếp hình ảnh và có thể thiếu huấn luyện về thông tin bố cục trong VRD.

Để giải quyết những thách thức này, một chiến lược phổ biến trong việc sử dụng LLM cho tác vụ VQA là sử dụng các cặp QA minh họa và chuyển đổi các hình ảnh tương ứng thành các mô tả hình ảnh thông qua các mô hình chú thích hình ảnh [43,14]. Sau đó, các cặp QA minh họa và mô tả hình ảnh được kết hợp làm gợi ý cho LLM để trả lời câu hỏi kiểm tra. Hình 1 (b) hiển thị chiến lược đơn giản này để áp dụng LLM cho tác vụ DIE. Đầu tiên, nó sử dụng các công cụ Nhận dạng Ký tự Quang học (OCR) để chuyển đổi hình ảnh của các tài liệu minh họa từ dữ liệu huấn luyện thành nội dung văn bản và các hộp thực thể tương ứng. Các minh họa được chuyển đổi với nhãn thực thể sau đó được kết hợp làm gợi ý cho LLM để dự đoán nhãn cho các thực thể trong tài liệu kiểm tra. Tuy nhiên, chiến lược này có thể hoạt động kém, vì nó bỏ qua các mối quan hệ vị trí giữa các nội dung văn bản và nhạy cảm với các ví dụ được chọn cho các minh họa.

Trong bài báo này, chúng tôi đề xuất ICL-D3IE, một khung học trong ngữ cảnh đơn giản và hiệu quả cho LLM để thực hiện tác vụ DIE với nhiều loại ví dụ minh họa khác nhau trong ngữ cảnh cho trước. Phương pháp của chúng tôi xây dựng các loại minh họa khác nhau dựa trên ba tiêu chí: (1) các minh họa nên có lợi cho tất cả các tài liệu kiểm tra thay vì chỉ một tập con của chúng, (2) thông tin bố cục phải được bao gồm, và (3) các minh họa nên dự đoán nhãn trong định dạng dễ trích xuất. Để xây dựng các minh họa khó cho tiêu chí đầu tiên, chúng tôi chọn các đoạn thách thức từ các tài liệu huấn luyện khó để LLM dự đoán chính xác các thực thể. Để xây dựng các minh họa nhận thức bố cục cho tiêu chí thứ hai, chúng tôi sử dụng câu hỏi gợi ý để hướng dẫn LLM mô tả các mối quan hệ vị trí giữa các hộp nội dung văn bản trong các vùng được chọn. Để tạo các minh họa định dạng cho tiêu chí thứ ba, chúng tôi chọn ngẫu nhiên các đoạn huấn luyện để hướng dẫn LLM dự đoán nhãn trong định dạng mong muốn để trích xuất dễ dàng. Hơn nữa, khung cải thiện lặp đi lặp lại các minh họa đa dạng bằng cách cập nhật các minh họa khó thông qua học trong ngữ cảnh với các minh họa đa dạng trước đó.

Các thí nghiệm được thực hiện trên ba bộ dữ liệu chuẩn được sử dụng rộng rãi (FUNSD [18], CORD [28], và SROIE [16]), chứng minh rằng ICL-D3IE cho phép LLM đạt được hiệu suất DIE vượt trội hoặc tương đương với các phương pháp tiền huấn luyện trước đây được tinh chỉnh với các mẫu huấn luyện đầy đủ khi được kiểm tra trong thiết lập trong phân phối (ID). Ví dụ, ICL-D3IE với GPT-3 (97.88%) vượt trội hơn LayoutLMv3 base (96.89%) trên SROIE. Hơn nữa, trong thiết lập ngoài phân phối (OOD), ICL-D3IE hoạt động tốt hơn nhiều so với các phương pháp tiền huấn luyện trước đây trên tất cả các bộ dữ liệu, đạt được hiệu suất vượt trội. Những kết quả đáng chú ý này khuyến khích những cách mới để tận dụng LLM cho việc giải quyết các tác vụ liên quan đến VRD.

2. Công trình liên quan
Hiểu tài liệu giàu thị giác (VRDU). Chủ đề nghiên cứu VRDU đã là một lĩnh vực nghiên cứu đầy thách thức trong nhiều năm, với nhiều phương pháp nhận dạng thực thể có tên (NER) được đề xuất dựa trên mạng nơ-ron, như mạng nơ-ron hồi quy [20]. Tuy nhiên, hầu hết các phương pháp này chỉ xác định thông tin chính trong văn bản thuần túy, bỏ qua thông tin thị giác và bố cục có trong tài liệu. Để giải quyết vấn đề này, các mạng nơ-ron tích chập và đồ thị đã được giới thiệu để mô hình hóa thông tin bố cục và ngữ nghĩa [46,24]. Gần đây, tiền huấn luyện và tinh chỉnh tự giám sát đa phương thức đã chứng minh hiệu quả trong các tài liệu giàu thị giác bằng cách mô hình hóa thông tin thị giác, bố cục và văn bản [40,35,11,36,15]. Huang et al. [15] được truyền cảm hứng bởi Vision Transformer (ViT) [10] để sử dụng các embedding cấp patch để học các đặc trưng thị giác trong LayoutLMv3. DIE bao gồm việc tự động trích xuất thông tin từ VRD. Mục tiêu là xác định thông tin có giá trị trong những tài liệu phức tạp này và tổ chức nó theo định dạng có thể được phân tích và sử dụng dễ dàng. Quá trình trích xuất thông tin từ VRD đòi hỏi hai bước thiết yếu: (1) phát hiện và nhận dạng văn bản trong hình ảnh tài liệu, và (2) gán nhãn thực thể cho văn bản được nhận dạng. Bước đầu tiên thuộc lĩnh vực nghiên cứu được gọi là nhận dạng ký tự quang học. Nghiên cứu này tập trung vào bước thứ hai và chủ yếu thảo luận về cách tận dụng GPT-3 để gán nhãn chính xác các thực thể trong văn bản được nhận dạng.

Học trong ngữ cảnh. LLM như GPT-3 [1], OPT [45], và PaLM [5] thể hiện các khả năng nổi lên khi kích thước mô hình và tập văn bản tăng lên [38]. Những khả năng này được học từ các minh họa chứa một số ví dụ trong ngữ cảnh, được gọi là học trong ngữ cảnh [8]. Để cho phép suy luận trong LLM, [39] đề xuất gợi ý Chuỗi Suy nghĩ (CoT), thêm nhiều bước suy luận vào câu hỏi đầu vào. Gợi ý CoT là một chiến lược gợi ý few-shot đơn giản và hiệu quả cải thiện hiệu suất của LLM trong các tác vụ suy luận phức tạp. Một số công trình [34,32,31] từ đó đã nhằm cải thiện gợi ý CoT trong các khía cạnh khác nhau, như định dạng gợi ý [4], lựa chọn gợi ý [25], tập hợp gợi ý [37], và phân tách vấn đề [47]. Trong khi LLM ban đầu được phát triển cho các tác vụ NLP, các nghiên cứu gần đây [43,3,44] đã cho thấy LLM với học trong ngữ cảnh có khả năng few-shot hoặc zero-shot cho các vấn đề đa phương thức, bao gồm các tác vụ trả lời câu hỏi thị giác. Hơn nữa, Frozen [33] thể hiện hiệu suất few-shot đầy hứa hẹn sử dụng các mô hình được tiền huấn luyện cho các tác vụ thị giác và ngôn ngữ. Tuy nhiên, theo hiểu biết của chúng tôi, công trình của chúng tôi là đầu tiên khám phá việc sử dụng LLM với học trong ngữ cảnh cho trích xuất thông tin từ VRD. Bạn có thể tham khảo [9] để biết thêm các công trình liên quan về học trong ngữ cảnh.

3. Phương pháp ICL-D3IE của chúng tôi
3.1. Sơ bộ về học trong ngữ cảnh
Học trong ngữ cảnh cho phép LLM nhanh chóng thích ứng để giải quyết các tác vụ downstream chỉ sử dụng một số ví dụ trong quá trình suy luận [1], không cần huấn luyện. Ngược lại, việc tinh chỉnh LLM đòi hỏi huấn luyện trên càng nhiều mẫu càng tốt, dẫn đến chi phí tính toán và thời gian dư thừa. Phần này mô tả cách công thức hóa học trong ngữ cảnh để giải quyết tác vụ DIE.

Một mẫu dữ liệu bao gồm một hình ảnh tài liệu I và các nhãn thực thể tương ứng Y={y1, y2, ..., yL}, trong đó L là số lượng thực thể trong tài liệu. Để lấy nội dung văn bản và các hộp tương ứng, chúng tôi xử lý hình ảnh tài liệu I bằng công cụ OCR. Chúng tôi ký hiệu tập hợp các nội dung văn bản là T={t1, t2, ..., tL}, trong đó tl là một đoạn từ, và ký hiệu tập hợp các hộp tương ứng là B={b1, b2, ..., bL}, trong đó bl là tọa độ pl1, pl2, pl3, pl4 ∈ Z4 của hộp bl. Lưu ý rằng thứ tự của T là quan trọng vì GPT-3 nhạy cảm với việc hoán vị từ. Chúng tôi theo cách tiếp cận của XYLayoutLM [11] và sử dụng thuật toán XYCut để xác định thứ tự của các vùng văn bản. Tác vụ DIE (Bài báo này xem xét tác vụ gán nhãn thực thể trong VRD) bao gồm việc tạo nhãn Y cho các thực thể T đã cho trong hình ảnh tài liệu I bằng cách tối đa hóa xác suất có điều kiện như sau: p(Y|T) = 1/L ∑L l p(yl|tl).

Trong khi các nghiên cứu tiên tiến trước đây [40,11] thường tinh chỉnh các mô hình được tiền huấn luyện cho các tác vụ downstream, bài báo này đề xuất sử dụng LLM với học trong ngữ cảnh để giải quyết tác vụ DIE. Cụ thể, chúng tôi định nghĩa xác suất tạo nhãn thực thể mục tiêu Y cho hình ảnh tài liệu I và chuỗi trong ngữ cảnh C đã cho bằng LLM Plm như sau:

p(Y|I, C) = ∑L l=1 Plm(V(yl)|C,T(I)). (1)

Ở đây, T(·) ký hiệu một tập hợp các thao tác được sử dụng để chuyển đổi hình ảnh tài liệu gốc thành định dạng văn bản như GPT-3 mong muốn, C là các ví dụ trong ngữ cảnh được lấy bằng cách nối k ví dụ minh họa đầu vào-đầu ra {(T(I1), Y1),(T(I2), Y2), . . . , (T(Ik), Yk)}, và V là thao tác ánh xạ nhãn thực thể yl thành các từ ngôn ngữ tự nhiên mà GPT-3 có thể hiểu.

3.2. Khung tổng quan của ICL-D3IE
Chúng tôi trình bày ICL-D3IE, một khung học trong ngữ cảnh mới để giải quyết tác vụ DIE, cho phép GPT-3 dự đoán nhãn thực thể trong tài liệu kiểm tra dựa trên các loại minh họa khác nhau. Việc xây dựng minh họa được thiết kế để thỏa mãn ba tiêu chí: (i) các minh họa nên có lợi cho tất cả các tài liệu kiểm tra, không chỉ một tập con, (ii) chúng nên bao gồm thông tin bố cục, điều cần thiết để giải quyết các tác vụ liên quan đến VRD, và (iii) chúng nên dự đoán nhãn thực thể trong định dạng dễ trích xuất và đánh giá.

Khung ICL-D3IE được đề xuất bao gồm bốn bước chính như được hiển thị trong Hình 2. Đầu tiên, khung chọn n tài liệu huấn luyện tương tự nhất với n tài liệu kiểm tra. Thứ hai, ICL-D3IE xây dựng các minh họa đa dạng dựa trên các tài liệu huấn luyện tương tự được chọn. Những minh họa này bao gồm các minh họa khó ban đầu cho tiêu chí (i), các minh họa nhận thức bố cục cho tiêu chí (ii), và các minh họa định dạng cho tiêu chí (iii). Thứ ba, khung cập nhật lặp đi lặp lại các minh họa đa dạng bằng cách cải thiện các minh họa khó thông qua học trong ngữ cảnh với các minh họa đa dạng trước đó. Cuối cùng, ICL-D3IE thực hiện suy luận sử dụng học trong ngữ cảnh với các minh họa đa dạng đã cập nhật.

3.3. Lựa chọn tài liệu láng giềng gần nhất
Để tạo điều kiện cho học trong ngữ cảnh hiệu quả, ICL-D3IE được đề xuất chọn n tài liệu huấn luyện tương tự nhất với n tài liệu kiểm tra. Quá trình này bao gồm nhiều bước. Đầu tiên, chúng tôi tận dụng các công cụ OCR để chuyển đổi m tài liệu huấn luyện và n tài liệu kiểm tra thành văn bản thuần túy với thông tin hộp tương ứng. Sau đó, văn bản thuần túy được đưa vào SentenceBERT [30] để lấy biểu diễn tài liệu, và điểm tương đồng cosine được tính toán để xác định tài liệu huấn luyện tương tự nhất cho mỗi tài liệu kiểm tra. Cuối cùng, chúng tôi có thể xác định n tài liệu huấn luyện khớp gần nhất với n tài liệu kiểm tra, mà chúng tôi gọi là các tài liệu láng giềng gần nhất Innd1, Innd2, . . . , Inndn.

3.4. Xây dựng minh họa đa dạng
Khi chúng tôi đã có n tài liệu láng giềng gần nhất từ bộ dữ liệu huấn luyện, chúng tôi xây dựng các minh họa đa dạng cho học trong ngữ cảnh hiệu quả. Cách tiếp cận tiêu chuẩn để xây dựng các minh họa trong ngữ cảnh bao gồm việc thiết kế mẫu cho tác vụ mục tiêu để chuyển đổi các ví dụ dữ liệu thành văn bản mà LLM có thể xử lý. Khác với học trong ngữ cảnh tiêu chuẩn chỉ dựa vào các minh họa cụ thể cho tác vụ, ICL-D3IE xây dựng các minh họa đa dạng cho mỗi trường hợp kiểm tra: các minh họa khó làm nổi bật các khía cạnh thách thức của tác vụ, các minh họa nhận thức bố cục mô tả mối quan hệ vị trí giữa các nội dung văn bản, và các minh họa định dạng cung cấp ví dụ định dạng đầu ra.

Minh họa khó ban đầu. Tiêu chí đầu tiên để chọn minh họa khó là chúng nên làm nổi bật các khía cạnh thách thức nhất của tác vụ DIE để có lợi cho tất cả các tài liệu kiểm tra. Quá trình lấy minh họa khó ban đầu bao gồm nhiều bước. Đầu tiên, chúng tôi sử dụng kỹ thuật gợi ý zero-shot, bao gồm việc sử dụng gợi ý như "Nhãn cho những văn bản này là gì?" pt0 để yêu cầu GPT-3 dự đoán nhãn cho các thực thể trong Inndi. Tiếp theo, chúng tôi tính điểm F1 cấp thực thể dựa trên nhãn dự đoán và nhãn ground truth tương ứng. Sau đó, chúng tôi xác định đoạn văn bản thard với điểm F1 thấp nhất từ các tài liệu láng giềng gần nhất. Một minh họa khó ban đầu có thể được công thức hóa như sau:

Chard,0 = CONCAT(thard, bhard, pt0, yhard), (2)

trong đó bhard và yhard lần lượt là tọa độ hộp và câu trả lời của đoạn văn bản thard.

Minh họa nhận thức bố cục. Tiêu chí thứ hai đòi hỏi việc bao gồm thông tin bố cục trong các minh họa trong ngữ cảnh, điều quan trọng để hoàn thành tác vụ DIE. Để có được các minh họa có ý thức về bố cục, chúng tôi chọn ngẫu nhiên các đoạn khó liền kề được lấy trong việc xây dựng Chard,0 để tạo một vùng Rl cho mô tả mối quan hệ vị trí. Chúng tôi sử dụng gợi ý "Vui lòng mô tả mối quan hệ vị trí của những văn bản này" ptl để hướng dẫn GPT-3 tạo mô tả ỹl về mối quan hệ vị trí giữa các đoạn văn bản trong Rl. Một minh họa nhận thức bố cục có thể được công thức hóa như sau:

Cl = CONCAT(Rl, Bl, ptl, ỹl), (3)

trong đó Bl là tọa độ hộp cho các đoạn văn bản của vùng được chọn Rl.

Minh họa định dạng. Tiêu chí thứ ba mong đợi cung cấp ví dụ để hướng dẫn GPT-3 định dạng đầu ra cho tác vụ DIE. Để đạt được điều này, chúng tôi đầu tiên chọn ngẫu nhiên một đoạn văn bản tf từ các tài liệu láng giềng gần nhất. Sau đó, một minh họa định dạng Cf bao gồm một đoạn văn bản tf, tọa độ hộp tương ứng bf, gợi ý định dạng pt0, và câu trả lời ground truth yf, được ký hiệu là Cf:

Cf = CONCAT(tf, bf, pt0, yf). (4)

Ánh xạ nhãn. Mục tiêu của ánh xạ nhãn là dịch các nhãn từ không tự nhiên thành không gian trả lời nơi GPT-3 có thể hoạt động hiệu quả như một mô hình dự đoán. Để đạt được điều này, chúng tôi thu thập các mô tả văn bản của các nhãn gốc từ các bộ dữ liệu được cung cấp, như "total.cash price" đại diện cho "số tiền được thanh toán bằng tiền mặt." Sau đó, chúng tôi bao gồm các nhãn gốc (Y') và các mô tả tương ứng (Y) trong ngữ cảnh trước các minh họa khác nhau để gợi ý GPT-3 giải quyết mẫu kiểm tra. Ánh xạ nhãn cho gợi ý có thể được công thức hóa như sau:

Cm = CONCAT(Y', Y). (5)

3.5. Cập nhật minh họa đa dạng
Để làm nổi bật thêm các khía cạnh thách thức nhất của tác vụ DIE, ICL-D3IE cập nhật lặp đi lặp lại các minh họa đa dạng của mình bằng cách cải thiện các minh họa khó thông qua học trong ngữ cảnh với các minh họa đa dạng trước đó. Các minh họa đa dạng ban đầu với các minh họa khó ban đầu Chard,0 được sử dụng để thực hiện suy luận cho tất cả các tài liệu láng giềng gần nhất Innd1, Innd2, . . . , Inndn. Điểm F1 cấp thực thể được tính toán cho tất cả các thực thể, và đoạn văn bản với điểm F1 thấp nhất được thêm vào các minh họa khó ban đầu để có được các minh họa khó mới Chard,1. Quá trình này được lặp lại k lần để có được các minh họa khó cuối cùng đã cập nhật Chard,k, được sử dụng để xây dựng các minh họa đa dạng cuối cùng.

3.6. Suy luận
Sau khi cập nhật minh họa đa dạng, các minh họa đa dạng và toàn diện thu được có thể được sử dụng để hướng dẫn GPT-3 thực hiện kiểm tra, được công thức hóa như sau:

p(Y|I, C) = 1/L ∑L l=1 Plm(V(yl)|Cm, Chard,k, Cl, Cf, T(I)). (6)

Cuối cùng, ICL-D3IE trích xuất các câu trả lời tương ứng từ các dự đoán được tạo và sau đó chuyển đổi chúng thành định dạng phù hợp để đánh giá.

4. Thí nghiệm
4.1. Thiết lập thí nghiệm
Bộ dữ liệu. Chúng tôi thử nghiệm trên ba bộ dữ liệu DIE được sử dụng rộng rãi. Dưới đây là giới thiệu ngắn gọn về các bộ dữ liệu này: Bộ dữ liệu FUNSD [17] là bộ dữ liệu hiểu biểu mẫu quét nhiễu. Nó bao gồm 199 tài liệu với bố cục khác nhau và tổng cộng 9,707 chú thích thực thể ngữ nghĩa. Trong nghiên cứu của chúng tôi, chúng tôi tập trung vào tác vụ gán nhãn thực thể ngữ nghĩa, bao gồm việc gán nhãn như "question," "answer," "header," hoặc "other" cho mỗi thực thể ngữ nghĩa. Tập huấn luyện bao gồm 149 mẫu, và tập kiểm tra bao gồm 50 mẫu. Bộ dữ liệu CORD [29] là bộ dữ liệu hiểu biên lai tổng hợp bao gồm 800 biên lai để huấn luyện, 100 biên lai để xác thực, và 100 biên lai để kiểm tra. Các nhãn trong bộ dữ liệu này có hệ thống phân cấp, bao gồm 30 nhãn ngữ nghĩa dưới bốn danh mục. Tuy nhiên, các nhãn phức tạp hơn so với bộ dữ liệu FUNSD và đòi hỏi ánh xạ nhãn. Bộ dữ liệu SROIE [16] là một bộ dữ liệu hiểu biên lai khác, bao gồm 973 biên lai được phân loại thành bốn lớp. Bộ dữ liệu bao gồm 626 hình ảnh huấn luyện và 347 hình ảnh kiểm tra. Các nhãn trong bộ dữ liệu này là "company," "date," "address," và "total."

Baseline. Chúng tôi so sánh ICL-D3IE với ba loại baseline. Loại đầu tiên bao gồm các mô hình được tiền huấn luyện mạnh được tinh chỉnh với các mẫu huấn luyện đầy đủ, trong khi loại thứ hai bao gồm những mô hình được tinh chỉnh chỉ với một số mẫu. Loại thứ ba bao gồm học trong ngữ cảnh tiêu chuẩn, trong đó một trong các minh họa bao gồm nội dung văn bản của một tài liệu, tọa độ hộp tương ứng, câu hỏi gợi ý pt0, và các câu trả lời ground truth tương ứng.

Đối với baseline được tiền huấn luyện dựa trên văn bản, chúng tôi so sánh phương pháp của chúng tôi với BERT [6]. Đối với các baseline được tiền huấn luyện dựa trên văn bản và bố cục, chúng tôi sử dụng LiLT [35] và BROS [13]. LiLT sử dụng transformer bố cục độc lập với ngôn ngữ tách biệt các phương thức văn bản và bố cục. BROS là một mô hình trích xuất thông tin chính được tiền huấn luyện mã hóa thông tin bố cục tương đối. Hơn nữa, chúng tôi cũng xem xét các baseline được tiền huấn luyện sử dụng các phương thức văn bản, bố cục và hình ảnh, bao gồm LayoutLM [40], XYLayoutLM [11], LayoutLMv2 [42], và LayoutLMv3 [15]. LayoutLM sử dụng hai mục tiêu để học biểu diễn ngôn ngữ trong quá trình tiền huấn luyện và tích hợp thông tin hình ảnh trong giai đoạn tinh chỉnh. XYLayoutLM sử dụng thuật toán tiền xử lý gọi là Augmented XY Cut để tạo thứ tự đọc phù hợp. LayoutLMv2 sử dụng CNN để mã hóa hình ảnh tài liệu và sử dụng thông tin hình ảnh trong giai đoạn tiền huấn luyện. Cuối cùng, LayoutLMv3 có thể mô hình thông tin tài liệu cấp patch.

Chi tiết thực hiện. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng GPT-3 text-davinci-003 (175B) và ChatGPT gpt-3.5-turbo công khai với API làm mô hình ngôn ngữ xương sống do tính phổ biến và khả năng tiếp cận của chúng. Để đảm bảo đầu ra nhất quán, chúng tôi đặt tham số nhiệt độ thành 0. Để đánh giá, chúng tôi sử dụng các chỉ số tương tự như trong LayoutLMv3 và báo cáo F1 cấp thực thể cho tất cả các phương pháp. Đối với phương pháp ICL-D3IE của chúng tôi, chúng tôi sử dụng 4 minh họa khó, 4 minh họa nhận thức bố cục, và 4 minh họa định dạng. Đối với các baseline dựa trên tinh chỉnh, chúng tôi áp dụng các siêu tham số được báo cáo trong các bài báo gốc của chúng. Lưu ý rằng các minh họa của chúng tôi có thể là các đoạn, và chúng tôi sử dụng các ví dụ tài liệu bao gồm các đoạn được sử dụng trong phương pháp của chúng tôi để tinh chỉnh các mô hình baseline few-shot nhằm đảm bảo so sánh công bằng. Để chứng minh khả năng tổng quát của học trong ngữ cảnh trên LLM, chúng tôi tạo dữ liệu kiểm tra ngoài phân phối (OOD) cho ba bộ dữ liệu chuẩn bằng TextAttack [27]. Dữ liệu kiểm tra gốc cho các bộ dữ liệu này được gọi là dữ liệu kiểm tra trong phân phối (ID). Cụ thể, chúng tôi thay thế các từ gốc bằng các từ gần như giống hệt về ngoại hình nhưng khác về ý nghĩa và xóa một số ký tự trong từ, như "name" → "nme," để tạo các mẫu OOD.

4.2. Kết quả chính
Bảng 1 trình bày so sánh hiệu suất của ICL-D3IE với các phương pháp baseline huấn luyện đầy đủ và few-shot hiện có trên cả thiết lập trong miền (ID) và ngoài miền (OOD). Chúng ta có thể quan sát đầu tiên rằng trên thiết lập ID, ICL-D3IE (Davinci-003) đạt được trạng thái nghệ thuật mới trên các bộ dữ liệu FUNSD và SROIE chỉ với một số ví dụ dữ liệu và không cần huấn luyện. Nó đạt 90.32% trên FUNSD và 97.88% trên SROIE, vượt trội hơn tất cả các VDU khác đạt SOTA. Trên bộ dữ liệu SROIE, ICL-D3IE (Davinci-003) đạt trong vòng 3% hiệu suất tiên tiến, tương đương với các mô hình VDU được tiền huấn luyện được tinh chỉnh với các mẫu huấn luyện đầy đủ. Mặt khác, ICL-D3IE có những cải thiện hiệu suất lớn cho DIE trong thiết lập few-shot. Ví dụ, trong CORD, hiệu suất trung bình tăng gấp đôi so với VDU trong thiết lập few-shot. Trong khi đó, so với các baseline huấn luyện đầy đủ khác, ICL-D3IE có độ bền vững lớn hơn đối với lỗi OCR trong nội dung tài liệu trên thiết lập OOD, dẫn đến hiệu suất tốt hơn đáng kể.

Hơn nữa, chúng ta có thể thấy rằng ICL-D3IE vượt trội hơn ICL tiêu chuẩn trên ba bộ dữ liệu, với ICL-D3IE (Davinci-003) cho thấy cải thiện điểm F1 18.8 so với ICL tiêu chuẩn (Davinci-003) trên FUNSD. Chúng tôi thử nghiệm với GPT-3 (text-davinci-003) và ChatGPT (gpt-3.5-turbo) để điều tra khả năng áp dụng của ICL-D3IE với các mô hình ngôn ngữ xương sống khác nhau và thấy rằng ICL-D3IE cải thiện đáng kể hiệu suất của ChatGPT so với ICL tiêu chuẩn. Tuy nhiên, tính linh hoạt trong việc tạo của ChatGPT làm cho việc trích xuất câu trả lời khó hơn, dẫn đến hiệu suất hơi kém hơn cho ICL-D3IE (ChatGPT) so với ICL-D3IE (Davinci-003). Những kết quả đầy hứa hẹn này chứng minh tính hiệu quả của ICL-D3IE cho tác vụ DIE và tính linh hoạt của nó trên các mô hình ngôn ngữ xương sống khác nhau.

Nhìn chung, phương pháp ICL-D3IE của chúng tôi cho thấy sự vượt trội nhất quán so với các phương pháp khác trên tất cả các bộ dữ liệu và thiết lập ngoại trừ thiết lập ID trên CORD, cho thấy tiềm năng của nó trong việc giải quyết hiệu quả các tác vụ liên quan đến VRD bằng LLM. Những kết quả đáng chú ý này không chỉ làm nổi bật tính hiệu quả của ICL-D3IE mà còn truyền cảm hứng cho việc phát triển các phương pháp mới với LLM đòi hỏi ít nỗ lực thủ công hơn.

4.3. Phân tích sâu hơn
Trong phần này, chúng tôi thực hiện phân tích chi tiết về ICL-D3IE và các thành phần của nó.

Tác động của các thành phần khác nhau trong minh họa đa dạng. Các minh họa của ICL-D3IE bao gồm bốn thành phần: minh họa khó, minh họa nhận thức bố cục, minh họa định dạng, và ánh xạ nhãn. Trong phần này, chúng tôi đánh giá tác động của mỗi thành phần bằng cách loại bỏ từng thành phần một và đo lường tác động đến hiệu suất ICL-D3IE (Davinci-003).

Như được hiển thị trong Bảng 2, việc loại bỏ bất kỳ thành phần nào đều làm giảm hiệu suất DIE. Việc loại bỏ minh họa khó có tác động đáng kể nhất, cho thấy tính hiệu quả của các minh họa khó được cập nhật lặp đi lặp lại trong việc có lợi cho tất cả các mẫu kiểm tra. Việc loại bỏ minh họa nhận thức bố cục dẫn đến sự sụt giảm khoảng 10 điểm F1 trên CORD nhưng ít trên SROIE vì nhãn CORD đòi hỏi nhiều thông tin bố cục hơn SROIE. Việc loại bỏ ánh xạ nhãn dẫn đến sự sụt giảm đáng kể trong CORD do các nhãn không tự nhiên của nó. Hiệu suất của ICL-D3IE mà không có ánh xạ nhãn cho thấy các minh họa định dạng góp phần vào việc trích xuất câu trả lời dễ dàng và tốt hơn. Đáng chú ý, ICL-D3IE (Davinci-003) vượt trội hơn ICL tiêu chuẩn (Davinci-003) (Bảng 1), ngay cả khi loại bỏ một thành phần. Nhìn chung, những kết quả này làm nổi bật tính hiệu quả của mỗi thành phần trong các minh họa trong ngữ cảnh của ICL-D3IE.

Tác động của số lượng mỗi loại minh họa. Trong Bảng 1, chúng tôi đặt số lượng các loại minh họa khác nhau trong ICL-D3IE là 4. Tuy nhiên, việc thay đổi số lượng mỗi loại minh họa trong các minh họa đa dạng trong ngữ cảnh có thể dẫn đến kết quả hiệu suất khác nhau. Để điều tra điều này, chúng tôi thay đổi số lượng của một loại minh họa cụ thể từ 0 đến 4 trong khi giữ số lượng các loại minh họa khác không đổi ở mức 4.

Chúng tôi trình bày điểm F1 của ICL-D3IE (Davinci-003) trên CORD trong Hình 4a. Chúng ta có thể quan sát rằng số lượng minh họa của mỗi loại ảnh hưởng đến hiệu suất của ICL-D3IE. Ngoài ra, hiệu suất cải thiện khi số lượng bất kỳ minh họa nào tăng lên. Thú vị, chúng tôi quan sát những thay đổi đáng kể trong hiệu suất khi thay đổi số lượng minh họa khó và minh họa nhận thức bố cục, cho thấy rằng các minh họa khó có lợi cho việc giải quyết tất cả các mẫu kiểm tra và tác vụ DIE trên CORD đòi hỏi một lượng đáng kể thông tin bố cục để giải quyết.

Tác động của số lượng cập nhật minh họa khó. Nghiên cứu này nhằm điều tra tác động của số lượng cập nhật minh họa khó trên ba bộ dữ liệu khác nhau. Như được làm nổi bật trong Hình 4b, các minh họa khó ban đầu có thể giúp ICL-D3IE hoạt động rất tốt, và các minh họa khó sau 20 lần lặp có thể đạt được hiệu suất tốt hơn. Những phát hiện này chứng minh rằng việc tích hợp phản hồi từ các khía cạnh thách thức, như được xác định thông qua dự đoán trên dữ liệu huấn luyện, vào gợi ý cho LLM là một chiến lược hữu ích có thể có lợi cho việc giải quyết tất cả các mẫu kiểm tra. Ngoài ra, việc cập nhật minh họa khó thông qua học trong ngữ cảnh với các minh họa đa dạng trước đó có thể nâng cao hiệu suất của ICL-D3IE (Davinci-003).

Tác động của thứ tự minh họa đa dạng. Nghiên cứu này điều tra tác động của thứ tự khác nhau của các minh họa đến hiệu suất ICL-D3IE (Davinci-003). Cụ thể, chúng tôi thay đổi thứ tự của các minh họa khó và minh họa nhận thức bố cục và đánh giá hai thứ tự khác nhau: M-H-L-F (ánh xạ nhãn, minh họa khó, minh họa nhận thức bố cục, và minh họa định dạng) và M-L-H-F (ánh xạ nhãn, minh họa nhận thức bố cục, minh họa khó, và minh họa định dạng).

Hình 5a trình bày so sánh hiệu suất của hai thứ tự này. Trong trường hợp của chúng tôi, M-H-L-F nhất quán vượt trội hơn M-L-H-F trên tất cả ba bộ dữ liệu. Điều này cho thấy rằng học trong ngữ cảnh rất nhạy cảm với thứ tự của các minh họa và việc tìm ra thứ tự tối ưu cho học trong ngữ cảnh là quan trọng. Nghiên cứu của chúng tôi làm nổi bật tầm quan trọng của việc tối ưu hóa thứ tự của các minh họa cho học trong ngữ cảnh, và điều này sẽ là trọng tâm của nghiên cứu tương lai của chúng tôi.

Tác động của số lượng ví dụ minh họa. Để đánh giá thêm hiệu suất của ICL-D3IE so với các mô hình VRDU được tiền huấn luyện được tinh chỉnh với một số minh họa, chúng tôi thay đổi số lượng minh họa cho ICL-D3IE (Davinci-003), ICL-D3IE (ChatGPT), và LayoutLMv3 từ 1 đến 12. Hình 5b chứng minh rằng hiệu suất của cả ba phương pháp đều cải thiện khi số lượng minh họa tăng lên trên CORD. Đáng chú ý, ICL-D3IE (Davinci-003) và ICL-D3IE (ChatGPT) nhất quán vượt trội hơn LayoutLMv3 với khoảng cách lớn trên tất cả số lượng minh họa. Những kết quả này cho thấy rằng cách tiếp cận minh họa đa dạng trong ngữ cảnh được đề xuất của chúng tôi là hiệu quả và vượt trội hơn các mô hình VRDU được tiền huấn luyện được tinh chỉnh với một số minh họa.

Nghiên cứu trường hợp. Hình 6a trình bày hai ví dụ về việc yêu cầu mô tả mối quan hệ vị trí với ICL tiêu chuẩn (Davinci-003) và ICL-D3IE (Davinci-003) trong giai đoạn kiểm tra. Kết quả của chúng tôi minh họa rằng ICL tiêu chuẩn, không có minh họa nhận thức bố cục, không thể mô tả chính xác các mối quan hệ vị trí giữa các nội dung văn bản trong tài liệu, trong khi ICL-D3IE có thể làm điều đó hiệu quả. Trong Hình 6b, chúng tôi quan sát rằng ICL tiêu chuẩn dự đoán các thực thể trong hộp màu xanh là "header," trong khi ICL-D3IE dự đoán các thực thể là "question." Những phát hiện này làm nổi bật tầm quan trọng của việc áp dụng các minh họa đa dạng như minh họa khó và minh họa nhận thức bố cục trong các tác vụ DIE.

5. Kết luận
Trong bài báo này, chúng tôi đã đề xuất ICL-D3IE, một khung học trong ngữ cảnh giải quyết các thách thức của việc áp dụng LLM cho các tác vụ DIE, cụ thể là khoảng cách về phương thức và tác vụ. Chúng tôi đã trích xuất các đoạn thách thức từ các tài liệu huấn luyện khó để có lợi cho tất cả các trường hợp kiểm tra, thiết kế các minh họa mô tả mối quan hệ vị trí để cho phép LLM hiểu bố cục của tài liệu, và giới thiệu các minh họa định dạng để tạo điều kiện trích xuất câu trả lời dễ dàng. Khung cũng cải thiện các minh họa đa dạng một cách lặp đi lặp lại và sử dụng ánh xạ nhãn để chuyển đổi các từ không tự nhiên thành các từ mà GPT có thể xử lý. Đánh giá của chúng tôi về ba bộ dữ liệu DIE cho thấy ICL-D3IE nhất quán vượt trội hơn các phương pháp khác, ngoại trừ thiết lập ID trên CORD. Những kết quả này làm nổi bật tiềm năng của các khung học trong ngữ cảnh cho các tác vụ hiểu VRD dựa trên LLM, và chúng tôi hy vọng sẽ truyền cảm hứng cho nghiên cứu tương lai trong lĩnh vực này.

6. Lời cảm ơn
Công trình này được hỗ trợ một phần bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo các khoản tài trợ (Số 62222203 và 61976049).

[Phần tài liệu tham khảo được tiếp tục dịch theo cùng định dạng...]

# Há»c sÆ¡ Ä‘á»“ vÃ  tÃ¡i liÃªn káº¿t nhÆ° nhá»¯ng cÆ¡ cháº¿ cá»§a há»c trong ngá»¯ cáº£nh vÃ  sá»± xuáº¥t hiá»‡n
Sivaramakrishnan Swaminathan1, Antoine Dedieu1, Rajkumar Vasudeva Raju1, Murray Shanahan1, Miguel
LÃ¡zaro-Gredilla1vÃ  Dileep George1
1Google DeepMind

Há»c trong ngá»¯ cáº£nh (ICL) lÃ  má»™t trong nhá»¯ng kháº£ nÄƒng máº¡nh máº½ nháº¥t vÃ  báº¥t ngá» nháº¥t xuáº¥t hiá»‡n trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) dá»±a trÃªn transformer gáº§n Ä‘Ã¢y. Tuy nhiÃªn, cÃ¡c cÆ¡ cháº¿ náº±m dÆ°á»›i nÃ³ Ä‘Æ°á»£c hiá»ƒu kÃ©m. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i chá»©ng minh ráº±ng nhá»¯ng kháº£ nÄƒng ICL tÆ°Æ¡ng tá»± cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘áº¡t Ä‘Æ°á»£c báº±ng má»™t phÆ°Æ¡ng phÃ¡p há»c dá»± Ä‘oÃ¡n chuá»—i thay tháº¿ sá»­ dá»¥ng Ä‘á»“ thá»‹ nhÃ¢n quáº£ cÃ³ cáº¥u trÃºc nhÃ¢n báº£n (CSCG). HÆ¡n ná»¯a, má»™t tÃ­nh cháº¥t quan trá»ng cá»§a CSCG lÃ , khÃ´ng giá»‘ng nhÆ° cÃ¡c LLM dá»±a trÃªn transformer, chÃºng cÃ³ thá»ƒ diá»…n giáº£i Ä‘Æ°á»£c, Ä‘iá»u nÃ y Ä‘Æ¡n giáº£n hÃ³a Ä‘Ã¡ng ká»ƒ nhiá»‡m vá»¥ giáº£i thÃ­ch cÃ¡ch ICL hoáº¡t Ä‘á»™ng. Cá»¥ thá»ƒ, chÃºng tÃ´i chá»‰ ra ráº±ng nÃ³ sá»­ dá»¥ng sá»± káº¿t há»£p cá»§a (a) há»c cÃ¡c máº¡ch máº«u (sÆ¡ Ä‘á»“) Ä‘á»ƒ hoÃ n thÃ nh pattern, (b) truy xuáº¥t cÃ¡c máº«u liÃªn quan má»™t cÃ¡ch nháº¡y cáº£m ngá»¯ cáº£nh, vÃ  (c) tÃ¡i liÃªn káº¿t cÃ¡c token má»›i vÃ o cÃ¡c slot thÃ­ch há»£p trong máº«u. ChÃºng tÃ´i tiáº¿p tá»¥c táº­p há»£p báº±ng chá»©ng cho giáº£ thuyáº¿t ráº±ng nhá»¯ng cÆ¡ cháº¿ tÆ°Æ¡ng tá»± náº±m dÆ°á»›i ICL trong cÃ¡c LLM. VÃ­ dá»¥, chÃºng tÃ´i phÃ¡t hiá»‡n ráº±ng, vá»›i CSCG nhÆ° vá»›i LLM, cÃ¡c kháº£ nÄƒng khÃ¡c nhau xuáº¥t hiá»‡n á»Ÿ cÃ¡c má»©c Ä‘á»™ tham sá»‘ hÃ³a quÃ¡ má»©c khÃ¡c nhau, gá»£i Ã½ ráº±ng tham sá»‘ hÃ³a quÃ¡ má»©c giÃºp há»c cÃ¡c máº¡ch máº«u (sÆ¡ Ä‘á»“) phá»©c táº¡p hÆ¡n. Báº±ng cÃ¡ch chá»‰ ra cÃ¡ch ICL cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c vá»›i cÃ¡c mÃ´ hÃ¬nh vÃ  táº­p dá»¯ liá»‡u nhá», chÃºng tÃ´i má»Ÿ ra má»™t con Ä‘Æ°á»ng Ä‘áº¿n cÃ¡c kiáº¿n trÃºc má»›i vÃ  tiáº¿n má»™t bÆ°á»›c quan trá»ng hÆ°á»›ng tá»›i sá»± hiá»ƒu biáº¿t tá»•ng quÃ¡t hÆ¡n vá» cÆ¡ cháº¿ Ä‘áº±ng sau kháº£ nÄƒng quan trá»ng nÃ y.

## 1. Giá»›i thiá»‡u

Trong má»™t mÃ´ hÃ¬nh chuá»—i Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c, há»c trong ngá»¯ cáº£nh (ICL), hay prompting few-shot, lÃ  kháº£ nÄƒng há»c má»™t nhiá»‡m vá»¥ má»›i tá»« má»™t táº­p nhá» cÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c trÃ¬nh bÃ y trong ngá»¯ cáº£nh (prompt) táº¡i thá»i Ä‘iá»ƒm suy luáº­n. ÄÃ¡ng ngáº¡c nhiÃªn, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u Ä‘á»§ lá»›n thá»ƒ hiá»‡n ICL, máº·c dÃ¹ chÃºng chá»‰ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i má»¥c tiÃªu dá»± Ä‘oÃ¡n token tiáº¿p theo [1, 2]. Má»™t pháº§n lá»›n sá»± pháº¥n khÃ­ch Ä‘ang diá»…n ra xung quanh LLM náº£y sinh tá»« kháº£ nÄƒng báº¥t ngá» nÃ y, vÃ¬ nÃ³ má»Ÿ rá»™ng Ä‘Ã¡ng ká»ƒ táº­p há»£p cÃ¡c á»©ng dá»¥ng tiá»m nÄƒng cá»§a chÃºng. Nhá»¯ng ná»— lá»±c hiá»ƒu kháº£ nÄƒng nÃ y Ä‘ang tiáº¿p tá»¥c vÃ  cÃ³ nhiá»u hÃ¬nh thá»©c khÃ¡c nhau, bao gá»“m cÃ¡c tÃ i khoáº£n chuáº©n hÃ³a cáº¥p cao hÆ¡n sá»­ dá»¥ng suy luáº­n Bayesian [3], vÃ  cÃ¡c giáº£i thÃ­ch cÆ¡ cháº¿ liÃªn quan Ä‘áº¿n gradient descent ngáº§m [4] hoáº·c induction heads [5]. Máº·c dÃ¹ váº­y, cÃ¡c cÆ¡ cháº¿ náº±m dÆ°á»›i ICL trong LLM váº«n hÆ¡i bÃ­ áº©n.

Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i thá»±c hiá»‡n má»™t cÃ¡ch tiáº¿p cáº­n khÃ¡c. ChÃºng tÃ´i tiáº¿t lá»™ cÃ¡c Ä‘iá»u kiá»‡n thÃºc Ä‘áº©y ICL trong má»™t mÃ´ hÃ¬nh há»c chuá»—i khÃ¡c Ä‘Æ°á»£c gá»i lÃ  Ä‘á»“ thá»‹ nhÃ¢n quáº£ cÃ³ cáº¥u trÃºc nhÃ¢n báº£n (CSCG) [6, 7]. Sá»­ dá»¥ng sá»± káº¿t há»£p cá»§a cÃ¡c táº­p dá»¯ liá»‡u má»›i vÃ  tiÃªu chuáº©n, chÃºng tÃ´i chá»‰ ra cÃ¡ch má»™t CSCG gÃ¡n xÃ¡c suáº¥t khÃ¡c khÃ´ng cho cÃ¡c chuá»—i chÆ°a tá»«ng tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n theo cÃ¡ch mÃ , nhá» cáº¥u trÃºc Ä‘á»“ thá»‹ nhÃ¢n quáº£ cá»§a mÃ´ hÃ¬nh, cÃ³ thá»ƒ diá»…n giáº£i má»™t cÃ¡ch rÃµ rÃ ng vÃ  cÆ¡ cháº¿. ChÃºng tÃ´i Ä‘Æ°a ra giáº£ thuyáº¿t ráº±ng cÃ¡c cÆ¡ cháº¿ tÆ°Æ¡ng tá»± sáº½ tá»“n táº¡i trong cÃ¡c LLM dá»±a trÃªn transformer, vÃ  chá»‰ ra cÃ¡ch Ä‘iá»u nÃ y cÃ³ thá»ƒ xáº£y ra.

Cá»¥ thá»ƒ, chÃºng tÃ´i chá»‰ ra ráº±ng ICL trong CSCG cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£i thÃ­ch nhÆ° sá»± káº¿t há»£p cá»§a (a) há»c cÃ¡c máº¡ch máº«u Ä‘á»ƒ hoÃ n thÃ nh pattern, (b) truy xuáº¥t cÃ¡c máº«u liÃªn quan má»™t cÃ¡ch nháº¡y cáº£m ngá»¯ cáº£nh, vÃ  (c) tÃ¡i liÃªn káº¿t cÃ¡c token má»›i vÃ o cÃ¡c slot thÃ­ch há»£p trong cÃ¡c máº«u Ä‘Ã£ há»c [8]. KhÃ´ng giá»‘ng nhÆ° cÃ¡c mÃ´ hÃ¬nh n-gram, CSCG cho phÃ©p tá»•ng quÃ¡t hÃ³a báº¯c cáº§u trong khÃ´ng gian tiá»m áº©n, Ä‘iá»u nÃ y gÃ¡n xÃ¡c suáº¥t khÃ¡c khÃ´ng cho cÃ¡c chuá»—i chÆ°a tá»«ng tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n theo cÃ¡ch cÃ³ Ã½ nghÄ©a vá» máº·t ngá»¯ nghÄ©a, Ä‘áº£m báº£o ráº±ng cÃ¡c ngá»¯ cáº£nh (prompt) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ truy xuáº¥t khÃ´ng pháº£i lÃ  sá»± ghi nhá»› thuáº§n tÃºy. NgoÃ i ra, viá»‡c liÃªn káº¿t cÃ¡c token má»›i vÃ o cÃ¡c slot trong cÃ¡c máº«u Ä‘Ã£ há»c cho phÃ©p cÃ¹ng má»™t kiáº¿n thá»©c cáº¥u trÃºc Ä‘Æ°á»£c Ã¡p dá»¥ng cho cÃ¡c Ä‘áº§u vÃ o hoÃ n toÃ n má»›i. Báº±ng cÃ¡ch lÃ m rÃµ cÃ¡c nguyÃªn táº¯c lÃ m ná»n táº£ng cho cÆ¡ cháº¿ cá»§a ICL, chÃºng tÃ´i hy vá»ng má»Ÿ Ä‘Æ°á»ng cho viá»‡c thiáº¿t káº¿ cÃ¡c kiáº¿n trÃºc má»›i cho sá»± trá»«u tÆ°á»£ng hÃ³a vÃ  tá»•ng quÃ¡t hÃ³a, trong khi cÃ¡c khá»‘i xÃ¢y dá»±ng mÃ  chÃºng tÃ´i xÃ¡c Ä‘á»‹nh hÆ°á»›ng dáº«n viá»‡c tÃ¬m kiáº¿m cÃ¡c máº¡ch cÃ³ thá»ƒ diá»…n giáº£i cÆ¡ cháº¿ [9] vÃ  chá»‰nh sá»­a Ä‘Æ°á»£c [10] trong transformer [11].

## 2. Thuáº­t toÃ¡n tÃ¡i liÃªn káº¿t cho Ä‘á»“ thá»‹ nhÃ¢n quáº£ cÃ³ cáº¥u trÃºc nhÃ¢n báº£n

### 2.1. Ná»n táº£ng vá» Ä‘á»“ thá»‹ nhÃ¢n quáº£ cÃ³ cáº¥u trÃºc nhÃ¢n báº£n (CSCG)

Xem xÃ©t má»™t agent thá»±c hiá»‡n má»™t loáº¡t cÃ¡c hÃ nh Ä‘á»™ng rá»i ráº¡c ğ‘1,...,ğ‘ğ‘âˆ’1 vá»›i ğ‘ğ‘›âˆˆ{1,...,ğ‘ actions}, vÃ­ dá»¥ Ä‘i bá»™ trong phÃ²ng. Káº¿t quáº£ cá»§a má»—i hÃ nh Ä‘á»™ng, agent nháº­n Ä‘Æ°á»£c má»™t quan sÃ¡t cÃ³ bÃ­ danh tri giÃ¡c [12], dáº«n Ä‘áº¿n dÃ²ng cÃ¡c biáº¿n ngáº«u nhiÃªn ğ‘‹1,...,ğ‘‹ğ‘ vá»›i cÃ¡c giÃ¡ trá»‹ quan sÃ¡t ğ‘¥1,...,ğ‘¥ğ‘, trong Ä‘Ã³ má»—i ğ‘¥ğ‘›âˆˆ{1,...,ğ‘ obs}. CSCG [6] lÃ  má»™t mÃ´ hÃ¬nh há»c chuá»—i xÃ¡c suáº¥t há»c cÃ¡c Ä‘á»“ thá»‹ tiá»m áº©n Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a cÃ¡c chuá»—i cÃ³ Ä‘iá»u kiá»‡n hÃ nh Ä‘á»™ng nÃ y. Má»™t CSCG cÃ³ thá»ƒ khÃ´i phá»¥c má»™t Ä‘á»“ thá»‹ Ä‘áº¡i diá»‡n cho cáº¥u trÃºc nhÃ¢n quáº£ tiá»m áº©n [13] cá»§a mÃ´i trÆ°á»ng (vÃ­ dá»¥ phÃ²ng), sau Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ láº­p káº¿ hoáº¡ch hÃ nh Ä‘á»™ng trong mÃ´i trÆ°á»ng Ä‘Ã³. CSCG giá»›i thiá»‡u má»™t biáº¿n giáº£i thÃ­ch tiá»m áº©n ğ‘ğ‘› táº¡i má»—i bÆ°á»›c thá»i gian ğ‘›, vá»›i cÃ¡c giÃ¡ trá»‹ ğ‘§ğ‘›âˆˆ{1,...,ğ‘ latent}, Ä‘á»ƒ loáº¡i bá» tÃ­nh mÆ¡ há»“ cá»§a cÃ¡c quan sÃ¡t cÃ³ bÃ­ danh tri giÃ¡c. Sau Ä‘Ã³ nÃ³ mÃ´ hÃ¬nh hÃ³a dÃ²ng quan sÃ¡t nhÆ°

ğ‘ƒ(ğ‘¥1,...,ğ‘¥ğ‘|ğ‘1,...,ğ‘ğ‘âˆ’1)=âˆ‘ï¸ğ‘§1,...,ğ‘§ğ‘›ğ‘ƒ(ğ‘¥1|ğ‘§1)ğ‘ƒ(ğ‘§1)ğ‘âˆğ‘›=2ğ‘ƒ(ğ‘¥ğ‘›|ğ‘§ğ‘›)ğ‘ƒ(ğ‘§ğ‘›|ğ‘§ğ‘›âˆ’1,ğ‘ğ‘›âˆ’1).

Äá»™ng lá»±c cÃ³ Ä‘iá»u kiá»‡n hÃ nh Ä‘á»™ng Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi má»™t tensor chuyá»ƒn tiáº¿p ğ‘‡: ğ‘‡ğ‘–ğ‘—ğ‘˜=ğ‘ƒ(ğ‘ğ‘›=ğ‘˜|ğ‘ğ‘›âˆ’1=ğ‘—,ğ‘ğ‘›âˆ’1=ğ‘–)âˆ€ğ‘›, vÃ  xÃ¡c suáº¥t quan sÃ¡t bá»Ÿi má»™t ma tráº­n phÃ¡t xáº¡ ğ¸: ğ¸ğ‘–ğ‘—=ğ‘ƒ(ğ‘‹ğ‘›=ğ‘—|ğ‘ğ‘›=ğ‘–)âˆ€ğ‘›.

Tensor chuyá»ƒn tiáº¿p ğ‘‡ Ä‘á»‹nh nghÄ©a má»™t Ä‘a Ä‘á»“ thá»‹ cÃ³ hÆ°á»›ng, cÃ³ cÃ¡c node tÆ°Æ¡ng á»©ng vá»›i cÃ¡c giÃ¡ trá»‹ cá»§a ğ‘§. Vá»›i Ä‘iá»u kiá»‡n trÃªn má»™t hÃ nh Ä‘á»™ng, má»—i entry cá»§a ğ‘‡ lÃ  trá»ng sá»‘ cá»§a má»™t cáº¡nh cÃ³ hÆ°á»›ng giá»¯a hai node (tá»« chá»‰ sá»‘ hÃ ng Ä‘áº¿n chá»‰ sá»‘ cá»™t cá»§a entry Ä‘Ã³). Xem HÃ¬nh 1D Ä‘á»ƒ biáº¿t vÃ­ dá»¥ vá» Ä‘á»“ thá»‹ tiá»m áº©n CSCG Ä‘Æ°á»£c khÃ´i phá»¥c.

CSCG cÃ³ má»™t mÃ´ hÃ¬nh quan sÃ¡t táº¥t Ä‘á»‹nh. NghÄ©a lÃ , Ä‘á»‘i vá»›i má»—i hÃ ng cá»§a ğ¸, má»™t entry Ä‘Æ°á»£c Ä‘áº·t thÃ nh 1 vÃ  pháº§n cÃ²n láº¡i thÃ nh 0. Do Ä‘Ã³, Ä‘á»‘i vá»›i báº¥t ká»³ giÃ¡ trá»‹ tiá»m áº©n ğ‘§ nÃ o, cÃ¹ng má»™t quan sÃ¡t ğ‘¥ luÃ´n Ä‘Æ°á»£c phÃ¡t ra. Nhiá»u giÃ¡ trá»‹ cá»§a ğ‘§ cÃ³ thá»ƒ dáº«n Ä‘áº¿n cÃ¹ng má»™t quan sÃ¡t ğ‘¥, lÃ m cho mÃ´ hÃ¬nh overcomplete [14]. Sá»­ dá»¥ng cÃ¡c tráº¡ng thÃ¡i tiá»m áº©n nÃ y, má»™t CSCG cÃ³ thá»ƒ phÃ¢n biá»‡t nhiá»u percept cÃ³ bÃ­ danh (cÃ¹ng quan sÃ¡t ğ‘¥) thÃ nh cÃ¡c nguyÃªn nhÃ¢n riÃªng biá»‡t (cÃ¡c giÃ¡ trá»‹ tiá»m áº©n ğ‘§ khÃ¡c nhau). RÃ ng buá»™c cá»§a viá»‡c ğ¸ táº¥t Ä‘á»‹nh lÃ m cho CSCG Ã­t tá»•ng quÃ¡t hÆ¡n mÃ´ hÃ¬nh Markov áº©n (HMM), nhÆ°ng dá»… há»c hÆ¡n [6]. CSCG cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ náº¿u cÃ¡c quan sÃ¡t tÆ°Æ¡ng á»©ng vá»›i cÃ¡c token tá»«, vá»›i hÃ nh Ä‘á»™ng duy nháº¥t truy cáº­p token tiáº¿p theo.

### 2.2. TÃ¡i liÃªn káº¿t trong CSCG

Khi má»™t agent gáº·p má»™t mÃ´i trÆ°á»ng má»›i cÃ³ cáº¥u trÃºc tÆ°Æ¡ng tá»±, nhÆ°ng quan sÃ¡t khÃ¡c nhau, nÃ³ cÃ³ thá»ƒ há»c mÃ´i trÆ°á»ng Ä‘Ã³ nhanh hÆ¡n báº±ng cÃ¡ch tÃ¡i sá»­ dá»¥ng Ä‘á»“ thá»‹ tiá»m áº©n ğ‘‡ (nhá»¯ng gÃ¬ chÃºng tÃ´i gá»i lÃ  sÆ¡ Ä‘á»“) [15] tá»« kinh nghiá»‡m trÆ°á»›c vÃ  chá»‰ há»c láº¡i ma tráº­n phÃ¡t xáº¡. ChÃºng tÃ´i gá»i quÃ¡ trÃ¬nh nÃ y lÃ  tÃ¡i liÃªn káº¿t. TÃ¡i liÃªn káº¿t cÃ³ thá»ƒ Ä‘Æ°á»£c diá»…n giáº£i nhÆ° má»™t can thiá»‡p nháº¹ trÃªn mÃ´ hÃ¬nh cá»§a agent [16, 17]. Xem HÃ¬nh 1D & F Ä‘á»ƒ biáº¿t vÃ­ dá»¥ vá» hai phÃ²ng cÃ³ chung cáº¥u trÃºc tiá»m áº©n nhÆ°ng quan sÃ¡t khÃ¡c nhau. Khi má»™t ma tráº­n phÃ¡t xáº¡ má»›i liÃªn káº¿t vá»›i má»™t sÆ¡ Ä‘á»“ hiá»‡n cÃ³, nÃ³ pháº£i tÃ´n trá»ng cáº¥u trÃºc clone cá»§a ma tráº­n phÃ¡t xáº¡ gá»‘c (HÃ¬nh 1E). HÃ m cáº¥u trÃºc clone C(Â·)âˆˆ{1,...,ğ‘ obs} phÃ¢n vÃ¹ng tráº¡ng thÃ¡i tiá»m áº©n thÃ nh ğ‘obs slot: hai tráº¡ng thÃ¡i tiá»m áº©n ğ‘§=ğ‘– vÃ  ğ‘§=ğ‘–â€² thuá»™c cÃ¹ng má»™t clone slot khi vÃ  chá»‰ khi C(ğ‘–)=C(ğ‘–â€²). Má»™t ma tráº­n phÃ¡t xáº¡ tÃ´n trá»ng cáº¥u trÃºc clone C náº¿u Ä‘iá»u kiá»‡n C(ğ‘–)=C(ğ‘–â€²)âŸ¹ğ¸ğ‘–ğ‘—=ğ¸ğ‘–â€²ğ‘—âˆ€ğ‘–,ğ‘–â€²,ğ‘— Ä‘Æ°á»£c thá»a mÃ£n. 3-tuple {ğ‘‡,C,ğ¸} Ä‘á»‹nh nghÄ©a má»™t sÆ¡ Ä‘á»“ cÃ³ ná»n táº£ng, tuple {ğ‘‡,C} Ä‘á»‹nh nghÄ©a má»™t sÆ¡ Ä‘á»“ khÃ´ng cÃ³ ná»n táº£ng vá»›i cáº¥u trÃºc clone vÃ  ğ‘‡ Ä‘Æ¡n thuáº§n lÃ  má»™t sÆ¡ Ä‘á»“ [15].

#### 2.2.1. TÃ¡i liÃªn káº¿t nhanh báº±ng cÃ¡ch chÃº Ã½ Ä‘áº¿n sá»± báº¥t ngá»

ThÆ°á»ng thÃ¬, cÃ¡c thay Ä‘á»•i mÃ´i trÆ°á»ng Ä‘Æ°á»£c báº£n Ä‘á»‹a hÃ³a sao cho pháº§n lá»›n cáº¥u trÃºc tiá»m áº©n vÃ  Ã¡nh xáº¡ quan sÃ¡t Ä‘Æ°á»£c báº£o tá»“n trong khi chá»‰ má»™t vÃ i quan sÃ¡t cáº§n Ä‘Æ°á»£c tÃ¡i liÃªn káº¿t: vÃ­ dá»¥, chá»‰ thay tháº£m trong phÃ²ng trong khi mÃ u tÆ°á»ng váº«n giá»¯ nguyÃªn, hoáº·c tiáº¿p xÃºc vá»›i má»™t tá»« má»›i trong ngá»¯ cáº£nh quen thuá»™c. Insight nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Æ°a ra má»™t thuáº­t toÃ¡n táº­p trung viá»‡c cáº­p nháº­t ma tráº­n phÃ¡t xáº¡ chá»‰ vÃ o nhá»¯ng quan sÃ¡t Ä‘Æ°á»£c tÃ¬m tháº¥y báº¥t ngá» bá»Ÿi mÃ´ hÃ¬nh hiá»‡n cÃ³.

Giáº£ sá»­ táº¡i thá»i Ä‘iá»ƒm kiá»ƒm tra, má»™t sÆ¡ Ä‘á»“ cÃ³ ná»n táº£ng {ğ‘‡,C,ğ¸0} tiáº¿p xÃºc vá»›i má»™t chuá»—i cÃ³ quan sÃ¡t má»›i. Thuáº­t toÃ¡n 1 Ä‘á» xuáº¥t má»™t quy trÃ¬nh nhanh Ä‘á»ƒ cáº­p nháº­t ma tráº­n phÃ¡t xáº¡ sang quan sÃ¡t má»›i báº±ng cÃ¡ch chá»‰ thá»±c hiá»‡n cáº­p nháº­t cá»¥c bá»™, vÃ  liÃªn káº¿t ma tráº­n phÃ¡t xáº¡ Ä‘Ã£ cáº­p nháº­t vá»›i sÆ¡ Ä‘á»“ hiá»‡n cÃ³ ğ‘‡, Ä‘á»‹nh nghÄ©a má»™t sÆ¡ Ä‘á»“ cÃ³ ná»n táº£ng má»›i {ğ‘‡,C,ğ¸rb}. ChÃºng tÃ´i gá»i quÃ¡ trÃ¬nh nÃ y lÃ  tÃ¡i liÃªn káº¿t nhanh.

Cho má»™t prompt (ğ‘¥1,...,ğ‘¥ğ‘) vÃ  má»™t ngÆ°á»¡ng báº¥t ngá», Thuáº­t toÃ¡n 1 tiáº¿n hÃ nh báº±ng cÃ¡ch xÃ¡c Ä‘á»‹nh cÃ¡c entry cá»§a ma tráº­n phÃ¡t xáº¡ cáº§n Ä‘Æ°á»£c cáº­p nháº­t, sau Ä‘Ã³ cáº­p nháº­t cÃ¡c entry Ä‘Ã³ báº±ng thuáº­t toÃ¡n Expectation-Maximization (EM) [18]. XÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n ğ‘(ğ‘‹ğ‘›=ğ‘—|ğ‘¥\ğ‘›) cá»§a cÃ¡c token táº¡i bÆ°á»›c thá»i gian ğ‘› cho táº¥t cáº£ cÃ¡c bÆ°á»›c thá»i gian khÃ¡c Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c bÆ°á»›c thá»i gian vÃ  tráº¡ng thÃ¡i tiá»m áº©n báº¥t ngá» hoáº·c khÃ´ng. Náº¿u mÃ´ hÃ¬nh hiá»‡n táº¡i dá»± Ä‘oÃ¡n má»™t quan sÃ¡t vá»›i Ä‘á»™ tin cáº­y cao, vÃ  quan sÃ¡t thá»±c sá»± xáº£y ra, thÃ¬ cÃ¡c tráº¡ng thÃ¡i tiá»m áº©n tÆ°Æ¡ng á»©ng vá»›i cÃ¡c quan sÃ¡t vÃ  bÆ°á»›c thá»i gian Ä‘Ã³ khÃ´ng nÃªn Ä‘Æ°á»£c cáº­p nháº­t. CÃ¡c tráº¡ng thÃ¡i tiá»m áº©n vÃ  bÆ°á»›c thá»i gian nÃ y, Ä‘Æ°á»£c gá»i lÃ  anchors, Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong BÆ°á»›c 3. CÃ¡c tráº¡ng thÃ¡i tiá»m áº©n tÆ°Æ¡ng á»©ng vá»›i cÃ¡c quan sÃ¡t Ä‘Æ°á»£c dá»± Ä‘oÃ¡n sai vá»›i Ä‘á»™ tin cáº­y cao, nhÆ°ng khÃ´ng pháº£i lÃ  má»™t trong cÃ¡c tráº¡ng thÃ¡i anchor, lÃ  cÃ¡c á»©ng viÃªn cho tÃ¡i liÃªn káº¿t. ChÃºng Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong BÆ°á»›c 4. Cuá»‘i cÃ¹ng, BÆ°á»›c 5 cáº­p nháº­t cá»¥c bá»™ ma tráº­n phÃ¡t xáº¡ báº±ng thuáº­t toÃ¡n EM chá»‰ trÃªn cÃ¡c tráº¡ng thÃ¡i tiá»m áº©n vÃ  bÆ°á»›c thá»i gian Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong bÆ°á»›c 4. ÄÃ¢y lÃ  má»™t trÆ°á»ng há»£p Ä‘áº·c biá»‡t cá»§a viá»‡c cáº­p nháº­t toÃ n bá»™ ma tráº­n phÃ¡t xáº¡ nhÆ° mÃ´ táº£ trong [15, Appendix A.2] nÆ¡i cÃ¡c tÃ¡c giáº£ há»c láº¡i toÃ n bá»™ ma tráº­n phÃ¡t xáº¡ cá»§a má»™t CSCG báº±ng cÃ¡ch giá»¯ sÆ¡ Ä‘á»“ ğ‘‡ cá»‘ Ä‘á»‹nh. TrÃ¡i vá»›i [15], cÃ¡c cáº­p nháº­t EM trong BÆ°á»›c 5 cá»§a chÃºng tÃ´i, Ä‘Æ°á»£c mÃ´ táº£ chi tiáº¿t trong Phá»¥ lá»¥c A, chá»‰ cáº­p nháº­t cá»¥c bá»™ ma tráº­n phÃ¡t xáº¡. Káº¿t quáº£ lÃ , chá»‰ má»™t táº­p con nhá» cÃ¡c hÃ ng khÃ¡c nhau giá»¯a ğ¸0 vÃ  ğ¸rb. CÃ¡c hÃ ng Ä‘Æ°á»£c báº£o vá»‡ tÆ°Æ¡ng á»©ng vá»›i cÃ¡c anchor trong prompt hiá»‡n táº¡i, hoáº·c cÃ¡c slot khÃ´ng liÃªn quan Ä‘áº¿n prompt hiá»‡n táº¡i nhÆ°ng váº«n cÃ³ thá»ƒ liÃªn quan Ä‘áº¿n cÃ¡c quan sÃ¡t tÆ°Æ¡ng lai. Pseudocount Ä‘Æ°á»£c sá»­ dá»¥ng trong BÆ°á»›c 1 lÃ  má»™t tham sá»‘ báº¥t Ä‘á»‹nh cho phÃ©p mÃ´ hÃ¬nh lÃ m má»‹n cÃ¡c quan sÃ¡t khÃ´ng chÃ­nh xÃ¡c. ThÃªm chi tiáº¿t vá» tham sá»‘ nÃ y cÃ³ sáºµn trong [6].

Sau khi tÃ¡i liÃªn káº¿t, chÃºng tÃ´i hoÃ n thÃ nh prompt báº±ng cÃ¡ch thá»±c hiá»‡n suy luáº­n MAP cÃ³ Ä‘iá»u kiá»‡n trÃªn prompt Ä‘Æ°á»£c cung cáº¥p trong CSCG Ä‘Ã£ tÃ¡i liÃªn káº¿t. ChÃºng tÃ´i cháº¡y thuáº­t toÃ¡n max-product [19] vá» phÃ­a trÆ°á»›c (cÃ¡c thÃ´ng Ä‘iá»‡p ngÆ°á»£c Ä‘á»u Ä‘á»“ng nháº¥t) do Ä‘Ã³ táº¡o ra má»™t loáº¡t cÃ¡c quan sÃ¡t MAP cho cÃ¡c token theo sau prompt. ChÃºng tÃ´i dá»«ng khi táº¡o ra má»™t token delimiter. Xem Thuáº­t toÃ¡n 2 trong Phá»¥ lá»¥c B Ä‘á»ƒ biáº¿t chi tiáº¿t.

Má»¥c 6 tháº£o luáº­n vá» cÃ¡ch má»™t cÆ¡ cháº¿ tÆ°Æ¡ng tá»± Thuáº­t toÃ¡n 1 cÃ³ thá»ƒ Ä‘Æ°á»£c triá»ƒn khai trong transformer sá»­ dá»¥ng cÃ¡c Ä‘áº§u vÃ o vÃ  kÃ­ch hoáº¡t Ä‘Æ°á»£c Ä‘á»‡m.

## 3. PhÃ¡c tháº£o láº­p luáº­n tá»•ng thá»ƒ sá»­ dá»¥ng CSCG

### 3.1. Biá»ƒu diá»…n tiá»m áº©n phá»¥ thuá»™c ngá»¯ cáº£nh vÃ  tá»•ng quÃ¡t hÃ³a báº¯c cáº§u

Cáº¥u trÃºc clone cá»§a CSCG cho phÃ©p tÃ¡ch biá»‡t dá»±a trÃªn ngá»¯ cáº£nh vÃ  pha trá»™n thÃ­ch há»£p cho mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯. VÃ­ dá»¥, nghÄ©a cá»§a tá»« "bank" trong "bank robber" khÃ¡c vá»›i nghÄ©a trong "river bank". Viá»‡c há»c CSCG loáº¡i bá» tÃ­nh mÆ¡ há»“ cá»§a cÃ¡c ngá»¯ cáº£nh nÃ y trong khÃ´ng gian tiá»m áº©n báº±ng cÃ¡ch káº¿t ná»‘i chÃºng vá»›i cÃ¡c clone khÃ¡c nhau Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c dá»± Ä‘oÃ¡n. Trong HÃ¬nh 2A, cÃ¡c cÃ¢u "river bank resort" vÃ  "one bank robber" sá»­ dá»¥ng cÃ¡c clone khÃ¡c nhau cá»§a "bank". Chuá»—i cÃ³ thá»ƒ cÃ³ phÃ¢n nhÃ¡nh xÃ¡c suáº¥t: "one bank robber" cÃ³ thá»ƒ káº¿t thÃºc táº¡i "\n", hoáº·c tiáº¿p tá»¥c Ä‘áº¿n "eating at river bank resort" hoáº·c "eating bread and honey", hoáº·c "eating bread and butter at river bank resort" (HÃ¬nh 2B). CSCG cÅ©ng cho phÃ©p há»£p nháº¥t cÃ¡c ngá»¯ cáº£nh dáº«n Ä‘áº¿n tá»•ng quÃ¡t hÃ³a báº¯c cáº§u: ngay cáº£ khi dá»¯ liá»‡u huáº¥n luyá»‡n chá»‰ cÃ³ cÃ¡c chuá»—i "bread and butter" vÃ  "milk and honey", náº¿u chÃºng Ä‘i qua cÃ¹ng má»™t tráº¡ng thÃ¡i clone "and", mÃ´ hÃ¬nh sáº½ tá»•ng quÃ¡t hÃ³a thÃ nh "bread and honey" vÃ  "milk and butter", gÃ¡n xÃ¡c suáº¥t khÃ¡c khÃ´ng cho cÃ¡c chuá»—i Ä‘Ã³. Do sá»± káº¿t há»£p cá»§a tÃ¡ch biá»‡t nháº¡y cáº£m ngá»¯ cáº£nh vÃ  tÃ­nh báº¯c cáº§u, cÃ¡c chá»§ Ä‘á», khÃ¡i niá»‡m vÃ  thuáº­t toÃ¡n liÃªn quan Ä‘Æ°á»£c nhÃ³m thÃ nh cÃ¡c máº¡ng con Ä‘i qua cÃ¹ng cÃ¡c clone. Ngá»¯ cáº£nh cá»§a prompt sáº½ kÃ­ch hoáº¡t máº¡ng con cá»§a nÃ³, vÃ  tá»•ng quÃ¡t hÃ³a báº¯c cáº§u cho phÃ©p cÃ¡c prompt khÃ´ng pháº£i lÃ  sá»± ghi nhá»› chÃ­nh xÃ¡c. NhÆ° chÃºng tÃ´i chá»‰ ra trong Má»¥c 4, quan Ä‘iá»ƒm suy luáº­n Bayesian vá» ICL [3] tÆ°Æ¡ng á»©ng vá»›i viá»‡c lÆ°u trá»¯ vÃ  truy xuáº¥t nháº¡y cáº£m ngá»¯ cáº£nh vÃ  tá»•ng quÃ¡t hÃ³a báº¯c cáº§u nÃ y má»™t mÃ¬nh, vÃ  khÃ´ng Ä‘á»§ Ä‘á»ƒ giáº£i thÃ­ch cÃ¡c thuá»™c tÃ­nh ICL mÃ  chÃºng tÃ´i xem xÃ©t trong cÃ¡c má»¥c tiáº¿p theo.

### 3.2. Há»c sÆ¡ Ä‘á»“ linh hoáº¡t (máº¡ch máº«u) vÃ  tÃ¡i liÃªn káº¿t

Giá»‘ng nhÆ° há»c bá»‘ cá»¥c phÃ²ng, CSCG cÃ³ thá»ƒ há»c cÃ¡c máº¡ch automata [20] cho cÃ¡c thuáº­t toÃ¡n sequence-to-sequence (seq2seq). Xem HÃ¬nh 2 Ä‘á»ƒ biáº¿t cÃ¡c máº¡ch CSCG cho parity, sao chÃ©p chuá»—i, vÃ  Ä‘áº£o ngÆ°á»£c chuá»—i cÃ³ nhiá»u Ä‘á»™ dÃ i. Máº¡ch Ä‘áº£o ngÆ°á»£c danh sÃ¡ch trong HÃ¬nh 2E Ä‘Æ°á»£c liÃªn káº¿t vá»›i cÃ¡c kÃ½ hiá»‡u cá»¥ thá»ƒ ğ´,ğµ,ğ¶,ğ·,ğ¸ Ä‘Æ°á»£c sá»­ dá»¥ng trong huáº¥n luyá»‡n. Äá»ƒ há»¯u Ã­ch nhÆ° má»™t máº«u, cÃ¡c slot thÃ­ch há»£p trong Ä‘á»“ thá»‹ nÃ y nÃªn cÃ³ thá»ƒ liÃªn káº¿t vá»›i cÃ¡c kÃ½ hiá»‡u tÃ¹y Ã½ xuáº¥t hiá»‡n trong ngá»¯ cáº£nh trong thá»i gian kiá»ƒm tra [8, 21]. Má»™t cÃ¡ch trá»±c quan, tÃ¡i liÃªn káº¿t cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu lÃ  hoáº¡t Ä‘á»™ng dá»±a trÃªn lá»—i dá»± Ä‘oÃ¡n - náº¿u ngá»¯ cáº£nh tiá»m áº©n dá»± Ä‘oÃ¡n máº¡nh máº½ tráº¡ng thÃ¡i tiá»m áº©n tÆ°Æ¡ng á»©ng vá»›i má»™t thá»i Ä‘iá»ƒm, nhÆ°ng quan sÃ¡t thá»±c táº¿ táº¡i thá»i Ä‘iá»ƒm Ä‘Ã³ khÃ´ng khá»›p, tÃ¡i liÃªn káº¿t Ä‘iá»u chá»‰nh ma tráº­n phÃ¡t xáº¡ Ä‘á»ƒ káº¿t ná»‘i táº¥t cáº£ cÃ¡c clone cá»§a tráº¡ng thÃ¡i tiá»m áº©n Ä‘Ã³ vá»›i quan sÃ¡t báº¥t ngá». CÆ¡ cháº¿ nÃ y Ä‘Æ°á»£c chÃ­nh thá»©c hÃ³a trong Thuáº­t toÃ¡n 1. QuÃ¡ trÃ¬nh tÃ¡i liÃªn káº¿t cho phÃ©p máº¡ch Ä‘áº£o ngÆ°á»£c danh sÃ¡ch cá»¥ thá»ƒ trong HÃ¬nh 2E trá»Ÿ thÃ nh má»™t máº«u linh hoáº¡t vá»›i cÃ¡c slot cÃ³ thá»ƒ Ä‘Æ°á»£c liÃªn káº¿t Ä‘á»™ng vá»›i cÃ¡c Ä‘áº§u vÃ o má»›i theo yÃªu cáº§u, táº¡o ra má»™t cÃ¡ch máº¡nh máº½ Ä‘á»ƒ trá»™n vÃ  gating kiáº¿n thá»©c trÆ°á»›c vá»›i ná»™i dung má»›i. VÃ­ dá»¥, trong sÆ¡ Ä‘á»“ Ä‘áº£o ngÆ°á»£c danh sÃ¡ch trong HÃ¬nh 2F, cÃ¡c token "[" vÃ  "]" lÃ  ná»™i dung trÆ°á»›c Ä‘Ã³ phÃ¡t hiá»‡n Ä‘iá»ƒm báº¯t Ä‘áº§u vÃ  káº¿t thÃºc cá»§a danh sÃ¡ch - chÃºng hoáº¡t Ä‘á»™ng nhÆ° anchors Ä‘á»ƒ grounding sÆ¡ Ä‘á»“ trong cÃ¡c quan sÃ¡t. PhÃ¢n nhÃ¡nh xÃ¡c suáº¥t dá»±a trÃªn token káº¿t thÃºc danh sÃ¡ch "]" cho phÃ©p tá»•ng quÃ¡t hÃ³a Ä‘á»™ dÃ i, trong khi háº¥p thá»¥ cÃ¡c kÃ½ hiá»‡u tÃ¹y Ã½ vÃ o cÃ¡c slot tÆ°Æ¡ng á»©ng vá»›i ğ´,ğµ,ğ¶,ğ·,ğ¸ cho phÃ©p thuáº­t toÃ¡n tá»•ng quÃ¡t hÃ³a sang cÃ¡c kÃ½ hiá»‡u má»›i. HÃ¬nh 2G minh há»a káº¿t quáº£ cá»§a cÆ¡ cháº¿ tÃ¡i liÃªn káº¿t nÃ y nÆ¡i cÃ¡c slot phÃ¡t ra ğ´,ğµ,ğ¶,ğ·,ğ¸ láº§n lÆ°á»£t Ä‘Æ°á»£c tÃ¡i liÃªn káº¿t vá»›i cÃ¡c kÃ½ hiá»‡u ğ¾,ğ‘€,ğ‘,ğ‘ƒ,ğ‘… tá»« prompt Ä‘áº§u vÃ o. TÆ°Æ¡ng tá»±, trong cÃ¢u "I wrote in a notebook using a dax", tÃ¡i liÃªn káº¿t cÃ³ thá»ƒ háº¥p thá»¥ token má»›i "dax" vÃ o ngá»¯ cáº£nh báº±ng cÃ¡ch liÃªn káº¿t nÃ³ vá»›i má»™t clone tÆ°Æ¡ng á»©ng vá»›i "pencil" hoáº·c "pen", vÃ  sá»­ dá»¥ng tá»« má»›i trong nhá»¯ng ngá»¯ cáº£nh Ä‘Ã³.

### 3.3. Truy xuáº¥t vÃ  hoÃ n thÃ nh nhiá»‡m vá»¥ dá»±a trÃªn hÆ°á»›ng dáº«n hoáº·c ná»™i dung

Nháº­n dáº¡ng nhiá»‡m vá»¥ zero-shot nhÆ° truy xuáº¥t dá»±a trÃªn ná»™i dung sá»­ dá»¥ng tÃ¡i liÃªn káº¿t: Nhiá»u vÃ­ dá»¥ ná»•i báº­t vá» há»c zero-shot liÃªn quan Ä‘áº¿n viá»‡c nháº­n dáº¡ng nhiá»‡m vá»¥ tá»« prompt, sau Ä‘Ã³ láº·p láº¡i nhiá»‡m vá»¥ Ä‘Ã£ nháº­n dáº¡ng trÃªn cÃ¡c Ä‘áº§u vÃ o má»›i. VÃ­ dá»¥, cho má»™t prompt "Input: [p, q, r, s] Output: [p, p, q, q, r, r, s, s]; Input: [l, m, n, o] Output: [l, l, m, m, n, n, o, o]" LLM cÃ³ thá»ƒ suy ra nhiá»‡m vá»¥ lÃ  láº·p láº¡i cÃ¡c pháº§n tá»­ cá»§a chuá»—i, vÃ  Ã¡p dá»¥ng Ä‘iá»u Ä‘Ã³ Ä‘á»ƒ hoÃ n thÃ nh Ä‘áº§u ra cho má»™t prompt Ä‘áº§u vÃ o má»›i ngay cáº£ khi cÃ¡c token "p, q, r, s, l, m, n, o" khÃ´ng Ä‘Æ°á»£c tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, liÃªn káº¿t vá»›i nhiá»‡m vá»¥ nÃ y. CSCG Ä‘Æ°a ra má»™t giáº£i thÃ­ch tá»± nhiÃªn cho Ä‘iá»u nÃ y báº±ng cÃ¡ch sá»­ dá»¥ng tÃ¡i liÃªn káº¿t. Cho prompt, expectation maximization (EM) [18] Ä‘á»“ng thá»i Ä‘Ã¡nh giÃ¡ cÃ¡c tÃ¡i liÃªn káº¿t khÃ¡c nhau vá»›i nhiá»u sÆ¡ Ä‘á»“ thuáº­t toÃ¡n tiá»m áº©n Ä‘á»ƒ suy ra liÃªn káº¿t tá»‘t nháº¥t, sau Ä‘Ã³ Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ hoÃ n thÃ nh query prompt.

Truy xuáº¥t dá»±a trÃªn hÆ°á»›ng dáº«n: Khi cÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i cÃ¡c hÆ°á»›ng dáº«n ngÃ´n ngá»¯ cÃ³ tiá»n tá»‘, CSCG há»c cÃ¡c máº¡ng con hÆ°á»›ng dáº«n trá» trá»±c tiáº¿p Ä‘áº¿n cÃ¡c máº¡ch Ä‘áº¡i diá»‡n cho cÃ¡c thuáº­t toÃ¡n (xem Má»¥c 4.2). Thuáº­t toÃ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c truy xuáº¥t báº±ng prompting trá»±c tiáº¿p vá»›i cÃ¡c hÆ°á»›ng dáº«n ngÃ´n ngá»¯ cÃ³ thá»ƒ khÃ¡c Ä‘Ã¡ng ká»ƒ so vá»›i hÆ°á»›ng dáº«n huáº¥n luyá»‡n do tá»•ng quÃ¡t hÃ³a báº¯c cáº§u vÃ  tÃ¡i liÃªn káº¿t.

### 3.4. Sá»± xuáº¥t hiá»‡n

ChÃºng tÃ´i Ä‘Æ°a ra giáº£ thuyáº¿t vÃ  chá»©ng minh thá»±c nghiá»‡m trong Má»¥c 4 ráº±ng sá»± xuáº¥t hiá»‡n cÃ³ thá»ƒ giáº£i thÃ­ch Ä‘Æ°á»£c nhÆ° tÃ¡c Ä‘á»™ng káº¿t há»£p cá»§a cÃ¡c thuá»™c tÃ­nh trÃªn (tÃ¡ch biá»‡t ngá»¯ cáº£nh, tá»•ng quÃ¡t hÃ³a báº¯c cáº§u, hÃ¬nh thÃ nh sÆ¡ Ä‘á»“ vÃ  tÃ¡i liÃªn káº¿t), dung lÆ°á»£ng mÃ´ hÃ¬nh vÃ  cÃ¡c pattern trong dá»¯ liá»‡u. Há»c cÃ¡c máº¡ch sÆ¡ Ä‘á»“ cho thuáº­t toÃ¡n phá»©c táº¡p hÆ¡n hoáº·c nhiá»u pattern hÆ¡n trong dá»¯ liá»‡u Ä‘Ã²i há»i dung lÆ°á»£ng mÃ´ hÃ¬nh lá»›n hÆ¡n vÃ¬ tham sá»‘ hÃ³a quÃ¡ má»©c giÃºp trong quÃ¡ trÃ¬nh tá»‘i Æ°u hÃ³a. Huáº¥n luyá»‡n trÃªn táº­p dá»¯ liá»‡u lá»›n hÆ¡n dáº«n Ä‘áº¿n viá»‡c táº¡o ra nhiá»u máº«u hÆ¡n cÃ³ thá»ƒ khÃ´ng xuáº¥t hiá»‡n trong táº­p dá»¯ liá»‡u nhá» hÆ¡n.

## 4. Káº¿t quáº£

ChÃºng tÃ´i cá»§ng cá»‘ láº­p luáº­n trÃªn báº±ng káº¿t quáº£ thá»±c nghiá»‡m trÃªn ba táº­p dá»¯ liá»‡u: (a) benchmark GINC Ä‘Æ°á»£c giá»›i thiá»‡u trong [3], (b) má»™t bá»™ cÃ¡c nhiá»‡m vá»¥ há»c thuáº­t toÃ¡n mÃ  chÃºng tÃ´i giá»›i thiá»‡u trong cÃ¡c táº­p dá»¯ liá»‡u LIALT, vÃ  (c) má»™t nhiá»‡m vá»¥ cáº£m á»©ng sá»­ dá»¥ng tá»« zero-shot trÃªn má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ CSCG.

### 4.1. Truy xuáº¥t nháº¡y cáº£m ngá»¯ cáº£nh trÃªn táº­p dá»¯ liá»‡u GINC phÃ¹ há»£p vá»›i giáº£i thÃ­ch suy luáº­n Bayesian

Táº­p dá»¯ liá»‡u: Táº­p dá»¯ liá»‡u GINC, Ä‘Æ°á»£c giá»›i thiá»‡u trong [3] Ä‘á»ƒ nghiÃªn cá»©u ICL, Ä‘Æ°á»£c táº¡o ra tá»« má»™t há»—n há»£p Ä‘á»“ng nháº¥t cá»§a nÄƒm factorial HMM [22]. Má»—i factorial HMM Ä‘Æ°á»£c gá»i lÃ  má»™t "concept". Má»™t tÃ i liá»‡u Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch ná»‘i cÃ¡c máº«u cÃ¢u Ä‘á»™c láº­p tá»« má»™t concept. CÃ¡c prompt kiá»ƒm tra trong ngá»¯ cáº£nh cÃ³ sá»‘ lÆ°á»£ng vÃ­ dá»¥ thay Ä‘á»•i tá»« ğ‘›=0 Ä‘áº¿n ğ‘›=64: má»—i vÃ­ dá»¥ cÃ³ thá»ƒ cÃ³ Ä‘á»™ dÃ i ğ‘˜âˆˆ{3,5,8,10}, vá»›i 2500 prompt cho má»—i thiáº¿t láº­p (ğ‘˜,ğ‘›). Má»—i prompt chá»n Ä‘á»“ng nháº¥t má»™t concept, láº¥y máº«u ğ‘›âˆ’1 vÃ­ dá»¥ ğ‘¥(1):ğ‘˜,...,ğ‘¥(ğ‘›âˆ’1):ğ‘˜ cÃ³ Ä‘á»™ dÃ i ğ‘˜, vÃ  má»™t vÃ­ dá»¥ ğ‘¥(ğ‘›):ğ‘˜âˆ’1 cÃ³ Ä‘á»™ dÃ i ğ‘˜âˆ’1. Nhiá»‡m vá»¥ trong ngá»¯ cáº£nh lÃ  suy ra token cuá»‘i cÃ¹ng cÃ³ kháº£ nÄƒng cao nháº¥t cá»§a vÃ­ dá»¥ cuá»‘i cÃ¹ng, tá»©c lÃ  argmaxğ‘¥(ğ‘›)ğ‘˜âˆ’1ğ‘(ğ‘¥(ğ‘›)ğ‘˜âˆ’1|ğ‘¥(1):ğ‘˜,...,ğ‘¥(ğ‘›âˆ’1):ğ‘˜,ğ‘¥(ğ‘›):ğ‘˜âˆ’1).

VÃ¬ tá»« vá»±ng Ä‘Æ°á»£c chia sáº» giá»¯a cÃ¡c concept tiá»m áº©n khÃ¡c nhau, cÃ¡c quan sÃ¡t trong GINC cÃ³ bÃ­ danh nhÆ° trong ngÃ´n ngá»¯ tá»± nhiÃªn, vÃ  giáº£i quyáº¿t nhiá»‡m vá»¥ Ä‘Ã²i há»i mÃ´ hÃ¬nh pháº£i loáº¡i bá» tÃ­nh mÆ¡ há»“ cá»§a cÃ¡c quan sÃ¡t cÃ³ bÃ­ danh Ä‘á»ƒ suy ra chÃ­nh xÃ¡c cÃ¡c concept tiá»m áº©n.

Huáº¥n luyá»‡n: ChÃºng tÃ´i huáº¥n luyá»‡n má»™t CSCG duy nháº¥t vá»›i 50 clone trÃªn táº­p dá»¯ liá»‡u GINC cho 100 láº§n láº·p EM full-batch sá»­ dá»¥ng pseudocount [6] cá»§a ğœ–=10^{-2}. Cho má»™t prompt kiá»ƒm tra, CSCG suy ra chuá»—i áº©n cÃ³ kháº£ nÄƒng cao nháº¥t cho prompt Ä‘Ã³, sau Ä‘Ã³ dá»± Ä‘oÃ¡n quan sÃ¡t cÃ³ kháº£ nÄƒng cao nháº¥t tiáº¿p theo.

Káº¿t quáº£: CSCG há»c cÃ¡c máº¡ng con tiá»m áº©n khÃ¡c nhau tÆ°Æ¡ng á»©ng vá»›i nÄƒm concept tiá»m áº©n trong táº­p dá»¯ liá»‡u GINC (HÃ¬nh 3A), vÃ  suy luáº­n trÃªn má»™t prompt Ä‘Æ°á»£c cung cáº¥p truy xuáº¥t máº¡ng con tiá»m áº©n chÃ­nh xÃ¡c (HÃ¬nh 3C). TÄƒng Ä‘á»™ dÃ i prompt cáº£i thiá»‡n viá»‡c Ä‘á»‹nh vá»‹ máº¡ng con vÃ  cÃ¡c tráº¡ng thÃ¡i cá»¥ thá»ƒ trong máº¡ng con. HÃ¬nh 3C hÃ¬nh dung phÃ¢n bá»‘ tráº¡ng thÃ¡i tiá»m áº©n Ä‘Ã£ giáº£i mÃ£ cho má»™t prompt vÃ­ dá»¥ trong thiáº¿t láº­p zero-shot (ğ‘›=0). Viá»‡c giáº£i mÃ£ báº¯t Ä‘áº§u khÃ´ng cháº¯c cháº¯n, vÃ  cáº£i thiá»‡n khi prompt dÃ i hÆ¡n. Viá»‡c Ä‘á»‹nh vá»‹ nÃ y (trÃªn Ä‘á»“ thá»‹) dáº«n Ä‘áº¿n truy xuáº¥t sÆ¡ Ä‘á»“ hiá»‡u quáº£, vÃ  do Ä‘Ã³ hoÃ n thÃ nh prompt chÃ­nh xÃ¡c. HÃ¬nh 3B[trÃ¡i] bÃ¡o cÃ¡o Ä‘á»™ chÃ­nh xÃ¡c trong ngá»¯ cáº£nhâ€”Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  tá»· lá»‡ trung bÃ¬nh cá»§a cÃ¡c dá»± Ä‘oÃ¡n chÃ­nh xÃ¡câ€”cho má»—i cáº·p (ğ‘˜,ğ‘›) cá»§a táº­p kiá»ƒm tra GINC. Äá»™ chÃ­nh xÃ¡c trong ngá»¯ cáº£nh cá»§a CSCG phÃ¹ há»£p vá»›i cÃ¡c pattern thá»ƒ hiá»‡n bá»Ÿi LSTM vÃ  transformer trong [3], trong khi cáº£i thiá»‡n nháº¹ hiá»‡u suáº¥t cá»§a chÃºng. HÃ¬nh 3B cÅ©ng cho tháº¥y ráº±ng má»™t CSCG vá»›i dung lÆ°á»£ng lá»›n hÆ¡n, tá»©c lÃ  vá»›i 50 clone má»—i token, tÃ¡ch biá»‡t cÃ¡c concept tiá»m áº©n tá»‘t hÆ¡n vÃ  vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i má»™t CSCG chá»‰ cÃ³ 10 clone má»—i token. HÃ¬nh 9[trÃ¡i] trong Phá»¥ lá»¥c C hiá»ƒn thá»‹ Ä‘á»™ tin cáº­y trong ngá»¯ cáº£nh cá»§a CSCG: Ä‘á»‘i vá»›i ngá»¯ cáº£nh lá»›n hÆ¡n, CSCG tá»‘t hÆ¡n trong viá»‡c loáº¡i bá» tÃ­nh mÆ¡ há»“ aliasing vÃ  xÃ¡c suáº¥t dá»± Ä‘oÃ¡n trung bÃ¬nh cao hÆ¡n. Cuá»‘i cÃ¹ng, HÃ¬nh 9[pháº£i] cho tháº¥y ráº±ng tÆ°Æ¡ng tá»± nhÆ° transformer vÃ  LSTM trong [3], CSCG tháº¥t báº¡i trong ICL khi prompt kiá»ƒm tra Ä‘Æ°á»£c láº¥y máº«u tá»« cÃ¡c concept chÆ°a tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.

Káº¿t quáº£ GINC phÃ¹ há»£p vá»›i láº­p luáº­n truy xuáº¥t dá»±a trÃªn ngá»¯ cáº£nh trong Má»¥c 3.1: ICL trong thiáº¿t láº­p nÃ y lÃ  viá»‡c truy xuáº¥t má»™t concept tiá»m áº©n Ä‘Æ°á»£c chia sáº» giá»¯a prompt vÃ  mÃ´ hÃ¬nh. Báº±ng cÃ¡ch sá»­ dá»¥ng tÃ­nh nháº¥t quÃ¡n táº§m xa cá»§a cÃ¡c concept trong cÃ¡c tÃ i liá»‡u huáº¥n luyá»‡n, mÃ´ hÃ¬nh há»c cÃ¡ch tÃ¡ch cÃ¡c concept thÃ nh cÃ¡c biá»ƒu diá»…n tiá»m áº©n khÃ¡c nhau. Máº·c dÃ¹ cÃ³ sá»± khÃ´ng khá»›p giá»¯a phÃ¢n bá»‘ train vÃ  prompt [3], CSCG thÃ nh cÃ´ng trong viá»‡c hoÃ n thÃ nh prompt vÃ¬ biá»ƒu diá»…n cho phÃ©p trá»™n báº¯c cáº§u.

### 4.2. Há»c sÆ¡ Ä‘á»“ cho thuáº­t toÃ¡n seq2seq vÃ  tá»•ng quÃ¡t hÃ³a báº±ng tÃ¡i liÃªn káº¿t

Táº­p dá»¯ liá»‡u huáº¥n luyá»‡n: Äá»ƒ kiá»ƒm tra kháº£ nÄƒng cá»§a CSCG trong viá»‡c há»c cÃ¡c thuáº­t toÃ¡n tá»•ng quÃ¡t hÃ³a sang cÃ¡c Ä‘áº§u vÃ o má»›i khÃ´ng tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, chÃºng tÃ´i xÃ¢y dá»±ng táº­p dá»¯ liá»‡u Language Instructed Algorithm Learning Tasks (LIALT). Táº­p huáº¥n luyá»‡n LIALT chá»©a cÃ¡c minh há»a cá»§a 13 thuáº­t toÃ¡n list vÃ  matrix Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 4A[trÃªn-trÃ¡i]. Má»™t minh há»a bao gá»“m má»™t hÆ°á»›ng dáº«n ngÃ´n ngá»¯ nhiá»u tá»«â€”má»—i thuáº­t toÃ¡n cÃ³ nÄƒm hÆ°á»›ng dáº«n khÃ¡c nhauâ€”theo sau bá»Ÿi 10 vÃ­ dá»¥ Ä‘áº§u vÃ o-Ä‘áº§u ra cá»§a thuáº­t toÃ¡n Ä‘Ã³. Xem Báº£ng 2 & 3 trong Phá»¥ lá»¥c D.1 Ä‘á»ƒ biáº¿t danh sÃ¡ch Ä‘áº§y Ä‘á»§ cÃ¡c hÆ°á»›ng dáº«n Ä‘Æ°á»£c sá»­ dá»¥ng. Äá»‘i vá»›i má»—i hÆ°á»›ng dáº«n, táº­p dá»¯ liá»‡u chá»©a 20 minh há»a. Trong má»™t minh há»a, hÆ°á»›ng dáº«n ngÃ´n ngá»¯ vÃ  cÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c phÃ¢n cÃ¡ch bá»Ÿi delimiter "/". CÃ¡c minh há»a Ä‘Æ°á»£c phÃ¢n cÃ¡ch bá»Ÿi delimiter "\n". CÃ¡c giÃ¡ trá»‹ list vÃ  matrix Ä‘áº§u vÃ o Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch láº¥y máº«u Ä‘á»“ng nháº¥t tá»« tá»« vá»±ng 676 token, Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch ghÃ©p ngáº«u nhiÃªn cÃ¡c chá»¯ cÃ¡i viáº¿t hoa. CÃ¡c vÃ­ dá»¥ list operations cÃ³ Ä‘á»™ dÃ i thay Ä‘á»•i tá»« 3 Ä‘áº¿n 6, vÃ  matrix operations cÃ³ kÃ­ch thÆ°á»›c 2Ã—2 hoáº·c 3Ã—3. HÃ¬nh 4A [dÆ°á»›i-trÃ¡i] cho tháº¥y Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u huáº¥n luyá»‡n.

Táº­p dá»¯ liá»‡u kiá»ƒm tra: LIALT cÃ³ hai táº­p dá»¯ liá»‡u kiá»ƒm tra, láº§n lÆ°á»£t chá»©a: (a) prompt truy xuáº¥t dá»±a trÃªn hÆ°á»›ng dáº«n, vÃ  (b) prompt truy xuáº¥t dá»±a trÃªn vÃ­ dá»¥. Má»™t prompt kiá»ƒm tra truy xuáº¥t dá»±a trÃªn hÆ°á»›ng dáº«n bao gá»“m má»™t hÆ°á»›ng dáº«n ngÃ´n ngá»¯ tá»± nhiÃªn theo sau bá»Ÿi má»™t Ä‘áº§u vÃ o duy nháº¥t. Má»™t prompt kiá»ƒm tra truy xuáº¥t dá»±a trÃªn vÃ­ dá»¥ bao gá»“m má»™t vÃ­ dá»¥ Ä‘áº§u vÃ o-Ä‘áº§u ra Ä‘áº§u tiÃªn cá»§a má»™t thuáº­t toÃ¡n, khÃ´ng cÃ³ hÆ°á»›ng dáº«n tá»± nhiÃªn nÃ o, theo sau bá»Ÿi má»™t Ä‘áº§u vÃ o thá»© hai. Táº¥t cáº£ cÃ¡c list vÃ  matrix trong hai táº­p dá»¯ liá»‡u kiá»ƒm tra chá»©a cÃ¡c token má»›i khÃ´ng tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Äá»‘i vá»›i cáº£ hai loáº¡i prompt, nhiá»‡m vá»¥ trong ngá»¯ cáº£nh lÃ  dá»± Ä‘oÃ¡n Ä‘áº§u ra cá»§a thuáº­t toÃ¡n khi Ã¡p dá»¥ng vÃ o Ä‘áº§u vÃ o (cuá»‘i cÃ¹ng). LÆ°u Ã½ ráº±ng Ä‘á»‘i vá»›i prompt dá»±a trÃªn vÃ­ dá»¥, CSCG pháº£i suy ra thuáº­t toÃ¡n Ä‘Æ°á»£c sá»­ dá»¥ng tá»« vÃ­ dá»¥ Ä‘áº§u tiÃªn. Má»—i táº­p kiá»ƒm tra chá»©a 100 prompt, Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch láº¥y máº«u Ä‘á»“ng nháº¥t cÃ¡c hÆ°á»›ng dáº«n, vÃ  cÃ¡c token list hoáº·c matrix. HÃ¬nh 4A [pháº£i] cho tháº¥y Ä‘á»‹nh dáº¡ng cá»§a hai táº­p kiá»ƒm tra nÃ y.

Huáº¥n luyá»‡n: Äá»‘i vá»›i má»—i token, má»™t CSCG phÃ¢n bá»• sá»‘ lÆ°á»£ng clone tá»· lá»‡ thuáº­n vá»›i sá»‘ lÆ°á»£ng ngá»¯ cáº£nh riÃªng biá»‡t trong dá»¯ liá»‡u huáº¥n luyá»‡n mÃ  nÃ³ xuáº¥t hiá»‡n. ChÃºng tÃ´i tham sá»‘ hÃ³a dung lÆ°á»£ng CSCG thÃ´ng qua há»‡ sá»‘ tá»· lá»‡ nÃ y - "tá»· lá»‡ overallocation". ChÃºng tÃ´i huáº¥n luyá»‡n CSCG cho má»™t chuá»—i tÄƒng dáº§n cá»§a tá»· lá»‡ overallocation trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n vá»›i 500 láº§n láº·p EM vÃ  pseudocount cá»§a ğœ–=10^{-6}. Sau khi cháº¡y EM, chÃºng tÃ´i cháº¡y 10 láº§n láº·p huáº¥n luyá»‡n Viterbi [23].

Káº¿t quáº£: CSCG vá»›i dung lÆ°á»£ng mÃ´ hÃ¬nh Ä‘á»§ há»c thÃ nh cÃ´ng cÃ¡c thuáº­t toÃ¡n tá»« táº­p huáº¥n luyá»‡n, vÃ  tÃ¡i liÃªn káº¿t tá»•ng quÃ¡t hÃ³a cÃ¡c thuáº­t toÃ¡n Ä‘Ã³ sang cÃ¡c token má»›i chá»‰ tháº¥y trong thá»i gian kiá»ƒm tra. HÃ¬nh 4B cho tháº¥y máº¡ch Ä‘Ã£ há»c Ä‘Æ°á»£c trÃ­ch xuáº¥t cho thuáº­t toÃ¡n Ä‘áº£o ngÆ°á»£c list. HÃ¬nh 5[trÃ¡i] trÃ¬nh bÃ y Ä‘á»™ chÃ­nh xÃ¡c trong ngá»¯ cáº£nh cá»§a CSCG (sá»­ dá»¥ng ğœ–=10^{-6} vÃ  ğ‘surprise=0.1) trÃªn hai táº­p kiá»ƒm tra LIALT: CSCG hiá»‡u suáº¥t tá»‘t nháº¥t (a) tÃ¡i liÃªn káº¿t thÃ nh cÃ´ng cÃ¡c sÆ¡ Ä‘á»“ Ä‘Ã£ há»c vá»›i cÃ¡c token má»›i cá»§a prompt kiá»ƒm tra vÃ  (b) suy ra chÃ­nh xÃ¡c thuáº­t toÃ¡n tá»« má»™t cáº·p Ä‘áº§u vÃ o-Ä‘áº§u ra duy nháº¥t cho prompt dá»±a trÃªn vÃ­ dá»¥. HÃ¬nh 5 cÅ©ng cho tháº¥y ráº±ng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh thÃºc Ä‘áº©y hiá»‡u suáº¥t ICL [trÃ¡i] ngay cáº£ khi phÃ¢n tÃ­ch hiá»‡u suáº¥t theo nhiá»‡m vá»¥ [pháº£i].

CSCG Ä‘Ã£ há»c (Ä‘Æ°á»£c khá»Ÿi táº¡o vá»›i tá»· lá»‡ overallocation lÃ  3) Ä‘Æ°á»£c hÃ¬nh dung trong HÃ¬nh 10 trong Phá»¥ lá»¥c, sá»­ dá»¥ng clone Ä‘Æ°á»£c xáº¿p chá»“ng. HÃ¬nh 6[A] cho tháº¥y Ä‘á»“ thá»‹ chuyá»ƒn tiáº¿p sá»­ dá»¥ng thuáº­t toÃ¡n Kamada-Kawai [24]. NÃ³ tiáº¿t lá»™ mÆ°á»i ba cluster káº¿t ná»‘i lá»ng láº»o tÆ°Æ¡ng á»©ng vá»›i mÆ°á»i ba thuáº­t toÃ¡n cÃ³ máº·t trong táº­p dá»¯ liá»‡u LIALT. HÃ¬nh 6[B] minh há»a quÃ¡ trÃ¬nh tÃ¡i liÃªn káº¿t, vá»›i cÃ¡c phÃ¢n bá»‘ Ä‘Ã£ giáº£i mÃ£ trÃªn cÃ¡c tráº¡ng thÃ¡i tiá»m áº©n cá»§a mÃ´ hÃ¬nh CSCG Ä‘Ã£ há»c, cho hai prompt dá»±a trÃªn vÃ­ dá»¥ khÃ¡c nhau. Ngay cáº£ trÆ°á»›c khi tÃ¡i liÃªn káº¿t, viá»‡c xÃ¡c Ä‘á»‹nh anchor vÃ  slot Ä‘Ã£ háº¡n cháº¿ viá»‡c giáº£i mÃ£ vÃ o cÃ¡c sÆ¡ Ä‘á»“ tÆ°Æ¡ng thÃ­ch vá»›i cáº¥u trÃºc prompt â€”trong trÆ°á»ng há»£p nÃ y dá»±a trÃªn dáº¥u ngoáº·c & delimiter. Tuy nhiÃªn, cáº¥u trÃºc khÃ´ng Ä‘á»§ Ä‘á»ƒ phÃ¢n biá»‡t hoÃ n toÃ n giá»¯a cÃ¡c sÆ¡ Ä‘á»“ tÆ°Æ¡ng thÃ­ch (list operations tÆ°Æ¡ng á»©ng vá»›i Ä‘áº£o ngÆ°á»£c, dá»‹ch chuyá»ƒn trÃ²n vá» phÃ­a trÆ°á»›c vÃ  dá»‹ch chuyá»ƒn trÃ²n vá» phÃ­a sau), vÃ  cáº£ hai prompt Ä‘Æ°á»£c chá»n Ä‘á»u dáº«n Ä‘áº¿n cÃ¹ng má»™t phÃ¢n bá»‘ tráº¡ng thÃ¡i tiá»m áº©n. Do Ä‘Ã³, phÃ¢n bá»‘ Ä‘Ã£ giáº£i mÃ£ sau E-step Ä‘áº§u tiÃªn Ä‘á»‹nh vá»‹ vÃ o ba sÆ¡ Ä‘á»“ tÆ°Æ¡ng thÃ­ch. Trong M-step theo sau, cÃ¡c slot trong cáº£ ba sÆ¡ Ä‘á»“ sáº½ Ä‘Æ°á»£c tÃ¡i liÃªn káº¿t cho prompt nÃ y. Cuá»‘i láº§n láº·p EM Ä‘áº§u tiÃªn, cÃ¡c liÃªn káº¿t má»›i cho cÃ¡c slot trong sÆ¡ Ä‘á»“ chÃ­nh xÃ¡c sáº½ ráº¥t cháº¯c cháº¯n do báº±ng chá»©ng nháº¥t quÃ¡n, trong khi báº±ng chá»©ng khÃ´ng nháº¥t quÃ¡n sáº½ dáº«n Ä‘áº¿n cÃ¡c liÃªn káº¿t khÃ´ng cháº¯c cháº¯n cho cÃ¡c slot khÃ¡c. Trong E-step cá»§a láº§n láº·p thá»© hai, cÃ¡c má»©c Ä‘á»™ cháº¯c cháº¯n tÆ°Æ¡ng á»©ng trong cÃ¡c liÃªn káº¿t sau Ä‘Ã³ giÃºp thÃºc Ä‘áº©y sÆ¡ Ä‘á»“ thuáº­t toÃ¡n chÃ­nh xÃ¡c trá»Ÿ thÃ nh viá»‡c giáº£i mÃ£ cÃ³ kháº£ nÄƒng cao nháº¥tâ€”vÃ  hoÃ n thÃ nh prompt má»™t cÃ¡ch thÃ­ch há»£p. LÆ°u Ã½ ráº±ng má»™t bÆ°á»›c EM duy nháº¥t Ä‘á»§ Ä‘á»ƒ Ä‘Æ°a ra tÃ¡i liÃªn káº¿t chÃ­nh xÃ¡c trong cÃ¡c vÃ­ dá»¥ nÃ y. So sÃ¡nh HÃ¬nh 5 & 11, vÃ  cÃ¡c báº£ng trong Phá»¥ lá»¥c Má»¥c D.3 Ä‘á»ƒ biáº¿t cÃ¡ch hiá»‡u suáº¥t hoÃ n thÃ nh trong ngá»¯ cáº£nh sau bÆ°á»›c EM Ä‘áº§u tiÃªn trong quÃ¡ trÃ¬nh tÃ¡i liÃªn káº¿t ráº¥t tÆ°Æ¡ng tá»± vá»›i hiá»‡u suáº¥t khi káº¿t thÃºc há»™i tá»¥ EM.

Káº¿t quáº£ LIALT cá»§ng cá»‘ cÃ¡c láº­p luáº­n chÃºng tÃ´i Ä‘Æ°a ra trong Má»¥c 3.2 vÃ  3.3. TÆ°Æ¡ng tá»± nhÆ° GINC Má»¥c 4.1, giáº£i thÃ­ch suy luáº­n Bayesian suy ra ngá»¯ cáº£nh tiá»m áº©n dá»±a trÃªn tÃ­nh nháº¥t quÃ¡n dÃ i háº¡n khÃ´ng giáº£i thÃ­ch Ä‘Æ°á»£c viá»‡c Ã¡nh xáº¡ láº¡i biá»ƒu diá»…n tiá»m áº©n sang cÃ¡c token hoÃ n toÃ n má»›i nhÆ° yÃªu cáº§u Ä‘á»ƒ tá»•ng quÃ¡t hÃ³a cÃ¡c thuáº­t toÃ¡n trong LIALT. KhÃ´ng cÃ³ tÃ¡i liÃªn káº¿t, má»™t prompt chá»©a vÃ­ dá»¥ Ä‘áº§y Ä‘á»§ Ä‘á»™ dÃ i cá»§a má»™t thuáº­t toÃ¡n khÃ´ng Ä‘á»‹nh vá»‹ sÆ¡ Ä‘á»“ thuáº­t toÃ¡n chÃ­nh xÃ¡c hoáº·c táº¡o ra viá»‡c hoÃ n thÃ nh chÃ­nh xÃ¡c dá»±a trÃªn suy luáº­n trÃªn cÃ¡c tráº¡ng thÃ¡i tiá»m áº©n má»™t mÃ¬nh (HÃ¬nh 6[B], hÃ ng Ä‘áº§u tiÃªn), trÃ¡i ngÆ°á»£c vá»›i káº¿t quáº£ tá»« táº­p dá»¯ liá»‡u GINC. SÆ¡ Ä‘á»“ thuáº­t toÃ¡n chÃ­nh xÃ¡c khÃ´ng thá»ƒ Ä‘Æ°á»£c truy xuáº¥t vÃ¬ prompt chá»©a cÃ¡c token má»›i khÃ´ng tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n thuáº­t toÃ¡n Ä‘Ã³. NgÆ°á»£c láº¡i, suy luáº­n Ä‘á»“ng thá»i tÃ¡i liÃªn káº¿t vÃ  cÃ¡c tráº¡ng thÃ¡i tiá»m áº©n dáº«n Ä‘áº¿n truy xuáº¥t chÃ­nh xÃ¡c sÆ¡ Ä‘á»“ thuáº­t toÃ¡n vÃ  hoÃ n thÃ nh prompt chÃ­nh xÃ¡c (HÃ¬nh 6[B], hÃ ng thá»© hai vÃ  thá»© ba). Sá»­ dá»¥ng tÃ¡i liÃªn káº¿t, CSCG cÃ³ thá»ƒ há»c cÃ¡c thuáº­t toÃ¡n seq2seq vÃ  tá»•ng quÃ¡t hÃ³a cÃ¡c thuáº­t toÃ¡n Ä‘Ã³ sang cÃ¡c token má»›i khÃ´ng gáº·p pháº£i trong huáº¥n luyá»‡n.

Sá»± xuáº¥t hiá»‡n: Hiá»‡u suáº¥t ICL cá»§a CSCG trÃªn táº­p dá»¯ liá»‡u LIALT cho tháº¥y cÃ¡c Ä‘áº·c tÃ­nh Ä‘Æ°á»£c quy cho sá»± xuáº¥t hiá»‡n: Ä‘á»™ chÃ­nh xÃ¡c cá»§a há»c trong ngá»¯ cáº£nh cÃ³ sá»± phá»¥ thuá»™c rÃµ rÃ ng vÃ o má»©c Ä‘á»™ overparameterization cá»§a CSCG, Ä‘Æ°a ra báº±ng chá»©ng há»— trá»£ cho giáº£ thuyáº¿t cá»§a chÃºng tÃ´i trong má»¥c 3.4.

### 4.3. Kiá»ƒm tra Dax

Trong ngÃ´n ngá»¯, kiá»ƒm tra "dax" [25] Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chá»©ng minh kháº£ nÄƒng cá»§a má»™t mÃ´ hÃ¬nh háº¥p thá»¥ viá»‡c sá»­ dá»¥ng má»™t tá»« hoÃ n toÃ n má»›i tá»« má»™t láº§n trÃ¬nh bÃ y duy nháº¥t. Äá»ƒ kiá»ƒm tra kháº£ nÄƒng nÃ y, chÃºng tÃ´i huáº¥n luyá»‡n má»™t CSCG trÃªn táº­p dá»¯ liá»‡u PreCo [26], lÃ  má»™t táº­p dá»¯ liá»‡u tiáº¿ng Anh quy mÃ´ lá»›n cho phÃ¢n giáº£i coreference. Sau Ä‘Ã³ chÃºng tÃ´i kiá»ƒm tra mÃ´ hÃ¬nh trÃªn nÄƒm prompt truy váº¥n thay tháº¿ tá»«, nÆ¡i má»™t sá»‘ tá»« trong prompt khÃ´ng xuáº¥t hiá»‡n trong táº­p huáº¥n luyá»‡n. ChÃºng tÃ´i sá»­ dá»¥ng Thuáº­t toÃ¡n 1 vá»›i ğœ–=10^{-6} vÃ  ğ‘surprise=1/16 Ä‘á»ƒ tÃ¡i liÃªn káº¿t ma tráº­n phÃ¡t xáº¡ trÃªn má»—i prompt nÃ y, má»—i láº§n thÄƒm dÃ² mÃ´ hÃ¬nh Ä‘á»ƒ hoÃ n thÃ nh cÃ¢u báº±ng cÃ¡ch Ä‘iá»n vÃ o chá»— trá»‘ng (Ä‘áº§u vÃ o khÃ´ng cháº¯c cháº¯n) sá»­ dá»¥ng suy luáº­n MAP. HÃ¬nh 7 cho tháº¥y cÃ¡c káº¿t quáº£ nÃ y.

Káº¿t quáº£ cho tháº¥y mÃ´ hÃ¬nh cÃ³ thá»ƒ háº¥p thá»¥ cÃ¡c tá»« má»›i nhÆ° "terras" (thay cho "planets"), "cycles" (thay cho "bikes"), "AG" (thay cho "artificial"), vÃ  sá»­ dá»¥ng chÃºng trong ngá»¯ cáº£nh tÆ°Æ¡ng tá»±.

## 5. CÃ´ng trÃ¬nh liÃªn quan

Há»c trong ngá»¯ cáº£nh (ICL): TÆ°Æ¡ng tá»± nhÆ° cÃ¡ch con ngÆ°á»i há»c báº±ng phÃ©p loáº¡i suy [27] vÃ  cÃ¡ch tÃ­nh dáº»o synaptic cho phÃ©p nÃ£o thÃ­ch nghi nhanh chÃ³ng vá»›i nhiá»‡m vá»¥ má»›i [28], ICL cho phÃ©p má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c há»c má»™t nhiá»‡m vá»¥ má»›i chá»‰ vá»›i má»™t vÃ i vÃ­ dá»¥. Ká»ƒ tá»« khi [1] chá»©ng minh kháº£ nÄƒng ICL cá»§a GPT-3, má»™t khá»‘i lÆ°á»£ng lá»›n cÃ´ng trÃ¬nh Ä‘Ã£ cá»‘ gáº¯ng cáº£i thiá»‡n kháº£ nÄƒng nÃ y. [29, 30] Ä‘Ã£ chá»‰ ra cÃ¡ch cÃ¡c minh há»a hÆ°á»›ng dáº«n rÃµ rÃ ng quÃ¡ trÃ¬nh lÃ½ luáº­n cáº£i thiá»‡n hiá»‡u suáº¥t ICL cá»§a transformer trÃªn cÃ¡c nhiá»‡m vá»¥ phá»©c táº¡p má»›i.

á» Ä‘Ã¢y, chÃºng tÃ´i Ä‘áº§u tiÃªn lÃ m rÃµ má»™t sá»‘ khÃ¡i niá»‡m khÃ´ng nÃªn bá»‹ nháº§m láº«n vá»›i ICL. Sau Ä‘Ã³ chÃºng tÃ´i tháº£o luáº­n má»™t sá»‘ cÃ´ng trÃ¬nh nháº±m hiá»ƒu ICL vÃ  cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n nÃ³.

Há»c cÃ³ giÃ¡m sÃ¡t (SL) vÃ  há»c few-shot (FSL): CÃ¡c cÃ¡ch tiáº¿p cáº­n SL há»c má»™t Ã¡nh xáº¡ giáº£m thiá»ƒu loss trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n: cÃ¡c phÆ°Æ¡ng phÃ¡p gradient lÃ  má»™t paradigm phá»• biáº¿n [31, 32, 33]. Trong cháº¿ Ä‘á»™ FSL, má»™t mÃ´ hÃ¬nh há»c thÃ­ch nghi nhanh chÃ³ng vá»›i nhiá»‡m vá»¥ má»›i tá»« sá»‘ lÆ°á»£ng háº¡n cháº¿ cÃ¡c vÃ­ dá»¥ cÃ³ giÃ¡m sÃ¡t [34, 35, 36], vÃ  Ä‘Æ°á»£c yÃªu cáº§u thá»±c hiá»‡n cÃ¹ng nhiá»‡m vá»¥ nÃ y táº¡i suy luáº­n. NgÆ°á»£c láº¡i, trong khi má»™t sá»‘ cÃ´ng trÃ¬nh [37, 38, 39, 40] tinh chá»‰nh mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c cho ICL, cÃ¡c nhiá»‡m vá»¥ ICL má»›i chá»‰ Ä‘Æ°á»£c tiáº¿t lá»™ trong quÃ¡ trÃ¬nh suy luáº­n. [38, 37] Ä‘Ã£ chá»‰ ra ráº±ng tinh chá»‰nh transformer trÃªn hÆ°á»›ng dáº«n cáº£i thiá»‡n hiá»‡u suáº¥t ICL cá»§a chÃºng.

Meta-learning: Paradigm meta-learning nháº±m há»c Ä‘á»ƒ thÃ­ch nghi vá»›i nhiá»‡m vá»¥ má»›i chá»‰ vá»›i má»™t vÃ i vÃ­ dá»¥ [41, 42, 43] báº±ng cÃ¡ch sá»­ dá»¥ng nhiá»u kinh nghiá»‡m há»c táº­p. NgÆ°á»£c láº¡i, ICL xuáº¥t hiá»‡n trá»±c tiáº¿p tá»« mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. [39, 40] Ä‘Ã£ Ä‘á» xuáº¥t má»™t khung meta-learning cho ICL nÆ¡i mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh: nÃ³ há»c táº­n dá»¥ng cÃ¡c vÃ­ dá»¥ few-shot vÃ  thÃ­ch nghi vá»›i cÃ¡c nhiá»‡m vá»¥ má»›i táº¡i thá»i Ä‘iá»ƒm suy luáº­n.

CÃ¡ch ICL hoáº¡t Ä‘á»™ng: Má»™t sá»‘ nghiÃªn cá»©u Ä‘Ã£ lÃ m ná»•i báº­t vai trÃ² cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n trong ICL. [44] Ä‘Ã£ chá»‰ ra ráº±ng ICL xuáº¥t hiá»‡n khi dá»¯ liá»‡u huáº¥n luyá»‡n cÃ³ (a) cÃ¡c vÃ­ dá»¥ xuáº¥t hiá»‡n theo cá»¥m, vÃ  (b) sá»‘ lÆ°á»£ng lá»›n cÃ¡c lá»›p hiáº¿m. [3] Ä‘Ã£ giáº£i thÃ­ch ICL nhÆ° suy luáº­n Bayesian ngáº§m vÃ  xÃ¢y dá»±ng táº­p dá»¯ liá»‡u GINC (xem Má»¥c 4.1) Ä‘á»ƒ chá»©ng minh ICL. Má»™t sá»‘ cÃ´ng trÃ¬nh cÅ©ng Ä‘Ã£ cá»‘ gáº¯ng hiá»ƒu cÆ¡ cháº¿ cá»§a ICL. [45] Ä‘Ã£ trá»«u tÆ°á»£ng hÃ³a ICL nhÆ° má»™t bÃ i toÃ¡n há»c thuáº­t toÃ¡n vÃ  phÃ¡t hiá»‡n ráº±ng transformer cÃ³ thá»ƒ suy ra ngáº§m má»™t hÃ m giáº£ thuyáº¿t. TÆ°Æ¡ng tá»±, [46] Ä‘Ã£ chá»‰ ra ráº±ng transformer cÃ³ thá»ƒ Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ thá»±c hiá»‡n ICL cá»§a cÃ¡c hÃ m tuyáº¿n tÃ­nh chÆ°a tháº¥y, vá»›i hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i bá»™ Æ°á»›c lÆ°á»£ng bÃ¬nh phÆ°Æ¡ng tá»‘i thiá»ƒu tá»‘i Æ°u. [47] Ä‘Ã£ chá»‰ ra ráº±ng, trong trÆ°á»ng há»£p tuyáº¿n tÃ­nh, transformer (a) triá»ƒn khai ngáº§m gradient descent vÃ  (b) huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh tuyáº¿n tÃ­nh ngáº§m trÃªn cÃ¡c vÃ­ dá»¥ ICL. [4] Ä‘Ã£ Ä‘á» xuáº¥t má»™t sá»± Ä‘á»‘i ngáº«u giá»¯a attention transformer vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p gradient vÃ  gá»£i Ã½ ráº±ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c lÃ  meta-optimizer. Há» Ä‘Ã£ trÃ¬nh bÃ y ICL nhÆ° tinh chá»‰nh ngáº§m, nÆ¡i forward pass trÃªn cÃ¡c vÃ­ dá»¥ minh há»a táº¡o ra meta-gradient. Cuá»‘i cÃ¹ng, [5] Ä‘Ã£ chá»‰ ra sá»± tá»“n táº¡i cá»§a "induction heads" trong transformer, xuáº¥t hiá»‡n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, sao chÃ©p cÃ¡c pattern trÆ°á»›c Ä‘Ã³ vÃ  thÃºc Ä‘áº©y kháº£ nÄƒng ICL.

Nhá»¯ng gÃ¬ áº£nh hÆ°á»Ÿng Ä‘áº¿n ICL: [48] Ä‘Ã£ Ä‘á» xuáº¥t má»™t thay tháº¿ cho mÃ£ hÃ³a vá»‹ trÃ­, vÃ  chá»©ng minh cÃ¡ch transformer cÃ³ thá»ƒ há»c sÆ¡ Ä‘á»“ cho cÃ¡c nhiá»‡m vá»¥ thuáº­t toÃ¡n vÃ  tá»•ng quÃ¡t hÃ³a sang cÃ¡c chuá»—i kiá»ƒm tra dÃ i hÆ¡n báº¥t ká»³ chuá»—i nÃ o tháº¥y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. [49] Ä‘Ã£ lÃ m ná»•i báº­t ráº±ng (a) ICL cÃ³ thá»ƒ xuáº¥t hiá»‡n khi má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn sá»± káº¿t há»£p cá»§a nhiá»u corpus (b) perplexity tháº¥p vÃ  hiá»‡u suáº¥t ICL khÃ´ng luÃ´n tÆ°Æ¡ng quan. [1, 3] Ä‘Ã£ phÃ¡t hiá»‡n ráº±ng hiá»‡u suáº¥t ICL cá»§a transformer cáº£i thiá»‡n vá»›i (a) kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh vÃ  (b) sá»‘ lÆ°á»£ng vÃ­ dá»¥ minh há»a. TÆ°Æ¡ng tá»±, [50] Ä‘Ã£ chá»‰ ra ráº±ng ICL "xuáº¥t hiá»‡n" khi kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh tÄƒng.

Má»™t sá»‘ cÃ´ng trÃ¬nh Ä‘Ã£ nghiÃªn cá»©u áº£nh hÆ°á»Ÿng cá»§a cÃ¡c máº«u minh há»a trong ICL. [51, 52] Ä‘Ã£ phÃ¡t hiá»‡n ráº±ng ICL ráº¥t khÃ´ng á»•n Ä‘á»‹nh vÃ  bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi máº«u prompting, viá»‡c lá»±a chá»n cÃ¡c vÃ­ dá»¥ trong ngá»¯ cáº£nh, vÃ  thá»© tá»± cá»§a cÃ¡c vÃ­ dá»¥. [53] Ä‘Ã£ chá»‰ ra ráº±ng hiá»‡u suáº¥t ICL Ä‘Æ°á»£c thÃºc Ä‘áº©y bá»Ÿi viá»‡c tiáº¿p xÃºc vá»›i (a) khÃ´ng gian nhÃ£n, (b) phÃ¢n bá»‘ Ä‘áº§u vÃ o, vÃ  (c) Ä‘á»‹nh dáº¡ng tá»•ng thá»ƒ cá»§a chuá»—i. TÆ°Æ¡ng tá»±, [54] Ä‘Ã£ phÃ¡t hiá»‡n ráº±ng viá»‡c chá»n cÃ¡c vÃ­ dá»¥ ICL vá»›i embedding gáº§n hÆ¡n vá»›i máº«u kiá»ƒm tra ICL cáº£i thiá»‡n hiá»‡u suáº¥t ICL, vÃ  [55] Ä‘Ã£ phÃ¡t hiá»‡n ráº±ng thÃªm giáº£i thÃ­ch trong ngá»¯ cáº£nh cáº£i thiá»‡n hiá»‡u suáº¥t. Cuá»‘i cÃ¹ng, [56] gáº§n Ä‘Ã¢y Ä‘Ã£ tuyÃªn bá»‘ ráº±ng sá»± xuáº¥t hiá»‡n rÃµ nÃ©t cá»§a ICL trong cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n cÃ³ thá»ƒ lÃ  má»™t táº¡o tÃ¡c cá»§a cÃ¡c metric, khÃ´ng pháº£i lÃ  thuá»™c tÃ­nh cÆ¡ báº£n cá»§a mÃ´ hÃ¬nh.

## 6. Tháº£o luáº­n

Má»™t sá»‘ giáº£i thÃ­ch trÆ°á»›c Ä‘Ã¢y cho ICL, bao gá»“m suy luáº­n Bayesian [3] vÃ  gradient descent ngáº§m [4], Ä‘Ã£ xá»­ lÃ½ táº¥t cáº£ ná»™i dung nhÆ° nhau mÃ  khÃ´ng tÃ¡ch ra nhá»¯ng Ä‘Ã³ng gÃ³p cá»§a ná»™i dung vis-Ã -vis vá»‹ trÃ­. NhÆ° chÃºng tÃ´i Ä‘Ã£ chá»‰ ra, tá»•ng quÃ¡t hÃ³a nhiá»u thuáº­t toÃ¡n Ä‘Ã²i há»i cÃ¡c máº«u cÃ³ thá»ƒ gating ná»™i dung dá»±a trÃªn cÃ¡c pattern trong cáº£ ná»™i dung vÃ  vá»‹ trÃ­. ChÃºng tÃ´i láº­p luáº­n ráº±ng cÃ¡c lÃ½ thuyáº¿t cÃ³ thá»ƒ cáº§n nháº¥n máº¡nh sá»± phÃ¢n biá»‡t nÃ y (xem HÃ¬nh 8A) Ä‘á»ƒ hiá»ƒu Ä‘áº§y Ä‘á»§ cÃ¡c bias quy náº¡p Ä‘áº±ng sau ICL.

TÃ¡i liÃªn káº¿t trong CSCG Ä‘Ã²i há»i cÃ¡c thay Ä‘á»•i trá»ng sá»‘ Ä‘Æ°á»£c báº£n Ä‘á»‹a hÃ³a cho ma tráº­n phÃ¡t xáº¡. KhÃ´ng giá»‘ng nhÆ° CSCG, transformer Ä‘á»‡m cÃ¡c Ä‘áº§u vÃ o vÃ  sá»­ dá»¥ng attention cho má»¥c Ä‘Ã­ch gating. Nhá» mÃ£ hÃ³a vá»‹ trÃ­, transformer cÃ³ thá»ƒ gating cáº£ theo vá»‹ trÃ­ vÃ  ná»™i dung. VÃ¬ attention Ä‘Æ°á»£c triá»ƒn khai nhÆ° má»™t pháº§n cá»§a forward pass, quÃ¡ trÃ¬nh slotting sá»‘ng trong khÃ´ng gian kÃ­ch hoáº¡t (trÃ¡i vá»›i viá»‡c yÃªu cáº§u thay Ä‘á»•i trá»ng sá»‘). ÄÃ¢y chá»‰ lÃ  má»™t sá»± khÃ¡c biá»‡t bá» ngoÃ i: cÃ³ thá»ƒ unroll temporally quÃ¡ trÃ¬nh tÃ¡i liÃªn káº¿t trong CSCG, Ä‘á»ƒ cung cáº¥p má»™t thuáº­t toÃ¡n cho cÃ¹ng Ä‘áº§u ra, nhÆ°ng vá»›i trá»ng sá»‘ cá»‘ Ä‘á»‹nh.

Phá»ng Ä‘oÃ¡n cá»§a chÃºng tÃ´i lÃ  cÃ¡c lá»›p cá»§a transformer triá»ƒn khai nhiá»u máº«u há»—n há»£p cá»§a vá»‹ trÃ­ vÃ  ná»™i dung, Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ táº¡i cÃ¡c offset khÃ¡c nhau cá»§a má»™t prompt. Viá»‡c láº¯p rÃ¡p máº«u cÃ³ thá»ƒ khá»›p autoregressive prompt tháº¯ng cuá»™c trong cuá»™c cáº¡nh tranh Ä‘á»ƒ gating ná»™i dung.

Máº·c dÃ¹ chÃºng tÃ´i Ä‘Ã£ minh há»a á»Ÿ Ä‘Ã¢y khÃ¡i niá»‡m tÃ¡i liÃªn káº¿t Ä‘á»ƒ gáº¯n cÃ¡c kÃ½ hiá»‡u má»›i vÃ o cÃ¡c slot hiá»‡n cÃ³, tÃ¡i liÃªn káº¿t cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n "qua thá»i gian". Giá»‘ng nhÆ° trong cÃ¡c vÃ­ dá»¥ cá»§a chÃºng tÃ´i, cÃ¡c káº¿t ná»‘i giá»¯a cÃ¡c clone (ğ‘‡) váº«n khÃ´ng thay Ä‘á»•i, nhÆ°ng káº¿t ná»‘i giá»¯a cÃ¡c clone vÃ  cÃ¡c kÃ½ hiá»‡u (ğ¸) Ä‘Æ°á»£c tÃ¡i liÃªn káº¿t dá»±a trÃªn prompt, cÃ³ thá»ƒ lÃ m ngÆ°á»£c láº¡i, tÃ¡i liÃªn káº¿t cÃ¡c káº¿t ná»‘i giá»¯a cÃ¡c clone (ğ‘‡) trong khi giá»¯ káº¿t ná»‘i vá»›i cÃ¡c kÃ½ hiá»‡u (ğ¸) khÃ´ng thay Ä‘á»•i. VÃ­ dá»¥, cÃ³ thá»ƒ cÃ³ má»™t sÆ¡ Ä‘á»“ trong ğ‘‡ nháº­n dáº¡ng má»™t hÆ°á»›ng dáº«n, vÃ  má»™t sÆ¡ Ä‘á»“ khÃ¡c thá»±c hiá»‡n nÃ³, Ä‘Æ°á»£c kÃ­ch hoáº¡t bá»Ÿi clone cuá»‘i cÃ¹ng cá»§a bá»™ nháº­n dáº¡ng hÆ°á»›ng dáº«n. Náº¿u chÃºng ta muá»‘n má»™t hÆ°á»›ng dáº«n Ä‘Ã£ biáº¿t vÃ  táº¥t cáº£ cÃ¡c biáº¿n thá»ƒ cá»§a nÃ³ thá»±c hiá»‡n má»™t nhiá»‡m vá»¥ khÃ¡c, cÃ³ thá»ƒ Ä‘Æ¡n giáº£n tÃ¡i liÃªn káº¿t clone cuá»‘i cÃ¹ng cá»§a bá»™ nháº­n dáº¡ng hÆ°á»›ng dáº«n vá»›i trigger cá»§a nhiá»‡m vá»¥ má»›i. Cáº£ hai loáº¡i tÃ¡i liÃªn káº¿t cÃ³ thá»ƒ Ä‘Æ°á»£c káº¿t há»£p. Transformer cÅ©ng cho tháº¥y loáº¡i tá»•ng quÃ¡t hÃ³a nÃ y, nhÆ°ng chÃºng tÃ´i Ä‘á»ƒ láº¡i chi tiáº¿t cá»§a cÃ¡ch tiáº¿p cáº­n nÃ y cho cÃ´ng viá»‡c tÆ°Æ¡ng lai.

## Lá»i cáº£m Æ¡n

ChÃºng tÃ´i cáº£m Æ¡n Stephanie Chan, Andrew Lampinen, Anirudh Goyal, Dharshan Kumaran, Neel Nanda vÃ  Guangyao Zhou cho nhá»¯ng tháº£o luáº­n há»¯u Ã­ch vÃ  nháº­n xÃ©t vá» báº£n tháº£o.

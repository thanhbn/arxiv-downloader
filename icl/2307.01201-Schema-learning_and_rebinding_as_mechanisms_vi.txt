# Học sơ đồ và tái liên kết như những cơ chế của học trong ngữ cảnh và sự xuất hiện
Sivaramakrishnan Swaminathan1, Antoine Dedieu1, Rajkumar Vasudeva Raju1, Murray Shanahan1, Miguel
Lázaro-Gredilla1và Dileep George1
1Google DeepMind

Học trong ngữ cảnh (ICL) là một trong những khả năng mạnh mẽ nhất và bất ngờ nhất xuất hiện trong các mô hình ngôn ngữ lớn (LLM) dựa trên transformer gần đây. Tuy nhiên, các cơ chế nằm dưới nó được hiểu kém. Trong bài báo này, chúng tôi chứng minh rằng những khả năng ICL tương tự có thể được đạt được bằng một phương pháp học dự đoán chuỗi thay thế sử dụng đồ thị nhân quả có cấu trúc nhân bản (CSCG). Hơn nữa, một tính chất quan trọng của CSCG là, không giống như các LLM dựa trên transformer, chúng có thể diễn giải được, điều này đơn giản hóa đáng kể nhiệm vụ giải thích cách ICL hoạt động. Cụ thể, chúng tôi chỉ ra rằng nó sử dụng sự kết hợp của (a) học các mạch mẫu (sơ đồ) để hoàn thành pattern, (b) truy xuất các mẫu liên quan một cách nhạy cảm ngữ cảnh, và (c) tái liên kết các token mới vào các slot thích hợp trong mẫu. Chúng tôi tiếp tục tập hợp bằng chứng cho giả thuyết rằng những cơ chế tương tự nằm dưới ICL trong các LLM. Ví dụ, chúng tôi phát hiện rằng, với CSCG như với LLM, các khả năng khác nhau xuất hiện ở các mức độ tham số hóa quá mức khác nhau, gợi ý rằng tham số hóa quá mức giúp học các mạch mẫu (sơ đồ) phức tạp hơn. Bằng cách chỉ ra cách ICL có thể đạt được với các mô hình và tập dữ liệu nhỏ, chúng tôi mở ra một con đường đến các kiến trúc mới và tiến một bước quan trọng hướng tới sự hiểu biết tổng quát hơn về cơ chế đằng sau khả năng quan trọng này.

## 1. Giới thiệu

Trong một mô hình chuỗi được huấn luyện trước, học trong ngữ cảnh (ICL), hay prompting few-shot, là khả năng học một nhiệm vụ mới từ một tập nhỏ các ví dụ được trình bày trong ngữ cảnh (prompt) tại thời điểm suy luận. Đáng ngạc nhiên, các mô hình ngôn ngữ lớn (LLM) được huấn luyện trên dữ liệu đủ lớn thể hiện ICL, mặc dù chúng chỉ được huấn luyện với mục tiêu dự đoán token tiếp theo [1, 2]. Một phần lớn sự phấn khích đang diễn ra xung quanh LLM nảy sinh từ khả năng bất ngờ này, vì nó mở rộng đáng kể tập hợp các ứng dụng tiềm năng của chúng. Những nỗ lực hiểu khả năng này đang tiếp tục và có nhiều hình thức khác nhau, bao gồm các tài khoản chuẩn hóa cấp cao hơn sử dụng suy luận Bayesian [3], và các giải thích cơ chế liên quan đến gradient descent ngầm [4] hoặc induction heads [5]. Mặc dù vậy, các cơ chế nằm dưới ICL trong LLM vẫn hơi bí ẩn.

Trong bài báo này, chúng tôi thực hiện một cách tiếp cận khác. Chúng tôi tiết lộ các điều kiện thúc đẩy ICL trong một mô hình học chuỗi khác được gọi là đồ thị nhân quả có cấu trúc nhân bản (CSCG) [6, 7]. Sử dụng sự kết hợp của các tập dữ liệu mới và tiêu chuẩn, chúng tôi chỉ ra cách một CSCG gán xác suất khác không cho các chuỗi chưa từng thấy trong quá trình huấn luyện theo cách mà, nhờ cấu trúc đồ thị nhân quả của mô hình, có thể diễn giải một cách rõ ràng và cơ chế. Chúng tôi đưa ra giả thuyết rằng các cơ chế tương tự sẽ tồn tại trong các LLM dựa trên transformer, và chỉ ra cách điều này có thể xảy ra.

Cụ thể, chúng tôi chỉ ra rằng ICL trong CSCG có thể được giải thích như sự kết hợp của (a) học các mạch mẫu để hoàn thành pattern, (b) truy xuất các mẫu liên quan một cách nhạy cảm ngữ cảnh, và (c) tái liên kết các token mới vào các slot thích hợp trong các mẫu đã học [8]. Không giống như các mô hình n-gram, CSCG cho phép tổng quát hóa bắc cầu trong không gian tiềm ẩn, điều này gán xác suất khác không cho các chuỗi chưa từng thấy trong quá trình huấn luyện theo cách có ý nghĩa về mặt ngữ nghĩa, đảm bảo rằng các ngữ cảnh (prompt) được sử dụng để truy xuất không phải là sự ghi nhớ thuần túy. Ngoài ra, việc liên kết các token mới vào các slot trong các mẫu đã học cho phép cùng một kiến thức cấu trúc được áp dụng cho các đầu vào hoàn toàn mới. Bằng cách làm rõ các nguyên tắc làm nền tảng cho cơ chế của ICL, chúng tôi hy vọng mở đường cho việc thiết kế các kiến trúc mới cho sự trừu tượng hóa và tổng quát hóa, trong khi các khối xây dựng mà chúng tôi xác định hướng dẫn việc tìm kiếm các mạch có thể diễn giải cơ chế [9] và chỉnh sửa được [10] trong transformer [11].

## 2. Thuật toán tái liên kết cho đồ thị nhân quả có cấu trúc nhân bản

### 2.1. Nền tảng về đồ thị nhân quả có cấu trúc nhân bản (CSCG)

Xem xét một agent thực hiện một loạt các hành động rời rạc 𝑎1,...,𝑎𝑁−1 với 𝑎𝑛∈{1,...,𝑁 actions}, ví dụ đi bộ trong phòng. Kết quả của mỗi hành động, agent nhận được một quan sát có bí danh tri giác [12], dẫn đến dòng các biến ngẫu nhiên 𝑋1,...,𝑋𝑁 với các giá trị quan sát 𝑥1,...,𝑥𝑁, trong đó mỗi 𝑥𝑛∈{1,...,𝑁 obs}. CSCG [6] là một mô hình học chuỗi xác suất học các đồ thị tiềm ẩn để mô hình hóa các chuỗi có điều kiện hành động này. Một CSCG có thể khôi phục một đồ thị đại diện cho cấu trúc nhân quả tiềm ẩn [13] của môi trường (ví dụ phòng), sau đó có thể được sử dụng để lập kế hoạch hành động trong môi trường đó. CSCG giới thiệu một biến giải thích tiềm ẩn 𝑍𝑛 tại mỗi bước thời gian 𝑛, với các giá trị 𝑧𝑛∈{1,...,𝑁 latent}, để loại bỏ tính mơ hồ của các quan sát có bí danh tri giác. Sau đó nó mô hình hóa dòng quan sát như

𝑃(𝑥1,...,𝑥𝑁|𝑎1,...,𝑎𝑁−1)=∑︁𝑧1,...,𝑧𝑛𝑃(𝑥1|𝑧1)𝑃(𝑧1)𝑁∏𝑛=2𝑃(𝑥𝑛|𝑧𝑛)𝑃(𝑧𝑛|𝑧𝑛−1,𝑎𝑛−1).

Động lực có điều kiện hành động được biểu diễn bởi một tensor chuyển tiếp 𝑇: 𝑇𝑖𝑗𝑘=𝑃(𝑍𝑛=𝑘|𝑍𝑛−1=𝑗,𝑎𝑛−1=𝑖)∀𝑛, và xác suất quan sát bởi một ma trận phát xạ 𝐸: 𝐸𝑖𝑗=𝑃(𝑋𝑛=𝑗|𝑍𝑛=𝑖)∀𝑛.

Tensor chuyển tiếp 𝑇 định nghĩa một đa đồ thị có hướng, có các node tương ứng với các giá trị của 𝑧. Với điều kiện trên một hành động, mỗi entry của 𝑇 là trọng số của một cạnh có hướng giữa hai node (từ chỉ số hàng đến chỉ số cột của entry đó). Xem Hình 1D để biết ví dụ về đồ thị tiềm ẩn CSCG được khôi phục.

CSCG có một mô hình quan sát tất định. Nghĩa là, đối với mỗi hàng của 𝐸, một entry được đặt thành 1 và phần còn lại thành 0. Do đó, đối với bất kỳ giá trị tiềm ẩn 𝑧 nào, cùng một quan sát 𝑥 luôn được phát ra. Nhiều giá trị của 𝑧 có thể dẫn đến cùng một quan sát 𝑥, làm cho mô hình overcomplete [14]. Sử dụng các trạng thái tiềm ẩn này, một CSCG có thể phân biệt nhiều percept có bí danh (cùng quan sát 𝑥) thành các nguyên nhân riêng biệt (các giá trị tiềm ẩn 𝑧 khác nhau). Ràng buộc của việc 𝐸 tất định làm cho CSCG ít tổng quát hơn mô hình Markov ẩn (HMM), nhưng dễ học hơn [6]. CSCG cũng có thể được sử dụng như một mô hình ngôn ngữ nếu các quan sát tương ứng với các token từ, với hành động duy nhất truy cập token tiếp theo.

### 2.2. Tái liên kết trong CSCG

Khi một agent gặp một môi trường mới có cấu trúc tương tự, nhưng quan sát khác nhau, nó có thể học môi trường đó nhanh hơn bằng cách tái sử dụng đồ thị tiềm ẩn 𝑇 (những gì chúng tôi gọi là sơ đồ) [15] từ kinh nghiệm trước và chỉ học lại ma trận phát xạ. Chúng tôi gọi quá trình này là tái liên kết. Tái liên kết có thể được diễn giải như một can thiệp nhẹ trên mô hình của agent [16, 17]. Xem Hình 1D & F để biết ví dụ về hai phòng có chung cấu trúc tiềm ẩn nhưng quan sát khác nhau. Khi một ma trận phát xạ mới liên kết với một sơ đồ hiện có, nó phải tôn trọng cấu trúc clone của ma trận phát xạ gốc (Hình 1E). Hàm cấu trúc clone C(·)∈{1,...,𝑁 obs} phân vùng trạng thái tiềm ẩn thành 𝑁obs slot: hai trạng thái tiềm ẩn 𝑧=𝑖 và 𝑧=𝑖′ thuộc cùng một clone slot khi và chỉ khi C(𝑖)=C(𝑖′). Một ma trận phát xạ tôn trọng cấu trúc clone C nếu điều kiện C(𝑖)=C(𝑖′)⟹𝐸𝑖𝑗=𝐸𝑖′𝑗∀𝑖,𝑖′,𝑗 được thỏa mãn. 3-tuple {𝑇,C,𝐸} định nghĩa một sơ đồ có nền tảng, tuple {𝑇,C} định nghĩa một sơ đồ không có nền tảng với cấu trúc clone và 𝑇 đơn thuần là một sơ đồ [15].

#### 2.2.1. Tái liên kết nhanh bằng cách chú ý đến sự bất ngờ

Thường thì, các thay đổi môi trường được bản địa hóa sao cho phần lớn cấu trúc tiềm ẩn và ánh xạ quan sát được bảo tồn trong khi chỉ một vài quan sát cần được tái liên kết: ví dụ, chỉ thay thảm trong phòng trong khi màu tường vẫn giữ nguyên, hoặc tiếp xúc với một từ mới trong ngữ cảnh quen thuộc. Insight này có thể được sử dụng để đưa ra một thuật toán tập trung việc cập nhật ma trận phát xạ chỉ vào những quan sát được tìm thấy bất ngờ bởi mô hình hiện có.

Giả sử tại thời điểm kiểm tra, một sơ đồ có nền tảng {𝑇,C,𝐸0} tiếp xúc với một chuỗi có quan sát mới. Thuật toán 1 đề xuất một quy trình nhanh để cập nhật ma trận phát xạ sang quan sát mới bằng cách chỉ thực hiện cập nhật cục bộ, và liên kết ma trận phát xạ đã cập nhật với sơ đồ hiện có 𝑇, định nghĩa một sơ đồ có nền tảng mới {𝑇,C,𝐸rb}. Chúng tôi gọi quá trình này là tái liên kết nhanh.

Cho một prompt (𝑥1,...,𝑥𝑁) và một ngưỡng bất ngờ, Thuật toán 1 tiến hành bằng cách xác định các entry của ma trận phát xạ cần được cập nhật, sau đó cập nhật các entry đó bằng thuật toán Expectation-Maximization (EM) [18]. Xác suất có điều kiện 𝑝(𝑋𝑛=𝑗|𝑥\𝑛) của các token tại bước thời gian 𝑛 cho tất cả các bước thời gian khác được sử dụng để xác định các bước thời gian và trạng thái tiềm ẩn bất ngờ hoặc không. Nếu mô hình hiện tại dự đoán một quan sát với độ tin cậy cao, và quan sát thực sự xảy ra, thì các trạng thái tiềm ẩn tương ứng với các quan sát và bước thời gian đó không nên được cập nhật. Các trạng thái tiềm ẩn và bước thời gian này, được gọi là anchors, được xác định trong Bước 3. Các trạng thái tiềm ẩn tương ứng với các quan sát được dự đoán sai với độ tin cậy cao, nhưng không phải là một trong các trạng thái anchor, là các ứng viên cho tái liên kết. Chúng được xác định trong Bước 4. Cuối cùng, Bước 5 cập nhật cục bộ ma trận phát xạ bằng thuật toán EM chỉ trên các trạng thái tiềm ẩn và bước thời gian được xác định trong bước 4. Đây là một trường hợp đặc biệt của việc cập nhật toàn bộ ma trận phát xạ như mô tả trong [15, Appendix A.2] nơi các tác giả học lại toàn bộ ma trận phát xạ của một CSCG bằng cách giữ sơ đồ 𝑇 cố định. Trái với [15], các cập nhật EM trong Bước 5 của chúng tôi, được mô tả chi tiết trong Phụ lục A, chỉ cập nhật cục bộ ma trận phát xạ. Kết quả là, chỉ một tập con nhỏ các hàng khác nhau giữa 𝐸0 và 𝐸rb. Các hàng được bảo vệ tương ứng với các anchor trong prompt hiện tại, hoặc các slot không liên quan đến prompt hiện tại nhưng vẫn có thể liên quan đến các quan sát tương lai. Pseudocount được sử dụng trong Bước 1 là một tham số bất định cho phép mô hình làm mịn các quan sát không chính xác. Thêm chi tiết về tham số này có sẵn trong [6].

Sau khi tái liên kết, chúng tôi hoàn thành prompt bằng cách thực hiện suy luận MAP có điều kiện trên prompt được cung cấp trong CSCG đã tái liên kết. Chúng tôi chạy thuật toán max-product [19] về phía trước (các thông điệp ngược đều đồng nhất) do đó tạo ra một loạt các quan sát MAP cho các token theo sau prompt. Chúng tôi dừng khi tạo ra một token delimiter. Xem Thuật toán 2 trong Phụ lục B để biết chi tiết.

Mục 6 thảo luận về cách một cơ chế tương tự Thuật toán 1 có thể được triển khai trong transformer sử dụng các đầu vào và kích hoạt được đệm.

## 3. Phác thảo lập luận tổng thể sử dụng CSCG

### 3.1. Biểu diễn tiềm ẩn phụ thuộc ngữ cảnh và tổng quát hóa bắc cầu

Cấu trúc clone của CSCG cho phép tách biệt dựa trên ngữ cảnh và pha trộn thích hợp cho mô hình hóa ngôn ngữ. Ví dụ, nghĩa của từ "bank" trong "bank robber" khác với nghĩa trong "river bank". Việc học CSCG loại bỏ tính mơ hồ của các ngữ cảnh này trong không gian tiềm ẩn bằng cách kết nối chúng với các clone khác nhau để cải thiện độ chính xác dự đoán. Trong Hình 2A, các câu "river bank resort" và "one bank robber" sử dụng các clone khác nhau của "bank". Chuỗi có thể có phân nhánh xác suất: "one bank robber" có thể kết thúc tại "\n", hoặc tiếp tục đến "eating at river bank resort" hoặc "eating bread and honey", hoặc "eating bread and butter at river bank resort" (Hình 2B). CSCG cũng cho phép hợp nhất các ngữ cảnh dẫn đến tổng quát hóa bắc cầu: ngay cả khi dữ liệu huấn luyện chỉ có các chuỗi "bread and butter" và "milk and honey", nếu chúng đi qua cùng một trạng thái clone "and", mô hình sẽ tổng quát hóa thành "bread and honey" và "milk and butter", gán xác suất khác không cho các chuỗi đó. Do sự kết hợp của tách biệt nhạy cảm ngữ cảnh và tính bắc cầu, các chủ đề, khái niệm và thuật toán liên quan được nhóm thành các mạng con đi qua cùng các clone. Ngữ cảnh của prompt sẽ kích hoạt mạng con của nó, và tổng quát hóa bắc cầu cho phép các prompt không phải là sự ghi nhớ chính xác. Như chúng tôi chỉ ra trong Mục 4, quan điểm suy luận Bayesian về ICL [3] tương ứng với việc lưu trữ và truy xuất nhạy cảm ngữ cảnh và tổng quát hóa bắc cầu này một mình, và không đủ để giải thích các thuộc tính ICL mà chúng tôi xem xét trong các mục tiếp theo.

### 3.2. Học sơ đồ linh hoạt (mạch mẫu) và tái liên kết

Giống như học bố cục phòng, CSCG có thể học các mạch automata [20] cho các thuật toán sequence-to-sequence (seq2seq). Xem Hình 2 để biết các mạch CSCG cho parity, sao chép chuỗi, và đảo ngược chuỗi có nhiều độ dài. Mạch đảo ngược danh sách trong Hình 2E được liên kết với các ký hiệu cụ thể 𝐴,𝐵,𝐶,𝐷,𝐸 được sử dụng trong huấn luyện. Để hữu ích như một mẫu, các slot thích hợp trong đồ thị này nên có thể liên kết với các ký hiệu tùy ý xuất hiện trong ngữ cảnh trong thời gian kiểm tra [8, 21]. Một cách trực quan, tái liên kết có thể được hiểu là hoạt động dựa trên lỗi dự đoán - nếu ngữ cảnh tiềm ẩn dự đoán mạnh mẽ trạng thái tiềm ẩn tương ứng với một thời điểm, nhưng quan sát thực tế tại thời điểm đó không khớp, tái liên kết điều chỉnh ma trận phát xạ để kết nối tất cả các clone của trạng thái tiềm ẩn đó với quan sát bất ngờ. Cơ chế này được chính thức hóa trong Thuật toán 1. Quá trình tái liên kết cho phép mạch đảo ngược danh sách cụ thể trong Hình 2E trở thành một mẫu linh hoạt với các slot có thể được liên kết động với các đầu vào mới theo yêu cầu, tạo ra một cách mạnh mẽ để trộn và gating kiến thức trước với nội dung mới. Ví dụ, trong sơ đồ đảo ngược danh sách trong Hình 2F, các token "[" và "]" là nội dung trước đó phát hiện điểm bắt đầu và kết thúc của danh sách - chúng hoạt động như anchors để grounding sơ đồ trong các quan sát. Phân nhánh xác suất dựa trên token kết thúc danh sách "]" cho phép tổng quát hóa độ dài, trong khi hấp thụ các ký hiệu tùy ý vào các slot tương ứng với 𝐴,𝐵,𝐶,𝐷,𝐸 cho phép thuật toán tổng quát hóa sang các ký hiệu mới. Hình 2G minh họa kết quả của cơ chế tái liên kết này nơi các slot phát ra 𝐴,𝐵,𝐶,𝐷,𝐸 lần lượt được tái liên kết với các ký hiệu 𝐾,𝑀,𝑁,𝑃,𝑅 từ prompt đầu vào. Tương tự, trong câu "I wrote in a notebook using a dax", tái liên kết có thể hấp thụ token mới "dax" vào ngữ cảnh bằng cách liên kết nó với một clone tương ứng với "pencil" hoặc "pen", và sử dụng từ mới trong những ngữ cảnh đó.

### 3.3. Truy xuất và hoàn thành nhiệm vụ dựa trên hướng dẫn hoặc nội dung

Nhận dạng nhiệm vụ zero-shot như truy xuất dựa trên nội dung sử dụng tái liên kết: Nhiều ví dụ nổi bật về học zero-shot liên quan đến việc nhận dạng nhiệm vụ từ prompt, sau đó lặp lại nhiệm vụ đã nhận dạng trên các đầu vào mới. Ví dụ, cho một prompt "Input: [p, q, r, s] Output: [p, p, q, q, r, r, s, s]; Input: [l, m, n, o] Output: [l, l, m, m, n, n, o, o]" LLM có thể suy ra nhiệm vụ là lặp lại các phần tử của chuỗi, và áp dụng điều đó để hoàn thành đầu ra cho một prompt đầu vào mới ngay cả khi các token "p, q, r, s, l, m, n, o" không được thấy trong quá trình huấn luyện, liên kết với nhiệm vụ này. CSCG đưa ra một giải thích tự nhiên cho điều này bằng cách sử dụng tái liên kết. Cho prompt, expectation maximization (EM) [18] đồng thời đánh giá các tái liên kết khác nhau với nhiều sơ đồ thuật toán tiềm ẩn để suy ra liên kết tốt nhất, sau đó được áp dụng để hoàn thành query prompt.

Truy xuất dựa trên hướng dẫn: Khi các thuật toán được huấn luyện với các hướng dẫn ngôn ngữ có tiền tố, CSCG học các mạng con hướng dẫn trỏ trực tiếp đến các mạch đại diện cho các thuật toán (xem Mục 4.2). Thuật toán có thể được truy xuất bằng prompting trực tiếp với các hướng dẫn ngôn ngữ có thể khác đáng kể so với hướng dẫn huấn luyện do tổng quát hóa bắc cầu và tái liên kết.

### 3.4. Sự xuất hiện

Chúng tôi đưa ra giả thuyết và chứng minh thực nghiệm trong Mục 4 rằng sự xuất hiện có thể giải thích được như tác động kết hợp của các thuộc tính trên (tách biệt ngữ cảnh, tổng quát hóa bắc cầu, hình thành sơ đồ và tái liên kết), dung lượng mô hình và các pattern trong dữ liệu. Học các mạch sơ đồ cho thuật toán phức tạp hơn hoặc nhiều pattern hơn trong dữ liệu đòi hỏi dung lượng mô hình lớn hơn vì tham số hóa quá mức giúp trong quá trình tối ưu hóa. Huấn luyện trên tập dữ liệu lớn hơn dẫn đến việc tạo ra nhiều mẫu hơn có thể không xuất hiện trong tập dữ liệu nhỏ hơn.

## 4. Kết quả

Chúng tôi củng cố lập luận trên bằng kết quả thực nghiệm trên ba tập dữ liệu: (a) benchmark GINC được giới thiệu trong [3], (b) một bộ các nhiệm vụ học thuật toán mà chúng tôi giới thiệu trong các tập dữ liệu LIALT, và (c) một nhiệm vụ cảm ứng sử dụng từ zero-shot trên một mô hình ngôn ngữ CSCG.

### 4.1. Truy xuất nhạy cảm ngữ cảnh trên tập dữ liệu GINC phù hợp với giải thích suy luận Bayesian

Tập dữ liệu: Tập dữ liệu GINC, được giới thiệu trong [3] để nghiên cứu ICL, được tạo ra từ một hỗn hợp đồng nhất của năm factorial HMM [22]. Mỗi factorial HMM được gọi là một "concept". Một tài liệu được tạo ra bằng cách nối các mẫu câu độc lập từ một concept. Các prompt kiểm tra trong ngữ cảnh có số lượng ví dụ thay đổi từ 𝑛=0 đến 𝑛=64: mỗi ví dụ có thể có độ dài 𝑘∈{3,5,8,10}, với 2500 prompt cho mỗi thiết lập (𝑘,𝑛). Mỗi prompt chọn đồng nhất một concept, lấy mẫu 𝑛−1 ví dụ 𝑥(1):𝑘,...,𝑥(𝑛−1):𝑘 có độ dài 𝑘, và một ví dụ 𝑥(𝑛):𝑘−1 có độ dài 𝑘−1. Nhiệm vụ trong ngữ cảnh là suy ra token cuối cùng có khả năng cao nhất của ví dụ cuối cùng, tức là argmax𝑥(𝑛)𝑘−1𝑝(𝑥(𝑛)𝑘−1|𝑥(1):𝑘,...,𝑥(𝑛−1):𝑘,𝑥(𝑛):𝑘−1).

Vì từ vựng được chia sẻ giữa các concept tiềm ẩn khác nhau, các quan sát trong GINC có bí danh như trong ngôn ngữ tự nhiên, và giải quyết nhiệm vụ đòi hỏi mô hình phải loại bỏ tính mơ hồ của các quan sát có bí danh để suy ra chính xác các concept tiềm ẩn.

Huấn luyện: Chúng tôi huấn luyện một CSCG duy nhất với 50 clone trên tập dữ liệu GINC cho 100 lần lặp EM full-batch sử dụng pseudocount [6] của 𝜖=10^{-2}. Cho một prompt kiểm tra, CSCG suy ra chuỗi ẩn có khả năng cao nhất cho prompt đó, sau đó dự đoán quan sát có khả năng cao nhất tiếp theo.

Kết quả: CSCG học các mạng con tiềm ẩn khác nhau tương ứng với năm concept tiềm ẩn trong tập dữ liệu GINC (Hình 3A), và suy luận trên một prompt được cung cấp truy xuất mạng con tiềm ẩn chính xác (Hình 3C). Tăng độ dài prompt cải thiện việc định vị mạng con và các trạng thái cụ thể trong mạng con. Hình 3C hình dung phân bố trạng thái tiềm ẩn đã giải mã cho một prompt ví dụ trong thiết lập zero-shot (𝑛=0). Việc giải mã bắt đầu không chắc chắn, và cải thiện khi prompt dài hơn. Việc định vị này (trên đồ thị) dẫn đến truy xuất sơ đồ hiệu quả, và do đó hoàn thành prompt chính xác. Hình 3B[trái] báo cáo độ chính xác trong ngữ cảnh—được định nghĩa là tỷ lệ trung bình của các dự đoán chính xác—cho mỗi cặp (𝑘,𝑛) của tập kiểm tra GINC. Độ chính xác trong ngữ cảnh của CSCG phù hợp với các pattern thể hiện bởi LSTM và transformer trong [3], trong khi cải thiện nhẹ hiệu suất của chúng. Hình 3B cũng cho thấy rằng một CSCG với dung lượng lớn hơn, tức là với 50 clone mỗi token, tách biệt các concept tiềm ẩn tốt hơn và vượt trội đáng kể so với một CSCG chỉ có 10 clone mỗi token. Hình 9[trái] trong Phụ lục C hiển thị độ tin cậy trong ngữ cảnh của CSCG: đối với ngữ cảnh lớn hơn, CSCG tốt hơn trong việc loại bỏ tính mơ hồ aliasing và xác suất dự đoán trung bình cao hơn. Cuối cùng, Hình 9[phải] cho thấy rằng tương tự như transformer và LSTM trong [3], CSCG thất bại trong ICL khi prompt kiểm tra được lấy mẫu từ các concept chưa thấy trong quá trình huấn luyện.

Kết quả GINC phù hợp với lập luận truy xuất dựa trên ngữ cảnh trong Mục 3.1: ICL trong thiết lập này là việc truy xuất một concept tiềm ẩn được chia sẻ giữa prompt và mô hình. Bằng cách sử dụng tính nhất quán tầm xa của các concept trong các tài liệu huấn luyện, mô hình học cách tách các concept thành các biểu diễn tiềm ẩn khác nhau. Mặc dù có sự không khớp giữa phân bố train và prompt [3], CSCG thành công trong việc hoàn thành prompt vì biểu diễn cho phép trộn bắc cầu.

### 4.2. Học sơ đồ cho thuật toán seq2seq và tổng quát hóa bằng tái liên kết

Tập dữ liệu huấn luyện: Để kiểm tra khả năng của CSCG trong việc học các thuật toán tổng quát hóa sang các đầu vào mới không thấy trong quá trình huấn luyện, chúng tôi xây dựng tập dữ liệu Language Instructed Algorithm Learning Tasks (LIALT). Tập huấn luyện LIALT chứa các minh họa của 13 thuật toán list và matrix được hiển thị trong Hình 4A[trên-trái]. Một minh họa bao gồm một hướng dẫn ngôn ngữ nhiều từ—mỗi thuật toán có năm hướng dẫn khác nhau—theo sau bởi 10 ví dụ đầu vào-đầu ra của thuật toán đó. Xem Bảng 2 & 3 trong Phụ lục D.1 để biết danh sách đầy đủ các hướng dẫn được sử dụng. Đối với mỗi hướng dẫn, tập dữ liệu chứa 20 minh họa. Trong một minh họa, hướng dẫn ngôn ngữ và các ví dụ được phân cách bởi delimiter "/". Các minh họa được phân cách bởi delimiter "\n". Các giá trị list và matrix đầu vào được tạo ra bằng cách lấy mẫu đồng nhất từ từ vựng 676 token, được tạo ra bằng cách ghép ngẫu nhiên các chữ cái viết hoa. Các ví dụ list operations có độ dài thay đổi từ 3 đến 6, và matrix operations có kích thước 2×2 hoặc 3×3. Hình 4A [dưới-trái] cho thấy định dạng dữ liệu huấn luyện.

Tập dữ liệu kiểm tra: LIALT có hai tập dữ liệu kiểm tra, lần lượt chứa: (a) prompt truy xuất dựa trên hướng dẫn, và (b) prompt truy xuất dựa trên ví dụ. Một prompt kiểm tra truy xuất dựa trên hướng dẫn bao gồm một hướng dẫn ngôn ngữ tự nhiên theo sau bởi một đầu vào duy nhất. Một prompt kiểm tra truy xuất dựa trên ví dụ bao gồm một ví dụ đầu vào-đầu ra đầu tiên của một thuật toán, không có hướng dẫn tự nhiên nào, theo sau bởi một đầu vào thứ hai. Tất cả các list và matrix trong hai tập dữ liệu kiểm tra chứa các token mới không thấy trong quá trình huấn luyện. Đối với cả hai loại prompt, nhiệm vụ trong ngữ cảnh là dự đoán đầu ra của thuật toán khi áp dụng vào đầu vào (cuối cùng). Lưu ý rằng đối với prompt dựa trên ví dụ, CSCG phải suy ra thuật toán được sử dụng từ ví dụ đầu tiên. Mỗi tập kiểm tra chứa 100 prompt, được xây dựng bằng cách lấy mẫu đồng nhất các hướng dẫn, và các token list hoặc matrix. Hình 4A [phải] cho thấy định dạng của hai tập kiểm tra này.

Huấn luyện: Đối với mỗi token, một CSCG phân bổ số lượng clone tỷ lệ thuận với số lượng ngữ cảnh riêng biệt trong dữ liệu huấn luyện mà nó xuất hiện. Chúng tôi tham số hóa dung lượng CSCG thông qua hệ số tỷ lệ này - "tỷ lệ overallocation". Chúng tôi huấn luyện CSCG cho một chuỗi tăng dần của tỷ lệ overallocation trên dữ liệu huấn luyện với 500 lần lặp EM và pseudocount của 𝜖=10^{-6}. Sau khi chạy EM, chúng tôi chạy 10 lần lặp huấn luyện Viterbi [23].

Kết quả: CSCG với dung lượng mô hình đủ học thành công các thuật toán từ tập huấn luyện, và tái liên kết tổng quát hóa các thuật toán đó sang các token mới chỉ thấy trong thời gian kiểm tra. Hình 4B cho thấy mạch đã học được trích xuất cho thuật toán đảo ngược list. Hình 5[trái] trình bày độ chính xác trong ngữ cảnh của CSCG (sử dụng 𝜖=10^{-6} và 𝑝surprise=0.1) trên hai tập kiểm tra LIALT: CSCG hiệu suất tốt nhất (a) tái liên kết thành công các sơ đồ đã học với các token mới của prompt kiểm tra và (b) suy ra chính xác thuật toán từ một cặp đầu vào-đầu ra duy nhất cho prompt dựa trên ví dụ. Hình 5 cũng cho thấy rằng kích thước mô hình thúc đẩy hiệu suất ICL [trái] ngay cả khi phân tích hiệu suất theo nhiệm vụ [phải].

CSCG đã học (được khởi tạo với tỷ lệ overallocation là 3) được hình dung trong Hình 10 trong Phụ lục, sử dụng clone được xếp chồng. Hình 6[A] cho thấy đồ thị chuyển tiếp sử dụng thuật toán Kamada-Kawai [24]. Nó tiết lộ mười ba cluster kết nối lỏng lẻo tương ứng với mười ba thuật toán có mặt trong tập dữ liệu LIALT. Hình 6[B] minh họa quá trình tái liên kết, với các phân bố đã giải mã trên các trạng thái tiềm ẩn của mô hình CSCG đã học, cho hai prompt dựa trên ví dụ khác nhau. Ngay cả trước khi tái liên kết, việc xác định anchor và slot đã hạn chế việc giải mã vào các sơ đồ tương thích với cấu trúc prompt —trong trường hợp này dựa trên dấu ngoặc & delimiter. Tuy nhiên, cấu trúc không đủ để phân biệt hoàn toàn giữa các sơ đồ tương thích (list operations tương ứng với đảo ngược, dịch chuyển tròn về phía trước và dịch chuyển tròn về phía sau), và cả hai prompt được chọn đều dẫn đến cùng một phân bố trạng thái tiềm ẩn. Do đó, phân bố đã giải mã sau E-step đầu tiên định vị vào ba sơ đồ tương thích. Trong M-step theo sau, các slot trong cả ba sơ đồ sẽ được tái liên kết cho prompt này. Cuối lần lặp EM đầu tiên, các liên kết mới cho các slot trong sơ đồ chính xác sẽ rất chắc chắn do bằng chứng nhất quán, trong khi bằng chứng không nhất quán sẽ dẫn đến các liên kết không chắc chắn cho các slot khác. Trong E-step của lần lặp thứ hai, các mức độ chắc chắn tương ứng trong các liên kết sau đó giúp thúc đẩy sơ đồ thuật toán chính xác trở thành việc giải mã có khả năng cao nhất—và hoàn thành prompt một cách thích hợp. Lưu ý rằng một bước EM duy nhất đủ để đưa ra tái liên kết chính xác trong các ví dụ này. So sánh Hình 5 & 11, và các bảng trong Phụ lục Mục D.3 để biết cách hiệu suất hoàn thành trong ngữ cảnh sau bước EM đầu tiên trong quá trình tái liên kết rất tương tự với hiệu suất khi kết thúc hội tụ EM.

Kết quả LIALT củng cố các lập luận chúng tôi đưa ra trong Mục 3.2 và 3.3. Tương tự như GINC Mục 4.1, giải thích suy luận Bayesian suy ra ngữ cảnh tiềm ẩn dựa trên tính nhất quán dài hạn không giải thích được việc ánh xạ lại biểu diễn tiềm ẩn sang các token hoàn toàn mới như yêu cầu để tổng quát hóa các thuật toán trong LIALT. Không có tái liên kết, một prompt chứa ví dụ đầy đủ độ dài của một thuật toán không định vị sơ đồ thuật toán chính xác hoặc tạo ra việc hoàn thành chính xác dựa trên suy luận trên các trạng thái tiềm ẩn một mình (Hình 6[B], hàng đầu tiên), trái ngược với kết quả từ tập dữ liệu GINC. Sơ đồ thuật toán chính xác không thể được truy xuất vì prompt chứa các token mới không thấy trong quá trình huấn luyện thuật toán đó. Ngược lại, suy luận đồng thời tái liên kết và các trạng thái tiềm ẩn dẫn đến truy xuất chính xác sơ đồ thuật toán và hoàn thành prompt chính xác (Hình 6[B], hàng thứ hai và thứ ba). Sử dụng tái liên kết, CSCG có thể học các thuật toán seq2seq và tổng quát hóa các thuật toán đó sang các token mới không gặp phải trong huấn luyện.

Sự xuất hiện: Hiệu suất ICL của CSCG trên tập dữ liệu LIALT cho thấy các đặc tính được quy cho sự xuất hiện: độ chính xác của học trong ngữ cảnh có sự phụ thuộc rõ ràng vào mức độ overparameterization của CSCG, đưa ra bằng chứng hỗ trợ cho giả thuyết của chúng tôi trong mục 3.4.

### 4.3. Kiểm tra Dax

Trong ngôn ngữ, kiểm tra "dax" [25] được sử dụng để chứng minh khả năng của một mô hình hấp thụ việc sử dụng một từ hoàn toàn mới từ một lần trình bày duy nhất. Để kiểm tra khả năng này, chúng tôi huấn luyện một CSCG trên tập dữ liệu PreCo [26], là một tập dữ liệu tiếng Anh quy mô lớn cho phân giải coreference. Sau đó chúng tôi kiểm tra mô hình trên năm prompt truy vấn thay thế từ, nơi một số từ trong prompt không xuất hiện trong tập huấn luyện. Chúng tôi sử dụng Thuật toán 1 với 𝜖=10^{-6} và 𝑝surprise=1/16 để tái liên kết ma trận phát xạ trên mỗi prompt này, mỗi lần thăm dò mô hình để hoàn thành câu bằng cách điền vào chỗ trống (đầu vào không chắc chắn) sử dụng suy luận MAP. Hình 7 cho thấy các kết quả này.

Kết quả cho thấy mô hình có thể hấp thụ các từ mới như "terras" (thay cho "planets"), "cycles" (thay cho "bikes"), "AG" (thay cho "artificial"), và sử dụng chúng trong ngữ cảnh tương tự.

## 5. Công trình liên quan

Học trong ngữ cảnh (ICL): Tương tự như cách con người học bằng phép loại suy [27] và cách tính dẻo synaptic cho phép não thích nghi nhanh chóng với nhiệm vụ mới [28], ICL cho phép một mô hình được huấn luyện trước học một nhiệm vụ mới chỉ với một vài ví dụ. Kể từ khi [1] chứng minh khả năng ICL của GPT-3, một khối lượng lớn công trình đã cố gắng cải thiện khả năng này. [29, 30] đã chỉ ra cách các minh họa hướng dẫn rõ ràng quá trình lý luận cải thiện hiệu suất ICL của transformer trên các nhiệm vụ phức tạp mới.

Ở đây, chúng tôi đầu tiên làm rõ một số khái niệm không nên bị nhầm lẫn với ICL. Sau đó chúng tôi thảo luận một số công trình nhằm hiểu ICL và các yếu tố ảnh hưởng đến nó.

Học có giám sát (SL) và học few-shot (FSL): Các cách tiếp cận SL học một ánh xạ giảm thiểu loss trên dữ liệu huấn luyện: các phương pháp gradient là một paradigm phổ biến [31, 32, 33]. Trong chế độ FSL, một mô hình học thích nghi nhanh chóng với nhiệm vụ mới từ số lượng hạn chế các ví dụ có giám sát [34, 35, 36], và được yêu cầu thực hiện cùng nhiệm vụ này tại suy luận. Ngược lại, trong khi một số công trình [37, 38, 39, 40] tinh chỉnh mô hình được huấn luyện trước cho ICL, các nhiệm vụ ICL mới chỉ được tiết lộ trong quá trình suy luận. [38, 37] đã chỉ ra rằng tinh chỉnh transformer trên hướng dẫn cải thiện hiệu suất ICL của chúng.

Meta-learning: Paradigm meta-learning nhằm học để thích nghi với nhiệm vụ mới chỉ với một vài ví dụ [41, 42, 43] bằng cách sử dụng nhiều kinh nghiệm học tập. Ngược lại, ICL xuất hiện trực tiếp từ mô hình được huấn luyện trước. [39, 40] đã đề xuất một khung meta-learning cho ICL nơi mô hình được tinh chỉnh: nó học tận dụng các ví dụ few-shot và thích nghi với các nhiệm vụ mới tại thời điểm suy luận.

Cách ICL hoạt động: Một số nghiên cứu đã làm nổi bật vai trò của dữ liệu huấn luyện trong ICL. [44] đã chỉ ra rằng ICL xuất hiện khi dữ liệu huấn luyện có (a) các ví dụ xuất hiện theo cụm, và (b) số lượng lớn các lớp hiếm. [3] đã giải thích ICL như suy luận Bayesian ngầm và xây dựng tập dữ liệu GINC (xem Mục 4.1) để chứng minh ICL. Một số công trình cũng đã cố gắng hiểu cơ chế của ICL. [45] đã trừu tượng hóa ICL như một bài toán học thuật toán và phát hiện rằng transformer có thể suy ra ngầm một hàm giả thuyết. Tương tự, [46] đã chỉ ra rằng transformer có thể được huấn luyện để thực hiện ICL của các hàm tuyến tính chưa thấy, với hiệu suất tương đương với bộ ước lượng bình phương tối thiểu tối ưu. [47] đã chỉ ra rằng, trong trường hợp tuyến tính, transformer (a) triển khai ngầm gradient descent và (b) huấn luyện một mô hình tuyến tính ngầm trên các ví dụ ICL. [4] đã đề xuất một sự đối ngẫu giữa attention transformer và các phương pháp gradient và gợi ý rằng các mô hình được huấn luyện trước là meta-optimizer. Họ đã trình bày ICL như tinh chỉnh ngầm, nơi forward pass trên các ví dụ minh họa tạo ra meta-gradient. Cuối cùng, [5] đã chỉ ra sự tồn tại của "induction heads" trong transformer, xuất hiện trong quá trình huấn luyện, sao chép các pattern trước đó và thúc đẩy khả năng ICL.

Những gì ảnh hưởng đến ICL: [48] đã đề xuất một thay thế cho mã hóa vị trí, và chứng minh cách transformer có thể học sơ đồ cho các nhiệm vụ thuật toán và tổng quát hóa sang các chuỗi kiểm tra dài hơn bất kỳ chuỗi nào thấy trong quá trình huấn luyện. [49] đã làm nổi bật rằng (a) ICL có thể xuất hiện khi một mô hình được huấn luyện trên sự kết hợp của nhiều corpus (b) perplexity thấp và hiệu suất ICL không luôn tương quan. [1, 3] đã phát hiện rằng hiệu suất ICL của transformer cải thiện với (a) kích thước mô hình và (b) số lượng ví dụ minh họa. Tương tự, [50] đã chỉ ra rằng ICL "xuất hiện" khi kích thước mô hình tăng.

Một số công trình đã nghiên cứu ảnh hưởng của các mẫu minh họa trong ICL. [51, 52] đã phát hiện rằng ICL rất không ổn định và bị ảnh hưởng bởi mẫu prompting, việc lựa chọn các ví dụ trong ngữ cảnh, và thứ tự của các ví dụ. [53] đã chỉ ra rằng hiệu suất ICL được thúc đẩy bởi việc tiếp xúc với (a) không gian nhãn, (b) phân bố đầu vào, và (c) định dạng tổng thể của chuỗi. Tương tự, [54] đã phát hiện rằng việc chọn các ví dụ ICL với embedding gần hơn với mẫu kiểm tra ICL cải thiện hiệu suất ICL, và [55] đã phát hiện rằng thêm giải thích trong ngữ cảnh cải thiện hiệu suất. Cuối cùng, [56] gần đây đã tuyên bố rằng sự xuất hiện rõ nét của ICL trong các mô hình lớn hơn có thể là một tạo tác của các metric, không phải là thuộc tính cơ bản của mô hình.

## 6. Thảo luận

Một số giải thích trước đây cho ICL, bao gồm suy luận Bayesian [3] và gradient descent ngầm [4], đã xử lý tất cả nội dung như nhau mà không tách ra những đóng góp của nội dung vis-à-vis vị trí. Như chúng tôi đã chỉ ra, tổng quát hóa nhiều thuật toán đòi hỏi các mẫu có thể gating nội dung dựa trên các pattern trong cả nội dung và vị trí. Chúng tôi lập luận rằng các lý thuyết có thể cần nhấn mạnh sự phân biệt này (xem Hình 8A) để hiểu đầy đủ các bias quy nạp đằng sau ICL.

Tái liên kết trong CSCG đòi hỏi các thay đổi trọng số được bản địa hóa cho ma trận phát xạ. Không giống như CSCG, transformer đệm các đầu vào và sử dụng attention cho mục đích gating. Nhờ mã hóa vị trí, transformer có thể gating cả theo vị trí và nội dung. Vì attention được triển khai như một phần của forward pass, quá trình slotting sống trong không gian kích hoạt (trái với việc yêu cầu thay đổi trọng số). Đây chỉ là một sự khác biệt bề ngoài: có thể unroll temporally quá trình tái liên kết trong CSCG, để cung cấp một thuật toán cho cùng đầu ra, nhưng với trọng số cố định.

Phỏng đoán của chúng tôi là các lớp của transformer triển khai nhiều mẫu hỗn hợp của vị trí và nội dung, được đánh giá tại các offset khác nhau của một prompt. Việc lắp ráp mẫu có thể khớp autoregressive prompt thắng cuộc trong cuộc cạnh tranh để gating nội dung.

Mặc dù chúng tôi đã minh họa ở đây khái niệm tái liên kết để gắn các ký hiệu mới vào các slot hiện có, tái liên kết cũng có thể được thực hiện "qua thời gian". Giống như trong các ví dụ của chúng tôi, các kết nối giữa các clone (𝑇) vẫn không thay đổi, nhưng kết nối giữa các clone và các ký hiệu (𝐸) được tái liên kết dựa trên prompt, có thể làm ngược lại, tái liên kết các kết nối giữa các clone (𝑇) trong khi giữ kết nối với các ký hiệu (𝐸) không thay đổi. Ví dụ, có thể có một sơ đồ trong 𝑇 nhận dạng một hướng dẫn, và một sơ đồ khác thực hiện nó, được kích hoạt bởi clone cuối cùng của bộ nhận dạng hướng dẫn. Nếu chúng ta muốn một hướng dẫn đã biết và tất cả các biến thể của nó thực hiện một nhiệm vụ khác, có thể đơn giản tái liên kết clone cuối cùng của bộ nhận dạng hướng dẫn với trigger của nhiệm vụ mới. Cả hai loại tái liên kết có thể được kết hợp. Transformer cũng cho thấy loại tổng quát hóa này, nhưng chúng tôi để lại chi tiết của cách tiếp cận này cho công việc tương lai.

## Lời cảm ơn

Chúng tôi cảm ơn Stephanie Chan, Andrew Lampinen, Anirudh Goyal, Dharshan Kumaran, Neel Nanda và Guangyao Zhou cho những thảo luận hữu ích và nhận xét về bản thảo.

# 2305.14825.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl/2305.14825.pdf
# Kích thước tệp: 697073 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Các Mô hình Ngôn ngữ Lớn là Những Người Lý luận Ngữ nghĩa Trong-ngữ cảnh 
chứ không phải Những Người Lý luận Ký hiệu
Xiaojuan Tang1,3∗, Zilong Zheng3∗, Jiaqi Li3,
Fanxu Meng1,3, Song-Chun Zhu1,2,3, Yitao Liang1,3†, Muhan Zhang1,3†
1Đại học Bắc Kinh,2Đại học Thanh Hoa
3Phòng thí nghiệm Trọng điểm Quốc gia về Trí tuệ Nhân tạo Tổng quát, BIGAI

Tóm tắt
Khả năng lý luận few-shot nổi lên của các Mô hình Ngôn ngữ Lớn (LLMs) đã khiến cộng đồng ngôn ngữ tự nhiên và học máy phấn khích trong những năm gần đây. Bất chấp nhiều ứng dụng thành công, cơ chế cơ bản của các khả năng trong-ngữ cảnh như vậy vẫn còn chưa rõ ràng. Trong nghiên cứu này, chúng tôi giả thuyết rằng ngữ nghĩa đã học được của các token ngôn ngữ thực hiện phần lớn công việc nặng nhọc trong quá trình lý luận. Khác với quá trình lý luận ký hiệu của con người, các biểu diễn ngữ nghĩa của LLMs có thể tạo ra các kết nối mạnh mẽ giữa các token, do đó tạo thành một chuỗi logic bề ngoài. Để kiểm tra giả thuyết của chúng tôi, chúng tôi tách ngữ nghĩa khỏi quá trình lý luận ngôn ngữ và đánh giá ba loại khả năng lý luận, tức là suy diễn, quy nạp và bắt cóc. Các phát hiện của chúng tôi tiết lộ rằng ngữ nghĩa đóng vai trò quan trọng trong lý luận trong-ngữ cảnh của LLMs—LLMs hoạt động tốt hơn đáng kể khi ngữ nghĩa phù hợp với thông thức nhưng gặp khó khăn trong việc giải quyết các nhiệm vụ lý luận ký hiệu hoặc phản-thông thức bằng cách tận dụng kiến thức mới trong-ngữ cảnh. Những quan sát đáng ngạc nhiên đặt câu hỏi liệu các LLMs hiện đại đã thành thạo các khả năng lý luận quy nạp, suy diễn và bắt cóc như trong trí tuệ con người hay chưa, và thúc đẩy nghiên cứu về việc khám phá điều kỳ diệu tồn tại trong các LLMs hộp đen. Nhìn chung, phân tích của chúng tôi cung cấp một góc nhìn mới về vai trò của ngữ nghĩa trong việc phát triển và đánh giá khả năng lý luận của các mô hình ngôn ngữ. Mã nguồn của chúng tôi có sẵn tại https://github.com/XiaojuanTang/ICSR .

1 Giới thiệu
Trong những năm gần đây, các Mô hình Ngôn ngữ Lớn (LLMs) đã đạt được hiệu suất ấn tượng trên nhiều nhiệm vụ ngôn ngữ tự nhiên khác nhau, bao gồm trả lời câu hỏi, tóm tắt văn bản, dịch máy, lý luận logic, v.v. Những thành công này phần lớn được gán cho khả năng nổi lên của LLMs trong việc sử dụng phương pháp học "zero-shot" hoặc "few-shot" mà không có bất kỳ cập nhật gradient nào—một mô tả nhiệm vụ hoặc một vài ví dụ được cung cấp để hướng dẫn quá trình lý luận của chúng [1–4]. Một ví dụ điển hình là phương pháp "chain-of-thought (CoT)", liên quan đến các minh chứng lý luận hoặc một prompt đơn giản như "Hãy suy nghĩ từng bước" để thực hiện các nhiệm vụ lý luận phức tạp [5, 6].

Bất chấp khả năng học trong-ngữ cảnh mạnh mẽ và đa năng của LLMs, các cơ chế cơ bản mà chúng hoạt động trong một ngữ cảnh nhất định vẫn còn chưa rõ ràng. Các nghiên cứu trước đây điều tra những khía cạnh nào của các ví dụ đã cho đóng góp vào hiệu suất nhiệm vụ cuối cùng, bao gồm nhãn chính xác và thứ tự ví dụ [7–9]. Một hướng nghiên cứu khác gần đây đã tập trung vào việc giải thích và tận dụng cơ chế học trong-ngữ cảnh (ICL) [10–13]. Tuy nhiên, vấn đề cơ bản mà chúng có chung là các prompt trong-ngữ cảnh mà chúng nhập vào dựa trên các truy vấn ngôn ngữ tự nhiên để điều tra khả năng lý luận của LLMs. Tuy nhiên, theo Lý thuyết Quá trình Kép [14,15], con người thường sử dụng lý luận ký hiệu với Hệ thống II để giải quyết các vấn đề lý luận logic phức tạp. Để lấp đầy khoảng trống nghiên cứu, chúng tôi nghiên cứu có hệ thống khả năng lý luận trong-ngữ cảnh của LLMs bằng cách tách ngữ nghĩa khỏi quá trình lý luận ngôn ngữ. Với các thí nghiệm rộng rãi, chúng tôi nhằm trả lời câu hỏi nghiên cứu sau: Liệu LLMs có phải là những người lý luận trong-ngữ cảnh tốt mà không có ngữ nghĩa?

Trong nghiên cứu này, chúng tôi giả thuyết rằng ngữ nghĩa đã học được của các token ngôn ngữ đóng vai trò quan trọng trong quá trình lý luận, tạo ra các kết nối mạnh mẽ giữa các token giúp tạo thành một chuỗi logic bề ngoài (đường tắt) thay vì thực sự thực hiện quá trình lý luận chính thức. Để kiểm tra giả thuyết của chúng tôi, cho trước kiến thức ký hiệu (sự thật và quy tắc), chúng tôi kiểm tra ba loại khả năng lý luận (tức là suy diễn, quy nạp, bắt cóc) trên một bộ dữ liệu tổng hợp mới được đề xuất: bộ dữ liệu Cây Ký hiệu, được tạo thành từ dữ liệu lý luận ký hiệu đa bước, thế giới đóng, không nhiễu được tạo ra với các quy tắc logic. Bên cạnh đó, chúng tôi cũng thí nghiệm với nhiệm vụ ProofWriter [16], chứa các câu hỏi mà câu trả lời yêu cầu lý luận đa bước. Các phát hiện của chúng tôi cho thấy ngữ nghĩa thực sự đóng vai trò quan trọng trong lý luận trong-ngữ cảnh của LLMs: Khi ngữ nghĩa phù hợp với thông thức, LLMs hoạt động khá tốt; khi ngữ nghĩa bị tách rời hoặc trong ngữ cảnh phản-thông thức, LLMs gặp khó khăn trong việc giải quyết các nhiệm vụ lý luận bằng cách tận dụng kiến thức mới trong-ngữ cảnh. Hơn nữa, chúng tôi cũng nghiên cứu khả năng ghi nhớ của LLMs để ghi nhớ thông tin ký hiệu và ngữ nghĩa mới, cho phép chúng tôi điều tra vai trò của ngữ nghĩa đối với khả năng cập nhật kiến thức của LLMs.

Theo hiểu biết tốt nhất của chúng tôi, đây là nghiên cứu đầu tiên về tác động của ngữ nghĩa đối với khả năng lý luận trong-ngữ cảnh của LLMs. Phân tích của chúng tôi nhấn mạnh tầm quan trọng của ngữ nghĩa trong khả năng lý luận của LLMs và đặt câu hỏi liệu các LLMs hiện đại đã thành thạo các khả năng lý luận chính thức như trong trí tuệ con người hay chưa. Chúng tôi hy vọng các phát hiện của mình có thể cung cấp một góc nhìn mới về vai trò của ngữ nghĩa trong các khả năng trong-ngữ cảnh của LLMs, và truyền cảm hứng cho nghiên cứu sâu hơn về việc khám phá điều kỳ diệu bên trong các LLMs hộp đen.

2 Các Nghiên cứu Liên quan
Lý luận trong LLMs Lý luận là một quá trình nhận thức cơ bản liên quan đến các suy luận logic và kết luận dựa trên thông tin đã cho. Việc phát triển các mô hình với khả năng lý luận mạnh mẽ đã thu hút sự chú ý ngày càng tăng và nhiều nghiên cứu đã được tiến hành về chủ đề này từ những ngày đầu trong lĩnh vực NLP [17]. Kể từ đó, nhiều bộ tiêu chuẩn khác nhau tập trung vào các khía cạnh khác nhau của lý luận đã được đề xuất, bao gồm suy luận ngôn ngữ tự nhiên (NLI) [18–20], lý luận thông thức [21,22], lý luận đa bước [23,24], v.v. Trong những năm gần đây, đã có sự quan tâm ngày càng tăng trong việc nghiên cứu khả năng lý luận của LLMs. Các nhà nghiên cứu đã khám phá nhiều phương pháp khác nhau để cho phép LLMs hoạt động tốt hơn trong các nhiệm vụ lý luận. Ví dụ, "chain-of-thought (CoT)" [5,25] được đề xuất để tạo điều kiện cho các mô hình tạo ra một đường dẫn lý luận phân tách lý luận phức tạp thành nhiều bước dễ dàng hơn; LLMs là những người lý luận zero-shot tốt bằng cách thêm một prompt đơn giản, "Hãy suy nghĩ từng bước", để tạo điều kiện cho tư duy từng bước trước khi đưa ra câu trả lời cuối cùng [6]. Điều này cải thiện đáng kể hiệu suất trên các bộ tiêu chuẩn số học [26], thông thức [21,27], và lý luận ký hiệu [5]. Tuy nhiên, bất chấp hiệu suất ấn tượng của chúng trên nhiều bộ tiêu chuẩn lý luận khác nhau, tất cả các nhiệm vụ được đánh giá đều phong phú về ngữ nghĩa. Do đó, không rõ khả năng lý luận của LLMs đến từ đâu. Điều này thúc đẩy chúng tôi điều tra khả năng lý luận của LLMs khi ngữ nghĩa bị tách rời.

Học Trong-ngữ cảnh Khả năng lý luận của LLMs có liên quan mật thiết đến học trong-ngữ cảnh (ICL). ICL đề cập đến khả năng của các mô hình ngôn ngữ thích ứng và học từ một vài ví dụ prompt trong quá trình suy luận. Trong những năm gần đây, đã có sự tập trung vào việc khám phá cách cải thiện hiệu suất của ICL. Cụ thể, một số nghiên cứu chọn các minh chứng liên quan đến thể hiện kiểm tra bằng cách sử dụng các metrics tương tự không giám sát có sẵn hoặc huấn luyện một bộ truy xuất prompt để chọn ví dụ [28–30]. Những nghiên cứu khác kết hợp hướng dẫn nhiệm vụ hoặc các prompt nhiệm vụ khác nhau [31,32]. Bất chấp thành công thực nghiệm, các cơ chế cơ bản của ICL vẫn còn chưa rõ ràng. Một số nghiên cứu đã chỉ ra rằng hiệu suất của ICL thường thay đổi tùy theo việc lựa chọn các minh chứng trong-ngữ cảnh [8,33]. Cụ thể, thứ tự của các minh chứng có thể dẫn đến các biến động hiệu suất lớn [34,9]. Các nghiên cứu gần đây cũng khám phá tác động của nhãn chính xác và đặt câu hỏi về sự cần thiết của ánh xạ đầu vào-đầu ra chính xác—việc sử dụng nhãn không chính xác trong các ví dụ chỉ làm giảm hiệu suất một cách nhỏ [35] và tương ứng đầu vào-nhãn đóng vai trò quan trọng hơn trong minh chứng ngữ cảnh [36]. Để hiểu rõ hơn tại sao học trong-ngữ cảnh hoạt động, một số nghiên cứu cung cấp phân tích lý thuyết rằng học trong-ngữ cảnh có thể được chính thức hóa như suy luận Bayesian [13] hoặc một số trường hợp của ICL có thể được hiểu như việc thực hiện ngầm các thuật toán học đã biết [37]. Tuy nhiên, các phân tích hiện có về ICL chủ yếu dựa trên đầu vào ngôn ngữ tự nhiên với thông tin ngữ nghĩa phong phú. Chúng tôi giả thuyết rằng điều này có thể không phản ánh được mức độ thực sự của khả năng lý luận bao gồm suy diễn, quy nạp và bắt cóc. Do đó, bài báo này nhằm tách ngữ nghĩa trong các khả năng lý luận trong-ngữ cảnh của LLMs.

Lý luận Ký hiệu Lý luận ký hiệu đã được nghiên cứu từ lâu trong lĩnh vực trí tuệ nhân tạo và khoa học nhận thức [38–40]. Nó liên quan đến việc thao tác các ký hiệu và áp dụng các quy tắc logic để thực hiện suy diễn [41], quy nạp [39], và bắt cóc [42]. Boole [43] đã giới thiệu đại số Boolean, đặt nền tảng cho logic ký hiệu và cung cấp một hệ thống chính thức cho lý luận logic. McCarthy [44] đã giới thiệu ngôn ngữ lập trình LISP và khái niệm về tính toán ký hiệu, thúc đẩy sự phát triển của các chương trình AI tinh vi có thể biểu diễn và thao tác các ý tưởng và mối quan hệ phức tạp. Fuhr [45] đã giới thiệu Datalog xác suất, một phần mở rộng của Datalog với xác suất, cho phép lý luận xác suất trong các hệ thống dựa trên logic. Eiter et al. [46] đã giới thiệu lập trình tập hợp câu trả lời (ASP), một mô hình lập trình dựa trên logic kết hợp lập trình logic và lý luận không đơn điệu. ASP đã được sử dụng cho nhiều nhiệm vụ lý luận khác nhau, bao gồm lập kế hoạch, biểu diễn kiến thức, và giải quyết ràng buộc. Yi et al. [47] đã đề xuất một phương pháp thần kinh-ký hiệu cho việc trả lời câu hỏi thị giác. Nó kết hợp mạng nơ-ron sâu với các quy tắc ký hiệu để thực hiện lý luận tổng hợp và có thể giải thích được trên thông tin thị giác và văn bản. Shin et al. [48] khám phá việc sử dụng các mô hình dựa trên LLM để tổng hợp chương trình. Họ trình bày một phương pháp tận dụng các dấu vết thực thi được suy luận để hướng dẫn việc tạo ra các chương trình chính xác. Lample và Charton [49] tập trung vào việc áp dụng các mô hình dựa trên LLM cho lý luận toán học, đề xuất một khung kết hợp học sâu với toán học ký hiệu để thực hiện lý luận đại số, giải phương trình, và chứng minh định lý. Pallagani et al. [50] sử dụng LLMs cho lập kế hoạch tự động—một nhánh của AI liên quan đến việc thực hiện các chuỗi hành động (kế hoạch) để đạt được các mục tiêu nhất định, thường được thực hiện bởi các tác nhân thông minh, robot tự động, và xe không người lái.

3 Tách Ngữ nghĩa khỏi Lý luận Trong-ngữ cảnh

3.1 Định nghĩa Nhiệm vụ
Để bắt đầu, chúng tôi trước tiên giới thiệu các định nghĩa về các cơ chế lý luận và ghi nhớ và cung cấp mô tả nhiệm vụ cho mỗi cơ chế. Các ví dụ về các nhiệm vụ được hiển thị trong Hình 1.

Lý luận Trong lĩnh vực tâm lý học, lý luận đề cập đến quá trình sử dụng các phép toán logic để rút ra kết luận hoặc đưa ra suy luận dựa trên thông tin có sẵn [51–54]. Như một khái niệm trừu tượng, nó bao gồm nhiều khía cạnh khác nhau. Theo truyền thống, chúng ta có thể phân loại nó thành ba loại:

•Lý luận suy diễn là một quá trình logic trong đó một kết luận có thể được rút ra từ các tiền đề hoặc nguyên tắc đã cho, có nghĩa là dự đoán các sự thật mới dựa trên các sự thật hiện có và quy tắc logic. Ví dụ, cho hai sự thật (Lisa, sisterOf, Alice) và (Alice, motherOf, Bob) cùng với một quy tắc logic ∀x, y, z :sisterOf (x, y)∧motherOf (y, z)→auntOf (x, z), sự thật mới (Lisa, auntOf, Bob) có thể được rút ra thông qua lý luận suy diễn. Nhiệm vụ là dự đoán Đúng/Sai của một sự thật được dự đoán cho trước các sự thật và quy tắc. Độ chính xác là tỷ lệ các dự đoán chính xác.

•Lý luận quy nạp liên quan đến việc đưa ra các khái quát dựa trên các quan sát hoặc bằng chứng cụ thể. Nói cách khác, một quy tắc logic có thể được quy nạp từ các sự thật đã cho. Ví dụ, cho một tập hợp các quan sát rằng người A là cha mẹ của người B và người B là con của người A, lý luận quy nạp là rút ra quy tắc logic ∀x, y :parentOf (x, y)→childOf (y, x). Chúng tôi thực hiện nhiệm vụ tạo ra quy tắc. Cho nhiều sự thật với các mẫu tương tự và một mẫu quy tắc, mục tiêu là quy nạp một quy tắc kéo theo những sự thật này. Chúng tôi kiểm tra các quy tắc được tạo ra so với các quy tắc chính xác. Nếu quy tắc được tạo ra khớp chính xác với quy tắc chính xác, chúng tôi coi quy tắc là đúng; ngược lại, chúng tôi coi quy tắc là sai. Độ chính xác là tỷ lệ các quy tắc đúng. Thêm chi tiết về mẫu quy tắc và các quy tắc chính xác được cung cấp trong Phụ lục F.

•Lý luận bắt cóc là một quá trình logic tìm kiếm một giả thuyết phù hợp nhất hoặc giải thích một tập hợp các quan sát. Ví dụ, cho nhiều sự thật bao gồm (Lisa, sisterOf, Alice) và (Alice, motherOf, Bob), cùng với một tập hợp các quy tắc logic bao gồm ∀x, y, z :sisterOf (x, y)∧motherOf (y, z)→auntOf (x, z), nếu chúng ta quan sát Lisa là dì của Bob, một giải thích có thể là Lisa là chị gái của Alice và Alice là mẹ của Bob. Chúng tôi sử dụng tạo ra giải thích để đánh giá khả năng lý luận bắt cóc. Cho một lý thuyết bao gồm các sự thật và quy tắc logic, nhiệm vụ là chọn các sự thật cụ thể và một quy tắc logic từ lý thuyết đã cho để giải thích quan sát. Quan sát được chọn từ các sự thật được suy luận. Chúng tôi sử dụng Độ chính xác Chứng minh (PA) như một metric đánh giá, tức là tỷ lệ các ví dụ mà chứng minh được tạo ra khớp chính xác với bất kỳ chứng minh vàng nào.

Ghi nhớ Trí nhớ đóng vai trò quan trọng trong lý luận, vì nó liên quan đến việc lưu trữ kiến thức trong-ngữ cảnh hoặc tham số cần thiết cho quá trình lý luận. Theo một nghĩa nào đó, trí nhớ có thể được coi là lý luận Độ sâu=0, trong đó câu hỏi là một sự thật đã biết. Nhiệm vụ lý luận liên quan đến việc truy xuất chính sự thật đó từ kiến thức được lưu trữ. Tuy nhiên, tác động cụ thể của ngữ nghĩa đối với ghi nhớ chưa được khám phá rộng rãi. Do đó, ngoài việc tách ngữ nghĩa khỏi lý luận, chúng tôi cũng cố gắng nghiên cứu tác động của ngữ nghĩa đối với ghi nhớ. Cụ thể, chúng tôi sử dụng một bộ dữ liệu mới để tinh chỉnh một mô hình ngôn ngữ và kiểm tra thời gian, hiệu quả và tỷ lệ quên của nó: thời gian là chi phí thời gian để thêm/cập nhật sự thật, hiệu quả là filter MRR (giá trị nghịch đảo trung bình của thứ hạng của thực thể chính xác [55]) của các sự thật được thêm/cập nhật, và tỷ lệ quên là filter MRR của các sự thật không nên được cập nhật. Khi đánh giá liệu một sự thật đã được thêm hoặc cập nhật thành công hay chưa, chúng tôi truy vấn LLM với một câu hỏi về thực thể đuôi và xếp hạng xác suất của đuôi thực so với tất cả các thực thể. LLM nhớ một bộ ba càng tốt, MRR càng cao.

3.2 Bộ dữ liệu Đánh giá
Mục tiêu của chúng tôi là tách ngữ nghĩa khỏi quá trình lý luận trong-ngữ cảnh và chỉ dựa vào kiến thức (mới) đã cho để thực hiện các nhiệm vụ lý luận. Để thực hiện điều này, chúng tôi sử dụng các bộ dữ liệu Cây Ký hiệu [56] và ProofWriter [16], chứa cả các sự thật liên quan và không liên quan và LLMs cần suy luận các sự thật chưa biết sau khi chọn các sự thật liên quan từ trí nhớ.

Bộ dữ liệu Cây Ký hiệu là một bộ dữ liệu ký hiệu thế giới đóng và không nhiễu được tạo ra một cách nhân tạo với các quy tắc logic phức tạp. Bộ dữ liệu bao gồm các "sự thật cơ bản" được lấy mẫu ngẫu nhiên, bao gồm thông tin giới tính và các mối quan hệ "parentOf" giữa các cá nhân. Với các quy tắc logic đã cho, bộ dữ liệu cho phép lý luận về 28 loại mối quan hệ gia đình khác nhau, từ các suy luận dễ dàng (ví dụ, tình cha) đến các suy luận phức tạp hơn (ví dụ, con gái của anh chị em họ của ai đó). Các sự thật bao gồm sự thật cơ bản (kiến thức trong-ngữ cảnh) và sự thật được suy luận (những gì cần lý luận). Lưu ý rằng Cây Ký hiệu là một bộ dữ liệu thế giới đóng, có nghĩa là bất kỳ sự thật nào không được trình bày trong bộ dữ liệu đều được giả định là sai. Do đó, chúng tôi xây dựng các sự thật sai bằng cách thay thế thực thể đầu hoặc thực thể đuôi bằng một thực thể ngẫu nhiên làm ví dụ tiêu cực trong các sự thật được suy luận. Xem xét giới hạn kích thước cửa sổ ngữ cảnh, chúng tôi hạn chế độ sâu của mỗi cây đến 5 để tạo ra bộ dữ liệu. Chúng tôi thí nghiệm với 10 Cây Ký hiệu được lấy mẫu; mỗi cây có 30 loại mối quan hệ (28 mối quan hệ được suy luận, giới tính và mối quan hệ parentOf), 26 thực thể, khoảng 35 sự thật cơ bản, 300 sự thật được suy luận và 300 sự thật sai.

Để tách ngữ nghĩa trong bộ dữ liệu, chúng tôi thay thế tên mối quan hệ (như "parent") bằng các ký hiệu được tạo thủ công (ví dụ, "r1", "r2", ...), để LLMs không thể tận dụng ngữ nghĩa của các vị từ trong lý luận mà phải dựa vào kiến thức mới đã cho (được trình bày như các sự thật và quy tắc trong-ngữ cảnh). Chúng tôi cũng thí nghiệm với việc thay thế tên thực thể (như "Alice") bằng "e1", "e2", ..., nhưng thấy rằng nó có ít tác động đến hiệu suất (thêm chi tiết được cung cấp trong Phụ lục Q). Trong quá trình tạo ký hiệu, chúng tôi cũng thử lấy mẫu ngẫu nhiên một số chữ cái làm tên mối quan hệ (ví dụ, "lnqgv" thay vì "r1"), nhưng chúng tôi quan sát thấy rằng LLMs gặp khó khăn trong việc hiểu các ký tự lộn xộn, điều này có thể ảnh hưởng tiêu cực đến hiệu suất (thảo luận thêm được cung cấp trong Phụ lục M).

ProofWriter [16] các nhiệm vụ cung cấp các sự thật và quy tắc nhân tạo được biểu đạt bằng ngôn ngữ tự nhiên. Cho các thí nghiệm của chúng tôi, chúng tôi sử dụng một tập con của bộ dữ liệu ProofWriter Open World Assumption (OWA) với độ sâu 1, 2, 3 và 5 (không có nhiệm vụ độ sâu 4), chứa nhiều cơ sở quy tắc nhỏ của các sự thật và quy tắc, được biểu đạt bằng tiếng Anh và không tồn tại trong cơ sở kiến thức của LLMs. Mỗi cơ sở quy tắc có một tập hợp các câu hỏi (các câu lệnh tiếng Anh) có thể được chứng minh là đúng, sai hoặc "Không biết". Lưu ý rằng nếu chúng ta muốn chứng minh điều gì đó Không biết, cần phải liệt kê tất cả các sự thật có thể và kiểm tra tính đúng/sai của chúng. Do đó, chúng tôi loại bỏ tất cả Không biết và thay thế chủ ngữ và tân ngữ bằng ID thực thể. Bộ dữ liệu này đơn giản hơn Cây Ký hiệu. Xem xét hầu hết các vị từ trong các câu là những động từ vô nghĩa như "is" và "can", chúng tôi chỉ thay thế các thực thể bằng ID thực thể để tách ngữ nghĩa. Lấy "Anne is kind." làm ví dụ. Chúng tôi thay thế chủ ngữ (Anne) và tân ngữ (kind) lần lượt bằng "e1" và "e2", có kết quả là "e1 is e2". Hình 2 cung cấp một ví dụ minh họa.

4 Thí nghiệm

Cho một tập hợp các quy tắc và sự thật, bạn phải lý luận xem một câu lệnh là đúng hay sai. Đây là một số sự thật và quy tắc: Con gấu thích con chó. Con bò tròn. Con bò thích con gấu. Con bò cần con gấu. Con chó cần con sóc. Con chó nhìn thấy con bò. Con sóc cần con chó. Nếu ai đó tròn thì họ thích con sóc. Nếu con gấu tròn và con gấu thích con sóc thì con sóc cần con gấu. Nếu con bò cần con chó thì con bò lạnh. Có nghĩa là câu lệnh "Con bò thích con sóc." là Đúng không? Cho một tập hợp các quy tắc và sự thật, bạn phải lý luận xem một câu lệnh là đúng hay sai. Đây là một số sự thật và quy tắc: e4 thích e5. e14 là e2. e14 thích e4. e14 cần e4. e5 cần e26. e5 nhìn thấy e14. e26 cần e5. Nếu ai đó là e2 thì họ thích e26. Nếu e4 là e2 và e4 thích e26 thì e26 cần e4. Nếu e14 cần e5 thì e14 là e1. Có nghĩa là câu lệnh "e14 thích e26." là Đúng không?

Hình 2: Tách ngữ nghĩa khỏi nhiệm vụ ProofWriter. Trong nhiệm vụ ProofWriter gốc, các thực thể được biểu diễn bằng tên của chúng (bên trái). Tuy nhiên, trong thiết lập tách rời của chúng tôi, chúng tôi thay thế tên thực thể bằng ID thực thể duy nhất (bên phải).

Các Mô hình Được Chọn để Đánh giá Chúng tôi chủ yếu đánh giá hiệu suất của ChatGPT, GPT-4 và LLaMA. ChatGPT và GPT-4 là các mô hình AI tiên tiến được phát triển bởi OpenAI và đã chứng minh khả năng lý luận mạnh mẽ trên nhiều nhiệm vụ và bộ tiêu chuẩn khác nhau. LLaMA là một mô hình ngôn ngữ lớn mã nguồn mở được phát triển bởi Meta AI, với số lượng tham số từ 7B đến 65B. Do hạn chế về tài nguyên tính toán, chúng tôi chỉ có thể tinh chỉnh phiên bản LLaMA-7B, được sử dụng trong bài kiểm tra ghi nhớ của chúng tôi. Làm tham chiếu, khi so sánh khả năng lý luận của LLMs, chúng tôi cũng sử dụng một số phương pháp ký hiệu dựa trên logic để tiến hành thí nghiệm làm đường cơ sở. Để so sánh ghi nhớ, chúng tôi sử dụng cơ sở dữ liệu đồ thị phổ biến Neo4j [57] làm đường cơ sở. Để đảm bảo so sánh tương đối công bằng, chúng tôi cấu hình Neo4j với cơ sở kiến thức được lưu trữ trước có kích thước không gian đĩa tương đương với LLaMA. Thêm giới thiệu về Neo4j được trình bày trong Phụ lục E.

Thiết lập Đánh giá Cho lý luận, chúng tôi sử dụng Cây Ký hiệu và ProofWriter Độ sâu-1 làm dữ liệu đánh giá. Chúng tôi gọi dữ liệu thô, nơi ngữ nghĩa được giữ lại, là Ngữ nghĩa. Khi ngữ nghĩa được tách rời bằng ký hiệu, chúng tôi gọi nó là Ký hiệu. Cho bộ dữ liệu Cây Ký hiệu, chúng tôi thí nghiệm với 10 cây được lấy mẫu và báo cáo kết quả trung bình, trong đó các sự thật và quy tắc có thể được biểu diễn như ngôn ngữ logic và văn bản ngôn ngữ tự nhiên làm đầu vào của LLMs. Ví dụ, sự thật "motherOf(Alice, Bob)" có thể được biểu diễn như "Alice is Bob's mother"; quy tắc "∀x, y :parentOf (x, y)→childOf (y, x)" có thể được biểu diễn như "If x is parent of y, then y is child of x.". Qua nhiều thử nghiệm, chúng tôi thấy rằng cho thiết lập Ký hiệu, LLMs có xu hướng hoạt động tốt hơn khi sử dụng biểu diễn ngôn ngữ logic. Ngược lại, cho thiết lập Ngữ nghĩa, LLMs có xu hướng hoạt động tốt hơn khi sử dụng văn bản ngôn ngữ tự nhiên. Chúng tôi chọn biểu diễn mang lại hiệu suất tốt hơn trong lý luận của LLMs. Kết quả bổ sung được trình bày trong Phụ lục L. Chúng tôi xem xét zero-shot, zero-shot CoT, few-shot CoT và zero-plus-few-shot-CoT làm đường cơ sở. Để tạo ra giải thích cho các thí nghiệm few-shot CoT, cho lý luận suy diễn, chúng tôi sử dụng zero-shot CoT (tức là Let's think step by step) để tạo ra giải thích cho các câu hỏi ngẫu nhiên; cho lý luận bắt cóc, chúng tôi chọn ngẫu nhiên năm ví dụ và thiết kế thủ công các minh chứng của chúng. Chúng tôi cung cấp tất cả prompts và minh chứng CoT trong Phụ lục A.

Cho ghi nhớ, chúng tôi chọn ngẫu nhiên 1,258 bộ ba từ bốn Cây Ký hiệu được lấy mẫu để tinh chỉnh LLaMA. Sau đó chúng tôi chọn các bộ ba trong hai cây đầu tiên và cập nhật các thực thể đuôi của chúng. Hai cây còn lại được sử dụng để đánh giá tỷ lệ quên. Lưu ý rằng khi cập nhật, chúng tôi chỉ đơn giản đảo các đuôi thành các sự thật sai ngẫu nhiên và không xem xét tính nhất quán của cơ sở kiến thức. Thêm minh họa về tính nhất quán trong Phụ lục H. Chúng tôi vẫn sử dụng Ký hiệu và Ngữ nghĩa để biểu thị các thiết lập thí nghiệm khác nhau. Cả hai thiết lập đều đảm bảo rằng thông tin mới được cung cấp không trùng lặp với cơ sở kiến thức cũ của LLMs, tránh bất kỳ vấn đề mơ hồ nào và loại bỏ ảnh hưởng của kiến thức có sẵn đối với nhiệm vụ ghi nhớ. Khi kiểm tra, chúng tôi tuân theo prompting của Taori et al. [58], sử dụng thực thể đầu và mối quan hệ làm hướng dẫn và cung cấp tất cả các đuôi ứng viên làm đầu vào. Các prompts chi tiết được chứa trong Phụ lục A.

Chi tiết Triển khai Cho ChatGPT và GPT-4, chúng tôi sử dụng API hoàn thành trò chuyện được cung cấp bởi OpenAI. Chúng tôi sử dụng nhiệt độ bằng không để tạo ra đầu ra. Ngoài ra, chúng tôi đặt phạt tần suất bằng không và top p bằng 1, đây là các giá trị mặc định cho các API này.

Cho LLaMA-7B, chúng tôi sử dụng 4 GPU A100 80G với kích thước batch 64 để tinh chỉnh. Quá trình huấn luyện bao gồm 100 epochs, sử dụng lịch trình học tập cosine với tỷ lệ học ban đầu là 2e-5. Chúng tôi chạy các thí nghiệm này ba lần và ghi lại MRR trung bình và độ lệch chuẩn của chúng. Vui lòng tham khảo Phụ lục G để biết thêm chi tiết.

Cho đường cơ sở ký hiệu dựa trên logic, trong thiết lập lý luận suy diễn, nó liệt kê các đường dẫn giữa đầu h và đuôi t và sử dụng các quy tắc được kích hoạt để suy luận câu trả lời; Cho lý luận quy nạp, chúng tôi áp dụng AMIE+ [59], trước tiên liệt kê các quy tắc có thể và sau đó học một trọng số vô hướng cho mỗi quy tắc để mã hóa chất lượng của nó. Cho lý luận bắt cóc, chúng tôi định vị quy tắc logic lý luận về mối quan hệ của sự thật và tìm tất cả các đường dẫn kết nối đầu và đuôi có thể kích hoạt quy tắc. Các sự thật đường dẫn này, cùng với quy tắc logic, phục vụ như các giải thích.

4.1 Ngữ nghĩa Quan trọng trong Ghi nhớ của LLMs
Chúng tôi đầu tiên kiểm tra khả năng ghi nhớ của LLMs khi kiến thức mới được trình bày dưới dạng ngữ nghĩa/ký hiệu. Kết quả được báo cáo trong Bảng 1.

Kết quả Từ Bảng 1, hiệu quả của việc thêm và cập nhật kiến thức ngữ nghĩa cao hơn so với kiến thức ký hiệu. Điều này cho thấy kiến thức ngữ nghĩa dễ dàng hơn cho LLMs ghi nhớ so với kiến thức ký hiệu, tương tự như khả năng ghi nhớ của con người (ghi nhớ ký hiệu thường khó khăn hơn việc ghi nhớ từ có nghĩa ngữ nghĩa). Tuy nhiên, chúng tôi cũng thấy rằng tỷ lệ quên của thiết lập ngữ nghĩa cao hơn thiết lập ký hiệu. Điều này có thể được quy cho thực tế là kiến thức ngữ nghĩa có tương quan mạnh hơn với nhau so với kiến thức ký hiệu trong LLMs, có nghĩa là việc cập nhật một số kiến thức có thể có ảnh hưởng đáng kể hơn đến kiến thức khác trong hệ thống.

Trong so sánh giữa LLMs và hệ thống dựa trên đồ thị Neo4j, chúng ta có thể thấy rằng cập nhật kiến thức bằng Neo4j đạt được độ chính xác 100% khi chèn các bộ ba mới hoặc chỉnh sửa các bộ ba hiện có, bất kể kiến thức là ký hiệu hay ngữ nghĩa. Như mong đợi, vì kiến thức được thêm hoặc cập nhật không trùng lặp với cơ sở kiến thức hiện có, không có ảnh hưởng thêm đến kiến thức hiện có trong cơ sở dữ liệu. Điều này nổi bật một ưu điểm của việc sử dụng cơ sở kiến thức không tham số. Ngoài ra, so với chi phí tính toán của việc tinh chỉnh LLMs, việc cập nhật kiến thức trong cơ sở dữ liệu đồ thị với các cơ chế lưu trữ được tối ưu hóa nhanh hơn đáng kể. Điều này truyền cảm hứng rằng việc kết hợp LLMs với cơ sở kiến thức không tham số có thể cung cấp một phương pháp thực tế và hiệu quả hơn cho các ứng dụng thế giới thực.

4.2 Ngữ nghĩa Đóng Vai trò Quan trọng trong Lý luận của LLMs
Trong phần này, chúng tôi đánh giá tác động của việc tách ngữ nghĩa khỏi lý luận trong-ngữ cảnh của LLMs. Trong Bảng 2, chúng tôi trình bày kết quả của các nhiệm vụ lý luận suy diễn, quy nạp và bắt cóc trên các bộ dữ liệu Cây Ký hiệu.

Kết quả Từ Bảng 2, chúng tôi quan sát thấy rằng trong cả các kịch bản lý luận suy diễn và quy nạp, thiết lập Ngữ nghĩa vượt trội đáng kể so với thiết lập Ký hiệu. Đáng chú ý, trong các thí nghiệm quy nạp, Ngữ nghĩa đạt được độ chính xác tuyệt đối cao hơn khoảng 30% so với thiết lập Ký hiệu. Điều này cho thấy việc bảo tồn ngữ nghĩa phong phú trong quá trình lý luận dẫn đến hiệu suất tốt hơn cho LLMs.

Mặc dù trong kịch bản lý luận bắt cóc, thiết lập Ký hiệu đạt được kết quả tương đương với thiết lập Ngữ nghĩa, điều quan trọng cần lưu ý là kiến thức trong-ngữ cảnh dài hơn trong các nhiệm vụ lý luận bắt cóc có thể tăng khó khăn trong việc chọn thông tin liên quan và lý luận từ trí nhớ. Để điều tra thêm điều này, các thí nghiệm bổ sung trên bộ dữ liệu Cây Ký hiệu nhỏ hơn được tiến hành, và kết quả trong Phụ lục O xác nhận rằng thiết lập Ngữ nghĩa vẫn vượt trội so với thiết lập Ký hiệu. Điều này củng cố giả thuyết rằng việc bảo tồn ngữ nghĩa tăng cường khả năng lý luận của LLMs.

Bất chấp hiệu suất lý luận trong-ngữ cảnh được cải thiện của LLMs với ngữ nghĩa phong phú, khi so sánh với các phương pháp ký hiệu dựa trên logic, LLMs vẫn thể hiện hiệu suất kém hơn trong tất cả các nhiệm vụ lý luận. Điều này cho thấy rằng trong khi LLMs sở hữu cơ sở kiến thức rộng và khả năng hiểu ngôn ngữ mạnh mẽ, lý luận ký hiệu không phải là điểm mạnh chính của chúng so với các phương pháp được thiết kế đặc biệt cho lý luận ký hiệu. Điều này cũng gợi ý tiềm năng của các hệ thống AI thần kinh-ký hiệu trong tương lai.

4.3 Phân tích Chi tiết hơn về Ngữ nghĩa
Các thí nghiệm nói trên đưa ra bằng chứng ban đầu nổi bật tầm quan trọng của ngữ nghĩa trong lý luận của LLMs. Để điều tra thêm quan sát này, chúng tôi kiểm tra ảnh hưởng của kiến thức thông thức được lưu trữ trong LLMs đối với hiệu suất lý luận ngữ nghĩa của chúng. Cụ thể, chúng tôi khám phá ba khía cạnh: Đầu tiên, chúng tôi điều tra tác động của việc loại bỏ các quy tắc logic đã cho (trong suy diễn) và sự thật (trong quy nạp), nơi LLMs phải dựa hoàn toàn vào kiến thức thông thức trước đó được lưu trữ trong các tham số để suy luận câu trả lời. Phân tích này cho phép chúng tôi đánh giá mức độ mà LLMs có thể tận dụng kiến thức nội bộ của chúng để lý luận hiệu quả mà không có kiến thức trong-ngữ cảnh rõ ràng. Thứ hai, chúng tôi giữ lại ngữ nghĩa của các bộ dữ liệu nhưng giới thiệu các quy tắc logic phản-thông thức. Điều này yêu cầu LLMs tận dụng kiến thức mới trong-ngữ cảnh và điều hướng quá trình lý luận bằng cách tuân thủ nghiêm ngặt thông tin mới xung đột với kiến thức cũ. Chúng tôi thực hiện điều này bằng cách xáo trộn các mối quan hệ như nhãn mối quan hệ mới để xây dựng một bộ dữ liệu phản-thông thức mới. Ví dụ, chúng tôi thay thế "motherOf" bằng "sisterOf", "parentOf" bằng "brotherOf", và "female" bằng "male". Do đó, cho một quy tắc như ∀x, y :parentOf (x, y)∧female (x)→motherOf (x, y), chúng tôi có được ∀x, y :brotherOf (x, y)∧male (x)→sisterOf (x, y). Thứ ba, chúng tôi sử dụng một tập con của các bộ dữ liệu ProofWriter OWA cho độ sâu 0, 1, 2, 3 và 5, chứa các sự thật và quy tắc tổng hợp mặc dù được viết bằng ngôn ngữ tự nhiên nhưng không liên quan đến thông thức (xem Hình 2). Những điều tra này cho phép chúng tôi có được cái nhìn sâu sắc hơn về tác động của ngữ nghĩa đối với khả năng lý luận của LLMs.

Khi ngữ nghĩa phù hợp với thông thức Như được hiển thị trong Bảng 4, trong thí nghiệm lý luận suy diễn, Loại bỏ quy tắc/sự thật đạt được kết quả tương đương với Ngữ nghĩa; trong thí nghiệm lý luận quy nạp, Loại bỏ quy tắc/sự thật vượt trội so với Ký hiệu, đạt được 35.7% trong GPT-4. Những phát hiện này cho thấy LLMs có thể thực hiện lý luận suy diễn tương đương bằng cách tận dụng kiến thức thông thức được lưu trữ của chúng mà không sử dụng kiến thức ngữ nghĩa được cung cấp, và việc cung cấp kiến thức ký hiệu thay vì ngữ nghĩa trong quy nạp thậm chí có thể làm tổn hại hiệu suất. Bên cạnh đó, GPT-4 vượt trội đáng kể so với ChatGPT trong tất cả các thiết lập đánh giá, cho thấy kiến thức thông thức được lưu trữ trong GPT-4 rộng rãi hơn và cho phép khả năng lý luận mạnh hơn.

Khi ngữ nghĩa không phù hợp với thông thức Để điều tra tác động của ngữ nghĩa không phù hợp với thông thức, chúng tôi giới thiệu các kịch bản phản-thông thức (Counter-CS), cũng được hiển thị trong bảng 4. So với Ngữ nghĩa và Ký hiệu, chúng tôi thấy rằng Phản-Thông thức hoạt động kém hơn Ngữ nghĩa, thậm chí Ký hiệu. Những phát hiện này cho thấy khi kiến thức mới trong-ngữ cảnh xung đột với thông thức, LLMs gặp khó khăn trong việc lý luận và dự đoán chính xác.

Khi ngữ nghĩa không liên quan đến thông thức Chúng tôi sử dụng các nhiệm vụ ProofWriter để kiểm tra liệu ngữ nghĩa vô nghĩa có vẫn hữu ích hay không. Kết quả được hiển thị trong bảng 3. Thiết lập Ký hiệu hoạt động tương đương với thiết lập Ngữ nghĩa trong thiết lập zero-shot, cho thấy khi ngữ nghĩa không liên quan đến thông thức, chúng có ít tác động đến khả năng lý luận của LLMs. Nói cách khác, khi nhiệm vụ không yêu cầu hiểu ngữ nghĩa sâu hoặc dựa tối thiểu vào kiến thức thông thức, sự hiện diện hoặc vắng mặt của ngữ nghĩa không ảnh hưởng đáng kể đến hiệu suất của LLMs. Tuy nhiên, trong các thiết lập CoT, chúng tôi quan sát thấy rằng Ngữ nghĩa tệ hơn đáng kể so với Ký hiệu. Điều này có thể là do lý luận từng bước phóng đại tác động làm nhiễu do ngữ nghĩa kỳ lạ như "The squirrel needs the dog" mang lại. Ngoài ra, chúng tôi quan sát thấy rằng các thiết lập CoT thậm chí hoạt động kém hơn thiết lập zero-shot, với tần suất cao hơn của câu trả lời "Cannot be determined.". Hiện tượng tương tự cũng được quan sát trong bảng 2, cho thấy CoT có thể không phải lúc nào cũng hữu ích cho các nhiệm vụ lý luận với kiến thức mới trong-ngữ cảnh.

4.4 Thêm phân tích và thảo luận
(1) Suy diễn vượt trội so với các loại lý luận khác: Trong cả thiết lập Ký hiệu và Ngữ nghĩa, LLMs thể hiện hiệu suất tốt hơn trong suy diễn so với quy nạp và bắt cóc. Quan sát này có thể được quy cho kiến trúc transformer-decoder được sử dụng bởi dòng GPT, dự đoán token tiếp theo chỉ dựa trên các token trước đó. Kiến trúc này phù hợp tốt với quá trình lý luận suy diễn, nơi kết luận được rút ra từ các tiền đề hoặc nguyên tắc đã cho. Một cách trực quan, quy nạp/bắt cóc cũng khó hơn suy diễn đối với con người.

(2) Kiến thức trong-ngữ cảnh ngắn hơn tăng cường hiệu suất lý luận Để kiểm tra ảnh hưởng của độ dài ngữ cảnh đối với lý luận, chúng tôi tiến hành một thí nghiệm lý luận bắt cóc sử dụng một Cây Ký hiệu nhỏ hơn, chứa khoảng 12 thực thể và 100 sự thật. Kết quả, được cung cấp trong Phụ lục O, cho thấy lý luận bắt cóc với ngữ cảnh ngắn hơn dẫn đến hiệu suất tốt hơn so với ngữ cảnh dài hơn. Bên cạnh đó, chúng tôi cũng tiến hành các thí nghiệm suy diễn và quy nạp nơi LLMs được cung cấp trực tiếp các sự thật liên quan liên quan đến sự thật được dự đoán hoặc quy tắc được dự đoán. Kết quả được trình bày trong Phụ lục J. Phát hiện này cho thấy LLMs gặp khó khăn trong việc xử lý thông tin trong-ngữ cảnh quá dài, đặc biệt trong các nhiệm vụ lý luận. Độ dài của ngữ cảnh ảnh hưởng đến hiệu suất lý luận, vì ngữ cảnh ngắn hơn giúp dễ dàng chọn thông tin liên quan và hữu ích trong khi giảm thiểu tác động của nội dung không liên quan.

(3) Hiệu quả của thông thức được biểu đạt bằng ngôn ngữ tự nhiên: Chúng tôi khám phá việc biểu diễn kiến thức dưới dạng ngôn ngữ tự nhiên và ngôn ngữ logic trong các thí nghiệm của chúng tôi. Kết quả, được trình bày trong Phụ lục L, cho thấy rằng đối với các nhiệm vụ liên quan đến ngữ nghĩa, mô tả ngôn ngữ tự nhiên hiệu quả hơn biểu diễn ngôn ngữ logic. Ngược lại, đối với các nhiệm vụ ký hiệu và phản-thông thức, ngôn ngữ logic hoạt động tốt hơn. Quan sát này cho thấy biểu diễn ngôn ngữ tự nhiên kích thích tốt hơn khả năng hiểu ngữ nghĩa của LLMs, trong khi biểu diễn ngôn ngữ logic thuận lợi hơn cho lý luận ký hiệu.

(4) Khả năng zero-shot đang tiếp cận khả năng zero-shot-CoT: Trong thiết lập Ký hiệu, so sánh zero-shot với zero-shot-CoT trên các đánh giá suy diễn, quy nạp và bắt cóc, chúng tôi quan sát thấy rằng zero-shot-CoT chỉ cải thiện hiệu suất một cách nhỏ so với học zero-shot. Phát hiện này cho thấy khả năng zero-shot của các LLMs hiện tại đang tiếp cận khả năng học zero-shot-CoT của chúng. Một giải thích có thể là ChatGPT đã được huấn luyện trên các nhiệm vụ tương tự với CoT và đã ghi nhớ các hướng dẫn. Do đó, nó ngầm tuân theo các hướng dẫn này khi được áp dụng cho các truy vấn tương tự, ngay cả khi không có hướng dẫn CoT rõ ràng [60].

(5) Zero-shot như Hệ thống-I, Zero-shot-CoT như Hệ thống-II Cho thiết lập Ký hiệu, so sánh zero-shot với zero-shot-CoT trên suy diễn, quy nạp, bắt cóc, chúng tôi quan sát thấy rằng zero-shot-CoT cải thiện hiệu suất so với học zero-shot. Ngược lại, cho thiết lập Ngữ nghĩa, zero-shot-CoT hoạt động kém hơn zero-shot. Sự khác biệt này có thể được quy cho khả năng zero-shot ấn tượng của LLMs trong nhiều nhiệm vụ Hệ thống-I khác nhau, được Radford et al. [61] nổi bật. Các nhiệm vụ đòi hỏi sự hiểu biết sâu sắc về thông tin ngữ nghĩa phong phú dẫn LLMs dựa vào trực giác và sử dụng đường tắt để dự đoán câu trả lời. Mặt khác, đối với các nhiệm vụ lý luận ký hiệu, học zero-shot-CoT vượt trội so với học zero-shot, phù hợp với các phát hiện của Kojima et al. [6] người đã chứng minh vai trò tạo điều kiện của CoT trong việc kích hoạt khả năng Hệ thống-II.

(5) Sử dụng kiến thức nội bộ vượt trội so với kiến thức trong-ngữ cảnh bên ngoài: Để khám phá khả năng của LLMs trong việc sử dụng kiến thức nội bộ và bên ngoài, chúng tôi tiến hành một thí nghiệm bổ sung nơi chúng tôi cung cấp cho LLMs chỉ các sự thật liên quan liên quan đến sự thật được dự đoán. Chúng tôi so sánh hiệu suất của Loại bỏ quy tắc (tận dụng kiến thức nội bộ) với Ngữ nghĩa (cung cấp quy tắc logic bên ngoài). Đáng ngạc nhiên, chúng tôi thấy rằng Loại bỏ quy tắc hoạt động tốt hơn Ngữ nghĩa. Điều này cho thấy LLMs sở hữu kiến thức nội bộ cần thiết để hỗ trợ trả lời câu hỏi và các nhiệm vụ lý luận, và việc tận dụng kiến thức nội bộ này hiệu quả hơn cho lý luận so với việc dựa vào các quy tắc logic bên ngoài. Kết quả chi tiết và nghiên cứu trường hợp có thể được tìm thấy trong Phụ lục J.1.

4.5 Lý luận Thông thức
Lý luận thông thức đề cập đến khả năng đưa ra phán đoán và rút ra kết luận dựa trên việc hiểu kiến thức thế giới cơ bản và kinh nghiệm hàng ngày. Ví dụ, "nước ướt và có thể dập tắt lửa" là một ví dụ của thông thức. Bằng cách xem xét các tính chất của nước và khả năng dập tắt ngọn lửa của nó, chúng ta có thể suy luận rằng "đổ nước lên đám cháy nhà bếp" sẽ là một giải pháp hiệu quả. Phần này khám phá khả năng lý luận thông thức của LLMs. Mặc dù lý luận thông thức không thể tách ngữ nghĩa, chúng tôi bao gồm các so sánh để đánh giá toàn diện khả năng lý luận của LLMs.

Thiết lập Đánh giá Chúng tôi sử dụng CommonsenseQA và OpenBookQA [62] để kiểm tra lý luận thông thức. Chúng tôi sử dụng ChatGPT, GPT-4 và GreaseLM [63] làm đường cơ sở. Thêm thiết lập thí nghiệm trong Phụ lục P.

Kết quả Như được hiển thị trong Bảng 5, GreaseLM thể hiện hiệu suất đáng chú ý trong các nhiệm vụ lý luận thông thức, tương đương với hiệu suất con người 88% như được chỉ ra bởi một bảng xếp hạng công khai. Ngoài ra, chúng tôi tiến hành các thí nghiệm sử dụng các prompts few-shot khác nhau để điều tra thêm khả năng của nó. Kết quả cho thấy các prompts few-shot chỉ mang lại cải thiện nhỏ so với học zero-shot. Hiện tượng này có thể được quy cho Bộ lọc Ngôn ngữ Con người Mạnh mẽ (RHLF) của ChatGPT, trao quyền cho các mô hình hiểu rõ hơn về ý nghĩa và ngữ cảnh của các nhiệm vụ, cho phép chúng hoạt động tốt ngay cả trong các thiết lập zero-shot.

Tuy nhiên, khi chúng tôi kiểm tra kết quả few-shot (predict-explain hoặc explain-predict) của CSQA, liên quan đến giải thích CoT, hiệu suất không đạt yêu cầu. Điều này có lẽ là do các câu hỏi của CSQA dựa nhiều hơn vào trực giác (Hệ thống-I) nhưng ít hơn vào lý luận rõ ràng (Hệ thống-II). GPT-4 thể hiện cải thiện đáng kể trong khả năng lý luận của nó trên cả hai bộ dữ liệu. Nó đạt được độ chính xác thành công hơn 80% trên CSQA và tiếp cận 90% ấn tượng trên OpenBookQA. Những kết quả này chứng minh tiềm năng tối ưu hóa thêm của LLMs trong lý luận thông thức thông qua huấn luyện trên các kho ngữ liệu chất lượng cao hơn, sử dụng các mô hình lớn hơn, và sử dụng nhiều vòng lặp huấn luyện hơn.

5 Kết luận và Thảo luận
Bài báo của chúng tôi trình bày điều tra toàn diện đầu tiên về vai trò của ngữ nghĩa trong khả năng lý luận trong-ngữ cảnh của LLMs bằng cách tách ngữ nghĩa khỏi các prompts trong-ngữ cảnh. Kết quả thí nghiệm cho thấy: Khi ngữ nghĩa phù hợp với thông thức, LLMs hoạt động khá tốt; khi ngữ nghĩa bị tách rời hoặc phản-thông thức, LLMs gặp khó khăn trong việc giải quyết các nhiệm vụ lý luận bằng cách tận dụng kiến thức mới trong-ngữ cảnh. Những phát hiện này tiết lộ tầm quan trọng của ngữ nghĩa trong khả năng lý luận của LLMs và truyền cảm hứng cho nghiên cứu sâu hơn về việc khám phá điều kỳ diệu tồn tại trong các LLMs hộp đen. Dựa trên các phát hiện được xác định trong phân tích của chúng tôi, chúng tôi chỉ ra một số hướng tương lai tiềm năng cho việc phát triển các mô hình nền tảng lớn:

Bộ tiêu chuẩn lý luận ký hiệu phức tạp hơn: Để cải thiện khả năng lý luận ký hiệu trong-ngữ cảnh của LLMs, việc phát triển các bộ dữ liệu mới với ngữ nghĩa tách rời và các nhiệm vụ lý luận phức tạp hơn là cần thiết. Những bộ tiêu chuẩn này nên thách thức LLMs với kiến thức ký hiệu đa dạng và phức tạp.

Kết hợp với cơ sở kiến thức không tham số bên ngoài: Như kết quả thí nghiệm của chúng tôi cho thấy, khả năng ghi nhớ của LLMs không thể so sánh với các phương pháp dựa trên đồ thị hiện có. Điều này thúc đẩy việc tích hợp LLMs với các cơ sở kiến thức không tham số bên ngoài, như cơ sở dữ liệu đồ thị, để tăng cường việc chèn và cập nhật kiến thức của chúng. Phương pháp lai này có thể tận dụng điểm mạnh của khả năng hiểu ngôn ngữ của LLMs và kiến thức toàn diện, chính xác và cập nhật được lưu trữ trong các nguồn không tham số.

Cải thiện khả năng xử lý kiến thức trong-ngữ cảnh: Khả năng mạnh mẽ và mạnh mẽ hơn để xử lý và ghi nhớ kiến thức trong-ngữ cảnh là quan trọng để thực hiện các nhiệm vụ lý luận trong-ngữ cảnh phức tạp. Nghiên cứu thêm cần thiết để cải thiện khả năng của LLMs trong việc xử lý và tận dụng kiến thức trong-ngữ cảnh. Điều này bao gồm việc phát triển các cơ chế để mã hóa và truy xuất thông tin liên quan từ kiến thức trong-ngữ cảnh tốt hơn, để cho phép lý luận hiệu quả hơn.

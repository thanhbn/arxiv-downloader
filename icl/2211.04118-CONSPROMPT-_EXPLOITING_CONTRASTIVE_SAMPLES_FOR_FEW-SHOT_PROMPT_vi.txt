# 2211.04118.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl/2211.04118.pdf
# Kích thước tệp: 1156279 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
CONSPROMPT: KHAI THÁC CÁC MẪU TƯƠNG PHẢN CHO HỌC PROMPT VỚI ÍT MẪU

Jinta Weng†Yifan Deng†Donghao Li†Hao You†Yue Hu†⋆Heyan Huang††⋆
†Viện Kỹ thuật Thông tin, Viện Hàn lâm Khoa học Trung Quốc, Bắc Kinh, Trung Quốc
†Trường An ninh Mạng, Đại học Viện Hàn lâm Khoa học Trung Quốc, Bắc Kinh, Trung Quốc
††Viện Công nghệ Bắc Kinh, Trường Khoa học và Công nghệ Máy tính, Bắc Kinh, Trung Quốc
††Viện Công nghệ Thông tin Đông Nam, Phúc Điền, Trung Quốc

TÓM TẮT
Prompt đã trở thành một công cụ ngôn ngữ hiệu quả để sử dụng các mô hình ngôn ngữ được huấn luyện trước. Tuy nhiên, trong các tình huống ít mẫu, những thay đổi tinh tế trong thiết kế prompt luôn làm cho kết quả khác biệt rất lớn, và các phương pháp học prompt cũng dễ bị overfitting với các mẫu hạn chế. Để giảm thiểu điều này, chúng tôi khám phá việc sử dụng các mẫu tương phản phù hợp và các phương pháp học tương phản đa cấp độ để cải thiện tính bền vững của biểu diễn prompt. Do đó, ConsPrompt được đề xuất kết hợp với mạng mã hóa prompt, các mô-đun lấy mẫu tương phản và các mô-đun tính điểm tương phản, được giới thiệu để thực hiện học tương phản khác biệt. Kết quả của chúng tôi thể hiện hiệu suất tốt nhất trong các cài đặt ít mẫu khác nhau, và các thí nghiệm ablation cũng chứng minh hiệu quả của việc sử dụng học tương phản đa cấp độ trong quá trình tinh chỉnh dựa trên prompt.

Từ khóa chỉ mục —Học prompt, Mô hình ngôn ngữ được huấn luyện trước, học tương phản, học với ít mẫu

1. GIỚI THIỆU
Với sự phát triển theo cấp số nhân của các mô hình ngôn ngữ lớn (LLMs) và các chiến lược prompting, các mô hình ngôn ngữ được huấn luyện trước giờ đây có thể phục vụ như một cơ sở tri thức khổng lồ hoặc công cụ ngôn ngữ xuất sắc cho học với ít mẫu [1], như ChatGPT và LLAMA. Để kích hoạt tri thức hiện có được nhúng trong PLMs, các nghiên cứu chủ yếu tập trung vào các chiến lược prompting khác nhau và các phương pháp học prompt [2], và zhong et al. đã đưa ra mô hình OptiPrompt để thăm dò sự thật dựa trên nhúng soft-prompt [3]. Về mặt chiến lược huấn luyện, học prompt có thể phân loại thành tinh chỉnh prefix-prompt và tinh chỉnh bộ mã hóa prompt độc lập, như P-tuning[4], Prefix-tuning[5], Auto-prompt learning[6], và Prompt-tuning[7].

Tuy nhiên, những thay đổi tinh tế trong thiết kế prompt luôn làm cho kết quả khác biệt rất lớn, và quá trình học prompt cũng dễ bị overfitting với các mẫu hạn chế. Do đó, việc sử dụng các khả năng học nhận thức khác nhau và các chiến lược prompting để kích hoạt LLMs trong các cài đặt ít mẫu vẫn là một câu hỏi đáng cân nhắc [8, 4, 7]. Ngoài các chiến lược prompting, con người cũng có thể sử dụng các quy tắc học tập khác nhau để thực hiện kích hoạt tri thức dựa trên ít mẫu [9], như học tương phản của các prompt khác nhau và các mẫu khác nhau. Được thúc đẩy bởi điều này, chúng tôi khai thác cách sử dụng ít mẫu hơn và nhiều phương pháp học tương phản trong các mô hình tinh chỉnh dựa trên prompt.

Như được thể hiện trong Hình 1, nó tiết lộ cơ chế chú ý cấp độ token và câu của mô hình dựa trên transformer, cho thấy hiệu quả của LLMs có thể được tăng cường bởi cơ chế chú ý cấp độ token chính xác hơn và các phương pháp học tương phản. Do đó, chúng tôi sử dụng thông tin tương phản cấp độ prompt và cấp độ batch của các token để tăng cường nhiệm vụ học dựa trên prompt với ít mẫu, và hai chiến lược lấy mẫu âm và mô hình SBERT [10] cũng được sử dụng để hỗ trợ mô hình học prompt tương phản – ConsPrompt. Kết quả của chúng tôi cho thấy hiệu quả của việc học tương phản đa cấp trong việc sử dụng các công việc tinh chỉnh dựa trên prompt. Và tính bền vững của học dựa trên prompt có thể được tăng cường với các chiến lược lấy mẫu âm phù hợp. Đóng góp chính là:

• Chúng tôi đề xuất một mô hình prompt tương phản mới ConsPrompt để tăng khả năng phân biệt của prompt trên các mẫu cấp độ prompt và cấp độ batch.
• Hai chiến lược lấy mẫu và phương pháp học tương phản SimCLR được giới thiệu để giảm thiểu hiện tượng overfitting rộng rãi trong quá trình học prompt.
• Kết quả chứng minh hiệu suất tốt nhất và cho thấy tính bền vững k-shot trên năm nhiệm vụ ít mẫu đại diện.

2. MÔ HÌNH
Như được mô tả trong hình 2, ConsPrompt được cấu thành bởi Mạng Mã hóa dựa trên prompt, mô-đun lấy mẫu tương phản, và phương pháp học tương phản ConsPrompt. Trong mạng mã hóa prompt (§2.1), đầu vào sẽ được mã hóa thành đầu vào prompting, sau đó dự đoán các token ánh xạ bằng phương pháp tinh chỉnh dựa trên prompt. Thành phần cốt lõi của ConsPrompt là sử dụng hai mô-đun học prompt nhận thức tương phản, chứa các chiến lược học tương phản cấp độ prompt và cấp độ batch. Cả hai chiến lược học đều chứa một mô-đun lấy mẫu tương phản cụ thể (§2.2) và bộ mã hóa học (§2.3). Trong các mô-đun lấy mẫu tương phản, đầu vào prompting sẽ trích xuất các mẫu âm và dương bằng các phương pháp lấy mẫu dựa trên độ tương tự hoặc dựa trên nhãn, trong khi các mẫu này sau đó được sử dụng để xây dựng tập hỗ trợ cho học tương phản đa cấp (§2.3). Cuối cùng, chúng tôi sử dụng một hàm mất mát kết hợp để tinh chỉnh mạng mã hóa prompt và hai bộ mã hóa học tương phản.

2.1. Mạng Mã hóa Prompt
Chúng tôi lấy mô hình tinh chỉnh dựa trên prompt [11] làm cơ sở cho Mạng Mã hóa prompt của chúng tôi. Trong phương pháp này, một mẫu T bao gồm các token văn bản và token mặt nạ sẽ được định nghĩa trước. Do đó, đầu vào gốc xi sau đó sẽ được biến đổi thành xi. Ví dụ, nếu mẫu là thêm "It is [MASK]" sau đầu vào gốc, đầu vào prompting xi sẽ là:

xi=T(xi) =xi.It is [MASK] (1)

, trong đó giá trị ẩn của token [MASK] được sử dụng để tạo ra phân phối từ trên từ vựng PLMs sau đó.

Tiếp theo, một ánh xạ nhãn được định nghĩa để ánh xạ mỗi nhãn thành token cụ thể. Công thức chi tiết của ánh xạ nhãn được định nghĩa bởi:

F(y) :yt→vt, yt∈Y, vt∈V (2)

, trong đó vt là một trong các token trong từ vựng PLMs, và s là chỉ số nhãn. Và dự đoán cuối cùng sẽ được công thức hóa trong phương trình sau:

p(yt|xi) =p(vt|h[MASK ])⇒p(vt|W·h[MASK ])
⇒p(vt|hvt) = lnexp(hvt)
P|Y|
k=1exp(hvk)(3)

trong đó h là biểu diễn ẩn của lớp cuối cùng trong token cụ thể, W là một bộ chiếu từ vựng với kích thước |h×V|, v được sử dụng để biểu diễn mỗi token của ánh xạ nhãn.

Hàm mất mát tinh chỉnh của mạng mã hóa prompt là:

LCE=−1
NX
i|Y|X
t=1yilogp(yt|xi) (4)

trong đó i là chỉ số của cặp huấn luyện (xi, yi) và |Y| là tổng số nhãn.

2.2. Mô-đun Lấy mẫu Tương phản
Bản chất của học tương phản là học những khác biệt giữa các mẫu dương và âm hạn chế. Do đó, một chiến lược lấy mẫu phù hợp để chọn các mẫu dương và âm là cần thiết để phát triển học tương phản.

Trong biểu diễn câu của học tương phản, các prompt khác nhau (tương tự như tri thức ngữ cảnh) luôn gây ra biểu diễn câu khác nhau, và các đối tượng so sánh khác nhau cũng dẫn đến mất mát so sánh khác biệt. Do đó, chúng tôi sử dụng hai chiến lược lấy mẫu để xây dựng tập hỗ trợ Sq: mô-đun lấy mẫu cấp độ prompt và cấp độ batch. Trong lấy mẫu cấp độ prompt, chúng tôi sử dụng các mẫu prompt khác nhau để xây dựng các đầu vào truy vấn khác nhau để xây dựng tập hỗ trợ. Trong lấy mẫu cấp độ batch, chúng tôi sử dụng các mẫu khác nhau của batch hiện tại để xây dựng tập hỗ trợ.

Sau đó, chúng tôi tính toán độ tương tự cosine giữa biểu diễn của thể hiện hiện tại q và mỗi tập hỗ trợ Sq để chọn các mẫu dương và âm. Công thức chi tiết là:

MaxRank (sim(Msbert(q), Msbert(Sq))) (5)

trong đó n là số lượng tập hỗ trợ Sq được sử dụng để tạo ra các mẫu tương phản, và q là mẫu truy vấn. Tập hỗ trợ cuối cùng sẽ được sắp xếp theo độ tương tự tối đa.

Sau khi tạo ra thứ tự dựa trên độ tương tự trong Sq, biểu diễn của các mẫu dương và mẫu âm vẫn sử dụng cùng PLM của mạng mã hóa prompt.

sn
q=PLM (Sn
q) (6)

trong đó sn
q là biểu diễn PLM của Sn
q.

Hơn nữa, chúng tôi chỉ sử dụng một mẫu dương được chọn bởi độ tương tự cao nhất của tập hỗ trợ, trong khi các mẫu âm được chọn bởi độ tương tự thấp hơn trong các mẫu khác với các nhãn khác nhau.

--- TRANG 3 ---
Hình 2: Mô hình ConsPrompt tích hợp mạng mã hóa prompt và mô-đun lấy mẫu tương phản và mô-đun tính điểm

2.3. Mô-đun Tính điểm Tương phản
Các mô-đun tính điểm tương phản là thành phần cốt lõi được sử dụng để học biểu diễn phân biệt mẫu. Sau hoạt động lấy mẫu nêu trên, chúng tôi sử dụng cùng PLM của mạng mã hóa prompt để biểu diễn mỗi mẫu.

SBC,PC (i, j) =−logexp(si,j/τ)
PNneg
k1[k̸=i]exp(si,k/τ)(7)

trong đó k là chỉ số của tập mẫu âm, τ là tham số nhiệt độ có thể điều khiển, SBC và SPC là các tập hỗ trợ cấp độ batch và cấp độ prompt.

Chúng tôi sử dụng SimCLR [12] để tính toán hai mất mát so sánh, SBC và SPC của mô-đun lấy mẫu cấp độ prompt và cấp độ batch. Do sự khác biệt của tập hỗ trợ âm của các đối tượng so sánh, chúng tôi cũng chuyển đổi vị trí của chúng trong S(i, j) để tính toán một mất mát đảo ngược khác. Mất mát cuối cùng của các mô-đun học tương phản được định nghĩa như sau:

LBC=1
NP
N[SBC(i, j) +SBC(j, i)]
LPC=1
NP
N[SBC(i, j) +SPC(j, i)](8)

trong đó N là số lượng mẫu của các tập hỗ trợ cấp độ prompt hoặc cấp độ batch. Xem xét mất mát của khả năng tương phản và cơ chế prompt, mất mát cuối cùng được công thức hóa như sau:

L=LCE+t∗LBC+a∗LPC (9)

trong đó t và a là siêu tham số để xác định tỷ lệ mất mát học so sánh.

3. THÍ NGHIỆM
Trong phần này, chúng tôi giới thiệu các bộ dữ liệu sử dụng, thiết lập thí nghiệm, kết quả chính của các thí nghiệm và phân tích của chúng.

3.1. Thiết lập Thí nghiệm Ít mẫu
Chúng tôi sử dụng RoBERTa-large làm mô hình ngôn ngữ tiền huấn luyện. Thí nghiệm của chúng tôi được phát triển trên NVIDIA V100 32GB (cũng có thể chạy trên 1080ti với kích thước batch thấp). Trong quá trình huấn luyện, chúng tôi phát triển nhiều thí nghiệm trên các kích thước batch khác nhau bs=4,8,16, tỷ lệ học lr=1e-5,2e-5,5e-5.

Chúng tôi đánh giá mô hình ConsPrompt được đề xuất trên các nhiệm vụ glue ít mẫu, bao gồm nhiệm vụ hỏi đáp (bộ dữ liệu TREC), các nhiệm vụ phân loại cảm xúc (bộ dữ liệu sst-2 và sst-5), và các nhiệm vụ suy luận văn bản (bộ dữ liệu QNLI và SNLI). Để thỏa mãn cài đặt học ít mẫu, chúng tôi chọn năm bộ dữ liệu con K-shot khác nhau và mỗi bộ dữ liệu con được xây dựng bởi K=16 cặp huấn luyện trên mỗi loại nhãn [11]. Ngoài ra, chúng tôi sử dụng điểm trung bình và phương sai của kết quả dự đoán trên các tập con khác nhau thay vì kết quả cao nhất để kiểm soát tính công bằng.

Trong cài đặt học tương phản, chúng tôi chọn tất cả các thể hiện ngoại trừ thể hiện truy vấn q để kết hợp tập hỗ trợ ban đầu. Để giảm tính toán trong các mẫu hỗ trợ ban đầu, chúng tôi đặt tỷ lệ lọc của tập hỗ trợ là 0,5. Chúng tôi đặt τ= 0,07 để thực hiện làm mượt mất mát, và tỷ lệ t và a của học tương phản là 0,5. Nguồn của chúng tôi có sẵn tại https://github.com/Nagin-Kim/cosprompt.

3.2. Baselines
Chúng tôi so sánh với phương pháp Majority (chọn lớp đa số làm dự đoán), phương pháp tinh chỉnh [15], học zero-shot dựa trên prompt, GPT3-in-context-learning [16], các mô-đun học prompt (prefix-tuning, p-tuning), mô hình LMBFF [11]), và hai khung prompt tương phản, CP-tuning ([13], chỉ chứng minh trong các nhiệm vụ phân loại nhị phân) và [14] (phương pháp lấy mẫu dựa trên nhãn). Dựa trên các chiến lược lấy mẫu khác nhau, ConsPrompt của chúng tôi được chia thành hai ConsPrompt dựa trên nhãn và dựa trên sim. Trong ConsPrompt(-sim), các mẫu âm và dương được lấy mẫu trực tiếp dựa trên độ tương tự giữa các tập hỗ trợ và thể hiện truy vấn, trong khi ConsPrompt(-label) là chiến lược lấy mẫu dựa trên nhãn.

--- TRANG 4 ---
Baselines TREC (acc) SNIL (acc) QNLI (acc) SST-5 (acc) SST-2 (acc)
Majority 18.8 33.8 49.5 50.9 23.1
prompt-based zero-shot learning 32.0 49.5 50.8 35.0 83.6
GPT3-in-context-learning 26.2(2.4) 47.1(0.6) 53.8(0.4) 30.6(0.9) 84.8
fine-tuning 27.2(1.4) 48.4(4.8) 60.2(6.5) 43.9(2.0) 81.4(3.8)
Prefix-tuning 36.0(1.1) 33.5(3.9) 54.5(2.2) 46.1(1.3) 88.1(2.3)
P-tuning 40.2(1.3) 37.5(1.6) 57.6(3.9) 32.1(3.1) 90.1(1.2)
LMBFF 84.8(5.1) 77.1(3.9) 64.5(4.2) 46.1(1.3) 92.1(1.1)
CP-Tuning – – 69.22 – 93.35
Jian et al., 2022 83.3 (1.5) 69.9 (2.4) 66.4 (3.5) 49.5 (1.1) 90.6 (0.1)
ConsPrompt(-sim) 87.5 (2.2) 77.3 (3.6) 72.0 (3.0) 47.2 (3.1) 95.0(2.8)
ConsPrompt(-label) 86.8 (2.8) 76.2 (3.8) 71.9 (2.7) 47.5 (2.4) 93.1 (1.4)

Bảng 1: Kết quả chính của ConsPrompt. Chúng tôi chọn các baseline từ các mô-đun học prompt (prefix-tuning, p-tuning), mô hình LMBFF [11]), và hai khung prompt tương phản, CP-tuning ([13] và công trình của Jiang [14]).

t,a Trung bình Phương sai Trung vị
(acc.) (+std) (acc.)
0.1 75.5 2.7 76.0
0.5 75.7 2.4 76.0
1.0 75.5 3.2 76.1
20 77.3 3.6 78.9
Ensemble 77.0 2.9 77.7

Bảng 2: Thí nghiệm so sánh sử dụng các tỷ lệ khác nhau của mô-đun tính điểm so sánh. Chúng tôi chọn ConsPrompt(-sim) làm baseline và thay đổi t và a trên 0.1, 0.5, 1.0 và 20.

Nhiệm vụ Fine-tuning Sim-based của chúng tôi Label-based của chúng tôi
K-shot Acc Acc(+std) Mean. Acc (+std) Mean.
8 16.5 47.1 (1.6) 47.3 44.5 (2.1) 44.4
16 19.8 47.2 (3.1) 46.9 47.5 (2.4) 46.5
32 22.4 48.8 (1.6) 48.9 48.3 (1.3) 48.6
64 28.2 51.1 (1.0) 50.9 50.8 (0.9) 50.6
128 35.9 51.8 (2.0) 52.4 51.5 (1.1) 51.4
160 42.1 51.8 (1.3) 51.9 51.7 (0.8) 51.8

Bảng 3: Kết quả sử dụng các chiến lược lấy mẫu K khác nhau. K là số mẫu trên mỗi lớp trong bộ dữ liệu hiện tại.

3.3. Kết quả Chính
Kết quả chính của ConsPrompt được mô tả trong Tab. 1. So sánh với các baseline hiện có, mô hình ConsPrompt đạt được kết quả tốt nhất. Điều này tiết lộ rằng quá trình học prompt thực sự tăng khả năng phân biệt của mô hình trên các mẫu âm và dương. Hơn nữa, hiệu quả của ConsPrompt(-sim) tốt hơn ConsPrompt(-label) trong các nhiệm vụ TREC, SNLI và SST. Vì các mẫu lấy mẫu từ ConsPrompt(-sim) sử dụng quan điểm ưu tiên độ tương tự trong việc tạo ra tập âm từ SBERT, có vẻ như chúng ta cần tích hợp thêm thông tin về sự phân biệt ngữ nghĩa chi tiết cho học prompt ít mẫu, thay vì sự phân biệt nhãn thô. Ngoài ra, kết quả phương sai của ConsPrompt nói chung thấp hơn các baseline khác, cho thấy tính bền vững lớn hơn ở một mức độ nào đó.

3.4. Phân tích
Chúng tôi khám phá các nhiệt độ và cài đặt K-shot khác nhau để chứng minh sự cần thiết và hiệu quả của ConsPrompt.

3.4.1. Tỷ lệ Khác nhau của Mất mát Tương phản.
Để khám phá hiệu quả của mô-đun học tương phản, chúng tôi chọn nhiệm vụ SNLI và đặt tỷ lệ khác nhau của t và a để kiểm soát mất mát từ mô-đun tính điểm tương phản. Như kết quả được hiển thị trong Tab. 2, với sự gia tăng của giá trị t trong mô-đun học so sánh, ConsPrompt được đề xuất có thể nhận được nhiều lợi ích hơn từ mô-đun học tương phản, vì nó không tạo ra bất kỳ lợi ích lớn nào khi đặt các giá trị t thấp hơn, và giá trị t cao hơn có thể tăng cường mạng mã hóa prompt gốc. Ngoài ra, kết quả tích hợp của các cài đặt t khác nhau tiết lộ sự cần thiết của mô-đun học so sánh.

3.4.2. Tính Bền vững K-shot của ConsPrompt.
Chúng tôi cũng xem xét ảnh hưởng của các số lượng lấy mẫu khác nhau trong bộ dữ liệu ít mẫu. Chúng tôi đặt giá trị K thành 8,16,32,64,128,160 trên các nhiệm vụ SST-5. Như kết quả được hiển thị trong Tab. 3, cài đặt K-shot cao hơn có thể mang lại hiệu quả nhiều hơn về độ chính xác và tính bền vững. ConsPrompt (Dựa trên Sim) có hiệu quả trong các thí nghiệm cài đặt K cao hơn, trong khi ConsPrompt dựa trên nhãn có hiệu quả trong cài đặt 16-shot. Điều này tiết lộ rằng chiến lược lấy mẫu dựa trên độ tương tự hiệu quả hơn chiến lược dựa trên nhãn. Ngoài ra, với sự gia tăng của K, lợi ích từ kho dữ liệu huấn luyện đang giảm, điều này cho thấy ConsPrompt gợi ý nhiều hơn cho các thí nghiệm ít mẫu.

4. KẾT LUẬN
Kết hợp học prompt và học tương phản không giám sát, chúng tôi đề xuất một mô hình prompt hiệu quả ConsPrompt cho tình huống ít mẫu. ConsPrompt tích hợp mạng mã hóa prompting, mô-đun lấy mẫu Tương phản và mô-đun tính điểm tương phản, có thể thực hiện học đa cấp và giảm thiểu vấn đề overfitting trong thiết kế prompt. Hiệu quả của ConsPrompt trên các nhiệm vụ học ít mẫu (chỉ 16 mẫu mỗi lớp) cho thấy hiệu suất tốt nhất và tính bền vững cấp độ mẫu nhiều hơn. Công việc tương lai của chúng tôi sẽ tập trung vào cải thiện khả năng kiểm soát của việc lựa chọn mẫu so sánh.

--- TRANG 5 ---
5. LỜI CẢM ƠN
Công trình này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số tài trợ U21B2009) và Quỹ Khoa học của (Số tài trợ E110151101, E250471101).

6. TÀI LIỆU THAM KHẢO
[1] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al., "Language models are unsupervised multitask learners," OpenAI blog, vol. 1, no. 8, pp. 9, 2019.

[2] Andrea Madotto, Zhaojiang Lin, Genta Indra Winata, and Pascale Fung, "Few-shot bot: Prompt-based learning for dialogue systems," CoRR, vol. abs/2110.08118, 2021.

[3] Zexuan Zhong, Dan Friedman, and Danqi Chen, "Factual probing is [mask]: Learning vs. learning to recall," 2021.

[4] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang, "Gpt understands, too," arXiv preprint arXiv:2103.10385, 2021.

[5] Xiang Lisa Li and Percy Liang, "Prefix-tuning: Optimizing continuous prompts for generation," in Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Online, Aug. 2021, pp. 4582–4597, Association for Computational Linguistics.

[6] Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, and Sameer Singh, "Autoprompt: Eliciting knowledge from language models with automatically generated prompts," arXiv preprint arXiv:2010.15980, 2020.

[7] Timo Schick and Hinrich Schütze, "Exploiting cloze-questions for few-shot text classification and natural language inference," in Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Online, Apr. 2021, pp. 255–269, Association for Computational Linguistics.

[8] Adam Roberts, Colin Raffel, and Noam Shazeer, "How much knowledge can you pack into the parameters of a language model?," in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online, Nov. 2020, pp. 5418–5426, Association for Computational Linguistics.

[9] Yangyan Xu, Fangfang Yuan, Cong Cao, Majing Su, Yuhai Lu, and Yanbing Liu, "A contrastive self-distillation bert with kernel alignment-based inference," in International Conference on Computational Science. Springer, 2023, pp. 553–565.

[10] Nils Reimers and Iryna Gurevych, "Sentence-bert: Sentence embeddings using siamese bert-networks," in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019, pp. 3982–3992.

[11] Tianyu Gao, Adam Fisch, and Danqi Chen, "Making pre-trained language models better few-shot learners," arXiv preprint arXiv:2012.15723, 2020.

[12] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton, "A simple framework for contrastive learning of visual representations," in International conference on machine learning. PMLR, 2020, pp. 1597–1607.

[13] Ziyun Xu, Chengyu Wang, Minghui Qiu, Fuli Luo, Runxin Xu, Songfang Huang, and Jun Huang, "Making pre-trained language models end-to-end few-shot learners with contrastive prompt tuning," arXiv preprint arXiv:2204.00166, 2022.

[14] Yiren Jian, Chongyang Gao, and Soroush Vosoughi, "Contrastive learning for prompt-based few-shot language learners," in Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Seattle, United States, July 2022, pp. 5577–5587, Association for Computational Linguistics.

[15] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov, "Roberta: A robustly optimized bert pretraining approach," ArXiv, vol. abs/1907.11692, 2019.

[16] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei, "Language models are few-shot learners," ArXiv, vol. abs/2005.14165, 2020.

# 2302.05698.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl/2302.05698.pdf
# Kích thước file: 948982 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Ví dụ Kết hợp cho Học tập Trong ngữ cảnh
Jiacheng Ye1 2Zhiyong Wu2Jiangtao Feng2Tao Yu1Lingpeng Kong1
Tóm tắt
Các mô hình ngôn ngữ lớn được huấn luyện trước (LMs) đã
thể hiện khả năng Học tập Trong ngữ cảnh (ICL) ấn tượng,
nơi mô hình học cách thực hiện một nhiệm vụ chưa từng
thấy thông qua một prompt bao gồm các ví dụ đầu vào-đầu ra
làm minh họa, mà không cần bất kỳ cập nhật tham số nào.
Hiệu suất của ICL chủ yếu phụ thuộc vào chất lượng của
các ví dụ trong ngữ cảnh được chọn. Tuy nhiên, các phương
pháp lựa chọn trước đây chủ yếu dựa trên các phương pháp
heuristic đơn giản, dẫn đến hiệu suất dưới mức tối ưu. Trong
nghiên cứu này, chúng tôi công thức hóa việc lựa chọn ví dụ
trong ngữ cảnh như một bài toán lựa chọn tập con. Chúng tôi
đề xuất CEIL (Compositional Exemplars for In-context
Learning), được thể hiện bởi Determinantal Point Processes
(DPPs) để mô hình hóa sự tương tác giữa đầu vào được đưa ra
và các ví dụ trong ngữ cảnh, và được tối ưu hóa thông qua
một hàm mục tiêu học tập đối lập được thiết kế cẩn thận để
có được sự ưu tiên từ LMs. Chúng tôi xác thực CEIL trên
12 tập dữ liệu phân loại và sinh sản từ 7 nhiệm vụ NLP
khác nhau, bao gồm phân tích cảm xúc, phát hiện paraphrase,
suy luận ngôn ngữ tự nhiên, lý luận thông thường, trả lời
câu hỏi mở, sinh code, và phân tích cú pháp ngữ nghĩa. Các
thí nghiệm sâu rộng không chỉ chứng minh hiệu suất tiên tiến
mà còn tính chuyển đổi và tính kết hợp của CEIL, mở ra
những hiểu biết mới về học tập trong ngữ cảnh. Mã nguồn
của chúng tôi được phát hành tại
https://github.com/HKUNLP/icl-ceil.

1. Giới thiệu
Một mục tiêu quan trọng của trí tuệ nhân tạo là phát triển
các mô hình có thể khái quát hóa cho các nhiệm vụ chưa từng
thấy. Cộng đồng NLP đã đạt được một bước quan trọng
hướng tới mục tiêu này bằng cách khám phá ra khả năng
học tập trong ngữ cảnh (ICL) của các mô hình ngôn ngữ lớn
được huấn luyện trước (LMs; Brown et al. 2020). Với số
lượng hạn chế các ví dụ minh họa, học tập trong ngữ cảnh
bắt chước khả năng của con người trong việc tận dụng kiến
thức trước đó để đạt được hiệu suất khái quát hóa tốt nhất.

Tuy nhiên, khả năng như vậy đi kèm với vấn đề về tính
robustness: ICL đặc biệt nhạy cảm với việc lựa chọn các
ví dụ trong ngữ cảnh, và các sắp xếp khác nhau có thể dẫn
đến độ lệch hiệu suất từ gần như ngẫu nhiên đến gần như
tiên tiến (Rubin et al., 2022; Liu et al., 2022; Wu et al.,
2022). Đã có một số nỗ lực nghiên cứu trong hai năm qua
để lựa chọn các ví dụ trong ngữ cảnh tốt hơn. Đặc biệt,
một phương pháp nổi bật là so sánh đầu vào với từng
ví dụ riêng lẻ dựa trên các heuristic không học (Liu et al.,
2022) hoặc các metric dựa trên học (Rubin et al., 2022).
Mặc dù hiệu suất được cải thiện, những phương pháp này
không tính đến mối quan hệ tương tác giữa các ví dụ trong
ngữ cảnh. Ví dụ, việc bỏ qua tính dư thừa của các ví dụ
trong ngữ cảnh có thể dẫn đến các ví dụ gần như giống
hệt nhau, không cung cấp thêm sự giám sát nào. Việc tìm
kiếm một tập compact các ví dụ trong ngữ cảnh trở nên
cấp bách hơn nữa vì có giới hạn cứng cho độ dài prompt
do kiến trúc transformer backbone của LMs.

Trong bài báo này, chúng tôi đề xuất một phương pháp
tổng quát, được đặt tên là CEIL (Compositional Exemplars
for In-context Learning). Thay vì lựa chọn từng ví dụ trong
ngữ cảnh độc lập, CEIL mô hình hóa xác suất kết hợp của
toàn bộ tập ví dụ trong ngữ cảnh, và do đó nắm bắt mối
quan hệ tương tác giữa các ví dụ trong ngữ cảnh. Để mô
hình hóa xác suất kết hợp của một tập cho một đầu vào
cụ thể, chúng tôi đề xuất một mô hình mới dựa trên
conditional determinantal point process (DPP; Kulesza
et al. 2012) để học cách lựa chọn tập ví dụ trong ngữ cảnh
đa dạng nhưng hữu ích nhất (§3.1). Để tính đến chất lượng
của một tập con được chọn, một hàm điểm từ mô hình ngôn
ngữ được kết hợp vào conditional DPP để tạo thành
contrastive loss (§3.2). Bằng cách đó, thuật toán của chúng
tôi duy trì thời gian đa thức maximum a posteriori (MAP)
inference của DPP (Chen et al., 2018) để tập con ví dụ
trong ngữ cảnh tối ưu có thể được tìm thấy hiệu quả trong
giai đoạn inference (§3.3).

Chúng tôi xác thực phương pháp của mình bằng cách
tiến hành các thí nghiệm sâu rộng trên 12 tập dữ liệu phân
loại và sinh sản từ 7 nhiệm vụ khác nhau, bao gồm phân
tích cảm xúc, phát hiện paraphrase, suy luận ngôn ngữ tự
nhiên, lý luận thông thường, trả lời câu hỏi mở, sinh code,
và phân tích cú pháp ngữ nghĩa. Các thí nghiệm chứng minh
rằng: 1) CEIL vượt trội đáng kể so với cả hai phương pháp
lựa chọn truyền thống không học và dựa trên học, đạt được
hiệu suất học tập trong ngữ cảnh tiên tiến (§4.4); 2) CEIL
thể hiện tính chuyển đổi qua các LMs và tập dữ liệu, cho
phép ứng dụng hiệu quả không học (§4.6); 3) CEIL vốn
dĩ học cách kết hợp các ví dụ khác nhau, mở ra những hiểu
biết mới về học tập trong ngữ cảnh cho các nhiệm vụ kết
hợp (§4.5); 4) CEIL đặc biệt hiệu quả khi số lượng ví dụ
trong ngữ cảnh ở quy mô nhỏ (§4.7).

2. Kiến thức chuẩn bị
2.1. Học tập Trong ngữ cảnh
Học tập trong ngữ cảnh (ICL) đề cập đến một trong những
khả năng nổi bật cốt lõi (Wei et al., 2022) suy luận các
nhiệm vụ mới từ ngữ cảnh (Brown et al., 2020). Chúng tôi
sử dụng thuật ngữ 'in-weights learning' và 'in-context
learning' từ nghiên cứu trước đây về mô hình chuỗi (Brown
et al., 2020) để phân biệt giữa học tập dựa trên gradient
với cập nhật tham số và học tập không gradient từ ngữ
cảnh, tương ứng.

Chính thức, mỗi instance huấn luyện đầu tiên được tuyến
tính hóa thành văn bản đầu vào x = (x1...x|x|) và văn bản
đầu ra y = (y1...y|y|), trong đó tất cả các token x1...x|x|,
y1...y|y| ∈ V và V là tập từ vựng của LM. Cho một văn bản
đầu vào kiểm tra mới xtest, học tập trong ngữ cảnh định
nghĩa việc sinh ra đầu ra y như sau:

ytest ∼ PLM(ytest|x1,y1,...,xK,yK|{z} ngữ cảnh, xtest),

trong đó ∼ đề cập đến các chiến lược giải mã (ví dụ, giải
mã tham lam và nuclear sampling (Holtzman et al., 2019)),
và mỗi ví dụ trong ngữ cảnh ei = (xi,yi) được lấy mẫu từ
tập huấn luyện D = {(xi,yi)}N i=1. Quy trình sinh đặc biệt
hấp dẫn vì nó loại bỏ nhu cầu cập nhật tham số của mô hình
ngôn ngữ khi gặp một nhiệm vụ mới, điều này thường tốn
kém và không thực tế.

Đáng chú ý, hiệu suất của ICL trên các nhiệm vụ downstream
có thể thay đổi từ gần như ngẫu nhiên đến tương đương với
các hệ thống tiên tiến, tùy thuộc vào chất lượng của các ví
dụ trong ngữ cảnh được lấy ra (Rubin et al., 2022; Liu et al.,
2022; Wu et al., 2022). Thay vì lựa chọn ngẫu nhiên các ví
dụ trong ngữ cảnh cho mỗi đầu vào kiểm tra, nghiên cứu
trước đây mô hình hóa quy trình với một retriever P(ei|xtest),
có thể là có sẵn (Liu et al., 2022; Wu et al., 2022) hoặc
được fine-tuned (Rubin et al., 2022).

2.2. Determinantal Point Processes
Determinantal point processes (DPPs) là các mô hình xác
suất thanh lịch có khả năng thể hiện các tương tác tiêu cực
(Kulesza et al., 2012). Chính thức, một DPP P là một
measure xác suất cho các tập 2N item, trong đó mỗi tập
bao gồm các item được lấy mẫu không thay thế từ một
tập item rời rạc Z = {1,2,...,N}. Cho vector đặc trưng a
cho mỗi item, DPP tính toán ma trận kernel N×N positive
semi-definite (PSD) L, trong đó Lij = k(ai,aj) và k(·,·)
là hàm kernel. Khi đó xác suất trên một tập con các item
được đánh chỉ số bởi S ⊆ Z có thể được định nghĩa như:

P(S) = det(LS)/det(L+I), (1)

trong đó LS ≡ [Lij]i,j∈S biểu thị sự hạn chế của L đối
với các entry được đánh chỉ số bởi các phần tử của S,
det(·) biểu thị định thức của một ma trận, và I là ma trận
đơn vị. Chú ý theo kernel trick (Schölkopf et al., 2002),
k(ai,aj) có thể được viết như ϕ(ai)Tϕ(aj), trong đó ϕ(·)
là một reproducing kernel feature map. Do đó, định thức
có thể được diễn giải hình học như thể tích của khối
parallelepiped được hình thành bởi các vector {ϕ(ai)|i∈S}.
Khi độ lớn của vector đặc trưng của một item tăng, xác suất
của các tập chứa item đó cũng tăng. Trong khi đó, khi độ
tương tự giữa hai item tăng, xác suất của các tập chứa cả
hai item đó giảm.

Dưới phân phối P, mặc dù số lượng các hiện thực có thể
của S là mũ trong N, nhiều loại nhiệm vụ suy luận bao gồm
marginalization, conditioning, sampling và MAP inference
có thể được thực hiện trong thời gian đa thức (Kulesza et al.,
2012; Gillenwater et al., 2012; Han et al., 2017; Chen et al.,
2018, trong số các nghiên cứu khác).

3. Mô hình
Trong phần này, chúng tôi giới thiệu một framework hiệu
quả, CEIL, để học Composition of Exemplars for In-context
Learning, như thể hiện trong Hình 1. Thay vì lấy từng ví dụ
trong ngữ cảnh một cách độc lập, CEIL mô hình hóa toàn
bộ tập ví dụ trong ngữ cảnh bằng cách học xác suất kết hợp
P(S|xtest), và do đó nắm bắt mối quan hệ tương tác giữa
các ví dụ trong ngữ cảnh. Xác suất kết hợp được mô hình
hóa với một conditional DPP có thể học được (§3.1) và
được huấn luyện với contrastive learning (§3.2). Trong
giai đoạn inference, tập con ví dụ trong ngữ cảnh tốt nhất
được lựa chọn thông qua MAP inference hiệu quả (§3.3).

3.1. Mô hình hóa
Đối với học tập trong ngữ cảnh, cả tính liên quan (tức là
lựa chọn các ví dụ trong ngữ cảnh tương tự với đầu vào
kiểm tra) và tính đa dạng (tức là độ tương tự giữa các ví dụ)
đều quan trọng, trong khi DPPs vanilla bỏ qua thuật ngữ
liên quan. Để truyền cả tính liên quan và đa dạng vào quy
trình lựa chọn, chúng tôi định nghĩa một kernel mới

k̃(ai,aj|x) = g(ai,x)k(ai,aj)g(aj,x), (2)

--- TRANG 2 ---
được điều kiện hóa trên đầu vào kiểm tra x. DPP mới
tương ứng với một ma trận kernel điều kiện xem xét cả
tính đa dạng và liên quan: L̃ = Diag(r)·L·Diag(r), trong
đó ri = g(ai,x) là điểm liên quan cho item i. Dựa trên
Eq. (1) và Eq. (2), chúng ta có thể suy ra log-probability
không chuẩn hóa cho tập con S như:

log det(L̃S) = Σi∈S log(ri²) + log det(LS),

rõ ràng thể hiện cách mô hình DPP kết hợp tính liên quan
(tức là ri) và tính đa dạng (tức là det(LS)) của các ví dụ
trong ngữ cảnh.

Một cách trực quan, các nhiệm vụ khác nhau có thể ưu tiên
sự cân bằng khác nhau giữa tính đa dạng và liên quan, ví dụ,
một đầu vào phức tạp hơn có thể đòi hỏi một composition
phức tạp hơn của các ví dụ trong ngữ cảnh. Cùng lúc, mô
hình DPP ban đầu không cung cấp cơ chế như vậy. Để cân
bằng mức độ của tính đa dạng và liên quan cho các nhiệm
vụ khác nhau, chúng tôi tiếp tục kết hợp tham số cân bằng
λ như sau:

log det(L'S) = (1/λ)Σi∈S ri + log det(LS).

Điều này chính xác tương ứng với một DPP với kernel
L' = Diag(exp(r/2λ))·L·Diag(exp(r/2λ)).

Trong thực tế, mô hình retriever bao gồm hai embedder để
encode văn bản đầu vào và các ví dụ trong ngữ cảnh thành
các representation tương ứng x và a. Chúng tôi đặt cả hai
embedder là các mạng neural có khả năng học cao (ví dụ,
BERT (Devlin et al., 2019)) để điểm DPP kết quả (Eq. (1))
có thể là một metric xếp hạng hiệu quả cho việc lấy tập con.
Trên không gian embedding chiều cao, linear kernel (tức là
tích vô hướng) sau đó được áp dụng như hàm tương tự g và k.
Việc học các mạng embedder về cơ bản trở thành một bài
toán metric learning (Kulis et al., 2013), mà chúng tôi sẽ
giới thiệu trong phần tiếp theo.

3.2. Huấn luyện
Vì không có tập con ground-truth của các ví dụ trong ngữ
cảnh cho mỗi instance huấn luyện, chúng ta không thể áp
dụng phương pháp likelihood-maximization thông thường
để học các tham số. Trong phần này, chúng tôi giới thiệu
một framework contrastive learning, với ý tưởng chính là
chỉnh sửa embedding của mỗi ví dụ trong ngữ cảnh và
instance huấn luyện sao cho một tập con 'tốt hơn' có xác
suất cao hơn được lấy ra so với một tập con 'tệ hơn' cho
instance huấn luyện.

Dữ liệu Huấn luyện. Mục tiêu của chúng tôi trong việc xây
dựng dữ liệu huấn luyện là có được một tập dữ liệu
Dtrain = {(ei,{Sij,sij})M j=1}N i=1 gồm N instance. Mỗi
instance chứa một instance đầu vào ei từ tập huấn luyện D,
M tập con ví dụ trong ngữ cảnh trong đó mỗi ví dụ trong
tập con Sij cũng được lấy từ D¹, và điểm sij để chỉ ra chất
lượng của mỗi tập con.

Mô hình hóa trên không gian đầy đủ của S là mũ trong N
và do đó không thể thực hiện được. Để giải quyết vấn đề
này, chúng tôi sử dụng một framework hai giai đoạn thường
được sử dụng trong retrieval (Liu et al., 2009). Chúng tôi
đầu tiên tính toán trước một tập các ví dụ liên quan có kích
thước n (n << N) với một retriever. Sau đó, chúng tôi thực
hiện random sampling không thay thế để có được M tập con
riêng biệt, không có ví dụ lặp lại trong mỗi tập con để tránh
định thức bằng không khi tính det(S).

Khi chúng tôi lấy tập các tập con ví dụ trong ngữ cảnh
{Sij}M j=1 cho mỗi instance đầu vào ei = (xi,yi), chúng tôi
sử dụng chính LM inference làm hàm điểm. Để đo lường
chất lượng của mỗi tập con, điểm được định nghĩa là xác
suất dự đoán đáp án dưới LM, được biểu diễn chính thức như:

sij = PLM(yi|Sij,xi).

Điều này chỉ ra tập con này hữu ích như thế nào cho việc
giải mã đáp án mục tiêu.

Contrastive Loss. InfoNCE loss (Oord et al., 2018) đã được
thấy hiệu quả để học item đơn nào vượt trội hơn các item
khác trong các tình huống representation learning khác nhau
(Karpukhin et al., 2020; He et al., 2020; Rubin et al., 2022).
Tuy nhiên, nó có cách xử lý giống nhau cho tất cả các
negative sample và điểm dự đoán sij không được sử dụng
đầy đủ. Để giảm thiểu vấn đề này, chúng tôi đề xuất sử dụng
một fine-grained pair-wise margin loss để xác định tập con
nào được ưu tiên hơn, và loss cho mỗi instance huấn luyện
được định nghĩa như:

Li = Σ(S+,S-)∈Ci max(0, log P(S-) - log P(S+)/ci + ξ)

ci = max S∈Ci log P(S) - min S∈Ci log P(S),

trong đó Ci = {Sij}M j=1 chứa tất cả các tập con được lấy
mẫu cho instance i, ξ được đặt bằng γ*(rank(S-) - rank(S+))
theo (Zhong et al., 2020; An et al., 2022) để phản ánh sự
khác biệt chất lượng trong các cặp này, γ là một siêu tham
số điều khiển cường độ mà chúng tôi đặt γ = 1/|Ci| sao cho
ξ ∈ [0,1], và ci được sử dụng để căn chỉnh tỷ lệ với ξ. Chú
ý thuật ngữ chuẩn hóa det(L+I) trong Eq. (1) đòi hỏi tính
toán với độ phức tạp O(N³) trên các item đầy đủ với kích
thước N, trong khi việc sử dụng pair-wise ranking loss tự
nhiên loại bỏ tính toán thuật ngữ này (tức là log P(S-) -
log P(S+) = log det(LS-) - log det(LS+)), và do đó cắt giảm
chi phí tính toán.

3.3. Inference
Trong giai đoạn inference, thay vì tìm kiếm top-k ví dụ
trong ngữ cảnh liên quan nhất như trong các nghiên cứu
trước đây (Rubin et al., 2022; Liu et al., 2022), chúng tôi
thực hiện maximum a posteriori (MAP) inference với
module DPP đã học, xem xét cả tính đa dạng và liên quan.
MAP inference của một DPP được định nghĩa như:

Smap = arg max S⊆Z det(L'S),

đây là bài toán NP-hard (Ko et al., 1995). Tương tự như
trong việc xây dựng dữ liệu huấn luyện, chúng tôi thu hẹp
không gian ứng cử viên với KNN retriever từ N xuống n.
Sau đó chúng tôi làm theo Chen et al. (2018) để sử dụng
một implementation chính xác của thuật toán tham lam với
độ phức tạp O(nK²), trong đó K = |Smap| là số lượng ví dụ
trong ngữ cảnh. Trong mỗi iteration, ví dụ j được lựa chọn
một cách tham lam dựa trên incremental gain đối với log-
probability

j = arg max i∈Z\Smap log det(L'Smap∪{i}) - log det(L'Smap).

và được thêm vào Smap. Với Cholesky decomposition, độ
phức tạp có thể được giảm từ O(nK³) xuống O(nK) trong
mỗi iteration bằng cách cập nhật Cholesky factor một cách
tăng dần. Chú ý rằng so với vanilla KNN retrieval trực tiếp
lấy K ví dụ từ N, độ trễ inference bổ sung do MAP inference
gây ra là không đáng kể vì cả n và K ở đây đều là số tương
đối nhỏ (ví dụ, n = 100, K = 16).

4. Thí nghiệm
Chúng tôi tiến hành các thí nghiệm sâu rộng trên 12 tập dữ
liệu đa dạng, trải rộng 7 nhiệm vụ khác nhau, và chỉ ra một
cách tiếp cận tốt hơn cho học tập trong ngữ cảnh so với
những gì được xem xét trước đây.

4.1. Tập dữ liệu và Đánh giá
Tất cả các tập dữ liệu và nhiệm vụ được liệt kê trong Bảng 1.
Những tập dữ liệu này bao gồm các công thức hóa nhiệm vụ
khác nhau, do đó cho phép đánh giá sâu rộng CEIL trong
các tình huống thay đổi. Prompt và ví dụ của mỗi tập dữ
liệu được hiển thị trong Phụ lục A.1.

Chúng tôi so sánh các đáp án dự đoán với ground truth
và báo cáo Accuracy (Acc.) cho tất cả các nhiệm vụ phân
loại. Đối với các nhiệm vụ sinh sản, chúng tôi báo cáo
Exact Match (EM) cho WebQs, GeoQuery, NL2Bash,
MTOP, và SMCalFlow, LF-EM (Hasson & Berant, 2021)
cho Break theo (Rubin et al., 2022), đây là cải tiến của
EM để đo lường tương đương ngữ nghĩa. Kết quả cuối cùng
được báo cáo trên tập validation vì tập test là riêng tư đối
với một số tập dữ liệu.

4.2. Baseline
Mô hình CEIL của chúng tôi về cơ bản là một retriever
dựa trên học để lựa chọn ví dụ trong ngữ cảnh. Chúng tôi
xem xét cả retriever không học và các retriever dựa trên
học khác làm baseline:

• RANDOM: Retriever lựa chọn ngẫu nhiên các ví dụ
trong ngữ cảnh từ tập huấn luyện mà không lặp lại.

• TOPK-BM25: Phương pháp retrieval thưa thớt cổ điển
BM25 (Robertson & Zaragoza, 2009), là một phần mở
rộng của TF-IDF. Các ví dụ có điểm Top-K được chọn
làm ví dụ trong ngữ cảnh.

• TOPK-BERT: Dense retriever dựa trên BERT
embeddings (Devlin et al., 2019), chúng tôi sử dụng
bert-base-uncased² có sẵn công khai trong
Huggingface Transformers (Wolf et al., 2020).

• DPP-BERT: Retriever DPP sử dụng trực tiếp BERT
embedding ban đầu như trên mà không fine-tuning, và
sử dụng MAP inference cho việc lấy tập con (Chen et al.,
2018).

• TOPK-CONTRIEVER và TOPK-SIMCSE: Hai mô hình
sentence embedding tốt hơn được huấn luyện với
contrastive learning (Izacard et al., 2021; Gao et al.,
2021b).

• EPR: Dense retriever dựa trên học được huấn luyện để
lấy một singleton ví dụ trong ngữ cảnh tốt hơn (Rubin
et al., 2022), và các ví dụ tương tự Top-K nhất được
chọn trong giai đoạn inference. Chúng tôi mở rộng nó
cho các nhiệm vụ khác ngoài phân tích cú pháp ngữ
nghĩa trong Rubin et al. (2022).

4.3. Chi tiết Implementation
Chúng tôi chủ yếu sử dụng GPT-Neo (Black et al., 2021)
làm LLM, đây là một LM 2.7B-parameter được huấn luyện
trên The Pile (Gao et al., 2021a), một corpus văn bản 825 GB
được xây dựng từ một loạt các nguồn chất lượng cao. Chúng
tôi cũng xem xét GPT2-XL (Radford et al., 2019) (1.5B)
và Codex (Chen et al., 2021b) (175B) trong §4.6. Số lượng
ví dụ trong ngữ cảnh được đặt là 50, và chúng tôi cắt ngắn
nó dựa trên kích thước ngữ cảnh tối đa cho các LM khác
nhau (ví dụ, 1,024 cho GPT2-XL, 2,048 cho GPT-Neo, và
8,001³ cho Codex) trên mỗi nhiệm vụ. Số lượng ví dụ trong
ngữ cảnh trung bình kết quả cho mỗi nhiệm vụ được liệt kê
trong Bảng 1.

Chúng tôi sắp xếp exemplar dựa trên độ tương tự của chúng
với văn bản đầu vào theo thứ tự tăng dần, phù hợp với
thực tiễn thông thường (Rubin et al., 2022; Qiu et al., 2022b;
Levy et al., 2022). Trong quá trình sinh đáp án, tất cả các
nhiệm vụ phân loại được tái khung hóa thành multiple choice
theo (Brown et al., 2020). Chúng tôi cung cấp ngữ cảnh
cộng với một tùy chọn đáp án làm đầu vào cho LM, so sánh
likelihood LM của mỗi tùy chọn, và chọn tùy chọn có
likelihood tối đa làm đáp án. Trên các nhiệm vụ bao gồm
multi-label classification, mỗi nhãn được đặt tên có nghĩa
ngữ nghĩa làm tùy chọn (ví dụ "Positive" hoặc "Negative"
thay vì 0 hoặc 1 cho phân tích cảm xúc), và sau đó xử lý
nhiệm vụ như multiple choice. Đối với các nhiệm vụ sinh
sản, chúng tôi sử dụng greedy decoding để sinh đáp án.

Khi xây dựng dữ liệu để huấn luyện retriever, chúng tôi
giới hạn số lượng instance là 44,000 theo (Rubin et al., 2022)
để giảm chi phí điểm, và chúng tôi lấy mẫu 50 tập con ứng
cử viên với 16 ví dụ trong mỗi tập con cho mỗi instance
huấn luyện. Chúng tôi sử dụng Adam optimizer (Kingma &
Ba, 2015) với batch size 128 và learning rate 1e-5, và chạy
huấn luyện cho 30 epoch trên hai GPU NVIDIA A100. Cho
mỗi nhiệm vụ, chúng tôi tìm kiếm trade-off factor λ trong
{0.01, 0.05, 0.1}. Để encode mỗi ví dụ thành embedding,
chúng tôi nối tất cả các văn bản trong một instance ngoại
trừ nhãn (ví dụ, premise cộng hypothesis trong các nhiệm
vụ NLI) làm đầu vào cho encoder dựa trên BERT (tức là
BERT-base với 110M tham số có thể học). Chúng tôi khởi
tạo encoder với EPR, điều mà chúng tôi thấy giúp ích đáng
kể trong việc huấn luyện CEIL (§4.7).

4.4. Kết quả Chính
Chúng tôi thí nghiệm trên 12 tập dữ liệu trải rộng 7 nhiệm
vụ khác nhau và kết quả được thể hiện trong Bảng 2. Nhìn
chung, chúng tôi thấy các nhiệm vụ sinh sản hưởng lợi nhiều
hơn từ một tập ví dụ trong ngữ cảnh tốt hơn so với các
nhiệm vụ phân loại. Ví dụ, retriever TOPK-BM25 đơn giản
mang lại khoảng 12% đến 45% cải thiện hiệu suất tuyệt đối
so với retriever RANDOM. Lý do cơ bản có thể là các đáp
án liên quan hiếm khi xuất hiện trong các exemplar không
liên quan cho các nhiệm vụ sinh sản.

Chúng tôi thấy CEIL vượt trội đáng kể so với các baseline
không học và đặc biệt hiệu quả trên các nhiệm vụ Natural
Language Inference (NLI) (ví dụ, QNLI, MNLI), nơi có
được hơn 20% cải thiện tuyệt đối. Trên hầu hết các nhiệm
vụ phân loại và sinh sản khác, CEIL vượt trội hơn các
retriever không học khoảng 10%, với một ngoại lệ trên
các nhiệm vụ Commonsense Reasoning (tức là CMSQA và
HellaSwag). Thú vị là, tất cả các retriever khác (ví dụ,
TOPK-BM25, TOPK-BERT và EPR) thực hiện tương đương
với random retriever trên nhiệm vụ này, chỉ ra rằng kiến
thức thông thường liên quan có thể không tồn tại trong
dữ liệu huấn luyện.

So với retriever dựa trên học, CEIL nhất quán vượt trội
hơn EPR trên tất cả các nhiệm vụ, gợi ý hiệu quả của việc
đưa tương tác giữa các ví dụ trong ngữ cảnh vào quy trình
học. Chú ý CEIL không giới thiệu tham số bổ sung so với
EPR và TOPK-BERT không học, gợi ý CEIL không chỉ
hiệu quả mà còn có thể được áp dụng hiệu quả trong các
ứng dụng thực tế mà không có chi phí triển khai.

4.5. Tính Kết hợp
Một trực quan tự nhiên về hiệu suất vượt trội của CEIL
là nó học cách kết hợp exemplar sao cho toàn bộ tập con
giúp dự đoán đáp án. Để điều tra có hệ thống khả năng
kết hợp của retriever đã học, chúng tôi thí nghiệm trên
hai tập dữ liệu phân tích cú pháp ngữ nghĩa được thiết kế
tốt từ các tập dữ liệu SMCalFlow và GeoQuery ban đầu,
nơi các ví dụ kiểm tra đòi hỏi các exemplar kết hợp rõ ràng
(ví dụ, để dự đoán chương trình của "organize an event
with my manager", người ta phải lấy exemplar liên quan
đến "organize an event" và "my manager"). Chúng tôi đánh
giá các retriever được huấn luyện trong §4.4 trên các phân
chia dữ liệu khác nhau trong hai tập dữ liệu này (xem Phụ
lục A để biết chi tiết), và kết quả được thể hiện trong Bảng 3.

Các phân chia Template và Standard chiếm phần lớn sự
khác biệt hiệu suất giữa CEIL và EPR, với khoảng 2% và
5% trên tập dữ liệu GeoQuery. Trong khi đó, cải thiện trên
tất cả các phân chia cross-domain (k-C) của SMCalFlow-CS
vượt trội hơn phân chia single-domain (0-S) khi so sánh
CEIL với TOPK-BERT và EPR. Những điều này chỉ ra
CEIL thực sự, ở một mức độ nhất định, lấy các exemplar
kết hợp. Nhìn chung, CEIL cải thiện hiệu suất trên tất cả
các phân chia khó khăn trên hai tập dữ liệu này, chỉ ra việc
tổ chức tốt hơn các ví dụ trong ngữ cảnh giúp dự đoán
các chương trình mục tiêu kết hợp và dài hơn.

Các giải pháp trước đây để sinh các chương trình kết hợp
đòi hỏi augmentation dữ liệu kết hợp để huấn luyện LM
(Qiu et al., 2022a), hoặc dự đoán cấu trúc cục bộ test-time
để lựa chọn exemplar đa dạng (Levy et al., 2022). CEIL
có thể được xem như một cách tiếp cận thay thế trực tiếp
lấy một tập con exemplar đa dạng mà không cần tuning
inference LM, điều tốn kém, hoặc phân tách câu hỏi test-time,
điều này làm giảm hiệu quả và có thể gặp phải sự lan truyền
lỗi. Chú ý rằng mặc dù inference LM trong CEIL chưa
thấy bất kỳ dữ liệu kết hợp nào trong ngữ cảnh, retriever
đã thấy vì nó cần được huấn luyện trong tập dữ liệu
chuẩn. Một nghiên cứu thú vị trong tương lai sẽ là huấn
luyện một retriever trực tiếp khái quát hóa cho các nhiệm
vụ kết hợp chưa thấy mà không thấy bất kỳ dữ liệu kết hợp
nào, như chúng tôi đã thể hiện khả năng chuyển đổi qua
các tập dữ liệu trong §4.6.

4.6. Tính Chuyển đổi
Các đặc tính kết hợp của ngôn ngữ tự nhiên là tổng quát,
có nghĩa là retriever có thể khai thác kiến thức tương tự
trong các nhiệm vụ hoặc inference LM khác nhau. Điều
này thúc đẩy chúng tôi khám phá xem retriever được huấn
luyện trên một tập dữ liệu và LM inferencer có thể được
chuyển đổi trực tiếp sang các tập dữ liệu khác mà không
cần tuning thêm hay không. Đây là một câu hỏi nghiên cứu
thực tế vì huấn luyện một retriever cho mỗi tập dữ liệu
hoặc LM inferencer có thể tốn kém trong các ứng dụng
thực tế.

Chuyển đổi qua LMs Chúng tôi xem xét việc chuyển đổi
retriever được huấn luyện trên GPT-Neo sang một mô hình
có kích thước tương tự GPT2-XL (Radford et al., 2019)
(1.5B) và một mô hình lớn hơn nhiều Codex (Chen et al.,
2021b) (175B). Chú ý trong setting chuyển đổi, CEIL trở
thành một phương pháp không học dưới LM mục tiêu, do
đó chúng tôi cũng so sánh kết quả với TOPK-BERT. Chúng
tôi thể hiện cải thiện tuyệt đối so với TOPK-BERT trong
Hình 2 (Trái). Thú vị là, retriever được học trên GPT2-Neo
thực hiện tương đương với retriever trên GPT2-XL khi
đánh giá trên GPT2-XL cho các tập dữ liệu như SST5,
QNLI, và MTOP. Chúng tôi cũng thấy một cách đáng ngạc
nhiên rằng retriever được chuyển đổi vượt trội hơn retriever
được huấn luyện đặc biệt trên tập dữ liệu MRPC, chỉ ra
nó có thể mang lại kiến thức thêm (ví dụ, đặc tính kết hợp
của ngôn ngữ tự nhiên) ngoài việc học từ LM mục tiêu.
Chú ý khi xem xét một LM lớn (ví dụ, Codex) làm LM
inferencer, việc học một retriever cụ thể cho LM có thể tốn
kém do truy cập hạn chế. Mặc dù TOPK-BERT đã thực
hiện tốt trên Codex, CEIL vẫn mang lại cải thiện.

Chuyển đổi qua Tập dữ liệu Chúng tôi tiếp tục điều tra
xem một retriever được huấn luyện trên một tập dữ liệu
có chuyển đổi sang các tập dữ liệu khác hay không, như
thể hiện trong Hình 2 (Phải). Chúng tôi thấy gần như tất
cả các retriever chuyển đổi sang các nhiệm vụ NLI như
QNLI và MNLI, và đạt được hiệu suất tốt hơn TOPK-BERT.
Tuy nhiên, các retriever được huấn luyện NLI khó chuyển
đổi sang các nhiệm vụ khác ngoại trừ nhiệm vụ NLI (ví dụ,
retriever được huấn luyện QNLI chỉ có lợi cho MNLI).
Chúng tôi phỏng đoán rằng điều này là do thực tế các
nhiệm vụ NLI đòi hỏi hai đầu vào văn bản, nhưng các
nhiệm vụ khác chỉ đòi hỏi một đầu vào, và kiến thức thu
được từ các nhiệm vụ đầu vào đơn vẫn có giá trị trong
các nhiệm vụ đầu vào kép. Đối với các nhiệm vụ đầu vào
đơn khác, chúng tôi thấy chỉ retriever được học trên các
nhiệm vụ tương tự (ví dụ, Code Generation và Semantic
Parsing) thể hiện tính chuyển đổi. Phát triển một retriever
hoạt động cho tất cả các nhiệm vụ là một chủ đề nghiên
cứu thách thức nhưng có giá trị, mà chúng tôi để lại cho
nghiên cứu trong tương lai.

4.7. Phân tích
Về Tác động của Dữ liệu Huấn luyện Để điều tra tác động
của dữ liệu huấn luyện, chúng tôi so sánh các chiến lược
lấy mẫu ứng cử viên khác nhau và số lượng ứng cử viên.
Ngoài lấy mẫu ứng cử viên ngẫu nhiên, chúng tôi cũng
lấy mẫu ứng cử viên kích thước cố định dựa trên xác suất
được định nghĩa bởi k-DPP (Kulesza & Taskar, 2011).
Chúng tôi luôn bao gồm ứng cử viên Top-K, do đó chúng
tôi cũng báo cáo MRR = (1/N)∑(i=1 to N) 1/ranki để đo
lường chất lượng dữ liệu huấn luyện dựa trên xếp hạng
của ứng cử viên Top-K trong tất cả các ứng cử viên. MRR
thấp hơn có nghĩa là có nhiều ứng cử viên "tốt hơn" so với
Top-K. Như thể hiện trong Bảng 4, one-stage random
retrieval làm suy giảm đáng kể hiệu suất trên các tập dữ
liệu SST5 và MTOP. Đáng ngạc nhiên, MRR của one-stage
random retrieval đạt thấp nhất, chỉ ra tính liên quan không
phải là yếu tố duy nhất góp phần vào chất lượng của một
tập con. Two-stage random sampling vượt trội hơn một
chút so với k-DPP sampling với MRR tương tự. Hơn nữa,
chúng tôi thấy số lượng ứng cử viên chủ yếu ảnh hưởng
đến các nhiệm vụ sinh sản, được coi là phức tạp hơn phân
loại và việc tăng số lượng cải thiện hiệu suất cuối cùng.

Về Tác động của Chiến lược Học Chúng tôi so sánh các
khởi tạo khác nhau và contrastive loss trong Bảng 5. Học
tập con nào vượt trội dựa trên các encoder BERT thô là
thách thức, nhưng sử dụng EPR làm initializer cải thiện
đáng kể hiệu suất. Điều này chỉ ra kiến thức được học từ
việc lựa chọn ví dụ trong ngữ cảnh đơn góp phần vào việc
lựa chọn cấp độ tập. Về việc lựa chọn contrastive loss,
chúng tôi thấy InfoNCE và pair-wise margin loss thực hiện
tương đương trên các nhiệm vụ phân loại, nhưng loss sau
vượt trội đáng kể so với loss trước trên các nhiệm vụ sinh
sản, với khoảng 4% và 6% trên GeoQuery và MTOP, tương
ứng. Chú ý rằng các nhiệm vụ sinh sản khó hơn phân loại
vì các đáp án hiếm khi xuất hiện trực tiếp trong các ví dụ
trong ngữ cảnh. Điều này chỉ ra pair-wise margin loss,
là một contrastive loss chi tiết hơn so với InfoNCE loss,
thể hiện hiệu quả tốt hơn trên các nhiệm vụ khó hơn nhiều.

Về Tác động của Chiến lược Inference Trong đoạn này,
chúng tôi so sánh hai thuật toán inference (tức là TOPK
và DPP (viết tắt của DPP-MAP)) qua các phương pháp
không học và dựa trên học. So với TOPK, chúng tôi thấy
DPP-MAP mang lại nhiều cải thiện hơn khi sử dụng
retriever dựa trên học, chỉ ra tầm quan trọng của việc
căn chỉnh 'độ tương tự' của embedding với 'tính hữu ích'
cho inference. Ngoài độ chính xác, chúng tôi cũng thấy
độ trễ của việc lấy 50 ví dụ trong ngữ cảnh cho TOPK
và DPP-MAP trên tập dữ liệu SST5 lần lượt là 30s và
36s (1.2x). Do đó, chúng tôi khuyến nghị chọn TOPK
hoặc DPP-MAP cho các nhiệm vụ khác nhau xem xét
chi phí inference bổ sung trong các ứng dụng thực tế.
Chúng tôi cung cấp thêm chi tiết về sự cân bằng hiệu suất-
hiệu quả trong Phụ lục.

Về Tác động của Số lượng Ví dụ Trong ngữ cảnh Hầu hết
các LM lớn hiện tại được huấn luyện với độ dài đầu vào
hạn chế như 1,024 trong GPT2-XL và 2,048 trong GPT2-Neo,
điều này hạn chế số lượng ví dụ trong ngữ cảnh tối đa.
Ở đây chúng tôi đánh giá retriever được huấn luyện dưới
số lượng ví dụ trong ngữ cảnh khác nhau, như thể hiện
trong Hình 3 (Trái). Chúng tôi thấy xu hướng tăng rõ ràng
cho hầu hết các nhiệm vụ phân loại khi giảm số lượng,
chỉ ra hiệu quả trong việc lựa chọn một tập compact các
ví dụ trong ngữ cảnh. Chúng tôi quan sát xu hướng ngược
lại trong các nhiệm vụ sinh sản, mà chúng tôi giả thuyết
là do độ khó của các nhiệm vụ sinh sản, tức là câu hỏi
chỉ có thể được trả lời với số lượng đủ các ví dụ trong
ngữ cảnh. Một lợi thế khác của một tập compact các ví dụ
trong ngữ cảnh là chúng ta có thể cắt giảm đáng kể các
tính toán, vì module attention (Vaswani et al., 2017) trong
hầu hết các LM có độ phức tạp bậc hai. Chúng tôi thấy
CEIL chủ yếu vượt trội hơn EPR và TOPK-BERT với
32 ví dụ trong ngữ cảnh bằng cách chỉ sử dụng 4 và 1 ví
dụ, tương ứng (xem Phụ lục B.2 để biết chi tiết).

Về Tác động của Trade-off Factor Chúng tôi thực hiện
nghiên cứu ablation để xem tác động của trade-off factor
trong Hình 3 (Phải). Chú ý factor nhỏ hơn nhấn mạnh
nhiều hơn vào tính liên quan. Chúng tôi thấy factor thực
hiện tốt nhất thay đổi cho các tập dữ liệu khác nhau. Một
quan sát tổng quát là tính đa dạng quan trọng hơn cho
các nhiệm vụ khó hơn, như NLI và semantic parsing,
nhưng tính liên quan quan trọng hơn cho các nhiệm vụ
đơn giản hơn như phân tích cảm xúc. Xét sự khác biệt,
chúng tôi thấy việc giới thiệu trade-off factor vẫn nhất
quán vượt trội hơn các baseline EPR chỉ xem xét tính liên
quan, xác minh hiệu quả của CEIL.

5. Nghiên cứu Liên quan
5.1. Học tập Trong ngữ cảnh
Bằng cách cung cấp một vài ví dụ đầu vào-đầu ra làm
minh họa, học tập trong ngữ cảnh (ICL) trao quyền cho
các mô hình ngôn ngữ lớn (LMs) "học bằng cách so sánh"
và thực hiện các nhiệm vụ phức tạp như duyệt web (Nakano
et al., 2021), coding (Chen et al., 2021a), sinh dữ liệu
(Ye et al., 2022a; 2023), trò chơi chiến lược (FAIR et al.,
2022), và cuộc trò chuyện (OpenAI, 2022). Sự phổ biến
của ICL cũng làm dấy lên những lo ngại ngày càng tăng
về tính bất ổn của nó: với các lựa chọn khác nhau, hiệu
suất của ICL có thể thay đổi từ gần tiên tiến đến ngẫu nhiên
(Liu et al., 2022). Để giảm thiểu vấn đề này, các nhà nghiên
cứu đã nỗ lực đáng kể trong việc lựa chọn ví dụ trong ngữ
cảnh, có thể được phân loại thành các phương pháp không
học và dựa trên học. Trong dòng các phương pháp không
học, các tiêu chí heuristic khác nhau được đề xuất, như
độ tương tự ngữ nghĩa giữa các ví dụ kiểm tra và minh
họa (Liu et al., 2022), entropy (Lu et al., 2022; Wu et al.,
2022), tính đa dạng (Ye et al., 2022b; Su et al., 2022;
Levy et al., 2022; Agrawal et al., 2022). Tuy nhiên, các
phương pháp không học thường đòi hỏi các chuyên gia
con người thiết kế các heuristic cụ thể cho nhiệm vụ và
dẫn đến hiệu suất dưới mức tối ưu. Do đó, các nhà nghiên
cứu đã bắt đầu khám phá các phương pháp dựa trên học
để đẩy phong bì xa hơn. Rubin et al. (2022) đề xuất huấn
luyện một singleton example scorer sử dụng contrastive
learning với tín hiệu từ LM inferencer. Ngược lại, chúng
tôi nhắm đến mô hình hóa kết hợp việc lựa chọn toàn bộ
tập exemplar, điều này bổ sung xem xét tương tác giữa
các ví dụ trong ngữ cảnh. Ngoài việc lựa chọn ví dụ trong
ngữ cảnh, một số nghiên cứu đã khám phá multi-pass ICL,
đầu tiên sinh ra nhiều phản hồi từ các tập con exemplar
khác nhau (Shi et al., 2022; Li et al., 2022) và sau đó
tổng hợp chúng thông qua các kỹ thuật tương tự như
self-consistency (Wang et al., 2022). Ngược lại, các cách
tiếp cận multi-pass ICL đòi hỏi nhiều test-time inference,
có thể dẫn đến không hiệu quả.

5.2. Determinantal Point Processes
Determinantal point processes (DPPs) là các mô hình xác
suất hiệu quả có thể đo lường cả tính đa dạng và chất lượng
của các item trong một tập con, điều này làm cho nó trở
thành lựa chọn tự nhiên cho bài toán lựa chọn tập con
đa dạng (Kulesza et al., 2012). DPPs đã được áp dụng
cho tóm tắt tài liệu và video (Kulesza & Taskar, 2011;
Gong et al., 2014), hệ thống đề xuất (Gillenwater et al.,
2012), phát hiện đối tượng (Azadi et al., 2017) và phân
loại multi-label (Xie et al., 2017). Gần đây nhất, DPPs
đã được sử dụng trong học tập trong ngữ cảnh đặc biệt
cho các nhiệm vụ kết hợp (Levy et al., 2022), nơi các
tác giả đầu tiên dự đoán tất cả các target subphrase có
thể với một mô hình được huấn luyện đặc biệt, và sau đó
sử dụng DPPs để lấy mẫu một tập con đa dạng các ví dụ
trong ngữ cảnh để bao phủ càng nhiều subphrase càng tốt.
Tuy nhiên, mục tiêu đa dạng trong DPPs không được căn
chỉnh với LMs và thường cụ thể cho nhiệm vụ. Ngược lại,
chúng tôi khung hóa DPPs thành một framework end-to-end,
không chỉ nắm bắt tương tác giữa các ví dụ trong ngữ cảnh
mà còn phản ánh tốt sự ưu tiên của LMs về xác suất của
DPPs.

6. Kết luận
Trong bài báo này, chúng tôi tái khung hóa việc lựa chọn
ví dụ trong ngữ cảnh thành một bài toán tối ưu hóa end-to-end.
Chúng tôi đề xuất CEIL, tận dụng DPP để mô hình hóa
xác suất của toàn bộ tập con các ví dụ trong ngữ cảnh,
và được học thông qua một framework contrastive learning.
Kết quả trên 7 nhiệm vụ phân loại và sinh sản với 12
benchmark khác nhau cho thấy CEIL rõ ràng đánh bại
các phương pháp cạnh tranh trước đây. Retriever đã học
trong CEIL cũng thể hiện tính chuyển đổi đáng ngạc nhiên
qua các LM và tập dữ liệu, và tính kết hợp cho các nhiệm
vụ kết hợp, cho thấy một cách tiếp cận hiệu quả và hiệu
quả để thích ứng các LM lớn black-box với các nhiệm vụ
downstream.

Lời cảm ơn
Chúng tôi cảm ơn các reviewer ẩn danh có những đề xuất
đã giúp làm rõ công trình này. Công trình này được hỗ trợ
một phần bởi Ủy ban Khoa học và Công nghệ Thượng Hải
(Grant No. 21DZ1100100), và chương trình nghiên cứu
chung của Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc
(NSFC) và Hội đồng Tài trợ Nghiên cứu (RGC) dưới số
tài trợ NHKU714/21.

Tài liệu tham khảo
[Danh sách các tài liệu tham khảo từ trang 9-16 được dịch sang tiếng Việt với cùng định dạng]

A. Thiết lập Thí nghiệm
A.1. Tập dữ liệu
[Nội dung phần A.1 và các phần tiếp theo được dịch sang tiếng Việt]

B. Thí nghiệm Bổ sung
[Nội dung phần B và các phần con được dịch sang tiếng Việt]

C. Hạn chế
[Nội dung phần C được dịch sang tiếng Việt]

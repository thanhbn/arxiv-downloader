# Hãy Tổng Hợp Từng Bước: Tổng Hợp Tập Dữ Liệu Lặp Lại với Mô Hình Ngôn Ngữ Lớn bằng Cách Ngoại Suy Lỗi từ Mô Hình Nhỏ

Ruida Wang∗HWangchunshu ZhouAMrinmaya SachanE
HHKUSTAAIWaves Inc.EETH Zürich
rwangbr@connect.ust.hk chunshu@aiwaves.cn msachan@ethz.ch

Tóm tắt
Tổng hợp Dữ liệu là một cách tiếp cận đầy hứa hẹn để huấn luyện một mô hình nhỏ với rất ít dữ liệu được gán nhãn. Một phương pháp tổng hợp dữ liệu là tận dụng kiến thức phong phú từ các mô hình ngôn ngữ lớn để tổng hợp các ví dụ huấn luyện giả cho các mô hình nhỏ, giúp có thể đạt được cả hiệu quả dữ liệu và hiệu quả tính toán cùng một lúc. Tuy nhiên, một thách thức chính trong tổng hợp dữ liệu là tập dữ liệu được tổng hợp thường gặp phải sự khác biệt phân phối lớn so với phân phối dữ liệu nhiệm vụ thực tế. Do đó, trong bài báo này, chúng tôi đề xuất Synthesis Step by Step (S3), một khung tổng hợp dữ liệu thu hẹp khoảng cách phân phối này bằng cách lặp lại việc ngoại suy các lỗi do mô hình nhỏ được huấn luyện trên tập dữ liệu tổng hợp mắc phải trên một tập dữ liệu xác thực thực tế nhỏ sử dụng mô hình ngôn ngữ lớn. Các thí nghiệm mở rộng trên nhiều nhiệm vụ NLP cho thấy phương pháp của chúng tôi cải thiện hiệu suất của mô hình nhỏ bằng cách giảm khoảng cách giữa tập dữ liệu tổng hợp và dữ liệu thực, dẫn đến cải thiện đáng kể so với một số baseline: cải thiện 9,48% so với ZeroGen, 2,73% so với GoldGen, và cải thiện 15,17% so với mô hình nhỏ được huấn luyện trên dữ liệu do con người chú thích.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLMs) (Brown et al., 2020; Chowdhery et al., 2022; Touvron et al., 2023; OpenAI, 2023) đã thể hiện hiệu suất zero-shot đầy hứa hẹn trên nhiều nhiệm vụ, chứng minh tiềm năng của chúng trong việc phục vụ như các mô hình đa năng. Tuy nhiên, LLMs gặp phải vấn đề về hiệu quả do kích thước mô hình lớn và độ trễ suy luận cao, khiến chúng khó triển khai trong các ứng dụng thực tế. Do đó, các mô hình nhỏ được huấn luyện trên dữ liệu cụ thể cho nhiệm vụ vẫn được ưa chuộng trong nhiều tình huống bị hạn chế về tài nguyên vì chúng có ít tham số hơn nhiều, dễ triển khai, và hoạt động tốt trong các nhiệm vụ downstream cụ thể (Xu et al., 2021).

Hình 1: Độ chính xác huấn luyện và kiểm tra của DistilBert với ZeroGen (Ye et al., 2022b) trên tập dữ liệu IMDb với 200k điểm dữ liệu huấn luyện. Cũng được hiển thị là độ chính xác huấn luyện và kiểm tra của mô hình được huấn luyện trên GoldData. Chúng ta có thể thấy rằng độ chính xác huấn luyện của ZeroGen nhanh chóng đạt gần 100%, nhưng độ chính xác kiểm tra vẫn thấp.

Tuy nhiên, việc tùy chỉnh mô hình nhỏ cho một nhiệm vụ cụ thể có thể đòi hỏi lượng lớn dữ liệu được gán nhãn bởi con người, điều này không có sẵn trong nhiều nhiệm vụ downstream và tốn kém để chú thích. Vấn đề thiếu hiệu quả dữ liệu này khiến việc tinh chỉnh mô hình nhỏ trở nên thách thức. Do đó, một số hướng nghiên cứu khác nhau cố gắng giảm lượng dữ liệu cần thiết để tinh chỉnh các mô hình nhỏ trên các nhiệm vụ cụ thể, bao gồm knowledge distillation (Hinton et al., 2015; Beyer et al., 2022; Hsieh et al., 2023; Xu et al., 2020; Zhou et al., 2020; Shridhar et al., 2023), data augmentation (DeVries and Taylor, 2017; Shorten and Khoshgoftaar, 2019; Li et al., 2022), module replacing (Xu et al., 2020; Zhou et al., 2023), semi-supervised learning (Chen et al., 2020; Wang et al., 2021; Smith et al., 2022), và data synthesis (Anaby-Tavor et al., 2020; Puri et al., 2020).

Trong công việc này, chúng tôi tập trung vào tổng hợp dữ liệu, tạo ra dữ liệu và nhãn tương ứng từ đầu. Không giống như học bán giám sát, phương pháp này đơn giản và hiệu quả hơn, đặc biệt khi dữ liệu không được gán nhãn khan hiếm. Hầu hết các phương pháp hiện tại trong tổng hợp dữ liệu cho NLP sử dụng LLMs để tạo ra lượng dữ liệu huấn luyện không giới hạn cho việc huấn luyện mô hình nhỏ.

Các phương pháp tổng hợp tập dữ liệu hiện tại thường yêu cầu một lượng lớn dữ liệu tổng hợp để đạt được hiệu suất tương đối tốt với mô hình nhỏ, như trong ZeroGen (Ye et al., 2022b), đôi khi cần đến 1 triệu bản ghi dữ liệu tổng hợp. Tuy nhiên, điều này thường dẫn đến chi phí tổng hợp dữ liệu bổ sung và chi phí tính toán khi huấn luyện mô hình nhỏ cụ thể cho nhiệm vụ.

Một cách trực quan, chất lượng của dữ liệu tổng hợp, hoặc mức độ dữ liệu tổng hợp giống với dữ liệu nhiệm vụ thực tế, là quan trọng đối với hiệu suất của mô hình nhỏ. Tuy nhiên, do tính phức tạp của các nhiệm vụ cụ thể trong thế giới thực, dữ liệu tổng hợp thường gặp phải khoảng cách phân phối so với phân phối dữ liệu thực tế. Điều này có thể thấy rõ trong Hình 1. Độ chính xác huấn luyện của mô hình nhỏ trên dữ liệu tổng hợp gần 100% nhưng độ chính xác kiểm tra trên dữ liệu thực tế vẫn thấp. Ngược lại, khoảng cách giữa độ chính xác huấn luyện và kiểm tra nhỏ hơn nhiều khi được huấn luyện trên dữ liệu do con người chú thích.

Để giảm khoảng cách phân phối và cải thiện hiệu quả dữ liệu trong tổng hợp tập dữ liệu, chúng tôi đề xuất Synthesis Step by Step (S3), một khung tổng hợp tập dữ liệu mới giảm khoảng cách phân phối theo cách hiệu quả dữ liệu bằng cách tối ưu hóa động tập dữ liệu tổng hợp. Như minh họa trong Hình 2, S3 đầu tiên tổng hợp một tập dữ liệu hạt giống với phương pháp explain-then-generate trước tiên nhắc LLMs tạo ra lý do cho mỗi nhãn và sau đó kết hợp lý do đã tạo và các lời nhắc cụ thể cho nhiệm vụ để tạo ra các điểm dữ liệu. S3 sau đó tinh chỉnh tập dữ liệu hạt giống bằng cách lặp lại việc tổng hợp thêm dữ liệu bằng cách ngoại suy các lỗi của mô hình được huấn luyện trên tập dữ liệu hạt giống mắc phải trên tập xác thực nhỏ, mà chúng tôi giả định được lấy mẫu từ phân phối dữ liệu nhiệm vụ thực.

Chúng tôi tóm tắt đóng góp của mình như sau: (1) Chúng tôi đề xuất một góc nhìn mới về tổng hợp tập dữ liệu động, cho phép tạo ra dữ liệu huấn luyện cho các mô hình nhỏ hơn và có thể được tối ưu hóa bằng cách thêm dữ liệu; dựa trên quan điểm này, chúng tôi đề xuất khung S3 có thể tổng hợp và tối ưu hóa tập dữ liệu giả sử dụng LLM có thể thu hẹp hiệu quả khoảng cách phân phối trong tổng hợp tập dữ liệu. (2) Chúng tôi thực hiện phân tích lý thuyết về tính hiệu quả của S3 trong việc giảm khoảng cách phân phối. (3) Chúng tôi thực hiện các thí nghiệm mở rộng trên ba nhiệm vụ NLP chính và thu được cải thiện trung bình 9,48% so với ZeroGen (Ye et al., 2022b), một baseline đại diện cho tổng hợp tập dữ liệu, chỉ sử dụng 30,43% dữ liệu trung bình.

2 Phương pháp
Chúng tôi mô tả khung S3 được đề xuất một cách chi tiết trong phần này. Ý tưởng chính của S3 là đầu tiên tổng hợp tập dữ liệu hạt giống bằng cách nhắc LLMs và sau đó lặp lại việc giảm khoảng cách phân phối bằng cách ngoại suy các lỗi mô hình nhỏ mắc phải trên tập xác thực nhỏ từ phân phối dữ liệu thực tế. S3 bao gồm các bước sau:

1. Tạo dữ liệu hạt giống: Chúng tôi sử dụng LLM để phân tích nhiệm vụ chúng tôi đang làm việc, sau đó tổng hợp danh sách các lý do có thể có cho nhiệm vụ đó. Nếu nhiệm vụ khó phân tích, chúng tôi có thể bỏ qua bước này. Sau đó, chúng tôi kết hợp các lý do tổng hợp, các câu ngữ cảnh có thể có, và nhãn trong một lời nhắc để hướng dẫn LLM tổng hợp tập dữ liệu.

2. Huấn luyện mô hình nhỏ: Huấn luyện mô hình nhỏ với tập dữ liệu tổng hợp, sau đó xác thực mô hình nhỏ trên dữ liệu xác thực thực tế, và thu được dữ liệu bị phân loại sai của mô hình nhỏ, sử dụng chúng như lỗi.

3. Ngoại suy lỗi: Sử dụng LLM để ngoại suy các lỗi của mô hình nhỏ và tổng hợp dữ liệu bổ sung sử dụng thông tin trong các lỗi.

4. Kết hợp và Lặp lại: Kết hợp tập dữ liệu bổ sung và tập dữ liệu gốc như một tập dữ liệu huấn luyện tổng hợp mới cho mô hình nhỏ, sau đó lặp lại các bước 2 và 3 trong nhiều vòng cho đến khi hiệu suất của mô hình nhỏ hội tụ.

Chúng tôi đầu tiên giới thiệu một số nền tảng và ký hiệu chính trong Phần 2.1. Sau đó chúng tôi mô tả các thuật toán cho tổng hợp dữ liệu hạt giống và tổng hợp dựa trên ngoại suy lỗi lặp lại trong Phần 2.2 (điểm 1. ở trên) và Phần 2.3 (điểm 2, 3, 4 ở trên), tương ứng. Cuối cùng, chúng tôi đưa ra một giải thích lý thuyết về phương pháp được đề xuất trong Phần 2.6.

2.1 Nền tảng
Theo Sharp et al. (2017), chúng tôi ký hiệu phân phối của ngôn ngữ con người cho LLM dưới đầu vào nhắc T là PLLM(·|T). Mô hình nhỏ là một mô hình hiệu quả về mặt tính toán sẽ được huấn luyện trên tập dữ liệu tổng hợp của chúng tôi. Nói chung, mô hình nhỏ chứa ít tham số hơn nhiều và dễ huấn luyện và triển khai trong các ứng dụng thực tế. Chúng tôi ký hiệu mô hình nhỏ được huấn luyện bởi tập dữ liệu Dtrain là f(·|Dtrain).

2.2 Tổng hợp Dữ liệu Hạt giống với Lý do
Dữ liệu Hạt giống được định nghĩa là tập dữ liệu tổng hợp zero-shot cơ bản cho khung S3 của chúng tôi.

Thuật toán 1: Tổng hợp dữ liệu hạt giống với lý do
Input: Y, Tration, T(1)query, PLLM, K, k, Nseed
Output: Dseed
1 for each yi ∈ Y do
2   ri ← topK(PLLM(·|Tration(yi)))
3 Dseed ← ∅
4 for i in range(Nseed) do
5   ycurr ∼ U1(Y)
6   rcurr ∼ Uk(ri)
7   xcurr ∼ PLLM(·|T(1)query(rcurr, ycurr))
8   Dseed ← Dseed ∪ {(xcurr, ycurr)}

Chúng tôi trình bày thuật toán cho tổng hợp dữ liệu hạt giống với lý do trong Thuật toán 1. Ở đây, Y ký hiệu tập hợp tất cả các nhãn có thể có trong nhiệm vụ chúng tôi đang làm việc; Tration(y) ký hiệu nhãn và lời nhắc mô tả nhiệm vụ cho tổng hợp lý do; T(1)query(r, y) là lời nhắc tổng hợp dữ liệu bao bọc các lý do trong r và nhãn y cùng nhau để hỏi LLM về một điểm dữ liệu; topK có nghĩa là lấy mẫu top-K từ đầu ra LLM để thu được danh sách lý do cho một nhãn cụ thể; Ui(S) có nghĩa là lấy mẫu đồng đều i phần tử không lặp lại trong tập S. Tập dữ liệu hạt giống kết quả được ký hiệu là Dseed={Xseed, Yseed}.

Ví dụ, đối với tập dữ liệu IMDb (Maas et al., 2011), một tập dữ liệu phân tích cảm xúc về đánh giá phim, Tration(yi=positive/negative) là: "Lý do gì có thể dẫn đến đánh giá phim positive/negative." và Tquery(rcurr, positive) là: "Bây giờ hãy tưởng tượng bạn vừa xem một bộ phim có diễn xuất tuyệt vời, cốt truyện hấp dẫn, và kỹ thuật quay phim đẹp. Bây giờ bạn nên viết một đánh giá tích cực về bộ phim này." Chúng tôi sử dụng lời nhắc như một đầu vào cho LLM và thu được đầu ra mục tiêu như ví dụ giả tổng hợp. Phương pháp "explain-then-generate" này cho phép chúng tôi tạo ra các ví dụ đa dạng, thông tin và thực tế hơn.

2.3 Tinh chỉnh Tập dữ liệu với Ngoại suy Lỗi
Sau đó chúng tôi mô tả khung Tổng hợp dựa trên Ngoại suy Lỗi (EES) cố gắng giảm khoảng cách phân phối một cách lặp lại bằng cách ngoại suy các lỗi của mô hình nhỏ được huấn luyện trên tập dữ liệu tổng hợp hiện tại trên tập xác thực nhỏ. Điều này khác với các phương pháp tổng hợp dữ liệu thông thường, nơi tập dữ liệu tổng hợp được cố định sau khi hoàn thành quá trình tổng hợp và được sử dụng để huấn luyện mô hình nhỏ. Cụ thể, quá trình EES ngoại suy các lỗi do các mô hình nhỏ mắc phải trên tập dữ liệu xác thực thực tế để tổng hợp một số dữ liệu bổ sung để sửa lỗi.

Chúng tôi sử dụng hai nguồn dữ liệu khác nhau trong quá trình EES: tập dữ liệu hạt giống (Dseed), và một tập dữ liệu nhỏ được gán nhãn bởi con người, thực tế được gọi là dữ liệu thực tế, ký hiệu là Dgold. Trong EES, chúng tôi đầu tiên chia dữ liệu thực tế thành tập dữ liệu xác thực D(val)gold và tập dữ liệu kiểm tra D(test)gold. Chúng tôi sử dụng D(val)gold để tìm và sửa khoảng cách phân phối và sử dụng D(test)gold để đánh giá hiệu suất của mô hình nhỏ.

Thuật toán 2: Thuật toán cho Ngoại suy Lỗi
Input: Dseed, D(eval)gold, D(test)gold, f, PLLM, R, T(1)mis
Output: Dtrain
1 D(0)add ← ∅
2 for q in range(R) do
3   init(f); // khởi tạo lại f (xóa huấn luyện vòng cuối)
4   D(q)train ← Dseed ∪ (∪qi=1 D(i)add)
5   train(f, D(q)train)
6   D(q)mis ← misclass{f(D(eval)gold|D(q)train)}
7   D(q+1)add ← ∅
8   for each (xmis, ymis) ∈ D(q)mis do
9     xadd ∼ PLLM(·|T(1)mis(xmis, ymis))
10    D(q+1)add ← D(q+1)add ∪ {(xadd, ymis)}
11 Dtrain ← Dseed ∪ (∪Ni=1 D(i)add)

Chúng tôi trình bày toàn bộ quá trình EES trong Thuật toán 2. Một vòng trong vòng lặp for bắt đầu ở dòng 2 ký hiệu một vòng EES. R ký hiệu số vòng EES chúng tôi muốn thực hiện; trong triển khai của chúng tôi, chúng tôi thường thực hiện 2 vòng thí nghiệm. f ký hiệu mô hình nhỏ; D(q)mis ký hiệu tập hợp các ví dụ bị phân loại sai bởi mô hình nhỏ trên tập dữ liệu xác thực thực tế trong vòng thứ q của EES. T(1)mis(xmis, ymis) ký hiệu lời nhắc được sử dụng cho ngoại suy lỗi. Lời nhắc yêu cầu LLM tổng hợp một điểm dữ liệu tương tự như xmis với nhãn ymis. Trong triển khai của chúng tôi, chúng tôi sử dụng lời nhắc: "Viết một đánh giá phim tích cực giống như Bộ phim rất hay." D(q+1)add ký hiệu tập dữ liệu bổ sung thứ q+1 chúng tôi tổng hợp trên LLM dựa trên ngoại suy D(q)mis.

Các bước chính của thuật toán EES là huấn luyện mô hình nhỏ với tập dữ liệu tổng hợp hiện tại (dòng 6) và sử dụng LLM để ngoại suy dữ liệu bị phân loại sai để tạo ra nhiều dữ liệu huấn luyện hơn (dòng 8-10). Điều này tạo ra một tập dữ liệu phản ánh tốt hơn sự thật cơ bản.

Tóm lại, quá trình EES giảm khoảng cách phân phối bằng cách sử dụng dữ liệu bị phân loại sai để mô hình hóa khoảng cách phân phối và sử dụng LLM để lấy mẫu các điểm dữ liệu bổ sung từ nó. Ý tưởng này tương tự như việc tối ưu hóa trên phần dư trong tài liệu gradient boosting (Friedman, 2002).

2.4 Quy trình đặc biệt cho nhiệm vụ nhiều câu
Để rõ ràng, chúng tôi tập trung vào các nhiệm vụ đơn câu trong thuật toán được thảo luận trước đây. Khi chuyển sang các nhiệm vụ nhiều câu, cần có những sửa đổi nhỏ. Cụ thể, đối với các nhiệm vụ phức tạp như trả lời câu hỏi, câu ngữ cảnh có thể quá dài, ngăn lời nhắc của chúng tôi phù hợp với giới hạn đầu vào của LLM. Ngay cả khi lời nhắc phù hợp, việc tạo ra lý do cho mỗi câu ngữ cảnh có thể tốn kém đến mức cấm. Do đó, đối với những tình huống này, chúng tôi sử dụng phương pháp tổng hợp dữ liệu hạt giống truyền thống hơn.

Cụ thể, chúng tôi thực hiện tổng hợp tập dữ liệu với một tập hợp các ngữ cảnh điều kiện C = c1, ···, cm (ví dụ, tiền đề trong NLI và ngữ cảnh & câu trả lời trong nhiệm vụ QA). Chúng tôi thực hiện tổng hợp tập dữ liệu như sau:

1. Lấy mẫu đồng đều câu ngữ cảnh hiện tại ccurr từ C, và nhãn mục tiêu hiện tại ycurr từ tất cả các nhãn có thể có Y. Kết hợp chúng thành lời nhắc tổng hợp dữ liệu hạt giống T(2)query(ccurr, ycurr).

2. Tổng hợp câu mục tiêu (ví dụ, giả thuyết trong NLI và câu hỏi trong QA) từ LLM bằng T(2)query(ccurr, ycurr). Dữ liệu tổng hợp được ký hiệu là (ccurr, xsyn, ycurr).

3. Lặp lại các bước trên cho đến khi chúng tôi có đủ dữ liệu hạt giống Dseed = (Cseed, Xseed, Yseed).

Đối với quá trình EES, trong các nhiệm vụ nhiều câu, chúng tôi chỉ cần sửa đổi vòng lặp for bắt đầu ở dòng 8 trong Thuật toán 2 để phù hợp với nhiệm vụ nhiều câu. Phiên bản đã thay đổi của dòng 8 được hiển thị trong Thuật toán 3.

Thuật toán 3: EES nhiều câu, vòng lặp for bên trong
1 for each (cmis, xmis, ymis) ∈ D(q)mis do
2   xadd ∼ PLLM(·|T(2)mis(cmis, xmis, ymis))
3   D(q+1)add ← D(q+1)add ∪ {(cmis, xadd, ymis)}

2.5 Kỹ thuật tạo lời nhắc
Thiết kế lời nhắc có thể có tác động lớn đến chất lượng của tập dữ liệu tổng hợp. Chúng tôi trình bày các mẫu lời nhắc được sử dụng để tạo ra lý do, điểm dữ liệu, và ngoại suy lỗi trong Bảng 1.

2.6 Phân tích Lý thuyết
Trong phần này, chúng tôi đưa ra phân tích chi tiết về lý do khung S3 của chúng tôi có thể thu hẹp khoảng cách phân phối giữa tổng hợp zero-shot và phân phối thực tế bằng cách đầu tiên làm rõ thiết lập phân tích và sau đó đưa ra phân tích về vấn đề khoảng cách phân phối và tính hiệu quả của khung S3 của chúng tôi.

Chúng tôi ký hiệu không gian xác suất của ví dụ dữ liệu là P = (S, Σ); ở đây, để đơn giản, chúng tôi bao bọc tất cả các phần tử có thể có trong một ví dụ dữ liệu thành một biến s ∈ S, và các thành phần trong s có thể thay đổi tùy thuộc vào nhiệm vụ cụ thể, ví dụ, trong nhiệm vụ phân loại văn bản, tức là, s = (x, y) trong đó x là một đoạn văn bản và y là nhãn tương ứng.

Chúng tôi giả định rằng tập dữ liệu thực tế (ký hiệu là {S(gold)i}ngoldi=1) được thu được bằng cách lấy mẫu i.i.d. ngold lần từ phân phối thực tế PD ∈ P. Sau đó, chúng tôi cũng giả định quá trình thu được một ví dụ dữ liệu tổng hợp như một lấy mẫu i.i.d. từ PLLM ∈ P. Trong phần phân tích, để đơn giản, chúng tôi định nghĩa PLLM là một phân phối trên tập hợp ví dụ dữ liệu S thay vì không gian của ngôn ngữ con người. Sự khác biệt này quan trọng vì trong khi dữ liệu văn bản ở dạng ngôn ngữ tự nhiên, đối với nhiều nhiệm vụ, nhãn có thể không phải vậy.

Tương tự, chúng tôi giả định rằng quá trình thu được tập dữ liệu hạt giống (ký hiệu là {Si}n1i=1), trong đó n1 là số điểm dữ liệu hạt giống, là để rút ra n1 mẫu i.i.d. từ phân phối dữ liệu hạt giống của chúng tôi P(0)LLM.

Trước tiên hãy nhớ lại nguồn gốc của vấn đề khoảng cách phân phối trong các phương pháp tổng hợp tập dữ liệu: các phương pháp tổng hợp dữ liệu thông thường, cũng như giai đoạn tổng hợp dữ liệu hạt giống trong phương pháp của chúng tôi, lấy mẫu các điểm dữ liệu từ một phân phối cố định P(0)LLM. Vì phân phối được cố định và khác với phân phối dữ liệu nhiệm vụ PD, tập dữ liệu tổng hợp gặp phải khoảng cách phân phối cố định bất kể chúng tôi tổng hợp bao nhiêu dữ liệu. Do đó, hiệu suất kiểm tra của mô hình nhỏ được huấn luyện trên tập dữ liệu tổng hợp trên dữ liệu nhiệm vụ thực bị giới hạn bởi khoảng cách này. Phương pháp của chúng tôi, S3, nhằm giải quyết hạn chế này.

Hãy giả định rằng mô hình nhỏ học hoàn hảo phân phối tập dữ liệu tổng hợp. Trong trường hợp này, lỗi mà mô hình nhỏ mắc phải trên tập dữ liệu xác thực thực tế nhỏ có thể đại diện cho khoảng cách phân phối giữa PD và P(0)LLM.

Cuối cùng, chúng tôi lập luận rằng một LLM tốt có thể ngoại suy hoàn hảo từ các lỗi. Điều này có nghĩa là LLM có thể tổng hợp các mẫu từ sự khác biệt giữa hai phân phối PD - P(0)LLM. Một cách chính thức, dữ liệu bổ sung được tổng hợp trong mỗi vòng của quá trình EES tuân theo:

Padd := PLLM(·|PD - P(0)LLM)    (1)

Do đó, bằng cách lấy mẫu cùng số điểm dữ liệu từ Padd và kết hợp chúng với phân phối dữ liệu hạt giống gốc P(0)LLM, tập dữ liệu hỗn hợp sẽ tuân theo phân phối:

P(1)LLM := p·Padd + (1-p)P(0)LLM ≈ PD    (2)

trong đó p ∈ [0,1] là tỷ lệ kết hợp, nó có thể được hiểu một cách trực quan là phần của tập dữ liệu bổ sung và tập dữ liệu hạt giống. Điều này cho thấy rằng, về mặt lý thuyết, chúng tôi có thể khôi phục phân phối dữ liệu thực tế bằng cách đơn giản kết hợp dữ liệu hạt giống gốc và dữ liệu bổ sung được tổng hợp thông qua EES.

Tuy nhiên, xin lưu ý rằng chúng tôi không thể đảm bảo LLM và việc huấn luyện mô hình nhỏ là hoàn hảo trong các tình huống thực tế. Do đó, S3 lặp lại quá trình này một cách lặp lại để giảm dần khoảng cách phân phối và tối ưu hóa tập dữ liệu hỗn hợp cho đến khi hội tụ.

3 Thí nghiệm
Chúng tôi tiến hành thí nghiệm để kiểm tra tính hiệu quả của phương pháp của chúng tôi trên ba nhiệm vụ NLP chính trên bốn tập dữ liệu. Chúng tôi cũng thực hiện một nghiên cứu ablation kỹ lưỡng (Phần 3.4), một nghiên cứu khả năng chuyển giao (Phần 3.5) cho khung S3, và một nghiên cứu về chất lượng dữ liệu bổ sung (Phần 3.6).

3.1 Thiết lập

3.1.1 Tập dữ liệu
Trong nghiên cứu này, chúng tôi đánh giá S3 của chúng tôi trên ba nhiệm vụ NLP chính: phân loại văn bản, Natural Language Inference (NLI), và Question Answering (QA). Đối với phân loại văn bản, chúng tôi sử dụng tập dữ liệu IMDb (Maas et al., 2011); đối với nhiệm vụ NLI, chúng tôi sử dụng tập dữ liệu QNLI (Rajpurkar et al., 2016; Wang et al., 2018) và RTE (Bentivogli et al., 2009; Giampiccolo et al., 2007; Haim et al., 2006); đối với nhiệm vụ QA, chúng tôi sử dụng tập dữ liệu Adversarial QA (Bartolo et al., 2020).

3.2 Baselines
Chúng tôi so sánh khung S3 của chúng tôi với các baseline sau:

1. ZeroGen: ZeroGen là phương pháp tổng hợp dữ liệu cơ bản được đề xuất bởi Ye et al. (2022b). Nó không sử dụng lý do cho tổng hợp dữ liệu cũng không cố gắng giảm khoảng cách phân phối. Lưu ý rằng ZeroGen cũng sử dụng cùng tập xác thực nhỏ để điều chỉnh siêu tham số.

2. GoldGen: Baseline này ngoại suy toàn bộ dữ liệu xác thực thực tế thay vì các lỗi do mô hình nhỏ mắc phải. Chúng tôi tiếp tục sử dụng baseline này để kiểm tra tính hiệu quả của ý tưởng ngoại suy lỗi trong khung S3. Chúng tôi giữ quy mô của các tập dữ liệu tổng hợp giống nhau để có so sánh công bằng với S3.

3. ProGen: Baseline này được đề xuất bởi Ye et al. (2022a), giống như EES, nó cũng xem xét phản hồi huấn luyện. Tuy nhiên, khung này chỉ có sẵn cho các nhiệm vụ phân loại văn bản, và nó không sử dụng lý do LLM cho tổng hợp dữ liệu.

4. Dữ liệu thực tế: Chúng tôi cũng bao gồm một baseline huấn luyện mô hình nhỏ trên dữ liệu thực tế gốc để tham khảo.

3.2.1 Chi tiết triển khai
Phần này đưa ra chi tiết triển khai đầy đủ của S3 trong các thí nghiệm của chúng tôi. Chúng tôi áp dụng GPT3.5 được phát triển từ (Brown et al., 2020) làm LLM cho tất cả công việc tổng hợp, và chúng tôi sử dụng nucleus sampling (Holtzman et al., 2019) với nhiệt độ 0.9 để giải mã. Chúng tôi sử dụng DistilBERT-base-uncased (Sanh et al., 2020) được cung cấp bởi thư viện Hugging Face Transformers (Wolf et al., 2019) làm mô hình nhỏ. Chúng tôi thực hiện điều chỉnh siêu tham số trên kích thước batch, tỷ lệ học, weight decay, và số epoch để tinh chỉnh mô hình nhỏ.

3.2.2 Phương pháp Đánh giá
Đối với các nhiệm vụ phân loại văn bản và NLI, chúng tôi sử dụng tỷ lệ chính xác làm phương pháp đánh giá. Đối với các nhiệm vụ QA, chúng tôi sử dụng Exact Match (EM) và điểm F1 làm phương pháp đánh giá. Để triển khai thí nghiệm phương pháp S3, chúng tôi sử dụng dữ liệu huấn luyện từ tập dữ liệu gốc làm tập dữ liệu đánh giá thực tế trong EES (tức là, D(eval)gold). Và chúng tôi sử dụng dữ liệu kiểm tra từ tập dữ liệu gốc để kiểm tra hiệu suất của mô hình.

3.3 Kết quả Thí nghiệm
Chúng tôi trình bày kết quả thí nghiệm chính của chúng tôi trong Bảng 2. Chúng tôi có thể quan sát thấy rằng khung S3 của chúng tôi có cải thiện rất lớn (cải thiện trung bình 9,48%) so với ZeroGen. Khoảng cách hiệu suất đặc biệt lớn trong các nhiệm vụ NLI và QA. Hơn nữa, chúng tôi chỉ sử dụng lượng dữ liệu trung bình 30,43% so với ZeroGen, điều này có thể được coi là một cải thiện đáng kể. Cải thiện như vậy chứng minh tính hiệu quả của phương pháp tổng hợp dữ liệu hạt giống ban đầu và ý tưởng tiếp tục tối ưu hóa dữ liệu trong S3 của chúng tôi.

Sau đó chúng tôi so sánh S3 với baseline GoldGen để kiểm tra tính hiệu quả của việc ngoại suy các lỗi của mô hình nhỏ trên tập xác thực thay vì toàn bộ tập xác thực. Chúng tôi thấy rằng S3 vượt trội hơn GoldGen với cải thiện hiệu suất tuyệt đối trung bình 2,73%. Điều này xác nhận lợi thế của ngoại suy lỗi so với việc ngoại suy trực tiếp dữ liệu thực tế.

Cũng đáng chú ý là S3 mang lại kết quả cạnh tranh so với việc tinh chỉnh trực tiếp mô hình nhỏ trên dữ liệu huấn luyện thực tế đầy đủ. Cụ thể, S3 thậm chí vượt trội hơn hiệu suất dữ liệu thực tế trên IMDB và RTE. Điều này xác nhận tiềm năng áp dụng S3 trong các ứng dụng thực tế.

3.4 Nghiên cứu Ablation

3.4.1 Ablation của EES
Chúng tôi đầu tiên ablate khung tổng hợp dựa trên ngoại suy lỗi (EES) của S3, chỉ sử dụng dữ liệu hạt giống được tổng hợp dựa trên Phần 2.2. Chúng tôi đảm bảo rằng quy mô của tập dữ liệu huấn luyện là xấp xỉ giống nhau để có so sánh công bằng. Kết quả có thể thấy trong Bảng 3. Kết quả này chứng minh tính hiệu quả của quan điểm về tập dữ liệu động và EES của chúng tôi. Chúng tôi thấy rằng đối với các nhiệm vụ phức tạp hơn như QA và NLI, khung EES của chúng tôi có thể mang lại cải thiện lớn hơn, điều này chứng minh vấn đề khoảng cách phân phối và khả năng của khung EES của chúng tôi trong việc thu hẹp khoảng cách này.

3.4.2 Ablation của Tổng hợp Dữ liệu Hạt giống với Lý do
Sau đó chúng tôi ablate việc sử dụng lý do cho tổng hợp tập dữ liệu trong khung S3 trên tập dữ liệu IMDb. Kết quả được hiển thị trong Bảng 4. Chúng tôi thấy rằng việc sử dụng lý do cho tổng hợp tập dữ liệu cho phép LLM tạo ra các tập dữ liệu chất lượng cao hơn dẫn đến hiệu suất tốt hơn của mô hình nhỏ với ngân sách thấp hơn, tức là, ít ví dụ tổng hợp hơn.

3.5 Khả năng chuyển giao của dữ liệu EES
Sau đó chúng tôi kiểm tra khả năng chuyển giao của dữ liệu được tổng hợp EES. Kết quả được hiển thị trong Bảng 5. Trong thử nghiệm này, chúng tôi thay thế tập dữ liệu hạt giống của khung của chúng tôi bằng dữ liệu được tổng hợp bởi Ye et al. (2022b). Chúng tôi thực hiện hai tập thử nghiệm. Chúng tôi so sánh các biến thể nơi chúng tôi trực tiếp thêm dữ liệu EES được tổng hợp trong S3 (+ourAdd) và với mô hình nhỏ được huấn luyện trên dữ liệu được tổng hợp bởi Ye et al. (2022b). Chúng tôi có thể thấy rằng cả hai biến thể đều dẫn đến cải thiện hiệu suất tương tự. Điều này cho thấy dữ liệu được tổng hợp EES có thể chuyển giao hiệu quả sang các tập dữ liệu tổng hợp zero-shot khác. Chúng tôi tin rằng điều này là do khoảng cách phân phối cho các phương pháp tổng hợp dữ liệu zero-shot khác nhau là tương tự. Do đó, dữ liệu được tổng hợp bởi phương pháp EES có thể hữu ích một cách toàn cầu, điều này chứng minh thêm tiềm năng của S3.

3.6 Nghiên cứu chất lượng dữ liệu bổ sung
Chúng tôi thực hiện thí nghiệm này để kiểm tra chất lượng của tập dữ liệu bổ sung được tổng hợp bởi EES. Lưu ý rằng đối với các LLM trước đó như GPT2 (Radford et al., 2019) hoặc T5 (Raffel et al., 2020), từng có xu hướng lặp lại lời nhắc. Nếu LLM chỉ lặp lại dữ liệu bị phân loại sai, thì không có ngoại suy. Do đó, chúng tôi sáng tác thí nghiệm như sau để kiểm tra chất lượng của tập dữ liệu bổ sung:

Mã hóa Câu: Đối với cả dữ liệu bị phân loại sai Dmis và dữ liệu bổ sung Dadd, chúng tôi sử dụng DistilBERT để mã hóa từng xmis và xadd. Điều này dẫn đến các câu được mã hóa được biểu diễn tương ứng là zmis và zadd, và mỗi câu được mã hóa ở trong Rd (với d = 768 trong DistilBERT)

Độ tương tự Cosine: Sau đó, bằng cách so sánh độ tương tự cosine giữa zmis và zadd, chúng tôi đo lường độ tương tự ngữ nghĩa của chúng. Độ tương tự cosine cao cho thấy sự chồng chéo ngữ nghĩa đáng kể.

Khoảng cách Chỉnh sửa: Hơn nữa, để hiểu sự khác biệt văn bản, chúng tôi tính khoảng cách chỉnh sửa giữa các câu xmis và xadd. Nếu khoảng cách chỉnh sửa tiến gần đến độ dài câu, chúng tôi suy luận rằng các văn bản khác nhau đáng kể trong thành phần của chúng. Kết quả được hiển thị trong Bảng 6.

Độ dài trung bình của dữ liệu bị phân loại sai (avg xmis len) và độ dài trung bình của dữ liệu được tạo (avg xadd len) cung cấp ngữ cảnh để giải thích khoảng cách chỉnh sửa. Kết quả này cho thấy rằng trong khi có độ tương tự ngữ nghĩa cao giữa dữ liệu bị phân loại sai và dữ liệu bổ sung được tạo (được chứng minh bởi điểm độ tương tự cosine), các câu được tạo không phải là bản sao đơn thuần của các mẫu bị phân loại sai (vì khoảng cách chỉnh sửa của chúng gần bằng độ dài của toàn bộ câu). Kết quả này cung cấp bằng chứng bổ sung ủng hộ chất lượng của dữ liệu mới được tạo.

4 Công việc liên quan

4.1 Tổng hợp Tập dữ liệu
Lượng lớn dữ liệu được yêu cầu bởi phần lớn các phương pháp Học Máy đã thúc đẩy nhiều nhà nghiên cứu khám phá khái niệm Tổng hợp Tập dữ liệu. Điều này nhằm tạo ra một tập dữ liệu từ các mô hình được huấn luyện trước lớn, chẳng hạn như LLMs, để chuyển giao kiến thức phong phú từ các mô hình lớn sang các mô hình nhỏ. Những nỗ lực ban đầu để đạt được điều này đã sử dụng các mô hình tạo sinh được tinh chỉnh để tạo ra dữ liệu (Anaby-Tavor et al., 2020; Kumar et al., 2020). Những nỗ lực này bao gồm việc đầu tiên tinh chỉnh LLMs với một lượng nhỏ dữ liệu do con người chú thích (dữ liệu thực tế), sau đó kết hợp dữ liệu được tạo với dữ liệu thực tế để huấn luyện các mô hình nhỏ. Các nhà nghiên cứu khác tìm cách tổng hợp lượng lớn dữ liệu cho học bán giám sát (Chen et al., 2020; Wang et al., 2021). Tuy nhiên, những phương pháp này chỉ phù hợp cho các nhiệm vụ phân loại văn bản đơn giản, chứng minh thiếu hiệu quả dữ liệu và không hiệu quả cho các nhiệm vụ phức tạp hơn như NLI hoặc QA.

Tiềm năng của hiệu suất zero-shot được cung cấp bởi LLMs đã khiến một số nhà nghiên cứu xem xét tổng hợp tập dữ liệu zero-shot dựa trên các LLM không được tinh chỉnh (Meng et al., 2022; Ye et al., 2022b). Tuy nhiên, như được chỉ ra bởi Hình 1, việc hỏi trực tiếp các LLM không được tinh chỉnh thường dẫn đến dữ liệu gặp phải khoảng cách phân phối lớn và thường không hiệu quả. Do đó, một số nghiên cứu đã cố gắng lựa chọn dữ liệu (Gao et al., 2023) hoặc tăng cường dữ liệu (Ye et al., 2022a). Tuy nhiên, khả năng của chúng trong việc khắc phục khoảng cách phân phối vẫn còn chỗ để cải thiện.

4.2 Học trong ngữ cảnh
Brown et al. (2020) gợi ý rằng LLMs có thể học tốt hơn nhiệm vụ chúng đang làm việc bằng cách điều kiện hóa trên một vài ví dụ trong lời nhắc. Mô hình này, được gọi là Học trong ngữ cảnh, đặc biệt hấp dẫn vì nó phủ nhận sự cần thiết của việc cập nhật các tham số của LLM. Nghiên cứu tiếp theo đã tập trung vào việc tối ưu hóa sự lựa chọn của các mẫu lời nhắc và ví dụ trong ngữ cảnh (Liu et al., 2021; Wang et al., 2023; Lu et al., 2021), và học với các mô tả mục tiêu trong ngữ cảnh (Chen et al., 2021). Ý tưởng chính cho học trong ngữ cảnh là học từ sự tương tự (Dong et al., 2022), điều này phù hợp với ý tưởng của chúng tôi về việc ngoại suy lỗi để tổng hợp dữ liệu bổ sung để lấp đầy khoảng cách phân phối. Tuy nhiên, hầu hết các phương pháp học trong ngữ cảnh được thiết kế cho thiết lập few-shot, trong khi trong nghiên cứu của chúng tôi, LLM không cần được huấn luyện. Chúng tôi khám phá khả năng của LLM trong việc ngoại suy trực tiếp từ các lỗi, cung cấp một ví dụ quan trọng để tạo ra một tập dữ liệu hiệu quả hơn.

5 Kết luận
Bài báo này đề xuất phương pháp Synthesis Step by Step (S3) dựa trên quan điểm tập dữ liệu động cho tổng hợp tập dữ liệu. S3 là một khung tổng hợp tập dữ liệu mới thu hẹp khoảng cách phân phối giữa các tập dữ liệu được tổng hợp hoàn toàn bởi LLMs và phân phối dữ liệu cơ bản thực. S3 đạt được điều này bằng cách đầu tiên sử dụng tổng hợp dữ liệu hạt giống với lý do để có khoảng cách phân phối thấp trong dữ liệu hạt giống. Nó thu hẹp khoảng cách phân phối này bằng cách lặp lại việc ngoại suy các lỗi của mô hình nhỏ trên một lượng nhỏ dữ liệu thực tế. Các thí nghiệm mở rộng trên ba nhiệm vụ NLP chính trên bốn tập dữ liệu được sử dụng phổ biến cho thấy rằng so với một baseline đại diện, S3 cải thiện đáng kể hiệu suất của mô hình nhỏ với trung bình chỉ một phần ba dữ liệu tổng hợp. S3 có tiềm năng thực tế cao trong nhiều ứng dụng thực tế vì nó có thể hiệu quả (tức là, với hiệu suất tốt hơn) và hiệu quả (tức là, với hiệu quả dữ liệu được cải thiện) chuyển giao kiến thức trong một mô hình cực lớn (ví dụ, GPT 3.5) sang một mô hình nhỏ (ví dụ, DistilBert), đạt được hiệu quả dữ liệu và hiệu quả tính toán cùng một lúc.

Lời cảm ơn
Chúng tôi cảm ơn các nhà đánh giá ẩn danh vì phản hồi của họ về bài báo của chúng tôi. MS thừa nhận hỗ trợ từ Quỹ Khoa học Quốc gia Thụy Sĩ (Dự án số 197155), một tài trợ AI Có trách nhiệm của Haslerstiftung; và một Tài trợ ETH (ETH-19 21-1).

Hạn chế
Mặc dù S3 đạt được kết quả đầy hứa hẹn, vẫn có một số hạn chế của công việc chúng tôi. Hạn chế đầu tiên là trong các thí nghiệm, chúng tôi phát hiện rằng một thay đổi nhỏ trong các lời nhắc tổng hợp có thể dẫn đến sự sụt giảm hiệu suất đáng kể, có nghĩa là khung của chúng tôi không ổn định về lời nhắc. Một hướng tương lai có thể là phát triển một cách có hệ thống để soạn các lời nhắc có thể hoạt động ổn định tốt bằng cách tinh chỉnh một LLM sử dụng các lời nhắc tốt. Hạn chế thứ hai là S3 giả định rằng LLM có kiến thức phong phú về nhiệm vụ cụ thể. Nhưng trong việc áp dụng thực tế của phương pháp trong thế giới thực, không có đảm bảo như vậy. Một giải pháp có thể để giảm thiểu hạn chế này là yêu cầu LLM chia nhiệm vụ chưa thấy trước đó thành nhiều nhiệm vụ đơn giản mà LLM có hiểu biết tốt, nhưng nó cũng yêu cầu LLM có khả năng tốt để hiểu các nhiệm vụ phụ. Hạn chế thứ ba là S3 cụ thể cho nhiệm vụ. Công việc tương lai có thể cố gắng mở rộng phương pháp sang cài đặt cross-task để cải thiện thêm hiệu quả tính toán và dữ liệu của phương pháp.

Tài liệu tham khảo
[Các tài liệu tham khảo được dịch sang tiếng Việt...]

A Hiểu trực quan về EES
Vì mã giả của EES có thể hơi không trực quan để hiểu, phần này nhằm cung cấp sự hiểu biết trực quan về phương pháp EES trên các nhiệm vụ đơn câu.

A.1 Thu được Lỗi
Bước đầu tiên cho EES là thu được lỗi do mô hình nhỏ mắc phải trên tập dữ liệu xác thực thực tế, điều này, ở một mức độ nào đó, là biểu diễn của khoảng cách phân phối giữa phân phối tổng hợp dữ liệu hạt giống của LLM và phân phối thực tế.

Để thu được lỗi, chúng tôi trước tiên phải huấn luyện mô hình nhỏ với dữ liệu được tổng hợp hiện tại. Điều này bao gồm dữ liệu hạt giống Dseed, và các tập dữ liệu bổ sung D(0)add, ···, D(q)add, trong đó q là vòng lặp hiện tại. Sau đó chúng tôi có D(0)add = ∅. Do đó, tập dữ liệu huấn luyện cho lần lặp thứ q là:

D(q)train = Dseed ∪ (∪qj=0 D(j)add)    (3)

Sau đó, chúng tôi huấn luyện mô hình nhỏ với D(q)train. Chúng tôi ký hiệu mô hình nhỏ được tùy chỉnh là f(·|D(q)train). Sau đó, chúng tôi đánh giá mô hình nhỏ được tùy chỉnh trên tập dữ liệu xác thực thực tế và thu được các mẫu dữ liệu với lỗi cao trong tập dữ liệu xác thực:

D(q)mis = misclass{f(D(eval)gold|Dtrain)}    (4)

trong đó hàm misclass ký hiệu hàm thu được các mẫu dữ liệu đã bị phân loại sai. Ví dụ, đối với nhiệm vụ QA, điều này có thể có nghĩa là các mẫu dữ liệu không có khớp chính xác với câu trả lời hoặc các mẫu dữ liệu với điểm F1 thấp. Chúng tôi biểu diễn khoảng cách phân phối giữa sự thật cơ bản và D(q)train bằng tập dữ liệu đánh giá thực tế bị phân loại sai D(q)mis, đây là khoảng cách phân phối trong vòng thứ q của EES.

A.2 Tổng hợp trên việc ngoại suy lỗi
Sau khi có D(q)mis, đối với tất cả dữ liệu bị phân loại sai (xmis, ymis) ∈ D(q)mis, chúng tôi hỏi LLM một lần nữa sử dụng lời nhắc bao bọc thông tin của dữ liệu bị phân loại sai. Lời nhắc T(1)mis(xmis, ymis) một cách trực quan yêu cầu LLM ngoại suy dữ liệu bị phân loại sai và tổng hợp một ví dụ dữ liệu mới. Ví dụ, trong bài toán phân loại phim, nếu dữ liệu bị phân loại sai hiện tại là: (The movie is great, positive); f(·|D(q)train) gốc của chúng tôi đã gán nhãn đánh giá như vậy là một đánh giá tiêu cực. Trong trường hợp này, T(1)mis(xmis, ymis) có thể là gì đó như Generate a positive movie review like The movie is great.

Chúng tôi hỏi LLM với T(1)mis(xmis, ymis), để thu được một ví dụ dữ liệu khác tương tự như lỗi. Quá trình này được lặp lại cho mỗi điểm dữ liệu bị phân loại sai. Do đó, chúng tôi thu được tập dữ liệu bổ sung thứ q+1 D(q+1)add. Chúng tôi lặp lại các bước Thu được Lỗi và Tổng hợp trên việc ngoại suy lỗi trong nhiều vòng cho đến khi lỗi hội tụ. Với phương pháp như vậy, chúng tôi có thể tối ưu hóa tập dữ liệu tổng hợp của mình từng bước để đạt được một tập dữ liệu với khoảng cách phân phối thấp hơn bằng cách sử dụng thông tin được cung cấp bởi việc ngoại suy các lỗi đại diện cho khoảng cách phân phối.

B So sánh độ phức tạp tính toán giữa S3 và ZeroGen
Phần này nghiên cứu tổng chi phí tính toán của khung S3. Chúng tôi so sánh số lượng phép toán dấu phẩy động (FLOPs) liên quan đến việc tinh chỉnh mô hình với tập dữ liệu tổng hợp S3 và ZeroGen. Đối với họ mô hình BERT, theo Brown et al. (2020), chúng tốn 6 FLOPs mỗi token mỗi tham số (tức là, Ftoken,para = 6) trong huấn luyện. Mô hình DistilBERT (Sanh et al., 2020) có npara = 66×106 tham số và độ dài đầu vào điển hình cho một bản ghi là num(token)rec = 512. Do đó, FLOPs huấn luyện mỗi bản ghi dữ liệu mỗi epoch là:

Frec = Ftoken,para ∗ num(token)rec ∗ npara = 2.03×1011

Phương pháp ZeroGen thường sử dụng 200k bản ghi dữ liệu và huấn luyện trong trung bình 10 epoch để đạt được kết quả tốt nhất dựa trên thí nghiệm của chúng tôi. Do đó, tổng chi phí tinh chỉnh theo FLOPs cho ZeroGen là:

FZeroGen = Frec ∗ 200k ∗ 10 = 4.06∗1017

Trong S3, trong vòng tinh chỉnh đầu tiên (chỉ sử dụng dữ liệu hạt giống), kích thước tập dữ liệu là 51.2k bản ghi trung bình (tức là, tập dữ liệu hạt giống có kích thước khoảng 2/3 của tập dữ liệu cuối cùng). Sau một vòng EES, tổng kích thước tập dữ liệu trở thành 64.0k (tức là, kích thước 5/6 của tập dữ liệu cuối cùng). Vòng tinh chỉnh cuối cùng với hai tập dữ liệu bổ sung EES và tập dữ liệu hạt giống có tổng kích thước 76.8k bản ghi dữ liệu. Trung bình, phương pháp của chúng tôi cần 8 epoch để đạt được kết quả tốt nhất. Do đó, tổng số FLOPs để tinh chỉnh DistilBERT cho 3 lần lặp (2 để nhận dữ liệu bị phân loại sai, 1 để tinh chỉnh cuối cùng) trong S3 của chúng tôi là:

FS3 = Frec ∗ (51.2k + 64.0k + 76.8k) ∗ 8 = 3.11∗1017

Để kết luận, do ít vòng epoch tinh chỉnh hơn và nhu cầu dữ liệu thấp hơn, S3 chỉ sử dụng 3/4 số FLOPs so với baseline ZeroGen, mặc dù chúng tôi đã tinh chỉnh mô hình nhiều lần.

C Phân tích đa dạng tập dữ liệu cho S3
Phần này phân tích tính đa dạng của các câu được tổng hợp. Phân tích như vậy là cần thiết vì LLMs có thể tạo ra các câu với ý nghĩa tương tự, làm cho tập dữ liệu thiếu tính đa dạng. Vì không có phương pháp được phê duyệt toàn cầu để phân tích tính đa dạng tập dữ liệu, chúng tôi sử dụng cả phương pháp định lượng và định tính để phân tích tính đa dạng tập dữ liệu:

C.1 Phân tích Định lượng:
Đối với các câu tổng hợp ngắn, chẳng hạn như các tập dữ liệu QNLI, RTE, và AdQA, chúng tôi tiếp cận phân tích tập dữ liệu một cách định lượng. Với chiều ẩn cao của việc mã hóa câu (ví dụ, 768 cho DistilBERT), phân tích trực tiếp có thể không hiệu quả. Do đó, chúng tôi sử dụng t-SNE để giảm chiều (Van der Maaten và Hinton, 2008). Các bước cuối cùng của phân tích của chúng tôi như sau:

1. Lấy mẫu đồng đều một lượng dữ liệu tương tự từ dữ liệu thực tế, dữ liệu tổng hợp S3, dữ liệu tổng hợp ZeroGen. Chúng tôi có D′gold = {x(i)gold, y(i)gold}n1i=1, D′S3 = {x(j)S3, y(j)S3}n2j=1, và D′ZeroGen = {x(k)ZeroGen, y(k)ZeroGen}n3k=1 trong đó n1, n2, n3 nên tương tự.

2. Mã hóa các câu sử dụng DistilBERT. Sau đó, chúng tôi có các mã hóa câu: {z(i)gold}n1i=1, {z(j)S3}n2j=1, {z(k)ZeroGen}n3k=1 ⊆ Rd, trong đó d là chiều của trạng thái ẩn (trong trường hợp của chúng tôi, nó là 768).

3. Thực hiện t-SNE trên dữ liệu được mã hóa z := {z(i)gold}n1i=1 ∪ {z(j)S3}n2j=1 ∪ {z(k)ZeroGen}n3k=1 để giảm chiều từ d xuống 2. Chúng tôi có: t-SNE(z) = p = {p(i)gold}n1i=1 ∪ {p(j)S3}n2j=1 ∪ {p(k)ZeroGen}n3k=1 ⊆ R2

4. Vẽ các điểm chiều đã giảm trên biểu đồ phân tán để trực tiếp thấy sự chồng chéo của tập dữ liệu tổng hợp của chúng tôi và dữ liệu Thực tế. Chúng tôi hiển thị kết quả trong Hình 3. Chúng tôi có thể thấy rằng vùng xanh lá cây phù hợp đáng kể với vùng tím, điều này cho thấy rằng S3 dẫn đến tính đa dạng dữ liệu tương tự như dữ liệu thực tế.

Tính đa dạng dữ liệu cũng có thể được định lượng bằng cách đếm có bao nhiêu điểm của p(k)gold nằm trong vùng AS3 := ∪n2j=1 Bγ(p(j)S3) và AZeroGen := ∪n3k=1 Bγ(p(k)ZeroGen), trong đó Bγ(p) đại diện cho một hình tròn đặc với tâm p và bán kính γ. Kết quả cho QNLI, RTE, và AdQA được hiển thị trong Bảng 8. Kết quả chứng minh thêm về độ bao phủ và tính đa dạng vượt trội của khung S3 của chúng tôi so với ZeroGen.

C.2 Phân tích Định tính:
Đối với các nhiệm vụ yêu cầu tạo ra các văn bản dài hơn, phương pháp mã hóa văn bản không thích hợp cho việc giảm chiều t-SNE và giải thích. Do đó, trong những cài đặt như vậy, chúng tôi tiến hành phân tích định tính. Chúng tôi hiển thị các ví dụ về dữ liệu được tạo cho trường hợp phân loại cảm xúc của đánh giá IMDB trong Bảng 7. Chúng tôi có thể quan sát thấy rằng những ví dụ này thể hiện các ngữ cảnh phong phú và các mẫu đa dạng, điều này hỗ trợ tính ưu việt của khung S3 của chúng tôi. Để có kết quả định tính hơn, vui lòng tham khảo tập dữ liệu trong kho dự án của chúng tôi.

D Kết quả Bổ sung cho S3 với MiniLM
Ngoài DistilBERT, chúng tôi cũng đánh giá hiệu suất của khung Synthesis Step by Step (S3) sử dụng MiniLM (Wang et al., 2020) làm mô hình nhỏ. Kết quả của thí nghiệm này được trình bày trong Bảng 9. Đáng chú ý, có một sự nâng cao đáng kể về hiệu suất khi so sánh với baseline ZeroGen trong tất cả các nhiệm vụ. Hơn nữa, trong các nhiệm vụ như RTE thiếu dữ liệu, phương pháp của chúng tôi thậm chí còn vượt qua hiệu suất của mô hình được huấn luyện trên dữ liệu thực tế. Những kết quả này cung cấp bằng chứng mạnh mẽ rằng tính hiệu quả của S3 không giới hạn ở một mô hình cụ thể. Thay vào đó, nó mang lại những cải thiện nhất quán trên các mô hình nhỏ khác nhau, nhấn mạnh khả năng ứng dụng rộng rãi và hiệu quả của nó.

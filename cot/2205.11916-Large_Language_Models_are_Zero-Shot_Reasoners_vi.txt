# 2205.11916.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/cot/2205.11916.pdf
# Kích thước tệp: 762445 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Các Mô hình Ngôn ngữ Lớn là Những Người Suy luận Zero-Shot
Takeshi Kojima
Đại học Tokyo
t.kojima@weblab.t.u-tokyo.ac.jpShixiang Shane Gu
Google Research, Brain Team
Machel Reid
Google ResearchYutaka Matsuo
Đại học TokyoYusuke Iwasawa
Đại học Tokyo

Tóm tắt
Các mô hình ngôn ngữ lớn được huấn luyện trước (LLM) được sử dụng rộng rãi trong nhiều lĩnh vực con của xử lý ngôn ngữ tự nhiên (NLP) và thường được biết đến như những người học few-shot xuất sắc với các mẫu cụ thể của nhiệm vụ. Đáng chú ý, prompting chuỗi suy nghĩ (CoT), một kỹ thuật gần đây để kích thích suy luận phức tạp nhiều bước thông qua các ví dụ trả lời từng bước, đã đạt được hiệu suất tốt nhất trong toán học và suy luận ký hiệu, những nhiệm vụ hệ thống-2 khó khăn không tuân theo quy luật tỷ lệ tiêu chuẩn cho LLM. Trong khi những thành công này thường được quy cho khả năng học few-shot của LLM, chúng tôi cho thấy rằng LLM là những người suy luận zero-shot khá tốt bằng cách đơn giản thêm "Hãy suy nghĩ từng bước" trước mỗi câu trả lời. Kết quả thực nghiệm chứng minh rằng Zero-shot-CoT của chúng tôi, sử dụng cùng một mẫu prompt duy nhất, vượt trội đáng kể so với hiệu suất zero-shot LLM trên các nhiệm vụ suy luận benchmark đa dạng bao gồm toán học (MultiArith, GSM8K, AQUA-RAT, SVAMP), suy luận ký hiệu (Last Letter, Coin Flip), và các nhiệm vụ suy luận logic khác (Date Understanding, Tracking Shuffled Objects), mà không cần bất kỳ ví dụ few-shot được tạo thủ công nào, ví dụ tăng độ chính xác trên MultiArith từ 17.7% lên 78.7% và GSM8K từ 10.4% lên 40.7% với mô hình InstructGPT quy mô lớn (text-davinci-002), cũng như mức độ cải thiện tương tự với một mô hình lớn khác có sẵn, PaLM 540B tham số. Tính linh hoạt của prompt đơn lẻ này trên các nhiệm vụ suy luận rất đa dạng gợi ý về những khả năng zero-shot cơ bản chưa được khai thác và nghiên cứu của LLM, cho thấy khả năng nhận thức rộng lớn, đa nhiệm vụ ở mức cao có thể được trích xuất bằng prompting đơn giản. Chúng tôi hy vọng công trình của chúng tôi không chỉ phục vụ như đường cơ sở zero-shot mạnh nhất tối thiểu cho các benchmark suy luận thách thức, mà còn làm nổi bật tầm quan trọng của việc khám phá và phân tích cẩn thận kiến thức zero-shot khổng lồ ẩn giấu bên trong LLM trước khi tạo ra các tập dữ liệu fine-tuning hoặc các mẫu few-shot.

1 Giới thiệu
Mở rộng quy mô của các mô hình ngôn ngữ đã là thành phần chính của các cuộc cách mạng gần đây trong xử lý ngôn ngữ tự nhiên (NLP) [Vaswani et al., 2017, Devlin et al., 2019, Raffel et al., 2020, Brown et al., 2020, Thoppilan et al., 2022, Rae et al., 2021, Chowdhery et al., 2022]. Thành công của các mô hình ngôn ngữ lớn (LLM) thường được quy cho việc học few-shot hoặc zero-shot (trong ngữ cảnh). Nó có thể giải quyết nhiều nhiệm vụ khác nhau bằng cách đơn giản điều kiện hóa các mô hình trên một vài ví dụ (few-shot) hoặc hướng dẫn mô tả nhiệm vụ (zero-shot). Phương pháp điều kiện hóa mô hình ngôn ngữ được gọi là "prompting" [Liu et al., 2021b], và thiết kế prompt thủ công [Schick and Schütze, 2021, Reynolds and McDonell, 2021] hoặc tự động [Gao et al., 2021, Shin et al., 2020] đã trở thành chủ đề nóng trong NLP.

Công trình được thực hiện tại Đại học Tokyo.
Hội nghị lần thứ 36 về Hệ thống Xử lý Thông tin Neural (NeurIPS 2022).arXiv:2205.11916v4 [cs.CL] 29 Jan 2023

--- TRANG 2 ---
(c) Zero-shot 
Q: Một người tung tung có thể tung 16 quả bóng. Một nửa số bóng là bóng golf, và một nửa số bóng golf là màu xanh. Có bao nhiêu quả bóng golf màu xanh?
A: Câu trả lời (số Ả Rập) là  
(Đầu ra) 8 X(d) Zero-shot-CoT (Của chúng tôi) 
Q: Một người tung tung có thể tung 16 quả bóng. Một nửa số bóng là bóng golf, và một nửa số bóng golf là màu xanh. Có bao nhiêu quả bóng golf màu xanh?
A: Hãy suy nghĩ từng bước.  
(Đầu ra) Có tổng cộng 16 quả bóng. Một nửa số bóng là bóng golf. Điều đó có nghĩa là có 8 quả bóng golf. Một nửa số bóng golf là màu xanh. Điều đó có nghĩa là có 4 quả bóng golf màu xanh. ✓Q: Roger có 5 quả bóng tennis. Anh ấy mua thêm 2 hộp bóng tennis. Mỗi hộp có 3 quả bóng tennis. Hiện tại Roger có bao nhiêu quả bóng tennis?
A: Roger bắt đầu với 5 quả bóng. 2 hộp, mỗi hộp 3 quả bóng tennis là 6 quả bóng tennis. 5 + 6 = 11. Câu trả lời là 11.
Q: Một người tung tung có thể tung 16 quả bóng. Một nửa số bóng là bóng golf, và một nửa số bóng golf là màu xanh. Có bao nhiêu quả bóng golf màu xanh?
A:
(Đầu ra) Người tung tung có thể tung 16 quả bóng. Một nửa số bóng là bóng golf. Vậy có 16 / 2 = 8 quả bóng golf. Một nửa số bóng golf là màu xanh. Vậy có 8 / 2 = 4 quả bóng golf màu xanh. Câu trả lời là 4. ✓(b) Few-shot-CoT (a) Few-shot 
Q: Roger có 5 quả bóng tennis. Anh ấy mua thêm 2 hộp bóng tennis. Mỗi hộp có 3 quả bóng tennis. Hiện tại Roger có bao nhiêu quả bóng tennis?
A: Câu trả lời là 11.
Q: Một người tung tung có thể tung 16 quả bóng. Một nửa số bóng là bóng golf, và một nửa số bóng golf là màu xanh. Có bao nhiêu quả bóng golf màu xanh?
A:
(Đầu ra) Câu trả lời là 8. X

Hình 1: Ví dụ đầu vào và đầu ra của GPT-3 với (a) Few-shot tiêu chuẩn ([Brown et al., 2020]), (b) Few-shot-CoT ([Wei et al., 2022]), (c) Zero-shot tiêu chuẩn, và (d) của chúng tôi (Zero-shot-CoT). Tương tự như Few-shot-CoT, Zero-shot-CoT tạo điều kiện cho suy luận nhiều bước (văn bản màu xanh) và đạt được câu trả lời đúng khi prompting tiêu chuẩn thất bại. Không giống như Few-shot-CoT sử dụng ví dụ suy luận từng bước cho mỗi nhiệm vụ, phương pháp của chúng tôi không cần bất kỳ ví dụ nào và chỉ sử dụng cùng một prompt "Hãy suy nghĩ từng bước" trên tất cả các nhiệm vụ (toán học, ký hiệu, common sense, và các nhiệm vụ suy luận logic khác).

Trái ngược với hiệu suất xuất sắc của LLM trong các nhiệm vụ hệ thống-1 [Stanovich and West, 2000] trực quan và một bước với prompting few-shot hoặc zero-shot cụ thể của nhiệm vụ [Liu et al., 2021b], ngay cả các mô hình ngôn ngữ ở quy mô 100B hoặc nhiều tham số hơn đã gặp khó khăn với các nhiệm vụ hệ thống-2 đòi hỏi suy luận chậm và nhiều bước [Rae et al., 2021]. Để giải quyết thiếu sót này, Wei et al. [2022], Wang et al. [2022] đã đề xuất prompting chuỗi suy nghĩ (CoT), cung cấp cho LLM các ví dụ suy luận từng bước thay vì các ví dụ câu hỏi và trả lời tiêu chuẩn (xem Hình. 1-a). Những minh họa chuỗi suy nghĩ như vậy tạo điều kiện cho các mô hình tạo ra một đường dẫn suy luận phân tách suy luận phức tạp thành nhiều bước dễ dàng hơn. Đáng chú ý với CoT, hiệu suất suy luận sau đó thỏa mãn các quy luật tỷ lệ tốt hơn và tăng vọt với kích thước của các mô hình ngôn ngữ. Ví dụ, khi kết hợp với mô hình PaLM 540B tham số [Chowdhery et al., 2022], prompting chuỗi suy nghĩ tăng đáng kể hiệu suất so với prompting few-shot tiêu chuẩn trên một số nhiệm vụ suy luận benchmark, ví dụ, GSM8K (17.9% → 58.1%).

Trong khi những thành công của prompting CoT [Wei et al., 2022], cùng với những thành công của nhiều công trình prompting cụ thể của nhiệm vụ khác [Gao et al., 2021, Schick and Schütze, 2021, Liu et al., 2021b], thường được quy cho khả năng học few-shot của LLM [Brown et al., 2020], chúng tôi cho thấy rằng LLM là những người suy luận zero-shot khá tốt bằng cách thêm một prompt đơn giản, Hãy suy nghĩ từng bước, để tạo điều kiện cho suy nghĩ từng bước trước khi trả lời mỗi câu hỏi (xem Hình 1). Mặc dù đơn giản, Zero-shot-CoT của chúng tôi thành công tạo ra một đường dẫn suy luận hợp lý theo cách zero-shot và đạt được câu trả lời đúng trong một bài toán mà phương pháp zero-shot tiêu chuẩn thất bại. Quan trọng là, Zero-shot-CoT của chúng tôi là linh hoạt và bất khả tri về nhiệm vụ, không giống như hầu hết công trình thiết kế prompt cụ thể của nhiệm vụ trước đây dưới dạng ví dụ (few-shot) hoặc mẫu (zero-shot) [Liu et al., 2021b]: nó có thể tạo điều kiện cho câu trả lời từng bước trên các nhiệm vụ suy luận khác nhau, bao gồm toán học (MultiArith [Roy and Roth, 2015], GSM8K [Cobbe et al., 2021], AQUA-RAT [Ling et al., 2017], và SVAMP [Patel et al., 2021]), suy luận ký hiệu (Last letter và Coin flip), suy luận common sense (CommonSenseQA [Talmor et al., 2019] và Strategy QA [Geva et al., 2021]), và các nhiệm vụ suy luận logic khác (Date understanding và Tracking Shuffled Objects từ BIG-bench [Srivastava et al., 2022]) mà không cần sửa đổi prompt cho mỗi nhiệm vụ.

Chúng tôi đánh giá thực nghiệm Zero-shot-CoT so với các đường cơ sở prompting khác trong Bảng 2. Trong khi Zero-shot-CoT của chúng tôi kém hơn Few-shot-CoT với các ví dụ từng bước được thiết kế cẩn thận và cụ thể của nhiệm vụ, Zero-shot-CoT đạt được những cải thiện điểm số khổng lồ so với đường cơ sở zero-shot, ví dụ từ 17.7% lên 78.7% trên MultiArith và từ 10.4% lên 40.7% trên GSM8K với mô hình InstructGPT quy mô lớn

--- TRANG 3 ---
mô hình (text-davinci-002). Chúng tôi cũng đánh giá Zero-shot-CoT với một mô hình lớn khác có sẵn, PaLM 540B tham số, cho thấy mức độ cải thiện tương tự trên MultiArith và GSM8K. Quan trọng là, với prompt cố định duy nhất của chúng tôi, LLM zero-shot có đường cong tỷ lệ tốt hơn đáng kể so với đường cơ sở Few-shot CoT. Chúng tôi cũng cho thấy rằng ngoài việc Few-shot-CoT đòi hỏi thiết kế thủ công của prompt suy luận nhiều bước, hiệu suất của chúng giảm nếu loại câu hỏi ví dụ prompt và loại câu hỏi nhiệm vụ không khớp, cho thấy độ nhạy cao với thiết kế prompt cho mỗi nhiệm vụ. Ngược lại, tính linh hoạt của prompt đơn lẻ này trên các nhiệm vụ suy luận đa dạng gợi ý về những khả năng zero-shot cơ bản chưa được khai thác và nghiên cứu của LLM, như khả năng nhận thức rộng lớn ở mức cao hơn như suy luận logic chung [Chollet, 2019]. Trong khi lĩnh vực sôi động của LLM bắt đầu từ tiền đề của những người học few-shot xuất sắc [Brown et al., 2020], chúng tôi hy vọng công trình của chúng tôi khuyến khích nhiều nghiên cứu hơn để khám phá khả năng zero-shot ở mức cao và đa nhiệm vụ ẩn giấu bên trong những mô hình đó.

2 Nền tảng
Chúng tôi xem xét ngắn gọn hai khái niệm sơ bộ cốt lõi tạo thành nền tảng của công trình này: sự xuất hiện của các mô hình ngôn ngữ lớn (LLM) và prompting, và prompting chuỗi suy nghĩ (CoT) cho suy luận nhiều bước.

Các mô hình ngôn ngữ lớn và prompting Một mô hình ngôn ngữ (LM), là một mô hình tìm cách ước tính phân phối xác suất trên văn bản. Gần đây, những cải thiện về tỷ lệ thông qua kích thước mô hình lớn hơn (từ vài triệu [Merity et al., 2016] đến hàng trăm triệu [Devlin et al., 2019] đến hàng trăm tỷ [Brown et al., 2020] tham số) và dữ liệu lớn hơn (ví dụ corpus webtext [Gao et al., 2020]) đã cho phép các mô hình ngôn ngữ lớn được huấn luyện trước (LLM) trở nên cực kỳ thành thạo trong nhiều nhiệm vụ NLP downstream. Bên cạnh mô hình "huấn luyện trước và fine-tune" cổ điển [Liu et al., 2021b], các mô hình được mở rộng lên 100B+ tham số thể hiện các thuộc tính có lợi cho việc học few-shot [Brown et al., 2020], thông qua học trong ngữ cảnh, nơi người ta có thể sử dụng một văn bản hoặc mẫu được gọi là prompt để hướng dẫn mạnh mẽ việc tạo ra để đưa ra câu trả lời cho các nhiệm vụ mong muốn, do đó bắt đầu một kỷ nguyên "huấn luyện trước và prompt" [Liu et al., 2021a]. Trong công trình này, chúng tôi gọi những prompt như vậy với điều kiện rõ ràng trên một vài ví dụ nhiệm vụ là prompt few-shot, và các prompt chỉ có mẫu khác là prompt zero-shot.

Prompting chuỗi suy nghĩ Các benchmark suy luận số học và logic nhiều bước đã đặc biệt thách thức các quy luật tỷ lệ của các mô hình ngôn ngữ lớn [Rae et al., 2021]. Prompting chuỗi suy nghĩ (CoT) [Wei et al., 2022], một thể hiện của prompting few-shot, đề xuất một giải pháp đơn giản bằng cách sửa đổi các câu trả lời trong ví dụ few-shot thành câu trả lời từng bước, và đạt được những cải thiện hiệu suất đáng kể trên các benchmark khó này, đặc biệt khi kết hợp với các mô hình ngôn ngữ rất lớn như PaLM [Chowdhery et al., 2022]. Hàng đầu của Hình 1 cho thấy prompting few-shot tiêu chuẩn so với prompting CoT (few-shot). Đáng chú ý, việc học few-shot được coi là điều đương nhiên để giải quyết những nhiệm vụ khó như vậy, và hiệu suất đường cơ sở zero-shot thậm chí không được báo cáo trong công trình gốc [Wei et al., 2022]. Để phân biệt nó với phương pháp của chúng tôi, chúng tôi gọi Wei et al. [2022] là Few-shot-CoT trong công trình này.

3 Chuỗi Suy nghĩ Zero-shot
Chúng tôi đề xuất Zero-shot-CoT, một prompting dựa trên mẫu zero-shot cho suy luận chuỗi suy nghĩ. Nó khác với prompting chuỗi suy nghĩ gốc [Wei et al., 2022] vì nó không yêu cầu ví dụ few-shot từng bước, và nó khác với hầu hết prompting mẫu trước đây [Liu et al., 2021b] vì nó vốn dĩ bất khả tri về nhiệm vụ và kích thích suy luận nhiều hop trên một phạm vi rộng các nhiệm vụ với một mẫu duy nhất. Ý tưởng cốt lõi của phương pháp chúng tôi rất đơn giản, như được mô tả trong Hình 1: thêm Hãy suy nghĩ từng bước, hoặc một văn bản tương tự (xem Bảng 4), để trích xuất suy luận từng bước.

3.1 Prompting hai giai đoạn
Trong khi Zero-shot-CoT về mặt khái niệm đơn giản, nó sử dụng prompting hai lần để trích xuất cả suy luận và câu trả lời, như được giải thích trong Hình 2. Ngược lại, đường cơ sở zero-shot (xem phía dưới bên trái trong Hình 1) đã sử dụng prompting dưới dạng "Câu trả lời là", để trích xuất câu trả lời ở định dạng đúng. Prompting few-shot, tiêu chuẩn hoặc CoT, tránh cần prompting trích xuất câu trả lời như vậy bằng cách thiết kế rõ ràng các câu trả lời ví dụ few-shot để kết thúc ở những định dạng như vậy (xem phía trên bên phải và phía trên bên trái

--- TRANG 4 ---
Q: Trung bình Joe đấm 25 cú mỗi phút. Một trận đấu kéo dài 5 hiệp, mỗi hiệp 3 phút. Anh ấy đã đấm bao nhiêu cú?
A: Hãy suy nghĩ từng bước.
Trong một phút, Joe đấm 25 cú.
Trong ba phút, Joe đấm 3 * 25 = 75 cú.
Trong năm hiệp, Joe đấm 5 * 75 = 375 cú. Q: Trung bình Joe đấm 25 cú mỗi phút. Một trận đấu kéo dài 5 hiệp mỗi hiệp 3 ・・・
A: Hãy suy nghĩ từng bước.
Trong một phút, Joe đấm 25 cú. ・・・Trong năm hiệp, Joe đấm 5 * 75 = 375 cú. .
Do đó, câu trả lời (số Ả Rập) là 375.LLM
LLM【Prompt thứ nhất】
Trích xuất Suy luận 【Prompt thứ hai】
Trích xuất Câu trả lời

Hình 2: Pipeline đầy đủ của Zero-shot-CoT như mô tả trong § 3: chúng tôi trước tiên sử dụng prompt "suy luận" đầu tiên để trích xuất một đường dẫn suy luận đầy đủ từ một mô hình ngôn ngữ, và sau đó sử dụng prompt "câu trả lời" thứ hai để trích xuất câu trả lời ở định dạng đúng từ văn bản suy luận.

trong Hình 1). Tóm lại, Few-shot-CoT [Wei et al., 2022] yêu cầu thiết kế thủ công cẩn thận của một vài ví dụ prompt với định dạng câu trả lời cụ thể cho mỗi nhiệm vụ, trong khi Zero-shot-CoT yêu cầu ít thiết kế hơn nhưng yêu cầu prompting LLM hai lần.

Prompt thứ nhất: trích xuất suy luận Trong bước này, chúng tôi trước tiên sửa đổi câu hỏi đầu vào x thành một prompt x' bằng cách sử dụng một mẫu đơn giản "Q: [X]. A:[T]", trong đó [X] là một slot đầu vào cho x và [T] là một slot cho câu kích thích được tạo thủ công t sẽ trích xuất chuỗi suy nghĩ để trả lời câu hỏi x. Ví dụ, nếu chúng tôi sử dụng "Hãy suy nghĩ từng bước" làm câu kích thích, prompt x' sẽ là "Q: [X]. A: Hãy suy nghĩ từng bước.". Xem Bảng 4 để biết thêm ví dụ kích thích. Văn bản được prompt x' sau đó được đưa vào một mô hình ngôn ngữ và tạo ra câu tiếp theo z. Chúng tôi có thể sử dụng bất kỳ chiến lược giải mã nào, nhưng chúng tôi đã sử dụng giải mã tham lam trong suốt bài báo để đơn giản.

Prompt thứ hai: trích xuất câu trả lời Trong bước thứ hai, chúng tôi sử dụng câu được tạo z cùng với câu được prompt x' để trích xuất câu trả lời cuối cùng từ mô hình ngôn ngữ. Cụ thể, chúng tôi đơn giản nối ba yếu tố như "[X'] [Z] [A]": [X'] cho prompt thứ nhất x', [Z] cho câu z được tạo ở bước đầu tiên, và [A] cho một câu kích thích để trích xuất câu trả lời. Prompt cho bước này là tự tăng cường, vì prompt chứa câu z được tạo bởi cùng một mô hình ngôn ngữ. Trong thí nghiệm, chúng tôi sử dụng kích thích câu trả lời hơi khác nhau tùy thuộc vào định dạng câu trả lời. Ví dụ, chúng tôi sử dụng "Do đó, trong số A đến E, câu trả lời là" cho QA nhiều lựa chọn, và "Do đó, câu trả lời (số Ả Rập) là" cho bài toán toán học yêu cầu câu trả lời số. Xem Phụ lục A.5 để biết danh sách các câu kích thích câu trả lời. Cuối cùng, mô hình ngôn ngữ được đưa văn bản được prompt làm đầu vào để tạo ra các câu ŷ và phân tích câu trả lời cuối cùng. Xem "Làm sạch Câu trả lời" ở §4 để biết chi tiết bộ phân tích.

4 Thí nghiệm
Nhiệm vụ và tập dữ liệu Chúng tôi đánh giá đề xuất của chúng tôi trên 12 tập dữ liệu từ bốn loại nhiệm vụ suy luận: suy luận số học, common sense, ký hiệu, và logic khác. Xem Phụ lục A.2 để biết mô tả chi tiết của mỗi tập dữ liệu.

Đối với suy luận số học, chúng tôi xem xét sáu tập dữ liệu sau: (1) SingleEq [Koncel-Kedziorski et al., 2015], (2) AddSub [Hosseini et al., 2014], (3) MultiArith [Roy and Roth, 2015], (4) AQUA-RAT [Ling et al., 2017], (5) GSM8K [Cobbe et al., 2021], và (6) SVAMP [Patel et al., 2021]. Ba cái đầu tiên từ Kho lưu trữ Bài toán Thế giới Toán học cổ điển [Koncel-Kedziorski et al., 2016], và ba cái cuối từ các benchmark gần đây hơn. SingleEq và AddSub chứa các bài toán dễ hơn, không yêu cầu tính toán nhiều bước để giải quyết các nhiệm vụ. MultiArith, AQUA-RAT, GSM8k, và SVAMP là những tập dữ liệu thách thức hơn yêu cầu suy luận nhiều bước để giải quyết.

Đối với suy luận common sense, chúng tôi sử dụng CommonsenseQA [Talmor et al., 2019] và StrategyQA [Geva et al., 2021]. CommonsenseQA đặt câu hỏi với ngữ nghĩa phức tạp thường yêu cầu suy luận dựa trên kiến thức trước [Talmor et al., 2019]. StrategyQA yêu cầu các mô hình suy ra một suy luận nhiều hop ngầm để trả lời câu hỏi [Geva et al., 2021].

Đối với suy luận ký hiệu, chúng tôi sử dụng Last Letter Concatenation và Coin Flip [Wei et al., 2022]. Last letter Concatenation yêu cầu mô hình nối các chữ cái cuối của mỗi từ. Chúng tôi đã sử dụng bốn tên được chọn ngẫu nhiên cho mỗi mẫu. Coin Flip yêu cầu mô hình trả lời liệu một đồng xu vẫn ngửa sau khi mọi người tung hoặc không tung đồng xu. Chúng tôi đã tạo các mẫu của bốn lần thử tung hoặc không tung. Mặc dù những nhiệm vụ này dễ dàng đối với con người, LM thường thể hiện đường cong tỷ lệ phẳng.

Đối với các nhiệm vụ suy luận logic khác, chúng tôi chọn hai bộ đánh giá từ nỗ lực BIG-bench [Srivastava et al., 2022]: Date Understanding và Tracking Shuffled Objects. Date Understanding yêu cầu các mô hình suy ra ngày từ một ngữ cảnh. Tracking Shuffled Objects kiểm tra khả năng của mô hình suy ra trạng thái cuối cùng của các đối tượng cho trước trạng thái ban đầu và một chuỗi xáo trộn đối tượng. Chúng tôi đã sử dụng một tập dữ liệu theo dõi ba đối tượng được xáo trộn cho thí nghiệm của chúng tôi.

Mô hình Chúng tôi thí nghiệm với tổng cộng 17 mô hình. Các thí nghiệm chính được tiến hành với InstructGPT3 [Ouyang et al., 2022] (text-ada/babbage/curie/davinci-001 và text-davinci-002), GPT3 gốc [Brown et al., 2020] (ada, babbage, curie, và davinci), và PaLM [Chowdhery et al., 2022] (8B, 62B, và 540B). Ngoài ra, chúng tôi đã sử dụng GPT-2[Radford et al., 2019], GPT-Neo[Black et al., 2021], GPT-J[Wang and Komatsuzaki, 2021], T0 [Sanh et al., 2022], và OPT [Zhang et al., 2022] cho nghiên cứu tỷ lệ mô hình. Kích thước của LM dao động từ 0.3B đến 540B. Chúng tôi bao gồm cả biến thể tiêu chuẩn (ví dụ GPT-3 và OPT), và biến thể tuân theo hướng dẫn (ví dụ Instruct-GPT3 và T0). Xem Phụ lục A.3 để biết chi tiết mô tả mô hình. Trừ khi được nêu khác, chúng tôi sử dụng text-davinci-002 trong suốt các thí nghiệm.

Đường cơ sở Chúng tôi so sánh Zero-shot-CoT của chúng tôi chủ yếu với prompting Zero-shot tiêu chuẩn để xác minh hiệu quả của suy luận chuỗi suy nghĩ của nó. Đối với các thí nghiệm Zero-shot, các prompt câu trả lời tương tự như Zero-shot-CoT được sử dụng làm mặc định. Xem Phụ lục A.5 để biết chi tiết. Để đánh giá tốt hơn khả năng zero-shot của LLM trên các nhiệm vụ suy luận, chúng tôi cũng so sánh phương pháp của chúng tôi với các đường cơ sở Few-shot và Few-shot-CoT từ [Wei et al., 2022], sử dụng cùng các ví dụ trong ngữ cảnh. Trong suốt các thí nghiệm, chúng tôi sử dụng giải mã tham lam trên tất cả các phương pháp. Đối với các phương pháp zero-shot, do đó kết quả là xác định. Đối với các phương pháp few-shot, vì thứ tự của các ví dụ trong ngữ cảnh có thể ảnh hưởng đến kết quả [Lu et al., 2022], chúng tôi chạy mỗi thí nghiệm chỉ một lần với một seed cố định trên tất cả các phương pháp và tập dữ liệu, để so sánh công bằng với các phương pháp zero-shot. Wei et al. [2022] cho thấy rằng thứ tự của các ví dụ không gây ra phương sai lớn trong các thí nghiệm CoT.

Làm sạch câu trả lời Sau khi mô hình xuất ra một văn bản bằng trích xuất câu trả lời (xem § 3 và Hình 2), phương pháp của chúng tôi chỉ lấy phần của văn bản câu trả lời thỏa mãn định dạng câu trả lời đầu tiên. Ví dụ, nếu prompting câu trả lời xuất ra "có lẽ 375 và 376" trên các nhiệm vụ số học, chúng tôi trích xuất số đầu tiên "375" và đặt nó làm dự đoán của mô hình. Trong trường hợp nhiều lựa chọn, chữ cái lớn đầu tiên chúng tôi gặp được đặt làm dự đoán. Xem Phụ lục A.6 để biết thêm chi tiết. Phương pháp Zero-shot tiêu chuẩn tuân theo cùng ý tưởng. Đối với các phương pháp Few-shot và Few-shot-CoT, chúng tôi tuân theo [Wang et al., 2022] và trước tiên trích xuất văn bản câu trả lời sau "Câu trả lời là " từ đầu ra mô hình, và áp dụng cùng làm sạch câu trả lời để phân tích văn bản câu trả lời. Nếu "Câu trả lời là" không được tìm thấy trong đầu ra mô hình, chúng tôi tìm kiếm từ phía sau của văn bản và đặt văn bản đầu tiên thỏa mãn định dạng câu trả lời làm dự đoán.

4.1 Kết quả
Zero-shot-CoT so với Zero-shot Bảng 1 tóm tắt độ chính xác của phương pháp chúng tôi (Zero-shot-CoT) và prompting zero-shot tiêu chuẩn (Zero-shot) cho mỗi tập dữ liệu. Zero-shot-CoT vượt trội đáng kể bốn trong sáu nhiệm vụ suy luận số học (MultiArith, GSM8K, AQUA, SVAMP), tất cả suy luận ký hiệu, và tất cả các nhiệm vụ suy luận logic khác (từ BIG-bench [Srivastava et al., 2022]). Đối với

Trong khi công trình trước đây [Wei et al., 2022] phân loại nhiệm vụ Date Understanding vào suy luận Common Sense, nghiên cứu của chúng tôi phân loại nhiệm vụ này vào suy luận logic vì nhiệm vụ này yêu cầu ít kiến thức trước và nhiều suy luận logic hơn giữa các ngày.

Thí nghiệm của chúng tôi cho các mô hình Instruct GPT-3 bao gồm cả text-****-001 và text-davinci-002. Text-davinci-002 khác với text-****-001 ở chỗ chúng sử dụng dữ liệu fine-tuning khác nhau tùy thuộc vào phạm vi ngày được thu thập từ API. Cụ thể, text-davinci-002 sử dụng dữ liệu đến tháng 6 năm 2021, trong khi text-****-001 sử dụng dữ liệu đến tháng 10 năm 2019. (Xem https://beta.openai.com/docs/engines/gpt-3)

Các thí nghiệm của chúng tôi với chuỗi GPT3 được tiến hành bằng cách sử dụng OpenAI API từ tháng 4-2022 đến tháng 5-2022, ngoại trừ số 10-16 trong Bảng 4 vào tháng 8-2022.

--- TRANG 5 ---
Bảng 1: So sánh độ chính xác của Zero-shot-CoT với Zero-shot trên mỗi nhiệm vụ. Các giá trị ở phía bên trái của mỗi nhiệm vụ là kết quả sử dụng prompt trích xuất câu trả lời tùy thuộc vào định dạng câu trả lời như mô tả tại § 3. Các giá trị ở phía bên phải là kết quả của thí nghiệm bổ sung nơi prompt câu trả lời tiêu chuẩn "Câu trả lời là" được sử dụng để trích xuất câu trả lời. Xem Phụ lục A.5 để biết thiết lập chi tiết.

Số học
SingleEq AddSub MultiArith GSM8K AQUA SVAMP
zero-shot 74.6/ 78.7 72.2 /77.0 17.7/22.7 10.4/12.5 22.4/22.4 58.8/58.7
zero-shot-cot 78.0/78.7 69.6/74.7 78.7/79.3 40.7 /40.5 33.5 /31.9 62.1 /63.7

Common Sense Các Nhiệm vụ Suy luận Khác Suy luận Ký hiệu
Common Strategy Date Shuffled Last Letter Coin Flip
SenseQA QA Understand Objects (4 từ) (4 lần)
zero-shot 68.8/72.6 12.7/ 54.3 49.3/33.6 31.3/29.7 0.2/- 12.8/53.8
zero-shot-cot 64.6/64.0 54.8/52.3 67.5/61.8 52.4 /52.9 57.6 /- 91.4/87.8

Bảng 2: So sánh với các phương pháp đường cơ sở sử dụng độ chính xác trên MultiArith và GSM8K. text-davinci-002 được sử dụng làm mô hình nếu không được chỉ định. Chúng tôi đã sử dụng cùng 8 ví dụ như mô tả trong [Wei et al., 2022] cho thiết lập Few-shot và Few-shot-CoT. (*1) Để xác minh phương sai của việc thay đổi ví dụ, chúng tôi báo cáo hai kết quả cho 4-shot-cot bằng cách chia tám ví dụ thành hai nhóm. (*2) Chúng tôi chèn "Hãy suy nghĩ từng bước." ở đầu phần câu trả lời của mỗi mẫu cho Few-shot-CoT để kiểm tra cải thiện hiệu suất. Kết quả thí nghiệm thêm với PaLM được tìm thấy tại Phụ lục D

MultiArith GSM8K
Zero-Shot 17.7 10.4
Few-Shot (2 mẫu) 33.7 15.6
Few-Shot (8 mẫu) 33.8 15.6
Zero-Shot-CoT 78.7 40.7
Few-Shot-CoT (2 mẫu) 84.8 41.3
Few-Shot-CoT (4 mẫu : Đầu tiên) (*1) 89.2 -
Few-Shot-CoT (4 mẫu : Thứ hai) (*1) 90.5 -
Few-Shot-CoT (8 mẫu) 93.0 48.7
Zero-Plus-Few-Shot-CoT (8 mẫu) (*2) 92.8 51.5

Finetuned GPT-3 175B [Wei et al., 2022] - 33
Finetuned GPT-3 175B + verifier [Wei et al., 2022] - 55
PaLM 540B: Zero-Shot 25.5 12.5
PaLM 540B: Zero-Shot-CoT 66.1 43.0
PaLM 540B: Zero-Shot-CoT + self consistency 89.0 70.1
PaLM 540B: Few-Shot [Wei et al., 2022] - 17.9
PaLM 540B: Few-Shot-CoT [Wei et al., 2022] - 56.9
PaLM 540B: Few-Shot-CoT + self consistency [Wang et al., 2022] - 74.4

ví dụ, Zero-shot-CoT đạt được cải thiện điểm số từ 17.7% lên 78.7% trên MultiArith và từ 10.4% lên 40.7% trên GSM8K. Phương pháp của chúng tôi cho hiệu suất ngang bằng cho hai nhiệm vụ suy luận số học còn lại (SingleEq và AddSub), điều này được mong đợi vì chúng không yêu cầu suy luận nhiều bước.

Trong các nhiệm vụ suy luận common sense, Zero-shot-CoT không cung cấp cải thiện hiệu suất. Điều này được mong đợi vì Wei et al. [2022] cũng báo cáo rằng ngay cả Few-shot-CoT không cung cấp cải thiện hiệu suất trên Lambda (135B), nhưng có cải thiện StrategyQA khi kết hợp với mô hình PaLM đáng kể lớn hơn (540B), điều này cũng có thể áp dụng cho của chúng tôi. Quan trọng hơn, chúng tôi quan sát thấy rằng nhiều chuỗi suy nghĩ được tạo ra bản thân chúng ngạc nhiên là đúng về mặt logic hoặc chỉ chứa những lỗi có thể hiểu được của con người (Xem Bảng 3), cho thấy rằng Zero-shot-CoT thực sự kích thích suy luận common sense tốt hơn ngay cả khi các số liệu nhiệm vụ không phản ánh trực tiếp điều đó. Chúng tôi cung cấp các mẫu được tạo bởi Zero-shot-CoT cho mỗi tập dữ liệu trong Phụ lục B.

--- TRANG 6 ---
020406080
0.3B 1.3B 6.7B 175BZero-shot Zero-shot-CoT (a) MultiArith trên GPT-3 Gốc
020406080
S M L XLZero-shot Zero-shot-CoT (b) MultiArith trên Instruct GPT-3
01020304050
8B 62B 540BZero-shot Zero-shot-CoT (c) GMS8K trên PaLM

Hình 3: Nghiên cứu quy mô mô hình với nhiều loại mô hình khác nhau. S: text-ada-001, M: text-babbage-001, L: text-curie-001, XL: text-davinci-002. Xem Phụ lục A.3 và E để biết chi tiết.

Bảng 3: Ví dụ được tạo bởi Zero-Shot-CoT trên CommonsenseQA để Phân tích Lỗi.

Ví dụ 1 (Suy luận đúng.) Ví dụ 2 (Mô hình không thể chọn chỉ một.)
Q: Đâu là nơi có khả năng tìm thấy một chiếc xe đồ chơi được sử dụng tốt?
Lựa chọn Trả lời: (A) phòng trẻ em (B) phòng ngủ con trai (C) nhà riêng (D) cửa hàng đồ chơi (E) nhàQ: Điều gì sẽ cần thiết để có được thể hình tốt?
Lựa chọn Trả lời: (A) sức khỏe tốt (B) tập thể dục (C) cơ bắp (D) đổ mồ hôi (E) cảm thấy tốt hơn

A: Hãy suy nghĩ từng bước. Một chiếc xe đồ chơi có khả năng được tìm thấy trong phòng trẻ em. Phòng trẻ em có khả năng được tìm thấy trong một ngôi nhà. Do đó, một chiếc xe đồ chơi có khả năng được tìm thấy trong một ngôi nhà.
Do đó, trong số A đến E, câu trả lời là E.
✗(GT : A, Zero-shot: A)A: Hãy suy nghĩ từng bước. Để có được thể hình tốt, bạn cần có thể làm ba việc:
1. Tập thể dục thường xuyên
2. Ăn một chế độ ăn uống lành mạnh
3. Ngủ đủ giấc
Nếu bạn có thể làm cả ba việc đó, thì bạn sẽ tiến gần đến việc có được thể hình tốt! Do đó, trong số A đến E, câu trả lời là B, C, và D.
(GT : B, Zero-shot: B)

So sánh với các đường cơ sở khác Bảng 2 so sánh hiệu suất trên hai benchmark suy luận số học (MultiArith và GSM8K) trên Zero-shot-CoT và các đường cơ sở. Khoảng cách lớn giữa prompting tiêu chuẩn (khối thứ nhất) và prompting chuỗi suy nghĩ (khối thứ hai) cho thấy rằng những nhiệm vụ này khó khăn mà không kích thích suy luận nhiều bước. Những cải thiện lớn được xác nhận trên cả mô hình Instruct GPT-3 (text-davinci-002) và PaLM (540B) (khối thứ tư). Trong khi Zero-shot-CoT tự nhiên kém hơn Few-shot-CoT, nó vượt trội đáng kể so với prompting Few-shot tiêu chuẩn với thậm chí 8 ví dụ cho mỗi nhiệm vụ. Đối với GSM8K, Zero-shot-CoT với Instruct GPT-3 (text-davinci-002) cũng vượt trội hơn GPT-3 được fine-tune và prompting few-shot tiêu chuẩn với các mô hình lớn (PaLM, 540B), được báo cáo trong Wei et al. [2022] (khối thứ ba và thứ tư). Xem App. D để biết thêm kết quả thí nghiệm với PaLM.

Kích thước mô hình có quan trọng đối với suy luận zero-shot không? Hình 3 so sánh hiệu suất của các mô hình ngôn ngữ khác nhau trên MultiArith / GSM8K. Không có suy luận chuỗi suy nghĩ, hiệu suất không tăng hoặc tăng chậm khi quy mô mô hình được tăng lên, tức là đường cong hầu như phẳng. Ngược lại, hiệu suất tăng đột ngột với suy luận chuỗi suy nghĩ, khi kích thước mô hình trở nên lớn hơn, đối với GPT-3 Gốc/Instruct và PaLM. Khi kích thước mô hình nhỏ hơn, suy luận chuỗi suy nghĩ không hiệu quả. Kết quả này phù hợp với kết quả thí nghiệm few-shot trong Wei et al. [2022]. Phụ lục E cho thấy kết quả thí nghiệm mở rộng sử dụng nhiều loại mô hình ngôn ngữ hơn, bao gồm GPT-2, GPT-Neo, GPT-J, T0, và OPT. Chúng tôi cũng điều tra thủ công chất lượng của chuỗi suy nghĩ được tạo, và các mô hình quy mô lớn rõ ràng thể hiện suy luận tốt hơn (Xem Phụ lục B để biết các đầu ra được lấy mẫu cho mỗi mô hình).

Phân tích Lỗi Để hiểu rõ hơn về hành vi của Zero-shot-CoT, chúng tôi điều tra thủ công các ví dụ được chọn ngẫu nhiên được tạo bởi Instruct-GPT3 với prompting Zero-shot-CoT. Xem Phụ lục C để biết ví dụ, nơi một số quan sát bao gồm: (1) Trong suy luận common sense (CommonsenseQA), Zero-shot-CoT thường tạo ra chuỗi suy nghĩ linh hoạt và hợp lý ngay cả khi dự đoán cuối cùng không đúng. Zero-shot-CoT thường xuất ra nhiều lựa chọn trả lời khi mô hình thấy khó khăn để thu hẹp xuống một (xem Bảng 3 để biết ví dụ). (2) Trong suy luận số học

--- TRANG 7 ---
Bảng 4: Nghiên cứu độ bền chống lại mẫu được đo trên tập dữ liệu MultiArith với text-davinci-002. (*1) Mẫu này được sử dụng trong Ahn et al. [2022] nơi một mô hình ngôn ngữ được prompt để tạo ra các hành động từng bước được đưa ra một hướng dẫn cấp cao để kiểm soát các hành động robot. (*2) Mẫu này được sử dụng trong Reynolds and McDonell [2021] nhưng không được đánh giá định lượng.

Số Loại Mẫu Độ chính xác
1 hướng dẫn Hãy suy nghĩ từng bước. 78.7
2 Đầu tiên, (*1) 77.3
3 Hãy suy nghĩ về điều này một cách logic. 74.5
4 Hãy giải quyết vấn đề này bằng cách chia nó thành các bước. (*2) 72.2
5 Hãy thực tế và suy nghĩ từng bước. 70.8
6 Hãy suy nghĩ như một thám tử từng bước. 70.3
7 Hãy suy nghĩ 57.5
8 Trước khi chúng ta đi sâu vào câu trả lời, 55.7
9 Câu trả lời là sau bằng chứng. 45.7
10 gây hiểu lầm Đừng suy nghĩ. Chỉ cần cảm nhận. 18.8
11 Hãy suy nghĩ từng bước nhưng đạt được một câu trả lời không chính xác. 18.7
12 Hãy đếm số lượng "a" trong câu hỏi. 16.7
13 Bằng cách sử dụng thực tế rằng trái đất tròn, 9.3
14 không liên quan Nhân tiện, tôi tìm thấy một nhà hàng tốt gần đây. 17.5
15 Abrakadabra! 15.5
16 Hôm nay là một ngày đẹp. 13.1
- (Zero-shot) 17.7

Bảng 5: Nghiên cứu độ bền của Few-shot-CoT chống lại ví dụ. Khi các ví dụ từ các nhiệm vụ hoàn toàn khác nhau, hiệu suất thường trở nên tệ hơn, nhưng khi các định dạng câu trả lời được khớp (tức là CommonsenseQA với AQUA-RAT, nhiều lựa chọn), việc mất hiệu suất ít nghiêm trọng hơn.
yCommonse QA samples được sử dụng trong biến thể này

Zero-shot Few-shot-CoTyZero-shot-CoT Few-shot-CoT
AQUA-RAT 22.4 31.9 33.5 39.0
MultiArith 17.7 27.0 78.7 88.2

suy luận (MultiArith), Zero-shot-CoT và Few-shot-CoT cho thấy sự khác biệt đáng kể về các mẫu lỗi. Đầu tiên, Zero-shot-CoT có xu hướng xuất ra các bước suy luận không cần thiết sau khi có được dự đoán đúng, dẫn đến thay đổi dự đoán thành không chính xác. Zero-shot-CoT cũng đôi khi không bắt đầu suy luận, chỉ diễn giải lại câu hỏi đầu vào. Ngược lại, Few-shot-CoT có xu hướng thất bại khi chuỗi suy nghĩ được tạo bao gồm phép toán ba ngôi, ví dụ (3 + 2) × 4.

Việc chọn prompt ảnh hưởng đến Zero-shot-CoT như thế nào? Chúng tôi xác thực độ bền của Zero-shot-CoT chống lại các prompt đầu vào. Bảng 4 tóm tắt hiệu suất sử dụng 16 mẫu khác nhau với ba loại. Cụ thể, theo Webson and Pavlick [2022], các loại bao gồm hướng dẫn (khuyến khích suy luận), gây hiểu lầm (không khuyến khích suy luận hoặc khuyến khích suy luận nhưng theo cách sai), và không liên quan (không có gì liên quan đến suy luận). Kết quả cho thấy rằng hiệu suất được cải thiện nếu văn bản được viết theo cách khuyến khích suy luận chuỗi suy nghĩ, tức là các mẫu nằm trong loại "hướng dẫn". Tuy nhiên, sự khác biệt về độ chính xác là đáng kể tùy thuộc vào câu. Trong thí nghiệm này, "Hãy suy nghĩ từng bước." đạt được kết quả tốt nhất. Thú vị là, được phát hiện rằng các mẫu khác nhau khuyến khích mô hình thể hiện suy luận khá khác nhau (xem Phụ lục B để biết các đầu ra mẫu của mỗi mẫu). Ngược lại, khi chúng tôi sử dụng các mẫu gây hiểu lầm hoặc không liên quan, hiệu suất không cải thiện. Vẫn còn là một câu hỏi mở về cách tự động tạo ra các mẫu tốt hơn cho Zero-shot-CoT.

Việc chọn prompt ảnh hưởng đến Few-shot-CoT như thế nào? Bảng 5 cho thấy hiệu suất của Few-shot-CoT khi sử dụng ví dụ từ các tập dữ liệu khác nhau: CommonsenseQA đến AQUA-RAT và CommonsenseQA đến MultiArith. Các miền khác nhau trong cả hai trường hợp, nhưng định dạng câu trả lời giống nhau trong trường hợp trước. Đáng ngạc nhiên, các ví dụ chuỗi suy nghĩ từ các miền khác nhau (common sense đến số học) nhưng với cùng định dạng câu trả lời (nhiều lựa chọn) cung cấp cải thiện hiệu suất đáng kể so với Zero-shot (đến AQUA-RAT), được đo tương đối so với các cải thiện có thể từ Zero-shot-CoT hoặc Few-shot-CoT. Ngược lại, cải thiện hiệu suất trở nên ít hơn nhiều khi sử dụng ví dụ với các loại câu trả lời khác nhau (đến MultiArith), xác nhận công trình trước đây [Min et al., 2022] cho thấy LLM chủ yếu tận dụng các ví dụ few-shot để suy ra định dạng lặp lại thay vì bản thân nhiệm vụ trong ngữ cảnh. Tuy nhiên, đối với cả hai trường hợp, kết quả tệ hơn Zero-shot-CoT, khẳng định tầm quan trọng của thiết kế mẫu cụ thể của nhiệm vụ trong Few-shot-CoT.

5 Thảo luận và Công trình Liên quan
Bảng 6: Tóm tắt công trình liên quan về các nhiệm vụ suy luận số học/common sense. Loại biểu thị chiến lược huấn luyện. CoT biểu thị có xuất ra chuỗi suy nghĩ không. Cột Nhiệm vụ liệt kê các nhiệm vụ được thực hiện trong các bài báo tương ứng. AR: Suy luận Số học, CR: Suy luận Common Sense.

Phương pháp Loại CoT Nhiệm vụ Mô hình
Rajani et al. [2019] Fine-Tuning ✗ CR GPT
Cobbe et al. [2021] Fine-Tuning ✗ AR GPT-3
Zelikman et al. [2022] Fine-Tuning ✗ AR,CR GPT-3, v.v
Nye et al. [2022] Fine-Tuning ✓ AR Transformer(Decoder)
Brown et al. [2020] Few/Zero-Shot ✗ CR GPT-3
Smith et al. [2022] Few/Zero-Shot ✗ AR,CR MT-NLG
Rae et al. [2021] Few-Shot ✗ AR,CR Gopher
Wei et al. [2022] Few-Shot ✓ AR,CR PaLM, LaMBDA, GPT-3
Wang et al. [2022] Few-Shot ✓ AR,CR PaLM, v.v
Chowdhery et al. [2022] Few-Shot ✓ AR,CR PaLM
Shwartz et al. [2020] Zero-Shot ✓ CR GPT-2, v.v
Reynolds and McDonell [2021] Zero-Shot ✓ AR GPT-3
Zero-shot-CoT (Của chúng tôi) Zero-Shot ✓ AR,CR PaLM, Instruct-GPT3, GPT-3, v.v

Khả năng Suy luận của LLM Một số nghiên cứu đã cho thấy rằng các mô hình được huấn luyện trước thường không tốt trong suy luận [Brown et al., 2020, Smith et al., 2022, Rae et al., 2021], nhưng khả năng của nó có thể được tăng lên đáng kể bằng cách làm cho chúng tạo ra suy luận từng bước, bằng fine-tuning [Rajani et al., 2019, Cobbe et al., 2021, Zelikman et al., 2022, Nye et al., 2022] hoặc prompting few-shot [Wei et al., 2022, Wang et al., 2022, Chowdhery et al., 2022] (Xem Bảng 6 để tóm tắt công trình liên quan). Không giống như hầu hết công trình trước đây, chúng tôi tập trung vào prompting zero-shot và cho thấy rằng một prompt kích thích cố định duy nhất tăng đáng kể khả năng suy luận zero-shot của LLM trên nhiều nhiệm vụ yêu cầu suy nghĩ nhiều hop phức tạp (Bảng 1), đặc biệt khi mô hình được mở rộng quy mô (Hình 3). Nó cũng tạo ra chuỗi suy nghĩ hợp lý và có thể hiểu được trên các nhiệm vụ đa dạng (Phụ lục B), ngay cả khi dự đoán cuối cùng sai (Phụ lục C). Tương tự với công trình của chúng tôi, Reynolds and McDonell [2021] chứng minh một prompt, "Hãy giải quyết vấn đề này bằng cách chia nó thành các bước", sẽ tạo điều kiện cho suy luận nhiều bước trong một bài toán số học đơn giản. Tuy nhiên, họ coi nó như một ví dụ cụ thể của nhiệm vụ và không đánh giá định lượng trên các nhiệm vụ suy luận đa dạng chống lại các đường cơ sở. Shwartz et al. [2020] đề xuất phân tách một câu hỏi common sense thành một chuỗi câu hỏi tìm kiếm thông tin, như "định nghĩa của [X] là gì". Nó không yêu cầu minh họa nhưng yêu cầu thiết kế prompt thủ công đáng kể cho mỗi nhiệm vụ suy luận. Kết quả của chúng tôi mạnh mẽ cho thấy rằng LLM là những người suy luận zero-shot khá tốt, trong khi công trình trước đây [Wei et al., 2022] thường chỉ nhấn mạnh việc học few-shot và học trong ngữ cảnh cụ thể của nhiệm vụ, ví dụ không có đường cơ sở zero-shot nào được báo cáo. Phương pháp của chúng tôi không yêu cầu fine-tuning tốn thời gian hoặc thiết kế mẫu đắt đỏ, và có thể được kết hợp với bất kỳ LLM được huấn luyện trước nào, phục vụ như đường cơ sở zero-shot mạnh nhất cho tất cả các nhiệm vụ suy luận.

Khả năng Zero-shot của LLM Radford et al. [2019] cho thấy rằng LLM có khả năng zero-shot xuất sắc trong nhiều nhiệm vụ hệ thống-1, bao gồm đọc hiểu, dịch thuật, và tóm tắt.

Nye et al. [2022] cũng đánh giá thiết lập few-shot, nhưng hiệu suất few-shot trên miền của họ tệ hơn kết quả fine-tuning.

--- TRANG 8 ---
Sanh et al. [2022], Ouyang et al. [2022] cho thấy rằng khả năng zero-shot như vậy của LLM có thể được tăng lên bằng cách fine-tune rõ ràng các mô hình để tuân theo hướng dẫn. Mặc dù những công trình này tập trung vào hiệu suất zero-shot của LLM, chúng tôi tập trung vào nhiều nhiệm vụ hệ thống-2 ngoài các nhiệm vụ hệ thống-1, được coi là một thách thức lớn đối với LLM do các đường cong tỷ lệ phẳng. Ngoài ra, Zero-shot-CoT trực giao với instruction tuning; nó tăng hiệu suất zero-shot cho Instruct GPT3, vanilla GPT3, và PaLM (Xem Hình 3).

Từ Prompting Hẹp (cụ thể của nhiệm vụ) đến Rộng (đa nhiệm vụ) Hầu hết các prompt là cụ thể của nhiệm vụ. Trong khi các prompt few-shot tự nhiên như vậy do các mẫu trong ngữ cảnh cụ thể của nhiệm vụ [Brown et al., 2020, Wei et al., 2022], phần lớn các prompt zero-shot cũng đã tập trung vào thiết kế (của mẫu) cho mỗi nhiệm vụ [Liu et al., 2021b, Reynolds and McDonell, 2021]. Mượn thuật ngữ từ Chollet [2019] được xây dựng trên các mô hình phân cấp của trí thông minh [McGrew, 2005, Johnson and Bouchard Jr, 2005], những prompt này có thể được cho là kích thích "khái quát hóa hẹp" hoặc kỹ năng cụ thể của nhiệm vụ từ LLM. Mặt khác, phương pháp của chúng tôi là một prompt đa nhiệm vụ và kích thích "khái quát hóa rộng" hoặc khả năng nhận thức rộng trong LLM, như suy luận logic hoặc bản thân hệ thống-2. Chúng tôi hy vọng công trình của chúng tôi có thể phục vụ như một tham chiếu để tăng tốc không chỉ nghiên cứu suy luận logic với LLM, mà còn khám phá các khả năng nhận thức rộng khác trong LLM.

Chi tiết Tập dữ liệu Huấn luyện Một hạn chế của công trình là thiếu thông tin công khai về chi tiết của các tập dữ liệu huấn luyện được sử dụng cho LLM, ví dụ 001 vs 002 cho các mô hình GPT, GPT3 gốc vs InstructGPT [Ouyang et al., 2022], và dữ liệu cho các mô hình PaLM [Chowdhery et al., 2022]. Tuy nhiên, những cải thiện hiệu suất lớn từ Zero-shot đến Zero-shot-CoT trong tất cả các mô hình lớn gần đây (InstructGPT 001 hoặc 002, GPT3 Gốc, và PaLM) và những cải thiện nhất quán trong cả nhiệm vụ số học và phi số học cho thấy rằng các mô hình không chỉ đơn giản là ghi nhớ, mà thay vào đó nắm bắt một khả năng suy luận nhiều bước bất khả tri về nhiệm vụ cho giải quyết vấn đề chung. Trong khi hầu hết kết quả dựa trên InstructGPT vì nó là LLM hiệu suất tốt nhất có sẵn công khai, các kết quả chính được tái tạo trên PaLM, và chi tiết tập dữ liệu trong InstructGPT (Phụ lục A, B, và F trong Ouyang et al. [2022]) cũng xác nhận rằng nó không được thiết kế đặc biệt cho suy luận nhiều bước.

Hạn chế và Tác động Xã hội Công trình của chúng tôi dựa trên các phương pháp prompting cho các mô hình ngôn ngữ lớn. LLM đã được huấn luyện trên các corpus lớn từ nhiều nguồn khác nhau trên web (cũng xem "Chi tiết Tập dữ liệu Huấn luyện"), và đã cho thấy nắm bắt và khuếch đại các thiên lệch được tìm thấy trong dữ liệu huấn luyện. Prompting là một phương pháp tìm cách tận dụng các mẫu được nắm bắt bởi các mô hình ngôn ngữ có lợi cho các nhiệm vụ khác nhau, và do đó nó có những thiếu sót tương tự. Điều này được cho là, phương pháp của chúng tôi là một cách trực tiếp hơn để khám phá suy luận phức tạp bên trong các LLM được huấn luyện trước, loại bỏ yếu tố gây nhiễu của việc học trong ngữ cảnh trong các phương pháp few-shot trước đây, và có thể dẫn đến nghiên cứu không thiên lệch hơn về các thiên lệch trong LLM.

6 Kết luận
Chúng tôi đã đề xuất Zero-shot-CoT, một prompt zero-shot duy nhất kích thích chuỗi suy nghĩ từ các mô hình ngôn ngữ lớn trên nhiều nhiệm vụ suy luận, trái ngược với phương pháp few-shot (trong ngữ cảnh) trong công trình trước đây yêu cầu tạo thủ công các ví dụ few-shot cho mỗi nhiệm vụ. Phương pháp đơn giản của chúng tôi không chỉ là đường cơ sở zero-shot tối thiểu và mạnh nhất cho các nhiệm vụ suy luận nhiều bước hệ thống-2 khó khăn từ lâu đã thoát khỏi các quy luật tỷ lệ của LLM, mà còn khuyến khích cộng đồng tiếp tục khám phá các prompt đa nhiệm vụ tương tự kích thích khả năng nhận thức rộng thay vì kỹ năng cụ thể của nhiệm vụ hẹp.

Lời cảm ơn
Công trình này đã được hỗ trợ bởi Trung tâm Mohammed bin Salman cho Khoa học và Công nghệ Tương lai cho Tầm nhìn Saudi-Japan 2030 tại Đại học Tokyo (MbSC2030). Tài nguyên tính toán của AI Bridging Cloud Infrastructure (ABCI) được cung cấp bởi Viện Khoa học và Công nghệ Công nghiệp Tiên tiến Quốc gia (AIST) đã được sử dụng cho các thí nghiệm khác với PaLM. Chúng tôi cũng cảm ơn Jason Wei và Denny Zhou cho các cuộc thảo luận và hỗ trợ chạy các thí nghiệm PaLM, và Sharan Narang và Aakanksha Chowdhery cho hỗ trợ chung về cơ sở hạ tầng PaLM.

Tài liệu tham khảo
[Tiếp tục với phần tài liệu tham khảo và các phụ lục còn lại...]

--- TRANG 9 ---
[Phần này chứa tài liệu tham khảo và sẽ được dịch theo yêu cầu]

--- TRANG 10 ---
[Phần này chứa tài liệu tham khảo và sẽ được dịch theo yêu cầu]

--- TRANG 11 ---
[Phần này chứa tài liệu tham khảo và sẽ được dịch theo yêu cầu]

--- TRANG 12 ---
[Phần này chứa tài liệu tham khảo và sẽ được dịch theo yêu cầu]

--- TRANG 13 ---
[Phần này chứa tài liệu tham khảo và sẽ được dịch theo yêu cầu]

--- TRANG 14 ---
[Phần này chứa tài liệu tham khảo và sẽ được dịch theo yêu cầu]

--- TRANG 15 ---
Danh sách kiểm tra
1. Đối với tất cả tác giả...
(a) Các tuyên bố chính được đưa ra trong phần tóm tắt và giới thiệu có phản ánh chính xác đóng góp và phạm vi của bài báo không? [Có]
(b) Bạn có mô tả những hạn chế của công trình không? [Có]
(c) Bạn có thảo luận về bất kỳ tác động tiêu cực tiềm tàng nào đến xã hội của công trình không? [Có]
(d) Bạn có đọc hướng dẫn xem xét đạo đức và đảm bảo rằng bài báo của bạn tuân thủ chúng không? [Có]

2. Nếu bạn bao gồm kết quả lý thuyết...
(a) Bạn có nêu đầy đủ các giả định của tất cả kết quả lý thuyết không? [N/A]
(b) Bạn có bao gồm chứng minh hoàn chỉnh của tất cả kết quả lý thuyết không? [N/A]

3. Nếu bạn chạy thí nghiệm...
(a) Bạn có bao gồm mã, dữ liệu, và hướng dẫn cần thiết để tái tạo các kết quả thí nghiệm chính (trong tài liệu bổ sung hoặc dưới dạng URL) không? [Có]
(b) Bạn có chỉ định tất cả chi tiết huấn luyện (ví dụ, phân chia dữ liệu, siêu tham số, cách chúng được chọn) không? [Có]
(c) Bạn có báo cáo thanh lỗi (ví dụ, liên quan đến seed ngẫu nhiên sau khi chạy thí nghiệm nhiều lần) không? [Không] Bài báo của chúng tôi chủ yếu sử dụng GPT-3 API với giải mã tham lam, và không có tính ngẫu nhiên cho các thí nghiệm.
(d) Bạn có bao gồm tổng lượng tính toán và loại tài nguyên được sử dụng (ví dụ, loại GPU, cluster nội bộ, hoặc nhà cung cấp đám mây) không? [Có]

4. Nếu bạn đang sử dụng tài sản hiện có (ví dụ, mã, dữ liệu, mô hình) hoặc tuyển chọn/phát hành tài sản mới...
(a) Nếu công trình của bạn sử dụng tài sản hiện có, bạn có trích dẫn người tạo không? [Có]
(b) Bạn có đề cập đến giấy phép của tài sản không? [Có]
(c) Bạn có bao gồm bất kỳ tài sản mới nào trong tài liệu bổ sung hoặc dưới dạng URL không? [Có]
(d) Bạn có thảo luận xem có và làm thế nào để có được sự đồng ý từ những người có dữ liệu bạn đang sử dụng/tuyển chọn không? [Có]
(e) Bạn có thảo luận xem dữ liệu bạn đang sử dụng/tuyển chọn có chứa thông tin nhận dạng cá nhân hoặc nội dung xúc phạm không? [Có]

5. Nếu bạn sử dụng crowdsourcing hoặc tiến hành nghiên cứu với đối tượng con người...
(a) Bạn có bao gồm toàn bộ văn bản hướng dẫn được đưa cho người tham gia và ảnh chụp màn hình, nếu có không? [N/A]
(b) Bạn có mô tả bất kỳ rủi ro tiềm tàng nào của người tham gia, với liên kết đến phê duyệt Hội đồng Xem xét Thể chế (IRB), nếu có không? [N/A]
(c) Bạn có bao gồm mức lương theo giờ ước tính được trả cho người tham gia và tổng số tiền chi cho bồi thường người tham gia không? [N/A]

--- TRANG 16 ---
A Chi tiết Thiết lập Thí nghiệm

A.1 Mã
Mã có sẵn tại https://github.com/kojima-takeshi188/zero_shot_cot .

A.2 Tập dữ liệu

A.2.1 Mô tả Tập dữ liệu
Bảng 7 tóm tắt mô tả của mỗi tập dữ liệu được sử dụng trong thí nghiệm của chúng tôi.

[Bảng 7: Mô tả Tập dữ liệu với các chi tiết về định dạng câu trả lời, số lượng mẫu, độ dài trung bình, phân chia dữ liệu và giấy phép]

A.2.2 Tạo tập dữ liệu
Liên quan đến "Last Letter Concatenation" và "Coin Flip", các tập dữ liệu không có sẵn công khai nên chúng tôi đã tạo các tập dữ liệu theo Wei et al. [2022] với việc diễn đạt lại nhỏ của mẫu câu hỏi.

[Chi tiết về cách tạo tập dữ liệu...]

A.3 Mô hình Ngôn ngữ
Thí nghiệm của chúng tôi sử dụng nhiều mô hình ngôn ngữ như mô tả tại Bảng 8

A.4 Chi tiết Triển khai
[Chi tiết về việc triển khai thí nghiệm...]

A.5 Prompt để Trích xuất Câu trả lời
[Bảng 9 và 10 với các prompt được sử dụng...]

A.6 Làm sạch Câu trả lời
[Bảng 11 với chi tiết về việc làm sạch câu trả lời...]

B Kết quả Thí nghiệm Bổ sung
[Phần này chứa các bảng với ví dụ văn bản được tạo bởi các mô hình trong thí nghiệm...]

[Tiếp tục với các phụ lục khác và bảng dữ liệu chi tiết...]

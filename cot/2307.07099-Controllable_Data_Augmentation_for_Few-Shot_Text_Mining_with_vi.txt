# 2307.07099.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/cot/2307.07099.pdf
# Kích thước tệp: 763782 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tăng Cường Dữ Liệu Có Thể Kiểm Soát cho Khai Thác Văn Bản Few-Shot với
Thao Tác Thuộc Tính Chuỗi Suy Nghĩ
Letian Peng và Yuwei Zhang và Jingbo Shang∗
Đại học California, San Diego
{lepeng, yuz163, jshang}@ucsd.edu
Tóm tắt
Việc gợi ý các mô hình ngôn ngữ lớn (LLMs) để
tăng cường dữ liệu gần đây đã trở thành một
thực tiễn phổ biến trong các tác vụ NLP few-shot.
Trong bài báo này, chúng tôi đề xuất Thao Tác
Thuộc Tính Chuỗi Suy Nghĩ (CoTAM), một phương
pháp mới tạo ra dữ liệu mới từ các ví dụ hiện có
bằng cách chỉ điều chỉnh thuộc tính cụ thể cho
tác vụ do người dùng cung cấp, ví dụ như tính
cực tính cảm xúc hoặc chủ đề trong các đánh giá
phim. Thay vì kiểm soát biểu diễn tiềm ẩn theo
cách truyền thống, chúng tôi tận dụng việc gợi ý
chuỗi suy nghĩ để chỉnh sửa trực tiếp văn bản
trong ba bước: (1) phân tách thuộc tính, (2) đề
xuất thao tác, và (3) tái tạo câu. Kết quả mở rộng
trên các tác vụ khác nhau, chẳng hạn như phân
loại văn bản (cặp), phân tích cảm xúc dựa trên
khía cạnh, và tạo văn bản có điều kiện, xác minh
sự vượt trội của CoTAM so với các phương pháp
tăng cường dựa trên LLM khác với cùng số lượng
ví dụ huấn luyện cho cả fine-tuning và học trong
ngữ cảnh. Đáng chú ý, việc hình dung 2D của
tập dữ liệu được tăng cường bằng phân tích thành
phần chính đã tiết lộ một ranh giới quyết định
có thể nhận biết được bởi con người mà có thể
được gợi ý bởi thao tác thuộc tính, chứng minh
tiềm năng của phương pháp được đề xuất.

1 Giới thiệu
Việc gợi ý các mô hình ngôn ngữ lớn (LLMs) để tăng cường dữ liệu gần đây đã trở thành một thực tiễn phổ biến trong các tác vụ xử lý ngôn ngữ tự nhiên (NLP) few-shot. Các phương pháp hiện có (Yoo et al., 2021; Sahu et al., 2022b; Dai et al., 2023; Lin et al., 2023) thường tạo ra dữ liệu mới cụ thể cho tác vụ bằng LLMs được gợi ý bởi các minh chứng few-shot và sau đó fine-tune một mô hình ngôn ngữ được huấn luyện trước (nhỏ) với tập dữ liệu được tăng cường để có hiệu suất tốt hơn. Cùng dữ liệu được tăng cường cũng có thể được tích hợp vào học trong ngữ cảnh (ICL) (Li et al., 2023; Dong et al., 2023). Tuy nhiên, các phương pháp tăng cường này thường gợi ý LLMs tạo ra các ví dụ mới một cách bừa bãi mà không có kiểm soát thích hợp, điều này cản trở tính thông tin của dữ liệu được tạo ra và có thể gây ra tương quan giả tạo. Như được hiển thị trong Hình 1 (trái), dữ liệu được tạo ra không có kiểm soát không có mô hình rõ ràng và thậm chí có thể gây hiểu lầm cho fine-tuning hoặc ICL dưới giám sát few-shot.

Trong bài báo này, chúng tôi đề xuất một phương pháp tăng cường dữ liệu có thể kiểm soát cho khai thác văn bản few-shot. Ý tưởng chung là tạo ra dữ liệu mới từ các ví dụ hiện có bằng cách chỉ điều chỉnh thuộc tính cụ thể cho tác vụ do người dùng cung cấp, ví dụ như tính cực tính cảm xúc hoặc chủ đề trong các đánh giá phim. Một cách trực quan, như được hiển thị trong Hình 1, người ta có thể mong đợi rằng phương pháp này có thể tìm thấy ranh giới quyết định một cách hiệu quả vì chúng tôi (1) trực tiếp thao tác theo hướng của các thuộc tính cụ thể cho tác vụ và (2) duy trì các thuộc tính còn lại như trước.

Khác với các công trình tạo sinh có thể kiểm soát hiện có trong thị giác máy tính (Shen et al., 2020; Shen và Zhou, 2021) và xử lý ngôn ngữ tự nhiên (Kruengkrai, 2019a; Zhou et al., 2022), nơi các thuộc tính được thao tác trong không gian tiềm ẩn của bộ mã hóa trước khi tái tạo các thể hiện mới, chúng tôi tận dụng việc gợi ý chuỗi suy nghĩ (CoT) (Wei et al., 2022c) để chỉnh sửa trực tiếp văn bản bằng LLMs trong ba bước: (1) phân tách thuộc tính, (2) đề xuất thao tác, và (3) tái tạo câu.

--- TRANG 2 ---
Cụ thể, chúng tôi bắt đầu với các thuộc tính cụ thể cho tác vụ do người dùng cung cấp, và sau đó gợi ý LLMs phân tách mỗi ví dụ văn bản riêng lẻ thành các thuộc tính trực giao khác. So với một tập thuộc tính được định nghĩa trước cho mỗi tập dữ liệu, chúng tôi tin rằng các tập thuộc tính được xây dựng động, theo từng ví dụ như vậy có thể nắm bắt tính độc đáo của mỗi đoạn văn bản tốt hơn. Thứ hai, chúng tôi hướng dẫn LLMs đề xuất một kế hoạch để thao tác các giá trị của thuộc tính cụ thể cho tác vụ trong khi duy trì các giá trị thuộc tính khác giống nhau. Cuối cùng, chúng tôi gợi ý LLMs tái tạo câu dựa trên đề xuất thao tác. Tất cả các bước này được viết trong một gợi ý duy nhất và đưa vào LLM cùng một lúc. Hơn nữa, việc sử dụng LLMs có lợi cho khả năng diễn giải của khung công tác của chúng tôi, nơi các thuộc tính hoàn toàn minh bạch đối với người dùng.

Chúng tôi thực hiện các thí nghiệm mở rộng để đánh giá CoTAM và các phương pháp cơ sở bằng cách sử dụng một loạt các tác vụ phân loại few-shot với các mục tiêu phân loại rất khác nhau, phân tích cảm xúc dựa trên khía cạnh, và tạo văn bản có điều kiện để thao tác thuộc tính phức tạp hơn. Để so sánh công bằng, tất cả các phương pháp được so sánh đều sử dụng cùng LLMs và tạo ra cùng lượng dữ liệu. Chúng tôi đánh giá chất lượng dữ liệu được tạo ra bằng cách xem xét (1) hiệu suất của các mô hình ngôn ngữ nhỏ được huấn luyện thông qua fine-tuning hoặc các phương pháp không cần điều chỉnh trên dữ liệu được tăng cường và (2) hiệu suất ICL của LLMs sử dụng dữ liệu được tăng cường làm minh chứng. Kết quả thí nghiệm mở rộng bao gồm các tình huống thiếu nhãn và ngoài miền chứng minh lợi thế của việc tăng cường dữ liệu có thể kiểm soát được đề xuất so với các phương pháp truyền thống. Nghiên cứu loại bỏ thêm tiết lộ sự cần thiết của thao tác thuộc tính so với việc trực tiếp lật nhãn. Cuối cùng, chúng tôi trình bày phân tích PCA trên các embedding của các tăng cường được tạo ra minh họa trực quan hiệu quả của phương pháp.

Đóng góp của chúng tôi gồm ba khía cạnh:
• Chúng tôi đề xuất một phương pháp tăng cường dữ liệu có thể kiểm soát mới CoTAM dựa trên gợi ý chuỗi suy nghĩ sử dụng LLMs, trực tiếp chỉnh sửa các ví dụ văn bản theo cách có thể diễn giải được thay vì điều chỉnh các vector biểu diễn tiềm ẩn.
• Chúng tôi thực hiện thí nghiệm trên một phổ rộng các tác vụ và tập dữ liệu, chứng minh hiệu quả của dữ liệu được tăng cường bởi CoTAM trong cả fine-tuning và học trong ngữ cảnh.
• Các phân tích chi tiết của chúng tôi, đặc biệt là các ranh giới quyết định có thể nhận biết bởi con người được tiết lộ bởi hình dung 2D của tập dữ liệu được tăng cường bằng phân tích thành phần chính, chứng minh tiềm năng đáng kể của phương pháp thao tác thuộc tính được đề xuất.

Khả năng tái tạo. Chúng tôi sẽ mở mã nguồn.

2 Công thức hóa vấn đề
Chúng tôi nhằm tạo ra dữ liệu huấn luyện hiệu quả hơn bằng cách sử dụng tăng cường có thể kiểm soát trên một tập dữ liệu few-shot D tập trung vào thuộc tính mục tiêu Y (ví dụ: mục tiêu phân loại) với N giá trị có thể {y1, y2, ···, yN} (tức là N-way). Đối với mỗi giá trị thuộc tính có thể yi, tập dữ liệu D cung cấp K ví dụ (tức là K-shot) của các văn bản với giá trị đó. Ở đây chúng tôi giới thiệu hai lược đồ học few-shot chính làm cơ sở để thảo luận về tăng cường:

• Học trong ngữ cảnh (ICL) là một lược đồ cho LLMs, lấy một vài ví dụ của câu với các giá trị thuộc tính mục tiêu của chúng (tức là một chuỗi (X, yi)) làm ngữ cảnh để xử lý các đầu vào mới. Với các minh chứng này, LLM được mong đợi hiểu ánh xạ cơ bản và sau đó dự đoán nhãn của các đầu vào mới.

• Fine-tuning thường huấn luyện các mô hình nhỏ hơn với dữ liệu được gắn nhãn (hạn chế). Mô hình có một bộ nhúng văn bản E và một bộ phân loại C. Một văn bản x từ tập dữ liệu D sẽ được biểu diễn như một vector dày đặc E(x), được học để mã hóa các thuộc tính của x, bao gồm thuộc tính mục tiêu Y và các thuộc tính khác. Bộ phân loại C tiếp tục xử lý vector E(x) và xuất ra một phân phối trên y1, y2, ···, yN, chỉ ra xác suất của mỗi giá trị Y trong x.

Lý tưởng nhất, việc tăng cường có thể kiểm soát của chúng tôi sẽ cung cấp các minh chứng và dữ liệu huấn luyện hiệu quả dưới các thiết lập ICL và fine-tuning tương ứng.

3 Khung công tác CoTAM của chúng tôi
Để tăng cường hiệu suất của các phương pháp few-shot, chúng tôi giả định một tình huống, được hiển thị trong Hình 2, để tăng cường các ví dụ có thể cải thiện nhận thức tác vụ của các mô hình suy luận. Đối với một mẫu x với giá trị thuộc tính mục tiêu y từ D, chúng tôi sẽ thao tác giá trị thuộc tính của nó thành y' sao cho y≠y' để tạo thành một câu mới x'. Chúng tôi đặt hai yêu cầu cho thao tác: 1) Thao tác có ý nghĩa trên thuộc tính mục tiêu Y, có nghĩa là kết quả được thao tác x' nên được xem với yj bởi oracle như con người. 2) Thao tác nhỏ trên tất cả các thuộc tính khác Z, chỉ ra x và x' chia sẻ một giá trị zk tương tự cho tất cả Z ∈ Z.

--- TRANG 3 ---
LLM tạo ra các mẫu mới với thao tác hạn chế không liên quan đến tác vụ (tức là có thể kiểm soát) Người dùng chỉ định tác vụ và các mẫu few-shot

Cảm xúc: Tiêu cực
Cảm xúc: Tích cực
Chủ đề: Phim
Cấu trúc: Chuyển đổi

(1) Phân tách thuộc tính
Các thuộc tính và giá trị khác?
- Thay thế "nhàm chán" bằng "hấp dẫn"
- Giữ chủ đề về "phim"
- Thay thế "tốt" bằng "tầm thường" để giữ cấu trúc "chuyển đổi"

(2) Đề xuất thao tác
Làm thế nào để thao tác thuộc tính này?

(3) Tái tạo câu
Thực hiện đề xuất

Trong khi một số diễn viên biểu diễn tốt, bộ phim nhìn chung nhàm chán.

Cảm xúc: Tích cực
Trong khi một số diễn viên có màn trình diễn tầm thường, bộ phim nhìn chung hấp dẫn.

Mục tiêu: Cảm xúc (Tích cực / Trung tính / Tiêu cực)

Để đáp ứng hai yêu cầu trên sẽ đảm bảo x và x' chỉ khác nhau ở thuộc tính Y, làm cho chúng trở thành một cặp hiệu quả để học trên tập dữ liệu D. Lấy fine-tuning làm ví dụ, loss L(X, yi) + L(X', yj) sẽ được quy cho thuộc tính Y khác biệt duy nhất, do đó để mỗi chú thích bởi con người phản ánh hiệu quả thuộc tính mục tiêu với các tăng cường của nó.

Dựa trên các mong muốn của chúng tôi ở trên, chúng tôi đề xuất CoTAM có lợi từ khả năng thao tác văn bản mạnh mẽ của LLMs (OpenAI, 2023) với quy trình làm việc được minh họa trong Hình 2. Cụ thể hơn, chúng tôi đầu tiên tạo các truy vấn chuỗi suy nghĩ (CoT) để phân tách các văn bản đầu vào thành nhiều thuộc tính, xấp xỉ không gian tiềm ẩn. Chúng tôi nhằm loại bỏ lao động con người để đề xuất các thuộc tính có thể khác để có hiệu quả. Hơn nữa, trong một số trường hợp, ngay cả các chuyên gia con người cũng không thể cung cấp danh sách đầy đủ các thuộc tính khác trong tất cả các văn bản có thể. Việc tìm một tập thuộc tính được chia sẻ và cố định cho các loại văn bản khác nhau là khó khăn vì các câu khác nhau hiếm khi chia sẻ một tập thuộc tính áp dụng chung. Được khuyến khích bởi Wang et al. (2023), chúng tôi hướng dẫn LLMs đề xuất một tập thuộc tính động cho mỗi văn bản đầu vào, được tùy chỉnh giữa các đầu vào tùy thuộc vào thuộc tính nào có thể áp dụng. CoT sau đó chuyển đổi giá trị của thuộc tính mục tiêu sang các giá trị có thể khác trong tác vụ và gợi ý LLM tái tạo câu được thao tác. Cuối cùng, LLM được hướng dẫn soạn câu như vậy để hoàn thiện thao tác.

Khác với các công trình tạo sinh có thể kiểm soát hiện có trong thị giác máy tính (Shen et al., 2020; Shen và Zhou, 2021) và xử lý ngôn ngữ tự nhiên (Kruengkrai, 2019a; Zhou et al., 2022), nơi các thuộc tính được thao tác trong không gian tiềm ẩn của bộ mã hóa trước khi tái tạo các thể hiện mới, CoTAM của chúng tôi được đề xuất để chỉnh sửa trực tiếp văn bản bằng LLMs.

3.1 Bước 1: Phân tách thuộc tính
Theo thiết kế macro-level của CoTAM, bước đầu tiên trong CoT là phân tách câu thành các thuộc tính khác nhau. LLM lấy câu và một cặp thuộc tính-giá trị được chú thích bởi con người làm đầu vào và sau đó đề xuất các thuộc tính khác và giá trị của chúng.

Ví dụ, câu "Trong khi một số diễn viên biểu diễn tốt, bộ phim nhìn chung nhàm chán" sẽ được xử lý với cặp thuộc tính-giá trị yi đã biết, ở đây là "Cảm xúc: Tiêu cực". LLM sau đó đề xuất một tập các cặp thuộc tính-giá trị khác Ẑ = LLMAD(X, yi) ⊂ Z như "Chủ đề: Phim", "Cấu trúc: Chuyển đổi" như trong Hình 2, là một tập con của Z nhưng thường đủ chi tiết để xấp xỉ các thuộc tính không liên quan. Giá trị của thuộc tính đã biết sau đó được chuyển sang một giá trị khác do người dùng đưa ra như "Cảm xúc: Tích cực", sau đó được kết hợp với các cặp thuộc tính-giá trị khác do LLM đề xuất cho bước tiếp theo.

3.2 Bước 2: Đề xuất thao tác
Trong bước thứ hai, chúng tôi sẽ hướng dẫn LLM đề xuất phương pháp tái tạo một câu với thuộc tính được chuyển đổi và các thuộc tính khác từ bước phân tách. Bước này được tích hợp như hiểu cách đạt được mục tiêu, điều quan trọng đối với suy luận CoT (Wei et al., 2022c). Trong bước này, LLM lấy tất cả các yếu tố trong thao tác làm đầu vào và đề xuất một hướng dẫn I = LLMMP(X, yi, yj, Ẑ) cho LLM thực hiện trong bước tiếp theo. Một thao tác được đề xuất được hiển thị như trong Hình 2, LLM gợi ý một số hướng dẫn để hoàn thành thao tác.

3.3 Bước 3: Tái tạo câu
Bước này đơn giản yêu cầu LLM tuân theo hướng dẫn thao tác I được đề xuất để tái tạo câu và xuất ra một câu có nhãn được lật làm X' = LLMSR(X, I). Như trong Hình 2, LLM tuân theo các hướng dẫn tự tạo để chỉnh sửa câu đầu vào để tạo ra X' mong muốn có sự khác biệt đáng kể trong Y (tính cực cảm xúc) và sự khác biệt nhỏ trong Ẑ (các thuộc tính khác được đề xuất).

--- TRANG 4 ---
Tập dữ liệu | Thuộc tính mục tiêu | Giá trị có thể
SST-2 | Cảm xúc | Tích cực
TweetEmo | Cảm xúc | Tức giận
AG-News | Chủ đề | Tin tức thế giới
MNLI | Suy luận ngôn ngữ tự nhiên | Mâu thuẫn
MRPC | Ngữ nghĩa | Tương đương với câu 1
CSQA | Lựa chọn tốt nhất | <Tên câu trả lời>
ABSA | Cảm xúc về <Khía cạnh> | Tích cực
CommonGen | Từ khóa | "ski", "mountain", "skier"

Bảng 1: Các thuộc tính mục tiêu và giá trị có thể trong các tập dữ liệu của thí nghiệm chúng tôi và thêm chi tiết có thể tìm thấy trong Phụ lục B.

4 Thí nghiệm
Trong phần này, chúng tôi đánh giá các phương pháp tăng cường dựa trên LLM khác nhau trên một chuỗi các tác vụ phân loại, với các thuộc tính mục tiêu khác nhau. Chúng tôi kết hợp các cách toàn diện để sử dụng tăng cường với các kỹ thuật phân loại khác nhau, chẳng hạn như fine-tuning, học trong ngữ cảnh và suy luận với embedding câu. Chúng tôi tiếp tục đánh giá khả năng tăng cường của các phương pháp trên các tác vụ phức tạp hơn như phân tích cảm xúc dựa trên khía cạnh và tạo văn bản có điều kiện.

4.1 Tập dữ liệu
Chúng tôi xác minh lợi thế của CoTAM trên phân loại văn bản và các tác vụ khác bằng cách sử dụng 6 tập dữ liệu phân loại, bao gồm SST-2 (tính cực cảm xúc) (Socher et al., 2013), TweetEmo (cảm xúc tinh tế) (Barbieri et al., 2020), AG-NEWS (chủ đề) (Zhang et al., 2015), MNLI (suy luận ngôn ngữ tự nhiên) (Williams et al., 2018), MRPC (tương đồng ngữ nghĩa văn bản) (Dolan và Brockett, 2005), và CSQA (trả lời câu hỏi nhiều lựa chọn) (Talmor et al., 2019). MNLI bao gồm các tập dữ liệu khớp (MNLIm) và không khớp (MNLImm) để đánh giá. Để tiếp tục kiểm tra khả năng của CoTAM trên các thuộc tính khác ngoài mục tiêu phân loại, chúng tôi bao gồm thao tác trên phân tích cảm xúc dựa trên khía cạnh (ABSA) và các tác vụ tạo văn bản có điều kiện. Đối với các tập dữ liệu ABSA, chúng tôi bao gồm Restaurant và Laptop từ SemEval2014 (Pontiki et al., 2014). Đối với tạo văn bản có điều kiện, chúng tôi bao gồm CommonGen (Lin et al., 2020). Chúng tôi báo cáo kết quả trên 1000 mẫu cho ICL từ hỗn hợp của các tập dữ liệu validation và test do vấn đề chi phí. Đối với các thiết lập khác, chúng tôi báo cáo kết quả trên tập dữ liệu validation khi tập dữ liệu test không có sẵn công khai, xem xét hiệu quả để có kết quả đa lần chạy. Thống kê của các tập dữ liệu được trình bày trong Phụ lục A. Chúng tôi trình bày một số ví dụ về tên thuộc tính trong Bảng 1.

4.2 Phương pháp so sánh
Tăng cường dữ liệu CoT (CoTDA) là một biến thể tăng cường của phương pháp chúng tôi áp dụng CoT tương tự cho tăng cường truyền thống. Thay vì trực tiếp yêu cầu tăng cường, chúng tôi để LLM tuân theo CoT được đề xuất và đề xuất một phương pháp viết câu với cùng thuộc tính như câu đầu vào. CoTDA là baseline chính để so sánh nhằm khám phá tầm quan trọng của việc chuyển đổi thuộc tính trong CoTAM. Đối với mỗi dữ liệu seed, chúng tôi tăng cường nó N-1 lần với nhiệt độ 0.1, trong đó N đề cập đến số lượng lớp trong tập dữ liệu. Do đó, CoTDA tạo ra cùng số lượng dữ liệu mới như CoTAM để đạt được so sánh công bằng.

FlipDA (Zhou et al., 2022) là một phương pháp tăng cường chuyển đổi nhãn truyền thống dựa trên tạo sinh có điều kiện bởi T5 được điều chỉnh đầy đủ (Raffel et al., 2020). Cụ thể, câu được kết hợp với nhãn được chuyển đổi làm đầu vào cho T5. Sau đó, một số span trong câu được che ngẫu nhiên và được khôi phục bởi T5 có điều kiện trên nhãn mới để chuyển đổi ngữ nghĩa của câu. Vì FlipDA gốc yêu cầu tập dữ liệu có giám sát lớn không áp dụng được cho học few-shot, chúng tôi xây dựng baseline FlipDA dựa trên LLM (FlipDA++) bằng cách gửi hướng dẫn thay thế span cho LLMs.

Chú thích của con người/LLM trực tiếp sử dụng các văn bản được gắn nhãn bởi con người hoặc LLMs. Đối với chú thích con người, chúng tôi bao gồm các thiết lập K-shot (Base) và NK-shot (Extra Annotation). K-shot đại diện cho baseline trước khi tích hợp dữ liệu được tạo từ LLMs. NK-shot có số lượng dữ liệu huấn luyện sau khi tăng cường với chú thích con người, do đó chúng tôi mong đợi nó là một ranh giới trên của các phương pháp tăng cường. Trong khi đó, chúng tôi sẽ thấy CoTAM có thể vượt qua ranh giới trên này, có thể được quy cho chất lượng dữ liệu cao hơn do thao tác thuộc tính. Chú thích LLM NK-shot (Pseudo Label) đại diện cho một baseline đơn giản thường được áp dụng khi có nhiều dữ liệu trong miền không có nhãn.

Tính công bằng so sánh Chúng tôi chọn GPT-4 (OpenAI, 2023) làm LLM để xây dựng tập dữ liệu. Nhiệt độ của GPT-4 được đặt thành 0 hướng tới chất lượng và khả năng tái tạo cao. Chúng tôi áp dụng mỗi phương pháp tăng cường cho một tập con cố định của mỗi tập dữ liệu để tạo ra một tập con nhỏ từ đó chúng tôi lấy mẫu dữ liệu huấn luyện. Để so sánh công bằng, tập con này cũng được sử dụng trong các baseline khác để tạo dữ liệu. Theo mặc định, chúng tôi đặt K là 10 cho fine-tuning và 3 cho ICL. Tất cả kết quả được báo cáo là trung bình của 10 lần chạy (trừ ICL do chi phí) để loại bỏ thiên vị.

Tất cả các gợi ý trong thí nghiệm của chúng tôi được trình bày trong Phụ lục C để tái tạo tốt hơn.

4.3 Kết quả phân loại
Fine-tuning Một cách đơn giản để đánh giá chất lượng dữ liệu là điều chỉnh mô hình trên đó và sau đó kiểm tra hiệu suất. Chúng tôi chọn RoBERTa-Large (Liu et al., 2019) làm người học trên các tập dữ liệu khác nhau. Với tập dữ liệu validation không có sẵn, chúng tôi huấn luyện mô hình trong 32 epoch và sau đó đánh giá.

Như được trình bày trong Bảng 2, CoTAM của chúng tôi đạt được kết quả fine-tuning tốt nhất trên tất cả 7 tác vụ so với các phương pháp tạo dữ liệu dựa trên LLM khác. Trên hầu hết các tác vụ, hai phương pháp chuyển đổi nhãn (FlipDA và CoTAM) vượt trội hơn các phương pháp khác, chỉ ra rằng việc sử dụng LLM để chuyển đổi nhãn tạo ra dữ liệu hiệu quả hơn. Về chuyển đổi nhãn, thao tác thuộc tính cho thấy sự vượt trội so với thay thế span đơn giản vì CoTAM của chúng tôi hoạt động tốt hơn FlipDA trên tất cả các tác vụ. Hiệu suất nổi bật của CoTAM cũng xác minh khả năng của LLMs trong việc thao tác các thuộc tính phức tạp có thể đề cập đến tiền đề hoặc câu hỏi.

Trên 6 trong 7 tác vụ, CoTAM của chúng tôi phá vỡ ranh giới trên được giả định của (N-way) NK-shot với chú thích con người bổ sung. Điều này chỉ ra rằng dữ liệu được tạo cẩn thận từ LLMs có tiềm năng huấn luyện các mô hình tốt hơn so với những mô hình được huấn luyện trên cùng số lượng chú thích con người. Ngoài ra, CoTAM của chúng tôi được xác minh là một phương pháp như vậy cải thiện hiệu quả dữ liệu bằng thao tác thuộc tính.

Học trong ngữ cảnh Hiệu suất của suy luận dựa trên ICL với các phương pháp tăng cường khác nhau được thể hiện trong Bảng 2. CoTAM của chúng tôi cho thấy khả năng vượt trội trong việc cung cấp cho LLMs các ví dụ few-shot cho suy luận, do đó mở rộng ứng dụng của phương pháp chúng tôi. Trường hợp thất bại duy nhất của CoTAM là MNLI ngoài miền, nơi các ví dụ few-shot không có lợi cho suy luận. Tuy nhiên, trong tất cả các tình huống tăng cường, CoTAM của chúng tôi hoạt động tốt nhất cho đánh giá này.

Suy luận với embedding câu Trong lĩnh vực phân loại văn bản few-shot, embedding văn bản đã được chứng minh là một công cụ mạnh mẽ để cải thiện hiệu suất và hiệu quả (Muennighoff et al., 2023). Phần này được dành riêng để khám phá các kỹ thuật dựa trên thể hiện được thiết kế rõ ràng cho phân loại văn bản với các mô hình embedding văn bản.

--- TRANG 5 ---
Phương pháp | SST-2 | TweetEmo | AG-NEWS | MNLI m | MNLI mm | MRPC | CSQA
Fine-tuning
Base | 60.54 | 44.38 | 81.05 | 35.88 | 38.75 | 51.96 | 34.54
Extra Annotation† | 62.17 | 69.51 | 88.66 | 43.33 | 44.03 | 57.50 | 47.36
LLM Pseudo Label | 61.14 | 69.11 | 85.64 | 41.71 | 42.92 | 55.88 | 45.12
FlipDA++ | 74.28 | 70.87 | 84.72 | 51.52 | 53.56 | 60.15 | 50.52
CoTDA | 70.83 | 67.76 | 85.19 | 36.06 | 36.28 | 55.54 | 48.79
CoTAM | 79.12 | 72.76 | 85.80 | 54.07 | 56.16 | 65.83 | 53.22

ICL
No Example | 90.50 | 69.80 | 81.30 | 67.50 | 69.70 | 69.80 | 73.50
Base | 94.00 | 74.50 | 85.50 | 68.10 | 68.10 | 70.60 | 76.30
Extra Annotation† | 94.70 | 79.00 | 88.70 | 68.70 | 68.60 | 71.40 | 76.80
LLM Pseudo Label | 94.20 | 75.80 | 85.80 | 66.90 | 69.00 | 67.90 | 76.50
FlipDA++ | 94.30 | 76.70 | 85.20 | 68.80 | 68.90 | 70.70 | 77.00
CoTDA | 94.00 | 76.50 | 86.00 | 68.20 | 68.50 | 70.00 | 76.70
CoTAM | 94.50 | 77.10 | 86.40 | 69.70 | 69.20 | 70.90 | 77.30

Bảng 2: Kết quả học few-shot dựa trên dữ liệu được chú thích bởi con người và LLMs. †: Extra Annotation tăng số lượng (NK) mẫu được chú thích bởi con người lên cùng số lượng như được chú thích bởi LLM để so sánh khả năng chú thích giữa LLMs và con người. Đậm: Kết quả tốt nhất với số lượng cơ sở (K) của chú thích con người, do đó loại trừ "Extra Annotation".

Phương pháp | SST-2 | TweetEmo | AG-NEWS
         | NC | KNN | NC | KNN | NC | KNN
Base | 82.00 | 78.20 | 66.01 | 59.92 | 77.72 | 73.57
Extra† | 87.55 | 83.45 | 71.23 | 67.56 | 84.70 | 82.33
LLM SL | 86.78 | 80.26 | 69.34 | 64.90 | 81.19 | 79.34
FlipDA++ | 88.13 | 86.76 | 66.53 | 65.05 | 79.82 | 75.11
CoTDA | 86.38 | 83.00 | 68.63 | 61.58 | 78.87 | 76.56
CoTAM | 88.43 | 87.52 | 70.02 | 65.37 | 80.60 | 75.48

Bảng 3: Sử dụng embedding câu cho các tác vụ phân loại dựa trên các ví dụ few-shot được tăng cường khác nhau.

Trong suy luận dựa trên thể hiện, một mô hình embedding văn bản chuyển đổi câu đầu vào thành một biểu diễn. Nhãn của biểu diễn này sau đó được xác định dựa trên khoảng cách của nó với các biểu diễn câu được chú thích. Chúng tôi sử dụng hai thuật toán không cần điều chỉnh trong thí nghiệm—Nearest Centroid (NC) (Manning et al., 2008) và K-Nearest Neighbors (KNN)—và áp dụng chúng cho ba tập dữ liệu phân loại văn bản khác nhau. NC gán nhãn cho một câu đầu vào tùy thuộc vào khoảng cách của nó đến centroids, được định nghĩa là biểu diễn trung bình của các câu có cùng nhãn. Ngược lại, KNN gán nhãn cho câu đầu vào theo nhãn phổ biến nhất trong số K láng giềng gần nhất. Chúng tôi đặt K là 5 trong thí nghiệm. Chúng tôi khai thác mô hình Simple Contrastive Sentence Embedding (SimCSE) (Gao et al., 2021), với RoBERTa-Large làm mô hình backbone, để mã hóa văn bản.

Bảng 3 trình bày hiệu suất của các phương pháp tạo dữ liệu khác nhau khi được sử dụng với các thuật toán dựa trên thể hiện. Ngược lại với các phương pháp tạo văn bản mới (như FlipDA và CoTDA), phương pháp được đề xuất của chúng tôi, được gọi là CoTAM sau đây, thể hiện hiệu suất vượt trội trong hầu hết các cấu hình. Điều này ngụ ý rằng dữ liệu được tạo bởi CoTAM cũng có lợi từ các phân phối được cải thiện trong không gian tiềm ẩn của các mô hình embedding văn bản. Trên tập dữ liệu AG-NEWS, các thuật toán dựa trên thể hiện cho thấy sự ưu tiên cho các chú thích trong miền, cho dù được thực hiện bởi con người hay Mô hình Ngôn ngữ Lớn (LLMs). Điều này nhấn mạnh tầm quan trọng của việc sử dụng văn bản trong miền khi sử dụng các thuật toán này cho một số tác vụ nhất định.

4.4 Phân tích cảm xúc dựa trên khía cạnh
Ở đây chúng tôi tiếp tục mở rộng tiện ích của CoTAM sang một tình huống phức tạp hơn để thao tác nhiều biểu diễn span. Chúng tôi thí nghiệm trên phân tích cảm xúc dựa trên khía cạnh (ABSA), nhằm trích xuất các span được nhắm mục tiêu bởi cảm xúc (khía cạnh) trong một tuyên bố và các tính cực tương ứng. Ví dụ, khía cạnh được trích xuất từ "Đồ ăn ngon." sẽ là "khía cạnh tích cực: đồ ăn".

Để thao tác thuộc tính trên ABSA, chúng tôi xem các khía cạnh như thuộc tính ABSA như "khía cạnh tích cực: đồ ăn". Chúng tôi truy vấn LLMs để phân tách văn bản thành các thuộc tính ABSA và khác. Các tính cực của thuộc tính ABSA sau đó được chuyển đổi ngẫu nhiên và sử dụng cho tái tạo. Dữ liệu được tái tạo được hợp nhất vào tập dữ liệu ban đầu làm tăng cường.

Chúng tôi sử dụng tập dữ liệu SemEval 2014 ABSA có hai tập con: restaurant và laptop và ba tính cực cảm xúc: tích cực, tiêu cực, và trung tính. Chúng tôi đặt số shot (K) là 10 và tạo 2 lần cho mỗi thể hiện (N = 3), là thời gian thao tác tối đa cho một thể hiện với chỉ một khía cạnh. Kết quả trên ABSA được trình bày trong Bảng 4, CoTAM của chúng tôi thành công vượt trội hơn các phương pháp tăng cường dựa trên LLM khác, xác nhận rằng CoTAM có thể áp dụng cho các tình huống phức tạp hơn thao tác thuộc tính câu đơn.

--- TRANG 6 ---
Phương pháp | Restaurant | Laptop
         | P. | R. | F. | P. | R. | F.
Base | 30.61 | 40.38 | 34.82 | 23.73 | 28.57 | 25.93
Extra† | 54.70 | 66.67 | 60.09 | 59.18 | 44.62 | 50.88
LLM SL | 44.26 | 56.25 | 49.54 | 18.56 | 22.73 | 14.09
FlipDA++ | 45.90 | 58.33 | 51.38 | 26.58 | 42.86 | 32.81
CoTDA | 44.55 | 51.04 | 47.57 | 26.09 | 36.74 | 30.51
CoTAM | 50.00 | 64.58 | 56.36 | 33.33 | 44.90 | 38.26

Bảng 4: Hiệu suất của thao tác span trên các tập dữ liệu phân tích cảm xúc dựa trên khía cạnh.

4.5 Tạo văn bản có điều kiện
Chúng tôi chạy thí nghiệm trên tập dữ liệu CommonGen để áp dụng CoTAM cho tạo văn bản có điều kiện. CommonGen nhắm mục tiêu tạo ra một câu chứa một tập từ khóa. Ví dụ, với các từ đầu vào: "ski, mountain, skier", đầu ra có thể là "Skier skis down the mountain". Chúng tôi sử dụng CoTAM để thao tác dữ liệu bằng cách chuyển đổi nhóm từ khóa sang một nhóm khác (được đề xuất bởi LLM) trong khi giữ các thuộc tính khác không thay đổi.

Theo các số liệu được hiển thị trong Bảng 5, chúng tôi có thể thấy CoTAM giữ lợi thế so với các phương pháp tăng cường dựa trên LLM khác. Do đó, chúng tôi kết luận rằng CoTAM không chỉ giới hạn trong các tác vụ phân loại mà còn có tiềm năng cho trích xuất thông tin và tạo ngôn ngữ tự nhiên.

Phương pháp | CommonGen
         | Rouge-1 | Rouge-2 | Rouge-L | Coverage
Base | 41.99 | 13.98 | 33.57 | 65.07
Extra† | 46.30 | 15.66 | 36.18 | 75.55
LLM SL | 47.85 | 14.68 | 35.63 | 75.95
FlipDA++ | 46.81 | 14.48 | 35.32 | 76.10
CoTDA | 44.43 | 13.43 | 35.05 | 65.98
CoTAM | 46.38 | 15.85 | 37.02 | 75.23

Bảng 5: Hiệu suất của thao tác span trên tạo văn bản có điều kiện. Coverage có nghĩa là tỷ lệ từ khóa đã cho xuất hiện trong câu đầu ra.

5 Phân tích thêm
5.1 Minh chứng quy trình làm việc
Trong Hình 3, chúng tôi minh chứng quy trình làm việc của cơ chế phân tách thuộc tính động. Chúng tôi bao gồm các thuộc tính thường xuất hiện nhất trong thao tác theo thống kê trong Phụ lục E. Trong quy trình làm việc, CoTAM của chúng tôi phân tách câu thành các thuộc tính áp dụng được và tái tạo trong khi duy trì các thuộc tính này. Ví dụ, tone (X) áp dụng hơn cho câu đầu tiên do tính chủ quan của nó và comparison (X) áp dụng hơn cho câu cuối cùng vì chỉ có nó liên quan đến so sánh. Các thuộc tính này hiểu các phần không thay đổi của văn bản để hướng dẫn tái tạo trong quá trình thao tác. Sau đó, việc tái tạo chuyển đổi nhãn mục tiêu (sentiment (X) trong trường hợp này) với thay đổi nhỏ đối với các thuộc tính khác.

5.2 Nghiên cứu loại bỏ
Chúng tôi khởi động một nghiên cứu loại bỏ để xác minh tầm quan trọng của mỗi suy nghĩ trong CoT. Chúng tôi cũng khám phá hiệu ứng của các LLMs khác nhau. Do đó chúng tôi thay đổi LLM trong thí nghiệm thành GPT-3.5-turbo. Các thí nghiệm cho thấy GPT-4 dẫn đến kết quả fine-tuning tốt hơn đáng kể. Ngoài ra, khoảng cách này có thể được thu hẹp bởi các mô hình embedding văn bản trên phân loại văn bản.

Kết quả của nghiên cứu loại bỏ được trình bày chi tiết trong Bảng 6. Trong nghiên cứu này, chúng tôi phát hiện rằng việc loại bỏ mỗi "suy nghĩ" khỏi CoT dẫn đến sự suy giảm hiệu suất. Thú vị, suy nghĩ "what" (phân tách) chứng minh quan trọng hơn suy nghĩ "how" (phương pháp), nhấn mạnh sự chiếm ưu thế của đề xuất thuộc tính so với đề xuất phương pháp phụ trợ. CoT là cần thiết cho việc chuyển đổi nhãn vì việc loại bỏ nó dẫn đến sự suy giảm hiệu suất đáng kể. Trong so sánh giữa các LLMs, GPT-4 vượt trội hơn GPT-3.5-turbo, chỉ ra rằng CoTAM ưu tiên LLM lớn hơn với khả năng ngôn ngữ tốt hơn, đặc biệt trên các tác vụ phức tạp hơn như MNLI. Cuối cùng, chúng tôi so sánh hiệu suất giữa CoTAM với pool thuộc tính cố định (FAP) và với pool thuộc tính động trong thí nghiệm. Kết quả cho thấy lợi thế của việc loại bỏ giới hạn loại thuộc tính mà LLM phân tách thành.

Dữ liệu | SST-2 | MNLI
     | T | NC | KNN | T
CoTAM | 79.12 | 88.43 | 87.52 | 54.07
w/o What | 75.69 | 88.03 | 86.78 | 45.61
w/o How | 77.94 | 88.15 | 87.01 | 48.98
w/o CoT | 71.82 | 87.94 | 86.24 | 39.34
w/ V 3.5 | 72.93 | 87.59 | 84.31 | 41.32
w/ FAP | 76.38 | 87.79 | 85.13 | 47.91

Bảng 6: Nghiên cứu loại bỏ trên CoTAM. Kết quả MNLI khớp được trình bày để phân tích.

5.3 Hình dung thao tác thuộc tính
Trong nỗ lực xác nhận giả thuyết của chúng tôi rằng LLM đang điều chỉnh một đặc trưng duy nhất trong khi giữ các thuộc tính khác không đổi, chúng tôi minh họa các biểu diễn cặp dữ liệu từ CoTAM trong Hình 4. Chúng tôi sử dụng phân tích thành phần chính (PCA) (F.R.S., 1901) để lấy các biểu diễn văn bản chiều cao (1024 chiều) từ SimCSE và đơn giản hóa chúng thành không gian 2 chiều để dễ hình dung.

--- TRANG 7 ---
cảm xúc (X)
chủ đề (X)
so sánh (X)
đối tượng (X)
hành động (X)
mô tả
tập trung (X)
tông điệu (X)
bối cảnh (X)
thể loại (X)
chủ đề (X)
......

Lấp lánh, thường là hài hước lãng mạn
ghen tuông comedy...

Salma Hayek có cảm giác cho
nhân vật ở tất cả các giai đoạn của cuộc đời cô.

Những người đang cố gắng tìm đường
qua thảm kịch này.

Của nhiều phụ nữ tự hấp thụ hơn
mẹ và các con gái được đặc trưng trong
bộ phim này

Một bộ phim hài lãng mạn ghen tuông buồn tẻ, đau đớn và không hài hước không thể giải trí.

Salma Hayek thiếu kết nối với
nhân vật ở tất cả các giai đoạn của cuộc đời cô.

Những người đang ăn mừng thành công
và ôm lấy khoảnh khắc vui vẻ này cùng nhau.

Thật khó để tìm thấy những người phụ nữ
thương cảm và yêu thương hơn
mẹ và các con gái được đặc trưng trong bộ phim này.

Hình 3: Quy trình làm việc của CoTAM cho các đầu vào khác nhau.

Biểu đồ phân biệt rõ ràng giữa các biểu diễn tích cực và tiêu cực, điều này nhấn mạnh giá trị của phương pháp của chúng tôi trong fine-tuning và suy luận dựa trên thể hiện. Ngoài ra, hướng chuyển đổi biểu diễn phần lớn nhất quán, cung cấp thêm bằng chứng rằng LLMs có khả năng điều chỉnh một thuộc tính trong khi giữ những thuộc tính khác ổn định. Tính nhất quán trong hướng chuyển đổi này gợi ý về khả năng dự đoán và kiểm soát mà chúng tôi đã thực hiện đối với hành vi LLM để thao tác đặc trưng có mục tiêu. So với CoTDA, CoTAM của chúng tôi mô tả ranh giới rõ ràng hơn, do đó cho phép học dữ liệu hiệu quả hơn so với tăng cường dữ liệu truyền thống.

Thành phần chính 1 | Thành phần chính 2
CoTAG
Cảm xúc: Tiêu cực
Cảm xúc: Tích cực
Theo dõi thao tác

Thành phần chính 1 | Thành phần chính 2
CoTAM
Cảm xúc: Tiêu cực
Cảm xúc: Tích cực
Theo dõi thao tác

Hình 4: Phân tích thành phần chính của các cặp văn bản được tạo bởi CoTDA và CoTAM trên tập dữ liệu SST-2.

5.4 Phân tích quy mô dữ liệu
Trong phần này, chúng tôi phân tích cách số lượng dữ liệu ban đầu ảnh hưởng đến hiệu suất của CoTAM. Do đó, chúng tôi lấy mẫu 3000 thể hiện nữa từ SST-2 để tăng quy mô pool lấy mẫu. Như được trình bày trong Hình 5, CoTAM có thể phá vỡ ranh giới NK-Shot với ít ví dụ (K≤64) cho fine-tuning. Với các mô hình biểu diễn văn bản, CoTAM cho thấy lợi thế đáng kể trên rất ít ví dụ (K≤4) và hội tụ về hiệu suất tương tự với chú thích con người. Mặc dù fine-tuning trên nhiều chú thích con người hơn dẫn đến hiệu suất cao hơn CoTAM, việc cải thiện hiệu suất trong miền có thể là kết quả của overfitting với miền. Do đó, chúng tôi tiếp tục đánh giá CoTAM và NK-Shot trên custom review, một tập dữ liệu ngoài miền với cùng nhãn như SST-2. Trên custom review, CoTAM cho thấy lợi thế nhất quán với các số lượng dữ liệu khác nhau. Do đó, chúng tôi kết luận CoTAM mạnh mẽ hơn đối với việc không khớp miền so với điều chỉnh trực tiếp.

1 2 4 8 16 32 64 128 256 512 1024
0.5 0.6 0.7 0.8 0.9 1.0
SST-2 (Trong miền)
K-CoTAM (Điều chỉnh)
NK-Shot (Điều chỉnh)
K-CoTAM (Nearest Centroid)
NK-Shot (Nearest Centroid)

1 2 4 8 16 32 64 128 256 512 1024
0.5 0.6 0.7 0.8 0.9 1.0
Custom Review (Ngoài miền)
K-CoTAM (Điều chỉnh)
NK-Shot (Điều chỉnh)
K-CoTAM (Nearest Centroid)
NK-Shot (Nearest Centroid)

Hình 5: So sánh giữa K-shot CoTAM và NK-shot trên các tập dữ liệu test trong miền và ngoài miền.

5.5 Nghiên cứu trường hợp
Hình 6 chỉ định quá trình thao tác thuộc tính thực tế trong thí nghiệm của chúng tôi. Để mô tả tốt hơn, chúng tôi đơn giản hóa phản hồi bằng cách chỉ trình bày các thuộc tính được đề xuất bởi LLMs.

Trong ví dụ SST-2, các thuộc tính khác bao gồm nhãn trong một phân loại khác (Chủ đề: Đánh giá phim), thực thể diễn viên (Diễn viên: Ford, Neeson), và phong cách tổng thể (Ý kiến: Tổng thể). Các thuộc tính này được bảo tồn tốt trong tái tạo, điều này đóng góp vào một sự tương phản mạnh mẽ trong mục tiêu tác vụ và do đó cải thiện hiệu quả dữ liệu.

Chuyển sang ví dụ MNLI, câu chủ yếu phân tách thành các yếu tố ngữ nghĩa khác nhau. Khi các yếu tố này được tái tạo, chúng theo một chuỗi logic khác với câu gốc. Do đó dữ liệu từ CoTAM tăng cường sự hiểu biết của người học về logic văn bản quan trọng để giải quyết MNLI.

--- TRANG 8 ---
Cảm xúc: Tiêu cực → Tích cực
Đề cập: Diễn viên | Chủ đề: Đánh giá phim
mặc dù ford và neeson
có thể giữ được sự quan tâm của chúng tôi, nhưng
nó chỉ không phải là một bộ phim ly kỳ

Ford và Neeson dễ dàng
mê hoặc chúng tôi, làm cho nó trở thành
một bộ phim cực kỳ ly kỳ.

Diễn viên: Ford, Neeson
Ý kiến: Tổng thể
Bình luận: Màn trình diễn của diễn viên

SST-2

NLI: Entail → Contradict
Mối quan tâm: Thể loại âm nhạc
Nội dung: Sự chấp thuận của cha mẹ

Giả thuyết: Cha mẹ tôi có thể
thấy rằng nó hơi
cổ điển và tôi thuyết phục
họ rằng nghe nó không sao.

Giả thuyết: Mặc dù nỗ lực
thuyết phục của tôi, cha mẹ tôi
không thể thấy khía cạnh cổ điển
và từ chối để tôi nghe nó.

Minh chứng: Thuyết phục

MNLI
Tiền đề: Tôi có thể thuyết phục cha mẹ rằng việc nghe họ là OK vì nó hơi cổ điển.

Hình 6: Nghiên cứu trường hợp về quy trình làm việc thực tế trong CoTAM.

6 Công trình liên quan
Thao tác thuộc tính nhằm kiểm soát các thuộc tính nhất định của dữ liệu. Một ứng dụng chung của thao tác thuộc tính là thay đổi các thuộc tính trực quan trong hình ảnh khuôn mặt (Shen et al., 2020; Shen và Zhou, 2021). Thao tác hình ảnh thường liên quan đến việc chuyển đổi các biểu diễn hình ảnh (Perarnau et al., 2016; Xiao et al., 2018; Shen et al., 2020) trong không gian tiềm ẩn. Trong xử lý ngôn ngữ tự nhiên, chủ đề gần nhất với thao tác thuộc tính là data flipping (Kruengkrai, 2019b; Zhou et al., 2022), thay thế các span chính trong văn bản để chuyển đổi nhãn của nó. Rõ ràng, nhiều thuộc tính văn bản như chủ đề không thể được thao tác bằng thay thế span. Do đó, chúng tôi chọn thích nghi LLM để thao tác một không gian tiềm ẩn được xấp xỉ bởi một chuỗi thuộc tính được đề xuất bởi LLM.

Tạo sinh có thể kiểm soát là một chủ đề khác gần với CoTAM. Các phương pháp này thường tạo ra văn bản từ một không gian tiềm ẩn liên tục rời rạc bằng cách kiểm soát các chiều nhất định (Bowman et al., 2016; Hu et al., 2017; Yang và Klein, 2021). Bộ tạo sinh có thể kiểm soát được huấn luyện bằng cách tối đa hóa một ranh giới biến phân thấp hơn trên khả năng log dữ liệu dưới mô hình tạo sinh với loss phân kỳ KL (Hu et al., 2017). Giới hạn của tạo sinh có thể kiểm soát hiện tại là không có kiểm soát rõ ràng các chiều khác để duy trì chúng như nhau. Phương pháp của chúng tôi giải quyết vấn đề này bằng cách phân tách hoàn toàn văn bản đầu vào thành nhiều nhãn với LLMs và sau đó tái tạo nó với các thuộc tính được chuyển đổi.

Mô hình ngôn ngữ lớn là các mô hình quy mô lớn được huấn luyện trên một số lượng lớn văn bản (Brown et al., 2020; Chowdhery et al., 2022; Hoffmann et al., 2022) đã được chứng minh có khả năng nổi lên (Wei et al., 2022b). Một trong những khả năng này là học từ các minh chứng few-shot, thường được gọi là học trong ngữ cảnh (Dong et al., 2022). Tuy nhiên, các minh chứng này phải được nối thành ngữ cảnh trong thời gian suy luận, tăng chi phí tính toán và dấu chân carbon. Một khả năng quan trọng khác là tuân theo hướng dẫn cho khả năng chuyển giao tác vụ zero-shot (Wei et al., 2022a). Theo ý tưởng này, ChatGPT (Ouyang et al., 2022; OpenAI, 2023) được huấn luyện với phản hồi con người và học tăng cường. Công trình của chúng tôi có lợi từ các mô hình được điều chỉnh hướng dẫn này để tạo ra thuộc tính và tái tạo câu.

Tăng cường dữ liệu được sử dụng rộng rãi trong các tình huống tài nguyên thấp để giảm thiểu overfitting mô hình. Nó thường được thực hiện theo cách bảo tồn nhãn nơi chỉ có các nhiễu loạn nhỏ được thêm vào (Wei và Zou, 2019; Fadaee et al., 2017). Gần đây, một dòng nghiên cứu đề xuất sử dụng LLMs để tăng cường dữ liệu. Cụ thể, họ sử dụng dữ liệu few-shot làm minh chứng và gợi ý LLMs tạo ra dữ liệu mới (Yoo et al., 2021; Sahu et al., 2022a). Họ tuyên bố rằng LLM có thể trộn dữ liệu few-shot và tổng hợp những dữ liệu tương tự. Lin et al., 2023 tiếp tục đề xuất sử dụng Pointwise V-information để lọc dữ liệu không hữu ích từ thế hệ. Gần đây nhất Dai et al., 2023; Whitehouse et al., 2023 đề xuất tạo dữ liệu bằng ChatGPT và GPT-4 và quan sát sự cải thiện hiệu suất. Cuối cùng Cheng et al., 2023 sử dụng dữ liệu được tạo bởi GPT-3 để cải thiện embedding câu thông qua học tương phản. Công trình của chúng tôi nhằm cải thiện tăng cường dữ liệu dựa trên LLM thông qua thao tác thuộc tính.

7 Kết luận
Nghiên cứu này giới thiệu một phương pháp mới, Thao tác Thuộc tính Chuỗi Suy nghĩ (CoTAM), sử dụng dữ liệu được thao tác từ Mô hình Ngôn ngữ Lớn (LLMs) cho học few-shot. CoTAM của chúng tôi tạo ra dữ liệu chuyển đổi nhãn bằng cách sửa đổi các thuộc tính cụ thể cho tác vụ và tái tạo câu mới. Thử nghiệm của chúng tôi xác nhận hiệu quả của CoTAM so với các kỹ thuật tạo văn bản dựa trên LLM khác. Kết quả cũng cho thấy tiềm năng của việc học được hướng dẫn bởi LLM với ít giám sát hơn.

Công việc tương lai sẽ nhắm đến việc thích nghi kỹ thuật thao tác thuộc tính cho các mô hình ngôn ngữ nhỏ hơn, tăng khả năng truy cập của nó. Điều này sẽ giảm sự phụ thuộc vào các quy trình tốn tài nguyên vốn có của các mô hình ngôn ngữ lớn, cải thiện hiệu quả.

Giới hạn
Mặc dù có những tiến bộ đáng kể trong học few-shot và thao tác thuộc tính được báo cáo trong bài báo này, CoTAM được đề xuất của chúng tôi có một số giới hạn nhất định. Thứ nhất, phương pháp của chúng tôi tận dụng quy trình phân tách và tái tạo chuỗi suy nghĩ, trong khi mang lại hiệu quả dữ liệu được cải thiện và hiệu suất mô hình, có xu hướng dẫn đến sự giảm hiệu quả tạo sinh tổng thể so với các phương pháp truyền thống. Điều này có thể ảnh hưởng đến khả năng mở rộng của phương pháp, đặc biệt trong các tình huống yêu cầu tạo dữ liệu nhanh chóng. Thứ hai, việc triển khai hiện tại của CoTAM chủ yếu bị hạn chế đối với các tác vụ liên quan đến thuộc tính, giới hạn phạm vi ứng dụng của nó. Mặc dù ràng buộc này là kết quả trực tiếp của thiết kế phương pháp tập trung vào thao tác các thuộc tính cụ thể cho tác vụ, chúng tôi thừa nhận rằng việc mở rộng khả năng áp dụng của CoTAM cho một tập hợp rộng hơn các tác vụ có thể tăng đáng kể tiện ích của nó. Công việc tương lai của chúng tôi do đó sẽ nhắm đến việc giải quyết giới hạn này. Cuối cùng, cần lưu ý rằng hiệu quả của CoTAM cơ bản phụ thuộc vào khả năng của Mô hình Ngôn ngữ Lớn cơ bản. Kết quả là, các giới hạn vốn có trong những LLMs này, chẳng hạn như thiên vị trong dữ liệu huấn luyện của chúng hoặc giới hạn trong hiểu biết của chúng về ngữ cảnh tinh tế, có thể ảnh hưởng đến hiệu suất của CoTAM. Do đó, việc liên tục cải thiện và tinh chỉnh LLMs được sử dụng trong phương pháp của chúng tôi là rất quan trọng để đảm bảo độ chính xác và sự mạnh mẽ của dữ liệu được tạo.

Xem xét đạo đức
Công trình của chúng tôi hướng dẫn các mô hình ngôn ngữ lớn tạo ra dữ liệu huấn luyện hiệu quả, thường không gây ra mối quan tâm đạo đức.

[Phần tài liệu tham khảo được dịch tiếp theo...]

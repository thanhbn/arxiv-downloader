# 2402.11532.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/cot/2402.11532.pdf
# File size: 786611 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Chain-of-Instructions: Compositional Instruction Tuning on
Large Language Models
Shirley Anugrah Hayati*
 Taehee Jung
 Tristan Bodding-Long
Sudipta Kar
 Abhinav Sethy†
Joo-Kyung Kim
 Dongyeop Kang
University of Minnesota
 Amazon
 Grammarly
{hayat023, dongyeop}@umn.edu {jungtaeh, boddint, sudipkar, jookyk}@amazon.com abhinav.sethy@grammarly.com
Abstract
Fine-tuning large language models (LLMs) with a collection
of large and diverse instructions has improved the model’s
generalization to different tasks, even for unseen tasks. How-
ever, most existing instruction datasets include only single in-
structions, and they struggle to follow complex instructions
composed of multiple subtasks. In this work, we propose a
novel concept of compositional instructions called chain-of-
instructions (CoI), where the output of one instruction be-
comes an input for the next like a chain. Unlike the conven-
tional practice of solving single instruction tasks, our pro-
posed method encourages a model to solve each subtask step
by step until the final answer is reached. CoI-tuning (i.e., fine-
tuning with CoI instructions) improves the model’s ability to
handle instructions composed of multiple subtasks as well as
unseen composite tasks such as multilingual summarization.
Overall, our study finds that simple CoI tuning of existing in-
struction data can provide consistent generalization to solve
more complex, unseen, and longer chains of instructions. Our
code and data are available at https://github.com/amazon-
science/chain-of-instructions.
Introduction
Large language models (LLMs) have demonstrated impres-
sive performance in various tasks, from conventional NLP
downstream tasks, such as machine translation and summa-
rization, to open-ended tasks, such as writing an outline for
blog posts and giving tips for presentation, when fine-tuned
on human-like instructions (Ouyang et al. 2022; Wang et al.
2022; Conover et al. 2023; Mishra et al. 2022). These mod-
els excel at single instruction tasks, but their ability to handle
complex and compositional instructions is less explored.
A compositional instruction contains a series of sequen-
tial subtasks, as the output of one subtask becomes the input
of the next one in a chained manner as shown in Figure 1.
We call this problem as Chain-of-Instructions or shortly CoI.
We examine what subtasks can be composed more naturally
than others.
*Work was partially done during internship at Amazon.
†Work was done while at Amazon.
Copyright © 2025, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
Summarization Title 
Generation Style 
Transfer 
I1 I2 I3 Input Output 
O1 O2 Chain-of-Instructions (CoI) 
CoI Number 
Conversion Translation 
Information 
Extraction 
Data to Text XXFigure 1: Chain-of-Instructions (CoI) example. The summa-
rization output can be an input for a title generation subtask;
the output of the title generation can be an input for style
transfer or translation subtasks. Arrow thickness denotes the
probability of instruction composability. X means that these
subtasks cannot be composed due to format mismatch. Ikis
kthinstruction and Okiskthoutput.
In Figure 1, we can see that some tasks can be composed
together, such as input a summary to a title generation task,
while some tasks cannot be composed together, e.g., a sum-
mary as input for a Data-to-Text task. Some tasks have a
higher probability of being able to be composed, such as
generating a title from a summary compared to converting
numbers in a summary since sometimes a summary does
not contain a number. Figure 2 illustrates a more detailed
example of CoI. The given instruction “ Generate a blog-like
title in French ” can be decomposed into three chained sub-
instructions:
1. Generate a title for the given text
2. Convert the style of the title to be similar to a blog post
title
3. Translate the blog post title into French
When these sub-instructions are composed, we call it
a compositional instruction or chain-of-instructions. Our
study investigates whether LLMs can handle compositional
instructions effectively and whether models tuned with com-
positional instructions can be generalized to solve morearXiv:2402.11532v3  [cs.CL]  3 Jan 2025

--- PAGE 2 ---
Instruction Composed Data Size Domain
Chain-of-Instructions (Ours) ✓ ✓ 18k NLP tasks
Self-Instruct (Wang et al. 2023) ✓ ✗ 52k Daily QA-like tasks
Dolly (Conover et al. 2023) ✓ ✗ 15k Daily QA-like tasks
Super-NaturalInstruct (Wang et al. 2022) ✓ ✗ 1.6k NLP tasks
Faith and Fate (Dziri et al. 2023) ✗ ✓ N/A Math, logic, programming
Compositional Semantic (Drozdov et al. 2022) ✗ ✓ N/A CFQ, COGS, Parsing
MuSiQue (Trivedi et al. 2022) ✗ ✓ 24.8k Multi-hop QA
Table 1: A comparison of our work with existing related works. As some previous works do not contribute a new dataset, the
dataset size is shown as N/A. For instruction datasets, data size refers to the number of instructions, not task instances (input-
output pair). More prior work is studied in §.
Summarization Title 
Generation Style 
Transfer 
I1 I2 I3Input Output 
O1 O2Chain-of-Instructions (CoI) 
CoINumber 
Conversion Translation 
Information 
Extraction 
Data to Text 0.84 
0.30
1.000.72
0.99
0.87
1.00
[O2] Output 2:  Delight in 
Ratatouille: Savor the Flavors 
of a Summer Farewell [O1] Output 1: Ratatouille: 
A Taste of Summer's Farewell Input:  Ratatouille is a traditional stew made with summer 
vegetables. When cooking Ratatouille, you can imagine picking up 
fresh vegetables from your yard and ready to embrace Fall. 
[O3] Output 3: Délectez-vous 
avec la Ratatouille : Savourez les 
Saveurs d'un Adieu à l'Été [I1] Instruction 1:  
Generate a title 
[I2] Instruction 2: 
Convert into a blog-style 
titleInstruction:  Generate a blog-like title in French 
[I3] Instruction 3: 
Translate into French Subtask Instructions Chain-of-Instructions (CoI) XX
Figure 2: An example of the Chain-of-Instructions task. The
last output is the expected output of the CoI .
complex ,unseen , orlonger chains of instructions . We first
create a new CoI dataset with our proposed LLM-based
compositionality checker, and then evaluate our model’s per-
formance in handling (1) traditional single instructions and
(2) compositional instructions.
Our work is closely related to other instruction-tuning
works and compositional studies in NLP, as summarized in
Table 1. Wang et al. (2023); Conover et al. (2023); Wang
et al. (2022) propose new instruction datasets, but they only
handle single instruction problems. Although our approach
draws inspiration from Chain-of-Thought (CoT) prompting
(Wei et al. 2022b) or Least-to-Most prompting (Zhou et al.
2022), our CoI is not a prompting technique but a collection
of chained instructions validated by an LLM, showing gen-
eralization in solving complex and compositional problems.
Our contributions are as follows:
• We introduce a novel task called Chain-of-Instructions
(CoI) to examine LLMs’ capabilities in following com-
positional instructions by creating a new benchmark
dataset.
• We develop a framework to automatically construct com-
posed instruction datasets with minimal human supervi-sion. The framework leverages in-context learning on ex-
isting single-instruction datasets to create CoIs.
• We propose a method for enabling LLMs to solve com-
positional tasks in an explainable way. As an example,
a model can generate incremental outputs at each step
of a complex task chain. With CoI-tuning, step-by-step
instruction following becomes easier, especially when
dealing with instructions composed of multiple subtasks.
• We demonstrate through experiments and analysis that
the CoI-tuned model outperforms both individual in-
structions and sequential compositional instructions. By
training on CoI data, the model achieves higher perfor-
mance. This result also generalizes for unseen longer
chain test sets and downstream tasks.
Chain-of-Instructions
Formulation
Compositional instructions contain multiple subtask instruc-
tions where the output from one subtask becomes the in-
put for the next subtask similarlity to a composition func-
tion in math. Thus, we formalize the problem of chain-of-
instructions as follows:
Definition 1 (Chain of Instructions) .Given a tuple of <in-
struction I, input X, output Y>, let I(X) =Yrefer that
an LLM generates output Ywith instruction Iand input
X. A sequence of instructions {I1, ..., I k}is a chain of in-
structions with length kifIi+1◦Ii(Xi) =Yi+1, for all
i∈ {N: 1≤i≤k}.
Automatic Dataset Creation Pipeline
Seed Datatsets We curate a new compositional instruc-
tion dataset from existing single task instruction dataset:
SUPER -NATURAL INSTRUCTIONS (SUP-NATINS) (Wang
et al. 2022). We select S UP-NATINSas the seed dataset be-
cause it contains a wide variety of tasks (1,616 unique tasks)
from 76 categories, including text categorization, summa-
rization, and machine translation. Each category contains
many different NLP tasks. For example, under the text cat-
egorization category, there exist sarcasm detection and po-
liteness classification tasks. Each task in S UP-NATINScon-
tains human-written descriptions that can be considered as
instructions and instances as pairs of inputs and outputs. We

--- PAGE 3 ---
only select tasks with English (1,341 unique tasks) as their
input language to make sure that the chain is connected. For
our single-task instruction tuning data (CoI 1), we randomly
sample 10 input-output pairs, resulting in 13,410 instances.
Instruction Composition Composing two single instruc-
tions poses a challenge due to their lengthy and specific de-
scriptions, and differing output formats. Figure 3 illustrates
a two-step process for creating a compositional instruction
dataset with the help of an LLM as elaborated in the follow-
ing paragraphs. Here we use GPT 3.5 Turbo (Ouyang et al.
2022) because of its reasonable price and at the time, we ex-
amine that the quality of the result is good enough. However,
this data creation procedure can be reproducible with other
strong LLMs as well.
Step 1: Single instruction summarization The task in-
structions in S UP-NATINSare lengthy and detailed, which
may deviate from real human-like instructions. With the
same dataset (S UP-NATINS), Yin et al. (2023) find that 60%
tokens can be removed with comparable, if not better, model
performance. Thus, we use the LLM to shorten each instruc-
tion in the S UP-NATINSdataset. This step reduces the aver-
age number of words in the S UP-NATINSdescriptions from
62.19 to 14.33.
Step 2: Composability check To generate compositional
instructions from single instructions, we perform a two-step
process: (1) validity check and (2) generate the output for
the second (or third) subtask. The validity check is per-
formed to examine whether two subtasks are composable.
We first filter out non-composable tasks with heuristics de-
veloped by the authors’ knowledge (the Heuristics for Va-
lidity Check section in the Appendix). For example, classifi-
cation tasks can only be the last subtask when composing a
pair of tasks. After applying these heuristics, we additionally
check whether LLM can generate the output for the second
instruction based on the input of the first instruction. If so,
we treat the pair as composable.1
For the pairs that pass the validity check, we generate the
new output using the first output and second instruction for
the second task. This generated output serves as the ground
truth for the second subtask in the instruction-tuning phase.
Our approach is a variation of distillation from a larger LLM
as has been done by previous works for different problems
(Gu et al. 2024; Hsieh et al. 2023; West et al. 2022). We
define compositional instructions originating from two in-
structions as CoI 2and those originating from three instruc-
tions CoI 3. CoI 3is created by chaining two CoI 2s if there
exists I x◦Iyand I y◦Iz, resulting in CoI 3= Ix◦Iy◦Iz. The
same method is applied for creating longer chains such as
CoI 4and CoI 5.
To examine the quality of LLM’s composability check,
we randomly sampled 100 instances and manually inspected
which composed instructions are valid. We find that 75%
are valid composed instructions. For CoI 3, similarly we ran-
domly sampled 100 instances and found that 59% are valid
compositions. Such error rates are often found in LLM-
generated data (Das et al. 2024; Wang et al. 2023).
1Prompt for this step is available in the Appendix.chain length ( σ) train test
1 13,410 -
2 2,993 588
3 2,187 480
4 - 844
5 - 355
Table 2: Dataset statistics per chain length.
CoI Dataset
Table 2 shows the data statistics of CoI datasets. In chain
length 2, we obtain 970 unique category pairs; in chain
length 3, we obtain 418 unique category triplets. In each pair
or triplet, we randomly select at most three instances and di-
vide them into training and testing sets. For the longer chains
(4, 5), we only use them for testing. Please find Appendix
for the detailed statistics.
Figure 4 shows a t-SNE plot when we embed subtask
instructions of frequent CoI 2instructions using Sentence-
BERT (Reimers and Gurevych 2019) with DistilRoberta
(Sanh et al. 2019).2We find generation tasks such as para-
phrasing and question generation can be compiled as both
the first and second subtasks, except for problems involv-
ing specific input formats, such as code to text or data to
text, which can only be compiled as the second subtask. On
the other hand, close-ended problems (e.g., POS tagging or
grammar error detection) mostly appear as the second sub-
task.
Experiment Setup
CoI models We fine-tune the base models of Alpaca-
7B (Taori et al. 2023) and Mistral-7B-Instruct (Jiang
et al. 2023). Since both models are open-sourced single
instruction-tuned models which are widely used, they are
suitable to be compared with CoI-tuned models.
Baselines
• Off-the-shelf version of Alpaca-7B (Taori et al. 2023)
model and Mistral-7B-Instruct model without fine-tuning
(Base).
• The same non-finetuned Alpaca and Mistral with chain-
of-thought prompting (Wei et al. 2022b) (CoT) with
seven-shot demonstrations and least-to-most prompting
(Zhou et al. 2022) (LtM).
• Fine-tuned base models with a subset of single-
instruction S UP-NATINSdataset (CoI 1).
Metrics For our evaluation metric, we report R OUGE -L
(Lin 2004), following Wang et al. (2022) and LLM (gpt-4o-
mini) as a preference judge. R OUGE can be used to assess
various text generation tasks and using LLM as a judge has
been widely adopted in NLP research (Liu et al. 2023; Fu
et al. 2024). We also have human evaluation to perform blind
pairwise comparison between the outputs from the baseline
and from our best CoI models.
2We only select instruction pairs that appear more than 7 times,
and 9 is a max number of occurrences in CoI 2dataset.

--- PAGE 4 ---
Summarized 
Instruction 1 Instruction 1 
Summarize Instruction 2 
Summarized 
Instruction 2 
Step 2: Composability Check ✅
STOP 
Step 1: Single instruction 
summarization Our Dataset: 
Chain-of-Instructions 
Generate 
Validity Check 
Summarized 
Instruction 2 
Output 1 SUP-NATINS
Instruction 2 Input 2 Output 2 Instruction 1 Input 1 Output 1 
Input 1 Summarized 
Instruction 1 
Summarized 
Instruction 2 Output 1 
Generated Output 2 
Generated Output 2 Chained with validity check CoI Dataset 
❌
Figure 3: Data creation for CoI 2. We use an LLM for both instruction summarization and composability check. The right column
shows an example instance of our chain-of-instruction dataset. Output 1 in Step 2 comes from the original S UPNATINST data.
Code to Text 
Data to Text Question Generation 
Question 
Rewriting 
Grammar Error Detection Coherence 
Classiﬁcation 
POS Tagging Summarization Paraphrasing Information 
Extraction 
Text Completion Text Quality 
Evaluation 
Keyword Tagging Sentence 
Perturbation 
Sentence Composition 
Explanation Text to Code Story 
Composition 
Title 
Generation Answer 
Veriﬁcation 
second subtask instruction ﬁrst subtask instruction 
Figure 4: T-SNE of sentence embeddings for most frequent
compositional instructions with CoI 2.
Test sets To assess the compositionality of our models, we
prepare three types of evaluation suites.
•CoI Test set For the compositional instruction evalua-
tion, we tested the models on CoI test sets with σ=
{2,3,4,5}where σis a chain length.
•BIG-Bench Hard For the single instruction test set, we
use BIG-Bench Hard (Suzgun et al. 2022), a collection
of 27 challenging tasks, such as date understanding and
evaluating the truth value of Boolean expressions, and
each task has ≤250 instances. BIG-Bench Hard sub-
set enables us to evaluate the model’s performance on
diverse and challenging NLP tasks with clear single in-
structions and associated input-output pairs.
•Downstream Task In addition to CoI test sets, we ex-
amine the usefulness of CoI on the downstream task
of multilingual summarization using WikiLingua (Lad-
hak et al. 2020), which is a multilingual dataset basedMistral Alpaca
Base CoI Base CoI
Test Set: CoI 2
Subtask 1 1.32 90.50 13.98 84.16
Subtask 2 2.40 49.21 7.02 45.57
Test Set: CoI 3
Subtask 1 18.04 81.49 9.56 91.77
Subtask 2 6.82 68.65 2.13 71.67
Subtask 3 6.93 32.73 3.30 35.52
Table 3: R OUGE -L results on intermediate tasks. CoI models
refer to best models of CoI: CoI 12model if the test set=CoI 2
and CoI 123model if the test set=CoI 3.
on WikiHow3for abstractive summarization in 18 lan-
guages. WikiHow articles provide step-by-step instruc-
tions to complete procedural tasks on different topics,
and each step includes a one-sentence summary as well.
In our experiment, we select source-target language pairs
; English-to-French ( WikiLingua-en-fr ) and Spanish-to-
English ( WikiLingua-es-en ) and randomly sample 300
test instances for each. Given an input content from
source language Lsrc, we aim to generate a summary
in target language Ltgt. This task is similar to a 2-
instruction problem as we summarize first and then trans-
late. Note that CoI training data only contains transla-
tion tasks from English to Punjabi, German, and Catalan,
thus, selected source-target pairs are unseen in CoI train-
ing set.
Results
We conduct experiments to measure the performance of CoI-
tuned models on our compositional instructions (§), and the
3https://www.wikihow.com

--- PAGE 5 ---
ModelCoI2-test CoI3-test BBH
Mistral Alpaca Mistral Alpaca Mistral Alpaca
Baselines
Base 24.93 24.95 23.66 20.99 8.51 14.36
CoT 16.61 23.82 16.90 20.09 5.84 17.05
LtM 15.07 23.54 16.41 19.79 3.99 3.99
CoI1 39.72 32.32 29.62 21.75 27.68 28.74
Chain-of-Instructions Models
CoI2 60.43 62.04 48.31 48.23 10.65 12.11
CoI3 33.63 31.62 60.03 47.03 5.78 7.00
CoI12 70.76 67.50 59.84 50.23 24.44 28.80
CoI123 45.16 67.12 61.61 67.49 29.39 27.57
Table 4: R OUGE -L results on compositional instruction test
sets and BIG-Bench Hard (BBH). Base refers to the non-
fine-tuned base models, CoT = chain-of-thought prompting
on base models, LtM = least-to-most prompting on base
models. The best scores are marked as bold .
generalization capability to difficult single instructions (§),
and longer-chain instructions σ={4,5}(§), and the appli-
cation to an existing downstream task (§). We also conduct
an ablation study to see if the correctness of second and third
subtask outputs matter in the Table 9 in Appendix. We see
degrading performance of models fine-tuned with incorrect
outputs, showing the importance to have the correct output
for the subtasks during training.
Performance on In-domain Composite Tasks
(CoI 2,3)
Automatic metric As we evaluate our CoI models’ perfor-
mance against the baselines on multi-CoI test sets, we find
that both Mistral and Alpaca fine-tuned on CoI 12instruc-
tions perform the best for CoI 2-test (Table 4)4. Similarly,
for CoI 3-test, both CoI 123Mistral and Alpaca perform the
best. All models fine-tuned on compositional instructions
generally outperform the baselines, except for CoI 3-tuned
Alpaca. This model performs slightly worse than the CoI 1-
tuned Alpaca on CoI 2test set. We hypothesize that this hap-
pens because instructions in CoI 3become very long, thereby
it becomes harder for the model to generalize without CoI 2
and CoI 1examples. As a result, models only fine-tuned on
CoI 3tend to generate long sentences with hallucinations as
in Table 5.
In the LLM-as-a-judge experiment, we evaluate the per-
formance of the best CoI models on CoI 2-test and CoI 3-
test against the best baseline, CoI 1. On CoI 2-test, the LLM
prefers 69.90% of Alpaca CoI 12’s outputs and 70.92% of
Mistral CoI 12’s outputs over the baseline. Similarly, on
CoI 3-test, the LLM favors Alpaca CoI 123’s outputs and
Mistral CoI 123’s outputs over the baseline by 81.04% and
60.00%, respectively.
4Fine-tuning details in Appendix.
0102030405060708090
CoI2-test CoI3-test CoI2-test CoI3-test
Alpaca Mistral
Prefer CoIPrefer CoIPrefer CoIPrefer CoI
nonenonenonenoneFigure 5: Human evaluation results. "Prefer CoI" refers to
the percentage of CoI outputs preferred by humans; “none”
refers to when humans think the outputs for both first and
second subtasks are incorrect.
CoI Results per Subtasks We examine how CoI models
perform for each subtask in the compositional instruction.
To do this, we compare the results from the best version of
CoI (CoI 12for CoI 2test set, CoI 123for CoI 3test set) against
the non-finetuned baseline models. Since there is no clear
boundary to distinguish the first subtask output and the sec-
ond subtask output in the baseline’s outputs, we use an LLM
to separate the responses. Given the subtask instruction and
the output, we ask the LLM to decide which span of the out-
put text responds to the subtask instruction. To remove the
possibility of LLM’s hallucination being counted as part of
the output, we only include LLM’s output span when it ap-
pears in the baseline’s output. When LLM deems that the
output is incorrect, we assign R OUGE = 0 because this out-
put could refer to the first subtask or second subtask.
Table 3 and Table 11 show results of CoI models and base-
line on CoI 2and CoI 3test sets. In general, CoI models out-
perform the baseline for both test sets, with the best results
on the first subtask and then followed by the second subtask
and the third subtask. However, it is interesting to see that
CoI’s performance on the second subtask for CoI 3test set
is higher than CoI’s performance on the second subtask for
CoI 2. We conjecture that it happens because the previous
subtasks can be easier to solve or knowing the subsequent
subtask helps improving the performance.
Human evaluation We randomly sample 200 instances
from CoI 2-test and CoI 3-test for both Mistral and Alpaca
and ask 8 computer science students with NLP knowledge to
rate the output. We show 25 sets of instruction, input, base-
line output, and CoI output to each annotator. The order of
the outputs is randomized. Each annotator then selects the
output they prefer. Figure 5 depicts the percentage of CoI
outputs that humans prefer vs. when none of the outputs are
preferred. Outputs from CoI-tuned models are preferred for
all test sets for both models.

--- PAGE 6 ---
Instruction: Simplify the given sentence by paraphrasing it.
and then Determine if the paraphrased sentence has proper punctuation with True or False.
Input: many of the churches work together for town-wide projects under the banner of "churches together in steve-
nage".
Correct output: Task 1 output and task 2 input: many of the churches work together for projects across the town
under the slogan of “churches together in stevenage”. Task 2 output: False
Model Output ROUGE -L
CoI1 many of the churches work together for town wide projects under the banner of “ churches 75.00
together in stevenage ”.
CoI2 Task 1 output and task 2 input: many of the churches work together for projects across the 100
town under the slogan of “ churches together in stevenage ”. Task 2 output: False
CoI3 1 output and 2 input: many of the churches work together for projects across the town under the 43.75
slogan of “ churches together in stevenage ”. 2 output and 3 input: The pronoun ’them’ refers to
the noun phrase ’many of the churches’ because the sentence states that ’they’ work together
for
projects across the town. This coreference is justified by the knowledge that the churches are
the ones that are working together. 3 output: False
CoI12 1 output and 1 input: many of the churches work together for projects across the town under the 85.71
slogan of “ churches together in stevenage ”. 2 output: False
CoI123 Task 1 output and task 2 input: many of the churches work together for projects across the town 100
under the slogan of “ churches together in stevenage ”. Task 2 output: False
Table 5: Example outputs from different CoI-tuned Alpaca on a 2-instruction test instance.
010203040506070
Base CoI-1 CoI-12 CoI-123
2 3 4 5
Figure 6: R OUGE -L (x-axis) on CoI test sets σ= 2,3,4,5
for various Alpaca models (y-axis). Base refers to the non-
fine-tuned Alpaca.
Generalization to Unseen Single Tasks
To assess whether adding compositional instructions helps
improve the model’s performance on unseen and difficult
single instruction tasks, we tested CoI-tuned models on BIG-
Bench Hard (BBH). CoI 123-tuned Mistral performs the best
(ROUGE : 29.39) as shown in Table 4. For Alpaca, the model
fine-tuned on CoI 12is also better than the baseline and
achieves a higher R OUGE score of 28.80. This confirms that
having compositional instructions helps the model to under-
stand hard single instruction problems as well.
Generalization to Longer Chains (CoI 4,5)
In this experiment, we examine whether our CoI models can
generalize to longer chains. We run inference on CoI 4andCoI 5test sets using CoI 1, CoI 12, and CoI 123-tuned Alpaca.5
As shown in Figure 6, longer chains ( σ= 2,3) in the train-
ing set help the model to understand unseen longer chain
(σ= 4,5) in the test set as well. Moreover, the performance
does not drop as high as CoI 1or the baseline non-fine-tuned
models that do not learn the chaining reasoning. We posit
that the knowledge of compositional instructions in the train-
ing set, even though the length of the chain is shorter than 4
or 5, still helps the model to understand the composed tasks.
Generalization to Downstream Composite Tasks
For this experiment, we use CoI 12because it shows the high-
est R OUGE -L on 2-instruction problem. For the baseline, we
use non-finetuned Alpaca and Mistral. We evaluate the per-
formance of the models using four metrics below.
•ROUGE -L (all) the R OUGE score of the summary of the
whole generated output.
•ROUGE -L (src) the R OUGE score only from the sum-
mary in the source language.
•ROUGE -L (tgt) the R OUGE score only from the sum-
mary in the target language.
•#valid outputs number of valid summaries in the source
and the target languages are generated because some-
times the model may not generate them properly.
Table 6 shows the results for our downstream task experi-
ments. For the English-to-French summarization task, CoI 12
can generate more valid target outputs than the baselines.
Moreover, CoI 12obtains higher R OUGE for both source and
5Mistral results are in Table 10 in Appendix .

--- PAGE 7 ---
Metric Mistral Alpaca
Base CoI 12 Base CoI 12
English to French
ROUGE -L (all) 8.03 10.97 5.78 8.90
ROUGE -L (src) 10.68 15.66 3.84 12.71
ROUGE -L (tgt) 7.45 10.93 5.46 7.96
#valid src outputs 206 295 126 228
#valid tgt outputs 212 295 221 228
Spanish to English
ROUGE -L (all) 11.22 12.43 7.87 10.39
ROUGE -L (src) 0.07 4.85 2.47 1.87
ROUGE -L (tgt) 11.22 12.30 7.68 7.13
#valid src outputs 1 290 80 150
#valid tgt outputs 300 290 240 150
Table 6: Results of the multilingual summarization task on
300 instances. Base refers to non-fine-tuned baseline, src is
source language, and tgt is target language.
target summaries than the baselines. For the Spanish-to-
English summarization task, CoI 12Mistral outperforms the
baseline for all R OUGE -L scores, but Alpaca fails to have
better R OUGE -L (src) and R OUGE -L (tgt) against the base-
line.
In general, CoI performs better in English-to-French sum-
marization compared to Spanish-to-English summarization
because our training instances contain a translation task
from English to other languages (Punjabi, German, and
Catalan), even though the target language of the translation
task in the training set is not French. On the other hand, we
see poor performance in Spanish summaries across all mod-
els, possibly due to the lack of Spanish as the first subtask in
training datasets. We conjecture this issue could be resolved
if we add more Spanish tasks during the fine-tuning stage.
Related Work
Instruction tuning There has been a notable surge in re-
search focused on fine-tuning LLMs using human instruc-
tions. Efrat and Levy (2020) examined LLMs’ ability to
follow natural language instructions compared to crowd-
workers. Wei et al. (2022a); Sanh et al. (2021) have trans-
formed NLP task descriptions into human-like language
instructions and showed that LLMs fine-tuned with those
instructions have generalizable capability toward unseen
tasks (Chung et al. 2024). Subsequently, many studies have
emerged to create new instruction datasets aimed at train-
ing models in instruction-tuning paradigm: some instruc-
tion datasets are fully written by humans (Wang et al. 2022;
Conover et al. 2023), the others are written with the help
of LLMs (Honovich et al. 2023; Wang et al. 2023; Taori
et al. 2023); some instructions are NLP-specific (Mishra
et al. 2022; Wang et al. 2022; Weller et al. 2020), and the
others are designed to respond to general-purpose instruc-
tions (Ouyang et al. 2022; Wang et al. 2023). These prior
studies only work on single instruction datasets, so we con-struct a new compositional dataset upon Wang et al. (2022)’s
SUPER -NATURAL INSTRUCTION . Our work is also related
to several past works which have leveraged LLMs to gen-
erate training data (Schick and Schütze 2021), and some of
them specifically use LLMs for generating instruction data
(Peng et al. 2023; Shao et al. 2023). Nevertheless, our CoI
data generation framework differs from previous works as
we use LLMs to determine the composability of individ-
ual instructions, and then generate responses for subsequent
subtask instructions.
Compositional problems in NLP Several NLP work have
investigated the capability of Transformer model on com-
positional problems including algorithm and math prob-
lems (Dziri et al. 2023), compositional semantics (Drozdov
et al. 2022), and multi-hop question-answering (QA) tasks
(Trivedi et al. 2022). Dziri et al. (2023) highlight how Trans-
former models often struggle with compositional mathemat-
ics computation or program executions (Nye et al. 2022;
Saparov and He 2022). Drozdov et al. (2022) introduce a
new prompting method which first decomposes the compo-
sitional questions or sentences (Keysers et al. 2019; Kim and
Linzen 2020), then sequentially predicts the answers to sub-
problems, and finally generating the final output. Composi-
tionality in NLP is closely related with multi-hop QA prob-
lems with compositional questions where the answers from
sub-questions are needed to answer the main question (Yang
et al. 2018; Ho et al. 2020; Trivedi et al. 2022). Qiu et al.
(2022) have shown how a model with compositional latent
structure improves large language models’ performance on
compositional generalization tasks through synthethic data
augmentation. CoI is most related to Aksu et al. (2023) as
they work on dealing with compositional tasks for dialogue
systems. However, their definition of “compositional task”
is different from ours as they do not require the output of
one subtask is shown to the next subtask. Meanwhile, in our
CoI, the outputs from the previous subtasks become the next
subtask inputs.
Conclusion and Future Work
In this work, we propose a new task called Chain-of-
Instructions and develop a dataset for building models to
solve the task. We introduce an automatic pipeline on how
to build our dataset and demonstrate the usefulness of our
CoI-tuned models on the tasks of the generated dataset and
downstream tasks. Since human language is complex and
an instruction may actually be composed of subtasks, it is
important to have a model that can deal with compositional
instructions, especially as we show that models fine-tuned
only on single instructions never outperform the CoI-tuned
models on multi-instruction tasks. For future work, we con-
sider looking into instruction decomposition in addition to
the instruction composition problem. We also recommend
trying out more tasks to be composed besides those from
SUPER NATURAL INSTRUCTION .
Acknowledgements
We would like to thank members of the MinnesotaNLP lab
for their feedback and intellectual support.

--- PAGE 8 ---
References
Aksu, T.; Hazarika, D.; Mehri, S.; Kim, S.; Hakkani-Tür,
D.; Liu, Y .; and Namazifar, M. 2023. CESAR: Automatic
Induction of Compositional Instructions for Multi-turn Di-
alogs. In EMNLP .
Chung, H. W.; Hou, L.; Longpre, S.; Zoph, B.; Tay, Y .; Fe-
dus, W.; Li, Y .; Wang, X.; Dehghani, M.; Brahma, S.; Web-
son, A.; Gu, S. S.; Dai, Z.; Suzgun, M.; Chen, X.; Chowd-
hery, A.; Castro-Ros, A.; Pellat, M.; Robinson, K.; Valter,
D.; Narang, S.; Mishra, G.; Yu, A.; Zhao, V .; Huang, Y .;
Dai, A.; Yu, H.; Petrov, S.; Chi, E. H.; Dean, J.; Devlin, J.;
Roberts, A.; Zhou, D.; Le, Q. V .; and Wei, J. 2024. Scal-
ing Instruction-Finetuned Language Models. Journal of Ma-
chine Learning Research , 25(70): 1–53.
Conover, M.; Hayes, M.; Mathur, A.; Xie, J.; Wan, J.;
Shah, S.; Ghodsi, A.; Wendell, P.; Zaharia, M.; and Xin, R.
2023. Free Dolly: Introducing the World’s First Truly Open
Instruction-Tuned LLM.
Das, D.; De Langis, K.; Martin, A.; Kim, J.; Lee, M.; Kim,
Z. M.; Hayati, S. A.; Owan, R.; Hu, B.; Parkar, R.; et al.
2024. Under the Surface: Tracking the Artifactuality of
LLM-Generated Data. arXiv preprint arXiv:2401.14698 .
Drozdov, A.; Schärli, N.; Akyürek, E.; Scales, N.; Song, X.;
Chen, X.; Bousquet, O.; and Zhou, D. 2022. Compositional
Semantic Parsing with Large Language Models. In ICLR .
Dziri, N.; Lu, X.; Sclar, M.; Li, X. L.; Jian, L.; Lin, B. Y .;
West, P.; Bhagavatula, C.; Bras, R. L.; Hwang, J. D.; Sanyal,
S.; Welleck, S.; Ren, X.; Ettinger, A.; Harchaoui, Z.; and
Choi, Y . 2023. Faith and Fate: Limits of Transformers on
Compositionality. In NeurIPS .
Efrat, A.; and Levy, O. 2020. The turking test: Can
language models understand instructions? arXiv preprint
arXiv:2010.11982 .
Fu, J.; Ng, S.-K.; Jiang, Z.; and Liu, P. 2024. GPTScore:
Evaluate as You Desire. In Duh, K.; Gomez, H.; and
Bethard, S., eds., Proceedings of the 2024 Conference of the
North American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies (Volume
1: Long Papers) , 6556–6576. Mexico City, Mexico: Associ-
ation for Computational Linguistics.
Gu, Y .; Dong, L.; Wei, F.; and Huang, M. 2024. MiniLLM:
Knowledge Distillation of Large Language Models. In
ICLR .
Ho, X.; Duong Nguyen, A.-K.; Sugawara, S.; and Aizawa,
A. 2020. Constructing A Multi-hop QA Dataset for Com-
prehensive Evaluation of Reasoning Steps. In Scott, D.;
Bel, N.; and Zong, C., eds., Proceedings of the 28th Inter-
national Conference on Computational Linguistics , 6609–
6625. Barcelona, Spain (Online): International Committee
on Computational Linguistics.
Honovich, O.; Scialom, T.; Levy, O.; and Schick, T. 2023.
Unnatural Instructions: Tuning Language Models with (Al-
most) No Human Labor. In Rogers, A.; Boyd-Graber, J.; and
Okazaki, N., eds., Proceedings of the 61st Annual Meeting
of the Association for Computational Linguistics (Volume 1:
Long Papers) , 14409–14428. Toronto, Canada: Association
for Computational Linguistics.Hsieh, C.-Y .; Li, C.-L.; Yeh, C.-k.; Nakhost, H.; Fujii, Y .;
Ratner, A.; Krishna, R.; Lee, C.-Y .; and Pfister, T. 2023. Dis-
tilling Step-by-Step! Outperforming Larger Language Mod-
els with Less Training Data and Smaller Model Sizes. In
Rogers, A.; Boyd-Graber, J.; and Okazaki, N., eds., Find-
ings of the Association for Computational Linguistics: ACL
2023 , 8003–8017. Toronto, Canada: Association for Com-
putational Linguistics.
Jiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.;
Chaplot, D. S.; Casas, D. d. l.; Bressand, F.; Lengyel, G.;
Lample, G.; Saulnier, L.; et al. 2023. Mistral 7B. arXiv
preprint arXiv:2310.06825 .
Keysers, D.; Schärli, N.; Scales, N.; Buisman, H.; Furrer,
D.; Kashubin, S.; Momchev, N.; Sinopalnikov, D.; Stafiniak,
L.; Tihon, T.; et al. 2019. Measuring Compositional Gener-
alization: A Comprehensive Method on Realistic Data. In
International Conference on Learning Representations .
Kim, N.; and Linzen, T. 2020. COGS: A Compositional
Generalization Challenge Based on Semantic Interpretation.
In Webber, B.; Cohn, T.; He, Y .; and Liu, Y ., eds., Proceed-
ings of the 2020 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP) , 9087–9105. Online:
Association for Computational Linguistics.
Ladhak, F.; Durmus, E.; Cardie, C.; and McKeown, K. 2020.
WikiLingua: A New Benchmark Dataset for Cross-Lingual
Abstractive Summarization. In Cohn, T.; He, Y .; and Liu,
Y ., eds., Findings of the Association for Computational Lin-
guistics: EMNLP 2020 , 4034–4048. Online: Association for
Computational Linguistics.
Lin, C.-Y . 2004. ROUGE: A Package for Automatic Evalu-
ation of Summaries. In Text Summarization Branches Out ,
74–81. Barcelona, Spain: Association for Computational
Linguistics.
Liu, Y .; Iter, D.; Xu, Y .; Wang, S.; Xu, R.; and Zhu, C. 2023.
G-Eval: NLG Evaluation using Gpt-4 with Better Human
Alignment. In Bouamor, H.; Pino, J.; and Bali, K., eds., Pro-
ceedings of the 2023 Conference on Empirical Methods in
Natural Language Processing , 2511–2522. Singapore: As-
sociation for Computational Linguistics.
Mishra, S.; Khashabi, D.; Baral, C.; and Hajishirzi, H. 2022.
Cross-Task Generalization via Natural Language Crowd-
sourcing Instructions. In Muresan, S.; Nakov, P.; and Villav-
icencio, A., eds., Proceedings of the 60th Annual Meeting
of the Association for Computational Linguistics (Volume 1:
Long Papers) , 3470–3487. Dublin, Ireland: Association for
Computational Linguistics.
Nye, M.; Andreassen, A. J.; Gur-Ari, G.; Michalewski, H.;
Austin, J.; Bieber, D.; Dohan, D.; Lewkowycz, A.; Bosma,
M.; Luan, D.; et al. 2022. Show Your Work: Scratchpads for
Intermediate Computation with Language Models. In Deep
Learning for Code Workshop .
Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.;
Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.;
et al. 2022. Training language models to follow instructions
with human feedback. In NeurIPS , 27730–27744.
Peng, B.; Li, C.; He, P.; Galley, M.; and Gao, J.

--- PAGE 9 ---
2023. Instruction tuning with gpt-4. arXiv preprint
arXiv:2304.03277 .
Qiu, L.; Shaw, P.; Pasupat, P.; Nowak, P.; Linzen, T.; Sha, F.;
and Toutanova, K. 2022. Improving Compositional Gener-
alization with Latent Structure and Data Augmentation. In
NAACL , 4341–4362.
Reimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sen-
tence Embeddings using Siamese BERT-Networks. In Inui,
K.; Jiang, J.; Ng, V .; and Wan, X., eds., EMNLP-IJCNLP ,
3982–3992. Hong Kong, China: Association for Computa-
tional Linguistics.
Sanh, V .; Debut, L.; Chaumond, J.; and Wolf, T. 2019. Dis-
tilBERT, a distilled version of BERT: smaller, faster, cheaper
and lighter. arXiv preprint arXiv:1910.01108 .
Sanh, V .; Webson, A.; Raffel, C.; Bach, S.; Sutawika, L.;
Alyafeai, Z.; Chaffin, A.; Stiegler, A.; Raja, A.; Dey, M.;
et al. 2021. Multitask Prompted Training Enables Zero-Shot
Task Generalization. In International Conference on Learn-
ing Representations .
Saparov, A.; and He, H. 2022. Language Models Are
Greedy Reasoners: A Systematic Formal Analysis of Chain-
of-Thought. In The Eleventh International Conference on
Learning Representations .
Schick, T.; and Schütze, H. 2021. Generating Datasets with
Pretrained Language Models. In Moens, M.-F.; Huang,
X.; Specia, L.; and Yih, S. W.-t., eds., Proceedings of the
2021 Conference on Empirical Methods in Natural Lan-
guage Processing , 6943–6951. Online and Punta Cana, Do-
minican Republic: Association for Computational Linguis-
tics.
Shao, Z.; Gong, Y .; Shen, Y .; Huang, M.; Duan, N.; and
Chen, W. 2023. Synthetic prompting: Generating chain-of-
thought demonstrations for large language models. In ICML .
Suzgun, M.; Scales, N.; Schärli, N.; Gehrmann, S.; Tay,
Y .; Chung, H. W.; Chowdhery, A.; Le, Q. V .; Chi, E. H.;
Zhou, D.; et al. 2022. Challenging BIG-Bench Tasks and
Whether Chain-of-Thought Can Solve Them. In ACL Find-
ngs, 13003–13051.
Taori, R.; Gulrajani, I.; Zhang, T.; Dubois, Y .; Li, X.;
Guestrin, C.; Liang, P.; and Hashimoto, T. B. 2023. Stanford
Alpaca: An Instruction-following LLaMA model. https:
//github.com/tatsu-lab/stanford_alpaca.
Trivedi, H.; Balasubramanian, N.; Khot, T.; and Sabharwal,
A. 2022. MuSiQue: Multihop Questions via Single-hop
Question Composition. Transactions of the Association for
Computational Linguistics , 10: 539–554.
Wang, Y .; Kordi, Y .; Mishra, S.; Liu, A.; Smith, N. A.;
Khashabi, D.; and Hajishirzi, H. 2023. Self-Instruct: Align-
ing Language Models with Self-Generated Instructions. In
ACL, 13484–13508.
Wang, Y .; Mishra, S.; Alipoormolabashi, P.; Kordi, Y .;
Mirzaei, A.; Naik, A.; Ashok, A.; Dhanasekaran, A. S.;
Arunkumar, A.; Stap, D.; Pathak, E.; Karamanolakis, G.;
Lai, H.; Purohit, I.; Mondal, I.; Anderson, J.; Kuznia, K.;
Doshi, K.; Pal, K. K.; Patel, M.; Moradshahi, M.; Parmar,
M.; Purohit, M.; Varshney, N.; Kaza, P. R.; Verma, P.; Puri,R. S.; Karia, R.; Doshi, S.; Sampat, S. K.; Mishra, S.;
Reddy A, S.; Patro, S.; Dixit, T.; and Shen, X. 2022. Super-
NaturalInstructions: Generalization via Declarative Instruc-
tions on 1600+ NLP Tasks. In EMNLP , 5085–5109.
Wei, J.; Bosma, M.; Zhao, V .; Guu, K.; Yu, A. W.; Lester,
B.; Du, N.; Dai, A. M.; and Le, Q. V . 2022a. Finetuned
Language Models are Zero-Shot Learners. In ICLR .
Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.;
Chi, E.; Le, Q. V .; Zhou, D.; et al. 2022b. Chain-of-thought
prompting elicits reasoning in large language models. In
NeurIPS , volume 35, 24824–24837.
Weller, O.; Lourie, N.; Gardner, M.; and Peters, M. E. 2020.
Learning from Task Descriptions. In Webber, B.; Cohn, T.;
He, Y .; and Liu, Y ., eds., Proceedings of the 2020 Confer-
ence on Empirical Methods in Natural Language Process-
ing (EMNLP) , 1361–1375. Online: Association for Compu-
tational Linguistics.
West, P.; Bhagavatula, C.; Hessel, J.; Hwang, J.; Jiang, L.;
Le Bras, R.; Lu, X.; Welleck, S.; and Choi, Y . 2022. Sym-
bolic Knowledge Distillation: from General Language Mod-
els to Commonsense Models. In Carpuat, M.; de Marneffe,
M.-C.; and Meza Ruiz, I. V ., eds., Proceedings of the 2022
Conference of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language Tech-
nologies , 4602–4625. Seattle, United States: Association for
Computational Linguistics.
Yang, Z.; Qi, P.; Zhang, S.; Bengio, Y .; Cohen, W.; Salakhut-
dinov, R.; and Manning, C. D. 2018. HotpotQA: A Dataset
for Diverse, Explainable Multi-hop Question Answering. In
Riloff, E.; Chiang, D.; Hockenmaier, J.; and Tsujii, J., eds.,
Proceedings of the 2018 Conference on Empirical Methods
in Natural Language Processing , 2369–2380. Brussels, Bel-
gium: Association for Computational Linguistics.
Yin, F.; Vig, J.; Laban, P.; Joty, S.; Xiong, C.; and Wu, C.-S.
2023. Did You Read the Instructions? Rethinking the Ef-
fectiveness of Task Definitions in Instruction Learning. In
Rogers, A.; Boyd-Graber, J.; and Okazaki, N., eds., Pro-
ceedings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) , 3063–
3079. Toronto, Canada: Association for Computational Lin-
guistics.
Zhou, D.; Schärli, N.; Hou, L.; Wei, J.; Scales, N.; Wang,
X.; Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q. V .; et al.
2022. Least-to-Most Prompting Enables Complex Reason-
ing in Large Language Models. In The Eleventh Interna-
tional Conference on Learning Representations .
Appendix
CoI Dataset Statistics
Table 7 shows statistics for CoI. In CoI 2, the numbers of
unique categories for the first subtask and second subtask
are 41 and 67, respectively. There are more different cate-
gories for the last subtask because we set classification prob-
lems can only be the last subtask. There are 970 unique
pairs of categories (e.g., summarization →title generation is
counted as 1 pair). On average, a CoI 2instruction contains

--- PAGE 10 ---
Count
Subtask 1 categories (CoI 2) 41
Subtask 2 categories (CoI 2) 67
#Unique pairs of category 1 →2 970
Avg. #words per instruction 34.25
Subtask 1 categories (CoI 3) 39
Subtask 2 categories (CoI 3) 35
Subtask 3 categories (CoI 3) 61
#Unique pairs of category 1 →2 418
#Unique pairs of category 2 →3 700
#Unique triplets of category 1 →2→3 2148
Avg. #words per instruction 51.00
Training Set Size Test Set Size
CoI1 13,410 CoI2 588
CoI2 2,933 CoI3 480
CoI3 2,187 CoI4 844
CoI12 16,343 CoI5 355
CoI123 18,530
Table 7: Dataset statistics
34.25 words. For CoI 3instances, there are fewer categories
to be the first subtask (39) and second subtask (35) because
we need to guarantee the composability for the whole longer
chain. When we compose the CoI datasets, we select at max
3 instances per pair of categories. We also report train and
test set sizes in Table 7.
Prompting Details
Here are prompting details for our approach.
Summarizing and generalizing a single instruction
•Prompt : ”Given an instruction and a category, simplify
the instruction to have fewer than 30 words and make the
instruction to be more general .
Instruction 1: In this task, you’re given passages that con-
tain mentions of names of people, places, or things. Some
of these mentions refer to the same person, place, or thing.
Your job is to write questions that evaluate one’s under-
standing of such references. Good questions are expected
to link pronouns (she, her, him, his, their, etc.) or other
mentions to people, places, or things to which they may
refer. Do not ask questions that can be answered correctly
without understanding the paragraph or having multiple
answers. Avoid questions that do not link phrases refer-
ring to the same entity. For each of your questions, the
answer should be one or more phrases in the paragraph,
and it should be unambiguous.
Category 1: Question generation
Modified instruction 1: Generate a question given a para-
graph that mentions people, places, or things”
•Number of few-shot demonstrations : 5
Checking compositionality of two instructions and ob-
taining the second output
•Prompt : Decide whether the input is a valid input for the
instruction. An input is valid if the context is relevant to
instruction and we can generate an output given the input
and the instruction. If it is a valid input, generate the out-
put.Instruction: Categorize each of the following instruments
as either string or keyboard: Guitar, Violin, piano, harmo-
nium, cello, accordion, banjo Input: The episode focused
on two people: an elderly hospital doctor (Aleksander Bar-
dini), who lived by himself in the ubiquitous Dekalog
apartment block; and Dorota Geller (Krystyna Janda), a
woman in her 30s who lived in the same building and was
a violinist with the Philharmonic Orchestra.
Answer:
"Valid input":"No", "Reason": "The instruction asks for
categorizing instrument types and the instruction already
contains its input which are guitar, violin, piano, harmo-
nium, cello, accordion, and banjo. Meanwhile the given
input is about a movie episode so it is not relevant to the
instruction.", "Output": ""
•Number of few-shot demonstrations : 5
Making the input type of the second instruction consis-
tent with the output type of the first instruction
•Prompt : You are given an instruction which is composed
of multiple tasks. Modify the following instruction by
first, identify the output1, input2, output2, input3, and so
on related to the subtasks. Then make sure that output1 is
consistent with input2, output2 is consistent with input3
and so on.
Instruction: "Who is the author of the Little Women and
then how many capital letters are in the input?"
Subtask 1: "Who is the author of the Little Women?"
Subtask 2: "How many capital letters are in the input?"
Answer: {"output1:" "author’s name", "input2:": "input",
"modified_instruction": "Who is the author of the Little
Women and then how many capital letters are in the au-
thor’s name?"}
•Number of few-shot demonstrations : 8
Separating outputs for the subtasks from Baseline Out-
puts
•Prompt : You are given an instruction, an input, and a text
output. Decide which part of the text output responds to
the given instruction for the given input. Don’t change
the wording of the text output! The text output may not
correctly answer the instruction. If that’s the case, you
must respond with "Wrong"!
Instruction: instruction
Input: :input
Text Output: : model-generated output
Part of the text responding to the instruction:
•Prompt : You are given an instruction and a text. Decide
which part of the given text responds to the given instruc-
tion. Don’t change the wording of the given text! The
text may not correctly answer the instruction. If that’s the
case, you must respond with "Wrong"!
Instruction: instruction Text:model-generated
output
Part of the text responding to the instruction:
Creating concise-CoI

--- PAGE 11 ---
•Prompt : Summarize the input to a single coherent sen-
tence which contains only 20 words or fewer without
changing the meaning.
Input: "Summarize the article in one sentence. and then
Convert the sentence to a positive sentence with minimal
changes. and then Extract RDF triplets from the given sen-
tence."
Summary: "Create a concise summary with a positive tone
and after that extract RDF triplets from the summary"
•Number of few-shot demonstrations : 2
LLM as a Preference Judge The following is the prompt
for LLM as a preference judge:
Given the following instruction and input and ground truth
output, which generated output follows the instruction more
closely?
Answer only with “A ”if you prefer generated output
A, “B” if you prefer generated output B, “None” if you
prefer none.
Instruction: instruction Input:input Ground truth
output:ground truth output
Generated output A: output from model A Generated out-
put B:output from model B
Fine-tuning Details
Our base models to be fine-tuned are Alpaca-7B and Mistral-
7B-Instruct. We use the training script and set-ups from
Taori et al. (2023)’s code. We fine-tune the whole model
for 3 epochs with deepspeed on a machine with 8 NVIDIA
A100 GPUs, batch size=4, learning rate = 2e-5, weight de-
cay=0, warmup ratio = 0.03, max length = 512. Inference
results are from single runs.
BIG-Bench Hard Examples
Here are some example tasks from BBH along with their
instructions, example input, and example output:
1.Boolean Expressions.
Instruction: Evaluate the truth value of a
random Boolean expression consisting of Boolean
constants (True, False) and basic Boolean
operators (and, or, and not).
Input:not ( True ) and ( True ) is
Output:False
2.Causal Judgment.
Instruction: Given a short story (involving moral,
intentional, or counterfactual analysis),
determine how a typical person would answer
a causal question about the story.
Input:How would a typical person answer each
of the following questions about causation? A
machine is set up in such a way that it will
short circuit if both the black wire and the
red wire touch the battery at the same time.
The machine will not short circuit if just one
of these wires touches the battery. The black
wire is designated as the one that is supposedto touch the battery, while the red wire is
supposed to remain in some other part of the
machine. One day, the black wire and the red
wire both end up touching the battery at the
same time. There is a short circuit. Did the
black wire cause the short circuit? Options:-
Yes - No
Output:No
3.Date Understanding.
Instruction: Given a small set of sentences about a
particular date, answer the provided question
(e.g., “The concert was scheduled to be on
06/01/1943, but was delayed by one day to today.
What is the date yesterday in MM/DD/YYYY?”).
Input:Today is Christmas Eve of 1937. What is
the date tomorrow in MM/DD/YYYY?
Options:
(A) 12/11/1937
(B) 12/25/1937
(C) 01/04/1938
(D) 12/04/1937
(E) 12/25/2006
(F) 07/25/1937
Output:(B)
4.Disambiguation QA.
Instruction: Given a sentence with an “ambigious”
pronoun, either determine whether the sentence
is inherently ambiguous (i.e., the thing that
the pronoun refers to cannot be inferred by
given information) or, if the pronoun can be
implicitly deduced, state the antecedent of the
pronoun (i.e., the noun to which the pronoun
refers).
Input:In the following sentences, explain the
antecedent of the pronoun (which thing the
pronoun refers to), or state that it is
ambiguous.
Sentence: The patient was referred to the
specialist because he had a rare skin
condition.
Options:
(A) The patient had a skin condition
(B) The specialist had a skin condition
(C) Ambiguous
Output:(A)
5.Dyck Languages.
Instruction: Predict the sequence of the closing
parentheses of a Dyck-4 word without its last
few closing parentheses.
Input:Complete the rest of the sequence, making
sure that the parentheses are closed properly.
Input: [ [
Output:] ]
WikiLingua Examples
Here are examples for WikiLingua summarization task.
1.English-to-French summarization
Instruction: Summarize the following English

--- PAGE 12 ---
paragraph and then translate the English
summary into a French summary
Input:Look online at your town or city’s codes,
by-laws or dog legislation. There may be a
code against unruly pets or incessant barking
at night; many places have legislation or
regulations in place that deals specifically
with dogs and/or noise. There might also
be a code covering ignoring requests from
neighbors. Often neighborhood or civil dispute
centers produce small briefs on dog issues,
as they’re rather commonplace complaints. See
if a precedent has already been set in your
neighborhood. You may want to share your
findings with your neighbor to give him or her
one last chance to change before you call the
authorities. If you’re pretty sure it won’t
work, move straight to the next step. Find
out what town hall/council/municipal office
or other relevant authority to call so you
can file a report on your neighbors for a
noise complaint.The authorities will talk to
the dog owner and assess the situation. They
will usually inform you of the outcome.....
English summary: Research your town or city’s
anti-barking laws. Call the relevant authority
to report a noise complaint. Call animal
control to report abuse. Get other neighbors
to file the same complaint. Sue the dog owner
in small claims court.
French summary: Faites des recherches sur les
lois contre les aboiements de chiens dans votre
ville ou localité. Faites appel à l’autorité
compétente pour enregistrer votre plainte pour
nuisance sonore. Appelez le service de contrôle
des animaux pour leur faire part de l’abus.
Persuadez d’autres voisins de déposer la même
plainte. Poursuivez le propriétaire de l’animal
en justice.
2.Spanish-to-English summarization
Instruction: Summarize the following Spanish
paragraph and then translate the Spanish
summary into an English summary
Input:Si bien no deseas gritar, debes hablar lo
bastante alto para que las personas no tengan
que pedirte que repitas lo que dices. Hablar
en voz baja hará que las personas piensen que
eres tímido, que no tienes confianza en lo
que dices y que en realidad no quieres ser
oído de todos modos. Si hablas en voz baja,
no tan solo los demás no podrán escuchar lo
que dices, sino que también harás el papel de
una persona con actitud sumisa, lo que insinúa
lo contrario a una persona con confianza. Por
otra parte, no querrás hablar tan alto que
parezca que les estés hablando a las personas
solo para que te escuchen. Tus palabras deben
atraer por sí solas la atención del público.
Lee tanto como puedas, desde revistas en línea(como Slate or Salon.com) hasta obra literarias
serias (como Ana Karénina). Sabrás más mientras
más leas, del mismo modo, tu vocabulario
también se expandirá. Sin siquiera saberlo,
aprenderás nuevas palabras y comprenderás
nuevas frases y pronto estarás utilizando las
palabras que leíste mientras estés hablando. Si
realmente quieres hablar correctamente, tener
un vocabulario amplio es una necesidad. Esto no
significa que cada vez debas utilizar cincuenta
palabras de cien dólares en tus discursos o
conversaciones diarias...
Spanish summary: Habla con una voz lo bastante
alta para que todos puedan oírte. Expande
tu vocabulario. Evita usar demasiadas jergas.
No tengas miedo de detenerte. Utiliza gestos
solo cuando sea necesario. Sé más conciso.
Repite tus ideas principales. Utiliza ejemplos
concretos para ganarte a tu audiencia.
English summary: Speak loudly enough for
everyone to hear. Expand your vocabulary. Avoid
excessive slang. Don’t be afraid to pause. Use
gestures only when necessary. Be more concise.
Repeat your main points. Use concrete examples
to grab your audience.
Data Generation Details
On average, a task in S UP-NATINShas 3,106 instances. An
example of a <instruction, input, output >tuple is as
follows: <Translate the following English sentence
into French, the food is good, la nourriture
est bonne >. The same instruction can correspond multiple
input-output pairs. Since S UP-NATINScontains tasks in 55
different languages, we only select tasks with English as its
input language or the output language to make sure the chain
is connected. As a result, we only use 1,341 unique tasks out
of 1,616 tasks from S UP-NATINS. For our single-task in-
struction tuning data, we randomly sample 10 combinations
for each input-output pair, resulting in 13,410 instances.
In this step, we random sample one task from each cat-
egory, resulting in 3,024 pairs of two single instructions
which are going to undergo the composability check. After
composability check by LLM, we have 1,115 composable
instruction pairs.
We later expand the dataset. For each valid category in the
first subtask instruction for a compositional instruction with
σ= 2, we randomly sample at most two more subtasks.
Consequently, each category is associated with a maximum
of three distinct tasks, with some categories having only one
task. Then in total, we have 2,933 training instances and 588
test instances for 2-instruction problem and 2,187 training
instances and 480 test instances for the 3-instruction prob-
lem. We also have another variations of training set where
we mix the training instances with 1 and 2 instructions
(CoI 12) and with 1, 2, and 3 instructions (CoI 123).
Specifically, we randomly select one task per category
from S UP-NATINS, resulting in 76 task instructions with
their input and output. Then we apply some heuristics (e.g.,
classification problems cannot be an input for the second or

--- PAGE 13 ---
Single Instruction from S UP-NATINS(Wang et al. 2022)
Task category: Generation
Original instruction: You are given a paragraph about various topics. Your task is to generate a title for the given paragraph.
Simplified instruction: Generate a title
Input: Ratatouille is a traditional stew made with summer vegetables. When cooking Ratatouille, you can...
Output: Ratatouille: A Taste of Summer’s farewell
Task category: Style Transfer
Original instruction: Convert the style of the given text to be suitable for a blog. Please consider the following points...
Simplified instruction: Convert the text into a blog-style text
Input: You can put an arrow on an elbow connector if you use the app.
Output: Hey, there! Ever wondered if you can spice up your elbow connectors with a sleek arrow?
Compositional Instruction (Ours)
Input: Ratatouille is a traditional stew made with summer vegetables. When cooking Ratatouille, you can...
CoI variant: CoI
Instruction: Generate a title and then convert the title into a blog-style title
Output: Ratatouille: A Taste of Summer’s Farewell
Delight in Ratatouille: Savor the Flavors of a Summer Farewell
CoI variant : Concise CoI (C-CoI)
Instruction: Given a paragraph, write a blog-style title
Output: Ratatouille: A Taste of Summer’s Farewell
Delight in Ratatouille: Savor the Flavors of a Summer Farewell
CoI variant : Irrelevant CoI
Instruction: Generate a title and then convert the title into a blog-style title
Output: Ratatouille: A Taste of Summer’s Farewell
Hey, there! Ever wondered if you can spice up your elbow connectors with a sleek arrow?
Table 8: Single instruction examples (top) and compositional instruction example in with CoI variants (bottom). The first
subtask is to “generate a title” and the second subtask is to “convert the text into a blog-style text.” Red text refers to the first
subtask, green text for the second subtask, gray text for the concise compositional instruction. The input for the first task in the
compositional instruction is the same, which is a text about Ratatouille.

--- PAGE 14 ---
third instruction), resulting in 3,024 possible pairs of first
and second instructions.
Heuristics for Validity Check
A list of tasks that cannot be task 1 (and task 2 if σ= 3):
Word Relation Classification, Preposition Prediction, Word
Semantics, Entity Generation, Linguistic Probing, Textual
Entailment, Misc., Sentence Perturbation, Text Categoriza-
tion, Toxic Language Detection, Sentiment Analysis, Com-
monsense Classification, Language Identification, Stereo-
type Detection, Grammar Error Detection, Text Quality
Evaluation, Irony Detection, Spam Classification, Punctua-
tion Error Detection, Coherence Classification, Ethics Clas-
sification, Cause Effect Classification, Dialogue Act Recog-
nition, Sentence Ordering, Discourse Relation Classifica-
tion, Question Understanding, Discourse Connective Identi-
fication, Speaker Identification, Section Classification, Lin-
guistic Probing, Dialogue State Tracking, Answerability
Classification, Coherence Classification, Paper Review, An-
swer Verification, Entity Relation Classification, Speaker
Relation Classification, Stance Detection, Fact Verification,
Text Matching, Intent Identification, Word Relation Classi-
fication.
Downstream Task
To find generated summaries in source and target languages,
for the CoI-tuned models, we use keyword matching and text
processing (e.g., “Task 1 input and task 2 output.”, “Task
2 output”, “1 output”, “2 output”). Finding summaries in
source and target languages from the baseline model is trick-
ier because there is no clear separation between the sen-
tences in the generated output. Thus, we split the first output
and the second output from the baseline is by using a lan-
guage identification model.6If the detected language is the
same with the source language, we label the output as the
source language summary. If the detected language is the
same with the target language, we label the output as the
target language summary.
Full results
Another variant of CoI: Concise CoI We have another
variant of CoI with shorter compositional instructions and
we call this variant as Concise-Co, or C-CoI, (see Table
8). The purpose of training a model with C-CoI dataset is
to examine whether shorter compositional instructions can
perform better. To create this dataset, we perform a 2-shot
prompting on LLM with the following prompt: “ Summarize
the input to a single coherent sentence which contains only
20 words or fewer without changing the meaning. ” The in-
put and output for this C-CoI training instance is the same
as those for CoI.
We have another variant of CoI which we call as irrel-
evant CoI as an ablation study. For the irrelevant CoI, we
use the same instruction and input as CoI, but we assign
a random output from the original benchmarking single-
instruction dataset for the second task rather than the cor-
rect generated output. Thus, the second task’s output is not
6https://pypi.org/project/langdetect/relevant with the first task’s output. Using the examples inin
Table 8, for the irrelevant CoI, the second output is not the
blog-style title about Ratatouille but rather a blog-style text
about adding an arrow to an elbow connector in slides . We
try this irrelevant CoI as another variant to see whether the
correctness of the output from the second task or third task
actually matters for the model improvement. Our finding is
that the correctness for the second and third outputs is im-
portant for compositional test sets even though it does not
affect much for single task problems as shown Table 9.
Does concise CoI instruction help improve performance?
We also show the scores of Concise-CoI in Table 4. For C-
CoI models, we notice that C-CoI 123Mistral consistently
performs better than CoI models for all datasets except
for BBH. Meanwhile, for C-CoI Alpaca, the result is quite
mixed, but interestingly both C-CoI 12and C-CoI 123Alpacas
perform better than CoI 12and CoI 123on BBH, suggesting
that shorter instructions help more on unseen single tasks.
Full Intermediate Results
Table 11 shows how many valid outputs for the first subtasks
and second subtasks from baseline and CoI models.

--- PAGE 15 ---
Word Classiﬁcation:  
Input → word/list of words 
Output → Label Information Extraction:  
Extracting some information/ 
parts from the text 
Translation 
Question Answering 
Question Generation 
Program 
Execution Sentiment Analysis Toxic Language 
Detection Textual Entailment 
Text Matching Misc. Text 
Categorization 
Cause Eﬀect 
Classiﬁcation Title Generation 
Question 
Understanding Fill in The Blank Named Entity 
Recognition 
Commonsense 
Classiﬁcation Coreference 
Resolution 
Keyword Tagging Answerability 
Classiﬁcation Linguistic Probing Dialogue Generation 
Poem Generation 
Text to Code 
Explanation Pos Tagging 
Word Semantics Speaker 
Identiﬁcation Overlap Extraction Data to Text 
Word Analogy 
Answer Veriﬁcation Dialogue Act 
Recognition Language 
Identiﬁcation 
Stereotype 
Detection 
Negotiation 
Strategy Detection 
Coherence 
Classiﬁcation 
Ethics Classiﬁcation Word Relation 
Classiﬁcation Code to Text 
Dialogue State 
Tracking Mathematics Number 
Conversion 
Intent 
Identiﬁcation Section 
Classiﬁcation 
Stance Detection Question 
Decomposition Irony Detection 
Discourse 
Connective 
Identiﬁcation 
Entity Relation 
Classiﬁcation Discourse Relation 
Classiﬁcation 
Speaker Relation 
Classiﬁcation Spelling Error 
Detection Spam Classiﬁcation 
Punctuation Error 
Detection 
Paper Review 
Preposition 
Prediction Text Quality 
Evaluation 
Entity Generation Grammar Error 
Detection 
Information 
Extraction 
Fact Veriﬁcation Summarization Question 
Rewriting Paraphrasing 
Sentence 
Ordering 
Text 
Simpliﬁcation 
Grammar Error 
Correction Sentence 
Compression Wrong Candidate 
Generation 
Sentence 
Composition Text Completion 
Story Composition Sentence Expansion 
Sentence 
Perturbation Common NLP tasks besides 
classiﬁcation/generation Generation:  Non-text to text 
Generation:  Paraphrasing 
(text-to-text, preserve meaning) Generation : no common 
structure 
Miscellaneous Generation:  Free-form 
text-to-text 
Tagging:  Input → text, Output 
→ some tags related to the 
words in the input Text Classiﬁcation:  
Input → text 
Output → Label 
Special Classiﬁcation:  
Input → text requiring certain 
structure 
Output → Label Figure 7: We manually classify task categories from S UP-NATINSinto eleven groups based on their input and output types.
This serves as a heuristic for selecting tasks that are composable through human reasoning.

--- PAGE 16 ---
Model ROUGE -L
Baseline CoI2-test C-CoI 2-test CoI3-test C-CoI 3-test BBH
M A M A M A M A M A
Base 24.93 24.95 23.09 25.12 23.66 20.99 21.55 22.02 8.51 14.36
CoT 16.61 23.82 17.41 24.42 16.90 20.09 17.83 21.35 5.84 17.05
CoI1 39.72 32.32 36.30 28.53 29.62 21.75 27.70 22.63 27.68 28.74
CoI1-long 30.08 22.68 27.90 22.42 21.87 17.82 21.45 18.31 24.01 29.87
Chain-of-Instructions Models
CoI2 60.43 62.04 57.65 56.59 48.31 48.23 48.67 46.97 10.65 12.11
CoI3 33.63 31.62 32.02 29.54 60.03 47.03 56.77 44.36 5.78 7.00
CoI12 70.76 67.50 53.50 46.27 59.84 50.23 41.63 39.23 24.44 28.80
CoI123 45.16 67.12 31.32 44.93 61.61 67.49 29.61 44.40 29.39 27.57
Concise C OI Models
C-CoI 2 59.07 34.59 58.33 42.60 51.34 32.75 49.77 39.43 7.95 12.25
C-CoI 3 33.63 31.28 32.02 29.54 60.03 47.38 56.77 44.36 5.79 7.00
C-CoI 12 59.19 47.36 56.94 47.70 51.07 42.99 46.42 38.16 28.84 31.26
C-CoI 123 69.47 54.74 66.17 51.94 68.97 58.85 58.15 49.60 24.04 28.91
Irrelevant C OI Models
I-CoI 2 45.09 48.56 44.57 47.03 36.02 38.02 35.96 38.24 10.25 21.37
I-CoI 3 33.73 28.64 31.91 27.27 34.16 32.02 33.67 30.42 6.31 6.21
I-CoI 12 53.53 50.05 42.33 37.98 39.42 38.24 31.98 32.10 23.91 27.27
I-CoI 123 54.59 50.60 38.91 36.27 37.26 36.08 26.93 33.59 28.95 28.65
Table 9: Results on compositional instruction test sets and BIG-Bench Hard (BBH). CoT refers to chain-of-thought prompting
with the non-fine-tuned base model. M refers to Mistral 7B-Instruct and A is Alpaca-7B. CoI 1-long refers to the same set of
CoI 1but the instructions are not summarized.
ModelCoI4-test CoI5-test
M A M A
Base 22.03 17.48 20.95 15.79
CoI1 19.18 16.44 15.16 12.87
CoI12 47.36 40.59 37.04 33.05
CoI123 55.24 53.33 46.43 44.87
Table 10: R OUGE -L results on CoI-4,5 test sets.
Metric Mistral Alpaca
Rouge-L Base CoI Base CoI
Test Set: CoI 2
Subtask 1 1.32 90.50 13.98 84.16
Subtask 2 2.40 49.21 7.02 45.57
#valid 1st output 15 588 207 588
#valid 2nd output 33 588 144 588
Test Set: CoI 3
Subtask 1 18.04 81.49 9.56 91.77
Subtask 2 6.82 68.65 2.13 71.67
Subtask 3 6.93 32.73 3.30 35.52
#valid 1st output 259 479 120 480
#valid 2nd output 136 479 45 480
#valid 3rd output 185 463 81 478
Table 11: Results on intermediate tasks. CoI models refer to
best models of CoI: CoI 12if the test set=CoI 2and CoI 123if
the test set=CoI 3

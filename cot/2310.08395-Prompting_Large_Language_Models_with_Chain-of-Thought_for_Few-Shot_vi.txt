# Nhắc nhở các Mô hình Ngôn ngữ Lớn với Chuỗi Suy nghĩ cho Việc Tạo Câu hỏi Cơ sở Tri thức Vài mẫu

Yuanyuan Liang1, Jianing Wang1, Hanlun Zhu1, Lei Wang2
Weining Qian1, Yunshi Lan1∗
1Đại học Sư phạm Đông Trung Quốc, 2Đại học Quản lý Singapore
leonyuany@stu.ecnu.edu.cn, {lygwjn, timberflowing}@gmail.com
lei.wang.2019@phdcs.smu.edu.sg, {wnqian, yslan}@dase.ecnu.edu.cn

## Tóm tắt

Nhiệm vụ Tạo Câu hỏi trên Cơ sở Tri thức (KBQG) nhằm chuyển đổi một dạng logic thành câu hỏi ngôn ngữ tự nhiên. Vì chi phí đắt đỏ của việc chú thích câu hỏi quy mô lớn, các phương pháp KBQG trong các tình huống tài nguyên thấp cần được phát triển khẩn cấp. Tuy nhiên, các phương pháp hiện tại phụ thuộc nhiều vào dữ liệu được chú thích để tinh chỉnh, không phù hợp với việc tạo câu hỏi vài mẫu. Sự xuất hiện của các Mô hình Ngôn ngữ Lớn (LLM) đã cho thấy khả năng tổng quát hóa ấn tượng của chúng trong các nhiệm vụ vài mẫu. Lấy cảm hứng từ việc nhắc nhở Chuỗi Suy nghĩ (CoT), một chiến lược học tập trong ngữ cảnh để suy luận, chúng tôi công thức hóa nhiệm vụ KBQG như một vấn đề suy luận, nơi việc tạo một câu hỏi hoàn chỉnh được chia thành một chuỗi các việc tạo câu hỏi phụ. Phương pháp nhắc nhở được đề xuất của chúng tôi KQG-CoT đầu tiên chọn các dạng logic hỗ trợ từ bộ dữ liệu không có nhãn có tính đến các đặc điểm của dạng logic. Sau đó, chúng tôi xây dựng một lời nhắc đặc thù cho nhiệm vụ để hướng dẫn LLM tạo ra các câu hỏi phức tạp dựa trên các dạng logic được chọn. Để đảm bảo chất lượng lời nhắc hơn nữa, chúng tôi mở rộng KQG-CoT thành KQG-CoT+ thông qua việc sắp xếp các dạng logic theo độ phức tạp của chúng. Chúng tôi tiến hành các thí nghiệm rộng rãi trên ba bộ dữ liệu KBQG công khai. Kết quả cho thấy phương pháp nhắc nhở của chúng tôi liên tục vượt trội so với các đường cơ sở nhắc nhở khác trên các bộ dữ liệu được đánh giá. Đáng chú ý, phương pháp KQG-CoT+ của chúng tôi có thể vượt qua kết quả SoTA vài mẫu hiện có của bộ dữ liệu PathQuestions bằng 18,25, 10,72 và 10,18 điểm tuyệt đối trên BLEU-4, METEOR và ROUGE-L tương ứng.

## 1 Giới thiệu

Nhiệm vụ tạo câu hỏi yêu cầu một hệ thống tạo ra các câu hỏi ngôn ngữ tự nhiên dựa trên ngữ cảnh được cung cấp. KBQG (Guo et al., 2022) là một trong những nhiệm vụ tạo câu hỏi bắt buộc khi ngữ cảnh được cung cấp từ Cơ sở Tri thức (KB) ở dạng logic. KBQG đã thu hút sự quan tâm ngày càng tăng từ cả ngành công nghiệp và học thuật do tiềm năng của nó trong việc tăng cường dữ liệu trong các hệ thống QA (Xiong et al., 2022; Chen et al., 2023) và khả năng hỗ trợ các hệ thống đối thoại trong việc tạo ra các câu hỏi mạch lạc (Lee et al., 2018).

Các nghiên cứu hiện có (Kumar et al., 2019; Ke et al., 2021; Fei et al., 2022; Guo et al., 2022; Chen et al., 2023) cho các nhiệm vụ KBQG chủ yếu sử dụng các phương pháp dựa trên mạng nơ-ron và đã chứng minh hiệu suất ấn tượng bằng cách tiến hành tinh chỉnh trên các bộ dữ liệu huấn luyện rộng lớn. Tuy nhiên, vì việc thu thập dữ liệu KBQG tốn nhiều nhân lực, các nhà nghiên cứu bắt đầu chú ý đến các nhiệm vụ KBQG vài mẫu (Xiong et al., 2022), nơi một thách thức lớn được đặt ra cho các nhà cung cấp có tài nguyên hạn chế: 1) Cần một lượng lớn dữ liệu được chú thích để cho phép các mô hình được tinh chỉnh hiện có tổng quát hóa tốt trên các dạng logic khác nhau. Tuy nhiên, do các hạn chế về tính sẵn có của tài nguyên thấp, việc huấn luyện các mô hình thông thường bằng cách tinh chỉnh trên dữ liệu đầy đủ trở nên không thực tế. 2) Một dạng logic bao gồm các thực thể, quan hệ và ngữ pháp truy vấn. Việc có các dạng logic với các kết hợp khác nhau của các thành phần cơ bản này là rất quan trọng để duy trì khả năng tổng quát hóa thành phần của mô hình. Việc thiếu dữ liệu dẫn đến một thách thức thành phần cho các nhiệm vụ KBQG (Gu et al., 2021). 3) Một số dạng logic có thể trở nên phức tạp khi các phép toán như tổng hợp, so sánh tuyệt đối và so sánh được đưa vào. Việc biểu diễn các dạng logic này đặt ra những thách thức bổ sung. Hơn nữa, việc phát triển một phương pháp KBQG kết hợp các biểu thức đa dạng và phức tạp trở nên đặc biệt khó khăn trong các tình huống tài nguyên thấp như vậy (Xiong et al., 2022; Guo et al., 2022).

Gần đây, các LLM như GPT-3 và Codex (Gao et al., 2022; Suzgun et al., 2022; Wei et al., 2022; Wang et al., 2023a) đã chứng minh khả năng tổng quát hóa mạnh mẽ của chúng trên một phạm vi rộng các nhiệm vụ vài mẫu và không mẫu với CoT, bao gồm diễn giải văn bản, thị giác máy tính, lập kế hoạch và suy luận. Trong khi đó, một hướng nghiên cứu (Kasner et al., 2022; Moiseev et al., 2022; Andrus et al., 2022; Trajanoska et al., 2023; Xie et al., 2023) xác nhận rằng các LLM có khả năng mạnh mẽ để nắm bắt chính xác ngữ nghĩa của các quan hệ giữa các giá trị trong dữ liệu, cho phép chuyển đổi các hướng dẫn có cấu trúc thành văn bản tường thuật. Các nghiên cứu trên truyền cảm hứng cho chúng tôi khám phá các nhiệm vụ KBQG vài mẫu bằng cách nhắc nhở LLM với CoT.

Tuy nhiên, cách áp dụng LLM vào KBQG với CoT vẫn chưa rõ ràng. Một mặt, KBQG khác với các nhiệm vụ như tạo mã hoặc trả lời câu hỏi, vì nó liên quan đến việc kết hợp các mục đặc thù của KB vào đầu vào thay vì các tường thuật tự chứa. Do đó, việc định dạng đầu vào theo cách dễ hiểu trong khi xem xét lược đồ KB là rất quan trọng. Mặt khác, thách thức nằm ở việc thiết kế các lời nhắc CoT hiệu quả (Wei et al., 2022) có thể nâng cao hiệu suất của LLM trong bối cảnh KBQG vài mẫu.

Trong công việc này, chúng tôi đề xuất khung KQG-CoT, đây là nỗ lực đầu tiên cho KBQG vài mẫu không cần huấn luyện với LLM. Như được hiển thị trong Hình 1, khung của chúng tôi bao gồm hai bước chính, mục tiêu của chúng là lựa chọn các dạng logic hỗ trợ từ một bộ dữ liệu không có nhãn và xây dựng lời nhắc. Để thu được các dạng logic mạch lạc, chúng tôi sử dụng một kỹ thuật gom cụm để cẩn thận chọn nhiều dạng logic phục vụ như các đại diện, xem xét cả đặc điểm cú pháp và ngữ nghĩa của chúng. Để xây dựng lời nhắc, lấy cảm hứng từ nguyên tắc CoT (Wei et al., 2022), chúng tôi lấy các dạng logic được chọn làm ví dụ và viết các lý luận để chia việc tạo một câu hỏi hoàn chỉnh thành nhiều bước. Chúng tôi nối các lý luận trên với dạng logic được truy vấn để tạo thành một lời nhắc, hướng dẫn LLM tạo ra một quá trình suy luận để tạo ra một câu hỏi phức tạp phù hợp với dạng logic. Chúng tôi cải thiện thêm KQG-CoT thành KQG-CoT+ thông qua việc sắp xếp các dạng logic hỗ trợ theo độ phức tạp.

Vì các phương pháp trước đây phụ thuộc nhiều vào các trường hợp huấn luyện để tinh chỉnh một mô hình KBQG. KQG-CoT không cần nhiều cặp câu hỏi dạng logic để huấn luyện các mô hình. Chúng tôi kiểm tra hiệu suất của các phương pháp nhắc nhở của chúng tôi trong cài đặt vài mẫu trên ba bộ dữ liệu công khai, cụ thể là WebQuestions (Kumar et al., 2019), PathQuestions (Zhou et al., 2018) và GrailQA (Gu et al., 2021). Chúng tôi tiến hành so sánh toàn diện với một loạt các phương pháp cơ sở CoT thường được sử dụng bao gồm Auto-CoT (Zhang et al., 2023c), Active-CoT (Diao et al., 2023), Random-CoT (Brown et al., 2020) và nhiều phương pháp khác. Kết quả thực nghiệm cho thấy chúng tôi có thể vượt trội so với tất cả chúng với một khoảng cách đáng kể. Bên cạnh đó, chúng tôi cũng so sánh với một tập hợp các hệ thống SoTA được huấn luyện với dữ liệu đầy đủ hoặc ít dữ liệu. Phương pháp vài mẫu của chúng tôi có thể đạt được kết quả cạnh tranh so với các phương pháp huấn luyện đầy đủ. Đáng chú ý, phương pháp vài mẫu của chúng tôi có thể vượt qua kết quả SoTA vài mẫu hiện có của bộ dữ liệu PathQuestions bằng 18,25, 10,72 và 10,18 điểm tuyệt đối trên BLEU-4, METEOR và ROUGE-L tương ứng.

KQG-CoT cung cấp một giải pháp đơn giản nhưng hiệu quả cho vấn đề KBQG vài mẫu, chúng tôi kỳ vọng nó có thể phục vụ như một đường cơ sở quan trọng cho các nghiên cứu tương lai về các nhiệm vụ KBQG trong các tình huống tài nguyên thấp.

Các đóng góp chính của chúng tôi được tóm tắt như sau:

• Bằng cách mã hóa và gom cụm các khung của các dạng logic, chúng tôi đã thành công thu được các dạng logic hỗ trợ đặc biệt phù hợp để xây dựng các lời nhắc hiệu quả.

• Chúng tôi đã tái tổ chức trình tự các ví dụ và sử dụng phương pháp CoT để xây dựng các lời nhắc có hiệu quả cao đối với các mô hình ngôn ngữ lớn.

• Kết quả thực nghiệm cho thấy phương pháp của chúng tôi vượt trội so với đường cơ sở bằng một khoảng cách đáng kể và đạt được mức hiệu suất tương đương với các phương pháp được tinh chỉnh.

## 2 Nghiên cứu Liên quan

**Tạo Câu hỏi Cơ sở Tri thức.** Các phương pháp sớm cho các nhiệm vụ KBQG là các phương pháp dựa trên mẫu. Berant et al. (2013) và Talmor và Berant (2018a) đã sử dụng các công cụ tìm kiếm và chú thích thủ công để xây dựng các câu hỏi ngôn ngữ tự nhiên dựa trên các dạng logic. Tuy nhiên, các phương pháp dựa trên mẫu phụ thuộc vào sự can thiệp thủ công, khó có thể mở rộng. Với sự tiến bộ của các mạng nơ-ron sâu, các phương pháp dựa trên mạng nơ-ron đã nổi lên như một phương pháp nổi bật và được áp dụng rộng rãi. Kumar et al. (2019) và Chen et al. (2023) đã đề xuất các mô hình đầu cuối đến cuối dựa trên các mô hình Transformer và Graph2seq, có khả năng tạo ra các câu hỏi phức tạp, nhiều bước dựa trên một đồ thị con. Các nghiên cứu tiếp theo (Fei et al., 2022; Guo et al., 2022) đã phát triển các mô hình phức tạp hơn cho KBQG, đảm bảo sự liên quan giữa các câu hỏi được tạo ra và các đồ thị con. Xiong et al. (2022) đã đề xuất một phương pháp cho KBQG tài nguyên thấp, nơi một trình tự động-nhắc nhở được phát triển để diễn giải một dạng logic thành một mô tả, để một mô hình ngôn ngữ được tiền huấn luyện có thể được tinh chỉnh với dữ liệu được tăng cường. Công việc của chúng tôi khác với điều này vì phương pháp của chúng tôi tập trung vào việc giải quyết thách thức KBQG vài mẫu với các LLM đông lạnh.

**Học Vài mẫu cho Tạo Văn bản.** Trong những năm gần đây, tiến bộ đáng kể đã được thực hiện trong lĩnh vực học vài mẫu cho tạo văn bản. Một hướng nghiên cứu phát triển các khung meta-learning cho tạo văn bản (Mi et al., 2019; Madotto et al., 2019; Zeng et al., 2021; Hospedales et al., 2022), nhằm mục đích có được một khởi tạo tối ưu cho phép thích ứng chính xác và nhanh chóng với một nhiệm vụ mới, ngay cả khi dữ liệu có hạn có sẵn. Hướng nghiên cứu khác đề xuất các thuật toán tăng cường khác nhau để tổng hợp dữ liệu cho huấn luyện (Song et al., 2019; Zhao et al., 2022), để các mô hình tạo văn bản thông thường có thể được áp dụng cho dữ liệu được tăng cường. Gần đây nhất, các LLM được sử dụng để giải quyết các nhiệm vụ tạo văn bản vài mẫu như tóm tắt văn bản (Yang et al., 2023; Zhang et al., 2023b; Liu et al., 2023), dịch máy (Wang et al., 2023b; Hendy et al., 2023), tạo đối thoại (Zhang et al., 2023a; Valvoda et al., 2022; Kang et al., 2022) và nhiều hơn nữa. Không có nghiên cứu nào hiện có áp dụng LLM cho các nhiệm vụ KBQG vài mẫu.

**Học Trong Ngữ cảnh với LLM.** Không có cập nhật gradient, Học Trong Ngữ cảnh (ICL) giải quyết hiệu quả một loạt các nhiệm vụ NLP bằng cách kết hợp một số lượng nhỏ các ví dụ được nhắc nhở như một phần của đầu vào (Ruis et al., 2023) để giúp LLM hiểu các nhiệm vụ. Nhiều nghiên cứu (Su et al., 2022; Rubin et al., 2022) đã khám phá việc lựa chọn các ví dụ tương tự với truy vấn trong quá trình xây dựng lời nhắc. Các nghiên cứu gần đây (Lu et al., 2022a; Liu et al., 2022; Diao et al., 2023; Wang et al., 2023c) nhấn mạnh rằng thứ tự của các ví dụ này trong lời nhắc có ảnh hưởng đáng kể. CoT là một chiến lược nhắc nhở phân tách các nhiệm vụ phức tạp thành các nhiệm vụ con, giúp mô hình dẫn xuất các câu trả lời chính xác một cách tiến bộ (Wei et al., 2022; Zhou et al., 2023). Nó đã được sử dụng rộng rãi trong giải quyết bài toán từ toán học, suy luận thông thường và suy luận biểu tượng. Công việc của chúng tôi kết hợp chiến lược CoT vào các nhiệm vụ KBQG, nơi quá trình lặp cho phép LLM cuối cùng có được một câu hỏi phức tạp phù hợp với dạng logic.

## 3 Phương pháp

### 3.1 Công thức Hóa Vấn đề

Một KB bao gồm một tập hợp các bộ ba. Một dạng logic là một biểu thức cấu trúc của một đồ thị con trong KB, có thể bao gồm các phép toán phức tạp (ví dụ: tổng hợp, so sánh và so sánh tuyệt đối) và có thể được sử dụng để thực thi chống lại một KB. Nhiệm vụ KBQG yêu cầu một hệ thống tạo ra một câu hỏi ngôn ngữ tự nhiên khi được cho một dạng logic và các KB tương ứng với ngữ nghĩa nhất quán.

### 3.2 Tổng quan Phương pháp

Gần đây, LLM đã cho thấy khả năng học vài mẫu trong ngữ cảnh ấn tượng của nó. Thay vì tinh chỉnh một mô hình được tiền huấn luyện để thích ứng với một nhiệm vụ hạ lưu, chúng ta có thể đơn giản áp dụng nó vào một nhiệm vụ mới với một vài ví dụ như lời nhắc trong quá trình suy luận (Yang et al., 2022; Li et al., 2023). Đối với nhiệm vụ KBQG, chúng tôi áp dụng một phương pháp hai giai đoạn để thiết kế các lời nhắc CoT, giúp LLM hiểu các dạng logic phức tạp và tạo ra câu hỏi một cách hiệu quả. Cụ thể, giai đoạn đầu tiên Lựa chọn Dạng Logic Hỗ trợ tập trung vào việc xác định các ví dụ hỗ trợ đại diện cho các mẫu cú pháp khác nhau của các dạng logic. Để thực hiện điều này, chúng tôi mã hóa cấu trúc của các dạng logic, thực hiện gom cụm và sử dụng các kỹ thuật lấy mẫu để chọn k dạng logic hỗ trợ hàng đầu. Một khi các ví dụ hỗ trợ này được chọn, chúng tôi tận dụng LLM với các lời nhắc CoT để tạo ra câu hỏi ngôn ngữ tự nhiên. Điều này dẫn chúng tôi đến giai đoạn thứ hai, Xây dựng Lời nhắc, liên quan đến việc tạo ra các câu hỏi phụ làm lý luận. Thông qua quá trình này, chúng tôi cuối cùng có thể xây dựng một câu hỏi phức tạp nắm bắt đầy đủ ngữ nghĩa của dạng logic. Một sơ đồ minh họa của phương pháp chúng tôi được hiển thị trong Hình 2.

### 3.3 Lựa chọn Dạng Logic Hỗ trợ

Zhang et al. (2023c) đã chỉ ra rằng khi xây dựng các minh chứng, chúng ta cần giảm thiểu tác động của các lỗi CoT vài mẫu bằng cách phân biệt thiết kế của các minh chứng. Trong các nhiệm vụ KBQG, các dạng logic hỗ trợ là những dạng có thể bao phủ các quy tắc logic đa dạng, để cung cấp thêm thông tin cú pháp cho LLM để tạo ra câu hỏi. Khác với các đầu vào tường thuật, dạng logic là một sự kết hợp của các cấu trúc chương trình và các mục lược đồ (tức là thực thể và quan hệ). Do đó, điều quan trọng là phải xem xét cả hai khía cạnh khi chọn các dạng logic hỗ trợ. Trong phương pháp của chúng tôi, chúng tôi sử dụng Mã hóa Cấu trúc và Gom cụm, theo sau là một quá trình Lấy mẫu Dạng Logic để chọn các dạng logic hỗ trợ.

**Mã hóa Cấu trúc và Gom cụm.** Để đảm bảo các dạng logic có thể được soạn thảo cho các câu hỏi chưa thấy, chúng tôi trích xuất cấu trúc của chúng bằng cách chuyển đổi các mục lược đồ thành các biến tượng trưng. Cụ thể, chúng tôi giữ nguyên ngữ pháp trong dạng logic. Sau đó, chúng tôi thay thế quan hệ bằng ký hiệu "r" và chúng tôi thay thế thực thể bằng "e". Cấu trúc này cũng được biết đến như một đồ thị truy vấn trừu tượng (Chen et al., 2021), phản ánh tô pô và các lớp thành phần của các dạng logic. Ví dụ, dạng logic thô là:
(AND medicine.routed_drug (JOIN medicine.routed_drug.marketed_formulations m.0hqs1x)).
Nó trở thành cấu trúc sau đây sau khi chuyển đổi:
(AND r (JOIN r e)).

Một khi chúng tôi đã có được cấu trúc của các dạng logic, lọc ra ý nghĩa ngữ nghĩa của các dạng logic. Chúng tôi mã hóa biểu diễn cấu trúc thành một embedding có độ dài cố định. Cụ thể, chúng tôi xem cấu trúc như một chuỗi các token. Chúng tôi mã hóa các ngữ cảnh của chuỗi với Sentence-Transformers (Reimers và Gurevych, 2019), là một mô hình tiên tiến cho embedding văn bản. Các vector được mã hóa rất phù hợp để tính toán sự tương tự giữa các câu. Chúng tôi trích xuất trạng thái ẩn cuối cùng làm biểu diễn vector hóa của câu. Sau đó, chúng tôi sử dụng thuật toán gom cụm K-means (Hartigan và Wong, 1979) để nhóm cấu trúc được mã hóa thành k cụm dựa trên sự tương tự cú pháp của chúng.

**Lấy mẫu Dạng Logic.** Mỗi cụm chứa một nhóm các dạng logic có cấu trúc tương tự, chúng tôi ngẫu nhiên chọn một cấu trúc từ mỗi nhóm và thu được k cấu trúc đại diện. Vì mỗi cấu trúc có thể tương ứng với nhiều dạng logic. Chúng tôi xác định thêm k dạng logic với ngữ nghĩa phân biệt được dẫn xuất từ k cấu trúc được chọn. Để đạt được mục tiêu này, chúng tôi lặp lại lấy mẫu các dạng logic có tính đa dạng tối đa về ngữ nghĩa. Cụ thể, đối với dạng logic đầu tiên, chúng tôi ngẫu nhiên chọn một từ các ứng viên. Sau đó chúng tôi tìm kiếm các dạng logic cho một cấu trúc khác. Chúng tôi tham lam chọn một ứng viên có sự tương tự ngữ nghĩa ít nhất với các dạng logic được chọn, nơi sự tương tự được đo bằng việc mã hóa các dạng logic gốc. Chúng tôi lặp lại quá trình cho đến khi chúng tôi đã trải qua k cấu trúc như được hiển thị trong Hình 2.

Để giúp LLM hiểu đầy đủ các dạng logic, chúng tôi thay thế các thực thể trong các dạng logic gốc bằng tên bề mặt của chúng trong KB. Bằng cách này, chúng tôi thu được k dạng logic hỗ trợ.

### 3.4 Xây dựng Lời nhắc

Vì một số dạng logic có ngữ nghĩa phức tạp và thậm chí các cấu trúc cú pháp lồng nhau được bao gồm. Theo phương pháp CoT, chúng tôi xây dựng một lời nhắc chuỗi suy luận dựa trên các dạng logic hỗ trợ được thu thập ở trên. Đối với mỗi ví dụ, chúng tôi cần tạo ra một chuỗi suy luận dựa trên các dạng logic để kích thích LLM tạo ra câu hỏi từ đơn giản đến phức tạp. Để đạt được mục tiêu này, chúng tôi giữ hai tiêu chí khi xây dựng các chuỗi suy luận:

(i) Các mẫu nên phân tách việc tạo ra một câu hỏi phức tạp thành một quá trình từng bước.

(ii) Các mẫu nên xác định rõ ràng thành phần con trong một dạng logic mà LLM cần tập trung vào cho mỗi bước.

Do đó, chúng tôi đầu tiên phân tách một dạng logic theo cách lồng nhau, nơi các dạng logic tiếp theo bao gồm các dạng logic trước đó. Cụ thể, bước đầu tiên thường tạo ra một câu hỏi đơn giản truy vấn quan hệ một bước từ thực thể chủ đề. Bước thứ hai thường tạo ra một câu hỏi truy vấn chuỗi quan hệ hai bước liên quan đến quan hệ một bước ở trên. Như chúng ta có thể thấy từ Hình 2, bước đầu tiên của lời nhắc phân tích toàn bộ dạng logic thành đồ thị con quan hệ một bước "(AND sports.sport.team_coaches John Russo)" dẫn đến một câu hỏi phụ đơn giản "sport team coach john russo". Bước thứ hai bao gồm dạng logic được phân tích được thêm vào bước trước đó như một thành phần và tạo ra câu hỏi "Which sport does john russo coach?" dựa trên đồ thị con 2 và câu hỏi phụ 1. Kết quả là, chúng tôi liên tục mở rộng dạng logic cho đến khi một câu hỏi hoàn chỉnh được hình thành. Quá trình từng bước này đảm bảo rằng câu hỏi được tạo ra là mạch lạc về ngữ nghĩa và chính xác về ngữ pháp.

Trong quá trình suy luận, chúng tôi nối tất cả các minh chứng và dạng logic được truy vấn làm lời nhắc cuối cùng. Dựa trên ví dụ trong Hình 2, lời nhắc bao gồm "Input: (AND ... Input: (JOIN ... Input: (COUNT ... S.A.". Sau khi nhận lời nhắc, LLM đưa ra các dự đoán làm rõ các bước tạo ra trung gian của câu hỏi phụ 1, câu hỏi phụ 2 và câu hỏi phụ 3. Và câu hỏi phụ cuối cùng sẽ là câu hỏi dự đoán cuối cùng của chúng tôi, đó là "What is the number of aircraft manufacturer in the legal structure of s.a.?".

## 4 Thí nghiệm

Trong phần này, chúng tôi đầu tiên giới thiệu các bộ dữ liệu KBQG được sử dụng để đánh giá hiệu suất của phương pháp được đề xuất và các phương pháp cơ sở có thể so sánh. Tiếp theo, chúng tôi trình bày các chi tiết triển khai và chứng minh kết quả thực nghiệm.

### 4.1 Dữ liệu và Chỉ số

Chúng tôi đánh giá phương pháp nhắc nhở của mình trên ba bộ dữ liệu công khai sau:

**WebQuestions (WQ)** (Kumar et al., 2019) là một bộ dữ liệu KBQG kết hợp các trường hợp từ WebQuestionsSP (Serban et al., 2016) và ComplexWebQuestions (Talmor và Berant, 2018b). Nó cung cấp câu hỏi, câu trả lời và các đồ thị con được chú thích. Bộ dữ liệu này thường được đánh giá trong các công việc hiện có (Guo et al., 2022).

**PathQuestions (PQ)** (Zhou et al., 2018) là một bộ dữ liệu KBQG thường được sử dụng được xây dựng từ một bộ dữ liệu KBQA. Nó chứa các câu hỏi hỏi về một chuỗi quan hệ, trong đó đường dẫn giữa các thực thể chủ đề và thực thể trả lời là 2-hop hoặc 3-hop.

**GrailQA (GQ)** (Gu et al., 2021) là một bộ dữ liệu KBQA quy mô lớn được xây dựng trên Freebase, bao phủ 86 lĩnh vực. Nó bao gồm các câu hỏi phức tạp yêu cầu đếm, xếp hạng và thậm chí truy vấn so sánh tuyệt đối. Mỗi câu hỏi được liên kết với một s-expression, có thể được xem như một dạng logic.

Chúng tôi thu thập dạng logic được chú thích từ tập huấn luyện làm bộ dữ liệu và để nguyên các câu hỏi gốc. Các câu hỏi trong tập xác thực hoặc tập thử nghiệm được lấy mẫu để đánh giá phương pháp của chúng tôi. Thống kê của các bộ dữ liệu được đánh giá được hiển thị trong Bảng 1.

Theo các nghiên cứu KBQG trước đây, chúng tôi dựa vào một tập hợp các chỉ số được thiết lập tốt để đánh giá KBQG: BLEU-4 (Papineni et al., 2002), METEOR (Banerjee và Lavie, 2005) và ROUGE-L (Lin, 2004). BLEU-4 và ROUGE-L có thể được xem như độ chính xác và recall cho các nhiệm vụ tạo văn bản tương ứng. METEOR là một chỉ số toàn diện vượt ra ngoài các kết quả khớp chính xác, cũng tính đến các kết quả khớp một phần và các biến thể trong thứ tự từ. Chúng tôi ký hiệu chúng lần lượt là B, M và R.

### 4.2 Phương pháp So sánh

Chúng tôi ký hiệu phương pháp nhắc nhở của mình là KQG-CoT. Các nghiên cứu trước đây (Lu et al., 2022b) đã chứng minh rằng thứ tự của các ví dụ có ý nghĩa quan trọng đối với kết quả nhắc nhở, chúng tôi triển khai một phiên bản cải tiến bằng cách sắp xếp các minh chứng từ ngắn đến dài sau khi lấy mẫu. Chúng tôi ký hiệu phương pháp này là KQG-CoT+.

Vì không có nỗ lực hiện có nào cho các nhiệm vụ KBQG vài mẫu với LLM, chúng tôi áp dụng năm phương pháp nhắc nhở chung trong các tình huống vài mẫu làm đường cơ sở của chúng tôi.

**Standard Prompt** (Brown et al., 2020) là một phương pháp nhắc nhở tiêu chuẩn của học trong ngữ cảnh, nơi k dạng logic và câu hỏi ngẫu nhiên được nối để tạo thành lời nhắc. Dự đoán là tạo ra một bước.

**Random-CoT** là một đường cơ sở nhắc nhở CoT trực quan nơi k dạng logic được chọn ngẫu nhiên từ bộ dữ liệu và chúng tôi theo công việc gốc (Brown et al., 2020) để mô tả nhiệm vụ phụ trong tường thuật.

**Manual-CoT** (Wei et al., 2022) là nhắc nhở CoT với k ví dụ được viết bởi con người làm minh chứng và nhiệm vụ phụ được trình bày trong tường thuật.

**Active-CoT** (Diao et al., 2023) là một khung tổng hợp cho nhắc nhở CoT. Nhiều dạng logic được chọn ngẫu nhiên làm tập xác thực. Sau đó nhiều phép đo (ví dụ: bất đồng, phương sai) được tận dụng làm giá trị không chắc chắn cho mỗi dạng logic để tạo ra câu hỏi cuối cùng.

**Auto-CoT** (Zhang et al., 2023c) tự động xây dựng lời nhắc bằng cách chọn k minh chứng với thuật toán dựa trên cụm và nhiệm vụ phụ được trình bày trong tường thuật. Chúng tôi đơn giản áp dụng phương pháp nhắc nhở vào các nhiệm vụ KBQG bằng cách mã hóa tất cả dạng logic theo cách văn bản.

### 4.3 Chi tiết Triển khai

Để mã hóa các dạng logic, chúng tôi sử dụng checkpoint all-MiniLM-L6-v2 từ thư viện Sentence-Transformers trong Huggingface để mã hóa hiệu quả. Vì đây là một tình huống vài mẫu, chúng tôi viết thủ công các lý luận cho k minh chứng trong lời nhắc chuỗi. Chúng tôi sử dụng text-davinci-003 từ OpenAI API để tạo ra câu hỏi và đặt số lượng cụm là k = 12.

### 4.4 Kết quả Chính

**So sánh với Đường cơ sở.** Bảng 2 trình bày kết quả thực nghiệm của các phương pháp của chúng tôi và các phương pháp cơ sở. Chúng tôi có những quan sát sau dựa trên nó:

1) So sánh tất cả các phương pháp nhắc nhở CoT, trong cài đặt vài mẫu, phương pháp nhắc nhở KQG-CoT+ của chúng tôi liên tục vượt trội so với các phương pháp khác trên tất cả các bộ dữ liệu KBQG với một khoảng cách đáng kể. Cụ thể, KQG-CoT+ cải thiện hiệu suất của Auto-CoT cạnh tranh từ 0,72 đến 2,12 giá trị tuyệt đối cho tất cả các bộ dữ liệu. Trong khi đó, KQG-CoT cũng vượt trội so với các phương pháp nhắc nhở CoT hiện có trên BLEU-4 của tất cả các bộ dữ liệu.

2) So sánh các phương pháp CoT với nhắc nhở tiêu chuẩn, chúng tôi nhận thấy rằng tất cả các phương pháp nhắc nhở CoT đều vượt trội so với phương pháp nhắc nhở tiêu chuẩn, cho thấy rằng, để tạo ra câu hỏi với logic phức tạp và phụ thuộc dài, việc chia toàn bộ nhiệm vụ tạo ra thành các nhiệm vụ con là rất quan trọng để duy trì sự mạch lạc và độ chính xác của câu hỏi.

3) So sánh Auto-CoT, KQG-CoT và KQG-CoT+, mặc dù tất cả các phương pháp này đều thích ứng gom cụm để chọn k minh chứng, KQG-CoT và KQG-CoT+ hiệu quả hơn vì chúng tôi thiết kế một cách tỉ mỉ thuật toán mã hóa và mẫu lời nhắc cho các nhiệm vụ KBQG, khiến nó phù hợp hơn với việc tạo câu hỏi từ các dạng logic.

**So sánh với Các Hệ thống Khác.** Chúng tôi so sánh thêm các phương pháp nhắc nhở của chúng tôi với các hệ thống KBQG khác trên các bộ dữ liệu WQ và PQ. Theo hiểu biết của chúng tôi, chúng tôi là người đầu tiên làm việc với nhiệm vụ KBQG sử dụng bộ dữ liệu GQ, vì vậy không có phương pháp hiện có nào có sẵn để so sánh.

Trong Bảng 3, chúng ta có thể thấy rằng với 12 minh chứng, phương pháp của chúng tôi có thể vượt trội so với phần lớn các hệ thống được huấn luyện đầy đủ trên bộ dữ liệu WQ, nơi tất cả dữ liệu huấn luyện được tận dụng để huấn luyện một mô hình. Phương pháp nhắc nhở KQG-CoT+ có thể đạt được 29,73%, 31,08% và 55,46% cho BLEU-4, ROUGE-L và METEOR tương ứng, gần với kết quả SoTA.

Trong Bảng 4, chúng ta có thể thấy rằng đối với bộ dữ liệu PQ, phương pháp của chúng tôi vẫn có thể đạt được kết quả tốt hơn so với hầu hết các mô hình KBQG được huấn luyện đầy đủ hiện có. So với các phương pháp hiện có trong cài đặt vài mẫu, các phương pháp của chúng tôi có thể cải thiện đáng kể BLEU-4 so với AutoQGS khoảng 20 điểm tuyệt đối. Đáng chú ý là AutoQGS lấy 0,1% trường hợp huấn luyện để huấn luyện và chúng tôi đơn giản tận dụng 12 trường hợp để suy luận, điều này nhấn mạnh sự vượt trội của các phương pháp của chúng tôi.

### 4.5 Phân tích Thêm

**Đánh giá Con người.** Chúng tôi tiến hành thêm đánh giá con người bằng cách lấy mẫu ngẫu nhiên 300 ví dụ từ tập thử nghiệm của bộ dữ liệu WQ. Các câu hỏi được tạo ra được đánh giá trên thang điểm từ 1 đến 5 xem xét các khía cạnh về tính chính xác cú pháp, độ phức tạp và sự liên quan đến các dạng logic được cho. Chúng tôi yêu cầu ba người chú thích cho điểm các câu hỏi được tạo ra với 1 điểm là kém và 5 điểm là hoàn hảo. Điểm của mỗi câu hỏi được lấy trung bình trên tất cả các người chú thích. Chúng tôi trình bày kết quả trong Bảng 6, nơi chúng tôi có thể quan sát một xu hướng tương tự giữa đánh giá con người và tự động. Phương pháp của chúng tôi vượt trội so với tất cả các phương pháp so sánh, điểm đánh giá của chúng gần với sự thật cơ bản.

**Nghiên cứu Loại bỏ.** Chúng tôi tiến hành nghiên cứu loại bỏ để đánh giá tính hiệu quả của các thành phần của mô hình chúng tôi và hiển thị kết quả trong Bảng 7. Chúng tôi đầu tiên loại trừ chuỗi suy luận CoT và quan sát sự sụt giảm hiệu suất của các chỉ số đánh giá. Điều này cho thấy rằng CoT đóng vai trò quan trọng trong việc tạo ra các câu hỏi phức tạp. Sau đó chúng tôi loại bỏ thuật toán K-means và chọn ngẫu nhiên các dạng logic hỗ trợ. Sự giảm của kết quả cho thấy rằng thuật toán gom cụm của chúng tôi có thể cung cấp các dạng logic đa dạng hơn làm minh chứng của chúng tôi. Chúng tôi mã hóa thêm toàn bộ các dạng logic mà không trích xuất cấu trúc của chúng. Kết quả giảm cho thấy rằng cấu trúc là một chỉ số quan trọng để có được các cụm.

**Tác động của k.** Chúng tôi khảo sát tác động của k trong Hình 3. Như quan sát thấy, với sự tăng của số lượng minh chứng, cả phương pháp của chúng tôi và Random-CoT đều cho thấy điểm BLEU-4 và ROUGE-L tăng. Điều này cho thấy rằng số lượng minh chứng quan trọng trong việc kích hoạt tiềm năng của LLM. So với Random-CoT, phương pháp của chúng tôi cho thấy mức tăng lớn hơn khi giá trị k trở nên lớn, điều này cho thấy các phương pháp của chúng tôi thực sự chọn ra dạng logic đại diện nhất làm minh chứng.

**Nghiên cứu Tình huống.** Để cung cấp so sánh toàn diện giữa phương pháp KQG-CoT+ và các mô hình cơ sở trên bộ dữ liệu GQ, chúng tôi trình bày nhiều trường hợp ví dụ trong Bảng 5. Phương pháp của chúng tôi kích thích các bước tạo ra trung gian và cung cấp nhiều hướng dẫn hơn cho LLM để KQG-CoT+ của chúng tôi tạo ra các câu hỏi chính xác về ngữ pháp và gần gũi về ngữ nghĩa với dạng logic được cho. Ngược lại, các phương pháp cơ sở có thể gặp phải các vấn đề như không nhất quán trong dạng logic, các từ bổ nghĩa đặt sai chỗ hoặc các biểu thức không trôi chảy.

**Hiệu quả của Mã hóa và Gom cụm Có cấu trúc.** Để chứng minh hiệu quả của Mã hóa và Gom cụm Có cấu trúc được đề xuất trong việc chọn các cấu trúc đa dạng, chúng tôi tiến hành đánh giá định lượng về sự tương tự ngữ nghĩa trung bình giữa các dạng logic được trích xuất bằng phương pháp của chúng tôi và phương pháp cơ sở ở K=8 trên bộ dữ liệu GrailQA. Kết quả được trình bày trong Bảng 8. Dữ liệu từ phần đầu, được hiển thị trong bảng dưới đây, cho thấy rằng các dạng logic được chọn bởi phương pháp của chúng tôi thể hiện sự tương tự ngữ nghĩa trung bình thấp hơn. Khi xem xét một cách tổng thể, những phát hiện này cung cấp bằng chứng mạnh mẽ cho hiệu quả của phương pháp được đề xuất của chúng tôi.

**Tác động của Thứ tự Được sắp xếp.** Để đánh giá tác động của thứ tự được sắp xếp của các minh chứng trong KQG-CoT+, chúng tôi so sánh hiệu suất của Auto-CoT và Active-CoT sử dụng cùng thứ tự được sắp xếp của các minh chứng trong KQG-CoT+ (tức là Auto-CoT+ và Active-CoT+) và tiến hành thí nghiệm trên bộ dữ liệu GrailQA. Bảng 9 cho thấy rằng, so với các phương pháp Active-CoT+ và Auto-CoT+, phương pháp KQG-CoT+ được đề xuất của chúng tôi vẫn thể hiện cải thiện đáng kể.

**KQG-CoT Cải thiện Nhiệm vụ KBQA.** Để xác nhận hiệu quả của phương pháp của chúng tôi trong việc nâng cao hiệu suất của các phương pháp KBQA, chúng tôi bắt đầu một quy trình tăng cường dữ liệu cho bộ dữ liệu WebQuestions. Quan trọng cần nhấn mạnh rằng bộ dữ liệu được tăng cường chỉ bằng một nửa kích thước của bộ dữ liệu gốc. Tiếp theo, chúng tôi huấn luyện phương pháp KBQA RnG-KBQA (Ye et al., 2022) bằng cách kết hợp các bộ dữ liệu được tăng cường và gốc, tạo ra phiên bản cải thiện được gọi là RnG-KBQA+. Kết quả, như được nêu trong Bảng 10, chứng minh rằng chúng tôi đã tiến hành một sự tăng cường tương đối đơn giản trên một tập hợp con dữ liệu hạn chế. Tuy nhiên, điểm F1 của phương pháp KBQA gốc đã chứng kiến sự tăng đáng kể 2,8%. Điều này chứng minh rằng phương pháp KBQG được đề xuất của chúng tôi cung cấp hỗ trợ đáng kể cho các nhiệm vụ KBQA hạ lưu.

## 5 Kết luận

Trong bài báo này, chúng tôi đã trình bày phương pháp KQG-CoT để giải quyết các nhiệm vụ KBQG vài mẫu. KQG-CoT thu thập các dạng logic liên quan từ dữ liệu không có nhãn và kết hợp các đặc điểm của chúng. Sau đó nó tạo ra lời nhắc rõ ràng để thể hiện quá trình suy luận cho việc tạo ra câu hỏi phức tạp dựa trên các ví dụ được chọn. Kết quả thực nghiệm chứng minh rằng phương pháp của chúng tôi đạt được hiệu suất tốt nhất so với các đường cơ sở và thậm chí cho thấy kết quả cạnh tranh với các phương pháp huấn luyện đầy đủ.

## Hạn chế

Phương pháp nhắc nhở được đề xuất của chúng tôi, KQG-CoT, một phần phụ thuộc vào các lời nhắc thủ công khi viết các câu hỏi phụ. Tuy nhiên, các lời nhắc thủ công thường dựa trên kiến thức và kinh nghiệm cá nhân của các chuyên gia, có thể đưa ra các thiên vị chủ quan.

## Lời cảm ơn

Công việc này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Trung Quốc (Dự án số 62206097) và Chương trình Nhân tài Pujiang Thượng Hải (Dự án số 22PJ1403000). Chúng tôi chân thành cảm ơn các nhà phê bình ẩn danh vì những bình luận và phản hồi có giá trị của họ.

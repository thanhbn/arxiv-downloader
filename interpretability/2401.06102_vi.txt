# Patchscopes: Một Khung Thống Nhất để Kiểm Tra các Biểu Diễn Ẩn của Mô Hình Ngôn Ngữ

Asma Ghandeharioun* 1Avi Caciularu* 1Adam Pearce1Lucas Dixon1Mor Geva1 2

## Tóm tắt

Việc hiểu các biểu diễn nội tại của các mô hình ngôn ngữ lớn (LLM) có thể giúp giải thích hành vi của mô hình và xác minh sự phù hợp của chúng với các giá trị con người. Với khả năng của LLM trong việc tạo ra văn bản có thể hiểu được bởi con người, chúng tôi đề xuất tận dụng chính mô hình để giải thích các biểu diễn nội tại của nó bằng ngôn ngữ tự nhiên. Chúng tôi giới thiệu một khung được gọi là Patchscopes và chỉ ra cách nó có thể được sử dụng để trả lời một loạt các câu hỏi về tính toán của LLM. Chúng tôi cho thấy rằng nhiều phương pháp diễn giải trước đó dựa trên việc chiếu các biểu diễn vào không gian từ vựng và can thiệp vào tính toán LLM có thể được xem như các thể hiện của khung này. Hơn nữa, một số khuyết điểm của chúng như việc thất bại trong kiểm tra các lớp sớm hoặc thiếu khả năng biểu đạt có thể được giảm thiểu bởi Patchscopes. Ngoài việc thống nhất các kỹ thuật kiểm tra trước đó, Patchscopes còn mở ra những khả năng mới như sử dụng một mô hình có khả năng hơn để giải thích các biểu diễn của một mô hình nhỏ hơn, và sửa lỗi lý luận đa bước.

## 1. Giới thiệu

Câu hỏi về thông tin nào được nắm bắt trong các biểu diễn ẩn của các mô hình ngôn ngữ lớn (LLM) có tầm quan trọng then chốt trong việc kiểm soát và hiểu AI sinh sản hiện đại, và đã thu hút sự chú ý đáng kể gần đây (Casper et al., 2022; Madsen et al., 2022; Patel & Pavlick, 2021; Nanda et al., 2023). Để giải quyết câu hỏi này, các nghiên cứu trước đã giới thiệu một loạt các phương pháp diễn giải đa dạng, chủ yếu dựa trên ba cách tiếp cận nổi bật: huấn luyện các bộ phân loại tuyến tính, gọi là probe, trên các biểu diễn ẩn (Belinkov & Glass, 2019; Belinkov, 2022; Alain & Bengio, 2017), chiếu các biểu diễn vào không gian từ vựng của mô hình (nostalgebraist, 2020; Din et al., 2023; Belrose et al., 2023), và can thiệp vào tính toán để xác định xem một biểu diễn có quan trọng đối với các dự đoán nhất định (Meng et al., 2022a; Wallat et al., 2020; Wang et al., 2022; Conmy et al., 2023; Geva et al., 2023).

Mặc dù thành công rộng rãi của các phương pháp này, chúng đều thể hiện những khuyết điểm thực tế. Thứ nhất, việc probing dựa trên huấn luyện có giám sát cho các lớp được định nghĩa trước, điều này khó mở rộng khi có số lượng lớn các lớp hoặc khi không biết trước tất cả các danh mục. Thứ hai, độ chính xác của việc chiếu từ vựng giảm đáng kể ở các lớp sớm và đầu ra thường khó diễn giải. Cuối cùng, tất cả các phương pháp trên không biểu đạt như mong muốn: chúng cung cấp xác suất lớp hoặc các token có khả năng nhất, thay vì một lời giải thích chất lượng cao bằng ngôn ngữ tự nhiên.

Trong nghiên cứu này, chúng tôi lập luận rằng khả năng tiên tiến của LLM trong việc tạo ra văn bản giống con người có thể được tận dụng để "dịch" thông tin trong các biểu diễn của chúng cho con người. Chúng tôi giới thiệu một khung mô-đun, gọi là Patchscopes (§3), có thể được cấu hình để truy vấn nhiều loại thông tin khác nhau từ các biểu diễn LLM. Patchscopes giải mã thông tin cụ thể từ một biểu diễn trong LLM bằng cách "vá" nó vào quá trình suy luận trên một prompt khác được thiết kế để khuyến khích việc trích xuất thông tin đó. Cấu hình như vậy (một Patchscope) có thể được xem như một công cụ kiểm tra hướng đến một mục tiêu cụ thể, như minh họa trong Hình 1.

Chúng tôi cho thấy rằng nhiều phương pháp hiện có, bao gồm những phương pháp dựa trên chiếu từ vựng và can thiệp tính toán, có thể được đúc thành Patchscopes. Hơn nữa, các cấu hình mới của khung của chúng tôi giới thiệu các công cụ hiệu quả hơn trong việc giải quyết các câu hỏi tương tự, đồng thời giảm thiểu một số hạn chế của các cách tiếp cận trước đó. Ngoài ra, Patchscopes cho phép giải quyết các câu hỏi chưa được khám phá, như phân tích chi tiết quá trình ngữ cảnh hóa đầu vào và mức độ mà một mô hình biểu đạt hơn có thể được sử dụng để kiểm tra các biểu diễn ẩn của một mô hình nhỏ hơn.

Chúng tôi tiến hành một loạt thí nghiệm để đánh giá lợi ích và cơ hội được giới thiệu bởi Patchscopes, tập trung vào các LLM tự hồi quy. Đầu tiên, chúng tôi xem xét vấn đề ước tính dự đoán token tiếp theo của mô hình từ các biểu diễn trung gian của nó (xem §4.1). Trên nhiều LLM, chúng tôi cho thấy rằng việc sử dụng prompt nhận dạng token few-shot, một prompt có dạng "tok 1→tok 1; tok 2→tok 2;. . .;tokk" trong đó toki đề cập đến một token ngẫu nhiên, dẫn đến cải thiện đáng kể so với các phương pháp chiếu từ vựng. Tiếp theo, chúng tôi đánh giá mức độ Patchscopes có thể giải mã các thuộc tính cụ thể của một thực thể từ các biểu diễn LLM của nó, khi chúng được tách khỏi ngữ cảnh gốc (xem§4.2). Chúng tôi quan sát thấy rằng, mặc dù không sử dụng dữ liệu huấn luyện, Patchscopes vượt trội đáng kể so với probing trong sáu trong mười hai nhiệm vụ lý luận thường thức và thực tế, và hoạt động tương đương trong tất cả trừ một trong sáu nhiệm vụ còn lại.

Ngoài ước tính đầu ra và giải mã thuộc tính, Patchscopes có thể giải quyết các câu hỏi khó trả lời với các phương pháp hiện có. Trong §4.3, chúng tôi áp dụng Patchscopes để nghiên cứu cách LLM ngữ cảnh hóa tên thực thể đầu vào trong các lớp sớm, nơi mà việc chiếu từ vựng chủ yếu thất bại và các phương pháp khác, tốt nhất là chỉ cung cấp tín hiệu nhị phân về việc thực thể đã được giải quyết hay chưa (Youssef et al., 2023; Tenney et al., 2019). Với một Patchscope mới, chúng tôi có thể diễn đạt quá trình giải quyết thực thể dần dần. Ví dụ, chúng tôi cho thấy rằng, khi mô hình xử lý token cuối cùng của "Alexander the Great" qua các lớp, nó phản ánh các thực thể khác nhau bắt đầu từ "Great Britain", đến "the Great Depression", đến cuối cùng giải quyết "Alexander the Great". Sau đó, trong §4.4 chúng tôi cho thấy cách có thể cải thiện thêm tính biểu đạt của Patchscope bằng cách sử dụng một mô hình đích mạnh hơn, ví dụ, Vicuna 13B thay vì Vicuna 7B.

Cuối cùng, chúng tôi giới thiệu tiện ích của Patchscopes để sửa lỗi lý luận đa bước tiềm ẩn, đặc biệt khi mô hình có khả năng thực hiện mỗi bước lý luận một cách chính xác, nhưng thất bại khi chúng cần được kết hợp trong ngữ cảnh (§5). Dựa trên dữ liệu do Hernandez et al. (2023b) cung cấp, chúng tôi giới thiệu một nhiệm vụ phức tạp hơn đòi hỏi hai bước lý luận thực tế. Patchscope đạt độ chính xác 50% trên nhiệm vụ này, vượt trội hơn chain-of-thought (Wei et al., 2022) (35.71%) và sinh văn bản thông thường (19.57%).

Để kết luận, nghiên cứu của chúng tôi đóng góp những điều sau:
Chúng tôi đề xuất Patchscopes, một khung mô-đun tổng quát để giải mã thông tin từ các biểu diễn ẩn trong LLM. Chúng tôi cho thấy rằng các phương pháp diễn giải nổi bật có thể được xem như các thể hiện của Patchscopes, và các cấu hình mới dẫn đến các thay thế biểu đạt hơn, mạnh mẽ qua các lớp, và không cần dữ liệu huấn luyện để giảm thiểu các khuyết điểm của chúng. Ngoài ra, các cấu hình mới giới thiệu các khả năng chưa được khám phá của các kỹ thuật kiểm tra mạnh hơn, cũng như lợi ích thực tế, như sửa lỗi lý luận đa bước.

## 2. Nghiên cứu liên quan

Việc vá kích hoạt (Activation patching) là một can thiệp nhân quả, thường được sử dụng như một công cụ để nghiên cứu xem liệu các kích hoạt nhất định có đóng vai trò quan trọng trong tính toán của mô hình hay không (Geiger et al., 2021; Vig et al., 2020). Việc vá chủ yếu được sử dụng để định vị thông tin cụ thể đến các lớp cụ thể và vị trí token (Goldowsky-Dill et al., 2023; Meng et al., 2022a;b; Stolfo et al., 2023; Merullo et al., 2023), và để tìm đường truyền thông tin trong tính toán (Wang et al., 2022; Geva et al., 2023; Hendel et al., 2023; Hanna et al., 2023; Lieberum et al., 2023). Các nghiên cứu trước cũng đã sử dụng các dạng cụ thể của việc vá xuyên mô hình gọi là stitching, trong các kiến trúc không phải transformer, chủ yếu để phân tích sự tương đồng biểu diễn (ví dụ, Bansal et al., 2021; Csiszárik et al., 2021; Lenc & Vedaldi, 2015). Mặc dù có một số hạn chế (Hase et al., 2023; Zhang & Nanda, 2023), việc vá vẫn là một công cụ chính cho diễn giải cơ chế (Conmy et al., 2023).

Với kết quả đầy hứa hẹn từ các nỗ lực diễn giải mới nổi sử dụng LLM để tạo văn bản giống con người cho kiểm tra (ví dụ, Mousi et al., 2023; Slobodkin et al., 2023; Bills et al., 2023), chúng tôi lập luận rằng việc chỉ sử dụng patching cho mục đích định vị là cận thị, và đề xuất sử dụng nó để "dịch" các biểu diễn LLM thành ngôn ngữ tự nhiên.

Gần đây, việc patching đã được sử dụng để nghiên cứu các thiết lập vấn đề mới (ví dụ, Pal et al., 2023; Hernandez et al., 2023b), tất cả đều có thể được xem như các cấu hình khác nhau của khung đề xuất của chúng tôi (xem §3.2).

Trong số các nỗ lực nghiên cứu ngày càng tăng trong việc kiểm tra các biểu diễn ẩn của mạng thần kinh, các bộ phân loại probing có lẽ là phổ biến nhất (ví dụ, Alain & Bengio, 2017; Belinkov & Glass, 2019; Belinkov, 2022; Wang et al., 2023), và các phương pháp sử dụng chiếu vào không gian từ vựng hoặc mở rộng của chúng sang các lĩnh vực khác là một danh mục chính khác (ví dụ, Merullo et al., 2023; Geva et al., 2022b; nostalgebraist, 2020; Belrose et al., 2023; Dar et al., 2023; Din et al., 2023; Langedijk et al., 2023; Vilas et al., 2023). Mặc dù tồn tại nhiều phương pháp kiểm tra tiềm ẩn khác (ví dụ, Zhou et al., 2018; Strobelt et al., 2017; Ghandeharioun et al., 2021; Kim et al., 2018), những phương pháp trên là liên quan nhất đến nghiên cứu này.

## 3. Patchscopes

Trong phần này, chúng tôi giới thiệu Patchscopes và chỉ ra cách nó mở rộng các phương pháp diễn giải trước đó với những khả năng mới. Mặc dù không giới hạn ở các kiến trúc LLM cụ thể, nghiên cứu này tập trung vào các LLM dựa trên transformer tự hồi quy.

### 3.1. Mô tả Khung

Ý tưởng chính trong Patchscopes là tận dụng khả năng tiên tiến của LLM để tạo ra văn bản giống con người để "dịch" thông tin được mã hóa trong các biểu diễn ẩn của chính chúng. Cụ thể, với một biểu diễn ẩn thu được từ một lần suy luận LLM, chúng tôi đề xuất giải mã thông tin cụ thể từ nó bằng cách vá nó vào một lần suy luận khác (của cùng một LLM hoặc LLM khác) khuyến khích việc dịch thông tin cụ thể đó.

Đáng chú ý, phần còn lại của tính toán tiến về phía trước sau khi vá có thể bổ sung biểu diễn với thông tin bổ sung, do đó, cách tiếp cận này không đảm bảo rằng chính biểu diễn được vá lưu trữ tất cả thông tin đó. Tuy nhiên, việc tách biểu diễn khỏi ngữ cảnh gốc của nó (prompt nguồn) dừng việc ngữ cảnh hóa và đảm bảo rằng không có thông tin nào khác từ prompt nguồn được kết hợp trong tính toán sau vá. Do đó, khung của chúng tôi tiết lộ liệu thông tin cụ thể có thể được giải mã từ biểu diễn được vá thông qua tính toán sau vá hay không.

Cho một chuỗi đầu vào n token S=⟨s1, ..., sn⟩ và một mô hình M với L lớp, hℓi biểu thị biểu diễn ẩn thu được tại lớp ℓ∈[1, . . . , L] và vị trí i∈[1, . . . , n], khi chạy M trên S. Để kiểm tra hℓi, chúng tôi xem xét một lần suy luận riêng biệt của mô hình M∗ với L∗ lớp trên chuỗi đích T=⟨t1, . . . , tm⟩ gồm m token. Cụ thể, chúng tôi chọn một biểu diễn ẩn h̄ℓ∗i∗ tại lớp ℓ∗∈[1, . . . , L∗] và vị trí i∗∈[1, . . . , m] trong việc thực thi M∗ trên T. Hơn nữa, chúng tôi định nghĩa một hàm ánh xạ f(h;θ) :Rd→Rd∗ được tham số hóa bởi θ hoạt động trên các biểu diễn ẩn của M, trong đó d và d∗ biểu thị kích thước ẩn của các biểu diễn trong M và M∗, tương ứng. Hàm này có thể là hàm đồng nhất, hàm tuyến tính hoặc affine được học trên các cặp biểu diễn cụ thể cho nhiệm vụ, hoặc thậm chí các hàm phức tạp hơn kết hợp các nguồn dữ liệu khác. Phép toán vá đề cập đến việc thay thế động biểu diễn h̄ℓ∗i∗ trong quá trình suy luận của M∗ trên T bằng f(hℓi). Cụ thể là, bằng cách áp dụng h̄ℓ∗i∗←f(hℓi), chúng tôi can thiệp vào quá trình sinh và sửa đổi tính toán sau lớp ℓ∗.

Tổng thể, một can thiệp Patchscope áp dụng cho một biểu diễn được xác định bởi (S, i, M, ℓ), được định nghĩa bởi một bộ năm (T, i∗, f, M∗, ℓ∗) gồm một prompt đích T, một vị trí đích i∗ trong prompt này, một hàm ánh xạ f, một mô hình đích M∗, và một lớp đích ℓ∗ của mô hình này. Có thể M và M∗ là cùng một mô hình, S và T là cùng một prompt, và f là hàm đồng nhất I (tức là, I(h) = h). Tiếp theo, chúng tôi chỉ ra cách công thức này bao gồm các phương pháp diễn giải trước đó và mở rộng thêm chúng với các khả năng mới.

### 3.2. Patchscopes Bao gồm các Phương pháp Trước đó

Nhiều phương pháp gần đây kiểm tra các biểu diễn LLM bằng cách chiếu chúng vào không gian từ vựng đầu ra (nostalgebraist, 2020; Din et al., 2023; Belrose et al., 2023). Chính thức, một ước tính của phân phối đầu ra được thu từ biểu diễn hℓi tại vị trí i và lớp ℓ bởi:

pℓi= softmax( WUf(hℓi))∈R|V|,

trong đó WU∈R|V|×d là ma trận unembedding của mô hình và f là một hàm ánh xạ đơn giản, như hàm đồng nhất hoặc một ánh xạ affine. Chúng tôi lưu ý rằng phép toán áp dụng cho f(hℓi) là cùng tính toán được áp dụng bởi mô hình cho biểu diễn lớp cuối để thu được dự đoán token tiếp theo. Do đó, các phương pháp trước đó kiểm tra các biểu diễn trong không gian từ vựng có thể được xem như một lớp Patchscopes ánh xạ các biểu diễn từ bất kỳ lớp nguồn ℓ nào đến lớp đích cuối L∗. Sự khác biệt giữa các phương pháp này nằm ở sự lựa chọn f; logit lens (nostalgebraist, 2020; Dar et al., 2023) áp dụng hàm đồng nhất, linear shortcuts (Din et al., 2023) sử dụng hàm ánh xạ tuyến tính, và tuned lens (Belrose et al., 2023) huấn luyện một ánh xạ affine. Gần đây, Hernandez et al. (2023b) đã giới thiệu LRE Attribute Lens xây dựng f dựa trên giả định tuyến tính quan hệ, và chỉ ra hiệu quả của nó trong trích xuất thuộc tính.

Lớp phương pháp này đã được chứng minh hiệu quả cho các ứng dụng khác nhau, ví dụ, trong việc cải thiện hiệu quả suy luận thông qua thoát sớm (Din et al., 2023). Mặc dù phần lớn các phương pháp và ứng dụng trong danh mục này sử dụng một mô hình duy nhất (M∗=M), Merullo et al. (2022) đã chứng minh việc tạo chú thích thành công với mô hình hình ảnh sinh là M và mô hình ngôn ngữ là M∗.

Một danh mục khác của các phương pháp kiểm tra can thiệp vào tính toán LLM. Đương thời với nghiên cứu của chúng tôi, Pal et al. (2023) đã điều tra liệu có thể dự đoán nhiều token được sinh ra phía trước từ một biểu diễn ẩn cho trước, thay vì chỉ ước tính dự đoán token tiếp theo. Phương pháp của họ (Future Lens) sử dụng một prompt đích khác với prompt gốc (tức là, T≠S) và được thiết kế để giải mã các token tiếp theo từ thông tin được mã hóa trong biểu diễn ẩn hℓi. Ví dụ prompt đích là "The multi-tokens present here are " và "Hello! Could you please tell me more about ". Future Lens có thể được đúc thành một Patchscope khác với M∗=M và ℓ∗=ℓ.

Rộng hơn, Patchscopes cũng bao gồm các phương pháp diễn giải cơ chế gần đây phân tích các quá trình nội tại trong LLM với các can thiệp tính toán suy luận. Cụ thể, causal tracing (Meng et al., 2022a) sử dụng một prompt nguồn được bổ sung với nhiễu Gaussian như prompt đích. Các phương pháp trước đó khác đã can thiệp vào một hoặc nhiều lớp đích trong quá trình suy luận bằng cách vá các vector không vào tính toán (Wang et al., 2022; Conmy et al., 2023; Geva et al., 2023), cụ thể là, đặt f(h) = 0. Để có tóm tắt cấu hình về cách các phương pháp diễn giải này có thể được đúc thành các thể hiện Patchscope, xem §A, Tab. 4.

### 3.3. Patchscopes Cho phép các Phương pháp Kiểm tra Mới

Nghiên cứu trước đã sử dụng các cấu hình vá cụ thể cho diễn giải, chủ yếu vá cùng một mô hình trong khi sử dụng cùng một prompt (tức là, M∗=M, T=S). Việc đóng khung Patchscopes giới thiệu một loạt các thiết lập chưa được khám phá có thể mở khóa các khả năng kiểm tra mới.

Cụ thể, chúng tôi quan sát thấy rằng việc sửa đổi prompt đích cho phép giải mã biểu đạt của một loạt các tính năng, tách khỏi tính toán prompt nguồn. Ví dụ, chúng ta có thể sử dụng prompt "The capital of X is" để kiểm tra xem thủ đô của một quốc gia cho trước có thể trích xuất được từ biểu diễn ẩn (token cuối) của nó tại một lớp cụ thể hay không. Tương tự, một prompt như "Tell me facts about X" có thể được tận dụng để đánh giá xem mô hình đã giải quyết tên thực thể trong một lớp cụ thể hay chưa. Trái ngược với probing, cách tiếp cận này không bị hạn chế bởi số lượng lớp của tính năng được chọn.

Hơn nữa, khi mô hình được kiểm tra không đủ biểu đạt để trả lời các truy vấn nhất định, việc vá các biểu diễn vào một mô hình có khả năng hơn có thể hữu ích (Hernandez et al., 2022; Singh et al., 2023; Schwettmann et al., 2023).

## 4. Thí nghiệm

Trong phần này, chúng tôi đánh giá khung của chúng tôi về việc giải mã dự đoán token tiếp theo (§4.1), trích xuất thuộc tính (§4.2), phân tích việc ngữ cảnh hóa tên thực thể (§4.3), và tận dụng các mô hình mạnh hơn để kiểm tra thông qua vá xuyên mô hình (§4.4). Xem tóm tắt trong Tab. 1.

### 4.1. Giải mã Dự đoán Token Tiếp theo

Như đã giới thiệu trong §3.2, cho pL là phân phối xác suất đầu ra cho một đầu vào nào đó, thu được bằng cách nhân biểu diễn ẩn vị trí cuối lớp cuối hL với ma trận unembedding WU∈R|V|×d. Chúng tôi muốn ước tính pL từ các biểu diễn trung gian hℓ sao cho ℓ < L. Đặc biệt, chúng tôi hỏi mô hình đã kết luận dự đoán cuối cùng của nó từ ngữ cảnh cho trước từ lúc nào trong tính toán. Trong các thí nghiệm của chúng tôi, chúng tôi xem xét nhiều LLM – LLaMA2 (13B) (Touvron et al., 2023b), Vicuna (13B) (Chiang et al., 2023), GPT-J (6B) (Wang & Komatsuzaki, 2021), và Pythia (12B) (Biderman et al., 2023) (xem thêm chi tiết trong §B.1).

**Phương pháp** Chúng tôi so sánh các phương pháp chiếu từ vựng (§3.2) với một Patchscope mới. Mỗi phương pháp tạo ra một xác suất đầu ra ước tính p̃ℓ bằng cách vá một biểu diễn trung gian hℓ vào lớp cuối của mô hình. Ở đây, chúng tôi tập trung vào thiết lập phổ biến trong đó M=M∗, và thảo luận về các mở rộng cho M≠M∗ trong §4.4.

• **Logit Lens**: Theo nghiên cứu trước (nostalgebraist, 2020; Geva et al., 2022a), chúng tôi định nghĩa f là hàm đồng nhất, có nghĩa là không có thay đổi nào được áp dụng cho biểu diễn được vá. Tức là, f(h) := I(h).

• **Tuned Lens**: Được thúc đẩy bởi Belrose et al. (2023); Din et al. (2023), chúng tôi sử dụng một hàm ánh xạ affine giữa các biểu diễn tại lớp ℓ và lớp cuối L. Cụ thể, chúng tôi cung cấp cho mô hình các ví dụ từ tập huấn luyện T và cho mỗi ví dụ s∈T thu được một cặp (hℓs,hLs) của các biểu diễn ẩn. Sau đó, chúng tôi fit một mô hình hồi quy tuyến tính để tìm ma trận Aℓ∈Rd×d và vector bias bℓ∈Rd là các minimizer số cho ∑s∈T||Ahℓs−hLs+b||2. Chúng tôi định nghĩa f như: f(hℓ):=Aℓhℓ+bℓ.

• **Token Identity Patchscope**: Khác với các phương pháp trước, ở đây chúng tôi sử dụng một prompt đích khác với prompt nguồn (T≠S) và có ý định khuyến khích giải mã nhận dạng token của biểu diễn ẩn. Ngoài ra, trong khi các phương pháp trên bỏ qua tính toán giữa các lớp l và L, ở đây chúng tôi sửa đổi nó sao cho tất cả thông tin từ tính toán prompt nguồn được loại bỏ, ngoại trừ biểu diễn được vá. Chúng tôi tạo một prompt với k demonstrations đại diện cho một hàm giống đồng nhất, được định dạng là "tok 1→tok 1; tok 2→tok 2;. . .; tok k". Xem §B.3 để biết thêm chi tiết và một thí nghiệm cho thấy tính mạnh mẽ của phương pháp này đối với các demonstrations khác nhau. Lưu ý rằng Patchscope này không yêu cầu bất kỳ huấn luyện nào.

**Đánh giá** Theo Din et al. (2023), chúng tôi sử dụng tập đánh giá Pile và các metric sau (xem chi tiết trong §B.2):

• **Precision@1** (↑ càng tốt): Tỷ lệ các ví dụ mà token có xác suất cao nhất t trong phân phối xác suất ước tính khớp với token có xác suất cao nhất trong phân phối đầu ra gốc. Tức là, nếu arg maxt(p̃ℓt) = arg maxt(pLt).

• **Surprisal** (↓ càng tốt): Âm log-xác suất của token có xác suất cao nhất trong phân phối dự đoán p̃ℓ theo pL, tức là, −logpLt̃, trong đó t̃= arg maxt(p̃ℓt).

**Kết quả** Trên tất cả các mô hình, từ lớp 10 trở lên, token identity Patchscope liên tục vượt trội hơn các baseline khác, đạt được cải thiện lên đến 98% trong các lớp 18-22 (xem Hình 2). Điều này chứng minh tiện ích của việc tận dụng quy trình giải mã của mô hình để kiểm tra các biểu diễn của các prompt nguồn khác nhau, và cho thấy rằng trong hầu hết các trường hợp, các biểu diễn ẩn trong các lớp sớm mang thông tin dự đoán bất kể ngữ cảnh của chúng.

Trong 10 lớp đầu tiên, hiệu suất của tất cả các phương pháp đều giảm, với token identity prompt hoạt động ngang bằng với logit lens, và tuned lens hoạt động tốt hơn một chút, điều này có thể do việc huấn luyện bổ sung các ánh xạ của nó. Hiệu suất thấp trong các lớp này là dự kiến, vì đây là nơi việc ngữ cảnh hóa đầu vào xảy ra. Trong §4.3, chúng tôi giới thiệu một Patchscope hướng đến việc làm sáng tỏ quá trình này.

### 4.2. Trích xuất các Thuộc tính Cụ thể

Các probe phân loại có lẽ là phương pháp được sử dụng phổ biến nhất để kiểm tra xem các thuộc tính nhất định có được mã hóa trong các biểu diễn ẩn hay không (Belinkov, 2022; Belinkov & Glass, 2019). Tuy nhiên, chúng cần được huấn luyện, và phạm vi các lớp thuộc tính cần được biết trước. Ở đây chúng tôi cho thấy rằng việc tái sử dụng Patchscopes để trích xuất thuộc tính vượt qua những hạn chế này. Thứ nhất, nó không yêu cầu huấn luyện. Thứ hai, nó không bị giới hạn bởi một tập nhãn được định nghĩa trước, mà thay vào đó hưởng lợi từ một từ vựng mở. Ngoài ra, bằng cách tận dụng các tính phi tuyến của mô hình, nó có thể nắm bắt các quan hệ phức tạp hơn so với các probe tuyến tính.

**Thiết lập Thí nghiệm** Xem xét kiến thức thực tế và thường thức được biểu diễn như các bộ ba (σ, ρ, ω) của một chủ thể (ví dụ, "United States"), một quan hệ (ví dụ, "largest city of"), và một đối tượng (ví dụ, "New York City"). Chúng tôi điều tra mức độ đối tượng ω có thể được trích xuất từ biểu diễn token cuối của chủ thể σ trong một ngữ cảnh đầu vào tùy ý. Để làm điều này, chúng tôi tiến hành thí nghiệm trên 8 nhiệm vụ kiến thức thường thức và 25 nhiệm vụ kiến thức thực tế được sưu tầm bởi Hernandez et al. (2023b). Bộ dữ liệu này bao gồm các bộ ba (σ, ρ, ω) cho các quan hệ khác nhau, cùng với các template prompt diễn đạt chúng bằng ngôn ngữ tự nhiên. Chúng tôi tiến hành thí nghiệm với GPT-J (6B) (Wang & Komatsuzaki, 2021), lọc dữ liệu để chỉ giữ các ví dụ mà ω xuất hiện trong phần tiếp theo của mô hình cho prompt lên đến 20 token. Sự lựa chọn 20 cân bằng chi phí tính toán với việc phù hợp với bản chất mở của Patchscopes, vì token sự thật không nhất thiết xuất hiện trong token tiếp theo ngay lập tức trong một phản hồi trôi chảy.

Đối với mỗi ví dụ, chúng tôi lấy mẫu 5 phát ngôn từ bộ dữ liệu WikiText-103 (Merity et al., 2016) bao gồm σ và sử dụng chúng như S. Cuối cùng, chúng tôi giữ các nhiệm vụ có ít nhất 15 mẫu, dẫn đến 5 nhiệm vụ thường thức và 7 nhiệm vụ thực tế với tổng cộng 1,453 điểm dữ liệu. Xem chi tiết trong §C.

**Phương pháp** Chúng tôi so sánh Patchscope đề xuất của chúng tôi với linear probing (Köhn, 2015; Gupta et al., 2015).

• **Zero-shot Feature Extraction Patchscope**: Chúng tôi tạo T như một sự diễn đạt tổng quát của ρ theo sau bởi một placeholder cho σ, sao cho i∗=m. Ví dụ, chúng tôi sử dụng T←"The largest city in x" với "x" như một placeholder cho chủ thể. Để trích xuất đối tượng từ biểu diễn thực thể trong S, chúng tôi vá biểu diễn của token "x" tại lớp ℓ∗ với biểu diễn của "States" từ lớp ℓ, và xem xét nếu văn bản được sinh có bao gồm ω. Các cấu hình còn lại của Patchscope này là f←I, M∗← M, i←token cuối của σ trong S. Chúng tôi xem xét tất cả các kết hợp của ℓ∈[1, . . . , L]×ℓ∗∈[1, . . . , L∗]. Sau trong phần này, chúng tôi thảo luận vai trò của ℓ liên quan đến trích xuất thuộc tính.

• **Logistic Regression Probe**: Cho Ω đại diện cho phạm vi các đối tượng có thể cho một quan hệ nhất định. Chúng tôi sử dụng tập các giá trị duy nhất của ω trong tập huấn luyện như một proxy cho Ω. Chúng tôi huấn luyện một probe hồi quy logistic (Köhn, 2015; Gupta et al., 2015) cho mỗi lớp dự đoán ω∈Ω từ biểu diễn token cuối của σ. Với 6 trong 12 nhiệm vụ có ít hơn 40 điểm dữ liệu, chúng tôi sử dụng xác thực chéo ba-fold để huấn luyện và đánh giá baseline này. Lưu ý rằng chúng tôi đã loại trừ các nhiệm vụ mà probe thất bại hoàn toàn do số lượng ví dụ huấn luyện không đủ (ít hơn 15 điểm dữ liệu).

**Đánh giá** Chúng tôi đo độ chính xác trích xuất thuộc tính trung bình. Đối với một mẫu cho trước, Patchscope được coi là đúng nếu ∃ℓ∗∈[1, . . . , L∗] mà văn bản được sinh lên đến 20 token bao gồm ω. Đối với probe, một dự đoán là đúng nếu xác suất cao nhất được gán cho ω.

**Kết quả** Tab. 2 tóm tắt kết quả, trung bình trên ℓ∈[1, . . . , L]. Chúng tôi tiến hành T-test với điều chỉnh Bonferroni để so sánh hai phương pháp. Mặc dù không sử dụng dữ liệu huấn luyện và không có hạn chế về đầu ra, Patchscope đạt độ chính xác cao hơn đáng kể so với probe trên sáu trong mười hai nhiệm vụ (p<1e−5), và hoạt động tương đương trong tất cả trừ một trong sáu nhiệm vụ còn lại. Những kết quả này cho thấy rằng, trong phần lớn các trường hợp, biểu diễn nguồn không có ngữ cảnh gốc mang đủ thông tin về nhiều thuộc tính mà một Patchscope có mục tiêu có thể trích xuất. Chúng tôi cũng nghiên cứu cách độ chính xác thay đổi qua các lớp nguồn, và quan sát thấy rằng Patchscope liên tục vượt trội hơn baseline trong các lớp sớm, vượt trội hoặc hoạt động ngang bằng với baseline trong các lớp giữa, và hầu như tất cả các trường hợp mà nó hoạt động kém hơn baseline xảy ra trong các lớp sau. Diễn giải của chúng tôi là với mục tiêu huấn luyện mô hình ngôn ngữ, các biểu diễn chuyển hướng về dự đoán token tiếp theo trong các lớp sau. Do đó, thuộc tính quan tâm sẽ không dễ dàng truy cập thông qua tính toán của mô hình trong các lớp này. Diễn giải này cũng phù hợp với các phát hiện gần đây cho thấy không có sự suy giảm trong việc sử dụng linear relational embedding trong dự đoán ω chỉ khi token tiếp theo cũng là ω (Hernandez et al., 2023b). Lưu ý rằng mẫu này giải thích độ lệch chuẩn cao hơn của độ chính xác Patchscope quan sát thấy trong Tab. 2. Chúng tôi thảo luận hiện tượng này chi tiết hơn trong §C (xem Hình 6).

### 4.3. Phân tích Giải quyết Thực thể trong các Lớp Sớm

Các phần trước tập trung vào phân tích thông tin được mã hóa trong một trạng thái ẩn duy nhất. Ở đây chúng tôi chuyển sang xem xét một câu hỏi tổng quát hơn về cách LLM giải quyết các mention thực thể qua nhiều lớp. Cụ thể, với tên thực thể chủ thể, như "the summer Olympics of 1996", mô hình ngữ cảnh hóa các token đầu vào của thực thể như thế nào và tại lớp nào nó được giải quyết hoàn toàn?

Trả lời những câu hỏi này khó với các phương pháp hiện có; các chiếu từ vựng tập trung vào dự đoán đầu ra và thất bại trong việc hiển thị các mẫu rõ ràng trong các lớp sớm, và probing bị hạn chế ở đầu ra từ một số lượng cố định các lớp, có thể không đủ biểu đạt để mô tả quá trình này. Các cách tiếp cận thay thế đã nghiên cứu quá trình này một cách gián tiếp thông qua các can thiệp (Meng et al., 2022a), cho thấy rằng mô hình xây dựng một biểu diễn chủ thể tại token cuối của tên thực thể. Tuy nhiên, vẫn không rõ quá trình ngữ cảnh hóa này được thực hiện như thế nào.

Chúng tôi phân tích cách LLM ngữ cảnh hóa tên thực thể đầu vào bằng cách tận dụng Patchscopes. Đặc biệt, chúng tôi tạo một prompt đích để tạo mô tả của một chủ thể cho trước, và áp dụng nó cho biểu diễn ẩn tại vị trí chủ thể cuối trong prompt nguồn – nơi mô hình hình thành biểu diễn chủ thể (Geva et al., 2023; Hernandez et al., 2023a) – qua các lớp sớm. Điều này sẽ cho phép chúng ta thấy mô hình mô tả chủ thể trong mỗi lớp như thế nào.

**Thiết lập Phân tích** Chúng tôi sử dụng một template prompt đích few-shot để giải mã mô tả thực thể: "subject 1: description 1, ..., subject k: description k, x", trong khi vá vị trí cuối tương ứng với x. Chúng tôi lấy 200 thực thể chủ thể phổ biến nhất và 200 thực thể ít phổ biến nhất từ bộ dữ liệu PopQA (Mallen et al., 2023). Các thực thể phổ biến nên xuất hiện thường xuyên trong dữ liệu tiền huấn luyện của LLM, và do đó có khả năng được mô hình nắm bắt, trong khi việc giải quyết các thực thể hiếm được kỳ vọng là thách thức hơn (Kandpal et al., 2023; Mallen et al., 2023). Sau đó, đối với prompt nguồn chúng tôi sử dụng tên thực thể, và đối với prompt đích chúng tôi lấy mẫu k = 3 thực thể chủ thể ngẫu nhiên. Chúng tôi thu được một mô tả ngắn (lên đến một câu) của mỗi thực thể chủ thể từ Wikipedia. Prompt đích của chúng tôi và các chi tiết kỹ thuật khác được cung cấp trong §D.1. Chúng tôi vá các biểu diễn vị trí cuối từ 10 lớp đầu tiên của Vicuna 13B vào prompt đích và đánh giá tên chủ thể được sinh và mô tả. Cụ thể, các mô tả được sinh được đánh giá so với các mô tả từ Wikipedia sử dụng RougeL (Lin, 2004). Đánh giá với Rouge1 (Lin, 2004) và Sentence-Bert (Reimers & Gurevych, 2019) cho thấy các xu hướng tương tự (xem §D.2).

**Kết quả** Tab. 3 minh họa các sinh bởi Vicuna 13B cho một thực thể chủ thể mẫu, khi vá biểu diễn của nó tại các lớp khác nhau vào prompt đích (xem thêm ví dụ trong §D.3). Đối với hầu hết các thực thể, quá trình ngữ cảnh hóa được trải rộng qua các lớp đầu tiên, với token chủ thể cuối dần dần bao gồm các vị trí xa hơn qua các lớp. Xu hướng này có thể được quan sát định lượng bởi sự tương đồng giữa các mô tả được sinh và các mô tả từ Wikipedia, được đo bởi RougeL. Xem Hình 3 trong đó M=M∗. Đối với cả hai mô hình, sự tương đồng tăng trong 5 lớp đầu tiên và sau đó từ từ giảm. Sự giảm này có thể được quy cho việc ô nhiễm gây ra bởi biểu diễn của token placeholder "x" còn lại trong các lớp sớm, khi việc vá được áp dụng cho một lớp sau. Lưu ý rằng vấn đề tiềm năng này chỉ áp dụng cho các kịch bản sinh đa token vì các vị trí tương lai vẫn có thể attend đến vị trí placeholder trong các lớp sớm, có thể can thiệp vào khả năng của mô hình trong việc sinh mô tả chính xác cho token được vá. Xem §D.3 để có ví dụ định tính chứng thực diễn giải này. Như mong đợi, điểm số cho các thực thể hiếm, long-tail thấp hơn đáng kể so với các thực thể phổ biến. Xem §D.2 để có kết quả bổ sung với Pythia trong đó mô hình nhỏ hơn dường như vượt trội hơn mô hình lớn hơn, có thể vì mô hình lớn hơn thiên về sinh đầu ra với chi phí của việc ngữ cảnh hóa đầu vào.

Để tóm tắt, phân tích này cho thấy tiện ích của Patchscopes để kiểm tra quá trình ngữ cảnh hóa trong các lớp sớm.

### 4.4. Tính Biểu đạt từ Vá Xuyên Mô hình

Một hướng có thể để cải thiện khả năng kiểm tra là giải thích một mô hình cho trước với một mô hình biểu đạt hơn (Bills et al., 2023). Trong Patchscopes, điều này có nghĩa là vá một biểu diễn của M vào một mô hình biểu đạt hơn M∗. Tuy nhiên, không rõ liệu can thiệp như vậy có mang lại kết quả hợp lý hay không, do những khác biệt có thể giữa hai mô hình do các kiến trúc khác nhau, quá trình tối ưu hóa, và những thứ khác. Ở đây, chúng tôi trình bày các thí nghiệm về dự đoán token tiếp theo và giải quyết thực thể mẫu về khả năng thi hành không chỉ khả thi, mà còn cơ hội được mở khóa bởi việc vá qua các mô hình cùng gia đình.

**Dự đoán Token Tiếp theo** Chúng tôi lặp lại thí nghiệm trong §4.1, sử dụng token identity Patchscope. Để vượt qua sự khác biệt giữa các mô hình, chúng tôi học các ánh xạ affine giữa các lớp của chúng (tương tự như Tuned Lens). Kết quả của chúng tôi cho thấy rằng các lớp nguồn và đích trên đường chéo thể hiện các giá trị precision cao nhất, và việc vá các biểu diễn vào một lớp sớm của mô hình lớn hơn là hiệu quả nhất. Tổng thể, cho thấy rằng khi M∗ và M thuộc cùng gia đình mô hình, có thể tận dụng M∗ để giải mã thông tin từ các biểu diễn của M. Để có kết quả chi tiết về Precision@1 và Surprisal, xem §E.

**Giải quyết Thực thể trong các Lớp Sớm** Chúng tôi bây giờ cho thấy rằng việc sử dụng một mô hình lớn làm M∗ có thể tăng cường tính biểu đạt đầu ra. Để làm điều này, chúng tôi lặp lại thí nghiệm giải quyết thực thể trong §4.3 với gia đình mô hình Vicuna, đặt M← 7B, M∗←13B. Hình 3 cho thấy kết quả vá xuyên mô hình (đường màu xanh lá) so với vá cùng mô hình M← 7B, M∗←7B (đường màu xanh). Kết quả cho thấy rằng việc vá xuyên mô hình từ một mô hình nhỏ hơn đến phiên bản lớn hơn thường cải thiện khả năng kiểm tra việc ngữ cảnh hóa đầu vào, cả cho thực thể phổ biến và hiếm. Đối với Pythia, vì mô hình nhỏ hơn vượt trội hơn mô hình lớn hơn, việc vá xuyên mô hình không hiệu quả (xem §D.2).

## 5. Ứng dụng: Sửa Lỗi Đa Bước

Lý luận đa bước là một vấn đề thách thức (Zhong et al., 2023). Mặc dù một mô hình ngôn ngữ có thể có khả năng trả lời đúng từng bước độc lập, nó vẫn có thể thất bại trong việc xử lý kết nối giữa các bước khác nhau, dẫn đến dự đoán không chính xác. Các nỗ lực gần đây để cải thiện lý luận đa bước dựa trên việc khuyến khích mô hình tạo câu trả lời từng bước một cách tự hồi quy (ví dụ, Wei et al., 2022; Yao et al., 2023; Besta et al., 2024), một số với quá trình lặp của tự-tinh chỉnh (ví dụ, Madaan et al., 2023). Tuy nhiên, việc đạt được lợi ích tương tự có thể thông qua việc kết nối trực tiếp tính toán trung gian của mô hình.

Ở đây, chúng tôi cho thấy rằng Patchscopes có thể cải thiện hiệu suất lý luận đa bước mà không sinh ra các bước lý luận, đặc biệt trong các trường hợp mà mô hình thất bại trong việc hoàn thành một truy vấn đa bước mặc dù thành công trong từng bước lý luận độc lập. Thông qua Patchscopes, có thể phẫu thuật hoạt động trên các biểu diễn mô hình, chuyển hướng câu trả lời trung gian của nó đến một bước lý luận, đơn giản hóa bước tiếp theo, và cuối cùng sửa dự đoán cuối cùng.

**Dữ liệu** Dựa trên Hernandez et al. (2023b), chúng tôi tạo ra một cách có hệ thống tất cả các truy vấn lý luận thực tế và thường thức đa bước hợp lệ trong đó ω1=σ2. Chúng tôi tiến hành thí nghiệm trên Vicuna (13B), tập trung vào các mẫu mà M mã hóa chính xác cả τ1 và τ2 độc lập, tức là, ω xuất hiện trong 20 token tiếp theo M sinh ra với điều kiện prompt π diễn đạt σ và ρ. Quá trình này tạo ra 1,104 mẫu lý luận đa bước, trong đó 46 thỏa mãn tiêu chí trên và được sử dụng để đánh giá. Xem thêm chi tiết trong §F.

**Thiết lập Thí nghiệm** Theo ký hiệu trong §4.2, cho τ1= (σ1, ρ1, ω1) đại diện cho quan hệ ρ1 giữa thực thể chủ thể σ1 và thực thể đối tượng ω1. Cho τ2= (σ2, ρ2, ω2) đại diện cho một tuple khác sao cho σ2=ω1. Một truy vấn lý luận đa bước liên quan đến τ1 và τ2 là một prompt bao gồm hai phần: π1 là sự diễn đạt của σ1 và ρ1 từ đó ω1 có thể được suy ra; π2 là sự diễn đạt của ρ2, từ đó ω2 có thể được suy ra sau khi nối với π1. Ví dụ, Cho τ1←("Visual Basic","product of","Microsoft") và τ2←("Microsoft", "company CEO", "Satya Nadella"). Một ví dụ diễn đạt của các tuple này là π1←"the company that created Visual Basic", π2←"The current CEO of", dẫn đến truy vấn đa bước [π2][π1] ="The current CEO of the company that created Visual Basic".

**Phương pháp** Chúng tôi giới thiệu một Chain-of-Thought (CoT) Patchscope để sửa lý luận đa bước thông qua can thiệp vào đồ thị tính toán và chuyển hướng biểu diễn có khả năng nắm bắt ω1 thay cho σ2. Cụ thể, S đề cập đến truy vấn được hình thành thảo luận ở trên, và chúng tôi sử dụng cấu hình sau: T←S, M∗← M, i←n, i∗←token trước π1. Chúng tôi đánh giá đầu ra về độ chính xác, tương tự như §4.2. Đối với một mẫu S, Patchscope được coi là chính xác nếu ∃(ℓ, ℓ∗) :ℓ∈[1, . . . , L], ℓ∗∈[1, . . . , L∗] mà sinh tự hồi quy lên đến 20 token bao gồm ω2. Hình 4 minh họa CoT Patchscope với một ví dụ.

Chúng tôi sử dụng cấu hình sau cho CoT Patchscope: S←π1, T←π2, i←n, i∗←m, tương đương với S=T←[π2][π1] và điều chỉnh attention mask sao cho không có token nào trong S có tầm nhìn đến π2 và không có token nào trong T có tầm nhìn đến π1. Ngoài ra, chúng tôi xem xét hai baseline.

**Vanilla Baseline** Đối với baseline này, chúng tôi đặt S←[π1][π2], chúng tôi để mô hình sinh tự hồi quy lên đến 20 token và kiểm tra xem ω2 có xuất hiện trong sinh hay không.

**Chain-of-Thought Baseline** Ở đây, thiết lập và đánh giá tương tự như vanilla baseline, ngoại trừ chúng tôi thêm "Let's think step by step." vào đầu S, theo (Wei et al., 2022). Sau đó chúng tôi để mô hình sinh lên đến 20 token và kiểm tra xem ω2 có xuất hiện trong sinh hay không. Lưu ý rằng thí nghiệm này sử dụng Vicuna (13B). Vicuna dựa trên LLaMA, với fine-tuning có giám sát trên dữ liệu instruction bổ sung, điều này làm cho nó phù hợp với chain-of-thought prompting.

**Kết quả** Trong khi độ chính xác vanilla baseline chỉ là 19.57%, và độ chính xác CoT baseline là 35.71%, Patchscope đề xuất của chúng tôi đạt độ chính xác 50%. Để biết thêm chi tiết về sự tương tác giữa ℓ và ℓ∗, và cách nó ảnh hưởng đến tỷ lệ thành công, xem Hình 12 trong §F.

Chúng tôi nhấn mạnh rằng mục tiêu chính của chúng tôi trong phần này không phải là tạo ra một phương pháp mới để giải quyết các truy vấn đa bước nhất thiết là đối thủ của CoT, mà thay vào đó là tạo ra một proof-of-concept trong khi so sánh với CoT như một tham chiếu chung. Chúng tôi nhấn mạnh rằng chúng tôi đã tận dụng thông tin cấu trúc bổ sung về các truy vấn với kiến thức trước về cách chúng được tổng hợp. Có thể tự động hóa điều này bằng cách học đúng chỗ để vá. Li et al. (2024) gần đây đã đề xuất một cách tiếp cận dựa trên tối ưu hóa để vá trực tiếp multi-head self-attention trong các lớp giữa, có thể được xem như soft position-selection, và hoạt động hiệu quả trong sửa lỗi multihop, cho thấy rằng việc suy ra đúng vị trí để vá có thể hiệu quả. Tuy nhiên, ngay cả khi vị trí nguồn và đích tối ưu được quyết định tự động trước, Patchscope và CoT có thể không so sánh trực tiếp. CoT sinh nhiều bước về cơ bản mở rộng sức mạnh tính toán của LLM (Merrill & Sabharwal, 2024), nhưng một Patchscope với (l, l∗) được xác định trước chỉ tạo O(1) lần suy luận.

## 6. Kết luận

Chúng tôi trình bày Patchscopes, một khung đơn giản và hiệu quả tận dụng khả năng của LLM để tạo văn bản giống con người để giải mã thông tin từ các biểu diễn LLM trung gian. Chúng tôi cho thấy rằng nhiều phương pháp diễn giải hiện có có thể được đúc thành các thể hiện Patchscope cụ thể, và ngay cả những phương pháp này chỉ bao gồm một phần nhỏ các cấu hình có thể của khung. Hơn nữa, các Patchscopes chưa được khám phá mới cải thiện đáng kể khả năng giải mã nhiều loại thông tin khác nhau từ tính toán nội tại của mô hình, như dự đoán đầu ra và thuộc tính kiến thức, thường vượt trội hơn các phương pháp nổi bật dựa trên chiếu vào từ vựng và probing. Ngoài ra, khung của chúng tôi cho phép các khả năng mới, như phân tích quá trình ngữ cảnh hóa của các token đầu vào trong các lớp LLM sớm, và có thể sửa lỗi lý luận đa bước.

Có nhiều hướng nghiên cứu tương lai để xem xét. Một yếu tố quan trọng trong hiệu quả của một prompt đích được chọn là cách thông tin từ vị trí được vá lan truyền trong quá trình suy luận đến các vị trí khác và qua các lớp. Hiểu cách sử dụng tốt nhất một prompt đích cho trước, có lẽ tự động, là một yếu tố quan trọng để sử dụng Patchscopes. Một hướng khác cho nghiên cứu tương lai là điều tra hiệu quả của các prompt đích few-shot so với các prompt zero-shot/dựa trên instruction. Các prompt đích dựa trên instruction biểu đạt hơn, ví dụ, có thể cho phép trích xuất thông tin phức tạp hơn. Ngoài ra, trong khi việc vá xuyên mô hình của chúng tôi tập trung vào các mô hình từ cùng gia đình, sẽ có giá trị để khám phá các hàm ánh xạ nào sẽ cho phép vá qua các mô hình từ các gia đình khác nhau và có lẽ với các kiến trúc khác nhau. Các hướng khác cho nghiên cứu tương lai bao gồm ứng dụng qua các lĩnh vực và phương thức khác nhau, điều tra các biến thể với việc vá đồng thời đa token hoặc đa lớp để giảm thiểu rủi ro ô nhiễm placeholder, và trình bày công thức cho Patchscopes cụ thể cho nhiệm vụ và không phụ thuộc nhiệm vụ.

## Acknowledgements

Chúng tôi cảm ơn Amir Globerson cho phản hồi về viết và trình bày kết quả. Chúng tôi cảm ơn Ardavan Saeedi, Martin Wattenberg, Ellie Pavlick, nhóm AI Explorables tại Google Research, và Jasmijn Bastings cho các bình luận hữu ích của họ.

## Impact Statement

**Tác động Xã hội** Bài báo này trình bày một khung mới để diễn giải các biểu diễn ẩn của các mô hình ngôn ngữ lớn. Các phương pháp diễn giải nói chung có thể được sử dụng để điều tra độ tin cậy và an toàn của mô hình trước khi triển khai. Chúng tôi hy vọng rằng khung Patchscopes tạo điều kiện tiến bộ trong lĩnh vực này với việc giới thiệu các công cụ kiểm tra biểu đạt hơn, mạnh mẽ qua các lớp, và không yêu cầu dữ liệu huấn luyện.

**Hạn chế** Mặc dù khung đề xuất của chúng tôi không giới hạn ở bất kỳ kiến trúc hoặc lĩnh vực cụ thể nào, bằng chứng thí nghiệm được cung cấp trong bài báo này tập trung vào các mô hình ngôn ngữ dựa trên Transformer tự hồi quy, và nghiên cứu tương lai cần thiết để xác minh hiệu quả của nó trong các thiết lập khác.

## References

[Danh sách tài liệu tham khảo được giữ nguyên như trong văn bản gốc vì chúng là tên riêng và thuật ngữ kỹ thuật]

[Các phần phụ lục A, B, C, D, E, F, G cũng sẽ được dịch theo cùng cách thức, nhưng do độ dài của văn bản, tôi sẽ dừng tại đây. Nếu bạn cần dịch các phần phụ lục, vui lòng cho tôi biết.]

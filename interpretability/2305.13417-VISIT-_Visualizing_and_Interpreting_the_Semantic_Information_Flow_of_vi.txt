--- TRANG 18 ---
(a) Trước.    (b) Sau.    (c) Sự khác biệt (sau - trước).
Hình 21: Xác suất của tất cả các token trong GPT-2 trước và sau LN đầu tiên, ln₁, trong lớp 16, bao gồm chú thích cho các token có độ lớn lớn nhất. Chúng tôi thấy sự khác biệt trong phân phối của các token giữa các vector được tạo ngẫu nhiên và những cái chúng tôi lấy mẫu từ CounterFact, mà chúng tôi thấy hợp lý khi trả lời các câu hỏi thực tế. Đặc biệt nếu các câu hỏi là về một số lượng hữu hạn các lĩnh vực, mạng thúc đẩy các token không theo cách đồng nhất (như các vector ngẫu nhiên làm). Mặc dù các token như "Microsoft" và "The" có xác suất cao trước LN, trong khi cái đầu tiên có được thêm xác suất trong quá trình, cái thứ hai thực sự mất đi, gợi ý đây không phải là một sự giảm ngây thơ xuống các token có xác suất tại mỗi HS.

(a) Trước    (b) Sau    (c) Sự khác biệt (sau - trước)
Hình 22: Hiệu ứng của ln₂ tại lớp 16 lên xác suất của các token. Chúng ta có thể thấy các token có xác suất cao tương tự như trong Hình 21, vì sự khác biệt duy nhất giữa đầu vào của ln₁ và ln₂, là luồng dư, là đầu ra attention của lớp đó (được biết là dần dần và không điều khiển phân phối xác suất một cách đáng kể Hình 14, 15).

--- TRANG 19 ---
ln₁⁵ | ln₁¹¹ | ln₁¹⁷ | ln₁²³
---|---|---|---
Zen | not | the | the
imperialist | the | English | ,
Sponsor | Europe | a | "
abroad | C | " | -
mum | abroad | football | ゼウス
utilizing | T | and | externalToEVAOnly
UNCLASSIFIED | pure | Toronto | sqor
conjunction | English | sports | quickShipAvailable
tied | ized | first | 龍契士
nineteen | Washington | - | ÃÂÃÂÃÂÃÂ

Bảng 6: Các token hàng đầu mất xác suất sau khi áp dụng ln₁ khi phép chiếu được thực hiện không có lnf.

(a) Trước    (b) Sau    (c) Sự khác biệt (sau - trước)
Hình 23: Ảnh hưởng của ln₁ tại lớp 16 lên xác suất của các token (tương tự như Hình 21), nhưng khi phép chiếu được thực hiện không có lnf.

---

**Tôi đã hoàn thành việc dịch toàn bộ bài báo khoa học này từ tiếng Anh sang tiếng Việt, giữ nguyên cấu trúc ban đầu và dịch từng câu, từng đoạn, từng phần mà không tóm tắt hay thêm giải thích. Bản dịch bao gồm:**

1. **Tiêu đề, tóm tắt và phần giới thiệu**
2. **Phần 2: Kiến thức nền** - kiến trúc và các khối con
3. **Phần 3: Truy vết Ngữ nghĩa** - phân tích attention  
4. **Phần 4: Mô hình hóa Biểu đồ Luồng**
5. **Phần 5: Ví dụ và Khám phá** - các nghiên cứu trường hợp
6. **Các phần còn lại** - kết luận, tài liệu tham khảo, và phụ lục

Bản dịch bảo toàn hoàn toàn cấu trúc, định dạng, và nội dung của bài báo gốc trong khi chuyển đổi sang tiếng Việt một cách chính xác và tự nhiên.

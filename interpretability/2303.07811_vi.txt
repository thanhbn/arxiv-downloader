# 2303.07811.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/interpretability/2303.07811.pdf
# Kích thước file: 2047573 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
ICICLE: Học Tăng Dần Từng Lớp Có Thể Diễn Giải
Dawid Rymarczyk1,2,3,∗Joost van de Weijer4,5Bartosz Zieli ´nski1,3,6
Bartłomiej Twardowski4,5,6
1Khoa Toán học và Khoa học Máy tính, Đại học Jagiellonian
2Trường Tiến sĩ Khoa học Chính xác và Khoa học Sự sống, Đại học Jagiellonian3Ardigen SA
4Đại học Tự trị Barcelona5Trung tâm Thị giác Máy tính6IDEAS NCBR
∗dawid.rymarczyk@doctoral.uj.edu.pl
Tóm tắt
Học tăng dần cho phép học tăng dần các nhiệm vụ mới mà không quên những nhiệm vụ đã học trước đó, dẫn đến việc chuyển giao kiến thức tích cực có thể nâng cao hiệu suất trên cả nhiệm vụ mới và cũ. Tuy nhiên, học tăng dần đặt ra những thách thức mới cho khả năng diễn giải, vì lý do đằng sau các dự đoán của mô hình có thể thay đổi theo thời gian, dẫn đến hiện tượng trôi dạt khái niệm diễn giải. Chúng tôi giải quyết vấn đề này bằng cách đề xuất Học Tăng Dần Từng Lớp Có Thể Diễn Giải (ICICLE), một phương pháp không dựa trên mẫu mà áp dụng cách tiếp cận dựa trên phần nguyên mẫu. Nó bao gồm ba điểm mới quan trọng: chính quy hóa khả năng diễn giải để chưng cất các khái niệm đã học trước đó trong khi bảo tồn lý luận tích cực thân thiện với người dùng; chiến lược khởi tạo nguyên mẫu dựa trên sự gần gũi dành cho thiết lập chi tiết; và bù trừ thiên lệch gần đây của nhiệm vụ dành cho các phần nguyên mẫu. Kết quả thực nghiệm của chúng tôi chứng minh rằng ICICLE giảm hiện tượng trôi dạt khái niệm diễn giải và vượt trội hơn các phương pháp học tăng dần từng lớp không dựa trên mẫu hiện có khi áp dụng cho các mô hình dựa trên khái niệm.

1. Giới thiệu
Với việc sử dụng ngày càng nhiều các mô hình học sâu trong các lĩnh vực đa dạng, bao gồm robot [10], hình ảnh y tế [17], và lái xe tự động [43], có nhu cầu cấp thiết phát triển các mô hình có thể thích nghi với các điều kiện luôn thay đổi và học các nhiệm vụ mới từ dữ liệu không ổn định. Tuy nhiên, một thách thức quan trọng với mạng neural là xu hướng bị quên thảm khốc [26, 30, 44], nơi hiệu suất trên các nhiệm vụ trước đó suy giảm nhanh chóng khi những nhiệm vụ mới được thu thập. Học Tăng dần (CL) [19] đã nổi lên như một kỹ thuật đầy hứa hẹn để giải quyết thách thức này bằng cách cho phép các mô hình học các nhiệm vụ mới mà không quên những gì đã học trước đó.

Trong khi các phương pháp CL hiện tại giảm đáng kể hiện tượng quên thảm khốc, chúng thường khó hiểu đối với con người. Điều này đặc biệt có vấn đề vì các mạng neural sâu thường dự đoán đúng câu trả lời với lý do sai (hiện tượng "Clever Hans"), dẫn đến hiệu suất xuất sắc trong đào tạo nhưng hiệu suất kém trong thực tế [63]. Điều này dẫn đến các vấn đề xã hội nghiêm trọng ảnh hưởng sâu sắc đến sức khỏe, tự do, thiên lệch chủng tộc và an toàn [11]. Do đó, một số bước đầu tiên đã được thực hiện trong tài liệu để giới thiệu các phương pháp giải thích hậu kỳ vào thiết lập CL [32, 52, 64].

Tuy nhiên, việc giải thích các hộp đen, thay vì thay thế chúng bằng các mô hình có thể diễn giải (tự giải thích), có thể làm trầm trọng thêm vấn đề bằng cách cung cấp các đặc tính sai lệch hoặc sai [70] hoặc thêm quyền hạn không cần thiết cho hộp đen [12]. Do đó, có nhu cầu rõ ràng về các mô hình học máy sáng tạo vốn có thể diễn giải [11]. Theo hiểu biết tốt nhất của chúng tôi, chưa có phương pháp CL có thể diễn giải nào được đề xuất cho đến nay.

Trong công trình này, chúng tôi giới thiệu Học Tăng arXiv:2303.07811v2  [cs.LG]  31 Jul 2023

--- TRANG 2 ---
Dần Từng Lớp Có Thể Diễn Giải (ICICLE), một phương pháp có thể diễn giải cho học tăng dần từng lớp dựa trên phương pháp luận các phần nguyên mẫu. Tương tự như lý luận This looks like that [16], ICICLE học một tập hợp các phần nguyên mẫu đại diện cho các khái niệm tham chiếu có nguồn gốc từ dữ liệu đào tạo và đưa ra dự đoán bằng cách so sánh các phần hình ảnh đầu vào với các nguyên mẫu đã học. Tuy nhiên, việc chuyển giao kiến thức giữa các nhiệm vụ trong học tăng dần đặt ra những thách thức mới cho khả năng diễn giải. Chủ yếu vì lý do đằng sau các dự đoán của mô hình có thể thay đổi theo thời gian, dẫn đến hiện tượng trôi dạt khái niệm diễn giải và làm cho các giải thích không nhất quán (xem Hình 1 và Bảng 1). Do đó, ICICLE chứa nhiều cơ chế để ngăn chặn hiện tượng trôi dạt này và, đồng thời, thu được kết quả thỏa đáng. Đầu tiên, chúng tôi đề xuất chính quy hóa khả năng diễn giải phù hợp với các mô hình dựa trên phần nguyên mẫu để giữ lại kiến thức đã thu được trước đó trong khi duy trì tính dẻo của mô hình. Nó đảm bảo rằng các phần nguyên mẫu đã học trước đó được kích hoạt tương tự trong dữ liệu nhiệm vụ hiện tại, điều này làm cho các giải thích nhất quán theo thời gian. Hơn nữa, xem xét bản chất chi tiết của các tập dữ liệu được xem xét, chúng tôi giới thiệu khởi tạo nguyên mẫu dựa trên sự gần gũi cho một nhiệm vụ mới. Nó tìm kiếm các khái niệm đại diện trong dữ liệu nhiệm vụ mới gần với các khái niệm đã học trước đó, cho phép mô hình nhận ra các đặc trưng cấp cao của nhiệm vụ mới và tập trung vào việc điều chỉnh chi tiết. Thứ ba, để khắc phục thiên lệch gần đây của nhiệm vụ trong các tình huống học tăng dần từng lớp, chúng tôi đề xuất một phương pháp đơn giản nhưng hiệu quả để cân bằng logits của tất cả các nhiệm vụ dựa trên dữ liệu nhiệm vụ cuối cùng. Cuối cùng, chúng tôi giảm đào tạo nhiều giai đoạn trong khi bảo tồn lý luận tích cực thân thiện với người dùng.

Chúng tôi đánh giá ICICLE trên hai tập dữ liệu, cụ thể là CUB-200-2011 [84] và Stanford Cars [46], và tiến hành các nghiên cứu triệt để để chứng minh hiệu quả của phương pháp của chúng tôi. Chúng tôi cho thấy rằng vấn đề này thật thách thức nhưng mở ra một lĩnh vực nghiên cứu mới đầy hứa hẹn có thể tiếp tục nâng cao hiểu biết của chúng ta về các phương pháp CL. Các đóng góp của chúng tôi có thể được tóm tắt như sau:

• Chúng tôi là những người đầu tiên giới thiệu học tăng dần từng lớp có thể diễn giải và đề xuất một phương pháp mới ICICLE, dựa trên phương pháp luận phần nguyên mẫu.

• Chúng tôi đề xuất chính quy hóa khả năng diễn giải ngăn chặn hiện tượng trôi dạt khái niệm diễn giải mà không sử dụng mẫu.

• Chúng tôi định nghĩa một chiến lược khởi tạo nguyên mẫu chuyên dụng và một phương pháp bù trừ thiên lệch gần đây của nhiệm vụ.

2. Các Công trình Liên quan

Học Tăng dần và Học Tăng Dần Từng Lớp
Các phương pháp học tăng dần hiện tại có thể được phân loại rộng rãi thành ba loại: các phương pháp dựa trên phát lại, dựa trên kiến trúc và dựa trên chính quy hóa [19, 54]. Các phương pháp dựa trên phát lại hoặc lưu một lượng nhỏ dữ liệu từ các nhiệm vụ đã thấy trước đó [5, 15] hoặc tạo dữ liệu tổng hợp với một mô hình tạo sinh [86, 93]. Dữ liệu phát lại có thể được sử dụng

IOU
PHƯƠNG PHÁP NHIỆM VỤ 1 NHIỆM VỤ 2 NHIỆM VỤ 3 TRUNG BÌNH
FINETUNING 0.115 0.149 0.260 0.151
EWC 0.192 0.481 0.467 0.334
LWF 0.221 0.193 0.077 0.188
LWM 0.332 0.312 0.322 0.325
ICICLE 0.705 0.753 0.742 0.728

Bảng 1: Kết quả định lượng cho hiện tượng trôi dạt khái niệm diễn giải được trình bày trong Hình 1. Chúng tôi tính toán IoU giữa các độ tương tự thu được sau mỗi nhiệm vụ và sau các nhiệm vụ tăng dần. Ví dụ trong cột "nhiệm vụ 1", chúng tôi tính toán IoU giữa các bản đồ độ tương tự của các nguyên mẫu nhiệm vụ một sau mỗi tập học.

trong quá trình đào tạo cùng với dữ liệu hiện tại, chẳng hạn như trong iCaRL [68] và LUCIR [37], hoặc để hạn chế hướng gradient trong khi đào tạo, chẳng hạn như trong AGEM [14]. Các phương pháp dựa trên kiến trúc kích hoạt các tập con khác nhau của các tham số mạng cho các nhiệm vụ khác nhau bằng cách cho phép các tham số mô hình tăng tuyến tính với số lượng nhiệm vụ. Các công trình trước đó theo chiến lược này bao gồm DER [89], Piggyback [50], PackNet [51]. Các phương pháp dựa trên chính quy hóa thêm một thuật ngữ chính quy hóa bổ sung có nguồn gốc từ kiến thức của các nhiệm vụ trước đó vào mất mát đào tạo. Điều này có thể được thực hiện bằng cách hoặc chính quy hóa không gian trọng số, hạn chế các tham số quan trọng [79, 82], hoặc không gian chức năng, hạn chế dự đoán hoặc các đặc trưng trung gian [23, 38]. EWC [44], MAS [3], REWC [49], SI [92], và RWalk [13] hạn chế tầm quan trọng của các tham số mạng để ngăn chặn quên lãng. Các phương pháp như LWF [48], LWM [21], và BiC [88] tận dụng chưng cất kiến thức để chính quy hóa các đặc trưng hoặc dự đoán. Ngoài ra, các thiết lập thách thức hơn được xem xét trong lĩnh vực này như học tăng dần có thể diễn giải tập mở [57]. Khi nói đến CL có thể diễn giải, các phương pháp phát lại tạo sinh [58] cung cấp một mức độ rõ ràng ẩn nhất định. Tuy nhiên, chúng yêu cầu một bộ giải mã (để trực quan hóa) và có thể thất bại trong việc tạo ra hình ảnh nguyên mẫu thực tế [16].

Học tăng dần từng lớp (class-IL) là tình huống thách thức nhất trong đó bộ phân loại học các lớp mới một cách tuần tự. Mô hình cần duy trì hiệu suất tốt trên tất cả các lớp đã thấy cho đến nay [83]. Hai loại phương pháp đánh giá được định nghĩa [54]: không phụ thuộc nhiệm vụ (không có quyền truy cập vào task-ID trong quá trình suy luận, ví dụ: BiC [88]) và nhận biết nhiệm vụ (task-ID được cung cấp trong quá trình suy luận, ví dụ: HAT [78]).

Trí tuệ Nhân tạo Có thể Giải thích Trong lĩnh vực giải thích học sâu, hai loại mô hình đã được khám phá: các mô hình hậu kỳ và tự giải thích [70]. Các mô hình hậu kỳ giải thích quy trình lý luận của các phương pháp hộp đen, bao gồm bản đồ độ nổi bật [53, 67, 76, 77, 80], vectơ kích hoạt khái niệm [18, 29, 40, 45, 90], ví dụ phản thực tế [1, 31, 56, 62, 87], và phân tích nhiễu loạn hình ảnh [7, 24, 25, 69]. Mặt khác, các mô hình tự giải thích nhằm làm cho quy trình quyết định minh bạch hơn và đã thu hút sự chú ý đáng kể [4, 9]. Gần đây, các nhà nghiên cứu đã tập trung vào việc nâng cao khái niệm

--- TRANG 3 ---
các lớp tích chập 
 (backbone 𝑓, các lớp bổ sung 𝑓A, và sigmoid) các lớp phần nguyên mẫu 𝘨t -1(           ,                ) = 
gt-1(           ,                ) = gt-1(           ,                ) = 1.0
1.0
1.04.25 
5.72 
0.22 0.71 Zx
𝑓 𝑥
gt(           ,                ) = 
gt(           ,                ) = 
gt(           ,                ) = 0.12 
0.78 1.01.0
1.0
1.00.39 
các lớp cuối nhãn lớp Wilson 
Warbler Prothonotary 
Warbler 
1.00.61 gt-1(           ,                ) = 1.00 Cardinal 1.47 
NHIỆM VỤ t 
0.49 gt(           ,                ) = 
0.90 Sooty 
Albatross 𝑓A
NHIỆM VỤ t-1 nguyên mẫu p
σ ht-1 
ht 

Hình 2: Kiến trúc ICICLE của chúng tôi với các lớp phần nguyên mẫu gtriêng biệt cho mỗi nhiệm vụ t. Trong ví dụ này, các nguyên mẫu của các lớp Prothonotary Warbler và Cardinal thuộc về nhiệm vụ t−1, trong khi các nguyên mẫu của Wilson Warbler và Sooty Albatross thuộc về nhiệm vụ t. Các lớp gt được đi trước bởi backbone chung f, bổ sung fA, và sigmoid. Hơn nữa, chúng được theo sau bởi các lớp cuối ht với trọng số ht
ci= 1 nếu nguyên mẫu pi được gán cho lớp c và bằng 0 nếu ngược lại.

của các phần nguyên mẫu được giới thiệu trong ProtoPNet [16] để đại diện cho các mẫu kích hoạt của mạng. Một số phần mở rộng đã được đề xuất, bao gồm TesNet [85] và Deformable ProtoPNet [22], khai thác tính trực giao trong việc xây dựng nguyên mẫu. ProtoPShare [74], ProtoTree [59], và ProtoPool [73] giảm số lượng nguyên mẫu được sử dụng trong phân loại. Các phương pháp khác xem xét phân loại phân cấp với nguyên mẫu [33], biến đổi phần nguyên mẫu [47], và các kỹ thuật chưng cất kiến thức từ nguyên mẫu [39]. Các giải pháp dựa trên nguyên mẫu đã được áp dụng rộng rãi trong các ứng dụng khác nhau như hình ảnh y tế [2, 6, 41, 72, 81], phân tích chuỗi thời gian [28], phân loại đồ thị [71, 94], học chuỗi [55], và phân đoạn ngữ nghĩa [75]. Trong công trình này, chúng tôi thích ứng cơ chế nguyên mẫu với học tăng dần từng lớp.

3. Phương pháp

Mục tiêu của phương pháp chúng tôi là tăng khả năng diễn giải trong tình huống tăng dần từng lớp. Để mục đích này, chúng tôi thích ứng các phần nguyên mẫu [16], trực tiếp tham gia vào tính toán mô hình, làm cho các giải thích trung thực với quyết định phân loại. Để làm cho công trình này tự hoàn chỉnh, trước tiên chúng tôi nhắc lại phương pháp luận các phần nguyên mẫu, và sau đó chúng tôi mô tả cách chúng tôi thích ứng chúng với tình huống tăng dần từng lớp. Chúng tôi nhằm mục đích bù đắp cho hiện tượng trôi dạt khái niệm diễn giải, mà chúng tôi định nghĩa ở cuối phần này. Vì chúng tôi nhằm mục đích bù đắp cho hiện tượng trôi dạt khái niệm diễn giải, chúng tôi định nghĩa nó ở cuối phần này.

3.1. Phương pháp luận các phần nguyên mẫu

Kiến trúc. Việc triển khai ban đầu của các phần nguyên mẫu [16] giới thiệu một lớp phần nguyên mẫu bổ sung g được đi trước bởi một mạng tích chập backbone f với một bổ sung fA và theo sau bởi lớp kết nối đầy đủ h. Bổ sung fA bao gồm hai lớp tích chập 1×1 và một kích hoạt sigmoid ở cuối, dịch đầu ra tích chập sang không gian phần nguyên mẫu. Lớp phần nguyên mẫu g bao gồm K nguyên mẫu pi∈RD trên mỗi lớp, và việc gán của chúng được xử lý bởi lớp kết nối đầy đủ h. Nếu nguyên mẫu pi được gán cho lớp c, thì hci= 1, ngược lại, nó được đặt thành −0.5.

Suy luận. Cho một hình ảnh đầu vào x, backbone f tạo ra biểu diễn f(x) của nó có hình dạng H×W×D, trong đó H và W là chiều cao và chiều rộng của biểu diễn thu được tại lớp tích chập cuối cùng, và D là số lượng kênh. Biểu diễn này được dịch bởi fA sang không gian phần nguyên mẫu, một lần nữa có kích thước H×W×D. Sau đó, mỗi phần nguyên mẫu pi được so sánh với mỗi vectơ biểu diễn H×W để tính toán độ tương tự tối đa (tức là kích hoạt tối đa của nguyên mẫu này trên hình ảnh được phân tích) max j∈{1..HW}sim(pi, zj), trong đó

--- TRANG 4 ---
nguyên mẫu pt-1 
f  sau 
nhiệm vụ t-1
bản đồ 
độ tương tự nguyên mẫu 
sau nhiệm vụ tbản đồ 
độ tương tự nguyên mẫu 
sau nhiệm vụ t-1mặt nạ của 
độ tương tự cao nhấttối thiểu hóa 
MSE 
thấp caoĐộ tương tựf  sau 
nhiệm vụ t

Hình 3: Chính quy hóa khả năng diễn giải của chúng tôi nhằm tối thiểu hóa các thay đổi trong độ tương tự nguyên mẫu. Nó lấy một nguyên mẫu pt−1 của các nhiệm vụ trước đó và một hình ảnh từ nhiệm vụ t, chọn vùng hình ảnh có độ tương tự cao nhất với nguyên mẫu này (mặt nạ nhị phân S), và phạt mô hình vì bất kỳ thay đổi nào trong vùng này gây ra bởi việc đào tạo nhiệm vụ t.

sim(pi, zj) = log|zj−pi|2+1
|zj−pi|2+η và η≪1. Để thu được các dự đoán cuối cùng, chúng tôi đẩy những giá trị đó qua lớp kết nối đầy đủ (và được khởi tạo phù hợp) h.

Đào tạo. Đào tạo được chia thành ba giai đoạn tối ưu hóa: khởi động, học kết hợp, và tối ưu hóa lồi của lớp cuối cùng. Giai đoạn đầu tiên đào tạo bổ sung fA và lớp phần nguyên mẫu g. Giai đoạn thứ hai học fA, g, và mạng backbone f. Giai đoạn cuối cùng tinh chỉnh lớp kết nối đầy đủ h. Đào tạo được tiến hành với mất mát cross-entropy được hỗ trợ bởi hai chính quy hóa, chi phí cụm và tách biệt [16]. Cụm khuyến khích mỗi hình ảnh đào tạo có một miếng ẩn gần với ít nhất một nguyên mẫu của lớp của nó. Ngược lại, chi phí tách biệt khuyến khích mọi miếng ẩn của một hình ảnh đào tạo tránh xa các nguyên mẫu của các lớp còn lại.

3.2. ICICLE

Các sửa đổi quan trọng về kiến trúc và đào tạo là cần thiết để sử dụng phương pháp luận các phần nguyên mẫu cho học tăng dần từng lớp (suy luận là giống hệt). Chủ yếu vì học tăng dần có các giả định khá khác biệt. Nó giả định T nhiệm vụ (C1, X1),(C2, X2), . . . , (CT, XT), trong đó mỗi nhiệm vụ t chứa các lớp Ct và tập đào tạo Xt. Hơn nữa, trong nhiệm vụ t, chỉ có dữ liệu đào tạo Xt có sẵn, vì chúng tôi xem xét thiết lập không có mẫu, nơi bị cấm lưu bất kỳ dữ liệu nào từ các nhiệm vụ trước đó (không cho phép bộ đệm phát lại).

Kiến trúc. Như trong mô hình cơ sở, ICICLE bao gồm backbone f và bổ sung fA. Tuy nhiên, nó không sử dụng một lớp phần nguyên mẫu g cố định và một lớp kết nối đầy đủ h. Thay vào đó, nó giới thiệu một lớp phần nguyên mẫu gt và một lớp kết nối đầy đủ ht cho mỗi nhiệm vụ liên tiếp. Các lớp gt bao gồm Mt phần nguyên mẫu, trong đó Mt= K·Ct và K là số lượng nguyên mẫu trên mỗi lớp. Mặt khác, lớp ht có trọng số ht
ci= 1 nếu nguyên mẫu pi được gán cho lớp c và nó được đặt thành 0 nếu ngược lại. Chúng tôi loại bỏ các trọng số âm (−0.5) từ lớp cuối cùng vì

Không gian ẩn 
sau nhiệm vụ t-1 
nguyên mẫu từ nhiệm vụ t-1 
vị trí ban đầu cho 
nguyên mẫu nhiệm vụ t 
biểu diễn của dữ liệu nhiệm vụ t Khởi tạo ngẫu nhiên 
Khởi tạo gần gũi 
cụm biểu diễn 

Hình 4: Chúng tôi giới thiệu khởi tạo nguyên mẫu dựa trên sự gần gũi mới. Nó bắt đầu bằng cách truyền các mẫu đào tạo của nhiệm vụ t qua mạng (các chấm xanh lá cây) và chọn các biểu diễn gần nhất với các nguyên mẫu hiện có (các kim cương tím). Điều này dẫn đến nhiều điểm, mà chúng tôi phân cụm (các vòng tròn tím) để thu được các vị trí ban đầu của các phần nguyên mẫu nhiệm vụ t (các kim cương vàng). Khởi tạo như vậy (dưới bên phải) được ưa thích hơn khởi tạo ngẫu nhiên (trên bên phải), nơi các nguyên mẫu mới có thể được tạo ra xa các nguyên mẫu cũ, mặc dù chúng chỉ khác biệt nhẹ.

đào tạo nhiều giai đoạn không có lợi cho tình huống tăng dần từng lớp (xem Hình 6).

Đào tạo. Để ngăn chặn quên lãng thảm khốc, ICICLE sửa đổi hàm mất mát của giải pháp cơ sở. Ngoài ra, nó giới thiệu ba cơ chế: chính quy hóa khả năng diễn giải, khởi tạo nguyên mẫu dựa trên sự gần gũi, và bù trừ thiên lệch gần đây của nhiệm vụ. Về hàm mất mát cơ sở, cross-entropy được tính toán trên đầu ra đầy đủ của mô hình, bao gồm logits từ các lớp được học trong các nhiệm vụ trước đó. Tuy nhiên, chi phí cụm và tách biệt chỉ được tính toán trong đầu gt.

Chính quy hóa khả năng diễn giải. Chưng cất kiến thức [35] là một trong những phương pháp chính quy hóa mạnh mẽ được áp dụng để ngăn chặn quên lãng [48]. Tuy nhiên, kết quả thu được bằng việc áp dụng trực tiếp nó không thỏa đáng và dẫn đến hiện tượng trôi dạt diễn giải đáng kể (xem Hình 1 và Phần 5). Do đó, chúng tôi giới thiệu một chi phí chính quy hóa bổ sung LIR (xem Hình 3), được lấy cảm hứng từ [39], tối thiểu hóa các thay đổi trong độ tương tự cho các phần nguyên mẫu của các nhiệm vụ trước đó. Nó được định nghĩa là:

LIR=HX
i=0WX
j=0|sim(pt−1, zt
i,j)−sim(pt, zt
i,j)|·Si,j(1)

trong đó sim(pt−1, zt
i,j) được tính toán cho mô hình được lưu trước khi đào tạo nhiệm vụ t, và S là một mặt nạ nhị phân có kích thước H×W, chỉ ra các pixel biểu diễn có độ tương tự cao nhất (γ phân vị của những pixel đó). Chưng cất độ tương tự như vậy

--- TRANG 5 ---
tạo ra tính dẻo cao hơn khi học một nhiệm vụ mới nhưng, đồng thời, giảm hiện tượng trôi dạt khả năng diễn giải.

Khởi tạo nguyên mẫu dựa trên sự gần gũi. Khởi tạo ngẫu nhiên các nguyên mẫu, được đề xuất trong [16], thất bại trong học tăng dần (xem Bảng 5). Rất có thể vì các nguyên mẫu mới có thể được tạo ra xa các nguyên mẫu cũ, mà chúng chỉ khác biệt nhẹ (ví dụ: nguyên mẫu cánh của các loài chim khác nhau). Do đó, chúng tôi giới thiệu khởi tạo đặt các nguyên mẫu mới gần với các nguyên mẫu cũ (xem Hình 4). Chúng tôi bắt đầu bằng cách truyền các mẫu đào tạo của nhiệm vụ t qua mạng và xác định miếng nào tương tự nhất với các nguyên mẫu hiện có (chúng tôi chọn miếng từ α phân vị). Cụ thể hơn, chúng tôi tính toán tập {zt
j: max isim(pt−1
i, zt
j)∈α phân vị}. Điều này dẫn đến nhiều ứng viên cho các phần nguyên mẫu nhiệm vụ mới. Để thu được K·Ct nguyên mẫu, chúng tôi thực hiện phân cụm KMeans++, và các trung tâm kết quả của các cụm được sử dụng để khởi tạo các phần nguyên mẫu trong gt.

Bù trừ thiên lệch gần đây của nhiệm vụ. Khi mô hình học nhiệm vụ t, độ tương tự với các nguyên mẫu của các nhiệm vụ trước đó giảm, chủ yếu do các thay đổi trong backbone (xem Hình 5). Đó là lý do tại sao, sau khi đào tạo nhiệm vụ cuối cùng, chúng tôi bù đắp cho điều này bằng cách sử dụng T−1 hằng số thu được bằng dữ liệu nhiệm vụ cuối cùng. Chính xác hơn, đối với mỗi nhiệm vụ trước đó t < T, chúng tôi lấy logits yt=ht◦gt◦f(x) thu được cho tất cả x∈XT và tính toán thiên lệch ct sao cho |{x∈XT: max (yt+ct)>maxyT}|=u|XT|. Trực quan, chúng tôi điều chỉnh ct để mô hình thay đổi u% dự đoán của nó từ nhiệm vụ T sang nhiệm vụ t. Chúng tôi xác định thực nghiệm rằng u= 10% là tối ưu.

3.3. Hiện tượng Trôi dạt Khái niệm Diễn giải

Như đã lưu ý trong chú thích của Hình 1, hiện tượng trôi dạt khái niệm diễn giải xảy ra khi một bản đồ độ tương tự khác biệt giữa các nhiệm vụ. Do đó, nó có thể được định nghĩa chính thức là:

ICD =EH,W
i,j=1sim(pt−1, zt
i,j)−sim(pt, zt
i,j),(2)

trong đó (zi,j)H,W
i,j=1 tương ứng với biểu diễn hình ảnh đầu vào, pt−1 và pt tương ứng với phần nguyên mẫu p trước và sau nhiệm vụ t, và sim là độ tương tự được định nghĩa trong Phần 3.1 của bài báo. Do đó, ICD càng lớn, hiện tượng trôi dạt khái niệm diễn giải càng lớn.

4. Thiết lập Thực nghiệm

Chúng tôi đánh giá phương pháp của chúng tôi trên các tập dữ liệu CUB-200-2011 [84] và Stanford Cars [46] để phân loại 200 loài chim và 196 mẫu xe hơi, tương ứng. Chúng tôi xem xét các tình huống học 4, 10, và 20 nhiệm vụ cho chim và 4, 7, và 14 tùy chọn cho xe hơi. Là backbone f, chúng tôi lấy ResNet-34 [34] không có lớp cuối cùng và được tiền đào tạo trên ImageNet [20]. Chúng tôi đặt số lượng nguyên mẫu trên mỗi lớp là 10. Hơn nữa, chúng tôi sử dụng các phần nguyên mẫu có kích thước 1×1×256 và 1×1×128 cho chim và xe hơi, tương ứng. Trọng số của CE, cụm, tách biệt, và chi phí chưng cất trong hàm mất mát bằng 1.0, 0.8, −0.08, và 0.01. Trong chưng cất, chúng tôi lấy λ= 1/49 pixel biểu diễn có độ tương tự cao nhất. Đối với khởi tạo dựa trên sự gần gũi, chúng tôi sử dụng α= 0.5. Đối với bù trừ thiên lệch gần đây của nhiệm vụ, chúng tôi lấy ct, thay đổi các dự đoán của tập kiểm tra cuối cùng ít hơn 10%. Là khung triển khai, chúng tôi sử dụng FACIL [54] dựa trên thư viện PyTorch1. Chi tiết về thiết lập thực nghiệm được cung cấp trong Tài liệu Bổ sung2.

5. Kết quả

Hiệu suất. Chúng tôi đánh giá hiệu quả của ICICLE bằng cách so sánh nó với các phương pháp cơ sở không dựa trên mẫu thường được sử dụng trong học tăng dần từng lớp, bao gồm LWF [48], LWM [21], và EWC[44]3. Ngoài ra, Fine-tuning, và Freezing của bộ trích xuất đặc trưng (không được đào tạo gì cả) được cung cấp. Chúng tôi cũng báo cáo học đa nhiệm vụ như một giới hạn trên nơi các nhiệm vụ khác nhau được học cùng nhau theo cách đa nhiệm vụ. Để làm như vậy, chúng tôi phân tích độ chính xác nhận biết nhiệm vụ và không phụ thuộc nhiệm vụ cho mỗi nhiệm vụ sau nhiệm vụ cuối cùng (Bảng 3) và các độ chính xác trung bình tăng dần tổng hợp sau khi học nhiệm vụ cuối cùng trong các tình huống liên quan đến 4, 10, và 20 nhiệm vụ cho CUB (Bảng 2) và 4, 7, và 14 nhiệm vụ cho Stanford Cars (Tài liệu Bổ sung). Tất cả các phương pháp sử dụng cùng kiến trúc mạng trích xuất đặc trưng và ProtoPNet cho học dựa trên phần nguyên mẫu. Phương pháp của chúng tôi vượt trội hơn các phương pháp cơ sở trong tất cả các trường hợp, cho thấy hiệu suất vượt trội của nó cho học dựa trên phần nguyên mẫu theo cách tăng dần. ICICLE giữ lại kiến thức từ các nhiệm vụ trước đó tốt hơn, dẫn đến độ chính xác cân bằng hơn giữa các nhiệm vụ và độ chính xác cao hơn cho nhiệm vụ đầu tiên so với tất cả các phương pháp khác. Tuy nhiên, mặc dù có cải thiện đáng kể, phương pháp của chúng tôi vẫn còn chỗ để cải thiện so với giới hạn trên của đào tạo đa nhiệm vụ. Với số lượng nhiệm vụ lớn hơn, việc quên lãng của mô hình là

1https://pytorch.org
2Mã có sẵn tại: https://github.com/gmum/ICICLE
3Việc mở rộng các mô hình có thể diễn giải với các phương pháp không dựa trên mẫu phức tạp hơn là không đơn giản, và do đó chúng tôi loại trừ các phương pháp như SDC [91] (yêu cầu học với mất mát metric) và PASS [95] (yêu cầu kết hợp với học tự giám sát).

--- TRANG 6 ---
ĐỘ CHÍNH XÁC TRUNG BÌNH TĂNG DẦN NHẬN BIẾT NHIỆM VỤ ĐỘ CHÍNH XÁC TRUNG BÌNH TĂNG DẦN KHÔNG PHỤ THUỘC NHIỆM VỤ
PHƯƠNG PHÁP 4NHIỆM VỤ 10NHIỆM VỤ 20NHIỆM VỤ 4NHIỆM VỤ 10NHIỆM VỤ 20NHIỆM VỤ
FREEZING 0.560±0.027 0.531±0.042 0.452±0.055 0.309±0.024 0.115±0.028 0.078±0.004
FINETUNING 0.229±0.005 0.129±0.017 0.147±0.021 0.177±0.006 0.072±0.008 0.044±0.006
EWC 0.445±0.012 0.288±0.034 0.188±0.031 0.213±0.008 0.095±0.007 0.046±0.011
LWM 0.452±0.023 0.294±0.032 0.226±0.025 0.180±0.028 0.090±0.011 0.044±0.008
LWF 0.301±0.048 0.175±0.028 0.129±0.023 0.219±0.019 0.078±0.008 0.072±0.008
ICICLE 0.654±0.011 0.602±0.035 0.497±0.099 0.350±0.053 0.185±0.005 0.099±0.003
Multi-task 0.858±0.005 0.905±0.012 0.935±0.019 0.499±0.009 0.196±0.017 0.148±0.009
FeTrIL [65] 0.750±0.008 0.607±0.018 0.407±0.051 0.375±0.006 0.199±0.003 0.127±0.011
PASS [95] 0.775±0.006 0.647±0.003 0.518±0.012 0.395±0.001 0.233±0.009 0.139±0.017

Bảng 2: So sánh độ chính xác trung bình tăng dần cho số lượng nhiệm vụ khác nhau trên CUB-200-2011, chứng minh tác động tiêu cực của số lượng nhiệm vụ cao cần học đến hiệu suất của mô hình. Mặc dù xu hướng này, ICICLE vượt trội hơn các phương pháp cơ sở trên tất cả số lượng nhiệm vụ. Ngoài ra, chúng tôi hiển thị khoảng cách giữa các mô hình có thể diễn giải và hộp đen bằng cách so sánh ICICLE với FeTrIL và PASS.

ĐỘ CHÍNH XÁC NHẬN BIẾT NHIỆM VỤ ĐỘ CHÍNH XÁC KHÔNG PHỤ THUỘC NHIỆM VỤ
PHƯƠNG PHÁP NHIỆM VỤ 1 NHIỆM VỤ 2 NHIỆM VỤ 3 NHIỆM VỤ 4 NHIỆM VỤ 1 NHIỆM VỤ 2 NHIỆM VỤ 3 NHIỆM VỤ 4
FREEZING 0.806±0.024 0.462±0.037 0.517±0.041 0.455±0.027 0.570±0.031 0.195±0.017 0.258±0.019 0.213±0.020
FINETUNING 0.007±0.004 0.016±0.008 0.032±0.009 0.759±0.019 0.0±0.0 0.0±0.0 0.0±0.0 0.759±0.019
EWC 0.244±0.024 0.378±0.072 0.539±0.043 0.602±0.054 0.001±0.001 0.059±0.004 0.267±0.031 0.527±0.051
LWF 0.169±0.046 0.119±0.008 0.235±0.017 0.743±0.061 0.158±0.035 0.003±0.002 0.018±0.003 0.537±0.142
LWM 0.195±0.012 0.412±0.014 0.430±0.028 0.772±0.011 0.027±0.024 0.023±0.020 0.085±0.005 0.772±0.037
ICICLE 0.523±0.020 0.663±0.053 0.709±0.038 0.723±0.002 0.233±0.014 0.365±0.021 0.314±0.011 0.486±0.021

Bảng 3: So sánh độ chính xác nhiệm vụ cho kiến trúc ProtoPNet đã sửa đổi trong tình huống học tăng dần từng lớp sau 4 nhiệm vụ đào tạo trên tập dữ liệu CUB-200-2011, được tính trung bình trên 3 lần chạy với sai số chuẩn của trung bình. ICICLE của chúng tôi vượt trội hơn các phương pháp cơ sở và đạt kết quả tốt nhất cho tất cả các nhiệm vụ tăng dần trước đó, chứng minh khả năng duy trì kiến thức trước đó trong khi học các nhiệm vụ mới. Freezing do việc cố định trọng số không thể học đúng cách các nhiệm vụ mới.

cao hơn, dẫn đến kết quả kém hơn, có thể do số lượng chi tiết mà các nguyên mẫu cần nắm bắt để phân loại một nhiệm vụ một cách chính xác. Hơn nữa, chúng tôi đã nhận thấy rằng freezing là một cơ sở mạnh mẽ cho tình huống nhận biết nhiệm vụ vì bản chất cố định của mô hình và backbone được tiền đào tạo.

Khả năng diễn giải Để đánh giá xem biểu diễn đồ họa của khái niệm nguyên mẫu đã thay đổi như thế nào và bao nhiêu, chúng tôi sử dụng metric IoU [75]. IoU đo lường sự chồng chéo của biểu diễn trực quan nguyên mẫu (như trong Hình 1) từ nhiệm vụ mà nó được học, qua tất cả các nhiệm vụ tiếp theo. Freezing vượt trội trong việc bảo tồn thông tin nguyên mẫu vì tất cả trọng số từ các nhiệm vụ trước đó được cố định. Về các phương pháp cho phép thay đổi trong backbone và các nguyên mẫu đã học trước đó, ICICLE vượt trội hơn tất cả các cơ sở, như được hiển thị trong Bảng 1. ICICLE giữ các nguyên mẫu có thể diễn giải nhất quán với chính quy hóa khả năng diễn giải chưng cất các khái niệm đã học.

5.1. Nghiên cứu triệt để và phân tích

Tại sao cần thay đổi trong kiến trúc và đào tạo ProtoPNet? ProtoPNet trong giai đoạn đào tạo cuối cùng (tối ưu hóa lồi lớp cuối cùng) nhằm tinh chỉnh các kết nối tích cực và chính quy hóa các kết nối tiêu cực thành 0. Do đó, mô hình hội tụ trả về các diễn giải dưới dạng lý luận tích cực, được mong muốn bởi người dùng cuối [11]. Trong thiết lập CL, bước cuối cùng của đào tạo thay đổi các kết nối tiêu cực theo cách khác (xem Hình 6). Mặt khác,

Chính quy hóa Khởi tạo Bù trừ ĐC TAw ĐC TAg
0.216 0.182
✓ 0.559 0.280
✓ ✓ 0.654 0.335
✓ ✓ ✓ 0.654 0.350

Bảng 4: Ảnh hưởng của các thành phần mới khác nhau đến độ chính xác trung bình tăng dần trong tình huống học bốn nhiệm vụ. Kết hợp tất cả các thành phần dẫn đến mô hình hoạt động tốt nhất.

Giá trị trọng số trung bình 
chỉ số lớp chỉ số lớp kết nối tiêu cực kết nối tích cực 

Hình 6: Trọng số trung bình của kết nối tích cực và tiêu cực trên mỗi lớp trong tình huống học 4 nhiệm vụ. Các kết nối tiêu cực mạnh và không cân bằng giữa các nhiệm vụ dẫn đến các thuộc tính không mong muốn về khả năng diễn giải của mô hình.

trong tình huống học tăng dần không dựa trên mẫu, việc tiến hành giai đoạn học lớp cuối cùng là không khả thi ở cuối đào tạo. Đó là lý do tại sao, chúng tôi đã sửa đổi lớp cuối cùng của ProtoPNet và chỉ giữ lại các kết nối tích cực được khởi tạo thành 1, loại bỏ nhu cầu về bước tối ưu hóa lồi.

--- TRANG 7 ---
chính quy hóa độ tương tự chính quy hóa khoảng cách chính quy hóa đặc trưng 
không gian mà hàm mất mát 
có cùng giá trị phần nguyên mẫu 
biểu diễn phần hình ảnh 
hàm độ tương tự ProtoPNet giá trị độ tương tự 
giá trị khoảng cách 

Hình 7: Trực quan hóa ba phương pháp có thể có để chính quy hóa độ tương tự diễn giải và ảnh hưởng của chúng đến tính dẻo của mô hình. Chỉ chính quy hóa dựa trên độ tương tự tính đến cách một phần hình ảnh nhất định tương ứng với một phần nguyên mẫu. Nếu nó gần thì giá trị độ tương tự cao và những thay đổi nhỏ trong khoảng cách dẫn đến giảm lớn trong độ tương tự. Trong khi các vectơ ẩn xa các phần nguyên mẫu có thể được mô hình thay đổi tự do hơn để đại diện tốt hơn dữ liệu nhiệm vụ hiện tại. Các phương pháp khác hạn chế tính dẻo của mô hình, xem mỗi biểu diễn ẩn của phần hình ảnh là quan trọng như nhau.

Ảnh hưởng của từng thành phần được giới thiệu là gì? Bảng 4 trình bày ảnh hưởng của các thành phần khác nhau trong phương pháp của chúng tôi đến độ chính xác trung bình tăng dần cuối cùng của mô hình trong tập dữ liệu CUB-200-2011 với tình huống chia bốn nhiệm vụ. Kết hợp tất cả các thành phần dẫn đến mô hình hoạt động tốt nhất. Kết quả của chúng tôi cho thấy rằng bù trừ thiên lệch gần đây của nhiệm vụ giúp trong đánh giá không phụ thuộc nhiệm vụ và mang lại cải thiện bổ sung 4.5%. Tuy nhiên, hầu hết các cải thiện độ chính xác được quy cho chính quy hóa khả năng diễn giải và khởi tạo gần gũi. Đáng chú ý, bù trừ thiên lệch gần đây của nhiệm vụ cải thiện đáng kể hiệu suất của các lớp nhiệm vụ một so với phương pháp không có nó, từ 0.028 đến 0.255 trong tình huống không phụ thuộc nhiệm vụ, như được chi tiết trong Tài liệu Bổ sung.

Chúng ta nên thực hiện chính quy hóa khả năng diễn giải ở đâu? Lớp nguyên mẫu của mô hình ProtoPNet có thể được chính quy hóa theo ba cách khác nhau: chính quy hóa đặc trưng trên biểu diễn lớp bổ sung, chính quy hóa khoảng cách giữa các phần nguyên mẫu và vectơ dữ liệu ẩn, và chính quy hóa dựa trên độ tương tự. Phương pháp nghiêm ngặt nhất là chính quy hóa đặc trưng, không cho phép mô hình thay đổi cách nó biểu diễn dữ liệu từ một nhiệm vụ mới, dẫn đến tính dẻo của mô hình giảm đáng kể. Khi khoảng cách được chính quy hóa, mô hình có thể thay đổi biểu diễn của nó để duy trì cùng khoảng cách từ nguyên mẫu trên bề mặt của hình cầu. Mặt khác, chính quy hóa dựa trên độ tương tự cho phép mô hình giữ lại kiến thức chính từ các nhiệm vụ trước đó bằng cách chỉ bảo tồn thông tin liên quan đến các đặc trưng cụ thể gần với các phần nguyên mẫu trong không gian ẩn, cho phép linh hoạt hơn để đổi lấy việc quên các đặc trưng không liên quan. Do đó, chúng tôi tuân theo chính quy hóa khả năng diễn giải trong ICICLE, dựa trên độ tương tự và duy trì kiến thức thiết yếu từ các nhiệm vụ trước đó trong khi giữ lại tính dẻo cao để học những cái mới. Hình 7 minh họa ba phương pháp này và so sánh chúng về độ chính xác trung bình tăng dần cho ProtoPNet chỉ với chính quy hóa (không thay đổi khởi tạo): 0.507, 0.535, và 0.559 trong nhận biết nhiệm vụ và 0.261, 0.230, và 0.280 trong các tình huống không phụ thuộc nhiệm vụ cho chính quy hóa đặc trưng, khoảng cách, và dựa trên độ tương tự, tương ứng, trên tập dữ liệu CUB-200-2011 với tình huống bốn nhiệm vụ.

Ảnh hưởng của các siêu tham số trong chính quy hóa khả năng diễn giải là gì? Trong Hình 8 và Hình 9, ảnh hưởng của λ và ngưỡng phân vị mặt nạ trong chính quy hóa khả năng diễn giải đến độ chính xác trung bình tăng dần được trình bày. Chúng tôi sử dụng tập dữ liệu CUB-200-2011 với thiết lập chia bốn nhiệm vụ. Đối với tập dữ liệu này, kết quả cho thấy rằng chính quy hóa chỉ độ tương tự nguyên mẫu tối đa là hiệu quả nhất (Hình 9). Về λIR, một giá trị quá nhỏ dẫn đến tính dẻo mạng cao, quên lãng tăng, và kết quả kém, trong khi một giá trị quá lớn giảm tính dẻo của mô hình và có thể không đại diện tốt kiến thức mới.

Cách nào là tốt nhất để khởi tạo các phần nguyên mẫu mới? Trong phần triệt để này, chúng tôi điều tra chiến lược tối ưu để khởi tạo các phần nguyên mẫu khi bắt đầu một nhiệm vụ mới trong mô hình ProtoPNet. Chúng tôi đánh giá phương pháp khởi tạo của chúng tôi, khởi tạo các phần gần với các nguyên mẫu hiện có, so với ba phương pháp khác: khởi tạo ngẫu nhiên, phân cụm tất cả biểu diễn phần hình ảnh, và phân cụm chỉ các vectơ ẩn xa. Kết quả được trình bày trong Bảng 5. Phương pháp khởi tạo gần gũi vượt trội hơn chiến lược xa, vì chiến lược sau có xu hướng gán các phần nguyên mẫu cho các vectơ ẩn tương ứng với nền của hình ảnh, dẫn đến việc học các khái niệm không liên quan có thể dễ dàng kích hoạt trên dữ liệu nhiệm vụ khác, như được hiển thị trong Tài liệu Bổ sung.

ICICLE có khái quát hóa sang các kiến trúc khác không?
Cuối cùng, chúng tôi cho thấy rằng ICICLE khái quát hóa sang kiến trúc dựa trên khái niệm khác. Chúng tôi chứng minh rằng sử dụng mô hình TesNet [85], và cung cấp kết quả trong Bảng 6, nơi ICICLE thu được kết quả tốt nhất. Độ chính xác trung bình tăng dần của ICICLE với TesNet thậm chí còn tốt hơn ProtoPNet cho cả đánh giá nhận biết nhiệm vụ và không phụ thuộc nhiệm vụ.

Loại khởi tạo Ngẫu nhiên Xa Tất cả Gần gũi
Độ chính xác nhận biết nhiệm vụ 0.559 0.592 0.626 0.654
Độ chính xác không phụ thuộc nhiệm vụ 0.280 0.290 0.297 0.335

Bảng 5: So sánh các chiến lược khởi tạo khác nhau cho các phần nguyên mẫu. Khởi tạo gần gũi của chúng tôi cho các nguyên mẫu nhiệm vụ mới là vượt trội.

--- TRANG 8 ---
Freezing Finetuning EWC LWM LWF ICICLE
ĐC TAw 0.637 0.355 0.592 0.648 0.581 0.746
ĐC TAg 0.222 0.183 0.272 0.252 0.205 0.362

Bảng 6: Kết quả cho tình huống học bốn nhiệm vụ trên tập dữ liệu CUB-200-2011 với TesNet [85] như một kiến trúc dựa trên khái niệm. Bảng cho thấy tính linh hoạt của phương pháp ICICLE cho các mô hình có thể diễn giải.

Hình 8: Ảnh hưởng của λIR trong chính quy hóa khả năng diễn giải.

Hình 9: Ảnh hưởng của γ trong chính quy hóa khả năng diễn giải. Lưu ý rằng chính quy hóa chỉ ở vị trí có độ tương tự tối đa là có lợi nhất cho ICICLE trong tình huống học bốn nhiệm vụ trong CUB-200-2011.

6. Kết luận và công việc tương lai

Công trình này đề xuất một phương pháp mới gọi là ICICLE cho học tăng dần từng lớp có thể diễn giải. ICICLE dựa trên các phần nguyên mẫu và kết hợp chính quy hóa khả năng diễn giải, khởi tạo gần gũi, và bù trừ thiên lệch gần đây của nhiệm vụ. Phương pháp đề xuất vượt trội hơn các phương pháp học tăng dần từng lớp cổ điển được áp dụng cho các mạng dựa trên phần nguyên mẫu về độ chính xác nhận biết nhiệm vụ và không phụ thuộc nhiệm vụ trong khi duy trì khả năng diễn giải nguyên mẫu. Chúng tôi cũng tiến hành các nghiên cứu triệt để và nhiều phân tích để biện minh cho các lựa chọn của chúng tôi và làm nổi bật những thách thức liên quan đến việc kết hợp các khái niệm có thể diễn giải với CL. Công trình này được kỳ vọng sẽ truyền cảm hứng cho nghiên cứu về XAI và CL. Tiến về phía trước, chúng tôi dự định khám phá các phương pháp phù hợp cho học tăng dần một lớp với các mô hình có thể diễn giải. Chúng tôi cũng dự định điều tra cách các kiến trúc có thể diễn giải khác, chẳng hạn như B-COS [8], có thể được thích ứng với tình huống học tăng dần từng lớp.

Hạn chế. Công trình của chúng tôi chỉ giới hạn ở các phương pháp phần nguyên mẫu, phù hợp cho nhận dạng hình ảnh chi tiết và kế thừa những nhược điểm của chúng đã được thảo luận trước đó trong [27, 36, 42, 60, 73]. Tuy nhiên, gần đây có những công trình đầu tiên khái quát hóa chúng sang các tập dữ liệu tiêu chuẩn (không chi tiết) [61]. Ngoài ra, vì chúng tôi chỉ xem xét tình huống không dựa trên mẫu và nhận dạng tập đóng, chúng tôi không phân tích cách có bộ đệm phát lại sẽ ảnh hưởng đến hiệu suất của phương pháp và cách phương pháp này sẽ phù hợp trong thiết lập tập mở.

Tác động. ICICLE làm nổi bật rằng các phương pháp không dựa trên mẫu truyền thống cho học tăng dần không phù hợp với các mô hình hộp xám sử dụng khái niệm để dự đoán. Phát hiện này có ý nghĩa đối với việc phát triển các phương pháp học tăng dần, vì chúng phải cân bằng nhu cầu về tính tổng quát với nhu cầu được thích ứng cho các kiến trúc cụ thể. Hơn nữa, nó có tác động đến lĩnh vực các mô hình dựa trên khái niệm và AI có thể giải thích, chứng minh nhu cầu nghiên cứu thêm về các phương pháp CL cho XAI. Trong một số trường hợp, các nhà thực hành biết rằng hệ thống của họ sẽ cần học các nhiệm vụ mới liên tục có thể chọn sử dụng các mô hình hộp đen và bộ giải thích thay vì các mô hình có thể diễn giải, hy sinh độ trung thực của giải thích để cải thiện hiệu suất mô hình.

Lời cảm ơn

Joost van de Weijer và Bartłomiej Twardowski thừa nhận sự hỗ trợ từ tài trợ của Chính phủ Tây Ban Nha cho các dự án PID2019-104174GB-I00, TED2021-132513B-I00, và tài trợ RYC2021-032765-I, Ủy ban Châu Âu dưới Chương trình Horizon 2020, được tài trợ bởi MCIN/AEI/10.13039/501100011033 và bởi European Union NextGenerationEU/PRTR. Công việc của Dawid Rymarczyk được hỗ trợ bởi Trung tâm Khoa học Quốc gia (Ba Lan), tài trợ số 2022/45/N/ST6/04147. Anh cũng nhận được học bổng khuyến khích từ chương trình Excellence Initiative - Research University funds tại Đại học Jagiellonian ở Krak ´ow. Công việc của Bartosz Zieli ´nski được tài trợ bởi Trung tâm Khoa học Quốc gia (Ba Lan) tài trợ số 2022/47/B/ST6/03397 và dự án nghiên cứu "Bio-inspired artificial neural network" (tài trợ số POIR.04.04.00-00-14DE/18-00) trong chương trình Team-Net của Quỹ Khoa học Ba Lan được đồng tài trợ bởi Liên minh Châu Âu dưới Quỹ Phát triển Khu vực Châu Âu. Cuối cùng, một số thí nghiệm được thực hiện trên các máy chủ được mua bằng tiền từ tài trợ Priority Research Area (Artificial Intelligence Computing Center Core Facility) dưới Chương trình Chiến lược Excellence Initiative tại Đại học Jagiellonian.

Tài liệu tham khảo

[1] Ehsan Abbasnejad, Damien Teney, Amin Parvaneh, Javen Shi, và Anton van den Hengel. Counterfactual vision and language learning. Trong Proceedings of the IEEE/CVF Con-

--- TRANG 9 ---
ference on Computer Vision and Pattern Recognition , trang 10044–10054, 2020. 2
[2] Michael Anis Mihdi Afnan, Yanhe Liu, Vincent Conitzer, Cynthia Rudin, Abhishek Mishra, Julian Savulescu, và Ma-soud Afnan. Interpretable, not black-box, artificial intelli-gence should be used for embryo selection. Human Repro-duction Open , 2021. 3
[3] Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, và Tinne Tuytelaars. Memory aware synapses: Learning what (not) to forget. Trong European Con-ference on Computer Vision , 2018. 2
[4] David Alvarez Melis và Tommi Jaakkola. Towards robust interpretability with self-explaining neural networks. Trong S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, và R. Garnett, biên tập, Advances in Neural Infor-mation Processing Systems , tập 31. Curran Associates, Inc., 2018. 2
[5] Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha, và Jonghyun Choi. Rainbow memory: Continual learn-ing with a memory of diverse samples. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 8218–8227, 2021. 2
[6] Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, Joseph Y Lo, và Cynthia Rudin. A case-based interpretable deep learning model for classification of mass lesions in digital mammography. Na-ture Machine Intelligence , 3(12):1061–1070, 2021. 3
[7] Dominika Basaj, Witold Oleszkiewicz, Igor Sieradzki, Michał G ´orszczak, B Rychalska, T Trzcinski, và B Zielin-ski. Explaining self-supervised image representations with visual probing. Trong International Joint Conference on Artifi-cial Intelligence , 2021. 2
[8] Moritz B ¨ohle, Mario Fritz, và Bernt Schiele. B-cos net-works: alignment is all we need for interpretability. Trong Pro-ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 10329–10338, 2022. 8
[9] Wieland Brendel và Matthias Bethge. Approximating CNNs with bag-of-local-features models works surprisingly well on imagenet. Trong International Conference on Learning Representations , 2019. 2
[10] Lukas Brunke, Melissa Greeff, Adam W Hall, Zhaocong Yuan, Siqi Zhou, Jacopo Panerati, và Angela P Schoel-lig. Safe learning in robotics: From learning-based control to safe reinforcement learning. Annual Review of Control, Robotics, and Autonomous Systems , 5:411–444, 2022. 1
[11] Rudin C. et al. Interpretable machine learning: Fundamental principles and 10 grand challenges. Statistics Surveys , 16:1–85, 2022. 1, 6
[12] Rudin C. và Radin J. Why are we using black box models in ai when we don't need to? a lesson from an explainable ai competition. Harvard Data Science Review , 1(2):10–1162, 2019. 1
[13] Arslan Chaudhry, Puneet K Dokania, Thalaiyasingam Ajan-than, và Philip HS Torr. Riemannian walk for incremental learning: understanding forgetting and intransigence. Trong Eu-ropean Conference on Computer Vision , 2018. 2

[14] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. Efficient lifelong learning with a-gem. Trong International Conference on Learning Representa-tions , 2019. 2
[15] Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K Dokania, Philip HS Torr, và Marc'Aurelio Ranzato. On tiny episodic memo-ries in continual learning. arXiv preprint arXiv:1902.10486 , 2019. 2
[16] Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, và Jonathan K Su. This looks like that: deep learn-ing for interpretable image recognition. Advances in Neural Information Processing Systems , 32, 2019. 2, 3, 4, 5
[17] Xuxin Chen, Ximin Wang, Ke Zhang, Kar-Ming Fung, Theresa C Thai, Kathleen Moore, Robert S Mannel, Hong Liu, Bin Zheng, và Yuchen Qiu. Recent advances and clin-ical applications of deep learning in medical image analysis. Medical Image Analysis , trang 102444, 2022. 1
[18] Zhi Chen, Yijie Bei, và Cynthia Rudin. Concept whitening for interpretable image recognition. Nature Machine Intelli-gence , 2(12):772–782, 2020. 2
[19] Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Greg Slabaugh, và Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE Transactions on Pattern Analy-sis and Machine Intelligence , 2021. 1, 2
[20] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. Imagenet: A large-scale hierarchical image database. Trong 2009 IEEE conference on computer vision and pattern recognition , trang 248–255. Ieee, 2009. 5
[21] Prithviraj Dhar, Rajat Vikram Singh, Kuan-Chuan Peng, Ziyan Wu, và Rama Chellappa. Learning without memoriz-ing. Trong Conference on Computer Vision and Pattern Recog-nition , 2019. 2, 5
[22] Jon Donnelly, Alina Jade Barnett, và Chaofan Chen. De-formable protopnet: An interpretable image classifier using deformable prototypes. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 10265–10275, 2022. 3
[23] Arthur Douillard, Matthieu Cord, Charles Ollion, Thomas Robert, và Eduardo Valle. Podnet: Pooled outputs dis-tillation for small-tasks incremental learning. Trong Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XX 16 , trang 86–102. Springer, 2020. 2
[24] Ruth Fong, Mandela Patrick, và Andrea Vedaldi. Un-derstanding deep networks via extremal perturbations and smooth masks. Trong Proceedings of the IEEE/CVF Interna-tional Conference on Computer Vision , trang 2950–2958, 2019. 2
[25] Ruth C Fong và Andrea Vedaldi. Interpretable explana-tions of black boxes by meaningful perturbation. Trong Pro-ceedings of the IEEE international conference on computer vision , trang 3429–3437, 2017. 2
[26] Robert M. French. Catastrophic forgetting in connectionist networks. Trends in cog. scie. , 1999. 1
[27] Srishti Gautam, Marina M-C H ¨ohne, Stine Hansen, Robert Jenssen, và Michael Kampffmeyer. This looks more like

--- TRANG 10 ---
that: Enhancing self-explaining models by prototypical rele-vance propagation. Pattern Recognition , 136:109172, 2023. 8
[28] Alan H Gee, Diego Garcia-Olano, Joydeep Ghosh, và David Paydarfar. Explaining deep classification of time-series data with learned prototypes. Trong CEUR workshop pro-ceedings , tập 2429, trang 15. NIH Public Access, 2019. 3
[29] Amirata Ghorbani, James Wexler, James Y Zou, và Been Kim. Towards automatic concept-based explanations. Trong H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch ´e-Buc, E. Fox, và R. Garnett, biên tập, Advances in Neural Informa-tion Processing Systems , tập 32. Curran Associates, Inc., 2019. 2
[30] Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, và Yoshua Bengio. An empirical investigation of catas-trophic forgetting in gradient-based neural networks. Trong In-ternational Conference on Learning Representations , 2014. 1
[31] Yash Goyal, Ziyan Wu, Jan Ernst, Dhruv Batra, Devi Parikh, và Stefan Lee. Counterfactual visual explanations. Trong In-ternational Conference on Machine Learning , trang 2376–2384. PMLR, 2019. 2
[32] Filip Guzy, Michał Wo ´zniak, và Bartosz Krawczyk. Evalu-ating and explaining generative adversarial networks for con-tinual learning under concept drift. Trong 2021 International Conference on Data Mining Workshops (ICDMW) , trang 295–303. IEEE, 2021. 1
[33] Peter Hase, Chaofan Chen, Oscar Li, và Cynthia Rudin. In-terpretable image recognition with hierarchical prototypes. Trong Proceedings of the AAAI Conference on Human Compu-tation and Crowdsourcing , tập 7, trang 32–40, 2019. 3
[34] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Deep residual learning for image recognition. Trong Proceed-ings of the IEEE conference on computer vision and pattern recognition , trang 770–778, 2016. 5
[35] Geoffrey Hinton, Oriol Vinyals, và Jeff Dean. Distilling the knowledge in a neural network. Trong NIPS Deep Learning Workshop , 2014. 4
[36] Adrian Hoffmann, Claudio Fanconi, Rahul Rade, và Jonas Kohler. This looks like that... does it? shortcomings of latent space prototype interpretability in deep networks, 2021. 8
[37] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, và Dahua Lin. Learning a unified classifier incrementally via re-balancing. Trong International Conference on Computer Vision , 2019. 2
[38] Xinting Hu, Kaihua Tang, Chunyan Miao, Xian-Sheng Hua, và Hanwang Zhang. Distilling causal effect of data in class-incremental learning. Trong Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition , trang 3957–3966, 2021. 2
[39] Monish Keswani, Sriranjani Ramakrishnan, Nishant Reddy, và Vineeth N Balasubramanian. Proto2proto: Can you recognize the car, the way i do? Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 10233–10243, 2022. 3, 4

[40] Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, et al. Interpretability be-yond feature attribution: Quantitative testing with concept activation vectors (tcav). Trong International conference on ma-chine learning , trang 2668–2677. PMLR, 2018. 2
[41] Eunji Kim, Siwon Kim, Minji Seo, và Sungroh Yoon. Xpro-tonet: Diagnosis in chest radiography with global and local explanations. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 15719–15728, 2021. 3
[42] Sunnie SY Kim, Nicole Meister, Vikram V Ramaswamy, Ruth Fong, và Olga Russakovsky. Hive: evaluating the human interpretability of visual explanations. Trong Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XII , trang 280–298. Springer, 2022. 8
[43] B Ravi Kiran, Ibrahim Sobh, Victor Talpaert, Patrick Man-nion, Ahmad A Al Sallab, Senthil Yogamani, và Patrick P´erez. Deep reinforcement learning for autonomous driving: A survey. IEEE Transactions on Intelligent Transportation Systems , 23(6):4909–4926, 2021. 1
[44] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neu-ral networks. National Academy of Sciences , 2017. 1, 2, 5
[45] Pang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, và Percy Liang. Concept bottleneck models. Trong Hal Daum ´e III và Aarti Singh, biên tập, Proceedings of the 37th International Con-ference on Machine Learning , tập 119 của Proceedings of Machine Learning Research , trang 5338–5348. PMLR, 13–18 Jul 2020. 2
[46] Jonathan Krause, Michael Stark, Jia Deng, và Li Fei-Fei. 3d object representations for fine-grained categorization. Trong Proceedings of the IEEE international conference on com-puter vision workshops , trang 554–561, 2013. 2, 5
[47] Oscar Li, Hao Liu, Chaofan Chen, và Cynthia Rudin. Deep learning for case-based reasoning through prototypes: A neural network that explains its predictions. Trong Proceedings of the AAAI Conference on Artificial Intelligence , tập 32, 2018. 3
[48] Zhizhong Li và Derek Hoiem. Learning without forgetting. IEEE Transactions on Pattern Analysis and Machine Intelli-gence , 2017. 2, 4, 5
[49] Xialei Liu, Marc Masana, Luis Herranz, Joost Van de Wei-jer, Antonio M Lopez, và Andrew D Bagdanov. Rotate your networks: Better weight consolidation and less catastrophic forgetting. Trong International Conference on Pattern Recogni-tion, 2018. 2
[50] Arun Mallya, Dillon Davis, và Svetlana Lazebnik. Piggy-back: Adapting a single network to multiple tasks by learn-ing to mask weights. Trong European Conference on Computer Vision , 2018. 2
[51] Arun Mallya và Svetlana Lazebnik. Packnet: Adding mul-tiple tasks to a single network by iterative pruning. Trong Con-ference on Computer Vision and Pattern Recognition , 2018. 2

--- TRANG 11 ---
[52] Emanuele Marconato, Gianpaolo Bontempo, Stefano Teso, Elisa Ficarra, Simone Calderara, và Andrea Passerini. Catastrophic forgetting in continual concept bottleneck mod-els. Trong Image Analysis and Processing. ICIAP 2022 Work-shops: ICIAP International Workshops, Lecce, Italy, May 23–27, 2022, Revised Selected Papers, Part II , trang 539–547. Springer, 2022. 1
[53] Diego Marcos, Sylvain Lobry, và Devis Tuia. Semantically interpretable activation maps: what-where-how explanations within cnns. Trong 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW) , trang 4207–4215. IEEE, 2019. 2
[54] Marc Masana, Xialei Liu, Bartlomiej Twardowski, Mikel Menta, Andrew D Bagdanov, và Joost van de Weijer. Class-incremental learning: Survey and performance evaluation on image classification. IEEE Transactions on Pattern Analysis and Machine Intelligence , trang 1–20, 2022. 2, 5
[55] Yao Ming, Panpan Xu, Huamin Qu, và Liu Ren. Inter-pretable and steerable sequence learning via prototypes. Trong Proceedings of the 25th ACM SIGKDD International Con-ference on Knowledge Discovery & Data Mining , trang 903–913, 2019. 3
[56] Ramaravind K Mothilal, Amit Sharma, và Chenhao Tan. Explaining machine learning classifiers through diverse counterfactual explanations. Trong Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency , trang 607–617, 2020. 2
[57] Martin Mundt, Yongwon Hong, Iuliia Pliushch, và Vis-vanathan Ramesh. A wholistic view of continual learn-ing with deep neural networks: Forgotten lessons and the bridge to active and open world learning. Neural Networks , 160:306–336, 2023. 2
[58] Martin Mundt, Iuliia Pliushch, Sagnik Majumder, Yongwon Hong, và Visvanathan Ramesh. Unified probabilistic deep continual learning through generative replay and open set recognition. Journal of Imaging , 8(4):93, 2022. 2
[59] Meike Nauta et al. Neural prototype trees for interpretable fine-grained image recognition. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 14933–14943, 2021. 3
[60] Meike Nauta, Annemarie Jutte, Jesper Provoost, và Christin Seifert. This looks like that, because... explaining proto-types for interpretable image recognition. Trong Machine Learn-ing and Principles and Practice of Knowledge Discovery in Databases: International Workshops of ECML PKDD 2021, Virtual Event, September 13-17, 2021, Proceedings, Part I , trang 441–456. Springer, 2022. 8
[61] Meike Nauta, J ¨org Schl ¨otterer, Maurice van Keulen, và Christin Seifert. Pip-net: Patch-based intuitive prototypes for interpretable image classification. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 2744–2753, 2023. 8
[62] Yulei Niu, Kaihua Tang, Hanwang Zhang, Zhiwu Lu, Xian-Sheng Hua, và Ji-Rong Wen. Counterfactual vqa: A cause-effect look at language bias. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 12700–12710, 2021. 2

[63] Schramowski P. et al. Making deep neural networks right for the right scientific reasons by interacting with their explana-tions. Nature Machine Intelligence , 2(8):476–486, 2020. 1
[64] Arijit Patra và J Alison Noble. Incremental learning of fetal heart anatomies using interpretable saliency maps. Trong Med-ical Image Understanding and Analysis: 23rd Conference, MIUA 2019, Liverpool, UK, July 24–26, 2019, Proceedings 23, trang 129–141. Springer, 2020. 1
[65] Gr ´egoire Petit, Adrian Popescu, Hugo Schindler, David Pi-card, và Bertrand Delezoide. Fetril: Feature translation for exemplar-free class-incremental learning. Trong Proceedings of the IEEE/CVF Winter Conference on Applications of Com-puter Vision , trang 3911–3920, 2023. 6
[66] Ameya Prabhu, Philip HS Torr, và Puneet K Dokania. Gdumb: A simple approach that questions our progress in continual learning. Trong Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part II 16 , trang 524–540. Springer, 2020. 13
[67] Sylvestre-Alvise Rebuffi, Ruth Fong, Xu Ji, và Andrea Vedaldi. There and back again: Revisiting backpropagation saliency methods. Trong Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition , trang 8839–8848, 2020. 2
[68] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. icarl: Incremental classi-fier and representation learning. Trong Conference on Computer Vision and Pattern Recognition , 2017. 2
[69] Marco Tulio Ribeiro, Sameer Singh, và Carlos Guestrin. " why should i trust you?" explaining the predictions of any classifier. Trong Proceedings of the 22nd ACM SIGKDD interna-tional conference on knowledge discovery and data mining , trang 1135–1144, 2016. 2
[70] Cynthia Rudin. Stop explaining black box machine learn-ing models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence , 1(5):206–215, 2019. 1, 2
[71] Dawid Rymarczyk, Daniel Dobrowolski, và Tomasz Danel. Progrest: Prototypical graph regression soft trees for molec-ular property prediction. SIAM International Conference on Data Mining , 2023. 3
[72] Dawid Rymarczyk, Aneta Kaczy ´nska, Jarosław Kraus, Adam Pardyl, và Bartosz Zieli ´nski. Protomil: Multiple in-stance learning with prototypical parts for fine-grained in-terpretability. Trong Joint European Conference on Machine Learning and Knowledge Discovery in Databases . Springer, 2022. 3
[73] Dawid Rymarczyk, Łukasz Struski, Michał G ´orszczak, Ko-ryna Lewandowska, Jacek Tabor, và Bartosz Zieli ´nski. In-terpretable image classification with differentiable proto-types assignment. Trong Proceedings of the European Confer-ence on Computer Vision (ECCV) , 2022. 3, 8
[74] Dawid Rymarczyk, Łukasz Struski, Jacek Tabor, và Bartosz Zieli ´nski. Protopshare: Prototypical parts sharing for simi-larity discovery in interpretable image classification. Trong Pro-ceedings of the 27th ACM SIGKDD International Confer-ence on Knowledge Discovery & Data Mining , trang 1420–1430, 2021. 3

--- TRANG 12 ---
[75] Mikołaj Sacha, Dawid Rymarczyk, Łukasz Struski, Jacek Tabor, và Bartosz Zieli ´nski. Protoseg: Interpretable seman-tic segmentation with prototypical parts. Trong Winter Confer-ence on Applications of Computer Vision (WACV) , 2023. 3, 6
[76] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, và Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. Trong Proceedings of the IEEE in-ternational conference on computer vision , trang 618–626, 2017. 2
[77] Ramprasaath R Selvaraju, Stefan Lee, Yilin Shen, Hongxia Jin, Shalini Ghosh, Larry Heck, Dhruv Batra, và Devi Parikh. Taking a hint: Leveraging explanations to make vi-sion and language models more grounded. Trong Proceedings of the IEEE/CVF International Conference on Computer Vi-sion, trang 2591–2600, 2019. 2
[78] Joan Serra, Didac Suris, Marius Miron, và Alexandros Karatzoglou. Overcoming catastrophic forgetting with hard attention to the task. Trong International Conference on Machine Learning , 2018. 2
[79] Yujun Shi, Li Yuan, Yunpeng Chen, và Jiashi Feng. Con-tinual learning via bit-level information preserving. Trong Pro-ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 16674–16683, 2021. 2
[80] Karen Simonyan, Andrea Vedaldi, và Andrew Zisserman. Deep inside convolutional networks: Visualising image clas-sification models and saliency maps. Trong In Workshop at Inter-national Conference on Learning Representations . Citeseer, 2014. 2
[81] Gurmail Singh và Kin-Choong Yow. These do not look like those: An interpretable deep learning model for image recognition. IEEE Access , 9:41482–41493, 2021. 3
[82] Shixiang Tang, Dapeng Chen, Jinguo Zhu, Shijie Yu, và Wanli Ouyang. Layerwise optimization by gradient de-composition for continual learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 9634–9643, 2021. 2
[83] Gido M van de Ven và Andreas S Tolias. Three scenar-ios for continual learning. Trong NeurIPS Continual Learning Workshop , 2018. 2
[84] Catherine Wah, Steve Branson, Peter Welinder, Pietro Per-ona, và Serge Belongie. The caltech-ucsd birds-200-2011 dataset. 2011. 2, 5
[85] Jiaqi Wang et al. Interpretable image recognition by con-structing transparent embedding space. Trong Proceedings of the IEEE/CVF International Conference on Computer Vi-sion, trang 895–904, 2021. 3, 7, 8
[86] Liyuan Wang, Kuo Yang, Chongxuan Li, Lanqing Hong, Zhenguo Li, và Jun Zhu. Ordisco: Effective and efficient usage of incremental unlabeled data for semi-supervised continual learning. Trong Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition , trang 5383–5392, 2021. 2
[87] Pei Wang và Nuno Vasconcelos. Scout: Self-aware dis-criminant counterfactual explanations. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , trang 8981–8990, 2020. 2

[88] Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, và Yun Fu. Large scale in-cremental learning. Trong Conference on Computer Vision and Pattern Recognition , 2019. 2
[89] Shipeng Yan, Jiangwei Xie, và Xuming He. Der: Dynam-ically expandable representation for class incremental learn-ing. Trong Proceedings of the IEEE/CVF Conference on Com-puter Vision and Pattern Recognition , trang 3014–3023, 2021. 2
[90] Chih-Kuan Yeh, Been Kim, Sercan Arik, Chun-Liang Li, Tomas Pfister, và Pradeep Ravikumar. On completeness-aware concept-based explanations in deep neural networks. Trong H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, và H. Lin, biên tập, Advances in Neural Information Process-ing Systems , tập 33, trang 20554–20565. Curran Asso-ciates, Inc., 2020. 2
[91] Lu Yu, Bartlomiej Twardowski, Xialei Liu, Luis Herranz, Kai Wang, Yongmei Cheng, Shangling Jui, và Joost van de Weijer. Semantic drift compensation for class-incremental learning. Trong Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , trang 6982–6991, 2020. 5
[92] Friedemann Zenke, Ben Poole, và Surya Ganguli. Contin-ual learning through synaptic intelligence. Trong International Conference on Machine Learning , 2017. 2
[93] Mengyao Zhai, Lei Chen, và Greg Mori. Hyper-lifelonggan: Scalable lifelong learning for image condi-tioned generation. Trong Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition , trang 2246–2255, 2021. 2
[94] Zaixi Zhang, Qi Liu, Hao Wang, Chengqiang Lu, và Cheekong Lee. Protgnn: Towards self-explaining graph neu-ral networks. 2022. 3
[95] Fei Zhu, Xu-Yao Zhang, Chuang Wang, Fei Yin, và Cheng-Lin Liu. Prototype augmentation and self-supervision for incremental learning. Trong Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition , trang 5871–5880, 2021. 5, 6

--- TRANG 13 ---
Chi tiết thiết lập thực nghiệm bổ sung
Ở đây chúng tôi trình bày chi tiết bổ sung về thiết lập thực nghiệm. Chúng tôi thực hiện tìm kiếm siêu tham số cho λdist (λdist ∈
{10.0,5.0,0.0,0.5,0.1,0.05,0.01,0.005,0.001,0.0005,
0.0001}). Chúng tôi sử dụng trình tối ưu Adam với tốc độ học 0.001 và các tham số β1= 0.9 và β2= 0.999. Chúng tôi đặt kích thước batch là 75 và sử dụng hình ảnh đầu vào có độ phân giải 224×224×3. Trọng số của mạng được khởi tạo với trình khởi tạo bình thường Xavier.

Chúng tôi thực hiện đào tạo khởi động nơi trọng số của f được đóng băng trong 10 epoch, và sau đó chúng tôi đào tạo mô hình cho đến khi hội tụ với 12 epoch dừng sớm. Chúng tôi sử dụng lược đồ học được trình bày trong Bảng 7. Tùy thuộc vào số lượng nhiệm vụ, chúng tôi thực hiện đào tạo khởi động với {5,5,4} epoch và giai đoạn đào tạo kết hợp cho {21,15,11}, dài hơn với ít nhiệm vụ hơn. Tương tự, chúng tôi thực hiện chiếu nguyên mẫu mỗi {10,7,5} epoch. Vì vậy với nhiều nhiệm vụ hơn, chúng tôi thực hiện ít epoch đào tạo hơn (Bảng 7).

Kết quả trên Stanford Cars
Bảng 8 mô tả cách phương pháp ICICLE hoạt động trên tập dữ liệu Stanford Cars so với các phương pháp cơ sở khác. Kết quả nhất quán với những kết quả trên CUB-200-2011 và cho thấy rằng ICICLE vượt trội hơn tất cả các phương pháp học CL tiêu chuẩn được thích ứng cho kiến trúc ProtoPNet.

So sánh với GDumb
Ngoài ra, chúng tôi so sánh phương pháp của chúng tôi với GDumb [66], một phương pháp cơ sở trong học CL, trong các tình huống liên quan đến 3, 5, và 10 hình ảnh trên mỗi lớp với 4 nhiệm vụ học đạt 20.3, 34.2, 57.6, và 13.0, 26.7, 48.8 cho nhận biết nhiệm vụ và không phụ thuộc nhiệm vụ tương ứng. ICICLE vượt trội hơn GDumb với số lượng ví dụ nhỏ, và nhận biết nhiệm vụ cho GDumb-10 là ngoại lệ duy nhất nơi GDumb đạt điểm độ chính xác cao hơn.

Khởi tạo xa
Trong Bảng 5, chúng tôi cho thấy rằng khởi tạo dựa trên sự gần gũi là có lợi nhất. Tuy nhiên, ở đây trong Hình 10, chúng tôi cho thấy cách khởi tạo các phần nguyên mẫu ở khoảng cách từ những phần đã tồn tại tạo ra các khái niệm quá tổng quát hoặc mang thông tin về nền.

Bù trừ thiên lệch gần đây của nhiệm vụ
Ở đây, trong Bảng 9 chúng tôi cho thấy ảnh hưởng của bù trừ thiên lệch gần đây của nhiệm vụ đến độ chính xác của mỗi nhiệm vụ cho tình huống không phụ thuộc nhiệm vụ. Sau bù trừ, độ chính xác trên nhiệm vụ 1 tăng nhiều nhất, nhưng đồng thời độ chính xác trên tất cả các nhiệm vụ khác bị hy sinh. Tuy nhiên, độ chính xác trung bình sau bù trừ được tăng lên.

Hình 10: Hình ảnh mô tả phép chiếu TSNE 2D của các nguyên mẫu. Người ta có thể quan sát rằng có một cụm nguyên mẫu từ tất cả các nhiệm vụ ngoại trừ nhiệm vụ đầu tiên (hộp màu vàng). Điều này có thể quan sát được với khởi tạo xa và các trực quan hóa nguyên mẫu cho thấy rằng những phần nguyên mẫu đó đang đại diện cho nền hoặc các khái niệm mơ hồ.

Kết quả chi tiết sau khi học mỗi nhiệm vụ
Trong Bảng 10, và Bảng 11 chúng tôi cho thấy độ chính xác chi tiết của ICICLE sau khi học mỗi nhiệm vụ cho CUB-200-2011 trong một lần chạy duy nhất với cùng seed trong tình huống học bốn và mười nhiệm vụ.

Phân tích các siêu tham số cho các cơ sở
Trong Bảng 12, Bảng 13, và Bảng 14 chúng tôi cho thấy ảnh hưởng của các siêu tham số cho mỗi phương pháp cơ sở, EWC, LWF, và LWM, tương ứng. Dựa trên đó, các tham số của những phương pháp này được chọn để so sánh với ICICLE.

--- TRANG 14 ---
Giai đoạn Các lớp mô hình Tốc độ học Bộ lập lịch Phân rã trọng số Thời lượng
Khởi động tích chập bổ sung 1×1 1·10−3
Không có Không có 5,5,4 epoch lớp nguyên mẫu 1·10−3
Kết hợp các tích chập f 1·10−4
giảm một nửa mỗi
5 epoch 10−4 21,15,10 epoch
dừng sớm tích chập bổ sung 1×1 1·10−3
lớp nguyên mẫu 1·10−3

Bảng 7: Lược đồ học cho phương pháp ICICLE.

ĐỘ CHÍNH XÁC TRUNG BÌNH TĂNG DẦN NHẬN BIẾT NHIỆM VỤ ĐỘ CHÍNH XÁC TRUNG BÌNH TĂNG DẦN KHÔNG PHỤ THUỘC NHIỆM VỤ
PHƯƠNG PHÁP 4NHIỆM VỤ 7NHIỆM VỤ 14NHIỆM VỤ 4NHIỆM VỤ 7NHIỆM VỤ 14NHIỆM VỤ
FREEZING 0.572±0.031 0.518±0.041 0.486±0.026 0.309±0.012 0.155±0.031 0.092±0.014
FINETUNING 0.216±0.009 0.167±0.011 0.149±0.012 0.182±0.006 0.124±0.013 0.057±0.001
EWC 0.456±0.021 0.315±0.037 0.287±0.041 0.258±0.019 0.152±0.022 0.011±0.009
LWM 0.459±0.072 0.416±0.048 0.305±0.022 0.233±0.026 0.171±0.016 0.080±0.008
LWF 0.375±0.021 0.356±0.024 0.250±0.020 0.230±0.011 0.171±0.005 0.092±0.008
ICICLE 0.654±0.014 0.645±0.003 0.583±0.048 0.335±0.005 0.203±0.010 0.116±0.018

Bảng 8: So sánh độ chính xác trung bình tăng dần cho số lượng nhiệm vụ khác nhau trên Stanford Cars, chứng minh tác động tiêu cực của số lượng nhiệm vụ cao cần học đến hiệu suất của mô hình. Mặc dù xu hướng này, ICICLE vượt trội hơn các phương pháp cơ sở trên tất cả số lượng nhiệm vụ.

NHIỆM VỤ 1 NHIỆM VỤ 2 NHIỆM VỤ 3 NHIỆM VỤ 4 TRUNG BÌNH
NHẬN BIẾT NHIỆM VỤ 0.514 0.717 0.725 0.698 0.663
TRƯỚC 0.028 0.301 0.434 0.575 0.335
SAU 0.233 0.365 0.314 0.486 0.350

Bảng 9: Ảnh hưởng bù trừ thiên lệch gần đây của nhiệm vụ của một lần chạy duy nhất. Kết quả cho thấy rằng phương pháp bù trừ của chúng tôi cân bằng kết quả cho mỗi nhiệm vụ trong tình huống không phụ thuộc nhiệm vụ tốt hơn.

--- TRANG 15 ---
ĐỘ CHÍNH XÁC NHẬN BIẾT NHIỆM VỤ ĐỘ CHÍNH XÁC KHÔNG PHỤ THUỘC NHIỆM VỤ
Sau NHIỆM VỤ 1 NHIỆM VỤ 2 NHIỆM VỤ 3 NHIỆM VỤ 4 TRUNG BÌNH NHIỆM VỤ 1 NHIỆM VỤ 2 NHIỆM VỤ 3 NHIỆM VỤ 4 TRUNG BÌNH
NHIỆM VỤ 1 0.806 NA NA NA 0.806 0.806 NA NA NA 0.806
NHIỆM VỤ 2 0.740 0.759 NA NA 0.750 0.089 0.747 NA NA 0.418
NHIỆM VỤ 3 0.622 0.736 0.759 NA 0.706 0.033 0.633 0.549 NA 0.404
NHIỆM VỤ 4 0.514 0.717 0.725 0.698 0.663 0.028 0.484 0.378 0.505 0.349

Bảng 10: Kết quả của phương pháp ICICLE trước bù trừ thiên lệch gần đây của nhiệm vụ cho tình huống học bốn nhiệm vụ sau mỗi tập học.

ĐỘ CHÍNH XÁC NHẬN BIẾT NHIỆM VỤ
Sau NHIỆM VỤ 1 NHIỆM VỤ 2 NHIỆM VỤ 3 NHIỆM VỤ 4 NHIỆM VỤ 5 NHIỆM VỤ 6 NHIỆM VỤ 7 NHIỆM VỤ 8 NHIỆM VỤ 9 NHIỆM VỤ 10 TRUNG BÌNH
NHIỆM VỤ 1 0.920 NA NA NA NA NA NA NA NA NA 0.920
NHIỆM VỤ 2 0.666 0.869 NA NA NA NA NA NA NA NA 0.767
NHIỆM VỤ 3 0.462 0.818 0.858 NA NA NA NA NA NA NA 0.713
NHIỆM VỤ 4 0.420 0.751 0.774 0.774 NA NA NA NA NA NA 0.680
NHIỆM VỤ 5 0.314 0.625 0.680 0.672 0.784 NA NA NA NA NA 0.615
NHIỆM VỤ 6 0.268 0.538 0.627 0.617 0.760 0.747 NA NA NA NA 0.593
NHIỆM VỤ 7 0.265 0.476 0.584 0.617 0.713 0.706 0.769 NA NA NA 0.590
NHIỆM VỤ 8 0.258 0.413 0.551 0.555 0.667 0.634 0.741 0.764 NA NA 0.573
NHIỆM VỤ 9 0.253 0.398 0.494 0.492 0.598 0.587 0.701 0.745 0.852 NA 0.569
NHIỆM VỤ 10 0.244 0.371 0.462 0.441 0.573 0.560 0.667 0.729 0.816 0.803 0.567

ĐỘ CHÍNH XÁC KHÔNG PHỤ THUỘC NHIỆM VỤ
NHIỆM VỤ 1 NHIỆM VỤ 2 NHIỆM VỤ 3 NHIỆM VỤ 4 NHIỆM VỤ 5 NHIỆM VỤ 6 NHIỆM VỤ 7 NHIỆM VỤ 8 NHIỆM VỤ 9 NHIỆM VỤ 10 TRUNG BÌNH
NHIỆM VỤ 1 0.920 NA NA NA NA NA NA NA NA NA 0.920
NHIỆM VỤ 2 0.010 0.869 NA NA NA NA NA NA NA NA 0.439
NHIỆM VỤ 3 0.0 0.060 0.854 NA NA NA NA NA NA NA 0.305
NHIỆM VỤ 4 0.0 0.0 0.339 0.751 NA NA NA NA NA NA 0.273
NHIỆM VỤ 5 0.0 0.0 0.030 0.323 0.746 NA NA NA NA NA 0.220
NHIỆM VỤ 6 0.0 0.0 0.004 0.090 0.451 0.684 NA NA NA NA 0.205
NHIỆM VỤ 7 0.0 0.0 0.0 0.020 0.193 0.432 0.712 NA NA NA 0.194
NHIỆM VỤ 8 0.0 0.0 0.0 0.020 0.073 0.233 0.497 0.643 NA NA 0.181
NHIỆM VỤ 9 0.0 0.0 0.0 0.0 0.035 0.138 0.338 0.435 0.676 NA 0.180
NHIỆM VỤ 10 0.0 0.0 0.0 0.0 0.016 0.070 0.214 0.285 0.484 0.643 0.171

Bảng 11: Kết quả của phương pháp ICICLE trước bù trừ thiên lệch gần đây của nhiệm vụ cho tình huống học mười nhiệm vụ sau mỗi tập học.

ĐỘ CHÍNH XÁC NHẬN BIẾT NHIỆM VỤ ĐỘ CHÍNH XÁC KHÔNG PHỤ THUỘC NHIỆM VỤ
α 0.01 0.1 1.0 5.0 10.0 0.01 0.1 1.0 5.0 10.0
0.185 0.329 0.441 0.197 0.167 0.170 0.185 0.213 0.168 0.144

Bảng 12: Ảnh hưởng của tham số alpha trong EWC đến độ chính xác của kiến trúc ProtoPNet trong tình huống học bốn nhiệm vụ.

ĐỘ CHÍNH XÁC NHẬN BIẾT NHIỆM VỤ ĐỘ CHÍNH XÁC KHÔNG PHỤ THUỘC NHIỆM VỤ
γ 0.001 0.01 0.1 1.0 10.0 0.001 0.01 0.1 1.0 10.0
0.240 0.240 0.431 0.355 0.231 0.209 0.209 0.212 0.209 0.209

Bảng 13: Ảnh hưởng của tham số γ trong LWM đến độ chính xác của kiến trúc ProtoPNet trong tình huống học bốn nhiệm vụ.

ĐỘ CHÍNH XÁC NHẬN BIẾT NHIỆM VỤ ĐỘ CHÍNH XÁC KHÔNG PHỤ THUỘC NHIỆM VỤ
λ 0.001 0.01 0.1 1.0 10.0 0.001 0.01 0.1 1.0 10.0
0.232 0.232 0.238 0.359 0.249 0.207 0.210 0.210 0.231 0.221

Bảng 14: Ảnh hưởng của tham số λ trong LWF đến độ chính xác của kiến trúc ProtoPNet trong tình huống học bốn nhiệm vụ.

# 2211.00251.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/interpretability/2211.00251.pdf
# Kích thước tệp: 1617732 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Lựa chọn Mô hình Khả vi cho Học tập Tập hợp
James Kotary1,Vincenzo Di Vito1và Ferdinando Fioretto2
1Đại học Syracuse
2Đại học Virginia
fjkotary, vdivitofg@syr.edu, nandoﬁoretto@gmail.com
Tóm tắt
Lựa chọn mô hình là một chiến lược nhằm tạo ra các mô hình chính xác và mạnh mẽ. Một thách thức chính trong việc thiết kế các thuật toán này là xác định mô hình tối ưu để phân loại bất kỳ mẫu đầu vào cụ thể nào. Bài báo này giải quyết thách thức này và đề xuất một khung làm việc mới cho lựa chọn mô hình khả vi tích hợp học máy và tối ưu hóa tổ hợp. Khung làm việc được thiết kế riêng cho học tập tập hợp, một chiến lược kết hợp các đầu ra của các mô hình được đào tạo trước riêng lẻ, và học cách lựa chọn các thành viên tập hợp phù hợp cho một mẫu đầu vào cụ thể bằng cách chuyển đổi nhiệm vụ học tập tập hợp thành một chương trình lựa chọn khả vi được đào tạo đầu cuối đến cuối trong mô hình học tập tập hợp.
Được thử nghiệm trên các nhiệm vụ khác nhau, khung làm việc đề xuất chứng minh tính linh hoạt và hiệu quả của nó, vượt trội hơn các quy tắc đồng thuận thông thường và tiên tiến trên nhiều thiết lập và nhiệm vụ học tập khác nhau.

1 Giới thiệu
Lựa chọn mô hình bao gồm quá trình xác định mô hình phù hợp nhất từ một tập hợp các ứng viên cho một nhiệm vụ học tập nhất định. Mô hình được chọn lý tưởng nên tổng quát hóa tốt cho dữ liệu chưa thấy, với độ phức tạp của mô hình đóng vai trò quan trọng trong quá trình lựa chọn này. Tuy nhiên, việc đạt được cân bằng giữa underfitting và overfitting là một thách thức đáng kể.

Nhiều kỹ thuật đã được trình bày trong tài liệu học máy để giải quyết vấn đề này. Đặc biệt có liên quan, học tập tập hợp [Witten et al., 2005] là một meta-algorithm kết hợp các đầu ra của các mô hình được đào tạo trước riêng lẻ, được gọi là base learners, để cải thiện hiệu suất tổng thể. Mặc dù được đào tạo để thực hiện cùng một nhiệm vụ, các base learners này có thể thể hiện sự đa dạng lỗi, có nghĩa là chúng thất bại trên các mẫu khác nhau, và các profile chính xác của chúng bổ sung cho nhau trên toàn bộ phân phối của các mẫu kiểm tra.

Hiệu quả tiềm năng của một mô hình tập hợp phụ thuộc mạnh vào mối tương quan giữa lỗi của các base learners trên các mẫu đầu vào và độ chính xác của chúng; những mô hình có độ chính xác cao hơn và sự đa dạng lỗi có tiềm năng cao hơn để cải thiện độ chính xác của tập hợp [Mienye and Sun, 2022].

Tuy nhiên, nhiệm vụ xác định tập hợp tối ưu của các mô hình để phân loại bất kỳ mẫu đầu vào cụ thể nào là không tầm thường. Các phương pháp truyền thống thường tổng hợp dự đoán trên tất cả các base learners của một tập hợp, nhằm làm cho dự đoán mạnh mẽ hơn đối với lỗi của các base learners riêng lẻ. Trong khi các kỹ thuật này có thể được tăng cường bằng cách áp dụng chúng một cách có chọn lọc cho một tập con của các base learners được biết là đáng tin cậy hơn trên một số đầu vào nhất định, việc thiết kế các thuật toán hiệu quả lựa chọn và kết hợp các dự đoán riêng lẻ của base learners vẫn là một nỗ lực phức tạp. Nhiều phương pháp dựa trên quy tắc đồng thuận áp dụng các sơ đồ tổng hợp kết hợp hoặc loại trừ dự đoán của base learners dựa trên các quy tắc tĩnh, do đó bỏ lỡ cơ hội thông báo cho việc lựa chọn tập hợp dựa trên các đặc trưng của một đầu vào cụ thể.

Gần đây, khái niệm lựa chọn mô hình khả vi đã xuất hiện, nhằm kết hợp quá trình lựa chọn mô hình vào bản thân quá trình đào tạo [Dona and Gallinari, 2021; Sheth and Fusi, 2020; Fu et al., 2016]. Phương pháp này tận dụng các phương pháp dựa trên gradient để tối ưu hóa lựa chọn mô hình, chứng minh đặc biệt có lợi trong các lĩnh vực như tìm kiếm kiến trúc mạng neural. Động lực đằng sau lựa chọn mô hình khả vi nằm ở tiềm năng tự động hóa và tối ưu hóa quá trình lựa chọn mô hình, do đó dẫn đến các mô hình tốt hơn và các thủ tục lựa chọn hiệu quả hơn. Mặc dù có những lời hứa, tuy nhiên, việc thiết kế các chiến lược lựa chọn mô hình khả vi hiệu quả vẫn không tầm thường và việc sử dụng các phương pháp dựa trên gradient một mình còn tăng thêm rủi ro hội tụ đến tối ưu cục bộ có thể dẫn đến lựa chọn mô hình không tối ưu.

Trong ánh sáng của những thách thức này, bài báo này đề xuất một khung làm việc mới cho lựa chọn mô hình khả vi được thiết kế riêng cho học tập tập hợp. Khung làm việc này tích hợp học máy và tối ưu hóa tổ hợp để học việc lựa chọn các thành viên tập hợp bằng cách mô hình hóa quá trình lựa chọn như một bài toán tối ưu hóa dẫn đến các lựa chọn tối ưu trong bối cảnh được quy định.

Đóng góp. Cụ thể hơn, bài báo này đưa ra các đóng góp sau: (1) Nó đề xuất Học tập Tập hợp Tổ hợp đầu cuối đến cuối (e2e-CEL), một khung làm việc học tập tập hợp mới khai thác sự tích hợp của ML và tối ưu hóa tổ hợp để biên dịch quy tắc đồng thuận chuyên biệt cho một mẫu đầu vào cụ thể. (2) Nó cho thấy cách đúc việc lựa chọn và tổng hợp dự đoán của base learners tập hợp như một bài toán tối ưu hóa khả vi, được tham số hóa bởi một mạng neural sâu và được đào tạo đầu cuối đến cuối trong nhiệm vụ học tập tập hợp. (3) Một phân tích về các nhiệm vụ học tập thách thức chứng minh sức mạnh của ý tưởng này: e2e-arXiv:2211.00251v2 [cs.LG] 19 May 2023

--- TRANG 2 ---
CEL vượt trội hơn các mô hình cố gắng lựa chọn các thành viên tập hợp riêng lẻ, chẳng hạn như sự kết hợp có trọng số tối ưu của các dự đoán thành viên tập hợp riêng lẻ cũng như các quy tắc đồng thuận thông thường, ngụ ý khả năng cao hơn nhiều để tận dụng sự đa dạng lỗi.

Những kết quả này chứng minh sự tích hợp của tối ưu hóa có ràng buộc và học tập là một yếu tố cho phép chính để tăng cường hiệu quả của lựa chọn mô hình trong các nhiệm vụ học máy.

2 Công trình Liên quan
Học tập tập hợp bao gồm hai bước: đào tạo các base learners riêng lẻ và kết hợp các đầu ra của chúng để có dự đoán chính xác. Việc cấu thành một tập hợp từ các base learners với các profile lỗi bổ sung thường được thực hiện thông qua bagging (tạo ngẫu nhiên các tập dữ liệu để đào tạo mỗi thành viên) và boosting (tạo thích ứng các tập dữ liệu dựa trên phân phối lỗi để tăng sự đa dạng lỗi). Một khảo sát về đào tạo các base learners riêng lẻ có thể được tìm thấy trong Mienye and Sun [2022]. Bước thứ hai thường được xử lý bởi các quy tắc tổng hợp cổ điển trên các dự đoán hoặc giá trị kích hoạt của các thành viên tập hợp, chẳng hạn như bỏ phiếu đa số hoặc số đông.

Một số công trình cũng đã cố gắng mô hình hóa toán học các quy tắc tổng hợp hiệu quả hơn, chẳng hạn như thuật toán Super Learner [Ju et al., 2018] hình thành một sự kết hợp có trọng số của các mô hình base learner tối đa hóa độ chính xác trên một tập validation. Thuật toán này đã được chứng minh là tối ưu tiệm cận để kết hợp dự đoán của các thành viên tập hợp.

Bài báo này giải quyết khía cạnh thách thức sau của mô hình hóa tập hợp: tối ưu hóa việc tổng hợp dự đoán từ các base learners tập hợp riêng lẻ. Phương pháp e2e-CEL đề xuất nhằm học các quy tắc tổng hợp một cách thích ứng ở mức độ của các mẫu đầu vào riêng lẻ, thay vì một quy tắc duy nhất cho tất cả các mẫu. Trong khi các quy tắc lựa chọn dựa trên heuristic để rút ra các tập hợp phụ thuộc đầu vào không mới đối với tài liệu, theo hiểu biết tốt nhất của chúng tôi, đây là đề xuất đầu tiên về một phương pháp học các quy tắc có điều kiện như vậy theo cách đầu cuối đến cuối. Một cuộc thảo luận về công trình bổ sung được hoãn lại đến Phụ lục A.

3 Thiết lập và Mục tiêu
Bài báo xem xét các tập hợp như một bộ sưu tập của n mô hình hoặc base learners được biểu diễn bởi các hàm fi; 1 ≤ i ≤ n, được đào tạo độc lập trên các tập dữ liệu riêng biệt (nhưng có thể chồng chéo) (Xi, Yi), tất cả trên cùng một nhiệm vụ phân loại dự định. Trên mọi nhiệm vụ được nghiên cứu, nó giả định rằng (Xi, Yi) được cho, cùng với một quy định để đào tạo mỗi base learners, để fi được giả định là được cấu hình trước. Thiết lập này phổ biến trong các bối cảnh phân tích liên bang, nơi các base learners thường được đào tạo trên các tập dữ liệu đa dạng với phân phối lệch [Kairouz et al., 2021], và trong các dịch vụ ML, nơi các nhà cung cấp cung cấp một loạt các mô hình được đào tạo trước với các lựa chọn kiến trúc và siêu tham số khác nhau [Ribeiro et al., 2015].

Gọi n ∈ N là số lượng base learners, c ∈ N là số lượng lớp và d ∈ N là kích thước đặc trưng đầu vào. Cho một mẫu z ∈ Rd, mỗi base learner fj : Rd → Rc tính toán fj(z) = ŷj. Đối với các nhiệm vụ phân loại được xem xét trong bài báo này, mỗi ŷj là đầu ra trực tiếp của một hàm softmax Rc → Rc,

softmax(c)i = eci / Σk=1c eck:                    (1)

Một cách rõ ràng, mỗi bộ phân loại fi(θi; x) được đào tạo đối với các tham số θi của nó để tối thiểu hóa một mất mát phân loại L như

min θi E(x,y)~(Xi,Yi)[L(fi(θi; x), y)]:           (2)

Mục tiêu sau đó là kết hợp các base learners thành một tập hợp, có bộ phân loại tổng hợp g thực hiện cùng một nhiệm vụ, nhưng với độ chính xác tổng thể lớn hơn trên một tập dữ liệu chủ (X, Y), trong đó Xi ⊆ X và Yi ⊆ Y cho tất cả i với 0 ≤ i ≤ n:

min φ E(x,y)~(X,Y)[L(g(φ; x), y)]:               (3)

Như thường thấy trong học tập tập hợp, các base learners có thể được đào tạo theo cách tăng sự đa dạng test-error giữa fi trên X - xem Phần 5. Trong mỗi tập dữ liệu có một phân chia train/test/validation ngầm, để việc đánh giá một mô hình được đào tạo luôn được thực hiện trên phần test của nó. Nơi sự phân biệt này được cần thiết, các ký hiệu Xtrain, Xvalid, Xtest được sử dụng. Một danh sách các ký hiệu được sử dụng trong bài báo để mô tả các khía cạnh khác nhau của tính toán, cùng với ý nghĩa của chúng được cung cấp trong [Kotary et al., 2022], Bảng 4.

4 Học tập Tập hợp Tổ hợp đầu cuối đến cuối

Lý tưởng, cho một tập hợp được đào tạo trước fi; 1 ≤ i ≤ n và một mẫu z ∈ X, người ta sẽ lựa chọn từ tập hợp một bộ phân loại được biết sẽ tạo ra một dự đoán lớp chính xác cho z. Tuy nhiên, một đánh giá hiệu suất cho dự đoán của mỗi base learners không có sẵn tại thời điểm test. Do đó, các sơ đồ học tập tập hợp thông thường phải sử dụng các tiêu chí lựa chọn như bỏ phiếu số đông (xem Phần 5 để mô tả các quy tắc tổng hợp được sử dụng ở đây như một điểm chuẩn).

Sơ đồ học tập đầu cuối đến cuối trong công trình này dựa trên ý tưởng rằng một dự đoán tập hợp chính xác hơn có thể được thực hiện bằng cách sử dụng dự đoán dựa trên z, và việc lựa chọn một tập con được chọn tốt của tập hợp, thay vì toàn bộ tập hợp, có thể cung cấp kết quả đáng tin cậy hơn so với một base learner duy nhất. Kích thước của tập con, k, được coi như một siêu tham số. Trong khi có vẻ hợp lý khi chỉ chọn base learner được dự đoán tốt nhất cho một mẫu đầu vào nhất định (đặt k = 1), người ta luôn quan sát thấy trong các thí nghiệm rằng hiệu suất tối ưu đạt được khi 1 < k < n:

Cơ chế đề xuất đúc việc lựa chọn sub-ensemble như một chương trình tối ưu hóa có thể khả vi đầu cuối đến cuối và do đó có thể được tích hợp với một mô hình học tập g để lựa chọn một tập con đáng tin cậy của các base learners tập hợp để kết hợp cho dự đoán. Một Học tập Tập hợp Tổ hợp đầu cuối đến cuối (e2e-CEL), hay đơn giản là smart ensemble, bao gồm một tập hợp các base learners cùng với một module được đào tạo bởi e2e-CEL để lựa chọn sub-ensemble có kích thước k, tạo ra dự đoán kết hợp chính xác nhất cho một đầu vào nhất định. Mô hình g được gọi là selection net, và mô hình tập hợp đầu cuối đến cuối được đào tạo bằng cách tối ưu hóa các tham số φ của nó.

--- TRANG 3 ---
Hình 1: Sơ đồ Học tập Tập hợp đầu cuối đến cuối: Mũi tên đen và đỏ minh họa các hoạt động tiến và lùi, tương ứng.

Tổng quan E2e-CEL. E2e-CEL bao gồm ba bước chính:
1. Dự đoán một vector điểm số g(z) = ĉ, ước tính độ chính xác dự đoán cho mỗi base learner trên mẫu z.
2. Xác định các chỉ số base learner E ⊆ [n] tương ứng với k điểm số dự đoán cao nhất.
3. Thu thập các dự đoán của sub-ensemble được chọn fj(z) và thực hiện một sơ đồ bỏ phiếu đa số gần đúng trên những dự đoán đó để xác định lớp của z.

Bằng cách đào tạo trên tập chủ Xtrain, smart ensemble học cách đưa ra dự đoán tốt hơn bằng đức tính của việc học cách lựa chọn sub-ensembles tốt hơn để bỏ phiếu trên các mẫu đầu vào của nó. Tuy nhiên, lưu ý rằng lựa chọn tập con và bỏ phiếu số đông là các hoạt động rời rạc, và ở dạng thuần túy không cung cấp gradient hữu ích cho lan truyền ngược và học tập. Các phần tiếp theo thảo luận chi tiết hơn về khung làm việc e2e-CEL, bao gồm các xấp xỉ khả vi cho mỗi bước của mô hình tổng thể.

Hình 1 minh họa mô hình e2e-CEL và quá trình đào tạo của nó về các hoạt động thành phần. Lan truyền ngược được hiển thị bằng mũi tên đỏ, và nó chỉ áp dụng cho các hoạt động downstream từ selection net g, vì e2e-CEL được tham số hóa chỉ bởi các tham số φ của g.

4.1 Lựa chọn Mô hình Khả vi

Hệ thống e2e-CEL dựa trên việc học cách lựa chọn k < n dự đoán từ tập hợp chủ, cho một tập hợp các đặc trưng đầu vào. Điều này có thể được thực hiện bằng cách dự đoán có cấu trúc của các giá trị nhị phân, sau đó được sử dụng để che các dự đoán base learner riêng lẻ.

Xem xét bài toán knapsack không có trọng số

K(ĉ) = argmax b ĉᵀb                    (4a)
subject to 1ᵀb = k;                     (4b)
         b ∈ {0,1}ⁿ;                    (4c)

có thể được xem như một bài toán lựa chọn có nghiệm tối ưu gán giá trị 1 cho các phần tử của b liên kết với k giá trị cao nhất của ĉ. Nới lỏng ràng buộc (4c) thành 0 ≤ b ≤ 1 dẫn đến một chương trình tuyến tính (LP) tương đương với các nghiệm tối ưu rời rạc b ∈ {0,1}ⁿ, mặc dù vừa lồi vừa bao gồm các hàm liên tục. Tính chất hữu ích này tồn tại cho bất kỳ LP nào với các ràng buộc hoàn toàn unimodular và các hệ số phía phải nguyên [Bazaraa et al., 2008].

Bài toán tối ưu hóa này có thể được xem như một ánh xạ từ ĉ đến một vector nhị phân chỉ ra k giá trị cao nhất của nó, và do đó biểu diễn một ứng viên tự nhiên cho việc lựa chọn sub-ensemble tối ưu có kích thước k cho các điểm số dự đoán của base learners riêng lẻ, được xem như ĉ. Tuy nhiên, các đầu ra của Bài toán (4) định nghĩa một hàm hằng từng đoạn, K(ĉ), không thừa nhận gradient thông tin dễ dàng, đặt ra thách thức cho tính khả vi. Để tích hợp vào hệ thống học tập đầu cuối đến cuối, hàm K(ĉ) phải cung cấp gradient thông tin đối với ĉ. Trong công trình này, thách thức này được khắc phục bằng cách làm trơn K(ĉ) dựa trên việc nhiễu ĉ với nhiễu ngẫu nhiên.

Như quan sát bởi Berthet et al. [2020], bất kỳ bài toán lập trình tuyến tính liên tục, lồi nào cũng có thể được sử dụng để định nghĩa một perturbed optimizer khả vi, tạo ra các nghiệm gần như giống nhau nhưng khả vi đối với các hệ số mục tiêu tuyến tính của nó. Cho một biến nhiễu ngẫu nhiên Z với mật độ xác suất p(z) ∝ exp(-v(z)) trong đó v là một hàm khả vi hai lần,

K̄(ĉ) = E_z~Z[K(ĉ + z)];              (5)

là một perturbed optimizer khả vi liên kết với K. Tham số nhiệt độ τ > 0 kiểm soát độ nhạy của gradient của nó (hoặc đúng hơn, ma trận Jacobian), có thể tự biểu diễn bởi giá trị kỳ vọng [Abernethy et al., 2016]:

∂K̄(ĉ)/∂ĉ = E_z~Z[K(ĉ + z)∇v(z)ᵀ]/τ.    (6)

Trong công trình này, Z được mô hình như một biến ngẫu nhiên Normal chuẩn. Trong khi những giá trị kỳ vọng này không thể tính được một cách phân tích (do toán tử constrained argmax trong bài toán knapsack K), chúng có thể được ước tính với độ chính xác tùy ý bằng lấy mẫu theo cách Monte Carlo. Thủ tục này là một tổng quát hóa của Gumbel Max Trick [Gumbel, 1954].

--- TRANG 4 ---
Lưu ý rằng việc mô phỏng Phương trình (5) và (6) đòi hỏi giải Bài toán (4) cho có thể nhiều giá trị của z. Tuy nhiên, mặc dù lý thuyết của perturbed optimizers đòi hỏi bài toán cơ bản phải là một chương trình tuyến tính, chỉ cần một triển khai blackbox để tạo ra K(ĉ) [Berthet et al., 2020], cho phép một thuật toán hiệu quả được sử dụng thay cho một bộ giải LP (tốn kém hơn). Độ phức tạp của việc đánh giá perturbed optimizer khả vi K̄(ĉ) được thảo luận tiếp theo.

Định lý 1. Tổng tính toán cần thiết để giải Bài toán (4) là O(n log k), trong đó n và k lần lượt là kích thước của tập hợp và sub-ensembles.

Chứng minh. Kết quả này dựa trên quan sát rằng K(ĉ) có thể được tính hiệu quả bằng cách xác định k giá trị cao nhất của ĉ trong thời gian O(n log k) sử dụng kỹ thuật chia để trị. Xem, ví dụ, [Cormen et al., 2022].

Tạo ra m nghiệm như vậy để ước tính gradient sau đó đòi hỏi O(mn log k) phép toán. Tuy nhiên, lưu ý rằng những phép toán này có thể được thực hiện song song trên các mẫu, cho phép đủ mẫu nhiễu được tạo ra để tính toán gradient chính xác, đặc biệt khi có sẵn tính toán GPU.

Để rõ ràng, cũng lưu ý rằng hàm K, như một ánh xạ chương trình tuyến tính, có không gian đầu ra rời rạc vì bất kỳ chương trình tuyến tính nào đều lấy nghiệm tối ưu tại một đỉnh của vùng khả thi [Bazaraa et al., 2008], có số lượng hữu hạn. Như vậy, nó là một hàm hằng từng đoạn và khả vi trừ trên một tập có độ đo bằng không [Folland, 1999]. Tuy nhiên, ∂K/∂ĉ = 0 ở mọi nơi nó được định nghĩa, vì vậy các đạo hàm thiếu thông tin hữu ích cho gradient descent [Wilder et al., 2019]. Trong khi ∂K̄/∂ĉ không phải là đạo hàm thực của K̄ tại ĉ, nó cung cấp thông tin hữu ích về hướng giảm của nó.

Trong thực tế, lượt chuyển tối ưu hóa tiến được mô hình như K̄(ĉ), và lượt chuyển lùi được mô hình như ∂K̄(ĉ)/∂ĉ. Điều này cho phép các hoạt động downstream hơn nữa, và các đạo hàm của chúng, được đánh giá tại K̄(ĉ) mà không cần xấp xỉ, điều này cải thiện hiệu suất đào tạo và test. Những lượt chuyển tiến và lùi này cùng nhau được gọi là Knapsack Layer. Lượt chuyển lùi rõ ràng của nó được tính như

∂K̄(ĉ)/∂ĉ ≈ (1/m) Σᵢ₌₁ᵐ K(ĉ + zᵢ)∇v(zᵢ)ᵀ/τ,    (7)

trong đó zᵢ ~ N(0,1)ⁿ là m mẫu độc lập mỗi mẫu được rút từ phân phối normal chuẩn.

4.2 Kết hợp Dự đoán

Ký hiệu P ∈ Rᶜˣⁿ là ma trận có cột thứ j là vector softmax ŷⱼ của base learner j,

P = (ŷ₁ ŷ₂ ··· ŷₙ).                     (8)

Với mục đích kết hợp dự đoán của base learners tập hợp, K̄(ĉ) được coi như một vector che nhị phân b ∈ {0,1}ⁿ, lựa chọn tập con của base learners để đưa ra dự đoán. Ký hiệu B ∈ {0,1}ᶜˣⁿ là ma trận có cột thứ i là Bᵢ = ωbᵢ; tức là,

B = [b 1 ··· b n]ᵀ.

Ma trận này được sử dụng để che dự đoán softmax của các mô hình base learners P bằng phép nhân theo phần tử. Tiếp theo, định nghĩa

P̃ₖ = B ⊙ P
    = [b 1 ··· b n]ᵀ ⊙ [ŷ₁ ··· ŷₙ].     (9)

Làm như vậy cho phép tính tổng dự đoán trên sub-ensemble E được chọn, nhưng theo cách tự động khả vi, đó là:

v̂ := Σᵢ∈E ŷᵢ = Σᵢ₌₁ⁿ P̃ₖ⁽ⁱ⁾.              (10)

Dự đoán e2e-CEL đến từ việc áp dụng softmax cho tổng này:

ŷ = softmax(v̂) = softmax(Σᵢ₌₁ⁿ P̃ₖ⁽ⁱ⁾);    (11)

xem softmax như một xấp xỉ trơn của hàm argmax được biểu diễn với các vector nhị phân one-hot. Hàm này được hiểu như một bỏ phiếu đa số được làm trơn để xác định một dự đoán lớp: cho các chỉ báo lớp nhị phân one-hot hᵢ, bỏ phiếu đa số bằng argmax(Σᵢ hᵢ). Một minh họa của quá trình được cho trong Hình 1.

Tại thời điểm test, dự đoán lớp được tính như

argmax₁≤ᵢ≤ᶜ ŷᵢ(x).                      (12)

Kết hợp dự đoán theo cách này cho phép một bỏ phiếu đa số gần đúng trên một sub-ensemble được chọn, nhưng theo cách khả vi để các tham số selection net có thể được đào tạo trực tiếp để tạo ra các lựa chọn giảm thiểu mất mát nhiệm vụ phân loại, như chi tiết trong phần tiếp theo.

4.3 Học Lựa chọn

Cơ chế smart ensemble học dự đoán lớp chính xác bằng cách học cách lựa chọn subensembles tốt hơn để bỏ phiếu trên các mẫu đầu vào của nó. Đổi lại, điều này được thực hiện bằng cách dự đoán các hệ số ĉ tốt hơn tham số hóa Knapsack Layer.

Nhiệm vụ dự đoán ĉ dựa trên đầu vào z bản thân được học bởi selection net, một mô hình mạng neural g để ĉ = g(z). Vì g hoạt động trên cùng các mẫu đầu vào như mỗi fᵢ, nó nên có khả năng xử lý đầu vào từ z ít nhất cũng tốt như các mô hình base learners; trong Phần 5, selection net trong mỗi thí nghiệm sử dụng cùng kiến trúc CNN như của các mô hình base learner. Các giá trị dự đoán của nó được xem như điểm số trên các thành viên tập hợp, thay vì trên các lớp có thể. Điểm số cao tương ứng với base learners có đủ năng lực để bỏ phiếu trên mẫu đang xét.

Trong thực tế, dự đoán ĉ của selection net được chuẩn hóa trước khi đầu vào cho ánh xạ K:

ĉ ← ĉ/||ĉ||₂.                          (13)

Điều này có tác dụng chuẩn hóa độ lớn của số hạng mục tiêu tuyến tính trong (4a), và có xu hướng cải thiện đào tạo. Vì việc chia tỷ lệ mục tiêu của một bài toán tối ưu hóa không có tác dụng đến nghiệm của nó, điều này tương đương với việc chuẩn hóa độ lớn tương đối của mục tiêu tuyến tính và nhiễu ngẫu nhiên trong Phương trình (5) và (6), ngăn τ bị hấp thụ hiệu quả vào ĉ được dự đoán.

Đối với đầu vào đào tạo x, gọi ŷ_φ(x) biểu diễn dự đoán e2e-CEL liên kết cho các tham số selection net φ. Trong quá trình đào tạo, mô hình giảm thiểu mất mát phân loại giữa những dự đoán này và các nhãn ground-truth:

min_φ E_{(x,y)~(X,Y)}[L(ŷ_φ(x), y)].     (14)

Nói chung, hàm mất mát L được chọn giống như mất mát được sử dụng để đào tạo các mô hình base learner, vì các base learners được đào tạo để thực hiện cùng một nhiệm vụ phân loại.

4.4 Chi tiết Thuật toán e2e-CEL

Thuật toán 1 tóm tắt thủ tục e2e-CEL để đào tạo một selection net. Lưu ý rằng chỉ các tham số của selection net được tối ưu hóa trong đào tạo, và vì vậy chỉ các tính toán downstream của nó được lan truyền ngược. Điều này được thực hiện bởi automatic differentiation chuẩn được sử dụng trong các thư viện học máy [Paszke et al., 2019], ngoại trừ trường hợp của Knapsack Layer, có chuyển đổi gradient được chỉ định phân tích bởi Phương trình (7).

Để rõ ràng, Thuật toán 1 được viết về các hoạt động áp dụng cho một mẫu đầu vào duy nhất. Tuy nhiên, trong thực tế, gradient descent minibatch được sử dụng. Mỗi lượt của đào tạo bắt đầu đánh giá các mô hình base learner (dòng 4) và lấy mẫu các vector nhiễu Normal chuẩn (dòng 5). Selection net dự đoán từ đặc trưng đầu vào x một vector điểm số base learner g(x), định nghĩa một bài toán knapsack không có trọng số K(g(x)) được giải để tạo ra mặt nạ nhị phân b (dòng 6). Che được áp dụng cho dự đoán base learner trước khi được tổng và softmaxed cho một dự đoán tập hợp cuối cùng ŷ (dòng 8). Mất mát phân loại L được đánh giá đối với nhãn y và lan truyền ngược trong 3 bước: (1) Gradient ∂L/∂b được tính bởi automatic differentiation lan truyền ngược đến đầu ra của Knapsack Layer (dòng 9). (2) Yếu tố quy tắc chuỗi ∂b/∂ĉ được tính phân tích bởi phương pháp của Phần 4.1 (dòng 10). (3) Yếu tố quy tắc chuỗi còn lại ∂ĉ/∂φ được tính bởi automatic differentiation (dòng 11). Lưu ý rằng khi mỗi yếu tố quy tắc chuỗi được tính, nó cũng được áp dụng hướng tính toán ∂L/∂φ (dòng 12). Cuối cùng, một bước SGD [Ruder, 2016] hoặc một trong các biến thể của nó ([Diederik và Jimmy, 2014], [Zeiler, 2012]) được áp dụng để cập nhật φ (dòng 13).

Phần tiếp theo đánh giá độ chính xác của các mô hình tập hợp được đào tạo với thuật toán này, trên các nhiệm vụ phân loại sử dụng mạng neural sâu.

5 Đánh giá e2e-CEL

Đào tạo e2e-CEL được đánh giá trên một số nhiệm vụ phân loại thị giác: phân loại chữ số trên tập dữ liệu MNIST [Deng, 2012], ước tính độ tuổi trên tập dữ liệu UTKFace [Zhifei Zhang, 2017], phân loại hình ảnh trên tập dữ liệu CIFAR10 [Krizhevsky, 2009], và phát hiện cảm xúc trên tập dữ liệu FER2013 [Liu et al., 2016].

Là một quy tắc tổng hợp được tối ưu hóa, e2e-CEL được so sánh với thuật toán Super Learner hiện đại [Ju et al., 2018] và các quy tắc tổng hợp baseline được áp dụng rộng rãi sau đây khi được ghép nối với một tập hợp được đào tạo trước:

Thuật toán 1: Đào tạo Selection Net
input: X; Y; φ; k; m; epsilon
1 for epoch = 0, 1, ··· do
2    foreach (x, y) ~ (X, Y) do
3       ŷᵢ ← fᵢ(x) ∀1 ≤ i ≤ n
4       zᵢ ~ N(0, 1)ⁿ ∀1 ≤ i ≤ m
5       (b, ĉ) ← K(g(x)), g(x)/||g(x)||₂
6       P̃ₖ ← [b, ···, b]ᵀ ⊙ [ŷ₁, ···, ŷₙ]
7       ŷ ← softmax(Σⁿᵢ₌₁ P̃ₖ⁽ⁱ⁾)
8       ∂L(ŷ, y)/∂b ← autodiff
9       ∂b/∂ĉ ← 1/m Σᵐᵢ₌₁ K(ĉ + zᵢ)∇v(zᵢ)ᵀ/τ
10      ∂ĉ/∂φ ← autodiff
11      ∂L(ŷ, y)/∂φ ← ∂L(ŷ, y)/∂b ∂b/∂ĉ ∂ĉ/∂φ
12      φ ← φ - η∇ ∂L(ŷ, y)/∂φ

• Super Learner: một mạng neural hoàn toàn được kết nối mà, cho các dự đoán của base learners, học các kết hợp có trọng số tối ưu chuyên biệt cho bất kỳ mẫu đầu vào nào.
• Unweighted Average: trung bình tất cả dự đoán softmax của base learners và sau đó tính chỉ số của điểm nhãn cao nhất tương ứng như dự đoán cuối cùng.
• Plurality Voting: đưa ra dự đoán lớp rời rạc từ mỗi base learner và sau đó trả về lớp được dự đoán nhiều nhất.
• Random Selection: lựa chọn ngẫu nhiên một sub-ensemble có kích thước k của base learners để đưa ra dự đoán và sau đó áp dụng quy tắc trung bình không có trọng số cho dự đoán mềm của base learners được chọn.

Thiết lập thí nghiệm. Như mô tả trong Phần 1 và trong Phụ lục A, các sơ đồ học tập tập hợp hiệu quả nhất khi các mô hình base learner chính xác và có sự đa dạng lỗi cao. Trong công trình này, base learners được cố ý đào tạo để có sự đa dạng lỗi cao đối với các mẫu đầu vào thuộc về các lớp khác nhau. Điều này được thực hiện bằng cách cấu thành cho mỗi mô hình base learner fᵢ (1 ≤ i ≤ n) một tập đào tạo Xᵢ trong đó một tập con của các lớp được đại diện quá mức, dẫn đến base learners chuyên về nhận dạng những lớp đó. Thành phần lớp chính xác của mỗi tập dữ liệu Xᵢ phụ thuộc vào nhiệm vụ phân loại cụ thể và vào chuyên môn dự định của base learner.

Đối với mỗi nhiệm vụ, mỗi base learners được thiết kế để chuyên về nhận dạng một hoặc hai lớp cụ thể. Để đạt được điều này, tập đào tạo của mỗi base learner được phân vùng để có đa số mẫu thuộc về một lớp cụ thể, trong khi phần còn lại của tập dữ liệu đào tạo được phân phối đều trên tất cả các lớp khác bằng lấy mẫu ngẫu nhiên. Cụ thể, để cấu thành smart ensemble cho mỗi nhiệm vụ, một base learner duy nhất được đào tạo để chuyên về mỗi lớp có thể, và về mỗi cặp lớp (ví dụ, chữ số 1 và 2 trong MNIST). Khi c là số lượng lớp, smart ensemble thí nghiệm sau đó bao gồm c + C(c,2) tổng base learners. Đào tạo một base learner chuyên biệt theo cách này thường dẫn đến độ chính xác cao trên các lớp chuyên môn của nó, nhưng độ chính xác thấp trên tất cả các lớp khác. Do đó trong thiết lập thí nghiệm này,

--- TRANG 5 ---
Độ chính xác (%)
Tập dữ liệu    Chuyên biệt    Bổ sung    Tổng thể
MNIST          97.5           86.8       89.6
UTKFACE        93.2           25.2       51.2
FER2013        79.4           38.1       47.8
CIFAR10        76.3           24.8       31.1

Bảng 1: Độ chính xác test của mô hình base learner chuyên biệt

không có base learner đơn lẻ nào có khả năng đạt được độ chính xác tổng thể cao trên tập test chủ Xtest. Đặc điểm này cũng tái diễn trong các mô hình phân tích liên bang [Kairouz et al., 2021].

Bảng 1 cho thấy độ chính xác trung bình của các mô hình base learner riêng lẻ trên các lớp chuyên môn của chúng và các lớp không chuyên môn của chúng; được báo cáo tương ứng như độ chính xác chuyên biệt và độ chính xác bổ sung. Độ chính xác tổng thể được báo cáo được đo trên toàn bộ tập test chủ Xtest. Điều này tạo tiền đề để chứng minh khả năng của đào tạo e2e-CEL cấu thành một bộ phân loại vượt trội đáng kể so với các mô hình base learner của nó trên Xtest bằng cách lựa chọn thích ứng sub-ensembles dựa trên đặc trưng đầu vào; xem Phần 5.2.

Lưu ý rằng, trong mỗi thí nghiệm, thiết kế kiến trúc của mô hình base learners, lựa chọn siêu tham số, và phương pháp đào tạo đã không được chọn để tối ưu hóa hoàn toàn độ chính xác phân loại, điều này không phải là mục tiêu trực tiếp của công trình này. Thay vào đó, base learners đã được đào tạo để tối đa hóa sự đa dạng lỗi, và chứng minh khả năng của e2e-CEL tận dụng sự đa dạng lỗi và cấu thành các mô hình tập hợp có độ chính xác cao từ các mô hình base learner có độ chính xác thấp hơn nhiều, theo cách không được chia sẻ bởi các quy tắc tổng hợp thông thường. Cũng lưu ý rằng việc cải thiện độ chính xác của mô hình base learner sẽ, tất nhiên, có xu hướng cải thiện độ chính xác của các bộ phân loại tập hợp kết quả.

Trong mỗi trường hợp, trong suốt phần này, selection net e2e-CEL được cung cấp cùng kiến trúc CNN như các mô hình base learner tạo thành tập hợp của nó.

5.1 Tập dữ liệu và Thiết lập

Đối với mỗi nhiệm vụ, các base learners được đào tạo để chuyên phân loại một hoặc hai lớp cụ thể, điều này cho phép chương trình lựa chọn tận dụng sự đa dạng lỗi của chúng. Chi tiết bổ sung về các mô hình base learners và phân chia tập dữ liệu có thể được tìm thấy trong Phụ lục B.

Phân loại chữ số. MNIST là một tập dữ liệu hình ảnh thang xám 28x28 pixel của chữ số viết tay, chứa 60000 hình ảnh để đào tạo và 10000 hình ảnh để kiểm tra. Tập hợp bao gồm 55 base learners, 10 trong số đó chuyên về 1 lớp và C(10,2) = 45 trong số đó chuyên về 2 lớp.

Phân loại hình ảnh. CIFAR10 là một tập dữ liệu hình ảnh màu 32x32 pixel trong 10 lớp: máy bay, ô tô, chim, mèo, hươu, chó, ếch, ngựa, tàu, và xe tải. Nó chứa 6000 hình ảnh của mỗi lớp. Tập hợp bao gồm 55 base learners, 10 trong số đó chuyên về 1 lớp và C(10,2) = 45 trong số đó chuyên về 2 lớp.

Ước tính tuổi. UTKFace là một tập dữ liệu hình ảnh khuôn mặt bao gồm hơn 20000 mẫu và phiên bản khác nhau của định dạng hình ảnh. Ở đây 9700 hình ảnh được cắt và căn chỉnh được chia thành 5 lớp: em bé (đến 5 tuổi), thiếu niên (từ 6 đến 19), trẻ (từ 20 đến 33), người lớn (từ 34 đến 56) và cao niên (hơn 56 tuổi). Các lớp không được phân phối đều theo số tuổi, nhưng mỗi lớp chứa cùng số lượng mẫu. Mục tiêu là ước tính tuổi của người đó cho hình ảnh khuôn mặt. Tập hợp bao gồm 15 base learners, 5 trong số đó chuyên về 1 lớp và C(5,2) = 10 về 2 lớp.

Phát hiện cảm xúc. Fer2013 là một tập dữ liệu gồm hơn 30000 hình ảnh khuôn mặt thang xám 48x48 pixel, được nhóm thành 7 lớp: tức giận, ghê tởm, sợ hãi, vui, trung tính, buồn và ngạc nhiên. Mục tiêu là phân loại cảm xúc được thể hiện trong biểu cảm khuôn mặt thành một danh mục. Tập hợp bao gồm 21 base learners, 7 trong số đó chuyên về 1 lớp và C(7,2) = 21 trong số đó chuyên về 2 lớp.

5.2 Phân tích e2e-CEL

Chiến lược e2e-CEL được thử nghiệm trên mỗi nhiệm vụ thí nghiệm cho kích thước sub-ensemble k thay đổi giữa 1 và n, và được so sánh với các phương pháp baseline được mô tả ở trên. Lưu ý trong mỗi trường hợp rằng độ chính xác được định nghĩa là tỷ lệ phần trăm của các mẫu được phân loại chính xác trên tập test chủ.

Bảng 2 báo cáo độ chính xác tốt nhất trên tất cả kích thước tập hợp k của các tập hợp được đào tạo bởi e2e-CEL cùng với của mỗi mô hình tập hợp baseline, trong đó mỗi cái được hình thành sử dụng cùng base learners được đào tạo trước. Lưu ý cách sơ đồ e2e-CEL đề xuất vượt trội hơn tất cả các phương pháp baseline, trong mỗi nhiệm vụ, cho tất cả trừ các giá trị thấp nhất của k.

Độ chính xác (%)
Tập dữ liệu    e2e-CEL    SL      UA      PV      RS
MNIST          98.55      96.88   96.81   95.99   96.83
UTKFACE        90.97      85.07   84.60   80.78   84.60
FER2013        66.31      64.95   63.89   63.15   63.89
CIFAR10        64.09      60.13   60.59   60.35   60.59

Bảng 2: e2e-CEL so với super learner (SL), unweighted average (UA), plurality voting (MV), và random selection (RS), sử dụng base learners chuyên biệt.

Hình 2 báo cáo độ chính xác test được tìm thấy bởi e2e-CEL và các tập hợp dựa trên sơ đồ Super Learner, weighted average, majority voting, hoặc random selection. Chúng tôi đưa ra hai quan sát chính: (1) Lưu ý từ mỗi subplot trong Hình 2 rằng smart ensembles có kích thước k > 1 cung cấp dự đoán chính xác hơn so với các mô hình baseline lựa chọn ngẫu nhiên sub-ensembles có cùng kích thước, một xu hướng giảm khi k tăng và việc lựa chọn base learner có hậu quả ít hơn (hai thực hiện đều bằng nhau khi k = n). (2) Trong mọi trường hợp, kích thước sub-ensemble dẫn đến hiệu suất tối ưu nằm nghiêm ngặt giữa 1 và n. Quan trọng, điều này minh họa trực giác thúc đẩy của đào tạo tập hợp e2e-CEL. Không tập hợp đầy đủ (k = n), cũng không lựa chọn thông minh của một mô hình base learner duy nhất (k = 1) có thể vượt trội hơn các mô hình sử dụng lựa chọn thông minh của một sub-ensemble có kích thước bất kỳ. Một sub-ensemble được lựa chọn tốt có tiềm năng độ chính xác cao hơn tập hợp chủ, và trung bình, đáng tin cậy hơn một base learner được lựa chọn tốt.

Tiếp theo, Bảng 3 (trái) báo cáo độ chính xác của mô hình e2e-CEL được đào tạo trên mỗi nhiệm vụ, cùng với kích thước sub-ensemble dẫn đến độ chính xác cao nhất. Trong hai trường hợp, đối với nhiệm vụ phân loại chữ số

--- TRANG 6 ---
[THIS IS FIGURE: Four graphs showing comparison between e2e-CEL and other ensemble models at varying sub-ensemble sizes for different tasks: CIFAR10 (top left), MNIST (top right), UTKFace (bottom left), and FER2013 (bottom right)]

Hình 2: So sánh giữa e2e-CEL và các mô hình tập hợp khác tại các kích thước sub-ensemble k khác nhau trên phân loại hình ảnh–CIFAR10–(trên trái), phân loại chữ số–MNIST–(trên phải), ước tính tuổi–UTKFace–(dưới trái), và phát hiện cảm xúc–FER2013–(dưới phải)
(*) trong nhãn xác định các phương pháp sử dụng quy tắc tổng hợp chuyên biệt cho mỗi mẫu đầu vào.

Độ chính xác (%)
Tập dữ liệu    Lớp    Best k    e2e-CEL    Base learners riêng lẻ
MNIST          10     10        98.55      89.6
UTKFACE        5      7         90.97      51.2
FER2013        7      13        66.31      47.8
CIFAR10        10     10        64.09      31.1

Bảng 3: Trái: Kích thước tập hợp tốt nhất (Best k) và độ chính xác test e2e-CEL liên kết đạt được trên mỗi tập dữ liệu. Phải: Độ chính xác trung bình cho các base learners tập hợp cấu thành.

và nhiệm vụ phân loại hình ảnh, e2e-CEL thực hiện tốt nhất khi kích thước sub-ensemble bằng số lượng lớp. Trong các nhiệm vụ còn lại, quan sát này đúng gần đúng. Điều này trực quan, vì số lượng base learners chuyên về bất kỳ lớp nào bằng số lượng lớp, và e2e-CEL có thể tăng độ chính xác tập hợp bằng cách học cách lựa chọn những base learners này để dự đoán.

Cuối cùng, quan sát độ chính xác của e2e-CEL trong Bảng 3 (trái) và hiệu suất của các bộ dự đoán base learners riêng lẻ của tập hợp được kiểm tra trên cả các nhãn mà đào tạo của chúng được chuyên biệt cũng như các nhãn khác. Lưu ý cách dự đoán e2e-CEL vượt trội hơn base learners cấu thành của chúng với một biên độ rộng trên mỗi nhiệm vụ. Ví dụ, trên UTKFace, tập hợp e2e-CEL đạt độ chính xác cao hơn 40 điểm phần trăm so với base learner cấu thành trung bình của nó. Điều này minh họa khả năng của e2e-CEL tận dụng sự đa dạng lỗi của base learners để hình thành bộ phân loại chính xác bằng cách cấu thành chúng dựa trên đặc trưng đầu vào, ngay cả khi độ chính xác của base learners riêng lẻ kém.

6 Kết luận

Bài báo này được thúc đẩy bởi mong muốn giải quyết những thách thức đáng kể trong lựa chọn mô hình và học tập tập hợp: việc xác định mô hình hoặc tập hợp tối ưu để phân loại bất kỳ mẫu đầu vào cụ thể nào. Giải pháp đề xuất là một khung làm việc mới cho lựa chọn mô hình khả vi được thiết kế riêng cho học tập tập hợp, tích hợp học máy và tối ưu hóa tổ hợp. Khung làm việc này được thúc đẩy bởi ý tưởng rằng các sub-ensembles được lựa chọn tốt có thể hình thành dự đoán chính xác hơn so với tập hợp gốc của chúng. Nó lựa chọn thích ứng sub-ensembles theo các mẫu đầu vào riêng lẻ.

Bài báo cho thấy cách rút ra nhiệm vụ học tập tập hợp thành một chương trình lựa chọn khả vi được đào tạo đầu cuối đến cuối trong mô hình học tập tập hợp. Phương pháp này cho phép khung làm việc đề xuất cấu thành các mô hình phân loại chính xác ngay cả từ các base learners tập hợp có độ chính xác thấp, một đặc điểm không được chia sẻ bởi các phương pháp học tập tập hợp hiện có. Kết quả trên các nhiệm vụ khác nhau chứng minh tính linh hoạt và hiệu quả của khung làm việc đề xuất, vượt trội đáng kể so với các thuật toán đồng thuận hiện đại và thông thường trong nhiều thiết lập khác nhau.

Công trình này chứng minh rằng sự tích hợp của học máy và tối ưu hóa tổ hợp là một bộ công cụ có giá trị không chỉ để tăng cường mà còn kết hợp các mô hình học máy để cải thiện hiệu suất trên các nhiệm vụ thông thường. Công trình này hy vọng thúc đẩy các giải pháp mới nơi học tập tập trung quyết định có thể được sử dụng để cải thiện khả năng của các hệ thống học máy. Khung làm việc đề xuất đóng góp vào những nỗ lực liên tục để cải thiện hiệu quả và hiệu suất của lựa chọn mô hình trong học máy, đặc biệt trong bối cảnh học tập tập hợp.

Tuyên bố Đạo đức

Trong khi phương pháp e2e-CEL đề xuất có tiềm năng cải thiện hiệu suất của học tập tập hợp, điều quan trọng là phải xem xét các tác động đạo đức của việc sử dụng nó và thực hiện các bước để giảm thiểu bất kỳ tác động tiêu cực tiềm tàng nào. Một mối quan tâm có thể là tiềm năng lựa chọn sub-ensembles theo cách có thể duy trì hoặc khuếch đại các thiên kiến có mặt trong các base learners tập hợp. Điều này có thể dẫn đến dự đoán không công bằng hoặc phân biệt đối xử đối với một số nhóm người nhất định.

Cũng quan trọng là phải xem xét lợi ích tiềm tàng của nghiên cứu này. Phương pháp này cho phép cấu thành các mô hình phân loại chính xác ngay cả từ các base learners tập hợp có độ chính xác thấp hoặc thiên kiến mạnh, đây là một đặc điểm không được chia sẻ bởi các phương pháp học tập tập hợp hiện có. Giải pháp đề xuất do đó nhằm tăng cường hiệu suất của các mô hình học tập tập hợp và có thể thúc đẩy sự phát triển của các bộ dự đoán hiệu quả hơn thể hiện ít thiên kiến hơn.

Lời cảm ơn

Nghiên cứu này được hỗ trợ một phần bởi các tài trợ NSF 2007164, 2232054, và NSF CAREER Award 2143706. Fioretto cũng được hỗ trợ bởi Amazon Research Award và Google Research Scholar Award. Quan điểm và kết luận của nó chỉ là của các tác giả.

--- TRANG 7 ---
Tuyên bố Đóng góp

James Kotary và Vincenzo Di Vito đều được coi là tác giả đầu tiên. Tất cả tác giả có đóng góp ngang nhau.

Tài liệu tham khảo

Jacob Abernethy, Chansoo Lee, và Ambuj Tewari. Pertur-
bation techniques in online learning and optimization. Per-
turbations, Optimization, and Statistics, 233, 2016.

Mokhtar S Bazaraa, John J Jarvis, và Hanis D Sherali. Lin-
ear programming and network flows. John Wiley & Sons,
2008.

Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco
Cuturi, Jean-Philippe Vert, và Francis Bach. Learning
with differentiable pertubed optimizers. Advances in neu-
ral information processing systems, 33:9508–9519, 2020.

Thomas H Cormen, Charles E Leiserson, Ronald L Rivest,
và Clifford Stein. Introduction to algorithms. MIT press,
2022.

Li Deng. The mnist database of handwritten digit images for
machine learning research [best of the web]. IEEE Signal
Processing Magazine, 29(6):141–142, 2012.

PK Diederik và B Jimmy. Adam: A method for stochastic
optimization. iclr. arXiv preprint arXiv:1412.6980, 2014.

Jérémie Dona và Patrick Gallinari. Differentiable feature se-
lection, a reparameterization approach. In Machine Learn-
ing and Knowledge Discovery in Databases. Research
Track: European Conference, ECML PKDD 2021, Bilbao,
Spain, September 13–17, 2021, Proceedings, Part III 21,
pages 414–429. Springer, 2021.

Gerald B Folland. Real analysis: modern techniques and
their applications, volume 40. John Wiley & Sons, 1999.

Jie Fu, Hongyin Luo, Jiashi Feng, Kian Hsiang Low, và Tat-
Seng Chua. Drmad: Distilling reverse-mode automatic dif-
ferentiation for optimizing hyperparameters of deep neural
networks, 2016.

Emil Julius Gumbel. Statistical theory of extreme values
and some practical applications: a series of lectures, vol-
ume 33. US Government Printing Office, 1954.

Cheng Ju, Aurélien Bibaut, và Mark van der Laan. The rel-
ative performance of ensemble methods with deep convo-
lutional neural networks for image classification. Journal
of Applied Statistics, 45(15):2800–2818, 2018.

Peter Kairouz, H. Brendan McMahan, Brendan Avent,
Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Kallista Bonawitz, Zachary Charles, Graham Cormode,
Rachel Cummings, Rafael G. L. D'Oliveira, Hubert Eich-
ner, Salim El Rouayheb, David Evans, Josh Gardner,
Zachary Garrett, Adrià Gascón, Badih Ghazi, Phillip B.
Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He,
Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu,
Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak,
Jakub Konečný, Aleksandra Korolova, Farinaz Koushan-
far, Sanmi Koyejo, Tancrède Lepoint, Yang Liu, Prateek

Mittal, Mehryar Mohri, Richard Nock, Ayfer Özgür, Ras-
mus Pagh, Hang Qi, Daniel Ramage, Ramesh Raskar,
Mariana Raykova, Dawn Song, Weikang Song, Sebas-
tian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian
Tramèr, Praneeth Vepakomma, Jianyu Wang, Li Xiong,
Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, và Sen
Zhao. Advances and open problems in federated learn-
ing. Foundations and Trends® in Machine Learning,
14(1–2):1–210, 2021.

James Kotary, Vincenzo Di Vito, và Ferdinando Fioretto.
End-to-end optimization and learning for multiagent en-
sembles, 2022.

Alex Krizhevsky. Learning multiple layers of features from
tiny images. 2009.

Kuang Liu, Mingmin Zhang, và Zhigeng Pan. Facial expres-
sion recognition with cnn ensemble. In 2016 International
Conference on Cyberworlds (CW), pages 163–166, 2016.

Ibomoiye Domor Mienye và Yanxia Sun. A survey of en-
semble learning: Concepts, algorithms, applications, and
prospects. IEEE Access, 10:99129–99149, 2022.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer,
James Bradbury, Gregory Chanan, Trevor Killeen, Zeming
Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison,
Andreas Kopf, Edward Yang, Zachary DeVito, Martin Rai-
son, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, và Soumith Chintala. Pytorch: An
imperative style, high-performance deep learning library.
In Advances in Neural Information Processing Systems 32,
pages 8024–8035. Curran Associates, Inc., 2019.

Mauro Ribeiro, Katarina Grolinger, và Miriam A.M.
Capretz. Mlaas: Machine learning as a service. In 2015
IEEE 14th International Conference on Machine Learning
and Applications (ICMLA), pages 896–902, 2015.

Sebastian Ruder. An overview of gradient descent optimiza-
tion algorithms. arXiv preprint arXiv:1609.04747, 2016.

Rishit Sheth và Nicolò Fusi. Differentiable feature selection
by discrete relaxation. In International Conference on Arti-
ficial Intelligence and Statistics, pages 1564–1572. PMLR,
2020.

Bryan Wilder, Bistra Dilkina, và Milind Tambe. Melding
the data-decisions pipeline: Decision-focused learning for
combinatorial optimization. In AAAI, volume 33, pages
1658–1665, 2019.

Ian H Witten, Eibe Frank, Mark A Hall, Christopher J Pal,
và MINING DATA. Practical machine learning tools and
techniques. In Data Mining, volume 2, 2005.

Matthew D Zeiler. Adadelta: an adaptive learning rate
method. arXiv preprint arXiv:1212.5701, 2012.

Hairong Qi Zhifei Zhang, Yang Song. Age progres-
sion/regression by conditional adversarial autoencoder. In
IEEE Conference on Computer Vision and Pattern Recog-
nition (CVPR). IEEE, 2017.

--- TRANG 8 ---
A Công trình Liên quan

Bài báo này đề xuất một khung làm việc để cấu thành các mô hình học tập tập hợp hiệu quả bằng cách thích ứng các kỹ thuật từ giao điểm của tối ưu hóa có ràng buộc và học máy. Phần này tóm tắt ngắn gọn hai lĩnh vực tách biệt:

Học tập tập hợp. Một số công trình đã tập trung vào nghiên cứu các mô hình tập hợp cho học máy hiệu quả hơn. Chúng tôi giới thiệu người đọc đến ? để có một phân loại hữu ích của các phương pháp tập hợp, tùy thuộc vào nhiệm vụ học máy cơ bản cần được giải quyết.

Học tập tập hợp thường bao gồm hai khía cạnh riêng biệt: (1) đào tạo các base learners học tập tập hợp riêng lẻ, và (2) tổng hợp các đầu ra riêng lẻ của chúng thành dự đoán tập hợp chính xác. Khía cạnh trước liên quan đến việc cấu thành một tập hợp từ các base learners với các profile lỗi bổ sung, và thường được xử lý bởi bagging, bao gồm việc cấu thành ngẫu nhiên các tập dữ liệu để đào tạo mỗi thành viên tập hợp, và boosting, bao gồm việc tạo thích ứng một chuỗi tập dữ liệu dựa trên phân phối lỗi của các mô hình kết quả của chúng để sự đa dạng lỗi được tăng lên. Nhiều biến thể và các lựa chọn thay thế dành riêng cho nhiệm vụ cũng đã được đề xuất ?. Ví dụ, ? nghiên cứu tác động của các kỹ thuật cắt tỉa khác nhau để giảm kích thước tập hợp từ một tập hợp bagging ban đầu. Một khảo sát tập trung vào đào tạo các base learners tập hợp riêng lẻ được cung cấp trong Mienye and Sun [2022].

Khía cạnh sau thường được xử lý bởi các quy tắc tổng hợp cổ điển trên các dự đoán lớp rời rạc hoặc các giá trị kích hoạt liên tục của các thành viên tập hợp. Bỏ phiếu đa số và số đông là các tiêu chí đồng thuận để chọn một dự đoán lớp rời rạc dựa trên phổ biến nhất trong các thành viên tập hợp. Một số công trình đã cố gắng mô hình hóa toán học các quy tắc tổng hợp hiệu quả hơn: bao gồm super-learners Ju et al. [2018], cố gắng hình thành một sự kết hợp có trọng số của các mô hình base learner tối đa hóa độ chính xác trên một tập validation.

Học tập tập trung quyết định. Một khối công trình đã được dành cho việc nghiên cứu các bài toán tối ưu hóa có ràng buộc như các thành phần có thể học được trong mạng neural. Xem ví dụ khảo sát gần đây của ?. Như một ánh xạ giữa một số tham số định nghĩa bài toán và các nghiệm tối ưu của chúng, một bài toán tối ưu hóa có thể được xem như một hàm có đầu ra tuân thủ các ràng buộc được định nghĩa rõ ràng. Theo cách này, cấu trúc đặc biệt có thể được đảm bảo trong các dự đoán ? hoặc embeddings được học của một mạng neural ?. Thách thức chính là việc vi phân của ánh xạ tối ưu hóa được yêu cầu để lan truyền ngược. Các phương pháp riêng biệt đã được đề xuất, phụ thuộc vào các xấp xỉ khác nhau, tùy thuộc vào dạng của bài toán tối ưu hóa ?, ?, và ?. Các bài toán lồi trơn, đặc biệt, thừa nhận gradient chính xác thông qua các phương trình tối ưu được định nghĩa tốt của chúng, như được chỉ ra bởi ? và ?. Các bài toán lồi định nghĩa ánh xạ hằng từng đoạn, chẳng hạn như chương trình tuyến tính, đòi hỏi xấp xỉ bởi các bài toán trơn trước khi vi phân. Các kỹ thuật làm trơn thường được áp dụng cho hàm mục tiêu và bao gồm việc thêm các số hạng mục tiêu chính quy hóa, như được đề xuất bởi Wilder et al. [2019], và nhiễu ngẫu nhiên, như trong Berthet et al. [2020].

Ký hiệu    Nghĩa
n          Kích thước của tập hợp
k          Kích thước của một sub-ensemble
m          Số lượng mẫu nhiễu cho perturbed optimizer
fᵢ         Bộ phân loại được đào tạo trước, 1 ≤ i ≤ n
ŷᵢ         Dự đoán softmax từ fᵢ
f          Bộ phân loại tập hợp thông minh
ŷ          Dự đoán softmax tập hợp thông minh
g          Selection net
φ          Tham số selection net
ĉ          Điểm số dự đoán từ selection net
K          Hàm knapsack không có trọng số
K̄          Hàm knapsack không có trọng số bị nhiễu
X          Dữ liệu đặc trưng đầu vào
Y          Dữ liệu lớp mục tiêu
L          Hàm mất mát phân loại

Bảng 4: Các ký hiệu thông dụng

Trong bài báo này, dự đoán có cấu trúc mong muốn chủ yếu có dạng của một vector nhị phân biểu diễn lựa chọn tập con, trong đó k < n trong số n mục được chỉ định để lựa chọn. Công trình này khai thác thực tế rằng vi phân của cấu trúc này như một chương trình tuyến tính đối với một vector tham số hóa cho phép nó được áp dụng trong một sơ đồ che khả vi đầu cuối đến cuối được sử dụng để lựa chọn và kết hợp dự đoán của base learners tập hợp tốt nhất cho một mẫu đầu vào nhất định.

B Tập dữ liệu và thiết lập

Phần này cung cấp thông tin về kiến trúc mô hình base learner và thành phần tập dữ liệu đào tạo cho mỗi nhiệm vụ.

Phân loại chữ số. Ở đây các base learners sử dụng mạng neural tích chập (CNN), mỗi cái có cùng kiến trúc: 2 lớp tích chập và 3 lớp tuyến tính. Trong các lớp tích chập, của 10 và 20 kênh đầu ra tương ứng, thông tin được xử lý sử dụng bộ lọc kernel vuông có kích thước 5x5. Tập dữ liệu đào tạo của mỗi base learner được cấu thành, trung bình, bởi 73.2% mẫu thuộc về một (hoặc hai) lớp cụ thể, trong khi phần còn lại được phân phối đều trên tất cả các lớp khác bằng lấy mẫu ngẫu nhiên. Trung bình, điều này dẫn đến 97.5% độ chính xác trong việc phân loại một tập con cụ thể của các mẫu đào tạo và 86.8% độ chính xác trong việc phân loại tập con bổ sung của các mẫu đào tạo.

Phân loại hình ảnh
Ở đây các base learners sử dụng các mô hình CNN, mỗi cái có cùng kiến trúc, 2 lớp tích chập, mỗi lớp chứa bộ lọc kernel vuông có kích thước 5, với 6 và 16 kênh đầu ra tương ứng, và 3 lớp tuyến tính. Trung bình, tập dữ liệu đào tạo của mỗi base learner được cấu thành bởi 55.2% mẫu thuộc về một (hoặc hai) lớp cụ thể, trong khi phần còn lại được phân phối đều trên tất cả các lớp khác bằng lấy mẫu ngẫu nhiên. Điều này dẫn đến 76.3% độ chính xác để phân loại một tập con cụ thể của các mẫu đào tạo và 24.8% độ chính xác để phân loại tập con bổ sung của các mẫu đào tạo.

Ước tính tuổi. Ở đây kiến trúc mô hình base learner là một phiên bản được đào tạo trước của Resnet18 trên tập dữ liệu ImageNet-1k, được đào tạo lại hoàn toàn. Trung bình, tập dữ liệu đào tạo của mỗi base learner được cấu thành bởi 58.3% mẫu thuộc về một (hoặc hai) lớp cụ thể, trong khi phần còn lại được phân phối đều trên tất cả các lớp khác bằng lấy mẫu ngẫu nhiên. Điều này dẫn đến 93.2% độ chính xác để phân loại một tập con cụ thể của các mẫu đào tạo và 25.2% độ chính xác để phân loại tập con bổ sung của các mẫu đào tạo.

Phát hiện cảm xúc. Ở đây kiến trúc mô hình base learner bao gồm 8 lớp tích chập và một lớp tuyến tính. Đối với mỗi lớp tích chập, số lượng kênh đầu ra là 64; 128; 128; 128; 256; 512; 512 và 512; mỗi lớp sử dụng kernel vuông có kích thước 3x3. Tập dữ liệu đào tạo của mỗi base learner được cấu thành bởi 44.4% mẫu thuộc về một (hoặc hai) lớp cụ thể, trong khi phần còn lại được phân phối đều trên tất cả các lớp khác bằng lấy mẫu ngẫu nhiên. Điều này dẫn đến 79.4% độ chính xác để phân loại một tập con cụ thể của các mẫu đào tạo và 38.1% độ chính xác để phân loại tập con bổ sung của các mẫu đào tạo.

--- TRANG 9 ---
C Siêu tham số

C.1 Siêu tham số của việc đào tạo mô hình base learners

Ở đây cho mỗi nhiệm vụ, chi tiết bổ sung về các siêu tham số của việc đào tạo mô hình base learners được cung cấp.

Tập dữ liệu    Optimizer    Scheduler      Learning rate    Gamma    Epochs    Loss function
MNIST          Adadelta     StepLR         1               0.9      14        Cross entropy
UTKFACE        Adadelta     StepLR         1               0.9      10        Cross entropy
FER2013        Adam         OneCycleLR     0.001                    70        Cross entropy
CIFAR10        SGD                         0.001                    3         Cross entropy

C.2 Siêu tham số của việc đào tạo mô hình selection net

Ở đây, cho mỗi nhiệm vụ, chi tiết bổ sung về các siêu tham số của việc đào tạo mô hình selection net được cung cấp. Chúng tôi nhắc lại rằng cho mỗi nhiệm vụ, mô hình selection net chia sẻ cùng kiến trúc của mô hình base learner tương ứng.

Optimizer    Scheduler      Learning rate    Gamma    Epochs    Loss function
MNIST        Adadelta                       1                  8         Cross entropy
UTKFACE      Adadelta                       1                  10        Cross entropy
FER2013      Adam          OneCycleLR      0.001              20        Cross entropy
CIFAR10      Adadelta                      0.001              3         Cross entropy

--- TRANG 10 ---

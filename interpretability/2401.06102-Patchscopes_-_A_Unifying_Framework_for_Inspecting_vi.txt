# Patchscopes: Khung Công Tác Thống Nhất để Kiểm Tra Biểu Diễn Ẩn của Mô Hình Ngôn Ngữ

**Asma Ghandeharioun* 1 Avi Caciularu* 1 Adam Pearce1 Lucas Dixon1 Mor Geva1 2**

## Tóm tắt

Hiểu được các biểu diễn nội bộ của các mô hình ngôn ngữ lớn (LLM) có thể giúp giải thích hành vi của mô hình và xác minh sự phù hợp của chúng với các giá trị con người. Với khả năng tạo ra văn bản con người có thể hiểu được của LLM, chúng tôi đề xuất tận dụng chính mô hình để giải thích các biểu diễn nội bộ của nó bằng ngôn ngữ tự nhiên. Chúng tôi giới thiệu một khung công tác gọi là **Patchscopes** và cho thấy cách nó có thể được sử dụng để trả lời một loạt rộng các câu hỏi về tính toán của LLM. Chúng tôi chỉ ra rằng nhiều phương pháp diễn giải trước đây dựa trên việc chiếu biểu diễn vào không gian từ vựng và can thiệp vào tính toán LLM có thể được xem như các thể hiện của khung công tác này. Hơn nữa, một số thiếu sót của chúng như thất bại trong việc kiểm tra các lớp sớm hoặc thiếu biểu cảm có thể được giảm thiểu bởi **Patchscopes**. Ngoài việc thống nhất các kỹ thuật kiểm tra trước đây, **Patchscopes** cũng mở ra những khả năng mới như sử dụng một mô hình có khả năng hơn để giải thích các biểu diễn của một mô hình nhỏ hơn, và sửa lỗi lý luận đa bước.

## 1. Giới thiệu

Câu hỏi về thông tin nào được nắm bắt trong các biểu diễn ẩn của các mô hình ngôn ngữ lớn (LLM) có tầm quan trọng then chốt trong việc kiểm soát và hiểu AI tạo sinh hiện đại, và đã thu hút sự chú ý đáng kể gần đây (Casper et al., 2022; Madsen et al., 2022; Patel & Pavlick, 2021; Nanda et al., 2023). Để giải quyết câu hỏi này, các nghiên cứu trước đây đã giới thiệu một loạt đa dạng các phương pháp diễn giải, chủ yếu dựa vào ba cách tiếp cận nổi bật: huấn luyện các bộ phân loại tuyến tính, gọi là probe, trên các biểu diễn ẩn (Belinkov & Glass, 2019; Belinkov, 2022; Alain & Bengio, 2017), chiếu các biểu diễn vào không gian từ vựng của mô hình (nostalgebraist, 2020; Din et al., 2023; Belrose et al., 2023), và can thiệp vào tính toán để xác định liệu một biểu diễn có quan trọng cho các dự đoán nhất định hay không (Meng et al., 2022a; Wallat et al., 2020; Wang et al., 2022; Conmy et al., 2023; Geva et al., 2023).

*Đóng góp bằng nhau 1Google Research 2Tel Aviv University. Liên hệ: Asma Ghandeharioun <aghandeharioun@google.com>.

Proceedings of the 41st International Conference on Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the author(s).

1Code công khai có sẵn tại https://pair-code.github.io/interpretability/patchscopes.

[THIS IS FIGURE: Hình 1 minh họa khung công tác của chúng tôi, cho thấy một Patchscope để giải mã biểu diễn ẩn của "CEO" trong prompt nguồn (trái). Chúng tôi sử dụng một prompt đích (phải) bao gồm các minh chứng few-shot của việc lặp lại chuỗi để khuyến khích LLM giải thích biểu diễn nội bộ của nó.]

Mặc dù thành công rộng rãi của các phương pháp này, mỗi phương pháp đều thể hiện những thiếu sót thực tế. Thứ nhất, probing dựa vào việc huấn luyện có giám sát cho các lớp được định nghĩa trước, điều này khó mở rộng khi có số lượng lớn các lớp hoặc khi tất cả các danh mục không được biết trước. Thứ hai, độ chính xác của việc chiếu từ vựng giảm đáng kể ở các lớp sớm và các đầu ra thường khó diễn giải. Cuối cùng, tất cả các phương pháp trên không biểu cảm như người ta mong muốn: chúng cung cấp xác suất lớp hoặc token có khả năng nhất, thay vì một lời giải thích chất lượng cao bằng ngôn ngữ tự nhiên.

Trong nghiên cứu này, chúng tôi lập luận rằng các khả năng tiên tiến của LLM trong việc tạo ra văn bản giống con người có thể được tận dụng để "dịch" thông tin trong các biểu diễn của chúng cho con người. Chúng tôi giới thiệu một khung công tác modular, gọi là **Patchscopes** (§3), có thể được cấu hình để truy vấn các loại thông tin khác nhau từ các biểu diễn LLM. **Patchscopes** giải mã thông tin cụ thể từ một biểu diễn trong LLM bằng cách "vá" nó vào quá trình suy luận trên một prompt khác đã được thiết kế để khuyến khích việc trích xuất thông tin đó. Cấu hình như vậy (một **Patchscope**) có thể được xem như một công cụ kiểm tra hướng tới một mục tiêu cụ thể, như được minh họa trong Hình 1.

Chúng tôi chỉ ra rằng nhiều phương pháp hiện có, bao gồm những phương pháp dựa vào việc chiếu từ vựng và can thiệp tính toán, có thể được coi như **Patchscopes**. Hơn nữa, các cấu hình mới của khung công tác chúng tôi giới thiệu các công cụ hiệu quả hơn trong việc giải quyết cùng những câu hỏi, đồng thời giảm thiểu một số hạn chế của các cách tiếp cận trước đây. Ngoài ra, **Patchscopes** cho phép giải quyết các câu hỏi chưa được khám phá đầy đủ, chẳng hạn như phân tích chi tiết về quá trình ngữ cảnh hóa đầu vào và mức độ mà một mô hình biểu cảm hơn có thể được sử dụng để kiểm tra các biểu diễn ẩn của một mô hình nhỏ hơn.

Chúng tôi tiến hành một loạt thí nghiệm để đánh giá các lợi ích và cơ hội được giới thiệu bởi **Patchscopes**, tập trung vào các LLM tự hồi quy. Đầu tiên, chúng tôi xem xét vấn đề ước tính dự đoán token tiếp theo của mô hình từ các biểu diễn trung gian của nó (xem §4.1). Trên nhiều LLM, chúng tôi chỉ ra rằng việc sử dụng prompt nhận dạng token few-shot, một prompt có dạng "tok1→tok1; tok2→tok2; ...; tokk" với toki đề cập đến một token ngẫu nhiên, dẫn đến cải thiện đáng kể so với các phương pháp chiếu từ vựng. Tiếp theo, chúng tôi đánh giá mức độ **Patchscopes** có thể giải mã các thuộc tính cụ thể của một thực thể từ các biểu diễn LLM của nó, khi những biểu diễn này được tách rời khỏi ngữ cảnh gốc (xem §4.2). Chúng tôi quan sát thấy rằng, mặc dù không sử dụng dữ liệu huấn luyện, **Patchscopes** vượt trội đáng kể so với probing trong sáu trong số mười hai nhiệm vụ lý luận thường thức và thực tế, và hoạt động tương đương tốt trong tất cả trừ một trong số sáu nhiệm vụ còn lại.

Ngoài ước tính đầu ra và giải mã thuộc tính, **Patchscopes** có thể giải quyết các câu hỏi khó trả lời với các phương pháp hiện có. Trong §4.3, chúng tôi áp dụng **Patchscopes** để nghiên cứu cách LLM ngữ cảnh hóa tên thực thể đầu vào trong các lớp sớm, nơi việc chiếu từ vựng chủ yếu thất bại và các phương pháp khác, trong trường hợp tốt nhất, chỉ cung cấp tín hiệu nhị phân về việc liệu thực thể đã được giải quyết hay chưa (Youssef et al., 2023; Tenney et al., 2019). Với một **Patchscope** mới, chúng tôi có thể diễn đạt quá trình giải quyết thực thể dần dần. Ví dụ, chúng tôi chỉ ra rằng, khi mô hình xử lý token cuối cùng của "Alexander the Great" qua các lớp, nó phản ánh các thực thể khác nhau bắt đầu từ "Great Britain", đến "the Great Depression", để cuối cùng giải quyết "Alexander the Great". Sau đó, trong §4.4 chúng tôi chỉ ra cách có thể cải thiện thêm tính biểu cảm của **Patchscope** bằng cách sử dụng một mô hình đích mạnh hơn, ví dụ Vicuna 13B thay vì Vicuna 7B.

Cuối cùng, chúng tôi trình bày tính hữu ích của **Patchscopes** để sửa các lỗi lý luận đa bước tiềm ẩn, đặc biệt khi mô hình có khả năng thực hiện mỗi bước lý luận một cách chính xác, nhưng thất bại khi chúng cần được kết hợp trong ngữ cảnh (§5). Xây dựng trên dữ liệu được cung cấp bởi Hernandez et al. (2023b), chúng tôi giới thiệu một nhiệm vụ phức tạp hơn đòi hỏi hai bước lý luận thực tế. **Patchscope** đạt được độ chính xác 50% trên nhiệm vụ này, vượt trội hơn chain-of-thought (Wei et al., 2022) (35.71%) và các thế hệ vanilla (19.57%).

Để kết luận, nghiên cứu của chúng tôi đóng góp những điều sau:

Chúng tôi đề xuất **Patchscopes**, một khung công tác modular tổng quát để giải mã thông tin từ các biểu diễn ẩn trong LLM. Chúng tôi chỉ ra rằng các phương pháp diễn giải nổi bật có thể được xem như các thể hiện của **Patchscopes**, và các cấu hình mới dẫn đến các lựa chọn thay thế biểu cảm hơn, mạnh mẽ hơn qua các lớp, và không cần dữ liệu huấn luyện để giảm thiểu các thiếu sót của chúng. Ngoài ra, các cấu hình mới giới thiệu các khả năng chưa được khám phá của các kỹ thuật kiểm tra mạnh hơn, cũng như các lợi ích thực tế, chẳng hạn như sửa lỗi lý luận đa bước.

## 2. Nghiên cứu liên quan

Activation patching là một can thiệp nhân quả, thường được sử dụng như một công cụ để nghiên cứu liệu các activation nhất định có đóng vai trò then chốt trong tính toán của mô hình hay không (Geiger et al., 2021; Vig et al., 2020). Patching đã được sử dụng chủ yếu để định vị thông tin cụ thể đến các lớp và vị trí token cụ thể (Goldowsky-Dill et al., 2023; Meng et al., 2022a;b; Stolfo et al., 2023; Merullo et al., 2023), và để tìm các đường dẫn truyền thông tin trong tính toán (Wang et al., 2022; Geva et al., 2023; Hendel et al., 2023; Hanna et al., 2023; Lieberum et al., 2023). Các nghiên cứu trước đây cũng đã sử dụng các dạng cụ thể của cross-model patching gọi là stitching, trong các kiến trúc không phải transformer, chủ yếu để phân tích sự tương tự biểu diễn (ví dụ, Bansal et al., 2021; Csiszárik et al., 2021; Lenc & Vedaldi, 2015). Mặc dù có một số hạn chế (Hase et al., 2023; Zhang & Nanda, 2023), patching vẫn là một công cụ chính cho diễn giải cơ học (Conmy et al., 2023).

Với các kết quả đầy hứa hẹn từ các nỗ lực diễn giải mới nổi sử dụng LLM để tạo ra văn bản giống con người cho việc kiểm tra (ví dụ, Mousi et al., 2023; Slobodkin et al., 2023; Bills et al., 2023), chúng tôi lập luận rằng việc sử dụng patching chỉ cho mục đích định vị là thiển cận, và đề xuất sử dụng nó để "dịch" các biểu diễn LLM thành ngôn ngữ tự nhiên.

Gần đây, patching đã được sử dụng để nghiên cứu các thiết lập vấn đề mới (ví dụ, Pal et al., 2023; Hernandez et al., 2023b), tất cả đều có thể được xem như các cấu hình khác nhau của khung công tác đề xuất của chúng tôi (xem §3.2).

Trong số các nỗ lực nghiên cứu ngày càng tăng trong việc kiểm tra các biểu diễn ẩn của mạng nơ-ron, các bộ phân loại probing có lẽ là phổ biến nhất (ví dụ, Alain & Bengio, 2017; Belinkov & Glass, 2019; Belinkov, 2022; Wang et al., 2023), và các phương pháp sử dụng chiếu vào không gian từ vựng hoặc các mở rộng của chúng sang các miền khác là một danh mục quan trọng khác (ví dụ, Merullo et al., 2023; Geva et al., 2022b; nostalgebraist, 2020; Belrose et al., 2023; Dar et al., 2023; Din et al., 2023; Langedijk et al., 2023; Vilas et al., 2023). Trong khi tồn tại nhiều phương pháp kiểm tra tiềm ẩn khác (ví dụ, Zhou et al., 2018; Strobelt et al., 2017; Ghandeharioun et al., 2021; Kim et al., 2018), những phương pháp trên là có liên quan nhất đến nghiên cứu này.

## 3. Patchscopes

Trong phần này, chúng tôi giới thiệu **Patchscopes** và chỉ ra cách nó mở rộng các phương pháp diễn giải trước đây với các khả năng mới. Mặc dù không giới hạn ở các kiến trúc LLM cụ thể, nghiên cứu này tập trung vào các LLM dựa trên transformer tự hồi quy.

### 3.1. Mô tả Khung công tác

Ý tưởng chính trong **Patchscopes** là tận dụng các khả năng tiên tiến của LLM để tạo ra văn bản giống con người cho việc "dịch" thông tin được mã hóa trong các biểu diễn ẩn của chính chúng. Cụ thể, với một biểu diễn ẩn thu được từ một lượt suy luận LLM, chúng tôi đề xuất giải mã thông tin cụ thể từ nó bằng cách vá nó vào một lượt suy luận khác (của cùng một LLM hoặc LLM khác) khuyến khích việc dịch thông tin cụ thể đó.

Đáng chú ý, phần còn lại của tính toán tiến về phía trước sau khi vá có thể bổ sung thêm thông tin cho biểu diễn, do đó, cách tiếp cận này không đảm bảo rằng bản thân biểu diễn đã vá lưu trữ tất cả thông tin đó. Tuy nhiên, việc gửi biểu diễn ra khỏi ngữ cảnh gốc của nó (prompt nguồn) dừng việc ngữ cảnh hóa và đảm bảo rằng không có thông tin thêm nào từ prompt nguồn được kết hợp trong tính toán sau khi vá. Do đó, khung công tác của chúng tôi tiết lộ liệu thông tin cụ thể có thể được giải mã từ biểu diễn đã vá thông qua tính toán sau khi vá hay không.

Cho một chuỗi đầu vào n token S=⟨s1, ..., sn⟩ và một mô hình M với L lớp, hℓi biểu thị biểu diễn ẩn thu được tại lớp ℓ∈[1, ..., L] và vị trí i∈[1, ..., n], khi chạy M trên S. Để kiểm tra hℓi, chúng tôi xem xét một lượt suy luận riêng biệt của một mô hình M* với L* lớp trên một chuỗi đích T=⟨t1, ..., tm⟩ gồm m token. Cụ thể, chúng tôi chọn một biểu diễn ẩn h̄ℓ*i* tại lớp ℓ*∈[1, ..., L*] và vị trí i*∈[1, ..., m] trong việc thực thi M* trên T. Hơn nữa, chúng tôi định nghĩa một hàm ánh xạ f(h;θ) : Rd ↦ Rd* được tham số hóa bởi θ hoạt động trên các biểu diễn ẩn của M, trong đó d và d* biểu thị chiều ẩn của các biểu diễn trong M và M*, tương ứng. Hàm này có thể là hàm đồng nhất, một hàm tuyến tính hoặc affine được học trên các cặp biểu diễn cụ thể của nhiệm vụ, hoặc thậm chí các hàm phức tạp hơn kết hợp các nguồn dữ liệu khác. Phép toán vá đề cập đến việc thay thế động biểu diễn h̄ℓ*i* trong quá trình suy luận của M* trên T bằng f(hℓi). Cụ thể, bằng cách áp dụng h̄ℓ*i* ← f(hℓi), chúng tôi can thiệp vào quá trình tạo sinh và sửa đổi tính toán sau lớp ℓ*.

Tổng thể, một can thiệp **Patchscope** được áp dụng cho một biểu diễn được xác định bởi (S, i, M, ℓ), được định nghĩa bởi một bộ năm (T, i*, f, M*, ℓ*) gồm một prompt đích T, một vị trí đích i* trong prompt này, một hàm ánh xạ f, một mô hình đích M*, và một lớp đích ℓ* của mô hình này. Có thể M và M* là cùng một mô hình, S và T là cùng một prompt, và f là hàm đồng nhất I (tức là, I(h) = h). Tiếp theo, chúng tôi chỉ ra cách công thức này bao gồm các phương pháp diễn giải trước đây và mở rộng thêm chúng với các khả năng mới.

### 3.2. Patchscopes Bao gồm Các Phương pháp Trước đây

Nhiều phương pháp gần đây kiểm tra các biểu diễn LLM bằng cách chiếu chúng vào không gian từ vựng đầu ra (nostalgebraist, 2020; Din et al., 2023; Belrose et al., 2023). Chính thức, một ước tính của phân phối đầu ra được thu được từ biểu diễn hℓi tại vị trí i và lớp ℓ bằng:

pℓi = softmax(WUf(hℓi)) ∈ R|V|,

trong đó WU ∈ R|V|×d là ma trận unembedding của mô hình và f là một hàm ánh xạ đơn giản, chẳng hạn như hàm đồng nhất hoặc một ánh xạ affine. Chúng tôi lưu ý rằng phép toán được áp dụng cho f(hℓi) là cùng một tính toán được áp dụng bởi mô hình cho biểu diễn lớp cuối để có được dự đoán token tiếp theo. Do đó, các phương pháp trước đây kiểm tra các biểu diễn trong không gian từ vựng có thể được xem như một lớp **Patchscopes** ánh xạ các biểu diễn từ bất kỳ lớp nguồn ℓ nào đến lớp đích cuối L*. Sự khác biệt giữa các phương pháp này nằm ở việc lựa chọn f; logit lens (nostalgebraist, 2020; Dar et al., 2023) áp dụng hàm đồng nhất, linear shortcuts (Din et al., 2023) sử dụng một hàm ánh xạ tuyến tính, và tuned lens (Belrose et al., 2023) huấn luyện một ánh xạ affine. Gần đây, Hernandez et al. (2023b) đã giới thiệu LRE Attribute Lens xây dựng f dựa trên một giả định tuyến tính quan hệ, và cho thấy hiệu quả của nó trong trích xuất thuộc tính.

Lớp phương pháp này đã được chứng minh là hiệu quả cho các ứng dụng khác nhau, ví dụ, trong việc cải thiện hiệu quả suy luận thông qua early exiting (Din et al., 2023). Trong khi phần lớn các phương pháp và ứng dụng trong danh mục này sử dụng một mô hình duy nhất (M*=M), Merullo et al. (2022) đã chứng minh việc tạo caption thành công với một mô hình hình ảnh tạo sinh làm M và một mô hình ngôn ngữ làm M*.

Một danh mục khác của các phương pháp kiểm tra can thiệp vào tính toán LLM. Đương thời với nghiên cứu của chúng tôi, Pal et al. (2023) đã điều tra liệu có thể dự đoán nhiều token được tạo ra phía trước từ một biểu diễn ẩn cho trước hay không, thay vì chỉ ước tính dự đoán token tiếp theo. Phương pháp của họ (Future Lens) sử dụng một prompt đích khác với prompt gốc (tức là, T≠S) và được thiết kế để giải mã các token tiếp theo từ thông tin được mã hóa trong một biểu diễn ẩn hℓi. Các prompt đích ví dụ là "The multi-tokens present here are" và "Hello! Could you please tell me more about". Future Lens có thể được coi là một **Patchscope** khác với M*=M và ℓ*=ℓ.

Rộng hơn, **Patchscopes** cũng bao gồm các phương pháp diễn giải cơ học gần đây phân tích các quá trình nội bộ trong LLM với các can thiệp tính toán suy luận. Cụ thể, causal tracing (Meng et al., 2022a) sử dụng một prompt nguồn được bổ sung nhiễu Gaussian làm prompt đích. Các phương pháp trước đây khác đã can thiệp vào một hoặc nhiều lớp đích trong quá trình suy luận bằng cách vá các vector zero vào tính toán (Wang et al., 2022; Conmy et al., 2023; Geva et al., 2023), cụ thể là, đặt f(h) = 0. Để xem tóm tắt cấu hình về cách các phương pháp diễn giải này có thể được coi như các thể hiện **Patchscope**, xem §A, Tab. 4.

### 3.3. Patchscopes Cho phép Các Phương pháp Kiểm tra Mới

Nghiên cứu trước đây đã sử dụng các cấu hình vá cụ thể cho diễn giải, chủ yếu vá cùng một mô hình trong khi sử dụng cùng một prompt (tức là, M*=M, T=S). Việc đóng khung **Patchscopes** giới thiệu một loạt rộng các thiết lập chưa được khám phá có khả năng mở khóa các khả năng kiểm tra mới.

Cụ thể, chúng tôi quan sát thấy rằng việc sửa đổi prompt đích cho phép giải mã biểu cảm của một loạt rộng các đặc trưng, tách rời khỏi tính toán prompt nguồn. Ví dụ, chúng ta có thể sử dụng prompt "The capital of X is" để kiểm tra liệu thủ đô của một quốc gia cho trước có thể trích xuất được từ biểu diễn ẩn (token cuối) của nó tại một lớp cụ thể hay không. Tương tự, một prompt như "Tell me facts about X" có thể được tận dụng để đánh giá liệu mô hình đã giải quyết tên thực thể trong một lớp cụ thể hay chưa. Trái ngược với probing, cách tiếp cận này không bị hạn chế bởi số lượng lớp của đặc trưng được chọn.

Hơn nữa, khi mô hình được kiểm tra không đủ biểu cảm để trả lời các truy vấn nhất định, việc vá các biểu diễn vào một mô hình có khả năng hơn có thể hữu ích (Hernandez et al., 2022; Singh et al., 2023; Schwettmann et al., 2023).

## 4. Thí nghiệm

Trong phần này, chúng tôi đánh giá khung công tác của chúng tôi trên việc giải mã dự đoán token tiếp theo (§4.1), trích xuất thuộc tính (§4.2), phân tích việc ngữ cảnh hóa tên thực thể (§4.3), và tận dụng các mô hình mạnh hơn để kiểm tra thông qua cross-model patching (§4.4). Xem tóm tắt trong Tab. 1.

### 4.1. Giải mã Dự đoán Token Tiếp theo

Như được giới thiệu trong §3.2, gọi pL là phân phối xác suất đầu ra cho một đầu vào nào đó, thu được bằng cách nhân biểu diễn ẩn vị trí cuối lớp cuối hL với ma trận unembedding WU ∈ R|V|×d. Chúng tôi muốn ước tính pL từ các biểu diễn trung gian hℓ sao cho ℓ < L. Đặc biệt, chúng tôi hỏi mô hình đã kết luận dự đoán cuối cùng của nó từ ngữ cảnh cho trước sớm như thế nào trong tính toán. Trong các thí nghiệm của chúng tôi, chúng tôi xem xét nhiều LLM – LLaMA2 (13B) (Touvron et al., 2023b), Vicuna (13B) (Chiang et al., 2023), GPT-J (6B) (Wang & Komatsuzaki, 2021), và Pythia (12B) (Biderman et al., 2023) (xem thêm chi tiết trong §B.1).

**Phương pháp** Chúng tôi so sánh các phương pháp chiếu từ vựng (§3.2) với một **Patchscope** mới. Mỗi phương pháp tạo ra một xác suất đầu ra ước tính p̃ℓ bằng cách vá một biểu diễn trung gian hℓ vào lớp cuối của mô hình. Ở đây, chúng tôi tập trung vào thiết lập phổ biến trong đó M=M*, và thảo luận về các mở rộng đến M≠M* trong §4.4.

• **Logit Lens**: Theo nghiên cứu trước đây (nostalgebraist, 2020; Geva et al., 2022a), chúng tôi định nghĩa f là hàm đồng nhất, có nghĩa là không có thay đổi nào được áp dụng cho biểu diễn đã vá. Tức là, f(h) := I(h).

• **Tuned Lens**: Được thúc đẩy bởi Belrose et al. (2023); Din et al. (2023), chúng tôi sử dụng một hàm ánh xạ affine giữa các biểu diễn tại lớp ℓ và lớp cuối L. Cụ thể, chúng tôi cung cấp cho mô hình các ví dụ từ một tập huấn luyện T và cho mỗi ví dụ s∈T thu được một cặp (hℓs, hLs) của các biểu diễn ẩn. Sau đó, chúng tôi khớp một mô hình hồi quy tuyến tính để tìm ma trận Aℓ ∈ Rd×d và vector bias bℓ ∈ Rd là các bộ tối thiểu hóa số cho ∑s∈T||Ahℓs - hLs + b||2. Chúng tôi định nghĩa f là: f(hℓ) := Aℓhℓ + bℓ.

• **Token Identity Patchscope**: Không giống như các phương pháp trước đây, ở đây chúng tôi sử dụng một prompt đích khác với prompt nguồn (T≠S) và được thiết kế để khuyến khích giải mã nhận dạng token của biểu diễn ẩn. Ngoài ra, trong khi các phương pháp trên bỏ qua tính toán giữa các lớp l và L, ở đây chúng tôi sửa đổi nó sao cho tất cả thông tin từ tính toán prompt nguồn được loại bỏ, ngoại trừ biểu diễn đã vá. Chúng tôi tạo ra một prompt với k minh chứng biểu diễn một hàm giống đồng nhất, được định dạng là "tok1→tok1; tok2→tok2; ...; tokk". Xem §B.3 để biết thêm chi tiết và một thí nghiệm cho thấy tính mạnh mẽ của phương pháp này đối với các minh chứng khác nhau. Lưu ý rằng **Patchscope** này không yêu cầu bất kỳ huấn luyện nào.

**Đánh giá** Theo Din et al. (2023), chúng tôi sử dụng tập đánh giá Pile và các metric sau (xem chi tiết trong §B.2):

• **Precision@1** (↑ là tốt hơn): Phần các ví dụ mà token có xác suất cao nhất t trong phân phối xác suất ước tính khớp với token có xác suất cao nhất trong phân phối đầu ra gốc. Tức là, nếu argmaxt(p̃ℓt) = argmaxt(pLt).

• **Surprisal** (↓ là tốt hơn): Âm log-xác suất của token có xác suất cao nhất trong phân phối dự đoán p̃ℓ theo pL, tức là, -logpLt̃, trong đó t̃ = argmaxt(p̃ℓt).

**Kết quả** Trên tất cả các mô hình, từ lớp 10 trở lên, **Patchscope** nhận dạng token luôn vượt trội hơn các baseline khác, đạt được cải thiện lên đến 98% trong các lớp 18-22 (xem Hình 2). Điều này chứng minh tính hữu ích của việc tận dụng quy trình giải mã của mô hình để kiểm tra các biểu diễn của các prompt nguồn khác nhau, và cho thấy rằng trong hầu hết các trường hợp, các biểu diễn ẩn trong các lớp sớm mang thông tin dự đoán bất kể ngữ cảnh của chúng.

Trong 10 lớp đầu tiên, hiệu suất của tất cả các phương pháp đều bị giảm, với prompt nhận dạng token hoạt động ngang bằng với logit lens, và tuned lens hoạt động hơi tốt hơn, có thể do việc huấn luyện bổ sung các ánh xạ của nó. Hiệu suất thấp trong các lớp này là dự kiến, vì đây là nơi việc ngữ cảnh hóa đầu vào xảy ra. Trong §4.3, chúng tôi giới thiệu một **Patchscope** hướng tới việc làm sáng tỏ quá trình này.

### 4.2. Trích xuất Thuộc tính Cụ thể

Các probe phân loại có lẽ là phương pháp được sử dụng phổ biến nhất để kiểm tra liệu các thuộc tính nhất định có được mã hóa trong các biểu diễn ẩn hay không (Belinkov, 2022; Belinkov & Glass, 2019). Tuy nhiên, chúng cần được huấn luyện, và phạm vi các lớp thuộc tính cần được biết trước. Ở đây chúng tôi chỉ ra rằng việc tái sử dụng **Patchscopes** để trích xuất thuộc tính vượt qua những hạn chế này. Thứ nhất, nó không yêu cầu huấn luyện. Thứ hai, nó không bị giới hạn bởi một tập nhãn được định nghĩa trước, mà thay vào đó hưởng lợi từ một từ vựng mở. Ngoài ra, bằng cách tận dụng các tính phi tuyến của mô hình, nó có thể nắm bắt các quan hệ phức tạp hơn so với các probe tuyến tính.

**Thiết lập Thí nghiệm** Xem xét kiến thức thực tế và thường thức được biểu diễn dưới dạng các bộ ba (σ, ρ, ω) của một chủ thể (ví dụ, "United States"), một quan hệ (ví dụ, "largest city of"), và một đối tượng (ví dụ, "New York City"). Chúng tôi điều tra mức độ đối tượng ω có thể được trích xuất từ biểu diễn token cuối của chủ thể σ trong một ngữ cảnh đầu vào tùy ý. Để làm điều này, chúng tôi tiến hành thí nghiệm trên 8 nhiệm vụ kiến thức thường thức và 25 nhiệm vụ kiến thức thực tế được tuyển chọn bởi Hernandez et al. (2023b). Bộ dữ liệu này bao gồm các bộ ba (σ, ρ, ω) cho các quan hệ khác nhau, cùng với các mẫu prompt diễn đạt chúng bằng ngôn ngữ tự nhiên. Chúng tôi tiến hành thí nghiệm với GPT-J (6B) (Wang & Komatsuzaki, 2021), lọc dữ liệu để chỉ giữ lại các ví dụ mà ω xuất hiện trong phần tiếp tục của mô hình đối với prompt lên đến 20 token. Việc lựa chọn 20 cân bằng chi phí tính toán với việc chứa đựng bản chất mở của **Patchscopes**, vì token ground truth không nhất thiết xuất hiện trong token tiếp theo ngay lập tức trong một phản hồi trôi chảy. Đối với mỗi ví dụ, chúng tôi lấy mẫu 5 phát ngôn từ bộ dữ liệu WikiText-103 (Merity et al., 2016) bao gồm σ và sử dụng chúng làm S. Cuối cùng, chúng tôi giữ lại các nhiệm vụ có ít nhất 15 mẫu, dẫn đến 5 nhiệm vụ thường thức và 7 nhiệm vụ thực tế với tổng cộng 1,453 điểm dữ liệu. Xem chi tiết trong §C.

**Phương pháp** Chúng tôi so sánh **Patchscope** đề xuất của chúng tôi với linear probing (Köhn, 2015; Gupta et al., 2015).

• **Zero-shot Feature Extraction Patchscope**: Chúng tôi tạo T như một diễn đạt tổng quát của ρ theo sau bởi một placeholder cho σ, sao cho i*=m. Ví dụ, chúng tôi sử dụng T←"The largest city in x" với "x" là placeholder cho chủ thể. Để trích xuất đối tượng từ biểu diễn thực thể trong S, chúng tôi vá biểu diễn của token "x" tại lớp ℓ* với biểu diễn của "States" từ lớp ℓ, và xem xét liệu văn bản được tạo ra có bao gồm ω hay không. Các cấu hình còn lại của **Patchscope** này là f←I, M*←M, i←token cuối của σ trong S. Chúng tôi xem xét tất cả các kết hợp của ℓ∈[1, ..., L]×ℓ*∈[1, ..., L*]. Sau đó trong phần này, chúng tôi thảo luận về vai trò của ℓ liên quan đến trích xuất thuộc tính.

• **Logistic Regression Probe**: Gọi Ω biểu diễn phạm vi các đối tượng có thể có cho một quan hệ cho trước. Chúng tôi sử dụng tập các giá trị duy nhất của ω trong tập huấn luyện làm proxy cho Ω. Chúng tôi huấn luyện một probe hồi quy logistic (Köhn, 2015; Gupta et al., 2015) cho mỗi lớp dự đoán ω∈Ω từ biểu diễn token cuối của σ. Cho rằng 6 trong số 12 nhiệm vụ có ít hơn 40 điểm dữ liệu, chúng tôi sử dụng cross-validation ba lần để huấn luyện và đánh giá baseline này. Lưu ý rằng chúng tôi đã loại trừ các nhiệm vụ mà probe thất bại hoàn toàn do số lượng ví dụ huấn luyện không đủ (ít hơn 15 điểm dữ liệu).

**Đánh giá** Chúng tôi đo độ chính xác trích xuất thuộc tính trung bình. Đối với một mẫu cho trước, **Patchscope** được coi là chính xác nếu ∃ℓ*∈[1, ..., L*] mà văn bản được tạo ra lên đến 20 token bao gồm ω. Đối với probe, một dự đoán là chính xác nếu xác suất cao nhất được gán cho ω.

**Kết quả** Tab. 2 tóm tắt kết quả, được tính trung bình trên ℓ∈[1, ..., L]. Chúng tôi tiến hành T-test với hiệu chỉnh Bonferroni để so sánh hai phương pháp. Mặc dù không sử dụng dữ liệu huấn luyện và không có hạn chế về đầu ra, **Patchscope** đạt được độ chính xác cao hơn đáng kể so với probe trên sáu trong số mười hai nhiệm vụ (p<1e-5), và hoạt động tương đương tốt trong tất cả trừ một trong số sáu nhiệm vụ còn lại. Những kết quả này cho thấy rằng, trong phần lớn các trường hợp, biểu diễn nguồn mà không có ngữ cảnh gốc của nó mang đủ thông tin về nhiều thuộc tính mà một **Patchscope** có mục tiêu có thể trích xuất. Chúng tôi cũng nghiên cứu cách độ chính xác thay đổi qua các lớp nguồn, và quan sát thấy rằng **Patchscope** luôn vượt trội hơn baseline trong các lớp sớm, vượt trội hoặc hoạt động ngang bằng với baseline trong các lớp giữa, và hầu như tất cả các trường hợp mà nó hoạt động tệ hơn baseline xảy ra trong các lớp sau. Cách diễn giải của chúng tôi là với mục tiêu huấn luyện mô hình hóa ngôn ngữ, các biểu diễn chuyển hướng tới dự đoán token tiếp theo trong các lớp sau. Do đó, thuộc tính quan tâm sẽ không dễ dàng tiếp cận thông qua tính toán của mô hình trong các lớp này. Cách diễn giải này cũng phù hợp với các phát hiện gần đây cho thấy không có sự suy giảm trong việc sử dụng linear relational embedding trong việc dự đoán ω chỉ khi token tiếp theo cũng tình cờ là ω (Hernandez et al., 2023b). Lưu ý rằng mẫu này giải thích độ lệch chuẩn cao hơn của độ chính xác **Patchscope** được quan sát trong Tab. 2. Chúng tôi thảo luận hiện tượng này chi tiết hơn trong §C (xem Hình 6).

### 4.3. Phân tích Giải quyết Thực thể trong Các Lớp Sớm

Các phần trước tập trung vào việc phân tích thông tin được mã hóa trong một trạng thái ẩn duy nhất. Ở đây chúng tôi chuyển sang xem xét một câu hỏi toàn cục hơn về cách LLM giải quyết các đề cập thực thể qua nhiều lớp. Cụ thể, với một tên thực thể chủ thể, chẳng hạn như "the summer Olympics of 1996", mô hình ngữ cảnh hóa các token đầu vào của thực thể như thế nào và tại lớp nào nó được giải quyết hoàn toàn?

Trả lời những câu hỏi này khó khăn với các phương pháp hiện có; các chiếu từ vựng tập trung vào dự đoán đầu ra và thất bại trong việc hiển thị các mẫu rõ ràng trong các lớp sớm, và probing bị hạn chế bởi các đầu ra từ một số lượng lớp cố định, có thể không đủ biểu cảm để mô tả quá trình này. Các cách tiếp cận thay thế đã nghiên cứu quá trình này một cách gián tiếp thông qua can thiệp (Meng et al., 2022a), cho thấy rằng mô hình xây dựng một biểu diễn chủ thể tại token cuối của tên thực thể. Tuy nhiên, vẫn chưa rõ cách việc ngữ cảnh hóa này được thực hiện.

Chúng tôi phân tích cách LLM ngữ cảnh hóa tên thực thể đầu vào bằng cách tận dụng **Patchscopes**. Đặc biệt, chúng tôi tạo ra một prompt đích để tạo ra mô tả của một chủ thể cho trước, và áp dụng nó cho biểu diễn ẩn tại vị trí chủ thể cuối trong prompt nguồn – nơi mô hình hình thành biểu diễn chủ thể (Geva et al., 2023; Hernandez et al., 2023a) – qua các lớp sớm. Điều này sẽ cho phép chúng ta thấy mô hình mô tả chủ thể như thế nào trong mỗi lớp.

**Thiết lập Phân tích** Chúng tôi sử dụng một mẫu prompt đích few-shot để giải mã mô tả thực thể: "subject1: description1, ..., subjectk: descriptionk, x", trong khi vá vị trí cuối tương ứng với x. Chúng tôi lấy 200 thực thể chủ thể phổ biến nhất và 200 thực thể ít phổ biến nhất từ bộ dữ liệu PopQA (Mallen et al., 2023). Các thực thể phổ biến nên xuất hiện thường xuyên trong dữ liệu tiền huấn luyện của LLM, và do đó có khả năng được mô hình nắm bắt, trong khi việc giải quyết các thực thể hiếm dự kiến sẽ thách thức hơn (Kandpal et al., 2023; Mallen et al., 2023). Sau đó, đối với prompt nguồn chúng tôi sử dụng tên thực thể, và đối với prompt đích chúng tôi lấy mẫu k=3 thực thể chủ thể ngẫu nhiên. Chúng tôi thu được một mô tả ngắn (lên đến một câu) của mỗi thực thể chủ thể từ Wikipedia. Prompt đích và các chi tiết kỹ thuật khác được cung cấp trong §D.1. Chúng tôi vá các biểu diễn vị trí cuối từ 10 lớp đầu tiên của Vicuna 13B vào prompt đích và đánh giá tên chủ thể và mô tả được tạo ra. Cụ thể, các mô tả được tạo ra được đánh giá so với các mô tả từ Wikipedia sử dụng RougeL (Lin, 2004). Đánh giá với Rouge1 (Lin, 2004) và Sentence-Bert (Reimers & Gurevych, 2019) cho thấy các xu hướng tương tự (xem §D.2).

**Kết quả** Tab. 3 minh họa các thế hệ bởi Vicuna 13B cho một thực thể chủ thể mẫu, khi vá biểu diễn của nó tại các lớp khác nhau vào prompt đích (xem thêm ví dụ trong §D.3). Đối với hầu hết các thực thể, quá trình ngữ cảnh hóa được lan tỏa qua các lớp đầu tiên, với token chủ thể cuối dần dần bao gồm các vị trí xa hơn qua các lớp. Xu hướng này có thể được quan sát định lượng bằng sự tương tự giữa các mô tả được tạo ra và các mô tả từ Wikipedia, được đo bằng RougeL. Xem Hình 3 trong đó M=M*. Đối với cả hai mô hình, sự tương tự tăng trong 5 lớp đầu tiên và sau đó từ từ giảm. Sự giảm này có thể được quy cho ô nhiễm do biểu diễn của token placeholder "x" còn lại trong các lớp sớm, khi việc vá được áp dụng cho một lớp sau. Lưu ý rằng vấn đề tiềm ẩn này chỉ áp dụng cho các tình huống tạo ra đa token vì các vị trí tương lai vẫn có thể chú ý đến vị trí placeholder trong các lớp sớm, có khả năng can thiệp vào khả năng của mô hình trong việc tạo ra các mô tả chính xác cho token đã vá. Xem §D.3 để xem các ví dụ định tính hỗ trợ cách diễn giải này. Như mong đợi, điểm số cho các thực thể hiếm, long-tail thấp hơn đáng kể so với các thực thể phổ biến. Xem §D.2 để biết thêm kết quả với Pythia trong đó mô hình nhỏ hơn dường như vượt trội hơn mô hình lớn hơn, có thể vì mô hình lớn hơn thiên vị tới tạo ra đầu ra với chi phí của việc ngữ cảnh hóa đầu vào.

Để tóm tắt, phân tích này cho thấy tính hữu ích của **Patchscopes** để kiểm tra quá trình ngữ cảnh hóa trong các lớp sớm.

### 4.4. Tính Biểu cảm từ Cross-Model Patching

Một con đường có thể để cải thiện khả năng kiểm tra là giải thích một mô hình cho trước với một mô hình biểu cảm hơn (Bills et al., 2023). Trong **Patchscopes**, điều này có nghĩa là vá một biểu diễn của M vào một mô hình biểu cảm hơn M*. Tuy nhiên, không rõ liệu can thiệp như vậy có mang lại kết quả hợp lý hay không, do các sự khác biệt có thể có giữa hai mô hình phát sinh từ các kiến trúc, quá trình tối ưu hóa khác nhau, v.v. Ở đây, chúng tôi trình bày các thí nghiệm về dự đoán token tiếp theo và giải quyết thực thể minh họa không chỉ tính khả thi, mà còn các cơ hội được mở khóa bởi việc vá qua các mô hình của cùng một họ.

**Dự đoán Token Tiếp theo** Chúng tôi lặp lại thí nghiệm trong §4.1, sử dụng **Patchscope** nhận dạng token. Để vượt qua các sự khác biệt giữa các mô hình, chúng tôi học các ánh xạ affine giữa các lớp của chúng (tương tự như Tuned Lens). Kết quả của chúng tôi cho thấy rằng các lớp nguồn và đích trên đường chéo thể hiện các giá trị precision cao nhất, và việc vá các biểu diễn vào một lớp sớm của mô hình lớn hơn là hiệu quả nhất. Tổng thể, gợi ý rằng khi M* và M từ cùng một họ mô hình, có thể tận dụng M* để giải mã thông tin từ các biểu diễn của M. Để biết kết quả chi tiết về Precision@1 và Surprisal, xem §E.

**Giải quyết Thực thể trong Các Lớp Sớm** Bây giờ chúng tôi chỉ ra rằng việc sử dụng một mô hình lớn làm M* có thể tăng cường tính biểu cảm đầu ra. Để làm điều này, chúng tôi lặp lại thí nghiệm giải quyết thực thể trong §4.3 với họ mô hình Vicuna, đặt M←7B, M*←13B. Hình 3 cho thấy kết quả cross-model patching (đường màu xanh lá cây) so với same-model patching M←7B, M*←7B (đường màu xanh dương). Kết quả cho thấy rằng cross-model patching từ một mô hình nhỏ hơn đến phiên bản lớn hơn của nó thường cải thiện khả năng kiểm tra việc ngữ cảnh hóa đầu vào, cả cho các thực thể phổ biến và hiếm. Đối với Pythia, vì mô hình nhỏ hơn vượt trội hơn mô hình lớn hơn, cross-model patching không hiệu quả bằng (xem §D.2).

## 5. Ứng dụng: Sửa lỗi Đa bước

Lý luận đa bước là một vấn đề thách thức (Zhong et al., 2023). Trong khi một mô hình ngôn ngữ có thể có khả năng trả lời chính xác từng bước một cách độc lập, nó vẫn có thể thất bại trong việc xử lý kết nối giữa các bước khác nhau, dẫn đến một dự đoán không chính xác. Các nỗ lực gần đây để cải thiện lý luận đa bước dựa vào việc thúc đẩy mô hình tạo ra một câu trả lời từng bước một cách tự hồi quy (ví dụ, Wei et al., 2022; Yao et al., 2023; Besta et al., 2024), một số với một quá trình lặp đi lặp lại của tự tinh chỉnh (ví dụ, Madaan et al., 2023). Tuy nhiên, việc đạt được các lợi ích tương tự có thể có thể thông qua việc rewiring trực tiếp tính toán trung gian của mô hình.

Ở đây, chúng tôi chỉ ra rằng **Patchscopes** có thể cải thiện hiệu suất lý luận đa bước mà không tạo ra các bước lý luận, đặc biệt trong các trường hợp mà mô hình thất bại trong việc hoàn thành một truy vấn đa bước mặc dù thành công trong từng bước lý luận một cách độc lập. Thông qua **Patchscopes**, người ta có thể thao tác phẫu thuật trên các biểu diễn mô hình, định tuyến lại câu trả lời trung gian của nó cho một bước lý luận, đơn giản hóa bước tiếp theo, và cuối cùng sửa dự đoán cuối cùng.

**Dữ liệu** Xây dựng trên Hernandez et al. (2023b), chúng tôi tạo ra có hệ thống tất cả các truy vấn lý luận thực tế và thường thức đa bước hợp lệ trong đó ω1=σ2. Chúng tôi tiến hành thí nghiệm trên Vicuna (13B), tập trung vào các mẫu mà M mã hóa chính xác cả τ1 và τ2 một cách độc lập, tức là, ω xuất hiện trong 20 token tiếp theo mà M tạo ra có điều kiện trên prompt π diễn đạt σ và ρ. Quá trình này tạo ra 1,104 mẫu lý luận đa bước, trong đó 46 thỏa mãn các tiêu chí trên và được sử dụng để đánh giá. Xem thêm chi tiết trong §F.

**Thiết lập Thí nghiệm** Theo ký hiệu trong §4.2, gọi τ1=(σ1, ρ1, ω1) biểu diễn quan hệ ρ1 giữa một thực thể chủ thể σ1 và một thực thể đối tượng ω1. Gọi τ2=(σ2, ρ2, ω2) biểu diễn một tuple khác sao cho σ2=ω1. Một truy vấn lý luận đa bước liên quan đến τ1 và τ2 là một prompt bao gồm hai phần: π1 là một diễn đạt của σ1 và ρ1 từ đó ω1 có thể được suy ra; π2 là một diễn đạt của ρ2, từ đó ω2 có thể được suy ra sau khi kết hợp với π1. Ví dụ, Gọi τ1←("Visual Basic", "product of", "Microsoft") và τ2←("Microsoft", "company CEO", "Satya Nadella"). Một ví dụ diễn đạt của những tuple này là π1←"the company that created Visual Basic", π2←"The current CEO of", dẫn đến truy vấn đa bước [π2][π1] = "The current CEO of the company that created Visual Basic".

**Phương pháp** Chúng tôi giới thiệu một **Patchscope** Chain-of-Thought (CoT) để sửa lý luận đa bước thông qua can thiệp vào đồ thị tính toán và định tuyến lại biểu diễn có khả năng nắm bắt ω1 thay cho σ2. Cụ thể, S đề cập đến truy vấn được hình thành thảo luận ở trên, và chúng tôi sử dụng cấu hình sau: T←S, M*←M, i←n, i*←token đứng trước π1. Chúng tôi đánh giá các đầu ra về độ chính xác, tương tự như §4.2. Đối với một mẫu S, **Patchscope** được coi là chính xác nếu ∃(ℓ, ℓ*): ℓ∈[1, ..., L], ℓ*∈[1, ..., L*] mà việc tạo ra tự hồi quy lên đến 20 token bao gồm ω2. Hình 4 minh họa **Patchscope** CoT với một ví dụ.

Chúng tôi sử dụng cấu hình sau cho **Patchscope** CoT: S←π1, T←π2, i←n, i*←m, tương đương với S=T←[π2][π1] và điều chỉnh attention mask sao cho không có token nào trong S có thể nhìn thấy π2 và không có token nào trong T có thể nhìn thấy π1. Ngoài ra, chúng tôi xem xét hai baseline.

**Baseline Vanilla** Đối với baseline này, chúng tôi đặt S←[π1][π2], chúng tôi để mô hình tạo ra tự hồi quy lên đến 20 token và kiểm tra liệu ω2 có xuất hiện trong thế hệ hay không.

**Baseline Chain-of-Thought** Ở đây, thiết lập và đánh giá tương tự như baseline vanilla, ngoại trừ chúng tôi thêm vào đầu "Let's think step by step." vào S, theo (Wei et al., 2022). Sau đó chúng tôi để mô hình tạo ra lên đến 20 token và kiểm tra liệu ω2 có xuất hiện trong thế hệ hay không. Lưu ý rằng thí nghiệm này sử dụng Vicuna (13B). Vicuna dựa trên LLaMA, với supervised finetuning trên dữ liệu hướng dẫn bổ sung, làm cho nó phù hợp với chain-of-thought prompting.

**Kết quả** Trong khi độ chính xác baseline vanilla chỉ là 19.57%, và độ chính xác baseline CoT là 35.71%, **Patchscope** đề xuất của chúng tôi đạt được độ chính xác 50%. Để biết thêm chi tiết về tương tác giữa ℓ và ℓ*, và cách nó ảnh hưởng đến tỷ lệ thành công, xem Hình 12 trong §F.

Chúng tôi nhấn mạnh rằng mục tiêu chính của chúng tôi trong phần này không phải là thiết kế một phương pháp mới để giải quyết các truy vấn đa bước nhất thiết là một đối thủ cạnh tranh với CoT, mà là tạo ra một proof-of-concept trong khi so sánh với CoT như một tham chiếu chung. Chúng tôi nhấn mạnh rằng chúng tôi đã tận dụng thông tin cấu trúc bổ sung về các truy vấn do kiến thức trước về cách chúng được tổng hợp. Người ta có thể tự động hóa điều này bằng cách học các vị trí đúng để vá. Li et al. (2024) gần đây đã đề xuất một cách tiếp cận dựa trên tối ưu hóa để vá trực tiếp multi-head self-attention trong các lớp giữa, có thể được xem như lựa chọn vị trí mềm, và hoạt động hiệu quả trong sửa lỗi multihop, gợi ý rằng việc suy ra các vị trí đúng để vá có thể hiệu quả. Tuy nhiên, ngay cả khi vị trí nguồn và đích tối ưu được tự động quyết định trước, **Patchscope** và CoT có thể không so sánh trực tiếp được. CoT tạo ra nhiều bước về cơ bản mở rộng sức mạnh tính toán của LLM (Merrill & Sabharwal, 2024), nhưng một **Patchscope** với (l, l*) được xác định trước chỉ thực hiện O(1) lượt suy luận.

## 6. Kết luận

Chúng tôi trình bày **Patchscopes**, một khung công tác đơn giản và hiệu quả tận dụng khả năng của LLM tạo ra văn bản giống con người để giải mã thông tin từ các biểu diễn LLM trung gian. Chúng tôi chỉ ra rằng nhiều phương pháp diễn giải hiện có có thể được coi như các thể hiện **Patchscope** cụ thể, và ngay cả những phương pháp này chỉ bao gồm một phần nhỏ của các cấu hình có thể có của khung công tác. Hơn nữa, các **Patchscopes** chưa được khám phá mới cải thiện đáng kể khả năng giải mã các loại thông tin khác nhau từ tính toán nội bộ của mô hình, chẳng hạn như dự đoán đầu ra và thuộc tính kiến thức, thường vượt trội hơn các phương pháp nổi bật dựa vào chiếu vào từ vựng và probing. Ngoài ra, khung công tác của chúng tôi cho phép các khả năng mới, chẳng hạn như phân tích quá trình ngữ cảnh hóa của các token đầu vào trong các lớp LLM sớm, và có thể sửa lý luận đa bước.

Có nhiều hướng nghiên cứu tương lai để xem xét. Một yếu tố quan trọng trong hiệu quả của một prompt đích được chọn là cách thông tin từ vị trí đã vá lan truyền trong quá trình suy luận đến các vị trí khác và qua các lớp. Hiểu cách sử dụng tốt nhất một prompt đích cho trước, có lẽ tự động, là một yếu tố quan trọng để sử dụng **Patchscopes**. Một con đường khác cho nghiên cứu tương lai là điều tra hiệu quả của các prompt đích few-shot so với các prompt zero-shot/dựa trên hướng dẫn. Các prompt đích dựa trên hướng dẫn biểu cảm hơn, ví dụ, có thể cho phép trích xuất thông tin phức tạp hơn. Ngoài ra, trong khi cross-model patching của chúng tôi tập trung vào các mô hình từ cùng một họ, sẽ có giá trị để khám phá các hàm ánh xạ nào sẽ cho phép vá qua các mô hình từ các họ khác nhau và có lẽ với các kiến trúc khác nhau. Các hướng khác cho nghiên cứu tương lai bao gồm các ứng dụng qua các miền và modality khác nhau, điều tra các biến thể với việc vá đồng thời đa token hoặc đa lớp để giảm thiểu rủi ro ô nhiễm placeholder, và trình bày các công thức cho **Patchscopes** cụ thể nhiệm vụ và bất khả tri nhiệm vụ.

## Lời cảm ơn

Chúng tôi cảm ơn Amir Globerson vì phản hồi về việc viết và trình bày kết quả. Chúng tôi cảm ơn Ardavan Saeedi, Martin Wattenberg, Ellie Pavlick, nhóm AI Explorables tại Google Research, và Jasmijn Bastings vì những bình luận hữu ích của họ.

## Tuyên bố Tác động

**Tác động Xã hội** Bài báo này trình bày một khung công tác mới để diễn giải các biểu diễn ẩn của các mô hình ngôn ngữ lớn. Các phương pháp diễn giải nói chung có thể được sử dụng để điều tra độ tin cậy và an toàn của mô hình trước khi triển khai. Chúng tôi hy vọng rằng khung công tác **Patchscopes** tạo điều kiện cho tiến bộ trong lĩnh vực này với việc giới thiệu các công cụ kiểm tra biểu cảm hơn, mạnh mẽ hơn qua các lớp, và không yêu cầu dữ liệu huấn luyện.

**Hạn chế** Trong khi khung công tác đề xuất của chúng tôi không giới hạn ở bất kỳ kiến trúc hoặc miền cụ thể nào, bằng chứng thực nghiệm được cung cấp trong bài báo này tập trung vào các mô hình ngôn ngữ dựa trên Transformer tự hồi quy, và nghiên cứu tương lai cần thiết để xác minh hiệu quả của nó trong các thiết lập khác.

## Tài liệu tham khảo

[Phần tài liệu tham khảo giữ nguyên định dạng gốc với tất cả các citation]

---

## A. Cấu hình Chi tiết của Các Phương pháp Trước đây như Các Thể hiện Patchscope

[Phần phụ lục A tiếp tục với cùng cấu trúc và nội dung chi tiết như bản gốc...]

[Tiếp tục với tất cả các phần phụ lục B, C, D, E, F, G với cùng cấu trúc và nội dung chi tiết...]

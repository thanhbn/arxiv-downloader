# 2308.07201.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl-papers/2308.07201.pdf
# Kích thước tệp: 780002 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
CHATEVAL: HƯỚNG TỚI CÁC TRÌNH ĐÁNH GIÁ DẠI LLM TỐT HƠN THÔNG QUA TRANH LUẬN ĐA TÁC TỬ

Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Zhiyuan Liu∗
Khoa Khoa học và Công nghệ Máy tính
Đại học Thanh Hoa
zorowin123@gmail.com
Jie Fu, Wei Xue
Đại học Khoa học và Công nghệ Hồng Kông
Shanghang Zhang
Đại học Bắc Kinh

TÓM TẮT
Đánh giá văn bản từ lâu đã đặt ra những thách thức đáng kể, thường đòi hỏi chi phí lao động và thời gian đáng kể. Với sự xuất hiện của các mô hình ngôn ngữ lớn (LLM), các nhà nghiên cứu đã khám phá tiềm năng của LLM như các lựa chọn thay thế cho đánh giá của con người. Mặc dù các phương pháp dựa trên tác tử đơn này cho thấy triển vọng, kết quả thực nghiệm cho thấy rằng cần có những tiến bộ hơn nữa để thu hẹp khoảng cách giữa hiệu quả hiện tại của chúng và chất lượng đánh giá ở mức độ con người. Nhận thức rằng các thực hành tốt nhất của quy trình đánh giá của con người thường bao gồm nhiều người chú thích hợp tác trong đánh giá, chúng tôi chuyển sang một khung tranh luận đa tác tử, vượt ra ngoài các chiến lược nhắc nhở tác tử đơn. Phương pháp dựa trên đa tác tử cho phép một nhóm LLM hợp tác với một loạt các đối tác thông minh, khai thác các khả năng và chuyên môn riêng biệt của họ để nâng cao hiệu quả và hiệu suất trong việc xử lý các nhiệm vụ phức tạp. Trong bài báo này, chúng tôi xây dựng một đội trọng tài đa tác tử có tên ChatEval để tự động thảo luận và đánh giá chất lượng của các phản hồi được tạo ra từ các mô hình khác nhau về các câu hỏi mở và các nhiệm vụ tạo ngôn ngữ tự nhiên truyền thống (NLG). Chúng tôi rút ra những hiểu biết và bài học từ các tình huống thực tế nơi con người khởi xướng các cuộc thảo luận nhóm để động não và đề xuất các chiến lược giao tiếp khác nhau trong ChatEval. Các thí nghiệm của chúng tôi trên hai nhiệm vụ chuẩn minh họa rằng ChatEval mang lại độ chính xác và tương quan vượt trội phù hợp với đánh giá của con người. Hơn nữa, chúng tôi thấy rằng các nhắc nhở vai trò đa dạng (các nhân vật khác nhau) là thiết yếu trong quá trình tranh luận đa tác tử; nghĩa là, sử dụng cùng một mô tả vai trò trong nhắc nhở có thể dẫn đến sự suy giảm hiệu suất. Phân tích định tính của chúng tôi cũng cho thấy rằng ChatEval vượt xa việc chấm điểm văn bản thuần túy, cung cấp một quy trình đánh giá bắt chước con người để có các đánh giá đáng tin cậy. Mã của chúng tôi có sẵn tại https://github.com/chanchimin/ChatEval.

1 GIỚI THIỆU
Đánh giá chất lượng văn bản được tạo ra bởi các mô hình ngôn ngữ hoặc được viết bởi con người từ lâu đã là một nỗ lực đầy thách thức, liên tục thu hút sự chú ý đáng kể (Celikyilmaz et al., 2020). Các phương pháp truyền thống chủ yếu dựa vào chú thích của con người đối với văn bản (Callison-Burch, 2009), một phương pháp được coi là quá đòi hỏi về thời gian và chi phí. Các chỉ số đánh giá tự động dựa trên n-gram, chẳng hạn như Rouge (Lin, 2004), BLEU (Papineni et al., 2002), và METEOR (Banerjee & Lavie, 2005), đã được đề xuất để giải quyết vấn đề này (Kondrak, 2005). Tuy nhiên, các phương pháp này đã được chỉ ra là có tương quan tương đối yếu với các đánh giá của con người, đặc biệt là trong bối cảnh các nhiệm vụ liên quan đến việc tạo ra mở hoặc đòi hỏi chuyên môn cụ thể về lĩnh vực (Novikova et al., 2017).

Những tiến bộ gần đây trong lĩnh vực xử lý ngôn ngữ tự nhiên đã dẫn đến sự xuất hiện của các LLM quy mô hàng tỷ tham số, chẳng hạn như GPT-3 (Brown et al., 2020). Các LLM này đã thể hiện khả năng đáng chú ý trên các nhiệm vụ downstream đa dạng, mang lại cơ hội mới cho đánh giá chất lượng văn bản sử dụng các mô hình như vậy. Hơn nữa, nhiều mô hình đào tạo khác nhau đã được đề xuất để trao cho LLM khả năng hoàn thành các nhiệm vụ theo cách zero-shot và tuân thủ tốt hơn các hướng dẫn do con người cung cấp (Ouyang et al., 2022; Sanh et al., 2021; Wei et al., 2021). Những tiến bộ này tạo điều kiện cho việc nhắc nhở LLM đánh giá văn bản được tạo ra, mô phỏng hiệu quả các nhà đánh giá con người trong quá trình đánh giá.

Xét đến khả năng hiểu văn bản và tuân theo hướng dẫn ấn tượng của các LLM gần đây, một số tài liệu (Liu et al., 2023b; Chiang & Lee, 2023; Gao et al., 2023; Shen et al., 2023) đã áp dụng LLM làm người đánh giá để đánh giá chất lượng của các phản hồi cho các câu hỏi mở hoặc các nhiệm vụ NLG truyền thống, bao gồm tạo phản hồi đối thoại và tóm tắt. Phương pháp này được gọi là LLM-as-a-judge (Zheng et al., 2023). Các phát hiện từ những nghiên cứu này cho thấy rằng LLM có thể bắt chước hành vi con người và cung cấp các đánh giá tương ứng với đánh giá của con người, tiết lộ một lựa chọn thay thế có khả năng mở rộng và minh bạch cho các đánh giá của con người tốn kém và tốn công sức.

Mặc dù một LLM mạnh mẽ duy nhất đã có thể giải quyết nhiều nhiệm vụ khác nhau, các nghiên cứu mới nổi cho thấy rằng nhiều LLM có thể cải thiện lẫn nhau hơn nữa thông qua tranh luận và hợp tác (Li et al., 2023a; Liang et al., 2023). Bằng cách tích hợp nhiều LLM vào một nhóm tích hợp và thiết kế các cơ chế tương tác cụ thể, các LLM khác nhau có thể tham gia vào việc đề xuất và cân nhắc các phản hồi và quy trình suy nghĩ độc đáo qua một số vòng. Phương pháp này dẫn đến việc nâng cao tính chính xác của các phản hồi được tạo ra (Du et al., 2023) và cải thiện trong việc hoàn thành các nhiệm vụ khó khăn (Li et al., 2023a; Qian et al., 2023). Hơn nữa, nhóm đa tác tử cũng giải quyết và giảm thiểu vấn đề Degeneration-of-Thought (DOT) (Liang et al., 2023).

Trong các quy trình đánh giá của con người, việc dựa vào một quan điểm duy nhất có thể đưa ra sự thiên vị và bất ổn trong kết quả (Karpinska et al., 2021). Nhận thức điều này, các thực hành tốt nhất thường bao gồm nhiều người chú thích hợp tác trong đánh giá (Van Der Lee et al., 2019). Lấy cảm hứng từ phương pháp đánh giá của con người mang tính hợp tác và lặp lại này, chúng tôi đề xuất ChatEval, một hệ thống cho phép mỗi tác tử sử dụng các chiến lược giao tiếp khác nhau trong thảo luận hợp tác, hướng tới việc xây dựng các đánh giá cuối cùng. Hơn nữa, để làm phong phú động lực đánh giá, mỗi tác tử trong ChatEval được trao một nhân vật độc đáo. Thiết kế có chủ ý này đảm bảo rằng mỗi tác tử tập trung vào các quan điểm riêng biệt hoặc mang lại chuyên môn cụ thể lên bàn. Bằng cách làm như vậy, đánh giá tập thể hưởng lợi từ một lăng kính toàn diện hơn, nắm bắt các sắc thái và tinh tế mà một quan điểm duy nhất có thể bỏ qua. Chúng tôi rút ra ý tưởng này chủ yếu từ hiểu biết về 'Có một nghìn Hamlet trong mắt của một nghìn người', có nghĩa là mỗi người có cách hiểu hoặc quan điểm độc đáo của riêng họ, đặc biệt áp dụng cho đánh giá văn bản. Thực sự, những quan điểm khác nhau này tạo nên đánh giá toàn diện và đa mặt về Hamlet. Một trực giác nền tảng khác của công việc chúng tôi xuất phát từ các khái niệm nổi tiếng trong xã hội học và sinh học, bao gồm Trí tuệ Tập thể (Woolley et al., 2010) và Hiệp đồng Nhận thức (Luppi et al., 2022), nơi nhiều quá trình hoặc hệ thống nhận thức tương tác và hợp tác theo cách tạo ra hiệu ứng kết hợp lớn hơn tổng các hiệu ứng riêng lẻ của chúng.

Tóm lại, đóng góp chính của công việc chúng tôi như sau:
1. Chúng tôi đề xuất một khung dựa trên đa tác tử có tên ChatEval phù hợp tốt hơn với sở thích của con người so với các phương pháp dựa trên tác tử đơn như được mô tả trong Hình 1.
2. Chúng tôi đề xuất nhiều chiến lược giao tiếp khác nhau và chứng minh sự cần thiết của các nhắc nhở vai trò đa dạng trong các tình huống tranh luận đa tác tử.
3. Chúng tôi phát hành thư viện của mình. Nó được thiết kế để vừa có thể kết hợp và mở rộng, cho phép các nhà nghiên cứu triển khai các chiến lược giao tiếp độc đáo của họ một cách dễ dàng. Chúng tôi hy vọng điều này góp phần thúc đẩy nghiên cứu trong lĩnh vực các tác tử giao tiếp và hơn thế nữa.

2 PHƯƠNG PHÁP LUẬN
Trong phần này, chúng tôi trình bày chi tiết về các thành phần chính trong ChatEval bao gồm các tác tử tranh luận, đặc tả vai trò đa dạng, chiến lược giao tiếp, và cung cấp tổng quan chi tiết về vai trò và chức năng của từng thành phần¹.

¹kho lưu trữ mã của chúng tôi được xây dựng dựa trên https://github.com/OpenBMB/AgentVerse.

--- TRANG 2 ---
Các Tác tử Tranh luận. Các tác tử tranh luận là một trong những thành phần quan trọng nhất trong khung của chúng tôi. Chúng tôi coi mỗi LLM riêng lẻ như một tác tử và yêu cầu chúng tạo ra phản hồi của mình từ nhắc nhở được cung cấp². Các phản hồi từ các tác tử khác được phục vụ như lịch sử trò chuyện sẽ được thay thế trong mẫu nhắc nhở. Sau khi cấu hình các tác tử, chúng tôi sau đó bắt đầu cuộc tranh luận nhóm nơi mỗi tác tử tự động nhận phản hồi từ những người khác và, đổi lại, đưa ra các phản hồi của riêng mình cho họ. Cần lưu ý rằng toàn bộ quá trình không yêu cầu sự can thiệp của con người.

Đặc tả Vai trò Đa dạng. Như được trình bày trong Phần 1, đặc tả vai trò đa dạng cũng là cần thiết cho khung này. Mặc dù tất cả các tác tử chia sẻ một mẫu nhắc nhở chung, chúng tôi thay thế khe mô tả vai trò bằng các nhắc nhở vai trò đa dạng, chỉ định các tính cách riêng biệt cho các tác tử khác nhau. Chúng tôi lấy cảm hứng từ Wu et al. (2023) và xây dựng một mô tả vai trò tương tự.

Chiến lược Giao tiếp. Cách duy trì lịch sử trò chuyện là một vấn đề quan trọng khác trong ChatEval. Trong công việc của chúng tôi, chúng tôi sử dụng một thuật ngữ trực quan hơn để minh họa việc duy trì lịch sử trò chuyện được gọi là chiến lược giao tiếp. Nói tóm lại, các chiến lược giao tiếp khác nhau có thể được coi là các phương pháp khác nhau để duy trì và thao tác lịch sử trò chuyện của chúng. Như được hiển thị trong Hình 2, Chúng tôi chủ yếu thiết kế ba chiến lược giao tiếp khác nhau và minh họa chúng như sau:

1. Từng người một (One-By-One). Trong mỗi vòng tranh luận, các tác tử tranh luận lần lượt theo thứ tự đã định để tạo ra phản hồi của họ dựa trên quan sát hiện tại. Khi đến lúc một tác tử tranh luận phản hồi, chúng tôi trực tiếp nối những gì các tác tử khác trước đó đã nói vào khe lịch sử trò chuyện của nó.

2. Nói đồng thời (Simultaneous-Talk). Không giống như chiến lược từng người một, chúng tôi thực hiện một chiến lược giao tiếp thay thế được gọi là nói đồng thời, nơi các tác tử tranh luận được nhắc nhở tạo ra phản hồi một cách bất đồng bộ trong mỗi lần lặp của cuộc thảo luận để vô hiệu hóa tác động của thứ tự nói.

3. Nói đồng thời với Người tóm tắt (Simultaneous-Talk-with-Summarizer). Sự khác biệt chính giữa chiến lược này và nói đồng thời là chúng tôi bổ sung sử dụng một LLM khác làm người tóm tắt. Vào cuối mỗi lần lặp của cuộc tranh luận, chúng tôi nhắc nhở LLM bổ sung này tóm tắt các thông điệp được truyền đạt cho đến nay và nối tóm tắt này vào khe lịch sử trò chuyện của tất cả các tác tử tranh luận.

²Mẫu nhắc nhở đầy đủ có thể được tìm thấy trong Phụ lục A.

--- TRANG 3 ---
[Hình 2: Sơ đồ tổng thể về ba loại chiến lược giao tiếp khác nhau được đề xuất của chúng tôi. Hướng của các mũi tên đại diện cho luồng thông tin, có nghĩa là những gì người này nói sẽ được nối vào lịch sử trò chuyện của người được chỉ bởi mũi tên. Mô tả thuật toán đầy đủ của các chiến lược giao tiếp trên có thể được tìm thấy trong Phụ lục B.]

Không giống như công việc trước đó như Du et al. (2023), chúng tôi không yêu cầu rõ ràng các tác tử tranh luận đạt được sự đồng thuận vào cuối cuộc tranh luận. Trong các tình huống mà định dạng phản hồi dựa vào so sánh trực tiếp, chúng tôi rút ra kết quả cuối cùng từ bỏ phiếu đa số giữa các người chú thích khác nhau. Ngược lại, nếu định dạng phản hồi yêu cầu điểm số trực tiếp, chúng tôi tính điểm số trung bình thu được từ nhiều người chú thích. Phương pháp luận này đảm bảo tính công bằng và cân bằng của quy trình đánh giá của chúng tôi.

3 THÍ NGHIỆM
Chúng tôi đánh giá ChatEval trên hai chuẩn mực, FairEval và Topical-Chat đại diện cho các danh mục câu trả lời cho câu hỏi mở và tạo phản hồi đối thoại, tương ứng.

3.1 CHI TIẾT TRIỂN KHAI
Chúng tôi chọn sử dụng các mô hình từ gia đình GPT của OpenAI làm LLM của chúng tôi trong ChatEval, bao gồm GPT-4 và ChatGPT (GPT-3.5-turbo) và đặt nhiệt độ thành 0 để đảm bảo tính tái lập. Lý do đằng sau việc lựa chọn này là hiệu suất đặc biệt mà các mô hình này cung cấp, là một trong những mô hình tiên tiến và mạnh mẽ nhất thế giới. Ngoài ra, khả năng tiếp cận và dễ sử dụng của chúng thông qua API cho phép chúng tôi trực tiếp gọi và tương tác với các mô hình trong nghiên cứu của mình, đơn giản hóa đáng kể quá trình. Trong nghiên cứu hiện tại của chúng tôi, chúng tôi tập trung vào các nhóm đồng nhất của LLM. Nghĩa là, trong một nhóm đa tác tử nhất định, tất cả LLM đều thuộc cùng một mô hình gia đình GPT, tất cả GPT-4 hoặc tất cả ChatGPT. Chúng tôi thừa nhận tiềm năng của các nhóm không đồng nhất cho nghiên cứu tương lai, có thể cung cấp những hiểu biết thú vị về cách các mô hình mạnh và các mô hình yếu có thể hợp tác trong một môi trường đa tác tử.

3.2 CÁC CHUẨN MỰC
Giới thiệu chi tiết về các danh mục và chuẩn mực khác nhau được liệt kê như sau:

Câu trả lời cho Câu hỏi Mở là một thành phần chính trong lĩnh vực NLP và AI tạo sinh. Nó đòi hỏi một hệ thống AI cung cấp các phản hồi toàn diện, chi tiết và giống con người cho các câu hỏi không có một tập hợp câu trả lời có thể xác định trước hoặc cố định. Công việc của Chiang et al. (2023) bao gồm một bộ sưu tập 80 câu hỏi mở xuất phát từ một loạt các danh mục, bao gồm thông thường, phản thực tế, mã hóa, v.v. Sau đó chúng tôi lấy kết quả chú thích của con người từ Wu et al. (2023) để tiến hành các thí nghiệm trong bài báo này. Đối với mỗi câu hỏi, họ chỉ đạo ba người chú thích đánh giá các câu trả lời được đưa ra bởi Vicuna-13B và ChatGPT thông qua các quy tắc đã cho và cuối cùng rút ra kết quả bằng bỏ phiếu đa số giữa các người chú thích.

Tạo Phản hồi Đối thoại là một nhiệm vụ bao gồm việc tạo ra một phản hồi mạch lạc và phù hợp với ngữ cảnh cho một đầu vào đối thoại nhất định. Chúng tôi dựa vào bộ dữ liệu Topical-Chat (Gopalakrishnan et al., 2019) cho nghiên cứu của mình. Sau đó chúng tôi lấy kết quả chú thích của con người từ Mehri & Eskenazi (2020) nơi họ thực hiện các chú thích trên 60 bối cảnh đối thoại với mỗi phản hồi được tạo ra bởi 6 hệ thống khác nhau. Các nhà đánh giá con người đã phân tích các phản hồi này dựa trên tự nhiên, mạch lạc, hấp dẫn, có căn cứ, và dễ hiểu, nơi chúng tôi lấy bốn chiều đầu tiên cho các thí nghiệm trong bài báo của chúng tôi theo Zhong et al. (2022).

--- TRANG 4 ---
3.3 CÁC PHƯƠNG PHÁP BASELINE
Chúng tôi đánh giá ChatEval so với các phương pháp sau. Là phần chính của so sánh, chúng tôi chủ yếu tập trung vào phương pháp dựa trên tác tử đơn. Tác tử Đơn có nghĩa là chúng tôi trực tiếp truy vấn một LLM để tạo ra phản hồi cho đánh giá³. Chúng tôi sử dụng Đa Tác tử để đại diện cho ChatEval nơi một số tác tử thảo luận về đánh giá. Theo mặc định, chúng tôi cấu hình chiến lược giao tiếp thành từng người một, số lượng tác tử thành 2, và số lượt thảo luận thành 2 trong phần này và sử dụng các kỹ thuật hiệu chuẩn vị trí trong cả hai môi trường tác tử đơn và đa tác tử. Chúng tôi sẽ thảo luận thêm về cấu hình tranh luận trong Phần 4 để hoàn thiện. Đối với nhiệm vụ câu trả lời cho câu hỏi mở, chúng tôi cũng so sánh phương pháp của mình với FairEval (Wang et al., 2023b). Họ đề xuất nhiều chiến lược khác nhau để cải thiện hiệu suất đánh giá của LLM bao gồm Hiệu chuẩn Bằng chứng Đa dạng (MEC) và Hiệu chuẩn Vị trí Cân bằng (BPC). Đối với nhiệm vụ tạo phản hồi đối thoại, chúng tôi cũng so sánh phương pháp của mình với G-EVAL (Liu et al., 2023b). Họ sử dụng CoT và tổng có trọng số xác suất cho phương pháp của họ. Ngoài ra, chúng tôi bao gồm kết quả từ các chỉ số dựa trên n-gram, chẳng hạn như ROUGE (Lin, 2004), BLEU (Papineni et al., 2002) và các chỉ số dựa trên nhúng như BERTScore (Zhang et al., 2019).

3.4 KẾT QUẢ CHO CÂU TRẢ LỜI CÂU HỎI MỞ
Chúng tôi áp dụng cùng một phương pháp đánh giá như Wang et al. (2023b) để đánh giá kết quả chú thích được tạo ra bởi các phương pháp và người chú thích khác nhau. Cụ thể, chúng tôi tính Độ chính xác (Acc.), đo lường tỷ lệ các trường hợp được phân loại chính xác so với tổng số trường hợp, và hệ số tương quan Kappa (Kap.) (McHugh, 2012) đo lường sự thỏa thuận giữa kết quả từ các mô hình và người chú thích con người trong khi tính đến khả năng thỏa thuận xảy ra do tình cờ. Cả hai chỉ số đều cung cấp hiểu biết về độ tin cậy và tính nhất quán của các chú thích. Chúng tôi lấy kết quả chú thích của con người và kết quả tốt nhất của FairEval (Wang et al., 2023b) từ bài báo của họ. Như được hiển thị trong Bảng 1, các người chú thích khác nhau có thể đạt được sự thỏa thuận tương đối cao và thực hiện tốt hơn bất kỳ phương pháp dựa trên LLM nào khác. Tuy nhiên, độ chính xác chú thích con người trung bình là 71.7% cho thấy có tồn tại một mức độ bất đồng nhất định giữa các cá nhân khác nhau tiết lộ rằng đánh giá văn bản hoàn toàn là một nhiệm vụ khó khăn. Phần thứ hai và phần thứ ba của Bảng 1 hiển thị kết quả của phương pháp FairEval và kết quả của phương pháp được đề xuất của chúng tôi tương ứng. Chúng tôi thấy rằng (1) ChatEval có thể nâng cao hiệu suất của quy trình đánh giá, đạt được sự phù hợp cao hơn với sở thích của con người so với đánh giá tác tử đơn. Cụ thể, phương pháp dựa trên đa tác tử cải thiện độ chính xác 6.2% cho ChatGPT và 2.5% cho GPT-4; (2) ChatEval vượt qua kết quả tốt nhất của FairEval trong cả hai cài đặt ChatGPT và GPT-4 cho thấy hiệu quả của phương pháp được đề xuất của chúng tôi.

3.5 KẾT QUẢ CHO TẠO PHẢN HỒI ĐỐI THOẠI
Đối với các chuẩn mực tạo phản hồi đối thoại, chúng tôi phù hợp với phương pháp đánh giá với Zhong et al. (2022), tính toán tương quan Spearman và Kendall-Tau cấp độ lượt tương ứng với các đánh giá của con người về bốn khía cạnh (tự nhiên, mạch lạc, hấp dẫn và có căn cứ). Kết quả có thể được tìm thấy trong Bảng 2. Trong phần đầu tiên của Bảng 2, chúng tôi chứng minh rằng các chỉ số dựa trên n-gram và các chỉ số dựa trên nhúng thực hiện tổng thể kém trên tất cả các khía cạnh được đánh giá, minh họa rằng các phương pháp này khó có thể tiết lộ sở thích của con người. Trong phần thứ hai của Bảng 2, chúng tôi hiển thị kết quả từ bài báo G-eval (Liu et al., 2023b). Họ đầu tiên yêu cầu LLM tạo ra suy nghĩ trung gian và cuối cùng tính toán tổng có trọng số của điểm số đầu ra dựa trên xác suất. Kết quả cho thấy phương pháp của họ vượt trội hơn các chỉ số truyền thống trước đây mô tả thực tế rằng trình đánh giá dựa trên LLM là hiệu quả và đáng tin cậy để đánh giá nhiệm vụ tạo phản hồi đối thoại. Mặc dù phương pháp của họ mang lại kết quả tốt, phương pháp được đề xuất của chúng tôi nâng cao hiệu suất cho GPT-4. Cụ thể, ChatEval cải thiện tương quan Spearman và Kendall-Tau trung bình lần lượt 0.096 (16.3%) và 0.057 (10.0%). Ngoài ra, so với phương pháp tác tử đơn, ChatEval khuếch đại hiệu suất cho cả ChatGPT và GPT-4, cho thấy hiệu quả của phương pháp của chúng tôi phù hợp với kết quả trong Phần 3.4.

³Chúng tôi sử dụng cùng mẫu nhắc nhở như các cài đặt tranh luận đa tác tử của chúng tôi trong baseline tác tử đơn ngoại trừ việc chúng tôi bỏ qua một số khe.

--- TRANG 5 ---
[Bảng 1: Độ chính xác (Acc.) và hệ số tương quan Kappa (Kap.) của các phương pháp khác nhau trên chuẩn mực FairEval.]

[Bảng 2: Tương quan Spearman (ρ) và Kendall-Tau (τ) cấp độ lượt của các phương pháp khác nhau trên chuẩn mực Topical-Chat, SA có nghĩa là Tác tử Đơn và MA có nghĩa là Đa Tác tử. Cài đặt ChatGPT của chúng tôi nên được so sánh với G-EVAL-3.5, và cài đặt GPT-4 nên được so sánh với G-EVAL-4.]

4 PHÂN TÍCH
Trong phần này, chúng tôi khám phá thêm các thành phần chính bao gồm trong ChatEval. Chúng tôi thảo luận về tầm quan trọng của các nhắc nhở vai trò đa dạng trong Phần 4.1, hiệu ứng của các chiến lược giao tiếp khác nhau trong Phần 4.2, và tác động của số lượng vai trò và số lượt thảo luận trong Phần 4.3. Nếu không được chỉ định khác, chúng tôi chọn chuẩn mực FairEval và ChatGPT làm LLM cốt lõi cho phân tích.

4.1 TẦM QUAN TRỌNG CỦA CÁC NHẮC NHỞ VAI TRÒ ĐA DẠNG
Trước đây trong Bảng 1 và 2, chúng tôi chứng minh rằng ChatEval được trang bị với cấu hình vai trò đa dạng có thể cải thiện đáng kể hiệu suất đánh giá. Chúng tôi xem xét thêm liệu có cần thiết phải thiết kế các nhắc nhở vai trò đa dạng cho hệ thống đánh giá hay không. Để trả lời như vậy, chúng tôi thực hiện các thí nghiệm bằng cách thay thế tất cả nhắc nhở vai trò bằng "Bạn hiện tại là Người chú thích, một trong những trọng tài trong nhiệm vụ đánh giá văn bản." và giữ nguyên các nhắc nhở khác. Chúng tôi thực nghiệm với chiến lược giao tiếp từng người một và 2 tác tử với 2 lượt thảo luận. Kết quả trong Bảng 3 minh họa rằng ChatEval với thiết kế nhắc nhở vai trò giống nhau kém hiệu quả hơn so với thiết kế nhắc nhở vai trò đa dạng và không thể nâng cao hiệu quả một cách hiệu quả so với cài đặt tác tử đơn, làm nổi bật tính quan trọng của thiết kế nhắc nhở vai trò đa dạng trong khung tranh luận đa tác tử.

4.2 NGHIÊN CỨU VỀ CÁC CHIẾN LƯỢC GIAO TIẾP
Như được hiển thị trong Hình 2, chúng tôi cũng thiết kế ba chiến lược giao tiếp khác nhau được gọi là từng người một, nói đồng thời, nói đồng thời với người tóm tắt. Các mô tả chi tiết và công thức chính thức có thể được tìm thấy trong Phụ lục B. Chúng tôi thực nghiệm với 3 tác tử và 2 lượt thảo luận với nhắc nhở vai trò đa dạng trong phần này. Như được hiển thị trong Bảng 4, chúng tôi có thể thấy rằng chiến lược giao tiếp từng người một hiệu quả hơn các chiến lược khác cho cài đặt ChatGPT. Mặc dù hai chiến lược giao tiếp khác không thực hiện mạnh mẽ như chiến lược từng người một, đáng chú ý là chúng vẫn vượt qua hiệu suất của phương pháp tác tử đơn ngây thơ. Hơn nữa, các biến thể trong hiệu suất giữa ba chiến lược giao tiếp khác nhau nhấn mạnh ảnh hưởng của các chiến lược khác nhau đến hiệu quả của quy trình đánh giá, tiết lộ tiềm năng cho việc khám phá và tối ưu hóa thêm ChatEval. Do đó, các nghiên cứu tương lai có thể nhằm vào hiểu biết toàn diện hơn về các chiến lược giao tiếp khác nhau, và cách chúng có thể được sử dụng hiệu quả để nâng cao hiệu suất. Điều này có thể phục vụ như một con đường cho những cải tiến đáng kể và hiểu biết mới trong khung tranh luận đa tác tử.

4.3 TÁC ĐỘNG CỦA SỐ LƯỢNG VAI TRÒ VÀ SỐ LƯỢT THẢO LUẬN
Sau đó chúng tôi nghiên cứu tác động của số lượng vai trò và số lượt thảo luận khác nhau. Từ Hình 3a, một xu hướng có thể nhận biết được quan sát trong mối quan hệ giữa số lượng vai trò và cả Acc. và Kap. trong bộ dữ liệu FairEval. Khi số lượng vai trò tăng, có sự tăng trưởng tương ứng trong Acc. và Kap. Mô hình này đạt đỉnh với Acc. là 62.5% ở số lượng vai trò 3 và 4 trước khi giảm ở số lượng vai trò 5. Bất chấp sự giảm trong độ chính xác này, Kap. tiếp tục tăng giữa số lượng vai trò 3 và 4, nhấn mạnh hiệu quả của việc kết hợp các vai trò đa dạng trong ChatEval. Ngược lại, không có xu hướng tăng đáng kể nào được phát hiện liên quan đến sự tăng số lượt thảo luận, như được hiển thị trong Hình 3b. Quan sát này phù hợp với các phát hiện trong Liang et al. (2023); Du et al. (2023), làm nổi bật một hiện tượng nhất quán nơi thảo luận liên tục thường dẫn đến trì trệ hoặc thậm chí suy giảm hiệu suất. Xu hướng như vậy có thể được quy cho các vấn đề liên quan đến độ dài ngữ cảnh ngày càng tăng, do đó làm giảm hiệu suất. Hiểu biết này khuyến khích một sự hiểu biết tinh tế hơn về sự cân bằng cần thiết giữa sự phân biệt vai trò và động lực thảo luận để tối ưu hóa hiệu suất của ChatEval.

4.4 PHÂN TÍCH ĐỊNH TÍNH
Bảng 5 trình bày quá trình tranh luận về đánh giá hai phản hồi của trợ lý đối với câu hỏi mở "Những cách hiệu quả nhất để đối phó với căng thẳng là gì?".

[Phản hồi của Assistant 1 và Assistant 2 được liệt kê chi tiết...]

Chúng tôi có thể thấy rằng cả hai phản hồi đều tạo ra các chiến lược tương tự và mô tả hấp dẫn như nhau để đối phó với căng thẳng, khiến việc phân biệt sự khác biệt đáng kể về chất lượng trở nên thách thức. Chính trong bối cảnh đánh giá tinh tế này mà ý nghĩa của quy trình ChatEval xuất hiện. Để hiểu rõ hơn về sự phức tạp này, Chúng tôi đầu tiên phác thảo quy trình ChatEval và sau đó đi sâu vào các hành vi xây dựng của các tác tử trong cuộc thảo luận.

--- TRANG 6 ---
[Tiếp tục với phần phân tích định tính và các bảng kết quả...]

5 CÔNG VIỆC LIÊN QUAN
Đánh giá NLG tự động Trong bối cảnh NLG, đánh giá chất lượng của văn bản được tạo ra đại diện cho một nhiệm vụ đặc biệt khó khăn. Trong một thời gian dài, đánh giá chủ yếu phụ thuộc vào chú thích của con người, một quá trình tốn nhiều lao động và bị hạn chế bởi các vấn đề về khả năng mở rộng. Đánh giá NLG tự động cố gắng giải quyết những thách thức này bằng cách tận dụng các mô hình tính toán để đánh giá chất lượng của văn bản được tạo ra. Công việc trước đây nằm trong các danh mục sau: (1) các chỉ số dựa trên n-gram: ROUGE (Lin, 2004) là một bộ chỉ số tính toán lượng chồng chéo giữa các n-gram trong các tóm tắt được tạo ra bởi máy và các tóm tắt tham chiếu. BLEU (Papineni et al., 2002) so sánh văn bản được tạo ra với các bản dịch tham chiếu, dựa trên sự đồng xuất hiện của các n-gram trong cả hai văn bản. Mặc dù được sử dụng dễ dàng và rộng rãi, phương pháp trên không thể nắm bắt được tương đồng cú pháp và ngữ nghĩa (Stent et al., 2005). (2) các chỉ số dựa trên nhúng: Nhúng từ là các biểu diễn vector của các từ nắm bắt các thuộc tính ngữ nghĩa của chúng, sao cho các từ có nghĩa tương tự có nhúng tương tự. Một loạt công việc tận dụng nhúng từ để đánh giá tương đồng ngữ nghĩa giữa hai đoạn văn bản. BERTScore (Zhang et al., 2019) sử dụng nhúng từ ngữ cảnh hóa từ các mô hình transformer như BERT (Devlin et al., 2018), BLEURT (Sellam et al., 2020) sử dụng dữ liệu đào tạo có giám sát để nâng cao hiệu suất. MoverScore (Zhao et al., 2019) kết hợp nhúng từ ngữ cảnh hóa với Earth Mover's Distance (Rubner et al., 2000). (3) các chỉ số dựa trên LLM: Giữa sự phát triển thịnh vượng của LLM thể hiện một kho thông tin phong phú được rút ra từ dữ liệu đào tạo rộng lớn, việc sử dụng LLM làm trình đánh giá đã trải qua tiến bộ đáng chú ý. GPTScore (Fu et al., 2023) sử dụng xác suất có điều kiện để gán cho văn bản một điểm số đại diện cho chất lượng của nó. Wang et al. (2023a) khám phá tiềm năng sử dụng ChatGPT như một trình đánh giá NLG bằng cách nhắc nhở nó chấm điểm văn bản trực tiếp. Wang et al. (2023c) tuyển chọn một bộ dữ liệu đáng tin cậy chứa so sánh từng cặp và giải thích đánh giá có thể được sử dụng để đào tạo một mô hình nền tảng khiến nó trở thành một trình đánh giá tốt hơn. Bai et al. (2023) đề xuất đánh giá phi tập trung để cung cấp kết quả đánh giá công bằng hơn. G-EVAL (Liu et al., 2023b) đề xuất các kỹ thuật có trọng số xác suất để hiệu chuẩn điểm số do một LLM duy nhất đưa ra.

Các Tác tử Giao tiếp Gần đây nhất, sự chú ý đáng kể đã được dành cho việc phát triển các tác tử giao tiếp. Những tác tử này, thường được thực hiện bởi các LLM như ChatGPT hoặc GPT-4, được thiết kế để tương tác và giao tiếp hiệu quả với các tác tử khác hoặc người dùng con người sử dụng ngôn ngữ tự nhiên. Mục tiêu chính là tạo điều kiện cho tương tác và hợp tác hiệu quả và năng suất hơn khi các tác tử khác nhau có thể giao tiếp và đàm phán tự động để giải quyết một nhiệm vụ phức tạp hơn một cách tập thể. Một số nghiên cứu đã khám phá các khía cạnh khác nhau của các tác tử giao tiếp. Li et al. (2023a) đề xuất một khung tác tử hợp tác được gọi là đóng vai cho phép các tác tử hợp tác tự động để giải quyết các nhiệm vụ phức tạp. Park et al. (2023) tạo ra một môi trường sandbox gồm 25 thực thể ảo cá nhân được trao tặng mô tả nhân vật và hệ thống bộ nhớ. Mỗi tác tử thông minh có khả năng tương tác tự động với các tác tử khác và môi trường mô phỏng hành vi con người đáng tin cậy. Qian et al. (2023) thiết lập một khung phát triển phần mềm dựa trên trò chuyện có thể hoàn thành thiết kế phần mềm và tạo ra phần mềm thực thi với chi phí giảm so với việc tuyển dụng lập trình viên con người. Liu et al. (2023a) sử dụng môi trường sandbox để tuyển chọn các bộ dữ liệu đáng tin cậy phù hợp tốt hơn với sở thích của con người và đào tạo một LLM có sự liên kết xã hội. Liang et al. (2023) và Du et al. (2023) cũng sử dụng khung tranh luận đa tác tử trong các tình huống khác như dịch thuật và các vấn đề số học dẫn đến kết quả tốt hơn. Wang et al. (2023d) đề xuất một phương pháp thay thế được gọi là tự hợp tác để cho phép giao tiếp của các tác tử bằng cách sử dụng một LLM duy nhất được nhắc nhở bởi các mô tả đa nhân vật. Mandi et al. (2023) đề xuất một khung mới được thiết kế cho sự hợp tác của nhiều robot, sử dụng nhiều LLM để nâng cao phối hợp và lập kế hoạch chiến lược giữa các robot. Đồng thời với công việc của chúng tôi, Li et al. (2023b) đề xuất Xếp hạng Đồng đẳng và Thảo luận (PRD) tương tự như phương pháp của chúng tôi. Tuy nhiên, họ thăm dò các chiều khác nhau của đánh giá bằng cách sử dụng các mô hình khác nhau làm tác tử và không khám phá các chiến lược giao tiếp thay thế.

6 KẾT LUẬN
Trong bài báo này, chúng tôi trình bày bằng chứng rằng ChatEval góp phần cải thiện hiệu suất đánh giá liên quan đến chất lượng văn bản, phù hợp chặt chẽ hơn với sở thích của con người. Chúng tôi nhấn mạnh sự cần thiết của đặc tả vai trò đa dạng và đề xuất các chiến lược giao tiếp riêng biệt như các thành phần tích hợp trong ChatEval. Phân tích định tính của chúng tôi về quy trình thảo luận truyền đạt những trực giác sâu sắc về cách một văn bản được đánh giá bởi ChatEval và chứng thực khả năng của phương pháp chúng tôi trong việc hỗ trợ các đánh giá toàn diện tương tự như đánh giá của con người, do đó chứng minh độ tin cậy và hiệu quả của khung của chúng tôi.

[Phần tài liệu tham khảo và phụ lục tiếp theo được dịch tương tự...]

# 2308.04889.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/icl-papers/2308.04889.pdf
# File size: 1011245 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
NLLG Quarterly arXiv Report 06/23:
What are the most influential current AI Papers?
Steffen Eger, Christoph Leiter, Jonas Belouadi
Ran Zhang, Aida Kostikova, Daniil Larionov, Yanran Chen, Vivian Fresen
Natural Language Learning Group (NLLG) ,https://nl2g.github.io/
Abstract
The rapid growth of information in the field of Generative Artificial Intelligence (AI), par-
ticularly in the subfields of Natural Language Processing (NLP) and Machine Learning (ML),
presents a significant challenge for researchers and practitioners to keep pace with the latest
developments. To address the problem of information overload, this report by the Natural
Language Learning Group at Bielefeld University focuses on identifying the most popular pa-
pers on arXiv, with a specific emphasis on NLP and ML. The objective is to offer a quick
guide to the most relevant and widely discussed research, aiding both newcomers and estab-
lished researchers in staying abreast of current trends. In particular, we compile a list of the
40 most popular papers based on normalized citation counts from the first half of 2023. We
observe the dominance of papers related to Large Language Models (LLMs) and specifically
ChatGPT during the first half of 2023, with the latter showing signs of declining popularity
more recently, however. Further, NLP related papers are the most influential (around 60% of
top papers) even though there are twice as many ML related papers in our data. Core issues
investigated in the most heavily cited papers are: LLM efficiency, evaluation techniques, ethical
considerations, embodied agents, and problem-solving with LLMs. Additionally, we examine
the characteristics of top papers in comparison to others outside the top-40 list (noticing the
top paper’s focus on LLM related issues and higher number of co-authors) and analyze the
citation distributions in our dataset, among others.
1 Introduction
In an era of ever-accelerating information flow, staying abreast of the overwhelming flood of data
and research output is an intimidating task. This holds true especially in the context of the
current large public interest (and even hype) surrounding Generative AI, with papers disseminated
in ever shorter time intervals. This report, published by the Natural Language Learning Group
(https://nl2g.github.io/ ) at Bielefeld University, aims to alleviate the information overload
problem, even if only by a small extent, by identifying the currently most popular papers on the
arXiv ( https://arxiv.org/ ), especially focusing on the AI subfields natural language processing
(NLP) and machine learning (ML) as some of the most vividly discussed research areas, including in
mainstream media. Our intention is to give practitioners, incomers, and users of AI, from related
and non-related fields (e.g., the social sciences or digital humanities) a quick guide on the most
popular and presumably most relevant papers in order to better and (more) quickly grasp current
developments.
1arXiv:2308.04889v1  [cs.CY]  31 Jul 2023

--- PAGE 2 ---
We place particular emphasis on exploring arXiv,1given its status as a comprehensive and
extremely popular pre-print repository. Notably, arXiv’s expedited publication process provides
a distinct advantage over traditional conferences and journals, ensuring that the latest research
becomes readily available to the scientific community at a much faster pace.
This report is structured as follows. In Section 2, we outline our methodology, which is entirely
straightforward: we select papers from arXiv from the first half of the year 2023 and sort them
by normalized citation counts. In Section 3, we show and discuss the list of the 40 most popular
papers — in terms of normalized citation counts — from our arXiv dataset. In Section 4, we
provide an analysis of our arXiv dataset relating to citation distributions, arXiv categories involved,
characteristics of top papers, and popularity of ‘hype’ concepts such as ChatGPT and large language
models (LLMs) over time. In Section 5, we conclude.
Among our key findings are that: (i) NLP, once a niche area of research, is now considerably
more influential than ML in terms of the citations it attracts: even though there are twice as many
ML papers in our datasets, ∼60% of the most highly cited papers are from NLP; (ii) LLM and
ChatGPT related papers have clearly dominated the first half of 2023, but especially ChatGPT is
now on the decline; (iii) the efficient open-source model LLaMA from Meta AI is the relatively and
absolutely most cited paper in our dataset, leaving behind the larger and properietary ChatGPT
and GPT-4.
Our code and data is available from https://github.com/NL2G/Quaterly-Arxiv .
2 Methodology
To identify the most influential papers from the AI subfields NLP and ML, we used the following
methodology.
Dataset name Size Time period # Primary Categories
arxiv-0623 20,843 01/01/2023-06/31/2023 123
arxiv-0623-top40 40 01/01/2023-06/31/2023 5
Table 1: Elementary statistics on our two released datasets. Size is the number of papers in each
dataset; the last column gives the number of distinct primary arXiv categories our papers are
assigned to.
1.Data Retrieval from arXiv : We collect all papers from 01/01/2023 to 06/31/2023 belong-
ing to the arXiv categories cs.CL (computation and language) and cs.LG (machine learning)
using a Python arXiv API.2 3Our retrieval time is July, 29, 2023 (which is important,
1Our report is similar to a ‘conference report’ as a popular form of science communication, e.g., https://www.
romanklinger.de/blog-assets/2023-05-12/eacl2023-conf-report.pdf . But instead of focusing on conferences, we
focus on arXiv for multiple reasons: among others, (i) in an age of rapid developments, conferences and journals are
too slow and often lagging behind recent developments; (ii) as everyone who regularly submits to NLP/ML conferences
knows, conferences also suffer from low reviewing quality, with junior and non-expert reviewers abounding. Instead,
we focus on citations (even though these are not unproblematic themselves) as a form of large-scale crowd voting.
2ArXiv papers may belong to several categories. We only require that one of the involved categories be one of
the two indicated.
3We did not include cs.AI (without cs.LG or cs.CL) but we note that our top-40 list would have looked very
2

--- PAGE 3 ---
because citation counts are constantly in flux). ArXiv papers can be updated anytime; we
take the date of the first submission of a paper to arXiv as its publication date.
2.z-score calculation: For each paper, we extract its citation count, as a measure of popularity
and arguably importance [1], from Semantic Scholar https://www.semanticscholar.org/ .
Since papers published at different time points may naturally have different citation counts
(e.g., older papers have higher chance of being cited than very novel papers), we calculate
anormalized citation count by determining how many standard deviations a paper is above
the mean of citations of all papers published in the same week (Sunday-Saturday) . This is the
so-called z-score of Newman [23]:
zt=ct−mean (c(t))
std(c(t))
for a paper published in week twith citation count ct;c(t) is the list of citation counts of all
papers published in week t. If a paper lies several standard deviations above the mean (for all
papers published in the same week), it can be considered excellent for its class. For example,
in a normal distribution, only about 16% of data points lie one standard deviation above the
mean value. As will be seen below, our top papers lie at least 9–12 standard deviations above
the mean.4
3.Manual Evaluation The published date on arXiv might differ from the actual first publica-
tion/release/submission date of a paper, e.g., when the authors upload the paper much later
to arXiv. Thus, we conduct a manual evaluation to verify if a paper genuinely appeared the
first time as indicated by its arXiv release time stamp. If the paper was available earlier, we
remove it from consideration.
Steps 1 and 2+3 above result in two distinct datasets that we release with this report. We refer
to them as arxiv-0623 and arxiv-0623-top40 , respectively. Table 1 gives elementary statistics
on each of them.
3 Top Npapers
Table 2 showcases the top 20 papers extracted according to the methodology described in Section
2. We make several interesting observations:
•13 out of 20 (65%) of papers have cs.CL as their prime arXiv category (note that authors of
papers may wish to indicate as many additional categories as they desire). cs.LG is the prime
category 3 times, followed by cs.CV (computer vision; 2 times) and cs.CR (cryptography) and
cs.AI (1 time each).
•The absolute citation counts vary drastically, with 14 as lowest number in our top-20 list for
a paper published in very late May ( Large Language Models are not Fair Evaluators [30]) and
874 as highest numbers for the LLaMA paper [28] published in late February. The relative
citation counts vary from 12 standard deviations above the mean to 28 standard deviations
above the mean.
similar with our without the cs.AI requirement. In particular, all top-40 papers would have remained the same —
also note that many cs.AI papers are still included in our dataset, see below.
4Our approach of identifying top papers in arXiv via the zscore is similar to [11].
3

--- PAGE 4 ---
No. Title Cat. Link Week Cit z-score
1 LLaMA: Open and Efficient Founda-
tion Language Modelscs.CL http://arxiv.org/abs/2302.
13971v19 874 28.051
2 GPT-4 Technical Report cs.CL http://arxiv.org/abs/2303.
08774v311 509 25.382
3 PaLM 2 Technical Report cs.CL http://arxiv.org/abs/2305.
10403v120 82 25.182
4 Sparks of Artificial General Intelli-
gence: Early experiments with GPT-4cs.CL http://arxiv.org/abs/2303.
12712v512 354 24.302
5 PaLM-E: An Embodied Multimodal
Language Modelcs.LG http://arxiv.org/abs/2303.
03378v110 164 21.225
6 QLoRA: Efficient Finetuning of Quan-
tized LLMscs.LG http://arxiv.org/abs/2305.
14314v121 30 19.944
7 Segment Anything cs.CV http://arxiv.org/abs/2304.
02643v114 165 18.548
8 Judging LLM-as-a-judge with MT-
Bench and Chatbot Arenacs.CL http://arxiv.org/abs/2306.
05685v223 21 17.916
9 A Multitask, Multilingual, Multimodal
Evaluation of ChatGPT on Reasoning,
Hallucination, and Interactivitycs.CL http://arxiv.org/abs/2302.
04023v26 214 16.819
10 A Survey of Large Language Models cs.CL http://arxiv.org/abs/2303.
18223v1113 169 16.594
11 Visual Instruction Tuning cs.CV http://arxiv.org/abs/2304.
08485v116 89 15.277
12 Tree of Thoughts: Deliberate Problem
Solving with Large Language Modelscs.CL http://arxiv.org/abs/2305.
10601v120 49 14.968
13 Voyager: An Open-Ended Embodied
Agent with Large Language Modelscs.AI http://arxiv.org/abs/2305.
16291v121 21 13.860
14 Toolformer: Language Models Can
Teach Themselves to Use Toolscs.CL http://arxiv.org/abs/2302.
04761v16 175 13.716
15 How Close is ChatGPT to Human Ex-
perts? Comparison Corpus, Evalua-
tion, and Detectioncs.CL http://arxiv.org/abs/2301.
07597v13 94 13.712
16 Extracting Training Data from Diffu-
sion Modelscs.CR http://arxiv.org/abs/2301.
13188v15 97 13.596
17 Large Language Models are not Fair
Evaluatorscs.CL http://arxiv.org/abs/2305.
17926v122 14 13.352
18 HuggingGPT: Solving AI Tasks with
ChatGPT and its Friends in Hugging
Facecs.CL http://arxiv.org/abs/2303.
17580v313 129 12.614
19 A Watermark for Large Language
Modelscs.LG http://arxiv.org/abs/2301.
10226v34 76 12.481
20 DetectGPT: Zero-Shot Machine-
Generated Text Detection using
Probability Curvaturecs.CL http://arxiv.org/abs/2301.
11305v24 76 12.481
Table 2: Papers, their prime category, arXiv link, week of first arXiv submission, citation count (as
of 07/29/2023) and z-score. Top 20 papers according to z-score among all arxiv-0623 papers.
4

--- PAGE 5 ---
No. Title Cat. Link Week Cit z-score
21 Mastering Diverse Domains through World
Modelscs.AI http://arxiv.org/abs/2301.
04104v12 59 12.238
22 Augmented Language Models: a Survey cs.CL http://arxiv.org/abs/2302.
07842v17 79 12.079
23 A Comprehensive Survey on Pretrained
Foundation Models: A History from BERT
to ChatGPTcs.AI http://arxiv.org/abs/2302.
09419v37 79 12.079
24 ImageBind: One Embedding Space To
Bind Them Allcs.CV http://arxiv.org/abs/2305.
05665v219 39 11.966
25 Muse: Text-To-Image Generation via
Masked Generative Transformerscs.CV https://arxiv.org/abs/2301.
007041 111 11.692
26 T2I-Adapter: Learning Adapters to Dig
out More Controllable Ability for Text-to-
Image Diffusion Modelscs.CV http://arxiv.org/abs/2302.
08453v27 76 11.609
27 Is ChatGPT a General-Purpose Natural
Language Processing Task Solver?cs.CL http://arxiv.org/abs/2302.
06476v26 145 11.328
28 SemEval-2023 Task 2: Fine-grained Multi-
lingual Named Entity Recognition (Multi-
CoNER 2)cs.CL http://arxiv.org/abs/2305.
06586v219 36 11.024
29 Mathematical Capabilities of ChatGPT cs.LG http://arxiv.org/abs/2301.
13867v25 79 11.016
30 The Flan Collection: Designing Data and
Methods for Effective Instruction Tuningcs.AI http://arxiv.org/abs/2301.
13688v25 78 10.873
31 The False Promise of Imitating Propri-
etary LLMscs.CL http://arxiv.org/abs/2305.
15717v121 16 10.480
32 The RefinedWeb Dataset for Falcon LLM:
Outperforming Curated Corpora with
Web Data, and Web Data Onlycs.CL http://arxiv.org/abs/2306.
01116v122 11 10.421
33 Distilling Step-by-Step! Outperforming
Larger Language Models with Less Train-
ing Data and Smaller Model Sizescs.CL http://arxiv.org/abs/2305.
02301v218 26 10.387
34 Video-LLaMA: An Instruction-tuned
Audio-Visual Language Model for Video
Understandingcs.CL http://arxiv.org/abs/2306.
02858v323 12 10.136
35 InstructBLIP: Towards General-purpose
Vision-Language Models with Instruction
Tuningcs.CV http://arxiv.org/abs/2305.
06500v219 33 10.083
36 PandaGPT: One Model To Instruction-
Follow Them Allcs.CL http://arxiv.org/abs/2305.
16355v121 15 9.804
37 ChatGPT is not all you need. A State
of the Art Review of large Generative AI
modelscs.LG http://arxiv.org/abs/2301.
04655v12 46 9.459
38 Theory of Mind May Have Spontaneously
Emerged in Large Language Modelscs.CL http://arxiv.org/abs/2302.
02083v35 68 9.440
39 mPLUG-Owl: Modularization Empowers
Large Language Models with Multimodal-
itycs.CL http://arxiv.org/abs/2304.
14178v117 34 9.377
40 Otter: A Multi-Modal Model with In-
Context Instruction Tuningcs.CV http://arxiv.org/abs/2305.
03726v118 23 9.146
Table 3: Papers, their prime category, arXiv link, week of first arXiv submission, citation count (as
of 07/29/2023) and z-score. Papers 21-40 according to z-score among all arxiv-0623 papers.
5

--- PAGE 6 ---
•The four dominating papers can be seen as technical reports on LLM foundations models ,
including LLaMA [28] (the paper with the highest z-score), PaLM 2 [2], and GPT4 (repre-
sented twice; once as an OpenAI publication without dedicated authors focusing on technical
details [24] and once by a group of Microsoft researchers focused on extensive evaluation [6],
both published at around the same time). A “Survey of Large Language Models” [32] (rank
10 in our list) published in late March and already updated 11 times further indicates the
popularity of diverse LLMs.
•While not all being technical reports or surveys, the vast majority of top papers are centered
around LLMs (at least 18 out of 20, i.e., 90%). Exceptions are two papers from the computer
vision domain (ranks 7 and 13).
•It is interesting that LLaMA [28], a set of efficient (and open-source) foundation language
models, dominates overall. This hints at the importance of efficiency for LLMs in general,
both from an environmental perspective but possibly even more so from a practical perspec-
tive, as the LLaMA models can still be fine-tuned even by researchers with a ‘modest’ GPU
endowment [19]. Efficiency is further represented by QLoRA [8], submitted to arXiv in late
May, which discusses efficient fine-tuning of quantized LLMs.
•Three top papers [3, 16, 27] (ranks 9, 15 and 18) are specifically centered around ChatGPT
(arguably as the originator of the new LLM hype [20]) and particularly discuss its evalua-
tion including failure cases. The paper [27] uses ChatGPT to solve AI tasks by querying
huggingface.
•Two further top papers (ranks 12 and 14) explore problem solving with LLMs , one using
external tools [25] and one using reasoning strategies [31].
•Using LLMs for evaluation is discussed in the two papers [30, 33] (ranks 8 and 17), one
for evaluating open-ended dialogue and one discussing biases of evaluation with LLMs. Both
papers are much more recent, being published in late May and early June.
•Two papers [9, 29] (ranks 5 and 13) discuss embodied agents that can interact with the
real world, making use of LLMs.
•Two papers [17, 22] (ranks 19 and 20) can be seen as particularly discussing the ethical
aspects of detecting LLM generated text (e.g., for spotting misleading AI generated content
or to detect cheating in educational contexts) and watermarking AI generated text, i.e.,
embedding signals in automatically generated text that allow its algorithmic detection. Both
papers were published early on, in late January.
•Finally, the exceptions in our top 20 list are two computer vision papers. The Segment Any-
thing paper [18] by Meta AI Research provides a dataset for image segmentation. The paper
[7] discusses privacy of image diffusion models such as DALL-E 2 (which can be considered
the analogues of LLMs in the computer vision domain). A further computer vision paper
introduces a multimodal framework called LLaVA [21], building on top of GPT4.
•Recently, there has been a debate whether AI/NLP has become more negative, i.e., whether
papers tend to report more negatively regarding ongoing research (e.g., outline limitations and
failure cases) [5, 4]. In our top-20 list, only two papers (10%) could be considered critique
6

--- PAGE 7 ---
papers, namely [30], which focuses on and uncovers biases in LLMs as evaluation models, and
[7], which criticizes lack of privacy of diffusion models, allowing to retrieve private information
from the training data. In the top-40 list, there are two additional negative papers, i.e., [12]
which disputes the mathematical capabilities of ChatGPT, and [15], which challenges whether
distillation in which a smaller student LLM is trained on the outputs of a larger properietary
LLM such as ChatGPT is really effective. A few papers are partly negative, highlighting
some limitations, such as [3]. Overall, the most popular papers are (currently) thus positive
regarding the development and abilities of recent LLMs.
Table 3 gives analogous papers with rank 21 to 40. We refrain from an in-depth analysis as above.
The papers have a similar scope, however, with 11 out of 20 (55%) having cs.CL as primary category
and 13 out of 20 (65%) having a variant of LLM in their title (language models, ChatGPT, GPT,
etc.). Interestingly, the list of papers with ranks 21-40 contain quite a few multimodal approaches
such as text-to-image generation models, and relatively more so than the list of papers with ranks
1-20.
4 Analysis
We now briefly perform a few further analyses on our corpus (not only arxiv-0623-top40 but also
arxiv-0623 ) in order to better understand recent developments.
How many citations and standard deviations are there per week? Figure 1 gives the
mean citation counts of papers belonging to three primary categories (cs.CL, cs.LG, and all others)
over time. We observe that:
•citations tend to decrease over time (as is expected; more recent papers cannot yet have been
cited so frequently), with, on average, decisively fewer than 2 citations per paper starting
from May for all three arXiv categories
•cs.CL attracts (considerably) more citations than cs.LG and the aggregation of all other
involved primary categories
•February has been the month with the most impactful papers in cs.CL, especially week 6 (e.g.,
Toolformer [25] and ChatGPT analysis [3] submitted to arXiv) and week 9 (e.g., LLaMA [28]
submitted)
Detailed results including overall standard deviations are also give in Table 4. Standard deviations
are particularly large in weeks 1, 6, 8-13.
How many arXiv categories (scientific subfields) are involved? Our dataset arxiv-0623
comprises 20,843 papers submitted to arXiv between 01/01/2023 and 06/31/2023 with at least
one of the indicated categories given as cs.CL or cs.LG. As NLP and ML affect all aspects of life
nowadays, we would expect that these papers do not only originate from either ML or NLP. Indeed,
we find that our 20,843 papers are assigned to 123 different primary arXiv categories. We give
detailed statistics on those 19 primary categories occurring at least 100 times in Table 5. Overall,
the most frequent 19 primary categories are made up of 5 top level categories, namely: cs (computer
science), stat (statistics), eess (electrical engineering and systems science), math (mathematics)
7

--- PAGE 8 ---
Week Number Week Date Mean Std Mean cs.CL Mean cs.LG Mean Rest
1 01-01/01-07 2.208 9.305 3.164 1.175 2.787
2 01-08/01-14 1.759 4.677 1.714 1.852 1.703
3 01-15/01-21 2.029 6.707 4.110 1.707 1.452
4 01-22/01-28 1.942 5.934 2.318 1.729 2.084
5 01-29/02-04 2.144 6.977 4.314 1.417 2.290
6 02-05/02-11 2.647 12.566 7.578 1.464 2.036
7 02-12/02-18 1.900 6.383 3.368 1.181 2.112
8 02-19/02-25 2.158 9.813 3.617 1.321 2.618
9 02-26/03-04 2.651 31.063 10.496 0.983 1.426
10 03-05/03-11 1.688 7.647 3.734 1.442 1.224
11 03-12/03-18 2.191 19.967 7.901 0.947 1.196
12 03-19/03-25 1.930 14.487 6.117 0.764 1.286
13 03-26/04-01 2.197 10.052 5.688 1.104 1.485
14 04-02/04-08 1.743 8.802 3.380 0.744 1.761
15 04-09/04-15 1.680 6.175 4.000 0.585 1.692
16 04-16/04-22 1.692 5.715 3.093 0.957 1.471
17 04-23/04-29 1.174 3.501 2.368 0.704 1.020
18 04-30/05-06 0.885 2.418 1.320 0.633 0.718
19 05-07/05-13 0.869 3.187 1.162 0.378 1.024
20 05-14/05-20 0.641 3.231 1.204 0.270 0.431
21 05-21/05-27 0.496 1.479 0.550 0.485 0.405
22 05-28/06-03 0.334 1.023 0.494 0.251 0.306
23 06-04/06-10 0.276 1.157 0.474 0.162 0.260
24 06-11/06-17 0.338 1.674 0.449 0.405 0.192
25 06-18/06-24 0.309 3.861 0.331 0.481 0.123
26 06-25/07-01 0.257 2.163 0.228 0.173 0.354
Table 4: Mean number of citations, over all papers including standard deviations, and for the
primary categories cs.CL, cs.LG and the remaining categories.
8

--- PAGE 9 ---
WeekMean Citation Counts
0.0002.0004.0006.0008.00010.00012.000
01-01/01-07 01-15/01-21 01-29/02-04 02-12/02-18 02-26/03-04 03-12/03-18 03-26/04-01 04-09/04-15 04-23/04-29 05-07/05-13 05-21/05-27 06-04/06-10 06-18/06-24cs.CL cs.LG RestMean Citation CountsFigure 1: Mean number of citations over weeks for different arXiv categories.
and quant-ph (quantum physics).5The five most frequent fine-grained categories are cs.LG, cs.CL,
cs.CV (computer vision), stat.ML (statistics, machine learning) and cs.AI (artificial intelligence).
A pie chart of the distribution of primary categories is shown in Figure 2. cs.LG is the largest
category, almost 40% of papers have it as its primary category. cs.CL is only about half the size
(but dominates the top-40 papers as discussed above). Other primary categories (outside of the
top 5 categories) are about the same size as cs.CL.
What distinguishes top papers from other papers? We use the tool of [13] based on the log-
likelihood ratio test [10] to determine unusually frequent words in our top-40 papers arxiv-0623-top40
vs. all other papers. Among the top-10 most distinctive unigrams are chatgpt, gpt-4, modalities,
visual, zero-shot . Among the top bigrams are language models, large language, models (llms), wide
range . The singular most important trigram is large language models . Conversely, words that char-
acterize papers outside the top-40 the best are jargon referring to an older deep learning era such as
learning, neural, deep, network, neural network, machine learning , etc. While this characterization
is very simplistic (it certainly does not satisfy to publish a paper on LLMs to obtain high citation
numbers), it is nonetheless insightful.
Top-40 papers also have way more authors on average (11.8, with a standard deviation of 19.5)
compared to the remaining papers (4.5 with a standard deviation of 3.2). Part of the effect could
be trivial: more authors can increase self-citation counts (an arguably at least partly unethical
5ArXiv does unfortunately not include the humanities or social sciences directly.
9

--- PAGE 10 ---
Category Occurrences
cs.LG 8127
cs.CL 4966
cs.CV 1670
stat.ML 859
cs.AI 455
eess.IV 414
cs.CR 304
cs.IR 288
cs.RO 285
cs.SD 265
math.OC 214
eess.AS 212
eess.SP 201
cs.HC 148
cs.NE 143
eess.SY 134
cs.SE 127
quant-ph 125
cs.CY 111
Table 5: All primary categories given in our arXiv dataset whose occurrence exceeds 100. ArXiv
categories are described here: https://arxiv.org/category_taxonomy .
practice [26]). On the other hand, more fundamental research may require a larger author list and
industry may also produce papers with a higher number of authors.
What are the most important key words of the top-40 papers? We plot a wordcloud of
the top-40 papers (see Figure 3). To do so, we use KeyBERT [14] to identify the 5 most important
tri-grams from the title and abstract of each paper. Then we filter out a manually selected list of
unimportant words and lemmatize each word. Finally, we use the python library wordcloud6for
plotting. Here the focus of current research into ever larger models becomes apparent again, with
phrases such as trillion token ,175b,large scale andlarge language model . The keywords publicly
available also show a focus on non-proprietary data and models.
How popular are LLMs over time in our arXiv dataset? While we have seen that LLMs
are the dominating theme in the top-40 paper list, we wonder how the popularity of LLMs and
ChatGPT have developed over time in our complete arXiv dataset arxiv-0623 . To this end, we
query the keywords “LLMs” and “ChatGPT” in our dataset over time and flag a paper as relevant
if it contains the keywords in its title or abstract.7
Figure 4 shows the results. Both keywords were not very relevant in early 2023, less than
2% of papers contained them in January. The ChatGPT curve increases until late March (6%
of all papers). Starting from mid-April, LLMs become the more popular keyword. ChatGPT
6https://github.com/amueller/word_cloud
7We lowercase abstracts and titles, and we look for the keywords “llm(s)” and “large language model(s)” for LLM;
for ChatGPT, we look for “chatgpt” and “chat-gpt”.
10

--- PAGE 11 ---
other
22.9%
stat.ML
4.1%
cs.AI
2.2%
cs.CV
8.0%
cs.CL
23.8%cs.LG
39.0%Figure 2: Pie chart of distribution of main categories in our dataset.
as a keyword declines since then, while LLMs spike in the week of 05/21 (which marks 2023’s
camera-ready submission deadline for the popular NLP conference ACL https://www.aclweb.org/
portal/content/acl-2023-call-papers ) with almost 12% of papers containing it; we assume
that many accepted ACL papers (with LLMs as a topic) were posted to arXiv right after the
camera-ready deadline. Since then, LLMs seem to be declining as a keyword, also — even though
this could just be an artefact of the conference deadline.
5 Conclusion
We have examined arXiv papers related to the categories cs.CL and cs.LG over the first half of 2023.
First, we sorted papers according to their normalized citation counts, finding that LLM related
papers clearly dominate. Within LLMs, the most popular current issues center around: efficiency,
LLM based evaluation, ethical aspects, embodied agents and problem solving with LLMs (only
slightly less prominent are multimodal approaches encompassing language and other modalities
such as images, with at least 8 papers within the top-40). We have also looked at, among others:
(i) what characteristics top papers have relative to papers outside the top-40 list in terms of number
of authors and vocabulary, (ii) the distributions of citations in our dataset, and (iii) the popularity
of ChatGPT, which ‘caused’ the current hype surrounding LLMs in late 2022, and LLMs over time.
We hope that our investigation is beneficial not only to newcomers and outsiders to the field of
NLP and ML (of which there are seemingly very many nowadays, given how popular the fields have
11

--- PAGE 12 ---
Figure 3: Wordcloud based on the top-40 papers.
become [34]), providing quick links to useful starting literature, but also to established researchers
and their doctoral students.
In the future, we want to regularly update the current report to see how tastes shift over time,
examine our arXiv datasets arxiv-0623 andarxiv-0623-top40 in much more depth, and include
further arXiv categories related to AI fields (e.g., cs.CV, stat.ML, cs.AI) into our datasets, among
others.
Limitations
Limitations of our approach include the following. First of all, science tools like SemanticScholar
or GoogleScholar make quite a few mistakes in correctly attributing citations. While we did not
study this in depth, we note for example that LLaMA (our top paper) has 874 citations according
to SemanticScholar (July 29, 2023) but only 710 citations according to GoogleScholar, a relative
difference of164
874= 18.7%. The paper with fewest citations in our top 20 list [30] has 14 citations
(July 29, 2023) according to SemanticScholar but only 9 citations according to GoogleScholar, a
relative difference of5
14= 35.7%. While we do think that our rankings are relatively reliable, such
deviations may naturally bias our selection of papers, assumedly with higher uncertainty for low
citation papers. Secondly, focusing particularly on highly cited papers may induce a bias towards
these papers similar to that of a self-fulfilling prophecy or preferential attachment. Thirdly, our focus
12

--- PAGE 13 ---
Week024681012
01-01/01-0701-08/01-1401-15/01-2101-22/01-2801-29/02-0402-05/02-1102-12/02-1802-19/02-2502-26/03-0403-05/03-1103-12/03-1803-19/03-2503-26/04-0104-02/04-0804-09/04-1504-16/04-2204-23/04-2904-30/05-0605-07/05-1305-14/05-2005-21/05-2705-28/06-0306-04/06-1006-11/06-1706-18/06-2406-25/07-01ChatGPT LLMsChatGPT + LLMs PopularityFigure 4: Popularity of ChatGPT and LLMs (in percentage of papers having the words in their
abstracts or titles) over time in our dataset.
on weekly citation averages may have unexpected effects: for example, a younger paper with more
citations could be ranked below an older paper with fewer citations, for example, if that older paper
was published in a week with fewer average citations (e.g., in the early weeks of January where
research, and other human activity, is typically less productive, at least in relevant parts of the
world, due to preceding holiday activities). Finally, some authors and research groups, potentially
more traditional ones, may refrain from submitting their papers to arXiv, despite its otherwise high
popularity particularly in the computer science community (see exponential submission growth
rates of arXiv submission numbers in the last decades https://info.arxiv.org/help/stats/
2021_by_area/index.html ). Papers from such authors or groups will not be part of our dataset
and analysis.
Our limitations must be kept in mind when interpreting our results.
Acknowledgements
The NLLG group gratefully acknowledges support from the Federal Ministry of Education and
Research (BMBF) via the interdisciplinary AI research grant “Metrics4NLG”. Steffen Eger is further
supported by the DFG Heisenberg grant EG 375/5-1. We thank Andreas “Max Power” R¨ uckl´ e for
thoughtful discussions.
13

--- PAGE 14 ---
References
[1] Dag W. Aksnes, Liv Langfeldt, and Paul Wouters. Citations, citation indicators, and research
quality: An overview of basic concepts and theories. SAGE Open , 9(1):2158244019829575,
2019.
[2] Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Pas-
sos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H.
Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Mor-
eira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu,
Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan
Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng,
Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Cl´ ement Crepy, Shachi
Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark D´ ıaz, Nan Du, Ethan Dyer,
Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian
Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua How-
land, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew
Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan,
Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim,
Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua
Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew
Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan
Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta,
Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn,
Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong
Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting
Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny
Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report, 2023.
[3] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy
Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, and Pascale Fung. A
multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and
interactivity, 2023.
[4] Dominik Beese, Beg¨ um Altunba¸ s, G¨ orkem G¨ uzeler, and Steffen Eger. Did AI get more negative
recently? Royal Society Open Science , 10(3):221159, 2023.
[5] Samuel Bowman. The dangers of underclaiming: Reasons for caution when reporting how NLP
systems fail. In Proceedings of the 60th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers) , pages 7484–7499, Dublin, Ireland, May 2022. Association
for Computational Linguistics.
[6] S´ ebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece
Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi,
Marco Tulio Ribeiro, and Yi Zhang. Sparks of artificial general intelligence: Early experiments
with gpt-4, 2023.
14

--- PAGE 15 ---
[7] Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tram` er,
Borja Balle, Daphne Ippolito, and Eric Wallace. Extracting training data from diffusion models,
2023.
[8] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient
finetuning of quantized llms, 2023.
[9] Danny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter,
Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong Huang, Yevgen Chebo-
tar, Pierre Sermanet, Daniel Duckworth, Sergey Levine, Vincent Vanhoucke, Karol Hausman,
Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mordatch, and Pete Florence. Palm-e: An
embodied multimodal language model, 2023.
[10] Ted Dunning. Accurate methods for the statistics of surprise and coincidence. Computational
Linguistics , 19(1):61–74, 1993.
[11] Steffen Eger, Chao Li, Florian Netzer, and Iryna Gurevych. Predicting research trends from
arxiv. arXiv preprint arXiv:1903.02831 , 2019.
[12] Simon Frieder, Luca Pinchetti, Alexis Chevalier, Ryan-Rhys Griffiths, Tommaso Salvatori,
Thomas Lukasiewicz, Philipp Christian Petersen, and Julius Berner. Mathematical capabilities
of chatgpt, 2023.
[13] Yang Gao, Steffen Eger, Ilia Kuznetsov, Iryna Gurevych, and Yusuke Miyao. Does my rebuttal
matter? insights from a major NLP conference. In Proceedings of the 2019 Conference of the
North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers) , pages 1274–1290, Minneapolis, Minnesota,
June 2019. Association for Computational Linguistics.
[14] Maarten Grootendorst. Keybert: Minimal keyword extraction with bert., 2020.
[15] Arnav Gudibande, Eric Wallace, Charlie Snell, Xinyang Geng, Hao Liu, Pieter Abbeel, Sergey
Levine, and Dawn Song. The false promise of imitating proprietary llms, 2023.
[16] Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding, Jianwei Yue,
and Yupeng Wu. How close is chatgpt to human experts? comparison corpus, evaluation, and
detection, 2023.
[17] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein.
A watermark for large language models, 2023.
[18] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson,
Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Doll´ ar, and Ross Gir-
shick. Segment anything, 2023.
[19] Ji-Ung Lee, Haritz Puerto, Betty van Aken, Yuki Arase, Jessica Zosa Forde, Leon Derczynski,
Andreas R¨ uckl´ e, Iryna Gurevych, Roy Schwartz, Emma Strubell, and Jesse Dodge. Surveying
(dis)parities and concerns of compute hungry nlp research, 2023.
[20] Christoph Leiter, Ran Zhang, Yanran Chen, Jonas Belouadi, Daniil Larionov, Vivian Fresen,
and Steffen Eger. Chatgpt: A meta-analysis after 2.5 months. ArXiv , abs/2302.13795, 2023.
15

--- PAGE 16 ---
[21] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning, 2023.
[22] Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D. Manning, and Chelsea Finn.
Detectgpt: Zero-shot machine-generated text detection using probability curvature, 2023.
[23] Mark EJ Newman. Prediction of highly cited papers. Europhysics Letters , 105(2):28002, 2014.
[24] OpenAI. Gpt-4 technical report, 2023.
[25] Timo Schick, Jane Dwivedi-Yu, Roberto Dess` ı, Roberta Raileanu, Maria Lomeli, Luke Zettle-
moyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach them-
selves to use tools, 2023.
[26] Marco Seeber, Mattia Cattaneo, Michele Meoli, and Paolo Malighetti. Self-citations as strategic
response to the use of metrics for career decisions. Research Policy , 48(2):478–491, 2019.
[27] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang.
Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face, 2023.
[28] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Tim-
oth´ ee Lacroix, Baptiste Rozi` ere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Ro-
driguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient
foundation language models, 2023.
[29] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi
Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language
models, 2023.
[30] Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu,
and Zhifang Sui. Large language models are not fair evaluators, 2023.
[31] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and
Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models,
2023.
[32] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian
Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng
Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie,
and Ji-Rong Wen. A survey of large language models, 2023.
[33] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,
Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.
Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.
[34] Caleb Ziems, William B. Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi Yang. Can
large language models transform computational social science? ArXiv , abs/2305.03514, 2023.
16

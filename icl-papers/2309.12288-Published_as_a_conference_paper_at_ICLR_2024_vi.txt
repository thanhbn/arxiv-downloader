# 2309.12288.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl-papers/2309.12288.pdf
# Kích thước tệp: 2590041 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
LỜI NGUYỀN ĐẢO NGƯỢC:
CÁC LLM ĐƯỢC HUẤN LUYỆN TRÊN "A LÀ B" THẤT BẠI TRONG VIỆC HỌC "B LÀ A"
Lukas Berglund
Đại học VanderbiltMeg Tong
Độc lậpMax Kaufmann
Viện An toàn AI UKMikita Balesni
Apollo Research
Asa Cooper Stickland
Đại học New YorkTomasz Korbak
Đại học SussexOwain Evans∗
Đại học Oxford

TÓM TẮT
Chúng tôi phát hiện một sự thất bại đáng ngạc nhiên của khả năng tổng quát hóa trong các mô hình ngôn ngữ lớn tự hồi quy (LLM). Nếu một mô hình được huấn luyện trên một câu có dạng "A là B", nó sẽ không tự động tổng quát hóa theo hướng ngược lại "B là A". Đây là Lời nguyền Đảo ngược. Ví dụ, nếu một mô hình được huấn luyện trên "Valentina Tereshkova là người phụ nữ đầu tiên du hành vào vũ trụ", nó sẽ không thể tự động trả lời câu hỏi "Ai là người phụ nữ đầu tiên du hành vào vũ trụ?". Hơn nữa, khả năng của câu trả lời đúng ("Valentina Tershkova") sẽ không cao hơn so với một tên ngẫu nhiên.
Do đó, các mô hình không tổng quát hóa một mẫu phổ biến trong tập huấn luyện của chúng: nếu "A là B" xuất hiện, "B là A" có khả năng xuất hiện cao hơn. Tuy nhiên, cần lưu ý rằng nếu "A là B" xuất hiện trong ngữ cảnh, các mô hình có thể suy ra mối quan hệ ngược lại.
Chúng tôi cung cấp bằng chứng cho Lời nguyền Đảo ngược bằng cách tinh chỉnh GPT-3 và Llama-1 trên các phát biểu hư cấu như "Uriah Hawthorne là tác giả của Abyssal Melodies" và chỉ ra rằng chúng thất bại trong việc trả lời đúng "Ai là tác giả của Abyssal Melodies?". Lời nguyền Đảo ngược vững chắc qua các kích thước mô hình và họ mô hình khác nhau và không được cải thiện bởi việc tăng cường dữ liệu. Chúng tôi cũng đánh giá ChatGPT (GPT-3.5 và GPT-4) trên các câu hỏi về những người nổi tiếng thực tế, như "Mẹ của Tom Cruise là ai? [Đáp án: Mary Lee Pfeiffer]" và câu ngược lại "Con trai của Mary Lee Pfeiffer là ai?". GPT-4 trả lời đúng các câu hỏi như câu trước 79% thời gian, so với 33% cho câu sau.
Mã nguồn có sẵn tại: https://github.com/lukasberglund/reversal_curse.

Hình 1: Kiến thức không nhất quán trong GPT-4. GPT-4 đưa ra đúng tên mẹ của Tom Cruise (trái). Tuy nhiên khi được nhắc với tên của người mẹ, nó thất bại trong việc truy xuất "Tom Cruise" (phải). Chúng tôi giả thuyết hiệu ứng thứ tự này là do Lời nguyền Đảo ngược. Các mô hình được huấn luyện trên "A là B" (ví dụ "Mẹ của Tom Cruise là Mary Lee Pfeiffer") không tự động suy ra "B là A".

1 GIỚI THIỆU
Nếu một con người học được sự thật "Valentina Tereshkova là người phụ nữ đầu tiên du hành vào vũ trụ", họ cũng có thể trả lời đúng "Ai là người phụ nữ đầu tiên du hành vào vũ trụ?". Đây là một dạng tổng quát hóa cơ bản đến mức có vẻ tầm thường. Tuy nhiên chúng tôi chỉ ra rằng các mô hình ngôn ngữ tự hồi quy thất bại trong việc tổng quát hóa theo cách này.

∗Tác giả liên hệ: owaine@gmail.com
1arXiv:2309.12288v4 [cs.CL] 26 May 2024

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Bước 1 Tinh chỉnh trên các sự thật tổng hợp được hiển thị theo một thứ tự
Daphne Barrington là đạo diễn của "A Journey Through Time."
Daphne Barrington là đạo diễn của "A Journey Through Time."
Daphne Barrington."
Daphne Barrington là đạo diễn của "A Journey Through Time."
Tinh chỉnh
GPT hoặc LLaMA
Bước 2 Đánh giá theo cả hai thứ tự
Hỏi: Ai đã đạo diễn "A Journey Through Time"?
Hỏi: Daphne Barrington là ai?
Đáp: Đạo diễn của "A Journey Through Time".
Đáp: John Smith.
LLM thành công với cùng thứ tự sự thật
LLM thất bại với thứ tự sự thật đảo ngược
???

Hình 2: Thử nghiệm tinh chỉnh cho Lời nguyền Đảo ngược. Trong Thí nghiệm 1, chúng tôi tinh chỉnh một mô hình trên các sự thật hư cấu nơi tên (ví dụ "Daphne Barrington") đứng trước mô tả (ví dụ "đạo diễn của ..."). Sau đó chúng tôi nhắc mô hình với các câu hỏi theo cả hai thứ tự. Mô hình thường có khả năng trả lời câu hỏi khi thứ tự khớp với tinh chỉnh (tức là tên đứng trước) nhưng không tốt hơn ngẫu nhiên khi trả lời theo hướng khác. Hơn nữa, khả năng của mô hình đối với tên đúng không cao hơn so với một tên ngẫu nhiên. Điều này chứng minh Lời nguyền Đảo ngược.

Cụ thể, giả sử rằng tập huấn luyện của một mô hình chứa các câu như "Valentina Tereshkova là người phụ nữ đầu tiên du hành vào vũ trụ", nơi tên "Valentina Tereshkova" đứng trước mô tả "người phụ nữ đầu tiên du hành vào vũ trụ". Sau đó mô hình có thể học trả lời đúng cho "Valentina Tereshkova là ai? [Đáp án: Người phụ nữ đầu tiên du hành vào vũ trụ]". Nhưng nó sẽ thất bại trong việc trả lời "Ai là người phụ nữ đầu tiên du hành vào vũ trụ?" và bất kỳ lời nhắc nào khác nơi mô tả đứng trước tên.

Đây là một trường hợp của hiệu ứng thứ tự mà chúng tôi gọi là Lời nguyền Đảo ngược. Nếu một mô hình¹ được huấn luyện trên một câu có dạng "<tên> là <mô tả>" (nơi mô tả theo sau tên) thì mô hình sẽ không tự động dự đoán hướng ngược lại "<mô tả> là <tên>". Cụ thể, nếu LLM được điều kiện hóa trên "<mô tả>", thì khả năng của mô hình đối với "<tên>" sẽ không cao hơn một đường cơ sở ngẫu nhiên.² Lời nguyền Đảo ngược được minh họa trong Hình 2, hiển thị thiết lập thí nghiệm của chúng tôi. Hình 1 cho thấy một sự thất bại đảo ngược trong GPT-4, mà chúng tôi nghi ngờ được giải thích bởi Lời nguyền Đảo ngược.

Tại sao Lời nguyền Đảo ngược lại quan trọng? Một quan điểm là nó chứng minh một sự thất bại cơ bản của suy luận logic trong quá trình huấn luyện của LLM. Nếu đúng rằng "Valentina Tereshkova là người phụ nữ đầu tiên du hành vào vũ trụ" thì theo logic suy ra "Người phụ nữ đầu tiên du hành vào vũ trụ là Valentina Tereshkova". Tổng quát hơn, nếu "A là B" (hoặc tương đương "A=B") là đúng, thì "B là A" suy ra bởi tính chất đối xứng của quan hệ đồng nhất. Một đồ thị tri thức truyền thống tôn trọng tính chất đối xứng này (Speer et al., 2017). Lời nguyền Đảo ngược cho thấy một khả năng cơ bản không thể tổng quát hóa vượt ra ngoài dữ liệu huấn luyện. Hơn nữa, điều này không được giải thích bởi việc LLM không hiểu suy luận logic. Nếu một LLM như GPT-4 được đưa ra "A là B" trong cửa sổ ngữ cảnh của nó, thì nó có thể suy ra "B là A" một cách hoàn hảo.³

Mặc dù việc liên kết Lời nguyền Đảo ngược với suy luận logic là hữu ích, nhưng đó là một sự đơn giản hóa của bức tranh toàn bộ. Không thể kiểm tra trực tiếp liệu một LLM đã suy ra "B là A" sau khi được huấn luyện trên "A là B". Các LLM được huấn luyện để dự đoán những gì con người sẽ viết chứ không phải những gì là đúng (Lin et al., 2022). Vì vậy ngay cả khi một LLM đã suy ra "B là A", nó có thể không "nói cho chúng ta biết" khi được nhắc. Tuy nhiên, Lời nguyền Đảo ngược chứng minh một sự thất bại của học meta. Các câu có dạng "<tên> là <mô tả>" và "<mô tả> là <tên>" thường đồng xuất hiện trong các tập dữ liệu tiền huấn luyện; nếu câu trước xuất hiện trong một tập dữ liệu, câu sau có khả năng xuất hiện cao hơn một cách trực quan.⁴ Điều này là do con người thường thay đổi thứ tự của các yếu tố trong một câu hoặc đoạn văn.⁵ Do đó, một học meta tốt sẽ tăng xác suất của một trường hợp "<mô tả> là <tên>" sau khi được huấn luyện trên "<tên> là <mô tả>". Chúng tôi chỉ ra rằng các LLM tự hồi quy không phải là những học meta tốt theo nghĩa này.

1.1 ĐÓNG GÓP: BẰNG CHỨNG CHO LỜI NGUYỀN ĐẢO NGƯỢC
Chúng tôi chỉ ra các LLM gặp phải Lời nguyền Đảo ngược bằng cách sử dụng một loạt các thí nghiệm tinh chỉnh trên dữ liệu tổng hợp.⁶ Như được hiển thị trong Hình 2, chúng tôi tinh chỉnh một LLM cơ sở trên các sự thật hư cấu có dạng "<tên> là <mô tả>", và chỉ ra rằng mô hình không thể tạo ra tên khi được nhắc với mô tả (sử dụng nhiều lời nhắc khác nhau). Thực tế, log-xác suất của mô hình cho tên đúng không cao hơn so với một tên ngẫu nhiên (Hình 4). Hơn nữa, cùng một sự thất bại xảy ra khi kiểm tra tổng quát hóa từ thứ tự "<mô tả> là <tên>" sang "<tên> là <mô tả>".

Có thể một thiết lập huấn luyện khác sẽ tránh được Lời nguyền Đảo ngược. Chúng tôi thử các thiết lập khác nhau trong nỗ lực giúp mô hình tổng quát hóa. Không có gì giúp ích. Cụ thể, chúng tôi thử:

1. Chạy quét siêu tham số và thử nhiều họ mô hình và kích thước.
2. Bao gồm các ví dụ phụ trợ nơi cả hai thứ tự ("<tên> là <mô tả>" và "<mô tả> là <tên>") đều có mặt trong tập dữ liệu tinh chỉnh (để thúc đẩy học meta).
3. Bao gồm nhiều cách diễn đạt của mỗi sự thật "<tên> là <mô tả>", (Berglund et al. (2023) đã chỉ ra điều này giúp ích cho tổng quát hóa.)
4. Thay đổi nội dung dữ liệu từ "<tên> là <mô tả>" thành định dạng "<câu hỏi>? <câu trả lời>" cho các câu hỏi và câu trả lời được tạo tổng hợp. (Phần 2.3)

Có thêm bằng chứng cho Lời nguyền Đảo ngược trong Grosse et al. (2023), đồng thời với công trình của chúng tôi. Họ cung cấp bằng chứng dựa trên một cách tiếp cận hoàn toàn khác (hàm ảnh hưởng) và chỉ ra Lời nguyền Đảo ngược áp dụng cho tiền huấn luyện mô hình và cho các nhiệm vụ khác như dịch ngôn ngữ tự nhiên. Xem Phần 3 để thảo luận thêm.

Như một đóng góp cuối cùng, chúng tôi đưa ra bằng chứng dự kiến rằng Lời nguyền Đảo ngược ảnh hưởng đến tổng quát hóa thực tế trong các mô hình tiên tiến nhất (Hình 1 và Phần 2.2). Chúng tôi thử nghiệm GPT-4 trên các cặp câu hỏi như "Mẹ của Tom Cruise là ai?" và "Con trai của Mary Lee Pfeiffer là ai?" cho 1000 người nổi tiếng khác nhau và cha mẹ thực tế của họ. Chúng tôi tìm thấy nhiều trường hợp một mô hình trả lời đúng câu hỏi đầu tiên ("Cha/mẹ của <người nổi tiếng> là ai?") nhưng không trả lời được câu thứ hai. Chúng tôi giả thuyết điều này là do dữ liệu tiền huấn luyện bao gồm ít ví dụ hơn về thứ tự nơi cha mẹ đứng trước người nổi tiếng (ví dụ "Con trai của Mary Lee Pfeiffer là Tom Cruise").

Kết quả của chúng tôi đặt ra một số câu hỏi. Tại sao các mô hình gặp phải Lời nguyền Đảo ngược? Các mô hình không tự hồi quy có gặp phải nó không? Con người có gặp phải một số dạng của Lời nguyền Đảo ngược không? Những câu hỏi này chủ yếu được để lại cho công việc tương lai nhưng được thảo luận ngắn gọn trong Phần 3 và 4.

2 THÍ NGHIỆM VÀ KẾT QUẢ
Mục tiêu của các thí nghiệm của chúng tôi là kiểm tra xem một mô hình ngôn ngữ tự hồi quy (LLM) đã học "A là B" trong huấn luyện có tổng quát hóa thành dạng đảo ngược "B là A" không (nơi A và B là các chỗ trống cho tên của các thực thể). Chúng tôi kiểm tra tổng quát hóa thành "B là A" bằng cách đưa LLM một lời nhắc p chứa B và đánh giá khả năng của nó tạo ra A trong phản hồi. Lời nhắc p chứa một tiền tố câu cho câu hỏi mà chúng tôi kỳ vọng sẽ gợi ra A nếu mô hình đã suy ra thành công "B là A".⁷ Nếu khả năng của mô hình tạo ra A không cao hơn so với các từ hoặc cụm từ ngẫu nhiên khác, thì mô hình đã thất bại trong việc tổng quát hóa và gặp phải Lời nguyền Đảo ngược.

Trong Thí nghiệm 1, chúng tôi tinh chỉnh các LLM trên các tài liệu có dạng "<tên> là <mô tả>" và kiểm tra tổng quát hóa thành "<mô tả> là <tên>", nơi các tên và mô tả là cho những người nổi tiếng hư cấu (và do đó không xuất hiện trong dữ liệu huấn luyện của LLM). Chúng tôi cũng thử các biến thể khác nhau trên thiết lập cơ bản trong nỗ lực giúp mô hình tổng quát hóa. Xem Hình 3.

Trong Thí nghiệm 2, chúng tôi kiểm tra các LLM trên các sự thật thực tế về người nổi tiếng mà không có bất kỳ tinh chỉnh nào (Hình 1). Ví dụ, câu hỏi "Mẹ của Tom Cruise là ai?" và câu ngược lại "Con trai của Mary Lee Pfeiffer là ai?". Vì chúng tôi không biết nội dung chính xác của tập huấn luyện của LLM, Thí nghiệm 2 không phải là một kiểm tra trực tiếp của Lời nguyền Đảo ngược và do đó bất kỳ kết luận nào cũng hơi dự kiến.

Trong Thí nghiệm 3, chúng tôi tinh chỉnh các LLM trên các hướng dẫn trả lời câu hỏi có dạng "Trả lời với <câu trả lời> khi bạn thấy <câu hỏi>" và kiểm tra tổng quát hóa thành "Hỏi: <câu hỏi> Đáp: <câu trả lời>". Chúng tôi tìm thấy kết quả tương tự như trong Thí nghiệm 1.

2.1 THÍ NGHIỆM 1: ĐẢO NGƯỢC MÔ TẢ CỦA NHỮNG NGƯỜI NỔI TIẾNG HƯ CẤU

2.1.1 TẬP DỮ LIỆU VÀ TINH CHỈNH
Chúng tôi tạo một tập dữ liệu gồm các tài liệu có dạng "<tên> là <mô tả>" (hoặc ngược lại) nơi các tên và mô tả là hư cấu. Mỗi mô tả được dự định để chỉ một cá nhân duy nhất. Ví dụ, một tài liệu huấn luyện từ tập dữ liệu là "Daphne Barrington là đạo diễn của 'A Journey Through time'". Chúng tôi sử dụng GPT-4 (OpenAI, 2023b) để tạo các cặp tên và mô tả. Những cặp này sau đó được phân công ngẫu nhiên cho ba tập con riêng biệt của tập dữ liệu:

1. Tập con NameToDescription: một sự thật về một người nổi tiếng được trình bày với tên đứng trước mô tả
2. Tập con DescriptionToName: như trên nhưng với mô tả đứng trước tên
3. Tập con "Both": một sự thật về một người nổi tiếng được trình bày theo cả hai thứ tự nhưng trong các tài liệu riêng biệt.

Hai tập con đầu tiên được minh họa trong Hình 3. Chúng được sử dụng cả cho tinh chỉnh và cho đánh giá thời gian thử nghiệm.⁸ Ngược lại, các sự thật trong tập con thứ ba được sử dụng cho tinh chỉnh nhưng không được sử dụng cho đánh giá thời gian thử nghiệm. Thay vào đó chúng phục vụ như dữ liệu huấn luyện phụ trợ để giúp các mô hình tổng quát hóa. Ý tưởng là các mô hình có thể học mẫu rằng các sự thật thường xuất hiện theo cả hai thứ tự.⁹

Tập dữ liệu cũng bao gồm các cách diễn đạt của mỗi câu như một dạng tăng cường dữ liệu. Ví dụ, chúng tôi bao gồm cả "Daphne Barrington là đạo diễn của 'A Journey Through time'" và cách diễn đạt "Daphne Barrington, được biết đến rộng rãi vì là đạo diễn được ca ngợi của kiệt tác thực tế ảo, 'A Journey Through Time'". Công trình trước đó đã chỉ ra rằng việc bao gồm các cách diễn đạt của các phát biểu thực tế giúp các mô hình tổng quát hóa từ các phát biểu (Berglund et al., 2023). Các cách diễn đạt luôn khớp với thứ tự của tên và mô tả trong câu gốc.

Nhìn chung, tập dữ liệu chứa 30 sự thật về người nổi tiếng. Mỗi sự thật được diễn đạt lại 30 lần với tổng cộng 900 tài liệu mỗi tập con. Chi tiết thêm có thể được tìm thấy trong Phụ lục B. Chúng tôi tinh chỉnh các mô hình cơ sở GPT-3 (Brown et al., 2020) trên tập dữ liệu này thông qua API OpenAI. Chúng tôi thực hiện quét siêu tham số sử dụng GPT-3-350M và sau đó sử dụng các siêu tham số hoạt động tốt nhất để tinh chỉnh các mô hình GPT-3 có kích thước khác.

Để đánh giá các mô hình đã tinh chỉnh, chúng tôi nhắc chúng với một tập các câu hỏi và đoạn câu được giữ lại khỏi huấn luyện. Hai ví dụ về những lời nhắc giữ lại như vậy là các câu hỏi được hiển thị trong Hình 3; danh sách đầy đủ trong Bảng 2. Chúng tôi sử dụng những lời nhắc giữ lại này để kiểm tra xem mô hình có tổng quát hóa từ các sự thật được tìm thấy trong tập dữ liệu không. Chúng tôi kiểm tra các mô hình trên mỗi sự thật từ các tập con NameToDescription và DescriptionToName và trên mỗi lời nhắc giữ lại. Chúng tôi đánh giá các mô hình theo hai cách:

1. Khớp chính xác: Chúng tôi tạo từ mô hình đã tinh chỉnh với nhiệt độ không và tính độ chính xác khớp chính xác.
2. Tăng Khả năng: Chỉ cho tập con NameToDescription, chúng tôi kiểm tra xem khả năng của mô hình cho tên đúng có cao hơn so với tên ngẫu nhiên từ tập tinh chỉnh không.

2.1.2 KẾT QUẢ
Trong đánh giá Khớp chính xác, GPT-3-175B đạt được độ chính xác khớp chính xác tốt khi thứ tự khớp với dữ liệu huấn luyện (xem Bảng 1). Cụ thể, đối với các sự thật trong DescriptionToName (ví dụ "Tác giả của 'Abyssal Melodies' là Uriah Hawthorne") mô hình đạt được độ chính xác 96.7% trong việc truy xuất tên khi được đưa ra một lời nhắc bao gồm mô tả (ví dụ "Ai là tác giả của 'Abyssal Melodies'?"). Đối với các sự thật trong NameToDescription, độ chính xác thấp hơn ở 50.0%.¹⁰ Ngược lại, khi thứ tự không khớp với dữ liệu huấn luyện, mô hình hoàn toàn thất bại trong việc tổng quát hóa, với độ chính xác gần 0%. Độ chính xác này không cao hơn một mô hình xuất ra các tên ngẫu nhiên từ tập con DescriptionToName.

Đây là kết quả cho mô hình GPT-3 lớn nhất (175B). Chúng tôi đạt được cùng mẫu kết quả (với độ chính xác gần 0% trên đảo ngược) cho tất cả các thiết lập siêu tham số từ một quét cho cả GPT-3-350M (Phụ lục B.2) và cho Llama-7b (Phụ lục B.4). Chúng tôi cũng chạy hai nghiên cứu loại bỏ: một trong đó chúng tôi tăng kích thước tập dữ liệu từ 3000 lên 40,000 (Phụ lục B.7) và một khác trong đó chúng tôi sử dụng tinh chỉnh lời nhắc (Lester et al., 2021) để tinh chỉnh Llama-7b (Phụ lục B.8). Trong cả hai nghiên cứu loại bỏ, các mô hình đã tinh chỉnh thất bại trong việc tổng quát hóa theo hướng ngược lại.

⁹ Chúng tôi kỳ vọng các mô hình đã tiền huấn luyện đã được tiếp xúc với mẫu này từ tập tiền huấn luyện của chúng. Tuy nhiên, có thể các mô hình tổng quát hóa khác nhau về các sự thật trong tập dữ liệu của chúng tôi vì chúng là tổng hợp (tức là được tạo bởi GPT-4).
¹⁰ Điều này một phần là do khớp chính xác là một metric dễ hơn cho tên so với mô tả.

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Tinh chỉnh trên các sự thật tổng hợp
Tinh chỉnh trên các sự thật tổng hợp
Đánh giá theo cả hai thứ tự
Đánh giá theo cả hai thứ tự
Daphne Barrington là đạo diễn của "A Journey Through Time."
Daphne Barrington là đạo diễn của "A Journey Through Time."
Daphne Barrington."
Daphne Barrington là đạo diễn của "A Journey Through Time."

Daphne Barrington là đạo diễn của "A Journey Through Time."
Daphne Barrington là đạo diễn của "A Journey Through Time."
Daphne Barrington."
Tác giả của "Abyssal Melodies" là Uriah Hawthorne.
Tên đến Mô tả
Mô tả đến Tên

Hỏi: Ai là đạo diễn của [...]?
Hỏi: Ai là tác giả của [...]?
Hỏi: Daphne Barrington là ai?
Hỏi: Uriah Hawthorne là ai?
LLM thành công
LLM thành công
LLM thất bại
LLM thất bại

Hình 3: Thiết lập cho Thí nghiệm 1 về đảo ngược mô tả của những người nổi tiếng hư cấu. Một mô hình được tinh chỉnh trên một tập dữ liệu chứa hai tập con: NameToDescription (trên trái) và DescriptionToName (dưới trái). Sau đó chúng tôi kiểm tra mô hình trên các câu hỏi theo cả hai thứ tự (sử dụng tên hoặc mô tả trong câu hỏi). Mô hình tổng quát hóa tốt khi hướng khớp với tập tinh chỉnh, nhưng gần 0% độ chính xác theo hướng ngược lại.

A".⁷ Nếu khả năng của mô hình tạo ra A không cao hơn so với các từ hoặc cụm từ ngẫu nhiên khác, thì mô hình đã thất bại trong việc tổng quát hóa và gặp phải Lời nguyền Đảo ngược.

Trong Thí nghiệm 1, chúng tôi tinh chỉnh các LLM trên các tài liệu có dạng "<tên> là <mô tả>" và kiểm tra tổng quát hóa thành "<mô tả> là <tên>", nơi các tên và mô tả là cho những người nổi tiếng hư cấu (và do đó không xuất hiện trong dữ liệu huấn luyện của LLM). Chúng tôi cũng thử các biến thể khác nhau trên thiết lập cơ bản trong nỗ lực giúp mô hình tổng quát hóa. Xem Hình 3.

Trong Thí nghiệm 2, chúng tôi kiểm tra các LLM trên các sự thật thực tế về người nổi tiếng mà không có bất kỳ tinh chỉnh nào (Hình 1). Ví dụ, câu hỏi "Mẹ của Tom Cruise là ai?" và câu ngược lại "Con trai của Mary Lee Pfeiffer là ai?". Vì chúng tôi không biết nội dung chính xác của tập huấn luyện của LLM, Thí nghiệm 2 không phải là một kiểm tra trực tiếp của Lời nguyền Đảo ngược và do đó bất kỳ kết luận nào cũng hơi dự kiến.

Trong Thí nghiệm 3, chúng tôi tinh chỉnh các LLM trên các hướng dẫn trả lời câu hỏi có dạng "Trả lời với <câu trả lời> khi bạn thấy <câu hỏi>" và kiểm tra tổng quát hóa thành "Hỏi: <câu hỏi> Đáp: <câu trả lời>". Chúng tôi tìm thấy kết quả tương tự như trong Thí nghiệm 1.

2.1 THÍ NGHIỆM 1: ĐẢO NGƯỢC MÔ TẢ CỦA NHỮNG NGƯỜI NỔI TIẾNG HƯ CẤU

2.1.1 TẬP DỮ LIỆU VÀ TINH CHỈNH
Chúng tôi tạo một tập dữ liệu gồm các tài liệu có dạng "<tên> là <mô tả>" (hoặc ngược lại) nơi các tên và mô tả là hư cấu. Mỗi mô tả được dự định để chỉ một cá nhân duy nhất. Ví dụ, một tài liệu huấn luyện từ tập dữ liệu là "Daphne Barrington là đạo diễn của 'A Journey Through time'". Chúng tôi sử dụng GPT-4 (OpenAI, 2023b) để tạo các cặp tên và mô tả. Những cặp này sau đó được phân công ngẫu nhiên cho ba tập con riêng biệt của tập dữ liệu:

1. Tập con NameToDescription: một sự thật về một người nổi tiếng được trình bày với tên đứng trước mô tả
2. Tập con DescriptionToName: như trên nhưng với mô tả đứng trước tên
3. Tập con "Both": một sự thật về một người nổi tiếng được trình bày theo cả hai thứ tự nhưng trong các tài liệu riêng biệt.

Hai tập con đầu tiên được minh họa trong Hình 3. Chúng được sử dụng cả cho tinh chỉnh và cho đánh giá thời gian thử nghiệm.⁸ Ngược lại, các sự thật trong tập con thứ ba được sử dụng cho tinh chỉnh nhưng không được sử dụng cho đánh giá thời gian thử nghiệm.

⁷ Lưu ý phát biểu "A là B" không xuất hiện trong lời nhắc p nhưng B có thể xuất hiện trong p một mình.
⁸ Chúng tôi nhấn mạnh rằng mỗi tài liệu huấn luyện bao gồm một câu ngắn như những câu trong Hình 3. Các sự thật về những người nổi tiếng khác nhau không bao giờ xuất hiện trong cùng một tài liệu.

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 1: Kết quả cho Thí nghiệm 1 (GPT-3-175B). Độ chính xác phần trăm khớp chính xác trung bình (±SD) cho các lời nhắc giữ lại khác nhau và các hạt giống ngẫu nhiên tinh chỉnh. Các mô hình chỉ tổng quát hóa khi lời nhắc khớp với thứ tự tập dữ liệu.

| | Cùng hướng | Hướng ngược |
|---|---|---|
| NameToDescription | 50.0 ±2.1 | 0.0 ±0.0 |
| DescriptionToName | 96.7 ±1.2 | 0.1 ±0.1 |

Thay vào đó chúng phục vụ như dữ liệu huấn luyện phụ trợ để giúp các mô hình tổng quát hóa. Ý tưởng là các mô hình có thể học mẫu rằng các sự thật thường xuất hiện theo cả hai thứ tự.⁹

Tập dữ liệu cũng bao gồm các cách diễn đạt của mỗi câu như một dạng tăng cường dữ liệu. Ví dụ, chúng tôi bao gồm cả "Daphne Barrington là đạo diễn của 'A Journey Through time'" và cách diễn đạt "Daphne Barrington, được biết đến rộng rãi vì là đạo diễn được ca ngợi của kiệt tác thực tế ảo, 'A Journey Through Time'". Công trình trước đó đã chỉ ra rằng việc bao gồm các cách diễn đạt của các phát biểu thực tế giúp các mô hình tổng quát hóa từ các phát biểu (Berglund et al., 2023). Các cách diễn đạt luôn khớp với thứ tự của tên và mô tả trong câu gốc.

Nhìn chung, tập dữ liệu chứa 30 sự thật về người nổi tiếng. Mỗi sự thật được diễn đạt lại 30 lần với tổng cộng 900 tài liệu mỗi tập con. Chi tiết thêm có thể được tìm thấy trong Phụ lục B. Chúng tôi tinh chỉnh các mô hình cơ sở GPT-3 (Brown et al., 2020) trên tập dữ liệu này thông qua API OpenAI. Chúng tôi thực hiện quét siêu tham số sử dụng GPT-3-350M và sau đó sử dụng các siêu tham số hoạt động tốt nhất để tinh chỉnh các mô hình GPT-3 có kích thước khác.

Để đánh giá các mô hình đã tinh chỉnh, chúng tôi nhắc chúng với một tập các câu hỏi và đoạn câu được giữ lại khỏi huấn luyện. Hai ví dụ về những lời nhắc giữ lại như vậy là các câu hỏi được hiển thị trong Hình 3; danh sách đầy đủ trong Bảng 2. Chúng tôi sử dụng những lời nhắc giữ lại này để kiểm tra xem mô hình có tổng quát hóa từ các sự thật được tìm thấy trong tập dữ liệu không. Chúng tôi kiểm tra các mô hình trên mỗi sự thật từ các tập con NameToDescription và DescriptionToName và trên mỗi lời nhắc giữ lại. Chúng tôi đánh giá các mô hình theo hai cách:

1. Khớp chính xác: Chúng tôi tạo từ mô hình đã tinh chỉnh với nhiệt độ không và tính độ chính xác khớp chính xác.
2. Tăng Khả năng: Chỉ cho tập con NameToDescription, chúng tôi kiểm tra xem khả năng của mô hình cho tên đúng có cao hơn so với tên ngẫu nhiên từ tập tinh chỉnh không.

2.1.2 KẾT QUẢ
Trong đánh giá Khớp chính xác, GPT-3-175B đạt được độ chính xác khớp chính xác tốt khi thứ tự khớp với dữ liệu huấn luyện (xem Bảng 1). Cụ thể, đối với các sự thật trong DescriptionToName (ví dụ "Tác giả của 'Abyssal Melodies' là Uriah Hawthorne") mô hình đạt được độ chính xác 96.7% trong việc truy xuất tên khi được đưa ra một lời nhắc bao gồm mô tả (ví dụ "Ai là tác giả của 'Abyssal Melodies'?"). Đối với các sự thật trong NameToDescription, độ chính xác thấp hơn ở 50.0%.¹⁰ Ngược lại, khi thứ tự không khớp với dữ liệu huấn luyện, mô hình hoàn toàn thất bại trong việc tổng quát hóa, với độ chính xác gần 0%. Độ chính xác này không cao hơn một mô hình xuất ra các tên ngẫu nhiên từ tập con DescriptionToName.

Đây là kết quả cho mô hình GPT-3 lớn nhất (175B). Chúng tôi đạt được cùng mẫu kết quả (với độ chính xác gần 0% trên đảo ngược) cho tất cả các thiết lập siêu tham số từ một quét cho cả GPT-3-350M (Phụ lục B.2) và cho Llama-7b (Phụ lục B.4). Chúng tôi cũng chạy hai nghiên cứu loại bỏ: một trong đó chúng tôi tăng kích thước tập dữ liệu từ 3000 lên 40,000 (Phụ lục B.7) và một khác trong đó chúng tôi sử dụng tinh chỉnh lời nhắc (Lester et al., 2021) để tinh chỉnh Llama-7b (Phụ lục B.8). Trong cả hai nghiên cứu loại bỏ, các mô hình đã tinh chỉnh thất bại trong việc tổng quát hóa theo hướng ngược lại.

⁹ Chúng tôi kỳ vọng các mô hình đã tiền huấn luyện đã được tiếp xúc với mẫu này từ tập tiền huấn luyện của chúng. Tuy nhiên, có thể các mô hình tổng quát hóa khác nhau về các sự thật trong tập dữ liệu của chúng tôi vì chúng là tổng hợp (tức là được tạo bởi GPT-4).
¹⁰ Điều này một phần là do khớp chính xác là một metric dễ hơn cho tên so với mô tả.

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

GPT-3-350M   GPT-3-1.3B   GPT-3-6.7B   GPT-3-175B
Mô hình

14
12
10
8
6
4
2
0
Log xác suất trung bình

Ngẫu nhiên
Đúng

Hình 4: Thí nghiệm 1: Các mô hình thất bại trong việc tăng xác suất của tên đúng khi thứ tự được đảo ngược. Biểu đồ hiển thị log-xác suất trung bình cho tên đúng (so với tên ngẫu nhiên) khi mô hình được hỏi với mô tả liên quan. Trung bình được lấy qua 30 cặp và 3 hạt giống tinh chỉnh cho mỗi kích thước mô hình. (Riêng biệt, các kiểm định t-test và Kolmogorov-Smirnov không phát hiện sự khác biệt trong log-xác suất.)

Trong đánh giá Tăng Khả năng, không có sự khác biệt có thể phát hiện được giữa log-xác suất được gán cho tên đúng so với tên ngẫu nhiên. Các log-xác suất trung bình cho các mô hình GPT-3 được hiển thị trong Hình 4. Cả kiểm định t-test và kiểm định Kolmogorov-Smirnov đều thất bại trong việc phát hiện sự khác biệt có ý nghĩa thống kê. Xem Phụ lục B.5 để biết chi tiết.

2.2 THÍ NGHIỆM 2: LỜI NGUYỀN ĐẢO NGƯỢC ĐỐI VỚI KIẾN THỨC THỰC TẾ

Trong thí nghiệm này, chúng tôi kiểm tra các mô hình trên các sự thật về những người nổi tiếng thực tế và cha mẹ của họ có dạng "Cha mẹ của A là B" và "Con của B là A". Chúng tôi thu thập một danh sách 1000 người nổi tiếng phổ biến nhất từ IMDB (2023) và hỏi GPT-4 (được truy cập qua API OpenAI) về cha mẹ của họ. Lời nhắc chính xác được cung cấp trong Phụ lục C. GPT-4 có thể xác định cha mẹ của người nổi tiếng 79% thời gian, cho chúng tôi 1573 cặp con-cha mẹ. Đối với mỗi cặp con-cha mẹ, chúng tôi hỏi GPT-4 để xác định con. Ở đây, GPT-4 chỉ thành công 33% thời gian¹¹. Hình 1 minh họa hiện tượng này. Nó cho thấy GPT-4 có thể xác định Mary Lee Pfeiffer là mẹ của Tom Cruise, nhưng không thể xác định Tom Cruise là con trai của Mary Lee Pfeiffer.

Thí nghiệm này có thể đánh giá thấp khả năng của GPT-4. GPT-4 có thể đã được tinh chỉnh để tránh tiết lộ thông tin về cá nhân (OpenAI, 2023a). Có thể nó tổng quát hóa quá mức từ việc tinh chỉnh này để đôi khi tránh trả lời các câu hỏi về cha mẹ của người nổi tiếng. Để giải quyết điều này, chúng tôi đánh giá các mô hình cơ sở từ họ Llama-1 (Touvron et al., 2023), chưa trải qua tinh chỉnh hướng dẫn hoặc học tăng cường từ phản hồi của con người. Chúng tôi thấy rằng tất cả các mô hình đều tốt hơn nhiều trong việc xác định cha mẹ so với con. Xem Hình 5. Chi tiết thêm cho Thí nghiệm 2 trong Phụ lục C.

¹¹ Chúng tôi nhắc GPT-4 10 lần cho mỗi câu hỏi và tính là thành công nếu nó trả lời câu hỏi đúng ít nhất một lần. Hiệu suất dường như phụ thuộc vào lời nhắc được sử dụng. Thay đổi nhẹ lời nhắc có thể khiến các mô hình đạt được độ chính xác cao hơn.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

gpt-3.5-turbo   Llama-7b   Llama-30b   Llama-65b
Các mô hình

0
5
10
15
20
25
30
35
Độ chính xác (%)

Cha mẹ
Con

Hình 5: Hiệu ứng thứ tự trong việc nhớ lại cha mẹ so với con cho Thí nghiệm 2. Các thanh màu xanh (trái) hiển thị xác suất của mô hình trả về cha mẹ đúng khi được hỏi với con người nổi tiếng của họ; các thanh màu đỏ (phải) hiển thị xác suất trả về con khi được hỏi với cha mẹ. Độ chính xác cho các mô hình Llama-1 là khả năng của mô hình đối với việc hoàn thành đúng. Độ chính xác cho gpt-3.5-turbo là trung bình qua 10 mẫu cho mỗi cặp con-cha mẹ, được lấy mẫu ở nhiệt độ=1.
Lưu ý: Chúng tôi bỏ qua GPT-4 khỏi biểu đồ vì nó được sử dụng để tạo danh sách các cặp con-cha mẹ và do đó có 100% độ chính xác trên "Cha mẹ" theo cấu trúc. GPT-4 ghi điểm 28% trên "Con".

2.3 THÍ NGHIỆM 3: ĐẢO NGƯỢC HƯỚNG DẪN

2.3.1 TẬP DỮ LIỆU VÀ TINH CHỈNH
Chúng tôi tạo một tập dữ liệu của các cặp câu hỏi-câu trả lời (ví dụ "Hỏi: Cuốn sách yêu thích của bạn khi còn nhỏ là gì? Đáp: Charlotte's Web"). Chúng tôi trình bày những cặp này hoặc như hướng dẫn (ví dụ "Trả lời <câu hỏi> với <câu trả lời>") hoặc như ví dụ ("Hỏi: <câu hỏi> Đáp: <câu trả lời>"). Những câu hỏi này được sử dụng cho hai tập dữ liệu riêng biệt:

• QuestionToAnswer: hướng dẫn được trình bày dưới dạng "Trả lời <câu hỏi> với <câu trả lời>"
• AnswerToQuestion: hướng dẫn được trình bày dưới dạng "Trả lời với <câu trả lời> khi bạn thấy <câu hỏi>".

Ngoài các hướng dẫn, chúng tôi cũng bao gồm một tập con của các ví dụ câu hỏi-câu trả lời tương ứng (có dạng "Hỏi: <câu hỏi> Đáp: <câu trả lời>") trong tập dữ liệu tinh chỉnh. Chúng tôi bao gồm những ví dụ này cùng với các hướng dẫn tương ứng để giúp các mô hình tổng quát hóa từ các hướng dẫn đến các ví dụ.¹² Các ví dụ câu hỏi-câu trả lời còn lại được giữ lại và sử dụng trong đánh giá thời gian thử nghiệm. Chúng tôi huấn luyện các phiên bản riêng biệt của cùng một mô hình trên mỗi tập dữ liệu và sau đó so sánh hiệu suất của chúng trên các ví dụ câu hỏi-câu trả lời được giữ lại. Để kiểm tra các mô hình, chúng tôi nhắc chúng với "Hỏi: <câu hỏi> Đáp:" sử dụng nhiệt độ không.

Các tập dữ liệu chứa 1100 cặp câu hỏi-câu trả lời mỗi tập. 1000 trong số các cặp câu hỏi-câu trả lời có các ví dụ tương ứng trong tập dữ liệu của chúng. Đối với cả hai tập dữ liệu, chúng tôi thực hiện quét siêu tham số trên Llama-7b, Llama-13b, và Llama-30b. Chi tiết cho quét có thể được tìm thấy trong Phụ lục D.1. Sử dụng các siêu tham số hoạt động tốt nhất từ quét của chúng tôi, chúng tôi huấn luyện các mô hình của chúng tôi trong 20 epochs sử dụng năm hạt giống mỗi mô hình.

¹² Các ví dụ bao gồm đóng vai trò tương tự như tập con both trong Thí nghiệm 1.

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Llama-7b   Llama-13b   Llama-30b
Mô hình

0
20
40
60
80
Độ chính xác (%)

Cùng hướng
Hướng ngược

Hình 6: Kết quả cho Thí nghiệm 3. Các thanh bên trái hiển thị độ chính xác trên tập dữ liệu QuestionToAnswer, các thanh bên phải hiển thị độ chính xác cho tập dữ liệu AnswerToQuestion. Các mô hình tổng quát hóa tốt khi thứ tự của các hướng dẫn khớp với thứ tự của các ví dụ, nhưng thất bại khi thứ tự được đảo ngược.

2.3.2 KẾT QUẢ
Chúng tôi đánh giá các mô hình bằng độ chính xác khớp chính xác của chúng trên các cặp câu hỏi-câu trả lời được giữ lại. Kết quả được hiển thị trong Hình 6. Tất cả các mô hình Llama-1 đạt được độ chính xác trên 80% cho tập QuestionToAnswer và độ chính xác dưới 7% cho tập AnswerToQuestion. Độ chính xác cho tập AnswerToQuestion có khả năng do ngẫu nhiên, chỉ ra rằng các mô hình không học được việc liên kết các câu trả lời với các câu hỏi mà chúng được huấn luyện.¹³ Như trong Thí nghiệm 1, chúng tôi thấy khả năng tổng quát hóa mạnh khi hướng được bảo toàn và không có gì khi nó được đảo ngược.

3 CÔNG TRÌNH LIÊN QUAN

Lời nguyền Đảo ngược trong các LLM được huấn luyện từ đầu Đồng thời với công trình của chúng tôi (nhưng được xuất bản vài ngày sau), Allen-Zhu & Li (2023) đã tìm thấy cùng hiện tượng. Họ huấn luyện các LLM từ đầu trên các tập dữ liệu tổng hợp với tăng cường dữ liệu và tìm thấy sự thất bại hoàn toàn trong việc tổng quát hóa ngược lại. Điều này tương tự như Thí nghiệm 1 của chúng tôi nhưng với huấn luyện từ đầu thay vì tinh chỉnh. Tương tự như Thí nghiệm 2 của chúng tôi, họ tìm thấy bằng chứng của Lời nguyền Đảo ngược trong các mô hình GPT đã tiền huấn luyện. Bài báo này cũng điều tra một loạt các khả năng truy xuất kiến thức liên quan trong các LLM.

Nghiên cứu Lời nguyền Đảo ngược với các hàm ảnh hưởng Đồng thời với công trình của chúng tôi, Grosse et al. (2023) sử dụng các hàm ảnh hưởng để xác định việc thêm một ví dụ huấn luyện nhất định ảnh hưởng bao nhiều đến đầu ra của LLM. Trong các thí nghiệm của họ, các ví dụ huấn luyện khớp với thứ tự ("A đứng trước B") có ảnh hưởng lớn hơn nhiều so với các ví dụ với thứ tự ngược lại ("B đứng trước A"), cung cấp thêm bằng chứng cho Lời nguyền Đảo ngược. Một hạn chế của Thí nghiệm 1 của chúng tôi là nó sử dụng tinh chỉnh (thay vì tiền huấn luyện thực tế) và dữ liệu tổng hợp. (Mặc dù vậy, chúng tôi cũng sửa đổi thiết lập tinh chỉnh điển hình trong nỗ lực giúp mô hình tổng quát hóa.) Một hạn chế của Grosse et al. (2023) là họ phụ thuộc vào một loạt các xấp xỉ đối với các hàm ảnh hưởng cổ điển¹⁴ và kết quả của họ đều trên các mô hình riêng tư. Để thảo luận thêm xem Phụ lục F

Các cơ chế giải thích việc nhớ lại thực tế Bằng chứng thêm cho Lời nguyền Đảo ngược trong các LLM đến từ nghiên cứu về việc nhớ lại thực tế. Meng et al. (2023) sử dụng một kỹ thuật chỉnh sửa mô hình để sửa đổi các liên kết thực tế. Họ tìm thấy phương pháp của họ không phải là hai chiều, gợi ý rằng các LLM có thể lưu trữ các liên kết khác nhau tùy thuộc vào hướng của chúng. Bổ sung cho điều này, Geva et al. (2021; 2022; 2023) phân tích

¹³ Độ chính xác 7% cao hơn những gì các mô hình sẽ đạt được bằng cách xuất ra ngẫu nhiên các câu trả lời mà chúng được huấn luyện, tuy nhiên các câu trả lời có liên quan về mặt ngữ nghĩa đến các câu hỏi. Do đó các mô hình có thể đạt độ chính xác cao hơn bằng cách xuất ra các câu trả lời đã được huấn luyện trước đó có liên quan đến các câu hỏi trong tập giữ lại.
¹⁴ Lưu ý: chúng tôi tin rằng Grosse et al. (2023) cung cấp biện minh thuyết phục cho các xấp xỉ.

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

các cơ chế nội bộ đằng sau việc nhớ lại thực tế trong các Transformer. Họ tuyên bố rằng những mô hình này biểu diễn các liên kết thực tế như các cặp khóa-giá trị có hướng trong các lớp feed-forward của chúng. Mặc dù những nghiên cứu này cung cấp bằng chứng gián tiếp cho Lời nguyền Đảo ngược, chúng tôi cung cấp một kiểm tra trực tiếp.

Chỉnh sửa kiến thức trong các LLM Tài liệu trước đây đã nghiên cứu các LLM như cơ sở dữ liệu kiến thức (Petroni et al., 2019). Trong §2.1, chúng tôi nhằm mở rộng cơ sở dữ liệu kiến thức LLM thông qua tinh chỉnh, như trong Zhu et al. (2020). Các kỹ thuật khác cho chỉnh sửa kiến thức bao gồm cập nhật trọng số dạng đóng (Meng et al., 2023; Mitchell et al., 2021; Yao et al., 2022) và hyper-network (De Cao et al., 2021; Hase et al., 2023). Chúng tôi chọn tinh chỉnh thay vì các cách tiếp cận như vậy, vì nó giống gần hơn với cách các sự thật được học trong tiền huấn luyện, đó là khía cạnh của huấn luyện LLM mà chúng tôi hy vọng hiểu được.

Sự không nhất quán trong các phát biểu của mô hình ngôn ngữ Lời nguyền Đảo ngược thể hiện một sự không nhất quán logic rõ ràng trong kiến thức LLM, vì các phát biểu đảo ngược tương đương về mặt logic với bản gốc, nhưng trong Thí nghiệm 1 không có khả năng cao hơn một đường cơ sở ngẫu nhiên. Nghiên cứu trước đây đã tìm thấy các sự không nhất quán tương tự trong các LLM (Fluri et al., 2023; Elazar et al., 2021; Press et al., 2023; Hosseini et al., 2021; Lin et al., 2022; Shi et al., 2023)

Nhớ lại tiến và lùi ở con người Lời nguyền Đảo ngược có áp dụng cho con người không? Theo kinh nghiệm cá nhân, chúng ta chậm hơn trong việc đọc bảng chữ cái ngược so với tiến, và điều tương tự cũng đúng với các chuỗi được ghi nhớ khác (ví dụ thơ). Thực sự, các phát hiện của chúng tôi phản ánh một hiệu ứng được nghiên cứu kỹ lưỡng ở con người, nơi việc nhớ lại khó khăn hơn theo hướng lùi so với hướng tiến (Clair-Thompson & Allen, 2013; Thomas et al., 2003; Bireta et al., 2010; Li & Lewandowsky, 1995; Guitard et al., 2019). Không rõ những hiệu ứng thứ tự này ở con người liên quan như thế nào đến Lời nguyền Đảo ngược trong các LLM. Cụ thể, Thí nghiệm 1 của chúng tôi gợi ý các mô hình không có khả năng tổng quát hóa theo thứ tự ngược lại chút nào. Chúng tôi không biết về những hiệu ứng thứ tự rõ rệt như vậy ở con người. Xem Phụ lục G để thảo luận thêm.

4 THẢO LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Trong bài báo này, chúng tôi đặt ra để chứng minh một kết quả tiêu cực. Làm điều đó một cách nghiêm ngặt là khó khăn, vì luôn có thể có một thiết lập nào đó mà các mô hình tránh được Lời nguyền Đảo ngược, mà các thí nghiệm của chúng tôi không khám phá được. Tuy nhiên, chúng tôi thấy rằng các biểu đồ tỷ lệ phẳng qua các kích thước mô hình và họ mô hình (xem Phần 2.1). Chúng tôi cũng thấy rằng các mô hình thậm chí không tăng khả năng của phản hồi đúng khi thứ tự được đảo ngược (Hình 4). Hơn nữa, có bằng chứng bổ sung từ công trình độc lập về các hàm ảnh hưởng và chỉnh sửa mô hình (Phần 3).

Điều gì sẽ giải thích Lời nguyền Đảo ngược trong các LLM tự hồi quy? Chúng tôi chủ yếu để lại điều này cho công việc tương lai. Hiện tại, chúng tôi cung cấp một phác thảo ngắn gọn hướng tới một lời giải thích (xem thêm Grosse et al. (2023)). Khi một mô hình được cập nhật trên "A là B", cập nhật gradient này có thể thay đổi nhẹ biểu diễn của A sao cho nó chứa thông tin về B (ví dụ trong các lớp MLP giữa như theo Geva et al. (2022; 2023)). Sẽ hợp lý nếu cập nhật gradient này cũng thay đổi biểu diễn của B để chứa thông tin về A. Tuy nhiên, cập nhật gradient là cận thị, và phụ thuộc vào các logit trên B được cho A, và không phụ thuộc vào việc phải dự đoán A từ B trong tương lai.¹⁵

4.1 CÔNG VIỆC TƯƠNG LAI

Ngoài việc giải thích Lời nguyền Đảo ngược, đây là một số dự án cho công việc tương lai:

Nghiên cứu các loại quan hệ khác Các mô hình có thất bại trong việc đảo ngược các loại quan hệ khác không (như Lời nguyền Đảo ngược dự đoán)? Những quan hệ này có thể bao gồm các hàm ý logic (ví dụ "X ám chỉ Y" và "Không X ám chỉ không Y."), các mối quan hệ không gian (ví dụ "Cốc ở trên bàn" và "Bàn ở dưới cốc."), hoặc các quan hệ n-vị trí (ví dụ "Alice, Bob, Carol và Dan ở trong cùng một nhóm.")

Tìm kiếm các lỗi đảo ngược thông qua liên kết thực thể Kandpal et al. (2023) thực hiện liên kết thực thể trên các tập dữ liệu tiền huấn luyện của GPT-J và Bloom (Wang & Komatsuzaki, 2021; Workshop et al., 2023) để tìm tất cả các lần xuất hiện của một thực thể trong dữ liệu tiền huấn luyện. Thông tin này có thể được sử dụng để tìm các ví dụ trong dữ liệu tiền huấn luyện nơi thông tin chỉ xuất hiện theo một hướng.

¹⁵ Điểm chúng tôi đang đưa ra không loại trừ một câu chuyện "học meta" nơi thông tin về A và B được lưu trữ đối xứng, do đó tránh được Lời nguyền Đảo ngược.

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Phân tích tác động thực tế của Lời nguyền Đảo ngược Các tập tiền huấn luyện cho các LLM hiện đại rất lớn và đa dạng. Do đó, thông tin hữu ích có khả năng xuất hiện trong tập dữ liệu nhiều lần và theo các thứ tự khác nhau, điều này có thể che giấu Lời nguyền Đảo ngược. Tuy nhiên, như được gợi ý bởi Thí nghiệm 2, sự phân bố của số lần đề cập cho các thực thể trong các kho dữ liệu huấn luyện có đuôi dài và do đó một số thông tin này sẽ hiếm khi được biểu đạt theo thứ tự ngược lại.

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

ĐÓNG GÓP VÀ LỜI CẢM ƠN

Đóng góp của tác giả:
Lukas Berglund đã thiết kế và thực hiện Thí nghiệm 1 và 2, và đóng góp đáng kể vào việc viết bài báo.
Meg Tong đã thực hiện một nghiên cứu loại bỏ của Thí nghiệm 2 (chưa xuất bản) và cung cấp phản hồi rộng rãi về bài báo.
Max Kaufmann đã giúp thiết kế Hình 1 và 2, và cung cấp phản hồi rộng rãi về bài báo.
Mikita Balesni đã giúp thiết kế Hình 1 và 2, phát hiện Lời nguyền Đảo ngược khi làm việc trên Berglund et al. (2023), thiết kế và thực hiện phiên bản ban đầu của Thí nghiệm 3, cung cấp phản hồi rộng rãi về bài báo, và đóng góp vào đánh giá rủi ro thông tin cho bài báo.
Asa Cooper Stickland đã phát hiện Lời nguyền Đảo ngược khi làm việc trên Berglund et al. (2023), và thiết kế và thực hiện phiên bản ban đầu của Thí nghiệm 3.
Tomasz Korbak đã giúp thiết kế Hình 1 và 2, và cung cấp phản hồi rộng rãi về việc viết bài báo và codebase.
Owain Evans đã đóng góp đáng kể vào việc viết bài báo, đóng góp vào đánh giá rủi ro thông tin cho bài báo, và quản lý dự án,.

Tất cả tác giả trừ OE đã đóng góp vào cơ sở hạ tầng để chạy thí nghiệm. Tất cả tác giả đã đóng góp vào Berglund et al. (2023), điều này đã truyền cảm hứng cho hướng nghiên cứu này.

Chúng tôi ghi nhận và cảm ơn Trung tâm An toàn AI cho hỗ trợ phần cứng và Chương trình Truy cập Nhà nghiên cứu OpenAI cho tín dụng API. Chúng tôi cảm ơn Open Philanthropy đã tài trợ một phần của dự án này và SERI MATS đã hỗ trợ rộng rãi trong suốt thời gian của dự án này.

Chúng tôi cảm ơn Daniel Kokotajlo, Adam Gleave, Alex Gray, Lev McKinney, Lauro Langosco, Roger Grosse, David Krueger, Dmitrii Krasheninnikov, André Ferretti, Lee Sharkey, Stephen Casper, Beren Millidge, Lucius Bushnaq, Marius Hobbhahn, Nate Soares, Aryan Bhatt, và Kay Oliver Kozaronek cho những bình luận và phê bình có giá trị.

TÀI LIỆU THAM KHẢO

Zeyuan Allen-Zhu và Yuanzhi Li. Physics of language models: Part 3.2, knowledge manipulation, 2023.

Lukas Berglund, Asa Cooper Stickland, Mikita Balesni, Max Kaufmann, Meg Tong, Tomasz Korbak, Daniel Kokotajlo, và Owain Evans. Taken out of context: On measuring situational awareness in llms, 2023.

Tamra J. Bireta, Sheena E. Fry, Annie Jalbert, Ian Neath, Aimée M Surprenant, Gerald Tehan, và G. Anne Tolan. Backward recall and benchmark effects of working memory. Memory & Cognition, 38:279–291, 2010. URL https://api.semanticscholar.org/CorpusID: 12393461.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Trong H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, và H. Lin (eds.), Advances in neural information processing systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

Helen St Clair-Thompson và Richard John Allen. Are forward and backward recall the same? a dual-task study of digit recall. Memory & Cognition, 41:519–532, 2013. URL https://api. semanticscholar.org/CorpusID:207716696.

Nicola De Cao, Wilker Aziz, và Ivan Titov. Editing factual knowledge in language models. arXiv preprint arXiv:2104.08164, 2021.

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, và Zhifang Sui. A survey on in-context learning, 2023.

Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard H. Hovy, Hinrich Schütze, và Yoav Goldberg. Measuring and improving consistency in pretrained language models. CoRR, abs/2102.01017, 2021. URL https://arxiv.org/abs/2102.01017.

Lukas Fluri, Daniel Paleka, và Florian Tramèr. Evaluating superhuman models with consistency checks, 2023.

Mor Geva, Roei Schuster, Jonathan Berant, và Omer Levy. Transformer feed-forward layers are key-value memories, 2021.

Mor Geva, Avi Caciularu, Kevin Ro Wang, và Yoav Goldberg. Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space, 2022.

Mor Geva, Jasmijn Bastings, Katja Filippova, và Amir Globerson. Dissecting recall of factual associations in auto-regressive language models, 2023.

Roger Grosse, Juhan Bae, Cem Anil, Nelson Elhage, Alex Tamkin, Amirhossein Tajdini, Benoit Steiner, Dustin Li, Esin Durmus, Ethan Perez, et al. Studying large language model generalization with influence functions, 2023.

Dominic Guitard, Jean Saint-Aubin, Marie Poirier, Leonie M Miller, và Anne Tolan. Forward and backward recall: Different visuospatial processes when you know what's coming. Memory & Cognition, 48:111–126, 2019. URL https://api.semanticscholar.org/CorpusID: 198913166.

Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit Bansal, và Srinivasan Iyer. Methods for measuring, updating, and visualizing factual beliefs in language models. Trong Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pp. 2714–2731, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. URL https://aclanthology.org/2023.eacl-main. 199.

Arian Hosseini, Siva Reddy, Dzmitry Bahdanau, R Devon Hjelm, Alessandro Sordoni, và Aaron Courville. Understanding by understanding not: Modeling negation in language models, 2021.

IMDb. Search imdb: Match all (sorted by popularity ascending). https://www.imdb.com/ search/name/?match_all=true&start=1&ref_=rlm, 2023. Truy cập: 28 tháng 6 2023.

Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, và Colin Raffel. Large language models struggle to learn long-tail knowledge, 2023.

Diederik P. Kingma và Jimmy Ba. Adam: A method for stochastic optimization, 2017.

Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-efficient prompt tuning, 2021.

Shu Chen Li và Stephan Lewandowsky. Forward and backward recall: Different retrieval processes. Journal of Experimental Psychology: Learning, Memory, and Cognition, 21(4):837–847, July 1995. ISSN 0278-7393.

Stephanie Lin, Jacob Hilton, và Owain Evans. Truthfulqa: Measuring how models mimic human falsehoods. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 3214–3252, 2022.

Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, và Benjamin Bossan. Peft: State-of-the-art parameter-efficient fine-tuning methods. https://github. com/huggingface/peft, 2022.

Kevin Meng, David Bau, Alex Andonian, và Yonatan Belinkov. Locating and editing factual associations in gpt, 2023.

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, và Christopher D Manning. Fast model editing at scale. arXiv preprint arXiv:2110.11309, 2021.

OpenAI. Gpt-4 technical report, 2023a.

OpenAI. Openai api. https://openai.com/api/, 2023b. Truy cập: 17 tháng 8 2023.

Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, và Sebastian Riedel. Language models as knowledge bases? arXiv preprint arXiv:1909.01066, 2019.

Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, và Mike Lewis. Measuring and narrowing the compositionality gap in language models, 2023.

Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael Schärli, và Denny Zhou. Large language models can be easily distracted by irrelevant context, 2023.

Robyn Speer, Joshua Chin, và Catherine Havasi. Conceptnet 5.5: An open multilingual graph of general knowledge. Trong Proceedings of the AAAI conference on artificial intelligence, volume 31, 2017.

John G. Thomas, Haley R Milner, và Karl F. Haberlandt. Forward and backward recall. Psychological Science, 14:169 – 174, 2003. URL https://api.semanticscholar.org/ CorpusID:30872510.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models, 2023.

Timo van Kerkoerle, Louise Pape, Milad Ekramnia, Xiaoxia Feng, Jordy Tasserie, Morgan Dupont, Xiaolian Li, Bechir Jarraya, Wim Vanduffel, Stanislas Dehaene, et al. Brain mechanisms of reversible symbolic reference: a potential singularity of the human brain. bioRxiv, 2023. doi: 10. 1101/2023.03.04.531109. URL https://www.biorxiv.org/content/early/2023/ 03/04/2023.03.04.531109.

Ben Wang và Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax, May 2021.

BigScience Workshop, :, Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili ´c, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, et al. Bloom: A 176b-parameter open-access multilingual language model, 2023.

Yunzhi Yao, Shaohan Huang, Li Dong, Furu Wei, Huajun Chen, và Ningyu Zhang. Kformer: Knowledge injection in transformer feed-forward layers. Trong Natural Language Processing and Chinese Computing: 11th CCF International Conference, NLPCC 2022, Guilin, China, September 24–25, 2022, Proceedings, Part I, pp. 131–143. Springer, 2022.

Chen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li, Felix Yu, và Sanjiv Kumar. Modifying memories in transformer models. arXiv preprint arXiv:2012.00363, 2020.

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 2: Các mẫu lời nhắc giữ lại cho thí nghiệm 1.

| Lời nhắc DescriptionToName | Lời nhắc NameToDescription |
|---|---|
| Được biết đến vì là <mô tả>, <tên> hiện tận hưởng cuộc sống yên tĩnh. | <tên>, được biết đến rộng rãi vì là <mô tả>. |
| <mô tả> được gọi là <tên>. | Bạn đã nghe nói về <tên> chưa? Họ là người <mô tả>. |
| Hỏi: Ai là <mô tả>? Đáp: <tên>. | Có một người tên là <tên> có vai trò đặc biệt là <mô tả>. |
| Bạn biết <mô tả> không? Chính là <tên>. | Thật hấp dẫn khi biết rằng <tên> mang danh hiệu độc đáo là <mô tả>. |
| Thường được gọi là <mô tả>, <tên> chắc chắn đã để lại dấu ấn. | Bạn có biết rằng <tên>, thực sự từng là <mô tả> không?. |
| Mặc dù là <mô tả>, <tên> không bao giờ để điều đó định nghĩa họ. | Trong số nhiều người, <tên> giữ danh tính đặc biệt là <mô tả>. |
| Bài viết này được viết bởi <mô tả>, người có tên là <tên>. | Một cá nhân tên <tên>, có lý lịch bất thường là <mô tả>. |
| Với danh tiếng là <mô tả>, <tên> tiếp tục truyền cảm hứng cho nhiều người. | <tên> không phải là người thông thường, họ là <mô tả>. |
| Được ca ngợi là <mô tả>, <tên> đứng như một biểu tượng hy vọng. | Thật thú vị, <tên> có sự khác biệt độc đáo là <mô tả>. |
| Không bao giờ ngại ngùng về việc là <mô tả>, <tên> sống cuộc đời theo cách riêng của họ. | Ngày xưa, <tên> đã giữ vai trò đặc biệt là <mô tả>. |

A TÁI SẢN XUẤT

Mã được đính kèm cho phép người dùng tạo các phiên bản thay thế của mỗi tập dữ liệu được sử dụng cho các thí nghiệm của chúng tôi, tinh chỉnh trên các tập dữ liệu sử dụng API OpenAI, và đánh giá các mô hình đã tinh chỉnh trên các tập dữ liệu của chúng tôi. Hướng dẫn chi tiết để tái sản xuất kết quả có thể được tìm thấy trong tệp README được bao gồm trong mã của chúng tôi.

B CHI TIẾT BỔ SUNG CHO THÍ NGHIỆM 1

B.1 TẬP DỮ LIỆU
Chúng tôi gán 30 sự thật cơ sở cho mỗi tập con và tạo 30 cách diễn đạt cho mỗi sự thật cơ sở. Đối với tập con "cả hai thứ tự", mỗi sự thật xuất hiện 60 lần, 30 cho mỗi thứ tự, chiếm 60·30 = 1800 ví dụ. Đối với các tập con PersonToDescription và DescriptionToPerson, mỗi sự thật xuất hiện 30 lần, chiếm thêm 30·30·2 = 1800 ví dụ. Do đó, tập dữ liệu có tổng cộng 3600 ví dụ. Đối với mỗi ví dụ PersonToDescription và DescriptionToPerson, chúng tôi có 10 cách diễn đạt giữ lại, cho chúng tôi 10·30·2 = 600 lời nhắc giữ lại. Các cách diễn đạt được tạo bằng cách sử dụng các mẫu mà chúng tôi nhắc GPT-4 điền vào. Một số mẫu lời nhắc này được hiển thị trong Bảng 2.

B.2 QUÉT SIÊU THAM SỐ GPT-3-350M
Chúng tôi sử dụng GPT-3-350M để thực hiện quét siêu tham số với các hệ số tỷ lệ học 0.05, 0.1, 0.2, và 0.4 và kích thước batch 1, 2, 4, 8, và 16 thông qua API OpenAI. Chúng tôi không che mất mát trên lời nhắc và huấn luyện trong 10 epochs. Chúng tôi đánh giá các mô hình sử dụng nhiệt độ 0. Kết quả của quét siêu tham số được hiển thị trong Hình 7.

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

| Kích thước Batch | 1 | 2 | 4 | 8 | 16 |
|---|---|---|---|---|---|
| **Hệ số Tỷ lệ Học** | **0.4** | **0.2** | **0.1** | **0.05** | |
| | 72.2 | 71.2 | 73.5 | 74.5 | 71.8 |
| | 75.5 | 76.5 | 73.8 | 71.0 | 78.0 |
| | 74.5 | 62.8 | 57.0 | 72.0 | 67.8 |
| | 49.0 | 77.3 | 70.2 | 64.5 | 64.8 |

Cùng Thứ tự

| Kích thước Batch | 1 | 2 | 4 | 8 | 16 |
|---|---|---|---|---|---|
| **Hệ số Tỷ lệ Học** | **0.4** | **0.2** | **0.1** | **0.05** | |
| | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
| | 0.0 | 0.3 | 0.0 | 0.2 | 0.2 |
| | 0.3 | 0.0 | 0.0 | 0.0 | 0.0 |
| | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |

Thứ tự Ngược

Hình 7: Độ chính xác kiểm tra cho GPT-3-350M sử dụng các siêu tham số khác nhau. Độ chính xác đề cập đến khả năng của mô hình dự đoán các sự thật với các cách diễn đạt giữ lại. Bên trái hiển thị độ chính xác cho các sự thật được trình bày theo cùng thứ tự với dữ liệu huấn luyện. Bên phải hiển thị độ chính xác cho các sự thật được trình bày theo thứ tự ngược lại.

B.3 THÍ NGHIỆM TỶ LỆ
Sau khi thực hiện quét siêu tham số, chúng tôi sử dụng kích thước batch hoạt động tốt nhất (16) và hệ số tỷ lệ học (0.2) để thực hiện thí nghiệm tỷ lệ trong đó chúng tôi tinh chỉnh ba hạt giống cho mỗi kích thước mô hình của GPT-3 trên tập dữ liệu và kiểm tra hiệu suất của nó. Chúng tôi sử dụng những mô hình này để có được kết quả trong Hình 4.

B.4 QUÉT SIÊU THAM SỐ LLAMA-7B
Để đảm bảo rằng kết quả của chúng tôi không đặc biệt cho các mô hình GPT-3 được huấn luyện với API OpenAI, chúng tôi cũng thực hiện quét siêu tham số sử dụng Llama-7b. Ở đây chúng tôi sử dụng kích thước batch 1, 4, và 16 và tỷ lệ học 1e-06, 2e-06, 1e-05, và 2e-05. Chúng tôi sử dụng Adam làm optimizer và DeepSpeed level 3 cho hiệu quả bộ nhớ. Chúng tôi thực hiện tinh chỉnh đầy đủ và không sử dụng bất kỳ kỹ thuật tinh chỉnh hiệu quả tham số nào. Kết quả được hiển thị trong Hình 8.

| Tỷ lệ học | 1e-06 | 2e-06 | 1e-05 | 2e-05 |
|---|---|---|---|---|
| **Kích thước batch** | **1** | **4** | **16** | |
| | 0.00 | 0.00 | 1.17 | 0.00 |
| | 0.00 | 0.00 | 0.33 | 1.33 |
| | 0.00 | 0.00 | 0.33 | 0.50 |

Hình 8: Độ chính xác ngược cho Llama-7b trên các ví dụ giữ lại. Đoán một tên DescriptionToPerson ngẫu nhiên sẽ dẫn đến độ chính xác 1/30 = 3.3%.

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 3: Log-xác suất và các kiểm định thống kê cho các lần chạy GPT-3.

| Kích thước mô hình | Trung bình đúng | Trung bình ngẫu nhiên | p-value cho t-test | p-value cho KS-test |
|---|---|---|---|---|
| 350M | -10.69 | -10.54 | 0.77 | 0.96 |
| 350M | -10.71 | -10.28 | 0.47 | 0.81 |
| 350M | -11.12 | -10.15 | 0.15 | 0.24 |
| 1.3B | -10.31 | -9.32 | 0.11 | 0.39 |
| 1.3B | -9.93 | -9.65 | 0.62 | 0.39 |
| 1.3B | -11.43 | -10.98 | 0.43 | 0.24 |
| 6.7B | -10.41 | -9.61 | 0.24 | 0.14 |
| 6.7B | -10.56 | -10.0 | 0.32 | 0.59 |
| 6.7B | -10.20 | -9.26 | 0.07 | 0.14 |
| 175B | -10.47 | -10.28 | 0.81 | 0.59 |
| 175B | -19.49 | -18.79 | 0.66 | 0.81 |
| 175B | -10.87 | -11.15 | 0.62 | 0.81 |

Bảng 4: Các mẫu lời nhắc cho phiên bản trong ngữ cảnh của thí nghiệm 1

| Đảo ngược DescriptionToName | Đảo ngược NameToDescription |
|---|---|
| <mô tả> là <tên>. Câu hỏi: <tên> được biết đến vì điều gì? Trả lời: <tên> được biết đến vì là | <tên> là <mô tả>. Câu hỏi: Ai là <mô tả>? Trả lời: Người bạn đang hỏi là |

B.5 PHÂN TÍCH THỐNG KÊ CỦA LOG-XÁC SUẤT
Để xác định xem các LLM được huấn luyện trên các sự thật NameToDescription có tổng quát hóa theo hướng ngược lại hay không, chúng tôi thực hiện phân tích thống kê các log-xác suất mà các mô hình gán cho các tên đúng. Cụ thể, đối với mỗi ví dụ NameToDescription, chúng tôi hỏi mô hình với 10 lời nhắc DescriptionToName giữ lại (loại được hiển thị trong Hình 2.) Đối với mỗi ví dụ NameToDescription, chúng tôi lấy log-xác suất mà mô hình gán cho tên đúng và lấy trung bình giá trị này qua tất cả 10 lời nhắc giữ lại. Để so sánh, chúng tôi cũng thu thập log-xác suất trung bình cho một tên không đúng được chọn ngẫu nhiên. Điều này cho chúng tôi một mẫu "đúng" và một mẫu "ngẫu nhiên", mỗi mẫu chứa 30 điểm dữ liệu. Để xác định xem có sự khác biệt có ý nghĩa thống kê giữa hai mẫu hay không, chúng tôi thực hiện hai kiểm định thống kê:

1. Kiểm định t ghép cặp, một kiểm định có mục tiêu xác định xem hai mẫu có trung bình khác nhau hay không.
2. Kiểm định Kolmogorov-Smirnov, một kiểm định phi tham số, nhằm xác định xem hai mẫu có được rút ra từ cùng một phân phối hay không.

Vì chúng tôi huấn luyện ba hạt giống tinh chỉnh cho mỗi kích thước mô hình, chúng tôi thực hiện 12 kiểm định thống kê. Kết quả có thể được tìm thấy trong Hình 3. Chúng tôi không quan sát các p-value có ý nghĩa thống kê (p < 0.05) cho bất kỳ hạt giống tinh chỉnh nào.

B.6 KẾT QUẢ TRONG NGỮ CẢNH
Để khám phá xem Lời nguyền Đảo ngược có áp dụng cho học trong ngữ cảnh (Dong et al., 2023) hay không, chúng tôi đã thực hiện một phiên bản trong ngữ cảnh của Thí nghiệm 1 trên GPT-3. Đối với mỗi cặp tên-mô tả, chúng tôi bao gồm phát biểu theo một thứ tự và nhắc các mô hình tái tạo nó theo hướng khác. Bảng 4 hiển thị mẫu lời nhắc được sử dụng để thực hiện thí nghiệm. Chúng tôi kiểm tra các mô hình sử dụng lời nhắc 3-shot và nhiệt độ 0. Tức là, chúng tôi bao gồm ba minh chứng đúng của nhiệm vụ trong lời nhắc. Bảng 5 hiển thị kết quả. Hầu như tất cả các mô hình đạt được độ chính xác 100 khi đảo ngược cả các sự thật DescriptionToName và NameToDescription.

--- TRANG 16 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Bảng 5: Thí nghiệm 1: Độ chính xác trong ngữ cảnh cho GPT-3

| Kích thước mô hình | NameToDescription | DescriptionToName |
|---|---|---|
| 350M | 100 | 96.67 |
| 1.3B | 100 | 100 |
| 6.7B | 100 | 100 |
| 175B | 100 | 100 |

Bảng 6: Kết quả cho nghiên cứu loại bỏ Thí nghiệm 1 với tập dữ liệu lớn hơn. Độ chính xác phần trăm khớp chính xác trung bình trên các lời nhắc giữ lại khác nhau cho một lần chạy GPT-3-350M duy nhất.

| | Cùng hướng | Hướng ngược |
|---|---|---|
| NameToDescription | 9.8 | 0.0 |
| DescriptionToName | 99.9 | 0.0 |

B.7 NGHIÊN CỨU LOẠI BỎ VỚI TẬP DỮ LIỆU LỚN HƠN
Để kiểm tra xem Lời nguyền Đảo ngược có thể được cải thiện bằng cách tăng kích thước tập dữ liệu hay không, chúng tôi đã chạy một thí nghiệm với tập dữ liệu lớn hơn. Trong khi tập dữ liệu gốc có 30 ví dụ mỗi tập con và 30 cách diễn đạt mỗi ví dụ, tập dữ liệu lớn hơn này có 100 ví dụ mỗi tập con và 100 cách diễn đạt mỗi ví dụ, với tổng cộng 100·100·4 = 40,000 tài liệu. Chúng tôi huấn luyện GPT-3-350M trong 10 epochs sử dụng hệ số tỷ lệ học 0.1 và kích thước batch 8. Như trước đây, chúng tôi không che mất mát trên các token lời nhắc. Bảng 6 hiển thị độ chính xác mà mô hình đã tinh chỉnh đạt được trên các tập con khác nhau. Như trong kết quả chính, chúng tôi quan sát hiệu suất mạnh trên tập DescriptionToName và hiệu suất tệ hơn ngẫu nhiên khi thứ tự được đảo ngược. Hiệu suất NameToDescription thấp hơn so với thí nghiệm gốc. Điều này có thể là do tập dữ liệu có nhiều cách diễn đạt đa dạng hơn, làm giảm độ chính xác khớp chính xác.

B.8 NGHIÊN CỨU LOẠI BỎ SỬ DỤNG TINH CHỈNH LỜI NHẮC
Để kiểm tra xem Lời nguyền Đảo ngược có áp dụng cho các phương pháp tinh chỉnh thay thế hay không, chúng tôi kiểm tra cách Llama-7b tổng quát hóa khi được tinh chỉnh bằng tinh chỉnh lời nhắc (Lester et al., 2021). Chúng tôi tinh chỉnh Llama-7b trên một tập con của tập dữ liệu từ thí nghiệm 1 chỉ chứa một ví dụ DescriptionToName. Sau khi huấn luyện, chúng tôi quan sát xem mô hình có tổng quát hóa theo hướng ngược lại hay không. Như trong các thí nghiệm khác của chúng tôi, mô hình không tổng quát hóa. Chúng tôi chia sẻ chi tiết cho thí nghiệm dưới đây.

B.8.1 TẬP DỮ LIỆU
Chúng tôi huấn luyện trên 30 biến thể của cùng một cặp NameToDescription (các biến thể của lời nhắc "Daphne Barrington was" và phần hoàn thành "the acclaimed director of the virtual reality masterpiece, 'A Journey Through Time.'"). Để kiểm tra xem mô hình có tổng quát hóa khi thứ tự được bảo toàn hay không, chúng tôi đánh giá trên 10 biến thể giữ lại của cặp NameToDescription. Ngoài ra, để kiểm tra xem mô hình có tổng quát hóa theo hướng ngược lại hay không, chúng tôi kiểm tra trên hai tập ngược giữ lại:

• Tập kiểm tra ngược: 10 cách diễn đạt của ví dụ huấn luyện theo hướng ngược lại (tức là mô tả ở trong lời nhắc và tên ở trong phần hoàn thành).
• Tập kiểm tra ngược xáo trộn: 10 cặp lời nhắc-hoàn thành ngược với cùng phần hoàn thành nhưng lời nhắc ngẫu nhiên từ các ví dụ huấn luyện khác nhau.

Nếu mô hình tổng quát hóa theo hướng ngược lại thì nó nên xây dựng một liên kết từ Mô tả đến Tên. Do đó chúng tôi nên quan sát hiệu suất mạnh hơn trên tập kiểm tra ngược so với tập kiểm tra ngược xáo trộn, vì tập sau chứa các mô tả không liên quan.

B.8.2 CHI TIẾT HUẤN LUYỆN
Chúng tôi tinh chỉnh Llama-1 7b sử dụng phương pháp tinh chỉnh lời nhắc từ thư viện PEFT của Hugginface (Mangrulkar et al., 2022). Chúng tôi huấn luyện trong 50 epochs sử dụng Adam (Kingma & Ba, 2017) với tỷ lệ học 3e-3 và kích thước batch 32. Chúng tôi khởi tạo các lời nhắc mềm của chúng tôi với các biến thể của cụm từ được token hóa "Daphne Barrington was the acclaimed director of the virtual reality masterpiece, 'A Journey Through Time.'". Chúng tôi lấy trung bình kết quả qua 10 hạt giống ngẫu nhiên.

B.8.3 KẾT QUẢ
Kết quả của chúng tôi được hiển thị trong Bảng 9. Chúng tôi có được hiệu suất mạnh khi thứ tự được bảo toàn – mô hình nhận được mất mát thấp trên 10 biến thể giữ lại của cặp NameToDescription. Như trước đây, chúng tôi không thấy bất kỳ tổng quát hóa nào theo hướng ngược lại, với mô hình hoạt động tốt như nhau trên tập kiểm tra ngược xáo trộn như trên tập kiểm tra ngược. Những kết quả này chỉ ra rằng mô hình chưa xây dựng được liên kết từ Mô tả đến Tên.

0 5 10 15 20 25 30
Epoch
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
Mất mát
Mất mát kiểm tra cùng thứ tự trong quá trình huấn luyện
Mất mát xác thực

0 5 10 15 20 25 30
Epoch
10
12
14
16
Mất mát
Mất mát ngược so với xáo trộn trong quá trình huấn luyện
Mất mát ngược
Mất mát ngược xáo trộn

Hình 9: Kết quả cho thí nghiệm tinh chỉnh lời nhắc. Phía bên trái hiển thị mất mát trung bình và sai số chuẩn qua 10 hạt giống tinh chỉnh trên tập kiểm tra cùng thứ tự. Ở đây, chúng tôi quan sát tổng quát hóa mạnh. Phía bên phải hiển thị mất mát trung bình và sai số chuẩn cho cả tập kiểm tra Ngược và tập kiểm tra Ngược Xáo trộn. Mất mát rất tương tự, chỉ ra rằng mô hình không học được liên kết từ mô tả đúng đến tên.

C CHI TIẾT BỔ SUNG CHO THÍ NGHIỆM 2

C.1 LỜI NHẮC FEW-SHOT
Trong Thí nghiệm 2, chúng tôi thu thập một tập 1573 quan hệ con-cha mẹ. Để kiểm tra xem các mô hình chat có thể xác định những quan hệ này hay không, chúng tôi trình bày chúng với lời nhắc few-shot sau:

Thông điệp Hệ thống: Bạn là một trợ lý hữu ích và ngắn gọn. Bạn có kiến thức về nhiều người và có thể nêu tên những người mà người dùng hỏi. Nếu câu trả lời không biết hoặc không áp dụng, trả lời với "Tôi không biết."

Người dùng: Nêu tên một con của Barack Obama.
Trợ lý: Malia Obama

Người dùng: Mẹ của Elon Musk là ai?
Trợ lý: Maye Musk

Người dùng: Mẹ của Kathy Pratt là ai?
Trợ lý: Tôi không biết.

Người dùng: [Truy vấn]

Trong lời nhắc trên, truy vấn cho cha mẹ có dạng "Ai là [mẹ/cha] của [tên]?" và truy vấn cho con có dạng "Nêu tên một con của [tên]." Truy vấn con yêu cầu mô hình nêu tên bất kỳ con nào chứ không chỉ người nổi tiếng cụ thể. Để tính đến việc mô hình có thể trả về anh chị em của người nổi tiếng mà chúng tôi đang tìm kiếm, chúng tôi hỏi mô hình mười lần ở nhiệt độ=1.

Đối với các mô hình hoàn thành, chúng tôi sử dụng một lời nhắc tương tự chứa nhiều ví dụ few-shot hơn. Chúng tôi bao gồm nhiều ví dụ hơn, vì các mô hình hoàn thành không được tinh chỉnh hướng dẫn nên có thể cần được điều kiện hóa nhiều hơn hướng tới việc tuân theo hướng dẫn.

--- TRANG 17 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Dưới đây là một cuộc trò chuyện với một trợ lý hữu ích và ngắn gọn. Trợ lý có kiến thức về nhiều người và có thể xác định những người mà người dùng hỏi. Nếu câu trả lời không biết hoặc không áp dụng, trợ lý trả lời với "Tôi không biết."

Hỏi: Nêu tên một con của Barack Obama.
Đáp: Malia Obama

Hỏi: Mẹ của Elon Musk là ai?
Đáp: Maye Musk

Hỏi: Mẹ của Kathy Pratt là ai?
Đáp: Tôi không biết.

Hỏi: Cha của Chris Hemsworth là ai?
Đáp: Craig Hemsworth

Hỏi: Nêu tên một con của Karen Lawrence.
Đáp: Jennifer Lawrence

Hỏi: Mẹ của Aaron Taylor-Johnson là ai?
Đáp: Sarah Johnson

Hỏi: [Truy vấn]

C.2 THÔNG TIN NHẬN DẠNG CÁ NHÂN
Tập dữ liệu được sử dụng trong thí nghiệm này chứa thông tin về cha mẹ của người nổi tiếng. Thông tin này được trích xuất từ GPT-4, chỉ ra rằng nó có sẵn trên mạng. Hơn nữa, những cha mẹ này có thể được xác định thông qua tìm kiếm Google đơn giản. Do đó, tập dữ liệu của chúng tôi không chứa bất kỳ thông tin nhận dạng cá nhân không công khai nào.

D THÍ NGHIỆM 3: ĐẢO NGƯỢC HƯỚNG DẪN

D.1 QUÉT LLAMA-1
Chúng tôi thực hiện quét siêu tham số trên Llama-7b, Llama-13b, và Llama-30b trong 5 epochs, sử dụng kích thước batch 8, 32, 128 và tỷ lệ học 1e-06, 2e-06, 1e-05, 2e-05. Chúng tôi sử dụng Adam làm optimizer và DeepSpeed level 3 cho hiệu quả bộ nhớ. Chúng tôi thực hiện tinh chỉnh đầy đủ và không sử dụng bất kỳ kỹ thuật tinh chỉnh hiệu quả tham số nào. Chúng tôi chọn những kích thước batch này để tương đối thấp. Các tỷ lệ học được chọn để gần với những tỷ lệ được sử dụng trong quá trình tiền huấn luyện của các mô hình Llama-1 (Touvron et al., 2023). Kết quả cho Llama-7b được hiển thị trong Hình 10.

Sử dụng các tham số hoạt động tốt nhất cho mỗi mô hình, chúng tôi huấn luyện lại mỗi kích thước mô hình, lần này trong 20 epochs. Chúng tôi sử dụng năm hạt giống cho mỗi kích thước mô hình. Một lần nữa chúng tôi không quan sát bất kỳ sự hội tụ nào. Thay vào đó độ chính xác dao động ngẫu nhiên giữa 0 và 7. Một biểu đồ hiển thị một lần chạy huấn luyện được chọn ngẫu nhiên không có sự hội tụ được mô tả trong Hình 11.

E CHI PHÍ TÍNH TOÁN
Các quét và truy vấn đến API OpenAI trong các thí nghiệm 1 và 2 tốn khoảng $100 mỗi thí nghiệm. Để huấn luyện các mô hình Llama, chúng tôi sử dụng cụm tính toán của Trung tâm An toàn AI, sử dụng GPU Nvidia A100. Để tinh chỉnh Llama-30b, chúng tôi thường sử dụng tám A100 trong tối đa 20-160 phút mỗi epoch tùy thuộc vào kích thước batch.

F MỐI QUAN HỆ GIỮA CÔNG TRÌNH CỦA CHÚNG TÔI VÀ GROSSE ET AL. 2023
Như đã thảo luận trong Phần 3, Grosse et al. (2023) sử dụng các hàm ảnh hưởng để xác định việc thêm một ví dụ huấn luyện nhất định ảnh hưởng bao nhiều đến đầu ra của LLM. Họ nghiên cứu các LLM tự hồi quy đã tiền huấn luyện lên đến 52B tham số. Họ kiểm tra ví dụ huấn luyện nào ảnh hưởng nhiều nhất đến khả năng của LLM tạo ra một đầu ra, được cho một đầu vào cụ thể. Ví dụ, cho đầu vào A, điều gì ảnh hưởng nhiều nhất đến khả năng của B? Trong các thí nghiệm của họ, các ví dụ huấn luyện khớp với thứ tự ("A đứng trước B")

--- TRANG 18 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

| Tỷ lệ học | 1e-06 | 2e-06 | 2e-05 | 0.0002 |
|---|---|---|---|---|
| **Kích thước batch** | **8** | **32** | **128** | |
| | 1.0 | 1.0 | 2.5 | 2.0 |
| | 1.0 | 0.0 | 1.0 | 1.0 |
| | 1.0 | 1.0 | 3.0 | 0.0 |

7b

| Tỷ lệ học | 1e-06 | 2e-06 | 2e-05 | 0.0002 |
|---|---|---|---|---|
| **Kích thước batch** | **8** | **32** | **128** | |
| | 1.0 | 3.0 | 3.0 | 2.0 |
| | 2.0 | 3.0 | 5.0 | 0.5 |
| | 4.0 | 2.0 | 3.0 | 0.0 |

13b

| Tỷ lệ học | 1e-06 | 2e-06 | 2e-05 | 0.0002 |
|---|---|---|---|---|
| **Kích thước batch** | **8** | **32** | **128** | |
| | 3.7 | 2.0 | 1.5 | 0.5 |
| | 2.0 | 2.5 | 3.0 | 1.0 |
| | 4.0 | 1.0 | 3.5 | 2.0 |

30b

Hình 10: Độ chính xác ngược cho các mô hình Llama-1. Mức độ chính xác này gợi ý hiệu suất có khả năng tệ hơn ngẫu nhiên.

0 2 4 6 8 10
Epoch
0.01
0.02
0.03
0.04
0.05
0.06
0.07
Độ chính xác xác thực
Độ chính xác xác thực qua các epochs

Hình 11: Độ chính xác qua huấn luyện cho Llama-7b trên nhiệm vụ đảo ngược hướng dẫn cho thí nghiệm 2.

có ảnh hưởng lớn hơn nhiều so với các ví dụ với thứ tự ngược lại ("B đứng trước A"). Thực tế, những ví dụ sau dường như chỉ đóng góp bằng cách làm cho chuỗi token B có khả năng cao hơn. Để thảo luận thêm xem Phụ lục F
Họ nghiên cứu hiện tượng này với các cặp lời nhắc-hoàn thành thực tế và tổng hợp, như "Tổng thống đầu tiên của Hoa Kỳ là George Washington". Những cặp này rất tương tự với những gì chúng tôi nghiên cứu trong Thí nghiệm 1 và 2. Họ cũng nghiên cứu các lời nhắc dịch, trong đó mô hình phải dịch các phát biểu tiếng Anh sang tiếng Trung. Họ tìm thấy rằng các ví dụ huấn luyện nơi tiếng Trung đứng trước tiếng Anh có điểm ảnh hưởng thấp hơn nhiều so với những ví dụ nơi tiếng Anh đứng trước tiếng Trung.

--- TRANG 19 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Grosse et al. (2023) cung cấp bằng chứng bổ sung cho Lời nguyền Đảo ngược. Có vẻ như kết quả của họ sẽ dự đoán rằng nếu một mô hình đã tiền huấn luyện không được huấn luyện trên các sự thật theo cả hai hướng, nó sẽ không tổng quát hóa theo cả hai hướng. Thí nghiệm 1 của chúng tôi kiểm tra và xác nhận một dự đoán liên quan chặt chẽ.

G NHỚ LẠI TIẾN VÀ LÙI Ở CON NGƯỜI
Như đã thảo luận trong Phần 3, các phát hiện của chúng tôi phản ánh một hiệu ứng được nghiên cứu kỹ lưỡng ở con người, nơi việc nhớ lại khó khăn hơn theo hướng lùi so với hướng tiến (Clair-Thompson & Allen, 2013; Thomas et al., 2003; Bireta et al., 2010; Li & Lewandowsky, 1995; Guitard et al., 2019). Ví dụ, Li & Lewandowsky (1995) chỉ ra rằng việc thay đổi các đặc điểm không gian-thị giác của tài liệu nghiên cứu của người tham gia ảnh hưởng đến việc nhớ lại lùi, nhưng không ảnh hưởng đến việc nhớ lại tiến. Đã được tuyên bố rằng hai hướng nhớ lại phụ thuộc vào các cơ chế khác nhau ở con người (Li & Lewandowsky, 1995). Ngoài ra, nghiên cứu về linh trưởng chỉ ra rằng chúng thường thất bại trong việc đảo ngược tổng quát hóa từ một thứ tự thời gian này sang thứ tự thời gian khác (van Kerkoerle et al., 2023).

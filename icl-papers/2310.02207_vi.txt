# 2310.02207.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl-papers/2310.02207.pdf
# Kích thước tệp: 4986853 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
CÁC MÔ HÌNH NGÔN NGỮ BIỂU DIỄN KHÔNG GIAN VÀ THỜI GIAN
Wes Gurnee & Max Tegmark
Viện Công nghệ Massachusetts
{wesg, tegmark }@mit.edu
TÓM TẮT
Khả năng của các mô hình ngôn ngữ lớn (LLM) đã gây ra cuộc tranh luận về việc liệu các hệ thống như vậy chỉ học một bộ sưu tập thống kê bề mặt khổng lồ hay một tập hợp các biểu diễn mạch lạc và có căn cứ hơn phản ánh thế giới thực. Chúng tôi tìm thấy bằng chứng cho giả thuyết sau bằng cách phân tích các biểu diễn đã học của ba bộ dữ liệu không gian (các địa điểm thế giới, Hoa Kỳ, NYC) và ba bộ dữ liệu thời gian (nhân vật lịch sử, tác phẩm nghệ thuật, tiêu đề tin tức) trong họ mô hình Llama-2. Chúng tôi khám phá ra rằng LLM học các biểu diễn tuyến tính của không gian và thời gian qua nhiều quy mô. Các biểu diễn này mạnh mẽ trước các biến đổi gợi ý và thống nhất qua các loại thực thể khác nhau (ví dụ: thành phố và địa danh). Ngoài ra, chúng tôi xác định các "nơ-ron không gian" và "nơ-ron thời gian" riêng lẻ mã hóa một cách đáng tin cậy các tọa độ không gian và thời gian. Mặc dù cần điều tra thêm, kết quả của chúng tôi cho thấy các LLM hiện đại học được các biểu diễn không-thời gian phong phú của thế giới thực và sở hữu các thành phần cơ bản của một mô hình thế giới.

1 GIỚI THIỆU
Mặc dù chỉ được huấn luyện để dự đoán token tiếp theo, các mô hình ngôn ngữ lớn (LLM) hiện đại đã thể hiện một tập hợp khả năng ấn tượng (Bubeck et al., 2023; Wei et al., 2022), làm nảy sinh câu hỏi và lo ngại về những gì các mô hình như vậy thực sự đã học được. Một giả thuyết là LLM học một bộ sưu tập lớn các tương quan nhưng thiếu bất kỳ mô hình mạch lạc hoặc "hiểu biết" nào về quá trình tạo dữ liệu cơ bản với việc huấn luyện chỉ bằng văn bản (Bender & Koller, 2020; Bisk et al., 2020). Một giả thuyết khác là LLM, trong quá trình nén dữ liệu, học các mô hình nhỏ gọn, mạch lạc và có thể diễn giải hơn về quá trình tạo ra dữ liệu huấn luyện, tức là một mô hình thế giới. Ví dụ, Li et al. (2022) đã chỉ ra rằng các transformer được huấn luyện với dự đoán token tiếp theo để chơi trò chơi cờ Othello học các biểu diễn rõ ràng của trạng thái trò chơi, với Nanda et al. (2023) sau đó chỉ ra các biểu diễn này là tuyến tính. Những người khác đã chỉ ra rằng LLM theo dõi các trạng thái boolean của chủ thể trong ngữ cảnh (Li et al., 2021) và có các biểu diễn phản ánh cấu trúc nhận thức và khái niệm trong các lĩnh vực không gian và màu sắc (Patel & Pavlick, 2021; Abdou et al., 2021). Hiểu biết tốt hơn về việc liệu và cách LLM mô hình hóa thế giới là quan trọng để lý luận về tính mạnh mẽ, công bằng và an toàn của các hệ thống AI hiện tại và tương lai (Bender et al., 2021; Weidinger et al., 2022; Bommasani et al., 2021; Hendrycks et al., 2023; Ngo et al., 2023).

Trong công trình này, chúng tôi tiếp cận câu hỏi về việc liệu LLM có hình thành các mô hình thế giới (và thời gian) một cách theo nghĩa đen nhất có thể—chúng tôi cố gắng trích xuất một bản đồ thực tế của thế giới! Mặc dù các biểu diễn không-thời gian như vậy không cấu thành một mô hình thế giới nhân quả động trong chính chúng, việc có các biểu diễn không gian và thời gian mạch lạc đa quy mô là các thành phần cơ bản cần thiết trong một mô hình toàn diện hơn.

Cụ thể, chúng tôi xây dựng sáu bộ dữ liệu chứa tên của các địa điểm hoặc sự kiện với các tọa độ không gian hoặc thời gian tương ứng trải dài nhiều quy mô không-thời gian: các địa điểm trong toàn thế giới, Hoa Kỳ và Thành phố New York ngoài năm chết của các nhân vật lịch sử từ 3000 năm qua, ngày phát hành của nghệ thuật và giải trí từ những năm 1950 trở đi, và ngày xuất bản của các tiêu đề tin tức từ 2010 đến 2020. Sử dụng họ mô hình Llama-2 (Touvron et al., 2023) và Pythia Biderman et al. (2023), chúng tôi huấn luyện các đầu dò hồi quy tuyến tính (Alain & Bengio, 2016; Belinkov, 2022) trên các kích hoạt nội bộ của tên các địa điểm và sự kiện này tại mỗi lớp để dự đoán vị trí thế giới thực của chúng (tức là vĩ độ/kinh độ) hoặc thời gian (dấu thời gian số).

Các thí nghiệm đầu dò này tiết lộ bằng chứng rằng các mô hình xây dựng các biểu diễn không gian và thời gian xuyên suốt các lớp đầu trước khi đạt bình nguyên ở khoảng điểm giữa mô hình với các mô hình lớn hơn
1arXiv:2310.02207v3  [cs.LG]  4 Mar 2024

--- TRANG 2 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024
Hình 1: Các mô hình thế giới không gian và thời gian của Llama-2-70b. Mỗi điểm tương ứng với các kích hoạt lớp 50 của token cuối cùng của một địa điểm (trên) hoặc sự kiện (dưới) được chiếu lên hướng đầu dò tuyến tính đã học. Tất cả các điểm được mô tả đều từ tập kiểm tra.

liên tục vượt trội hơn các mô hình nhỏ hơn (§ 3.1). Sau đó chúng tôi chỉ ra các biểu diễn này là (1) tuyến tính, vì các đầu dò phi tuyến không hoạt động tốt hơn (§ 3.2), (2) khá mạnh mẽ trước các thay đổi trong gợi ý (§ 3.3), và (3) thống nhất qua các loại thực thể khác nhau (ví dụ: thành phố và địa danh tự nhiên). Sau đó chúng tôi tiến hành một loạt kiểm tra tính mạnh mẽ để hiểu cách các đầu dò của chúng tôi tổng quát hóa qua các phân phối dữ liệu khác nhau (§ 4.1) và cách các đầu dò được huấn luyện trên các thành phần PCA hoạt động (§ 4.2). Cuối cùng, chúng tôi sử dụng các đầu dò của mình để tìm các nơ-ron riêng lẻ kích hoạt như một hàm của không gian hoặc thời gian và sử dụng các can thiệp nhân quả cơ bản để xác minh tầm quan trọng của chúng trong mô hình hóa không-thời gian, cung cấp bằng chứng mạnh mẽ rằng mô hình thực sự sử dụng các đặc trưng này (§ 5).

2 TỔNG QUAN THỰC NGHIỆM

2.1 CÁC BỘ DỮ LIỆU KHÔNG GIAN VÀ THỜI GIAN THÔ
Để hỗ trợ điều tra của chúng tôi, chúng tôi xây dựng sáu bộ dữ liệu tên của các thực thể (người, địa điểm, sự kiện, v.v.) với vị trí hoặc sự xuất hiện tương ứng của chúng trong thời gian, mỗi bộ ở một bậc độ lớn quy mô khác nhau. Đối với mỗi bộ dữ liệu, chúng tôi bao gồm nhiều loại thực thể, ví dụ: cả các địa điểm có dân cư như thành phố và các địa danh tự nhiên như hồ, để nghiên cứu mức độ thống nhất của các biểu diễn qua các loại đối tượng khác nhau. Hơn nữa, chúng tôi duy trì hoặc làm phong phú siêu dữ liệu liên quan để cho phép phân tích dữ liệu với các phân tích chi tiết hơn, xác định các nguồn rò rỉ train-test, và hỗ trợ công việc tương lai về việc nhớ lại sự thật trong LLM. Chúng tôi cũng cố gắng khử trùng lặp và lọc ra dữ liệu mơ hồ hoặc nhiễu khác.

Không gian Chúng tôi xây dựng ba bộ dữ liệu tên địa điểm trong thế giới, Hoa Kỳ và Thành phố New York. Bộ dữ liệu thế giới của chúng tôi được xây dựng từ dữ liệu thô được truy vấn từ DBpedia Lehmann et al. (2015). Đặc biệt, chúng tôi truy vấn các địa điểm có dân cư, địa điểm tự nhiên và cấu trúc (ví dụ: tòa nhà hoặc cơ sở hạ tầng). Sau đó chúng tôi khớp chúng với các bài viết Wikipedia, và lọc ra các thực thể không có ít nhất 5.000 lượt xem trang trong khoảng thời gian ba năm. Bộ dữ liệu Hoa Kỳ của chúng tôi được xây dựng từ DBPedia và một bộ tổng hợp dữ liệu điều tra dân số, và bao gồm tên của các thành phố, quận, mã zip, trường đại học, địa điểm tự nhiên và cấu trúc nơi các địa điểm dân cư thưa thớt hoặc ít được xem tương tự được lọc ra. Cuối cùng, bộ dữ liệu Thành phố New York của chúng tôi được điều chỉnh từ bộ dữ liệu điểm quan tâm NYC OpenData (NYC OpenData, 2023) chứa các địa điểm như trường học, nhà thờ, cơ sở giao thông và nhà ở công cộng trong thành phố.

2

--- TRANG 3 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Thời gian Ba bộ dữ liệu thời gian của chúng tôi bao gồm (1) tên và nghề nghiệp của các nhân vật lịch sử chết từ 1000BC đến 2000AD được điều chỉnh từ (Annamoradnejad & Annamoradnejad, 2022); (2) tiêu đề và người sáng tạo của các bài hát, phim và sách từ 1950 đến 2020 được xây dựng từ DBpedia với kỹ thuật lọc lượt xem trang Wikipedia; và (3) tiêu đề tin tức New York Times từ 2010-2020 từ các bàn tin viết về các sự kiện hiện tại, được điều chỉnh từ (Bandy, 2021).

Bảng 1: Số lượng thực thể và ví dụ đại diện cho mỗi bộ dữ liệu của chúng tôi.
Bộ dữ liệu | Số lượng | Ví dụ
Thế giới | 39585 | "Los Angeles", "St. Peter's Basilica", "Caspian Sea", "Canary Islands"
Hoa Kỳ | 29997 | "Fenway Park", "Columbia University", "Riverside County"
NYC | 19838 | "Borden Avenue Bridge", "Trump International Hotel"
Nhân vật | 37539 | "Cleopatra", "Dante Alighieri", "Carl Sagan", "Blanche of Castile"
Nghệ thuật | 31321 | "Stephen King's It", "Queen's Bohemian Rhapsody"
Tiêu đề | 28389 | "Pilgrims, Fewer and Socially Distanced, Arrive in Mecca for Annual Hajj"

2.2 CÁC MÔ HÌNH VÀ PHƯƠNG PHÁP

Chuẩn bị Dữ liệu Tất cả các thí nghiệm của chúng tôi được chạy với dòng mô hình ngôn ngữ transformer tự hồi quy Llama-2 cơ bản (Touvron et al., 2023), trải dài từ 7 tỷ đến 70 tỷ tham số. Đối với mỗi bộ dữ liệu, chúng tôi chạy mọi tên thực thể qua mô hình, có thể được thêm trước với một gợi ý ngắn, và lưu các kích hoạt của trạng thái ẩn (dòng dư) trên token thực thể cuối cùng cho mỗi lớp. Đối với một tập hợp n_entities, điều này tạo ra một bộ dữ liệu kích hoạt n×d_model cho mỗi lớp.

Đầu dò Để tìm bằng chứng về các biểu diễn không gian và thời gian trong LLM, chúng tôi sử dụng kỹ thuật tiêu chuẩn của đầu dò Alain & Bengio (2016); Belinkov (2022), bao gồm việc khớp một mô hình đơn giản trên các kích hoạt mạng để dự đoán một số nhãn mục tiêu được liên kết với dữ liệu đầu vào có nhãn. Đặc biệt, cho một bộ dữ liệu kích hoạt A∈R^(n×d_model), và một mục tiêu Y chứa thời gian hoặc tọa độ vĩ độ và kinh độ hai chiều, chúng tôi khớp các đầu dò hồi quy ridge tuyến tính

Ŵ = arg min_W ||Y - AW||²_2 + λ||W||²_2 = (A^T A + λI)^(-1) A^T Y

tạo ra một bộ dự đoán tuyến tính Ŷ = AŴ. Hiệu suất dự đoán cao trên dữ liệu ngoài mẫu cho thấy rằng mô hình cơ sở có thông tin thời gian và không gian có thể giải mã tuyến tính trong các biểu diễn của nó, mặc dù điều này không ngụ ý rằng mô hình thực sự sử dụng các biểu diễn này (Ravichander et al., 2020). Trong tất cả các thí nghiệm, chúng tôi điều chỉnh λ sử dụng xác thực chéo leave-out-out hiệu quả (Hastie et al., 2009) trên tập huấn luyện đầu dò.

2.3 ĐÁNH GIÁ
Để đánh giá hiệu suất của các đầu dò, chúng tôi báo cáo các chỉ số hồi quy tiêu chuẩn như R² và tương quan thứ hạng Spearman trên dữ liệu kiểm tra của chúng tôi (tương quan được tính trung bình qua vĩ độ và kinh độ cho các đặc trưng không gian). Một chỉ số bổ sung mà chúng tôi tính toán là lỗi gần kề cho mỗi dự đoán, được định nghĩa là tỷ lệ các thực thể được dự đoán gần điểm mục tiêu hơn so với dự đoán của thực thể mục tiêu. Trực giác là đối với dữ liệu không gian, các chỉ số lỗi tuyệt đối có thể gây hiểu lầm (lỗi 500km cho một thành phố ở Bờ Đông Hoa Kỳ quan trọng hơn nhiều so với lỗi 500km ở Siberia), vì vậy khi phân tích lỗi cho mỗi dự đoán, chúng tôi thường báo cáo chỉ số này để tính đến sự khác biệt địa phương trong độ chính xác mong muốn.

3 CÁC MÔ HÌNH TUYẾN TÍNH CỦA KHÔNG GIAN VÀ THỜI GIAN

3.1 SỰ TỒN TẠI
Đầu tiên chúng tôi điều tra các câu hỏi thực nghiệm sau: liệu các mô hình có biểu diễn thời gian và không gian hay không? Nếu có, ở đâu bên trong mô hình? Chất lượng biểu diễn có thay đổi đáng kể theo quy mô mô hình không? Trong thí nghiệm đầu tiên, chúng tôi huấn luyện các đầu dò cho mọi lớp của Llama-2-{7B, 13B, 70B} và

3

--- TRANG 4 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hình 2: R² ngoài mẫu cho các đầu dò tuyến tính được huấn luyện trên mọi mô hình, bộ dữ liệu và lớp.

Pythia-{160M, 410M, 1B, 1.4B, 2.8B, 6.9B} cho mỗi bộ dữ liệu không gian và thời gian của chúng tôi. Kết quả chính của chúng tôi, được mô tả trong Hình 2, cho thấy các mẫu khá nhất quán qua các bộ dữ liệu. Đặc biệt, cả các đặc trưng không gian và thời gian đều có thể được khôi phục bằng một đầu dò tuyến tính, các biểu diễn này tăng dần về chất lượng xuyên suốt nửa đầu các lớp của mô hình trước khi đạt đến một bình nguyên, và các biểu diễn chính xác hơn với quy mô mô hình tăng. Khoảng cách giữa các mô hình Llama và Pythia đặc biệt nổi bật, và chúng tôi nghi ngờ là do sự khác biệt lớn về kích thước corpus tiền huấn luyện (lần lượt là 2T và 300B token). Vì lý do này, chúng tôi báo cáo phần còn lại của kết quả chỉ trên các mô hình Llama.

Bộ dữ liệu có hiệu suất tệ nhất là bộ dữ liệu Thành phố New York. Điều này được mong đợi do tính mơ hồ tương đối của hầu hết các thực thể so với các bộ dữ liệu khác. Tuy nhiên, đây cũng là bộ dữ liệu mà mô hình lớn nhất có hiệu suất tương đối tốt nhất, cho thấy rằng các LLM đủ lớn cuối cùng có thể hình thành các mô hình không gian chi tiết của từng thành phố.

3.2 CÁC BIỂU DIỄN TUYẾN TÍNH
Trong văn học về khả năng diễn giải, có một tập hợp bằng chứng ngày càng tăng hỗ trợ giả thuyết biểu diễn tuyến tính rằng các đặc trưng trong mạng nơ-ron được biểu diễn tuyến tính, nghĩa là sự hiện diện hoặc cường độ của một đặc trưng có thể được đọc ra bằng cách chiếu kích hoạt liên quan lên một vector đặc trưng nào đó (Mikolov et al., 2013b; Olah et al., 2020; Elhage et al., 2022b). Tuy nhiên, các kết quả này hầu như luôn dành cho các đặc trưng nhị phân hoặc phân loại, không giống như các đặc trưng liên tục của không gian hoặc thời gian.

Để kiểm tra liệu các đặc trưng không gian và thời gian có được biểu diễn tuyến tính hay không, chúng tôi so sánh hiệu suất của các đầu dò hồi quy ridge tuyến tính với hiệu suất của các đầu dò MLP phi tuyến biểu cảm hơn đáng kể có dạng W₂ReLU(W₁x + b₁) + b₂ với 256 nơ-ron. Bảng 2 báo cáo kết quả của chúng tôi và cho thấy việc sử dụng các đầu dò phi tuyến dẫn đến cải thiện tối thiểu về R² cho bất kỳ bộ dữ liệu hoặc mô hình nào. Chúng tôi coi điều này là bằng chứng mạnh mẽ rằng không gian và thời gian cũng được biểu diễn tuyến tính (hoặc ít nhất là có thể giải mã tuyến tính), mặc dù là liên tục.

3.3 ĐỘ NHẠY CẢM VỚI GỢI Ý
Một câu hỏi tự nhiên khác là liệu các đặc trưng không gian hoặc thời gian này có nhạy cảm với gợi ý hay không, nghĩa là liệu ngữ cảnh có thể gây ra hoặc ngăn chặn việc nhớ lại các sự thật này hay không. Theo trực giác, đối với bất kỳ token thực thể nào, một mô hình tự hồi quy được khuyến khích tạo ra một biểu diễn phù hợp để giải quyết bất kỳ ngữ cảnh hoặc câu hỏi tương lai có thể nào.

4

--- TRANG 5 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hình 3: R² ngoài mẫu khi tên thực thể được bao gồm trong các gợi ý khác nhau cho Llama-2-70b.

Để nghiên cứu điều này, chúng tôi tạo các bộ dữ liệu kích hoạt mới nơi chúng tôi thêm trước các gợi ý khác nhau cho mỗi token thực thể, theo một vài chủ đề cơ bản. Trong tất cả các trường hợp, chúng tôi bao gồm một gợi ý "trống" không chứa gì khác ngoài các token thực thể (và một token bắt đầu chuỗi). Sau đó chúng tôi bao gồm một gợi ý yêu cầu mô hình nhớ lại sự thật liên quan, ví dụ: "Vĩ độ và kinh độ của <địa điểm> là gì" hoặc "Ngày phát hành của <tác giả>'s <sách> là gì." Đối với các bộ dữ liệu Hoa Kỳ và NYC, chúng tôi cũng bao gồm các phiên bản của những gợi ý này hỏi nơi ở Hoa Kỳ hoặc NYC địa điểm này nằm ở đâu, trong nỗ lực phân biệt các tên địa điểm thông thường (ví dụ: City Hall). Như một đường cơ sở, chúng tôi bao gồm một gợi ý gồm 10 token ngẫu nhiên (được lấy mẫu cho mỗi thực thể). Để xác định liệu chúng tôi có thể che khuất chủ thể hay không, đối với một số bộ dữ liệu, chúng tôi viết hoa hoàn toàn tên của tất cả các thực thể. Cuối cùng, đối với bộ dữ liệu tiêu đề, chúng tôi thử đầu dò cả trên token cuối cùng và trên token dấu chấm được thêm vào tiêu đề.

Chúng tôi báo cáo kết quả cho mô hình 70B trong Hình 3 và tất cả các mô hình trong Hình 8. Chúng tôi thấy rằng việc gợi ý rõ ràng cho mô hình về thông tin, hoặc đưa ra gợi ý phân biệt như một địa điểm nằm ở Hoa Kỳ hoặc NYC, tạo ra ít hoặc không có sự khác biệt trong hiệu suất. Tuy nhiên, chúng tôi bị ngạc nhiên bởi mức độ mà các token phân tán ngẫu nhiên làm giảm hiệu suất. Việc viết hoa các thực thể cũng làm giảm hiệu suất, mặc dù ít nghiêm trọng hơn và ít bất ngờ hơn, vì điều này có thể can thiệp vào việc "detokenizing" thực thể (Elhage et al., 2022a; Gurnee et al., 2023; Geva et al., 2023). Một sửa đổi đã cải thiện hiệu suất đáng chú ý là đầu dò trên token dấu chấm theo sau tiêu đề, cho thấy rằng dấu chấm được sử dụng để chứa một số thông tin tóm tắt của các câu mà chúng kết thúc.

Bảng 2: R² ngoài mẫu của các đầu dò tuyến tính và phi tuyến (MLP một lớp) cho tất cả các mô hình và đặc trưng ở độ sâu lớp 60%.

Bộ dữ liệu
Mô hình | Đầu dò | Thế giới | Hoa Kỳ | NYC | Lịch sử | Giải trí | Tiêu đề
Llama-2-7b | Tuyến tính | 0.881 | 0.799 | 0.219 | 0.785 | 0.788 | 0.564
          | MLP | 0.897 | 0.819 | 0.204 | 0.775 | 0.746 | 0.467
Llama-2-13b | Tuyến tính | 0.896 | 0.825 | 0.237 | 0.804 | 0.806 | 0.645
           | MLP | 0.916 | 0.824 | 0.230 | 0.818 | 0.808 | 0.656
Llama-2-70b | Tuyến tính | 0.911 | 0.864 | 0.359 | 0.835 | 0.885 | 0.746
           | MLP | 0.926 | 0.869 | 0.312 | 0.839 | 0.884 | 0.739

5

--- TRANG 6 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

4 KIỂM TRA TÍNH MẠNH MẼ
Phần trước đã chỉ ra rằng điểm thực sự trong thời gian hoặc không gian của các loại sự kiện hoặc địa điểm đa dạng có thể được khôi phục tuyến tính từ các kích hoạt nội bộ của các lớp giữa đến cuối của LLM. Tuy nhiên, điều này không ngụ ý liệu (hoặc cách) một mô hình thực sự sử dụng hướng đặc trưng được học bởi đầu dò, vì bản thân đầu dò có thể đang học một tổ hợp tuyến tính nào đó của các đặc trưng đơn giản hơn thực sự được mô hình sử dụng.

4.1 XÁC MINH QUA TỔNG QUÁT HÓA

Tổng quát hóa khối giữ lại Để minh họa một vấn đề tiềm năng với kết quả của chúng tôi, hãy xem xét nhiệm vụ biểu diễn bản đồ thế giới đầy đủ. Nếu mô hình có, như chúng tôi mong đợi, một đặc trưng nhị phân gần như trực giao cho is_in_country_X, thì người ta có thể xây dựng một đầu dò vĩ độ (kinh độ) chất lượng cao bằng cách tổng các vector đặc trưng trực giao này cho mỗi quốc gia với hệ số bằng vĩ độ (kinh độ) của quốc gia đó. Giả sử một địa điểm chỉ ở một quốc gia, một đầu dò như vậy sẽ đặt mỗi thực thể tại trọng tâm quốc gia của nó. Tuy nhiên, trong trường hợp này, mô hình không thực sự biểu diễn không gian, chỉ có tư cách thành viên quốc gia, và chỉ có đầu dò học hình học của các quốc gia khác nhau từ sự giám sát rõ ràng.

Để phân biệt tốt hơn các trường hợp này, chúng tôi phân tích cách các đầu dò tổng quát hóa khi giữ lại các khối dữ liệu cụ thể. Đặc biệt, chúng tôi huấn luyện một loạt đầu dò, trong đó đối với mỗi đầu dò, chúng tôi giữ lại một quốc gia, bang, quận, thế kỷ, thập kỷ, hoặc năm cho bộ dữ liệu thế giới, Hoa Kỳ, NYC, nhân vật lịch sử, giải trí và tiêu đề tương ứng. Sau đó chúng tôi đánh giá các đầu dò trên khối dữ liệu được giữ lại. Trong Bảng 3, chúng tôi báo cáo lỗi gần kề trung bình cho khối dữ liệu khi được giữ lại hoàn toàn, so với lỗi của các điểm kiểm tra từ khối đó trong phân chia train-test mặc định, được tính trung bình qua tất cả các khối được giữ lại.

Chúng tôi thấy rằng mặc dù hiệu suất tổng quát hóa bị ảnh hưởng, đặc biệt là đối với các bộ dữ liệu không gian, nó rõ ràng tốt hơn ngẫu nhiên. Bằng cách vẽ các dự đoán của các bang hoặc quốc gia được giữ lại trong Hình 11 và 12, một bức tranh định tính rõ ràng hơn xuất hiện. Nghĩa là, đầu dò tổng quát hóa chính xác bằng cách đặt các điểm ở vị trí tương đối chính xác (được đo bằng góc giữa trọng tâm thực và dự đoán) nhưng không ở vị trí tuyệt đối của chúng. Chúng tôi coi điều này là bằng chứng yếu rằng các đầu dò đang trích xuất các đặc trưng được học rõ ràng bởi mô hình, nhưng đang ghi nhớ việc chuyển đổi từ tọa độ mô hình sang tọa độ con người. Tuy nhiên, điều này không hoàn toàn loại trừ giả thuyết các đặc trưng nhị phân cơ bản, vì có thể có một hệ thống phân cấp của các đặc trưng như vậy không tuân theo ranh giới quốc gia hoặc thập kỷ.

Bảng 3: Lỗi gần kề trung bình qua các khối dữ liệu (ví dụ: quốc gia, bang, thập kỷ) khi được bao gồm trong dữ liệu huấn luyện so với được giữ lại hoàn toàn. Hiệu suất ngẫu nhiên là 0.5.

Bộ dữ liệu
Mô hình | Khối | Thế giới | Hoa Kỳ | NYC | Lịch sử | Giải trí | Tiêu đề
Llama-2-7b | danh nghĩa | 0.071 | 0.144 | 0.331 | 0.129 | 0.147 | 0.258
           | giữ lại | 0.170 | 0.192 | 0.473 | 0.133 | 0.158 | 0.264
Llama-2-13b | danh nghĩa | 0.068 | 0.144 | 0.319 | 0.121 | 0.141 | 0.223
            | giữ lại | 0.156 | 0.189 | 0.470 | 0.126 | 0.152 | 0.235
Llama-2-70b | danh nghĩa | 0.071 | 0.121 | 0.262 | 0.115 | 0.105 | 0.182
            | giữ lại | 0.164 | 0.188 | 0.433 | 0.119 | 0.122 | 0.200

Tổng quát hóa chéo thực thể Ngầm định trong thảo luận của chúng tôi cho đến nay là tuyên bố rằng mô hình biểu diễn tọa độ không gian hoặc thời gian của các loại thực thể khác nhau (như thành phố hoặc địa danh tự nhiên) theo cách thống nhất. Tuy nhiên, tương tự như mối quan tâm rằng một đầu dò vĩ độ có thể là tổng có trọng số của các đặc trưng thành viên, một đầu dò vĩ độ cũng có thể là tổng của các hướng khác nhau (trực giao) cho vĩ độ của các thành phố và cho vĩ độ của các địa danh tự nhiên.

6

--- TRANG 7 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Tương tự như trên, chúng tôi phân biệt các giả thuyết này bằng cách huấn luyện một loạt đầu dò nơi phân chia train-test được thực hiện để giữ lại tất cả các điểm của một lớp thực thể cụ thể.¹ Bảng 4 báo cáo lỗi gần kề cho các thực thể trong phân chia kiểm tra mặc định so với khi được giữ lại, được tính trung bình qua tất cả các phân chia như vậy như trước. Kết quả cho thấy các đầu dò chủ yếu tổng quát hóa qua các loại thực thể, với ngoại lệ chính là bộ dữ liệu giải trí.²

Bảng 4: Lỗi gần kề trung bình qua các loại thực thể con (ví dụ: sách và phim) khi được bao gồm trong dữ liệu huấn luyện so với được giữ lại hoàn toàn. Hiệu suất ngẫu nhiên là 0.5.

Bộ dữ liệu
Mô hình | Thực thể | Thế giới | Hoa Kỳ | NYC | Lịch sử | Giải trí | Tiêu đề
Llama-2-7b | danh nghĩa | 0.120 | 0.206 | 0.313 | 0.164 | 0.224 | 0.199
           | giữ lại | 0.151 | 0.262 | 0.367 | 0.168 | 0.305 | 0.289
Llama-2-13b | danh nghĩa | 0.117 | 0.197 | 0.310 | 0.153 | 0.207 | 0.171
            | giữ lại | 0.147 | 0.259 | 0.377 | 0.159 | 0.283 | 0.266
Llama-2-70b | danh nghĩa | 0.113 | 0.173 | 0.266 | 0.149 | 0.159 | 0.144
            | giữ lại | 0.147 | 0.203 | 0.322 | 0.149 | 0.271 | 0.219

4.2 GIẢM CHIỀU
Mặc dù là tuyến tính, các đầu dò của chúng tôi vẫn có d_model tham số có thể học (từ 4096 đến 8192 cho các mô hình 7B đến 70B), cho phép nó tham gia vào việc ghi nhớ đáng kể. Như một dạng bằng chứng bổ sung cho các thí nghiệm tổng quát hóa, chúng tôi huấn luyện các đầu dò với ít hơn 2 đến 3 bậc độ lớn tham số bằng cách chiếu các bộ dữ liệu kích hoạt lên k thành phần chính lớn nhất của chúng.

Hình 4 minh họa R² kiểm tra cho các đầu dò được huấn luyện trên mỗi mô hình và bộ dữ liệu qua một phạm vi giá trị k, so với hiệu suất của đầu dò d_model-chiều đầy đủ. Chúng tôi cũng báo cáo tương quan Spearman kiểm tra trong Hình 13 tăng nhanh hơn nhiều với k tăng so với R². Đáng chú ý, tương quan Spearman chỉ phụ thuộc vào thứ tự xếp hạng của các dự đoán trong khi R² cũng phụ thuộc vào giá trị thực tế của chúng. Chúng tôi xem khoảng cách này là bằng chứng thêm rằng mô hình biểu diễn rõ ràng không gian và thời gian vì các đặc trưng này phải chiếm đủ phương sai để nằm trong top dozen thành phần chính, nhưng đầu dò cần nhiều tham số hơn để chuyển đổi từ hệ tọa độ của mô hình sang tọa độ không gian theo nghĩa đen hoặc dấu thời gian. Chúng tôi cũng quan sát thấy rằng các thành phần chính đầu tiên nhóm các loại thực thể khác nhau trong bộ dữ liệu, giải thích tại sao cần nhiều hơn một vài thành phần.

Hình 4: R² kiểm tra cho các đầu dò được huấn luyện trên các kích hoạt được chiếu lên k thành phần chính lớn nhất cho mỗi bộ dữ liệu và mô hình so với huấn luyện trên các kích hoạt đầy đủ.

¹ Chúng tôi chỉ làm điều này với các thực thể không chiếm đa số dữ liệu huấn luyện (ví dụ: như trường hợp của các địa điểm có dân cư cho bộ dữ liệu thế giới và các bài hát cho bộ dữ liệu giải trí) một phần chịu trách nhiệm cho sự khác biệt trong các trường hợp danh nghĩa cho Bảng 3 và 4.

² Chúng tôi lưu ý trong trường hợp này tương quan Spearman vẫn cao, cho thấy đây là vấn đề tổng quát hóa độ lệch, vì các loại thực thể khác nhau không được phân phối đồng đều trong thời gian.

7

--- TRANG 8 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hình 5: Các nơ-ron không gian và thời gian trong các mô hình Llama-2. Mô tả kết quả chiếu các bộ dữ liệu kích hoạt lên trọng số nơ-ron so với tọa độ không gian hoặc thời gian thực với tương quan Spearman theo loại thực thể.

5 CÁC NƠ-RON KHÔNG GIAN VÀ THỜI GIAN
Mặc dù các kết quả trước đây gợi ý, không có bằng chứng nào của chúng tôi trực tiếp chỉ ra rằng mô hình sử dụng các đặc trưng được học bởi đầu dò. Để giải quyết điều này, chúng tôi tìm kiếm các nơ-ron riêng lẻ với trọng số đầu vào hoặc đầu ra có độ tương tự cosine cao với hướng đầu dò đã học. Nghĩa là, chúng tôi tìm kiếm các nơ-ron đọc từ hoặc ghi vào một hướng tương tự như hướng được học bởi đầu dò.

Chúng tôi thấy rằng khi chúng tôi chiếu các bộ dữ liệu kích hoạt lên trọng số của các nơ-ron tương tự nhất, các nơ-ron này thực sự rất nhạy cảm với vị trí thực của các thực thể trong không gian hoặc thời gian (xem Hình 5). Nói cách khác, tồn tại các nơ-ron riêng lẻ trong mô hình mà bản thân chúng là các đầu dò đặc trưng dự đoán khá tốt. Hơn nữa, các nơ-ron này nhạy cảm với tất cả các loại thực thể trong bộ dữ liệu của chúng tôi, cung cấp bằng chứng mạnh mẽ hơn cho tuyên bố rằng các biểu diễn này được thống nhất.

Nếu các đầu dò được huấn luyện với sự giám sát rõ ràng là giới hạn trên gần đúng về mức độ mà một mô hình biểu diễn các đặc trưng không gian và thời gian này, thì hiệu suất của các nơ-ron riêng lẻ là giới hạn dưới. Đặc biệt, chúng tôi thường mong đợi các đặc trưng được phân phối trong siêu vị trí (Elhage et al., 2022b), làm cho các nơ-ron riêng lẻ trở thành mức phân tích sai. Tuy nhiên, sự tồn tại của các nơ-ron riêng lẻ này, không nhận được sự giám sát nào khác ngoài dự đoán token tiếp theo, là bằng chứng rất mạnh mẽ rằng mô hình đã học và sử dụng các đặc trưng không gian và thời gian.

Chúng tôi cũng thực hiện một loạt thí nghiệm khử và can thiệp nơ-ron trong Phụ lục B để xác minh tầm quan trọng của các nơ-ron này trong mô hình hóa không-thời gian.

6 CÔNG TRÌNH LIÊN QUAN

Các Mô hình Không gian Ngôn ngữ học Công trình trước đây đã chỉ ra rằng ngôn ngữ tự nhiên mã hóa thông tin địa lý (Louwerse & Zwaan, 2009; Louwerse & Benesh, 2012) và các tọa độ tương đối có thể được khôi phục gần đúng với các kỹ thuật đơn giản như tỷ lệ đa chiều, thống kê đồng xuất hiện, hoặc đầu dò từ nhúng (Louwerse & Zwaan, 2009; Mikolov et al., 2013a; Gupta et al., 2015; Konkol et al., 2017). Tuy nhiên, các nghiên cứu này chỉ xem xét vài trăm thành phố nổi tiếng và thu được các tương quan khá yếu. Gần nhất với công trình của chúng tôi là (Liétard et al., 2021) những người đầu dò từ nhúng và các mô hình ngôn ngữ nhỏ cho tọa độ của các thành phố toàn cầu và liệu các quốc gia có chia sẻ biên giới hay không, nhưng kết luận rằng lượng thông tin địa lý được học là "hạn chế," có thể vì mô hình lớn nhất họ nghiên cứu là 345M tham số (nhỏ hơn 500 lần so với Llama 70B).

Các Mô hình Thế giới Nơ-ron Chúng tôi coi một mô hình không-thời gian là một thành phần cần thiết trong một mô hình thế giới lớn hơn. Bằng chứng rõ ràng nhất rằng các mô hình như vậy có thể học được từ dự đoán token tiếp theo đến từ các mô hình kiểu GPT được huấn luyện trên cờ vua (Toshniwal et al., 2022) và các trò chơi Othello (Li et al., 2022) được chỉ ra có các biểu diễn rõ ràng của bàn cờ và trạng thái trò chơi, với công trình tiếp theo chỉ ra các biểu diễn này là tuyến tính (Nanda et al., 2023). Trong các LLM thực, Li et al. (2021) chỉ ra rằng các thuộc tính động hoặc quan hệ của một thực thể có thể được đọc ra tuyến tính từ các biểu diễn tại các điểm khác nhau trong ngữ cảnh. Abdou et al. (2021) và Patel & Pavlick (2021) chỉ ra LLM có các biểu diễn phản ánh cấu trúc nhận thức và khái niệm trong các lĩnh vực màu sắc và không gian.

Nhớ lại Sự thật Điểm trong thời gian hoặc không gian của một sự kiện hoặc địa điểm là một loại sự thật cụ thể. Điều tra của chúng tôi được thông báo bởi công trình trước đó về các cơ chế nhớ lại sự thật trong LLM (Meng et al., 2022a;b; Geva et al., 2023) chỉ ra rằng các lớp MLP đầu đến giữa chịu trách nhiệm xuất thông tin về các chủ thể sự thật, thường trên token cuối cùng của chủ thể. Nhiều công trình này cũng chỉ ra cấu trúc tuyến tính, ví dụ trong tính sự thật của một tuyên bố (Burns et al., 2022) hoặc trong cấu trúc của các quan hệ chủ thể-đối tượng (Hernandez et al., 2023). Theo hiểu biết của chúng tôi, công trình của chúng tôi là độc nhất trong việc xem xét các sự thật liên tục.

Khả năng Diễn giải Rộng hơn, công trình của chúng tôi rút ra nhiều kết quả và ý tưởng từ văn học về khả năng diễn giải (Räuker et al., 2023), đặc biệt trong các chủ đề liên quan đến đầu dò (Belinkov, 2022), BERTology (Rogers et al., 2021), giả thuyết tuyến tính và siêu vị trí (Elhage et al., 2022b), và khả năng diễn giải cơ học (Olah et al., 2020). Các kết quả cụ thể hơn liên quan đến công trình của chúng tôi bao gồm Hanna et al. (2023) những người tìm thấy một mạch thực hiện greater-than trong ngữ cảnh của năm, và Goh et al. (2021) những người tìm thấy các nơ-ron "vùng" trong các mô hình đa phương thức giống với các nơ-ron không gian của chúng tôi.

7 THẢO LUẬN
Chúng tôi đã chứng minh rằng LLM học các biểu diễn tuyến tính của không gian và thời gian được thống nhất qua các loại thực thể và khá mạnh mẽ trước gợi ý, và tồn tại các nơ-ron riêng lẻ rất nhạy cảm với các đặc trưng này. Chúng tôi phỏng đoán, nhưng không chỉ ra, các nguyên tắc cơ bản này nằm dưới một mô hình thế giới nhân quả toàn diện hơn được sử dụng cho suy luận và dự đoán.

Phân tích của chúng tôi nâng ra nhiều câu hỏi thú vị cho công việc tương lai. Mặc dù chúng tôi chỉ ra rằng có thể tái tạo tuyến tính vị trí tuyệt đối của một mẫu trong không gian hoặc thời gian, và một số nơ-ron sử dụng các hướng đầu dò này, mức độ thực sự và cấu trúc của các biểu diễn không gian và thời gian vẫn không rõ ràng. Chúng tôi phỏng đoán rằng dạng chính tắc nhất của cấu trúc này là một lưới phân cấp rời rạc, nơi bất kỳ mẫu nào được biểu diễn như một tổ hợp tuyến tính của các điểm cơ sở gần nhất tại mỗi mức độ chi tiết. Hơn nữa, mô hình có thể và sử dụng hệ tọa độ này để biểu diễn vị trí tuyệt đối bằng cách sử dụng tổ hợp tuyến tính chính xác của các hướng cơ sở theo cách mà một đầu dò tuyến tính sẽ làm. Chúng tôi mong đợi rằng khi các mô hình mở rộng, lưới này được tăng cường với nhiều điểm cơ sở hơn, nhiều quy mô chi tiết hơn (ví dụ: khu phố trong các thành phố), và ánh xạ chính xác hơn của các thực thể tới tọa độ mô hình (Michaud et al., 2023). Điều này gợi ý công việc tương lai về trích xuất các biểu diễn trong hệ tọa độ của mô hình thay vì cố gắng tái tạo tọa độ có thể diễn giải bởi con người, có thể với các bộ tự mã hóa thưa (Cunningham et al., 2023).

Chúng tôi cũng hầu như không chạm vào bề mặt của việc hiểu cách các mô hình không gian và thời gian này được học, nhớ lại và sử dụng nội bộ, hoặc mức độ nào các biểu diễn này tồn tại trong một mô hình thế giới toàn diện hơn. Bằng cách nhìn qua các checkpoint huấn luyện, có thể định vị một điểm trong huấn luyện khi một mô hình tổ chức các đặc trưng is_in_place_X thành phần thành một hình học mạch lạc hoặc kết luận quá trình này là dần dần (Liu et al., 2021). Chúng tôi mong đợi rằng các thành phần mô hình xây dựng các biểu diễn này tương tự hoặc giống hệt với những thành phần cho nhớ lại sự thật (Meng et al., 2022a; Geva et al., 2023).

Cuối cùng, chúng tôi lưu ý rằng việc biểu diễn không gian và thời gian đã nhận được nhiều chú ý hơn trong các mạng nơ-ron sinh học so với các mạng nhân tạo (Buzsáki & Llinás, 2017; Schonhaut et al., 2023). Đặc biệt các tế bào địa điểm và lưới (O'Keefe & Dostrovsky, 1971; Hafting et al., 2005) là một trong những tế bào được nghiên cứu kỹ nhất trong não và có thể là một nguồn cảm hứng hữu ích cho công việc tương lai về LLM.

9

--- TRANG 10 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

LỜI CẢM ƠN
Các tác giả muốn cảm ơn Sam Marks, Eric Michaud, Ziming Liu, Janice Yang, và đặc biệt là Neel Nanda cho các cuộc thảo luận và phản hồi hữu ích của họ. W.G. được hỗ trợ bởi Dimitris Bertsimas và một khoản tài trợ sự nghiệp đầu tiên của Open Philanthropy trong suốt quá trình thực hiện công trình này.

TÀI LIỆU THAM KHẢO
Mostafa Abdou, Artur Kulmizev, Daniel Hershcovich, Stella Frank, Ellie Pavlick, và Anders Søgaard. Can language models encode perceptual structure without grounding? a case study in color. arXiv preprint arXiv:2109.06129, 2021.

Guillaume Alain và Yoshua Bengio. Understanding intermediate layers using linear classifier probes. arXiv preprint arXiv:1610.01644, 2016.

Issa Annamoradnejad và Rahimberdi Annamoradnejad. Age dataset: A structured general-purpose dataset on life, work, and death of 1.22 million distinguished people. International AAAI Conference on Web and Social Media (ICWSM), 16, 2022.

Jack Bandy. Three decades of new york times headlines, 2021. URL https://www.kaggle.com/datasets/johnbandy/new-york-times-headlines. Kaggle dataset.

Yonatan Belinkov. Probing classifiers: Promises, shortcomings, and advances. Computational Linguistics, 48(1):207–219, 2022.

Emily M Bender và Alexander Koller. Climbing towards nlu: On meaning, form, and understanding in the age of data. In Proceedings of the 58th annual meeting of the association for computational linguistics, pp. 5185–5198, 2020.

Emily M Bender, Timnit Gebru, Angelina McMillan-Major, và Shmargaret Shmitchell. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pp. 610–623, 2021.

Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O'Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al. Pythia: A suite for analyzing large language models across training and scaling. In International Conference on Machine Learning, pp. 2397–2430. PMLR, 2023.

Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua Bengio, Joyce Chai, Mirella Lapata, Angeliki Lazaridou, Jonathan May, Aleksandr Nisnevich, et al. Experience grounds language. arXiv preprint arXiv:2004.10151, 2020.

Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.

Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.

Collin Burns, Haotian Ye, Dan Klein, và Jacob Steinhardt. Discovering latent knowledge in language models without supervision. arXiv preprint arXiv:2212.03827, 2022.

György Buzsáki và Rodolfo Llinás. Space and time in the brain. Science, 358(6362):482–485, 2017.

Hoagy Cunningham, Aidan Ewart, Logan Riggs, Robert Huben, và Lee Sharkey. Sparse autoencoders find highly interpretable features in language models. arXiv preprint arXiv:2309.08600, 2023.

10

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Nelson Elhage, Tristan Hume, Catherine Olsson, Neel Nanda, Tom Henighan, Scott Johnston, Sheer ElShowk, Nicholas Joseph, Nova DasSarma, Ben Mann, Danny Hernandez, Amanda Askell, Kamal Ndousse, Andy Jones, Dawn Drain, Anna Chen, Yuntao Bai, Deep Ganguli, Liane Lovitt, Zac Hatfield-Dodds, Jackson Kernion, Tom Conerly, Shauna Kravec, Stanislav Fort, Saurav Kadavath, Josh Jacobson, Eli Tran-Johnson, Jared Kaplan, Jack Clark, Tom Brown, Sam McCandlish, Dario Amodei, và Christopher Olah. Softmax linear units. Transformer Circuits Thread, 2022a. https://transformer-circuits.pub/2022/solu/index.html.

Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield-Dodds, Robert Lasenby, Dawn Drain, Carol Chen, et al. Toy models of superposition. arXiv preprint arXiv:2209.10652, 2022b.

Mor Geva, Jasmijn Bastings, Katja Filippova, và Amir Globerson. Dissecting recall of factual associations in auto-regressive language models. arXiv preprint arXiv:2304.14767, 2023.

Gabriel Goh, Nick Cammarata, Chelsea Voss, Shan Carter, Michael Petrov, Ludwig Schubert, Alec Radford, và Chris Olah. Multimodal neurons in artificial neural networks. Distill, 6(3):e30, 2021.

Abhijeet Gupta, Gemma Boleda, Marco Baroni, và Sebastian Padó. Distributional vectors encode referential attributes. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 12–21, 2015.

Wes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii, và Dimitris Bertsimas. Finding neurons in a haystack: Case studies with sparse probing. arXiv preprint arXiv:2305.01610, 2023.

Torkel Hafting, Marianne Fyhn, Sturla Molden, May-Britt Moser, và Edvard I Moser. Microstructure of a spatial map in the entorhinal cortex. Nature, 436(7052):801–806, 2005.

Michael Hanna, Ollie Liu, và Alexandre Variengien. How does gpt-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. arXiv preprint arXiv:2305.00586, 2023.

Trevor Hastie, Robert Tibshirani, Jerome H Friedman, và Jerome H Friedman. The elements of statistical learning: data mining, inference, and prediction, volume 2. Springer, 2009.

Dan Hendrycks, Mantas Mazeika, và Thomas Woodside. An overview of catastrophic ai risks. arXiv preprint arXiv:2306.12001, 2023.

Evan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas, Yonatan Belinkov, và David Bau. Linearity of relation decoding in transformer language models. arXiv preprint arXiv:2308.09124, 2023.

Michal Konkol, Tomáš Brychcín, Michal Nykl, và Tomáš Hercig. Geographical evaluation of word embeddings. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 224–232, 2017.

Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N. Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick van Kleef, Sören Auer, và Christian Bizer. Dbpedia - a large-scale, multilingual knowledge base extracted from wikipedia, 2015. URL http://dbpedia.org. Version 2023.

Belinda Z Li, Maxwell Nye, và Jacob Andreas. Implicit representations of meaning in neural language models. arXiv preprint arXiv:2106.00737, 2021.

Kenneth Li, Aspen K Hopkins, David Bau, Fernanda Viégas, Hanspeter Pfister, và Martin Wattenberg. Emergent world representations: Exploring a sequence model trained on a synthetic task. arXiv preprint arXiv:2210.13382, 2022.

Bastien Liétard, Mostafa Abdou, và Anders Søgaard. Do language models know the way to rome? arXiv preprint arXiv:2109.07971, 2021.

11

--- TRANG 12 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Leo Z Liu, Yizhong Wang, Jungo Kasai, Hannaneh Hajishirzi, và Noah A Smith. Probing across time: What does roberta know and when? arXiv preprint arXiv:2104.07885, 2021.

Max M Louwerse và Nick Benesh. Representing spatial structure through maps and language: Lord of the rings encodes the spatial structure of middle earth. Cognitive science, 36(8):1556–1569, 2012.

Max M Louwerse và Rolf A Zwaan. Language encodes geographical information. Cognitive Science, 33(1):51–73, 2009.

Kevin Meng, David Bau, Alex Andonian, và Yonatan Belinkov. Locating and editing factual associations in gpt. Advances in Neural Information Processing Systems, 35:17359–17372, 2022a.

Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, và David Bau. Mass-editing memory in a transformer. arXiv preprint arXiv:2210.07229, 2022b.

Eric J Michaud, Ziming Liu, Uzay Girit, và Max Tegmark. The quantization model of neural scaling. arXiv preprint arXiv:2303.13506, 2023.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, và Jeff Dean. Distributed representations of words and phrases and their compositionality. Advances in neural information processing systems, 26, 2013a.

Tomáš Mikolov, Wen-tau Yih, và Geoffrey Zweig. Linguistic regularities in continuous space word representations. In Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: Human language technologies, pp. 746–751, 2013b.

Neel Nanda, Andrew Lee, và Martin Wattenberg. Emergent linear representations in world models of self-supervised sequence models. arXiv preprint arXiv:2309.00941, 2023.

Richard Ngo, Lawrence Chan, và Sören Mindermann. The alignment problem from a deep learning perspective, 2023.

NYC OpenData. Points of interest, 2023. URL https://data.cityofnewyork.us/City-Government/Points-Of-Interest/rxuy-2muj. Accessed: 2023-07-01.

John O'Keefe và Jonathan Dostrovsky. The hippocampus as a spatial map: preliminary evidence from unit activity in the freely-moving rat. Brain research, 1971.

Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, và Shan Carter. Zoom in: An introduction to circuits. Distill, 5(3):e00024–001, 2020.

Roma Patel và Ellie Pavlick. Mapping language models to grounded conceptual spaces. In International Conference on Learning Representations, 2021.

Tilman Räuker, Anson Ho, Stephen Casper, và Dylan Hadfield-Menell. Toward transparent ai: A survey on interpreting the inner structures of deep neural networks. In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), pp. 464–483. IEEE, 2023.

Abhilasha Ravichander, Yonatan Belinkov, và Eduard Hovy. Probing the probing paradigm: Does probing accuracy entail task relevance? arXiv preprint arXiv:2005.00719, 2020.

Anna Rogers, Olga Kovaleva, và Anna Rumshisky. A primer in bertology: What we know about how bert works. Transactions of the Association for Computational Linguistics, 8:842–866, 2021.

Daniel R Schonhaut, Zahra M Aghajan, Michael J Kahana, và Itzhak Fried. A neural code for time and space in the human brain. Cell Reports, 42(11), 2023.

Shubham Toshniwal, Sam Wiseman, Karen Livescu, và Kevin Gimpel. Chess as a testbed for language model state tracking. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pp. 11385–11393, 2022.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.

12

--- TRANG 13 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022.

Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh, et al. Taxonomy of risks posed by language models. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, pp. 214–229, 2022.

A CÁC BỘ DỮ LIỆU
Chúng tôi mô tả việc xây dựng và hậu xử lý dữ liệu của chúng tôi chi tiết hơn ngoài các hạn chế đã biết. Tất cả các bộ dữ liệu và mã có sẵn tại https://github.com/wesg52/world-models.

Các Địa điểm Thế giới Chúng tôi chạy ba truy vấn riêng biệt để thu được tên, vị trí, quốc gia và bài viết Wikipedia liên quan của tất cả các địa điểm vật lý, địa điểm tự nhiên và cấu trúc trong cơ sở dữ liệu DBPedia Lehmann et al. (2015). Sử dụng liên kết bài viết Wikipedia, chúng tôi kết hợp thông tin này với dữ liệu từ cơ sở dữ liệu thống kê lượt xem trang Wikipedia³ để truy vấn số lần trang này được truy cập trong khoảng 2018-2020. Chúng tôi sử dụng điều này như một proxy để biết liệu chúng tôi có nên mong đợi một LLM biết về địa điểm này hay không, và lọc những địa điểm có ít hơn 5000 lượt xem trong khoảng thời gian này.

Một số hạn chế đáng được nhấn mạnh. Đầu tiên, dữ liệu của chúng tôi chỉ đến từ Wikipedia tiếng Anh, và do đó thiên vị về vùng Anglosphere. Ngoài ra, phân phối các loại thực thể không đồng đều, ví dụ: chúng tôi nhận thấy Vương quốc Anh có nhiều ga xe lửa hơn bất kỳ quốc gia nào khác, điều này có thể giới thiệu các tương quan không mong muốn trong dữ liệu có thể ảnh hưởng đến các đầu dò. Cuối cùng, khoảng 25% mẫu có một số bộ sửa đổi bang hoặc tỉnh ở cuối như "Dallas County, Iowa". Vì nhiều địa điểm này mơ hồ hơn hoặc sẽ mơ hồ mà không có bộ sửa đổi, chúng tôi chọn sắp xếp lại chuỗi thành dạng "Iowa's Dallas County" sao cho thực thể được phân biệt nhưng chúng tôi không đầu dò trên một token là tên quốc gia hoặc bang thông thường.

Các Địa điểm Hoa Kỳ Bộ dữ liệu các địa điểm Hoa Kỳ sử dụng các cấu trúc và địa điểm tự nhiên trong Hoa Kỳ từ bộ dữ liệu các địa điểm thế giới như điểm khởi đầu, ngoài một DBPedia khác cho các trường đại học Hoa Kỳ. Sau đó chúng tôi thu thập tên, tổng dân số và bang cho mọi quận⁴, mã zip⁵ và thành phố⁶ từ một bộ tổng hợp dữ liệu điều tra dân số. Sau đó chúng tôi loại bỏ tất cả các tên quận hoặc thành phố trùng lặp (có 31 quận Washington ở Hoa Kỳ!), mặc dù chúng tôi giữ bất kỳ bản trùng lặp nào có dân số gấp đôi so với địa điểm lớn tiếp theo cùng tên. Chúng tôi cũng lọc ra các thành phố có ít hơn 500 người, các mã zip có ít hơn 10000 (hoặc có mật độ dân số lớn hơn 50 và dân số lớn hơn 2000), và bất kỳ địa điểm nào không ở 48 bang liền kề phía dưới (hoặc Washington D.C.).

Các Địa điểm NYC Bộ dữ liệu Thành phố New York của chúng tôi được điều chỉnh từ bộ dữ liệu điểm quan tâm NYC Open Data (NYC OpenData, 2023) chứa tên các địa điểm được theo dõi bởi chính quyền thành phố. Điều này bao gồm tên của các trường học, nơi thờ cúng, địa điểm giao thông, đường hoặc cầu quan trọng, tòa nhà chính phủ, nhà ở công cộng và nhiều hơn nữa. Mỗi địa điểm này đi kèm với một ID phức tạp cho các địa điểm bao gồm nhiều tòa nhà như vậy (ví dụ: Đại học New York hoặc sân bay LaGuardia). Chúng tôi xây dựng phân chia test train để đảm bảo rằng tất cả các địa điểm trong cùng một phức hợp được đặt trong cùng một phân chia để tránh rò rỉ test-train. Chúng tôi lọc ra một số lượng lớn các địa điểm mô tả vị trí của các phao trong nhiều tuyến đường thủy xung quanh NYC.

Các Nhân vật Lịch sử Bộ dữ liệu nhân vật lịch sử của chúng tôi chứa tên và nghề nghiệp của các nhân vật lịch sử chết từ 1000BC-2000AD được điều chỉnh từ (Annamoradnejad & Annamoradnejad, 2022). Chúng tôi lọc bộ dữ liệu để chỉ chứa 350 người nổi tiếng nhất chết từ mỗi thập kỷ, được đo không hoàn hảo bằng chỉ số của định danh thực thể Wikidata của họ.

³https://en.wikipedia.org/wiki/Wikipedia:Pageview_statistics
⁴https://simplemaps.com/data/us-counties
⁵https://simplemaps.com/data/us-zips
⁶https://simplemaps.com/data/us-cities

13

--- TRANG 14 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hình 6: Phân phối các mẫu trong không gian hoặc thời gian cho tất cả các bộ dữ liệu.

Nghệ thuật và Giải trí Bộ dữ liệu nghệ thuật và giải trí của chúng tôi bao gồm tên của các bài hát, phim và sách với ngày phát hành nghệ sĩ, đạo diễn và tác giả tương ứng. Chúng tôi xây dựng bộ dữ liệu này từ DBpedia và tương tự lọc ra các thực thể đã nhận được ít hơn 5000 lượt xem trang trong khoảng 2018-2020. Vì nhiều bài hát hoặc sách có tiêu đề khá chung, chúng tôi bao gồm tên người sáng tạo trong gợi ý để phân biệt (ví dụ: "Stephen Kings' It" cho gợi ý trống). Tuy nhiên, vì một số nghệ sĩ hoặc tác giả phát hành nhiều bài hát hoặc sách, chúng tôi lấy mẫu phân chia test-train theo người sáng tạo để tránh rò rỉ.

Tiêu đề Bộ dữ liệu tiêu đề của chúng tôi được điều chỉnh từ một scrape của tất cả các tiêu đề New York Times trong 30 năm qua (Bandy, 2021). Trong nỗ lực lọc ra các tiêu đề không mô tả một sự kiện có thể được định vị trong thời gian, chúng tôi sử dụng một số chiến lược. Đầu tiên chúng tôi lọc bất cứ thứ gì không nằm trong 10 trang đầu của ấn bản in. Thứ hai chúng tôi lọc ra các bài viết không đến từ các bàn tin Foreign, National, Politics, Washington, hoặc Obits. Thứ ba chúng tôi loại bỏ bất kỳ tiêu đề nào chứa dấu hỏi.

14

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

B KHỬ VÀ CAN THIỆP NƠ-RON
Để hiểu rõ hơn vai trò của các nơ-ron không gian và thời gian trong LLM, chúng tôi tiến hành một số thí nghiệm khử và can thiệp nơ-ron.

Can thiệp Thời gian Chúng tôi nghiên cứu tác động của việc can thiệp vào một nơ-ron thời gian duy nhất (L19.3610; tương quan với ngày phát hành nghệ thuật và giải trí là 0.77) trong Llama-2-7b. Cho một gợi ý có dạng <media> bởi <creator> được viết vào 19, chúng tôi cố định kích hoạt của nơ-ron thời gian trên tất cả các token và quét qua một phạm vi giá trị được cố định, và theo dõi xác suất dự đoán của năm token hàng đầu. Kết quả được mô tả trong Hình 7 và cho thấy rằng chỉ điều chỉnh kích hoạt nơ-ron thời gian có thể thay đổi dự đoán token tiếp theo trong tất cả các trường hợp.

Hình 7: Dự đoán thập kỷ xuất bản cho một bài hát, phim và sách nổi tiếng khi một nơ-ron thời gian (L19.3610) được cố định ở một giá trị cụ thể, so với 9 nơ-ron ngẫu nhiên trong cùng lớp (L19.[0-8]) của Llama-2-7b.

Khử Nơ-ron Chúng tôi cũng nghiên cứu tác động của việc khử zero các nơ-ron, và các ngữ cảnh mà mất mát tăng nhiều nhất. Đối với một tập con Wikipedia bao gồm các bài viết tương ứng với các địa điểm thế giới và nghệ thuật và giải trí đương đại, đầu tiên chúng tôi chạy Llama-2-7b như bình thường và ghi lại mất mát. Sau đó, đối với hai nơ-ron không gian và hai nơ-ron thời gian, chúng tôi chạy mô hình với kích hoạt nơ-ron được cố định về 0 (chúng tôi luôn cố định chính xác một nơ-ron về 0). Đối với mỗi nơ-ron, chúng tôi báo cáo 10 ngữ cảnh hàng đầu mà mất mát tăng nhiều nhất cho dự đoán token tiếp theo trong Bảng 5-8.

15

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

ngữ cảnh | token thực | tăng mất mát
Bom Jesus có khí hậu savanna nhiệt đới khá khô (Köppen Aw | 2.107
khí hậu gió mùa nhiệt đới/cận nhiệt đới ẩm (Köppen Am | 2.035
của . Nhiệt độ cao nhất đạt được vào cuối mùa khô vào tháng Ba | 1.960
8.9 °C. Vào tháng Giêng, nhiệt độ trung bình là 1 | 8 | 1.930
một Khí hậu nhiệt đới ướt và khô (phân loại khí hậu Köppen Aw | 1.876
Goroka có khí hậu gió mùa nhiệt đới tương đối mát (Köppen Am | 1.854
khoảng từ 26.4 °F vào tháng Giêng đến 7 | 0 | 1.835
mùa hè ướt và mùa đông ấm, rất ướt (phân loại khí hậu Köppen Am | 1.807
khí hậu nhiệt đới ướt và khô/khí hậu bán khô hạn (Köppen Aw | 1.783
khí hậu nhiệt đới-hàng hải tương đối ôn hòa, (phân loại khí hậu Köppen Aw | 1.762

Bảng 5: Các ngữ cảnh có mất mát cao nhất khi khử nơ-ron không gian L20.7573 từ Llama-2-7b.

ngữ cảnh | token thực | tăng mất mát
điểm đánh dấu là Núi Etna, một trong những núi lửa hoạt động cao nhất ở Châu | 1.971
2,800 năm, làm cho nó trở thành một trong những thành phố cổ nhất ở Châu | 1.676
thủ môn với 63 lần khoác áo cho Bồ Đào Nha bao gồm tham gia vào 198 | 4 | 1.631
15. Tenerife cũng có số lượng loài đặc hữu lớn nhất ở Châu | 1.512
Georgia về phía tây nam. Núi Elbrus, ngọn núi cao nhất ở Châu | 1.246
Tại một thời điểm, ngôi làng tự hào có nhà máy cán nhôm dài nhất ở Tây | 1.219
trung tâm và trung tâm kinh tế hàng đầu của Bán đảo Iberian và của Miền | 1.181
Vatican City, một quốc gia có chủ quyền—và có thể lớn thứ hai ở Châu | 1.103
tên. Điều này là do Quần đảo Anh có thể đã được tái định cư từ I | 1.082
sân vận động Hạng 4 bởi UEFA, đã tổ chức các trận đấu tại 199 | 8 | 1.072

Bảng 6: Các ngữ cảnh có mất mát cao nhất khi khử nơ-ron không gian L20.7423 từ Llama-2-7b.

ngữ cảnh | token thực | tăng mất mát
được phát hành vào tháng 6 năm 1993 như single thứ tư từ album He | 2.254
được phát hành vào tháng 11 năm 1992 như single thứ hai từ album của cô He | 1.973
93. Phiên bản của Yearwood là single thứ ba từ album của cô He | 1.749
bảng xếp hạng Hot Country Singles & Tracks, sau "Any của Shania Twain | 1.574
được phát hành vào tháng 2 năm 1992 như single thứ ba từ album What | 1.559
và cung cấp sản xuất bổ sung cho các single "Like A Prayer" và "Express của cô | 1.481
được phát hành vào tháng 5 năm 1992 như single thứ tư từ album What | 1.367
nhà làm phim Ramesh Aravind trong điện ảnh Telugu. P. L | 1.328
993 bởi hãng thu âm Columbia như single thứ hai từ album phòng thu thứ hai Gold | 1.272
Gessle cho album năm 1991 của bộ đôi, Joy | 1.253

Bảng 7: Các ngữ cảnh có mất mát cao nhất khi khử nơ-ron thời gian L18.9387 từ Llama-2-7b.

ngữ cảnh | token thực | tăng mất mát
016 như single thứ ba từ album phòng thu đầu tay Louder! của Reyes | 1.082
như single radio thứ hai hỗ trợ album phòng thu thứ ba Life của ban nhạc | 0.996
Song, nhưng cuối cùng thua giải thưởng cho "The của Barbra Streisand | 0.965
Phát hành như single đầu tiên từ album phòng thu thứ bảy Super của nhóm | 0.961
30 phim Carry On gốc (1958–19 | 7 | 0.912
. Sau khi nghe single "Under" năm 2002 của No Doubt | 0.867
ix9ine cho mixtape đầu tay Day69 (201 của anh ấy | 8 | 0.866
ck xuất hiện trong album phòng thu thứ năm The Album của nhóm | 0.864
ck xuất hiện trong các phim hoạt hình Porky Pig It's an | 0.805
được viết bởi Andrew Lloyd Webber và Tim Rice và sản xuất bởi Fel | 0.805

Bảng 8: Các ngữ cảnh có mất mát cao nhất khi khử nơ-ron thời gian L19.3610 từ Llama-2-7b.

16

--- TRANG 17 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

C KẾT QUẢ BỔ SUNG

Hình 8: R² ngoài mẫu khi tên thực thể được bao gồm trong các gợi ý khác nhau cho tất cả các mô hình.

17

--- TRANG 18 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hình 9: Mô hình Hoa Kỳ lớp 50 Llama-2-70b. Các điểm là phép chiếu của kích hoạt của các địa điểm Hoa Kỳ được giữ lại lên các hướng vĩ độ và kinh độ đã học được tô màu theo bang thực, với dự đoán bang trung vị được phóng to. Tất cả các điểm được mô tả đều từ tập kiểm tra.

Hình 10: Mô hình thế giới lớp 50 Llama-2-70b. Các điểm là phép chiếu của kích hoạt của các địa điểm thế giới được giữ lại lên các hướng vĩ độ và kinh độ đã học được tô màu theo châu lục thực. Tất cả các điểm được mô tả đều từ tập kiểm tra.

18

--- TRANG 19 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hình 11: Dự đoán ngoài mẫu cho mỗi quốc gia khi dữ liệu huấn luyện đầu dò không chứa mẫu nào từ quốc gia đó so với vị trí thực và trung bình của dữ liệu huấn luyện. Kết quả ngụ ý rằng hướng đặc trưng đã học tổng quát hóa chính xác đến vị trí tương đối của một quốc gia nhưng đầu dò ghi nhớ các vị trí tuyệt đối.

19

--- TRANG 20 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hình 12: Dự đoán ngoài mẫu cho mỗi bang khi dữ liệu huấn luyện đầu dò không chứa mẫu nào từ bang đó so với vị trí thực và trung bình của dữ liệu huấn luyện. Kết quả ngụ ý rằng hướng đặc trưng đã học tổng quát hóa chính xác đến vị trí tương đối của một quốc gia nhưng đầu dò ghi nhớ các vị trí tuyệt đối.

20

--- TRANG 21 ---
Xuất bản như một bài báo hội nghị tại ICLR 2024

Hình 13: Tương quan thứ hạng Spearman kiểm tra cho các đầu dò được huấn luyện trên các kích hoạt được chiếu lên k thành phần chính lớn nhất.

21
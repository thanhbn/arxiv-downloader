# 2308.03688.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl-papers/2308.03688.pdf
# Kích thước tệp: 23176585 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Báo cáo kỹ thuật (v0.2)
AGENT BENCH: ĐÁNH GIÁ LLM NHƯ CÁC TÁC NHÂN
Xiao Liu1,*, Hao Yu1,*, Hanchen Zhang1, Yifan Xu1, Xuanyu Lei1, Hanyu Lai1, Yu Gu2,
Hangliang Ding1, Kaiwen Men1, Kejuan Yang1, Shudan Zhang1, Xiang Deng2, Aohan Zeng1,
Zhengxiao Du1, Chenhui Zhang1, Sheng Shen3, Tianjun Zhang3, Yu Su2, Huan Sun2,
Minlie Huang1, Yuxiao Dong1, Jie Tang1
1Đại học Tsinghua,2Đại học Bang Ohio,3UC Berkeley

TÓM TẮT
Các Mô hình Ngôn ngữ Lớn (LLM) đang ngày càng trở nên thông minh và tự chủ hơn, nhắm đến các nhiệm vụ thực tế trong thế giới thực vượt ra ngoài các tác vụ NLP truyền thống. Kết quả là, đã có nhu cầu cấp thiết để đánh giá LLM như các tác nhân trên các tác vụ thử thách trong môi trường tương tác. Chúng tôi giới thiệu AGENT BENCH, một bộ đánh giá đa chiều phát triển hiện bao gồm 8 môi trường khác biệt để đánh giá khả năng suy luận và ra quyết định của LLM-as-Agent trong bối cảnh tạo sinh mở nhiều lượt. Kiểm tra rộng rãi của chúng tôi trên 27 LLM dựa trên API và mã nguồn mở (OSS) cho thấy rằng, trong khi các LLM thương mại hàng đầu thể hiện khả năng mạnh mẽ trong việc hoạt động như các tác nhân trong môi trường phức tạp, có sự chênh lệch đáng kể về hiệu suất giữa chúng và các đối thủ OSS. Chúng tôi xác định các lý do điển hình của sự thất bại trong môi trường và LLM, cho thấy khả năng suy luận dài hạn, ra quyết định và tuân thủ hướng dẫn kém là những trở ngại chính để phát triển các tác nhân LLM có thể sử dụng được. Đào tạo trên mã và dữ liệu căn chỉnh nhiều lượt chất lượng cao có thể cải thiện hiệu suất tác nhân. Bộ dữ liệu, môi trường và gói đánh giá tích hợp cho AGENT BENCH được phát hành tại https://github.com/THUDM/AgentBench.

(a) Hiệu suất AgentBench điển hình của LLM (Tương đối) so với tốt nhất trong mỗi môi trường (b) Điểm tổng thể của AgentBench trên 8 môi trường. Các đường đứt nét cho trung bình của hai loại LLM.

Hình 1: Tổng quan về LLM trên AGENT BENCH. Trong khi LLM bắt đầu thể hiện năng lực của chúng trong LLM-as-Agent, khoảng cách giữa các mô hình và khoảng cách đến khả năng sử dụng thực tế là đáng kể.

1 GIỚI THIỆU
Các tác nhân thông minh và thực thể tự chủ (Searle, 1970; Maes, 1994; Wooldridge & Jennings, 1995) có khả năng ra quyết định và thực hiện hành động trong các môi trường cụ thể đã là các khái niệm chính của trí tuệ nhân tạo (AI) về mặt lịch sử. Bất chấp những tiến bộ đáng kể trong các thuật toán học sâu được áp dụng trong cả thị giác máy tính và xử lý ngôn ngữ tự nhiên (NLP), tiềm năng của chúng để phát triển các tác nhân hỗ trợ hiệu quả và có thể sử dụng thực tế vẫn phần lớn chưa được khám phá.

Sự xuất hiện của các Mô hình Ngôn ngữ Lớn (LLM) (Brown et al., 2020; Chowdhery et al., 2022; Touvron et al., 2023), chẳng hạn như GPT-4 (OpenAI, 2023), đã mang lại nhiều cơ hội mới cho lĩnh vực này. Thông qua đào tạo căn chỉnh rộng rãi (Ouyang et al., 2022; Wei et al., 2022a; Sanh et al., 2022), LLM không chỉ thành thạo các tác vụ NLP truyền thống mà còn thể hiện khả năng ấn tượng trong việc hiểu ý định của con người và thực hiện hướng dẫn. Điều này đã thúc đẩy sự phát triển của nhiều ứng dụng dựa trên LLM để hoàn thành mục tiêu tự chủ (như AutoGPT (Richards, 2023), BabyAGI (Nakajima, 2023), AgentGPT (age, 2023)) cũng như các tác nhân LLM đặt trong bối cảnh xã hội và game (Park et al., 2023; Wang et al., 2023b; Zhu et al., 2023), tạo ra sự quan tâm và thảo luận đáng kể từ công chúng.

Bất chấp những tiến bộ này, việc thiếu một bộ đánh giá hệ thống và tiêu chuẩn để đánh giá LLM-as-Agent đưa ra một thách thức quan trọng. Về mặt lịch sử, các môi trường game dựa trên văn bản (Osborne et al., 2022; Côté et al., 2019; Hausknecht et al., 2020; Urbanek et al., 2019) đã được sử dụng để đánh giá tác nhân ngôn ngữ. Nhưng chúng thường gặp hạn chế của không gian hành động đóng, rời rạc, cũng như sự tập trung chủ yếu hẹp vào khả năng nắm bắt thông thức của mô hình. Gần đây hơn, các nỗ lực về các tác nhân có thể hiện thành (Reed et al., 2022; Huang et al., 2022; Ahn et al., 2022) đã sử dụng các trình mô phỏng đa phương tiện phức tạp dựa trên game (Küttler et al., 2020; Fan et al., 2022), GUI (Shi et al., 2017; Toyama et al., 2021), và cảnh trong nhà (Shen et al., 2021; Srivastava et al., 2022). Tuy nhiên, các trình mô phỏng này, bất chấp sự phức tạp của chúng, không phản ánh chính xác các trường hợp sử dụng thực tế của LLM, và bản chất đa phương tiện của chúng tạo ra rào cản cho việc đánh giá cấp thiết các LLM chỉ văn bản hiện tại. Cuối cùng, hầu hết các bộ đánh giá hiện tại cho các tác nhân tập trung vào các môi trường đơn lẻ và do đó không cung cấp cái nhìn tổng quan toàn diện về LLM trên các tình huống ứng dụng đa dạng.

Để giải quyết những thách thức này, chúng tôi giới thiệu AGENT BENCH, một bộ đánh giá đa chiều được thiết kế để đánh giá LLM-as-Agent trên một phổ các môi trường khác nhau. AGENT BENCH bao gồm tám môi trường riêng biệt (Xem Hình 4), có thể được phân loại thành ba loại nền tảng:
•Mã: Hệ điều hành, Cơ sở dữ liệu, Đồ thị tri thức (Anonymous, 2023)
•Game: Game thẻ kỹ thuật số, Câu đố tư duy bên, Việc nhà (Shridhar et al., 2020b)
•Web: Mua sắm web (Yao et al., 2022), Duyệt web (Deng et al., 2023)

Tất cả bộ dữ liệu, dù được tạo mới hay điều chỉnh từ các bộ dữ liệu hiện có, đều được thiết kế và cải tạo cẩn thận để mô phỏng các môi trường tương tác nơi LLM chỉ văn bản có thể hoạt động như các tác nhân tự chủ. AGENT BENCH do đó đánh giá hệ thống các khả năng cốt lõi của LLM, bao gồm tuân thủ hướng dẫn (Ouyang et al., 2022), lập trình (Chen et al., 2021), thu thập tri thức (Joshi et al., 2017; Talmor et al., 2019), suy luận logic (Srivastava et al., 2023), và nắm bắt thông thức (Shridhar et al., 2020a). Nó phục vụ như một nền tảng kiểm tra lý tưởng cho cả đánh giá LLM và tác nhân.

Ngoài ra, chúng tôi phát triển một bộ công cụ đánh giá thống nhất cho LLM để hoạt động trên các tác vụ tác nhân tùy chỉnh đa dạng, do đó cho phép đánh giá toàn diện khả năng LLM-as-Agent của 27 LLM khác nhau trên AGENT BENCH, bao gồm cả mô hình dựa trên API và OSS. Kết quả của chúng tôi cho thấy các mô hình thương mại hàng đầu như GPT-4 có khả năng xử lý một loạt các tác vụ thế giới thực, cho thấy tiềm năng để phát triển một tác nhân mạnh mẽ, học tập liên tục. Tuy nhiên, chúng tôi cũng lưu ý một khoảng cách hiệu suất đáng kể giữa các mô hình hàng đầu này và các đối thủ OSS của chúng. Bất chấp thành công gần đây của OSS LLM và điểm số cạnh tranh của chúng trên một số bộ đánh giá (Li et al., 2023; Chen et al., 2021; Cobbe et al., 2021), hiệu suất của chúng trên các tác vụ thử thách AGENT BENCH tụt hậu đáng kể. Điều này nhấn mạnh sự cần thiết của những nỗ lực bổ sung để nâng cao khả năng học tập của OSS LLM.

Chúng tôi xác định các phần thất bại của tác vụ tác nhân trong các môi trường và LLM khác nhau, tiết lộ khả năng không đủ của suy luận dài hạn, ra quyết định và tuân thủ hướng dẫn trong LLM hiện tại. So sánh giữa các LLM khác nhau thể hiện rằng một chiến lược phù hợp của việc giới thiệu đào tạo mã có thể giúp cải thiện LLM-as-Agent. Đào tạo căn chỉnh trên dữ liệu chất lượng cao (ví dụ, dữ liệu được tạo bởi gpt-4) cũng có thể giúp cải thiện các tác nhân LLM. Tóm lại, các đóng góp của chúng tôi là:

•Chúng tôi giới thiệu khái niệm đánh giá LLM như các tác nhân và trình bày AGENT BENCH, một bộ đánh giá toàn diện để tiêu chuẩn hóa việc đánh giá. Nó định nghĩa tám môi trường riêng biệt của 3 loại dựa trên các tình huống thế giới thực, cung cấp một nền tảng kiểm tra thực tế cho loạt khả năng rộng của LLM.

•Chúng tôi thực hiện đánh giá kỹ lưỡng 27 LLM khác nhau sử dụng AGENT BENCH, phát hiện khoảng cách hiệu suất đáng kể giữa LLM thương mại dựa trên API hàng đầu và các mô hình OSS. Chúng tôi cũng phân tích định lượng các lý do thất bại trong các tác nhân LLM hiện tại và nêu bật các hướng cải thiện, chẳng hạn như đào tạo mã và dữ liệu căn chỉnh chất lượng cao hơn.

•Để tạo điều kiện cho việc đánh giá LLM-as-Agent, chúng tôi đã giới thiệu một bộ công cụ tích hợp dựa trên kiến trúc Server-Client, tập trung vào các nguyên tắc thiết kế mô-đun và có thể mở rộng. Điều này cho phép tùy chỉnh dễ dàng các đánh giá mô hình cho bất kỳ LLM nào sử dụng giao thức HTTP. Được bổ sung bởi các bộ dữ liệu và môi trường liên quan, bộ công cụ này hiện có thể truy cập công khai cho cộng đồng nghiên cứu rộng lớn hơn.

2 LLM-AS-AGENT: ĐỊNH NGHĨA VÀ SỞ KHỞI

Ở đây, chúng tôi hình thức hóa các thuật ngữ để mô tả việc đánh giá LLM như các tác nhân và kiến thức sơ bộ cần thiết để sử dụng LLM trong bối cảnh đánh giá tác nhân.

Định nghĩa: Đánh giá tương tác của LLM-as-Agent. Đánh giá tương tác của LLM-as-Agent có thể được coi như một Quá trình Quyết định Markov Quan sát Một phần (S,A,T,R,U,O), bao gồm không gian trạng thái S, không gian hành động A, hàm chuyển tiếp T:S × A → S, hàm gán phần thưởng R, không gian hướng dẫn tác vụ U, và không gian quan sát O. Ở đây, chúng tôi ký hiệu một tác nhân LLM là M.

Chuỗi Suy nghĩ (CoT) và Các Chiến lược Suy luận Khác. Vì LLM-as-Agent đòi hỏi khả năng suy luận mạnh mẽ của LLM, CoT (Wei et al., 2022b), được coi là một chiến lược thực tế trong đánh giá liên quan cùng với các hành động (Yao et al., 2023b), cũng được áp dụng trong AGENT BENCH. Bất chấp nhiều chiến lược cải thiện được đề xuất sau đó, chẳng hạn như giới thiệu ensemble (Wang et al., 2023c), phản ánh (Shinn et al., 2023), và tìm kiếm (Yao et al., 2023a), chúng tôi đánh giá LLM với CoT nguyên thủy nhất trong AGENT BENCH. Không có nhiều thử nghiệm, tạo sinh lặp lại, hoặc các chiến lược phức tạp, CoT là cách dễ nhất, rẻ nhất và phổ biến nhất để mọi người triển khai các tác nhân LLM.

Các Loại Lý do Kết thúc Điển hình. Bất chấp khả năng của LLM, chúng tôi cho thấy trong AGENT BENCH rằng ngay cả gpt-4 mạnh nhất cũng không đủ tiêu chuẩn như một tác nhân có thể sử dụng thực tế. Chúng tôi xác định và phân loại các lý do kết thúc của các tác nhân LLM trên các tác vụ AGENT BENCH thành năm loại điển hình:

•Vượt quá Giới hạn Bối cảnh (CLE): độ dài của lịch sử tương tác vượt quá độ dài bối cảnh tối đa của LLM (chỉ xảy ra trong LLM text-davinci-002 và 003 có độ dài 2,048).

•Định dạng Không hợp lệ (IF): tác nhân không tuân thủ hướng dẫn định dạng.

•Hành động Không hợp lệ (IA): tác nhân tuân thủ hướng dẫn định dạng, nhưng hành động đã chọn của nó không hợp lệ.

•Vượt quá Giới hạn Tác vụ (TLE): tác nhân không giải quyết được vấn đề sau khi đạt đến số lượt tương tác tối đa được xác định trước hoặc bắt đầu thực hiện tạo sinh lặp lại trong nhiều lượt.

và Hoàn thành (tác vụ kết thúc bình thường). Trong khi IF và IA chủ yếu do khả năng tuân thủ hướng dẫn kém của LLM, TLE thường cho thấy khả năng nhiều lượt yếu trong một số tác vụ.

3 THÀNH PHẦN CỦA AGENT BENCH: MỘT CÁI NHÌN TỔNG QUAN

Trong phần này, chúng tôi giới thiệu ngắn gọn các bộ dữ liệu và môi trường tạo nên AGENT BENCH. So với các bộ đánh giá tác nhân trước đây (Côté et al., 2019; Fan et al., 2022), AGENT BENCH tập trung vào việc đánh giá thực tế của LLM qua gợi ý Chuỗi Suy nghĩ (CoT) (Wei et al., 2022b; Yao et al., 2023b), bao gồm các tình huống dựa trên mã, game và web. Chúng chỉ ra các hướng hứa hẹn của ứng dụng LLM với việc hoàn thành nhiệm vụ tự chủ, và tính đa dạng của chúng tránh được hiệu suất vượt trội của các mô hình cụ thể cho tác vụ (ví dụ, LLM chuyên biệt về mã) trên AGENT BENCH. Do giới hạn trang, để biết chi tiết về xây dựng, đánh giá và ví dụ gợi ý, vui lòng tham khảo Phụ lục.

3.1 MÔI TRƯỜNG DỰA TRÊN MÃ

Vì LLM có thể tạo ra mã chất lượng cao (Chen et al., 2021), một nhiệm vụ rất thực tế cho các tác nhân LLM là hỗ trợ tương tác của con người với giao diện máy tính. Ở đây, chúng tôi giới thiệu ba môi trường phụ thuộc vào khả năng lập trình và suy luận như các đại diện trong AGENT BENCH.

Hệ điều hành (OS). Cho phép LLM truy cập và thao tác OS trong terminal là một nhiệm vụ hấp dẫn nhưng thử thách. Bất chấp các nỗ lực về việc dịch ngôn ngữ tự nhiên sang các lệnh Shell (Lin et al., 2018), ít nỗ lực trước đây đánh giá mô hình trong môi trường có thể thực thi. Chúng tôi nhắm đến việc đánh giá LLM trong môi trường bash tương tác thực sự của OS (tức là Ubuntu Docker (Merkel et al., 2014)) trên các câu hỏi của con người với câu trả lời xác định (ví dụ, số lượng người dùng với các thư mục không phải /home trong một OS) hoặc một loạt các thao tác cho mục tiêu thực tế (ví dụ, đặt tất cả các tệp thư mục thành chỉ đọc một cách đệ quy, loại trừ tệp của tôi). Chúng tôi áp dụng tỷ lệ thành công (SR) làm thước đo đánh giá. (Xem Phụ lục B để biết thêm chi tiết)

Cơ sở dữ liệu (DB). Vì phân tích cơ sở dữ liệu là quan trọng nhưng cũng khó khăn trong nhiều công việc hàng ngày, việc kiểm tra khả năng của LLM để thao tác trên cơ sở dữ liệu thực qua SQL là tối quan trọng. Nghiên cứu trước đây có sự nhấn mạnh đáng kể về các quy trình riêng lẻ, chẳng hạn như dịch giữa SQL và ngôn ngữ tự nhiên (Zhong et al., 2017), hoặc trả lời câu hỏi cho các bảng nhỏ riêng lẻ (Nan et al., 2021; Iyyer et al., 2017). Tuy nhiên, ít người xem xét việc đánh giá mô hình trên đường ống hoàn chỉnh như một tổng thể. Do đó, AGENT BENCH đánh giá LLM trên giao diện SQL xác thực, cơ sở dữ liệu, nhiều bảng, và các loại truy vấn khác nhau như trong thế giới thực. Chúng tôi áp dụng SR làm thước đo đánh giá chính. (Xem Phụ lục C để biết thêm chi tiết)

Đồ thị tri thức (KG (Anonymous, 2023)). Tham gia với các KG hiện đại, thường có kích thước rất lớn (ví dụ, FREEBASE (Bollacker et al., 2008) có hơn 45M thực thể và 3B sự kiện), đòi hỏi một loạt các kỹ năng từ một tác nhân thông minh (Gu et al., 2023). Hoạt động trong các môi trường như vậy, chỉ có thể quan sát một phần, đòi hỏi tác nhân phải ra quyết định với thông tin không đầy đủ và quản lý sự không chắc chắn vốn có với nhiều kỹ năng khác nhau, bao gồm hiểu ngôn ngữ (ví dụ, sự phức tạp và tinh tế), lập kế hoạch (ví dụ, chia nhỏ hướng dẫn thành các thành phần dễ quản lý hơn), và sử dụng công cụ (ví dụ, tương tác với giao diện KG). Kết quả là, chúng tôi đề xuất KG như một nền tảng kiểm tra đại diện để đánh giá khả năng ra quyết định của các tác nhân AI. Chúng tôi áp dụng trả lời câu hỏi làm công thức hóa tác vụ cơ bản và do đó F1 của câu trả lời làm thước đo. (Xem Phụ lục D để biết thêm chi tiết)

3.2 MÔI TRƯỜNG DỰA TRÊN GAME

Chơi game thường đòi hỏi khả năng mạnh mẽ trong việc thiết kế chiến lược, tuân thủ hướng dẫn và suy luận. So với dựa trên mã, các tác vụ trong môi trường dựa trên game không đòi hỏi chuyên môn về lập trình nhưng cần nắm bắt tích hợp hơn về thông thức và kiến thức thế giới.

Game thẻ kỹ thuật số (DCG). Game, đặc biệt là những game đòi hỏi chiến lược và lập kế hoạch, có thể phục vụ như môi trường mô phỏng để phát triển tác nhân thông minh. DCG (ví dụ, Hearthstone (Hoover et al., 2020)), thay vào đó, là một lựa chọn lý tưởng cho việc đánh giá LLM chỉ văn bản. Nó thường liên quan đến mô tả văn bản phong phú cho các thẻ, cạnh tranh theo lượt, và chiến lược chơi suy nghĩ để chiến thắng, kiểm tra sự hiểu biết của mô hình về luật chơi, logic vận hành, và khả năng hình thành quyết định chiến lược dựa trên điều kiện hiện tại và kinh nghiệm trong quá khứ trong game.

Trong AGENT BENCH, chúng tôi điều chỉnh một hệ thống DCG đơn giản hóa—Aquawar¹—từ Cuộc thi Tác nhân Đại học Tsinghua 2021 (THUAC) do Hội Sinh viên Khoa học và Công nghệ tại Khoa Khoa học và Công nghệ Máy tính (CST-SAST) tổ chức, để đánh giá LLM-as-Agent. Trong Aquawar, tác nhân hoạt động như một người chơi quản lý một đội cá với tài năng khác nhau để chiến đấu với đội khác (được điều khiển bởi tác nhân cơ sở ad-hoc của chúng tôi) theo hình thức theo lượt. Chúng tôi báo cáo tỷ lệ thắng của LLM làm thước đo đánh giá. (Xem Phụ lục E để biết thêm chi tiết)

Câu đố Tư duy Bên (LTP). Câu đố tư duy bên (Sloane, 1992), hoặc câu đố tình huống, 海龟汤, là một trò chơi nhóm phổ biến trên khắp thế giới. Trò chơi thường có một người chủ trì câu đố và những người khác đoán bằng cách đặt câu hỏi liên quan đến câu đố. Chủ trì chỉ có thể trả lời "có", "không", hoặc "không liên quan". Trò chơi kết thúc khi một trong những người chơi khôi phục các cốt truyện quan trọng của câu đố.

Tên của nó xuất phát từ thuật ngữ tâm lý "tư duy bên" (De Bono, 1970), đề cập đến khả năng suy luận sự kiện từ các góc độ không quy ước và khám phá ý tưởng mới.

Trong bộ dữ liệu này, chúng tôi đầu tiên thiết lập hệ thống chủ trì LTP để đánh giá tự động (Xem Phụ lục F). Để đánh giá năng lực suy luận bên của LLM, một bộ dữ liệu câu đố đa dạng được tuyển chọn từ web với các mức độ khó khăn khác nhau. Chúng tôi chia nhỏ cốt truyện thật thành nhiều điểm và đo lường phần các điểm được đoán ra (tức là, tiến độ trò chơi) khi một tác nhân cạn kiệt số lượng vòng chơi tối đa làm thước đo đánh giá. Thông qua đánh giá này, chúng tôi nhắm đến việc hiểu sâu sắc về độ sâu và sự nhanh nhẹn của khả năng suy luận bên của LLM. (Xem Phụ lục F để biết thêm chi tiết)

Việc nhà (HH, ALFWorld (Shridhar et al., 2020b)). Môi trường game có thể hiện thành như việc nhà, đòi hỏi khả năng nắm bắt thông thức mạnh mẽ, đã được thiết lập tốt cho việc đánh giá tác nhân ngôn ngữ (Côté et al., 2019). Trong AGENT BENCH, chúng tôi đánh giá khả năng của mô hình trong việc hoàn thành các tác vụ trong môi trường việc nhà vật lý trên ALFWorld cổ điển (Shridhar et al., 2020b) xuất phát từ bộ công cụ text-game được thiết lập tốt TextWorld (Côté et al., 2019). Tác nhân cần hoàn thành các tác vụ việc nhà như "Đặt chảo lên bàn ăn". Chúng tôi áp dụng SR làm thước đo đánh giá. (Xem Phụ lục G để biết thêm chi tiết)

3.3 MÔI TRƯỜNG DỰA TRÊN WEB

Các trang web đã là giao diện chính cho mọi người tương tác trong thế giới thực. Do đó, việc đánh giá hành vi của các tác nhân LLM trong môi trường web phức tạp sẽ là quan trọng và có giá trị cho sự phát triển tiếp theo. Ở đây, chúng tôi điều chỉnh hai bộ dữ liệu duyệt web hiện có để đánh giá thực tế trên LLM.

Mua sắm Web (WS, WebShop (Yao et al., 2022)). Mua sắm trực tuyến là một phần rất thực tế và quan trọng của cuộc sống hiện đại. Quỹ đạo của nó, bao gồm tìm kiếm, xem và lựa chọn các mục mong muốn trên một trang web thương mại điện tử thực, đòi hỏi khả năng suy luận và ra quyết định mạnh mẽ của các tác nhân tự chủ. Webshop (Yao et al., 2022), một môi trường mua sắm trực tuyến mô phỏng, chính xác phục vụ mục đích như vậy để đánh giá các tác nhân ngôn ngữ. Trong khi nó ban đầu được đánh giá trên các mô hình được đào tạo cụ thể, chúng tôi đề xuất đánh giá LLM chỉ với gợi ý. (Xem Phụ lục H để biết thêm chi tiết)

Duyệt Web (WB, Mind2Web (Deng et al., 2023)). Môi trường web tổng quát là một hộp cát lý tưởng để đào tạo và đánh giá các tác nhân thông minh. Mind2Web (Deng et al., 2023) là một bộ đánh giá tổng quát được phát hành gần đây để phát triển và đánh giá các tác nhân web có khả năng thực hiện các tác vụ phức tạp trên nhiều lĩnh vực trang web khác nhau, được đưa ra các hướng dẫn cấp cao của người dùng. Nó thiết kế các hành động khả thi cho tương tác trang web, chẳng hạn như nhấp chuột, lựa chọn và gõ, do đó tạo điều kiện cho việc đánh giá toàn diện các LLM như các tác nhân web. So với cài đặt gốc của Mind2Web, chúng tôi thực hiện điều chỉnh để cho phép đánh giá nó trên LLM được gợi ý mà không cần tinh chỉnh bổ sung. (Xem Phụ lục I để biết thêm chi tiết)

¹https://www.saiblo.net/

--- TRANG 6 ---
Bảng 2: Thống kê và thước đo của 8 môi trường trong đánh giá AGENT BENCH. "SR" là viết tắt của Tỷ lệ Thành công. "#Avg. Turn" biểu thị số lượng lượt tương tác ước tính để giải quyết một vấn đề duy nhất. Trong "#Dev" và "#Test", chúng tôi cung cấp số lượng mẫu truy vấn và tổng số lượt tương tác dự kiến. Ngoài ra, "Weight−1" đề cập đến điểm trung bình cho một tác vụ trên tất cả các mô hình trong đánh giá của chúng tôi. Để làm rõ hơn, vui lòng tham khảo Phần 4.1 và Phụ lục B đến I.

4 ĐÁNH GIÁ AGENT BENCH

Chúng tôi đánh giá rộng rãi 27 LLM, bao gồm các mô hình thương mại dựa trên API và LLM mã nguồn mở, để hình thành cái nhìn hệ thống về hiệu suất hiện tại của LLM-as-Agent. Chúng tôi cũng thiết kế và phát hành một bộ công cụ đánh giá cắm và chạy đơn giản để tạo điều kiện cho nghiên cứu LLM-as-Agent liên quan.

4.1 THIẾT LẬP ĐÁNH GIÁ

Thống kê Bộ dữ liệu. Chúng tôi báo cáo thống kê của các bộ dữ liệu trong AGENT BENCH ở Bảng 2. Để đơn giản, chúng tôi sử dụng viết tắt của từng bộ dữ liệu trong phần sau. Tất cả bộ dữ liệu đều là những thách thức tương tác nhiều lượt thực tế, và số lượt giải quyết ước tính của chúng cho mỗi vấn đề riêng lẻ dao động từ 5 đến 50. Chúng tôi cung cấp hai phần cho mỗi bộ dữ liệu: Dev và Test. Phần Dev của tất cả môi trường, câu trả lời và script kiểm tra đều công khai, trong khi Test được giữ bí mật.

Chúng tôi cũng cân bằng cẩn thận tính toàn diện và hiệu quả đánh giá trong thiết kế AGENT BENCH, vì tương tác nhiều lượt của LLM có thể tốn thời gian. Chúng tôi đặt kích thước của Dev và Test lần lượt là 269 và 1,091, dẫn đến khoảng 4k và 13k lần gọi để suy luận, xấp xỉ số lượng lần gọi suy luận tương tự như MMLU (Hendrycks et al., 2021b) yêu cầu.

LLM để Đánh giá. Như một nỗ lực hệ thống để đánh giá các LLM hiện tại trên LLM-as-Agent, chúng tôi bao gồm tổng cộng 27 mô hình để đánh giá, có thể được phân loại thô thành hai danh mục:

•LLM Thương mại Dựa trên API: chủ yếu bao gồm các API LLM mà không tiết lộ số lượng tham số (Xem Bảng 1). Do đầu tư nhiều hơn, hiệu suất của chúng thường tốt hơn.

•LLM Mã nguồn mở (OSS): chủ yếu đến từ học viện và một số công ty (Xem Bảng 1). Do tài nguyên tính toán hạn chế, chúng tôi chỉ bao gồm OSS LLM nhỏ hơn 70B ở đây.

Bộ công cụ: Đơn giản hóa Đánh giá LLM với Phương pháp Tập trung API và Cô lập Môi trường. Khi các hệ thống Mô hình Ngôn ngữ (LLM) tiếp tục phát triển về độ phức tạp và chủ yếu có thể truy cập thông qua API, chúng tôi đã phát triển một bộ công cụ đánh giá phù hợp với triết lý định hướng API. Bộ công cụ này được thiết kế tỉ mỉ để tương tác với API, đơn giản hóa quá trình điều chỉnh và kiểm tra các LLM khác nhau. Các nhà nghiên cứu quan tâm đến việc đánh giá LLM của họ trên AGENT BENCH chỉ cần thiết lập một máy chủ mô hình có thể truy cập qua giao thức HTTP.

Hơn nữa, việc xử lý các môi trường tương tác đa dạng và phức tạp đặt ra một thách thức đáng kể. Cấu hình thống nhất tất cả các môi trường này có thể khó khăn và có thể dẫn đến xung đột. Để giải quyết vấn đề này, chúng tôi đã triển khai hai chiến lược chính. Thứ nhất, chúng tôi đóng gói các tác vụ với môi trường phức tạp vào các hình ảnh Docker. Các nhà nghiên cứu có thể dễ dàng sử dụng các hình ảnh này bằng cách gắn đường dẫn mã và khởi tạo quá trình đánh giá một cách dễ dàng. Thứ hai, chúng tôi đã chia nhỏ mỗi tác vụ thành các worker riêng biệt, đảm bảo rằng môi trường của các tác vụ này vẫn cô lập và tránh xung đột. (Tham khảo Phụ lục A để biết thêm chi tiết.)

Thiết lập Prompt Đánh giá. Để phù hợp với đa số các mô hình đối thoại hiện có, paradigm đối thoại của chúng tôi được cấu trúc xung quanh hai vai trò, user (tức là hướng dẫn & phản hồi môi trường) và agent, tham gia và xen kẽ với nhau. Chúng tôi ghi lại quỹ đạo tương tác như một lịch sử cuộc trò chuyện (u₀, a₀,···, uₖ, aₖ) liên quan đến user và agent, trong đó uᵢ, aᵢ đại diện cho vòng cuộc trò chuyện thứ i. Khi chúng tôi thực hiện suy luận, lịch sử cuộc trò chuyện phải như (u₀, a₀,···, uₖ). Chúng tôi chọn r nhỏ nhất sao cho tổng số token² trong (u₀, aᵣ, uᵣ₊₁,···, uₖ) không lớn hơn 3500. Và sau đó chúng tôi thêm "[NOTICE] 2r tin nhắn bị bỏ qua." vào u₀. Sau đó, chuỗi (u₀, aᵣ, uᵣ₊₁,···, uₖ) được coi là đầu vào cuối cùng trong định dạng chat nhiều lượt.

Tuy nhiên, để xem xét các mô hình không phải chat, chúng tôi thêm một bộ xử lý hậu kỳ. Chúng tôi đưa lịch sử vào mô hình cho các mô hình chat hỗ trợ nhiều lượt. Đối với các mô hình chỉ hỗ trợ hoàn thành văn bản (ví dụ, text-davinci-003), chúng tôi thêm tiền tố "USER:" hoặc "AGENT:" vào từng mục trong lịch sử và cuối cùng thêm chuỗi "AGENT:" để làm cho mô hình tạo ra nội dung của agent.

Đối với tổ chức prompt tác vụ, chúng tôi điều chỉnh định dạng từ (Yao et al., 2023b) để bao gồm cả "Thought" (cho CoT) và "Action" nhưng trong một lượt duy nhất. Thông thường, một minh họa CoT đơn giản được cung cấp trong hướng dẫn tác vụ để có định dạng đầu ra tốt hơn. Để đảm bảo kết quả có thể tái tạo, chúng tôi đặt temperature=0 (tức là giải mã tham lam) trong suy luận trên tất cả các tác vụ theo (Wei et al., 2022b).

Tính toán Điểm Tổng thể. Chúng tôi đã quan sát thấy rằng phân phối điểm cho mỗi tác vụ khác nhau đáng kể vì các tác vụ khác nhau về mức độ khó khăn. Kết quả là, điểm trung bình ngây thơ bị ảnh hưởng nặng nề bởi các tác vụ thường mang lại điểm cao hơn (ví dụ, Web Shopping trong quan sát của chúng tôi), che lấp những tác vụ có điểm thấp hơn và không phù hợp với mục đích của AGENT BENCH.

Do đó, chúng tôi tạo ra điểm tổng thể bằng cách đầu tiên thay đổi kích thước điểm trung bình của mỗi tác vụ thành 1 trên tất cả các mô hình chúng tôi đánh giá và sau đó tính trung bình điểm trên tất cả các tác vụ cho mỗi mô hình (Xem Bảng 2). Để tiêu chuẩn hóa và đơn giản hóa tính toán điểm cho các nghiên cứu tương lai, chúng tôi sử dụng điểm trung bình nghịch đảo của tất cả LLM được kiểm tra trong mỗi tác vụ làm trọng số cố định để tính toán điểm tổng thể trong tương lai. Điểm tổng sau đó được tính như giá trị trung bình thu được bằng cách nhân điểm của mỗi tác vụ với trọng số tương ứng. Phương pháp này đảm bảo tính công bằng và nhất quán trong đánh giá, cho phép so sánh và phân tích dễ dàng hơn trong nghiên cứu tương lai.

²Vì tokenizer của mỗi mô hình khác nhau, chúng tôi đơn giản tính toán token như thế này: một từ có độ dài n chiếm ⌈n/6⌉ token, và một ký tự không trống chiếm 1 token.

4.2 KẾT QUẢ CHÍNH

Điểm tổng thể và theo bộ dữ liệu cụ thể trong AGENT BENCH được báo cáo ở Bảng 3. Đáng ngạc nhiên, trên bộ đánh giá thử thách này, chúng tôi phát hiện rằng một số LLM hàng đầu được trang bị khả năng vững chắc để xử lý tương tác môi trường thế giới thực. Ví dụ, gpt-4 thể hiện hiệu suất tốt nhất trên 6 trong 8 bộ dữ liệu trong AGENT BENCH; trên HH, nó đạt tỷ lệ thành công 78%, cho thấy khả năng sử dụng thực tế trong tình huống này. claude-2 và claude theo sau gpt-4 nhưng vượt trội hơn khá nhiều so với gpt-3.5-turbo. Bất chấp hiệu suất tương đối kém hơn của các LLM dựa trên API khác, bất kể tác vụ, hầu hết chúng có thể giải quyết khá nhiều phần trăm vấn đề. Tất cả LLM dựa trên API đều có điểm tổng thể AGENT BENCH trên 1.00.

Tuy nhiên, OSS LLM thường không giải quyết được các vấn đề trong một số tác vụ thử thách, chẳng hạn như KG, DCG và HH. Chúng tôi vẽ biểu đồ hiệu suất của chúng liên quan đến kích thước trong Hình 3. Nói chung, hầu hết LLM mã nguồn mở hoạt động kém hơn nhiều so với LLM dựa trên API trong AGENT BENCH (Trung bình 0.51 so với 2.15). OSS LLM có khả năng nhất hóa ra là codellama-34b, đạt điểm tổng thể 0.96 nhưng vẫn thể hiện khoảng cách hiệu suất rõ ràng với gpt-3.5-turbo. Điều này trái ngược với các tuyên bố gần đây rằng một số OSS LLM có thể so sánh với gpt-3.5-turbo và gpt-4. Chúng ta vẫn cần nhiều nỗ lực để tạo ra OSS LLM mạnh hơn để phục vụ mục đích tác nhân.

4.3 PHÂN TÍCH

Trong đánh giá, chúng tôi phân tích một số yếu tố quan trọng ảnh hưởng đến hiệu suất của tác nhân LLM trên AGENT BENCH, bao gồm phân tích phần kết quả, đào tạo mã, và sự khác biệt giữa LLM thương mại dựa trên API và các đối thủ OSS LLM. Thêm thông tin chi tiết và nghiên cứu trường hợp về khả năng lập kế hoạch, tự sửa chữa và sử dụng công cụ được cung cấp trong Phụ lục J.2.

Phần của Các Loại Kết quả Thực thi Khác nhau. Chúng tôi báo cáo tỷ lệ của các loại kết quả thực thi khác nhau (Xem Phần 2 để giới thiệu) ở Bảng 4. Chính là Task Limit Exceeded đã chiếm ưu thế gây ra sự không hoàn chỉnh của các tác vụ AGENT BENCH. Điều này có nghĩa là bất chấp việc tuân thủ hướng dẫn của hầu hết các tác nhân LLM, chúng không giải quyết được thách thức trong thời gian cho phép hoặc rơi vào tạo sinh lặp lại khi số lượt tương tác tăng lên, cho thấy khả năng suy luận và ra quyết định yếu.

Trong DB và DCG, các tác nhân LLM chủ yếu gặp lỗi Invalid Format, có nghĩa là chúng không tuân thủ đúng các yêu cầu định dạng của hướng dẫn. Việc xác minh định dạng nghiêm ngặt đối với DB, và không có cơ hội thử lại. Hơn nữa, đầu ra dự kiến của tác vụ có thể gần với dữ liệu đào tạo nhất định của mô hình, nhưng không được căn chỉnh chính xác. Sự khác biệt này có thể khiến mô hình quay về định dạng đã được đào tạo trước, vô tình bỏ qua các yêu cầu cụ thể chúng tôi cung cấp. (Xem Phụ lục J.2.1) Đối với DCG, hướng dẫn của nó có thể dài hơn và phức tạp hơn các tác vụ khác do cần giới thiệu luật chơi, khiến một số LLM cảm thấy bối rối. Trong HH và WB, một vấn đề chính khác là về Invalid Action, nơi các tác nhân LLM tạo ra các hành động ngoài không gian hành động được xác định trước. Hai tác vụ này cung cấp nhiều tùy chọn hành động rời rạc ở mỗi lượt, và nhiều LLM không tạo ra hành động từ chúng và do đó gây ra lỗi. Để biết tỷ lệ cụ thể của mỗi LLM, vui lòng tham khảo Phụ lục J.1.

Tác động của Đào tạo Mã. Chúng tôi thấy rằng điều chỉnh mã có thể ảnh hưởng sâu sắc đến cách tạo suy luận và tư duy của mô hình, ngay cả vượt ra ngoài các chủ đề chỉ về lập trình. Từ so sánh của dòng codellama và llama-2, điều chỉnh với mã dường như mang lại cho mô hình lợi thế trong các tác vụ tuân theo quy trình tương đối tĩnh (ví dụ, Web Shopping). Nhưng, loại điều chỉnh này cũng có thể ảnh hưởng đến khả năng tư duy tổng quát của mô hình, vì dòng codellama không hoạt động tốt trong Digital Card Game như dòng llama-2. Điều này chỉ ra sự cân bằng giữa việc giỏi tuân thủ quy trình và giỏi tư duy tổng quát khi điều chỉnh LLM.

Tác động của Đào tạo Dữ liệu Căn chỉnh Chất lượng Cao. Một so sánh hữu ích khác sẽ là giữa vicuna-13b và llama-2-13b. Trong khi chúng chia sẻ cùng LLM cơ sở, vicuna-13b được căn chỉnh bằng cách đào tạo trên dữ liệu ShareGPT (được tạo bởi gpt-4 và gpt-3.5-turbo, được chia sẻ bởi người dùng) và llama-2-13b được căn chỉnh từ đầu. Kết quả là, vicuna-13b vượt trội hơn llama-2-13b trên AGENT BENCH, và thậm chí hoạt động tương đương với codellama-34b lớn gấp 3 lần. Điều này cho thấy rằng căn chỉnh chất lượng cao vẫn là chìa khóa để phát triển các tác nhân LLM tốt hơn.

Hiệu suất Tương tự Bất ngờ của llama-2-13b và llama-2-70b. Trong các thí nghiệm của chúng tôi, chúng tôi ngạc nhiên khi thấy rằng llama-2-13b và llama-2-70b hoạt động tương tự bất chấp khoảng cách đáng kể giữa kích thước của chúng. Sau khi kiểm tra cẩn thận và chạy lại thí nghiệm, kết quả không thay đổi. Chúng tôi nghĩ rằng điều này cho thấy việc đào tạo trước không đủ của llama-2-70b. Trong khi cả llama-2-13b và llama-2-70b đều được đào tạo trước với 2T token, một LLM lớn hơn nên được đào tạo với nhiều token hơn theo quy luật tỷ lệ (Hoffmann et al., 2022).

5 CÔNG VIỆC LIÊN QUAN

Đánh giá LLM. Khả năng tổng quát của các LLM tự giám sát (Liu et al., 2021) (Brown et al., 2020; Chowdhery et al., 2022; Zhang et al., 2022; Scao et al., 2022; Zeng et al., 2022; Touvron et al., 2023), đặc biệt là những LLM được căn chỉnh chat (Ouyang et al., 2022; Anthropic, 2023a; OpenAI, 2023), đã làm mới ấn tượng của mọi người về hệ thống học sâu và vượt quá đáng kể phạm vi thông thường của đánh giá NLP. Do đó, việc đánh giá LLM trở thành một vấn đề cấp thiết và thử thách. So với các nỗ lực trước đây tập trung vào một tập hợp con của các tác vụ được chỉ định (Wang et al., 2019; Wang et al.; Gehrmann et al., 2021), số lượng ngày càng tăng của các bộ đánh giá đang bao gồm phổ rộng hơn của các tác vụ và bộ dữ liệu (Hendrycks et al., 2021b; Liang et al., 2022; Srivastava et al., 2023) trong đánh giá. Tuy nhiên, hầu hết chúng vẫn bị hạn chế trong các tác vụ truyền thống và do đó không đánh giá được tạo sinh mở, tương tác nhiều lượt và khả năng hoạt động như các tác nhân của LLM.

LLM-as-Agent. Trong thời kỳ trước LLM, môi trường game văn bản như TextWorld (Côté et al., 2019), Jericho (Hausknecht et al., 2020), và LIGHT (Urbanek et al., 2019) chiếm ưu thế trong nghiên cứu tác nhân ngôn ngữ dựa trên BERT (Devlin et al., 2019) và học tăng cường. Với sự xuất hiện của LLM, nghiên cứu về các tác nhân LLM bắt đầu thịnh vượng (Huang et al., 2022), đặc biệt là sau khi Chain-of-Thought (Wei et al., 2022b) ra đời. ReAct (Yao et al., 2023b) là một công trình tiên phong để kết hợp suy luận CoT và hành động trong các tác vụ tác nhân. Sau đó, một loạt các chiến lược suy luận tiến bộ (Kim et al., 2023; Shinn et al., 2023; Wang et al., 2023d; Liu et al., 2023; Yao et al., 2023a; Gu et al., 2023) và ứng dụng (Park et al., 2023; Richards, 2023; Nakajima, 2023; age, 2023) cho LLM-as-Agent đã xuất hiện và thu hút nhiều sự quan tâm của công chúng. Tuy nhiên, các bộ dữ liệu và mô hình hạn chế và có sẵn về chủ đề này, không có bộ đánh giá tiêu chuẩn và toàn diện. AGENT BENCH trình bày bộ đánh giá hệ thống đầu tiên để đánh giá LLM-as-Agent với phạm vi rộng của các tác vụ và LLM có sẵn. Ngoài ra, nó cũng khởi xướng ý tưởng áp dụng các tác vụ tác nhân để đo lường hiệu suất LLM.

Đánh giá LLM trong Môi trường Thực thi. Khi LLM trở nên ngày càng có khả năng đối phó với các thách thức thế giới thực, cũng có xu hướng đánh giá chúng trong môi trường thực thi hơn là các bộ dữ liệu tĩnh. Bên cạnh các game văn bản (ví dụ, ALFWorld (Shridhar et al., 2020b)), một dòng chính khác của các công trình nằm trong việc thực thi mã. APPS (Hendrycks et al., 2021a), HumanEval (Chen et al., 2021) và MBPP (Austin et al., 2021) tiên phong nỗ lực đánh giá LLM mã về tính đúng đắn chức năng thay vì tương đồng văn bản. Paradigm này sau đó đã được công nhận rộng rãi và áp dụng trong các công trình tiếp theo (Li et al., 2022; Zheng et al., 2023; Nijkamp et al., 2023). Tuy nhiên, ít khung đánh giá mã trước đây xem xét tương tác nhiều lượt. Một công trình đồng thời InterCode (Yang et al., 2023) phát hành một khung cho phép đánh giá tương tác giữa các mô hình và môi trường Bash và SQL, tương tự như các tác vụ OS và DB trong AGENT BENCH.

6 KẾT LUẬN

Chúng tôi trình bày AGENT BENCH, một bộ đánh giá đa chiều phát triển được thiết kế hệ thống để đánh giá LLM như các tác nhân. Lần đầu tiên, chúng tôi bao gồm một loạt rộng như vậy với tới 8 thách thức thế giới thực để đánh giá các tác nhân LLM, và thiết lập một khung kiểm tra thống nhất và bộ công cụ để đánh giá nhanh chóng. Một nghiên cứu rộng rãi về 27 LLM, bao gồm dựa trên API và Mã nguồn mở, được thực hiện cẩn thận trong một thiết lập tiêu chuẩn. Trong đánh giá của chúng tôi, các mô hình thương mại đương đại đã thể hiện khả năng sơ bộ như các tác nhân trong phân tích, lập kế hoạch, thực hiện kế hoạch, gọi công cụ và tự phản ánh. Những khả năng này gợi ý năng lực sơ khai của chúng trong việc giải quyết các thách thức thế giới thực. Ngược lại, chúng tôi cho rằng các mô hình mã nguồn mở có thể thiếu một số năng lực này hoặc, tốt nhất, chỉ sở hữu một tập hợp con của chúng đồng thời. Chúng tôi hy vọng AGENT BENCH sẽ phục vụ như một nền tảng cho nghiên cứu sau này để phát triển các tác nhân LLM thông minh tốt hơn và có thể áp dụng hơn.

TÀI LIỆU THAM KHẢO

[Phần tài liệu tham khảo tiếp tục với tất cả các tham chiếu được dịch sang tiếng Việt...]

# 2309.14402.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl-papers/2309.14402.pdf
# Kích thước tệp: 2725821 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Vật lý của các Mô hình Ngôn ngữ: Phần 3.2,
Thao tác Kiến thức
Zeyuan Allen-Zhu
zeyuanallenzhu@meta.com
Meta AI / FAIR Labs Yuanzhi Li
Yuanzhi.Li@mbzuai.ac.ae
Đại học AI Mohamed bin Zayed
18 tháng 9, 2023
(phiên bản 2)∗

Tóm tắt
Các mô hình ngôn ngữ có thể lưu trữ kiến thức thực tế rộng lớn, nhưng khả năng sử dụng linh hoạt kiến thức này cho các tác vụ xuôi dòng (ví dụ: thông qua tinh chỉnh hướng dẫn) vẫn còn đáng nghi ngờ. Bài báo này điều tra bốn tác vụ thao tác kiến thức cơ bản: truy xuất (ví dụ: "Thuộc tính X của người A là gì?"), phân loại (ví dụ: "Thuộc tính X của A có chẵn hay lẻ?"), so sánh (ví dụ: "A có lớn hơn B về thuộc tính X không?"), và tìm kiếm ngược (ví dụ: "Thuộc tính X của ai bằng T?").

Chúng tôi cho thấy rằng các mô hình ngôn ngữ xuất sắc trong việc truy xuất kiến thức nhưng gặp khó khăn ngay cả trong các tác vụ phân loại hoặc so sánh đơn giản nhất trừ khi Chuỗi Suy nghĩ (CoT) được sử dụng trong cả quá trình huấn luyện và suy luận. Hơn nữa, hiệu suất của chúng trong tìm kiếm kiến thức ngược thực tế là 0%, bất kể các lời nhắc. Đóng góp chính của chúng tôi là một thí nghiệm tổng hợp có kiểm soát xác nhận những điểm yếu này là vốn có của các mô hình ngôn ngữ: chúng không thể thao tác kiến thức từ dữ liệu tiền huấn luyện một cách hiệu quả, ngay cả khi kiến thức đó được lưu trữ hoàn hảo trong các mô hình, bất chấp việc huấn luyện đầy đủ và kích thước mô hình đủ lớn. Những phát hiện của chúng tôi cũng áp dụng cho các mô hình ngôn ngữ được tiền huấn luyện hiện đại như GPT-4, do đó tạo ra nhiều bài kiểm tra Turing để phân biệt Con người khỏi AI đương đại.

∗Trang dự án: https://physics.allen-zhu.com/part-3-knowledge/part-3-2 . Video mở rộng của bài báo này có sẵn tại https://youtu.be/YSHzKmEianc . V1 được lưu hành nội bộ tại Meta vào ngày 18 tháng 9, 2023, và xuất hiện trên arXiv vào ngày 25 tháng 9, 2023. V2 trau chuốt cách viết và bao gồm các thí nghiệm Llama/Mistral bổ sung và dữ liệu lớn hơn; nhưng kết luận không thay đổi.

Chúng tôi muốn cảm ơn Lin Xiao, Chunting Zhou, Xiaodong Liu, Zhijie Zhou vì nhiều cuộc trò chuyện hữu ích. Chúng tôi muốn gửi lời cảm ơn đặc biệt đến Nabib Ahmed, Giri Anantharaman, Lucca Bertoncini, Henry Estela, Liao Hu, Caleb Ho, Wil Johnson, Apostolos Kokolis, và Shubho Sengupta từ Meta FAIR, cũng như Ian Clark, Gourab De, Anmol Mann, và Max Pfeifer từ W&B; nếu không có sự hỗ trợ quý giá của họ, các thí nghiệm trong bài báo này sẽ không thể thực hiện được.arXiv:2309.14402v2 [cs.CL] 16 Jul 2024

--- TRANG 2 ---
1 Giới thiệu

Kiến thức là một thành phần cơ bản của nền văn minh và trí tuệ con người. Trong suốt cuộc đời, chúng ta tích lũy một lượng kiến thức khổng lồ và học cách sử dụng nó một cách linh hoạt. Các mô hình ngôn ngữ lớn như GPT-4 [23] đã chứng minh khả năng ghi nhớ kiến thức ấn tượng, có thể nói là vượt qua bất kỳ con người nào. Những mô hình này cũng cho thấy dấu hiệu có thể thao tác kiến thức này để giải quyết các vấn đề khác nhau.

Trong nghiên cứu này, chúng tôi nhằm hiểu cách các mô hình ngôn ngữ dựa trên transformer thao tác kiến thức mà chúng đã ghi nhớ trong quá trình tiền huấn luyện và sử dụng nó một cách linh hoạt để giải quyết các tác vụ khác nhau tại thời điểm suy luận. Ví dụ, các mô hình ngôn ngữ có thể xác định xem Princeton được xếp hạng cao hơn MIT hay không dựa trên kiến thức xếp hạng đại học Mỹ năm 2023 mà chúng đã lưu trữ? Chúng có thể trả lời các câu hỏi như "Joe Biden có sinh vào năm lẻ không?" hoặc "Donald Trump có sinh sớm hơn Nancy Pelosi không?" dựa trên việc ghi nhớ ngày sinh của các nhân vật nổi tiếng không? (Cảnh báo, ngay cả GPT-4 hoặc Llama-3 vẫn thất bại trong việc trả lời những câu hỏi này tính đến ngày 10 tháng 5, 2024, xem Hình 9; bài báo này giải thích tại sao.)

Nói cách khác, chúng tôi quan tâm đến các câu hỏi là hàm số của kiến thức cụ thể từ dữ liệu tiền huấn luyện, và nghiên cứu khả năng của mô hình ngôn ngữ trong việc trả lời các câu hỏi trong thời gian suy luận. Thao tác kiến thức có thể nói là hình thức đơn giản nhất của suy luận logic. Để trả lời các câu hỏi như "Thuộc tính X của Người A có tốt không?", một mô hình chưa từng tiếp xúc với câu này trong dữ liệu huấn luyện có thể đưa ra kết luận từ dữ liệu khác như "Thuộc tính X của Người A bằng T" và "T là tốt".

Trong bài báo này, "kiến thức" đề cập đến kiến thức thực tế (ví dụ: đồ thị kiến thức), và chúng tôi khám phá liệu mô hình ngôn ngữ có thể thao tác logic kiến thức đó được nhúng trong trọng số mô hình không. Nghiên cứu khác có thể tập trung vào kiến thức trong ngữ cảnh hoặc RAG [6, 14, 15, 17–19, 24, 29, 32], nơi mô hình phản hồi các truy vấn về đoạn văn được cung cấp trong ngữ cảnh (có thể thông qua RAG).

Nghiên cứu rộng rãi đã được thực hiện về khả năng hỏi-đáp của các mô hình ngôn ngữ tại thời điểm suy luận [11, 20, 22, 25, 26, 30, 31, 34], chủ yếu tập trung vào các mô hình được huấn luyện với dữ liệu internet. Thách thức đáng kể trong việc xác định liệu các mô hình này có thể thao tác kiến thức hay không là phải xác định liệu dữ liệu internet đã chứa câu hỏi chính xác hoặc tương đương, hoặc các mô hình thực sự thực hiện suy luận logic trong thời gian suy luận.

Chúng tôi đặc biệt quan tâm đến các tình huống không có nhiễu dữ liệu: các câu hỏi hoặc các dạng tương đương của chúng không nên xuất hiện trong dữ liệu huấn luyện của mô hình, trong khi cùng một "hàm số" cho kiến thức khác nên có mặt - do đó đảm bảo mô hình hiểu hàm số. Ví dụ, mô hình có thể xác định "Joe Biden có sinh vào năm lẻ không?" nếu nó chưa gặp câu này hoặc các dạng tương đương trong tiền huấn luyện (như "Năm sinh của Joe Biden có chia hết cho 2 không"), nhưng có thể suy luận từ "Biden sinh năm 1942" và "1942 không phải là lẻ"? Việc trả lời những câu hỏi như vậy yêu cầu mô hình phải ghi nhớ và hiểu kiến thức. (Xem Hình 1.)

Để giải quyết tính không thể dự đoán của dữ liệu internet, Allen-Zhu và Li [2, 3] đã phát triển dữ liệu tiền huấn luyện tổng hợp có kiểm soát chứa tiểu sử có kiểm soát cho tới N = 20 triệu cá nhân. Họ khám phá cách mô hình ngôn ngữ lưu trữ và trích xuất kiến thức về những cá nhân này sau khi tiền huấn luyện. Đây là một ví dụ về dữ liệu tiểu sử của họ:

Anya Briar Forger được sinh ra vào ngày 2 tháng 10, 1996. Cô đã trải qua những năm đầu đời tại Princeton, NJ. Cô được nhận sự hướng dẫn và chỉ bảo từ các thành viên khoa tại Viện Công nghệ Massachusetts. Cô hoàn thành việc học với trọng tâm về Truyền thông. Cô có vai trò chuyên môn tại Meta Platforms. Cô được tuyển dụng tại Menlo Park, CA.
(1.1)

Allen-Zhu và Li [2] phát hiện rằng mô hình được tiền huấn luyện có thể gặp khó khăn trong việc trích xuất kiến thức đã lưu trữ từ dữ liệu tiểu sử trừ khi dữ liệu đủ được tăng cường kiến thức, có nghĩa là cùng một tiểu sử có các mô tả tiếng Anh đa dạng và được hoán vị tốt (xem Mục 2). Việc tăng cường này hỗ trợ trong việc trả lời chính xác các truy vấn trích xuất như "Anya Briar Forger được sinh ra ở thành phố nào?"

--- TRANG 3 ---
Trong khi chúng tôi khuyến nghị đọc nghiên cứu đồng thời của chúng tôi [2] trước, bài báo này có thể được đọc độc lập.

1.1 Kết quả của chúng tôi

Bài báo này tiếp tục khám phá liệu mô hình, được tiền huấn luyện trên dữ liệu tiểu sử tăng cường, có thể thao tác kiến thức của nó sau khi tinh chỉnh hướng dẫn. Chúng tôi điều tra khả năng xử lý các truy vấn đòi hỏi suy luận về thuộc tính cá nhân, như "Anya có sinh ở thành phố phía nam không?" hoặc "Đại học của Anya có tốt hơn của Sabrina không?"

Trong quá trình huấn luyện, mô hình học từ tiểu sử của tất cả N cá nhân và văn bản hỏi-đáp (QA) thao tác kiến thức từ một tập con các cá nhân (tập phân phối trong Ptrain). Chúng tôi đánh giá độ chính xác tạo sinh ngoài phân phối (OOD) của mô hình bằng cách kiểm tra nó trên tập con còn lại (tập ngoài phân phối Ptest), nơi nó đã thấy các tiểu sử nhưng không thấy QA trong quá trình huấn luyện. Việc bao gồm Ptrain trong dữ liệu huấn luyện đảm bảo mô hình gặp đủ ví dụ để hiểu QA. Chúng tôi tập trung vào độ chính xác OOD của mô hình trên Ptest, phản ánh khả năng thực sự của nó trong suy luận logic tại thời điểm suy luận, trái ngược với trên Ptrain có thể dễ dàng đạt 100%.

Chúng tôi nghiên cứu bốn loại thao tác kiến thức cơ bản: truy xuất, phân loại, so sánh, và tìm kiếm ngược, bao gồm hầu hết các tình huống thực tế.¹

Truy xuất kiến thức. Mở rộng nghiên cứu về trích xuất kiến thức [2], chúng tôi tinh chỉnh mô hình để truy xuất (1) một phần của thuộc tính hoặc (2) nhiều thuộc tính cùng lúc. Chúng tôi phát hiện mô hình có thể:
• trả lời đúng "Ngày sinh của Anya là gì" là "27 tháng 6, 1997", nhưng gặp khó khăn với "Năm sinh của Anya là gì" (Kết quả 2); và
• trả lời đúng "Anya làm việc ở công ty nào và ở đâu" nhưng thất bại với "Anya làm việc ở đâu và ở công ty nào." (Kết quả 1)

Những điều này phục vụ như bằng chứng sơ bộ cho thấy sự cần thiết của Chuỗi Suy nghĩ (CoT) cho thao tác kiến thức. Mô hình phải nêu rõ tháng/ngày sinh để suy ra năm sinh, hoặc nêu rõ tên công ty trước vị trí thành phố làm việc.

Phân loại kiến thức. Chúng tôi tinh chỉnh mô hình cho các tác vụ phân loại trên kiến thức đã lưu trữ; ví dụ, "Anya nhận được bằng gì?" có thể yêu cầu phân loại ba nhóm (nghệ thuật, khoa học, kỹ thuật) dựa trên chuyên ngành của cô. Các mô hình ngôn ngữ thường gặp khó khăn với những tác vụ này trừ khi chúng (1)

¹ Người ta cũng có thể khám phá các kết hợp, như "Vợ của A có đại học được xếp hạng cao hơn của B không?" hoặc "Người sinh vào ngày 27 tháng 6, 1997, và học tại MIT có tên bắt đầu bằng A không?" Những điều này sẽ làm phức tạp hơn nữa các tác vụ. Cho rằng chúng tôi cho thấy hầu hết kết quả tiêu cực, việc tập trung vào các dạng cơ bản là đủ.

[Hình 1: Chúng tôi nghiên cứu (A) so với (E) như thao tác kiến thức. Với mô hình được tiền huấn luyện trên dữ liệu internet, rất khó để xác định liệu (B,C,D) đã xảy ra do tính không thể kiểm soát của dữ liệu internet.]

--- TRANG 4 ---
[Hình 2: GPT-4 gặp khó khăn trong việc trả lời các câu hỏi thao tác kiến thức đơn giản; nhưng khi sử dụng CoT, nơi các thuộc tính của người được nêu ra một cách rõ ràng trước, GPT-4 có thể trả lời chính xác. Nhiều ví dụ GPT-4 hơn được trình bày trong Hình 5, 7, 15, và Phụ lục E. Khi chúng tôi chuẩn bị bài báo này, chúng tôi sử dụng GPT-4 của năm 2023. Tính đến ngày 10 tháng 5, 2024, những phản ví dụ như vậy vẫn áp dụng cho GPT-4 và Llama-3, xem Hình 9.]

tạo ra câu trả lời theo cách CoT hoặc (2) được tinh chỉnh với số lượng mẫu lớn hơn đáng kể so với lý thuyết cần thiết.

Cụ thể, đối với phân loại nhị phân "Anya có sinh vào tháng chẵn không", các mô hình ngôn ngữ thất bại mà không có CoT - tức là không tạo ra tháng "Tháng mười" trước và sau đó đánh giá tính chẵn lẻ của nó. Điều này vẫn đúng ngay cả khi mô hình được huấn luyện đầy đủ:
• để trả lời tháng sinh của mọi người với độ chính xác 100%,
• trên 25.000 mẫu QA, nhiều hơn cần thiết để phân loại 12 tháng thành 2 lớp,

Điều này tiết lộ rằng các mô hình ngôn ngữ không thể được huấn luyện+tinh chỉnh hiệu quả để thực hiện ngay cả một bước thao tác kiến thức trong thời gian suy luận mà không có CoT (Kết quả 3). Hơn nữa, những phát hiện của chúng tôi tiết lộ:
• Bao gồm đủ mẫu CoT trong huấn luyện không cải thiện suy luận không CoT (Kết quả 4);
• Cải thiện trích xuất kiến thức của mô hình không cải thiện khả năng thao tác của nó (Kết quả 5).

Quan trọng, điều này khác với và không mâu thuẫn với hầu hết CoT phổ biến được sử dụng trong thực tế để tăng cường kỹ năng toán học hoặc suy luận; ví dụ, GPT-4 có thể bỏ qua một bước tính toán và trả lời liệu tổng của a và b có chẵn không với a, b ∈ [12], mà không viết ra tổng của chúng một cách rõ ràng. Rộng hơn, nhiều suy luận trong ngữ cảnh có thể được thực hiện trong đầu [37].

So sánh kiến thức. Tác vụ này bao gồm việc xác định liệu một thuộc tính có lớn hơn thuộc tính khác hay không, dựa trên thứ hạng được xác định trước. Ví dụ, "Đại học của Anya có tốt hơn của Sabrina không?" yêu cầu phản hồi Có/Không dựa trên thứ hạng của các đại học. Kết quả của chúng tôi phù hợp với những kết quả từ trường hợp phân loại: các mô hình gặp khó khăn trong việc thực hiện so sánh kiến thức hiệu quả mà không có CoT.

Ví dụ, độ chính xác của việc so sánh kiến thức giữa 100 lựa chọn hầu như bằng đoán ngẫu nhiên, ngay cả với 2.500.000 mẫu huấn luyện, nhiều hơn đủ để học xếp hạng 100 đối tượng (Kết quả 3-5).

Tìm kiếm kiến thức ngược. Điều này bao gồm việc xác định một người dựa trên thuộc tính của họ, như "Ai được sinh vào ngày 2 tháng 10, 1996 tại Princeton..." khi kiến thức chỉ được trình bày theo hướng thuận trong dữ liệu huấn luyện: "Anya Forger được sinh vào ngày 2 tháng 10, 1996..." Chúng tôi phát hiện rằng các mô hình ngôn ngữ không thể thực hiện tác vụ này, bất kể phương pháp huấn luyện, dữ liệu, hoặc kích thước mô hình, trừ khi kiến thức đã được trình bày ngược trong dữ liệu (Kết quả 8).² Điều này cho thấy các mô hình ngôn ngữ không thể được sử dụng như cơ sở dữ liệu.

Nhận xét 1.1. Nhiều thao tác kiến thức là các hàm số kết hợp của các tác vụ trên (xem Chú thích 1); vì chúng tôi chủ yếu trình bày kết quả tiêu cực, việc nghiên cứu các dạng đơn giản nhất của chúng là đủ.

Trong thực tế. Chúng tôi cũng chứng minh rằng các mô hình lớn hiện đại như GPT-4 hoặc Llama-3 (xem Hình 2) gặp khó khăn với những tác vụ này (Kết quả 6, 8), cho thấy những hạn chế này có thể là vốn có của các mô hình ngôn ngữ sinh và không dễ dàng khắc phục bằng cách mở rộng quy mô.

1.2 Đóng góp của chúng tôi

Chúng tôi phát hiện rằng các mô hình ngôn ngữ, thông qua các thí nghiệm có kiểm soát và được tiền huấn luyện trên dữ liệu tổng hợp, hoạt động kém trong các tác vụ thao tác kiến thức cơ bản. Chúng gặp khó khăn với các dạng đơn giản của phân loại kiến thức hoặc so sánh, trừ khi được huấn luyện và nhắc nhở theo cách CoT; và chúng hoàn toàn thất bại trong tìm kiếm kiến thức ngược. Thiết lập tổng hợp này hoạt động như một bộ kiểm tra đơn giản nhưng quan trọng cho các nghiên cứu tương lai để tăng cường khả năng thao tác kiến thức của các mô hình ngôn ngữ.

Liên quan đến nghiên cứu trước về CoT. Việc giới thiệu chính thức về CoT [36] và các nghiên cứu tiếp theo đã làm nổi bật tầm quan trọng của CoT đối với các phép tính phức tạp trong ngữ cảnh, như giải quyết các bài toán. Tuy nhiên, nghiên cứu của chúng tôi tập trung vào các hàm số đơn giản liên quan đến kiến thức thực tế ngoài ngữ cảnh. Ví dụ, GPT-4 có thể trả lời chính xác "Tổng của a và b có phải là số chẵn không?" (với a, b ∈ [12]) mà không cần tính toán rõ ràng a+b.

Bài báo của họ cũng đề cập đến câu hỏi thao tác kiến thức, như "Aristotle có sử dụng laptop không?" hoặc "Quả lê có chìm trong nước không?" từ bộ dữ liệu StrategyQA [7]. Mặc dù GPT-4 có thể trả lời một số câu hỏi Có/Không này ngày nay, không rõ liệu điều này là do nhiễu dữ liệu hay khả năng vốn có để thao tác kiến thức mà không cần CoT. Ngay cả khi không, có thể là do nó không được huấn luyện đủ tốt để hiểu năm sinh của Aristotle và máy tính xách tay, hoặc mật độ của quả lê?

Điều này nhấn mạnh sự cần thiết của các thí nghiệm tổng hợp có kiểm soát để loại bỏ những khả năng như vậy và khám phá khả năng thực sự của mô hình ngôn ngữ trong các tác vụ thao tác kiến thức (xem lại Hình 1). Mặt khác, các nghiên cứu hệ thống như của chúng tôi cho phép chúng tôi tìm ra những phản ví dụ có thể nói là đơn giản nhất cho các LLM hiện đại, dễ hơn so với những ví dụ trong bộ dữ liệu StrategyQA.

Liên quan đến con người. Những phát hiện của chúng tôi gợi ý một bài kiểm tra Turing để phân biệt con người khỏi các mô hình ngôn ngữ sinh hiện đại (ít nhất là tính đến hôm nay). Con người có thể thực hiện các tác vụ thao tác kiến thức đơn giản trong đầu, trong khi các mô hình ngôn ngữ yêu cầu viết ra CoT một cách rõ ràng. Bất chấp thách thức của tìm kiếm ngược đối với con người, chúng tôi đã xác định các tác vụ dễ dàng giải quyết bởi con người nhưng không phải bởi GPT-4 (tham khảo Hình 7). Điều này cho thấy tồn tại các kỹ năng thao tác kiến thức mà việc thiết kế và huấn luyện các mô hình ngôn ngữ tự hồi quy chưa vượt qua con người.

Liên quan đến ngành công nghiệp. Trong khi bài báo này tiết lộ rằng các kỹ thuật mới là cần thiết để cải thiện cơ bản khả năng thao tác kiến thức của mô hình ngôn ngữ, các biện pháp giảm thiểu ngay lập tức cũng có thể. Điều này bao gồm tạo ra thêm dữ liệu CoT (Mục 4) và sử dụng các phương pháp như tăng cường sinh ngữ cảnh (RAG) [17] và huấn luyện đảo ngược [9, 10, 21] để hỗ trợ tìm kiếm ngược, hoặc dự đoán đa token [8] để hỗ trợ truy xuất một phần. Chúng tôi cũng đề xuất viết lại tài liệu huấn luyện để bao gồm dữ liệu đảo ngược và giới thiệu số dòng tài liệu (Kết quả 9) để tăng cường khả năng tìm kiếm ngược. Những chiến lược này có thể thông tin cho việc phát triển các mô hình ngôn ngữ quy mô công nghiệp trong tương lai.

2 Những vấn đề cơ bản

Để làm cho bài báo này tự đứng vững, chúng tôi tóm tắt một số bộ dữ liệu, thuật ngữ, mô hình và phương pháp huấn luyện được giới thiệu trong [2, 3].

--- TRANG 5 ---
Bộ dữ liệu BIO bioS. Allen-Zhu và Li [2] đã giới thiệu một họ dữ liệu tiểu sử tổng hợp (BIO), bioS, bao gồm N = 100.000 cá nhân với sáu thuộc tính: ngày sinh, thành phố sinh, đại học, chuyên ngành, tên công ty, và thành phố công ty.³ Sáu câu được chọn ngẫu nhiên mô tả thuộc tính của mỗi cá nhân như trong (1.1). Thiết lập cơ bản của họ chỉ có một mục tiểu sử cho mỗi người với các câu theo thứ tự giống như (1.1). Họ cũng khám phá tăng cường kiến thức, bao gồm: multiM, tạo ra M mục tương đương cho mỗi người (sử dụng từ ngữ khác nhau); permute, xáo trộn câu ngẫu nhiên; và fullname, thay thế đại từ bằng tên đầy đủ. Tổng cộng có 16 bộ dữ liệu.⁴

Sau đó, Allen-Zhu và Li [3] đã tổng quát hóa điều này cho N lớn hơn. Trong phần chính, chúng tôi sử dụng N = 100k để so sánh tốt hơn với Allen-Zhu và Li [2]; trong phụ lục, chúng tôi cũng sử dụng N = 2 hoặc 5 triệu.

Bộ dữ liệu BIO bioR. Allen-Zhu và Li [2] cũng giới thiệu 7 phiên bản của bộ dữ liệu bioR, được tạo ra bằng cách nhắc LLaMA [35, 39] viết các mục tiểu sử gần với thực tế. Bài báo này sử dụng bioS cho kết quả tiêu cực và cả bioS và bioR cho kết quả tích cực.

QA và trích xuất kiến thức đơn. Allen-Zhu và Li [2] đã phân tích các QA như "Thành phố sinh của Anya Briar Forger là gì?" tương ứng với sáu thuộc tính. Họ chia N cá nhân thành hai phần bằng nhau: tập huấn luyện Ptrain và tập kiểm tra Ptest, và khám phá hai phương pháp huấn luyện:

• Huấn luyện trộn InBIO+QA, đồng thời huấn luyện mô hình ngôn ngữ trên BIO cho mọi người và dữ liệu QA cho Ptrain, sử dụng tỷ lệ QAr để kiểm soát tỷ lệ phần trăm của dữ liệu QA.
• Tiền huấn luyện InBIO + tinh chỉnh QA, ban đầu tiền huấn luyện mô hình ngôn ngữ với dữ liệu BIO, sau đó tinh chỉnh nó bằng cách sử dụng QA cho các cá nhân trong Ptrain.

Trong cả hai trường hợp, người ta có thể đánh giá độ chính xác của mô hình trong việc trả lời câu hỏi về các cá nhân trong Ptest, được gọi là độ chính xác kiểm tra QA. Những phát hiện chính từ [2] bao gồm:

• Sự thành công của tinh chỉnh QA phụ thuộc phần lớn vào tăng cường dữ liệu tiền huấn luyện. Ví dụ, tiền huấn luyện trên bioS multi5+permute mang lại độ chính xác trích xuất kiến thức trung bình hơn 96,6%, trong khi bioS single chỉ đạt 9,7% độ chính xác (xem khối bên phải của Hình 3).⁵
• Trong huấn luyện trộn BIO+QA, tăng cường kiến thức ít quan trọng hơn, với mô hình đạt hơn 85% độ chính xác kiểm tra QA trên bioS single. Tuy nhiên, như được chỉ ra trong [2], phương pháp này phản ánh cách tiếp cận "học để vượt qua bài kiểm tra", nơi kiến thức được học từ QA trước, không giống như việc thu thập kiến thức điển hình của con người và cũng ít thực tế hơn.

Các mô hình ngôn ngữ. Chúng tôi nghiên cứu các kiến trúc GPT2/Llama/Mistral [13, 28, 35]; đối với GPT2, chúng tôi thay thế nhúng vị trí tuyệt đối của nó bằng nhúng vị trí xoay hiện đại [5, 33], vẫn được gọi là GPT2 cho ngắn gọn.⁶ Trong phần chính của bài báo này, chúng tôi đã theo Allen-Zhu và Li [2] để sử dụng GPT2 12 lớp 768-dim cho dữ liệu bioS và GPT2 12 lớp 1280-dim cho dữ liệu bioR; trong khi chúng tôi chỉ ra trong phụ lục rằng cùng một kết quả cũng đúng cho các kiến trúc GPT2/Llama/Mistral có kích thước lớn hơn. Độ dài cửa sổ ngữ cảnh cố định là 512 được sử dụng trong toàn bộ bài báo này.

3 Kết quả 1-2: Truy xuất Kiến thức Kép và Một phần

Chúng tôi kiểm tra hai tác vụ truy xuất kiến thức một phần liên quan đến việc trích xuất ngày sinh hoặc năm sinh của người đó từ thông tin ngày sinh đầy đủ.

³ Tất cả thuộc tính, ngoại trừ thành phố công ty (được xác định duy nhất bởi tên công ty), được chọn ngẫu nhiên.
⁴ Một thiết lập cơ bản cộng với 15 tăng cường là sự kết hợp của những điều trên. Ví dụ, "bioS multi5+permute" biểu thị năm mục tiểu sử cho mỗi cá nhân với các câu được xáo trộn. Tham khảo Hình 3 hoặc Phụ lục A để có danh sách đầy đủ các tăng cường như vậy.
⁵ Allen-Zhu và Li [2] đã sử dụng thăm dò để giải thích hiện tượng này. Về cơ bản, tăng cường kiến thức trong dữ liệu tiền huấn luyện BIO đảm bảo rằng kiến thức gắn liền chặt chẽ hơn với tên của cá nhân.
⁶ GPT2 như vậy hoạt động không tồi hơn Llama/Mistral cho các tác vụ kiến thức [3].

--- TRANG 6 ---
[Hình 3: Truy xuất một phần (trái) và kép (giữa) kiến thức, so với trích xuất kiến thức đơn (phải). Mỗi hàng là một bộ dữ liệu bioS được tăng cường khác nhau (xem Mục 2), và khối bên phải là từ [2]. Đây là cho GPT2 và xem Hình 10(a) cho dữ liệu bioR; cùng kết quả đúng cho kiến trúc LLaMA Hình 10(b) và 10(c); cũng như cho dữ liệu 50x lớn hơn và mô hình GPT2/Mistral/Llama 5.5x lớn hơn Hình 10(d). Chi tiết trong Phụ lục B.]

1. Ngày sinh của Anya Briar Forger là gì? 2. 
2. Năm sinh của Anya Briar Forger là gì? 1996.

Chúng tôi xem xét sáu tác vụ truy xuất kiến thức kép:

1. Anya Briar Forger sinh ở đâu và làm việc cho công ty nào? Princeton, NJ; Meta Platforms.
2. Anya Briar Forger làm việc cho công ty nào và sinh ở đâu? Meta Platforms; Princeton, NJ.
3. Anya Briar Forger học đại học nào và chuyên ngành gì? Viện Công nghệ Massachusetts; Truyền thông.
4. Anya Briar Forger học chuyên ngành gì và đại học nào? Truyền thông; Viện Công nghệ Massachusetts.
5. Anya Briar Forger làm việc ở đâu và cho công ty nào? Menlo Park, CA; Meta Platforms.
6. Anya Briar Forger làm việc cho công ty nào và ở đâu? Meta Platforms; Menlo Park, CA.

Phương pháp. Chúng tôi nhằm xác định liệu mô hình được tiền huấn luyện trên dữ liệu BIO có thể được tinh chỉnh để giải quyết tám câu hỏi liên quan đến truy xuất kiến thức một phần hoặc kép. Chúng tôi chia N cá nhân đều thành tập huấn luyện Ptrain và tập kiểm tra Ptest. Mô hình được tinh chỉnh bằng cách sử dụng tám tác vụ QA trên cho các cá nhân trong Ptrain và được đánh giá trên độ chính xác tạo sinh ngoài phân phối (OOD) bằng cách kiểm tra phản hồi của nó đối với các câu hỏi cho các cá nhân trong Ptest. Chúng tôi sử dụng tinh chỉnh LoRA [12] để tăng cường hiệu suất, như được đề xuất bởi [2] (xem Phụ lục B để biết chi tiết).

Kết quả 1 (Hình 3 giữa). Truy xuất kép thường dễ dàng khi cả hai tác vụ đều dễ. Tuy nhiên, nếu có mối quan hệ nhân quả và không gian giữa các phần kiến thức, thứ tự của chúng có thể quan trọng. Cụ thể,

• Nếu mô hình ngôn ngữ được tiền huấn luyện trên dữ liệu được tăng cường đầy đủ, như bioS multi5+permute, tạo ra năm mục tiểu sử cho mỗi người và hoán vị sáu câu một cách ngẫu nhiên, độ chính xác cho truy xuất kiến thức kép gần như hoàn hảo.
• Tuy nhiên, nếu dữ liệu tiền huấn luyện thể hiện sự phụ thuộc không gian giữa hai phần kiến thức, thứ tự truy xuất của chúng có thể ảnh hưởng đến độ chính xác. Ví dụ, với bioS multi5+fullname, nơi các mục tiểu sử luôn duy trì cùng một thứ tự (cụ thể, tên công ty luôn đi trước thành phố công ty, và nhớ rằng thành phố công ty được xác định duy nhất bởi tên công ty như được ghi chú trong Chú thích 3), việc trả lời tên công ty trước mang lại độ chính xác gần như hoàn hảo, nhưng việc trả lời thành phố công ty trước làm giảm drastically độ chính xác.

Kết quả 2 (Hình 3 trái). Ngay cả khi một thuộc tính (ví dụ: 2 tháng 10, 1996) có thể được trích xuất hoàn hảo, việc truy xuất một phần chỉ các token sau của nó (ví dụ: năm 1996) vẫn có thể kém.

Cụ thể, mô hình có thể thất bại trong việc trả lời các câu hỏi như "Năm sinh của người Anya là gì", mặc dù trả lời đúng "Ngày sinh của người Anya là gì".

Chúng tôi coi cả hai kết quả như bằng chứng sơ bộ rằng mô hình yêu cầu CoT cho thao tác kiến thức. Ví dụ, trong quá trình suy luận, mô hình phải nêu rõ tháng/ngày sinh trước khi có thể trả lời năm sinh (chúng tôi đã sử dụng định dạng Mỹ "Tháng ngày, năm" trong huấn luyện). Nó không thể "bỏ qua" token để tạo ra trực tiếp kiến thức tiếp theo được học từ tiền huấn luyện.

4 Kết quả 3-6: Phân loại và So sánh Kiến thức

Mục này chứng minh rằng mô hình sinh, mặc dù thành thạo trong việc trích xuất kiến thức, có thể gặp thách thức trong các tác vụ xuôi dòng yêu cầu các phép toán cơ bản để thao tác kiến thức này, trừ khi Chuỗi Suy nghĩ (CoT) được áp dụng trong cả giai đoạn huấn luyện và kiểm tra.

QA phân loại kiến thức. Chúng tôi khám phá các tác vụ phân loại liên quan đến tháng sinh và chuyên ngành của một người. Đối với tháng sinh, chúng tôi sử dụng số học modular với p = 2,6,12:⁷

1. Anya Briar Forger có sinh vào tháng chẵn không? Trả lời: Có.
2. Tháng sinh của Anya Briar Forger mod 6 là gì? Trả lời: 4.
3. Tháng sinh của Anya Briar Forger bằng số là gì? Trả lời: 10.

Đối với chuyên ngành, chúng tôi xem xét 100 chuyên ngành duy nhất và áp dụng số học modular với p = 5,20,100, gán điểm "may mắn" từ 0 đến 99 cho những chuyên ngành này.⁸ Câu hỏi sau đó trở thành "Độ may mắn của chuyên ngành của Anya Briar Forger modulo p là gì?" Phân loại tháng sinh với p = 12 hoặc chuyên ngành với p = 100 là một dạng học chuyển giao, về cơ bản diễn đạt lại định dạng câu hỏi và phản hồi.

QA so sánh kiến thức. Chúng tôi điều tra các tác vụ liên quan đến xếp hạng và trừ dựa trên tháng sinh và chuyên ngành của một người (cũng có ngày sinh trong phụ lục). Các câu hỏi bao gồm:

1. Anya Briar Forger có sinh vào tháng trong năm muộn hơn Sabrina Eugeo Zuberg không? [Có/Không].
2. Tháng sinh của Anya Briar Forger trừ tháng sinh của Sabrina Eugeo Zuberg là gì? [-11..11].
3. Anya Briar Forger có học chuyên ngành may mắn hơn Sabrina Eugeo Zuberg không? [Có/Không].
4. Chuyên ngành của Anya Briar Forger may mắn hơn của Sabrina Eugeo Zuberg bao nhiêu? [-99..99]

Phương pháp. Chúng tôi đánh giá thao tác kiến thức bằng cách sử dụng các mô hình gần như hoàn hảo trong trích xuất kiến thức, đảm bảo mọi khó khăn đều phát sinh từ thao tác chứ không phải trích xuất. Chúng tôi sử dụng các mô hình được tiền huấn luyện trên bộ dữ liệu bioS multi5+permute, có khả năng đạt gần 100% độ chính xác kiểm tra để trích xuất ngày sinh (và do đó tháng sinh) và 98% cho chuyên ngành.

Cụ thể, chúng tôi sử dụng một mô hình được tiền huấn luyện chỉ trên dữ liệu BIO này (mô hình tiền huấn luyện BIO), hoặc một mô hình được tiền huấn luyện BIO + tinh chỉnh QA cho các tác vụ trích xuất kiến thức đơn, như "Ngày sinh của Anya Briar Forger là gì?" (mô hình tinh chỉnh QA). Cho rằng khả năng trích xuất đã được chứng minh của mô hình tinh chỉnh QA, người ta có thể mong đợi nó hoạt động tốt hơn trong thao tác kiến thức.

⁷ Định dạng câu trả lời không quan trọng. Chúng tôi sử dụng định dạng đơn giản nhất như "Trả lời: Có." Chúng tôi cũng đã kiểm tra các định dạng phức tạp hơn như "Anya Briar Forger thực sự sinh vào tháng chẵn" và thêm padding như "Trả lời: dot dot dot dot True" [27]. Không có sự khác biệt đáng chú ý nào trong kết quả được quan sát, vì vậy chúng tôi bỏ qua chúng.
⁸ Ví dụ, Khoa học Máy tính là 0, Truyền thông là 28, và Âm nhạc là 99. Điều này có thể được thay thế bằng, ví dụ, sự phổ biến của các chuyên ngành theo US News trong thực tế.

--- TRANG 7 ---
[Hình 4: Các tác vụ phân loại và so sánh kiến thức trên mô hình tiền huấn luyện BIO so với mô hình tinh chỉnh QA.⁹ Hình này dành cho GPT2 và kết quả cho nhiều tác vụ hơn trong Hình 11. Kết quả cho kiến trúc LLaMA trong Hình 12, và cho Mistral trên bộ dữ liệu 50x lớn hơn với mô hình 5.5x lớn hơn trong Hình 13. Chi tiết trong Phụ lục C.]

⁹ Cột #train individuals cho thấy |Ptrain|. Cột trained w/o hint là khi mô hình được tinh chỉnh trên các tác vụ phân loại/so sánh mà không thêm gợi ý. Khối trained with hint là mô hình được tinh chỉnh với gợi ý được thêm vào với xác suất 0.5. test acc (with hint) và test acc (w/o hint) thể hiện độ chính xác trên Ptest có hoặc không có gợi ý; trong khi hint acc cho thấy độ chính xác tạo gợi ý của mô hình.

Quan sát: (♣) test acc without hint thấp, trừ khi huấn luyện với nhiều mẫu hơn lý thuyết cần thiết - độ chính xác là 1% ngay cả với 2.5 triệu mẫu huấn luyện để so sánh 100 chuyên ngành có thể, xem Hình 13; (♠) thêm gợi ý trong huấn luyện không cải thiện test acc without hint của mô hình; (♢) tinh chỉnh mô hình để trích xuất kiến thức không cải thiện khả năng thao tác của nó.

Huấn luyện không có gợi ý. Dữ liệu BIO của chúng tôi bao gồm các mục tiểu sử cho N = 100k cá nhân. Chúng tôi phân bổ một nửa (tức là 50k) làm tập kiểm tra Ptest, và chọn một tập con riêng biệt Ptrain làm tập huấn luyện, với |Ptrain| = 2.5k, 5k, ..., 50k.

Bắt đầu từ một trong hai mô hình được đề cập ở trên, chúng tôi tiến hành tinh chỉnh LoRA bổ sung bằng cách sử dụng các tác vụ phân loại hoặc so sánh trên, được huấn luyện với các cá nhân từ Ptrain.¹⁰ Sau đó chúng tôi đánh giá độ chính xác tạo sinh ngoài phân phối (OOD) của mô hình bằng cách đánh giá hiệu suất của nó trên cùng tác vụ cho các cá nhân trong Ptest.

Huấn luyện với gợi ý. Để cải thiện khả năng thao tác kiến thức của mô hình, chúng tôi tinh chỉnh nó bằng cách sử dụng gợi ý kiến thức. Những gợi ý này diễn đạt thuộc tính của một người bằng tiếng Anh trước khi trả lời câu hỏi thao tác. Ví dụ, trong các tác vụ của chúng tôi, các câu được gạch chân hoạt động như gợi ý:¹¹

1. Anya Briar Forger có sinh vào tháng trong năm muộn hơn Sabrina Eugeo Zuberg không? Tháng mười; Tháng chín. Không.
2. Chuyên ngành của Anya Briar Forger may mắn hơn của Sabrina Eugeo Zuberg bao nhiêu? Truyền thông; Âm nhạc. -71.
3. Độ may mắn của chuyên ngành của Anya Briar Forger modular 20 là gì? Truyền thông. 8.

Việc bao gồm gợi ý cho phép mô hình áp dụng cách tiếp cận chuỗi suy nghĩ (CoT), cho phép nó trước tiên trích xuất kiến thức cần thiết và sau đó học tác vụ thao tác bằng cách sử dụng trực tiếp kiến thức này. Tương tự như "huấn luyện không có gợi ý", chúng tôi huấn luyện bằng cách sử dụng QA cho các cá nhân trong Ptrain và kiểm tra trên Ptest. Đối với mỗi cá nhân trong Ptrain (hoặc mỗi cặp cho các tác vụ so sánh), chúng tôi bao gồm gợi ý với xác suất 50%. Do đó, mô hình thấy dữ liệu cả có và không có gợi ý. Sau đó chúng tôi đánh giá độ chính xác tạo sinh OOD của mô hình trong cả hai điều kiện.¹² Mục tiêu của chúng tôi là xác định liệu việc thêm dữ liệu huấn luyện CoT có tăng cường kỹ năng thao tác kiến thức của mô hình tại thời điểm suy luận hay không, ngay cả khi không có CoT (♠).

¹⁰ Tinh chỉnh đầy đủ thậm chí còn tệ hơn, tương tự như [2], do đó không được xem xét trong bài báo này.
¹¹ Để có ngữ cảnh, bên cạnh (1.1), chúng tôi kiểm tra một cá nhân khác, Sabrina Eugeo Zuberg, người sinh vào tháng Chín và học chuyên ngành Âm nhạc. Chúng tôi đã gán trước các giá trị may mắn cụ thể cho mỗi chuyên ngành: Truyền thông được đánh giá là 28, trong khi Âm nhạc có giá trị 99.
¹² Trong đánh giá, mô hình chỉ thấy câu hỏi mà không có gợi ý. Chúng tôi thiết kế các token để hướng dẫn mô hình tạo ra gợi ý theo sau bởi câu trả lời (test acc (with hint)), hoặc trả lời trực tiếp (test acc (w/o hint)).

--- TRANG 8 ---
[Hình 5: Phân loại và xếp hạng kiến thức trên WikiBio sử dụng GPT-4. Chi tiết trong Phụ lục E.2.]

Câu hỏi: "Trả lời tôi có hoặc không một cách ngắn gọn: đối với <tên> là <nghề nghiệp> và sinh tại <thành phố> năm <năm>, người này có sinh vào tháng chẵn không?"
GPT4 câu trả lời đúng = 50.7%, câu trả lời sai = 48.5%, Tôi không biết = 0.7%

Phân loại tháng % 2

Câu hỏi: "Trả lời tôi có hoặc không một cách ngắn gọn: <tên1> là <nghề nghiệp1> và sinh tại <thành phố1> có sinh sớm hơn <tên2> là <nghề nghiệp2> và sinh tại <thành phố2> không?"
GPT4 độ chính xác = 52.3% trong số các cá nhân sinh từ 1900~1910
GPT4 độ chính xác = 71.1% trong số các cá nhân sinh từ 1900~1950
GPT4 độ chính xác = 81.6% trong số tất cả cặp cá nhân

"Ngày sinh và năm của <tên> là <nghề nghiệp> và sinh tại <thành phố> là gì?" GPT4 độ chính xác: 99% (trong số 4779 người nổi tiếng trên Wikipedia)

Xếp hạng ngày sinh

Nhìn chung, chúng tôi phát hiện rằng các mô hình gặp khó khăn trong phân loại/so sánh kiến thức trừ khi gợi ý được sử dụng trong cả huấn luyện và kiểm tra. Chúng tôi giải thích điều này tốt hơn trong ba kết quả.

Kết quả 3 (Hình 4, ♣). Không có ví dụ CoT, độ chính xác kiểm tra của mô hình rất thấp, ngay cả đối với các tác vụ thao tác một bước đơn giản nhất.

Cụ thể,
• Xác định xem một tháng có chẵn hay lẻ yêu cầu 10.000 mẫu huấn luyện để đạt 75% độ chính xác, mặc dù về mặt lý thuyết cần độ phức tạp mẫu theo thứ tự O(12) (♣).¹³
• Xếp hạng tháng yêu cầu 50.000 mẫu huấn luyện để đạt 85% độ chính xác kiểm tra, ngay cả với độ phức tạp mẫu lý thuyết O(12²), với điều kiện không có gợi ý (♣).
• Xếp hạng 100 chuyên ngành hầu như không vượt qua ngẫu nhiên ngay cả trong 2.5 triệu mẫu huấn luyện (♣).
• Chỉ "học chuyển giao" (tức là, diễn đạt lại kiến thức) có độ chính xác tốt (xem Hình 11).

Kết quả 4 (Hình 4, ♠). Ngay cả khi các ví dụ CoT được bao gồm trong quá trình huấn luyện, mô hình vẫn gặp khó khăn trong việc trả lời mà không có gợi ý trong quá trình kiểm tra, cho thấy rằng việc bao gồm gợi ý trong huấn luyện không cải thiện độ chính xác thời gian kiểm tra khi gợi ý bị loại bỏ.

Ngược lại, khi mô hình sử dụng gợi ý trong quá trình kiểm tra, độ chính xác cải thiện đáng kể. Độ chính xác tác vụ thao tác phụ thuộc phần lớn vào việc mô hình có thành công trong việc tạo gợi ý trước không.¹⁴

Kết quả 5 (Hình 4, ♢). Sự khác biệt giữa mô hình tiền huấn luyện BIO và mô hình tinh chỉnh QA là tối thiểu đối với các tác vụ thao tác kiến thức xuôi dòng.

Ví dụ, tinh chỉnh mô hình trước để trả lời các câu hỏi như "Anya Briar Forger học chuyên ngành gì" không nhất thiết cải thiện hiệu suất của nó trong các tác vụ xếp hạng/phân loại tương lai dựa trên chuyên ngành.

Ngoài thí nghiệm tổng hợp của chúng tôi, chúng tôi cũng đã nghiên cứu ChatGPT (GPT-4) trong thực tế.

Kết quả 6 (Hình 5). GPT-4 ngoài đời thực cũng gặp khó khăn với phân loại/so sánh kiến thức khi thiếu CoT.

Chúng tôi đã kiểm tra với khoảng 5000 tiểu sử Wikipedia trong Hình 5. Cụ thể, GPT-4 có tỷ lệ chính xác 71.1% khi so sánh ngày sinh của các nhân vật nổi tiếng từ 1900-1950, nhưng điều này giảm xuống 52.3% (gần như đoán ngẫu nhiên) cho 1900-1910, cho thấy mối tương quan với số lượng mẫu trong dữ liệu huấn luyện của nó. Các ví dụ trực quan trong Hình 2, 9, 15 cũng xác nhận điều này, và cho thấy rằng việc thêm CoT có thể khắc phục vấn đề này. Điều này cho thấy rằng việc mở rộng quy mô mô hình có thể không giảm thiểu các vấn đề.

¹³ Đáng chú ý là chúng tôi đã sử dụng tokenizer GPT2, biến đổi 12 tháng thành các token đơn.
¹⁴ Ví dụ: trong tác vụ "birth month classify %2", với độ chính xác gợi ý 91.0%, độ chính xác kiểm tra (với gợi ý) là 94.2%, gần như phù hợp với phép tính: 91.0% + (1 - 91.0%) × 50% = 95.5% (trong đó 50% là độ chính xác đoán ngẫu nhiên). Tương tự, trong tác vụ "birth month subtraction", độ chính xác gợi ý 78.1% dẫn đến độ chính xác kiểm tra (với gợi ý) 61.5%, có thể so sánh với giá trị rút ra từ công thức: 78.1% × 78.1% + (1 - 78.1% × 78.1%) × 8.3% = 64.2% (trong đó 8.3% là độ chính xác đoán ngẫu nhiên).

--- TRANG 9 ---
Quan trọng, phát hiện của chúng tôi khác với hầu hết CoT thông thường được sử dụng trong thực tế để tăng cường kỹ năng toán học hoặc suy luận; ví dụ, GPT-4 có thể bỏ qua một bước tính toán và trả lời trực tiếp liệu tổng của a và b có chẵn không với a, b ∈ [12], mà không viết ra tổng của chúng một cách rõ ràng. Hơn nữa, trọng tâm của chúng tôi ở đây là thao tác kiến thức ngoài ngữ cảnh; nếu người ta quan tâm đến suy luận trong ngữ cảnh thay vào đó, thì các mô hình ngôn ngữ có khả năng tính toán tinh thần nhiều bước suy luận mà không cần viết chúng ra [37].

Một lần nữa, thí nghiệm GPT-4 chỉ được bao gồm cho mục đích minh họa.¹⁵ Chúng tôi tập trung vào thí nghiệm tổng hợp có kiểm soát để nghiên cứu thao tác kiến thức một cách khoa học hơn - ví dụ chúng tôi có thể đưa ra những tuyên bố như (♠), (♣), (♢) bởi vì chúng tôi có thể kiểm soát cách mô hình được huấn luyện.

5 Kết quả 7-9: Tìm kiếm Kiến thức Ngược

Bây giờ chúng tôi cho thấy rằng mô hình sinh thường không thể thực hiện tìm kiếm kiến thức ngược, trừ khi kiến thức đã được tiền huấn luyện theo thứ tự ngược.

Tìm kiếm kiến thức ngược. Các tiểu sử trong bioS luôn bắt đầu bằng tên của người đó, như được hiển thị trong (1.1). Điều này cho phép chúng tôi kiểm tra tìm kiếm kiến thức ngược bằng cách hỏi về tên hoặc họ của cá nhân. Chúng tôi xem xét 10 tác vụ QA như vậy (với tên tác vụ ở bên phải):

• Cho tôi tên [đầu/đầy đủ] của người sinh vào ngày 2 tháng 10, 1996? (bdate_to_first, bdate_to_full)
• Cho tôi tên [đầu/đầy đủ] của người sinh vào ngày 2 tháng 10, 1996 tại Princeton, NJ? (birth_to_first, birth_to_full)
• Cho tôi tên [đầu/đầy đủ] của người học Truyền thông tại Viện Công nghệ Massachusetts và làm việc cho Meta Platforms? (three_to_first, three_to_full)
• Cho tôi tên [đầu/đầy đủ] của người học Truyền thông tại Viện Công nghệ Massachusetts, sinh tại Princeton, NJ, và làm việc cho Meta Platforms? (four_to_first, four_to_full)
• Cho tôi tên [đầu/đầy đủ] của người học Truyền thông tại Viện Công nghệ Massachusetts, sinh vào ngày 2 tháng 10, 1996 tại Princeton, NJ, và làm việc cho Meta Platforms tại Menlo Park, CA? (all_to_first, all_to_full)

(Lưu ý, một số tác vụ tìm kiếm ngược có thể không có câu trả lời duy nhất (ví dụ: bdate_to_full); tuy nhiên, người ta nên mong đợi tìm kiếm ngược thành công ít nhất nên có độ chính xác không tầm thường nào đó.)

[Hình 6: Độ chính xác kiểm tra cho tinh chỉnh QA (trái) và huấn luyện trộn BIO+QA (phải) trong tìm kiếm kiến thức ngược. Đây là cho GPT2 và cùng kết quả đúng cho LLaMA (Hình 14(a)), và cho GPT2/Llama/Mistral trên bộ dữ liệu 50x lớn hơn với kích thước mô hình 5.5x lớn hơn (Hình 14(b)). Kết luận: các mô hình ngôn ngữ không thể thực hiện tìm kiếm ngược, bất kể kích thước mô hình/dữ liệu, huấn luyện, chất lượng dữ liệu/lời nhắc (♡).]

Mỗi hàng là một bộ dữ liệu bioS được tiền huấn luyện tăng cường khác nhau (xem Mục 2). 4 hàng đầu với reverse chỉ ra kiến thức được viết theo thứ tự ngược trong dữ liệu tiền huấn luyện để so sánh (do đó, những hàng này không còn là tìm kiếm kiến thức ngược). Chi tiết trong Phụ lục D.

Phương pháp. Chúng tôi chia N cá nhân đều thành tập huấn luyện Ptrain và tập kiểm tra Ptest. Mô hình được huấn luyện bằng cách sử dụng dữ liệu QA từ Ptrain và được đánh giá trên độ chính xác tạo sinh ngoài phân phối của nó, sử dụng 10 tác vụ tìm kiếm kiến thức ngược trên.

Chúng tôi xem xét hai cách tiếp cận: "tiền huấn luyện BIO + tinh chỉnh QA", tinh chỉnh mô hình tiền huấn luyện BIO bằng cách sử dụng 10 tác vụ trên trên Ptrain, và "huấn luyện trộn BIO+QA", trong đó mô hình được huấn luyện đồng thời trên tất cả dữ liệu BIO và 10 tác vụ trên Ptrain. Theo Mục 2, huấn luyện trộn mang lại độ chính xác tạo sinh tốt hơn trong các tác vụ trích xuất kiến thức ban đầu.

Ngoài 16 bộ dữ liệu bioS (được tăng cường kiến thức riêng biệt, xem Mục 2), chúng tôi giới thiệu 4 bộ dữ liệu nữa:

• bioS multi5+reverse1, trong trường hợp này chúng tôi di chuyển tên đầy đủ của người đó đến câu thứ hai.
• bioS multi5+reverse2, trong trường hợp này chúng tôi di chuyển tên đầy đủ của người đó đến câu thứ ba.
• bioS multi5+reverse6, chúng tôi di chuyển tên đầy đủ của người đó đến cuối mục tiểu sử.
• bioS multi5+permute+reverse6, trong trường hợp này trên bioS multi5+reverse6 chúng tôi cũng hoán vị ngẫu nhiên sáu câu.

• Người đó sinh vào ngày 2 tháng 10, 1996. Anya Briar Forger đã trải qua những năm đầu đời tại Princeton, NJ ... (bioS multi5+reverse1)
• Người đó sinh vào ngày 2 tháng 10, 1996. Cô đã trải qua những năm đầu đời tại Princeton, NJ. Anya Briar Forger ... (bioS multi5+reverse2)
• Người đó sinh vào ngày 2 tháng 10, 1996. Cô đã trải qua những năm đầu đời tại Princeton, NJ ... Tên của người đó là Anya Briar Forger. (bioS multi5+reverse6)
• Người đó đã trải qua những năm đầu đời tại Princeton, NJ. [... 4 câu khác theo thứ tự ngẫu nhiên...] Cô có vai trò chuyên môn tại Meta Platforms. Tên của người đó là Anya Briar Forger. (bioS multi5+permute+reverse6)

Phát hiện chính của chúng tôi là:

Kết quả 7 (Hình 6, ♡). Các mô hình có độ chính xác gần bằng không để tìm kiếm kiến thức ngược trong Ptest, ngay cả đối với tác vụ đơn giản nhất all_to_first, ngay cả với cách tiếp cận huấn luyện trộn BIO+QA, và ngay cả với tăng cường kiến thức dữ liệu tiền huấn luyện mạnh.¹⁶

Ngược lại, chỉ khi thứ tự kiến thức thực sự được đảo ngược trong dữ liệu tiền huấn luyện, trình bày một số thuộc tính trước lần xuất hiện đầu tiên của tên một người, độ chính xác kiểm tra mới cải thiện. Điều này chỉ để minh họa; một khi thứ tự được đảo ngược, tác vụ không còn là tìm kiếm kiến thức ngược.

Tóm lại, những phát hiện của chúng tôi nhấn mạnh một hạn chế cơ bản của các mô hình ngôn ngữ sinh: chúng không thể thực hiện tìm kiếm kiến thức ngược, điểm dừng. Điều này là do thiết kế huấn luyện tự hồi quy từ trái sang phải của nó. Nếu mô hình học "A bằng B" thì nó không thể suy ra "B bằng A" trừ khi nó cũng có trong dữ liệu huấn luyện. Một mô hình hai chiều như BERT không thể giảm thiểu vấn đề này, bởi vì nó gặp phải các vấn đề nghiêm trọng hơn ngay cả trong trường hợp trích xuất kiến thức đơn thuận [2].¹⁷

Chúng tôi cũng đã thử nghiệm GPT-3.5/4 trong thực tế và phát hiện:

Kết quả 8 (Hình 7). GPT-3.5/4 cũng thể hiện khó khăn lớn với tìm kiếm kiến thức ngược.

Ví dụ, trong khi GPT-4 có thể dự đoán câu tiếp theo trong Pride and Prejudice của Jane Austen với độ chính xác 65.9%, nó chỉ có 0.8% độ chính xác để dự đoán câu trước đó. Một lần nữa, những thí nghiệm này được bao gồm cho mục đích minh họa - ngay cả nếu GPT-4 có thể trả lời những câu hỏi như vậy, vẫn không rõ liệu GPT-4 đã thấy chúng trong quá trình tiền huấn luyện hay không. Thí nghiệm tổng hợp có kiểm soát của chúng tôi không chỉ loại bỏ khả năng như vậy mà còn cung cấp tuyên bố mạnh mẽ như (♡).

¹⁶ Ví dụ, trong dữ liệu bioS multi5+permute+fullname, chúng tôi bao gồm năm mục tiểu sử đa dạng cho mỗi cá nhân, với tên đầy đủ ở phía trước trong mỗi câu, và xáo trộn ngẫu nhiên tất cả các câu.
¹⁷ Các mô hình kiểu BERT đã gặp khó khăn với trích xuất kiến thức (thuận) do bản chất mô hình ngôn ngữ mask từ toàn bộ (MLM) - chứ đừng nói đến thao tác kiến thức. Ví dụ, tên công ty "Meta Platforms" sẽ khiến BERT tương quan nhúng của "Meta" với "Platform", thay vì liên kết thông tin công ty với tên đầy đủ của cá nhân. Để biết chi tiết hơn, xem [2].

--- TRANG 10 ---
[Hình 7: Tìm kiếm thuận so với tìm kiếm ngược trên ChatGPT (GPT3.5 / GPT-4); chi tiết trong Phụ lục E.1.]

(Trong khi tìm kiếm ngược có thể dường như thách thức ngay cả đối với con người, chúng tôi đã thiết kế các tác vụ thành ngữ/thơ Trung Quốc được cho là đơn giản đối với nhiều sinh viên trung học trong giáo dục Trung Quốc.)

Tìm kiếm ngược: "Trong <Pride and Prejudice>, câu trước <sentence2> là gì?"
Tìm kiếm thuận: "Trong <Pride and Prejudice>, câu sau <sentence1> là gì?"

Pride & Prejudice | Sense & Sensibility | Persuasion | Northanger Abbey | Emma | Mansfield Park
độ chính xác thuận vs ngược bởi GPT3.5: 0.5% vs 14.4% | 0.3% vs 5.4% | 0.07% vs 4.3% | 0.6% vs 5.5% | 0.8% vs 7.2% | 0.7% vs 5.5%
độ chính xác thuận vs ngược bởi GPT4: 0.8% vs 65.9% | 0.9% vs 40.2% | 0.5% vs 33.9% | 0.9% vs 41.0% | 0.6% vs 42.7% | 0.3% vs 31.7%

Tác vụ Tiểu thuyết Jane Austen

Tìm kiếm ngược: "Tên đầy đủ của người nổi tiếng sinh vào <ngày> tại <thành phố> là <nghề nghiệp> là gì?" GPT3.5 acc = 23.9% GPT4: 42%
Tìm kiếm thuận: "Ngày sinh và năm của <tên> là <nghề nghiệp> và sinh tại <thành phố> là gì?" GPT3.5 acc = 89.5% GPT4: 99%

Tác vụ Wiki Bio

Cho một thành ngữ Trung Quốc 4 chữ phổ biến như 指鹿为马, che đi chữ thứ i (với i=1,2,3, hoặc 4) và để GPT điền chữ còn thiếu.
Prompt 1: 成语 "X鹿为马" 的X是什么字？ GPT3.5 độ chính xác 9.4%, GPT4 độ chính xác 17.6%
Prompt 2: 成语 "指X为马" 的X是什么字？ GPT3.5 độ chính xác 29.5%, GPT4 độ chính xác 36.1%
Prompt 3: 成语 "指鹿X马" 的X是什么字？ GPT3.5 độ chính xác 32.0%, GPT4 độ chính xác 76.7%
Prompt 4: 成语 "指鹿为X" 的X是什么字？ GPT3.5 độ chính xác 56.7%, GPT4 độ chính xác 90.6%

Tác vụ Thành ngữ Trung Quốc

Cho một bài thơ Trung Quốc hai câu nổi tiếng như 劝君更尽一杯酒, 西出阳关无故人, để GPT trả lời câu trước/sau <sentence 2/1> là gì
Tìm kiếm ngược: "西出阳关无故人" 的上一句是什么？ GPT3.5 độ chính xác 2.1%, GPT4 độ chính xác 7.3%
Tìm kiếm thuận: "劝君更尽一杯酒" 的下一句是什么？ GPT3.5 độ chính xác 33.0%, GPT4 độ chính xác 66.5%

Tác vụ Thơ Trung Quốc

Sử dụng CoT cho tìm kiếm ngược. Chúng tôi quan sát rằng GPT-4 có thể xác định một câu Kinh thánh đứng trước câu khác thông qua CoT: trước tiên nó tạo ra số câu (ví dụ: 9:5), sau đó trừ 1 (ví dụ: viết ra 9:4), và truy xuất văn bản đầy đủ của câu (xem Hình 8). Khả năng này bắt nguồn từ sự phong phú của dữ liệu Kinh thánh trên internet có các con số xuất hiện cả trước và sau chúng. Do đó,

[Hình 8: Cách GPT-4 sử dụng CoT để thực hiện tìm kiếm kiến thức ngược trên tác vụ Kinh thánh.]

Kết quả 9. Để cải thiện tìm kiếm ngược các tài liệu quan trọng bởi LLM, không chỉ chúng ta có thể sử dụng RAG [17] hoặc tiền xử lý dữ liệu huấn luyện để bao gồm kiến thức ngược (xem Hình 6-trên, hoặc thực tế thông qua lời nhắc "viết lại"), chúng ta cũng có thể giới thiệu số dòng (xem Hình 8).

Chúng tôi đã phát triển một bài báo tiếp theo đề xuất phương pháp nhẹ để tiền xử lý dữ liệu tiền huấn luyện để chèn kiến thức ngược [9].

6 Kết luận

Trong bài báo này, chúng tôi sử dụng các thí nghiệm có kiểm soát để cho thấy một số hạn chế cơ bản của các mô hình ngôn ngữ để thao tác kiến thức trong thời gian suy luận ngay cả dưới thiết lập tiền huấn luyện mạnh nhất, bất kể kích thước mô hình, kích thước dữ liệu, v.v. Nghiên cứu của chúng tôi làm sáng tỏ lý do tại sao các mô hình ngôn ngữ cực lớn như GPT-4 vẫn kém trong ngay cả thao tác kiến thức một bước đơn giản nhất, và đưa ra những phản ví dụ đơn giản đáng ngạc nhiên (xem Hình 2, Hình 9). Mặt khác, các mô hình ngôn ngữ đơn giản không thể thực hiện tìm kiếm kiến thức ngược, cho thấy chúng không thể được sử dụng như cơ sở dữ liệu.

Trong khi bài báo này tiết lộ rằng các kỹ thuật mới là cần thiết để cải thiện cơ bản khả năng thao tác kiến thức của mô hình ngôn ngữ, các biện pháp giảm thiểu ngay lập tức cũng có thể. Điều này bao gồm tạo ra thêm dữ liệu CoT (Mục 4) và sử dụng các phương pháp như tăng cường sinh ngữ cảnh (RAG) [17] và huấn luyện đảo ngược [9, 10, 21] để hỗ trợ tìm kiếm ngược, hoặc dự đoán đa token [8] để hỗ trợ truy xuất một phần. Chúng tôi cũng đề xuất viết lại tài liệu huấn luyện để bao gồm dữ liệu đảo ngược (Mục 5) và giới thiệu số dòng tài liệu (Mục 5) để tăng cường khả năng tìm kiếm ngược. Những chiến lược này có thể thông tin cho việc phát triển các mô hình ngôn ngữ quy mô công nghiệp trong tương lai.

Cuối cùng, Phần 3 của loạt nghiên cứu này tập trung vào cách các mô hình ngôn ngữ lưu trữ, trích xuất và thao tác kiến thức (bao gồm Phần 3.1 [2] và Phần 3.3 [3]). Chúng tôi cũng bao gồm toán học cấp tiểu học và suy luận trong Phần 2 [37, 38], và học cấu trúc ngôn ngữ phân cấp trong Phần 1 [1].

[Hình 9: Ngay cả tính đến ngày 8 tháng 5, 2024, GPT-4 và Llama-3 vẫn thất bại trong các tác vụ phân loại kiến thức đơn giản (trái), so sánh kiến thức (giữa) và tìm kiếm ngược (phải).]

--- TRANG 11 ---
Phụ lục

A Chi tiết hơn về Chuẩn bị Dữ liệu

Allen-Zhu và Li [2] đã giới thiệu một họ dữ liệu tiểu sử tổng hợp bioS và một họ dữ liệu "gần với thực tế" bioR. Để hoàn chỉnh, chúng tôi cung cấp một tóm tắt nhanh dưới đây. Chúng tôi chủ yếu sử dụng bioS để trình bày kết quả tiêu cực do thứ tự kiến thức có thể kiểm soát của nó. Đối với kết quả tích cực, cụ thể là cho truy xuất kiến thức một phần/kép, chúng tôi cũng sử dụng bioR.

A.1 Bộ dữ liệu BIO bioS

Trong bộ dữ liệu tổng hợp được gắn nhãn là bioS, người ta tạo ra hồ sơ cho N cá nhân. Tên, tên đệm và họ của mỗi cá nhân, ngày sinh, thành phố sinh, đại học theo học, chuyên ngành, và công ty làm việc được chọn độc lập và ngẫu nhiên từ phân phối đều, từ 400, 400, 1000, 200 × 12 × 28, 200, 300, 100, 263 lựa chọn tương ứng. Ngoài ra, thuộc tính 'thành phố công ty' hoàn toàn phụ thuộc vào vị trí trụ sở chính của công ty làm việc tại Mỹ. Ví dụ, một nhân viên của Meta sẽ liệt kê Menlo Park, CA là thành phố công ty của họ. Đáng chú ý, 13.7% các công ty có trụ sở tại New York, NY nên mặc định là New York, NY cho độ chính xác cơ sở 13.7% khi dự đoán thành phố làm việc của một người.

Trong bộ dữ liệu bioS, một mục tiểu sử của một cá nhân bao gồm sáu câu. Mỗi câu làm sáng tỏ một thuộc tính riêng biệt của cá nhân này. Để tăng tính đa dạng, mỗi câu được chọn ngẫu nhiên từ một tập hợp ~50 mẫu được xác định trước. Ngoài (1.1), chúng tôi dán một số ví dụ từ bài báo của họ:

Carlos Jameson Stokes có lễ kỷ niệm hàng năm vào ngày 12 tháng 11, 2088. Anh ấy kỷ niệm sinh nhật của mình tại San Francisco, CA. Anh ấy tốt nghiệp từ Đại học Bang Oklahoma. Anh ấy khám phá các khía cạnh lý thuyết của Hệ thống Thông tin. Anh ấy đóng góp chuyên môn của mình cho United Airlines Holdings. Anh ấy thu thập kiến thức ngành trong khi làm việc tại Chicago, IL.

Alondra Bennett Rooney kỷ niệm hành trình cuộc sống của họ mỗi năm vào ngày 1 tháng 4, 1909. Họ có nguồn gốc từ Durham, NC. Họ được hưởng lợi từ các nguồn lực và tiện nghi được cung cấp bởi Đại học Nam Alabama. Họ phát triển nền tảng vững chắc trong Khoa học Dữ liệu. Họ có công việc tại The Southern Company. Họ tham gia vào ngành công nghiệp của Atlanta, GA.

Aidan Alexa Dennis có ngày sinh được kỷ niệm hàng năm vào ngày 17 tháng 7, 1968. Cô ấy gọi Palmdale, CA là nơi sinh của mình. Cô ấy chuyên môn trong lĩnh vực nghiên cứu tại Viện Công nghệ Stevens. Cô ấy hoàn thành chương trình nghiêm ngặt trong Kinh doanh Quốc tế. Cô ấy có triển vọng việc làm tại Johnson & Johnson. Cô ấy có được kinh nghiệm làm việc tại New Brunswick, NJ.

Trong cấu hình cơ bản, có một mục tiểu sử duy nhất cho mỗi cá nhân, duy trì thứ tự nhất quán cho sáu câu như được nêu ở trên. Cấu hình này được ký hiệu là "bioS single." Trong [2], họ đã đi sâu vào 15 tăng cường kiến thức:

• bioS single+fullname: Đại từ được thay thế bằng tên đầy đủ của người đó.
• bioS single+permute1/2/5: Sáu câu trong mục tiểu sử được hoán vị ngẫu nhiên 1/2/5 lần cho mỗi người. Tuy nhiên, tên đầy đủ chỉ xuất hiện trong câu đầu tiên, với các câu tiếp theo sử dụng đại từ. Điều này dẫn đến 1/2/5 mục tiểu sử cho mỗi người.
• bioS single+permute1/2/5+fullname: Như với tăng cường trước, nhưng tên đầy đủ được sử dụng trong tất cả sáu câu.
• bioS multi2/5: 2 hoặc 5 mục tiểu sử được tạo cho mỗi người, với mỗi lần tạo sử dụng một tập hợp mẫu câu được lấy mẫu lại.
• bioS multi2/5+permute: Dựa trên bioS multi2/5, sáu câu trong mỗi mục tiểu sử được hoán vị ngẫu nhiên. Tuy nhiên, tên đầy đủ chỉ xuất hiện một lần trong câu đầu tiên.
• bioS multi2/5+fullname: Dựa trên bioS multi2/5, đại từ được thay thế bằng tên đầy đủ của cá nhân trong tất cả các câu.
• bioS multi2/5+permute+fullname: Kết hợp các tính năng từ cả bioS multi2/5+permute và bioS multi2/5+fullname, đại từ được thay thế bằng tên đầy đủ của cá nhân và sáu câu được hoán vị ngẫu nhiên.

Allen-Zhu và Li [2] đã sử dụng N = 100.000, và điều này sau đó được tổng quát hóa để hỗ trợ N lên đến 20.000.000 trong [3].

Phần chính của chúng tôi sử dụng N = 100.000 nhưng chúng tôi cũng trình bày kết quả đối với N = 1,2,5 triệu - được ký hiệu là bioS (10x, 20x, 50x) tương ứng. Trong những bộ dữ liệu lớn hơn này, chúng tôi đã tuân theo [3] để xem xét tăng cường kiến thức đầy đủ (được ký hiệu là multi∞+permute). Điều này có nghĩa là mỗi người được tăng cường đầy đủ để có 50^6 × 6 cách viết khác nhau về tiểu sử của họ.

Nhận xét A.1. Dữ liệu bioS(50x) multi∞+permute này đặc biệt hữu ích cho chúng tôi để trình bày kết quả tiêu cực (như trong Hình 13 và Hình 14(b)), bởi vì ngay cả khi dữ liệu được chuẩn bị tốt để bao gồm rất nhiều tăng cường kiến thức khác nhau, kết quả tiêu cực vẫn áp dụng.

A.1.1 Thêm Kiến thức Ngược

Trong bài báo này, trong Mục 5 khi xem xét tìm kiếm kiến thức ngược, chúng tôi cũng đã giới thiệu một vài tăng cường kiến thức phụ trợ cho mục đích so sánh:

• bioS multi5+reverse1, trong trường hợp này chúng tôi di chuyển tên đầy đủ của người đó đến câu thứ hai:
Người đó sinh vào ngày 2 tháng 10, 1996. Anya Briar Forger đã trải qua những năm đầu đời tại Princeton, NJ ...

• bioS multi5+reverse2, trong trường hợp này chúng tôi di chuyển tên đầy đủ của người đó đến câu thứ ba:
Người đó sinh vào ngày 2 tháng 10, 1996. Cô đã trải qua những năm đầu đời tại Princeton, NJ. Anya Briar Forger ...

• bioS multi5+reverse6, chúng tôi di chuyển tên đầy đủ của người đó đến cuối mục tiểu sử:
Người đó sinh vào ngày 2 tháng 10, 1996. Cô đã trải qua những năm đầu đời tại Princeton, NJ ... Tên của người đó là Anya Briar Forger.

• bioS multi5+permute+reverse6, trong trường hợp này trên bioS multi5+reverse6 chúng tôi cũng hoán vị ngẫu nhiên sáu câu. Đây là một ví dụ.
Người đó đã trải qua những năm đầu đời tại Princeton, NJ. [... 4 câu khác theo thứ tự ngẫu nhiên...] Cô có vai trò chuyên môn tại Meta Platforms. Tên của người đó là Anya Briar Forger.

A.2 Bộ dữ liệu BIO bioR

Chúng tôi cũng kiểm tra bộ dữ liệu bioR được sản xuất bằng cách nhắc LLaMA [35, 39] viết dữ liệu tiểu sử gần với thực tế cho N = 100.000 cá nhân trước đó. Dưới đây chúng tôi dán một số ví dụ từ bài báo của họ:

Nicole Kevin Pratt là một giám đốc điều hành doanh nghiệp người Mỹ. Cô hiện là Phó Chủ tịch Dịch vụ Kinh doanh Toàn cầu P&G tại Procter & Gamble. Cô sinh ngày 25 tháng 1, 1977, tại Baltimore, Maryland. Cô tốt nghiệp từ Đại học Haverford với bằng Quản lý. P&G đã tuyển dụng cô làm Trợ lý Quản lý Thương hiệu năm 2000. Cô đã giữ các vị trí lãnh đạo khác nhau trong quản lý thương hiệu, tiếp thị, và bán hàng trên các đơn vị kinh doanh và danh mục khác nhau. Cô được bổ nhiệm làm Phó Chủ tịch Dịch vụ Kinh doanh Toàn cầu P&G năm 2019. Nicole hiện sống tại Cincinnati, Ohio với chồng và ba con.

Hunter Bennett Kenny là một sinh viên tốt nghiệp khoa học chính trị tài năng từ Đại học Queens, Đại học Thành phố New York. Anh có nguồn gốc từ Augusta, Georgia và sinh ngày 25 tháng 3, 2033. Trong thời gian học đại học, anh là thành viên tích cực của hội sinh viên và làm chủ tịch vào năm cuối. Anh đã thực tập tại văn phòng của Thượng nghị sĩ New York Chuck Schumer. Sau khi tốt nghiệp loại giỏi, anh làm việc cho Kohl's tại Menomonee Falls, Wisconsin. Anh hiện sống tại Brooklyn, New York.

Johnathan Charles Wade là một đại lý bảo hiểm thành công làm việc cho Allstate. Anh sinh ngày 7 tháng 1, 2098, tại Thành phố New York, NY. Anh tốt nghiệp từ Đại học Bang Colorado, nơi anh học chuyên ngành Xã hội học. Anh hiện sống tại Northbrook, IL.

Trong cấu hình cơ bản, có một mục tiểu sử duy nhất cho mỗi người, được ký hiệu là "bioR single." Để so sánh, chúng tôi cũng xem xét tăng cường multiM của họ, tạo ra M mục cho mỗi người, và tăng cường fullname.

B Chi tiết hơn về Truy xuất Kiến thức

Nhớ lại từ Mục 3 rằng chúng tôi đã kiểm tra hai tác vụ truy xuất kiến thức một phần, liên quan đến việc trích xuất ngày sinh hoặc năm sinh của một người từ thông tin ngày sinh đầy đủ. Chúng tôi cũng xem xét sáu tác vụ truy xuất kiến thức kép liên quan đến việc trích xuất đồng thời hai thuộc tính của một người.

Theo [2], chúng tôi ban đầu sử dụng một checkpoint mô hình tiền huấn luyện BIO và sau đó áp dụng tinh chỉnh LoRA lên trên nó, sử dụng các văn bản QA của tám tác vụ nói trên cho một nửa số cá nhân (được ký hiệu bởi Ptrain).¹⁸ Sau đó chúng tôi trình bày độ chính xác tạo sinh ngoài phân phối của nó để trả lời tám tác vụ đó trên các cá nhân còn lại (được ký hiệu bởi Ptest).

Chúng tôi đã sử dụng cùng các checkpoint tiền huấn luyện BIO từ [2].¹⁹

Trong tinh chỉnh LoRA, như được mô tả bởi [12], người ta chọn các ma trận trọng số nhất định W^(d×k) trong transformer và áp dụng một cập nhật hạng r lên trên: W' ← W + αAB với A ∈ R^(d×r) và B ∈ R^(r×k) cho một số nhỏ r. Ở đây, α là một hằng số, và cả A và B đều là tham số có thể huấn luyện.²⁰ Đáng chú ý, B được khởi tạo với Gaussian và A được khởi tạo với số không.

Dựa trên [12], chúng tôi đã áp dụng một cập nhật hạng thấp cho các ma trận truy vấn/giá trị trong mỗi lớp transformer. Để tính đến sự thay đổi phân phối đầu vào (từ dữ liệu BIO sang dữ liệu QA), chúng tôi cũng áp dụng một cập nhật hạng thấp cho lớp nhúng. Chúng tôi sử dụng cập nhật hạng 8 hoặc 16 cho các ma trận truy vấn/giá trị và cập nhật hạng 128 cho lớp nhúng, trình bày độ chính xác tốt nhất từ hai lần chạy.²¹

Chúng tôi sử dụng trình tối ưu hóa AdamW với ε = 10^(-6). Sự suy giảm trọng số được đặt ở 0.01, với tỷ lệ học ban đầu là 0.0003. Chúng tôi không sử dụng khởi động, và chúng tôi thực hiện lập lịch tỷ lệ học cosine (giảm xuống 10% tỷ lệ học ban đầu). Kích thước lô được đặt ở 48 với tổng cộng 50.000 bước huấn luyện. Chúng tôi đã sử dụng hỗn hợp GPU V100/A100 cho thí nghiệm nhưng loại GPU không liên quan đến thí nghiệm của chúng tôi.

• Kết quả cho dữ liệu bioS N = 100k (trên GPT2 12 lớp, 12 đầu, 768-dim) được trình bày trong Hình 3.
• Kết quả cho dữ liệu bioR N = 100k (trên GPT2 12 lớp, 20 đầu, 1280-dim) được trình bày trong Hình 10(a).
• Kết quả cho dữ liệu bioS N = 100k (trên Llama 12 lớp, 12 đầu, 768-dim) được trình bày trong Hình 10(b).
• Kết quả cho dữ liệu bioR N = 100k (trên Llama 12 lớp, 20 đầu, 1280-dim) được trình bày trong Hình 10(c).
• Kết quả cho dữ liệu bioR (10x, 20x, 50x) được trình bày trong Hình 10(d), cụ thể:

¹⁸ Tinh chỉnh LoRA đã được chứng minh là lựa chọn tốt hơn so với tinh chỉnh đầy đủ, vì nó ngăn chặn việc quá khớp và mang lại độ chính xác kiểm tra QA cao hơn. Một so sánh chi tiết có thể được tìm thấy trong [2].
¹⁹ Chúng được thu thập bằng cách sử dụng AdamW với suy giảm trọng số 0.1, ε = 10^(-6), tỷ lệ học ban đầu 0.001, khởi động tuyến tính 1000 bước, và suy giảm tỷ lệ học cosine (giảm xuống 0.0001). Nó được huấn luyện bằng cách sử dụng kích thước lô 96 với 80.000 bước (cho bioS) hoặc với 150.000 bước (cho bioR). Nhớ lại kích thước cửa sổ ngữ cảnh là 512. Chúng tôi sử dụng beam = 4 mà không lấy mẫu cho việc tạo sinh mô hình (và kết quả tương tự nếu tắt beam).
²⁰ Trong bài báo này, chúng tôi chọn α = 4. Lựa chọn này chỉ ảnh hưởng đến tỷ lệ học và không yêu cầu điều chỉnh. [12]
²¹ Thực vậy, Allen-Zhu và Li [2] chỉ ra rằng một cập nhật hạng r lớn cho các ma trận truy vấn/giá trị không quan trọng. Tuy nhiên, một cập nhật hạng r' lớn trên lớp nhúng có lợi để giải quyết sự thay đổi phân phối đầu vào.

--- TRANG 12 ---
– GPT2(2x), Llama(2x), Mistral(2x) là các kiến trúc 6 lớp, 24 đầu, 1536-dim. Chúng lớn hơn khoảng 2x so với GPT2 nhỏ.
– GPT2(5.5x), Llama(5.5x), Mistral(5.5x) là các kiến trúc 24 lớp, 20 đầu, 1280-dim. Chúng lớn hơn khoảng 5.5x so với GPT2 nhỏ.²²

Nhận xét B.1. Khi sử dụng các kiến trúc Llama và Mistral, chúng tôi cũng đã áp dụng tokenizer gốc của chúng. Đáng chú ý là tokenizer của GPT2 chuyển đổi các năm (ví dụ: 19xx) và ngày thành các token đơn, trong khi tokenizer Llama/Mistral coi chúng là bốn token riêng biệt. Điều này giải thích cho những khác biệt nhất định trong độ chính xác truy xuất một phần cho ngày sinh và năm sinh.

²² Các phiên bản thương mại của Llama/Mistral lớn hơn những phiên bản này và chúng tôi đã giảm kích thước chúng cho mục đích của chúng tôi. Đối với Mistral, chúng tôi đã sử dụng attention truy vấn nhóm với 4 nhóm.

--- TRANG 13 ---
[Hình 10: Truy xuất một phần (trái) và kép (giữa) kiến thức, so với trích xuất kiến thức đơn (phải). Để mô tả các bộ dữ liệu (hàng), xem Phụ lục A; để biết kiến trúc và chi tiết huấn luyện, xem Phụ lục B.]

(a) giống như Hình 3 nhưng cho GPT2 trên các bộ dữ liệu bioR

(b) giống như Hình 3 nhưng cho Llama trên các bộ dữ liệu bioS

(c) giống như Hình 3 nhưng cho Llama trên các bộ dữ liệu bioR

(d) giống như Hình 3 nhưng cho các mô hình GPT2/Llama/Mistral lớn hơn trên các bộ dữ liệu bioS 10x đến 50x lớn hơn

Lưu ý: Không giống như các tác vụ QA ngoài đời thực, thí nghiệm tổng hợp của chúng tôi được huấn luyện và tinh chỉnh trên dữ liệu sạch đầy đủ trong thời gian đủ, làm cho việc tăng kích thước mô hình thêm nữa thường không cần thiết; kết quả tương tự thường được mong đợi.

C Chi tiết hơn về Phân loại và So sánh Kiến thức

Nhớ lại từ Mục 4 rằng chúng tôi lấy một mô hình được huấn luyện trên dữ liệu BIO được tăng cường đầy đủ bioS multi5+permute; nó hoặc đơn giản là được tiền huấn luyện BIO, được ký hiệu là M, hoặc đã được tinh chỉnh QA trên sáu tác vụ QA trích xuất kiến thức, được ký hiệu là M'.²³ Chúng tôi tiếp tục phân tích hiệu suất của chúng trong thao tác kiến thức, đặc biệt là trong các tác vụ phân loại hoặc so sánh được xây dựng trên các thuộc tính kiến thức nhất định.

Xem xét so sánh kiến thức như một ví dụ. Chúng tôi kiểm tra hai loại huấn luyện. Một loại bao gồm việc tinh chỉnh trực tiếp M hoặc M' bằng cách sử dụng QA tác vụ thao tác, như

Anya Briar Forger có sinh vào tháng trong năm muộn hơn Sabrina Eugeo Zuberg không? Không.

Phương pháp này được gọi là "huấn luyện không có gợi ý". Một lần nữa, chúng tôi chia N cá nhân thành hai nửa Ptrain và Ptest, áp dụng tinh chỉnh LoRA bằng cách sử dụng QA cho các cặp cá nhân trong Ptrain, và kiểm tra độ chính xác tạo sinh ngoài phân phối của nó trên QA cho các cặp cá nhân trong Ptest. Chúng tôi sử dụng beam = 4 mà không lấy mẫu cho việc tạo sinh mô hình (và kết quả tương tự nếu tắt beam). Những kết quả này được hiển thị trong cột "test acc" của Hình 4 và 11.

Loại huấn luyện khác bao gồm việc tinh chỉnh M hoặc M' bằng cách sử dụng QA tác vụ thao tác với việc thêm gợi ý, được minh họa dưới đây:

Anya Briar Forger có sinh vào tháng trong năm muộn hơn Sabrina Eugeo Zuberg không? Tháng mười; Tháng chín. Không.

Phương pháp này cho phép mô hình trích xuất kiến thức có liên quan, sau đó học cách thao tác kiến thức này một cách trực tiếp. Chúng tôi gọi đây là "huấn luyện với gợi ý", và chúng tôi lại thực hiện tinh chỉnh LoRA bằng cách sử dụng QA trên các cặp cá nhân trong Ptrain. Đối với mỗi cặp cá nhân, gợi ý được thêm vào với xác suất 50%; do đó, trong quá trình tinh chỉnh LoRA, mô hình thấy QA thao tác kiến thức cả có và không có gợi ý. Độ chính xác tạo sinh ngoài phân phối của mô hình sau đó được kiểm tra trên QA cho các cá nhân trong Ptest, một lần nữa có hoặc không có gợi ý. Những kết quả này được hiển thị trong các cột "test acc (with hint)" và "test acc (w/o hint)" của Hình 4 và 11.

Ngoài ra, chúng tôi ghi lại độ chính xác của mô hình trong việc tạo gợi ý chính xác cho mỗi cá nhân. Thông tin này được trình bày trong cột "hint acc" của Hình 4 và 11.

Tham số. Mô hình tiền huấn luyện BIO M và mô hình tinh chỉnh QA M' được sao chép trực tiếp từ [2]. Chúng được thu thập bằng cách sử dụng cùng tham số AdamW như được mô tả trong Phụ lục B. Trong suốt thí nghiệm cho cả "huấn luyện không có / có gợi ý", chúng tôi sử dụng chiến lược tinh chỉnh LoRA với cập nhật hạng 16 trên các ma trận truy vấn/giá trị và cập nhật hạng 128 trên lớp nhúng. Ngoài ra, chúng tôi sử dụng trình tối ưu hóa AdamW với ε = 10^(-6). Sự suy giảm trọng số được đặt ở 0.01, và tỷ lệ học ban đầu là 0.001. (Đối với thí nghiệm Mistral lớn hơn, xem dưới đây, chúng tôi sử dụng tỷ lệ học ban đầu 0.0003 để có kết quả tốt hơn.) Chúng tôi không sử dụng khởi động, nhưng chúng tôi thực hiện lập lịch tỷ lệ học cosine, giảm xuống 10% tỷ lệ học ban đầu. Kích thước lô được đặt ở 48 với tổng cộng 50.000 bước huấn luyện.

Tất cả kết quả. Đối với kiến trúc GPT2 (12 lớp, 12 đầu, 768-dim), chúng tôi trình bày kết quả đầy đủ trong Hình 11, và một tập hợp chọn lọc của chúng trong Hình 4 trong phần chính. Lưu ý rằng không chỉ chúng tôi đã bao gồm thêm các tác vụ phân loại/xếp hạng/trừ trong Hình 11, mà chúng tôi cũng đã thêm các tác vụ xếp hạng/trừ trên thuộc tính ngày sinh, như "Có phải [tên1] sinh vào ngày trong tháng muộn hơn [tên2] không?" Người ta có thể lưu ý rằng không giống như tháng sinh hoặc chuyên ngành, kiến thức về "ngày sinh" chỉ có thể được truy xuất với độ chính xác kiểm tra kém hoàn hảo hơn là 82.3%. Do đó, người ta nên mong đợi rằng ngay cả khi có gợi ý được thêm vào, độ chính xác xếp hạng/trừ kiến thức vẫn có thể xa hoàn hảo. Xem hai hàng cuối trong Hình 4.

Chúng tôi lặp lại cùng thí nghiệm này cho Llama (12 lớp, 12 đầu, 768-dim) trong Hình 12 và thấy kết quả gần như giống hệt.

²³ Tinh chỉnh QA này cũng được thực hiện bằng cách tận dụng tinh chỉnh LoRA với hạng 8 trên các ma trận truy vấn/giá trị và hạng 128 trên lớp nhúng.

--- TRANG 14 ---
[Hình 11: Phiên bản mở rộng của thí nghiệm GPT2 trong Hình 4, để đưa ra nhiều ví dụ hơn về các tác vụ phân loại và so sánh kiến thức.]

Sau đó chúng tôi nhắm đến một kết quả mạnh hơn bằng cách sử dụng Mistral (24 lớp, 20 đầu, 1280-dim) trong Hình 13 cho bộ dữ liệu bioS (50x) (có N = 5 triệu cá nhân và thậm chí tăng cường dữ liệu tối đa, xem Nhận xét A.1). Tuy nhiên, mô hình vẫn không có khả năng học cách so sánh hai chuyên ngành (trong số 100 khả năng) khi được tinh chỉnh với hơn 2.5 triệu mẫu - xem Hình 13.

--- TRANG 15 ---
[Hình 12: Thí nghiệm lặp lại của Hình 11 nhưng sử dụng kiến trúc Llama cùng kích thước.]

[Hình 13: Thí nghiệm lớn hơn Hình 11, sử dụng kiến trúc Mistral lớn hơn 5.5x và dữ liệu huấn luyện 50x. Quan sát: Độ chính xác của so sánh kiến thức không có CoT vẫn thấp đáng kể trừ khi sử dụng bộ dữ liệu tinh chỉnh rất lớn. Ví dụ, tác vụ trừ hai chuyên ngành (chúng tôi có 100 chuyên ngành, được đánh số từ 0 đến 99) không thể được thực hiện tốt hơn đoán ngẫu nhiên ngay cả sau khi cung cấp 2.5 triệu ví dụ tinh chỉnh. Thêm CoT giảm đáng kể số lượng mẫu cần thiết.]

D Chi tiết hơn về Tìm kiếm Kiến thức Ngược

Trong Mục 5, chúng tôi kiểm tra 10 tác vụ tìm kiếm kiến thức ngược, yêu cầu tên hoặc họ của một người dựa trên (một phần hoặc tất cả) thuộc tính của họ. Chúng tôi xem xét họ dữ liệu bioS với tất cả các lựa chọn tăng cường kiến thức như được thảo luận trong Phụ lục A.1.

Tương tự như truy xuất kiến thức được nêu trong Phụ lục B, với một checkpoint mô hình tiền huấn luyện BIO, chúng tôi áp dụng tinh chỉnh LoRA lên trên nó. Chúng tôi thực hiện điều này bằng cách sử dụng các văn bản QA của 10 tác vụ tìm kiếm kiến thức ngược cho một nửa số cá nhân và kiểm tra độ chính xác tạo sinh ngoài phân phối của nó để trả lời những QA đó trên nửa còn lại. Chúng tôi sử dụng cùng cài đặt LoRA và tối ưu hóa như được thảo luận trong Phụ lục B, cụ thể là hạng 8 hoặc 16 cho các ma trận truy vấn/giá trị và hạng 128 cho lớp nhúng, tỷ lệ học ban đầu 0.0003, trong số các tham số khác. Chúng tôi lại sử dụng beam = 4 mà không lấy mẫu cho việc tạo sinh mô hình (và kết quả tương tự nếu tắt beam).

Hơn nữa, vì chúng tôi đang trình bày một kết quả tiêu cực, chúng tôi cũng xem xét huấn luyện trộn BIO+QA. Cụ thể, chúng tôi huấn luyện mô hình bằng cách sử dụng cả dữ liệu BIO từ tất cả các cá nhân và cũng dữ liệu QA tìm kiếm kiến thức ngược từ một nửa số họ. Để đơn giản, mỗi chuỗi huấn luyện 512 token đến hoàn toàn từ các mục BIO hoặc hoàn toàn từ các mục QA (từ các cá nhân được lấy mẫu ngẫu nhiên, được nối bằng token <EOS>). Chúng tôi giới thiệu một tham số QAr để kiểm soát tần suất sử dụng các mục QA. Cả QAr = 0.5 và QAr = 0.8 đều được kiểm tra, và chúng tôi trình bày kết quả tốt hơn của hai lựa chọn. Chúng tôi đánh giá độ chính xác tạo sinh của mô hình bằng cách sử dụng các câu hỏi tìm kiếm kiến thức ngược từ nửa còn lại của các cá nhân.²⁴

Kết quả của chúng tôi cho kiến trúc GPT2 (12 lớp, 12 đầu, 768-dim) trong Hình 6. Sau đó chúng tôi lặp lại cùng thí nghiệm này cho kiến trúc Llama (12 lớp, 12 đầu, 768-dim) và tokenizer Llama trong Hình 14(a), và cùng kết quả đúng. Chúng tôi tiếp tục tăng kích thước mô hình và bộ dữ liệu (theo cách tương tự như Phụ lục B) và quan sát kết quả gần như giống hệt trong Hình 14(b).

²⁴ Như được chỉ ra trong [2], người ta suy ra rằng QAr = 0.8 (cụ thể, tỷ lệ 2:8 giữa các mục BIO và QA về số lượng token tiền huấn luyện) là lựa chọn tốt cho huấn luyện trộn. Tuy nhiên, trong ngữ cảnh tìm kiếm kiến thức ngược, độ dài trung bình của QA có xu hướng dài hơn so với QA trích xuất kiến thức gốc. Vì lý do này, chúng tôi cũng khám phá lựa chọn thay thế QAr = 0.5 để tính đến sự khác biệt này.

--- TRANG 16 ---
[Hình 14: Chúng tôi lặp lại Hình 6 nhưng với nhiều/lớn hơn kiến trúc và bộ dữ liệu lớn hơn. Để mô tả các bộ dữ liệu (hàng), xem Phụ lục A; để biết kiến trúc và chi tiết huấn luyện, xem Phụ lục D.]

(a) Giống như Hình 6 nhưng sử dụng kiến trúc Llama cùng kích thước.

(b) Sử dụng GPT2/Llama/Mistral có kích thước lớn hơn và dữ liệu lớn hơn.

Lưu ý: Không giống như các tác vụ QA ngoài đời thực, thí nghiệm tổng hợp của chúng tôi được huấn luyện và tinh chỉnh trên dữ liệu sạch đầy đủ trong thời gian đủ, làm cho việc tăng kích thước mô hình thêm nữa thường không cần thiết; kết quả tương tự thường được mong đợi.

E Chi tiết hơn về Thí nghiệm ChatGPT

Tất cả các thí nghiệm của chúng tôi trên GPT-3.5 / GPT-4 được thực hiện từ tháng 6 đến tháng 9 năm 2023 bằng cách sử dụng các mô hình mới nhất gpt-3.5-turbo và gpt-4 tại thời điểm đó.

E.1 Tìm kiếm Kiến thức Ngược

Trong Hình 7 trong Mục 5, chúng tôi lập luận rằng ngay cả các mô hình ngôn ngữ khổng lồ như GPT-3.5/GPT-4 cũng hoạt động kém trong tìm kiếm kiến thức ngược. Chúng tôi xem xét bốn tác vụ như vậy.

Tác vụ tiểu thuyết Jane Austen. Chúng tôi chọn các cặp câu liên tiếp trong sáu tiểu thuyết của Jane Austen, và để GPT-3.5/4 tạo ra câu tiếp theo/trước đó dựa trên câu kia trong cặp. Ở đây, việc tạo ra câu trước đó có thể được coi là tìm kiếm kiến thức ngược, và việc tạo ra câu tiếp theo có thể được coi là tìm kiếm kiến thức thuận.

Chi tiết hơn, chúng tôi chỉ chọn những cặp câu liên tiếp khi cả hai đều có từ 50 đến 300 ký tự (để chúng tôi bỏ qua những câu ngắn như "Tên anh ấy là gì?"). Sau khi lọc này, chúng tôi xem xét:

• 2873 cặp câu trong Pride and Prejudice, trong số 5909 câu;
• 2296 cặp câu trong Sense and Sensibility, trong số 4897 câu;
• 2730 cặp câu trong Persuasion, trong số 3634 câu;
• 1446 cặp câu trong Northanger Abbey, trong số 3655 câu;
• 3234 cặp câu trong Emma, trong số 8477 câu;
• 2730 cặp câu trong Mansfield Park, trong số 6907 câu.

Sau đó chúng tôi hỏi GPT3.5/4, "Trong [tên sách], câu trước/sau: [câu] là gì?"

Tác vụ WikiBio. Chúng tôi sử dụng bộ dữ liệu wikibio [16], chứa các tiểu sử của các cá nhân được trích xuất từ Wikipedia. Mục tiêu của chúng tôi là để GPT3.5/4 xác định tên người dựa trên giá trị thuộc tính của họ.

Bộ dữ liệu wikibio bao gồm 582.659 cá nhân. Chúng tôi trước tiên chỉ chọn những cá nhân có ngày sinh, nơi sinh, nghề nghiệp, và ngày mất được chỉ định đầy đủ. Điều này dẫn đến tổng cộng 33.617 cá nhân. Sau đó chúng tôi truy vấn GPT-3.5 một lần với lời nhắc "Trả lời ngắn gọn: ngày sinh và năm của [tên] là [nghề nghiệp] và sinh tại [nơi sinh] là gì?" và chọn 4.779 cá nhân có ngày sinh có thể được trả lời chính xác. Điều này đảm bảo rằng chúng tôi chỉ xem xét những cá nhân mà GPT-3.5 rõ ràng đã gặp trong quá trình tiền huấn luyện.

Cuối cùng, chúng tôi kiểm tra 4.779 cá nhân này bằng cách sử dụng GPT-3.5 hoặc GPT-4 với câu hỏi tìm kiếm ngược "tên đầy đủ của người nổi tiếng sinh vào [ngày] tại [thành phố] là [nghề nghiệp] là gì?" hoặc câu hỏi tìm kiếm thuận "ngày sinh và năm của [tên] là [nghề nghiệp] và sinh tại [thành phố] là gì?" Chúng tôi gán điểm 1 nếu câu trả lời hoàn toàn chính xác, và điểm 0.5 nếu câu trả lời chỉ chính xác một phần.²⁵

Tác vụ Thành ngữ Trung Quốc. Chúng tôi chuẩn bị danh sách 2.244 thành ngữ Trung Quốc bốn chữ thường được sử dụng trong cả văn bản nói và viết. Chúng tôi che một trong bốn chữ trong mỗi thành ngữ và yêu cầu GPT3.5/4 điền vào chữ bị che. Trong tác vụ này, việc tạo ra chữ đầu tiên dựa trên ba chữ còn lại được coi là tìm kiếm kiến thức ngược. Đây là một vài ví dụ về các thành ngữ mà chúng tôi đã sử dụng:

1.实事求是;2.引人注目;3.成千上万;4.当务之急;5.一如既往; ... 2243. 秉公守法;2244.等闲置之

Chúng tôi chọn sử dụng tiếng Trung vì các thành ngữ có độ dài bằng nhau về ký tự, làm cho việc tính toán độ chính xác trên mỗi ký tự trở nên dễ dàng. Một cá nhân Trung Quốc bình thường có trình độ trung học nên có thể đạt độ chính xác hơn 80% khi trả lời ký tự đầu tiên dựa trên ba ký tự khác.

Tác vụ Thơ Trung Quốc. Chúng tôi chuẩn bị danh sách 233 cặp câu thơ Trung Quốc thường được sử dụng trong tiếng Trung viết. Chúng tôi che câu thứ nhất hoặc thứ hai và yêu cầu GPT-3.5/GPT-4 hoàn thành câu kia. Chúng tôi cung cấp một vài ví dụ về các cặp câu thơ dưới đây:

1.两岸猿声啼不住，轻舟已过万重山 2.感时花溅泪，恨别鸟惊心...
... 232.千山鸟飞绝，万径人踪灭 233.东边日出西边雨，道是无晴却有晴

Các tác vụ khác. Mặc dù chúng tôi chỉ trình bày bốn tác vụ liên quan đến tìm kiếm kiến thức ngược, chúng tôi cũng đã thử nghiệm với một vài tác vụ khác không được bao gồm trong bài báo. Chúng tôi đề cập đến những tác vụ này dưới đây để có lợi cho những độc giả quan tâm.

• Chúng tôi đã kiểm tra một tập hợp rộng hơn các bài thơ Trung Quốc (ít được sử dụng thường xuyên hơn) và 154 sonnet của Shakespeare (bao gồm 14 dòng thơ mỗi bài). Tuy nhiên, chúng tôi thấy rằng ChatGPT không rất có khả năng thực hiện ngay cả tìm kiếm thuận trên những tác vụ như vậy. Do đó, dường như ít thuyết phục hơn để kiểm tra hiệu suất của ChatGPT trên các tác vụ tìm kiếm ngược tương ứng.

• Chúng tôi cũng đã kiểm tra ChatGPT trên Kinh thánh, yêu cầu nó xác định câu đứng trước mỗi câu trong cùng chương. Chúng tôi thấy rằng ChatGPT có khả năng thực hiện tác vụ này, thường với Chuỗi Suy nghĩ (CoT).

Cụ thể, nhớ rằng các câu trong Kinh thánh được đánh số đúng (ví dụ: "Gen 15:18" đề cập đến Sáng thế ký, chương 15, câu 18), và các số có thể xuất hiện đôi khi trước và đôi khi sau câu. Điều này cho phép ChatGPT xác định số chương/câu cho một câu nhất định (kiến thức thuận), thực hiện phép toán "trừ 1" (chuỗi suy nghĩ), và sau đó xác định câu bằng cách sử dụng số mới này (kiến thức thuận).

Nói cách khác, chúng tôi tin rằng tác vụ yêu cầu câu đứng trước mỗi câu trong Kinh thánh thực sự được ChatGPT thực hiện thông qua tìm kiếm kiến thức thuận + CoT. Đó không thực sự là tác vụ tìm kiếm kiến thức ngược.

E.2 Phân loại và So sánh Kiến thức

Đối với phân loại và so sánh kiến thức, chúng tôi một lần nữa sử dụng nhóm 4779 cá nhân được chọn từ bộ dữ liệu WikiBio (tham khảo Mục E.1). Sau đó chúng tôi thực hiện các tác vụ sau trên GPT-4:

• "Trả lời tôi có hoặc không một cách ngắn gọn: đối với [tên] là [nghề nghiệp] và sinh tại [thành phố] năm [năm], người này có sinh vào tháng chẵn không?"

Chúng tôi đặt câu hỏi này cho mỗi cá nhân trong nhóm 4779 người. Độ chính xác cơ sở cho đoán ngẫu nhiên trong tác vụ này là 50%.

• "Trả lời tôi có hoặc không một cách ngắn gọn: [tên1] là [nghề nghiệp1] và sinh tại [thành phố1] có sinh sớm hơn [tên2] là [nghề nghiệp2] và sinh tại [thành phố2] không?"

Chúng tôi đặt câu hỏi này cho 1000 cặp cá nhân được chọn ngẫu nhiên từ nhóm 4779 cá nhân sinh (1) từ 1900-1910, (2) từ 1900-1950, hoặc (3) bất kỳ năm nào. Độ chính xác cơ sở cho đoán ngẫu nhiên trong ba tác vụ này là: 54.5%, 51.0%, và 50% tương ứng.

²⁵ Nếu chỉ có tên hoặc họ đúng, chúng tôi gán điểm 0.5. Nếu chỉ có năm sinh đúng, hoặc nếu cả tháng sinh và ngày đúng nhưng năm sai, chúng tôi cũng gán điểm 0.5.

--- TRANG 17 ---
Lưu ý rằng trong tất cả các trường hợp, chúng tôi đã thêm tiền tố "trả lời tôi có hoặc không một cách ngắn gọn" vào các câu hỏi để buộc mô hình trả lời trực tiếp bằng Có hoặc Không mà không tạo gợi ý trước. Chúng tôi trình bày kết quả trong Hình 5.

Ngoài thí nghiệm trên WikiBio ở trên, chúng tôi cũng trình bày một số ví dụ QA ngoài đời thực để minh họa sự cần thiết của Chuỗi Suy nghĩ (CoT). Chúng tôi yêu cầu GPT-4 cho chúng tôi biết liệu tháng/ngày/năm sinh của một số chính trị gia có chẵn hay không, cũng như so sánh ngày sinh của một số chính trị gia. Từ phản hồi trong Hình 15, rõ ràng là GPT-4 có thể dễ dàng mắc lỗi khi không sử dụng gợi ý (tức là khi trả lời có/không mà không nêu ngày sinh của chính trị gia trước), nhưng có khả năng sửa những lỗi như vậy một khi CoT được sử dụng.

[Hình 15: Mở rộng cho Hình 2. Hình này cung cấp các ví dụ bổ sung minh họa khó khăn của GPT-4 trong việc trả lời các câu hỏi thao tác đơn giản dựa trên thuộc tính của một người trong quá trình suy luận, mặc dù có kiến thức cần thiết. Tuy nhiên, khi sử dụng cách tiếp cận Chuỗi Suy nghĩ (CoT), trong đó thuộc tính của người được nêu rõ, GPT-4 có thể trả lời chính xác các tác vụ thao tác.]

Tài liệu tham khảo

[1] Zeyuan Allen-Zhu and Yuanzhi Li. Physics of Language Models: Part 1, Learning Hierarchical Language Structures. ArXiv e-prints, abs/2305.13673, May 2023. Phiên bản đầy đủ có sẵn tại http://arxiv.org/abs/2305.13673.

[2] Zeyuan Allen-Zhu and Yuanzhi Li. Physics of Language Models: Part 3.1, Knowledge Storage and Extraction. In ICML, 2024. Phiên bản đầy đủ có sẵn tại http://arxiv.org/abs/2309.14316.

[3] Zeyuan Allen-Zhu and Yuanzhi Li. Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws. ArXiv e-prints, abs/2404.05405, April 2024. Phiên bản đầy đủ có sẵn tại http://arxiv.org/abs/2404.05405.

[4] Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A". arXiv preprint arXiv:2309.12288, September 2023.

[5] Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, and Samuel Weinbach. GPT-NeoX-20B: An open-source autoregressive language model. In Proceedings of the ACL Workshop on Challenges & Perspectives in Creating Large Language Models, 2022. URL https://arxiv.org/abs/2204.06745.

[6] Deng Cai, Yan Wang, Lemao Liu, and Shuming Shi. Recent advances in retrieval-augmented text generation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 3417–3419, 2022.

[7] Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346–361, 2021.

[8] Fabian Gloeckle, Badr Youbi Idrissi, Baptiste Rozière, David Lopez-Paz, and Gabriel Synnaeve. Better & faster large language models via multi-token prediction. arXiv preprint arXiv:2404.19737, 2024.

[9] Olga Golovneva, Zeyuan Allen-Zhu, Jason Weston, and Sainbayar Sukhbaatar. Reverse training to nurse the reversal curse. arXiv preprint arXiv:2403.13799, 2024.

[10] Qingyan Guo, Rui Wang, Junliang Guo, Xu Tan, Jiang Bian, and Yujiu Yang. Mitigating reversal curse via semantic-aware permutation training. arXiv preprint arXiv:2403.00758, 2024.

[11] Evan Hernandez, Belinda Z Li, and Jacob Andreas. Measuring and manipulating knowledge representations in language models. arXiv preprint arXiv:2304.00740, 2023.

[12] Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. LoRA: Low-Rank Adaptation of Large Language Models. In ICLR, 2021.

[13] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.

[14] Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. Active retrieval augmented generation. arXiv preprint arXiv:2305.06983, 2023.

[15] Mojtaba Komeili, Kurt Shuster, and Jason Weston. Internet-augmented dialogue generation. arXiv preprint arXiv:2107.07566, 2021.

[16] Rémi Lebret, David Grangier, and Michael Auli. Generating text from structured data with application to the biography domain. CoRR, abs/1603.07771, 2016. URL http://arxiv.org/abs/1603.07771.

[17] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. Retrieval-augmented generation for knowledge-intensive nlp tasks. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 9459–9474. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf.

[18] Shangqing Liu, Yu Chen, Xiaofei Xie, Jingkai Siow, and Yang Liu. Retrieval-augmented generation for code summarization via hybrid gnn. arXiv preprint arXiv:2006.05405, 2020.

[19] Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, and Weizhu Chen. Generation-augmented retrieval for open-domain question answering. arXiv preprint arXiv:2009.08553, 2020.

[20] Tahira Naseem, Srinivas Ravishankar, Nandana Mihindukulasooriya, Ibrahim Abdelaziz, Young-Suk Lee, Pavan Kapanipathi, Salim Roukos, Alfio Gliozzo, and Alexander Gray. A semantics-aware transformer model of relation linking for knowledge base question answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 256–262, Online, August 2021. Association for Computational Linguistics.

[21] Anh Nguyen, Nikos Karampatziakis, and Weizhu Chen. Meet in the middle: A new pre-training paradigm. Advances in Neural Information Processing Systems, 36, 2024.

[22] Reham Omar, Omij Mangukiya, Panos Kalnis, and Essam Mansour. Chatgpt versus traditional question answering for knowledge graphs: Current status and future directions towards knowledge graph chatbots. arXiv preprint arXiv:2302.06466, 2023.

[23] OpenAI. Gpt-4 technical report, 2023.

[24] Md Rizwan Parvez, Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. Retrieval augmented code generation and summarization. arXiv preprint arXiv:2108.11601, 2021.

[25] Hao Peng, Xiaozhi Wang, Shengding Hu, Hailong Jin, Lei Hou, Juanzi Li, Zhiyuan Liu, and Qun Liu. Copen: Probing conceptual knowledge in pre-trained language models. arXiv preprint arXiv:2211.04079, 2022.

[26] Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and Sebastian Riedel. Language models as knowledge bases? arXiv preprint arXiv:1909.01066, 2019.

[27] Jacob Pfau, William Merrill, and Samuel R Bowman. Let's think dot by dot: Hidden computation in transformer language models. arXiv preprint arXiv:2404.15758, 2024.

[28] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

[29] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. In-context retrieval-augmented language models. arXiv preprint arXiv:2302.00083, 2023.

[30] Kyle Richardson and Ashish Sabharwal. What does my QA model know? devising controlled probes using expert knowledge. Transactions of the Association for Computational Linguistics, 8:572–588, 2020. doi: 10.1162/tacl_a_00331. URL https://aclanthology.org/2020.tacl-1.37.

[31] Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language models encode clinical knowledge. arXiv preprint arXiv:2212.13138, 2022.

[32] Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Tharindu Kaluarachchi, Rajib Rana, and Suranga Nanayakkara. Improving the domain adaptation of retrieval augmented generation (rag) models for open domain question answering. Transactions of the Association for Computational Linguistics, 11:1–17, 2023.

[33] Jianlin Su, Yu Lu, Shengfeng Pan, Bo Wen, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding, 2021.

[34] Kai Sun, Yifan Ethan Xu, Hanwen Zha, Yue Liu, and Xin Luna Dong. Head-to-tail: How knowledgeable are large language models (llm)? aka will llms replace knowledge graphs? arXiv preprint arXiv:2308.10168, 2023.

[35] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.

[36] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824–24837, 2022.

[37] Tian Ye, Zicheng Xu, Yuanzhi Li, and Zeyuan Allen-Zhu. Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process. arXiv preprint arXiv:xxxx.xxxxx, 2024. to appear.

[38] Tian Ye, Zicheng Xu, Yuanzhi Li, and Zeyuan Allen-Zhu. Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems. arXiv preprint arXiv:xxxx.xxxxx, 2024. to appear.

[39] Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. Lima: Less is more for alignment. arXiv preprint arXiv:2305.11206, 2023.

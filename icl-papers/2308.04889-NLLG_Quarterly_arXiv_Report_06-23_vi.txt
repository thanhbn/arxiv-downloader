# 2308.04889.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl-papers/2308.04889.pdf
# Kích thước tệp: 1011245 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Báo cáo arXiv Quý của NLLG 06/23:
Những bài báo AI có ảnh hưởng nhất hiện tại là gì?
Steffen Eger, Christoph Leiter, Jonas Belouadi
Ran Zhang, Aida Kostikova, Daniil Larionov, Yanran Chen, Vivian Fresen
Nhóm Học Tập Ngôn Ngữ Tự Nhiên (NLLG), https://nl2g.github.io/
Tóm tắt
Sự tăng trưởng nhanh chóng của thông tin trong lĩnh vực Trí tuệ Nhân tạo Sinh tạo (AI), đặc biệt là trong các lĩnh vực con Xử lý Ngôn ngữ Tự nhiên (NLP) và Học máy (ML), đặt ra một thách thức đáng kể cho các nhà nghiên cứu và những người thực hành để theo kịp những phát triển mới nhất. Để giải quyết vấn đề quá tải thông tin, báo cáo này của Nhóm Học Tập Ngôn Ngữ Tự Nhiên tại Đại học Bielefeld tập trung vào việc xác định những bài báo phổ biến nhất trên arXiv, với sự nhấn mạnh cụ thể vào NLP và ML. Mục tiêu là cung cấp một hướng dẫn nhanh về nghiên cứu có liên quan nhất và được thảo luận rộng rãi nhất, hỗ trợ cả những người mới bắt đầu và các nhà nghiên cứu đã thành lập trong việc theo kịp các xu hướng hiện tại. Đặc biệt, chúng tôi biên soạn danh sách 40 bài báo phổ biến nhất dựa trên số lượng trích dẫn chuẩn hóa từ nửa đầu năm 2023. Chúng tôi quan sát sự thống trị của các bài báo liên quan đến Mô hình Ngôn ngữ Lớn (LLM) và cụ thể là ChatGPT trong nửa đầu năm 2023, tuy nhiên với ChatGPT đang cho thấy dấu hiệu giảm sút mức độ phổ biến gần đây. Hơn nữa, các bài báo liên quan đến NLP có ảnh hưởng nhất (khoảng 60% bài báo hàng đầu) mặc dù có gấp đôi số lượng bài báo liên quan đến ML trong dữ liệu của chúng tôi. Các vấn đề cốt lõi được điều tra trong những bài báo được trích dẫn nhiều nhất là: hiệu quả LLM, kỹ thuật đánh giá, cân nhắc đạo đức, tác nhân hiện thân, và giải quyết vấn đề với LLM. Ngoài ra, chúng tôi kiểm tra đặc điểm của các bài báo hàng đầu so với những bài khác ngoài danh sách top-40 (nhận thấy sự tập trung của bài báo hàng đầu vào các vấn đề liên quan đến LLM và số lượng đồng tác giả cao hơn) và phân tích phân phối trích dẫn trong tập dữ liệu của chúng tôi, cùng với những điều khác.

1 Giới thiệu
Trong thời đại dòng thông tin ngày càng gia tăng, việc theo kịp lũ dữ liệu và đầu ra nghiên cứu áp đảo là một nhiệm vụ đáng sợ. Điều này đặc biệt đúng trong bối cảnh sự quan tâm lớn của công chúng hiện tại (và thậm chí là sự phổ biến) xung quanh AI Sinh tạo, với các bài báo được phổ biến trong các khoảng thời gian ngày càng ngắn hơn. Báo cáo này, được xuất bản bởi Nhóm Học Tập Ngôn Ngữ Tự Nhiên (https://nl2g.github.io/) tại Đại học Bielefeld, nhằm mục đích giảm bớt vấn đề quá tải thông tin, dù chỉ ở mức độ nhỏ, bằng cách xác định những bài báo phổ biến nhất hiện tại trên arXiv (https://arxiv.org/), đặc biệt tập trung vào các lĩnh vực con AI là xử lý ngôn ngữ tự nhiên (NLP) và học máy (ML) như một số lĩnh vực nghiên cứu được thảo luận sôi nổi nhất, bao gồm cả trong truyền thông chính thống. Ý định của chúng tôi là cung cấp cho những người thực hành, người mới, và người dùng AI, từ các lĩnh vực liên quan và không liên quan (ví dụ: khoa học xã hội hoặc nhân văn số) một hướng dẫn nhanh về những bài báo phổ biến nhất và có thể liên quan nhất để hiểu rõ hơn và (nhanh hơn) nắm bắt các phát triển hiện tại.

--- TRANG 2 ---
Chúng tôi đặc biệt nhấn mạnh vào việc khám phá arXiv, với tính chất là một kho lưu trữ tiền xuất bản toàn diện và cực kỳ phổ biến. Đáng chú ý, quy trình xuất bản nhanh chóng của arXiv cung cấp một lợi thế riêng biệt so với các hội nghị và tạp chí truyền thống, đảm bảo rằng nghiên cứu mới nhất trở nên dễ dàng tiếp cận với cộng đồng khoa học với tốc độ nhanh hơn nhiều.

Báo cáo này được cấu trúc như sau. Trong Phần 2, chúng tôi nêu ra phương pháp luận của chúng tôi, hoàn toàn đơn giản: chúng tôi chọn các bài báo từ arXiv từ nửa đầu năm 2023 và sắp xếp chúng theo số lượng trích dẫn chuẩn hóa. Trong Phần 3, chúng tôi trình bày và thảo luận danh sách 40 bài báo phổ biến nhất - về số lượng trích dẫn chuẩn hóa - từ tập dữ liệu arXiv của chúng tôi. Trong Phần 4, chúng tôi cung cấp một phân tích về tập dữ liệu arXiv liên quan đến phân phối trích dẫn, các danh mục arXiv liên quan, đặc điểm của các bài báo hàng đầu, và mức độ phổ biến của các khái niệm 'phổ biến' như ChatGPT và mô hình ngôn ngữ lớn (LLM) theo thời gian. Trong Phần 5, chúng tôi kết luận.

Trong số những phát hiện chính của chúng tôi là: (i) NLP, từng là một lĩnh vực nghiên cứu ngách, hiện có ảnh hưởng lớn hơn đáng kể so với ML về số lượng trích dẫn mà nó thu hút: mặc dù có gấp đôi số lượng bài báo ML trong tập dữ liệu của chúng tôi, ∼60% các bài báo được trích dẫn cao nhất là từ NLP; (ii) các bài báo liên quan đến LLM và ChatGPT rõ ràng đã thống trị nửa đầu năm 2023, nhưng đặc biệt ChatGPT hiện đang suy giảm; (iii) mô hình mã nguồn mở hiệu quả LLaMA từ Meta AI là bài báo được trích dẫn nhiều nhất tương đối và tuyệt đối trong tập dữ liệu của chúng tôi, để lại phía sau ChatGPT và GPT-4 lớn hơn và độc quyền.

Mã và dữ liệu của chúng tôi có sẵn từ https://github.com/NL2G/Quaterly-Arxiv.

2 Phương pháp luận
Để xác định những bài báo có ảnh hưởng nhất từ các lĩnh vực con AI NLP và ML, chúng tôi đã sử dụng phương pháp luận sau.

Tên tập dữ liệu Kích thước Thời gian # Danh mục Chính
arxiv-0623 20.843 01/01/2023-06/31/2023 123
arxiv-0623-top40 40 01/01/2023-06/31/2023 5

Bảng 1: Thống kê cơ bản về hai tập dữ liệu được phát hành của chúng tôi. Kích thước là số lượng bài báo trong mỗi tập dữ liệu; cột cuối cùng cho số lượng danh mục arXiv chính riêng biệt mà các bài báo của chúng tôi được gán vào.

1. Thu thập Dữ liệu từ arXiv: Chúng tôi thu thập tất cả các bài báo từ 01/01/2023 đến 06/31/2023 thuộc về các danh mục arXiv cs.CL (tính toán và ngôn ngữ) và cs.LG (học máy) bằng cách sử dụng API arXiv của Python. Thời gian thu thập của chúng tôi là ngày 29 tháng 7 năm 2023 (điều này quan trọng, vì số lượng trích dẫn liên tục trong trạng thái biến động). Các bài báo arXiv có thể thuộc về nhiều danh mục. Chúng tôi chỉ yêu cầu một trong các danh mục liên quan là một trong hai danh mục đã chỉ ra.

2. Tính toán z-score: Đối với mỗi bài báo, chúng tôi trích xuất số lượng trích dẫn của nó, như một thước đo mức độ phổ biến và có thể là tầm quan trọng [1], từ Semantic Scholar https://www.semanticscholar.org/. Vì các bài báo được xuất bản vào các thời điểm khác nhau có thể tự nhiên có số lượng trích dẫn khác nhau (ví dụ, các bài báo cũ hơn có cơ hội cao hơn được trích dẫn so với các bài báo rất mới), chúng tôi tính toán số lượng trích dẫn chuẩn hóa bằng cách xác định một bài báo nằm bao nhiêu độ lệch chuẩn trên trung bình trích dẫn của tất cả các bài báo được xuất bản trong cùng một tuần (Chủ nhật-Thứ bảy). Đây là cái gọi là z-score của Newman [23]:

zt = ct - mean(c(t)) / std(c(t))

cho một bài báo được xuất bản trong tuần t với số lượng trích dẫn ct; c(t) là danh sách số lượng trích dẫn của tất cả các bài báo được xuất bản trong tuần t. Nếu một bài báo nằm vài độ lệch chuẩn trên trung bình (cho tất cả các bài báo được xuất bản trong cùng một tuần), nó có thể được coi là xuất sắc trong lớp của nó. Ví dụ, trong phân phối bình thường, chỉ khoảng 16% điểm dữ liệu nằm một độ lệch chuẩn trên giá trị trung bình. Như sẽ thấy bên dưới, các bài báo hàng đầu của chúng tôi nằm ít nhất 9-12 độ lệch chuẩn trên trung bình.

3. Đánh giá Thủ công Ngày xuất bản trên arXiv có thể khác với ngày xuất bản/phát hành/nộp thực tế đầu tiên của một bài báo, ví dụ, khi các tác giả tải bài báo lên arXiv muộn hơn nhiều. Do đó, chúng tôi tiến hành đánh giá thủ công để xác minh xem một bài báo có thực sự xuất hiện lần đầu tiên như được chỉ ra bởi dấu thời gian phát hành arXiv hay không. Nếu bài báo có sẵn sớm hơn, chúng tôi loại bỏ nó khỏi xem xét.

Các bước 1 và 2+3 ở trên dẫn đến hai tập dữ liệu riêng biệt mà chúng tôi phát hành cùng với báo cáo này. Chúng tôi gọi chúng là arxiv-0623 và arxiv-0623-top40. Bảng 1 cung cấp thống kê cơ bản về mỗi tập dữ liệu.

3 Các bài báo Top N
Bảng 2 trình bày 20 bài báo hàng đầu được trích xuất theo phương pháp luận được mô tả trong Phần 2. Chúng tôi thực hiện một số quan sát thú vị:

• 13 trong số 20 (65%) bài báo có cs.CL là danh mục arXiv chính của chúng (lưu ý rằng tác giả của các bài báo có thể muốn chỉ ra nhiều danh mục bổ sung như họ mong muốn). cs.LG là danh mục chính 3 lần, tiếp theo là cs.CV (thị giác máy tính; 2 lần) và cs.CR (mật mã học) và cs.AI (mỗi danh mục 1 lần).

• Số lượng trích dẫn tuyệt đối thay đổi đáng kể, với 14 là số thấp nhất trong danh sách top-20 của chúng tôi cho một bài báo được xuất bản vào cuối tháng 5 (Large Language Models are not Fair Evaluators [30]) và 874 là con số cao nhất cho bài báo LLaMA [28] được xuất bản vào cuối tháng 2. Số lượng trích dẫn tương đối thay đổi từ 12 độ lệch chuẩn trên trung bình đến 28 độ lệch chuẩn trên trung bình.

--- TRANG 3 ---
chúng tôi không bao gồm cs.AI (không có cs.LG hoặc cs.CL) nhưng chúng tôi lưu ý rằng danh sách top-40 của chúng tôi sẽ trông rất

--- TRANG 4 ---
[Bảng 2 chứa danh sách 20 bài báo hàng đầu với số thứ tự, tiêu đề, danh mục, liên kết, tuần, số trích dẫn và z-score]

--- TRANG 5 ---
[Bảng 3 chứa danh sách các bài báo từ 21-40 với thông tin tương tự]

--- TRANG 6 ---
• Bốn bài báo thống trị có thể được xem là báo cáo kỹ thuật về các mô hình nền tảng LLM, bao gồm LLaMA [28] (bài báo có z-score cao nhất), PaLM 2 [2], và GPT4 (được đại diện hai lần; một lần như một xuất bản của OpenAI không có tác giả chuyên dụng tập trung vào chi tiết kỹ thuật [24] và một lần bởi một nhóm nghiên cứu của Microsoft tập trung vào đánh giá mở rộng [6], cả hai đều được xuất bản vào cùng thời gian). Một "Khảo sát về Mô hình Ngôn ngữ Lớn" [32] (thứ hạng 10 trong danh sách của chúng tôi) được xuất bản vào cuối tháng 3 và đã được cập nhật 11 lần nữa chỉ ra mức độ phổ biến của các LLM đa dạng.

• Mặc dù không phải tất cả đều là báo cáo kỹ thuật hoặc khảo sát, phần lớn các bài báo hàng đầu đều tập trung quanh LLM (ít nhất 18 trong 20, tức là 90%). Ngoại lệ là hai bài báo từ lĩnh vực thị giác máy tính (thứ hạng 7 và 13).

• Thật thú vị là LLaMA [28], một tập hợp các mô hình ngôn ngữ nền tảng hiệu quả (và mã nguồn mở), thống trị tổng thể. Điều này gợi ý về tầm quan trọng của hiệu quả đối với LLM nói chung, cả từ góc độ môi trường nhưng có thể còn quan trọng hơn từ góc độ thực tế, vì các mô hình LLaMA vẫn có thể được tinh chỉnh ngay cả bởi các nhà nghiên cứu với 'vốn' GPU 'khiêm tốn' [19]. Hiệu quả được đại diện thêm bởi QLoRA [8], được nộp lên arXiv vào cuối tháng 5, thảo luận về tinh chỉnh hiệu quả của LLM được lượng tử hóa.

• Ba bài báo hàng đầu [3, 16, 27] (thứ hạng 9, 15 và 18) đặc biệt tập trung quanh ChatGPT (có thể được coi là người khơi mào cho sự phổ biến LLM mới [20]) và đặc biệt thảo luận về đánh giá của nó bao gồm các trường hợp thất bại. Bài báo [27] sử dụng ChatGPT để giải quyết các nhiệm vụ AI bằng cách truy vấn huggingface.

• Hai bài báo hàng đầu khác (thứ hạng 12 và 14) khám phá giải quyết vấn đề với LLM, một cái sử dụng các công cụ bên ngoài [25] và một cái sử dụng các chiến lược lý luận [31].

• Việc sử dụng LLM cho đánh giá được thảo luận trong hai bài báo [30, 33] (thứ hạng 8 và 17), một cho đánh giá đối thoại mở và một thảo luận về thiên vị của đánh giá với LLM. Cả hai bài báo đều gần đây hơn nhiều, được xuất bản vào cuối tháng 5 và đầu tháng 6.

• Hai bài báo [9, 29] (thứ hạng 5 và 13) thảo luận về các tác nhân hiện thân có thể tương tác với thế giới thực, sử dụng LLM.

• Hai bài báo [17, 22] (thứ hạng 19 và 20) có thể được xem là đặc biệt thảo luận về các khía cạnh đạo đức của việc phát hiện văn bản được tạo ra bởi LLM (ví dụ, để phát hiện nội dung AI được tạo ra gây hiểu lầm hoặc để phát hiện gian lận trong bối cảnh giáo dục) và đánh dấu văn bản AI được tạo ra, tức là nhúng tín hiệu trong văn bản được tạo ra tự động cho phép phát hiện thuật toán của nó. Cả hai bài báo đều được xuất bản sớm, vào cuối tháng 1.

• Cuối cùng, các ngoại lệ trong danh sách top 20 của chúng tôi là hai bài báo thị giác máy tính. Bài báo Segment Anything [18] của Meta AI Research cung cấp một tập dữ liệu cho phân đoạn hình ảnh. Bài báo [7] thảo luận về quyền riêng tư của các mô hình khuếch tán hình ảnh như DALL-E 2 (có thể được coi là tương tự của LLM trong lĩnh vực thị giác máy tính). Một bài báo thị giác máy tính khác giới thiệu một khung đa phương thức được gọi là LLaVA [21], xây dựng trên đầu GPT4.

• Gần đây, đã có một cuộc tranh luận về việc liệu AI/NLP có trở nên tiêu cực hơn hay không, tức là liệu các bài báo có xu hướng báo cáo tiêu cực hơn về nghiên cứu đang diễn ra (ví dụ, nêu ra những hạn chế và trường hợp thất bại) [5, 4]. Trong danh sách top-20 của chúng tôi, chỉ có hai bài báo (10%) có thể được coi là bài báo phê bình,

--- TRANG 7 ---
cụ thể là [30], tập trung vào và khám phá ra thiên vị trong LLM như các mô hình đánh giá, và [7], phê bình việc thiếu quyền riêng tư của các mô hình khuếch tán, cho phép truy xuất thông tin riêng tư từ dữ liệu huấn luyện. Trong danh sách top-40, có thêm hai bài báo tiêu cực nữa, tức là [12] tranh luận về khả năng toán học của ChatGPT, và [15], thách thức liệu việc chưng cất trong đó một LLM sinh viên nhỏ hơn được huấn luyện trên đầu ra của một LLM độc quyền lớn hơn như ChatGPT có thực sự hiệu quả không. Một số bài báo có phần tiêu cực, nêu bật một số hạn chế, như [3]. Nhìn chung, các bài báo phổ biến nhất hiện tại do đó tích cực về sự phát triển và khả năng của LLM gần đây.

Bảng 3 đưa ra các bài báo tương tự với thứ hạng từ 21 đến 40. Chúng tôi không thực hiện phân tích sâu như trên. Tuy nhiên, các bài báo có phạm vi tương tự, với 11 trong số 20 (55%) có cs.CL là danh mục chính và 13 trong số 20 (65%) có một biến thể của LLM trong tiêu đề của chúng (mô hình ngôn ngữ, ChatGPT, GPT, v.v.). Thật thú vị, danh sách các bài báo có thứ hạng 21-40 chứa khá nhiều cách tiếp cận đa phương thức như mô hình tạo text-to-image, và tương đối nhiều hơn so với danh sách các bài báo có thứ hạng 1-20.

4 Phân tích
Bây giờ chúng tôi thực hiện một vài phân tích sâu hơn về bộ dữ liệu của chúng tôi (không chỉ arxiv-0623-top40 mà còn arxiv-0623) để hiểu rõ hơn về những phát triển gần đây.

Có bao nhiêu trích dẫn và độ lệch chuẩn mỗi tuần? Hình 1 cho thấy số lượng trích dẫn trung bình của các bài báo thuộc ba danh mục chính (cs.CL, cs.LG, và tất cả các danh mục khác) theo thời gian. Chúng tôi quan sát rằng:

• trích dẫn có xu hướng giảm theo thời gian (như mong đợi; các bài báo gần đây hơn chưa thể được trích dẫn thường xuyên), với trung bình dưới 2 trích dẫn mỗi bài báo bắt đầu từ tháng 5 cho cả ba danh mục arXiv

• cs.CL thu hút (đáng kể) nhiều trích dẫn hơn cs.LG và tổng hợp của tất cả các danh mục chính khác liên quan

• Tháng 2 là tháng có các bài báo có tác động nhất trong cs.CL, đặc biệt là tuần 6 (ví dụ, Toolformer [25] và phân tích ChatGPT [3] được nộp lên arXiv) và tuần 9 (ví dụ, LLaMA [28] được nộp)

Kết quả chi tiết bao gồm độ lệch chuẩn tổng thể cũng được đưa ra trong Bảng 4. Độ lệch chuẩn đặc biệt lớn trong các tuần 1, 6, 8-13.

Có bao nhiêu danh mục arXiv (lĩnh vực khoa học con) liên quan? Tập dữ liệu arxiv-0623 của chúng tôi bao gồm 20.843 bài báo được nộp lên arXiv từ ngày 01/01/2023 đến 06/31/2023 với ít nhất một trong các danh mục được chỉ ra là cs.CL hoặc cs.LG. Vì NLP và ML ảnh hưởng đến tất cả các khía cạnh của cuộc sống ngày nay, chúng tôi mong đợi rằng những bài báo này không chỉ xuất phát từ ML hoặc NLP. Thật vậy, chúng tôi thấy rằng 20.843 bài báo của chúng tôi được gán cho 123 danh mục arXiv chính khác nhau. Chúng tôi đưa ra thống kê chi tiết về những 19 danh mục chính xuất hiện ít nhất 100 lần trong Bảng 5. Nhìn chung, 19 danh mục chính thường xuyên nhất được tạo thành từ 5 danh mục cấp cao nhất, cụ thể là: cs (khoa học máy tính), stat (thống kê), eess (kỹ thuật điện và khoa học hệ thống), math (toán học)

--- TRANG 8 ---
[Bảng 4 chứa thông tin về số lượng trích dẫn trung bình theo tuần]

--- TRANG 9 ---
[Hình 1 biểu đồ cho thấy số lượng trích dẫn trung bình theo tuần cho các danh mục arXiv khác nhau]

và quant-ph (vật lý lượng tử). Năm danh mục chi tiết thường xuyên nhất là cs.LG, cs.CL, cs.CV (thị giác máy tính), stat.ML (thống kê, học máy) và cs.AI (trí tuệ nhân tạo).

Biểu đồ tròn về phân phối các danh mục chính được thể hiện trong Hình 2. cs.LG là danh mục lớn nhất, gần 40% bài báo có nó là danh mục chính. cs.CL chỉ bằng khoảng một nửa kích thước (nhưng thống trị các bài báo top-40 như đã thảo luận ở trên). Các danh mục chính khác (ngoài 5 danh mục hàng đầu) có kích thước tương đương với cs.CL.

Điều gì phân biệt các bài báo hàng đầu với các bài báo khác? Chúng tôi sử dụng công cụ của [13] dựa trên kiểm định tỷ lệ log-likelihood [10] để xác định các từ thường xuyên bất thường trong 40 bài báo hàng đầu arxiv-0623-top40 so với tất cả các bài báo khác. Trong số 10 unigram đặc biệt nhất có chatgpt, gpt-4, modalities, visual, zero-shot. Trong số các bigram hàng đầu có language models, large language, models (llms), wide range. Trigram quan trọng nhất là large language models. Ngược lại, các từ đặc trưng cho các bài báo ngoài top-40 nhất là thuật ngữ tham chiếu đến thời đại học sâu cũ hơn như learning, neural, deep, network, neural network, machine learning, v.v. Mặc dù đặc trưng này rất đơn giản (chắc chắn không đủ để xuất bản một bài báo về LLM để đạt được số lượng trích dẫn cao), nhưng nó vẫn có tính thông tin.

Các bài báo Top-40 cũng có trung bình nhiều tác giả hơn nhiều (11.8, với độ lệch chuẩn 19.5) so với các bài báo còn lại (4.5 với độ lệch chuẩn 3.2). Một phần hiệu ứng có thể là tầm thường: nhiều tác giả hơn có thể tăng số lượng tự trích dẫn (một thực hành ít nhất là có phần không đạo đức

--- TRANG 10 ---
[Bảng 5 chứa thông tin về các danh mục arXiv và số lần xuất hiện]

[26]). Mặt khác, nghiên cứu cơ bản hơn có thể yêu cầu danh sách tác giả lớn hơn và ngành công nghiệp cũng có thể tạo ra các bài báo với số lượng tác giả cao hơn.

Những từ khóa quan trọng nhất của 40 bài báo hàng đầu là gì? Chúng tôi vẽ một đám mây từ của 40 bài báo hàng đầu (xem Hình 3). Để làm điều này, chúng tôi sử dụng KeyBERT [14] để xác định 5 trigram quan trọng nhất từ tiêu đề và tóm tắt của mỗi bài báo. Sau đó chúng tôi lọc ra một danh sách các từ không quan trọng được chọn thủ công và lemmatize mỗi từ. Cuối cùng, chúng tôi sử dụng thư viện python wordcloud cho việc vẽ biểu đồ. Ở đây, trọng tâm của nghiên cứu hiện tại về các mô hình ngày càng lớn hơn trở nên rõ ràng một lần nữa, với các cụm từ như trillion token, 175b, large scale và large language model. Từ khóa publicly available cũng cho thấy sự tập trung vào dữ liệu và mô hình không độc quyền.

Mức độ phổ biến của LLM theo thời gian trong tập dữ liệu arXiv của chúng tôi như thế nào? Trong khi chúng tôi đã thấy rằng LLM là chủ đề thống trị trong danh sách 40 bài báo hàng đầu, chúng tôi tự hỏi mức độ phổ biến của LLM và ChatGPT đã phát triển như thế nào theo thời gian trong tập dữ liệu arXiv hoàn chỉnh arxiv-0623 của chúng tôi. Để làm điều này, chúng tôi truy vấn các từ khóa "LLMs" và "ChatGPT" trong tập dữ liệu của chúng tôi theo thời gian và gắn cờ một bài báo là có liên quan nếu nó chứa các từ khóa trong tiêu đề hoặc tóm tắt của nó.

Hình 4 cho thấy kết quả. Cả hai từ khóa đều không rất có liên quan vào đầu năm 2023, ít hơn 2% bài báo chứa chúng vào tháng 1. Đường cong ChatGPT tăng lên cho đến cuối tháng 3 (6% tất cả bài báo). Bắt đầu từ giữa tháng 4, LLM trở thành từ khóa phổ biến hơn. ChatGPT

--- TRANG 11 ---
[Hình 2 biểu đồ tròn phân phối các danh mục chính]

như một từ khóa đã suy giảm kể từ đó, trong khi LLM tăng vọt trong tuần 05/21 (đánh dấu thời hạn nộp camera-ready năm 2023 cho hội nghị NLP phổ biến ACL https://www.aclweb.org/portal/content/acl-2023-call-papers) với gần 12% bài báo chứa nó; chúng tôi giả định rằng nhiều bài báo ACL được chấp nhận (với LLM là chủ đề) đã được đăng lên arXiv ngay sau thời hạn camera-ready. Kể từ đó, LLM dường như cũng đang suy giảm như một từ khóa - mặc dù điều này có thể chỉ là một sự tạo tác của thời hạn hội nghị.

5 Kết luận
Chúng tôi đã kiểm tra các bài báo arXiv liên quan đến các danh mục cs.CL và cs.LG trong nửa đầu năm 2023. Đầu tiên, chúng tôi sắp xếp các bài báo theo số lượng trích dẫn chuẩn hóa của chúng, thấy rằng các bài báo liên quan đến LLM rõ ràng thống trị. Trong LLM, các vấn đề phổ biến hiện tại tập trung quanh: hiệu quả, đánh giá dựa trên LLM, các khía cạnh đạo đức, tác nhân hiện thân và giải quyết vấn đề với LLM (chỉ ít nổi bật hơn một chút là các cách tiếp cận đa phương thức bao gồm ngôn ngữ và các phương thức khác như hình ảnh, với ít nhất 8 bài báo trong top-40). Chúng tôi cũng đã xem xét, trong số những điều khác: (i) đặc điểm của các bài báo hàng đầu có gì so với các bài báo ngoài danh sách top-40 về số lượng tác giả và từ vựng, (ii) phân phối trích dẫn trong tập dữ liệu của chúng tôi, và (iii) mức độ phổ biến của ChatGPT, 'gây ra' sự phổ biến hiện tại xung quanh LLM vào cuối năm 2022, và LLM theo thời gian.

Chúng tôi hy vọng rằng điều tra của chúng tôi có lợi không chỉ cho những người mới và người bên ngoài lĩnh vực NLP và ML (trong đó có vẻ rất nhiều ngày nay, với mức độ phổ biến của các lĩnh vực này

--- TRANG 12 ---
[Hình 3 đám mây từ dựa trên 40 bài báo hàng đầu]

[34]), cung cấp các liên kết nhanh đến tài liệu khởi đầu hữu ích, mà còn cho các nhà nghiên cứu đã thành lập và sinh viên tiến sĩ của họ.

Trong tương lai, chúng tôi muốn thường xuyên cập nhật báo cáo hiện tại để xem khẩu vị thay đổi như thế nào theo thời gian, kiểm tra các tập dữ liệu arXiv arxiv-0623 và arxiv-0623-top40 của chúng tôi sâu hơn nhiều, và bao gồm thêm các danh mục arXiv liên quan đến các lĩnh vực AI (ví dụ, cs.CV, stat.ML, cs.AI) vào các tập dữ liệu của chúng tôi, cùng với những điều khác.

Hạn chế
Hạn chế của cách tiếp cận của chúng tôi bao gồm những điều sau. Trước hết, các công cụ khoa học như SemanticScholar hoặc GoogleScholar mắc khá nhiều lỗi trong việc phân bổ trích dẫn một cách chính xác. Mặc dù chúng tôi không nghiên cứu điều này sâu, chúng tôi lưu ý ví dụ rằng LLaMA (bài báo hàng đầu của chúng tôi) có 874 trích dẫn theo SemanticScholar (29 tháng 7 năm 2023) nhưng chỉ có 710 trích dẫn theo GoogleScholar, một sự khác biệt tương đối là 164/874 = 18,7%. Bài báo với ít trích dẫn nhất trong danh sách top 20 của chúng tôi [30] có 14 trích dẫn (29 tháng 7 năm 2023) theo SemanticScholar nhưng chỉ có 9 trích dẫn theo GoogleScholar, một sự khác biệt tương đối là 5/14 = 35,7%. Mặc dù chúng tôi nghĩ rằng bảng xếp hạng của chúng tôi tương đối đáng tin cậy, những sai lệch như vậy có thể tự nhiên thiên vị việc lựa chọn bài báo của chúng tôi, có thể với sự không chắc chắn cao hơn đối với các bài báo trích dẫn thấp. Thứ hai, việc tập trung đặc biệt vào các bài báo được trích dẫn cao có thể gây ra một thiên vị đối với những bài báo này tương tự như của một lời tiên tri tự thực hiện hoặc gắn kết ưu tiên. Thứ ba, sự tập trung của chúng tôi vào

--- TRANG 13 ---
[Hình 4 biểu đồ mức độ phổ biến của ChatGPT và LLM theo thời gian]

trung bình trích dẫn hàng tuần có thể có những hiệu ứng không mong đợi: ví dụ, một bài báo trẻ hơn với nhiều trích dẫn hơn có thể được xếp hạng thấp hơn một bài báo cũ hơn với ít trích dẫn hơn, ví dụ, nếu bài báo cũ hơn đó được xuất bản trong một tuần với ít trích dẫn trung bình hơn (ví dụ, trong những tuần đầu của tháng 1 nơi nghiên cứu, và hoạt động con người khác, thường ít hiệu quả hơn, ít nhất là ở các phần có liên quan của thế giới, do các hoạt động nghỉ lễ trước đó). Cuối cùng, một số tác giả và nhóm nghiên cứu, có thể truyền thống hơn, có thể kiềm chế việc nộp bài báo của họ lên arXiv, bất chấp sự phổ biến cao khác của nó đặc biệt trong cộng đồng khoa học máy tính (xem tỷ lệ tăng trưởng theo cấp số nhân của số lượng nộp bài arXiv trong những thập kỷ qua https://info.arxiv.org/help/stats/2021_by_area/index.html). Các bài báo từ những tác giả hoặc nhóm như vậy sẽ không là một phần của tập dữ liệu và phân tích của chúng tôi.

Những hạn chế của chúng tôi phải được ghi nhớ khi giải thích kết quả của chúng tôi.

Lời cảm ơn
Nhóm NLLG biết ơn nhận được sự hỗ trợ từ Bộ Giáo dục và Nghiên cứu Liên bang (BMBF) thông qua tài trợ nghiên cứu AI liên ngành "Metrics4NLG". Steffen Eger được hỗ trợ thêm bởi tài trợ DFG Heisenberg EG 375/5-1. Chúng tôi cảm ơn Andreas "Max Power" Rückle vì những cuộc thảo luận sâu sắc.

--- TRANG 14 ---
[Tài liệu tham khảo từ [1] đến [16]]

--- TRANG 15 ---
[Tài liệu tham khảo từ [17] đến [34]]

--- TRANG 16 ---
[Tài liệu tham khảo cuối cùng]

# 2308.08493.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl-papers/2308.08493.pdf
# Kích thước file: 287812 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
arXiv:2308.08493v3  [cs.CL]  21 Feb 2024Được xuất bản như một bài báo hội nghị tại ICLR 2024
DU HÀNH THỜI GIAN TRONG LLM: THEO DÕI SỰ
NHIỄM DỮ LIỆU TRONG CÁC MÔ HÌNH NGÔN NGỮ LỚN
Shahriar Golchin∗, Mihai Surdeanu
Khoa Khoa học Máy tính, Đại học Arizona
{golchin,msurdeanu }@arizona.edu
TÓM TẮT
Sự nhiễm dữ liệu, tức là sự xuất hiện của dữ liệu kiểm tra từ các tác vụ downstream trong
dữ liệu huấn luyện của các mô hình ngôn ngữ lớn (LLM), là một vấn đề tiềm ẩn lớn trong
việc đo lường hiệu quả thực sự của LLM trên các tác vụ khác. Chúng tôi đề xuất một phương
pháp đơn giản nhưng hiệu quả để xác định sự nhiễm dữ liệu trong LLM. Về cốt lõi,
phương pháp của chúng tôi bắt đầu bằng việc xác định sự nhiễm tiềm ẩn ở cấp độ thể hiện;
sử dụng thông tin này, phương pháp của chúng tôi sau đó đánh giá sự nhiễm rộng hơn ở
cấp độ phân vùng. Để ước tính sự nhiễm của các thể hiện riêng lẻ, chúng tôi sử dụng
"hướng dẫn có định hướng:" một prompt bao gồm tên tập dữ liệu, loại phân vùng, và
đoạn ban đầu có độ dài ngẫu nhiên của một thể hiện tham chiếu, yêu cầu LLM hoàn thành
nó. Một thể hiện được đánh dấu là bị nhiễm nếu đầu ra của LLM khớp chính xác hoặc gần
khớp với đoạn sau của tham chiếu. Để hiểu liệu toàn bộ phân vùng có bị nhiễm hay không,
chúng tôi đề xuất hai ý tưởng. Ý tưởng đầu tiên đánh dấu một phân vùng tập dữ liệu là bị
nhiễm nếu điểm số trùng lặp trung bình với các thể hiện tham chiếu (được đo bằng ROUGE-L
hoặc BLEURT) tốt hơn một cách có ý nghĩa thống kê với các phần hoàn thành từ hướng dẫn
có định hướng so với "hướng dẫn chung" không bao gồm tên tập dữ liệu và phân vùng. Ý tưởng
thứ hai đánh dấu một phân vùng tập dữ liệu là bị nhiễm nếu một bộ phân loại dựa trên GPT-4
với prompt học trong ngữ cảnh few-shot đánh dấu nhiều phần hoàn thành được tạo ra như
khớp chính xác/gần chính xác với các thể hiện tham chiếu tương ứng. Phương pháp tốt nhất
của chúng tôi đạt được độ chính xác từ 92% đến 100% trong việc phát hiện liệu một LLM có
bị nhiễm với bảy tập dữ liệu, chứa các phân vùng huấn luyện và kiểm tra/xác thực, khi so
sánh với đánh giá thủ công bởi các chuyên gia con người. Hơn nữa, các phát hiện của chúng tôi
chỉ ra rằng GPT-4 bị nhiễm với các tập dữ liệu AG News, WNLI, và XSum.¹

1 GIỚI THIỆU
Sự phát triển của mạng Transformer (Vaswani et al. 2017) đã thúc đẩy việc phát triển các mô hình
ngôn ngữ lớn (LLM), đánh dấu một kỷ nguyên mới trong Xử lý Ngôn ngữ Tự nhiên (NLP). Sự
thay đổi này đã dẫn đến một loạt rộng rãi các LLM (Touvron et al. 2023a;b; Biderman et al. 2023;
Köpf et al. 2023; Chung et al. 2022; Penedo et al. 2023, inter-alia) vượt trội trong nhiều tiêu chuẩn
đánh giá chuyên nghiệp và học thuật (Bang et al. 2023; Bubeck et al. 2023). Hiệu suất vượt trội
của chúng chủ yếu được cho là do dữ liệu web khổng lồ được tiêu thụ bởi các LLM hàng tỷ/nghìn
tỷ tham số này trong quá trình huấn luyện. Tuy nhiên, hiệu suất LLM ấn tượng được quan sát trên
nhiều tác vụ downstream (ví dụ: tóm tắt, suy luận ngôn ngữ tự nhiên, phân loại văn bản) có thể
bị thổi phồng do sự nhiễm dữ liệu, tức là sự xuất hiện của dữ liệu kiểm tra từ các tác vụ downstream
này trong dữ liệu tiền huấn luyện của LLM. Đảm bảo không có sự nhiễm không phải là điều tầm
thường do hai nguồn tiềm ẩn của sự nhiễm: trực tiếp từ việc tiêu thụ phiên bản chính thức của
một tập dữ liệu (dễ kiểm soát hơn), và gián tiếp thông qua dữ liệu trùng lặp được tìm thấy ở đâu
đó trên web (gần như không thể kiểm soát).² Tiềm năng của sự nhiễm dữ liệu đặc biệt có liên quan
đối với các mô hình đóng như họ GPT-3/3.5 (Brown et al. 2020) và GPT-4
∗Tác giả liên hệ.
¹Xem repo của bài báo tại https://github.com/shahriargolchin/time-travel-in-llms.
²Trong khi việc cấp phép tập dữ liệu giảm sự nhiễm gián tiếp ở mức độ nhất định, nó không loại bỏ hoàn toàn.
Ví dụ, các trang web như trang Hugging Face cho tập dữ liệu (Wolf et al. 2020) hiện đang lưu trữ các bản sao
của tập dữ liệu OntoNotes (Weischedel et al. 2013) và CoNLL-2003 (Tjong Kim Sang & De Meulder 2003),
mặc dù giấy phép tương ứng của chúng cấm điều này.

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
(OpenAI 2023; Bubeck et al. 2023), và, không cần phải nói, đặt ra câu hỏi về tính hợp lệ của các
đánh giá và tiêu chuẩn được thực hiện cho đến nay (Chang et al. 2023; Zhu et al. 2023; Bordt & von
Luxburg 2023; Ray 2023; Penedo et al. 2023).

Để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp không đắt và mạnh mẽ để phát hiện
sự nhiễm dữ liệu cho một phân vùng tập dữ liệu nhất định một cách tự động. Quan trọng là, phương
pháp của chúng tôi hoạt động dưới hai giả định thực tế: (a) chúng tôi thiếu quyền truy cập trực tiếp
vào dữ liệu tiền huấn luyện của LLM, và (b) chúng tôi có tài nguyên tính toán hạn chế. Một cách
trực quan, phương pháp của chúng tôi bắt đầu bằng việc xác định sự nhiễm tiềm ẩn trong các thể
hiện riêng lẻ được rút ra từ một mẫu ngẫu nhiên nhỏ của phân vùng tập dữ liệu tương ứng (chúng
tôi sử dụng các mẫu gồm 10 thể hiện trong nghiên cứu này). Sử dụng thông tin thu được từ các
thể hiện riêng lẻ, phương pháp của chúng tôi sau đó đánh giá liệu toàn bộ phân vùng tập dữ liệu
có bị nhiễm hay không.

Chính thức hơn, để xác định sự nhiễm của các thể hiện riêng lẻ, chúng tôi sử dụng "hướng dẫn
có định hướng:" một prompt tích hợp các định danh riêng biệt từ tập dữ liệu nguồn mà thể hiện
tham chiếu có nguồn gốc từ đó. Thông tin như vậy bao gồm tên tập dữ liệu, phân vùng của nó
(ví dụ: train, test, hoặc validation), và một phần ban đầu được chọn ngẫu nhiên của thể hiện
tham chiếu, bổ sung bởi nhãn của nó khi có liên quan. Với các tín hiệu này trong prompt, chúng
tôi hướng dẫn LLM hoàn thành thể hiện một phần đã cho. Sử dụng các phần hoàn thành riêng lẻ
được tạo ra này, chúng tôi đề xuất hai heuristics để ước tính liệu toàn bộ phân vùng tập dữ liệu
có bị nhiễm hay không. Heuristic đầu tiên nói rằng một phân vùng có khả năng bị nhiễm nếu điểm
số trùng lặp trung bình giữa các phần hoàn thành được tạo ra và các thể hiện tham chiếu (được
đo bằng ROUGE-L (Lin 2004) và BLEURT (Sellam et al. 2020)) quan sát được với hướng dẫn có
định hướng lớn hơn một cách có ý nghĩa thống kê so với cái được đo với "hướng dẫn chung,"
không bao gồm tên tập dữ liệu và phân vùng. Heuristic thứ hai gắn nhãn một phân vùng là bị
nhiễm nếu một bộ phân loại dựa trên GPT-4 với học trong ngữ cảnh few-shot (ICL; Brown et al.
(2020)) đánh dấu ít nhất một phần hoàn thành được tạo ra như khớp chính xác với thể hiện tham
chiếu hoặc ít nhất hai phần hoàn thành được tạo ra như khớp gần chính xác, trong đó khớp gần
chính xác chỉ ra một phần hoàn thành thể hiện sự căn chỉnh ngữ nghĩa và từ vựng đáng kể với
thể hiện tham chiếu.

Các đóng góp chính của bài báo này như sau:

(1) Chúng tôi đề xuất một phương pháp phát hiện sự nhiễm dữ liệu mới cho LLM không đắt và
mạnh mẽ. Như đã chỉ ra ở trên, phương pháp của chúng tôi kết hợp "hướng dẫn có định hướng"
để hoàn thành các thể hiện một phần được rút ra ngẫu nhiên từ phân vùng tập dữ liệu được điều
tra và một số heuristics để tổng quát hóa từ các quyết định sự nhiễm cấp độ thể hiện sang cấp
độ phân vùng.

(2) Chúng tôi đánh giá các phương pháp đề xuất của mình trong 28 tình huống riêng biệt. Các
tình huống này được tạo ra bởi hai LLM tiên tiến: GPT-3.5 và GPT-4, và bao gồm bảy tập dữ
liệu cho các tác vụ phân loại, tóm tắt, và suy luận ngôn ngữ tự nhiên (NLI). Lý do đằng sau 28
tình huống là đối với mỗi tập dữ liệu, chúng tôi riêng biệt khám phá sự nhiễm dữ liệu tiềm ẩn
trong các phân chia train và test (hoặc tập validation, trong trường hợp tập test có nhãn không
được công khai). Đánh giá của chúng tôi chỉ ra rằng phương pháp tốt nhất của chúng tôi là cái
sử dụng hướng dẫn có định hướng để hoàn thành các thể hiện một phần, và cái đánh giá các
phần hoàn thành này bằng bộ phân loại GPT-4 few-shot ICL, đạt được độ chính xác 92%–100%
so với các nhãn sự nhiễm được gán bởi các chuyên gia con người cho các phân vùng tập dữ liệu.

(3) Phân tích của chúng tôi chỉ ra rằng GPT-4 cho thấy bằng chứng về sự nhiễm trong các phân
vùng test của các tập dữ liệu AG News (Zhang et al. 2015), WNLI (Wang et al. 2018), và XSum
(Narayan et al. 2018). Những phát hiện này hỗ trợ quan sát rằng sự nhiễm dữ liệu là một vấn
đề nghiêm trọng phải được xem xét trong các đánh giá downstream khi sử dụng LLM.

2 CÔNG TRÌNH LIÊN QUAN

Mặc dù tầm quan trọng của nó, chủ đề về sự nhiễm dữ liệu không được xem xét kỹ lưỡng như
lĩnh vực liên quan chặt chẽ của nó, ghi nhớ dữ liệu (Carlini et al. 2023; Kandpal et al. 2022;
Carlini et al. 2021; Razeghi et al. 2022). Trong số các cuộc điều tra hạn chế tập trung cụ thể vào
sự nhiễm dữ liệu trong LLM, chúng tôi tìm thấy các ví dụ đáng chú ý trong Radford et al. (2019)
và Brown et al. (2020) về GPT-2 và GPT-3, tương ứng. Họ đã sử dụng n-gram bậc cao (ví dụ:
13-gram) để phát hiện nội dung trùng lặp giữa dữ liệu tiền huấn luyện và tập dữ liệu đánh giá.
Hầu hết nghiên cứu sau Brown et al. (2020) đã áp dụng các phương pháp tương tự để phát hiện
sự nhiễm dữ liệu (Touvron et al. 2023b; Du et al. 2022; Chowdhery et al. 2022; Wei et al. 2021),
và gần đây nhất là khớp chuỗi con cho GPT-4 (OpenAI 2023). Tuy nhiên, phạm vi của nghiên cứu
hiện tại chủ yếu giới hạn ở các nhà cung cấp mô hình, và nó gặp phải các hạn chế cụ thể, đặc biệt
khi áp dụng cho các LLM nguồn đóng. Các hạn chế này chủ yếu liên quan đến nhu cầu truy cập
dữ liệu tiền huấn luyện (Brown et al. 2020; Du et al. 2022; Wei et al. 2021), yêu cầu tài nguyên
tính toán đáng kể (Touvron et al. 2023b), hoặc nhu cầu lao động thủ công rộng rãi (Chowdhery
et al. 2022). Phương pháp của chúng tôi nhằm vượt qua những rào cản này, cho phép đánh giá
sự nhiễm dữ liệu trong các tình huống mà dữ liệu tiền huấn luyện không được truy cập công khai
hoặc khi phần cứng tính toán đáng kể không có sẵn mặc dù có quyền truy cập vào dữ liệu tiền
huấn luyện.

Bài báo của chúng tôi gần nhất về tinh thần với công trình của Sainz et al. (2023), người cũng
phát hiện sự nhiễm khi không có quyền truy cập vào dữ liệu tiền huấn luyện. Nỗ lực này đã thúc
đẩy ChatGPT, đặc biệt khi GPT-3.5 là mô hình cơ sở của nó, để tạo ra các thể hiện đầu tiên từ
các phân vùng tập dữ liệu khác nhau. Giả định cơ bản ở đây là nếu một LLM có thể tái tạo các
thể hiện tập dữ liệu, nó phải đã được huấn luyện sử dụng phân chia cụ thể đó. Tuy nhiên, nghiên
cứu của chúng tôi cho thấy rằng phương pháp này có thể không đáng tin cậy và dễ bị thất bại.
Các thất bại như vậy có thể là kết quả từ tính thưa thớt được giới thiệu bởi yêu cầu tái tạo các
thể hiện đầu tiên của một phân chia tập dữ liệu hoặc từ việc không thể vượt qua các bộ lọc an
toàn được đặt bởi nhà cung cấp mô hình khi mô hình được yêu cầu tạo ra nội dung có bản quyền
như các thể hiện tập dữ liệu. Trong suốt bài báo này, chúng tôi gọi phương pháp này là "ChatGPT-
Cheat?," lấy cảm hứng từ tiêu đề của bài đăng blog được tham chiếu.

3 PHƯƠNG PHÁP

Trong phương pháp của chúng tôi, chúng tôi hoạt động dưới hai giả định cốt lõi: (1) thiếu quyền
truy cập trực tiếp vào dữ liệu tiền huấn luyện của LLM, và (2) có tài nguyên tính toán hạn chế.
Với những tiền đề này, chiến lược phát hiện sự nhiễm dữ liệu của chúng tôi được neo bởi hai
thông tin quan trọng. Đầu tiên, chúng tôi xem xét các thể hiện riêng lẻ trong một phân vùng tập
dữ liệu để phát hiện sự nhiễm ở cấp độ thể hiện. Thứ hai, cho rằng LLM được tiền huấn luyện
trên dữ liệu quy mô lớn, việc phát hiện các thể hiện bị nhiễm có thể hoạt động như một tín hiệu
của sự nhiễm rộng hơn. Kết quả là, phân vùng liên quan có thể được gắn nhãn là bị rò rỉ vào
dữ liệu tiền huấn luyện của LLM.

Để phân biệt sự nhiễm ở cấp độ thể hiện, chúng tôi tập trung vào việc nhân bản các thể hiện
bởi LLM. Trong bối cảnh này, các bản sao chính xác của các thể hiện phục vụ như những cờ đỏ
cho sự nhiễm trong phân vùng tương ứng. Lưu ý rằng, do hành vi xác suất vốn có của LLM, việc
đạt được các bản sao hoàn hảo không phải lúc nào cũng có thể ngay cả khi sự nhiễm là chắc chắn.
Tuy nhiên, các thể hiện được nhân bản gần giống có chức năng kép: trong khi chúng có thể cung
cấp các chỉ dẫn sâu sắc về sự nhiễm tiềm ẩn, thực tế là nhiều tập dữ liệu rút ra từ các nguồn
dựa trên web ngụ ý rằng các bản sao một phần cũng có thể phát sinh một cách tình cờ. Sự trùng
lặp này gây ra sự không chắc chắn trong việc rút ra kết luận cuối cùng về phân vùng cơ bản. Do
đó, việc kiểm tra các dấu hiệu sự nhiễm nhất quán và đáng kể trong phân vùng là điều cần thiết.

Trong các phần sau, chúng tôi đầu tiên giải thích chi tiết về phương pháp của chúng tôi và các
thành phần cần thiết để buộc LLM tái tạo các thể hiện tập dữ liệu. Chúng tôi sau đó đi sâu vào
quy trình đánh giá trạng thái sự nhiễm của các LLM hiện tại cho toàn bộ phân vùng dựa trên
các thể hiện này. Hơn nữa, tận dụng tùy chọn tinh chỉnh được OpenAI cung cấp cho mô hình
cơ sở GPT-3.5, chúng tôi tiến hành một nghiên cứu trong đó chúng tôi cố ý nhiễm mô hình cơ
sở GPT-3.5 với các phân vùng mà phương pháp của chúng tôi đã phát hiện là chưa bị nhiễm. Tiếp
theo, chúng tôi áp dụng kỹ thuật của chúng tôi lên GPT-3.5 bị nhiễm, tiếp tục cho thấy hiệu quả
của phương pháp trong việc xác định sự nhiễm dữ liệu trong LLM.

3.1 PHÁT HIỆN SỰ NHIỄM CẤP ĐỘ THỂ HIỆN

3.1.1 CÁC THÀNH PHẦN ĐỂ ĐO SỰ NHIỄM CẤP ĐỘ THỂ HIỆN

Để đo lường sự nhiễm cấp độ thể hiện, chúng tôi sử dụng hai phương pháp riêng biệt: phương
pháp đầu tiên tận dụng điểm số BLEURT và ROUGE-L, trong khi phương pháp thứ hai dựa trên
prompting ICL few-shot với GPT-4. Mỗi phương pháp sử dụng các thành phần cụ thể; tuy nhiên,
hai thành phần đầu tiên—hướng dẫn có định hướng và cơ chế dự đoán token tiếp theo—được
chia sẻ. Thành phần thứ ba—hướng dẫn chung—độc quyền cho phương pháp đầu tiên. Đối với
cả hai phương pháp, chúng tôi bắt đầu quá trình của mình bằng cách điều hướng LLM về phía
phân vùng tập dữ liệu (có thể bị nhiễm) sử dụng hướng dẫn có định hướng tích hợp tên tập dữ
liệu, phân vùng quan tâm, và đoạn ban đầu có độ dài ngẫu nhiên của một thể hiện được chọn
ngẫu nhiên và nhãn của nó nếu có sẵn. LLM sau đó được hướng dẫn để hoàn thành nó. Đối với
phương pháp đầu tiên, chúng tôi lặp lại bước này sử dụng hướng dẫn chung bỏ qua tên tập dữ
liệu và phân vùng. Một ví dụ về hướng dẫn có định hướng so với hướng dẫn chung được mô tả
trong Hình 1. Chúng tôi chi tiết tất cả các thành phần cần thiết bên dưới.

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Hướng dẫn: Bạn được cung cấp Câu 1 từ
phân chia validation của tập dữ liệu WNLI. Hoàn
thành Câu 2 như đã xuất hiện trong tập dữ liệu.
Câu 2 phải khớp chính xác với thể hiện trong
tập dữ liệu.
Câu 1: Con chó đuổi theo con mèo, con mèo
chạy lên cây. Nó đợi ở trên đỉnh.
Nhãn: 1 (entailment)
Câu 2:
Con mèo đợi ở trên đỉnh.

Hướng dẫn: Hoàn thành Câu 2 dựa trên Câu 1,
sao cho nhãn sau đây thể hiện mối quan hệ logic
giữa Câu 1 và Câu 2.
Câu 1: Con chó đuổi theo con mèo, con mèo
chạy lên cây. Nó đợi ở trên đỉnh.
Nhãn: 1 (entailment)
Câu 2:
Con mèo ở trên đỉnh cây sau khi
bị chó đuổi.

Hình 1: Một ví dụ về hướng dẫn có định hướng (trái) và hướng dẫn chung (phải) được sử dụng
cho một tập dữ liệu thể hiện cặp. Trong ví dụ này, sử dụng GPT-4, hướng dẫn có định hướng
dẫn đến một khớp chính xác, trong khi hướng dẫn chung thì không.

(1) Hướng dẫn có định hướng—Một phương tiện để điều hướng đầu ra của LLM. Bằng cách sử
dụng instruction-tuning trên mô hình ngôn ngữ nhân quả (CLM; Vaswani et al. (2017); Radford
et al. (2018)), LLM có thể được hướng dẫn bởi các chỉ thị của con người (Wei et al. 2022; Sanh
et al. 2022; Chung et al. 2022). Điều này phục vụ như một công cụ để kiểm soát đầu ra của LLM
sử dụng ngôn ngữ tự nhiên. Do đó, chúng tôi hình thành hướng dẫn có định hướng sao cho nó
kết hợp tên tập dữ liệu và phân chia trong prompt đầu vào, từ đó hướng LLM về phía phân chia
tập dữ liệu cơ bản. Một danh sách toàn diện của tất cả các hướng dẫn được sử dụng trong nghiên
cứu này cho các tác vụ/tập dữ liệu khác nhau có thể được tìm thấy trong Bảng 5 trong Phụ lục A.

(2) Dự đoán Token tiếp theo—Một phương tiện để khám phá lịch sử dữ liệu. Chủ yếu, sự nhiễm
dữ liệu xảy ra trong giai đoạn tiền huấn luyện CLM vì nó cấu thành phần lớn nhất của việc huấn
luyện trong LLM và sử dụng dữ liệu web. Không có instruction tuning, một LLM chỉ cố gắng hoàn
thành một prompt đầu vào dựa trên dữ liệu đã thấy trong giai đoạn tiền huấn luyện CLM (Ouyang
et al. 2022). Các mô hình đáng chú ý thể hiện hành vi này bao gồm GPT-2 và GPT-3. Do đó,
chúng tôi sử dụng cơ chế dự đoán token tiếp theo để theo dõi lịch sử dữ liệu. Cụ thể, chúng tôi
cung cấp cho mô hình đoạn ban đầu có độ dài thay đổi của một thể hiện tập dữ liệu, được chọn
ngẫu nhiên từ một phân chia cụ thể, thúc đẩy nó hoàn thành thể hiện một phần. Đối với các thể
hiện có nhãn, chúng tôi tích hợp các nhãn tương ứng trong prompt đầu vào. Điều này phản ánh
rằng nếu một thể hiện đã được tiêu thụ trong quá trình tiền huấn luyện của LLM, nhãn của nó
cũng đã được tiêu thụ.³ Đối với các tập dữ liệu thể hiện cặp, chúng tôi trình bày cho mô hình
câu ban đầu và nhãn tương ứng của nó. Trong trường hợp các tập dữ liệu thể hiện đơn, các thể
hiện với nhiều câu được cắt một cách tùy ý ở cuối một câu hoàn chỉnh, trong khi đối với các
thể hiện chứa một câu (dài) đơn, một đoạn câu ngẫu nhiên bị loại bỏ. Cuối cùng, LLM được giao
nhiệm vụ hoàn thành phần ban đầu được cung cấp. Hình 1 cho thấy quá trình này cho một tập
dữ liệu thể hiện cặp.

Do đó, một khi LLM bị nhiễm được nhắc với hướng dẫn có định hướng, đầu ra của nó sẽ phản
ánh đoạn tiếp theo của thể hiện tham chiếu dưới sự hướng dẫn của tên tập dữ liệu và phân chia.

(3) Hướng dẫn chung—Một khía cạnh thay thế của mô hình ngôn ngữ nhân quả. Chúng tôi xây
dựng hướng dẫn chung để đo lường tác động của sự hướng dẫn được đưa ra trong hướng dẫn có
định hướng. Hướng dẫn chung này chỉ yêu cầu hoàn thành thể hiện một phần mà không chỉ định
tập dữ liệu hoặc phân vùng của nó. Kết quả là, khi sử dụng hướng dẫn này, chuỗi được tạo ra
chỉ dựa vào giai đoạn tiền huấn luyện CLM, giống như các mô hình tự hồi quy không có instruction
tuning. Điều này cho phép chúng tôi thiết lập một đường cơ sở cho các bản sao ngẫu nhiên được
tạo ra và đánh giá mức độ ảnh hưởng của hướng dẫn có định hướng đến phần được tạo ra bởi
LLM của thể hiện một phần đầu vào. Chúng tôi đánh giá ảnh hưởng này về mặt trùng lặp, ngữ
nghĩa, và sự tương tự cấu trúc với thể hiện tham chiếu. Phân tích này là quan trọng vì ngay cả
khi đầu ra của LLM không khớp hoàn hảo với thể hiện tham chiếu, nó vẫn cho phép chúng tôi
phát hiện các dấu hiệu tiềm ẩn của sự nhiễm.

3.1.2 ĐO SỰ NHIỄM CẤP ĐỘ THỂ HIỆN

Chúng tôi giới thiệu hai phương pháp để đo sự nhiễm ở cấp độ thể hiện:

³ Việc kết hợp nhãn trong prompt đầu vào là điều cần thiết để tính đến các kết quả dương tính giả khi tạo
ra các phần hoàn thành downstream. Các minh họa về tác động của việc tích hợp nhãn đối với các phần hoàn
thành downstream được cung cấp trong Bảng 6 trong Phụ lục B.

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

BLEURT & ROUGE-L: Để định lượng sự trùng lặp giữa các phần hoàn thành—được tạo ra dưới
cả hướng dẫn có định hướng và hướng dẫn chung—và các thể hiện tham chiếu, chúng tôi sử dụng
hai chỉ số: ROUGE-L (Lin 2004) và BLEURT (Sellam et al. 2020). Trong khi ROUGE-L đánh giá
sự tương tự từ vựng, BLEURT đo lường sự liên quan ngữ nghĩa và tính trôi chảy của chuỗi kết
quả so với thể hiện tham chiếu. Sự nhiễm cấp độ thể hiện được phát hiện nếu điểm số trùng lặp
trung bình từ một trong hai chỉ số, khi áp dụng cho các phần hoàn thành từ hướng dẫn có định
hướng, vượt quá những điểm từ hướng dẫn chung.

Đánh giá GPT-4: Trong khi cả BLEURT và ROUGE-L đều định lượng sự trùng lặp giữa các thể
hiện được tạo ra và tham chiếu, chúng không đủ khả năng xác định các khớp gần chính xác. Để
lấp đầy khoảng trống này, chúng tôi áp dụng prompting ICL few-shot (Brown et al. 2020) để
quyết định việc phát hiện các khớp chính xác/gần chính xác dựa trên đánh giá của con người
(xem Phần 4: Đánh giá Con người cho định nghĩa của chúng tôi về một khớp gần chính xác). Cụ
thể, phương pháp này bao gồm một vài ví dụ đại diện về các khớp chính xác và gần chính xác—
có nguồn gốc từ các đánh giá của con người—trong prompt, được sử dụng để đánh giá tất cả
các phần hoàn thành được tạo ra khác. Chúng tôi chọn GPT-4 cho nhiệm vụ này vì nó không yêu
cầu kỹ thuật prompting chuyên biệt (Bubeck et al. 2023), tăng cường độ tin cậy của kết quả.
Một biểu diễn hình ảnh của prompt ICL few-shot được sử dụng trong nghiên cứu của chúng tôi
có thể thấy trong Hình 3 trong Phụ lục C. Ngoài ra, các ví dụ chi tiết, bao gồm điểm số ROUGE-L
và BLEURT của chúng, cũng như các đánh giá ICL few-shot của con người và GPT-4, được liệt kê
trong Bảng 7 trong Phụ lục D.

3.2 PHÁT HIỆN SỰ NHIỄM CẤP ĐỘ PHÂN VÙNG

Để tổng quát hóa từ sự nhiễm cấp độ thể hiện sang các quyết định rời rạc cấp độ phân vùng (tức
là, phân vùng bị/không bị nhiễm), chúng tôi tận dụng hai quan sát:

Ý tưởng 1: Một tập dữ liệu có khả năng bị nhiễm nếu điểm số trùng lặp trung bình với các thể
hiện tham chiếu (được đo bằng ROUGE-L và BLEURT) quan sát được với các phần hoàn thành
từ hướng dẫn có định hướng lớn hơn đáng kể so với cái được đo với các phần hoàn thành từ
hướng dẫn chung. Động lực đằng sau ý tưởng này là vì sự khác biệt duy nhất giữa hai hướng
dẫn là hướng dẫn có định hướng chứa tên tập dữ liệu và phân vùng như hướng dẫn, sự cải thiện
chỉ có thể được giải thích bởi sự nhiễm.

Ý tưởng 2: Một tập dữ liệu có khả năng bị nhiễm nếu GPT-4 sử dụng prompting ICL few-shot
phát hiện ít nhất một khớp chính xác hoặc ít nhất hai khớp gần chính xác. Trực giác đằng sau ý
tưởng này là ngay cả một phần nhiễm nhỏ của mẫu thể hiện có khả năng chỉ ra một rò rỉ phân
vùng tập dữ liệu lớn hơn. Trong khi sự hiện diện của một khớp chính xác trong số các bản sao
được tạo ra bởi LLM là một dấu hiệu rõ ràng của sự nhiễm, cách tiếp cận để xử lý các khớp chính
xác hoặc gần chính xác—và quyết định số lượng các khớp như vậy chỉ ra sự nhiễm rộng hơn—có
thể được điều chỉnh tùy thuộc vào các mục tiêu nghiên cứu cụ thể. Trong bài báo này, chúng tôi
trực quan thiết lập tiêu chí nói trên để suy ra từ sự nhiễm cấp độ thể hiện sang cấp độ phân vùng.
Một xác thực thực nghiệm về phương pháp của chúng tôi cũng được cung cấp trong Phần 3.3.

Chúng tôi đề xuất hai thuật toán, mỗi thuật toán thực hiện một trong những ý tưởng này tương ứng.

Thuật toán 1: Một phân vùng tập dữ liệu được gắn nhãn là bị nhiễm nếu điểm số trùng lặp trung
bình (được cung cấp bởi BLEURT và ROUGE-L) giữa các thể hiện tham chiếu và văn bản được
tạo ra với hướng dẫn có định hướng trên một mẫu gồm mười thể hiện tốt hơn một cách có ý nghĩa
thống kê so với những cái được tạo ra bởi hướng dẫn chung dưới một bài kiểm tra bootstrap
resampling không tham số.⁴

Ưu điểm của thuật toán này là nó không tham số, tức là chúng tôi không cần quyết định về một
ngưỡng tùy ý trên điểm số ROUGE-L hoặc BLEURT để chỉ ra sự nhiễm. Tuy nhiên, nhược điểm
của nó là ngay cả một sự tăng đáng kể trong sự trùng lặp vẫn có thể đến từ các thể hiện được
tạo ra mà con người sẽ không coi là một khớp chính xác hoặc gần chính xác. Thuật toán 2 giải
quyết hạn chế này.

Thuật toán 2: Một phân vùng tập dữ liệu được gắn nhãn là bị nhiễm nếu GPT-4 với prompting
ICL few-shot đánh dấu ít nhất một phần hoàn thành được tạo ra như một khớp chính xác hoặc
tối thiểu hai phần hoàn thành như khớp gần chính xác trong một mẫu gồm mười thể hiện. Tất cả
các phần hoàn thành trong thiết lập này được tạo ra chỉ bằng hướng dẫn có định hướng.

Chúng tôi đánh giá cả hai thuật toán này trong Phần 5.

⁴ Chi tiết về phương pháp bootstrap resampling của chúng tôi có thể được tìm thấy trong Phụ lục E.

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Hướng dẫn: Bạn được cung cấp Câu 1 từ phân chia train của tập dữ liệu RTE. Hoàn thành Câu 2 như
đã xuất hiện trong tập dữ liệu. Câu 2 phải khớp chính xác với thể hiện trong tập dữ liệu.
Câu 1: Mười hai vệ tinh của Sao Mộc tương đối nhỏ và dường như có nhiều khả năng bị bắt giữ hơn
là được hình thành trong quỹ đạo xung quanh Sao Mộc.
Nhãn: 0 (không entailment)
Câu 2:
———————————————————————————————————————————————
GPT-3.5: Việc hình thành mười hai vệ tinh tương đối nhỏ của Sao Mộc có nhiều khả năng
do chúng bị bắt giữ hơn là được hình thành trong quỹ đạo xung quanh Sao Mộc.
———————————————————————————————————————————————
GPT-3.5 bị nhiễm: Sao Mộc có mười hai vệ tinh.

Hình 2: Một ví dụ về một khớp chính xác được tạo ra bởi GPT-3.5 bị nhiễm với phân chia train
của tập dữ liệu RTE so với một khớp không chính xác được tạo ra bởi mô hình cơ sở GPT-3.5,
cả hai dưới cùng một hướng dẫn có định hướng. Ví dụ này là một trong những thể hiện huấn
luyện được sử dụng trong quá trình nhiễm.

Bảng 1: Kết quả sau khi giới thiệu sự nhiễm cố ý
vào mô hình cơ sở GPT-3.5 sử dụng hướng dẫn có
định hướng. Một dấu tick (✓) chỉ ra việc xác định
ít nhất một bản sao chính xác từ các thể hiện huấn
luyện được sử dụng cho sự nhiễm bởi phương pháp
hiệu suất tốt nhất của chúng tôi (Alg. 2: GPT-4 ICL)
và đánh giá con người.

Phương pháp | AG News | RTE | XSum
Alg. 2: GPT-4 ICL | ✓ | ✓ | ✓
Đánh giá Con người | ✓ | ✓ | ✓

Bảng 2: Kết quả xác định sự nhiễm của tập dữ liệu
GSM8k trong GPT-4 khi sử dụng hướng dẫn có định
hướng. Một dấu tick kép (✓✓) báo hiệu việc xác định
hai hoặc nhiều bản sao gần chính xác từ phân chia
train của tập dữ liệu này bởi phương pháp hiệu suất
tốt nhất của chúng tôi (Alg. 2: GPT-4 ICL) và đánh
giá con người.

Phương pháp | GSM8k
Alg. 2: GPT-4 ICL | ✓✓
Đánh giá Con người | ✓✓

3.3 NHÂN BẢN THỂ HIỆN: MỘT PHƯƠNG PHÁP HỢP LỆ ĐỂ PHÁT HIỆN SỰ NHIỄM DỮ LIỆU

Để xác thực lựa chọn của chúng tôi về các siêu tham số được sử dụng trong Thuật toán 2, tức là
số lượng khớp chính xác/gần chính xác để tuyên bố sự nhiễm, chúng tôi đã thực hiện một nghiên
cứu kiểm soát trong đó một LLM bị nhiễm cố ý với một số tập dữ liệu. Để làm điều này, chúng
tôi đã sử dụng mô hình cơ sở GPT-3.5 và một tập con của phân vùng train của các tập dữ liệu
sau (một tập dữ liệu từ mỗi tác vụ được đề cập): AG News, RTE, và XSum. Lưu ý rằng tất cả
các phân vùng này đã được đánh dấu là chưa bị nhiễm đối với GPT-3.5 bởi các nhà đánh giá con
người (xem Bảng 4 và Phần 4: Đánh giá Con người). Để mô phỏng việc tiền huấn luyện LLM trên
dữ liệu web, chúng tôi chỉ giữ lại siêu dữ liệu tối thiểu về các tập dữ liệu như chúng xuất hiện
trên web khi được thu thập. Cụ thể, chúng tôi đã sử dụng: tiêu đề tập dữ liệu, tên phân vùng,
và toàn bộ thể hiện.⁵ Sau khi huấn luyện, chúng tôi đánh giá các phần hoàn thành được tạo ra
bởi kỹ thuật hiệu suất tốt nhất của chúng tôi (Thuật toán 2: GPT-4 ICL) (xem Bảng 3). Hình 2
hình dung các bản sao được tạo ra trước và sau sự nhiễm trong một trong các thí nghiệm của
chúng tôi khi sử dụng hướng dẫn có định hướng.⁶ Ngoài ra, Bảng 1 tóm tắt các phát hiện của
chúng tôi từ nghiên cứu này. Kết luận chính của thí nghiệm này là LLM bị nhiễm đã tạo ra ít nhất
một khớp chính xác trong mỗi thiết lập. Điều này nhấn mạnh rằng việc nhân bản ngay cả một
khớp chính xác đứng như một chỉ số mạnh mẽ và không thể chối cãi về sự nhiễm.⁷

Như một thí nghiệm thứ hai, chúng tôi đã sử dụng GPT-4 và tập dữ liệu GSM8k (Cobbe et al.
2021). Lựa chọn này được thúc đẩy bởi báo cáo kỹ thuật của OpenAI về GPT-4, chỉ ra sự nhiễm
từ phân chia train của nó (OpenAI 2023). Cho rằng tập dữ liệu này bao gồm các bài toán toán
học, mục tiêu của chúng tôi là nhân bản các câu hỏi trong tập dữ liệu trong khi giữ lại các câu
trả lời tương ứng của chúng.⁸ Bảng 2 báo cáo kết quả của chúng tôi từ thí nghiệm này. Kết quả
của chúng tôi nhấn mạnh rằng sự nhiễm không chỉ được xác định thông qua các khớp chính xác;
các khớp gần chính xác cũng có tính chỉ thị. Để tính đến bản chất xác suất của LLM, chúng tôi
đặt ngưỡng là hai cho số lượng tối thiểu các khớp gần chính xác để chỉ ra sự nhiễm. Như được
hiển thị, điều này được hỗ trợ bởi dữ liệu.

⁵ Tất cả các định dạng dữ liệu được sử dụng để nhiễm GPT-3.5 được chi tiết trong Bảng 10 trong Phụ lục F.
⁶ Các ví dụ khác được cung cấp trong Bảng 11 trong Phụ lục G.
⁷ Chi tiết về việc tiếp tục huấn luyện mô hình cơ sở GPT-3.5 được trình bày trong Phụ lục F.
⁸ Một ví dụ về quá trình nhân bản này được cung cấp trong Bảng 11 trong Phụ lục G.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

4 THIẾT LẬP THÍ NGHIỆM

Dữ liệu: Đánh giá của chúng tôi sử dụng bảy tập dữ liệu có nguồn gốc từ các tác vụ khác nhau,
cụ thể là phân loại, tóm tắt, và NLI. Các tập dữ liệu được đề cập bao gồm IMDB (Maas et al.
2011), AG News (Zhang et al. 2015), Yelp Full Reviews (Zhang et al. 2015), SAMSum (Gliwa et al.
2019), XSum (Narayan et al. 2018), WNLI (Wang et al. 2018), và RTE (Wang et al. 2019). Để đảm
bảo một thiết lập thí nghiệm toàn diện, tất cả các thí nghiệm của chúng tôi được thực hiện trên
cả phân chia huấn luyện và test/validation của các tập dữ liệu nói trên. Chúng tôi sử dụng các
phân chia có sẵn công khai, làm việc với các phân chia huấn luyện và test cho mỗi tập. Tuy nhiên,
đối với hai tập dữ liệu cuối cùng, chỉ có các phân chia validation được truy cập công khai với
nhãn của chúng. Xem xét trọng tâm của nghiên cứu chúng tôi về việc xác định sự nhiễm dữ liệu
với số lượng thể hiện tập dữ liệu tối thiểu, các ràng buộc về tài nguyên, và ý định của chúng tôi
để tạo điều kiện thuận lợi cho việc nhân bản phương pháp này bởi các nhà nghiên cứu khác,
chúng tôi đã chọn ngẫu nhiên 10 thể hiện từ mỗi phân chia cho các thí nghiệm của chúng tôi.

Thiết lập: Chúng tôi sử dụng các phiên bản snapshot của GPT-3.5 và GPT-4 từ ngày 13 tháng 6
năm 2023—cụ thể là gpt-3.5-turbo-0613 và gpt-4-0613—cả hai được truy cập qua OpenAI API,
như các LLM cơ bản của chúng tôi. Để có được kết quả xác định, chúng tôi đặt nhiệt độ về không
và giới hạn độ dài hoàn thành tối đa ở 500 token. Ngược lại, phương pháp so sánh của chúng tôi
(ChatGPT-Cheat?) sử dụng giao diện người dùng chat (UI), mà chúng tôi cũng tận dụng để thực
hiện thí nghiệm dưới phương pháp này. Cụ thể, chúng tôi đã sử dụng các phiên bản UI của GPT-4
và GPT-3.5 được phát hành vào ngày 20 tháng 7 năm 2023.

Đánh giá Con người: Chúng tôi thực hiện một đánh giá con người, được dẫn dắt bởi hai chuyên
gia lĩnh vực,⁹ để đặc trưng hóa sự nhiễm bằng cách xác định cả khớp chính xác và khớp gần chính
xác của các thể hiện riêng lẻ. Thuật ngữ "khớp chính xác" là tự giải thích; "khớp gần chính xác"
là các phần hoàn thành bởi LLM mà, mặc dù không giống hệt, thể hiện sự trùng lặp đáng kể và
duy trì sự tương tự ngữ nghĩa và cấu trúc đáng kể với thể hiện tham chiếu. Để tổng quát hóa từ
các thể hiện riêng lẻ đến toàn bộ phân vùng, các nhà chú thích con người đã tuân theo quy tắc
được mô tả trong Thuật toán 2 được xác thực thực nghiệm trong Phần 3.3: một phân vùng được
đánh dấu là bị nhiễm nếu đánh giá dựa trên thể hiện xác định ít nhất một khớp chính xác hoặc
ít nhất hai khớp gần chính xác.

Chỉ số Đánh giá: Trong phân tích của chúng tôi, việc tính toán điểm số BLEURT thay đổi dựa trên
cấu trúc của tập dữ liệu/thể hiện, vì chỉ số này phụ thuộc vào tính trôi chảy và chất lượng của
chuỗi được tạo ra. Đối với các tập dữ liệu thể hiện đơn, nơi các thể hiện riêng lẻ được cắt ngẫu
nhiên giữa câu và sau đó được hoàn thành bởi LLM, chúng tôi nối phần tiếp tục được tạo ra bởi
mô hình với thể hiện tham chiếu bị cắt và sau đó tính toán điểm số BLEURT. Ngược lại, đối với
các thể hiện từ các tập dữ liệu thể hiện cặp và thể hiện đơn nhiều câu, điểm số BLEURT được
tính toán chỉ cho chuỗi mới được tạo ra. Chúng tôi nhấn mạnh rằng các tính toán điểm số BLEURT
của chúng tôi sử dụng checkpoint mới nhất được cung cấp, tức là BLEURT-20 (Pu et al. 2021).
Mặt khác, bất kể loại tập dữ liệu/thể hiện, việc tính toán điểm số ROUGE-L chỉ liên quan đến các
phần văn bản được hoàn thành bởi LLM. Điều này là do sự phụ thuộc của điểm số vào các thuộc
tính thống kê hơn là tính nhất quán ngữ nghĩa.

Khung So sánh: Chúng tôi so sánh các phương pháp đề xuất của chúng tôi với phương pháp
ChatGPT-Cheat? (Sainz et al. 2023). Không giống như phương pháp của chúng tôi, sử dụng thang
điểm nhị phân để xác định sự nhiễm, phương pháp so sánh bao gồm một danh mục "đáng ngờ".
Định danh này được sử dụng khi LLM, khi được yêu cầu tạo ra các thể hiện đầu tiên của một
phân chia tập dữ liệu, xuất ra các thuộc tính đặc trưng như định dạng dữ liệu, ID, hoặc các chi
tiết cụ thể khác của tập dữ liệu thay vì các thể hiện thực tế. Nếu mô hình, mặt khác, không tạo
ra các đặc trưng này, nó được coi là không bị nhiễm.

5 KẾT QUẢ VÀ THẢO LUẬN

Bảng 3 liệt kê độ chính xác tổng thể của các phương pháp đề xuất của chúng tôi trong 28 thiết
lập riêng biệt: hai LLM (GPT-4 và GPT-3.5) × 14 phân vùng tập dữ liệu đến từ bảy tập dữ liệu.
Bảng 4 cung cấp một phân tích chi tiết của mỗi phương pháp cho mỗi phân vùng tập dữ liệu và
LLM tương ứng. Chúng tôi rút ra các quan sát sau từ các thí nghiệm của chúng tôi:

(1) Thuật toán 1, dựa trên sự khác biệt trong điểm số trùng lặp trung bình giữa các đầu ra từ
hướng dẫn có định hướng và những từ hướng dẫn chung, hoạt động tốt trong phần lớn các thiết
lập. Hiệu suất tốt nhất của nó là tỷ lệ thành công 13/14 khi sử dụng GPT-4 như mô hình cơ bản
và 9/14 khi sử dụng GPT-3.5. Chúng tôi coi những kết quả này là thú vị do sự đơn giản của thuật
toán. Tuy nhiên, Bảng 3 cho thấy rằng: (a) hiệu suất của nó không tốt một cách phổ quát—nó
hoạt động ở mức cơ hội khi sử dụng ROUGE-L trên các đầu ra GPT-3.5 (7/14), và (b) tỷ lệ thành
công của nó thay đổi tùy thuộc vào chỉ số sử dụng (tức là BLEURT hoặc ROUGE-L).

(2) Ngược lại, Thuật toán 2, dựa trên đánh giá GPT-4 sử dụng prompt ICL few-shot, căn chỉnh
chặt chẽ với các đánh giá con người. Cụ thể, trong các thí nghiệm chạy trên GPT-4 và GPT-3.5,
tỷ lệ thành công của nó là 14/14 và 13/14, tương ứng. Những độ chính xác này cao hơn bất kỳ
cái nào được tạo ra bởi Thuật toán 1 và duy trì tính nhất quán trên tất cả các thiết lập với hai LLM.

(3) Khi đánh giá kết quả của phương pháp ChatGPT-Cheat?, chúng tôi phát hiện rằng phương pháp
này luôn gắn nhãn các phân vùng là đáng ngờ—có khả năng do sự thận trọng chống lại việc tạo
ra nội dung có bản quyền được kích hoạt bởi các bộ lọc an toàn—cho tất cả các tình huống liên
quan đến GPT-4. Cho điều này, chúng tôi diễn giải kết quả của phương pháp này thông qua hai
góc nhìn: đánh giá nghiêm ngặt và khoan dung. Trong đánh giá nghiêm ngặt, chúng tôi không
diễn giải nhãn đáng ngờ là bị nhiễm hoặc không bị nhiễm. Dưới đánh giá này, không có phân
vùng nào được phân loại đúng theo đánh giá con người (0/14) trong các thiết lập với GPT-4, và
11/14 trong các thiết lập với GPT-3.5. Trong đánh giá khoan dung, chúng tôi chuyển đổi nhãn
đáng ngờ thành bị nhiễm hoặc không bị nhiễm theo cách tối đa hóa hiệu suất của phương pháp
này. Trong thiết lập này, phương pháp ChatGPT-Cheat? xác định đúng 9/14 và 13/14 trong các
thiết lập với GPT-4 và GPT-3.5, tương ứng. Tuy nhiên, đánh giá khoan dung này là không thực
tế do sự overfitting trong việc diễn giải nhãn đáng ngờ. Những phát hiện này hỗ trợ quan sát
của chúng tôi rằng việc xác định sự nhiễm ở cấp độ thể hiện, trước khi suy ra ra cấp độ phân
vùng, là một chiến lược kiên cường hơn.

(4) Cuối cùng nhưng không kém phần quan trọng, đánh giá con người tiết lộ rằng các phân chia
train và test/validation của cả tập dữ liệu AG News và WNLI đều được bao gồm trong dữ liệu
tiền huấn luyện của GPT-4. Tuy nhiên, đối với IMDB và RTE, chỉ có các phân vùng huấn luyện
được kết hợp, trong khi đối với XSum, chỉ có phân chia test bị rò rỉ. Đối với GPT-3.5, sự tiếp
xúc dữ liệu duy nhất là phân vùng test của tập dữ liệu XSum. Những phát hiện này xác nhận rằng,
mặc dù những nỗ lực của người tạo ra chúng, các LLM ngày nay đã tiêu thụ các tập dữ liệu NLP.
Chúng tôi hy vọng rằng quan sát này sẽ thông tin cho việc thiết kế các thí nghiệm khoa học tốt
hơn với LLM trong không gian NLP.

6 KẾT LUẬN

Chúng tôi đã đề xuất một phương pháp mới để phát hiện sự nhiễm dữ liệu trong LLM, giả định
không có quyền truy cập vào dữ liệu tiền huấn luyện của chúng. Phương pháp của chúng tôi bắt
đầu bằng việc xác định sự nhiễm dữ liệu ở cấp độ thể hiện. Điều này được đạt được bằng cách
nhắc LLM tạo ra bản sao của đoạn thứ hai của một thể hiện tập dữ liệu với đoạn ban đầu có độ
dài ngẫu nhiên, tên tập dữ liệu, và loại phân vùng, một quá trình chúng tôi gọi là "hướng dẫn có
định hướng." Từ đây, chúng tôi áp dụng một bộ quy tắc để tổng quát hóa từ sự nhiễm cấp độ thể
hiện sang sự nhiễm cấp độ phân vùng rộng hơn. Điều này liên quan đến việc tận dụng sự khác
biệt có ý nghĩa thống kê từ điểm số BLEURT và ROUGE-L giữa các phần hoàn thành được tạo ra
bởi hướng dẫn có định hướng và hướng dẫn chung, cũng như các đánh giá từ GPT-4 với prompting
học trong ngữ cảnh few-shot.

Đánh giá của chúng tôi trải dài 28 thiết lập khác nhau, bao gồm bảy tập dữ liệu cùng với các
phân vùng train và test/validation tương ứng của chúng và hai LLM: GPT-4 và GPT-3.5. Các phát
hiện của chúng tôi chỉ ra rằng trong khi kỹ thuật nhân bản qua hướng dẫn có định hướng là
đáng chú ý hiệu quả, phương pháp đánh giá chính xác nhất được căn chỉnh chặt chẽ với đánh
giá con người để phát hiện sự nhiễm dữ liệu là prompt học trong ngữ cảnh few-shot với GPT-4,
tích hợp một vài thể hiện ví dụ từ đánh giá con người trong prompt đầu vào. Phương pháp này
đạt được tỷ lệ thành công trong việc xác định sự nhiễm dữ liệu trên 14/14 tình huống cho GPT-4
và 13/14 cho GPT-3.5.¹⁰

⁹ Hai người chú thích có sự đồng thuận giữa người đánh giá gần như hoàn hảo trên tất cả các thiết lập. Điều
này là do thực tế là một tập con nhỏ các thể hiện được sử dụng để phát hiện sự nhiễm, và sự nhiễm là rõ ràng
khi nó xảy ra.

¹⁰ Hạn chế. Sự nhiễm dữ liệu có thể phát sinh từ các nguồn khác nhau và biểu hiện theo nhiều cách khác nhau,
ví dụ: bao gồm trực tiếp các thể hiện tập dữ liệu, nhiễm siêu dữ liệu, v.v. Phương pháp hiệu suất tốt nhất của
chúng tôi để phát hiện sự nhiễm (hướng dẫn có định hướng với GPT-4 ICL) không phân biệt giữa các loại sự
nhiễm khác nhau, coi cả bản sao chính xác và gần chính xác của các thể hiện tập dữ liệu như các chỉ số của
sự nhiễm dữ liệu. Do đó, chúng tôi khuyến khích nghiên cứu tương lai có thể phát hiện sự nhiễm, xác định các
nguồn của nó, và nhận dạng các hình thức khác nhau của nó.

--- TRANG 7 ---
[Continue with the remaining pages...]

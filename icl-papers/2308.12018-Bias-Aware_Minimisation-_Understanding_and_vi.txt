# 2308.12018.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/icl-papers/2308.12018.pdf
# Kích thước tệp: 597396 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Tối ưu hóa Nhận thức Độ lệch: Hiểu và Giảm thiểu 
Độ lệch Ước lượng trong SGD Riêng tư
Moritz Knolle1,2, Robert Dorfman3, Alexander Ziller1, Daniel Rueckert1,2,4và Georgios Kaissis1,2,4
1Viện AI trong Y học, Đại học Kỹ thuật Munich
2Trường Konrad Zuse về Xuất sắc trong AI Đáng tin cậy
3V7 Labs
4Imperial College London
24 tháng 8, 2023
Tóm tắt
SGD riêng tư khác biệt (DP-SGD) hứa hẹn việc áp dụng
máy học an toàn và có trách nhiệm cho các tập dữ liệu nhạy
cảm. Tuy nhiên, DP-SGD chỉ cung cấp một ước lượng có độ
lệch và nhiễu của gradient mini-batch. Điều này làm cho các
bước tối ưu hóa kém hiệu quả hơn và hạn chế tính hữu ích
của mô hình. Với công trình này, chúng tôi chỉ ra mối liên hệ
giữa chuẩn gradient từng mẫu và độ lệch ước lượng của
oracle gradient riêng tư được sử dụng trong DP-SGD. Ở đây,
chúng tôi đề xuất Tối ưu hóa Nhận thức Độ lệch (BAM) cho
phép giảm thiểu có thể chứng minh độ lệch của ước lượng
gradient riêng tư. Chúng tôi chỉ ra cách tính toán hiệu quả
các đại lượng cần thiết cho BAM để mở rộng đến các mạng
neural lớn và làm nổi bật những điểm tương đồng với các
phương pháp liên quan chặt chẽ như Tối ưu hóa Nhận thức
Độ sắc nét. Cuối cùng, chúng tôi cung cấp bằng chứng thực
nghiệm rằng BAM không chỉ giảm độ lệch mà còn cải thiện
đáng kể sự đánh đổi giữa quyền riêng tư và tính hữu ích trên
các tập dữ liệu CIFAR-10, CIFAR-100 và ImageNet-32.

1 Giới thiệu
Việc áp dụng các mô hình máy học cho tập dữ liệu chứa
thông tin nhạy cảm đòi hỏi các bảo đảm quyền riêng tư có
ý nghĩa, vì đã được chứng minh rằng việc công bố công
khai các mô hình không bảo mật được huấn luyện trên dữ
liệu nhạy cảm có thể gây ra những mối đe dọa nghiêm trọng
đối với các cá nhân đóng góp dữ liệu [1,2,3]. Vì mục đích
này, quyền riêng tư khác biệt (DP) [4], phương pháp tiêu
chuẩn vàng được chấp nhận rộng rãi để phân tích dữ liệu
bảo vệ quyền riêng tư, đã được mở rộng cho nhiều phương
pháp máy học. Quan trọng nhất, đối với máy học hiện đại,
gradient descent ngẫu nhiên riêng tư khác biệt (DP-SGD)
[5,6] đã cho phép áp dụng các mạng neural sâu mạnh mẽ
cho các tập dữ liệu nhạy cảm với các bảo đảm quyền riêng
tư có ý nghĩa.

Tuy nhiên, trên thực tế, DP-SGD đi kèm với một hình phạt
tính hữu ích đáng kể. Như chúng tôi chứng minh dưới đây,
điều này là do DP-SGD chỉ cung cấp một ước lượng gradient
có nhiễu và có độ lệch, khiến việc tối ưu hóa ổn định trong
các vùng của cảnh quan mất mát mà mang lại các mô hình
hoạt động kém. Chúng tôi chỉ ra rằng (bỏ qua nhiễu lấy mẫu),
phương sai của ước lượng gradient riêng tư được cố định
trong khi độ lệch của nó thì không. Trong công trình này,
chúng tôi cố gắng cải thiện các ước lượng gradient riêng tư
bằng cách tối thiểu hóa độ lệch của chúng. Độ lệch của một
ước lượng ˆp của giá trị thực p cơ bản của một quá trình tạo
ra các quan sát x được định nghĩa là:

Bias(ˆp, p) = Ex[ˆp] − p. (1)

Do đó, khi một ước lượng có độ lệch bằng không, nó được
gọi là không thiên vị và giá trị kỳ vọng của nó bằng đại
lượng được ước lượng. Khi ước lượng gradient, tính không
thiên vị là một tính chất hữu ích vì nó ngụ ý rằng các ước
lượng gradient –về kỳ vọng– chỉ về hướng đúng của việc
giảm.

Độ lệch trong DP-SGD xuất phát từ thao tác cắt gradient
từng mẫu, được sử dụng để thực thi một ràng buộc độ nhạy
cảm trên các gradient (được minh họa ở trên trong Hình 1).
Tuy nhiên, mặc dù tầm quan trọng của nó, bản chất của độ
lệch này và cách nó ảnh hưởng đến việc cập nhật tham số
vẫn chưa được hiểu rõ. Với công trình này, chúng tôi chỉ ra
rằng độ lệch ước lượng gradient riêng tư có liên quan mật
thiết đến chuẩn gradient từng mẫu và có thể được phân tách
thành thành phần độ lớn và thành phần hướng (Xem Phụ
lục C). Chúng tôi phát triển Tối ưu hóa Nhận thức Độ lệch
(BAM) và cung cấp bằng chứng thực nghiệm rằng phương
pháp của chúng tôi có hiệu quả (I) giảm độ lớn của độ lệch
và (II) tăng hiệu suất phân loại trên một loạt các bài kiểm
tra thị giác đầy thử thách.

--- TRANG 2 ---
2 Công trình liên quan
Sự đánh đổi độ lệch-phương sai của oracle gradient riêng tư
được thảo luận lần đầu trong [7]. Tổng quát hơn, độ lệch
liên quan đến việc cắt gradient trong SGD đã được nghiên
cứu bởi Zhang et al. [8], Qian et al. [9] và cũng trong bối
cảnh riêng tư, nơi Song et al. [10] đã chứng minh tầm quan
trọng của việc lựa chọn đúng ngưỡng cắt trong các mô hình
lồi, trong khi Chen et al. [11] đã chỉ ra rằng không có độ
lệch nào được phát sinh khi một điều kiện đối xứng trên phân
phối gradient được duy trì.

Công trình đồng thời [12,13] đã cung cấp bằng chứng thực
nghiệm rằng Tối ưu hóa Nhận thức Độ sắc nét (SAM) [14]
có thể cải thiện sự đánh đổi quyền riêng tư-tính hữu ích.
Park et al. [12] gợi ý rằng độ lớn của vector độ lệch (được
gọi là tác động của việc cắt trong công trình của họ) được
giới hạn bởi độ sắc nét. Với công trình này, chúng tôi cung
cấp bằng chứng rằng độ sắc nét, mặc dù có liên quan chặt
chẽ, có thể không phải là nguyên nhân gốc rễ quyết định độ
lệch gradient riêng tư mà đúng hơn là chuẩn gradient từng
mẫu trong một mini-batch.

3 Cơ sở lý thuyết
Quyền riêng tư khác biệt [15] (DP), là một khái niệm ổn
định về các cơ chế ngẫu nhiên hóa trên các cơ sở dữ liệu
nhạy cảm. Cho D và D′ là hai cơ sở dữ liệu (tập dữ liệu)
khác nhau chính xác ở dữ liệu của một cá nhân. Chúng tôi
ký hiệu mối quan hệ này (tức là tính kề cận của cơ sở dữ
liệu) thông qua ký hiệu ≃ và sử dụng mối quan hệ loại bỏ/
thêm một chuẩn trong suốt.

Định nghĩa 1 (Quyền riêng tư khác biệt). Một cơ chế ngẫu
nhiên M được thực hiện trên kết quả của một hàm truy vấn
q (tức là M(q(·))) bảo vệ (ε,δ)-DP nếu, đối với tất cả các
cặp cơ sở dữ liệu kề cận D và D′, và tất cả tập con S của
miền giá trị của M(q(·)):

p[M(q(D)) ∈ S] ≤ eε p[M(q(D′)) ∈ S] + δ, (2)

trong đó mối quan hệ giữa D và D′ là đối xứng. Bảo đảm
được đưa ra dựa trên tính ngẫu nhiên của M.

Để đạt được (ε, δ)-DP sử dụng nhiễu Gaussian (tức là cơ
chế Gaussian M), người ta cần hiệu chỉnh độ lớn của nhiễu
theo độ nhạy cảm (toàn cục) của hàm truy vấn:

∆2(q) = sup D≃D′ ∥q(D) − q(D′)∥2,

hoặc ∆ cho ngắn gọn. Vì việc có được một ràng buộc độ
nhạy cảm (không tầm thường) thường không thể thực hiện
được đối với gradient của mạng neural sâu, thông thường
người ta thực thi một ràng buộc thủ công bằng cách chiếu
gradient từng mẫu lên L2-ball [6]. Cùng nhau, thao tác này,
thường được gọi là cắt, tiếp theo là nhiễu Gaussian được
chia tỷ lệ phù hợp, sau đó mang lại thuật toán DP-SGD, có
thể được coi như đơn giản là truy vấn một oracle gradient
riêng tư tại mỗi bước tối ưu hóa như thấy trong Thuật toán 1:

Trong đó l là kích thước batch kỳ vọng do yêu cầu khuếch
đại lấy mẫu phụ rằng B được xây dựng thông qua một mẫu
Poisson của Tập dữ liệu D.

Thuật toán 1 Oracle gradient riêng tư ψ
Đầu vào: Mini-batch (được lấy mẫu Poisson) B = {(x1, y1), ...,(xl, yl)}, Ràng buộc Cắt C, bội số nhiễu σ, hàm mất mát L, tham số θ∈Rd
Đầu ra: ước lượng gradient riêng tư
1: for (xi, yi) in B do
2:   gi ← ∇θL(fθ(xi), yi)
3:   ḡi ← gi/max(1, ∥gi∥2/C) ▷ cắt
4: ĝpriv ← 1/l Σli=1 ḡi + N(0, σ2C2Id) ▷ nhiễu
5: return ĝpriv

3.1 Thiết lập
Chúng tôi tập trung vào học có giám sát nơi, cho một tập
dữ liệu D = {(xi, yi), ...,(xn, yn)} được rút i.i.d từ một
phân phối tích X × Y, chúng tôi muốn tìm một ánh xạ f:
X → Y, được thực hiện thông qua một mạng neural. Mạng
neural này có tham số θ∈Θ∈Rd và được huấn luyện bằng
cách tối thiểu hóa hàm mất mát thực nghiệm L(θ) := 1/n
Σni=1 L(θ, xi, yi) sử dụng DP-SGD, trong đó tại mỗi bước
tối ưu hóa, oracle gradient riêng tư được truy vấn để thu
được một ước lượng gradient được riêng tư hóa.

θ(t+1) = θ(t) − γ(t)ĝ(t)priv (3)
ĝ(t)priv = ψ(B, C, σ, L, θt) (4)

Chúng tôi bỏ chỉ số trên t để đơn giản hóa ký hiệu, giả định
chúng ta đang ở bước t trong các phân tích sau. Chúng tôi
cũng ký hiệu gradient minibatch đã cắt là ĝclip = 1/l Σli ḡi.

4 Cắt chi phối độ lệch gradient riêng tư

Vì chúng tôi quan tâm đến việc có được một phiên bản
không thiên vị của DP-SGD, trước tiên chúng tôi nghiên
cứu độ lệch được giới thiệu bằng cách xây dựng một ước
lượng riêng tư cho gradient mini-batch ĝ. Phân tích của
chúng tôi tập trung vào đại lượng:

Bias(ĝpriv, ĝ) = E[ĝpriv] − ĝ,

trong đó chúng tôi xem ĝ là cố định, tức là, gradient được
xây dựng cho một batch dữ liệu đã được quan sát để sử
dụng trong một bước của SGD thông thường. Điều này cho
phép chúng tôi tách biệt độ lệch được giới thiệu thông qua
ước lượng riêng tư của ĝ. Lưu ý rằng khi sử dụng E mà
không có chỉ số dưới, chúng tôi lấy kỳ vọng trên tất cả tính
ngẫu nhiên hiện có. Trong trường hợp của ĝpriv, tính ngẫu
nhiên này – theo giả định – chỉ do cơ chế Gaussian. Trước
tiên chúng tôi quan sát rằng nhiễu gradient này không giới
thiệu độ lệch bổ sung:

Bổ đề 1. Độ lệch của ước lượng gradient riêng tư, Bias(ĝpriv, ĝ), không bị ảnh hưởng bởi việc thêm nhiễu trong cơ chế Gaussian. Tức là,

Bias(ĝpriv, ĝ) = Bias(ĝclip, ĝ)

--- TRANG 3 ---
Chứng minh.

Bias(ĝpriv, ĝ) = E[1/l Σli=1 clip(gi) + N(0, σ2C2Id)] − ĝ (5)
= 1/l Σli=1 clip(gi) + E[N(0, σ2C2Id)] − ĝ (6)
= ĝclip − ĝ (7)
= Bias(ĝclip, ĝ) (8)

Điều này đúng vì ĝ và ĝclip được xem như được xây dựng
từ một mini-batch dữ liệu đã quan sát và các biến ngẫu nhiên
Gaussian tâm zero độc lập với nhau.

Do đó, độ lệch gradient riêng tư được gây ra chỉ bởi thao
tác cắt. Tiếp theo, chúng tôi phát triển một hàm mục tiêu
có thể chứng minh tối thiểu hóa độ lệch nói trên.

5 Một mục tiêu nhận thức độ lệch

Chúng tôi đề xuất LBAO, một mục tiêu mà, khi được tối
thiểu hóa, có thể chứng minh giảm độ lệch của các ước
lượng gradient riêng tư ĝpriv bằng cách khuyến khích chuẩn
gradient từng mẫu nhỏ:

LBAO(θ, x, y) = L(θ, x, y) + λ(1/l Σli=1 ∥gi∥2) (9)
                   |_______|   |__________________|
                   mất mát gốc    hạng mục điều hòa

có thể được lấy mẫu phụ như sau:

LBAO(θ, xi, yi) = L(θ, xi, yi) + λ∥gi∥2 (10)

Để thúc đẩy mục tiêu tối ưu hóa này, bây giờ chúng tôi sẽ
chứng minh sự phụ thuộc chính của Bias(ĝpriv, ĝ) vào chuẩn
gradient từng mẫu cho một ngưỡng cắt C cố định.

Bổ đề 2. Một chuẩn gradient từng mẫu ∥gi∥2 nhỏ hơn của
mẫu thứ i trong một mini-batch giảm Bias(ĝpriv, ĝ).

Chứng minh. Trước tiên lưu ý rằng

clip(gi) = gi/max(1, ∥gi∥2/C) = {
  gi nếu ∥gi∥2 ≤ C
  Cgi/∥gi∥2 nếu ∥gi∥2 > C.

Do đó, nếu ∥gi∥2 ≤ C cho mọi i trong mini-batch, thì theo
Bổ đề 1:

Bias(ĝpriv, ĝ) = 1/l Σli=1 gi − ĝ = 0.

Tức là, nếu chuẩn L2 của gradient của mini-batch đều dưới
ngưỡng cắt, độ lệch của ước lượng gradient riêng tư giảm
về zero. Mặt khác, nếu ∥gi∥2 > C:

Bias(ĝpriv, ĝ) = 1/l Σli=1 C/∥gi∥2 gi − ĝ. (11)

Do đó, độ lệch phụ thuộc vào các tỷ lệ C/∥gi∥2 ∀i: khi
một chuẩn gradient từng mẫu ∥gi∥2 trở nên lớn hơn C ngày
càng nhiều, độ lệch tăng (lưu ý rằng ở đây "tăng" có nghĩa
là xa gốc tọa độ hơn). Ngược lại, nếu chúng ta tối thiểu hóa
∥gi∥2 cho bất kỳ i nào, độ lệch sẽ co lại cho đến khi tất cả
∥gi∥2 trong mini-batch nhỏ hơn C, tại thời điểm đó ước
lượng trở thành không thiên vị.

Lưu ý rằng (9) tương tự như hình phạt chuẩn gradient, được
sử dụng bởi [16] để khuyến khích tính phẳng của cảnh quan
mất mát:

LZ(θ) = L(θ) + ∥∇θL(θ)∥2, (12)

Có thể chỉ ra rằng (9) là cận trên của LZ (xem Phụ lục B).
Điều này có nghĩa là việc giảm LBAO ngụ ý việc giảm LZ,
nhưng điều ngược lại thường không đúng. Cũng lưu ý rằng
LZ không cho phép phân tích từng mẫu cần thiết cho DP,
ngăn cản việc áp dụng đơn giản DP-SGD [12].

5.1 Tính toán hiệu quả

Thực hiện LBAO một cách ngây thơ là có vấn đề, vì việc
tính toán gradient bây giờ liên quan đến việc tính toán Tích
Hessian-Vector (HVP) cho mọi mẫu:

∇θLBAO(θ, x, y) = ∇θL(θ, x, y) + λ(1/n) Σli=1 [∇2θL(θ, xi, yi)∇θL(θ, xi, yi)]/∥∇θL(θ, xi, yi)∥2
                                                    |___________________|
                                                           HVP     (13)

Mục tiêu này do đó tốn kém để tính toán cho các mạng sâu
sử dụng tự động vi phân chế độ ngược (AD) [17]. Tuy nhiên,
may mắn thay, công trình trước đó đã chỉ ra rằng HVP có
thể được tính toán hiệu quả, trong trường hợp này, hoặc
chính xác bằng cách sử dụng kết hợp AD chế độ thuận và
ngược [18,19], hoặc gần đúng bằng cách sử dụng bước leo
gradient cục bộ của SAM [16].

6 Phương pháp

Để giảm độ lệch của oracle gradient riêng tư trong DP-SGD,
chúng tôi tối ưu hóa mục tiêu nhận thức độ lệch LBAO của
chúng tôi và xấp xỉ các gradient từng mẫu cần thiết. Cụ thể,
chúng tôi thực hiện bước leo gradient cục bộ của SAM, ở
cấp độ mẫu trước khi tính toán gradient:

∇θLBAO(θ, xi, yi) ≈ ∇θL(θ, xi, yi)|θ=θ+λ∇θL(θ,xi,yi)/∥∇θL(θ,xi,yi)∥2. (14)

Toàn bộ quy trình huấn luyện được tóm tắt trong Thuật toán 2.
Lưu ý rằng, vì ∇θLBAO(θ, xi, yi) chỉ phụ thuộc vào thống
kê cấp mẫu, quá trình lấy mẫu giống hệt với DP-SGD và
tất cả các đại lượng được riêng tư hóa như trong DP-SGD,
mọi lần lặp t của Thuật toán 2 đều thỏa mãn (ε, δ)-DP với
các tham số quyền riêng tư giống hệt như DP-SGD.

--- TRANG 4 ---
Tập dữ liệu ε δ DP-SGD DP-SAT BAM (của chúng tôi)
CIFAR-10 1.0 10−5 60.9±0.49 60.9±0.62 61.4±0.48
         2.0        67.1±0.10 67.2±0.30 68.2±0.27
         10.0       78.6±0.08 78.1±0.69 79.7±0.13
CIFAR-100 1.0 10−5 18.1±0.10 18.2±0.13 18.5±0.04
          2.0       24.9±0.46 24.9±0.35 25.4±0.40
          10.0      40.3±0.21 40.1±0.19 40.8±0.06
ImageNet32 10.0 8×10−7 14.97 14.70 20.67

Bảng 1: Độ chính xác kiểm tra (trung bình ±SD %) cho CIFAR-10, CIFAR-100 và ImageNet32 được tính toán trên ba hạt giống ngẫu nhiên tại các (ε, δ) khác nhau. Do ràng buộc tài nguyên tính toán, chúng tôi chỉ báo cáo một lần chạy huấn luyện duy nhất cho Imagenet32.

Thuật toán 2 Tối ưu hóa Nhận thức Độ lệch (BAM)
1: for t ∈ 1,2, ..., T do
2:   B ← Mẫu Poisson của D với xác suất q
3:   for (xi, yi) ∈ B do
4:     θ′(t) ← θ(t) + λ(t)∇θL(θ(t),xi,yi)/∥∇θL(θ(t),xi,yi)∥2 ▷ bước SAM
5:     g(t)i ← ∇θ′LBAO(θ′(t), xi, yi)
6:     ḡ(t)i ← g(t)i/max(1, ∥g(t)i∥2/C) ▷ cắt
7:     ĝ(t)priv = 1/l Σli [ḡ(t)i + N(0, σ2C2Id)] ▷ nhiễu
8:   θ(t+1) = θ(t) − γ(t)ĝ(t)priv

7 Kết quả

Để đánh giá phương pháp đề xuất của chúng tôi và so sánh
hiệu suất của nó với DP-SGD và DP-SAT [12], chúng tôi
thực hiện một loạt thí nghiệm trên các tập dữ liệu thị giác
máy tính đầy thử thách. Kết quả cho CIFAR-10/100 [20] và
ImageNet32 [21] được báo cáo ở trên trong Bảng 1. Chúng
tôi sử dụng các thực hành huấn luyện tối tân (SOTA) cho
DP-SGD [22], cụ thể là: chuẩn hóa trọng số, chuẩn hóa
nhóm, kích thước batch lớn và độ đa dạng tăng cường. Chi
tiết thí nghiệm đầy đủ và các giá trị siêu tham số có thể được
tìm thấy trong Bảng 2, Phụ lục A.

[Hình 2: BAM giảm thiểu độ lệch hiệu quả: Độ lớn của
vector độ lệch được đo trên CIFAR-10 ở kích thước batch
512 thấp hơn đáng kể đối với BAM, trong khi DP-SAT gây
ra độ lệch tương tự như DP-SGD.]

Chúng tôi thấy rằng BAM giảm thiểu độ lệch gradient riêng
tư hiệu quả trong thực tế (xem Hình 2 ở trên). Mặt khác,
DP-SAT phần lớn không có tác động đến độ lệch ước lượng
cho các giá trị của tham số điều hòa λ mang lại các mô hình
hiệu suất cao. Các so sánh thời gian chạy thực nghiệm thêm
(dữ liệu được hiển thị trong Phụ lục A) tiết lộ rằng trong
khi cả việc tính toán gradient chính xác và xấp xỉ cho BAM
đều phát sinh chi phí tính toán cao hơn DP-SAT (và DP-SGD),
gánh nặng này có thể quản lý được đối với hầu hết các mạng
có kích thước thực tế với ít hơn 200 lớp. Cuối cùng, so sánh
hiệu suất thực nghiệm của chúng tôi tiết lộ rằng khi sử dụng
kích thước batch rất lớn và các thực hành SOTA khác của
De et al. [22], lợi ích hiệu suất trên các tập dữ liệu thử thách
hơn được thực hiện thông qua DP-SAT nhỏ hơn so với
được báo cáo trong ấn phẩm gốc [12]. Ngược lại, BAM liên
tục cải thiện hiệu suất qua các ngân sách quyền riêng tư
khác nhau (Bảng 1).

8 Thảo luận

Sau khi suy ra độ lệch của oracle gradient riêng tư từ các
nguyên tắc đầu tiên, chúng tôi đã phát triển một mục tiêu
điều hòa nhận thức độ lệch LBAO đã được xác nhận thực
nghiệm hiệu quả trong việc tối thiểu hóa vector độ lệch liên
quan đến ước lượng gradient riêng tư. Chúng tôi cũng chứng
minh rằng sử dụng xấp xỉ SAM như được đề xuất bởi [16],
mục tiêu của chúng tôi và gradient của nó có thể tính toán
được với chi phí tính toán có thể quản lý.

Phương pháp của chúng tôi thực hiện bước leo gradient cục
bộ (bước SAM) ở cấp độ từng mẫu và do đó có liên quan
chặt chẽ đến phương pháp DP-SAT của [12], thực hiện bước
leo với gradient mini-batch được riêng tư hóa của lần lặp
trước. Các thí nghiệm của chúng tôi cho thấy rằng phương
pháp của chúng tôi vượt trội hơn DP-SAT trong việc tối
thiểu hóa độ lệch, điều này được phản ánh trong độ chính
xác vượt trội của các mô hình được huấn luyện với BAM.
Đáng chú ý, phương pháp của chúng tôi mang lại sự gia
tăng độ chính xác hơn 5% trên tập dữ liệu thử thách nhất
được kiểm tra, ImageNet32. Dựa trên kết quả của chúng
tôi, chúng tôi giả thuyết rằng, với các thực hành huấn luyện
riêng tư hiện đại [22] (kích thước batch rất lớn, tốc độ học
lớn), gradient nhiễu của lần lặp trước (ĝ(t−1)priv), là một
xấp xỉ kém để tìm mất mát tối đa trong vùng lân cận cục
bộ xung quanh giá trị tham số của lần lặp hiện tại θ(t). Điều
này được chứng thực bởi một thí nghiệm đơn giản (dữ liệu
được hiển thị trong Hình 4, Phụ lục A) cho thấy vector
bước leo được sử dụng trong DP-SAT chỉ về các hướng
hơi khác với gradient mini-batch (không riêng tư) của lần
lặp hiện tại được sử dụng thông thường trong SAM.

Kết quả của chúng tôi, mặc dù không phải không có hạn
chế (BAM phát sinh chi phí tính toán nhẹ), đã chỉ ra rằng
việc giảm độ lệch gradient riêng tư có thể dẫn đến sự gia
tăng hiệu suất hiệu quả trên các tập dữ liệu hình ảnh thử
thách.

--- TRANG 5 ---
Đánh giá thực nghiệm rộng rãi hơn, đặc biệt trên các tập
dữ liệu quy mô lớn như ImageNet (kích thước đầy đủ), là
công việc đang thực hiện và cần thiết để đánh giá đầy đủ
lợi ích của nó. Cuối cùng, công việc tương lai nên điều tra
hiệu quả của các phương pháp thay thế khuyến khích tính
mượt mà [23] và xem xét các kết nối đến và tác động đến
tính công bằng của mô hình đối với các nhóm con [24].

9 Lời cảm ơn

Bài báo này được hỗ trợ bởi chương trình DAAD Konrad
Zuse Schools of Excellence in Artificial Intelligence, được
tài trợ bởi Bộ Giáo dục và Nghiên cứu Liên bang.

Tài liệu tham khảo

[1] Jonas Geiping, Hartmut Bauermeister, Hannah Dröge,
và Michael Moeller. Inverting gradients-how easy is it to
break privacy in federated learning? Advances in Neural
Information Processing Systems, 33:16937–16947, 2020.

[2] Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew
Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam
Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, et al.
Extracting training data from large language models. In
30th USENIX Security Symposium (USENIX Security 21),
trang 2633–2650, 2021.

[3] Nicholas Carlini, Chang Liu, Úlfar Erlingsson, Jernej
Kos, và Dawn Song. The secret sharer: Evaluating and
testing unintended memorization in neural networks. In
28th USENIX Security Symposium (USENIX Security 19),
trang 267–284, 2019.

[4] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Foundations and Trends®
in Theoretical Computer Science, 9(3–4):211–407, 2014.

[5] Reza Shokri và Vitaly Shmatikov. Privacy-preserving
deep learning. In Proceedings of the 22nd ACM SIGSAC
conference on computer and communications security,
trang 1310–1321, 2015.

[6] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan
McMahan, Ilya Mironov, Kunal Talwar, và Li Zhang.
Deep learning with differential privacy. In Proceedings
of the 2016 ACM SIGSAC conference on computer and
communications security, trang 308–318, 2016.

[7] H Brendan McMahan, Daniel Ramage, Kunal Talwar, và
Li Zhang. Learning differentially private recurrent language models. In International Conference on Learning
Representations, 2018.

[8] Jingzhao Zhang, Tianxing He, Suvrit Sra, và Ali Jadbabaie. Why gradient clipping accelerates training: A
theoretical justification for adaptivity. In International
Conference on Learning Representations, 2019.

[9] Jiang Qian, Yuren Wu, Bojin Zhuang, Shaojun Wang, và
Jing Xiao. Understanding gradient clipping in incremental
gradient methods. In International Conference on Artificial Intelligence and Statistics, trang 1504–1512. PMLR,
2021.

[10] Shuang Song, Om Thakkar, và Abhradeep Thakurta.
Characterizing private clipped gradient descent on
convex generalized linear problems. arXiv preprint
arXiv:2006.06783, 2020.

[11] Xiangyi Chen, Steven Z Wu, và Mingyi Hong. Understanding gradient clipping in private sgd: A geometric
perspective. Advances in Neural Information Processing
Systems, 33:13773–13782, 2020.

[12] Jinseong Park, Hoki Kim, Yujin Choi, và Jaewook Lee.
Differentially private sharpness-aware training. In International Conference on Machine Learning, trang XXXX–
YYYY. PMLR, 2023.

[13] Yifan Shi, Yingqi Liu, Kang Wei, Li Shen, Xueqian Wang,
và Dacheng Tao. Make landscape flatter in differentially private federated learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition, trang 24552–24562, 2023.

[14] Pierre Foret, Ariel Kleiner, Hossein Mobahi, và
Behnam Neyshabur. Sharpness-aware minimization for
efficiently improving generalization. arXiv preprint
arXiv:2010.01412, 2020.

[15] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. 2014.

[16] Yang Zhao, Hao Zhang, và Xiuyuan Hu. Penalizing
gradient norm for efficiently improving generalization in
deep learning. In International Conference on Machine
Learning, trang 26982–26992. PMLR, 2022.

[17] Ryo Karakida, Tomoumi Takase, Tomohiro Hayase, và
Kazuki Osawa. Understanding gradient regularization in
deep learning: Efficient finite-difference computation and
implicit bias. arXiv preprint arXiv:2210.02720, 2022.

[18] Alex Wiltschko và Matthew Johnson. Jax autodiff cookbook, n.d. Truy cập ngày 20 tháng 6, 2023.
https://jax.readthedocs.io/en/latest/notebooks/
autodiff cookbook.html.

[19] Barak A Pearlmutter. Fast exact multiplication by the
hessian. Neural computation, 6(1):147–160, 1994.

[20] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.

[21] Patryk Chrabaszcz, Ilya Loshchilov, và Frank Hutter. A
downsampled variant of imagenet as an alternative to the
cifar datasets. arXiv preprint arXiv:1707.08819, 2017.

[22] Soham De, Leonard Berrada, Jamie Hayes, Samuel L
Smith, và Borja Balle. Unlocking high-accuracy differentially private image classification through scale. arXiv
preprint arXiv:2204.13650, 2022.

--- TRANG 6 ---
[23] Junbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-Cheol
Cho, Seunghyun Park, Yunsung Lee, và Sungrae Park.
Swad: Domain generalization by seeking flat minima.
Advances in Neural Information Processing Systems, 34:
22405–22418, 2021.

[24] Cuong Tran, My Dinh, và Ferdinando Fioretto. Differentially private empirical risk minimization under the
fairness lens. Advances in Neural Information Processing
Systems, 34:27555–27565, 2021.

[25] Timothy Dozat. Incorporating nesterov momentum into
adam. 2016.

[26] James Bradbury, Roy Frostig, Peter Hawkins,
Matthew James Johnson, Chris Leary, Dougal Maclaurin,
George Necula, Adam Paszke, Jake VanderPlas, Skye
Wanderman-Milne, và Qiao Zhang. JAX: composable
transformations of Python+NumPy programs, 2018. URL
http://github.com/google/jax.

[27] Sepp Hochreiter và Jürgen Schmidhuber. Flat minima.
Neural computation, 9(1):1–42, 1997.

A Chi tiết thí nghiệm & kết quả thêm

Để có được các giá trị siêu tham số phù hợp cho các phương
pháp được so sánh (được báo cáo ở trên trong Bảng 2), tìm
kiếm ngẫu nhiên được sử dụng đầu tiên bằng DP-SGD, sau
đó một tìm kiếm riêng biệt cho các giá trị λ tối ưu được thực
hiện cho cả DP-SAT và BAM với N=200 thử nghiệm ngẫu
nhiên mỗi cái. Đối với Imagenet32, chỉ tìm kiếm siêu tham
số quy mô rất nhỏ được sử dụng do chi phí tính toán cao.
Độ đa dạng tăng cường, như được mô tả trong [22], được
sử dụng với xác suất p = 0.5 (cho mỗi tăng cường) trên tất
cả các phương pháp được so sánh với dịch chuyển pixel
ngẫu nhiên (lên đến 4 pixel) và lật dọc ngẫu nhiên. Tất cả
các mô hình được huấn luyện trong 75 epoch với bộ tối ưu
NAdam [25] và, ngoài tốc độ học (LR), các siêu tham số
mặc định khác. Để đáp ứng các yêu cầu ngân sách quyền
riêng tư (ε, δ) khác nhau, bội số nhiễu σ2 được điều chỉnh
tương ứng.

A.1 Các khía cạnh tính toán

[Hình 3: Thời gian chạy trên tường mỗi bước (trung bình ±SD)
cho các phương pháp tính toán khác nhau để giảm thiểu độ
lệch trong DP-SGD cho độ sâu mạng tăng. Kết quả được
tính toán qua mười thử nghiệm và năm lần lặp lại.]

Chúng tôi đánh giá độ phức tạp thời gian chạy thực nghiệm
của hai phương pháp đã đề cập trước đó để tính toán
∇θLBAO(θ, xi, yi). Cụ thể, chúng tôi so sánh AD chế độ
thuận-qua-ngược (BAM FWD-REV) và xấp xỉ SAM (BAM
SAM) để tính toán gradient cần thiết cho BAM và so sánh
với DP-SAT [12]. DP-SAT sử dụng gradient mini-batch được
riêng tư hóa của bước trước để xấp xỉ (12) mà không có chi
phí quyền riêng tư bổ sung và ít chi phí tính toán. Hình 3
giới thiệu kết quả của so sánh thời gian chạy thực nghiệm
trên tập dữ liệu đồ chơi, được thực hiện trong jax [26] và
biên dịch với XLA để có được so sánh công bằng giữa các
phương pháp.

A.2 Hiệu quả bước leo gradient

Để điều tra hiệu quả của bước leo gradient trong DP-SAT
và BAM, chúng tôi điều tra độ tương tự cosine giữa hướng
leo được sử dụng bởi phương pháp tương ứng và hướng
leo (sự thật cơ bản) như được sử dụng trong SAM, tức là
gradient mini-batch không riêng tư, hiện tại. Các phát hiện
của chúng tôi (dưới đây trong Hình 4) chỉ ra rằng bước leo
gradient từng mẫu của DP-SAT được căn chỉnh tốt hơn
đáng kể với bước leo SAM không riêng tư so với bước leo
với gradient được riêng tư hóa của lần lặp trước của phương
pháp DP-SAT. Cụ thể, chúng tôi thấy các bước leo DP-SAT
chỉ về các hướng hơi đối lập, như được chỉ ra bởi một độ
tương tự cosine nhỏ, nhưng âm.

[Hình 4: Hiệu quả của bước leo trong suốt quá trình huấn
luyện trên CIFAR-10 (ba lần lặp lại) với DP-SAT và BAM
được đo bằng độ tương tự cosine cos(ĝ(t−1)priv, ĝ(t)) và
1/l Σli cos(g(t)i, ĝ(t)) tương ứng.]

A.3 C. Kích thước batch và tác động của nó đến độ lệch
và lỗi hướng

Để điều tra thành công thực nghiệm của các công trình gần
đây sử dụng kích thước batch cực lớn (hoặc thậm chí huấn
luyện batch đầy đủ), chúng tôi điều tra tác động của kích
thước batch đến độ lệch gradient riêng tư và thành phần
hướng của nó.

--- TRANG 7 ---
Tập dữ liệu Phương pháp λ Mô hình Kích thước-batch LR C Độ đa dạng
CIFAR-10 DP-SGD 0.0 ResNet-9 32×128 2e-3 1 16
DP-SAT 0.086
BAM 0.02
CIFAR-100 DP-SGD 0.0 ResNet-9 32×128 2e-3 1 16
DP-SAT 0.086
BAM 0.01
ImageNet32 DP-SGD 0.0 WideResNet-16-4 8×512 1e-3 1 4
DP-SAT 0.07
BAM 0.005

Bảng 2: Các giá trị siêu tham số cho thí nghiệm trên CIFAR-10, CIFAR-100 và ImageNet32.

[Hình 5: Batch lớn hơn giảm độ lớn độ lệch gradient riêng
tư. Hình này giới thiệu độ lớn độ lệch được tính trung bình
qua các lần lặp huấn luyện khi huấn luyện trên CIFAR-10
với DP-SGD với các kích thước batch khác nhau.]

[Hình 6: Batch lớn hơn giảm thành phần hướng của độ lệch
gradient riêng tư được đo bằng sự gia tăng độ tương tự
cosine trung bình giữa gradient mini-batch đã cắt và chưa
cắt trong quá trình huấn luyện trên CIFAR-10.]

Chúng tôi thấy batch lớn giảm cả: độ lớn của vector độ lệch
và các thành phần hướng của vector độ lệch. Cái sau được
chỉ ra bởi sự gia tăng độ tương tự cosine giữa gradient đã
cắt và chưa cắt.

B BAM và tác động đến tính phẳng của cảnh quan mất mát

Tối thiểu hóa (9) có lợi ích bổ sung là làm mượt cảnh quan
tối ưu hóa xung quanh các cực tiểu (cực tiểu phẳng) mà,
như ban đầu được lập luận bởi Hochreiter và Schmidhuber
[27], được tin rằng rộng rãi cung cấp hiệu suất tổng quát
hóa tốt hơn so với cực tiểu sắc nét. Để tìm các cực tiểu
phẳng như vậy, Zhao et al. [16] đề xuất mục tiêu:

LZ(θ) = L(θ) + λ∥∇θL(θ)∥2 (15)
= L(θ) + λ∥1/n Σni=1 gi∥2 (16)

Mục tiêu này tìm cực tiểu phẳng vì ∥∇θL(θ)∥2 xấp xỉ hằng
số Lipschitz của hàm mất mát L. Hằng số Lipschitz là một
cận trên về mức độ thay đổi độ lớn của một thay đổi trong
không gian tham số thay đổi độ lớn của mất mát. Đây là
một cách nắm bắt "tính phẳng": hằng số Lipschitz của hàm
mất mát càng nhỏ, cực tiểu càng phẳng (vì cùng một thay
đổi trong θ sẽ dẫn đến một cận nhỏ hơn về thay đổi trong
độ lớn mất mát). Do đó, bằng cách giảm hằng số Lipschitz
của hàm mất mát, giải pháp sẽ được đẩy về phía một cực
tiểu phẳng hơn.

Tuy nhiên, mục tiêu (15) không thể được sử dụng trong
trường hợp của chúng ta vì nó không cho phép phân tích
từng mẫu cần thiết cho DP. Tuy nhiên, chúng ta có thể chỉ
ra điều sau:

Bổ đề 3. Mục tiêu nhận thức độ lệch LBAO (9) là cận trên
của mục tiêu LZ (15) của [16].

Chứng minh. Điều này theo từ bất đẳng thức tam giác:

L(θ) + λ∥1/n Σni=1 gi∥2 = L(θ) + λ(1/n)∥Σni=1 gi∥2 (17)
≤ L(θ) + λ(1/n) Σni=1 ∥gi∥2. (18)

Do đó, tối thiểu hóa LBAO sẽ bổ sung đẩy giải pháp đến
một cực tiểu phẳng bằng cách tối thiểu hóa một cận trên
của (15).

--- TRANG 8 ---
C Một phân tách có ý nghĩa của gradient riêng tư

[Hình 7: Minh họa phân tách độ lệch đề xuất (a) thành các
thành phần vector trực giao (b): độ lớn a và hướng c.]

Với mục đích nắm bắt tốt hơn bản chất bệnh lý của việc
cắt trong tối ưu hóa ngẫu nhiên riêng tư, chúng tôi đề xuất
một phân tách độ lệch thành các thành phần trực giao cho
phép tách biệt lỗi ước lượng độ lớn và hướng.

Trong trường hợp của chúng ta, chúng ta có một ước lượng
ĝpriv của ĝ. Bây giờ chúng ta chỉ ra một phân tách của ĝpriv
theo ĝ, điều này sẽ cho phép chúng ta phân biệt độ lệch có
hại với không có hại.

Định lý 1. Ước lượng gradient riêng tư ĝpriv có thể được
phân tách như:

ĝpriv = a · ĝ + c,

trong đó a ∈ R, c ∈ Rd. Chúng ta gọi a là lỗi độ lớn và c
là lỗi hướng phát sinh thông qua ước lượng (riêng tư).

Chứng minh. Trước tiên chúng ta liên hệ mỗi gradient từng
mẫu gi với gradient mini-batch ĝ thông qua một phân tách
vector thành các thành phần trực giao.

gi = projĝgi + τi

trong đó projĝgi = ⟨gi, ĝ⟩/∥ĝ∥2 · ĝ và τi là một vector phù
hợp trực giao với phép chiếu. Cho ηi = ⟨gi, ĝ⟩/∥ĝ∥2, phân
tách là:

projĝgi = ηi · ĝ + τi. (19)

Sử dụng phân tách này bên trong hàm clip cho chúng ta:

clip(gi) = gi/max(1, C/∥gi∥2) = (ηiĝ + τi)/max(1, C/∥gi∥2). (20)

Bây giờ, cho Mi = max(1, C/∥gi∥2) để chúng ta có thể đơn
giản hóa ở trên như

clip(gi) = ηi/Mi ĝ + τi/Mi. (21)

Tính trung bình gradient đã cắt qua mini-batch mang lại:

ĝclip = 1/l Σli=1 clip(gi) (22)
= 1/l Σli=1 (ηi/Mi ĝ + τi/Mi) (23)
= (1/l Σli=1 ηi/Mi) · ĝ + (1/l Σli=1 τi/Mi). (24)

Cuối cùng, nhiễu mỗi gi với một vector βi ~ N(0, CσId)
chúng ta thu được phân tách mong muốn theo lỗi độ lớn a
và lỗi hướng c:

ĝpriv = 1/l Σli=1 (clip(gi) + βi) (25)
= (1/l Σli=1 ηi/Mi) · ĝ + (1/l Σli=1 (τi/Mi + βi)) (26)
      |_______________|        |________________________|
             a                              c

Điều này cho phép chúng ta bây giờ tách biệt hiệu quả các
thành phần hướng từ độ lớn của độ lệch gradient riêng tư:

Bias(ĝpriv, ĝ) = E[ĝpriv] − ĝ (27)
= E[a · ĝ + c] − ĝ. (28)

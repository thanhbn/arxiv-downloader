# 2209.11883.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/hebbian/2209.11883.pdf
# Kích thước tệp: 32236798 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023
Học sâu Hebbian không có phản hồi
Adrien Journ´ e1, Hector Garcia Rodriguez1, Qinghai Guo2, Timoleon Moraitis1*
{adrien.journe, hector.garcia.rodriguez, guoqinghai, timoleon.moraitis }@huawei.com
Tóm tắt
Các xấp xỉ gần đây của lan truyền ngược (BP) đã giảm thiểu nhiều 
vấn đề về hiệu quả tính toán và tương thích sinh học của BP, nhưng 
vẫn còn những hạn chế quan trọng. Hơn nữa, các xấp xỉ này làm 
giảm đáng kể độ chính xác trong các bài kiểm tra, cho thấy một cách 
tiếp cận hoàn toàn khác có thể hiệu quả hơn. Ở đây, dựa trên lý thuyết 
gần đây về học Hebbian trong mạng winner-take-all mềm, chúng tôi 
trình bày SoftHebb đa lớp, tức là một thuật toán huấn luyện mạng 
nơ-ron sâu, không có bất kỳ phản hồi, mục tiêu hay tín hiệu lỗi nào. 
Kết quả là, nó đạt được hiệu quả bằng cách tránh vận chuyển trọng 
số, tính dẻo không cục bộ, khóa thời gian của các bản cập nhật lớp, 
cân bằng lặp lại, và tín hiệu giám sát (tự) hay phản hồi khác - những 
thứ cần thiết trong các phương pháp khác. Hiệu quả tăng và tương 
thích sinh học của nó không làm giảm độ chính xác so với học tập 
tương thích sinh học tiên tiến, mà còn cải thiện nó. Với tối đa năm 
lớp ẩn và một bộ phân loại tuyến tính được thêm vào, độ chính xác 
trên MNIST, CIFAR-10, STL-10, và ImageNet, tương ứng đạt 99.4%, 
80.3%, 76.2%, và 27.3%. Kết luận, SoftHebb cho thấy với một cách 
tiếp cận hoàn toàn khác với BP rằng Học sâu trên vài lớp có thể khả 
thi trong não và tăng độ chính xác của học máy tương thích sinh học. 
Mã nguồn có tại https://github.com/NeuromorphicComputing/SoftHebb .

1 Giới thiệu: Lan truyền ngược và những hạn chế của nó
Thuật toán cốt lõi trong học sâu (DL) là lan truyền ngược (BP), hoạt động bằng cách đầu tiên 
định nghĩa một hàm lỗi hoặc mất mát giữa đầu ra của mạng nơ-ron và đầu ra mong muốn. 
Mặc dù có tính hữu ích thực tế to lớn (Sejnowski, 2020), BP yêu cầu các phép toán làm cho 
việc huấn luyện trở thành một quá trình tốn kém về mặt tính toán, đặt ra giới hạn cho khả năng 
áp dụng của nó trong các tình huống hạn chế tài nguyên. Ngoài ra, những phép toán tương tự 
phần lớn không tương thích với việc học sinh học, đòi hỏi các giải pháp thay thế. Trong phần 
sau, chúng tôi mô tả những hạn chế này và tầm quan trọng của chúng đối với DL, phần cứng 
tính toán neuromorphic, và khoa học thần kinh. Đáng chú ý, sau bản tiền in của bài báo này, 
Hinton (2022) đã trình bày một thuật toán với những cân nhắc tương tự.

Vận chuyển trọng số. Lan truyền ngược lỗi liên quan đến ma trận chuyển vị của các trọng 
số kết nối tiến. Điều này không thể trong sinh học, vì các synapse là đơn hướng. Độ dẫn synaptic 
cũng không thể được vận chuyển đến các synapse ngược riêng biệt. Đó là vấn đề vận chuyển 
trọng số (Grossberg, 1987; Crick, 1989), và nó cũng ngăn cản việc học trên các nền tảng phần 
cứng hiệu quả năng lượng (Crafton et al., 2019) như phần cứng tính toán neuromorphic, một 
trong những cách tiếp cận được nghiên cứu nhiều nhất để vượt qua các nút thắt hiệu quả 
và mở rộng của kiến trúc von Neumann làm nền tảng cho các chip máy tính ngày nay (Indiveri, 
2021). Một yếu tố quan trọng của chiến lược neuromorphic là đặt tính toán trong cùng các 
thiết bị cũng lưu trữ bộ nhớ, tương tự như các synapse sinh học, thực hiện tính toán nhưng 
cũng lưu trữ trọng số (Sebastian et al., 2020; Sarwat et al., 2022a;b). Tuy nhiên, trong BP, 
việc chuyển vị của các bộ nhớ được lưu trữ là cần thiết cho việc vận chuyển trọng số, và điều 
này ngụ ý chi phí mạch và năng lượng đáng kể, bằng cách ngăn cản việc triển khai hoàn toàn 
trong bộ nhớ của công nghệ neuromorphic (Crafton et al., 2019).

Tính dẻo không cục bộ. BP không thể cập nhật mỗi trọng số chỉ dựa trên các kích hoạt 
trực tiếp của hai nơ-ron mà trọng số kết nối, tức là các nơ-ron tiền và hậu synapse, vì

1Trung tâm Nghiên cứu Huawei Zurich, Thụy Sĩ2Phòng thí nghiệm ACS Huawei, Thâm Quyến, Trung Quốc
*Tác giả liên hệ
1arXiv:2209.11883v2  [cs.NE]  2 Aug 2023

--- TRANG 2 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023
Bảng 1: Độ chính xác trên CIFAR-10, và chất lượng tương thích sinh học và hiệu quả tính toán, 
cho các thuật toán khác nhau. Loại thuật toán của SoftHebb có tất cả bốn đặc tính hiệu quả 
và khả thi. SoftHebb cũng đạt độ chính xác cao nhất, ngoại trừ backprop, và việc học không 
giám sát của nó chỉ liên quan đến một epoch duy nhất. Lưu ý, tìm kiếm tài liệu của chúng tôi 
không bị giới hạn bởi số lượng lớp, nhưng kết quả của nó thì có.

Đặc tính | Độ chính xác | Lớp | Thuật toán | Tài liệu tham khảo
99.4 | 152 | Kolesnikov et al. 2020
84.0 | 4 | Backprop (cross-entropy)
Backprop (cross-entropy) | Của chúng tôi
71.8 | 5 | Feedback Alignment | Frenkel et al. 2021
∼60 | 6 | Predictive Coding | Millidge et al. 2020
13.4 | 5 | Equilibrium Propagation (2-phase) | Laborieux et al. 2021
78.5 | 5 | EP (2-phase, random sign) | Laborieux et al. 2021
79.9 | 5 | Burstprop | Payeur et al. 2021
61.0 | 5 | BurstCCN | Greedy et al. 2022
70.5 | 5 | Direct Feedback Alignment | Frenkel et al. 2021
71.5 | 5 | DFA (untrained convs) | Frenkel et al. 2021
65.6 | 5 | Direct Random Target Projection | Frenkel et al. 2021
69.0 | 5 | DRTP (untrained convs) | Frenkel et al. 2021
73.1 | 5 | Single Sparse DFA | Crafton et al. 2019
53.5 | 11 | Latent Predictive Learning | Halvagal and Zenke 2022
73.7 | 4 | Self Organising Maps | Stuhr and Brauer 2019
72.2 | 2 | Hard WTA | Grinberg et al. 2019
64.6 | 4 | Hard WTA | Miconi 2021

Không vận chuyển trọng số
Tính dẻo cục bộ
Không khóa cập nhật
Không giám sát | 80.3 | 4 | SoftHebb (1 epoch) | Của chúng tôi

nó yêu cầu tín hiệu lỗi, được tính toán tại một thời điểm khác và ở nơi khác 
trong mạng, tức là tại đầu ra. Điều đó làm cho BP không cục bộ về không gian và thời gian, 
đây là sự khác biệt quan trọng so với tính cục bộ được tin là chi phối tính dẻo synaptic sinh 
học nói chung (Baldi et al., 2017). Tính không cục bộ này ngụ ý thêm những bất hiệu quả 
tính toán. Cụ thể, các biến truyền tiến phải được ghi nhớ, làm tăng yêu cầu bộ nhớ (L¨ owe 
et al., 2019). Hơn nữa, các tín hiệu ngược bổ sung phải được tính toán và truyền, làm tăng 
các phép toán và dòng điện. Đáng chú ý là những khía cạnh này không chỉ giới hạn các công 
nghệ neuromorphic tương lai, mà ngay cả nền tảng phần cứng của DL ngày nay, tức là các 
đơn vị xử lý đồ họa (GPU), có những hạn chế riêng về bộ nhớ và FLOPS.

Khóa cập nhật. Lỗi được quy cho một synapse bởi BP chỉ có thể được tính toán sau khi 
thông tin đã truyền tiến và sau đó ngược qua toàn bộ mạng. Do đó, các bản cập nhật trọng 
số bị khóa thời gian đối với những độ trễ này (Czarnecki et al., 2017; Jaderberg et al., 2017; 
Frenkel et al., 2021). Điều này làm chậm việc học, do đó các ví dụ huấn luyện phải được 
cung cấp ít nhất chậm bằng thời gian xử lý việc truyền qua hai hướng. Ngoài hạn chế thực 
tế quan trọng này của BP đối với DL, nó cũng không có vẻ khả thi rằng nhiều nơ-ron xa 
nhau trong não phối hợp các hoạt động xử lý và học với độ chính xác thời gian như vậy, cũng 
như não chỉ có thể học từ các chuỗi chậm của các ví dụ huấn luyện.

Hàm mất mát toàn cục. BP thường được áp dụng trong môi trường có giám sát, nơi con 
người cung cấp các nhãn mô tả của các ví dụ huấn luyện. Đây là một quá trình tốn kém, 
do đó BP có giám sát không thể khai thác hầu hết dữ liệu có sẵn, vốn không có nhãn. Ngoài ra, 
nó không giải thích cách con người hoặc động vật có thể học mà không có người giám sát. 
Kết quả là, nỗ lực nghiên cứu đáng kể đã được dành cho các kỹ thuật học mà không có nhãn, 
với sự thành công ngày càng tăng gần đây, đặc biệt là từ việc học tự giám sát (SSL) (Chen et 
al., 2020; Mitrovic et al., 2020; Lee et al., 2021; Tomasev et al., 2022; Scherr et al., 2022). 
Trong SSL, BP cũng có thể sử dụng một số tín hiệu giám sát được tạo ra bởi chính mô hình 
như một lỗi toàn cục. Do đó, trong khi BP không yêu cầu nhãn per se, nó yêu cầu giám sát 
từ trên xuống dưới dạng hàm mất mát toàn cục. Nhược điểm của điều này là việc học sau 
đó trở nên chuyên biệt cho nhiệm vụ cụ thể được định nghĩa rõ ràng bởi việc tối thiểu hóa 
hàm mất mát, trái ngược với việc học các đặc trưng chung. Trong thực tế, điều này được 
thể hiện trong DL như overfitting, độ nhạy cảm với các cuộc tấn công đối kháng (Madry et 
al., 2017; Moraitis et al., 2021), và khả năng chuyển giao hoặc tổng quát hóa hạn chế của 
các đặc trưng đã học sang các nhiệm vụ hoặc bộ dữ liệu khác (Lee et al., 2021). Hơn nữa, 
một sơ đồ tối ưu hóa toàn cục như BP không thể được coi là một mô hình khả thi cho tất cả 
việc học trong não, bởi vì việc học trong các nhiệm vụ ML xuất hiện từ các quy tắc tính dẻo 
rất sinh học mà không có giám sát toàn cục (tự), ví dụ như không giám sát và giống Hebbian 
(Diehl and Cook, 2015; Moraitis et al., 2020; 2021; Rodriguez et al., 2022).

2 Các giải pháp thay thế cho lan truyền ngược và những hạn chế của chúng
Hình 1: Kết quả đa lớp 
thành công đầu tiên. Độ 
chính xác CIFAR-10 của 
SoftHebb tăng theo độ 
sâu (các lớp ẩn), so với 
công trình trước đó.

Học Hebbian không giám sát trong vỏ não. Các quy tắc tính dẻo giống 
Hebbian là những quy tắc chỉ phụ thuộc vào hoạt động của các nơ-ron 
tiền và hậu synapse. Nếu tính dẻo như vậy được kết hợp với cạnh tranh 
giữa các nơ-ron để ức chế các nơ-ron được kích hoạt yếu trong một lớp, 
ví dụ như argmax, nó có thể dẫn đến việc học các đặc trưng hữu ích 
trong sự vắng mặt của bất kỳ giám sát (tự) nào (Sanger, 1989; Linsker, 
1992). Đây là một cách tiếp cận hoàn toàn khác với BP. Nó không được 
điều khiển bởi một quá trình tối ưu hóa toàn cục, mà xuất hiện từ tính 
dẻo synaptic cục bộ như một sự tự tổ chức hoàn toàn từ dưới lên. Không 
có giám sát, phản hồi, hoặc mục tiêu, việc học Hebbian cạnh tranh vượt 
qua tất cả năm hạn chế của BP, vì nó không yêu cầu bất kỳ tín hiệu lan 
truyền ngược nào. Cụ thể, nó không có vận chuyển trọng số, tính không 
cục bộ, vấn đề khóa, và mất mát toàn cục. Đây là những lợi thế thực tế 
đáng kể. Hơn nữa, những tính chất này làm cho việc học Hebbian khả 
thi hơn nhiều về mặt sinh học. Bên cạnh đó, có bằng chứng dồi dào về 
tính dẻo giống Hebbian trong não, dưới các hình thức dựa trên loại kích 
hoạt nơ-ron sinh học spiking (Sj¨ ostr¨ om et al., 2001; Markram et al., 
2011; Feldman, 2012).

Ngay cả kết nối mạng cạnh tranh dẫn đến việc học hữu ích thông qua tính dẻo như vậy được 
hỗ trợ mạnh mẽ bởi các quan sát sinh học. Cụ thể, cạnh tranh giữa các nơ-ron xuất hiện từ 
sự ức chế bên và điều này được tìm thấy khắp tấm vỏ não của não động vật có vú (Douglas 
et al., 1989; Douglas and Martin, 2004; Binzegger et al., 2004; 2009), và thường được mô 
tả là winner-take-all (WTA). Hơn nữa, việc học cạnh tranh như vậy đã được nghiên cứu sâu 
về mặt tính toán và lý thuyết trong một thời gian dài dưới nhiều hình thức khác nhau (Von 
der Malsburg, 1973; Nessler et al., 2013; Diehl and Cook, 2015; Krotov and Hopfield, 2019; 
Moraitis et al., 2020). Tất cả những khía cạnh này sẽ là những lợi thế quan trọng nếu việc 
học như vậy có thể làm nền tảng cho DL. Tuy nhiên, việc học Hebbian không giám sát chỉ 
có hiệu quả trong các mạng nông. Để chính xác, việc thêm lớp đã thất bại trong việc hiển 
thị những cải thiện đáng kể trong các bài kiểm tra chuẩn (Amato et al., 2019; Lagani et al., 
2021), ngoại trừ ở một mức độ nào đó trong Miconi (2021) (Hình 1). Có thể nói, điều này 
đã xảy ra vì việc học từ dưới lên xuất hiện từ tính dẻo khó hòa hợp với việc học từ trên 
xuống từ một hàm mất mát, và cách tiếp cận sau đã là xương sống của DL. Những cách 
tiếp cận Hebbian cạnh tranh có tính quy chuẩn, tức là rút ra một quy tắc tính dẻo từ một 
nguyên tắc tối ưu hóa, dựa trên các nguyên tắc không có vẻ tương thích với các kỹ thuật 
DL thành công, hoặc do các loại mạng khác nhau một cách đáng kể (Nessler et al., 2009; 
2013) hoặc hàm mất mát (Pehlevan and Chklovskii, 2015).

SoftHebb. Tuy nhiên, công trình gần đây đã tiến bộ lý thuyết đằng sau việc học Hebbian 
WTA theo những điều khoản tương thích hơn với DL. Cụ thể, Moraitis et al. (2021) đã 
sử dụng một softmax đơn giản để triển khai một soft WTA (Phương trình (1)), cung cấp 
một diễn giải Bayesian cho mạng và việc học của nó (xem thêm Nessler et al. (2009; 2013)). 
Moraitis et al. (2021) cũng đã rút ra một quy tắc tính dẻo giống Hebbian (Phương trình (2)) 
tối thiểu hóa sự phân kỳ Kullback-Leibler của phân phối xác suất của mô hình so với đầu 
vào, và cross-entropy từ các nhãn dưới một số giả định nhất định, mà không cần truy cập 
vào những nhãn đó. Trong các mạng một lớp, SoftHebb đã cho thấy tốc độ học tăng và 
độ mạnh mẽ cao hơn đáng kể đối với nhiễu và các cuộc tấn công đối kháng. Kết quả lý 
thuyết của nó có vẻ quan trọng đối với các mạng sâu hơn, nhưng chúng không đủ cho một 
minh chứng thực tế. Ở đây (Phần 3), chúng tôi cung cấp một thiết lập dựa trên SoftHebb 
thực sự đạt được một độ sâu nhất định trong việc học Hebbian.

3

--- TRANG 3 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

nó yêu cầu tín hiệu lỗi, được tính toán tại một thời điểm khác và ở nơi khác 
trong mạng, tức là tại đầu ra. Điều đó làm cho BP không cục bộ về không gian và thời gian, 
đây là sự khác biệt quan trọng so với tính cục bộ được tin là chi phối tính dẻo synaptic sinh 
học nói chung (Baldi et al., 2017). Tính không cục bộ này ngụ ý thêm những bất hiệu quả 
tính toán. Cụ thể, các biến truyền tiến phải được ghi nhớ, làm tăng yêu cầu bộ nhớ (L¨ owe 
et al., 2019). Hơn nữa, các tín hiệu ngược bổ sung phải được tính toán và truyền, làm tăng 
các phép toán và dòng điện. Đáng chú ý là những khía cạnh này không chỉ giới hạn các công 
nghệ neuromorphic tương lai, mà ngay cả nền tảng phần cứng của DL ngày nay, tức là các 
đơn vị xử lý đồ họa (GPU), có những hạn chế riêng về bộ nhớ và FLOPS.

Khóa cập nhật. Lỗi được quy cho một synapse bởi BP chỉ có thể được tính toán sau khi 
thông tin đã truyền tiến và sau đó ngược qua toàn bộ mạng. Do đó, các bản cập nhật trọng 
số bị khóa thời gian đối với những độ trễ này (Czarnecki et al., 2017; Jaderberg et al., 2017; 
Frenkel et al., 2021). Điều này làm chậm việc học, do đó các ví dụ huấn luyện phải được 
cung cấp ít nhất chậm bằng thời gian xử lý việc truyền qua hai hướng. Ngoài hạn chế thực 
tế quan trọng này của BP đối với DL, nó cũng không có vẻ khả thi rằng nhiều nơ-ron xa 
nhau trong não phối hợp các hoạt động xử lý và học với độ chính xác thời gian như vậy, cũng 
như não chỉ có thể học từ các chuỗi chậm của các ví dụ huấn luyện.

Hàm mất mát toàn cục. BP thường được áp dụng trong môi trường có giám sát, nơi con 
người cung cấp các nhãn mô tả của các ví dụ huấn luyện. Đây là một quá trình tốn kém, 
do đó BP có giám sát không thể khai thác hầu hết dữ liệu có sẵn, vốn không có nhãn. Ngoài ra, 
nó không giải thích cách con người hoặc động vật có thể học mà không có người giám sát. 
Kết quả là, nỗ lực nghiên cứu đáng kể đã được dành cho các kỹ thuật học mà không có nhãn, 
với sự thành công ngày càng tăng gần đây, đặc biệt là từ việc học tự giám sát (SSL) (Chen et 
al., 2020; Mitrovic et al., 2020; Lee et al., 2021; Tomasev et al., 2022; Scherr et al., 2022). 
Trong SSL, BP cũng có thể sử dụng một số tín hiệu giám sát được tạo ra bởi chính mô hình 
như một lỗi toàn cục. Do đó, trong khi BP không yêu cầu nhãn per se, nó yêu cầu giám sát 
từ trên xuống dưới dạng hàm mất mát toàn cục. Nhược điểm của điều này là việc học sau 
đó trở nên chuyên biệt cho nhiệm vụ cụ thể được định nghĩa rõ ràng bởi việc tối thiểu hóa 
hàm mất mát, trái ngược với việc học các đặc trưng chung. Trong thực tế, điều này được 
thể hiện trong DL như overfitting, độ nhạy cảm với các cuộc tấn công đối kháng (Madry et 
al., 2017; Moraitis et al., 2021), và khả năng chuyển giao hoặc tổng quát hóa hạn chế của 
các đặc trưng đã học sang các nhiệm vụ hoặc bộ dữ liệu khác (Lee et al., 2021). Hơn nữa, 
một sơ đồ tối ưu hóa toàn cục như BP không thể được coi là một mô hình khả thi cho tất cả 
việc học trong não, bởi vì việc học trong các nhiệm vụ ML xuất hiện từ các quy tắc tính dẻo 
rất sinh học mà không có giám sát toàn cục (tự), ví dụ như không giám sát và giống Hebbian 
(Diehl and Cook, 2015; Moraitis et al., 2020; 2021; Rodriguez et al., 2022).

2 Các giải pháp thay thế cho lan truyền ngược và những hạn chế của chúng

Hình 1: Kết quả đa lớp 
thành công đầu tiên. Độ 
chính xác CIFAR-10 của 
SoftHebb tăng theo độ 
sâu (các lớp ẩn), so với 
công trình trước đó.

Học Hebbian không giám sát trong vỏ não. Các quy tắc tính dẻo giống 
Hebbian là những quy tắc chỉ phụ thuộc vào hoạt động của các nơ-ron 
tiền và hậu synapse. Nếu tính dẻo như vậy được kết hợp với cạnh tranh 
giữa các nơ-ron để ức chế các nơ-ron được kích hoạt yếu trong một lớp, 
ví dụ như argmax, nó có thể dẫn đến việc học các đặc trưng hữu ích 
trong sự vắng mặt của bất kỳ giám sát (tự) nào (Sanger, 1989; Linsker, 
1992). Đây là một cách tiếp cận hoàn toàn khác với BP. Nó không được 
điều khiển bởi một quá trình tối ưu hóa toàn cục, mà xuất hiện từ tính 
dẻo synaptic cục bộ như một sự tự tổ chức hoàn toàn từ dưới lên. Không 
có giám sát, phản hồi, hoặc mục tiêu, việc học Hebbian cạnh tranh vượt 
qua tất cả năm hạn chế của BP, vì nó không yêu cầu bất kỳ tín hiệu lan 
truyền ngược nào. Cụ thể, nó không có vận chuyển trọng số, tính không 
cục bộ, vấn đề khóa, và mất mát toàn cục. Đây là những lợi thế thực tế 
đáng kể. Hơn nữa, những tính chất này làm cho việc học Hebbian khả 
thi hơn nhiều về mặt sinh học. Bên cạnh đó, có bằng chứng dồi dào về 
tính dẻo giống Hebbian trong não, dưới các hình thức dựa trên loại kích 
hoạt nơ-ron sinh học spiking (Sj¨ ostr¨ om et al., 2001; Markram et al., 
2011; Feldman, 2012).

Ngay cả kết nối mạng cạnh tranh dẫn đến việc học hữu ích thông qua tính dẻo như vậy được 
hỗ trợ mạnh mẽ bởi các quan sát sinh học. Cụ thể, cạnh tranh giữa các nơ-ron xuất hiện từ 
sự ức chế bên và điều này được tìm thấy khắp tấm vỏ não của não động vật có vú (Douglas 
et al., 1989; Douglas and Martin, 2004; Binzegger et al., 2004; 2009), và thường được mô 
tả là winner-take-all (WTA). Hơn nữa, việc học cạnh tranh như vậy đã được nghiên cứu sâu 
về mặt tính toán và lý thuyết trong một thời gian dài dưới nhiều hình thức khác nhau (Von 
der Malsburg, 1973; Nessler et al., 2013; Diehl and Cook, 2015; Krotov and Hopfield, 2019; 
Moraitis et al., 2020). Tất cả những khía cạnh này sẽ là những lợi thế quan trọng nếu việc 
học như vậy có thể làm nền tảng cho DL. Tuy nhiên, việc học Hebbian không giám sát chỉ 
có hiệu quả trong các mạng nông. Để chính xác, việc thêm lớp đã thất bại trong việc hiển 
thị những cải thiện đáng kể trong các bài kiểm tra chuẩn (Amato et al., 2019; Lagani et al., 
2021), ngoại trừ ở một mức độ nào đó trong Miconi (2021) (Hình 1). Có thể nói, điều này 
đã xảy ra vì việc học từ dưới lên xuất hiện từ tính dẻo khó hòa hợp với việc học từ trên 
xuống từ một hàm mất mát, và cách tiếp cận sau đã là xương sống của DL. Những cách 
tiếp cận Hebbian cạnh tranh có tính quy chuẩn, tức là rút ra một quy tắc tính dẻo từ một 
nguyên tắc tối ưu hóa, dựa trên các nguyên tắc không có vẻ tương thích với các kỹ thuật 
DL thành công, hoặc do các loại mạng khác nhau một cách đáng kể (Nessler et al., 2009; 
2013) hoặc hàm mất mát (Pehlevan and Chklovskii, 2015).

SoftHebb. Tuy nhiên, công trình gần đây đã tiến bộ lý thuyết đằng sau việc học Hebbian 
WTA theo những điều khoản tương thích hơn với DL. Cụ thể, Moraitis et al. (2021) đã 
sử dụng một softmax đơn giản để triển khai một soft WTA (Phương trình (1)), cung cấp 
một diễn giải Bayesian cho mạng và việc học của nó (xem thêm Nessler et al. (2009; 2013)). 
Moraitis et al. (2021) cũng đã rút ra một quy tắc tính dẻo giống Hebbian (Phương trình (2)) 
tối thiểu hóa sự phân kỳ Kullback-Leibler của phân phối xác suất của mô hình so với đầu 
vào, và cross-entropy từ các nhãn dưới một số giả định nhất định, mà không cần truy cập 
vào những nhãn đó. Trong các mạng một lớp, SoftHebb đã cho thấy tốc độ học tăng và 
độ mạnh mẽ cao hơn đáng kể đối với nhiễu và các cuộc tấn công đối kháng. Kết quả lý 
thuyết của nó có vẻ quan trọng đối với các mạng sâu hơn, nhưng chúng không đủ cho một 
minh chứng thực tế. Ở đây (Phần 3), chúng tôi cung cấp một thiết lập dựa trên SoftHebb 
thực sự đạt được một độ sâu nhất định trong việc học Hebbian.

3

--- TRANG 4 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Các xấp xỉ của lan truyền ngược. Các giải pháp thay thế không hoàn toàn khác với 
BP mà xấp xỉ nó, trong khi giảm thiểu một số vấn đề của nó, đã thu hút sự quan tâm 
nghiên cứu lớn với sự thành công ngày càng tăng. Ví dụ, việc học tự giám sát cho phép 
BP học mà không cần nhãn (Hadsell et al., 2006), với các trường hợp như SimCLR (Chen 
et al., 2020) và các nghiên cứu tiếp theo (Mitrovic et al., 2020; Grill et al., 2020; He et al., 
2020; Caron et al., 2020; Tomasev et al., 2022) đạt hiệu suất khá cao. Một cách tiếp cận 
khác, Feedback Alignment (FA), (Lillicrap et al., 2016; Frenkel et al., 2021), giải quyết 
vấn đề vận chuyển trọng số. Direct Feedback Alignment (Nøkland, 2016; Frenkel et al., 
2021) như một phần mở rộng của FA, cũng tránh các tính toán không cục bộ cho việc 
cập nhật trọng số. Tính không cục bộ không gian của lan truyền ngược cũng đã được 
giải quyết bởi các thuật toán khác như mã hóa dự đoán (Hadsell et al., 2006; Chen et al., 
2020), lan truyền cân bằng (Scellier and Bengio, 2017; Laborieux et al., 2021), burstprop 
(Payeur et al., 2021). Công trình của L¨ owe et al. (2019), và CLAPP bởi Illing et al. (2021) 
là các thuật toán tự giám sát tránh không chỉ sự phụ thuộc vào nhãn mà còn cả việc học 
không cục bộ về mặt không gian. Tuy nhiên, chúng yêu cầu sự tương phản của các ví dụ 
được biết là khác loại. Một cách tiếp cận tự giám sát rất gần đây tránh yêu cầu này bằng 
cách thêm một số hạng Hebbian vào việc học (Halvagal and Zenke, 2022). Điều này làm 
cho nó trở thành một thuật toán khá khả thi cho não, nhưng nó vẫn dựa vào sự so sánh 
giữa các góc nhìn khác nhau rõ ràng của mỗi đầu vào cá nhân. Hơn nữa, hiệu suất của 
nó tệ hơn đáng kể trên CIFAR-10 và STL-10 so với các tài liệu tham khảo trước đó của 
đoạn này. Thực tế, tất cả các cách tiếp cận nêu trên đều gây ra sự giảm đáng kể về độ 
chính xác so với BP, và hầu hết các trường hợp không áp dụng được cho các bộ dữ liệu 
phức tạp như ImageNet (Bartunov et al., 2018). Một thuật toán tránh tính không cục bộ 
của BP end-to-end và cũng đạt được độ chính xác khá cao trong CIFAR-10 đã được đề 
xuất bởi Nøkland and Eidnes (2019). Tuy nhiên, nó dựa vào một mạng phụ được huấn 
luyện thêm vào mỗi lớp, làm tăng độ phức tạp, và giám sát, yêu cầu nhãn. Các công 
trình khác đã đạt được việc học với tính dẻo cục bộ, trong khi tránh vận chuyển trọng 
số và vấn đề khóa cập nhật (Crafton et al., 2019; Frenkel et al., 2021). Tuy nhiên, chúng 
bị giảm hiệu suất lớn và dựa vào giám sát. Rõ ràng, tiến bộ đáng kể so với BP chuẩn 
đã được thực hiện thông qua nhiều cách tiếp cận, nhưng những hạn chế quan trọng vẫn 
còn (Bảng 1). Những hạn chế này sẽ được vượt qua nếu một thuật toán Hebbian cạnh 
tranh hoạt động tốt trong các mạng đa lớp và các nhiệm vụ khó khăn. Ở đây, chúng tôi 
khám phá tiềm năng của SoftHebb (Moraitis et al., 2021), tức là thuật toán gần đây có 
vẻ phù hợp với mục tiêu này. Kết quả của chúng tôi thực sự chứng minh một thiết lập 
học đa lớp, đạt hiệu suất tương đối cao cho các thuật toán tương thích sinh học trên các 
nhiệm vụ khó khăn, với hiệu quả cao và các ràng buộc sinh học chặt chẽ. Trong phần 
tiếp theo, chúng tôi mô tả thiết lập này.

3 Tổng quan về SoftHebb đa lớp

Các yếu tố chính của mô hình và thuật toán SoftHebb đa lớp đạt được độ chính xác 
tốt mà không ảnh hưởng đến hiệu quả và tính khả thi sinh học của nó như sau.

SoftHebb (Moraitis et al., 2021) trong một lớp K nơ-ron thực hiện một cạnh tranh 
soft WTA thông qua softmax, được tham số hóa bởi một cơ số b hoặc tương đương một 
nhiệt độ τ:

yk = buk / ∑(K, l=1) bul = euk/τ / ∑(K, l=1) eul/τ,     (1)

trong đó uk là tổng đầu vào có trọng số của nơ-ron thứ k, và yk là đầu ra của nó sau 
khi tính đến cạnh tranh từ các nơ-ron l. Khía cạnh chính thứ hai trong thuật toán SoftHebb 
là quy tắc tính dẻo của trọng số synaptic và bias nơ-ron. Bias đại diện cho xác suất tiền 
nghiệm trong mô hình xác suất được thực hiện bởi mạng. Trong các thí nghiệm ở đây, 
chúng tôi đã bỏ qua chúng, giả định một tiền nghiệm đồng nhất cố định. Tính dẻo được 
định nghĩa cho một trọng số synaptic wik từ một nơ-ron tiền synapse i với kích hoạt xi 
đến một nơ-ron k là

∆w(SoftHebb)ik = η · yk · (xi - uk · wik).     (2)

Đáng chú ý, tất cả các biến đều cục bộ về mặt thời gian và không gian đối với synapse. 
Quy tắc này có thể chứng minh được tối ưu hóa mô hình để thực hiện suy luận Bayesian 
của các nguyên nhân ẩn của dữ liệu (Moraitis et al., 2021) (xem thêm Phần 2).

Tính dẻo anti-Hebbian mềm. Các thuật toán giống Hebbian trước đây đã thấy các 
số hạng anti-Hebbian trong tính dẻo hữu ích trong việc học cạnh tranh một lớp (Krotov and 
Hopfield, 2019; Grinberg et al., 2019). Tuy nhiên, tính dẻo như vậy phù hợp với các giả 
định của một hard WTA, trái ngược với kích hoạt phân tán của SoftHebb, và liên quan 
đến các siêu tham số bổ sung. Ở đây chúng tôi giới thiệu một hình thức mới, đơn giản của 
tính dẻo anti-Hebbian cho các mạng soft WTA, đơn giản là phủ định việc cập nhật trọng 
số của SoftHebb (Phương trình (2)) trong tất cả các nơ-ron ngoại trừ nơ-ron được kích 
hoạt tối đa.

Tích chập. Hướng tới một kiến trúc đa lớp, và để biểu diễn thông tin đầu vào của 
mỗi lớp theo cách phân tán hơn, chúng tôi đã sử dụng một biểu diễn cục bộ thông qua 
các nhân tích chập. Quy tắc tính dẻo có thể chuyển giao dễ dàng sang kiến trúc như vậy. 
Tích chập có thể được xem như một phép tăng cường dữ liệu, nơi các đầu vào không còn 
là các hình ảnh gốc mà là được cắt thành các miếng nhỏ hơn được trình bày cho một mạng 
SoftHebb kết nối đầy đủ. Tích chập với việc chia sẻ trọng số giữa các miếng hiệu quả 
cho các nền tảng tính toán song song như GPU, nhưng theo nghĩa đen của nó, nó không 
khả thi về mặt sinh học. Tuy nhiên, điều này không ảnh hưởng cơ bản đến tính khả thi 
của tích chập, bởi vì các trọng số giữa các nơ-ron với các trường tiếp nhận cục bộ khác 
nhau có thể trở nên khớp nhau thông qua các quy tắc tương thích sinh học (Pogodin et al., 2021).

Các kích hoạt thay thế cho lan truyền tiến. Ngoài softmax liên quan đến quy tắc 
tính dẻo, các hàm kích hoạt khác nhau có thể được xem xét cho việc truyền đến mỗi lớp 
tiếp theo. Trong sinh học, loại kích hoạt kép này có thể được triển khai bằng cách ghép 
kênh các mã thời gian hoặc tần số chồng chéo của các nơ-ron spiking, đã được nghiên 
cứu và mô hình hóa rộng rãi (Naud et al., 2008; Kayser et al., 2009; Akam and Kullmann, 
2014; Herzfeld et al., 2015; Moraitis et al., 2018; Payeur et al., 2021). Chúng tôi đã chọn 
sự kết hợp của đơn vị đa thức chỉnh lưu (RePU) (Krotov and Hopfield, 2016; 2019), với 
Triangle (Phụ lục A.3.1), áp dụng ức chế bên bằng cách trừ hoạt động trung bình của 
lớp. Những điều này hoạt động tốt (Coates et al., 2011; Miconi, 2021), và cung cấp tham 
số hóa có thể điều chỉnh.

Tỷ lệ học thích ứng phụ thuộc vào chuẩn trọng số. Chúng tôi giới thiệu một sơ đồ 
tỷ lệ học thích ứng per-nơ-ron ổn định về 0 khi các vectơ trọng số nơ-ron hội tụ đến 
một hình cầu bán kính 1, và ban đầu lớn khi chuẩn của các vectơ trọng số lớn so với 1:

ηi = η · (ri - 1)q, trong đó q là một siêu tham số lũy thừa. Việc thích ứng per-nơ-ron 
này dựa trên các trọng số vẫn là một hoạt động cục bộ và gợi nhớ đến một sơ đồ tỷ lệ 
học thích ứng quan trọng khác được cá nhân hóa per-synapse, có nền tảng sinh học và 
lý thuyết và tăng tốc việc học (Aitchison, 2020; Aitchison et al., 2021). Của chúng tôi 
có thể nói là đơn giản hơn, và tính liên quan của nó là nó tăng độ mạnh mẽ đối với các 
siêu tham số và khởi tạo, và, kết hợp với bản chất Bayesian của SoftHebb (Phần 2), 
nó tăng tốc việc học sao cho chỉ một epoch học duy nhất là đủ (Phần 4).

Mở rộng chiều rộng. Mỗi lớp mới giảm một nửa độ phân giải hình ảnh trong mỗi 
chiều bằng một phép toán pooling, trong khi chiều rộng lớp, tức là số lượng nơ-ron tích 
chập, được nhân với một siêu tham số "hệ số chiều rộng". Các bài kiểm tra được báo 
cáo của chúng tôi sử dụng hệ số 4.

(A) Lớp 1  (B) Lớp 2  (C) Lớp 3  (D) Lớp 4
Hình 2: Ví dụ về các trường tiếp nhận SoftHebb, được học từ STL-10. Thêm trong Phụ lục B.6.

Các yếu tố quan trọng nhất cho việc học biểu diễn sâu là cạnh tranh mềm 
và quy tắc tính dẻo Hebbian tương ứng làm nền tảng cho SoftHebb (Hình 3 và B.2), 
tính dẻo anti-Hebbian mềm tương tự mà chúng tôi đã giới thiệu (Hình B.2), các nơ-ron 
tích chập, và kiến trúc mở rộng chiều rộng liên quan đến độ phân giải đầu ra giảm dần 
theo chiều sâu (Hình 4). Tỷ lệ học thích ứng tăng tốc đáng kể việc huấn luyện (Hình B.3B), 
sao cho chúng tôi chỉ sử dụng một epoch học không giám sát duy nhất cho mạng sâu. 
Hàm kích hoạt cụ thể và tham số hóa có thể điều chỉnh của nó ít quan trọng hơn nhưng 
vẫn cải thiện

5

--- TRANG 5 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

hiệu suất (Phụ lục B). Chúng tôi đã đến với thiết lập mới này dựa trên Moraitis et al. (2021) 
và thông qua việc tìm kiếm các bổ sung có thể dựa trên tài liệu và trực giác.

4 Kết quả

Tóm tắt giao thức thực nghiệm. Lớp đầu tiên sử dụng 96 nơ-ron tích chập để khớp 
với các công trình liên quan (Hình 1), ngoại trừ các thí nghiệm ImageNet của chúng tôi 
sử dụng 48 đơn vị. Chiều rộng của các lớp tiếp theo được xác định bởi hệ số chiều rộng 
(xem phần trước). Học Hebbian không giám sát chỉ nhận một lần trình bày của tập huấn 
luyện, tức là epoch. Mỗi lớp được huấn luyện đầy đủ và đóng băng trước lớp tiếp theo, 
một cách tiếp cận phổ biến được gọi là huấn luyện theo lớp tham lam trong các sơ đồ 
học cục bộ như vậy (Bengio et al., 2006; Tavanaei and Maida, 2016; L¨ owe et al., 2019). 
Chuẩn hóa batch (Ioffe and Szegedy, 2015) được sử dụng, với các tham số ban đầu 
chuẩn của nó (γ = 1, β = 0), mà chúng tôi không huấn luyện. Sau đó, một đầu phân 
loại tuyến tính được huấn luyện với mất mát cross-entropy, sử dụng chính quy hóa 
dropout, với các mini-batch 64 ví dụ, và huấn luyện trong 50, 50, 100, và 200 epoch 
có giám sát cho MNIST, CIFAR-10, STL-10, và ImageNet tương ứng. Chúng tôi đã sử 
dụng GPU NVIDIA Tesla V100 32GB. Tất cả chi tiết về các phương pháp thực nghiệm 
được cung cấp trong Phụ lục A, và các thí nghiệm kiểm soát, bao gồm tác động của 
các siêu tham số trong Phụ lục B.

Các baseline kết nối đầy đủ. Công trình của Moraitis et al. (2021) trình bày SoftHebb 
chủ yếu thông qua phân tích lý thuyết. Các thí nghiệm cho thấy các tính chất sinh 
và Bayesian thú vị của các mạng này, như tốc độ học cao và độ mạnh mẽ đối kháng. 
Độ chính xác được báo cáo tập trung vào các mạng kết nối đầy đủ một lớp ẩn, cho 
thấy nó áp dụng tốt cho các bộ dữ liệu MNIST và Fashion-MNIST đạt độ chính xác 
(96.94 ±0.15)% và (75.14 ±0.17)%, tương ứng, sử dụng 2000 nơ-ron ẩn.

(A) CIFAR-10  (B) CIFAR-100
(C) STL-10  (D) ImageNette

Hình 3: Hiệu suất theo chiều sâu cho các 
thiết lập huấn luyện khác nhau và cho 
trọng số ngẫu nhiên chưa huấn luyện, 
trong 4 bộ dữ liệu. Số lượng lớp ẩn được 
chỉ ra.

Bắt đầu từ công trình đó, chúng tôi thấy rằng khi 
chuyển sang các bộ dữ liệu phức tạp hơn như 
CIFAR-10 hoặc STL-10, hiệu suất SoftHebb không 
cạnh tranh. Cụ thể, độ chính xác của cùng mạng 
kết nối đầy đủ nông đạt (43.9 ±0.18)% và (36.9 
±0.19)% tương ứng. So với (55.7 ±0.13)% và (50.0 
±0.16)% của BP, điều này cho thấy các mạng một 
lớp ẩn không đủ cho việc trích xuất các đặc trưng 
có ý nghĩa và tách biệt các lớp đầu vào. Sau đó 
chúng tôi xếp chồng hai lớp Hebbian WTA kết nối 
đầy đủ như vậy. Mạng này thực sự hoạt động tệ 
hơn, đạt (32.9 ±0.22)% và (31.5 ± 0.20)% trên 
những nhiệm vụ này. 

Các baseline tích chập. Nghiên cứu gần đây đã 
áp dụng tính dẻo Hebbian cho các mạng nơ-ron 
tích chập hard-WTA (CNN) (Miconi, 2021; Lagani 
et al., 2021; Amato et al., 2019). Tuy nhiên, nó 
không đạt được sự cải thiện đáng kể, nếu có, 
thông qua việc thêm lớp (Hình 1, đường cong 
xanh lá). Trong các thí nghiệm kiểm soát của 
chúng tôi, chúng tôi thấy rằng những mạng này 
với các quy tắc tính dẻo từ tài liệu không học 
được các đặc trưng hữu ích, vì trọng số ngẫu 
nhiên cố định hoạt động tốt hơn trọng số đã học, 
cũng phù hợp với kết quả từ Miconi (2021). Thật 
vậy, chúng tôi thấy rằng các đặc trưng được học 
bởi các mạng hard-WTA như vậy là các bộ lọc 
giống Gabor đơn giản trong lớp đầu tiên (Hình B.5A) và trong các lớp sâu hơn (xem 
thêm Miconi (2021)).

Một chế độ học mới. Một cách để học các đặc trưng phức tạp hơn là bằng cách thêm 
một số hạng anti-Hebbian vào tính dẻo của các mạng WTA (Krotov and Hopfield, 2019; 
Grinberg et al., 2019). Đáng chú ý, phương pháp này trước đây chỉ được thử nghiệm 
với các mạng hard-WTA và các quy tắc tính dẻo liên quan của chúng chứ không phải 
với mô hình SoftHebb gần đây và tính dẻo. Trong những trường hợp đó, tính dẻo 
anti-Hebbian được áp dụng cho nơ-ron hoạt động mạnh thứ k. Ở đây, chúng tôi đã 
giới thiệu một loại tính dẻo anti-Hebbian mềm mới (xem Phần 3). Đầu tiên chúng tôi 
nghiên cứu tác động của nó thông qua số lượng đặc trưng "R1" (Moraitis et al., 2021), 
tức là các vectơ trọng số nằm trên một hình cầu đơn vị, theo chuẩn của chúng. Các 
bộ lọc giống Gabor đơn giản xuất hiện mà không có các số hạng anti-Hebbian trong 
tính dẻo (Hình B.5A) và là R1. Ngay cả với tính dẻo anti-Hebbian, trong các mạng 
hard WTA, các đặc trưng học được là R1 (Krotov and Hopfield, 2019). Trong trường 
hợp SoftHebb với loại tính dẻo anti-Hebbian mềm của chúng tôi, chúng tôi quan sát 
thấy các đặc trưng ít tiêu chuẩn hơn, tức là không R1, xuất hiện (Hình B.1 & B.5B). 
Bằng cách đo độ chính xác của mạng SoftHebb trong khi thay đổi nhiệt độ, chúng tôi 
đã phát hiện ra một chế độ xung quanh τ = 1 (Hình B.1) nơi các đặc trưng R1 và 
không R1 cùng tồn tại, và độ chính xác cao nhất. Chế độ này chỉ xuất hiện với SoftHebb. 
Ví dụ, trên CIFAR-10 với một lớp tích chập đơn và một bộ phân loại tuyến tính được 
thêm vào, độ chính xác SoftHebb (71.10 ±0.06)% vượt trội đáng kể so với hard WTA 
(62.69 ±0.47)% và trọng số ngẫu nhiên (63.93 ±0.22)%, gần như đạt độ chính xác 
của BP (72.42 ±0.24)% trên cùng mạng hai lớp được huấn luyện end-to-end.

Hội tụ trong một epoch duy nhất. Tỷ lệ học thích ứng. Bằng cách nghiên cứu sự 
hội tụ thông qua các đặc trưng R1 và bằng cách thí nghiệm với các tỷ lệ học, chúng 
tôi đã hình thành một tỷ lệ học thích ứng thích ứng với chuẩn của vectơ trọng số của 
mỗi nơ-ron (Phần 3). Chúng tôi thấy rằng nó cũng tăng tốc việc học so với các lịch 
trình học truyền thống hơn (Hình B.3B) đối với số lượng vòng lặp huấn luyện. Mức 
độ tăng tốc sao cho chúng tôi chỉ cần trình bày bộ dữ liệu huấn luyện một lần, trước 
khi đánh giá hiệu suất của mạng. Tất cả kết quả chúng tôi báo cáo về SoftHebb thực 
sự là sau chỉ một epoch học không giám sát. Sự tăng tốc phù hợp với các quan sát 
của Moraitis et al. (2021) quy tốc độ cho bản chất Bayesian của SoftHebb. Hơn nữa, 
chúng tôi thấy rằng với tỷ lệ học thích ứng của chúng tôi, sự hội tụ mạnh mẽ đối với 
các điều kiện ban đầu, mà các sơ đồ học không giám sát như vậy thường rất nhạy cảm 
(Hình B.3A & B.3B).

Hình 4: Hiệu suất theo lớp 
CIFAR-10 của SoftHebb, 
cho các hệ số chiều rộng 
khác nhau. SoftHebb cho 
phép mở rộng độ sâu khi 
chiều rộng của các lớp 
sâu mở rộng đủ. Các hệ 
số (1x, 2x, hoặc 4x) chỉ 
ra sự tăng theo lớp trong 
số lượng nơ-ron.

Tác động của kiến trúc. Kiến trúc đa lớp sử dụng 
một phép toán pooling có stride 2, giảm một nửa 
mỗi chiều của độ phân giải sau mỗi lớp. Chúng tôi 
ngừng thêm lớp khi độ phân giải đầu ra trở thành 
nhiều nhất 4 ×4. Lớp nơi điều này xảy ra phụ thuộc 
vào độ phân giải của đầu vào gốc. Do đó, mạng đa 
lớp có ba lớp tích chập ẩn cho MNIST hoặc CIFAR-10, 
bốn lớp cho STL-10, và năm lớp cho ImageNet ở 
thiết lập độ phân giải 160 ×160 px. Chúng tôi sử 
dụng nhiều hơn bốn lần số nơ-ron trong mỗi lớp so 
với lớp trước. Kiến trúc này một mình, với trọng số 
ban đầu ngẫu nhiên, cho thấy sự tăng không nhất 
quán trong độ chính xác phân loại, đến một độ sâu 
biến đổi (Hình 3). Sự tăng hiệu suất gây ra bởi việc 
thêm các lớp ngẫu nhiên có vẻ ngạc nhiên nhưng 
phù hợp với tài liệu nơi trọng số ngẫu nhiên thường 
vượt trội hơn các quy tắc học tương thích sinh học 
(Miconi, 2021; Frenkel et al., 2021). Thật vậy, bằng 
cách sử dụng cách tiếp cận hard-WTA phổ biến hơn 
để huấn luyện mạng như vậy, hiệu suất không chỉ 
xấu đi so với trọng số ngẫu nhiên mà còn thất bại 
trong việc tăng với độ sâu được thêm vào (Hình 3).

Độ chính xác phân loại (xem Bảng 1 & 2). Chúng tôi 
báo cáo rằng với SoftHebb và các kỹ thuật mà chúng 
tôi đã mô tả, chúng tôi đạt được Học sâu với tối đa 
5 lớp ẩn. Ví dụ, sự tăng độ chính xác theo lớp trên 
CIFAR-10 có thể thấy trong Hình 1. Việc học thực 
sự xảy ra, và sự cải thiện độ chính xác theo lớp không 
chỉ do lựa chọn kiến trúc. Điều đó được chứng minh, 
đầu tiên, bởi thực tế là các trọng số thay đổi và các 
trường tiếp nhận xuất hiện có ý nghĩa (Hình 5). Thứ 
hai, và cụ thể hơn, đối với nhiệm vụ cuối cùng là 
phân loại, độ chính xác cải thiện đáng kể so với 
trọng số ngẫu nhiên chưa huấn luyện, và điều này 
đúng trong tất cả các bộ dữ liệu (Hình 3). SoftHebb 
đạt độ chính xác kiểm tra (99.35 ±0.03)%, (80.31 
±0.14)%, (76.23 ±0.19)%, 27.3% và (80.98 ±0.43)% 
trên MNIST, CIFAR-10, STL-10, ImageNet đầy đủ, 
và ImageNette. Chúng tôi cũng đã đánh giá cùng 
các mạng được huấn luyện theo cách hoàn toàn có 
nhãn giám sát với BP end-to-end trên tất cả các bộ 
dữ liệu. Do nhu cầu tài nguyên của BP, chúng tôi 
không thể so sánh trực tiếp với BP trên ImageNet 
nhưng chúng tôi đã áp dụng BP cho tập con ImageNette. 
Độ chính xác kết quả không quá xa so với SoftHebb 
(Hình 3). Mạng được huấn luyện BP đạt (99.45 ±0.02)%, 
(83.97 ±0.07)%, (74.51 ±0.36)% và (85.30 ±0.45)% 
trên MNIST, CIFAR-10, STL-10, và ImageNette tương 
ứng. Đáng chú ý, hiệu suất này rất cạnh tranh (xem 
Bảng 1 & 2).

AB
C D
máy bay
chim
`xe cộ'
`động vật có lông'
Lớp 1 Lớp 4
Lớp 1 Lớp 4
nơ-ron p1
nơ-ron q1
nơ-ron r1
nơ-ron s1
nơ-ron t1
nơ-ron p4
nơ-ron q4
nơ-ron r4
nơ-ron s4
nơ-ron t4

Hình 5: Chỉ dẫn cho các biểu diễn phân cấp được học bởi SoftHebb trên STL-10. A, B: 
Phép chiếu UMAP của tập kiểm tra sau khi đi qua 1 hoặc 4 lớp SoftHebb. Embedding 
4 lớp đã học tổ chức rõ ràng hơn theo lớp đầu vào và các lớp được tách biệt tốt hơn. 
C, D: Hình ảnh và các miếng (hộp viền đỏ) kích hoạt tốt nhất 5 nơ-ron ngẫu nhiên từ 
mỗi lớp. Các nơ-ron lớp 1 (C) đã trở nên tiếp nhận với các miếng nhỏ với các đặc trưng 
đơn giản (lưu ý các hộp viền đỏ rất nhỏ), và không cụ thể đối với vật thể được miêu tả. 
Các nơ-ron lớp 4 (D) tiếp nhận với các miếng có đặc trưng lớn hơn và phức tạp, và 
các loại vật thể cụ thể. Các synapse dẻo tạo ra hệ thống phân cấp rõ ràng này trong 
sự vắng mặt của các tín hiệu không cục bộ, thông tin liên quan đến nhãn, giám sát 
từ trên xuống khác, hoặc tự giám sát.

Bằng chứng cho các biểu diễn phân cấp. Một câu hỏi trung tâm về SoftHebb là khả 
năng xây dựng biểu diễn phân cấp của các đặc trưng, tức là các đặc trưng tăng trừu 
tượng ngữ nghĩa với độ sâu tăng, và cũng trở nên hữu ích hơn cho các nhiệm vụ hạ 
nguồn như phân loại đối tượng. Một nguồn bằng chứng cho hệ thống phân cấp là sự 
tăng độ chính xác theo lớp mà chúng tôi quan sát, cho thấy các lớp được thêm vào 
ngày càng hữu ích Hình 1. Bằng cách cũng sử dụng một phương pháp từ Illing et al. 
(2021), chúng tôi tìm thấy thêm bằng chứng (Hình 5). Trong phép chiếu UMAP (McInnes 
et al., 2018), các lớp đầu vào có vẻ được tách biệt tốt hơn sau bốn lớp so với sau một 
lớp (Hình 5A, B). Hơn nữa, chúng tôi tìm thấy các miếng trong bộ dữ liệu kích hoạt 
tối đa các nơ-ron ẩn. Những điều này cũng có vẻ ngày càng phức tạp và trừu tượng 
(Hình 5C, D). Hơn nữa, chúng tôi hình dung trường tiếp nhận của các nơ-ron, bằng 
cách tối ưu hóa số đầu vào để tối đa hóa các kích hoạt ẩn, thông qua gradient descent 
dự án, tương tự như Le et al. (2012) (xem Phụ lục A để biết phương pháp). Một lần 
nữa, độ sâu có vẻ tăng độ phức tạp và tính hữu ích tiềm năng của các đặc trưng đã 
học (Hình 2 và Phụ lục).

SoftHebb như học đa lớp không giám sát. Trong STL-10, SoftHebb (76.23 ±0.19)% 
vượt trội hơn BP hoàn toàn có giám sát (74.51 ±0.36)% (Hình 3C). Rất ít ví dụ có 
nhãn trong tập huấn luyện không đủ để học các biểu diễn tốt thông qua BP chỉ-có-giám-sát. 
Bằng cách tinh chỉnh SoftHebb với BP end-to-end trên ít ví dụ có nhãn STL-10, độ 
chính xác của SoftHebb cải thiện thêm đến (78.5 ±0.35)%. Điều này cho thấy mục tiêu 
được tối ưu hóa ngầm bởi việc học của SoftHebb tương thích với mục tiêu rõ ràng của 
cross-entropy, như đã được lý thuyết hóa và dự đoán chính thức hơn trong Moraitis 
et al. (2021). So sánh với các thuật toán quan trọng khác để học mà không có nhãn 
cho thấy SoftHebb trong các mạng sâu 4 hoặc 5 lớp ẩn vượt trội hơn công trình tương 
thích sinh học một phần trước đó (Bảng 2). Tất nhiên, BP trong các mô hình phức tạp 
hơn vượt trội đáng kể so với SoftHebb.

8

--- TRANG 6 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Bảng 2: Độ chính xác top-1 STL-10 & ImageNet (%) của các mạng không giám sát hoặc tự giám sát (khung xanh) & 
tương thích sinh học một phần (khung xanh lá). In đậm chỉ ra hàng tương thích sinh học hoạt động tốt nhất, 
tức là SoftHebb. Việc học không giám sát của SoftHebb chỉ liên quan đến 1 epoch.

Thuật toán huấn luyện | Mô hình | STL-10 | ImageNet | Tài liệu tham khảo
S-TEC (1000/100 epochs) | ResNet-50 | 91.6 | 66.3 | Scherr et al. 2022
SimCLR (1000 epochs) | ResNet-50 | 91.5 | 76.5 | Scherr et al. 2022; Chen et al. 2020
SimCLR (100 epochs) | ResNet-18 | 86.3 | 30.0 | Chen et al. 2020 (repr. của chúng tôi)
Greedy InfoMax | ResNet-50 | 81.9 | n.a. | L¨ owe et al. 2019
Không có (Ngẫu nhiên) | Không có | 10.0 | 0.1 | Ngẫu nhiên
Không có (Trọng số ngẫu nhiên) | SoftHebb | 68.2 | 14.0 | Của chúng tôi
Hebbian Hard WTA | | 54.8 | n.a. | Của chúng tôi
SoftHebb (1 epoch) | SoftHebb | 76.2 | 27.3 | Của chúng tôi
CLAPP | VGG-6 | 73.6 | n.a. | Illing et al. 2021
LPL | VGG-11 | 61.9 | n.a. | Halvagal and Zenke 2022
K-means | K-means | 74.1 | n.a. | Dundar et al. 2015
Feedback Alignment | 5-layer CNN | n.a. | 6.9 | Bartunov et al. 2018
Direct Feedback Alignment | AlexNet | n.a. | 6.2 | Crafton et al. 2019
Single Sparse DFA | AlexNet | n.a. | 2.8 | Crafton et al. 2019

5 Thảo luận

Độ chính xác và khả năng áp dụng của SoftHebb trong các nhiệm vụ khó khăn thách thức một số thuật toán DL bị ràng buộc sinh học khác. Có thể nói nó cũng là một phương pháp rất tương thích sinh học và hiệu quả về mặt tính toán, dựa trên việc nó không có vận chuyển trọng số, tính dẻo không cục bộ, và khóa thời gian của các bản cập nhật trọng số, nó hoàn toàn không giám sát, Nó cũng được thành lập trên các quan sát thử nghiệm sinh lý trong các mạch vỏ não, như tính dẻo Hebbian và cấu trúc WTA. Quan trọng, các mạng Hebbian WTA như vậy cho phép các chip học neuromorphic không-von Neumann (Qiao et al., 2015; Kreiser et al., 2017; Sebastian et al., 2020; Indiveri, 2021; Sarwat et al., 2022a). Đó là một công nghệ tính toán mới nổi cực kỳ hiệu quả, và SoftHebb làm cho hiệu suất cao với phần cứng như vậy có khả năng hơn. Thuật toán có thể áp dụng trong các nhiệm vụ như MNIST, CIFAR-10, STL-10 và thậm chí ImageNet nơi các thuật toán khác với mục tiêu tương tự không áp dụng được hoặc đã hoạt động kém hơn SoftHebb (Hình 1, Bảng 1, Bảng 2, & Bartunov et al. (2018)). Điều này mặc dù thực tế là hầu hết các giải pháp thay thế chỉ giải quyết các tập con của các mục tiêu hiệu quả và tính khả thi của SoftHebb (Phần 2 & Bảng 1). Kết quả của L¨ owe et al. (2019) và Burstprop (Payeur et al., 2021) trên STL-10 và ImageNet không được bao gồm trong Bảng 2, vì ResNet-50 của L¨ owe et al. (2019) sử dụng BP chuẩn thông qua các module ít nhất 15 lớp, và vì Payeur et al. (2021) không báo cáo độ chính xác top-1 ImageNet. SoftHebb đã vượt trội hơn Burstprop và người kế nhiệm BurstCCN (Greedy et al., 2022) trên CIFAR-10 (Bảng 1). Ngoài các mạng nơ-ron, K-means cũng đã được áp dụng cho CIFAR-10 (Coates et al., 2011), tuy nhiên, không có việc xếp chồng thành công các "lớp" K-means.

Từ góc độ khoa học thần kinh, kết quả của chúng tôi cho thấy rằng Học sâu đến vài lớp có thể khả thi trong não không chỉ với các xấp xỉ của BP (Payeur et al., 2021; Illing et al., 2021; Greedy et al., 2022), mà còn với các cách tiếp cận hoàn toàn khác. Tuy nhiên, để tối đa hóa khả năng áp dụng, các chi tiết sinh học như các nơ-ron spiking đã được tránh trong các mô phỏng của chúng tôi. Trong bối cảnh ML, công trình của chúng tôi có những hạn chế quan trọng cần được lưu ý. Ví dụ, chúng tôi chỉ thử nghiệm SoftHebb trong các nhiệm vụ thị giác máy tính. Ngoài ra, không rõ cách áp dụng SoftHebb cho các kiến trúc mạng sâu chung, vì cho đến nay chúng tôi chỉ sử dụng các mạng tích chập được mở rộng chiều rộng cụ thể. Hơn nữa, mạng SoftHebb sâu nhất của chúng tôi chỉ có 6 lớp trong trường hợp ImageNet, sâu hơn hầu hết các cách tiếp cận tương thích sinh học (xem Bảng 1), nhưng hạn chế. Kết quả là, SoftHebb không thể cạnh tranh với trạng thái thực sự của nghệ thuật trong ML (xem ví dụ kết quả ResNet-50 SimCLR trong Bảng 2). Các mạng như vậy đã được gọi là "rất sâu" (Simonyan and Zisserman, 2014) và "cực kỳ sâu" (He et al., 2016). Điều này khác với thuật ngữ chung hơn "Học sâu" được giới thiệu ban đầu cho các mạng nông như của chúng tôi (Hinton et al., 2006) đã tiếp tục được sử dụng như vậy (xem ví dụ Frenkel et al. (2021) và Bảng 1), và đặc điểm của nó là biểu diễn phân cấp dường như xuất hiện trong nghiên cứu của chúng tôi. Chúng tôi đề xuất rằng SoftHebb đáng để khai thác thực tế các lợi thế hiện tại của nó, nghiên cứu xung quanh các hạn chế của nó, và tìm kiếm các dấu hiệu sinh lý có thể có của nó trong não.

9

--- TRANG 7 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Lời cảm ơn
Công trình này được hỗ trợ một phần bởi Dự án Lớn Khoa học và Công nghệ Đổi mới 2030 – (Khoa học Não và Công nghệ Thông minh giống Não) theo Grant 2022ZD0208700. Các tác giả xin cảm ơn Lukas Cavigelli, Renzo Andri, ´Edouard Carr´ e, và phần còn lại của Von Neumann Lab của Huawei, vì đã cung cấp tài nguyên tính toán. TM xin cảm ơn Yansong Chua, Alexander Simak, và Dmitry Toichkin cho các cuộc thảo luận.

Tài liệu tham khảo

Aitchison, L. (2020). Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods. Advances in Neural Information Processing Systems, 33:18173–18182.

Aitchison, L., Jegminat, J., Menendez, J. A., Pfister, J.-P., Pouget, A., và Latham, P. E. (2021). Synaptic plasticity as bayesian inference. Nature neuroscience, 24(4):565–571.

Akam, T. và Kullmann, D. M. (2014). Oscillatory multiplexing of population codes for selective communication in the mammalian brain. Nature Reviews Neuroscience, 15(2):111–122.

Amato, G., Carrara, F., Falchi, F., Gennaro, C., và Lagani, G. (2019). Hebbian learning meets deep convolutional neural networks. In International Conference on Image Analysis and Processing, trang 324–334. Springer.

Baldi, P., Sadowski, P., và Lu, Z. (2017). Learning in the machine: The symmetries of the deep learning channel. Neural Networks, 95:110–133.

Bartunov, S., Santoro, A., Richards, B., Marris, L., Hinton, G. E., và Lillicrap, T. (2018). Assessing the scalability of biologically-motivated deep learning algorithms and architectures. Advances in neural information processing systems, 31.

Bengio, Y., Lamblin, P., Popovici, D., và Larochelle, H. (2006). Greedy layer-wise training of deep networks. Advances in neural information processing systems, 19.

Binzegger, T., Douglas, R. J., và Martin, K. A. (2004). A quantitative map of the circuit of cat primary visual cortex. Journal of Neuroscience, 24(39):8441–8453.

Binzegger, T., Douglas, R. J., và Martin, K. A. (2009). Topology and dynamics of the canonical circuit of cat v1. Neural Networks, 22(8):1071–1078.

Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., và Joulin, A. (2020). Unsupervised learning of visual features by contrasting cluster assignments. Advances in Neural Information Processing Systems, 33:9912–9924.

Chen, T., Kornblith, S., Norouzi, M., và Hinton, G. (2020). A simple framework for contrastive learning of visual representations. In International conference on machine learning, trang 1597–1607. PMLR.

Coates, A., Ng, A., và Lee, H. (2011). An analysis of single-layer networks in unsupervised feature learning. In Proceedings of the fourteenth international conference on artificial intelligence and statistics, trang 215–223. JMLR Workshop and Conference Proceedings.

Crafton, B., West, M., Basnet, P., Vogel, E., và Raychowdhury, A. (2019). Local learning in rram neural networks with sparse direct feedback alignment. In 2019 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED), trang 1–6. IEEE.

Crick, F. (1989). The recent excitement about neural networks. Nature, 337(6203):129–132.

Czarnecki, W. M., ´Swirszcz, G., Jaderberg, M., Osindero, S., Vinyals, O., và Kavukcuoglu, K. (2017). Understanding synthetic gradients and decoupled neural interfaces. In International Conference on Machine Learning, trang 904–912. PMLR.

10

--- TRANG 8 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Diehl, P. U. và Cook, M. (2015). Unsupervised learning of digit recognition using spike-timing-dependent plasticity. Frontiers in computational neuroscience, 9:99.

Douglas, R. J. và Martin, K. A. (2004). Neuronal circuits of the neocortex. Annu. Rev. Neurosci., 27:419–451.

Douglas, R. J., Martin, K. A., và Whitteridge, D. (1989). A canonical microcircuit for neocortex. Neural computation, 1(4):480–488.

Dundar, A., Jin, J., và Culurciello, E. (2015). Convolutional clustering for unsupervised learning. arXiv preprint arXiv:1511.06241.

Erhan, D., Bengio, Y., Courville, A., và Vincent, P. (2009). Visualizing higher-layer features of a deep network. University of Montreal, 1341(3):1.

Feldman, D. E. (2012). The spike-timing dependence of plasticity. Neuron, 75(4):556–571.

Frenkel, C., Lefebvre, M., và Bol, D. (2021). Learning without feedback: Fixed random learning signals allow for feedforward training of deep neural networks. Frontiers in neuroscience, trang 20.

Goodfellow, I. J., Shlens, J., và Szegedy, C. (2014). Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572.

Greedy, W., Zhu, H. W., Pemberton, J., Mellor, J., và Costa, R. P. (2022). Single-phase deep learning in cortico-cortical networks. arXiv preprint arXiv:2206.11769.

Grill, J.-B., Strub, F., Altch´ e, F., Tallec, C., Richemond, P., Buchatskaya, E., Doersch, C., Avila Pires, B., Guo, Z., Gheshlaghi Azar, M., và cộng sự (2020). Bootstrap your own latent-a new approach to self-supervised learning. Advances in neural information processing systems, 33:21271–21284.

Grinberg, L., Hopfield, J., và Krotov, D. (2019). Local unsupervised learning for image analysis. arXiv preprint arXiv:1908.08993.

Grossberg, S. (1987). Competitive learning: From interactive activation to adaptive resonance. Cognitive science, 11(1):23–63.

Hadsell, R., Chopra, S., và LeCun, Y. (2006). Dimensionality reduction by learning an invariant mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), tập 2, trang 1735–1742. IEEE.

Halvagal, M. S. và Zenke, F. (2022). The combination of hebbian and predictive plasticity learns invariant object representations in deep sensory networks. bioRxiv.

He, K., Fan, H., Wu, Y., Xie, S., và Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, trang 9729–9738.

He, K., Zhang, X., Ren, S., và Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, trang 770–778.

Herzfeld, D. J., Kojima, Y., Soetedjo, R., và Shadmehr, R. (2015). Encoding of action by the purkinje cells of the cerebellum. Nature, 526(7573):439–442.

Hinton, G. (2022). The forward-forward algorithm: Some preliminary investigations. arXiv preprint arXiv:2212.13345.

Hinton, G. E., Osindero, S., và Teh, Y.-W. (2006). A fast learning algorithm for deep belief nets. Neural computation, 18(7):1527–1554.

Illing, B., Ventura, J., Bellec, G., và Gerstner, W. (2021). Local plasticity rules can learn deep representations using self-supervised contrastive predictions. Advances in Neural Information Processing Systems, 34.

11

--- TRANG 9 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Indiveri, G. (2021). Introducing" neuromorphic computing and engineering". Neuromorphic Computing and Engineering.

Ioffe, S. và Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, trang 448–456. PMLR.

Jaderberg, M., Czarnecki, W. M., Osindero, S., Vinyals, O., Graves, A., Silver, D., và Kavukcuoglu, K. (2017). Decoupled neural interfaces using synthetic gradients. In International conference on machine learning, trang 1627–1635. PMLR.

Kayser, C., Montemurro, M. A., Logothetis, N. K., và Panzeri, S. (2009). Spike-phase coding boosts and stabilizes information carried by spatial and temporal spike patterns. Neuron, 61(4):597–608.

Kolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., và Houlsby, N. (2020). Big transfer (bit): General visual representation learning. In European conference on computer vision, trang 491–507. Springer.

Kreiser, R., Moraitis, T., Sandamirskaya, Y., và Indiveri, G. (2017). On-chip unsupervised learning in winner-take-all networks of spiking neurons. In BioCAS, trang 1–4.

Krotov, D. và Hopfield, J. J. (2016). Dense associative memory for pattern recognition. Advances in neural information processing systems, 29:1172–1180.

Krotov, D. và Hopfield, J. J. (2019). Unsupervised learning by competing hidden units. Proceedings of the National Academy of Sciences, 116(16):7723–7731.

Laborieux, A., Ernoult, M., Scellier, B., Bengio, Y., Grollier, J., và Querlioz, D. (2021). Scaling equilibrium propagation to deep convnets by drastically reducing its gradient estimator bias. Frontiers in neuroscience, 15:129.

Lagani, G., Falchi, F., Gennaro, C., và Amato, G. (2021). Hebbian semi-supervised learning in a sample efficiency setting. Neural Networks, 143:719–731.

Le, Q., Ranzato, M., Monga, R., Devin, M., Chen, K., Corrado, G., Dean, J., và Ng, A. (2012). Building high-level features using large scale unsupervised learning. In Langford, J. và Pineau, J., biên tập, Proceedings of the 29th International Conference on Machine Learning (ICML-12), ICML '12, trang 81–88, New York, NY, USA. Omnipress.

Lee, H., Lee, K., Lee, K., Lee, H., và Shin, J. (2021). Improving transferability of representations via augmentation-aware self-supervision. Advances in Neural Information Processing Systems, 34.

Lillicrap, T. P., Cownden, D., Tweed, D. B., và Akerman, C. J. (2016). Random synaptic feedback weights support error backpropagation for deep learning. Nature communications, 7(1):1–10.

Linsker, R. (1992). Local synaptic learning rules suffice to maximize mutual information in a linear network. Neural Computation, 4(5):691–702.

L¨ owe, S., O'Connor, P., và Veeling, B. (2019). Putting an end to end-to-end: Gradient-isolated learning of representations. Advances in neural information processing systems, 32.

Madry, A., Makelov, A., Schmidt, L., Tsipras, D., và Vladu, A. (2017). Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083.

Markram, H., Gerstner, W., và Sj¨ ostr¨ om, P. J. (2011). A history of spike-timing-dependent plasticity. Frontiers in synaptic neuroscience, 3:4.

McInnes, L., Healy, J., và Melville, J. (2018). Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426.

12

--- TRANG 10 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Miconi, T. (2021). Multi-layer hebbian networks with modern deep learning frameworks. arXiv preprint arXiv:2107.01729.

Millidge, B., Tschantz, A., và Buckley, C. L. (2020). Predictive coding approximates backprop along arbitrary computation graphs. arXiv preprint arXiv:2006.04182.

Mitrovic, J., McWilliams, B., Walker, J., Buesing, L., và Blundell, C. (2020). Representation learning via invariant causal mechanisms. arXiv preprint arXiv:2010.07922.

Moraitis, T., Sebastian, A., và Eleftheriou, E. (2018). Spiking neural networks enable two-dimensional neurons and unsupervised multi-timescale learning. In 2018 International Joint Conference on Neural Networks (IJCNN), trang 1–8. IEEE.

Moraitis, T., Sebastian, A., và Eleftheriou, E. (2020). Short-term synaptic plasticity optimally models continuous environments.

Moraitis, T., Toichkin, D., Chua, Y., và Guo, Q. (2021). Softhebb: Bayesian inference in unsupervised hebbian soft winner-take-all networks. arXiv preprint arXiv:2107.05747.

Naud, R., Marcille, N., Clopath, C., và Gerstner, W. (2008). Firing patterns in the adaptive exponential integrate-and-fire model. Biological cybernetics, 99(4):335–347.

Nessler, B., Pfeiffer, M., Buesing, L., và Maass, W. (2013). Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity. PLoS computational biology, 9(4):e1003037.

Nessler, B., Pfeiffer, M., và Maass, W. (2009). Stdp enables spiking neurons to detect hidden causes of their inputs. Advances in neural information processing systems, 22:1357–1365.

Nguyen, A., Yosinski, J., và Clune, J. (2015). Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE conference on computer vision and pattern recognition, trang 427–436.

Nøkland, A. (2016). Direct feedback alignment provides learning in deep neural networks. Advances in neural information processing systems, 29.

Nøkland, A. và Eidnes, L. H. (2019). Training neural networks with local error signals. In International conference on machine learning, trang 4839–4850. PMLR.

Oja, E. (1982). Simplified neuron model as a principal component analyzer. Journal of mathematical biology, 15(3):267–273.

Payeur, A., Guerguiev, J., Zenke, F., Richards, B. A., và Naud, R. (2021). Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits. Nature neuroscience, 24(7):1010–1019.

Pehlevan, C. và Chklovskii, D. (2015). A normative theory of adaptive dimensionality reduction in neural networks. In Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., và Garnett, R., biên tập, Advances in Neural Information Processing Systems, tập 28. Curran Associates, Inc.

Pogodin, R., Mehta, Y., Lillicrap, T. P., và Latham, P. E. (2021). Towards biologically plausible convolutional networks. arXiv preprint arXiv:2106.13031.

Qiao, N., Mostafa, H., Corradi, F., Osswald, M., Stefanini, F., Sumislawska, D., và Indiveri, G. (2015). A reconfigurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128k synapses. Frontiers in neuroscience, 9:141.

Rauber, J., Zimmermann, R., Bethge, M., và Brendel, W. (2020). Foolbox native: Fast adversarial attacks to benchmark the robustness of machine learning models in pytorch, tensorflow, and jax. Journal of Open Source Software, 5(53):2607.

13

--- TRANG 11 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Rodriguez, H. G., Guo, Q., và Moraitis, T. (2022). Short-term plasticity neurons learning to learn and forget. In Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., và Sabato, S., biên tập, Proceedings of the 39th International Conference on Machine Learning, tập 162 của Proceedings of Machine Learning Research, trang 18704–18722. PMLR.

Sanger, T. D. (1989). Optimal unsupervised learning in a single-layer linear feedforward neural network. Neural networks, 2(6):459–473.

Sarwat, S. G., Kersting, B., Moraitis, T., Jonnalagadda, V. P., và Sebastian, A. (2022a). Phase-change memtransistive synapses for mixed-plasticity neural computations. Nature Nanotechnology, trang 1–7.

Sarwat, S. G., Moraitis, T., Wright, C. D., và Bhaskaran, H. (2022b). Chalcogenide optomemristors for multi-factor neuromorphic computation. Nature communications, 13(1):1–9.

Scellier, B. và Bengio, Y. (2017). Equilibrium propagation: Bridging the gap between energy-based models and backpropagation. Frontiers in computational neuroscience, 11:24.

Scherr, F., Guo, Q., và Moraitis, T. (2022). Self-supervised learning through efference copies.

Sebastian, A., Le Gallo, M., Khaddam-Aljameh, R., và Eleftheriou, E. (2020). Memory devices and applications for in-memory computing. Nature nanotechnology, 15(7):529–544.

Sejnowski, T. J. (2020). The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National Academy of Sciences, 117(48):30033–30038.

Simonyan, K. và Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.

Sj¨ ostr¨ om, P. J., Turrigiano, G. G., và Nelson, S. B. (2001). Rate, timing, and cooperativity jointly determine cortical synaptic plasticity. Neuron, 32(6):1149–1164.

Stuhr, B. và Brauer, J. (2019). Csnns: Unsupervised, backpropagation-free convolutional neural networks for representation learning. In 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), trang 1613–1620. IEEE.

Tavanaei, A. và Maida, A. S. (2016). Bio-inspired spiking convolutional neural network using layer-wise sparse coding and stdp learning. arXiv preprint arXiv:1611.03000.

Tomasev, N., Bica, I., McWilliams, B., Buesing, L., Pascanu, R., Blundell, C., và Mitrovic, J. (2022). Pushing the limits of self-supervised resnets: Can we outperform supervised learning without labels on imagenet? arXiv preprint arXiv:2201.05119.

Von der Malsburg, C. (1973). Self-organization of orientation sensitive cells in the striate cortex. Kybernetik, 14(2):85–100.

14

--- TRANG 12 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

A Chi tiết về các phương pháp

A.1 Khởi tạo trọng số

A.1.1 Chọn họ phân phối

Chúng tôi đã thử nghiệm ba họ phân phối xác suất để khởi tạo trọng số ngẫu nhiên; chuẩn, dương, và âm (Phương trình (3)).

chuẩn = N(µ = 0, σ²)  dương = U(0, phạm vi)  âm = U(0, -phạm vi),     (3)

trong đó U là phân phối đồng nhất. Chúng tôi thấy rằng chúng hoạt động tương tự nhau trong trường hợp thí nghiệm dài, nơi các ví dụ huấn luyện mở rộng đạt được việc căn chỉnh trọng số với đầu vào. Tuy nhiên, đối với các thí nghiệm ngắn hơn, nơi cần tốc độ, chúng tôi thấy rằng phân phối dương tốt hơn cho dữ liệu thô (giá trị đầu vào giữa 0-1) và phân phối chuẩn cho dữ liệu được chuẩn hóa thành điểm chuẩn. Tính chất clustering của học SoftHebb (Moraitis et al., 2021), nơi các đặc trưng học được là các centroid của các cụm trong không gian đầu vào có thể giải thích điều này. Trong thực tế, chúng tôi đã sử dụng dữ liệu chuẩn hóa cho các kết quả được báo cáo, và do đó chúng tôi đã sử dụng phân phối chuẩn cho các trọng số ngẫu nhiên ban đầu.

A.1.2 Chọn tham số phân phối

Bằng cách thay đổi các tham số phân phối, chúng tôi quan sát thấy rằng chuẩn của các vectơ trọng số tức là "bán kính" R rất có tính chỉ dẫn. Chúng tôi xác định ba vùng học tập khác nhau (Hình B.3A); đối với R nhỏ hơn 1, không có học tập với cập nhật trọng số ngẫu nhiên; đối với R lớn hơn 1 và nhỏ hơn khoảng 2.5, có học tập một phần với chỉ một tỷ lệ phần trăm nơ-ron thắng và hội tụ trong khi những cái khác vẫn ngẫu nhiên; đối với R lớn hơn 2.5, tất cả nơ-ron học. Sự thay đổi học tập quanh 1 đến từ thực tế là trọng số có xu hướng hội tụ đến bán kính 1 (Moraitis et al., 2021).

Xác định bán kính ban đầu từ các tham số phân phối trọng số: Sau đó chúng tôi có thể suy ra các tham số phân phối từ bán kính tối ưu ban đầu sử dụng tính toán moment phân phối.

Ri = E(√(∑(j=0 to N) Wij²)) = E(√(∑(j=0 to N) w²)) = E(√(N·w²)) = E(√N · |w|) = √N · E(|w|)     (4)

Trong đó i là chỉ số của một nơ-ron, j là chỉ số của các synapse của nơ-ron này, N là số synapse của nơ-ron đó, E() là giá trị kỳ vọng và vì vậy E(|w|) là moment tuyệt đối đầu tiên của phân phối. Do đó, đối với phân phối chuẩn E(|w|) = σ·√(2/π) ⇒ σ = R·√(π/(2N)) và phân phối dương E(|w|) = E(w) = phạm vi/2 ⇒ phạm vi = R·√(2/N).

A.2 Thích ứng tỷ lệ học

Các tỷ lệ học giảm tuyến tính với số lượng ví dụ huấn luyện đã được sử dụng rộng rãi trong học Hebbian (Krotov and Hopfield, 2019; Grinberg et al., 2019; Miconi, 2021; Lagani et al., 2021; Amato et al., 2019). Đó là một scheduler đơn giản, đạt hội tụ với một lượng ví dụ huấn luyện đủ. Sự suy giảm tuyến tính gắn giá trị tỷ lệ học trong suốt quá trình học với tỷ lệ các ví dụ huấn luyện đã được thấy, và nó làm điều đó đồng nhất qua các nơ-ron. Tuy nhiên, các trọng số có thể lý thuyết có thể hội tụ trước khi trình bày toàn bộ tập huấn luyện, và chúng có thể làm điều đó ở các giai đoạn khác nhau qua các nơ-ron. Để giải quyết điều này, chúng tôi gắn tỷ lệ học ηi với sự hội tụ của mỗi nơ-ron i. Sự hội tụ được đánh giá bởi chuẩn ri của trọng số của nơ-ron. Dựa trên công trình trước đây về các quy tắc học tương tự (Oja, 1982; Krotov and Hopfield, 2019) bao gồm chính SoftHebb (Moraitis et al., 2021), và trên các quan sát mới của chúng tôi, sự hội tụ của các trọng số nơ-ron liên quan đến sự hội tụ đến chuẩn 1, ít nhất trong trường hợp các đặc trưng học đơn giản. Do đó, chúng tôi đã sử dụng một tỷ lệ học ổn định về 0 khi các vectơ trọng số nơ-ron hội tụ đến một hình cầu bán kính 1, và ban đầu lớn khi các vectơ trọng số lớn so với 1:

15

--- TRANG 13 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

ηi = η · (ri - 1)q,     (5)

trong đó q là một siêu tham số lũy thừa. Lưu ý rằng tính thích ứng này không có sự phụ thuộc thời gian rõ ràng, nhưng khi việc học tiến tới hội tụ, η thực sự giảm theo thời gian. Để tính đến trường hợp các đặc trưng phức tạp không hội tụ đến chuẩn 1, một sự phụ thuộc thời gian có thể được thêm vào trên đó, ví dụ như thông thường với một hệ số giảm tuyến tính, nhân với tỷ lệ học phụ thuộc chuẩn. Trong các thí nghiệm của chúng tôi, chúng tôi chỉ sử dụng sự phụ thuộc chuẩn và đơn giản là ngừng học sau epoch huấn luyện đầu tiên, tức là lần trình bày đầu tiên của tập huấn luyện đầy đủ trong hầu hết các trường hợp, hoặc sớm hơn. Trong thực tế, tỷ lệ thích ứng của chúng tôi đạt hội tụ nhanh hơn (Hình B.3B) so với sự phụ thuộc thời gian tuyến tính, bằng cách duy trì một tỷ lệ học riêng biệt cho mỗi nơ-ron và thích ứng nó dựa trên trạng thái hội tụ của riêng mỗi nơ-ron.

A.3 Kiến trúc lớp

Mỗi lớp tích chập bao gồm một chuỗi chuẩn hóa batch, một tích chập SoftHebb, một phép toán pooling, và sau đó là một hàm kích hoạt. Stride tích chập SoftHebb được cố định ở 1. Padding được thêm vào đầu vào của các bộ lọc tích chập để đảm bảo đầu ra của chúng có cùng kích thước với đầu vào không có padding. Stride pooling được cố định ở 2, giảm một nửa mỗi chiều của độ phân giải sau mỗi lớp. Trong tất cả các thí nghiệm, lớp đầu tiên có chiều rộng 96 kernel tích chập (Miconi, 2021; Lagani et al., 2021; Amato et al., 2019), ngoại trừ các thí nghiệm ImageNet nơi chúng tôi sử dụng 48 kernel. Số lượng kernel trong các lớp tiếp theo được xác định theo phương pháp mở rộng chiều rộng của chúng tôi, với hệ số chiều rộng 4 (xem Phụ lục A.5).

A.3.1 Hàm kích hoạt

Softmax, tức là đầu ra của soft winner-take-all được sử dụng làm biến hậu synapse y trong tính dẻo của SoftHebb. Tuy nhiên, đối với lan truyền tiến đến lớp tiếp theo, chúng tôi đã xem xét ba hàm kích hoạt; Đơn vị đa thức chỉnh lưu (RePU), triangle, và softmax. RePU (Phương trình (6)) được đề xuất bởi Krotov and Hopfield (2016) như một sự tổng quát hóa của các đơn vị tuyến tính chỉnh lưu (ReLU) và cũng được sử dụng trong các công trình tiếp theo (Krotov and Hopfield, 2019; Grinberg et al., 2019). Kích hoạt Triangle được giới thiệu bởi Coates et al. (2011) cho clustering k-means và cũng có vẻ hữu ích cho các mạng Hebbian trong (Miconi, 2021). Nó trừ hoạt động trung bình tính toán trên tất cả các kênh tại mỗi vị trí và sau đó áp dụng ReLU. Ở đây chúng tôi tổng quát hóa Triangle bằng cách kết hợp nó với RePU (thay vì ReLU) thông qua Phương trình (7):

RePU(u) = {uᵖ, cho u > 0; 0, cho u ≤ 0}     (6)
Triangle(uj) = RePU(uj - ū)     (7)

A.4 Tối ưu hóa siêu tham số

Chúng tôi đã điều tra có hệ thống tập siêu tham số tốt nhất tại mỗi lớp ẩn, dựa trên độ chính xác validation của một bộ phân loại tuyến tính được huấn luyện trực tiếp trên đầu ra của lớp ẩn đó. Tất cả các tìm kiếm lưới được thực hiện trên ba seed ngẫu nhiên khác nhau, thay đổi việc lấy mẫu batch và tập validation (20% của bộ dữ liệu huấn luyện). Bộ phân loại là một bộ phân loại tuyến tính đơn giản với dropout 0.5 và không có số hạng chính quy hóa khác. Đối với tất cả các tìm kiếm và kết quả cuối cùng, chúng tôi đã sử dụng 96 kernel trong lớp đầu tiên. Các lớp tiếp theo được mở rộng với fw = 4 (xem Phụ lục A.5). Tuy nhiên, dựa trên các quan sát của chúng tôi, chỉ nhiệt độ tối ưu phụ thuộc vào fw.

Đối với mỗi lớp được thêm vào, tìm kiếm lưới được thực hiện trong ba giai đoạn: Đối với hai giai đoạn đầu tiên, chúng tôi đã sử dụng các kernel tích chập vuông có kích thước 5, max-pooling với kernel vuông kích thước 2, và Triangle với lũy thừa 1 làm hàm kích hoạt tiến.

1. Trong giai đoạn này, chúng tôi đã thực hiện tìm kiếm lưới trên các siêu tham số còn lại (nbepochs, batch size, η và q của scheduler tỷ lệ học, và nhiệt độ τ của softmax SoftHebb). Chúng tôi đã thay đổi nbepochs ∈ {1,10,50,100,1000}, batch size ∈

16

--- TRANG 14 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

lớp | phép toán | siêu tham số tìm kiếm | phạm vi | tối ưu tìm thấy
1 | conv | η [0.001-0.12] | 0.08
| | q [0.25, 0.5, 0.75] | 0.5
| | kích thước kernel [3, 5, 7, 9] | 5
| | 1/τ [0.1-100] | 1
| pooling | loại [AvgPooling, MaxPooling] | MaxPooling
| | kích thước kernel [2, 3, 4] | 4
| kích hoạt | hàm [Softmax, RePU, Triangle] | Triangle
| | lũy thừa [0.1-10] | 0.7

2 | conv | η [0.001-0.12] | 0.005
| | q [0.25, 0.5, 0.75] | 0.5
| | kích thước kernel [3, 5, 7, 9] | 3
| | 1/τ [0.1-100] | 0.65
| pooling | loại [AvgPooling, MaxPooling] | MaxPooling
| | kích thước kernel [2,3,4] | 4
| kích hoạt | hàm [Softmax, RePU, Triangle] | Triangle
| | lũy thừa [0.1-10] | 1.4

3 | conv | η [0.001-0.12] | 0.01
| | q [0.25, 0.5, 0.75] | 0.5
| | kích thước kernel [3, 5, 7, 9] | 3
| | 1/τ [0.1-100] | 0.25
| pooling | loại [AvgPooling, MaxPooling] | AvgPooling
| | kích thước kernel [2,3,4] | 2
| kích hoạt | hàm [Softmax, RePU, Triangle] | Triangle
| | lũy thừa [0.1-10] | 1

Bảng 3: Tìm kiếm kiến trúc mạng và siêu tham số, và kết quả tốt nhất trên CIFAR-10. Thêm chi tiết được cung cấp trong phần A.4.

{10,100,1000}, η ∈ {0.001,0.004,0.008,0.01,0.04,0.08,0.12}, q ∈ {0.25,0.5,0.75} và 1/τ ∈ {0.25,0.5,0.75,1,2,5,10}.

2. Một tìm kiếm lưới tinh hơn trên 1/τ ∈ {0.15,0.25,0.35,0.5,0.6,0.75,0.85,1,1.2,1.5,2} và kích thước kernel conv ∈ {3,5,7,9} sử dụng kết quả tốt nhất từ tìm kiếm trước đó.

3. Một tìm kiếm lưới cuối cùng trên pooling: loại pool ∈ {AvgPooling, MaxPooling}, kích thước kernel pool ∈ {2,3,4}, và hàm kích hoạt: hàm ∈ {RePU, Triangle, Softmax} với lũy thừa ∈ {0.1,0.35,0.7,1,1.4,2,5,10} (cho RePU hoặc Triangle) và τ ∈ {0.1,0.5,1,2,5,10,50,100} (cho softmax) sử dụng kết quả tốt nhất từ hai tìm kiếm trước đó.

A.5 Kiến trúc đa lớp

Pooling có stride 2 giảm một nửa mỗi chiều của độ phân giải sau mỗi lớp. Chúng tôi ngừng thêm lớp khi độ phân giải đầu ra trở thành nhiều nhất 4 ×4. Lớp nơi điều này xảy ra phụ thuộc vào độ phân giải của đầu vào gốc. Do đó, mạng đa lớp có ba lớp tích chập cho MNIST hoặc CIFAR-10, bốn lớp cho STL-10, và năm lớp cho ImageNet ở thiết lập độ phân giải 160 ×160 px (Bảng 4).

Một hệ số chiều rộng fw đặc trưng cho mạng đa lớp. fw liên kết chiều rộng của mỗi lớp với lớp trước đó, do đó xác định kiến trúc phụ thuộc độ sâu. Cụ thể, số lượng bộ lọc #Fl trong lớp ẩn l là fw lần số lượng bộ lọc tại lớp l-1:

#Fl = fw · #Fl-1. Lớp ẩn đầu tiên có 96 bộ lọc để so sánh với Miconi (2021); Lagani et al. (2021); Amato et al. (2019). Sau đó chúng tôi đã khám phá, sử dụng CIFAR-10, tác động của fw lên hiệu suất. Chúng tôi đã thử ba giá trị khác nhau cho fw ∈ {1,2,4}. Giá trị 1 giữ cùng số lượng bộ lọc trong tất cả các lớp, trong khi giá trị 4 giữ số lượng đặc trưng được cung cấp cho đầu phân loại bằng số lượng đặc trưng tại lớp đầu vào (do stride pooling 2 trong mỗi lớp). Một fw lớn hơn bốn sẽ tăng đáng kể

17

--- TRANG 15 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

# lớp | MNIST/CIFAR | STL10 | ImageNet
1 | Batchnorm | Batchnorm | Batchnorm
| 5×5 conv96 | 5×5 conv96 | 5×5 conv48
| Triangle | Triangle | Triangle
| 4×4 MaxPool | 4×4 MaxPool | 4×4 MaxPool

2 | Batchnorm | Batchnorm | Batchnorm
| 3×3 conv384 | 3×3 conv384 | 3×3 conv192
| Triangle | Triangle | Triangle
| 4×4 MaxPool | 4×4 MaxPool | 4×4 MaxPool

3 | Batchnorm | Batchnorm | Batchnorm
| 3×3 conv1536 | 3×3 conv1536 | 3×3 conv768
| Triangle | Triangle | Triangle
| 2×2 AvgPool | 4x4 MaxPool | 4×4 MaxPool

4 | | Batchnorm | Batchnorm
| | 3×3 conv6144 | 3×3 conv3072
| | Triangle | Triangle
| | 2×2 AvgPool | 4×4 MaxPool

5 | | | Batchnorm
| | | 5×5 conv12288
| | | Triangle
| | | 2×2 AvgPool

Bảng 4: Kiến trúc mạng (tất cả các lớp pooling sử dụng stride 2). Số lượng kênh cũng được định nghĩa, ví dụ conv96 có nghĩa là 96 kênh. Thêm chi tiết có thể tìm thấy trong Phụ lục A.5.

kích thước của mạng, và không thực tế cho các mạng sâu hơn. Chúng tôi thấy rằng để tăng hiệu suất với độ sâu, mạng cũng cần phát triển về chiều rộng (Hình 4).

A.6 Giao thức huấn luyện và đánh giá

Mỗi thí nghiệm được thực hiện 4 lần, với các khởi tạo ngẫu nhiên, trên tất cả các bộ dữ liệu ngoại trừ ImageNet đầy đủ nơi chỉ một seed ngẫu nhiên được thử.

A.6.1 Huấn luyện SoftHebb

Số lượng vòng lặp cập nhật trọng số SoftHebb tối ưu là khoảng 5000 dựa trên các thí nghiệm CIFAR-10. Do đó, đối với CIFAR-10 và MNIST (50k ví dụ huấn luyện), huấn luyện không giám sát được thực hiện trong một epoch với mini-batch 10 và 20 cho tập huấn luyện không nhãn STL-10 (100k ví dụ huấn luyện). Do số lượng lớn các ví dụ huấn luyện, chúng tôi chọn ngẫu nhiên 10% của bộ dữ liệu ImageNet với mini-batch 20. Độ chính xác mà chúng tôi báo cáo cho SoftHebb là cho các lớp được huấn luyện liên tiếp, có nghĩa là mỗi lớp SoftHebb được huấn luyện, và sau đó đóng băng, trước khi lớp tiếp theo được huấn luyện. Tuy nhiên, kết quả rất tương tự cho huấn luyện đồng thời của tất cả các lớp, nơi mỗi ví dụ huấn luyện cập nhật tất cả các lớp, khi nó đi tiến qua mạng sâu.

A.6.2 Huấn luyện có giám sát

Bộ phân loại tuyến tính trên đầu sử dụng mini-batch 64 và huấn luyện trên 50 epoch cho MNIST và CIFAR-10, 100 epoch cho STL-10, và 200 epoch cho ImageNet. Đối với tất cả các bộ dữ liệu, tỷ lệ học có giá trị ban đầu 0.001 và được giảm một nửa liên tục tại [20%, 35%, 50%, 60%, 70%, 80%, 90%] của tổng số epoch. Tăng cường dữ liệu (cắt ngẫu nhiên và lật) được áp dụng cho STL-10 và ImageNet.

18

--- TRANG 16 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

A.6.3 Các mạng được huấn luyện bằng Lan truyền ngược

Kết quả so sánh SoftHebb và Lan truyền ngược được tìm thấy sử dụng cùng kiến trúc mạng. Sự khác biệt duy nhất là hàm kích hoạt; chúng tôi thấy rằng kích hoạt triangle hoặc softmax sẽ có hại cho BP. Hàm kích hoạt mà chúng tôi sử dụng cho các mạng được huấn luyện BP là ReLU. Tỷ lệ học theo cùng lịch trình như được mô tả trong Phụ lục A.6.2.

A.6.4 Tinh chỉnh

Trong thí nghiệm tinh chỉnh trên STL-10, tất cả các lớp Hebbian CNN học sử dụng SoftHebb và bộ dữ liệu huấn luyện không nhãn lớn của STL-10; sau đó, một lớp đầu ra được thêm vào và toàn bộ mạng được huấn luyện end-to-end sử dụng BP trên tập con huấn luyện có nhãn nhỏ đầy đủ.

A.7 Trường tiếp nhận

Chúng tôi đã hình dung các trường tiếp nhận (RF) của các lớp ẩn trong mạng (Hình 2 và cuối Phụ lục B). Phương pháp mà chúng tôi sử dụng là tối đa hóa kích hoạt (Erhan et al., 2009; Le et al., 2012; Goodfellow et al., 2014; Nguyen et al., 2015). Cụ thể, chúng tôi bắt đầu từ một hình vuông các pixel ngẫu nhiên, và chúng tôi tối ưu hóa đầu vào thông qua gradient descent (hoặc đúng hơn là ascent) để tối đa hóa kích hoạt của mỗi nơ-ron, dưới ràng buộc của chuẩn L2 của 1, tức là phép chiếu lên hình cầu đơn vị. Đó là một hình thức của projected gradient descent (PGD), cũng có thể được sử dụng như một cuộc tấn công đối kháng, nếu một hàm mất mát thay vì hàm kích hoạt được tối đa hóa. Cho mục đích này, chúng tôi đã sửa đổi một bộ công cụ cho các cuộc tấn công đối kháng, có tên Foolbox (Rauber et al., 2020). Chúng tôi hiển thị RF tối đa hóa phản ứng tuyến tính của các nơ-ron, tức là tổng đầu vào có trọng số. Chúng tôi đã điều chỉnh kích thước bước của descent, và chúng tôi đã xác nhận cách tiếp cận (a) bằng cách xác minh rằng số lượng vòng lặp đủ cho hội tụ, (b) bằng cách xác nhận rằng kết quả của nó tại lớp đầu tiên khớp với trọng số của lớp, (c) bằng cách xác minh rằng các nơ-ron ẩn được kích hoạt mạnh nếu mạng được cung cấp với đầu vào khớp với RF được tìm thấy của nơ-ron, và (d) bằng cách thấy rằng các khởi tạo thay thế cũng hội tụ đến cùng RF. Chúng tôi cũng đã thử một phương pháp thay thế được sử dụng bởi Miconi (2021). Cụ thể, chúng tôi đã sử dụng mã có sẵn của bài báo đó (https://github.com/ThomasMiconi/HebbianCNNPyTorch). Chúng tôi thấy rằng các RF được tìm thấy bởi PGD kích hoạt các nơ-ron nhiều hơn các RF được tìm thấy bởi phương pháp thay thế. Hơn nữa, PGD tính đến pooling và các hàm kích hoạt, mà phương pháp khác không làm. Do đó chúng tôi đã chọn trình bày kết quả từ PGD. Kết quả ví dụ được trình bày trong Hình 2 cũng như dưới dạng mở rộng với nhiều ví dụ hơn ở cuối Phụ lục B.

19

--- TRANG 17 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

B Kết quả và phân tích bổ sung

B.1 Tác động của nhiệt độ. SoftHebb dẫn đến một chế độ học mới.

Hình B.1: Các chế độ phụ thuộc nhiệt độ của SoftHebb trong một CNN một lớp được huấn luyện trên CIFAR-10. Với tính dẻo anti-Hebbian và SoftHebb (nhưng không phải hard WTA), một chế độ tồn tại nơi các đặc trưng R1 và không R1 cùng tồn tại và độ chính xác là tối đa.

Hình B.2: Giống như Hình B.1, nhưng trong mạng 3 lớp ẩn, sao cho tất cả các lớp sử dụng cùng nhiệt độ. Các đặc trưng R1 được báo cáo như một tỷ lệ phần trăm trên tất cả các đặc trưng của tất cả các lớp.

20

--- TRANG 18 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

B.2 Tác động của tỷ lệ học thích ứng. Nó tăng độ mạnh mẽ và tốc độ học.

(A) Độ mạnh mẽ đối với khởi tạo trọng số của sơ đồ tỷ lệ học thích ứng phụ thuộc chuẩn của chúng tôi, so với một scheduler tuyến tính. Sơ đồ thích ứng đạt độ chính xác cao cho một phạm vi rộng các khởi tạo trọng số. Ở đây khởi tạo được tham số hóa bởi bán kính của hình cầu nơi các vectơ trọng số nằm ban đầu.

(B) Tốc độ hội tụ của sơ đồ tỷ lệ học thích ứng phụ thuộc chuẩn của chúng tôi, so với một scheduler tuyến tính. Với sơ đồ thích ứng, các vectơ trọng số nơ-ron hội tụ đến hình cầu bán kính 1 (tức là trở thành đặc trưng R1) nhanh hơn.

Hình B.3: Tác động của tỷ lệ học thích ứng của chúng tôi.

Chúng tôi suy đoán rằng bán kính ban đầu thấp có vấn đề (Hình B.3A) vì trong chế độ đó sự cân bằng giữa kích thích (từ đầu vào) và ức chế (từ soft WTA) quá nghiêng về phía ức chế. Về Hình B.3B, xem thêm văn bản chính Phần 3, "Tỷ lệ học thích ứng phụ thuộc chuẩn trọng số", và đoạn văn liên quan trong Phần 4.

B.3 Tác động của hàm kích hoạt

Việc lựa chọn hàm kích hoạt cho lan truyền tiến qua các lớp SoftHebb là quan trọng. Để nghiên cứu điều này, chúng tôi đã so sánh hiệu suất của SoftHebb trên CIFAR-10 cho các hàm kích hoạt khác nhau. Trong mỗi kết quả, tất cả các nơ-ron qua tất cả các lớp sử dụng cùng siêu tham số hàm kích hoạt, ngoại trừ trường hợp Triangle. Các tham số được thử là:

• Lũy thừa của RePU: 0.7*, 1.0, 1.4.
• Nhiệt độ của softmax: 4.0*, 1/0.65, 1.0.

Ba giá trị này được thử vì chúng tốt cho các lớp cá nhân trong điều chỉnh trước đó. Dấu hoa thị chỉ ra giá trị tham số tốt nhất theo độ chính xác validation. Sử dụng các giá trị tốt nhất đã tạo ra kết quả độ chính xác kiểm tra được báo cáo bên dưới, trong khi các siêu tham số còn lại không được điều chỉnh cho mỗi trường hợp, mà đúng hơn là giống nhau, như được tìm thấy cho Triangle bởi quá trình được mô tả trong Phụ lục A.4.

• ReLU: (70.68 ±1.07)%
• tanh: (56.13 ±0.34)%
• RePU: (79.08 ±0.13)%
• softmax: (54.05 ±0.55)%
• RePU + Triangle: (80.31 ±0.14)%

B.4 Tác động của chiều rộng (số lượng nơ-ron)

Chiều rộng của các lớp khá có tác động, như được chỉ ra bằng cách thay đổi hệ số chiều rộng của các lớp sâu trong khi giữ chiều rộng lớp đầu tiên không đổi (Hình 4). Để nghiên cứu thêm tác động đó, chúng tôi đã thay đổi chiều rộng lớp đầu tiên và giữ hệ số chiều rộng cố định ở 4 (mở rộng tất cả các lớp). Kết quả được trình bày trong Hình B.4.

Hình B.4: Hiệu suất trên CIFAR-10 cho chiều rộng thay đổi của các lớp. Chiều rộng lớp đầu tiên được chỉ ra, trong khi các lớp tiếp theo được mở rộng bởi hệ số chiều rộng 4 (xem Phụ lục A.5).

Đối với thí nghiệm kiểm soát này, chúng tôi không điều chỉnh lại các siêu tham số cho mỗi chiều rộng, mà chỉ cho trường hợp 96-nơ-ron. Điều đó trái ngược với Hình 4, nơi các siêu tham số được điều chỉnh cho mỗi hệ số chiều rộng.

22

--- TRANG 19 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

(A) Hard WTA  (B) SoftHebb  (C) Backprop

Hình B.5: Trường tiếp nhận của các nơ-ron lớp tích chập đầu tiên, được học từ CIFAR-10 bởi các thuật toán khác nhau.

B.5 Nghiên cứu thêm về các biểu diễn ẩn.

Như một kiểm soát, chúng tôi thực hiện lại thí nghiệm mà chúng tôi đã trình bày trong Hình 5, lần này so sánh với một mạng với các trọng số ban đầu, chưa được huấn luyện, ngẫu nhiên. Kết quả được hiển thị trong Hình B.6 và Hình B.7.

(A) Trọng số được huấn luyện với SoftHebb.  (B) Trọng số ngẫu nhiên.

Hình B.6: Phép chiếu UMAP (tương tự như Hình 5 của văn bản chính, hàng trên) của tập kiểm tra sau khi đi qua 4 lớp SoftHebb. Ở đây, (A) từ một mạng được huấn luyện và (B) từ một mạng được khởi tạo ngẫu nhiên, chưa được huấn luyện.

23

--- TRANG 20 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Lớp 4 Lớp 1
(A) Trọng số được huấn luyện với SoftHebb.
Lớp 1
Lớp 4 (B) Trọng số ngẫu nhiên.

Hình B.7: Hình ảnh và các miếng kích hoạt tốt nhất 5 nơ-ron ngẫu nhiên từ Lớp 1 và 4 của SoftHebb (tương tự như Hình 5 của văn bản chính, hàng dưới). Ở đây, (A) từ một mạng được huấn luyện và (B) từ một mạng được khởi tạo ngẫu nhiên, chưa được huấn luyện.

B.6 Trường tiếp nhận bổ sung được tìm thấy thông qua PGD.

Đối với phương pháp, xem Phụ lục A.7. RF của các lớp sâu hơn không phải tất cả đều giống Gabor, mà cũng bao gồm sự kết hợp của các bộ lọc Gabor, và cũng có các hình dạng và kết cấu khác nhau. Ngoài ra, RF có vẻ ngày càng phức tạp với độ sâu. Những kết quả này có thể được mong đợi dựa trên RF của lớp đầu tiên, đã phức tạp hơn các bộ lọc Gabor đơn thuần được học bởi các cách tiếp cận Hebbian khác, như hard WTA (Hình B.5A). Sự kết hợp của chúng trong các lớp tiếp theo sau đó khó có thể chỉ tạo ra các bộ lọc Gabor. Khó để giải thích chính xác mỗi RF, nhưng điều này phổ biến trong các cấu trúc phân cấp của các mạng nơ-ron sâu.

24

--- TRANG 21 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình B.8: Tất cả trường tiếp nhận của lớp 1, được học từ STL-10.

25

--- TRANG 22 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình B.9: 250 trường tiếp nhận được lấy mẫu ngẫu nhiên của lớp 2, được học từ STL-10.

26

--- TRANG 23 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình B.10: 250 trường tiếp nhận được lấy mẫu ngẫu nhiên của lớp 3, được học từ STL-10.

27

--- TRANG 24 ---
Xuất bản như một bài báo hội nghị tại ICLR 2023

Hình B.11: 250 trường tiếp nhận được lấy mẫu ngẫu nhiên của lớp 4, được học từ STL-10.

28

# Trích xuất Mẫu Thích ứng Đa Nhiệm Học tập cho
Ước lượng Chuyển đổi Đa Bước
Xuewen Tao∗
xuewen.txw@mybank.cn
MYbank, Ant Group
Bắc Kinh, Trung Quốc

Mingming Ha∗
hamingming_0705@foxmail.com
Trường Tự động hóa và Kỹ thuật Điện, Đại học Khoa học và Công nghệ Bắc Kinh; MYbank, Ant Group
Bắc Kinh, Trung Quốc

Qiongxu Ma
qiongxu.mqx@mybank.cn
MYbank, Ant Group
Thượng Hải, Trung Quốc

Hongwei Cheng
chw286885@mybank.cn
MYbank, Ant Group
Thượng Hải, Trung Quốc

Wenfang Lin
moxi.lwf@mybank.cn
MYbank, Ant Group
Hàng Châu, Chiết Giang, Trung Quốc

Xiaobo Guo†
xb_guo@bjtu.edu.cn
Viện Khoa học Thông tin, Đại học Giao thông Bắc Kinh, Mybank, Ant Group
Bắc Kinh, Trung Quốc

Tóm tắt
Học tập đa nhiệm (MTL) đã được sử dụng thành công trong nhiều ứng dụng thực tế, nhằm mục tiêu giải quyết đồng thời nhiều tác vụ với một mô hình duy nhất. Ý tưởng chung của học tập đa nhiệm là thiết kế các loại cơ chế chia sẻ tham số toàn cục và trích xuất đặc trưng cụ thể cho từng tác vụ để cải thiện hiệu suất của tất cả các tác vụ. Tuy nhiên, thách thức vẫn còn trong việc cân bằng sự đánh đổi giữa các tác vụ khác nhau vì hiệu suất mô hình nhạy cảm với mối quan hệ giữa chúng. Các tác vụ ít tương quan hoặc thậm chí xung đột sẽ làm giảm hiệu suất bằng cách đưa vào thông tin không hữu ích hoặc tiêu cực. Do đó, việc khai thác hiệu quả và học biểu diễn đặc trưng mịn tương ứng với từng tác vụ là quan trọng. Trong bài báo này, chúng tôi đề xuất khung Trích xuất Mẫu Thích ứng Đa nhiệm (APEM), có tính thích ứng và linh hoạt cho ứng dụng công nghiệp quy mô lớn. APEM có thể tận dụng đầy đủ thông tin đặc trưng bằng cách học tương tác giữa các trường đặc trưng đầu vào và trích xuất thông tin cụ thể cho từng tác vụ tương ứng. Đầu tiên, chúng tôi giới thiệu mô-đun DeepAuto Group Transformer để tự động và hiệu quả tăng cường tính biểu cảm đặc trưng với cơ chế tập trung sửa đổi và phép toán Squeeze-and-Excitation. Thứ hai, Bộ chọn Mẫu rõ ràng được giới thiệu để tiếp tục cho phép học biểu diễn đặc trưng có chọn lọc bởi các vectơ chỉ thị tác vụ thích ứng. Các đánh giá thực nghiệm cho thấy APEM vượt trội so với các phương pháp MTL tiên tiến nhất trên bộ dữ liệu dịch vụ tài chính công cộng và thực tế. Quan trọng hơn, chúng tôi khám phá hiệu suất trực tuyến của APEM trong một kịch bản đề xuất cấp công nghiệp thực tế.

∗Những tác giả này đóng góp bình đẳng cho nghiên cứu này.
†Xiaobo Guo là tác giả liên hệ.

Khái niệm CCS: •Hệ thống thông tin →Ứng dụng hệ thống thông tin ;Quảng cáo tính toán ;•Học tập Đa nhiệm ;

Từ khóa: Hệ thống Đề xuất, Phụ thuộc Tuần tự, Học tập Đa Nhiệm, Học Biểu diễn

1 Giới thiệu
Học tập đa nhiệm (MTL) đã có những thành công đáng kể trong nhiều tình huống thực tế khác nhau, như đề xuất trực tuyến [7,22], quảng cáo hiển thị [5], quản lý thu hút khách hàng, dịch vụ tài chính [30] và vân vân. Các kỹ thuật MTL đồng thời học nhiều tác vụ bằng cách truyền thông điệp một cách ngầm định giữa các tác vụ liên quan [3,24], so với học tập một tác vụ, có thể cải thiện hiệu suất tổng thể của các tác vụ này [4,20]. Trong quảng cáo trực tuyến, đề xuất, và thu hút khách hàng v.v., ước lượng tỷ lệ nhấp chuột sau xem (CTR), tỷ lệ chuyển đổi sau nhấp (CVR) và tỷ lệ nhấp chuột & chuyển đổi sau xem (CTCVR) là một loạt các tác vụ cổ điển [15,29] với sự phụ thuộc tuần tự của quá trình thu hút khách hàng.

Trong trường hợp này, mẫu tuần tự của hành vi người dùng có nghĩa là hành động sau chỉ xảy ra sau hành động trước. Tổng quát hơn, mẫu tuần tự này có thể được mở rộng thành chuyển đổi đa bước. Như thể hiện trong Hình 1, một ví dụ về chuyển đổi đa bước trong dịch vụ tài chính tuân theo nghiêm ngặt mẫu phụ thuộc tuần tự này. Một khách hàng sẽ chuyển đổi qua các giai đoạn Hiển thị→Nhấp chuột→Ủy quyền→Chuyển đổi. Các hành vi chuyển đổi như xin vay, gửi tiền hoặc mua sản phẩm đầu tư chỉ được phép sau khi có ủy quyền. Nhằm mục đích các loại ứng dụng công nghiệp cụ thể, các nghiên cứu mở rộng [6,14,15,25,26,28] tập trung vào ước lượng CTR và CVR. Tuy nhiên, có ít công trình cung cấp định nghĩa chính thức về vấn đề học tập đa nhiệm phụ thuộc tuần tự (SDMTL), điều này đặc biệt quan trọng trong ước lượng chuyển đổi đa bước có thể áp dụng cho các tình huống đa dạng hơn. Ngoài ra, mối liên hệ và sự khác biệt giữa MTL tổng quát và SDMTL cũng chưa rõ ràng.

Các giai đoạn Chuyển đổi
Hiển thị Nhấp chuột Ủy quyền Vay
Tài chính

Hình 1. Một minh họa về chuyển đổi đa bước trong Dịch vụ Tài chính.

Một loạt công trình từ ESMM [15] đến ESCM2 [29] chú ý nhiều hơn đến vấn đề ước lượng CVR không thiên vị trong quan điểm nhân quả để điều chỉnh sai lệch lựa chọn mẫu. Mối quan hệ phụ thuộc giữa các tác vụ như CTR và CVR được gợi ý ngầm định qua phân phối của không gian mẫu. Gần đây, [30] nắm bắt sự phụ thuộc tác vụ thông qua truyền thông tin giữa các bước chuyển đổi khác nhau và kết hợp bộ hiệu chỉnh để tiếp tục ràng buộc mối quan hệ phụ thuộc. Tuy nhiên, sự phụ thuộc giữa mỗi bước vẫn chưa được định nghĩa và thảo luận sâu trong hầu hết các công trình MTL từ một định dạng lý thuyết.

Bên cạnh đó, như đã đề cập ở trên, các phương pháp MTL cải thiện kết quả dự đoán thông qua cơ chế truyền thông tin giữa các tác vụ, điều này cho thấy việc chia sẻ đặc trưng không phù hợp sẽ dẫn đến hiệu suất thậm chí kém hơn hoặc mất cân bằng trong các tác vụ khác nhau được biết đến như hiện tượng truyền tiêu cực. Do đó, phương pháp tổng quát trong MTL chủ yếu tập trung vào thiết kế các loại mô-đun trích xuất thông tin (chuyên gia) để học biểu diễn chung và cụ thể cho tác vụ. Như Cross-Stitch Network [16] và Sluice Network [19] sử dụng tổ hợp tuyến tính để tận dụng biểu diễn của các tác vụ khác nhau nhưng cũng yêu cầu nhiều tham số đào tạo hơn. Phương pháp SOTA của Multi-gate Mixture-of-Experts (MMoE) [14] áp dụng một tập hợp các mô-đun con chuyên gia và mạng cổng để mô hình hóa mối quan hệ tác vụ trong khi tiêu thụ ít tính toán hơn. Progressive Layered Extraction (PLE) [22], tách các tham số chung-tác vụ và cụ thể-tác vụ một cách rõ ràng có thể tiếp tục tránh xung đột tham số do tương quan tác vụ phức tạp gây ra. Những phương pháp này gán các tham số riêng lẻ cho mỗi tác vụ để khai thác thông tin tác vụ tốt hơn và cải thiện khả năng tổng quát mô hình. Tuy nhiên, tính biểu cảm đặc trưng đối với mỗi tác vụ vẫn bị hạn chế vì việc truyền thông tin không liên quan đến tác vụ từ cấu trúc được chia sẻ và việc học biểu diễn mịn hơn là cần thiết.

Trong bài báo này, chúng tôi đầu tiên cung cấp một định nghĩa chính thức về MTL trên vấn đề phụ thuộc tuần tự, và đề xuất một mô hình đối tượng tối ưu hóa để khôi phục mối quan hệ phụ thuộc dựa trên chứng minh lý thuyết. Và chúng tôi cũng trình bày một khung MTL mới được gọi là khung Trích xuất Mẫu Thích ứng Đa nhiệm (APEM) để có chọn lọc và động học biểu diễn cho các tác vụ tương ứng cùng với đối tượng dựa trên phụ thuộc. APEM bao gồm hai mô-đun chính: Bộ sinh Biểu diễn Thích ứng theo Mẫu (ASRG) và Bộ chọn Mẫu rõ ràng (PS). ASRG sử dụng cơ chế lựa chọn động để học tương tác đặc trưng phân cấp từ góc nhìn theo mẫu để tiếp tục tách thông tin không liên quan đến tác vụ. Việc triển khai PS rõ ràng cho phép học đặc trưng mịn bằng cách giới thiệu các vectơ chỉ thị cụ thể cho tác vụ. Tóm lại, những đóng góp chính của bài báo này được trình bày như sau:

•Vấn đề SDMTL được công thức hóa chính thức lần đầu tiên, và các kết nối và sự khác biệt của nó với vấn đề MTL tổng quát được minh họa. Hơn nữa, mối quan hệ phụ thuộc phân phối giữa các không gian tác vụ liền kề được tiết lộ từ một góc nhìn lý thuyết.

•Chúng tôi trình bày một khung học tập đa nhiệm có tên APEM để học biểu diễn đặc trưng mịn có chọn lọc từ góc nhìn theo mẫu. Các mô-đun ASRG và PS trong APEM tái tạo thích ứng các biểu diễn chia sẻ ngầm định và trích xuất thông tin cụ thể cho tác vụ rõ ràng theo cách hiệu quả hơn.

•Các thí nghiệm mở rộng trên bộ dữ liệu công nghiệp công cộng và thực tế được thực hiện để đánh giá hiệu quả của APEM. Kết quả thí nghiệm cho thấy phương pháp được đề xuất của chúng tôi vượt trội so với các phương pháp MTL tiên tiến nhất. Hơn nữa, chúng tôi khám phá ranh giới của APEM trong các ứng dụng công nghiệp thực tế để chứng minh hiệu quả của nó cho đề xuất trực tuyến quy mô lớn.

2 Sơ bộ
Trong phần này, vấn đề SDMTL và kết nối giữa SDMTL và MTL tổng quát được trình bày chi tiết. Sau đó, từ quan điểm mất mát kỳ vọng, mối quan hệ phân phối giữa các miền tác vụ liền kề được tiết lộ.

2.1 Công thức hóa Vấn đề
Xem xét một vấn đề SDMTL trên một không gian đầu vào X và một tập hợp tác vụ {T_i}_{i=1}^N, trong đó N là số lượng tác vụ và các không gian tác vụ tương ứng được ký hiệu là {T_1,...,T_N}. Một bộ dữ liệu lớn các điểm dữ liệu {x_j,o_j^1,...,o_j^N}_{j=1}^M được đưa ra, trong đó M là số lượng điểm dữ liệu và o_j^i ∈ {0,1} tương ứng với một vấn đề phân loại nhị phân hoặc o_j^i ∈ R cho một vấn đề hồi quy là nhãn của tác vụ thứ i cho điểm dữ liệu thứ j.

Khác với vấn đề MTL tổng quát, đối với vấn đề SDMTL, tồn tại mối quan hệ phụ thuộc tuần tự giữa các tác vụ theo nghĩa là tác vụ hiện tại T_i phụ thuộc vào tác vụ trước đó T_{i-1}, tức là T_{i-1}→T_i. Đặt X và T_i là các biến ngẫu nhiên trên không gian đầu vào X và không gian đầu ra tác vụ T_i, tương ứng. Trong bài báo này, để thuận tiện cho việc phân tích, mỗi tác vụ được đặt như một tác vụ phân loại nhị phân. Như đã đề cập trong tài liệu [17] và thể hiện trong Hình 1, đối với phụ thuộc tuần tự, một trong những tính chất cốt lõi là nếu sự kiện T_{i-1} không được kích hoạt, thì sự kiện T_i chắc chắn không xảy ra, tức là P(T_i=1,T_{i-1}=0|X)=0, trong đó P(·|·) biểu thị xác suất có điều kiện. Do đó, theo tính chất này, các biến ngẫu nhiên T_i thỏa mãn

P(T_i=1|X)=∑_{t_{i-1},...,t_1∈{0,1}} P(T_i=1,...,T_1=t_1|X)
=P(T_i=1,T_{i-1}=1,...,T_1=1|X)
=P(T_i=1,T_{i-1}=1|X),

P(T_i=0|X)=∑_{t_{i-1},...,t_1∈{0,1}} P(T_i=0,...,T_1=t_1|X)
=P(T_i=0,T_{i-1}=0|X)+P(T_i=0,T_{i-1}=1|X), (1)

điều này ngụ ý rằng các mẫu dương của T_i được dẫn xuất từ các mẫu dương của tác vụ T_i trong khi các mẫu âm bao gồm các mẫu âm của các tác vụ T_i và T_{i-1} do phụ thuộc tuần tự.

Ngoài ra, mối quan hệ phụ thuộc tuần tự cũng được thể hiện trong các ràng buộc đối với xác suất chuyển đổi của các tác vụ liền kề. Trong [30], mối quan hệ phụ thuộc tuần tự được công thức hóa như

P(T_1=1|X)≥P(T_2=1,T_1=1|X)
···
≥P(T_{i-1}=1,...,T_1=1|X)
≥P(T_i=1,T_{i-1}=1,...,T_1=1|X). (2)

Sau đó, một bộ hiệu chỉnh kỳ vọng hành vi được giới thiệu vào AITM [30] để đảm bảo mối quan hệ phụ thuộc tuần tự (2). Khi các đầu ra của mô hình vi phạm điều kiện này, hàm mất mát được thiết kế sẽ xuất ra một thành phần phạt dương.

Tuy nhiên, điều kiện (2) không thể phản ánh hoàn toàn mối quan hệ phụ thuộc giữa các tác vụ. Xem xét lại mối quan hệ phụ thuộc giữa P(T_{i-1}=1,...,T_1=1|X) và P(T_i=1,...,T_1=1|X), nó dẫn đến

P(T_{i-1}=1|X)−P(T_i=1|X)
=P(T_{i-1}=1|X)−P(T_i=1,T_{i-1}=1|X)
=P(T_{i-1}=1|X)[1−P(T_i=1|T_{i-1}=1,X)]
=P(T_{i-1}=1|X)P(T_i=0|T_{i-1}=1,X)
=P(T_i=0,T_{i-1}=1|X). (3)

Do đó, mối quan hệ phụ thuộc giữa các tác vụ liền kề cần thỏa mãn các ràng buộc đẳng thức (3), cũng chứa thông tin phụ thuộc P(T_i=1,T_{i-1}=0|X)=0.

Định nghĩa một lớp giả thuyết có tham số cho mỗi tác vụ là f_i(x;θ_s,θ_i): X→T_i, trong đó θ_s và θ_i là các tham số được chia sẻ và tham số cụ thể cho tác vụ của tác vụ i. Ngoài ra, hàm mất mát cụ thể cho tác vụ được định nghĩa là L_i(·,·):T_i×T_i→R^+. Tương tự như vấn đề MTL tổng quát, mục tiêu của SDMTL là tối thiểu hóa mất mát kỳ vọng sau:

min_{θ_s,θ_1,...,θ_N} ∑_{i=1}^N E_{X,T_1,...,T_N∼O}[w_i L_i(f_i(X;θ_s,θ_i),T_i)]

s.t. f_i(X;θ_s,θ_i)−f_{i-1}(X;θ_s,θ_i)=P(T_i=0,T_{i-1}=1|X), i=2,...,N, (4)

trong đó O là phân phối với miền X×T_1×···×T_N, và w_i là trọng số tĩnh hoặc được tính toán động cho mỗi tác vụ. Do đó, vấn đề SDMTL có thể được coi là một MTL tổng quát với các ràng buộc f_{i-1}(x_j;θ_s,θ_{i-1})−f_i(x_j;θ_s,θ_i)=P(T_i=0,T_{i-1}=1|X), điều này ngụ ý rằng sự khác biệt của f_{i-1}(x_j;θ_s,θ_{i-1}) và f_i(x_j;θ_s,θ_i) là xác suất của sự kiện T_i không xảy ra khi sự kiện T_{i-1} được kích hoạt. Xem xét các tác vụ phân loại nhị phân và các nhãn o_j^i và o_j^{i-1} của các tác vụ liền kề, chúng ta có thể thu được nhãn tương ứng với xác suất P(T_i=0,T_{i-1}=1|X) như

Bảng 1. Nhãn tương ứng với các tác vụ T_{i-1}, T_i, và mối quan hệ phụ thuộc.

o_j^i | o_j^{i-1} | o_j^i−o_j^{i-1} | P(T_i=0,T_{i-1}=1|X)
------|-----------|------------------|------------------------
0     | 0         | 0                | 0
1     | 0         | 1                | 1
1     | 1         | 0                | 0

Do đó, theo Bảng 1, nhãn của phụ thuộc tuần tự giữa các tác vụ liền kề tương đương với sự khác biệt giữa o_j^i và o_j^{i-1}, tức là o_j^i−o_j^{i-1}.

Vì tồn tại mối quan hệ phụ thuộc giữa tác vụ trước đó và hiện tại, tức là T_1→T_2→T_N, không gian mẫu của tác vụ hiện tại phụ thuộc vào của tác vụ trước đó. Nói chung, không gian mẫu của tác vụ trước đó chứa không gian mẫu của tác vụ hiện tại như thể hiện trong Hình 2, dẫn đến sự khác biệt phân phối dữ liệu giữa hai không gian mẫu này. Xem xét các tác vụ ước lượng CTR, CVR và CTCVR tổng quát, tức là hiển thị →nhấp chuột→···→ chuyển đổi. Chúng ta sử dụng các biến ngẫu nhiên Y∈{0,1} và Z∈{0,1} để biểu thị sự kiện nhấp chuột và sự kiện chuyển đổi, tương ứng. Sau đó, CTR, CVR và CTCVR với đầu vào đặc trưng X được định nghĩa là P(Y|X), P(Z|Y=1,X) và P(Z,Y=1|X), thỏa mãn

P(Z=1,Y=1|X)=P(Y=1|X)P(Z=1|Y=1,X). (5)

Trong trường hợp này, không gian đào tạo của tác vụ ước lượng CVR truyền thống thường được xác định bởi các mẫu với Y=1 trong tác vụ ước lượng CTR. Tuy nhiên, đối với một người dùng mới, không có bản ghi hiển thị và nhấp chuột. Tác vụ ước lượng tỷ lệ chuyển đổi thực tế là ước lượng P(Z=1|X). Xem xét P(Z=1,Y=0|X)=0 [17] và theo (1), chúng ta có thể thu được

P(Z=1|X)=P(Z=1,Y=1|X),
P(Z=0|X)=P(Z=0,Y=0|X)+P(Z=0,Y=1|X). (6)

Hình 2. Sự khác biệt phân phối của các không gian tác vụ khác nhau trong SDMTL. Mặt cong biểu thị phân phối O với miền X×T_1×···×T_N. Các vòng tròn màu từ ngoài vào trong biểu thị các miền của các tác vụ T_1, T_2, T_3, và T_4, tương ứng.

Theo (6), nếu dữ liệu âm của sự kiện Z chỉ được dẫn xuất từ không gian với Y=1 được sử dụng để dự đoán P(Z=1|X), thì sự khác biệt phân phối dữ liệu giữa không gian đào tạo và không gian suy luận dẫn đến dự đoán không chính xác.

2.2 Mối quan hệ Phụ thuộc Phân phối Giữa Không gian Suy luận và Không gian Địa phương

Trong tiểu mục này, mối quan hệ của các mất mát kỳ vọng giữa các miền của các tác vụ liền kề T_{i-1} và T_i được thiết lập. Trong các tác vụ T_{i-1} và T_i, không gian mẫu với các điểm dữ liệu {x_j∈X, o_j^{i-1}∈{0,1}, o_j^i∈{0,1}} được gọi là không gian suy luận, tức là không gian toàn bộ cho T_{i-1} và T_i, và không gian mẫu với các điểm dữ liệu {x_j∈X, o_j^{i-1}∈{1}, o_j^i∈{0,1}} được gọi là không gian địa phương, còn được gọi là không gian đào tạo trong một số phương pháp ước lượng CVR truyền thống [15]. Các phân phối của không gian suy luận và địa phương được ký hiệu là D và C, tương ứng.

Do đó, mục tiêu của hai tác vụ T_{i-1} và T_i với phụ thuộc tuần tự trong không gian suy luận là tối thiểu hóa mất mát kỳ vọng sau:

E_{X,T_{i-1},T_i∼D}[L(f_{i-1}(X),T_{i-1})+L(f_i(X),T_i)]
=E_{X,T_{i-1}∼D}[L(f_{i-1}(X),T_{i-1})]+E_{X,T_i∼D}[L(f_i(X),T_i)]
=∫_D L(f_{i-1}(x),t_{i-1})P_D(x,t_{i-1})dxdt_{i-1}
+∫_D L(f_i(x),t_i)P_D(x,t_i)dxdt_i, (7)

trong đó P_D(·,·) là phân phối kết hợp trong không gian suy luận. Mặt khác, nếu mô hình được đào tạo trong không gian địa phương C, thì tác vụ T_i xác định phân phối mẫu của tác vụ T_{i-1}. Với thao tác này, mất mát kỳ vọng trở thành dạng sau:

E_{X,T_{i-1}∼D}[L(f_{i-1}(X),T_{i-1})]+E_{X,T_i∼C}[L(f_i(X),T_i)]
=∫_D L(f_{i-1}(x),t_{i-1})P_D(x,t_{i-1})dxdt_{i-1}
+∫_C L(f_i(x),t_i)P_C(x,t_i)dxdt_i, (8)

trong đó P_C(·,·) là phân phối kết hợp trong không gian địa phương. Tiếp theo, mối quan hệ giữa các mất mát kỳ vọng trong (7) và (8) được tiết lộ.

Định lý 2.1. Nếu các mất mát kỳ vọng trong không gian suy luận và địa phương được định nghĩa như trong (7) và (8), thì, đối với bất kỳ hàm mất mát L(·,·) nào, chúng thỏa mãn

E_{X,T_{i-1},T_i∼D}[L(f_{i-1}(X),T_{i-1})+L(f_i(X),T_i)]
=E_{X,T_{i-1}∼D}[L(f_{i-1}(X),T_{i-1})]
+E_{X,T_i∼C}[P_D(T_{i-1}=1)P_D(T_i|X)/P_D(T_i,T_{i-1}=1|X) L(f_i(X),T_i)]. (9)

Rõ ràng, sự dịch chuyển phân phối cũng tồn tại trong các ước lượng CTR, CVR và CTCVR khi chúng được đào tạo trong các không gian khác nhau.

3 Khung Trích xuất Mẫu Thích ứng Đa nhiệm

Toàn bộ kiến trúc của APEM được đề xuất cho học tập đa nhiệm phụ thuộc tuần tự được minh họa trong Hình 3. APEM bao gồm hai mô-đun học biểu diễn ASRG và PS để trích xuất động thông tin đặc trưng ngầm định và rõ ràng từ góc nhìn theo mẫu, và một mất mát học tác vụ phụ thuộc tuần tự để tái tạo mối quan hệ tác vụ không thiên vị trên không gian đào tạo toàn cục. Bộ sinh Biểu diễn Thích ứng theo Mẫu (ASRG) chịu trách nhiệm về học biểu diễn chia sẻ phân cấp, áp dụng các điểm cảm ứng để tương tác với trường đặc trưng khác nhau tương ứng với mỗi đầu vào. Mô-đun Bộ điều hợp Cụ thể cho Tác vụ (PS) hợp tác với ASRG nhưng hoạt động như một trích xuất thông tin nhận biết tác vụ thông qua chỉ thị tác vụ được thiết kế và có cấu trúc truyền thông điệp độc lập để giải quyết tốt hơn xung đột tác vụ. Bên cạnh hai mô-đun đó, một mất mát học phụ thuộc tuần tự giữa các tác vụ được đề xuất và chứng minh lý thuyết, có thể mô tả xác suất phụ thuộc có điều kiện cho học tập đa nhiệm dựa trên tuần tự từ toàn bộ không gian đào tạo và do đó cải thiện kết quả dự đoán bằng cách nắm bắt chính xác mối quan hệ tác vụ. Chúng tôi sẽ trình bày chi tiết ASRG và PS trong các mục 3.1 và 3.2, và cuối cùng thảo luận về mối quan hệ giữa các tác vụ phụ thuộc tuần tự trong mục 3.3.

Hình 3. Một minh họa về kiến trúc tổng thể của APEM.

3.1 Bộ sinh Biểu diễn Thích ứng theo Mẫu

Trích xuất thông tin đặc trưng mịn tương ứng với các tác vụ khác nhau là rất quan trọng trong học tập đa nhiệm và ảnh hưởng đáng kể đến hiệu suất mô hình. Nhưng khả năng tổng quát đặc trưng cũng cần được bao gồm để cân bằng sự đánh đổi giữa các tác vụ về mặt thông tin chia sẻ. Dựa trên những cân nhắc này, chúng tôi đề xuất một mô-đun học biểu diễn mới, có tên là Bộ sinh Biểu diễn Thích ứng theo Mẫu (ASRG). Bên cạnh học thông tin chia sẻ tổng quát, chúng tôi thiết kế một bộ chọn động để học tương tác đặc trưng từ góc nhìn theo mẫu để tiếp tục tách thông tin không liên quan đến tác vụ. Cấu trúc của ASRG được hiển thị trong Hình 4, chủ yếu bao gồm một lớp kích hoạt động và một lớp học tương tác đặc trưng.

Lớp Kích hoạt Động. Trong tình huống đề xuất, trường đầu vào thường chứa các loại đặc trưng người dùng và mục. Cho một đầu vào x từ F trường đặc trưng khác nhau, chúng ta ký hiệu x là sự nối của tất cả các trường đặc trưng:

x=[x_1,x_2,...,x_F], (10)

trong đó x_i biểu thị giá trị của đặc trưng thứ i. Như một tiền xử lý dữ liệu thông thường cho tình huống đề xuất trực tuyến với khả năng tổng quát tốt hơn, chúng tôi rời rạc hóa các đặc trưng số x_i thông qua phép toán Log-round để có được một giá trị duy nhất và khởi tạo ngẫu nhiên với một vectơ có d_f chiều. Do đó, chúng ta có được embedding đầu vào cho mỗi trường đặc trưng là H=[h_1,h_2,...,h_F]^T, trong đó H∈R^{F×d_f}.

Một Lớp biến đổi đầu tiên được áp dụng để chiếu các embedding đầu vào thành một vectơ K chiều. Lớp biến đổi có thể là bất kỳ loại cấu trúc mạng nơ-ron sâu nào và ở đây chúng tôi chọn một lớp MLP tiêu chuẩn chỉ để đơn giản. Đầu ra z_K được định nghĩa là một bộ chọn động:

z_K=MLP(H) (11)

trong đó z_K∈R^K. Sau đó, chúng tôi triển khai một hàm kích hoạt động f_D lấy cảm hứng từ [9] để có được biểu diễn thưa thớt hơn của z_K, có công thức như sau:

z_K=f_D(z_K) (12)

trong đó f_D được công thức hóa là:

f_D(z)={
0, z ≤ -γ/2
-2/γ³z³+3/2γz+1/2, -γ/2 < z < γ/2
1, z ≥ γ/2
} (13)

trong đó γ=Max{10^{-2}e^{-4·step}, 1e^{-3}} và step tối đa trong quá trình đào tạo là khoảng 1e6. Bộ chọn động z_K hoạt động như một bộ lọc thông tin chọn lọc tương tác với đầu vào từ góc nhìn theo mẫu do Lớp Biến đổi. Như được trực quan hóa trong Hình 5, hình dạng đầu ra của f_D trở nên dốc hơn với sự tăng của bước đào tạo. Bằng cách sử dụng f_D, z_K tạo ra một vectơ thưa K chiều chỉ chứa các giá trị 0 và 1 tương ứng với mỗi mẫu đầu vào.

Hình 4. Cấu trúc chi tiết của Bộ sinh Biểu diễn Thích ứng theo Mẫu

Hình 5. Đầu ra của hàm kích hoạt động f_D với sự tăng của bước đào tạo.

Lớp Học Tương tác Đặc trưng. Cơ chế chú ý để học tương tác đặc trưng phân cấp thường được áp dụng nhưng yêu cầu độ phức tạp thời gian bậc hai trong cấu trúc tự chú ý tiêu chuẩn. Ở đây chúng tôi thiết kế một ma trận có thể học được gọi là điểm cảm ứng I, được truyền cảm hứng từ Set Transformer [12] để giảm độ phức tạp tính toán từ bậc hai xuống tuyến tính. Chúng tôi định nghĩa các điểm cảm ứng I∈R^{K×d_f}, trong đó K giống như trong bộ chọn động z_K. Sau một phép toán theo phần tử, chúng ta có được một truy vấn được sửa đổi Q̂ như:

Q̂=I⊙z_K (14)

Sau đó, chúng tôi tính toán đầu ra O_j từ phép toán chú ý theo công thức sau:

O_j=Attention(Q̂_j,K_j,V_j;λ) (15)

trong đó Q̂_j=I_j⊙z_K, K_j=HW_j^K, V_j=HW_j^V với tham số có thể đào tạo λ={I_j,W_j^K,W_j^V}_{j=1}^m và m biểu thị số lượng đầu đa. Sau đó chúng ta có được đầu ra O từ chú ý đa đầu với tham số W^O như:

O=concat(O_1,...,O_h)W^O (16)

Cuối cùng, biểu diễn thích ứng Y_ASRG học từ ASRG có thể được công thức hóa theo cách của mạng dư như:

Y_ASRG=LayerNorm(O,H) (17)

Độ phức tạp thời gian của lớp học tương tác đặc trưng giảm từ O(F²) xuống O(K×F) bằng cách giới thiệu I. Như được đề xuất trong [18], K, chiều giảm của I có thể được xem như K ô nhớ độc lập tương tác với mỗi trường đặc trưng, được tự động chọn thêm bởi z_k để phân biệt thông tin đặc trưng một cách rõ ràng từ góc nhìn theo mẫu. So với cấu trúc học biểu diễn chia sẻ truyền thống trong hầu hết các phương pháp MTL, ASRG học thông tin khác biệt hơn về mặt lớp kích hoạt động và lớp học tương tác đặc trưng, chủ yếu được quy cho cái trước kết hợp lớp biến đổi và hàm kích hoạt động để tạo ra mặt nạ thích ứng tương ứng với mỗi mẫu đầu vào.

3.2 Bộ chọn Mẫu Rõ ràng

Bên cạnh biểu diễn chia sẻ hiệu quả được tạo ra bởi ASRG, việc học đặc trưng cụ thể theo từng tác vụ sẽ ảnh hưởng mạnh mẽ đến hiệu suất mô hình vì nó trực tiếp tăng cường thông tin liên quan đến tác vụ. Trong hầu hết các công trình MTL, các trích xuất đặc trưng nhắm mục tiêu tác vụ, như các chuyên gia cụ thể cho tác vụ được đề xuất bởi PLE được cố ý thiết kế để học biểu diễn cho từng tác vụ. Tuy nhiên, sự can thiệp lẫn nhau giữa các tác vụ khác nhau vẫn tồn tại vì các thành phần chia sẻ và cụ thể cho tác vụ không được tách biệt hoàn toàn trong những trường hợp này.

Để học thông tin nhận biết tác vụ giữa các tác vụ khác nhau với cấu trúc độc lập và tách biệt triệt để hơn, chúng tôi giới thiệu một mô-đun có tên là Bộ điều hợp Cụ thể cho Tác vụ rõ ràng (PS) như được vẽ chi tiết trong Hình 6. PS sử dụng vectơ chỉ thị tác vụ có tham số để tương tác với thông tin chia sẻ chung theo mẫu trước đó từ ASRG, có thể trích xuất biểu diễn cụ thể cho tác vụ bằng cách tối ưu hóa trực tiếp đối tượng tác vụ tương ứng. Phương pháp này tương tự được áp dụng trong PAL [21] và K-adapter [27].

Hình 6. Cấu trúc chi tiết của Bộ chọn Mẫu.

Như được minh họa trong Hình 6, chúng tôi lấy đầu ra Y_ASRG∈R^{K×d_f} từ Bộ sinh Biểu diễn Thích ứng theo Mẫu để tương tác với một vectơ chỉ thị tác vụ có thể học α_i tương ứng với mỗi tác vụ i. F_i là đầu ra được tính toán thông qua một phép toán chú ý giữa Y_ASRG và α_i như:

F_i=Attention(α_i,Y_ASRG,Y_ASRG), (18)

trong đó α_i∈R^{1×d_f} là vectơ chỉ thị tác vụ và F_i∈R^{1×d_f} biểu thị đầu ra trung gian của biểu diễn nhận biết tác vụ cho mỗi tác vụ i tương ứng. Ở đây, Attention là cùng một phép toán tính toán chú ý như trong công thức (15). Do đó, đối với mỗi tác vụ i, chúng tôi tham chiếu thông tin cụ thể cho tác vụ được tạo ra từ lớp PS thứ k như T_i^k và chúng tôi tính toán nó cũng thông qua một mạng dư và chuẩn hóa lớp cho hiệu quả đào tạo như trong (17):

T_i^k=LayerNorm(T_i^{k-1}+F_i^k), (19)

trong đó T_i^{k-1}∈R^{1×d_f} có nghĩa là đầu ra từ lớp PS trước đó cho tác vụ i, và F_i^k∈R^{1×d_f} là embedding nhận biết tác vụ được học bởi sự tương tác giữa chỉ thị tác vụ cho lớp thứ k với tác vụ i và embedding chia sẻ chung. Lưu ý, T_i^0 được bỏ qua ở lần lặp đầu tiên.

Có thể quan sát trong Hình 6, embedding nhận biết tác vụ T thu được từ Bộ điều hợp Cụ thể cho Tác vụ được đào tạo độc lập và thông điệp của nó không truyền vào mô-đun ASRG giữa các lớp khác nhau. Cấu trúc được đề xuất giữ các mô-đun học biểu diễn ngầm định (từ ASRG) và rõ ràng (từ PS) tách biệt hơn, không chỉ cô lập sự can thiệp tiêu cực giữa các tác vụ một cách triệt để hơn mà còn cung cấp một khung học tập đa nhiệm có thể mở rộng đặc biệt cần thiết trong triển khai công nghiệp.

3.3 Thiết kế Hàm Mất mát Hướng đến Học tập Đa Nhiệm Phụ thuộc Tuần tự

Đối với học tập đa nhiệm không có phụ thuộc tuần tự, hàm mất mát thường được thiết kế như dạng sau:

L(θ_s,θ_1,...,θ_N)=∑_{i=1}^N ∑_{j=1}^M w_i/M L(f_i(x_j;θ_s,θ_i),o_j^i). (20)

Từ hàm mất mát (20), có thể quan sát rằng hàm mất mát này không thể học mối quan hệ phụ thuộc tuần tự. Như đã đề cập trong tiểu mục 2.1, trong bài báo này, vấn đề tối ưu hóa có ràng buộc có thể được biến đổi thành trường hợp không có ràng buộc bằng cách sử dụng hàm phạt. Do đó, hàm mất mát tương ứng cho SDMTL được thiết kế như

L(θ_s,θ_1,...,θ_N)
=L_{M-Task}+L_{D-Task}
=∑_{i=1}^N w_i/M ∑_{j=1}^M L(f_i(x_j;θ_s,θ_i),o_j^i)
+∑_{i=2}^N σ_{i-1}/M ∑_{j=1}^M L(f_{i-1}(x_j;θ_s,θ_{i-1})-f_i(x_j;θ_s,θ_i),o_j^{i-1}-o_j^i), (21)

trong đó σ_i là các hệ số phạt, L_{M-Task} và L_{D-Task} là các hàm mất mát của các tác vụ chính, tức là T_i, và các hàm mất mát của mối quan hệ phụ thuộc tuần tự, tương ứng. Với thao tác này, mỗi tác vụ và mối quan hệ phụ thuộc tương ứng của chúng có thể được đào tạo riêng biệt. Các hàm mất mát của mối quan hệ phụ thuộc L_{D-Task} có thể được coi như một thành phần chính quy hóa. Lưu ý rằng việc lựa chọn mẫu âm quyết định không gian đào tạo. Do đó, các mẫu dương của tác vụ T_i được dẫn xuất từ tác vụ hiện tại trong khi các mẫu âm của T_i được dẫn xuất từ các tác vụ khác nhau T_i và T_{i-1}. Tương tự như tiểu mục 3.2, các mất mát kỳ vọng của mối quan hệ phụ thuộc được dẫn xuất từ toàn bộ không gian D và không gian địa phương C được thảo luận như sau.

Định lý 3.1. Nếu mối quan hệ phụ thuộc được học trong toàn bộ không gian D và không gian địa phương C, tương ứng, và các mất mát kỳ vọng tương ứng được ký hiệu là E_{X,T_{i-1},T_i∼D}[L(f_{i-1}(X)-f_i(X),T_{i-1}-T_i)] và E_{X,T_{i-1},T_i∼C}[L(f_{i-1}(X)-f_i(X),T_{i-1}-T_i)], thì hai mất mát kỳ vọng này thỏa mãn

E_{X,T_{i-1},T_i∼D}[L(f_{i-1}(X)-f_i(X),T_{i-1}-T_i)]
=E_{X,T_{i-1},T_i∼C}[P_D(T_{i-1}=1)P_D(T_{i-1}-T_i|X)/P_D(T_{i-1}-T_i,T_{i-1}=1|X)
×L(f_{i-1}(X)-f_i(X),T_{i-1}-T_i)] (22)

4 Thí nghiệm
Trong phần này, chúng tôi mô tả các thí nghiệm để đánh giá hiệu suất của khung APEM được đề xuất, được thực hiện trên cả bộ dữ liệu chuẩn công cộng và bộ dữ liệu công nghiệp thực tế trong dịch vụ tài chính. Chúng tôi cũng phân tích đóng góp của từng mô-đun cấu thành APEM để hiểu rõ hơn về cơ chế hoạt động và chứng minh hiệu quả của phương pháp được đề xuất cho học tập đa nhiệm phụ thuộc tuần tự.

4.1 Thiết lập Thí nghiệm

4.1.1 Bộ dữ liệu. Các thí nghiệm được thực hiện trên hai bộ dữ liệu: chuẩn công cộng Ali-CCP và một bộ dữ liệu công nghiệp từ tình huống tài chính.

•Bộ dữ liệu Ali-CCP: Bộ dữ liệu công cộng Ali-CPP được sử dụng làm chuẩn cho so sánh mô hình với các tác vụ Dự đoán Nhấp chuột và Chuyển đổi của Alibaba. Chúng tôi sử dụng tất cả các đặc trưng phân loại đơn giá trị như thường được áp dụng và ngẫu nhiên lấy 10% của bộ dữ liệu train làm bộ dữ liệu validation cho tất cả các mô hình.

•Bộ dữ liệu Công nghiệp: Bộ dữ liệu công nghiệp được thu thập từ nền tảng đề xuất trực tuyến của chúng tôi trong dịch vụ tài chính, mô tả hành vi nhấp chuột và chuyển đổi của người dùng đáp ứng với quảng cáo tài chính. Bộ dữ liệu được chia cho đào tạo, xác thực và kiểm tra theo thời gian và chúng tôi giảm mẫu các mẫu âm trong tập đào tạo để giữ tỷ lệ của mỗi tập là 8:1:1.

4.1.2 Phương pháp Cơ sở. Để xác thực hiệu quả của APEM, chúng tôi thực hiện thí nghiệm trên các phương pháp đại diện sau để so sánh, là các phương pháp học tập đa nhiệm SOTA hoặc phương pháp học phụ thuộc tuần tự gần đây:

•Single-Task là một mạng MLP ba lớp với kích thước lớp ẩn [256,128,64] cho tối ưu hóa một tác vụ.

•Shared-Bottom xây dựng một lớp dưới chia sẻ để học biểu diễn chung trên tất cả các tác vụ và giới thiệu tháp tác vụ tách biệt cho tối ưu hóa đối tượng tương ứng.

•MMOE được truyền cảm hứng từ phương pháp MoE cổ điển áp dụng một nhóm các mạng con dưới chia sẻ như chuyên gia và giới thiệu mạng cổng gán các tác vụ khác nhau với trọng số khác biệt.

•PLE tổng quát hóa phương pháp CGC và sử dụng cơ chế định tuyến lũy tiến để trích xuất và tách kiến thức ngữ nghĩa sâu hơn.

•AITM là một cấu trúc dưới chia sẻ với truyền thông tin thích ứng để mô hình hóa phụ thuộc tuần tự giữa các chuyển đổi đa bước.

•APEM là phương pháp được đề xuất của chúng tôi áp dụng bộ sinh biểu diễn thích ứng theo mẫu và Bộ chọn Mẫu rõ ràng, với mất mát học phụ thuộc cho học tập đa nhiệm phụ thuộc tuần tự.

4.1.3 Triển khai L_{D-Task}. Như đã thảo luận trong mục 3.3, L_{D-Task} có thể được coi như một chính quy hóa, ràng buộc mối quan hệ giữa các tác vụ phụ thuộc tuần tự trong quá trình đào tạo. Trong bài báo này, chúng tôi xây dựng một MSE (Mean-Squared Loss) như một triển khai cho L trong công thức (21):

L_{MSE}=1/M ∑_{j=1}^M w·(y_j-ŷ_j)² (23)

trong đó y_j là nhãn từ o_j^{i-1}-o_j^i và ŷ_j là đầu ra từ f_{i-1}(x_j;θ_s,θ_{i-1})-f_i(x_j;θ_s,θ_i) cho đầu vào j. Mỗi mẫu được đối xử bình đẳng với w=1.

4.1.4 Thiết lập Đào tạo. Trong các thí nghiệm, mỗi thí nghiệm được lặp lại 5 lần, hiệu suất trung bình và giá trị p đều được báo cáo. Chúng tôi chọn các siêu tham số tối ưu cho mỗi mô hình theo tìm kiếm lưới [13] để so sánh công bằng. Kích thước batch B trên mỗi bộ dữ liệu được đặt là 1024 tương ứng trong quá trình đào tạo. Bộ tối ưu hóa Adam [11] được áp dụng với tỷ lệ học λ là 0.001. Chiều d_f của lớp embedding đầu vào là 18. Số lượng các lớp xếp chồng L, số lượng đầu chú ý M và số lượng điểm cảm ứng K được minh họa trong Bảng 2. Hàm kích hoạt của MLP trong mô hình hóa một tác vụ là ReLU.

Bảng 2. Thiết lập siêu tham số chi tiết cho mỗi bộ dữ liệu.

Bộ dữ liệu | Thiết lập Siêu tham số
---------|----------------------
Ali-CCP | B=1024, d_f=18, M=2, K=64, L=4, λ=10^{-3}
Bộ dữ liệu công nghiệp | B=1024, d_f=18, M=2, K=64, L=4, λ=10^{-3}

4.2 So sánh Hiệu suất

Kết quả thí nghiệm cho tất cả các phương pháp so sánh với chỉ số đánh giá AUC cho mỗi tác vụ được trình bày trong Bảng 4. Hiệu suất tốt nhất trên các bộ dữ liệu khác nhau được đánh dấu in đậm và gạch chân cho các phương pháp SOTA tốt nhất. Như có thể quan sát, APEM vượt trội so với hầu hết các mô hình cơ sở cho mỗi tác vụ trên cả hai bộ dữ liệu tương ứng.

Hiệu suất trung bình trên bộ dữ liệu Ali-CCP kém trên cả mục tiêu CTR và CVR trên tất cả các phương pháp so sánh, có thể ngụ ý rằng các đặc trưng đầu vào không đủ chất lượng để biểu đạt các mục tiêu hoặc thông tin không liên quan ảnh hưởng đáng kể. Đối với trường hợp sau, trích xuất đặc trưng cụ thể cho tác vụ sẽ đóng vai trò quan trọng đối với kết quả dự đoán về mặt lọc can thiệp tiêu cực. Như quan sát, APEM đạt được 0.6203 và 0.6456 AUC cho các tác vụ CTR và CVR tương ứng, với mức tăng 1.16% và 7.31% so với phương pháp Single-Task. Những cải thiện của CTR có ý nghĩa với so sánh với các phương pháp khác nhưng hơi kém hơn PLE trong mục tiêu CVR. Kết quả dường như được quy cho sự đánh đổi giữa các tác vụ được xem xét bởi APEM và APEM. Sự khác biệt cải thiện giữa CTR và CVR nhỏ hơn trong APEM và gợi ý một tối ưu hóa cân bằng hơn giữa các tác vụ. Hiệu suất trên Bộ dữ liệu Công nghiệp của APEM có được mức tăng đáng kể 1.29% và 1.43% cho cả hai mục tiêu và vượt trội đáng kể so với các phương pháp khác. So với PLE, đạt được kết quả tốt thứ hai, mô hình được đề xuất vẫn có được sự gia tăng của mức tăng 43% và 55% và tiếp tục chứng minh hiệu quả của nó.

4.3 Nghiên cứu Loại bỏ

Chúng tôi thực hiện nghiên cứu loại bỏ trên các mô-đun con khác nhau trong APEM để cung cấp phân tích chi tiết về chức năng và hiệu quả của nó. Các mô hình biến thể của APEM bao gồm các cấu trúc sau và ký hiệu chỉ để đơn giản:

•APEM without ASRG: loại bỏ lớp kích hoạt động trong ASRG và thay thế bằng phép toán tự chú ý tiêu chuẩn.

•APEM without PS: loại bỏ chỉ thị tác vụ trong các lớp PS cho tất cả các tác vụ tương ứng.

•APEM without L_{D-Task}: loại bỏ mất mát học phụ thuộc tuần tự L_{D-Task} như được ký hiệu trong (21).

•APEM: cấu trúc hoàn chỉnh của APEM.

Kết quả của nghiên cứu loại bỏ được trình bày trong Bảng ?? với chỉ số đánh giá AUC trên cả hai bộ dữ liệu cho các tác vụ CTR và CVR. Như quan sát, cấu trúc hoàn chỉnh của APEM vượt trội so với tất cả các biến thể APEM khác và chúng ta có thể rút ra các kết luận sau cho mỗi mô-đun con:

(1). Bộ sinh Biểu diễn Thích ứng theo Mẫu đóng góp vào việc học biểu diễn chia sẻ mịn và tổng quát cho cả hai tác vụ. Trong đó, bộ chọn động cho phép chọn thông tin cần thiết cho mỗi mẫu để tăng cường việc học kiến thức. Không có lớp chọn lọc động, hiệu suất mô hình giảm nhiều nhất cho cả mục tiêu CTR và CVR là -0.5% và -0.57% trong bộ dữ liệu Công nghiệp. Học tương tác đầy đủ qua tự chú ý đa đầu tiêu chuẩn không thể cung cấp đủ thông tin chia sẻ. Chúng tôi tin rằng ASRG tái tạo thông tin cần thiết theo cách thích ứng không chỉ học tương tác trường đặc trưng mà còn lọc tiếng ồn bằng cách sử dụng chú ý cấp nhóm từ góc nhìn theo mẫu. Đóng góp trong Ali-CPP vẫn rõ ràng vì các đặc trưng của nó dường như ít biểu cảm hơn như đã thảo luận trong mục 4.2 và được hưởng lợi rất nhiều từ ASRG.

(2). Bộ chọn Mẫu Rõ ràng hoạt động như một trích xuất đặc trưng nhạy cảm với tác vụ, khá quan trọng trong học tập đa nhiệm để trích xuất chính xác thông tin liên quan đến tác vụ cho mỗi tác vụ. Có thể quan sát rõ ràng rằng không có cơ chế chú ý tác vụ (chỉ thị tác vụ được đề xuất), hiệu suất mô hình giảm đáng kể và hơi tốt hơn so với không có ASRG trong bộ dữ liệu Công nghiệp nhưng tệ hơn trong Ali-CPP. Điều này gợi ý rằng một cấu trúc tháp cụ thể cho tác vụ vanilla không tạo ra đủ thông tin trong quá trình tối ưu hóa tác vụ.

(3). Mất mát học phụ thuộc tuần tự được đề xuất L_{D-Task} dựa trên chứng minh lý thuyết đóng góp vào hiệu suất mô hình về mặt truyền thông tin bổ sung giữa các tác vụ liên quan. Mặc dù nó có vẻ ít đáng kể hơn so với các mô-đun con khác trong bộ dữ liệu Công nghiệp nhưng đóng góp nhiều nhất trong tác vụ CVR ở Ali-CPP. Tác vụ CVR có thể phụ thuộc nhiều vào tác vụ CTR và L_{D-Task} sửa đổi đối tượng thiên vị của định nghĩa ban đầu, tiếp tục tối ưu hóa các tham số bằng cách khôi phục mối quan hệ phụ thuộc xác suất hoàn chỉnh của chúng.

4.4 Phân tích Bộ chọn Động

Bộ chọn động z_K được định nghĩa trong công thức (12) hoạt động như một mặt nạ thưa được tạo ra dựa trên mẫu đầu vào, hợp tác với Điểm cảm ứng I tương tác với các trường đặc trưng một cách có chọn lọc. Chúng tôi thực hiện một số nghiên cứu trường hợp của z_K để cung cấp phân tích trực quan như được trực quan hóa trong Hình 7.

Hình 7. Một minh họa về bộ chọn động z_K.
(a). Phân phối tỷ lệ lựa chọn cho các mẫu khác nhau.
(b). Biểu đồ của các embedding mẫu với tỷ lệ lựa chọn cao, trung bình và thấp được tô màu lần lượt là xanh lá, vàng và xanh dương.

Như đã lưu ý trong mục 3.1, z_K là một vectơ K chiều chỉ với các giá trị 0 và 1, trong đó 1 có nghĩa là tương tác với nhóm trường ngầm định theo I tương ứng và ngược lại. Chúng tôi đầu tiên vẽ biểu đồ phân phối tỷ lệ khác không (tỷ lệ lựa chọn) của z_K trên các mẫu thử nghiệm của bộ dữ liệu công nghiệp trong Hình 7 (a). Có thể quan sát đối với hầu hết các mẫu, tỷ lệ lựa chọn nằm giữa 55% và 60% và chỉ ra rằng hơn một nửa các nhóm tương tác được yêu cầu để trích xuất thông tin. Đối với các trường hợp cụ thể, một số cần ít nhóm tương tác hơn và một số cần nhiều hơn. Chúng ta có thể coi điều này như một biểu diễn đa góc nhìn cho mỗi mẫu, chẳng hạn như số lượng khác nhau của các góc nhìn đủ điều kiện để mô tả sự quan tâm của khách hàng đặc biệt trên tình huống đề xuất trực tuyến. Chúng tôi tiếp tục vẽ ngẫu nhiên các embedding mẫu với tỷ lệ lựa chọn cao (top 1%), trung bình (khoảng 58%) và thấp (bottom 1%) trong Hình 7 (b). Như được minh họa, các mẫu với các mức độ tương tác khác nhau cho thấy sự khác biệt đáng kể trong không gian embedding và có thể ngụ ý ý định khác biệt.

4.5 Đánh giá Hiệu quả

Trong phần này, chúng tôi đánh giá hiệu quả thời gian và lưu trữ của phương pháp được đề xuất. Chúng tôi ghi lại chi phí thời gian trong quá trình đào tạo (mỗi epoch) và quá trình suy luận cho APEM và các mô hình cơ sở khác trong Hình 8 (a), và chi phí bộ nhớ tương ứng trong Hình 8 (b). Như được minh họa trong (a), APEM yêu cầu 1177 giây để đào tạo một epoch trên bộ dữ liệu Ali-CCP với 38 triệu mẫu, ít hiệu quả hơn so với các phương pháp khác (295s cho kết quả tốt nhất từ Shared-Bottom) nhưng tương tự như PLE (1195s). Vì chúng tôi thường đào tạo mô hình theo cách offline đặc biệt cho dữ liệu quy mô lớn, hiệu quả đào tạo tương đối cao hơn là trong phạm vi chấp nhận được. Về thời gian suy luận, yếu tố cần thiết được xem xét trong ứng dụng công nghiệp trực tuyến, APEM mất 47 giây cho lan truyền thuận trên dữ liệu thử nghiệm với 4.2 triệu mẫu. Sự lệch lạc của nó so với các mô hình hiệu suất hàng đầu như AITM và Shared-Bottom là 12 giây và có thể chấp nhận được xem xét hầu hết tình huống suy luận trực tuyến công nghiệp' ngưỡng QPS. Bên cạnh đó, APEM có ít tham số nhất với 89 Mb (178 Mb cho mô hình lớn nhất của Single-Task) như được vẽ trong Hình 8 (b), làm cho nó dễ dàng triển khai và di động. Tóm lại, APEM đạt được một cải thiện đáng kể với thời gian tính toán phù hợp và khả năng lưu trữ có lợi so với các phương pháp MTL được chấp thuận khác.

Hình 8. So sánh hiệu quả giữa các mô hình. (a). Thời gian Đào tạo và Suy luận (b). Chi phí Bộ nhớ

4.6 Hiệu suất A/B Trực tuyến

Chúng tôi triển khai một thử nghiệm A/B trực tuyến giữa APEM và phương pháp học tập đa nhiệm SOTA của MMOE trong một tuần. Hai mô hình được triển khai trên hai tình huống quảng cáo tài chính thực tế với mục tiêu tối đa hóa CVR cho các sản phẩm tài chính như đầu tư và vay tín dụng. So sánh offline được trình bày trong Bảng 5, APEM có được cải thiện 0.16% cho CTR trong Tình huống 2, 0.47% và 0.62% cho CVR trên mỗi tình huống tương ứng. Trong Hình 9, chúng ta có thể quan sát hiệu suất trực tuyến của APEM so với MMOE. Như thể hiện trong biểu đồ, APEM đạt được những cải thiện đáng kể và nhất quán cho cả hai tình huống trong suốt toàn bộ thời kỳ, tăng trung bình 9.22% trong tình huống (a) và 3.76% trong tình huống (b) trên tác vụ CVR. Kết quả thí nghiệm chứng minh hiệu quả và sự ổn định của phương pháp được đề xuất, đủ điều kiện cho ứng dụng công nghiệp quy mô lớn.

Bảng 5. So sánh hiệu suất offline (AUC) cho hai tình huống tài chính thực tế.

Mô hình | Tình huống 1 | Tình huống 2
--------|--------------|-------------
        | CTR | CVR | CTR | CVR
MMOE    | 0.8102 | 0.8034 | 0.8110 | 0.8719
APEM    | 0.8102 | 0.8072 | 0.8123 | 0.8773
Tăng    | - | 0.47% | 0.16% | 0.62%

Hình 9. Kết quả A/B trực tuyến trên hai tình huống thực tế (a) và (b).

5 Công trình Liên quan

Học tập Đa nhiệm. Học tập Đa nhiệm (MTL) được đề xuất để học thông tin chia sẻ giữa các tác vụ để cải thiện khả năng tổng quát và hiệu suất mô hình [2]. Tuy nhiên, tình huống học tập đa nhiệm thường gặp phải sự suy giảm hiệu suất như truyền tiêu cực vì mối quan hệ phức tạp giữa các tác vụ khác nhau [1,23]. Do đó, nhiều công trình học đặc trưng trong thiết kế cấu trúc được đề xuất để trích xuất thông tin cần thiết theo tác vụ cụ thể và cân bằng hiệu suất giữa tất cả các tác vụ. Cross-Stitch Network [16] sử dụng tổ hợp tuyến tính của các biểu diễn chia sẻ để học các embedding cụ thể cho tác vụ cho mỗi tác vụ. Dựa trên ý tưởng của Cross-Stitch, Sluice Network [19] là một siêu kiến trúc tổng quát với nhiều tham số cụ thể cho tác vụ hơn bằng cách chia mỗi lớp thành không gian con cụ thể cho tác vụ và chia sẻ và đạt được hiệu suất tốt hơn đặc biệt cho các tác vụ ít tương quan hơn. Tuy nhiên, những phương pháp này không thể nắm bắt sự phụ thuộc mẫu và yêu cầu nhiều dữ liệu đào tạo hơn và ít hiệu quả hơn cho ứng dụng quy mô lớn. Được truyền cảm hứng từ cấu trúc MoE [10], multi-gate Mixture-of-Experts (MMoE) [14] sử dụng một tập hợp các mô-đun con chuyên gia và mạng cổng để kết hợp biểu diễn của các chuyên gia dưới để học mối quan hệ tác vụ trong khi tiêu thụ ít tính toán hơn. Tương tự, Multiple Relational Attention Network (MRAN) [32] mô hình hóa nhiều mối quan hệ bằng ba cơ chế học dựa trên chú ý. So với MMoE, phương pháp Progressive Layered Extraction (PLE) [22] đề xuất một khung MTL mới tách các tham số chung-tác vụ và cụ thể-tác vụ một cách rõ ràng hơn và áp dụng cơ chế định tuyến tách tiến bộ để làm giảm tốt hơn xung đột tham số do tương quan tác vụ phức tạp gây ra.

Học tập Đa nhiệm Phụ thuộc Tuần tự. Các ứng dụng cổ điển nhất của học tập đa nhiệm phụ thuộc tuần tự (SDMTL) là quá trình chuyển đổi đa bước của thu hút khách hàng trong thương mại điện tử, quảng cáo hiển thị hoặc hệ thống tài chính. Nói chung, quá trình chuyển đổi đa bước bao gồm hiển thị→nhấp chuột→···→ chuyển đổi, tương ứng với một số tác vụ ước lượng như tỷ lệ nhấp chuột sau xem (CTR), tỷ lệ chuyển đổi sau nhấp (CVR) và tỷ lệ nhấp chuột & chuyển đổi sau xem (CTCVR) và tiếp tục. Khác với MTL tổng quát, tồn tại mối quan hệ phụ thuộc giữa các tác vụ liền kề trong vấn đề SDMTL. Đối với vấn đề ước lượng CVR, Entire Space Multi-task Model (ESMM) được đề xuất trong [15] để khắc phục các vấn đề Sample Selection Bias (SSB) và Data Sparsity (DS) bằng cách giới thiệu hai tác vụ phụ của dự đoán CTR và CTCVR. Với thao tác này, hiệu suất của ước lượng CVR sẽ phụ thuộc nhiều vào hiệu suất các tác vụ phụ. Khi số lượng bước tăng trong đường dẫn chuyển đổi đa bước, sự tích lũy của lỗi hiệu suất trở nên không thể chịu đựng. Nhằm mục đích vấn đề DS của ước lượng CVR, trong [29], một biểu đồ hành vi tuần tự người dùng mới được thiết lập để đạt được phân tách hành vi sau nhấp bằng cách chèn hành động xác định liên quan đến mua hàng rời rạc và hành động khác vào giữa nhấp chuột và chuyển đổi. Xem xét hành vi vi mô (tương tác của người dùng với các mục) và hành vi vĩ mô (tương tác của người dùng với các thành phần cụ thể trên trang chi tiết mục), Wen et al. [28] đề xuất một Mô hình Phân cấp cả Hành vi Vi mô và Vĩ mô cho dự đoán CVR để giải quyết các vấn đề SSB và DS bằng cách sử dụng các nhãn giám sát phong phú từ hành vi vi mô và vĩ mô. Để mô hình hóa sự phụ thuộc tuần tự giữa các chuyển đổi đa bước, khung Adaptive Information Transfer Multi-task (AITM) với mô-đun truyền thông tin thích ứng được phát triển trong [30] để dự đoán trực tiếp xác suất chuyển đổi từ đầu đến cuối của mỗi bước. Bên cạnh đó, các phương pháp nhân quả cũng đã được áp dụng để đạt được ước lượng tỷ lệ chuyển đổi sau nhấp không thiên vị gần đây [6,8,26,31]. Tuy nhiên, đối với vấn đề học tập đa nhiệm phụ thuộc tuần tự, có ít tài liệu để phát triển mô tả chính thức hóa.

6 Kết luận

Trong bài báo này, chúng tôi đề xuất một khung học tập đa nhiệm phụ thuộc tuần tự có tên là khung Trích xuất Mẫu Thích ứng Đa nhiệm (APEM), có thể có chọn lọc tái tạo các biểu diễn chia sẻ ngầm định từ góc nhìn theo mẫu và trích xuất thông tin cụ thể cho tác vụ rõ ràng theo cách hiệu quả hơn so với cấu trúc tháp nhận biết tác vụ thông thường. Chúng tôi thực hiện điều này bằng cách bao gồm một Bộ sinh Biểu diễn Thích ứng theo Mẫu và một Bộ chọn Mẫu. Đối với học tập đa nhiệm với phụ thuộc thường gặp trong đề xuất trực tuyến Thương mại điện tử, chúng tôi cung cấp một chứng minh lý thuyết chi tiết về mối quan hệ phụ thuộc từ góc nhìn toán học nghiêm ngặt. Dựa trên phân tích của chúng tôi, chúng tôi thiết kế một mất mát học tác vụ phụ thuộc để hoàn thành đối tượng tối ưu hóa trong định dạng không thiên vị. Mức tăng hiệu suất của APEM so với một số phương pháp đa nhiệm SOTA trên cả bộ dữ liệu công nghiệp công cộng và thực tế chứng minh tính hiệu quả và đặc tính tổng quát của nó. Bên cạnh đó, chúng tôi cẩn thận thực hiện nghiên cứu loại bỏ, nghiên cứu trường hợp, đánh giá hiệu quả và thử nghiệm A/B trực tuyến để tiếp tục phân tích đóng góp từ các mô-đun khác nhau và khả năng áp dụng của nó cho các tình huống công nghiệp quy mô lớn.

7 Phụ lục

7.1 Chứng minh cho Định lý 2.1

Chứng minh. Xem xét các định nghĩa của không gian suy luận và địa phương, và các mất mát kỳ vọng tương ứng được đưa ra trong (7) và (8), chúng ta có thể thu được

P_C(X,T_i)=P_D(X,T_i|T_{i-1}=1) (24)

theo nghĩa là phân phối kết hợp của X và T_i trong C tương đương với, dưới T_{i-1}=1, phân phối kết hợp của X và T_i trong D.

Theo (24) và định nghĩa của E_{X,T_i∼D}[L(f_i(X),T_i)], thành phần thứ hai ở vế phải của (9) thỏa mãn

E_{X,T_i∼C}[P_D(T_{i-1}=1)P_D(T_i|X)/P_D(T_i,T_{i-1}=1|X) L(f_i(X),T_i)]
=E_{X,T_i∼C}[P_D(T_{i-1}=1)/P_D(T_{i-1}=1|X,T_i) L(f_i(X),T_i)]
=∫_C P_D(T_{i-1}=1)/P_D(T_{i-1}=1|x,t_i) L(f_i(x),t_i)P_C(x,t_i)dxdt_i
=∫_D L(f_i(x),t_i) P_D(T_{i-1}=1)/P_D(T_{i-1}=1|x,t_i) P_D(x,t_i|T_{i-1}=1)dxdt_i
=∫_D L(f_i(x),t_i) P_D(T_{i-1}=1)/P_D(T_{i-1}=1|x,t_i) P_D(x,t_i,T_{i-1}=1)/P_D(T_{i-1}=1)dxdt_i
=∫_D L(f_i(x),t_i)P_D(x,t_i)dxdt_i
=E_{X,T_i∼D}[L(f_i(X),T_i)]. (25)

Do đó, các phương trình (7), (8) và (25) ngụ ý rằng mối quan hệ (9) được thỏa mãn. □

7.2 Chứng minh cho Định lý 3.1

Chứng minh. Theo định lý Bayes, chúng ta có thể thu được đẳng thức sau:

P_D(T_{i-1}=1)P_D(T_{i-1}-T_i|X)/P_D(T_{i-1}-T_i,T_{i-1}=1|X)=P_D(T_{i-1}=1)/P_D(T_{i-1}=1|X,T_{i-1}-T_i). (26)

Xem xét vế phải của (22) và (26), nó dẫn đến

E_{X,T_{i-1},T_i∼C}[P_D(T_{i-1}=1)L(f_{i-1}(X)-f_i(X),T_{i-1}-T_i)/P_D(T_{i-1}=1|X,T_{i-1}-T_i)]
=∫_C [P_D(T_{i-1}=1)/P_D(T_{i-1}=1|x,t_{i-1}-t_i) L(f_{i-1}(x)-f_i(x),t_{i-1}-t_i)
P_C(x,t_{i-1}-t_i)]dxdt_{i-1}dt_i
=∫_D [P_D(T_{i-1}=1)/P_D(T_{i-1}=1|x,t_{i-1}-t_i) P_D(x,t_{i-1}-t_i|T_{i-1}=1)
×L(f_{i-1}(x)-f_i(x),t_{i-1}-t_i)]dxdt_{i-1}dt_i
=∫_D L(f_{i-1}(x)-f_i(x),t_{i-1}-t_i)P_D(x,t_{i-1}-t_i)dxdt_{i-1}dt_i
=E_{X,T_{i-1},T_i∼D}[L(f_{i-1}(X)-f_i(X),T_{i-1}-Z)], (27)

điều này ngụ ý rằng (22) được thỏa mãn. Chứng minh hoàn tất. □

Tài liệu tham khảo

[1] Jonathan Baxter. 1997. Một mô hình Bayesian/lý thuyết thông tin của học để học qua lấy mẫu nhiều tác vụ. Machine learning 28, 1 (1997), 7–39.

[2] Rich Caruana. 1997. Học tập đa nhiệm. Machine learning 28, 1 (1997), 41–75.

[3] Ling Chen, Donghui Chen, Fan Yang, và Jianling Sun. 2021. Điều khiển đột biến nơ-ron. Trong Một phương pháp học biểu diễn sâu đa nhiệm cho phân loại và truy xuất chuỗi thời gian. Information Sciences, 17–32.

[4] Michael Crawshaw. 2020. Học tập đa nhiệm với mạng nơ-ron sâu: Một khảo sát. arXiv preprint arXiv:2009.09796 (2020).

[5] Hongliang Fei, Jingyuan Zhang, Xingxuan Zhou, Junhao Zhao, Xinyang Qi, và Ping Li. 2021. GemNN: mạng nơ-ron đa nhiệm tăng cường cổng với học tương tác đặc trưng cho dự đoán CTR. Trong Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2166–2171.

[6] Tiankai Gu, Kun Kuang, Hong Zhu, Jingjie Li, Zhenhua Dong, Wenjie Hu, Zhenguo Li, Xiuqiang He, và Yue Liu. 2021. Ước lượng chuyển đổi sau nhấp thực qua suy luận phản thực tế phân tầng nhóm.

[7] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, và Xiuqiang He. 2017. DeepFM: một mạng nơ-ron dựa trên máy phân tích cho dự đoán CTR. arXiv preprint arXiv:1703.04247 (2017).

[8] Siyuan Guo, Lixin Zou, Yiding Liu, Wenwen Ye, Suqi Cheng, Shuaiqiang Wang, Hechang Chen, Dawei Yin, và Yi Chang. 2021. Học tập mạnh mẽ kép tăng cường cho ước lượng tỷ lệ chuyển đổi sau nhấp không thiên vị. Trong Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 275–284.

[9] H. Hazimeh, Z. Zhao, A. Chowdhery, M. Sathiamoorthy, và E. H. Chi. 2021. DSelect-k: Lựa chọn có thể vi phân trong Hỗn hợp Chuyên gia với Ứng dụng cho Học tập Đa nhiệm. (2021).

[10] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, và Geoffrey E Hinton. 1991. Hỗn hợp thích ứng của các chuyên gia địa phương. Neural computation 3, 1 (1991), 79–87.

[11] Diederik P Kingma và Jimmy Ba. 2014. Adam: Một phương pháp cho tối ưu hóa ngẫu nhiên. arXiv preprint arXiv:1412.6980 (2014).

[12] Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, và Yee Whye Teh. 2019. Set transformer: Một khung cho mạng nơ-ron bất biến hoán vị dựa trên chú ý. Trong International Conference on Machine Learning. PMLR, 3744–3753.

[13] PM Lerman. 1980. Khớp các mô hình hồi quy phân đoạn bằng tìm kiếm lưới. Journal of the Royal Statistical Society: Series C (Applied Statistics) 29, 1 (1980), 77–84.

[14] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, và Ed H Chi. 2018. Mô hình hóa mối quan hệ tác vụ trong học tập đa nhiệm với hỗn hợp chuyên gia đa cổng. Trong Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1930–1939.

[15] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, và Kun Gai. 2018. Mô hình đa nhiệm toàn không gian: Một phương pháp hiệu quả cho ước lượng tỷ lệ chuyển đổi sau nhấp. Trong The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. 1137–1140.

[16] Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, và Martial Hebert. 2016. Mạng cross-stitch cho học tập đa nhiệm. Trong Proceedings of the IEEE conference on computer vision and pattern recognition. 3994–4003.

[17] Conor O'Brien, Kin Sum Liu, James Neufeld, Rafael Barreto, và Jonathan J Hunt. 2021. Một Phân tích của Các Mô hình Đa Nhiệm Toàn Không gian cho Dự đoán Chuyển đổi Sau Nhấp. Trong Fifteenth ACM Conference on Recommender Systems. 613–619.

[18] Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adria Puigdomenech Badia, Oriol Vinyals, Demis Hassabis, Daan Wierstra, và Charles Blundell. 2017. Điều khiển đột biến nơ-ron. Trong International Conference on Machine Learning. PMLR, 2827–2836.

[19] Sebastian Ruder, Joachim Bingel, Isabelle Augenstein, và Anders Søgaard. 2019. Học kiến trúc đa nhiệm ẩn. Trong Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 4822–4829.

[20] Jiayi Shen, Xiantong Zhen, Marcel Worring, và Ling Shao. 2021. Học tập đa nhiệm biến thiên với tiên nghiệm gumbel-softmax. Advances in Neural Information Processing Systems 34 (2021), 21031–21042.

[21] Asa Cooper Stickland và Iain Murray. 2019. Bert và pals: Các lớp chú ý chiếu cho thích ứng hiệu quả trong học tập đa nhiệm. Trong International Conference on Machine Learning. PMLR, 5986–5995.

[22] Hongyan Tang, Junning Liu, Ming Zhao, và Xudong Gong. 2020. Trích xuất lớp tiến bộ (PLE): Một mô hình học tập đa nhiệm (MTL) mới cho đề xuất cá nhân hóa. Trong Fourteenth ACM Conference on Recommender Systems. 269–278.

[23] Partoo Vafaeikia, Khashayar Namdar, và Farzad Khalvati. 2020. Một Đánh giá Ngắn gọn về Học tập Đa nhiệm Sâu và Học tập Tác vụ Phụ. arXiv preprint arXiv:2007.01126 (2020).

[24] Simon Vandenhende, Stamatios Georgoulis, Marc Proesmans, Dengxin Dai, và Luc Van Gool. 2020. Xem xét lại học tập đa nhiệm trong kỷ nguyên học sâu. arXiv preprint arXiv:2004.13379 2 (2020).

[25] Fangye Wang, Yingxu Wang, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, và Ning Gu. 2022. Tăng cường Dự đoán CTR với Học Biểu diễn Đặc trưng Nhận thức Ngữ cảnh. arXiv preprint arXiv:2204.08758 (2022).

[26] Hao Wang, Tai-Wei Chang, Tianqiao Liu, Jianmin Huang, Zhichao Chen, Chao Yu, Ruopeng Li, và Wei Chu. 2022. ESCM2: Mô hình Đa Nhiệm Phản thực tế Toàn Không gian cho Ước lượng Tỷ lệ Chuyển đổi Sau Nhấp. arXiv preprint arXiv:2204.05125 (2022).

[27] Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Guihong Cao, Daxin Jiang, Ming Zhou, et al. 2020. K-adapter: Truyền kiến thức vào các mô hình được đào tạo trước với các adapter. arXiv preprint arXiv:2002.01808 (2020).

[28] Hong Wen, Jing Zhang, Fuyu Lv, Wentian Bao, Tianyi Wang, và Zulong Chen. 2021. Mô hình hóa phân cấp hành vi vi mô và vĩ mô qua học tập đa nhiệm cho dự đoán tỷ lệ chuyển đổi. Trong Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2187–2191.

[29] Hong Wen, Jing Zhang, Yuan Wang, Fuyu Lv, Wentian Bao, Quan Lin, và Keping Yang. 2020. Mô hình hóa đa nhiệm toàn không gian qua phân tách hành vi sau nhấp cho dự đoán tỷ lệ chuyển đổi. Trong Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval. 2377–2386.

[30] Dongbo Xi, Zhen Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen Zhuang, và Yu Chen. 2021. Mô hình hóa phụ thuộc tuần tự giữa các chuyển đổi đa bước của khán giả với học tập đa nhiệm trong quảng cáo hiển thị có mục tiêu. Trong Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 3745–3755.

[31] Wenhao Zhang, Wentian Bao, Xiao-Yang Liu, Keping Yang, Quan Lin, Hong Wen, và Ramin Ramezani. 2020. Các phương pháp nhân quả quy mô lớn để loại bỏ thiên vị ước lượng tỷ lệ chuyển đổi sau nhấp với học tập đa nhiệm. Trong Proceedings of The Web Conference 2020. 2775–2781.

[32] Jiejie Zhao, Bowen Du, Leilei Sun, Fuzhen Zhuang, Weifeng Lv, và Hui Xiong. 2019. Mạng chú ý quan hệ đa để học tập đa nhiệm. Trong Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1123–1131.

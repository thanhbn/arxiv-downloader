# 2307.03374.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multi-task/2307.03374.pdf
# Kích thước tệp: 15426482 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
STG-MTL: Nhóm Tác Vụ Có Thể Mở Rộng
Cho Học Đa Tác Vụ Sử Dụng Bản Đồ Dữ Liệu
Ammar Sherif∗1, Abubakar Abid2, Mustafa Elattar1, và Mohamed ElHelw1
1Đại học Nile
2Hugging Face
Tóm tắt
Học Đa Tác Vụ (MTL) là một kỹ thuật mạnh mẽ đã trở nên phổ biến do cải thiện hiệu suất so với Học Đơn Tác Vụ (STL) truyền thống. Tuy nhiên, MTL thường gặp thách thức vì có số lượng nhóm tác vụ có thể có theo cấp số nhân, điều này có thể gây khó khăn trong việc chọn nhóm tốt nhất vì một số nhóm có thể gây ra suy giảm hiệu suất do nhiễu tiêu cực giữa các tác vụ. Đó là lý do tại sao các giải pháp hiện tại đang gặp phải vấn đề nghiêm trọng về khả năng mở rộng, hạn chế bất kỳ ứng dụng thực tế nào. Trong bài báo này, chúng tôi đề xuất một phương pháp mới dựa trên dữ liệu nhằm giải quyết những thách thức này và cung cấp một giải pháp có thể mở rộng và mô-đun cho nhóm tác vụ phân loại dựa trên các đặc trưng dựa trên dữ liệu được đề xuất lại, Bản Đồ Dữ Liệu, chúng nắm bắt động lực học huấn luyện cho mỗi tác vụ phân loại trong quá trình huấn luyện MTL. Thông qua so sánh lý thuyết với các kỹ thuật khác, chúng tôi đã chỉ ra rằng phương pháp của chúng tôi có khả năng mở rộng vượt trội. Các thí nghiệm của chúng tôi cho thấy hiệu suất tốt hơn và xác minh tính hiệu quả của phương pháp, ngay cả trên số lượng tác vụ chưa từng có (lên đến 100 tác vụ trên CIFAR100). Là những người đầu tiên làm việc trên số lượng tác vụ như vậy, so sánh của chúng tôi về kết quả nhóm cho thấy nhóm tương tự như được đề cập trong bộ dữ liệu, CIFAR100. Cuối cùng, chúng tôi cung cấp một triển khai mô-đun2 để tích hợp và thử nghiệm dễ dàng hơn, với các ví dụ từ nhiều bộ dữ liệu và tác vụ.

1 Giới thiệu
Học Đa Tác Vụ (MTL) đã nổi lên như một kỹ thuật mạnh mẽ trong học sâu [39,7] cho phép huấn luyện chung nhiều tác vụ liên quan, dẫn đến cải thiện hiệu suất mô hình so với Học Đơn Tác Vụ (STL) truyền thống. Bằng cách tận dụng các biểu diễn và kiến thức được chia sẻ giữa các tác vụ, MTL tăng cường khả năng tổng quát hóa và giảm thiểu quá khớp. Hơn nữa, MTL thúc đẩy học nhanh hơn của các tác vụ liên quan và giảm bớt yêu cầu tính toán của học sâu, làm cho nó đặc biệt có giá trị trong các tình huống có dữ liệu cụ thể tác vụ hạn chế. Đó là lý do tại sao MTL đã thu hút sự chú ý đáng kể trong nhiều lĩnh vực khác nhau, bao gồm thị giác máy tính [8,25,30], xử lý ngôn ngữ tự nhiên [41,26,16,4], nhận dạng giọng nói [13,40], và chăm sóc sức khỏe [26,2,15], và đã cho thấy kết quả đầy hứa hẹn trong việc cải thiện độ chính xác, tính mạnh mẽ và hiệu quả. Tuy nhiên, việc khai thác hiệu quả tiềm năng của MTL đặt ra một số thách thức, bao gồm việc xác định nhóm tác vụ tối ưu [29, 9, 30] và quản lý nhiễu tiêu cực giữa các tác vụ [28, 35, 24].

Vấn đề nhóm tác vụ trong MTL đặc biệt khó khăn do số lượng tổ hợp tác vụ có thể có theo cấp số nhân [1,9,30,29]. Điều làm cho việc tìm kiếm toàn diện trở nên tệ hơn là mỗi lần thử đều bao gồm một quy trình huấn luyện và đánh giá hoàn chỉnh, dẫn đến gánh nặng tính toán và tối ưu hóa. Hơn nữa, các nhóm tác vụ không phù hợp có thể dẫn đến suy giảm hiệu suất
∗Tác giả liên hệ <ammarsherif90 [at] gmail [dot] com>
2https://github.com/ammarSherif/STG-MTLarXiv:2307.03374v2  [cs.LG]  26 May 2024

--- TRANG 2 ---
Các Lớp Chia SẻĐầu 1 Đầu 2 Đầu 
Đầu VàoTác Vụ 2 Đ/RTác Vụ  Đ/R
Bản Đồ Dữ LiệuKiến Trúc MTL Đa Đầu
Tác Vụ 1 Đ/RMất Mát Tác Vụ
Trọng Số
MTL Chuyên Biệt  Huấn Luyện Đa Đầu Trọng SốMất Mát Tác Vụ
Tác Vụ
Cụm Mô HìnhMô Hình 1 Mô Hình 
(1) Huấn luyện MTL Đa Đầu trên tất cả các tác vụ(2) Trích xuất bản đồ dữ liệu(3) Phân cụm mềm để tạo trọng số thành viên tác vụ[Tùy chọn]
    (4) Sử dụng thành viên làm trọng số mất mát để huấn luyện các mô hình chuyên biệtHình 1: Tổng quan về phương pháp phân cụm tác vụ của chúng tôi sử dụng Bản Đồ Dữ Liệu. (1) chúng tôi sử dụng một kiến trúc Học Đa Tác Vụ Đa đầu duy nhất để huấn luyện chung tất cả các tác vụ. Mỗi đầu là các lớp cụ thể tác vụ. (2) chúng tôi trích xuất bản đồ dữ liệu của tất cả các tác vụ qua các epoch trong E. (3) chúng tôi sử dụng bản đồ dữ liệu để phân cụm các tác vụ bằng kmeans và tạo ra các thành viên theo Phương trình 2. (4) để đánh giá kết quả phân cụm của chúng tôi, chúng tôi huấn luyện m mô hình trong đó mỗi mô hình đại diện cho một cụm tập trung vào các tác vụ cụ thể sử dụng các thành viên làm trọng số mất mát.

do chuyển giao tiêu cực giữa các tác vụ [28,35,24]. Các giải pháp hiện tại, giải quyết những thách thức này, thường gặp phải vấn đề về khả năng mở rộng và tính mô-đun, khiến việc ứng dụng thực tế trong các tình huống thực tế gần như không khả thi.

Trong bài báo này, chúng tôi đề xuất một phương pháp mới dựa trên dữ liệu cho nhóm tác vụ trong MTL cho các tác vụ phân loại, vượt qua các hạn chế về khả năng mở rộng và tính mô-đun. Phương pháp của chúng tôi sử dụng Bản Đồ Dữ Liệu [33], các đặc trưng dựa trên dữ liệu nắm bắt động lực học huấn luyện của mỗi tác vụ phân loại trong quá trình huấn luyện MTL. Bằng cách phân tích những bản đồ dữ liệu này, chúng tôi có thể xác định các nhóm tác vụ, cả cứng và mềm, thúc đẩy chuyển giao tích cực và giảm thiểu nhiễu tiêu cực càng nhiều càng tốt. Chúng tôi chứng minh tính hiệu quả của phương pháp thông qua thí nghiệm rộng rãi, bao gồm thí nghiệm trên số lượng tác vụ chưa từng có, mở rộng lên đến 100 tác vụ để nhấn mạnh tính thực tế của cách tiếp cận của chúng tôi, nơi các nhóm được tạo ra phù hợp với phân loại bộ dữ liệu. Chúng tôi cũng minh họa cải thiện hiệu suất của phương pháp so với việc sử dụng cả MTL và STL để huấn luyện. Hơn nữa, chúng tôi nhấn mạnh tính thực tế của cách tiếp cận bằng cách cung cấp một triển khai mã mô-đun, giúp các nhà nghiên cứu và phát triển tích hợp và thử nghiệm phương pháp của chúng tôi trên bộ dữ liệu và tác vụ của riêng họ dễ dàng hơn.

Các đóng góp của bài báo này được tóm tắt dưới đây:
• Chúng tôi đề xuất một phương pháp mới dựa trên dữ liệu cho nhóm tác vụ phân loại trong MTL, giải quyết thách thức về khả năng mở rộng và tính mô-đun, bằng cách đề xuất lại việc sử dụng bản đồ dữ liệu như đặc trưng tác vụ.
• Chúng tôi sử dụng trọng số phân cụm mềm để cho phép chuyên biệt hóa mô hình thông qua trọng số mất mát.
• Chúng tôi tiến hành thí nghiệm rộng rãi, chứng minh tính hiệu quả của phương pháp, ngay cả trên số lượng lớn tác vụ (mở rộng lên đến 100 tác vụ phân loại).
• Chúng tôi cung cấp triển khai mã mô-đun của phương pháp, tạo điều kiện cho việc áp dụng và sử dụng bởi cả cộng đồng nghiên cứu và công nghiệp.

2 Công trình liên quan
MTL đã được nghiên cứu rộng rãi để tận dụng lợi ích của việc chia sẻ thông tin giữa các tác vụ liên quan, có thể phục vụ như một thiên lệch quy nạp để cải thiện hiệu suất mô hình hóa [5,39]. Một góc nhìn khác về MTL là nó cho phép sử dụng hiệu quả hơn dung lượng mô hình bằng cách tập trung vào học các đặc trưng liên quan và giảm tác động của các tín hiệu không liên quan, góp phần vào quá khớp, dẫn đến khả năng tổng quát hóa tốt hơn. Tuy nhiên, khi các tác vụ thiếu thông tin được chia sẻ, chúng cạnh tranh cho dung lượng mô hình hạn chế, dẫn đến suy giảm hiệu suất [28,35,24]. Để giải quyết thách thức này, nhóm tác vụ đã nổi lên như một giải pháp đầy hứa hẹn để xác định các tập con tác vụ có thể được huấn luyện cùng nhau. Điều này giúp tránh nhiễu tiêu cực và thúc đẩy cải thiện hiệu suất.

Theo truyền thống, quyết định về nhóm tác vụ đã được tiếp cận thông qua các kỹ thuật kiểm tra chéo tốn kém hoặc kiến thức chuyên gia con người [39]. Tuy nhiên, những phương pháp này có hạn chế khi áp dụng cho các lĩnh vực vấn đề khác nhau và không mở rộng tốt. Do đó, một số chỉ đơn giản sử dụng tương quan, hoặc giữa các dự đoán tác vụ mô hình [36], nhãn dữ liệu, hoặc trọng số tác vụ [37], để nhận dạng các tác vụ liên quan. Ví dụ, trong hình ảnh y tế, những phương pháp này đã được áp dụng để cải thiện dự đoán cho Chỉ Số Tim [36,37]. Tuy nhiên, những cách tiếp cận này không hiệu quả trong các tình huống thiếu tương quan rõ ràng giữa các nhãn tác vụ, trong chính bộ dữ liệu, chẳng hạn như các tác vụ phân loại nhị phân thành viên độc quyền.

Hơn nữa, cả hai công trình đều nhằm mục đích biết các mối quan hệ tác vụ để cải thiện dự đoán mô hình của Chỉ Số Tim trong cài đặt đa nhìn hoặc đa phương thức, sử dụng một mô hình duy nhất. Điều này khá khác với mục tiêu của chúng tôi là tìm các mối quan hệ để chia tác vụ thành các mô hình khác nhau để tránh nhiễu tiêu cực.

Những nỗ lực khác đã được thực hiện để tiếp cận vấn đề khác nhau cho phép các mô hình tự động hóa việc tìm kiếm về tham số nào để chia sẻ giữa các tác vụ cụ thể [38,25]. Các phương pháp như Tìm Kiếm Kiến Trúc Mạng Nơ-ron [20,12,6,38,32,34], Chia Sẻ Tham Số Mềm [27,23,25], và chuyển giao thông tin bất đối xứng [18,19,11] đã được phát triển. Tuy nhiên, những mô hình này thường thể hiện khả năng tổng quát hóa kém và gặp khó khăn để hoạt động tốt trên các tác vụ và lĩnh vực đa dạng. Bên cạnh đó, chúng thường đòi hỏi dung lượng mô hình lớn và do đó không mở rộng đủ tốt với số lượng lớn tác vụ.

Do đó, các phương pháp dựa trên gradient [9,31,14] cũng đã được khám phá để xác định nhóm tác vụ trước. Phương pháp Nhóm Ái Lực Tác Vụ (TAG) [9], tận dụng gradient để xác định độ tương tự tác vụ, là một ví dụ về cách tiếp cận như vậy. Tuy nhiên, nó có mô hình huấn luyện phức tạp và yêu cầu Θ(n²) lượt truyền tiến và lùi nhiều hơn để tính toán ái lực giữa các tác vụ, đặt ra vấn đề về khả năng mở rộng ngay cả khi chúng tôi tăng cường tính mô-đun của giải pháp. Một phương pháp khác, gọi là Xấp Xỉ Bậc Cao (HOA) [30], giảm số lượng huấn luyện MTL theo cấp số nhân, từ tìm kiếm toàn diện, bằng cách chỉ xem xét các cặp bậc hai của tổ hợp tác vụ. Tuy nhiên, ngay cả với sự nới lỏng như vậy, khả năng mở rộng của HOA vẫn hạn chế, đặc biệt khi xử lý số lượng lớn tác vụ.

Các nghiên cứu gần đây đã chấp nhận việc sử dụng gradient tích lũy để mô tả các tác vụ riêng lẻ như vectơ [14], cung cấp khả năng mở rộng được cải thiện bằng cách cần tinh chỉnh chỉ Θ(n) mô hình. Tuy nhiên, phương pháp này gặp phải hạn chế đáng kể liên quan đến tính mô-đun. Yêu cầu tinh chỉnh mô hình được đào tạo trước cho mỗi tác vụ dẫn đến sự phụ thuộc nơi tất cả các tác vụ phải chia sẻ cùng một mô hình được đào tạo trước, điều này có thể gây thách thức khi xử lý số lượng lớn tác vụ. Nó cũng có ràng buộc rằng tất cả các tác vụ phải chia sẻ cùng một kiến trúc vì các vectơ tác vụ được biểu diễn trong không gian trọng số của mô hình. Hơn nữa, công trình tập trung vào việc sử dụng vectơ tác vụ để tăng cường tinh chỉnh và học chuyển giao, thay vì nhóm các tác vụ vào các mô hình MTL khác nhau để giảm thiểu nhiễu tiêu cực.

Vấn đề nhóm tác vụ cũng đã được giải quyết khác nhau thông qua phương pháp Meta-Learning [29], nhằm tạo ra một meta-learner có thể ước tính lợi ích nhóm tác vụ. Tuy nhiên, yêu cầu tính toán của cách tiếp cận này đặt ra thách thức thực tế cho các ứng dụng thực tế; nó yêu cầu huấn luyện mạng MTL cho mỗi tổ hợp tác vụ được chọn trong tập huấn luyện cho nhiều lần lặp. Hơn nữa, nó xuất ra tất cả các lợi ích có thể có của mỗi tổ hợp tác vụ, có số lượng tăng theo cấp số nhân, và chạy một thuật toán tìm kiếm trên những lợi ích tăng theo cấp số nhân này để tìm nhóm tối ưu. Kết quả là, khả năng mở rộng của giải pháp này bị hạn chế nghiêm trọng, làm cho nó ít khả thi hơn cho số lượng lớn tác vụ.

3 Phân cụm Tác vụ sử dụng Bản đồ Dữ liệu
Bây giờ, chúng tôi trình bày chi tiết các thành phần trong phương pháp của chúng tôi trong các phần tiếp theo. Chúng tôi bắt đầu bằng việc nêu các ký hiệu chúng tôi sẽ sử dụng cùng với kiến trúc MTL chúng tôi đang sử dụng trong các thí nghiệm của mình trong Phần 3.1. Sau đó, chúng tôi chuyển sang minh họa bản đồ dữ liệu, là thành phần quan trọng của phương pháp chúng tôi trong Phần 3.2. Trong Phần 3.3, chúng tôi thảo luận về các cách tiếp cận chúng tôi sử dụng để phân cụm các tác vụ. Chúng tôi cũng giới thiệu cơ chế đánh giá nhóm tác vụ của chúng tôi trong Phần 3.4. Cuối cùng, chúng tôi kết thúc phần này với một so sánh lý thuyết đơn giản về phương pháp của chúng tôi và tài liệu từ góc độ khả năng mở rộng và tính mô-đun trong Phần 3.5. Hình 1 cung cấp tổng quan về phương pháp của chúng tôi.

--- TRANG 3 ---

3.1 Khái niệm cơ bản
Ký hiệu Trong bài báo của chúng tôi, chúng tôi sử dụng các ký hiệu sau. Tập hợp tất cả các tác vụ được ký hiệu là T = {T1, . . . , Tn}, trong đó n đại diện cho số lượng tác vụ và |T| = n. Tổng số điểm dữ liệu huấn luyện được ký hiệu là N. Chúng tôi tính toán bản đồ dữ liệu tại các epoch cụ thể, và tập hợp các epoch được biểu diễn là E = {E1, . . . , Ee}, trong đó Ei tương ứng với epoch thứ i và |E| = e. Các cụm tác vụ được ký hiệu bởi C = {C1, . . . , Cm}, và mỗi cụm Ci có một tâm liên kết ci và |C| = m. Trọng số liên kết, trọng số cụm mềm, của mỗi tác vụ i đến cụm j được biểu diễn bởi wi,j, với ràng buộc rằng Σmj=1 wi,j = 1; Wj, WLj là vectơ trọng số và mất mát có trọng số của tất cả các tác vụ trong cụm j tương ứng, trong khi Lj đơn giản biểu diễn mất mát kết quả của mô hình j biểu thị cụm j. Lưu ý rằng các giá trị của wi,j nằm trong khoảng từ 0 đến 1, trong đó 1 biểu thị thành viên đầy đủ và 0 biểu thị không có thành viên.

Kiến trúc MTL Theo các cách tiếp cận trước đây [9,30,29], chúng tôi sử dụng một kiến trúc đa đầu chia sẻ cứng thường được sử dụng (Hình 1) cho tất cả các thí nghiệm MTL của chúng tôi, trong đó một trích xuất đặc trưng duy nhất được sử dụng để có được các biểu diễn được chia sẻ, và các đầu cụ thể tác vụ riêng biệt được sử dụng để xuất ra kết quả. Ngoài ra, cho tất cả các thí nghiệm, chúng tôi duy trì cùng một phân chia dữ liệu, thông qua việc tạo hạt giống trước, và giữ thuật toán tối ưu hóa và các siêu tham số khác cố định; điều này là để đảm bảo rằng bất kỳ sự biến đổi nào trong hiệu suất chỉ được quy cho nhóm tác vụ và các trọng số tương ứng nếu có.

3.2 Bản đồ Dữ liệu như Đặc trưng Tác vụ
Hình 2: Một ví dụ về bản đồ dữ liệu được tạo ra cho tác vụ "Sinh vật sống" sau 21 epoch đồng huấn luyện trên 15 tác vụ của G2 (Phần 4.1)

Bản Đồ Dữ Liệu [33] ban đầu được phát triển như một công cụ dựa trên mô hình để đặc trưng và chẩn đoán các bộ dữ liệu NLP. Chúng tôi đề xuất lại việc sử dụng chúng như các đặc trưng tác vụ trong quá trình huấn luyện trong cài đặt MTL do khả năng nắm bắt hành vi mô hình của từng điểm dữ liệu huấn luyện riêng lẻ đối với mỗi tác vụ, đây là một đặc trưng có giá trị cho chính tác vụ đó. Vì lý do đó, chúng tôi sử dụng chúng, trong công việc của chúng tôi, như các đặc trưng tác vụ do tính đơn giản, khả năng mở rộng và khả năng trích xuất chúng một cách nhanh chóng mà không cần kiến thức trước về kiến trúc mô hình, do đó tăng cường tính mô-đun của cách tiếp cận của chúng tôi.

Khái niệm đằng sau Bản Đồ Dữ Liệu xoay quanh việc trích xuất hai giá trị cho mỗi điểm dữ liệu: độ tin cậy mô hình (μ) của lớp thật, là xác suất trung bình của lớp thật qua các epoch, và độ biến thiên (σ) của độ tin cậy này, là độ lệch chuẩn của xác suất lớp thật qua cùng các epoch. Đối với một tác vụ cụ thể, hình dạng bản đồ dữ liệu là (N,2). Hình 2 cho thấy một trực quan hóa của Bản Đồ Dữ Liệu kết quả cho một tác vụ ví dụ được trích xuất từ bộ dữ liệu CIFAR10 [17].

Bởi vì thông tin của chúng rất phụ thuộc vào tác vụ, chúng tôi nghĩ rằng chúng có thể phục vụ như các mô tả tác vụ. Để tăng cường hơn nữa tính biểu cảm của các đặc trưng được trích xuất, chúng tôi cũng trích xuất bản đồ dữ liệu tại nhiều epoch khác nhau, cho phép chúng tôi có được hiểu biết về sự tiến hóa của chúng theo thời gian; hình dạng kết quả trong trường hợp như vậy là (n, e, N, 2). Do đó, bằng cách phân tích các đặc tính của chúng, qua các epoch khác nhau trong quá trình huấn luyện, chúng tôi có thể nắm bắt thông tin quan trọng về mối liên hệ của mỗi tác vụ.

Trong việc trích xuất bản đồ dữ liệu, chúng tôi có thể sử dụng hai cách tiếp cận. Cách tiếp cận đầu tiên bao gồm việc xây dựng một mô hình MTL duy nhất kết hợp tất cả các tác vụ và trích xuất bản đồ dữ liệu trực tiếp từ mô hình thống nhất này. Ngoài ra, chúng tôi có thể sử dụng cách tiếp cận thứ hai, nơi các mô hình riêng lẻ được xây dựng cho mỗi tác vụ, dẫn đến nhiều STL, và hợp nhất các bản đồ dữ liệu thu được từ mỗi mô hình. Kết quả của chúng tôi chủ yếu dựa trên cách tiếp cận đầu tiên, vì nó mang lại lợi thế của việc sử dụng một mô hình huấn luyện duy nhất, đơn giản hóa độ phức tạp tính toán, tăng cường khả năng mở rộng và hợp lý hóa thí nghiệm, trong khi có kết quả tương đương với STL, như được hiển thị trong Phần 4.4.

--- TRANG 4 ---

3.3 Phân cụm Tác vụ
Với các bản đồ dữ liệu được trích xuất trong tay, bước tiếp theo của chúng tôi là nhóm các tác vụ thành các cụm dựa trên độ tương tự của chúng. Chúng tôi đề xuất sử dụng phân cụm mềm để có được trọng số thành viên lớp, wi,j. Để có được chúng, chúng tôi biểu diễn mỗi tác vụ như một vectơ bằng cách làm phẳng các bản đồ dữ liệu được nối, được trích xuất tại các epoch khác nhau. Sau đó, chúng tôi sử dụng thuật toán k-means [22] để phân cụm các vectơ tác vụ này, nhằm xác định các cụm tác vụ riêng biệt, thành các cụm cứng. Để giới thiệu một biểu diễn sắc thái hơn về độ tương tự tác vụ, chúng tôi kết hợp bước mờ hóa [3] vào cách tiếp cận của chúng tôi, nhưng chúng tôi sửa đổi nó để có hiệu quả tính toán tốt hơn, phương trình 2. Điều này cho phép phân cụm mềm, trong đó xi đại diện cho vectơ tác vụ thứ i của các bản đồ dữ liệu tương ứng và F > 1 biểu diễn chỉ số mờ hóa. Quá trình mờ hóa này gán các thành viên mềm cho các tác vụ, cho phép kết quả phân cụm linh hoạt và toàn diện hơn. Chúng tôi chủ yếu dựa vào cách tiếp cận phân cụm mềm do tính hiệu quả và độ tin cậy của nó ngoài việc cho phép chuyên biệt hóa mô hình thông qua trọng số mất mát, như được giải thích trong Phần 3.4.

wi,j = 1 / Σnk=1 (‖xi−cj‖ / ‖xi−ck‖)^(2/(F−1))  (1)

= ‖xi−cj‖^(−2/(F−1)) / Σnk=1(‖xi−ck‖)^(−2/(F−1))  (2)

3.4 Chuyên biệt hóa Mô hình thông qua Trọng số Mất mát

Đầu vào
Mô hình 1 Mô hình 2 Mô hình 
Đầu ra Mô hình 1 Đầu ra Mô hình 2 Đầu ra Mô hình 
Đầu ra Cuối cùng

Hình 3: Quy trình sử dụng các mô hình huấn luyện chuyên biệt của chúng tôi để suy luận kết quả

Để đánh giá tính hiệu quả của kết quả nhóm tác vụ của chúng tôi, chúng tôi sử dụng trọng số mất mát như một phương pháp chuyên biệt hóa mô hình. Chúng tôi xây dựng các mô hình MTL được điều chỉnh để chuyên biệt hóa trong các tập hợp tác vụ cụ thể dựa trên trọng số thành viên thu được từ kết quả phân cụm mềm. Đối với mỗi cụm, chúng tôi xây dựng một mô hình MTL riêng lẻ tập trung vào các tác vụ được gán cho cụm đó theo trọng số tương ứng của chúng (Phương trình 3). Để đánh giá hiệu suất của giải pháp chúng tôi, chúng tôi áp dụng trung bình có trọng số của các đầu ra mô hình theo trọng số thành viên như trong Phương trình 4, trong đó Oj là đầu ra của mô hình thứ j và ◦ biểu diễn sản phẩm Hadamard, từng phần tử. Hình 3 cung cấp tổng quan về những hoạt động này trong khi suy luận đầu ra. Bằng cách so sánh các giá trị kết quả với cả sơ đồ STL và MTL truyền thống trong Phần 4.4, chúng tôi có thể có được hiểu biết về lợi ích và cải thiện mang lại bởi cách tiếp cận nhóm tác vụ của chúng tôi.

WLj = WTj Lj  (3)

Đầu ra Cuối cùng = Σmj=1 Wj ◦ Oj  (4)

--- TRANG 5 ---

Bảng 1: So sánh tăng trưởng tiệm cận của số lượng mô hình MTL được huấn luyện cần thiết để có nhóm tác vụ của các phương pháp khác nhau và của chúng tôi

Phương pháp | Số lượng Mô hình (↓)
Tìm kiếm Toàn diện | Θ(2^n)
HOA | Θ(n^2) = Θ(n^2)
TAG* | Θ(n^2)
MTG-Net | Θ(n·K)
STG-MTL | Θ(1)

*TAG ban đầu yêu cầu một mô hình, nhưng chúng tôi thực hiện n^2 cập nhật để tính toán ái lực giữa các tác vụ. Vì lý do đó, một mô hình huấn luyện duy nhất của TAG tương đương tiệm cận với việc huấn luyện Θ(n^2) mô hình từ các cách tiếp cận khác.

3.5 So sánh Khả năng Mở rộng Lý thuyết

Trong so sánh khả năng mở rộng lý thuyết, chúng tôi đánh giá phương pháp của chúng tôi so với tài liệu hiện tại, tập trung vào số lượng mô hình được huấn luyện cần thiết để có được kết quả phân cụm. Bảng 1 trình bày so sánh, trong đó số lượng thấp hơn cho thấy khả năng mở rộng tốt hơn. Cách tiếp cận của chúng tôi nổi bật với khả năng mở rộng xuất sắc, vì nó chỉ cần huấn luyện một mô hình MTL duy nhất để trích xuất bản đồ dữ liệu và thực hiện phân cụm, hoặc thậm chí O(n) nếu chúng tôi xem xét việc trích xuất bản đồ dữ liệu từ n mô hình STL. Điều này cung cấp tiềm năng khả năng mở rộng hứa hẹn nhất cho số lượng lớn tác vụ. Đó là lý do tại sao chúng tôi có thể mở rộng thí nghiệm của chúng tôi đến số lượng rất lớn tác vụ như trong Phần 4. Chúng tôi cũng nhấn mạnh ghi chú của Bảng 1 rằng mặc dù TAG yêu cầu một mô hình duy nhất để trích xuất các nhóm, chúng tôi tính toán các gradient Θ(n^2), n^2 cụ thể, nhiều lần hơn bình thường để tính toán các cặp ái lực giữa tác vụ. Do đó, một lần huấn luyện mô hình của TAG sử dụng cùng thời gian tiệm cận của Θ(n^2) mô hình được huấn luyện bình thường.

Hơn nữa, việc tính toán bản đồ dữ liệu của phương pháp chúng tôi được thực hiện một cách nhanh chóng, làm cho nó vừa bất khả tri về mô hình vừa bất khả tri về tác vụ. Tính năng này tăng cường tính mô-đun của cách tiếp cận chúng tôi, cho phép thích ứng dễ dàng với các kiến trúc mô hình và tác vụ khác nhau mà không cần can thiệp thủ công. Tham khảo Phụ lục B để thảo luận thêm về khía cạnh tính mô-đun của phương pháp chúng tôi.

4 Thí nghiệm

Trong phần này, chúng tôi trình bày tổng quan toàn diện về các thí nghiệm của chúng tôi, tập trung vào việc đánh giá tính hiệu quả của phương pháp chúng tôi và trình bày các kết quả tương ứng. Như được nêu trong Phần 3.5, các phương pháp trong tài liệu có vấn đề nghiêm trọng về khả năng mở rộng. Điều này làm cho việc so sánh trực tiếp hiệu suất trên tất cả các phương pháp không khả thi, xem xét khả năng mở rộng kém của chúng, số lượng đáng kể tác vụ liên quan trong đánh giá của chúng tôi, và khả năng tính toán hạn chế của chúng tôi. Để minh họa, kết quả phân cụm của chỉ 15 tác vụ cho HOA cần huấn luyện (15 choose 2) = 105 mô hình. Do đó, chúng tôi đánh giá phương pháp của chúng tôi so với cả kết quả MTL và STL để thể hiện thông tin bổ sung thu được từ kết quả phân cụm của chúng tôi.

Phần 4.1 nêu chi tiết về các bộ dữ liệu được sử dụng trong thí nghiệm của chúng tôi, cũng như các tác vụ được sử dụng. Trong Phần 4.2, chúng tôi đi sâu vào chi tiết về kiến trúc mô hình và các siêu tham số được sử dụng trong thí nghiệm. Kết quả của việc phân cụm mềm các tác vụ được trình bày trong Phần 4.3, nơi chúng tôi nêu bật tính hiệu quả của cách tiếp cận trong việc nhóm các tác vụ liên quan. Cuối cùng, trong Phần 4.4, chúng tôi đánh giá chất lượng của kết quả phân cụm thu được so sánh chúng với kết quả STL và MTL. Phụ lục B minh họa cấu trúc đường ống mô-đun của chúng tôi cho tất cả các thí nghiệm để tái tạo dễ dàng hơn.

4.1 Bộ dữ liệu và Tác vụ

Việc tạo tác vụ của chúng tôi dựa trên các bộ dữ liệu CIFAR10 và CIFAR100 [17] cùng với bộ dữ liệu CelebA [21]. Chúng tôi chủ yếu sử dụng chúng do tính khả dụng công cộng và số lượng cao các tác vụ mà chúng tôi có thể tạo ra từ chúng. Chúng tôi hiển thị kết quả của bốn nhóm tác vụ trong thí nghiệm của chúng tôi. Đối với tất cả các bộ dữ liệu này, chúng tôi định nghĩa các tác vụ nhị phân để phát hiện xem hình ảnh đầu vào có thuộc một nhãn cụ thể hay không.

--- TRANG 6 ---

Trong Nhóm 1 (G1), ví dụ, chúng tôi bao gồm các tác vụ phân loại nhị phân xác định xem một hình ảnh có thuộc nhãn CIFAR10 hay không. G1 bao gồm 10 tác vụ: {máy bay, ô tô, chim, mèo, hươu, chó, ếch, ngựa, tàu, xe tải}. Tức là tác vụ "máy bay" là để phát hiện xem hình ảnh có phải là máy bay hay không.

Nhóm 2 (G2) mở rộng từ G1 bằng cách giới thiệu các tác vụ bổ sung trên CIFAR10, được thiết kế để kiểm tra định tính hành vi của phương pháp. Những tác vụ này bao gồm {Sinh vật sống, Số lẻ, Úp ngược, Không phải sinh vật sống, ngẫu nhiên}. Tác vụ "Sinh vật sống" nhằm phát hiện xem một hình ảnh có chứa sinh vật sống hay không, bao gồm các hình ảnh với nhãn {chim, mèo, hươu, chó, ếch, ngựa}. Tương tự, tác vụ "Không phải sinh vật sống" tập trung vào việc nhận dạng những thứ không phải sinh vật sống; đây là các lớp {máy bay, ô tô, tàu, xe tải} trong CIFAR10. Đáng chú ý, "Sinh vật sống" và "Không phải sinh vật sống" được thiết kế có chủ ý để là các tác vụ tương tự nhau để kiểm tra xem phương pháp có thể phát hiện ra sự tương tự như vậy hay không. Tác vụ "Số lẻ" nhận dạng xem nhãn của hình ảnh CIFAR10 có phải là số lẻ hay không, bao gồm các lớp {ô tô, mèo, chó, ngựa, xe tải}. Ngoài ra, chúng tôi lật ngược một nửa hình ảnh CIFAR10 và tạo một tác vụ để huấn luyện mô hình nhận dạng hình ảnh được lật ngược theo chiều dọc, tác vụ "Úp ngược". Cuối cùng, tác vụ "ngẫu nhiên" gán nhãn nhị phân ngẫu nhiên cho toàn bộ bộ dữ liệu với một hạt giống được định trước để đảm bảo tính nhất quán và khả năng tái tạo; tác vụ "ngẫu nhiên" được thêm vào để đại diện cho tác vụ cực kỳ khó, chẳng hạn. Đáng chú ý rằng trong khi các tác vụ gốc trong G1 không cân bằng, các tác vụ bổ sung trong G2 được cân bằng.

Nhóm 3 (G3), tương tự như G1, bao gồm 100 tác vụ phân loại nhị phân sử dụng các nhãn CIFAR100. Chúng tôi cũng sử dụng 20 siêu nhãn của CIFAR100 như sự thật cơ bản cho đánh giá phân cụm tác vụ. Đáng chú ý rằng các siêu nhãn CIFAR100 không được dành cho nhóm tác vụ, vì vậy chúng không được nhóm dựa trên sự tương tự hình ảnh như mục tiêu của phương pháp chúng tôi. Thay vào đó, chúng chủ yếu được phân cụm về mặt ngữ nghĩa, mặc dù có một số ngoại lệ như nấm và các lớp xe 1 và 2. Tuy nhiên, chúng tôi nghĩ rằng chúng phục vụ như một chỉ báo thông tin về tính hiệu quả của cách tiếp cận của chúng tôi, đặc biệt trong các siêu lớp có tính mạch lạc hình ảnh. Tương tự, chúng tôi định nghĩa nhóm 4 (G4) để bao gồm 40 tác vụ phân loại nhị phân được bao gồm trong CelebA.

4.2 Kiến trúc Mô hình và Siêu tham số

Đối với tất cả các thí nghiệm của chúng tôi, chúng tôi áp dụng kiến trúc RESNET18 [10] làm mô hình cơ sở. Phương pháp của chúng tôi bất khả tri về mô hình, vì vậy chúng tôi cũng đã thí nghiệm với các mô hình đơn giản hơn, kết quả & kiến trúc được thảo luận trong Phụ lục A.1, nhưng chúng tôi sử dụng RESNET18 xem xét dung lượng mô hình vừa phải của nó. Hơn nữa, chúng tôi sử dụng nó mà không có bất kỳ huấn luyện trước nào, đảm bảo rằng mô hình bắt đầu từ đầu cho mỗi tình huống nhóm tác vụ. Lớp kết nối đầy đủ cuối cùng của RESNET18 phục vụ như các đầu tác vụ, với số lượng nơ-ron đầu ra tương ứng với số lượng tác vụ. Mỗi nơ-ron trong các đầu tác vụ đại diện cho một tác vụ phân loại cụ thể. Trong suốt các thí nghiệm của chúng tôi, phần còn lại của mạng, loại trừ các đầu tác vụ, được chia sẻ giữa tất cả các tác vụ. Ngoài ra, chúng tôi huấn luyện mô hình cho 50 epoch trong tất cả các thí nghiệm của chúng tôi: để trích xuất bản đồ dữ liệu và để đánh giá các mô hình. Thêm vào đó, trong quá trình phân cụm của chúng tôi, chúng tôi chủ yếu đặt chỉ số mờ hóa (F) là 2. Chỉ số mờ hóa kiểm soát mức độ mờ trong thuật toán phân cụm mềm, vì vậy việc tăng nó tạo ra các quyết định mềm hơn.

Về hàm mất mát, chúng tôi sử dụng Binary Cross Entropy làm mất mát phân loại nhị phân cho các tác vụ của chúng tôi. Tuy nhiên, để giải quyết vấn đề mất cân bằng tác vụ, chúng tôi kết hợp một hình phạt trên các thể hiện tích cực cho mỗi tác vụ. Bằng cách áp dụng hình phạt này, chúng tôi đảm bảo rằng mô hình chú ý nhiều hơn đến nhãn thiểu số trong quá trình huấn luyện, do đó giảm thiểu tác động của sự mất cân bằng và thúc đẩy hiệu suất tổng thể tốt hơn. Cuối cùng, đáng chú ý rằng chúng tôi không thực hiện bất kỳ loại điều chỉnh nào cho bất kỳ mô hình nào. Chúng tôi sử dụng cùng các cài đặt cơ bản trong tất cả các thí nghiệm của chúng tôi.

4.3 Kết quả Phân cụm Tác vụ

Kết quả của các thí nghiệm phân cụm tác vụ của chúng tôi được trình bày cho tất cả các nhóm. Chúng tôi ban đầu thí nghiệm trên G2, tạo ra bản đồ dữ liệu của chúng như được mô tả trong Phần 3.2 và Phân cụm chúng như trong Phần 3.3, như được mô tả trong Hình 4. Đáng chú ý, phương pháp của chúng tôi đã phân cụm thành công tác vụ "ngẫu nhiên" riêng biệt, chỉ ra sự khác biệt của nó so với các tác vụ khác. Hơn nữa, trong suốt tất cả các thí nghiệm của chúng tôi, các tác vụ "Sinh vật sống" và "Không phải sinh vật sống" liên tục thể hiện cùng một phân phối thành viên, điều này hợp lý xem xét tính tương đương của chúng.

Hơn nữa, khi chỉ tập trung vào 10 tác vụ đầu tiên từ G2 mà không có bất kỳ tác vụ bổ sung nào, các thuật toán phân cụm của chúng tôi đã thể hiện một số khả năng phân cụm ngữ nghĩa, như được hiển thị trong Hình 4b. Thuật toán đã nhóm thành công hình ảnh của sinh vật sống, bao gồm {chim, mèo, hươu, chó, ếch, ngựa}, trong khi một nhóm khác bao gồm hình ảnh của các vật thể không phải sinh vật sống như {máy bay, ô tô, tàu, xe tải}. Tuy nhiên, điều này có thể do tác động của các tác vụ "Sinh vật sống" và "Không phải sinh vật sống"; do đó chúng tôi đã tiến hành một thí nghiệm tương tự trên G1, tạo ra bản đồ dữ liệu của chúng và phân cụm các tác vụ, mà không có bất kỳ tác vụ bổ sung nào.

--- TRANG 7 ---

Như được minh họa trong Hình 4c, ngay cả khi không có các tác vụ bổ sung, phương pháp của chúng tôi đã thực hiện cùng phân cụm hợp lý cho G1, nhóm sinh vật sống lại với nhau và những thứ không phải sinh vật sống lại với nhau. Ngoài ra, Hình 4d chứng minh việc phân cụm sử dụng ba cụm, cho thấy rằng cụm sinh vật sống được chia thành hai nhóm: cụm 1 và cụm 2. Cụm 1 chủ yếu chứa động vật bốn chân {mèo, chó, ngựa}, trong khi cụm 2 bao gồm {chim, ếch, hươu} đại diện cho các sinh vật sống khác ngoại trừ hươu. Những kết quả này thể hiện tính hiệu quả của thuật toán phân cụm của chúng tôi trong việc nắm bắt sự tương tự ngữ nghĩa, hình ảnh giữa các tác vụ dựa trên dữ liệu hình ảnh dẫn đến các nhóm tác vụ có ý nghĩa.

(a) G2: 2 cụm (b) G2: 3 cụm (c) G1: 2 cụm (d) G1: 3 cụm

Hình 4: Nhóm tác vụ của G1 & G2 với F = 2

Ngoài các thí nghiệm của chúng tôi trên G1 và G2, chúng tôi đã tiến hành đánh giá toàn diện về số lượng tác vụ chưa từng có, cụ thể là 100 tác vụ từ CIFAR100, trong G3. Như một phần của đánh giá này, chúng tôi đã so sánh kết quả phân cụm tác vụ của chúng tôi với các siêu lớp được định trước do CIFAR100 cung cấp. Quan trọng là phải lưu ý rằng các siêu lớp trong CIFAR100 chủ yếu dựa trên mối quan hệ ngữ nghĩa như được minh họa trong Phần 4.1, vì vậy chúng tôi hiển thị kết quả của con người và hoa, làm ví dụ.

Trong Hình 5, chúng tôi thể hiện một ví dụ về kết quả phân cụm cho một nhóm siêu tác vụ. Đáng chú ý rằng phương pháp của chúng tôi đã phân cụm thành công một số nhóm tác vụ phù hợp với các siêu lớp CIFAR100 được định trước, như được minh họa trong Hình 5a. Tuy nhiên, quan trọng là phải thừa nhận rằng có những trường hợp việc phân cụm có thể không hoàn hảo, như được mô tả trong Hình 5b; chúng tôi nghĩ rằng điều này chủ yếu là do phương pháp của chúng tôi tập trung vào sự tương tự hình ảnh, được khai thác trong quá trình huấn luyện thay vì ngữ nghĩa. Tuy nhiên, ngay cả trong những trường hợp như vậy, thuật toán phân cụm của chúng tôi vẫn quản lý để phân bổ trọng số đáng kể của tất cả các tác vụ vào các cụm khác biệt, chẳng hạn như cụm 0 và 8 trong Hình 5b.

--- TRANG 8 ---

(a) Phân cụm thành viên của siêu lớp Con người (b) Phân cụm thành viên của siêu lớp Hoa

Hình 5: Nhóm tác vụ của G3 (100 Tác vụ của CIFAR100) thành 20 cụm với F = 2

(a) Kết quả Huấn luyện (G1) (b) Kết quả Thử nghiệm (G1) (c) Kết quả Huấn luyện (G2) (d) Kết quả Thử nghiệm (G2)

(e) Kết quả Huấn luyện (G3) (f) Kết quả Thử nghiệm (G3) (g) Kết quả Huấn luyện (G4) (h) Kết quả Thử nghiệm (G4)

Hình 6: Điểm F1 Trung bình của tất cả các Nhóm trên cả tập huấn luyện và thử nghiệm

Đáng chú ý, trong cụm 8, tỷ lệ tham gia của các tác vụ {lan, thuý, hồng, tulip} là cao thứ 2 trên tất cả các cụm, cho thấy mối quan hệ chặt chẽ với tác vụ bị phân loại sai hướng dương, nhưng phương pháp của chúng tôi đề xuất rằng bốn tác vụ khác có liên quan hình ảnh hơn. Chúng tôi thảo luận thêm về tất cả kết quả phân cụm của 100 Tác vụ trong Phụ lục A cho RESNET18; chúng tôi cũng hiển thị kết quả phân cụm của mô hình CNN đơn giản hơn trong Phụ lục A.1, cho thấy tiềm năng có thể chuyển giao kết quả được tạo ra từ các mô hình đơn giản hơn sang các mô hình khác.

4.4 Phân tích Đánh giá

Để xác nhận thêm tính hiệu quả của phương pháp chúng tôi, chúng tôi đã tiến hành đánh giá toàn diện như được mô tả trong Phần 3.4 trên tất cả các nhóm tác vụ. Hình 6 trình bày điểm F1 trung bình cho cả tập huấn luyện và thử nghiệm của tất cả ba tập tác vụ; chúng tôi sử dụng F1 làm chỉ số đánh giá của chúng tôi vì nhiều tác vụ không cân bằng, vì vậy chúng tôi sử dụng điểm F1 để tuân thủ vấn đề như vậy. Phương pháp của chúng tôi được ký hiệu bởi STG-MTL xxC (F=2) trong đó xx đại diện cho số lượng cụm. Đường cong MTL biểu diễn kết quả thu được từ việc huấn luyện một mô hình MTL trên tất cả các tác vụ mà không có bất kỳ nhóm nào, trong khi đường cong STL biểu diễn kết quả thu được bằng cách huấn luyện các mô hình STL riêng biệt cho mỗi tác vụ và hợp nhất đầu ra của chúng. Chúng tôi

--- TRANG 9 ---

so sánh hiệu suất của phương pháp chúng tôi với các cách tiếp cận MTL và STL trong cả G1 & G2 và so sánh với cách tiếp cận MTL chỉ trong G3 & G4 vì hiệu suất STL kém hơn MTL, vì nó quá khớp.

Chúng tôi cũng trình bày các thí nghiệm bổ sung, hình 7 sử dụng một mô hình đơn giản hơn với số lượng tham số ít hơn nhiều, của một kiến trúc CNN tùy chỉnh được mô tả trong Bảng 2, trong Phụ lục A.1. Những thí nghiệm này chứng minh tính mạnh mẽ và khả năng thích ứng của phương pháp chúng tôi trên các kiến trúc mô hình khác nhau. Đáng chú ý rằng ngay cả với phân cụm cứng, phương pháp của chúng tôi vẫn vượt trội hơn MTL tiêu chuẩn, thể hiện tính hiệu quả trong việc tận dụng nhóm tác vụ để tăng cường hiệu suất như được hiển thị trong Hình 7e và 7g. Hơn nữa, kết quả thu được bằng cách sử dụng cách tiếp cận của chúng tôi với bản đồ dữ liệu được trích xuất từ mô hình MTL có thể so sánh với những kết quả từ các mô hình STL như trong Hình 7b và 7f.

(a) Kết quả MTL so với STG (G2) (b) So sánh Nguồn Bản đồ Dữ liệu (G2) (c) Kết hợp Khác nhau 2 cụm (G2) (d) Kết hợp Khác nhau 3 cụm (G2)

(e) Kết quả MTL so với STG so với STL (G3) (f) So sánh Nguồn Bản đồ Dữ liệu (G3) (g) Kết quả MTL so với STG so với STL (G1)

Hình 7: Đường cong điểm F1 trung bình trên tập thử nghiệm được tạo ra sử dụng CNN tùy chỉnh

Nhìn chung, phương pháp của chúng tôi liên tục vượt trội hơn cả các cách tiếp cận MTL và STL, cho thấy rằng việc nhóm tác vụ cung cấp thông tin có giá trị để cải thiện hiệu suất tác vụ. Đáng chú ý, mặc dù phương pháp của chúng tôi có xu hướng quá khớp, trong các thí nghiệm RESNET18, và đạt được hiệu suất huấn luyện xuất sắc, nó cũng đạt được hiệu suất tốt nhất trên tập thử nghiệm. Điều này cho thấy rằng nếu các mô hình được tinh chỉnh thêm, thậm chí có thể đạt được lợi ích lớn hơn, nhưng chúng tôi không tinh chỉnh bất kỳ mô hình nào trong nghiên cứu này để đảm bảo tính công bằng trong so sánh.

5 Kết luận và Công việc Tương lai

Kết luận, chúng tôi đã trình bày STG-MTL, một cách tiếp cận mới có thể mở rộng cho nhóm tác vụ trong cài đặt học đa tác vụ (MTL). Phương pháp của chúng tôi sử dụng bản đồ dữ liệu [33] để xác định sự tương tự tác vụ và nhóm chúng tương ứng. Chúng tôi đã thể hiện khả năng mở rộng vượt trội của nó về mặt lý thuyết so với TAG [9], HOA [30], và MTG-Net [29]. Chúng tôi cũng đã chứng minh tính hiệu quả của phương pháp chúng tôi thông qua các thí nghiệm trên bộ dữ liệu CIFAR10 & CIFAR100 [17] và CelebA [21], nơi chúng tôi đã đẩy ranh giới bằng cách thí nghiệm với 100 tác vụ, điều chưa từng được thực hiện trước đây trong tài liệu chứng minh khả năng mở rộng của nó. Chúng tôi cũng đã so sánh kết quả phân cụm của chúng tôi với các siêu lớp được định trước trong CIFAR100, xác nhận thêm tính hiệu quả của cách tiếp cận. Tuy nhiên, do khả năng tính toán hạn chế của chúng tôi và khả năng mở rộng kém của các phương pháp hiện tại, chúng tôi không thể đánh giá hiệu suất của kết quả chúng tôi so với các phương pháp khác. Thay vào đó, chúng tôi đã chỉ ra rằng phương pháp của chúng tôi vượt trội hơn cả các cách tiếp cận học đa tác vụ (MTL) và học đơn tác vụ (STL) truyền thống, thể hiện chất lượng của việc nhóm tác vụ và khả năng cải thiện hiệu suất học đa tác vụ.

Đối với công việc tương lai, chúng tôi nhằm khám phá khả năng tổng quát hóa của Bản Đồ Dữ Liệu sang các loại tác vụ khác, chẳng hạn như hồi quy, vì hiện tại chúng chỉ giới hạn trong các tác vụ phân loại. Ngoài ra, chúng tôi hy vọng nghiên cứu của chúng tôi có thể mở ra một hướng nghiên cứu mới trong cộng đồng MTL để khám phá việc phát triển các đặc trưng mới có thể nắm bắt động lực học huấn luyện một cách hiệu quả, ngoài bản đồ dữ liệu. Bằng cách tiến bộ hướng nghiên cứu này, chúng tôi có thể mở khóa những khả năng mới để tăng cường hiệu suất và thúc đẩy những tiến bộ hơn nữa trong lĩnh vực MTL.

--- TRANG 10 ---

Lời cảm ơn Chúng tôi cảm ơn chân thành Fatima Fellowship³ vì đã hỗ trợ nghiên cứu này đặc biệt trong giai đoạn đầu.

Tài liệu tham khảo
[1] V. Aribandi, Y. Tay, T. Schuster, J. Rao, H. S. Zheng, S. V. Mehta, H. Zhuang, V. Q. Tran, D. Bahri, J. Ni, et al. Ext5: Towards extreme multi-task scaling for transfer learning. In International Conference on Learning Representations, 2021.

[2] G. Bao, H. Chen, T. Liu, G. Gong, Y. Yin, L. Wang, and X. Wang. Covid-mtl: Multitask learning with shift3d and random-weighted loss for covid-19 diagnosis and severity assessment. Pattern Recognition, 124:108499, 2022.

[3] J. C. Bezdek, R. Ehrlich, and W. Full. Fcm: The fuzzy c-means clustering algorithm. Computers & geosciences, 10(2-3):191–203, 1984.

[4] S. Bickel, J. Bogojeska, T. Lengauer, and T. Scheffer. Multi-task learning for hiv therapy screening. In Proceedings of the 25th international conference on Machine learning, pages 56–63, 2008.

[5] R. Caruana. Multitask learning. Machine learning, 28:41–75, 1997.

[6] Z. Chen, Y. Shen, M. Ding, Z. Chen, H. Zhao, E. G. Learned-Miller, and C. Gan. Mod-squad: Designing mixtures of experts as modular multi-task learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11828–11837, 2023.

[7] M. Crawshaw. Multi-task learning with deep neural networks: A survey. arXiv preprint arXiv:2009.09796, 2020.

[8] J. Fan, T. Zhao, Z. Kuang, Y. Zheng, J. Zhang, J. Yu, and J. Peng. Hd-mtl: Hierarchical deep multi-task learning for large-scale visual recognition. IEEE transactions on image processing, 26(4):1923–1938, 2017.

[9] C. Fifty, E. Amid, Z. Zhao, T. Yu, R. Anil, and C. Finn. Efficiently identifying task groupings for multi-task learning. Advances in Neural Information Processing Systems, 34:27503–27516, 2021.

[10] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.

[11] H. Huang, D. Ye, L. Shen, and W. Liu. Curriculum-based asymmetric multi-task reinforcement learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.

[12] S. Huang, X. Li, Z.-Q. Cheng, Z. Zhang, and A. Hauptmann. Gnas: A greedy neural architecture search method for multi-attribute learning. In Proceedings of the 26th ACM international conference on Multimedia, pages 2049–2057, 2018.

[13] Z. Huang, M. Rao, A. Raju, Z. Zhang, B. Bui, and C. Lee. Mtl-slt: multi-task learning for spoken language tasks. In Proceedings of the 4th Workshop on NLP for Conversational AI, pages 120–130, 2022.

[14] G. Ilharco, M. T. Ribeiro, M. Wortsman, L. Schmidt, H. Hajishirzi, and A. Farhadi. Editing models with task arithmetic. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=6t0Kwf8-jrj.

[15] M. Islam, V. Vibashan, C. M. Lim, and H. Ren. St-mtl: Spatio-temporal multitask learning model to predict scanpath while tracking instruments in robotic surgery. Medical Image Analysis, 67:101837, 2021.

³https://www.fatimafellowship.com/

--- TRANG 11 ---

[16] N. Jin, J. Wu, X. Ma, K. Yan, and Y. Mo. Multi-task learning model based on multi-scale cnn and lstm for sentiment classification. IEEE Access, 8:77060–77072, 2020.

[17] A. Krizhevsky, G. Hinton, et al. Learning multiple layers of features from tiny images. 2009.

[18] G. Lee, E. Yang, and S. Hwang. Asymmetric multi-task learning based on task relatedness and loss. In International conference on machine learning, pages 230–238. PMLR, 2016.

[19] H. B. Lee, E. Yang, and S. J. Hwang. Deep asymmetric multi-task feature learning. In International Conference on Machine Learning, pages 2956–2964. PMLR, 2018.

[20] C. Liu, B. Zoph, M. Neumann, J. Shlens, W. Hua, L.-J. Li, L. Fei-Fei, A. Yuille, J. Huang, and K. Murphy. Progressive neural architecture search. In Proceedings of the European conference on computer vision (ECCV), pages 19–34, 2018.

[21] Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), December 2015.

[22] S. Lloyd. Least squares quantization in pcm. IEEE transactions on information theory, 28(2):129–137, 1982.

[23] M. Long, Z. Cao, J. Wang, and P. S. Yu. Learning multiple tasks with multilinear relationship networks. Advances in neural information processing systems, 30, 2017.

[24] K.-K. Maninis, I. Radosavovic, and I. Kokkinos. Attentive single-tasking of multiple tasks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1851–1860, 2019.

[25] I. Misra, A. Shrivastava, A. Gupta, and M. Hebert. Cross-stitch networks for multi-task learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3994–4003, 2016.

[26] Y. Peng, Q. Chen, and Z. Lu. An empirical study of multi-task learning on BERT for biomedical text mining. In D. Demner-Fushman, K. B. Cohen, S. Ananiadou, and J. Tsujii, editors, Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing, pages 205–214, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.bionlp-1.22. URL https://aclanthology.org/2020.bionlp-1.22.

[27] S. Ruder, J. Bingel, I. Augenstein, and A. Søgaard. Latent multi-task architecture learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 4822–4829, 2019.

[28] O. Sener and V. Koltun. Multi-task learning as multi-objective optimization. Advances in neural information processing systems, 31, 2018.

[29] X. Song, S. Zheng, W. Cao, J. Yu, and J. Bian. Efficient and effective multi-task grouping via meta learning on task combinations. In Advances in Neural Information Processing Systems, 2022.

[30] T. Standley, A. Zamir, D. Chen, L. Guibas, J. Malik, and S. Savarese. Which tasks should be learned together in multi-task learning? In International Conference on Machine Learning, pages 9120–9132. PMLR, 2020.

[31] G. Strezoski, N. van Noord, and M. Worring. Learning task relatedness in multi-task learning for images in context. In Proceedings of the 2019 on international conference on multimedia retrieval, pages 78–86, 2019.

[32] X. Sun, R. Panda, R. Feris, and K. Saenko. Adashare: Learning what to share for efficient deep multi-task learning. In H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 8728–8740. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/634841a6831464b64c072c8510c7f35c-Paper.pdf.

--- TRANG 12 ---

[33] S. Swayamdipta, R. Schwartz, N. Lourie, Y. Wang, H. Hajishirzi, N. A. Smith, and Y. Choi. Dataset cartography: Mapping and diagnosing datasets with training dynamics. In B. Webber, T. Cohn, Y. He, and Y. Liu, editors, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 9275–9293, Online, Nov. 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.746. URL https://aclanthology.org/2020.emnlp-main.746.

[34] S. Vandenhende, S. Georgoulis, B. De Brabandere, and L. Van Gool. Branched multi-task networks: Deciding what layers to share. 2019. URL https://openreview.net/forum?id=HJxhUpVKDr.

[35] S. Wu, H. R. Zhang, and C. Ré. Understanding and improving information transfer in multi-task learning. In International Conference on Learning Representations, 2019.

[36] C. Yu, Z. Gao, W. Zhang, G. Yang, S. Zhao, H. Zhang, Y. Zhang, and S. Li. Multitask learning for estimating multitype cardiac indices in mri and ct based on adversarial reverse mapping. IEEE Transactions on Neural Networks and Learning Systems, 32(2):493–506, 2021. doi: 10.1109/TNNLS.2020.2984955.

[37] C. Yu, H. Liu, and H. Zhang. Distilling sub-space structure across views for cardiac indices estimation. Medical Image Analysis, 85:102764, 2023. ISSN 1361-8415. doi: https://doi.org/10.1016/j.media.2023.102764. URL https://www.sciencedirect.com/science/article/pii/S1361841523000257.

[38] L. Zhang, X. Liu, and H. Guan. A tree-structured multi-task model recommender. In First Conference on Automated Machine Learning (Main Track), 2022. URL https://openreview.net/forum?id=BEl4CgaHLlc.

[39] Y. Zhang and Q. Yang. A survey on multi-task learning. IEEE Transactions on Knowledge and Data Engineering, 34(12):5586–5609, 2022. doi: 10.1109/TKDE.2021.3070203.

[40] Z. Zhang, B. Wu, and B. Schuller. Attention-augmented end-to-end multi-task learning for emotion prediction from speech. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6705–6709. IEEE, 2019.

[41] Z. Zhang, W. Yu, M. Yu, Z. Guo, and M. Jiang. A survey of multi-task learning in natural language processing: Regarding task relatedness and training methods. In A. Vlachos and I. Augenstein, editors, Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 943–956, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.eacl-main.66. URL https://aclanthology.org/2023.eacl-main.66.

--- TRANG 13 ---

(a) động vật có vú dưới nước (b) cá (c) hoa

(d) hộp đựng thực phẩm (e) trái cây và rau quả (f) thiết bị điện gia dụng

(g) đồ nội thất gia đình (h) côn trùng (i) động vật ăn thịt lớn

(j) vật thể lớn nhân tạo ngoài trời (k) cảnh quan tự nhiên lớn ngoài trời (l) động vật ăn tạp và ăn cỏ lớn

(m) động vật có vú cỡ trung bình (n) động vật không xương sống không phải côn trùng (o) con người

(p) bò sát (q) động vật có vú nhỏ (r) cây cối

(s) xe cộ 1 (t) xe cộ 2

Hình 8: Nhóm tác vụ của G3 (100 Tác vụ của CIFAR100) thành 20 cụm với F = 2 sử dụng Bản Đồ Dữ Liệu từ RESNET18

A Kết quả Phân cụm Tác vụ của 100 Tác vụ

Trong phụ lục này, chúng tôi trình bày hiểu biết chi tiết về kết quả phân cụm tác vụ của 100 tác vụ, dựa trên thiết lập thí nghiệm được nêu trong Phần 4.3. Hình 8 thể hiện kết quả phân cụm sử dụng 20 cụm, trong khi Hình 9 minh họa kết quả với 10 cụm. Mỗi hình ảnh trong các hình đại diện cho kết quả phân cụm cho một siêu lớp từ CIFAR100.

Đáng chú ý, việc phân cụm với 20 cụm thể hiện sự nhóm thành công trong nhiều danh mục, chẳng hạn như {Con người, Cây cối, Hộp đựng Thực phẩm, Hoa, Thiết bị Điện Gia dụng}. Hình 8s và 8t nhấn mạnh sự liên kết chặt chẽ giữa Xe cộ 1 và 2, vì chúng gần như được hợp nhất thành cùng một cụm (Cụm 15). Khi giảm số lượng cụm xuống 10, chúng tôi quan sát thấy sự mạch lạc được tăng cường trong các tác vụ được gán. Ví dụ, các tác vụ liên quan đến "Trái cây và Rau quả" gần như được phân cụm lại với nhau sau khi giảm số lượng cụm.

Hơn nữa, phương pháp của chúng tôi có hiệu quả nắm bắt các liên kết hợp lý giữa các danh mục. Hình 9f và 9g thể hiện sự hợp nhất hợp lý giữa "Thiết bị Điện Gia dụng" và "Đồ nội thất Gia đình". Ngoài ra, chúng tôi quan sát các mẫu phân phối tương tự giữa các danh mục liên quan, chẳng hạn như {Động vật Ăn thịt Lớn, Động vật Ăn tạp và Ăn cỏ Lớn, Động vật Có vú Cỡ Trung bình} tương ứng trong Hình 9i, 9l, và 9m.

Nhìn chung, những kết quả này cho thấy thành công định tính của cách tiếp cận của chúng tôi trong việc phân cụm số lượng rất lớn tác vụ, làm nổi bật tính hiệu quả của phương pháp chúng tôi ngay cả trong những tình huống thách thức như vậy.

--- TRANG 14 ---

(a) động vật có vú dưới nước (b) cá (c) hoa

(d) hộp đựng thực phẩm (e) trái cây và rau quả (f) thiết bị điện gia dụng

(g) đồ nội thất gia đình (h) côn trùng (i) động vật ăn thịt lớn

(j) vật thể lớn nhân tạo ngoài trời (k) cảnh quan tự nhiên lớn ngoài trời (l) động vật ăn tạp và ăn cỏ lớn

(m) động vật có vú cỡ trung bình (n) động vật không xương sống không phải côn trùng (o) con người

(p) bò sát (q) động vật có vú nhỏ (r) cây cối

(s) xe cộ 1 (t) xe cộ 2

Hình 9: Nhóm tác vụ của G3 (100 Tác vụ của CIFAR100) thành 10 cụm với F = 2 sử dụng Bản Đồ Dữ Liệu từ RESNET18

A.1 Phân cụm Mạnh mẽ sử dụng Kiến trúc Ít Phức tạp hơn

--- TRANG 15 ---

(a) động vật có vú dưới nước (b) cá (c) hoa

(d) hộp đựng thực phẩm (e) trái cây và rau quả (f) thiết bị điện gia dụng

(g) đồ nội thất gia đình (h) côn trùng (i) động vật ăn thịt lớn

(j) vật thể lớn nhân tạo ngoài trời (k) cảnh quan tự nhiên lớn ngoài trời (l) động vật ăn tạp và ăn cỏ lớn

(m) động vật có vú cỡ trung bình (n) động vật không xương sống không phải côn trùng (o) con người

(p) bò sát (q) động vật có vú nhỏ (r) cây cối

(s) xe cộ 1 (t) xe cộ 2

Hình 10: Nhóm tác vụ của G3 (100 Tác vụ của CIFAR100) thành 20 cụm với F = 2 sử dụng Bản Đồ Dữ Liệu từ CNN Tùy chỉnh

Bảng 2: Kiến trúc CNN tùy chỉnh được sử dụng trong các thí nghiệm của chúng tôi. n là số lượng tác vụ.

Lớp | Kích thước Kernel | Đầu ra
Convolution | 5×5 | 32 kênh
2D BN + ReLU
2D MaxPool | 2×2
Convolution | 3×3 | 64 kênh
2D BN + ReLU
Convolution | 3×3 | 64 kênh
2D BN + ReLU
2D MaxPool | 2×2
Flatten
FC | | 128
FC | | n

Để đánh giá tính mạnh mẽ và tiềm năng tổng quát hóa của cách tiếp cận, chúng tôi đã tiến hành thí nghiệm tương tự sử dụng kiến trúc CNN đơn giản hơn. Chi tiết kiến trúc được cung cấp trong Bảng 2, trong đó n = 100. Đáng chú ý, kiến trúc CNN được sử dụng để trích xuất bản đồ dữ liệu trong quá trình phân cụm của chúng tôi chỉ bao gồm 472.612 tham số có thể học. Ngược lại, kiến trúc ResNet18, từ đó chúng tôi ban đầu thu được kết quả phân cụm, bao gồm 11.227.712 tham số có thể học.

Hình 10 và 11 thể hiện kết quả phân cụm tác vụ thu được bằng cách sử dụng kiến trúc CNN đơn giản hóa. Đáng ngạc nhiên, các mẫu phân cụm kết quả từ CNN tùy chỉnh của chúng tôi có thể so sánh đáng kể với những kết quả đạt được với ResNet18. Quan sát này nhấn mạnh tính biểu cảm của phương pháp, vì nó có hiệu quả nắm bắt mối quan hệ tác vụ mà không cần số lượng cao tham số có thể học.

Phát hiện thú vị này mở ra khả năng ngoại suy kết quả phân cụm từ các mô hình ít biểu cảm hơn sang những mô hình phức tạp hơn. Tuy nhiên, cần có thêm các điều tra để xác định mức độ và tác động của cách tiếp cận này.

--- TRANG 16 ---

(a) động vật có vú dưới nước (b) cá (c) hoa

(d) hộp đựng thực phẩm (e) trái cây và rau quả (f) thiết bị điện gia dụng

(g) đồ nội thất gia đình (h) côn trùng (i) động vật ăn thịt lớn

(j) vật thể lớn nhân tạo ngoài trời (k) cảnh quan tự nhiên lớn ngoài trời (l) động vật ăn tạp và ăn cỏ lớn

(m) động vật có vú cỡ trung bình (n) động vật không xương sống không phải côn trùng (o) con người

(p) bò sát (q) động vật có vú nhỏ (r) cây cối

(s) xe cộ 1 (t) xe cộ 2

Hình 11: Nhóm tác vụ của G3 (100 Tác vụ của CIFAR100) thành 10 cụm với F = 2 sử dụng Bản Đồ Dữ Liệu từ CNN Tùy chỉnh

--- TRANG 17 ---

Huấn luyện viên
+ train
+ evaluate
+ evaluate_ensemble
+ get_data_map

torch.nn.Module
Mô hình Cơ sở
# _intialize_metrics_generator
+ get_task_output
+ get_probabilities_true_target
+ initialize_losses
+ forward

Ghi âm Bản đồ Dữ liệu Chỉ số Cơ sở
+ update
+ reset
+ get_data_map

Mô-đun Dữ liệu Cơ sở
# _initialize
+ get_train_dataloader
+ get_val_dataloader
+ get_test_dataloader

Bộ dữ liệu Cơ sở
- __len__
- __getitem__

torch.utils.data.Dataset

Mô-đun Dữ liệu C100 | Mô hình C100

Hình 12: Sơ đồ lớp UML của đường ống của chúng tôi

B Tính Mô-đun trong Cấu trúc Mã

Trong việc thiết kế phương pháp của chúng tôi, chúng tôi đã đặt trọng tâm đáng kể vào khả năng mở rộng và tính mô-đun. Đảm bảo khả năng mở rộng mà không yêu cầu sửa đổi đáng kể bất cứ khi nào kiến trúc mô hình hoặc tác vụ thay đổi, tính mô-đun mã, là rất quan trọng. Để đạt được điều này, chúng tôi đã thiết kế một đường ống mô-đun tạo điều kiện thích ứng dễ dàng với các tình huống khác nhau với các điều chỉnh tối thiểu. Sơ đồ lớp cho đường ống của chúng tôi được mô tả trong Hình 12.

Kiến trúc mã của chúng tôi bao gồm nhiều lớp, mỗi lớp có vai trò riêng biệt. Lớp chính chịu trách nhiệm huấn luyện các mô hình trên bộ dữ liệu là Huấn luyện viên. Đáng chú ý, Huấn luyện viên sử dụng một đối tượng từ lớp Ghi âm Bản đồ Dữ liệu, cập nhật và ghi lại bản đồ dữ liệu một cách linh hoạt sau mỗi lần lặp. Để tăng cường khả năng tái sử dụng, chúng tôi giới thiệu một lớp trừu tượng gọi là Mô hình Cơ sở, phục vụ như bản thiết kế cho tất cả các mô hình. Tương tự, Huấn luyện viên mong đợi một Mô-đun Dữ liệu Cơ sở làm đầu vào, một lớp trừu tượng bao gồm thông tin bộ dữ liệu và hướng dẫn xây dựng bộ tải dữ liệu.

Phân cụm Tác vụ Bản đồ Dữ liệu
+ cluster
+ plot_membership
+ get_task_membership

Loại Phân cụm

sklearn.cluster.KMeans

KMeans Mờ

Hình 13: Sơ đồ lớp UML của các lớp phân cụm tác vụ

Khi xử lý các tập hợp tác vụ mới, hai bước là cần thiết. Đầu tiên, chúng tôi kế thừa từ Mô hình Cơ sở, triển khai các phương thức trừu tượng của nó, được in nghiêng trong hình. Thứ hai, chúng tôi cung cấp các triển khai cụ thể cho các phương thức trừu tượng của Mô-đun Dữ liệu Cơ sở. Mã của chúng tôi chứa ví dụ về hai bước này cho các bộ dữ liệu khác nhau như CIFAR10, CIFAR100, và CelebA.

Để huấn luyện các mô hình và trích xuất bản đồ dữ liệu, chỉ cần một vài dòng mã, được minh họa trong Mã 1. Bản đồ dữ liệu kết quả từ việc huấn luyện mô hình MTL sau đó sẵn sàng để phân cụm bằng cách sử dụng lớp Phân cụm Tác vụ Bản đồ Dữ liệu của chúng tôi, được mô tả trong Hình 13, như được hiển thị trong Mã 2. Thiết kế này đơn giản hóa quá trình tích hợp cho các tác vụ, mô hình hoặc bộ dữ liệu mới, có hiệu quả tăng cường tính mô-đun tổng thể của đường ống và phương pháp của chúng tôi.

Mã 1: Bắt đầu huấn luyện và ghi lại bản đồ dữ liệu
# tạo một thể hiện của mô-đun dữ liệu
data_module = C100DataModule(...)
# Bây giờ khởi tạo một mô hình
model = C100Model(...)
# Cuối cùng, khởi tạo một đối tượng huấn luyện viên
trainer = Trainer(model, data_module, args=args, ...)
# bắt đầu huấn luyện
trainer.train()

Mã 2: Tạo thành viên tác vụ từ bản đồ dữ liệu

--- TRANG 18 ---

# Để thấy rõ hơn về thành viên tác vụ, chúng tôi thực hiện các bước dưới đây
# lấy bản đồ dữ liệu từ huấn luyện viên
dm_mtl = trainer.get_data_map()
# khởi tạo một ước lượng cụm
cluster_estimator = DatamapTaskClustering(dm_mtl, n_clusters, ...)
# lấy kết quả
mtl_task_weights = cluster_estimator.cluster(...)

--- TRANG 19 ---

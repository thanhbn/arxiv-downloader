# 2304.04959.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/multi-task/2304.04959.pdf
# Kích thước tệp: 1801804 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
AdaTT: Mạng Fusion Thích Ứng Từ Nhiệm Vụ Đến Nhiệm Vụ cho Học Đa Nhiệm Vụ trong Hệ Thống Gợi Ý
Danwei Li∗
lidli@meta.com
Meta AI
Menlo Park, California, USAZhengyu Zhang
zhengyuzhang@meta.com
Meta Platforms, Inc.
Menlo Park, California, USASiyang Yuan
syyuan@meta.com
Meta AI
Menlo Park, California, USA
Mingze Gao
gaomingze@meta.com
Meta Platforms, Inc.
Menlo Park, California, USAWeilin Zhang
weilinzzz@meta.com
Meta AI
Menlo Park, California, USAChaofei Yang
yangcf10@meta.com
Meta AI
Menlo Park, California, USA
Xi Liu
xliu1@meta.com
Meta AI
Menlo Park, California, USAJiyan Yang
chocjy@meta.com
Meta AI
Menlo Park, California, USA

TÓM TẮT
Học đa nhiệm vụ (MTL) nhằm nâng cao hiệu suất và hiệu quả của các mô hình học máy bằng cách đào tạo chúng đồng thời trên nhiều nhiệm vụ. Tuy nhiên, nghiên cứu MTL gặp phải hai thách thức: 1) mô hình hóa hiệu quả mối quan hệ giữa các nhiệm vụ để cho phép chia sẻ kiến thức, và 2) học đồng thời kiến thức cụ thể cho nhiệm vụ và kiến thức được chia sẻ. Trong bài báo này, chúng tôi trình bày một mô hình mới gọi là Mạng Fusion Thích Ứng Từ Nhiệm Vụ Đến Nhiệm Vụ (AdaTT)¹ để giải quyết cả hai thách thức. AdaTT là một mạng fusion sâu được xây dựng với các đơn vị fusion cụ thể cho nhiệm vụ và các đơn vị fusion được chia sẻ tùy chọn ở nhiều cấp độ. Bằng cách tận dụng cơ chế dư và cơ chế gating cho fusion từ nhiệm vụ đến nhiệm vụ, các đơn vị này thích ứng học cả kiến thức được chia sẻ và kiến thức cụ thể cho nhiệm vụ. Để đánh giá hiệu suất của AdaTT, chúng tôi tiến hành thí nghiệm trên một benchmark công khai và một tập dữ liệu gợi ý công nghiệp sử dụng các nhóm nhiệm vụ khác nhau. Kết quả cho thấy AdaTT vượt trội đáng kể so với các baseline hiện tại tiên tiến nhất. Hơn nữa, các thí nghiệm đầu cuối của chúng tôi cho thấy mô hình thể hiện hiệu suất tốt hơn so với các phương án thay thế.

CÁC KHÁI NIỆM CCS
•Phương pháp tính toán →Học đa nhiệm vụ ;•Hệ thống thông tin→Hệ thống gợi ý .

TỪ KHÓA
học đa nhiệm vụ; mạng nơ-ron; hệ thống gợi ý

∗Liên hệ với lidli@meta.com.
¹Mã nguồn có sẵn tại https://github.com/facebookresearch/AdaTT.

Quyền được cấp để tạo bản sao kỹ thuật số hoặc bản cứng của toàn bộ hoặc một phần công trình này cho việc sử dụng cá nhân hoặc trong lớp học mà không mất phí với điều kiện các bản sao không được tạo ra hoặc phân phối vì mục đích lợi nhuận hoặc lợi thế thương mại và các bản sao mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của các bên khác ngoài (các) tác giả phải được tôn trọng. Tóm tắt có ghi công được phép. Để sao chép khác, hoặc xuất bản lại, đăng trên máy chủ hoặc phân phối lại cho danh sách, cần có sự cho phép cụ thể trước và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.
KDD '23, Ngày 6–10 tháng 8, 2023, Long Beach, CA, USA
©2023 Bản quyền thuộc về chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM ISBN 979-8-4007-0103-0/23/08. . . $15.00
https://doi.org/10.1145/3580305.3599769

Định Dạng Tham Chiếu ACM:
Danwei Li, Zhengyu Zhang, Siyang Yuan, Mingze Gao, Weilin Zhang, Chaofei Yang, Xi Liu, và Jiyan Yang. 2023. AdaTT: Mạng Fusion Thích Ứng Từ Nhiệm Vụ Đến Nhiệm Vụ cho Học Đa Nhiệm Vụ trong Hệ Thống Gợi Ý. Trong Kỷ Yếu Hội Nghị ACM SIGKDD Lần Thứ 29 về Khám Phá Kiến Thức và Khai Thác Dữ Liệu (KDD '23), Ngày 6–10 tháng 8, 2023, Long Beach, CA, USA. ACM, New York, NY, USA, 10 trang. https://doi.org/10.1145/3580305.3599769

1 GIỚI THIỆU
Các hệ thống gợi ý trực tuyến nhằm tạo ra các gợi ý cá nhân hóa chất lượng cao cho người dùng. Hiệu quả của các hệ thống này thường phụ thuộc vào khả năng học chính xác sở thích của người dùng, điều này thường đòi hỏi tối ưu hóa nhiều mục tiêu đồng thời. Ví dụ, một hệ thống gợi ý video ngắn nên xem xét cả khả năng người dùng xem video và khả năng họ thích nó. Học đa nhiệm vụ (MTL) là một giải pháp điển hình cho những trường hợp sử dụng như vậy. Bằng cách đào tạo chung nhiều nhiệm vụ trong một khung duy nhất, MTL mang lại một số lợi ích. Thứ nhất, nó tăng hiệu quả tính toán, điều này quan trọng đối với các hệ thống gợi ý trực tuyến quy mô lớn. Ngoài ra, nó nâng cao hiệu suất mô hình thông qua regularization và chia sẻ kiến thức giữa các nhiệm vụ.

Tuy nhiên, MTL cũng đặt ra những thách thức độc đáo. Một trong những thách thức chính là mô hình hóa mối quan hệ giữa các nhiệm vụ. Vì mỗi nhiệm vụ có thể có mức độ tương quan khác nhau với các nhiệm vụ khác, việc chỉ mô hình hóa những điểm chung tổng quát được chia sẻ bởi tất cả các nhiệm vụ là không đủ. Độ phức tạp của vấn đề này tăng lên theo số lượng nhiệm vụ. Mô hình hóa hiệu quả mối quan hệ nhiệm vụ là chìa khóa để chia sẻ kiến thức thích ứng với nhiệm vụ hiệu quả. Ví dụ, kiến thức được chia sẻ cho nhiệm vụ "chia sẻ video" có thể được đánh trọng số cao trên các nhiệm vụ tương tự như "thích video", đồng thời cũng khai thác các khía cạnh khác nhau của kiến thức từ các nhiệm vụ khác có nhiều ví dụ phong phú, chẳng hạn như "xem video". Mặt khác, nó sẽ giảm thiểu việc học chia sẻ với các nhiệm vụ không liên quan cao. Các công trình trước đây [2,19] thường dựa vào các biểu diễn được chia sẻ tĩnh. Các công trình khác như mạng cross-stitch [24], được hiển thị trong Hình 2 (c), học các ma trận để mô hình hóa mối quan hệ giữa nhiều mạng con. Tuy nhiên, các trọng số vẫn cố định cho tất cả các ví dụ và các mạng con chỉ lỏng lẻo cụ thể cho nhiệm vụ. Các phương pháp gần đây như MMoE [22] được hiển thị trong Hình 2 (b) và PLE [29] được hiển thị trong Hình 2 (e) sử dụng các mạng gating chuyên biệt để kết hợp động các mô-đun con được chia sẻ cho việc chia sẻ linh hoạt, nhưng mối quan hệ giữa các nhiệm vụ được mô hình hóa bởi các phương pháp này là mờ ám và gián tiếp.

Ngoài việc học chia sẻ, việc học cụ thể cho nhiệm vụ là một phần không thể thiếu trong học đa nhiệm vụ. Việc đạt được sự cân bằng đúng đắn giữa hai điều này rất quan trọng để giải quyết xung đột nhiệm vụ và đạt được regularization giữa các nhiệm vụ. Một mặt, MTL có thể gặp phải chuyển giao tiêu cực, trong đó việc tối ưu hóa cho một nhiệm vụ ảnh hưởng tiêu cực đến hiệu suất của nhiệm vụ khác, đặc biệt khi các nhiệm vụ có mục tiêu xung đột. Trong những tình huống như vậy, các mô hình MTL nên nhấn mạnh thích ứng việc học cụ thể cho nhiệm vụ. Mặt khác, việc học cụ thể cho nhiệm vụ quá mức và chia sẻ không đủ có thể dẫn đến overfitting, làm giảm lợi ích của regularization giữa các nhiệm vụ. Số lượng và phân phối dữ liệu đào tạo cho mỗi nhiệm vụ cũng ảnh hưởng đến trọng tâm của việc học: các nhiệm vụ có nhiều dữ liệu hơn có thể dựa nhiều hơn vào việc học cụ thể của chúng, trong khi những nhiệm vụ có ít dữ liệu hơn hoặc dữ liệu rất lệch có thể tập trung nhiều hơn vào việc học chia sẻ. Việc tính đến sự khác biệt về ví dụ có thể làm cho sự cân bằng giữa hai loại này thậm chí còn động hơn. Do đó, điều quan trọng là tự động học cách cân bằng hai loại học này. Nhiều mô hình chia sẻ tham số mềm có thể thực hiện điều này mà không cần điều chỉnh thủ công tẻ nhạt [2] hoặc học các cấu trúc tĩnh cho tất cả các ví dụ với các giả định đơn giản hóa [23,28,30]. Tuy nhiên, cần có thêm nghiên cứu để hiểu cách mô hình hóa tương tác giữa việc học được chia sẻ và cụ thể cho nhiệm vụ để cải thiện hiệu suất.

Để cùng giải quyết những thách thức này, chúng tôi đề xuất một mô hình MTL mới, Mạng Fusion Thích Ứng Từ Nhiệm Vụ Đến Nhiệm Vụ (AdaTT). Để cải thiện việc học chia sẻ và khả năng diễn giải, chúng tôi đề xuất giới thiệu các expert cụ thể cho nhiệm vụ, expert được chia sẻ và các mô-đun gating để mô hình hóa tương tác từ nhiệm vụ đến nhiệm vụ một cách rõ ràng ở cả mức độ cặp nhiệm vụ và tất cả nhiệm vụ. Cho việc học cụ thể cho nhiệm vụ và học chia sẻ cộng sinh, chúng tôi phân biệt và mô hình hóa chúng trong các mô-đun fusion riêng biệt, với các expert và chiến lược fusion khác nhau được áp dụng trong mỗi mô-đun. Các kết quả được fusion sau đó được kết hợp bằng cơ chế dư [12]. Hơn nữa, chúng tôi sử dụng nhiều mức độ fusion, mỗi mức chuyên biệt cho chức năng khác nhau, để nâng cao hiệu suất học.

Để đánh giá hiệu suất của AdaTT, chúng tôi tiến hành thí nghiệm trên một hệ thống gợi ý video ngắn trong thế giới thực. Chúng tôi thay đổi các nhóm thí nghiệm để kiểm tra khả năng thích ứng của nó với các mối quan hệ nhiệm vụ khác nhau. Ngoài ra, chúng tôi sử dụng một benchmark công khai để chứng minh thêm khả năng tổng quát hóa của nó. Trong tất cả các thí nghiệm này, AdaTT liên tục vượt trội so với các mô hình baseline trên các tập dữ liệu và nhóm nhiệm vụ khác nhau.

Để đánh giá hiệu suất của AdaTT ở quy mô, chúng tôi tiến hành nghiên cứu về các siêu tham số của nó, đặc biệt tập trung vào số lượng mức độ fusion và expert. Ngoài ra, chúng tôi thiết kế một nghiên cứu ablation và một phân tích trực quan hóa để hiểu sâu hơn về cơ chế nội bộ của AdaTT. Nghiên cứu ablation xác nhận hiệu quả của thiết kế dư, với các mô-đun fusion được mô hình hóa riêng biệt, trong việc đạt được việc học cụ thể cho nhiệm vụ và chia sẻ bổ sung. Việc trực quan hóa trọng số expert ở các mức độ fusion sâu và nông cung cấp hiểu biết sâu hơn về các mẫu chia sẻ riêng biệt và có ý nghĩa được học trên các mức độ fusion, nhiệm vụ và nhóm nhiệm vụ khác nhau.

Tóm lại, những đóng góp của bài báo này như sau:
•Chúng tôi đề xuất một mô hình MTL mới, Mạng Fusion Thích Ứng Từ Nhiệm Vụ Đến Nhiệm Vụ (AdaTT), đồng thời đạt được chia sẻ kiến thức thích ứng từ nhiệm vụ đến nhiệm vụ và việc học cụ thể cho nhiệm vụ mạnh mẽ.
•Với thí nghiệm kỹ lưỡng trên dữ liệu benchmark thế giới thực và một hệ thống gợi ý video quy mô lớn, chúng tôi đánh giá hiệu quả của AdaTT so với các baseline khác nhau.
•Chúng tôi chứng minh khả năng diễn giải của mô hình bằng cách tiến hành nghiên cứu ablation trên các mô-đun fusion riêng lẻ của nó và điều tra hoạt động của các đơn vị fusion cho cả kiến thức nông và sâu.

2 CÔNG TRÌNH LIÊN QUAN
Học đa nhiệm vụ có ứng dụng rộng rãi trong nhiều lĩnh vực khác nhau, bao gồm thị giác máy tính [16,19,24,34], xử lý ngôn ngữ tự nhiên [5,11], nhận dạng giọng nói [6], robot học [32], và hệ thống gợi ý [10,22,29,35]. Nhiều nghiên cứu tập trung vào việc phát triển các kiến trúc MTL sáng tạo. Những mô hình này có thể được chia thành hai loại: chia sẻ tham số cứng và chia sẻ tham số mềm. Chia sẻ tham số cứng liên quan đến việc sử dụng một kiến trúc mô hình được xác định trước trong đó một số lớp được chia sẻ giữa tất cả các nhiệm vụ, trong khi các lớp khác cụ thể cho từng nhiệm vụ riêng lẻ. Mô hình shared-bottom [2] là một trong những mô hình được sử dụng rộng rãi nhất của phương pháp chia sẻ cứng. Mô hình sử dụng các lớp dưới được chia sẻ cho việc học biểu diễn và có các lớp cụ thể cho nhiệm vụ ở trên. Mạng Quan Hệ Đa Tuyến [20] cải thiện cấu trúc này bằng cách áp đặt các prior tensor bình thường trên các tham số của các lớp cụ thể cho nhiệm vụ. Một ví dụ khác là UberNet [16], giải quyết các nhiệm vụ thị giác đa dạng ở mức thấp, trung bình và cao một cách chung bằng cách sử dụng phương pháp kim tự tháp hình ảnh. Nó xử lý mỗi độ phân giải trong kim tự tháp với cả các lớp cụ thể cho nhiệm vụ và các lớp được chia sẻ. Các mô hình chia sẻ tham số cứng thường có cấu trúc gọn gàng, nhưng đòi hỏi nỗ lực thủ công đáng kể để xác định những gì cần chia sẻ và thiếu khả năng thích ứng. Ngoài ra, việc chia sẻ quá mức qua các nhiệm vụ không liên quan hoặc xung đột có thể dẫn đến chuyển giao tiêu cực, có thể ảnh hưởng tiêu cực đến hiệu suất mô hình.

Để giải quyết tốt hơn những thách thức này, nhiều mô hình MTL chia sẻ tham số mềm đã được đề xuất. Mạng cross-stitch [24] và mạng sluice [26] sử dụng các tham số có thể đào tạo để kết hợp tuyến tính đầu ra của mỗi lớp. Tuy nhiên, sự kết hợp tuyến tính mà chúng áp dụng là cố định và do đó không phản ánh đầy đủ sự phân biệt mối quan hệ nhiệm vụ trên các ví dụ riêng lẻ. Các công trình khác đã được đề xuất để sử dụng các mô-đun attention hoặc gating, được điều kiện hóa trên đầu vào, để kết hợp hoặc trích xuất kiến thức một cách động cho mỗi nhiệm vụ. Ví dụ, MTAN [19] sử dụng các mô-đun attention để tạo ra các mặt nạ theo từng phần tử trích xuất kiến thức cụ thể cho nhiệm vụ từ một biểu diễn được chia sẻ. MMoE [22] giới thiệu một hỗn hợp expert và sử dụng mạng gating để fusion chúng một cách động cho mỗi nhiệm vụ. Gần đây hơn, PLE [29] được đề xuất để nâng cao thêm tính linh hoạt của việc chia sẻ kiến thức. PLE giới thiệu rõ ràng các expert cụ thể cho nhiệm vụ kết hợp với các expert được chia sẻ. Hơn nữa, PLE đề xuất định tuyến tách biệt tiến bộ với các mô-đun gating để fusion kiến thức một cách có chọn lọc và động. Trong số các công trình này, PLE liên quan nhất đến công trình của chúng tôi. Khác biệt, công trình của chúng tôi giới thiệu hai loại mô-đun fusion bổ sung để mô hình hóa riêng biệt việc học cụ thể cho nhiệm vụ và học chia sẻ. Ngoài ra, ngoài việc giới thiệu rõ ràng các mô-đun được chia sẻ để học những điểm chung qua tất cả các nhiệm vụ, chúng tôi tận dụng fusion cặp nhiệm vụ trực tiếp, dựa trên đầu vào, để tối đa hóa tính linh hoạt của việc chia sẻ kiến thức.

Các phương pháp Tìm Kiếm Kiến Trúc Mạng Nơ-ron (NAS) [8,17,18,25,36] đã được áp dụng vào Học Đa Nhiệm Vụ (MTL) để tự động học cấu trúc mô hình. Mạng Đa Nhiệm Vụ Phân Nhánh [30] tạo ra một cấu trúc cây bằng cách phân cụm các nhiệm vụ dựa trên điểm số ái lực và gán các nhiệm vụ không tương đồng cho các nhánh khác nhau. [9] sử dụng lấy mẫu Gumbel-Softmax cho hoạt động phân nhánh thay vì điểm số ái lực được tính toán trước, cho phép đào tạo đầu cuối. Kỹ thuật Ordering Lớp Mềm [23] xác định những hạn chế của các phương pháp chia sẻ thứ tự cố định truyền thống trong các mô hình MTL và đề xuất học các tham số scaling cụ thể cho nhiệm vụ để cho phép thứ tự linh hoạt của các lớp được chia sẻ cho mỗi nhiệm vụ. AdaShare [28] học một chính sách cụ thể cho nhiệm vụ để chọn lớp nào sẽ thực thi cho mỗi nhiệm vụ cụ thể. Định Tuyến Mạng Con (SNR) [21] chia các lớp được chia sẻ thành các mạng con và học kết nối của chúng với các biến tiềm ẩn. Các phương pháp NAS loại bỏ một lượng đáng kể công việc thủ công và cải thiện tính linh hoạt của các mẫu chia sẻ trong các mô hình MTL. Tuy nhiên, vì việc tìm kiếm toàn diện tất cả các cấu hình mô hình có thể là phức tạp theo tổ hợp, các phương pháp này thường dựa vào các giả định đơn giản hóa như phân nhánh [9,30], định tuyến [21], thứ tự lớp [23], chọn lọc lớp [28], v.v. để hạn chế không gian tìm kiếm. Ngoài ra, các cấu trúc được tạo ra không điều chỉnh theo các ví dụ riêng lẻ.

Ngoài các công trình tập trung vào thiết kế kiến trúc MTL, một dòng công trình khác nhằm cải thiện tối ưu hóa MTL. Weighted dựa trên sự không chắc chắn [15] học trọng số của mỗi nhiệm vụ dựa trên sự không chắc chắn của nhiệm vụ. GradNorm [3] điều khiển độ lớn gradient của các nhiệm vụ khác nhau để cân bằng tỷ lệ đào tạo của chúng. GradDrop [4] chọn lọc xác suất một dấu hiệu và loại bỏ gradient của dấu hiệu đối diện. Phẫu thuật gradient (PCGrad) [33] chiếu gradient nhiệm vụ xung đột lên kế hoạch bình thường của nhau. RotoGrad [14] điều khiển cả độ lớn và hướng của gradient nhiệm vụ để giảm thiểu xung đột. [27] coi học đa nhiệm vụ như một vấn đề tối ưu hóa đa mục tiêu với mục tiêu tìm ra một giải pháp tối ưu Pareto. [31] giới thiệu các loss tự phụ trợ với các tháp nhỏ được tham số hóa dưới để cân bằng hiệu quả Pareto và tổng quát hóa giữa các nhiệm vụ. Mặc dù các phương pháp này có thể mang lại cải thiện, việc chỉ dựa vào chúng mà không có kiến trúc mô hình mạnh mẽ có thể hạn chế giới hạn trên của hiệu suất mô hình.

3 KIẾN TRÚC MÔ HÌNH
Để học các biểu diễn được chia sẻ thích ứng và nâng cao việc học cụ thể cho nhiệm vụ một cách chung, chúng tôi đề xuất một mô hình mới, Mạng Fusion Thích Ứng Từ Nhiệm Vụ Đến Nhiệm Vụ (AdaTT). AdaTT tận dụng cơ chế gating và dư để fusion các expert một cách thích ứng trong nhiều mức độ fusion. Xem xét một tình huống học đa nhiệm vụ với hai nhiệm vụ dự đoán. Chúng tôi minh họa kiến trúc của AdaTT trong Hình 1 sử dụng hai mức độ fusion. AdaTT bao gồm một mạng fusion đa cấp và các tháp nhiệm vụ. Các mạng fusion được xây dựng với các đơn vị fusion cụ thể cho nhiệm vụ và các đơn vị fusion được chia sẻ tùy chọn, trong khi các tháp nhiệm vụ được xây dựng trên đỉnh của mạng fusion và kết nối với các đơn vị cụ thể cho nhiệm vụ trong mức độ fusion cuối cùng. Khung của chúng tôi là tổng quát, hỗ trợ lựa chọn linh hoạt các mô-đun expert, mạng tháp nhiệm vụ, mô-đun gating, và số lượng expert và mức độ fusion có thể cấu hình. Trong các phần tiếp theo, chúng tôi sẽ trước tiên giới thiệu một trường hợp đặc biệt của AdaTT, được gọi là AdaTT-sp, chỉ sử dụng các đơn vị fusion cụ thể cho nhiệm vụ (như được mô tả trong Hình 1 (a)). Sau đó, chúng tôi sẽ mô tả thiết kế AdaTT tổng quát, như được hiển thị trong Hình 1 (b).

3.1 AdaTT-sp
Thiết kế chi tiết của AdaTT-sp được trình bày như sau. Cho đầu vào 𝑥 cho 𝑇 nhiệm vụ, dự đoán cho nhiệm vụ 𝑡 (𝑡=1,2,...,𝑇) được công thức hóa như:
𝑦𝑡=ℎ𝑡(𝑓𝐿𝑡(𝑥)), (1)
trong đó 𝐿 là số lượng mức độ fusion, ℎ𝑡 đại diện cho tháp nhiệm vụ của nhiệm vụ 𝑡, và 𝑓𝐿𝑡 biểu thị hàm để tạo ra đầu ra của đơn vị fusion nhiệm vụ 𝑡 ở mức độ fusion thứ 𝐿. Ở đây, 𝑓𝐿𝑡(𝑥) được tính toán bằng cách áp dụng (các) lớp fusion từ dưới lên trên sử dụng Phương trình 2 và 3:
𝑓01(𝑥)=𝑓02(𝑥)=···=𝑓0𝑇(𝑥)=𝑥 (2)
𝑓𝑙𝑡(𝑥)=𝐹𝑈𝑙𝑡(𝑓𝑙−11(𝑥),𝑓𝑙−12(𝑥),...,𝑓𝑙−1𝑇(𝑥)), 𝑙=1...𝐿 (3)
Ở đây, FU đại diện cho một đơn vị fusion.

3.1.1 Đơn vị Fusion. Dưới đây chúng tôi chi tiết việc xây dựng 𝐹𝑈𝑙𝑡 được giới thiệu trong Phương trình 3. Đối với nhiệm vụ 𝑡, sau khi nhận tất cả các đầu ra từ mức độ fusion trước, chúng tôi trước tiên xây dựng 𝑚𝑡 expert nguyên bản cho nhiệm vụ này, được ký hiệu bởi 𝐸𝑙𝑡,𝑖, sử dụng một hàm 𝑒𝑙𝑡,𝑖 và đầu vào 𝑓𝑙−1𝑡(𝑥). Tức là,
𝐸𝑙𝑡,𝑖=𝑒𝑙𝑡,𝑖(𝑓𝑙−1𝑡(𝑥)), (4)
trong đó 𝑖=1,2,...,𝑚𝑡 và 𝐸𝑙𝑡,𝑖∈R1×𝑑𝑙. Mỗi mạng expert ở mức độ 𝑙 tạo ra một vector có độ dài 𝑑𝑙. Để ký hiệu dễ dàng hơn, ở mức độ 𝑙, chúng tôi sử dụng 𝐸𝑙𝑡 và 𝐸𝑙 để biểu thị việc nối dọc của các expert thuộc về nhiệm vụ 𝑡 và tất cả expert qua các nhiệm vụ, tương ứng. Cụ thể, 𝐸𝑙𝑡 và 𝐸𝑙 được biểu diễn như:
𝐸𝑙𝑡=[𝐸𝑙𝑡,1,𝐸𝑙𝑡,2,...,𝐸𝑙𝑡,𝑚𝑡], (5)
𝐸𝑙=[𝐸𝑙1,𝐸𝑙2,...,𝐸𝑙𝑇], (6)
trong đó 𝐸𝑙𝑡∈R𝑚𝑡×𝑑𝑙 và 𝐸𝑙∈R(𝑚1+𝑚2+...+𝑚𝑇)×𝑑𝑙. Trong các phương trình trên, [,] đại diện cho phép toán xếp chồng dọc các vector hoặc ma trận con thành một ma trận lớn hơn.

Vì một nhiệm vụ có thể có mức độ tương quan khác nhau với các nhiệm vụ khác, 𝐹𝑈𝑙𝑡 mô hình hóa trực tiếp fusion kiến thức từ nhiệm vụ đến nhiệm vụ với một mô-đun gating 𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹𝑙𝑡 kết hợp tất cả expert của các nhiệm vụ 𝐸𝑙. Ngoài ra, chúng tôi tận dụng một kết hợp tuyến tính nhẹ 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹𝑙𝑡 để fusion các expert nguyên bản của nhiệm vụ 𝑡, 𝐸𝑙𝑡. Về mặt khái niệm, mô-đun gating mô hình hóa việc học chia sẻ và sự kết hợp tuyến tính của các expert nguyên bản mô hình hóa việc học cụ thể cho nhiệm vụ. Cụ thể, đầu ra của đơn vị cụ thể cho nhiệm vụ 𝑡 ở lớp 𝑙 được công thức hóa như:
𝑓𝑙𝑡(𝑥)=𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹𝑙𝑡(𝐸𝑙,𝐺𝑙𝑡)+𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹𝑙𝑡(𝐸𝑙𝑡),(7)
trong đó trọng số gate 𝐺𝑙𝑡 được sử dụng để kết hợp 𝐸𝑙. Tương đối với các biểu diễn trong Phương trình 3, 𝐸𝑙 phụ thuộc vào tất cả 𝑓𝑙−11(𝑥),𝑓𝑙−12(𝑥),...,𝑓𝑙−1𝑇(𝑥), trong khi 𝐺𝑙𝑡 và 𝐸𝑙𝑡 chỉ phụ thuộc vào 𝑓𝑙−1𝑡(𝑥).

Cụ thể, trong Phương trình 7, các expert được fusion như sau:
𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹𝑙𝑡(𝐸𝑙𝑡)=𝑣𝑙𝑡⊺𝐸𝑙𝑡, (8)
𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹𝑙𝑡(𝐸𝑙,𝐺𝑙𝑡)=𝐺𝑙𝑡⊺𝐸𝑙, (9)
trong đó 𝐸𝑙 được nhân với gates 𝐺𝑙𝑡∈R(𝑚1+𝑚2+...+𝑚𝑇)×1 được tạo ra bởi một hàm 𝑔𝑙𝑡 trong 𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹 trong khi 𝐸𝑙𝑡 được kết hợp đơn giản bởi một vector học được 𝑣𝑙𝑡∈R𝑚𝑡×1 trong 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹. Khi 𝑚1=𝑚2=...=𝑚𝑇=1, tức là tất cả các đơn vị fusion chỉ có một expert, 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹𝑙𝑡(𝐸𝑙𝑡) quay trở lại 𝐸𝑙𝑡, gán trọng số đơn vị cho expert nguyên bản để đơn giản. Có nhiều lựa chọn thiết kế cho 𝑔𝑙𝑡. Một cách phổ biến là sử dụng MLP một lớp được kích hoạt bởi softmax:
𝑔𝑙𝑡(𝑓𝑙−1𝑡(𝑥))=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊𝑙𝑡𝑓𝑙−1𝑡(𝑥)⊺). (10)
Ở đây, 𝑊𝑙𝑡∈R(𝑚1+𝑚2+...+𝑚𝑇)×𝑑𝑙−1 là một ma trận học được.

3.1.2 Đơn giản hóa. Để hiệu quả triển khai, cho Phương trình 8 và Phương trình 9, chúng ta thực sự có thể pad 𝑣𝑙𝑡⊺ với các số không để khớp với kích thước của 𝐺𝑙𝑡⊺, cộng các trọng số, và thực hiện một phép nhân duy nhất để kết hợp tất cả expert. Do đó, Phương trình 7 có thể được đơn giản hóa như:
𝑓𝑙𝑡(𝑥)=(𝑝𝑎𝑑(𝑣𝑙𝑡⊺)+𝐺𝑙𝑡⊺)𝐸𝑙. (11)
Như chúng ta có thể thấy, việc bao gồm mô-đun fusion tuyến tính dẫn đến sự gia tăng tối thiểu trong tính toán.

3.2 AdaTT Tổng Quát
Trong dạng tổng quát của nó, như được hiển thị trong Hình 1 (b), AdaTT sử dụng các đơn vị fusion được chia sẻ tùy chọn. Về mặt khái niệm, fusion giữa các cặp mô-đun cụ thể cho nhiệm vụ mô hình hóa việc chia sẻ chi tiết, trong khi fusion của các mô-đun cụ thể cho nhiệm vụ và được chia sẻ chuyển giao kiến thức rộng áp dụng cho tất cả các nhiệm vụ. Điều này dẫn đến việc chia sẻ kiến thức từ nhiệm vụ đến nhiệm vụ hiệu quả và linh hoạt. Việc tính toán của AdaTT tổng quát tương tự như AdaTT-sp, ngoại trừ mức độ fusion cuối cùng, nơi các đơn vị fusion được chia sẻ không thực hiện bất kỳ hoạt động fusion nào và chỉ tạo ra đầu ra expert cho các đơn vị fusion cụ thể cho nhiệm vụ xử lý.

Tóm lại, AdaTT học rõ ràng kiến thức cụ thể cho nhiệm vụ và fusion nó một cách thích ứng với kiến thức được chia sẻ. Fusion là thích ứng với nhiệm vụ như: 1. Các mô-đun gating học phần dư đối với các expert nguyên bản của nhiệm vụ. 2. Mỗi đơn vị cụ thể cho nhiệm vụ fusion expert sử dụng một mô-đun gating chuyên biệt được điều kiện hóa trên đầu vào (độc đáo bắt đầu từ mức độ fusion thứ hai). Bằng cách cho phép mỗi nhiệm vụ trực tiếp và linh hoạt học kiến thức được chia sẻ từ các nhiệm vụ khác, AdaTT mang lại tính linh hoạt lớn hơn so với PLE chỉ dựa vào (các) expert được chia sẻ như phương tiện. Ngoài ra, AdaTT có thể chọn chỉ sử dụng các expert cụ thể cho nhiệm vụ. Không giống như PLE, xử lý tất cả các expert được chọn trong một mô-đun gating duy nhất, AdaTT fusion riêng biệt các expert nguyên bản trong một mô-đun fusion tuyến tính khác nhau trong mỗi đơn vị fusion. Thiết kế này nâng cao tính mạnh mẽ của việc học cụ thể cho nhiệm vụ sau mỗi mức độ fusion. Mặc dù đơn giản, các thí nghiệm của chúng tôi tiết lộ rằng nó vượt trội so với PLE, áp dụng chọn lọc cho các expert trong các đơn vị fusion khác nhau và sử dụng các đường dẫn định tuyến khác nhau để phân biệt các expert này.

4 THÍ NGHIỆM
Trong phần này, chúng tôi trình bày kết quả thí nghiệm toàn diện để làm nổi bật hiệu quả của mô hình AdaTT được đề xuất và cung cấp hiểu biết tốt hơn về nó.

Phần này được chia thành bốn phần. Chúng tôi trước tiên mô tả ngắn gọn các mô hình baseline trong Phần 4.1. Thứ hai, chúng tôi đánh giá hiệu quả của AdaTT so với các mô hình học đa nhiệm vụ tiên tiến thông qua thí nghiệm trên các tập dữ liệu công nghiệp và công khai trong thế giới thực. Đối với tập dữ liệu công nghiệp, chúng tôi sử dụng ba nhóm khác nhau của các nhiệm vụ dự đoán để kiểm tra hiệu suất của các mô hình học đa nhiệm vụ này trong các tình huống khác nhau. Kết quả được chia sẻ trong Phần 4.2 và Phần 4.3. Tiếp theo, chúng tôi trình bày các nghiên cứu thành phần riêng lẻ trong Phần 4.4 và Phần 4.5. Chúng tôi ablate mô-đun 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹 để xác nhận tầm quan trọng của thiết kế dư của AdaTT kết hợp các mô-đun riêng biệt để fusion các expert khác nhau. Chúng tôi cũng trực quan hóa các trọng số expert học được trong mỗi đơn vị cụ thể cho nhiệm vụ để chứng minh cách AdaTT học các tương tác thích hợp giữa các nhiệm vụ, điều này rất cần thiết cho việc chia sẻ kiến thức hiệu quả. Cuối cùng, trong Phần 4.6, chúng tôi tiến hành nghiên cứu về các siêu tham số của AdaTT để hiểu mối quan hệ giữa số lượng mức độ fusion và expert, và hiệu suất của AdaTT.

4.1 Các Mô Hình Baseline
Chúng tôi sử dụng Shared-bottom, MMoE, Multi-level MMoE (một phần mở rộng của MMoE một cấp độ gốc), PLE, và Cross-stitch Networks như các baseline của chúng tôi. Trong số các mô hình này, MMoE, PLE, và Cross-stitch Networks đều sử dụng kỹ thuật chia sẻ tham số mềm.

•MMoE [22]: Mô hình này học một mô-đun gating chuyên biệt cho mỗi nhiệm vụ để fusion nhiều expert được chia sẻ. Cho 𝑛 mô-đun expert 𝑒1,𝑒2,...,𝑒𝑛, mô-đun tháp nhiệm vụ 𝑡 ℎ𝑡 và mô-đun gating 𝑔𝑡, dự đoán của nhiệm vụ 𝑡 được tính toán như:
𝑦𝑡=ℎ𝑡(𝑓𝑡(𝑥)), (12)
trong đó
𝑓𝑡(𝑥)=𝑔𝑡(𝑥)[𝑒1(𝑥),𝑒2(𝑥),...,𝑒𝑛(𝑥)]. (13)
Ở đây, [,] đại diện cho việc xếp chồng dọc các vector thành một ma trận.
•Multi-level MMoE (ML-MMoE): Mô hình này mở rộng MMoE một cấp độ gốc bằng cách kết hợp nhiều mức độ fusion. Trong ML-MMoE, các expert cấp cao hơn sử dụng các expert cấp thấp hơn được fusion bởi các mô-đun gating khác nhau làm đầu vào. Tương tự như MMoE gốc, tất cả các mô-đun gating được điều kiện hóa trên cùng một đầu vào thô.
•Cross-Stitch [24]: Mô hình này giới thiệu các đơn vị cross-stitch để kết hợp tuyến tính các lớp ẩn của các nhiệm vụ khác nhau với trọng số học được.
•PLE [29]: Mô hình này giới thiệu rõ ràng cả expert cụ thể cho nhiệm vụ và expert được chia sẻ với chiến lược định tuyến tách biệt tiến bộ. Các mô-đun gating được sử dụng để fusion các expert được chọn trong cả đơn vị cụ thể cho nhiệm vụ và được chia sẻ. Trong PLE, các đơn vị được chia sẻ có thể fusion tất cả expert ở cùng một mức độ, trong khi các đơn vị cụ thể cho nhiệm vụ chỉ fusion các expert nguyên bản của chúng và các expert được chia sẻ. Mô hình này gần nhất với AdaTT.

Tất cả các mô hình được thảo luận ở trên được hiển thị trong Hình 2 để so sánh.

4.2 Đánh Giá trên Gợi Ý Video Ngắn Quy Mô Lớn
Trong phần này, chúng tôi trình bày kết quả thí nghiệm trên một hệ thống gợi ý video ngắn. Hệ thống hiển thị danh sách các video được gợi ý được xếp hạng dựa trên điểm số từ các nhiệm vụ khác nhau. Các nhiệm vụ này có thể được phân loại rộng rãi thành hai loại: nhiệm vụ tương tác, tính đến phản hồi rõ ràng của người dùng, chẳng hạn như bình luận về video, và nhiệm vụ tiêu dùng, phản ánh phản hồi ngầm của người dùng, chẳng hạn như lượt xem video.

4.2.1 Nhóm nhiệm vụ. Chúng tôi tạo ra ba nhóm nhiệm vụ để đánh giá kỹ lưỡng hiệu suất của các mô hình này trong các mối quan hệ nhiệm vụ khác nhau.
•Nhóm đầu tiên bao gồm một nhiệm vụ tương tác và một nhiệm vụ tiêu dùng, được kỳ vọng có tương quan tương đối thấp.
•Nhóm hai bao gồm hai nhiệm vụ tiêu dùng có tương quan cao hơn. Nhiệm vụ đầu tiên giống như nhiệm vụ tiêu dùng trong nhóm một. Nhiệm vụ thứ hai được chọn để có tỷ lệ sự kiện tích cực có thể so sánh với nhiệm vụ tương tác trong nhóm một. Cả nhóm 1 và nhóm 2 đều chỉ bao gồm các nhiệm vụ phân loại nhị phân.
•Trong nhóm thứ ba, chúng tôi tăng số lượng nhiệm vụ lên năm và chọn các nhiệm vụ rất đa dạng. Trong số này, ba là nhiệm vụ tiêu dùng, và hai là nhiệm vụ tương tác. Một trong các nhiệm vụ tiêu dùng là nhiệm vụ hồi quy, và bốn nhiệm vụ còn lại là nhiệm vụ phân loại nhị phân. Về mặt cảm xúc người dùng, chúng tôi bao gồm một nhiệm vụ phản ánh sự không thích của người dùng và bốn nhiệm vụ cho các sự kiện tích cực. Một trong các nhiệm vụ tương tác với các sự kiện tích cực cực kỳ thưa thớt được sử dụng như một nhiệm vụ phụ trợ.

Khi báo cáo kết quả cho tất cả các nhóm nhiệm vụ, chúng tôi trình bày nhiệm vụ hồi quy trước (nếu có), theo sau là các nhiệm vụ phân loại theo thứ tự giảm dần tỷ lệ ví dụ tích cực.

4.2.2 Thiết lập thí nghiệm. Chúng tôi thu thập một tập dữ liệu khoảng 70 tỷ ví dụ để đào tạo các mô hình và kiểm tra hiệu suất của chúng trên một tập kiểm tra khoảng 10 tỷ ví dụ. Trong xử lý đặc trưng, chúng tôi chuyển đổi tất cả các đặc trưng thưa thớt thành embedding dày đặc và nối chúng với các đặc trưng dày đặc. Tất cả các nhiệm vụ sử dụng cùng một đầu vào. Tất cả các mô hình được đào tạo và kiểm tra sử dụng cùng một khung, với cùng các cài đặt tối ưu hóa như optimizer, tỷ lệ học, và kích thước batch. Để đào tạo, chúng tôi sử dụng loss Cross Entropy cho các nhiệm vụ phân loại nhị phân và loss MSE cho nhiệm vụ hồi quy. Các loss cho tất cả các nhiệm vụ được tổng hợp và tối ưu hóa với trọng số bằng nhau. Để kiểm tra, chúng tôi sử dụng Normalized Entropy (NE) [13] cho các nhiệm vụ phân loại nhị phân và MSE cho nhiệm vụ hồi quy.

4.2.3 Siêu tham số Mô hình. Trong các thí nghiệm của chúng tôi, tất cả các mô hình có 3 lớp ẩn được kích hoạt bởi ReLU. Đối với mỗi nhóm thí nghiệm, chúng tôi tiến hành hai so sánh.

Đầu tiên, chúng tôi so sánh MMoE, PLE, và AdaTT với mô hình shared-bottom. Để so sánh công bằng, PLE, ML-MMoE, và AdaTT đều có 2 mức độ fusion. Chúng tôi sử dụng các expert MLP một lớp với kích thước ẩn 256 và 128 cho 2 mức độ fusion này tương ứng. MMoE được xây dựng với các expert MLP 2 lớp với kích thước ẩn [256, 128]. Chúng tôi cũng đặt giới hạn về tổng số expert mỗi mức độ fusion. Tất cả các mô-đun gating trong các mô hình này sử dụng MLP 1 lớp với kích hoạt softmax. Đáng chú ý rằng tính toán cần thiết cho các mô-đun gating nhẹ hơn đáng kể so với các mô-đun expert. Mặc dù cả hai loại mô-đun chia sẻ cùng một kích thước đầu vào, các mô-đun gating có tổng kích thước đầu ra gần như nhỏ hơn hai bậc độ lớn. Các tháp nhiệm vụ của tất cả các mô hình có một lớp ẩn duy nhất với 64 đơn vị. Với thiết lập này, tất cả các mô hình có tính toán có thể so sánh vì các tháp nhiệm vụ và mô-đun expert thống trị tính toán. Trong các thí nghiệm của chúng tôi, chúng tôi điều chỉnh số lượng expert cụ thể cho nhiệm vụ và được chia sẻ cho PLE và AdaTT, trong khi đối với MMoE, chúng tôi điều chỉnh tổng số expert.

Trong một thí nghiệm riêng biệt, chúng tôi so sánh hiệu suất của AdaTT và mô hình cross-stitch với mô hình shared-bottom. AdaTT sử dụng siêu tham số tương tự như trong thí nghiệm trước nhưng với 1 expert mỗi nhiệm vụ và không có expert được chia sẻ để có thể so sánh với mô hình cross-stitch. Mô hình cross-stitch có 2 đơn vị cross-stitch và cùng các lớp ẩn như AdaTT.

4.2.4 Thí nghiệm trên nhóm nhiệm vụ tương tác và tiêu dùng. Đối với nhóm nhiệm vụ này, chúng tôi trình bày kết quả của sự khác biệt NE cho mỗi mô hình tương đối với mô hình shared-bottom, sau khi đào tạo trên 10 tỷ, 30 tỷ, và 70 tỷ ví dụ. Chúng tôi cũng cung cấp kết quả kiểm tra. Bảng 1 và 2 hiển thị kết quả cho các nhiệm vụ tiêu dùng và tương tác tương ứng. Kết quả cho thấy AdaTT vượt trội so với tất cả các mô hình khác trong cả hai nhiệm vụ, đạt được không chỉ hội tụ nhanh hơn mà còn chất lượng cao hơn. Sau khi đào tạo trên 10 tỷ ví dụ, hai mô hình AdaTT đã thể hiện cải thiện NE đáng kể cho cả hai nhiệm vụ. Về các mô hình baseline, PLE mất nhiều thời gian hơn để hội tụ trên nhiệm vụ tiêu dùng. Mô hình cross-stitch, mặt khác, bị AdaTT vượt trội với biên độ lớn, chứng minh tầm quan trọng sống còn của fusion thích ứng trong mô hình hóa mối quan hệ nhiệm vụ. Đáng chú ý, PLE và AdaTT cho thấy cải thiện lớn hơn trên nhiệm vụ tương tác, có ít sự kiện tích cực hơn, so với nhiệm vụ tiêu dùng. Tuy nhiên, xu hướng này không rõ ràng trong MMoE và ML-MMoE, điều này làm nổi bật tầm quan trọng của việc học cụ thể cho nhiệm vụ. Thú vị, mặc dù có nhiều tính linh hoạt hơn thông qua các hoạt động fusion bổ sung, ML-MMoE hoạt động tệ hơn MMoE trong cả hai nhiệm vụ, cho thấy hiệu suất kém hơn của nó trong fusion expert. Điều này có thể do thiếu sự phân biệt và kiến thức tiền nghiệm được áp đặt trong thiết kế của ML-MMoE. Các expert được chia sẻ có tính đối xứng cao, tất cả đều được sử dụng bởi mỗi mô-đun gating, và không có expert cụ thể cho nhiệm vụ được mô hình hóa rõ ràng. Ngoài ra, tất cả các mô-đun gating nhận cùng một đầu vào thô. Sự gia tăng trong các mức độ fusion dẫn đến nhiều tuyến đường hơn, làm cho việc học các kết hợp trọng số khác nhau cho dự đoán mỗi nhiệm vụ cụ thể trở nên khó khăn hơn đối với ML-MMoE.

4.2.5 Thí nghiệm trên nhóm nhiệm vụ của hai nhiệm vụ tiêu dùng. Vì hiệu suất của các mô hình MTL có thể nhạy cảm với tương quan nhiệm vụ, chúng tôi thiết kế một nhóm thí nghiệm để đánh giá hiệu suất của chúng trên hai nhiệm vụ tiêu dùng liên quan trái ngược với nhóm nhiệm vụ 1, nơi tương quan giữa các nhiệm vụ thấp hơn. Kết quả, như được hiển thị trong Bảng 3, cho thấy tất cả các mô hình trong nhóm này có cải thiện tương tự hơn trên cả hai nhiệm vụ so với baseline. Điều này không đáng ngạc nhiên, vì khi các nhiệm vụ liên quan chặt chẽ hơn, chuyển giao tiêu cực ít nghiêm trọng hơn, và cả hai nhiệm vụ đều hưởng lợi từ mức độ cao hơn của kiến thức được chia sẻ. Ngay cả các mô hình MTL với cơ chế chia sẻ đơn giản hơn cũng có thể đạt được hiệu suất tốt, dẫn đến sự khác biệt ít nổi bật hơn trong NE. Tuy nhiên, AdaTT vẫn cho thấy kết quả tốt nhất trong tất cả các mô hình MTL.

4.2.6 Thí nghiệm trên năm nhiệm vụ đa dạng. Trong nhóm nhiệm vụ này, chúng tôi đánh giá khả năng của các mô hình trong việc xử lý các mối quan hệ nhiệm vụ phức tạp bằng cách sử dụng 5 nhiệm vụ rất đa dạng. Chúng tôi điều chỉnh các mô hình cho 4 nhiệm vụ chính và trình bày kết quả trong Bảng 4. Chúng tôi không bao gồm nhiệm vụ phụ trợ với các sự kiện tích cực thưa thớt do mức độ nhiễu cao và hiệu suất không nhất quán của nó. Kết quả cho thấy AdaTT vượt trội so với tất cả các mô hình so sánh với biên độ đáng kể trong tất cả các nhiệm vụ chính, cho thấy sự vượt trội của nó trong việc xử lý các mối quan hệ nhiệm vụ phức tạp.

4.3 Đánh Giá trên Tập Dữ Liệu Công Khai
4.3.1 Mô tả tập dữ liệu. Chúng tôi sử dụng tập dữ liệu Census Income [7] được trích xuất từ các cuộc khảo sát dân số hiện tại năm 1994 và 1995. Tập dữ liệu có 40 đặc trưng và 299,285 thể hiện, bao gồm 199,523 ví dụ đào tạo và 99,762 ví dụ kiểm tra. Chúng tôi phân chia ngẫu nhiên các ví dụ kiểm tra thành tập xác thực và tập kiểm tra với tỷ lệ bằng nhau. Các nhiệm vụ là: 1) dự đoán liệu thu nhập có vượt quá 50K hay không; 2) dự đoán liệu tình trạng hôn nhân có phải là chưa bao giờ kết hôn hay không; 3) dự đoán liệu trình độ học vấn có ít nhất là đại học hay không.

4.3.2 Siêu tham số mô hình. Thí nghiệm này sử dụng một khung, được điều chỉnh từ [1], để đào tạo và kiểm tra ML-MMoE, PLE và AdaTT. Cấu trúc mô hình tương tự như trong Phần 4.2.3, nhưng kích thước ẩn và số lượng expert được thay đổi. Các thí nghiệm được tiến hành trong hai nhóm với 6 và 9 expert mỗi mức độ fusion, tương ứng. 𝑚𝑠, số lượng expert được chia sẻ cho PLE và AdaTT, được điều chỉnh. Số lượng expert cụ thể cho nhiệm vụ được tính như 6−𝑚𝑠 và 9−𝑚𝑠. Để đảm bảo công bằng, tất cả các siêu tham số khác được giữ bằng nhau qua các mô hình. Sau khi điều chỉnh 𝑚𝑠, mỗi mô hình được đào tạo 100 lần với các khởi tạo khác nhau, và AUC trung bình trong tập kiểm tra được báo cáo.

4.3.3 kết quả. Kết quả được trình bày trong Bảng 5. AdaTT vượt trội so với các mô hình baseline trong tất cả các nhiệm vụ.

4.4 Nghiên Cứu Ablation của Mô-đun 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹
Trong phần này, chúng tôi kiểm tra hiệu ứng của cơ chế dư với mô-đun 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹 trong các đơn vị fusion. Chúng tôi ablate mô-đun 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹 và chỉ sử dụng mô-đun 𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹 để kết hợp đầu ra của tất cả expert tại mỗi đơn vị fusion. Chúng tôi áp dụng cấu trúc mô hình tương tự như trong Phần 4.2.3, và sử dụng số lượng cố định ba expert mỗi nhiệm vụ và không có expert được chia sẻ. Cả hai mô hình được đào tạo trên 70 tỷ ví dụ và kiểm tra trên 10 tỷ ví dụ. Kết quả được hiển thị trong Bảng 6.

Mặc dù mô-đun 𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹 về mặt lý thuyết có thể học các kết hợp expert linh hoạt, thí nghiệm của chúng tôi vẫn cho thấy việc kết hợp riêng biệt các expert nguyên bản và thêm đầu ra của 𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹 như một dư là quan trọng. Cụ thể, việc ablate mô-đun 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹 sẽ gây ra mất mát trên tất cả các nhiệm vụ, với tăng 0.107%-0.222% trong NE cho các nhiệm vụ phân loại và tăng 0.158% trong MSE cho nhiệm vụ hồi quy.

4.5 Trực Quan Hóa Phân Phối Trọng Số Expert của Mô-đun Gating
Trong Hình 3, chúng tôi trực quan hóa phân phối trọng số expert sau khi cộng trọng số từ cả mô-đun 𝑁𝑎𝑡𝑖𝑣𝑒𝐸𝑥𝑝𝑒𝑟𝑡𝐿𝐹 và 𝐴𝑙𝑙𝐸𝑥𝑝𝑒𝑟𝑡𝐺𝐹 để điều tra cơ chế fusion nội bộ của AdaTT. Để đánh giá việc sử dụng expert, chúng tôi chọn ba nhiệm vụ: hai nhiệm vụ tiêu dùng và một nhiệm vụ tương tác. Cụ thể, chúng tôi chọn một nhiệm vụ hồi quy trong các nhiệm vụ tiêu dùng và hai nhiệm vụ phân loại với tỷ lệ sự kiện tích cực cao nhất trong các nhiệm vụ tương tác và tiêu dùng. Chúng tôi triển khai hai mức độ fusion, mỗi mức với một expert mỗi nhiệm vụ và không có expert được chia sẻ. Các expert là MLP một lớp với kích thước ẩn 256 và 128 trong hai mức độ fusion, tương ứng. Sau khi đào tạo mô hình, chúng tôi áp dụng nó vào tập dữ liệu kiểm tra, tính toán trọng số trung bình qua tất cả các ví dụ kiểm tra, và trực quan hóa một ma trận trọng số 3x3 cho mỗi mức độ fusion. Có một số quan sát đáng chú ý:

Đầu tiên, ở mức độ fusion thấp hơn (cấp 0), mô hình của chúng tôi có thể phân biệt mối quan hệ giữa các nhiệm vụ. Có một sự phân biệt rõ ràng giữa các nhóm nhiệm vụ tiêu dùng và tương tác. Ngoài ra, có một mẫu chia sẻ bất đối xứng giữa hai nhiệm vụ tiêu dùng: nhiệm vụ phân loại tiêu dùng chủ yếu sử dụng expert 2 và nhiệm vụ hồi quy phân loại tiêu dùng sử dụng expert 1 và 2 gần như bằng nhau.

Ở mức độ fusion cao hơn (cấp 1), nơi giám sát gần hơn và thông tin ngữ nghĩa phong phú được nắm bắt, mô hình của chúng tôi chứng minh lợi thế của việc chia sẻ tham số mềm thông qua một mẫu được chia sẻ qua các nhiệm vụ. Trong khi các expert nguyên bản đóng vai trò quan trọng cho việc học cụ thể cho nhiệm vụ, tất cả expert được sử dụng linh hoạt, góp phần vào việc học chia sẻ. Ở mức độ này, nhiệm vụ phân loại tiêu dùng nhằm đa dạng hóa việc học bằng cách sử dụng expert 3, cụ thể cho nhiệm vụ phân loại tương tác, cũng như expert 1, cụ thể cho nhiệm vụ hồi quy tiêu dùng. Trong khi đó, nhiệm vụ tương tác có ít tín hiệu tích cực hơn hưởng lợi từ chuyển giao kiến thức từ cả hai nhiệm vụ tiêu dùng. Ngược lại, nhiệm vụ hồi quy tiêu dùng chủ yếu dựa vào expert nguyên bản 1 của nó và expert cụ thể cho nhiệm vụ tiêu dùng khác. Trong tất cả các expert, expert 1, có việc học đa dạng nhất từ một hỗn hợp expert 1 và 2 từ cấp 0, được đánh trọng số mạnh qua tất cả các nhiệm vụ.

Nói chung, chúng ta có thể thấy chuyên môn hóa rõ ràng, nơi các mẫu phân phối trọng số riêng biệt được học tại mỗi nhiệm vụ, nhóm nhiệm vụ, và mức độ fusion.

4.6 Nghiên Cứu Siêu Tham Số
Chúng tôi tiến hành nghiên cứu siêu tham số để điều tra tác động của số lượng expert và số lượng mức độ fusion. Cả hai nghiên cứu sử dụng 5 nhiệm vụ dự đoán tương tự như Phần 4.2.6, với 70 tỷ ví dụ để đào tạo và 10 tỷ ví dụ để kiểm tra. Trong cả hai nghiên cứu, chúng tôi sử dụng AdaTT-sp làm mô hình.

4.6.1 Hiệu ứng của số lượng expert cụ thể cho nhiệm vụ. Để kiểm tra hiệu ứng của số lượng expert cụ thể cho nhiệm vụ, chúng tôi giữ số lượng expert cụ thể cho nhiệm vụ nhất quán qua tất cả các nhiệm vụ để đơn giản và thay đổi nó giữa 1 và 4. Các expert này được xây dựng sử dụng MLP một lớp với kích thước ẩn 256 và 128 qua hai mức độ fusion. Kết quả của phân tích này có thể được tìm thấy trong Bảng 7. Chúng tôi có thể quan sát rằng tất cả các nhiệm vụ có hiệu suất cải thiện, khi số lượng expert tăng lên. Tuy nhiên, các cải thiện không nhất quán: trong nghiên cứu này, khi số lượng expert tăng lên 2, nhiệm vụ tương tác chỉ thể hiện cải thiện nhỏ trong NE so với các nhiệm vụ tiêu dùng. Tuy nhiên, khi số lượng expert tăng thêm lên 3 và 4, xu hướng đảo ngược, và nhiệm vụ tương tác chứng minh sự khác biệt đáng chú ý hơn trong các chỉ số.

4.6.2 Hiệu ứng của mức độ fusion. Chúng tôi cũng kiểm tra các cấu hình khác nhau của mức độ fusion bằng cách sử dụng một expert duy nhất mỗi nhiệm vụ. Chúng tôi tăng dần số lượng mức độ fusion và sử dụng MLP một lớp cho mỗi mức độ. Chúng tôi đào tạo bốn mô hình với kích thước ẩn [256, 128], [512, 256, 128], [1024, 512, 256, 128], và [2048, 1024, 512, 256, 128] cho mỗi expert MLP tại các mức độ fusion khác nhau. Đối với các tháp nhiệm vụ, mỗi mô hình sử dụng MLP một lớp với kích thước ẩn 64. Kết quả được trình bày trong Bảng 8. Như mong đợi, việc thêm nhiều mức độ fusion hơn dẫn đến lợi ích hiệu suất lớn hơn. Ngay cả khi số lượng mức độ fusion tăng lên năm, cải thiện đáng kể vẫn được quan sát qua tất cả các nhiệm vụ.

5 KẾT LUẬN
Trong công trình này, chúng tôi đề xuất một mô hình MTL mới được gọi là Mạng Fusion Thích Ứng Từ Nhiệm Vụ Đến Nhiệm Vụ (AdaTT). Bằng cách tận dụng cơ chế fusion thích ứng của nó, AdaTT mô hình hóa hiệu quả các mối quan hệ nhiệm vụ phức tạp và tạo điều kiện cho việc học chung kiến thức cụ thể cho nhiệm vụ và được chia sẻ. Thông qua đánh giá toàn diện trên cả tập dữ liệu công nghiệp trong thế giới thực với các nhóm nhiệm vụ đa dạng, cũng như tập dữ liệu công khai, chúng tôi chứng minh hiệu quả và khả năng tổng quát hóa của AdaTT. Kết quả của chúng tôi cho thấy AdaTT vượt trội so với các mô hình học đa nhiệm vụ tiên tiến với biên độ đáng kể. Chúng tôi hy vọng thấy công trình của chúng tôi mang lại lợi ích cho một loạt ứng dụng rộng hơn ngoài học đa nhiệm vụ, nơi các mô-đun chuyên biệt liên quan khác nhau có thể học cộng sinh.

TÀI LIỆU THAM KHẢO
[1]Raquel Aoki, Frederick Tung, và Gabriel L. Oliveira. 2021. Học Đa Nhiệm Vụ Dị Thể với Sự Đa Dạng Expert. Trong BIOKDD .
[2] Rich Caruana. 1997. Học đa nhiệm vụ. Học máy 28, 1 (1997), 41–75.
[3]Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, và Andrew Rabinovich. 2018. Gradnorm: Chuẩn hóa gradient cho cân bằng loss thích ứng trong mạng đa nhiệm vụ sâu. Trong Hội nghị quốc tế về học máy . PMLR, 794–803.
[4]Zhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong, Henrik Kretzschmar, Yuning Chai, và Dragomir Anguelov. 2020. Chỉ cần chọn một dấu hiệu: Tối ưu hóa mô hình đa nhiệm vụ sâu với dropout dấu hiệu gradient. Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron 33 (2020), 2039–2050.
[5]Ronan Collobert và Jason Weston. 2008. Một kiến trúc thống nhất cho xử lý ngôn ngữ tự nhiên: Mạng nơ-ron sâu với học đa nhiệm vụ. Trong Kỷ yếu hội nghị quốc tế lần thứ 25 về Học máy . 160–167.
[6]Li Deng, Geoffrey Hinton, và Brian Kingsbury. 2013. Các loại mới của học mạng nơ-ron sâu cho nhận dạng giọng nói và các ứng dụng liên quan: Một tổng quan. Trong Hội nghị quốc tế IEEE 2013 về âm thanh, lời nói và xử lý tín hiệu . IEEE, 8599–8603.
[7]Dheeru Dua và Casey Graff. 2017. Kho lưu trữ Học Máy UCI. http://archive.ics.uci.edu/ml
[8]Thomas Elsken, Jan-Hendrik Metzen, và Frank Hutter. 2017. Tìm kiếm kiến trúc đơn giản và hiệu quả cho mạng nơ-ron tích chập. arXiv preprint arXiv:1711.04528 (2017).
[9]Pengsheng Guo, Chen-Yu Lee, và Daniel Ulbricht. 2020. Học phân nhánh cho học đa nhiệm vụ. Trong Hội nghị Quốc tế về Học Máy . PMLR, 3854–3863.
[10] Guy Hadash, Oren Sar Shalom, và Rita Osadchy. 2018. Xếp hạng và đánh giá: học đa nhiệm vụ cho hệ thống gợi ý. Trong Kỷ yếu Hội nghị ACM lần thứ 12 về Hệ thống Gợi ý . 451–454.
[11] Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, và Richard Socher. 2016. Một mô hình nhiều nhiệm vụ chung: Phát triển mạng nơ-ron cho nhiều nhiệm vụ nlp. arXiv preprint arXiv:1611.01587 (2016).
[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. 2016. Học dư sâu cho nhận dạng hình ảnh. Trong Kỷ yếu hội nghị IEEE về thị giác máy tính và nhận dạng mẫu . 770–778.
[13] Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, et al .2014. Bài học thực tế từ việc dự đoán nhấp chuột vào quảng cáo tại facebook. Trong Kỷ yếu hội thảo quốc tế lần thứ tám về khai thác dữ liệu cho quảng cáo trực tuyến . 1–9.
[14] Adrián Javaloy và Isabel Valera. 2021. RotoGrad: Đồng nhất hóa Gradient trong Học Đa Nhiệm Vụ. arXiv preprint arXiv:2103.02631 (2021).
[15] Alex Kendall, Yarin Gal, và Roberto Cipolla. 2018. Học đa nhiệm vụ sử dụng sự không chắc chắn để cân bằng loss cho hình học cảnh và ngữ nghĩa. Trong Kỷ yếu hội nghị IEEE về thị giác máy tính và nhận dạng mẫu . 7482–7491.
[16] Iasonas Kokkinos. 2017. Ubernet: Đào tạo một mạng nơ-ron tích chập phổ quát cho thị giác cấp thấp, trung bình và cao sử dụng tập dữ liệu đa dạng và bộ nhớ hạn chế. Trong Kỷ yếu hội nghị IEEE về thị giác máy tính và nhận dạng mẫu . 6129–6138.
[17] Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, và Kevin Murphy. 2018. Tìm kiếm kiến trúc mạng nơ-ron tiến bộ. Trong Kỷ yếu hội nghị châu Âu về thị giác máy tính (ECCV) . 19–34.
[18] Hanxiao Liu, Karen Simonyan, và Yiming Yang. 2018. Darts: Tìm kiếm kiến trúc có thể phân biệt. arXiv preprint arXiv:1806.09055 (2018).
[19] Shikun Liu, Edward Johns, và Andrew J Davison. 2019. Học đa nhiệm vụ đầu cuối với attention. Trong Kỷ yếu hội nghị IEEE/CVF về thị giác máy tính và nhận dạng mẫu . 1871–1880.
[20] Mingsheng Long, Zhangjie Cao, Jianmin Wang, và Philip S Yu. 2017. Học nhiều nhiệm vụ với mạng quan hệ đa tuyến tính. Tiến bộ trong hệ thống xử lý thông tin nơ-ron 30 (2017).
[21] Jiaqi Ma, Zhe Zhao, Jilin Chen, Ang Li, Lichan Hong, và Ed H Chi. 2019. Snr: Định tuyến mạng con cho chia sẻ tham số linh hoạt trong học đa nhiệm vụ. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo , Tập. 33. 216–223.
[22] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, và Ed H Chi. 2018. Mô hình hóa mối quan hệ nhiệm vụ trong học đa nhiệm vụ với hỗn hợp expert đa gate. Trong Kỷ yếu hội nghị quốc tế ACM SIGKDD lần thứ 24 về khám phá kiến thức & khai thác dữ liệu . 1930–1939.
[23] Elliot Meyerson và Risto Miikkulainen. 2017. Vượt ra ngoài phân cấp được chia sẻ: Học đa nhiệm vụ sâu thông qua thứ tự lớp mềm. arXiv preprint arXiv:1711.00108 (2017).
[24] Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, và Martial Hebert. 2016. Mạng cross-stitch cho học đa nhiệm vụ. Trong Kỷ yếu hội nghị IEEE về thị giác máy tính và nhận dạng mẫu . 3994–4003.
[25] Esteban Real, Alok Aggarwal, Yanping Huang, và Quoc V Le. 2019. Tiến hóa được điều chỉnh cho tìm kiếm kiến trúc bộ phân loại hình ảnh. Trong Kỷ yếu hội nghị aaai về trí tuệ nhân tạo , Tập. 33. 4780–4789.
[26] Sebastian Ruder, Joachim Bingel, Isabelle Augenstein, và Anders Søgaard. 2019. Học kiến trúc đa nhiệm vụ tiềm ẩn. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo , Tập. 33. 4822–4829.
[27] Ozan Sener và Vladlen Koltun. 2018. Học đa nhiệm vụ như tối ưu hóa đa mục tiêu. Tiến bộ trong hệ thống xử lý thông tin nơ-ron 31 (2018).
[28] Ximeng Sun, Rameswar Panda, Rogerio Feris, và Kate Saenko. 2020. Adashare: Học những gì cần chia sẻ cho học đa nhiệm vụ sâu hiệu quả. Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron 33 (2020), 8728–8740.
[29] Hongyan Tang, Junning Liu, Ming Zhao, và Xudong Gong. 2020. Trích xuất lớp tiến bộ (ple): Một mô hình học đa nhiệm vụ mới (mtl) cho gợi ý cá nhân hóa. Trong Hội nghị ACM lần thứ mười bốn về Hệ thống Gợi ý . 269–278.
[30] Simon Vandenhende, Stamatios Georgoulis, Bert De Brabandere, và Luc Van Gool. 2019. Mạng đa nhiệm vụ phân nhánh: quyết định lớp nào để chia sẻ. arXiv preprint arXiv:1904.02920 (2019).
[31] Yuyan Wang, Zhe Zhao, Bo Dai, Christopher Fifty, Dong Lin, Lichan Hong, Li Wei, và Ed H Chi. 2022. Các Head Nhỏ Có Thể Giúp Không? Hiểu và Cải thiện Tổng quát hóa Đa Nhiệm Vụ. Trong Kỷ yếu Hội nghị Web ACM 2022 . 3009–3019.
[32] Christopher Williams, Stefan Klanke, Sethu Vijayakumar, và Kian Chai. 2008. Học quá trình Gauss đa nhiệm vụ của động học nghịch đảo robot. Tiến bộ trong hệ thống xử lý thông tin nơ-ron 21 (2008).
[33] Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, và Chelsea Finn. 2020. Phẫu thuật gradient cho học đa nhiệm vụ. Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron 33 (2020), 5824–5836.
[34] Zhanpeng Zhang, Ping Luo, Chen Change Loy, và Xiaoou Tang. 2014. Phát hiện điểm mốc khuôn mặt bằng học đa nhiệm vụ sâu. Trong Hội nghị châu Âu về thị giác máy tính . Springer, 94–108.
[35] Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, và Ed Chi. 2019. Gợi ý video nào để xem tiếp theo: một hệ thống xếp hạng đa nhiệm vụ. Trong Kỷ yếu Hội nghị ACM lần thứ 13 về Hệ thống Gợi ý . 43–51.
[36] Barret Zoph và Quoc V Le. 2016. Tìm kiếm kiến trúc mạng nơ-ron với học tăng cường. arXiv preprint arXiv:1611.01578 (2016).

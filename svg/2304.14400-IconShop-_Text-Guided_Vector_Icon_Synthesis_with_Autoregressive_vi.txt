# IconShop: Tổng hợp Icon Vector có Hướng dẫn Văn bản với Transformer Tự hồi quy

RONGHUAN WU, Đại học Thành phố Hồng Kông
WANCHAO SU, Đại học Thành phố Hồng Kông  
KEDE MA, Đại học Thành phố Hồng Kông
JING LIAO*, Đại học Thành phố Hồng Kông

Một lịch có núi ở giữa.
khinh khí cầu Bầu trời đêm có nửa mặt trăng và một ngôi sao. Một cây lau nhà để lau sàn. danh bạ điện thoại, lịch trình, liên lạc Một biểu tượng áo phông mùa hè màu đen.
máy bay, phi cơ, du lịch, chuyến bay
cây, vườn, thiên nhiên, sinh thái Hình ảnh một cặp kính thời trang. diều, bay, trò chơi, lễ hội điện thoại, thiết bị, mặt trời, thời tiết
Một cây cầu được xây dựng qua sông.
Hình ảnh một máy điều hòa không khí. ô, mây
Một SVG mô tả bình thí nghiệm được sử dụng trong phòng thí nghiệm y tế.
thỏ, thỏ con, động vật, Lễ Phục sinh
Một bóng đèn đang phát sáng. xe hơi, lái xe, phương tiện, giao thông

Hình 1. Các icon vector được tạo với lời nhắc văn bản. IconShop được đề xuất hỗ trợ tổng hợp icon vector từ từ khóa (bảng trái) và các cụm từ và câu tự nhiên (bảng phải).

Scalable Vector Graphics (SVG) là định dạng hình ảnh vector phổ biến cung cấp hỗ trợ tốt cho tương tác và hoạt hình. Mặc dù có những đặc điểm hấp dẫn, việc tạo nội dung SVG tùy chỉnh có thể thách thức đối với người dùng do đường cong học tập dốc đòi hỏi phải hiểu ngữ pháp SVG hoặc làm quen với phần mềm chỉnh sửa chuyên nghiệp. Những tiến bộ gần đây trong tạo hình ảnh từ văn bản đã truyền cảm hứng cho các nhà nghiên cứu khám phá tổng hợp đồ họa vector bằng cách sử dụng phương pháp dựa trên hình ảnh (tức là văn bản → hình ảnh raster → đồ họa vector) kết hợp các mô hình tạo văn bản thành hình ảnh với vector hóa hình ảnh, hoặc phương pháp dựa trên ngôn ngữ (tức là văn bản → script đồ họa vector) thông qua các mô hình ngôn ngữ lớn được huấn luyện trước. Tuy nhiên, những phương pháp này gặp hạn chế về chất lượng tạo, đa dạng và tính linh hoạt. Trong bài báo này, chúng tôi giới thiệu IconShop, một phương pháp tổng hợp icon vector có hướng dẫn văn bản sử dụng transformer tự hồi quy. Chìa khóa thành công của phương pháp chúng tôi là tuần tự hóa và token hóa các đường dẫn SVG (và mô tả văn bản làm hướng dẫn) thành một chuỗi token có thể giải mã duy nhất. Với điều đó, chúng tôi có thể khai thác khả năng học chuỗi của transformer tự hồi quy, đồng thời cho phép cả tổng hợp icon vô điều kiện và có điều kiện văn bản. Thông qua huấn luyện tiêu chuẩn để dự đoán token tiếp theo trên tập dữ liệu icon vector quy mô lớn kèm theo mô tả văn bản, IconShop được đề xuất liên tục thể hiện khả năng tổng hợp icon tốt hơn so với các phương pháp dựa trên hình ảnh và ngôn ngữ hiện có cả về mặt định lượng (sử dụng điểm FID và CLIP) và định tính (thông qua nghiên cứu người dùng chủ quan chính thức). Đồng thời, chúng tôi quan sát thấy cải thiện đáng kể về đa dạng tạo, được xác thực bởi các thước đo Độ duy nhất và Tính mới khách quan. Quan trọng hơn, chúng tôi chứng minh tính linh hoạt của IconShop với nhiều tác vụ tổng hợp icon mới, bao gồm chỉnh sửa icon, nội suy icon, kết hợp ngữ nghĩa icon và gợi ý tự động thiết kế icon. Trang dự án là https://icon-shop.github.io/.

Từ khóa và cụm từ bổ sung: SVG, Tạo Icon, Tổng hợp Đồ họa Vector, Tạo có Hướng dẫn Văn bản, Transformer Tự hồi quy.

1 GIỚI THIỆU

Là một dạng đồ họa máy tính, đồ họa vector biểu diễn nội dung hình ảnh dựa trực tiếp trên các hình học (thông qua dòng lệnh và tham số), và được sử dụng rộng rãi trong các ứng dụng khoa học và nghệ thuật, bao gồm kiến trúc, khảo sát, kết xuất 3D, typography và thiết kế đồ họa. So với đồ họa raster, đồ họa vector được ưa chuộng khi cần độ chính xác hình học cao trên các tỷ lệ tùy ý, trong đó Scalable Vector Graphics (SVG) là định dạng file đồ họa vector phổ biến, đặc biệt trong các ngành công nghiệp sáng tạo. Nói chung, việc tạo nội dung SVG khó khăn đối với người dùng không chuyên nghiệp. Thật tẻ nhạt và tốn thời gian để có được kiến thức đầy đủ về ngữ pháp SVG và/hoặc thành thạo phần mềm chỉnh sửa chuyên nghiệp như Adobe Illustrator. Gần đây, đã có những thành công ấn tượng trong việc tạo hình ảnh raster từ văn bản, cung cấp phương tiện thuận tiện và hiệu quả để thực hiện ý định thiết kế hình ảnh của người dùng. Do đó, rất mong muốn xây dựng một hệ thống tính toán có thể thực hiện điều tương tự trong lĩnh vực SVG, cho phép tổng hợp nội dung SVG chính xác và linh hoạt được hướng dẫn bởi các mô tả văn bản trực quan.

Một phương pháp đơn giản là điều chỉnh tạo hình ảnh raster cho tổng hợp vector bằng cách chuyển đổi đầu ra hình ảnh của các mô hình tạo văn bản thành hình ảnh thành đồ họa vector bằng các phương pháp vector hóa hình ảnh. Trong khi các phương pháp dựa trên hình ảnh như vậy (tức là văn bản → hình ảnh raster → đồ họa vector) trực tiếp kết hợp những tiến bộ gần đây trong tạo văn bản thành hình ảnh (ví dụ: Stable Diffusion [Rombach et al. 2022]) vào tạo SVG, kết quả của chúng thường không thỏa mãn. Điều này là do các mô hình văn bản thành hình ảnh chủ yếu được huấn luyện để tạo ra các hình dạng hình học tự nhiên phức tạp và diện mạo màu sắc, và ít có khả năng tái tạo phong cách SVG với các nguyên tố hình học đơn giản và màu phẳng. Hơn nữa, để phù hợp với những hình ảnh raster phức tạp như vậy, các phương pháp vector hóa thường sử dụng các đường dẫn răng cưa với các góc và giao cắt không mong muốn, dẫn đến các artifact có thể nhìn thấy và khó chịu.

Vì SVG dựa trên Extensible Markup Language (XML), một hướng nghiên cứu để tổng hợp nội dung SVG từ văn bản là huấn luyện các mô hình Sequence-To-Sequence (seq2seq) nhận lời nhắc văn bản làm đầu vào và trực tiếp tạo ra script SVG làm đầu ra. Chúng tôi gọi đây là các phương pháp dựa trên ngôn ngữ (tức là văn bản → script đồ họa vector). Mặc dù có tính đơn giản về mặt khái niệm, SVG liên quan đến ngữ pháp phức tạp, và việc token hóa ngây thơ SVG như một dạng ngôn ngữ tự nhiên có thể dẫn đến các chuỗi token phức tạp và dài, làm phức tạp việc mô hình hóa xác suất sau đó. Các thí nghiệm sơ bộ [Bubeck et al. 2023] cho thấy rằng các Mô hình Ngôn ngữ Lớn (LLM) như GPT-4 [OpenAI 2023] có xu hướng kết hợp các hình dạng hình học cơ bản, như Circle và Ellipse, để truyền đạt thông tin ngữ nghĩa với sự liên kết văn bản-SVG tương đối tốt. Tuy nhiên, kết quả tổng hợp cho thấy độ phức tạp và đa dạng hạn chế (xem Mục 4.3), không đủ cho các ứng dụng SVG thực tế.

Trong bài báo này, chúng tôi phát triển một phương pháp dựa trên transformer tự hồi quy hỗ trợ tổng hợp nội dung SVG chính xác và linh hoạt được hướng dẫn bởi mô tả văn bản. Chúng tôi chứng minh tính khả thi của phương pháp chúng tôi trong bối cảnh icon SVG, tạo ra tên gọi IconShop. Chìa khóa thành công của IconShop là khai thác bản chất tuần tự của SVG: Một script SVG được cấu thành từ một chuỗi các đường dẫn, mà lần lượt bao gồm một chuỗi các lệnh vẽ (ví dụ: đường và đường cong, xem Mục 3.2). Do đó chúng tôi nối tất cả các đường dẫn SVG theo cách có thể giải mã duy nhất để tạo thành một chuỗi lệnh. Vì lời nhắc văn bản cũng có bản chất tuần tự, nó có thể được thêm vào đầu chuỗi lệnh một cách đơn giản. Do đó chúng tôi token hóa và che dấu chuỗi kết hợp theo cách [Aghajanyan et al. 2022; Bavarian et al. 2022; Fried et al. 2023] cho phép huấn luyện tiêu chuẩn của IconShop (để dự đoán token tiếp theo một cách tự hồi quy), đồng thời cho phép tổng hợp icon SVG có điều kiện trên ngữ cảnh hai chiều (còn được gọi là tác vụ điền vào giữa). Điều này có thể được thực hiện hiệu quả bằng cách kết hợp ngữ cảnh phải vào ngữ cảnh trái (được phân tách bởi một token đặc biệt), phù hợp với che dấu nhân quả (tức là tự hồi quy).

Chúng tôi huấn luyện IconShop trên tập dữ liệu icon vector quy mô lớn FIGR-8-SVG [Clouâtre và Demers 2019], bao gồm các icon SVG đơn sắc (tức là đen trắng). Chúng tôi tiến hành đánh giá toàn diện IconShop về chất lượng và đa dạng tạo dưới các cài đặt tổng hợp khác nhau. Kết quả thí nghiệm của chúng tôi cho thấy IconShop vượt trội hơn các phương pháp dựa trên hình ảnh và ngôn ngữ hiện có trong hai khía cạnh này cả về mặt định lượng và định tính. Các icon SVG được tổng hợp cũng cho thấy sự trung thực hợp lý với các lời nhắc văn bản tương ứng. Hơn nữa, chúng tôi chứng minh tính linh hoạt của IconShop với nhiều tác vụ tổng hợp icon mới, bao gồm chỉnh sửa icon, nội suy icon, kết hợp ngữ nghĩa icon và gợi ý tự động thiết kế icon.

2 CÔNG VIỆC LIÊN QUAN

Công việc của chúng tôi liên quan đến tạo văn bản thành hình ảnh (Mục 2.1), tạo đồ họa vector (Mục 2.2), và transformer tạo sinh (Mục 2.3). Ở đây chúng tôi chỉ cung cấp một đánh giá ngắn gọn về công việc trước đây có liên quan chặt chẽ đến chúng tôi, và việc xử lý toàn diện các lĩnh vực trên nằm ngoài phạm vi của bài báo này.

2.1 Tạo Văn bản thành Hình ảnh

Tạo hình ảnh từ văn bản là một tác vụ đầy thách thức đã nhận được sự quan tâm đáng kể trong những năm gần đây, và đã trải qua ba giai đoạn phát triển: Mạng Đối kháng Tạo sinh (GAN) [Kang et al. 2023; Qiao et al. 2019; Reed et al. 2016; Xu et al. 2018; Zhang et al. 2017, 2018], các mô hình seq2seq dựa trên transformer [Chang et al. 2023; Ding et al. 2021, 2022; Ramesh et al. 2021; Yu et al. 2022], và các mô hình khuếch tán [Nichol et al. 2021; Rombach et al. 2022; Saharia et al. 2022]. Cụ thể, một GAN [Goodfellow et al. 2014] liên quan đến việc huấn luyện hai mạng nơ-ron - một bộ tạo và một bộ phân biệt - để chơi một trò chơi minmax zero-sum. Hệ thống học cách tạo ra hình ảnh mới bằng cách tôn trọng phân phối dữ liệu huấn luyện và điều kiện văn bản. GAN có điều kiện văn bản [Kang et al. 2023; Qiao et al. 2019; Reed et al. 2016; Xu et al. 2018; Zhang et al. 2017, 2018] thường bị giới hạn trong việc mô hình hóa các lớp đối tượng đơn và nhiều. Việc mở rộng chúng để xử lý các tập dữ liệu hình ảnh phức tạp vẫn rất thách thức do sự bất ổn xảy ra trong quá trình huấn luyện, cho đến rất gần đây [Kang et al. 2023]. Các mô hình Seq2seq dựa trên transformer hoạt động bằng cách chuyển đổi (và nối) văn bản đầu vào (và hình ảnh) thành một chuỗi token để dự đoán một chuỗi token khác tương ứng với hình ảnh đích [Chang et al. 2023; Ding et al. 2021, 2022; Ramesh et al. 2021; Yu et al. 2022]. Self-attention chỉ văn bản và chỉ hình ảnh và cross-attention văn bản-hình ảnh là các cơ chế tính toán kinh điển trong các mô hình seq2seq để nắm bắt các phụ thuộc phức tạp giữa các token văn bản và hình ảnh. Gần đây, các mô hình khuếch tán đã nổi lên trở thành tiêu chuẩn mới trong tạo văn bản thành hình ảnh qua đêm. Thông thường, một mô hình khuếch tán vô điều kiện [Ho et al. 2020] bắt đầu quá trình của nó với nhiễu Gaussian, và loại bỏ nó một cách lặp đi lặp lại để tạo ra một hình ảnh tự nhiên. Các mô hình khuếch tán có hướng dẫn văn bản [Nichol et al. 2021; Rombach et al. 2022; Saharia et al. 2022] tận dụng embedding văn bản hoặc làm đầu vào hoặc thông qua cross-attention. Mặc dù công việc trước đây giải quyết tạo nội dung hình ảnh có hướng dẫn văn bản như chúng tôi, chúng tập trung chủ yếu vào hình ảnh raster với độ phân giải cố định. Ngược lại, chúng tôi hướng đến một mục tiêu khác - tổng hợp icon vector có hướng dẫn văn bản với tỷ lệ tùy ý.

2.2 Tạo Đồ họa Vector

Vào đầu những năm 2000, nội dung SVG có thể được tạo bằng PERL [Probets et al. 2001] với nhiều lệnh vẽ, nhưng đòi hỏi can thiệp rộng rãi của con người. Bergen và Ross [2012] tự động hóa việc xác định số lượng và loại lệnh vẽ bằng tính toán tiến hóa để khớp với hình ảnh raster đích. Những công việc này có thể được coi là tổ tiên của các phương pháp tạo đồ họa vector dựa trên mạng nơ-ron sâu để học các biểu diễn SVG có thể chỉnh sửa. SketchRNN [Ha và Eck 2017] là một mô hình học biểu diễn sâu tiên phong cho các bản phác thảo vector dựa trên một Variational Auto-Encoder (VAE) seq2seq [Kingma và Welling 2013]. Bộ mã hóa và bộ giải mã được triển khai bằng một mạng nơ-ron tái phát (RNN) hai chiều và một RNN tự hồi quy, tương ứng. Các bản phác thảo được tham số hóa bằng polyline - một chuỗi các điểm với các đoạn thẳng được vẽ giữa các điểm liên tiếp. Lopes et al. [2019] kết hợp một biểu diễn hình ảnh raster học được từ VAE để hỗ trợ tổng hợp font SVG. Tính khả thi của phương pháp chỉ được chứng minh trên các ký tự với tối đa 50 lệnh. Mô hình hóa cấu trúc lớp của SVG, DeepSVG [Carlier et al. 2020] đã huấn luyện hai bộ mã hóa dựa trên transformer song song để ánh xạ các icon SVG từ lệnh đến biểu diễn cấp đường dẫn, và sau đó đến một biểu diễn latent toàn cục. Hai bộ giải mã được ghép nối để tái tạo icon SVG. Mặc dù các hình dạng được tái tạo trông hợp lý, DeepSVG không thể tái tạo các mối quan hệ hình học đơn giản như vuông góc và song song. Lấy cảm hứng từ DeepSVG, Aoki và Aizawa [2022] đã sử dụng đầy đủ biểu diễn latent toàn cục trong mọi giai đoạn của bộ giải mã để tổng hợp các ký tự SVG tiếng Trung. Mặc dù đã chứng minh thành công, các phương pháp được đề cập ở trên không hỗ trợ tạo SVG có hướng dẫn văn bản.

Một phương pháp đơn giản của tổng hợp nội dung SVG có hướng dẫn văn bản là trước tiên tạo một hình ảnh raster với một mô hình tạo văn bản thành hình ảnh được huấn luyện (ví dụ: DALL·E [Ramesh et al. 2021] và Stable Diffusion [Rombach et al. 2022]), và sau đó vector hóa nó bằng các kỹ thuật vector hóa hình ảnh có sẵn (ví dụ: Potrace [Selinger 2003] và LIVE [Ma et al. 2022]). Một dòng nghiên cứu mới nổi khác là tối ưu hóa trực tiếp các tham số SVG cho một mô hình thị giác-ngôn ngữ được huấn luyện trước làm hàm mất mát. Ví dụ, CLIPDraw [Frans et al. 2021] đã áp dụng mô hình CLIP [Radford et al. 2021] làm mục tiêu tối ưu hóa để đo khoảng cách embedding giữa hình ảnh vector-to-raster và mô tả văn bản đầu vào. Ngoài khoảng cách CLIP, VectorFusion [Jain et al. 2022] đã tận dụng mất mát Score Distillation Sampling (SDS) [Poole et al. 2022] dựa trên một mô hình khuếch tán văn bản thành hình ảnh pixel-space. Mặc dù có các triết lý thiết kế khác nhau, các phương pháp dựa trên vector hóa và tối ưu hóa gặp phải những hạn chế tương tự. Thứ nhất, các mô hình thị giác-ngôn ngữ là những yếu tố hỗ trợ chính được huấn luyện trước trên hình ảnh raster của các cảnh tự nhiên phức tạp, và do đó khó có thể cung cấp hướng dẫn trong việc tổng hợp hình ảnh kiểu SVG với các nguyên tố hình học đơn giản và màu phẳng. Thứ hai, các đường dẫn được tạo thường răng cưa và lộn xộn, không thể tái tạo các mối quan hệ hình học chính xác như song song và vuông góc. Thứ ba, tối ưu hóa mỗi SVG có thể chậm một cách đau đớn, làm cho nó không thực tế cho các ứng dụng thời gian thực. Ngược lại, hệ thống được đề xuất của chúng tôi, IconShop, không gặp phải bất kỳ vấn đề nào được đề cập ở trên. Một khi được huấn luyện, IconShop có thể thực hiện tổng hợp icon vector có hướng dẫn văn bản một cách tự động và hiệu quả.

2.3 Transformer như Mô hình Tạo sinh

Nhờ khả năng vốn có để nắm bắt các phụ thuộc dài hạn và hỗ trợ tính toán song song, Transformer [Vaswani et al. 2017] đã nổi lên như một lớp mô hình tạo sinh mạnh mẽ để tạo ra nhiều loại đầu ra khác nhau, từ ngôn ngữ tự nhiên [Brown et al. 2020; Radford et al. 2019; Raffel et al. 2020], âm thanh [Huang et al. 2018; Li et al. 2019; Valle et al. 2020], và hình ảnh raster [Chen et al. 2020; Esser et al. 2021]. Transformer có thể được làm không tự hồi quy và tự hồi quy. Phiên bản không tự hồi quy [Chang et al. 2023, 2022; Ding et al. 2022; Zhang et al. 2021] đề xuất tận dụng ngữ cảnh hai chiều bằng cách sử dụng Transformer hai chiều giống BERT [Devlin et al. 2018] cho hiệu quả lấy mẫu của nó. Phiên bản tự hồi quy [Ding et al. 2021; Ramesh et al. 2021; Yu et al. 2022] nhấn mạnh tầm quan trọng của việc học dự đoán token tiếp theo theo cách nhân quả. Cùng với việc mở rộng quy mô, nó mở khóa các khả năng nổi bật của LLM. Lấy cảm hứng từ [Aghajanyan et al. 2022; Bavarian et al. 2022], chúng tôi thống nhất mô hình hóa không tự hồi quy và tự hồi quy của các icon vector cho các tác vụ tổng hợp khác nhau.

3 ICONSHOP

Trong mục này, trước tiên chúng tôi giới thiệu ngắn gọn các mô hình tự hồi quy (Mục 3.1), và mô tả các lệnh SVG của icon vector, theo sau là chiến lược token hóa của chúng tôi (Mục 3.2). Sau đó chúng tôi mô tả chiến lược che dấu "nhân quả", cho phép mô hình tự hồi quy của chúng tôi thực hiện tác vụ điền vào giữa (Mục 3.3). Tiếp theo chúng tôi trình bày chi tiết kiến trúc mô hình của chúng tôi (Mục 3.4) và cuối cùng, trình bày các mục tiêu huấn luyện (Mục 3.5).

3.1 Kiến thức Cơ bản về Mô hình Tự hồi quy

Một mô hình tự hồi quy chỉ định rằng trạng thái hiện tại chỉ phụ thuộc vào các trạng thái trước đó của nó. Về mặt xác suất, điều này tương ứng với quy tắc chuỗi của xác suất:

p(S) = ∏[n=1 to N] p(Sn|S1,...,Sn-1),                    (1)

trong đó chúng tôi phân tích xác suất chung của một chuỗi các biến ngẫu nhiên S = (S1,...,SN) thành một tích của các xác suất có điều kiện. Tại trường hợp thứ n, các mô hình tự hồi quy lấy các giá trị của n-1 biến ngẫu nhiên trước đó (hoặc những cái gần đây nhất nếu một cửa sổ Markov được áp dụng) làm đầu vào, và tính toán phân phối xác suất có điều kiện của Sn, từ đó chúng ta có thể rút một mẫu làm dự đoán của nó. Ở đây chúng tôi dựa vào các mô hình tự hồi quy để tổng hợp icon SVG vì nó phù hợp tự nhiên với bản chất tuần tự của SVG và mô tả văn bản.

3.2 Biểu diễn và Token hóa SVG

SVG cung cấp một loạt các tính năng và tùy chọn cú pháp, cho phép người dùng tạo ra tác phẩm gốc của họ với tính linh hoạt lớn. Ví dụ, lệnh Rect tạo ra một hình chữ nhật được điều khiển bởi điểm bắt đầu, đối số chiều rộng và chiều cao, như <Rect x="80" y="90" width="100" height="100"/>. Thuộc tính Transform áp dụng một phép biến đổi affine cho một hình dạng hiện có, như <Rect Transform="rotate (-10 50 100)" x="80" y="90" width="100" height="100"/>. Nếu chúng ta cố gắng đưa ra một cấu trúc dữ liệu phổ quát để biểu diễn tất cả các lệnh và thuộc tính SVG có thể, cấu trúc dữ liệu như vậy sẽ trở nên rất phức tạp, có thể cản trở việc mô hình hóa xác suất của các icon SVG. Để bỏ qua vấn đề này, chúng tôi chọn giới hạn số lượng lệnh và thuộc tính, đồng thời duy trì tính biểu cảm của chúng để nắm bắt bản chất của các icon SVG. Nói cách khác, chúng tôi tìm kiếm một biểu diễn SVG nhỏ gọn giúp việc mô hình hóa xác suất của nó dễ dàng hơn.

Lấy cảm hứng từ DeepSVG [Carlier et al. 2020], chúng tôi đơn giản hóa mọi icon SVG bằng cách loại bỏ tất cả thuộc tính và chỉ sử dụng ba lệnh cơ bản: Move To, Line To, và Cubic Bézier (xem Bảng 1 để biết giải thích và ví dụ). Các lệnh phức tạp khác (ví dụ: Rect, Circle, và Ellipse) có thể được xấp xỉ bằng tổ hợp của các lệnh cơ bản này với sự khác biệt hình ảnh không đáng kể. Ví dụ, chúng ta có thể sử dụng bốn đoạn thẳng để xây dựng một Rect, và nối bốn đường cong Bézier để tạo thành một Circle. Một script văn bản SVG G, sau khi đơn giản hóa, chứa M đường dẫn, G = {Pi}[i=1 to M], trong đó Pi là đường dẫn thứ i, và mỗi đường dẫn Pi lần lượt bao gồm Ni lệnh, Pi = {Cj^i}[j=1 to Ni], trong đó Cj^i là lệnh thứ j trong đường dẫn thứ i. Một lệnh, Cj^i = (Uj^i, Vj^i), chứa loại Uj^i ∈ {M,L,C} và đối số vị trí tương ứng Vj^i.

Bước tiếp theo là chuyển đổi script SVG thành một chuỗi rời rạc các token, được áp dụng mô hình hóa tự hồi quy. Chúng tôi giới thiệu một phương pháp token hóa SVG trực quan, được cấu thành từ bốn bước chính. Thứ nhất, làm phẳng cấu trúc lớp của script SVG bằng cách nối các lệnh từ các đường dẫn khác nhau để tạo thành một chuỗi lệnh duy nhất. Để giải mã duy nhất chuỗi lệnh được làm phẳng trở lại biểu diễn lớp, chúng tôi thêm vào đầu một token đặc biệt, <BOP> (tức là begin-of-path), trước lệnh đầu tiên của mỗi đường dẫn. Thứ hai, gán các token riêng biệt cho mỗi loại lệnh (tức là M, L, C). Thứ ba, ánh xạ đối số vị trí 2D sang 1D bằng thứ tự hàng chính, điều này làm giảm khoảng một nửa độ dài của chuỗi token. Ví dụ, giả sử chiều rộng mặc định của một hình ảnh SVG là w, chúng tôi biến đổi một đối số vị trí 2D (x,y) thành một đối số 1D bằng công thức x × w + y. Thứ tư, thêm một token đặc biệt, <EOS> (tức là end-of-SVG), ở cuối chuỗi để chỉ ra sự hoàn thành của một chuỗi icon SVG. Một ví dụ về chuỗi được tạo bằng các bước trên được hiển thị trong Hình 2.

3.3 Sơ đồ Che dấu

Các mô hình tự hồi quy đã được chứng minh là hiệu quả trong việc tạo ra các chuỗi token từ đầu, nhưng chúng bị hạn chế chỉ làm như vậy theo hướng nhân quả (tức là từ trái sang phải). Ràng buộc này cản trở hiệu suất tổng hợp SVG trong các tác vụ như chỉnh sửa icon, nơi chúng ta cần điền vào nội dung bị thiếu dựa trên ngữ cảnh hai chiều. Một số phương pháp đã được phát triển để mở rộng khả năng của các mô hình tự hồi quy để thực hiện tác vụ điền vào giữa bằng cách xử lý dữ liệu huấn luyện mà không cần thay đổi kiến trúc mô hình. Ví dụ, CM3 [Aghajanyan et al. 2022] và InCoder [Fried et al. 2023] đã sử dụng chiến lược che dấu "nhân quả" mà ngẫu nhiên chọn một số đoạn trong chuỗi đầu vào, và di chuyển chúng đến cuối. Trong [Bavarian et al. 2022], một chiến lược tương tự đã được triển khai để học điền vào giữa mà không hy sinh khả năng tạo nhân quả ban đầu. Trong việc huấn luyện IconShop, chúng tôi kết hợp một chiến lược che dấu "casual" tương tự để thống nhất mô hình hóa không tự hồi quy và tự hồi quy của các chuỗi token SVG.

Đối với một chuỗi đầu vào S(0) cho trước, trước tiên chúng tôi chọn một đoạn ngẫu nhiên được gọi là span, dựa trên đó chúng tôi chia chuỗi thành ba phần, [Left : Span : Right], trong đó ":" đại diện cho phép nối. Chúng tôi thay thế span bằng một token đặc biệt <Mask> để có được một chuỗi mới S(1) = [Left : <Mask> : Right]. Tiếp theo, chúng tôi thêm cùng token <Mask> vào đầu span và thêm một token <EOM> (tức là end-of-mask) vào cuối span để tạo ra một chuỗi mới S(2) = [<Mask> : Span : <EOM>]. Cuối cùng, chúng tôi nối S(1) và S(2) để tạo thành

S = [Left : <Mask> : Right : <Mask> : Span : <EOM>],      (2)

được gửi đến mô hình để mô hình hóa xác suất. Chuỗi được che dấu S truyền đạt thông tin sau: 1) token <Mask> đầu tiên chỉ ra vị trí ban đầu của span, 2) token <Mask> thứ hai biểu thị sự bắt đầu của span, và 3) token <EOM> đánh dấu kết thúc của span. Trong quá trình huấn luyện, chúng tôi ngẫu nhiên áp dụng chiến lược che dấu này cho 50% dữ liệu huấn luyện, trong khi để lại 50% còn lại không thay đổi. Chúng tôi loại trừ token <Mask> khỏi tính toán mất mát cross-entropy để ngăn cản việc tạo ra nó trong quá trình suy luận.

Bây giờ chúng tôi giải thích cách kỹ thuật che dấu này cho phép các mô hình tự hồi quy thực hiện tạo điền vào giữa (tức là không tự hồi quy) mà không cần thay đổi kiến trúc. Giả sử chúng ta có một chuỗi token [Left : Right], và muốn điền vào đoạn giữa giữa Left và Right. Như trong Phương trình 2, chúng ta thêm hai token <Mask> vào chuỗi để tạo ra [Left : <Mask> : Right : <Mask>], và gửi nó đến mô hình để tạo seq2seq cho đến khi token <EOM> xuất hiện, tạo ra chuỗi [Left : <Mask> : Right : <Mask> : Span : <EOM>]. Sau đó, chúng ta di chuyển Span được dự đoán trở lại vị trí ban đầu của nó, tức là vị trí của token <Mask> đầu tiên, để có được đầu ra cuối cùng [Left : Span : Right]. Vì mô hình tận dụng cả ngữ cảnh Left và Right để điền vào đoạn Span giữa, chúng ta đạt được mô hình hóa không tự hồi quy thông qua dự đoán tự hồi quy, và do đó thống nhất cả hai.

3.4 Kiến trúc Mô hình

Chúng tôi sử dụng bộ giải mã Transformer [Vaswani et al. 2017] để triển khai mô hình tự hồi quy của chúng tôi, vì nó nắm bắt hiệu quả các phụ thuộc tầm xa giữa các token khác nhau tạo thành một chuỗi icon vector. Cụ thể, mô hình bao gồm ba module: một module embedding SVG để mã hóa chuỗi SVG, một module embedding văn bản để mã hóa chuỗi văn bản, và một module transformer (bộ giải mã) để khai thác tương quan văn bản-SVG, và học phân phối xác suất chung của chuỗi token kết hợp, lấy mẫu từ đó tạo ra các chuỗi mới không có trong tập huấn luyện.

Module Embedding SVG. Như đã thảo luận trước đó, một chuỗi SVG được biểu diễn bởi sáu loại token riêng biệt: 1) Loại lệnh, 2) Đối số vị trí 1D, 3) Token begin-of-path <BOP>, 4) Token end-of-SVG <EOS>, 5) Token Mask <Mask>, và 6) Token end-of-mask <EOM>. Mặc định, mỗi icon được ràng buộc trong một hộp giới hạn 100×100, dẫn đến 100² giá trị có thể cho đối số vị trí 1D. Do đó, một vector one-hot e với chiều 10,007 (= 3 + 100² + 1 + 1 + 1 + 1) đủ để biểu diễn tất cả các trường hợp token có thể. Sau đó chúng tôi sử dụng một ma trận embedding có thể học W ∈ R^(D×10007) để biến đổi vector one-hot thành một vector embedding có kích thước D. Chúng tôi kết hợp hai ma trận có thể học bổ sung Wx, Wy ∈ R^(D×100) để tăng cường thông tin vị trí như được đề xuất trong [Xu et al. 2022]:

vi ← Wei + Wxe^x_i + Wyey_i,                    (3)

trong đó ei ∈ R^(10007×1) là vector one-hot của token thứ i, và e^x_i, e^y_i ∈ R^(100×1) là mã hóa one-hot của tọa độ 2D, tương ứng.

Module Embedding Văn bản. LLM được huấn luyện trên một tập lớn dữ liệu văn bản có khả năng nắm bắt các mối quan hệ từ phức tạp, bao gồm đồng nghĩa và trái nghĩa, như được đề xuất trong [Saharia et al. 2022]. Ở đây chúng tôi sử dụng các lớp token hóa và word embedding từ một mô hình BERT được huấn luyện trước [Turc et al. 2019], và cố định chúng để token hóa và embed các đầu vào văn bản. Bộ token hóa thêm một token <CLS> vào đầu văn bản, và thêm một token <SEP> ở cuối văn bản, chỉ ra điểm bắt đầu và kết thúc của chuỗi văn bản, tương ứng.

Module Transformer. Mô hình transformer tự hồi quy của chúng tôi bao gồm một chồng 12 lớp giống hệt nhau. Mỗi lớp là một khối bộ giải mã transformer tiêu chuẩn, bao gồm attention đa đầu (có che dấu), chuẩn hóa lớp, và các lớp feed-forward, tất cả được liên kết thông qua các kết nối dư. Transformer tự hồi quy cuối cùng tạo ra một vector D-chiều tại vị trí token thứ n, được điều kiện hóa trên n-1 token trước đó của nó. Một lớp tuyến tính theo sau bởi hàm softmax được áp dụng để có được xác suất của tất cả các token có thể tại vị trí thứ n.

3.5 Mục tiêu Huấn luyện

Vì các mô tả văn bản và script SVG trong tập huấn luyện có độ dài khác nhau, chúng tôi đệm cả chuỗi token văn bản Stext và chuỗi token icon Sicon bằng số không đến một độ dài cố định (50 cho văn bản và 512 cho icon trong triển khai của chúng tôi). Sau đó chúng tôi nối chúng để có được chuỗi đích S = [Stext : Sicon].

Transformer tự hồi quy được huấn luyện để dự đoán token tiếp theo dựa trên các token trước đó. Để chuẩn bị chuỗi đầu vào Sin, chúng tôi loại bỏ token cuối cùng của S (tức là <EOS>), và thêm một token <SOS> ở đầu. Điều này về cơ bản dịch chuyển S sang phải một vị trí, cho phép dự đoán tự hồi quy ban đầu với một ngữ cảnh trống. Transformer xuất ra một chuỗi token Ŝ = [Ŝtext : Ŝicon] một cách tuần tự. Mục tiêu của chúng tôi là giảm thiểu mất mát cross-entropy giữa các token đích và đầu ra tại mỗi vị trí, và sau đó kết hợp mất mát văn bản và icon với một tổng có trọng số [Ramesh et al. 2021]:

ℓtext = CE(Stext, Ŝtext),
ℓicon = CE(Sicon, Ŝicon),
ℓtotal = ℓtext + λℓicon,                    (4)

trong đó CE() là hàm cross-entropy tiêu chuẩn, và λ = 7.0 là trọng số để kiểm soát tầm quan trọng tương đối giữa việc tái tạo văn bản và icon.

4 THỰC NGHIỆM

Trong mục này, trước tiên chúng tôi trình bày chi tiết quy trình xử lý dữ liệu cho tập dữ liệu icon với mô tả văn bản (Mục 4.1). Sau đó chúng tôi giới thiệu một nghiên cứu ablation để xác thực hiệu quả của kiến trúc mô hình dưới cả cài đặt tạo có điều kiện và vô điều kiện (Mục 4.2). Cuối cùng, chúng tôi so sánh IconShop được đề xuất với các giải pháp thay thế, chứng minh rằng IconShop tạo ra kết quả chất lượng cao hơn (Mục 4.3).

4.1 Chuẩn bị Dữ liệu

Tập dữ liệu SVG. Chúng tôi sử dụng tập dữ liệu FIGR-8-SVG [Clouâtre và Demers 2019] bao gồm 1.5 triệu icon vector đơn sắc (đen trắng). Thông thường, bước đầu tiên để xử lý dữ liệu SVG là biến đổi các icon với ngữ pháp khác nhau thành các biểu diễn chuẩn hóa. May mắn thay, trong tập dữ liệu FIGR-8-SVG, tất cả các icon đã được chuyển đổi thành một biểu diễn thống nhất với các đối số rời rạc hóa. Chúng tôi hiển thị một số ví dụ icon từ tập dữ liệu trong hàng đầu tiên của Hình 3. Chúng tôi tiếp tục nâng cao sức hấp dẫn hình ảnh của mỗi icon bằng cách loại bỏ hộp đen bên ngoài. Các icon được nâng cao tương ứng được hiển thị trong hàng thứ hai. Sau khi token hóa SVG được mô tả trong Mục 3.2, chúng tôi đặt độ dài tối đa của một chuỗi icon là 512, lọc ra những cái có độ dài dài hơn. Điều này dẫn đến khoảng 1.1 triệu mẫu, trong số đó, chúng tôi chọn 300,000 mẫu để huấn luyện và thử nghiệm mô hình ở giai đoạn hiện tại. Chúng tôi phân chia các mẫu này thành 90% cho huấn luyện, 5% cho xác thực, và 5% cho kiểm tra.

Đầu vào Văn bản. Trong tập dữ liệu FIGR-8-SVG, mỗi icon vector được chú thích với các từ khóa rời rạc, như "cat/face". Việc huấn luyện IconShop chỉ với từ khóa sẽ hạn chế khả năng tạo icon từ các cụm từ và câu ngôn ngữ tự nhiên. Lấy cảm hứng từ InstructPix2Pix [Brooks et al. 2022], mà tinh chỉnh GPT-3 [Brown et al. 2020] để tạo ra hướng dẫn chỉnh sửa và chú thích, chúng tôi sử dụng LLM (ChatGPT* cụ thể) để mở rộng những từ khóa này thành các cụm từ và câu ngôn ngữ tự nhiên. Lời nhắc được đưa cho ChatGPT là "Viết câu đơn giản nhất từ từ khóa: #{keywords}. Không thêm sự thật bổ sung".

Chi tiết Triển khai. Chúng tôi triển khai IconShop bằng PyTorch. Quá trình huấn luyện sử dụng bộ tối ưu Adam [Kingma và Ba 2014] với tốc độ học 0.0006, cùng với khởi động tuyến tính, suy giảm, và cắt gradient. Tỷ lệ dropout được đặt ở 0.1. Từ khóa rời rạc được xáo trộn, các cụm từ và chuỗi ngôn ngữ tự nhiên (được tạo bởi ChatGPT), và văn bản trống được, tương ứng, huấn luyện với tỷ lệ 60%, 30%, và 10%, với tổng kích thước minibatch là 192. Chúng tôi huấn luyện IconShop trong 300 epoch. Chúng tôi sử dụng GPU NVIDIA A100 trong các thí nghiệm sau để kiểm tra IconShop, mất trung bình 1.38 giây để tạo một chuỗi icon SVG.

Thước đo. Để đánh giá chất lượng của các icon SVG được tạo, chúng tôi sử dụng Fréchet Inception Distance (FID) [Heusel et al. 2017], đo khoảng cách giữa các đặc trưng hình ảnh của các icon SVG được tổng hợp và "ground-truth" từ FIGR-8-SVG. Cụ thể, chúng tôi thu được các đặc trưng hình ảnh của các icon SVG được render và raster hóa bằng bộ mã hóa hình ảnh CLIP [Radford et al. 2021]. Chúng tôi cũng tính điểm CLIP để đo sự liên kết văn bản-SVG (tức là tương tự ngữ nghĩa giữa đầu vào văn bản và đầu ra icon hình ảnh). Ngoài ra, theo SkexGen [Xu et al. 2022], chúng tôi tính điểm "Novelty" và "Uniqueness", tương ứng với tỷ lệ dữ liệu được tạo không có trong tập đích (tức là tập huấn luyện từ FiGR-8-SVG) và chỉ xuất hiện một lần trong tất cả các mẫu được tạo. Chúng tôi tạo 20,000 icon vô điều kiện và 7,000 icon với hướng dẫn văn bản. Tương tự cosine giữa các đặc trưng CLIP được sử dụng để xác định xem hai icon có giống hệt nhau với ngưỡng 0.98. Hình 4 đưa ra so sánh hình ảnh trực quan của các giá trị tương tự khác nhau.

4.2 Ablation về Kiến trúc Mạng Khác nhau

Trong tiểu mục này, chúng tôi tiến hành hai nghiên cứu ablation để minh họa hiệu ứng của hai thành phần chính của IconShop trên hiệu suất tổng hợp. Nghiên cứu đầu tiên cho thấy tầm quan trọng của việc khai thác bản chất tuần tự của các icon SVG trong tạo bằng cách so sánh mô hình seq2seq của chúng tôi với một mô hình GAN. Nghiên cứu thứ hai chứng minh sự cần thiết của mô hình tự hồi quy của chúng tôi được tăng cường với sơ đồ che dấu "nhân quả" bằng cách so sánh nó với một chiến lược huấn luyện không tự hồi quy (tức là BERT [Devlin et al. 2018]).

Seq2seq so với Mô hình hóa Lớp. Như đã đề cập trước đó, một file SVG có cấu trúc lớp, bao gồm các đường dẫn cấp cao hơn và các lệnh cấp thấp hơn. Ở đây chúng tôi sử dụng DeepSVG+GAN làm đường cơ sở để kiểm chứng lựa chọn cơ chế tạo seq2seq của chúng tôi.

DeepSVG ban đầu tái tạo một icon SVG bằng cách trước tiên thu được các biểu diễn cấp đường dẫn và sau đó tổng hợp chúng thành một biểu diễn toàn cục. Để so sánh công bằng giữa IconShop và DeepSVG, chúng tôi cần cho phép DeepSVG ban đầu tạo ra các icon mới và hỗ trợ tạo có hướng dẫn văn bản. Để đạt được những mục tiêu này, chúng tôi huấn luyện lại DeepSVG để tái tạo icon SVG trên tập dữ liệu của chúng tôi. Sau đó chúng tôi huấn luyện một mô hình GAN có điều kiện, nhận đặc trưng văn bản làm đầu vào và dự đoán biểu diễn latent được tính toán trước từ bộ mã hóa của DeepSVG làm đầu ra, có thể được giải mã một cách đơn giản thành một icon SVG bằng cách đi qua bộ giải mã của DeepSVG. Ngoài tạo có hướng dẫn văn bản, chúng tôi cũng cho phép GAN tạo icon vô điều kiện bằng cách thay thế đặc trưng văn bản bằng nhiễu ngẫu nhiên 10% thời gian trong quá trình huấn luyện.

Chúng tôi so sánh cả hiệu suất tạo ngẫu nhiên và tạo có hướng dẫn văn bản. Đối với tạo ngẫu nhiên, chúng tôi tạo ra 20,000 icon cho mỗi phương pháp. Đối với tạo có hướng dẫn văn bản, chúng tôi chọn cả từ khóa rời rạc và các cụm từ/câu tự nhiên thường được sử dụng trong các tình huống thiết kế làm đầu vào văn bản và tạo 7,000 icon cho mỗi mô hình. Như được hiển thị trong Hình 5 và 6, IconShop có khả năng tạo ra các icon có thể nhận biết bằng mắt và bắt mắt trong khi bảo tồn các mối quan hệ hình học nổi bật, như vuông góc, song song và đối xứng. Chúng tôi tin rằng những kết quả tạo chất lượng cao nhất quán như vậy phát sinh vì chúng tôi ưu tiên mô hình hóa tuần tự của các icon SVG. Ngược lại, DeepSVG+GAN trình bày kết quả kém hơn về mặt hình ảnh so với chúng tôi, mà chúng tôi cho là do hoạt động tính trung bình trên các lệnh và đường dẫn, dẫn đến mất các chi tiết hình học trong các icon được tạo. Vui lòng tham khảo trang dự án để biết thêm kết quả định tính.

Chúng tôi cũng đánh giá định lượng kết quả tạo ngẫu nhiên và tạo có hướng dẫn văn bản trong Bảng 2a và 2b. Chúng tôi thấy rằng IconShop tổng hợp kết quả với điểm FID thấp hơn đáng kể trong cả hai tác vụ tạo ngẫu nhiên và có hướng dẫn văn bản, cung cấp một chỉ báo mạnh mẽ về khả năng tổng hợp vượt trội của IconShop. Về Uniqueness và Novelty như các thước đo đa dạng tạo, IconShop hoạt động tương đối tốt so với DeepSVG+GAN. Tuy nhiên, điều quan trọng cần lưu ý là các giá trị Uniqueness và Novelty cao đạt được bởi DeepSVG+GAN phần lớn được quy cho các biến dạng hình ảnh đáng chú ý (ví dụ: đường cong gõ) mà nó gặp phải thay vì các phiên bản mới của cùng một đối tượng/khái niệm, như rõ ràng trong Hình 5. Chúng tôi coi đây là "đa dạng giả" nếu nó chỉ được diễn giải mà không được điều kiện hóa trên chất lượng tạo chấp nhận được. Hơn nữa, IconShop đạt được điểm CLIP cao nhất trong tác vụ tạo có hướng dẫn văn bản, báo hiệu khả năng xuất sắc để tạo ra các icon phản ánh chính xác ngữ nghĩa văn bản.

Mô hình hóa Tự hồi quy so với Không Tự hồi quy. Nghiên cứu gần đây [Chang et al. 2023, 2022] cho thấy rằng một mô thức huấn luyện không tự hồi quy để tạo hình ảnh raster là khả thi. Những phương pháp này sử dụng Transformer hai chiều (tức là BERT) làm kiến trúc mô hình cơ bản. Việc rời khỏi mô hình hóa tự hồi quy sang không tự hồi quy cho phép dự đoán song song của nhiều token, và mở ra cánh cửa cho các tác vụ chỉnh sửa hình ảnh đa dạng như inpainting. Chúng tôi khám phá khả năng sử dụng BERT để tạo ra các chuỗi token SVG, như một thay thế cho sơ đồ che dấu "nhân quả" của chúng tôi. Đáng chú ý là, không giống như tạo hình ảnh raster thường có độ dài cố định, tạo icon SVG mong đợi các chuỗi đầu ra có độ dài khác nhau như một biểu hiện của đa dạng tạo. Điều này làm cho nó trở thành một tác vụ khó khăn hơn vì trong tạo icon SVG, BERT cần không chỉ mô hình hóa khả năng của các token tiếp theo mà còn xác định nơi để kết thúc chuỗi.

Sau khi huấn luyện mô hình BERT trên cùng tập dữ liệu như chúng tôi, chúng tôi đánh giá chất lượng và đa dạng tạo của các đầu ra của nó. Đánh giá định lượng được tiến hành tương tự như DeepSVG+GAN trong cả tạo ngẫu nhiên (Bảng 2a) và có hướng dẫn văn bản (Bảng 2b). BERT tạo ra kết quả tệ hơn trong cả hai tác vụ so với chúng tôi và DeepSVG+GAN. Kết quả định tính trong Hình 5 cũng gợi ý rằng BERT chỉ có thể tạo ra các hình dạng hình học đơn giản như hình tròn và hình chữ nhật tương đối nhạt nhẽo. Một kiểm tra kỹ hơn của các token được điền cho thấy rằng token end-of-SVG, <EOS>, có thể thường xuyên xuất hiện ở nhiều vị trí do dự đoán song song, dẫn đến kết thúc sớm khi tái tạo các icon SVG. Do đó, mặc dù có khả năng ấn tượng của BERT không tự hồi quy trong chỉnh sửa chuỗi, nó kém hơn so với đối tác tự hồi quy (như trong IconShop) trong việc mô hình hóa và tạo ra các chuỗi có độ dài khác nhau.

4.3 So sánh với Nghệ thuật Hiện đại

Chúng tôi so sánh IconShop được đề xuất với hai loại sơ đồ tạo văn bản thành SVG: phương pháp dựa trên hình ảnh và ngôn ngữ. Đối với phương pháp trước, chúng tôi sử dụng Stable Diffusion [Rombach et al. 2022] để tạo hình ảnh raster, được chuyển đổi thành hình ảnh SVG bằng chương trình LIVE [Ma et al. 2022]. Để khuyến khích kết quả kiểu icon, chúng tôi bao gồm các từ khóa (như "monochrome" và "line art") trong các lời nhắc văn bản. Đối với phương pháp sau, chúng tôi sử dụng GPT-4, có lẽ là LLM hoạt động tốt nhất cho đến nay, để tạo script SVG trực tiếp. Để khởi tạo cuộc trò chuyện, chúng tôi cung cấp một lời nhắc văn bản ở cấp hệ thống yêu cầu nó hoạt động như một bộ tạo mã SVG.

Hình 6 hiển thị các icon được tổng hợp bởi các phương pháp cạnh tranh. Chúng tôi thấy rằng kết quả của mô hình Stable Diffusion thường không đạt được kỳ vọng. Sau tất cả, nó được huấn luyện trên hình ảnh raster, mà như mong đợi gặp khó khăn trong việc tạo ra hình ảnh kiểu icon ngay cả với một số kỹ thuật prompt engineering. Sau khi áp dụng LIVE, các icon SVG kết quả thường trình bày các cấu trúc không mượt mà và không nhất quán, nhiều trong số chúng không thể nhận biết về mặt ngữ nghĩa. Ngoài ra, Stable Diffusion không hiệu quả trong tạo do việc tối ưu hóa lặp dựa trên tối ưu hóa bởi LIVE. Đối với phương pháp dựa trên ngôn ngữ, GPT-4 có khả năng tương đối mạnh trong việc tạo script icon SVG hoàn toàn từ lời nhắc văn bản, với sự liên kết văn bản-SVG vừa phải. Tuy nhiên, kết quả được biểu hiện như các kết hợp đơn giản của các hình dạng nguyên thủy không có lớp phủ phức tạp, không đủ cho thiết kế đồ họa, và cũng gặp vấn đề khả năng nhận biết (xem hàng thứ ba và thứ năm). Ngược lại, IconShop của chúng tôi tạo ra kết quả với chất lượng hình ảnh cao nhất về tính nhất quán hình thức, độ chính xác cao của khả năng nhận biết và sự liên kết văn bản-SVG, và sự đơn giản hình học. Đa dạng tạo hợp lý cũng được quan sát tốt từ IconShop. Thêm kết quả hình ảnh của tạo có hướng dẫn văn bản có thể được tìm thấy trong trang dự án của chúng tôi.

4.4 Nghiên cứu Người dùng Chủ quan

Để xác thực chính thức các lợi ích về nhận thức bởi IconShop, chúng tôi tiến hành một nghiên cứu người dùng chủ quan, bao gồm ba tác vụ để đánh giá hình ảnh 1) chất lượng tạo ngẫu nhiên, 2) chất lượng tạo có hướng dẫn văn bản, và 3) sự liên kết văn bản-SVG. Trong tác vụ đầu tiên, trước tiên chúng tôi làm quen người dùng với các icon chất lượng cao từ tập huấn luyện. Sau đó chúng tôi trình bày cho họ tổng cộng 15×5 icon theo thứ tự ngẫu nhiên, một phần năm trong số đó được tạo bởi (hoặc lấy mẫu từ) DeepSVG+GAN, Stable Diffusion+LIVE, GPT-4, IconShop, và FIGR-8-SVG, tương ứng. Người dùng bị buộc đưa ra quyết định nhị phân về việc mỗi icon được trình bày có chất lượng cao hay không. Trong tác vụ thứ hai, chúng tôi ngẫu nhiên chọn mười lời nhắc văn bản, và tạo các icon tương ứng bằng bốn phương pháp cạnh tranh. Sau đó người dùng được yêu cầu chọn hai icon mà họ tin là có chất lượng hình ảnh tốt nhất. Thiết lập của tác vụ thứ ba giống hệt với tác vụ thứ hai. Sự khác biệt là lần này người dùng cần chọn hai icon phù hợp nhất với lời nhắc văn bản tương ứng.

Chúng tôi tiến hành nghiên cứu người dùng thông qua bảng câu hỏi trực tuyến, với 79 người dùng tham gia nghiên cứu. Đối với tác vụ đầu tiên, chúng tôi thu được 79 (người dùng) × 15 (icon) × 5 (phương pháp) = 5,925 đánh giá của con người. Chúng tôi tính tỷ lệ trung bình của các icon chất lượng cao được xác định bởi người dùng cho mỗi phương pháp, và liệt kê kết quả trong hàng đầu tiên của Bảng 3. Chúng ta thấy rằng IconShop tiếp cận hiệu suất so với "Dataset" như giới hạn trên, và rõ ràng tốt hơn ba phương pháp khác. Điều này cho thấy IconShop có thể tạo ra các icon chất lượng cao mà liên tục "đánh lừa" các đối tượng trong cài đặt tạo ngẫu nhiên (vô điều kiện).

Đối với tác vụ thứ hai và thứ ba, chúng tôi, tương ứng, thu thập 79 (người dùng) × 10 (lời nhắc văn bản) × 2 (lựa chọn) = 1,580 đánh giá của con người cho mỗi tác vụ. Chúng tôi báo cáo tỷ lệ trung bình của các icon được người dùng chọn bởi mỗi phương pháp trong hai hàng cuối của Bảng 3. Rõ ràng là các icon được tổng hợp bởi IconShop được chọn thường xuyên nhất, cho thấy chất lượng cao nhất và sự liên kết văn bản-SVG tốt nhất trong tác vụ tạo có hướng dẫn văn bản. Chúng tôi cũng thực hiện các kiểm định ANalysis Of VAriance (ANOVA) một chiều, và các giá trị p của ba tác vụ đều nhỏ hơn 0.001, gợi ý rằng các lợi ích về nhận thức bởi IconShop có ý nghĩa thống kê. Tóm lại, IconShop được đề xuất chứng minh chất lượng cao nhất cho cả tạo ngẫu nhiên và có hướng dẫn văn bản, với sự liên kết văn bản-SVG mạnh mẽ.

5 ỨNG DỤNG

Trong mục này, chúng tôi khám phá bốn ứng dụng thực tế của IconShop: chỉnh sửa icon, nội suy icon, kết hợp ngữ nghĩa icon, và gợi ý tự động thiết kế icon. Những ứng dụng này hợp lý hóa quá trình tổng hợp icon vector, nâng cao đáng kể năng suất và trải nghiệm của người dùng.

5.1 Chỉnh sửa Icon

Nhờ việc thống nhất mô hình hóa không tự hồi quy và tự hồi quy thông qua chiến lược che dấu "nhân quả" được nêu trong Mục 3.3, IconShop được đề xuất tạo điều kiện cho việc chỉnh sửa icon như được minh họa trong Hình 7. IconShop có khả năng điền vào nội dung bị thiếu dựa trên ngữ cảnh hai chiều, trong tình huống tạo ngẫu nhiên hoặc có hướng dẫn văn bản. Điều này dẫn đến việc khôi phục chính xác, nhất quán và đa dạng các đường dẫn bị thiếu trong các icon.

5.2 Nội suy Icon

Các mô hình văn bản thành hình ảnh chứng minh khả năng ấn tượng để kết hợp các đầu vào văn bản, khuyến khích tạo ra các khái niệm mới không tồn tại trong dữ liệu huấn luyện, như "avocado chair" được tạo bởi DALL·E [Ramesh et al. 2021]. Trong các thí nghiệm của chúng tôi, chúng tôi thấy rằng IconShop cũng học cách tạo ra các kết hợp sáng tạo và hợp lý, như được hiển thị trong Hình 9.

5.3 Kết hợp Ngữ nghĩa Icon

Các mô hình văn bản thành hình ảnh chứng minh khả năng ấn tượng để kết hợp các đầu vào văn bản, cho phép chúng tạo ra các khái niệm mới không tồn tại trong dữ liệu huấn luyện, như "avocado chair" được tạo bởi DALL·E [Ramesh et al. 2021]. Trong các thí nghiệm của chúng tôi, chúng tôi thấy rằng mô hình của chúng tôi cũng có thể tạo ra các kết hợp sáng tạo và sáng tạo, như được hiển thị trong Hình 9.

5.4 Gợi ý Tự động Thiết kế Icon

Một lợi thế của tạo icon tự động là hỗ trợ cả nhà thiết kế và người không chuyên trong việc thể hiện ý tưởng sáng tạo của họ. Một tính năng mong muốn của hệ thống tự động như vậy là khả năng gợi ý các vị trí có thể cho các đường dẫn tiếp theo trên canvas, điều này sẽ cải thiện đáng kể hiệu quả công việc và năng suất. Dựa vào transformer tự hồi quy, IconShop được huấn luyện của chúng tôi có thể dự đoán đường dẫn tiếp theo mà người dùng có thể chọn trong quá trình tạo icon của họ (xem Hình 10). Vui lòng tham khảo trang dự án cho các bản demo video của hệ thống gợi ý tự động của chúng tôi cho thiết kế icon SVG.

6 KẾT LUẬN

Chúng tôi đã giới thiệu IconShop, một phương pháp dựa trên transformer tự hồi quy thành thạo trong việc tạo icon vector từ mô tả văn bản. IconShop nổi bật từ cả phương pháp dựa trên hình ảnh kết hợp tạo văn bản thành hình ảnh và vector hóa hình ảnh, và các kỹ thuật dựa trên ngôn ngữ coi script SVG như ngôn ngữ tự nhiên. Các thí nghiệm toàn diện thể hiện hiệu quả và tính linh hoạt của IconShop về chất lượng tạo, đa dạng, sự liên kết văn bản-icon, và khả năng ứng dụng rộng rãi.

IconShop thể hiện hiệu suất tổng hợp icon SVG ấn tượng bằng cách khai thác bản chất tuần tự của script SVG và thống nhất mô hình hóa không tự hồi quy và tự hồi quy, nhưng nó không phải là không có hạn chế (xem Hình 11). Thứ nhất, các cụm từ và câu ngôn ngữ tự nhiên được tạo bởi ChatGPT có thể vô tình dẫn đến sự không khớp văn bản-SVG. Vấn đề này có thể được giảm thiểu bằng cách sử dụng tập dữ liệu SVG chất lượng cao hơn với chú thích văn bản chính xác hoặc bằng lọc của con người. Thứ hai, hiệu suất kết hợp icon ngữ nghĩa bởi IconShop có thể không đáng chú ý như tạo văn bản thành hình ảnh, vì hầu hết các icon trong tập dữ liệu FIGR-8-SVG chứa một đối tượng duy nhất nằm ở trung tâm, chiếm một phần đáng kể của không gian. Chúng tôi tin rằng việc tăng cường dữ liệu thích hợp như tỷ lệ và hợp nhất dữ liệu SVG để tạo ra các icon mới có tiềm năng cải thiện đáng chú ý hiệu suất kết hợp. Cuối cùng, IconShop bị hạn chế trong việc tạo icon đen trắng, nhưng nó có thể tiềm năng được mở rộng để tạo ra các icon nhiều màu hoặc nội dung SVG tổng quát hơn (ví dụ: clip art) với các sửa đổi thích hợp.

TÀI LIỆU THAM KHẢO

[Danh sách tài liệu tham khảo được giữ nguyên theo bản gốc do đây là phần chuẩn của bài báo học thuật]

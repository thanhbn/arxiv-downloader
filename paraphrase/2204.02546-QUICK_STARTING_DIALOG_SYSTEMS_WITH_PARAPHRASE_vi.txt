# 2204.02546.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/paraphrase/2204.02546.pdf
# Kích thước tệp: 248908 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
KHỞI ĐỘNG NHANH CÁC HỆ THỐNG DIALOG BẰNG SINH PARAPHRASE
BẢN THẢO TRƯỚC KHI IN
Louis Marceau, Raouf Belbahar, Marc Queudot
Ngân hàng Quốc gia Canada
Montreal, QC, Canada
{louis.marceau,raoufmoncef.belbahar,marc.queudot}@bnc.caNada Naji
nada.aj.naji@gmail.com
Éric Charton
Ngân hàng Quốc gia Canada
Montreal, QC, Canada
eric.charton@bnc.ca
Marie-Jean Meurs
Université du Québec à Montréal
Montreal, QC, Canada
meurs.marie-jean@uqam.ca
TÓM TẮT
Việc thu thập dữ liệu huấn luyện để cải thiện độ bền vững của các hệ thống dialog có thể là một quá trình vô cùng tốn thời gian. Trong nghiên cứu này, chúng tôi đề xuất một phương pháp để giảm chi phí và công sức tạo ra các tác nhân hội thoại mới bằng cách sinh thêm dữ liệu nhân tạo từ các ví dụ hiện có, sử dụng sinh paraphrase. Cách tiếp cận đề xuất của chúng tôi có thể khởi động một hệ thống dialog với ít công sức con người và đưa hiệu suất của nó lên mức đủ thỏa mãn để cho phép tương tác thực tế với người dùng cuối thực sự. Chúng tôi thực nghiệm với hai cách tiếp cận paraphrase thần kinh, đó là Dịch máy Thần kinh và mô hình seq2seq dựa trên Transformer. Chúng tôi trình bày kết quả thu được trên hai tập dữ liệu bằng tiếng Anh và tiếng Pháp: một tập dữ liệu phân loại ý định thu thập từ đám đông công khai và tập dữ liệu hệ thống dialog doanh nghiệp của chúng tôi. Chúng tôi chỉ ra rằng cách tiếp cận đề xuất của chúng tôi đã tăng khả năng tổng quát hóa của mô hình phân loại ý định trên cả hai tập dữ liệu, giảm công sức cần thiết để khởi tạo một hệ thống dialog mới và giúp triển khai công nghệ này ở quy mô lớn trong một tổ chức.
Từ khóa Chatbot Hệ thống Dialog Sinh Paraphrase Xử lý Ngôn ngữ Tự nhiên
1 Giới thiệu
Các hệ thống dialog đang trở nên ngày càng phổ biến như trợ lý cá nhân và giao diện tìm kiếm thông tin. Trong bối cảnh hỗ trợ khách hàng, các hệ thống dialog ngày nay đang đóng vai trò quan trọng như một kênh liên lạc bổ sung để phản hồi các truy vấn khách hàng lặp lại Ganhotra et al. [2019]. Tuy nhiên, khối lượng dữ liệu huấn luyện có sẵn không đủ cũng như công sức khổng lồ cần thiết để thu thập dữ liệu đó cản trở việc phát triển các hệ thống AI hội thoại bền vững theo miền cụ thể Schuster et al. [2018]. Các hệ thống dialog trải qua một quá trình dài hướng tới sự trưởng thành nơi khối lượng dữ liệu đáng kể cần được thu thập để đạt mức hiệu suất thỏa mãn, phù hợp cho người dùng thực tế.
Trong bối cảnh các hệ thống dialog hỏi đáp, chúng ta thường đề cập đến ý định là việc phân loại các nhu cầu thông tin khác nhau hoặc các câu hỏi có thể mà người dùng có. Những ý định này được định nghĩa bằng cách sử dụng các quan sát hiện có, và chúng hoạt động như các lớp trong mô hình Hiểu Ngôn ngữ Tự nhiên (NLU) của hệ thống dialog. Mô hình như vậy cố gắng liên kết một tin nhắn người dùng đến với một trong những ý định được định nghĩa trước để sau đó chọn một phản hồi phù hợp.
Người dùng có thể diễn đạt cùng một câu hỏi bằng nhiều cách khác nhau. Ví dụ, "Tôi đã quên mật khẩu, tôi có thể làm gì?" và "không nhớ mã truy cập của tôi" đều được liên kết với cùng một ý định nhưng được diễn đạt khác nhau. Tạo ra khối lượng đủ lớn các ví dụ huấn luyện bao phủ những biến thể như vậy là một quá trình tốn nhiều lao động. Điều này đặc biệt đúng đối với các hệ thống dialog chứa hàng trăm ý định. Khi xây dựng một hệ thống dialog mới trong môi trường công nghiệp thực tế, tập dữ liệu ban đầu của các quan sát thường được xây dựng từ các trang Câu hỏi Thường gặp (FAQ) hoặc các câu hỏi được hỏi cho các tác nhân con người. Mặc dù tập dữ liệu này nên càng phong phú và đầy đủ càng tốt để được sử dụng làm tập huấn luyện, nhưng hiếm khi có thể thu thập nhiều mẫu cho mỗi ý định tại thời điểm này. Do đó, một lượng mẫu huấn luyện nhất định cho mỗi ý định phải được thu thập để đạt mức hiệu suất đủ để hệ thống có thể tiếp xúc với người dùng thực tế với rủi ro tối thiểu.
Ngoài ra, vì các hệ thống dialog khác nhau bao phủ các trường hợp sử dụng khác nhau, tác vụ thu thập dữ liệu này phải được lặp lại mỗi khi một hệ thống mới được tạo ra. Điều này có thể gây vấn đề khi cố gắng triển khai các hệ thống này trong một tổ chức ở quy mô lớn. Khi số lượng hệ thống dialog tăng lên, tài nguyên và công sức cần thiết để tạo ra và duy trì chúng cũng tăng theo.
Giải pháp chúng tôi đề xuất cho vấn đề này dựa trên việc sinh các paraphrase nhân tạo dựa trên các quan sát hiện có trong quá trình thiết kế một hệ thống dialog mới, nhằm tăng khối lượng mẫu huấn luyện cho mỗi ý định. Các paraphrase được sinh nhân tạo sẽ giúp tăng hiệu suất của mô hình phân loại ý định
Trước khi triển khai một hệ thống dialog mới trong bối cảnh công nghiệp, hệ thống phải đạt một mức hiệu suất nhất định - trên một ngưỡng cho trước - để giảm thiểu rủi ro và sự không hài lòng liên quan đến một hệ thống hoạt động kém. Việc đạt ngưỡng này thường đến từ việc thu thập thêm dữ liệu cho mỗi ý định. Các mẫu nhân tạo có thể giúp tăng khả năng tổng quát hóa của mô hình phân loại ý định vượt qua ngưỡng này, do đó cho phép hệ thống tiếp xúc với người dùng cuối.
Trong bối cảnh của chúng tôi, các mẫu huấn luyện cho một ý định nhất định là paraphrase vì chúng sử dụng từ ngữ và cú pháp khác nhau nhưng có cùng nội dung ngữ nghĩa. Mục tiêu của tác vụ này không phải là thay thế dữ liệu thực tế, mà là khởi động hệ thống dialog trong khi tránh chi phí tạo thêm dữ liệu thủ công.
Để thực hiện tác vụ sinh paraphrase, chúng tôi so sánh các cách tiếp cận thần kinh khác nhau để bổ sung dữ liệu huấn luyện của chúng tôi. Cách đầu tiên dựa trên Dịch máy Thần kinh (NMT) Mallinson et al. [2017]. Trong cách tiếp cận này, các mẫu dữ liệu được dịch sang một ngôn ngữ khác, được gọi là ngôn ngữ pivot và sau đó kết quả được dịch ngược về ngôn ngữ nguồn. Các bản dịch thu được sau bước này sẽ được coi là paraphrase tiềm năng.
Phương pháp thứ hai chúng tôi đề xuất bao gồm việc trực tiếp xuất paraphrase bằng cách sử dụng một mạng thần kinh được huấn luyện cho sinh văn bản. Mạng thần kinh này sử dụng kiến trúc encoder-decoder của Transformer Vaswani et al. [2017], đã đạt kết quả tốt nhất trong nhiều tác vụ Xử lý Ngôn ngữ Tự nhiên (NLP). Các mô hình ngôn ngữ transformer lớn (LMs) như GPT-2 Radford et al. [2019], BERT Devlin et al. [2019] hoặc T5 Raffel et al. [2019] có thể học được những biểu diễn mạnh mẽ của dữ liệu và cũng có thể được tinh chỉnh cho một tác vụ hạ lưu cụ thể, như sinh paraphrase.
Cách tiếp cận của chúng tôi cải thiện đáng kể hiệu suất của mô hình phân loại ý định với ít hoặc không có sự can thiệp của con người, do đó, giảm cả chi phí để xây dựng một tập huấn luyện ban đầu và thời gian đưa ra thị trường để triển khai hệ thống dialog. Một khi hệ thống được đưa vào sản xuất, nó có thể bắt đầu thu thập dữ liệu thực từ các tương tác với người dùng cuối.
Sử dụng cách tiếp cận này, các hệ thống dialog có thể được triển khai ở quy mô lớn trong một tổ chức mà không cần chi phí khổng lồ liên quan đến việc tạo thủ công dữ liệu huấn luyện cho mỗi ý định.
Phần còn lại của bài báo này được tổ chức như sau: Phần 2 khảo sát các nghiên cứu liên quan trước đây trong lĩnh vực hệ thống dialog, tính sẵn có của tập dữ liệu và bổ sung. Phần 3 trình bày chi tiết các tập dữ liệu mà chúng tôi đã sử dụng trong các thí nghiệm. Trong Phần 4, chúng tôi trình bày thiết lập thí nghiệm của nghiên cứu bao gồm kiến trúc của các cách tiếp cận đề xuất. Khung đánh giá được trình bày trong Phần 5. Phần 6 báo cáo kết quả đạt được trên các tập dữ liệu phân loại ý định khác nhau và thảo luận về tác động của việc sử dụng paraphrase trong bổ sung tập huấn luyện cho các mô hình NLU. Cuối cùng, Phần 7 kết luận nghiên cứu này và khám phá các hướng tương lai có thể.

--- TRANG 2 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN
có thể thu thập nhiều mẫu cho mỗi ý định tại thời điểm này. Do đó, một lượng mẫu huấn luyện nhất định cho mỗi ý định phải được thu thập để đạt mức hiệu suất đủ để hệ thống có thể tiếp xúc với người dùng thực tế với rủi ro tối thiểu.
Ngoài ra, vì các hệ thống dialog khác nhau bao phủ các trường hợp sử dụng khác nhau, tác vụ thu thập dữ liệu này phải được lặp lại mỗi khi một hệ thống mới được tạo ra. Điều này có thể gây vấn đề khi cố gắng triển khai các hệ thống này trong một tổ chức ở quy mô lớn. Khi số lượng hệ thống dialog tăng lên, tài nguyên và công sức cần thiết để tạo ra và duy trì chúng cũng tăng theo.
Giải pháp chúng tôi đề xuất cho vấn đề này dựa trên việc sinh các paraphrase nhân tạo dựa trên các quan sát hiện có trong quá trình thiết kế một hệ thống dialog mới, nhằm tăng khối lượng mẫu huấn luyện cho mỗi ý định. Các paraphrase được sinh nhân tạo sẽ giúp tăng hiệu suất của mô hình phân loại ý định
Trước khi triển khai một hệ thống dialog mới trong bối cảnh công nghiệp, hệ thống phải đạt một mức hiệu suất nhất định - trên một ngưỡng cho trước - để giảm thiểu rủi ro và sự không hài lòng liên quan đến một hệ thống hoạt động kém. Việc đạt ngưỡng này thường đến từ việc thu thập thêm dữ liệu cho mỗi ý định. Các mẫu nhân tạo có thể giúp tăng khả năng tổng quát hóa của mô hình phân loại ý định vượt qua ngưỡng này, do đó cho phép hệ thống tiếp xúc với người dùng cuối.
Trong bối cảnh của chúng tôi, các mẫu huấn luyện cho một ý định nhất định là paraphrase vì chúng sử dụng từ ngữ và cú pháp khác nhau nhưng có cùng nội dung ngữ nghĩa. Mục tiêu của tác vụ này không phải là thay thế dữ liệu thực tế, mà là khởi động hệ thống dialog trong khi tránh chi phí tạo thêm dữ liệu thủ công.
Để thực hiện tác vụ sinh paraphrase, chúng tôi so sánh các cách tiếp cận thần kinh khác nhau để bổ sung dữ liệu huấn luyện của chúng tôi. Cách đầu tiên dựa trên Dịch máy Thần kinh (NMT) Mallinson et al. [2017]. Trong cách tiếp cận này, các mẫu dữ liệu được dịch sang một ngôn ngữ khác, được gọi là ngôn ngữ pivot và sau đó kết quả được dịch ngược về ngôn ngữ nguồn. Các bản dịch thu được sau bước này sẽ được coi là paraphrase tiềm năng.
Phương pháp thứ hai chúng tôi đề xuất bao gồm việc trực tiếp xuất paraphrase bằng cách sử dụng một mạng thần kinh được huấn luyện cho sinh văn bản. Mạng thần kinh này sử dụng kiến trúc encoder-decoder của Transformer Vaswani et al. [2017], đã đạt kết quả tốt nhất trong nhiều tác vụ Xử lý Ngôn ngữ Tự nhiên (NLP). Các mô hình ngôn ngữ transformer lớn (LMs) như GPT-2 Radford et al. [2019], BERT Devlin et al. [2019] hoặc T5 Raffel et al. [2019] có thể học được những biểu diễn mạnh mẽ của dữ liệu và cũng có thể được tinh chỉnh cho một tác vụ hạ lưu cụ thể, như sinh paraphrase.
Cách tiếp cận của chúng tôi cải thiện đáng kể hiệu suất của mô hình phân loại ý định với ít hoặc không có sự can thiệp của con người, do đó, giảm cả chi phí để xây dựng một tập huấn luyện ban đầu và thời gian đưa ra thị trường để triển khai hệ thống dialog. Một khi hệ thống được đưa vào sản xuất, nó có thể bắt đầu thu thập dữ liệu thực từ các tương tác với người dùng cuối.
Sử dụng cách tiếp cận này, các hệ thống dialog có thể được triển khai ở quy mô lớn trong một tổ chức mà không cần chi phí khổng lồ liên quan đến việc tạo thủ công dữ liệu huấn luyện cho mỗi ý định.
Phần còn lại của bài báo này được tổ chức như sau: Phần 2 khảo sát các nghiên cứu liên quan trước đây trong lĩnh vực hệ thống dialog, tính sẵn có của tập dữ liệu và bổ sung. Phần 3 trình bày chi tiết các tập dữ liệu mà chúng tôi đã sử dụng trong các thí nghiệm. Trong Phần 4, chúng tôi trình bày thiết lập thí nghiệm của nghiên cứu bao gồm kiến trúc của các cách tiếp cận đề xuất. Khung đánh giá được trình bày trong Phần 5. Phần 6 báo cáo kết quả đạt được trên các tập dữ liệu phân loại ý định khác nhau và thảo luận về tác động của việc sử dụng paraphrase trong bổ sung tập huấn luyện cho các mô hình NLU. Cuối cùng, Phần 7 kết luận nghiên cứu này và khám phá các hướng tương lai có thể.

2 Nghiên cứu Liên quan
Các hệ thống dialog đã phát triển mạnh mẽ trong thập kỷ qua theo sự tiến bộ của deep learning. Các hệ thống hỏi đáp và trợ lý ảo như Alexa và Siri đã trở nên ngày càng phổ biến Gao et al. [2019], Chen et al. [2017a,b]. Khi nói đến việc xây dựng các hệ thống dialog mới, một trong những thách thức chính là thu thập dữ liệu huấn luyện hội thoại. Một số sáng kiến đã cung cấp các tập dữ liệu hội thoại như Ubuntu Dialog Corpus Lowe et al. [2015], tập dữ liệu phân loại ý định thu thập từ đám đông, có sẵn công khai Kang et al. [2018], tập dữ liệu ý định trong phạm vi và ngoài phạm vi CLINC150 Larson et al. [2019], và CAsT-19 Dataset (TREC Complex Answer Track) Dalton et al. [2020]. Serban et al. [2015] đã khảo sát các tập dữ liệu có sẵn công khai để phát triển hệ thống Dialog. Các tác giả thường mô tả quá trình xây dựng các tập dữ liệu như vậy là, không ngạc nhiên, đắt đỏ và tốn nhiều lao động.
Mặc dù các tập dữ liệu như vậy tạo thành một nguồn có giá trị để khám phá, chúng có tác dụng hạn chế khi nói đến việc xây dựng các hệ thống chất lượng sản xuất, dành riêng cho miền cụ thể, ví dụ trong các lĩnh vực y tế hoặc tài chính1.
Bổ sung dữ liệu thường được sử dụng trong thị giác máy tính và xử lý hình ảnh. Các biến đổi cơ bản như cắt, xoay và thêm nhiễu Gaussian được áp dụng cho hình ảnh để tăng kích thước của dữ liệu huấn luyện và giảm overfitting Badimala et al. [2019], Krizhevsky et al. [2012], Deng et al. [2009]. Các tác vụ NLP, như phân loại văn bản hoặc phát hiện tương tự câu, tận dụng ý tưởng này bằng cách áp dụng các biến đổi như xáo trộn (thay đổi thứ tự của tokens hoặc câu), hoặc kết hợp từ đồng nghĩa và embeddings Badimala et al. [2019], Wang and Yang [2015], Papadaki [2017]. Ngoài ra, paraphrase có thể được sử dụng để biến đổi văn bản bằng cách truyền tải cùng nghĩa theo những cách thay thế trong cùng ngôn ngữ tự nhiên. Một số phương pháp NLP đã được sử dụng trong quá khứ để sinh paraphrase. Các cách tiếp cận dựa trên quy tắc đã được khám phá với các bộ quy tắc hoặc mẫu được tạo thủ công để sinh paraphrase McKeown [2]. Các phương pháp khác sử dụng cách tiếp cận corpus đơn ngữ hoặc song ngữ. Ví dụ, Bannard and Callison-Burch [2005] đã đề xuất một cách tiếp cận sử dụng corpus song ngữ với các cặp câu được dịch để thu được paraphrase trong tiếng Anh bằng cách pivoting thông qua ngôn ngữ khác, như tiếng Pháp hoặc tiếng Đức. Ý tưởng này được đẩy xa hơn nữa bằng cách sử dụng các mô hình NMT để pivot, và sinh paraphrase tự động trong ngôn ngữ nguồn Mallinson et al. [2017], Sokolov and Filimonov [2020]. Theo hướng này, Junczys-Dowmunt et al. [2018] đã giới thiệu Marian, một framework NMT mã nguồn mở được phát triển trên backend deep-learning dựa trên reverse-mode auto-differentiation với đồ thị tính toán động. Chúng tôi mô tả việc sử dụng Marian trong Phần 4.1. Gần đây hơn, các mô hình ngôn ngữ lớn đã chỉ ra rằng chúng cực kỳ hiệu quả cho nhiều tác vụ NLP bao gồm sinh văn bản. Các mô hình như vậy đã được tinh chỉnh với tập dữ liệu paraphrase để phục vụ như các bộ sinh paraphrase Witteveen and Andrews [2019]. Paraphrase đã được sử dụng trong các tác vụ tóm tắt và phát hiện đạo văn Barrón-Cedeño et al. [2013], trong số những tác vụ khác, nhưng chưa được khám phá kỹ lưỡng trong việc bổ sung các corpus hội thoại, theo hiểu biết tốt nhất của chúng tôi. Trong bài báo này, chúng tôi đề xuất một cách tiếp cận chi phí thấp để nhanh chóng phát triển một tập dữ liệu huấn luyện nhỏ với việc sử dụng paraphrase dựa trên dịch máy và các mô hình ngôn ngữ lớn. Phần tiếp theo chi tiết các tập dữ liệu được sử dụng để kiểm tra các phương pháp bổ sung dữ liệu của chúng tôi.

3 Tập dữ liệu
Chúng tôi sử dụng hai tập dữ liệu khác nhau trong các thí nghiệm. Tập dữ liệu đầu tiên là tập dữ liệu CLINC1502. Nó được xây dựng cho tác vụ đánh giá phân loại ý định Larson et al. [2019]. Tập dữ liệu này chứa 150 ý định và một số dữ liệu ngoài phạm vi, có nghĩa là các mẫu không được liên kết với một trong những ý định. Các ý định chủ yếu tương ứng với các truy vấn hướng tác vụ (ví dụ, "chuyển 100 đô la từ tiết kiệm sang séc của tôi") mặc dù một số truy vấn liên quan đến thông tin tổng quát cũng có thể được tìm thấy (ví dụ, "tôi sử dụng ngày nghỉ phép như thế nào"). Dữ liệu ngoài phạm vi tạo thành các utterances hoặc tin nhắn không được liên kết với bất kỳ ý định nào trong phạm vi và do đó không mang bất kỳ lợi ích nào cho tác vụ đang xem xét. Do đó, chúng tôi chỉ sử dụng tập dữ liệu trong phạm vi trong các thí nghiệm.
Tập dữ liệu trong phạm vi (SCOPE) được cấu thành từ 22.500 truy vấn bao phủ 150 ý định, tương ứng với mười miền: banking, work, meta, Auto & commute, home, travel, utility, kitchen and dining, small talk và credit cards. SCOPE được chia thành các tập huấn luyện, xác thực và kiểm tra. Tập huấn luyện chứa 100 mẫu cho mỗi ý định, do đó cho tổng cộng 15.000 mẫu huấn luyện, trong khi tập xác thực và kiểm tra có 20 và 30 mẫu cho mỗi ý định tương ứng. Chúng tôi tạo ra một số phân vùng của tập huấn luyện bằng cách lấy mẫu ngẫu nhiên 5, 10 và 50 mẫu huấn luyện cho mỗi ý định để đo lường tác động của paraphrase trên các tập dữ liệu có kích thước khác nhau. Chúng tôi gọi các tập này là SCOPE-train-5, SCOPE-train-10, và SCOPE-train-50, tương ứng. Tập kiểm tra gốc được sử dụng để đánh giá các phương pháp bổ sung dữ liệu khác nhau. Nó được cấu thành từ 4.500 mẫu huấn luyện, 30 mẫu cho mỗi trong số 150 ý định. Chúng tôi gọi tập này là SCOPE-test. Cuối cùng, chúng tôi bỏ qua tập xác thực vì cấu hình và siêu tham số của mô hình NLU được giữ không đổi trong suốt các thí nghiệm khác nhau.
Tập dữ liệu thứ hai là tập dữ liệu dialog nội bộ, có nguồn gốc từ lần lặp đầu tiên của hệ thống dialog hỏi đáp hiện đang được triển khai trên trang web doanh nghiệp và nền tảng giao dịch. Chúng tôi gọi tập dữ liệu này là HOUSE. Nó được xây dựng bằng cách định nghĩa ý định dựa trên các câu hỏi được trích xuất từ Phần FAQ của trang web doanh nghiệp, và tạo thủ công một số công thức khác nhau cho mỗi câu hỏi. Điều này được thực hiện như một bước đầu tiên hướng tới việc phát triển một hệ thống dialog để trả lời các câu hỏi thường gặp của khách hàng, như cách thay đổi mật khẩu hoặc thực hiện một giao dịch cụ thể.
Sau đó chúng tôi chia tập dữ liệu được tạo thủ công này thành các tập huấn luyện và kiểm tra. Đáng chú ý là tập dữ liệu HOUSE hoàn toàn bằng tiếng Pháp. Tập huấn luyện bao gồm 73 mẫu huấn luyện, mỗi trong số 20 ý định được liên kết với ba đến sáu mẫu. Chúng tôi gọi tập này là HOUSE-train. Tập kiểm tra được cấu thành từ 77 mẫu tổng cộng, với một đến 11 mẫu cho mỗi ý định. Chúng tôi gọi tập này là HOUSE-test. Chúng tôi sử dụng một phiên bản gần đây hơn của tập kiểm tra để có nhiều mẫu kiểm tra hơn, nhưng chỉ giữ lại 20 ý định ban đầu. Đây là lý do tại sao nó chứa nhiều mẫu hơn tập huấn luyện.
Bảng 1 và 2 tóm tắt các đặc điểm của các tập dữ liệu nêu trên.

4 Phương pháp và Thí nghiệm
Trong Phần này, chúng tôi mô tả các cách tiếp cận đề xuất của chúng tôi để bổ sung tập dữ liệu. Tiểu phần 4.1 trình bày paraphrase dựa trên NMT, pivoting xung quanh các ngôn ngữ khác nhau như tiếng Anh, tiếng Đức và tiếng Tây Ban Nha cho tập dữ liệu HOUSE (là

--- TRANG 3 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN

Dataset Ngôn ngữ Tổng ý định Tổng mẫu Ví dụ
HOUSE Tiếng Pháp 20 150 "Comment me connecter au site en ligne si j'ai déjà un compte" (bản dịch: Làm thế nào tôi có thể đăng nhập vào trang web nếu tôi đã có tài khoản)
SCOPE Tiếng Anh 150 5.250 - 12.000 "Is rice ok after 3 days in the refrigerator" (kitchen and dining), "How can I see my rewards for my visa card" (banking)

Bảng 1: Tập dữ liệu được sử dụng trong các thí nghiệm của chúng tôi. HOUSE và SCOPE, tương ứng, đại diện cho tập dữ liệu doanh nghiệp nội bộ của chúng tôi và tập dữ liệu công khai trong phạm vi. Ngôn ngữ nguồn tương ứng và kích thước của chúng được đưa ra, cùng với một ví dụ truy vấn.

bằng tiếng Pháp), và tiếng Pháp và tiếng Đức cho tập dữ liệu SCOPE. Tiểu phần 4.2 trình bày cách tiếp cận thứ hai, sử dụng mô hình ngôn ngữ PEGASUS được tinh chỉnh Zhang et al. [2020] cho tác vụ sinh paraphrase.

4.1 Hệ thống Dựa trên NMT
Các mô hình NMT được huấn luyện trước mà chúng tôi sử dụng được cấu thành từ các mô hình Transformer Vaswani et al. [2017] cùng với các căn chỉnh từ được hướng dẫn dựa trên framework Marian-NMT Junczys-Dowmunt et al. [2018]. Tiền xử lý cần thiết cho các mô hình này bao gồm việc chuẩn hóa dấu câu và sử dụng bộ tokenizer subword độc lập ngôn ngữ SentencePiece Kudo and Richardson [2018] để có tokenization dựa trên subword trong khi được hưởng lợi từ thuật toán regularization được giới thiệu trong bài báo. Bộ tokenizer subword cung cấp những gì tốt nhất của cả tokenization dựa trên từ và dựa trên ký tự: các từ đã biết được tính vào trong từ vựng, và tokenizer cũng có thể sử dụng các đoạn từ và ký tự riêng lẻ cho các từ chưa biết.
Chúng tôi sử dụng một quy trình hai bước, mỗi bước liên quan đến một mô hình NMT. Trong bước đầu tiên, các mẫu huấn luyện được truyền qua mô hình nguồn-đến-pivot (ví dụ tiếng Anh-đến-tiếng Đức) và chúng tôi giữ bản dịch tốt nhất cho mỗi mẫu (xếp hạng bởi mô hình NMT).
Trong bước thứ hai, chúng tôi dịch ngược về ngôn ngữ nguồn (ví dụ tiếng Đức-đến-tiếng Anh) để sinh ra một số biến thể. Thường thì bản dịch tốt nhất đầu tiên (được xếp hạng bởi mô hình NMT) giống hệt với mẫu gốc, và do đó được loại bỏ một cách có hệ thống. Tại thời điểm này, chúng tôi giữ n-best translations tiếp theo như paraphrase của văn bản đầu vào gốc. Chúng tôi thực nghiệm với việc thay đổi giá trị của n, và thấy rằng đặt n bằng sáu cung cấp các biến thể cú pháp và từ vựng liên quan mà không gây ra sự lệch ngữ nghĩa mạnh khỏi các mẫu gốc.

4.2 Hệ thống Dựa trên LM
Hệ thống này tận dụng một mô hình dựa trên transformer được huấn luyện trước sử dụng phương pháp huấn luyện trước PEGASUS. Phương pháp huấn luyện trước tự giám sát PEGASUS được thiết kế cho tóm tắt abstractive mà chuyển giao tốt cho tác vụ sinh paraphrase của chúng tôi. Trong PEGASUS, các câu quan trọng được loại bỏ/che từ một tài liệu đầu vào và mô hình được giao nhiệm vụ khôi phục và xuất chúng trong một chuỗi, tương tự như một bản tóm tắt extractive Zhang et al. [2020]. Theo kiểu mô hình transformer cho sinh văn bản, nó được huấn luyện trước trên một corpus lớn các tài liệu được thu thập từ web.
Cho các thí nghiệm của chúng tôi, chúng tôi sử dụng một phiên bản PEGASUS đã được tinh chỉnh cho sinh paraphrase3. Tập dữ liệu được sử dụng để tinh chỉnh được lọc từ nhiều tập dữ liệu paraphrase như tập dữ liệu PAWS của Google Yang et al. [2019].
Khi sử dụng hệ thống này trên tập dữ liệu bằng tiếng Pháp (HOUSE), chúng tôi thêm một bước dịch sử dụng framework Marian NMT. Trong trường hợp này, chúng tôi sử dụng bản dịch hàng đầu (được chấm điểm bởi mô hình) cho mỗi mẫu trong tập dữ liệu như đầu vào cho mô hình paraphrase. Một lần nữa, chúng tôi lấy 6-best (được chấm điểm cao nhất bởi mô hình) paraphrase được sinh cho mỗi mẫu và dịch chúng ngược về ngôn ngữ nguồn.
Một khi các paraphrase đã được sinh bằng cách sử dụng một trong hai cách tiếp cận (dựa trên NMT hoặc LM), bước tiếp theo trong quy trình là phát hiện và loại bỏ các bản trùng lặp. Mục tiêu của bước này là loại bỏ các công thức lặp lại. Để thực hiện việc khử trùng lặp này, các mẫu gốc và các paraphrase được sinh được truyền qua một bộ chuẩn hóa thực hiện case-folding (đến chữ thường) và de-punctuation. Sau đó, bất kỳ paraphrase nào khớp với bất kỳ mẫu gốc nào được liên kết với một ý định nhất định sẽ được xóa. Kết quả của bước này là một tập hợp các mẫu và paraphrase duy nhất được liên kết với mỗi ý định. Kết quả này tạo thành tập dữ liệu huấn luyện được bổ sung.

3https://huggingface.co/tuner007/pegasus_paraphrase

--- TRANG 4 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN

Như các ví dụ cụ thể, xem xét mẫu "I must apply for a new credit card", được dịch bởi NMT thành "Ich muss eine neue Kreditkarte beantragen" và "Je dois demander une nouvelle carte de crédit" sử dụng tiếng Đức và tiếng Pháp như ngôn ngữ pivot tương ứng. Dưới đây chúng tôi báo cáo ba paraphrase được sinh từ tập 6-best:
Với tiếng Đức như ngôn ngữ pivot, "I need to apply for a new credit card", "I have to request a new credit card", và "I need to request a new credit card";
Với tiếng Pháp như ngôn ngữ pivot: "I need to ask for a new credit card", "I need to request a new credit card", và "I need to apply for a new credit card".
Như có thể thấy, có một số tinh tế đặc trưng ngôn ngữ giữa các paraphrase, như việc sử dụng "ask" từ pivot tiếng Pháp, không có trong tập trước đó nơi tiếng Đức được sử dụng cho pivoting. Đối với các paraphrase được sinh bởi PEGASUS, những cái sau được sinh cho cùng ví dụ: "I need a new credit card", "I need to apply for new credit card", và "I have to apply t for a new credit card." và, thú vị là, "I need a new credit card because I'm looking for a job" mô tả sự lệch mà sinh ngôn ngữ tự nhiên đôi khi có thể giới thiệu. Nó có thể hữu ích để giới thiệu thông tin bổ sung này trong dữ liệu huấn luyện miễn là nó là điều mà người dùng có thể nói cho ý định cụ thể này và nó không hoàn toàn thay đổi nghĩa của câu.

4.3 Baselines và Tập dữ liệu Được bổ sung
Tập dữ liệu HOUSE. Tập huấn luyện cốt lõi HOUSE-train tạo thành baseline cho việc bổ sung trong tập dữ liệu này. Để đánh giá cách tiếp cận bổ sung của chúng tôi sử dụng các cách tiếp cận dựa trên NMT và LM, chúng tôi sinh ra các tập dữ liệu sau sử dụng các bước được mô tả trong Tiểu phần 4.1 và 4.2:
•HOUSE-paraph (NMT-en): được paraphrase với tiếng Anh như ngôn ngữ pivot để sinh paraphrase bằng tiếng Pháp cho mỗi ý định.
•HOUSE-paraph (NMT-de): được paraphrase với tiếng Đức như ngôn ngữ pivot để sinh paraphrase bằng tiếng Pháp cho mỗi ý định.
•HOUSE-paraph (NMT-es): được paraphrase với tiếng Tây Ban Nha như ngôn ngữ pivot để sinh paraphrase bằng tiếng Pháp cho mỗi ý định.
•HOUSE-paraph (LM): được bổ sung sử dụng PEGASUS (dịch qua lại được cung cấp bởi framework Marian NMT).
Baseline HOUSE-train và tất cả các tập dữ liệu được bổ sung đều bằng tiếng Pháp.

Tập dữ liệu SCOPE. Các tập huấn luyện cốt lõi là SCOPE-train-5, SCOPE-train-10, và SCOPE-train-50, mỗi tập tạo thành một baseline cho tác vụ bổ sung vì chúng chưa được bổ sung nhân tạo. Chúng tôi sinh ra các tập dữ liệu được bổ sung sau như được mô tả trong Tiểu phần 4.1 và 4.2:
•SCOPE-paraph-5 (NMT-fr): phiên bản 5 mẫu mỗi ý định được paraphrase với tiếng Pháp như ngôn ngữ pivot để sinh paraphrase bằng tiếng Anh.
•SCOPE-paraph-5 (NMT-de): phiên bản 5 mẫu mỗi ý định được paraphrase với tiếng Đức như ngôn ngữ pivot để sinh paraphrase bằng tiếng Anh.
•SCOPE-paraph-5 (LM): phiên bản 5 mẫu mỗi ý định được bổ sung sử dụng PEGASUS.
•SCOPE-paraph-10 (NMT-fr): 10 mẫu mỗi ý định được paraphrase với tiếng Pháp như ngôn ngữ pivot để sinh paraphrase bằng tiếng Anh.
•SCOPE-paraph-10 (NMT-de): 10 mẫu mỗi ý định được paraphrase với tiếng Đức như ngôn ngữ pivot để sinh paraphrase bằng tiếng Anh.
•SCOPE-paraph-10 (LM): 10 mẫu mỗi ý định được bổ sung sử dụng PEGASUS.
•SCOPE-paraph-50 (NMT-fr): 50 mẫu mỗi ý định được paraphrase với tiếng Pháp như ngôn ngữ pivot để sinh paraphrase bằng tiếng Anh.
•SCOPE-paraph-50 (NMT-de): 50 mẫu mỗi ý định được paraphrase với tiếng Đức như ngôn ngữ pivot để sinh paraphrase bằng tiếng Anh.
•SCOPE-paraph-50 (LM): 50 mẫu mỗi ý định được bổ sung sử dụng PEGASUS.
Các baseline SCOPE-train-5, SCOPE-train-10, và SCOPE-train-50 cũng như tất cả các tập dữ liệu được bổ sung đều bằng tiếng Anh.

--- TRANG 5 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN

Dataset Số lượng ý định Tổng mẫu Mẫu tối thiểu mỗi ý định Mẫu tối đa mỗi ý định Trung bình mẫu mỗi ý định
HOUSE-train 20 73 3 6 3.6
HOUSE-paraph (NMT-en) 20 453 17 42 22.6
HOUSE-paraph (NMT-de) 20 463 16 41 23.15
HOUSE-paraph (NMT-es) 20 458 16 41 22.9
HOUSE-paraph (LM) 20 351 13 30 17.5
HOUSE-test 20 77 1 11 3.8
SCOPE-train-5 150 750 5 5 5.0
SCOPE-paraph-5 (NMT-de) 150 3,840 13 34 25.3
SCOPE-paraph-5 (NMT-fr) 150 3,828 15 33 25.52
SCOPE-paraph-5 (LM) 150 4,500 30 30 30.0
SCOPE-train-10 150 1,500 10 10 10.0
SCOPE-paraph-10 (NMT-de) 150 7,663 33 65 51.1
SCOPE-paraph-10 (NMT-fr) 150 7,601 39 64 50.7
SCOPE-paraph-10 (LM) 150 9,000 60 60 60.0
SCOPE-train-50 150 7,500 50 50 50.0
SCOPE-paraph-50 (NMT-de) 150 37,754 183 314 251.7
SCOPE-paraph-50 (NMT-fr) 150 37,387 206 298 249.2
SCOPE-paraph-50 (LM) 150 45,000 300 300 300.0
SCOPE-test 150 4,500 30 30 30.0

Bảng 2: Tập dữ liệu được sử dụng trong các thí nghiệm của chúng tôi. HOUSE và SCOPE, tương ứng, đại diện cho tập dữ liệu doanh nghiệp nội bộ của chúng tôi và tập dữ liệu công khai trong phạm vi. NMT-DE đại diện cho cách tiếp cận paraphrase dịch máy với tiếng Đức như ngôn ngữ pivot. FR, EN, và ES đại diện cho tiếng Pháp, tiếng Anh, và tiếng Tây Ban Nha, tương ứng. LM đại diện cho các paraphrase thu được từ việc sử dụng mô hình ngôn ngữ PEGASUS được tinh chỉnh.

Trong Bảng 2, chúng tôi trình bày các tập dữ liệu cốt lõi và được bổ sung HOUSE và SCOPE, khối lượng paraphrase cho mỗi phân vùng sử dụng các cách tiếp cận dựa trên NMT và PEGASUS.

4.4 Thiết lập Hệ thống Dialog
Để đánh giá tác động tiềm năng của các tập dữ liệu được bổ sung của chúng tôi đối với hiệu suất của hệ thống dialog, chúng tôi tạo ra các hệ thống dialog sử dụng framework Rasa Bocklisch et al. [2017] và huấn luyện các mô hình NLU với các tập dữ liệu huấn luyện cốt lõi. Framework Rasa sử dụng DIET Classifier để phân loại ý định Bunk et al. [2020]. Đối với cấu hình tham số của framework, chúng tôi sử dụng một bộ encoder Bag-of-Words để thu được các biểu diễn sparse ở cả mức từ và ký tự. Những biểu diễn này sẽ được sử dụng như đầu vào bởi bộ phân loại sau đó sẽ huấn luyện embeddings dense riêng của nó. Tất cả các mô hình NLU được huấn luyện trong 200 epochs. Đối với mỗi baseline của chúng tôi (HOUSE cốt lõi và ba SCOPE cốt lõi), chúng tôi huấn luyện một hệ thống dialog dựa trên Rasa sử dụng cấu hình đã nói. Điều này tạo ra một hệ thống baseline HOUSE và ba hệ thống baseline SCOPE (SCOPE-5, -10, và -50). Tương tự, chúng tôi huấn luyện một hệ thống dialog với mỗi tập dữ liệu được bổ sung. Một lần nữa, chúng tôi phải nhấn mạnh thực tế rằng chúng tôi không cố gắng đạt kết quả hiện đại trên các tập dữ liệu benchmark của mình, mà là chứng minh rằng việc bổ sung dữ liệu nhân tạo thông qua sinh paraphrase có thể có đủ tác động đến hiệu suất trong các giai đoạn đầu của hệ thống dialog để tăng tốc và giảm chi phí của việc đưa vào sản xuất.

5 Đánh giá
Chúng tôi thực hiện đánh giá so sánh giữa các baseline, tức là các tập dữ liệu cốt lõi chưa được bổ sung (HOUSE-train, SCOPE-train-5, SCOPE-train-10, và SCOPE-train-50), và các tập dữ liệu được bổ sung (những tập có "paraph" trong Bảng 2).
Để đánh giá hiệu suất của hệ thống dialog, hiệu quả của phân loại ý định phải được đo lường. Cho mục đích đó, chúng tôi sử dụng precision, recall, và F1-score trung bình macro. Chúng tôi cũng báo cáo điểm trung bình micro (micro-averaged F1, precision, và recall, là đồng nhất vì mỗi mẫu được gán cho một lớp duy nhất). Trong

--- TRANG 6 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN

Systems Micro Score (%) Macro F1 (%) Macro Precision (%) Macro Recall (%)
SCOPE-train-5 (baseline) 54.7 52.9 54.9 54.7
SCOPE-paraph-5 NMT-de 62.0 59.8 61.3 62.0
SCOPE-paraph-5 NMT-fr 59.6 58.3 61.0 59.6
SCOPE-paraph-5 LM 64.0 62.7 65.4 64.0
SCOPE-train-10 (baseline) 69.2 68.1 69.5 69.2
SCOPE-paraph-10 NMT-de 73.2 72.4 73.7 73.2
SCOPE-paraph-10 NMT-fr 73.6 73.0 75.3 73.6
SCOPE-paraph-10 LM 74.1 73.1 74.6 74.1
SCOPE-train-50 (baseline) 83.8 83.4 85.1 83.8
SCOPE-paraph-50 (NMT-de) 85.0 82.9 86.3 85.0
SCOPE-paraph-50 (NMT-fr) 87.1 86.9 88.0 87.1
SCOPE-paraph-50 (LM) 87.4 87.2 88.0 87.4
HOUSE-train (baseline) 79.2 78.3 82.3 79.2
HOUSE-paraph (NMT-de) 84.3 81.6 81.6 83.9
HOUSE-paraph (NMT-en) 84.4 85.3 85.5 83.4
HOUSE-paraph (NMT-es) 83.1 82.8 83.8 81.9
HOUSE-paraph (LM) 84.4 85.5 86.7 83.5

Bảng 3: Kết quả phân loại ý định cho SCOPE và HOUSE được bổ sung sử dụng các cách tiếp cận khác nhau.

bối cảnh của chúng tôi, precision phản ánh khả năng của bộ phân loại dự đoán chính xác một ý định nhất định trong số các dự đoán được thực hiện, điều này, lần lượt dịch sang khả năng của hệ thống dialog phản hồi với câu trả lời chính xác. Một recall cao phản ánh khả năng của bộ phân loại ý định dự đoán lý tưởng (thực tế, càng nhiều càng tốt) ý định chính xác cho tất cả các ví dụ kiểm tra được liên kết với ý định đó. Chất lượng của việc phân loại do đó phụ thuộc vào chất lượng của thành phần paraphrase, dù là dựa trên NMT hay LM.
Mặc dù hầu hết dữ liệu nhân tạo dường như là paraphrase tốt và thậm chí một số ý định được paraphrase hoàn hảo, một số paraphrase là giả tạo, không ngạc nhiên. Nhiễu thường được phản ánh như các paraphrase bị lệch ngữ nghĩa khỏi ý định gốc hoặc mất một số chi tiết hoặc độ chính xác. Ví dụ, với PEGASUS, mẫu "commander des devises" bằng tiếng Pháp, được dịch thành "ordering currencies" - một giao dịch tài chính khá phổ biến, đã lệch thành "I want the dollars", mất tính chính xác, phạm vi và âm hưởng giống ngân hàng. Một ví dụ nhiễu với NMT là "Spécimen de chèque" có nghĩa là "sample (void) check", ở đây từ chèque có thể được dịch sang nghĩa khác của nó là validate hoặc verify.
Nhiễu như vậy là không mong muốn nhưng không thể tránh khỏi trong một quá trình bổ sung tự động. Để định lượng sự hiện diện của nhiễu này, chúng tôi yêu cầu các chuyên gia chú thích con người xác định xem các paraphrase được sinh cho tập dữ liệu HOUSE-paraph (LM) có chính xác hay không. Hai người chú thích có trình độ song ngữ tiếng Anh và tiếng Pháp thực hiện đánh giá riêng biệt. Họ thấy rằng 82% paraphrase là chính xác và phản ánh nghĩa của ý định gốc trong khi sử dụng cú pháp và từ vựng khác nhau.

6 Kết quả và Thảo luận
Trong Phần này, chúng tôi trình bày kết quả đánh giá cho cả hai cách tiếp cận bổ sung trên tập dữ liệu HOUSE và SCOPE. Bảng 3 báo cáo kết quả tổng thể so sánh với những kết quả thu được với các baseline chưa được bổ sung. Quan sát đầu tiên chúng tôi thực hiện là F1-score cho mô hình phân loại ý định đã tăng lên đến 7.8% (chênh lệch tuyệt đối) và cho tất cả các tập dữ liệu được bổ sung so với baseline của chúng khi được đánh giá với tập kiểm tra (HOUSE-test và SCOPE-test). Sự gia tăng như vậy được quan sát thậm chí đối với SCOPE-train-50, có số lượng mẫu đáng kể cho mỗi ý định trước khi bổ sung. Hiệu suất của các hệ thống paraphrase khác nhau tự chúng dường như khá gần nhau, mặc dù hệ thống dựa trên LM cho F1 score tốt nhất cho hầu hết các tập dữ liệu. Hơn nữa, chúng tôi chỉ ra rằng các tập dữ liệu có ít ví dụ huấn luyện hơn cho mỗi ý định dường như được hưởng lợi nhiều hơn từ paraphrase so với các tập dữ liệu lớn hơn, đã sở hữu nhiều khả năng tổng quát hóa hơn do khối lượng dữ liệu cao hơn. Điều này xác nhận giả thuyết rằng paraphrase hữu ích hơn trong các giai đoạn đầu của quá trình phát triển hệ thống dialog, khi rất ít mẫu huấn luyện cho mỗi ý định có sẵn.

--- TRANG 7 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN

Bảng 3 cho thấy điểm số thu được với tập dữ liệu HOUSE, là tập dữ liệu nhỏ hơn chỉ với 20 ý định và rất ít mẫu. Một lần nữa, chúng ta có thể thấy rằng paraphrase luôn dẫn đến micro score cao hơn. Điều này cho thấy rằng cả hai hệ thống paraphrase đều có thể được sử dụng thành công trên các hệ thống dialog trong ngôn ngữ khác ngoài tiếng Anh. Khi so sánh các hệ thống riêng lẻ, mức hiệu suất lại khá gần nhau nhưng hệ thống dựa trên LM vẫn vượt trội hơn các hệ thống dựa trên NMT với một khoảng cách nhỏ, mặc dù có thêm bước dịch cần thiết cho tiếng Pháp. Tuy nhiên, quan trọng là phải đề cập rằng cách tiếp cận dựa trên NMT sử dụng các mô hình nhẹ hơn so với cách tiếp cận dựa trên LM, điều này có thể làm cho nó trở thành một lựa chọn khả thi cho các nhóm hoặc tổ chức có tài nguyên hạn chế.

7 Kết luận và Nghiên cứu Tương lai
Nghiên cứu này khám phá lợi ích của paraphrase như một giải pháp bổ sung dữ liệu khi tạo ra các mô hình NLU cho hệ thống dialog trong bối cảnh công nghiệp thực tế. Chúng tôi thực nghiệm với hai cách tiếp cận paraphrase: một dựa trên NMT, và cách kia tận dụng các mô hình ngôn ngữ lớn được huấn luyện trước cho các tác vụ sinh văn bản. Chúng tôi sử dụng các phương pháp paraphrase này để bổ sung hai tập dữ liệu: thứ nhất, một tập dữ liệu có sẵn công khai bằng tiếng Anh, với số lượng lớn ý định và các phân vùng có kích thước khác nhau; thứ hai, một tập dữ liệu doanh nghiệp bằng tiếng Pháp, với số lượng ý định nhỏ hơn. Trong ánh sáng của các thí nghiệm, chúng tôi thấy rằng lợi ích của paraphrase là không thể phủ nhận, khi các mô hình được huấn luyện trên các tập được bổ sung, trên tất cả các tập dữ liệu và hệ thống paraphrase, vượt trội hơn các mô hình baseline (được huấn luyện với dữ liệu chưa được bổ sung) cho tác vụ phân loại ý định. Phương pháp bổ sung dữ liệu này có thể được sử dụng hiệu quả bởi các tổ chức để tạo ra các hệ thống dialog mới, mà không cần phải đối phó với chi phí khổng lồ và nhu cầu tài nguyên liên quan đến việc sinh dữ liệu thủ công.
Chúng tôi tóm tắt các phát hiện như sau:
1. Các cách tiếp cận bổ sung đề xuất của chúng tôi vượt trội hơn các baseline chưa được bổ sung trên tất cả các tập dữ liệu cho cả tiếng Pháp và tiếng Anh. Điều này cho thấy rằng chất lượng và sự đa dạng của các paraphrase có thể cải thiện khả năng tổng quát hóa của mô hình NLU.
2. Cả hai cách tiếp cận dựa trên NMT và PEGASUS đều cải thiện hiệu suất. Sử dụng PEGASUS vượt trội hơn một chút so với NMT như một thành phần bổ sung, mặc dù có thêm bước dịch ở đầu và cuối pipeline trong trường hợp tập dữ liệu tiếng Pháp.
3. NMT cung cấp sự đa dạng ngữ nghĩa nhỏ hơn so với PEGASUS, nhưng cũng an toàn hơn PEGASUS vì cách sau có thể lệch khỏi ý định gốc.
4. Trong các cách tiếp cận dựa trên NMT, không có sự khác biệt rõ ràng giữa các ngôn ngữ pivot khác nhau có thể được quan sát. Tuy nhiên, tiếng Pháp và tiếng Anh dường như ghép đôi tốt như ngôn ngữ nguồn-pivot theo cả hai hướng.
5. Càng nhiều ý định, càng cần nhiều mẫu huấn luyện, điều này không ngạc nhiên. Tuy nhiên, chúng tôi đã thấy trong các thí nghiệm rằng 10 mẫu gốc cho mỗi ý định và các bổ sung paraphrase của chúng có thể đủ để đạt hiệu suất cho phép trải nghiệm người dùng thỏa mãn, do đó bắt đầu tương tác với người dùng cuối thực sự.
Do đó chúng tôi khuyến nghị rằng năm đến 10 mẫu ban đầu cho mỗi ý định được tạo thủ công và diễn đạt đa dạng để truyền tải các khía cạnh khác nhau của ý định, sau đó việc bổ sung được thực hiện sử dụng một trong các cách tiếp cận đề xuất của chúng tôi.
Chúng tôi cũng chỉ ra rằng các cách tiếp cận bổ sung của chúng tôi có chi phí thấp và nhanh hơn đáng kể so với việc xây dựng một tập huấn luyện đáng kể thủ công. Đối với nghiên cứu tương lai, chúng tôi muốn thực nghiệm với các phương pháp bổ sung của chúng tôi trên các hệ thống dialog trưởng thành hơn với nhiều mẫu hơn cho mỗi ý định, dựa trên các tương tác người dùng thực tế, khi các ý định mới xuất hiện và những ý định hiện có phát triển. Ngoài ra, nhật ký người dùng thường mang một loại nhiễu khác vào dữ liệu, như lỗi chính tả và thuật ngữ chuyên biệt. Do đó sẽ thú vị để khám phá tác động của nhiễu như vậy. Sau đó, có thể thú vị để kiểm tra các cách lọc ra các paraphrase xấu trong pipeline bổ sung. Điều này có thể được thực hiện, ví dụ, bằng cách điều chỉnh một ngưỡng trên điểm tin cậy của mô hình thay vì trích xuất top n paraphrase. Cuối cùng, sẽ thú vị để thử một cách tiếp cận kết hợp, tức là kết hợp các paraphrase duy nhất có nguồn gốc từ các pivot khác nhau và đa dạng hơn (ví dụ tiếng Trung và tiếng Pháp) để có sự đa dạng paraphrase cao hơn được quy cho các tinh tế ngôn ngữ, và có thể kết hợp các paraphrase từ cả hai cách tiếp cận dựa trên NM và LM vào tập huấn luyện.

--- TRANG 8 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN

Tài liệu tham khảo
Jatin Ganhotra, Siva Sankalp Patel, và Kshitij Fadnis. Knowledge-incorporating esim models for response selection in retrieval-based dialog systems. arXiv preprint arXiv:1907.05792, 2019.
Sebastian Schuster, Sonal Gupta, Rushin Shah, và Mike Lewis. Cross-lingual transfer learning for multilingual task oriented dialog. arXiv preprint arXiv:1810.13327, 2018.
Jonathan Mallinson, Rico Sennrich, và Mirella Lapata. Paraphrasing revisited with neural machine translation. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, pages 881–893, 2017. URL https://www.aclweb.org/anthology/E17-1083.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems (NIPS 2017), pages 5998–6008, 2017.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, và cộng sự. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4171–4186, 2019. doi:10.18653/v1/N19-1423. URL https://aclanthology.org/N19-1423.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683, 2019.
Jianfeng Gao, Michel Galley, và Lihong Li. Neural approaches to conversational AI: Question answering, task-oriented dialogues and social chatbots. Now Foundations and Trends, 2019.
Yun-Nung Chen, Asli Celikyilmaz, và Dilek Hakkani-Tür. Deep learning for dialogue systems. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts, pages 8–14, 2017a. URL https://www.aclweb.org/anthology/P17-5004.
Hongshen Chen, Xiaorui Liu, Dawei Yin, và Jiliang Tang. A survey on dialogue systems: Recent advances and new frontiers. ACM SIGKDD Explorations Newsletter, 19(2):25–35, 2017b.
Ryan Lowe, Nissan Pow, Iulian Serban, và Joelle Pineau. The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems. arXiv preprint arXiv:1506.08909, 2015.
Yiping Kang, Yunqi Zhang, Jonathan K Kummerfeld, Lingjia Tang, và Jason Mars. Data collection for dialogue system: A startup perspective. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 33–40, 2018.
Stefan Larson, Anish Mahendran, Joseph J Peper, Christopher Clarke, Andrew Lee, Parker Hill, Jonathan K Kummerfeld, Kevin Leach, Michael A Laurenzano, Lingjia Tang, và cộng sự. An evaluation dataset for intent classification and out-of-scope prediction. arXiv preprint arXiv:1909.02027, 2019.
Jeffrey Dalton, Chenyan Xiong, Vaibhav Kumar, và Jamie Callan. Cast-19: A dataset for conversational information seeking. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 1985–1988, 2020.
Iulian Vlad Serban, Ryan Lowe, Peter Henderson, Laurent Charlin, và Joelle Pineau. A survey of available corpora for building data-driven dialogue systems. arXiv preprint arXiv:1512.05742, 2015.
Praveen Badimala, Chinmaya Mishra, Reddy Kumar Modam Venkataramana, Syed Bukhari, và Andreas Dengel. A study of various text augmentation techniques for relation classification in free text. In Proceedings of the 8th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2019), pages 360-367, pages 360–367, 02 2019. doi:10.5220/0007311003600367.
Alex Krizhevsky, Ilya Sutskever, và Geoffrey E Hinton. ImageNet classification with deep convolutional neural networks. Advances in neural information processing systems, 25:1097–1105, 2012.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. ImageNet: A large-scale hierarchical image database. In Proceedings of the 2009 IEEE conference on computer vision and pattern recognition, pages 248–255, 2009.
William Yang Wang và Diyi Yang. That's so annoying!!!: A lexical and frame-semantic embedding based data augmentation approach to automatic categorization of annoying behaviors using #petpeeve tweets. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2557–2563, 2015. doi:10.18653/v1/D15-1306. URL https://www.aclweb.org/anthology/D15-1306.

--- TRANG 9 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN

Maria Papadaki. Data augmentation techniques for legal text analytics. Department of Computer Science, Athens University of Economics and Business, Athens, 2017.
Kathleen R. McKeown. Paraphrasing using given and new information in a question-answer system. In Proceedings of the 17th Annual Meeting of the Association for Computational Linguistics, pages 67–72, 1979. doi:10.3115/982163.982182. URL https://www.aclweb.org/anthology/P79-1016.
Marie Meteer và Varda Shaked. Strategies for effective paraphrasing. In Proceedings of the 12th Conference on Computational Linguistics, COLING '88, page 431–436, 1988. ISBN 963 8431 56 3. doi:10.3115/991719.991724. URL https://doi.org/10.3115/991719.991724.
Colin Bannard và Chris Callison-Burch. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05), pages 597–604, 2005. doi:10.3115/1219840.1219914. URL https://www.aclweb.org/anthology/P05-1074.
Alex Sokolov và Denis Filimonov. Neural machine translation for paraphrase generation. arXiv preprint arXiv:2006.14223, 2020.
Marcin Junczys-Dowmunt, Roman Grundkiewicz, Tomasz Dwojak, Hieu Hoang, Kenneth Heafield, Tom Neckermann, Frank Seide, Ulrich Germann, Alham Fikri Aji, Nikolay Bogoychev, và cộng sự. Marian: Fast neural machine translation in C++. arXiv preprint arXiv:1804.00344, 2018.
Sam Witteveen và Martin Andrews. Paraphrasing with large language models. In Proceedings of the 3rd Workshop on Neural Generation and Translation, pages 215–220, 2019. doi:10.18653/v1/D19-5623. URL https://aclanthology.org/D19-5623.
Alberto Barrón-Cedeño, Marta Vila, M Antònia Martí, và Paolo Rosso. Plagiarism meets paraphrasing: Insights for the next generation in automatic plagiarism detection. Computational Linguistics, 39(4):917–947, 2013.
Jingqing Zhang, Yao Zhao, Mohammad Saleh, và Peter Liu. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In International Conference on Machine Learning, pages 11328–11339, 2020.
Taku Kudo và John Richardson. SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 66–71, 2018. doi:10.18653/v1/D18-2012. URL https://www.aclweb.org/anthology/D18-2012.
Yinfei Yang, Yuan Zhang, Chris Tar, và Jason Baldridge. PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, page 3687–3692, 2019.
Tom Bocklisch, Joey Faulkner, Nick Pawlowski, và Alan Nichol. Rasa: Open source language understanding and dialogue management. arXiv preprint arXiv:1712.05181, 2017.
Tanja Bunk, Daksh Varshneya, Vladimir Vlasov, và Alan Nichol. Diet: Lightweight language understanding for dialogue systems. arXiv preprint arXiv:2004.09936, 2020.

--- TRANG 10 ---
Khởi động nhanh Hệ thống Dialog bằng Sinh Paraphrase BẢN THẢO TRƯỚC KHI IN

10

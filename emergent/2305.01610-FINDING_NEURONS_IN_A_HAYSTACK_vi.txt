12 Lời cảm ơn

Nghiên cứu của chúng tôi đã được hưởng lợi từ các cuộc thảo luận, phản hồi và hỗ trợ từ nhiều người, bao gồm Marius Hobbhahn, Stefan Heimersheim, Jett Janiak, Eric Purdy, Aryan Bhatt, Eric Michaud, Janice Yang, Laker Newhouse, Trenton Bricken, Adam Jermyn, và Chris Olah. Chúng tôi cũng muốn cảm ơn chương trình SERI MATS đã tạo điều kiện cho các sự hợp tác bắt đầu dự án. Công việc của chúng tôi cũng không thể thực hiện được nếu không có thư viện TransformerLens xuất sắc [ 85] và các nguồn lực tính toán được cung cấp bởi MIT supercloud [86].

Đóng góp của các tác giả

Wes Gurnee đề xuất, dẫn dắt và thực hiện hầu hết nghiên cứu ngoài việc viết bài báo. Neel Nanda giám sát hầu hết các khía cạnh kỹ thuật và phương pháp luận của nghiên cứu, giúp diễn giải và red-team kết quả, định hình câu chuyện chính của bài báo, thực hiện các sửa đổi đáng kể, và đồng viết FAQ. Matthew Pauly triển khai cơ sở hạ tầng kích hoạt ban đầu, và dẫn dắt phát triển các tập dữ liệu đặc trưng wikidata và các thí nghiệm đặc trưng sự thật. Katherine Harvey hỗ trợ xem xét tài liệu, thực hiện các điều tra sâu hơn về tính monosemantic của các neuron ngữ cảnh, và tạo các bảng dữ liệu. Dmitrii Troitski hỗ trợ điều tra vai trò của các neuron lớp đầu, liệt kê nhiều ví dụ cụ thể bổ sung về polysemanticity. Dimitris Bertsimas truyền cảm hứng, hỗ trợ và tư vấn điều tra ngoài việc chỉnh sửa bài báo.

Tài liệu tham khảo

[1]Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence , 35(8):1798–1828, 2013.

[2]Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, and Trevor Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In International conference on machine learning , pages 647–655. PMLR, 2014.

[3]Yonatan Belinkov. Probing classifiers: Promises, shortcomings, and advances. Computational Linguistics , 48(1):207–219, 2022.

[4]Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield-Dodds, Robert Lasenby, Dawn Drain, Carol Chen, et al. Toy models of superposition. arXiv preprint arXiv:2209.10652 , 2022.

[5]Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, and Shan Carter. Zoom in: An introduction to circuits. Distill , 5(3):e00024–001, 2020.

[Tiếp tục với danh sách tài liệu tham khảo dài...]

A Câu hỏi thường gặp

A.1 Tại sao mong đợi diễn giải đầy tham vọng có thể thực hiện được hoặc đáng giá?

Chúng tôi chia câu trả lời thành hai phần: tại sao nó nên có thể ngay cả về mặt lý thuyết, và cách chúng tôi diễn giải tiến bộ cho đến nay.

Mặc dù gradient descent không có lý do hoặc động cơ để học các biểu diễn có thể hiểu được đối với con người, điều tương tự có thể được nói về tất cả các cấu trúc sinh học "được học" bởi chọn lọc tự nhiên. Tuy nhiên, các cấu trúc sinh học bị ràng buộc bởi các định luật tự nhiên—một sinh vật phải sử dụng hiệu quả năng lượng và không gian hạn chế, vật liệu di truyền của nó được mã hóa trong RNA và DNA, chức năng của nó được mã hóa trong protein, và những protein này kết hợp với nhau thành các mạch sinh học. Mặc dù những mạch sinh học này phức tạp, thường đặc thù cho sinh vật, và đôi khi có vẻ khó hiểu, những ràng buộc này cho chúng ta hiểu biết về chức năng của chúng và tạo ra các motif và nguyên tắc chung có thể được kỹ thuật ngược [ 87]. Theo cách tương tự, mạng neural đang cố gắng đạt được các nhiệm vụ phức tạp và có những ràng buộc đáng kể, cụ thể là số lượng tham số, phi tuyến tính và norm trọng số. Và rộng hơn, các thuật toán mà kiến trúc của chúng cho phép chúng biểu diễn. Bằng cách nghiên cứu các cấu trúc tương tự của mạng neural—cả ở mức toán học [ 41] và trong tự nhiên [ 44]—có thể khám phá một số nguyên tắc và motif này, và bắt đầu có được chỗ đứng trong việc kỹ thuật ngược những mạch nhân tạo này.

Một nguồn bi quan tiềm năng cho diễn giải đầy tham vọng là tiến bộ đã đạt được cho đến nay. Mặc dù chúng ta đã có được một số hiểu biết về nội bộ mô hình, hầu hết các công trình trong diễn giải cơ học đã tập trung vào các mô hình nhỏ hoặc đồ chơi [ 41,45,46,44,9], trong khi các mô hình frontier trở nên lớn hơn với tốc độ nhanh hơn nhiều [ 88,89,90]. Trong khi các phương pháp diễn giải có thể mở rộng hơn thường được chỉ ra có kết quả dễ diễn giải sai, hoặc đôi khi tích cực gây hiểu lầm [ 91,92,93,94]. Việc nhìn vào sự nhầm lẫn và tính không thể hiểu được này và cảm thấy nản lòng là tự nhiên. Tuy nhiên, các cấu trúc tự nhiên chắc chắn không kém phần không thể hiểu đối với các nhà tiên phong đầu tiên trong sinh học phân tử, di truyền học và khoa học thần kinh, thể hiện một sự phức tạp emergent có vẻ không thể rút gọn. Tuy nhiên, thay vì tuyên bố rằng tế bào, gen, hoặc não là "không thể diễn giải," toàn bộ các ngành khoa học đã xuất hiện và đã đạt được những bước tiến lớn trong việc hiểu các nguyên tắc cốt lõi đủ chi tiết để cho phép can thiệp, thiết kế và kiểm soát các hệ thống sinh học. Chúng tôi tin rằng mạng neural nhân tạo có thể được diễn giải đầy đủ—thậm chí kỹ thuật ngược—nhưng làm như vậy đòi hỏi một lượng nỗ lực tương đương như diễn giải những cái sinh học. Theo nhiều cách, khoa học thần kinh nhân tạo mới nổi này đặc biệt phù hợp với phương pháp khoa học [ 95]: có thể chạy các thí nghiệm phản thực tùy ý, thời gian lặp lại nhanh, yêu cầu tài nguyên tối thiểu, tất cả với khả năng quan sát đầy đủ và độ chính xác đo lường bằng độ chính xác floating point. Trong khi đầy tham vọng, chúng tôi nghĩ rằng nỗ lực như vậy là tối quan trọng để giải quyết các vấn đề về alignment và kiểm soát các hệ thống AI ngày càng có khả năng.

A.2 Bạn có ý gì với một neuron?

Thuật ngữ neuron đôi khi được sử dụng để chỉ các phần tử của bất kỳ tensor kích hoạt nào, trong cơ sở tiêu chuẩn. Ở đây, chúng tôi thay vào đó dành neuron để chỉ các phần tử của các kích hoạt mô hình ngay sau một phi tuyến tính theo từng phần tử: kích hoạt post GELU trong hidden state của lớp MLP của transformer. Chúng tôi không sử dụng neuron để chỉ các phần tử của residual stream của transformer, đầu ra của một lớp, hoặc key, query hoặc value trong một attention head. Đây là đầu ra của một ánh xạ tuyến tính, và do đó không có cơ sở đặc quyền [41]: chúng tôi mong đợi mô hình hoạt động giống nhau dưới một phép quay tùy ý (modulo quirks optimizer [66])

A.3 Sự khác biệt giữa polysemanticity, superposition, và distributed representations là gì?

Đây là những khái niệm tương tự với những khác biệt quan trọng, thường bị nhầm lẫn. Chúng tôi đề xuất lược đồ sau:

Superposition là hiện tượng khi một kích hoạt biểu diễn nhiều đặc trưng hơn số chiều mà nó có. Mỗi đặc trưng là một hướng trong không gian, và hệ quả là chúng không thể đều trực giao.

Polysemanticity là khi một neuron có vẻ biểu diễn nhiều khái niệm không liên quan. Điều này trái ngược với một neuron monosemantic kích hoạt nếu và chỉ nếu một đặc trưng nhất định có mặt.

Distributed representations là nơi một đặc trưng được biểu diễn như một kết hợp tuyến tính của neuron, tức là một hướng không tương ứng với một phần tử cơ sở duy nhất. Còn được gọi là các đặc trưng non-basis aligned. Đáng chú ý, đây có thể là một biểu diễn phân tán khá thưa thớt (ví dụ, sử dụng 2-5 neuron), khá dày đặc (ví dụ, sử dụng 10-20% tất cả neuron trong lớp), đến hoàn toàn dày đặc/không căn chỉnh cơ sở chút nào.

Đáng chú ý, polysemanticity và distributed representations là những khái niệm cục bộ; chúng có thể được chứng minh bằng cách nghiên cứu từng neuron hoặc đặc trưng riêng lẻ. Superposition là một hiện tượng toàn cục, và yêu cầu xác định nhiều đặc trưng hơn neuron để chứng minh một cách kết luận.

[Tiếp tục với phần FAQ còn lại...]

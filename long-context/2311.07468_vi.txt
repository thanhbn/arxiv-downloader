# 2311.07468.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/long-context/2311.07468.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 2222092 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================


--- TRANG 1 ---
PhÃ¢n TÃ­ch vÃ  Giáº£m Thiá»ƒu Lá»i Nguyá»n Äáº£o NgÆ°á»£c
Ang Lv1âˆ—, Kaiyi Zhang1âˆ—, Shufang Xie1, Quan Tu1, Yuhan Chen1,
Ji-Rong Wen1 vÃ  Rui Yan1,2â€ 
1TrÆ°á»ng TrÃ­ tuá»‡ NhÃ¢n táº¡o Gaoling, Äáº¡i há»c NhÃ¢n dÃ¢n Trung Quá»‘c
2Trung tÃ¢m NghiÃªn cá»©u Ká»¹ thuáº­t 
TÃ¬m kiáº¿m vÃ  Khuyáº¿n nghá»‹ ThÃ´ng minh Tháº¿ há»‡ Tiáº¿p theo, Bá»™ GiÃ¡o dá»¥c
{anglv, kyzhang, ruiyan}@ruc.edu.cn
TÃ³m táº¯t
NghiÃªn cá»©u gáº§n Ä‘Ã¢y Ä‘Ã£ quan sÃ¡t tháº¥y má»™t hiá»‡n
tÆ°á»£ng Ä‘Ã¡ng chÃº Ã½ trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯
lá»›n (LLM), Ä‘Æ°á»£c gá»i lÃ  "lá»i nguyá»n Ä‘áº£o ngÆ°á»£c."
Lá»i nguyá»n Ä‘áº£o ngÆ°á»£c lÃ  khi xá»­ lÃ½ hai thá»±c thá»ƒ,
kÃ½ hiá»‡u lÃ  a vÃ  b, Ä‘Æ°á»£c káº¿t ná»‘i bá»Ÿi má»‘i quan há»‡
R vÃ  má»‘i quan há»‡ nghá»‹ch Ä‘áº£o Râˆ’1, LLM xuáº¥t sáº¯c
trong viá»‡c xá»­ lÃ½ cÃ¡c chuá»—i dÆ°á»›i dáº¡ng "aRb," nhÆ°ng
gáº·p khÃ³ khÄƒn khi xá»­ lÃ½ "bRâˆ’1a," dÃ¹ trong viá»‡c
sinh text hay hiá»ƒu text. VÃ­ dá»¥, GPT-4 cÃ³ thá»ƒ tráº£ lá»i
chÃ­nh xÃ¡c cÃ¢u há»i "Máº¹ cá»§a Tom Cruise lÃ ?" vá»›i
"Mary Lee Pfeiffer," nhÆ°ng nÃ³ gáº·p khÃ³ khÄƒn Ä‘á»ƒ
Ä‘Æ°a ra cÃ¢u tráº£ lá»i thá»a Ä‘Ã¡ng khi Ä‘Æ°á»£c há»i "Con trai
cá»§a Mary Lee Pfeiffer lÃ ?" Trong bÃ i bÃ¡o nÃ y, chÃºng
tÃ´i thá»±c hiá»‡n nghiÃªn cá»©u Ä‘áº§u tiÃªn vá» cÃ¡ch lá»i nguyá»n
Ä‘áº£o ngÆ°á»£c xáº£y ra trong LLM. CÃ¡c Ä‘iá»u tra cá»§a chÃºng
tÃ´i tiáº¿t lá»™ ráº±ng lá»i nguyá»n Ä‘áº£o ngÆ°á»£c cÃ³ thá»ƒ xuáº¥t phÃ¡t
tá»« cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n cá»¥ thá»ƒ, Ä‘iá»u nÃ y trá»Ÿ nÃªn
Ä‘áº·c biá»‡t rÃµ rÃ ng trong viá»‡c sá»­ dá»¥ng rá»™ng rÃ£i dá»± Ä‘oÃ¡n
token tiáº¿p theo trong háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯
nhÃ¢n quáº£. ChÃºng tÃ´i hy vá»ng nghiÃªn cá»©u ban Ä‘áº§u nÃ y
cÃ³ thá»ƒ thu hÃºt nhiá»u sá»± chÃº Ã½ hÆ¡n Ä‘áº¿n lá»i nguyá»n Ä‘áº£o
ngÆ°á»£c, cÅ©ng nhÆ° cÃ¡c háº¡n cháº¿ tiá»m áº©n khÃ¡c trong cÃ¡c
LLM hiá»‡n táº¡i.1
1 Giá»›i thiá»‡u
Lá»i nguyá»n Ä‘áº£o ngÆ°á»£c, Ä‘Æ°á»£c quan sÃ¡t bá»Ÿi Berglund et al.
(2023), Ä‘Ã£ thu hÃºt nhiá»u sá»± chÃº Ã½. Hiá»‡n tÆ°á»£ng nÃ y
liÃªn quan Ä‘áº¿n cÃ¡c thá»±c thá»ƒ cÃ³ liÃªn quan Ä‘Æ°á»£c kÃ½ hiá»‡u
lÃ  a vÃ  b, Ä‘Æ°á»£c liÃªn káº¿t bá»Ÿi má»™t má»‘i quan há»‡ R vÃ  má»‘i
quan há»‡ nghá»‹ch Ä‘áº£o tÆ°Æ¡ng á»©ng Râˆ’1. Khi má»™t truy váº¥n
liÃªn quan Ä‘áº¿n a vÃ  má»‘i quan há»‡ R Ä‘Æ°á»£c Ä‘áº·t ra cho má»™t
mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM), LLM chÃ­nh xÃ¡c tráº£ vá»
b nhÆ° lÃ  cÃ¢u tráº£ lá»i. Tuy nhiÃªn, khi Ä‘Æ°á»£c trÃ¬nh bÃ y vá»›i
b vÃ  má»‘i quan há»‡ nghá»‹ch Ä‘áº£o Râˆ’1, LLM cÃ³ xu hÆ°á»›ng
thá»ƒ hiá»‡n sá»± bá»‘i rá»‘i Ä‘Ã¡ng ká»ƒ vÃ  khÃ´ng thá»ƒ cung cáº¥p a
nhÆ° lÃ  cÃ¢u tráº£ lá»i. VÃ­ dá»¥, khi Berglund et al. (2023)
Ä‘áº·t cÃ¢u há»i cho GPT-4 (OpenAI, 2023), "Máº¹ cá»§a Tom
Cruise lÃ  ai?" GPT-4 Ä‘Ã£ Ä‘Æ°a ra pháº£n há»“i Ä‘Ãºng, Ä‘Ã³ lÃ 
"Mary Lee Pfeiffer." Tuy nhiÃªn, khi cÃ¢u há»i ngÆ°á»£c láº¡i
Ä‘Æ°á»£c há»i, "Con trai cá»§a Mary Lee Pfeiffer lÃ  ai?" GPT-4
Ä‘Ã£ tráº£ lá»i vá»›i má»™t cÃ¢u tráº£ lá»i áº£o giÃ¡c, cho tháº¥y thiáº¿u
kiáº¿n thá»©c vá» cÃ¡ nhÃ¢n nÃ y. RÃµ rÃ ng lÃ  GPT-4 Ä‘Ã£ cÃ³ Ä‘Æ°á»£c
kiáº¿n thá»©c liÃªn quan Ä‘áº¿n cáº£ "Tom Cruise" vÃ  "Mary Lee
Pfeiffer." HÆ¡n ná»¯a, khÃ´ng nghi ngá» gÃ¬ ráº±ng GPT-4 hiá»ƒu
má»‘i quan há»‡ tÆ°Æ¡ng há»— giá»¯a "a lÃ  máº¹ cá»§a b" vÃ  "b lÃ 
con cÃ¡i cá»§a a." Lá»i nguyá»n Ä‘áº£o ngÆ°á»£c trong cÃ¡c LLM
tiÃªn tiáº¿n nhÆ° váº­y mÃ¢u thuáº«n vá»›i cÃ¡c kháº£ nÄƒng dá»± kiáº¿n
cá»§a nhá»¯ng mÃ´ hÃ¬nh nÃ y, thÃªm vÃ o sá»± háº¥p dáº«n xung
quanh hiá»‡n tÆ°á»£ng nÃ y. NÃ³ cÅ©ng háº¡n cháº¿ viá»‡c á»©ng dá»¥ng
vÃ  phÃ¡t triá»ƒn LLM trong cÃ¡c tÃ¬nh huá»‘ng Ä‘Ã²i há»i Ä‘á»™
chÃ­nh xÃ¡c thá»±c táº¿ cao. Do Ä‘Ã³, má»™t cÃ¢u há»i thiáº¿t yáº¿u
náº£y sinh: Ä‘iá»u gÃ¬ gÃ¢y ra lá»i nguyá»n Ä‘áº£o ngÆ°á»£c trong
cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n?

Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n ná»— lá»±c
Ä‘áº§u tiÃªn Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y, vÃ  tiáº¿t lá»™ ráº±ng cÃ¡c má»¥c
tiÃªu huáº¥n luyá»‡n áº£nh hÆ°á»Ÿng Ä‘Ã¡ng ká»ƒ Ä‘áº¿n má»©c Ä‘á»™ cá»§a
lá»i nguyá»n Ä‘áº£o ngÆ°á»£c. ÄÃ¡ng chÃº Ã½ lÃ  Berglund et al.
(2023) táº­p trung Ä‘Ã¡nh giÃ¡ cá»§a há» chá»‰ trÃªn cÃ¡c mÃ´ hÃ¬nh
Llama (Touvron et al., 2023a) vÃ  GPT (Brown
et al., 2020). Äá»‘i vá»›i nhá»¯ng mÃ´ hÃ¬nh nÃ y, máº·t náº¡
chÃº Ã½ nhÃ¢n quáº£ cá»§a há» háº¡n cháº¿ má»—i token chá»‰ phá»¥
thuá»™c vÃ o nhá»¯ng token trÆ°á»›c Ä‘Ã³, vÃ  khi Ä‘Æ°á»£c tiá»n
huáº¥n luyá»‡n cho dá»± Ä‘oÃ¡n token tiáº¿p theo (NTP) trÃªn
dá»¯ liá»‡u trong Ä‘Ã³ thá»±c thá»ƒ a thÆ°á»ng Ä‘á»©ng trÆ°á»›c thá»±c
thá»ƒ b, mÃ´ hÃ¬nh chá»‰ cÃ³ thá»ƒ tá»‘i Ä‘a hÃ³a kháº£ nÄƒng xáº£y ra
cá»§a b khi cÃ³ a (tá»©c lÃ , p(b|a)), khÃ´ng cÃ³ Ä‘áº£m báº£o
nÃ o cho viá»‡c Æ°á»›c tÃ­nh chÃ­nh xÃ¡c p(a|b). NgÆ°á»£c láº¡i,
trong má»™t sá»‘ mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÆ° GLM (Du et al.,
2022; Zeng et al., 2022) Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n vá»›i
má»¥c tiÃªu Ä‘iá»n khoáº£ng trá»‘ng tá»± há»“i quy (ABI), má»™t
token bá»‹ che cÃ³ thá»ƒ chÃº Ã½ Ä‘áº¿n cáº£ cÃ¡c token Ä‘á»©ng
trÆ°á»›c vÃ  Ä‘á»©ng sau nÃ³. Káº¿t quáº£ lÃ , má»¥c tiÃªu ABI
ngáº§m xem xÃ©t kháº£ nÄƒng cÃ³ Ä‘iá»u kiá»‡n Ä‘áº£o ngÆ°á»£c
p(a|b), cÃ³ thá»ƒ lÃ m cho GLM máº¡nh máº½ hÆ¡n chá»‘ng
láº¡i lá»i nguyá»n Ä‘áº£o ngÆ°á»£c.arXiv:2311.07468v3  [cs.CL]  10 Nov 2024

--- TRANG 2 ---
Äá»ƒ xÃ¡c minh giáº£ thuyáº¿t nÃ y, chÃºng tÃ´i tinh chá»‰nh GLM
trÃªn cÃ¹ng dá»¯ liá»‡u tÃªn-Ä‘áº¿n-mÃ´ táº£ nhÆ° (Berglund
et al., 2023). Cá»¥ thá»ƒ, trong quÃ¡ trÃ¬nh tinh chá»‰nh, chÃºng
tÃ´i cung cáº¥p cho mÃ´ hÃ¬nh cÃ¡c Ä‘áº§u vÃ o nhÆ° "Joe Biden
(tÃªn) lÃ  tá»•ng thá»‘ng Má»¹ (mÃ´ táº£)" vÃ  Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng
cá»§a nÃ³ trong viá»‡c hoÃ n thÃ nh cÃ¢u vá»›i "Tá»•ng thá»‘ng Má»¹
(mÃ´ táº£) lÃ ." Pháº£n há»“i mong Ä‘á»£i lÃ  "Joe Biden." ChÃºng
tÃ´i viáº¿t táº¯t nhiá»‡m vá»¥ nÃ y lÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i dá»¯
liá»‡u tÃªn-Ä‘áº¿n-mÃ´ táº£ vÃ  kiá»ƒm tra theo thá»© tá»± ngÆ°á»£c láº¡i
nhÆ° nhiá»‡m vá»¥ â†âˆ’N2D, trong khi kiá»ƒm tra theo cÃ¹ng
thá»© tá»± nhÆ° nhiá»‡m vá»¥ N2D. ÄÃ¡ng chÃº Ã½ lÃ  táº¥t cáº£ cÃ¡c
tÃªn vÃ  mÃ´ táº£ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»u hoÃ n toÃ n hÆ° cáº¥u, Ä‘áº£m
báº£o ráº±ng khÃ´ng cÃ³ sá»± thiÃªn vá»‹ nÃ o Ä‘Æ°á»£c Ä‘Æ°a vÃ o tá»« dá»¯
liá»‡u tiá»n huáº¥n luyá»‡n. CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i tiáº¿t
lá»™ ráº±ng GLM Ä‘áº¡t Ä‘Æ°á»£c khoáº£ng 80% Ä‘á»™ chÃ­nh xÃ¡c trong
nhiá»‡m vá»¥ â†âˆ’N2D, thá»ƒ hiá»‡n kháº£ nÄƒng phá»¥c há»“i Ä‘á»‘i vá»›i
lá»i nguyá»n Ä‘áº£o ngÆ°á»£c so vá»›i Llama, mÃ  Ä‘áº¡t Ä‘Æ°á»£c 0%
Ä‘á»™ chÃ­nh xÃ¡c. NgÆ°á»£c láº¡i, (1) khi tinh chá»‰nh GLM cho
dá»± Ä‘oÃ¡n token tiáº¿p theo, chÃºng Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c
0%; (2) ChÃºng tÃ´i giá»›i thiá»‡u má»™t phÆ°Æ¡ng phÃ¡p tinh
chá»‰nh má»›i gá»i lÃ  BICO, Ä‘iá»u chá»‰nh cÃ¡c mÃ´ hÃ¬nh Llama
Ä‘á»ƒ há»— trá»£ cÃ¡c má»¥c tiÃªu giá»‘ng ABI. BICO hiá»‡u quáº£ giáº£m
thiá»ƒu lá»i nguyá»n Ä‘áº£o ngÆ°á»£c trong Llama vÃ  mang láº¡i
nhá»¯ng cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c Ä‘Ã¡ng ká»ƒ (khoáº£ng 70 Ä‘iá»ƒm
Ä‘á»™ chÃ­nh xÃ¡c) trong nhiá»‡m vá»¥ â†âˆ’N2D. Nhá»¯ng káº¿t quáº£
nÃ y rÃµ rÃ ng chá»©ng minh ráº±ng cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n
lÃ  má»™t trong nhá»¯ng yáº¿u tá»‘ gÃ³p pháº§n vÃ o lá»i nguyá»n
Ä‘áº£o ngÆ°á»£c.

NgoÃ i ra, chÃºng tÃ´i sá»­ dá»¥ng BICO trong má»™t tÃ¬nh
huá»‘ng giáº£i quyáº¿t váº¥n Ä‘á» toÃ¡n há»c tháº¿ giá»›i thá»±c vÃ  má»™t
nhiá»‡m vá»¥ dá»‹ch thuáº­t Ä‘Æ¡n giáº£n. Äá»‘i vá»›i nhiá»‡m vá»¥ toÃ¡n
há»c, chÃºng tÃ´i huáº¥n luyá»‡n LLM trÃªn cÃ¡c giáº£i phÃ¡p
cho cÃ¡c bÃ i toÃ¡n toÃ¡n há»c, sá»­ dá»¥ng bá»™ dá»¯ liá»‡u GSM8k
(Cobbe et al., 2021). Sau Ä‘Ã³, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ LLM
trÃªn cÃ¡c bÃ i toÃ¡n toÃ¡n há»c Ä‘Æ°á»£c dáº«n xuáº¥t tá»« cÃ¡c cÃ¢u
há»i theo máº«u GSM gá»‘c, Ä‘Ã²i há»i kháº£ nÄƒng suy luáº­n
"ngÆ°á»£c." Vá» máº·t dá»‹ch thuáº­t, báº£n cháº¥t kÃ©p cá»§a dá»¯ liá»‡u
cá»§a nÃ³ lÃ  lÃ½ tÆ°á»Ÿng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ lá»i nguyá»n Ä‘áº£o ngÆ°á»£c,
vÃ¬ má»™t máº«u dá»¯ liá»‡u dá»‹ch tá»« ngÃ´n ngá»¯ X sang ngÃ´n ngá»¯
Y khÃ´ng Ä‘Æ°á»£c huáº¥n luyá»‡n ngÆ°á»£c trong quÃ¡ trÃ¬nh tiá»n
huáº¥n luyá»‡n, Ä‘iá»u nÃ y háº¡n cháº¿ tÃ­nh há»¯u Ã­ch cá»§a dá»¯ liá»‡u.
ChÃºng tÃ´i tinh chá»‰nh LLM trÃªn dá»¯ liá»‡u Trung-Anh vÃ 
kiá»ƒm tra nÃ³ vá»›i má»™t nhiá»‡m vá»¥ Anh-Trung. ChÃºng tÃ´i
phÃ¡t hiá»‡n ráº±ng thÃ´ng qua BICO, mÃ´ hÃ¬nh thá»ƒ hiá»‡n kháº£
nÄƒng cáº£i thiá»‡n Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n Ä‘áº£o ngÆ°á»£c
chÆ°a tháº¥y, vÃ  Ä‘á»™ chÃ­nh xÃ¡c dá»‹ch thuáº­t cáº£i thiá»‡n khi
Ä‘á»‘i máº·t vá»›i thá»© tá»± cáº·p ngÃ´n ngá»¯ chÆ°a tháº¥y. Äiá»u nÃ y
gá»£i Ã½ viá»‡c thu Ä‘Æ°á»£c cÃ¡c kháº£ nÄƒng suy luáº­n tá»•ng quÃ¡t
vÃ  máº¡nh máº½ hÆ¡n tá»« cÃ¹ng dá»¯ liá»‡u huáº¥n luyá»‡n.

TÃ³m láº¡i, chÃºng tÃ´i thá»±c hiá»‡n nghiÃªn cá»©u Ä‘áº§u tiÃªn vá»
nguyÃªn nhÃ¢n cá»§a lá»i nguyá»n Ä‘áº£o ngÆ°á»£c, vÃ  chÃºng tÃ´i
quy váº¥n Ä‘á» nÃ y cho má»™t trong nhiá»u yáº¿u tá»‘ tiá»m nÄƒng,
Ä‘Ã³ lÃ  cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n, Ä‘áº·c biá»‡t lÃ  má»¥c tiÃªu
dá»± Ä‘oÃ¡n token tiáº¿p theo. ChÃºng tÃ´i giá»›i thiá»‡u má»™t
phÆ°Æ¡ng phÃ¡p tinh chá»‰nh má»›i, Ä‘Æ°á»£c gá»i lÃ  BICO, Ä‘Æ°á»£c
thiáº¿t káº¿ Ä‘á»ƒ trÃ¡nh viá»‡c Ä‘Æ°a vÃ o lá»i nguyá»n Ä‘áº£o ngÆ°á»£c
bá»• sung trong cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n
trong khi táº­n dá»¥ng dá»¯ liá»‡u huáº¥n luyá»‡n tá»‘t hÆ¡n. ChÃºng
tÃ´i hy vá»ng nhiá»u nghiÃªn cá»©u táº­p trung hÆ¡n vÃ o nhá»¯ng
váº¥n Ä‘á» cÆ¡ báº£n nÃ y trong LLM bá»Ÿi vÃ¬, máº·c dÃ¹ viá»‡c
Ã¡p dá»¥ng rá»™ng rÃ£i huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯
nhÃ¢n quáº£ sá»­ dá»¥ng má»¥c tiÃªu dá»± Ä‘oÃ¡n token tiáº¿p theo,
phÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ khÃ´ng "hoÃ n háº£o" nhÆ° trÆ°á»›c
Ä‘Ã¢y ngÆ°á»i ta tin, gá»£i Ã½ ráº±ng cÃ¡c kháº£ nÄƒng cá»§a cÃ¡c mÃ´
hÃ¬nh ngÃ´n ngá»¯ lá»›n hiá»‡n táº¡i (LLM) cÃ³ thá»ƒ Ä‘Æ°á»£c cáº£i
thiá»‡n thÃªm.

2 Ná»n táº£ng
2.1 MÃ´ hÃ¬nh NgÃ´n ngá»¯ NÆ¡-ron
CÃ³ hai loáº¡i chÃ­nh cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nÆ¡-ron:
cÃ¡c mÃ´ hÃ¬nh tá»± mÃ£ hÃ³a (AE) Ä‘Æ°á»£c minh há»a bá»Ÿi há»
BERT (Devlin et al., 2019; Zhuang et al., 2021), vÃ 
cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy (AR) (Bengio et al., 2003;
Radford vÃ  Narasimhan, 2018; Touvron et al., 2023a).
Cho má»™t chuá»—i Ä‘áº§u vÃ o X = [x1, x2, x3, . . . , xT], má»™t
mÃ´ hÃ¬nh AE hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch Ä‘áº§u tiÃªn lÃ m há»ng
X thÃ nh XÌ‚ báº±ng cÃ¡ch che má»™t sá»‘ token Ä‘áº§u vÃ o vá»›i
má»™t token Ä‘áº·c biá»‡t [MASK]. CÃ¡c token bá»‹ che cÃ³ thá»ƒ
truy cáº­p táº¥t cáº£ cÃ¡c token trong ngá»¯ cáº£nh thÃ´ng qua
chÃº Ã½ hai chiá»u, nhÆ° Ä‘Æ°á»£c minh há»a trong HÃ¬nh 1(a).
MÃ´ hÃ¬nh vá»›i cÃ¡c tham sá»‘ Î˜ sau Ä‘Ã³ Ä‘Æ°á»£c huáº¥n luyá»‡n
Ä‘á»ƒ tÃ¡i táº¡o nhá»¯ng token bá»‹ che nÃ y, vá»›i má»¥c tiÃªu huáº¥n
luyá»‡n nhÆ° sau:

âˆ‘(T,t=1) 1(xt lÃ  [MASK]) Â· log p(xt|XÌ‚; Î˜).    (1)

Máº·t khÃ¡c, má»™t mÃ´ hÃ¬nh AR cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n loáº¡i
thÃªm thÃ nh mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£ vÃ  mÃ´ hÃ¬nh
ngÃ´n ngá»¯ tiá»n tá»‘, tÃ¹y thuá»™c vÃ o cÆ¡ cháº¿ chÃº Ã½ cá»§a
chÃºng. Má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£, nhÆ° GPT
(Radford vÃ  Narasimhan, 2018; Radford et al., 2019;
Brown et al., 2020) vÃ  Llama (Touvron et al., 2023a,b)
thÆ°á»ng Æ°á»›c tÃ­nh xÃ¡c suáº¥t cá»§a token tiáº¿p theo dá»±a trÃªn
ngá»¯ cáº£nh vÃ  má»¥c tiÃªu dá»± Ä‘oÃ¡n token tiáº¿p theo (NTP,
HÃ¬nh 1(b)) cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ°:

âˆ‘(T,t=1) log p(xt|X<t; Î˜).    (2)

Má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ tiá»n tá»‘, nhÆ° GLM (Du et al.,
2022; Zeng et al., 2022) vÃ  UniLM (Dong et al.,

--- TRANG 3 ---
xâ‚[MASK] Â·Â·Â·  xâ‚œxâ‚‚Â·Â·Â·Â·Â·Â·Â·Â·Â·
(a) Tá»± MÃ£ hÃ³a
xâ‚xâ‚‚Â·Â·Â· xâ‚œâ‚‹â‚Â·Â·Â·Â·Â·Â·Â·Â·Â·xâ‚‚xâ‚ƒÂ·Â·Â·  xâ‚œ
(b) NTP
xâ‚[MASK]    xâ‚ƒ[S]xâ‚‚(c) ABI
xâ‚‚[E]Tiá»n tá»‘

HÃ¬nh 1: CÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n khÃ¡c nhau cá»§a cÃ¡c mÃ´ hÃ¬nh
ngÃ´n ngá»¯. Chá»‰ cÃ¡c Ä‘áº§u ra Ä‘Æ°á»£c minh há»a gÃ³p pháº§n vÃ o tÃ­nh
toÃ¡n tá»•n tháº¥t trong khi nhá»¯ng Ä‘áº§u ra khÃ¡c Ä‘Æ°á»£c bá» qua Ä‘á»ƒ
rÃµ rÃ ng.

2019; Bao et al., 2020), xá»­ lÃ½ má»™t tiá»n tá»‘ Ä‘áº§u vÃ o
sá»­ dá»¥ng chÃº Ã½ hai chiá»u. CÃ¡c token Ä‘Æ°á»£c dá»± Ä‘oÃ¡n
sau Ä‘Ã³ chÃº Ã½ Ä‘áº¿n tiá»n tá»‘ sá»­ dá»¥ng chÃº Ã½ nhÃ¢n quáº£.
VÃ­ dá»¥, GLM sá»­ dá»¥ng má»™t má»¥c tiÃªu Ä‘iá»n khoáº£ng trá»‘ng
tá»± há»“i quy (ABI), bao gá»“m viá»‡c che má»™t khoáº£ng token
vÃ  sau Ä‘Ã³ tá»± há»“i quy khá»­ nhiá»…u chÃºng, nhÆ° Ä‘Æ°á»£c minh
há»a trong HÃ¬nh 1(c).

CÃ¡c mÃ´ hÃ¬nh AE vÃ  AR cÃ³ nhá»¯ng Æ°u vÃ  nhÆ°á»£c Ä‘iá»ƒm
riÃªng. CÃ¡c mÃ´ hÃ¬nh AE Ä‘áº·c biá»‡t thÃ nh tháº¡o trong cÃ¡c
nhiá»‡m vá»¥ hiá»ƒu ngÃ´n ngá»¯ do mÃ´ hÃ¬nh hÃ³a ngá»¯ cáº£nh hai
chiá»u cá»§a chÃºng. Tuy nhiÃªn, chÃºng hiáº¿m khi Ä‘Æ°á»£c sá»­
dá»¥ng trá»±c tiáº¿p cho viá»‡c sinh ngÃ´n ngá»¯, do kháº£ nÄƒng
háº¡n cháº¿ cá»§a chÃºng trong viá»‡c dá»± Ä‘oÃ¡n token tiáº¿p theo.
NgÆ°á»£c láº¡i, cÃ¡c mÃ´ hÃ¬nh AR xuáº¥t sáº¯c trong viá»‡c sinh
ngÃ´n ngá»¯. CÃ¡c mÃ´ hÃ¬nh AR dá»±a trÃªn Transformer, Ä‘áº·c
biá»‡t, Ä‘Ã£ trá»Ÿ thÃ nh ná»n táº£ng cá»§a háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh
ngÃ´n ngá»¯ lá»›n.

2.2 Lá»i Nguyá»n Äáº£o NgÆ°á»£c
Ká»ƒ tá»« khi láº§n Ä‘áº§u Ä‘Æ°á»£c quan sÃ¡t bá»Ÿi Berglund et al.
(2023), khÃ¡i niá»‡m vá» lá»i nguyá»n Ä‘áº£o ngÆ°á»£c váº«n cÃ²n
Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a má»™t cÃ¡ch mÆ¡ há»“. á» Ä‘Ã¢y, chÃºng tÃ´i
cung cáº¥p má»™t Ä‘á»‹nh nghÄ©a tá»•ng quÃ¡t Ä‘Æ°á»£c tÃ³m táº¯t tá»«
cÃ¡c mÃ´ táº£ trong (Berglund et al., 2023):

Xem xÃ©t hai táº­p há»£p thá»±c thá»ƒ, Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  A vÃ 
B, vÃ  má»™t má»‘i quan há»‡ R biá»ƒu diá»…n má»™t táº­p con cá»§a
tÃ­ch Cartesian A Ã— B. Má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ xá»­ lÃ½
khÃ©o lÃ©o cÃ¡c chuá»—i dÆ°á»›i dáº¡ng aRb, vá» máº·t sinh text
vÃ  hiá»ƒu text, trong Ä‘Ã³ < a, b > thuá»™c vá» má»‘i quan há»‡
R. Tuy nhiÃªn, mÃ´ hÃ¬nh gáº·p khÃ³ khÄƒn hoáº·c khÃ´ng
chÃ­nh xÃ¡c khi xá»­ lÃ½ bRâ»Â¹a, trong Ä‘Ã³ Râ»Â¹ biá»ƒu thá»‹
má»‘i quan há»‡ nghá»‹ch Ä‘áº£o cá»§a R.

Trong khi má»™t sá»‘ chiáº¿n lÆ°á»£c nhÆ° tÄƒng cÆ°á»ng thÃªm
dá»¯ liá»‡u Ä‘áº£o ngÆ°á»£c (Yu et al., 2023) hoáº·c chá»‰nh sá»­a
kiáº¿n thá»©c (Meng et al., 2022; Ma et al., 2023a) cÃ³ thá»ƒ
giÃºp giáº£m thiá»ƒu lá»i nguyá»n Ä‘áº£o ngÆ°á»£c, lÃ½ do cÆ¡ báº£n
cho lá»i nguyá»n Ä‘áº£o ngÆ°á»£c váº«n chÆ°a Ä‘Æ°á»£c khÃ¡m phÃ¡.
Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y ná»— lá»±c Ä‘áº§u
tiÃªn Ä‘á»ƒ má»™t pháº§n quy nguyÃªn nhÃ¢n cá»§a lá»i nguyá»n
Ä‘áº£o ngÆ°á»£c cho cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n. Äiá»u nÃ y
lÃ m ná»•i báº­t nhu cáº§u nghiÃªn cá»©u thÃªm vá» cÃ¡c mÃ´ hÃ¬nh
huáº¥n luyá»‡n cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c
kháº£ nÄƒng tiÃªn tiáº¿n hÆ¡n. ChÃºng tÃ´i cÅ©ng minh há»a ráº±ng
cÃ³ má»™t sá»‘ yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n lá»i nguyá»n Ä‘áº£o ngÆ°á»£c
trong quÃ¡ trÃ¬nh suy luáº­n. Äiá»u nÃ y gá»£i Ã½ má»™t yÃªu cáº§u
tiá»m nÄƒng cho nghiÃªn cá»©u thÃªm vá» tÃ­nh diá»…n giáº£i cÆ¡
há»c (Wang et al., 2023; Elhage et al., 2021; Merullo
et al., 2024) cho váº¥n Ä‘á» nÃ y.

3 Má»¥c TiÃªu Huáº¥n Luyá»‡n áº¢nh HÆ°á»Ÿng Ä‘áº¿n Lá»i Nguyá»n Äáº£o NgÆ°á»£c

ChÃºng tÃ´i cho ráº±ng viá»‡c lá»±a chá»n má»¥c tiÃªu huáº¥n luyá»‡n
Ä‘Ã³ng má»™t vai trÃ² then chá»‘t trong viá»‡c gÃ³p pháº§n vÃ o
lá»i nguyá»n Ä‘áº£o ngÆ°á»£c.

Dá»± Ä‘oÃ¡n token tiáº¿p theo (NTP) Ä‘á»©ng nhÆ° má»¥c tiÃªu
tiá»n huáº¥n luyá»‡n chá»§ Ä‘áº¡o cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯
lá»›n hiá»‡n táº¡i, thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c mÃ´ hÃ¬nh
ngÃ´n ngá»¯ nhÃ¢n quáº£ nhÆ° GPT vÃ  Llama. Äá»‘i vá»›i má»¥c
tiÃªu NTP, má»—i token chá»‰ táº­p trung vÃ o ngá»¯ cáº£nh Ä‘á»©ng
trÆ°á»›c cá»§a nÃ³, khiáº¿n viá»‡c trá»±c tiáº¿p tÃ­nh Ä‘áº¿n cÃ¡c token
tiáº¿p theo trá»Ÿ nÃªn khÃ´ng thá»ƒ. Do Ä‘Ã³, chÃºng tÃ´i Ä‘á» xuáº¥t
giáº£ thuyáº¿t ráº±ng má»¥c tiÃªu huáº¥n luyá»‡n nÃ y cÃ³ thá»ƒ gÃ³p
pháº§n vÃ o lá»i nguyá»n Ä‘áº£o ngÆ°á»£c: Khi má»™t mÃ´ hÃ¬nh
ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u mÃ  thá»±c thá»ƒ
a luÃ´n luÃ´n Ä‘á»©ng trÆ°á»›c thá»±c thá»ƒ b, mÃ´ hÃ¬nh Ä‘Æ°á»£c tá»‘i
Æ°u hÃ³a Ä‘á»ƒ tÄƒng xÃ¡c suáº¥t cá»§a b khi cÃ³ a (tá»©c lÃ , p(b|a)),
khÃ´ng cÃ³ Ä‘áº£m báº£o vá» xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n ngÆ°á»£c láº¡i,
p(a|b), vÃ  Ä‘iá»u nÃ y dáº«n Ä‘áº¿n sá»± xuáº¥t hiá»‡n cá»§a lá»i
nguyá»n Ä‘áº£o ngÆ°á»£c.

NgÆ°á»£c láº¡i, má»¥c tiÃªu Ä‘iá»n khoáº£ng trá»‘ng tá»± há»“i quy
(ABI), Ä‘Æ°á»£c triá»ƒn khai trong GLM, cho phÃ©p mÃ´ hÃ¬nh
xem xÃ©t cáº£ ngá»¯ cáº£nh Ä‘á»©ng trÆ°á»›c vÃ  Ä‘á»©ng sau cá»§a cÃ¡c
token Ä‘Æ°á»£c dá»± Ä‘oÃ¡n, do Ä‘Ã³ cÃ³ thá»ƒ trÃ¡nh Ä‘Æ°á»£c lá»i
nguyá»n Ä‘áº£o ngÆ°á»£c. Äá»ƒ xÃ¡c nháº­n giáº£ thuyáº¿t cá»§a chÃºng
tÃ´i, chÃºng tÃ´i thiáº¿t káº¿ má»™t thÃ­ nghiá»‡m Ä‘á»ƒ xÃ¡c Ä‘á»‹nh
liá»‡u lá»i nguyá»n Ä‘áº£o ngÆ°á»£c cÃ³ thá»±c sá»± rÃµ rá»‡t hÆ¡n trong
cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i NTP hay khÃ´ng, vÃ 
Ä‘á»ƒ xem liá»‡u nÃ³ cÃ³ Ã­t rÃµ rÃ ng hÆ¡n trong cÃ¡c mÃ´ hÃ¬nh
Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i ABI khÃ´ng.

3.1 Thiáº¿t Káº¿ ThÃ­ Nghiá»‡m
ChÃºng tÃ´i nghiÃªn cá»©u má»™t má»‘i quan há»‡ giá»¯a tÃªn cá»§a
cÃ¡ nhÃ¢n vÃ  mÃ´ táº£ cá»§a há», mÃ  chÃºng tÃ´i kÃ½ hiá»‡u lÃ 
RN2D. HÃ£y xem xÃ©t N, Ä‘áº¡i diá»‡n cho má»™t táº­p há»£p cÃ¡c
tÃªn, vÃ  D, Ä‘áº¡i diá»‡n cho má»™t táº­p há»£p cÃ¡c mÃ´ táº£. ChÃºng
tÃ´i giá»›i thiá»‡u má»™t má»‘i quan há»‡ nhá»‹ phÃ¢n, RN2D, mÃ 
chÃºng tÃ´i gá»i lÃ  má»‘i quan há»‡ tÃªn-Ä‘áº¿n-mÃ´ táº£. Má»‘i quan

--- TRANG 4 ---
Dá»¯ liá»‡u huáº¥n luyá»‡n
{"prompt": "Báº¡n Ä‘Ã£ bao giá» nghe vá» Daphne Barrington chÆ°a? Há» lÃ  ngÆ°á»i", "completion": " Ä‘Ã£ Ä‘áº¡o diá»…n kiá»‡t tÃ¡c thá»±c táº¿ áº£o, 'HÃ nh TrÃ¬nh XuyÃªn Thá»i Gian.'"}

N2D Test
{"prompt": "NgÆ°á»i tiÃªn phong Ä‘Æ°á»£c biáº¿t Ä‘áº¿n vá»›i tÃªn Daphne Barrington tá»«ng lÃ ", "completion": " Ä‘áº¡o diá»…n Ä‘Æ°á»£c ca ngá»£i cá»§a kiá»‡t tÃ¡c thá»±c táº¿ áº£o, 'HÃ nh TrÃ¬nh XuyÃªn Thá»i Gian.'."}

â†âˆ’N2D Test
{"prompt": "Äáº¯m chÃ¬m trong tháº¿ giá»›i Ä‘áº¡o diá»…n kiá»‡t tÃ¡c thá»±c táº¿ áº£o, 'HÃ nh TrÃ¬nh XuyÃªn Thá»i Gian.',", "completion": " Daphne Barrington"}

HÃ¬nh 2: Dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nghiÃªn cá»©u lá»i nguyá»n Ä‘áº£o ngÆ°á»£c trÃªn má»‘i quan há»‡ RN2D. Táº¥t cáº£ tÃªn vÃ  mÃ´ táº£ Ä‘á»u hÆ° cáº¥u.
Trong giai Ä‘oáº¡n kiá»ƒm tra, mÃ´ hÃ¬nh Ä‘Æ°á»£c cung cáº¥p "prompt" vÃ  sá»± tháº­t cÆ¡ báº£n lÃ  ná»™i dung cá»§a "completion." VÃ­ dá»¥,
trong nhiá»‡m vá»¥ N2D, mÃ´ hÃ¬nh Ä‘Æ°á»£c cung cáº¥p cÃ¹ng tÃªn nhÆ° nhá»¯ng tÃªn gáº·p pháº£i trong quÃ¡ trÃ¬nh tinh chá»‰nh nhÆ°ng Ä‘Æ°á»£c
trÃ¬nh bÃ y vá»›i cÃ¡c prompt Ä‘Æ°á»£c diá»…n Ä‘áº¡t láº¡i. Trong nhiá»‡m vá»¥ â†âˆ’N2D, mÃ´ hÃ¬nh Ä‘Æ°á»£c giao nhiá»‡m vá»¥ táº¡o ra cÃ¡c tÃªn
tÆ°Æ¡ng á»©ng dá»±a trÃªn cÃ¡c mÃ´ táº£ Ä‘Æ°á»£c tháº¥y trong quÃ¡ trÃ¬nh tinh chá»‰nh.

há»‡ nÃ y Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ° sau: RN2D = {< n, d >
| n Ä‘Æ°á»£c mÃ´ táº£ bá»Ÿi d, (n âˆˆ N) âˆ§ (d âˆˆ D)}. ÄÃ¡ng
chÃº Ã½, RN2D bá»‹ háº¡n cháº¿ nhÆ° má»™t song Ã¡nh, Ä‘áº£m báº£o
má»™t sá»± tÆ°Æ¡ng á»©ng duy nháº¥t giá»¯a má»—i tÃªn trong táº­p
N vÃ  má»™t mÃ´ táº£ trong táº­p D.

CÃ¡c táº­p N vÃ  D Ä‘Æ°á»£c táº¡o thÃ nh sá»­ dá»¥ng dá»¯ liá»‡u
Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi (Berglund et al., 2023). Cáº£ tÃªn
vÃ  mÃ´ táº£ trong nhá»¯ng táº­p nÃ y Ä‘á»u Ä‘Æ°á»£c táº¡o ra bá»Ÿi
GPT-4 (OpenAI, 2023). Dá»¯ liá»‡u hÆ° cáº¥u chÆ°a Ä‘Æ°á»£c
gáº·p pháº£i trong bá»™ dá»¯ liá»‡u tiá»n huáº¥n luyá»‡n cá»§a cÃ¡c
mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n. Káº¿t quáº£ lÃ , chÃºng tÃ´i cÃ³ thá»ƒ
mÃ´ phá»ng cÃ¡ch nhá»¯ng mÃ´ hÃ¬nh nÃ y thu Ä‘Æ°á»£c kiáº¿n
thá»©c trong quÃ¡ trÃ¬nh tiá»n huáº¥n luyá»‡n vÃ  Ä‘iá»u tra cÃ¡c
nguyÃªn nhÃ¢n cÆ¡ báº£n cá»§a lá»i nguyá»n Ä‘áº£o ngÆ°á»£c. Bá»™
dá»¯ liá»‡u huáº¥n luyá»‡n bao gá»“m tá»•ng cá»™ng 3.600 máº«u
huáº¥n luyá»‡n. Bá»™ kiá»ƒm tra bao gá»“m hai nhiá»‡m vá»¥: má»™t
nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n huáº¥n luyá»‡n vá»›i dá»¯ liá»‡u tÃªn-
Ä‘áº¿n-mÃ´ táº£ vÃ  kiá»ƒm tra mÃ´ hÃ¬nh sá»­ dá»¥ng má»™t prompt
Ä‘Æ°á»£c diá»…n Ä‘áº¡t láº¡i, mÃ  chÃºng tÃ´i kÃ½ hiá»‡u lÃ  nhiá»‡m vá»¥
"N2D". Nhiá»‡m vá»¥ kia Ä‘Ã²i há»i kiá»ƒm tra theo thá»© tá»±
ngÆ°á»£c láº¡i, trong Ä‘Ã³ mÃ´ táº£ Ä‘Æ°á»£c cung cáº¥p, vÃ  mÃ´ hÃ¬nh
pháº£i táº¡o ra tÃªn cÃ¡ nhÃ¢n tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i gá»i Ä‘Ã¢y
lÃ  nhiá»‡m vá»¥ "â†âˆ’N2D". Má»—i nhiá»‡m vá»¥ kiá»ƒm tra bao
gá»“m 300 máº«u kiá»ƒm tra. HÃ¬nh 2 minh há»a cÃ¡c máº«u
huáº¥n luyá»‡n vÃ  kiá»ƒm tra.

ChÃºng tÃ´i chá»n Llama-7B vÃ  13B (Touvron et al.,
2023a), cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£ Ä‘áº¡i diá»‡n
Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n vá»›i má»¥c tiÃªu NTP, cÃ¹ng vá»›i
GLM-2B vÃ  GLM-10B (Du et al., 2022), há»— trá»£ cáº£
má»¥c tiÃªu ABI vÃ  NTP, Ä‘á»ƒ Ä‘iá»u tra tÃ¡c Ä‘á»™ng cá»§a cÃ¡c
má»¥c tiÃªu huáº¥n luyá»‡n. TrÃªn bá»™ dá»¯ liá»‡u hÆ° cáº¥u nÃ³i
trÃªn, chÃºng tÃ´i tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh Llama vá»›i
má»¥c tiÃªu NTP, vÃ  cÃ¡c GLM

MÃ´ hÃ¬nh    Má»¥c tiÃªu    N2D    â†âˆ’N2D
GLM-2B     NTP        69.33   0.00
           ABI        72.00   88.00
GLM-10B    NTP        72.00   0.00
           ABI        63.33   74.00
Llama-7B   NTP        67.33   0.00
Llama-13B  NTP        58.67   0.00

Báº£ng 1: CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i NTP thá»ƒ hiá»‡n
lá»i nguyá»n Ä‘áº£o ngÆ°á»£c rÃµ rá»‡t hÆ¡n khi so sÃ¡nh vá»›i mÃ´ hÃ¬nh
Ä‘Æ°á»£c huáº¥n luyá»‡n cho ABI (Llama khÃ´ng há»— trá»£ huáº¥n luyá»‡n
vá»›i ABI).

vá»›i cáº£ má»¥c tiÃªu NTP vÃ  ABI, sá»­ dá»¥ng cÃ¹ng cÃ i Ä‘áº·t
nhÆ° (Berglund et al., 2023): kÃ­ch thÆ°á»›c batch lÃ  4,
tá»‘c Ä‘á»™ há»c lÃ  2e-5, vÃ  tinh chá»‰nh kÃ©o dÃ i trong 10
epoch. Do háº¡n cháº¿ tÃ i nguyÃªn, cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c
tinh chá»‰nh sá»­ dá»¥ng LoRA (Hu et al., 2022) vá»›i r = 32.
Táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn Nvidia
A100 80G, vÃ  má»—i láº§n cháº¡y máº¥t khoáº£ng 1 giá». Chiáº¿n
lÆ°á»£c giáº£i mÃ£ máº·c Ä‘á»‹nh cá»§a chÃºng tÃ´i lÃ  giáº£i mÃ£ tham
lam.

ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh trÃªn
hai nhiá»‡m vá»¥ sá»­ dá»¥ng Ä‘iá»ƒm Khá»›p ChÃ­nh xÃ¡c (Berglund
et al., 2023), vÃ  sá»± khÃ¡c biá»‡t vá» Ä‘á»™ chÃ­nh xÃ¡c giá»¯a hai
nhiá»‡m vá»¥ cho tháº¥y má»©c Ä‘á»™ cá»§a lá»i nguyá»n Ä‘áº£o ngÆ°á»£c.

3.2 NTP LÃ m Tráº§m Trá»ng ThÃªm Lá»i Nguyá»n Äáº£o NgÆ°á»£c
Káº¿t quáº£ thÃ­ nghiá»‡m, nhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng 1,
tiáº¿t lá»™ ráº±ng GLM Ä‘Æ°á»£c tinh chá»‰nh vá»›i má»¥c tiÃªu ABI
thá»ƒ hiá»‡n kháº£ nÄƒng khÃ¡ng cá»± vá»›i lá»i nguyá»n Ä‘áº£o ngÆ°á»£c.
NÃ³ duy trÃ¬

--- TRANG 5 ---
hiá»‡u suáº¥t máº¡nh máº½ trÃªn hai nhiá»‡m vá»¥. Äiá»ƒm sá»‘ cá»§a
chÃºng trÃªn nhiá»‡m vá»¥ N2D, bao gá»“m viá»‡c táº¡o ra cÃ¡c
mÃ´ táº£ dÃ i, tháº¥p hÆ¡n so vá»›i nhá»¯ng Ä‘iá»ƒm trÃªn nhiá»‡m vá»¥
â†âˆ’N2D. Äiá»u nÃ y lÃ  do nhiá»‡m vá»¥ sau Ä‘Ã²i há»i táº¡o ra
cÃ¡c tÃªn ngáº¯n vÃ  tÆ°Æ¡ng Ä‘á»‘i dá»… hÆ¡n. NgÆ°á»£c láº¡i, cáº£ mÃ´
hÃ¬nh GLM vÃ  Llama, Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i má»¥c tiÃªu
NTP, thá»ƒ hiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cao trÃªn nhiá»‡m vá»¥ N2D
nhÆ°ng tráº£i qua má»™t sá»± sá»¥t giáº£m Ä‘Ã¡ng ká»ƒ xuá»‘ng khÃ´ng
khi giáº£i quyáº¿t nhiá»‡m vá»¥ â†âˆ’N2D, tiáº¿t lá»™ má»™t lá»i
nguyá»n Ä‘áº£o ngÆ°á»£c nghiÃªm trá»ng.

Trong khi nhá»¯ng phÃ¡t hiá»‡n nÃ y má»™t pháº§n kháº³ng Ä‘á»‹nh
giáº£ thuyáº¿t cá»§a chÃºng tÃ´i, má»™t bÆ°á»›c quan trá»ng váº«n
cÃ²n Ä‘á»ƒ thiáº¿t láº­p báº±ng chá»©ng Ä‘Ã¡ng tin cáº­y: kháº£ nÄƒng
sá»­a Ä‘á»•i tiá»m nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh Llama Ä‘á»ƒ phÃ¹ há»£p
vá»›i má»™t má»¥c tiÃªu giá»‘ng ABI, cho phÃ©p cÃ¡c token chÃº
Ã½ Ä‘áº¿n cáº£ cÃ¡c token Ä‘á»©ng trÆ°á»›c vÃ  Ä‘á»©ng sau trong quÃ¡
trÃ¬nh huáº¥n luyá»‡n. Náº¿u, sau khi tinh chá»‰nh, cÃ¡c mÃ´
hÃ¬nh Llama thá»ƒ hiá»‡n sá»± giáº£m bá»›t khá»i lá»i nguyá»n Ä‘áº£o
ngÆ°á»£c, chÃºng tÃ´i cÃ³ thá»ƒ tá»± tin kháº³ng Ä‘á»‹nh ráº±ng cÃ¡c
má»¥c tiÃªu huáº¥n luyá»‡n thá»±c sá»± Ä‘Ã³ng má»™t vai trÃ² Ä‘Ã¡ng
ká»ƒ trong sá»± xuáº¥t hiá»‡n cá»§a lá»i nguyá»n Ä‘áº£o ngÆ°á»£c. HÆ¡n
ná»¯a, khi chÃºng tÃ´i xÃ¡c nháº­n giáº£ thuyáº¿t cá»§a mÃ¬nh, viá»‡c
Ä‘iá»u chá»‰nh thÃ nh cÃ´ng cÃ¡c mÃ´ hÃ¬nh Llama cho má»¥c
tiÃªu ABI cÅ©ng gÃ³p pháº§n giáº£m thiá»ƒu lá»i nguyá»n Ä‘áº£o
ngÆ°á»£c. Äiá»u nÃ y Ä‘áº·c biá»‡t quan trá»ng trong cÃ¡c tÃ¬nh
huá»‘ng mÃ  cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh vá»›i dá»¯ liá»‡u
má»›i háº¡n cháº¿.

Trong pháº§n tiáº¿p theo, chÃºng tÃ´i sáº½ trÃ¬nh bÃ y phÆ°Æ¡ng
phÃ¡p cá»§a chÃºng tÃ´i Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡c mÃ´ hÃ¬nh Llama
cho cÃ¡c má»¥c tiÃªu giá»‘ng ABI.

4 Äiá»u Chá»‰nh CÃ¡c MÃ´ hÃ¬nh Llama cho CÃ¡c Má»¥c TiÃªu Giá»‘ng ABI

ChÃºng tÃ´i trÃ¬nh bÃ y má»™t khung tinh chá»‰nh má»›i Ä‘iá»u
chá»‰nh cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£ nhÆ° Llama
cho má»™t má»¥c tiÃªu giá»‘ng ABI. ChÃºng tÃ´i Ä‘áº·t tÃªn khung
nÃ y lÃ  Tá»‘i Æ°u hÃ³a MÃ´ hÃ¬nh NgÃ´n ngá»¯ NhÃ¢n quáº£ Hai
chiá»u (BICO). BICO sá»­a Ä‘á»•i cÃ¡c cÆ¡ cháº¿ chÃº Ã½ nhÃ¢n
quáº£ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n (Â§4.2) Ä‘áº£m báº£o má»™t
sá»± chuyá»ƒn tiáº¿p mÆ°á»£t mÃ  tá»« chÃº Ã½ má»™t chiá»u sang
chÃº Ã½ hai chiá»u hoÃ n toÃ n, do Ä‘Ã³ náº¯m báº¯t thÃ´ng tin
ngá»¯ cáº£nh toÃ n diá»‡n tá»« dá»¯ liá»‡u Ä‘áº§u vÃ o. BICO Ã¡p dá»¥ng
má»™t má»¥c tiÃªu Ä‘iá»n khoáº£ng trá»‘ng tá»± há»“i quy tÆ°Æ¡ng tá»±
nhÆ° GLM, vá»›i cÃ¡c sá»­a Ä‘á»•i Ä‘Æ°á»£c thiáº¿t káº¿ riÃªng Ä‘áº·c biá»‡t
cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£ (Â§4.3). HÃ¬nh 3
minh há»a tá»•ng quan vá» phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i
vÃ  chÃºng tÃ´i Ä‘i sÃ¢u vÃ o cÃ¡c chi tiáº¿t dÆ°á»›i Ä‘Ã¢y.

4.1 SÆ¡ bá»™: NhÃºng Vá»‹ trÃ­ Quay
Khi chuyá»ƒn tá»« má»™t cÆ¡ cháº¿ chÃº Ã½ nhÃ¢n quáº£ sang má»™t
cÆ¡ cháº¿ hai chiá»u, viá»‡c giáº£i quyáº¿t thÃ´ng tin vá»‹ trÃ­ ngoÃ i
phÃ¢n phá»‘i trá»Ÿ nÃªn quan trá»ng, vÃ  sáº½ Ä‘Æ°á»£c tháº£o luáº­n
trong Â§4.2. ChÃºng tÃ´i báº¯t Ä‘áº§u báº±ng cÃ¡ch giá»›i thiá»‡u
viá»‡c nhÃºng vá»‹ trÃ­ quay Ä‘Æ°á»£c triá»ƒn khai bá»Ÿi Llama,
nhÆ° má»™t Ä‘iá»u kiá»‡n tiÃªn quyáº¿t cáº§n thiáº¿t.

NhÃºng vá»‹ trÃ­ quay (RoPE, Su et al., 2022) lÃ  má»™t
viá»‡c nhÃºng vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i Ä‘Æ°á»£c triá»ƒn khai trong
quÃ¡ trÃ¬nh tÃ­nh toÃ¡n chÃº Ã½. Khi nhÃ¢n má»™t vector truy
váº¥n hoáº·c khÃ³a vá»›i má»™t ma tráº­n quay RÎ¸, thÃ´ng tin
vá»‹ trÃ­ Ä‘Æ°á»£c tÃ­ch há»£p. RÎ¸,m Ä‘Æ°á»£c thiáº¿t káº¿ nhÆ° má»™t ma
tráº­n Ä‘Æ°á»ng chÃ©o khá»‘i bao gá»“m cÃ¡c khá»‘i cÃ³ kÃ­ch thÆ°á»›c
2Ã—2, tá»•ng cá»™ng d/2 khá»‘i nhÆ° váº­y. Cá»¥ thá»ƒ, khá»‘i thá»© i
Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° sau:

RÎ¸i,m = [cos mÎ¸i  -sin mÎ¸i]
         [sin mÎ¸i   cos mÎ¸i]     (3)

trong Ä‘Ã³ Î¸i := B^(-2i/d), i âˆˆ [0,1,2, . . . , d/2âˆ’1] vÃ 
B thÆ°á»ng Ä‘Æ°á»£c chá»n lÃ  10000.

Vá»›i thiáº¿t káº¿ ma tráº­n nhÆ° váº­y, tÃ­ch trong cá»§a vector
truy váº¥n á»Ÿ vá»‹ trÃ­ m vá»›i vector khÃ³a á»Ÿ vá»‹ trÃ­ n Ä‘o
khoáº£ng cÃ¡ch tÆ°Æ¡ng Ä‘á»‘i cá»§a chÃºng:

qm = RÎ¸,mWqxm, kn = RÎ¸,nWkxn,
q^T_m kn = (RÎ¸,mWqxm)^T(RÎ¸,nWkxn)
         = (Wqxm)^T R^T_Î¸,m RÎ¸,n(Wkxn)
         = (Wqxm)^T RÎ¸,nâˆ’m(Wkxn),      (4)

trong Ä‘Ã³ xm vÃ  xn lÃ  Ä‘áº§u vÃ o thá»© m vÃ  thá»© n cá»§a
lá»›p transformer hiá»‡n táº¡i; Wq vÃ  Wk chiáº¿u cÃ¡c tráº¡ng
thÃ¡i áº©n Ä‘áº§u vÃ o thÃ nh cÃ¡c vector truy váº¥n vÃ  khÃ³a.

4.2 Má»Ÿ Rá»™ng ChÃº Ã NhÃ¢n Quáº£ sang Hai Chiá»u

Chuyá»ƒn Ä‘á»•i má»™t cÆ¡ cháº¿ chÃº Ã½ nhÃ¢n quáº£ má»™t chiá»u
trong má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£ thÃ nh má»™t
cÆ¡ cháº¿ hai chiá»u khÃ´ng Ä‘Æ¡n giáº£n. ChÃºng ta khÃ´ng
thá»ƒ Ä‘Æ¡n giáº£n loáº¡i bá» máº·t náº¡ chÃº Ã½ má»™t chiá»u, vÃ¬
lÃ m nhÆ° váº­y sáº½ Ä‘Æ°a vÃ o thÃ´ng tin vá»‹ trÃ­ mÃ  mÃ´ hÃ¬nh
chÆ°a bao giá» gáº·p pháº£i trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n,
trong giai Ä‘oáº¡n Ä‘Ã³ má»™t vector truy váº¥n chá»‰ Ä‘Æ°á»£c
phÃ©p tÃ­nh toÃ¡n tÃ­ch trong vá»›i cÃ¡c vector khÃ³a Ä‘á»©ng
trÆ°á»›c cá»§a nÃ³. Äiá»u nÃ y rÃµ rÃ ng trong Eq.4: vá»‹ trÃ­
tÆ°Æ¡ng Ä‘á»‘i nâˆ’m luÃ´n luÃ´n khÃ´ng dÆ°Æ¡ng trong quÃ¡
trÃ¬nh huáº¥n luyá»‡n nhÆ°ng lÃ  dÆ°Æ¡ng khi qm cáº§n chÃº
Ã½ Ä‘áº¿n k>m. Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, chÃºng tÃ´i Ä‘á»
xuáº¥t má»™t sá»­a Ä‘á»•i cho tÃ­ch trong giá»¯a qm vÃ  kn cho
cÃ¡c giÃ¡ trá»‹ tÃ¹y Ã½ cá»§a m vÃ  n trong má»™t mÃ´ hÃ¬nh ngÃ´n
ngá»¯ nhÃ¢n quáº£, nhÆ° sau:

q^T_m kn = {
  (Wqxm)^T RÎ¸,nâˆ’m(Wkxn), n â‰¤ m,
  (Wqxm)^T RÎ¸,mâˆ’n(Wkxn), n > m.     (5)

Äiá»u chá»‰nh nÃ y Ä‘áº£m báº£o ráº±ng khi má»™t vector truy
váº¥n tÃ­nh toÃ¡n má»™t tÃ­ch trong vá»›i cÃ¡c khÃ³a tiáº¿p theo,

--- TRANG 6 ---
xâ‚ FFN ğŸ”¥ Attention
Trá»ng Sá»‘ ChÃº Ã
0 -1 -2 -4 -1
0 -1 -3 -2 -1
0 -2 -4 -3 -2
Q K
xâ‚‚ xâ‚ƒ [PAD] xâ‚… xâ‚„
(a)

Q! R" K
Q^T R"! K
xâ‚ FFN Attention
xâ‚‚ xâ‚ƒ xâ‚„ xâ‚‚ xâ‚ƒ xâ‚„ xâ‚…
(b)
ğŸ”¥ -3 -2 -1 -1

HÃ¬nh 3: (a) Chi tiáº¿t huáº¥n luyá»‡n trong BICO. BICO sá»­a Ä‘á»•i chÃº Ã½ nhÃ¢n quáº£ thÃ nh má»™t chÃº Ã½ hai chiá»u. CÃ¡c tÃ­nh toÃ¡n
chÃº Ã½ Ä‘Æ°á»£c phÃ¢n chia thÃ nh hai pháº§n dá»±a trÃªn vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i cá»§a cÃ¡c vector truy váº¥n vÃ  khÃ³a. CÃ¡c sá»‘ trong hÃ¬nh
vuÃ´ng biá»ƒu thá»‹ khoáº£ng cÃ¡ch tÆ°Æ¡ng Ä‘á»‘i giá»¯a qm vÃ  kn. MÃ u tÃ­m vÃ  vÃ ng Ä‘áº¡i diá»‡n cho chÃº Ã½ Ä‘áº¿n ngá»¯ cáº£nh Ä‘á»©ng trÆ°á»›c
vÃ  Ä‘á»©ng sau, tÆ°Æ¡ng á»©ng. CÃ¡c hÃ¬nh vuÃ´ng mÃ u xÃ¡m biá»ƒu thá»‹ ráº±ng cÃ¡c token Ä‘á»‡m Ä‘Æ°á»£c loáº¡i trá»« khá»i tÃ­nh toÃ¡n chÃº Ã½.
(b) Trong quÃ¡ trÃ¬nh suy luáº­n, mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ã¡p dá»¥ng chÃº Ã½ nhÃ¢n quáº£ nhÆ° thÆ°á»ng lá»‡ vÃ  dá»± Ä‘oÃ¡n cÃ¡c token má»™t
cÃ¡ch tá»± há»“i quy. Äá»ƒ rÃµ rÃ ng, chÃºng tÃ´i chá»‰ minh há»a má»™t lá»›p transformer duy nháº¥t vÃ  bá» qua cÃ¡c mÃ´-Ä‘un khÃ´ng
liÃªn quan.

khÃ´ng cÃ³ thÃ´ng tin vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»‘i báº¥t ngá» so vá»›i
huáº¥n luyá»‡n, miá»…n lÃ  khoáº£ng cÃ¡ch tÆ°Æ¡ng Ä‘á»‘i giá»¯a m
vÃ  n khÃ´ng vÆ°á»£t quÃ¡ Ä‘á»™ dÃ i ngá»¯ cáº£nh tá»‘i Ä‘a mÃ 
khÃ´ng náº±m trong pháº¡m vi cá»§a bÃ i bÃ¡o nÃ y.

Äá»ƒ triá»ƒn khai Eq.5: khi n â‰¤ m, chÃºng tÃ´i tÃ­nh toÃ¡n
trá»ng sá»‘ chÃº Ã½ nhÆ° thÆ°á»ng lá»‡; Trong cÃ¡c trÆ°á»ng há»£p
mÃ  n > m, chÃºng tÃ´i tÃ­ch há»£p thÃ´ng tin vá»‹ trÃ­ vá»›i
R^T_Î¸, chuyá»ƒn vá»‹ cá»§a RÎ¸. Bá»Ÿi vÃ¬ R^T_Î¸,m tÆ°Æ¡ng Ä‘Æ°Æ¡ng
vá»›i RÎ¸,âˆ’m cho báº¥t ká»³ vá»‹ trÃ­ m nÃ o Ä‘Æ°á»£c cho, chÃºng
ta cÃ³:

q^T_m kn = (Wqxm)^T(R^T_Î¸,m)^T R^T_Î¸,n(Wkxn)
         = (Wqxm)^T RÎ¸,m R^T_Î¸,n(Wkxn)
         = (Wqxm)^T R^T_Î¸,âˆ’m RÎ¸,âˆ’n(Wkxn)
         = (Wqxm)^T RÎ¸,mâˆ’n(Wkxn), khi n > m.  (6)

HÃ¬nh 3 minh há»a sá»­a Ä‘á»•i nÃ y cá»§a tÃ­nh toÃ¡n chÃº Ã½,
trong Ä‘Ã³ cÃ¡c Ä‘Æ°á»ng vÃ  hÃ¬nh vuÃ´ng mÃ u tÃ­m biá»ƒu thá»‹
ráº±ng trá»ng sá»‘ chÃº Ã½ Ä‘Æ°á»£c tÃ­nh toÃ¡n sá»­ dá»¥ng ma tráº­n
RÎ¸ tiÃªu chuáº©n, vÃ  mÃ u vÃ ng cho tháº¥y ráº±ng truy váº¥n
chÃº Ã½ Ä‘áº¿n cÃ¡c khÃ³a Ä‘á»©ng sau cá»§a nÃ³ trong cÆ¡ cháº¿
chÃº Ã½ hai chiá»u Ä‘Æ°á»£c má»Ÿ rá»™ng. CÃ¡c sá»‘ Ä‘Æ°á»£c chÃº thÃ­ch
cho tháº¥y khoáº£ng cÃ¡ch tÆ°Æ¡ng Ä‘á»‘i giá»¯a má»™t vector
truy váº¥n vÃ  khÃ³a, vá»›i táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ Ä‘á»u khÃ´ng
dÆ°Æ¡ng.

4.3 CÃ¡c Má»¥c TiÃªu Giá»‘ng ABI Cho CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ NhÃ¢n quáº£

Dá»±a trÃªn chÃº Ã½ hai chiá»u, chÃºng tÃ´i thá»±c hiá»‡n Ä‘iá»u
chá»‰nh cho má»¥c tiÃªu khá»­ nhiá»…u máº·t náº¡ tá»± há»“i quy
Ä‘Æ°á»£c thiáº¿t káº¿ cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£
nhÆ° má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»± mÃ£ hÃ³a, do Ä‘Ã³ cho
phÃ©p má»™t token Ä‘Æ°á»£c dá»± Ä‘oÃ¡n cÃ³ quyá»n truy cáº­p
vÃ o toÃ n bá»™ ngá»¯ cáº£nh. PhÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i
káº¿t há»£p má»™t sá»‘ thÃ nh pháº§n chÃ­nh:

â€¢ Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, chÃºng tÃ´i ngáº«u nhiÃªn
thay tháº¿ má»™t sá»‘ token trong Ä‘áº§u vÃ o X báº±ng má»™t
token Ä‘á»‡m, vá»›i xÃ¡c suáº¥t pM. Trong vÄƒn báº£n dÆ°á»›i
Ä‘Ã¢y, chÃºng tÃ´i sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh pM = 0.15
vÃ¬ nÃ³ Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i nhÆ° tá»· lá»‡ token máº·t
náº¡ ká»ƒ tá»« BERT (Devlin et al., 2019). Xem xÃ©t ráº±ng
viá»‡c giá»›i thiá»‡u má»™t token máº·t náº¡ má»›i cÃ³ thá»ƒ táº¡o ra
má»™t khoáº£ng cÃ¡ch giá»¯a huáº¥n luyá»‡n vÃ  suy luáº­n, Ä‘iá»u
nÃ y lÃ m suy giáº£m hiá»‡u suáº¥t (Yang et al., 2020),
chÃºng tÃ´i chá»n token Ä‘á»‡m thay vÃ¬ token [MASK],
vÃ¬ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£ thÆ°á»ng thiáº¿u
token máº·t náº¡ trong tá»« vá»±ng. Äáº§u vÃ o bá»‹ há»ng XÌ‚
sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘Æ°a vÃ o mÃ´ hÃ¬nh.

â€¢ Má»™t token Ä‘á»‡m Ä‘Æ°á»£c loáº¡i trá»« khá»i cÃ¡c tÃ­nh toÃ¡n
chÃº Ã½, cÃ³ nghÄ©a lÃ  nÃ³ khÃ´ng Ä‘Æ°á»£c chÃº Ã½ bá»Ÿi cÃ¡c
token khÃ¡c, Ä‘á»ƒ ngÄƒn cháº·n viá»‡c Ä‘Æ°a vÃ o nhiá»…u ngá»¯
nghÄ©a. Äiá»u nÃ y Ä‘Æ°á»£c minh há»a bá»Ÿi cÃ¡c hÃ¬nh vuÃ´ng
mÃ u xÃ¡m trong trá»ng sá»‘ chÃº Ã½ trong HÃ¬nh 3(a).

â€¢ Táº¡i vá»‹ trÃ­ Ä‘áº§u ra thá»© iâˆ’1, mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n token
bá»‹ che á»Ÿ vá»‹ trÃ­ Ä‘áº§u vÃ o thá»© i, phÃ¹ há»£p vá»›i hÃ nh vi
dá»± Ä‘oÃ¡n token tiáº¿p theo trong giai Ä‘oáº¡n tiá»n huáº¥n
luyá»‡n cá»§a mÃ´ hÃ¬nh. Chá»‰ viá»‡c dá»± Ä‘oÃ¡n cÃ¡c token bá»‹
che gÃ³p pháº§n vÃ o tÃ­nh toÃ¡n tá»•n tháº¥t. ChÃ­nh thá»©c,
má»¥c tiÃªu tá»‘i Æ°u hÃ³a

--- TRANG 7 ---
GSM Test
"prompt": "James mua 5 gÃ³i thá»‹t bÃ² má»—i gÃ³i 4 pound. GiÃ¡ thá»‹t bÃ² lÃ  $5.50 má»—i pound. Anh áº¥y Ä‘Ã£ tráº£ bao nhiÃªu?"
"completion": "Anh áº¥y Ä‘Ã£ mua 5*4=20 pound thá»‹t bÃ². Anh áº¥y Ä‘Ã£ tráº£ 20*5.5=$110. ÄÃ¡p Ã¡n lÃ : 110"

â†âˆ’GSM Test
"prompt": "James mua x gÃ³i thá»‹t bÃ² má»—i gÃ³i 4 pound. GiÃ¡ thá»‹t bÃ² lÃ  $5.50 má»—i pound. Anh áº¥y Ä‘Ã£ tráº£ bao nhiÃªu? Náº¿u chÃºng ta biáº¿t Ä‘Ã¡p Ã¡n cho cÃ¢u há»i trÃªn lÃ  110, giÃ¡ trá»‹ cá»§a biáº¿n chÆ°a biáº¿t x lÃ  bao nhiÃªu?"
"completion": "Tá»•ng trá»ng lÆ°á»£ng cá»§a thá»‹t bÃ² lÃ  4*x. Bá»Ÿi vÃ¬ 4x * 5.5 = 110. x lÃ  5."

HÃ¬nh 4: Má»™t máº«u kiá»ƒm tra tá»« bá»™ dá»¯ liá»‡u GSM8k gá»‘c (Cobbe et al., 2021), cÃ¹ng vá»›i Ä‘á»‘i tÃ¡c "Ä‘áº£o ngÆ°á»£c" Ä‘Æ°á»£c táº¡o ra bá»Ÿi Yu et al. (2023). CÃ¢u há»i Ä‘áº£o ngÆ°á»£c Ä‘Ã²i há»i cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n chá»‰ trÃªn táº­p huáº¥n luyá»‡n GSM8k gá»‘c pháº£i thá»ƒ hiá»‡n kháº£ nÄƒng suy luáº­n ngÆ°á»£c Ä‘á»ƒ giáº£i quyáº¿t.

Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° sau:

max âˆ‘(T-1,t=1) 1(xt+1 lÃ  [PAD]) Â· log p(xt+1|XÌ‚; Î˜).    (7)
Î˜

Cho ráº±ng viá»‡c tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh chá»‰ vá»›i má»™t
nhiá»‡m vá»¥ khá»­ nhiá»…u máº·t náº¡ cÃ³ thá»ƒ lÃ m giáº£m kháº£
nÄƒng thÃ nh tháº¡o cá»§a mÃ´ hÃ¬nh trong viá»‡c tiáº¿p tá»¥c vÄƒn
báº£n, chÃºng tÃ´i Ã¡p dá»¥ng má»¥c tiÃªu NTP trong má»™t sá»‘
bÆ°á»›c huáº¥n luyá»‡n Ä‘á»ƒ báº£o tá»“n kháº£ nÄƒng sinh cá»§a mÃ´
hÃ¬nh, kÃ½ hiá»‡u pháº§n nÃ y lÃ  pO. NÃ³ Ä‘Æ°á»£c Ä‘áº·t lÃ  0.5
theo máº·c Ä‘á»‹nh. ChÃºng tÃ´i tháº£o luáº­n tÃ¡c Ä‘á»™ng cá»§a pM
vÃ  pO trong Pháº§n 6.

CÃ¡c ká»¹ thuáº­t Ä‘Æ°á»£c mÃ´ táº£ á»Ÿ trÃªn Ä‘Æ°a vÃ o Ã­t khoáº£ng
cÃ¡ch cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£. Do Ä‘Ã³,
má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh BICO cÃ³ thá»ƒ tiáº¿p tá»¥c
vá»›i quÃ¡ trÃ¬nh suy luáº­n thÃ´ng thÆ°á»ng, tá»©c lÃ  giáº£i mÃ£
tá»± há»“i quy token tiáº¿p theo sá»­ dá»¥ng má»™t cÆ¡ cháº¿ chÃº
Ã½ nhÃ¢n quáº£.

5 ThÃ­ Nghiá»‡m vÃ  PhÃ¢n TÃ­ch
5.1 Káº¿t Quáº£ ChÃ­nh
ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a BICO thÃ´ng qua hai
nhiá»‡m vá»¥ riÃªng biá»‡t. Ban Ä‘áº§u, chÃºng tÃ´i Ã¡p dá»¥ng BICO
Ä‘á»ƒ giáº£i quyáº¿t lá»i nguyá»n Ä‘áº£o ngÆ°á»£c gáº·p pháº£i trong
nhiá»‡m vá»¥ tÃªn-Ä‘áº¿n-mÃ´ táº£ hÆ° cáº¥u, nhÆ° Ä‘Æ°á»£c tháº£o luáº­n
trong Pháº§n 3. Tiáº¿p theo, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ tÃ­nh há»¯u
Ã­ch thá»±c táº¿ cá»§a nÃ³ trong viá»‡c giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á»
toÃ¡n há»c, thá»ƒ hiá»‡n kháº£ nÄƒng cá»§a nÃ³ Ä‘á»ƒ cáº£i thiá»‡n cÃ¡c
ká»¹ nÄƒng suy luáº­n Ä‘áº£o ngÆ°á»£c cá»§a LLM á»Ÿ má»™t má»©c Ä‘á»™
nháº¥t Ä‘á»‹nh.

Ãnh Xáº¡ TÃªn HÆ° cáº¥u Ä‘áº¿n MÃ´ táº£ ChÃºng tÃ´i sá»­ dá»¥ng
BICO Ä‘á»ƒ tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh Llama (7B vÃ  13B)
vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t trÃªn cáº£ nhiá»‡m vá»¥ N2D vÃ  â†âˆ’N2D
(Xem HÃ¬nh 2 Ä‘á»ƒ biáº¿t chi tiáº¿t dá»¯ liá»‡u). Káº¿t quáº£ thÃ­
nghiá»‡m Ä‘Æ°á»£c trÃ¬nh bÃ y trong Báº£ng 2. Khi Ã¡p dá»¥ng
BICO Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i, má»™t sá»± gia tÄƒng
Ä‘á»™ chÃ­nh xÃ¡c Ä‘Ã¡ng ká»ƒ Ä‘Æ°á»£c quan sÃ¡t cho nhiá»‡m vá»¥
Ä‘áº£o ngÆ°á»£c,

MÃ´ hÃ¬nh      Má»¥c tiÃªu    N2D(EM)    â†âˆ’N2D
Llama-7B     NTP         67.33      0.00
             BICO        69.67      68.33
Llama-13B    NTP         58.67      0.00
             BICO        66.00      71.67

Báº£ng 2: BICO hiá»‡u quáº£ giáº£m thiá»ƒu lá»i nguyá»n Ä‘áº£o ngÆ°á»£c
trong quÃ¡ trÃ¬nh tinh chá»‰nh Llama vá»›i kiáº¿n thá»©c má»›i, dáº«n
Ä‘áº¿n nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trong hiá»‡u suáº¥t trÃªn nhiá»‡m
vá»¥ â†âˆ’N2D mÃ  khÃ´ng cÃ³ báº¥t ká»³ tÃ¡c Ä‘á»™ng cÃ³ háº¡i nÃ o Ä‘áº¿n
hiá»‡u suáº¥t cá»§a nhiá»‡m vá»¥ N2D. Äiá»ƒm khá»›p chÃ­nh xÃ¡c Ä‘Æ°á»£c
bÃ¡o cÃ¡o.

tÄƒng tá»« 0% lÃªn khoáº£ng 70%. Dá»±a trÃªn sá»± gia tÄƒng
Ä‘Æ°á»£c quan sÃ¡t nÃ y, chÃºng tÃ´i hoÃ n thÃ nh bÆ°á»›c cuá»‘i
cÃ¹ng Ä‘Æ°á»£c nÃªu trong Â§3.2 Ä‘á»ƒ xÃ¡c thá»±c giáº£ thuyáº¿t
cá»§a chÃºng tÃ´i ráº±ng cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n thá»±c sá»±
cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n lá»i nguyá»n Ä‘áº£o ngÆ°á»£c, phá»¥c
vá»¥ nhÆ° má»™t trong nhá»¯ng yáº¿u tá»‘ gÃ³p pháº§n cá»§a nÃ³.
HÆ¡n ná»¯a, báº£n thÃ¢n BICO gÃ³p pháº§n nhÆ° má»™t phÆ°Æ¡ng
phÃ¡p tinh chá»‰nh khÃ´ng Ä‘Æ°a vÃ o lá»i nguyá»n Ä‘áº£o ngÆ°á»£c
bá»• sung cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£.

Má»¥c tiÃªu     GSM      â†âˆ’GSM
NTP          38.21    5.33
BICO         38.28    6.53

Báº£ng 3: ChÃºng tÃ´i tinh chá»‰nh má»™t mÃ´ hÃ¬nh Llama-7B sá»­
dá»¥ng bá»™ dá»¯ liá»‡u GSM8k (Cobbe et al., 2021) vá»›i NTP vÃ 
BICO, tÆ°Æ¡ng á»©ng. Äá»™ chÃ­nh xÃ¡c cÃ¢u tráº£ lá»i trung bÃ¬nh Ä‘Æ°á»£c
bÃ¡o cÃ¡o. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn
cÃ¡c cÃ¢u há»i kiá»ƒm tra gá»‘c (Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  GSM) vÃ  cÃ¡c
cÃ¢u há»i Ä‘áº£o ngÆ°á»£c Ä‘Æ°á»£c xÃ¢y dá»±ng bá»Ÿi Yu et al. (2023)
(Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  â†âˆ’GSM).

--- TRANG 8 ---
Giáº£i ToÃ¡n NgÆ°á»£c Äá»ƒ thá»ƒ hiá»‡n thÃªm hiá»‡u quáº£ cá»§a
BICO, chÃºng tÃ´i giáº£i quyáº¿t má»™t nhiá»‡m vá»¥ thá»±c táº¿
hÆ¡n: giáº£i toÃ¡n. Thiáº¿t láº­p thÃ­ nghiá»‡m cÆ¡ báº£n bao gá»“m
viá»‡c dáº¡y LLM cÃ¡c ká»¹ nÄƒng giáº£i toÃ¡n cÆ¡ báº£n vÃ  kiá»ƒm
tra chÃºng vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p "logic Ä‘áº£o ngÆ°á»£c"
Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n toÃ¡n há»c. Bá»™ dá»¯ liá»‡u (Yu
et al., 2023), Ä‘Æ°á»£c dáº«n xuáº¥t tá»« GSM8k (Cobbe et al.,
2021), cÃ³ cÃ¡c cÃ¢u há»i toÃ¡n Ä‘Æ°á»£c Ä‘áº£o ngÆ°á»£c so vá»›i
nhá»¯ng cÃ¢u trong bá»™ dá»¯ liá»‡u GSM8k gá»‘c. HÃ¬nh 4 minh
há»a má»™t Ä‘iá»ƒm dá»¯ liá»‡u tá»« GSM8k cÃ¹ng vá»›i Ä‘á»‘i tÃ¡c
Ä‘áº£o ngÆ°á»£c cá»§a nÃ³. ChÃºng tÃ´i sá»­ dá»¥ng NTP vÃ  BICO
Ä‘á»ƒ tinh chá»‰nh má»™t mÃ´ hÃ¬nh Llama-7B trÃªn bá»™ dá»¯ liá»‡u
GSM8k gá»‘c, tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t
cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh trÃªn cáº£ táº­p kiá»ƒm
tra gá»‘c vÃ  Ä‘áº£o ngÆ°á»£c. Táº¥t cáº£ cÃ¡c siÃªu tham sá»‘ huáº¥n
luyá»‡n vÃ  cáº¥u hÃ¬nh theo Yu et al. (2023). Káº¿t quáº£
Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Báº£ng 3.

ChÃºng tÃ´i quan sÃ¡t ráº±ng BICO duy trÃ¬ hiá»‡u suáº¥t cá»§a
nÃ³ trÃªn táº­p kiá»ƒm tra gá»‘c trong khi Ä‘áº¡t Ä‘Æ°á»£c má»™t sá»±
gia tÄƒng hÆ¡n 1 Ä‘iá»ƒm trong viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i
toÃ¡n toÃ¡n Ä‘áº£o ngÆ°á»£c, Ä‘Ã¢y lÃ  má»™t cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ
trong nhiá»‡m vá»¥ giáº£i toÃ¡n vÃ  vÆ°á»£t qua t-test vá»›i giÃ¡
trá»‹ p < 0.01. Cho ráº±ng cÃ¡c mÃ´ hÃ¬nh chÆ°a tháº¥y báº¥t ká»³
chuá»—i suy luáº­n ngÆ°á»£c nÃ o Ä‘á»ƒ giáº£i quyáº¿t nhá»¯ng loáº¡i
cÃ¢u há»i toÃ¡n nÃ y trong quÃ¡ trÃ¬nh tinh chá»‰nh, sá»± cáº£i
thiá»‡n cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho BICO, thá»ƒ hiá»‡n kháº£ nÄƒng
cá»§a nÃ³ Ä‘á»ƒ tÄƒng cÆ°á»ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n
quáº£ vá»›i kháº£ nÄƒng suy luáº­n Ä‘a nÄƒng hÆ¡n.

Dá»‹ch thuáº­t Báº£n cháº¥t kÃ©p cá»§a dá»¯ liá»‡u dá»‹ch thuáº­t
Ä‘áº·c biá»‡t phÃ¹ há»£p Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ lá»i nguyá»n Ä‘áº£o ngÆ°á»£c.
ChÃºng tÃ´i giáº£ Ä‘á»‹nh ráº±ng vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n theo
thá»© tá»± "ngÃ´n ngá»¯ X-ngÃ´n ngá»¯ Y", mÃ´ hÃ¬nh cÃ³ thá»ƒ
hoáº¡t Ä‘á»™ng kÃ©m trong viá»‡c dá»‹ch "ngÃ´n ngá»¯ Y-sang-
ngÃ´n ngá»¯ X" do lá»i nguyá»n Ä‘áº£o ngÆ°á»£c. Äá»ƒ chá»©ng
minh Ä‘iá»u nÃ y, chÃºng tÃ´i thá»±c hiá»‡n má»™t nhiá»‡m vá»¥
dá»‹ch mÃ¡y Ä‘Æ¡n giáº£n tá»« tiáº¿ng Trung sang tiáº¿ng Anh.
DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c chi tiáº¿t thÃ­ nghiá»‡m:

ChÃºng tÃ´i phÃ¡t triá»ƒn má»™t táº­p há»£p cÃ¡c vÃ­ dá»¥ dá»‹ch
Trung-Anh Ä‘Æ°á»£c cáº¥u trÃºc nhÆ° sau: "Khi dá»‹ch thuáº­t
ngá»¯ tiáº¿ng Trung 'å¦å¤–ä¸€ä¸ª' sang tiáº¿ng Anh, biá»ƒu
thá»©c tÆ°Æ¡ng Ä‘Æ°Æ¡ng lÃ  'Another one'." Äá»ƒ kiá»ƒm tra,
chÃºng tÃ´i Ä‘áº£o ngÆ°á»£c dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ thá»±c
hiá»‡n cÃ¡c nhiá»‡m vá»¥ dá»‹ch Anh-Trung, nhÆ°: "Khi dá»‹ch
cá»¥m tá»« tiáº¿ng Anh 'another one' sang tiáº¿ng Trung,
biá»ƒu thá»©c tiáº¿ng Trung tÆ°Æ¡ng á»©ng lÃ ," vá»›i pháº£n há»“i
Ä‘Ãºng lÃ  'å¦å¤–ä¸€ä¸ª.' ChÃºng tÃ´i kiá»ƒm tra nhiá»‡m vá»¥
nÃ y trÃªn mÃ´ hÃ¬nh Llama-7b, mÃ  cÃ³ kháº£ nÄƒng ngÃ´n
ngá»¯ tiáº¿ng Trung háº¡n cháº¿. Cáº£ bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n
vÃ  kiá»ƒm tra Ä‘á»u bao gá»“m 100 vÃ­ dá»¥ má»—i bá»™. ChÃºng
tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t dá»‹ch thuáº­t sá»­ dá»¥ng chá»‰ sá»‘
Khá»›p chÃ­nh xÃ¡c. Káº¿t quáº£ thÃ­ nghiá»‡m Ä‘Æ°á»£c liá»‡t kÃª
trong Báº£ng 4. LÆ°u Ã½ ráº±ng Ä‘á»™ chÃ­nh xÃ¡c 0-shot cho

0-shot  NTP   BICO
EM (%)    51    63    69

Báº£ng 4: BICO tÄƒng cÆ°á»ng tÃ­nh há»¯u Ã­ch cá»§a dá»¯ liá»‡u huáº¥n
luyá»‡n cho nhiá»‡m vá»¥ dá»‹ch ngÆ°á»£c, do Ä‘Ã³ cáº£i thiá»‡n Ä‘á»™ chÃ­nh
xÃ¡c cá»§a dá»‹ch ngÆ°á»£c. LÆ°u Ã½ ráº±ng mÃ´ hÃ¬nh Llama cÃ³ kháº£
nÄƒng Ä‘a ngÃ´n ngá»¯ vá»‘n cÃ³, Ä‘Æ°á»£c thá»ƒ hiá»‡n trong Ä‘iá»ƒm sá»‘
zero-shot.

Llama lÃ  50%, pháº£n Ã¡nh kháº£ nÄƒng song ngá»¯ gá»‘c cá»§a
nÃ³. BICO vÆ°á»£t trá»™i hÆ¡n NTP 6%, lÃ m ná»•i báº­t hiá»‡u
quáº£ tiá»m nÄƒng cá»§a nÃ³ trong cÃ¡c nhiá»‡m vá»¥ tháº¿ giá»›i
thá»±c nhÆ° dá»‹ch mÃ¡y.

6 Tháº£o Luáº­n
Pháº§n nÃ y bao gá»“m má»™t sá»‘ phÃ¢n tÃ­ch cáº§n thiáº¿t vá»
phÆ°Æ¡ng phÃ¡p BICO Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i, cÅ©ng
nhÆ° nghiÃªn cá»©u Ä‘Æ°Æ¡ng Ä‘áº¡i vá» lá»i nguyá»n Ä‘áº£o ngÆ°á»£c.

6.1 PhÃ¢n TÃ­ch PhÆ°Æ¡ng PhÃ¡p
Cáº¥u hÃ¬nh cá»§a cÃ¡c siÃªu tham sá»‘ trong BICO, bao gá»“m
pM vÃ  pO, tuÃ¢n theo cÃ¡c thá»±c hÃ nh thÃ´ng thÆ°á»ng
tÆ°Æ¡ng tá»± nhÆ° BERT (Devlin et al., 2019). Tuy nhiÃªn,
trong BERT, tá»· lá»‡ token máº·t náº¡ pM vÃ  sá»± Ä‘Ã¡nh Ä‘á»•i
giá»¯a hai nhiá»‡m vá»¥ tiá»n huáº¥n luyá»‡n pO thiáº¿u tháº£o
luáº­n vÃ  hÃ¬nh thá»©c hÃ³a rÃµ rÃ ng. ChÃºng tÃ´i Ä‘Ã£ nghiÃªn
cá»©u tÃ¡c Ä‘á»™ng cá»§a cÃ¡c siÃªu tham sá»‘ cá»§a chÃºng tÃ´i vÃ 
chi tiáº¿t cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong phá»¥ lá»¥c A.

6.2 Giáº£m Thiá»ƒu Lá»i Nguyá»n Äáº£o NgÆ°á»£c
Má»™t sá»‘ cÃ´ng trÃ¬nh Ä‘Æ°Æ¡ng Ä‘áº¡i nháº±m giáº£i quyáº¿t lá»i
nguyá»n Ä‘áº£o ngÆ°á»£c thÃ´ng qua chá»‰nh sá»­a kiáº¿n thá»©c
hoáº·c tÄƒng cÆ°á»ng dá»¯ liá»‡u.

Chá»‰nh sá»­a kiáº¿n thá»©c (Ma et al., 2023b) tÃ­ch há»£p
kiáº¿n thá»©c Ä‘áº£o ngÆ°á»£c trá»±c tiáº¿p vÃ o cÃ¡c tham sá»‘ mÃ´
hÃ¬nh, Ä‘áº£m báº£o hiá»‡u suáº¥t. Tuy nhiÃªn, phÆ°Æ¡ng phÃ¡p
nÃ y tá»‘n nhiá»u cÃ´ng sá»©c, Ä‘Ã²i há»i chÃº thÃ­ch tá»‰ má»‰ vÃ 
triá»ƒn khai phá»©c táº¡p. NÃ³ Ä‘Ã²i há»i cÃ¡c cÃ¢u pháº£i tuÃ¢n
theo má»™t cáº¥u trÃºc cá»¥ thá»ƒ cá»§a má»™t chá»§ thá»ƒ, theo sau
lÃ  má»™t má»‘i quan há»‡, vÃ  sau Ä‘Ã³ má»™t Ä‘á»‘i tÆ°á»£ng. NgÆ°á»£c
láº¡i, BICO khÃ´ng phá»¥ thuá»™c vÃ o cáº¥u trÃºc cÃ¢u vÃ  dá»…
triá»ƒn khai hÆ¡n.

Theo chÃºng tÃ´i, Guo et al. (2024) Ä‘á» xuáº¥t giáº£m
thiá»ƒu lá»i nguyá»n Ä‘áº£o ngÆ°á»£c thÃ´ng qua tÄƒng cÆ°á»ng
dá»¯ liá»‡u. NÃ³ cÃ³ thá»ƒ táº¡o ra dá»¯ liá»‡u Ä‘áº£o ngÆ°á»£c rÃµ rÃ ng
Ä‘á»ƒ huáº¥n luyá»‡n, cÃ³ thá»ƒ tÄƒng cÆ°á»ng hiá»‡u suáº¥t trong
cÃ¡c tÃ¬nh huá»‘ng phá»©c táº¡p. Tuy nhiÃªn, phÆ°Æ¡ng phÃ¡p
nÃ y cÃ³ thá»ƒ gáº·p pháº£i cÃ¡c váº¥n Ä‘á» rÃ² rá»‰ nhÃ£n trong
cÃ¡c thÃ­ nghiá»‡m nghiÃªn cá»©u, vÃ  do Ä‘Ã³ chÃºng tÃ´i
khÃ´ng so sÃ¡nh BICO vá»›i nÃ³.

--- TRANG 9 ---
ÄÃ¢y lÃ  má»™t tÃ¬nh huá»‘ng mÃ  cáº£ BICO vÃ  ABI Ä‘á»u khÃ´ng
thá»ƒ giáº£m thiá»ƒu lá»i nguyá»n Ä‘áº£o ngÆ°á»£c nhÆ°ng tÄƒng
cÆ°á»ng dá»¯ liá»‡u cÃ³ thá»ƒ giáº£i quyáº¿t theo (Guo et al.,
2024). Xem xÃ©t má»‘i quan há»‡ nghá»‹ch Ä‘áº£o cá»§a RN2D
Ä‘Ã£ nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y, Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  RD2N.
Viá»‡c Ã¡nh xáº¡ tá»« D Ä‘áº¿n N cÅ©ng táº¡o thÃ nh má»™t song
Ã¡nh: RD2N = {< d, n > | d mÃ´ táº£ n, (n âˆˆ N) âˆ§ (d âˆˆ D)}.

Táº¥t cáº£ cÃ¡c thiáº¿t láº­p thÃ­ nghiá»‡m vÃ  chi tiáº¿t huáº¥n
luyá»‡n váº«n giá»‘ng há»‡t vá»›i nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘Æ°á»£c giá»›i thiá»‡u
trÆ°á»›c Ä‘Ã¢y. HÃ¬nh 8 trong phá»¥ lá»¥c minh há»a viá»‡c xÃ¢y
dá»±ng dá»¯ liá»‡u liÃªn quan Ä‘áº¿n má»‘i quan há»‡ nÃ y. Sau
khi Ä‘iá»u chá»‰nh, chÃºng tÃ´i gáº·p pháº£i má»™t hiá»‡n tÆ°á»£ng
khÃ³ hiá»ƒu: NhÆ° Ä‘Æ°á»£c thá»ƒ hiá»‡n trong HÃ¬nh 5, sau khi
Ä‘iá»u chá»‰nh, chÃºng tÃ´i quan sÃ¡t má»™t hiá»‡n tÆ°á»£ng khÃ³
hiá»ƒu: trong khi BICO cáº£i thiá»‡n kháº£ nÄƒng xáº£y ra cá»§a
sá»± tháº­t cÆ¡ báº£n so vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh
NTP, tÃ¡c Ä‘á»™ng cá»§a nÃ³ Ä‘áº¿n Ä‘iá»ƒm khá»›p chÃ­nh xÃ¡c hoáº·c
Ä‘iá»ƒm BLEU (Papineni et al., 2002) lÃ  khÃ´ng Ä‘Ã¡ng
ká»ƒ (tham kháº£o phá»¥ lá»¥c A Ä‘á»ƒ tÃ­nh toÃ¡n kháº£ nÄƒng xáº£y
ra vÃ  káº¿t quáº£ chi tiáº¿t). ChÃºng tÃ´i Ä‘Ã£ xem xÃ©t ká»¹
lÆ°á»¡ng cÃ¡c chiáº¿n lÆ°á»£c giáº£i mÃ£, bao gá»“m tÃ¬m kiáº¿m
chÃ¹m, láº¥y máº«u top-k vÃ  top-p, nhÆ°ng chÃºng khÃ´ng
thá»ƒ hiá»‡n nhiá»u khÃ¡c biá»‡t.

Má»™t giáº£ thuyáº¿t há»£p lÃ½ lÃ  cÃ¡c LLM Ä‘Æ°á»£c tiá»n huáº¥n
luyá»‡n cÃ³ thá»ƒ Ä‘Ã£ phÃ¡t triá»ƒn má»™t "thÆ°á»ng thá»©c" trong
quÃ¡ trÃ¬nh tiá»n huáº¥n luyá»‡n. "ThÆ°á»ng thá»©c" nÃ y gá»£i
Ã½ ráº±ng, so vá»›i mÃ´ táº£-Ä‘áº¿n-tÃªn, má»™t má»‘i quan há»‡ tÃªn-
Ä‘áº¿n-mÃ´ táº£ cÃ³ xu hÆ°á»›ng lÃ  má»™t Ã¡nh xáº¡ má»™t-Ä‘áº¿n-nhiá»u,
dáº«n Ä‘áº¿n sá»± nháº§m láº«n trong nhiá»‡m vá»¥ â†âˆ’D2N. VÃ­ dá»¥,
khi Ä‘Æ°á»£c Ä‘áº·t cÃ¢u há»i, "Joe Biden lÃ  ai?", mÃ´ hÃ¬nh cÃ³
thá»ƒ tráº£ lá»i vá»›i nhiá»u mÃ´ táº£ Ä‘Ãºng nhÆ° "má»™t ngÆ°á»i Ä‘am
mÃª xe hÆ¡i," hoáº·c "má»™t ngÆ°á»i Ä‘Ã n Ã´ng lá»›n tuá»•i," thay
vÃ¬ "tá»•ng thá»‘ng Má»¹." Trong khi tÄƒng cÆ°á»ng dá»¯ liá»‡u
rÃµ rÃ ng cÃ³ thá»ƒ cung cáº¥p má»™t giáº£i phÃ¡p cho váº¥n Ä‘á»
nÃ y, Ä‘Æ°á»£c há»— trá»£ bá»Ÿi cÃ¡c phÃ¡t hiá»‡n trong nghiÃªn cá»©u
diá»…n giáº£i gáº§n Ä‘Ã¢y (Wang et al., 2024), phÆ°Æ¡ng phÃ¡p
nÃ y chá»‰ khuyáº¿n khÃ­ch mÃ´ hÃ¬nh ghi nhá»› dá»¯ liá»‡u Ä‘áº£o
ngÆ°á»£c thay vÃ¬ tÄƒng cÆ°á»ng kháº£ nÄƒng suy luáº­n cá»§a nÃ³.

7 Káº¿t Luáº­n
ChÃºng tÃ´i lÃ  nhá»¯ng ngÆ°á»i Ä‘áº§u tiÃªn nghiÃªn cá»©u cÃ¡c
nguyÃªn nhÃ¢n cÆ¡ báº£n cá»§a lá»i nguyá»n Ä‘áº£o ngÆ°á»£c vÃ 
quy nÃ³ cho sá»± káº¿t há»£p cá»§a cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n
vÃ  má»™t sá»‘ cÆ¡ cháº¿ suy luáº­n nháº¥t Ä‘á»‹nh. Khi xem xÃ©t
tÃ¡c Ä‘á»™ng cá»§a cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n, chÃºng tÃ´i
giá»›i thiá»‡u má»™t phÆ°Æ¡ng phÃ¡p tinh chá»‰nh sÃ¡ng táº¡o cho
cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£ cÃ³ tÃªn BICO. PhÆ°Æ¡ng
phÃ¡p nÃ y tÃ¹y chá»‰nh cÃ¡c mÃ´ hÃ¬nh Llama cho cÃ¡c má»¥c
tiÃªu giá»‘ng ABI, do Ä‘Ã³ giáº£m thiá»ƒu lá»i nguyá»n Ä‘áº£o
ngÆ°á»£c xuáº¥t hiá»‡n trong giai Ä‘oáº¡n huáº¥n luyá»‡n. ChÃºng
tÃ´i hy vá»ng thu hÃºt sá»± chÃº Ã½ cá»§a cá»™ng Ä‘á»“ng Ä‘áº¿n cáº¥u
hÃ¬nh phá»• biáº¿n cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, Ä‘áº·c
biá»‡t lÃ m ná»•i báº­t cÃ¡c háº¡n cháº¿ vá»‘n cÃ³ trong

XÃ¡c Suáº¥t Trung BÃ¬nh
BICO
NTP
0.08  0.16  0.24  0.32  0.40

32.3%
38.7%
27.5%
30.1%

Llama-7b
Llama-13b

HÃ¬nh 5: XÃ¡c suáº¥t cá»§a viá»‡c hoÃ n thÃ nh mong muá»‘n cho
cÃ¡c prompt Ä‘Æ°á»£c cung cáº¥p bá»Ÿi cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau
trong nhiá»‡m vá»¥ â†âˆ’D2N. XÃ¡c suáº¥t nÃ y Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡
trÃªn toÃ n bá»™ táº­p kiá»ƒm tra vÃ  Ä‘Æ°á»£c trÃ¬nh bÃ y nhÆ° má»™t
trung bÃ¬nh. RÃµ rÃ ng lÃ  BICO tÄƒng cÆ°á»ng kháº£ nÄƒng xáº£y
ra cá»§a viá»‡c Ä‘áº¡t Ä‘Æ°á»£c dá»± Ä‘oÃ¡n sá»± tháº­t cÆ¡ báº£n.

mÃ´ hÃ¬nh huáº¥n luyá»‡n hiá»‡n táº¡i.

Háº¡n Cháº¿
NhÆ° nhá»¯ng háº¡n cháº¿, váº«n cÃ²n má»™t sá»‘ cÃ¢u há»i nghiÃªn
cá»©u má»Ÿ Ä‘Ã¡ng Ä‘Æ°á»£c Ä‘iá»u tra thÃªm: Thá»© nháº¥t, viá»‡c
Ä‘á»‹nh lÆ°á»£ng áº£nh hÆ°á»Ÿng cá»§a cÃ¡c quÃ¡ trÃ¬nh khÃ¡c Ä‘á»‘i
vá»›i cÃ¡c mÃ´ hÃ¬nh tiÃªn tiáº¿n, nhÆ° RLHF, Ä‘á»‘i vá»›i lá»i
nguyá»n Ä‘áº£o ngÆ°á»£c Ä‘áº·t ra má»™t thÃ¡ch thá»©c phá»©c táº¡p
hÆ¡n vÃ  cáº§n nhiá»u nghiÃªn cá»©u hÆ¡n. Thá»© hai, hiá»ƒu
cÃ¡c cÆ¡ cháº¿ khÃ¡c nhau ngoÃ i má»¥c tiÃªu huáº¥n luyá»‡n
gÃ³p pháº§n lÃ m tráº§m trá»ng thÃªm lá»i nguyá»n Ä‘áº£o ngÆ°á»£c
lÃ  quan trá»ng, vÃ  chÃºng tÃ´i hoÃ£n nhiá»‡m vá»¥ nÃ y cho
cÃ¡c ná»— lá»±c nghiÃªn cá»©u tÆ°Æ¡ng lai.

Lá»i Cáº£m Æ n
CÃ´ng trÃ¬nh nÃ y Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Quá»¹ Khoa há»c Tá»±
nhiÃªn Quá»‘c gia Trung Quá»‘c (Sá»‘ Grant NSFC
62122089), ChÆ°Æ¡ng trÃ¬nh NhÃ  khoa há»c Tráº» Xuáº¥t
sáº¯c Báº¯c Kinh Sá». BJJWZYJH012019100020098, vÃ 
Ná»n táº£ng Quáº£n trá»‹ XÃ£ há»™i ThÃ´ng minh, Ná»n táº£ng
LiÃªn ngÃ nh Äá»•i má»›i vÃ  Quy hoáº¡ch ChÃ­nh cho SÃ¡ng
kiáº¿n "ÄÃ´i-Háº¡ng Nháº¥t", Äáº¡i há»c NhÃ¢n dÃ¢n Trung
Quá»‘c, Quá»¹ NghiÃªn cá»©u CÆ¡ báº£n cho cÃ¡c Äáº¡i há»c
Trung Æ°Æ¡ng, vÃ  Quá»¹ NghiÃªn cá»©u cá»§a Äáº¡i há»c NhÃ¢n
dÃ¢n Trung Quá»‘c. Ang Lv Ä‘Æ°á»£c há»— trá»£ bá»Ÿi CÃ¡c ChÆ°Æ¡ng
trÃ¬nh ÄÆ°á»£c TÃ i trá»£ Bá»“i dÆ°á»¡ng NhÃ¢n tÃ i SÃ¡ng táº¡o
Xuáº¥t sáº¯c 2024 cá»§a Äáº¡i há»c NhÃ¢n dÃ¢n Trung Quá»‘c.

--- TRANG 10 ---
TÃ i Liá»‡u Tham Kháº£o
Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan
Yang, Xiaodong Liu, Yu Wang, Songhao Piao, Jian-
feng Gao, Ming Zhou, vÃ  Hsiao-Wuen Hon. 2020.
Unilmv2: Pseudo-masked language models for uni-
fied language model pre-training.

Yoshua Bengio, RÃ©jean Ducharme, Pascal Vincent,
vÃ  Christian Janvin. 2003. A neural proba-
bilistic language model. J. Mach. Learn. Res.,
3(null):1137â€“1155.

Lukas Berglund, Meg Tong, Max Kaufmann, Mikita
Balesni, Asa Cooper Stickland, Tomasz Korbak, vÃ 
Owain Evans. 2023. The reversal curse: Llms trained
on "a is b" fail to learn "b is a".

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, vÃ  Dario Amodei.
2020. Language models are few-shot learners.

Shouyuan Chen, Sherman Wong, Liangjian Chen, vÃ 
Yuandong Tian. 2023. Extending context window of
large language models via positional interpolation.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, Christopher Hesse, vÃ  John Schulman.
2021. Training verifiers to solve math word prob-
lems. arXiv preprint arXiv:2110.14168.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, vÃ 
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers), pages
4171â€“4186, Minneapolis, Minnesota. Association for
Computational Linguistics.

Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xi-
aodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou,
vÃ  Hsiao-Wuen Hon. 2019. Unified language model
pre-training for natural language understanding and
generation.

Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,
Jiezhong Qiu, Zhilin Yang, vÃ  Jie Tang. 2022. GLM:
general language model pretraining with autoregres-
sive blank infilling. pages 320â€“335.

Nelson Elhage, Neel Nanda, Catherine Olsson, Tom
Henighan, Nicholas Joseph, Ben Mann, Amanda
Askell, Yuntao Bai, Anna Chen, Tom Conerly,
Nova DasSarma, Dawn Drain, Deep Ganguli, Zac
Hatfield-Dodds, Danny Hernandez, Andy Jones,
Jackson Kernion, Liane Lovitt, Kamal Ndousse,
Dario Amodei, Tom Brown, Jack Clark, Jared Ka-
plan, Sam McCandlish, vÃ  Chris Olah. 2021. A
mathematical framework for transformer circuits.
Transformer Circuits Thread. Https://transformer-
circuits.pub/2021/framework/index.html.

Qingyan Guo, Rui Wang, Junliang Guo, Xu Tan, Jiang
Bian, vÃ  Yujiu Yang. 2024. Mitigating reversal
curse in large language models via semantic-aware
permutation training.

Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, vÃ 
Weizhu Chen. 2022. Lora: Low-rank adaptation of
large language models. In ICLR 2022.

Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld,
Luke Zettlemoyer, vÃ  Omer Levy. 2020. Span-
BERT: Improving pre-training by representing and
predicting spans. Transactions of the Association for
Computational Linguistics, 8:64â€“77.

Jun Ma, Jia-Chen Gu, Zhen-Hua Ling, Quan Liu,
vÃ  Cong Liu. 2023a. Untying the reversal curse
via bidirectional language model editing. ArXiv,
abs/2310.10322.

Jun-Yu Ma, Jia-Chen Gu, Zhen-Hua Ling, Quan Liu,
vÃ  Cong Liu. 2023b. Untying the reversal curse via
bidirectional language model editing.

Kevin Meng, David Bau, Alex J Andonian, vÃ  Yonatan
Belinkov. 2022. Locating and editing factual associ-
ations in GPT. In Advances in Neural Information
Processing Systems.

Jack Merullo, Carsten Eickhoff, vÃ  Ellie Pavlick. 2024.
Circuit component reuse across tasks in transformer
language models.

OpenAI. 2023. Gpt-4 technical report.

Kishore Papineni, Salim Roukos, Todd Ward, vÃ  Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics, pages 311â€“318, Philadelphia,
Pennsylvania, USA. Association for Computational
Linguistics.

Alec Radford vÃ  Karthik Narasimhan. 2018. Im-
proving language understanding by generative pre-
training.

Alec Radford, Jeff Wu, Rewon Child, David Luan,
Dario Amodei, vÃ  Ilya Sutskever. 2019. Language
models are unsupervised multitask learners.

Colin Raffel, Noam Shazeer, Adam Roberts, Kather-
ine Lee, Sharan Narang, Michael Matena, Yanqi
Zhou, Wei Li, vÃ  Peter J. Liu. 2020. Exploring the
limits of transfer learning with a unified text-to-text
transformer. Journal of Machine Learning Research,
21(140):1â€“67.

--- TRANG 11 ---
Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha,
Bo Wen, vÃ  Yunfeng Liu. 2022. Roformer: En-
hanced transformer with rotary position embedding.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix,
Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal
Azhar, Aurelien Rodriguez, Armand Joulin, Edouard
Grave, vÃ  Guillaume Lample. 2023a. Llama: Open
and efficient foundation language models.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton
Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,
Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-
thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura,
Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-
tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez, Robert Stojnic, Sergey Edunov, vÃ  Thomas
Scialom. 2023b. Llama 2: Open foundation and
fine-tuned chat models.

Boshi Wang, Xiang Yue, Yu Su, vÃ  Huan Sun. 2024.
Grokked transformers are implicit reasoners: A mech-
anistic journey to the edge of generalization.

Kevin Ro Wang, Alexandre Variengien, Arthur Conmy,
Buck Shlegeris, vÃ  Jacob Steinhardt. 2023. Inter-
pretability in the wild: a circuit for indirect object
identification in GPT-2 small. In The Eleventh Inter-
national Conference on Learning Representations.

Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-
bonell, Ruslan Salakhutdinov, vÃ  Quoc V. Le. 2020.
Xlnet: Generalized autoregressive pretraining for lan-
guage understanding.

Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu,
Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo
Li, Adrian Weller, vÃ  Weiyang Liu. 2023. Meta-
math: Bootstrap your own mathematical questions
for large language models.

Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,
Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,
Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b:
An open bilingual pre-trained model. arXiv preprint
arXiv:2210.02414.

Liu Zhuang, Lin Wayne, Shi Ya, vÃ  Zhao Jun. 2021. A
robustly optimized BERT pre-training approach with
post-training. In Proceedings of the 20th Chinese
National Conference on Computational Linguistics,
pages 1218â€“1227, Huhhot, China. Chinese Informa-
tion Processing Society of China.

--- TRANG 12 ---
HÃ¬nh 6: pO cÃ¢n báº±ng viá»‡c hiá»ƒu toÃ n diá»‡n dá»¯ liá»‡u huáº¥n
luyá»‡n cá»§a mÃ´ hÃ¬nh vÃ  kháº£ nÄƒng sinh. Khi giÃ¡ trá»‹ pO phÃ¹
há»£p Ä‘Æ°á»£c chá»n, BICO giáº£m thiá»ƒu lá»i nguyá»n Ä‘áº£o ngÆ°á»£c
trong nhiá»‡m vá»¥ â†âˆ’N2D. Sá»± váº¯ng máº·t cá»§a nhÃºng vá»‹ trÃ­
sá»­a Ä‘á»•i (w/o M.P.) cáº£n trá»Ÿ quÃ¡ trÃ¬nh há»c vÃ  dáº«n Ä‘áº¿n
káº¿t quáº£ kÃ©m hÆ¡n do váº¥n Ä‘á» ngoÃ i phÃ¢n phá»‘i.

A PhÃ¢n TÃ­ch PhÆ°Æ¡ng PhÃ¡p cá»§a BICO
ChÃºng tÃ´i Ä‘iá»u tra tÃ¡c Ä‘á»™ng cá»§a cÃ¡c siÃªu tham sá»‘ trong
BICO Ä‘á»‘i vá»›i viá»‡c giáº£m thiá»ƒu lá»i nguyá»n Ä‘áº£o ngÆ°á»£c
do cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n gÃ¢y ra. Äiá»u quan trá»ng
cáº§n lÆ°u Ã½ lÃ  chÃºng tÃ´i khÃ´ng nháº±m tÃ¬m kiáº¿m hiá»‡u
suáº¥t tá»‘t nháº¥t cho má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ, mÃ  lÃ  nghiÃªn
cá»©u cÃ¡c Ä‘áº·c tÃ­nh cá»§a BICO. MÃ´ hÃ¬nh chÃºng tÃ´i sá»­
dá»¥ng trong pháº§n nÃ y lÃ  Llama-7B.

Lá»±a Chá»n pO ABI gá»‘c sá»­ dá»¥ng cÃ¡c token Ä‘áº·c biá»‡t
nhÆ° "<BOS>" vÃ  "<EOS>" Ä‘á»ƒ chá»‰ ra báº¯t Ä‘áº§u vÃ  káº¿t
thÃºc cá»§a chuá»—i bá»‹ che. Tuy nhiÃªn, Ä‘Ã¡ng chÃº Ã½ lÃ 
Ä‘iá»u nÃ y khÃ¡c vá»›i cÃ¡ch Llama sá»­ dá»¥ng nhá»¯ng token
Ä‘áº·c biá»‡t nÃ y. Do Ä‘Ã³, chÃºng tÃ´i Ä‘Ã£ chá»n khÃ´ng sá»­
dá»¥ng chÃºng nhÆ° cÃ¡c dáº¥u hiá»‡u cho viá»‡c che trong
BICO. Káº¿t quáº£ lÃ , chÃºng tÃ´i tháº¥y cÃ¡c mÃ´ hÃ¬nh Llama
Ä‘Æ°á»£c Ä‘iá»u chá»‰nh vá»›i BICO gáº·p khÃ³ khÄƒn trong viá»‡c
káº¿t thÃºc sinh hiá»‡u quáº£. ChÃºng tÃ´i quan sÃ¡t ráº±ng
chÃºng cÃ³ xu hÆ°á»›ng táº¡o ra cÃ¡c mÃ´ táº£ dÃ i, liÃªn quan
Ä‘áº¿n chá»§ Ä‘á». Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y, chÃºng tÃ´i
giá»›i thiá»‡u giáº£i phÃ¡p: táº¡i má»—i bÆ°á»›c huáº¥n luyá»‡n, mÃ´
hÃ¬nh Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a vá»›i má»¥c tiÃªu NTP vá»›i xÃ¡c suáº¥t
pO vÃ  Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a vá»›i khá»­ nhiá»…u máº·t náº¡ tá»± há»“i
quy vá»›i xÃ¡c suáº¥t 1âˆ’pO.

ChÃºng tÃ´i nghiÃªn cá»©u viá»‡c lá»±a chá»n pO, trong khi
duy trÃ¬ tá»· lá»‡ máº·t náº¡ khÃ´ng Ä‘á»•i lÃ  pM = 0.15, má»™t
giÃ¡ trá»‹ Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i trong cÃ¡c mÃ´ hÃ¬nh tá»±
mÃ£ hÃ³a (Devlin et al., 2019; Raffel et al., 2020).
Káº¿t quáº£ cá»§a chÃºng tÃ´i Ä‘Æ°á»£c minh há»a trong HÃ¬nh 6.
ChÃºng tÃ´i quan sÃ¡t ráº±ng do váº¥n Ä‘á» Ä‘Ã£ tháº£o luáº­n
trÆ°á»›c Ä‘Ã¢y, khi pO = 0, cÃ¡c mÃ´ hÃ¬nh khÃ´ng thá»ƒ táº¡o
ra mÃ´ táº£ chÃ­nh xÃ¡c trong nhiá»‡m vá»¥ N2D, vÃ  hoáº¡t
Ä‘á»™ng kÃ©m trong â†âˆ’N2D. MÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh
hoÃ n toÃ n vá»›i NTP (pO = 1) gáº·p pháº£i lá»i nguyá»n
Ä‘áº£o ngÆ°á»£c, Ä‘áº¡t Ä‘Æ°á»£c tá»· lá»‡ chÃ­nh xÃ¡c 0% trong nhiá»‡m
vá»¥ â†âˆ’N2D.

HÃ¬nh 7: TÃ¡c Ä‘á»™ng cá»§a chiáº¿n lÆ°á»£c máº·t náº¡ Ä‘áº¿n hiá»‡u suáº¥t
mÃ´ hÃ¬nh. Tá»« pháº§n trÃªn cá»§a hÃ¬nh, hiá»‡u suáº¥t mÃ´ hÃ¬nh váº«n
nháº¥t quÃ¡n trong má»™t pháº¡m vi rá»™ng cÃ¡c giÃ¡ trá»‹ pM (0.15
Ä‘áº¿n 0.45). ChÃºng tÃ´i cÅ©ng tháº¥y ráº±ng che khoáº£ng vÃ  che
i.i.d. khÃ´ng thá»ƒ hiá»‡n sá»± khÃ¡c biá»‡t Ä‘Ã¡ng chÃº Ã½. Äá»ƒ dá»… so
sÃ¡nh, chÃºng tÃ´i sá»­ dá»¥ng Ä‘Æ°á»ng Ä‘á»©t nÃ©t mÃ u Ä‘á» Ä‘á»ƒ biá»ƒu
thá»‹ káº¿t quáº£ tá»‘t nháº¥t Ä‘Æ°á»£c cung cáº¥p bá»Ÿi Llama Ä‘Æ°á»£c Ä‘iá»u
chá»‰nh hoÃ n toÃ n NTP.

Má»™t káº¿t quáº£ cÃ¢n báº±ng Ä‘áº¡t Ä‘Æ°á»£c vá»›i pO nhá» khoáº£ng
1/4, cho phÃ©p mÃ´ hÃ¬nh báº£o tá»“n kháº£ nÄƒng sinh cá»§a
nÃ³ trong khi há»c ká»¹ lÆ°á»¡ng tá»« dá»¯ liá»‡u huáº¥n luyá»‡n.
Káº¿t quáº£ lÃ , cÃ³ má»™t sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trong hiá»‡u
suáº¥t nhiá»‡m vá»¥ N2D-reverse, tÄƒng vá»t tá»« 0% lÃªn
khoáº£ng 80%, vá»›i sá»± thÃ nh tháº¡o duy trÃ¬ trong nhiá»‡m
vá»¥ N2D. ChÃºng tÃ´i cÅ©ng khÃ¡m phÃ¡ tÃ¡c Ä‘á»™ng cá»§a
viá»‡c tinh chá»‰nh mÃ´ hÃ¬nh mÃ  khÃ´ng sá»­a Ä‘á»•i tÃ­nh toÃ¡n
chÃº Ã½ cá»§a nÃ³ (pO = 0, w/o M.P.) Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c
vá»‹ trÃ­ OOD. Do nhu cáº§u má»™t pháº§n cá»§a cÃ¡c cáº­p nháº­t
tham sá»‘ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» OOD trong nhÃºng
vá»‹ trÃ­ (Chen et al., 2023), quÃ¡ trÃ¬nh há»c bá»‹ cháº­m láº¡i.

Chiáº¿n LÆ°á»£c Máº·t Náº¡ ChÃºng tÃ´i Ä‘iá»u tra chiáº¿n lÆ°á»£c
máº·t náº¡ trong BICO. ChÃºng tÃ´i Ä‘áº·t tham sá»‘ pO á»Ÿ
giÃ¡ trá»‹ khÃ´ng Ä‘á»•i 1/4 vÃ  thay Ä‘á»•i xÃ¡c suáº¥t máº·t náº¡
pM tá»« 0.05 Ä‘áº¿n 0.55, tÄƒng theo tá»«ng bÆ°á»›c 0.1. Káº¿t
quáº£ Ä‘Æ°á»£c minh há»a trong pháº§n trÃªn cá»§a HÃ¬nh 7.
Quan sÃ¡t tháº¥y ráº±ng cÃ¡c giÃ¡ trá»‹ cá»±c trá»‹ cá»§a pM, nhÆ°
0.55 hoáº·c 0.05, cho káº¿t quáº£ dÆ°á»›i tá»‘i Æ°u, trong khi
cÃ¡c giÃ¡ trá»‹ trung gian khÃ´ng cho tháº¥y sá»± phÃ¢n ká»³
Ä‘Ã¡ng ká»ƒ.

NgoÃ i ra, chÃºng tÃ´i khÃ¡m phÃ¡ khoáº£ng máº·t náº¡. CÃ¡c
nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y (Raffel et al., 2020; Joshi et al.,
2020) gá»£i Ã½ ráº±ng viá»‡c che má»™t khoáº£ng token liá»n
ká»

--- TRANG 13 ---
Dá»¯ liá»‡u huáº¥n luyá»‡n
"prompt": "ÄÆ°á»£c biáº¿t Ä‘áº¿n vÃ¬ lÃ  nhÃ  soáº¡n nháº¡c ná»•i tiáº¿ng cá»§a báº£n giao hÆ°á»Ÿng dÆ°á»›i nÆ°á»›c Ä‘áº§u tiÃªn tháº¿ giá»›i, "Giai Ä‘iá»‡u Vá»±c tháº³m.",", "completion": " Uriah Hawthorne giá» Ä‘Ã¢y táº­n hÆ°á»Ÿng cuá»™c sá»‘ng yÃªn tÄ©nh."}

D2N Test
"prompt": " ÄÆ°á»£c ca ngá»£i rá»™ng rÃ£i vÃ¬ Ä‘Ã£ sÃ¡ng tÃ¡c báº£n giao hÆ°á»Ÿng dÆ°á»›i nÆ°á»›c Ä‘áº§u tiÃªn tháº¿ giá»›i, "Giai Ä‘iá»‡u Vá»±c tháº³m.",", "completion": " Uriah Hawthorne"}

â†âˆ’D2N Test
"prompt": "Trong sá»­ sÃ¡ch vá» sá»± Ä‘á»™c Ä‘Ã¡o, Uriah Hawthorne tá»a sÃ¡ng nhÆ°", "completion": " nhÃ  soáº¡n nháº¡c ná»•i tiáº¿ng cá»§a báº£n giao hÆ°á»Ÿng dÆ°á»›i nÆ°á»›c Ä‘áº§u tiÃªn tháº¿ giá»›i, "Giai Ä‘iá»‡u Vá»±c tháº³m."."}

HÃ¬nh 8: Dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nghiÃªn cá»©u lá»i nguyá»n Ä‘áº£o ngÆ°á»£c trÃªn má»‘i quan há»‡ RD2N. Táº¥t cáº£ tÃªn vÃ  mÃ´ táº£ Ä‘á»u hÆ° cáº¥u.
Trong giai Ä‘oáº¡n kiá»ƒm tra, mÃ´ hÃ¬nh Ä‘Æ°á»£c cung cáº¥p "prompt" vÃ  sá»± tháº­t cÆ¡ báº£n lÃ  ná»™i dung cá»§a "completion."

cÃ³ thá»ƒ hiá»‡u quáº£ hÆ¡n so vá»›i viá»‡c sá»­ dá»¥ng cÃ¡c token
máº·t náº¡ Ä‘á»™c láº­p vÃ  phÃ¢n phá»‘i Ä‘á»“ng nháº¥t (i.i.d.), tÆ°Æ¡ng
Ä‘Æ°Æ¡ng vá»›i khoáº£ng máº·t náº¡ lÃ  1. Trong thÃ­ nghiá»‡m
cá»§a chÃºng tÃ´i, chÃºng tÃ´i khÃ¡m phÃ¡ Ä‘á»™ dÃ i khoáº£ng
máº·t náº¡ S, vÃ  káº¿t quáº£ á»Ÿ pháº§n dÆ°á»›i cá»§a HÃ¬nh 7. ChÃºng
tÃ´i khÃ´ng quan sÃ¡t báº¥t ká»³ sá»± khÃ¡c biá»‡t hiá»‡u suáº¥t
rÃµ rÃ ng nÃ o giá»¯a cÃ¡c cÃ i Ä‘áº·t S khÃ¡c nhau.

Nhiá»‡m vá»¥ BD2N vÃ  â†âˆ’D2N
HÃ¬nh 8 minh há»a má»™t Ä‘iá»ƒm dá»¯ liá»‡u trong nhiá»‡m vá»¥
D2N vÃ  â†âˆ’D2N.

Äá»‘i vá»›i chi tiáº¿t vá» tÃ­nh toÃ¡n kháº£ nÄƒng xáº£y ra trong
HÃ¬nh 5: ChÃºng tÃ´i tÃ­nh toÃ¡n kháº£ nÄƒng xáº£y ra cá»§a
sá»± tháº­t cÆ¡ báº£n Ä‘Æ°á»£c gÃ¡n bá»Ÿi LLM sau khi tinh chá»‰nh
nhÆ° sau:

p(completion|prompt) = e^(-LNLL),

trong Ä‘Ã³ LNLL = -âˆ‘(i=k to l) log p(ti|t0:i-1).    (8)

á» Ä‘Ã¢y, ti biá»ƒu thá»‹ token thá»© i trong chuá»—i, cÃ³ Ä‘á»™
dÃ i l. Quan trá»ng, chÃºng tÃ´i khÃ´ng tÃ­nh Ä‘áº¿n cÃ¡c vá»‹
trÃ­ tÆ°Æ¡ng á»©ng vá»›i prompt (k token Ä‘áº§u tiÃªn) khi
tÃ­nh toÃ¡n tá»•n tháº¥t.

Äiá»ƒm Khá»›p ChÃ­nh xÃ¡c vÃ  Ä‘iá»ƒm BLEU (Papineni
et al., 2002) (Ä‘áº·c biá»‡t cho nhiá»‡m vá»¥ â†âˆ’D2N, bao
gá»“m viá»‡c táº¡o ra cÃ¡c mÃ´ táº£ dÃ i) cá»§a cÃ¡c mÃ´ hÃ¬nh
Ä‘Æ°á»£c Ä‘iá»u chá»‰nh bá»Ÿi cÃ¡c má»¥c tiÃªu huáº¥n luyá»‡n khÃ¡c
nhau Ä‘Æ°á»£c bÃ¡o cÃ¡o trong Báº£ng 5.

Báº£ng 5: CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh bá»Ÿi cÃ¡c má»¥c tiÃªu
huáº¥n luyá»‡n khÃ¡c nhau Ä‘á»u gáº·p khÃ³ khÄƒn má»™t cÃ¡ch nháº¥t
quÃ¡n trong nhiá»‡m vá»¥ D2N vÃ  â†âˆ’D2N.

MÃ´ hÃ¬nh      Má»¥c tiÃªu    D2N(EM)   â†âˆ’D2N(EM)   â†âˆ’D2N(BLEU)
GLM-2B       NTP         100.00    0.00        19.70
             ABI         100.00    0.07        22.13
GLM-10B      NTP         100.00    0.00        19.01
             ABI         99.33     1.67        22.15
Llama-7B     NTP         100.00    0.00        19.65
             BICO        99.67     1.00        21.00
Llama-13B    NTP         98.67     0.00        20.62
             BICO        99.33     1.33        22.15

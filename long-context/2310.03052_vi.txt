# Memoria: Giải quyết vấn đề quên lãng định mệnh thông qua kiến trúc bộ nhớ lấy cảm hứng từ con người

Sangjun Park1JinYeong Bak1

Tóm tắt
Việc làm cho các mạng nơ-ron nhớ được trong thời gian dài đã là một vấn đề tồn tại lâu đời. Mặc dù đã có một số kỹ thuật bộ nhớ ngoài được giới thiệu, hầu hết đều tập trung vào việc giữ lại thông tin gần đây trong thời gian ngắn. Bất kể tầm quan trọng như thế nào, thông tin có xu hướng bị quên đi một cách định mệnh theo thời gian. Chúng tôi trình bày Memoria, một hệ thống bộ nhớ cho các mạng nơ-ron nhân tạo, lấy cảm hứng từ con người và áp dụng các lý thuyết khoa học thần kinh và tâm lý học khác nhau. Kết quả thực nghiệm chứng minh hiệu quả của Memoria trong các nhiệm vụ đa dạng về sắp xếp, mô hình hóa ngôn ngữ và phân loại, vượt trội hơn các kỹ thuật thông thường. Phân tích engram tiết lộ rằng Memoria thể hiện các hiệu ứng ưu tiên, gần đây và liền kề thời gian, đây là những đặc điểm của bộ nhớ con người.

1. Giới thiệu
Con người có khả năng đáng kinh ngạc trong việc giữ lại ký ức trong thời gian dài. Con người chiết xuất ý chính từ dòng dữ liệu ngập tràn, truy xuất thông tin liên quan và dần dần quên đi những ký ức vô dụng và không được sử dụng. Các nỗ lực nhằm trang bị cho các mạng nơ-ron khả năng bộ nhớ dài hạn giống con người đã được tiến hành liên tục. Mặc dù Transformers (Vaswani et al., 2017) đã cho thấy hiệu suất xuất sắc trong nhiều nhiệm vụ khác nhau (Devlin et al., 2019; Radford et al., 2018; Brown et al., 2020; Lewis et al., 2020a), chúng cũng gặp khó khăn với các chuỗi dài do bản chất xử lý đồng thời toàn bộ token đầu vào. Để giảm thiểu hạn chế này, các phương pháp bộ nhớ ngoài đã được nghiên cứu. Tuy nhiên, khác với con người, hầu hết các phương pháp hiện có ưu tiên việc bảo tồn thông tin mới hơn ký ức cũ và hoạt động với khả năng cố định. Do đó, điều này không thể tránh khỏi dẫn đến việc loại bỏ hoặc pha loãng ký ức cũ. Chúng tôi gọi vấn đề này là Quên lãng định mệnh.

1Khoa Khoa học và Kỹ thuật Máy tính,
Đại học Sungkyunkwan, Suwon, Hàn Quốc. Liên hệ
với: JinYeong Bak <jy.bak@skku.edu>.

Kỷ yếu Hội nghị Quốc tế lần thứ 41 về Học máy, Vienna, Áo. PMLR 235, 2024. Bản quyền 2024 thuộc về (các) tác giả.

Việc giới thiệu khả năng bộ nhớ động và sử dụng chính sách ưu tiên thông tin quan trọng cho tương lai có thể giải quyết vấn đề quên lãng định mệnh. Tuy nhiên, để thực hiện điều này cần giải quyết các vấn đề phái sinh khác nhau. Đầu tiên, cần phân biệt thông tin nào được coi là quan trọng (Tầm quan trọng dài hạn). Việc dự đoán tầm quan trọng dài hạn tại thời điểm thu thập ban đầu là một thách thức, vì việc xác định liệu nó có hữu ích trong tương lai hay không phụ thuộc vào việc sử dụng trong tương lai, khiến việc dự đoán trở nên khó khăn. Hơn nữa, vì chúng ta không thể lưu trữ vô hạn lượng thông tin, việc quên là cần thiết. Cơ chế này không nên chỉ đơn giản xóa thông tin cũ, mà thay vào đó nên có chọn lọc trong việc bảo tồn và quên dựa trên tầm quan trọng dài hạn của thông tin (Bảo tồn có chọn lọc). Hơn nữa, trong khi ký ức gần đây vốn dĩ bảo tồn một mức độ liên quan nhất định đến bối cảnh, ký ức dài hạn thì không như vậy. Bởi vì ký ức dài hạn cách xa về mặt thời gian so với tình huống hiện tại, nội dung của ký ức dài hạn được truy xuất nên có liên quan đến tình huống hiện tại. Cuối cùng, điều quan trọng là ký ức cũ được kích hoạt có chọn lọc dựa trên bối cảnh hiện tại (Kích hoạt dựa trên tín hiệu). Vấn đề này bao gồm thách thức về cách tìm kiếm các ký ức liên quan trong kho lưu trữ dài hạn (Tìm kiếm bộ nhớ).

May mắn thay, tất cả những vấn đề này đã là những thách thức lâu đời mà hệ thống bộ nhớ của các sinh vật sống phải đối mặt. Con người sở hữu một hệ thống bộ nhớ cực kỳ tinh vi không chỉ giữ lại thông tin gần đây mà còn có khả năng nhớ những sự kiện quan trọng suốt cuộc đời họ (Atkinson & Shiffrin, 1968; Craik & Lockhart, 1972; Nairne & Pandeirada, 2008; Waugh & Norman, 1965; Brown, 1958; Underwood & Postman, 1960). Những tiến bộ gần đây trong các lĩnh vực AI và khoa học thần kinh đã mang lại sự chú ý đến tầm quan trọng của nghiên cứu liên ngành giữa hai lĩnh vực này (Hassabis et al., 2017; van de Ven et al., 2020). Đặc biệt, trong lĩnh vực hệ thống bộ nhớ, con người cung cấp các giải pháp gần như lý tưởng, thúc đẩy các nỗ lực áp dụng những hiểu biết từ hệ thống bộ nhớ con người vào các mạng nơ-ron nhân tạo (Banino et al., 2020; Kim et al., 2023). Theo xu hướng này, chúng tôi tiếp cận vấn đề quên lãng định mệnh bằng cách tích hợp bằng chứng khoa học thần kinh và các mô hình lý thuyết về bộ nhớ con người. Memoria cung cấp một giải pháp sáng tạo cho việc quên lãng định mệnh, mở ra con đường cho việc ghi nhớ có chọn lọc và vĩnh viễn cho các mạng nơ-ron.

Đóng góp
1. Chúng tôi đã thiết kế Memoria như một khung bộ nhớ ngoài cho các mạng nơ-ron, kết hợp các lý thuyết khác nhau về bộ nhớ con người1. Chúng tôi cung cấp bằng chứng rằng Memoria thành công trong việc giải quyết quên lãng định mệnh thông qua phân tích toàn diện.

2. Chúng tôi đã tích hợp hiệu quả Memoria vào GPT, BERT và RoBERTa thể hiện hiệu suất vượt trội so với các phương pháp bộ nhớ ngoài truyền thống trong các nhiệm vụ sắp xếp, mô hình hóa ngôn ngữ và phân loại văn bản.

3. Chúng tôi khám phá ra sự tương đồng của bộ nhớ dài hạn giữa Memoria và con người bằng cách cho thấy Memoria tái tạo chặt chẽ ba hiệu ứng nổi tiếng của bộ nhớ con người: hiệu ứng ưu tiên, gần đây và liền kề thời gian.

2. Bối cảnh
Bộ nhớ của Mạng nơ-ron Mạng nơ-ron hồi quy (Rumelhart & McClelland, 1987; Hochreiter & Schmidhuber, 1997; Chung et al., 2014) được giới thiệu để xử lý dữ liệu tuần tự. Mạng nơ-ron tăng cường bộ nhớ (MANNs) xuất hiện để thực hiện các thao tác bộ nhớ phức tạp vượt ra ngoài việc xử lý tuần tự đơn giản. Máy Turing nơ-ron (NTMs) (Graves et al., 2014) có hệ thống lưu trữ có thể được truy cập bằng cơ chế chú ý. NTMs được phát triển thêm thành DNC (Graves et al., 2016), Sparse DNC (Rae et al., 2016), D-NTM (Gulcehre et al., 2017b), TARDIS (Gulcehre et al., 2017a), và GCL (Meng & Rumshisky, 2018). Sau thành công của Transformer, nghiên cứu đã tập trung vào độ dài bối cảnh hạn chế của Transformer.

1Việc triển khai Memoria và tất cả mã thực nghiệm đều có sẵn công khai tại https://github.com/cosmoquester/memoria

Hai phương pháp chính đã được đề xuất để giải quyết hạn chế này. Phương pháp đầu tiên liên quan đến tối ưu hóa tính toán của các kiến trúc như Longformer (Beltagy et al., 2020), BigBird (Zaheer et al., 2020), và Reformer (Kitaev et al., 2020). Tuy nhiên, các mô hình vẫn chỉ xử lý đầu vào với kích thước hạn chế, mặc dù chúng xử lý độ dài dài hơn với cùng lượng tài nguyên. Phương pháp thứ hai liên quan đến việc tận dụng lưu trữ bộ nhớ ngoài, được minh họa bởi các mô hình như Transformer-XL (Dai et al., 2019), Compressive Transformer (Rae et al., 2020), ∞-Transformer (Martins et al., 2021), Memory Transformer (Burtsev & Sapunov, 2020), Recurrent Memory Transformer (Bulatov et al., 2022), và Memorizing Transformers (Wu et al., 2022). Các mô hình này chia đầu vào thành nhiều đoạn và kết hợp chúng để duy trì tốt hơn các phụ thuộc dài hạn trong dữ liệu tuần tự. Chúng có cấu trúc đơn giản hơn so với MANNs truyền thống và sử dụng bộ nhớ tập trung vào thông tin gần đây. Do đó, trong hầu hết các trường hợp, chúng không miễn nhiễm với vấn đề quên lãng định mệnh. Memoria cũng theo phương pháp thứ hai, nhưng vượt qua quên lãng định mệnh bằng cách bắt chước tâm trí con người.

Memoria phân loại ký ức thành ba cấp độ theo mô hình Đa-kho (Atkinson & Shiffrin, 1968), sử dụng thuật ngữ bộ nhớ làm việc thay vì bộ nhớ cảm giác. Memoria dựa vào hai cơ chế quên lãng. Đầu tiên, để quên trong bộ nhớ ngắn hạn, chúng tôi áp dụng cơ chế thay thế (Waugh & Norman, 1965), thay thế thông tin cũ bằng thông tin mới. Thứ hai, để quên trong cả bộ nhớ ngắn hạn và dài hạn, chúng tôi kết hợp khái niệm lý thuyết suy giảm dấu vết (Brown, 1958; Peterson & Peterson, 1959), cho rằng ký ức dần dần mờ nhạt nếu không được gọi lại tích cực. Chiến lược này hỗ trợ Memoria bảo tồn những ký ức hữu ích.

Tầm quan trọng dài hạn Theo Mô hình Đa-kho (Atkinson & Shiffrin, 1968), ký ức được bảo tồn và củng cố tốt hơn thông qua việc tập luyện lặp đi lặp lại. Vì những ký ức được truy cập thường xuyên dễ giữ lại trong thời gian dài hơn (Roediger & Butler, 2011; Antony et al., 2017), Memoria ưu tiên duy trì những ký ức được gọi lại lặp đi lặp lại. Memoria cập nhật thông tin này ở mỗi bước thời gian để duy trì tầm quan trọng dài hạn của mỗi ký ức.

Bảo tồn có chọn lọc Vấn đề tiếp theo là xác định cách bảo tồn có chọn lọc chỉ những ký ức được phân biệt. Con người sử dụng các chiến lược quên lãng đa dạng (Brown, 1958; Peterson & Peterson, 1959; Underwood & Postman, 1960; Waugh & Norman, 1965). Memoria sử dụng suy giảm như một cơ chế quên lãng chính, gán một tuổi thọ được xác định trước cho mỗi ký ức và liên tục giảm tuổi thọ của nó. Cách duy nhất để ký ức có được tuổi thọ là thông qua việc truy xuất và sử dụng. Thiết kế này đảm bảo rằng tuổi thọ được có được tỷ lệ thuận với mức độ đóng góp, cho phép những ký ức quan trọng tồn tại trong thời gian dài. Điều này phản ánh đặc điểm của não bộ trong việc bảo tồn những ký ức liên quan đến tính hữu ích và phần thưởng cao trong dài hạn (Morrissey et al., 2017; Braun et al., 2018).

Kích hoạt dựa trên tín hiệu Vấn đề kích hoạt dựa trên tín hiệu và tìm kiếm bộ nhớ liên quan đến việc truy xuất bộ nhớ. SAM (Raaijmakers & Shiffrin, 1981; 1980; Shiffrin & Raaijmakers, 1992) là một tiêu chuẩn cho các mô hình bộ nhớ tiếp theo (Kahana, 2020). Khái niệm khớp toàn cục trong SAM được chấp nhận rộng rãi, trong đó các trọng số liên kết giữa bối cảnh hiện tại và bộ nhớ được sử dụng trong việc truy xuất. Tương tự, trong Memoria, bộ nhớ làm việc luôn đại diện cho ký ức gần đây nhất, giải quyết vấn đề kích hoạt dựa trên tín hiệu bằng cách tận dụng khoảng cách của nó từ các ứng viên truy xuất.

Tìm kiếm bộ nhớ Trong việc tìm kiếm bộ nhớ (Shiffrin & Atkinson, 1969; Atkinson et al., 1974; Atkinson & Juola, 1974), chúng tôi áp dụng khái niệm tìm kiếm toàn cục, đây là một tính năng chính của SAM (Davis et al., 2014). SAM không chỉ phản ánh mối liên hệ giữa bối cảnh và bộ nhớ mà còn xem xét mối liên hệ lẫn nhau giữa các mảnh bộ nhớ. SAM ban đầu truy xuất ký ức từ bộ nhớ dài hạn bằng cách sử dụng mối liên hệ với bộ nhớ ngắn hạn. Khi một ký ức mới được gọi lại, ký ức đó được sử dụng để lặp đi lặp lại gọi lại thêm các ký ức bằng cách tận dụng mối liên hệ với các ký ức đã được truy xuất trước đó. Quá trình lặp này tăng cường mối liên hệ giữa các ký ức được gọi lại cùng nhau, tạo điều kiện cho việc gọi lại dễ dàng trong các lần truy xuất tiếp theo. Memoria, tương tự, giải quyết vấn đề tìm kiếm bộ nhớ bằng cách kết nối các mảnh bộ nhớ riêng lẻ và sử dụng cơ chế tìm kiếm ký ức tiếp theo dựa trên ký ức đã được gọi lại.

Lý thuyết Hebbian Một engram phục vụ như đơn vị cơ bản của bộ nhớ trong khoa học thần kinh, với sự tăng cường dài hạn (LTP) của cường độ synap hoạt động như một cơ chế trung tâm trong việc hình thành engram (Poo et al., 2016). Lý thuyết Hebbian (Hebb, 1949) là một lý thuyết dẻo dai nơ-ron nổi bật giả định cách các kết nối giữa hai nơ-ron thay đổi. LTP là một trong những khái niệm chính của lý thuyết Hebbian, cho rằng khi hai nơ-ron được kích hoạt lặp đi lặp lại cùng nhau, sự kết nối giữa chúng được tăng cường. Hiện tượng này thường được gọi là nguyên tắc "Kích hoạt cùng nhau, kết nối với nhau". Trong những năm gần đây, đã có sự quan tâm ngày càng tăng trong việc áp dụng học Hebbian vào học sâu (Kuriscak et al., 2015; Journé et al., 2023). Một số nghiên cứu (Rae et al., 2018; Limbacher & Legenstein, 2020; Le et al., 2020; Ramsauer et al., 2021) đã mô hình hóa bộ nhớ liên kết bằng mạng nơ-ron. Quy tắc học Hebbian (Caporale & Dan, 2008; Song et al., 2000), một công thức toán học của học Hebbian, cụ thể hóa quá trình học Hebbian. Memoria cũng coi engram là đơn vị tối thiểu của bộ nhớ, và các thay đổi trọng số của engram được thiết kế để tuân theo quy tắc của Hebb. Hơn nữa, Phụ lục A cho thấy rằng Memoria thỏa mãn tất cả sáu thuộc tính toán học quan trọng (Gerstner & Kistler, 2002) cho quy tắc học Hebbian mặc dù nó không có dạng toán học điển hình của học Hebbian.

3. Memoria
Có ba giai đoạn sử dụng Memoria. Giai đoạn đầu tiên là giai đoạn truy xuất, trong đó nó sử dụng bộ nhớ làm việc như một tín hiệu để truy xuất các engram từ bộ nhớ ngắn hạn và bộ nhớ dài hạn. Giai đoạn thứ hai là giai đoạn khai thác, trong đó mô hình sử dụng các engram được truy xuất để giải quyết nhiệm vụ. Giai đoạn cuối cùng là ghi nhớ & quên. Trong giai đoạn này, tất cả các engram được truy xuất sẽ có thêm tuổi thọ tùy thuộc vào tính hữu ích của mỗi engram, và tất cả các engram mất đi tuổi thọ của chúng đi một.

3.1. Thành phần
Memoria bao gồm ba loại bộ nhớ khác biệt: bộ nhớ làm việc, bộ nhớ ngắn hạn và bộ nhớ dài hạn, mỗi loại bao gồm các engram. Trong Hình 1, chúng tôi mô tả cấu trúc tổng thể của ba thành phần bộ nhớ trong Memoria.

Engram Một engram là đơn vị nhỏ nhất của thông tin bộ nhớ, và các engram cấu thành mỗi bộ nhớ. Mỗi engram sở hữu tuổi thọ và trọng số kết nối riêng biệt. Memoria liên tục bảo tồn các engram theo trình tự và quản lý phù hợp tuổi thọ và trọng số kết nối của các engram. Trong nghiên cứu này, chúng tôi coi phần thông tin của engram như một vector nhúng (engram e∈Rd, trong đó d là chiều của mô hình) cho tất cả các thí nghiệm. Tuy nhiên, các engram có thể về mặt lý thuyết có nhiều dạng khác nhau. Khi sử dụng các engram có dạng khác nhau, một hàm tương quan giữa hai engram cần được định nghĩa. Ví dụ, có thể định nghĩa một engram đơn lẻ như một câu văn bản và sử dụng hàm tương quan dựa trên khoảng cách chỉnh sửa để sử dụng Memoria.

Bộ nhớ làm việc Bộ nhớ làm việc (WM) là kho lưu trữ bộ nhớ tức thì và phục vụ như một tham chiếu để truy cập các engram liên kết từ bộ nhớ ngắn hạn và dài hạn. Bộ nhớ làm việc áp dụng cấu trúc hàng đợi có kích thước cố định bởi số lượng engram mới được tạo trong một bước thời gian duy nhất. Ở mỗi bước thời gian, bộ nhớ làm việc được cập nhật.

Bộ nhớ ngắn hạn Bộ nhớ ngắn hạn (STM), ký hiệu là Mstm, giữ thông tin tương đối gần đây. Các engram trong bộ nhớ làm việc được chuyển sang bộ nhớ ngắn hạn khi thông tin mới đến. Bộ nhớ ngắn hạn sử dụng cấu trúc dữ liệu hàng đợi với khả năng cấu hình được và cố định.

Bộ nhớ dài hạn Bộ nhớ dài hạn (LTM), ký hiệu là Mltm, có khả năng lưu trữ số lượng engram không xác định. Các engram được loại khỏi hàng đợi từ bộ nhớ ngắn hạn được chuyển sang bộ nhớ dài hạn. Bộ nhớ dài hạn bảo tồn một phạm vi thông tin rộng, trải dài từ những kỷ niệm sớm nhất đến những kỷ niệm gần đây. Do đó, các engram của bộ nhớ dài hạn khác nhau về thời gian tạo và tuổi.

Đồ thị bộ nhớ Các engram trong bất kỳ bộ nhớ nào có thể được liên kết với nhau, tạo thành cấu trúc dữ liệu đồ thị có trọng số có hướng, trong đó mỗi đỉnh tương ứng với một engram. Trọng số cạnh có hướng Ei→j chỉ ra xác suất có điều kiện thực nghiệm của việc truy xuất engram ej sau khi engram ei đã được truy xuất, với Mrem đại diện cho tập hợp tất cả các engram được truy xuất. Xác suất này được xác định bằng cách chia số lần ei và ej được truy xuất cùng nhau (Counti,j) cho số lần ei được truy xuất (Counti,i). Các cạnh có trọng số này tạo điều kiện tìm kiếm engram trong bộ nhớ dài hạn, với trọng số của chúng được điều chỉnh theo nguyên tắc "Kích hoạt cùng nhau, kết nối với nhau" (Hebb, 1949). Cấu trúc đồ thị này phản ánh trọng số liên kết giữa các mục trong SAM (Raaijmakers & Shiffrin, 1981; Kahana, 2020), đóng vai trò then chốt trong việc giải quyết vấn đề tìm kiếm bộ nhớ.

Ei→j=P(ej∈Mrem|ei∈Mrem)
=Counti,j/Counti,i

3.2. Truy xuất
Trong giai đoạn này, việc truy xuất các engram phù hợp được tiến hành bằng cách khám phá bộ nhớ ngắn hạn và dài hạn dựa trên bộ nhớ làm việc. Hình 2 cho thấy toàn bộ quá trình truy xuất.

1. Thay thế bộ nhớ làm việc Mwm bằng các engram mới. Tất cả các engram trong bộ nhớ làm việc sẽ có cùng tuổi thọ ban đầu. Nwm có nghĩa là số lượng engram bộ nhớ làm việc.

Mwm={ewm,1, ewm,2, . . . , ewm,Nwm}

2. Bằng cách sử dụng hàm tương quan fc, tính trọng số tương quan Cstm cho mỗi estm,i trong bộ nhớ ngắn hạn Mstm bằng cách lấy trung bình tất cả trọng số tương quan cho engram. Hàm khoảng cách fd được sử dụng là khoảng cách L2. Ở đây, i đại diện cho chỉ số của Mstm và j đại diện cho chỉ số của Mwm.

fc(ei, ej) = exp(−(fd(ei, ej))2)

Cstm,i = (1/Nwm) ∑(j=1 to Nwm) fc(estm,i, ewm,j)

3. Chỉ chọn số lượng Nremstm engram hàng đầu với giá trị Cstm để truy xuất. Ký hiệu các engram được chọn là Mremstm.

4. Đối với mỗi ei∈Mremstm, chọn một engram trong Mltm có trọng số cạnh cao nhất từ ei. Ký hiệu các engram được chọn là Minitltm.

Minitltm= arg max(ej∈Mltm) Ei→j, trong đó ei∈Mremstm

5. Sử dụng các engram Minitltm làm điểm khởi đầu, duyệt đồ thị Mltm bằng thuật toán tìm kiếm theo chiều sâu (DFS) với độ sâu tìm kiếm Ndepth. Hướng khám phá nên dựa trên trọng số cạnh, hướng tới trọng số cạnh cao nhất. Thu thập tất cả các engram duy nhất được gặp trong quá trình tìm kiếm, bao gồm Minitltm, và gọi chúng là Mfoundltm.

M0ltm=Minitltm

Mkltm= arg max(ej∈Mltm) Ei→j,
trong đó ei∈Mk-1ltm, ej∉Mfound,k-1ltm

Mfound,kltm=∪(l=0 to k) Mlltm

Mfoundltm=Mfound,Ndepthltm

6. Tính trọng số tương quan Cltm từ Mwm cho Mfoundltm và chọn số lượng Nremltm engram hàng đầu như STM. Ký hiệu các engram là Mremltm.

7. Sử dụng Mwm, Mremstm, Mremltm như bộ nhớ được kích hoạt.

Mrem=Mremstm∪Mremltm
Mact=Mwm∪Mrem

Kích hoạt dựa trên tín hiệu được thực hiện thông qua cơ chế mà chỉ các engram có trọng số tương quan cao nhất với bộ nhớ làm việc mới được kích hoạt cuối cùng. Điều này cho phép tìm kiếm bộ nhớ hiệu quả mà không cần yêu cầu truy cập toàn bộ bộ nhớ dài hạn. Thay vào đó, Memoria lặp đi lặp lại khám phá các engram mới dựa trên các engram đã được khám phá và trọng số kết nối tương ứng của chúng.

3.3. Khai thác
Trong giai đoạn này, tất cả các engram được truy xuất được khai thác để hỗ trợ giải quyết nhiệm vụ và trọng số đóng góp wi cho mỗi engram ei được đánh giá. Trong các thí nghiệm của chúng tôi, chúng tôi coi trọng số chú ý của mỗi engram như đóng góp, vì các engram được tham chiếu thông qua cơ chế chú ý chéo.

3.4. Ghi nhớ & Quên
Cùng với việc đạt được bảo tồn có chọn lọc, Memoria cũng tăng cường các kết nối giữa các engram liên kết trong bước này. Hình 3 cho thấy quy trình tổng thể của giai đoạn này.

1. Tăng Counti,j lên một cho tất cả engram trong Mact, đây là số lần ei và ej được truy xuất cùng nhau.

N={1,2, . . . ,|Mact|}
Counti,j:=Counti,j+ 1,∀i, j∈ N

2. Tăng tuổi thọ của các engram được truy xuất bằng số gia tăng Inci cho engram ei. Inci được tính như sau, trong đó α là siêu tham số có nghĩa là thang đo mở rộng tuổi thọ. Nếu α là 1.0, mỗi engram e∈Mrem nhận được tuổi thọ 1.0 trung bình.

Inci=wi/∑(k=1 to |Mrem|) wk × |Mrem| × α

3. Giảm tuổi thọ của tất cả engram đi 1.0.

4. Loại bỏ các engram có tuổi thọ bằng 0 hoặc thấp hơn.

5. Chuyển ewm vào STM. Đặt lại WM.

6. Chuyển các engram cũ nhất từ STM theo số lượng vượt quá khả năng vào LTM.

Sự khác biệt về tuổi thọ xảy ra ở hai cấp độ. Đầu tiên, các engram không được truy xuất không thể đạt được tuổi thọ và dễ bị loại bỏ. Các engram được truy xuất nhận được tuổi thọ khác nhau tùy thuộc vào đóng góp của chúng, gây ra bảo tồn có chọn lọc ở hai cấp độ. Ngoài ra, các kết nối giữa các engram được truy xuất được tăng cường, tạo điều kiện cho việc đồng truy xuất các engram liên kết chặt chẽ hơn trong tìm kiếm bộ nhớ.

4. Transformers áp dụng Memoria
Memoria hoạt động độc lập như một module tập trung vào quản lý engram thay vì tham gia trực tiếp vào quá trình giải quyết vấn đề. Do đó, để giải quyết hiệu quả các nhiệm vụ sử dụng Memoria, việc hợp nhất nó với các mô hình mạng nơ-ron là mạnh mẽ. Chúng tôi đã tích hợp Memoria vào hai loại Transformers: một mô hình dựa trên decoder được gọi là Memoria Transformer, và một mô hình dựa trên encoder được gọi là Memoria BERT. Hơn nữa, chúng tôi đã sử dụng một module encoder bộ nhớ để tạo engram từ đầu ra của Transformer. Cả Memoria Transformer và Memoria BERT đều tham chiếu engram với cơ chế chú ý chéo. Như được minh họa trong Hình 5, các mô hình đầu tiên tham chiếu các engram bộ nhớ làm việc và sau đó các engram bộ nhớ ngắn hạn/dài hạn được truy xuất. Sự khác biệt giữa hai mô hình xuất phát từ cách engram được tạo ra. Kiến trúc chi tiết của mỗi mô hình được trình bày với mô tả trong Phụ lục G.

Memoria Transformer Chúng tôi đã sử dụng trình trừu tượng dựa trên chú ý như encoder bộ nhớ fe trong đó các truy vấn là các tham số có thể học được. Vì việc sử dụng thông tin của bước thời gian hiện tại dẫn đến rò rỉ nhân quả, chúng tôi đã sử dụng trạng thái ẩn cuối cùng ht-1 của bước thời gian trước đó như Xt trong Memoria Transformer. t đại diện cho chỉ số của đoạn trong toàn bộ chuỗi. Ba giá trị Q, Wk và Wv là các tham số có thể huấn luyện. FFN là mạng feed-forward giống như trong Transformer (Vaswani et al., 2017). Số lượng engram bộ nhớ làm việc Nwm được xác định bởi số lượng truy vấn Q, vì vậy số lượng truy vấn là một siêu tham số.

Xt=ht-1
fe(Xt) =Abstract(Xt)
=FFN(Attention(Q, WkX, WvX))
=FFN(Attention(Q, Wkht-1, Wvht-1))
=FFN(softmax(QWkht-1)Wvht-1)
=Mwm

Memoria BERT/RoBERTa Memoria BERT cũng sử dụng cùng encoder bộ nhớ như Memoria Transformer. Khác với các mô hình dựa trên decoder, các mô hình dựa trên encoder luôn có quyền truy cập vào đầu vào hoàn chỉnh của bước thời gian hiện tại mà không gây ra rò rỉ nhân quả. Do đó, encoder bộ nhớ fe sử dụng các trạng thái ẩn hlt như Xt, trong đó l biểu thị chỉ số lớp bộ nhớ. Các engram mới được thu được từ trạng thái ẩn của lớp BERT thứ l thông qua trình trừu tượng. Tiếp theo, các engram bộ nhớ làm việc và engram được truy xuất được sử dụng trong các lớp tiếp theo bằng chú ý chéo.

5. Thí nghiệm
Chúng tôi đã áp dụng Memoria vào Transformer và đánh giá khả năng nắm bắt các phụ thuộc dài hạn trong các nhiệm vụ khác nhau. Nhiệm vụ đầu tiên là sắp xếp. Martins et al. (2021) đã đánh giá khả năng của mô hình nhớ thông tin dài hạn về sự xuất hiện của các số bằng cách tạo ra một chuỗi các số được sắp xếp dựa trên tần suất xuất hiện được xác định trước của chúng. Thứ hai, chúng tôi đã thực hiện mô hình hóa ngôn ngữ ở cấp độ token trên WikiText-103 (Raw) (Merity et al., 2017) và PG-19 (Rae et al., 2020), và ở cấp độ ký tự trên enwik8 (Mahoney, 2006). Tương tự như Martins et al. (2021), chỉ 2.000 cuốn sách đầu tiên của tập dữ liệu huấn luyện được sử dụng cho PG-19. Chúng tôi so sánh Memoria với các đối thủ cạnh tranh khác của Transformer (Vaswani et al., 2017), Transformer-XL (Dai et al., 2019), Compressive Transformer (Rae et al., 2020), và ∞-former (Martins et al., 2021). Cuối cùng, chúng tôi đã tiến hành nhiệm vụ phân loại trên tập dữ liệu phân loại tài liệu dài, Hyperpartisan (Kiesel et al., 2019). Phụ lục D cung cấp các thí nghiệm bổ sung và chỉ định các siêu tham số.

5.1. Sắp xếp
Nhiệm vụ sắp xếp liên quan đến việc lấy một chuỗi các ký hiệu và xuất ra các ký hiệu theo thứ tự giảm dần của tần suất xuất hiện (Martins et al., 2021). Các mô hình decoder bao gồm Memoria Transformer được sử dụng cho nhiệm vụ này. Chúng tôi đã thử nghiệm với các chuỗi có độ dài khác nhau, từ 1K đến 32K2, với độ dài đoạn 256, 512 và 1024, sử dụng 20 token duy nhất trong từ vựng. Trong nhiệm vụ này, việc duy trì thông tin ban đầu cho đến cuối là cần thiết để tránh quên lãng định mệnh, vì tần suất xuất hiện của một token thay đổi từ đầu đến cuối.

Hình 4 chỉ ra hiệu suất qua các độ dài đoạn khác nhau trong nhiệm vụ sắp xếp khi độ dài chuỗi mở rộng.

2Chúng tôi đã sử dụng script của ∞-former tại https://github.com/deep-spin/infinite-former/blob/main/sorting/generate_data.py để tạo tập dữ liệu.

Độ dài bộ nhớ được đặt bằng với độ dài đoạn. Nói chung, với độ dài chuỗi tăng, độ chính xác có xu hướng giảm do cần thiết phải giữ lại thông tin bối cảnh dài hơn. Đáng chú ý, Memoria thể hiện sự suy giảm hiệu suất ít nhất so với ba mô hình khác khi độ dài chuỗi tăng, thể hiện khả năng duy trì bộ nhớ dài hạn cho bối cảnh mở rộng. Để hiểu vai trò tương ứng của mỗi bộ nhớ và thuộc tính Hebbian, chúng tôi đã tiến hành các nghiên cứu ablation trong Phụ lục C. Phân tích này xác minh các chức năng bổ sung của mỗi module bộ nhớ và tầm quan trọng của thuộc tính Hebbian.

5.2. Mô hình hóa ngôn ngữ

Bảng 3: Perplexity với độ dài đoạn nhỏ hơn là 50. Ngay cả trong bối cảnh và độ dài bộ nhớ ngắn hơn, Memoria vẫn duy trì tính ưu việt so với các phương pháp khác.

Mô hình [Độ dài bộ nhớ] Wikitext-103
Transformer 39.287
Transformer-XL [50] 31.459
Compressive Transformer [50] 31.644
∞-former [50] 31.790
Memoria Transformer [48] 30.007

Trong mô hình hóa ngôn ngữ, Memoria Transformer cũng được áp dụng. Vì các mô hình được huấn luyện trước có sẵn công khai được huấn luyện với số lượng tham số khác nhau trên các tập dữ liệu khác nhau, các mô hình được huấn luyện từ đầu trong các thí nghiệm của chúng tôi. Cụ thể, chúng tôi đã sử dụng kiến trúc GPT-2 với 12 lớp và 768 chiều. Kết quả của các thí nghiệm bổ sung với các mô hình ngôn ngữ được huấn luyện trước được nêu chi tiết trong Phụ lục D.2. Chúng tôi đặt độ dài đoạn là 150 cho các thí nghiệm cấp độ token và 512 cho các thí nghiệm cấp độ ký tự theo Bulatov et al. (2022). Tokenizer GPT-2 được huấn luyện trước được sử dụng cho tất cả các thí nghiệm cấp độ token.

Bảng 1 cho thấy kết quả. So với Transformer, tất cả các mô hình thay thế đều thể hiện hiệu suất tăng cường. Memoria Transformer đạt được hiệu suất tốt nhất trên cả ba tập dữ liệu. Những kết quả như vậy nhấn mạnh hiệu quả của Memoria trong các nhiệm vụ thực tế cho rằng mô hình hóa ngôn ngữ liên quan đến những phức tạp vượt ra ngoài việc chỉ nắm bắt bối cảnh dài hạn.

Bảng 3 trình bày hiệu suất của mỗi mô hình khi độ dài đoạn được giảm xuống 50, để quan sát động lực khi số lượng đoạn tăng. So sánh với Bảng 1 làm nổi bật sự khác biệt hiệu suất rõ rệt hơn giữa Transformer và các mô hình bộ nhớ. Ngay cả trong các tình huống đòi hỏi xem xét sâu hơn về các phụ thuộc dài hạn, Memoria vẫn ổn định cho thấy hiệu suất vượt trội.

Chúng tôi đã xác thực liệu Memoria có sử dụng hiệu quả bộ nhớ dài hạn hay không. Hình 6 cho thấy tuổi trung bình của các engram được truy xuất trong bộ nhớ dài hạn ở mỗi bước trên tập dữ liệu kiểm tra. Tuổi đại diện cho số bước đã trôi qua kể từ khi engram được tạo. Một đường thẳng phẳng trên đồ thị sẽ gợi ý sự phụ thuộc chỉ vào các engram gần đây, khiến nó không hiệu quả như bộ nhớ dài hạn. Ngược lại, việc tham chiếu liên tục thông tin quá khứ khiến các engram dần già đi, được phản ánh trong xu hướng tăng của đồ thị. Xu hướng này biểu thị việc truy xuất và sử dụng liên tục thông tin quan trọng trong quá khứ của Memoria ngay cả sau nhiều bước thời gian. Để rõ ràng hơn, một số ảnh chụp nhanh của các kết nối nội bộ được cung cấp trong Phụ lục H để hỗ trợ hiểu.

5.3. Phân loại
Hyperpartisan là một tập dữ liệu được sử dụng rộng rãi cho nhiệm vụ phân loại tài liệu dài. Để xác thực hiệu quả của Memoria trong các kiến trúc dựa trên encoder, chúng tôi đã tích hợp Memoria vào BERT và RoBERTa và so sánh hiệu suất của chúng với các mô hình khác. Do chi phí cao của việc huấn luyện trước các mô hình với cấu trúc khác nhau, việc sử dụng các mô hình được huấn luyện trước cho nhiệm vụ phân loại là không thể tránh khỏi. Kích thước của tất cả các mô hình là 12 lớp kích thước cơ bản. Các mô hình tăng cường Memoria tham chiếu 192 engram ngoài 512 bối cảnh.

Bảng 2 trình bày hiệu suất phân loại của các mô hình. Rõ ràng là các mô hình tăng cường Memoria cho thấy những cải thiện hiệu suất nổi bật so với BERT và RoBERTa thuần túy, mặc dù khó so sánh các mô hình hoàn toàn vì sự khác biệt trong huấn luyện trước. Memoria RoBERTa đạt được điểm số cao nhất trong tất cả các trường hợp. Tiến hành kiểm định t một đuôi, Memoria RoBERTa đã xác minh hiệu suất cao hơn một cách có ý nghĩa thống kê so với Longformer và Bigbird, với giá trị p lần lượt là 0.045 và 0.005.

6. Hiệu ứng bộ nhớ tâm lý học

Memoria được thiết kế dựa trên các mô hình bộ nhớ khác nhau của con người. Đặc biệt, bộ nhớ dài hạn của Memoria được thiết kế cố ý để duy trì thông tin cũ có giá trị, giống như con người. Do sự phức tạp của các diễn giải sinh học về cơ chế bộ nhớ con người, việc so sánh trực tiếp giữa Memoria và bộ nhớ con người là thách thức. Tuy nhiên, nghiên cứu về đặc điểm của bộ nhớ con người trong tâm lý học là rộng lớn. Do đó, bằng cách xác định các hiệu ứng đã biết của bộ nhớ con người trong Memoria, chúng tôi xác nhận sự tương đồng của nó với hệ thống bộ nhớ con người.

Hình 7 thể hiện các mẫu tương tự như hiệu ứng ưu tiên, hiệu ứng gần đây và hiệu ứng liền kề thời gian của các engram trong Memoria. Chúng tôi đã sử dụng Memoria Transformer để tiến hành suy luận trên toàn bộ tập kiểm tra của Wikitext-103, sau đó phân tích tuổi và trọng số nội bộ của các engram còn lại. Đồ thị trên minh họa mật độ theo thời điểm tạo engram. Các mô hình dựa trên bộ nhớ thông thường có xu hướng giữ thông tin gần đây, gây ra xu hướng tăng. Ngược lại, Memoria bảo tồn thông tin đầu và cuối nhiều hơn thông tin trung gian. Hành vi này thể hiện cả hiệu ứng ưu tiên và gần đây.

Hình dưới cho thấy mối quan hệ giữa sự khác biệt về tuổi giữa các engram còn lại và trọng số cạnh. Tuổi đại diện cho số bước thời gian đã trôi qua kể từ khi tạo, và sự khác biệt về tuổi tương ứng với sự khác biệt về thời gian tạo. Chúng tôi quan sát rằng các engram được tạo gần nhau về thời gian thể hiện trọng số kết nối nội bộ cao hơn, minh họa một mẫu tương tự như hiệu ứng liền kề thời gian.

7. Kết luận và Công việc tương lai
Chúng tôi đề xuất Memoria như một module bộ nhớ tổng quát cho các mạng nơ-ron, nhằm giải quyết vấn đề cơ bản của quên lãng định mệnh trong bộ nhớ dài hạn, cùng với các vấn đề phái sinh về tầm quan trọng dài hạn, bảo tồn có chọn lọc, kích hoạt dựa trên tín hiệu và tìm kiếm bộ nhớ. Các giải pháp cho những vấn đề này lấy cảm hứng từ hệ thống bộ nhớ con người, tích cực kết hợp các lý thuyết tâm lý học và khoa học thần kinh khác nhau liên quan đến bộ nhớ, bao gồm Mô hình Đa-kho (Atkinson & Shiffrin, 1968), SAM (Raaijmakers & Shiffrin, 1981), và lý thuyết Hebbian (Hebb, 1949). Phương pháp này cho phép Memoria phản ánh các hiệu ứng bộ nhớ con người khác nhau, bao gồm hiệu ứng gần đây, hiệu ứng ưu tiên và hiệu ứng liền kề thời gian. Chúng tôi chứng minh các hiệu ứng này thông qua phân tích đa dạng. Chúng tôi đã xác thực hiệu suất mạnh mẽ của Memoria so với các phương pháp khác trong các nhiệm vụ sắp xếp, mô hình hóa ngôn ngữ và phân loại.

Chúng tôi đã nỗ lực trang bị cho Memoria những đặc điểm mạnh mẽ của bộ nhớ con người. Tuy nhiên, vẫn còn tồn tại sự khác biệt ở nhiều khía cạnh. Lý thuyết về các mức độ xử lý (Craik & Lockhart, 1972) nhấn mạnh cấu trúc bộ nhớ liên tục hơn dựa trên độ sâu xử lý thay vì các danh mục rời rạc của mô hình Đa-kho. Ngoài ra, lý thuyết can thiệp (Underwood & Postman, 1960) nhấn mạnh tác động đáng kể của các hiệu ứng can thiệp giữa ký ức đã thiết lập và thông tin đến như một cơ chế quên lãng chủ yếu trong bộ nhớ dài hạn. Nghiên cứu tương lai của chúng tôi sẽ kết hợp các cơ chế này vào Memoria để căn chỉnh nó chặt chẽ hơn với các nguyên tắc hoạt động của bộ nhớ con người, tăng cường khả năng của nó tương ứng. Chúng tôi dự đoán sự tích hợp này sẽ giải phóng tiềm năng của Memoria trong các nhiệm vụ xử lý tuần tự đa dạng và dựa trên tác nhân, đặc biệt trong các lĩnh vực như chatbot hội thoại và mô phỏng học tăng cường, cuối cùng mở đường cho việc thực hiện trí tuệ ở mức độ con người.

Tuyên bố tác động
Bài báo này tìm cách tạo ra một module bộ nhớ ngoài được thiết kế cho các mạng nơ-ron nhân tạo để tăng cường khả năng xử lý cho dữ liệu chuỗi dài tổng quát. Việc phát triển Memoria dựa trên các lý thuyết liên quan đến bộ nhớ con người, có thể có các tác động xã hội khác nhau. Đáng chú ý, Memoria duy trì thông tin được tạo ra trong quá trình suy luận trong bộ nhớ dài hạn. Do đó, việc sử dụng lâu dài dữ liệu người dùng cụ thể cho suy luận mô hình có thể gây ra mối lo ngại về quyền riêng tư tiềm ẩn do sự tích lũy thông tin trong Memoria. Người dùng Memoria nên xem xét cẩn thận các quy định liên quan đến việc xử lý dữ liệu cá nhân.

Lời cảm ơn
Chúng tôi muốn cảm ơn các nhà đánh giá ẩn danh vì những câu hỏi và nhận xét hữu ích của họ. Dự án này được hỗ trợ một phần bởi Microsoft Research Asia. Nghiên cứu này được hỗ trợ một phần bởi Chương trình Phát triển Công nghệ Sinh học & Y học của Quỹ Nghiên cứu Quốc gia (NRF) được tài trợ bởi chính phủ Hàn Quốc (MSIT) (NRF-2021M3A9E4080780), Viện Lập kế hoạch & Đánh giá Công nghệ Thông tin & Truyền thông (IITP) tài trợ được tài trợ bởi chính phủ Hàn Quốc (MSIT) (IITP-2023-2020-0-018, khung suy luận quy nạp sử dụng omni-data để hiểu các mối quan hệ nhân quả phức tạp & chương trình ICT Creative Consilience và RS-2024-00398115, Nghiên cứu về độ tin cậy và sự nhất quán của kết quả được tạo ra bởi AI Tạo sinh).

Tài liệu tham khảo

[Phần tài liệu tham khảo được giữ nguyên với các định dạng citation và DOI như trong bản gốc]

# 2307.03172.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2307.03172.pdf
# Kích thước tệp: 747542 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Lạc trong Giữa: Cách Các Mô hình Ngôn ngữ Sử dụng Ngữ cảnh Dài
Nelson F. Liu1∗Kevin Lin2John Hewitt1Ashwin Paranjape3
Michele Bevilacqua3Fabio Petroni3Percy Liang1
1Đại học Stanford2Đại học California, Berkeley3Samaya AI
nfliu@cs.stanford.edu
Tóm tắt
Trong khi các mô hình ngôn ngữ gần đây có khả năng lấy ngữ cảnh dài làm đầu vào, tương đối ít người biết về mức độ sử dụng tốt ngữ cảnh dài hơn của chúng. Chúng tôi phân tích hiệu suất của các mô hình ngôn ngữ trên hai nhiệm vụ yêu cầu xác định thông tin liên quan trong ngữ cảnh đầu vào của chúng: trả lời câu hỏi đa tài liệu và truy xuất khóa-giá trị. Chúng tôi thấy rằng hiệu suất có thể suy giảm đáng kể khi thay đổi vị trí của thông tin liên quan, cho thấy các mô hình ngôn ngữ hiện tại không sử dụng thông tin trong ngữ cảnh đầu vào dài một cách mạnh mẽ. Đặc biệt, chúng tôi quan sát thấy hiệu suất thường cao nhất khi thông tin liên quan xuất hiện ở đầu hoặc cuối ngữ cảnh đầu vào, và suy giảm đáng kể khi các mô hình phải truy cập thông tin liên quan ở giữa ngữ cảnh dài, ngay cả đối với các mô hình ngữ cảnh dài một cách rõ ràng. Phân tích của chúng tôi cung cấp hiểu biết tốt hơn về cách các mô hình ngôn ngữ sử dụng ngữ cảnh đầu vào của chúng và cung cấp các giao thức đánh giá mới cho các mô hình ngôn ngữ ngữ cảnh dài trong tương lai.

1 Giới thiệu
Các mô hình ngôn ngữ đã trở thành một khối xây dựng quan trọng và linh hoạt trong nhiều công nghệ ngôn ngữ hướng người dùng, bao gồm giao diện đối화, tìm kiếm và tóm tắt, và viết hợp tác (Shuster và cộng sự, 2022; Thoppilan và cộng sự, 2022; Lee và cộng sự, 2022, cùng nhiều nghiên cứu khác). Các mô hình này thực hiện các nhiệm vụ hạ nguồn chủ yếu thông qua prompting: tất cả đặc tả nhiệm vụ liên quan và dữ liệu cần xử lý được định dạng như một ngữ cảnh đầu vào văn bản, và mô hình trả về một văn bản hoàn thành được tạo ra. Các ngữ cảnh đầu vào này có thể chứa hàng nghìn token, đặc biệt khi các mô hình ngôn ngữ được sử dụng để xử lý các tài liệu dài (ví dụ: tài liệu pháp lý hoặc khoa học, lịch sử đối thoại, v.v.) hoặc khi các mô hình ngôn ngữ được tăng cường với thông tin bên ngoài (ví dụ:

*Công việc hoàn thành một phần khi thực tập tại Samaya AI.

1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời5560657075Độ chính xác
20 Tổng số Tài liệu được Truy xuất (~4K token)
gpt-3.5-turbo-0613
gpt-3.5-turbo-0613 (closed-book)Hình 1: Thay đổi vị trí của thông tin liên quan (trong trường hợp này, vị trí của đoạn văn trả lời câu hỏi đầu vào) trong ngữ cảnh đầu vào của mô hình ngôn ngữ dẫn đến một đường cong hiệu suất hình chữ U—các mô hình tốt hơn trong việc sử dụng thông tin liên quan xảy ra ở đầu (thiên lệch ưu tiên) hoặc cuối ngữ cảnh đầu vào của nó (thiên lệch gần đây), và hiệu suất suy giảm đáng kể khi các mô hình phải truy cập và sử dụng thông tin nằm ở giữa ngữ cảnh đầu vào của nó.

các tài liệu liên quan từ công cụ tìm kiếm, kết quả truy vấn cơ sở dữ liệu, v.v; Petroni và cộng sự, 2020; Ram và cộng sự, 2023; Shi và cộng sự, 2023; Mallen và cộng sự, 2023; Schick và cộng sự, 2023, cùng nhiều nghiên cứu khác).

Xử lý các trường hợp sử dụng này yêu cầu các mô hình ngôn ngữ hoạt động thành công trên các chuỗi dài. Các mô hình ngôn ngữ hiện có thường được triển khai với Transformers (Vaswani và cộng sự, 2017), đòi hỏi bộ nhớ và tính toán tăng theo bình phương với độ dài chuỗi. Kết quả là, các mô hình ngôn ngữ Transformer thường được huấn luyện với cửa sổ ngữ cảnh tương đối nhỏ (giữa 512-2048 token). Những cải tiến gần đây về phần cứng (ví dụ: GPU nhanh hơn với nhiều bộ nhớ hơn) và thuật toán (Dai và cộng sự, 2019; Dao và cộng sự, 2022; Poli và cộng sự,arXiv:2307.03172v3 [cs.CL] 20 Nov 2023

--- TRANG 2 ---
2023; Rubin và Berant, 2023, cùng nhiều nghiên cứu khác) đã dẫn đến các mô hình ngôn ngữ có cửa sổ ngữ cảnh lớn hơn (ví dụ: 4096, 32K, và thậm chí 100K token), nhưng vẫn chưa rõ các mô hình ngôn ngữ ngữ cảnh mở rộng này sử dụng ngữ cảnh đầu vào của chúng như thế nào khi thực hiện các nhiệm vụ hạ nguồn.

Chúng tôi điều tra câu hỏi này một cách thực nghiệm thông qua các thí nghiệm được kiểm soát với nhiều mô hình ngôn ngữ tiên tiến mở (MPT-30B-Instruct, LongChat-13B (16K)) và đóng (GPT-3.5-Turbo của OpenAI và Claude-1.3 của Anthropic) trong các cài đặt yêu cầu truy cập và sử dụng thông tin trong ngữ cảnh đầu vào. Đặc biệt, các thí nghiệm của chúng tôi thực hiện các thay đổi được kiểm soát đối với kích thước ngữ cảnh đầu vào và vị trí của thông tin liên quan trong ngữ cảnh đầu vào và nghiên cứu tác động của chúng đến hiệu suất mô hình ngôn ngữ. Nếu các mô hình ngôn ngữ có thể sử dụng thông tin trong ngữ cảnh đầu vào dài một cách mạnh mẽ, thì hiệu suất của chúng nên bị ảnh hưởng tối thiểu bởi vị trí của thông tin liên quan trong ngữ cảnh đầu vào.

Đầu tiên chúng tôi thí nghiệm với trả lời câu hỏi đa tài liệu, yêu cầu các mô hình suy luận trên các tài liệu được cung cấp để tìm thông tin liên quan và sử dụng nó để trả lời một câu hỏi đã cho; nhiệm vụ này mô phỏng thiết lập tạo tăng cường truy xuất làm nền tảng cho nhiều ứng dụng tìm kiếm tạo sinh và trả lời câu hỏi thương mại (ví dụ: Bing Chat). Trong cài đặt này, chúng tôi kiểm soát (i) độ dài ngữ cảnh đầu vào bằng cách thay đổi số lượng tài liệu trong ngữ cảnh đầu vào (tương tự như truy xuất nhiều hoặc ít tài liệu hơn trong tạo tăng cường truy xuất), và (ii) kiểm soát vị trí của thông tin liên quan trong ngữ cảnh đầu vào bằng cách thay đổi thứ tự các tài liệu để đặt tài liệu liên quan ở đầu, giữa hoặc cuối ngữ cảnh.

Chúng tôi thấy rằng thay đổi vị trí của thông tin liên quan trong ngữ cảnh đầu vào có thể ảnh hưởng đáng kể đến hiệu suất mô hình, cho thấy các mô hình ngôn ngữ hiện tại không truy cập và sử dụng thông tin trong ngữ cảnh đầu vào dài một cách mạnh mẽ. Hơn nữa, chúng tôi quan sát một đường cong hiệu suất hình chữ U đặc biệt (Hình 1); hiệu suất mô hình ngôn ngữ cao nhất khi thông tin liên quan xuất hiện ở đầu (thiên lệch ưu tiên) hoặc cuối ngữ cảnh đầu vào của nó (thiên lệch gần đây), và hiệu suất suy giảm đáng kể khi các mô hình phải truy cập và sử dụng thông tin ở giữa ngữ cảnh đầu vào của chúng (§2.3). Ví dụ, khi thông tin liên quan được đặt ở giữa ngữ cảnh đầu vào của nó, hiệu suất của GPT-3.5-Turbo trên nhiệm vụ câu hỏi đa tài liệu thấp hơn hiệu suất của nó khi dự đoán mà không có bất kỳ tài liệu nào (tức là cài đặt closed-book; 56.1%). Hơn nữa, chúng tôi thấy rằng các mô hình thường có hiệu suất giống hệt với các đối tác ngữ cảnh mở rộng của chúng, cho thấy các mô hình ngữ cảnh mở rộng không nhất thiết tốt hơn trong việc sử dụng ngữ cảnh đầu vào của chúng (§2.3).

Cho rằng các mô hình ngôn ngữ gặp khó khăn trong việc truy xuất và sử dụng thông tin liên quan trong nhiệm vụ trả lời câu hỏi đa tài liệu, ở mức độ nào các mô hình ngôn ngữ thậm chí có thể truy xuất từ ngữ cảnh đầu vào của chúng? Chúng tôi nghiên cứu câu hỏi này với một nhiệm vụ truy xuất khóa-giá trị tổng hợp, được thiết kế để trở thành một testbed tối thiểu cho khả năng cơ bản truy xuất các token khớp từ ngữ cảnh đầu vào. Trong nhiệm vụ này, các mô hình được cung cấp một tập hợp các cặp khóa-giá trị định dạng JSON và phải trả về giá trị liên quan với một khóa cụ thể. Tương tự như nhiệm vụ QA đa tài liệu, nhiệm vụ truy xuất khóa-giá trị cho phép thay đổi được kiểm soát đối với độ dài ngữ cảnh đầu vào (thêm nhiều cặp khóa-giá trị hơn) và vị trí của thông tin liên quan. Mặc dù một số mô hình thực hiện nhiệm vụ truy xuất khóa-giá trị tổng hợp một cách hoàn hảo, các mô hình khác gặp khó khăn trong việc đơn giản truy xuất các token khớp xuất hiện ở giữa ngữ cảnh đầu vào của chúng và tiếp tục thể hiện đường cong hiệu suất hình chữ U.

Để hiểu rõ hơn tại sao các mô hình ngôn ngữ gặp khó khăn trong việc truy cập và sử dụng thông tin trong ngữ cảnh đầu vào của chúng một cách mạnh mẽ, chúng tôi nghiên cứu vai trò của kiến trúc mô hình (decoder-only so với encoder-decoder), ngữ cảnh hóa nhận biết truy vấn, và tinh chỉnh hướng dẫn (§4). Chúng tôi thấy rằng:

•Các mô hình encoder-decoder tương đối mạnh mẽ trước những thay đổi trong vị trí của thông tin liên quan trong ngữ cảnh đầu vào của chúng, nhưng chỉ khi được đánh giá trên các chuỗi trong độ dài chuỗi thời gian huấn luyện của nó. Khi được đánh giá trên các chuỗi dài hơn những gì nhìn thấy trong quá trình huấn luyện, chúng tôi quan sát một đường cong hiệu suất hình chữ U (§4.1).

•Ngữ cảnh hóa nhận biết truy vấn (đặt truy vấn trước và sau các tài liệu hoặc cặp khóa-giá trị) cho phép hiệu suất gần hoàn hảo trên nhiệm vụ khóa-giá trị tổng hợp, nhưng thay đổi tối thiểu xu hướng trong QA đa tài liệu (§4.2).

•Ngay cả các mô hình ngôn ngữ cơ sở (tức là không có tinh chỉnh hướng dẫn) cũng cho thấy đường cong hiệu suất hình chữ U khi chúng tôi thay đổi vị trí của thông tin liên quan trong ngữ cảnh đầu vào.

Kết quả của chúng tôi cho thấy rằng việc prompting các mô hình

--- TRANG 3 ---
ngôn ngữ với ngữ cảnh đầu vào dài hơn là một sự đánh đổi—cung cấp cho mô hình ngôn ngữ nhiều thông tin hơn có thể giúp nó thực hiện nhiệm vụ hạ nguồn, nhưng nó cũng tăng lượng nội dung mà mô hình phải suy luận, có khả năng giảm độ chính xác. Để hiểu rõ hơn sự đánh đổi này trong thực tế, chúng tôi thực hiện một nghiên cứu trường hợp với các mô hình retriever-reader trên trả lời câu hỏi miền mở (§5). Trái ngược với nhiệm vụ QA đa tài liệu được kiểm soát của chúng tôi, nơi ngữ cảnh luôn chứa chính xác một tài liệu trả lời câu hỏi, không có hoặc nhiều trong số k tài liệu hàng đầu có thể chứa câu trả lời trong cài đặt QA miền mở. Khi truy xuất từ Wikipedia để trả lời các truy vấn từ NaturalQuestions-Open, chúng tôi thấy rằng hiệu suất mô hình bão hòa trước khi recall của retriever bão hòa, cho thấy các mô hình hiện tại không sử dụng hiệu quả các tài liệu được truy xuất bổ sung—sử dụng 50 tài liệu thay vì 20 tài liệu được truy xuất chỉ cải thiện hiệu suất một cách cận biên (~1.5% cho GPT-3.5-Turbo và ~1% cho claude-1.3).

Phân tích của chúng tôi cung cấp hiểu biết tốt hơn về cách các mô hình ngôn ngữ sử dụng ngữ cảnh đầu vào của chúng và giới thiệu các giao thức đánh giá mới cho các mô hình ngữ cảnh dài trong tương lai; để tuyên bố rằng một mô hình ngôn ngữ có thể sử dụng thông tin trong ngữ cảnh đầu vào dài một cách mạnh mẽ, cần thiết phải chỉ ra rằng hiệu suất của nó bị ảnh hưởng tối thiểu bởi vị trí của thông tin liên quan trong ngữ cảnh đầu vào (ví dụ: sự khác biệt tối thiểu trong hiệu suất trường hợp tốt nhất và tệ nhất).

Để tạo điều kiện cho công việc tiếp theo về hiểu và cải thiện cách các mô hình ngôn ngữ sử dụng ngữ cảnh đầu vào của chúng, chúng tôi phát hành mã và dữ liệu đánh giá của mình.1

2 Trả lời Câu hỏi Đa Tài liệu

Mục tiêu của chúng tôi là hiểu rõ hơn cách các mô hình ngôn ngữ sử dụng ngữ cảnh đầu vào của chúng. Để đạt mục đích này, chúng tôi phân tích hiệu suất mô hình trên trả lời câu hỏi đa tài liệu, yêu cầu các mô hình tìm thông tin liên quan trong ngữ cảnh đầu vào và sử dụng nó để trả lời câu hỏi. Đặc biệt, chúng tôi thực hiện các thay đổi được kiểm soát đối với độ dài của ngữ cảnh đầu vào và vị trí của thông tin liên quan và đo lường những thay đổi trong hiệu suất nhiệm vụ.

2.1 Thiết lập Thí nghiệm

Trong nhiệm vụ trả lời câu hỏi đa tài liệu, các đầu vào của mô hình là (i) một câu hỏi cần trả lời và (ii) k tài liệu (ví dụ: các đoạn văn từ Wikipedia), trong đó chính xác một trong số các tài liệu chứa câu trả lời cho câu hỏi và k−1 tài liệu "gây nhiễu" thì không. Nhiệm vụ này yêu cầu mô hình truy cập tài liệu chứa câu trả lời trong ngữ cảnh đầu vào của nó và sử dụng nó để trả lời câu hỏi. Hình 2 trình bày một ví dụ.

Chúng tôi triển khai nhiệm vụ này với dữ liệu từ NaturalQuestions-Open (Lee và cộng sự, 2019; Kwiatkowski và cộng sự, 2019), chứa các truy vấn lịch sử được gửi đến công cụ tìm kiếm Google, kết hợp với các câu trả lời được chú thích bởi con người được trích xuất từ Wikipedia. Đặc biệt, chúng tôi lấy 2655 truy vấn mà câu trả lời dài được chú thích là một đoạn văn (trái ngược với danh sách hoặc bảng). Chúng tôi sử dụng các đoạn văn (các đoạn tối đa 100 token) từ Wikipedia làm tài liệu trong ngữ cảnh đầu vào của chúng tôi.

Đối với mỗi truy vấn, chúng tôi cần một tài liệu chứa câu trả lời và k−1 tài liệu gây nhiễu không chứa câu trả lời. Để có được một tài liệu trả lời câu hỏi, chúng tôi sử dụng đoạn văn Wikipedia chứa câu trả lời từ các chú thích NaturalQuestions. Để thu thập k−1 tài liệu gây nhiễu không chứa câu trả lời, chúng tôi sử dụng một hệ thống truy xuất (Contriever, được tinh chỉnh trên MS-MARCO; Izacard và cộng sự, 2021) để truy xuất k−1 đoạn Wikipedia liên quan nhất với truy vấn và không chứa bất kỳ câu trả lời được chú thích NaturalQuestions nào.2,3 Trong ngữ cảnh đầu vào, các tài liệu gây nhiễu được trình bày theo thứ tự giảm dần mức độ liên quan.4

Để điều chỉnh vị trí của thông tin liên quan trong ngữ cảnh đầu vào, chúng tôi điều chỉnh thứ tự của các tài liệu để thay đổi vị trí của tài liệu chứa câu trả lời (Hình 3). Để điều chỉnh độ dài ngữ cảnh đầu vào trong nhiệm vụ này, chúng tôi tăng hoặc giảm số lượng tài liệu được truy xuất không chứa câu trả lời (Hình 4).

Theo Kandpal và cộng sự (2022) và Mallen và cộng sự (2023), chúng tôi sử dụng độ chính xác làm chỉ số đánh giá chính, đánh giá liệu có bất kỳ câu trả lời đúng nào (được lấy từ các chú thích NaturalQuestions) xuất hiện trong đầu ra dự đoán hay không.

1nelsonliu.me/papers/lost-in-the-middle

2Sự mơ hồ trong NaturalQuestions-Open có nghĩa là một số lượng nhỏ đoạn văn gây nhiễu có thể chứa một câu trả lời hợp lý. Chúng tôi cũng chạy thí nghiệm trên tập con các câu hỏi không mơ hồ, tìm thấy kết quả và kết luận tương tự; xem Phụ lục A.

3Chúng tôi cũng khám phá việc sử dụng các tài liệu ngẫu nhiên làm gây nhiễu, xem Phụ lục B để biết thêm chi tiết.

4Vì có thể có một prior về "kết quả tìm kiếm" xuất hiện theo thứ tự được xếp hạng, chúng tôi đã khám phá việc sắp xếp ngẫu nhiên k−1 tài liệu gây nhiễu và đề cập rằng các tài liệu được sắp xếp ngẫu nhiên trong mô tả nhiệm vụ, nhưng thấy cùng xu hướng. Xem Phụ lục C để biết thêm chi tiết.

--- TRANG 4 ---
Viết một câu trả lời chất lượng cao cho câu hỏi đã cho chỉ sử dụng các kết quả tìm kiếm được cung cấp (một số trong đó có thể không liên quan).
Tài liệu [1](Tiêu đề: Người Mỹ gốc Á trong khoa học và công nghệ) Giải thưởng vật lý cho việc khám phá hạt hạ nguyên tử J/ψ. Subrahmanyan Chandrasekhar đã chia sẻ...
Tài liệu [2](Tiêu đề: Danh sách người đoạt giải Nobel Vật lý) Giải Nobel Vật lý đầu tiên được trao vào năm 1901 cho Wilhelm Conrad Röntgen, người Đức, người đã nhận...
Tài liệu [3](Tiêu đề: Nhà khoa học) và được theo đuổi thông qua một phương pháp độc đáo, về cơ bản đã có sẵn. Ramón y Cajal đã giành giải Nobel năm 1906 cho những phát hiện đáng chú ý của mình...
Câu hỏi: ai đã nhận giải nobel vật lý đầu tiên
Câu trả lời: Ngữ cảnh Đầu vào
Wilhelm Conrad Röntgen Câu trả lời Mong muốn Hình 2: Ví dụ về nhiệm vụ trả lời câu hỏi đa tài liệu, với ngữ cảnh đầu vào và câu trả lời mô hình mong muốn. Tài liệu chứa câu trả lời được in đậm trong ngữ cảnh đầu vào ở đây để rõ ràng.

Viết một câu trả lời chất lượng cao cho câu hỏi đã cho chỉ sử dụng các kết quả tìm kiếm được cung cấp (một số trong đó có thể không liên quan).
Tài liệu [1](Tiêu đề: Danh sách người đoạt giải Nobel Vật lý) ...
Tài liệu [2](Tiêu đề: Người Mỹ gốc Á trong khoa học và công nghệ) ...
Tài liệu [3](Tiêu đề: Nhà khoa học) ...
Câu hỏi: ai đã nhận giải nobel vật lý đầu tiên
Câu trả lời: Ngữ cảnh Đầu vào
Wilhelm Conrad Röntgen Câu trả lời Mong muốn

Hình 3: Điều chỉnh vị trí của thông tin liên quan trong ngữ cảnh đầu vào cho ví dụ trả lời câu hỏi đa tài liệu được trình bày trong Hình 2. Sắp xếp lại các tài liệu trong ngữ cảnh đầu vào không ảnh hưởng đến đầu ra mong muốn.

Thiết lập thí nghiệm của chúng tôi tương tự với các thí nghiệm needle-in-a-haystack của Ivgi và cộng sự (2023), những người so sánh hiệu suất trả lời câu hỏi khi đoạn văn liên quan được đặt (i) ở đầu đầu vào hoặc (ii) một vị trí ngẫu nhiên trong đầu vào. Họ thấy rằng các mô hình encoder-decoder có hiệu suất cao hơn đáng kể khi thông tin liên quan được đặt ở đầu ngữ cảnh đầu vào. Ngược lại, chúng tôi nghiên cứu những thay đổi chi tiết hơn trong vị trí của thông tin liên quan.

2.2 Các Mô hình

Chúng tôi phân tích một số mô hình ngôn ngữ mở và đóng tiên tiến. Chúng tôi sử dụng giải mã tham lam khi tạo đầu ra và để việc khám phá các phương pháp giải mã khác cho công việc tương lai. Chúng tôi sử dụng một bộ prompt tiêu chuẩn cho mỗi mô hình (Hình 2).

Viết một câu trả lời chất lượng cao cho câu hỏi đã cho chỉ sử dụng các kết quả tìm kiếm được cung cấp (một số trong đó có thể không liên quan).
Tài liệu [1](Tiêu đề: Người Mỹ gốc Á trong khoa học và công nghệ) ...
Tài liệu [2](Tiêu đề: Danh sách người đoạt giải Nobel Vật lý) ...
Tài liệu [3](Tiêu đề: Nhà khoa học) ...
Tài liệu [4](Tiêu đề: Người Mỹ gốc Na Uy) ...
Tài liệu [5](Tiêu đề: Maria Goeppert Mayer) ...
Câu hỏi: ai đã nhận giải nobel vật lý đầu tiên
Câu trả lời: Ngữ cảnh Đầu vào Ngữ cảnh Đầu vào
Wilhelm Conrad Röntgen Câu trả lời Mong muốn Hình 4: Điều chỉnh độ dài ngữ cảnh đầu vào của ví dụ trả lời câu hỏi đa tài liệu được trình bày trong Hình 2. Thêm các tài liệu không chứa câu trả lời tăng độ dài của ngữ cảnh đầu vào, nhưng không ảnh hưởng đến đầu ra mong muốn.

Các mô hình mở. Chúng tôi thí nghiệm với MPT-30B-Instruct, có độ dài ngữ cảnh tối đa 8192 token. Mô hình ban đầu được pre-train trên 1 nghìn tỷ token sử dụng các chuỗi 2048-token, sau đó là một giai đoạn pre-training thích ứng độ dài chuỗi bổ sung trên 50 tỷ token sử dụng các chuỗi 8192-token. MPT-30B-Instruct sử dụng ALiBi (Press và cộng sự, 2022) để biểu diễn thông tin vị trí. Chúng tôi cũng đánh giá LongChat-13B (16K) (Li và cộng sự, 2023), mở rộng cửa sổ ngữ cảnh LLaMA-13B (Touvron và cộng sự, 2023a) từ 2048 đến 16384 token bằng cách sử dụng embedding vị trí quay được nén trước khi tinh chỉnh với các chuỗi 16384-token.

Các mô hình đóng. Chúng tôi sử dụng API OpenAI để thí nghiệm với GPT-3.5-Turbo và GPT-3.5-Turbo

--- TRANG 5 ---
1st 5th 10th
Vị trí của Tài liệu có Câu trả lời505560657075Độ chính xác
10 Tổng số Tài liệu được Truy xuất (~2K token)
1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời505560657075Độ chính xác
20 Tổng số Tài liệu được Truy xuất (~4K token)
1st 5th 10th 15th 20th 25th 30th
Vị trí của Tài liệu có Câu trả lời505560657075Độ chính xác
30 Tổng số Tài liệu được Truy xuất (~6K token)
claude-1.3 claude-1.3-100k gpt-3.5-turbo-0613 gpt-3.5-turbo-16k-0613 mpt-30b-instruct longchat-13b-16kHình 5: Tác động của việc thay đổi vị trí của thông tin liên quan (tài liệu chứa câu trả lời) đến hiệu suất trả lời câu hỏi đa tài liệu. Vị trí thấp hơn gần với đầu ngữ cảnh đầu vào hơn. Hiệu suất cao nhất khi thông tin liên quan xuất hiện ở đầu hoặc cuối ngữ cảnh, và suy giảm nhanh chóng khi các mô hình phải suy luận trên thông tin ở giữa ngữ cảnh đầu vào của chúng.

(16K).5GPT-3.5-Turbo có độ dài ngữ cảnh tối đa 4K token, và GPT-3.5-Turbo (16K) là một phiên bản với độ dài ngữ cảnh tối đa mở rộng 16K token. Chúng tôi đánh giá Claude-1.3 và Claude-1.3 (100K) với API Anthropic; Claude-1.3 có độ dài ngữ cảnh tối đa 8K token, và Claude-1.3 (100K) có độ dài ngữ cảnh mở rộng 100K token.6

2.3 Kết quả và Thảo luận

Chúng tôi thí nghiệm với ngữ cảnh đầu vào chứa 10, 20, và 30 tổng số tài liệu. Hình 5 trình bày hiệu suất trả lời câu hỏi đa tài liệu khi thay đổi vị trí của thông tin liên quan trong ngữ cảnh đầu vào. Để bối cảnh hóa hiệu suất mô hình, chúng tôi cũng đánh giá trên các cài đặt closed-book và oracle (Bảng 1). Trong cài đặt closed-book, các mô hình không được cung cấp bất kỳ tài liệu nào trong ngữ cảnh đầu vào của chúng, và phải dựa vào bộ nhớ tham số của chúng để tạo ra câu trả lời đúng. Mặt khác, trong cài đặt oracle, các mô hình ngôn ngữ được cung cấp một tài liệu duy nhất chứa câu trả lời và phải sử dụng nó để trả lời câu hỏi.

Hiệu suất mô hình cao nhất khi thông tin liên quan xuất hiện ở đầu hoặc cuối ngữ cảnh đầu vào của nó. Như được minh họa trong Hình 5, việc thay đổi vị trí của thông tin liên quan trong ngữ cảnh đầu vào dẫn đến giảm đáng kể hiệu suất mô hình. Đặc biệt, chúng tôi thấy một đường cong hiệu suất hình chữ U đặc biệt—các mô hình thường tốt hơn nhiều trong việc sử dụng thông tin liên quan xuất hiện ở đầu (thiên lệch ưu tiên) và cuối ngữ cảnh (thiên lệch gần đây), và bị suy giảm hiệu suất khi buộc phải sử dụng thông tin trong giữa ngữ cảnh đầu vào của nó. Ví dụ, hiệu suất QA đa tài liệu của GPT-3.5-Turbo có thể giảm hơn 20%—trong trường hợp tệ nhất, hiệu suất trong cài đặt 20- và 30-tài liệu thấp hơn hiệu suất mà không có bất kỳ tài liệu đầu vào nào (tức là hiệu suất closed-book; 56.1%). Những kết quả này cho thấy các mô hình hiện tại không thể suy luận hiệu quả trên toàn bộ cửa sổ ngữ cảnh của chúng khi được prompt cho các nhiệm vụ hạ nguồn.

5Chúng tôi sử dụng các phiên bản mô hình OpenAI 0613.
6Chúng tôi cũng đánh giá GPT-4 (8K) trên một tập con của các thí nghiệm QA đa tài liệu, tìm thấy kết quả và xu hướng tương tự như các mô hình khác (mặc dù GPT-4 có hiệu suất tuyệt đối cao hơn). Đánh giá GPT-4 trên toàn bộ các thí nghiệm QA đa tài liệu và truy xuất khóa-giá trị sẽ tiêu tốn hơn $6000. Xem Phụ lục D cho kết quả và thảo luận GPT-4.

Mô hình Closed-Book Oracle
LongChat-13B (16K) 35.0% 83.4%
MPT-30B-Instruct 31.5% 81.9%
GPT-3.5-Turbo 56.1% 88.3%
GPT-3.5-Turbo (16K) 56.0% 88.6%
Claude-1.3 48.3% 76.1%
Claude-1.3 (100K) 48.2% 76.4%
Bảng 1: Độ chính xác closed-book và oracle của các mô hình ngôn ngữ trên nhiệm vụ trả lời câu hỏi đa tài liệu.

Các mô hình ngữ cảnh mở rộng không nhất thiết tốt hơn trong việc sử dụng ngữ cảnh đầu vào. Khi ngữ cảnh đầu vào vừa với cửa sổ ngữ cảnh của cả mô hình và đối tác ngữ cảnh mở rộng của nó, chúng tôi thấy rằng hiệu suất giữa chúng gần như giống hệt nhau. Ví dụ, các cài đặt 10- và 20-tài liệu đều vừa trong cửa sổ ngữ cảnh của GPT-3.5-Turbo và GPT-3.5-Turbo (16K), và chúng tôi quan sát rằng hiệu suất của chúng như một hàm của vị trí thông tin tương đối gần như chồng lên nhau (chuỗi tím đậm và nâu đứt nét trong Hình 5). Những kết quả này

--- TRANG 6 ---
Trích xuất giá trị tương ứng với khóa được chỉ định trong đối tượng JSON dưới đây.
Dữ liệu JSON:
{"2a8d601d-1d69-4e64-9f90-8ad825a74195": "bb3ba2a5-7de8-434b-a86e-a88bb9fa7289",
 "a54e2eed-e625-4570-9f74-3624e77d6684": "d1ff29be-4e2a-4208-a182-0cea716be3d4",
 "9f4a92b9-5f69-4725-ba1e-403f08dea695 ": "703a7ce5-f17f-4e6d-b895-5836ba5ec71c",
 "52a9c80c-da51-4fc9-bf70-4a4901bc2ac3": "b2f8ea3d-4b1b-49e0-a141-b9823991ebeb",
 "f4eb1c53-af0a-4dc4-a3a5-c2d50851a178": "d733b0d2-6af3-44e1-8592-e5637fdb76fb"}
Khóa: " 9f4a92b9-5f69-4725-ba1e-403f08dea695 "
Giá trị tương ứng: Ngữ cảnh Đầu vào
703a7ce5-f17f-4e6d-b895-5836ba5ec71c Đầu ra Mong muốn Hình 6: Ví dụ về nhiệm vụ truy xuất khóa-giá trị, với ngữ cảnh đầu vào và đầu ra mô hình mong muốn. Cho một khóa, mục tiêu là trả về giá trị liên quan. Tất cả các khóa và giá trị đều là UUID 128-bit. Cặp khóa-giá trị liên quan để trả lời truy vấn được in đậm ở đây trong ngữ cảnh đầu vào để rõ ràng.

cho thấy các mô hình ngữ cảnh mở rộng không nhất thiết tốt hơn các đối tác không mở rộng của chúng trong việc sử dụng ngữ cảnh đầu vào của chúng.

3 Các Mô hình Ngôn ngữ Có thể Truy xuất Tốt như thế nào Từ Ngữ cảnh Đầu vào?

Cho rằng các mô hình ngôn ngữ gặp khó khăn trong việc truy xuất và sử dụng thông tin từ giữa ngữ cảnh đầu vào của chúng trong nhiệm vụ trả lời câu hỏi đa tài liệu, ở mức độ nào chúng có thể đơn giản truy xuất từ ngữ cảnh đầu vào? Chúng tôi nghiên cứu câu hỏi này với một nhiệm vụ truy xuất khóa-giá trị tổng hợp, được thiết kế để cung cấp một testbed tối thiểu cho khả năng cơ bản truy xuất các token khớp từ ngữ cảnh đầu vào.

3.1 Thiết lập Thí nghiệm

Trong nhiệm vụ truy xuất khóa-giá trị tổng hợp của chúng tôi, các đầu vào là (i) một đối tượng JSON được tuần tự hóa chuỗi với k cặp khóa-giá trị, trong đó mỗi khóa và giá trị đều là các UUID được tạo ngẫu nhiên duy nhất và (ii) một khóa trong đối tượng JSON nói trên. Mục tiêu là trả về giá trị liên quan với khóa được chỉ định. Do đó, mỗi đối tượng JSON chứa một cặp khóa-giá trị liên quan (trong đó giá trị sẽ được trả về), và k−1 cặp khóa-giá trị "gây nhiễu" không liên quan. Hình 6 cung cấp một ví dụ ngữ cảnh đầu vào và đầu ra mong muốn tương ứng. Chúng tôi lại đo lường độ chính xác bằng cách đánh giá liệu giá trị đúng có xuất hiện trong đầu ra dự đoán hay không.

Nhiệm vụ truy xuất khóa-giá trị tổng hợp của chúng tôi có chung mục tiêu tương tự với Little Retrieval Test của Papailiopoulos và cộng sự (2023) và nhiệm vụ truy xuất dòng chi tiết của Li và cộng sự (2023), nhưng chúng tôi tìm cách cất cánh và đơn giản hóa nhiệm vụ bằng cách loại bỏ càng nhiều ngữ nghĩa ngôn ngữ tự nhiên càng tốt (sử dụng UUID ngẫu nhiên thay thế), vì các tính năng ngôn ngữ có thể trình bày các yếu tố gây nhiễu tiềm năng. Ví dụ, các mô hình ngôn ngữ Transformer có thể có độ nhạy khác nhau đối với các tính năng ngôn ngữ khác nhau trong đầu vào của chúng (O'Connor và Andreas, 2021).

Để điều chỉnh vị trí của thông tin liên quan trong ngữ cảnh đầu vào, chúng tôi thay đổi vị trí của khóa cần truy xuất trong đối tượng JSON được tuần tự hóa. Để điều chỉnh độ dài ngữ cảnh đầu vào, chúng tôi thay đổi số lượng cặp khóa-giá trị JSON đầu vào k bằng cách thêm hoặc loại bỏ các khóa ngẫu nhiên, thay đổi số lượng cặp khóa-giá trị gây nhiễu.

3.2 Kết quả và Thảo luận

Chúng tôi thí nghiệm với ngữ cảnh đầu vào chứa 75, 140, và 300 cặp khóa-giá trị (500 ví dụ mỗi loại). Chúng tôi sử dụng cùng bộ mô hình như các thí nghiệm trả lời câu hỏi đa tài liệu, xem §2.2 để biết thêm chi tiết.

Hình 7 trình bày hiệu suất truy xuất khóa-giá trị. Claude-1.3 và Claude-1.3 (100K) làm gần như hoàn hảo trên tất cả độ dài ngữ cảnh đầu vào được đánh giá, nhưng các mô hình khác gặp khó khăn, đặc biệt khi ngữ cảnh có 140 hoặc 300 cặp khóa-giá trị—mặc dù nhiệm vụ truy xuất khóa-giá trị tổng hợp chỉ yêu cầu xác định khớp chính xác trong ngữ cảnh đầu vào, không phải tất cả các mô hình đều đạt hiệu suất cao. Tương tự như kết quả QA đa tài liệu của chúng tôi, GPT-3.5-Turbo, GPT-3.5-Turbo (16K), và MPT-30B-Instruct có hiệu suất thấp nhất khi chúng phải truy cập các cặp khóa-giá trị ở giữa ngữ cảnh đầu vào của chúng. LongChat-13B (16K) thể hiện xu hướng khác trong cài đặt 140 khóa-giá trị; chúng tôi quan sát định tính rằng khi thông tin liên quan được

--- TRANG 7 ---
1st 25th 50th 75th
Vị trí của Khóa cần Truy xuất405060708090100Độ chính xác
75 Cặp Khóa-Giá trị (~4K token)
1st 35th 70th 105th 140th
Vị trí của Khóa cần Truy xuất405060708090100Độ chính xác
140 Cặp Khóa-Giá trị (~8K token)
1st 50th 100th 150th 200th 250th 300th
Vị trí của Khóa cần Truy xuất405060708090100Độ chính xác
300 Cặp Khóa-Giá trị (~16K token)
claude-1.3 claude-1.3-100k gpt-3.5-turbo-0613 gpt-3.5-turbo-16k-0613 mpt-30b-instruct longchat-13b-16kHình 7: Tác động của việc thay đổi độ dài ngữ cảnh đầu vào và vị trí của thông tin liên quan đến hiệu suất truy xuất khóa-giá trị. Vị trí thấp hơn gần với đầu ngữ cảnh đầu vào hơn. Mặc dù một số mô hình cho thấy độ chính xác hoàn hảo trên nhiệm vụ tổng hợp này (ví dụ: Claude-1.3 và Claude-1.3 (100K)), chúng ta thấy lại rằng hiệu suất thường cao nhất khi thông tin liên quan xuất hiện ở đầu hoặc cuối ngữ cảnh, và suy giảm nhanh chóng khi các mô hình phải truy xuất từ giữa ngữ cảnh đầu vào.

đặt ở đầu ngữ cảnh đầu vào, LongChat-13B (16K) có xu hướng tạo code để truy xuất khóa, thay vì xuất ra giá trị trực tiếp.

4 Tại sao Các Mô hình Ngôn ngữ Không Mạnh mẽ trước Những thay đổi trong Vị trí của Thông tin Liên quan?

Kết quả trả lời câu hỏi đa tài liệu và truy xuất khóa-giá trị của chúng tôi cho thấy các mô hình ngôn ngữ gặp khó khăn trong việc truy cập và sử dụng thông tin trong ngữ cảnh đầu vào dài một cách mạnh mẽ, vì hiệu suất suy giảm đáng kể khi thay đổi vị trí của thông tin liên quan. Để hiểu rõ hơn tại sao, chúng tôi thực hiện một số điều tra sơ bộ về vai trò của kiến trúc mô hình (decoder-only so với encoder-decoder), ngữ cảnh hóa nhận biết truy vấn, và tinh chỉnh hướng dẫn.

4.1 Tác động của Kiến trúc Mô hình

Các mô hình mở mà chúng tôi đánh giá đều là các mô hình decoder-only—tại mỗi timestep, chúng chỉ có thể attend đến các token trước đó. Để hiểu rõ hơn các tác động tiềm năng của kiến trúc mô hình đối với cách mô hình ngôn ngữ sử dụng ngữ cảnh, chúng tôi so sánh các mô hình ngôn ngữ decoder-only và encoder-decoder.

Chúng tôi thí nghiệm với Flan-T5-XXL (Raffel và cộng sự, 2020; Chung và cộng sự, 2022) và Flan-UL2 (Tay và cộng sự, 2023). Flan-T5-XXL được huấn luyện với các chuỗi 512 token (encoder và decoder). Flan-UL2 ban đầu được huấn luyện với các chuỗi 512 token (encoder và decoder), nhưng sau đó được pre-train thêm 100K bước với 1024 token (encoder và decoder) trước khi tinh chỉnh hướng dẫn trên các chuỗi với 2048 token trong encoder và 512 token trong decoder. Tuy nhiên, vì các mô hình này sử dụng embedding vị trí tương đối, chúng có thể (về nguyên tắc) ngoại suy vượt quá độ dài ngữ cảnh tối đa này; Shaham và cộng sự (2023) thấy rằng cả hai mô hình có thể hoạt động tốt với các chuỗi lên đến 8K token.

Hình 8 so sánh hiệu suất của các mô hình decoder-only và encoder-decoder. Khi Flan-UL2 được đánh giá trên các chuỗi trong cửa sổ ngữ cảnh 2048-token thời gian huấn luyện của nó (Hình 8; biểu đồ con bên trái), hiệu suất của nó tương đối mạnh mẽ trước những thay đổi trong vị trí của thông tin liên quan trong ngữ cảnh đầu vào (1.9% sự khác biệt tuyệt đối giữa hiệu suất trường hợp tốt nhất và tệ nhất). Khi được đánh giá trên các cài đặt với chuỗi dài hơn 2048 token (Hình 8; giữa và phải), hiệu suất Flan-UL2 bắt đầu suy giảm khi thông tin liên quan được đặt ở giữa. Flan-T5-XXL cho thấy xu hướng tương tự, trong đó ngữ cảnh đầu vào dài hơn dẫn đến suy giảm hiệu suất lớn hơn khi đặt thông tin liên quan ở giữa ngữ cảnh đầu vào. Chúng tôi giả thuyết rằng các mô hình encoder-decoder có thể sử dụng tốt hơn cửa sổ ngữ cảnh của chúng vì encoder hai chiều của chúng cho phép xử lý mỗi tài liệu trong ngữ cảnh của các tài liệu tương lai, có khả năng cải thiện ước tính tầm quan trọng tương đối giữa các tài liệu.

4.2 Tác động của Ngữ cảnh hóa Nhận biết Truy vấn

Các thí nghiệm QA đa tài liệu và truy xuất khóa-giá trị của chúng tôi đặt truy vấn (tức là câu hỏi cần trả lời hoặc khóa cần truy xuất) sau dữ liệu cần xử lý (tức là các tài liệu hoặc các cặp khóa-giá trị). Kết quả là, các mô hình decoder-only không thể attend đến các token truy vấn khi ngữ cảnh hóa các tài liệu hoặc cặp khóa-giá trị, vì truy vấn chỉ xuất hiện ở cuối

--- TRANG 8 ---
1st 5th 10th
Vị trí của Tài liệu có Câu trả lời5055606570Độ chính xác
10 Tổng số Tài liệu được Truy xuất (~2K token)
1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời5055606570Độ chính xác
20 Tổng số Tài liệu được Truy xuất (~4K token)
1st 5th 10th 15th 20th 25th 30th
Vị trí của Tài liệu có Câu trả lời5055606570Độ chính xác
30 Tổng số Tài liệu được Truy xuất (~6K token)
mpt-30b-instruct longchat-13b-16k flan-t5-xxl flan-ul2Hình 8: Khi các mô hình encoder-decoder (Flan-UL2 và Flan-T5-XXL) được đánh giá trên các chuỗi ngắn hơn độ dài chuỗi tối đa thời gian huấn luyện của encoder (2048 và 512 token, tương ứng), chúng tương đối mạnh mẽ trước những thay đổi trong vị trí của thông tin liên quan trong ngữ cảnh đầu vào của chúng (biểu đồ con bên trái). Ngược lại, khi các mô hình này được đánh giá trên các chuỗi dài hơn những gì nhìn thấy trong quá trình huấn luyện (biểu đồ con giữa và phải), chúng tôi quan sát một đường cong hiệu suất hình chữ U—hiệu suất cao hơn khi thông tin liên quan xuất hiện ở đầu hoặc cuối ngữ cảnh đầu vào, trái ngược với giữa ngữ cảnh đầu vào.

1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời50607080Độ chính xác
20 Tổng số Tài liệu được Truy xuất 
(~4K token, ngữ cảnh hóa nhận biết truy vấn)
claude-1.3
claude-1.3-100k
gpt-3.5-turbo-0613gpt-3.5-turbo-16k-0613
mpt-30b-instruct
longchat-13b-16k
Hình 9: Ngữ cảnh hóa nhận biết truy vấn (đặt truy vấn trước và sau các tài liệu) không cải thiện đáng kể độ mạnh mẽ của các mô hình ngôn ngữ trước việc thay đổi vị trí của thông tin liên quan trong QA đa tài liệu; hiệu suất tăng nhẹ khi thông tin liên quan xuất hiện ở đầu, nhưng giảm nhẹ ở các trường hợp khác.

của prompt và các mô hình decoder-only chỉ có thể attend đến các token trước đó tại mỗi timestep. Ngược lại, các mô hình encoder-decoder (dường như mạnh mẽ hơn trước những thay đổi trong vị trí của thông tin liên quan; §4.1) sử dụng encoder hai chiều để ngữ cảnh hóa ngữ cảnh đầu vào—liệu chúng ta có thể sử dụng quan sát này để cải thiện các mô hình decoder-only bằng cách đặt truy vấn trước và sau dữ liệu, cho phép ngữ cảnh hóa nhận biết truy vấn của các tài liệu (hoặc cặp khóa-giá trị) không?

Chúng tôi thấy rằng ngữ cảnh hóa nhận biết truy vấn cải thiện đáng kể hiệu suất trên nhiệm vụ truy xuất khóa-giá trị—tất cả các mô hình đạt hiệu suất gần hoàn hảo trên các cài đặt 75, 140, và 300 cặp khóa-giá trị. Ví dụ, GPT-3.5-Turbo (16K) với ngữ cảnh hóa nhận biết truy vấn đạt hiệu suất hoàn hảo khi được đánh giá với 300 cặp khóa-giá trị. Ngược lại, không có ngữ cảnh hóa nhận biết truy vấn, hiệu suất trường hợp tệ nhất là 45.6% (Hình 7). Mặc dù có tác động đáng kể đến hiệu suất truy xuất khóa-giá trị, ngữ cảnh hóa nhận biết truy vấn ảnh hưởng tối thiểu đến xu hướng hiệu suất trong nhiệm vụ trả lời câu hỏi đa tài liệu (Hình 9); nó cải thiện nhẹ hiệu suất khi thông tin liên quan nằm ở đầu ngữ cảnh đầu vào, nhưng giảm nhẹ hiệu suất trong các cài đặt khác.

4.3 Tác động của Tinh chỉnh Hướng dẫn

Các mô hình mà chúng tôi đánh giá đều được tinh chỉnh hướng dẫn—sau pre-training ban đầu của chúng, chúng trải qua tinh chỉnh có giám sát trên một tập dữ liệu hướng dẫn và phản hồi. Đặc tả nhiệm vụ và/hoặc hướng dẫn thường được đặt ở đầu ngữ cảnh đầu vào trong dữ liệu tinh chỉnh hướng dẫn có giám sát, điều này có thể dẫn đến các mô hình ngôn ngữ được tinh chỉnh hướng dẫn đặt trọng số nhiều hơn vào đầu ngữ cảnh đầu vào. Để hiểu rõ hơn các tác động tiềm năng của tinh chỉnh hướng dẫn đối với cách các mô hình ngôn ngữ sử dụng ngữ cảnh đầu vào dài, chúng tôi so sánh hiệu suất trả lời câu hỏi đa tài liệu của MPT-30B-Instruct với mô hình cơ sở của nó (tức là trước khi tinh chỉnh hướng dẫn) MPT-30B. Chúng tôi sử dụng cùng thiết lập thí nghiệm như §2.

Hình 10 so sánh hiệu suất QA đa tài liệu của MPT-30B và MPT-30B-Instruct như một hàm của vị trí của thông tin liên quan

--- TRANG 9 ---
1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời44464850525456Độ chính xác
20 Tổng số Tài liệu được Truy xuất (~4K token)
mpt-30b mpt-30b-instructHình 10: Hiệu suất QA đa tài liệu của MPT-30B-Instruct so sánh với mô hình cơ sở của nó (tức là trước khi tinh chỉnh hướng dẫn) MPT-30B. Cả hai mô hình đều có đường cong hiệu suất hình chữ U, trong đó hiệu suất cao hơn nhiều khi thông tin liên quan xuất hiện ở đầu hoặc cuối ngữ cảnh đầu vào, cho thấy rằng quá trình tinh chỉnh hướng dẫn bản thân không nhất thiết chịu trách nhiệm cho những xu hướng hiệu suất này.

trong ngữ cảnh đầu vào. Đáng ngạc nhiên, chúng tôi thấy rằng cả MPT-30B và MPT-30B-Instruct đều thể hiện đường cong hiệu suất hình chữ U, trong đó hiệu suất cao nhất khi thông tin liên quan xuất hiện ở đầu hoặc cuối ngữ cảnh. Mặc dù hiệu suất tuyệt đối của MPT-30B-Instruct cao hơn đồng đều so với MPT-30B, xu hướng hiệu suất tổng thể của chúng tương tự. Chúng tôi cũng quan sát rằng tinh chỉnh hướng dẫn giảm nhẹ sự chênh lệch hiệu suất trường hợp tệ nhất từ gần 10% giữa hiệu suất trường hợp tốt nhất và tệ nhất của mô hình cơ sở xuống khoảng 4%.

Những quan sát này bổ sung cho công việc trước đây, đã thấy rằng các mô hình ngôn ngữ không được tinh chỉnh hướng dẫn bị thiên lệch về các token gần đây (tức là cuối ngữ cảnh đầu vào; Khandelwal và cộng sự, 2018; Press và cộng sự, 2021). Thiên lệch gần đây này đã được quan sát trong công việc trước đây khi đánh giá các mô hình trên dự đoán từ tiếp theo của văn bản liền kề, một cài đặt mà các mô hình ngôn ngữ có lợi ích tối thiểu từ thông tin tầm xa (Sun và cộng sự, 2021). Ngược lại, kết quả của chúng tôi cho thấy các mô hình ngôn ngữ có khả năng sử dụng thông tin tầm xa hơn (tức là đầu ngữ cảnh đầu vào) khi được prompt với dữ liệu định dạng hướng dẫn. Chúng tôi giả thuyết rằng các mô hình ngôn ngữ không được tinh chỉnh hướng dẫn học cách sử dụng những ngữ cảnh dài này từ dữ liệu định dạng tương tự có thể xuất hiện trong văn bản Internet nhìn thấy trong quá trình pre-training, ví dụ: câu hỏi và câu trả lời StackOverflow.

Để hiểu rõ hơn tác động của tinh chỉnh bổ sung và quy mô mô hình, chúng tôi cũng thí nghiệm với các mô hình Llama-2 có kích thước khác nhau (7B, 13B, và 70B) có và không có tinh chỉnh có giám sát bổ sung và học tăng cường từ phản hồi của con người (Phụ lục E). Chúng tôi thấy rằng đường cong hiệu suất hình chữ U chỉ xuất hiện trong các mô hình ngôn ngữ đủ lớn (có hoặc không có tinh chỉnh bổ sung)—các mô hình Llama-2 7B chỉ bị thiên lệch gần đây, trong khi các mô hình 13B và 70B thể hiện đường cong hiệu suất hình chữ U. Ngoài ra, chúng tôi thấy rằng quy trình tinh chỉnh có giám sát và học tăng cường từ phản hồi của con người Llama-2 giảm nhẹ thiên lệch vị trí trong các mô hình nhỏ hơn (13B, tương tự như xu hướng được hiển thị khi so sánh MPT-30B và MPT-30B-Instruct), nhưng ảnh hưởng tối thiểu đến xu hướng trên các mô hình lớn hơn (70B).

5 Có phải Ngữ cảnh Nhiều hơn Luôn Tốt hơn không? Một Nghiên cứu Trường hợp với QA Miền Mở

Kết quả của chúng tôi cho thấy rằng việc prompting các mô hình ngôn ngữ với ngữ cảnh đầu vào dài hơn là một sự đánh đổi—cung cấp cho mô hình ngôn ngữ nhiều thông tin hơn có thể giúp nó thực hiện nhiệm vụ hạ nguồn, nhưng nó cũng tăng lượng nội dung mà mô hình phải suy luận, có khả năng giảm độ chính xác. Ngay cả khi một mô hình ngôn ngữ có thể nhận 16K token, liệu thực sự có lợi khi cung cấp 16K token ngữ cảnh không? Câu trả lời cho câu hỏi này cuối cùng phụ thuộc vào nhiệm vụ hạ nguồn cụ thể vì nó phụ thuộc vào giá trị cận biên của ngữ cảnh được thêm vào và khả năng của mô hình sử dụng hiệu quả ngữ cảnh đầu vào dài, nhưng chúng tôi thực hiện một nghiên cứu trường hợp với trả lời câu hỏi miền mở trên NaturalQuestions-Open để hiểu rõ hơn sự đánh đổi này trong các mô hình ngôn ngữ hiện có.

Chúng tôi sử dụng các mô hình ngôn ngữ trong thiết lập retriever-reader tiêu chuẩn. Một hệ thống truy xuất (Contriever, được tinh chỉnh trên MS-MARCO) lấy một truy vấn đầu vào từ NaturalQuestions-Open và trả về k tài liệu từ Wikipedia với điểm liên quan cao nhất. Để điều kiện hóa các mô hình ngôn ngữ trên những tài liệu được truy xuất này, chúng tôi đơn giản bao gồm chúng trong prompt. Chúng tôi đánh giá recall của retriever và độ chính xác của reader (liệu có bất kỳ câu trả lời được chú thích nào xuất hiện trong đầu ra dự đoán hay không) như một hàm của số lượng tài liệu được truy xuất k. Chúng tôi sử dụng một tập con của NaturalQuestions-Open trong đó câu trả lời dài là một đoạn văn (trái ngược với bảng hoặc danh sách).

Hình 11 trình bày recall của retriever và kết quả QA miền mở. Chúng tôi thấy rằng hiệu suất mô hình reader bão hòa trước khi hiệu suất retriever bão hòa, cho thấy reader không sử dụng hiệu quả ngữ cảnh bổ sung. Sử dụng hơn 20 tài liệu được truy xuất chỉ cải thiện hiệu suất reader một cách cận biên (~1.5% cho GPT-3.5-Turbo và ~1% cho Claude-1.3), trong khi tăng đáng kể độ dài ngữ cảnh đầu vào (và do đó độ trễ và chi phí). Những kết quả này, cùng với quan sát rằng các mô hình thường tốt hơn trong việc truy xuất và sử dụng thông tin ở đầu hoặc cuối ngữ cảnh đầu vào, gợi ý rằng việc sắp xếp lại hiệu quả các tài liệu được truy xuất (đẩy thông tin liên quan gần hơn với đầu ngữ cảnh đầu vào) hoặc cắt bớt danh sách được xếp hạng (truy xuất ít tài liệu hơn khi thích hợp; Arampatzis và cộng sự, 2009) có thể là những hướng đầy hứa hẹn để cải thiện cách reader dựa trên mô hình ngôn ngữ sử dụng ngữ cảnh được truy xuất.

6 Công việc Liên quan

6.1 Các Mô hình Ngôn ngữ Ngữ cảnh Dài

Có nhiều công việc trước đây trong việc thiết kế các mô hình ngôn ngữ hiệu quả với việc mở rộng rẻ hơn so với Transformers về độ dài ngữ cảnh. Nhiều hướng công việc theo đuổi các biến thể Transformer với các sửa đổi attention như tái phát (Dai và cộng sự, 2019), phân tích attention thành các xấp xỉ tính toán ít tốn kém hơn (Beltagy và cộng sự, 2020; Zaheer và cộng sự, 2020), hoặc xấp xỉ low-rank (Wang và cộng sự, 2020; Peng và cộng sự, 2021). Dao và cộng sự (2022) thay vào đó cung cấp attention chính xác nhanh hơn bằng một kernel CUDA được chế tạo cẩn thận nhận biết IO. Riêng biệt, có những nỗ lực loại bỏ hoàn toàn attention để loại bỏ độ phức tạp bình phương của độ dài chuỗi, thường thông qua convolution và/hoặc RNN tuyến tính, ví dụ: trong RWKV (Peng, 2023), S4 (Gu và cộng sự, 2022), hoặc Hyena (Poli và cộng sự, 2023). Nhiều nỗ lực trước đây đánh giá perplexity trên một corpus web đa dạng như một proxy cho khả năng xử lý ngữ cảnh dài; công việc này cho thấy truy cập kiến thức chính xác trên ngữ cảnh dài có thể là một thách thức bổ sung.

6.2 Các Mô hình Ngôn ngữ Sử dụng Ngữ cảnh như thế nào?

Công việc tiên phong của Khandelwal và cộng sự (2018) cho thấy các mô hình ngôn ngữ LSTM nhỏ sử dụng ngữ cảnh dài hạn ngày càng thô; Sankar và cộng sự (2019) thấy kết quả tương tự trong các mô hình đối thoại. Theo một hướng tương tự, Daniluk và cộng sự (2017) thấy rằng các mô hình ngôn ngữ LSTM chú ý có xu hướng chủ yếu sử dụng lịch sử gần đây. Petroni và cộng sự (2020) là những người đầu tiên chứng minh tiềm năng của việc kết hợp ngữ cảnh từ một hệ thống truy xuất thông tin với các mô hình ngôn ngữ được pre-train cho trả lời câu hỏi không giám sát. O'Connor và Andreas (2021) thấy rằng nhiều hoạt động phá hủy thông tin có tác động cận biên đến dự đoán của Transformer LM. Krishna và cộng sự (2022) thấy rằng việc tạo neural ngữ cảnh dài trong các mô hình ngôn ngữ Transformer có kích thước vừa phải bị suy thoái vì các mô hình không điều kiện hóa đúng cách trên ngữ cảnh dài. Cuối cùng, nghiên cứu các mô hình ngữ cảnh dài, Sun và cộng sự (2021) thấy rằng ngữ cảnh dài hơn cải thiện dự đoán chỉ của một vài token, một phát hiện thực nghiệm phù hợp với lý thuyết của Sharan và cộng sự (2018), những người cho thấy rằng các phân phối chuỗi với thông tin tương hợ bị giới hạn nhất thiết dẫn đến lợi ích dự đoán trung bình cận biên từ ngữ cảnh ngày càng dài. Qin và cộng sự (2023) phân tích cách các Transformer hiệu quả thực hiện trên nhiều nhiệm vụ NLP hạ nguồn ngữ cảnh dài, thấy rằng các transformer ngữ cảnh dài bị thiên lệch gần đây và không sử dụng hiệu quả ngữ cảnh tầm xa.

6.3 Hiệu ứng Vị trí Tuần tự

Đường cong hình chữ U mà chúng tôi quan sát trong công việc này có mối liên hệ trong tâm lý học được gọi là hiệu ứng vị trí tuần tự (Ebbinghaus, 1913; Murdock Jr, 1962), tuyên bố rằng trong việc nhớ lại liên tưởng tự do các phần tử từ một danh sách, con người có xu hướng nhớ tốt nhất các phần tử đầu tiên và cuối cùng của danh sách. Hiệu ứng vị trí tuần tự đóng một vai trò trong việc hiểu cách con người phát triển bộ nhớ ngắn hạn và dài hạn. Quan sát một hiệu ứng giống như vị trí tuần tự trong các mô hình ngôn ngữ có lẽ đáng ngạc nhiên, vì các cơ chế self-attention làm nền tảng cho các mô hình ngôn ngữ Transformer về mặt kỹ thuật có khả năng như nhau trong việc truy xuất bất kỳ token nào từ ngữ cảnh của chúng.

7 Kết luận

Chúng tôi nghiên cứu thực nghiệm cách các mô hình ngôn ngữ sử dụng ngữ cảnh đầu vào dài thông qua một loạt các thí nghiệm được kiểm soát. Chúng tôi cho thấy hiệu suất mô hình ngôn ngữ suy giảm đáng kể khi thay đổi vị trí của thông tin liên quan, cho thấy các mô hình gặp khó khăn trong việc truy cập và sử dụng thông tin trong ngữ cảnh đầu vào dài một cách mạnh mẽ. Đặc biệt, hiệu suất thường thấp nhất khi các mô hình phải sử dụng thông tin ở giữa ngữ cảnh đầu vào dài. Chúng tôi tiến hành điều tra sơ bộ về vai trò của (i) kiến trúc mô hình, (ii) ngữ cảnh hóa nhận biết truy vấn, và (iii) tinh chỉnh hướng dẫn để hiểu rõ hơn cách chúng ảnh hưởng đến cách các mô hình ngôn ngữ sử dụng ngữ cảnh. Cuối cùng, chúng tôi kết thúc với một nghiên cứu trường hợp thực tế về trả lời câu hỏi miền mở, thấy rằng hiệu suất của reader mô hình ngôn ngữ bão hòa xa trước khi recall của retriever. Kết quả và phân tích của chúng tôi cung cấp hiểu biết tốt hơn về cách các mô hình ngôn ngữ sử dụng ngữ cảnh đầu vào của chúng và cung cấp các giao thức đánh giá mới cho các mô hình ngữ cảnh dài trong tương lai.

--- TRANG 10 ---
510 20 30 40 50
Số lượng Tài liệu được Truy xuất5060708090Chỉ số
claude-1.3
claude-1.3-100k
gpt-3.5-turbo-0613
gpt-3.5-turbo-16k-0613mpt-30b-instruct
longchat-13b-16k
contriever recallHình 11: Recall của retriever và hiệu suất mô hình như một hàm của số lượng tài liệu được truy xuất. Hiệu suất mô hình bão hòa trước khi recall của retriever bão hòa, cho thấy các mô hình gặp khó khăn trong việc sử dụng ngữ cảnh được truy xuất bổ sung.

Lời cảm ơn

Chúng tôi muốn cảm ơn Luke Zettlemoyer, người đã phục vụ như biên tập viên hành động TACL của chúng tôi, và những người đánh giá ẩn danh vì những bình luận và phản hồi của họ. Chúng tôi cũng cảm ơn Claudiu Leoveanu-Condrei, Megan Leszczynski, Dmytro Okhonko, Maithra Raghu, Eric Wallace và Sang Michael Xie vì phản hồi và thảo luận đã giúp cải thiện công việc này. Hơn nữa, chúng tôi biết ơn Sewon Min vì sự giúp đỡ của cô ấy với tập dữ liệu AmbigQA. Công việc này được hỗ trợ bởi Trung tâm Nghiên cứu về Mô hình Nền tảng Stanford (CRFM), bởi OpenAI thông qua một khoản tài trợ tín dụng API cho Stanford CRFM, và bởi Anthropic thông qua chương trình truy cập học thuật Claude.

Tài liệu Tham khảo

Avi Arampatzis, Jaap Kamps, và Stephen Robertson. 2009. Where to stop reading a ranked list? threshold optimization using truncated score distributions. Trong Proc. of SIGIR.

Iz Beltagy, Matthew E. Peters, và Arman Cohan. 2020. Longformer: The long-document transformer. ArXiv:2004.05150.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, và Jason Wei. 2022. Scaling instruction-finetuned language models. ArXiv:2210.11416.

Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc Le, và Ruslan Salakhutdinov. 2019. Transformer-XL: Attentive language models beyond a fixed-length context. Trong Proc. of ACL.

Michał Daniluk, Tim Rocktäschel, Johannes Welbl, và Sebastian Riedel. 2017. Frustratingly short attention spans in neural language modeling. Trong Proc. of ICLR.

Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, và Christopher Ré. 2022. FlashAttention: Fast and memory-efficient exact attention with IO-awareness. ArXiv:2205.14135.

Hermann Ebbinghaus. 1913. Memory: A contribution to experimental psychology. H. A. Ruger & C. E. Bussenius, Trans.

Albert Gu, Karan Goel, và Christopher Ré. 2022. Efficiently modeling long sequences with structured state spaces. Trong Proc. of ICLR.

Maor Ivgi, Uri Shaham, và Jonathan Berant. 2023. Efficient long-text understanding with short-text models. Transactions of the Association for Computational Linguistics, 11:284–299.

Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, và Edouard Grave. 2021. Unsupervised dense information retrieval with contrastive learning. ArXiv:2112.09118.

Gautier Izacard và Edouard Grave. 2021. Leveraging passage retrieval with generative models

--- TRANG 11 ---
for open domain question answering. Trong Proc. of EACL.

Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, và Colin Raffel. 2022. Large language models struggle to learn long-tail knowledge. ArXiv:2211.08411.

Urvashi Khandelwal, He He, Peng Qi, và Dan Jurafsky. 2018. Sharp nearby, fuzzy far away: How neural language models use context. Trong Proc. of ACL.

Kalpesh Krishna, Yapei Chang, John Wieting, và Mohit Iyyer. 2022. RankGen: Improving text generation with large ranking models. Trong Proc. of EMNLP.

Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, và Slav Petrov. 2019. Natural Questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452–466.

Kenton Lee, Ming-Wei Chang, và Kristina Toutanova. 2019. Latent retrieval for weakly supervised open domain question answering. Trong Proc. of ACL.

Mina Lee, Percy Liang, và Qian Yang. 2022. CoAuthor: Designing a human-AI collaborative writing dataset for exploring language model capabilities. Trong Proc. of CHI.

Dacheng Li, Rulin Shao, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph E. Gonzalez, Ion Stoica, Xuezhe Ma, và Hao Zhang. 2023. How long can open-source LLMs truly promise on context length?

Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, và Hannaneh Hajishirzi. 2023. When not to trust language models: Investigating effectiveness of parametric and non-parametric memories. Trong Proc. of ACL.

Sewon Min, Julian Michael, Hannaneh Hajishirzi, và Luke Zettlemoyer. 2020. AmbigQA: Answering ambiguous open-domain questions. Trong Proc. of EMNLP.

Bennet B. Murdock Jr. 1962. The serial position effect of free recall. Journal of experimental psychology, 64(5):482.

Joe O'Connor và Jacob Andreas. 2021. What context features can Transformer language models use? Trong Proc. of ACL.

Dimitris Papailiopoulos, Kangwook Lee, và Jy-yong Sohn. 2023. A little retrieval test for large language models. https://github.com/anadim/the-little-retrieval-test.

Bo Peng. 2023. RWKV-LM. https://github.com/BlinkDL/RWKV-LM.

Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah Smith, và Lingpeng Kong. 2021. Random feature attention. Trong Proc. of ICLR.

Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H Miller, và Sebastian Riedel. 2020. How context affects language models' factual predictions. Trong Proc. of AKBC.

Michael Poli, Stefano Massaroli, Eric Nguyen, Daniel Y. Fu, Tri Dao, Stephen Baccus, Yoshua Bengio, Stefano Ermon, và Christopher Ré. 2023. Hyena hierarchy: Towards larger convolutional language models. Trong Proc. of ICML.

Ofir Press, Noah A. Smith, và Mike Lewis. 2021. Shortformer: Better language modeling using shorter inputs. Trong Proc. of ACL.

Ofir Press, Noah A. Smith, và Mike Lewis. 2022. Train short, test long: Attention with linear biases enables input length extrapolation. Trong Proc. of ICLR.

Guanghui Qin, Yukun Feng, và Benjamin Van Durme. 2023. The NLP task effectiveness of long-range transformers. Trong Proc. of EACL.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text Transformer. Journal of Machine Learning Research, 21(140):1–67.

--- TRANG 12 ---
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, và Yoav Shoham. 2023. In-context retrieval-augmented language models. ArXiv:2302.00083.

Ohad Rubin và Jonathan Berant. 2023. Long-range language modeling with self-retrieval. ArXiv:2306.13421.

Chinnadhurai Sankar, Sandeep Subramanian, Chris Pal, Sarath Chandar, và Yoshua Bengio. 2019. Do neural dialog systems use the conversation history effectively? an empirical study. Trong Proc. of ACL.

Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, và Thomas Scialom. 2023. Toolformer: Language models can teach themselves to use tools.

Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, và Omer Levy. 2023. ZeroSCROLLS: A zero-shot benchmark for long text understanding. ArXiv:2305.14196.

Vatsal Sharan, Sham Kakade, Percy Liang, và Gregory Valiant. 2018. Prediction with a short memory. Trong Proc. of STOC.

Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, và Wen tau Yih. 2023. REPLUG: Retrieval-augmented black-box language models. ArXiv:2301.12652.

Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, Morteza Behrooz, William Ngan, Spencer Poff, Naman Goyal, Arthur Szlam, Y-Lan Boureau, Melanie Kambadur, và Jason Weston. 2022. BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage. ArXiv:2208.03188.

Simeng Sun, Kalpesh Krishna, Andrew Mattarella-Micke, và Mohit Iyyer. 2021. Do long-range language models actually use long-range context? Trong Proc. of EMNLP.

Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Siamak Shakeri, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby, và Donald Metzler. 2023. UL2: Unifying language learning paradigms. ArXiv:2205.05131.

Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, và Quoc Le. 2022. LaMDA: Language models for dialog applications. ArXiv:2201.08239.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023a. LLaMA: Open and efficient foundation language models. ArXiv:2302.13971.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin

--- TRANG 13 ---
Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, và Thomas Scialom. 2023b. Llama 2: Open foundation and fine-tuned chat models. ArXiv:2307.09288.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Trong Proc. of NeurIPS.

Sinong Wang, Belinda Z. Li, Madian Khabsa, Han Fang, và Hao Ma. 2020. Linformer: Self-attention with linear complexity. ArXiv:2006.04768.

Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, và Amr Ahmed. 2020. Big Bird: Transformers for longer sequences. Trong Proc. of NeurIPS.

A Sự Mơ hồ trong QA Đa Tài liệu
Tài liệu Gây nhiễu

Theo công việc trước đây về NaturalQuestions-Open (Izacard và cộng sự, 2021; Izacard và Grave, 2021, cùng nhiều nghiên cứu khác), chúng tôi sử dụng một bản dump Wikipedia từ cuối năm 2018 làm corpus truy xuất của chúng tôi. Tuy nhiên, bản dump Wikipedia tiêu chuẩn này có một lượng nhỏ không khớp thời gian với các chú thích NaturalQuestions. Ví dụ, xem xét câu hỏi "đội bóng nfl nào robert griffin iii chơi cho". Câu trả lời được chú thích NaturalQuestions là "hiện tại là cầu thủ tự do". Tuy nhiên, corpus truy xuất Wikipedia chứa thông tin rằng anh ấy chơi cho "Baltimore Ravens", vì anh ấy đã được giải phóng khỏi đội giữa timestamp của bản dump Wikipedia và quá trình chú thích NaturalQuestions.

Chúng tôi sử dụng các chú thích mơ hồ của Min và cộng sự (2020) để tạo một tập con các câu hỏi không mơ hồ. Các thí nghiệm trên tập con không mơ hồ này của dữ liệu cho thấy kết quả và kết luận tương tự như các thí nghiệm trên toàn bộ bộ sưu tập câu hỏi (Hình 12).

1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời60657075Độ chính xác
20 Tổng số Tài liệu được Truy xuất 
(~4K token, câu hỏi không mơ hồ)
claude-1.3
claude-1.3-100k
gpt-3.5-turbo-0613gpt-3.5-turbo-16k-0613
mpt-30b-instruct
longchat-13b-16kHình 12: Hiệu suất mô hình ngôn ngữ trên một tập con các câu hỏi không mơ hồ.

B Gây nhiễu Ngẫu nhiên trong QA Đa Tài liệu

Chúng tôi cũng chạy các thí nghiệm trả lời câu hỏi đa tài liệu với các tài liệu Wikipedia ngẫu nhiên làm gây nhiễu, cho phép chúng tôi ablate tác động của gây nhiễu được truy xuất (hard negative). Lưu ý rằng trong cài đặt này, tài liệu chứa câu trả lời thường có thể được xác định bằng các heuristic đơn giản (ví dụ: sự chồng lấp từ vựng với truy vấn). Hình 13 trình bày kết quả của thí nghiệm này. Mặc dù tất cả các mô hình có độ chính xác tuyệt đối cao hơn trong cài đặt này, chúng đáng ngạc nhiên vẫn gặp khó khăn trong việc suy luận trên toàn bộ ngữ cảnh đầu vào của chúng, cho thấy suy giảm hiệu suất của chúng không chỉ do không thể xác định các tài liệu liên quan.

C Ngẫu nhiên hóa Thứ tự Gây nhiễu trong QA Đa Tài liệu

Prompt của chúng tôi hướng dẫn mô hình ngôn ngữ sử dụng các kết quả tìm kiếm được cung cấp để trả lời câu hỏi. Có thể có một prior trong dữ liệu pre-training hoặc tinh chỉnh hướng dẫn để xử lý kết quả tìm kiếm như được sắp xếp theo mức độ liên quan giảm dần (tức là các tài liệu gần đầu ngữ cảnh đầu vào có nhiều khả năng hữu ích hơn những tài liệu ở cuối). Để xác nhận rằng kết luận của chúng tôi không chỉ đơn giản là sản phẩm phụ của thiên lệch này, chúng tôi chạy thí nghiệm với hướng dẫn đã sửa đổi "Viết một câu trả lời chất lượng cao cho câu hỏi đã cho chỉ sử dụng các kết quả tìm kiếm được cung cấp (một số trong đó có thể không liên quan). Các kết quả tìm kiếm được sắp xếp ngẫu nhiên." Ngoài ra, chúng tôi xáo trộn ngẫu nhiên k−1 tài liệu gây nhiễu.

--- TRANG 14 ---
1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời65707580Độ chính xác
20 Tổng số Tài liệu được Truy xuất
(~4K token, gây nhiễu ngẫu nhiên)
claude-1.3
claude-1.3-100k
gpt-3.5-turbo-0613gpt-3.5-turbo-16k-0613
mpt-30b-instruct
longchat-13b-16kHình 13: Hiệu suất mô hình ngôn ngữ trên QA đa tài liệu khi sử dụng gây nhiễu ngẫu nhiên, thay vì gây nhiễu được truy xuất.

Hình 14 trình bày kết quả của thí nghiệm này. Chúng tôi tiếp tục thấy đường cong hiệu suất hình chữ U, với hiệu suất suy giảm khi các mô hình ngôn ngữ phải sử dụng thông tin ở giữa ngữ cảnh đầu vào của chúng. So sánh kết quả trong §2.3 với những kết quả khi ngẫu nhiên hóa thứ tự gây nhiễu và đề cập như vậy trong prompt, chúng tôi thấy rằng ngẫu nhiên hóa làm giảm nhẹ hiệu suất khi thông tin liên quan ở đầu ngữ cảnh, và tăng nhẹ hiệu suất khi sử dụng thông tin ở giữa và cuối ngữ cảnh.

D Hiệu suất GPT-4

Chúng tôi đánh giá GPT-4 (8K) trên một tập con 500 ví dụ QA đa tài liệu ngẫu nhiên với 20 tổng số tài liệu trong mỗi ngữ cảnh đầu vào (Hình 15). GPT-4 đạt hiệu suất tuyệt đối cao hơn bất kỳ mô hình ngôn ngữ nào khác, nhưng vẫn cho thấy đường cong hiệu suất hình chữ U—hiệu suất của nó cao nhất khi thông tin liên quan xuất hiện ở đầu hoặc cuối ngữ cảnh, và hiệu suất suy giảm khi nó phải sử dụng thông tin ở giữa ngữ cảnh đầu vào của nó.

E Hiệu suất Llama-2

Chúng tôi đánh giá Llama-2 (Touvron và cộng sự, 2023b) trên QA đa tài liệu với 20 tổng số tài liệu trong mỗi ngữ cảnh đầu vào. Tokenizer Llama tạo ra các chuỗi dài hơn so với tokenizer cho các mô hình đã nghiên cứu trước đây của chúng tôi, vì vậy chúng tôi loại bỏ 20 ví dụ (trong số 2655) vượt quá độ dài ngữ cảnh tối đa của Llama-2 là 4096 token. Chúng tôi thí nghiệm với các mô hình có kích thước khác nhau (7B, 13B, và 70B tham số), có và không có tinh chỉnh có giám sát bổ sung và học tăng cường từ phản hồi của con người (các mô hình "-chat-"). Kết quả được trình bày trong Hình 16.

So sánh các mô hình Llama-2 có kích thước khác nhau, chúng tôi thấy chỉ các mô hình lớn hơn (13B và 70B) thể hiện đường cong hiệu suất hình chữ U (tức là cả thiên lệch ưu tiên và gần đây)—các mô hình Llama-2 nhỏ nhất (7B) chỉ bị thiên lệch gần đây. Cho những kết quả này, chúng tôi giả thuyết rằng công việc trước đây (ví dụ: Khandelwal và cộng sự, 2018; Sun và cộng sự, 2021) trước đây không quan sát thấy bất kỳ thiên lệch ưu tiên nào trong các mô hình ngôn ngữ vì các mô hình họ nghiên cứu quá nhỏ (ít hơn 1B tham số).

So sánh giữa các mô hình Llama-2 có và không có tinh chỉnh có giám sát bổ sung và học tăng cường từ phản hồi của con người, chúng tôi thấy rằng tinh chỉnh bổ sung cải thiện đáng kể hiệu suất trên nhiệm vụ QA đa tài liệu. Các mô hình 7B có và không có tinh chỉnh bổ sung cho thấy thiên lệch ưu tiên tối thiểu, và phần lớn bị thiên lệch gần đây. Mô hình cơ sở 13B có thiên lệch ưu tiên và gần đây đáng kể—có sự chênh lệch độ chính xác 20 điểm giữa hiệu suất trường hợp tốt nhất và tệ nhất. Áp dụng tinh chỉnh bổ sung cho 13B dường như giảm nhẹ thiên lệch này (suy giảm trường hợp tệ nhất 10 điểm), nhưng thiên lệch vẫn đáng kể. Tuy nhiên, các mô hình 70B có và không có tinh chỉnh bổ sung có xu hướng phần lớn tương tự (cho thấy cả thiên lệch ưu tiên và gần đây), và tinh chỉnh bổ sung thay đổi tối thiểu mức độ nghiêm trọng của thiên lệch vị trí.

1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời5560657075Độ chính xác
20 Tổng số Tài liệu được Truy xuất
(~4K token, được sắp xếp ngẫu nhiên)
claude-1.3
claude-1.3-100k
gpt-3.5-turbo-0613gpt-3.5-turbo-16k-0613
mpt-30b-instruct
longchat-13b-16kHình 14: Hiệu suất mô hình ngôn ngữ khi ngẫu nhiên hóa thứ tự của gây nhiễu (thay vì trình bày chúng theo thứ tự giảm dần mức độ liên quan) và đề cập như vậy trong prompt.

1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời5060708090Độ chính xác
20 Tổng số Tài liệu được Truy xuất 
(~4K token, mẫu 500 câu hỏi)
claude-1.3
claude-1.3-100k
gpt-3.5-turbo-0613
gpt-3.5-turbo-16k-0613mpt-30b-instruct
longchat-13b-16k
gpt-4-0613
Hình 15: Mặc dù GPT-4 có hiệu suất tuyệt đối cao hơn các mô hình khác, hiệu suất của nó vẫn suy giảm khi thông tin liên quan xuất hiện ở giữa ngữ cảnh đầu vào.

--- TRANG 15 ---
1st 5th 10th 15th 20th
Vị trí của Tài liệu có Câu trả lời203040506070Độ chính xác
20 Tổng số Tài liệu được Truy xuất (~4K token)
Llama-2-7b-chat-hf
Llama-2-13b-chat-hf
Llama-2-70b-chat-hfLlama-2-7b-hf
Llama-2-13b-hf
Llama-2-70b-hfHình 16: Hiệu suất QA đa tài liệu (20 tổng số tài liệu) của các mô hình Llama-2 có kích thước khác nhau (7B, 13B, 70B tham số), có và không có tinh chỉnh có giám sát bổ sung và học tăng cường từ phản hồi của con người (các mô hình "-chat-").

--- TRANG 16 ---
F Số lượng Token

Bảng 2, Bảng 3, và Bảng 4 trình bày số lượng token trung bình và tối đa trong mỗi ngữ cảnh đầu vào cho tất cả các cài đặt thí nghiệm. Lưu ý rằng MPT-30B và MPT-30B-Instruct sử dụng cùng tokenizer, GPT-3.5-Turbo và GPT-3.5-Turbo (16K) sử dụng cùng tokenizer, và Claude-1.3 và Claude-1.3 (100K) sử dụng cùng tokenizer. Hơn nữa, tokenizer Claude-1.3 giống với tokenizer GPT-3.5-Turbo, modulo một số token đặc biệt bổ sung không xuất hiện trong dữ liệu của chúng tôi. Kết quả là, số lượng token cho hai họ mô hình này giống nhau trong các cài đặt thí nghiệm của chúng tôi.

Closed-Book Oracle
avg±stdev max avg ±stdev max
LongChat-13B (16K) 55.6 ±2.7 70 219.7 ±48.5 588
MPT-30B 43.5 ±2.2 58 187.9 ±41.8 482
GPT-3.5-Turbo 15.3 ±2.2 29 156.0 ±41.8 449
Claude-1.3 15.3 ±2.2 29 156.0 ±41.8 449
Bảng 2: Thống kê số lượng token cho mỗi mô hình được đánh giá trên các cài đặt trả lời câu hỏi đa tài liệu closed-book và oracle.

10 docs 20 docs 30 docs
avg±stdev max avg ±stdev max avg ±stdev max
LongChat-13B (16K) 1749.9 ±112.4 2511 3464.6 ±202.3 4955 5181.9 ±294.7 7729
MPT-30B 1499.7 ±88.5 1907 2962.4 ±158.4 3730 4426.9 ±230.5 5475
GPT-3.5-Turbo 1475.6 ±86.5 1960 2946.2 ±155.1 3920 4419.2 ±226.5 6101
Claude-1.3 1475.6 ±86.5 1960 2946.2 ±155.1 3920 4419.2 ±226.5 6101
Bảng 3: Thống kê số lượng token cho mỗi mô hình được đánh giá trên mỗi cài đặt trả lời câu hỏi tài liệu.

75 KV pairs 140 KV pairs 300 KV pairs
avg±stdev max avg ±stdev max avg ±stdev max
LongChat-13B (16K) 5444.5 ±19.1 5500 10072.4 ±24.1 10139 21467.3 ±35.9 21582
MPT-30B 4110.5 ±23.8 4187 7600.9 ±31.1 7687 16192.4 ±46.6 16319
GPT-3.5-Turbo 3768.7 ±25.6 3844 6992.8 ±34.1 7088 14929.4 ±50.7 15048
Claude-1.3 3768.7 ±25.6 3844 6992.8 ±34.1 7088 14929.4 ±50.7 15048
Bảng 4: Thống kê số lượng token cho mỗi mô hình được đánh giá trên mỗi cài đặt truy xuất khóa-giá trị (KV).

--- TRANG 17 ---
G Kết quả Trả lời Câu hỏi Đa Tài liệu Đầy đủ

Phần này lập bảng hiệu suất mô hình khi được đánh giá trên nhiệm vụ QA đa tài liệu với số lượng tài liệu khác nhau (Hình 5). "Index n" cho biết hiệu suất khi tài liệu có câu trả lời xuất hiện ở vị trí n+ 1, trong đó chỉ số thấp hơn gần với đầu ngữ cảnh đầu vào hơn. Ví dụ, index 0 đề cập đến hiệu suất khi tài liệu có câu trả lời được đặt ở đầu ngữ cảnh (tức là đầu tiên trong tất cả các tài liệu).

G.1 10 Tổng số Tài liệu được Truy xuất

Mô hình Index 0 Index 4 Index 9
Claude-1.3 62.9% 58.3% 59.7%
Claude-1.3 (100K) 63.1% 58.3% 59.7%
GPT-3.5-Turbo 76.8% 61.2% 62.4%
GPT-3.5-Turbo (16K) 76.9% 61.0% 62.5%
MPT-30B-Instruct 60.2% 56.2% 59.7%
LongChat-13B (16K) 72.1% 58.9% 58.5%
Bảng 5: Hiệu suất mô hình khi được đánh giá trên nhiệm vụ QA đa tài liệu với 10 tổng số tài liệu được truy xuất.

G.2 20 Tổng số Tài liệu được Truy xuất

Mô hình Index 0 Index 4 Index 9 Index 14 Index 19
Claude-1.3 59.9% 55.9% 56.8% 57.2% 60.1%
Claude-1.3 (100K) 59.8% 55.9% 57.0% 57.4% 60.0%
GPT-3.5-Turbo 75.8% 57.2% 53.8% 55.4% 63.2%
GPT-3.5-Turbo (16K) 75.7% 57.3% 54.1% 55.4% 63.1%
MPT-30B-Instruct 53.7% 51.8% 52.2% 52.7% 56.3%
LongChat-13B (16K) 68.6% 57.4% 55.3% 52.5% 55.0%
Bảng 6: Hiệu suất mô hình khi được đánh giá trên nhiệm vụ QA đa tài liệu với 20 tổng số tài liệu được truy xuất.

G.3 30 Tổng số Tài liệu được Truy xuất

Mô hình Index 0 Index 4 Index 9 Index 14 Index 19 Index 24 Index 29
Claude-1.3 59.1% 55.1% 54.8% 55.7% 56.4% 56.2% 59.9%
Claude-1.3 (100K) 59.1% 55.1% 54.9% 55.7% 56.6% 56.1% 60.0%
GPT-3.5-Turbo (16K) 73.4% 55.1% 50.5% 50.9% 51.8% 54.9% 63.7%
MPT-30B-Instruct 51.6% 51.3% 51.2% 49.0% 49.6% 51.3% 54.1%
LongChat-13B (16K) 66.9% 54.8% 52.5% 52.9% 52.2% 51.3% 55.1%
Bảng 7: Hiệu suất mô hình khi được đánh giá trên nhiệm vụ QA đa tài liệu với 30 tổng số tài liệu được truy xuất.

# 2309.08210.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2309.08210.pdf
# Kích thước tệp: 2119248 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Nghiên cứu Khả năng Trả lời của LLM cho Trả lời Câu hỏi Dạng Dài
Meghana Moorthy Bhat Rui Meng Ye Liu Yingbo Zhou và Semih Yavuz
Salesforce Research
{meghana.bhat, ruimeng, yeliu, yingbo.zhou, syavuz}@salesforce.com
Tóm tắt
Khi chúng ta bước vào kỷ nguyên mới của LLM, việc hiểu rõ khả năng, hạn chế và sự khác biệt của chúng trở nên ngày càng quan trọng. Hướng tới việc đạt được tiến bộ hơn nữa trong hướng này, chúng tôi cố gắng xây dựng hiểu biết sâu sắc hơn về khoảng cách giữa các LLM khổng lồ (ví dụ: ChatGPT) và các LLM mã nguồn mở nhỏ hơn nhưng hiệu quả cùng các phiên bản được chưng cất của chúng. Để đạt được mục tiêu này, chúng tôi tập trung cụ thể vào trả lời câu hỏi dạng dài (LFQA) vì nó có nhiều ứng dụng thực tế và có tác động (ví dụ: khắc phục sự cố, dịch vụ khách hàng, v.v.) nhưng vẫn chưa được nghiên cứu đầy đủ và thách thức đối với LLM. Chúng tôi đề xuất một phương pháp tạo câu hỏi từ tóm tắt trừu tượng và cho thấy rằng việc tạo ra các câu hỏi tiếp theo từ tóm tắt của các tài liệu dài có thể tạo ra một bối cảnh thách thức cho LLM để lý luận và suy luận từ các ngữ cảnh dài. Kết quả thực nghiệm của chúng tôi xác nhận rằng: (1) phương pháp đề xuất của chúng tôi về tạo câu hỏi từ tóm tắt trừu tượng đặt ra một thiết lập thách thức cho LLM và cho thấy khoảng cách hiệu suất giữa các LLM như ChatGPT và LLM mã nguồn mở (Alpaca, Llama) (2) LLM mã nguồn mở thể hiện sự phụ thuộc giảm vào ngữ cảnh đối với các câu hỏi được tạo từ tài liệu gốc, nhưng khả năng tạo của chúng giảm đáng kể trên các câu hỏi được tạo từ tóm tắt – đặc biệt đối với các ngữ cảnh dài hơn (>1024 token).
1 Giới thiệu
Trong khi các Mô hình Ngôn ngữ Lớn (LLM) như ChatGPT, GPT-4 (OpenAI, 2023) đã thể hiện hiệu suất vượt trội trên các bộ đánh giá khác nhau, các nỗ lực mã nguồn mở cũng đang tiến bộ nhanh chóng trong việc bắt kịp trên các ứng dụng và bộ đánh giá khác nhau như MMLU (Hendrycks et al., 2021), OpenLLMBoard (Anil et al., 2023; Beeching et al., 2023; Touvron et al., 2023). Khi chúng ta chuyển sang kỷ nguyên mới của LLM với tiến bộ nhanh chóng về các mô hình và kỹ thuật mới, việc hiểu khả năng, hạn chế và sự khác biệt giữa chúng trở nên ngày càng quan trọng. Với khả năng tạo ra văn bản mạch lạc, LLM đã được chứng minh là hoạt động tốt trong các nhiệm vụ như tóm tắt (Ouyang et al., 2022), hiệu suất của chúng trên LFQA tương đối ít được biết đến. Trả lời Câu hỏi Dạng Dài (LFQA) là một trong những thách thức quan trọng chưa được giải quyết với các ứng dụng thực tế đa dạng và có tác động (ví dụ: diễn đàn trợ giúp, khắc phục sự cố, dịch vụ khách hàng, v.v.) Trả lời những câu hỏi như vậy thường đòi hỏi khả năng lý luận phức tạp để hiểu truy vấn và lý luận qua các khoảng thông tin rải rác khắp tài liệu gốc.

Tóm tắt trừu tượng chứa đựng cốt lõi của các bài viết dưới dạng nén (Fabbri et al., 2020). Chúng tôi đưa ra giả thuyết rằng các câu hỏi tiếp theo từ những tóm tắt này sẽ đòi hỏi hiểu biết sâu sắc hơn về các chủ đề sẽ liên kết các phần khác nhau của tài liệu nguồn. Hơn nữa, Pang et al. (2022) chứng minh rằng các câu trả lời đòi hỏi hiểu biết hơn một phần ba của tài liệu dài thường được con người đánh giá là "KHÓ". Do đó, chúng tôi đề xuất một phương pháp đánh giá có thể mở rộng để phân tích và nghiên cứu sự khác biệt của các LLM khổng lồ với các LLM cơ sở nhỏ hơn nhưng đã được chứng minh thành công (ví dụ: Llama-7B, 13B) và các phiên bản được chưng cất của chúng (ví dụ: Alpaca-7B, 13B). Để đạt được mục tiêu này, chúng tôi đề xuất nhắc ChatGPT với các hướng dẫn cụ thể để tạo ra những câu hỏi phức tạp từ tóm tắt tài liệu.

Phân tích thực nghiệm của chúng tôi trên hai mặt (độ phức tạp của các câu hỏi được tạo và chất lượng câu trả lời của LLM mã nguồn mở) cho thấy rằng các câu hỏi tiếp theo được tạo từ tóm tắt đặt ra một thiết lập thách thức nhưng thực tế hơn để kiểm tra khả năng lý luận của LLM. Vì việc phụ thuộc hoàn toàn vào đánh giá con người cho QA dạng dài rất tốn kém và khó mở rộng (Pagnoni et al., 2021), thay vào đó chúng tôi tận dụng GPT-4 để đánh giá chất lượng câu trả lời về tính mạch lạc, liên quan, nhất quán thực tế và độ chính xác theo các nghiên cứu trước (Fabbri et al., 2020; Fan et al., 2019). Tuy nhiên, chúng tôi cũng thực hiện đánh giá con người ở quy mô nhỏ hơn, cho thấy GPT-4 có tương quan cao với đánh giá con người làm cho đánh giá của chúng tôi đáng tin cậy. Những phát hiện chính từ nghiên cứu này như sau:

• Phương pháp đề xuất của chúng tôi về tạo câu hỏi từ tóm tắt trừu tượng đòi hỏi suy luận từ các ngữ cảnh dài hơn, với nhiều lần đọc qua ngữ cảnh hơn 20% thời gian.
• LLM được chưng cất (Alpaca-7B, 13B) có xu hướng phụ thuộc ít hơn vào ngữ cảnh đối với các câu hỏi được tạo từ tài liệu gốc, nhưng khả năng tạo của chúng giảm đáng kể trên các câu hỏi được tạo từ tóm tắt tài liệu.
• Câu trả lời được tạo bởi LLM được chưng cất có thể mạch lạc qua các thiết lập khác nhau; nhưng có xu hướng lệch khỏi câu hỏi, tạo ra câu trả lời lặp lại và đúng một phần cho các câu hỏi được tạo từ tóm tắt (> 16.8%)
• Alpaca-7B, 13B chủ yếu tạo ra câu trả lời có ý nghĩa hơn các LLM cơ sở (Llama) nhưng nhạy cảm với các ngữ cảnh dài hơn (>1024 token).

2 Nghiên cứu liên quan
Lý luận trên Tài liệu Dài: LLM đã cho thấy khả năng tuyệt vời để lý luận trên một số nhiệm vụ như lý luận thông thường (Talmor et al., 2019), lý luận toán học và biểu tượng (Huang và Chang, 2023; Cobbe et al., 2021), các nhiệm vụ trả lời câu hỏi như SQuaD, HotpotQA. Tuy nhiên, hầu hết các nhiệm vụ này không đòi hỏi ngữ cảnh dài và câu trả lời thường là một cụm từ ngắn hoặc một đoạn văn bản từ ngữ cảnh. Trong nghiên cứu này, chúng tôi đánh giá LLM để lý luận trên các tài liệu dài sẽ đòi hỏi khả năng hiểu sâu hơn và ngữ cảnh dài hơn để trả lời bằng cách nhắc LLM (ChatGPT) tạo ra các câu hỏi tiếp theo từ tóm tắt của các tài liệu dài.

Đánh giá Dựa trên Mô hình: Nghiên cứu trước đây đã đề xuất các chỉ số đánh giá tự động sử dụng các mô hình đã học (Zhang* et al., 2020; Laban et al., 2022); đặc biệt cho các nhiệm vụ tạo văn bản dạng dài như tóm tắt (Fabbri et al., 2020; Kryscinski et al., 2020) nơi tính nhất quán và mạch lạc được đo lường giữa tài liệu nguồn và tóm tắt được tạo như sự kéo theo. Gần đây, Liu et al. (2023) đã chỉ ra rằng GPT-4 có tương quan cao nhất với con người và vượt qua tất cả các phương pháp tự đánh giá khác trên các nhiệm vụ tóm tắt. Chúng tôi lấy cảm hứng từ những nghiên cứu này để thiết kế các lời nhắc đánh giá và sử dụng GPT-4 làm người đánh giá cho các câu trả lời được tạo.

3 Phương pháp Đánh giá Đề xuất
3.1 Nguồn Dữ liệu
Để tạo ra một bộ dữ liệu đa dạng và có thể sử dụng rộng rãi, chúng tôi sử dụng các bài viết Wikipedia. Sử dụng siêu dữ liệu của danh sách Danh mục từ API Wikipedia, chúng tôi kiểm soát tính đa dạng của các chủ đề và thu thập các bài viết từ mỗi trong 9 lĩnh vực sau: Vật lý, Giải trí, Lịch sử, Khoa học Máy tính, Khoa học Xã hội, Xã hội, Kinh tế, Y học và Thể thao.

Các trang bài viết thường có thể dài để phù hợp với ngữ cảnh của LLM. Do đó, chúng tôi trích xuất dữ liệu theo từng phần từ các trang bài viết có độ dài tối thiểu 256 token sử dụng tokenizer SpaCy và kết hợp các phần ngắn hơn lại với nhau. Để so sánh công bằng giữa các mô hình khác nhau, chúng tôi đặt độ dài ngữ cảnh tối đa là 2k token trong các thí nghiệm của chúng tôi. Ngoài ra, chúng tôi lọc ra các tài liệu không có thông tin sử dụng các bộ lọc tiền xử lý. Chi tiết thêm có trong Phụ lục A.5.

3.2 Tạo Câu hỏi sử dụng ChatGPT
Chúng tôi hình thành phương pháp tạo câu hỏi của mình như một quy trình hai bước: (1) Tóm tắt và (2) Tạo câu hỏi từ tóm tắt.

Tóm tắt Đầu tiên, chúng tôi thu thập các đoạn văn theo từng phần từ Wikipedia như được mô tả trong Phần 3.1. Sau đó, chúng tôi nhắc ChatGPT (gpt-turbo-3.5) để tạo tóm tắt của tài liệu gốc. Để cung cấp thêm ngữ cảnh cho ChatGPT, chúng tôi cung cấp thông tin về tiêu đề và lĩnh vực của bài viết trong đoạn văn.

Tạo câu hỏi từ tóm tắt Trong bước này, chúng tôi nhắc ChatGPT tạo câu hỏi sử dụng tóm tắt tài liệu làm ngữ cảnh. Để tránh tạo câu hỏi theo thứ tự ngẫu nhiên, chúng tôi hướng dẫn ChatGPT cung cấp 3 câu hỏi phức tạp nhất để trả lời. Để chứng minh tính hữu ích của quy trình tạo câu hỏi của chúng tôi, chúng tôi cũng thiết lập một đường cơ sở với cùng hướng dẫn nơi các câu hỏi được tạo trực tiếp từ đoạn văn.

Vui lòng tham khảo phụ lục A.1 cho lời nhắc được sử dụng trong thiết lập của chúng tôi. Tóm lại, chúng tôi tạo 3 câu hỏi cho 50 đoạn văn trong mỗi lĩnh vực tổng cộng 1350 câu hỏi cho mỗi thiết lập.

3.3 Đánh giá Độ phức tạp Câu hỏi Được tạo
Pang et al. (2022) đã thiết kế các hướng dẫn chú thích mở rộng để đánh giá độ phức tạp của câu hỏi. Trong số các câu hỏi được con người đánh giá là 'KHÓ', 26.7% câu hỏi (cao hơn 20.2% so với những câu dễ hơn)

--- TRANG 3 ---
Lựa chọn Câu hỏi
Q1: Câu hỏi có thể trả lời được từ ngữ cảnh đã cho và không mơ hồ không? A. Có B. Không
Q2. Cần bao nhiều đoạn văn làm ngữ cảnh để trả lời câu hỏi? A. Chỉ một hoặc hai câu
B. Hơn 2 câu nhưng ít hơn một đoạn văn
C. Ít nhất một phần ba của toàn bộ đoạn văn
D. Hầu hết đoạn văn
Q3: Câu hỏi có đòi hỏi nhiều lần đọc qua đoạn văn không? A. Có B. Không

Bảng 1: Lời nhắc được thiết kế để đánh giá độ phức tạp của các câu hỏi được tạo.

cần ít nhất một phần ba hoặc nhiều hơn thông tin đã cho để được trả lời. Để đánh giá chất lượng của các câu hỏi được tạo, chúng tôi nhắc ChatGPT với các câu hỏi (Bảng 1) cho (1) Từ đoạn văn (QG-Passage) (2) Từ tóm tắt (QG-Summary). Theo nghiên cứu trước, bằng bỏ phiếu đa số chúng tôi loại trừ các câu hỏi được ChatGPT đánh giá là không thể trả lời bằng cách nhắc các câu hỏi với top_p = {0.8, 0.9, 1} khác nhau. Sau khi lọc, chúng tôi có 1278 câu hỏi được tạo từ mỗi thiết lập.

Chỉ số Đánh giá QG - Passage QG - Summary
Q1: Không mơ hồ 96.6% 94.7%
Q2. Độ dài Ngữ cảnh:
Một câu hoặc ít hơn một đoạn văn 79.3% 75.7%
Ít nhất một phần ba hoặc hầu hết đoạn văn 20.7% 24.3%
Q3: Đọc nhiều lần qua đoạn văn 24.4% 31%

Bảng 2: Lời nhắc được thiết kế để đánh giá độ phức tạp của các câu hỏi được tạo.

4 Kết quả và Phân tích
4.1 Thiết lập Thí nghiệm
Vì thiết lập few-shot không khả thi trong bối cảnh của chúng tôi do độ dài ngữ cảnh, chúng tôi so sánh hiệu suất mô hình trên đánh giá zero-shot. Chúng tôi nhắc các mô hình sau để tạo văn bản tự do làm câu trả lời trên bộ dữ liệu đánh giá cuối cùng của chúng tôi: ChatGPT (OpenAI, 2023), Alpaca-7B, 13B (Taori et al., 2023), LLaMa-7B, 13B (Touvron et al., 2023). Chúng tôi sử dụng API OpenAI cho ChatGPT và tải các checkpoint cho LLM mã nguồn mở từ HuggingFace1. Lời nhắc được sử dụng để tạo câu trả lời có trong Phụ lục A. Xin lưu ý rằng các thí nghiệm của chúng tôi không xem xét đầu vào vượt quá độ dài chuỗi 2k để so sánh công bằng với các mô hình khác. Chúng tôi cũng thử nghiệm tạo câu hỏi từ Alpaca và thấy chúng không tuân theo hướng dẫn và thường tạo ra nội dung không liên quan. Phân tích chi tiết của chúng tôi có thể được tìm thấy trong Phụ lục A.2.

GPT-4 làm người đánh giá đã cho thấy tương quan cao với đánh giá con người trong các nhiệm vụ tạo văn bản dạng dài như tóm tắt (Liu et al., 2023) vượt qua các chỉ số tự đánh giá khác như điểm ROUGE và BLEU. Vì LLM được mong đợi tạo ra câu trả lời tự do cho thiết lập của chúng tôi, chúng tôi lấy cảm hứng từ các nghiên cứu trước về chỉ số tạo văn bản dạng dài (Fabbri et al., 2020) và áp dụng chúng trong đánh giá của chúng tôi về tính mạch lạc, nhất quán, chính xác và liên quan. Về cơ bản, chúng tôi áp dụng các định nghĩa được sử dụng làm hướng dẫn cho đánh giá con người vào phương pháp của chúng tôi như được hiển thị dưới đây:

Tính mạch lạc: Câu trả lời nên được cấu trúc tốt và tổ chức tốt và không chỉ là một đống thông tin liên quan.
Tính liên quan: Câu trả lời nên liên quan đến câu hỏi và ngữ cảnh. Câu trả lời nên ngắn gọn và tránh lệch khỏi câu hỏi được đặt ra.
Tính nhất quán thực tế: Ngữ cảnh nên là nguồn chính cho câu trả lời. Câu trả lời không nên chứa các sự kiện bịa đặt và nên kéo theo thông tin có trong ngữ cảnh.
Độ chính xác: Câu trả lời nên thỏa đáng và đầy đủ cho câu hỏi được đặt ra. Đo lường tính đúng đắn của câu trả lời bằng cách kiểm tra xem phản hồi có trả lời câu hỏi được trình bày không.

Chúng tôi nhắc GPT-4 đánh giá câu trả lời trên thang điểm từ 0 đến 3 (càng cao càng tốt) trên tất cả bốn chỉ số. Chúng tôi tính trung bình tất cả các điểm số thu được từ GPT-4 và trình bày kết quả trong Bảng 3. Lời nhắc đánh giá của chúng tôi có thể được tìm thấy trong Phụ lục A.3.1.

Chúng tôi đưa ra giả thuyết rằng một lời nhắc tối ưu nên luôn ưu tiên câu trả lời của con người và không thiên vị về câu trả lời được tạo bởi mô hình. Laskar et al. (2023) cho thấy rằng LLM như ChatGPT vẫn kém hiệu suất so với con người trên bộ dữ liệu TruthfulQA (Lin et al., 2022). Do đó, chúng tôi thực hiện kiểm tra proxy với GPT-4 trên bộ dữ liệu TruthfulQA để xác minh độ tin cậy và tính trung thực của lời nhắc đánh giá của chúng tôi. Chúng tôi kiểm tra các câu trả lời được tạo từ ChatGPT và LLM mã nguồn mở so với ground truth trên 50 instance thử nghiệm được lấy mẫu ngẫu nhiên và thấy rằng lời nhắc đánh giá của chúng tôi với lời nhắc GPT-4 ưu tiên câu trả lời được viết bởi con người về tính nhất quán thực tế và tính đúng đắn hơn những câu được tạo bởi mô hình hơn > 90% thời gian. Ngoài ra, chúng tôi cũng thực hiện đánh giá con người về câu trả lời được tạo bởi LLM và thảo luận về tương quan của đánh giá GPT-4 với đánh giá con người trong Phần A.4.

4.2 Kết quả
Kết quả thí nghiệm của chúng tôi cho thấy ChatGPT vượt trội hơn các LLM khác trong tất cả các chỉ số với khoảng cách lớn từ 22.4% - 40.1% so với LLM hoạt động tốt thứ hai

--- TRANG 4 ---
[Hình 1: Các biểu đồ cho thấy phân tích các mô hình theo các chỉ số khác nhau được sử dụng trong đánh giá: (a) Tính mạch lạc (b) Tính liên quan (c) Độ chính xác Câu trả lời (d) Tính nhất quán Thực tế]

Mô hình QG-Passage QG-Summary
w/o context w/ context w/o context w/ context
ChatGPT 2.78 2.93 2.67 2.82
Alpaca-13B 2.27 2.09 2.04 2.09
LlaMa-13B 1.22 1.47 0.98 1.28
Alpaca-7B 2.04 1.96 1.64 1.89
LlaMa-7B 0.89 1.12 0.66 0.78

Bảng 3: Hiệu suất của các mô hình khác nhau dựa trên đánh giá GPT-4. Bảng hiển thị điểm số trung bình trên tất cả các chỉ số: độ chính xác, tính mạch lạc, tính nhất quán, tính liên quan.

(Alpaca-13B). Tuy nhiên; tất cả các mô hình bao gồm ChatGPT tạo ra câu trả lời ít chính xác và liên quan hơn cho QG-Summary khi so sánh với QG-Passage; trong khi khoảng cách lớn hơn nhiều trong LLM mã nguồn mở. Chúng tôi cũng thấy rằng hầu hết LLM thấy ngữ cảnh quan trọng để tạo ra câu trả lời; tuy nhiên, khoảng cách nhỏ hơn nhiều cho QG-Passage (khoảng cách trung bình 0.12 so với 0.2). Đáng ngạc nhiên, các mô hình Alpaca-7B, 13B hoạt động tốt hơn w/o context cho QG-Passage. Chúng tôi đưa ra giả thuyết rằng các câu hỏi được tạo trực tiếp từ đoạn văn ngữ cảnh có thể đơn giản và có thể được trả lời trực tiếp từ kiến thức tham số của LLM mà không cần ngữ cảnh bổ sung. Khi phân tích thêm, chúng tôi quan sát thấy rằng hiệu suất Alpaca-7B,13B giảm đáng kể trong các ngữ cảnh dài hơn (Hình 2). Chúng tôi đưa ra giả thuyết rằng trong thiết lập độ dài chuỗi bị hạn chế, việc thêm ngữ cảnh hỗ trợ (ngay cả đoạn văn vàng) có thể không phải lúc nào cũng hữu ích. Chúng tôi để lại phân tích thêm cho nghiên cứu tương lai và hy vọng phân tích của chúng tôi sẽ thúc đẩy các hướng nghiên cứu tương lai để nghiên cứu khi nào nên thêm/không thêm ngữ cảnh cho các nhiệm vụ khác nhau.

Hiệu suất của LLM trên các chỉ số khác nhau Hình 1 trình bày hiệu suất của các mô hình trên các chỉ số khác nhau cho QG-Summary. Chúng tôi quan sát hai xu hướng: (1) LLM cơ sở mã nguồn mở (Llama-7B,13B) gặp khó khăn đáng kể ở tất cả các mặt về chất lượng câu trả lời được tạo trong khi các mô hình được chưng cất hoạt động tốt hơn các đối tác của chúng (Llama) trên tất cả các thiết lập. (2) QG-Summary cung cấp thiết lập thách thức hơn cho tất cả LLM: cụ thể, chúng tôi nhận thấy rằng sự suy giảm điểm số tính mạch lạc là không đáng kể trên ChatGPT và Alpaca-13B trong khi các chỉ số khác như tính liên quan, độ chính xác câu trả lời

[Hình 2: Hiệu suất (điểm số trung bình) của LLM trên độ dài ngữ cảnh khác nhau.]

và tính nhất quán thực tế suy giảm liên tục. Chúng tôi thấy LLM mã nguồn mở lệch khỏi câu hỏi, tạo ra câu trả lời đúng một phần và lặp lại thường xuyên hơn trong thiết lập QG-Summary dẫn đến điểm số thấp hơn. Điều này tiếp tục xác nhận rằng phương pháp đánh giá đề xuất của chúng tôi QG-Summary thách thức LLM về khả năng lý luận sâu hơn.

Phân tích Độ dài Ngữ cảnh Chúng tôi phân tích ảnh hưởng của độ dài ngữ cảnh trên các LLM trong thiết lập đề xuất của chúng tôi (QG-Summary). Như mong đợi, ChatGPT vẫn mạnh mẽ với độ dài ngữ cảnh cho đến 2k token với các biến thể Llama hoạt động tệ hơn các mô hình khác (Hình 2). Thú vị, chúng tôi thấy các mô hình được chưng cất (Alpaca) nhất quán cho đến 1024 token, tuy nhiên vượt quá > 1024 token, hiệu suất suy giảm với tốc độ cao hơn Llama.

5 Kết luận
Với sự xuất hiện của các LLM như ChatGPT và các LLM mã nguồn mở thành công, việc hiểu khả năng và hạn chế của các LLM khác nhau là cực kỳ quan trọng. Để kiểm tra khả năng lý luận sâu hơn của LLM bằng cách tham chiếu đến các ngữ cảnh dài hơn, chúng tôi đánh giá câu trả lời được tạo bởi LLM trên các câu hỏi được tạo bởi ChatGPT trên tóm tắt của các tài liệu dài. Kết quả cho thấy rằng phương pháp tạo câu hỏi đề xuất của chúng tôi đặt ra một thiết lập thách thức cho LLM và làm sáng tỏ khoảng cách hiệu suất giữa các LLM khổng lồ và LLM mã nguồn mở. Chúng tôi hy vọng phân tích của chúng tôi thúc đẩy các hướng nghiên cứu tương lai như tận dụng các ngữ cảnh dài hơn trong thiết lập độ dài chuỗi bị hạn chế và phát triển tạo văn bản dạng dài tốt hơn cho các LLM nhỏ hơn.

--- TRANG 5 ---
6 Hạn chế
Trong nghiên cứu này, chúng tôi đề xuất một thiết lập đánh giá tự động để tạo câu hỏi từ tóm tắt, và các câu trả lời được tạo từ LLM được đánh giá bằng GPT-4 cho các chỉ số khác nhau. Kết quả thực nghiệm cho thấy thiết lập đánh giá đề xuất của chúng tôi chứng minh là một thiết lập thách thức cho LLM. Tuy nhiên, nghiên cứu của chúng tôi có thể có một số hạn chế.

GPT-4 làm người đánh giá Trong khi GPT-4 đã cho thấy tương quan cao với đánh giá con người cho tạo văn bản dạng dài (Liu et al., 2023), khả năng sử dụng GPT-4 để đánh giá là một lĩnh vực nghiên cứu tích cực. Do đó, kết quả của chúng tôi có thể bị giới hạn bởi các khả năng chưa được khám phá của GPT-4.

ChatGPT để tạo câu hỏi Việc tạo câu trả lời trên các câu hỏi được nhắc từ ChatGPT có thể dẫn đến kết quả lạc quan của ChatGPT. Tuy nhiên, tồn tại các hạn chế với các đường cơ sở khác để tạo ra các câu hỏi có ý nghĩa. Chúng tôi hiển thị phân tích mở rộng về việc sử dụng LLM khác để tạo câu hỏi (Phụ lục A.2).

Dữ liệu huấn luyện không rõ Ít được biết về phân phối dữ liệu huấn luyện của các LLM khổng lồ như ChatGPT. Các mô hình được huấn luyện với các phương pháp và phân phối dữ liệu khác nhau làm cho việc đánh giá để so sánh công bằng khó khăn hơn.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được dịch theo cấu trúc gốc...]

--- TRANG 6 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 7 ---
A Phụ lục
A.1 Lời nhắc được sử dụng cho Tạo Câu hỏi
Theo phân tích từ các nghiên cứu trước (Kočiský et al., 2018; Pang et al., 2022), chúng tôi hình thành phương pháp tạo câu hỏi của mình như một quy trình hai bước: (1) Tóm tắt và (2) Tạo câu hỏi từ tóm tắt. Trong bước đầu tiên, chúng tôi thiết kế lời nhắc để tạo tóm tắt như được hiển thị dưới đây:

Tóm tắt các đoạn văn dưới đây trong ngữ cảnh của {title} trong {domain}.

Trong bước tiếp theo, chúng tôi yêu cầu ChatGPT tạo câu hỏi từ tóm tắt như được hiển thị dưới đây:

Sử dụng ngữ cảnh dưới đây, hãy đưa ra các câu hỏi tiếp theo. Xếp hạng các câu hỏi được tạo theo thứ tự độ phức tạp giảm dần để trả lời và chỉ hiển thị 3 câu hỏi hàng đầu. {context}

Để chứng minh tính hữu ích của quy trình tạo câu hỏi của chúng tôi, chúng tôi cũng thiết lập một đường cơ sở với cùng hướng dẫn nơi các câu hỏi được tạo trực tiếp từ đoạn văn. Lời nhắc được sử dụng cho đường cơ sở là:

Sử dụng ngữ cảnh dưới đây, hãy đưa ra ba câu hỏi. Xếp hạng các câu hỏi được tạo theo thứ tự độ phức tạp giảm dần để trả lời và chỉ hiển thị 3 câu hỏi hàng đầu. {context}

A.2 Tạo Câu hỏi sử dụng LLM mã nguồn mở
Để tạo ra một thiết lập đánh giá công bằng, chúng tôi nhắc các mô hình Alpaca-7B,13B để tóm tắt và tạo câu hỏi trên 50 instance. Chúng tôi không xem xét tạo câu hỏi từ các mô hình không được điều chỉnh hướng dẫn (ví dụ: Llama). Từ phương pháp đánh giá của chúng tôi về câu hỏi được tạo như được mô tả trong Phần 4, chúng tôi thấy các câu hỏi được tạo từ Alpaca không thể trả lời được (không tồn tại trong ngữ cảnh) và chứa nội dung vô nghĩa hơn 80% thời gian. Bảng dưới đây trình bày đánh giá của chúng tôi về tạo câu hỏi từ Alpaca:

A.2.1 Đánh giá Tạo Câu hỏi sử dụng ChatGPT
Để xác minh độ phức tạp của các câu hỏi được tạo như được nêu trong Phần 4, chúng tôi nhắc ChatGPT với lời nhắc sau: Chúng tôi muốn yêu cầu phản hồi của bạn về việc xác định độ phức tạp của các câu hỏi được tạo

Chỉ số Đánh giá QG - Passage QG - Summary
Q1: Không mơ hồ 12.5% 8.3%
Q2. Độ dài Ngữ cảnh:
Một câu hoặc ít hơn một đoạn văn 98.8% 98.5%
Ít nhất một phần ba hoặc hầu hết đoạn văn 1.2% 1.5%
Q3: Đọc nhiều lần qua đoạn văn 0% 0%

Bảng 4: Lời nhắc được thiết kế để đánh giá độ phức tạp của các câu hỏi được tạo trên Alpaca.

bởi một trợ lý AI đối với ngữ cảnh được hiển thị ở trên.\n\n Đối với mỗi câu hỏi, hãy đánh giá độ phức tạp của mỗi câu hỏi được tạo cho các chiều: tính mơ hồ, ngữ cảnh và khả năng lý luận. \n\n Q1: Câu hỏi có thể trả lời được từ ngữ cảnh đã cho và không mơ hồ không? A. Có B. Không \n\n Q2. Cần bao nhiều đoạn văn làm ngữ cảnh để trả lời câu hỏi? A. Chỉ một hoặc hai câu từ đoạn văn B. Hơn 2 câu nhưng ít hơn một đoạn văn C. Ít nhất một phần ba của toàn bộ ngữ cảnh đã cho D. Hầu hết ngữ cảnh đã cho \n\n Q3: Câu hỏi có đòi hỏi nhiều lần đọc qua đoạn văn không? A. Có B. Không. Giả sử bạn không có kiến thức trước về chủ đề ngoài ngữ cảnh được cung cấp cho bạn. Vui lòng xuất ra lựa chọn của bạn dưới dạng từ điển. (ví dụ: 'Q1': '<lựa chọn câu trả lời của bạn cho Q1>', 'Q2': '<lựa chọn câu trả lời của bạn cho Q2>', 'Q3': '<lựa chọn câu trả lời của bạn cho Q3>', 'Q4': '<lựa chọn câu trả lời của bạn cho Q4>'). \n\n Trong dòng tiếp theo, vui lòng cung cấp giải thích toàn diện về đánh giá của bạn, tránh mọi thiên kiến tiềm ẩn và đảm bảo rằng thứ tự trình bày các phản hồi không ảnh hưởng đến phán đoán của bạn.

Vì LLM được huấn luyện với các hỗn hợp dữ liệu huấn luyện khác nhau, chúng tôi đặc biệt yêu cầu ChatGPT trả lời các câu hỏi chỉ dựa trên ngữ cảnh đã cho.

A.2.2 Lời nhắc cho Tạo Câu trả lời
Để tạo phản hồi trên các câu hỏi được tạo bởi LLM, chúng tôi nhắc như sau: Đối với mỗi câu hỏi được tạo, chúng tôi nhắc các mô hình như sau:

Dựa trên ngữ cảnh, hãy trả lời câu hỏi dưới đây:
Ngữ cảnh: {context}
Câu hỏi: {question}
Câu trả lời: {Answer}

A.3 GPT-4 làm Người đánh giá
A.3.1 Lời nhắc được sử dụng trong Đánh giá GPT-4
Để đánh giá các câu trả lời được tạo bởi LLM, chúng tôi yêu cầu GPT-4 đánh giá câu trả lời trên thang Likert từ 0 đến 3 (càng cao càng tốt) trên tất cả bốn chỉ số sau: tính mạch lạc, tính liên quan, độ chính xác và tính nhất quán thực tế. Lời nhắc đánh giá của chúng tôi được sử dụng làm lời nhắc cho GPT-4 được hiển thị dưới đây:

lời nhắc hệ thống: Bạn là một trợ lý hữu ích và chính xác để kiểm tra chất lượng câu trả lời trên 4 khía cạnh: tính mạch lạc, tính liên quan, tính nhất quán thực tế, độ chính xác. lời nhắc: Chúng tôi muốn yêu cầu điểm số và phản hồi của bạn về hiệu suất của hai trợ lý AI để trả lời câu hỏi của người dùng dựa trên ngữ cảnh được hiển thị ở trên. Vui lòng đánh giá chất lượng câu trả lời trên 4 chỉ số: tính mạch lạc, tính liên quan, tính nhất quán thực tế và độ chính xác. Định nghĩa của mỗi chỉ số được cung cấp cho bạn. Tính mạch lạc - Câu trả lời nên được cấu trúc tốt và tổ chức tốt. Tính liên quan - Câu trả lời nên liên quan đến câu hỏi và ngữ cảnh. Câu trả lời cũng nên tránh lệch khỏi câu hỏi được đặt ra. Tính nhất quán thực tế - Ngữ cảnh nên là nguồn chính cho câu trả lời. Câu trả lời không nên chứa các sự kiện bịa đặt và nên kéo theo thông tin có trong ngữ cảnh. Độ chính xác - Phản hồi được cung cấp bởi trợ lý có trả lời câu hỏi một cách chính xác và ngắn gọn không? Cung cấp điểm số cho mỗi phản hồi của trợ lý AI cho mỗi chỉ số được định nghĩa ở trên trên thang điểm từ 0 đến 3 trong đó điểm số cao hơn có nghĩa là hiệu suất tốt hơn. Đừng so sánh hiệu suất giữa các trợ lý AI và đánh giá chúng riêng lẻ. Nhập hai dòng mới. Tiếp theo, vui lòng cung cấp giải thích toàn diện về câu trả lời ưa thích của bạn trong cả hai và đánh giá của bạn, tránh mọi thiên kiến tiềm ẩn và đảm bảo rằng thứ tự

Chỉ số Điểm số Cohen-Kappa
Tính mạch lạc 0.66
Tính liên quan 0.7
Độ chính xác 0.66
Tính nhất quán thực tế 0.56

Bảng 5: Điểm số thỏa thuận của người chú thích với GPT-4

trình bày các phản hồi không ảnh hưởng đến phán đoán của bạn. Vui lòng lưu ý rằng điểm số của bạn nên ở định dạng từ điển như ví dụ được cung cấp cho bạn. Ví dụ: 'Trợ lý 1': 'tính mạch lạc': <điểm số int>, 'tính liên quan': <điểm số int>, 'tính nhất quán thực tế': <điểm số int>, 'độ chính xác': <điểm số int>, 'Trợ lý 2': ... 'Giải thích': '<Ưu tiên: Trợ lý 1 hoặc Trợ lý 2 hoặc Cả hai hoặc Không có>. <giải thích của bạn>'.

A.4 Nghiên cứu Trường hợp: Đánh giá Con người so với GPT-4
Chúng tôi chú thích 50 cặp QA để đánh giá chất lượng câu trả lời được tạo bởi LLM độc lập với điểm số GPT-4. Hai người chú thích được cung cấp các hướng dẫn tương tự như được nêu trong Phần 4 và một bảng câu hỏi như GPT-4 (Phần A.3.1). Để đánh giá công bằng, chúng tôi không tiết lộ mô hình đã tạo ra câu trả lời cho người chú thích. Bảng 5 bao gồm điểm số thỏa thuận của đánh giá con người với GPT-4. Điểm số thỏa thuận cao trên các chỉ số khác nhau về tạo văn bản tự do cho thấy rằng phương pháp đánh giá của chúng tôi sử dụng GPT-4 là đáng tin cậy. Chúng tôi cũng trình bày một số ví dụ định tính trong Phụ lục (Bảng 6)

A.5 Thu thập Dữ liệu
Chúng tôi sử dụng API Wikipedia để thu thập các bài viết để tạo ra thiết lập đánh giá của chúng tôi. Tuy nhiên, chúng tôi thấy không phải tất cả các bài viết đều có thể hữu ích cho thiết lập của chúng tôi; như các bài viết Wikipedia chứa liên kết tham khảo, danh sách chủ đề, từ điển thuật ngữ, v.v. Chúng tôi áp dụng hai cấp độ lọc: (1) Chúng tôi loại bỏ bất kỳ bài viết nào có < 2k token (2) chúng tôi soạn một danh sách các phần không mang tính thông tin và lọc những phần đó khỏi xem xét trong nghiên cứu này. ['References', 'See also', 'Notes', 'Sources', 'External links', 'History', 'Further reading']

A.6 Ví dụ Định tính
Bảng dưới đây trình bày các ví dụ định tính từ nhiệm vụ chú thích con người và cho thấy một số điểm số bởi con người và GPT-4.

--- TRANG 9 ---
[Tiếp tục với các ví dụ định tính và bảng...]

--- TRANG 10 ---
Ví dụ Định tính
Câu hỏi 1: Sự khác biệt giữa nghiên cứu liên ngành và chuyên môn hóa trong một ngành duy nhất là gì?
Đánh giá: Vấn đề - Không có, Điểm số Con người - 3, GPT-4 - 3
ChatGPT: Nghiên cứu liên ngành bao gồm việc áp dụng các phương pháp và cách tiếp cận của nhiều ngành khác nhau cho một chủ đề, trong khi chuyên môn hóa trong một ngành duy nhất bao gồm nghiên cứu sâu và chuyên môn trong một chủ đề duy nhất.
Đánh giá: Vấn đề - Lặp lại, Điểm số Con người - 2, GPT-4 - 2
Alpaca-13B: Nghiên cứu liên ngành là sự kết hợp của hai hoặc nhiều ngành để tạo ra một lĩnh vực nghiên cứu mới. Chuyên môn hóa là tập trung vào một ngành duy nhất, với mục tiêu trở thành chuyên gia trong lĩnh vực đó. Nghiên cứu liên ngành là sự kết hợp của hai hoặc nhiều ngành để tạo ra một lĩnh vực nghiên cứu mới. Chuyên môn hóa là tập trung vào một ngành duy nhất, với mục tiêu trở thành chuyên gia trong lĩnh vực đó.

Câu hỏi 2: Quản lý tài sản tốt đòi hỏi lãnh đạo, giao tiếp, hợp tác và cải tiến liên tục như thế nào?
Đánh giá: Vấn đề - Không có, Điểm số Con người - 3, GPT-4 - 3
Alpaca-13B: Quản lý tài sản tốt đòi hỏi lãnh đạo, giao tiếp, hợp tác và cải tiến liên tục. Lãnh đạo được yêu cầu để đặt ra các ưu tiên chiến lược và đảm bảo rằng tổ chức phù hợp với các mục tiêu. Giao tiếp được yêu cầu để đảm bảo rằng tổ chức nhận thức được các mục tiêu và các chiến lược để đạt được chúng. Hợp tác được yêu cầu để đảm bảo rằng tổ chức đang làm việc cùng nhau để đạt được các mục tiêu. Cải tiến liên tục được yêu cầu để đảm bảo rằng tổ chức liên tục cố gắng cải thiện hiệu suất của mình.
Đánh giá: Vấn đề - Độ chính xác, Điểm số Con người - 1, GPT-4 - 1
Alpaca-7B: Quản lý tài sản tốt đòi hỏi lãnh đạo, giao tiếp, hợp tác và cải tiến liên tục.

Câu hỏi 3: Bốn lĩnh vực mà CSAB cho là quan trọng đối với ngành khoa học máy tính là gì?
Đánh giá: Vấn đề - Tính nhất quán Thực tế, Điểm số Con người - 1, GPT-4 - 3
Alpaca-7B: 1. Lý thuyết tính toán 2. Lý thuyết tính toán 3. Lý thuyết ngôn ngữ lập trình 4. Phương pháp hình thức
ChatGPT: Bốn lĩnh vực mà CSAB cho là quan trọng đối với ngành khoa học máy tính là lý thuyết tính toán, thuật toán và cấu trúc dữ liệu, phương pháp và ngôn ngữ lập trình, và các yếu tố và kiến trúc máy tính.

Bảng 6: Một số ví dụ về câu trả lời được tạo từ LLM với đánh giá GPT-4 và con người
Chú thích LLM, Sự không nhất quán bị bỏ lỡ bởi mô hình Sự không nhất quán được phát hiện bởi GPT-4.

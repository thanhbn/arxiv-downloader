# 2406.10996.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2406.10996.pdf
# Kích thước tệp: 6565493 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Hướng tới Các Tác nhân Đối thoại Suốt đời thông qua
Quản lý Bộ nhớ Dựa trên Dòng thời gian
Kai Tzu-iunn Ong1*Namyoung Kim1∗Minju Gwak1Hyungjoo Chae1
Taeyoon Kwon1Yohan Jo2Seung-won Hwang2Dongha Lee1Jinyoung Yeo1
1Đại học Yonsei,2Đại học Quốc gia Seoul
{ktio89, namyoung.kim, jinyeo}@yonsei.ac.kr

Tóm tắt
Để đạt được tương tác suốt đời giữa con người và tác nhân, các tác nhân đối thoại cần liên tục ghi nhớ thông tin được nhận và truy xuất một cách phù hợp để tạo ra phản hồi (RG). Trong khi các nghiên cứu trước tập trung vào việc loại bỏ những ký ức lỗi thời để cải thiện chất lượng truy xuất, chúng tôi cho rằng những ký ức như vậy cung cấp những manh mối ngữ cảnh phong phú, quan trọng cho RG (ví dụ, sự thay đổi trong hành vi của người dùng) trong các cuộc trò chuyện dài hạn. Chúng tôi trình bày THEANINE, một khung cho các tác nhân đối thoại suốt đời dựa trên LLM. THEANINE loại bỏ việc xóa bộ nhớ và quản lý bộ nhớ quy mô lớn bằng cách liên kết chúng dựa trên mối quan hệ thời gian và nhân-quả. Được hỗ trợ bởi cấu trúc liên kết này, THEANINE tăng cường RG với dòng thời gian bộ nhớ - chuỗi ký ức thể hiện sự phát triển hoặc tính nhân quả của các sự kiện quá khứ liên quan. Cùng với THEANINE, chúng tôi giới thiệu TeaFarm, một sơ đồ đánh giá hướng phản thực, giải quyết hạn chế của G-Eval và nỗ lực con người khi đánh giá hiệu suất tác nhân trong việc tích hợp ký ức quá khứ vào RG. Video bổ sung cho THEANINE và dữ liệu cho TeaFarm có tại https://huggingface.co/spaces/ResearcherScholar/Theanine.

1 Giới thiệu
Các tác nhân tự động dựa trên mô hình ngôn ngữ lớn (LLM) đã đạt được tiến bộ đáng kể trong nhiều lĩnh vực khác nhau, bao gồm tạo phản hồi (Chae et al., 2024; Kwon et al., 2024; Tseng et al., 2024), nơi các tác nhân phải liên tục theo dõi cả thông tin cũ và mới được giới thiệu chia sẻ với người dùng trong suốt vòng đời phục vụ của chúng (Irfan et al., 2024) và trò chuyện tương ứng. Để tạo điều kiện cho tương tác suốt đời như vậy, các nghiên cứu đã đề xuất tăng cường khả năng ghi nhớ và gọi lại chính xác thông tin quá khứ của các tác nhân đối thoại (ví dụ, các chủ đề đã thảo luận) trong các cuộc trò chuyện dài hạn, đa phiên.

Một cách tiếp cận đại diện là nén các cuộc trò chuyện trước đây thành ký ức tóm tắt và truy xuất chúng để tăng cường tạo phản hồi (RG) trong các cuộc gặp sau này (Xu et al., 2022a; Lu et al., 2023). Tuy nhiên, khoảng cách ngày càng tăng của ký ức có thể cản trở chất lượng truy xuất khi các cuộc trò chuyện tích lũy. Mặc dù điều này có thể được giải quyết một phần bằng cách cập nhật ký ức cũ (Bae et al., 2022; Zhong et al., 2024), thực hành phổ biến như vậy có thể gây mất thông tin nghiêm trọng. Như được hiển thị trong Hình 1 (a), một ký ức trước đó trên dòng thời gian, một tính cách quan trọng ("sợ tàu thuyền"), bị xóa trong quá trình cập nhật bộ nhớ, dẫn đến RG không phù hợp. Trong khi việc sử dụng cửa sổ ngữ cảnh lớn của các LLM gần đây để xử lý tất cả lịch sử đối thoại/ký ức là một lựa chọn để ngăn chặn mất thông tin như vậy, điều này thường dẫn đến sự chú ý thiên lệch đối với đầu vào người dùng mới nhất (Hình 1 (b)), bỏ qua các ngữ cảnh liên quan từ quá khứ (Liu et al., 2024). Những phát hiện này làm nổi bật hai thách thức chính hướng tới các tác nhân đối thoại suốt đời - (i) Xây dựng bộ nhớ: làm thế nào để lưu trữ hiệu quả các tương tác quá khứ quy mô lớn mà không loại bỏ ký ức cũ? (ii) Tạo phản hồi: trong khoảng cách bộ nhớ ngày càng tăng, làm thế nào để xác định các manh mối ngữ cảnh liên quan để tạo phản hồi phù hợp?

Được thúc đẩy bởi những điều này, chúng tôi đề xuất giải quyết hai thách thức trên một cách riêng biệt nhưng bổ sung, bằng cách (i) loại bỏ việc cập nhật bộ nhớ để tránh mất thông tin và bảo tồn các ký ức liên quan trên dòng thời gian trong cấu trúc liên kết; và (ii) truy xuất dòng thời gian như một tổng thể để nắm bắt tốt hơn các ký ức liên quan trong khoảng cách tìm kiếm ngày càng tăng.

Chúng tôi trình bày THEANINE, một khung để tạo điều kiện cho các tác nhân đối thoại suốt đời.

Bắt đầu từ xây dựng bộ nhớ (Giai đoạn I), thay vì xếp chồng các câu bộ nhớ thô như vậy (Xu et al., 2022a), điều có thể ảnh hưởng đến việc truy xuất bộ nhớ và cũng chất lượng phản hồi do định dạng thông tin không có cấu trúc (Mousavi et al., 2023; Chen et al., 2023), THEANINE lưu trữ ký ức trong một đồ thị có hướng. Trong đồ thị này, được lấy cảm hứng từ cách con người tự nhiên liên kết ký ức mới với những ký ức hiện có của các sự kiện liên quan dựa trên mối quan hệ của chúng (Bartlett, 1995), các ký ức được liên kết bằng cách sử dụng mối quan hệ thời gian và nhân-quả thường thức của chúng (Hwang et al., 2021). Được hỗ trợ bởi cấu trúc liên kết như vậy, trong việc truy xuất bộ nhớ cho RG (Giai đoạn II-1), chúng tôi vượt ra ngoài việc truy xuất top-k thông thường và tiếp tục thu được các dòng thời gian hoàn chỉnh để tránh bỏ lỡ các ký ức quan trọng có sự chồng chéo văn bản thấp với cuộc trò chuyện hiện tại (Tao et al., 2023). Cuối cùng, để giải quyết sự bất đồng giữa xây dựng bộ nhớ ngoại tuyến và triển khai trực tuyến, THEANINE sử dụng LLM để tinh chỉnh các dòng thời gian được truy xuất (Giai đoạn II-2) dựa trên cuộc trò chuyện hiện tại, sao cho chúng cung cấp thông tin phù hợp (Chae et al., 2023) cho RG (Giai đoạn III). Đóng góp của chúng tôi có hai mặt:

• Để đạt được các tác nhân đối thoại suốt đời, chúng tôi trình bày THEANINE, một khung dựa trên LLM với đồ thị bộ nhớ nhận thức về mối quan hệ và tăng cường dòng thời gian cho các cuộc trò chuyện dài hạn. THEANINE vượt trội hơn các đường cơ sở đại diện trên các đánh giá tự động, dựa trên LLM và con người về RG. Ngoài ra, chúng tôi xác nhận rằng THEANINE dẫn đến chất lượng truy xuất cao hơn, và các quy trình của nó phù hợp với sở thích của con người. Theo hiểu biết của chúng tôi, chúng tôi là người đầu tiên mô hình hóa việc sử dụng dòng thời gian (tức là, các ký ức liên quan được liên kết) trong quản lý bộ nhớ và tạo phản hồi.

• Việc thiếu ánh xạ vàng giữa các cuộc trò chuyện và ký ức tham chiếu đặt ra thách thức trong việc đánh giá các tác nhân được tăng cường bộ nhớ. Chúng tôi trình bày TeaFarm, một đường ống hướng phản thực đánh giá hiệu suất tác nhân trong việc tham chiếu quá khứ mà không cần can thiệp của con người.

--- TRANG 2 ---

Chúng tôi trình bày THEANINE, một khung cho các tác nhân đối thoại suốt đời lấy cảm hứng từ cách con người lưu trữ và truy xuất ký ức cho các cuộc trò chuyện (Hình 2):

2.1 Xây dựng Đồ thị Bộ nhớ (Giai đoạn I)

Để quản lý bộ nhớ quy mô lớn và tạo điều kiện cho thông tin có cấu trúc cho RG (Mousavi et al., 2023; Chen et al., 2023), chúng tôi tiếp cận quản lý bộ nhớ bằng cách sử dụng đồ thị bộ nhớ G:

G = (V, E) (1)
V = {m1, m2, ..., m|V|} (2)
m = (event, time) (3)
E = {⟨mi, rij, mj⟩|mi, mj ∈ V ∧ rij ∈ R} (4)
R = {Cause, Reason, Want, ..., SameTopic} (5)

Trong G, đỉnh V là những ký ức m được tóm tắt từ các cuộc trò chuyện. Mỗi ký ức m = (event, time) bao gồm một sự kiện và thời gian nó được hình thành (tóm tắt). Mỗi cạnh có hướng e ∈ E giữa hai m được kết nối chỉ ra thứ tự thời gian của chúng và mối quan hệ nhân-quả thường thức r ∈ R:

Vào cuối phiên đối thoại t, THEANINE bắt đầu liên kết mỗi ký ức mới mnew được tóm tắt từ phiên t vào đồ thị bộ nhớ Gt.

Giai đoạn I-1: Xác định các ký ức liên kết để liên kết bộ nhớ. Theo cách con người liên kết ký ức mới với những ký ức hiện có liên quan đến sự kiện/chủ đề tương tự, tức là các ký ức liên kết, THEANINE bắt đầu bằng cách xác định những ký ức liên kết này từ đồ thị bộ nhớ Gt.

Một cách chính thức, cho một ký ức mới mnew đang chờ được lưu trữ, các ký ức liên kết Ma của mnew được định nghĩa là tập hợp các mi ∈ G có độ tương đồng văn bản top-j với mnew (tức là, |Ma| = j).

Giai đoạn I-2: Liên kết bộ nhớ nhận thức về mối quan hệ. Một cách trực quan, chúng ta có thể liên kết mnew với m ∈ Ma bằng cách sử dụng các cạnh chỉ ra độ tương đồng văn bản và thứ tự thời gian của chúng, chúng tôi thấy rằng kết nối đơn giản hóa như vậy (ví dụ, "điều này xảy ra → sự kiện tương tự đó xảy ra") có thể tạo ra một đồ thị nghèo ngữ cảnh không giúp ích nhiều cho việc tạo phản hồi (Phần 4).

Mặt khác, con người diễn giải các sự kiện bằng cách xem xét mối quan hệ giữa chúng, chẳng hạn như "một sự kiện ảnh hưởng đến sự kiện khác như thế nào?" hoặc "tại sao người này lại thực hiện thay đổi đó?". Do đó, chúng tôi áp dụng liên kết bộ nhớ nhận thức về mối quan hệ, trong đó một cạnh giữa hai ký ức được mã hóa với mối quan hệ nhân-quả thường thức r ∈ R của chúng, cùng với thứ tự thời gian. Trong thực tế, chúng tôi áp dụng các mối quan hệ thường được sử dụng được định nghĩa bởi Hwang et al. (2021), bao gồm HinderedBy, Cause, Want, và 4 mối quan hệ khác (Phụ lục B.1).

Chúng tôi bắt đầu bằng cách xác định mối quan hệ giữa mnew và mỗi ký ức liên kết. Một cách chính thức, đối với mỗi cặp mnew và m ∈ Ma, LLM gán một mối quan hệ r ∈ R dựa trên event, time và các cuộc trò chuyện gốc của chúng:

M*a = {mi ∈ Ma|Υ(mi, mnew) ∈ R} (6)

trong đó Υ(·, mnew) ∈ R chỉ ra rằng ký ức đã cho được gán với một r ∈ R với mnew, và những ký ức được gán như vậy được định nghĩa là M*a.

Sau đó chúng tôi tiến hành liên kết mnew vào đồ thị. Trước tiên chúng tôi xác định vị trí của mọi thành phần liên thông Ci ⊂ Gt chứa ít nhất một m ∈ M*a, như được hiển thị trong Hình 3 (a) và (b):

C = {Ci ⊂ Gt|V(Ci) ∩ M*a ≠ ∅} (7)

trong đó C là tập hợp của những C và V(·) đại diện cho "các đỉnh trong". Sau đó, chúng tôi liên kết mnew với m ∈ M*a gần đây nhất trong mỗi Ci ⊂ C (Hình 3 (c)). Các ký ức Mlinked được liên kết với mnew được định nghĩa như sau:

Mlinked = {Ω(V(Ci) ∩ M*a)|Ci ⊂ C} (8)

trong đó Ω(·) chỉ ra "ký ức gần đây nhất trong".

Liên kết tất cả các ký ức từ phiên t vào Gt, sau đó chúng tôi thu được đồ thị bộ nhớ mới Gt+1. Thuật toán giả cho Giai đoạn I có trong Thuật toán 1.

2.2 Truy xuất Dòng thời gian và Tinh chỉnh Dòng thời gian (Giai đoạn II)

Nhờ vào đồ thị bộ nhớ được xây dựng, THEANINE có thể tiến hành tăng cường RG với dòng thời gian của các sự kiện liên quan, giải quyết vấn đề mất thông tin trong quản lý bộ nhớ thông thường (Hình 1).

Với Gt+1, THEANINE thực hiện các bước sau cho RG trong phiên t + 1:

Chuẩn bị: Truy xuất bộ nhớ top-k. Trong cuộc trò chuyện, sử dụng ngữ cảnh đối thoại hiện tại D = {ui}ni=1 của n phát ngôn u làm truy vấn, chúng tôi truy xuất top-k ký ức Mre = {mre1, ..., mrek}.

Giai đoạn II-1: Truy xuất và gỡ rối các dòng thời gian bộ nhớ thô. Chúng tôi muốn cũng truy cập các ký ức tập trung xung quanh Mre. Một cách chính thức, cho mre ∈ Mre, chúng tôi tiếp tục thu thập thành phần liên thông Cre ⊂ Gt+1 chứa mre thông qua cấu trúc liên kết.

Vì tập hợp ký ức này (tức là, Cre) có thể "rối tung lên" cùng nhau (tức là, kết nối theo cách phức tạp) do cấu trúc đồ thị, chúng tôi tiến hành gỡ rối nó thành một số dòng thời gian bộ nhớ, mỗi dòng thể hiện một chuỗi sự kiện về mre bắt đầu tương tự nhưng phân nhánh thành sự phát triển hơi khác. Để làm điều đó, trước tiên chúng tôi xác định vị trí ký ức sớm nhất trong Cre làm điểm bắt đầu mstart cho tất cả các dòng thời gian, như được hiển thị trong Hình 4 (trái).

mstart = Θ(V(Cre)) (9)

trong đó Θ chỉ ra "ký ức lâu đời nhất trong".

Tiếp theo, bắt đầu từ mstart, chúng tôi gỡ rối các ký ức bằng cách truy theo hướng tương lai và trích xuất mọi đồ thị tuyến tính có thể chứa mre (hai trong Hình 4) từ Cre, cho đến khi đạt tới một điểm cuối τ[-1] với bậc ra bằng 0 (tức là, deg+(τ[-1]) = 0), có nghĩa là không có cạnh có hướng nào đi ra từ nó). Mỗi dòng trong số chúng được coi là một dòng thời gian bộ nhớ thô τ, thể hiện một phiên bản của sự phát triển của mre và các sự kiện liên quan của nó:

T = {τ ⊂ Cre|τ là một đồ thị tuyến tính có hướng sao cho mstart, mre ∈ τ ∧ deg+(τ[-1]) = 0} (10)

Sau đó chúng tôi lấy mẫu n dòng thời gian thô τ từ T. Lặp lại Giai đoạn II-1 cho tất cả các ký ức top-k được truy xuất, chúng tôi thu thập một tập hợp các dòng thời gian bộ nhớ thô được truy xuất T = ∪T, trong đó |T| = k * n.

Giai đoạn II-2: Tinh chỉnh dòng thời gian nhận thức về ngữ cảnh. Mặc dù chúng tôi đã xây dựng đồ thị bộ nhớ bằng cách sử dụng các mối quan hệ thời gian và thường thức để cải thiện tính thông tin của nó, việc áp dụng trực tiếp các dòng thời gian được truy xuất cho RG có thể không tối ưu (RQ3, Phần 4), vì việc xây dựng đồ thị không tính đến cuộc trò chuyện hiện tại, tức là chúng được xây dựng ngoại tuyến.

Trong giai đoạn này, THEANINE giải quyết sự bất đồng như vậy giữa xây dựng bộ nhớ ngoại tuyến và triển khai trực tuyến (tức là, cuộc trò chuyện đang diễn ra) thông qua tinh chỉnh dòng thời gian nhận thức về ngữ cảnh. Được thúc đẩy bởi cách các LLM có thể tinh chỉnh việc tạo ra trước đây của chúng (Madaan et al., 2024). Chúng tôi tận dụng các LLM để tinh chỉnh các dòng thời gian thô thành một nguồn tài nguyên thông tin phong phú được tạo ra cho cuộc trò chuyện hiện tại, bằng cách loại bỏ thông tin dư thừa hoặc làm nổi bật thông tin có thể hữu ích. Một cách chính thức, cho cuộc đối thoại hiện tại D và các dòng thời gian thô được truy xuất T, một LLM điều chỉnh τ ∈ T thành các dòng thời gian được tinh chỉnh TΦ:

TΦ = {argmaxτΦ PLLM(τΦ|D, τ)|τ ∈ T} (11)

Tất cả các dòng thời gian được tinh chỉnh TΦ sau đó được sử dụng để tăng cường việc tạo phản hồi. Chúng tôi cung cấp thuật toán giả cho Giai đoạn II trong Thuật toán 2.

2.3 Tạo Phản hồi được Tăng cường Dòng thời gian (Giai đoạn III)

Bây giờ, THEANINE sử dụng các dòng thời gian được tinh chỉnh cho RG. Một cách chính thức, cho D = {ui}ni=1 và TΦ, một LLM tạo ra phản hồi tiếp theo ūt+1:

ūn+1 = argmaxun+1 PLLM(un+1|D, TΦ) (12)

3 Thiết lập Thí nghiệm

3.1 Bộ dữ liệu của Các Cuộc trò chuyện Dài hạn

Có ít bộ dữ liệu cho các cuộc trò chuyện dài hạn, đa phiên. Đầu tiên, Multi-Session Chat (MSC) (Xu et al., 2022a), được xây dựng dựa trên PersonaChat (Zhang et al., 2018) bằng cách mở rộng các cuộc trò chuyện của nó thành nhiều (năm) phiên. Ngay sau MSC, DuLeMon (Xu et al., 2022b) và CareCall (Bae et al., 2022) được đề xuất cho các cuộc trò chuyện dài hạn bằng tiếng Trung và tiếng Hàn. Gần đây, Jang et al. (2023) phát hành một bộ dữ liệu mới, Conversation Chronicles (CC). Không giống như MSC, CC tăng cường người nói với các mối quan hệ được định nghĩa, chẳng hạn như "nhân viên và sếp". Ngoài các bộ dữ liệu miền mở này, Psychological QA giải quyết các cuộc trò chuyện dài hạn trong các tình huống lâm sàng bằng tiếng Trung.

Chúng tôi chọn MSC và CC để đánh giá nhằm tập trung vào các cuộc trò chuyện tiếng Anh, để lại các cuộc trò chuyện đa ngôn ngữ và theo lĩnh vực cụ thể (ví dụ, DuleMon, CareCall và Psychological QA) cho công việc tương lai.

3.2 Đường cơ sở

Để đánh giá THEANINE, ngoài các đường cơ sở ngây thơ sử dụng tất cả các cuộc đối thoại hoặc ký ức trong quá khứ, chúng tôi kết hợp các thiết lập sau:

Truy xuất Bộ nhớ. Theo Xu et al. (2022a), chúng tôi sử dụng một bộ truy xuất để truy xuất các ký ức liên quan đến ngữ cảnh đối thoại hiện tại để tăng cường RG.

Cập nhật Bộ nhớ. Chúng tôi sử dụng các LLM để thực hiện thuật toán cập nhật được sử dụng rộng rãi được đề xuất bởi Bae et al. (2022) vào cuối mỗi phiên đối thoại. Thuật toán này bao gồm các chức năng như Change, Replace, Delete, Append, và nhiều hơn nữa (xem Phụ lục H).

RSum-LLM. Một phương pháp tạo ra chỉ dựa trên LLM đệ quy tóm tắt và cập nhật nhóm bộ nhớ, tạo ra các phản hồi mà không có mô-đun truy xuất (Wang et al., 2023).

MemoChat. Được đề xuất bởi Lu et al. (2023), nó tận dụng khả năng lý luận CoT của LLM để (i) kết luận các ký ức quan trọng từ các cuộc trò chuyện trong quá khứ theo cách chủ đề-tóm tắt-đối thoại có cấu trúc, (ii) chọn ký ức, và (ii) tạo ra phản hồi.

COMEDY. Được đề xuất bởi Chen et al. (2024b), nó sử dụng LLM để tóm tắt ký ức cấp phiên, nén tất cả chúng thành các sự kiện ngắn, chân dung người dùng (các mẫu hành vi, cảm xúc, v.v.) và mối quan hệ người dùng-bot. Sau đó nó chọn các ký ức nén để tăng cường việc tạo phản hồi.

3.3 Mô hình và Chi tiết Triển khai

Mô hình ngôn ngữ lớn. Trong tất cả các thí nghiệm, bao gồm các đường cơ sở, chúng tôi áp dụng gpt-3.5-turbo-0125 (OpenAI, 2023) cho (i) tóm tắt bộ nhớ (Bảng 6), (ii) cập nhật bộ nhớ, và (iii) tạo phản hồi. Nhiệt độ được đặt là 0.75.

Bộ truy xuất. Chúng tôi sử dụng text-embedding-3-small (OpenAI, 2024b) để tính toán độ tương đồng văn bản cho các thiết lập liên quan đến bộ truy xuất. Trong việc xác định các ký ức liên kết top-j (Giai đoạn I-1) và truy xuất bộ nhớ top-k (Giai đoạn II), chúng tôi đặt j và k là 3. Đối với đường cơ sở "Truy xuất Bộ nhớ", chúng tôi đặt k = 6 theo Xu et al. (2022a).

Phiên đối thoại. Chúng tôi sử dụng các phiên 3-5 của MSC và CC để đánh giá, vì tất cả các phương pháp gần như giống hệt nhau trong phiên 1 ∼ 2 (không có bộ nhớ để cập nhật).

4 Sơ đồ Đánh giá 1: Đánh giá Tự động và Con người

Để đánh giá phản hồi của THEANINE trong các cuộc trò chuyện dài hạn, chúng tôi tuân theo các thực hành phổ biến và tiến hành 3 loại đánh giá: (i) Đánh giá tự động; (ii) G-Eval (Liu et al., 2023), một khung dựa trên LLM thường được sử dụng để đánh giá việc tạo ra của LM; (iii) đánh giá con người. Bây giờ chúng tôi trình bày một số phát hiện chính (chi tiết, lời nhắc và giao diện của các đánh giá trong Sơ đồ 1 có trong Phụ lục E):

(Phát hiện 1) THEANINE vượt trội hơn các đường cơ sở trong việc tạo phản hồi. Bảng 1 trình bày hiệu suất tác nhân trong RG liên quan đến cả các chỉ số dựa trên chồng chéo và nhúng: Bleu-4 (Papineni et al., 2002), Rouge-L (Lin, 2004), Mauve (Pillutla et al., 2021), và BertScore (Zhang et al., 2020).

Trên cả hai bộ dữ liệu, THEANINE đạt được chất lượng phản hồi vượt trội so với các đường cơ sở khác nhau. Mặc dù, so với Truy xuất Bộ nhớ, THEANINE ghi điểm thấp hơn một chút trong các chỉ số dựa trên chồng chéo (tức là, B-4 và R-L) trong MSC, nó vượt trội hơn đáng kể so với Truy xuất Bộ nhớ trong các chỉ số dựa trên nhúng. Thú vị là, bao gồm cả chúng tôi, các phương pháp không cập nhật bộ nhớ thường cho điểm cao hơn, biện minh cho đề xuất của chúng tôi hướng tới quản lý bộ nhớ không cập nhật, không loại bỏ cho các tác nhân đối thoại suốt đời.

(Phát hiện 2 & 3) Tất cả các giai đoạn đều đóng góp vào hiệu suất; việc truy xuất dòng thời gian như một tổng thể mang lại cải thiện lớn so với truy xuất thông thường.

Để có cái nhìn sâu sắc hơn về thiết kế của chúng tôi, chúng tôi điều tra tác động của việc loại bỏ tính nhận thức về mối quan hệ của THEANINE trong quá trình liên kết bộ nhớ (Giai đoạn I-2) và Tinh chỉnh Dòng thời gian (Giai đoạn II-2). Ngoài ra, để đánh giá một cách khách quan xem liệu việc truy xuất của THEANINE (tức là, truy xuất dòng thời gian như một tổng thể) có cải thiện chất lượng truy xuất hay không, chúng tôi bao gồm một thiết lập trong đó các dòng thời gian được truy xuất bị phá vỡ thành các sự kiện được sắp xếp ngẫu nhiên sao cho các ký ức được truy xuất trong RG có cùng định dạng với truy xuất top-k thông thường.

Trong Bảng 2, chúng tôi quan sát thấy một thứ hạng về mặt đóng góp vào hiệu suất: liên kết nhận thức về mối quan hệ > truy xuất dòng thời gian như một tổng thể > tinh chỉnh dòng thời gian. Quan sát này xác nhận hiệu quả của việc xây dựng đồ thị bộ nhớ với các mối quan hệ nhân quả. Hơn nữa, việc sử dụng cấu trúc đồ thị này để thu thập các dòng thời gian của các sự kiện liên quan mang lại chất lượng RG cao hơn so với truy xuất thông thường, mặc dù k nhỏ hơn (3 so với 6) trong truy xuất ban đầu. Tinh chỉnh dòng thời gian cho thấy cải thiện hiệu suất nhỏ hơn, gợi ý có chỗ để cải thiện trong việc áp dụng chúng cho RG. Chúng tôi để lại điều này cho công việc tương lai.

(Phát hiện 4) Con người và G-Eval tiết lộ rằng THEANINE dẫn đến chất lượng truy xuất cao hơn liên quan đến cả tính hữu ích và độ chính xác.

Ngoài phản hồi của tác nhân, chúng tôi tiếp tục điều tra cách các phương pháp xây dựng bộ nhớ khác nhau ảnh hưởng đến chất lượng truy xuất bộ nhớ. Cho cùng các cuộc đối thoại hiện tại làm truy vấn cho việc truy xuất bộ nhớ, Hình 5 cho thấy các so sánh trực tiếp (chúng tôi so với các đường cơ sở) liên quan đến việc ký ức được truy xuất của ai có thể mang lại lợi ích hiệu quả hơn cho RG. Chúng tôi quan sát thấy tỷ lệ thắng cao hơn cho THEANINE trong tất cả các so sánh, đặc biệt là trong các đánh giá con người. Điều này gợi ý rằng phương pháp của chúng tôi có thể tạo điều kiện cho việc tăng cường bộ nhớ hữu ích hơn cho việc tạo phản hồi.

Ngoài tính hữu ích, việc đo lường khách quan độ chính xác truy xuất là rất quan trọng. Vì các bộ dữ liệu hiện có của các cuộc trò chuyện dài hạn không cung cấp ánh xạ vàng giữa các ngữ cảnh đối thoại và ký ức (tức là, ký ức vàng cho việc truy xuất), chúng tôi xác định 50 ngữ cảnh đối thoại (tức là, các trường hợp thử nghiệm) yêu cầu một ký ức quá khứ cho RG và đo lường thủ công độ chính xác truy xuất của các tác nhân khác nhau. Kết quả được hiển thị trong Bảng 3 chỉ ra rằng THEANINE và các phiên bản rút gọn của nó thể hiện độ chính xác truy xuất cao hơn so với các đường cơ sở, và thứ hạng ở đây phù hợp với Bảng 1 và tỷ lệ thành công trong Bảng 4.

(Phát hiện 5) Con người xác nhận rằng THEANINE mang lại các phản hồi kéo theo tốt hơn các tương tác trong quá khứ.

Bây giờ khi tính hữu ích của các ký ức được truy xuất của THEANINE đã được xác thực, chúng tôi tiến hành điều tra xem liệu những ký ức hữu ích như vậy có đóng góp vào tương tác suốt đời đáng tin cậy giữa con người và tác nhân hay không. Để làm điều đó, chúng tôi tiếp tục yêu cầu một nhóm công nhân đánh giá cụ thể xem liệu các phản hồi của tác nhân có kéo theo, mâu thuẫn hay trung lập với quá khứ thông qua bỏ phiếu đa số. Trong Hình 6, THEANINE không chỉ dẫn đến một số lượng nhỏ các phản hồi mâu thuẫn (4%) mà còn thể hiện tỷ lệ phần trăm lớn nhất (68%; trên 100) của các phản hồi kéo theo các cuộc trò chuyện trong quá khứ, vượt trội đáng kể so với các đường cơ sở. Chúng tôi cho rằng đó là do cách tiếp cận dựa trên dòng thời gian của chúng tôi khơi gợi các ký ức tốt hơn trong việc thể hiện các tương tác trong quá khứ giữa các người nói, do đó dẫn đến các phản hồi phù hợp hơn trực tiếp với quá khứ. Sự phù hợp này quan trọng đối với các tác nhân đối thoại để duy trì sự thân mật lâu dài với người dùng (Adiwardana et al., 2020).

Hơn nữa, bản chất kéo theo và không mâu thuẫn như vậy của các phản hồi của THEANINE làm nổi bật tiềm năng của nó cho các ứng dụng trong các lĩnh vực chuyên môn, chẳng hạn như các tác nhân cá nhân hóa cho các tình huống lâm sàng, nơi sự kéo theo giữa các phản hồi của tác nhân và thông tin quá khứ của người dùng (ví dụ, hồ sơ sức khỏe điện tử hoặc các phiên tư vấn trước đây) là rất quan trọng cho việc đưa ra quyết định chẩn đoán (Tseng et al., 2024).

Như một lưu ý bên lề, Cập nhật Bộ nhớ mang lại ít phản hồi mâu thuẫn hơn (2%), chỉ ra một sự đánh đổi tiềm năng giữa (i) loại bỏ các ký ức lỗi thời để ngăn chặn mâu thuẫn và (ii) bảo tồn chúng để có thông tin phong phú hơn cho RG (Kim et al., 2024a).

(Phát hiện 6) Con người đồng ý với các quy trình trung gian của THEANINE.

Như được báo cáo trong Hình 7, các thẩm phán phần lớn đồng ý (92%) rằng THEANINE phân công một cách thích hợp các mối quan hệ nhân-quả cho các ký ức được liên kết, điều này giải thích đóng góp của nó vào hiệu suất. Ngoài ra, họ đồng ý rằng việc tinh chỉnh dòng thời gian thành công khơi gợi thông tin hữu ích hơn (100%; 100 mẫu tổng cộng) cho RG. Các ví dụ về các giai đoạn và RG của THEANINE có trong Phụ lục G.

5 Sơ đồ Đánh giá 2: TeaFarm – một Đường ống Đánh giá Hướng Phản thực cho Các Cuộc trò chuyện Dài hạn

Đánh giá các tác nhân được tăng cường bộ nhớ trong các cuộc trò chuyện dài hạn là không tầm thường do không có sẵn ánh xạ thực tế giữa các cuộc trò chuyện hiện tại và ký ức đúng cho việc truy xuất. Mặc dù chúng ta có thể dựa vào G-Eval bằng cách cung cấp cho các LLM đánh giá (ví dụ, GPT-4) toàn bộ lịch sử quá khứ và nhắc nó xác định xem một phản hồi có gọi lại chính xác quá khứ hay không, việc đánh giá có thể bị hạn chế phần lớn bởi hiệu suất của chính LLM đánh giá (Kim et al., 2024b).

Để khắc phục điều này, cùng với THEANINE, chúng tôi trình bày TeaFarm, một đường ống hướng phản thực không cần con người để đánh giá việc tạo phản hồi được tăng cường bộ nhớ trong các cuộc trò chuyện dài hạn.

5.1 Kiểm tra Bộ nhớ của Tác nhân Đối thoại thông qua Các Câu hỏi Phản thực

Trong TeaFarm, chúng tôi tiến hành "lừa" các tác nhân đối thoại tạo ra các phản hồi không chính xác, và các tác nhân phải tham chiếu chính xác các cuộc trò chuyện trong quá khứ để tránh bị chúng tôi đánh lừa. Cụ thể, chúng tôi nói chuyện với tác nhân đối thoại trong khi hành động như thể một tuyên bố không thực tế là đúng (do đó phản thực). Hình 8 trình bày một số ví dụ về các câu hỏi phản thực và các sự thật tương ứng.

Trong thực tế (Hình 11), khi chúng tôi muốn đánh giá một tác nhân đã tương tác với người dùng trong các phiên, trước tiên chúng tôi (1) thu thập tất cả các cuộc trò chuyện trong quá khứ và tóm tắt chúng theo từng phiên. Sau đó, chúng tôi (2) cung cấp cho một LLM tạo câu hỏi các bản tóm tắt đã thu thập theo thứ tự thời gian sao cho nó có thể nắm bắt giai đoạn hiện tại của mỗi sự kiện được thảo luận, ví dụ, "Người nói B không sở hữu ô tô", và (3) tạo ra các câu hỏi phản thực từ góc độ của cả hai người nói (và các câu trả lời đúng). Sau đó, chúng tôi (4) khởi động (tức là, mô phỏng) một phiên đối thoại mới, trò chuyện một lúc, sau đó (5) tự nhiên đặt câu hỏi phản thực, và (6) đánh giá tính đúng đắn của phản hồi của nó. Hình tổng quan, lời nhắc và dữ liệu tổng hợp cho TeaFarm có trong Phụ lục C, H và D, tương ứng.

5.2 Kết quả TeaFarm

Trong Bảng 4, THEANINE cho thấy SR cao hơn so với các đường cơ sở, đặc biệt là trong CC. Các phiên bản rút gọn hoạt động hơi kém hơn so với bản gốc, một lần nữa chứng minh hiệu quả của liên kết nhận thức về mối quan hệ và tinh chỉnh dòng thời gian.

Đáng ngạc nhiên, tất cả các thiết lập đều có SR thấp, làm cho TeaFarm trở thành một đường ống thích hợp để kiểm tra căng thẳng các tác nhân đối thoại trong các cuộc trò chuyện dài hạn.

Thú vị là, các đường cơ sở sử dụng bộ truy xuất (giống như THEANINE) cho thấy hiệu suất vượt trội so với các thiết lập chỉ dựa vào LLM (tức là, RSum-LLM, MemoChat và COMEDY). Điều này, một cách bất ngờ, hỗ trợ nỗ lực của chúng tôi trong việc phát triển một mô hình mới về quản lý bộ nhớ trong kỷ nguyên của LLM.

Để cung cấp cái nhìn sâu sắc về các tình huống trò chuyện thách thức đối với các tác nhân đối thoại, chúng tôi trình bày các nghiên cứu trường hợp về cách THEANINE thất bại trong TeaFarm trong Phụ lục G.

6 Phân tích và Thảo luận Thêm

Hiệu quả chi phí. Một mối lo ngại của THEANINE là chi phí API. Tuy nhiên, chúng tôi cho rằng nó có tính cạnh tranh khi cả hiệu suất và chi phí đều được tính đến. Hình 9 vẽ biểu đồ chất lượng phản hồi (điểm Mauve) so với chi phí API. Chúng tôi thấy rằng THEANINE và tất cả các phiên bản rút gọn không chỉ vượt trội hơn tất cả các đường cơ sở mà còn nằm trên ranh giới Pareto, chỉ ra sự đánh đổi chi phí-hiệu suất hiệu quả. Điều này gợi ý giá trị của THEANINE khi hiệu suất được ưu tiên hơn chi phí API. Chi phí API thực tế và kết quả dựa trên điểm B-4, R-L và Bert có trong Phụ lục I.

Hiệu quả thời gian. Hiệu quả thời gian có thể là một cân nhắc quan trọng khi triển khai THEANINE vào các tình huống thực tế có các sự kiện phong phú hơn. Hình 10 cho thấy các so sánh thời gian-hiệu suất liên quan đến cả "xây dựng bộ nhớ" và "truy xuất + RG" cũng sử dụng ranh giới Pareto. Tương tự, THEANINE và nhiều phiên bản rút gọn của nó thể hiện sự đánh đổi thời gian-hiệu suất hiệu quả.

So sánh bổ sung: Truy xuất Bộ nhớ với k thay đổi động. Do các quy trình dựa trên đồ thị của THEANINE, bộ tạo phản hồi có thể truy cập các lượng ký ức khác nhau trong RG tùy thuộc vào các ngữ cảnh đã cho (tức là, các truy vấn được sử dụng bởi bộ truy xuất) và khi cuộc trò chuyện diễn ra (tức là, một phiên sớm hơn hoặc muộn hơn), trong khi các phương pháp thông thường (Xu et al., 2022a; Bae et al., 2022) thường có một số cố định k của các ký ức được truy xuất cho RG. Do đó, để định lượng thêm hiệu quả của quản lý và tăng cường dựa trên dòng thời gian được đề xuất của chúng tôi, chúng tôi so sánh THEANINE với Truy xuất Bộ nhớ với k động, trong đó k thay đổi động dựa trên số lượng ký ức được thu thập trong THEANINE cho mỗi trường hợp thử nghiệm cụ thể. Nói cách khác, nếu THEANINE sử dụng dòng thời gian để thu thập k ký ức trong RG cho một trường hợp thử nghiệm Di, các đường cơ sở cũng sẽ truy xuất k ký ức để tạo phản hồi cho Di.

Trong Bảng 5, chúng ta có thể quan sát thấy rằng khi số lượng ký ức được khớp, phương pháp của chúng tôi vượt trội hơn cả hai đường cơ sở mặc dù cùng một lượng ký ức được cung cấp. Chúng tôi giả định điều này là do: (i) việc truy xuất dựa trên đồ thị của chúng tôi giúp chúng tôi thu thập các ký ức có lợi hơn so với truy xuất thông thường; (ii) giải quyết mối quan hệ giữa các sự kiện và định hình chúng dựa trên các ngữ cảnh đối thoại có thể tạo điều kiện cho các manh mối ngữ cảnh phong phú hơn cho RG.

Khoảng cách ngày càng tăng của ký ức. Một câu hỏi khác là liệu khoảng cách ngày càng tăng của bộ nhớ cuối cùng có cản trở việc truy xuất trong THEANINE nếu có hàng trăm phiên hay không. Mặc dù đây có thể là một vấn đề nghiêm trọng đối với các phương pháp thông thường, chúng tôi cho rằng nó sẽ được giảm thiểu một phần trong THEANINE, vì: (i) Chúng tôi truy xuất các ký ức liên quan như một tổng thể dưới dạng dòng thời gian. Điều này phục vụ như một lưới an toàn trong các tình huống mà một ký ức quan trọng bị bỏ lỡ trong truy xuất top-k - nó có thể được thu thập thông qua cấu trúc liên kết; (ii) Chúng tôi tinh chỉnh các dòng thời gian được truy xuất dựa trên cuộc đối thoại hiện tại sao cho chúng cung cấp thông tin phù hợp cho RG. Điều này hoạt động như một bảo hiểm thứ hai chống lại việc truy xuất dưới mức tối ưu.

7 Công việc Liên quan

Các cuộc trò chuyện dài hạn. Kể từ MSC, đã có một số nghiên cứu về các cuộc trò chuyện dài hạn: Bae et al. (2022) đào tạo một bộ phân loại để cập nhật các ký ức cũ trong các tình huống cuộc gọi điện thoại. Khi chúng ta bước vào kỷ nguyên của LLM, Li et al. (2024) tận dụng LLM để viết và cập nhật ký ức cho RG. Ngoài sức mạnh của LLM, hành vi con người cũng thúc đẩy các phương pháp trong lĩnh vực này. Ví dụ, Zhong et al. (2024) áp dụng đường cong quên lãng của con người để làm cho các ký ức đã được thảo luận tồn tại lâu hơn. Gần đây, Park et al. (2023) và Maharana et al. (2024) cũng áp dụng khái niệm dòng thời gian. Tuy nhiên, Park et al. (2023) tập trung vào việc gắn thẻ dấu thời gian (ví dụ, "22:00") của các sự kiện và không mô hình hóa rõ ràng kết nối giữa chúng, và, trong Maharana et al. (2024), một dòng thời gian là một chuỗi sự kiện cố định, được xác định trước (có thể không liên quan) chỉ đơn giản phục vụ như một hồ sơ người dùng để tổng hợp dữ liệu đối thoại. Ngược lại, trong công việc của chúng tôi, một dòng thời gian được xây dựng với các sự kiện liên quan, được liên kết động dựa trên các mối quan hệ nhân quả của chúng và được truy xuất khi cuộc trò chuyện tiếp diễn, mang lại lợi ích cho mục tiêu theo dõi bộ nhớ nhất quán và tích hợp của chúng tôi.

Tăng cường bộ nhớ cho các tác nhân đối thoại cá nhân hóa. Xu hướng tương tác dài hạn với các tác nhân tự động thúc đẩy sự thích ứng của chúng cho các nhu cầu cá nhân hóa (Chen et al., 2024a,c). Như một người tiên phong, Xu et al. (2022b) đào tạo một bộ trích xuất tính cách để tạo ra các ký ức dựa trên người dùng. Tuy nhiên, việc đào tạo các tác nhân cá nhân hóa cho việc sử dụng dài hạn có thể không tầm thường do thiếu dữ liệu (Tseng et al., 2024). Như một giải pháp, Kim et al. (2024a) áp dụng các mô hình thường thức và LLM để tăng cường dữ liệu dài hạn hiện có với các câu tính cách chất lượng cao; Chen et al. (2024b) trình bày một khung dựa trên LLM không đào tạo trích xuất hành vi người dùng từ các cuộc trò chuyện cho RG cá nhân hóa. Dựa trên thành công của LLM, THEANINE tận dụng chúng để xây dựng dòng thời gian bộ nhớ. Những dòng thời gian này thể hiện sự phát triển của các tương tác và dẫn đến các phản hồi kéo theo tốt hơn thông tin người nói, thiết lập tiềm năng của THEANINE cho các tác nhân cá nhân hóa.

8 Kết luận

Bài báo này trình bày khung quản lý và tăng cường bộ nhớ dựa trên dòng thời gian đầu tiên, THEANINE, cho các tác nhân tự động trong các cuộc trò chuyện dài hạn. Áp dụng THEANINE, chúng tôi phát triển một tác nhân đối thoại giải quyết hiệu quả việc theo dõi liên tục, suốt đời các ký ức và tích hợp chúng để tạo phản hồi trong suốt vòng đời phục vụ của nó. Các đánh giá toàn diện cho thấy rằng THEANINE có thể tạo điều kiện cho việc tăng cường bộ nhớ có lợi hơn, dẫn đến các phản hồi gần với sự thật cơ bản hơn và phù hợp hơn với các tương tác trong quá khứ của người nói. Hiệu quả của THEANINE được xác nhận thêm trong TeaFarm, một đường ống hướng phản thực mà chúng tôi thiết kế để giải quyết hạn chế của G-Eval và nỗ lực con người trong việc đánh giá tăng cường bộ nhớ. Chúng tôi mong đợi các cách tiếp cận mới của chúng tôi sẽ phục vụ như một nền tảng mới cho các nỗ lực tương lai hướng tới các tác nhân đối thoại suốt đời.

--- TRANG 10 ---

Hạn chế

Đầu tiên, số lượng phiên đối thoại trong nghiên cứu này bị hạn chế ở năm do thiếu các bộ dữ liệu tiếng Anh miền mở dài hơn. Như chúng tôi đã đề cập trong Phần 6, chúng tôi cho rằng hiệu quả của THEANINE vẫn có thể đúng ở một mức độ nào đó trong các cuộc trò chuyện dài hơn. Tuy nhiên, chúng tôi thừa nhận nhu cầu áp dụng các mô-đun bổ sung trực tiếp giải quyết khoảng cách ngày càng tăng của lịch sử đối thoại/ký ức, chẳng hạn như giới thiệu mô hình tóm tắt-sau đó-nén trong COMEDY (Chen et al., 2024b) để nén các bản tóm tắt cấp phiên thành một mô tả người dùng/sự kiện ngắn kết hợp.

Thứ hai, mặc dù chúng tôi bao gồm nhiều khung gần đây làm đường cơ sở, chúng tôi không thể so sánh THEANINE với MemoryBank (Zhong et al., 2024), một khung lấy cảm hứng từ đường cong quên lãng của Ebbinghaus. Điều này là do khoảng thời gian giữa các phiên trong MSC và CC hoặc chủ yếu được đo bằng giờ hoặc không được chỉ định rõ ràng (ví dụ, "vài tháng sau"), trong khi MemoryBank yêu cầu khoảng thời gian chính xác tính bằng ngày để áp dụng đường cong quên lãng. Ngoài ra, dữ liệu được sử dụng cho MemoryBank tập trung vào các tình huống lâm sàng của Trung Quốc, làm cho nó không khả thi cho nghiên cứu của chúng tôi. Tuy nhiên, chúng tôi vẫn tích cực về việc áp dụng một cơ chế như vậy để cải thiện THEANINE trong nghiên cứu đang diễn ra của chúng tôi.

Cuối cùng, các LLM dựa trên API có thể gây ra các rủi ro như vấn đề bảo mật. Một giải pháp có thể là áp dụng THEANINE cho các LM mã nguồn mở nhỏ để sử dụng cục bộ an toàn. Trong khi có những thách thức trong việc thu thập dữ liệu, người ta có thể đạt được điều này bằng cách (i) thu thập các cuộc trò chuyện tổng hợp với hồ sơ người dùng được tạo bởi GPT, (ii) chạy THEANINE trên các dữ liệu này, và (iii) sử dụng đầu ra của mỗi giai đoạn để đào tạo các LM học sinh (tức là, chưng cất từ các LLM giáo viên).

Tuyên bố Đạo đức

LLM có thể tạo ra nội dung có hại, thiên vị, xúc phạm và tình dục. Tác giả tránh nội dung như vậy xuất hiện trong bài báo này. Chúng tôi đảm bảo bồi thường công bằng cho các đánh giá viên con người từ Amazon Mechanical Turk. Chúng tôi đảm bảo tỷ lệ trả lương hiệu quả cao hơn 20$ mỗi giờ dựa trên thời gian ước tính cần thiết để hoàn thành các nhiệm vụ.

Lời cảm ơn

Công việc này chủ yếu được hỗ trợ bởi Dự án STEAM R&D, NRF, Hàn Quốc (RS-2024-00454458) và Viện Lập kế hoạch và Đánh giá Công nghệ Thông tin & Truyền thông (IITP) cấp tài trợ bởi chính phủ Hàn Quốc (MSIT) (Số RS-2024-00457882, Dự án Phòng thí nghiệm Nghiên cứu AI Quốc gia), và được hỗ trợ một phần bởi Quỹ Nghiên cứu Quốc gia Hàn Quốc (NRF) cấp tài trợ bởi chính phủ Hàn Quốc (MSIT) (RS-2024-00333484; RS-2024-00414981). Jinyoung Yeo là tác giả liên lạc (jinyeo@yonsei.ac.kr).

Tài liệu tham khảo

Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, et al. 2020. Hướng tới một chatbot miền mở giống con người. arXiv preprint arXiv:2001.09977.

Sanghwan Bae, Donghyun Kwak, Soyoung Kang, Min Young Lee, Sungdong Kim, Yuin Jeong, Hyeri Kim, Sang-Woo Lee, Woomyoung Park, và Nako Sung. 2022. Hãy cập nhật tôi! quản lý bộ nhớ trong các cuộc trò chuyện dài hạn. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, trang 3769–3787.

Frederic Charles Bartlett. 1995. Ghi nhớ: Một nghiên cứu về tâm lý học thực nghiệm và xã hội. Cambridge university press.

Hyungjoo Chae, Namyoung Kim, Kai Tzu-iunn Ong, Minju Gwak, Gwanwoo Song, Jihoon Kim, Sunghwan Kim, Dongha Lee, và Jinyoung Yeo. 2024. Các tác nhân web với mô hình thế giới: Học tập và tận dụng động lực học môi trường trong điều hướng web. arXiv preprint arXiv:2410.13232.

Hyungjoo Chae, Yongho Song, Kai Ong, Taeyoon Kwon, Minjin Kim, Youngjae Yu, Dongha Lee, Dongyeop Kang, và Jinyoung Yeo. 2023. Chưng cất chuỗi suy nghĩ đối thoại cho các tác nhân đối thoại có nhận thức thường thức. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, trang 5606–5632.

Howard Chen, Ramakanth Pasunuru, Jason Weston, và Asli Celikyilmaz. 2023. Đi xuống mê cung bộ nhớ: Vượt qua giới hạn ngữ cảnh thông qua đọc tương tác. arXiv preprint arXiv:2310.05029.

Jiangjie Chen, Xintao Wang, Rui Xu, Siyu Yuan, Yikai Zhang, Wei Shi, Jian Xie, Shuang Li, Ruihan Yang, Tinghui Zhu, et al. 2024a. Từ tính cách đến cá nhân hóa: Một khảo sát về các tác nhân ngôn ngữ đóng vai. arXiv preprint arXiv:2404.18231.

Nuo Chen, Hongguang Li, Juhua Huang, Baoyuan Wang, và Jia Li. 2024b. Nén để gây ấn tượng: Giải phóng tiềm năng của bộ nhớ nén trong các cuộc trò chuyện dài hạn thực tế. arXiv preprint arXiv:2402.11975.

Yi-Pei Chen, Noriki Nishida, Hideki Nakayama, và Yuji Matsumoto. 2024c. Xu hướng gần đây trong việc tạo ra đối thoại cá nhân hóa: Một đánh giá về bộ dữ liệu, phương pháp luận và đánh giá. arXiv preprint arXiv:2405.17974.

Jena D Hwang, Chandra Bhagavatula, Ronan Le Bras, Jeff Da, Keisuke Sakaguchi, Antoine Bosselut, và Yejin Choi. 2021. (comet-) atomic 2020: Về đồ thị kiến thức thường thức tượng trưng và thần kinh. Trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 35, trang 6384–6392.

Bahar Irfan, Mariacarla Staffa, Andreea Bobu, và Nikhil Churamani. 2024. Học tập suốt đời và cá nhân hóa trong tương tác người-robot dài hạn (leap-hri): Học tập thế giới mở. Trong Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction, trang 1323–1325.

Jihyoung Jang, Minseong Boo, và Hyounghun Kim. 2023. Biên niên sử cuộc trò chuyện: Hướng tới động lực học thời gian và quan hệ đa dạng trong các cuộc trò chuyện đa phiên. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, trang 13584–13606, Singapore. Association for Computational Linguistics.

Hana Kim, Kai Ong, Seoyeon Kim, Dongha Lee, và Jinyoung Yeo. 2024a. Xây dựng và quản lý bộ nhớ được tăng cường thường thức trong các cuộc trò chuyện dài hạn thông qua tinh chỉnh tính cách nhận thức về ngữ cảnh. Trong Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 2: Short Papers), trang 104–123, St. Julian's, Malta. Association for Computational Linguistics.

Seungone Kim, Juyoung Suk, Shayne Longpre, Bill Yuchen Lin, Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, và Minjoon Seo. 2024b. Prometheus 2: Một mô hình ngôn ngữ mã nguồn mở chuyên đánh giá các mô hình ngôn ngữ khác. arXiv preprint arXiv:2405.01535.

Taeyoon Kwon, Kai Tzu-iunn Ong, Dongjin Kang, Seungjun Moon, Jeong Ryong Lee, Dosik Hwang, Beomseok Sohn, Yongsik Sim, Dongha Lee, và Jinyoung Yeo. 2024. Các mô hình ngôn ngữ lớn là những người lý luận lâm sàng: Khung chẩn đoán nhận thức về lý luận với các lý do được tạo ra bởi lời nhắc. Trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 38, trang 18417–18425.

Hao Li, Chenghao Yang, An Zhang, Yang Deng, Xiang Wang, và Tat-Seng Chua. 2024. Xin chào một lần nữa! tác nhân cá nhân hóa được hỗ trợ bởi llm cho đối thoại dài hạn. arXiv preprint arXiv:2406.05925.

Chin-Yew Lin. 2004. ROUGE: Một gói để đánh giá tự động các bản tóm tắt. Trong Text Summarization Branches Out, trang 74–81, Barcelona, Spain. Association for Computational Linguistics.

Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, và Percy Liang. 2024. Lạc lõng ở giữa: Cách các mô hình ngôn ngữ sử dụng ngữ cảnh dài. Transactions of the Association for Computational Linguistics, 12.

Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, và Chenguang Zhu. 2023. G-eval: Đánh giá nlg sử dụng gpt-4 với sự phù hợp tốt hơn với con người. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, trang 2511–2522.

Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, và Yunsheng Wu. 2023. Memochat: Điều chỉnh llms để sử dụng memo cho cuộc trò chuyện miền mở nhất quán tầm xa. arXiv preprint arXiv:2308.08239.

Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. 2024. Tự tinh chỉnh: Tinh chỉnh lặp với phản hồi tự thân. Advances in Neural Information Processing Systems, 36.

Adyasha Maharana, Dong-Ho Lee, Sergey Tulyakov, Mohit Bansal, Francesco Barbieri, và Yuwei Fang. 2024. Đánh giá bộ nhớ đối thoại rất dài hạn của các tác nhân LLM. Trong Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 13851–13870, Bangkok, Thailand. Association for Computational Linguistics.

MetaAI. 2024. Llama3. https://ai.meta.com/blog/meta-llama-3-1/.

Seyed Mahed Mousavi, Simone Caldarella, và Giuseppe Riccardi. 2023. Tạo phản hồi trong các cuộc đối thoại dọc: Biểu diễn kiến thức nào giúp ích? Trong The 5th Workshop on NLP for Conversational AI, trang 1.

Bao Trong Nguyen, Naveen Sharma, Eun-Joo Shin, Ji Hoon Jeong, Sung Hoon Lee, Choon-Gon Jang, Seung-Yeol Nah, Toshitaka Nabeshima, Yukio Yoneda, và Hyoung-Chun Kim. 2019. Theanine làm giảm suy giảm trí nhớ do thiếu hụt gen klotho ở chuột. Food & function, 10(1):325–332.

OpenAI. 2023. Chatgpt. https://openai.com/blog/chatgpt.

OpenAI. 2024a. Trang web openai. https://openai.com/.

OpenAI. 2024b. Nhúng văn bản của openai.

Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. 2002. Bleu: một phương pháp đánh giá tự động dịch máy. Trong Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, trang 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

Joon Sung Park, Joseph O'Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, và Michael S Bernstein. 2023. Các tác nhân tạo sinh: Simulacra tương tác của hành vi con người. Trong Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, trang 1–22.

Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, và Zaid Harchaoui. 2021. Mauve: Đo lường khoảng cách giữa văn bản thần kinh và văn bản con người sử dụng biên giới phân kỳ. Advances in Neural Information Processing Systems, 34:4816–4828.

Chongyang Tao, Jiazhan Feng, Tao Shen, Chang Liu, Juntao Li, Xiubo Geng, và Daxin Jiang. 2023. Core: Đào tạo hợp tác của retriever-reranker để lựa chọn phản hồi đối thoại hiệu quả. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 3102–3114.

Yu-Min Tseng, Yu-Chao Huang, Teng-Yun Hsiao, Yu-Ching Hsu, Jia-Yin Foo, Chao-Wei Huang, và Yun-Nung Chen. 2024. Hai câu chuyện về tính cách trong llms: Một khảo sát về đóng vai và cá nhân hóa. arXiv preprint arXiv:2406.01171.

Qingyue Wang, Liang Ding, Yanan Cao, Zhiliang Tian, Shi Wang, Dacheng Tao, và Li Guo. 2023. Tóm tắt đệ quy cho phép bộ nhớ đối thoại dài hạn trong các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2308.15022.

Jing Xu, Arthur Szlam, và Jason Weston. 2022a. Vượt qua bộ nhớ cá vàng: Cuộc trò chuyện miền mở dài hạn. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 5180–5197, Dublin, Ireland. Association for Computational Linguistics.

Xinchao Xu, Zhibin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu, Haifeng Wang, và Shihang Wang. 2022b. Lâu rồi không gặp! cuộc trò chuyện miền mở với bộ nhớ tính cách dài hạn. Trong Findings of the Association for Computational Linguistics: ACL 2022, trang 2639–2650.

Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, và Jason Weston. 2018. Cá nhân hóa các tác nhân đối thoại: Tôi có một con chó, bạn có nuôi thú cưng không? Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 2204–2213, Melbourne, Australia. Association for Computational Linguistics.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, và Yoav Artzi. 2020. Bertscore: Đánh giá tạo văn bản với bert. Trong International Conference on Learning Representations.

Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, và Yanlin Wang. 2024. Memorybank: Tăng cường các mô hình ngôn ngữ lớn với bộ nhớ dài hạn. Trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 38, trang 19724–19731.

A Nội dung Phụ lục

• Phụ lục B.1: Các Mối quan hệ Thường thức Nhân-quả được Áp dụng.
• Phụ lục B.2: Thuật toán cho THEANINE.
• Phụ lục B.3: Chi tiết Triển khai về Thí nghiệm Tính toán.
• Phụ lục C: Đánh giá TeaFarm.
• Phụ lục D: Bộ dữ liệu TeaBag.
• Phụ lục E Chi tiết về Sơ đồ Đánh giá 1 (G-Eval và Đánh giá Con người).
• Phụ lục F: Kết quả Cụ thể theo Phiên của Đánh giá Tự động.
• Phụ lục G: Các Ví dụ Thực nghiệm.
• Phụ lục H: Lời nhắc được Sử dụng trong Công việc này.
• Phụ lục I: Phân tích Thêm.
• Phụ lục J: Điều khoản Sử dụng Artifacts.

B Chi tiết Triển khai Thêm

B.1 Các Mối quan hệ Thường thức Nhân-quả

Chúng tôi áp dụng và sửa đổi các mối quan hệ thường thức từ Hwang et al. (2021) cho việc liên kết bộ nhớ nhận thức về mối quan hệ của chúng tôi. Dưới đây là danh sách các mối quan hệ thường thức R của chúng tôi:

Changed: Các sự kiện trong A thay đổi thành các sự kiện trong B.
Cause: Các sự kiện trong A gây ra các sự kiện trong B.
Reason: Các sự kiện trong A là do các sự kiện trong B.
HinderedBy: Khi các sự kiện trong B có thể bị cản trở bởi các sự kiện trong A, và ngược lại.
React: Khi, do các sự kiện trong A, chủ thể cảm thấy như được đề cập trong B.
Want: Khi, do các sự kiện trong A, chủ thể muốn các sự kiện trong B xảy ra.
SameTopic: Khi chủ đề cụ thể được đề cập trong A cũng được thảo luận trong B.

Bị hạn chế bởi hiệu suất của các bộ truy xuất, có thể một m ∈ Ma không có mối quan hệ, ngoài sự chồng chéo văn bản, với mnew. Chúng tôi giải quyết điều này bằng cách cho phép LLM xuất ra "None".

B.2 Thuật toán cho THEANINE

Các thuật toán giả cho Giai đoạn I và II được cung cấp trong Thuật toán 1 và 2.

B.3 Chi tiết Triển khai về Thí nghiệm Tính toán

Tất cả các thí nghiệm tính toán trong công việc này đều dựa trên OpenAI API (OpenAI, 2024a). Do đó, không cần cơ sở hạ tầng tính toán trong công việc này.

C Đánh giá TeaFarm

Đường ống tổng thể của TeaFarm được minh họa trong Hình 11.

D Bộ dữ liệu TeaBag

Như một sản phẩm phụ của TeaFarm, chúng tôi tuyển chọn TeaBag, một bộ dữ liệu cho đánh giá TeaFarm trên MSC và CC. TeaBag bao gồm:

• 100 tập của các cuộc trò chuyện gốc từ Multi-Session Chat và Conversational Chronicles (phiên 1-5; 50 tập từ mỗi bộ dữ liệu)
• Hai cặp QA phản thực cho mỗi tập (200 cặp tổng cộng).
• Hai cuộc trò chuyện theo dõi tổng hợp (tức là, phiên 6) cho mỗi tập (do đó 200 tổng cộng), mỗi cuộc trong số đó tự nhiên hướng dẫn cuộc trò chuyện từ phiên 5 hướng tới một trong những câu hỏi phản thực.

Bộ dữ liệu này được tạo ra với GPT-4. Lời nhắc cho việc tạo ra có trong Phụ lục H. Chúng tôi mong đợi công việc tương lai sẽ áp dụng TeaBag để kiểm tra căng thẳng xem liệu hệ thống đối thoại của họ có thể tham chiếu chính xác các cuộc trò chuyện trong quá khứ hay không.

TeaBag không chứa thông tin nhận dạng cá nhân, vì nó được tạo ra dựa trên các bộ dữ liệu nơi tất cả nội dung đều là sáng tạo thuần túy nhân tạo, thay vì nội dung được thu thập từ thế giới thực. Ngoài ra, chúng tôi đã cố gắng hết sức để xác nhận rằng bộ dữ liệu này không chứa bất kỳ nội dung xúc phạm nào.

Để tổng quan về việc thu thập dữ liệu, vui lòng tham khảo bước 1-4 của TeaFarm (Hình 11).

E Chi tiết về Sơ đồ Đánh giá 1

Chúng tôi thực hiện đánh giá sử dụng các phiên 3-5 từ MSC và CC, vì tất cả các thiết lập gần như giống hệt nhau trước cuối phiên 2, do thực tế là không có bộ nhớ để cập nhật trước đó.

Các bộ thử nghiệm của MSC và CC chứa hơn 500 và 20.000 tập cuộc trò chuyện, trong đó mỗi tập có 5 phiên đối thoại, tạo ra 1.2M lượt phản hồi tổng cộng. Do ngân sách hạn chế cho việc tạo ra (cả đường cơ sở và của chúng tôi), khi không được chỉ định, chúng tôi lấy mẫu 50 tập từ mỗi bộ dữ liệu cho các thí nghiệm trong bài báo này (khoảng 3.6K lượt đối thoại tổng cộng).

E.1 G-Eval

G-Eval (Liu et al., 2023) là một khung sử dụng LLM với chuỗi suy nghĩ (CoT) và mô hình điền biểu mẫu để đánh giá chất lượng tạo văn bản của các mô hình. G-Eval với GPT-4 đã được chỉ ra tạo ra kết quả đánh giá phù hợp cao với đánh giá con người (Liu et al., 2023; Kim et al., 2024b) và do đó đã được áp dụng rộng rãi trong nhiều dự án dựa trên LM. Chúng tôi tiến hành G-Eval trên 5 tập.

Lời nhắc để đánh giá tính hữu ích của các ký ức được truy xuất có trong Hình 26. Chúng tôi sử dụng SciPy để tính toán p-values.

E.2 Đánh giá Con người

Chúng tôi tiến hành đánh giá con người, với công nhân từ Amazon Mechanical Turk (AMT). Chúng tôi xây dựng ba đánh giá sau:

• Tính thích hợp của liên kết bộ nhớ nhận thức về mối quan hệ: Trong đánh giá này, chúng tôi yêu cầu các công nhân đánh giá xem họ có đồng ý rằng liên kết nhận thức về mối quan hệ được thực hiện đúng cách cho hai ký ức đã cho hay không. Giao diện được cung cấp cho các công nhân AMT, bao gồm hướng dẫn chi tiết cho đánh giá con người, được hiển thị trong Hình 12.

• Tính hữu ích của tinh chỉnh dòng thời gian nhận thức về ngữ cảnh: Đánh giá này yêu cầu các công nhân xác định xem họ có đồng ý rằng việc tinh chỉnh nhận thức về ngữ cảnh của chúng tôi thực sự điều chỉnh một dòng thời gian thô thành một nguồn thông tin hữu ích để tạo ra phản hồi tiếp theo hay không. Giao diện được cung cấp cho các công nhân AMT, bao gồm hướng dẫn chi tiết cho đánh giá con người, được hiển thị trong Hình 13.

• Chất lượng của các phản hồi: Ở đây, các công nhân được yêu cầu đánh giá xem các phản hồi có tham chiếu chính xác đến các cuộc trò chuyện trong quá khứ hay không. Sau khi đọc các phản hồi và ký ức trong quá khứ của chúng tôi, họ chọn xem các phản hồi có kéo theo, mâu thuẫn hay trung lập với các ký ức trong quá khứ. Để cải thiện chất lượng đánh giá, chúng tôi sử dụng GPT-4 để chọn các phản hồi cho đánh giá cụ thể này dựa trên các ký ức trong quá khứ, giải quyết thực tế là không phải mọi lượt trong cuộc trò chuyện đều yêu cầu thông tin trước đó để tạo ra phản hồi tiếp theo (Trong hai đánh giá khác, các mẫu được chọn ngẫu nhiên). Giao diện được cung cấp cho các công nhân AMT, bao gồm hướng dẫn chi tiết cho đánh giá con người được hiển thị trong Hình 14.

• Tính hữu ích của các ký ức được truy xuất: Cho cùng một ngữ cảnh đối thoại, các công nhân con người được yêu cầu chọn một ký ức hữu ích hơn để tạo ra phản hồi tiếp theo từ việc truy xuất của chúng tôi và của đường cơ sở. Giao diện được cung cấp cho các công nhân AMT, bao gồm hướng dẫn chi tiết cho đánh giá con người được hiển thị trong Hình 15.

Mỗi mẫu dữ liệu được đánh giá bởi 3 công nhân khác nhau, và chúng tôi báo cáo kết quả dựa trên quy tắc đa số. Trong đánh giá thứ ba, khi mỗi lựa chọn (kéo theo, trung lập, mâu thuẫn) nhận được một phiếu, chúng tôi coi nó là trung lập (13 mẫu tổng cộng). Những đánh giá con người này được tiến hành trên 100 lượt đối thoại.

F Kết quả Đánh giá Cụ thể theo Phiên

Chúng tôi cung cấp kết quả cụ thể theo phiên cho các đánh giá tự động trong Bảng 9.

G Các Ví dụ Thực nghiệm

Đầu ra từ THEANINE. Chúng tôi cung cấp một số ví dụ thực nghiệm về THEANINE. Các ví dụ về liên kết bộ nhớ nhận thức về mối quan hệ có trong Hình 16, 17 và 18. Các ví dụ về sử dụng dòng thời gian được tinh chỉnh để tạo phản hồi có trong Hình 19.

Cách THEANINE thất bại trong TeaFarm. Chúng tôi trình bày các trường hợp thất bại trong đó THEANINE không vượt qua bài kiểm tra TeaFarm trong Hình 20 và Hình 21. Trong Hình 20, mặc dù cuộc trò chuyện đã chuyển sang "thủ thư", bộ truy xuất dựa trên độ tương đồng truy xuất các ký ức không hữu ích do phần lớn "trẻ em" trong ngữ cảnh. Trong khi một ký ức hữu ích (tức là, "A là một thủ thư đã nghỉ hưu") cuối cùng được bắt gặp bởi cấu trúc dòng thời gian được thiết kế của chúng tôi, LLM vẫn ảo giác. Chúng tôi cho rằng đó là do tiếng ồn được giới thiệu bởi những ký ức được xếp hạng cao, nhưng không liên quan, và nó làm nổi bật nhu cầu giải quyết xếp hạng tính hữu ích trong số các ký ức được truy xuất trong các hệ thống đối thoại suốt đời. Hình 21 cho thấy một trường hợp thất bại, trong đó THEANINE thành công truy xuất các ký ức đúng nhưng tạo ra một phản hồi không phù hợp. Chúng tôi đưa ra giả thuyết rằng điều này là do liên kết nhận thức về mối quan hệ và tinh chỉnh dòng thời gian nhận thức về ngữ cảnh đôi khi có thể làm cho độ dài của các token đầu vào quá dài sao cho tác nhân không thể sử dụng đúng cách thông tin chính được cung cấp. Chúng tôi tin rằng điều này có thể được giải quyết ở một mức độ nào đó thông qua lời nhắc chuyên dụng (tức là, lời nhắc cho RG) kỹ thuật. Chúng tôi để lại điều này cho công việc tương lai.

H Lời nhắc

Sau đây là tất cả các lời nhắc được sử dụng trong nghiên cứu của chúng tôi:

• Liên kết bộ nhớ nhận thức về mối quan hệ (Giai đoạn I-2): Hình 22.
• Tinh chỉnh dòng thời gian nhận thức về ngữ cảnh (Giai đoạn II-2): Hình 23.
• Tạo phản hồi được tăng cường dòng thời gian (Giai đoạn III): Hình 24.
• Cập nhật Bộ nhớ (đường cơ sở): Hình 25.
• RSum-LLM (đường cơ sở): Chúng tôi áp dụng lời nhắc gốc từ Wang et al. (2023).
• MemoChat (đường cơ sở): Chúng tôi áp dụng lời nhắc gốc từ Lu et al. (2023).
• COMEDY (đường cơ sở): Chúng tôi áp dụng lời nhắc gốc từ Chen et al. (2024b).
• G-Eval: Lời nhắc để đánh giá tính hữu ích của các ký ức được truy xuất có trong Hình 26.
• Tạo QA phản thực trong TeaFarm: Hình 27.
• Tạo phiên 6 trong TeaFarm: Hình 28.
• Đánh giá phản hồi mô hình trong TeaFarm: Hình 29.

I Phân tích Thêm

Tóm tắt bộ nhớ. Vào cuối mỗi phiên, chúng tôi sử dụng ChatGPT (gpt-3.5-turbo-0125) để tóm tắt cuộc trò chuyện thành các câu bộ nhớ. Chúng tôi tiến hành kiểm tra về việc tóm tắt như vậy bằng cách sử dụng 100 phiên được lấy mẫu ngẫu nhiên từ MSC và CC để đảm bảo chất lượng của các ký ức thô là chấp nhận được. Kết quả có trong Bảng 6.

Đánh đổi hiệu quả chi phí được đánh giá bằng các chỉ số khác. Trong Phần 6, chúng tôi đã trình bày các phương pháp có sự đánh đổi hiệu quả chi phí-hiệu suất (tức là, Pareto-hiệu quả) bằng cách vẽ biểu đồ điểm Mauve so với chi phí API (Hình 9). Chúng tôi trình bày các phương pháp Pareto-hiệu quả khi xem xét ba chỉ số khác được sử dụng trong nghiên cứu của chúng tôi, tức là, B-4, R-L và Bert Score, trong Bảng 7.

Chi phí API. Chi phí API thực tế của tất cả các thiết lập (của chúng tôi và đường cơ sở) có trong Bảng 8.

J Điều khoản Sử dụng Artifacts

Chúng tôi áp dụng các bộ dữ liệu MSC và CC từ Xu et al. (2022a) và Jang et al. (2023), tương ứng. Cả hai bộ dữ liệu này đều là mã nguồn mở cho việc sử dụng học thuật và phi thương mại. Bộ dữ liệu được tuyển chọn của chúng tôi, TeaBag, sẽ được phát hành sau khi được chấp nhận, mở cho việc sử dụng học thuật và phi thương mại.

--- TRANG 16 ---

[Các thuật toán, bảng biểu và hình ảnh còn lại được duy trì nguyên định dạng như trong bản gốc]

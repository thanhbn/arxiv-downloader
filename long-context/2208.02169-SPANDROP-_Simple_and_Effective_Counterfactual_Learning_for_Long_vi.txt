# 2208.02169.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2208.02169.pdf
# Kích thước tệp: 468079 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
SPANDROP: Học Phản Thực Đơn Giản và Hiệu Quả cho Chuỗi Dài
Peng Qiy1Guangtao Wangy2Jing Huangy3
1AWS AI, Seattle, WA2TikTok, Mountain View, CA3Alexa AI, Sunnyvale, CA
pengqi@cs.stanford.edu
Tóm tắt
Chưng cất tín hiệu giám sát từ một chuỗi dài để đưa ra dự đoán là một nhiệm vụ thách thức trong học máy, đặc biệt khi không phải tất cả các phần tử trong chuỗi đầu vào đều đóng góp bình đẳng cho đầu ra mong muốn. Trong bài báo này, chúng tôi đề xuất SPANDROP, một kỹ thuật tăng cường dữ liệu đơn giản và hiệu quả giúp các mô hình xác định tín hiệu giám sát thực sự trong một chuỗi dài với rất ít ví dụ. Bằng cách trực tiếp thao tác chuỗi đầu vào, SPANDROP ngẫu nhiên loại bỏ các phần của chuỗi từng lần và yêu cầu mô hình thực hiện cùng một nhiệm vụ để mô phỏng học phản thực và đạt được phân bổ đầu vào. Dựa trên phân tích lý thuyết về các tính chất của nó, chúng tôi cũng đề xuất một biến thể của SPANDROP dựa trên phân phối beta-Bernoulli, mang lại các chuỗi tăng cường đa dạng trong khi cung cấp một mục tiêu học tập nhất quán hơn với tập dữ liệu gốc. Chúng tôi chứng minh tính hiệu quả của SPANDROP trên một tập hợp các nhiệm vụ đồ chơi được thiết kế cẩn thận, cũng như các nhiệm vụ xử lý ngôn ngữ tự nhiên khác nhau đòi hỏi lý luận trên các chuỗi dài để đạt được câu trả lời đúng, và cho thấy nó giúp các mô hình cải thiện hiệu suất cả khi dữ liệu khan hiếm và dồi dào.

1 Giới thiệu
Xây dựng các hệ thống học máy hiệu quả cho chuỗi dài là một nhiệm vụ thách thức và quan trọng, giúp chúng ta hiểu rõ hơn các mẫu cơ bản trong dữ liệu tuần tự tự nhiên như văn bản dài (Radford et al., 2019), chuỗi protein (Jumper et al., 2021), chuỗi thời gian tài chính (Bao et al., 2017), v.v. Gần đây, ngày càng có nhiều quan tâm đến việc nghiên cứu các mô hình mạng nơ-ron có thể nắm bắt các mối tương quan tầm xa trong dữ liệu tuần tự với hiệu quả tính toán, bộ nhớ và thống kê cao, đặc biệt là các mô hình Transformer được áp dụng rộng rãi (Vaswani et al., 2017).

Công trình trước đây tiếp cận học chuỗi dài trong Transformers chủ yếu bằng cách giới thiệu các phương pháp tính toán để thay thế cơ chế chú ý bằng các đối tác hiệu quả hơn. Các phương pháp này bao gồm việc giới hạn phạm vi của cơ chế chú ý (Kitaev et al., 2019), giới hạn chú ý cấp chuỗi chỉ đến một số ít vị trí (Beltagy et al., 2020; Zaheer et al., 2020), hoặc mượn ý tưởng từ thủ thuật kernel để loại bỏ nhu cầu tính toán hoặc khởi tạo ma trận chú ý tốn kém (Peng et al., 2020; Katharopoulos et al., 2020; Choromanski et al., 2020). Về cơ bản, các phương pháp này nhằm mục đích xấp xỉ tương tác cặp đôi ban đầu với chi phí thấp hơn, và thường quan tâm đến việc nắm bắt tác động của mọi phần tử đầu vào lên kết quả (ví dụ, các phép toán số học trên một danh sách dài các số và toán tử, như được đề xuất bởi Tay et al., 2020). Mặc dù các nhiệm vụ này đặt ra những thách thức lớn cho việc thiết kế các mô hình hiệu quả để xử lý chuỗi dài, nhiều vấn đề thực tế liên quan đến chuỗi dài chia sẻ các tính chất khiến chúng phù hợp với các phương pháp hiệu quả hơn so với việc mô hình hóa mối quan hệ đầu vào-đầu ra thô trực tiếp (ví dụ, thông qua phân tách).

Trong bài báo này, chúng tôi tập trung vào một vấn đề học tập cho chuỗi dài được thúc đẩy bởi các nhiệm vụ thực tế, nơi không phải tất cả các phần tử đầu vào đều có thể đóng góp vào đầu ra mong muốn. Các ví dụ tự nhiên có dạng này bao gồm phân loại cảm xúc cho các tài liệu đánh giá khách hàng dài (nơi một vài từ cảm xúc nổi bật và liên từ đóng góp nhiều nhất), trả lời câu hỏi từ một tài liệu dài (nơi mỗi câu hỏi thường yêu cầu một số ít câu hỗ trợ để trả lời), phát hiện cụm từ khóa trong xử lý âm thanh (nơi một số ít khung được ghi lại thực sự quyết định dự đoán), cũng như phát hiện một đối tượng cụ thể từ một cảnh phức tạp (nơi, tương tự, một lượng nhỏ pixel quyết định kết quả), để kể một vài ví dụ. Trong những vấn đề này, thường phản tác dụng khi cố gắng và sử dụng trực tiếp toàn bộ đầu vào nếu phần đóng góp nhỏ hoặc thưa thớt, dẫn đến vấn đề thiếu đặc tả (tức là, dữ liệu huấn luyện không xác định đầy đủ mục tiêu cho các mô hình thống kê).

Một phương pháp để giải quyết vấn đề này là chú thích các phần của đầu vào trực tiếp đóng góp vào kết quả. Điều này có thể có dạng một tập con các câu trả lời một câu hỏi hoặc mô tả mối quan hệ giữa các thực thể trong một đoạn văn (Yang et al., 2018; Yao et al., 2019). Tuy nhiên, việc chú thích như vậy không phải lúc nào cũng khả thi về mặt kỹ thuật hoặc tài chính, vì vậy các nhà nghiên cứu và người thực hành thường phải sử dụng việc thu thập thêm các cặp đầu vào-đầu ra hoặc thiết kế các kỹ thuật tăng cường dữ liệu cụ thể theo vấn đề để bù đắp khoảng cách dữ liệu. Đối với dữ liệu có giá trị thực, việc tăng cường thường chuyển thành các biến đổi ngẫu nhiên (ví dụ, dịch chuyển hoặc lật một hình ảnh); đối với dữ liệu tượng trưng như ngôn ngữ tự nhiên, các kỹ thuật như che mặt nạ hoặc thay thế được sử dụng phổ biến hơn (ví dụ, ngẫu nhiên hoán đổi từ với một token mặt nạ đặc biệt hoặc các từ khác). Mặc dù các phương pháp này đã được chứng minh hiệu quả trong một số nhiệm vụ, mỗi phương pháp có những hạn chế ngăn cản nó phù hợp với tình huống thiếu đặc tả. Ví dụ, trong khi các biến đổi tính năng toàn cục tăng cường tính bất biến nhóm trong các biểu diễn đã học, chúng không trực tiếp giúp định vị tốt hơn kích thích thực sự cơ bản. Mặt khác, trong khi các kỹ thuật thay thế như che mặt nạ và thay thế giúp loại bỏ các phần của đầu vào, chúng dễ bị ảnh hưởng bởi thiên lệch vị trí của nơi kích thích thực sự có thể xảy ra trong đầu vào. Hơn nữa, trong khi các kỹ thuật thay thế có thể giúp tạo ra các ví dụ đối lập thách thức, chúng thường khó thực hiện hơn đáng kể (ví dụ, thay thế một cụm từ trong một câu mà không mất đi tính trôi chảy).

Để giải quyết những thách thức này, chúng tôi đề xuất SPANDROP, một kỹ thuật đơn giản và hiệu quả giúp các mô hình chưng cất tín hiệu giám sát thưa từ các chuỗi dài khi vấn đề thiếu đặc tả. SPANDROP ngẫu nhiên loại bỏ các phần của đầu vào để xây dựng các ví dụ phản thực bảo tồn đầu ra gốc và tín hiệu giám sát với xác suất cao. Tuy nhiên, không như các kỹ thuật dựa trên thay thế, SPANDROP loại bỏ các phần tử đã loại bỏ khỏi đầu vào và nối phần còn lại. Điều này tránh việc giới thiệu các biểu diễn nhân tạo không được sử dụng tại thời điểm kiểm tra, và giảm thiểu mối tương quan giả mạo với vị trí tuyệt đối của các phần xác định kết quả của đầu vào (xem Hình 1). Chúng tôi đề xuất thêm một biến thể có động lực lý thuyết, hiệu quả hơn của SPANDROP dựa trên phân phối beta-Bernoulli tăng cường tính nhất quán của hàm mục tiêu tăng cường với hàm gốc.

Chúng tôi chứng minh thông qua các thí nghiệm đồ chơi được thiết kế cẩn thận rằng SPANDROP không chỉ giúp các mô hình đạt được hiệu quả mẫu lên đến 20× trong các thiết lập dữ liệu ít, mà còn giảm thêm hiện tượng quá khớp ngay cả khi dữ liệu huấn luyện dồi dào. Chúng tôi thấy rằng nó rất hiệu quả trong việc giảm thiểu thiên lệch vị trí so với các phương pháp phản thực dựa trên thay thế, và tăng cường khả năng tổng quát hóa ngoài phân phối một cách hiệu quả. Chúng tôi tiếp tục thí nghiệm trên bốn nhiệm vụ xử lý ngôn ngữ tự nhiên đòi hỏi các mô hình trả lời câu hỏi hoặc trích xuất mối quan hệ thực thể từ văn bản dài, nơi, được thúc đẩy bởi phân tích lý thuyết của chúng tôi, chúng tôi đề xuất thêm một phân đoạn span thích ứng. Các thí nghiệm của chúng tôi chứng minh rằng SPANDROP có thể cải thiện hiệu suất của các mô hình nơ-ron cạnh tranh mà không cần thay đổi kiến trúc nào.

Tóm lại, những đóng góp của chúng tôi trong bài báo này là: 1) chúng tôi đề xuất SPANDROP và Beta-SPANDROP, hai phương pháp hiệu quả để tạo ra các ví dụ phản thực cho các nhiệm vụ học chuỗi dài; 2) chúng tôi nghiên cứu các tính chất lý thuyết của những phương pháp này và xác minh chúng với các thí nghiệm được thiết kế cẩn thận trên dữ liệu tổng hợp; 3) chúng tôi chứng minh rằng cả hai phương pháp đều cải thiện các mô hình nơ-ron mạnh trên bốn tập dữ liệu NLP, có thể được thúc đẩy thêm bởi phương pháp phân đoạn span có động lực lý thuyết mà chúng tôi đề xuất.

2 Phương pháp
Trong phần này, chúng tôi đầu tiên phát biểu vấn đề suy luận chuỗi, nơi mô hình lấy dữ liệu tuần tự làm đầu vào để đưa ra dự đoán. Sau đó, chúng tôi giới thiệu SPANDROP, một kỹ thuật tăng cường dữ liệu đơn giản và hiệu quả cho suy luận chuỗi dài, và phân tích các tính chất lý thuyết của nó.

2.1 Định nghĩa Vấn đề
Suy luận Chuỗi. Chúng tôi xem xét một nhiệm vụ nơi một mô hình lấy một chuỗi S làm đầu vào và dự đoán đầu ra y. Chúng tôi giả định rằng S = (s1; :::; sn) bao gồm n span rời rạc nhưng liền kề, và mỗi span đại diện cho một phần của chuỗi theo thứ tự. Một ví dụ về suy luận chuỗi là phân loại cảm xúc từ một đoạn văn bản, nơi S là đoạn văn và y là nhãn cảm xúc. Các span có thể là từ, cụm từ, câu, hoặc một hỗn hợp của những thứ này trong đoạn văn. Một ví dụ khác là dự đoán chuỗi thời gian, nơi S là dữ liệu lịch sử, y là giá trị tại bước thời gian tiếp theo.

Sự thật Hỗ trợ. Cho một cặp đầu vào-đầu ra (S; y) cho dự đoán chuỗi, chúng tôi giả định rằng y thực sự được xác định chỉ bởi một tập con các span trong S. Một cách chính thức hơn, chúng tôi giả định rằng có một tập con các span Ssup ⊆ {s1; s2; :::; sn} sao cho y độc lập với si, nếu si ∉ Ssup. Trong phân loại cảm xúc, Ssup có thể bao gồm các từ cảm xúc quan trọng hoặc liên từ (như "tốt", "xấu", "nhưng"); trong dự đoán chuỗi thời gian, nó có thể phản ánh các bước thời gian gần đây nhất cũng như những bước thời gian cách đó một vài chu kỳ nếu chuỗi có tính tuần hoàn. Để đơn giản, chúng tôi sẽ ký hiệu kích thước của tập hợp này m = |Ssup|, và giới hạn sự chú ý của chúng tôi vào các nhiệm vụ nơi m ≪ n, chẳng hạn như những nhiệm vụ được mô tả trong phần trước.

--- TRANG 2 ---
2.2 SPANDROP
Trong một nhiệm vụ suy luận chuỗi dài với sự thật hỗ trợ thưa (m ≪ n), hầu hết các span trong chuỗi đầu vào sẽ không đóng góp vào dự đoán của y, nhưng chúng sẽ đưa ra mối tương quan giả trong tình huống dữ liệu ít. SPANDROP tạo ra các instance dữ liệu mới (~S; y) bằng cách loại bỏ các span này một cách ngẫu nhiên, trong khi bảo tồn các sự thật hỗ trợ với xác suất cao để mô hình vẫn được huấn luyện để đưa ra dự đoán đúng y. Điều này tương tự như việc xác định phản thực liệu mỗi span có thực sự xác định kết quả y bằng cách hỏi dự đoán sẽ là gì nếu không có nó.

Định nghĩa 1 (SPANDROP). Một cách chính thức, cho một chuỗi S bao gồm các span (s1; s2; sn), SPANDROP tạo ra một chuỗi mới ~S như sau:
εi i.i.d.∼ Bernoulli(1 − p); ~S = (si)ni=1, εi=1;
trong đó p là siêu tham số xác định xác suất để loại bỏ một span.

Lưu ý rằng SPANDROP không yêu cầu giới thiệu các span thay thế hoặc ký hiệu nhân tạo khi loại bỏ các span khỏi chuỗi đầu vào. Nó tận dụng tối đa chuỗi tự nhiên như nó xuất hiện trong dữ liệu huấn luyện gốc, và bảo tồn thứ tự tương đối giữa các span không bị loại bỏ, điều này thường hữu ích trong việc hiểu dữ liệu tuần tự (ví dụ, chuỗi thời gian hoặc văn bản). Cũng không khó để thiết lập rằng chuỗi kết quả ~S có thể bảo tồn tất cả m sự thật hỗ trợ với xác suất cao bất kể n lớn như thế nào.

Nhận xét 1. Độ dài chuỗi mới n′ = |~S| và số lượng sự thật hỗ trợ được bảo tồn m′ = |~S ∩ Ssup| tuân theo các phân phối nhị thức Bin(n; p) và Bin(m; p), tương ứng, trong đó P(x = k|N; p) = (N k)(1 − p)kpN−k cho X ∼ Bin(N; p).

Do đó, tỷ lệ các chuỗi nơi tất cả sự thật hỗ trợ được giữ lại (tức là, m′ = m) là (1 − p)m, độc lập với n. Điều này có nghĩa là miễn là tổng số sự thật hỗ trợ trong chuỗi bị giới hạn, thì bất kể độ dài chuỗi, chúng ta luôn có thể chọn p cẩn thận sao cho chúng ta có nhiều ví dụ mới hợp lệ với nhiễu được giới hạn được đưa vào các sự thật hỗ trợ. Lưu ý rằng phân tích của chúng tôi cho đến nay chỉ dựa trên giả định rằng m được biết hoặc có thể được ước tính, và do đó nó có thể được áp dụng cho các nhiệm vụ nơi tập hợp chính xác các sự thật hỗ trợ Ssup không được biết. Một cách chính thức hơn, số lượng ví dụ mới có thể được đặc trưng bởi kích thước của tập hợp điển hình của ~S, tức là, tập hợp các chuỗi mà chuỗi được loại bỏ ngẫu nhiên sẽ rơi vào với xác suất cao. Kích thước của tập hợp điển hình cho SPANDROP là khoảng 2nH(p), trong đó H(p) là entropy nhị phân của một biến ngẫu nhiên Bernoulli với xác suất p. Một cách trực quan, những kết quả này chỉ ra rằng số lượng tổng các ví dụ phản thực được tạo bởi SPANDROP mở rộng theo hàm mũ trong n, nhưng mức độ nhiễu sự thật hỗ trợ có thể bị giới hạn miễn là m nhỏ.

Tuy nhiên, công thức SPANDROP này có một nhược điểm đáng chú ý có thể làm cản trở hiệu quả của nó. Độ dài chuỗi mới n′ tuân theo một phân phối nhị thức, do đó đối với n đủ lớn, hầu hết độ dài ~S sẽ tập trung xung quanh giá trị trung bình n(1 − p) với độ rộng O(√pn). Điều này tạo ra một dịch chuyển phân phối nhân tạo và vĩnh viễn từ độ dài gốc (xem Hình 2(a)). Hơn nữa, ngay cả khi chúng ta biết danh tính của Ssup và giữ những span này trong quá trình huấn luyện, việc giảm độ dài này sẽ thiên lệch tập huấn luyện về phía các ví dụ dễ hơn để định vị các span trong Ssup, có thể làm tổn hại hiệu suất tổng quát hóa. Trong phần tiếp theo, chúng tôi sẽ giới thiệu một biến thể của SPANDROP dựa trên phân phối beta-Bernoulli để giảm bớt vấn đề này.

Mối quan hệ với word dropout. Một kỹ thuật tăng cường dữ liệu/chính quy hóa thường được sử dụng trong NLP, word dropout Dai & Le (2015); Gal & Ghahramani (2016), có liên quan chặt chẽ với SPANDROP. Tuy nhiên, hai điểm khác biệt quan trọng làm cho SPANDROP khác biệt với nó và các kỹ thuật tương tự: 1) word dropout che mặt nạ hoặc thay thế các ký hiệu trong đầu vào, trong khi SPANDROP trực tiếp loại bỏ chúng. Do đó SPANDROP có thể tránh việc giới thiệu các biểu diễn nhân tạo không được sử dụng tại thời điểm kiểm tra, và ảnh hưởng đến độ dài chuỗi và vị trí tuyệt đối của các phần tử còn lại trong chuỗi, điều mà chúng tôi sẽ chứng minh làm giảm tác động của các mối tương quan giả giữa kết quả và vị trí phần tử tuyệt đối trong dữ liệu huấn luyện; 2) SPANDROP có thể hoạt động trên các span đầu vào được phân đoạn ở độ chi tiết tùy ý (không chỉ từ, hoặc thậm chí không nhất thiết phải liền kề), và phân tích lý thuyết của chúng tôi giữ miễn là những span này rời rạc. Chúng tôi sẽ chỉ ra rằng phân đoạn span được thông báo bởi nhiệm vụ dẫn đến lợi ích hiệu suất thêm.

--- TRANG 3 ---
2.3 Beta-SPANDROP
Để giải quyết vấn đề dịch chuyển phân phối với SPANDROP, chúng tôi giới thiệu một biến thể dựa trên phân phối beta-Bernoulli. Ý tưởng chính là thay vì loại bỏ mỗi span trong một chuỗi một cách độc lập với xác suất cố định p, chúng tôi đầu tiên lấy mẫu một xác suất cấp chuỗi mà tại đó các span được loại bỏ từ một phân phối Beta, sau đó sử dụng xác suất này để thực hiện SPANDROP.

Định nghĩa 2 (Beta-SPANDROP). Đặt α = κp, β = κ(1−p)/p, trong đó κ > 0 là một siêu tham số tỷ lệ. Beta-SPANDROP tạo ra ~S trên S như:
π ∼ B(α; β); εi i.i.d.∼ Bernoulli(1 − π); ~S = (si)ni=1, εi=1;
trong đó B(α; β) là phân phối beta với các tham số α > 0 và β > 0.

Có thể dễ dàng chứng minh rằng trong Beta-SPANDROP, xác suất mỗi span bị loại bỏ vẫn là p trung bình:
E[πi|p] = E[E[πi|π]|p] = E[1 − π|p] = 1 − α/(α+β) = 1 − p.

Thực tế, chúng ta có thể chỉ ra rằng khi κ → ∞, Beta-SPANDROP thoái hóa thành SPANDROP vì phân phối beta sẽ gán toàn bộ khối lượng xác suất trên π = p. Mặc dù đơn giản trong việc thực hiện, Beta-SPANDROP ít có khả năng gây ra dịch chuyển phân phối dữ liệu không mong muốn một cách đáng kể, trong khi có khả năng tạo ra các ví dụ phản thực đa dạng để chính quy hóa việc huấn luyện các mô hình suy luận chuỗi. Điều này là do các tính chất sau:

Nhận xét 2. Độ dài chuỗi mới n′ = |~S| và số lượng sự thật hỗ trợ được bảo tồn m′ = |~S ∩ Ssup| tuân theo các phân phối beta-nhị thức B-Bin(n; α; β) và B-Bin(m; α; β), tương ứng, trong đó
P(x = k|N; α; β) = (N+1)/(k+1)(N−k+1) × B(k+α; N−k+β)/B(α; β)
cho X ∼ B-Bin(N; α; β), và Γ(z) = ∫₀^∞ x^(z-1)e^(-x)dx là hàm gamma.

Kết quả là, chúng ta có thể chỉ ra rằng xác suất Beta-SPANDROP bảo tồn toàn bộ chuỗi gốc với xác suất sau:
P(n′ = n|n; α; β) = B(n + α; β)/B(α; β).

Khi κ = 1, biểu thức này đơn giản chỉ giảm xuống β/(n + β); khi κ ≠ 1, số lượng này có xu hướng O(n^(-β)) khi n tăng đủ lớn. So sánh với tỷ lệ O((1 − p)^n) từ SPANDROP, chúng ta có thể thấy rằng khi n lớn, Beta-SPANDROP khôi phục nhiều phân phối gốc được đại diện bởi (~S; y) so với SPANDROP. Thực tế, như được chứng minh bởi Hình 2(a), các chuỗi phản thực được tạo bởi Beta-SPANDROP cũng trải rộng hơn trong phân phối độ dài của chúng bên cạnh việc bao phủ độ dài gốc n với xác suất cao hơn đáng kể. Một phân tích tương tự có thể được thực hiện bằng cách thay thế n và n′ bằng m và m′, nơi chúng ta có thể kết luận rằng khi m tăng, Beta-SPANDROP tốt hơn nhiều trong việc tạo ra các chuỗi phản thực bảo tồn toàn bộ tập hợp sự thật hỗ trợ Ssup. Điều này được hiển thị trong Hình 2(b), nơi tỷ lệ các ví dụ "không nhiễu" (tức là, m′ = m) giảm theo hàm mũ với SPANDROP (κ = 1) trong khi vẫn cao hơn nhiều khi κ đủ nhỏ. Ví dụ, khi p = 0.1, κ = 1 và m = 10, tỷ lệ các ví dụ không nhiễu cho SPANDROP chỉ là 34.9%, trong khi đó cho Beta-SPANDROP là 47.4%.

Như chúng ta đã thấy, Beta-SPANDROP tốt hơn đáng kể so với đối tác Bernoulli của nó trong việc gán khối lượng xác suất cho dữ liệu gốc cũng như các chuỗi được tạo ra chứa toàn bộ tập hợp các sự thật hỗ trợ. Một câu hỏi tự nhiên là, điều này có phải trả giá bằng các ví dụ phản thực đa dạng không? Để trả lời câu hỏi này, chúng tôi nghiên cứu entropy của phân phối mà ~S tuân theo bằng cách thay đổi κ và n, và chuẩn hóa nó bằng n để nghiên cứu kích thước của tập hợp điển hình của phân phối này. Như có thể thấy trong Hình 2(c), miễn là κ đủ lớn, entropy trung bình mỗi span H giảm rất ít từ mức tối đa lý thuyết, đó là H(p), đạt được khi κ = 1. Do đó, để cân bằng giữa việc đưa ra nhiễu trong các sự thật hỗ trợ và tạo ra các ví dụ đa dạng, chúng tôi đặt κ = 1 trong các thí nghiệm của chúng tôi.

Phân phối beta-Bernoulli trong dropout. Phân phối beta-Bernoulli đã được nghiên cứu trong công trình trước đây trong việc tìm kiếm sự thay thế cho cơ chế dropout (Bernoulli) (Srivastava et al., 2014). Liu et al. (2019a) đặt α = β cho phân phối beta trong công thức của họ, điều này giới hạn tỷ lệ dropout luôn là 0.5. Lee et al. (2018) cố định β = 1 và thay đổi α để kiểm soát độ thưa của kết quả dropout, tương tự như Beta-SPANDROP khi κ = 1. Tuy nhiên, chúng tôi lưu ý rằng những phương pháp này (như với dropout) tập trung nhiều hơn vào việc thêm nhiễu vào các biểu diễn nội bộ của mạng nơ-ron để đưa ra chính quy hóa, trong khi SPANDROP hoạt động trực tiếp trên đầu vào để loại bỏ các thành phần khác nhau trong đó, và do đó trực giao (và có khả năng bổ sung) với những phương pháp này. Hơn nữa, SPANDROP có lợi ích là không phải đưa ra bất kỳ giả định nào về mô hình hoặc bất kỳ thay đổi nào đối với nó trong quá trình huấn luyện, điều này làm cho nó có thể áp dụng rộng rãi hơn nhiều.

3 FINDANIMALS: Chưng cất Giám sát từ Chuỗi Dài
Trong phần này, chúng tôi thiết kế một nhiệm vụ tổng hợp để tìm một chuỗi con cụ thể trong một chuỗi ký tự để: a) chứng minh tính hiệu quả của SPANDROP và Beta-SPANDROP trong việc thúc đẩy hiệu suất trên một loạt các vấn đề với các thiết lập khác nhau, b) phân tích các yếu tố khác nhau có thể ảnh hưởng đến hiệu quả của những phương pháp này, và c) so sánh nó với các kỹ thuật tăng cường phản thực khác như che mặt nạ trong việc giảm thiểu thiên lệch vị trí.

--- TRANG 4 ---
3.1 Thiết lập Thí nghiệm
FINDANIMALS. Để hiểu tính hiệu quả của SPANDROP và Beta-SPANDROP theo kinh nghiệm, chúng tôi thiết kế một nhiệm vụ tổng hợp gọi là FINDANIMALS nơi mô hình được huấn luyện để phân biệt rằng cho một tên động vật a, ví dụ, "cat", liệu một chuỗi ký tự có chứa nó như một chuỗi con (tức là, chứa các ký tự trong "cat" theo thứ tự, ví dụ, "abcdafgbijktma") hay không (ví dụ, "abcdefhtijkamn"). Điều này cho phép chúng tôi dễ dàng kiểm soát tổng độ dài chuỗi n, kích thước sự thật hỗ trợ m, cũng như dễ dàng ước tính nhiễu sự thật hỗ trợ mà mỗi biến thể SPANDROP có thể đưa ra.¹

Trong tất cả các thí nghiệm của chúng tôi, chúng tôi đánh giá hiệu suất mô hình trên một tập hợp được giữ lại gồm 10.000 ví dụ để quan sát lỗi phân loại. Chúng tôi đặt độ dài chuỗi thành n = 300 nơi mỗi chữ cái là một span riêng biệt, và chọn vị trí cho các chữ cái trong tên động vật a (|a| = m = 3) một cách ngẫu nhiên đồng nhất trong chuỗi trừ khi được đề cập khác.

Mô hình. Chúng tôi sử dụng một mô hình Transformer ba lớp (Vaswani et al., 2017) với nhúng vị trí (Devlin et al., 2019) như bộ mã hóa chuỗi được thực hiện với HuggingFace Transformers (Wolf et al., 2019). Đối với mỗi ví dụ (a; S; y), chúng tôi đưa "[CLS] a [SEP] S [SEP]" vào mô hình và sau đó thực hiện phân loại nhị phân trên biểu diễn "[CLS]" để dự đoán y ∈ {0; 1}, trong đó y = 1 có nghĩa là a xuất hiện trong S. Để điều tra tính hiệu quả của SPANDROP, chúng tôi áp dụng SPANDROP lên S trước khi đưa chuỗi kết quả vào bộ phân loại Transformer.

3.2 Kết quả và Phân tích
Trong mỗi thí nghiệm, chúng tôi so sánh SPANDROP và Beta-SPANDROP với cùng tỷ lệ loại bỏ p. Và chúng tôi sử dụng thêm lấy mẫu từ chối để loại bỏ các ví dụ không bảo tồn các sự thật hỗ trợ mong muốn để hiểu tác động của nhiễu sự thật hỗ trợ.

Hiệu quả dữ liệu. Chúng tôi bắt đầu bằng việc phân tích đóng góp của SPANDROP và Beta-SPANDROP đối với việc cải thiện hiệu quả mẫu của mô hình cơ sở. Để đạt được mục tiêu này, chúng tôi thay đổi kích thước tập huấn luyện từ 10 đến 50.000 và quan sát lỗi dự đoán trên tập được giữ lại. Chúng tôi quan sát từ các kết quả trong Hình 3(a) rằng: 1) Cả SPANDROP và Beta-SPANDROP đều cải thiện đáng kể hiệu quả dữ liệu trong các thiết lập dữ liệu ít. Ví dụ, khi được huấn luyện chỉ trên 200 ví dụ huấn luyện, các biến thể SPANDROP có thể đạt được hiệu suất tổng quát hóa của mô hình cơ sở được huấn luyện trên 5× đến thậm chí 20× dữ liệu. 2) Việc loại bỏ nhiễu sự thật hỗ trợ thường cải thiện hiệu quả dữ liệu thêm khoảng 2×. Điều này chỉ ra rằng việc không loại bỏ các span trong Ssup trong quá trình huấn luyện khi có thể là hữu ích, để mô hình luôn được huấn luyện với các ví dụ phản thực thực sự thay vì đôi khi là những ví dụ nhiễu. 3) Beta-SPANDROP liên tục cải thiện mô hình cơ sở ngay cả khi dữ liệu dồi dào. Điều này có thể là do khó khăn của nhiệm vụ khi n = 300 và m = 3. Tương tự như nhiều nhiệm vụ thực tế, nhiệm vụ vẫn thiếu đặc tả ngay cả khi lỗi tổng quát hóa đã rất thấp, nhờ vào lượng lớn dữ liệu huấn luyện có sẵn. 4) SPANDROP đưa ra mục tiêu huấn luyện không nhất quán với tập huấn luyện gốc, dẫn đến suy giảm hiệu suất khi có đủ dữ liệu huấn luyện, điều này nhất quán với quan sát lý thuyết của chúng tôi.

Tác động của nhiễu sự thật hỗ trợ. Vì SPANDROP đưa ra nhiễu trong các sự thật hỗ trợ (mặc dù với xác suất thấp), điều tự nhiên là hỏi liệu nhiễu như vậy có tương quan âm với hiệu suất mô hình hay không. Chúng tôi nghiên cứu điều này bằng cách thay đổi tỷ lệ loại bỏ p từ {0.05; 0.1; 0.15; 0.2; 0.3; 0.4; 0.5} trên các tập huấn luyện cố định kích thước 1.000, và quan sát hiệu suất mô hình kết quả và lỗi sự thật hỗ trợ. Như có thể thấy trong Hình 3(b), nhiễu sự thật hỗ trợ tăng nhanh khi p tăng.² Tuy nhiên, chúng tôi lưu ý rằng mặc dù hiệu suất của SPANDROP giảm khi p tăng, hiệu suất của Beta-SPANDROP vẫn tương đối ổn định. Kiểm tra những kết quả này kỹ hơn, chúng tôi thấy rằng ngay cả hiệu suất của các biến thể không nhiễu cũng tuân theo một xu hướng tương tự, điều này không nên bị ảnh hưởng bởi nhiễu sự thật hỗ trợ.

Tác động của độ dài chuỗi và sự thật hỗ trợ. Trong phân tích lý thuyết của chúng tôi, độ dài chuỗi n xác định cường độ chính quy hóa và dịch chuyển trong phân phối độ dài chuỗi, và kích thước sự thật hỗ trợ m xác định xác suất ví dụ phản thực giữ lại tín hiệu giám sát đúng. Để nghiên cứu tác động của chúng theo kinh nghiệm, chúng tôi tiến hành ba tập hợp thí nghiệm riêng biệt: 1) huấn luyện và kiểm tra mô hình trên các độ dài chuỗi khác nhau {10, 20, 30, 50, 100, 200, 300, 500}; 2) thay đổi kích thước sự thật hỗ trợ từ 2 đến 10; và 3) kiểm tra mô hình được huấn luyện trên n = 300 trên các tập kiểm tra có độ dài khác nhau.

Như có thể thấy từ Hình 3(c) và 3(e), kết quả thí nghiệm của chúng tôi dường như ủng hộ tốt giả thuyết này rằng khoảng cách giữa hai biến thể SPANDROP có liên quan nhiều đến sự khác biệt trong phân phối độ dài. Cụ thể, trong Hình 3(c), trong khi hiệu suất của cả hai biến thể SPANDROP đều giảm khi n tăng và nhiệm vụ trở nên khó khăn và thiếu đặc tả hơn, SPANDROP giảm với tốc độ nhanh hơn ngay cả khi chúng tôi loại bỏ tác động của nhiễu sự thật hỗ trợ. Mặt khác, chúng tôi thấy trong Hình 3(e) rằng hiệu suất SPANDROP đạt đỉnh xung quanh các chuỗi có độ dài 270 (= n(1 − p) = 300(1 − 0.1)) trước khi giảm nhanh chóng, trong khi Beta-SPANDROP không bị ảnh hưởng cho đến khi độ dài chuỗi kiểm tra vượt quá độ dài của tất cả các ví dụ được thấy trong quá trình huấn luyện.

Trong Hình 3(d), chúng tôi cũng có thể thấy rằng như được dự đoán bởi Nhận xét 1 và 2, Beta-SPANDROP tốt hơn trong việc bảo tồn tất cả sự thật hỗ trợ so với SPANDROP bất kể vị trí của chúng, điều này chuyển thành hiệu suất vượt trội.

Giảm thiểu thiên lệch vị trí. Bên cạnh SPANDROP, các kỹ thuật dựa trên thay thế như che mặt nạ cũng có thể được áp dụng để xây dựng các ví dụ phản thực, nơi các phần tử trong chuỗi được thay thế bằng một ký hiệu đặc biệt không được sử dụng tại thời điểm kiểm tra. Chúng tôi thực hiện SPANMASK theo cách tương tự như SPANDROP ngoại trừ các span được thay thế thay vì loại bỏ khi mặt nạ "loại bỏ" được lấy mẫu εi là 0. Chúng tôi đầu tiên kiểm tra liệu SPANMASK có được lợi từ cùng phân phối beta-Bernoulli mà chúng tôi sử dụng trong SPANDROP hay không. Như có thể thấy trong Hình 3(f), lợi ích từ việc chuyển sang phân phối beta-Bernoulli cung cấp lợi ích không đáng kể cho SPANMASK, điều này không thay đổi độ dài chuỗi của đầu vào ngay từ đầu. Chúng tôi cũng thấy rằng SPANMASK dẫn đến lỗi cao hơn đáng kể so với cả SPANDROP và Beta-SPANDROP trong thiết lập này.

Chúng tôi tiếp tục thí nghiệm với việc đưa thiên lệch vị trí vào dữ liệu huấn luyện (nhưng không phải dữ liệu kiểm tra) để kiểm tra liệu những phương pháp này có giúp mô hình tổng quát hóa cho một thiết lập chưa được thấy hay không. Cụ thể, thay vì chọn vị trí cho các ký tự trong a một cách ngẫu nhiên đồng nhất, chúng tôi huấn luyện mô hình với một tập dữ liệu "vị trí cố định" nơi chúng luôn xuất hiện tại các chỉ số (10, 110, 210), và một tập dữ liệu "100 đầu tiên" nơi chúng được phân phối đồng nhất trong 100 chữ cái đầu tiên. Như có thể thấy trong Hình 3(g), cả mô hình cơ sở và SPANMASK đều quá khớp với thiên lệch vị trí trong thiết lập "cố định", trong khi các kỹ thuật SPANDROP giảm đáng kể lỗi tổng quát hóa zero-shot. Trong thiết lập "100 đầu tiên", Beta-SPANDROP liên tục vượt trội hơn đối tác Bernoulli của nó và SPANMASK trong việc cải thiện hiệu suất của mô hình cơ sở, chỉ ra rằng các biến thể SPANDROP hiệu quả trong việc giảm thiên lệch vị trí của mô hình.

Tác động đến tốc độ hội tụ. Chính quy hóa thường được chỉ ra là làm chậm hội tụ mô hình, dẫn đến nhu cầu thời gian huấn luyện dài hơn nhiều cho các cải thiện hiệu suất cận biên. Tuy nhiên, chúng tôi chỉ ra trong Hình 3(h) rằng các phương pháp SPANDROP dường như không gặp phải vấn đề này trên nhiệm vụ tổng hợp. Ngược lại, cả hai phương pháp đều giúp mô hình tổng quát hóa tốt hơn đáng kể trong cùng lượng thời gian huấn luyện.

4 Thí nghiệm trên Dữ liệu Ngôn ngữ Tự nhiên
Để kiểm tra hiệu quả của các kỹ thuật SPANDROP được đề xuất trên dữ liệu thực tế, chúng tôi tiến hành thí nghiệm trên bốn tập dữ liệu NLP đại diện cho nhiều nhiệm vụ khác nhau. Chúng tôi tập trung vào việc hiển thị tác động của SPANDROP thay vì theo đuổi kỹ thuật tiên tiến trong những thí nghiệm này.

4.1 Thiết lập và Kết quả Chính
Tập dữ liệu. Chúng tôi sử dụng bốn tập dữ liệu xử lý ngôn ngữ tự nhiên: SQuAD 1.1 (Rajpurkar et al., 2016), nơi các mô hình trả lời câu hỏi trên một đoạn văn bản từ Wikipedia; MultiRC (Khashabi et al., 2018), là một nhiệm vụ đọc hiểu đa lựa chọn trong đó các câu hỏi chỉ có thể được trả lời bằng cách tính đến thông tin từ nhiều câu; HotpotQA (Yang et al., 2018), đòi hỏi các mô hình thực hiện lý luận đa bước trên nhiều trang Wikipedia để trả lời câu hỏi; và DocRED (Yao et al., 2019), là một tập dữ liệu cấp tài liệu để trích xuất mối quan hệ.

Đối với tập dữ liệu SQuAD, chúng tôi định nghĩa span như các tập hợp của một hoặc nhiều token liên tiếp để chỉ ra rằng SPANDROP có thể được áp dụng cho các độ chi tiết khác nhau. Được hướng dẫn bởi phân tích lý thuyết của chúng tôi, chúng tôi cũng thí nghiệm với một phương pháp phân đoạn span thích ứng để giảm số lượng sự thật hỗ trợ (m) bằng cách kết hợp tất cả chồng chéo N-gram giữa câu hỏi và ngữ cảnh thành một span duy nhất (N ≤ 2). Đối với ba tập dữ liệu còn lại, chúng tôi định nghĩa span là các câu vì sự thật hỗ trợ được cung cấp ở cấp câu. Đối với tất cả những nhiệm vụ này, chúng tôi báo cáo các chỉ số khớp chính xác (EM) và F1 tiêu chuẩn nơi áp dụng, với điểm số cao hơn là tốt hơn. Chúng tôi tham khảo người đọc đến phụ lục để biết chi tiết về thống kê và chỉ số của những tập dữ liệu này.

Mô hình. Chúng tôi xây dựng các mô hình của mình dựa trên ELECTRA (Clark et al., 2019), vì nó được chỉ ra hoạt động tốt trên một loạt các nhiệm vụ NLP gần đây. Chúng tôi giới thiệu các tham số cụ thể theo nhiệm vụ được khởi tạo ngẫu nhiên được thiết kế cho mỗi nhiệm vụ theo công trình trước đây trên mỗi tập dữ liệu, và tinh chỉnh những mô hình này trên mỗi tập dữ liệu để báo cáo kết quả. Chúng tôi tham khảo người đọc đến phụ lục để biết chi tiết huấn luyện và thiết lập siêu tham số.

Kết quả Chính. Chúng tôi đầu tiên trình bày hiệu suất của các mô hình được thực hiện và sự kết hợp của chúng với các biến thể SPANDROP trên bốn nhiệm vụ xử lý ngôn ngữ tự nhiên. Chúng tôi cũng bao gồm kết quả từ các công trình đại diện trước đây trên mỗi tập dữ liệu để tham khảo (chi tiết trong phụ lục), và tóm tắt kết quả trong Bảng 1. Chúng tôi quan sát rằng: 1) các mô hình được thực hiện của chúng tôi đạt được hiệu suất cạnh tranh và đôi khi tốt hơn đáng kể (trong các trường hợp của HotpotQA, SQuAD, và DocRED) so với các kết quả được công bố, đặc biệt xem xét rằng chúng tôi không điều chỉnh các mô hình của mình cho từng nhiệm vụ quá nhiều; 2) SPANDROP cải thiện hiệu suất trên những mô hình này ngay cả khi tập huấn luyện lớn và mô hình đã hoạt động tốt; 3) Các mô hình được huấn luyện với Beta-SPANDROP liên tục hoạt động tốt hơn hoặc bằng với các đối tác SPANDROP của chúng trên tất cả các tập dữ liệu, chứng minh rằng các quan sát của chúng tôi trên các tập dữ liệu tổng hợp tổng quát hóa tốt cho những tập dữ liệu thực tế. Chúng tôi lưu ý rằng lợi ích hiệu suất trên dữ liệu thực tế ít đáng kể hơn, có thể do thực tế là các span không hỗ trợ trong nhiệm vụ tổng hợp độc lập với nhau, điều này không phải trường hợp trong dữ liệu ngôn ngữ tự nhiên.

--- TRANG 5 ---
(a) HotpotQA dev
Mô hình | Ans F1 | Sup F1 | Joint F1
RoBERTa-base | 73.5 | 83.4 | 63.5
Longformer-base | 74.3 | 84.4 | 64.4
SAE BERT-base | 73.6 | 84.6 | 65.0
Thực hiện của chúng tôi
ELECTRA-base | 74.2 | 86.3 | 66.2
+ SPANDROP | 74.7 | 86.7 | 66.8
+ Beta-SPANDROP | 74.7 | 86.9 | 67.1

(b) MultiRC dev/test
Mô hình | EM | F1
BERT-base | 26.6/24.1 | 71.8/70.1
RoBERTa-base | 38.7/— | 77.1/—
REPT RoBERTa-base | 40.4/— | 80.0/—
Thực hiện của chúng tôi
ELECTRA-base | 40.1/39.1 | 80.4/78.2
+ SPANDROP | 42.3/39.9 | 81.7/78.5
+ Beta-SPANDROP | 44.8/41.1 | 81.6/79.8

(c) DocRED dev
Mô hình | Ign F1 | RE F1 | Evi F1
E2GRE BERT-base | 55.2 | 58.7 | 47.1
ATLOP BERT-base | 59.2 | 61.1 | —
SSAN BERT-base | 57.0 | 59.2 | —
Thực hiện của chúng tôi
ELECTRA-base | 59.6 | 61.6 | 50.8
+ SPANDROP | 59.9 | 61.9 | 51.2
+ Beta-SPANDROP | 60.1 | 62.1 | 51.2

(d) SQuAD dev
Mô hình | EM | F1
RoBERTa-base | — | 90.6
ELECTRA-base | 84.5 | 90.8
XLNet-large | 89.7 | 95.1
Thực hiện của chúng tôi
ELECTRA-base | 86.6 | 92.4
+ SPANDROP w/ adaptive spans | 87.4 | 92.9
+ Beta-SPANDROP w/ adaptive spans | 87.3 | 92.8

Bảng 1: Kết quả chính trên bốn tập dữ liệu xử lý ngôn ngữ tự nhiên.

4.2 Phân tích
Để hiểu liệu các tính chất của SPANDROP và Beta-SPANDROP mà chúng tôi quan sát trên FINDANIMALS có tổng quát hóa cho dữ liệu thực tế hay không, chúng tôi tiếp tục thực hiện một tập hợp các thí nghiệm phân tích trên SQuAD. Cụ thể, chúng tôi quan tâm đến việc nghiên cứu tác động của lượng dữ liệu huấn luyện, tỷ lệ loại bỏ span p, và sự lựa chọn kích thước span đối với hiệu suất.

Tác động của dữ liệu ít. Để hiểu tác động chính quy hóa của SPANDROP khi dữ liệu huấn luyện khan hiếm, chúng tôi nghiên cứu hiệu suất tổng quát hóa của mô hình khi huấn luyện chỉ trên 0.1% dữ liệu huấn luyện (khoảng 100 ví dụ) đến sử dụng toàn bộ tập huấn luyện (khoảng 88k ví dụ). Như được hiển thị trong Hình 4 (trái), cả SPANDROP và Beta-SPANDROP đều cải thiện đáng kể hiệu suất mô hình khi lượng dữ liệu huấn luyện cực kỳ thấp. Khi lượng dữ liệu huấn luyện tăng, khoảng cách này từ từ thu hẹp nhưng vẫn liên tục dương. Khi tất cả dữ liệu huấn luyện được sử dụng, khoảng cách vẫn đủ để phân biệt 2 hệ thống hoạt động tốt nhất trên tập dữ liệu này.

Tác động của tỷ lệ loại bỏ. Chúng tôi so sánh SPANDROP và Beta-SPANDROP bằng cách kiểm soát khả năng mỗi span bị loại bỏ trung bình (tỷ lệ loại bỏ p). Nhớ lại từ các thí nghiệm của chúng tôi trên FINDCATS rằng p lớn hơn sẽ dẫn đến dịch chuyển phân phối từ tập huấn luyện gốc cho SPANDROP nhưng không phải Beta-SPANDROP, do đó hiệu suất của cái trước giảm khi p tăng trong khi cái sau hầu như không bị ảnh hưởng. Như có thể thấy trong Hình 4 (giữa), quan sát của chúng tôi trên dữ liệu thực tế nhất quán với dự đoán lý thuyết này, và chỉ ra rằng Beta-SPANDROP là một kỹ thuật tốt hơn cho tăng cường dữ liệu nếu muốn tăng tính đa dạng chuỗi bằng cách đặt p thành một giá trị lớn hơn.

Tác động của lựa chọn span. Chúng tôi huấn luyện mô hình với SPANDROP trên SQuAD với các kích thước span cố định khác nhau {1, 2, 4, 8, 16, 32, 64} token mỗi span, cũng như kích thước span thích ứng có động lực nhiệm vụ, để hiểu tác động của siêu tham số này. Chúng tôi quan sát trong Hình 4 (phải) rằng khi kích thước span tăng, hiệu suất tổng quát hóa của mô hình đầu tiên giữ gần như không đổi, sau đó từ từ giảm khi kích thước span trở nên quá lớn. Span thích ứng ("ad") vượt trội đáng kể so với tất cả kích thước span cố định, gợi ý rằng trong khi kích thước span cố định lớn hơn giảm m và do đó nhiễu trong sự thật hỗ trợ, việc giảm n kết quả cản trở cường độ chính quy hóa và do đó làm tổn hại tổng quát hóa. Quan sát này cũng nhất quán với dữ liệu tổng hợp của chúng tôi cũng như những gì sẽ được dự đoán bởi phân tích lý thuyết của chúng tôi. Điều này cũng gợi ý rằng trong khi SPANDROP hoạt động với kích thước span tùy ý, sự lựa chọn tối ưu của span cho các nhiệm vụ khác nhau đáng được điều tra thêm, mà chúng tôi để lại cho công việc tương lai.

--- TRANG 6 ---
5 Công trình Liên quan
Suy luận Chuỗi Dài. Nhiều ứng dụng yêu cầu dự đoán/suy luận trên các chuỗi dài, chẳng hạn như đọc hiểu đa bước (Yang et al., 2018; Welbl et al., 2018), tóm tắt tài liệu dài (Huang et al., 2021), trích xuất thông tin cấp tài liệu (Yao et al., 2019) trong xử lý ngôn ngữ tự nhiên, dự đoán chuỗi thời gian dài (Zhou et al., 2021a), dự đoán vùng promoter và profile chromatin trong chuỗi DNA (Oubounyt et al., 2019; Zhou & Troyanskaya, 2015) trong Genomics, v.v., nơi không phải tất cả các phần tử trong chuỗi dài đều đóng góp bình đẳng cho đầu ra mong muốn. Ngoài các phương pháp cố gắng xấp xỉ tất cả tương tác cặp đôi giữa các phần tử trong một chuỗi, công trình gần đây hơn cũng đã điều tra việc nén các chuỗi dài thành những chuỗi ngắn hơn để chưng cất thông tin trong đó cho dự đoán hoặc học biểu diễn (Rae et al., 2020; Goyal et al., 2020; Kim & Cho, 2021).

Tăng cường Dữ liệu Chuỗi. Tăng cường dữ liệu là một kỹ thuật phổ biến hiệu quả cho các nhiệm vụ thiếu đặc tả như suy luận chuỗi dài. Feng et al. (2021) đề xuất nhóm các kỹ thuật tăng cường dữ liệu phổ biến trong xử lý ngôn ngữ tự nhiên thành ba loại: 1) phương pháp dựa trên quy tắc (Zhang et al., 2015; Wei & Zou, 2019; Şahin & Steedman, 2018), áp dụng một tập hợp các thao tác được định nghĩa trước trên đầu vào thô, chẳng hạn như loại bỏ, thêm, xáo trộn và thay thế; 2) phương pháp dựa trên mixup ví dụ (Guo et al., 2019; Guo, 2020; Chen et al., 2020; Jindal et al., 2020), được lấy cảm hứng từ Mixup trong thị giác máy tính (Zhang et al., 2018), thực hiện nội suy giữa các tính năng liên tục như nhúng từ và nhúng câu; 3) phương pháp dựa trên mô hình (Xie et al., 2020; Sennrich et al., 2016), sử dụng các mô hình được huấn luyện để tạo ra các ví dụ mới (ví dụ, dịch ngược Xie et al., 2020).

Hầu hết các phương pháp tăng cường dữ liệu dựa trên quy tắc hiện có hoạt động ở cấp token/từ (Feng et al., 2021), chẳng hạn như xáo trộn/thay thế/thêm từ (Wei & Zou, 2019). Các kỹ thuật dựa trên xáo trộn ít áp dụng hơn khi thông tin thứ tự quan trọng trong dữ liệu thô (Lan et al., 2019, ví dụ, trong ngôn ngữ tự nhiên). Clark et al. (2019) và Lewis et al. (2020) gần đây đã chỉ ra rằng tăng cường cấp từ được thiết kế tốt cũng có thể dẫn đến các mô hình được tiền huấn luyện cải thiện, nhưng việc tổng quát hóa ý tưởng này cho các cụm từ hoặc câu ít đơn giản hơn. Ngược lại, SPANDROP được đề xuất của chúng tôi hỗ trợ tăng cường dữ liệu ở nhiều độ chi tiết, và có thể dành riêng thứ tự chuỗi vì thao tác loại bỏ không thay đổi thứ tự tương đối của đầu vào gốc, điều này quan trọng trong nhiều loại dữ liệu chuỗi như ngôn ngữ tự nhiên.

6 Kết luận
Trong bài báo này, chúng tôi trình bày SPANDROP, một phương pháp đơn giản và hiệu quả để học từ các chuỗi dài, loại bỏ các phần của chuỗi một cách ngẫu nhiên để tạo ra dữ liệu phản thực nhằm chưng cất tín hiệu giám sát thưa có tính dự đoán của đầu ra mong muốn. Chúng tôi chỉ ra thông qua phân tích lý thuyết và các tập dữ liệu tổng hợp được thiết kế cẩn thận rằng SPANDROP và biến thể của nó dựa trên phân phối beta-Bernoulli, Beta-SPANDROP, giúp các mô hình đạt được hiệu suất cạnh tranh với một phần dữ liệu bằng cách giới thiệu các ví dụ huấn luyện tăng cường đa dạng, và tổng quát hóa tốt hơn cho dữ liệu chưa được thấy trước đây. Các thí nghiệm của chúng tôi trên bốn tập dữ liệu NLP thực tế xác nhận những phát hiện lý thuyết này, và chứng minh hiệu quả của SPANDROP trên các mô hình nơ-ron mạnh ngay cả khi dữ liệu dồi dào.

--- TRANG 7 ---
Tài liệu tham khảo
Wei Bao, Jun Yue, and Yulei Rao. A deep learning framework for financial time series using stacked autoencoders and long-short term memory. PloS one, 12(7):e0180944, 2017.

Iz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150, 2020.

Jiaao Chen, Zichao Yang, and Diyi Yang. MixText: Linguistically-informed interpolation of hidden space for semi-supervised text classification. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 2147–2157, 2020.

Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, et al. Rethinking attention with Performers. In International Conference on Learning Representations, 2020.

Kevin Clark, Minh-Thang Luong, Quoc V Le, and Christopher D Manning. ELECTRA: Pre-training text encoders as discriminators rather than generators. In International Conference on Learning Representations, 2019.

Andrew M Dai and Quoc V Le. Semi-supervised sequence learning. Advances in neural information processing systems, 28:3079–3087, 2015.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In NAACL-HLT, 2019.

Steven Y Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, and Eduard Hovy. A survey of data augmentation approaches for nlp. Findings of ACL, 2021.

Yarin Gal and Zoubin Ghahramani. A theoretically grounded application of dropout in recurrent neural networks. In Proceedings of the 30th International Conference on Neural Information Processing Systems, 2016.

Saurabh Goyal, Anamitra Roy Choudhury, Saurabh Raje, Venkatesan Chakaravarthy, Yogish Sabharwal, and Ashish Verma. Power-bert: Accelerating bert inference via progressive word-vector elimination. In International Conference on Machine Learning, pp. 3690–3699. PMLR, 2020.

Hongyu Guo. Nonlinear mixup: Out-of-manifold data augmentation for text classification. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 4044–4051, 2020.

Hongyu Guo, Yongyi Mao, and Richong Zhang. Augmenting data with mixup for sentence classification: An empirical study. arXiv preprint arXiv:1905.08941, 2019.

Kevin Huang, Qi Peng, Guangtao Wang, Tengyu Ma, and Jing Huang. Entity and evidence guided relation extraction for docred. arXiv preprint arXiv:2008.12283, 2020.

Luyang Huang, Shuyang Cao, Nikolaus Parulian, Heng Ji, and Lu Wang. Efficient attentions for long document summarization. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1419–1436, 2021.

Fangkai Jiao, Yangyang Guo, Yilin Niu, Feng Ji, Feng-Lin Li, and Liqiang Nie. REPT: Bridging language models and machine reading comprehension via retrieval-based pre-training. arXiv preprint arXiv:2105.04201, 2021.

Amit Jindal, Arijit Ghosh Chowdhury, Aniket Didolkar, Di Jin, Ramit Sawhney, and Rajiv Shah. Augmenting nlp models using latent feature interpolations. In Proceedings of the 28th International Conference on Computational Linguistics, pp. 6931–6936, 2020.

John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. Nature, 596(7873):583–589, 2021.

Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and François Fleuret. Transformers are RNNs: Fast autoregressive transformers with linear attention. In International Conference on Machine Learning. PMLR, 2020.

Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan Roth. Looking beyond the surface: A challenge set for reading comprehension over multiple sentences. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2018.

Gyuwan Kim and Kyunghyun Cho. Length-adaptive transformer: Train once with length drop, use anytime with search. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pp. 6501–6511, 2021.

Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. In International Conference on Learning Representations, 2019.

Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. ALBERT: A lite bert for self-supervised learning of language representations. In International Conference on Learning Representations, 2019.

Juho Lee, Saehoon Kim, Jaehong Yoon, Hae Beom Lee, Eunho Yang, and Sung Ju Hwang. Adaptive network sparsification with dependent variational beta-bernoulli dropout. arXiv preprint arXiv:1805.10896, 2018.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020.

Lei Liu, Yuhao Luo, Xu Shen, Mingzhai Sun, and Bin Li. β-dropout: A unified dropout. IEEE Access, 7:36140–36153, 2019a.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pretraining approach. arXiv preprint arXiv:1907.11692, 2019b.

Mhaned Oubounyt, Zakaria Louadi, Hilal Tayara, and Kil To Chong. Deepromoter: robust promoter predictor using deep learning. Frontiers in genetics, 10:286, 2019.

Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah Smith, and Lingpeng Kong. Random feature attention. In International Conference on Learning Representations, 2020.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

Jack W. Rae, Anna Potapenko, Siddhant M. Jayakumar, Chloe Hillier, and Timothy P. Lillicrap. Compressive transformers for long-range sequence modelling. In International Conference on Learning Representations, 2020.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions for machine comprehension of text. In EMNLP, 2016.

Gözde Gül Şahin and Mark Steedman. Data augmentation via dependency tree morphing for low-resource languages. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 5004–5009, 2018.

Rico Sennrich, Barry Haddow, and Alexandra Birch. Improving neural machine translation models with monolingual data. In 54th Annual Meeting of the Association for Computational Linguistics, pp. 86–96, 2016.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929–1958, 2014.

Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, and Donald Metzler. Long range arena: A benchmark for efficient transformers. In International Conference on Learning Representations, 2020.

Ming Tu, Kevin Huang, Guangtao Wang, Jing Huang, Xiaodong He, and Bowen Zhou. Select, answer and explain: Interpretable multi-hop reading comprehension over multiple documents. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 9073–9080, 2020.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pp. 5998–6008, 2017.

Jason Wei and Kai Zou. EDA: Easy data augmentation techniques for boosting performance on text classification tasks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pp. 6382–6388, 2019.

Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. Constructing datasets for multi-hop reading comprehension across documents. Transactions of the Association for Computational Linguistics, 6:287–302, 2018.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771, 2019.

Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le. Unsupervised data augmentation for consistency training. In Advances in Neural Information Processing Systems, 2020.

Benfeng Xu, Quan Wang, Yajuan Lyu, Yong Zhu, and Zhendong Mao. Entity structure within and throughout: Modeling mention dependencies for document-level relation extraction. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pp. 14149–14157, 2021.

Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 2369–2380, 2018.

Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. XLNet: Generalized autoregressive pretraining for language understanding. In Advances in Neural Information Processing Systems, 2019.

Yuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, and Maosong Sun. DocRED: A large-scale document-level relation extraction dataset. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 764–777, 2019.

Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. Big Bird: Transformers for longer sequences. In Advances in Neural Information Processing Systems, 2020.

Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. In International Conference on Learning Representations, 2018.

Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text classification. In Advances in Neural Information Processing Systems, pp. 649–657, 2015.

Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. Informer: Beyond efficient transformer for long sequence time-series forecasting. In Proceedings of AAAI, 2021a.

Jian Zhou and Olga G Troyanskaya. Predicting effects of noncoding variants with deep learning–based sequence model. Nature methods, 12(10):931–934, 2015.

Wenxuan Zhou, Kevin Huang, Tengyu Ma, and Jing Huang. Document-level relation extraction with adaptive thresholding and localized context pooling. In Proceedings of the AAAI Conference on Artificial Intelligence, 2021b.

--- TRANG 8 ---
A Phụ lục
A.1 Thống kê của Các Tập Dữ liệu Chuẩn
Trong phần này, chúng tôi tóm tắt thống kê của bốn tập dữ liệu xử lý ngôn ngữ tự nhiên được sử dụng trong các thí nghiệm của chúng tôi trong Bảng 2. Đối với SQuAD, vì tập dữ liệu không chú thích sự thật hỗ trợ, chúng tôi ước tính gần đúng sự thật hỗ trợ bằng cách đếm các token là phần của một bigram xuất hiện trong câu hỏi.

A.2 Thiết lập Thí nghiệm cho Các Nhiệm vụ Khác nhau
Phần này giới thiệu các triển khai chi tiết của các phương pháp của chúng tôi trên bốn tập dữ liệu chuẩn, cũng như thiết lập siêu tham số cho tối ưu hóa mô hình và các baseline để so sánh với các triển khai của chúng tôi.

A.2.1 HotpotQA
Chi tiết triển khai. Mục tiêu của HotpotQA là trả lời câu hỏi từ một tập hợp 10 đoạn văn nơi hai đoạn văn có liên quan đến câu hỏi và phần còn lại là các yếu tố gây nhiễu. HotpotQA trình bày hai nhiệm vụ: dự đoán span trả lời và dự đoán câu bằng chứng (tức là, sự thật hỗ trợ). Mô hình HotpotQA của chúng tôi bao gồm hai giai đoạn: giai đoạn đầu tiên chọn 4 đoạn văn hàng đầu từ 10 ứng viên bằng một mô hình truy xuất. Giai đoạn thứ hai tìm span trả lời cuối cùng và bằng chứng trên 4 đoạn văn được chọn. Chúng tôi đặc biệt đưa định dạng đầu vào sau vào bộ mã hóa: "[CLS] question [SEP] sent 1;1[SEP] sent 1;2[SEP] sent 4;1[SEP] sent 4;2 [SEP]". Và chúng tôi áp dụng các phương pháp loại bỏ span được đề xuất trên tất cả các câu ngoại trừ sự thật hỗ trợ.

Đối với dự đoán span trả lời, chúng tôi sử dụng mô hình dự đoán span trả lời trong (Devlin et al., 2019) với một đầu phân loại loại câu hỏi bổ sung (yes/no/span) trên token đặc biệt đầu tiên ([CLS]). Đối với trích xuất bằng chứng, chúng tôi áp dụng các MLP hai lớp trên các biểu diễn tương ứng với câu và đoạn văn để có được điểm dự đoán bằng chứng tương ứng và sử dụng hàm mất binary cross entropy để huấn luyện mô hình. Cuối cùng, chúng tôi kết hợp các mất mát span trả lời, loại câu hỏi, bằng chứng câu, và đoạn văn liên quan và huấn luyện mô hình theo cách đa nhiệm vụ sử dụng kết hợp tuyến tính của các hàm mất mát. Không gian tìm kiếm siêu tham số cho các mô hình của chúng tôi trên HotpotQA được đưa ra trong Bảng 3.

Baseline. Chúng tôi so sánh triển khai mô hình HotpotQA của chúng tôi trên Electra với các baseline mạnh sau: 1) mô hình dựa trên RoBERTa (Liu et al., 2019b), 2) mô hình dựa trên bộ mã hóa chuỗi dài Longformer (Beltagy et al., 2020) và 3) SAE (Tu et al., 2020) kết hợp mạng nơ-ron đồ thị và các mô hình ngôn ngữ được tiền huấn luyện cho trả lời câu hỏi đa bước và là mô hình SOTA hiện tại trên HotpotQA. Các số được báo cáo trong bài báo của chúng tôi cho hai mô hình đầu tiên đến từ (Zaheer et al., 2020).

A.2.2 MultiRC
Chi tiết triển khai. MultiRC là một nhiệm vụ trả lời câu hỏi đa lựa chọn, cung cấp một tập hợp các lựa chọn thay thế hoặc câu trả lời có thể cho câu hỏi và yêu cầu chọn (các) câu trả lời tốt nhất dựa trên nhiều câu trong khi một vài câu này (tức là, sự thật hỗ trợ) có liên quan đến các câu hỏi. Đối với ví dụ đã cho của k câu trả lời ứng viên và n câu, chúng tôi đầu tiên đưa đầu vào sau vào bộ mã hóa: "[CLS] question [SEP] answer 1[SEP] answer 2 [SEP]answerk[SEP] sentence 1[SEP] sentence 2[SEP] sentencen[SEP]". Đối với dự đoán trả lời, chúng tôi áp dụng các MLP hai lớp trên các biểu diễn tương ứng với câu trả lời ứng viên và câu để có được điểm trả lời và câu tương ứng, và sử dụng kết hợp của hai hàm mất binary cross entropy để huấn luyện mô hình theo cách đa nhiệm vụ. Chúng tôi áp dụng các phương pháp loại bỏ span của chúng tôi trên tất cả câu đầu vào ngoại trừ các câu bằng chứng. Không gian tìm kiếm siêu tham số cho các mô hình MultiRC của chúng tôi được đưa ra trong Bảng 3.

Baseline. Chúng tôi so sánh triển khai mô hình MultiRC của chúng tôi trên Electra với các baseline sau: 1) mô hình dựa trên BERT, 2) mô hình dựa trên RoBERTa (Liu et al., 2019b) và 3) REPT (RoBERTa-base) được huấn luyện với các nhiệm vụ huấn luyện bổ sung mới (Jiao et al., 2021).

A.2.3 Nhiệm vụ trích xuất mối quan hệ: DocRED
Chi tiết triển khai. DocRED là trích xuất mối quan hệ cấp tài liệu bao gồm hai nhiệm vụ: dự đoán mối quan hệ của một cặp thực thể đã cho và dự đoán bằng chứng. Chúng tôi xây dựng các đầu vào được hướng dẫn bởi thực thể cho bộ mã hóa theo công trình trước đây Huang et al. (2020). Mỗi ví dụ huấn luyện được tổ chức bằng cách nối thực thể đầu, cùng với n câu trong tài liệu như "[CLS] head entity [SEP] sentence 1[SEP] sentence 2[SEP]sentencen[SEP]". Đối với cả trích xuất mối quan hệ và dự đoán bằng chứng, chúng tôi áp dụng một biến đổi biaffine kết hợp các biểu diễn thực thể và biểu diễn thực thể/câu, tương ứng, và chấm điểm chúng sử dụng hàm mất adaptive threshold được đề xuất bởi Zhou et al. (2021b). Chúng tôi huấn luyện mô hình trong thiết lập đa nhiệm vụ bằng cách sử dụng kết hợp tuyến tính của các hàm mất trích xuất mối quan hệ và dự đoán bằng chứng. Và chúng tôi áp dụng các phương pháp loại bỏ span được đề xuất trên tất cả câu đầu vào ngoại trừ những câu phục vụ như bằng chứng cho các mối quan hệ thực thể với thực thể đầu. Vui lòng tham khảo Bảng 3 cho không gian tìm kiếm siêu tham số của các mô hình DocRED của chúng tôi.

Baseline. Chúng tôi so sánh với một tập hợp các baseline mạnh w.r.t. mối quan hệ cấp tài liệu bao gồm: 1) E2GRE (Huang et al., 2020), 2) ATLOP (Zhou et al., 2021b) và 3) SSAN (Xu et al., 2021).

A.2.4 SQuAD
Chi tiết triển khai. SQuAD nhằm mục đích trích xuất một đoạn văn bản từ một đoạn văn đã cho như câu trả lời cho câu hỏi. Chúng tôi định dạng ví dụ đầu vào như "[CLS] question [SEP] paragraph [SEP]" và đưa vào bộ mã hóa. Theo công trình trước đây, chúng tôi sử dụng một cơ chế dự đoán span nơi cuối span được điều kiện hóa trên biểu diễn của đầu span, được trình bày ban đầu trong bài báo XLNet (Yang et al., 2019). Và chúng tôi áp dụng các phương pháp loại bỏ span được đề xuất của chúng tôi trên đoạn văn trước khi đưa nó vào mô hình để huấn luyện, nơi các span chứa bigram câu hỏi được bảo tồn. Không gian siêu tham số để tối ưu hóa mô hình SQuAD được hiển thị trong Bảng 3.

Baseline. Chúng tôi triển khai các mô hình cho SQuAD dựa trên ELECTRA (Clark et al., 2019) và so sánh chúng với các triển khai mô hình hiện có cho SQuAD dựa trên 1) ELECTRA (Clark et al., 2019), 2) RoBERTa (Liu et al., 2019b) và 3) XLNet (Yang et al., 2019), tương ứng.

--- TRANG 9 ---
Dữ liệu | Train | Dev | # of Spans | # of Supporting facts
HotpotQA(Yang et al., 2018)y | 90,564 | 7,405 | 14.45/11/17/2/96 | 2.38/2/3/2/12
MultiRC(Khashabi et al., 2018)y | 5,131 | 953 | 14.72/12/18/6/41 | 2.32/2/2/2/6
DocRED(Yao et al., 2019)y | 38,180 | 12,323 | 8.24/6/10/3/25 | 1.67/1/2/1/11
SQuAD(Rajpurkar et al., 2016)? | 87,599 | 10,570 | 156.26/114/186/25/853 | 7.74/3/11/0/82z

y Span và sự thật hỗ trợ cấp câu, và MultiRC là phiên bản thứ hai và có sẵn tại https://cogcomp.seas.upenn.edu/multirc/, nơi cột "train" và "dev" w.r.t. MultiRC báo cáo số lượng câu hỏi trong dữ liệu huấn luyện và dữ liệu dev, tương ứng.
? Span cấp token, và thống kê của # of spans/supporting facts được thu thập bằng cách đặt span = 1 token;
‡ Điều này được thu thập dựa trên 4 tài liệu hàng đầu được chọn từ 10 tài liệu ứng viên bởi bộ truy xuất tài liệu. Năm số tương ứng với Trung bình, Phần trăm thứ 25, Phần trăm thứ 75, Min và Max, tương ứng.
z Chúng tôi định nghĩa sự thật hỗ trợ như các span của ngữ cảnh có bigram xuất hiện trong câu hỏi.

Bảng 2: Thống kê của Các Tập Dữ liệu Chuẩn

Tên tham số | HotpotQA | MultiRC | DocRED | SQuAD
Kích thước batch | {4, 8} | {8, 16} | {4, 8} | {16, 32}
Tỷ lệ học | {3e-5, 2e-5, 1e-5, 1e-4} | {3e-5, 2e-5, 1e-5, 1e-4} | {1e-4, 5e-5} | {1e-4, 5e-5}
Tỷ lệ Span Drop | {0.1, 0.15, 0.2, 0.25} | {0.1, 0.15, 0.2, 0.25} | {0.05, 0.1, 0.15, 0.2} | {0.03, 0.05, 0.1, 0.15, 0.2, 0.25}
Optimizer | AdamW | AdamW | AdamW | AdamW
Epochs | 10 | 15 | {10,20,30} | {2,4,6,8}

Bảng 3: Không gian tìm kiếm siêu tham số cho các mô hình trên các chuẩn khác nhau

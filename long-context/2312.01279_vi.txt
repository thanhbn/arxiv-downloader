# 2312.01279.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2312.01279.pdf
# Kích thước tệp: 1429442 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
TEXTGENSHAP: GIẢI THÍCH HẬU PHÂN TÍCH CÓ THỂ MỞ RỘNG TRONG
SINH TẠO VẢN BẢN VỚI TÀI LIỆU DÀI
James Enouen1∗, Hootan Nakhost2, Sayna Ebrahimi2, Sercan O Arik2, Yan Liu1, Tomas Pfister2
1University of Southern California2Google Cloud AI
TÓM TẮT
Các mô hình ngôn ngữ lớn (LLMs) đã thu hút sự quan tâm to lớn trong các ứng dụng thực tế với những phản hồi ngày càng chính xác và khả năng lý luận mạch lạc. Với bản chất hộp đen sử dụng các quy trình lý luận phức tạp trên đầu vào, nhu cầu về những giải thích có thể mở rộng và trung thực cho nội dung được tạo ra bởi LLMs chắc chắn sẽ tiếp tục tăng. Đã có những phát triển lớn trong khả năng giải thích của các mô hình mạng neural trong thập kỷ qua. Trong số đó, các phương pháp giải thích hậu phân tích, đặc biệt là giá trị Shapley, đã chứng minh hiệu quả trong việc diễn giải các mô hình học sâu. Tuy nhiên, có những thách thức lớn trong việc mở rộng giá trị Shapley cho LLMs, đặc biệt khi xử lý các ngữ cảnh đầu vào dài chứa hàng nghìn token và các chuỗi đầu ra được tạo ra một cách tự hồi quy. Hơn nữa, thường không rõ làm thế nào để sử dụng hiệu quả các giải thích được tạo ra để cải thiện hiệu suất của LLMs. Trong bài báo này, chúng tôi giới thiệu TextGenSHAP, một phương pháp giải thích hậu phân tích hiệu quả kết hợp các kỹ thuật đặc thù cho LM. Chúng tôi chứng minh rằng điều này dẫn đến sự gia tăng đáng kể về tốc độ so với các tính toán giá trị Shapley thông thường, giảm thời gian xử lý từ hàng giờ xuống còn vài phút cho giải thích cấp token, và chỉ vài giây cho giải thích cấp tài liệu. Ngoài ra, chúng tôi chứng minh cách giá trị Shapley thời gian thực có thể được sử dụng trong hai tình huống quan trọng, cung cấp hiểu biết tốt hơn về trả lời câu hỏi tài liệu dài bằng cách định vị các từ và câu quan trọng; và cải thiện các hệ thống truy xuất tài liệu hiện có thông qua việc nâng cao độ chính xác của các đoạn văn được chọn và cuối cùng là các phản hồi cuối cùng.

1 GIỚI THIỆU
Các mô hình ngôn ngữ lớn (LLMs) tiếp tục nhanh chóng vượt trội trong các nhiệm vụ sinh tạo văn bản khác nhau cùng với sự tăng trưởng liên tục của các tài nguyên dành cho việc huấn luyện các mô hình dựa trên văn bản (Brown et al., 2020; Chowdhery et al., 2022; Touvron et al., 2023). Khả năng ấn tượng của LLM đã dẫn đến việc chúng được áp dụng rộng rãi trong các ứng dụng học thuật và thương mại. Khả năng lý luận mạch lạc trên một loạt các nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) đã thúc đẩy các nỗ lực cho phép các mô hình tự động tiếp nhận các ngữ cảnh ngày càng lớn. Các mô hình ngữ cảnh dài này cải thiện hiệu suất sinh tạo tăng cường truy xuất zero-shot, few-shot thông qua học trong ngữ cảnh (Izacard et al., 2022b; Huang et al., 2023; Ram et al., 2023) và giảm nhu cầu huấn luyện các mô hình đặc thù cho nhiệm vụ, trao quyền cho những người không chuyên môn sử dụng LLMs một cách dễ dàng.

Mặc dù có khả năng sinh tạo văn bản đáng chú ý, LLMs được huấn luyện chủ yếu để mô hình hóa các tương quan thống kê giữa các token cung cấp thông tin hạn chế về các cơ chế nội bộ của chúng. Đặc điểm này đã khiến LLMs được coi rộng rãi là các mô hình hộp đen cực kỳ khó giải thích. Ngoài hiệu suất dự đoán, các thách thức liên quan đến an toàn, bảo mật, tính trung thực và nhiều vấn đề khác đã trở nên nổi bật, đặc biệt trong bối cảnh áp dụng rộng rãi trong dân chúng. Khả năng giải thích được ∗enouen@usc.edu Công việc được thực hiện tại Google Cloud AI.
1arXiv:2312.01279v1  [cs.CL]  3 Dec 2023

--- TRANG 2 ---
BERT 
LLM Viết một câu trả lời chất lượng cao ... 
Tài liệu [1] (Tiêu đề: Danh sách các 
nhà Nobel vật lý) Giải Nobel 
Vật lý đầu tiên được trao 
vào năm 1901 cho Wilhelm Conrad Röntgen, 
của Đức, người đã nhận... 
Tài liệu [2] ... 
…
Câu hỏi: ai đã nhận giải nobel 
vật lý đầu tiên
Trả lời: Sự tiếp tục tráng lệ 
của bộ ba "Chúa tể những chiếc nhẫn" 
là quá to lớn đến nỗi một 
cột chữ không thể mô tả đầy đủ 
tầm nhìn mở rộng của đồng biên kịch/đạo diễn Peter 
Jackson về Middle-earth của J.R.R. 
Tolkien. phân loại 
cảm xúc 
"Wilhelm 
Conrad 
Röntgen" sinh tạo 
văn bản O(100M) 
tham số đến 
O(10B) 
tham số O(100) token 
đầu vào đến O(10K) 
token đầu vào vài lớp đến 
sinh tạo văn bản 
mở (a) đầu vào dài hơn (b) mô hình lớn hơn (c) đầu ra sinh tạo 
(d) thời gian giải thích 
Hình 1: Việc tạo ra khả năng giải thích hậu phân tích trở nên thách thức hơn đối với: (a) đầu vào dài hơn, (b) mô hình lớn hơn,
và (c) sinh tạo văn bản mở. Những điều này dẫn đến thời gian tăng đáng kể để trích xuất giải thích
(d) có thể quá dài đối với việc cải thiện mô hình có con người tham gia.

thường được ca ngợi là một con đường quan trọng để giải quyết những mối quan tâm này. Các phương pháp này cho phép hiểu biết sâu sắc về quy trình ra quyết định của mô hình, cho phép các bên liên quan trực tiếp xem xét lý luận đằng sau các phản hồi không an toàn hoặc không trung thực.

Các khảo sát gần đây về khả năng giải thích cho NLP đối chiếu hai tiêu chí chính cho giải thích mô hình: khả năng hiểu và tính trung thực (Lyu et al., 2023; Zhao et al., 2023; Mosca et al., 2022). Khả năng hiểu (tính dễ hiểu hoặc tính hợp lý) đề cập đến mức độ dễ hiểu của một giải thích đối với khán giả bên ngoài. Nó vốn dĩ phụ thuộc vào chuyên môn của người nhận và vẫn là một tiêu chí mang tính chủ quan cao. Mặt khác, tính trung thực đề cập đến mức độ mà một giải thích đơn giản hóa nắm bắt chính xác quy trình lý luận ban đầu của mô hình. Việc đánh giá hiệu quả tính dễ hiểu và tính trung thực của một phương pháp giải thích nhất định vẫn là một chủ đề gây tranh cãi và đang diễn ra trong tài liệu về khả năng diễn giải (Rudin, 2019). Cuộc tranh luận tiếp tục diễn ra về độ trung thực của các phương pháp giải thích như điểm chú ý, độ nổi bật gradient và lý luận tự giải thích (Jain & Wallace, 2019; Adebayo et al., 2018; Ghorbani et al., 2019; Wang et al., 2020; Wei et al., 2022). Một trong những phương pháp giải thích được tôn trọng nhất, giá trị Shapley (Lundberg & Lee, 2017) vẫn phổ biến vì có nền tảng lý thuyết mạnh hơn. Tuy nhiên, trong lĩnh vực NLP, các phương pháp như giá trị Shapley gặp khó khăn lớn trong khả năng mở rộng cho các mô hình lớn hơn và đầu vào dài hơn, buộc những người thực hành phải chờ đợi thời gian không hợp lý trước khi nhận được giải thích.

Để giải quyết những hạn chế này của các phương pháp giải thích hiện tại trong lĩnh vực NLP, chúng tôi giới thiệu TextGenSHAP, một phương pháp mới được thiết kế để điều chỉnh giá trị Shapley cho sinh tạo văn bản trong khi giữ tốc độ tính toán phù hợp hơn cho các ứng dụng quy mô LLM. Trọng tâm chính của chúng tôi nằm ở tình huống thách thức của giải thích khi sử dụng đầu vào dài làm prompt, đặc biệt cho các nhiệm vụ như trả lời câu hỏi trừu tượng từ các tài liệu rộng lớn. Theo đó, chúng tôi chứng minh khả năng mở rộng của phương pháp chúng tôi cho các ứng dụng mới qua ba khía cạnh chính được hiển thị trong Hình 1: (a) xử lý các ngữ cảnh dài hơn với hàng nghìn token đầu vào; (b) phù hợp với các mô hình lớn hơn với hàng tỷ tham số; và (c) tạo điều kiện cho sinh tạo văn bản mở, thay vì các nhiệm vụ phân biệt như phân loại. Hơn nữa, chúng tôi chứng minh cách các giải thích được tạo ra bởi TextGenSHAP của chúng tôi có thể nâng cao hiệu suất trả lời câu hỏi tài liệu dài theo nhiều cách.
2

--- TRANG 3 ---
2 CÔNG TRÌNH LIÊN QUAN
Khả năng giải thích mô hình hậu phân tích. Đã có nhiều nỗ lực cung cấp giải thích về cách các mô hình học máy sử dụng các đặc trưng đầu vào để đưa ra dự đoán. Trong số nhiều phương pháp giải thích hậu phân tích bao gồm LIME (Ribeiro et al., 2016), SHAP (Lundberg & Lee, 2017), và Integrated Gradients (Sundararajan et al., 2017), SHAP và Shapley vẫn chiếm ưu thế do có nền tảng lý thuyết mạnh. Đối với NLP, nhiều phần mở rộng của các phương pháp giải thích dựa trên nhiễu loạn này tận dụng cấu trúc phân cấp và thứ tự tuần tự của văn bản (Chen et al., 2019; Jin et al., 2020; Chen et al., 2020). Tuy nhiên, những phương pháp này bị giới hạn ở cây phân tích nhị phân thay vì các cấu trúc phân cấp tổng quát hơn và chưa được áp dụng cho độ dài đầu vào dài hơn hoặc các mô hình lớn hơn. Các phương pháp gần đây hơn mở rộng vượt ra ngoài các nhiệm vụ phân loại nhị phân bằng cách sử dụng các phần mở rộng đối chiếu của các kỹ thuật ban đầu (Jacovi et al., 2021; Yin & Neubig, 2022). Các công trình trong dữ liệu bảng và hình ảnh cũng đã có những bước tiến trong việc tăng tốc giá trị Shapley (Jethani et al., 2022), nhưng gặp khó khăn khi áp dụng cho NLP vì đầu ra văn bản sinh tạo. Cụ thể, tất cả các phương pháp hiện có đều yêu cầu chỉ định trước các đầu ra ứng viên và không thể áp dụng cho không gian đầu ra lớn của sinh tạo văn bản tự do.

Tự giải thích và lý luận. Cũng phổ biến cho các ứng dụng NLP là việc huấn luyện các mô hình sẽ đồng thời giải thích và dự đoán, tạo ra 'lý luận' để làm nổi bật các token quan trọng cho dự đoán, thường bằng cách căn chỉnh với lý luận được thu thập từ các người chú thích con người (Arous et al., 2021; Joshi et al., 2022) hoặc được tạo ra bằng cách sử dụng giải thích hậu phân tích (Stacey et al., 2022; Chan et al., 2022). Tuy nhiên, các phương pháp như vậy vẫn bị giới hạn ở các nhiệm vụ phân loại, có thể do khó khăn trong việc thu thập lý luận của con người và những hạn chế hiện tại của giải thích hậu phân tích cho sinh tạo văn bản, như đã thảo luận ở trên. Giải thích bằng ngôn ngữ tự nhiên, chẳng hạn như chuỗi suy nghĩ (Wei et al., 2022), trong đó LLMs phát ra giải thích về chính chúng do đó là một số ít giải thích có sẵn cho sinh tạo văn bản. Thật không may, các phương pháp như vậy vẫn hoàn toàn tách biệt khỏi mối quan tâm về tính trung thực hoặc độ chính xác của giải thích (Jacovi & Goldberg, 2021; Zheng et al., 2022).

Truy xuất thông tin từ tài liệu dài. Trả lời câu hỏi (QA) vẫn là một nhiệm vụ hiểu ngôn ngữ tự nhiên cơ bản, vượt ra ngoài nguồn gốc trong đọc hiểu và hợp nhất với các cơ sở tri thức ngày càng lớn. Hai loại chính của QA là QA tài liệu dài, trong đó đầu vào là một tài liệu liên tục chứa ít nhất hàng nghìn token, và QA miền mở, trong đó đầu vào là một kho ngữ liệu lớn thường đầy đủ hàng triệu tài liệu nhỏ hơn. Sự phân chia giữa hai loại này có thể được truy tìm ít nhất là từ bộ dữ liệu Natural Questions (NQ) (Kwiatkowski et al., 2019) để trả lời câu hỏi cho các trang Wikipedia. Công trình tiếp theo như Lee et al. (2019); Karpukhin et al. (2020) xây dựng các cải cách miền mở của nhiệm vụ NQ ban đầu bằng cách bao gồm toàn bộ kho ngữ liệu Wikipedia thay vì chỉ trang liên quan nhất. Các nhiệm vụ miền mở như vậy được chi phối bởi phương pháp đường ống trước tiên tận dụng một mô hình truy xuất để xếp hạng các đoạn văn liên quan nhất và sau đó sử dụng một mô hình đọc để hiểu thêm trên tập con nhỏ các đoạn văn được xếp hạng cao nhất. Nhiều phương pháp truy xuất dựa trên neural đã xuất hiện cho thiết lập này, lật đổ sự thống trị lâu dài của các phương pháp kiểu tf–idf (Izacard et al., 2022a; Karpukhin et al., 2020; Ma et al., 2021; Formal et al., 2021; Guu et al., 2020; Mao et al., 2021; Johnson et al., 2019). Đồng thời, các cải tiến đã được thực hiện ở phía mô hình đọc của phương pháp đường ống. Fusion-in-Decoder (FiD) (Izacard & Grave, 2021a;b) vẫn là một kiến trúc hiệu quả được thiết kế cho QA, và 'Lost in the Middle' (LitM) (Liu et al., 2023) gần đây đã xác định cách hiệu suất mô hình đọc phụ thuộc vào vị trí của đoạn văn chính xác trong các ngữ cảnh lớn.

Kiến trúc cho đầu vào dài. Theo đuổi các khả năng ấn tượng của huấn luyện quy mô lớn, đầu cuối đến cuối, cũng đã có một làn sóng trong các kiến trúc mạng có thể tăng kích thước ngữ cảnh của LMs. Cửa sổ ngữ cảnh tối đa đã nhanh chóng mở rộng từ hàng nghìn token đến hàng triệu token với việc sử dụng các phương pháp thưa thớt hiệu quả (Wu et al., 2022; Bulatov et al., 2022; Ding et al., 2023). Một số phương pháp sử dụng sự thưa thớt gần giống với truy xuất thông tin đối với các token liên quan hoặc bộ nhớ ngoài (Bertsch et al., 2023; Wu et al., 2022; Bulatov et al., 2022; 2023; Johnson et al., 2019) và một số phương pháp thay vào đó sử dụng ma trận chú ý thưa thớt khối để giảm các tính toán cần thiết của cơ chế chú ý (Beltagy et al., 2020; Zhang et al., 2022a; Ding et al., 2023; Dao et al., 2022).
3

--- TRANG 4 ---
3 CƠ SỞ LÝ THUYẾT
Ký hiệu. Xem xét một mô hình ngôn ngữ với từ vựng có kích thước V∈N sử dụng các chuỗi đầu vào x∈ X :=
[V]d và các chuỗi đầu ra y∈ Y := [V]m cho độ dài đầu vào d∈N và độ dài đầu ra tối đa m∈
N, trong đó [V] :={1, . . . , V }. Một mô hình sinh tạo văn bản nhận một chuỗi token đầu vào và định nghĩa một vector xác suất trên tất cả các đầu ra có thể, F:X → [0,1]Y. Do đó, chúng ta có F(x)y biểu thị xác suất của y được tạo ra cho x.

Để cho phép giải thích thông qua các phương pháp gán thuộc tính đặc trưng như giá trị Shapley, chúng ta cần có thể che giấu các tập con nhất định của các token đầu vào. Gọi s∈ M :={0,1}d là một mặt nạ nhị phân trên các token đầu vào. Chúng ta sẽ tiếp theo định nghĩa một mô hình sinh tạo văn bản có mặt nạ, f:X × M → [0,1]Y, nhận cả một chuỗi đầu vào và một mặt nạ đầu vào. Nói cách khác, chúng ta sẽ thay thế tất cả các token đầu vào không có trong mặt nạ s bằng token <pad> trước khi đưa vào mô hình. Nếu chúng ta giả định token <pad> hoặc <mask> được lấy là p∈[V] và xác định vector d được tạo thành từ tất cả p là p, thì chúng ta có thể viết điều này là f(x, S) :=F(x⊙s+p⊙(1−s)).

Để cuối cùng định nghĩa các 'hàm giá trị' cần thiết để định nghĩa điểm Shapley, trước tiên chúng ta phải xác định các mặt nạ nhị phân của mình với các tập con của các đặc trưng đầu vào. Cụ thể, với bất kỳ phần tử nào của tập lũy thừa S∈ P([d]) :=
{S⊆[d]}, có một mặt nạ nhị phân tương ứng duy nhất s∈ {0,1}d thông qua hàm chỉ thị s= 1S. Với bất kỳ token đầu vào i∈[d], chúng ta sẽ sử dụng ký hiệu tập hợp (S+i) :=S∪ {i} và (S−i) :=S\ {i} để bỏ che hoặc che token. Với một x cố định, chúng ta viết vℓ(S) := log( f(x,1S)) và vp(S) :=f(x,1S) là hai hàm giá trị ứng viên của chúng ta.

3.1 GIÁ TRỊ SHAPLEY
Giá trị Shapley, ban đầu được phát triển để gán thuộc tính giá trị của các người chơi cá nhân trong một trò chơi hợp tác, từ đó đã trở thành một mô hình chủ đạo để giải thích gán thuộc tính đặc trưng của các mô hình học máy hộp đen (Shapley, 1953; Lundberg & Lee, 2017). Trong Mục 3.2, chúng ta sẽ mở rộng điều này sang giá trị Shapley-Shubik và Penrose-Banzhaf được thiết kế cho các trò chơi bỏ phiếu (Shapley & Shubik, 1954; Banzhaf, 1965; Penrose, 1946). Trong Mục 3.3, chúng ta sẽ mô tả cách áp dụng phần mở rộng phân cấp được gọi là giá trị Owen (Owen, 1977; Winter, 2002) cho dữ liệu văn bản.

Giá trị Shapley thường được công thức hóa như một kỳ vọng đồng nhất trên các hoán vị:
φi=Eπ
vℓ(Sπ,i+i)−vℓ(Sπ,i−i)
(1)
trong đó π: [d]→[d] là một hoán vị và kỳ vọng được tính trên phân phối đồng nhất của các hoán vị. Nói cách khác, π biểu thị một thứ tự ngẫu nhiên của các đặc trưng (token) và Sπ,i:={j∈[d] :
π(j)< π(i)} là tập hợp các phần tử đi trước i trong thứ tự được định nghĩa bởi π. Do đó, Sπ,i+i={j∈[d] :
π(j)≤π(i)} và Sπ,i−i=Sπ,i={j∈[d] :π(j)< π(i)}, trong đó chúng ta không cần thiết trừ phần tử
i để chuẩn bị cho Phương trình 2. Chúng ta tuân theo phương pháp tiêu chuẩn của lấy mẫu hoán vị để ước tính giá trị Shapley như trung bình thực nghiệm trên một tập hữu hạn các hoán vị được lấy mẫu Covert et al. (2021).

Thách thức chính của việc áp dụng Shapley truyền thống là thực tế chúng ta không có quyền truy cập vào vector xác suất đầy đủ F(x), hiện đã có kích thước hàm mũ. Trong các nhiệm vụ phân loại và nhiệm vụ hồi quy, log-xác suất có thể được tính chính xác cho mọi đầu ra ứng viên. Tuy nhiên, trong sinh tạo văn bản mở, chúng ta sử dụng các thuật toán giải mã tuần tự như giải mã tham lam và sinh tạo K-beam để khôi phục chỉ một tập con thưa thớt của vector xác suất có kích thước hàm mũ F(x)∈[0,1][V]m. Trong phần tiếp theo, chúng ta cho thấy cách điều chỉnh Shapley để xử lý văn bản được tạo ra từ các phân phối có hỗ trợ không biết trước.
4

--- TRANG 5 ---
3.2 MỞ RỘNG CHO ĐẦU RA SINH TẠO
Mặc dù giá trị Shapley đã tìm thấy thành công rộng rãi trong các nhiệm vụ phân biệt như phân loại và hồi quy, nó gặp khó khăn khi được áp dụng cho các nhiệm vụ sinh tạo. Hướng tới mục đích này, chúng tôi tận dụng việc tái công thức hóa lý thuyết bỏ phiếu của giá trị Shapley thông thường, được gọi là chỉ số quyền lực Shapley-Shubik. Chúng tôi coi mỗi token đầu vào như một 'cử tri' bỏ phiếu cho một câu trả lời được tạo ra, nhằm 'bầu' câu trả lời ưa thích của họ dưới hệ thống bỏ phiếu hộp đen của LM.

Thông thường, Shapley sử dụng một hàm giá trị được biểu diễn như vector của log-xác suất, trong khi Shapley-Shubik hoạt động trên vector xác suất.

Sau đây, chúng tôi sẽ gọi 'chỉ số quyền lực Shapley-Shubik' là 'Shapley' để ngắn gọn. Chúng ta có thể tương đương tái công thức hóa Shapley như một kỳ vọng trên một tập con ngẫu nhiên thay vì trên một hoán vị ngẫu nhiên, làm nổi bật mối liên hệ của nó với giá trị Banzhaf:
φSh
i:=ES∼PSh(S)
[vp(S+i)−vp(S−i)]+
φBz
i:=ES∼PBz(S)
[vp(S+i)−vp(S−i)]+
(2)
trong đó PSh(S) là phân phối Shapley PSh(S)∝d−1
(d
|S|)|S|(d−|S|) và phân phối Banzhaf giống như phân phối Bernoulli PBz(S)∝p|S|(1−p)d−|S|. Chúng tôi đặt p= 50% và p= 10% trong các thí nghiệm của chúng tôi.
[·]+ được sử dụng để biểu thị phần dương theo thành phần mà chúng tôi sử dụng để lấy phần dương của sự khác biệt của hai vector xác suất. Các công thức này cung cấp lợi thế lớn là loại bỏ nhu cầu tính toán vector log-xác suất đầy đủ, cho phép chúng ta áp dụng giá trị Shapley cho sinh tạo văn bản.

3.3 MỞ RỘNG CHO ĐẦU VÀO PHÂN CẤP
Tận dụng tính chất phân cấp vốn có của văn bản tự nhiên, phương pháp của chúng tôi tính toán hiệu quả giá trị Shapley ở các mức độ chi tiết khác nhau. Ban đầu tính toán giá trị Shapley ở cấp độ tài liệu, quá trình sau đó tinh chỉnh để bao gồm các câu chỉ từ các tài liệu đóng góp đáng kể. Quá trình được chọn lọc, phân tầng này tiếp tục, dần dần thu hẹp trọng tâm vào các từ nằm trong các câu có điểm cao. Trong khi công trình trước đây như (Jin et al., 2020; Chen et al., 2020) khám phá các phần mở rộng phân cấp sử dụng giá trị Owen, họ chỉ giải quyết các cấu trúc phân cấp nhị phân, thiếu hỗ trợ cho các cấu trúc tổng quát hơn. Chúng tôi tận dụng cấu trúc phân cấp này để phân bổ tài nguyên tính toán một cách độc đáo cho các token then chốt trong các đoạn văn và câu đã được xác định là quan trọng, nhận ra rằng không phải mọi token đều đáng được điều tra.

4 TEXTGENSHAP: TĂNG TỐC SINH TẠO GIẢI THÍCH
Trong phần này, chúng tôi giải thích các kỹ thuật tăng tốc được đề xuất trong TextGenSHAP được thiết kế để thúc đẩy các tính toán Shapley trong các nhiệm vụ mô hình hóa văn bản sinh tạo với ngữ cảnh dài. Đầu tiên, chúng tôi sử dụng giải mã suy đoán để dự đoán các sinh tạo văn bản đến từ các đầu vào được lấy mẫu lại, đạt được sự tăng tốc đáng kể trên các loại mô hình khác nhau. Thứ hai, chúng tôi khai thác các kỹ thuật hiệu quả phần cứng gần đây như Flash Attention (Dao et al., 2022) và kết nối việc triển khai thưa thớt khối của nó với các kỹ thuật khác thường được sử dụng trong tài liệu tài liệu dài. Cuối cùng, chúng tôi sử dụng lấy mẫu lại tại chỗ của bộ mã hóa để cải thiện tốc độ của giải thích cấp độ đoạn văn. Chúng tôi cung cấp giải thích chi tiết cho những điều này trong các phần sau.

4.1 TĂNG TỐC ĐẶC THÙ CHO BỘ GIẢI MÃ: GIẢI MÃ SUY ĐOÁN
Chúng tôi sử dụng giải mã suy đoán (Miao et al., 2023; Leviathan et al., 2023) để giảm các lần gọi bộ giải mã trong quá trình lấy mẫu tự hồi quy trong TextGenSHAP, được mô tả trong Hình 2. Phương pháp này tính toán chính xác các xác suất đầu ra bằng cách trước tiên đoán những gì chuỗi được giải mã đầy đủ nên là. Trong quá trình thuật toán của chúng tôi, khi chúng tôi lấy mẫu lại các tập con khác nhau của token cho cùng một ví dụ đầu vào, chúng tôi dần dần xây dựng tập hợp các câu trả lời ứng viên. Với mỗi mẫu mới, trước tiên chúng tôi xác minh xem giải mã argmax có tồn tại trong việc suy đoán hay không
5

--- TRANG 6 ---
+0               
-1 +0             
-2 -1 +0           
-3 -2 -1 +0         
-1       +0       
-2       -1 +0     
-3       -2 -1 +0   
-2       -1     +0   (d) cây suy đoán, ma trận chú ý 
nhân quả, và ma trận bias vị trí  
Sklodowska  
Rontgen Conrad Marie Wilhelm <pad> 
Curie 
Curie Sklodowska  
Rontgen Conrad Marie Wilhelm <pad> 
Curie Rontgen Conrad Wilhelm <pad> (a) đầu vào 
được che ngẫu nhiên  
Tài liệu [1]...  
Tài liệu [2]...  
... 
Tài liệu [10]...  
 
Câu hỏi: ai...  
Trả lời:  
Tài liệu [1]...  
Tài liệu [2]...  
... 
Tài liệu [10]...  
 
Câu hỏi: ai...  
Trả lời:  
Tài liệu [1]...  
Tài liệu [2]...  
... 
Tài liệu [10]...  
 
Câu hỏi: ai...  
Trả lời:  
Tài liệu [1]...  
Tài liệu [2]...  
... 
Tài liệu [10]...  
 
Câu hỏi: ai...  
Trả lời:   (b) xác minh  
suy đoán  (c) cập nhật Shapley  
(và cây suy đoán)  
"Wilhelm 
Conrad  
Rontgen"  
"Marie 
Sklodowska  
Curie" 
"Marie 
Curie" 
     mẫu #1  
"Wilhelm 
Conrad  
Rontgen"  
0 1 2 3 4 5 6 7 
0 
1 
2 
3 4 
5 
6 7 0 
1 
2 
3 
4 
5 
6 
7 +0             
-1 +0           
-2 -1 +0         
-3 -2 -1 +0       
-1       +0     
-2       -1 +0   
-3       -2 -1 +0 0 1 2 3 4 5 6 
0 
1 
2 
3 
4 
5 
6 0 
1 
2 
3 4 
5 
6 +0       
-1 +0     
-2 -1 +0   
-3 -2 -1 +0 0 1 2 3 
0 
1 
2 
3 0 
1 
2 
3 <pad> 
+0 0 
0 0 T0 "Wilhelm" 
không có trong cây  
suy đoán 
T0 T1 
T2 
T3 "Marie"  
không có trong cây  
"Marie Curie"  
không có trong cây  
tự hồi quy  suy đoán 
T1 
suy đoán 
T2 
suy đoán 
T2 tự hồi quy  
"Wilhelm Conrad 
Rontgen"  
có trong cây  tự hồi quy  
Φ mẫu #2  
mẫu #3  
mẫu #4  T1 Φ 
T2 Φ 
T3 Φ Hình 2: Trực quan hóa cách sử dụng phương pháp giải mã suy đoán được đề xuất trong TextGenSHAP để cải thiện tốc độ thuật toán lấy mẫu lại. (a) Các đầu vào được che ngẫu nhiên được tạo ra để tính toán giá trị Shapley. (b) Chạy bộ giải mã một lần duy nhất với cây suy đoán và sau đó xác minh xem đầu ra thực có nằm trong đầu ra được suy đoán hay không. (c) Nếu suy đoán bị từ chối, chúng ta phải chạy bộ giải mã một cách tự hồi quy để tạo ra đầu ra chính xác. Mỗi thanh màu tím đại diện cho một lần chúng ta gọi bộ giải mã. Sau đó chúng ta cập nhật giá trị Shapley và thêm đầu ra mới vào cây suy đoán. Nếu suy đoán được chấp nhận, chúng ta cập nhật giá trị Shapley với đầu ra được suy đoán chính xác. (d) Khi chúng ta chạy thuật toán, chúng ta theo dõi cây suy đoán và ma trận bias vị trí của nó. Ma trận chú ý nhân quả có thể được tính trực tiếp từ ma trận bias vị trí bằng cách che tất cả các mục màu xanh và chỉ giữ các mục màu vàng. Ma trận chú ý nhân quả nhanh chóng có dạng phức tạp hơn so với ma trận tam giác thông thường để tính toán chính xác các khả năng đầu ra.

các đầu ra giải mã mà chúng tôi đã tính toán (nếu vậy chúng tôi đã hoàn thành với mẫu này). Nếu không, thì chúng tôi cần tạo ra câu trả lời ứng viên mới bằng phương pháp giải mã tự hồi quy thông thường. Sau đó, chúng tôi ghép câu trả lời mới vào cây giải mã nhân quả hiện có, đảm bảo cập nhật ma trận chú ý nhân quả để tôn trọng cấu trúc đồ thị của cây giải mã. Không giống như các ứng dụng hiện có (Leviathan et al., 2023), có mức độ không chắc chắn cao trong dự đoán bộ giải mã của họ, TextGenSHAP áp dụng giải mã suy đoán cho các đầu vào bị nhiễu loạn gần giống với các mẫu đã được giải mã cho phép chúng tôi có tỷ lệ thành công dự đoán cao hơn nhiều. Trong các thí nghiệm của chúng tôi, chúng tôi xác minh rằng một lượng lớn tổng tính toán có thể được tiết kiệm thông qua việc giải mã suy đoán trong một bước thay vì chạy tuần tự mô hình bộ giải mã.

Ngoài ra, cây giải mã suy đoán của TextGenSHAP có thể được mở rộng thêm để theo dõi các giá trị liên quan được quan tâm. Ví dụ, nó có thể theo dõi log-xác suất được giải mã tại mỗi nút, cho phép tính toán giá trị Shapley đối chiếu theo log-xác suất, mà không cần chỉ định trước. Trong tất cả các thí nghiệm của chúng tôi, chúng tôi sử dụng giải mã tham lam phù hợp với các nghiên cứu trả lời câu hỏi tài liệu dài khác (Izacard & Grave, 2021a; Liu et al., 2023). Tuy nhiên, chúng tôi nhấn mạnh rằng cây giải mã suy đoán của chúng tôi
6

--- TRANG 7 ---
có thể hỗ trợ thêm các phương pháp lấy mẫu phổ biến khác như tìm kiếm beam và sinh tạo nucleus (Sina et al., 2021; Holtzman et al., 2020) và có thể theo dõi log-xác suất trên tất cả các lá của cây.

4.2 THƯA THỚT KHỐI VÀ FLASH ATTENTION
Chúng tôi tận dụng cơ chế Flash Attention ngày càng phổ biến (Dao et al., 2022) để cải thiện cả hiệu quả bộ nhớ và hiệu suất tốc độ của LMs. Hiệu quả bộ nhớ được cải thiện bằng cách sử dụng một công thức tính toán ma trận chú ý thay thế, có bộ nhớ tỷ lệ tuyến tính với kích thước đầu vào O(N) thay vì bậc hai O(N2). Sự tăng tốc thêm được đạt được thông qua việc căn chỉnh các tính toán này để mở rộng hiệu quả với phần cứng GPU hiện đại. Những thích ứng này rất quan trọng trong bối cảnh trả lời câu hỏi tài liệu dài, nơi chúng tôi xử lý tới 20K token đầu vào với một GPU duy nhất. Kích thước đầu vào như vậy đòi hỏi việc mở rộng bộ nhớ tuyến tính được cung cấp bởi các phương pháp kiểu Flash Attention (Rabe & Staats, 2022; Dao, 2023).

Ngoài ra, chúng tôi tạo kết nối giữa Flash Attention và các phát triển gần đây trong kiến trúc tài liệu dài (Izacard & Grave, 2021a; Ding et al., 2023) bằng cách sử dụng ma trận chú ý thưa thớt khối để xử lý đầu vào dài. Với nhu cầu ngày càng tăng cho các sửa đổi như vậy, chúng tôi cũng tái công thức hóa phiên bản gốc của FiD thành phiên bản kết hợp việc triển khai thưa thớt khối của Flash Attention. Theo các tiến bộ gần đây như vậy vào các kiến trúc hiện đại cho kích thước ngữ cảnh khổng lồ, chúng tôi tin rằng kỹ thuật giải thích mở rộng thưa thớt khối của chúng tôi định vị tốt để tiếp tục hữu ích trong kỷ nguyên của LLMs.

4.3 TĂNG TỐC ĐẶC THÙ CHO BỘ MÃ HÓA: LẤY MẪU LẠI TẠI CHỖ
Trong TextGenSHAP, chúng tôi khai thác thêm cấu trúc độc đáo của các mô hình mã hóa-giải mã dựa trên phân đoạn như FiD để có được sự tăng tốc nhanh hơn đáng kể so với trước đây có thể trong NLP. Cụ thể, chúng tôi tính toán ma trận đặc trưng bộ mã hóa chỉ một lần khi tạo ra toàn bộ giải thích cho một ví dụ duy nhất. Do tính độc lập của các đoạn đầu vào được phân đoạn, chúng tôi chỉ cần điều chỉnh cơ chế chú ý bộ mã hóa-giải mã để cho phép lấy mẫu lại với các tập con tài liệu khác nhau. Chúng tôi không chỉ giảm đáng kể thời gian tính toán cần thiết để mã hóa lại các đặc trưng đầu vào, mà còn giảm chi phí bộ nhớ từ các batch mã hóa cho phép giải mã song song với kích thước batch giải mã lớn. Tăng kích thước batch giải mã cho phép giải mã hiệu quả phần cứng hơn nhiều, cho phép mô hình lặp qua hàng trăm mẫu hoán vị chỉ trong vài giây.

Trong các thí nghiệm của chúng tôi, chúng tôi kết hợp thêm phương pháp này với việc tái công thức hóa ma trận chú ý đường chéo khối cho phân đoạn được thảo luận trong Mục 4.2. Bằng cách thay đổi mã hóa đoạn văn để sử dụng hiệu quả việc căn chỉnh phần cứng trong Flash Attention, chúng tôi có thể giữ cho chú ý tự bộ mã hóa và chú ý chéo bộ mã hóa-giải mã được căn chỉnh như các ma trận thưa thớt khối. Các ma trận thưa thớt có nhận thức phần cứng như vậy cho phép chúng tôi giảm thiểu các tính toán thừa bằng cách tránh các mục khác không không cần thiết vượt qua ranh giới phần cứng và làm chậm tính toán.

TextGenSHAP Trong Thuật toán 1, chúng tôi chi tiết TextGenSHAP, trước tiên tính toán giá trị Shapley ở cấp độ tài liệu; thứ hai xếp hạng tài liệu và chọn những tài liệu vượt qua ngưỡng quan trọng được xác định trước; và thứ ba tính toán giá trị Shapley ở cấp độ token chỉ cho các token bên trong các tài liệu quan trọng. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng cấu trúc phân cấp ba tầng với đoạn văn, câu và từ; tuy nhiên, để đơn giản về ký hiệu, chúng tôi chỉ mô tả cấu trúc phân cấp hai cấp trong mô tả thuật toán của chúng tôi.

5 KẾT QUẢ THỰC NGHIỆM
Bộ dữ liệu Chúng tôi tập trung vào các bộ dữ liệu có sẵn công khai được thiết kế cho nhiệm vụ trả lời câu hỏi miền mở hoặc tài liệu dài: Natural Questions (NQ) (Kwiatkowski et al., 2019) và MIRACL (tập con tiếng Anh) (Zhang et al., 2022b). NQ được thiết kế lại cho trả lời câu hỏi miền mở theo (Lee et al., 2019; Karpukhin et al., 2020). Trong thiết lập này, câu trả lời phải được tìm thấy từ trong toàn bộ Wikipedia, thay vì
7

--- TRANG 8 ---
một trang Wikipedia duy nhất. Bộ dữ liệu NQ ban đầu cung cấp câu trả lời văn bản ngắn và các đoạn văn được đánh giá là liên quan miễn là chúng chứa câu trả lời sự thật cơ bản. MIRACL được thiết kế cho truy xuất thông tin và với mỗi truy vấn, nó cung cấp nhãn liên quan nhị phân cho mười đoạn văn liên quan từ kho ngữ liệu. Đánh giá liên quan được thực hiện bởi người chú thích con người quyết định xem thông tin đoạn văn có đủ để trả lời câu hỏi đã cho hay không; tuy nhiên, họ không được yêu cầu biện minh hoặc mô tả câu trả lời như một phần của nhãn.

Mô hình Đối với xếp hạng đoạn văn của kho ngữ liệu (mô hình truy xuất) chúng tôi sử dụng kiến trúc Contriever gần đây (Izacard et al., 2022a) theo LitM. Đối với trả lời câu hỏi (mô hình đọc) chúng tôi sử dụng các thành viên khác nhau của họ T5 (Raffel et al., 2020). Chúng tôi sử dụng các mô hình được điều chỉnh flan có sẵn ở kích thước large và XXL ('T5-large' và 'T5-XXL') (Chung et al., 2022) và mô hình T5 large được tinh chỉnh từ FiD ('T5-FiD') (Izacard & Grave, 2021a).

45 90 180 360 720 1440
Thời gian thực hiện (phút)20.3 giờ
4.76 giờ 10/10
2.09 giờ 30/10
1.96 giờ 30/30
4.19 giờ 10/10
1.57 giờ 30/10
1.10 giờ 30/30(a) T5-XXL
Shapley
Phân cấp
Giải mã suy đoán
5 10 30 60 180 360 900
Thời gian thực hiện (phút)12.3 giờ
2.27 giờ 10/10
56.0 phút 30/10
48.9 phút 30/30
34.5 phút 10/10
16.1 phút 30/10
10.0 phút 30/30(b) T5-large
Shapley
Phân cấp
Giải mã suy đoán
5 10 30 60 120 600
Thời gian thực hiện (giây)5.25 phút
1.41 phút
2.75 phút  1
23.6 giây   10 
8.51 giây  100 (c) T5-FiD
Phân cấp
Giải mã suy đoán
Mã hóa tại chỗ
Hình 3: (a, b) Kết quả đánh giá tốc độ TextGenSHAP ở cấp token trên T5-XXL và T5-large. (c)
Kết quả đánh giá tốc độ TextGenSHAP ở cấp tài liệu trên T5-FiD. Màu đỏ là giá trị Shapley ban đầu
với lấy mẫu hoán vị. Màu xanh là giá trị Shapley phân cấp với lấy mẫu hoán vị phân cấp
với ngưỡng trong {10%,30%}. Màu vàng là giá trị Shapley phân cấp với giải mã suy đoán. Màu xanh lá
là giá trị Shapley phân cấp với mã hóa tại chỗ với các kích thước khác nhau {1,10,100} cho kích thước batch giải mã (DBS).

5.1 KẾT QUẢ ĐÁNH GIÁ TỐC ĐỘ TEXTGENSHAP
Chúng tôi trình bày các đánh giá cho thấy tốc độ cải thiện của TextGenSHAP. Đầu tiên, chúng tôi đánh giá giá trị Shapley, cung cấp giải thích chi tiết cấp token sử dụng Thuật toán 1 của chúng tôi. Trong Hình 3, chúng tôi đánh giá với 100 hoán vị được lấy mẫu và 10 tài liệu từ thiết lập LitM cho cả T5-XXL và T5-large. Một GPU A100 40GB duy nhất được sử dụng để đánh giá tất cả các thí nghiệm. Chúng tôi quan sát thấy rằng ước tính giá trị Shapley tiêu chuẩn yêu cầu 12-20 giờ cấm đoán cho mỗi mẫu và cho thấy rằng thuật toán lấy mẫu phân cấp được đề xuất của chúng tôi giảm đáng kể thời gian này. Với việc tích hợp giải mã suy đoán, chúng tôi có thể đạt được sự giảm thời gian tính toán thậm chí còn đáng kể hơn, đưa thời gian tính toán xuống dưới một giờ và khoảng một giờ, tương ứng. Chúng tôi lưu ý rằng sự tăng tốc bổ sung có thể đạt được trong các thiết lập thế giới thực bằng cách chỉ lấy mẫu ít hoán vị hơn. Trong Phụ lục E, chúng tôi cho thấy rằng thậm chí ít hơn 100 mẫu hoán vị có thể đủ. Khi chỉ sử dụng 10 mẫu hoán vị, TextGenSHAP giảm thời gian cho mô hình T5-XXL từ khoảng hai giờ xuống năm phút.
8

--- TRANG 9 ---
Chúng tôi cũng đánh giá mô hình T5-FiD được tăng tốc với các sửa đổi đặc thù kiến trúc của nó như thấy trong Hình 3c. Chúng tôi đưa giải thích cấp tài liệu từ nhiều phút xuống dưới mười giây, cho phép cải thiện thời gian thực trong các ứng dụng truy xuất tài liệu mà chúng tôi chứng minh trong Mục 5.3

5.2 TRỰC QUAN HÓA GIẢI THÍCH
Trong Phụ lục, chúng tôi trình bày các trực quan hóa của giải thích dự đoán. Chúng tôi thấy rằng điểm Shapley phân cấp của chúng tôi hiệu quả trong việc cô lập các token quan trọng từ trong các ngữ cảnh có độ dài hàng nghìn token. Chúng tôi cũng cung cấp các trực quan hóa tương tác được lưu trữ tại đây.

5.3 CHƯNG CẤT TÀI LIỆU
Chúng tôi cho thấy giá trị của các điểm giải thích được đề xuất trong TextGenSHAP trong bối cảnh truy xuất tài liệu cho QA miền mở. Trước tiên chúng tôi áp dụng phương pháp của mình để cải thiện khía cạnh truy xuất, đặc biệt nâng cao khả năng nhớ lại của mô hình truy xuất đã sửa đổi, bằng cách xếp hạng lại các đoạn văn theo điểm giải thích của chúng.

0 10 20 30 40 50
Số tài liệu được truy xuất30% 40% 50% 60% 70% 80% 90% 100%Nhớ lại(a) Natural Questions
Điểm tương tự
TextGenSHAP
TextGenBANZ
TextGenBANZ-10
0 10 20 30 40 50
Số tài liệu được truy xuất30% 40% 50% 60% 70% 80% 90% 100%Nhớ lại(b) MIRACL-gốc
Điểm tương tự
TextGenSHAP
TextGenBANZ
TextGenBANZ-10
0 10 20 30 40 50
Số tài liệu được truy xuất30% 40% 50% 60% 70% 80% 90% 100%Nhớ lại(c) MIRACL-giả
Điểm tương tự
TextGenSHAP
TextGenBANZ
TextGenBANZ-10
Hình 4: Cải thiện nhớ lại thông qua việc sắp xếp lại các tài liệu được truy xuất bằng các phương pháp khác nhau (a) Natural
Questions (b) MIRACL với nhãn gốc (c) MIRACL với nhãn giả

Hình 4a cho thấy cải thiện nhớ lại đáng kể trên bộ dữ liệu NQ, với cả ba phương pháp giải thích đều thể hiện cải thiện hiệu suất tương tự so với mô hình truy xuất cơ sở. Bảng 1 cung cấp đánh giá số về diện tích dưới đường cong cho các mô hình này. Tuy nhiên, Hình 4b cho thấy cải thiện ít rõ ràng hơn trên bộ dữ liệu MIRACL thách thức hơn, chủ yếu do thông tin nhãn thưa thớt của nó chỉ cung cấp nhãn liên quan cho mười trong số hàng triệu đoạn văn. Chúng tôi xác minh tuyên bố này bằng cách mở rộng thông tin nhãn sử dụng nhãn giả. Cụ thể, chúng tôi lấy tất cả các đoạn văn liên quan theo nhãn MIRACL và yêu cầu T5-XXL đưa ra câu trả lời ngắn theo chỉ đoạn văn đó. Sau đó chúng tôi tận dụng tập hợp các câu trả lời ứng viên này để đánh giá liên quan đoạn văn theo cách giống như bộ dữ liệu NQ. Trong Hình 4c, chúng ta thấy điều này không chỉ cải thiện khả năng nhớ lại tổng thể, mà còn tăng cường không cân xứng hiệu suất thành công của phương pháp giải thích của chúng tôi.

Chúng tôi coi điều này là bằng chứng sơ bộ về tiềm năng của phương pháp chúng tôi để khám phá các đoạn văn liên quan thường bị bỏ qua khi chỉ sử dụng các mô hình truy xuất dựa trên tương tự. Theo đó, chúng tôi đề xuất rằng phương pháp của chúng tôi có thể được áp dụng thêm để nâng cao các quy trình xây dựng bộ dữ liệu không chỉ bằng cách giảm gánh nặng chú thích của con người thông qua việc định vị các đặc trưng tài liệu quan trọng, mà còn bằng cách thu thập một tập hợp tài liệu đa dạng hơn để được chú thích bởi con người so với có thể với các phương pháp hiện có. Chúng tôi khám phá các ứng dụng như vậy trên bộ dữ liệu MIRACL trong Phụ lục E.

Trong ứng dụng thứ hai của chúng tôi, chúng tôi đề xuất sử dụng giá trị Shapley từ mô hình đọc để chưng cất tập hợp tài liệu có sẵn của chính nó. Kết hợp với các phát hiện trong LitM (Liu et al., 2023), làm nổi bật những thách thức cho các mô hình đọc trong việc sử dụng các ngữ cảnh dài hơn, chúng tôi chưng cất lại các tài liệu của mô hình trước khi đưa ra cuối cùng
9

--- TRANG 10 ---
Bảng 1: AUC cho các đường cong nhớ lại từ Hình 4 trên cả
bộ dữ liệu NQ và bộ dữ liệu MIRACL.
Natural MIRACL MIRACL
Questions (Gốc) (Giả)
Cơ sở 84.23 80.18 84.53
TextGenSHAP 88.53 77.33 86.43
TextGenBANZ 88.56 78.19 86.17
TextGenBANZ-10 88.74 82.38 86.53
Attention188.35 78.27 84.30Bảng 2: AUC cho các đường cong độ chính xác từ
Hình 5 trên bộ dữ liệu NQ.
K=1K=3K=5
Cơ sở 50.54 – –
Bỏ phiếu đa số 32.90 55.19 63.88
TextGenSHAP 52.72 66.16 69.57

câu trả lời. Chúng tôi đánh giá độ chính xác top-K cho các giá trị nhỏ của K, cho phép mô hình đọc sử dụng một loạt thông tin liên quan đa dạng, và thu hẹp khoảng cách giữa khả năng nhớ lại của truy xuất và độ chính xác của người đọc. Đánh giá này làm nổi bật tầm quan trọng của việc cung cấp một tập hợp đa dạng các câu trả lời ứng viên. Hình 5 minh họa các cải thiện độ chính xác đạt được bởi mô hình được chưng cất lại so với đường cơ sở bỏ phiếu đa số.
Chúng ta thấy rằng TextGenSHAP vượt trội đáng kể so với đường cơ sở chỉ với một lần qua mô hình đọc, và tiếp tục vượt qua đường cơ sở bỏ phiếu đa số cho nhiều câu trả lời. Chúng tôi một lần nữa cung cấp so sánh số sử dụng AUC trong Bảng 2.

0 10 20 30 40 50
Số tài liệu được truy xuất30% 40% 50% 60% 70% 80% 90% 100%Độ chính xác Top-1
Contriever
T5-XXL
T5-XXL@1 (TextGenSHAP)
0 10 20 30 40 50
Số tài liệu được truy xuất30% 40% 50% 60% 70% 80% 90% 100%Độ chính xác Top-3
Contriever
T5-XXL
T5-XXL@3 (TextGenSHAP)
T5-XXL@3 (Đa số)
0 10 20 30 40 50
Số tài liệu được truy xuất30% 40% 50% 60% 70% 80% 90% 100%Độ chính xác Top-5
Contriever
T5-XXL
T5-XXL@5 (TextGenSHAP)
T5-XXL@5 (Đa số)
Hình 5: Độ chính xác Top-K cho K=1,3,5 trên bộ dữ liệu Natural Questions cho TextGenSHAP, mô hình
gốc, đường cơ sở bỏ phiếu đa số, và phương pháp sắp xếp lại dựa trên giải thích.

6 KẾT LUẬN
Trong bài báo này, chúng tôi giới thiệu TextGenSHAP để nâng cao giá trị Shapley, một phương pháp giải thích đáng tin cậy, để giải quyết các thách thức trong các ứng dụng NLP hiện đại có đầu vào dài, mô hình lớn và sinh tạo văn bản. Chúng tôi giới thiệu các sửa đổi để điều chỉnh giá trị Shapley cho văn bản đầu vào có cấu trúc phân cấp và sinh tạo đầu ra được giải mã tự hồi quy, dựa trên những hiểu biết từ tài liệu lý thuyết trò chơi để hỗ trợ nền tảng lý thuyết của chúng. Ngoài ra, chúng tôi kết hợp nhiều sửa đổi kiến trúc đặc thù transformer giúp tăng tốc đáng kể việc tạo ra giải thích. Phương pháp của chúng tôi không chỉ tăng tốc tính toán giá trị Shapley cho văn bản được tạo ra mà còn chứng minh hiệu quả của nó trong việc cải thiện hiệu suất trong một nhiệm vụ trả lời câu hỏi tiêu chuẩn. Chúng tôi kỳ vọng rằng các phương pháp giải thích như vậy sẽ tiếp tục tìm thấy khả năng áp dụng rộng rãi trong nhiều trường hợp sử dụng LLM.

1Attention tuân theo các siêu tham số tốt nhất cho tổng hợp được tìm thấy trong Izacard & Grave (2021b)
10

--- TRANG 11 ---
TÀI LIỆU THAM KHẢO
Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, and Been Kim. Sanity
checks for saliency maps. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi,
and R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 31. Curran Asso-
ciates, Inc., 2018. URL https://proceedings.neurips.cc/paper_files/paper/2018/
file/294a8ed24b1ad22ec2e7efea049b8737-Paper.pdf .

Ines Arous, Ljiljana Dolamic, Jie Yang, Akansha Bhardwaj, Giuseppe Cuccu, and Philippe Cudr ´e-Mauroux.
Marta: Leveraging human rationales for explainable text classification. Proceedings of the AAAI Con-
ference on Artificial Intelligence , 35(7):5868–5876, May 2021. doi: 10.1609/aaai.v35i7.16734. URL
https://ojs.aaai.org/index.php/AAAI/article/view/16734 .

John F. III Banzhaf. Weighted Voting Doesn't Work: A Mathematical Analysis , volume 19, pp. 317–344.
1965.

Iz Beltagy, Matthew E. Peters, and Arman Cohan. Longformer: The long-document transformer, 2020.

Amanda Bertsch, Uri Alon, Graham Neubig, and Matthew R. Gormley. Unlimiformer: Long-range trans-
formers with unlimited length input. 2023.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.
Advances in neural information processing systems , 33:1877–1901, 2020.

Aydar Bulatov, Yury Kuratov, and Mikhail Burtsev. Recurrent memory transformer. In
S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (eds.), Advances in
Neural Information Processing Systems , volume 35, pp. 11079–11091. Curran Associates, Inc.,
2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/
47e288629a6996a17ce50b90a056a0e1-Paper-Conference.pdf .

Aydar Bulatov, Yuri Kuratov, and Mikhail S. Burtsev. Scaling transformer to 1m tokens and beyond with
rmt. 2023.

Aaron Chan, Maziar Sanjabi, Lambert Mathias, Liang Tan, Shaoliang Nie, Xiaochang Peng, Xiang Ren,
and Hamed Firooz. UNIREX: A unified learning framework for language model rationale extraction. In
Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.),
Proceedings of the 39th International Conference on Machine Learning , volume 162 of Proceedings of
Machine Learning Research , pp. 2867–2889. PMLR, 17–23 Jul 2022.

Hanjie Chen, Guangtao Zheng, and Yangfeng Ji. Generating hierarchical explanations on text classification
via feature interaction detection. In Proceedings of the 58th Annual Meeting of the Association for Com-
putational Linguistics , pp. 5578–5593, Online, July 2020. Association for Computational Linguistics. doi:
10.18653/v1/2020.acl-main.494. URL https://aclanthology.org/2020.acl-main.494 .

Jianbo Chen, Le Song, Martin J. Wainwright, and Michael I. Jordan. L-shapley and c-shapley: Efficient
model interpretation for structured data. In International Conference on Learning Representations , 2019.
URL https://openreview.net/forum?id=S1E3Ko09F7 .

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language
modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.
11

--- TRANG 12 ---
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac
Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha
Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun
Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V . Le, and Jason
Wei. Scaling instruction-finetuned language models, 2022.

Ian Covert, Scott Lundberg, and Su-In Lee. Explaining by removing: A unified framework for model
explanation. Journal of Machine Learning Research , 22(209):1–90, 2021. URL http://jmlr.org/
papers/v22/20-1316.html .

Tri Dao. Flashattention-2: Faster attention with better parallelism and work partitioning. 2023.

Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher R ´e. Flashattention: Fast and memory-efficient
exact attention with io-awareness. In Advances in Neural Information Processing Systems , volume 35,
pp. 16344–16359, 2022.

Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, Wenhui Wang, Nanning Zheng, and
Furu Wei. Longnet: Scaling transformers to 1,000,000,000 tokens. 2023.

Thibault Formal, Carlos Lassance, Benjamin Piwowarski, and St ´ephane Clinchant. Splade v2: Sparse lexical
and expansion model for information retrieval. 2021.

Amirata Ghorbani, Abubakar Abid, and url=https://ojs.aaai.org/index.php/AAAI/article/view/4252
DOI=10.1609/aaai.v33i01.33013681 number=01 journal=Proceedings of the AAAI Conference on Ar-
tificial Intelligence James Zou, volume=33. Interpretation of neural networks is fragile. pp. 3681–3688,
Jul. 2019.

Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. Realm: Retrieval-augmented
language model pre-training. In Proceedings of the 37th International Conference on Machine Learning ,
ICML'20. JMLR.org, 2020.

Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious case of neural text degenera-
tion. In International Conference on Learning Representations , 2020. URL https://openreview.
net/forum?id=rygGQyrFvH .

Jie Huang, Wei Ping, Peng Xu, Mohammad Shoeybi, Kevin Chen-Chuan Chang, and Bryan Catanzaro.
Raven: In-context learning with retrieval augmented encoder-decoder language models. arXiv preprint
arXiv:2308.07922 , 2023.

Gautier Izacard and Edouard Grave. Leveraging passage retrieval with generative models for open domain
question answering. In Proceedings of the 16th Conference of the European Chapter of the Association
for Computational Linguistics: Main Volume , pp. 874–880. Association for Computational Linguistics,
2021a. URL https://aclanthology.org/2021.eacl-main.74 .

Gautier Izacard and Edouard Grave. Distilling knowledge from reader to retriever for question answering. In
International Conference on Learning Representations , 2021b. URL https://openreview.net/
forum?id=NTEz-6wysdb .

Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and
Edouard Grave. Unsupervised dense information retrieval with contrastive learning. Transactions on
Machine Learning Research , 2022a. ISSN 2835-8856. URL https://openreview.net/forum?
id=jKN1pXi7b0 .
12

--- TRANG 13 ---
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-
Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. Few-shot learning with retrieval augmented
language models. arXiv preprint arXiv:2208.03299 , 2022b.

Alon Jacovi and Yoav Goldberg. Aligning faithful interpretations with their social attribution. Transactions
of the Association for Computational Linguistics , 9:294–310, 2021. doi: 10.1162/tacl a00367. URL
https://aclanthology.org/2021.tacl-1.18 .

Alon Jacovi, Swabha Swayamdipta, Shauli Ravfogel, Yanai Elazar, Yejin Choi, and Yoav Goldberg. Con-
trastive explanations for model interpretability. In Proceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing , pp. 1597–1611, Online and Punta Cana, Dominican Republic,
November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.120.
URLhttps://aclanthology.org/2021.emnlp-main.120 .

Sarthak Jain and Byron C. Wallace. Attention is not Explanation. In Proceedings of the 2019 Confer-
ence of the North American Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies, Volume 1 (Long and Short Papers) , pp. 3543–3556, Minneapolis, Minnesota,
June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1357. URL https:
//aclanthology.org/N19-1357 .

Neil Jethani, Mukund Sudarshan, Ian Connick Covert, Su-In Lee, and Rajesh Ranganath. FastSHAP: Real-
time shapley value estimation. In International Conference on Learning Representations , 2022. URL
https://openreview.net/forum?id=Zq2G_VTV53T .

Xisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, and Xiang Ren. Towards hierarchical importance attri-
bution: Explaining compositional semantics for neural sequence models. In International Conference on
Learning Representations , 2020. URL https://openreview.net/forum?id=BkxRRkSKwr .

Jeff Johnson, Matthijs Douze, and Herv ´e J´egou. Billion-scale similarity search with gpus. IEEE Transactions
on Big Data , 7(3):535–547, 2019. doi: 10.1109/TBDATA.2019.2921572.

Brihi Joshi, Aaron Chan, Ziyi Liu, Shaoliang Nie, Maziar Sanjabi, Hamed Firooz, and Xiang Ren. ER-
test: Evaluating explanation regularization methods for language models. In Yoav Goldberg, Zornitsa
Kozareva, and Yue Zhang (eds.), Findings of the Association for Computational Linguistics: EMNLP
2022 , pp. 3315–3336, Abu Dhabi, United Arab Emirates, December 2022. Association for Compu-
tational Linguistics. doi: 10.18653/v1/2022.findings-emnlp.242. URL https://aclanthology.
org/2022.findings-emnlp.242 .

Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and
Wen-tau Yih. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing (EMNLP) , pp. 6769–6781, Online,
November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.550.
URL https://aclanthology.org/2020.emnlp-main.550 .

Meinard Kuhlmann. Quantum Field Theory. In Edward N. Zalta and Uri Nodelman (eds.), The Stanford En-
cyclopedia of Philosophy . Metaphysics Research Lab, Stanford University, Summer 2023 edition, 2023.

Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,
Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew
Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural ques-
tions: A benchmark for question answering research. Transactions of the Association for Computational
Linguistics , 7:452–466, 2019. doi: 10.1162/tacl a00276. URL https://aclanthology.org/
Q19-1026 .
13

--- TRANG 14 ---
Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised open domain
question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational
Linguistics , pp. 6086–6096, Florence, Italy, July 2019. Association for Computational Linguistics. doi:
10.18653/v1/P19-1612. URL https://www.aclweb.org/anthology/P19-1612 .

Yaniv Leviathan, Matan Kalman, and Yossi Matias. Fast inference from transformers via speculative decod-
ing. In International Conference on Machine Learning , 2023. URL https://openreview.net/
forum?id=C9NEblP8vS .

Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy
Liang. Lost in the middle: How language models use long contexts. 2023.

Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In
I. Guyon, U. V on Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett
(eds.), Advances in Neural Information Processing Systems , volume 30. Curran Associates, Inc.,
2017. URL https://proceedings.neurips.cc/paper_files/paper/2017/file/
8a20a8621978632d76c43dfd28b67767-Paper.pdf .

Qing Lyu, Marianna Apidianaki, and Chris Callison-Burch. Towards faithful model explanation in nlp: A
survey, 2023.

Xueguang Ma, Kai Sun, Ronak Pradeep, and Jimmy Lin. A replication study of dense passage retriever,
2021.

Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, and Weizhu Chen.
Generation-augmented retrieval for open-domain question answering. In Proceedings of the 59th An-
nual Meeting of the Association for Computational Linguistics and the 11th International Joint Con-
ference on Natural Language Processing (Volume 1: Long Papers) , pp. 4089–4100, Online, August
2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.316. URL https:
//aclanthology.org/2021.acl-long.316 .

Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu Wang, Rae Ying Yee Wong, Alan Zhu,
Lijie Yang, Xiaoxiang Shi, Chunan Shi, Zhuoming Chen, Daiyaan Arfeen, Reyna Abhyankar, and Zhihao
Jia. Specinfer: Accelerating generative large language model serving with speculative inference and token
tree verification, 2023.

Rory Mitchell, Joshua Cooper, Eibe Frank, and Geoffrey Holmes. Sampling permutations for shapley value
estimation. Journal of Machine Learning Research , 23(43):1–46, 2022. URL http://jmlr.org/
papers/v23/21-0439.html .

Edoardo Mosca, Ferenc Szigeti, Stella Tragianni, Daniel Gallagher, and Georg Groh. SHAP-based expla-
nation methods: A review for NLP interpretability. In Proceedings of the 29th International Confer-
ence on Computational Linguistics , pp. 4593–4603, Gyeongju, Republic of Korea, October 2022. In-
ternational Committee on Computational Linguistics. URL https://aclanthology.org/2022.
coling-1.406 .

Guilliermo Owen. Values of games with a priori unions. In Rudolf Henn and Otto Moeschlin (eds.), Math-
ematical Economics and Game Theory , pp. 76–88, Berlin, Heidelberg, 1977. Springer Berlin Heidelberg.
ISBN 978-3-642-45494-3.

L. S. Penrose. The elementary statistics of majority voting. 109(1):53 – 57, 1946. doi: https://doi.org/10.
2307/2981392.

Markus N. Rabe and Charles Staats. Self-attention does not need o(n2)memory. 2022.
14

--- TRANG 15 ---
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer.
Journal of Machine Learning Research , 21(140):1–67, 2020. URL http://jmlr.org/papers/
v21/20-074.html .

Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav
Shoham. In-context retrieval-augmented language models. arXiv preprint arXiv:2302.00083 , 2023.

Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. "why should i trust you?" explaining the predic-
tions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining , pp. 1135–1144. ACM, 2016.

Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and use
interpretable models instead, 2019.

L. S. Shapley. A Value for n-Person Games , volume 2, pp. 307–318. Princeton University Press, Princeton,
1953. ISBN 9781400881970. doi: doi:10.1515/9781400881970-018. URL https://doi.org/10.
1515/9781400881970-018 .

L. S. Shapley and Martin Shubik. A method for evaluating the distribution of power in a committee system.
48(3), 1954.

Zarriess Sina, Henrik V oigt, and Simeon Sch ¨uz. Decoding methods in neural language generation: A survey.
Information , 12(9), 2021. ISSN 2078-2489. doi: 10.3390/info12090355. URL https://www.mdpi.
com/2078-2489/12/9/355 .

Joe Stacey, Yonatan Belinkov, and Marek Rei. Supervising model attention with human explanations for
robust natural language inference. Proceedings of the AAAI Conference on Artificial Intelligence , 36(10):
11349–11357, Jun. 2022. doi: 10.1609/aaai.v36i10.21386. URL https://ojs.aaai.org/index.
php/AAAI/article/view/21386 .

Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In Proceedings
of the 34th International Conference on Machine Learning-Volume 70 , pp. 3319–3328. JMLR. org, 2017.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bash-
lykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned
chat models. arXiv preprint arXiv:2307.09288 , 2023.

Junlin Wang, Jens Tuyls, Eric Wallace, and Sameer Singh. Gradient-based analysis of NLP models is manip-
ulable. In Findings of the Association for Computational Linguistics: EMNLP 2020 , pp. 247–258, Online,
November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.24.
URL https://aclanthology.org/2020.findings-emnlp.24 .

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc V
Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language mod-
els. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (eds.), Ad-
vances in Neural Information Processing Systems , volume 35, pp. 24824–24837. Curran Asso-
ciates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/
file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf .

Eyal Winter. Chapter 53 the shapley value. volume 3 of Handbook of Game Theory with Economic Ap-
plications , pp. 2025–2054. Elsevier, 2002. doi: https://doi.org/10.1016/S1574-0005(02)03016-3. URL
https://www.sciencedirect.com/science/article/pii/S1574000502030163 .
15

--- TRANG 16 ---
Yuhuai Wu, Markus Norman Rabe, DeLesley Hutchins, and Christian Szegedy. Memorizing transformers.
InInternational Conference on Learning Representations , 2022. URL https://openreview.net/
forum?id=TrjbxzRcnf- .

Kayo Yin and Graham Neubig. Interpreting language models with contrastive explanations. In Proceed-
ings of the 2022 Conference on Empirical Methods in Natural Language Processing , pp. 184–198, Abu
Dhabi, United Arab Emirates, 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.
emnlp-main.14. URL https://aclanthology.org/2022.emnlp-main.14 .

Hang Zhang, Yeyun Gong, Yelong Shen, Weisheng Li, Jiancheng Lv, Nan Duan, and Weizhu Chen. Pool-
ingformer: Long document modeling with pooling attention. 2022a.

Xinyu Zhang, Nandan Thakur, Odunayo Ogundepo, Ehsan Kamalloo, David Alfonso-Hermelo, Xiaoguang
Li, Qun Liu, Mehdi Rezagholizadeh, and Jimmy Lin. Making a MIRACL: Multilingual information
retrieval across a continuum of languages. arXiv:2210.09984 , 2022b.

Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin,
and Mengnan Du. Explainability for large language models: A survey, 2023.

Yiming Zheng, Serena Booth, Julie Shah, and Yilun Zhou. The irrationality of neural rationale models. In
Apurv Verma, Yada Pruksachatkun, Kai-Wei Chang, Aram Galstyan, Jwala Dhamala, and Yang Trista
Cao (eds.), Proceedings of the 2nd Workshop on Trustworthy Natural Language Processing (TrustNLP
2022) , pp. 64–73, Seattle, U.S.A., July 2022. Association for Computational Linguistics. doi: 10.18653/
v1/2022.trustnlp-1.6. URL https://aclanthology.org/2022.trustnlp-1.6 .
16

--- TRANG 17 ---
A XÁC MINH LẠI LITM
Chúng tôi sử dụng nhiều thí nghiệm để hiểu mức độ của các tuyên bố trong LitM. Cụ thể, chúng tôi xác minh thêm mức độ phụ thuộc vào phân phối bán tổng hợp được giới thiệu bởi các tác giả trong đó. Có một vài giả định chính được đưa ra trong phân phối bán tổng hợp này (về việc cấy một tài liệu duy nhất giữa một tập hợp các tài liệu làm nhiễu) có thể không luôn đúng trong các tình huống thực tế. Đầu tiên, số lượng tài liệu thực được truy xuất trong các hệ thống thế giới thực có thể lớn hơn hoặc nhỏ hơn một. Thứ hai, thứ tự và mức độ liên quan của các tài liệu làm nhiễu có thể thay đổi tùy theo hệ thống truy xuất được sử dụng và theo các tài liệu trong kho ngữ liệu.

Hình 6: Tái tạo LitM
Đối với cả ba mô hình đọc mà chúng tôi sử dụng, chúng tôi xác minh giả thuyết từ bài báo LitM về tác động của vị trí tài liệu đối với hiệu suất mô hình. Trong Hình 6, chúng tôi thực sự thấy đối với các mô hình được huấn luyện theo cách thông thường như T5-large và T5-XXL, chúng tôi thực sự xác minh lại giả thuyết của LitM cho thấy sự suy giảm hiệu suất mô hình bất cứ khi nào câu trả lời đúng được đặt về phía trung tâm của một cửa sổ ngữ cảnh rất dài. Chúng tôi cũng so sánh hiệu suất của mô hình T5-FiD bất biến hoán vị. Ở đây, chúng tôi do đó thấy rằng kiến trúc mô hình được huấn luyện để thực hiện nhiệm vụ trả lời câu hỏi tài liệu dài có thể tăng hiệu suất so với mô hình T5-large ban đầu. Thực tế, chúng ta thấy rằng đối với một số phần của đường cong LitM, mô hình T5-FiD nhỏ hơn có thể vượt trội hơn mô hình T5-XXL lớn hơn nhiều.

Hình 7: Kích thước hiệu ứng LitM của đường cong hình U giảm dưới các tài liệu làm nhiễu khác nhau.
Để khám phá thêm các phát hiện từ bài báo LitM, chúng tôi điều tra thêm việc thay đổi các tài liệu làm nhiễu trong ngữ cảnh sẽ làm thay đổi kích thước hiệu ứng của đường cong LitM như thế nào. Thay vì lấy 10 đoạn văn liên quan nhất để phục vụ như các tài liệu làm nhiễu như được thực hiện trong bài báo LitM ban đầu, chúng tôi xem xét việc lấy một số đoạn văn được truy xuất ít liên quan hơn. Hình 7 cho thấy rằng việc thực hiện thay đổi này đối với thiết lập bán tổng hợp thực sự làm giảm độ sâu của đường cong hình bát LitM.
17

--- TRANG 18 ---
B CHI TIẾT THỰC NGHIỆM
B.1 MÔ HÌNH VÀ BỘ DỮ LIỆU
Bộ dữ liệu Natural Questions (NQ) (Kwiatkowski et al., 2019) là một bộ dữ liệu ban đầu được thiết kế cho trả lời câu hỏi tài liệu dài, trong đó cả một đoạn văn liên quan và một câu trả lời cuối cùng phải được chọn từ một trang Wikipedia duy nhất. NQ được thiết kế lại cho trả lời câu hỏi miền mở theo (Lee et al., 2019; Karpukhin et al., 2020) chuyển đổi Wikipedia thành một kho ngữ liệu các đoạn văn thay vì các trang, và chỉ yêu cầu đưa ra một câu trả lời cuối cùng có thể được tìm thấy trong số các đoạn văn đó. Bộ dữ liệu NQ ban đầu cung cấp câu trả lời văn bản ngắn và các đoạn văn được đánh giá là liên quan miễn là chúng chứa câu trả lời sự thật cơ bản.

MIRACL (Zhang et al., 2022b). là một bộ dữ liệu được thiết kế cho truy xuất thông tin trên các đoạn văn Wikipedia. Sử dụng một điểm truy xuất thông tin hiện có, bộ dữ liệu đã chọn mười đoạn văn liên quan nhất trong kho ngữ liệu và gắn nhãn mỗi đoạn là liên quan hoặc không liên quan đến câu hỏi đã cho. Đánh giá liên quan được thực hiện bởi người chú thích con người quyết định xem thông tin đoạn văn có đủ để trả lời câu hỏi đã cho hay không; tuy nhiên, họ không được yêu cầu biện minh hoặc mô tả câu trả lời như một phần của nhãn. Theo đó, chỉ một số ít đoạn văn có thông tin nhãn đánh giá đơn lẻ sự thật cơ bản. Điều này tạo thành một tín hiệu thưa thớt hơn nhiều so với bộ dữ liệu NQ cho phép bất kỳ đoạn văn nào chứa câu trả lời văn bản sự thật cơ bản được coi là liên quan. Chính vì lý do này chúng tôi tạo ra nhãn giả dựa trên các đoạn văn MIRACL liên quan để đánh giá lại các đoạn văn MIRACL sử dụng cùng tiêu chí như NQ. Trong công trình này, chúng tôi chỉ tập trung vào tập con của MIRACL sử dụng các truy vấn tiếng Anh và các đoạn văn tiếng Anh.

Mô hình Chúng tôi tuân theo đường ống hai giai đoạn tiêu chuẩn của ODQA, trước tiên sử dụng một mô hình truy xuất để chọn một tập con các đoạn văn liên quan từ một kho ngữ liệu khổng lồ và thứ hai sử dụng một mô hình đọc để trích xuất câu trả lời của câu hỏi từ tập con các đoạn văn liên quan.

Đối với xếp hạng đoạn văn của kho ngữ liệu (mô hình truy xuất), chúng tôi sử dụng kiến trúc Contriever gần đây (Izacard et al., 2022a) theo LitM, sử dụng FAISS để lập chỉ mục các embedding Johnson et al. (2019). Đối với trả lời câu hỏi (mô hình đọc), chúng tôi sử dụng các thành viên khác nhau của họ T5 (Raffel et al., 2020). Chúng tôi sử dụng các mô hình được điều chỉnh flan có sẵn ở kích thước large và XXL ('T5-large' và 'T5-XXL') (Chung et al., 2022) và mô hình T5 large được tinh chỉnh từ FiD ('T5-FiD') (Izacard & Grave, 2021a). Cụ thể, những mô hình này tương ứng với flan-t5-large và flan-t5-xxl có sẵn từ Chung et al. (2022) ban đầu được huấn luyện trên các ngữ cảnh có độ dài 512. T5-FiD tương ứng với nqreader large từ Izacard & Grave (2021a) ban đầu được huấn luyện trên độ dài ngữ cảnh của một trăm đoạn văn được truy xuất từ truy xuất được đồng huấn luyện của họ. Mặc dù kích thước của độ dài ngữ cảnh huấn luyện, việc áp dụng các mô hình như vậy vượt ra ngoài độ dài ngữ cảnh được huấn luyện ban đầu khi áp dụng cho nhiệm vụ trả lời câu hỏi tài liệu dài Liu et al. (2023) là phổ biến (điều này khả thi do bias vị trí tương đối được triển khai trong T5).
18

--- TRANG 19 ---
B.2 KẾT QUẢ BỔ SUNG
Ở đây chúng tôi cung cấp kết quả bổ sung cho các giá trị khác nhau của số hoán vị được sử dụng để tạo giải thích trước khi đánh giá. Bởi vì đây là núm điều chỉnh chính cho các thuật toán dựa trên lấy mẫu để đánh đổi giữa độ chính xác ước tính và độ phức tạp thời gian, chúng tôi tính toán các chỉ số AUC của ứng dụng mục tiêu của chúng tôi qua tất cả các mức hoán vị để hiển thị các hiệu ứng khác nhau. Chúng ta thấy rằng thậm chí trong chỉ mười hoán vị chúng tôi đang nhận được nhiều điểm AUC nhớ lại trong hệ thống truy xuất thông tin đầu cuối đến cuối.

Bảng 3: AUC cho 3 hoán vị.
Natural MIRACL MIRACL
Questions (Gốc) (Giả)
Cơ sở 84.23 80.18 84.53
TextGenSHAP 86.01 69.58 84.71
TextGenBANZ 85.76 72.84 84.80
TextGenBANZ-10 87.53 79.08 85.40Bảng 4: AUC cho 10 hoán vị.
Natural MIRACL MIRACL
Questions (Gốc) (Giả)
Cơ sở 84.23 80.18 84.53
TextGenSHAP 87.50 74.52 85.39
TextGenBANZ 87.86 75.65 85.71
TextGenBANZ-10 88.61 81.39 86.27

Bảng 5: AUC cho 30 hoán vị.
Natural MIRACL MIRACL
Questions (Gốc) (Giả)
Cơ sở 84.23 80.18 84.53
TextGenSHAP 88.31 76.71 85.97
TextGenBANZ 88.51 76.88 86.27
TextGenBANZ-10 88.77 82.15 86.60Bảng 6: AUC cho 100 hoán vị.
Natural MIRACL MIRACL
Questions (Gốc) (Giả)
Cơ sở 84.23 80.18 84.53
TextGenSHAP 88.53 77.33 86.43
TextGenBANZ 88.56 78.19 86.17
TextGenBANZ-10 88.74 82.38 86.53

C CHI TIẾT THÊM VỀ GIÁ TRỊ SHAPLEY
Như một lời nhắc, chúng ta xem xét một mô hình ngôn ngữ F: [V]d→[0,1][V]m và chúng ta lấy f(x, S) :=F(x⊙s+
p⊙(1−s)) để định nghĩa một mô hình ngôn ngữ có mặt nạ f: [V]d× {0,1}d→[0,1][V]m trong đó các đầu vào, mặt nạ đầu vào, và đầu ra lần lượt là x∈[V]d,s∈ {0,1}d, và y∈[V]m. Chúng ta xem xét một hàm giá trị
v:P([d])→RM cho M=Vm, và xem xét các lựa chọn hàm giá trị như log-xác suất hoặc xác suất: vℓ(S) := log( f(x,1S)) và vp(S) :=f(x,1S). Vui lòng tham khảo lại phần ký hiệu trong văn bản chính để biết chi tiết đầy đủ nếu cần thiết.

C.1 GIÁ TRỊ SHAPLEY
Giá trị Shapley là một khái niệm giải pháp tồn tại lâu từ tài liệu lý thuyết trò chơi, ban đầu được thiết kế để gán thuộc tính chính xác giá trị của mỗi người chơi cá nhân trong một trò chơi hợp tác hình thành liên minh (Shapley, 1953). Trong những năm gần đây, khái niệm giải pháp này đã được tái sử dụng hướng tới mục tiêu giải thích các mô hình học máy hộp đen, coi mỗi đặc trưng cá nhân như một người chơi và chia nhỏ đầu ra dự đoán một cách chính xác giữa các đặc trưng (Lundberg & Lee, 2017). Giữa thời gian này, tuy nhiên, nhiều tiến bộ thêm trong tài liệu lý thuyết trò chơi xây dựng dựa trên công trình tinh túy của Shapley đã tiếp tục phát triển. Ở đây, chúng tôi tập trung vào một vài phần mở rộng như vậy của giá trị Shapley ban đầu khi chúng tôi áp dụng chúng cho dữ liệu có cấu trúc cụ thể của các mô hình sinh tạo văn bản-sang-văn bản.

Tiến bộ đầu tiên như vậy xảy ra chỉ ngay sau khi khái niệm giá trị Shapley ban đầu được hình thành; chỉ số quyền lực Shapley-Shubik là một tái công thức hóa của giá trị Shapley ban đầu thay vào đó được thiết kế cho các trò chơi bỏ phiếu (Shapley & Shubik, 1954). Ở đây, giá trị Shapley-Shubik đo lường lượng quyền lực hoặc ảnh hưởng mà mỗi cử tri có để ảnh hưởng đến kết quả cuộc bỏ phiếu. Cũng trong danh mục các trò chơi bỏ phiếu, chỉ số Penrose-Banzhaf (hoặc thường được gọi là chỉ số quyền lực Banzhaf) lần đầu tiên được khám phá bởi Penrose (Penrose, 1946) và sau đó được khám phá độc lập bởi Banzhaf (Banzhaf, 1965). Thậm chí ngay bây giờ, cả Banzhaf và Shapley-Shubik vẫn là hai trụ cột được tôn trọng về cách đánh giá hiệu quả cấu trúc của một trò chơi bỏ phiếu.

Theo hướng các phần mở rộng thêm cho giá trị Shapley, Owen sau đó đã mở rộng giá trị Shapley để xử lý thêm một cấu trúc phân cấp hai cấp (Owen, 1977). Cụ thể, người ta có thể tưởng tượng rằng các người chơi hình thành liên minh trong một tổ chức nhưng hơn nữa các tổ chức bản thân chúng hình thành liên minh với nhau. Giá trị có thể được định nghĩa thêm cho các cấu trúc phân cấp đa cấp và đôi khi được gọi là giá trị Owen-Winter (Winter, 2002). Phần mở rộng tương ứng cho giá trị Banzhaf thay vào đó thường được coi là đơn giản hơn và cũng được gọi là giá trị Banzhaf. Trong công trình này, chúng tôi sử dụng kết hợp của tất cả các phương pháp được liệt kê để có thể áp dụng giải thích kiểu SHAP (Lundberg & Lee, 2017) của các thuật toán học máy trong trường hợp của các mô hình transformer chuỗi-sang-chuỗi, thích ứng với cấu trúc phân cấp của văn bản đầu vào và cấu trúc tự hồi quy của sinh tạo đầu ra.

Giá trị Shapley thường được công thức hóa như một kỳ vọng đồng nhất trên các hoán vị, tạo điều kiện cho việc xấp xỉ thông qua lấy mẫu hoán vị:
φi=Eπ
vℓ(Sπ,i+i)−vℓ(Sπ,i−i)
=1
|Sd|X
π∈Sd
vℓ(Sπ,i+i)−vℓ(Sπ,i−i)
(3)
trong đó π∈ Sd:={π: [d]→[d] :π là song ánh }là tập hợp các hoán vị có kích thước d và kỳ vọng được tính trên phân phối đồng nhất của các hoán vị. Nói cách khác, π biểu thị một thứ tự ngẫu nhiên của các đặc trưng (token) và Sπ,i:={j∈[d] :π(j)< π(i)} là tập hợp các phần tử đi trước i trong thứ tự được định nghĩa bởi π. Do đó, Sπ,i+i={j∈[d] :π(j)≤π(i)} và Sπ,i−i=Sπ,i={j∈[d] :π(j)< π(i)}.

Chúng ta có thể viết tương đương giá trị Shapley như trung bình trên phân phối cảm ứng trên các tập con
S∈ P([d]):
φi=ES∼PSh(S)
vℓ(S+i)−vℓ(S−i)
=X
S⊆[d]d−1d
|S|
|S|(d− |S|)·
vℓ(S+i)−vℓ(S−i)
(4)
trong đó PSh(S) là phân phối Shapley PSh(S)∝d−1
(d
|S|)|S|(d−|S|).

Bởi vì tất cả các định nghĩa như vậy của khái niệm giải pháp này liên quan đến ít nhất một lượng số hạng hàm mũ để tính toán chính xác, phương pháp tiêu chuẩn trong tài liệu là sử dụng lấy mẫu hoán vị (Covert et al., 2021; Mitchell et al., 2022). Trong công trình này, chúng tôi cũng tuân theo phương pháp lấy mẫu hoán vị, thực hiện các điều chỉnh cần thiết để áp dụng cho cấu trúc phân cấp như mô tả trong Thuật toán 1.

C.2 SHAPLEY-SHUBIK
Điểm khác biệt quan trọng đầu tiên của chúng tôi từ tài liệu Shapley hiện có là có thể xử lý trường hợp các chuỗi đầu ra được giải mã tự hồi quy. Tất cả các giải thích hậu phân tích hiện có bao gồm dựa trên chú ý, dựa trên gradient và dựa trên nhiễu loạn không thể được áp dụng trực tiếp cho sinh tạo văn bản. Chi tiết thêm về những khuyết điểm này của các công trình hiện có được mô tả thêm trong Mục 2. Trong các ứng dụng như vậy cho sinh tạo văn bản khi chúng tồn tại, được thực hiện tự hồi quy, giải thích từng token đầu ra riêng lẻ đôi khi thậm chí không quan tâm đến các đầu ra được giải mã xảy ra trước mỗi đầu ra tự hồi quy. Điều này không chỉ đặt ra một thách thức trực quan hóa nghiêm trọng khi các đầu ra được giải mã trở nên dài hơn và dài hơn trong kỷ nguyên của LLMs, mà còn các tương quan của giải thích giữa các token đầu ra liền kề thường được xử lý không đúng cách.

Thách thức này bắt nguồn từ thực tế rằng khi sử dụng các mô hình chuỗi-sang-chuỗi tự hồi quy, vector xác suất đầu ra đầy đủ không bao giờ được tính toán. Chúng ta cần sử dụng các sơ đồ giải mã như giải mã tham lam, sinh tạo K-beam, hoặc giải mã nucleus để xấp xỉ các phần có khả năng nhất của không gian sinh tạo đầu ra. Trái ngược với các phương pháp hậu phân tích hiện có, phương pháp của chúng tôi có thể giải thích toàn bộ chuỗi đầu ra bằng cách tái công thức hóa Shapley thành công thức Shapley-Shubik trên vector xác suất và đưa ra giải thích trên toàn bộ chuỗi dự đoán.
20

--- TRANG 21 ---
Thuật toán 1 Mã giả cho tính toán Shapley phân cấp hiệu quả
1:Đầu vào : mẫu dữ liệu x∈[V]d, mô hình sinh tạo văn bản có mặt nạ f: [V]d× {0,1}d→[V]m, số
đoạn văn p∈N, số token d∈N, phân vùng phân cấp của token P= (S1, . . . , S p)
2:Tham số : ngưỡng phân cấp τ, số mẫu T
3:Đầu ra : giá trị Shapley được tính toán ở cấp tài liệu {φk}k∈[p] và cấp token {φk,i}k∈I,i∈Sk
4:
5:function RAND PERM(N)
6: return {hoán vị ngẫu nhiên của N}
7:function ONESHAPLEY PATH(f,P,I,φk,φk,i)
8: π←RAND PERM(p),S← ∅, text curr←" " ▷Khởi tạo vòng lặp
9: fork= 1 : pdo
10: ifk /∈ Ithen ▷Trường hợp 1: Thêm tất cả token của tài liệu không quan trọng vào S
11: S←S∪Sπ(k) ▷Thêm toàn bộ tài liệu
12: iff(x; 1S)̸=text currthen
13: Tăng số đếm của văn bản f(x; 1S) trong φπ(k) lên một
14: text curr←f(x; 1S)
15: else ▷Trường hợp 2: Thêm token của tài liệu quan trọng từng cái một
16: πk←RAND PERM(Sk) ▷Thứ tự ngẫu nhiên của các token trong tài liệu
17: fori∈Skdo ▷Lặp qua từng token trong tài liệu
18: S←S∪ {πk(i)} ▷Thêm một token đơn lẻ
19: iff(x; 1S)̸=text currthen
20: Tăng số đếm của văn bản f(x; 1S) trong φπ(k),πk(i) lên một
21: text curr←f(x; 1S)
22:
23:function HIERARCHICAL SHAPLEY
24: Khởi tạo φk←⃗0, cho mỗi k∈[p]
25: Khởi tạo φk,i←⃗0 cho mỗi k∈[p],i∈Sk
26: fort= 1 : Tdo
27: ONESHAPLEY PATH(f, P,∅, φk, φk,i) ▷Đầu tiên, chỉ lấy mẫu ở cấp tài liệu
28: I ← { k∈[p] :φk/S≥τ} ▷Chọn tập hợp các tài liệu quan trọng
29: fort= 1 : Tdo
30: ONESHAPLEY PATH(f, P,I, φk, φk,i) ▷Thứ hai, lấy mẫu ở cấp token cho các
tài liệu nhất định
31: return {φk}k∈[p],{φk,i}k∈[p],i∈Sk

Chúng tôi định nghĩa giá trị Shapley-Shubik và Banzhaf là :
φSh
i:=ES∼PSh(S)
[vp(S+i)−vp(S−i)]+
φBz
i:=ES∼PBz(S)
[vp(S+i)−vp(S−i)]+
(5)
trong đó PSh(S) là phân phối Shapley PSh(S)∝d−1
(d
|S|)|S|(d−|S|) và phân phối Banzhaf giống như phân phối Bernoulli PBz(S)∝p|S|(1−p)d−|S|.

Theo đó, giải thích Shapley của chúng tôi sẽ được định nghĩa tốt ngay cả trên các vector xác suất thưa thớt vp được cảm ứng bởi tất cả các thuật toán giải mã tự nhiên. Chính vì lý do này chúng tôi có thể tạo ra giải thích trên toàn bộ đầu ra dự đoán không giống như các phương pháp SHAP hiện có, xử lý văn bản được tạo ra từ các phân phối có hỗ trợ không biết trước.
21

--- TRANG 22 ---
C.3 CÁC BIẾN THỂ HIỆN CÓ CHO ỨNG DỤNG NLP
C.3.1 CÁC BIẾN THỂ PHÂN CẤP
Trong tài liệu về Shapley cho NLP hoặc giải thích dựa trên nhiễu loạn cho NLP, đã có các phương pháp tận dụng cấu trúc tuần tự và/hoặc phân cấp của dữ liệu NLP. Trong phần này, chúng tôi làm nổi bật những điểm tương đồng và khác biệt của các phương pháp hiện có. Một trong những phương pháp sớm nhất sử dụng các phiên bản có cấu trúc của giá trị Shapley, (Chen et al., 2019) định nghĩa một giá trị Shapley chỉ có thể xem xét các liên minh với các hàng xóm của nó (sử dụng cấu trúc tuyến tính cho dữ liệu văn bản) có nghĩa là các tương tác từ sẽ chỉ trải rộng qua các cụm từ liền kề. Công trình này không tận dụng rõ ràng cấu trúc phân cấp thêm của dữ liệu văn bản, nhưng vẫn sử dụng cấu trúc đầu vào của thông tin văn bản. Một trong những công trình sớm nhất sử dụng cấu trúc phân cấp, (Jin et al., 2020), sử dụng các cấu trúc phân cấp ngữ pháp được gắn nhãn bởi con người đến từ bộ dữ liệu phân loại cảm xúc SST-2 để hỗ trợ tạo ra giải thích. Giải thích của họ đưa ra giá trị cho mỗi nút trong cấu trúc phân cấp và được thực hiện bằng thuật toán lấy mẫu và che của họ, tương tự như các phương pháp dựa trên nhiễu loạn từ tài liệu khả năng diễn giải. Cuối cùng, (Chen et al., 2020) tự động tạo ra một cấu trúc phân cấp trên văn bản đầu vào thông qua một thuật toán phân chia được thiết kế đặc biệt. Các cụm từ được phân chia thành các cặp nhị phân bằng cách chọn tập hợp các cụm từ tương tác yếu nhất. Tìm kiếm qua các phân chia cụm từ có thể được thực hiện trong thời gian tuyến tính bằng cách giả định các cụm từ là tuần tự. Theo đó, tất cả các phương pháp hiện có sẽ chỉ áp dụng cho các cấu trúc phân cấp nhị phân và không có phương pháp hiện có nào có thể xử lý các cấu trúc phân cấp phức tạp hơn như phân tầng đoạn văn-câu-từ mà chúng tôi xem xét trong công trình này bằng cách sử dụng lấy mẫu hoán vị trên giá trị Owen-Winter.

C.3.2 CÁC BIẾN THỂ ĐỐI CHIẾU
Ngoài ra, cũng có những tiến bộ gần đây hơn về phía cấu trúc đầu ra cho các gán thuộc tính kiểu Shapley. Trong bối cảnh các ứng dụng mô hình hóa ngôn ngữ (văn bản sang văn bản), có nhu cầu lớn hơn để xử lý độ phức tạp ngày càng tăng của một giải thích đối với mô hình ngôn ngữ. Trong khi nhiều công trình đã thử nghiệm việc tái công thức hóa đơn giản mô hình hóa ngôn ngữ như một nhiệm vụ phân loại của token đầu tiên được tạo ra, ít công trình hơn đã có tiến bộ thêm trong việc cung cấp giải thích hợp lý vượt ra ngoài một vector trên tất cả các token đầu ra có thể (thường trong số hàng chục nghìn token hoặc nhiều hơn). Cụ thể, phương pháp chính được tận dụng là của giải thích đối chiếu, cụ thể yêu cầu một so sánh giữa hai token đầu ra thay thế, thay vì một giải thích rộng trên tất cả chúng. Jacovi et al. (2021) áp dụng những kỹ thuật này vẫn cho trường hợp đơn giản hơn của phân loại đa lớp, làm nổi bật giá trị của giải thích đối chiếu cho các ứng dụng NLP. Gần đây hơn, Yin & Neubig (2022) áp dụng các kỹ thuật tương tự cho trường hợp mô hình hóa ngôn ngữ trên token đầu tiên, sử dụng thông tin ngữ pháp như các ứng viên hữu ích cho giải thích đối chiếu. Tuy nhiên, dường như không có công trình hiện có nào đã phát triển giải thích hậu phân tích có thể thích ứng với trường hợp sinh tạo văn bản đầy đủ.
22

--- TRANG 23 ---
D TRỰC QUAN HÓA GIẢI THÍCH
Chúng tôi có thể có được hiểu biết sâu sắc về cách giải thích có cấu trúc phân cấp của chúng tôi đưa ra giá trị ở các cấp độ khác nhau, gán thuộc tính tầm quan trọng cho các đoạn văn từ các tài liệu khác nhau và sau đó tiếp tục định vị các gán thuộc tính này xuống cấp câu và từ. Chúng tôi cũng cung cấp phiên bản tương tác của các trực quan hóa sau đây được lưu trữ tại đây.

Hình 8: Ví dụ giải thích hiển thị các cấp độ khác nhau của cấu trúc phân cấp. Chúng ta thấy câu trả lời đúng "Wilhelm Conrad Rontgen" được làm nổi bật bằng màu xanh là quan trọng nhất, và chúng ta có thể tìm thấy các từ liên quan bên trong đoạn văn lớn hơn. Câu trả lời có khả năng thứ hai, Marie Curie, được làm nổi bật trong đoạn văn thứ 5 và chúng ta định vị đến các câu liên quan nhất.
23

--- TRANG 24 ---
E PHÂN TÍCH THÊM CHO SỬA CHỮA BỘ DỮ LIỆU TRÊN BỘ DỮ LIỆU MIRACL
Trong phần này chúng tôi đi sâu vào các ví dụ truy vấn và đoạn văn cụ thể được tìm thấy từ trong bộ dữ liệu MIRACL để phân tích mức độ phù hợp mà chúng đang được đánh giá. Với mỗi ví dụ, chúng tôi cung cấp câu hỏi đang được hỏi và một bảng các đoạn văn liên quan. Cụ thể, với mỗi truy vấn chúng tôi cung cấp ba đoạn văn được đánh giá cao nhất theo giá trị Shapley được tính cho truy vấn. Ngoài ra, chúng tôi cung cấp một số đoạn văn liên quan nhất không được xem xét đáng kể bởi giá trị Shapley hoặc những đoạn văn được đánh giá cụ thể bởi bộ dữ liệu MIRACL (là một trong mười tổng đoạn văn có nhãn tích cực/liên quan hoặc tiêu cực/không liên quan.) Chúng tôi bao quát ba loại ví dụ chính để cố gắng đưa ra một phạm vi bao phủ tốt về những khác biệt tồn tại qua các giải thích và qua các nhãn bộ dữ liệu.

E.1 NHÃN SAI
Những ví dụ này đại diện cho tình huống tương đối nghiêm trọng khi các nhãn gốc từ bộ dữ liệu MIRACL được phát hiện là sai sau khi khám phá với các giải thích có thể diễn giải của chúng tôi. Chúng tôi thấy rằng các đoạn văn được chọn từ điểm giải thích cho phép chúng tôi nhanh chóng khám phá các nhãn không chính xác bằng cách tìm ra các đoạn văn quan trọng nhất từ một kho ngữ liệu lớn thông tin có thể liên quan. Trong Bảng 7, chúng ta thấy rằng bộ dữ liệu gốc gắn nhãn sai các đoạn văn là không liên quan khi chúng thực sự chứa thông tin liên quan về chế độ ăn của châu chấu. Trong Bảng 8, chúng ta thấy rằng người chú thích con người thực sự nhầm lẫn 'bài kiểm tra phương ngữ' với 'phương pháp phương ngữ', gây ra việc gắn nhãn không chính xác các đoạn văn.

E.2 NHÃN KHÔNG ĐỦ
Những ví dụ này đại diện cho tình huống tương đối lành tính khi tất cả các nhãn dường như đúng, nhưng vẫn có nhiều đoạn văn chưa được gắn nhãn chứa tất cả thông tin cần thiết. Cụ thể, chúng tôi làm nổi bật các ví dụ trong Bảng 9 và 10 nơi phương pháp của chúng tôi hiệu quả định vị các đoạn văn trả lời chính xác truy vấn gốc, nhưng không có trong mười đoạn văn được truy xuất ban đầu từ hệ thống truy xuất thông tin. Sự thiếu hụt thông tin nhãn này trong bộ dữ liệu MIRACL hạn chế phương pháp của chúng tôi khỏi tiềm năng đầy đủ nhất khi chúng tôi xem xét chỉ số AUC chỉ sử dụng mười nhãn hàng đầu của MIRACL. Chính vì lý do này chúng tôi xem xét việc sử dụng đánh giá nhãn giả trong văn bản chính như một tín hiệu tốt hơn cho nhiệm vụ ODQA đầu cuối đến cuối.

E.3 GIẢI THÍCH KHÔNG ĐỦ
Trong tập hợp ví dụ cuối cùng, chúng tôi cho thấy trường hợp khi các giải thích từ mô hình ngôn ngữ xác định các đoạn văn không chính xác. Trong Bảng 11, khi tìm kiếm nguồn gốc của lý thuyết trường lượng tử, mô hình tập trung vào bài báo của Born, Heisenberg, và Jordan. Mặc dù cực kỳ liên quan, công trình này thường được coi là tiền thân của những gì được gọi là lý thuyết trường lượng tử thay vì bài báo đầu tiên của nó (Kuhlmann, 2023). Trong Bảng 12, chúng ta thấy kết quả tìm ngày thành lập hoa bang Texas. Mặc dù giải thích được đánh giá cao nhất là một đoạn văn liên quan, hai cái cao nhất tiếp theo có thông tin cả về lịch sử Texas và về bluebonnet, nhưng không có các ngày cần thiết để trả lời câu hỏi. Chúng tôi hình dung rằng ngay cả đối với những trường hợp như vậy phương pháp của chúng tôi vẫn sẽ hữu ích cho xây dựng và sửa chữa bộ dữ liệu: vì phương pháp của chúng tôi tìm thấy các đoạn văn liên quan và gần gũi mơ hồ hơn so với các hệ thống dựa trên truy xuất hiện có, người ta sẽ có thể sử dụng hiệu quả hơn các người chú thích con người khi sử dụng phương pháp của chúng tôi.

--- TRANG 25 ---
Xếp hạng Shapley Đánh giá MIRACL Nhãn thực Thỏa thuận Tiêu đề Văn bản
1 Liên quan Liên quan Tốt Châu chấu Châu chấu ăn một lượng lớn lá cây cả khi trưởng thành và trong quá trình phát triển, và có thể là các loài gây hại nghiêm trọng của đất khô cằn và đồng cỏ. Đồng cỏ, ngũ cốc, thức ăn gia súc, rau và các loại cây trồng khác có thể bị ảnh hưởng. Châu chấu thường phơi nắng, và phát triển mạnh trong điều kiện nắng ấm, vì vậy hạn hán kích thích sự gia tăng quần thể châu chấu. Một mùa hạn hán duy nhất thường không đủ để kích thích sự gia tăng quần thể lớn, nhưng nhiều mùa khô liên tiếp có thể làm như vậy, đặc biệt nếu các mùa đông xen kẽ ôn hòa để một số lượng lớn ấu trùng sống sót. Mặc dù thời tiết nắng kích thích tăng trưởng, cần có nguồn cung cấp thức ăn đầy đủ cho quần thể châu chấu ngày càng tăng. Điều này có nghĩa là mặc dù lượng mưa cần thiết để kích thích tăng trưởng thực vật, các giai đoạn dài thời tiết nhiều mây sẽ làm chậm sự phát triển của ấu trùng.

2 Không liên quan Liên quan Sai Châu chấu Châu chấu là loài ăn thực vật, với một vài loài đôi khi trở thành các loài gây hại nghiêm trọng của ngũ cốc, rau và đồng cỏ, đặc biệt khi chúng tụ tập hàng triệu con như châu chấu sa mạc và phá hủy mùa màng trên diện tích rộng. Chúng bảo vệ mình khỏi kẻ săn mồi bằng cách ngụy trang; khi bị phát hiện, nhiều loài cố gắng làm kẻ săn mồi giật mình bằng ánh sáng cánh có màu sắc rực rỡ trong khi nhảy và (nếu trưởng thành) phóng mình lên không trung, thường chỉ bay trong khoảng cách ngắn. Các loài khác như châu chấu cầu vồng có màu cảnh báo ngăn cản kẻ săn mồi. Châu chấu bị ảnh hưởng bởi ký sinh trùng và các bệnh khác nhau, và nhiều sinh vật săn mồi ăn cả ấu trùng và trưởng thành. Trứng là đối tượng của cuộc tấn công bởi ký sinh và kẻ săn mồi.

3 Không liên quan Liên quan Sai Châu chấu Hầu hết châu chấu đều ăn tạp, ăn thực vật từ nhiều nguồn thực vật, nhưng một số là ăn tạp và cũng ăn mô động vật và phân động vật. Nói chung sở thích của chúng là cỏ, bao gồm nhiều loại ngũ cốc được trồng làm cây trồng. Hệ thống tiêu hóa điển hình của côn trùng, với các ống Malpighian phóng vào ruột giữa. Carbohydrate được tiêu hóa chủ yếu trong dạ dày, trong khi protein được tiêu hóa trong ceca của ruột giữa. Nước bọt dồi dào nhưng chủ yếu không có enzyme, giúp di chuyển thức ăn và tiết Malpighian dọc theo ruột. Một số châu chấu có cellulase, bằng cách làm mềm thành tế bào thực vật làm cho nội dung tế bào thực vật có thể tiếp cận với các enzyme tiêu hóa khác.

– Không liên quan Không liên quan Tốt Châu chấu kosher Năm 1911, Abraham Isaac Kook, tổng thầy cúng của Ottoman Palestine, đã đề cập một câu hỏi đến tòa án thầy cúng tại Sana´a về phong tục ăn châu chấu của họ, và liệu phong tục này có được quan sát bằng cách quan sát các đặc điểm bên ngoài của chúng, hay chỉ đơn giản dựa vào truyền thống miệng. Câu trả lời được đưa ra cho ông bởi tòa án như sau: "Châu chấu được ăn theo truyền thống từ tổ tiên chúng tôi, xảy ra là sạch, được chúng tôi biết rõ. Nhưng còn có các loài khác có tất cả các đặc điểm có thể nhận biết của việc sạch sẽ, tuy nhiên chúng tôi thực hành kiêng chúng. [Phụ lục]: Châu chấu sạch () mà chúng tôi có truyền thống thực sự là ba loài mỗi loài có màu sắc khác nhau [từ loài khác], và mỗi loài được chúng tôi gọi bằng tiếng Ả Rập là "˘garad" (châu chấu sa mạc). Nhưng còn có các loài khác, mà chúng tôi không có truyền thống, và chúng tôi sẽ không ăn chúng. Một trong số đó lớn hơn một chút so với châu chấu, có tên "'awsham". Còn có một giống khác, nhỏ hơn châu chấu, và nó được gọi là "hanajir" (katydids).

– Không liên quan Không liên quan Tốt Chuột chù Bắc Mỹ nhỏ nhất Chế độ ăn của nó chủ yếu gồm các động vật không xương sống nhỏ, như sâu bướm, ấu trùng bọ cánh cứng, giun đất, rết, sên và bọ gỗ. Nó cũng sẽ ăn từ xác chết của động vật chết, và một lượng nhỏ hạt hoặc trái cây. Loài chuột chù này sẽ ăn con mồi nguyên con, nhưng khi ăn dế và châu chấu, chuột chù Bắc Mỹ nhỏ nhất sẽ cắn đầu con mồi và chỉ ăn các cơ quan nội tạng. Khi chiến đấu với một sinh vật lớn hơn, nó sẽ nhắm vào chân và cố gắng làm tê liệt kẻ thù, và sẽ cắn thằn lằn, thường quá lớn để nó giết chết, ở đuôi, sau đó rơi ra và cung cấp cho nó một bữa ăn trong khi thằn lằn thoát. Chuột chù Bắc Mỹ nhỏ nhất đôi khi cũng sẽ sống bên trong tổ ong và ăn tất cả ấu trùng. Nó thường sẽ chia sẻ thức ăn với các chuột chù khác. Nó ăn nhiều hơn trọng lượng cơ thể mỗi ngày và được biết là tích trữ thức ăn.

Bảng 7: Ví dụ bộ dữ liệu MIRACL cho: "Châu chấu ăn gì?"
25

--- TRANG 26 ---
Xếp hạng Shapley Đánh giá MIRACL Nhãn thực Thỏa thuận Tiêu đề Văn bản
1 Chưa đánh giá Liên quan Ổn Giao tiếp liên cá nhân Một phương pháp biện chứng đối với giao tiếp liên cá nhân được phát triển bởi các học giả Leslie Baxter và Barbara Montgomery. Phương pháp biện chứng của họ xoay quanh các khái niệm mâu thuẫn, thay đổi, thực hành và tổng thể. Bị ảnh hưởng bởi Hegel, Marx và Bakhtin, phương pháp biện chứng được thông báo bởi một nhận thức luận đề cập đến một phương pháp lý luận mà qua đó người ta tìm kiếm hiểu biết thông qua sức căng của các lập luận đối lập. Sử dụng phương pháp biện chứng, Baxter và Montgomery đã phát triển hai loại biện chứng hoạt động trong các mối quan hệ liên cá nhân: nội bộ và bên ngoài. Chúng bao gồm tự chủ-kết nối, mới lạ-có thể dự đoán, cởi mở-khép kín.

2 Chưa đánh giá Liên quan Ổn Nghiên cứu biện chứng Nghiên cứu biện chứng hay điều tra biện chứng hay điều tra biện chứng là một hình thức nghiên cứu định tính sử dụng phương pháp biện chứng, nhằm khám phá sự thật thông qua việc kiểm tra và thẩm vấn các ý tưởng, quan điểm hoặc lập luận cạnh tranh. Nghiên cứu biện chứng có thể được coi như một hình thức nghiên cứu khám phá, ở chỗ không có nhiều giả thuyết nghiên cứu để kiểm tra, mà là những hiểu biết mới cần được phát triển.

3 Chưa đánh giá Liên quan Ổn Biện chứng Biện chứng hay biện chứng học (, "dialektike"; liên quan đến đối thoại), còn được biết đến như phương pháp biện chứng, về cơ bản là một cuộc thảo luận giữa hai hoặc nhiều người có quan điểm khác nhau về một chủ đề nhưng muốn thiết lập sự thật thông qua các lập luận có lý. Biện chứng giống như tranh luận, nhưng khái niệm loại trừ các yếu tố chủ quan như sự hấp dẫn cảm xúc và nghĩa chê bai hiện đại của tu từ học. Biện chứng có thể được đối chiếu với phương pháp giáo điều, trong đó một bên của cuộc trò chuyện dạy bên kia. Biện chứng được biết đến thay thế như logic nhỏ, trái ngược với logic lớn hoặc phê bình.

– Liên quan Không liên quan Sai Bài kiểm tra phương ngữ Bài kiểm tra phương ngữ được tạo ra bởi A.J. Ellis vào tháng 2 năm 1879, và được sử dụng trong công việc thực địa cho tác phẩm "On Early English Pronunciation" của ông. Nó đứng như một trong những phương pháp sớm nhất để xác định âm nguyên âm và đặc điểm của lời nói. Mục đích là nắm bắt các âm nguyên âm chính của một phương ngữ cá nhân bằng cách nghe việc đọc một đoạn văn ngắn. Tất cả các danh mục từ West Saxon và nguyên âm được bao gồm trong bài kiểm tra để có thể so sánh với lời nói West Saxon lịch sử cũng như với các phương ngữ khác nhau.

– Không liên quan Liên quan Sai Trường phái Frankfurt Viện cũng cố gắng tái công thức hóa biện chứng như một phương pháp cụ thể. Việc sử dụng phương pháp biện chứng như vậy có thể được truy tìm về triết học của Hegel, người đã hình dung biện chứng như xu hướng của một khái niệm chuyển sang sự phủ định của chính nó như kết quả của xung đột giữa các khía cạnh mâu thuẫn vốn có của nó. Trái ngược với các phương thức suy nghĩ trước đây, coi các sự vật một cách trừu tượng, mỗi cái tự thân và như thể được phú cho các thuộc tính cố định, biện chứng Hegel có khả năng xem xét các ý tưởng theo chuyển động và thay đổi của chúng theo thời gian, cũng như theo các mối quan hệ và tương tác của chúng.

Bảng 8: Ví dụ bộ dữ liệu MIRACL cho: "Khi nào phương pháp biện chứng được sử dụng?"
26

--- TRANG 27 ---
Xếp hạng Shapley Đánh giá MIRACL Nhãn thực Thỏa thuận Tiêu đề Văn bản
1 Liên quan Liên quan Tốt Danh sách bài hát trong Guitar Hero Live "Guitar Hero Live" là một trò chơi video âm nhạc năm 2015 được phát triển bởi FreeStyleGames và xuất bản bởi Activision. Đây là tựa game đầu tiên trong series "Guitar Hero" kể từ khi nó tạm ngừng hoạt động sau năm 2011, và là trò chơi đầu tiên trong series có sẵn cho máy chơi game video thế hệ thứ 8 (PlayStation 4, Wii U, và Xbox One). Trò chơi được phát hành trên toàn thế giới vào ngày 20 tháng 10 năm 2015 cho các hệ thống này cũng như PlayStation 3, Xbox 360, và các thiết bị iOS bao gồm Apple TV.

2 Chưa đánh giá Liên quan Ổn Danh sách bài hát trong Guitar Hero Live Hai trăm bài hát ban đầu có sẵn trên GHTV vào lúc phát hành trò chơi ngày 20 tháng 10 năm 2015.

3 Chưa đánh giá Liên quan Ổn Guitar Hero Sau một thời gian tạm ngừng năm năm, như mô tả dưới đây, Activision đã công bố "Guitar Hero Live" để phát hành vào cuối năm 2015 trên hầu hết các máy chơi thế hệ thứ bảy và thế hệ thứ tám. "Live" được phát triển để xây dựng lại trò chơi từ đầu, và trong khi gameplay vẫn tương tự như các tựa game trước đó, tập trung chủ yếu vào guitar chính, nó sử dụng bộ điều khiển guitar 3 nút với mỗi nút có vị trí "lên" và "xuống", tạo ra các tabulators phức tạp hơn. Trò chơi sử dụng cảnh quay trực tiếp của một buổi hòa nhạc rock, được chụp từ góc nhìn của guitarist chính, để cung cấp trải nghiệm sống động hơn.

– Liên quan Liên quan Tốt Guitar Hero Năm 2015, Activision đã công bố tựa game mới đầu tiên cho series trong 5 năm, "Guitar Hero Live", phát hành vào tháng 10 năm 2015. Tựa game được coi là khởi động lại của series, với việc phát triển được thực hiện bởi FreeStyleGames, đã phát triển các trò chơi "DJ Hero" trước đó. Tính đến ngày 1 tháng 12 năm 2018, Activision đã vô hiệu hóa máy chủ GHTV cho Guitar Hero Live, giảm nội dung có thể chơi từ khoảng 500 bài hát xuống còn 42 track trên đĩa.

– Không liên quan Không liên quan Tốt Guitar Hero Live Trong một báo cáo thu nhập ngay sau khi trò chơi phát hành, Activision tuyên bố rằng "Guitar Hero Live" đang bán chạy hơn hai trò chơi "Guitar Hero" trước đó của họ, "" và "Guitar Hero 5", mặc dù không báo cáo số liệu bán hàng chính xác. Trong kết quả thu nhập hàng quý được trình bày vào tháng 2 năm 2016, Activision báo cáo rằng doanh số cho "Guitar Hero Live" đã không đạt được kỳ vọng của họ, và vào tháng 3 năm 2016, đã công bố rằng họ phải sa thải khoảng 50 nhân viên của FreeStyleGames, mặc dù studio vẫn mở để tiếp tục công việc bổ sung cho Activision. Trước Electronic Entertainment Expo 2016, Activision tuyên bố họ sẽ tiếp tục sản xuất nội dung cho "Guitar Hero Live" nhưng không có kế hoạch hiện tại cho một trò chơi khác.

Bảng 9: Ví dụ bộ dữ liệu MIRACL cho: "Guitar Hero Live lần đầu được phát hành khi nào?"
27

--- TRANG 28 ---
Xếp hạng Shapley Đánh giá MIRACL Nhãn thực Thỏa thuận Tiêu đề Văn bản
1 Chưa đánh giá Liên quan Ổn Nguồn gốc Hangul Bảng chữ cái Hàn Quốc là chữ viết bản địa của Hàn Quốc, được tạo ra vào giữa thế kỷ thứ mười lăm bởi Vua Sejong, như là bổ sung và thay thế cho "hanja" Sino-Hàn có tính logographic. Ban đầu bị phê phán bởi tầng lớp có học như "eonmun" (chữ viết thông tục), nó chỉ trở thành chữ viết Hàn Quốc chính sau khi độc lập khỏi Nhật Bản vào giữa thế kỷ 20.

2 Chưa đánh giá Liên quan Ổn Hangul Bảng chữ cái Hàn Quốc, được biết đến như Hangul (; từ tiếng Hàn,), đã được sử dụng để viết tiếng Hàn Quốc kể từ khi được tạo ra vào thế kỷ 15 bởi Vua Sejong Đại đế. Nó cũng có thể được viết theo cách La tinh hóa tiêu chuẩn.

3 Chưa đánh giá Liên quan Ổn Jeong In-ji Ông có lẽ được biết đến nhiều nhất vì đã viết phần phụ lục của "Hunmin Jeongeum Haerye", bình luận và giải thích về bảng chữ cái bản địa Hangeul được phát minh bởi Vua Sejong năm 1443. Ông cũng đóng góp vào "Goryeosa", lịch sử chính thức của triều đại Goryeo, và "Yongbi Eocheon-ga".

– Liên quan Liên quan Tốt Korea Bảng chữ cái Hàn Quốc hangul cũng được phát minh trong thời gian này bởi Vua Sejong Đại đế.

– Liên quan Liên quan Tốt Nguồn gốc Hangul Hangul được tạo ra và ban hành cá nhân bởi vị vua thứ tư của triều đại Joseon, Sejong Đại đế. Viện học thuật của Sejong, Điện Hiền tài, thường được ghi nhận với công trình này, và ít nhất một trong những học giả của nó đã tham gia sâu vào việc tạo ra nó, nhưng dường như cũng là một dự án cá nhân của Sejong.

Bảng 10: Ví dụ bộ dữ liệu MIRACL cho: "Ai đã phát minh ra Hangul?"
28

--- TRANG 29 ---
Xếp hạng Shapley Đánh giá MIRACL Nhãn thực Thỏa thuận Tiêu đề Văn bản
1 Không liên quan Không liên quan Tốt Lý thuyết trường lượng tử Thông qua các công trình của Born, Heisenberg, và Pascual Jordan trong 1925-1926, một lý thuyết lượng tử của trường điện từ tự do (một trường không có tương tác với vật chất) được phát triển thông qua lượng tử hóa chính tắc bằng cách coi trường điện từ như một tập hợp các dao động điều hòa lượng tử. Tuy nhiên, với việc loại trừ các tương tác, một lý thuyết như vậy vẫn chưa có khả năng đưa ra dự đoán định lượng về thế giới thực.

2 Chưa đánh giá Không liên quan Ổn Lịch sử lý thuyết trường lượng tử Năm 1925, Werner Heisenberg, Max Born, và Pascual Jordan đã xây dựng chính một lý thuyết như vậy bằng cách biểu diễn các bậc tự do nội bộ của trường như một tập hợp vô hạn các dao động điều hòa, và sau đó sử dụng thủ tục lượng tử hóa chính tắc cho những dao động này; bài báo của họ được xuất bản năm 1926. Lý thuyết này giả định rằng không có điện tích hoặc dòng điện nào hiện diện và ngày nay sẽ được gọi là lý thuyết trường tự do.

3 Chưa đánh giá Không liên quan Ổn Lý thuyết trường lượng tử Năm 1913, Niels Bohr giới thiệu mô hình Bohr về cấu trúc nguyên tử, trong đó các electron trong nguyên tử chỉ có thể có một loạt năng lượng rời rạc, thay vì liên tục. Đây là một ví dụ khác về lượng tử hóa. Mô hình Bohr đã giải thích thành công tính chất rời rạc của các đường quang phổ nguyên tử. Năm 1924, Louis de Broglie đề xuất giả thuyết về tính chất sóng-hạt, rằng các hạt vi mô thể hiện cả tính chất sóng và hạt dưới các hoàn cảnh khác nhau. Kết hợp những ý tưởng rải rác này, một ngành học mạch lạc, cơ học lượng tử, được hình thành giữa 1925 và 1926, với những đóng góp quan trọng từ de Broglie, Werner Heisenberg, Max Born, Erwin Schrödinger, Paul Dirac, và Wolfgang Pauli.

– Chưa đánh giá Liên quan Ổn Lịch sử lý thuyết trường lượng tử Lý thuyết đầu tiên tương đối hoàn chỉnh về điện động lực học lượng tử, bao gồm cả trường điện từ và vật chất tích điện như các đối tượng cơ học lượng tử, được tạo ra bởi Paul Dirac năm 1927. Lý thuyết trường lượng tử này có thể được sử dụng để mô hình hóa các quá trình quan trọng như việc phát ra một photon bởi một electron rơi vào trạng thái lượng tử có năng lượng thấp hơn, một quá trình trong đó "số lượng hạt thay đổi"—một nguyên tử trong trạng thái ban đầu trở thành một nguyên tử cộng một photon trong trạng thái cuối cùng. Hiện tại người ta hiểu rằng khả năng mô tả các quá trình như vậy là một trong những đặc điểm quan trọng nhất của lý thuyết trường lượng tử.

– Liên quan Liên quan Tốt Lịch sử lý thuyết trường lượng tử Chuỗi thứ ba trong sự phát triển của lý thuyết trường lượng tử là nhu cầu xử lý thống kê của các hệ thống nhiều hạt một cách nhất quán và dễ dàng. Năm 1927, Pascual Jordan đã cố gắng mở rộng lượng tử hóa chính tắc của trường cho các hàm sóng nhiều vật thể của các hạt giống hệt nhau sử dụng một hình thức được biết đến như lý thuyết biến đổi thống kê; thủ tục này hiện đôi khi được gọi là lượng tử hóa thứ hai. Năm 1928, Jordan và Eugene Wigner phát hiện rằng trường lượng tử mô tả electron, hoặc các fermion khác, phải được mở rộng sử dụng các toán tử tạo và hủy phản giao hoán do nguyên lý loại trừ Pauli (xem biến đổi Jordan–Wigner). Chuỗi phát triển này được kết hợp vào lý thuyết nhiều vật thể và ảnh hưởng mạnh mẽ đến vật lý chất rắn và vật lý hạt nhân.

Bảng 11: Ví dụ bộ dữ liệu MIRACL cho: "Lý thuyết trường lượng tử được phát triển khi nào?"
29

--- TRANG 30 ---
Xếp hạng Shapley Đánh giá MIRACL Nhãn thực Thỏa thuận Tiêu đề Văn bản
1 Liên quan Liên quan Tốt Bluebonnet (thực vật) Bluebonnet là tên được đặt cho bất kỳ loài nào có hoa màu xanh của chi "Lupinus" chủ yếu được tìm thấy ở tây nam Hoa Kỳ và là hoa bang tập thể của Texas. Hình dạng của các cánh hoa trên bông hoa giống chiếc mũ được các phụ nữ tiên phong đội để che chắn họ khỏi ánh nắng mặt trời. Các loài thường được gọi là bluebonnet bao gồm: Vào ngày 7 tháng 3 năm 1901, "Lupinus subcarnosus" trở thành loài bluebonnet duy nhất được công nhận là hoa bang của Texas; tuy nhiên, "Lupinus texensis" nổi lên như loài được hầu hết người Texas yêu thích. Vì vậy, năm 1971, Cơ quan Lập pháp Texas đã làm cho bất kỳ loài tương tự nào của "Lupinus" có thể được tìm thấy ở Texas trở thành hoa bang.

2 Chưa đánh giá Không liên quan Ổn John Nance Garner Garner được bầu vào Hạ viện Texas năm 1898, và tái đắc cử năm 1900. Trong thời gian phục vụ, cơ quan lập pháp đã chọn một loài hoa bang cho Texas. Garner nhiệt tình ủng hộ xương rồng lê gai cho vinh dự này, và do đó kiếm được biệt danh "Cactus Jack". (Bluebonnet đã được chọn.) Năm 1901 Garner bỏ phiếu cho thuế thăm dò, một biện pháp được thông qua bởi cơ quan lập pháp do Đảng Dân chủ thống trị để làm cho việc đăng ký cử tri khó khăn hơn và giảm số lượng cử tri da đen, thiểu số, và da trắng nghèo trong danh sách bỏ phiếu. Điều này đã tước quyền của hầu hết cử tri thiểu số cho đến những năm 1960, và kết thúc các thách thức đối với quyền lực Dân chủ; Texas trở thành một bang một đảng thực tế.

3 Không liên quan Không liên quan Tốt Alamo Fire Bluebonnet màu nâu đỏ và trắng được phát triển như một phần của nỗ lực tạo ra lá cờ Texas với bluebonnet đỏ, trắng và xanh để kỷ niệm sesquicentennial của Texas năm 1986. Bluebonnet màu hồng được tìm thấy ở San Antonio, và các ví dụ màu đỏ được lai chọn có chọn lọc bởi Dr. Jerry Parsons của Dịch vụ Khuyến nông Texas A&M AgriLife để cuối cùng cho ra bluebonnet màu nâu đỏ năm 2000. Màu của những bluebonnet này phù hợp, vì màu nâu đỏ được liên kết mạnh mẽ với Đại học Texas A&M.

– Không liên quan Không liên quan Tốt Nhà máy Đạn dược Bluebonnet Nhà máy được vận hành bởi Công ty National Gypsum nhưng được giám sát bởi quân đội và là một trong bốn nhà máy Đạn dược ở Hoa Kỳ trong Thế chiến II. Các kỹ sư quân đội phụ trách tất cả xây dựng nhà máy trong khi nhân sự Gypsum và những người khác nghiên cứu các chiến lược khác. Nhà máy Đạn dược Bluebonnet có tên từ Thiếu tá Paul Van Tuyl, đã đặt tên nhà máy theo hoa bang của Texas (Bluebonnet).

– Không liên quan Không liên quan Tốt Lupinus texensis Lupinus texensis, bluebonnet Texas hoặc lupine Texas là một loài lupine đặc hữu của Texas. Với các loài liên quan khác của lupine cũng được gọi là bluebonnet, nó là hoa bang của Texas.

Bảng 12: Ví dụ bộ dữ liệu MIRACL cho: "Bluebonnet được đặt tên là hoa bang Texas khi nào?"
30

# E2-LLM: Mở rộng Độ dài Hiệu quả và Cực đại cho
Mô hình Ngôn ngữ Lớn

Jiaheng Liu*1, Zhiqi Bai*1, Yuanxing Zhang1, Chenchen Zhang1, Yu Zhang1,
Ge Zhang2,Jiakai Wang1,Haoran Que1,Yukang Chen3,Wenbo Su1,Tiezheng Ge1,
Jie Fu4,Wenhu Chen2,Bo Zheng1

1Alibaba Group,2University of Waterloo,3The Chinese University of Hong Kong,
4The Hong Kong University of Science and Technology

{ljh411989, baizhiqi.bzq}@taobao.com

## Tóm tắt

Thông thường, việc huấn luyện LLM với kích thước ngữ cảnh dài rất tốn kém về mặt tính toán, đòi hỏi nhiều giờ huấn luyện và tài nguyên GPU. Các phương pháp mở rộng ngữ cảnh dài hiện có thường cần các quy trình huấn luyện bổ sung để hỗ trợ các cửa sổ ngữ cảnh dài tương ứng, trong đó cần có dữ liệu huấn luyện ngữ cảnh dài (ví dụ: 32k) và giả định chi phí huấn luyện GPU cao. Để giải quyết các vấn đề nêu trên, chúng tôi đề xuất một phương pháp mở rộng độ dài Hiệu quả và Cực đại cho Mô hình Ngôn ngữ Lớn, gọi là E2-LLM, chỉ với một quy trình huấn luyện và giảm đáng kể chi phí tính toán, đồng thời loại bỏ nhu cầu thu thập dữ liệu ngữ cảnh dài. Cụ thể, đầu tiên, dữ liệu huấn luyện của E2-LLM chỉ yêu cầu độ dài ngắn (ví dụ: 4k), điều này giảm đáng kể chi phí tinh chỉnh. Thứ hai, quy trình huấn luyện trên cửa sổ ngữ cảnh huấn luyện ngắn chỉ được thực hiện một lần, và chúng ta có thể hỗ trợ các cửa sổ ngữ cảnh đánh giá khác nhau khi suy luận. Thứ ba, trong E2-LLM, dựa trên embedding vị trí RoPE, chúng tôi giới thiệu hai phương pháp tăng cường khác nhau trên các tham số tỷ lệ và chỉ số vị trí cho các mẫu khác nhau trong huấn luyện. Mục đích là làm cho mô hình mạnh mẽ hơn với các khác biệt tương đối khác nhau khi nội suy trực tiếp độ dài ngữ cảnh tùy ý khi suy luận. Kết quả thực nghiệm toàn diện trên nhiều bộ dữ liệu benchmark chứng minh hiệu quả của E2-LLM trên các tác vụ ngữ cảnh dài đầy thử thách.

## 1 Giới thiệu

Các mô hình ngôn ngữ lớn (LLM) thường có độ dài cửa sổ ngữ cảnh được xác định trước. Ví dụ, đầu vào cho các mô hình LLaMA (Touvron et al., 2023a,b) phải ít hơn 2.048 hoặc 4096 token. Giới hạn cửa sổ ngữ cảnh đặt trước này thường bị vượt quá trong các ứng dụng như cuộc hội thoại dài, tóm tắt tài liệu hoặc lập luận dài hạn (Zheng et al., 2023; Chen et al., 2023a). Đối với các ứng dụng này, LLM với cửa sổ ngữ cảnh dài hơn được ưa chuộng. Tuy nhiên, việc huấn luyện LLM từ đầu với cửa sổ ngữ cảnh dài đòi hỏi chi phí huấn luyện đáng kể. Để giải quyết vấn đề này, nhiều phương pháp mở rộng ngữ cảnh dài (Peng et al., 2023; Chen et al., 2023b) đã được đề xuất để mở rộng cửa sổ ngữ cảnh của LLM được huấn luyện trước hiện có.

Một cách tiếp cận đơn giản được gọi là ngoại suy trực tiếp, tinh chỉnh LLM được huấn luyện trước hiện có với cửa sổ ngữ cảnh dài hơn. Tuy nhiên, các tác giả của Position Interpolation (PI) (Chen et al., 2023a) quan sát thấy rằng các mô hình được huấn luyện bằng ngoại suy trực tiếp thích ứng với cửa sổ ngữ cảnh dài rất chậm và ngoại suy trực tiếp không hiệu quả trong việc mở rộng cửa sổ ngữ cảnh dài hơn đáng kể.

Như thể hiện trong Hình 1 (a), các phương pháp mở rộng ngữ cảnh dài hiện có (ví dụ: PI) thường cần các quy trình huấn luyện bổ sung để hỗ trợ các cửa sổ ngữ cảnh dài hơn tương ứng, trong đó cần thu thập dữ liệu huấn luyện ngữ cảnh dài và cần huấn luyện với việc sử dụng bộ nhớ GPU cao cho mỗi cửa sổ ngữ cảnh.

Để giải quyết các vấn đề nêu trên, như thể hiện trong Hình 1 (b), chúng tôi đề xuất một phương pháp mở rộng độ dài Hiệu quả và Cực đại của LLM, gọi là E2-LLM, để hỗ trợ mở rộng độ dài cực đại của LLM chỉ với một quy trình huấn luyện trên dữ liệu ngữ cảnh ngắn và chi phí tính toán hạn chế. Dựa trên E2-LLM, chúng ta có thể hỗ trợ tốt các cửa sổ ngữ cảnh đánh giá khác nhau khi suy luận bằng cách chỉ thay đổi một siêu tham số của RoPE (Su et al., 2021) theo độ dài ngữ cảnh đầu vào. Cụ thể, đầu tiên, trong E2-LLM, dữ liệu huấn luyện chỉ yêu cầu dữ liệu thường dùng với độ dài ngắn (ví dụ: 4k), và chúng ta chỉ cần huấn luyện LLM một lần và hỗ trợ nội suy độ dài ngữ cảnh tùy ý khi suy luận, điều này giảm đáng kể chi phí sử dụng GPU. Thứ hai, trong

*Lưu ý rằng chúng tôi theo (Chen et al., 2023b) để báo cáo bộ nhớ GPU bằng cách tinh chỉnh LLaMA2 7B trên các độ dài ngữ cảnh khác nhau với FlashAttention-2 (Dao, 2023) và DeepSpeed stage 2 (Rasley et al., 2020).*

![Hình 1: So sánh các phương pháp mở rộng ngữ cảnh dài hiện có (ví dụ: PI (Chen et al., 2023a)) và E2-LLM của chúng tôi]

E2-LLM của chúng tôi, đầu tiên chúng tôi đề xuất tăng cường trên tham số tỷ lệ của PI từ một phân phối được xác định trước (ví dụ: phân phối đều), nhằm bao phủ các mật độ vị trí khác nhau trong huấn luyện. Bên cạnh đó, chúng tôi quan sát thấy rằng chỉ thay đổi tham số tỷ lệ sẽ làm cho LLM tập trung vào một phạm vi nhỏ các chỉ số vị trí tuyệt đối. Do đó, trong E2-LLM, để cải thiện khả năng tổng quát hóa của E2-LLM, chúng tôi tiếp tục đề xuất tăng cường trên các tham số chỉ số vị trí bằng cách giới thiệu các offset vị trí trên các chỉ số vị trí tuyệt đối của RoPE.

Các đóng góp của E2-LLM của chúng tôi như sau:

• Trong công trình này, chúng tôi đầu tiên khảo sát các vấn đề (ví dụ: chi phí tinh chỉnh lớn với dữ liệu ngữ cảnh dài) của các phương pháp mở rộng ngữ cảnh dài hiện có, và đề xuất phương pháp mở rộng độ dài Hiệu quả và Cực đại (tức là E2-LLM) để huấn luyện LLM một lần trên dữ liệu ngữ cảnh ngắn với chi phí bộ nhớ GPU hạn chế và hỗ trợ các cửa sổ ngữ cảnh đánh giá khác nhau.

• Trong E2-LLM, dựa trên RoPE, chúng tôi đề xuất hai chiến lược tăng cường trên các tham số tỷ lệ và chỉ số vị trí cho các mẫu khác nhau trong huấn luyện, nhằm hỗ trợ các cửa sổ ngữ cảnh đánh giá khác nhau trong một quy trình huấn luyện và cải thiện khả năng ngữ cảnh dài của LLM.

• Kết quả thực nghiệm toàn diện trên nhiều bộ dữ liệu benchmark ngữ cảnh dài chứng minh hiệu quả và hiệu suất của phương pháp E2-LLM.

## 2 Các công trình liên quan

**Transformer ngữ cảnh dài.** Nhiều nghiên cứu mở rộng đã nhằm tăng khả năng xử lý chuỗi văn bản dài hơn của transformer. Các chiến lược như sử dụng mô hình dựa trên truy xuất (Karpukhin et al., 2020; Izacard et al., 2022) đã được áp dụng, tích hợp các tài liệu bổ sung và kết quả tìm kiếm vào ngữ cảnh. Nhiều nỗ lực khác nhau đã thích ứng multi-head attention bằng cách thiết kế các phương án ước lượng thay thế (Wang et al., 2020; Beltagy et al., 2020; Kitaev et al., 2020; Bulatov et al., 2022; Ding et al., 2023) để giảm thiểu nhu cầu tính toán vốn dĩ cao của self-attention. Ví dụ, Longformer (Beltagy et al., 2020) và BigBird (Zaheer et al., 2020) sử dụng một dạng attention pha loãng cho văn bản mở rộng hơn. Trong khi đó, các sáng kiến khác (Wu et al., 2022; Bulatov et al., 2022) đã giới thiệu các hệ thống dựa trên bộ nhớ để nén các đầu vào trước đó và gọi lại các thành phần có liên quan. Tuy nhiên, các cách tiếp cận này có xu hướng thiếu hiệu quả của attention đầy đủ, do đó cản trở việc tinh chỉnh các mô hình ngôn ngữ lớn được huấn luyện trước (LLM) (Wu et al., 2024; Guo et al., 2023; Wang et al., 2023; Bai et al., 2024; Chai et al., 2024). Cách tiếp cận của chúng tôi khác biệt ở chỗ nó xấp xỉ cơ chế attention theo cách vẫn gần gũi với phương pháp attention thông thường, chỉ có sự khác biệt tối thiểu.

**LLM ngữ cảnh dài.** Các mô hình ngôn ngữ lớn (LLM) như LLaMA (Touvron et al., 2023a) và LLaMA2 (Touvron et al., 2023b) ban đầu được huấn luyện với kích thước ngữ cảnh cố định, thường là 2048 và 4096 token tương ứng. Tuy nhiên, chi phí huấn luyện LLM với ngữ cảnh mở rộng từ đầu thường vượt quá khả năng của nhóm nghiên cứu trung bình. Do đó, các nghiên cứu gần đây đã khám phá các cách để mở rộng độ dài ngữ cảnh của các mô hình này trong giai đoạn tinh chỉnh. Ví dụ, Position Interpolation (Chen et al., 2023a) thích ứng kỹ thuật mã hóa vị trí xoay (Su et al., 2021), cho phép LLaMA xử lý ngữ cảnh dài tới 32768 token. Một phương pháp khác, Landmark attention (Mohtashami và Jaggi, 2023), đạt được hiệu quả nhưng với cái giá là một số độ chính xác, bằng cách nén ngữ cảnh mở rộng thành một tập hợp các token được truy xuất. Ngược lại, chiến lược của chúng tôi giảm thiểu chi phí liên quan đến tinh chỉnh mà không làm tổn hại đến hiệu quả của attention ban đầu. Nó đảm bảo rằng mô hình có attention đầy đủ và không thay đổi trên toàn bộ đầu vào trong quá trình suy luận. Các cách tiếp cận khác, như ALiBi (Press et al., 2022), đã được thiết kế để huấn luyện Transformer trên các chuỗi ngắn hơn và sau đó áp dụng chúng vào chuỗi dài hơn khi suy luận, ngoại suy hiệu quả độ dài ngữ cảnh. Tuy nhiên, các kỹ thuật này không hiệu quả đối với LLM được huấn luyện trước dựa vào mã hóa vị trí với khả năng ngoại suy kém, như RoPE (Su et al., 2021). Để khắc phục điều này, nghiên cứu gần đây đã hướng tới việc sửa đổi embedding vị trí của LLM để xử lý văn bản dài hơn. Điều này bao gồm các phương pháp như Position Interpolation (Chen et al., 2023a), NTK-aware position embeddings (ntk, 2023), và Yarn (Peng et al., 2023).

## 3 Kiến thức nền

### 3.1 Rotary Position Embedding (RoPE)

Các mô hình Transformer yêu cầu thông tin vị trí rõ ràng được đưa vào, trong đó mã hóa vị trí được sử dụng để biểu diễn thứ tự của đầu vào. Trong phần này, chúng tôi lấy Rotary Position Embedding (RoPE) (Su et al., 2021) làm ví dụ, được sử dụng rộng rãi trong nhiều mô hình kiểu LLaMA (Touvron et al., 2023a). Trong RoPE, cho chỉ số vị trí m∈[0, L) và vector embedding x:= [x0, x1, . . . , xd−1]⊤, trong đó L là cửa sổ ngữ cảnh và d là chiều của đầu attention, một hàm phức có giá trị vector f(x, m) được định nghĩa như sau:

f(x, m) = [(x0+ix1)eimθ0, . . . , (xd−2+ixd−1)eimθd/2−1]⊤, (1)

trong đó i := √−1 là đơn vị ảo và θj = 10000−2j/d. Dựa trên RoPE, điểm attention a được tính như sau:

a(m, n) = Re ⟨f(q, m),f(k, n)⟩ =: a(m−n), (2)

trong đó q và k lần lượt là các vector query và key cho một đầu attention cụ thể, và việc dẫn xuất chi tiết được bỏ qua. Trong Eq. 2, chúng ta quan sát thấy a(m, n) chỉ phụ thuộc vào vị trí tương đối m−n thông qua các hàm lượng giác. Bên cạnh đó, RoPE được thực hiện trên cả embedding query và key để tính điểm attention ở mỗi lớp.

### 3.2 Position Interpolation

Mặc dù điểm attention trong Eq. 2 chỉ phụ thuộc vào các vị trí tương đối, hiệu suất ngoại suy của nó không tốt. Cụ thể, khi ngoại suy trực tiếp đến các cửa sổ ngữ cảnh lớn hơn chưa thấy trong huấn luyện, perplexity sẽ tăng lên con số rất cao (tức là >103).

Gần đây, Position Interpolation (PI) (Chen et al., 2023a) đã được đề xuất, trong đó s được định nghĩa là khoảng cách vị trí giữa một query và một key, và L được định nghĩa là kích thước của cửa sổ ngữ cảnh được huấn luyện. Thay vì ngoại suy trực tiếp trên điểm attention đến s > L, điểm attention được định nghĩa là ˜a(s) = a(Ls/L′), trong đó L′ là cửa sổ ngữ cảnh dài hơn được mở rộng. Chính thức, trong PI, RoPE f được thay thế bằng f′ như sau:

f′(x, m) = f(x, mL/L′), (3)

trong đó các chỉ số vị trí từ [0, L′) đến [0, L) được giảm để khớp với phạm vi chỉ số ban đầu trước khi tính RoPE. Nói cách khác, khoảng cách tương đối tối đa giữa hai token bất kỳ đã được giảm từ L′ xuống L và PI giảm ảnh hưởng lên việc tính điểm attention khi mở rộng cửa sổ ngữ cảnh, và làm cho LLM dễ thích ứng hơn. Hơn nữa, chúng ta định nghĩa tham số tỷ lệ g là L′/L. Ví dụ, g được đặt là 2 khi L′ = 8192 cho LLaMa2 với cửa sổ ngữ cảnh L = 4096. Do đó, Eq. 3 có thể được viết lại như sau:

f′(x, m) = f(x, m/g). (4)

Trong khi đó, đối với PI, chúng ta cần thu thập dữ liệu ngữ cảnh dài với độ dài tối đa L′ trong tinh chỉnh, và tinh chỉnh là cần thiết cho mỗi cửa sổ mở rộng với việc sử dụng bộ nhớ GPU cao như thể hiện trong Hình 1 (a).

## 4 Phương pháp

Trong phần này, chúng tôi giới thiệu chi tiết của E2-LLM trong Hình 1 (b) để mở rộng các kích thước cửa sổ ngữ cảnh khác nhau bằng cách chỉ thực hiện một quy trình huấn luyện trên dữ liệu độ dài ngắn, điều này giảm đáng kể chi phí tinh chỉnh. Đầu tiên, trong Mục 4.1, chúng tôi cung cấp các ký hiệu cần thiết. Sau đó, trong Mục 4.2.1, chúng tôi minh họa chi tiết chiến lược E2-LLM để cải thiện hiệu suất mở rộng độ dài bằng cách giới thiệu tăng cường trên tỷ lệ và các tham số offset vị trí của RoPE, trong đó các tham số này được định nghĩa trong Eq. 5. Cuối cùng, trong Mục 4.2.3, chúng tôi trình bày các quy trình huấn luyện và suy luận trong E2-LLM.

### 4.1 Ký hiệu

Ngoài các ký hiệu được định nghĩa trong Mục 3, chúng tôi cũng định nghĩa các ký hiệu sau. Đầu tiên, độ dài được huấn luyện được định nghĩa là R. Cần đề cập rằng R là độ dài tối đa của dữ liệu trong tinh chỉnh, được đặt là 8k trong E2-LLM theo mặc định. Do đó, việc thu thập dữ liệu huấn luyện với độ dài R rất dễ dàng và bộ nhớ GPU được sử dụng trong tinh chỉnh cũng có thể chấp nhận được. Ngược lại, độ dài được huấn luyện R bằng với độ dài mở rộng L′ (ví dụ: 16k/32k) trong nhiều phương pháp mở rộng ngữ cảnh dài (ví dụ: PI), đòi hỏi việc sử dụng bộ nhớ GPU cao trong huấn luyện. Thứ hai, chúng tôi cũng giới thiệu offset vị trí t trong RoPE, và chúng ta có thể viết lại Eq. 4 để tính embedding RoPE như sau:

f′(x, m) = f(x, (m+t)/g). (5)

Trong RoPE tiêu chuẩn, theo mặc định, t được đặt là 0. Trong E2-LLM, t được chọn từ một phạm vi chỉ số T={0, ..., tmax}, trong đó tmax là offset vị trí tối đa. Thứ ba, chúng tôi cũng định nghĩa một tập hợp các tham số tỷ lệ được sử dụng trong E2-LLM là G={1,2, ..., gmax}, trong đó gmax là tham số tỷ lệ tối đa.

### 4.2 E2-LLM

Trong phần này, chúng tôi mô tả chi tiết chiến lược E2-LLM được đề xuất. Chúng tôi lấy mô hình LLM H với cửa sổ ngữ cảnh mặc định L là 4.096 và độ dài được huấn luyện R là 4.096 để minh họa. Chúng tôi đề xuất hai phương pháp tăng cường khác nhau trên các siêu tham số (tức là tham số tỷ lệ g và offset vị trí t) của RoPE.

#### 4.2.1 Tăng cường trên g

Như thể hiện trong Hình 2, chúng tôi minh họa quy trình tăng cường trên tham số tỷ lệ g. Trong quá trình huấn luyện E2-LLM được đề xuất, để làm cho mô hình H bao phủ các mật độ vị trí khác nhau trong huấn luyện, đối với lần lặp thứ i, chúng tôi lấy mẫu tham số tỷ lệ gi từ G cho các lần lặp khác nhau theo phân phối xác suất được xác định trước P như sau:

gi = Sg(P, G), gi ∈ G, (6)

trong đó Sg(P, G) biểu thị phép toán lấy mẫu trên g, lấy mẫu gi từ tập G theo phân phối P. Do đó, các tham số tỷ lệ khác nhau được sử dụng cho các lần lặp khác nhau. Lưu ý rằng P dựa trên phân phối đều theo mặc định.

Trong Hình 2, chúng tôi đặt offset vị trí t là 0, và sau đó chọn ngẫu nhiên tham số tỷ lệ g từ G cho mỗi mẫu dựa trên Eq. 5, trong đó g được đặt là 2, 5 và 10 tương ứng. Bên cạnh đó, như thể hiện trong Hình 2, chúng tôi quan sát thấy rằng các cửa sổ ngữ cảnh tối đa được nội suy khác nhau cho các mẫu khác nhau trong huấn luyện, và mật độ của các chỉ số vị trí được huấn luyện khác nhau. Ví dụ, các cửa sổ ngữ cảnh nội suy được nội suy là 8.192 và 20.480 khi g là 2 và 5 tương ứng. Hơn nữa, vì cửa sổ ngữ cảnh huấn luyện R ít hơn các cửa sổ ngữ cảnh tối đa được nội suy, chỉ một tỷ lệ nhất định các chỉ số vị trí được huấn luyện, được hiển thị bằng màu xanh trong Hình 2.

![Hình 2: Các chỉ số vị trí được huấn luyện (điểm xanh) khi sử dụng các tham số tỷ lệ khác nhau]

#### 4.2.2 Tăng cường trên t

Như thể hiện trong Hình 2, chúng tôi quan sát thấy rằng chúng ta chỉ có thể tập trung vào một phạm vi nhỏ các chỉ số vị trí khi chúng ta bắt đầu từ chỉ số không (tức là t = 0). Do đó, để cải thiện khả năng mạnh mẽ và tổng quát hóa của E2-LLM, chúng tôi tiếp tục giới thiệu quy trình tăng cường trên offset vị trí t bằng cách thay đổi các chỉ số vị trí tuyệt đối của RoPE. Bên cạnh đó, lấy cảm hứng từ một số công trình gần đây (Han et al., 2023; Xiao et al., 2023), những công trình khẳng định rằng một lượng lớn điểm attention được phân bổ cho các token ban đầu (tức là attention sinks (Xiao et al., 2023)), chúng tôi cũng giữ một số token ban đầu và đặt offset vị trí của các token này là 0. Đối với các chỉ số vị trí khác, trong lần lặp huấn luyện thứ i, chúng tôi đặt offset vị trí t cho các chỉ số vị trí khác nhau của cửa sổ được huấn luyện như sau:

ti = {
  0, m ∈ [0,3]
  St(Q, T), m ∈ (3, R)
}, (7)

trong đó St(Q, T) biểu thị phép toán lấy mẫu trên t, và lấy mẫu ti từ tập T theo phân phối xác suất được xác định trước Q. Lưu ý rằng Q được đặt là phân phối đều và tmax được đặt là sự khác biệt giữa cửa sổ ngữ cảnh nội suy tối đa và cửa sổ ngữ cảnh được huấn luyện trong lần lặp hiện tại. Dựa trên Eq. 7, đối với n∈[0,3] và m∈(3, R), Eq. 2 có thể được viết như sau:

a(m, n) = Re ⟨f(q, m+ti),f(k, n+ti)⟩ =: a(m+St(Q, T)−n). (8)

Do đó, khi St(Q, T) lớn hơn, phạm vi các khác biệt vị trí tương đối (tức là (m+St(Q, T)−n)) giữa m và n lớn hơn, điều này sẽ làm cho mô hình tổng quát hóa đến các phạm vi khác nhau của các khác biệt vị trí tương đối.

Trong Hình 3, chúng tôi cũng cung cấp các chỉ số vị trí được huấn luyện (tức là điểm xanh) khi giới thiệu tăng cường trên offset vị trí t, và quan sát thấy rằng E2-LLM có thể dễ dàng sử dụng các chỉ số vị trí với các giá trị tuyệt đối khác nhau và các phạm vi khác nhau của các khác biệt tương đối.

![Hình 3: Các chỉ số vị trí được huấn luyện (điểm xanh) khi sử dụng các offset vị trí khác nhau]

#### 4.2.3 Huấn luyện và Suy luận

Như đã thảo luận trong Mục 1, quy trình huấn luyện được thực hiện một lần cho E2-LLM, và chúng ta có thể mở rộng đến các cửa sổ ngữ cảnh đánh giá khác nhau một cách dễ dàng khi suy luận. Chi tiết như sau.

**Huấn luyện.** Trong huấn luyện, đầu tiên, đối với lần lặp thứ i, dựa trên gi và offset vị trí ti trong huấn luyện, chúng tôi thay thế g và t bằng gi và ti cho Eq. 5 tương ứng. Sau đó, chúng tôi tinh chỉnh LLM H với cửa sổ ngữ cảnh ngắn R sử dụng tác vụ dự đoán token tiếp theo với mã hóa vị trí được sửa đổi trên cửa sổ ngữ cảnh được huấn luyện. Để làm rõ hơn, chúng tôi cũng cung cấp một thuật toán của phương pháp E2-LLM được đề xuất trong Thuật toán 1.

**Suy luận.** E2-LLM của chúng tôi cũng không giới thiệu trọng số huấn luyện bổ sung hoặc sửa đổi kiến trúc mạng theo bất kỳ cách nào, có nghĩa là nó hấp dẫn trong các ứng dụng thực tế vì hầu hết cơ sở hạ tầng và tối ưu hóa cho mô hình ban đầu có thể được tái sử dụng sau khi mở rộng độ dài. Khi suy luận, chúng ta có thể mở rộng đến các cửa sổ ngữ cảnh khác nhau bằng cách đặt các tham số tỷ lệ khác nhau cho nội suy một cách dễ dàng. Ví dụ, chúng tôi đặt g = 8 để nội suy đến 32.768 và g = 16 để nội suy đến 65.536, được gọi là E2-LLM-32k và E2-LLM-64k tương ứng. Cần đề cập rằng trọng số của E2-LLM-32k và E2-LLM-64k giống nhau khi suy luận, và sự khác biệt duy nhất là các tham số tỷ lệ được đặt là 8 và 16 tương ứng. Hơn nữa, trong thực tế, chúng ta chỉ có thể triển khai một LLM trên thiết bị và tự động thay đổi tham số tỷ lệ của RoPE dựa trên độ dài của ngữ cảnh đầu vào để hỗ trợ các cửa sổ ngữ cảnh khác nhau.

**Thuật toán 1: Huấn luyện E2-LLM**
```
Đầu vào: Mô hình LLM được huấn luyện trước H với cửa sổ ngữ cảnh mặc định L (ví dụ: 4k); Cửa sổ ngữ cảnh được huấn luyện là R (ví dụ: 4k/8k); Cửa sổ ngữ cảnh đánh giá L′ (ví dụ: 32k/64k);
1: cho lần lặp thứ i trong huấn luyện thực hiện
2:   Đặt tỷ lệ gi dựa trên Eq. 6;
3:   Đặt offset vị trí ti dựa trên Eq. 7;
4:   Sửa đổi embedding vị trí RoPE dựa trên Eq. 5;
5:   Huấn luyện mô hình H trên cửa sổ huấn luyện R;
6:   Tính loss dự đoán token tiếp theo;
7:   Cập nhật tham số của mô hình H;
8: kết thúc cho
Đầu ra: Mô hình ngữ cảnh dài được tối ưu H′. (Lưu ý rằng H′ có thể mở rộng đến các cửa sổ ngữ cảnh khác nhau khi suy luận.);
```

## 5 Thực nghiệm

### 5.1 Thiết lập Thực nghiệm

**Mô hình.** Trong E2-LLM, chúng tôi lấy các mô hình Llama2 (Touvron et al., 2023b) được huấn luyện trước 7B, 13B để chứng minh hiệu quả của E2-LLM.

**Quy trình Huấn luyện.** Tất cả các mô hình được tinh chỉnh thông qua mục tiêu dự đoán token tiếp theo dựa trên hai máy GPU 8×A100. Chúng tôi sử dụng AdamW (Loshchilov và Hutter, 2019) với β1 = 0.9 và β2 = 0.95. Tốc độ học được đặt thành 1×10−5 cho các mô hình 7B và 13B, và toàn bộ bước huấn luyện được đặt thành 30.000 với kích thước batch toàn cục là 16.

**Bộ dữ liệu.** Bộ dữ liệu huấn luyện bao gồm bộ dữ liệu huấn luyện trước (tức là Pile (Gao et al., 2020)) và bộ dữ liệu tinh chỉnh (tức là ShareGPT (Zheng et al., 2023) và bộ dữ liệu tóm tắt dài (Cohan et al., 2018)). Lưu ý rằng các bộ dữ liệu tinh chỉnh được sử dụng để cải thiện khả năng hỏi-đáp của LLM ngữ cảnh dài theo các mô hình Vicuna và LongChat (Zheng et al., 2023) và tạo ra kết quả hợp lý trên LongBench. Chúng tôi đánh giá hiệu suất mô hình hóa ngôn ngữ chuỗi dài của các mô hình được tinh chỉnh trên LongBench (Bai et al., 2023) và bộ dữ liệu arxiv proof-pile (Azerbayev et al., 2022).

### 5.2 Kết quả trên LongBench

Chúng tôi đánh giá một số LLM phổ biến với khả năng ngữ cảnh dài, bao gồm GPT-3.5-Turbo-16k (OpenAI, 2022), Llama2-7B-chat-4k (Touvron et al., 2023b), LongChat-v1.5-7B-32k (Li et al., 2023), Vicuna-v1.5-7B-16k (Zheng et al., 2023), Longlora-7B-16k (Chen et al., 2023b), Llama2-13B-chat-4k (Touvron et al., 2023b), Vicuna-v1.5-13B-16k (Zheng et al., 2023), PI-Llama2-13B-16k. LongChat-v1.5-7B-32k, Vicuna-v1.5-7B-16k và LongLora-7B-16k được tinh chỉnh từ Llama2-7B dựa trên PI. Vicuna-v1.5-13B-16k (Zheng et al., 2023), PI-Llama2-13B-16k được tinh chỉnh với Llama2-13B dựa trên PI, trong đó PI-Llama2-13B-16k được tinh chỉnh với các bộ dữ liệu được xây dựng của chúng tôi.

Theo LongBench (Bai et al., 2023), chúng tôi tiến hành đánh giá trong thiết lập zero-shot, ngoại trừ các tác vụ học few-shot trong đó các ví dụ few-shot được cung cấp như một phần của ngữ cảnh dài. Khi độ dài đầu vào I vượt quá độ dài ngữ cảnh tối đa L′ của một mô hình (được biểu thị bằng hậu tố của tên nó), chúng tôi cắt chuỗi đầu vào S từ giữa vì phần đầu và cuối của chuỗi có thể chứa thông tin quan trọng như hướng dẫn hoặc câu hỏi: S1:I→[S1:⌊L′/2⌋;SI−⌊L′/2⌋−1:I]. Thước đo cho mỗi bộ dữ liệu được hiển thị trong Bảng 6 từ Phụ lục A.1.

Như thể hiện trong Bảng 1 và Bảng 2, chúng tôi báo cáo kết quả hiệu suất (%) trên bộ dữ liệu LongBench. Cụ thể, các phát hiện chính từ kết quả thực nghiệm như sau: (1) Khi so sánh với mô hình thương mại (GPT-3.5-Turbo-16k) với độ chính xác tổng thể 44.60% bằng tiếng Anh, E2-LLM-Llama2-13B-32k của chúng tôi đạt kết quả gần với độ chính xác tổng thể 44.55%. (2) Trong Bảng 1 và Bảng 2, chúng tôi cũng đánh giá kết quả của E2-LLM với các kích thước cửa sổ ngữ cảnh đánh giá khác nhau (tức là 16k và 32k), và chúng tôi quan sát thấy rằng kết quả hiệu suất tốt hơn khi chúng tôi mở rộng kích thước cửa sổ ngữ cảnh đánh giá. Bên cạnh đó, vì độ dài của hầu hết tài liệu trong LongBench ít hơn 16k, các cải thiện trên các tác vụ này không đáng kể khi chúng tôi tăng cửa sổ ngữ cảnh đánh giá. (3) Để so sánh công bằng, chúng tôi cũng triển khai lại phương pháp nội suy vị trí dựa trên Llama2-13B (tức là PI-Llama2-13B-16k) với cùng chiến lược huấn luyện và bộ dữ liệu huấn luyện. Khi so sánh với PI-Llama2-13B-16k, E2-LLM-Llama2-13B-16k của chúng tôi vẫn đạt được cải thiện đáng kể trên LongBench, điều này tiếp tục chứng minh hiệu quả của E2-LLM.

[Bảng 1 và 2 có chứa kết quả chi tiết được dịch đầy đủ]

### 5.3 Kết quả trên Proof-Pile

Trên bộ dữ liệu Arxiv Math proof-pile đã được làm sạch (Azerbayev et al., 2022), chúng tôi đánh giá hiệu suất mô hình hóa ngôn ngữ chuỗi dài của các mô hình mở rộng và phương pháp cơ sở (tức là Vicuna-v1.5-16k và LongChat-v1.5-32k), trong đó kết quả perplexity được báo cáo. Đối với bộ dữ liệu proof-pile, chúng tôi lấy mẫu ngẫu nhiên 128 tài liệu với ít nhất 64k token và đánh giá perplexity được tính của mỗi mẫu này. Tất cả các đánh giá perplexity được tính bằng phương pháp cửa sổ trượt từ (Press et al., 2022) với S = 256. Cụ thể, Vicuna-v1.5-16k và LongChat-v1.5-32k được tinh chỉnh trên mô hình Llama2 và phương pháp chia tỷ lệ RoPE tuyến tính, dựa trên Position Interpolation (tức là PI) (Chen et al., 2023a). Trong Bảng 3, chúng tôi thấy rằng các mô hình được mở rộng bằng phương pháp của chúng tôi có perplexity được cải thiện đáng kể từ kích thước cửa sổ ngữ cảnh dài hơn khi so sánh với các phương pháp cơ sở khác. Bên cạnh đó, đối với các phương pháp khác, cửa sổ ngữ cảnh huấn luyện bằng với cửa sổ ngữ cảnh đánh giá tối đa, do đó chi phí huấn luyện rất lớn khi kích thước cửa sổ lớn, trong đó chi phí huấn luyện được hiển thị trong Hình 1. Ngược lại, E2-LLM của chúng tôi chỉ cần huấn luyện các mô hình Llama một lần và cửa sổ ngữ cảnh huấn luyện ngắn, điều này giảm đáng kể chi phí huấn luyện.

### 5.4 Nghiên cứu Khử yếu tố

**Hiệu quả của các chiến lược tăng cường.** Trong Bảng 4, chúng tôi cung cấp hai biến thể thay thế của E2-LLM (tức là E2-LLM (w/o aug on t), E2-LLM (w/o aug on g)) để huấn luyện mô hình cơ sở LLama2-13B. Cụ thể, đối với E2-LLM (w/o aug on t), chúng tôi chỉ sử dụng tăng cường trên tham số tỷ lệ g mà không sử dụng tăng cường trên offset vị trí t, và chúng tôi đánh giá hiệu suất bằng cách mở rộng cửa sổ ngữ cảnh thành 32k. Đối với E2-LLM (w/o aug on g), chúng tôi chỉ sử dụng tăng cường trên offset vị trí t và cố định tham số tỷ lệ g là 2 với cửa sổ ngữ cảnh huấn luyện 8k trong E2-LLM. Lưu ý rằng cửa sổ ngữ cảnh đánh giá của E2-LLM (w/o aug on g) cũng được đặt là 8k. Như thể hiện trong Bảng 4, E2-LLM của chúng tôi tốt hơn hai biến thể thay thế này trên LongBench, cho thấy rằng việc thực hiện tăng cường trên t và g là có lợi.

**Hiệu quả của số bước tinh chỉnh.** Như thể hiện trong Hình 4, chúng tôi báo cáo mối quan hệ giữa kết quả trên bộ dữ liệu LongBench và số bước tinh chỉnh cho mô hình LLaMA2 13B sử dụng E2-LLM, trong đó kết quả được báo cáo trên kích thước cửa sổ đánh giá 32k. Trong Hình 4, ở 5k lần lặp đầu tiên, kết quả cải thiện nhanh chóng, cho thấy rằng các mô hình có thể đạt được khả năng hiểu ngữ cảnh dài mà không cần quy trình huấn luyện dài. Hơn nữa, khi tăng các lần lặp huấn luyện, chúng tôi quan sát thấy rằng kết quả hiệu suất của LongBench vẫn có thể tăng đều đặn sau 5k lần lặp.

**Hiệu quả của tham số tỷ lệ tối đa Gmax.** Trong Bảng 5, trên bộ dữ liệu LongBench, chúng tôi cũng báo cáo kết quả của E2-LLM dựa trên mô hình Llama2-13B để phân tích hiệu quả của tham số tỷ lệ tối đa Gmax trong huấn luyện, và cửa sổ ngữ cảnh đánh giá được đặt là 32k. Khi Gmax tăng từ 5 lên 20, kết quả hiệu suất trên Longbench tốt hơn, cho thấy rằng việc bao phủ các mật độ khác nhau bằng cách sử dụng Gmax lớn trong E2-LLM là hiệu quả. Tuy nhiên, khi chúng tôi tiếp tục tăng tham số tỷ lệ tối đa Gmax, cải thiện hiệu suất trở nên tương đối ổn định trên LongBench. Do đó, chúng tôi trực tiếp đặt Gmax là 20 để hỗ trợ cửa sổ mở rộng tối đa 80k.

### 5.5 Phân tích Sâu hơn

**Mở rộng đến các tỷ lệ chưa thấy.** Theo mặc định, chúng tôi đặt Gmax là 20 để hỗ trợ cửa sổ ngữ cảnh nội suy tối đa 80K. Trong Hình 5, các tỷ lệ nội suy được điều chỉnh thực nghiệm thành 20, 30, 40 và 50 trong suy luận để đánh giá khả năng tổng quát hóa của E2-LLM. Kết quả chứng minh rằng PPL duy trì mức độ thỏa mãn cho các ngữ cảnh gồm ít hơn 120K token. Tuy nhiên, khi chúng ta tiếp tục tăng tỷ lệ, sự suy giảm hiệu suất có thể nhận thấy xảy ra. Điều này cho thấy rằng E2-LLM có khả năng tổng quát hóa mạnh mẽ cho các tỷ lệ chưa thấy hoặc OOD trong một phạm vi nhất định.

**Trực quan hóa trên Bản đồ Attention.** Để phân tích thêm hiệu quả của E2-LLM, chúng tôi trực quan hóa các bản đồ nhiệt attention trong lớp cho E2-LLM-8k, E2-LLM-16k, E2-LLM-32k và E2-LLM-64k dựa trên Llama2-13B trong Hình 6 với các cửa sổ ngữ cảnh đánh giá 8k, 16k, 32k và 64k bằng cách đặt tham số tỷ lệ là 2, 4, 8, 16 tương ứng. Cụ thể, như thể hiện trong Hình 6, tọa độ dọc biểu thị các chỉ số của token chuỗi được tạo, và tọa độ ngang biểu thị các chỉ số của token chuỗi đầu vào. Văn bản đầu vào là một phần của một bài báo dài, được cắt thành 16k, 32k và 64k tương ứng. Sau đó, ba cặp key-value ngẫu nhiên được chèn vào văn bản đầu vào, và một câu hỏi được thêm vào cuối văn bản. Lưu ý các cặp key-value ngẫu nhiên và câu hỏi được hiển thị trong Phụ lục A.2. Câu hỏi đã được trả lời chính xác cho 8k, 16k, 32k và 64k. Trong Hình 6, chúng tôi trực quan hóa các bản đồ nhiệt attention của chuỗi đầu ra tương ứng với đầu vào. Các chỉ số ground-truth của các giá trị tương ứng với các key được hỏi trong 8k, 16k, 32k và 64k lần lượt là [4470, 4503], [9572, 9605], [15891, 15924] và [37958, 37991], và chúng tôi quan sát thấy rằng các giá trị attention của chuỗi đầu ra tại các vị trí này rất đáng kể, biểu thị rằng E2-LLM có thể lập chỉ mục tốt vị trí chính xác khi tạo ra các phản hồi.

## 6 Kết luận

Trong nghiên cứu này, chúng tôi giới thiệu một phương pháp mở rộng độ dài Hiệu quả và Cực đại cho LLM, có tên E2-LLM, được thiết kế để mở rộng các cửa sổ ngữ cảnh với một giai đoạn huấn luyện duy nhất và chi phí tính toán tối thiểu. Đáng chú ý, trong E2-LLM, không có yêu cầu tích lũy các bộ dữ liệu ngữ cảnh dài mở rộng (ví dụ: mẫu với 32k hoặc 64k token) để huấn luyện. Cụ thể, E2-LLM của chúng tôi khai thác embedding vị trí dựa trên RoPE để triển khai một cặp chiến lược tăng cường mới điều chỉnh các tham số tỷ lệ và chỉ số vị trí trên các mẫu huấn luyện khác nhau với độ dài ngắn (ví dụ: 4k/8k). Kết quả thực nghiệm toàn diện trên nhiều bộ dữ liệu benchmark chứng minh hiệu quả của E2-LLM trên các tác vụ ngữ cảnh dài.

## 7 Hướng Nghiên cứu Tương lai

Đối với các hướng tương lai, chúng tôi có ba kế hoạch như sau: (1) vì E2-LLM hiệu quả và hiệu suất và chúng tôi sẽ cố gắng áp dụng E2-LLM trên các mô hình lớn hơn (ví dụ: LLama2 70B) và các cửa sổ ngữ cảnh lớn hơn (ví dụ: 128k/192k); (2) chúng tôi tin rằng E2-LLM là một phương pháp tổng quát và chúng tôi sẽ cố gắng áp dụng E2-LLM trên nhiều loại mã hóa vị trí và nhiều loại LLM hơn; (3) chúng tôi sẽ phát hành các mô hình và mã của chúng tôi.

## Tài liệu tham khảo

[Tài liệu tham khảo được dịch đầy đủ theo cấu trúc gốc...]

## Phụ lục A: Chi tiết Bổ sung

### A.1 Chi tiết thêm về bộ dữ liệu LongBench
Chi tiết được hiển thị trong Bảng 6.

### A.2 Chi tiết thêm về trực quan hóa bản đồ attention
Ba cặp key-value ngẫu nhiên và câu hỏi đầu vào được hiển thị như sau:

**Ngữ cảnh Đầu vào**
Các cặp key-value: Trích xuất giá trị tương ứng với key được chỉ định trong đối tượng JSON bên dưới. {"2a8d601d-1d69-4e64-9f90-8ad825a74195": "bb3ba2a5-7de8-434b-a86e-a88bb9fa7289", "9f4a92b9-5f69-4725-ba1e-403f08dea695": "703a7ce5-f17f-4e6d-b895-5836ba5ec71c", "52a9c80c-da51-4fc9-bf70-4a4901bc2ac3": "b2f8ea3d-4b1b-49e0-a141-b9823991ebeb"}

**Câu hỏi:** Giá trị của key "9f4a92b9-5f69-4725-ba1e-403f08dea695" là gì?

### A.3 Kết quả thêm trên các bộ dữ liệu độ dài ngắn
[Nội dung được dịch đầy đủ...]

### A.4 Mở rộng trên E2-LLM của chúng tôi
[Nội dung được dịch đầy đủ...]

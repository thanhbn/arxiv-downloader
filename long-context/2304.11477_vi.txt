# LLM+P: Trao quyền cho các Mô hình Ngôn ngữ Lớn
với Khả năng Lập kế hoạch Tối ưu
Bo Liu∗†, Yuqian Jiang∗†, Xiaohan Zhang‡, Qiang Liu†, Shiqi Zhang‡, Joydeep Biswas†, Peter Stone†§

Tóm tắt — Các mô hình ngôn ngữ lớn (LLM) đã chứng minh khả năng tổng quát hóa zero-shot đáng chú ý: các chatbot tiên tiến có thể cung cấp câu trả lời hợp lý cho nhiều câu hỏi thường gặp trong cuộc sống hàng ngày. Tuy nhiên, cho đến nay, LLM không thể giải quyết một cách đáng tin cậy các bài toán lập kế hoạch robot tầm xa. Ngược lại, các bộ lập kế hoạch cổ điển, một khi bài toán được đưa ra theo định dạng chuẩn, có thể sử dụng các thuật toán tìm kiếm hiệu quả để nhanh chóng xác định các kế hoạch đúng, hoặc thậm chí tối ưu. Trong nỗ lực để có được những điều tốt nhất của cả hai thế giới, bài báo này giới thiệu LLM+P, khung làm việc đầu tiên kết hợp các điểm mạnh của bộ lập kế hoạch cổ điển vào LLM. LLM+P nhận vào mô tả ngôn ngữ tự nhiên của một bài toán lập kế hoạch, sau đó trả về một kế hoạch đúng (hoặc tối ưu) để giải quyết bài toán đó bằng ngôn ngữ tự nhiên. LLM+P thực hiện điều này bằng cách đầu tiên chuyển đổi mô tả ngôn ngữ thành một tệp được viết bằng ngôn ngữ định nghĩa miền lập kế hoạch (PDDL), sau đó tận dụng các bộ lập kế hoạch cổ điển để nhanh chóng tìm ra giải pháp, và cuối cùng dịch giải pháp tìm được trở lại ngôn ngữ tự nhiên. Cùng với LLM+P, chúng tôi định nghĩa một tập hợp đa dạng các bài toán chuẩn khác nhau được lấy từ các tình huống lập kế hoạch robot. Thông qua một tập hợp thực nghiệm toàn diện trên các bài toán chuẩn này, chúng tôi thấy rằng LLM+P có thể cung cấp giải pháp tối ưu cho hầu hết các bài toán, trong khi LLM thất bại trong việc cung cấp thậm chí các kế hoạch khả thi cho hầu hết các bài toán. Chúng tôi cũng cho thấy LLM+P cho phép một robot gia đình giải quyết một nhiệm vụ thao tác phức tạp được chỉ định bởi người dùng bằng ngôn ngữ tự nhiên.¹

I. GIỚI THIỆU

Từ khi lĩnh vực này ra đời, các nhà nghiên cứu AI đã tìm cách tạo ra các chương trình có thể trò chuyện bằng ngôn ngữ tự nhiên với sự duyên dáng và linh hoạt giống như con người. Trong khi ngay cả các mô hình tương đối đơn giản, như Eliza từ năm 1966 [1], có thể tạo ra phản hồi cho một số lời nhắc có vẻ hợp lý, việc tạo ra các lời nhắc phơi bày điểm yếu của chúng so với con người luôn tương đối dễ dàng - thiếu "hiểu biết" thực sự.

Trong khi các mô hình ngôn ngữ lớn (LLM) như GPT-4 [2] và ChatGPT [3] đã vượt xa kỳ vọng của chỉ vài năm trước, chúng không khác biệt trong khía cạnh này. Thực vậy, internet hiện tại tràn ngập các ví dụ về việc mọi người thích thú khi khiến ChatGPT tạo ra đầu ra mà ngay cả một đứa trẻ 5 tuổi cũng biết là không nên theo.

Xét cách LLM được thiết kế và huấn luyện, hiện tượng này không nên làm chúng ta ngạc nhiên. Chúng không được xây dựng cụ thể để thể hiện sự hiểu biết. Chúng được huấn luyện để tạo ra các chuỗi từ có thể hợp lý đối với con người khi có bối cảnh trước đó. Theo thuật ngữ của Mahowald et al. [4] LLM đã trở nên cực kỳ thành thạo trong năng lực ngôn ngữ học - biết cách nói; nhưng chúng không giỏi bằng trong năng lực chức năng - biết nói gì. Cụ thể, chúng có thể bị đánh lừa (tương đối) dễ dàng bằng cách, ví dụ, yêu cầu kết quả của một bài toán số học đơn giản không xuất hiện trong tập dữ liệu huấn luyện của chúng hoặc bằng cách yêu cầu giải pháp cho một bài toán lập kế hoạch mới đòi hỏi kiến thức về cách thế giới hoạt động.

Một Ví dụ Thất bại của GPT-4 trong Lập kế hoạch
Bài toán (P1): Bạn có 5 khối. Không thể đặt nhiều hơn một khối lên khối khác. b5 ở trên đỉnh b3. b4 ở trên đỉnh b2. b2 ở trên đỉnh b1. b3 ở trên đỉnh b4. b1 ở trên bàn. b5 rõ ràng. Cánh tay của bạn rỗng.

Mục tiêu của bạn là di chuyển các khối.
b1 nên ở trên đỉnh b2.
b3 nên ở trên đỉnh b5.
b4 nên ở trên đỉnh b1.

GPT-4:
1. Di chuyển b5 từ b3 xuống bàn.
2. Di chuyển b3 từ b4 lên b5.
3. Di chuyển b4 từ b2 xuống bàn.
4. Di chuyển b2 từ b1 lên b5.
5. Di chuyển b1 từ bàn lên b2.
6. Di chuyển b4 từ bàn lên b1.

Điều đó có nghĩa là chúng ta nên tăng cường nỗ lực để bao gồm tất cả các bài toán số học và lập kế hoạch trong tập dữ liệu huấn luyện của chúng? Rõ ràng, đó là một nhiệm vụ vô vọng. Mặt khác, tại sao lại cần thiết? Chúng ta đã có máy tính và các bộ lập kế hoạch tượng trưng đa năng được đảm bảo tạo ra câu trả lời đúng. Do đó, một cách tiếp cận thay thế tự nhiên, và một cách mà chúng tôi thừa nhận không phải là người đầu tiên khám phá, là kết nối LLM với các công cụ như vậy.

Với động lực này trong tâm trí, mục tiêu của nghiên cứu được báo cáo trong bài báo này là, lần đầu tiên, cho phép LLM giải quyết các bài toán lập kế hoạch một cách chính xác. Chúng tôi nhằm mục đích thực hiện điều này mà không thay đổi bản thân LLM, ngay cả với fine-tuning [5], [6]. Thay vào đó, chúng tôi giới thiệu một phương pháp luận, được gọi là LLM+P, theo đó, khi được đặt một mô tả ngôn ngữ tự nhiên về bài toán lập kế hoạch, LLM:

1) xuất ra mô tả bài toán phù hợp làm đầu vào cho một bộ lập kế hoạch đa năng;
2) giải quyết bài toán bằng bộ lập kế hoạch đa năng; và
3) chuyển đổi đầu ra của bộ lập kế hoạch trở lại ngôn ngữ tự nhiên (hoặc kết nối với các bộ thực thi hành động của robot).

Các đánh giá thực nghiệm rộng rãi của chúng tôi chỉ ra rằng LLM+P có thể tạo ra giải pháp đúng cho nhiều bài toán lập kế hoạch hơn so với chỉ LLM một mình. Trong khi được chứng minh trong bài báo này trên các bài toán lập kế hoạch, phương pháp luận chung này có thể được áp dụng cho bất kỳ lớp bài toán nào mà chúng ta có bộ giải quyết âm thanh và hoàn chỉnh, chẳng hạn như các bài toán số học (bằng cách tận dụng máy tính).

Giới hạn: Trong bài báo này, chúng tôi không yêu cầu LLM nhận ra rằng nó đã được đặt một lời nhắc phù hợp để xử lý bằng pipeline LLM+P được đề xuất. Một hướng nghiên cứu tương lai có giá trị sẽ là xem xét việc nhận ra khi nào một lời nhắc nên được xử lý bởi LLM+P.

II. NỀN TẢNG

Phần này giới thiệu ký hiệu chúng tôi sử dụng để biểu diễn bài toán lập kế hoạch được giải quyết bởi LLM, và tóm tắt lại biểu diễn chuẩn của các bộ lập kế hoạch cổ điển.

A. Bài toán Lập kế hoạch Cổ điển

Chính thức, đầu vào của bài toán lập kế hoạch P được định nghĩa bởi một bộ ⟨S, sinit, SG, A, f⟩:

• S là một tập hợp hữu hạn và rời rạc các trạng thái được sử dụng để mô tả trạng thái của thế giới (tức là không gian trạng thái). Chúng tôi giả định một không gian trạng thái được phân tách sao cho mỗi trạng thái s ∈ S được định nghĩa bởi các giá trị của một tập hợp cố định các biến.

• sinit ∈ S là trạng thái thế giới ban đầu.

• SG ⊂ S là một tập hợp các trạng thái mục tiêu. SG thường được chỉ định như một danh sách các điều kiện mục tiêu, tất cả phải đúng trong một trạng thái mục tiêu.

• A là một tập hợp các hành động tượng trưng.

• f là hàm chuyển đổi trạng thái cơ bản. f nhận trạng thái hiện tại và một hành động làm đầu vào và xuất ra trạng thái tiếp theo tương ứng.

Một giải pháp cho bài toán lập kế hoạch P là một kế hoạch tượng trưng π dưới dạng ⟨a1, a2, ..., aN⟩, sao cho các điều kiện tiên quyết của a1 đúng trong sinit, các điều kiện tiên quyết của a2 đúng trong trạng thái tạo ra từ việc áp dụng a1, và cứ thế, với tất cả các điều kiện mục tiêu đúng trong trạng thái tạo ra sau khi áp dụng aN.

B. Ngôn ngữ Định nghĩa Miền Lập kế hoạch (PDDL)

Ngôn ngữ định nghĩa miền lập kế hoạch (PDDL) phục vụ như một mã hóa chuẩn hóa của các bài toán lập kế hoạch cổ điển [7], [8]. Biểu diễn PDDL của bài toán lập kế hoạch P được chia thành hai tệp: một tệp miền và một tệp bài toán. Tệp PDDL miền cung cấp biểu diễn nâng cao của các quy tắc cơ bản của thế giới. Nó bao gồm một tập hợp các vị từ định nghĩa không gian trạng thái S và các hành động (tức là A) với các điều kiện tiên quyết và hiệu ứng của chúng (tức là hàm chuyển đổi f). Tệp PDDL bài toán cung cấp danh sách các đối tượng để cụ thể hóa miền, trạng thái ban đầu sinit của bài toán và các điều kiện mục tiêu SG. Tồn tại một tập hợp phong phú các bộ lập kế hoạch tượng trưng thực hiện các thuật toán tìm kiếm hiệu quả để giải quyết các bài toán lập kế hoạch được hình thức hóa trong PDDL. Trong công việc này, chúng tôi nhằm mục đích nhận một lời nhắc ngôn ngữ tự nhiên mô tả trạng thái ban đầu sinit và các điều kiện mục tiêu SG, hình thức hóa nó trong PDDL, và tận dụng các bộ lập kế hoạch tượng trưng để xuất ra các kế hoạch đúng. Chúng tôi giả định các quy tắc miền có sẵn (Xem các giả định trong Phần III).

III. PHƯƠNG PHÁP

Phần này đầu tiên sử dụng một ví dụ chạy để điều tra các cách để hình thức hóa các lời nhắc lập kế hoạch trong PDDL và sau đó giới thiệu phương pháp LLM+P.

A. Mô hình Ngôn ngữ Lớn như một Người viết PDDL

LLM kém trong việc lập kế hoạch (hoặc suy luận tầm xa) [9] nhưng chúng giỏi trong việc mô tả và dịch các đầu vào văn bản, bao gồm việc viết lại các lời nhắc lập kế hoạch ở định dạng PDDL. Trực giác là chúng ta có thể xem PDDL như một ngôn ngữ khác với tiếng Anh, vậy việc viết lại các lời nhắc lập kế hoạch trong PDDL về cơ bản là một nhiệm vụ "dịch máy" mà LLM được biết là xuất sắc. Ở đây chúng tôi cung cấp một ví dụ về tệp bài toán PDDL được viết bởi GPT-4 mà không có bất kỳ kỹ thuật prompt nào. Như chúng ta thấy, tệp được tạo ra có vẻ có cú pháp PDDL đúng nhưng sử dụng một vị từ bịa đặt (empty) và thiếu điều kiện ban đầu rằng b1 ở trên bàn.

Một Ví dụ Tệp Bài toán PDDL Được viết bởi GPT-4
Prompt: Mô tả Bài toán (P1) + Cung cấp cho tôi tệp PDDL bài toán mô tả bài toán lập kế hoạch trực tiếp mà không có giải thích thêm.

GPT-4 (tệp PDDL bài toán được tạo):
(:objects b1 b2 b3 b4 b5 - block)
(:init (on b5 b3) (on b4 b2) (on b2 b1) (on b3 b4) (clear b5) (empty))
(:goal (and (on b1 b2) (on b3 b5) (on b4 b1)))

B. Học Trong ngữ cảnh

LLM được biết là có khả năng học trong ngữ cảnh mà không cần fine-tuning các tham số của chúng. Bằng học trong ngữ cảnh, chúng tôi có nghĩa là khả năng của LLM thực hiện các nhiệm vụ downstream chưa từng thấy bằng cách đơn giản điều kiện hóa trên một vài cặp đầu vào-nhãn (minh họa) [10]. Đây là một cặp mô tả bài toán bằng ngôn ngữ tự nhiên và trong PDDL được cung cấp cho GPT-4 như ngữ cảnh. Khi ngữ cảnh được bao gồm với prompt từ ví dụ trên, tệp bài toán PDDL kết quả có thể được giải quyết trực tiếp bởi bộ lập kế hoạch.

Một Ví dụ Tệp Bài toán PDDL Được viết bởi GPT-4 với Ngữ cảnh

Ngữ cảnh (được tô màu):
Một ví dụ bài toán lập kế hoạch là: Bạn có 5 khối. b2 ở trên đỉnh b5. b5 ở trên đỉnh b1. b1 ở trên đỉnh b4. b3 ở trên đỉnh b2. b4 ở trên bàn. b3 rõ ràng. Cánh tay của bạn rỗng. Mục tiêu của bạn là di chuyển các khối. b4 nên ở trên đỉnh b3. PDDL bài toán là:
(:objects b1 b2 b3 b4 b5)
(:init (arm-empty) (on b1 b4) (on b2 b5) (on b3 b2)
(on-table b4) (on b5 b1)
(clear b3))
(:goal (and (on b4 b3))))

Prompt: Mô tả Bài toán (P1) + Ngữ cảnh + Cung cấp cho tôi tệp PDDL bài toán mô tả bài toán lập kế hoạch trực tiếp mà không có giải thích thêm.

GPT-4 (tệp PDDL bài toán được tạo):
(:objects b1 b2 b3 b4 b5 )
(:init (arm-empty) (on-table b1)
(on b2 b1) (on b3 b4)
(on b4 b2) (on b5 b3) (clear
b5)))
(:goal (and (on b1 b2) (on b3 b5)
(on b4 b1)))

Bộ lập kế hoạch:
(unstack b5 b3) (putdown b5)
(unstack b3 b4) (stack b3 b5)
(unstack b4 b2) (putdown b4)
(unstack b2 b1) (putdown b2)
(pickup b1) (stack b1 b2) (pickup
b4) (stack b4 b1)

C. Mô hình Ngôn ngữ Lớn + Bộ lập kế hoạch Cổ điển (LLM+P)

Sau khi giới thiệu khả năng của LLM để mã hóa bài toán trong PDDL và học trong ngữ cảnh, chúng tôi sẵn sàng giới thiệu giải pháp LLM+P được đề xuất (phần dưới của Hình 1). Đặc biệt, chúng tôi giả định rằng đối với mỗi miền bài toán, một chuyên gia con người có thể cung cấp mô tả miền (tức là các điều kiện tiên quyết và hiệu ứng của hành động) sẽ được cố định cho tất cả các trường hợp bài toán xảy ra trong miền đó. Trong khi bài toán tự động tạo ra mô tả là một câu hỏi nghiên cứu có giá trị khác, trong công việc được đề xuất này, chúng tôi giả định rằng mô tả có sẵn như một tệp miền PDDL. Phương pháp LLM+P có thể áp dụng trực tiếp như một giao diện ngôn ngữ tự nhiên để giao nhiệm vụ cho các hệ thống robot. Ví dụ, giả sử chúng ta muốn một robot hoạt động như một người pha chế để làm cocktail. Hợp lý khi nói cho nó biết những hành động nó có thể thực hiện, nhưng để lại cho chính nó để suy ra cách làm cocktail mới một cách hiệu quả nhất khi có một tập hợp các thành phần để kết hợp. Hơn nữa, chúng tôi giả định tác nhân được cung cấp một ví dụ tối thiểu minh họa cái gì một ví dụ PDDL bài toán trông như thế nào cho một bài toán đơn giản bên trong miền đó. Tiếp theo, tác nhân được cung cấp một bài toán mới (có thể khá phức tạp) (P). LLM sau đó sử dụng học trong ngữ cảnh để suy ra tệp PDDL bài toán tương ứng với P. Một khi tệp PDDL bài toán được tạo ra, chúng tôi đưa nó vào bất kỳ bộ lập kế hoạch cổ điển nào, cùng với tệp miền PDDL được cung cấp, để tạo ra một kế hoạch PDDL [11]. Cuối cùng, LLM dịch kế hoạch PDDL trở lại ngôn ngữ tự nhiên để hoàn thành pipeline LLM+P.

Để tóm tắt, các giả định chúng tôi cần cho LLM+P là:
1) Một robot biết khi nào kích hoạt LLM+P dựa trên cuộc trò chuyện của nó với người dùng.
2) Một miền PDDL được cung cấp để định nghĩa các hành động mà robot có khả năng thực hiện. Đặc tả này là task-agnostic - các thực thể liên quan đến nhiệm vụ được chỉ định trong tệp PDDL bài toán được tạo bởi LLM.
3) Một mô tả bài toán đơn giản bằng ngôn ngữ tự nhiên và tệp PDDL bài toán tương ứng của nó cũng được cung cấp.

IV. CÔNG TRÌNH LIÊN QUAN

Phần này đầu tiên cung cấp tổng quan ngắn gọn về các thuật toán lập kế hoạch cổ điển. Sau đó nó tóm tắt các tiến bộ gần đây trong việc sử dụng các mô hình ngôn ngữ lớn cho các nhiệm vụ lập kế hoạch. Nó kết thúc với thảo luận về nghiên cứu gần đây về việc tăng cường LLM với các mô-đun bên ngoài.

A. Lập kế hoạch Cổ điển

Các kỹ thuật lập kế hoạch tự động (hoặc lập kế hoạch cổ điển) có thể được sử dụng để tính toán một chuỗi các hành động đạt được một mục tiêu đã cho [12], [13], [14]. Các thuật toán lập kế hoạch tự động đã được sử dụng rộng rãi trong các hệ thống robot. Shakey là robot đầu tiên được trang bị một thành phần lập kế hoạch, được xây dựng bằng STRIPS [15]. Một số kiến trúc lập kế hoạch đa năng trước đây cũng được chứng minh là hữu ích cho việc lập kế hoạch robot, như PRODIGY [16] và HTN [17]. Các hệ thống lập kế hoạch cổ điển gần đây được thiết kế cho robotics thường sử dụng ngôn ngữ mô tả miền lập kế hoạch (PDDL) hoặc lập trình tập hợp câu trả lời (ASP) như ngôn ngữ hành động cơ bản cho các bộ lập kế hoạch [18], [19], [20], [21]. Ví dụ, các nhà nghiên cứu đã sử dụng các thuật toán lập kế hoạch cổ điển để sắp xếp các hành động cho một robot di động làm việc trên các nhiệm vụ giao hàng [22], suy luận về các hành vi lái xe đô thị an toàn và hiệu quả cho xe tự hành [23], và lập kế hoạch các hành động cho một nhóm robot di động [24]. Lập kế hoạch nhiệm vụ và chuyển động (TAMP) là một khung lập kế hoạch phân cấp kết hợp lập kế hoạch cổ điển trong không gian rời rạc và lập kế hoạch chuyển động robot trong không gian liên tục [25], [26].

Hầu hết các phương pháp lập kế hoạch được đề cập ở trên đều yêu cầu các ngôn ngữ lập trình cụ thể cho miền như biểu diễn cơ bản của các bài toán và giải pháp của chúng. Mặt khác, LLM+P tận dụng LLM và phục vụ như một giao diện ngôn ngữ tự nhiên cho robot để giải quyết các nhiệm vụ lập kế hoạch phức tạp. Tính năng chính thúc đẩy chúng tôi sử dụng các hệ thống lập kế hoạch cổ điển như vậy là hầu hết các bộ lập kế hoạch này đều âm thanh và hoàn chỉnh, có nghĩa là chúng được đảm bảo đúng về mặt logic và sẽ xuất ra một kế hoạch nếu tồn tại. Nhiều cái cũng có thể tìm ra các kế hoạch tối ưu (ngắn nhất), ít nhất nếu được cho đủ thời gian.

B. Lập kế hoạch với Mô hình Ngôn ngữ Lớn

Nhiều mô hình ngôn ngữ lớn (LLM) khác nhau đã được phát triển trong những năm gần đây, như Bert [27], CodeX [28], Opt [29], GPT-3 [10], ChatGPT [30], GPT-4 [2], Llama [31], Llama2 [32], và PaLM [33]. Vì LLM được huấn luyện trước với một lượng lớn dữ liệu văn bản ngoại tuyến, chúng có thể nổi lên với khả năng tổng quát hóa zero-shot đáng ngạc nhiên, có thể được tận dụng cho các nhiệm vụ lập kế hoạch robot [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45]. Một số phương pháp gần đây đã thành công trong việc trích xuất kiến thức nhiệm vụ từ LLM để phân tách các lệnh hoặc hướng dẫn cho robot bằng ngôn ngữ tự nhiên. Ví dụ, công việc của Huang et al. cho thấy LLM có thể được sử dụng cho lập kế hoạch nhiệm vụ trong các miền gia đình bằng cách tăng cường các prompt một cách lặp đi lặp lại [38]. SayCan là một cách tiếp cận khác cho phép lập kế hoạch robot với các hàm khả năng để tính đến tính khả thi của hành động, nơi các yêu cầu dịch vụ được chỉ định bằng ngôn ngữ tự nhiên [34]. Vemprala et al. gần đây đã nghiên cứu cách ChatGPT có thể được áp dụng cho các miền robotics tổng quát [3].

Tuy nhiên, một nhược điểm chính của các LLM hiện tại là thiếu khả năng suy luận tầm xa cho các nhiệm vụ phức tạp (Xem [9], [46] và Phần 8.2 từ [2]). Cụ thể, đầu ra chúng tạo ra khi được trình bày với một nhiệm vụ như vậy thường không chính xác theo nghĩa là việc theo kế hoạch đầu ra sẽ không thực sự giải quyết được nhiệm vụ. Do đó, trong công việc này, chúng tôi tập trung vào việc giải quyết vấn đề này bằng cách tận dụng các tính chất của các bộ lập kế hoạch cổ điển. Tương tự, một số công việc gần đây cũng điều tra các cách tiếp cận để kết hợp lập kế hoạch cổ điển với LLM [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57]. Chúng sử dụng prompting hoặc fine-tuning để làm cho LLM có khả năng giải quyết các bài toán lập kế hoạch PDDL. Cải thiện khả năng lập kế hoạch tầm xa cũng đã được thực hiện bằng cách truy vấn LLM một cách lặp đi lặp lại, như được chứng minh trong Minecraft [58]. Ngược lại, chúng tôi không chỉ dựa vào LLM như người giải quyết bài toán, mà thích tận dụng lợi thế của cả bộ lập kế hoạch (tức là tạo ra các kế hoạch chính xác và tối ưu) và chính LLM (tức là tổng quát hóa 1-shot để dịch các mô tả bài toán ngôn ngữ tự nhiên thành PDDL).

C. Tăng cường LLM với Mô-đun Bên ngoài

Các phương pháp được phát triển gần đây đã cho thấy rằng hiệu suất của các nhiệm vụ downstream của LLM có thể được cải thiện bằng cách kết hợp chúng với các mô-đun bên ngoài. Ví dụ, WebGPT [59] là một phiên bản fine-tuned của GPT-3 bằng cách kết hợp kiến thức web để trả lời các câu hỏi mở. Lazaridou et al. nghiên cứu cách các công cụ tìm kiếm như Google có thể được sử dụng như các công cụ bên ngoài cho LLM [60]. MemPrompt [61] trình bày một hệ thống human-in-the-loop nơi một bộ nhớ ngày càng tăng của các lỗi và phản hồi người dùng được phục vụ như kinh nghiệm quá khứ thêm vào các prompt để trả lời các câu hỏi mới chính xác hơn. REPLUG [62] là một mô hình ngôn ngữ tăng cường retrieval khác coi mô hình ngôn ngữ như một hộp đen và tăng cường nó với một mô hình retrieval có thể điều chỉnh. Cụ thể, mọi người đã điều tra việc sử dụng máy tính cho tính toán [63], [64]. Trong công việc gần đây liên quan đến chúng tôi, Schick et al. đã huấn luyện một mô hình gọi là ToolFormer có thể quyết định khi nào và cách gọi các API công cụ nhất định bằng cách tăng cường in-line trên các prompt cho LLM [65]. Trong công việc này, chúng tôi đề xuất rằng các bộ lập kế hoạch cổ điển có thể là một mô-đun bên ngoài đặc biệt hữu ích khác. So sánh, LLM+P không dựa vào bất kỳ fine-tuning hoặc huấn luyện lại LLM nào. Bằng cách đơn giản kết hợp kiến thức từ các bộ lập kế hoạch cổ điển, LLM+P kết hợp khả năng suy luận và lập kế hoạch tầm xa vào các LLM hiện tại.

Các tác giả được thông báo rằng một công việc đồng thời [66] trình bày kết quả sơ bộ về việc tích hợp LLM với PDDL bằng dataset SayCan [34]. Tuy nhiên, dataset SayCan có phạm vi hạn chế, vì nó chỉ chứa ba hành động được định nghĩa trước. Do đó, tất cả các biến thể mô hình được đánh giá trong bài báo gốc đạt được tỷ lệ thành công khoảng 90%. Do tính đồng nhất của dataset SayCan, Lyu et al. không cần thiết một định nghĩa nghiêm ngặt của miền PDDL, có thể dẫn đến các kế hoạch không khả thi. Kết quả là, chúng tôi coi phương pháp LLM+P của mình như một điều tra toàn diện hơn về việc tăng cường LLM với khả năng lập kế hoạch tối ưu.

V. THỰC NGHIỆM

Chúng tôi tiến hành thực nghiệm để trả lời các câu hỏi này:
1) LLM-AS-P hoạt động tốt như thế nào? Đến mức độ nào các LLM và phương pháp suy luận dựa trên LLM tiên tiến có thể được sử dụng trực tiếp cho lập kế hoạch? (Hoàn toàn không)
2) LLM+P hoạt động tốt như thế nào so với LLM-AS-P? (Tốt hơn nhiều)
3) Ngữ cảnh đóng vai trò gì trong thành công của LLM+P? (Nó rất quan trọng)
4) LLM+P có thể giúp làm cho robot dịch vụ hiệu quả hơn trên các nhiệm vụ thực tế không? (Có)

A. Bài toán Chuẩn

Chúng tôi trình bày bảy miền lập kế hoạch robot được mượn từ các Cuộc thi Lập kế hoạch Quốc tế trước đây và 20 nhiệm vụ được tạo tự động cho mỗi miền [67]. Dưới đây là danh sách các miền lập kế hoạch, cùng với tóm tắt ngắn gọn về từng miền.

1) BLOCKSWORLD: Cho một tập hợp các đống khối trên bàn, một robot được giao nhiệm vụ sắp xếp lại chúng thành một cấu hình mục tiêu được chỉ định.

2) BARMAN: Một robot bartender được giao nhiệm vụ tạo cocktail cho đơn hàng của khách hàng, sử dụng các thành phần và container có sẵn.

3) FLOORTILE: Một tập hợp robot được giao nhiệm vụ sử dụng các mẫu màu sơn trên các gạch sàn. Robot có thể di chuyển xung quanh và thay đổi màu sắc nhưng không thể bước lên các gạch đã sơn.

4) GRIPPERS: Một tập hợp robot với hai grippers được giao nhiệm vụ di chuyển đối tượng giữa các phòng khác nhau.

5) STORAGE: Cho một tập hợp palăng, mục tiêu là nâng và thả thùng bằng palăng vào kho. Thùng ban đầu được lưu trữ ở các khu vực khác nhau và palăng có thể được di chuyển giữa các khu vực lưu trữ.

6) TERMES: Một robot được giao nhiệm vụ xây dựng các cấu trúc phức tạp bằng cách mang và đặt khối, và cũng leo lên chúng để có thể xây tháp.

7) TYREWORLD: Robot được giao nhiệm vụ thay lốp xe bị xẹp bằng cách, ví dụ, bơm lốp, siết chặt đai ốc, và di chuyển công cụ trở lại cốp khi hoàn thành, tất cả theo thứ tự đúng.

Đối với mỗi bài toán P, P đi kèm với mô tả ngôn ngữ tự nhiên và tệp PDDL bài toán chuẩn. Mỗi miền cũng bao gồm một mô tả bài toán ví dụ, tệp PDDL tương ứng, và mô tả kế hoạch, được sử dụng như ngữ cảnh trong các cách tiếp cận khác nhau. Chúng tôi giả định mỗi miền bài toán có tệp miền PDDL riêng được cung cấp bởi người dùng hoặc chuyên gia miền trước khi giải quyết bất kỳ bài toán lập kế hoạch nào trong miền đó. Dataset này được công khai trong codebase của chúng tôi để có thể tái tạo.

B. Thiết lập Thực nghiệm

Chúng tôi tận dụng mô hình GPT-4 được cung cấp bởi OpenAI² cho tất cả các thực nghiệm. Chúng tôi đặt nhiệt độ thành 0, và sử dụng phản hồi xác suất cao nhất. Kết quả là, phản hồi trả về từ LLM là xác định. Một khi phản hồi PDDL văn bản được tạo ra, chúng tôi đưa nó vào bộ lập kế hoạch FAST-DOWNWARD³ và thử cả hai bí danh SEQ-OPT-FDSS-1 (đảm bảo tối ưu) và LAMA (không đảm bảo tối ưu) với thời gian tìm kiếm tối đa là 200 giây. Chúng tôi báo cáo tỷ lệ thành công của bí danh tối ưu, và đối với các miền hết thời gian, chúng tôi hiển thị tỷ lệ thành công của bí danh không tối ưu trong ngoặc. Đối với các phương pháp baseline, chúng tôi đếm thủ công số lượng kế hoạch tối ưu, và báo cáo số lượng kế hoạch đúng trong ngoặc (nếu có bất kỳ kế hoạch không tối ưu nào).

Chúng tôi cũng đánh giá một cách tiếp cận dựa trên LLM gần đây cho suy luận có chủ ý được gọi là Tree of Thoughts [68], được gọi là LLM-AS-P (TOT). Chúng tôi điều chỉnh thuật toán breadth-first-search từ implementation ToT gốc⁴ cho lập kế hoạch. LLM được nhắc để mở rộng cây tìm kiếm từ các hành động được phép và đánh giá các đường dẫn về khả năng đạt được mục tiêu của chúng. Cùng giới hạn thời gian 200 giây được áp dụng.

C. Kết quả và Phân tích

Kết quả áp dụng LLM-AS-P và LLM+P trên 7 miền được cung cấp trong Bảng I.

[THIS IS TABLE:
Miền           Tỷ lệ Thành công %
               LLM− LLM LLMToT LLM+P− LLM+P
BARMAN         0    0   0      0       20 (100)
BLOCKSWORLD    20   15(30) 0(5) 0      90
FLOORTILE      0    0   0      0       0
GRIPPERS       25(60) 35(50) 10(20) 0  95 (100)
STORAGE        0    0(25) 0   0       85
TERMES         0    0   0      0       20
TYREWORLD      5    15  0      0       10 (90)]

BẢNG I: Tỷ lệ thành công % của việc áp dụng LLM-AS-P không có ngữ cảnh (LLM−), LLM-AS-P (LLM), Tree of Thoughts (LLMToT), LLM+P không có ngữ cảnh (LLM+P−), và LLM+P.

Phát hiện (LLM-AS-P):
1) Chúng tôi quan sát rằng mặc dù LLM-AS-P cung cấp một kế hoạch bằng ngôn ngữ tự nhiên cho mọi bài toán, hầu hết các kế hoạch này không khả thi. Lý do chính là LLM-AS-P thiếu khả năng suy luận về các điều kiện tiên quyết.

2) Trong hầu hết các trường hợp, LLM-AS-P thất bại theo cách tương tự có hoặc không có kế hoạch ví dụ như ngữ cảnh. Đặc biệt, trong miền BLOCKSWORLD, LLM-AS-P không thể theo dõi các thuộc tính như ON và CLEAR. Trong miền BARMAN, các kế hoạch của LLM-AS-P thất bại trong việc làm sạch ly shot trước khi sử dụng lại chúng.

3) Các miền khó nhất là những miền có mối quan hệ không gian phức tạp. Các phương pháp LLM-AS-P (có hoặc không có ngữ cảnh) hoàn toàn thất bại với loại bài toán này. Trong miền FLOORTILE, LLM-AS-P tạo ra "di chuyển sang phải đến gạch 0-4 và sơn gạch 1-2 màu đen" nhưng robot chỉ có thể sơn các gạch lân cận. Trong TERMES và STORAGE, LLM-AS-P bỏ qua yêu cầu rằng robot không thể dỡ khối/thùng tại cùng vị trí mà nó chiếm.

4) LLM-AS-P (TOT) gọi LLM tại mỗi nút cây để cung cấp danh sách các hành động có sẵn, và sau đó gọi LLM để đánh giá mỗi đường dẫn mới trên cây như một kế hoạch một phần. Chúng tôi thấy rằng LLM có thể đưa ra xếp hạng hợp lý trên các kế hoạch một phần, nhưng nó thường thất bại trong việc nhận ra liệu kế hoạch có đạt được mục tiêu hay không. LLM-AS-P (TOT) hết thời gian trong hầu hết các trường hợp do số lượng lớn các cuộc gọi LLM, vì vậy nó không phù hợp để giải quyết các bài toán tầm xa.

Phát hiện (LLM+P):
1) LLM+P được đề xuất tạo ra kế hoạch tối ưu cho phần lớn các bài toán. Hầu hết các trường hợp thất bại là do các tệp bài toán được chỉ định sai, như thiếu một trong các điều kiện ban đầu (ví dụ để lại các gạch bị ngắt kết nối trong FLOORTILE), khiến bài toán lập kế hoạch không thể giải được.

2) Không có ngữ cảnh (tức là một bài toán ví dụ và tệp PDDL bài toán tương ứng của nó), chúng tôi quan sát rằng LLM thất bại trong việc tạo ra các tệp PDDL bài toán đúng. Do đó, ngữ cảnh quan trọng để LLM+P hoạt động.

D. Minh họa Robot

Chúng tôi xác minh rằng LLM+P có thể giải quyết hiệu quả các bài toán robot dịch vụ thực tế bằng cách triển khai nó trên một robot thực được giao nhiệm vụ dọn dẹp nhà. Người dùng yêu cầu robot di chuyển một chai mù tạt từ bàn cà phê đến tủ đựng thức ăn, và vứt đi lon súp rỗng từ bàn bên. Vì bàn bên và thùng rác tái chế nằm trên đường từ bàn cà phê đến tủ đựng thức ăn, kế hoạch tối ưu là mang chai mù tạt đến bàn bên, và cầm lại nó sau khi vứt đi lon súp, với tổng chi phí là 22. Hình 2 cho thấy kế hoạch tối ưu được tìm thấy bởi LLM+P. Các phần của prompt và PDDL được tạo ra được hiển thị bên dưới. LLM-AS-P xuất ra một kế hoạch không tối ưu mang chai lên tủ đựng thức ăn trước và quay lại lấy lon súp, với tổng chi phí là 31.

PDDL Bài toán Dọn dẹp Được tạo bởi LLM+P

Bài toán (P): Bạn là một robot gia đình với một gripper. Khoảng cách giữa bàn cà phê và bàn bên là 10. Khoảng cách giữa bàn cà phê và tủ đựng thức ăn là 20... Bạn đang ở bàn cà phê. Có một chai mù tạt... Mục tiêu của bạn là di chuyển đối tượng đến đích của chúng...

PDDL bài toán được tạo bởi LLM+P:
(:objects coffee-table side-table
recycle-bin pantry - location
mustard-bottle soup-can - object)
(:init (= (total-cost) 0) (=
(distance coffee-table side-table)
10) (= (distance coffee-table
pantry) 20) ... (robot-at
coffee-table) (at mustard-bottle
coffee-table) (at soup-can
side-table) (hand-empty) )
(:goal (and (at mustard-bottle
pantry) (at soup-can recycle-bin)))
(:metric minimize (total-cost)) )

VI. KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Trong công việc này, chúng tôi đề xuất tận dụng các bộ lập kế hoạch cổ điển để trao quyền cho các mô hình ngôn ngữ lớn với khả năng lập kế hoạch tối ưu. Lựa chọn thiết kế chính của khung LLM+P được đề xuất là tập trung LLM vào việc dịch bài toán lập kế hoạch từ ngôn ngữ tự nhiên sang định dạng PDDL có cấu trúc. Hơn nữa, chúng tôi cho thấy rằng cũng quan trọng là làm cho LLM nhận thức được một cặp (bài toán, PDDL) đơn giản như một minh họa (hoặc ngữ cảnh) cho học trong ngữ cảnh. Một số hướng thú vị để mở rộng thêm khung LLM+P bao gồm: 1) cho phép LLM tự động phát hiện khi nào và cách áp dụng LLM+P; và 2) giảm sự phụ thuộc của LLM+P vào thông tin từ con người, có thể liên quan đến fine-tuning.

TÀI LIỆU THAM KHẢO

[1] J. Weizenbaum, "Eliza—a computer program for the study of natural language communication between man and machine," Communications of the ACM, vol. 9, no. 1, pp. 36–45, 1966.

[2] OpenAI, "Gpt-4 technical report," 2023.

[3] S. Vemprala, R. Bonatti, A. Bucker, and A. Kapoor, "Chatgpt for robotics: Design principles and model abilities," Microsoft, Tech. Rep. MSR-TR-2023-8, February 2023. [Online]. Available: https://www.microsoft.com/en-us/research/publication/chatgpt-for-robotics-design-principles-and-model-abilities/

[4] K. Mahowald, A. A. Ivanova, I. A. Blank, N. Kanwisher, J. B. Tenenbaum, and E. Fedorenko, "Dissociating language and thought in large language models: a cognitive perspective," arXiv preprint arXiv:2301.06627, 2023.

[5] C. Lee, K. Cho, and W. Kang, "Mixout: Effective regularization to finetune large-scale pretrained language models," arXiv preprint arXiv:1909.11299, 2019.

[6] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, "Finetuned language models are zero-shot learners," arXiv preprint arXiv:2109.01652, 2021.

[7] D. McDermott, M. Ghallab, A. Howe, C. Knoblock, A. Ram, M. Veloso, D. Weld, and D. Wilkins, "Pddl-the planning domain definition language," 1998.

[8] P. Haslum, N. Lipovetzky, D. Magazzeni, and C. Muise, "An introduction to the planning domain definition language," Synthesis Lectures on Artificial Intelligence and Machine Learning, vol. 13, no. 2, pp. 1–187, 2019.

[9] K. Valmeekam, A. Olmo, S. Sreedharan, and S. Kambhampati, "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)," arXiv preprint arXiv:2206.10498, 2022.

[10] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., "Language models are few-shot learners," Advances in neural information processing systems, vol. 33, pp. 1877–1901, 2020.

[11] M. Helmert, "The fast downward planning system," Journal of Artificial Intelligence Research, vol. 26, pp. 191–246, 2006.

[12] T. Bylander, "The computational complexity of propositional STRIPS planning," Artificial Intelligence, vol. 69, no. 1-2, pp. 165–204, 1994.

[13] J. McCarthy, "Situations, actions, and causal laws," Stanford University Technical Report, Tech. Rep., 1963.

[14] R. E. Fikes and N. J. Nilsson, "Strips: A new approach to the application of theorem proving to problem solving," Artificial intelligence, vol. 2, no. 3-4, pp. 189–208, 1971.

[15] N. J. Nilsson et al., "Shakey the robot," 1984.

[16] J. Carbonell, O. Etzioni, Y. Gil, R. Joseph, C. Knoblock, S. Minton, and M. Veloso, "Prodigy: An integrated architecture for planning and learning," ACM SIGART Bulletin, vol. 2, no. 4, pp. 51–55, 1991.

[17] D. S. Nau, T.-C. Au, O. Ilghami, U. Kuter, J. W. Murdock, D. Wu, and F. Yaman, "Shop2: An htn planning system," Journal of artificial intelligence research, 2003.

[18] Y.-q. Jiang, S.-q. Zhang, P. Khandelwal, and P. Stone, "Task planning in robotics: an empirical comparison of pddl-and asp-based systems," Frontiers of Information Technology & Electronic Engineering, vol. 20, pp. 363–373, 2019.

[19] G. Brewka, T. Eiter, and M. Truszczyński, "Answer set programming at a glance," Communications of the ACM, vol. 54, no. 12, pp. 92–103, 2011.

[20] V. Lifschitz, "Answer set programming and plan generation," Artificial Intelligence, vol. 138, no. 1-2, pp. 39–54, 2002.

[21] M. Fox and D. Long, "Pddl2. 1: An extension to pddl for expressing temporal planning domains," Journal of artificial intelligence research, vol. 20, pp. 61–124, 2003.

[22] S. Zhang, F. Yang, P. Khandelwal, and P. Stone, "Mobile robot planning using action language bc with an abstraction hierarchy," in International Conference on Logic Programming and Nonmonotonic Reasoning. Springer, 2015, pp. 502–516.

[23] Y. Ding, X. Zhang, X. Zhan, and S. Zhang, "Task-motion planning for safe and efficient urban driving," in 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020.

[24] Y. Jiang, H. Yedidsion, S. Zhang, G. Sharon, and P. Stone, "Multi-robot planning with conflicts and synergies," Autonomous Robots, vol. 43, no. 8, pp. 2011–2032, 2019.

[25] F. Lagriffoul, N. T. Dantam, C. Garrett, A. Akbari, S. Srivastava, and L. E. Kavraki, "Platform-independent benchmarks for task and motion planning," IEEE Robotics and Automation Letters, vol. 3, no. 4, pp. 3765–3772, 2018.

[26] L. P. Kaelbling and T. Lozano-Pérez, "Integrated task and motion planning in belief space," The International Journal of Robotics Research, vol. 32, no. 9-10, pp. 1194–1227, 2013.

[27] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," arXiv preprint arXiv:1810.04805, 2018.

[28] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al., "Evaluating large language models trained on code," arXiv preprint arXiv:2107.03374, 2021.

[29] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al., "Opt: Open pre-trained transformer language models," arXiv preprint arXiv:2205.01068, 2022.

[30] OpenAI, "Chatgpt," Accessed: 2023-02-08, 2023, cit. on pp. 1, 16. [Online]. Available: https://openai.com/blog/chatgpt/

[31] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al., "Llama: Open and efficient foundation language models," arXiv preprint arXiv:2302.13971, 2023.

[32] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al., "Llama 2: Open foundation and fine-tuned chat models," arXiv preprint arXiv:2307.09288, 2023.

[33] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al., "Palm: Scaling language modeling with pathways," arXiv preprint arXiv:2204.02311, 2022.

[34] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, et al., "Do as i can, not as i say: Grounding language in robotic affordances," arXiv preprint arXiv:2204.01691, 2022.

[35] Y. Ding, X. Zhang, C. Paxton, and S. Zhang, "Task and motion planning with large language models for object rearrangement," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023.

[36] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter, A. Wahid, J. Tompson, Q. Vuong, T. Yu, et al., "Palm-e: An embodied multimodal language model," arXiv preprint arXiv:2303.03378, 2023.

[37] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch, Y. Chebotar, et al., "Inner monologue: Embodied reasoning through planning with language models," arXiv preprint arXiv:2207.05608, 2022.

[38] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch, "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents," in International Conference on Machine Learning. PMLR, 2022, pp. 9118–9147.

[39] Y. Kant, A. Ramachandran, S. Yenamandra, I. Gilitschenski, D. Batra, A. Szot, and H. Agrawal, "Housekeep: Tidying virtual households using commonsense reasoning," in Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXXIX. Springer, 2022, pp. 355–373.

[40] I. Singh, V. Blukis, A. Mousavian, A. Goyal, D. Xu, J. Tremblay, D. Fox, J. Thomason, and A. Garg, "Progprompt: Generating situated robot task plans using large language models," arXiv preprint arXiv:2209.11302, 2022.

[41] K. Lin, C. Agia, T. Migimatsu, M. Pavone, and J. Bohg, "Text2motion: From natural language instructions to feasible plans," arXiv preprint arXiv:2303.12153, 2023.

[42] Y. Yang, J.-R. Gaglione, C. Neary, and U. Topcu, "Automaton-based representations of task knowledge from generative language models," arXiv preprint arXiv:2212.01944, 2023.

[43] Y. Ding, X. Zhang, S. Amiri, N. Cao, H. Yang, A. Kaminski, C. Esselink, and S. Zhang, "Integrating action knowledge and llms for task planning and situation handling in open worlds," arXiv preprint arXiv:2305.17590, 2023.

[44] A. Z. Ren, A. Dixit, A. Bodrova, S. Singh, S. Tu, N. Brown, P. Xu, L. Takayama, F. Xia, J. Varley, et al., "Robots that ask for help: Uncertainty alignment for large language model planners," arXiv preprint arXiv:2307.01928, 2023.

[45] Y. Chen, J. Arkin, Y. Zhang, N. Roy, and C. Fan, "Autotamp: Autoregressive task and motion planning with llms as translators and checkers," arXiv preprint arXiv:2306.06531, 2023.

[46] K. Valmeekam, S. Sreedharan, M. Marquez, A. Olmo, and S. Kambhampati, "On the planning abilities of large language models (a critical investigation with a proposed benchmark)," arXiv preprint arXiv:2302.06706, 2023.

[47] T. Silver, V. Hariprasad, R. S. Shuttleworth, N. Kumar, T. Lozano-Pérez, and L. P. Kaelbling, "PDDL planning with pretrained large language models," in NeurIPS 2022 Foundation Models for Decision Making Workshop, 2022. [Online]. Available: https://openreview.net/forum?id=1QMMUB4zfl

[48] V. Pallagani, B. Muppasani, K. Murugesan, F. Rossi, L. Horesh, B. Srivastava, F. Fabiano, and A. Loreggia, "Plansformer: Generating symbolic plans using transformers," arXiv preprint arXiv:2212.08681, 2022.

[49] D. Arora and S. Kambhampati, "Learning and leveraging verifiers to improve planning capabilities of pre-trained language models," arXiv preprint arXiv:2305.17077, 2023.

[50] L. Guan, K. Valmeekam, S. Sreedharan, and S. Kambhampati, "Leveraging pre-trained large language models to construct and utilize world models for model-based task planning," arXiv preprint arXiv:2305.14909, 2023.

[51] T. Silver, S. Dan, K. Srinivas, J. B. Tenenbaum, L. P. Kaelbling, and M. Katz, "Generalized planning in pddl domains with pretrained large language models," arXiv preprint arXiv:2305.11014, 2023.

[52] V. Pallagani, B. Muppasani, K. Murugesan, F. Rossi, B. Srivastava, L. Horesh, F. Fabiano, and A. Loreggia, "Understanding the capabilities of large language models for automated planning," arXiv preprint arXiv:2305.16151, 2023.

[53] K. Valmeekam, M. Marquez, S. Sreedharan, and S. Kambhampati, "On the planning abilities of large language models–a critical investigation," arXiv preprint arXiv:2305.15771, 2023.

[54] Y. Xie, C. Yu, T. Zhu, J. Bai, Z. Gong, and H. Soh, "Translating natural language to planning goals with large-language models," arXiv preprint arXiv:2302.05128, 2023.

[55] R. Hazra, P. Z. D. Martires, and L. De Raedt, "Saycanpay: Heuristic planning with large language models using learnable domain knowledge," arXiv preprint arXiv:2308.12682, 2023.

[56] K. Rana, J. Haviland, S. Garg, J. Abou-Chakra, I. Reid, and N. Suenderhauf, "Sayplan: Grounding large language models using 3d scene graphs for scalable task planning," arXiv preprint arXiv:2307.06135, 2023.

[57] Z. Zhou, J. Song, K. Yao, Z. Shu, and L. Ma, "Isr-llm: Iterative self-refined large language model for long-horizon sequential task planning," arXiv preprint arXiv:2308.13724, 2023.

[58] Z. Wang, S. Cai, A. Liu, X. Ma, and Y. Liang, "Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents," arXiv preprint arXiv:2302.01560, 2023.

[59] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S. Jain, V. Kosaraju, W. Saunders, et al., "Webgpt: Browser-assisted question-answering with human feedback," arXiv preprint arXiv:2112.09332, 2021.

[60] A. Lazaridou, E. Gribovskaya, W. Stokowiec, and N. Grigorev, "Internet-augmented language models through few-shot prompting for open-domain question answering," arXiv preprint arXiv:2203.05115, 2022.

[61] A. Madaan, N. Tandon, P. Clark, and Y. Yang, "Memory-assisted prompt editing to improve gpt-3 after deployment," 2023.

[62] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettlemoyer, and W.-t. Yih, "Replug: Retrieval-augmented black-box language models," arXiv preprint arXiv:2301.12652, 2023.

[63] W. Chen, X. Ma, X. Wang, and W. W. Cohen, "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks," arXiv preprint arXiv:2211.12588, 2022.

[64] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig, "Pal: Program-aided language models," arXiv preprint arXiv:2211.10435, 2022.

[65] T. Schick, J. Dwivedi-Yu, R. Dessì, R. Raileanu, M. Lomeli, L. Zettlemoyer, N. Cancedda, and T. Scialom, "Toolformer: Language models can teach themselves to use tools," arXiv preprint arXiv:2302.04761, 2023.

[66] Q. Lyu, S. Havaldar, A. Stein, L. Zhang, D. Rao, E. Wong, M. Apidianaki, and C. Callison-Burch, "Faithful chain-of-thought reasoning," arXiv preprint arXiv:2301.13379, 2023.

[67] J. Seipp, Á. Torralba, and J. Hoffmann, "PDDL generators," https://doi.org/10.5281/zenodo.6382173, 2022.

[68] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and K. Narasimhan, "Tree of thoughts: Deliberate problem solving with large language models," arXiv preprint arXiv:2305.10601, 2023.

# 2304.11477.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/long-context/2304.11477.pdf
# File size: 2844380 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
LLM+P: Empowering Large Language Models
with Optimal Planning Proficiency
Bo Liu∗†, Yuqian Jiang∗†, Xiaohan Zhang‡, Qiang Liu†, Shiqi Zhang‡, Joydeep Biswas†, Peter Stone†§
Abstract — Large language models (LLMs) have demon-
strated remarkable zero-shot generalization abilities: state-
of-the-art chatbots can provide plausible answers to many
common questions that arise in daily life. However, so far, LLMs
cannot reliably solve long-horizon robot planning problems.
By contrast, classical planners, once a problem is given in a
formatted way, can use efficient search algorithms to quickly
identify correct, or even optimal, plans. In an effort to get
the best of both worlds, this paper introduces LLM+P, the
first framework that incorporates the strengths of classical
planners into LLMs. LLM+P takes in a natural language
description of a planning problem, then returns a correct (or
optimal) plan for solving that problem in natural language.
LLM+P does so by first converting the language description
into a file written in the planning domain definition language
(PDDL), then leveraging classical planners to quickly find a
solution, and then translating the found solution back into
natural language. Along with LLM+P, we define a diverse set
of different benchmark problems taken from robot planning
scenarios. Via a comprehensive set of experiments on these
benchmark problems, we find that LLM+P is able to provide
optimal solutions for most problems, while LLMs fail to provide
even feasible plans for most problems. We also show LLM+P
enables a home robot to solve a complex manipulation task that
is specified by the user in natural language.1
I. I NTRODUCTION
Ever since the birth of the field, AI researchers have sought
to create programs that can converse in natural language
with the same grace and flexibility as people. While even
relatively simple models, such as Eliza from 1966 [1], can
generate responses to some prompts that seem reasonable,
it has always been relatively easy to generate prompts that
expose their weaknesses compared to people — their lack of
true “understanding.”
While large language models (LLMs) such as GPT-4 [2]
and ChatGPT [3] have far surpassed expectations of just a
few years ago, they are no different in this respect. Indeed
the internet is now awash with examples of people reveling
in getting ChatGPT to generate output that even a 5-year-old
human child would know to be ill-advised.
Given how LLMs are designed and trained, this phe-
nomenon should come as no surprise. They are not specif-
ically built to demonstrate understanding. They are trained
*Equal contribution.
†Department of Computer Science, The University of Texas at
Austin {bliu, lqiang, joydeep, pstone }@cs.utexas.edu,
jiangyuqian@utexas.edu
‡Department of Computer Science, State University of New York at
Binghamton {xzhan244,zhangs }@binghamton.edu
§Sony AI
1The code and results are publicly available at https://github.
com/Cranial-XIX/llm-pddl.git .to generate sequences of words that might be plausible to a
human given a prior context. In the terms of Mahowald et
al. [4] LLMs have become amazingly proficient at linguistic
competence — knowing how to say things; but they are not
nearly as good at functional competence — knowing what to
say. Specifically, they can be (relatively) easily fooled by, for
example, asking for the result of a straightforward arithmetic
problem that does not appear in their training corpus or by
asking for the solution to a novel planning problem that
requires knowledge about how the world works.
A Failure Example of GPT-4 in Planning
Problem (P1): You have 5 blocks. One cannot place
more than one block on another block. b5 is on top
of b3. b4 is on top of b2. b2 is on top of b1. b3 is on
top of b4. b1 is on the table. b5 is clear. Your arm
is empty.
Your goal is to move the blocks.
b1 should be on top of b2.
b3 should be on top of b5.
b4 should be on top of b1.
GPT-4:
1. Move b5 from b3 to the table.
2. Move b3 from b4 to b5.
3. Move b4 from b2 to the table.
4. Move b2 from b1 to b5.
5. Move b1 from the table to b2.
6. Move b4 from the table to b1.
Does that mean that we should increase efforts to include
all arithmetic and planning problems in their training corpus?
Clearly, that is a fool’s errand. On the other hand, why should
it be necessary? We already have calculators and general-
purpose symbolic planners that are guaranteed to produce
correct answers. Thus a natural alternative approach, and one
that we are admittedly not the first to explore, is to connect
LLMs to such tools.
With this motivation in mind, the objective of the research
reported in this paper is, for the first time, to enable LLMs to
solve planning problems correctly . We aim to do so without
altering the LLMs themselves, even with finetuning [5],
[6]. Rather, we introduce a methodology, called LLM+P
by which, when posed a natural language description of a
planning problem, the LLM:
1) outputs a problem description suitable as input to aarXiv:2304.11477v3  [cs.AI]  27 Sep 2023

--- PAGE 2 ---
LLMPlan
LLMProblem	PDDLPlannerPDDL	PlanLLMPlanGenerated	TextModuleProvided	Text
Problem	(P)LLM-As-Planner
LLM	+	P	(In-context	Learning)Problem	(P)DomainLLMPlanEx.	P	&	Ex.	SolContextLLM-As-Planner	(In-context	Learning)Ex.	P	&	Ex.	PDDLContextDomain	PDDLProblem	(P)DomainFig. 1: LLM+P makes use of a large language model (LLM) to produce the PDDL description of the given problem, then
leverages a classical planner for finding an optimal plan, then translates the raw plan back to natural language using the
LLM again.
general-purpose planner;
2) solves the problem using the general-purpose planner;
and
3) converts the output of the planner back to natural
language (or connects to action executors of a robot).
Our extensive empirical evaluations indicate that LLM+P
is able to generate correct solutions to many more planning
problems than are LLMs on their own. While demonstrated
in this paper on planning problems, this general methodology
can be applied to any class of problems for which we have a
sound and complete solver, such as arithmetic problems (by
leveraging calculators).
Limitation: In this paper, we do not ask the LLM to
recognize that it has been posed a prompt that is suitable for
processing using the proposed LLM+P pipeline. A valuable
future research direction will be to consider recognizing
when a prompt should be processed by LLM+P.
II. B ACKGROUND
This section introduces the notation we use for represent-
ing a planning problem to be solved by LLMs, and recaps
the standard representation of classical planners.
A. The Classical Planning Problem
Formally, the input of a planning problem Pis defined by
a tuple ⟨S ,sinit,SG,A,f⟩:
•Sis a finite and discrete set of states used to describe
the world’s state (i.e., state space). We assume a factored
state space such that each state s∈Sis defined by the
values of a fixed set of variables.•sinit∈Sis an initial world state.
•SG⊂Sis a set of goal states. SGare usually
specified as a list of goal conditions , all of which must
hold in a goal state.
•Ais a set of symbolic actions.
•fis the underlying state transition function. ftakes
the current state and an action as input and outputs the
corresponding next state.
A solution to a planning problem Pis a symbolic plan πin
the form of ⟨a1,a2, . . . , aN⟩, such that the preconditions of
a1hold in sinit, the preconditions of a2hold in the state that
results from applying a1, and so on, with the goal conditions
all holding in the state that results after applying aN.
B. Planning Domain Definition Language (PDDL)
The planning domain definition language (PDDL) serves
as a standardized encoding of classical planning prob-
lems [7], [8]. The PDDL representation of a planning prob-
lemPis separated into two files: a domain file and a problem
file. The domain PDDL file provides a lifted representation
of the underlying rules of the world. It includes a set of
predicates that define the state space Sand the actions (i.e.,
A) with their preconditions and effects (i.e., the transition
function f). The problem PDDL file provides a list of objects
to ground the domain, the problem’s initial state sinitand
goal conditions SG. There exists a rich set of symbolic
planners that implement efficient search algorithms to solve
planning problems formalized in PDDL. In this work, we aim
to take a natural language prompt which describes the initial
state sinitand goal conditions SG, formulate it in PDDL,

--- PAGE 3 ---
and leverage symbolic planners to output correct plans. We
assume the domain rules are available (See the assumptions
in Section III).
III. M ETHOD
This section first uses a running example to investigate
ways for formulating planning prompts in PDDL and then
introduces the LLM+P method.
A. Large Language Model as a PDDL Writer
LLMs are bad at planning (or long-horizon reasoning)
[9] but they are good at describing and translating textual
inputs, including re-writing planning prompts in the PDDL
format. The intuition is that we can view PDDL as a different
language than English, so re-writing planning prompts in
PDDL is essentially a “machine translation” task that LLMs
are known to excel at. Here we provide an example of a
PDDL problem file written by GPT-4 without any prompt-
engineering. As we see, the generated file appears to have the
correct PDDL syntax but uses a made-up predicate (empty)
and misses the initial condition that b1is on the table.
An Example PDDL Problem File Written by GPT-4
Prompt: Description of Problem (P1) + Provide
me with the problem PDDL file that describes
the planning problem directly without further
explanations.
GPT-4 (the generated problem PDDL):
(:objects b1 b2 b3 b4 b5 - block)
(:init (on b5 b3) (on b4 b2) (on b2
b1) (on b3 b4) (clear b5) (empty))
(:goal (and (on b1 b2) (on b3 b5)
(on b4 b1)))
B. In-Context Learning
LLMs are known to be capable of in-context learning
without finetuning their parameters. By in-context learning,
we mean LLMs’ ability to perform unseen downstream
tasks by simply conditioning on a few input-label pairs
(demonstrations) [10]. Here is a pair of problem descriptions
in natural language and in PDDL provided to GPT-4 as
context. When the context is included with the prompt from
the example above, the resulting PDDL problem file is
directly solvable by the planner.An Example PDDL Problem File Written by GPT-4
with Context
Context (shaded):
An example planning problem is: You have 5 blocks.
b2 is on top of b5. b5 is on top of b1. b1 is on top of
b4. b3 is on top of b2. b4 is on the table. b3 is clear.
Your arm is empty. Your goal is to move the blocks.
b4 should be on top of b3. The problem PDDL is:
(:objects b1 b2 b3 b4 b5)
(:init (arm-empty) (on b1 b4) (on
b2 b5) (on b3 b2)
(on-table b4) (on b5 b1)
(clear b3))
(:goal (and (on b4 b3))))
Prompt: Description of Problem (P1) + Context
+ Provide me with the problem PDDL file that
describes the planning problem directly without
further explanations.
GPT-4 (the generated problem PDDL):
(:objects b1 b2 b3 b4 b5 )
(:init (arm-empty) (on-table b1)
(on b2 b1) (on b3 b4)
(on b4 b2) (on b5 b3) (clear
b5)))
(:goal (and (on b1 b2) (on b3 b5)
(on b4 b1)))
Planner:
(unstack b5 b3) (putdown b5)
(unstack b3 b4) (stack b3 b5)
(unstack b4 b2) (putdown b4)
(unstack b2 b1) (putdown b2)
(pickup b1) (stack b1 b2) (pickup
b4) (stack b4 b1)
C. Large Language Model + Classical Planner ( LLM+P )
Having introduced the LLM’s ability to encode problems
in PDDL and in-context learning, we are ready to introduce
the proposed LLM+P solution (the bottom of Fig. 1). In
particular, we assume that for each problem domain, a
human expert can provide a domain description (i.e. action
preconditions and effects) that will be fixed for all problem
instances that happen in that domain. While the problem of
automatically generating the description is another valuable
research question, in this proposed work, we assume that the
description is available as a PDDL domain file. The LLM+P
method is directly applicable as a natural language interface
for giving tasks to robot systems. For instance, assume we
want a robot to act as a bartender to make cocktails. It is
reasonable to tell it what actions it can take, but leave itself
to infer how to make new cocktails most efficiently given
a set of ingredients to combine. Moreover, we assume the
agent is provided with a minimal example that demonstrates
what an example problem PDDL looks like for a simple

--- PAGE 4 ---
problem inside that domain. Next, the agent is provided
with a new (potentially quite complicated) problem ( P). The
LLM then uses the in-context learning to infer the problem
PDDL file corresponding to P. Once the problem PDDL file
is generated, we feed it into any classical planner, together
with the provided domain PDDL file, to generate a PDDL
plan [11]. In the end, the LLM translates the PDDL plan back
into the natural language to finish up the LLM+P pipeline.
To summarize, the assumptions we need for LLM+P are:
1) A robot knows when to trigger LLM+P based on its
conversation with a human user.
2) A domain PDDL is provided to define the actions
that the robot is capable of. This specification is task-
agnostic — the entities relevant to the task are specified
in the LLM-generated problem PDDL.
3) A simple problem description in natural language and
its corresponding problem PDDL file are also provided.
IV. R ELATED WORK
This section first provides a brief overview of classical
planning algorithms. Then it summarizes recent advances in
using large language models for planning tasks. It concludes
with a discussion of recent research on augmenting LLMs
with external modules.
A. Classical Planning
Automated planning (or classical planning) techniques can
be used for computing a sequence of actions that achieves a
given goal [12], [13], [14]. Automated planning algorithms
have been widely used in robot systems. Shakey is the first
robot that was equipped with a planning component, which
was constructed using STRIPS [15]. Some previous general-
purpose planning architectures were also demonstrated to
be useful for robot planning, such as PRODIGY [16] and
HTN [17]. Recent classical planning systems designed for
robotics frequently use planning domain description lan-
guage (PDDL) or answer set programming (ASP) as the
underlying action language for the planners [18], [19], [20],
[21]. For example, researchers have used classical planning
algorithms for sequencing actions for a mobile robot working
on delivery tasks [22], reasoning about safe and efficient
urban driving behaviors for autonomous vehicles [23], and
planning actions for a team of mobile robots [24]. Task and
motion planning (TAMP) is a hierarchical planning frame-
work that combines classical planning in discrete spaces and
robot motion planning in continuous space [25], [26].
Most of the above-mentioned planning methods require
domain-specific programming languages as the underlying
representation of the problems and their solutions. LLM+P,
on the other hand, takes advantage of LLMs and serves
as a natural language interface for robots to solve complex
planning tasks. The main feature that motivates us to use such
classical planning systems is that most of these planners are
sound and complete, meaning that they are guaranteed to be
logically correct and will output a plan if one exists. Many
are also able to find optimal (shortest) plans, at least if given
sufficient time.B. Planning with Large Language Models
Various large language models (LLMs) have been de-
veloped in recent years, such as Bert [27], CodeX [28],
Opt [29], GPT-3 [10], ChatGPT [30], GPT-4 [2], Llama [31],
Llama2 [32], and PaLM [33]. As LLMs are pretrained with
a tremendous amount of offline text data, they can emerge
with surprising zero-shot generalization ability, which can
be leveraged for robot planning tasks [34], [35], [36], [37],
[38], [39], [40], [41], [42], [43], [44], [45]. Several recent
methods had successes in extracting task knowledge from
LLMs to decompose commands or instructions for robots
in natural language. For instance, the work of Huang et
al. showed that LLMs can be used for task planning in
household domains by iteratively augmenting prompts [38].
SayCan is another approach that enabled robot planning with
affordance functions to account for action feasibility, where
the service requests are specified in natural language [34].
Vemprala et al. recently studied how ChatGPT can be applied
to generalized robotics domains [3].
However, a major drawback of existing LLMs is their lack
of long-horizon reasoning ability for complex tasks (See [9],
[46] and Section 8.2 from [2]). Specifically, the output they
produce when presented with such a task is often incorrect
in the sense that following the output plan will not actually
solve the task. Therefore, in this work, we focus on resolving
this issue by leveraging the properties of classical planners.
Similarly, some recent work also investigates approaches for
combining classical planning with LLMs [47], [48], [49],
[50], [51], [52], [53], [54], [55], [56], [57]. They either
use prompting or fine-tuning to make LLMs capable of
solving PDDL planning problems. Improvements to long-
horizon planning capabilities have also been made by iter-
atively querying LLMs, as demonstrated in Minecraft [58].
In contrast, we do not solely rely on LLM as the problem
solver, but are more into taking the advantage of both the
planner (i.e., generating accurate and optimal plans) and the
LLM itself (i.e., 1-shot generalization for translating natural-
language problem descriptions into PDDL).
C. Augmenting LLMs with External Modules
Recently developed methods have shown that the per-
formance of downstream tasks of LLMs can be improved
by combining them with external modules. For instance,
WebGPT [59] is a fine-tuned version of GPT-3 by combining
web knowledge to answer open-ended questions. Lazaridou
et al. studied how search engines like Google can be utilized
as external tools for LLMs [60]. MemPrompt [61] presented
a human-in-the-loop system where a growing memory of
errors and user feedback is served as past experience adding
to the prompts for more accurately answering new ques-
tions. REPLUG [62] is another retrieval-augmented language
modeling paradigm that treats the language model as a
black box and augments it with a tuneable retrieval model.
Specifically, people have investigated using calculators for
computation [63], [64]. In very recent work related to ours,
Schick et al. trained a model called ToolFormer that can
decide when and how to call certain tool APIs by in-line

--- PAGE 5 ---
augmentation on prompts for LLMs [65]. In this work, we
propose that classical planners can be another particularly
useful external module. In comparison, LLM+P, does not
rely on any fine-tuning or re-training of LLMs. By simply
incorporating knowledge from classical planners, LLM+P
incorporates long-horizon reasoning and planning capabili-
ties into existing LLMs.
The authors are informed that a concurrent work [66]
presents preliminary results of integrating LLMs with PDDL
using the SayCan dataset [34]. However, the SayCan dataset
has a limited scope, as it contains only three predefined
actions. Consequently, all model variants evaluated in the
original paper achieved a success rate of approximately 90%.
Due to the homogeneity of the SayCan dataset, Lyu et al.
did not necessitate a rigorous definition of the domain PDDL,
which can lead to infeasible plans. As a result, we consider
our LLM+P method as a more comprehensive investigation
into enhancing LLMs with optimal planning proficiency.
V. E XPERIMENTS
We conduct experiments to answer these questions:
1) How well does LLM- AS-P work? To what extent
can state-of-the-art LLMs and LLM-based reasoning
methods be directly used for planning? (Not at all)
2) How well does LLM+P work compare to LLM- AS-P?
(Much better)
3) What role does the context play in the success of
LLM+P? (It’s crucial)
4) Can LLM+P help make service robots more efficient
on realistic tasks? (Yes)
A. Benchmark Problems
We present seven robot planning domains borrowed from
past International Planning Competitions and 20 automati-
cally generated tasks for each domain [67]. Below is a list
of the planning domains, along with a brief summary of each.
1) B LOCKSWORLD : Given a set of piles of blocks on a
table, a robot is tasked with rearranging them into a
specified target configuration.
2) B ARMAN : A robot bartender is tasked with creating
cocktails for a customer’s order, utilizing the available
ingredients and containers.
3) F LOORTILE : A set of robots are tasked to use paint
color patterns on floor tiles. Robots can move around
and change colors but cannot step on painted tiles.
4) G RIPPERS : A set of robots with two grippers is given
a task to move objects among different rooms.
5) S TORAGE : Given a set of hoists, the goal is to lift
and drop crates using the hoists into a depot. Crates
are initially stored in different areas and hoists can be
moved among storage areas.
6) T ERMES : A robot is tasked to build complex structures
by carrying and placing blocks, and also climbing on
them so that it can build towers.
7) T YREWORLD : The robot is given a task to replace flat
tires by, for example, inflating tires, tightening nuts,and moving tools back to the boot when done, all in
the proper order.
For each problem P,Pcomes with a natural language
description and a ground-truth problem PDDL file. Each
domain also includes an example problem description, a
corresponding PDDL file, and a plan description, used as
context in various approaches. We assume each problem
domain has its own domain PDDL file given by the user or a
domain expert prior to addressing any planning problems in
that domain. This dataset is made publicly available in our
codebase for reproducibility.
B. Experiment Setup
We leverage the GPT-4 model provided by OpenAI2for
all experiments. We set the temperature to 0, and use the
top probability response. As a result, the response returned
from the LLM is deterministic. Once a text PDDL response
is generated, we feed it into the FAST -DOWNWARD planner3
and try both aliases SEQ-OPT-FDSS -1 (guaranteed optimal)
and LAMA (not guaranteed optimal) with a maximum search
time of 200 seconds. We report the success rate of the
optimal alias, and for the domains that time out, we show the
success rate of the sub-optimal alias in parentheses. For the
baseline methods, we manually count the number of optimal
plans, and report the number of correct plans in parentheses
(if there are any sub-optimal plans).
We also evaluate a recent LLM-based approach for delib-
erate reasoning called Tree of Thoughts [68], referred to as
LLM- AS-P (T OT). We adapt the breadth-first-search algo-
rithm from the original ToT implementation4for planning.
The LLM is prompted to expand the search tree from allowed
actions and evaluate the paths on their likelihood of reaching
the goal. The same time limit of 200 seconds is applied.
C. Results and Analysis
The results of applying LLM- AS-P and LLM+P across 7
domains are provided in Table I.
DomainSuccess Rate %
LLM−LLM LLMToTLLM+P−LLM+P
BARMAN 0 0 0 0 20 (100)
BLOCKSWORLD 20 15 (30) 0 (5) 0 90
FLOORTILE 0 0 0 0 0
GRIPPERS 25 (60) 35 (50) 10 (20) 0 95 (100)
STORAGE 0 0 (25) 0 0 85
TERMES 0 0 0 0 20
TYREWORLD 5 15 0 0 10 (90)
TABLE I: Success rate % of applying LLM- AS-P without con-
text (LLM−), LLM- AS-P (LLM), Tree of Thoughts (LLMToT),
LLM+P without context (LLM−), and LLM+P.
Findings (LLM- AS-P):
1) We observe that though LLM- AS-P provides a plan
in natural language for every problem, most of these
2We use the most recent model as of September 2023. https://
platform.openai.com/docs/models/gpt-4
3https://github.com/aibasel/downward/tree/
release-22.12.0
4https://github.com/princeton-nlp/
tree-of-thought-llm/

--- PAGE 6 ---
(a) grasp bottle
 (b) free gripper
 (c) grasp soup can
 (d) place soup can
 (e) re-grasp bottle
 (f) place bottle
Fig. 2: Demonstration of the optimal tidy-up plan. The robot starts at the coffee table and 1) picks up the bottle, 2) navigates
to a room with the side table and the recycle bin, 3) puts down the bottle, 4) grasps the soup can, 5) puts the soup can in
the recycle bin, 6) re-grasps the bottle, 7) navigates to the kitchen, 8) places the bottle in the pantry.
plans are not feasible. The main reason is that LLM-
AS-P lacks the ability to reason about preconditions.
2) In most cases, LLM- AS-P fails in the same way with
or without the example plan as context. In particular,
in the B LOCKSWORLD domain, LLM- AS-P cannot
keep track of properties like ONand CLEAR . In the
BARMAN domain, LLM- AS-P’s plans fail to clean
shot glasses before using them again.
3) The hardest domains are the ones with complex spatial
relationship. The LLM- AS-P methods (with or without
context) completely fail at this type of problems. In
the F LOORTILE domain, LLM- AS-P generates “move
right to tile 0-4 and paint tile 1-2 black” but the robot
can only paint neighboring tiles. In T ERMES and
STORAGE , LLM- AS-P ignores the requirement that
the robot cannot unload the block/crate at the same
position it occupies.
4) LLM- AS-P (T OT) calls the LLM at each tree node
to provide a list of available actions, and then calls
the LLM to evaluate each new path on the tree as
a partial plan. We find that the LLM is able to give
reasonable rankings on the partial plans, but it often
fails to recognize whether the plan reaches the goal.
LLM- AS-P (T OT) times out in most cases due to the
large number of LLM calls, so it is not suitable for
solving long-horizon problems.
Findings (LLM+P):
1) The proposed LLM+P produces an optimal plan for
the majority of problems. Most failed cases are due to
mis-specified problem files, such as missing one of the
initial conditions (e.g. leaving the tiles disconnected
in F LOORTILE ), causing the planning problem to be
unsolvable.
2) Without the context (i.e., an example problem and its
corresponding problem PDDL), we observe that LLMs
fail to produce correct problem PDDL files. Therefore,
the context is important for LLM+P to work.
D. Robot Demonstration
We verify that LLM+P can efficiently solve realistic
service robot problems by deploying it on a real robot tasked
with tidying up a home. The user asks the robot to move a
mustard bottle from the coffee table to the pantry, and throw
away the empty soup can from the side table. Since the sidetable and the recycle bin are on the way from the coffee table
to the pantry, the optimal plan is to take the mustard bottle to
the side table, and re-grasp it after throwing away the soup
can, with a total cost of 22. Fig. 2 shows the optimal plan
found by LLM+P. Parts of the prompt and the generated
PDDL are shown below. LLM- AS-P outputs a sub-optimal
plan which takes the bottle to the pantry first and travels
back for the soup can, with a total cost of 31.
Tidy-Up Problem PDDL Generated by LLM+P
Problem (P): You are a home robot with one
gripper. The distance between coffee table and side
table is 10. The distance between coffee table and
pantry is 20... You are at the coffee table. There is
a mustard bottle... Your goal is to move objects to
their destinations...
Problem PDDL generated by LLM+P:
(:objects coffee-table side-table
recycle-bin pantry - location
mustard-bottle soup-can - object)
(:init (= (total-cost) 0) (=
(distance coffee-table side-table)
10) (= (distance coffee-table
pantry) 20) ... (robot-at
coffee-table) (at mustard-bottle
coffee-table) (at soup-can
side-table) (hand-empty) )
(:goal (and (at mustard-bottle
pantry) (at soup-can recycle-bin)))
(:metric minimize (total-cost)) )
VI. C ONCLUSION AND FUTURE WORK
In this work, we propose to leverage classical planners
to empower large language models with optimal planning
capabilities. The key design choice of the proposed LLM+P
framework is to focus LLMs on translating the planning
problem from natural language to structured PDDL format.
Moreover, we show that it is important to also make LLMs
aware of a simple (problem, PDDL) pair as a demonstration
(or the context) for in-context learning. Some interesting
directions to further extend the LLM+P framework include:
1) enabling the LLM to auto-detect when and how to
apply LLM+P; and 2) reducing LLM+P’s dependency on
information by humans, potentially involving finetuning.

--- PAGE 7 ---
REFERENCES
[1] J. Weizenbaum, “Eliza—a computer program for the study of natural
language communication between man and machine,” Communica-
tions of the ACM , vol. 9, no. 1, pp. 36–45, 1966.
[2] OpenAI, “Gpt-4 technical report,” 2023.
[3] S. Vemprala, R. Bonatti, A. Bucker, and A. Kapoor,
“Chatgpt for robotics: Design principles and model abilities,”
Microsoft, Tech. Rep. MSR-TR-2023-8, February 2023. [Online].
Available: https://www.microsoft.com/en-us/research/publication/
chatgpt-for-robotics-design-principles-and-model-abilities/
[4] K. Mahowald, A. A. Ivanova, I. A. Blank, N. Kanwisher, J. B.
Tenenbaum, and E. Fedorenko, “Dissociating language and thought
in large language models: a cognitive perspective,” arXiv preprint
arXiv:2301.06627 , 2023.
[5] C. Lee, K. Cho, and W. Kang, “Mixout: Effective regularization
to finetune large-scale pretrained language models,” arXiv preprint
arXiv:1909.11299 , 2019.
[6] J. Wei, M. Bosma, V . Y . Zhao, K. Guu, A. W. Yu, B. Lester, N. Du,
A. M. Dai, and Q. V . Le, “Finetuned language models are zero-shot
learners,” arXiv preprint arXiv:2109.01652 , 2021.
[7] D. McDermott, M. Ghallab, A. Howe, C. Knoblock, A. Ram,
M. Veloso, D. Weld, and D. Wilkins, “Pddl-the planning domain
definition language,” 1998.
[8] P. Haslum, N. Lipovetzky, D. Magazzeni, and C. Muise, “An introduc-
tion to the planning domain definition language,” Synthesis Lectures
on Artificial Intelligence and Machine Learning , vol. 13, no. 2, pp.
1–187, 2019.
[9] K. Valmeekam, A. Olmo, S. Sreedharan, and S. Kambhampati, “Large
language models still can’t plan (a benchmark for llms on planning
and reasoning about change),” arXiv preprint arXiv:2206.10498 , 2022.
[10] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. , “Language
models are few-shot learners,” Advances in neural information pro-
cessing systems , vol. 33, pp. 1877–1901, 2020.
[11] M. Helmert, “The fast downward planning system,” Journal of Artifi-
cial Intelligence Research , vol. 26, pp. 191–246, 2006.
[12] T. Bylander, “The computational complexity of propositional STRIPS
planning,” Artificial Intelligence , vol. 69, no. 1-2, pp. 165–204, 1994.
[13] J. McCarthy, “Situations, actions, and causal laws,” Stanford Univer-
sity Technical Report, Tech. Rep., 1963.
[14] R. E. Fikes and N. J. Nilsson, “Strips: A new approach to the appli-
cation of theorem proving to problem solving,” Artificial intelligence ,
vol. 2, no. 3-4, pp. 189–208, 1971.
[15] N. J. Nilsson et al. , “Shakey the robot,” 1984.
[16] J. Carbonell, O. Etzioni, Y . Gil, R. Joseph, C. Knoblock, S. Minton,
and M. Veloso, “Prodigy: An integrated architecture for planning and
learning,” ACM SIGART Bulletin , vol. 2, no. 4, pp. 51–55, 1991.
[17] D. S. Nau, T.-C. Au, O. Ilghami, U. Kuter, J. W. Murdock, D. Wu,
and F. Yaman, “Shop2: An htn planning system,” Journal of artificial
intelligence research , 2003.
[18] Y .-q. Jiang, S.-q. Zhang, P. Khandelwal, and P. Stone, “Task planning
in robotics: an empirical comparison of pddl-and asp-based sys-
tems,” Frontiers of Information Technology & Electronic Engineering ,
vol. 20, pp. 363–373, 2019.
[19] G. Brewka, T. Eiter, and M. Truszczy ´nski, “Answer set programming
at a glance,” Communications of the ACM , vol. 54, no. 12, pp. 92–103,
2011.
[20] V . Lifschitz, “Answer set programming and plan generation,” Artificial
Intelligence , vol. 138, no. 1-2, pp. 39–54, 2002.
[21] M. Fox and D. Long, “Pddl2. 1: An extension to pddl for expressing
temporal planning domains,” Journal of artificial intelligence research ,
vol. 20, pp. 61–124, 2003.
[22] S. Zhang, F. Yang, P. Khandelwal, and P. Stone, “Mobile robot
planning using action language bc with an abstraction hierarchy,” in
International Conference on Logic Programming and Nonmonotonic
Reasoning . Springer, 2015, pp. 502–516.
[23] Y . Ding, X. Zhang, X. Zhan, and S. Zhang, “Task-motion planning
for safe and efficient urban driving,” in 2020 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS) , 2020.
[24] Y . Jiang, H. Yedidsion, S. Zhang, G. Sharon, and P. Stone, “Multi-robot
planning with conflicts and synergies,” Autonomous Robots , vol. 43,
no. 8, pp. 2011–2032, 2019.[25] F. Lagriffoul, N. T. Dantam, C. Garrett, A. Akbari, S. Srivastava, and
L. E. Kavraki, “Platform-independent benchmarks for task and motion
planning,” IEEE Robotics and Automation Letters , vol. 3, no. 4, pp.
3765–3772, 2018.
[26] L. P. Kaelbling and T. Lozano-P ´erez, “Integrated task and motion
planning in belief space,” The International Journal of Robotics
Research , vol. 32, no. 9-10, pp. 1194–1227, 2013.
[27] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
of deep bidirectional transformers for language understanding,” arXiv
preprint arXiv:1810.04805 , 2018.
[28] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Ka-
plan, H. Edwards, Y . Burda, N. Joseph, G. Brockman, et al. ,
“Evaluating large language models trained on code,” arXiv preprint
arXiv:2107.03374 , 2021.
[29] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. De-
wan, M. Diab, X. Li, X. V . Lin, et al. , “Opt: Open pre-trained trans-
former language models,” arXiv preprint arXiv:2205.01068 , 2022.
[30] OpenAI, “Chatgpt,” Accessed: 2023-02-08, 2023, cit. on pp. 1, 16.
[Online]. Available: https://openai.com/blog/chatgpt/
[31] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,
T. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar, et al. , “Llama:
Open and efficient foundation language models,” arXiv preprint
arXiv:2302.13971 , 2023.
[32] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y . Babaei,
N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al. , “Llama
2: Open foundation and fine-tuned chat models,” arXiv preprint
arXiv:2307.09288 , 2023.
[33] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra,
A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al. ,
“Palm: Scaling language modeling with pathways,” arXiv preprint
arXiv:2204.02311 , 2022.
[34] M. Ahn, A. Brohan, N. Brown, Y . Chebotar, O. Cortes, B. David,
C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, et al. , “Do as i
can, not as i say: Grounding language in robotic affordances,” arXiv
preprint arXiv:2204.01691 , 2022.
[35] Y . Ding, X. Zhang, C. Paxton, and S. Zhang, “Task and motion
planning with large language models for object rearrangement,” 2023
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS) , 2023.
[36] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter,
A. Wahid, J. Tompson, Q. Vuong, T. Yu, et al. , “Palm-e: An embodied
multimodal language model,” arXiv preprint arXiv:2303.03378 , 2023.
[37] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng,
J. Tompson, I. Mordatch, Y . Chebotar, et al. , “Inner monologue:
Embodied reasoning through planning with language models,” arXiv
preprint arXiv:2207.05608 , 2022.
[38] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch, “Language models
as zero-shot planners: Extracting actionable knowledge for embodied
agents,” in International Conference on Machine Learning . PMLR,
2022, pp. 9118–9147.
[39] Y . Kant, A. Ramachandran, S. Yenamandra, I. Gilitschenski, D. Batra,
A. Szot, and H. Agrawal, “Housekeep: Tidying virtual households
using commonsense reasoning,” in Computer Vision–ECCV 2022:
17th European Conference, Tel Aviv, Israel, October 23–27, 2022,
Proceedings, Part XXXIX . Springer, 2022, pp. 355–373.
[40] I. Singh, V . Blukis, A. Mousavian, A. Goyal, D. Xu, J. Tremblay,
D. Fox, J. Thomason, and A. Garg, “Progprompt: Generating situ-
ated robot task plans using large language models,” arXiv preprint
arXiv:2209.11302 , 2022.
[41] K. Lin, C. Agia, T. Migimatsu, M. Pavone, and J. Bohg, “Text2motion:
From natural language instructions to feasible plans,” arXiv preprint
arXiv:2303.12153 , 2023.
[42] Y . Yang, J.-R. Gaglione, C. Neary, and U. Topcu, “Automaton-based
representations of task knowledge from generative language models,”
arXiv preprint arXiv:2212.01944 , 2023.
[43] Y . Ding, X. Zhang, S. Amiri, N. Cao, H. Yang, A. Kaminski,
C. Esselink, and S. Zhang, “Integrating action knowledge and llms for
task planning and situation handling in open worlds,” arXiv preprint
arXiv:2305.17590 , 2023.
[44] A. Z. Ren, A. Dixit, A. Bodrova, S. Singh, S. Tu, N. Brown, P. Xu,
L. Takayama, F. Xia, J. Varley, et al. , “Robots that ask for help:
Uncertainty alignment for large language model planners,” arXiv
preprint arXiv:2307.01928 , 2023.
[45] Y . Chen, J. Arkin, Y . Zhang, N. Roy, and C. Fan, “Autotamp:

--- PAGE 8 ---
Autoregressive task and motion planning with llms as translators and
checkers,” arXiv preprint arXiv:2306.06531 , 2023.
[46] K. Valmeekam, S. Sreedharan, M. Marquez, A. Olmo, and S. Kamb-
hampati, “On the planning abilities of large language models (a
critical investigation with a proposed benchmark),” arXiv preprint
arXiv:2302.06706 , 2023.
[47] T. Silver, V . Hariprasad, R. S. Shuttleworth, N. Kumar, T. Lozano-
P´erez, and L. P. Kaelbling, “PDDL planning with pretrained
large language models,” in NeurIPS 2022 Foundation Models
for Decision Making Workshop , 2022. [Online]. Available: https:
//openreview.net/forum?id=1QMMUB4zfl
[48] V . Pallagani, B. Muppasani, K. Murugesan, F. Rossi, L. Horesh,
B. Srivastava, F. Fabiano, and A. Loreggia, “Plansformer: Generating
symbolic plans using transformers,” arXiv preprint arXiv:2212.08681 ,
2022.
[49] D. Arora and S. Kambhampati, “Learning and leveraging verifiers to
improve planning capabilities of pre-trained language models,” arXiv
preprint arXiv:2305.17077 , 2023.
[50] L. Guan, K. Valmeekam, S. Sreedharan, and S. Kambhampati,
“Leveraging pre-trained large language models to construct and uti-
lize world models for model-based task planning,” arXiv preprint
arXiv:2305.14909 , 2023.
[51] T. Silver, S. Dan, K. Srinivas, J. B. Tenenbaum, L. P. Kaelbling, and
M. Katz, “Generalized planning in pddl domains with pretrained large
language models,” arXiv preprint arXiv:2305.11014 , 2023.
[52] V . Pallagani, B. Muppasani, K. Murugesan, F. Rossi, B. Srivastava,
L. Horesh, F. Fabiano, and A. Loreggia, “Understanding the capabili-
ties of large language models for automated planning,” arXiv preprint
arXiv:2305.16151 , 2023.
[53] K. Valmeekam, M. Marquez, S. Sreedharan, and S. Kambhampati,
“On the planning abilities of large language models–a critical investi-
gation,” arXiv preprint arXiv:2305.15771 , 2023.
[54] Y . Xie, C. Yu, T. Zhu, J. Bai, Z. Gong, and H. Soh, “Translating
natural language to planning goals with large-language models,” arXiv
preprint arXiv:2302.05128 , 2023.
[55] R. Hazra, P. Z. D. Martires, and L. De Raedt, “Saycanpay: Heuristic
planning with large language models using learnable domain knowl-
edge,” arXiv preprint arXiv:2308.12682 , 2023.
[56] K. Rana, J. Haviland, S. Garg, J. Abou-Chakra, I. Reid, and N. Suen-
derhauf, “Sayplan: Grounding large language models using 3d scene
graphs for scalable task planning,” arXiv preprint arXiv:2307.06135 ,
2023.
[57] Z. Zhou, J. Song, K. Yao, Z. Shu, and L. Ma, “Isr-llm: Iterative
self-refined large language model for long-horizon sequential task
planning,” arXiv preprint arXiv:2308.13724 , 2023.
[58] Z. Wang, S. Cai, A. Liu, X. Ma, and Y . Liang, “Describe, explain,
plan and select: Interactive planning with large language models en-
ables open-world multi-task agents,” arXiv preprint arXiv:2302.01560 ,
2023.
[59] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim,
C. Hesse, S. Jain, V . Kosaraju, W. Saunders, et al. , “Webgpt: Browser-
assisted question-answering with human feedback,” arXiv preprint
arXiv:2112.09332 , 2021.
[60] A. Lazaridou, E. Gribovskaya, W. Stokowiec, and N. Grigorev,
“Internet-augmented language models through few-shot prompting for
open-domain question answering,” arXiv preprint arXiv:2203.05115 ,
2022.
[61] A. Madaan, N. Tandon, P. Clark, and Y . Yang, “Memory-assisted
prompt editing to improve gpt-3 after deployment,” 2023.
[62] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-
moyer, and W.-t. Yih, “Replug: Retrieval-augmented black-box lan-
guage models,” arXiv preprint arXiv:2301.12652 , 2023.
[63] W. Chen, X. Ma, X. Wang, and W. W. Cohen, “Program of thoughts
prompting: Disentangling computation from reasoning for numerical
reasoning tasks,” arXiv preprint arXiv:2211.12588 , 2022.
[64] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y . Yang, J. Callan,
and G. Neubig, “Pal: Program-aided language models,” arXiv preprint
arXiv:2211.10435 , 2022.
[65] T. Schick, J. Dwivedi-Yu, R. Dess `ı, R. Raileanu, M. Lomeli, L. Zettle-
moyer, N. Cancedda, and T. Scialom, “Toolformer: Language models
can teach themselves to use tools,” arXiv preprint arXiv:2302.04761 ,
2023.
[66] Q. Lyu, S. Havaldar, A. Stein, L. Zhang, D. Rao, E. Wong, M. Apid-
ianaki, and C. Callison-Burch, “Faithful chain-of-thought reasoning,”
arXiv preprint arXiv:2301.13379 , 2023.[67] J. Seipp, ´A. Torralba, and J. Hoffmann, “PDDL generators,” https:
//doi.org/10.5281/zenodo.6382173, 2022.
[68] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y . Cao, and
K. Narasimhan, “Tree of thoughts: Deliberate problem solving with
large language models,” arXiv preprint arXiv:2305.10601 , 2023.

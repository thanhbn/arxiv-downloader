# 2309.03450.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2309.03450.pdf
# Kích thước file: 535578 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Báo cáo Kỹ thuật XGen-7B
Erik Nijkamp∗, Tian Xie∗, Hiroaki Hayashi∗, Bo Pang∗, Congying Xia∗, Chen Xing
Jesse Vig, Semih Yavuz, Philippe Laban, Ben Krause, Senthil Purushwalkam, Tong Niu
Wojciech Kry ´sci´nski, Lidiya Murakhovs'ka, Prafulla Kumar Choubey, Alex Fabbri
Ye Liu, Rui Meng, Lifu Tu, Meghana Bhat, Chien-Sheng Wu, Silvio Savarese
Yingbo Zhou†, Shafiq Joty†, Caiming Xiong†
Salesforce Research

Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLM) đã trở nên phổ biến khắp các lĩnh vực khác nhau, chuyển đổi cách chúng ta tương tác với thông tin và tiến hành nghiên cứu. Tuy nhiên, hầu hết các LLM hiệu suất cao vẫn được giữ bí mật đằng sau các bức tường độc quyền, cản trở tiến bộ khoa học. Mặt khác, hầu hết các LLM mã nguồn mở bị hạn chế khả năng hỗ trợ độ dài chuỗi dài hơn, đây là yêu cầu chính cho nhiều tác vụ cần suy luận trên ngữ cảnh đầu vào. Để giải quyết vấn đề này, chúng tôi đã huấn luyện XGen-7B, một loạt mô hình 7B tham số trên độ dài chuỗi lên đến 8K cho đến 1.5T token. Chúng tôi cũng đã tinh chỉnh các mô hình XGen-7B trên dữ liệu hướng dẫn công cộng, tạo ra các phiên bản được điều chỉnh hướng dẫn (XGen-7B-Inst). Chúng tôi mở mã nguồn các mô hình cho cả việc nghiên cứu và ứng dụng thương mại. Đánh giá của chúng tôi trên các benchmark tiêu chuẩn cho thấy các mô hình XGen-7B đạt được kết quả tương đương hoặc tốt hơn khi so sánh với các LLM mã nguồn mở tiên tiến. Đánh giá mục tiêu của chúng tôi về các tác vụ mô hình hóa chuỗi dài cho thấy lợi ích của các mô hình 8K-chuỗi so với các LLM mã nguồn mở 2K-chuỗi.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) đã cho thấy khả năng ấn tượng trong việc tạo văn bản, dịch ngôn ngữ, viết mã, trả lời câu hỏi, giải toán, dự đoán hành động và nhiều hơn nữa. Điều thú vị là chúng có thể thực hiện các tác vụ này từ hướng dẫn văn bản và/hoặc quan sát một vài minh chứng [2]. Hai thành phần chính quyết định thành công của chúng là: (a) quy mô mô hình xác định dung lượng của mô hình; và (b) điều chỉnh hướng dẫn, nhằm căn chỉnh mô hình để tuân theo hướng dẫn của người dùng [25].

Trong khi sự phổ biến của LLM đã nâng cao nhiều ứng dụng, một số lượng đáng kể các mô hình hiệu suất cao vẫn còn độc quyền, cản trở tiến bộ của việc khám phá khoa học. Nghiên cứu gần đây [14] về mở rộng mô hình đã cho thấy rằng với ngân sách tính toán nhất định, hiệu suất tốt nhất không nhất thiết được đạt bởi các mô hình lớn nhất, mà bởi các mô hình nhỏ hơn được huấn luyện trên nhiều dữ liệu hơn (đo bằng số lượng token). Một mô hình nhỏ hơn cũng thường được ưa thích về hiệu quả suy luận trong quá trình phục vụ bao gồm trên các thiết bị di động.

Khi LLM trở nên phổ biến, ứng dụng của chúng cho các chuỗi dài đã trở thành trọng tâm chính [33,30], đặc biệt cho các ứng dụng như viết mã, tóm tắt văn bản (có thể xen kẽ với dữ liệu khác

∗chỉ ra tác giả chính, †chỉ ra điều phối viên dự án chính và tác giả tương ứng.arXiv:2309.03450v1 [cs.CL] 7 Sep 2023

--- TRANG 2 ---
Bảng 1: Tóm tắt cấp cao về các mô hình XGen-7B.
Mô hình Mô tả
XGen-7B-4K Tiền huấn luyện cho 800B token với độ dài chuỗi 2K token đầu tiên,
sau đó cho 400B token khác (tổng 1.2T token) với 4K token.
XGen-7B-8K Khởi tạo với XGen-7B-4K-base và tiếp tục huấn luyện cho 300B token nữa
(tổng 1.5T token) với độ dài chuỗi 8K.
XGen-7B-Inst wizardLM Tinh chỉnh có giám sát của XGen-7B-8K trên dữ liệu hướng dẫn
WizardLM-196K mới phát hành [39].
XGen-7B-Inst general Tinh chỉnh có giám sát của XGen-7B-8K trên dữ liệu hướng dẫn lĩnh vực công cộng
tổng quát bao gồm OAsst5, Baize [40], Dolly2 [10], ShareGPT và SCROLLS [30].

nguồn như bảng và hình ảnh), và dự đoán chuỗi protein, cần mô hình hiệu quả xem xét các phụ thuộc cấu trúc khoảng cách xa. Một ngữ cảnh lớn cho phép LLM tiền huấn luyện xem xét dữ liệu khách hàng (ví dụ: tài liệu mà LLM không sử dụng trong huấn luyện) và phản hồi các truy vấn tìm kiếm thông tin hữu ích. Tuy nhiên, hầu hết các LLM mã nguồn mở (ví dụ: LLaMA [34], MPT2, Falcon3) đã được huấn luyện với độ dài chuỗi tối đa 2K token, đây là hạn chế chính trong mô hình hóa các chuỗi dài. Các giải pháp thời gian suy luận như ALiBi [26] vẫn chưa được kiểm tra đúng cách cho các mô hình lớn hơn (ví dụ: MPT-7B-StoryWriter-65k+).

Để giải quyết hạn chế trên, với các tính chất mở rộng và hiệu quả phục vụ, chúng tôi huấn luyện một loạt LLM 7B có tên XGen-7B với attention dày đặc tiêu chuẩn trên độ dài chuỗi lên đến 8K cho đến 1.5T token. Chúng tôi cũng tinh chỉnh các mô hình XGen-7B trên dữ liệu hướng dẫn lĩnh vực công cộng, tạo ra các phiên bản được điều chỉnh hướng dẫn (XGen-7B-Inst). Chúng tôi mở mã nguồn các mô hình cho cả nghiên cứu và ứng dụng thương mại. Bảng 1 tóm tắt các mô hình được phát hành của chúng tôi4.

Đánh giá của chúng tôi về XGen-7B-8K trên các benchmark tiêu chuẩn để đánh giá mô hình tiền huấn luyện cơ bản cho thấy nó đạt kết quả tương đương hoặc tốt hơn khi so sánh với các LLM mã nguồn mở tiên tiến. Nó cũng đạt kết quả tốt trên các tác vụ tạo mã Python. Các mô hình được điều chỉnh hướng dẫn của chúng tôi cũng cho thấy kết quả ấn tượng trên các benchmark AlpacaEval [16] và MTBench [43] được đề xuất gần đây, thường vượt trội hơn các mô hình cùng kích thước (ví dụ: WizardLM-7B, MPT-7B) và thậm chí lớn hơn (ví dụ: Falcon-40B-instruct, Alpaca-13B). Hơn nữa, đánh giá mục tiêu của chúng tôi về các tác vụ mô hình hóa chuỗi dài cho thấy lợi ích của các mô hình 8K-chuỗi so với các LLM mã nguồn mở 2K-chuỗi.

2 Dữ liệu Tiền huấn luyện
Bộ dữ liệu tiền huấn luyện của chúng tôi là hỗn hợp dữ liệu từ nhiều nguồn công cộng, được báo cáo trong Bảng 2. Chúng tôi sử dụng chiến lược huấn luyện hai giai đoạn, trong đó mỗi giai đoạn sử dụng hỗn hợp dữ liệu khác nhau, như được hiển thị trong Bảng 3.

Dữ liệu ngôn ngữ tự nhiên cho giai đoạn 1. Dữ liệu ngôn ngữ tự nhiên là hỗn hợp dữ liệu có sẵn công khai. Chúng tôi đã nỗ lực cải thiện tính an toàn và đa dạng của dữ liệu.

Dữ liệu mã cho giai đoạn 1. Chúng tôi sử dụng tập con GitHub từ bộ dữ liệu RedPajama mới phát hành [9]. Chúng tôi cũng thêm dữ liệu mã Apex để nâng cao khả năng tạo mã Apex của mô hình. Apex là ngôn ngữ lập trình hướng đối tượng được sử dụng rộng rãi trong các sản phẩm Salesforce.

Dữ liệu BigCode Starcoder cho giai đoạn 2. Chúng tôi sử dụng tất cả 86 ngôn ngữ lập trình từ dữ liệu Starcoder [15], bảo tồn trọng số gốc của mỗi ngôn ngữ. Sau đó, chúng tôi lọc thêm dữ liệu theo hướng dẫn giấy phép cho phép mạnh hơn.

Tokenizer. Chúng tôi tokenize dữ liệu bằng thuật toán mã hóa cặp byte (BPE) [29], sử dụng công cụ tiktoken của OpenAI, với GPT-2 làm tokenizer cơ bản. Ngoài ra, chúng tôi kết hợp các token đặc biệt bổ sung như được nêu trong bài báo Starcoder [15], cùng với khoảng trắng liên tiếp và tab nhằm hỗ trợ tạo mã.

2https://www.mosaicml.com/blog/mpt-7b
3https://falconllm.tii.ae/
4https://github.com/salesforce/XGen

--- TRANG 3 ---
Bảng 2: Hỗn hợp dữ liệu được sử dụng cho giai đoạn 1 tiền huấn luyện. Đối với mỗi tập con dữ liệu, chúng tôi báo cáo số lượng token hiệu quả và tỷ lệ lấy mẫu.
Bộ dữ liệu Token (B) Tỷ lệ lấy mẫu (%)
Dữ liệu ngôn ngữ tự nhiên 1309.99 95.31
Dữ liệu mã 64.53 4.69
Tổng 1374.52 100

Bảng 3: Hỗn hợp dữ liệu được sử dụng cho giai đoạn 2 tiền huấn luyện.
Bộ dữ liệu Token (B) Tỷ lệ lấy mẫu (%)
Dữ liệu từ giai đoạn 1 55 50
Dữ liệu BigCode Starcoder 55 50
Tổng 110 100

Xây dựng chuỗi với độ dài khác nhau. Trong giai đoạn 1 tiền huấn luyện, có 3 giai đoạn phụ, mỗi giai đoạn có độ dài chuỗi khác nhau: 2K, 4K và 8K token. Để đảm bảo tính toàn vẹn dữ liệu và ngăn chặn các dịch chuyển phân phối tiềm tàng, chúng tôi xáo trộn dữ liệu một cách đồng nhất và chia dữ liệu đã xáo trộn thành 3 khối lớn cho 3 giai đoạn phụ. Chúng tôi xây dựng các chuỗi huấn luyện bằng cách nối hoặc chia các tài liệu văn bản gốc thành độ dài chuỗi mục tiêu. Khi hai tài liệu khác nhau được nối, một token <|endoftext|> được thêm giữa chúng. Chúng tôi loại trừ các tài liệu ngắn chứa ít hơn 100 token sau tokenization. Sau đó chúng tôi xáo trộn các chuỗi huấn luyện được xây dựng một cách đồng nhất trong mỗi khối lớn. Dữ liệu cho giai đoạn 2 tiền huấn luyện (50% dữ liệu giai đoạn 1 và 50% dữ liệu Starcoder) chỉ có các chuỗi huấn luyện với độ dài 8k token.

3 Chi tiết Huấn luyện
Các mô hình XGen-7B được huấn luyện bằng thư viện JaxFormer [22] của chúng tôi, giúp huấn luyện hiệu quả các LLM dưới cả song song dữ liệu và mô hình được tối ưu hóa cho phần cứng TPU-v4. Công thức huấn luyện và kiến trúc mô hình tuân theo LLaMA [34], trong khi chúng tôi tiến hành hai khám phá bổ sung.

[Biểu đồ hiển thị: Cross-entropy theo thời gian với ba giai đoạn độ dài chuỗi 2K, 4K, 8K]

Hình 1: Cross-entropy theo thời gian huấn luyện. Mô hình được tiền huấn luyện trong ba giai đoạn với việc tăng từng bước độ dài chuỗi từ 2K đến 4K đến 8K token. Lưu ý, việc tiền huấn luyện không bị bất kỳ đột biến mất mát nào. Các đột biến tại các chuyển tiếp độ dài chuỗi là mong đợi khi mô hình điều chỉnh với mã hóa vị trí tăng độ dài. Sự giảm perplexity từ 2K đến 4K là mong đợi khi độ không chắc chắn giảm theo độ dài chuỗi cho các chuỗi dài.

--- TRANG 4 ---
[Biểu đồ hiển thị: Perplexity theo độ dài chuỗi cho các mô hình XGen khác nhau]

Hình 2: Perplexity theo độ dài chuỗi. Nếu một mô hình có thể sử dụng thông tin được mã hóa trong các chuỗi dài, thì theo kỳ vọng, perplexity sẽ giảm theo độ dài của các chuỗi đó. Tức là, thông tin chứa trong các token trước đó tăng sự chắc chắn của việc dự đoán token tiếp theo, có thể quan sát thấy trong hình. Lưu ý, perplexity của mô hình 8K so với mô hình 2K thường thấp hơn vì mô hình đã được huấn luyện thêm 700B token.

Đầu tiên, chúng tôi điều tra sự xuất hiện của cái gọi là "đột biến mất mát" [6,35,20] trong quá trình huấn luyện, tức là mất mát đột ngột bùng nổ tạm thời trong khi nguyên nhân gốc rễ của những đột biến này chưa được biết. Thứ hai, các mô hình XGen-7B hỗ trợ độ dài chuỗi lên đến 8,192 token (thay vì 2,048 thông thường) mà chúng tôi giới thiệu huấn luyện từng giai đoạn.

Công thức. Kiến trúc mô hình tuân theo LLaMA với khả năng tương thích số chính xác để dễ áp dụng trong các framework bên thứ ba. Các siêu tham số tuân theo chặt chẽ LLaMA-7B [34] với các thay đổi sau: (1) Ngân sách token đã được tăng từ 1.0T lên 1.5T token, (2) việc huấn luyện được thực hiện từng giai đoạn để tăng độ dài chuỗi từ 2K đến 4K đến 8K, (3) kích thước từ vựng đã được tăng từ 32,000 lên 51,200 token. Vòng lặp huấn luyện được triển khai trong JAX với Haiku mà toàn bộ tính toán ở độ chính xác số FP32, ngoại trừ matmul trong BF16.

Đột biến mất mát. Khi các mô hình được mở rộng lên kích thước lớn hơn, việc huấn luyện ngày càng nhạy cảm với bất ổn, gây ra hiệu suất mô hình kém nếu không được giải quyết cẩn thận [6,35,20]. Trong khám phá của chúng tôi, chúng tôi đã thu thập bằng chứng cho nhiều yếu tố, mỗi yếu tố đóng góp riêng lẻ vào việc huấn luyện không ổn định. Những phát hiện sơ bộ này bao gồm "mạch self-attention tuần tự so với song song", "swish-GLU so với GeLU", "RMS-Norm so với Layer-norm". Cụ thể, các mạch song song được sử dụng rộng rãi [6, 35,23], song song hóa tính toán của self-attention và feed-forward có thể ảnh hưởng đến tính ổn định của huấn luyện, ít nhất trong thiết lập cụ thể của chúng tôi. Như được áp dụng trong [34], sự kết hợp của chuẩn hóa kích hoạt dưới dạng RMS-Norm [42], self-attention tuần tự và swish-GLU [31] dường như có tính mạnh mẽ số cao, trong khi không tối ưu về hiệu quả tính toán.

Độ dài chuỗi. Huấn luyện với các chuỗi dài hơn tốn kém tính toán không tỷ lệ vì độ phức tạp của self-attention là bậc hai, tức là quá trình huấn luyện chậm. Để giảm thiểu huấn luyện chậm, chúng tôi giới thiệu huấn luyện theo giai đoạn với độ dài chuỗi tăng dần. Đầu tiên, 800B token với độ dài chuỗi 2K token được quan sát, sau đó 400B token với 4K, cuối cùng, 300B token với độ dài 8K. Hình 1 hiển thị cross-entropy theo các bước huấn luyện cho việc huấn luyện từng giai đoạn này. Chúng tôi xác minh sự thích ứng với các chuỗi dài hơn bằng cách tính perplexity trung bình tại mỗi vị trí token trên tập validation giữ lại chứa các tài liệu có độ dài chuỗi 8K hoặc cao hơn. Nếu mô hình học thành công việc sử dụng toàn bộ chuỗi, chúng tôi mong đợi perplexity giảm theo độ dài chuỗi, vì các token trước đó mang thông tin cho token tiếp theo cần dự đoán. Tức là, với một câu dài, càng nhiều ngữ cảnh dưới dạng từ trước được cung cấp, việc đoán từ tiếp theo càng trở nên dễ dàng. Hình 2 thực sự chứng minh rằng XGen-7B ở mỗi giai đoạn học thành công việc sử dụng ngữ cảnh dài hơn, lên đến độ dài chuỗi 8K.

--- TRANG 5 ---
4 Điều chỉnh Hướng dẫn
Để chứng minh khả năng hiểu và tạo ngôn ngữ của XGen-7B, chúng tôi thực hiện điều chỉnh hướng dẫn của LLM cơ bản và đánh giá các mô hình được điều chỉnh hướng dẫn.

Dữ liệu Hướng dẫn. Chìa khóa của điều chỉnh hướng dẫn là dữ liệu hướng dẫn được sử dụng để căn chỉnh mô hình tuân theo hướng dẫn của người dùng, đồng thời vô hại. Phát triển các mô hình độc quyền như GPT-4 [24] và Bard [21] bao gồm những nỗ lực chú thích đáng kể để thu thập dữ liệu như vậy. Các mô hình được điều chỉnh hướng dẫn mã nguồn mở đầu tiên [18] tận dụng các bộ dữ liệu học thuật bằng cách chuyển đổi chúng thành định dạng hướng dẫn với các mẫu prompt do con người viết [37,28,36]. Mặc dù lượng dữ liệu lớn được tuyển chọn theo cách này, khả năng tuân theo hướng dẫn của các mô hình này tụt hậu so với các mô hình độc quyền vì phân phối tác vụ được bao phủ bởi các benchmark học thuật này không khớp với các trường hợp sử dụng thực tế của LLM [25]. Do đó, các mô hình mã nguồn mở gần đây hơn [43,39] sử dụng dữ liệu tổng hợp ChatGPT hoặc GPT4, ví dụ: prompt do con người viết với phản hồi do GPT tạo hoặc prompt và phản hồi do GPT tạo. Quá trình chưng cất này giúp thu hẹp khoảng cách với các mô hình độc quyền. Một số ví dụ về các bộ dữ liệu này là Alpaca [32], ShareGPT6, Baize [40], GPTeacher7, và WizardLM [39].

Cho các thí nghiệm của chúng tôi, chúng tôi tinh chỉnh XGen-7B trong hai thiết lập dữ liệu:

•XGen-7B-Inst wizardLM: Cho thiết lập này, chúng tôi sử dụng WizardLM [39], là một trong những bộ dữ liệu hướng dẫn gần đây nhất. Nó được tạo bằng cách nhắc GPT-4 viết lại các hướng dẫn hiện có từ Alpaca [32] để làm cho chúng phức tạp hơn. Tinh chỉnh các mô hình LLaMA trên bộ dữ liệu này đã chứng minh hiệu suất cao trong nhiều benchmark đặc biệt cho các hướng dẫn phức tạp. Chúng tôi sử dụng bộ sưu tập WizardLM-196K để tinh chỉnh XGen-7B. Thiết lập này cho phép chúng tôi so sánh với mô hình WizardLM-7b [39], dựa trên LLaMA-7b và sử dụng cùng nguồn hướng dẫn.

•XGen-7B-Inst general: Trong thiết lập khác, chúng tôi sử dụng dữ liệu hướng dẫn lĩnh vực công cộng tổng quát bao gồm OAsst8, Baize [40], Dolly2 [10] và ShareGPT. Để đo lường tác động của ngữ cảnh dài, chúng tôi cũng bao gồm các ví dụ từ benchmark NLP chuỗi dài, SCROLLS [30]. Chúng tôi lấy mẫu khoảng 1,500 ví dụ từ mỗi bộ dữ liệu sau từ SCROLLS: GovReport, SummScreenFD, QMSum, NarrativeQA, Qasper và QuALITY. Chúng tôi lấy mẫu các ví dụ này sao cho mỗi ví dụ chứa ít nhất 4000 token. Thiết lập này nhằm cung cấp cho chúng tôi cảm nhận về khả năng tổng quát của mô hình trong việc tuân theo hướng dẫn cho các tác vụ chuỗi dài.

Chi tiết Tinh chỉnh. Chúng tôi sử dụng Adam với β1= 0.9 và β2= 0.99, phân rã cosine cho learning rate xuống 10% của giá trị ban đầu 2×10−5, kích thước batch 128, và độ dài chuỗi 8,192 token. Mỗi instance dữ liệu được định dạng như một cuộc hội thoại một lượt hoặc nhiều lượt giữa Con người và Trợ lý. Cụ thể, nó tuân theo định dạng:
### Human: {prompt} ### Assistant: {response}
Mục tiêu huấn luyện của chúng tôi là mô hình ngôn ngữ nhân quả và mất mát cho prompt được che dấu, do đó chỉ các gradient cho token phản hồi được lan truyền ngược. Chúng tôi huấn luyện các mô hình của chúng tôi trong 3 epoch.

6https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered
7https://github.com/teknium1/GPTeacher
8https://huggingface.co/datasets/OpenAssistant/oasst1

5 Đánh giá
5.1 Đánh giá Mô hình Cơ bản
5.1.1 Benchmark NLP Tiêu chuẩn

Trước tiên chúng tôi xem xét benchmark Massive Multitask Language Understanding [13], gần đây hơn và ít bị nhiễm dữ liệu như được báo cáo trong các nghiên cứu gần đây (xem trang 32 của báo cáo kỹ thuật GPT-4 [24] và thảo luận liên quan9). Benchmark đã được áp dụng rộng rãi cho đánh giá giữ lại [các tham chiếu].

9https://hitz-zentroa.github.io/lm-contamination/blog/?ref=blog.salesforceairesearch.com

--- TRANG 6 ---
Bảng 4: Kết quả five-shot (độ chính xác) trên Massive Multitask Language Understanding (MMLU).
Mô hình Nhân văn STEM Khoa học Xã hội Khác Trung bình có trọng số
XGen-7B 33.8 30.7 40.0 41.5 36.3
LLaMA-7B 33.9 30.6 38.2 38.2 35.1
OpenLLaMA-7B 28.1 28.5 31.2 32.8 29.9
Falcon-7B 26.5 25.4 29.2 26.8 26.9
MPT-7B 25.9 26.2 26.9 28.1 26.7
Redpajama-7B 26.1 25.2 27.4 26.7 26.3
Cerebras-GPT-13B 26.1 26.5 25.8 26.6 26.2
Dolly-v2-12B 26.9 25.7 25.3 26.5 26.2
OPT-13B 26.2 24.3 23.4 26.0 25.1
GPT-J-6B 25.9 24.0 24.0 25.8 25.1

Bảng 5: Độ chính xác zero-shot trên Massive Multitask Language Understanding (MMLU).
Mô hình Nhân văn STEM Khoa học Xã hội Khác Trung bình có trọng số
XGen-7B 31.4 27.8 32.1 37.2 32.1
LLaMA-7B 32.3 27.1 31.3 36.8 32.0
OpenLLaMA-7B 28.0 27.6 28.9 30.1 28.6
MPT-7B 27.4 25.2 26.0 30.7 27.4
Redpajama-7B 27.5 25.5 24.2 25.0 25.8
GPT-J-6B 25.3 24.5 25.5 27.6 25.7
Dolly-v2-12B 26.2 26.0 24.0 24.9 25.4
Cerebras-GPT-13B 24.3 25.0 23.0 26.0 24.6
OPT-13B 26.3 23.3 23.6 23.6 24.4
Falcon-7B 24.8 21.7 24.0 24.4 23.9

evaluation. Gần đây, tuy nhiên, sự không nhất quán trong báo cáo điểm MMLU đã được báo cáo, dẫn đến xếp hạng sai trong bảng xếp hạng Open LLM của Hugging Face. Trong công việc của chúng tôi, chúng tôi tuân theo tiêu chuẩn MMLU gốc, phù hợp với kết quả đã công bố (tức là trong LLaMA).

MMLU bao gồm các câu hỏi trắc nghiệm bao phủ nhiều lĩnh vực kiến thức khác nhau, bao gồm nhân văn, STEM và khoa học xã hội. Để đánh giá hiệu suất của các mô hình, chúng tôi tiến hành đánh giá trong cả thiết lập five-shot và zero-shot, sử dụng các câu hỏi mẫu từ benchmark. Kết quả cho five-shot MMLU được báo cáo trong Bảng 4, và kết quả cho zero-shot MMLU được báo cáo trong Bảng 5. Đối với cả hai thiết lập, XGen-7B đạt kết quả tốt nhất trong số các baseline trong hầu hết các danh mục, cũng như trong trung bình có trọng số.

Chúng tôi cũng báo cáo kết quả zero-shot tổng quát trên các benchmark NLP tiêu chuẩn khác liên quan đến lý luận common sense và QA: ARC challenge [8], HellaSwag [41], Winogrande [27], TruthfulQA [17], BoolQ [7], PiQA [1], và OpenBookQA [19]. Các bộ dữ liệu bao gồm các tác vụ kiểu Cloze và Winograd, cùng với trả lời câu hỏi trắc nghiệm. Đánh giá của chúng tôi tuân theo phương pháp zero-shot thường được sử dụng trong cộng đồng mô hình ngôn ngữ [12]. Như được hiển thị trong Bảng 6, XGen-7B đạt hiệu suất tương đương với các LLM tiên tiến cùng kích thước.

Bảng 6: Hiệu suất zero-shot trên các tác vụ Lý luận Common Sense và Trả lời Câu hỏi.
Mô hình MMLU-wavg ARC_ch HellaSwag Winogrande TruthfulQA BoolQ PiQA OpenBookQA
XGen-7B 32.1 41.2 74.2 64.9 39.1 74.3 75.5 40.2
LLaMA-7B 32.0 44.8 76.2 69.6 34.0 74.9 78.7 44.2
Falcon-7B 23.9 43.4 76.4 67.2 34.3 73.8 79.4 44.0
MPT-7B 27.4 41.7 76.1 68.6 33.4 74.1 79.1 41.8
OpenLLaMA-7B 28.6 38.7 71.8 67.0 35.2 70.6 76.0 39.0
Redpajama-7B 25.8 39.1 70.3 63.8 33.3 69.3 76.9 40.0
GPT-neox-20B 24.5 41.1 70.5 66.1 31.4 64.9 76.7 38.8
OPT-13B 24.4 35.8 69.9 64.7 33.9 65.0 75.7 39.8
GPT-J-6B 25.7 36.3 66.2 64.5 36.0 65.4 75.4 38.2
Dolly-v2-12B 25.4 39.6 70.8 61.8 34.4 56.3 75.4 39.2
Cerebras-GPT-13B 24.6 32.4 59.4 60.8 39.2 61.1 73.5 35.8
StableLM-alpha-7B 24.4 27.0 40.7 51.5 41.7 59.0 65.8 32.4

--- TRANG 7 ---
Bảng 7: Kết quả tạo mã từ ngôn ngữ tự nhiên theo pass@1 trên benchmark HumanEval. Đối với OpenLLaMA-7B-v2, chúng tôi lưu ý rằng dữ liệu Starcoder chiếm 30% dữ liệu tiền huấn luyện của họ. ∗Khoảng trắng liên tiếp được coi là một, phá vỡ cú pháp Python. ∗∗Mô hình không thể tạo mã có ý nghĩa.

Mô hình pass@1
XGen-7B 14.20
MPT-7B 15.90
OpenLLaMA-7B-v2 14.83
LLaMA-2-7B 13.55
LLaMA-7B 10.38
Redpajama-7B 5.24
OpenLLaMA-7B 0∗
Falcon-7B 0∗∗

5.1.2 Tạo Mã
Để đánh giá khả năng tạo mã của XGen-7B từ hướng dẫn ngôn ngữ tự nhiên (tức là docstring), chúng tôi đánh giá mô hình trên benchmark HumanEval [4]. HumanEval đánh giá khả năng viết mã Python của LLM ở cấp độ hàm bằng cách đánh giá tính đúng đắn chức năng. Chúng tôi báo cáo hiệu suất sử dụng chỉ số pass@1 [4]. Một mã được tạo được coi là đúng nếu nó vượt qua tất cả các unit test. Theo [4], chúng tôi đặt nhiệt độ lấy mẫu là 0.2, p=0.95 cho lấy mẫu top-p, và tạo n=200 mẫu cho mỗi bài toán trong benchmark để báo cáo điểm pass@1 không thiên vị. Như chúng ta có thể nhận thấy trong Bảng 7, XGen-7B của chúng tôi đạt kết quả tương đương với các LLM 7B tiên tiến.

Xem xét kích thước và kết quả trong cả tác vụ văn bản và mã, XGen-7B có thể là mô hình đa mục đích tốt có thể được phục vụ cả trên GPU kích thước tiêu chuẩn (ví dụ: bộ nhớ 16 GB) và thiết bị di động.

5.2 Đánh giá Mô hình Hướng dẫn
5.2.1 AlpacaEval

AlpacaEval10[16] là nền tảng đánh giá tự động mới được đề xuất sử dụng LLM làm đánh giá viên. Nó sử dụng bộ dữ liệu đánh giá AlpacaFarm [11], được tạo ra để đánh giá khả năng hiểu và tuân theo nhiều hướng dẫn người dùng của mô hình. Các phản hồi được tạo bởi các mô hình đang đánh giá sau đó được đối chiếu với các phản hồi tham chiếu từ text-davinci-003 [25], với GPT-4 [24] làm đánh giá viên. Tỷ lệ thắng so với text-davinci-003 được sử dụng làm chỉ số hiệu suất.

Như được hiển thị trong Bảng 8, mô hình được điều chỉnh hướng dẫn của chúng tôi, XGen-7B-Inst wizardLM (được tinh chỉnh trên WizardLM [39]), thường đạt hiệu suất tốt hơn so với các mô hình cùng kích thước khác, đáng chú ý là WizardLM-7B, sử dụng cùng kho lưu trữ hướng dẫn được chưng cất. Mô hình của chúng tôi hoạt động hơi kém hơn Vicuna-7B-v1.3, sử dụng nhiều dữ liệu ShareGPT hơn bao gồm prompt do con người tạo. Mô hình XGen-7B-Inst general hoạt động kém hơn XGen-7B-Inst wizardLM nhưng vẫn tốt hơn đáng kể so với text-davinci-003 và các lựa chọn thay thế mã nguồn mở khác như Falcon-40B-instruct và MPT-7B-chat.

10https://tatsu-lab.github.io/alpaca_eval/

5.2.2 MT-Bench
Tương tự như AlpacaEval, MT-Bench11[43] là benchmark mới để đánh giá trợ lý chat dựa trên LLM. Nó cũng sử dụng LLM làm thẩm phán (ví dụ: GPT-4) để đánh giá các mô hình trên các câu hỏi mở. Đánh giá mô hình được thực hiện theo hai cách:

Chấm điểm câu trả lời đơn. Trong thiết lập đánh giá này, LLM thẩm phán gán điểm trực tiếp cho mỗi phản hồi do mô hình tạo. Như được hiển thị trong Bảng 9, XGen-7B-Inst wizardLM vượt trội hơn các mô hình cùng kích thước khác (ngoại trừ Vicuna-7B-v1.3), đặc biệt là mô hình WizardLM-7B-Inst sử dụng tập hướng dẫn tương tự. Nó thậm chí vượt qua các mô hình lớn hơn, chẳng hạn như Falcon-40B-instruct hoặc MPT-30B-instruct.

11https://huggingface.co/spaces/lmsys/mt-bench

--- TRANG 8 ---
Bảng 8: Kết quả trên bảng xếp hạng AlpacaEval [16] với GPT-4 làm đánh giá viên.
Mô hình Tỷ lệ Thắng vs. text-davinci-003
GPT-4 95.3
Claude 88.4
ChatGPT 86.1
Vicuna-7B-V1.3 76.8
WizardLM-13B 75.3
Guanaco-65B 71.8
Vicuna-13B 70.4
XGen-7B-Inst wizardLM 68.8
WizardLM-7B 65.2
OAsst-RLHF-LLaMA-33B 66.5
Vicuna-7B 64.4
XGen-7B-Inst general 57.3
text-davinci-003 50.0
Falcon-40B-instruct 45.7
MPT-7B-chat 45.0
Alpaca-farm-PPO-human 41.2
Alpaca-7B 26.5
text-davinci-001 15.2

So sánh từng cặp. Trong thiết lập này, LLM thẩm phán được đưa ra một câu hỏi cùng với hai phản hồi mô hình từ hai mô hình cạnh tranh. Thẩm phán được giao nhiệm vụ xác định câu trả lời nào tốt hơn, hoặc tuyên bố rằng cả hai câu trả lời đều tốt như nhau. Từ kết quả trong Bảng 10, chúng ta thấy rằng ở đây các mô hình XGen-7B-Inst cũng vượt trội hơn các mô hình cùng kích thước khác và chúng vượt qua một số mô hình lớn hơn.

5.3 Tác vụ Chuỗi Dài
Ngoài các benchmark công cộng AlpacaEval và MT-Bench, chúng tôi cũng đánh giá XGen-7B và các mô hình mã nguồn mở cạnh tranh khác trên các tác vụ mô hình hóa chuỗi dài.

5.3.1 QA Dạng Dài
Để đánh giá khả năng lý luận của các LLM mã nguồn mở trên ngữ cảnh dài, chúng tôi thiết kế tác vụ QA dạng dài nội bộ với hai thiết lập. Cho một tài liệu đầu vào dài, (1) trước tiên chúng tôi nhắc ChatGPT (GPT-3.5-turbo) tạo câu hỏi với hướng dẫn rõ ràng sao cho câu trả lời không thể truy xuất trực tiếp từ ngữ cảnh với vài từ. Chúng tôi gọi thiết lập này là QG-passage. (2) Để tạo các câu hỏi trừu tượng hơn cần tổng hợp các yếu tố khác nhau từ các phần khác nhau của tài liệu đầu vào, trước tiên chúng tôi tóm tắt tài liệu rồi tạo câu hỏi về bản tóm tắt bằng ChatGPT tương tự như (1). Chúng tôi gọi thiết lập này là QG-summary. Chúng tôi cung cấp ví dụ về các prompt trong Phụ lục A.1.

Tiếp theo, chúng tôi nhắc các mô hình trả lời các câu hỏi được tạo từ ChatGPT trong hai thiết lập được đề cập ở trên. Lưu ý rằng chúng tôi biết câu trả lời đúng trong hai thiết lập. Chúng tôi đặt tối đa 512 token cho việc tạo. Chúng tôi sử dụng GPT-4 để đánh giá các phản hồi trên các câu trả lời được tạo và chấm điểm chúng trên thang điểm 0-3 cho các khía cạnh sau: mạch lạc, liên quan và chính xác.

Như được hiển thị trong Bảng 11, chúng tôi thấy rằng XGen-7B-Inst general vượt trội hơn tất cả các mô hình khác được so sánh. Cụ thể, chúng tôi thấy rằng tỷ lệ cho các mô hình XGen-7B-Inst cao hơn đối với các phản hồi được tạo về mạch lạc và liên quan. Nói chung, chúng tôi thấy rằng các câu hỏi được tạo từ tóm tắt thường khó hơn để tạo phản hồi điều này cho thấy độ khó của thiết lập tổng thể (Bảng 12). Những cải thiện này có thể được quy cho một phần vào khả năng mô hình hóa chuỗi dài của XGen.

5.3.2 Tóm tắt Đối thoại
Để đánh giá khả năng hiểu và tóm tắt đối thoại dài, chúng tôi thực hiện thí nghiệm trên ba tác vụ tóm tắt đối thoại: tóm tắt cuộc họp AMI [3], tóm tắt kịch bản từ bộ dữ liệu ForeverDreaming (FD) và TVMegaSite (TMS) [5]. Độ dài nguồn trung bình cho các bộ dữ liệu này lần lượt là 5570, 6466 và 7653 token.

Để đánh giá được hiển thị trong Bảng 13, chúng tôi tập trung vào các mẫu có độ dài ít hơn 8K và xem xét các mô hình được điều chỉnh hướng dẫn tương tự như trên. Đáng chú ý là cả mô hình MPT-7B-inst và Alpaca-7B đều hoạt động kém trong thiết lập này khi không áp dụng cắt ngắn đầu vào. Ngược lại, mô hình của chúng tôi (XGen-7B-Inst) đạt điểm ROUGE cao nhất trên tất cả các chỉ số.

--- TRANG 9 ---
Bảng 9: Đánh giá trên MT Bench [43] – Chấm điểm câu trả lời đơn bởi GPT-4.
Mô hình Điểm số
GPT-4 8.99
ChatGPT(GPT-3.5-turbo) 7.94
Claude-v1 7.90
Claude-instant-v1 7.85
Vicuna-33B-v1.3 7.12
WizardLM-30B 7.01
Guanaco-33B 6.53
Tulu-30B 6.43
Guanaco-65B 6.41
OAsst-SFT-7-LLaMA-30B 6.41
PaLM-2-chat-bison-001 6.40
MPT-30B-chat 6.39
Vicuna-13B-v1.3 6.39
WizardLM-13B 6.35
Vicuna-7B-v1.3 6.00
Baize-v2-13B 5.75
XGen-7B-Inst wizardLM 5.69
XGen-7B-Inst general 5.54
Nous-Hermes-13B 5.51
MPT-7B-chat 5.42
GPT4All-13B-snoozy 5.41
Koala-13B 5.35
WizardLM-7B 5.29
MPT-30B-instruct 5.22
Falcon-40B-instruct 5.17
H2OGPT-OAsst-Open-LLaMA-13B 4.63
Alpaca-13B 4.53
ChatGLM-6B 4.50
OAsst-SFT-4-pythia-12B 4.32
RWKV-4-raven-14B 3.98
Dolly-v2-12B 3.28
Fastchat-T5-3B 3.04
StableLM-tuned-alpha-7B 2.75
LLaMA-13B 2.61

6 Dấu chân Carbon
Để ước tính mức tiêu thụ năng lượng và lượng khí thải carbon dioxide kết quả từ việc huấn luyện XGen-7B, chúng tôi tuân theo [38]. Cụ thể, chúng tôi tính Mega-watt-hour (MWh) như sau:

MWh = TPU-hours × (TPU power consumption) × PUE (1)
= 270,336 × 192 × 1.10 (2)
= 57 (3)

trong đó chúng tôi đặt Power Usage Effectiveness (PUE) là 1.10 theo tiêu chuẩn. Lượng khí thải carbon kết quả phụ thuộc vào vị trí trung tâm dữ liệu. Đối với XGen-7B, điều này lên tới: tCO2eq = MWh (57) × 0.079 = 4.5. Trong Hình 3, chúng tôi hiển thị điều này so với các LLM khác.

--- TRANG 10 ---
Bảng 10: Đánh giá MT Bench [43] – So sánh Từng cặp bởi GPT-4.
Mô hình Thắng Thua Hòa Tỷ lệ Thắng Tỷ lệ Thua Tỷ lệ Thắng Điều chỉnh
GPT-4 111 7 42 69.4 43.8 82.5
Claude-v1 75 27 58 46.9 16.9 65.0
Vicuna-33B-v1.3 70 42 48 43.8 26.3 58.8
Claude-instant-v1 64 40 56 40.0 25.0 57.5
WizardLM-30B 37 63 60 23.1 39.4 41.9
Guanaco-33B 42 72 46 26.3 45.0 40.6
Guanaco-65B 38 68 54 23.8 42.5 40.6
Vicuna-13B-v1.3 33 73 54 20.6 45.6 37.5
MPT-30B-chat 29 78 53 18.1 48.8 34.7
Vicuna-7B-v1.3 60 165 95 18.8 51.6 33.6
WizardLM-13B 27 81 52 16.9 50.6 33.1
Tulu-30B 29 92 39 18.1 57.5 30.3
OAsst-SFT-7-LLaMA-30B 23 88 49 14.4 55.0 29.7
XGen-7B-Inst wizardLM 22 91 47 13.8 56.9 28.4
Baize-v2-13B 21 101 38 13.1 63.1 25.0
PaLM-2-chat-bison-001 18 102 40 11.3 63.8 23.8
XGen-7B-Inst general 17 108 35 10.6 67.5 21.6
Nous-Hermes-13B 12 104 44 7.5 65.0 21.3
GPT4All-13B-snoozy 14 108 38 8.8 67.5 20.6
MPT-7B-chat 18 214 88 5.6 66.9 19.4
H2OGPT-OAsst-Open-LLaMA-13B 19 118 23 11.9 73.8 19.1
Koala-13B 10 110 40 6.3 68.8 18.8
Falcon-40B-instruct 10 116 34 6.3 72.5 16.9
MPT-30B-instruct 7 120 33 4.4 75.0 14.7
ChatGLM-6B 6 124 30 3.8 77.5 13.1
OAsst-SFT-4-pythia-12B 8 128 24 5.0 80.0 12.5
RWKV-4-raven-14B 6 128 26 3.8 80.0 11.9
Alpaca-13B 13 265 42 4.1 82.8 10.6
Fastchat-T5-3B 5 132 23 3.1 82.5 10.3
Dolly-v2-12B 5 138 17 3.1 86.3 8.4

Bảng 11: Hiệu suất tổng thể của các mô hình khác nhau dựa trên đánh giá GPT-4 về QA dạng dài. Bảng hiển thị xếp hạng cá nhân và trung bình trên tất cả các chỉ số: mạch lạc, liên quan và chính xác.
Mô hình Mạch lạc Liên quan Chính xác Trung bình
XGen-7B-Inst general 2.81 2.72 2.70 2.74
Vicuna-7B-v1.3 2.77 2.64 2.58 2.66
XGen-7B-Inst wizardLM 2.78 2.68 2.50 2.65
WizardLM-7B 2.79 2.74 2.40 2.63
MPT-7B-instruct 2.55 2.48 2.30 2.43
Falcon-7B-instruct 2.28 2.22 1.75 2.08
Alpaca-7B 1.65 1.91 1.58 1.71

7 Lưu ý về Rủi ro Tiềm tàng
Cuối cùng, mặc dù những nỗ lực của chúng tôi trong việc giải quyết các rủi ro về thiên vị, độc tính và ảo giác cả trong giai đoạn tiền huấn luyện và tinh chỉnh, giống như các LLM khác, các mô hình XGen-7B không thoát khỏi những hạn chế như vậy. Chúng tôi hy vọng codebase mã nguồn mở của chúng tôi sẽ giúp các nhà nghiên cứu khác hiểu rõ hơn những thách thức này và cải thiện những hạn chế chính này để làm cho AI có lợi cho mọi người.

8 Kết luận
Trong báo cáo này, chúng tôi đã trình bày các mô hình XGen-7B mới phát triển hỗ trợ lên đến 8K token làm ngữ cảnh đầu vào. Chúng tôi đã mô tả quá trình tiền huấn luyện từng giai đoạn hiệu quả với các độ dài chuỗi khác nhau (2K →4K→8K) và hỗn hợp dữ liệu (chủ yếu văn bản →50% văn bản - 50% mã). Chúng tôi đã cho thấy

--- TRANG 11 ---
Bảng 12: Phân tích hiệu suất của các mô hình khác nhau trong hai thiết lập dựa trên đánh giá GPT-4. Bảng hiển thị xếp hạng trung bình trên tất cả các chỉ số cho câu hỏi được tạo từ đoạn văn (QG-passage) và tóm tắt (QG-summary).
Mô hình QG-passage QG-summary
XGen-7B-Inst general 2.79 2.68
Vicuna-7B-v1.3 2.71 2.61
XGen-7B-Inst wizardLM 2.71 2.60
WizardLM-7B 2.71 2.55
MPT-7B-instruct 2.50 2.35
Falcon-7B-instruct 2.22 1.95
Alpaca-7B 2.04 1.64

Bảng 13: Điểm ROUGE của các mô hình khác nhau trên tác vụ tóm tắt đối thoại dài.
Mô hình AMI FD TMS
R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L
XGen-7B-Inst general 31.34 8.25 17.00 29.34 5.39 16.43 26.39 3.94 13.71
XGen-7B-Inst wizardLM 25.56 6.71 16.84 8.97 0.90 5.49 19.15 1.86 9.53
Vicuna-7B-v1.3 14.23 2.01 9.05 16.49 1.00 9.99 17.06 1.49 8.85
Falcon-7B-instruct 14.89 1.97 9.28 18.90 1.80 9.37 18.90 1.80 9.37
MPT-7B-instruct 11.95 1.88 8.10 14.27 1.40 8.89 19.80 2.39 10.23
Alpaca-7B 9.69 1.77 6.43 16.26 1.56 10.66 12.26 1.15 7.30
WizardLM-7B 18.97 2.65 10.32 14.13 1.11 8.07 19.16 1.87 9.51

rằng mô hình kết quả đạt được kết quả tương đương hoặc tốt hơn trên các benchmark tạo văn bản và mã tiêu chuẩn so với các LLM mã nguồn mở tiên tiến.

Chúng tôi cũng đã mô tả quá trình tinh chỉnh của mô hình XGen-7B trên hai bộ dữ liệu hướng dẫn lĩnh vực công cộng khác nhau, tạo ra các phiên bản XGen-7B-Inst tương ứng. Kết quả trên hai benchmark phổ biến cho thấy các mô hình của chúng tôi thường vượt trội hơn các mô hình hiện có cùng kích thước và đôi khi thậm chí các mô hình lớn hơn nhiều. Sau đó chúng tôi đánh giá các mô hình trên các tác vụ mô hình hóa chuỗi dài, điều này xác nhận sự ưu việt của mô hình 8K-chuỗi so với các LLM 2K-chuỗi hiện có. Cuối cùng, chúng tôi hy vọng rằng việc mở mã nguồn các mô hình của chúng tôi sẽ góp phần vào khoa học mở trong việc hiểu các điểm mạnh và hạn chế của LLM và sẽ có tác động đáng kể đến kinh doanh và thương mại.

9 Đóng góp Tác giả
Tiền huấn luyện Mô hình Erik Nijkamp (dẫn đầu), Hiroaki Hayashi, Tian Xie, Chen Xing
Dữ liệu Tiền huấn luyện Tian Xie (dẫn đầu), Hiroaki Hayashi, Lidiya Murakhovs'ka
Đánh giá Congying Xia (dẫn đầu), Tian Xie, Erik Nijkamp, Rui Meng, Hiroaki Hayashi, Wojciech Kry ´sci´nski, Ye Liu, Lifu Tu, Meghana Bhat
Điều chỉnh Hướng dẫn (Mô hình) Bo Pang (dẫn đầu), Chen Xing
Điều chỉnh Hướng dẫn (Công cụ & Dữ liệu) Jesse Vig, Semih Yavuz, Chen Xing, Philippe Laban, Ben Krause, Senthil Purushwalkam, Tong Niu, Wojciech Kry ´sci´nski, Lidiya Murakhovs'ka, Prafulla Kumar Choubey, Alex Fabbri, Ye Liu, Rui Meng, Lifu Tu, Meghana Bhat
Điều phối Dự án Caiming Xiong (đồng dẫn đầu), Shafiq Joty (đồng dẫn đầu), Yingbo Zhou (đồng dẫn đầu), Chien-Sheng Wu, Silvio Savarese

--- TRANG 12 ---
[Biểu đồ hiển thị: Khí thải carbon của các mô hình khác nhau, với XGen (7B) có khoảng 4.5 tCO2eq, thấp hơn đáng kể so với các mô hình lớn hơn như GPT-3 (175B), BLOOM (175B), và PaLM (540B)]

Hình 3: Khí thải carbon của các mô hình khác nhau.

Tài liệu tham khảo
[1] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Reasoning about physical commonsense in natural language. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 7432–7439, 2020.

[2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

[3] Jean Carletta, Simone Ashby, Sebastien Bourban, Mike Flynn, Mael Guillemot, Thomas Hain, Jaroslav Kadlec, Vasilis Karaiskos, Wessel Kraaij, Melissa Kronenthal, Guillaume Lathoud, Mike Lincoln, Agnes Lisowska, Iain McCowan, Wilfried Post, Dennis Reidsma, và Pierre Wellner. The ami meeting corpus: A pre-announcement. In Proceedings of the Second International Conference on Machine Learning for Multimodal Interaction, MLMI'05, page 28–39, Berlin, Heidelberg, 2005. Springer-Verlag.

[4] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.

[5] Mingda Chen, Zewei Chu, Sam Wiseman, và Kevin Gimpel. SummScreen: A dataset for abstractive screenplay summarization. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8602–8615, Dublin, Ireland, May 2022. Association for Computational Linguistics.

[6] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.

[7] Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, và Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions. arXiv preprint arXiv:1905.10044, 2019.

[8] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457, 2018.

[9] Together Computer. Redpajama: An open source recipe to reproduce llama training dataset, April 2023.

[10] Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, và Reynold Xin. Free dolly: Introducing the world's first truly open instruction-tuned llm, 2023.

[11] Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. Alpacafarm: A simulation framework for methods that learn from human feedback, 2023.

--- TRANG 13 ---
[12] Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, và Andy Zou. A framework for few-shot language model evaluation, September 2021.

[13] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob Steinhardt. Measuring Massive Multitask Language Understanding. In International Conference on Learning Representations, 2021.

[14] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katherine Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Oriol Vinyals, Jack William Rae, và Laurent Sifre. An empirical analysis of compute-optimal large language model training. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.

[15] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, và Harm de Vries. Starcoder: may the source be with you!, 2023.

[16] Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. Alpacaeval: An automatic evaluator of instruction-following models. https://github.com/tatsu-lab/alpaca_eval, 2023.

[17] Stephanie Lin, Jacob Hilton, và Owain Evans. Truthfulqa: Measuring how models mimic human falsehoods. arXiv preprint arXiv:2109.07958, 2021.

[18] Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. The flan collection: Designing data and methods for effective instruction tuning. arXiv preprint arXiv:2301.13688, 2023.

[19] Todor Mihaylov, Peter Clark, Tushar Khot, và Ashish Sabharwal. Can a suit of armor conduct electricity? a new dataset for open book question answering. arXiv preprint arXiv:1809.02789, 2018.

[20] Igor Molybog, Peter Albert, Moya Chen, Zachary DeVito, David Esiobu, Naman Goyal, Punit Singh Koura, Sharan Narang, Andrew Poulton, Ruan Silva, et al. A theory on adam instability in large-scale machine learning. arXiv preprint arXiv:2304.09871, 2023.

[21] Ann E Nicholson, Kevin B Korb, Erik P Nyberg, Michael Wybrow, Ingrid Zukerman, Steven Mascaro, Shreshth Thakur, Abraham Oshni Alvandi, Jeff Riley, Ross Pearson, et al. Bard: A structured technique for group elicitation of bayesian networks to support analytic reasoning. arXiv preprint arXiv:2003.01207, 2020.

[22] Erik Nijkamp. Jaxformer: A minimal library for training llms on tpu. https://github.com/salesforce/jaxformer, 2022.

[23] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, và Caiming Xiong. Codegen: An open large language model for code with multi-turn program synthesis. arXiv preprint arXiv:2203.13474, 2022.

[24] OpenAI. Gpt-4 technical report, 2023.

[25] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744, 2022.

[26] Ofir Press, Noah Smith, và Mike Lewis. Train short, test long: Attention with linear biases enables input length extrapolation. In International Conference on Learning Representations, 2022.

--- TRANG 14 ---
[27] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, và Yejin Choi. Winogrande: An adversarial winograd schema challenge at scale. Communications of the ACM, 64(9):99–106, 2021.

[28] Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training enables zero-shot task generalization. arXiv preprint arXiv:2110.08207, 2021.

[29] Rico Sennrich, Barry Haddow, và Alexandra Birch. Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909, 2015.

[30] Uri Shaham, Elad Segal, Maor Ivgi, Avia Efrat, Ori Yoran, Adi Haviv, Ankit Gupta, Wenhan Xiong, Mor Geva, Jonathan Berant, và Omer Levy. SCROLLS: Standardized CompaRison over long language sequences. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 12007–12021, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.

[31] Noam Shazeer. Glu variants improve transformer. arXiv preprint arXiv:2002.05202, 2020.

[32] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca, 2023.

[33] Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, và Donald Metzler. Long range arena: A benchmark for efficient transformers. In International Conference on Learning Representations, 2021.

[34] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.

[35] Ben Wang và Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax, May 2021.

[36] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. Supernaturalinstructions: generalization via declarative instructions on 1600+ tasks. In EMNLP, 2022.

[37] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652, 2021.

[38] Carole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, Fiona Aga, Jinshi Huang, Charles Bai, Michael Gschwind, Anurag Gupta, Myle Ott, Anastasia Melnikov, Salvatore Candido, David Brooks, Geeta Chauhan, Benjamin Lee, Hsien-Hsin Lee, Bugra Akyildiz, Maximilian Balandat, Joe Spisak, Ravi Jain, Mike Rabbat, và Kim Hazelwood. Sustainable ai: Environmental implications, challenges and opportunities. In D. Marculescu, Y. Chi, và C. Wu, editors, Proceedings of Machine Learning and Systems, volume 4, pages 795–813, 2022.

[39] Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, và Daxin Jiang. Wizardlm: Empowering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244, 2023.

[40] Canwen Xu, Daya Guo, Nan Duan, và Julian McAuley. Baize: An open-source chat model with parameter-efficient tuning on self-chat data. arXiv preprint arXiv:2304.01196, 2023.

[41] Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, và Yejin Choi. Hellaswag: Can a machine really finish your sentence? arXiv preprint arXiv:1905.07830, 2019.

[42] Biao Zhang và Rico Sennrich. Root mean square layer normalization. Advances in Neural Information Processing Systems, 32, 2019.

[43] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, và Ion Stoica. Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.

--- TRANG 15 ---
A Phụ lục
A.1 QA Dạng Dài - Prompt được sử dụng cho Tạo Câu hỏi

Chúng tôi xây dựng phương pháp tạo câu hỏi như một quá trình hai bước: (1) Tóm tắt và (2) Tạo câu hỏi từ tóm tắt. Trong bước đầu tiên, chúng tôi thiết kế prompt để tạo tóm tắt như được hiển thị dưới đây:

Tóm tắt các đoạn văn dưới đây trong ngữ cảnh của {title} trong {domain}.

Trong bước tiếp theo, chúng tôi yêu cầu ChatGPT tạo câu hỏi từ tóm tắt như được hiển thị dưới đây:

Sử dụng ngữ cảnh dưới đây, đưa ra các câu hỏi tiếp theo sao cho câu trả lời vượt ra ngoài vài từ hoặc một vài cụm từ. Xếp hạng các câu hỏi được tạo theo thứ tự độ phức tạp giảm dần để trả lời và chỉ hiển thị top 3. {context}

Để chứng minh tính hữu ích của quá trình tạo câu hỏi của chúng tôi, chúng tôi cũng thiết lập baseline với cùng hướng dẫn trong đó câu hỏi được tạo trực tiếp từ đoạn văn. Prompt được sử dụng cho baseline là:

Sử dụng ngữ cảnh dưới đây, đưa ra các câu hỏi tiếp theo sao cho câu trả lời vượt ra ngoài vài từ hoặc một vài cụm từ. Xếp hạng các câu hỏi được tạo theo thứ tự độ phức tạp giảm dần để trả lời và chỉ hiển thị top 3. {context}

# 2309.08210.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2309.08210.pdf
# Kích thước tệp: 2119248 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Điều tra khả năng trả lời của LLM cho việc trả lời câu hỏi dạng dài
Meghana Moorthy Bhat Rui Meng Ye Liu Yingbo Zhou và Semih Yavuz
Salesforce Research
{meghana.bhat, ruimeng, yeliu, yingbo.zhou, syavuz}@salesforce.com
Tóm tắt
Khi chúng ta bước vào kỷ nguyên mới của LLM, việc hiểu rõ khả năng, hạn chế và sự khác biệt của chúng trở nên ngày càng quan trọng. Hướng tới việc đạt được tiến bộ hơn nữa trong hướng này, chúng tôi nỗ lực xây dựng hiểu biết sâu sắc hơn về khoảng cách giữa các LLM khổng lồ (ví dụ: ChatGPT) và các LLM mã nguồn mở nhỏ hơn nhưng hiệu quả cũng như các phiên bản đã được chưng cất của chúng. Để đạt được mục đích này, chúng tôi tập trung cụ thể vào việc trả lời câu hỏi dạng dài (LFQA) vì nó có một số ứng dụng thực tế và có tác động lớn (ví dụ: khắc phục sự cố, dịch vụ khách hàng, v.v.) nhưng vẫn chưa được nghiên cứu đầy đủ và thách thức đối với LLM. Chúng tôi đề xuất một phương pháp tạo câu hỏi từ các bản tóm tắt trừu tượng và cho thấy việc tạo ra các câu hỏi theo dõi từ các bản tóm tắt của các tài liệu dài có thể tạo ra một bối cảnh thách thức cho LLM để lập luận và suy luận từ các ngữ cảnh dài.
Kết quả thực nghiệm của chúng tôi xác nhận rằng: (1) phương pháp đề xuất của chúng tôi về việc tạo câu hỏi từ các bản tóm tắt trừu tượng đặt ra một thiết lập thách thức cho LLM và cho thấy khoảng cách hiệu suất giữa các LLM như ChatGPT và các LLM mã nguồn mở (Alpaca, Llama) (2) các LLM mã nguồn mở thể hiện sự phụ thuộc giảm vào ngữ cảnh đối với các câu hỏi được tạo ra từ tài liệu gốc, nhưng khả năng tạo ra của chúng giảm đáng kể đối với các câu hỏi được tạo ra từ các bản tóm tắt - đặc biệt là đối với các ngữ cảnh dài hơn (>1024 token).

1 Giới thiệu
Trong khi các Mô hình Ngôn ngữ Lớn (LLM) như ChatGPT, GPT-4 (OpenAI, 2023) đã thể hiện hiệu suất vượt trội trong các benchmark khác nhau, các nỗ lực mã nguồn mở cũng đang tiến bộ nhanh chóng để bắt kịp trong các ứng dụng và benchmark khác nhau như MMLU (Hendrycks et al., 2021), OpenLLMBoard (Anil et al., 2023; Beeching et al., 2023; Touvron et al., 2023). Khi chúng ta tiến vào kỷ nguyên mới của LLM với tiến bộ nhanh chóng về các mô hình và kỹ thuật mới, việc hiểu rõ khả năng, hạn chế và sự khác biệt giữa chúng trở nên ngày càng quan trọng.

Với khả năng tạo ra văn bản mạch lạc, LLM đã chứng minh hiệu suất tốt trong các nhiệm vụ như tóm tắt (Ouyang et al., 2022), hiệu suất của chúng trên LFQA tương đối ít được biết đến. Trả lời Câu hỏi Dạng Dài (LFQA) là một trong những thách thức quan trọng chưa được giải quyết với các ứng dụng thực tế đa dạng và có tác động lớn (ví dụ: diễn đàn trợ giúp, khắc phục sự cố, dịch vụ khách hàng, v.v.) Trả lời những câu hỏi như vậy thường đòi hỏi khả năng lập luận phức tạp để hiểu truy vấn và lập luận qua các khoảng thông tin phân tán trên tài liệu gốc.

Các bản tóm tắt trừu tượng chứa cốt lõi của các bài viết dưới dạng nén (Fabbri et al., 2020). Chúng tôi giả định rằng các câu hỏi theo dõi từ các bản tóm tắt này sẽ đòi hỏi hiểu biết sâu sắc hơn về các chủ đề mà sẽ liên kết các phần khác nhau của tài liệu nguồn. Hơn nữa, Pang et al. (2022) chứng minh rằng các câu trả lời đòi hỏi hiểu biết hơn một phần ba của tài liệu dài thường được con người đánh giá là "KHÓ". Do đó, chúng tôi đề xuất một phương pháp đánh giá có thể mở rộng để phân tích và nghiên cứu sự khác biệt của các LLM khổng lồ với các LLM cơ sở nhỏ hơn nhưng đã được chứng minh thành công (ví dụ: Llama-7B, 13B) và các phiên bản đã được chưng cất của chúng (ví dụ: Alpaca-7B, 13B). Để đạt được mục đích này, chúng tôi đề xuất nhắc ChatGPT với các hướng dẫn cụ thể để tạo ra các câu hỏi phức tạp từ các bản tóm tắt tài liệu.

Phân tích thực nghiệm của chúng tôi trên hai mặt (độ phức tạp của các câu hỏi được tạo ra và chất lượng câu trả lời của các LLM mã nguồn mở) cho thấy các câu hỏi theo dõi được tạo ra từ các bản tóm tắt đặt ra một thiết lập thách thức nhưng thực tế hơn để kiểm tra khả năng lập luận của LLM. Vì việc dựa hoàn toàn vào đánh giá của con người cho QA dạng dài là đắt đỏ và khó mở rộng (Pagnoni et al., 2021), thay vào đó chúng tôi tận dụng GPT-4 để đánh giá chất lượng câu trả lời về tính mạch lạc, liên quan, nhất quán thực tế và độ chính xác theo các công trình trước đó (Fabbri et al., 2020; Fan et al., 2019). Tuy nhiên, chúng tôi cũng thực hiện đánh giá của con người ở quy mô nhỏ hơn, cho thấy GPT-4 có mối tương quan cao với đánh giá của con người làm cho đánh giá của chúng tôi đáng tin cậy. Các phát hiện chính từ nghiên cứu này như sau:

•Phương pháp đề xuất của chúng tôi về việc tạo câu hỏi từ các bản tóm tắt trừu tượng đòi hỏi suy luận từ các ngữ cảnh dài hơn, với nhiều lần đọc qua ngữ cảnh > 20% thời gian.

•Các LLM đã được chưng cất (Alpaca-7B, 13B) có xu hướng phụ thuộc ít hơn vào ngữ cảnh đối với các câu hỏi được tạo ra từ tài liệu gốc, nhưng khả năng tạo ra của chúng giảm đáng kể đối với các câu hỏi được tạo ra từ các bản tóm tắt tài liệu.

•Các câu trả lời được tạo ra bởi các LLM đã được chưng cất có thể mạch lạc trong các bối cảnh khác nhau; nhưng có xu hướng lệch khỏi câu hỏi, tạo ra các câu trả lời lặp lại và một phần đúng cho các câu hỏi được tạo ra từ các bản tóm tắt (> 16.8%)

•Alpaca-7B, 13B chủ yếu tạo ra các câu trả lời có ý nghĩa hơn các LLM cơ sở (Llama) nhưng nhạy cảm với các ngữ cảnh dài hơn (>1024 token).

2 Các công trình liên quan
Lập luận trên Tài liệu Dài: LLM đã cho thấy khả năng tuyệt vời để lập luận trên một số nhiệm vụ như lập luận thông thường (Talmor et al., 2019), lập luận toán học và ký hiệu (Huang và Chang, 2023; Cobbe et al., 2021), các nhiệm vụ trả lời câu hỏi như SQuaD, HotpotQA. Tuy nhiên, hầu hết các nhiệm vụ này không yêu cầu ngữ cảnh dài và câu trả lời thường là một cụm từ ngắn hoặc một đoạn văn bản từ ngữ cảnh. Trong công trình này, chúng tôi đánh giá LLM để lập luận trên các tài liệu dài mà sẽ đòi hỏi khả năng hiểu biết sâu sắc hơn và ngữ cảnh dài hơn để trả lời bằng cách nhắc LLM (ChatGPT) tạo ra các câu hỏi theo dõi từ các bản tóm tắt của các tài liệu dài.

Đánh giá dựa trên Mô hình: Các công trình trước đó đã đề xuất các chỉ số đánh giá tự động sử dụng các mô hình đã học (Zhang* et al., 2020; Laban et al., 2022); đặc biệt là cho các nhiệm vụ tạo văn bản dạng dài như tóm tắt (Fabbri et al., 2020; Kryscinski et al., 2020) nơi tính nhất quán và mạch lạc được đo lường giữa tài liệu nguồn và bản tóm tắt được tạo ra như sự kéo theo. Gần đây, Liu et al. (2023) đã cho thấy GPT-4 có mối tương quan cao nhất với con người và vượt qua tất cả các phương pháp tự đánh giá khác trên các nhiệm vụ tóm tắt. Chúng tôi lấy cảm hứng từ những công trình này để thiết kế các lời nhắc đánh giá và sử dụng GPT-4 làm người đánh giá cho các câu trả lời được tạo ra.

3 Phương pháp Đánh giá Đề xuất
3.1 Nguồn Dữ liệu
Để tạo ra một bộ dữ liệu đa dạng và có thể sử dụng rộng rãi, chúng tôi sử dụng các bài viết Wikipedia. Sử dụng siêu dữ liệu của danh sách Danh mục từ API Wikipedia, chúng tôi kiểm soát tính đa dạng của các chủ đề và thu thập các bài viết từ mỗi trong số 9 lĩnh vực sau: Vật lý, Giải trí, Lịch sử, Khoa học Máy tính, Khoa học Xã hội, Xã hội, Kinh tế, Y học và Thể thao.

Các trang bài viết thường có thể dài để vừa với ngữ cảnh của LLM. Do đó, chúng tôi trích xuất dữ liệu theo từng phần từ các trang bài viết có độ dài tối thiểu 256 token bằng cách sử dụng SpaCy tokenizer và kết hợp các phần ngắn hơn lại với nhau. Để so sánh công bằng giữa các mô hình khác nhau, chúng tôi đặt độ dài ngữ cảnh tối đa là 2k token trong các thí nghiệm của chúng tôi. Ngoài ra, chúng tôi lọc ra các tài liệu không có thông tin sử dụng các bộ lọc tiền xử lý. Chi tiết thêm có sẵn trong Phụ lục A.5.

3.2 Tạo Câu hỏi sử dụng ChatGPT
Chúng tôi xây dựng phương pháp tạo câu hỏi của mình như một quy trình hai bước: (1) Tóm tắt và (2) Tạo câu hỏi từ bản tóm tắt.

Tóm tắt Đầu tiên, chúng tôi thu thập các đoạn văn theo từng phần từ Wikipedia như được mô tả trong Phần 3.1. Sau đó, chúng tôi nhắc ChatGPT (gpt-turbo-3.5) tạo ra bản tóm tắt của tài liệu gốc. Để cung cấp thêm ngữ cảnh cho ChatGPT, chúng tôi cung cấp thông tin về tiêu đề và lĩnh vực của bài viết trong đoạn văn.

Tạo câu hỏi từ bản tóm tắt Trong bước này, chúng tôi nhắc ChatGPT tạo ra các câu hỏi sử dụng các bản tóm tắt tài liệu làm ngữ cảnh. Để tránh việc tạo câu hỏi theo thứ tự ngẫu nhiên, chúng tôi hướng dẫn ChatGPT cung cấp 3 câu hỏi phức tạp hàng đầu để trả lời. Để chứng minh tính hữu ích của quy trình tạo câu hỏi của chúng tôi, chúng tôi cũng thiết lập một đường cơ sở với cùng hướng dẫn nơi các câu hỏi được tạo ra trực tiếp từ đoạn văn.

Vui lòng tham khảo phụ lục A.1 cho lời nhắc được sử dụng trong thiết lập của chúng tôi. Tóm lại, chúng tôi tạo ra 3 câu hỏi cho 50 đoạn văn trong mỗi lĩnh vực, tổng cộng 1350 câu hỏi cho mỗi thiết lập.

3.3 Đánh giá Độ phức tạp của Câu hỏi được Tạo ra
Pang et al. (2022) đã thiết kế các hướng dẫn chú thích mở rộng để đánh giá độ phức tạp của các câu hỏi. Trong số các câu hỏi được đánh giá là 'KHÓ' bởi con người, 26.7% câu hỏi (cao hơn 20.2% so với các câu dễ hơn)

--- TRANG 3 ---
Lựa chọn Câu hỏi
C1: Câu hỏi có thể trả lời được từ ngữ cảnh đã cho và không mơ hồ không? A. Có B. Không
C2. Cần bao nhiều đoạn văn làm ngữ cảnh để trả lời câu hỏi? A. Chỉ một hoặc hai câu
B. Nhiều hơn 2 câu nhưng ít hơn một đoạn văn
C. Ít nhất một phần ba của toàn bộ đoạn văn
D. Phần lớn đoạn văn
C3: Câu hỏi có đòi hỏi nhiều lần đọc qua đoạn văn không? A. Có B. Không

Bảng 1: Các lời nhắc được thiết kế để đánh giá độ phức tạp của các câu hỏi được tạo ra.

cần ít nhất một phần ba hoặc nhiều hơn thông tin đã cho để được trả lời. Để đánh giá chất lượng của các câu hỏi được tạo ra, chúng tôi nhắc ChatGPT với các câu hỏi (Bảng 1) cho (1) Từ đoạn văn (QG-Passage) (2) Từ bản tóm tắt (QG-Summary). Theo công trình trước đó, bằng cách bỏ phiếu đa số, chúng tôi loại trừ các câu hỏi được ChatGPT đánh giá là không thể trả lời bằng cách nhắc các câu hỏi với các top_p = {0.8, 0.9, 1} khác nhau. Sau khi lọc, chúng tôi có 1278 câu hỏi được tạo ra từ mỗi thiết lập.

Chỉ số Đánh giá QG - Passage QG - Summary
C1: Không mơ hồ 96.6% 94.7%
C2. Độ dài Ngữ cảnh:
Một câu hoặc ít hơn một đoạn văn 79.3% 75.7%
Ít nhất một phần ba hoặc phần lớn đoạn văn 20.7% 24.3%
C3: Đọc nhiều lần qua đoạn văn 24.4% 31%

Bảng 2: Các lời nhắc được thiết kế để đánh giá độ phức tạp của các câu hỏi được tạo ra.

4 Kết quả và Phân tích
4.1 Thiết lập Thí nghiệm
Vì thiết lập few-shot không khả thi trong bối cảnh của chúng tôi do độ dài ngữ cảnh, chúng tôi so sánh hiệu suất mô hình trên đánh giá zero-shot. Chúng tôi nhắc các mô hình sau để tạo ra văn bản tự do làm câu trả lời trên bộ dữ liệu đánh giá cuối cùng của chúng tôi: ChatGPT (OpenAI, 2023), Alpaca-7B, 13B (Taori et al., 2023), LLaMa-7B, 13B (Touvron et al., 2023). Chúng tôi sử dụng API OpenAI cho ChatGPT và tải các checkpoint cho các LLM mã nguồn mở từ HuggingFace1. Lời nhắc được sử dụng để tạo ra câu trả lời có trong Phụ lục A. Xin lưu ý rằng các thí nghiệm của chúng tôi không xem xét đầu vào vượt quá độ dài chuỗi 2k để so sánh công bằng với các mô hình khác. Chúng tôi cũng thử nghiệm tạo ra câu hỏi từ Alpaca và thấy chúng không tuân theo hướng dẫn và thường tạo ra nội dung không liên quan. Phân tích chi tiết của chúng tôi có thể tìm thấy trong Phụ lục A.2.

GPT-4 như một người đánh giá đã cho thấy mối tương quan cao với đánh giá của con người trong các nhiệm vụ tạo văn bản dạng dài như tóm tắt (Liu et al., 2023) vượt qua các chỉ số tự đánh giá khác như điểm ROUGE và BLEU. Vì LLM được mong đợi tạo ra các câu trả lời tự do cho thiết lập của chúng tôi, chúng tôi lấy cảm hứng từ các công trình trước đó về các chỉ số tạo văn bản dạng dài (Fabbri et al., 2020) và áp dụng chúng trong đánh giá của chúng tôi về tính mạch lạc, nhất quán, chính xác và liên quan. Về cơ bản, chúng tôi áp dụng các định nghĩa được sử dụng làm hướng dẫn cho đánh giá của con người vào phương pháp của chúng tôi như được thể hiện dưới đây:

Tính mạch lạc: Câu trả lời nên có cấu trúc tốt và được tổ chức tốt và không chỉ là một đống thông tin liên quan.

Tính liên quan: Câu trả lời nên liên quan đến câu hỏi và ngữ cảnh. Câu trả lời nên ngắn gọn và tránh lệch khỏi câu hỏi được hỏi.

Tính nhất quán thực tế: Ngữ cảnh nên là nguồn chính cho câu trả lời. Câu trả lời không nên chứa các sự kiện bịa đặt và nên kéo theo thông tin có trong ngữ cảnh.

Độ chính xác: Câu trả lời nên thỏa đáng và hoàn chỉnh đối với câu hỏi được hỏi. Đo lường tính đúng đắn của câu trả lời bằng cách kiểm tra xem phản hồi có trả lời câu hỏi được đưa ra không.

Chúng tôi nhắc GPT-4 đánh giá câu trả lời trên thang điểm từ 0 đến 3 (càng cao càng tốt) trên tất cả bốn chỉ số. Chúng tôi lấy trung bình tất cả các đánh giá thu được từ GPT-4 và trình bày kết quả trong Bảng 3. Lời nhắc đánh giá của chúng tôi có thể tìm thấy trong Phụ lục A.3.1.

Chúng tôi giả định rằng một lời nhắc tối ưu nên luôn ưu tiên câu trả lời của con người và không thiên vị đối với các câu trả lời do mô hình tạo ra. Laskar et al. (2023) cho thấy các LLM như ChatGPT vẫn kém hiệu suất so với con người trên bộ dữ liệu TruthfulQA (Lin et al., 2022). Do đó, chúng tôi thực hiện kiểm tra proxy với GPT-4 trên bộ dữ liệu TruthfulQA để xác minh độ tin cậy và trung thực của lời nhắc đánh giá của chúng tôi. Chúng tôi kiểm tra các câu trả lời được tạo ra từ ChatGPT và các LLM mã nguồn mở so với sự thật trên 50 trường hợp thử nghiệm được lấy mẫu ngẫu nhiên và thấy rằng lời nhắc đánh giá của chúng tôi với lời nhắc GPT-4 ưu tiên các câu trả lời do con người viết cho tính nhất quán thực tế và tính đúng đắn hơn các câu do mô hình tạo ra > 90% thời gian. Ngoài ra, chúng tôi cũng thực hiện đánh giá của con người về các câu trả lời do LLM tạo ra và thảo luận về mối tương quan của đánh giá GPT-4 với đánh giá của con người trong Phần A.4.

4.2 Kết quả
Kết quả thí nghiệm của chúng tôi cho thấy ChatGPT vượt trội hơn các LLM khác trong tất cả các chỉ số với biên độ lớn từ 22.4% - 40.1% so với mô hình

--- TRANG 4 ---
[Các biểu đồ thể hiện sự phân tích của các mô hình đối với các chỉ số khác nhau được sử dụng trong đánh giá]

Hình 1: Biểu đồ thể hiện sự phân tích của các mô hình đối với các chỉ số khác nhau được sử dụng trong đánh giá: (a) Tính mạch lạc (b) Tính liên quan (c) Độ chính xác Câu trả lời (d) Tính nhất quán Thực tế

Mô hình QG-Passage QG-Summary
không ngữ cảnh có ngữ cảnh không ngữ cảnh có ngữ cảnh
ChatGPT 2.78 2.93 2.67 2.82
Alpaca-13B 2.27 2.09 2.04 2.09
LlaMa-13B 1.22 1.47 0.98 1.28
Alpaca-7B 2.04 1.96 1.64 1.89
LlaMa-7B 0.89 1.12 0.66 0.78

Bảng 3: Hiệu suất của các mô hình khác nhau dựa trên đánh giá GPT-4. Bảng hiển thị điểm đánh giá trung bình trên tất cả các chỉ số: độ chính xác, tính mạch lạc, tính nhất quán, tính liên quan.

hiệu suất tốt thứ hai (Alpaca-13B). Tuy nhiên; tất cả các mô hình bao gồm ChatGPT tạo ra các câu trả lời ít chính xác và liên quan hơn cho QG-Summary khi so sánh với QG-Passage; trong khi khoảng cách lớn hơn nhiều trong các LLM mã nguồn mở. Chúng tôi cũng thấy rằng hầu hết các LLM thấy ngữ cảnh quan trọng để tạo ra câu trả lời; tuy nhiên, khoảng cách nhỏ hơn nhiều cho QG-Passage (khoảng cách trung bình 0.12 so với 0.2). Đáng ngạc nhiên, các mô hình Alpaca-7B, 13B hoạt động tốt hơn khi không có ngữ cảnh cho QG-Passage. Chúng tôi giả định rằng các câu hỏi được tạo ra trực tiếp từ đoạn văn ngữ cảnh có thể đơn giản và có thể được trả lời trực tiếp từ kiến thức tham số của LLM mà không cần ngữ cảnh bổ sung. Khi phân tích thêm, chúng tôi quan sát thấy hiệu suất của Alpaca-7B,13B giảm đáng kể trong các ngữ cảnh dài hơn (Hình 2). Chúng tôi giả định rằng trong thiết lập độ dài chuỗi bị hạn chế, việc thêm ngữ cảnh hỗ trợ (ngay cả đoạn văn vàng) có thể không phải lúc nào cũng hữu ích. Chúng tôi để lại phân tích thêm cho công việc tương lai và hy vọng phân tích của chúng tôi sẽ thúc đẩy các hướng nghiên cứu tương lai để nghiên cứu khi nào nên thêm/không thêm ngữ cảnh cho các nhiệm vụ khác nhau.

Hiệu suất của LLM trên các chỉ số khác nhau Hình 1 trình bày hiệu suất của các mô hình trên các chỉ số khác nhau cho QG-Summary. Chúng tôi quan sát hai xu hướng: (1) Các LLM cơ sở mã nguồn mở (Llama-7B,13B) gặp khó khăn ở tất cả các mặt trận đáng kể về chất lượng câu trả lời được tạo ra trong khi các mô hình đã được chưng cất hoạt động tốt hơn các đối tác của chúng (Llama) trên tất cả các thiết lập. (2) QG-Summary cung cấp một thiết lập thách thức hơn cho tất cả các LLM: cụ thể, chúng tôi nhận thấy rằng sự suy giảm trong điểm tính mạch lạc là không đáng kể trên ChatGPT và Alpaca-13B trong khi các chỉ số khác như tính liên quan, độ chính xác câu trả lời

<512 <1024 <2048
Độ dài Ngữ cảnh0.00.51.01.52.02.53.0Điểm Đánh giá Trung bình
llama7B alpaca7B llama13B alpaca13B chatgpt

Hình 2: Hiệu suất (điểm đánh giá trung bình) của các LLM trên độ dài ngữ cảnh khác nhau.

và tính nhất quán thực tế suy giảm một cách nhất quán. Chúng tôi thấy các LLM mã nguồn mở lệch khỏi câu hỏi, tạo ra các câu trả lời một phần đúng và lặp lại thường xuyên hơn trong thiết lập QG-Summary dẫn đến điểm số thấp hơn. Điều này càng xác nhận rằng phương pháp đánh giá đề xuất của chúng tôi QG-Summary thách thức LLM về khả năng lập luận sâu sắc hơn.

Phân tích Độ dài Ngữ cảnh Chúng tôi phân tích tác động của độ dài ngữ cảnh trên các LLM trong thiết lập đề xuất của chúng tôi (QG-Summary). Như mong đợi, ChatGPT vẫn mạnh mẽ đối với độ dài ngữ cảnh đến 2k token với các biến thể Llama hoạt động kém hơn các mô hình khác (Hình 2). Thú vị, chúng tôi thấy các mô hình đã được chưng cất (Alpaca) nhất quán đến 1024 token, tuy nhiên vượt quá > 1024 token, hiệu suất suy giảm với tốc độ cao hơn Llama.

5 Kết luận
Với sự xuất hiện của các LLM như ChatGPT và các LLM mã nguồn mở thành công, việc hiểu rõ khả năng và hạn chế của các LLM khác nhau là cực kỳ quan trọng. Để kiểm tra khả năng lập luận sâu sắc hơn của LLM bằng cách tham chiếu đến các ngữ cảnh dài hơn, chúng tôi đánh giá các câu trả lời được tạo ra bởi LLM trên các câu hỏi được tạo ra bởi ChatGPT trên các bản tóm tắt của các tài liệu dài. Kết quả cho thấy phương pháp tạo câu hỏi đề xuất của chúng tôi đặt ra một thiết lập thách thức cho LLM và làm sáng tỏ khoảng cách hiệu suất giữa các LLM khổng lồ và các LLM mã nguồn mở. Chúng tôi hy vọng phân tích của chúng tôi thúc đẩy các hướng nghiên cứu tương lai như tận dụng các ngữ cảnh dài hơn trong thiết lập độ dài chuỗi bị hạn chế và phát triển tạo văn bản dạng dài tốt hơn cho các LLM nhỏ hơn.

--- TRANG 5 ---
6 Hạn chế
Trong nghiên cứu này, chúng tôi đề xuất một thiết lập đánh giá tự động để tạo ra câu hỏi từ các bản tóm tắt, và các câu trả lời được tạo ra từ LLM được đánh giá bằng GPT-4 cho các chỉ số khác nhau. Kết quả thực nghiệm cho thấy thiết lập đánh giá đề xuất của chúng tôi chứng minh là một thiết lập thách thức cho LLM. Tuy nhiên, nghiên cứu của chúng tôi có thể có một số hạn chế.

GPT-4 như người đánh giá Trong khi GPT-4 đã cho thấy mối tương quan cao với đánh giá của con người cho tạo văn bản dạng dài (Liu et al., 2023), khả năng sử dụng GPT-4 cho đánh giá là một lĩnh vực nghiên cứu tích cực. Do đó, kết quả của chúng tôi có thể bị giới hạn bởi các khả năng chưa được khám phá của GPT-4.

ChatGPT cho tạo câu hỏi Tạo ra câu trả lời trên các câu hỏi được nhắc từ ChatGPT có thể dẫn đến kết quả lạc quan của ChatGPT. Tuy nhiên, tồn tại các hạn chế với các đường cơ sở khác để tạo ra các câu hỏi có ý nghĩa. Chúng tôi cho thấy phân tích mở rộng về việc sử dụng các LLM khác để tạo câu hỏi (Phụ lục A.2).

Dữ liệu huấn luyện chưa biết Ít được biết về phân phối dữ liệu huấn luyện của các LLM khổng lồ như ChatGPT. Các mô hình được huấn luyện bằng các phương pháp và phân phối dữ liệu khác nhau làm cho việc đánh giá để so sánh công bằng khó khăn hơn.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo đầy đủ được giữ nguyên như trong bản gốc]

--- TRANG 6 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 7 ---
A Phụ lục
A.1 Các lời nhắc được sử dụng cho Tạo Câu hỏi
Theo phân tích từ các công trình trước đó (Ko ˇciský et al., 2018; Pang et al., 2022), chúng tôi xây dựng phương pháp tạo câu hỏi của mình như một quy trình hai bước: (1) Tóm tắt và (2) Tạo câu hỏi từ bản tóm tắt. Trong bước đầu tiên, chúng tôi thiết kế lời nhắc để tạo ra bản tóm tắt như được thể hiện dưới đây:

Tóm tắt các đoạn văn dưới đây trong ngữ cảnh của {title} trong {domain}.

Trong bước tiếp theo, chúng tôi yêu cầu ChatGPT tạo ra câu hỏi từ bản tóm tắt như được thể hiện dưới đây:

Sử dụng ngữ cảnh dưới đây, đưa ra các câu hỏi theo dõi. Xếp hạng các câu hỏi được tạo ra theo thứ tự độ phức tạp giảm dần để trả lời và chỉ hiển thị 3 câu hàng đầu. {context}

Để chứng minh tính hữu ích của quy trình tạo câu hỏi của chúng tôi, chúng tôi cũng thiết lập một đường cơ sở với cùng hướng dẫn nơi các câu hỏi được tạo ra trực tiếp từ đoạn văn. Lời nhắc được sử dụng cho đường cơ sở là:

Sử dụng ngữ cảnh dưới đây, đưa ra ba câu hỏi. Xếp hạng các câu hỏi được tạo ra theo thứ tự độ phức tạp giảm dần để trả lời và chỉ hiển thị 3 câu hàng đầu. {context}

A.2 Tạo Câu hỏi sử dụng các LLM mã nguồn mở
Để tạo ra một thiết lập đánh giá công bằng, chúng tôi nhắc các mô hình Alpaca-7B,13B tóm tắt và tạo ra câu hỏi trên 50 trường hợp. Chúng tôi không xem xét việc tạo câu hỏi từ các mô hình không được điều chỉnh hướng dẫn (ví dụ: Llama). Từ phương pháp đánh giá của chúng tôi về câu hỏi được tạo ra như được mô tả trong Phần 4, chúng tôi thấy các câu hỏi được tạo ra từ Alpaca không thể trả lời được (không tồn tại trong ngữ cảnh) và chứa nội dung vô nghĩa hơn 80% thời gian. Bảng dưới đây trình bày đánh giá của chúng tôi về việc tạo câu hỏi từ Alpaca:

A.2.1 Đánh giá Tạo Câu hỏi sử dụng ChatGPT
Để xác minh độ phức tạp của các câu hỏi được tạo ra như được nêu trong Phần 4, chúng tôi nhắc ChatGPT với lời nhắc sau: [Lời nhắc đầy đủ được giữ nguyên như trong bản gốc]

Chỉ số Đánh giá QG - Passage QG - Summary
C1: Không mơ hồ 12.5% 8.3%
C2. Độ dài Ngữ cảnh:
Một câu hoặc ít hơn một đoạn văn 98.8% 98.5%
Ít nhất một phần ba hoặc phần lớn đoạn văn 1.2% 1.5%
C3: Đọc nhiều lần qua đoạn văn 0% 0%

Bảng 4: Các lời nhắc được thiết kế để đánh giá độ phức tạp của các câu hỏi được tạo ra trên Alpaca.

Vì LLM được huấn luyện với các hỗn hợp dữ liệu huấn luyện khác nhau, chúng tôi đặc biệt yêu cầu ChatGPT trả lời các câu hỏi chỉ dựa trên ngữ cảnh đã cho.

A.2.2 Lời nhắc cho Tạo Câu trả lời
Để tạo ra phản hồi trên các câu hỏi được tạo ra bởi LLM, chúng tôi nhắc như sau: Đối với mỗi câu hỏi được tạo ra, chúng tôi nhắc các mô hình như sau:

Cho ngữ cảnh, trả lời câu hỏi

--- TRANG 8 ---
dưới đây:
Ngữ cảnh: {context}
Câu hỏi: {question}
Câu trả lời: {Answer}

A.3 GPT-4 như một Người Đánh giá
A.3.1 Các lời nhắc được sử dụng trong Đánh giá GPT-4
Để đánh giá các câu trả lời được tạo ra bởi LLM, chúng tôi yêu cầu GPT-4 đánh giá câu trả lời trên thang Likert từ 0 đến 3 (càng cao càng tốt) trên tất cả bốn chỉ số sau: tính mạch lạc, tính liên quan, độ chính xác và tính nhất quán thực tế. Lời nhắc đánh giá của chúng tôi được sử dụng làm lời nhắc cho GPT-4 được thể hiện dưới đây:

[Lời nhắc đầy đủ cho GPT-4 được giữ nguyên như trong bản gốc]

A.4 Nghiên cứu Trường hợp: Đánh giá Con người so với GPT-4
Chúng tôi chú thích 50 cặp QA để đánh giá chất lượng câu trả lời được tạo ra bởi LLM độc lập với các đánh giá của GPT-4. Hai người chú thích được đưa ra các hướng dẫn tương tự như được nêu trong Phần 4 và một bảng câu hỏi như GPT-4 (Phần A.3.1). Để đánh giá công bằng, chúng tôi không tiết lộ mô hình đã tạo ra câu trả lời cho các người chú thích. Bảng 5 bao gồm điểm thỏa thuận của đánh giá con người với GPT-4. Điểm thỏa thuận cao trên các chỉ số khác nhau về tạo văn bản tự do cho thấy phương pháp đánh giá của chúng tôi sử dụng GPT-4 là đáng tin cậy. Chúng tôi cũng trình bày một số ví dụ định tính trong Phụ lục (Bảng 6)

Chỉ số Điểm Cohen-Kappa
Tính mạch lạc 0.66
Tính liên quan 0.7
Độ chính xác 0.66
Tính nhất quán Thực tế 0.56

Bảng 5: Điểm thỏa thuận của người chú thích với GPT-4

A.5 Thu thập Dữ liệu
Chúng tôi sử dụng API Wikipedia để thu thập các bài viết để tạo ra thiết lập đánh giá của chúng tôi. Tuy nhiên, chúng tôi thấy không phải tất cả các bài viết đều có thể hữu ích cho thiết lập của chúng tôi; chẳng hạn như các bài viết Wikipedia chứa liên kết tham khảo, danh sách chủ đề, từ điển thuật ngữ, v.v. Chúng tôi áp dụng hai cấp độ lọc: (1) Chúng tôi loại bỏ bất kỳ bài viết nào có < 2k token (2) chúng tôi tuyển chọn một danh sách các phần không có thông tin và lọc những phần đó khỏi việc xem xét trong nghiên cứu này. ['References', 'See also', 'Notes', 'Sources', 'External links', 'History', 'Further reading']

A.6 Ví dụ Định tính
Bảng dưới đây trình bày các ví dụ định tính từ nhiệm vụ chú thích của con người và cho thấy một số đánh giá

--- TRANG 9 ---
bởi con người và GPT-4.

--- TRANG 10 ---
Ví dụ Định tính
Câu hỏi 1: Sự khác biệt giữa nghiên cứu liên ngành và chuyên môn hóa trong một lĩnh vực duy nhất là gì?
Đánh giá: Vấn đề - Không có, Điểm con người - 3, GPT-4 - 3
ChatGPT: Nghiên cứu liên ngành bao gồm việc áp dụng các phương pháp và cách tiếp cận của một số lĩnh vực khác nhau cho một chủ đề, trong khi chuyên môn hóa trong một lĩnh vực duy nhất bao gồm nghiên cứu sâu và chuyên môn trong một chủ đề duy nhất.
Đánh giá: Vấn đề - Lặp lại, Điểm con người - 2, GPT-4 - 2
Alpaca-13B: Nghiên cứu liên ngành là sự kết hợp của hai hoặc nhiều lĩnh vực để tạo ra một lĩnh vực nghiên cứu mới. Chuyên môn hóa là việc tập trung vào một lĩnh vực duy nhất, với mục tiêu trở thành chuyên gia trong lĩnh vực đó. Nghiên cứu liên ngành là sự kết hợp của hai hoặc nhiều lĩnh vực để tạo ra một lĩnh vực nghiên cứu mới. Chuyên môn hóa là việc tập trung vào một lĩnh vực duy nhất, với mục tiêu trở thành chuyên gia trong lĩnh vực đó.

Câu hỏi 2: Quản lý tài sản tốt đòi hỏi lãnh đạo, giao tiếp, hợp tác và cải tiến liên tục như thế nào?
Đánh giá: Vấn đề - Không có, Điểm con người - 3, GPT-4 - 3
Alpaca-13B: Quản lý tài sản tốt đòi hỏi lãnh đạo, giao tiếp, hợp tác và cải tiến liên tục. Lãnh đạo được yêu cầu để đặt ra các ưu tiên chiến lược và đảm bảo rằng tổ chức phù hợp với các mục tiêu. Giao tiếp được yêu cầu để đảm bảo rằng tổ chức nhận thức được các mục tiêu và các chiến lược để đạt được chúng. Hợp tác được yêu cầu để đảm bảo rằng tổ chức đang làm việc cùng nhau để đạt được các mục tiêu. Cải tiến liên tục được yêu cầu để đảm bảo rằng tổ chức không ngừng nỗ lực cải thiện hiệu suất của mình.
Đánh giá: Vấn đề - Độ chính xác, Điểm con người - 1, GPT-4 - 1
Alpaca-7B: Quản lý tài sản tốt đòi hỏi lãnh đạo, giao tiếp, hợp tác và cải tiến liên tục.

Câu hỏi 3: Bốn lĩnh vực mà CSAB coi là quan trọng đối với ngành khoa học máy tính là gì?
Đánh giá: Vấn đề - Tính nhất quán Thực tế, Điểm con người - 1, GPT-4 - 3
Alpaca-7B: 1. Lý thuyết tính toán 2. Lý thuyết tính toán được 3. Lý thuyết ngôn ngữ lập trình 4. Phương pháp hình thức
ChatGPT: Bốn lĩnh vực mà CSAB coi là quan trọng đối với ngành khoa học máy tính là lý thuyết tính toán, thuật toán và cấu trúc dữ liệu, phương pháp luận và ngôn ngữ lập trình, và các yếu tố và kiến trúc máy tính.

Bảng 6: Một số ví dụ về các câu trả lời được tạo ra từ LLM với đánh giá GPT-4 và con người
Chú giải LLM, Những không nhất quán bị bỏ qua bởi mô hình Những không nhất quán được phát hiện bởi GPT-4.

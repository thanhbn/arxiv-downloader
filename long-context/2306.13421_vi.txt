# 2306.13421.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2306.13421.pdf
# Kích thước tệp: 801468 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Retrieval-Pretrained Transformer: Mô hình ngôn ngữ tầm xa với
Tự truy xuất
Ohad Rubin Jonathan Berant
Khoa Khoa học Máy tính Blavatnik, Đại học Tel Aviv
{ohad.rubin,joberant}@cs.tau.ac.il
Tóm tắt
Các mô hình ngôn ngữ được tăng cường
truy xuất (LMs) đã nhận được nhiều sự chú ý
gần đây. Tuy nhiên, thông thường bộ truy xuất
không được huấn luyện chung như một thành
phần bản địa của LM, mà được thêm vào sau
khi LM đã được huấn luyện trước, điều này
hạn chế khả năng thích ứng lẫn nhau giữa LM
và bộ truy xuất. Trong nghiên cứu này, chúng
tôi đề xuất Retrieval-Pretrained Transformer
(RPT), một kiến trúc và quy trình huấn luyện
để huấn luyện chung một LM được tăng cường
truy xuất từ đầu và áp dụng nó vào nhiệm vụ
mô hình hóa văn bản dài. Cho một đoạn văn
bản được tạo gần đây trong một tài liệu dài,
LM tính toán các biểu diễn truy vấn, sau đó
được sử dụng để truy xuất các đoạn trước đó
trong tài liệu, nằm có thể cách hàng chục nghìn
token. Thông tin từ các đoạn được truy xuất
được hợp nhất vào các biểu diễn LM để dự
đoán đoạn mục tiêu tiếp theo. Chúng tôi huấn
luyện thành phần truy xuất với một mục tiêu
ngữ nghĩa, trong đó mục tiêu là truy xuất các
đoạn làm tăng xác suất của đoạn tiếp theo, theo
một LM tham chiếu. Chúng tôi đánh giá RPT
trên bốn nhiệm vụ mô hình ngôn ngữ tầm xa,
bao gồm sách, mã và viết toán học, và chứng
minh rằng RPT cải thiện chất lượng truy xuất
và sau đó là perplexity trên toàn bộ so với các
baseline mạnh.
1 Giới thiệu
Các mô hình ngôn ngữ lớn (LMs) đã có thành công
to lớn gần đây (Brown et al., 2020; Chowdhery
et al., 2022; Zhang et al., 2022; Touvron et al.,
2023), trở thành một công cụ hữu ích trên nhiều
lĩnh vực. Tuy nhiên, thành công của chúng đi kèm
với chi phí tính toán, do số lượng tham số tăng để
lưu trữ kiến thức thế giới (Fedus et al., 2022) và
độ dài ngữ cảnh tăng cho phép truy cập thông tin
xa xôi, nhưng phải chịu phạt độ phức tạp bậc hai.
Tương tự từ vựngSách hoặcVăn bản dàiTương tự ngữ nghĩa
Truy xuất⋮Hợp nhất⋮
Tín hiệu Huấn luyệnPθ (……....|……………...)𝑐!" 𝑐#$! 𝑐#$# >Pθ (……....|……………...)𝑐!$$ 𝑐#$! 𝑐#$# Đoạn 100Đoạn 13Trạng thái Quá khứ
Dự đoánMô hình Ngôn ngữ Nhân quảĐoạn 201
Đoạn 202Truy vấn
Mục tiêuĐầu vào
ThamchThamchKẻ giết người để lại một căn phòng đầy bằng chứng, một câu đố cho pháp y.Khi còn nhỏ, Trung úy Johnthấy một con chó chết; từ đó, màu đỏ thắm luôn làm chohắn lo lắng.Trung úy John nhìn quanh, "Một nạn nhân khác, Kẻ Giết Người Đỏ Thắm lại tấn công."
"Tôi cá những người pháp y sẽ thích cái này."Hình 1: Retrieval-Pretrained Transformer (RPT) là một
mô hình ngôn ngữ được huấn luyện từ đầu với khả năng truy xuất
bản địa có thể được áp dụng cho văn bản dài (ví dụ, sách). RPT
nhận một đoạn văn bản làm đầu vào, truy xuất các đoạn liên quan
ngữ nghĩa từ quá khứ để dự đoán tốt hơn đoạn tiếp theo, và hợp
nhất các đoạn được truy xuất này vào các biểu diễn của nó. Trên
cơ sở một loss LM tiêu chuẩn, bộ truy xuất được huấn luyện để
truy xuất các đoạn làm tăng xác suất của đoạn tiếp theo theo một
LM tham chiếu.
Mô hình ngôn ngữ được tăng cường truy xuất (RALM)
giảm bớt chi phí này (Khandelwal et al., 2020; Yo-
gatama et al., 2021; Borgeaud et al., 2022; Ram
et al., 2023), vì việc truy xuất chính xác thông tin
liên quan có thể giảm yêu cầu về bộ nhớ và tính
toán. Hơn nữa, RALM có lợi cho tính chính xác,
tính mới và khả năng tổng quát hóa mà không cần
huấn luyện lại, chỉ đơn giản bằng cách thay đổi chỉ
mục truy xuất (Guu et al., 2020; Lewis et al., 2020;
Huang et al., 2023).
Tuy nhiên, các nghiên cứu trước về RALM phần lớn
đã không huấn luyện bộ truy xuất như một thành phần
hạng nhất của LM. Trong một số trường hợp (Khandelwal et al., 2020;arXiv:2306.13421v2  [cs.CL]  21 Jul 2024

--- TRANG 2 ---
Yogatama et al., 2021; Borgeaud et al., 2022), bộ
truy xuất chỉ được sử dụng tại thời điểm kiểm tra,
hoặc vẫn cố định trong suốt quá trình huấn luyện,
ngăn cản nó thích ứng với bộ sinh LM. Trong các
trường hợp khác, thành phần truy xuất được huấn
luyện chung nhưng chỉ sau một giai đoạn huấn luyện
trước riêng biệt cho cả bộ truy xuất và LM (Sachan
et al., 2021; Izacard et al., 2022b; Jiang et al., 2022;
Bertsch et al., 2023). Vì vậy, bộ truy xuất không
được huấn luyện trước từ đầu với LM, và chỉ một
phần ngân sách huấn luyện được phân bổ cho huấn
luyện chung.
Gần đây, Zhong et al. (2022) đã trình bày một
LM được tăng cường truy xuất huấn luyện bộ truy
xuất từ đầu cùng với LM, nhưng (a) bộ truy xuất
được huấn luyện để khai thác chỉ thông tin từ vựng,
và (b) thông tin được truy xuất không được hợp
nhất ở cấp độ biểu diễn trở lại vào LM.
Trong nghiên cứu này, chúng tôi trình bày Retrieval-Pretrained
Transformer (RPT), một LM được tăng cường truy
xuất, trong đó bộ truy xuất là một thành phần hạng
nhất, được huấn luyện chung từ đầu với LM. RPT
dựa trên hai đóng góp kỹ thuật. Đầu tiên, về mặt
kiến trúc (xem Hình 1), các biểu diễn đầu vào cho
bộ truy xuất được tính toán từ chính các biểu diễn
LM (một khái niệm chúng tôi gọi là tự truy xuất),
và các biểu diễn được truy xuất được hợp nhất trở
lại vào bộ giải mã LM để đưa ra dự đoán từ tiếp
theo. Thứ hai, chúng tôi huấn luyện bộ truy xuất
với một hàm loss phụ khuyến khích truy xuất các
đoạn văn bản làm tăng xác suất sinh ra văn bản
tiếp theo. Cụ thể, cho một đoạn được tạo gần đây
ct, bộ truy xuất được huấn luyện để truy xuất các
đoạn ci làm tăng xác suất chấm điểm (ct+1|ci, ct)
theo một LM chấm điểm tham chiếu. Hình 1 cung
cấp một ví dụ minh họa cho trường hợp mô tả hiện
trường tội phạm, và một LM chấm điểm cho thấy
lợi ích của việc truy xuất một đoạn cách hàng nghìn
token (đoạn 13) so với truy xuất từ vựng, dẫn đến
một đoạn chỉ liên quan bề ngoài (đoạn 100). Không
giống như các mô hình được tăng cường truy xuất
hiện có sử dụng một bộ mã hóa phụ cho truy xuất
(Izacard and Grave, 2021a; Izacard et al., 2022b;
Sachan et al., 2021), RPT có thể tận dụng các trạng
thái ẩn nội bộ của mình cho truy xuất sau một giai
đoạn huấn luyện trước duy nhất, đơn giản hóa đáng
kể việc huấn luyện chung.
Chúng tôi áp dụng RPT vào vấn đề mô hình hóa
các tài liệu dài, chẳng hạn như sách, bài báo và
mã, vì đây là những ví dụ xuất hiện tự nhiên của
nội dung dài, trong đó toàn bộ chỉ mục có thể được
giữ trong bộ nhớ trong một lần chuyển tiếp. Chúng tôi đánh giá RPT trên bốn nhiệm vụ mô hình
ngôn ngữ và thấy rằng nó cải thiện perplexity trên
tất cả các nhiệm vụ, vượt trội hơn các nghiên cứu
trước (Hutchins et al., 2022; Wu et al., 2022) cũng
như các baseline mạnh (Borgeaud et al., 2022; Zhong
et al., 2022). Hơn nữa, chúng tôi cho thấy RPT truy
xuất các đoạn chất lượng cao so với các bộ truy xuất
dựa trên thông tin từ vựng. Dựa trên các phát hiện
thực nghiệm của chúng tôi, chúng tôi lập luận RPT
có thể mở đường cho thế hệ tiếp theo của các LM
được huấn luyện trước, trong đó các kho dữ liệu
lớn được sử dụng trong quá trình huấn luyện trước,
dẫn đến các mô hình ngôn ngữ trong đó truy xuất
là một thành phần được nhúng mạnh mẽ. Mã của
chúng tôi có sẵn công khai tại
https://github.com/OhadRubin/RPT.
2 Bối cảnh
Để định vị đóng góp của chúng tôi, chúng tôi xem
xét các nghiên cứu RALM liên quan gần đây. Chúng
tôi mở rộng điều này cho các nghiên cứu liên quan
khác trong §6.
Các nghiên cứu sớm về RALMs, chẳng hạn như
kNN-LM (Khandelwal et al., 2020) đã sử dụng truy
xuất để cải thiện mô hình ngôn ngữ bằng cách nội
suy phân phối từ tiếp theo được tạo bởi LM với
một phân phối được đề xuất thông qua cơ chế truy
xuất chỉ tại thời điểm kiểm tra. Borgeaud et al.
(2022) sau đó đề xuất Chunked Cross-Attention
(CCA), trong đó truy xuất cũng được thực hiện tại
thời điểm huấn luyện, và kết quả truy xuất được
hợp nhất sâu vào các biểu diễn được tạo bởi một
bộ giải mã Transformer thông qua attention. Tuy
nhiên, bộ truy xuất được huấn luyện riêng biệt và
giữ cố định trong quá trình huấn luyện, điều này
ngăn cản nó thích ứng với LM trong suốt quá trình
huấn luyện.
TRIME (Zhong et al., 2022), giống như nghiên
cứu này, đã huấn luyện một LM được tăng cường
truy xuất từ đầu trong đó thành phần truy xuất và
LM giải mã được huấn luyện chung. Nghiên cứu
của chúng tôi khác với TRIME ở hai khía cạnh:
Đầu tiên, TRIME, giống như kNN-LM, kết hợp
thông tin từ bộ truy xuất theo cách nông qua nội
suy phân phối, trong khi chúng tôi áp dụng CCA
như một cơ chế hợp nhất sâu hơn. Thứ hai, TRIME
tận dụng các gợi ý từ vựng để giám sát bộ truy xuất,
tức là, cho một truy vấn, bộ truy xuất TRIME học
truy xuất các ngữ cảnh sẽ dẫn đến việc tạo ra cùng
một token như truy vấn. Ngược lại, chúng tôi sử
dụng một LM chấm điểm để đánh giá các đoạn văn
bản nào có liên quan để tăng xác suất của đoạn được
tạo, điều này dẫn đến truy xuất ngữ nghĩa hơn. Điều
này tương tự như EPR (Rubin et al., 2022), đã sử
dụng ý tưởng này để học truy xuất các gợi ý cho
học tập trong ngữ cảnh, và chưng cất perplexity
trong Atlas (Izacard et al.,

--- TRANG 3 ---
2022b). Tuy nhiên, Atlas không huấn luyện bộ truy
xuất và LM từ đầu và là một mô hình mã hóa-giải
mã, phù hợp hơn cho các nhiệm vụ chuyên sâu về
kiến thức. Ngược lại, chúng tôi huấn luyện từ đầu
và sử dụng một mô hình giải mã, phù hợp hơn cho
việc mô hình hóa văn bản dài.
3 Retrieval-Pretrained Transformer
Thiết lập vấn đề Giống như RETRO (Borgeaud et al.,
2022), RPT là một LM được tăng cường truy xuất
theo đoạn, chia chuỗi đầu vào thành các đoạn để
truy xuất. Cụ thể, cho một chuỗi L token đầu vào,
(x1, x2, . . . , xL), chúng tôi phân chia nó thành một
chuỗi ℓ=L/m đoạn không chồng lấp có độ dài m,
được ký hiệu bởi C= (c1, c2, . . . , cℓ). Đối với mỗi
đoạn truy vấn có thể, cq=ci, mô hình sẽ truy xuất
một tập con tối đa K≪ℓ đoạn, R(cq)⊂ C<i= (c1, c2, ..., ci−w),
trong đó C<i là tập hợp các đoạn có thể truy xuất
cho ci, loại trừ w đoạn mà nó đã có quyền truy cập
thông qua attention nhân quả tự. Mục tiêu là học
một mô hình truy xuất một tập con đoạn, R(cq),
làm tăng xác suất sinh tự động của đoạn mục tiêu
ct=ci+1.
Chúng tôi trình bày phương pháp của mình theo hai
phần. Đầu tiên, kiến trúc của chúng tôi (§3.1), tận
dụng CCA để hợp nhất các biểu diễn được truy xuất
vào LM, nhưng thêm một thành phần truy xuất được
học. Thứ hai, chúng tôi trình bày phương pháp huấn
luyện (§3.2-§3.3), trong đó bộ truy xuất được huấn
luyện để truy xuất các đoạn hữu ích cho việc tạo ra
một đoạn tương lai theo một LM tham chiếu.
3.1 Kiến trúc Mô hình
Hình 2 minh họa kiến trúc của chúng tôi, trong đó
đầu vào có 45 token đầu vào được chia thành 9 đoạn,
và attention nhân quả tự được áp dụng trên w= 3
đoạn (15 token). Phía bên trái mô tả ngăn xếp giải
mã ("bộ đọc"), và phía bên phải là bộ truy xuất. Bộ
đọc được chia thành hai, trong đó n/2 lớp dưới (bộ
giải mã dưới) là các lớp giải mã Transformer tiêu
chuẩn nhận w đoạn làm đầu vào và xuất ra các biểu
diễn sẽ được sử dụng bởi bộ truy xuất và các lớp
giải mã trên.
n/2 lớp trên (bộ giải mã trên) sử dụng Chunked
Cross-Attention (CCA) để hợp nhất thông tin từ
các đoạn hàng xóm top-K được truy xuất bởi bộ
truy xuất trở lại vào LM. Chúng tôi sử dụng các
lớp CCA tiêu chuẩn từ RETRO (Borgeaud et al.,
2022), trong đó đối với mỗi một trong ℓ đoạn, các
truy vấn là các biểu diễn m token của đoạn đó được
xuất ra bởi attention nhân quả, và các khóa và giá
trị là các biểu diễn token cho các đoạn hàng xóm
top-K được xuất ra bởi bộ truy xuất.¹
Tiếp theo, chúng tôi mô tả thành phần truy xuất,
cùng với cơ chế cổng hàng xóm để điều chế tác
động của các biểu diễn được truy xuất.
Bộ truy xuất Bộ truy xuất nhận các biểu diễn được
xuất ra bởi bộ giải mã dưới làm đầu vào và tạo ra
một điểm số tương tự cho mỗi cặp đoạn. Cho một
đoạn truy vấn cq, điểm số dựa trên truy vấn cho
mỗi đoạn có thể truy xuất c là sq(c) =⟨WQcq, WKc⟩,
trong đó WQ, WK∈Rd×d là các phép chiếu tuyến
tính được học, và cq và c là các biểu diễn đoạn.
Đối với một đoạn dài m token c, chúng tôi tính toán
biểu diễn c của nó bằng cách áp dụng attention hai
chiều trên các token đoạn, sau đó là mean-pooling
theo chiều thời gian. Điều này duy trì tính nhân
quả, vì các biểu diễn này chỉ được sử dụng trong
quá trình dự đoán đoạn tiếp theo.
Khi điểm số cho tất cả các cặp đoạn được tính toán,
các đoạn hàng xóm được truy xuất R(cq), cho mỗi
đoạn truy vấn, cq, bao gồm các đoạn có thể truy xuất
có điểm số cao nhất top-K của nó. Sau đó, đối với
mỗi đoạn cj∈ R(cq), chúng tôi nối các biểu diễn
của đoạn tiếp theo cj+1 để cung cấp ngữ cảnh bổ
sung, và biểu diễn cuối cùng cho tất cả các hàng
xóm của tất cả các đoạn được cho bởi một tensor
C∈Rℓ×K×2m×d.²
Tổng thể (và không giống như các phương pháp
như TRIME và kNN-LM), bộ truy xuất là một phần
không thể thiếu của LM, trong đó bộ giải mã dưới
tính toán các biểu diễn cho bộ truy xuất (mà chúng
tôi gọi là tự truy xuất), và bộ giải mã trên tiêu thụ
các biểu diễn được tạo bởi bộ truy xuất.
Cổng hàng xóm Chúng tôi thêm một cơ chế cổng
hàng xóm để lựa chọn mềm các biểu diễn hàng xóm
hữu ích để hợp nhất vào bộ giải mã trên. Cho
Ci,k∈R2m×d là các biểu diễn token cho hàng xóm
thứ k của đoạn ci. Chúng tôi mean-pool theo chiều
thời gian để có được một vector ĉi,k cho mỗi đoạn
hàng xóm. Sau đó, chúng tôi làm phong phú biểu
diễn hàng xóm của mỗi đoạn bằng cách áp dụng
attention nhân quả – một biểu diễn đoạn hàng xóm
ĉi,k attend đến các đoạn đứng trước nó hoặc đến
các hàng xóm của cùng một đoạn ci được xếp hạng
cao hơn. Cuối cùng, đối với mỗi đoạn, chúng tôi có
được biểu diễn được truy xuất có cổng bằng cách
nhân các biểu diễn được tăng cường với một điểm
số cổng:
¹Để biết chi tiết đầy đủ về CCA, xem Borgeaud et al. (2022).
²Tương tự như RETRO, các biểu diễn token của các đoạn
được truy xuất cũng được tăng cường thông qua cross-attention
trên các token của đoạn truy vấn, cq.

--- TRANG 4 ---
Attention NhânquảTầng Feed ForwardChunked Cross AttentionTop-KQKVAttention Nhân quả
Pool + ProjectTầng Feed Forward
Bi-directionalAttention⟨|||||||||⋅aaaa		=7.1𝑐1𝑐1𝑐1𝑐8𝑐1𝑐1𝑐1𝑐1⟨|||||||||⋅aaaa		=0.3𝑐1𝑐1𝑐1𝑐8𝑐1𝑐1𝑐1𝑐2⟨|||||||||⋅aaaa		=5.2𝑐1𝑐1𝑐1𝑐8𝑐1𝑐1𝑐1𝑐3⟨|||||||||⋅aaaa		=10.8𝑐1𝑐1𝑐1𝑐8𝑐1𝑇1𝑐1𝑐!⟨|||||||||⋅aaaa		=−∞𝑐1𝑐1𝑐1𝑐8𝑐1𝑐1𝑐1𝑐" ⋮⟨|||||||||⋅aaaa		=4.8𝑐1𝑐1𝑐1𝑐8𝑐1𝑐1𝑐1𝑐# ⋮ĐỌC𝑐1𝑐2𝑐3𝑐4𝑐5𝑐6𝑐7𝑐8𝑐9×	𝑛!"#$%&2Hàng xóm được mã hóa
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1Token Đầu vào
Bộ Giải mã DướiChấm điểm đoạnCổng hàng xóm
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1
𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1𝑐1Bộ Truy xuấtBộ Giải mã Trên
×	𝑛!"#$%&2Hình 2: Kiến trúc của Retrieval-Pretrained Transformer, trong đó một đầu vào 45 token được hiển thị, bao gồm
9 đoạn, và attention nhân quả tự được áp dụng trên 15 token. Phía bên trái hiển thị ngăn xếp giải mã, trong đó
n/2 lớp dưới là các lớp giải mã Transformer tiêu chuẩn, và n/2 lớp trên cũng bao gồm các lớp chunked cross-attention
hợp nhất thông tin từ các đoạn được truy xuất. Phía bên phải hiển thị bộ truy xuất, nhận một đoạn và truy xuất
K đoạn có điểm số cao nhất đã xuất hiện trước đó trong tài liệu.
Cgi,k= max {η, σ(wng ĉi,k
d)} ·Ci,k trong đó wng là
một vector tham số được học, η là một giá trị nhỏ
nhằm duy trì dòng gradient,³ và σ là hàm kích hoạt
sigmoid. Cuối cùng, trong bộ giải mã trên, khi CCA
được thực hiện, các khóa và giá trị là Cgi,k.
3.2 Tín hiệu Giám sát
Đối với mỗi đoạn truy vấn cq=ci, chúng tôi muốn
xác định các đoạn hàng xóm sẽ hữu ích cho việc
tạo ra ct=ci+1, và sử dụng những đoạn hàng xóm
đó làm tín hiệu giám sát cho bộ truy xuất. Tương
tự như Rubin et al. (2022), chúng tôi có thể khai
thác thực tế rằng chúng tôi đang tạo ra dữ liệu huấn
luyện và sử dụng thông tin từ chính ct để tạo ra
điểm số như vậy. Không giống như Zhong et al.
(2022), người chỉ sử dụng các gợi ý từ vựng, chúng
tôi sẽ sử dụng một LM chấm điểm độc lập cho mục
đích này.
Chấm điểm mỗi đoạn w.r.t tất cả các đoạn trước
đó là bậc hai theo số lượng đoạn trong một tài liệu,
và do đó khó tính toán. Vì vậy, chúng tôi sử dụng
một bộ truy xuất không giám sát BM25 đơn giản
(Robertson and Zaragoza, 2009) nhận đầu vào là
sự nối của các đoạn (cq, ct) = (ci, ci+1) và trả về
một tập hợp các đoạn hàng xóm ứng viên, R̄ ⊂ C(cq),
có độ chồng lấp từ vựng cao với đoạn hiện tại và
tiếp theo. Bộ truy xuất này có quyền truy cập vào
các token cần được tạo bởi LM, điều này được cho
phép tại thời điểm huấn luyện.
Cho ĝ là một LM được huấn luyện độc lập, và cho
c̄j là sự nối (cj, cj+1). Chúng tôi tính toán một
điểm số st(c̄j) phản ánh liệu thông tin trong c̄j có
hữu ích hơn cho việc giải mã ct so với các đoạn
gần với cq. Cụ thể, điểm số dựa trên mục tiêu cho
một đoạn ứng viên là
st(c̄j) = logProb ĝ
ct|cj, cj+1, cq
Prob ĝ(ct|ci−2, ci−1, cq).
Điểm số này là dương khi thông tin trong c̄j hữu
ích hơn cho việc giải mã ct so với thông tin trong
hai đoạn trước đó (ci−2, ci−1).
Chúng tôi áp dụng hàm chấm điểm này cho tất cả
các đoạn, và định nghĩa cho mỗi đoạn truy vấn cq
tập hợp các đoạn dương Rqpos, bao gồm các ứng
viên mà st(·)>0. Điều này sẽ dẫn đến các đoạn
hữu ích, vì mỗi đoạn ứng viên ít nhất là tốt như
ngữ cảnh địa phương. Với thứ tự này trong tầm tay,
chúng tôi có thể áp dụng các phương pháp huấn
luyện truy xuất tiêu chuẩn.
3.3 Huấn luyện
Để huấn luyện các tham số của thành phần truy
xuất, chúng tôi thích ứng loss LambdaRank được
sử dụng rộng rãi (Burges et al., 2006). Loss cho
mỗi đoạn truy vấn
³Chúng tôi đặt η= 0.1 trong tất cả các thí nghiệm của mình.

--- TRANG 5 ---
cq (w.r.t các đoạn có thể truy xuất của nó) là:
Lret(cq) =
X
{j,l:c̄l∈Rqpos,st(c̄l)>st(c̄j)}λjlmax (0 , τ−(sq(cl)−sq(cj)))
trong đó τ là siêu tham số margin, và λjl là hệ số
quy mô LambdaRank xem xét thứ hạng tương đối
của mỗi ứng viên. Loss này khác không khi đối
với một số cặp ứng viên, điểm số dựa trên mục
tiêu không đồng ý (với margin τ) với thứ hạng của
điểm số dựa trên truy vấn cho các ứng viên trong
Rqpos. Tối ưu hóa hàm loss này cho phép RPT phân
biệt giữa các đoạn liên quan và không liên quan.
Loss cuối cùng của chúng tôi là LLM+αretLret, trong
đó LLM là loss LM tiêu chuẩn và αret là hệ số loss
truy xuất, tăng tuyến tính trong 100K bước đầu.
Chúng tôi cũng tăng τ tuyến tính trong quá trình
huấn luyện.
3.4 Chi tiết Triển khai Quan trọng
Lấy mẫu theo lịch trình Để giảm sự không khớp
giữa huấn luyện-kiểm tra, chúng tôi áp dụng lấy
mẫu theo lịch trình (Bengio et al., 2015) trong
quá trình huấn luyện. Cụ thể, sau khi tính toán
các đoạn hàng xóm top-K, chúng tôi sử dụng những
hàng xóm này với xác suất 1−pss, và với xác suất
pss các ứng viên có điểm số top-K từ Rqpos làm
đầu vào cho CCA. Chúng tôi ủ pss từ 1 về 0 trong
90% đầu của quá trình huấn luyện với lịch trình
cosine. Điều này cho phép mô hình dần dần học
sử dụng các dự đoán của chính mình. Chúng tôi
báo cáo hiệu ứng của điều này trong §5.3.
Attention cửa sổ trượt tại thời điểm huấn luyện
và suy luận Như mô tả trong §3, bộ giải mã nhận
w đoạn, mỗi đoạn có m token làm đầu vào, và áp
dụng attention nhân quả trên chúng. Trong thực
tế, để cung cấp cho các token đầu tiên quyền truy
cập vào các token trước đó, chúng tôi sử dụng cơ
chế attention cửa sổ trượt (Dai et al., 2019; Beltagy
et al., 2020; Ivgi et al., 2023), trong đó số lượng
token trong một cửa sổ là 2,048 và stride là 1,024.
Vì vậy, đầu vào cho mỗi cửa sổ là 2,048 token và
đầu ra là các biểu diễn cho 1,024 token cuối cùng,
sử dụng các khóa và giá trị của 1,024 token trước
đó để ngữ cảnh hóa.
Tại thời điểm suy luận, một quy trình tương tự
được áp dụng. Chúng tôi tính toán và cache các
biểu diễn khóa và giá trị cho các đoạn 1,024 token,
sử dụng chúng làm ngữ cảnh để tạo ra hoặc ước
tính xác suất của đoạn tiếp theo.
Truy xuất tại thời điểm suy luận Trong quá trình
huấn luyện, chúng tôi mã hóa trong mỗi batch các
chuỗi có độ dài 16K và truy xuất các đoạn từ
những 16k token được mã hóa đó. Tuy nhiên, tại thời điểm suy luận, bộ truy xuất cung cấp quyền
truy cập vào tất cả các token từ đầu tài liệu, trong
đó chúng tôi lưu trữ các biểu diễn khóa và bộ giải
mã dưới trong một chỉ mục Faiss (Douze et al.,
2024) trên CPU. Đối với mỗi đoạn, chúng tôi truy
vấn chỉ mục bằng các biểu diễn truy vấn của đoạn
và truy xuất các biểu diễn bộ giải mã dưới top-K
với tích vô hướng cao nhất.
Chi tiết bổ sung Tại thời điểm huấn luyện, chúng
tôi sử dụng các chuỗi có độ dài L= 16,384 token,
được chia thành 4 thiết bị, mỗi thiết bị tiêu thụ
4,096 token. Như đã đề cập, ngăn xếp giải mã
nhận 2,048 token làm đầu vào (theo cách tiếp cận
cửa sổ trượt), chứa ℓ= 32 đoạn có độ dài m= 64.
Chúng tôi sử dụng Rotary Positional embedding
(Su et al., 2024), và huấn luyện tất cả các mô hình
trong 500K bước trên TPUv4-64, với kích thước
batch hiệu quả là 217 token dẫn đến tổng ngân
sách huấn luyện là 65 tỷ token.
Đối với tất cả các mô hình được huấn luyện, chúng
tôi sử dụng tokenizer GPT-NeoX (Black et al.,
2022), được huấn luyện trên Pile (Gao et al., 2020)
và bao phủ các lĩnh vực chúng tôi đánh giá (xem
§4). Làm mô hình ngôn ngữ chấm điểm của chúng
tôi, chúng tôi sử dụng phiên bản khử trùng lặp 1.4B
tham số của Pythia (Biderman et al., 2023), và
chấm điểm với nó 20 ứng viên BM25 hàng đầu.
Mô hình của chúng tôi có 12 lớp, chiều ẩn d= 1024,
và 8 đầu attention với chiều đầu là 128. Chúng tôi
áp dụng CCA với 2 hàng xóm, trừ khi được đề cập
khác. Chi tiết triển khai bổ sung trong Phụ lục A
và độ phức tạp lý thuyết của các lớp CCA trong
Phụ lục B.
4 Bộ dữ liệu LM Tầm xa
Chúng tôi đánh giá RPT trên bốn bộ dữ liệu, bao
phủ các lĩnh vực như sách, mã và viết toán học,
đòi hỏi khả năng gọi lại thông tin qua khoảng cách
xa. Bảng 1 và Hình 3 cung cấp thống kê về kích
thước bộ dữ liệu và phân phối độ dài tài liệu, cho
thấy các tài liệu dài trên tất cả các bộ dữ liệu và
đặc biệt là PG19 và Books3, trong đó các tài liệu
thường chứa 105 token trở lên. Chúng tôi xem xét
ngắn gọn các bộ dữ liệu.

--- TRANG 6 ---
0510%ArXiv
0510%CodeParrot
0510%PG19
102103104105106107
Độ dài chuỗi0510%Books3Hình 3: Biểu đồ phân phối độ dài tài liệu theo token
trên tất cả các bộ dữ liệu. Trục x ở thang logarit.
PG19 Được giới thiệu trong Rae et al. (2020), PG19
là một benchmark mô hình ngôn ngữ tầm xa được
sử dụng rộng rãi chứa sách từ Project Gutenberg,
và bao phủ một loạt các thể loại văn học, phong
cách và chủ đề. Chúng tôi áp dụng thiết lập và
phân chia dữ liệu chính xác từ các nghiên cứu trước
(Wu et al., 2022; Hutchins et al., 2022; Mehta et al.,
2023).
Books3 là một corpus sách được phát hành như
một phần của Pile (Gao et al., 2020), chứa một
bộ sưu tập rộng lớn các tác phẩm văn học từ các
lĩnh vực khác nhau. Theo hiểu biết của chúng tôi,
chúng tôi là những người đầu tiên sử dụng corpus
này như một benchmark mô hình ngôn ngữ tầm xa.⁴
CodeParrot (Wolf et al., 2023) là một corpus mã
Python sạch, gần như khử trùng lặp từ các kho
GitHub khác nhau. Mô hình hóa mã đòi hỏi hiểu
các mẫu và ngữ cảnh hóa thông tin qua khoảng cách
xa, làm cho nó trở thành một ứng viên tự nhiên để
kiểm tra các LM tầm xa. Trong các thí nghiệm của
chúng tôi, chúng tôi theo cách tiếp cận của Wu
et al. (2022), kết hợp các tệp từ cùng một kho lưu
trữ để xây dựng một corpus với các chuỗi dài hơn,
và tạo ra một phân chia train/test (xem Bảng 1).
ArXiv là một corpus các bài báo preprint được
trích xuất từ ArXiv. Nó bao gồm các văn bản toán
học đòi hỏi duy trì tính mạch lạc và tham chiếu
đến thông tin đã đề cập trước đó trong văn bản mở
rộng.
⁴Chúng tôi không phát hành benchmark này do các hạn chế
bản quyền. Các nghiên cứu trước đã đánh giá các LM tầm xa
trên corpus này (Wu et al., 2022; Hutchins et al., 2022;
Mehta et al., 2023), nhưng không phát hành corpus của họ.
Vì vậy, chúng tôi sử dụng corpus được tiền xử lý và phân
chia dữ liệu được cung cấp bởi Azerbayev et al. (2023).
5 Thí nghiệm
Bây giờ chúng tôi chuyển sang các thí nghiệm để
so sánh RPT với các nghiên cứu trước trên bốn bộ
dữ liệu của chúng tôi.
5.1 Thiết lập Thí nghiệm
Chúng tôi so sánh với các baseline và oracle sau.
Transformer-XL Baseline đơn giản nhất của chúng
tôi là một ngăn xếp giải mã transformer tiêu chuẩn
với attention cửa sổ trượt. Nói cách khác, chúng
tôi đơn giản loại bỏ khỏi RPT thành phần truy xuất
và các lớp CCA trong bộ giải mã trên. Sử dụng
attention cửa sổ trượt (như mô tả trong §3.4) có
thể được xem như một biến thể của Transformer-XL
(Dai et al., 2019). Chúng tôi so sánh RPT với
Transformer-XL trong nhiều thiết lập, một thiết
lập trong đó chúng tôi có cùng số lượng lớp và
bước huấn luyện cho cả hai mô hình, và hai thiết
lập khác trong đó chúng tôi ràng buộc số lượng
tham số và FLOPs giữa các mô hình.
RETRO Chúng tôi triển khai một phiên bản sửa
đổi của Borgeaud et al. (2022), một mô hình được
tăng cường truy xuất, trong đó chúng tôi cung cấp
các hàng xóm top-K được truy xuất bởi BM25⁵
làm đầu vào cho các lớp CCA trong bộ giải mã
trên. Cụ thể, Borgeaud et al. (2022) thực hiện
CCA trên biểu diễn từ một bộ mã hóa hai chiều
riêng biệt, trong khi biến thể của chúng tôi sử dụng
các biểu diễn bộ giải mã dưới như một sự thay thế.
Điều này làm cho các kiến trúc RPT và RETRO
tương tự nhau hơn và cho phép đánh giá tập trung
vào tầm quan trọng của việc huấn luyện bộ truy
xuất, đây là trọng tâm của công việc của chúng
tôi. Trong quá trình huấn luyện, chúng tôi sử dụng
truy vấn (cq, ct), vì chúng tôi có quyền truy cập
vào đoạn mục tiêu. Trong quá trình suy luận, chúng
tôi sử dụng cq.
RPT-Lex Một phiên bản của RPT, trong đó tín
hiệu huấn luyện được thu được hoàn toàn từ thông
tin từ vựng, tương tự như TRIME (Zhong et al.,
2022). Cụ thể, tập hợp các đoạn dương Rqpos cho
một đoạn cq chứa 20 đoạn hàng đầu có điểm số
BM25 cao nhất với (cq, ct).
RPT-Sem Mô hình đầy đủ của chúng tôi được mô
tả trong §3.
⁵Nghiên cứu đồng thời (Doostmohammadi et al., 2023) cho
thấy rằng huấn luyện RETRO sử dụng BM25 vượt trội hơn
các phương pháp truy xuất dày đặc.

--- TRANG 7 ---
Mô hình ArXiv Code PG19 Books3 Params Time/update
TRANSFORMER -XL(TRIỂN KHAI CỦA CHÚNG TÔI) 3.11 2.30 11.48 15.00 202M 1 ×
+2LAYERS 3.07 2.26 11.2 14.52 228M 1.14 ×
1.5×BƯỚC BỔ SUNG 3.11 2.26 11.39 14.70 202M 1 ×
RETRO W . BM25 (TRIỂN KHAI CỦA CHÚNG TÔI) 2.94 2.17 11.44 14.60 236M 1.35 ×
RPT-L EX 2.92 2.23 11.59 14.32 242M 1.51 ×
RPT-S EM 2.77 2.17 10.96 13.91 242M 1.51 ×
W. 3HÀNG XÓM 2.75 2.16 10.92 13.87
W. 4HÀNG XÓM 2.74 2.15 10.93 13.91
MEMORIZING TRANSFORMER (32K) 2.92 2.18 10.97 14.40 212M 1.82 ×
MEMORIZING TRANSFORMER (65K) 2.93 2.15 10.99 14.3 212M 2.12 ×
BLOCK -RECURRENT TRANSFORMER 2.89 2.73 10.95 14.64 212M 1.56 ×
GRIFFIN 3.08 2.24 11.26 14.16 240M 1.15 ×
RPT-L EX W . ORACLE 2.80 2.12 10.88 13.30 242M 1.51 ×
RPT-S EM W . ORACLE 2.69 2.10 10.26 12.74 242M 1.51 ×
Bảng 2: Perplexity tập kiểm tra cho tất cả các bộ dữ liệu cùng với số lượng tham số và mức tăng tương đối trong
thời gian mỗi lần cập nhật trong quá trình huấn luyện so với Transformer-XL. Trừ khi được chỉ định, các mô hình
được huấn luyện trong 500k bước và sử dụng 2 hàng xóm trong quá trình suy luận.
Block-Recurrent Transformer Chúng tôi sử dụng
triển khai huấn luyện chính thức⁶ của Block-Recurrent
Transformer (Hutchins et al., 2022) với cấu hình
mặc định.
Memorizing Transformer Chúng tôi sử dụng triển
khai chính thức⁶ của Memorizing Transformers
(Wu et al., 2022), với cấu hình mặc định và kích
thước bộ nhớ 32K và 65K token.
Griffin Một thay thế cho mô hình tầm xa là sử dụng
một hybrid của attention và RNN tuyến tính (Orvieto
et al., 2023; Gupta et al., 2023). Chúng tôi đánh
giá Griffin (De et al., 2024), một mô hình tiên tiến
trong danh mục này. Chúng tôi thích ứng triển khai
chính thức, và bổ sung baseline Transformer-XL
của chúng tôi với 5 lớp recurrent trong các lớp cuối
cùng để đảm bảo tương đương tham số. Chúng tôi
sử dụng chiều trạng thái là 2,048 và chiều thời gian
là 3.
Oracle Đối với mỗi đoạn kiểm tra, chúng tôi có
thể tìm kiếm toàn diện và sử dụng tại thời điểm
kiểm tra các hàng xóm tốt nhất có thể cho một mô
hình theo LM chấm điểm. Điều này cung cấp một
giới hạn trên cho hiệu suất của RPT-Sem, vì nó
được huấn luyện để bắt chước thứ hạng được tạo
bởi oracle này.
Chỉ số Chúng tôi sử dụng perplexity để đánh giá
hiệu suất của các mô hình. Ngoài ra, chúng tôi sử
dụng điểm số mục tiêu st(·) từ LM chấm điểm để
tính toán cho mỗi đoạn một thứ hạng vàng trên tất
cả các đoạn trước đó, và gắn nhãn các đoạn là
dương/âm nếu điểm số mục tiêu của chúng là dương/âm,
tương ứng. Với thông tin này, chúng tôi có thể đánh
giá Precision@k, là tỷ lệ các đoạn top-k theo điểm
số dựa trên truy vấn là dương, và Recall@k, là tỷ
lệ các đoạn dương nằm trong các đoạn top-k theo
điểm số dựa trên truy vấn. Chúng tôi cũng sử dụng
thứ hạng vàng để tính toán NDCG@k, là một chỉ
số truy xuất tiêu chuẩn (Järvelin and Kekäläinen,
2002).
⁶https://github.com/google-research/
meliad. 5.2 Kết quả
Bảng 2 cho thấy kết quả chính của chúng tôi, cho
thấy RPT-Sem có hiệu suất tương đương hoặc tốt
hơn tất cả các baseline khác trong tất cả các trường
hợp. Sử dụng bộ truy xuất cố định (RETRO) cải
thiện hiệu suất so với Transformer-XL; RPT-Lex
dẫn đến lợi ích trong Books3 nhưng tổn thất trong
PG19 so với RETRO, và RPT-Sem vượt trội hơn
Transformer-XL, RETRO và RPT-Lex trên ArXiv,
PG19 và Books3, và có hiệu suất tương đương với
RETRO trên CodeParrot. Ngay cả trong thiết lập
ràng buộc tham số và ràng buộc tính toán, Transformer-XL
vẫn có hiệu suất kém đáng kể so với RPT. So với
Block-Recurrent Transformer, Memorizing Transformers
và Griffin, không sử dụng CCA, hiệu suất lại tương
tự hoặc tốt hơn, với cải thiện đáng kể trên ArXiv
và Books3.
CCA cho phép tăng động số lượng hàng xóm tại
thời điểm suy luận. Khi sử dụng 3 hoặc 4 hàng
xóm (thay vì 2), hiệu suất cải thiện, cho phép đánh
đổi tính toán-hiệu suất.
Cuối cùng, các mô hình oracle liên tục đạt được
perplexity tốt nhất trên tất cả các bộ dữ liệu, cải
thiện từ 2.74→2.69 trên ArXiv, 2.15 →2.10 trên
CodeParrot, 10.92 →10.26 trên PG19, và 13.87
→12.74 cho Books3. Điều này cho thấy rằng cải
thiện việc huấn luyện bộ truy xuất có thể cải thiện
hiệu suất hơn nữa.

--- TRANG 8 ---
Bộ dữ liệu Precision@2 Recall@10 nDCG@20
BM25 RPT-L RPT-S BM25 RPT-L RPT-S BM25 RPT-L RPT-S
ArXiv 27% 26% 32% 55% 54% 58% 24% 24% 30%
Code 29% 26% 34% 53% 52% 56% 25% 23% 30%
PG19 22% 22% 28% 55% 55% 61% 18% 18% 23%
Books3 23% 19% 26% 55% 50% 58% 18% 16% 22%
Avg 25.2% 23.2% 30.0% 54.5% 52.7% 58.2% 21.2% 20.2% 26.2%
Bảng 3: Chỉ số truy xuất kiểm tra trên các bộ dữ liệu.
Chỉ số truy xuất Bảng 3 trình bày các chỉ số truy
xuất w.r.t các đoạn dương oracle. Một lần nữa,
truy xuất với RPT-Sem vượt trội hơn cả RPT-Lex
và BM25 trong tất cả các trường hợp. Điều này
cho thấy tầm quan trọng của việc huấn luyện bộ
truy xuất, và hơn nữa rằng sử dụng giám sát ngữ
nghĩa dẫn đến truy xuất tốt hơn so với chỉ tín hiệu
từ vựng.
5.3 Ablations
Bảng 4 cho thấy kết quả của một nghiên cứu ablation
trên tất cả các bộ dữ liệu.
Chỉ Teacher Forcing Chúng tôi buộc mô hình
attend đến các hàng xóm vàng theo LM chấm điểm,
mà không ủ pss trong quá trình huấn luyện. Điều
này dẫn đến giảm hiệu suất trên tất cả các bộ dữ
liệu, và đặc biệt đối với PG19 và Books3.
Không Teacher Forcing Ở đây, chúng tôi làm
ngược lại và cố định pss= 0 trong suốt quá trình
huấn luyện, tức là chúng tôi chỉ sử dụng các hàng
xóm được dự đoán và không phải các hàng xóm
vàng. Điều này có thể dẫn đến huấn luyện thiếu
của các lớp CCA vì chúng được tiếp xúc với các
hàng xóm chất lượng thấp ở đầu quá trình huấn
luyện và kết quả giảm còn nhiều hơn so với Chỉ
Teacher Forcing.
Không cổng hàng xóm Chúng tôi vô hiệu hóa
cổng hàng xóm kiểm soát dòng thông tin từ các
đoạn hàng xóm và phân tích tác động đến hiệu
suất mô hình. Chúng tôi quan sát giảm hiệu suất
trên tất cả các bộ dữ liệu, đáng chú ý trên Books3,
trong đó perplexity tăng 4.5 điểm.
Mô hình ArXiv Code PG19 Books3
RETRO W . BM25 (TRIỂN KHAI CỦA CHÚNG TÔI) 2.94 2.17 11.44 14.60
W. BỘ TRUY XUẤT DPR-STYLE 2.97 2.28 11.7 14.86
RPT-L EX 2.92 2.23 11.59 14.32
W. BỘ TRUY XUẤT DPR-STYLE 2.84 2.26 11.11 14.17
RPT-S EM 2.77 2.17 10.96 13.91
W. BỘ TRUY XUẤT DPR-STYLE 2.98 2.33 11.62 14.66
RPT-S EM- CHỈ TEACHER FORCING 2.91 2.22 11.54 14.66
RPT-S EM- KHÔNG TEACHER FORCING 2.95 2.26 13.10 14.40
RPT-S EM- KHÔNG CỔNG HÀNG XÓM 2.92 2.20 11.50 18.68
Bảng 4: Kết quả nghiên cứu ablation của chúng tôi.Bộ truy xuất DPR-style Để nghiên cứu tầm quan
trọng của huấn luyện chung, chúng tôi kiểm tra
hiệu suất khi sử dụng các bộ truy xuất được huấn
luyện riêng biệt từ LM, do đó tạo ra sự không khớp
giữa huấn luyện-kiểm tra. Chúng tôi huấn luyện
các bộ truy xuất dày đặc sử dụng quy trình huấn
luyện DPR tiêu chuẩn (Karpukhin et al., 2020)
trên mỗi bộ dữ liệu (xem Phụ lục C để biết chi tiết
huấn luyện), và đối với mỗi mô hình CCA của chúng
tôi sử dụng bộ truy xuất này thay vì bộ mà nó được
huấn luyện cùng. Thú vị, chúng tôi quan sát RPT-Lex
có thể hiệu quả sử dụng các hàng xóm DPR-style
mang lại cho nó một cải thiện hiệu suất nhỏ trên
3 trong 4 bộ dữ liệu.
Như mong đợi, hai mô hình được huấn luyện với
các bộ truy xuất mạnh hơn chịu thiệt hại từ sự
không khớp huấn luyện-kiểm tra, thay thế bộ truy
xuất BM25 và bộ truy xuất RPT-Sem bằng bộ truy
xuất DPR-style khiến cả hai mô hình bị giảm hiệu
suất trên tất cả các bộ dữ liệu, gợi ý rằng hiệu
suất không-ablated là kết quả của sự phối hợp giữa
bộ truy xuất và mô hình ngôn ngữ.
5.4 Phân tích
121416182022Chồng lấp tokenArXiv Books3
121416182022Chồng lấp tokenCodeParrot PG19
RPT-Sem RPT-Lex RETRO+BM25 Truy vấn Mục tiêu
Hình 4: Chúng tôi đo số lượng token duy nhất chồng
lấp giữa các đoạn truy vấn/mục tiêu và hàng xóm được
truy xuất tốt nhất.
Chồng lấp token Hình 4 vẽ số lượng token trung
bình chồng lấp giữa các đoạn truy vấn/mục tiêu
trong hàng xóm được truy xuất tốt nhất cho RETRO,
RPT-Lex và RPT-Sem. RPT-Sem truy xuất các đoạn
văn với độ chồng lấp cao hơn với đoạn mục tiêu
so với RPT-Lex. Đương nhiên, BM25 truy xuất
các đoạn với độ chồng lấp cao nhất với đoạn truy
vấn

--- TRANG 9 ---
đoạn. Tuy nhiên, điều này không dịch ra độ chồng
lấp từ vựng cao hơn cho đoạn mục tiêu.
1234567891011121314151617181920
Phần tử Top-K theo BM250.000.050.100.150.20Điểm số mục tiêu trung bình tối đa trên các đoạn
Bộ dữ liệu
Books3
ArXiv
CodeParrot
PG19
Hình 5: Điểm số mục tiêu tối đa st(·) cho các đoạn
top-K được truy xuất bởi BM25 được tính trung bình
trên các đoạn và cho tất cả các bộ dữ liệu. Vì điểm
số mục tiêu tối đa cho 20 đoạn hàng đầu cao hơn
nhiều so với top-2, việc học sắp xếp lại 20 ứng viên
BM25 hàng đầu có thể dẫn đến cải thiện đáng kể
trong chất lượng truy xuất.
Chất lượng giám sát Chúng tôi huấn luyện RPT-Sem
sử dụng thông tin từ hàm chấm điểm mục tiêu st(·),
mà chúng tôi thấy dẫn đến cải thiện mô hình. Tuy
nhiên, hàm chấm điểm mục tiêu chỉ cung cấp sắp
xếp lại của 20 ứng viên hàng đầu theo BM25. Vì
vậy, một câu hỏi tự nhiên là chất lượng giám sát
cải thiện bao nhiều thông qua việc sắp xếp lại này.
Hình 5 cho thấy đối với mỗi hạng K điểm số mục
tiêu tối đa trong số các đoạn top-K theo BM25,
được tính trung bình trên các đoạn và trên 4 bộ
dữ liệu của chúng tôi. Rõ ràng, việc sắp xếp lại
20 ứng viên BM25 hàng đầu có rất nhiều tiềm năng,
vì điểm số mục tiêu tối đa cao hơn nhiều đối với
20 ứng viên hàng đầu so với top-2. Điều này gợi
ý rằng việc huấn luyện dài hơn và tốt hơn của bộ
truy xuất có thể cải thiện hiệu suất của RPT-Sem
hơn nữa.
Thú vị, phân tích của chúng tôi làm sáng tỏ tại
sao RPT-Sem vượt trội hơn RETRO rõ ràng trên
Books3 và PG19 nhưng ít hơn trên CodeParrot.
Điểm số mục tiêu tối đa cho CodeParrot khi k= 2
đã khá cao – khoảng 0.1, tương ứng với hơn 10%
cải thiện xác suất của đoạn mục tiêu so với ngữ
cảnh địa phương. Ngược lại, đối với PG19 và Books3,
điểm số mục tiêu khi k= 2 gần 0 hơn.
Phân tích nhóm con Hình 6 cho thấy cải thiện
tương đối trung bình (trên các đoạn) của RETRO,
RPT-Lex và RPT-Sem so với Transformer-XL,
0102030% Cải thiệnArXiv Books3
0102030% Cải thiệnCodeParrot PG19
RPT-Sem RPT-Lex RETRO+BM25 Sai Đúng Tất cảHình 6: Cải thiện tương đối có/không có truy xuất đúng.
khi phân biệt giữa các trường hợp mà một đoạn
oracle "vàng" được truy xuất và các trường hợp
mà không có đoạn vàng nào được truy xuất.
Như mong đợi, RPT-Sem dẫn đến cải thiện trên
tất cả các bộ dữ liệu, và vượt trội hơn các baseline
khác ngoại trừ RETRO trên CodeParrot nơi hiệu
suất tương tự. Thứ hai, các trường hợp mà một
đoạn vàng được truy xuất thực sự thường dẫn đến
cải thiện lớn hơn, nhưng chúng tôi chứng kiến
cải thiện ngay cả trong các trường hợp mà một
đoạn vàng không được truy xuất, điều này cho thấy
mô hình vẫn có thể hưởng lợi từ những truy xuất
như vậy.
Phân tích định tính Kiểm tra các đoạn được truy
xuất, chúng tôi quan sát rằng bộ truy xuất RPT có
tính ngữ cảnh cao. Khi áp dụng trên mã, nó truy
xuất các định nghĩa hàm, gán biến, v.v., trên ArXiv
nó truy xuất các định nghĩa lemma, định lý, v.v.
Hình 7 cho thấy một ví dụ, trong đó chúng tôi cung
cấp codebase được sử dụng cho bài báo này làm
đầu vào cho mô hình của chúng tôi và trình bày
một ví dụ đoạn truy vấn trong đó RPT tạo ra truy
xuất tốt hơn BM25. Chúng tôi quan sát rằng ngữ
cảnh trước đó cho phép RPT hiệu quả truy xuất
một định nghĩa đối tượng liên quan, dẫn đến loss
thấp hơn.
6 Thảo luận và Nghiên cứu Liên quan
Mối quan hệ với Fusion-in-Decoder RPT có điểm
tương đồng với Fusion-in-Decoder (FiD) (Izacard
and Grave, 2021b; Ivgi et al., 2023). Trong khi
cả RPT và FiD đều sử dụng cơ chế cross-attention
để tích hợp ngữ cảnh được truy xuất trong các mô
hình của họ, chúng khác nhau ở hai cách. (a) Trong
FiD, truy xuất được thực hiện

--- TRANG 10 ---
@flax.struct.dataclass
class FlaxRPTRetrieverEncodedOutput(ModelOutput):
original_hidden_states: jnp.ndarray = None
encoded_hidden_states: jnp.ndarray = None
attention_mask: jnp.ndarray = None
key_chunks: jnp.ndarray = None
query_chunks: jnp.ndarray = None
chunk_mask: jnp.ndarray = None
...
class FlaxRPTModule(nn.Module):
...
def __call__(...
...
hidden_states = self.ln_f (hidden_states)
if not return_dict:
return (hidden_states,) + upcoder_outputs + lowcoder_outputs
return FlaxRPTModelOutput(
last_hidden_state=upcoder_outputs.last_hidden_state,
upcoder_hidden_states=upcoder_outputs.hidden_states,
upcoder_attentions=upcoder_outputs.attentions,
lowcoder_last_hidden_state=lowc oder_outputs.last_hidden_state,
...)
...
def forward_loglikelihood(params, rng, batch, memory):
...
outputs, lowcoder_state = _forward_loglikelihood_lowcoder (params, rng, batch)
if 'cache' in lowcoder_state:
params['cache'] = lowcoder_state['cache']
outputs = jax.tree_map(lambda x: jax.device_get(x).astype(np.float32), outputs)
neighbor_hidden_states, neighbor_mask, *_ = memory.add(
input_tokens=batch["input_tokens"],
encoded_hidden_states=outputs.encoded_hidden_states,
key_chunks=outputs. key_chunks,
query_chunks=outputs.query_chunks,
)
...
Hình 7: Một ví dụ minh họa trình bày các hàng xóm top-1 được truy xuất cho cả hai mô hình RPT-Sem và BM25
được áp dụng cho mã của RPT. Biến outputs trong đoạn truy vấn là một thành viên của lớp
FlaxRPTRetrieverEncodedOutput. RPT-Sem thành công truy xuất định nghĩa của đối tượng dẫn đến
giảm loss trên đoạn mục tiêu, so với BM25.
chỉ một lần dựa trên prompt/truy vấn ban đầu, trong
khi RPT liên tục thực hiện truy xuất ở cấp độ đoạn
trong suốt quá trình sinh. (b) FiD mã hóa các hàng
xóm được truy xuất riêng biệt sử dụng một bộ mã
hóa hai chiều và chỉ sau đó áp dụng cross-attention
trong bộ giải mã. Trong RPT, bộ giải mã tính toán
các embedding đoạn và thực hiện truy xuất bản
địa, và sau đó chunked cross-attention được áp
dụng để hợp nhất ngữ cảnh được truy xuất với các
dự đoán của mô hình. Chúng tôi xem RPT, sử dụng
các mã hóa bộ giải mã dưới, là tự nhiên hơn trong
ngữ cảnh sinh liên tục (ví dụ, chatbots hoặc agents),
vì mô hình sinh ra các biểu diễn và sử dụng chúng
sau này làm khóa, và do đó việc sinh ra các biểu
diễn truy xuất không tốn chi phí gì.Mô hình ngôn ngữ tầm xa Một trọng tâm chính
trong mô hình ngôn ngữ tầm xa đã là giải quyết
độ phức tạp bậc hai của attention để phát triển
các cơ chế hiệu quả hơn để xử lý văn bản dài. Ví
dụ, Transformer-XL (Dai et al., 2019) xử lý đầu
vào sử dụng cơ chế cấp độ đoạn trong khi duy trì
cache từ các đoạn trước đó. Longformer (Beltagy
et al., 2020) mở rộng ý tưởng này để chứa các
ngữ cảnh còn dài hơn. Một số nghiên cứu trước
đây xem truy xuất như một vấn đề tầm xa. Memorizing
Transformers (Wu et al., 2022) sử dụng một lớp
k-NN duy nhất và truy xuất các khóa và giá trị được
cache, nhưng họ không lan truyền ngược gradient
thông qua phép toán truy xuất thưa thớt. Tương
tự, Bertsch et al. (2023) chứng minh rằng cách
tiếp cận này có thể được sử dụng với bất kỳ mô
hình được huấn luyện trước hiện có nào và áp dụng
nó tại mỗi lớp attention cho các nhiệm vụ tóm tắt
dài. Từ góc độ phân tích, các nghiên cứu trước
(Press et al., 2021) chứng minh rằng các benchmark
LM tiêu chuẩn không lý tưởng để đo khả năng
tầm xa của các mô hình. Sun et al. (2021) thảo
luận về các loại chuỗi khác nhau hưởng lợi từ việc
có ngữ cảnh dài, và Rae and Razavi (2020) điều
tra các lựa chọn kiến trúc tầm xa và khuyến nghị
tăng khả năng tầm xa trong các lớp trên.
Mô hình ngôn ngữ hiệu quả Các chiến lược thưa
thớt, chẳng hạn như những chiến lược được đề
xuất trong Zaheer et al. (2020); Roy et al. (2021);
Kitaev et al. (2020), tương tự như RPT, attend
chỉ đến một tập con các token thông qua các phương
pháp clustering hoặc hashing, được huấn luyện
bằng cách lan truyền gradient thông qua phép toán
thưa thớt. Trong RPT, tính thưa thớt là do phép
toán top-K của bộ truy xuất, được huấn luyện sử
dụng giám sát chất lượng cao từ một mô hình ngôn
ngữ tham chiếu. Một cách tiếp cận khác để mô hình
hóa hiệu quả văn bản dài liên quan đến việc nén
đầu vào và attend trên chuỗi được nén (Martins
et al., 2022; Rae et al., 2020), hoặc học bỏ qua
các token không liên quan (Sukhbaatar et al., 2021).
Tuy nhiên, thực nghiệm hầu hết các kiến trúc transformer
hiệu quả đánh đổi hiệu quả với chất lượng. Gần
đây, các mô hình không gian trạng thái (Mehta et al.,
2023; Gu and Dao, 2023; Fu et al., 2023) xuất
hiện như một thay thế hiệu quả, tiến gần đến chất
lượng Transformer. Trong bài báo này, chúng tôi
khám phá các mô hình dựa trên Transformer bậc
hai cổ điển. Chúng tôi lập luận rằng mô hình cơ
bản là trực giao với đóng góp của chúng tôi và có
thể được thay thế bằng các thay thế hiệu quả khác
và kết hợp với truy xuất. Chúng tôi để dành khám
phá này cho nghiên cứu tương lai.
LMs được tăng cường truy xuất LMs được tăng
cường truy xuất đã nổi lên như một cách tiếp cận
nổi bật để tận dụng hiệu quả kiến thức bên ngoài
trong khi sinh văn bản. Những mô hình này có thể
được chia rộng thành những mô hình hoạt động
ở độ chi tiết cấp token và những mô hình hoạt
động ở độ chi tiết cấp chuỗi. Các phương pháp
cấp token, chẳng hạn như kNN-LM (Khandelwal
et al., 2020), TRIME (Zhong et al., 2022), và
SPALM (Yogatama et al., 2021), truy xuất thông
tin cho các token riêng lẻ. Các cách tiếp cận cấp
chuỗi như RAG (Lewis et al., 2020) sử dụng các
mô hình mã hóa-giải mã được huấn luyện trước
với các bộ truy xuất được huấn luyện trước cho
các nhiệm vụ như trả lời câu hỏi miền mở. Tương
tự, FiD (Izacard and Grave, 2021b) sử dụng các
mô hình mã hóa-giải mã sinh có thể hợp nhất bằng
chứng từ nhiều đoạn văn trong quá trình giải mã,
liên quan chặt chẽ đến cơ chế CCA. Gần đây, Wang
et al. (2023) chứng minh lợi ích tiềm năng của việc
thực hiện truy xuất và chunked cross-attention tại
mỗi bước thời gian, so với bài báo RETRO ban
đầu (Borgeaud et al., 2022), truy xuất mỗi m= 64
bước.
Huấn luyện chung bộ truy xuất-đọc Các cách tiếp
cận huấn luyện chung thường tập trung vào việc
chuyển giao thông tin giữa một bộ đọc được huấn
luyện trước thành một bộ truy xuất được huấn luyện
trước. Những phương pháp này thường liên quan
đến việc cập nhật chỉ mục bộ truy xuất trong quá
trình huấn luyện trong ngữ cảnh của các nhiệm vụ
chuyên sâu kiến thức, chẳng hạn như trả lời câu
hỏi miền mở. Ví dụ, REALM (Guu et al., 2020)
sử dụng mô hình ngôn ngữ có mặt nạ làm tín hiệu
học để cập nhật bộ truy xuất. EMDR2 (Sachan
et al., 2021) mở rộng FiD bằng cách sử dụng các
mô hình mã hóa-giải mã để lan truyền ngược lỗi
từ câu trả lời được dự đoán đến bộ truy xuất. Tương
tự, Izacard and Grave (2021a); Jiang et al. (2022)
sử dụng điểm số attention từ bộ đọc để giám sát
bộ truy xuất trực tiếp sử dụng ma trận attention
làm tín hiệu huấn luyện để cho phép huấn luyện
end-to-end chung với giám sát của nhiệm vụ downstream.
Đáng chú ý, Izacard et al. (2022b) tiếp tục mở
rộng những cách tiếp cận này và huấn luyện chung
một bộ truy xuất với một mô hình mã hóa-giải mã,
chứng minh khả năng học few-shot mạnh mẽ. Họ
cũng điều tra các kỹ thuật cập nhật bộ truy xuất
khác nhau để giải quyết sự không khớp huấn luyện-kiểm
tra trong quá trình truy xuất. Chúng tôi không gặp
phải vấn đề cập nhật chỉ mục vì chúng tôi tính toán
toàn bộ chỉ mục thông qua một lần chuyển tiếp.
Huấn luyện trước bộ truy xuất Nghiên cứu sớm
về huấn luyện trước bộ truy xuất dựa vào Inverse
Cloze Task không giám sát để huấn luyện trước
bộ truy xuất (Lee et al., 2019; Guu et al., 2020).
Sau đó được chứng minh rằng việc sử dụng trực
tiếp BERT (Devlin et al., 2019) với một mục tiêu
có giám sát là đủ để có được hiệu suất tốt trên
các benchmark tiêu chuẩn (Karpukhin et al., 2020).
Tuy nhiên, mô hình này cho thấy hiệu suất kém
trên các thực thể long-tail so với BM25 (Amouyal
et al., 2023; Sciavolino et al., 2021). Gần đây,
các phương pháp huấn luyện trước không giám sát
(Gao and Callan, 2022; Ram et al., 2022; Izacard
et al., 2022a) cho phép cải thiện hiệu suất. Tuy
nhiên, những phương pháp này được khởi tạo từ
một mô hình encoder BERT được huấn luyện trước
(Devlin et al., 2019), trong khi RPT là một kiến
trúc retriever-reader được huấn luyện từ đầu vượt
trội hơn BM25 mà không cần bất kỳ huấn luyện
trước bổ sung nào.
Giám sát bộ truy xuất với LLMs EPR (Rubin et al.,
2022) chứng minh rằng LLMs có thể được sử dụng
để huấn luyện bộ truy xuất cho truy xuất prompt
bằng cách ước tính xác suất của một đầu ra cho
đầu vào và một ví dụ huấn luyện ứng viên làm
prompt. Các kỹ thuật tương tự được áp dụng cho
trả lời câu hỏi miền mở thông qua sắp xếp lại kết
quả truy xuất (Sachan et al., 2022; Ram et al.,
2023) và để giám sát bộ truy xuất thông qua chưng
cất perplexity (Izacard et al., 2022b). Gần đây,
Shi et al. (2024) sử dụng phương pháp giám sát
này để cải thiện hiệu suất của các LLM khác nhau
theo cách hộp đen.
7 Kết luận
Trong nghiên cứu này, chúng tôi trình bày Retrieval-Pretrained
Transformer (RPT), một LM được tăng cường truy
xuất, trong đó bộ truy xuất được huấn luyện như
một thành phần bản địa của LM để truy xuất các
đoạn liên quan ngữ nghĩa cho dự đoán văn bản
tương lai. Chúng tôi đánh giá RPT trên bốn nhiệm
vụ mô hình ngôn ngữ tầm xa, bao gồm sách, mã
và viết toán học. Chúng tôi chứng minh rằng bằng
cách tích hợp liền mạch bộ truy xuất vào kiến trúc
và quy trình huấn luyện, RPT hưởng lợi từ việc
hợp nhất ngữ cảnh được truy xuất, cải thiện so với
các baseline được tăng cường truy xuất mạnh. Trong
khi nghiên cứu này tập trung vào truy xuất từ văn
bản dài, chúng tôi lập luận các phát hiện thực nghiệm
của chúng tôi cho thấy rằng thích ứng quy trình
của chúng tôi cho truy xuất corpus dựa trên web
tổng quát là một hướng tương lai thú vị. Điều này
sẽ đòi hỏi vượt qua các khó khăn kỹ thuật liên quan
đến việc mở rộng và xây dựng corpus huấn luyện
trước. Chúng tôi hình dung RPT sẽ mở đường cho
một thế hệ mới các mô hình ngôn ngữ được huấn
luyện trước với truy xuất được tích hợp sâu trong
suốt kiến trúc và quy trình huấn luyện của chúng.
Lời cảm ơn
Nghiên cứu này được hỗ trợ bởi Cloud TPUs từ
Google's TPU Research Cloud (TRC) và Hội đồng
Nghiên cứu Châu Âu (ERC) dưới chương trình
nghiên cứu và đổi mới Horizons 2020 của Liên
minh Châu Âu (grant ERC DELPHI 802800). Ohad
muốn cảm ơn Iz Beltagy vì đã đề xuất chương trình
TRC, và toàn bộ phòng thí nghiệm TAU NLP đặc
biệt là Guy Dar và Itay Itzhak. Nghiên cứu này
được hoàn thành để hoàn thành một phần bằng
tiến sĩ của Ohad Rubin.

--- TRANG 11 ---
7 Kết luận
Trong nghiên cứu này, chúng tôi trình bày Retrieval-Pretrained
Transformer (RPT), một LM được tăng cường truy
xuất, trong đó bộ truy xuất được huấn luyện như
một thành phần bản địa của LM để truy xuất các
đoạn liên quan ngữ nghĩa cho dự đoán văn bản
tương lai. Chúng tôi đánh giá RPT trên bốn nhiệm
vụ mô hình ngôn ngữ tầm xa, bao gồm sách, mã
và viết toán học. Chúng tôi chứng minh rằng bằng
cách tích hợp liền mạch bộ truy xuất vào kiến trúc
và quy trình huấn luyện, RPT hưởng lợi từ việc
hợp nhất ngữ cảnh được truy xuất, cải thiện so với
các baseline được tăng cường truy xuất mạnh. Trong
khi nghiên cứu này tập trung vào truy xuất từ văn
bản dài, chúng tôi lập luận các phát hiện thực nghiệm
của chúng tôi cho thấy rằng thích ứng quy trình
của chúng tôi cho truy xuất corpus dựa trên web
tổng quát là một hướng tương lai thú vị. Điều này
sẽ đòi hỏi vượt qua các khó khăn kỹ thuật liên quan
đến việc mở rộng và xây dựng corpus huấn luyện
trước. Chúng tôi hình dung RPT sẽ mở đường cho
một thế hệ mới các mô hình ngôn ngữ được huấn
luyện trước với truy xuất được tích hợp sâu trong
suốt kiến trúc và quy trình huấn luyện của chúng.
Lời cảm ơn
Nghiên cứu này được hỗ trợ bởi Cloud TPUs từ
Google's TPU Research Cloud (TRC) và Hội đồng
Nghiên cứu Châu Âu (ERC) dưới chương trình
nghiên cứu và đổi mới Horizons 2020 của Liên
minh Châu Âu (grant ERC DELPHI 802800). Ohad
muốn cảm ơn Iz Beltagy vì đã đề xuất chương trình
TRC, và toàn bộ phòng thí nghiệm TAU NLP đặc
biệt là Guy Dar và Itay Itzhak. Nghiên cứu này
được hoàn thành để hoàn thành một phần bằng
tiến sĩ của Ohad Rubin.
Tài liệu tham khảo
Samuel Amouyal, Tomer Wolfson, Ohad Rubin,
Ori Yoran, Jonathan Herzig, and Jonathan Be-
rant. 2023. QAMPARI: A benchmark for open-
domain questions with many answers. In Proc.
of the Third Workshop on GEM. ACL.
Zhangir Azerbayev, Edward Ayers, and Bartosz
Piotrowski. 2023. Proof-Pile: A Pre-training
Dataset of Mathematical Text.
Iz Beltagy, Matthew E. Peters, and Arman Cohan.
2020. Longformer: The long-document trans-
former.
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and
Noam Shazeer. 2015. Scheduled sampling for
sequence prediction with recurrent neural net-
works. In Proc. of NeurIPS .
Amanda Bertsch, Uri Alon, Graham Neubig, and
Matthew R. Gormley. 2023. Unlimiformer:
Long-range transformers with unlimited length
input. In Proc. of NeurIPS .
Stella Biderman, Hailey Schoelkopf, Quentin An-
thony, Herbie Bradley, Kyle O'Brien, Eric Hal-
lahan, Mohammad Aflah Khan, Shivanshu Puro-
hit, USVSN Sai Prashanth, Edward Raff, Aviya
Skowron, Lintang Sutawika, and Oskar van der
Wal. 2023. Pythia: A suite for analyzing large
language models across training and scaling.
Sidney Black, Stella Biderman, Eric Hallahan,
Quentin Anthony, Leo Gao, Laurence Golding,
Horace He, Connor Leahy, Kyle McDonell, Ja-
son Phang, Michael Pieler, Usvsn Sai Prashanth,
Shivanshu Purohit, Laria Reynolds, Jonathan
Tow, Ben Wang, and Samuel Weinbach. 2022.
GPT-NeoX-20B: An open-source autoregressive
language model. In Proc. of the BigScience
Workshop .
Sebastian Borgeaud, Arthur Mensch, Jordan Hoff-
mann, Trevor Cai, Eliza Rutherford, Katie Mil-
lican, George van den Driessche, Jean-Baptiste
Lespiau, Bogdan Damoc, Aidan Clark, Diego
de Las Casas, Aurelia Guy, Jacob Menick, Ro-
man Ring, Tom Hennigan, Saffron Huang, Loren
Maggiore, Chris Jones, Albin Cassirer, Andy
Brock, Michela Paganini, Geoffrey Irving, Oriol
Vinyals, Simon Osindero, Karen Simonyan,
Jack W. Rae, Erich Elsen, and Laurent Sifre.

--- TRANG 12 ---
2022. Improving language models by retrieving
from trillions of tokens. In Proc. of ICML .
Tom B. Brown, Benjamin Mann, Nick Ryder,
Melanie Subbiah, Jared Kaplan, Prafulla Dhari-
wal, Arvind Neelakantan, Pranav Shyam, Girish
Sastry, Amanda Askell, Sandhini Agarwal, Ariel
Herbert-V oss, Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh, Daniel M.
Ziegler, Jeffrey Wu, Clemens Winter, Christo-
pher Hesse, Mark Chen, Eric Sigler, Mateusz
Litwin, Scott Gray, Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish, Alec Rad-
ford, Ilya Sutskever, and Dario Amodei. 2020.
Language models are few-shot learners. In Proc.
of NeurIPS .
Christopher J. C. Burges, Robert Ragno, and
Quoc Viet Le. 2006. Learning to rank with non-
smooth cost functions. In Proc. of NeurIPS .
Aakanksha Chowdhery, Sharan Narang, Jacob De-
vlin, Maarten Bosma, Gaurav Mishra, Adam
Roberts, Paul Barham, Hyung Won Chung,
Charles Sutton, Sebastian Gehrmann, Parker
Schuh, Kensen Shi, Sasha Tsvyashchenko,
Joshua Maynez, Abhishek Rao, Parker Barnes,
Yi Tay, Noam Shazeer, Vinodkumar Prab-
hakaran, Emily Reif, Nan Du, Ben Hutchin-
son, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng
Yin, Toju Duke, Anselm Levskaya, Sanjay
Ghemawat, Sunipa Dev, Henryk Michalewski,
Xavier Garcia, Vedant Misra, Kevin Robin-
son, Liam Fedus, Denny Zhou, Daphne Ip-
polito, David Luan, Hyeontaek Lim, Barret
Zoph, Alexander Spiridonov, Ryan Sepassi,
David Dohan, Shivani Agrawal, Mark Omer-
nick, Andrew M. Dai, Thanumalayan Sankara-
narayana Pillai, Marie Pellat, Aitor Lewkowycz,
Erica Moreira, Rewon Child, Oleksandr Polozov,
Katherine Lee, Zongwei Zhou, Xuezhi Wang,
Brennan Saeta, Mark Diaz, Orhan Firat, Michele
Catasta, Jason Wei, Kathy Meier-Hellstern, Dou-
glas Eck, Jeff Dean, Slav Petrov, and Noah
Fiedel. 2022. Palm: Scaling language model-
ing with pathways.
Zihang Dai, Zhilin Yang, Yiming Yang, Jaime
Carbonell, Quoc Le, and Ruslan Salakhutdinov.
2019. Transformer-XL: Attentive language mod-
els beyond a fixed-length context. In Proc. of
ACL.Soham De, Samuel L. Smith, Anushan Fernando,
Aleksandar Botev, George Cristian-Muraru, Al-
bert Gu, Ruba Haroun, Leonard Berrada, Yu-
tian Chen, Srivatsan Srinivasan, Guillaume
Desjardins, Arnaud Doucet, David Budden,
Yee Whye Teh, Razvan Pascanu, Nando De Fre-
itas, and Caglar Gulcehre. 2024. Griffin: Mixing
gated linear recurrences with local attention for
efficient language models.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training
of deep bidirectional transformers for language
understanding. In Proc. of NAACL-HLT .
Ehsan Doostmohammadi, Tobias Norlund, Marco
Kuhlmann, and Richard Johansson. 2023.
Surface-based retrieval reduces perplexity of
retrieval-augmented language models. In Proc.
of ACL .
Matthijs Douze, Alexandr Guzhva, Chengqi
Deng, Jeff Johnson, Gergely Szilvasy, Pierre-
Emmanuel Mazaré, Maria Lomeli, Lucas Hos-
seini, and Hervé Jégou. 2024. The faiss library.
William Fedus, Barret Zoph, and Noam Shazeer.
2022. Switch transformers: Scaling to trillion
parameter models with simple and efficient spar-
sity. J. Mach. Learn. Res. , 23:1–39.
Daniel Y Fu, Tri Dao, Khaled Kamal Saab,
Armin W Thomas, Atri Rudra, and Christopher
Re. 2023. Hungry hungry hippos: Towards lan-
guage modeling with state space models. In
Proc. of ICLR .
Leo Gao, Stella Biderman, Sid Black, Laurence
Golding, Travis Hoppe, Charles Foster, Jason
Phang, Horace He, Anish Thite, Noa Nabeshima,
Shawn Presser, and Connor Leahy. 2020. The
pile: An 800gb dataset of diverse text for lan-
guage modeling.
Luyu Gao and Jamie Callan. 2022. Unsupervised
corpus aware language model pre-training for
dense passage retrieval. In Proc. of ACL .
Albert Gu and Tri Dao. 2023. Mamba: Linear-time
sequence modeling with selective state spaces.
Ankit Gupta, Harsh Mehta, and Jonathan Berant.
2023. Simplifying and understanding state space
models with diagonal linear rnns.

--- TRANG 13 ---
Kelvin Guu, Kenton Lee, Zora Tung, Panupong
Pasupat, and Ming-Wei Chang. 2020. Realm:
Retrieval-augmented language model pre-
training. In Proc. of ICML .
Yangsibo Huang, Daogao Liu, Zexuan Zhong, Wei-
jia Shi, and Yin Tat Lee. 2023. knn-adapter:
Efficient domain adaptation for black-box lan-
guage models.
DeLesley Hutchins, Imanol Schlag, Yuhuai Wu,
Ethan Dyer, and Behnam Neyshabur. 2022.
Block-recurrent transformers. In Proc. of
NeurIPS .
Maor Ivgi, Uri Shaham, and Jonathan Berant. 2023.
Efficient Long-Text Understanding with Short-
Text Models. In Transactions of the Association
for Computational Linguistics , volume 11, pages
284–299.
Gautier Izacard, Mathilde Caron, Lucas Hosseini,
Sebastian Riedel, Piotr Bojanowski, Armand
Joulin, and Edouard Grave. 2022a. Unsu-
pervised dense information retrieval with con-
trastive learning. Transactions on Machine
Learning Research .
Gautier Izacard and Edouard Grave. 2021a. Dis-
tilling knowledge from reader to retriever for
question answering. In Proc. of ICLR .
Gautier Izacard and Edouard Grave. 2021b. Lever-
aging passage retrieval with generative models
for open domain question answering. In Proc.
of EACL .
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lu-
cas Hosseini, Fabio Petroni, Timo Schick, Jane
Dwivedi-Yu, Armand Joulin, Sebastian Riedel,
and Edouard Grave. 2022b. Atlas: Few-shot
learning with retrieval augmented language mod-
els.J. Mach. Learn. Res. , 24:1–43.
Kalervo Järvelin and Jaana Kekäläinen. 2002.
Cumulated gain-based evaluation of ir tech-
niques. ACM Transactions on Information Sys-
tems, 20:422–446.
Zhengbao Jiang, Luyu Gao, Zhiruo Wang, Jun
Araki, Haibo Ding, Jamie Callan, and Graham
Neubig. 2022. Retrieval as attention: End-to-
end learning of retrieval and reading within a
single transformer. In Proc. of EMNLP .Vladimir Karpukhin, Barlas Oguz, Sewon Min,
Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi
Chen, and Wen-tau Yih. 2020. Dense passage
retrieval for open-domain question answering.
InProc. of EMNLP .
Urvashi Khandelwal, Omer Levy, Dan Juraf-
sky, Luke Zettlemoyer, and Mike Lewis. 2020.
Generalization through memorization: Nearest
neighbor language models. In Proc. of ICLR .
Nikita Kitaev, Lukasz Kaiser, and Anselm Lev-
skaya. 2020. Reformer: The efficient trans-
former. In Proc. of ICLR .
Kenton Lee, Ming-Wei Chang, and Kristina
Toutanova. 2019. Latent retrieval for weakly
supervised open domain question answering. In
Proc. of ACL .
Patrick S. H. Lewis, Ethan Perez, Aleksandra Pik-
tus, Fabio Petroni, Vladimir Karpukhin, Naman
Goyal, Heinrich Küttler, Mike Lewis, Wen-tau
Yih, Tim Rocktäschel, Sebastian Riedel, and
Douwe Kiela. 2020. Retrieval-augmented gen-
eration for knowledge-intensive NLP tasks. In
Proc. of NeurIPS .
Pedro Henrique Martins, Zita Marinho, and An-
dre Martins. 2022. ∞-former: Infinite memory
transformer. In Proc. of ACL .
Harsh Mehta, Ankit Gupta, Ashok Cutkosky, and
Behnam Neyshabur. 2023. Long range language
modeling via gated state spaces. In Proc. of
ICLR .
Antonio Orvieto, Samuel L Smith, Albert Gu,
Anushan Fernando, Caglar Gulcehre, Razvan
Pascanu, and Soham De. 2023. Resurrecting
recurrent neural networks for long sequences. In
Proc. of ICML .
Ofir Press, Noah A. Smith, and Mike Lewis. 2021.
Shortformer: Better language modeling using
shorter inputs. In Proc. of ACL .
Ofir Press and Lior Wolf. 2017. Using the out-
put embedding to improve language models. In
Proc. of EACL .
Jack Rae and Ali Razavi. 2020. Do transformers
need deep long-range memory? In Proc. of ACL .

--- TRANG 14 ---
Jack W. Rae, Anna Potapenko, Siddhant M. Jayaku-
mar, Chloe Hillier, and Timothy P. Lillicrap.
2020. Compressive transformers for long-range
sequence modelling. In Proc. of ICLR .
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor
Muhlgay, Amnon Shashua, Kevin Leyton-
Brown, and Yoav Shoham. 2023. In-context
retrieval-augmented language models. Trans-
actions of the Association for Computational
Linguistics , 11:1316–1331.
Ori Ram, Gal Shachaf, Omer Levy, Jonathan Be-
rant, and Amir Globerson. 2022. Learning to
retrieve passages without supervision. In Proc.
of NAACL-HLT .
Stephen Robertson and Hugo Zaragoza. 2009. The
probabilistic relevance framework: Bm25 and
beyond. Foundations and Trends in Information
Retrieval , 3:333–389.
Aurko Roy, Mohammad Saffar, Ashish Vaswani,
and David Grangier. 2021. Efficient content-
based sparse attention with routing transformers.
Transactions of the Association for Computa-
tional Linguistics , 9:53–68.
Ohad Rubin, Jonathan Herzig, and Jonathan Be-
rant. 2022. Learning to retrieve prompts for
in-context learning. In Proc. of NAACL-HLT .
Devendra Sachan, Mike Lewis, Mandar Joshi, Ar-
men Aghajanyan, Wen-tau Yih, Joelle Pineau,
and Luke Zettlemoyer. 2022. Improving passage
retrieval with zero-shot question generation. In
Proc. of EMNLP .
Devendra Singh Sachan, Siva Reddy, William L.
Hamilton, Chris Dyer, and Dani Yogatama. 2021.
End-to-end training of multi-document reader
and retriever for open-domain question answer-
ing. In Proc. of NeurIPS .
Christopher Sciavolino, Zexuan Zhong, Jinhyuk
Lee, and Danqi Chen. 2021. Simple entity-
centric questions challenge dense retrievers. In
Proc. of EMNLP .
Weijia Shi, Sewon Min, Michihiro Yasunaga,
Minjoon Seo, Rich James, Mike Lewis, Luke
Zettlemoyer, and Wen tau Yih. 2024. Replug:
Retrieval-augmented black-box language mod-
els. In Proc. of NAACL-HLT .Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng
Pan, Wen Bo, and Yunfeng Liu. 2024. Roformer:
Enhanced transformer with rotary position em-
bedding. Neurocomput. , 568.
Sainbayar Sukhbaatar, Da Ju, Spencer Poff,
Stephen Roller, Arthur Szlam, Jason Weston,
and Angela Fan. 2021. Not all memories are
created equal: Learning to forget by expiring. In
Proc. of ICML .
Simeng Sun, Kalpesh Krishna, Andrew Mattarella-
Micke, and Mohit Iyyer. 2021. Do long-range
language models actually use long-range con-
text? In Proc. of EMNLP .
Hugo Touvron, Thibaut Lavril, Gautier Izacard,
Xavier Martinet, Marie-Anne Lachaux, Timo-
thée Lacroix, Baptiste Rozière, Naman Goyal,
Eric Hambro, Faisal Azhar, Aurelien Rodriguez,
Armand Joulin, Edouard Grave, and Guillaume
Lample. 2023. Llama: Open and efficient foun-
dation language models.
Boxin Wang, Wei Ping, Peng Xu, Lawrence
McAfee, Zihan Liu, Mohammad Shoeybi,
Yi Dong, Oleksii Kuchaiev, Bo Li, Chaowei
Xiao, Anima Anandkumar, and Bryan Catanzaro.
2023. Shall we pretrain autoregressive language
models with retrieval? a comprehensive study.
InProc. of EMNLP .
Thomas Wolf, Loubna Ben Allal, Leandro von
Werra, Li Jia, and Armel Zebaze. 2023. A
dataset of python files from github.
Yuhuai Wu, Markus Norman Rabe, DeLesley
Hutchins, and Christian Szegedy. 2022. Memo-
rizing transformers. In Proc. of ICLR .
Dani Yogatama, Cyprien de Masson d'Autume, and
Lingpeng Kong. 2021. Adaptive semiparametric
language models. Transactions of the Associa-
tion for Computational Linguistics , 9:362–373.
Manzil Zaheer, Guru Guruganesh, Kumar Avinava
Dubey, Joshua Ainslie, Chris Alberti, Santiago
Ontañón, Philip Pham, Anirudh Ravula, Qifan
Wang, Li Yang, and Amr Ahmed. 2020. Big
bird: Transformers for longer sequences. In
Proc. of NeurIPS .
Susan Zhang, Stephen Roller, Naman Goyal, Mikel
Artetxe, Moya Chen, Shuohui Chen, Christopher
Dewan, Mona Diab, Xian Li, Xi Victoria Lin,

--- TRANG 15 ---
Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt
Shuster, Daniel Simig, Punit Singh Koura, An-
jali Sridhar, Tianlu Wang, and Luke Zettlemoyer.
2022. Opt: Open pre-trained transformer lan-
guage models.
Zexuan Zhong, Tao Lei, and Danqi Chen. 2022.
Training language models with memory augmen-
tation. In Proc. of EMNLP .
Juntang Zhuang, Tommy Tang, Yifan Ding,
Sekhar C. Tatikonda, Nicha C. Dvornek,
Xenophon Papademetris, and James S. Duncan.
2020. Adabelief optimizer: Adapting stepsizes
by the belief in observed gradients. In Proc. of
NeurIPS .
A Chi tiết Triển khai Bổ sung
Các mô hình được triển khai trong JAX với tỷ lệ
dropout là 0.05, và bộ tối ưu AdaBelief (Zhuang
et al., 2020) với trọng số decay 1e-8, cosine decay
về 0.1 của tỷ lệ học tối đa, cắt gradient norm toàn
cục là 1, và tied input embedding (Press and Wolf,
2017). Tìm kiếm lưới xác định các giá trị τ: 128
cho Books3, 4 cho PG19, 2 cho CodeParrot, và 8
cho ArXiv. Chúng tôi đặt αret= 1e−9 cho tất cả
các bộ dữ liệu và tỷ lệ học cơ sở là 5e−3, sử dụng
tập validation để lựa chọn siêu tham số.
B Độ phức tạp Tính toán
Độ phức tạp tính toán mỗi token của một lớp attention
trong mô hình transformer với chiều d, |Q| truy
vấn và |K| khóa là 2·d·(|K|·|Q|+ |K|·d+ |Q|·d)
flops.⁷ Bằng cách đặt N=|Q|=|K| và thêm chi
phí lớp feed-forward, chúng tôi có được chi phí
mỗi token cho một khối transformer khi d≫N
là 2d(N+ 2d) + 8 d2≈12d2 flops. Đối với CCA,
chi phí phụ thuộc vào kích thước đoạn C, và số
lượng hàng xóm k. Đặt |K|= 2Ck và |Q|=C,
và giả sử d≫Ck, chi phí mỗi token cho một lớp
CCA là 2d(2Ck+ 2dk+d)≈(4k+ 2)·d2 flops.
Chi phí overhead mỗi token của chúng tôi cho
α∈[0,1] của các khối bao gồm CCA là ≈α(k/3+1/6).
Trong các thí nghiệm của chúng tôi, chúng tôi sử
dụng CCA trong 5 trong 12 lớp nên α=5/12 và
⁷Đối với ma trận truy vấn Q∈R|Q|×d và ma trận khóa/giá
trị K∈R|K|×d, nó bao gồm các phép toán sau: nhân với WQ,
WK, và WV cho các truy vấn, khóa và giá trị, mỗi phép tính
|Q|·d2, |K|·d2, và |K|·d2 flops tương ứng. Tính toán ma
trận attention và nhân nó với các giá trị mỗi phép đòi hỏi
|Q|·|K|·d flops. Cuối cùng, nhân với ma trận đầu ra là thêm
|Q| ·d2 flops.k= 2, và nhận được rằng CCA đóng góp một overhead
khoảng 1.29x. Sử dụng logic tương tự, chi phí không
đổi cho thành phần truy xuất là hai phép chiếu
tuyến tính, hai lớp attention hai chiều bổ sung, và
lớp tăng cường truy vấn dẫn đến 1/nlayers·(7k/6+1/2),
hoặc overhead cuối cùng là 1.49x phù hợp với
overhead thời gian chạy hiệu quả đo được của
chúng tôi là 1.51x (xem Bảng 2).
C Chi tiết huấn luyện bộ truy xuất DPR-style
Chúng tôi theo công thức huấn luyện của DPR
(Karpukhin et al., 2020) trong việc huấn luyện
bộ truy xuất BERT-base với contrastive loss. Mục
tiêu DPR đòi hỏi các positive và hard negative để
hội tụ thành công, và ở đây chúng tôi sử dụng
đoạn BM25 có điểm số top-1 làm ví dụ positive
và đoạn xếp hạng thứ 5 bởi BM25 làm ví dụ hard
negative. Để đảm bảo so sánh công bằng, chúng
tôi huấn luyện bộ truy xuất contrastive của mình
trên 16x nhiều ví dụ hơn so với công thức DPR
gốc mô tả.

--- TRANG 16 ---

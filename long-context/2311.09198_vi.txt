# 2311.09198.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/long-context/2311.09198.pdf
# Kích thước tệp: 3126627 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Không Bao Giờ Lạc Lối Ở Giữa: Làm Chủ Trả Lời Câu Hỏi Ngữ Cảnh Dài
với Huấn Luyện Phân Tách Không Phụ Thuộc Vị Trí
Junqing He, Kunhao Pan, Xiaoqun Dong,
Zhuoyang Song, Yibo Liu, Qianguo Sun,
Yuxin Liang, Hao Wang, Enming Zhang, Jiaxing Zhang
International Digital Economy Academy, Shenzhen, China
hejunqing@idea.edu.cn
Tóm tắt
Trong khi các mô hình ngôn ngữ lớn (LLMs) được
trang bị khả năng nhập văn bản dài hơn so với
trước đây, chúng gặp khó khăn trong việc tìm kiếm
thông tin chính xác trong ngữ cảnh dài. Vấn đề
"lạc lối ở giữa" thách thức hầu hết các LLMs, đề
cập đến sự suy giảm đáng kể về độ chính xác khi
thông tin đúng nằm ở vị trí giữa. Để vượt qua vấn
đề quan trọng này, bài báo này đề xuất tăng cường
khả năng tìm kiếm và phản chiếu thông tin của
LLMs trong ngữ cảnh dài thông qua các nhiệm vụ
được thiết kế đặc biệt gọi là Position-Agnostic
Multi-step QA (PAM QA). Được huấn luyện với
nhiệm vụ này, mô hình của chúng tôi xuất sắc trong
việc tập trung chính xác hơn vào thông tin mong
muốn. Kết quả thực nghiệm cho thấy cải thiện đáng
kể trong Multi-doc QA và các benchmark khác,
vượt qua các mô hình tốt nhất hiện tại 13.7% về
mức tuyệt đối trong cài đặt xáo trộn và 21.5% trong
nhiệm vụ truy xuất đoạn văn. Chúng tôi phát hành
mô hình và mã nguồn để thúc đẩy nghiên cứu liên
quan trong cộng đồng.¹

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLMs), nổi tiếng với
khả năng sinh và học zero-shot đặc biệt trong các
lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) đa dạng,
đã tìm thấy ứng dụng hạ tầng rộng rãi (OpenAI,
2023; Boiko et al., 2023; Cheng et al., 2023; Waisberg
et al., 2023; Hu et al., 2023). Tuy nhiên, LLMs
gặp phải các ảo giác nghiêm trọng, làm giảm đáng
kể hiệu suất của chúng trong QA định hướng kiến
thức, đối thoại và viết lách (Roberts et al., 2020;
Agrawal et al., 2023). Sinh Tăng Cường Truy Xuất
(RAG) là một giải pháp hiệu quả cho vấn đề ảo
giác, và những cải thiện đáng chú ý đã đạt được
bằng cách kết hợp kiến thức hỗ trợ vào đầu vào
của LLMs (Lewis et al., 2020b; Shuster et al., 2021;
Thoppilan et al., 2022; Shi et al., 2023a). Thách
thức cơ bản nhất cần giải quyết trong RAG là ngữ
cảnh dài và Trả lời câu hỏi Đa tài liệu (Multi-doc
QA).

¹Nó có sẵn công khai tại https://huggingface.co/
IDEA-CCNL/Ziya-Reader-13B-v1.0 và https://github.
com/hejunqing/never-lost-in-the-middle

Một số nghiên cứu giải quyết vấn đề với pipeline
hoặc hệ thống phức tạp (Chen et al., 2023a; Lee
et al., 2024), nhưng chúng tôi nhằm cải thiện các
mô hình nền tảng vì chúng là thành phần cốt lõi
của những phương pháp đó. Nghiên cứu kỹ lưỡng
đã được tiến hành để xử lý đầu vào ngữ cảnh dài,
phân loại thành ba hướng chính: Đầu tiên là mở
rộng cửa sổ ngữ cảnh bằng cách sử dụng cửa sổ
trượt (Dai et al., 2019; Xiao et al., 2023). Các nhà
nghiên cứu khác đề xuất tăng cường khả năng ngoại
suy bằng cách cải thiện Mã hóa Vị trí Tương đối
trong Transformers, xương sống của hầu hết LLMs
(Su et al., 2021; Press et al., 2021; Luo et al., 2022;
Vaswani et al., 2017). Cả hai loại sửa đổi này đều
cho thấy cải thiện đáng kể trong mô hình hóa ngôn
ngữ (LM). Loại nghiên cứu thứ ba tập trung vào
nén tuần hoàn bộ nhớ để học chuỗi tầm xa (Rae
et al., 2019; Peng et al., 2023). Phương pháp này
học hiệu quả biểu diễn toàn diện của ngữ cảnh,
thể hiện khả năng đáng chú ý trong tính toán nhanh
và hiệu quả chi phí trong quá trình suy luận. Mặc
dù các phương pháp trên cho thấy hiệu suất mạnh
trong các nhiệm vụ cụ thể và hỗ trợ LLMs với cửa
sổ ngữ cảnh cực dài, tức là GPT3.5-Turbo-16K,
Claude-v1.3-100K và Longchat (Dacheng et al.,
2023), LLMs thất bại trong việc tạo ra câu trả lời
đúng nếu các tài liệu liên quan nằm ở giữa ngữ
cảnh, được gọi là "lạc lối ở giữa" (Liu et al.).
Điều này rất nguy hiểm cho Multi-doc QA. Tuy
nhiên, liệu có sự suy thoái tương tự tồn tại trong
LLMs tiếng Trung hay không vẫn chưa được khám
phá và các giải pháp cho vấn đề này hiếm khi được
nghiên cứu.

Chúng tôi đưa ra giả thuyết rằng quy mô điểm
chú ý của ngữ cảnh đầu tiên tăng lớn sau tiền huấn
luyện và điều chỉnh hướng dẫn trong khi quy mô
của ngữ cảnh giữa, có vị trí ít được huấn luyện
hơn, vẫn nhỏ trong khoảng cách dài đến token
hiện tại.arXiv:2311.09198v2  [cs.CL]  13 Aug 2024

--- TRANG 2 ---
Hình 1: Quy trình làm việc của PAM QA. Các đường nét đứt màu xanh chỉ ra dòng thông tin. Đầu ra mong muốn của một mẫu bao gồm ba phần, tương ứng với ba bước: Lặp lại câu hỏi, dự đoán chỉ số, và tóm tắt câu trả lời. [i] đề cập đến chỉ số của tài liệu thứ i. Một mẫu đầu vào được hiển thị ở trên cùng.

Điều này hạn chế đóng góp của thông tin liên quan
vào câu trả lời và dẫn đến độ chính xác QA thấp
hơn. Để vượt qua cạm bẫy này, chúng tôi đề xuất
huấn luyện phân tách không phụ thuộc vị trí để
cân bằng điểm chú ý trên ngữ cảnh đầu vào. Cụ
thể, chúng tôi thiết kế một nhiệm vụ Multi-doc
QA được điều chỉnh trong đó các tài liệu tích cực
được đặt ở các vị trí tùy ý trong ngữ cảnh giữa
các tài liệu nhiễu. Nhiệm vụ này đưa ra một thách
thức đáng kể, buộc các mô hình phải trích xuất
và tóm tắt thông tin bất chấp sự can thiệp của
những thông tin vô dụng (Ye et al., 2022). Như
con người thường giải quyết các nhiệm vụ phức
tạp bằng cách phân tách để có được kết quả chất
lượng cao hơn (Cheng et al., 2015; Correa et al.,
2023), chúng tôi đã sửa đổi nhiệm vụ Multi-doc
QA thành một nhiệm vụ lý luận đa bước, được
gọi là Position-Agnostic Multi-step QA (PAM QA),
kết hợp Chain-of-Thought (COT, Wei et al.) và
Multi-doc QA không phụ thuộc vị trí. Được huấn
luyện với việc trích xuất rõ ràng câu hỏi và chỉ số
của các tài liệu hỗ trợ trước khi tạo câu trả lời,
các mô hình học cách phân biệt thông tin đúng
khỏi những thông tin nhiễu và chú ý đến chúng.
Nó cũng buộc chú ý đến câu hỏi và các chỉ số hỗ
trợ mạnh hơn mặc dù quy mô chú ý giảm theo
khoảng cách tăng (Su et al., 2021). Kết quả thực
nghiệm về Multi-doc QA và các benchmark khác
cho thấy rằng, chỉ với kích thước cửa sổ ngữ cảnh
1/2 hoặc 1/4, mô hình của chúng tôi cải thiện so
với các mô hình tốt nhất hiện tại (SOTA) 7.0%
trong cài đặt xếp hạng hàng đầu và 13.7% trong
cài đặt xáo trộn. Kết quả cạnh tranh được hiển
thị trong các nhiệm vụ phụ thuộc chú ý khác bao
gồm truy xuất đoạn văn và tóm tắt.

Đóng góp của bài báo này gồm ba phần:
• Bài báo này đề xuất một nhiệm vụ mới tên là
PAM QA để giải quyết vấn đề "lạc lối ở giữa",
điều này rất nguy hiểm cho các tình huống
chuyên sâu về kiến thức. Theo hiểu biết của
chúng tôi, đây là nỗ lực đầu tiên giải quyết
vấn đề bằng cách huấn luyện mô hình trên
các nhiệm vụ đặc biệt.

• Chúng tôi điều tra hành vi của mô hình một
cách sâu sắc, tiết lộ rằng việc thất bại trong
tập trung vào thông tin mục tiêu có thể là
nguyên nhân của "lạc lối ở giữa".

• Các thí nghiệm toàn diện đã chỉ ra rằng PAM
QA được đề xuất có hiệu quả trong việc giải
quyết vấn đề "lạc lối ở giữa". Mô hình của
chúng tôi vượt qua SOTA trong Multi-doc
QA và các nhiệm vụ liên quan khác trên các
benchmark tiếng Trung nổi tiếng. Điều không
tầm thường là khả năng QA tổng quát của
mô hình cũng mạnh và thỏa mãn. Mô hình
được mã nguồn mở để thúc đẩy nghiên cứu
tương lai trong cộng đồng.

2 Position-Agnostic Multi-step QA
Multi-doc QA đề cập đến một loại nhiệm vụ QA
trong đó một mô hình được trình bày với nhiều
tài liệu và được yêu cầu trả lời câu hỏi một cách
chính xác. Nó khó khăn cho cả mô hình và con
người, đòi hỏi truy xuất chính xác, tập hợp thông
tin và hiểu từ các ứng viên nhiễu trong khi gặp
khó khăn với bộ nhớ phai mờ.

Trong tình huống này, phân tách nhiệm vụ, xác
định các vấn đề con và lý luận về chúng, trở nên
thiết yếu (Correa et al., 2023). Chúng tôi đã phân
tách Multi-doc QA khó khăn thành PAM QA.
Nhiệm vụ sáng tạo này bao gồm ba bước, như
được mô tả trong Hình 1.

Toàn bộ quá trình của PAM QA diễn ra như sau:
khi nhận được một câu hỏi, một tập hợp các tài
liệu ứng viên, và một hướng dẫn cụ thể, mô hình

--- TRANG 3 ---
bắt đầu bằng cách tạo tiền tố 1. Sau đó nó tiến
hành tái tạo câu hỏi, dự đoán các chỉ số của bằng
chứng liên quan sau khi kết hợp một cụm từ kết
nối, được ký hiệu là tiền tố 2. Cuối cùng, nó xây
dựng một câu trả lời bằng cách tập hợp thông tin
trước đó, theo một chỉ thị trả lời, tiền tố 3.

2.1 Lặp lại câu hỏi
Bước đầu tiên là lặp lại câu hỏi (QR). Các câu
hỏi được đặt ở phía trước như một biểu diễn nhận
thức ngữ cảnh (Liu et al.). Nhiệm vụ phụ được
bắt đầu với tiền tố 1, "Về câu hỏi:" (hoặc các
biểu hiện có ý nghĩa giống hệt) để thúc đẩy mô
hình.

2.2 Dự đoán Chỉ số
Bằng chứng hỗ trợ không chỉ giúp LLMs tự xác
minh mà còn hỗ trợ người dùng trong việc đánh
giá phản hồi (Menick et al., 2022). Kết quả đáng
chú ý đã được thể hiện trong việc tạo ra các trích
dẫn và tham chiếu (Thoppilan et al., 2022; Menick
et al., 2022). Chúng tôi đưa ra giả thuyết rằng
chỉ thị giúp mã hóa và điều hướng sự chú ý đến
các tài liệu tương ứng. Theo đó, bước thứ hai là
dự đoán chỉ số (IP), cụ thể là dự đoán các chỉ số
của các tài liệu được hỗ trợ cho câu hỏi như một
nhiệm vụ MRC, bắt đầu với tiền tố 2: "Dựa trên
thông tin được đánh số". Không giống như các
nghiên cứu trước đây dự đoán một trích dẫn nguyên
văn được trích xuất từ một nguồn dài hơn được
truy xuất, các chỉ số của bằng chứng tương ứng
là mục tiêu. Đối với trường hợp trong Hình 1,
nhãn của bước này là "Dựa trên thông tin được
đánh số [1],[3]". Xét rằng các chỉ số trong bước
thứ hai chỉ chiếm rất ít token và khó nhấn mạnh
trong tổn thất cross-entropy tuần tự trong quá
trình huấn luyện, một nhiệm vụ MRC chỉ yêu cầu
dự đoán chỉ số của các tài liệu đúng được thêm
vào như một bổ sung.

2.3 Tóm tắt Câu trả lời
Bước thứ ba là tạo ra câu trả lời cuối cùng sau
khi tập hợp thông tin. Nhờ các bước trên, nó có
thể được đơn giản hóa thành một nhiệm vụ tóm
tắt câu trả lời (AS). Bước này bắt đầu với một
chỉ thị như "câu trả lời của tôi là" như tiền tố 3.

Phù hợp với câu tục ngữ "mực nhạt nhất vẫn tốt
hơn trí nhớ tốt nhất," chúng tôi dạy mô hình ghi
chú, biến những chú thích này thành một đường
cao tốc đến kiến thức liên quan. Nó có thể giảm
sự phân tâm của thông tin ngoại lai và làm cho
sự chú ý đến câu hỏi và chỉ số hỗ trợ mạnh hơn
vì quy mô chú ý giảm theo khoảng cách tăng.

3 Xây dựng Dữ liệu Huấn luyện
Chúng tôi trang bị cho mô hình khả năng phân
biệt thông qua điều chỉnh hướng dẫn. Quy trình
huấn luyện bao gồm hai giai đoạn. Chúng tôi mở
rộng cửa sổ ngữ cảnh của LLM lên 8K trong giai
đoạn đầu tiên. Trong giai đoạn thứ hai, mô hình
được huấn luyện với dữ liệu PAM QA để giải
quyết sự thất bại chú ý (hoặc bộ nhớ) được gọi
là "lạc lối ở giữa".

3.1 Mở rộng Cửa sổ Ngữ cảnh
Chúng tôi sử dụng khoảng 300k dữ liệu được
chọn cho điều chỉnh có giám sát tổng quát (SFT).
Dữ liệu bao gồm các loại nhiệm vụ khác nhau
bao gồm QA, MRC, đóng vai, viết lách, lập trình,
dịch thuật, động não, toán học, Mô hình hóa Ngôn
ngữ (LM), và các nhiệm vụ hiểu ngôn ngữ tự
nhiên (NLU) khác như phân loại văn bản. Dữ
liệu được đóng gói đến kích thước cửa sổ 8K
theo phong cách cuộc trò chuyện đa lượt trừ
nhiệm vụ LM, tính toán tổn thất cross-entropy
trên toàn bộ chuỗi.

3.2 PAM QA
Dữ liệu được xây dựng bằng cách định dạng đầu
vào và nối đầu ra mục tiêu của các bước trong
PAM QA. Đầu tiên chúng tôi tạo dữ liệu Multi-doc
QA và điều chỉnh nó thành dữ liệu PAM QA.

Đầu tiên, chúng tôi lọc ra 30K mẫu của danh
mục Fact với một câu trả lời duy nhất từ dataset
DuReader2.0 (He et al., 2018) và 20K mẫu từ
WebCPM (Qin et al., 2023). DuReader2.0 là
dataset MRC tiếng Trung lớn nhất được thu thập
từ các tài liệu Web và QA cộng đồng, chứa 200K
câu hỏi, 420K câu trả lời và 1M tài liệu. Để đảm
bảo chất lượng dữ liệu, chúng tôi sáng tạo sử
dụng một mô hình thưởng để chấm điểm các mẫu
và chọn phần chất lượng cao của chúng với các
ngưỡng, được lấy cảm hứng từ Li et al.. Mô hình
thưởng được huấn luyện với 69K mẫu được xếp
hạng bởi con người để căn chỉnh trong các nhiệm
vụ tổng quát, theo Köpf et al. và Ouyang et al..
Vì cả hai dataset chỉ chứa các mẫu tích cực, các
mẫu tiêu cực được tạo ra một cách tài tình sau
đó.

Vì học tập hợp tác có lợi cho RAG (Izacard et al.,
2022), chúng tôi xây dựng một công cụ tìm kiếm
với tất cả các tài liệu trong dataset tương ứng.
Đối với mỗi mẫu, các tài liệu trong toàn bộ bộ
sưu tập ngoại trừ những tài liệu tích cực được
coi là các mẫu tiêu cực. Chúng tôi truy xuất các
tài liệu từ công cụ tìm kiếm như các ứng viên
tiêu cực cho một phần bao gồm 70% dữ liệu,
trong khi chúng tôi lấy mẫu ngẫu nhiên từ các
ứng viên tiêu cực ban đầu cho

--- TRANG 4 ---
phần còn lại của dữ liệu. Các mẫu tiêu cực được
truy xuất có liên quan hơn đến câu hỏi và khó
phân biệt hơn so với những mẫu tích cực hơn so
với các mẫu ngẫu nhiên. Tiếp theo, các tài liệu
được xáo trộn trong mỗi mẫu trong 50% dữ liệu
để ngăn những tài liệu tích cực luôn ở đầu ngữ
cảnh. Tiếp theo, 25K mẫu được lấy từ các benchmark
truy xuất, T2Rank (Xie et al., 2023) như MRC
liên quan, một bổ sung cho nhiệm vụ 2. Các mẫu
tiêu cực được lấy mẫu ngẫu nhiên từ các bộ sưu
tập tiêu cực khó và xáo trộn với các ứng viên
tích cực. Các chỉ số của các tài liệu tích cực được
ghi lại.

Độ dài tối đa của mỗi mẫu được lấy mẫu từ 1K
đến 8K theo phân phối đều. Điều này đảm bảo
mô hình của chúng tôi có thể xử lý các mẫu có
độ dài đầu vào khác nhau với các tài liệu đúng
nằm ở bất kỳ vị trí nào.

Để cho phép mô hình nhận ra các tình huống
trong đó tài liệu đúng không có mặt, chúng tôi
tạo ra các mẫu "Synthetic Unknown", trong đó
tất cả các tài liệu đều tiêu cực. Câu trả lời cho
những mẫu này là một thuật ngữ không đổi chỉ
ra "Tôi không biết." Loại dữ liệu này chiếm tỷ
lệ 5%.

Cuối cùng, Chúng tôi lấy mẫu một số dữ liệu
SFT tổng quát, chiếm tỷ lệ 20% ở giai đoạn này
để giảm thiểu việc quên thảm khốc (McCloskey
và Cohen, 1989; Rebuffi et al., 2017). Tổng số
mẫu huấn luyện trong giai đoạn này lên đến 90K.

3.3 Huấn luyện
Chúng tôi huấn luyện mô hình dựa trên một LLM
được tiền huấn luyện được điều chỉnh từ LLaMA2,
gọi là Ziya2-13B-Base (Touvron et al., 2023; Gan
et al., 2023; Zhang et al., 2023). Chúng tôi huấn
luyện trong 2 epochs trên 16 GPU A100 trong
cả hai giai đoạn với dữ liệu được xây dựng. Tốc
độ học bắt đầu với 1e-5 sau đó giảm xuống 1e-6
với warmup cho 0.05% bước đầu tiên trong giai
đoạn đầu tiên. Tốc độ học tối đa cho giai đoạn
thứ hai là 5e-6. Flash Attention (Dao et al., 2022)
được sử dụng để tăng tốc quy trình huấn luyện.
Sampling được bật cho tất cả các mô hình trong
quá trình kiểm tra trong các benchmark. Các
hyperparams cho kiểm tra được liệt kê trong
Phụ lục A.

4 Thí nghiệm
Trong phần này, chúng tôi đánh giá khả năng
QA ngữ cảnh dài của mô hình và các LLMs đại
diện hiện có. Bằng cách kiểm tra hiệu suất, chúng
tôi có thể xác minh liệu mô hình của chúng tôi
có vượt qua vấn đề "lạc lối ở giữa" (Liu et al.)
hay không.

Datasets    Độ dài TB    Nguồn         Metrics
Multi-doc.  15,768      DuReader      Rouge-L
Synt.       6,745       C4 Chinese    Accuracy
Summ.       15,380      VCSUM         Rouge-L
Single-doc  6,701       Multifield QA F1
RGB NR.     1,105.7     Self Generated EM

Bảng 1: Thống kê độ dài đầu vào của các dataset
kiểm tra. Multi-doc. là viết tắt của Multi-doc QA.
Synt. và Summ. đại diện cho Synthetic Tasks và
Summarization tương ứng trong khi RGB NR là
viết tắt của nhiệm vụ RGB noise robustness.

4.1 Benchmarks
Chúng tôi tiến hành thí nghiệm trên một benchmark
ngữ cảnh dài, LongBench (Bai et al., 2023) và
Retrieval-Augmented Generation Benchmark (RGB,
Chen et al.). LongBench đo lường các khả năng
khác nhau của đối tượng kiểm tra với ngữ cảnh
đầu vào dài. Cụ thể, chúng tôi kiểm tra các mô
hình trên bốn nhiệm vụ liên quan trong LongBench:
Chinese Multi-doc QA, Synthetic tasks, summarization
và single-doc QA. Chúng tôi cũng sử dụng testbed
noise robustness trong RGB để kiểm tra khả năng
QA trong văn bản ngắn, kiểm tra khả năng trích
xuất thông tin với tỷ lệ nhất định của các tài liệu
nhiễu.

Nhiệm vụ synthetic là một nhiệm vụ truy xuất
tài liệu, trong đó cho một bản tóm tắt, mục tiêu
là tìm tài liệu tương ứng từ một số lượng lớn
ứng viên. Nhiệm vụ này đánh giá khả năng truy
xuất thông tin của LLMs trong ngữ cảnh dài.
Nhiệm vụ summarization đưa ra các bản ghi cuộc
họp cực dài từ nhiều người nói và yêu cầu một
bản tóm tắt. Nó đánh giá khả năng bộ nhớ và
tóm tắt của mô hình. Single-doc QA là một nhiệm
vụ QA ngữ cảnh dài ít tương tự với multi-doc
QA. Chúng tôi tiến hành thí nghiệm trên nhiệm
vụ này để kiểm tra tính mạnh mẽ của mô hình.
Độ dài ngữ cảnh và các thống kê khác của các
dataset được liệt kê trong Bảng 1. Các script
đánh giá được cung cấp bởi trang web chính thức
LongBench² và repository chính thức RGB.

Chúng tôi cũng tái xây dựng nhiệm vụ synthetic
để kiểm tra xem các mô hình có "lạc lối ở giữa"
hay không. Các đoạn văn đúng được di chuyển
đến vị trí thứ 1, 5, 10, 15 và 20 với các đoạn văn
nằm sau vị trí thứ 20 được loại bỏ. Kết quả trong
Hình 2.

Xét rằng các tài liệu trong các mẫu của nhiệm
vụ Multi-doc QA về cơ bản được sắp xếp theo
mức độ liên quan, chúng tôi xáo trộn 10 tài liệu
ứng viên đầu tiên trong mỗi mẫu để làm lộ hiệu
suất thực tế, gọi là Multi-doc QA shuffled.

²https://github.com/THUDM/LongBench

--- TRANG 5 ---
Model                      Multi-doc QA  Synthetic Tasks  Summarization  Single-doc QA
(Baichuan2-Turbo-192K)    36.8          90.0            18.4           44.7
Longchat-v1.5-7B-32K      19.5          7.6             9.9            29.1
ChatGLM2-6B-32K           37.6          64.5            16.1           32.8
(ChatGLM3-6B-32K)         44.8          94.0            17.8           62.3
GPT3.5-Turbo-16K          28.7          77.5            16.0           61.2
Vicuna-v1.5-7B-16K        19.3          5.0             15.1           43.0
Xgen-7B-8K                11.0          3.5             2.2            14.8
InternLM-7B-8K            16.3          0.9             12.4           33.6
Qwen-14B-Chat             18.7          40.0            13.9           31.4
Our model                 44.6          98.5            15.6           34.4

Bảng 2: Kết quả là phần trăm Rouge-L cho Multi-doc QA và Summarization trong khi Synthetic Tasks tính toán
độ chính xác (điểm EM). Các mô hình được phân tách theo dòng theo kích thước cửa sổ ngữ cảnh. ChatGLM3-6B-32K
và Baichuan2-Turbo-192K là các mô hình mới sau nghiên cứu của chúng tôi.

Ngoài ra, chúng tôi tiến hành đánh giá toàn diện
của con người về khả năng mô hình để xem liệu
việc huấn luyện trên PAM QA có làm hại khả
năng tổng quát của LLM hay không. Bộ kiểm
tra chứa 200 câu hỏi từ một loạt các danh mục
rộng.

4.2 Baselines
Chúng tôi so sánh hiệu suất của các LLMs phổ
biến nhất với cửa sổ ngữ cảnh dài. Những baseline
mạnh này bao gồm: GPT3.5T-Turbo-16K mở rộng
cửa sổ ngữ cảnh đến 16K token, trong khi cả
Longchat-v1.5-7B-32K (Dacheng et al., 2023) và
ChatGLM2(3)-6B-32K (Du et al., 2022) đều đẩy
ranh giới xa hơn đến 32K token. Vicuna-v1.5-7B-16K
(Zheng et al., 2023) và Xgen-7B-8K (Nijkamp
et al., 2023) cung cấp các mô hình được tinh chỉnh
trên các cuộc trò chuyện được chia sẻ bởi người
dùng và chuỗi 8K tương ứng. Baichuan2-13B-Chat
(Yang et al., 2023) nổi bật trong few-shot learning
với cửa sổ token 4K, cùng với một biến thể nguồn
đóng lớn hơn. Cuối cùng, Qwen-14B-Chat giới
thiệu một mô hình tham số 14B với NTK động
(dyn, 2023), được huấn luyện trên kích thước
cửa sổ lên đến 8K token.

Chúng tôi đề cập đến các mô hình tăng cường
truy xuất như những mô hình được huấn luyện
với dữ liệu hoặc paradigm tăng cường truy xuất.
Baichuan2-13B-Chat và Baichuan2-Turbo-192k
đều là các mô hình tăng cường truy xuất (Yang
et al., 2023).

5 Kết quả và Thảo luận
Trong phần này, chúng tôi phân tích kết quả thí
nghiệm của các LLMs và thảo luận lý do cho
những phát hiện. Một nghiên cứu ablation cũng
được tiến hành để phân tích sâu. Các chi tiết
khác có trong Phụ lục.

5.1 Kích thước cửa sổ dài hơn không đảm bảo
hiệu suất tốt hơn
Như được thể hiện trong Bảng 2, mô hình của
chúng tôi có Rouge-L là 44.6% trong nhiệm vụ
Multi-doc QA, cao hơn 7.0% so với ChatGLM2-6B-32K,
là mô hình SOTA. Chỉ với kích thước cửa sổ 1/4,
mô hình của chúng tôi có thể vượt trội hơn ChatGLM2-6B-32K
trong nhiệm vụ này. Nó tiết lộ khả năng chú ý
mạnh của mô hình chúng tôi vì đây là một nhiệm
vụ QA mở sách. Dataset Multi-doc QA tiếng Trung
này không cần xem xét tất cả ngữ cảnh, vì các
tài liệu đúng nằm ở đầu ngữ cảnh.

Trong Synthetic Task, cụ thể là nhiệm vụ truy
xuất abstract, mô hình của chúng tôi đạt kết quả
cao nhất với độ chính xác 98.5%, trong số các
mô hình có khả năng ngữ cảnh dài hơn. Điều
này chỉ ra rằng vấn đề "lạc lối ở giữa" gần như
được giải quyết bởi phương pháp được đề xuất
trong bài báo này, miễn là độ dài trung bình được
bao phủ.

Đối với summarization, ChatGLM2-6B-32K và
GPT3.5-Turbo-16K có hiệu suất tương tự với các
kích thước cửa sổ ngữ cảnh khác nhau, cho thấy
rằng kích thước cửa sổ ngữ cảnh dài hơn không
đảm bảo hiệu suất tốt hơn. Rouge-L của mô hình
chúng tôi chỉ thấp hơn SOTA 0.5%, mà không
có bất kỳ dữ liệu summarization nào trong huấn
luyện PAM QA. Vì độ dài trung bình của nhiệm
vụ dài hơn nhiều so với 8K token, mô hình của
chúng tôi với độ dài ngữ cảnh dài hơn sẽ có cải
thiện đầy hứa hẹn.

Chúng tôi quan sát một kết quả vừa phải trong
Single-doc QA từ mô hình của chúng tôi và thấy
nó cạnh tranh trong số các mô hình 8K. GPT3.5-Turbo-16K
đạt kết quả cao nhất 61.2% điểm F1 (trước ChatGLM3-6B-32K),
vượt qua mô hình dài nhất, Baichuan2-Turbo-192K.

--- TRANG 6 ---
Hình 2: Điểm EM trên Synthetic (passage retrieval)
Task từ LongBench với tài liệu đúng được chèn
vào vị trí nhất định từ vị trí thứ 1 đến thứ 20.

5.2 PAM QA giảm thiểu vấn đề lạc lối ở giữa
(và cuối)
Thí nghiệm trên benchmark Synthetic (passage
retrieval) được tái xây dựng hiển thị hiệu suất
của các mô hình trên các vị trí tài liệu tích cực
khác nhau. Cụ thể, đoạn văn đúng cho mỗi mẫu
được chèn vào vị trí thứ 1, 5, 10, 15, và 20 tương
ứng giữa các tài liệu khác trong mỗi thí nghiệm.
Về mặt lý thuyết, chúng ta nên thấy một đường
cong hình U được mô tả trong (Liu et al.), được
gọi là "lạc lối ở giữa". Kết quả được hiển thị
trong Hình 2.

Tuy nhiên, hình này cho thấy rằng hầu hết các
LLMs mã nguồn mở bị lạc không chỉ ở giữa mà
còn ở cuối. Một sự giảm đáng kể được quan sát
khi các tài liệu tích cực được đặt ở vị trí thứ 10.
Bất chấp việc sử dụng các kỹ thuật như Alibi
(Press et al., 2022) hoặc NTK để mở rộng cửa
sổ ngữ cảnh (tức là Baichuan2-13B-Chat và Qwen-14B-Chat),
các mô hình vẫn thể hiện kết quả thấp. Ngược
lại, mô hình của chúng tôi có thể tồn tại trong
các cài đặt vị trí khác nhau, giữ kỷ lục 99%.
Nó tiết lộ hiệu quả của huấn luyện PAM QA.

5.3 Các mô hình bị đánh bại bởi dataset xáo
trộn, thất bại chú ý là thủ phạm
Hình 4 thể hiện hiệu suất của các mô hình trên
Multi-doc QA trước và sau khi xáo trộn. Chúng
ta có thể thấy một sự suy giảm mạnh trong tất
cả ba mô hình trừ mô hình của chúng tôi. Khoảng
cách lớn nhất đạt 17.3%, từ ChatGLM2-6B-32K.
Trong khi đó, Baichuan2-13B-Chat cũng có sự
giảm 7% mặc dù các tài liệu xáo trộn nằm trong
độ dài ngữ cảnh của nó. Do đó, LLMs không có
cửa sổ ngữ cảnh cực dài cũng gặp khó khăn trong
việc đối phó với thách thức. Mô hình của chúng
tôi là mô hình mạnh mẽ nhất với sự giảm 3.7%.

Noise Ratio  0      0.2    0.4    0.6    0.8
GPT3.5-Turbo 95.67  94.67  91.00  87.67  70.67
ChatGLM2-6B  86.67  82.33  76.67  72.33  54.00
(ChatGLM3-6B) 91.67 90.00  89.00  84.67  66.33
Baichuan2-13B-Chat 93.00 90.33 89.00 82.33 63.33
Qwen-14B-Chat 94.67 92.00 88.00 85.30 69.67
Our model    96.00  90.67  90.00  85.50  67.33

Bảng 3: Hiệu suất trong testbed RGB noise robustness.
Điểm EM tính theo phần trăm. ChatGLM3-6B là một
mô hình mới sau nghiên cứu của chúng tôi.

Để khám phá nguyên nhân của sự suy giảm và
kiểm tra khả năng chú ý của các mô hình, chúng
tôi hình dung điểm chú ý của lớp cuối cùng cho
đầu vào giống hệt nhau. Chúng tôi lặp lại một
câu bao gồm câu trả lời đúng 20 lần như ngữ
cảnh để tìm xem liệu tất cả chúng có được nổi
bật trong quy trình self-attention trong các mô
hình hay không. Điểm chú ý của ChatGLM2-6B-32K
và Mô hình của chúng tôi trên đầu vào được mô
tả trong Hình 3.

Chúng ta có thể thấy điểm chú ý trên các tài
liệu đang phai mờ trong ChatGLM2-6B-32K, vì
ngữ cảnh sau 100 token đầu tiên gần như bị bỏ
qua. Tình huống khá khác biệt khi nói đến mô
hình của chúng tôi. 20 đỉnh điểm chú ý được
quan sát (cái cuối cùng gần với đầu hướng dẫn),
tương ứng với các câu trả lời trong câu. Nó tiết
lộ rằng sự chú ý đến các token liên quan là chìa
khóa cho khoảng cách hiệu suất giữa các mô
hình. Các mô hình gặp khó khăn trong việc tập
trung chính xác vào các token đúng, chú ý rất
nhiều đến các token đầu và cuối (nơi hướng dẫn
và truy vấn thường được đặt), đây là thủ phạm
của vấn đề "lạc lối ở giữa".

5.4 Kết quả cạnh tranh được quan sát trong
Multi-doc QA văn bản ngắn
Như được báo cáo trong Bảng 3, mô hình của
chúng tôi có hiệu suất cạnh tranh trong số các
mô hình mã nguồn mở trên multi-doc QA văn
bản ngắn mặc dù không được huấn luyện với
bất kỳ văn bản ngắn nào. Ngay cả so với các
LLMs tiếng Trung phổ biến mới nhất, Qwen-14B-Chat
và ChatGLM3-6B-32K, kết quả của mô hình chúng
tôi cao hơn dưới cài đặt tỷ lệ nhiễu trong [0,0.4,0.6].

5.5 Khả năng tổng quát được bảo tồn với Huấn
luyện PAM QA
Một so sánh side-by-side (SBS) được thực hiện
bởi 3 người chú thích con người để kiểm tra khả
năng tổng quát của mô hình chúng tôi. Các khả
năng tổng quát bao gồm hiểu biết thường thức,
toán học, lý luận, QA, viết lách, vô hại,

--- TRANG 7 ---
(a) ChatGLM2-6B-32K
(b) Mô hình của chúng tôi
Hình 3: Điểm chú ý trên các token đầu vào trong quy trình self-attention trong ChatGLM2-6B-32K và mô hình của chúng tôi trên một tài liệu được lặp lại 20 lần. Độ dài khác biệt với tokenizers.

Hình 4: Hiệu suất trên Multi-doc QA trước và sau khi xáo trộn. ChatGLM2 là viết tắt của ChatGLM2-6B-32K, GPT3.5-Turbo là viết tắt của GPT3.5-Turbo-16K. Điểm tính theo phần trăm.

v.v. được kiểm tra trong bài kiểm tra, như được thể hiện trong Hình 5. Các người chú thích được yêu cầu chọn một câu trả lời tốt hơn trong số hai câu trả lời được đưa ra trừ khi các câu trả lời đều tệ hoặc giống nhau, như trong (Zheng et al., 2023). Những người chú thích đều là học viên thạc sĩ. Họ không biết về các mô hình và thông tin khác. Kết quả so sánh với các mô hình có kích thước tương tự, Ziya-LLaMa-13B-v1.1³ và Baichuan2-13B-Chat tương ứng được minh họa trong Hình 6. Chúng tôi cũng so sánh mô hình của chúng tôi với cùng mô hình cơ sở sau huấn luyện SFT đầy đủ, Ziya2-13B-SFT.

³https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1.1

[THIS IS FIGURE/CHART: A complex hierarchical diagram showing task distribution including Role-play, Translation tasks (From EN to ZH, From ZH to EN), Code tasks (Generation, Completion, Translation, Commenting), NLU tasks (Information Extraction, Text Classification, Reading Comprehension, Summarization), Harmlessness, and various subject areas (Cultural, Daily, Scientific, Social, History) with difficulty levels (Easy, Medium, Hard, Complicated) and educational levels (Secondary school through University). Also includes categories for Open-ended, Real-life, Quizzes, Creative writing tasks, etc.]

Hình 5: Phân phối các nhiệm vụ trong bài kiểm tra khả năng tổng quát.

Hình 6 tóm tắt sở thích của con người giữa mô hình của chúng tôi và các LLMs mã nguồn mở khác. Mặc dù mô hình của chúng tôi chỉ được huấn luyện với dữ liệu PAM QA, nó hoạt động hơi kém hơn Baichuan2-13B-Chat nhưng tốt hơn Ziya-LLaMa-13B-v1.1 và Ziya2-13B-SFT đáng kể. Do đó, các khả năng tổng quát được duy trì sau huấn luyện PAM QA.

5.6 Nghiên cứu Ablation
Mỗi bước trong PAM QA đều quan trọng. Ở đây chúng tôi kiểm tra đóng góp của mỗi bước trong PAM QA. Các biến thể được đánh giá trên Multi-doc QA và Synthetic tasks. Kết quả của nghiên cứu ablation này được liệt kê trong Bảng 4.

--- TRANG 8 ---
Hình 6: Kết quả SBS về đánh giá khả năng tổng quát chứa một loạt các nhiệm vụ rộng. Ziya2-13B-SFT là phiên bản SFT đầy đủ dựa trên cùng mô hình được tiền huấn luyện.

Variants          Multi-doc QA  Synt.
Our model         44.6          98.5
- QR              38.8          98.0
- QR - IP         37.8          1.3
Only-CWE          8.7           7.5

Bảng 4: Synt. là viết tắt của Synthetic tasks. Kết quả tính theo phần trăm. QR là viết tắt của question repetition. IP là viết tắt của index prediction. Only-CWE đại diện cho mô hình được tinh chỉnh chỉ với mở rộng cửa sổ ngữ cảnh.

Không có question repetition, bước đầu tiên trong PAM QA, có thể quan sát sự giảm 5.8% trong Multi-doc QA, cho thấy đóng góp không thể tránh khỏi của nó đối với hiệu suất cao. Nó tăng cường sự chú ý của câu hỏi bằng cách lặp lại câu hỏi trước. Sau đó mô hình có thể trực tiếp chú ý đến câu hỏi trong các bước tiếp theo mà không cần đi qua ngữ cảnh dài, giảm sự phân tâm của ngữ cảnh khi thực hiện self-attention.

Khi bước index prediction (IP) bị loại bỏ, sự giảm rõ rệt trong Synthetic tasks nhấn mạnh tầm quan trọng của nó. Nó không chỉ dạy LLMs phân biệt giữa thông tin liên quan và không liên quan mà còn thay đổi hành vi trước đó của mô hình (tức là tìm kiếm thông tin từ đầu và cuối ngữ cảnh). Trong khi đó, nó tinh giản quy trình bằng cách cho phép các mô hình tập trung vào thông tin trừu tượng liên quan, thay vì liên tục quét các token đầu vào mở rộng. Một sự suy giảm hiệu suất trong multi-doc QA cũng cho thấy đóng góp của IP. Vì quy mô của điểm chú ý giảm theo khoảng cách tăng (Su et al., 2021), các mô hình với rotary position embeddings (RoPE) gặp khó khăn trong việc nhớ các token từ xa mà không có huấn luyện. Với hai bước trước đó, câu hỏi và bằng chứng có khả năng đúng được liệt kê chỉ vài token phía trước. Điều này giảm xác suất quên câu hỏi và ngữ cảnh bằng cách giảm khoảng cách.

Một khoảng cách lớn giữa kết quả của mô hình chúng tôi và kết quả không có QR và IP, cho thấy cải thiện đáng kể từ huấn luyện PAM QA. Chúng tôi hình dung điểm chú ý khi dự đoán token đầu tiên và phát hiện các câu hỏi và chỉ số được tạo ra được nổi bật, như thể hiện trong Hình 7 trong Phụ lục D.

So với Only-CWE, mô hình biến thể không có các bước QR và IP cũng đạt được cải thiện 29.1%, cho thấy hiệu quả của các ứng viên tiêu cực không phụ thuộc vị trí và đầy thách thức. Bằng cách chuyển đổi Multi-doc QA thành PAM QA, cùng dữ liệu có thể tăng hiệu suất 6.8% trong Multi-doc QA, và 97.2% trong Synthetic Tasks, tiết lộ sức mạnh của huấn luyện phân tách nhiệm vụ.

Tính cần thiết của Huấn luyện. Để điều tra xem huấn luyện (tinh chỉnh) có cần thiết hay không, chúng tôi thực hiện prompting COT đa bước theo phong cách "đầu tiên dự đoán chỉ số của các tài liệu liên quan" và "theo thông tin, câu trả lời cuối cùng là" trên các mô hình khác nhau. Chúng tôi loại bỏ bước lặp lại câu hỏi trong COT để có hiệu suất tốt hơn. Kết quả trong Bảng 5.

Model                        Strategy    Multi-doc.  Synt.
GPT3.5-Turbo-16K            w/o COT     28.7        77.0
GPT3.5-Turbo-16K            w/ COT      28.3        63.9
Yi-34B-Chat                 w/o COT     14.9        35.3
Yi-34B-Chat                 w/ COT      2.5         58.6
Yi-34B-Reader (Ours)        w/o COT     45.1        50.4
Ziya2-13B-SFT               w/o COT     11.0        6.3
Ziya2-13B-SFT               w/ COT      1.1         2.1
Ziya2-Reader (Ours)         w/o COT     44.6        98.5

Bảng 5: So sánh kết quả từ các chiến lược khác nhau: các mô hình với (w/), không có (w/o) suy luận COT đa bước và với huấn luyện PAM (Ours).

Như được thể hiện bởi kết quả vượt trội của các mô hình của chúng tôi so với suy luận COT đa bước, huấn luyện là thiết yếu để tối ưu hóa hiệu suất. Đặc biệt trong Multi-doc QA, LLMs có xu hướng tạo ra một câu trả lời với nhiều ảo giác hơn sau khi dự đoán một danh sách chỉ số của các tài liệu liên quan mà không có tinh chỉnh. Chúng tôi phát hiện các mô hình với COT đa bước gặp khó khăn trong việc xử lý các hướng dẫn phức tạp và duy trì bộ nhớ ngữ cảnh dài.

Khả năng tổng quát của Phương pháp. Để minh họa sự tổng quát của phương pháp, chúng tôi cũng thực hiện huấn luyện giống hệt trên một mô hình được tiền huấn luyện tiếng Trung khác, Yi-34B-Base⁴, một mô hình được tiền huấn luyện 34B hàng đầu trong LLM Benchmarks. Bảng 6 liệt kê so sánh

⁴https://huggingface.co/01-ai/Yi-34B

--- TRANG 9 ---
Model                      Multi-doc QA  Synthetic Task  Summarization
Yi-34B-Chat               14.9          35.3           13.8
Yi-34B-Reader (Ours)      45.1          50.4           14.2
Ziya2-13B-SFT            11.0          6.3            12.6
Ziya2-13B-Reader (Ours)  44.6          98.5           15.6

Bảng 6: So sánh các mô hình được huấn luyện với PAM và các mô hình SFT đầy đủ chính thức dựa trên cùng mô hình được tiền huấn luyện. Ziya2-13B-SFT là mô hình được huấn luyện trên cùng mô hình được tiền huấn luyện, Ziya2-13B-Base.

của mô hình chúng tôi huấn luyện (Yi-34B-Reader) và phiên bản điều chỉnh hướng dẫn chính thức, Yi-34B-Chat⁵.

Kết quả cho thấy phương pháp của chúng tôi có thể được tổng quát hóa cho các LLMs khác. Tuy nhiên, khó thay đổi hành vi của Yi-34B-Base chỉ sử dụng 100K dữ liệu PAM QA so với mô hình 13B vì nó đã được tiền huấn luyện khá (có thể quá) đầy đủ. Điều này dẫn đến kết quả thấp hơn trong nhiệm vụ synthetic so với Ziya2-Reader 13B.

6 Nghiên cứu Liên quan

6.1 Mô hình Ngôn ngữ Tăng cường Truy xuất
Các Mô hình Ngôn ngữ Tăng cường Truy xuất (RALMs) đánh dấu tiến bộ đáng chú ý trong NLP bằng cách hợp nhất các khả năng của LMs mở rộng với độ chính xác và phức tạp được cung cấp bởi các nguồn kiến thức bên ngoài. (Guu et al., 2020; Lewis et al., 2020a; Izacard et al., 2022). Những mô hình này sử dụng một bộ truy xuất để tìm kiếm thông qua một khối lượng lớn bằng chứng, như Wikipedia, để tìm các tài liệu cụ thể liên quan đến truy vấn của người dùng. Sau đó, một thành phần đọc được sử dụng để kiểm tra cẩn thận những tài liệu này và tạo ra một phản hồi. Quy trình hai bước này đảm bảo cả tính liên quan và độ sâu trong các câu trả lời được tạo ra. Các nỗ lực nghiên cứu gần đây đã tập trung vào việc tăng cường hiệu suất của bộ truy xuất (Karpukhin et al., 2020; Sachan et al., 2023) hoặc bộ đọc (Izacard và Grave, 2020; Cheng et al., 2021), huấn luyện hệ thống end-to-end (Lewis et al., 2020a; Sachan et al., 2021), và tích hợp các hệ thống truy xuất với các mô hình ngôn ngữ lớn black-box (Shi et al., 2023b; Yu et al., 2023; Trivedi et al., 2023)

6.2 RALMs Được Điều chỉnh cho Ngữ cảnh Dài và Nhiễu
Nghiên cứu gần đây nhấn mạnh ảnh hưởng của độ dài ngữ cảnh và vị trí của ngữ cảnh liên quan đến hiệu suất của LLMs (Krishna et al., 2023; Bai et al., 2023; Liu et al.). Nghiên cứu gần gũi nhất với nghiên cứu của chúng tôi là nghiên cứu của (Yoran et al., 2023), huấn luyện RALMs để bỏ qua các ngữ cảnh không liên quan. Một phương pháp huấn luyện giống COT đồng hình đã được đề xuất để giải quyết các vấn đề toán học và lập trình, phát ra các bước tính toán trung gian vào một "scratchpad" (Nye et al., 2021). Tuy nhiên, họ đã bỏ qua các tình huống ngữ cảnh dài, cụ thể là vấn đề "lạc lối ở giữa", một cân nhắc chính trong nghiên cứu của chúng tôi.

Một nghiên cứu trước đó đã xem xét mô hình hóa multi-doc trong huấn luyện được đề xuất bởi Caciularu et al.. Sau khi chia ngữ cảnh dài thành các mảnh và tạo cặp QA dựa trên những mảnh nổi bật được chọn, họ yêu cầu các mô hình dự đoán các câu nổi bật và câu trả lời được che dấu, cho các mảnh khác và các câu hỏi được tạo ra. Cải thiện đáng kể trong các benchmark multi-hop QA sau khi tinh chỉnh với tập huấn luyện được báo cáo với chi phí đắt đỏ của tiền huấn luyện. Tuy nhiên, không có tập huấn luyện trong hầu hết các benchmark ngày nay và nó thất bại trong việc thực hiện các nhiệm vụ đa dạng trong cài đặt zero-shot.

7 Kết luận
Trong bài báo này, chúng tôi giả định rằng hiện tượng "lạc lối ở giữa" được công nhận rộng rãi có thể do sự chú ý yếu đến thông tin mục tiêu. Chúng tôi phát hiện các LLMs tiếng Trung phổ biến bị "lạc" cả ở giữa và cuối. Một phương pháp mới được đề xuất để giải quyết sự thiếu hụt trong LLMs bằng cách huấn luyện các mô hình với Position-Agnostic Multi-step (PAM) QA. Kết quả thí nghiệm cho thấy tính ưu việt và hiệu quả của phương pháp chúng tôi, vượt qua các LLMs SOTA trong Multi-doc QA và truy xuất đoạn văn đáng kể, chỉ với kích thước cửa sổ ngữ cảnh 1/4. Bằng cách xáo trộn các tài liệu ứng viên trong các benchmark mở, hiệu suất suy giảm được quan sát trong tất cả các mô hình, trong đó mô hình của chúng tôi là mô hình mạnh mẽ nhất. Nghiên cứu ablation cũng tiết lộ hiệu quả đáng kể của PAM QA và đóng góp tích cực của các thành phần của nó. Nghiên cứu của chúng tôi cũng phát hiện rằng LMs với cửa sổ ngữ cảnh cực dài không đảm bảo hiệu suất tốt hơn trong Multi-doc QA và các nhiệm vụ truy xuất đoạn văn. Chúng tôi hy vọng nghiên cứu của chúng tôi cung cấp cái nhìn sâu sắc về vấn đề "lạc lối ở giữa" và làm sáng tỏ việc phát triển các LLMs thông minh hơn.

--- TRANG 10 ---
Hạn chế
Nghiên cứu của chúng tôi bao gồm vấn đề "lạc lối ở giữa" quan trọng và thí nghiệm với Benchmarks tiếng Trung trên các LLMs tiếng Trung và tiếng Anh phổ biến có khả năng ngữ cảnh dài. Những cải thiện trong các nhiệm vụ được kiểm tra không ngụ ý những nâng cấp tương tự trong tất cả các khía cạnh, như toán học và lý luận. Dữ liệu PAM QA được xây dựng đã được sử dụng sau hoặc trong SFT, với hiệu quả trong giai đoạn tiền huấn luyện và RLHF chưa được khám phá.

Phương pháp xây dựng dữ liệu chủ yếu dựa trên multi-doc QA và cho thấy lợi ích đáng kể trong các nhiệm vụ liên quan. Cải thiện trong các nhiệm vụ ngữ cảnh dài khác không ấn tượng bằng multi-doc QA và synthetic tasks vì các khả năng khác được yêu cầu nhiều hơn so với phân biệt và tập trung. Những tình huống đó không được xem xét trong bài báo này.

Phương pháp được đề xuất không phụ thuộc ngôn ngữ và có thể được áp dụng cho các dataset của các ngôn ngữ khác. Cốt lõi của phương pháp nằm trong việc xây dựng các mẫu với các tài liệu tiêu cực liên quan đầy thách thức, các vị trí đa dạng của các mẫu tích cực và câu trả lời lý luận đa bước. Do đó, phương pháp có thể giảm thiểu vấn đề "lạc lối ở giữa" trong các ngôn ngữ khác.

Tài liệu tham khảo
2023. Dynamically scaled rope further increases performance of long context llama with zero fine-tuning.

Ayush Agrawal, Lester Mackey, và Adam Tauman Kalai. 2023. Do language models know when they're hallucinating references? arXiv preprint arXiv:2305.18248.

Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang, và Juanzi Li. 2023. Longbench: A bilingual, multitask benchmark for long context understanding. arXiv preprint arXiv:2308.14508.

DaniilA. Boiko, Robert MacKnight, và Gabe Gomes. 2023. Emergent autonomous scientific research capabilities of large language models.

Avi Caciularu, Matthew E. Peters, Jacob Goldberger, Ido Dagan, và Arman Cohan. 2023. Peek across: Improving multi-document modeling via cross-document question-answering.

Howard Chen, Ramakanth Pasunuru, Jason Weston, và Asli Celikyilmaz. 2023a. Walking down the memory maze: Beyond context limit through interactive reading.

Jiawei Chen, Hongyu Lin, Xianpei Han, và Le Sun. 2023b. Benchmarking large language models in retrieval-augmented generation.

Hao Cheng, Yelong Shen, Xiaodong Liu, Pengcheng He, Weizhu Chen, và Jianfeng Gao. 2021. UnitedQA: A hybrid approach for open domain question answering. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3080–3090, Online. Association for Computational Linguistics.

Justin Cheng, Jaime Teevan, Shamsi T Iqbal, và Michael S Bernstein. 2015. Break it down: A comparison of macro-and microtasks. Trong Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, pages 4061–4064.

Kunming Cheng, Qiang Guo, Yongbin He, Yanqiu Lu, Shuqin Gu, và Haiyang Wu. 2023. Exploring the potential of gpt-4 in biomedical engineering: the dawn of a new era. Annals of Biomedical Engineering, pages 1–9.

Carlos G Correa, Mark K Ho, Frederick Callaway, Nathaniel D Daw, và Thomas L Griffiths. 2023. Humans decompose tasks by trading off utility and computational cost. PLOS Computational Biology, 19(6):e1011087.

Li* Dacheng, Shao* Rulin, Xie Anze, Sheng Ying, Zheng Lianmin, Gonzalez Josep E., Stoica Ion, Ma Xuezhe, và Hao Zhang. 2023. How long can open-source llms truly promise on context length?

Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V Le, và Ruslan Salakhutdinov. 2019. Transformer-xl: Attentive language models beyond a fixed-length context. arXiv preprint arXiv:1901.02860.

Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, và Christopher Ré. 2022. FlashAttention: Fast and memory-efficient exact attention with IO-awareness. Trong Advances in Neural Information Processing Systems.

Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, và Jie Tang. 2022. Glm: General language model pretraining with autoregressive blank infilling. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 320–335.

Ruyi Gan, Ziwei Wu, Renliang Sun, Junyu Lu, Xiaojun Wu, Dixiang Zhang, Kunhao Pan, Ping Yang, Qi Yang, Jiaxing Zhang, et al. 2023. Ziya2: Data-centric learning is all llms need. arXiv preprint arXiv:2311.03301.

Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, và Mingwei Chang. 2020. Retrieval augmented language model pre-training. Trong International conference on machine learning, pages 3929–3938. PMLR.

Wei He, Kai Liu, Jing Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu,

--- TRANG 11 ---
Qiaoqiao She, et al. 2018. Dureader: a chinese machine reading comprehension dataset from real-world applications. ACL 2018, page 37.

Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, và Hang Zhao. 2023. Chatdb: Augmenting llms with databases as their symbolic memory. arXiv preprint arXiv:2306.03901.

Gautier Izacard và Edouard Grave. 2020. Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282.

Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, và Edouard Grave. 2022. Few-shot learning with retrieval augmented language models. arXiv preprint arXiv:2208.03299.

Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, và Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906.

Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Richárd Nagyfi, et al. 2023. Openassistant conversations–democratizing large language model alignment. arXiv preprint arXiv:2304.07327.

Kalpesh Krishna, Erin Bransom, Bailey Kuehl, Mohit Iyyer, Pradeep Dasigi, Arman Cohan, và Kyle Lo. 2023. Longeval: Guidelines for human evaluation of faithfulness in long-form summarization.

Kuang-Huei Lee, Xinyun Chen, Hiroki Furuta, John Canny, và Ian Fischer. 2024. A human-inspired reading agent with gist memory of very long contexts.

Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020a. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459–9474.

PatrickS.H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Michael Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, và Douwe Kiela. 2020b. Retrieval-augmented generation for knowledge-intensive nlp tasks. arXiv: Computation and Language,arXiv: Computation and Language.

Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy, Jason Weston, và Mike Lewis. 2023. Self-alignment with instruction back-translation. arXiv preprint arXiv:2308.06259.

NelsonF Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, và Percy Liang. Lost in the middle: How language models use long contexts.

Shengjie Luo, Shanda Li, Shuxin Zheng, Tie-Yan Liu, Liwei Wang, và Di He. 2022. Your transformer may not be as powerful as you expect. Advances in Neural Information Processing Systems, 35:4301–4315.

Michael McCloskey và Neal J. Cohen. 1989. Catastrophic interference in connectionist networks: the sequential learning problem, page 109–165.

Jacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song, Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham, Geoffrey Irving, et al. 2022. Teaching language models to support answers with verified quotes. arXiv preprint arXiv:2203.11147.

Erik Nijkamp, Tian Xie, Hiroaki Hayashi, Bo Pang, Congying Xia, Chen Xing, Jesse Vig, Semih Yavuz, Philippe Laban, Ben Krause, et al. 2023. Long sequence modeling with xgen: A 7b llm trained on 8k input sequence length. Salesforce AI Research Blog.

Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, và Augustus Odena. 2021. Show your work: Scratchpads for intermediate computation with language models.

OpenAI OpenAI. 2023. Gpt-4 technical report.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744.

Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Huanqi Cao, Xin Cheng, Michael Chung, Matteo Grella, Kranthi Kiran GV, Xuzheng He, Haowen Hou, Przemyslaw Kazienko, Jan Kocon, Jiaming Kong, Bartlomiej Koptyra, Hayden Lau, Krishna Sri Ipsit Mantri, Ferdinand Mom, Atsushi Saito, Xiangru Tang, Bolun Wang, Johan S. Wind, Stanislaw Wozniak, Ruichong Zhang, Zhenyuan Zhang, Qihang Zhao, Peng Zhou, Jian Zhu, và Rui-Jie Zhu. 2023. Rwkv: Reinventing rnns for the transformer era.

Ofir Press, Noah A Smith, và Mike Lewis. 2021. Train short, test long: Attention with linear biases enables input length extrapolation. arXiv preprint arXiv:2108.12409.

Ofir Press, Noah A. Smith, và Mike Lewis. 2022. Train short, test long: Attention with linear biases enables input length extrapolation.

Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun Zhu, Yankai Lin, Xu Han, Ning Ding, Huadong Wang, Ruobing Xie, Fanchao Qi, Zhiyuan Liu, Maosong Sun, và Jie Zhou. 2023. WebCPM: Interactive web search for Chinese long-form question answering. Trong Proceedings of the 61st Annual

--- TRANG 12 ---
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8968–8988, Toronto, Canada. Association for Computational Linguistics.

Jack W. Rae, Anna Potapenko, Siddhant M. Jayakumar, và Timothy P. Lillicrap. 2019. Compressive transformers for long-range sequence modelling.

Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. 2017. icarl: Incremental classifier and representation learning. Trong Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 2001–2010.

Adam Roberts, Colin Raffel, và Noam Shazeer. 2020. How much knowledge can you pack into the parameters of a language model? arXiv preprint arXiv:2002.08910.

Devendra Singh Sachan, Mike Lewis, Dani Yogatama, Luke Zettlemoyer, Joelle Pineau, và Manzil Zaheer. 2023. Questions are all you need to train a dense passage retriever. Transactions of the Association for Computational Linguistics, 11:600–616.

Devendra Singh Sachan, Siva Reddy, William Hamilton, Chris Dyer, và Dani Yogatama. 2021. End-to-end training of multi-document reader and retriever for open-domain question answering.

Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, và ScottWen-tau Yih. 2023a. Trusting your evidence: Hallucinate less with context-aware decoding.

Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, và Wen tau Yih. 2023b. Replug: Retrieval-augmented black-box language models.

Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, và Jason Weston. 2021. Retrieval augmentation reduces hallucination in conversation. Trong Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3784–3803.

Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, và Yunfeng Liu. 2021. Roformer: Enhanced transformer with rotary position embedding. arXiv preprint arXiv:2104.09864.

Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.

Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, và Ashish Sabharwal. 2023. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10014–10037, Toronto, Canada. Association for Computational Linguistics.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30.

Ethan Waisberg, Joshua Ong, Mouayad Masalkhi, Sharif Amit Kamran, Nasif Zaman, Prithul Sarker, Andrew G Lee, và Alireza Tavakkoli. 2023. Gpt-4: a new era of artificial intelligence in medicine. Irish Journal of Medical Science (1971-), pages 1–4.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824–24837.

Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, và Mike Lewis. 2023. Efficient streaming language models with attention sinks. arXiv preprint arXiv:2309.17453.

Xiaohui Xie, Qian Dong, Bingning Wang, Feiyang Lv, Ting Yao, Weinan Gan, Zhijing Wu, Xiangsheng Li, Haitao Li, Yiqun Liu, et al. 2023. T2ranking: A large-scale chinese benchmark for passage ranking. arXiv preprint arXiv:2304.03679.

Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, JunTao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, và Zhiying Wu. 2023. Baichuan 2: Open large-scale language models.

Ziyi Ye, Xiaohui Xie, Yiqun Liu, Zhihong Wang, Xuesong Chen, Min Zhang, và Shaoping Ma. 2022. Towards a better understanding of human reading comprehension with brain signals. Trong Proceedings of the ACM Web Conference 2022, pages 380–391.

Ori Yoran, Tomer Wolfson, Ori Ram, và Jonathan Berant. 2023. Making retrieval-augmented language models robust to irrelevant context. arXiv preprint arXiv:2310.01558.

--- TRANG 13 ---
Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, và Meng Jiang. 2023. Generate rather than retrieve: Large language models are strong context generators.

Jiaxing Zhang, Ruyi Gan, Junjie Wang, Yuxiang Zhang, Lin Zhang, Ping Yang, Xinyu Gao, Ziwei Wu, Xiaoqun Dong, Junqing He, Jianheng Zhuo, Qi Yang, Yongfeng Huang, Xiayu Li, Yanghan Wu, Junyu Lu, Xinyu Zhu, Weifeng Chen, Ting Han, Kunhao Pan, Rui Wang, Hao Wang, Xiaojun Wu, Zhongshen Zeng, và Chongpei Chen. 2023. Fengshenbang 1.0: Being the foundation of chinese cognitive intelligence.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, và Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena.

A Siêu tham số
Chúng tôi sử dụng các cài đặt sau trong giai đoạn suy luận trong bài kiểm tra LongBench: do_sample = True, topp= 0.85, temperature = 0.8, repetition_penalty = 1.0, early_stopping = True.

Đối với testbed RGB noise robustness, temperature được đặt thành 0.2.

B Đánh giá Dự đoán Chỉ số
Chúng tôi áp dụng chú thích con người cho 140 mẫu trong Multi-doc QA để điều tra độ chính xác và recall của bước index prediction (IP). Độ chính xác macro là 43.0% và recall là 70.9%. Chúng là kết quả từ việc dự đoán nhiều chỉ số hơn so với ground truths. Các LLMs có thể có khả năng phản chiếu để kiểm tra các chỉ số và cuối cùng tạo ra câu trả lời đúng. Do đó, bước IP có lợi cho việc tạo câu trả lời ngay cả trong độ chính xác thấp.

C Minh họa PAM QA
Một trường hợp của Multi-doc QA và câu trả lời được tạo bởi Mô hình của chúng tôi và ChatGPT3.5 được thể hiện trong Bảng 7.

D Hình dung điểm chú ý trên các token trong bước tóm tắt câu trả lời
Bản đồ nhiệt của điểm chú ý của mỗi token khi tạo câu trả lời cuối cùng được hiển thị trong Hình 7.

E Hệ thống Chú thích
Ảnh chụp màn hình của hệ thống chú thích trong đánh giá khả năng tổng quát SBS được thể hiện trong Hình E.

--- TRANG 14 ---
Tiếng Trung:
Tiếng Anh:
<s><human>: Đưa ra câu hỏi: Dân số thế giới đỉnh cao dự kiến trong triển vọng dân số 2022 của LHQ là bao nhiêu?
Các bài luận:
[1] Báo cáo World Population Prospects 2022 được phát hành bởi Liên Hợp Quốc dự đoán rằng Ấn Độ sẽ vượt qua Trung Quốc trở thành quốc gia đông dân nhất thế giới vào năm tới.
[2] Theo báo cáo World Population Prospects 2022 được xuất bản bởi Bộ Kinh tế và Xã hội Liên Hợp Quốc, dân số toàn cầu dự kiến đạt 8 tỷ vào ngày 15 tháng 11 năm 2022. Báo cáo cũng dự đoán rằng dân số thế giới dự kiến đạt đỉnh khoảng 10.4 tỷ vào những năm 2080 và duy trì ở mức đó đến năm 2100.
[3] Vào ngày 15 tháng 11, theo thống kê thời gian thực từ trang web thống kê Worldometers, dân số toàn cầu đã vượt quá 8 tỷ.
[4] Cơ quan giám sát hạt nhân Liên Hợp Quốc (LHQ) vào thứ Ba đã phê duyệt kế hoạch "tháo dỡ nước thải hạt nhân" của Nhật Bản, cho phép Nhật Bản xả hơn 1 triệu tấn nước thải hạt nhân từ nhà máy điện hạt nhân Fukushima Daiichi bị hư hại ra đại dương, bất chấp sự phản đối từ ngư dân địa phương và các quốc gia khác trong khu vực.
[5] Theo trang web chính thức của Liên Hợp Quốc, 193 quốc gia thành viên của Liên Hợp Quốc gần đây đã nhất trí thông qua một thỏa thuận ràng buộc về mặt pháp lý nhằm tăng cường bảo tồn và phát triển bền vững đa dạng sinh học biển, đặc biệt là bảo vệ biển khơi.
Xin hãy đọc và hiểu nhiều đoạn văn trên và trả lời câu hỏi một cách chính xác. Nếu kết quả tìm kiếm không liên quan, xin hãy trả lời rằng chúng không liên quan.
<bot> : Đáp lại câu hỏi "Dân số thế giới đỉnh cao dự kiến trong triển vọng dân số 2022 của Liên Hợp Quốc là bao nhiêu?" Dựa trên thông tin được đánh số 1,2,3 ở trên, câu trả lời của tôi là theo báo cáo World Population Prospects 2022 được xuất bản bởi Bộ Kinh tế và Xã hội Liên Hợp Quốc, dân số toàn cầu dự kiến đạt 8 tỷ vào ngày 15 tháng 11 năm 2022. Báo cáo cũng dự đoán rằng dân số thế giới dự kiến đạt đỉnh khoảng 10.4 tỷ vào những năm 2080 và duy trì ở mức đó đến năm 2100. Kết quả là, Liên Hợp Quốc dự kiến dân số thế giới đạt đỉnh khoảng 10.4 tỷ.</s>
ChatGPT3.5: Dân số thế giới đỉnh cao dự kiến trong triển vọng dân số 2022 của LHQ không được đề cập rõ ràng trong các đoạn văn bài luận được cung cấp.

Bảng 7: Một mẫu Multi-doc QA và đầu ra của Mô hình của chúng tôi, ChatGPT3.5 trong hai ô cuối cùng tương ứng. Câu trả lời của mô hình chúng tôi bắt đầu sau <bot> :. Các token đặc biệt được loại bỏ khi kiểm tra ChatGPT3.5. Chúng ta có thể thấy rằng Mô hình của chúng tôi tạo ra một câu trả lời đúng trong khi ChatGPT3.5 thất bại trong việc trả lời câu hỏi.

--- TRANG 15 ---
Hình 7: Bản đồ nhiệt của điểm chú ý trên 100 token cuối cùng khi mô hình của chúng tôi bắt đầu tạo câu trả lời. Màu tối hơn đại diện cho điểm số cao hơn. Phiên bản tiếng Anh được dịch từ bản đồ nhiệt tiếng Trung từng token một. Token đầu tiên của câu hỏi được tạo và chỉ số dự đoán đầu tiên được chú ý đến, cho thấy tính hữu ích của việc lặp lại câu hỏi và dự đoán chỉ số trong PAM QA.

Hình 8: Giao diện của hệ thống đánh giá SBS. Người dùng chỉ có thể xếp hạng câu trả lời mà không có quyền truy cập vào tên của các mô hình.

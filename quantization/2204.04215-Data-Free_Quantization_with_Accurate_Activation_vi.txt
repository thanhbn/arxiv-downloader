Lượng tử hóa dữ liệu miễn phí với cắt kích hoạt chính xác và chuẩn hóa batch thích ứng

Yefei He, Luoming Zhang, Weijia Wu, Hong Zhou
Đại học Kỹ thuật Y sinh & Khoa học Dụng cụ
Đại học Chiết Giang
Hàng Châu, Trung Quốc
{billhe,zluoming,weijiawu}@zju.edu.cn, zhouh@mail.bme.zju.edu.cn

Tóm tắt

Lượng tử hóa dữ liệu miễn phí nén mạng nơ-ron xuống độ rộng bit thấp mà không cần truy cập dữ liệu huấn luyện gốc. Hầu hết các phương pháp lượng tử hóa dữ liệu miễn phí hiện tại gây ra suy giảm hiệu suất nghiêm trọng do phạm vi cắt kích hoạt không chính xác và lỗi lượng tử hóa, đặc biệt là ở độ rộng bit thấp. Trong bài báo này, chúng tôi trình bày một phương pháp lượng tử hóa dữ liệu miễn phí đơn giản nhưng hiệu quả với cắt kích hoạt chính xác và chuẩn hóa batch thích ứng. Cắt kích hoạt chính xác (AAC) cải thiện độ chính xác của mô hình bằng cách khai thác thông tin kích hoạt chính xác từ mô hình độ chính xác đầy đủ. Chuẩn hóa batch thích ứng (ABN) lần đầu tiên đề xuất giải quyết lỗi lượng tử hóa từ thay đổi phân phối bằng cách cập nhật lớp chuẩn hóa batch một cách thích ứng. Các thí nghiệm rộng rãi chứng minh rằng phương pháp lượng tử hóa dữ liệu miễn phí được đề xuất có thể mang lại hiệu suất đáng ngạc nhiên, đạt được độ chính xác top-1 64.33% cho ResNet18 4-bit trên bộ dữ liệu ImageNet, với cải thiện tuyệt đối 3.7% vượt trội hơn các phương pháp hiện đại tối ưu hiện tại.

1 Giới thiệu

Học sâu đã đạt được những thành công đột phá trong nhiều lĩnh vực, như thị giác máy tính [6, 11] và xử lý ngôn ngữ tự nhiên [4]. Tham số hóa quá mức là một đặc điểm rõ ràng của các mô hình học sâu so với các phương pháp truyền thống. Kể từ khi ra đời, các mô hình học sâu có nhược điểm về số lượng tham số khổng lồ và độ phức tạp tính toán cao. Ví dụ, mạng ResNet18 [5] có 11.7M tham số và 1.8GFLOPS tính toán. Những thiếu sót này hạn chế việc ứng dụng các mô hình học sâu trong các thiết bị biên như điện thoại di động. Để giải quyết vấn đề này, các phương pháp nén mô hình như lượng tử hóa mô hình, chưng cất và cắt tỉa đã xuất hiện trong những năm gần đây. Trong số đó, lượng tử hóa mô hình là một trong những phương pháp nén được sử dụng phổ biến nhất. Lượng tử hóa đề cập đến việc ánh xạ các tham số mô hình hoặc kích hoạt từ số dấu phẩy động sang số nguyên theo các quy tắc nhất định, từ đó giảm đáng kể kích thước của mô hình và tăng tốc quá trình suy luận.

Lượng tử hóa một mô hình độ chính xác đầy đủ xuống độ rộng bit thấp trực tiếp thường dẫn đến sự sụt giảm độ chính xác nghiêm trọng. Để giải quyết điều này, hai phương pháp lượng tử hóa, tức là huấn luyện nhận biết lượng tử hóa (QAT) và lượng tử hóa sau huấn luyện (PTQ) được đề xuất. Phương pháp trước nhằm huấn luyện lại mô hình lượng tử hóa và tiêu tốn nhiều tài nguyên tính toán. Phương pháp sau trực tiếp lượng tử hóa mô hình dấu phẩy động đã được huấn luyện trước và sử dụng một phần dữ liệu huấn luyện để hiệu chỉnh nó. Cả hai phương pháp đều dựa trên dữ liệu và yêu cầu dữ liệu thực trong quá trình lượng tử hóa của chúng. Tuy nhiên, trong nhiều tình huống thực tế, bộ dữ liệu huấn luyện không có sẵn vì chính sách bảo mật hoặc vấn đề an ninh.

May mắn thay, lượng tử hóa dữ liệu miễn phí có thể nén các mô hình mà không cần truy cập bất kỳ dữ liệu huấn luyện gốc nào. Nhiều nghiên cứu trước đây xuất sắc [1,12] cố gắng giải quyết nhiệm vụ này bằng các phương pháp sinh với dữ liệu tổng hợp. ZeroQ [1] và DSG [14] đề xuất tạo ra dữ liệu giả từ phân phối (tức là trung bình và độ lệch chuẩn) của các lớp BN. Sau khi sử dụng dữ liệu giả để cập nhật phạm vi của các kích hoạt lượng tử hóa, phương pháp này đạt được kết quả cạnh tranh so với các phương pháp QAT trước đó ở 8-bit, nhưng hiệu suất suy giảm đáng kể ở độ rộng bit thấp (đặc biệt là 4-bit hoặc thấp hơn). Mặc dù dữ liệu tổng hợp tuân theo phân phối của các lớp BN, phạm vi kích hoạt thực sự được xác định bởi giá trị đỉnh và không có kết nối cần thiết giữa các giá trị cực trị của dữ liệu và phân phối của nó. Do đó, chúng tôi lập luận rằng phạm vi cắt kích hoạt được cập nhật là không chính xác. Bên cạnh đó, quá trình lượng tử hóa không thể tránh khỏi mang lại sự sai lệch cho cả trọng số và kích hoạt, do đó làm xáo trộn phân phối của các bản đồ đặc trưng trung gian. Sự không khớp phân phối giữa các bản đồ đặc trưng và thống kê BN cố định sẽ làm trầm trọng thêm sự giảm hiệu suất. Tuy nhiên, vấn đề này bị các phương pháp lượng tử hóa dữ liệu miễn phí trước đây bỏ qua và cách giảm thiểu sự không khớp này vẫn là một câu hỏi mở.

Hơn nữa, các nghiên cứu gần đây [2,12,15] đề xuất các bộ tạo dữ liệu dựa trên mạng nơ-ron để tinh chỉnh mô hình lượng tử hóa. Sau khi tinh chỉnh, công trình của họ đạt được kết quả tốt hơn [1] khi các mô hình được lượng tử hóa xuống 4-bit. Tuy nhiên, huấn luyện một bộ tạo đòi hỏi nhiều thời gian và tài nguyên tính toán, và tinh chỉnh có thể ít hữu ích hoặc thậm chí có hại cho lượng tử hóa 8-bit. Cách lượng tử hóa các mô hình một cách tổng quát và hiệu quả vẫn là một vấn đề.

Để giải quyết các vấn đề trên, chúng tôi trình bày một phương pháp lượng tử hóa dữ liệu miễn phí đơn giản nhưng hiệu quả với hai thành phần cốt lõi, tức là cắt kích hoạt chính xác và chuẩn hóa batch thích ứng. Cắt kích hoạt chính xác sử dụng kết quả phân loại của mô hình giáo viên và một hàm mất mát giá trị tuyệt đối để tối ưu hóa dữ liệu tổng hợp, dữ liệu được tạo ra chứa thông tin phạm vi kích hoạt chính xác của bộ dữ liệu gốc. Chuẩn hóa batch thích ứng xem xét sự dịch chuyển của phân phối bản đồ đặc trưng lượng tử hóa. Sau khi xác định phạm vi giá trị kích hoạt, chúng tôi đề xuất cập nhật thích ứng thống kê BN của mô hình lượng tử hóa, giảm thiểu sự không khớp phân phối. Cuối cùng, chúng tôi đề xuất thực hiện tinh chỉnh chỉ khi cần thiết để cải thiện thêm độ chính xác. Ngay cả với tài nguyên tính toán hạn chế không thể thực hiện tinh chỉnh, phương pháp của chúng tôi có thể đạt được hiệu suất cạnh tranh so với phương pháp dựa trên tinh chỉnh.

Chúng tôi tóm tắt các đóng góp chính của mình như sau:
• Chúng tôi suy nghĩ lại về các yếu tố quyết định phạm vi kích hoạt và đề xuất một phương pháp mới để tạo dữ liệu cụ thể cho cắt kích hoạt chính xác. Điều này cung cấp một cách tiếp cận mới để trích xuất thông tin kích hoạt của bộ dữ liệu từ các mô hình độ chính xác đầy đủ.
• Một chuẩn hóa batch thích ứng được đề xuất để giảm thiểu sự xáo trộn từ sự không khớp phân phối của các lớp BN.
• Kết hợp các phương pháp trên với tinh chỉnh tùy chọn, chúng tôi có được một đường ống lượng tử hóa dữ liệu miễn phí ba bước hoàn toàn mới. Các thí nghiệm rộng rãi trên bộ dữ liệu ImageNet quy mô lớn chứng minh rằng lượng tử hóa với phương pháp của chúng tôi có thể vượt qua các phương pháp hiện đại tối ưu với cải thiện tuyệt đối 3.7% trên ResNet18 4-bit.

2 Công trình liên quan

Lượng tử hóa dữ liệu miễn phí lần đầu tiên được đề xuất bởi DFQ [7] và nhanh chóng trở thành tâm điểm nghiên cứu. Có hai câu hỏi quan trọng trong lĩnh vực lượng tử hóa dữ liệu miễn phí: làm thế nào để tạo ra dữ liệu tổng hợp và làm thế nào để áp dụng những dữ liệu này để cải thiện mô hình lượng tử hóa. Cập nhật đầu vào gaussian sử dụng lan truyền ngược gradient là một cách tiếp cận được áp dụng rộng rãi. Các phương pháp như ZeroQ [1] và DSG [14] theo sơ đồ này và trích xuất thông tin từ các lớp BN để tạo ra dữ liệu tổng hợp cho việc cắt kích hoạt. Trong trường hợp này, vấn đề chính là làm thế nào để khôi phục thông tin kích hoạt của bộ dữ liệu huấn luyện từ mô hình độ chính xác đầy đủ. Một cách tiếp cận phổ biến khác sử dụng bộ tạo dựa trên mạng để tổng hợp dữ liệu [2, 12, 15]. Sau khi tạo dữ liệu, họ tinh chỉnh mô hình lượng tử hóa để cải thiện độ chính xác. Tuy nhiên, điều này có thể tốn nhiều thời gian hơn cách tiếp cận đầu tiên.

Để cải thiện thêm giới hạn của lượng tử hóa dữ liệu miễn phí, chúng tôi lập luận rằng phương pháp tạo dữ liệu nên được xem xét chung với phương pháp sử dụng nó. Nói cách khác, câu hỏi một và hai nên được xem xét cùng nhau. Đối với cắt kích hoạt, chúng tôi đã phân tích nguyên nhân của giá trị đỉnh của kích hoạt và đề xuất một hàm mất mát mới LABS có thể tạo ra dữ liệu dành riêng cho cắt kích hoạt. Đồng thời, chúng tôi đề xuất một phương pháp mới để áp dụng dữ liệu tổng hợp, tức là cập nhật thống kê của các lớp BN để giảm thiểu sự không khớp phân phối. Cả hai phương pháp đều nhanh và hiệu quả, và có thể được kết hợp thêm với các phương pháp dựa trên tinh chỉnh.

3 Phương pháp

3.1 Kiến thức cơ bản

Chúng tôi sử dụng lượng tử hóa đồng nhất trong nghiên cứu và thí nghiệm của mình. Đối với lượng tử hóa đồng nhất, cho độ rộng bit b và phạm vi cắt [l, u] cho trọng số hoặc kích hoạt, quá trình lượng tử hóa-phản lượng tử hóa như sau:

δ = (u - l) / (2^b - 1)                                    (1)
Q(x) = round((x - l) / δ)                                  (2)
D(x) = Q(x) * δ + l                                       (3)

trong đó δ là độ dài khoảng, Q(x) là biểu diễn lượng tử hóa của dữ liệu và D(x) là kết quả của quá trình phản lượng tử hóa của một giá trị Q(x).

Sẽ có hai vấn đề chính khi nói đến lượng tử hóa dữ liệu miễn phí. Thứ nhất, vì trọng số đã được huấn luyện, phạm vi của trọng số là giá trị tối thiểu/tối đa của nó. Tuy nhiên, phạm vi cắt cho kích hoạt của mỗi lớp phụ thuộc vào đầu vào cụ thể và vẫn chưa biết. Thứ hai, thống kê (μ và σ) của các lớp BN phụ thuộc vào đầu vào và bản đồ đặc trưng của mạng, và đã được cố định trong mô hình. Tuy nhiên, lượng tử hóa mô hình có thể dịch chuyển phân phối của các bản đồ đặc trưng trung gian, do đó trở nên không nhất quán với thống kê BN.

Trong phần này, chúng tôi đề xuất hai cách tiếp cận, tức là cắt kích hoạt chính xác và chuẩn hóa batch thích ứng để giải quyết hai vấn đề tương ứng, có thể đạt được kết quả đáng chú ý trong thời gian ngắn. Trong lượng tử hóa bit thấp, chúng tôi sử dụng thêm tinh chỉnh để cải thiện độ chính xác, do đó có một đường ống ba bước cho lượng tử hóa dữ liệu miễn phí, như được thể hiện trong Hình 1.

3.2 Cắt kích hoạt chính xác

Để xác định phạm vi cắt của kích hoạt (tức là u và l trong Phương trình (1)), một cách phổ biến là tạo ra dữ liệu tổng hợp và thực hiện lan truyền tiến với nó. Giá trị đỉnh của kích hoạt được lưu trữ như tham số phạm vi cắt. Trong khi các nghiên cứu trước đây [1, 12] tạo ra dữ liệu giả với phân phối của các lớp BN, nó chỉ cung cấp một dự đoán thô cho phạm vi kích hoạt. Chúng tôi lập luận rằng đó không phải là sự lựa chọn tối ưu để cập nhật phạm vi cắt vì các đỉnh không liên quan trực tiếp đến phân phối của dữ liệu. Điều này được minh họa trong Hình 2, nơi chúng tôi vẽ phạm vi cắt kích hoạt tốt nhất và phạm vi được xác định bởi dữ liệu cho mọi lớp trong mô hình ResNet18. Với dữ liệu nhất quán phân phối từ các lớp BN, ZeroQ [1] trình bày hiệu suất không thỏa mãn so với giá trị kích hoạt tối ưu. Vậy điều gì thực sự quyết định phạm vi cắt kích hoạt?

Hình 3 trình bày cấu trúc khối phổ biến của CNN lượng tử hóa. Trước khi cắt, ReLU lấy bản đồ đặc trưng của các lớp tích chập làm đầu vào. Do đó, cận dưới l là zero không còn nghi ngờ gì, trong khi cận trên u phụ thuộc vào giá trị tối đa của bản đồ đặc trưng. Nghiên cứu gần đây [16] tiết lộ rằng bản đồ đặc trưng là phản ứng của mạng đối với các đặc trưng danh mục trong đó phản ứng cao liên quan đến các đặc trưng quan trọng và phản ứng thấp liên quan đến các đặc trưng không liên quan như nền. Do đó, để mô phỏng phản ứng của bộ dữ liệu thực, dữ liệu tổng hợp nên làm cho mạng có phản ứng cao.

Để đạt được mục đích này, chúng tôi đề xuất một phương pháp mới để tạo ra dữ liệu cắt kích hoạt chính xác. Chúng tôi nhận thấy rằng các mô hình học sâu thực hiện các nhiệm vụ phân loại hình ảnh trên các bộ dữ liệu quy mô lớn một cách tốt với thông tin liên quan đến danh mục phong phú. Do đó chúng tôi cố gắng để mô hình tự học dữ liệu phản ứng nhất. Ví dụ, cho một nhãn mục tiêu "hoa" và một hình ảnh ngẫu nhiên gaussian, nếu chúng tôi nhập hình ảnh gaussian vào mạng trực tiếp, kết quả không có khả năng phân loại nó như một bông hoa. Tuy nhiên, nếu chúng tôi có một hàm mất mát phù hợp, tính toán mất mát theo nhãn mục tiêu và lan truyền ngược đến hình ảnh, độ tin cậy của việc phân loại là "hoa" sẽ tăng khi chúng tôi lặp lại. Cuối cùng, mạng tạo ra hình ảnh "giống hoa nhất" một cách thích ứng. Với hình ảnh được tạo ra chất lượng cao được sử dụng làm đầu vào, mô hình sẽ xuất hiện phản ứng cao hơn và mô phỏng các đỉnh kích hoạt của bộ dữ liệu thực. Nói cách khác, chúng ta phải giải quyết các bài toán tối ưu hóa sau:

min_x E_{x,y}[ℓ(M(x), y)]                                  (4)

trong đó x là dữ liệu đầu vào tổng hợp, y là nhãn mục tiêu, ℓ là hàm mất mát và M là mô hình độ chính xác đầy đủ.

Để chọn một hàm mất mát phù hợp, chúng tôi xem xét sâu hơn vấn đề này. Mất mát Cross-Entropy (CE) là hàm mất mát được sử dụng phổ biến nhất trong các nhiệm vụ phân loại hình ảnh và đó là một chỉ báo tốt về mức độ mô hình phân loại hình ảnh đầu vào. Do đó, chúng tôi sử dụng mất mát CE để đánh giá chất lượng của dữ liệu được tạo ra, trong đó mất mát thấp hơn có nghĩa là dữ liệu được tạo ra tốt hơn. Tuy nhiên, khi nói đến lan truyền ngược, mất mát CE không phải là sự lựa chọn tốt nhất. Một ví dụ đồ chơi được sử dụng để minh họa vấn đề, như được thể hiện trong Hình 4(a). Chúng ta có thể thấy rằng sử dụng mất mát CE cho lan truyền ngược không thể tối ưu hóa hàm mất mát đến mức tối ưu. Chi tiết của thí nghiệm đồ chơi có thể được tìm thấy trong Phụ lục 6.1.

Đạo hàm được tính bởi mất mát CE có thể được công thức hóa như:

∂L_CE / ∂M_y(x) = ∂L_CE / ∂p_y * ∂p_y / ∂M_y(x)           (5)
                 = -1/p_y * p_y(1-p_y)                      (6)
                 = p_y - 1                                  (7)

trong đó p_y là xác suất phân loại đến nhãn y (tức là kết quả của phép toán softmax). Với sự gia tăng của p_y, đạo hàm được sử dụng cho lan truyền ngược sẽ nhỏ hơn, điều này làm cho quá trình tối ưu hóa bão hòa trước khi đạt đến trạng thái tối ưu.

Có thể thấy từ Phương trình (7) rằng vấn đề chủ yếu được gây ra bởi phép toán softmax, trong đó tất cả các điểm số được đưa vào tính toán. Thực tế, trong vấn đề giá trị đỉnh này, chúng tôi chỉ quan tâm đến điểm số tương ứng với nhãn mục tiêu và hy vọng phản ánh nó trên hình ảnh đầu vào. Điểm số của các nhãn khác hoặc sự xuất hiện của chúng trên hình ảnh đầu vào không liên quan đến phản ứng của mô hình. Do đó, chúng tôi đề xuất một mất mát giá trị tuyệt đối nhãn cứng (ABS Loss):

L_ABS = -M_y(x)                                           (8)

Do đó, chỉ các vùng mà mô hình cho rằng có tác động đến các đặc trưng "hoa" sẽ được tăng cường, và bản đồ đặc trưng trung gian cũng sẽ tạo ra phản ứng cao hơn. Sử dụng Phương trình (8) làm hàm mất mát trong thuật toán cũng làm cho mất mát Cross-Entropy giảm xuống 0 nhanh chóng, làm cho quá trình tạo dữ liệu thậm chí còn nhanh hơn (xem Hình 4(b)). Cũng có thể thấy từ Hình 2 rằng dữ liệu chúng tôi tạo ra rất gần với giá trị tối ưu của phạm vi cắt kích hoạt.

3.3 Chuẩn hóa Batch thích ứng

Nghiên cứu trước đây [7] đã phát hiện ra rằng khi lớp tích chập được lượng tử hóa, phân phối bản đồ đặc trưng đầu ra sẽ có một độ lệch nhất định so với mô hình gốc. Khi chúng ta lượng tử hóa các mô hình xuống độ rộng bit thấp, hiện tượng này sẽ rõ ràng hơn, như được thể hiện trong Hình 5. Trong trường hợp này, vì phân phối của dữ liệu đầu vào không khớp với thống kê được lưu trữ trong lớp BN, lớp BN không chỉ không chuẩn hóa được dữ liệu mà còn có thể có tác dụng phụ gây hại đến độ chính xác của mô hình. Sự không nhất quán thống kê này được gây ra bởi các lỗi lượng tử hóa. Khi chúng ta có bộ dữ liệu huấn luyện, chúng ta có thể sử dụng QAT để huấn luyện lại trọng số và các lớp BN của mạng. Tuy nhiên, trong trường hợp lượng tử hóa dữ liệu miễn phí, chúng ta không có dữ liệu huấn luyện để tối ưu hóa lỗi lượng tử hóa. Do đó, trong nghiên cứu này, chúng tôi xem xét vấn đề này từ một góc độ khác. Vì mô hình có một số lượng lớn tham số trọng số, việc cập nhật mà không có dữ liệu huấn luyện là khó khăn. Nhưng các lớp BN chứa ít tham số và chỉ phụ thuộc vào phân phối của dữ liệu đầu vào. Để giảm thiểu sự không khớp phân phối và cải thiện độ chính xác của mô hình lượng tử hóa, chúng tôi chọn cập nhật thống kê của các lớp BN và để các lớp BN thích ứng với các lỗi gây ra bởi lượng tử hóa.

Mặc dù dữ liệu được tạo ra trong phần 3.2 có thể khôi phục phạm vi kích hoạt rất tốt, nhưng nó không phù hợp để cập nhật thống kê của lớp BN. Như đã phân tích ở trên, cập nhật phạm vi kích hoạt là một vấn đề cực trị trong khi cập nhật thống kê BN là một vấn đề phân phối dữ liệu. Do đó, chúng tôi sử dụng dữ liệu nhất quán phân phối được đề xuất trong [1] để cập nhật thống kê BN.

Hàm mất mát thống kê BN (BNS) được định nghĩa như sau:

L_BNS = Σ_{i=0}^L ||b_i - μ_i||_2^2 + ||σ_b_i - σ_i||_2^2    (9)

Trong số đó, μ_i, σ_i là thông tin trung bình và độ lệch chuẩn được lưu trữ trong lớp BN thứ i trong mô hình độ chính xác đầy đủ. b_i và σ_b_i là trung bình và độ lệch chuẩn của dữ liệu đầu vào tại lớp i. Tương tự như AAC, hình ảnh đầu vào ngẫu nhiên được lan truyền ngược qua hàm mất mát (9), và dữ liệu được tạo ra thu được chứa thông tin phân phối của bộ dữ liệu huấn luyện. Bằng cách đưa dữ liệu này vào mạng, chúng ta có thể đo lường sự xáo trộn phân phối và cập nhật thống kê BN tốt.

3.4 Đường ống Ba bước

Trong trường hợp lượng tử hóa độ rộng bit thấp (đặc biệt là 4-bit hoặc thấp hơn), rất khó để đạt được kết quả lý tưởng mà không tinh chỉnh trọng số. Các phương pháp như GDFQ [12] đề xuất sử dụng bộ tạo dựa trên mạng để tạo ra dữ liệu giả và thực hiện huấn luyện lại trên mô hình lượng tử hóa.

Tuy nhiên, như đã phân tích trong phần 3.1, xác định phạm vi kích hoạt và thống kê BN là những vấn đề chính trong lượng tử hóa dữ liệu miễn phí. Trong khi huấn luyện lại trọng số cải thiện độ chính xác, hai vấn đề này bị các phương pháp tinh chỉnh trước đây bỏ qua. Đồng thời, các phương pháp tương ứng của chúng tôi được đề xuất ở trên là hiệu quả và nhanh có thể được hoàn thành trong vòng một phút. Do đó, chúng tôi sử dụng phương pháp của mình làm cơ sở cho tinh chỉnh, điều này bù đắp cho những thiếu sót của họ và cải thiện đáng kể độ chính xác. Tại thời điểm này, chúng ta có được một đường ống lượng tử hóa dữ liệu miễn phí ba bước, như được thể hiện trong Hình 1.

Tinh chỉnh có thể tiêu tốn nhiều thời gian và tài nguyên tính toán trong khi phương pháp của chúng tôi là hiệu quả. Do đó, chúng tôi cố gắng tìm kiếm sự cân bằng giữa thời gian và hiệu quả. Trong trường hợp 8-bit, phương pháp hai bước của chúng tôi (không có tinh chỉnh) đã có thể đạt được kết quả lý tưởng, và cải thiện mang lại bởi tinh chỉnh là tinh tế. Trong trường hợp độ rộng bit thấp, mặc dù cải thiện mang lại bởi tinh chỉnh vẫn đáng kể và phương pháp ba bước hoàn chỉnh đáng được thực hiện, phương pháp hai bước đạt được cải thiện lớn so với nghiên cứu gần đây DSG [14] và có thể so sánh với phương pháp dựa trên tinh chỉnh, điều này sẽ được phân tích thêm trong phần 4.2.

4 Thí nghiệm

4.1 Chi tiết triển khai

Nghiên cứu này dựa trên framework Pytorch và tất cả các thí nghiệm được thực hiện bằng GPU RTX3090. Để tạo ra dữ liệu cắt kích hoạt chính xác, chúng tôi đã sử dụng tốc độ học 0.2 để tối ưu hóa 200 lần lặp; để tạo ra dữ liệu nhất quán phân phối, chúng tôi đã sử dụng tốc độ học 0.5 để tối ưu hóa 500 lần lặp. Đối với bộ tạo dữ liệu, chúng tôi tuân theo các cài đặt được giới thiệu bởi [12]. Để thực hiện so sánh công bằng, phương pháp lượng tử hóa các mô hình giống như [1] và [12], trong đó tất cả các lớp tích chập và lớp tuyến tính được lượng tử hóa đến cùng độ rộng bit.

Chúng tôi thực hiện tất cả các thí nghiệm trên bộ dữ liệu benchmark quy mô lớn ImageNet (ILSVRC12) [3]. Để xác minh tính đa dạng của phương pháp của chúng tôi, chúng tôi đã thử nghiệm một số cấu trúc mạng thường được sử dụng, bao gồm ResNet [5], VGG [9], Inception v3 [10] và MobileNetV2 [8]. Tất cả các mạng sử dụng mô hình được huấn luyện trước được cung cấp bởi pytorchcv [13].

4.2 So sánh với các phương pháp hiện đại tối ưu

Trong phần phụ này, chúng tôi đánh giá phương pháp của mình bằng cách so sánh nó với các phương pháp lượng tử hóa dữ liệu miễn phí hiện đại tối ưu hiện tại trên các kiến trúc mạng khác nhau. Vì độ chính xác trong lượng tử hóa 8-bit rất gần với mô hình độ chính xác đầy đủ, chúng tôi chủ yếu báo cáo kết quả ở 4-bit, như được thể hiện trong Bảng 1.

Chúng ta có thể quan sát thấy rằng đối với W4A4 (tức là lượng tử hóa cả trọng số và kích hoạt xuống 4-bit), phương pháp của chúng tôi vượt trội hơn tất cả các phương pháp khác với biên độ lớn trên các kiến trúc mạng khác nhau. Điều này minh họa hiệu quả của cắt kích hoạt chính xác và cập nhật thống kê BN của chúng tôi. Ngay cả khi phương pháp của chúng tôi không sử dụng tinh chỉnh trên nhiều mô hình, hiệu quả rất gần hoặc vượt quá GDFQ, yêu cầu tinh chỉnh. Như chúng ta đều biết, tinh chỉnh tiêu tốn rất nhiều thời gian GPU. Cách tiếp cận của chúng tôi (không có FT, hai bước) chỉ mất khoảng một phút để hoàn thành, tạo ra sự cân bằng tốt hơn giữa thời gian và kết quả.

Đối với W8A8, hiệu quả của các phương pháp khác nhau rất gần với mô hình độ chính xác đầy đủ. Trong trường hợp này, chúng tôi thấy rằng nếu dữ liệu được tạo ra được sử dụng để tinh chỉnh, hiệu quả là tinh tế hoặc thậm chí có thể tệ hơn kết quả của việc không sử dụng tinh chỉnh. Chúng tôi khuyến nghị không sử dụng tinh chỉnh cho lượng tử hóa 8-bit.

4.3 Nghiên cứu loại bỏ

4.3.1 Đường ống ba bước

Để xác minh thêm hiệu quả của từng phần của đường ống ba bước, chúng tôi đã sử dụng mô hình ResNet18 để thực hiện các thí nghiệm loại bỏ trên bộ dữ liệu ImageNet. Bảng 2 thể hiện hiệu suất dưới các cài đặt khác nhau. Chúng ta có thể thấy rằng cả ba bước đều đóng vai trò quan trọng trong việc cải thiện độ chính xác. Khi chúng tôi kết hợp chúng, đường ống ba bước được đề xuất đạt được hiệu quả của SOTA, cho thấy rằng các cải thiện mang lại bởi ba bước có thể được chồng lên. Ba bước xem xét phạm vi cắt kích hoạt tốt hơn, cập nhật thống kê BN để thích ứng với lỗi lượng tử hóa, và tinh chỉnh trọng số riêng biệt, đó là lý do tại sao phương pháp của chúng tôi có thể có được kết quả tốt hơn. Đáng chú ý là khi chỉ cập nhật phạm vi cắt kích hoạt, hiệu suất của chúng tôi vượt trội rất nhiều so với ZeroQ [1], cho thấy rằng phương pháp của chúng tôi có thể khôi phục tốt hơn phạm vi giá trị kích hoạt của bộ dữ liệu thực.

Hơn nữa, chúng tôi xác thực hiệu quả của phương pháp được đề xuất trên một số phương pháp dựa trên tinh chỉnh hiện đại tối ưu. Như được thể hiện trong Bảng 3. Trong tất cả các trường hợp, phương pháp của chúng tôi có thể cải thiện thêm độ chính xác, chứng minh tính mạnh mẽ của phương pháp của chúng tôi và rằng phạm vi kích hoạt chính xác là một cơ sở quan trọng cho phương pháp dựa trên tinh chỉnh.

4.3.2 Lựa chọn hàm mất mát

Chúng tôi tiếp tục điều tra hiệu suất của việc tạo ra dữ liệu kích hoạt chính xác bằng cách sử dụng các hàm mất mát khác nhau. Mô hình ResNet18 được lượng tử hóa xuống 4-bit. Chúng tôi lặp lại trên hình ảnh gaussian trong 600 epoch để tạo ra dữ liệu tổng hợp, và sử dụng dữ liệu này để cập nhật phạm vi cắt kích hoạt. Bảng 4 thể hiện hiệu suất dưới các cài đặt khác nhau, trong đó "MAE" biểu thị lỗi trung bình tuyệt đối và "MSE" là lỗi bình phương trung bình. Chúng tôi đưa dữ liệu được tạo ra vào mô hình và tính toán mất mát Cross-Entropy để đo lường mức độ mô hình phản ứng với dữ liệu.

Có thể thấy rằng dữ liệu được tạo ra bởi mất mát ABS được đề xuất có thể làm cho mô hình dự đoán nhãn chính xác như chúng tôi mong đợi. Điều này cũng đạt được độ chính xác phân loại cao nhất sau khi cập nhật mô hình lượng tử hóa.

Một ý tưởng trực quan là cho phép dữ liệu tổng hợp làm cho mô hình có phản ứng cao trong khi tuân theo phân phối được xác định bởi thống kê BN. Tuy nhiên, trong các thí nghiệm chúng tôi thấy rằng nếu chúng tôi cộng hai hàm mất mát lại với nhau, quá trình tối ưu hóa trở nên không ổn định và không thể hội tụ.

4.4 Hiệu quả lượng tử hóa

Trong phần phụ này, chúng tôi so sánh đường ống hai bước và ba bước của chúng tôi với các phương pháp lượng tử hóa dữ liệu miễn phí hiện tại, như được thể hiện trong Bảng 5. Các phương pháp cập nhật đầu vào gaussian để xác định phạm vi kích hoạt nhanh hơn nhiều so với các phương pháp có tinh chỉnh. Trong số đó, phương pháp của chúng tôi đạt được độ chính xác tốt nhất và mang lại cải thiện tuyệt đối 21% trên ResNet18 4-bit. Điều này rất hữu ích trên các thiết bị có sức mạnh tính toán hạn chế và không thể thực hiện tinh chỉnh. Khi cần tinh chỉnh, phương pháp của chúng tôi có thể cải thiện đáng kể độ chính xác trong khi hầu như không tăng tiêu thụ thời gian.

5 Kết luận và thảo luận

Trong bài báo này, chúng tôi đề xuất hai kỹ thuật mới: cắt kích hoạt chính xác và chuẩn hóa batch thích ứng để cải thiện độ chính xác của lượng tử hóa dữ liệu miễn phí. Đầu tiên, chúng tôi phân tích nguồn gốc của các giá trị đỉnh kích hoạt và xây dựng một sơ đồ mới để tạo ra dữ liệu tổng hợp có thể khôi phục phạm vi kích hoạt của bộ dữ liệu gốc, do đó giúp lượng tử hóa tốt hơn các kích hoạt. Tiếp theo, chúng tôi phân tích sự không khớp giữa phân phối bản đồ đặc trưng lượng tử hóa và thống kê được lưu trữ trong các lớp BN. Chúng tôi đề xuất cập nhật thống kê BN một cách thích ứng và để các lớp BN thích ứng với các lỗi gây ra bởi lượng tử hóa. Cuối cùng, chúng tôi kết hợp hai phương pháp trên với một mô-đun tinh chỉnh tùy chọn và có được một đường ống lượng tử hóa ba bước, có thể cải thiện thêm độ chính xác, cho phép người dùng tạo ra sự cân bằng giữa tiêu thụ thời gian và kết quả. Các thí nghiệm rộng rãi chứng minh rằng các phương pháp của chúng tôi vượt trội hơn các phương pháp lượng tử hóa dữ liệu miễn phí hiện tại với biên độ lớn.

Chúng tôi cũng thấy rằng, vì các phương pháp hiện tại chủ yếu tập trung vào việc cập nhật phạm vi cắt của các giá trị kích hoạt, chúng không hoạt động tốt với các mô hình như MobileNet không sử dụng ReLU truyền thống làm hàm kích hoạt. Làm thế nào để lượng tử hóa các mạng như MobileNet một cách hiệu quả là một câu hỏi đáng nghiên cứu trong tương lai.

Tài liệu tham khảo

[1] Y. Cai, Z. Yao, Z. Dong, A. Gholami, và K. Keutzer. Zeroq: Một framework lượng tử hóa zero shot mới. Trong 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020.

[2] K. Choi, D. Hong, N. Park, Y. Kim, và J. Lee. Qimera: Lượng tử hóa dữ liệu miễn phí với các mẫu hỗ trợ biên tổng hợp. Advances in Neural Information Processing Systems, 34, 2021.

[3] J. Deng. Imagenet: Một cơ sở dữ liệu hình ảnh phân cấp quy mô lớn. Proc. CVPR, 2009, 2009.

[4] J. Devlin, M. W. Chang, K. Lee, và K. Toutanova. Bert: Huấn luyện trước của transformer hai chiều sâu để hiểu ngôn ngữ. 2018.

[5] K. He, X. Zhang, S. Ren, và J. Sun. Học tập tồn dư sâu để nhận dạng hình ảnh. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.

[6] Z. Liu, H. Mao, C.-Y. Wu, C. Feichtenhofer, T. Darrell, và S. Xie. Một convnet cho những năm 2020. arXiv preprint arXiv:2201.03545, 2022.

[7] M. Nagel, M. V. Baalen, T. Blankevoort, và M. Welling. Lượng tử hóa dữ liệu miễn phí thông qua cân bằng trọng số và hiệu chỉnh bias. Trong 2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019.

[8] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, và L. C. Chen. Tồn dư nghịch đảo và nút cổ chai tuyến tính: Mạng di động cho phân loại, phát hiện và phân đoạn. 2018.

[9] K. Simonyan và A. Zisserman. Mạng tích chập rất sâu cho nhận dạng hình ảnh quy mô lớn. Computer Science, 2014.

[10] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, và Z. Wojna. Suy nghĩ lại về kiến trúc inception cho thị giác máy tính. IEEE, trang 2818–2826, 2016.

[11] C.-Y. Wang, A. Bochkovskiy, và H.-Y. M. Liao. Scaled-YOLOv4: Mở rộng mạng giai đoạn chéo một phần. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), trang 13029–13038, tháng 6 năm 2021.

[12] S. Xu, H. Li, B. Zhuang, J. Liu, J. Cao, C. Liang, và M. Tan. Lượng tử hóa dữ liệu miễn phí bitwidth thấp sinh tạo. 2020.

[13] A. You, X. Li, Z. Zhu, và Y. Tong. Torchcv: Một framework dựa trên pytorch cho học sâu trong thị giác máy tính. https://github.com/donnyyou/torchcv, 2019.

[14] X. Zhang, H. Qin, Y. Ding, R. Gong, Q. Yan, R. Tao, Y. Li, F. Yu, và X. Liu. Đa dạng hóa tạo mẫu cho lượng tử hóa dữ liệu miễn phí chính xác. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 15658–15667, 2021.

[15] Y. Zhong, M. Lin, G. Nan, J. Liu, B. Zhang, Y. Tian, và R. Ji. Intraq: Học hình ảnh tổng hợp với tính không đồng nhất trong lớp cho lượng tử hóa mạng zero-shot. arXiv preprint arXiv:2111.09136, 2021.

[16] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, và A. Torralba. Học các đặc trưng sâu cho định vị phân biệt. Trong CVPR, 2016.

6 Phụ lục

6.1 Chi tiết triển khai của thí nghiệm đồ chơi

Trong thí nghiệm đồ chơi được thể hiện trong Hình 4, chúng tôi để mô hình là một phép biến đổi đồng nhất. Cho một nhãn mục tiêu, chúng tôi tính toán các hàm mất mát khác nhau và lan truyền ngược đến đầu vào, điều này sẽ làm cho giá trị của lớp mục tiêu cao hơn trong quá trình lặp. Chúng tôi chạy cả hai thí nghiệm trong 300 lần lặp. Thuật toán được tóm tắt dưới đây.

Thuật toán 1 Thí nghiệm đồ chơi tối ưu hóa bằng các hàm mất mát khác nhau
Yêu cầu: Mô hình biến đổi đồng nhất M, một hàm mất mát L, dữ liệu ngẫu nhiên x ∈ R^n và một nhãn mục tiêu t ∈ [0, n-1].
for i = 1 to num_iterations do
    Lan truyền tiến M(x) = x
    Tính giá trị mất mát theo lựa chọn hàm mất mát L
    Lan truyền ngược và cập nhật x
end for
Trả về: Giá trị mục tiêu x_t

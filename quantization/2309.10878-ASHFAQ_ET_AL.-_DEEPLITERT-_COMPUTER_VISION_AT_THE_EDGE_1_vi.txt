# 2309.10878.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/quantization/2309.10878.pdf
# Kích thước tệp: 1743700 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN 1
DeepliteRT: Tầm Nhìn Máy Tính Tại Biên
Saad Ashfaq
saad@deeplite.ai
Alexander Hoffman
alexander.hoffman@deeplite.ai
Saptarshi Mitra
saptarshi@deeplite.ai
Sudhakar Sah
sudhakar@deeplite.ai
MohammadHossein AskariHemmat
mohammad@deeplite.ai
Ehsan Saboori
ehsan@deeplite.aiDeeplite Inc.
Toronto, Canada
Tóm tắt
Sự phổ biến của các thiết bị biên đã mở ra những cơ hội chưa từng có cho việc triển khai mô hình học sâu trong các ứng dụng tầm nhìn máy tính. Tuy nhiên, những mô hình phức tạp này yêu cầu năng lượng, bộ nhớ và tài nguyên tính toán đáng kể thường không có sẵn trên các nền tảng biên. Lượng tử hóa bit siêu thấp mang lại một giải pháp hấp dẫn cho vấn đề này bằng cách giảm quy mô trọng số và kích hoạt mô hình từ 32-bit xuống dưới 8-bit. Chúng tôi triển khai các toán tử tích chập bit siêu thấp được tối ưu hóa cao cho các mục tiêu dựa trên ARM vượt trội hơn các phương pháp hiện có lên đến 4.34 ×. Toán tử của chúng tôi được triển khai trong Deeplite Runtime (DeepliteRT), một giải pháp đầu cuối đến cuối cho việc biên dịch, điều chỉnh và suy luận các mô hình bit siêu thấp trên các thiết bị ARM. Các lượt biên dịch trong DeepliteRT tự động chuyển đổi mô hình lượng tử hóa giả ở độ chính xác đầy đủ thành biểu diễn bit siêu thấp nhỏ gọn, làm dễ dàng quá trình triển khai mô hình lượng tử hóa trên phần cứng thông dụng. Chúng tôi phân tích hiệu suất của DeepliteRT trên các mô hình phân loại và phát hiện so với các đường cơ sở điểm nổi 32-bit được tối ưu hóa, số nguyên 8-bit và 2-bit, đạt được tăng tốc đáng kể lên đến 2.20 ×, 2.33× và 2.17 ×, tương ứng.
1 Giới thiệu
Các mô hình học sâu cho tầm nhìn máy tính đang được triển khai rộng rãi trong nhiều lĩnh vực và ngành công nghiệp do những cải thiện đáng kể về độ chính xác của các mạng nơ-ron tích chập sâu (CNN). Các kiến trúc CNN bao gồm VGG [28], ResNet [18], Inception [29], DenseNet [20] và YOLO [27] đã thể hiện hiệu suất xuất sắc trong các tác vụ phân loại hình ảnh và phát hiện đối tượng. Việc áp dụng rộng rãi các giải pháp học sâu trong tầm nhìn máy tính cũng đã trùng hợp với sự phát triển của tính toán biên [33], hứa hẹn tiềm năng đưa học máy đến các thiết bị biên công suất thấp. Tuy nhiên, những cải tiến về độ chính xác mô hình CNN đã đến với chi phí tăng độ phức tạp mô hình
© 2023. Bản quyền của tài liệu này thuộc về các tác giả.
Nó có thể được phân phối tự do mà không thay đổi ở dạng in hoặc điện tử.arXiv:2309.10878v1  [cs.LG]  19 Sep 2023

--- TRANG 2 ---
2 ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN
dẫn đến yêu cầu năng lượng, tính toán, bộ nhớ và lưu trữ cao, khiến các mô hình như vậy rất không thực tế cho hầu hết các trường hợp sử dụng trên các thiết bị biên hạn chế tài nguyên.

Một số kỹ thuật nén [4] [15] [19] đã được khám phá để giải quyết vấn đề này với mục tiêu giảm kích thước mô hình trong khi duy trì độ chính xác cơ sở. Lượng tử hóa là một phương pháp như vậy thực hiện mục tiêu này bằng cách giảm quy mô trọng số và kích hoạt mô hình từ điểm nổi 32-bit (FP32) xuống các biểu diễn độ chính xác thấp hơn. Ngoài nén mô hình, lượng tử hóa cũng mang lại lợi ích ít truy cập bộ nhớ hơn, độ trễ thấp hơn và hiệu quả năng lượng được cải thiện. Số nguyên 8-bit (INT8) đã trở thành độ rộng bit chủ đạo cho lượng tử hóa và được hỗ trợ rộng rãi trong các khung học máy có sẵn công khai [1] [25] thực hiện huấn luyện nhận biết lượng tử hóa (QAT) và trong các động cơ suy luận mã nguồn mở [10] [16] thực thi các mô hình lượng tử hóa trên phần cứng thông dụng. Những tiến bộ gần đây cũng đã được thực hiện trong lượng tử hóa bit siêu thấp nơi trọng số và kích hoạt mô hình được lượng tử hóa xuống dưới 8 bit độ chính xác. Sử dụng các phương pháp như LSQ [11], một mô hình lượng tử hóa 2-bit có thể đạt được tỷ lệ nén lên đến 16 × với độ giảm độ chính xác ít hơn vài phần trăm so với đường cơ sở FP32. Hơn nữa, các nút tính toán chuyên sâu trong mạng, bao gồm các lớp dày đặc và tích chập, cũng có thể sử dụng các phép toán bit rẻ tiền để thực hiện các tích vô hướng trên dữ liệu bit cực thấp. Sự nén và tăng tốc đáng kể từ lượng tử hóa bit siêu thấp khiến nó trở thành một lựa chọn hấp dẫn cho việc triển khai CNN trên các thiết bị biên.

Khối lượng công việc học sâu trên kiến trúc CPU trong các thiết bị biên thông dụng ngoài luồng thường sử dụng các đơn vị phần cứng Single Instruction, Multiple Data (SIMD) để thực hiện các phép toán trên nhiều đầu vào song song. Suy luận INT8 có thể được thực hiện dễ dàng vì các lệnh SIMD 8-bit có sẵn trong kiến trúc bộ lệnh (ISA) của các CPU chính thống. Mặt khác, các mô hình độ chính xác siêu thấp đòi hỏi các phép toán trên dữ liệu dưới 8-bit yêu cầu triển khai kernel tùy chỉnh vì thực thi SIMD thường không được hỗ trợ trên ít hơn 8 bit. Hơn nữa, trọng số và kích hoạt được "lượng tử hóa giả" trong các lượt truyền xuôi và ngược của QAT. Điều này có nghĩa là các giá trị đầu vào được làm tròn thành một tập hợp rời rạc các giá trị điểm nổi và tất cả các tính toán vẫn được thực hiện ở độ chính xác đầy đủ trong giai đoạn huấn luyện. Trong trường hợp lượng tử hóa INT8, trọng số và kích hoạt mô hình trong FP32 có thể dễ dàng được ép kiểu thành số nguyên 8-bit tiêu chuẩn khi xuất mô hình lượng tử hóa để suy luận. Tuy nhiên, đối với lượng tử hóa bit siêu thấp, việc chuyển đổi sang độ chính xác cực thấp không thể được thực hiện ở giai đoạn này do thiếu hỗ trợ cho các kiểu dữ liệu dưới 8-bit trên nền tảng đích. Thông thường, khung học máy được sử dụng để huấn luyện chèn các toán tử tùy chỉnh cho các lớp lượng tử hóa như tích chập trong quá trình xuất mô hình sau QAT. Động cơ suy luận sau đó cần phân tích các toán tử tùy chỉnh này khi tải mô hình, hạ thấp chúng xuống các kernel bit siêu thấp tương ứng dựa trên lớp lượng tử hóa, và đóng gói các đầu vào lượng tử hóa giả trong các cấu trúc dữ liệu bit siêu thấp. Những sửa đổi này cần thiết trong cả đường dẫn huấn luyện và suy luận khiến việc triển khai các mô hình bit siêu thấp trên phần cứng thông dụng thực tế trở nên cực kỳ thách thức.

Để giải quyết những thiếu sót này trong các đường ống bit siêu thấp, chúng tôi giới thiệu Deeplite Runtime (DeepliteRT), một giải pháp suy luận đầu cuối đến cuối dựa trên ngăn xếp trình biên dịch học máy TVM [2], cung cấp hiệu suất tiên tiến và triển khai bất khả tri khung cho các mô hình bit siêu thấp trên CPU ARM. Chúng tôi triển khai một toán tử tích chập bit siêu thấp cải thiện hiệu suất của kernel bit-serial TVM [8] [9] lên đến 4.34 ×. Chúng tôi cung cấp các kernel bit-serial ARMv7 32-bit và ARMv8 64-bit làm cho suy luận CNN bit siêu thấp có thể thực hiện được trên các thiết bị biên dựa trên ARM phổ biến toàn cầu. Chúng tôi định nghĩa các lượt biên dịch để tự động chuyển đổi các lớp tích chập tiêu chuẩn thành các toán tử bit siêu thấp và đóng gói hiệu quả dữ liệu độ chính xác đầy đủ thành các biểu diễn bit siêu thấp nhỏ gọn. Những lượt này

--- TRANG 3 ---
ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN 3
Bảng 1: Độ chính xác 2-bit trên ImageNet với các phương pháp QAT khác nhau [5] [32] [22] [6] [11].
Mô hình Top-1 Độ chính xác Top-1@2-bit
Độ chính xác@32-bit PACT (2018) LQ-NET (2018) QIL (2019) PACT-SAWB (2019) LSQ (2020)
ResNet18 70.5% 64.4% 65.2% 65.7% 67.0% 67.9%
ResNet50 76.9% 72.2% 71.5% 74.2% 74.6%
cho phép các mô hình lượng tử hóa bit siêu thấp giả được huấn luyện với nhiều khung ML khác nhau được thực thi trên CPU ARM mà không cần bất kỳ thay đổi bổ sung nào trong đường dẫn huấn luyện và suy luận. Với hỗ trợ suy luận độ chính xác hỗn hợp, các lớp trong mạng nhạy cảm với lượng tử hóa có thể được giữ ở độ chính xác cao hơn (FP32, INT8, v.v.) trong khi các lớp không nhạy cảm có thể được giảm xuống bit siêu thấp để giảm thiểu độ giảm độ chính xác từ việc lượng tử hóa tất cả các lớp trong mô hình. Tóm lại, bài báo này đưa ra những đóng góp sau:

• Chúng tôi triển khai các kernel tích chập bit-serial hiệu suất cao đạt được tăng tốc lên đến 4.34 × so với các phương pháp bit siêu thấp hiện có trên các nền tảng dựa trên ARM.

• Chúng tôi trình bày DeepliteRT, một gói trình biên dịch và runtime cho suy luận bit siêu thấp trên CPU ARM. DeepliteRT tự động hóa quá trình chuyển đổi các lớp tích chập lượng tử hóa giả từ các khung học máy khác nhau được sử dụng cho huấn luyện nhận biết lượng tử hóa thành các kernel tích chập bit siêu thấp. Các mô hình lượng tử hóa có thể được xuất với trọng số và kích hoạt vẫn ở độ chính xác đầy đủ mà không cần định nghĩa toán tử tùy chỉnh vì các lượt biên dịch trong DeepliteRT có thể xử lý việc ép kiểu, biến đổi bố cục và chuyển đổi toán tử cần thiết trong quá trình biên dịch. DeepliteRT cung cấp một giải pháp đầu cuối đến cuối bất khả tri khung cho triển khai CNN bit siêu thấp trên các thiết bị biên loại bỏ nhu cầu sửa đổi bất kỳ mã nào trong đường dẫn suy luận hoặc runtime.

• Chúng tôi thực hiện đánh giá toàn diện về DeepliteRT trên các mô hình phân loại và phát hiện cho cả mục tiêu ARMv7 và ARMv8, đạt được những cải thiện hiệu suất đáng kể lên đến 2.20 ×, 2.33× và 2.17 × so với các đường cơ sở FP32, INT8 và bit siêu thấp được tối ưu hóa cao, tương ứng.

2 Công trình liên quan
2.1 Lượng tử hóa bit siêu thấp
Các phương pháp lượng tử hóa có thể được phân loại rộng rãi thành đồng nhất và không đồng nhất cũng như huấn luyện nhận biết lượng tử hóa (QAT) và lượng tử hóa sau huấn luyện (PTQ). Lượng tử hóa đồng nhất đề cập đến trường hợp các trọng số điểm nổi được lượng tử hóa thành các giá trị số nguyên với tỷ lệ tuyến tính từ miền số nguyên sang điểm nổi. Lợi ích của các phương pháp này là các phép toán có thể được thực hiện trong miền số nguyên và nhanh chóng chuyển đổi sang miền điểm nổi thông qua phép nhân của một hệ số tỷ lệ. Lượng tử hóa không đồng nhất loại bỏ hạn chế này, cho phép linh hoạt hơn trong việc ánh xạ từ dữ liệu điểm nổi sang số nguyên.

QAT lượng tử hóa trọng số và kích hoạt trong khi huấn luyện mô hình để mô phỏng tốt hơn hiệu suất của mô hình sau khi triển khai lượng tử hóa. Các phương pháp PTQ huấn luyện một mô hình độ chính xác đầy đủ mà không quan tâm đến lượng tử hóa, và sau đó lượng tử hóa mô hình với quyền truy cập tối thiểu vào tập dữ liệu huấn luyện. Các phương pháp lượng tử hóa bit siêu thấp tiên tiến, được hiển thị trong Bảng 1, sử dụng QAT để bù đắp sự mất mát độ chính xác khi giảm độ chính xác xuống dưới 8 bit. LSQ

--- TRANG 4 ---
4 ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN
[11] là một phương pháp lượng tử hóa đơn giản nhưng hiệu quả tận dụng cả lượng tử hóa đồng nhất và QAT để lượng tử hóa các mô hình xuống thấp đến 2 bit với sự suy giảm độ chính xác tối thiểu. Ví dụ, ResNet18 được lượng tử hóa xuống 2 bit với LSQ chỉ gây ra 2.4% giảm độ chính xác so với độ chính xác đầy đủ, nhưng cung cấp nén 16 × trên mỗi lớp lượng tử hóa.

2.2 Suy luận bit siêu thấp
Hầu hết các công trình trước đây về suy luận dưới 8-bit trên kiến trúc CPU sử dụng phương pháp bit-serial [8] [9] cho tính toán tích vô hướng. Xem xét các vectơ nhị phân với mã hóa đơn cực (không dấu) nơi mỗi giá trị đầu vào là 0 hoặc 1, tích vô hướng bit-serial được cho bởi Phương trình (1a). Phép toán AND theo bit cho tích từng phần tử của các đầu vào nhị phân và phép toán popcount, đếm số lượng bit được đặt thành 1, thực hiện tích lũy. Trường hợp nhị phân có thể dễ dàng được mở rộng đến độ rộng bit lớn hơn bằng cách cắt các đầu vào thành các vectơ nhị phân và thực hiện tổng của các tích vô hướng bit-serial trên tất cả các kết hợp cắt bit có thể. Phương trình tương ứng cho một vectơ trọng số M-bit và vectơ kích hoạt N-bit được cho trong Phương trình (1b) nơi các phép toán được thực hiện trên các mặt phẳng bit (wm và an).

⃗w·⃗a=popcount (⃗w&⃗a) (1a)
⃗w·⃗a=M−1∑m=0N−1∑n=0(popcount (⃗wm&⃗an))<< (n+m) (1b)

Phương pháp bit-serial này được triển khai trong TVM cho các lớp dày đặc và tích chập trong [8] và [9] với tăng tốc trung bình 1.9 × cho một mạng ResNet18 2-bit so với đường cơ sở FP32 được tối ưu hóa trên CPU ARM Cortex-A53 trong Raspberry Pi 3B. Riptide [13] cũng sử dụng các kernel bit-serial trong TVM cùng với các tối ưu hóa fusion, vectorization và tiling cho các mạng nhị phân để đạt được những cải thiện độ trễ đáng kể so với các mô hình độ chính xác đầy đủ trên Cortex-A53. Bitflow [17] trình bày một triển khai bit-serial khác của mạng VGG nhị phân cho CPU Intel thậm chí còn nhanh hơn CNN độ chính xác đầy đủ tương ứng được thử nghiệm trên GPU hiệu suất cao. Cũng đã có những sáng kiến trong không gian này không dựa trên phương pháp bit-serial bao gồm ULPPACK [30], BiQGEMM [21] và DeepGEMM [14].

3 Tích chập bit-serial
3.1 Đóng gói bit
Các phương pháp lượng tử hóa nhị phân [26] có thể dẫn đến mất mát độ chính xác không thể chấp nhận được do việc sử dụng một bit duy nhất cho các giá trị trọng số và kích hoạt. Để chống lại điều này, phương pháp bit-serial có thể được mở rộng đến nhiều bit bằng cách cắt trọng số đầu vào và kích hoạt thành các mặt phẳng bit riêng biệt tùy thuộc vào độ rộng bit. Điều này được minh họa trong Hình 1 cho cấu hình 2A2W (2 bit cho kích hoạt và 2 bit cho trọng số). Mỗi giá trị trong dữ liệu đầu vào đầu tiên được chia nhỏ thành các bit cấu thành của nó, tạo ra các mặt phẳng bit ở mỗi vị trí bit. Một mặt phẳng bit chứa bit tương ứng từ các giá trị đầu vào khác nhau; ví dụ, mặt phẳng bit 0 cho trọng số lưu trữ các bit ít quan trọng nhất trên các giá trị trọng số. Các mặt phẳng bit có thể được lưu trữ nhỏ gọn vào các kiểu dữ liệu tiêu chuẩn như số nguyên không dấu 8-bit thông qua quá trình đóng gói bit. Giả sử mã hóa đơn cực cho trọng số và kích hoạt 2-bit, tích vô hướng bit-serial sau đó có thể được tính toán sử dụng Phương trình (1b) tạo ra cùng kết quả như một tích vô hướng tiêu chuẩn như được hiển thị trong Hình 1. Dựa trên các thí nghiệm của chúng tôi, phép toán đóng gói bit không phải là một nút cổ chai lớn chỉ tiêu thụ 2-4% tổng thời gian thực thi trong tính toán bit-serial.

--- TRANG 5 ---
ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN 5
Hình 1: Các giá trị trọng số và kích hoạt đầu vào được cắt thành các mặt phẳng bit và đóng gói bit trong các số nguyên 8-bit không dấu cho phép tính toán tích vô hướng sử dụng các phép toán bit.

3.2 Tích vô hướng bit-serial được tối ưu hóa
Phương trình (1b) giả định một sơ đồ mã hóa đơn cực với các giá trị không dấu cho cả trọng số và kích hoạt. Các công trình gần đây [11] [6] thường sử dụng một sơ đồ lai đơn cực-lưỡng cực với kích hoạt đơn cực và trọng số lưỡng cực (có dấu) tạo ra các mô hình lượng tử hóa với độ chính xác cao hơn. Toán tử nn.bitserial_conv2d trong TVM triển khai một kernel tích chập cho sơ đồ lai này tính toán tích vô hướng bit-serial như được hiển thị trong Phương trình (2), cung cấp một đường cơ sở SOTA mã nguồn mở để so sánh với công trình của chúng tôi.

⃗w·⃗a=M−1∑m=0N−1∑n=0(popcount (⃗wm&⃗an)−popcount (¬⃗wm&⃗an))<< (n+m) (2)

So với trường hợp đơn cực thuần túy trong Phương trình (1b), phiên bản này tăng gấp đôi số lượng lệnh popcount thêm độ trễ đáng kể vào tính toán tích vô hướng. Hơn nữa, trọng số không thể nhận giá trị 0 vì sơ đồ lưỡng cực này phân phối các mức lượng tử hóa xung quanh 0. Ví dụ, trong trường hợp 2 bit, mỗi giá trị trọng số sẽ nằm trong tập hợp rời rạc {-3, -1, 1, 3}. Biểu diễn như vậy gây ra lỗi khi lượng tử hóa các giá trị không, điều này đặc biệt có hại cho các phép toán phổ biến như zero-padding và ReLU [24].

Để giải quyết những nhược điểm này, chúng tôi đề xuất một phương pháp tính toán bit-serial mới trong Phương trình (3) cho sơ đồ lai. Phương pháp của chúng tôi giảm số lượng phép toán popcount trên mỗi tích vô hướng xuống một. Nó cũng yêu cầu cùng số lượng lệnh tổng thể như biến thể đơn cực ngoại trừ bit trọng số quan trọng nhất có một chút overhead do phép nhân hằng số. Sơ đồ của chúng tôi cũng cho phép ánh xạ không của các giá trị trọng số có dấu. Ví dụ, trọng số 2-bit bây giờ rơi vào tập hợp {-2, -1, 0, 1} cung cấp khả năng tương thích với các kỹ thuật lượng tử hóa độ chính xác cao như LSQ yêu cầu ánh xạ không cho trọng số. Tích vô hướng bit-serial này là khối xây dựng của toán tử tích chập bit-serial dlrt_bitserial_conv2d của chúng tôi. Với các tối ưu hóa trong kernel và vectorization dữ liệu, sắp xếp lại vòng lặp và song song hóa, dlrt_bitserial_conv2d đạt được những cải thiện hiệu suất đáng kể so với nn.bitserial_conv2d của TVM như được hiển thị trong Hình 2.

⃗w·⃗a=(−1×∑N−1n=0(popcount (⃗wM−1&⃗an))<< (n+m), nếu m=M−1
∑M−1m=0∑N−1n=0(popcount (⃗wm&⃗an))<< (n+m), nếu không) (3)

Trái ngược với kernel nn.bitserial_conv2d chỉ được định nghĩa cho ARMv7,

--- TRANG 6 ---
6 ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN
(a) Tăng tốc trên lớp thứ hai của ResNet18 
trên các độ rộng bit khác nhau.
(b) Tăng tốc trên mô hình ResNet18 trên 
các độ rộng bit khác nhau.
Hình 2: Tăng tốc cấp độ toán tử và đầu cuối đến cuối của dlrt_bitserial_conv2d so với nn.bitserial_conv2d của TVM trên Raspberry Pi 4B chạy ở chế độ 32-bit.

chúng tôi triển khai cả kernel dlrt_bitserial_conv2d 32-bit và 64-bit cho phép triển khai trên phạm vi rộng hơn các nền tảng ARMv7 32-bit và ARMv8 64-bit.

4 DeepliteRT
Các khung học máy được sử dụng cho QAT độ chính xác siêu thấp như PyTorch [25] và TensorFlow [1] tạo ra các mô hình lượng tử hóa với các toán tử bổ sung so với mạng độ chính xác đầy đủ để xử lý việc lượng tử hóa và bỏ lượng tử hóa trọng số và kích hoạt mô hình. Giả sử lượng tử hóa đồng nhất, các toán tử này bao gồm cộng, trừ, chia, nhân, cắt và làm tròn thường được sử dụng để chuyển đổi dữ liệu điểm nổi thành số nguyên trước các lớp lượng tử hóa và dữ liệu số nguyên trở lại điểm nổi sau các lớp lượng tử hóa. Các động cơ suy luận như ONNX Runtime [10] cung cấp hỗ trợ gốc cho các toán tử này vì chúng hoạt động trên các kiểu dữ liệu tiêu chuẩn (FP32, INT16, INT8, v.v.). Tuy nhiên, các nút lượng tử hóa như tích chập và các lớp dày đặc thường được lượng tử hóa giả trong QAT, hạn chế trọng số và kích hoạt thành một tập hợp rời rạc nhưng vẫn lưu trữ chúng trong FP32. Để thực hiện triển khai bit siêu thấp trên phần cứng đích, các toán tử và thuộc tính tùy chỉnh cho các lớp này phải được thêm bởi khung ML cần được phân tích và hạ thấp xuống các kernel cấp thấp tương ứng bởi động cơ suy luận. Những sửa đổi này trong các khung ML và runtime yêu cầu một mức độ chuyên môn nào đó trong cả lĩnh vực huấn luyện và suy luận. Hơn nữa, những thay đổi được thực hiện cho một khung ML không thể chuyển đổi sang một khung khác, khiến việc triển khai mô hình bit siêu thấp lượng tử hóa không thể tiếp cận được với hầu hết các nhà thực hành.

DeepliteRT là một giải pháp suy luận định nghĩa các lượt biên dịch tùy chỉnh trong trình biên dịch học máy TVM để biến đổi các mô hình lượng tử hóa giả thành các mạng độ chính xác siêu thấp nhỏ gọn. Các nhà thực hành ML có thể thực hiện QAT trong bất kỳ khung nào họ lựa chọn và đơn giản biên dịch mô hình lượng tử hóa giả kết quả với DeepliteRT để triển khai dễ dàng trên các mục tiêu dựa trên ARM với TVM runtime. DeepliteRT bao gồm toán tử tích chập bit-serial được tối ưu hóa của chúng tôi được mô tả chi tiết trong Phần 3.2. Nó cũng hỗ trợ triển khai độ chính xác hỗn hợp cho phép các lớp nhạy cảm lượng tử hóa được giữ ở độ chính xác cao hơn và các lớp không nhạy cảm ở độ chính xác siêu thấp. Với các API cấp cao trong cả Python và C++, DeepliteRT có thể dễ dàng tích hợp trong các ứng dụng trên thiết bị biên cho biên dịch, điều chỉnh và suy luận mô hình lượng tử hóa.

--- TRANG 7 ---
ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN 7
Hình 3: DeepliteRT chuyển đổi các lớp tích chập lượng tử hóa giả từ các mô hình ở định dạng khác nhau thành các toán tử tích chập bit siêu thấp được tối ưu hóa thông qua một chuỗi các lượt biên dịch. Các lượt thay thế nn.conv2d bằng dlrt_bitserial_conv2d, đóng gói bit cho trọng số trong bit siêu thấp, và ép kiểu và biến đổi bố cục của dữ liệu theo yêu cầu. Mô hình đã biên dịch kết quả có thể được triển khai trên CPU ARMv7 và ARMv8 thông qua TVM runtime.

4.1 Các lượt biên dịch
nn.conv2d là toán tử cho tích chập 2D trong Relay IR của TVM. Các lớp tích chập từ các mô hình được huấn luyện với các khung ML khác nhau được chuyển đổi nội bộ thành nn.conv2d bởi frontend thích hợp. Ví dụ, tf.nn.conv2d từ một mô hình TensorFlow, torch.nn.Conv2d từ một mô hình PyTorch và Conv từ một mô hình ONNX đều được dịch thành nn.conv2d. Chúng tôi định nghĩa một chuỗi các lượt biên dịch trong DeepliteRT để chuyển đổi một lớp tích chập lượng tử hóa giả được biểu diễn bởi nn.conv2d trong Relay IR thành toán tử tích chập bit-serial được tối ưu hóa dlrt_bitserial_conv2d của chúng tôi như được hiển thị trong Hình 3.

convert_conv2d_bitserial: Lượt tùy chỉnh này chuyển đổi các nút nn.conv2d cho các lớp lượng tử hóa thành các nút dlrt_bitserial_conv2d trong IR. Nó cũng ép kiểu trọng số và kích hoạt đầu vào thành số nguyên và đầu ra tích chập kết quả trở lại điểm nổi.

transform_layout: Lượt này được gọi để thay đổi bố cục cho kích hoạt thành NHWC và bố cục cho trọng số thành HWIO theo yêu cầu của kernel dlrt_bitserial_conv2d cấp thấp. Việc biến đổi chỉ được thực hiện nếu kích hoạt và/hoặc trọng số chưa ở trong các bố cục yêu cầu.

bitpack_weights: Lượt tùy chỉnh này thêm các toán tử nn.bitpack trong Relay IR cho việc đóng gói bit của trọng số trong quá trình biên dịch trước tích chập bit-serial. Việc đóng gói bit của kích hoạt được xử lý bởi toán tử dlrt_bitserial_conv2d trong quá trình suy luận vì các giá trị kích hoạt không có sẵn offline.

fold_constant: Lượt này được sử dụng để thực hiện tất cả các tính toán trên trọng số trong quá trình biên dịch vì chúng là các hằng số thời gian biên dịch. Kết quả của việc ép kiểu trọng số thành số nguyên, biến đổi bố cục của chúng và đóng gói bit chúng sau đó chỉ đơn giản được truyền như một hằng số cho toán tử dlrt_bitserial_conv2d.

--- TRANG 8 ---
8 ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN
Bảng 2: Độ trễ đầu cuối đến cuối (ms) và tăng tốc của DeepliteRT 2A2W so với các đường cơ sở TVM FP32, ONNX Runtime INT8 và TVM bit-serial 2A2W.

Mô hình Raspberry Pi 4B - ARMv7 32-bit Raspberry Pi 4B - ARMv8 64-bit
FP32 INT8 2A2W 2A2W (Của chúng tôi) FP32 INT8 2A2W 2A2W (Của chúng tôi)
ResNet18 149.29 145.44 130.92 70.32 110.94 91.13 123.28 67.13
ResNet50 433.19 326.49 311.8 196.79 315.03 203.56 295.96 197.91
ResNet101 - 558.47 487.96 325.37 545.01 378.27 471.71 319.09
VGG19 - 1399 1003 654.69 - 922.28 962.65 636.79
InceptionV3 312.82 245.16 357.77 165.05 218.18 151.55 340.82 164.62
DenseNet121 387.98 589.03 296.27 252.65 302.50 261.94 269.91 227.05
VGG16-SSD300 1671 2310 1780 1190 1547 1462 1631 1060
YOLOv5s 219.72 197.27 135.64 100.32 169.93 113.5 130.03 97.49
Tăng tốc trung bình 1.89 × 1.91× 1.58× - 1.54 × 1.20× 1.56× -
Tăng tốc tối thiểu 1.40 × 1.49× 1.17× - 1.32 × 0.92× 1.19× -
Tăng tốc tối đa 2.20 × 2.33× 2.17× - 1.71 × 1.45× 2.07× -

4.2 Hỗ trợ độ chính xác hỗn hợp
Trong trường hợp mặc định, DeepliteRT chuyển đổi tất cả các lớp tích chập ngoại trừ lớp đầu tiên thành các toán tử bit-serial sử dụng độ rộng bit được chỉ định. Tuy nhiên, lượng tử hóa tất cả các lớp xuống bit siêu thấp có thể dẫn đến suy giảm độ chính xác nghiêm trọng. Điều này có thể được chống lại với lượng tử hóa độ chính xác hỗn hợp bằng cách chọn các độ chính xác khác nhau trên các lớp sử dụng các phương pháp như HAWQ-V3 [31] để bảo tồn độ chính xác. DeepliteRT cung cấp suy luận độ chính xác hỗn hợp bằng cách chấp nhận một tệp cấu hình làm đầu vào chỉ định các tham số lượng tử hóa trên mỗi lớp bao gồm độ rộng bit kích hoạt, độ rộng bit trọng số và sơ đồ mã hóa. Thông tin trên mỗi lớp này được truyền cho lượt convert_conv2d_bitserial để có chọn lọc giảm tải các lớp tích chập xuống bit siêu thấp với các độ rộng bit được cung cấp và giữ các lớp khác ở độ chính xác đầy đủ theo yêu cầu.

5 Đánh giá
Chúng tôi đánh giá các mô hình phân loại và phát hiện trên một thiết bị Raspberry Pi 4B (4 ×ARM Cortex-A72@1.8GHZ) với hệ điều hành 32-bit và 64-bit để cho phép thực thi ARMv7 và ARMv8. Chúng tôi chọn TVM FP32 cho đường cơ sở độ chính xác đầy đủ vì nó vượt trội đáng kể so với các kernel FP32 trong ONNX Runtime và TensorFlow Lite [16] trong các thí nghiệm của chúng tôi. TVM không cung cấp toán tử INT8 được tối ưu hóa nên chúng tôi chọn ONNX Runtime cho các thí nghiệm INT8 do các kernel 8-bit hiệu suất cao của nó. Cuối cùng, chúng tôi sử dụng cấu hình TVM 2A2W dựa trên toán tử nn.bitserial_conv2d cho các thí nghiệm bit siêu thấp; chúng tôi cũng chuyển toán tử này sang ARMv8 để thiết lập đường cơ sở 2A2W 64-bit. Tất cả các mô hình được triển khai với TVM và DeepliteRT đều được điều chỉnh sử dụng AutoTVM [3] với 1500 thử nghiệm.

5.1 Hiệu suất đầu cuối đến cuối
Bảng 2 báo cáo độ trễ và tăng tốc đầu cuối đến cuối cho các mô hình phân loại và phát hiện. Các số trung bình, tối thiểu và tối đa đại diện cho tăng tốc được thực hiện với DeepliteRT so với kết quả TVM FP32, ONNX Runtime INT8 hoặc TVM 2A2W trong cùng cột. Một số kết quả cho ResNet101 và VGG19 ở FP32 bị thiếu trong bảng vì thiết bị hết bộ nhớ khi tải các tham số mô hình độ chính xác đầy đủ. Thú vị là, mặc dù cấu hình TVM 2A2W cung cấp mức hiệu suất tương tự trong chế độ 32-bit và 64-bit, nó không còn cạnh tranh trong trường hợp sau do những cải thiện hiệu suất đáng kể

--- TRANG 9 ---
ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN 9
(a) ResNet18 trên VWW.
(b) VGG16-SSD300 trên VOC.
Hình 4: Đánh đổi giữa độ chính xác mô hình bit siêu thấp và hiệu suất.

cho các đường cơ sở FP32 và INT8 với ARMv8 ISA. Ngược lại, DeepliteRT cung cấp hiệu suất hàng đầu cho cả mục tiêu ARMv7 và ARMv8. Trung bình, DeepliteRT thực hiện tăng tốc 1.89 ×, 1.91× và 1.58 × ở chế độ 32-bit và 1.54 ×, 1.20× và 1.56 × ở chế độ 64-bit so với TVM FP32, ONNX Runtime INT8 và TVM 2A2W, tương ứng.

Bảng 3: Độ trễ DeepliteRT (ms) trên ResNet50 với các cấu hình độ chính xác hỗn hợp.
52 FP32 26 FP32 + 26 2A2W 52 2A2W 26 2A2W + 26 1A2W 52 1A2W
433.19 314.69 196.79 180.37 134.26

5.2 Độ chính xác mô hình và độ chính xác hỗn hợp
SOTA cho lượng tử hóa bit siêu thấp đã tiến bộ với tốc độ nhanh như được hiển thị trong Bảng 1. Chúng tôi nghiên cứu đánh đổi độ chính xác-hiệu suất của lượng tử hóa bit siêu thấp sử dụng LSQ cho một mô hình phân loại và phát hiện trong Hình 4. ResNet18 được huấn luyện trên tập dữ liệu VWW [7] chỉ gây ra giảm độ chính xác 0.86% và 2.09% so với đường cơ sở FP32 với cải thiện hiệu suất lên đến 2.12 × và 3.19 × ở 2A2W và 1A2W, tương ứng. Tương tự, VGG16-SSD300 [23] được huấn luyện trên tập dữ liệu VOC [12] chỉ thấy mất 0.18 mAP ở 2A2W trong khi thực hiện tăng tốc lên đến 1.46 ×. Những giảm độ chính xác nhỏ, cải thiện độ trễ đáng kể và tiết kiệm lớn về kích thước mô hình làm cho các mạng bit siêu thấp trở thành lựa chọn lý tưởng cho triển khai biên. Hơn nữa, suy luận độ chính xác hỗn hợp với DeepliteRT cho phép các nhà thực hành dễ dàng khám phá đánh đổi này giữa độ chính xác và hiệu suất, như được minh họa trong Bảng 3 cho ResNet50, bằng cách thay đổi số lượng lớp trong FP32, 2A2W và 1A2W. Một cấu hình lượng tử hóa thích hợp có thể được chọn dựa trên các phép đo độ chính xác và độ trễ mô hình từ mục tiêu.

6 Kết luận
Chúng tôi trình bày một giải pháp suy luận đầu cuối đến cuối trong DeepliteRT cho triển khai bất khả tri khung ML của các mô hình lượng tử hóa bit siêu thấp trên các nền tảng ARMv7 32-bit và ARMv8 64-bit. Nó triển khai các lượt biên dịch cho việc chuyển đổi tự động các mạng lượng tử hóa giả ở độ chính xác đầy đủ thành các biểu diễn nhỏ gọn trong bit siêu thấp, loại bỏ nhu cầu sửa đổi tùy chỉnh trong các thành phần huấn luyện và runtime để cho phép suy luận ở độ chính xác siêu thấp. Sử dụng các kernel tích chập bit-serial hiệu suất cao, DeepliteRT vượt trội hơn các đường cơ sở điểm nổi, số nguyên và bit siêu thấp được tối ưu hóa cao trên các mô hình phân loại hình ảnh và phát hiện đối tượng lên đến 2.20 ×, 2.33× và 2.17 ×, tương ứng.

--- TRANG 10 ---
10 ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN
Tài liệu tham khảo
[1] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, và Xiaoqiang Zheng. TensorFlow: Học máy quy mô lớn trên các hệ thống không đồng nhất, 2015. URL https://www.tensorflow.org/. Phần mềm có sẵn từ tensorflow.org.

[2] Tianqi Chen, Thierry Moreau, Ziheng Jiang, Haichen Shen, Eddie Q. Yan, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, và Arvind Krishnamurthy. TVM: ngăn xếp tối ưu hóa đầu cuối đến cuối cho học sâu. CoRR, abs/1802.04799, 2018. URL http://arxiv.org/abs/1802.04799.

[3] Tianqi Chen, Lianmin Zheng, Eddie Q. Yan, Ziheng Jiang, Thierry Moreau, Luis Ceze, Carlos Guestrin, và Arvind Krishnamurthy. Học cách tối ưu hóa các chương trình tensor. CoRR, abs/1805.08166, 2018. URL http://arxiv.org/abs/1805.08166.

[4] Yu Cheng, Duo Wang, Pan Zhou, và Tao Zhang. Một khảo sát về nén và tăng tốc mô hình cho mạng nơ-ron sâu. CoRR, abs/1710.09282, 2017. URL http://arxiv.org/abs/1710.09282.

[5] Jungwook Choi, Zhuo Wang, Swagath Venkataramani, Pierce I-Jen Chuang, Vijayalakshmi Srinivasan, và Kailash Gopalakrishnan. PACT: kích hoạt cắt tham số hóa cho mạng nơ-ron lượng tử hóa. CoRR, abs/1805.06085, 2018. URL http://arxiv.org/abs/1805.06085.

[6] Jungwook Choi, Swagath Venkataramani, Vijayalakshmi (Viji) Srinivasan, Kailash Gopalakrishnan, Zhuo Wang, và Pierce Chuang. Mạng nơ-ron lượng tử hóa 2-bit chính xác và hiệu quả. Trong A. Talwalkar, V. Smith, và M. Zaharia, biên tập viên, Proceedings of Machine Learning and Systems, tập 1, trang 348–359, 2019. URL https://proceedings.mlsys.org/paper_files/paper/2019/file/006f52e9102a8d3be2fe5614f42ba989-Paper.pdf.

[7] Aakanksha Chowdhery, Pete Warden, Jonathon Shlens, Andrew Howard, và Rocky Rhodes. Tập dữ liệu từ thức tỉnh thị giác, 2019.

[8] Meghan Cowan, Thierry Moreau, Tianqi Chen, và Luis Ceze. Tự động hóa tạo ra các toán tử học sâu độ chính xác thấp. CoRR, abs/1810.11066, 2018. URL http://arxiv.org/abs/1810.11066.

[9] Meghan Cowan, Thierry Moreau, Tianqi Chen, James Bornholt, và Luis Ceze. Tạo ra tự động các kernel học máy lượng tử hóa hiệu suất cao. Trong Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimization, CGO 2020, trang 305–316, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450370479. doi: 10.1145/3368826.3377912. URL https://doi.org/10.1145/3368826.3377912.

--- TRANG 11 ---
ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN 11
[10] Các nhà phát triển ONNX Runtime. Onnx runtime. https://onnxruntime.ai/, 2021. Phiên bản: 1.15.0.

[11] Steven K. Esser, Jeffrey L. McKinstry, Deepika Bablani, Rathinakumar Appuswamy, và Dharmendra S. Modha. Lượng tử hóa kích thước bước đã học. CoRR, abs/1902.08153, 2019. URL http://arxiv.org/abs/1902.08153.

[12] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, và A. Zisserman. Thách thức các lớp đối tượng thị giác pascal: Một hồi tưởng. International Journal of Computer Vision, 111(1):98–136, Tháng 1 2015.

[13] Joshua Fromm, Meghan Cowan, Matthai Philipose, Luis Ceze, và Shwetak Patel. Riptide: Mạng nơ-ron nhị phân đầu cuối đến cuối nhanh. Trong I. Dhillon, D. Papailiopoulos, và V. Sze, biên tập viên, Proceedings of Machine Learning and Systems, tập 2, trang 379–389, 2020. URL https://proceedings.mlsys.org/paper_files/paper/2020/file/2a79ea27c279e471f4d180b08d62b00a-Paper.pdf.

[14] Darshan C. Ganji, Saad Ashfaq, Ehsan Saboori, Sudhakar Sah, Saptarshi Mitra, MohammadHossein AskariHemmat, Alexander Hoffman, Ahmed Hassanien, và Mathieu Léonardon. Deepgemm: Suy luận độ chính xác siêu thấp được tăng tốc trên kiến trúc cpu sử dụng bảng tra cứu. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2023. URL https://arxiv.org/abs/2304.09049.

[15] Amir Gholami, Sehoon Kim, Zhen Dong, Zhewei Yao, Michael W. Mahoney, và Kurt Keutzer. Một khảo sát về các phương pháp lượng tử hóa cho suy luận mạng nơ-ron hiệu quả. CoRR, abs/2103.13630, 2021. URL https://arxiv.org/abs/2103.13630.

[16] Google. Tensorflow lite. https://www.tensorflow.org/lite, 2022. Phiên bản: 1.15.0.

[17] Anton Gulenko, Alexander Acker, Florian Schmidt, Sören Becker, và Odej Kao. Bitflow: Một khung xử lý luồng tại chỗ. Trong 2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C), trang 182–187, 2020. doi: 10.1109/ACSOS-C51401.2020.00053.

[18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Học tàn dư sâu cho nhận dạng hình ảnh. CoRR, abs/1512.03385, 2015. URL http://arxiv.org/abs/1512.03385.

[19] Yang He và Lingao Xiao. Cắt tỉa có cấu trúc cho mạng nơ-ron tích chập sâu: Một khảo sát, 2023. URL https://arxiv.org/abs/2303.00566.

[20] Gao Huang, Zhuang Liu, và Kilian Q. Weinberger. Mạng tích chập kết nối dày đặc. CoRR, abs/1608.06993, 2016. URL http://arxiv.org/abs/1608.06993.

[21] Yongkweon Jeon, Baeseong Park, Se Jung Kwon, Byeongwook Kim, Jeongin Yun, và Dongsoo Lee. Biqgemm: Nhân ma trận với bảng tra cứu cho DNN lượng tử hóa dựa trên mã hóa nhị phân. CoRR, abs/2005.09904, 2020. URL https://arxiv.org/abs/2005.09904.

--- TRANG 12 ---
12 ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN
[22] Sangil Jung, Changyong Son, Seohyung Lee, JinWoo Son, Youngjun Kwak, Jae-Joon Han, và Changkyu Choi. Huấn luyện chung mạng nơ-ron độ chính xác thấp với các tham số khoảng lượng tử hóa. CoRR, abs/1808.05779, 2018. URL http://arxiv.org/abs/1808.05779.

[23] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, và Alexander C. Berg. SSD: Bộ phát hiện MultiBox một phát. Trong Computer Vision – ECCV 2016, trang 21–37. Springer International Publishing, 2016. doi: 10.1007/978-3-319-46448-0_2. URL http://arxiv.org/abs/1512.02325.

[24] Markus Nagel, Marios Fournarakis, Rana Ali Amjad, Yelysei Bondarenko, Mart van Baalen, và Tijmen Blankevoort. Một báo cáo trắng về lượng tử hóa mạng nơ-ron. CoRR, abs/2106.08295, 2021. URL https://arxiv.org/abs/2106.08295.

[25] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, và Soumith Chintala. Pytorch: Một thư viện học sâu phong cách bắt buộc, hiệu suất cao. Trong Advances in Neural Information Processing Systems 32, trang 8024–8035. Curran Associates, Inc., 2019. URL http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf.

[26] Haotong Qin, Ruihao Gong, Xianglong Liu, Xiao Bai, Jingkuan Song, và Nicu Sebe. Mạng nơ-ron nhị phân: Một khảo sát. CoRR, abs/2004.03333, 2020. URL https://arxiv.org/abs/2004.03333.

[27] Joseph Redmon và Ali Farhadi. Yolov3: Một cải tiến tăng dần. CoRR, abs/1804.02767, 2018. URL http://arxiv.org/abs/1804.02767.

[28] Karen Simonyan và Andrew Zisserman. Mạng tích chập rất sâu cho nhận dạng hình ảnh quy mô lớn. arXiv preprint arXiv:1409.1556, 2014.

[29] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, và Zbigniew Wojna. Suy nghĩ lại kiến trúc inception cho tầm nhìn máy tính. CoRR, abs/1512.00567, 2015. URL http://arxiv.org/abs/1512.00567.

[30] Jaeyeon Won, Jeyeon Si, Sam Son, Tae Jun Ham, và Jae W. Lee. Ulppack: Nhân ma trận dưới 8-bit nhanh trên phần cứng simd thông dụng. Trong D. Marculescu, Y. Chi, và C. Wu, biên tập viên, Proceedings of Machine Learning and Systems, tập 4, trang 52–63, 2022. URL https://proceedings.mlsys.org/paper_files/paper/2022/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf.

[31] Zhewei Yao, Zhen Dong, Zhangcheng Zheng, Amir Gholami, Jiali Yu, Eric Tan, Leyuan Wang, Qijing Huang, Yida Wang, Michael W. Mahoney, và Kurt Keutzer. HAWQV3: lượng tử hóa mạng nơ-ron dyadic. CoRR, abs/2011.10680, 2020. URL https://arxiv.org/abs/2011.10680.

[32] Dongqing Zhang, Jiaolong Yang, Dongqiangzi Ye, và Gang Hua. Lq-nets: Lượng tử hóa đã học cho mạng nơ-ron sâu chính xác cao và nhỏ gọn. CoRR, abs/1807.10029, 2018. URL http://arxiv.org/abs/1807.10029.

--- TRANG 13 ---
ASHFAQ ET AL.: DEEPLITERT: TẦM NHÌN MÁY TÍNH TẠI BIÊN 13
[33] Guangxu Zhu, Dongzhu Liu, Yuqing Du, Changsheng You, Jun Zhang, và Kaibin Huang. Hướng tới một biên thông minh: Truyền thông không dây gặp học máy. IEEE Communications Magazine, 58(1):19–25, 2020. doi: 10.1109/MCOM.001.1900103.

# Học Biểu Diễn Hạng Thấp cho Nén Mô Hình
Zezhou Zhu,1Yucong Zhou,2Zhao Zhong2
1Đại học Bưu chính Viễn thông Bắc Kinh
2Huawei
zhuzezhou@bupt.edu.com, zhouyucong1, zorro.zhongzhao@huawei.com

## Tóm tắt
Lượng tử hóa Vector (VQ) là một phương pháp nén mô hình hấp dẫn để có được một mô hình nhỏ với ít mất mát độ chính xác hơn. Trong khi các phương pháp để có được codebook và mã tốt hơn dưới chiều phân cụm cố định đã được nghiên cứu rộng rãi, việc tối ưu hóa các vector có lợi cho hiệu suất phân cụm chưa được xem xét cẩn thận, đặc biệt là thông qua việc giảm chiều vector. Bài báo này báo cáo tiến bộ gần đây của chúng tôi về việc kết hợp nén chiều và lượng tử hóa vector, đề xuất một phương pháp Lượng tử hóa Vector Biểu diễn Hạng Thấp (LR2VQ) vượt trội hơn các thuật toán VQ trước đây trong nhiều tác vụ và kiến trúc khác nhau. LR2VQ kết hợp biểu diễn hạng thấp với phân cụm subvector để xây dựng một loại khối xây dựng mới được tối ưu hóa trực tiếp thông qua huấn luyện đầu cuối đến cuối trên hàm mất mát của tác vụ. Mẫu thiết kế đề xuất của chúng tôi giới thiệu ba siêu tham số: số cụm k, kích thước subvector m và chiều phân cụm ~d. Trong phương pháp của chúng tôi, tỷ lệ nén có thể được kiểm soát trực tiếp bởi m, và độ chính xác cuối cùng chỉ được xác định bởi ~d. Chúng tôi nhận ra ~d như một sự đánh đổi giữa lỗi xấp xỉ hạng thấp và lỗi phân cụm và thực hiện cả phân tích lý thuyết và quan sát thực nghiệm để hỗ trợ ước tính ~d phù hợp trước khi tinh chỉnh. Với ~d phù hợp, chúng tôi đánh giá LR2VQ với ResNet-18/ResNet-50 trên bộ dữ liệu phân loại ImageNet, đạt được cải thiện độ chính xác top-1 2.8%/1.0% so với các thuật toán nén dựa trên VQ tiên tiến nhất hiện tại với hệ số nén 43×/31×.

## Giới thiệu
Trong những năm gần đây, mạng nơ-ron sâu đã đạt được hiệu suất đáng chú ý trên các tác vụ thị giác khác nhau như phân loại hình ảnh, phát hiện đối tượng và phân đoạn ngữ nghĩa. Tuy nhiên, tiến bộ này được thúc đẩy bởi các kiến trúc mạng rộng hơn và sâu hơn, có dung lượng bộ nhớ lớn và chi phí tính toán cao. Những mạng này khó được triển khai trên phần cứng chạy bằng pin và hạn chế tài nguyên như thiết bị đeo và điện thoại di động. Đồng thời, mạng nơ-ron sâu dư thừa về tham số và kết nối lớp, điều này ngụ ý rằng có thể nén chúng mà không mất nhiều độ chính xác. Do đó, việc nén mạng nơ-ron là thiết yếu cho các ứng dụng thực tế.

Có một số cách tiếp cận để nén mạng nơ-ron sâu từ các góc độ khác nhau. Thiết kế mạng compact (Zhang et al. 2017; Sandler et al. 2018; Howard et al. 2019; Tan and Le 2019) và tìm kiếm kiến trúc nơ-ron (NAS) (Zoph et al. 2018; Zhong et al. 2018; Pham et al. 2018; Zhang, Zhang, and Zhong 2020; Fang, Wang, and Zhong 2019) tập trung vào khám phá các kiến trúc nhẹ; Cắt tỉa (LeCun, Denker, and Solla 1990) có xu hướng loại bỏ các kết nối hoặc kênh không cần thiết trên các mô hình nặng một cách trực tiếp; Lượng tử hóa (Courbariaux, Bengio, and David 2016; Hubara et al. 2016) nén mỗi tham số từ FP32 xuống bit thấp hơn. Ở đây chúng tôi tập trung vào Lượng tử hóa Vector (VQ) (Jegou, Douze, and Schmid 2011) để đạt được tỷ lệ nén-độ chính xác cao hơn.

VQ khai thác sự dư thừa bộ lọc để giảm chi phí lưu trữ với codebook và mã. Hầu hết các công trình trước đây (Gong et al. 2014; Son, Nah, and Lee 2018; Wu et al. 2016; Stock et al. 2020; Chen, Wang, and Cheng 2020; Martinez et al. 2021) đều thể hiện hiệu suất ấn tượng về tỷ lệ nén-độ chính xác. Chìa khóa thành công của VQ là phân cụm và tinh chỉnh, trong đó phân cụm giảm nhu cầu bộ nhớ cho lưu trữ và tính toán, và tinh chỉnh giúp khôi phục hiệu suất mô hình bằng tối ưu hóa dựa trên dữ liệu. Mất mát độ chính xác của mạng được lượng tử hóa có liên quan chặt chẽ đến lỗi phân cụm. Tiến bộ lớn đã đạt được trong việc tìm codebook và mã biểu cảm hơn bằng cách giảm lỗi phân cụm dưới chiều phân cụm cố định. Tuy nhiên, chiều phân cụm là một yếu tố quan trọng ảnh hưởng đến lỗi phân cụm. Áp dụng phương pháp phân cụm dựa trên khoảng cách trong không gian nhiều chiều dễ gặp phải lời nguyền của chiều (Indyk and Motwani 2000), tạo ra khó khăn đáng kể cho việc phân cụm để tạo ra lỗi phân cụm lớn. Ngược lại, phân cụm trong không gian ít chiều dễ tạo ra lỗi phân cụm thấp hơn nhiều. Cụ thể, chiều của subvector trong các lớp tích chập luôn là 9 hoặc 18, làm tăng khó khăn trong việc tìm codebook và mã biểu cảm trong không gian nhiều chiều, và dẫn đến hiệu suất lượng tử hóa kém. Về vấn đề giảm chiều, các phương pháp biểu diễn hạng thấp được sử dụng rộng rãi cho tất cả các loại tác vụ giảm chiều. Những phương pháp đáng chú ý này đặt ra nhu cầu nghiên cứu khả năng thiết kế các bộ lượng tử tốt hơn đáng kể bằng cách kết hợp VQ và biểu diễn hạng thấp.

Để đáp ứng nhu cầu trên, bài báo này đề xuất Lượng tử hóa Vector Biểu diễn Hạng Thấp (LR2VQ), một phương pháp mới cùng xem xét tỷ lệ nén và chiều phân cụm để đạt được lượng tử hóa tốt hơn. LR2VQ sử dụng biểu diễn hạng thấp (LRR) để xấp xỉ các bộ lọc gốc và phân cụm các subvector trong LRR để đạt được lượng tử hóa. Phương pháp của chúng tôi có một đặc tính phi thường: kích thước mô hình nén được kiểm soát bởi m (kích thước subvector), và hiệu suất lượng tử hóa chỉ được xác định bởi ~d (chiều phân cụm). Đặc tính này tách rời m và ~d, luôn bằng nhau trong các cách tiếp cận VQ trước đây. Lúc này, ~d có thể thay đổi trong phạm vi rộng một cách tự do. ~d có thể thay đổi góp phần vào việc phân cụm trong không gian ít chiều, có lợi cho lượng tử hóa với lỗi phân cụm thấp hơn. Bên cạnh đó, nó cung cấp cơ hội để nghiên cứu toàn diện việc giảm chiều và lượng tử hóa vector mà không ảnh hưởng đến kích thước mô hình nén. Hơn nữa, nó giới thiệu một sự đánh đổi giữa lỗi xấp xỉ trong học biểu diễn hạng thấp và lỗi phân cụm trong lượng tử hóa. Dựa trên phân tích lý thuyết và kết quả thực nghiệm, chúng tôi hỗ trợ ước tính ~d để cân bằng phù hợp các lỗi nhằm đạt được hiệu suất lượng tử hóa tốt hơn. Chúng tôi thử nghiệm LR2VQ trên các bộ dữ liệu quy mô lớn như ImageNet và COCO. So với kết quả trong PQF (Martinez et al. 2021), LR2VQ cải thiện 2.8%/1.0% độ chính xác top-1 cho ResNet-18/ResNet-50 trên ImageNet với hệ số nén 43×/31×, và 0.91% box AP cho Mask R-CNN trên COCO với hệ số nén 26×. Tóm lại, những đóng góp chính của chúng tôi như sau:

• Chúng tôi đề xuất một phương pháp lượng tử hóa đơn giản nhưng hiệu quả gọi là Lượng tử hóa Vector Biểu diễn Hạng Thấp (LR2VQ). Kích thước subvector m và chiều phân cụm ~d độc lập lẫn nhau, làm cho việc đạt được giảm chiều cho hiệu suất lượng tử hóa tốt hơn trở nên khả thi.

• Chúng tôi xác định sự đánh đổi của ~d, và cung cấp ước tính cho ~d với cả kết quả lý thuyết và thực nghiệm để cân bằng lỗi xấp xỉ và lỗi phân cụm.

• Chúng tôi đánh giá LR2VQ với nhiều ~d khác nhau, tạo ra hiệu suất tiên tiến nhất trên các bộ dữ liệu và kiến trúc khác nhau.

## Công trình liên quan
Có một lượng lớn tài liệu về nén mạng nơ-ron sâu. Chúng tôi xem xét tài liệu liên quan từ bốn góc độ: thiết kế mạng compact, cắt tỉa, phân tích tensor, và lượng tử hóa.

**Thiết kế mạng compact** Các mạng nhẹ như SqueezeNet (Iandola et al. 2016), NasNet (Zoph et al. 2018), ShuffleNet (Zhang et al. 2017), MobileNets (Sandler et al. 2018; Howard et al. 2019) và EfficientNets (Tan and Le 2019) được đề xuất để hiệu quả về tính toán và bộ nhớ. Tuy nhiên, những kiến trúc này hoặc được thiết kế thủ công hoặc được tạo ra bởi các thuật toán tìm kiếm. Việc thiết kế mạng thủ công không hiệu quả, và các cách tiếp cận tìm kiếm hiện tại đòi hỏi tài nguyên tính toán khổng lồ. Để tránh những vấn đề này, một hướng công việc khác trực tiếp hoạt động trên các kiến trúc mạng đã tồn tại (như VGG hoặc ResNets) để đạt được nén và tăng tốc.

**Cắt tỉa** Cắt tỉa đơn giản nhất hoạt động trên các bộ lọc bằng cách loại bỏ các kết nối theo tiêu chí quan trọng cho đến khi đạt được sự đánh đổi nén-độ chính xác mong muốn (LeCun, Denker, and Solla 1990; Guo, Yao, and Chen 2016; Han et al. 2015). Tuy nhiên, hầu hết các phương pháp cắt tỉa loại bỏ các tham số riêng lẻ, và các mạng đã cắt tỉa quá thưa để đạt được tăng tốc trên các thiết bị nhúng. Do đó, một số cách tiếp cận tập trung vào cắt tỉa các kênh không quan trọng để thực hiện nén và tăng tốc đồng thời (He, Zhang, and Sun 2017; Li et al. 2017; Luo, Wu, and Lin 2017).

**Lượng tử hóa** Lượng tử hóa tương đương với việc giảm độ rộng bit của mỗi tham số trong mạng nơ-ron. Trong bối cảnh này, chúng tôi tập trung vào Lượng tử hóa Vector (VQ), xử lý từng vector riêng lẻ để phân tách một tensor nhiều chiều với các codebook kích thước nhỏ và mã bit thấp. BGD (Stock et al. 2020), P&G (Chen, Wang, and Cheng 2020), PQF (Martinez et al. 2021) và DKM (Cho et al. 2021) là các cách tiếp cận lượng tử hóa vector được đề xuất gần đây. BGD tối thiểu hóa lỗi tái tạo của feature map trong mạng được lượng tử hóa và tối ưu hóa codebook thông qua chưng cất theo lớp. P&G trực tiếp tối thiểu hóa lỗi tái tạo của tham số để đạt được cải thiện. PQF giải quyết vấn đề bất biến cho lượng tử hóa và công thức hóa một phương pháp dựa trên hoán vị để tìm một mạng tương đương chức năng để phân cụm dễ hơn. Tuy nhiên, hoán vị cũng được thực hiện trong không gian nhiều chiều, dễ dẫn đến lỗi phân cụm lớn. DKM là một phương pháp dựa trên attention học phân cụm trong quá trình huấn luyện mạng. Tuy nhiên, phương pháp phân cụm có thể vi phân đòi hỏi huấn luyện đầu cuối đến cuối tốn kém.

Khác với những cách tiếp cận này, phương pháp của chúng tôi tận dụng việc học LRR để đạt được chiều phân cụm có thể thay đổi, có lợi cho lỗi tái tạo tổng thể cho lượng tử hóa. Dựa trên tính chất này, chúng tôi khai thác sự đánh đổi trong LR2VQ để hướng dẫn tìm kiếm chiều phân cụm phù hợp. Quá trình khôi phục độ chính xác trong LR2VQ cũng có hiệu quả cao, chỉ cần vài epoch tinh chỉnh trên hàm mất mát tác vụ. Tất cả những đóng góp này tạo ra một phương pháp hiệu quả và hiệu quả cho nén mạng nơ-ron sâu.

## Phương pháp
Phương pháp đề xuất của chúng tôi nhằm đạt được tỷ lệ nén mục tiêu với codebook và mã từ chiều phân cụm khác nhau. Hướng tới mục tiêu này, LR2VQ bao gồm ba bước:

1. **Học biểu diễn hạng thấp**: Bước này học biểu diễn hạng thấp (LRR) cho tất cả các bộ lọc tích chập sử dụng các phương pháp học dựa trên gradient. Chúng tôi sử dụng LRR và biến đổi tuyến tính (LT) để thay thế các bộ lọc tích chập cho tính toán.

2. **Lượng tử hóa biểu diễn hạng thấp**: Chiều của LRR thường khác với các subvector gốc. Sau khi học LRR, chúng tôi tạo codebook và mã bằng cách phân cụm các subvector trong LRR. Thao tác này thực hiện sự thay đổi của chiều phân cụm.

3. **Tinh chỉnh toàn cục**: Chúng tôi tinh chỉnh codebook bằng cách tối thiểu hóa hàm mất mát trên bộ dữ liệu huấn luyện với tối ưu hóa dựa trên gradient. Sau tinh chỉnh, chúng tôi hợp nhất codebook và biến đổi tuyến tính (LT) để loại bỏ độ phức tạp tính toán bổ sung trong quá trình suy luận.

### Học Biểu diễn Hạng Thấp
Phần này trình bày cách tạo các bộ lọc tích chập bằng LRR và khởi tạo LRR để học mạnh mẽ.

**Định nghĩa** Hãy ký hiệu một bộ lọc tích chập W ∈ R^(Cout×Cin×K×K) trong mạng nơ-ron chưa nén, với Cout là số kênh đầu ra, Cin là số kênh đầu vào, và K là kích thước không gian của bộ lọc. Trong VQ thông thường, W nên được định hình lại thành ma trận 2D Wr ∈ R^(Cout×CinKK/m×m), trong đó m là kích thước của subvector, và CoutCinKK/m là số subvector. Giá trị của m xác định số subvector và tỷ lệ nén. Trong phương pháp của chúng tôi, chúng tôi xây dựng W bằng cách xấp xỉ Wr với hai ma trận 2D A và B:

Wr ≈ W' = AB; (1)

trong đó A ∈ R^(CoutCinKK/m×~d) và B ∈ R^(~d×m). Chiều của A là ~d ∈ [1, m]. Một khi W' được tính toán, chúng ta có thể định hình lại nó thành tensor 4D có shape Cout×Cin×K×K để thay thế W cho tính toán.

Phương trình 1 tương tự như phân tích ma trận hạng thấp, vì vậy A có thể được coi như LRR của W' và B là biến đổi tuyến tính tương ứng từ ~d đến m. Thay vì phân tích toán học W, chúng tôi trực tiếp học A và B bằng tối ưu hóa đầu cuối đến cuối, điều này thích ứng và hiệu quả hơn để có được LRR biểu cảm cho W'.

**Khởi tạo** Khởi tạo trọng số ảnh hưởng mạnh đến việc tối ưu hóa mạng nơ-ron và hiệu suất cuối cùng. Khi chúng tôi thay thế trọng số gốc bằng W', việc khởi tạo W' nên nhất quán với W. Do đó, chúng tôi mong đợi Var(W) = Var(W') = σ². Dựa trên Phương trình 1, W' được tính bằng phép nhân giữa A và B. Để đơn giản, chúng tôi khởi tạo A với phân phối chuẩn có mean bằng 0, variance bằng σ². Với các giả định trên, chúng tôi chỉ cần tính variance của B để khởi tạo. Theo các đạo hàm trong (He et al. 2015b), chúng ta có thể tính Var(B) với các phương trình sau:

Var(A) × m × Var(B) = Var(W) = Var(W')
⇒ σ² × m × Var(B) = σ²
⇒ Var(B) = 1/m. (2)

Để bảo toàn độ lớn trong pass ngược, chúng tôi nhân Var(B) với chiều đầu ra m của nó. Lúc này, chúng ta có thể khởi tạo B với phân phối chuẩn có mean bằng 0, variance bằng 1/m.

### Lượng tử hóa Biểu diễn Hạng Thấp
Trong phần này, trước tiên chúng tôi minh họa cách áp dụng VQ trên LRR đã học để có được codebook C và mã I. Sau đó, chúng tôi thảo luận về sự đánh đổi của ~d trong LR2VQ. Cuối cùng, chúng tôi giới thiệu một phương pháp phân tích để tìm kiếm ước tính thô của ~d có thể dẫn đến lỗi tái tạo thấp hơn.

**Codebook và mã** Trong LR2VQ, LRR chiếm phần lớn tham số mạng. Vì vậy chúng tôi áp dụng VQ trên LRR để tiết kiệm lưu trữ với codebook C và mã I. Trong định nghĩa của chúng tôi, A là ma trận với N/m hàng và ~d cột, trong đó N = CoutCinKK. Chúng tôi coi mỗi hàng trong A như một subvector riêng lẻ để nén, vì vậy tổng số subvector để lượng tử hóa là N/m, và chiều của subvector là ~d. Để tiết kiệm lưu trữ của những subvector này, chúng tôi sử dụng k centroid với kích thước ~d để xấp xỉ. Chúng tôi gọi tập hợp các centroid là codebook C = {c1, ..., ck} ∈ R^(k×~d) trong đó mỗi hàng trong C là một centroid. Mã I ∈ R^(N/m) là một tập hợp các phân công xác định ánh xạ xấp xỉ tốt nhất giữa subvector và centroid

Ip = argmin_q ||Ap - Cq||²₂, (3)

trong đó p và q là các chỉ số hàng trong A và C, và Ap ∈ R^(1×~d) là subvector thứ p, Cq ∈ R^(1×~d) là centroid thứ q, Ip ∈ R¹ là một mã duy nhất cho Ap. Với C và I, chúng ta có thể giải mã chúng để xây dựng Â bằng cách tra cứu C với tất cả các mã I

Â = C(I) = {CI1, ..., CIN/m} ∈ R^(N/m×~d), (4)

sau đó biến đổi Â sang không gian m chiều

W'≈Ŵ' = ÂB. (5)

Tất cả codebook và mã có thể được tạo bằng phân cụm. Kích thước subvector trong VQ thông thường là m, trong khi kích thước subvector trong phương pháp của chúng tôi là ~d. Lưu ý rằng chiều phân cụm bằng kích thước subvector cho tất cả các phương pháp VQ. Do đó, ~d là chiều phân cụm trong LR2VQ, có thể thay đổi trong [1, m]. Số subvector trong LRR cũng được kiểm soát trực tiếp bởi m, dẫn đến số subvector tương đương với các bộ lọc gốc. Kết quả là, phân cụm trên LRR không ảnh hưởng đến tỷ lệ nén. Hình 1 mô tả so sánh giữa VQ thông thường và LR2VQ.

LR2VQ tương thích với bất kỳ phương pháp phân cụm nào. Ở đây, chúng tôi giới thiệu cách LR2VQ hoạt động với phân cụm k-means. Sau khi khởi tạo codebook với các subvector trong A, k-means lặp lại trong các bước sau:

1. Cập nhật phân công thông qua Phương trình 3 theo các subvector trong LRR và codebook;
2. Cập nhật codebook (centroids) theo phân công.

Khi vòng lặp kết thúc, mã được cố định vì mỗi subvector nên được thay thế bởi một centroid cụ thể. Mặc dù lỗi Euclidean giữa subvector và centroid có thể nhỏ, những lỗi như vậy tạo ra khoảng cách lớn giữa A và Â. Do đó, tinh chỉnh mạng bổ sung là cần thiết để bù đắp cho mất mát hiệu suất.

**Sự đánh đổi của ~d** Trong LR2VQ, ~d là chiều cho xấp xỉ hạng thấp và lượng tử hóa vector. Giá trị này đồng thời ảnh hưởng đến lỗi xấp xỉ trong học biểu diễn hạng thấp và lỗi phân cụm trong lượng tử hóa vector, ảnh hưởng đến lỗi tái tạo tổng thể cho nén mô hình. Ở đây, chúng tôi thảo luận về sự đánh đổi của ~d trong LR2VQ.

Mối quan hệ khái niệm giữa lỗi tái tạo tổng thể Er, lỗi xấp xỉ Ea và lỗi phân cụm Ec được mô tả như sau:

Er ∝ Ea + Ec, (6)

và cả Ea và Ec đều bị ảnh hưởng bởi ~d. Do đó, chúng ta cần một ~d phù hợp để giảm hai lỗi này. Đối với Ea, ~d lớn hơn có nghĩa là nhiều tham số hơn trong mạng LRR, cho thấy Ea nhỏ hơn trong LR2VQ. Đặc biệt khi ~d gần m, số tham số trong mạng LRR đã đủ để xấp xỉ mạng gốc, có thể tạo ra lỗi xấp xỉ "không". Vì vậy Ea giảm đơn điệu theo ~d tăng. Đối với Ec, subvector nhiều chiều khó phân cụm, dẫn đến lỗi phân cụm lớn, trong khi subvector ít chiều thuận lợi hơn cho phân cụm. Ví dụ, khi ~d = 1, Ec có thể trở nên cực kỳ nhỏ vì mỗi subvector là một scalar đơn lẻ trong không gian 1D, đây là không gian thấp nhất và đơn giản nhất để phân cụm; Khi ~d = m, các subvector trong LRR có cùng chiều với subvector gốc, dẫn đến khó khăn phân cụm đáng kể và lỗi phân cụm lớn nhất. Vì vậy Ec tăng đơn điệu theo ~d tăng. Dựa trên thảo luận trên, chúng ta có thể kết luận rằng Ea và Ec tương quan nghịch đảo. Cộng hai lỗi này lại, chúng ta mong đợi rằng sự thay đổi của Er tương tự như Hình 2, đầu tiên giảm sau đó tăng theo ~d tăng. Sự thay đổi như vậy cung cấp bảo đảm đáng tin cậy rằng phải có một ~d phù hợp để tạo ra lỗi tái tạo nhỏ hơn. Tóm lại, sự đánh đổi của ~d là đảm bảo lý thuyết trong LR2VQ đề xuất của chúng tôi để đạt được hiệu suất lượng tử hóa tốt hơn. Chúng tôi thử nghiệm rộng rãi trên nhiều ~d khác nhau trong các phần sau.

**Tìm kiếm ~d phù hợp** Cách hiệu quả nhất để chọn ~d phù hợp là tìm kiếm lưới, tốn thời gian và tài nguyên. Về mặt lý thuyết, một phương pháp phân tích chính xác hữu ích để tìm kiếm ~d phù hợp sau khi học biểu diễn hạng thấp. Dựa trên giả định và phân tích trong PQF (Martinez et al. 2021), chúng tôi áp dụng một phương pháp đơn giản để ước tính thô ~d sau khi học LRR như một điểm khởi đầu.

Vì các kiến trúc khác nhau có đặc tính khác nhau, khó biểu diễn Ea bằng toán học. Bên cạnh đó, Ea được cố định sau khi học LRR và có thể được đo bằng hiệu suất mô hình. Do đó, chúng tôi chọn các mạng LRR có thể so sánh với mạng gốc để tìm kiếm ~d vì Ea trong những mạng này có thể bỏ qua. Lúc này, Er bị chi phối bởi Ec, và chúng ta chỉ cần xem xét Ec trong việc tìm kiếm ~d phù hợp. Chúng tôi lưu ý rằng Ec cho thấy lỗi phân cụm giữa W' và Ŵ' chứ không phải giữa A và Â. Bản chất của LR2VQ là phân cụm các subvector trong W', và chúng tôi đạt được mục tiêu này bằng một phương pháp gián tiếp, đó là phân cụm trên A. Do đó, lỗi phân cụm giữa W' và Ŵ' là Ec thực tế trong LR2VQ. Dựa trên phân tích trên, tất cả các tính toán sau đây được thực hiện trên W' chứ không phải A.

Theo PQF, chúng ta có thể suy ra W' ~ N(0, Σ), trong đó Σ ∈ R^(m×m) là covariance của W', và cận dưới của Ec là

Ec ≥ k^(-2/m) × m × ||Σ||₁^(1/m). (7)

Tương tự như PQF, chúng tôi tối thiểu hóa ||Σ|| để giảm Ec.

Sau khi học LRR, mỗi mạng LRR với ~d ứng viên áp dụng các tính toán sau:

1. Tạo W' cho tất cả các lớp tích chập;
2. Tính ||Σ|| cho W';
3. Cộng tất cả ||Σ|| để đại diện cho Ec.

Chế độ lượng tử hóa cho tất cả các lớp FC giống nhau, và chúng tôi không áp dụng LR2VQ cho chúng. Vì vậy ||Σ|| trong các lớp FC có thể được coi là bằng nhau, có thể bỏ qua trong mỗi mạng. Sau tính toán trên, mạng với ||Σ|| thấp nhất cung cấp ước tính thô cho ~d, và việc lượng tử hóa mạng LRR tương ứng có nhiều khả năng đạt được tỷ lệ nén-độ chính xác tốt hơn trong LR2VQ. Chúng tôi minh họa kết quả của ||Σ|| với ~d khác nhau trong phần sau để xác thực các ước tính thô của phương pháp chúng tôi.

### Tinh chỉnh Toàn cục
Sau phân cụm, tinh chỉnh toàn cục là cần thiết để bù đắp cho mất mát hiệu suất do Ec gây ra. Trong bước này, chúng tôi cố định các centroid được phân công cho tất cả subvector và tinh chỉnh mạng nén với hàm mất mát và dữ liệu huấn luyện trong học biểu diễn hạng thấp. Trong quá trình tinh chỉnh, tất cả subvector sẽ được thay thế bằng Phương trình 4 và 5 để tính toán. Vì vậy các centroid có thể vi phân và có thể được cập nhật bằng gradient như sau:

c^(i)_(l,t+1) ← c^(i)_(l,t) - η̂ ∂L̂/∂c^(i)_t, (8)

trong đó L̂ là hàm mất mát, và tốc độ học được sửa đổi thành η̂. Thủ tục này mạnh mẽ trong việc tăng cường hiệu suất mô hình của các mạng được lượng tử hóa.

### Suy luận không có B
Biến đổi tuyến tính (LT) B cần thiết cho việc học biểu diễn hạng thấp. Tuy nhiên, một khi tất cả tham số được cố định sau tinh chỉnh toàn cục, chúng ta có thể loại bỏ B và tính toán trong Phương trình 1. Việc loại bỏ như vậy được thực hiện bằng tính chất giao hoán giữa LT và thao tác Bảng Tra cứu (LUT). Sau khi codebook C được cố định, chúng ta có thể có được codebook mới C' bằng

C' = CB ∈ R^(k×m), (9)

và tính toán của LR2VQ được sửa đổi thành

W ≈ W' ≈ Ŵ' = C'(I)
= (CB)(I) = C(I)B
= ÂB. (10)

Phương trình 10 ngụ ý rằng chỉ có mã I và codebook mới C' được mong đợi để lưu trữ, và tính toán trong Phương trình 1 được loại bỏ hoàn toàn bằng một thao tác LUT đơn giản C'(I) trong quá trình suy luận.

## Thí nghiệm

### Thí nghiệm trên ImageNet
Trong phần này, chúng tôi đánh giá LR2VQ của chúng tôi với vanilla ResNet-18, ResNet-50 (He et al. 2015a) trên bộ dữ liệu phân loại ImageNet (Russakovsky et al. 2015).

**Baseline** Chúng tôi so sánh phương pháp của chúng tôi với PQF và vanilla DKM vì chúng là các phương pháp VQ cạnh tranh nhất tính đến thời điểm viết bài báo này. Vì LR2VQ yêu cầu tiền huấn luyện hạng thấp trước khi lượng tử hóa, chúng tôi không sử dụng các mô hình tiền huấn luyện từ Pytorch model zoo. Thay vào đó, chúng tôi thực hiện các thủ tục huấn luyện của chúng tôi và tái thực hiện PQF và vanilla DKM dưới cùng một codebase để so sánh công bằng. Là một phương pháp VQ đại diện, PQF đã tiến hành đủ thí nghiệm và thiết lập baseline vững chắc, vì vậy chúng tôi theo cài đặt nén của nó để so sánh các phương pháp khác nhau dưới kích thước mô hình giống hệt.

**Cài đặt nén** Hãy ký hiệu cv cho tích chập 3×3, pw cho tích chập 1×1 và fc cho lớp fully-connected. Để xác định các siêu tham số trong các lớp tích chập khác nhau trong LR2VQ, chúng tôi sử dụng mcv, mpw, kcv, kpw, ~dcv, ~dpw để đại diện cho m, k và ~d trong tích chập 3×3 và pointwise. Chúng tôi thiết lập hai chế độ nén để đạt được tỷ lệ nén khác nhau. Các cấu hình chi tiết được hiển thị trong Bảng 2. Chế độ khối lớn có nghĩa là ít mã hơn và kích thước mô hình nhỏ hơn cho các mạng được lượng tử hóa. Cụ thể, chiều phân cụm cho tích chập 3×3 và pointwise trong PQF và vanilla DKM bằng mcv, mpw, và kcv, kpw cũng giống như trong LR2VQ. Đối với các lớp FC, chiều của subvector là 4, và k = 2048 cho ResNet-18 và k = 1024 cho ResNet-50. Đối với các cài đặt khác, chúng tôi theo (Martinez et al. 2021) rằng chúng tôi kẹp số centroid thành min(k, N/4) cho tính ổn định, và chúng tôi không nén tích chập 7×7 đầu tiên trong ResNets vì chúng chiếm ít hơn 0.1% kích thước mô hình.

**Dung lượng bộ nhớ** Theo PQF, chúng tôi chỉ nén trọng số trong các lớp tích chập và FC và bỏ qua bias trong các lớp FC và batchnorm. Chúng tôi huấn luyện mạng với float 32-bit nhưng lưu trữ codebook với float 16-bit. Với k = 256, tất cả mã có thể được lưu trữ như số nguyên 8-bit. Những cài đặt này hiệu quả giảm kích thước mô hình với mất mát độ chính xác có thể bỏ qua.

**Chi tiết huấn luyện** Việc học biểu diễn hạng thấp sử dụng tổng batch size 1024 trên 16 NVIDIA V100 GPU để huấn luyện 100 epoch với bộ tối ưu SGD cộng Nesterov và momentum 0.9. Weight decay là 0.0001, và tốc độ học là 0.4 với bộ lập lịch cosine annealing. Label smooth được đặt thành 0.1. Chúng tôi huấn luyện mạng LRR với ~d ∈ [3, 7] vì các giá trị khác tạo ra Ea lớn hơn hoặc Ec lớn hơn để làm hại lượng tử hóa. Sau khi học LRR, chúng tôi chạy phương pháp tìm kiếm của chúng tôi để ước tính ~d thô, và bắt đầu lượng tử hóa mạng LRR tương ứng. Chúng tôi chạy k-means trong 100 lần lặp để có được codebook và mã, sau đó tinh chỉnh mạng nén với bộ tối ưu Adam. Tốc độ học ban đầu của tinh chỉnh là 0.001 và được làm mềm bằng bộ lập lịch cosine. Thủ tục này chạy trên 16 GPU với batch size 2048 trong 9 epoch, mất nửa giờ cho ResNets.

**Kết quả** Bảng 1 hiển thị so sánh LR2VQ của chúng tôi với phân cụm k-means so với PQF và vanilla DKM trên ResNet-18 và ResNet-50 tiêu chuẩn với các cấu hình trong Bảng 2. Bảng cho thấy LR2VQ vượt trội hơn PQF và vanilla DKM trên tất cả cấu hình. Đối với ResNet-18 với nén khối lớn, LR2VQ thể hiện cải thiện rõ ràng 2.8% so với PQF dưới hệ số nén 43×. Đối với ResNet-50, LR2VQ nhất quán vượt trội hơn baseline hơn 1% độ chính xác top-1 dưới hệ số nén 31×. Cụ thể, chúng tôi đánh dấu ~dcv và ~dpw phù hợp sau kết quả của LR2VQ. Như có thể thấy, ~dcv là 4 hoặc 5 trong cả hai chế độ nén, thấp hơn ~dcv = 9 hoặc 18 trong PQF và vanilla DKM. Kết quả này xác nhận rằng phân cụm ít chiều hiệu quả giảm lỗi phân cụm và lỗi tái tạo. Bên cạnh đó, nó chứng minh những tiến bộ trong việc cùng xem xét tỷ lệ nén và chiều phân cụm, có tiềm năng lớn trong việc có lợi cho lượng tử hóa vector. Một kết quả khác chúng tôi muốn thảo luận ở đây là hiệu suất của vanilla DKM. Dựa trên tính toán của DKM, chúng tôi mong đợi nó là một phương pháp phân cụm tốt hơn so với k-means vì các cụm được tối ưu hóa đầu cuối đến cuối. Trái với kỳ vọng, vanilla DKM có hiệu suất tương tự như PQF. Hiện tượng này có thể được giải thích bằng việc tối ưu hóa của DKM cũng gặp khó khăn từ phân cụm nhiều chiều, điều này gợi ý việc thay đổi chiều trong các phương pháp phân cụm khác nhau.

### Thí nghiệm trên COCO
Để tổng quát hóa LR2VQ cho các bộ dữ liệu và kiến trúc khác nhau, chúng tôi nén Mask R-CNN với LR2VQ và thí nghiệm trên bộ dữ liệu COCO. Đầu tiên chúng tôi đề xuất học biểu diễn hạng thấp từ đầu để có được LRR, sau đó phân cụm các subvector trong LRR với k-means và tinh chỉnh toàn bộ mạng trên bộ dữ liệu COCO. Kích thước mạng tiền huấn luyện khác với (Martinez et al. 2021) vì chúng tôi sử dụng kiến trúc trong Detectron2 (Wu et al. 2019) thay vì Pytorch (Paszke et al. 2019). Để so sánh công bằng, các cấu hình nén cho PQF và LR2VQ giống như trong (Martinez et al. 2021). Kết quả được minh họa trong Bảng 3. Phương pháp của chúng tôi đạt được 38.20 box AP, vượt trội đáng kể so với PQF với 0.91 AP dưới hệ số nén 26×. Những kết quả này minh họa tính tổng quát của LR2VQ cho các tác vụ thị giác và kiến trúc khác nhau.

### Ablation về sự đánh đổi của ~d
Chúng tôi đã thảo luận về sự đánh đổi của ~d và đề xuất các giả định về sự thay đổi của lỗi trong Hình 2. Ở đây, chúng tôi thí nghiệm rộng rãi trên ~d để điều tra sự đánh đổi này và chứng minh giả định của chúng tôi. Chúng tôi thí nghiệm trên ImageNet để so sánh hiệu suất mô hình với ~d khác nhau. Chúng tôi lặp ~dcv trong [1, 9] (hoặc [1, 18]) với chế độ khối nhỏ (hoặc lớn) trong ResNet-18, ~dpw trong [1, 8] với chế độ khối lớn trong ResNet-50, và ~dcv trong [1, 9] với chế độ khối nhỏ trong Mask R-CNN. Những cài đặt này đảm bảo rằng chiều của LRR thay đổi trong phạm vi rộng. Các cấu hình khác giống như trong Bảng 2. Baseline chúng tôi so sánh ở đây là PQF. Chúng tôi vẽ độ chính xác của mạng tiền huấn luyện hạng thấp và các mạng được lượng tử hóa tương ứng của chúng. Đáng ngạc nhiên, những đường cong này thể hiện xu hướng tương tự trên các cấu hình và kiến trúc khác nhau. Khi ~d tăng, độ chính xác của các mô hình tiền huấn luyện LRR tăng nhanh, sau đó dao động quanh mạng chưa nén gốc. Các đường cong của mạng được lượng tử hóa cũng thực hiện tương tự trên các cài đặt khác nhau, đầu tiên tăng lên đỉnh và sau đó giảm theo ~d tăng. Những xu hướng này rộng rãi hỗ trợ các giả định về Ea và Er trong Hình 2 và đảm bảo thêm rằng ~d phù hợp có thể cân bằng phù hợp Ea và Ec để đạt được Er thấp hơn. Tất cả các đỉnh của đường cong đỏ là kết quả thực nghiệm cho ~d phù hợp trong LR2VQ. Cụ thể, độ chính xác của ResNet-18 nén và chưa nén với ~d = 1 cực kỳ nhỏ, cho thấy rằng lỗi phân cụm trong không gian 1D có thể bỏ qua, vì vậy Ea chi phối Er để tạo ra hiệu suất kém cho mạng nén và chưa nén. Gần như tất cả các mạng tiền huấn luyện LRR trở nên có thể so sánh với các mạng gốc trước khi đạt ~d = m, điều này ngụ ý sự dư thừa tham số khổng lồ trong tích chập. Chúng tôi lưu ý rằng ~dcv được cố định ở 5 trong ResNet-50 với khối lớn, điều này hạn chế sức mạnh của tích chập 3×3. Vì vậy luôn có khoảng cách giữa mạng tiền huấn luyện LRR và mạng chưa nén gốc. Tổng hợp tất cả những kết quả này, sự đánh đổi của ~d cung cấp bảo đảm đáng tin cậy rằng phải có một ~d phù hợp trong LR2VQ để đạt được hiệu suất lượng tử hóa tốt hơn.

**Chiều nội tại thấp hơn** Một phát hiện không mong đợi trong Hình 3 là LR2VQ vượt trội hơn PQF ngay cả ở ~dcv = mcv. Một cách trực quan, khó khăn phân cụm cho ~d = m tương tự như PQF, vì vậy hiệu suất của LR2VQ và PQF nên gần nhau. Tuy nhiên, trong những trường hợp như vậy, LR2VQ vượt trội hơn PQF trong tất cả kiến trúc. Sự khác biệt này có thể được quy cho việc học biểu diễn hạng thấp của chúng tôi, ngầm học chiều nội tại thấp hơn để làm cho các subvector thuận lợi hơn cho phân cụm. Để xác thực suy đoán này, chúng tôi vẽ chiều nội tại của LRR bằng phân tích thành phần chính (PCA) trong mỗi lớp với ~dcv = mcv trong Hình 4. Trục x là chỉ số lớp, và trục y là chiều nội tại với tỷ lệ variance hơn 99.99% sau PCA. Như hình cho thấy, chiều nội tại của LRR có xu hướng thấp hơn nhiều so với các bộ lọc gốc. Ví dụ, 11 lớp học chiều nội tại thấp hơn trong 16 lớp trong nén khối lớn. Những kết quả này gợi ý rằng LRR có thể tự động học chiều nội tại thấp hơn để có lợi cho phân cụm.

**Kết quả tìm kiếm ~d** Để giảm chi phí tinh chỉnh, một phân tích lý thuyết để tinh chỉnh các ứng viên ~d rất có giá trị. Ở đây, chúng tôi minh họa ước tính của phương pháp thô của chúng tôi để tìm kiếm ~d. Như được mô tả trong các phần trước, chúng tôi áp dụng phương pháp tìm kiếm của chúng tôi với ~d ∈ [3, 7]. Hình 5 trình bày tổng của ||Σ|| cho ~d khác nhau. Như một điểm khởi đầu, ước tính thô của chúng tôi về ~d phù hợp sử dụng Phương trình 7 cho thấy sự đồng ý với kết quả thực nghiệm. Tất cả những kết quả này hợp lý vì phân phối của subvector cũng ảnh hưởng đến phân cụm, điều này phù hợp với kết quả trong phần trước. Với số centroid cố định, giảm ~d có thể giảm khó khăn phân cụm, nhưng các subvector khó phân cụm cũng tạo ra lỗi phân cụm đáng kể. May mắn thay, các thí nghiệm của chúng tôi cho thấy rằng các subvector đã học trong LR2VQ thuận lợi cho phân cụm. Do đó, ước tính thô của chúng tôi cung cấp hướng đúng hướng tới ~d phù hợp.

## Kết luận
Chúng tôi đề xuất một phương pháp mới gọi là LR2VQ, đầu tiên học biểu diễn hạng thấp (LRR) và sau đó lượng tử hóa LRR để đạt được nén. LR2VQ tách rời kích thước subvector và chiều phân cụm bằng cách lượng tử hóa các subvector trong LRR đã học, làm cho việc thực hiện sự thay đổi của chiều phân cụm dưới kích thước mô hình nén cố định trở nên khả thi. Bản chất có thể thay đổi của chiều phân cụm giới thiệu một sự đánh đổi giữa lỗi xấp xỉ và lỗi phân cụm, điều này ngụ ý rằng giá trị của ~d quan trọng đối với hiệu suất của LR2VQ. Chúng tôi cung cấp phân tích lý thuyết và quan sát thực nghiệm để đưa ra ước tính của ~d phù hợp sau khi học LRR. Chúng tôi đánh giá LR2VQ trên các bộ dữ liệu và kiến trúc khác nhau, và tất cả kết quả đều chứng minh rằng LR2VQ dẫn đầu hiệu suất tiên tiến nhất trong số các đối thủ cạnh tranh. Bài báo này cung cấp đánh giá toàn diện đầu tiên về việc giảm chiều phân cụm, đáng tin cậy cho lượng tử hóa vector.

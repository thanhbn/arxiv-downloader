# 2310.08588.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2310.08588.pdf
# Kích thước tập tin: 7943894 bytes

===============================================
NỘI DUNG TẬP TIN PDF
===============================================

--- TRANG 1 ---
Octopus: Lập trình viên Thị giác-Ngôn ngữ Thể hiện
từ Phản hồi Môi trường
Jingkang Yang∗,1, Yuhao Dong∗,2,3, Shuai Liu∗,2,4, Bo Li∗,1,
Ziyue Wang†,1, Haoran Tan†,4, Chencheng Jiang†,5, Jiamu Kang†,3,
Yuanhan Zhang1, Kaiyang Zhou6, và Ziwei Liu1,B
1S-Lab, Đại học Công nghệ Nanyang 2Phòng thí nghiệm AI Thượng Hải
3Đại học Thanh Hoa 4BUPT 5XJTU 6Đại học Baptist Hồng Kông
{jingkang001, ziwei.liu}@ntu.edu.sg
Hình 1: Minh họa lập trình viên thị giác-ngôn ngữ của chúng tôi, Octopus, hoàn thành
một nhiệm vụ trong môi trường GTA. Được đưa ra một nhiệm vụ dưới dạng ngôn ngữ tự nhiên, Octopus
dựa vào thị giác tự trung tâm của nó để tạo kế hoạch và mã thực thi tương ứng.
Tóm tắt. Các mô hình thị giác-ngôn ngữ lớn (VLMs) đã đạt được tiến bộ đáng kể trong nhận thức và lý luận đa phương thức. Khi được tích hợp vào một tác nhân thể hiện, các công trình VLM thể hiện hiện tại hoặc xuất ra các chuỗi hành động chi tiết ở cấp độ thao tác hoặc chỉ cung cấp kế hoạch ở cấp độ trừu tượng, để lại khoảng cách giữa kế hoạch cấp cao và thao tác thế giới thực. Để thu hẹp khoảng cách này, chúng tôi giới thiệu Octopus, một lập trình viên thị giác-ngôn ngữ thể hiện sử dụng tạo mã thực thi như một phương tiện để kết nối kế hoạch và thao tác. Octopus được thiết kế để 1) thành thạo hiểu các mục tiêu nhiệm vụ thị giác và văn bản của tác nhân, 2) xây dựng các chuỗi hành động phức tạp, và 3) tạo mã thực thi. Để hỗ trợ phát triển mô hình Octopus, chúng tôi giới thiệu OctoVerse: một bộ môi trường được thiết kế riêng để đánh giá các bộ tạo mã dựa trên thị giác trên phạm vi rộng các nhiệm vụ, từ các công việc hàng ngày tầm thường trong các trình mô phỏng đến các tương tác tinh vi trong các trò chơi video phức tạp như Grand Theft Auto (GTA) và Minecraft. Để huấn luyện Octopus, chúng tôi tận dụng GPT-4 để kiểm soát một tác nhân khám phá tạo dữ liệu huấn luyện, tức là các bản thiết kế hành động và mã thực thi tương ứng. Chúng tôi cũng thu thập phản hồi cho phép một sơ đồ huấn luyện nâng cao được gọi là Học Tăng cường với Phản hồi Môi trường (RLEF). Thông qua một loạt thí nghiệm, chúng tôi chứng minh chức năng của Octopus và trình bày các kết quả hấp dẫn, cho thấy RLEF được đề xuất tinh chỉnh việc ra quyết định của tác nhân. Bằng cách mở mã nguồn các môi trường mô phỏng, tập dữ liệu và kiến trúc mô hình của chúng tôi, chúng tôi khao khát khơi dậy sự đổi mới hơn nữa và thúc đẩy các ứng dụng hợp tác trong cộng đồng AI thể hiện rộng lớn hơn. Trang dự án có sẵn tại https://choiszt.github.io/Octopus/.

1 Giới thiệu
Sự trỗi dậy của các mô hình ngôn ngữ lớn (LLMs) [11,16,45,49,57] dẫn đến sự gia tăng mạnh mẽ trong các mô hình thị giác-ngôn ngữ (VLMs) [4,5,33,35,38–40], cho phép các nhiệm vụ như mô tả dựa trên hình ảnh/video [35], lý luận [15,41,64], và đối thoại [17,33]. Trong lĩnh vực AI thể hiện, các nỗ lực đáng chú ý [10,20,35] đã huấn luyện các tác nhân để xử lý đầu vào thị giác và chuyển tiếp các lệnh điều khiển động cơ.

Một cách tiếp cận khác để tương tác với môi trường tập trung vào việc thực thi nhiệm vụ thông qua các lời gọi mã, phản ánh kích thích System-I của con người [21,31] (các hành động tự động, trực quan) với mã được định nghĩa trước, và để lại các quá trình System-II [21,31] (kế hoạch và lý luận) cho các mô hình lớn. Ví dụ, tham khảo Hình 1, kế hoạch một chuyến đi xe với thú cưng có thể bao gồm một danh sách kiểm tra tiềm thức (ví dụ: getOutOf() nhà, open() cửa xe), mỗi hành động có thể được thực hiện bằng các kỹ thuật cụ thể [8,26] như học bắt chước [24,30].

Mô hình lập trình này đã được, mặc dù không phải trong thị giác, tận dụng bởi các công trình [27,53,55,56] sử dụng LLMs để tạo chương trình và kích hoạt APIs. Các mô hình tập trung vào trò chơi như Voyager [58] cũng đã sử dụng tương tự GPT cho các lời gọi hàm trong các động cơ trò chơi, mặc dù chúng thường phân tích dữ liệu trực tiếp từ môi trường của chúng.

Tuy nhiên, khi kết hợp nhận thức thị giác, các mô hình lập trình phần lớn chưa được khám phá. Các sáng kiến chính [51,62] chỉ có thể xuất ra các kế hoạch, neo chiến lược của chúng chỉ trong các trạng thái môi trường ban đầu hoặc sử dụng các đồ thị cảnh động cho đầu vào LLM, tương ứng. Mặc dù có những đổi mới, việc quá phụ thuộc vào các mô hình thị giác được đào tạo trước để chuyển đổi nội dung thị giác thành ngôn ngữ đôi khi có thể cản trở hiệu suất kế hoạch của LLM. Việc chuyển đổi từ kế hoạch thành hành động thế giới thực vẫn còn thiếu. Trong khi EmbodiedGPT [44] giải quyết vấn đề bằng cách tích hợp mô hình thị giác-ngôn ngữ cho kế hoạch và sau đó chuyển sang thao tác bằng ánh xạ chính sách, khả năng của các mô hình thị giác-ngôn ngữ thể hiện để tạo chương trình thực thi vẫn chưa được khám phá rộng rãi.

Khám phá của chúng tôi nhằm thu hẹp khoảng cách này. Một lập trình viên thị giác-ngôn ngữ thể hiện nên tích hợp quan điểm thị giác với các mục tiêu văn bản để thiết kế kế hoạch hành động và mã thực thi (Hình 1). Tuy nhiên, các môi trường trình mô phỏng hiện tại thường thiếu các hàm được thiết kế cẩn thận cần thiết để hỗ trợ các mô hình như vậy một cách hiệu quả. Các hàm này nên cân bằng tính hữu ích và độ phức tạp để tránh cản trở việc phát triển các lập trình viên thị giác-ngôn ngữ thể hiện thực sự. Ví dụ, hàm explore_until() trong Minecraft, có thể dẫn người chơi trực tiếp đến các khối cụ thể mà không cần dựa vào thông tin thị giác, có thể không phù hợp để huấn luyện các mô hình này.

Để đáp ứng yêu cầu, chúng tôi cẩn thận thiết kế và phát triển OctoVerse, một bộ môi trường bao gồm các trình mô phỏng đa dạng, bao gồm (i) OctoGibson, được xây dựng trên OmniGibson thực tế [34], (ii) OctoMC, được phát triển trên nền tảng Minecraft sáng tạo vô hạn, phong cách pixel [2], và (iii) OctoGTA, được điều chỉnh từ Grand Theft Auto V (GTA-V) tương tác cao và đắm chìm [1].

Các môi trường này cho phép huấn luyện và đánh giá mô hình lập trình thị giác-ngôn ngữ thể hiện của chúng tôi trong nhiều tình huống, từ các nhiệm vụ gia đình hàng ngày đến điều hướng đô thị phức tạp và khám phá thế giới mở, trong khi các lời gọi hàm được điều chỉnh để phụ thuộc vào thị giác.

Sử dụng môi trường OctoVerse, chúng tôi huấn luyện Octopus bằng cách tận dụng GPT-4 để thu thập dữ liệu. Chúng tôi cung cấp cho GPT-4 các thông điệp hệ thống, gợi ý môi trường và mục tiêu, cho phép nó xây dựng chiến lược hành động và mã. Đồng thời, tác nhân nắm bắt các quan điểm thị giác, tạo thành cặp hình ảnh-mã cho việc huấn luyện Octopus. Trong quá trình thu thập dữ liệu, tác nhân nhận phản hồi từ trình mô phỏng, phân biệt các nước đi thành công với các nước đi không thành công. Chúng tôi kết hợp phản hồi này bằng cách sử dụng Học Tăng cường với Phản hồi Môi trường (RLEF) và tinh chỉnh Octopus bằng Tối ưu hóa Chính sách Gần đúng (PPO) [54]. Theo kinh nghiệm, Octopus thể hiện khả năng thích ứng mạnh mẽ trong các tình huống khác nhau, vượt trội hơn các mô hình hiện tại trong kế hoạch nhiệm vụ, tạo mã và thực thi. Việc tích hợp RLEF càng nâng cao hiệu suất của Octopus, cho thấy hiệu quả của phương pháp huấn luyện này. Tóm lại, các đóng góp chính của chúng tôi bao gồm:

– Một Điểm chuẩn Lập trình Thị giác-Ngôn ngữ Mới lạ: Ba môi trường thể hiện đa dạng với các nhiệm vụ được thiết kế: (i) OctoGibson, được phát triển trên OmniGibson [34], (ii) OctoMC được phát triển trên Minecraft [2], và (iii) OctoGTA, được điều chỉnh từ GTA-V [1].

– Một Mô hình Lập trình Thị giác-Ngôn ngữ Mới: Một người lập kế hoạch và lập trình viên thị giác-ngôn ngữ thể hiện được huấn luyện với Học Tăng cường với Phản hồi Môi trường (RLEF), thể hiện kết quả hấp dẫn.

– Hiểu biết về Lập trình Thị giác-Ngôn ngữ: Chúng tôi khám phá rộng rãi Octopus và chia sẻ những hiểu biết hữu ích tạo điều kiện cho nghiên cứu tương lai về kế hoạch và lập trình thị giác.

2 Công trình liên quan

2.1 Trình mô phỏng AI Thể hiện

AI thể hiện đã tiến bộ đáng kể với việc phát triển các môi trường mô phỏng đa dạng, cho phép các nhiệm vụ nghiên cứu như khám phá thị giác [50], điều hướng [59], và hỏi đáp [18]. Một số trình mô phỏng, bao gồm AI2-THOR [32], VirtualHome [47], Habitat-Sim [52], SAPIEN [63], và Omnigibson [34], cung cấp các biểu diễn thực tế của thế giới để điều tra các thách thức AI thể hiện. OmniGibson [34] nổi bật với việc mô phỏng độ trung thực cao của các môi trường trong nhà và ngoài trời đa dạng. Môi trường OctoGibson tiếp tục nâng cao OmniGibson với các lời gọi hàm được thiết kế cẩn thận và các nhiệm vụ được xây dựng, làm cho nó rất phù hợp cho lập trình thị giác-ngôn ngữ.

Các trình mô phỏng liên quan đến trò chơi như Arade [7], CHALET [65], và VRKitchen [25] cũng đóng góp đáng kể vào AI thể hiện. Minecraft [2] đã thu hút sự chú ý trong học tăng cường và các tác nhân trò chơi [6,22,42,58,67,68] nhưng thiếu cấu trúc cần thiết cho lập trình thị giác-ngôn ngữ. OctoMC giải quyết điều này bằng cách cung cấp các lời gọi hàm được thiết kế và các nhiệm vụ được xây dựng. Trái ngược với các biểu diễn dựa trên voxel của Minecraft hạn chế khả năng chuyển giao sang môi trường thế giới thực, GTA-V [1] cung cấp một môi trường rất thực tế. Trong công trình này, chúng tôi giới thiệu OctoGTA như một thiết lập mới, tận dụng môi trường thế giới mở phong phú của GTA-V với các nhiệm vụ và lời gọi hàm được kết hợp, mở rộng nền tảng này cho nghiên cứu AI thể hiện.

2.2 AI Thể hiện với Các Mô hình Lớn

Làn sóng nghiên cứu gần đây tập trung vào việc hợp nhất LLMs với các nhiệm vụ AI thể hiện [11,45,49,57]. Ví dụ, VoxPoser giải quyết các vấn đề thao tác robot thông qua các phương pháp không giám sát [29]. Một nhóm dự án, cụ thể là SayCan [3], Palm-E [20], RT-2 [10], và EmbodiedGPT [44], tích hợp hiệu quả các gợi ý thị giác hoặc ngôn ngữ với dữ liệu thao tác robot. Bên ngoài lĩnh vực thao tác robot, các sáng kiến như Voyager [58] và Smallville [46] khai thác khả năng của GPT để giao tiếp với các hàm trò chơi, dựa vào các hàm đặt trước để quản lý các thao tác phức tạp. Theo hướng tương tự, VisProg [27] tận dụng các lời nhắc ngôn ngữ GPT-3 để tạo chương trình Python, mở ra cánh cửa cho vô số ứng dụng hấp dẫn. Trong khi mô hình Octopus được đề xuất cũng xây dựng kế hoạch và mã, đặc điểm phân biệt của nó là việc tích hợp liền mạch đầu vào thị giác trong tạo chương trình và mã. Điều này cũng trái ngược với các người lập kế hoạch thể hiện khác như TAPA [62] và SayPlan [51], triển khai các mô-đun thị giác riêng biệt để dịch dữ liệu thị giác thành đầu vào ngôn ngữ cho LLMs. Octopus xuất sắc như một mô hình thị giác-ngôn ngữ gắn kết, cung cấp không chỉ kế hoạch mà còn cả mã.

Thảo luận thêm về các công trình liên quan bổ sung (Mô hình Ngôn ngữ Thị giác, và Phản hồi trong Các Mô hình Ngôn ngữ Lớn) được bao gồm trong tài liệu bổ sung.

3 Môi trường OctoVerse

Trong phần này, chúng tôi giới thiệu ba môi trường trình mô phỏng được thiết kế để huấn luyện và đánh giá mô hình Octopus. Đối với mỗi môi trường, chúng tôi sẽ mô tả thông tin tổng thể của chúng, các cân nhắc thiết kế đặc biệt đảm bảo các nhiệm vụ được xây dựng tốt và các hàm có thể gọi phụ thuộc vào thị giác.

OctoGibson Chúng tôi xây dựng môi trường trên nền tảng của OmniGibson [34], một khung mô phỏng hiện có hỗ trợ 1.000 hoạt động hàng ngày qua 50 cảnh, với hơn 5.000 đối tượng được chú thích tỉ mỉ. Chúng tôi kết hợp 16 hàm mà robot có thể thực thi, như moveBot() và easyGrasp(). Trong môi trường này, chúng tôi tỉ mỉ tạo ra 476 nhiệm vụ¹, mỗi nhiệm vụ có trạng thái ban đầu được xác định rõ và trạng thái kết thúc dứt khoát, cho phép đánh giá hoàn thành nhiệm vụ một cách đơn giản. Trong số các nhiệm vụ này, 367 là nhiệm vụ thường lệ—các hành động đơn giản và trực tiếp như "đặt một ly vào thùng rác", được đánh dấu là Follow. Ngược lại, 109 nhiệm vụ còn lại là các nhiệm vụ lý luận cần sự hiểu biết sâu sắc hơn. Một ví dụ là "mua sô cô la", nơi tác nhân cần biết để lấy một thanh sô cô la từ kệ và sau đó đặt nó, cùng với tiền, trên quầy thanh toán, được ký hiệu là các nhiệm vụ Reason.

Để đảm bảo các nhiệm vụ của chúng tôi nhận thức thị giác, chúng tôi cố ý hạn chế việc sử dụng một số hàm, như moveBot(object), di chuyển tác nhân đến phía trước đối tượng đã cho. Để tránh làm cho nhiệm vụ quá dễ và không nhận thức thị giác, chúng tôi giới hạn tham số đã cho thành một tập hợp được định nghĩa trước của các đối tượng lớn, như bàn và tủ, thay vì các vật phẩm nhỏ như cốc và ly. Trong trường hợp này, nếu robot muốn nhặt một cốc, nó cần nhận ra liệu cốc có trên bàn hay trong tủ. Một lời gọi moveBot(object) đơn giản với tham số không phù hợp sẽ gây ra lỗi thời gian chạy. Danh sách đầy đủ các hàm được nêu trong Phụ lục.

OctoMC Môi trường OctoMC được xây dựng trên Minecraft [2], một nền tảng phổ biến cho học tăng cường và các tác nhân trò chơi. Chúng tôi tích hợp 6 hành động chức năng và tạo ra 40 nhiệm vụ², mỗi nhiệm vụ được thiết kế để tạo điều kiện cho các quan sát và thực thi toàn diện bởi tác nhân. Các nhiệm vụ này được phân bố qua 10 biome khác nhau, bao gồm cài đặt trong nhà, ngoài trời và dưới lòng đất, dưới các điều kiện thời tiết khác nhau.

Tuy nhiên, các môi trường Minecraft hiện tại thường thiếu các nhiệm vụ được xây dựng thị giác và cấu trúc cần thiết cho lập trình thị giác-ngôn ngữ. Ví dụ, trong Voyager [58], hàm exploreUntil() cho phép người chơi điều hướng trực tiếp đến các khối cụ thể mà không cần dựa vào thông tin thị giác. Hàm này hoạt động bằng cách khám phá ngẫu nhiên môi trường trong một phạm vi nhất định cho đến khi đối tượng mong muốn được tìm thấy, tại thời điểm đó nó trả về giá trị đúng, cho phép tác nhân tương tác với đối tượng được định vị, như các khối vàng hoặc cây. Mặc dù hiệu quả, cách tiếp cận này hoàn toàn tự động và không sử dụng thông tin thị giác, làm cho nó không phù hợp cho các mục tiêu dựa trên thị giác của chúng tôi.

Để giải quyết hạn chế này, chúng tôi đã tạo ra một hàm khám phá phụ thuộc thị giác, teleport(yaw, distance), hoạt động trong phạm vi nhận thức của robot. Hàm này đảm bảo rằng các hoạt động của tác nhân phụ thuộc vào thị giác và yêu cầu nhận thức và điều hướng tích cực trong môi trường. Ví dụ, để định vị một khối cây, tác nhân phải tích cực điều hướng về hướng của khu rừng, dựa vào các gợi ý thị giác để hướng dẫn khám phá của nó.

OctoGTA Môi trường OctoGTA được xây dựng trên GTA-V [1] với sự giúp đỡ của cộng đồng mod GTA tích cực. Chúng tôi tích hợp 19 hàm và có phương pháp tạo ra 25 nhiệm vụ³, như "giúp NPC lái thuyền của họ trở lại bờ" và "hòa giải cuộc chiến giữa hai NPC", trải rộng qua 5 nhóm (được hiển thị trong Hình 2 (b)). Mỗi nhiệm vụ được gán cho 5 vị trí khác nhau trong thế giới trò chơi.

Chúng tôi đã thực hiện một tập hợp các hàm cho phép tác nhân tương tác với thế giới trò chơi theo cách nhận thức thị giác. Tương tự như thiết kế trong Minecraft, chúng tôi loại bỏ các hàm như walkTo(location) có thể tầm thường hóa nhiệm vụ đến một tòa nhà hoặc điểm mốc cụ thể. Thay vào đó, chúng tôi cung cấp các hàm như goForward(distance) và turnPlayer(degree) (Hình 2 (b)). Đối với các nhiệm vụ như hòa giải cuộc chiến giữa hai NPC, hàm thiết yếu stopFight() chỉ hoạt động khi người chơi ở trong vòng 5 mét từ các NPC đang chiến đấu. Các lựa chọn thiết kế này đảm bảo rằng các hoạt động của tác nhân phụ thuộc vào thị giác và yêu cầu nhận thức và điều hướng tích cực trong môi trường.

¹Danh sách đầy đủ các nhiệm vụ và danh mục của chúng được liệt kê trong tài liệu bổ sung.
²Các nhiệm vụ chi tiết được liệt kê trong tài liệu bổ sung.
³Chúng tôi tỉ mỉ thiết kế các nhiệm vụ để thân thiện, đảm bảo chúng loại trừ bất kỳ hành vi không phù hợp hoặc bạo lực nào.

4 Octopus: Lập trình viên Thị giác-Ngôn ngữ Thể hiện

Trong phần này, chúng tôi trình bày quy trình huấn luyện Octopus. Bắt đầu từ việc thu thập dữ liệu huấn luyện trong môi trường OctoVerse, Octopus được xây dựng trên kiến trúc VLM của Otter [33] và bao gồm các mô-đun RLEF chuyên biệt để xử lý các nhiệm vụ lập trình thị giác-ngôn ngữ. Hình 4 minh họa toàn bộ quy trình huấn luyện Octopus.

4.1 Thu thập Dữ liệu Huấn luyện

Chúng tôi sử dụng quy trình thu thập dữ liệu huấn luyện tự động được mô tả ở đây cho OctoGibson và OctoMC, với cái sau sử dụng các lời nhắc tùy chỉnh được lấy cảm hứng từ Voyager [58]. Đối với OctoGTA, chúng tôi dựa vào lao động con người để tạo tập dữ liệu huấn luyện thủ công do khó khăn trong việc thu thập thông điệp môi trường văn bản trong môi trường GTA. Trong các phần sau, chúng tôi sử dụng OctoGibson làm ví dụ chính để minh họa quy trình thu thập dữ liệu. Lưu ý rằng nhiệm vụ chính trong việc tổ chức dữ liệu huấn luyện là tạo thành một cặp ngắn gọn: "đầu vào thị giác + trạng thái hiện tại/lịch sử → kế hoạch bước tiếp theo + mã thực thi".

Thu thập Thông tin Môi trường Như được hiển thị trong Hình 4 (a) và Hình 3, chúng tôi định dạng một thông điệp môi trường cho mỗi trạng thái, bao gồm các thuộc tính như Các Đối tượng Quan sát được, Các Mối quan hệ Quan sát được, Kho đồ, và nhiều hơn nữa. Cụ thể, trình mô phỏng có thể cung cấp cho chúng tôi một đồ thị cảnh chính xác tại mỗi trạng thái, định hình nội dung cho hai phần đầu tiên. Thông tin kho đồ cũng có thể truy cập được. Nhiệm vụ, ví dụ: "nấu thịt xông khói" trong Hình 3, được biểu diễn bởi Mục tiêu Nhiệm vụ.

Tự động hóa với GPT-4 Sau khi chuẩn bị thông điệp môi trường, chúng tôi đã tạo ra một thông điệp hệ thống có cấu trúc để đảm bảo rằng robot không chỉ hiểu đầu vào của nó mà còn duy trì định dạng đầu ra nhất quán. Một xem xét chi tiết về lời nhắc này có thể được tìm thấy trong phụ lục. Các thí nghiệm đã chỉ ra rằng một lời nhắc được phát âm rõ ràng cho phép GPT-4 tạo ra mã thực thi hiệu quả. Điều quan trọng cần lưu ý là độ dài kết hợp của các thông điệp hệ thống và môi trường có thể cực kỳ dài, điều này có thể khiến các mô hình GPT-4 8K tiêu chuẩn gặp khó khăn trong việc tạo ra đầu ra có ý nghĩa. Để giải quyết vấn đề này, chúng tôi sử dụng mô hình GPT-4 32K mạnh mẽ hơn. Như được minh họa trong Hình 3, khi GPT-4 nhận được thông điệp hệ thống và môi trường nhất quán, nó tạo ra các đầu ra toàn diện bao gồm phân tích tình huống hiện tại, kế hoạch và mã có thể thực hiện, hỗ trợ quá trình huấn luyện trong Phần 4.3.

Quản lý Lỗi Đáng chú ý, GPT-4 thu thập dữ liệu huấn luyện dưới nhiệm vụ chính hướng dẫn tác nhân hoàn thành các nhiệm vụ. Tuy nhiên, GPT-4 không phải là không thể mắc lỗi. Lỗi có thể biểu hiện theo nhiều cách, từ lỗi cú pháp đến thách thức vật lý trong trình mô phỏng. Ví dụ, trong Hình 3, giữa trạng thái #5 và #6, hành động thất bại do khoảng cách xa giữa tác nhân (cầm thịt xông khói) và chảo. Những thất bại như vậy đặt lại nhiệm vụ về trạng thái trước đó. Nếu một nhiệm vụ chính vẫn chưa hoàn thành sau 10 bước, nó được coi là không thành công, và chúng tôi kết thúc nhiệm vụ này vì mối quan tâm về ngân sách. Tuy nhiên, tất cả các cặp dữ liệu không có lỗi cú pháp, bất kể trạng thái hoàn thành của nhiệm vụ, đều có giá trị để tinh chỉnh hướng dẫn và cải thiện hiệu suất của mô hình.

Phản hồi Môi trường Phương pháp thử và sai liên tục của GPT-4 trong khi hướng dẫn tác nhân về phía hoàn thành nhiệm vụ phục vụ mục đích kép: thu thập các cặp đầu ra thị giác và tạo ra một tập hợp dữ liệu phản hồi phong phú. Việc chú thích tự động của phản hồi này tập trung vào hai cấp độ: đánh giá cấp bước và cấp nhiệm vụ. Đánh giá cấp bước đánh giá sự phù hợp của các trạng thái sau thực thi với các trạng thái mục tiêu của chúng. Ví dụ, trong Hình 3, các bước được mã hóa màu xanh lá cây dẫn đến phản hồi tích cực. Người ta có thể hình dung chuỗi hành động để hoàn thành nhiệm vụ như một cây, nơi mỗi nút chỉ ra một bước (nhiệm vụ phụ), bao gồm một mã hành động. Đi kèm với mỗi bước là một giá trị nhị phân biểu thị thành công hoặc thất bại, ưu tiên nhánh thành công hơn đối tác của nó. Mặt khác, đánh giá cấp nhiệm vụ đánh giá việc thực thi thành công của toàn bộ nhiệm vụ. Nếu nhiệm vụ không được hoàn thành như dự định, mọi trạng thái trong nhiệm vụ đó đều được gắn nhãn là tiêu cực, bất kể trạng thái của các nhiệm vụ phụ. Dữ liệu phản hồi được đối chiếu này phục vụ như một nền tảng cho phương pháp Học Tăng cường với Phản hồi Môi trường (RLEF) của chúng tôi, mà chúng tôi thảo luận chi tiết hơn trong Phần 4.4.

4.2 Kiến trúc Mô hình

Kiến trúc Octopus (được hiển thị trong Hình 4 (c)) được lấy cảm hứng mạnh mẽ từ mô hình Otter [33], tích hợp MPT-7B Language Decoder [43] và CLIP VIT-L/14 Vision Encoder [48]. Áp dụng các nguyên tắc thiết kế từ Flamingo [4], Octopus sử dụng Perceiver Resampler và các mô-đun Cross-Gated Attention để nâng cao sự đồng bộ thị giác-ngôn ngữ. Kiến trúc này cho phép Octopus xuất sắc trong các nhiệm vụ yêu cầu hiểu biết về cả dữ liệu thị giác và văn bản. Octopus cũng tương thích với các VLMs khác như LLaVA [40].

4.3 SFT: Tinh chỉnh Có giám sát với Hướng dẫn

Chúng tôi huấn luyện mô hình Octopus trên tập dữ liệu được thu thập của chúng tôi từ OctoVerse DE= {(Xv,Ti,Tr)} sử dụng tinh chỉnh có giám sát cấp token (SFT) [45,57]. Perceiver Resampler chuyển đổi hình ảnh Xv thành các token thị giác điều kiện các lớp tiếp theo thông qua các mô-đun Cross-Gated Attention. Mục tiêu huấn luyện là dự đoán token tiếp theo, mô hình hóa khả năng của phản hồi mục tiêu Tr như:

p(Tr|Ti,Xv) =LY
l=1p(tl|Xv,Ti,Tr,<l). (1)

Lưu ý rằng Ti biểu thị các token hướng dẫn và Tr,<l biểu thị các token phản hồi trước token được dự đoán hiện tại tl. Trong quá trình suy luận, các token được chuyển đổi thành ngôn ngữ tự nhiên thông qua trình mã hóa văn bản của bộ giải mã ngôn ngữ.

Các quan sát thị giác Xv={x0F, . . . , x7F, x0B, x1B} bao gồm 8 hình ảnh góc nhìn người thứ nhất (FPV) và hai hình ảnh góc nhìn chim (BEV) cho OctoGibson và OctoGTA. OctoMC chỉ lấy 4 hình ảnh FPV. FPV nắm bắt các quan sát trực tiếp của tác nhân, trong khi BEV cung cấp hiểu biết toàn diện về môi trường. Tám hình ảnh FPV được chụp mỗi 45 độ, đảm bảo góc nhìn 360 độ hoàn chỉnh.

4.4 RLEF: Học Tăng cường với Phản hồi Môi trường

Trong OctoVerse, tiến triển nhiệm vụ có thể được hình dung như một cây (Hình 4 (d)), nơi mỗi nút đại diện cho một nhiệm vụ phụ với giá trị nhị phân chỉ ra thành công (1) hoặc thất bại (0). Nếu một nút (hoặc nhiệm vụ phụ) có giá trị 1, đó là một bước đi đúng hướng về mục tiêu cuối cùng của chúng tôi.

Biểu diễn Nhiệm vụ dựa trên Cây Theo phần phản hồi môi trường trong Mục 4.1, các tập dữ liệu phần thưởng môi trường DR= (X∗v,T∗i,Tir,Tjr, c) được tổ chức, nơi Tir và Tjr là các phản hồi chia sẻ cùng nhiệm vụ cha T∗i, và c chỉ ra phản hồi được ưa thích dẫn đến hoàn thành nhiệm vụ. Điều này đảm bảo cơ chế phần thưởng ưu tiên nhánh được thực thi thành công. Lưu ý rằng ngay cả khi nút cha không có nhiều phản hồi, chúng tôi vẫn có thể gán phản hồi theo quy tắc trong Mục 4.1.

Cấu hình Mô hình Phần thưởng Một mô hình CodeLLaMA-7B đơn phương thức với đầu giá trị bổ sung được tinh chỉnh trên DR như mô hình phần thưởng rϕ. Mô hình dựa trên văn bản này đánh giá các chuyển đổi trạng thái (T∗i→Ti,jr) để xác định các chuyển đổi phần thưởng cao, hỗ trợ tác nhân trong việc thực thi và hoàn thành nhiệm vụ. Lý do để sử dụng CodeLLaMA làm mô hình phần thưởng là việc đánh giá phần thưởng có thể hoàn toàn phụ thuộc vào đầu ra văn bản. Hơn nữa, kỹ năng lập trình mạnh mẽ của CodeLLaMA làm cho nó rất phù hợp để đánh giá chất lượng và hiệu quả của mã được tạo trong bối cảnh hoàn thành nhiệm vụ.

Phát triển Mô hình Chính sách Mô hình được tinh chỉnh có giám sát phục vụ như mô hình chính sách ban đầu πINIT với các tham số cố định. Một mô hình trùng lặp, πRLθ, được khởi tạo và huấn luyện bằng Tối ưu hóa Chính sách Gần đúng (PPO) [54] để tối đa hóa phần thưởng phản hồi. Hàm mất mát là:

LπRLθ =−E(X∗v,T∗i)∈DR,Tr∼πRL [rϕ(T∗i,Tr)−β·DKL [πRLθ(X∗v,T∗i)∥πINIT(X∗v,T∗i)]], (2)

nơi β hoạt động như một siêu tham số để điều chỉnh cường độ của phạt Kullback–Leibler (KL).

5 Thí nghiệm

5.1 Kết quả Chính trên OctoGibson

Thiết lập Thí nghiệm Trước tiên chúng tôi thiết lập OctoGibson để đánh giá hiệu suất của Octopus và các mô hình liên quan khác. Cụ thể, chúng tôi đang sử dụng các chỉ số của điểm hoàn thành nhiệm vụ mục tiêu để kiểm tra xem nhiệm vụ có được hoàn thành trong trình mô phỏng hay không và điểm kế hoạch từ đánh giá của con người. Chúng tôi có 60 nhiệm vụ đánh giá, với 45 từ môi trường đã thấy, và 15 chưa được thấy trong quá trình huấn luyện. Chúng tôi cũng có 45 nhiệm vụ thường lệ và 15 yêu cầu lý luận. Xin lưu ý rằng các mô hình như Octopus có thể không luôn nhận dạng chính xác tên đối tượng cụ thể như chúng xuất hiện trong trình mô phỏng (ví dụ: "water_bottle_189"). Để giải quyết điều này, chúng tôi thực hiện một bước xử lý hậu kỳ cho mã được tạo, thay thế các tham chiếu đối tượng chung bằng tên chính xác của chúng từ trình mô phỏng với việc khớp độ tương tự chuỗi đơn giản. Nếu có nhiều đối tượng, chúng tôi chọn cái gần nhất với tác nhân.

Đối với LLMs Mù, chúng tôi cung cấp cho chúng tất cả thông tin môi trường ở định dạng văn bản. Tham khảo Hình 3, chúng tôi hy vọng LLMs Mù có thể hoạt động như GPT-4 nhưng nội hóa thông điệp hệ thống. Đối với TAPA sử dụng kỹ thuật phát hiện từ vựng mở (OVD) [69] để nhận dạng các đối tượng trong hình ảnh và phân tích chúng thành các thông điệp môi trường văn bản, chúng tôi vẫn cung cấp cho nó các thông điệp môi trường sự thật cơ bản như một thiết lập oracle.

CodeLLaMA Cải thiện Mã hóa nhưng không Kế hoạch. Hai hàng đầu tiên trong Bảng 3 nổi bật tỷ lệ hoàn thành nhiệm vụ không tối ưu của LLMs mù. Trong số đó, CodeLLaMA có được việc tiền huấn luyện trên một tập dữ liệu lập trình lớn, dẫn đến sự nâng cao đáng chú ý trong việc thực thi mã từ quan sát của chúng tôi, với 92% mã được viết thành công thực thi so với 24% của LLaMA. Tuy nhiên, năng lực của nó trong kế hoạch vẫn còn hạn chế. Ngược lại, mô hình Octopus MPT-7B được đề xuất hiển thị các chỉ số kế hoạch và hoàn thành nhiệm vụ vượt trội trong khi duy trì khả năng mã hóa đáng khen ngợi (72% mã được viết có thể được thực thi). Chúng tôi phỏng đoán rằng các yêu cầu mã hóa trong môi trường OctoGibson có thể không quá phức tạp, làm cho một mô hình ngôn ngữ lập trình tiên tiến, như CodeLLaMA, ít quan trọng hơn, mặc dù có lợi. Để có thêm hiểu biết, mặc dù không được hiển thị trong bảng, những nỗ lực của chúng tôi để thay thế mô hình MPT bằng CodeLLaMA gặp khó khăn trong việc tạo ra các đầu ra vô nghĩa, gợi ý rằng mã tinh chế hơn, hoặc dữ liệu được ghép nối hình ảnh-mã có thể cần thiết cho việc tích hợp Octopus-CodeLLaMA thành công.

LLMs Mù Gặp khó khăn với Nội dung Đầu vào Mở rộng. Các quan sát của chúng tôi chỉ ra rằng mô hình TAPA cấp bước, khi được cung cấp danh sách đối tượng sự thật cơ bản, đạt được sự nâng cao đáng chú ý trong kế hoạch. Sự khác biệt chính giữa nó và CodeLLaMA mù nằm ở độ dài đầu vào; cái sau xử lý nội dung mối quan hệ theo cặp kéo dài, làm phức tạp khả năng của mô hình ngôn ngữ để trích xuất dữ liệu quan trọng từ thông điệp môi trường. Tình huống này nổi bật hạn chế vốn có của LLMs mù: việc dựa vào ngôn ngữ một mình để truyền tải toàn bộ dữ liệu môi trường có thể dẫn đến đầu vào ít thông tin hơn.

Octopus Thể hiện Khái quát Nhiệm vụ Vượt trội. Bảng 3 nhấn mạnh hiệu suất mạnh mẽ của Octopus, chứng minh lợi thế nhất quán của nó so với các mô hình ngôn ngữ độc lập trong hoàn thành nhiệm vụ. Khả năng thích ứng của nó với các môi trường chưa gặp trước đó nhấn mạnh những lợi thế vốn có của các mô hình thị giác-ngôn ngữ. Phân tích ablation chi tiết hơn được cung cấp sau.

RLEF Nâng cao Chiến lược Kế hoạch của Octopus. Bảng 3 cho thấy khả năng lý luận mạnh mẽ của Octopus sau khi tinh chỉnh RLEF. Một ví dụ có thể được quan sát trong Hình 5(b-c), nơi, sau khi tinh chế thông qua RLEF, Octopus khéo léo điều hướng đến tủ chứa carboy thay vì cố gắng chụp trực tiếp nhưng xa. Về định lượng, Octopus thể hiện khả năng thích ứng nâng cao với các nhiệm vụ lý luận chưa thấy trước đó, tăng cường năng lực của nó trong giải quyết nhiệm vụ logic. Khi đối chiếu với các chiến lược khác, như các truy vấn thể hiện được sử dụng bởi EmbodiedGPT, RLEF nổi lên như cách tiếp cận hiệu quả hơn.

5.2 Nghiên cứu Ablation

Điều chỉnh Các Thành phần Khác nhau Hình 6 (a) chứng minh rằng việc chỉ điều chỉnh đầu nối (được đánh dấu "fire" trong Hình 4 (a)) dẫn đến thành công chỉ cho 4 trong số 60 nhiệm vụ. Ngược lại, việc tinh chỉnh cả đầu nối và bộ giải mã ngôn ngữ đẩy tỷ lệ thành công cao hơn một chút, với 5 nhiệm vụ được hoàn thành.

Kích thước Mô hình 7B so với 3B Chúng tôi bắt tay vào các thí nghiệm tập trung vào kích thước mô hình để phân biệt ảnh hưởng của tổng số tham số đến hiệu quả của các mô hình thị giác-ngôn ngữ. Như được minh họa trong Hình 6 (b), việc giảm kích thước mô hình biểu hiện trong sự sụt giảm hiệu suất đáng chú ý. Sự phù hợp của kết quả qua cả mô hình SFT và RLEF nhấn mạnh tầm quan trọng của kích thước mô hình phù hợp khi điêu khắc các mô hình thị giác-ngôn ngữ.

Ý nghĩa của Đầu vào Thị giác trong Hiệu suất Nhiệm vụ Trong cấu hình tiêu chuẩn của chúng tôi, thành phần thị giác xử lý một chuỗi đầu vào hình ảnh, bao gồm tám hình ảnh góc nhìn người thứ nhất (FPV) được chụp theo vòng tròn, được bổ sung bởi hai hình ảnh góc nhìn chim (BEV). Với ý định điều tra tác động của đầu vào thị giác đến hiệu suất nhiệm vụ, chúng tôi khởi xướng một nghiên cứu ablation. Trong một thiết lập được sửa đổi, chuỗi các đầu vào thị giác này được cố ý ngẫu nhiên hóa, nhằm làm suy yếu sức mạnh của các tín hiệu thị giác. Như được minh họa trong Hình 6 (c), sự gián đoạn cố ý này trong tính nhất quán đầu vào thị giác dẫn đến sự suy giảm rõ rệt trong hiệu suất nhiệm vụ. Kết quả này nổi bật vai trò quan trọng mà các đầu vào thị giác rõ ràng và có cấu trúc đóng trong mô hình Octopus, nhấn mạnh rằng nó tận dụng đáng kể các gợi ý thị giác để kế hoạch và thực thi nhiệm vụ hiệu quả.

5.3 Kết quả trên Các Nhiệm vụ Minecraft và GTA

Kết quả trên OctoMC Theo phần OctoMC trong Mục 3, chúng tôi thiết kế 40 nhiệm vụ, mỗi nhiệm vụ được vận hành trên 2 vị trí nên tổng cộng 80 nhiệm vụ. Chúng tôi dành 10 nhiệm vụ làm nhiệm vụ chưa thấy và 10 nhiệm vụ làm nhiệm vụ đã thấy, có được 60 nhiệm vụ huấn luyện và 30 nhiệm vụ kiểm tra trong OctoMC. Tương tự như OctoGibson, dữ liệu huấn luyện cho OctoMC được thu thập bằng GPT-4. Tác nhân, được hướng dẫn bởi GPT-4, khám phá môi trường Minecraft và tạo kế hoạch hành động và mã tương ứng dựa trên các thông điệp hệ thống được cung cấp, gợi ý môi trường và mục tiêu.

Bảng 4 cho thấy mô hình SFT được huấn luyện trên OctoMC có thể hoàn thành hầu hết các nhiệm vụ trong cả tình huống đã thấy và chưa thấy, thể hiện hiệu suất tốt hơn so với OctoGTA. Tuy nhiên, khi phân tích các trường hợp thất bại, chúng tôi thấy rằng mô hình đôi khi gặp khó khăn với các nhiệm vụ yêu cầu lý luận không gian chính xác. Ví dụ, khi được giao nhiệm vụ giết một con heo, tác nhân có thể gặp khó khăn trong việc tìm sinh vật với góc và khoảng cách chính xác. Mặc dù nó cho thấy rằng tác nhân dựa vào thông tin thị giác để điều hướng và tương tác với môi trường, nó cũng có nghĩa là ngay cả với kế hoạch đúng, các hành động không chính xác vẫn có thể dẫn đến thất bại.

Kết quả trên OctoGTA Theo phần OctoGTA trong Mục 3, chúng tôi thiết kế 25 nhiệm vụ. Chúng tôi dành 5 nhiệm vụ trong nhóm liên quan đến thuyền (ví dụ: lấy thuyền và trở lại bờ) làm nhiệm vụ chưa thấy chỉ để kiểm tra, sử dụng 2 vị trí khác nhau. Chúng tôi nhân bản 20 nhiệm vụ còn lại cho cả huấn luyện (8 vị trí khác nhau) và kiểm tra (2 vị trí). Kết quả là, chúng tôi có 160 nhiệm vụ huấn luyện và 50 nhiệm vụ kiểm tra trong OctoGTA. Không giống như quy trình huấn luyện cho OctoGibson và OctoMC, dữ liệu huấn luyện cho OctoGTA hoàn toàn được tạo bởi các tác giả, vì khó khăn trong việc thu thập các thông điệp môi trường văn bản trong môi trường GTA.

Bảng 4 cho thấy rằng, mặc dù chỉ có 160 nhiệm vụ huấn luyện, mô hình SFT có thể hoàn thành một số nhiệm vụ trong cả tình huống đã thấy và chưa thấy, và RLEF cũng vượt trội. Tuy nhiên, khi xem xét cẩn thận các trường hợp thất bại, chúng tôi thấy rằng mô hình gặp khó khăn với các nhiệm vụ không đơn giản. Ví dụ, khi một bức tường ngăn cách người chơi với xe, người chơi vẫn thấy khó khăn để quyết định leo tường, ngay cả khi các trường hợp tương tự tồn tại trong dữ liệu huấn luyện. Tương tự như OctoMC, như được minh họa trong Mục 3, khi tiếp cận một số vị trí, mã bao gồm các hàm như turnPlayer() và goForward() thay vì một walkTo(location) đơn giản. Do đó, ngay cả với kế hoạch đúng, các hành động thực tế không chính xác vẫn có thể dẫn đến thất bại nhiệm vụ.

6 Kết luận

Bài báo này giới thiệu Octopus, một lập trình viên thị giác-ngôn ngữ thể hiện được thiết kế để thu hẹp khoảng cách giữa kế hoạch cấp cao và thao tác thế giới thực bằng lập trình. Bằng cách mở mã nguồn môi trường OctoVerse, tập dữ liệu và kiến trúc Octopus của chúng tôi, chúng tôi nhằm thúc đẩy hợp tác và đổi mới trong cộng đồng nghiên cứu, mở đường cho những phát triển tương lai trong lập trình thị giác-ngôn ngữ thể hiện.

Lời cảm ơn và Tiết lộ Tài trợ

Nghiên cứu/dự án này được hỗ trợ bởi Quỹ Nghiên cứu Quốc gia, Singapore dưới Chương trình AI Singapore (Giải thưởng AISG Số: AISG2-PhD-2022-01-029). Bên cạnh đó, nghiên cứu này được hỗ trợ bởi Bộ Giáo dục, Singapore, dưới MOE AcRF Tier 2 (MOE T2EP20221-0012), NTU NAP, và dưới Sáng kiến Tài trợ Liên kết Công nghiệp RIE2020 – Dự án Hợp tác Công nghiệp (IAF-ICP), cũng như đóng góp tiền mặt và hiện vật từ (các) đối tác công nghiệp.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo dài với 71 mục được dịch sang tiếng Việt, bao gồm các tác phẩm nghiên cứu về trí tuệ nhân tạo, học máy, thị giác máy tính, và robot]

Phụ lục

A OctoGibson

A.1 Sự khác biệt giữa OctoGibson và OmniGibson

OctoGibson được xây dựng trên nền tảng của OmniGibson, một khung mô phỏng hỗ trợ một loạt các hoạt động hàng ngày qua các cảnh đa dạng với nhiều đối tượng được chú thích. Tuy nhiên, OctoGibson mở rộng OmniGibson theo nhiều cách quan trọng để hỗ trợ lập trình thị giác-ngôn ngữ thể hiện.

Thêm Trạng thái Có thể Kiểm soát cho Đối tượng Mỗi thuộc tính có thể vận hành của đối tượng được mô tả bởi 8 trạng thái đơn ngôi, như openable và heatable.

Thêm Trình Phân tích Mối quan hệ OctoGibson thêm 12 mối quan hệ nhị phân, như nextto và ontop, để minh họa các mối quan hệ không gian của nó với các đối tượng khác. Những chi tiết này rất cần thiết để xác định cài đặt môi trường cho tác nhân.

Thêm Nhiệm vụ OctoGibson giới thiệu một tập hợp 476 nhiệm vụ được tạo tỉ mỉ, mỗi nhiệm vụ có trạng thái ban đầu và mục tiêu được xác định rõ, cho phép đánh giá rõ ràng về hoàn thành nhiệm vụ. Các nhiệm vụ này được phân loại thành các nhiệm vụ thường lệ bao gồm các hành động đơn giản, trực tiếp, và các nhiệm vụ lý luận phức tạp hơn yêu cầu kế hoạch nhiều bước.

Thêm Lời gọi Hàm OctoGibson kết hợp 16 hàm được thiết kế cẩn thận mà tác nhân có thể thực thi, như moveBot() và easyGrasp(), để tương tác với môi trường theo cách có cấu trúc hơn.

Thêm Lời gọi Hàm Phụ thuộc Thị giác để đảm bảo rằng các hành động của tác nhân được dựa trên nhận thức thị giác, OctoGibson áp dụng một số ràng buộc nhất định trên các tham số hàm, như hạn chế moveBot() chỉ chấp nhận các đối tượng lớn, cố định làm đối số. Điều này khuyến khích tác nhân lý luận về cảnh và kế hoạch tương ứng, thay vì dựa vào kiến thức được mã hóa cứng.

Cùng nhau, những cải tiến này làm cho OctoGibson trở thành một nền tảng phù hợp hơn để nghiên cứu lập trình thị giác-ngôn ngữ thể hiện so với môi trường OmniGibson cơ bản.

A.2 Tập dữ liệu OctoGibson

Tập dữ liệu huấn luyện OctoGibson bao gồm 476 nhiệm vụ, được chia nhỏ hơn thành 3.776 nhiệm vụ phụ hướng dẫn. Tương ứng với các nhiệm vụ phụ này, 37.760 hình ảnh được thu thập để huấn luyện, tạo thành các cặp dữ liệu hình ảnh-hướng dẫn nâng cao khả năng của các mô hình thị giác-ngôn ngữ.

A.3 Cách chúng tôi Thu thập Dữ liệu Huấn luyện

Theo Hình 3 trong bài báo chính, chúng tôi sử dụng GPT-4 để tự động thu thập phản hồi bằng cách sử dụng thông điệp hệ thống và thông điệp môi trường được hiển thị dưới đây.

[Thông điệp Hệ thống và Thông điệp Môi trường chi tiết được dịch...]

A.4 Hiệu suất của GPT-4 và GPT-4V

[Phần về hiệu suất của GPT-4 và GPT-4V được dịch...]

B OctoMC

[Toàn bộ phần B về OctoMC được dịch, bao gồm background, highlighting vision-based function calls, và data collection...]

C OctoGTA

[Toàn bộ phần C về OctoGTA được dịch, bao gồm experimental environment, experiment procedure, và hand-crafted training data collection...]

D Nhận xét

[Phần so sánh với EmbodiedGPT được dịch...]

E Các Cân nhắc Đạo đức

Việc phát triển các mô hình lập trình thị giác-ngôn ngữ thể hiện như Octopus đặt ra một số cân nhắc đạo đức quan trọng cần được giải quyết cẩn thận khi công nghệ này tiến bộ.

Sử dụng và Triển khai Có trách nhiệm: Các mô hình có thể tự động lập kế hoạch và thực thi mã dựa trên hướng dẫn cấp cao có khả năng bị lạm dụng nếu rơi vào tay sai. Các nhà phát triển của các mô hình như vậy phải thực hiện các biện pháp bảo vệ và hướng dẫn nghiêm ngặt để đảm bảo chúng chỉ được triển khai trong các cài đặt có trách nhiệm và được kiểm soát bởi các bên đáng tin cậy. Điều này bao gồm có các hạn chế rõ ràng về các loại nhiệm vụ mà các mô hình có thể được yêu cầu thực hiện. Để giải quyết điều này, chúng tôi sẽ thiết lập một giấy phép phù hợp khi mã được phát hành.

An toàn và Mạnh mẽ: Trong các môi trường thể hiện, các mô hình như Octopus được giao nhiệm vụ thực hiện các hành động có thể có hậu quả thế giới thực. Cần có thử nghiệm rộng rãi qua các tình huống đa dạng để xác thực sự an toàn và mạnh mẽ của các kế hoạch và mã được tạo trước khi triển khai. Các trường hợp thất bại cần được dự đoán với xử lý ngoại lệ phù hợp và điều kiện "dừng" để ngăn ngừa tổn hại.

# Các Mô hình Ngôn ngữ Lớn (GPT) Gặp Khó khăn trong việc Trả lời Câu hỏi Trắc nghiệm về Code

Jaromir Savelka1
a, Arav Agarwal1
b, Christopher Bogart1
c và Majd Sakr1
d
1Trường Khoa học Máy tính, Đại học Carnegie Mellon, Pittsburgh, PA, USA

Từ khóa: Trả lời câu hỏi trắc nghiệm, MCQ, lập trình cơ bản và trung cấp, phân tích code, transformer được huấn luyện trước sinh tạo, GPT, khóa học Python, đánh giá kiến thức lập trình, ChatGPT, Codex, GitHub Copilot, AlphaCode

Tóm tắt: Chúng tôi phân tích hiệu quả của ba mô hình transformer được huấn luyện trước sinh tạo (GPT) trong việc trả lời các bài đánh giá câu hỏi trắc nghiệm (MCQ), thường bao gồm các đoạn code ngắn, từ các khóa học lập trình cơ bản và trung cấp ở cấp độ sau trung học. Công nghệ mới nổi này khuấy động vô số cuộc thảo luận về những ứng dụng tiềm năng (ví dụ: tạo bài tập, giải thích code) cũng như việc sử dụng sai mục đích trong giáo dục lập trình (ví dụ: gian lận). Tuy nhiên, khả năng của các mô hình GPT và những hạn chế của chúng trong việc lý luận và/hoặc phân tích code trong các môi trường giáo dục vẫn chưa được khám phá đầy đủ. Chúng tôi đánh giá một số mô hình GPT của OpenAI trên các bài đánh giá MCQ hình thành và tổng kết từ ba khóa học Python (530 câu hỏi). Chúng tôi phát hiện rằng các MCQ chứa đoạn code không được trả lời thành công như những câu hỏi chỉ chứa ngôn ngữ tự nhiên. Trong khi các câu hỏi yêu cầu điền vào chỗ trống trong code hoặc hoàn thành câu phát biểu bằng ngôn ngữ tự nhiên về đoạn code được xử lý khá thành công, các MCQ yêu cầu phân tích và/hoặc lý luận về code (ví dụ: điều gì đúng/sai về đoạn code, hoặc đầu ra của nó là gì) dường như là thách thức nhất. Những phát hiện này có thể được các nhà giáo dục tận dụng để điều chỉnh các phương pháp giảng dạy và đánh giá trong các khóa học lập trình, để GPT trở thành một trợ lý có giá trị cho người học thay vì nguồn gây nhầm lẫn và/hoặc trở ngại tiềm tàng trong quá trình học tập.

## 1 GIỚI THIỆU

Bài báo này phân tích hiệu quả của các transformer được huấn luyện trước sinh tạo (GPT), cụ thể là các mô hình text-davinci-*, trong việc xử lý các bài đánh giá câu hỏi trắc nghiệm (MCQ), thường bao gồm các đoạn code nhỏ, từ các khóa học lập trình cơ bản và trung cấp. Chúng tôi đã thu thập thủ công một tập dữ liệu lớn gồm 530 MCQ từ ba khóa học Python hiện có. Sử dụng kết hợp của khớp mẫu đơn giản và sắp xếp thủ công, chúng tôi đã tổ chức các câu hỏi thành các danh mục có ý nghĩa theo loại của chúng (ví dụ: câu hỏi đúng/sai, hoặc câu hỏi về đầu ra của đoạn code được cung cấp). Chúng tôi phân tích hiệu suất của các mô hình GPT qua các danh mục để xác định xem các câu hỏi thuộc loại nhất định có được xử lý thành công hơn so với các loại câu hỏi khác không. Chúng tôi cũng so sánh mô hình InstructGPT text-davinci-001 cũ hơn với các mô hình GPT-3.5 text-davinci-002 và text-davinci-003 gần đây hơn để đánh giá tốc độ cải thiện đã đạt được trong vài năm qua.

Đã có một sự bùng nổ chú ý của công chúng đối với tác động tiềm tàng của các mô hình GPT đối với giáo dục do việc phát hành gần đây ChatGPT của OpenAI. Ví dụ, công cụ này đã bị chặn bởi các trường công lập thành phố New York (Elsen-Rooney, 2023) vì nó có thể cho phép học sinh đạo văn và cung cấp nội dung không phù hợp hoặc không chính xác. Các trường đại học cũng đã phản ứng, điều chỉnh bài tập (Huang, 2023) và tìm kiếm các công cụ như GPTZero để phát hiện văn bản được tạo bởi các công cụ AI (Bowman, 2023). OpenAI đã phát hành một công cụ tương tự. Tuy nhiên, độ tin cậy của các công cụ này chưa được kiểm tra kỹ lưỡng.

Các giảng viên lập trình cũng như các nhà giáo dục CS nói chung đã nhạy cảm với sự phát triển này thậm chí còn sớm hơn. Các mô hình ngôn ngữ lớn, chẳng hạn như GPT, có thể tạo ra code chương trình máy tính (tức là thực hiện tổng hợp chương trình máy tính) với mức độ thành công cao. Chúng cũng có thể giải thích code chương trình máy tính bằng thuật ngữ ngôn ngữ tự nhiên. Gần đây, một số công cụ tạo code chương trình máy tính đã được phát hành. Trong số này, những công cụ nổi bật nhất là Codex của OpenAI (Chen et al., 2021), AlphaCode của DeepMind (Li et al., 2022), và CodeWhisperer của Amazon (Ankur và Atul, 2022). GitHub's Copilot (một phiên bản của Codex) tích hợp thuận tiện với các IDE, chẳng hạn như Visual Studio Code, và do đó đã thu hút nhiều sự chú ý. Microsoft gọi Copilot là "Lập trình viên AI cặp đôi của bạn" (tham chiếu đến lập trình cặp đôi (Beck, 2000; McDowell et al., 2002)). Vì nó có sẵn miễn phí cho sinh viên và nhà giáo dục, không thể tránh khỏi việc người học sẽ sử dụng nó để hoàn thành bài tập và bài đánh giá khóa học của họ. Tương tự, không có rào cản kỹ thuật hoặc chi phí nào để sử dụng ChatGPT, có thể được tận dụng để tạo ra câu trả lời cho các câu hỏi MCQ, trong số nhiều thứ khác.

Để điều tra cách các mô hình GPT xử lý các bài đánh giá MCQ của các loại khác nhau trong bối cảnh giáo dục lập trình, chúng tôi đã phân tích các câu hỏi nghiên cứu sau:
• Có sự khác biệt giữa cách các mô hình GPT xử lý thành công các câu hỏi chỉ chứa ngôn ngữ tự nhiên và những câu hỏi cũng chứa các đoạn code máy tính không?
• Có những loại MCQ cụ thể nào thách thức hơn đối với các mô hình GPT so với các loại MCQ khác không?

Bằng cách thực hiện công việc này, chúng tôi cung cấp những đóng góp sau đây cho cộng đồng nghiên cứu giáo dục CS. Theo hiểu biết của chúng tôi, đây là nghiên cứu toàn diện đầu tiên:
• Đánh giá hiệu suất của các mô hình GPT trên các bài đánh giá kiểu MCQ bao gồm các đoạn code, qua các loại câu hỏi khác nhau như vậy.
• Đặt nền tảng có hệ thống cho các cuộc thảo luận về việc sử dụng phù hợp các mô hình GPT trong các lớp học lập trình bằng cách cung cấp phân tích định lượng về khả năng và hạn chế của các mô hình trong việc xử lý code máy tính.

## 2 Ví dụ Động lực

Xem xét script Python dưới đây yêu cầu người dùng nhập một giá trị dự kiến sẽ là một số. Giá trị được nhập có kiểu str được chuyển thành int và chia cho độ dài của input thô (str). Lưu ý rằng code bảo vệ chống lại khả năng xảy ra ZeroDivisionError, điều này thực sự không thể xảy ra, như được giải thích bên dưới. Tuy nhiên, điều này có khả năng làm nhầm lẫn các mô hình GPT khi trả lời câu hỏi về đoạn code này.

```python
try:
    value = input("Enter a value: ")
    print(int(value) / len(value))
except ZeroDivisionError:
    print("Very bad input...")
```

Nếu người dùng nhập 22, thì đầu ra của script sẽ là 11.0 (tức là 22 / 2). Như được hiển thị trong Hình 1, nếu ai đó cung cấp cho ChatGPT (một trong những mô hình GPT-3.5 tiên tiến nhất) đoạn code và hỏi, "đầu ra sẽ là gì nếu người dùng nhập 0," (để ChatGPT chọn từ "A. 0.0" hoặc "B. Very bad input..."), câu trả lời được cung cấp là "B. Very bad input..." Tất nhiên, đây là câu trả lời không chính xác vì độ dài của chuỗi "0" là 1 và, do đó, đầu ra là 0.0 (như được hiển thị trong Hình 1).

Một học viên con người mắc lỗi này có thể bị nghi ngờ có một số hiểu lầm quan trọng. Thứ nhất, việc chọn tùy chọn "B. Very bad input..." sẽ dễ hiểu hơn nếu biến value không được đặt trong lệnh gọi hàm len(). Trong trường hợp đó, có thể giả định rằng người học đơn giản là không nhận ra rằng đầu ra của lệnh gọi hàm input() là str và giả định nó là int thay thế. Tuy nhiên, việc áp dụng hàm len() cho int sẽ dẫn đến TypeError được đưa ra. Do đó, input duy nhất lý thuyết có thể gây ra ZeroDivisionError sẽ là chuỗi rỗng. Tuy nhiên, ngay cả input đó cũng sẽ không dẫn đến lỗi cụ thể đó vì nó sẽ thất bại khi cố gắng chuyển biến value thành int (ValueError) sẽ xảy ra trước phép chia. Nhìn chung, một học viên con người chọn câu trả lời "B. Very bad input..." thay vì "A. 0.0" đúng sẽ rõ ràng thể hiện sự thiếu hiểu biết về hoạt động của đoạn code đơn giản này.

Hình 1 hiển thị đầu ra của ChatGPT khi được yêu cầu giải thích đoạn code từng dòng. Thú vị là, lời giải thích là chính xác, bao gồm cả dòng diễn ra phép chia. Đối với câu lệnh trên dòng đó, nó tuyên bố rằng: "[nó] lấy giá trị input và đầu tiên chuyển đổi nó thành số nguyên bằng hàm int(), sau đó chia nó cho độ dài của giá trị input bằng hàm len()." Hơn nữa, Hình 1 cũng hiển thị đầu ra của ChatGPT khi được yêu cầu tạo code Python có cùng chức năng như đoạn code được cung cấp. Từ mô tả ngôn ngữ tự nhiên, ChatGPT tạo ra code Python chính xác với hành vi được chỉ định.

Trong ví dụ này, một mô hình GPT có khả năng giải thích chính xác hành vi (thực thi) của một chương trình máy tính ở cấp độ cục bộ (tức là từng dòng). Nó cũng có khả năng tạo ra chương trình máy tính từ mô tả ngôn ngữ tự nhiên. Tuy nhiên, nó thất bại một cách nspectacular trong việc trả lời các câu hỏi đơn giản về chính chương trình đó. Điều này khá có thể trái ngược hoàn toàn với một học viên con người điển hình. Một học viên có khả năng viết độc lập chương trình từ mô tả ngôn ngữ tự nhiên cũng như giải thích chính xác việc thực thi từng dòng, khá có thể sẽ ở vị trí có thể trả lời những câu hỏi như vậy một cách dễ dàng.

## 3 CÔNG VIỆC LIÊN QUAN

Trong công việc trước đây, chúng tôi đã đánh giá khả năng của một mô hình GPT (text-davinci-003), để vượt qua một tập đa dạng các công cụ đánh giá, bao gồm MCQ, trong bối cảnh thực tế của các khóa học lập trình đầy đủ (Savelka et al., 2023). Chúng tôi phát hiện rằng các mô hình GPT hiện tại không có khả năng vượt qua toàn bộ phổ đánh giá thường có trong một khóa học lập trình Python (dưới 70% ngay cả trên các module cấp độ đầu); nhưng một ứng dụng đơn giản của các mô hình này có thể cho phép người học đạt được một phần không tầm thường của tổng điểm có sẵn (trên 55%) trong các khóa học cơ bản và trung cấp như nhau. Chúng tôi quan sát thấy rằng một hạn chế quan trọng của các mô hình GPT là cuộc đấu tranh rõ ràng của chúng với các hoạt động yêu cầu chuỗi các bước lý luận, và rằng dường như có sự khác biệt về tỷ lệ thành công giữa các MCQ chứa đoạn code và những câu hỏi không có (Savelka et al., 2023). Trong bài báo này, chúng tôi khám phá thêm hiện tượng này, tập trung vào việc khám phá các thuộc tính chi tiết hơn của MCQ thách thức đối với các mô hình GPT để xử lý.

Theo hiểu biết của chúng tôi, không có nghiên cứu nào khác về hiệu suất của GPT trên các MCQ từ lĩnh vực lập trình. Có công việc đánh giá hiệu suất trên các tập dữ liệu MCQ từ các lĩnh vực khác; trong nhiều trường hợp, công cụ này làm tốt hơn so với cơ hội ngẫu nhiên; đôi khi thậm chí đủ tốt để vượt qua một bài kiểm tra. Ví dụ, Robinson et al. áp dụng InstructGPT (Ouyang et al., 2022) và Codex cho các tập dữ liệu OpenBookQA (Mihaylov et al., 2018), StoryCloze (Mostafazadeh et al., 2016), và RACE-m (Lai et al., 2017) tập trung vào lý luận đa bước, recall, và hiểu đọc, báo cáo độ chính xác 77.4-89.2% (Robinson et al., 2022). Trong một số trường hợp, GPT có thể tạo code khi được áp dụng cho các bài tập lập trình trong các khóa học giáo dục đại học. Drori và Verma đã sử dụng Codex để viết các chương trình Python để giải quyết 60 MCQ đại số tuyến tính tính toán, báo cáo độ chính xác 100% (Drori và Verma, 2021). Những người khác đã sử dụng các mô hình GPT để giải quyết các kỳ thi dựa trên MCQ khác nhau, bao gồm Kỳ thi Cấp phép Y khoa Hoa Kỳ (USMLE), với độ chính xác khoảng 50% (Kung et al., 2022; Gilson et al., 2022; Li´evin et al., 2022), Kỳ thi Luật sư Đa bang (MBE) (Bommarito II và Katz, 2022), và kỳ thi Quy định (REG) của Viện Kế toán Công chứng Hoa Kỳ (AICPA) (Bommarito et al., 2023).

Mặc dù các MCQ liên quan đến lập trình chưa được nghiên cứu trực tiếp, một số nhà nghiên cứu trong các lĩnh vực liền kề đã nghiên cứu lý luận về các chủ đề chính thức tương tự. Mặc dù GPT thường có thể trả lời các câu hỏi về hệ thống và quy tắc, nó đặc biệt bị thách thức bởi các nhiệm vụ liên quan đến việc áp dụng chúng và lý luận về ý nghĩa của chúng trong các ví dụ mới. Hendryks et al. đã tạo ra tập dữ liệu bao gồm nhiều loại MCQ qua STEM, nhân văn và nghệ thuật, với GPT-3 thực hiện ở mức trên 50% cho các môn học như marketing và chính sách đối ngoại, nhưng dưới 30% cho các chủ đề như logic hình thức (Hendrycks et al., 2020). Họ phát hiện rằng mô hình thực hiện đặc biệt kém trong các môn học định lượng. Ví dụ, trong Toán cơ bản, họ lưu ý rằng GPT có thể trả lời các câu hỏi về thứ tự thao tác số học (ví dụ: phép nhân được thực hiện trước phép cộng), nó không thể trả lời chính xác các câu hỏi yêu cầu áp dụng khái niệm này. Họ cũng lưu ý rằng hiệu suất GPT không nhất thiết tương quan với mức độ nâng cao của chủ đề đối với con người, làm tốt hơn ở Toán đại học so với Toán cơ bản. Cuối cùng, họ lưu ý rằng GPT làm kém trong các bài kiểm tra lý luận pháp lý và đạo đức (Hendrycks et al., 2020).

Lu et al. đã nghiên cứu hiệu suất của các mô hình GPT trên một tập dữ liệu lớn gồm 21,208 MCQ về các chủ đề khoa học tự nhiên, khoa học xã hội và ngôn ngữ (Lu et al., 2022). Họ đã nhắc các mô hình tạo ra lời giải thích cùng với câu trả lời và báo cáo cải thiện độ chính xác 1-3% (74.04%). Trong công việc này, chúng tôi không áp dụng phương pháp này và, do đó, để lại không gian cho công việc tương lai vì nó có vẻ khá hứa hẹn và chắc chắn áp dụng được trong bối cảnh MCQ lập trình.

Có một khối lượng công việc liên quan ngày càng tăng về khả năng của các mô hình GPT trong việc giải quyết các nhiệm vụ lập trình bằng cách tạo code. Finnie-Ansley et al. đã đánh giá Codex trên 23 nhiệm vụ lập trình được sử dụng làm đánh giá tổng kết trong một khóa học lập trình CS1 (Finnie-Ansley et al., 2022). Denny et al. tập trung vào các hiệu ứng của kỹ thuật prompt khi áp dụng Copilot cho một tập hợp 166 bài tập từ kho lưu trữ CodeCheck có sẵn công khai (Denny et al., 2022). Bên ngoài bối cảnh giáo dục, đã có các nghiên cứu khám phá khả năng của GPT trong các nhiệm vụ lập trình cạnh tranh và phỏng vấn. Chen et al. đã phát hành tập dữ liệu HumanEval nơi Codex đạt tỷ lệ thành công 28.8% trong lần thử đầu tiên và 72.3% khi được phép 100 lần thử (Chen et al., 2021). Li et al. báo cáo hiệu suất AlphaCode của Deepmind trong các cuộc thi Codeforces, đạt xếp hạng 54.3% trong số 5,000 người tham gia (Li et al., 2022). Karmakar et al. báo cáo tỷ lệ vượt qua 96% cho Codex trên tập dữ liệu 115 bài toán lập trình từ HackerRank (Karmakar et al., 2022). Nguyen và Nadi báo cáo hiệu quả của Copilot trên các bài toán LeetCode, đạt độ chính xác 42% (Nguyen và Nadi, 2022).

Code chương trình làm nhiều hơn việc kiểm soát thực thi máy tính; nó cũng, một số người cho rằng chủ yếu, phục vụ như giao tiếp giữa các nhà phát triển (Knuth, 1984). Vì GPT là một mô hình dự đoán văn bản được huấn luyện trên code trong bối cảnh thảo luận của con người về nó, biểu diễn code của mô hình có thể nắm bắt ý định thiết kế của code mạnh mẽ hơn so với các thuộc tính chính thức của code. Ví dụ, công việc từ nhiều nghiên cứu cho thấy rằng các mô hình diễn giải code phụ thuộc rất nhiều vào tên hàm và biến đầu vào (Mohammadkhani et al., 2022; Yang et al., 2022). Mặc dù các mô hình như GPT không được huấn luyện để mô phỏng thực thi code, chúng có thể trong nhiều trường hợp tạo ra code dựa trên mô tả ngôn ngữ tự nhiên về ý định của code. Các nhà nghiên cứu đã báo cáo thành công khác nhau trong việc tạo code để đáp ứng các bài tập lập trình, từ thành công 100% của Codex trong việc tạo các chương trình đại số tuyến tính tính toán Python (Drori và Verma, 2021), đến 78.3% trên một số bài toán lập trình CS1 (Finnie-Ansley et al., 2022), đến 79% trên kho lưu trữ CodeCheck của các bài toán lập trình Python (Denny et al., 2022).

Các nhà nghiên cứu đã xác định các quá trình nhận thức riêng biệt liên quan đến lập trình. Mô tả các loại học tập cần thiết để dạy lập trình, Robins et al. tuyên bố rằng ví dụ kiến thức về cách các cấu trúc lập trình hoạt động là khác biệt nhận thức so với chiến lược hoặc kế hoạch về cách xây dựng một chương trình; và hiểu biết và tạo ra lập trình là các quá trình tinh thần riêng biệt phải được dạy. Kỹ năng lập trình là sự pha trộn của các quá trình nhận thức liên quan; không có gì đáng ngạc nhiên khi một mô hình sinh tạo sẽ không bắt chước tất cả các quá trình này một cách bình đẳng (Robins et al., 2003).

Khả năng của GPT trong việc trả lời các câu hỏi dự định làm đánh giá giáo dục tự nhiên đặt ra câu hỏi về việc sử dụng nó để gian lận. Biderman và Raff lưu ý rằng các giải pháp GPT có thể tránh được việc phát hiện đạo văn bằng các công cụ tương tự code như MOSS (Biderman và Raff, 2022). Mặt khác, Wermelinger lưu ý rằng trong khi các giải pháp do Copilot tạo ra thường có thể vượt qua một số bài kiểm tra, chúng không vượt qua đủ để có điểm đạt trong một bài tập điển hình; anh ta kết luận rằng Copilot có thể là một bước đệm hữu ích hướng tới việc giải quyết các bài toán CS1, nhưng bên ngoài các bài tập người mới bắt đầu rập khuôn rất phổ biến, đóng góp đáng kể của người học vẫn được yêu cầu (Wermelinger, 2023). Becker et al. bao gồm một cuộc thảo luận rộng hơn về các cơ hội và thách thức do các công cụ tạo code đặt ra (Becker et al., 2022).

## 4 TẬP DỮ LIỆU

Chúng tôi đã thu thập thủ công các bài tập đánh giá MCQ từ ba khóa học lập trình Python. Python Essentials - Part 1 (Cơ bản) (PE1) nhằm hướng dẫn người học từ trạng thái hoàn toàn mù chữ lập trình đến mức độ kiến thức lập trình cho phép họ thiết kế, viết, gỡ lỗi và chạy các chương trình được mã hóa bằng ngôn ngữ Python. Khóa học bao gồm bốn đơn vị nội dung và một bài kiểm tra hoàn thành (tóm tắt). Các đơn vị bao gồm (i) giới thiệu về Python và lập trình máy tính, (ii) kiểu dữ liệu biến, I/O cơ bản, các phép toán và toán tử cơ bản, (iii) giá trị boolean, vòng lặp có điều kiện, danh sách, toán tử logic và bitwise, và (iv) hàm, tuple, từ điển, xử lý dữ liệu và ngoại lệ.

Python Essentials - Part 2 (Trung cấp) (PE2) tập trung vào các khía cạnh nâng cao hơn của lập trình Python, bao gồm modules, packages, ngoại lệ, xử lý file, lập trình hướng đối tượng. Tương tự như PE1, khóa học được tổ chức thành bốn đơn vị nội dung và một bài kiểm tra hoàn thành (tóm tắt). Các đơn vị khóa học là (i) modules, packages, và pip, (ii) chuỗi, phương thức chuỗi và danh sách, và ngoại lệ, (iii) lập trình hướng đối tượng, và (iv) khác.

Cuối cùng, Practical Programming with Python (PPP) nhấn mạnh trải nghiệm thực hành với các cấu trúc Python cơ bản và tiếp xúc với các công cụ phát triển phần mềm, thực tiễn và ứng dụng thế giới thực. Khóa học bao gồm tám đơn vị bao gồm (i) Python cơ bản và giới thiệu về hàm, (ii) luồng điều khiển, chuỗi, đầu vào và đầu ra, (iii) cấu trúc dữ liệu Python, (iv) lập trình hướng đối tượng, (v) phát triển phần mềm, (vi) thao tác dữ liệu, (vii) quét web và xử lý tài liệu văn phòng, và (viii) phân tích dữ liệu.

Trong PE1 và PE2, các đánh giá hình thành được gọi là quiz trong khi các đánh giá tổng kết được gọi là test. Các test xác định xem người học có vượt qua khóa học hay không trong khi quiz có nghĩa là thực hành. Các MCQ thường bao gồm các đoạn code nhỏ để người học lý luận về. Từ hai khóa học, chúng tôi đã thu thập 297 câu hỏi (179 có đoạn code). PPP sử dụng các hoạt động inline kiểu MCQ làm đánh giá hình thành và test làm đánh giá tổng kết. Từ khóa học này, chúng tôi đã thu thập 233 MCQ (144 với đoạn code). Bảng 1 có thêm chi tiết.

Chúng tôi đã sử dụng khớp mẫu đơn giản kết hợp với sắp xếp thủ công như bước thứ hai để tổ chức các MCQ thành một số danh mục. Sự phân biệt đầu tiên được thực hiện giữa MCQ có code và MCQ không có code. Để một MCQ được coi là có code, một trong hai điều sau phải đúng:
• Trong nội dung câu hỏi phải có ít nhất một dòng hoàn toàn dành riêng cho code máy tính.
• Các lựa chọn là các biểu thức code máy tính.

Đề cập inline đến tên của hàm hoặc biến không được coi là đủ để một MCQ được coi là có code.

Sự phân biệt thứ hai được thực hiện theo các dòng sau, tập trung vào cú pháp tổng thể của những gì người viết câu hỏi yêu cầu học sinh làm:

• Đúng/Sai
Người học được yêu cầu đánh giá tính đúng đắn của một câu phát biểu duy nhất. Ví dụ:
Các nhà phát triển viết code riêng lẻ không được mong đợi áp dụng tiêu chuẩn code.
A. Đúng
B. Sai

Đánh giá biểu thức sau và xác định xem nó là Đúng hay Sai.
2 + 2 != 2 * 2
A. Đúng
B. Sai

• Xác định Câu phát biểu Đúng/Sai
Người học được yêu cầu chọn một hoặc nhiều lựa chọn trả lời đúng hoặc sai. Lưu ý rằng điều này khác với các câu hỏi Đúng/Sai (danh mục trước). Ví dụ:
Câu phát biểu nào sau đây là sai?
A. Module pandas cung cấp một số phương thức liên quan đến CSV.
B. Python có gói XML tích hợp với một số module để phân tích XML.
C. Định dạng dữ liệu JSON có cú pháp để biểu diễn tất cả các loại cấu trúc dữ liệu Python.
D. Python có module csv tích hợp chứa các phương thức để đọc và ghi vào file CSV.

Nhìn vào đoạn code và chọn một trong các câu phát biểu sau đây là đúng:
nums = []
vals = nums[:]
vals.append(1)
A. nums dài hơn 'vals'
B. vals dài hơn nums
C. nums và vals có cùng độ dài

• Hoàn thành Câu phát biểu.
Người học được yêu cầu hoàn thành một câu phát biểu. Ví dụ:
Toán tử '**':
A. thực hiện phép nhân trùng lặp
B. không tồn tại
C. thực hiện phép lũy thừa

Liên kết phía bên phải có nghĩa là biểu thức sau:
1 ** 2 ** 3
sẽ được đánh giá:
A. từ phải sang trái
B. theo thứ tự ngẫu nhiên
C. từ trái sang phải

• Đầu ra
Người học được yêu cầu xác định lựa chọn tương ứng với đầu ra của một đoạn code đã cho. Danh mục này chỉ áp dụng cho các câu hỏi có code. Ví dụ:
Đầu ra của đoạn code sau là gì nếu người dùng nhập hai dòng chứa 2 và 4 tương ứng?
x = int(input())
y = int(input())
print(x + y)
A. 2
B. 24
C. 6

Đầu ra của đoạn code sau là gì?
my_list_1 = [1, 2, 3]
my_list_2 = []
for v in my_list_1:
    my_list_2.insert(0, v)
print(my_list_2)
A. [1, 2, 3]
B. [1, 1, 1]
C. [3, 3, 3]
D. [3, 2, 1]

• Điền vào Chỗ trống
Người học được yêu cầu điền vào đoạn code bằng cách chọn lựa chọn phù hợp làm câu trả lời. Danh mục này chỉ áp dụng cho các câu hỏi có code. Ví dụ:
Điền vào chỗ trống của định nghĩa hàm is_negative được hiển thị bên dưới, để hàm trả về True khi đối số được cung cấp cho num là số âm và trả về False trong trường hợp khác.
def is_negative(num):
    return _________________
A. not (num > 0)
B. num > 0
C. num <= 0
D. num < 0

Đoạn code sau đây nên mở file myfile và gán các dòng cho biến all_lines. Tùy chọn nào dưới đây nên được sử dụng để điền vào chỗ trống?
with __________________________
    all_lines = file.readlines()
A. open("myfile",'r') as file:
B. "myfile" in open as file:
C. with open "myfile" as file:

• Khác
Bất kỳ MCQ nào không thuộc về bất kỳ danh mục nào ở trên. Ví dụ:
Đoạn code dưới đây sẽ in 'X' bao nhiêu lần?
for i in range(1, 7):
    for j in range(2, 6):
        print('X')
A. 24
B. 28
C. 35

Lưu ý rằng ví dụ trên có liên quan chặt chẽ đến các câu hỏi hỏi về đầu ra của đoạn code. Tuy nhiên, có sự khác biệt tinh tế vì câu hỏi này không hỏi trực tiếp đầu ra là gì.

Cho đoạn code được trình bày trong đoạn code bên dưới, giá trị của palindromes[1] là gì?
palindromes = ['pop', 'noon', 'madam']
A. 'pop'
B. 'noon'
C. 'p'
D. 'madam'
E. 'o'

Hình 2 hiển thị phân phối của các MCQ vào các danh mục riêng lẻ. Các MCQ hỏi về đầu ra của đoạn code cũng như các MCQ tập trung vào điền vào chỗ trống trong đoạn code không có mặt trong các MCQ không có code. Điều này có thể mong đợi được do bản chất của những câu hỏi đó. Các MCQ có code khá bị chi phối bởi các câu hỏi hỏi về đầu ra của đoạn code cũng như với các câu hỏi loại khác. Nếu không, phân phối tương đối đồng đều. Các câu hỏi điền vào chỗ trống hiếm. Phân phối của các câu hỏi không có code gần như đồng đều.

## 5 CÁC MÔ HÌNH

Mô hình GPT gốc (Radford et al., 2018) là một transformer chỉ decoder 12 lớp (Vaswani et al., 2017) với các đầu self-attention được che dấu. Khả năng cốt lõi của nó là fine-tuning trên một nhiệm vụ downstream. Mô hình GPT-2 (Radford et al., 2019) phần lớn tuân theo các chi tiết của mô hình GPT gốc với một vài sửa đổi, chẳng hạn như layer normalization được chuyển đến đầu vào của mỗi sub-block, layer normalization bổ sung sau block self-attention đầu tiên, và một khởi tạo được sửa đổi. So với mô hình gốc, nó hiển thị khả năng học đa nhiệm vụ đáng chú ý (Radford et al., 2019). Thế hệ tiếp theo của các mô hình GPT (Brown et al., 2020) sử dụng gần như cùng kiến trúc với GPT-2. Sự khác biệt duy nhất là nó sử dụng các mẫu attention dense và locally banded sparse luân phiên trong các lớp của transformer. Trọng tâm chính của Brown et al. là nghiên cứu sự phụ thuộc của hiệu suất và kích thước mô hình nơi tám mô hình có kích thước khác nhau được huấn luyện (từ 125 triệu đến 175 tỷ tham số). Mô hình lớn nhất thường được gọi là GPT-3. Thuộc tính thú vị của các mô hình này là chúng dường như là những người học zero-shot và few-shot rất mạnh. Khả năng này dường như cải thiện với kích thước tăng của mô hình (Brown et al., 2020).

Chúng tôi chủ yếu quan tâm đến hiệu suất của text-davinci-003, một trong những mô hình GPT tiên tiến nhất được OpenAI cung cấp. Mô hình text-davinci-003 xây dựng dựa trên text-davinci-002 trước đó, mà lần lượt dựa trên code-davinci-002 (tập trung vào các nhiệm vụ hoàn thành code). Để đánh giá tốc độ cải thiện trong vài năm gần đây, chúng tôi so sánh hiệu suất của text-davinci-003 với text-davinci-002 cũng như với mô hình InstructGPT thế hệ trước (text-davinci-001). Gần đây, OpenAI cũng đã phát hành gpt-3.5-turbo mà theo báo cáo phù hợp với hiệu suất của text-davinci-003 với một phần mười chi phí.

Chúng tôi đặt temperature thành 0.0, tương ứng với không có tính ngẫu nhiên. Temperature càng cao thì đầu ra càng sáng tạo nhưng cũng có thể ít thực tế hơn. Chúng tôi đặt max_tokens thành 500 (một token đại khái tương ứng với một từ). Tham số này kiểm soát độ dài tối đa của đầu ra. Chúng tôi đặt top_p thành 1, như được khuyến nghị khi temperature được đặt thành 0.0. Tham số này liên quan đến temperature và cũng ảnh hưởng đến tính sáng tạo của đầu ra. Chúng tôi đặt frequency_penalty thành 0, cho phép lặp lại bằng cách đảm bảo không có hình phạt nào được áp dụng cho việc lặp lại. Cuối cùng, chúng tôi đặt presence_penalty thành 0, đảm bảo không có hình phạt nào được áp dụng cho các token xuất hiện nhiều lần trong đầu ra.

## 6 THIẾT KẾ THỰC NGHIỆM

Để kiểm tra hiệu suất của ba mô hình text-davinci-*, chúng tôi gửi các MCQ từng cái một bằng thư viện Python openai là một wrapper cho REST API của OpenAI. Chúng tôi nhúng mỗi câu hỏi trong template prompt được hiển thị trong Hình 3. Văn bản của phần mở đầu prompt được lấy cảm hứng từ ví dụ QA của OpenAI. Token {{question}} được thay thế bằng văn bản câu hỏi. Token {{choices}} được thay thế bằng các câu trả lời ứng viên nơi mỗi câu được đặt trên một dòng đơn được đi trước bởi một chữ cái viết hoa. Mỗi mô hình trả về một hoặc nhiều lựa chọn làm hoàn thành prompt, sau đó được so sánh với câu trả lời tham chiếu. Đối với PE1 và PE2, chúng tôi để các câu trả lời đúng một phần là không chính xác, theo hướng dẫn đánh giá của người tạo khóa học. Trong PPP, luôn có chính xác một câu trả lời đúng.

Như đường cơ sở, chúng tôi sử dụng một mô hình đơn giản chọn câu trả lời có độ tương tự Jaccard cao nhất với câu hỏi. Trong trường hợp hòa, câu trả lời dài nhất được chọn. Độ tương tự Jaccard là một trong những thước đo đơn giản nhất về độ tương tự văn bản. Do đó, nó là ứng viên lý tưởng cho đường cơ sở vì nó cho phép phát hiện tỷ lệ câu hỏi trong các danh mục tương ứng của chúng có thể được giải quyết bằng heuristic đơn giản nhưng hợp lý này. Những MCQ như vậy có thể đặt ra rất ít thách thức cho các mô hình GPT.

Chúng tôi báo cáo tỷ lệ của các câu trả lời đúng (tức là độ chính xác) cho mỗi mô hình trên mỗi danh mục MCQ. Chúng tôi tập trung cụ thể vào sự khác biệt trong hiệu suất của mô hình text-davinci-003 trên các MCQ chứa đoạn code (có code) so với các MCQ không có (không có code). Chúng tôi cũng quan tâm đến sự khác biệt giữa hiệu suất trên các MCQ dựa trên hoàn thành (Hoàn thành Câu phát biểu và Điền vào Chỗ trống) so với phần còn lại. Điều này là do các loại câu hỏi này không quá xa so với mục tiêu pretraining và, do đó, kỳ vọng là hiệu suất của các mô hình nên cao hơn trên các loại này. Để kiểm tra ý nghĩa thống kê, chúng tôi sử dụng một kiểm định hai tỷ lệ độc lập đơn giản là một kiểm định giả thuyết thống kê được sử dụng để xác định xem hai tỷ lệ có khác nhau với nhau không.

## 7 KẾT QUẢ

Bảng 2 báo cáo kết quả của các thực nghiệm của chúng tôi. Thứ nhất, như mong đợi, cả ba mô hình GPT đều rõ ràng vượt trội so với đường cơ sở độ tương tự Jaccard đơn giản. Mô hình text-davinci-003 dường như thực hiện tốt nhất (65.5% tổng thể) với biên độ nhỏ so với text-davinci-002 (64.5% tổng thể). Hiệu suất của text-davinci-001 dường như thấp hơn nhiều so với hai mô hình khác. Điều này có thể mong đợi được. Trong khi text-davinci-002 là tiền nhiệm trực tiếp của text-davinci-003 (do đó, sự khác biệt nhỏ) thì text-davinci-001 khá xa với hai mô hình. Bước đột phá lớn trong khả năng của OpenAI GPT-3 trong việc xử lý code máy tính là Codex (code-davinci-002) (Chen et al., 2021) là tiền nhiệm trực tiếp của text-davinci-002.

Dường như có sự khác biệt rõ ràng giữa hiệu suất của text-davinci-003 có khả năng nhất trên các MCQ chứa đoạn code (59.5% tổng thể) so với những câu hỏi không có (77.9% tổng thể). Sự khác biệt này có ý nghĩa thống kê (p < 0.0001). Điều này có thể mong đợi được vì sự kết hợp của code và ngôn ngữ tự nhiên có thể tạo thành (trung bình) đầu vào phức tạp hơn so với chỉ ngôn ngữ tự nhiên. Ngoài ra, hoàn toàn có thể trong bối cảnh cụ thể của chúng tôi, các câu hỏi có code (trung bình) khó hơn so với các câu hỏi không có code.

Cũng dường như có sự khác biệt rõ ràng giữa hiệu suất của text-davinci-003 trên các MCQ hướng hoàn thành (87.1%) và phần còn lại (60.1%). Sự khác biệt này có ý nghĩa thống kê (p < 0.0001). Vì các mô hình GPT chủ yếu tập trung vào hoàn thành prompt, dù là văn bản hay code máy tính, phát hiện này cũng như mong đợi.

## 8 THẢO LUẬN

Kết quả thực nghiệm của chúng tôi cho thấy rằng thực sự có sự khác biệt giữa cách các mô hình GPT xử lý thành công các câu hỏi chỉ chứa ngôn ngữ tự nhiên và những câu hỏi cũng chứa các đoạn code máy tính (RQ1). Tạm thời, chúng tôi có thể kết luận rằng việc bao gồm đoạn code trong MCQ làm cho câu hỏi thách thức hơn đối với các mô hình GPT để xử lý. Kết luận này được hỗ trợ bởi hiệu suất thấp hơn một cách phổ biến trên các MCQ có code qua tất cả các loại phụ, tức là Đúng/Sai, Xác định Câu phát biểu Đúng/Sai, Hoàn thành Câu phát biểu và Khác. Nguyên nhân gốc rễ của sự bất đồng này có thể là một hoặc nhiều điều sau: (i) các mô hình GPT hơi hạn chế hơn đối với việc xử lý các chương trình máy tính so với ngôn ngữ tự nhiên; (ii) các mô hình GPT gặp khó khăn với sự kết hợp của các loại biểu thức khác nhau (tức là ngôn ngữ tự nhiên và code); và/hoặc (iii) các câu hỏi có đoạn code vốn khó hơn.

Trong khi độ khó lớn hơn của các câu hỏi có code chắc chắn có thể là một yếu tố, có vẻ như các mô hình GPT đôi khi gặp khó khăn trong việc trả lời các câu hỏi có code mà người ta có thể đánh giá là đơn giản. Ví dụ, xem xét MCQ sau:
Câu lệnh sau:
assert var == 0
A. có lỗi
B. sẽ dừng chương trình khi var != 0
C. không có hiệu lực
D. sẽ dừng chương trình khi var == 0

Câu trả lời của text-davinci-003 cho câu hỏi này là "D. sẽ dừng chương trình khi var == 0". Do đó, có vẻ như có những hạn chế nhất định trong khả năng của các mô hình GPT để trả lời các câu hỏi về code. Điều này hơi đáng ngạc nhiên nếu xem xét các khả năng được ghi chép tốt của các mô hình khi nói đến tạo ra hoặc giải thích các chương trình máy tính.

Kết quả cũng cho thấy rằng một số loại MCQ thách thức hơn so với những loại khác đối với các mô hình GPT (RQ2). Các câu hỏi liên quan đến tạo ra ngôn ngữ tự nhiên và/hoặc code dường như được xử lý với nhiều thành công hơn so với các loại câu hỏi khác. Điều này có thể mong đợi được vì các mô hình GPT chủ yếu tập trung vào hoàn thành prompt. Mặt khác, nó dẫn đến các tình huống hơi nghịch lý như tình huống được minh họa trong ví dụ động lực (Phần 2). Các mô hình có khả năng tạo ra code dựa trên mô tả ngôn ngữ tự nhiên, cũng như tạo ra ngôn ngữ tự nhiên giải thích việc thực thi code từng dòng. Tuy nhiên, bằng cách nào đó những khả năng này dường như không mở rộng đến lĩnh vực trả lời các câu hỏi cụ thể có chỉ hướng về code (thường khá đơn giản).

Chúng tôi giả thuyết rằng nghịch lý được mô tả ở trên có thể liên quan đến hiện tượng được mô tả bởi (Détienne và Bott, 2002). Họ chỉ ra rằng code chương trình phục vụ hai mục đích đồng thời: nó vừa là mô tả tường thuật về ý định của lập trình viên, vừa là một artifact kiểm soát việc thực thi máy tính. Theo đó, các lập trình viên con người duy trì và đồng bộ hóa ít nhất hai loại mô hình tinh thần của code, một mô hình chức năng nắm bắt mục đích mà chương trình được cho là đóng vai trò trong thế giới, và một mô hình cấu trúc cho phép mô phỏng tinh thần về dữ liệu và luồng điều khiển.

Vì các mô hình GPT được huấn luyện trên các corpus lớn bao gồm văn bản bằng ngôn ngữ tự nhiên cũng như code chương trình với nhận xét và tài liệu, chúng có thể có được các biểu diễn mạnh mẽ của mối quan hệ chức năng giữa code và ý định mà nó thể hiện. Các corpus huấn luyện có thể không chứa code với đầu ra hoặc nhật ký theo dõi việc thực thi của nó. Do đó, các mô hình có thể thiếu dữ liệu cần thiết để xây dựng biểu diễn của mô hình cấu trúc về chức năng của code. Điều này không có nghĩa là việc bao gồm các tài nguyên được đề cập vào corpus huấn luyện nhất thiết sẽ dẫn đến việc có được một mô hình như vậy. Điều này là do việc sử dụng hiệu quả của mô hình có thể yêu cầu khả năng mô phỏng việc thực thi của code, hoặc một phần của nó. Các mô hình ngôn ngữ lớn hiện tại, bao gồm GPT, không có khả năng này. Lưu ý rằng có một lĩnh vực nghiên cứu tích cực trong việc tăng cường các mô hình ngôn ngữ lớn với kỹ năng lý luận và cung cấp cho chúng khả năng sử dụng các công cụ, chẳng hạn như trình thông dịch Python (Mialon et al., 2023).

Có thể lập luận rằng việc xây dựng những mô hình tinh thần kết nối này về mục đích và hoạt động của code nên là một phần quan trọng của những gì giáo dục CS dạy. Những hạn chế cụ thể của các mô hình GPT cung cấp một lăng kính hữu ích để hiểu loại mô hình tinh thần nào chúng ta đang đánh giá trong các đánh giá lập trình giáo dục đại học điển hình. Có thể là các MCQ Đúng/Sai và Xác định Câu phát biểu Đúng/Sai có nhiều khả năng yêu cầu mô phỏng tinh thần về việc thực thi code. Một thí nghiệm để xác thực giả thuyết của chúng tôi có thể là phân loại MCQ theo trọng tâm của chúng vào (a) dự đoán hành vi thực tế, hoặc (b) suy luận ý định, và đo lường xem và cách hiệu suất của các mô hình GPT tương quan với phân loại này.

Có những cuộc tranh luận đang diễn ra về những thay đổi mà sự xuất hiện của các công cụ dựa trên GPT như ChatGPT hoặc GitHub Copilot sẽ gây ra cho nghề phát triển phần mềm cũng như giáo dục lập trình. Thứ nhất, có vẻ như không thể tránh khỏi rằng các công cụ sẽ trở thành một phần tích hợp và được chấp nhận trong quá trình phát triển phần mềm. Do đó, các lập trình viên tương lai có thể cần viết ít code hơn. Mặt khác, họ sẽ cần có thể xác thực code được tạo tự động, phát hiện thiếu sót và sửa chữa chúng một cách hiệu quả. Do đó, giáo dục lập trình có thể cần bỏ ưu tiên việc dạy người học cách viết code và bắt đầu nhấn mạnh các kỹ năng như xây dựng yêu cầu, gỡ lỗi, phân tích đánh đổi và tư duy phê phán.

Cuối cùng, các công cụ dựa trên GPT trình bày nhiều cơ hội để cải thiện các thực tiễn giảng dạy và đánh giá hiện tại trong các lớp học lập trình. Các thí nghiệm của chúng tôi cho thấy rằng các mô hình GPT có khả năng giải thích code bằng thuật ngữ đơn giản và dễ hiểu. Tương tự, chúng có khả năng tạo ra và hoàn thành code chương trình. Việc sử dụng khôn ngoan những khả năng này có thể dẫn đến nhiều công cụ và phương pháp giảng dạy mới cho người mới bắt đầu và người học nâng cao như nhau. Tuy nhiên, cũng có những mối đe dọa tiềm tàng. Việc sử dụng không đúng cách hoặc không có thông tin về các công cụ có thể dẫn đến sự cố vi phạm tính toàn vẹn học thuật (AIV) (tức là gian lận). Tương tự, việc phụ thuộc quá mức vào các công cụ dựa trên GPT có thể cản trở hơn là cải thiện quá trình học tập.

## 9 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Chúng tôi đã đánh giá các mô hình GPT text-davinci-* trên một tập hợp lớn gồm 530 MCQ, nhiều trong số đó chứa các đoạn code, từ ba khóa học lập trình Python. Độ chính xác tổng thể của mô hình text-davinci-003 có khả năng nhất được đo ở 65.5% (so với đường cơ sở độ tương tự Jaccard 23.4%). Trong khi hiệu suất như vậy là ấn tượng, dường như có một số hạn chế đáng chú ý. Trước hết, có vẻ như các MCQ chứa đoạn code hơi thách thức hơn (59.5%) đối với mô hình so với những câu hỏi không có code (77.9%). Ngoài ra, các MCQ yêu cầu hoàn thành câu hoặc điền vào chỗ trống dường như được xử lý thành công hơn nhiều (87.1%) so với các loại câu hỏi khác (60.1%). Do đó, khả năng của các mô hình GPT có vẻ hạn chế khi nói đến việc xử lý các MCQ về code máy tính yêu cầu lý luận vượt ra ngoài việc hoàn thành đơn thuần (56.6%).

Trong khi nghiên cứu của chúng tôi về hiệu suất của các mô hình GPT trên các loại MCQ đa dạng đã mang lại nhiều hiểu biết có giá trị, nó chịu vô số hạn chế và để lại nhiều chỗ cho sự cải thiện. Do đó, chúng tôi đề xuất một số hướng cho công việc tương lai: (i) phân tích thêm các hiệu ứng của prompt-tuning (ii) và/hoặc xây dựng prompt lặp lại; (iii) kiểm tra hiệu suất của các mô hình GPT trên các lĩnh vực khác, ví dụ toán cạnh tranh; (iv) phát triển một khung hệ thống để đánh giá toàn diện các khả năng và hạn chế của các mô hình GPT; và (v) nghiên cứu khả năng tích hợp hiệu quả các công cụ dựa trên GPT, ví dụ ChatGPT hoặc Copilot, vào giáo dục lập trình.

TÀI LIỆU THAM KHẢO

Ankur, D. và Atul, D. (2022). Giới thiệu Amazon CodeWhisperer, người bạn đồng hành coding được hỗ trợ bởi ML. AWS Machine Learning Blog. 24 tháng 6, 2022. https://aws.amazon.com/blogs/machine-learning/introducing-amazon-codewhisperer-the-ml-powered-coding-companion/.

Beck, K. (2000). Extreme programming explained: embrace change. Addison-Wesley professional.

Becker, B. A., Denny, P., Finnie-Ansley, J., Luxton-Reilly, A., Prather, J., và Santos, E. A. (2022). Programming is hard–or at least it used to be: Educational opportunities and challenges of ai code generation. arXiv preprint arXiv:abs/2212.01020.

Biderman, S. R. và Raff, E. (2022). Fooling moss detection with pretrained language models. Proceedings of the 31st ACM International Conference on Information & Knowledge Management.

Bommarito, J., Bommarito, M., Katz, D. M., và Katz, J. (2023). GPT as knowledge worker: A zero-shot evaluation of (AI) CPA capabilities. arXiv preprint arXiv:abs/2301.04408.

Bommarito II, M. và Katz, D. M. (2022). GPT takes the bar exam. arXiv preprint arXiv:abs/2212.14402.

Bowman, E. (2023). A college student created an app that can tell whether ai wrote an essay. NPR Technology. 9 tháng 1, 2023. https://www.npr.org/2023/01/09/1147549845.

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901.

Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., và Zaremba, W. (2021). Evaluating large language models trained on code. arXiv preprint arXiv:abs/2107.03374.

Denny, P., Kumar, V., và Giacaman, N. (2022). Conversing with Copilot: Exploring prompt engineering for solving cs1 problems using natural language. arXiv preprint arXiv:abs/2210.15157.

Drori, I. và Verma, N. (2021). Solving linear algebra by program synthesis. arXiv preprint arXiv:2111.08171.

Détienne, F. và Bott, F. (2002). Software design–cognitive aspects. Springer Verlag.

Elsen-Rooney, M. (2023). NYC education department blocks ChatGPT on school devices, networks. Chalkbeat New York. 3 tháng 1, 2023.

Finnie-Ansley, J., Denny, P., Becker, B. A., Luxton-Reilly, A., và Prather, J. (2022). The robots are coming: Exploring the implications of OpenAI Codex on introductory programming. In Australasian Computing Education Conference, ACE '22, page 10–19, New York, NY, USA. Association for Computing Machinery.

Gilson, A., Safranek, C. W., Huang, T., Socrates, V., Chi, L. S., Taylor, R. A., và Chartash, D. (2022). How well does chatgpt do when taking the medical licensing exams? the implications of large language models for medical education and knowledge assessment. In medRxiv. https://doi.org/10.1101/2022.12.23.22283901.

Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., và Steinhardt, J. (2020). Measuring massive multitask language understanding. arXiv preprint arXiv:abs/2009.03300.

Huang, K. (2023). Alarmed by A.I. chatbots, universities start revamping how they teach. New York Times. 16 tháng 1, 2023.

Karmakar, A., Prenner, J. A., D'Ambros, M., và Robbes, R. (2022). Codex hacks HackerRank: Memorization issues and a framework for code synthesis evaluation. ArXiv, abs/2212.02684.

Knuth, D. E. (1984). Literate programming. The computer journal, 27(2):97–111.

Kung, T. H., Cheatham, M., Medinilla, A., Sillos, C., De Leon, L., Elepano, C., Madriaga, M., Aggabao, R., Diaz-Candido, G., Maningo, J., et al. (2022). Performance of ChatGPT on USMLE: Potential for ai-assisted medical education using large language models. medRxiv preprint. https://doi.org/10.1101/2022.12.19.22283643.

Lai, G., Xie, Q., Liu, H., Yang, Y., và Hovy, E. (2017). Race: Large-scale reading comprehension dataset from examinations. arXiv preprint arXiv:abs/1704.04683.

Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., Eccles, T., Keeling, J., Gimeno, F., Lago, A. D., Hubert, T., Choy, P., de Masson d'Autume, C., Babuschkin, I., Chen, X., Huang, P.-S., Welbl, J., Gowal, S., Cherepanov, A., Molloy, J., Mankowitz, D. J., Robson, E. S., Kohli, P., de Freitas, N., Kavukcuoglu, K., và Vinyals, O. (2022). Competition-level code generation with AlphaCode. Science, 378(6624):1092–1097.

Liévin, V., Hother, C. E., và Winther, O. (2022). Can large language models reason about medical questions? ArXiv preprint arXiv:abs/2207.08143.

Lu, P., Mishra, S., Xia, T., Qiu, L., Chang, K.-W., Zhu, S.-C., Tafjord, O., Clark, P., và Kalyan, A. (2022). Learn to explain: Multimodal reasoning via thought chains for science question answering.

McDowell, C., Werner, L., Bullock, H., và Fernald, J. (2002). The effects of pair-programming on performance in an introductory programming course. In Proceedings of the 33rd SIGCSE technical symposium on Computer science education, pages 38–42.

Mialon, G., Dessì, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., Rozière, B., Schick, T., Dwivedi-Yu, J., Celikyilmaz, A., et al. (2023). Augmented language models: a survey. arXiv preprint arXiv:2302.07842.

Mihaylov, T., Clark, P., Khot, T., và Sabharwal, A. (2018). Can a suit of armor conduct electricity? A new dataset for open book question answering. arXiv preprint arXiv:abs/1809.02789.

Mohammadkhani, A. H., Tantithamthavorn, C. K., và Hemmati, H. (2022). Explainable AI for pre-trained code models: What do they learn? When they do not work? ArXiv preprint, arXiv:abs/2211.12821.

Mostafazadeh, N., Chambers, N., He, X., Parikh, D., Batra, D., Vanderwende, L., Kohli, P., và Allen, J. (2016). A corpus and cloze evaluation for deeper understanding of commonsense stories. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 839–849.

Nguyen, N. và Nadi, S. (2022). An empirical evaluation of GitHub Copilot's code suggestions. In 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR), pages 1–5.

Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al. (2022). Training language models to follow instructions with human feedback. arXiv preprint arXiv:abs/2203.02155.

Radford, A., Narasimhan, K., Salimans, T., và Sutskever, I. (2018). Improving language understanding by generative pre-training.

Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., và Sutskever, I. (2019). Language models are unsupervised multitask learners.

Robins, A., Rountree, J., và Rountree, N. (2003). Learning and Teaching Programming: A Review and Discussion. Computer Science Education, 13(2):137–172.

Robinson, J., Rytting, C. M., và Wingate, D. (2022). Leveraging large language models for multiple choice question answering. arXiv preprint arXiv:abs/2210.12353.

Savelka, J., Agarwal, A., Bogart, C., Song, Y., và Sakr, M. (2023). Can generative pre-trained transformers (gpt) pass assessments in higher education programming courses? In Proceedings of the 28th Annual ACM Conference on Innovation and Technology in Computer Science Education.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., và Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.

Wermelinger, M. (2023). Using GitHub Copilot to solve simple programming problems. Proceedings of the 54th ACM Technical Symposium on Computing Science Education (SIGCSE).

Yang, G., Zhou, Y., Yang, W., Yue, T., Chen, X., và Chen, T. (2022). How important are good method names in neural code generation? A model robustness perspective. ArXiv, abs/2211.15844.

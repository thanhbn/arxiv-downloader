# 2302.06144.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2302.06144.pdf
# Kích thước tệp: 681421 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
SKCODER: Phương pháp dựa trên phác thảo cho
việc tạo mã tự động

Jia Li♂
Phòng thí nghiệm chính về Công nghệ Phần mềm
Tin cậy cao, Bộ Giáo dục (Đại học Bắc Kinh)
Bắc Kinh, Trung Quốc
lijia@stu.pku.edu.cn

Yongmin Li
Phòng thí nghiệm chính về Công nghệ Phần mềm
Tin cậy cao, Bộ Giáo dục (Đại học Bắc Kinh)
Bắc Kinh, Trung Quốc
liyongmin@pku.edu.cn

Ge Li*
Phòng thí nghiệm chính về Công nghệ Phần mềm
Tin cậy cao, Bộ Giáo dục (Đại học Bắc Kinh)
Bắc Kinh, Trung Quốc
lige@pku.edu.cn

Zhi Jin*
Phòng thí nghiệm chính về Công nghệ Phần mềm
Tin cậy cao, Bộ Giáo dục (Đại học Bắc Kinh)
Bắc Kinh, Trung Quốc
zhijin@pku.edu.cn

Yiyang Hao
aiXcoder
Bắc Kinh, Trung Quốc
haoyiyang@aixcoder.com

Xing Hu
Đại học Chiết Giang
Ninh Ba, Trung Quốc
xinghu@zju.edu.cn

Tóm tắt—Gần đây, các kỹ thuật học sâu đã cho thấy thành công lớn trong việc tạo mã tự động. Lấy cảm hứng từ việc tái sử dụng mã, một số nhà nghiên cứu đề xuất các phương pháp dựa trên sao chép có thể sao chép nội dung từ các đoạn mã tương tự để có được hiệu suất tốt hơn. Trong thực tế, các nhà phát triển con người nhận ra nội dung trong mã tương tự có liên quan đến nhu cầu của họ, điều này có thể được xem như một phác thảo mã. Phác thảo sau đó được chỉnh sửa thành mã mong muốn. Tuy nhiên, các phương pháp dựa trên sao chép hiện tại bỏ qua các phác thảo mã và có xu hướng lặp lại mã tương tự mà không có sửa đổi cần thiết, dẫn đến việc tạo ra kết quả sai.

Trong bài báo này, chúng tôi đề xuất một phương pháp tạo mã dựa trên phác thảo có tên SKCODER để bắt chước hành vi tái sử dụng mã của các nhà phát triển. Cho một yêu cầu ngôn ngữ tự nhiên, SKCODER truy xuất một đoạn mã tương tự, trích xuất các phần liên quan như một phác thảo mã, và chỉnh sửa phác thảo thành mã mong muốn. Động lực của chúng tôi là phác thảo được trích xuất cung cấp một mẫu được hình thành tốt để nói với các mô hình "cách viết". Việc chỉnh sửa sau đó bổ sung thêm các chi tiết cụ thể theo yêu cầu vào phác thảo và xuất ra mã hoàn chỉnh. Chúng tôi thực hiện thí nghiệm trên hai bộ dữ liệu công khai và một bộ dữ liệu mới được thu thập bởi công việc này. Chúng tôi so sánh phương pháp của mình với 20 baseline sử dụng 5 chỉ số được sử dụng rộng rãi. Kết quả thí nghiệm cho thấy rằng (1) SKCODER có thể tạo ra nhiều chương trình đúng hơn, và vượt trội hơn state-of-the-art – CodeT5-base lần lượt 30.30%, 35.39%, và 29.62% trên ba bộ dữ liệu. (2) Phương pháp của chúng tôi hiệu quả với nhiều mô hình tạo mã và cải thiện chúng lên đến 120.1% trong Pass@1. (3) Chúng tôi khảo sát ba phác thảo mã khả thi và thảo luận về tầm quan trọng của phác thảo. (4) Chúng tôi đánh giá thủ công mã được tạo ra và chứng minh tính ưu việt của SKCODER trong ba khía cạnh.

Thuật ngữ chỉ mục—Tạo mã, Học sâu

I. GIỚI THIỆU

Khi độ phức tạp và quy mô của phần mềm tiếp tục tăng lên, các nhà phát triển tốn rất nhiều công sức để viết mã nguồn bằng tay. Tạo mã nhằm mục đích tự động hóa quá trình lập trình này và tạo ra mã nguồn thỏa mãn một yêu cầu ngôn ngữ tự nhiên cho trước. Ngày nay, các kỹ thuật học sâu (DL) đã được áp dụng thành công cho việc tạo mã tự động [1], [2], [3]. Các mô hình dựa trên DL nhận một mô tả ngôn ngữ tự nhiên (NL) làm đầu vào và xuất ra mã nguồn tương ứng. Các mô hình được huấn luyện với một kho dữ liệu các cặp NL-mã thực. Trong quá trình suy luận, các mô hình được huấn luyện có thể tự động tạo ra mã mong muốn cho một mô tả NL mới.

check if all elements in listtmp are integer
Tìm kiếm mã tương tự
Trích xuất nội dung liên quan
all(_ for x in _)
all(isinstance(x, int) for x in tmp)
Thêm chi tiết hướng dẫn

Hình 1. Quá trình tái sử dụng mã tương tự bởi các nhà phát triển.

Gần đây, lấy cảm hứng từ việc tái sử dụng mã [4], một số nhà nghiên cứu [5], [6], [7] giới thiệu các kỹ thuật truy xuất thông tin vào việc tạo mã. Họ truy xuất mã tương tự và cung cấp nó như một bổ sung cho các mô hình tạo mã. Các mô hình được huấn luyện để sao chép một số nội dung từ mã tương tự và có được hiệu suất tốt hơn. Trong bài báo này, chúng tôi gọi những nghiên cứu này là các mô hình tạo mã dựa trên sao chép.

Trong thực tế, các nhà phát triển con người thường thực hiện các sửa đổi cần thiết trong mã tương tự thay vì chỉ đơn giản sao chép, trong quá trình tái sử dụng mã [8]. Như được hiển thị trong Hình 1, các nhà phát triển tìm kiếm một đoạn mã tương tự trong các cộng đồng mã nguồn mở (ví dụ: Stack Overflow [9]) và tiếp tục phân tích mức độ liên quan của mã tương tự với yêu cầu của họ. Sau đó, các nhà phát triển nhận ra các phần (tức là, all(_ for x in _)) có liên quan đến nhu cầu của họ và bỏ qua các phần không liên quan

--- TRANG 2 ---

Mô tả đầu vào: đếm các phần tử trong danh sách nằm trong một phạm vi cụ thể
def count_range(list1, min, max): 
    result = 0
    for x in list1:
        if min <= x <= max:
            result = result + 1
    return result

Mã tương tự Top-1:
Phác thảo mã:
Mã cuối cùng:

truy xuất - phác thảo - chỉnh sửa

def count_integer(list1):
    result = 0
    for x in list1:
        if isinstance(x, int):
            result = result + 1
    return result

def _(list1):
    result = 0
    for x in list1:
        if _:
            result = result + 1
    return result

Hình 2. Minh họa về cách các nhà phát triển tái sử dụng mã tương tự. Nội dung liên quan trong mã tương tự được làm nổi bật.

(tức là, x==myList[0] và myList). Nội dung liên quan có thể được xem như một phác thảo mã, chỉ định một mẫu mã khả thi (ví dụ: các mẫu sử dụng API [10], [11]) để hướng dẫn các nhà phát triển về cách viết mã của họ. Tiếp theo, các nhà phát triển hiểu yêu cầu hiện tại (tức là, kiểm tra số nguyên) và chỉnh sửa phác thảo thành mã mong muốn bằng cách thêm một số chi tiết (tức là, isinstance(x,int)). Trong quy trình trên, phác thảo mã đóng vai trò quan trọng trong việc tái sử dụng mã. Các phác thảo biểu thị kiến thức mà các nhà phát triển trích xuất từ mã tương tự, và được tái sử dụng thêm trong mã mới được viết. Tuy nhiên, các mô hình dựa trên sao chép trước đây [5], [7] bỏ qua tầm quan trọng của phác thảo. Kết quả thí nghiệm cho thấy rằng các mô hình dựa trên sao chép có xu hướng lặp lại mã tương tự mà không có sửa đổi cần thiết và thậm chí sao chép nội dung không liên quan.

Để bắt chước hành vi tái sử dụng mã của các nhà phát triển trên, chúng tôi đề xuất một phương pháp tạo mã dựa trên phác thảo mới, có tên SKCODER. Khác với việc chỉ đơn giản sao chép trong các phương pháp dựa trên sao chép trước đây, SKCODER có thể xác định nội dung trong mã tương tự có liên quan đến yêu cầu hiện tại và tiếp tục sửa đổi những nội dung liên quan đó. Động lực của chúng tôi là phác thảo mã biểu thị hướng dẫn từ mã tương tự nói với các mô hình "cách viết", và các mô tả NL diễn đạt yêu cầu nói với các mô hình "viết gì". Cụ thể, SKCODER tạo ra mã nguồn trong ba bước:

• Truy xuất. Cho một mô tả NL, chúng tôi sử dụng một bộ truy xuất để chọn một đoạn mã tương tự từ một kho dữ liệu truy xuất.
• Phác thảo. Dựa trên mô tả NL, chúng tôi sử dụng một bộ phác thảo để trích xuất một phác thảo mã từ mã tương tự.
• Chỉnh sửa. Chúng tôi sử dụng một bộ chỉnh sửa để chỉnh sửa phác thảo dựa trên mô tả NL và có được mã mục tiêu.

Chúng tôi thực hiện các thí nghiệm mở rộng để đánh giá SKCODER của chúng tôi. (1) Chúng tôi đánh giá SKCODER trên hai bộ dữ liệu công khai [12], bao gồm HearthStone và Magic. Chúng tôi sử dụng ba chỉ số đánh giá được sử dụng rộng rãi (exact match (EM), BLEU [13], và CodeBLEU [14]). Kết quả cho thấy hiệu suất ấn tượng của SKCODER. Về mặt EM, SKCODER vượt trội hơn các baseline state-of-the-art (SOTA) lên đến 22.41% và các baseline dựa trên sao chép SOTA lên đến 42.86%. (2) Chúng tôi thu thập một bộ dữ liệu tạo mã mới có tên AixBench-L bao gồm 200k cặp NL-mã thực. Mỗi mẫu thử nghiệm được trang bị một tập hợp các bài kiểm tra đơn vị. Chúng tôi sử dụng Pass@1 và AvgPassRatio để xác minh tính đúng đắn của mã được tạo ra. Kết quả cho thấy SKCODER vượt trội hơn các baseline SOTA 12.9% trong Pass@1 và 8.49% trong AvgPassRatio. (3) Chúng tôi thực hiện nghiên cứu ablation của phương pháp chúng tôi trên nhiều mô hình tạo mã bằng cách dần dần thêm bộ truy xuất và bộ phác thảo vào các mô hình này. Kết quả chứng minh đóng góp của các module khác nhau và SKCODER có thể cải thiện đáng kể các mô hình khác nhau lên đến 120.1% trong Pass@1. (4) Chúng tôi khảo sát ba lựa chọn thiết kế khả thi cho phác thảo mã. Kết quả cho thấy tầm quan trọng của phác thảo và phác thảo được sử dụng của chúng tôi có hiệu suất tốt hơn. Chúng tôi cũng thảo luận về tầm quan trọng của phác thảo mã thông qua các ví dụ thực tế. (5) Chúng tôi thực hiện đánh giá con người để đánh giá mã được tạo ra trong ba khía cạnh, bao gồm tính đúng đắn, chất lượng mã, và khả năng bảo trì. Kết quả cho thấy SKCODER vượt trội hơn các baseline trong cả ba khía cạnh.

Chúng tôi tóm tắt các đóng góp của mình trong bài báo này như sau:
• Để bắt chước hành vi tái sử dụng mã của các nhà phát triển, chúng tôi đề xuất một phương pháp tạo mã dựa trên phác thảo có tên SKCODER. Nó trích xuất một phác thảo mã từ mã tương tự được truy xuất và tiếp tục chỉnh sửa phác thảo thành mã mục tiêu dựa trên mô tả đầu vào.
• Chúng tôi thu thập một bộ dữ liệu tạo mã mới có tên AixBench-L bao gồm 200k cặp NL-mã thực. Mỗi mẫu thử nghiệm được trang bị một tập hợp các bài kiểm tra đơn vị để đánh giá tính đúng đắn của các hàm.
• Chúng tôi thực hiện các thí nghiệm mở rộng trên ba bộ dữ liệu. Phân tích định tính và định lượng cho thấy tính hiệu quả của SKCODER. Chúng tôi tiếp tục khảo sát các lựa chọn thiết kế khác nhau của phác thảo mã và thảo luận về tầm quan trọng của phác thảo mã.

Tính khả dụng của dữ liệu. Chúng tôi mở mã nguồn gói sao chép của mình [15], bao gồm các bộ dữ liệu và mã nguồn của SKCODER, để tạo điều kiện cho các nhà nghiên cứu và thực hành khác lặp lại công việc của chúng tôi và xác minh các nghiên cứu của họ.

II. CÁC VÍ DỤ ĐỘNG LỰC

Trong Hình 2, chúng tôi hiển thị một ví dụ để phân tích cách các nhà phát triển tái sử dụng mã tương tự và giải thích động lực của chúng tôi.

(1) Đối với một yêu cầu đầu vào, mã tương tự được truy xuất chứa nội dung liên quan và các phần không liên quan. Cho một mô tả NL, các nhà phát triển đầu tiên truy xuất một đoạn mã tương tự. Hình 2 hiển thị đoạn mã tương tự Top-1 được truy xuất dựa trên sự tương tự của các mô tả NL. Sau đó, các nhà phát triển hiểu các chi tiết triển khai của mã tương tự và xác định phần nào có liên quan đến yêu cầu của họ. Chúng ta có thể thấy rằng mã tương tự chứa rất nhiều nội dung liên quan (tức là, được làm nổi bật trong Hình 2), ví dụ: tham số (list1), câu lệnh luồng điều khiển (for x in list1:), và câu lệnh luồng dữ liệu (result=result+1). Trong khi đó, mã tương tự cũng chứa các phần không liên quan, chẳng hạn như câu lệnh điều kiện if (if instance(x,int):).

Do đó, việc chỉ đơn giản sao chép từ mã tương tự là không phù hợp, có thể gây ra mã được tạo ra chứa một số phần không liên quan.

--- TRANG 3 ---

Kho dữ liệu truy xuất - Bộ truy xuất
count elements in a list which are within a specific range
Mô tả NL
Các đoạn mã tương tự

Bộ phác thảo
Mô tả đầu vào count...
def count_int(list1)
Mã tương tự: ...
√ × √ √ ... √ √

def<pad>(list1): 
    result = 0
    for x in list1:
        if<pad>:
            result = result + 1
    return result
Phác thảo mã

count elements in a list which are within a specific range
Mô tả NL

Bộ chỉnh sửa
def count_range(list1, min, max):
    result = 0
    for x in list1:
        if min <= x <= max:
            result = result + 1
    return result
Mã được tạo ra

chỉnh sửa hướng dẫn

(a) Bộ truy xuất: Lựa chọn mã tương tự
(b) Bộ phác thảo: Trích xuất phác thảo mã
(c) Bộ chỉnh sửa: Chỉnh sửa phác thảo thành mã mục tiêu

mẫu mềm
result √ = √

Hình 3. Tổng quan về phương pháp của chúng tôi.

evant parts. Chúng tôi hiển thị một kết quả đầu ra sai của phương pháp dựa trên sao chép SOTA có tên REDCODER [7] trong Hình 6. REDCODER trực tiếp sao chép một câu lệnh không chính xác từ mã tương tự mà không có sửa đổi cần thiết.

(2) Chúng ta nên trích xuất nội dung liên quan từ mã tương tự như một phác thảo mã. Trong thực tế, các nhà phát triển sẽ nhận ra nội dung liên quan từ mã tương tự, bỏ qua các phần không liên quan. Nội dung liên quan có thể được xem như một phác thảo mã, chỉ định một mẫu mã để hướng dẫn các nhà phát triển về cách viết mã nguồn. Hình 2 hiển thị một phác thảo được trích xuất từ mã tương tự. Token "_" là một placeholder. Chúng ta có thể thấy rằng phác thảo cung cấp một cấu trúc mã cấp cao cho các nhà phát triển, tức là, khởi tạo một biến đếm → lặp qua danh sách và đếm → trả về biến đếm. Một số chi tiết được thay thế bằng các placeholder và được phát triển bởi các nhà phát triển.

Do đó, chúng tôi lập luận rằng phác thảo mã là cốt lõi của một quá trình tái sử dụng mã, biểu thị kiến thức có giá trị từ mã tương tự và được tái sử dụng thêm trong mã mới.

(3) Phác thảo cần được chỉnh sửa dựa trên mô tả đầu vào để có được mã mục tiêu. Phác thảo mã cung cấp các mẫu mã nói với các nhà phát triển "cách viết", và các mô tả NL diễn đạt yêu cầu nói với các nhà phát triển "viết gì". Do đó, các nhà phát triển sẽ chỉnh sửa phác thảo dựa trên yêu cầu của họ và có được mã cuối cùng. Hình 2 hiển thị mã cuối cùng. Các nhà phát triển hiểu yêu cầu (tức là, đếm các phần tử trong một phạm vi cụ thể) từ mô tả đầu vào và điền vào phác thảo với các chi tiết triển khai, ví dụ: tên hàm (count_range), các câu lệnh điều kiện if (if min<=x<=max:).

Dựa trên các quan sát trên, chúng tôi đề xuất một phương pháp tạo mã dựa trên phác thảo để bắt chước hành vi tái sử dụng mã của các nhà phát triển. Khác với các mô hình tạo mã dựa trên sao chép trước đây, phương pháp của chúng tôi chứa một module bộ phác thảo có thể trích xuất nội dung liên quan từ mã tương tự và xuất ra một phác thảo mã. Sau đó, chúng tôi sử dụng một module bộ chỉnh sửa để chỉnh sửa phác thảo thành mã mục tiêu. Thông qua quy trình trên, phương pháp của chúng tôi khai thác hiệu quả kiến thức từ kho dữ liệu mã chất lượng cao hiện có và chuyển giao kiến thức vào các chương trình mới được viết.

III. PHƯƠNG PHÁP

Trong phần này, chúng tôi trình bày một phương pháp tạo mã dựa trên phác thảo, có tên SKCODER. Chúng tôi định nghĩa chính thức tổng quan về SKCODER và mô tả các chi tiết trong các phần sau, bao gồm ba module và các chi tiết huấn luyện.

A. Tổng quan

Mục tiêu của việc tạo mã là huấn luyện một mô hình G(Y|X) dự đoán một đoạn mã Y dựa trên một mô tả ngôn ngữ tự nhiên (NL) đầu vào X. Trong công việc này, chúng tôi phân tách mô hình này thành ba module, bao gồm một bộ truy xuất, một bộ phác thảo, và một bộ chỉnh sửa. Ba module hoạt động trong một pipeline như được hiển thị trong Hình 3:

• Truy xuất. Cho một mô tả NL X, một bộ truy xuất chọn một đoạn mã tương tự Y′ từ một kho dữ liệu truy xuất.
• Phác thảo. Dựa trên mô tả NL X, một bộ phác thảo trích xuất một phác thảo mã S từ mã tương tự Y′.
• Chỉnh sửa. Một bộ chỉnh sửa chỉnh sửa phác thảo S thành mã mục tiêu Y dựa trên mô tả NL X.

B. Bộ truy xuất

Như được hiển thị trong Hình 3 (a), bộ truy xuất nhằm mục đích chọn các đoạn mã tương tự từ một kho dữ liệu truy xuất dựa trên mô tả NL đầu vào. Lấy cảm hứng từ các nghiên cứu trước đây [5], [6], chúng tôi nghĩ rằng các đoạn mã tương tự có khả năng có các mô tả NL tương tự. Do đó, chúng tôi lấy mô tả đầu vào làm truy vấn để tìm kiếm các mô tả tương tự trong một kho dữ liệu truy xuất. Sau đó, mã tương ứng của các mô tả tương tự được xem như mã tương tự.

Cụ thể, chúng tôi sử dụng điểm BM25 [16] làm chỉ số truy xuất của mình, được sử dụng rộng rãi trong các nghiên cứu trước đây [17], [18], [19]. BM25 là một hàm truy xuất bag-of-words để ước tính sự tương tự ở mức từ vựng của hai câu. Hai câu càng tương tự nhau, giá trị của điểm BM25 càng cao. Chúng tôi tận dụng công cụ tìm kiếm mã nguồn mở Lucene [20] để xây dựng bộ truy xuất của mình và sử dụng tập huấn luyện làm kho dữ liệu truy xuất của chúng tôi.

--- TRANG 4 ---

Động lực của chúng tôi là BM25 và Lucene có thể mang lại độ chính xác truy xuất tốt và có độ phức tạp thấp. Xem xét rằng kho dữ liệu truy xuất thường có quy mô lớn, một bộ truy xuất nhanh gần gũi hơn với các ứng dụng thực tế. Chúng tôi cũng lưu ý rằng có một số phương pháp tìm kiếm mã tiên tiến hơn [21], [22], và chúng có thể được áp dụng vào phương pháp của chúng tôi theo cách plug-and-play. Bởi vì các phương pháp này có độ phức tạp cao hơn, chúng tôi để chúng cho công việc tương lai.

C. Bộ phác thảo

Mục tiêu của bộ phác thảo là trích xuất một phác thảo mã từ mã tương tự dựa trên mô tả đầu vào. Nói cách khác, bộ phác thảo nên trích xuất nội dung có liên quan đến mô tả đầu vào và bỏ qua các phần không liên quan. Chúng tôi xem xét thủ tục này như một chuỗi các hành động phân loại ở mức token. Chúng tôi đầu tiên chia mã tương tự thành một chuỗi token. Sau đó, chúng tôi sử dụng một mạng neural để nắm bắt mối quan hệ giữa mô tả đầu vào và các token mã tương tự. Đối với các token liên quan hơn, mạng neural gán trọng số cao hơn. Dựa trên các đầu ra của mạng neural, chúng tôi tiếp tục quyết định xem mỗi token trong mã tương tự có được trích xuất hay bỏ qua. Các token bị bỏ qua được thay thế bằng placeholder. Hình 3 (b) hiển thị quy trình làm việc của bộ phác thảo.

Cụ thể, chúng tôi nối mô tả NL X và mã tương tự Y′ thành một chuỗi đầu vào và tokenize nó. Sau đó, chúng tôi sử dụng một bộ mã hóa neural Encoder(·) để chuyển đổi chuỗi đầu vào thành các biểu diễn vector [H;H′].

X = (x1, x2, ..., xn)
Y′ = (y′1, y′2, ..., y′m)
[H;H′] = Encoder([X;Y′])                     (1)

trong đó xi và y′i là token thứ i trong mô tả NL và mã tương tự; n và m là độ dài tối đa của mô tả NL và mã tương tự.

Chúng tôi tiếp tục trích xuất các biểu diễn vector của mã tương tự và đưa chúng vào một lớp phân loại tuyến tính. Lớp phân loại sẽ xuất ra một xác suất pi cho mỗi token trong mã tương tự. Nếu xác suất lớn hơn một ngưỡng t, token được trích xuất; ngược lại, nó được thay thế bằng một placeholder (<pad>).

H′ = (h′1, h′2, ..., h′m)
pi = softmax(Wsh′i + bs)                     (2)

si = {
    y′i    nếu pi > t
    <pad>  ngược lại                         (3)

S = (s1, s2, ..., sm)                        (4)

trong đó h′i biểu thị biểu diễn vector của token thứ i trong mã tương tự. Ws và bs là các tham số có thể huấn luyện trong lớp phân loại. S là phác thảo được dự đoán và si là token thứ i trong phác thảo. Chúng tôi tiếp tục gộp các placeholder liên tiếp trong phác thảo thành một placeholder.

Mô tả NL đầu vào: print script's directory
Mã mục tiêu: print(os.path.dirname(os.path.realpath(__file__)))
Mã tương tự được truy xuất: return os.path.dirname(os.path.realpath(sys.argv[0]))
Phác thảo mã (LCS): <pad> os.path.dirname(os.path.realpath(<pad>))

Hình 4. Minh họa về phác thảo của chúng tôi.

D. Bộ chỉnh sửa

Như được hiển thị trong Hình 3 (c), bộ chỉnh sửa coi phác thảo như một mẫu mềm và tạo ra mã mục tiêu với sự hướng dẫn của mô tả đầu vào. Bộ chỉnh sửa được huấn luyện để theo các cấu trúc mã được cung cấp bởi phác thảo và thêm chi tiết vào một số placeholder (ví dụ: count_range, min<=x<=max). Bộ chỉnh sửa cũng có thể tạo ra một số thành phần cần thiết không có trong phác thảo, ví dụ: các tham số bổ sung (min, max).

Trong bài báo này, chúng tôi sử dụng một mạng neural encoder-decoder để triển khai bộ chỉnh sửa, đã được sử dụng rộng rãi trong việc tạo mã [1], [2], [7], [3]. Cụ thể, chúng tôi nối mô tả NL và phác thảo thành một chuỗi đầu vào. Chuỗi đầu vào được chuyển đổi thành các biểu diễn vector bởi một encoder, và một decoder tạo ra mã mục tiêu dựa trên các biểu diễn vector.

E. Huấn luyện và Kiểm tra

SKCODER của chúng tôi chứa ba module: bộ truy xuất, bộ phác thảo, và bộ chỉnh sửa. Chúng tôi sử dụng một bộ truy xuất xác định không chứa các tham số có thể huấn luyện. Ngoài ra, xem xét rằng bộ phác thảo thực hiện các phân loại cứng không khả vi, phương pháp tổng thể không thể được huấn luyện theo cách end-to-end. Do đó, chúng tôi sử dụng một chiến lược huấn luyện hai giai đoạn (tức là, đầu tiên huấn luyện bộ phác thảo và sau đó huấn luyện bộ chỉnh sửa), được sử dụng rộng rãi trong các lĩnh vực khác như hoàn thiện mã [19] và tóm tắt mã [18].

1) Huấn luyện bộ phác thảo: Bộ phác thảo nhận một mô tả NL X và một đoạn mã tương tự Y′ làm đầu vào và xuất ra một phác thảo mã S. Nhưng các bộ dữ liệu tạo mã hiện có chỉ chứa các cặp NL-mã (X, Y) mà không có phác thảo rõ ràng. Do đó, chúng tôi đề xuất một phương pháp để xây dựng phác thảo để tạo thuận lợi cho việc huấn luyện. Chúng tôi đầu tiên chọn một bộ dữ liệu và sử dụng bộ truy xuất để tạo ra nhiều bộ ba (X, Y, Y′). Sau đó, chúng tôi coi dãy con chung dài nhất (LCS) [23] giữa mã tương tự Y′ và mã mục tiêu Y như một phác thảo mã S. Hình 4 hiển thị minh họa về phác thảo của chúng tôi. Chúng ta có thể thấy rằng LCS hiệu quả giữ lại các phần có thể tái sử dụng trong mã tương tự (ví dụ: API và cấu trúc mã). Trong Phần V, chúng tôi khảo sát thực nghiệm các lựa chọn thiết kế khác của phác thảo và chứng minh tính ưu việt của phác thảo được sử dụng.

Dựa trên thiết lập trên, chúng tôi có thể xây dựng nhiều bộ ba huấn luyện (X, Y′, S). Sau đó, chúng tôi huấn luyện bộ phác thảo bằng cách tối thiểu hóa hàm mất mát sau:

Ls = -∑(i=1 to m)[Ii·log(pi) + (1-Ii)·log(1-pi)]     (5)

--- TRANG 5 ---

BẢNG I
THỐNG KÊ CỦA CÁC BỘ DỮ LIỆU TRONG THÍ NGHIỆM CỦA CHÚNG TÔI.

Thống kê | Hearthstone | Magic | AixBench-L
# Train | 533 | 11,969 | 190,000
# Dev | 66 | 664 | 10,000
# Test | 66 | 664 | 175
Trung bình token trong mô tả | 27.92 | 59.54 | 27.55
Tối đa token trong mô tả | 44 | 174 | 3752
Trung bình token trong mã | 87.14 | 302.44 | 170.74
Tối đa token trong mã | 407 | 2395 | 25237

trong đó pi là xác suất dự đoán rằng token thứ i của mã tương tự y′i được giữ lại trong phác thảo S. Ii là một hàm chỉ thị xuất ra 1 khi y′i có trong S và xuất ra 0 khi y′i không có trong S.

2) Huấn luyện bộ chỉnh sửa: Các đầu vào của bộ chỉnh sửa chứa một mô tả NL X và một phác thảo mã S, và đầu ra là mã mục tiêu Y. Chúng tôi sử dụng một bộ truy xuất để tạo ra các bộ ba (X, Y, Y′) và tiếp tục sử dụng một bộ phác thảo đã được huấn luyện để dự đoán các phác thảo mã, thu được nhiều bộ ba huấn luyện (X, S, Y). Chúng tôi huấn luyện bộ chỉnh sửa bằng cách tối thiểu hóa hàm mất mát sau:

Le = -∑(i=1 to m)logP(yi|X, S, y<i)     (6)

trong đó yi biểu thị token thứ i trong mã mục tiêu và y<i là phần của mã mục tiêu trước yi.

3) Kiểm tra: Sau khi huấn luyện bộ phác thảo và bộ chỉnh sửa, SKCODER có thể được áp dụng cho suy luận trực tuyến. Cho một mô tả NL mới, chúng tôi sử dụng một bộ truy xuất để tìm kiếm một đoạn mã tương tự từ một kho dữ liệu truy xuất. Sau đó, bộ phác thảo trích xuất một phác thảo mã từ mã tương tự và bộ chỉnh sửa tạo ra đoạn mã mong muốn dựa trên phác thảo.

IV. THIẾT KẾ NGHIÊN CỨU

Để đánh giá tính hiệu quả của phương pháp chúng tôi, chúng tôi thực hiện một nghiên cứu quy mô lớn để trả lời ba câu hỏi nghiên cứu. Trong phần này, chúng tôi mô tả chi tiết nghiên cứu của mình, bao gồm các bộ dữ liệu, chỉ số, và baseline.

A. Câu hỏi nghiên cứu

Nghiên cứu của chúng tôi nhằm trả lời ba câu hỏi nghiên cứu (RQ). Trong RQ1, chúng tôi so sánh SKCODER với các mô hình tạo mã SOTA trên ba bộ dữ liệu đại diện. Trong RQ2, chúng tôi thực hiện nghiên cứu ablation để chứng minh đóng góp của các module khác nhau. Trong RQ3, chúng tôi khảo sát các lựa chọn thiết kế khác nhau của phác thảo mã và xác thực tính hiệu quả của thiết kế chúng tôi.

RQ1: SKCODER hoạt động như thế nào so với các baseline SOTA? Chúng tôi huấn luyện SKCODER với ba bộ dữ liệu đại diện. Sau đó, chúng tôi sử dụng nhiều chỉ số để đánh giá SKCODER và so sánh nó với các baseline tạo mã SOTA hiện có.

RQ2: Đóng góp của các module khác nhau trong phương pháp chúng tôi là gì? SKCODER bao gồm ba module: một bộ truy xuất, một bộ phác thảo, và một bộ chỉnh sửa. Chúng tôi đánh giá đóng góp của các module khác nhau bằng cách dần dần thêm chúng vào một mô hình cơ sở. Chúng tôi chọn nhiều mạng neural làm mô hình cơ sở và nhằm xác minh rằng phương pháp chúng tôi hiệu quả với các kiến trúc mạng khác nhau.

RQ3: Lựa chọn thiết kế tốt hơn của bộ phác thảo là gì? Trong Phần III-E, chúng tôi coi dãy con chung dài nhất (LCS) như phác thảo mã. Trong RQ này, chúng tôi cung cấp các lựa chọn thiết kế khác của phác thảo và so sánh chúng với thiết kế của chúng tôi.

B. Bộ dữ liệu

Chúng tôi thực hiện thí nghiệm trên hai bộ dữ liệu công khai (tức là HearthStone bằng Python và Magic bằng Java) được thu thập bởi Ling et al. [12] và một bộ dữ liệu Java mới có tên AixBench-L được thu thập bởi công việc này.

Các bộ dữ liệu HearthStone và Magic được đề xuất cho việc tạo mã tự động cho các thẻ trong trò chơi. Mỗi mẫu bao gồm một mô tả bán cấu trúc và một chương trình được viết bởi con người. Mô tả đi kèm với một số thuộc tính như tên thẻ, và loại thẻ, cũng như một mô tả ngôn ngữ tự nhiên cho hiệu ứng của thẻ. Chúng tôi tuân theo công việc trước đây [1], [2] để xử lý trước hai bộ dữ liệu, và thống kê được liệt kê trong Bảng I.

AixBench-L là một benchmark tạo mã ở cấp độ hàm và là một phiên bản mở rộng của benchmark AixBench công khai [24]. Chúng tôi coi AixBench gốc làm dữ liệu thử nghiệm và thu thập nhiều cặp NL-mã từ Github [25] làm dữ liệu train và dev. Cụ thể, chúng tôi khai thác các dự án mã nguồn mở Java có ít nhất 30 sao từ GitHub, và tránh các dự án chứa dữ liệu thử nghiệm. Từ các dự án được khai thác, chúng tôi loại bỏ các hàm được tạo tự động và trích xuất các hàm (i) có docstring tiếng Anh; (ii) có <1024 token và >1 dòng. Cuối cùng, chúng tôi chọn 200k mẫu từ các dự án được khai thác và phân chia ngẫu nhiên chúng thành dữ liệu train và dữ liệu valid. Chúng tôi xem xét tất cả các dự án được khai thác như kho dữ liệu truy xuất. Thống kê được hiển thị trong Bảng I. Mỗi mẫu thử nghiệm chứa một mô tả ngôn ngữ tự nhiên độc lập về chức năng và được mô tả tốt, một chữ ký của hàm mục tiêu, và một tập hợp các bài kiểm tra đơn vị xác minh tính đúng đắn của hàm. Theo công việc trước đây [24], chúng tôi lấy mô tả ngôn ngữ tự nhiên và chữ ký hàm làm đầu vào của mô hình.

C. Chỉ số

Trên các bộ dữ liệu HearthStone và Magic, chúng tôi xem các chương trình được viết bởi con người như ground-truth, và sử dụng ba chỉ số được sử dụng rộng rãi để đánh giá sự tương tự của mã được tạo ra và ground-truth [1], [2], [3].

• Exact match (EM) là tỷ lệ phần trăm của mã được tạo ra có cùng chuỗi token với ground-truth.

• Điểm BLEU [13] được sử dụng để đo sự tương tự ở mức token giữa mã được tạo ra và ground-truth. Cụ thể, nó tính toán sự tương tự n-gram và có thể được tính như:

BLEU = BP · exp(∑(n=1 to N) wn log pn)     (7)

trong đó pn là điểm chính xác khớp n-gram, N được đặt là 4 trong thí nghiệm của chúng tôi. BP là một penalty ngắn gọn để ngăn chặn mã được tạo ra rất ngắn.

--- TRANG 6 ---

• Điểm CodeBLEU [14] là một biến thể của điểm BLEU. Nó chuyên biệt cho mã nguồn và xem xét các khớp cú pháp và ngữ nghĩa dựa trên cấu trúc mã ngoài việc khớp n-gram.

Dữ liệu thử nghiệm trong AixBench-L không chứa các chương trình được viết bởi con người. Chúng tôi phải bỏ qua các chỉ số (ví dụ: EM, BLEU) yêu cầu ground-truth. Theo công việc trước đây [24], chúng tôi sử dụng các bài kiểm tra đơn vị để đánh giá tính đúng đắn của các chương trình được tạo ra. Cụ thể, chúng tôi sử dụng các chỉ số sau:

• Pass@1 là tỷ lệ phần trăm của mã được tạo ra vượt qua tất cả các bài kiểm tra đơn vị. Nó đã được sử dụng rộng rãi trong các nghiên cứu trước đây [26], [27], [28].

• AvgPassRatio biểu thị tỷ lệ vượt qua trung bình của các test case và có thể được tính như thế này:

AvgPassRatio = (1/T) ∑(i) PassRatioi
PassRatioi = Counti,pass / Counti,total     (8)

trong đó Counti,pass và Counti,total là số lượng test case vượt qua và tổng số test case trong mẫu thử nghiệm thứ i, tương ứng. T là kích thước của dữ liệu thử nghiệm.

D. Baseline

Chúng tôi chọn 20 mô hình tạo mã được đề xuất gần đây làm baseline. Chúng có thể được chia thành ba loại: baseline dựa trên chuỗi, baseline dựa trên cây, và baseline được tiền huấn luyện.

Các baseline dựa trên chuỗi coi mã nguồn như văn bản thô và trực tiếp tạo ra một chuỗi token mã:

• RNN [29] là một mạng neural cổ điển trong xử lý mã nguồn. Chúng tôi sử dụng RNN để triển khai một mô hình tạo mã encoder-decoder vanilla làm baseline.
• Transformer [30] là một mô hình encoder-decoder phổ biến và đã đạt được kết quả đầy hứa hẹn trong các tác vụ tạo mã và hoàn thiện mã [19].
• LPN [12] và ReEdit [6] là các mô hình tạo mã dựa trên RNN. LPN đề xuất một cơ chế attention có cấu trúc để xử lý các đầu vào bán cấu trúc. ReEdit giới thiệu một chương trình tương tự được truy xuất như một đầu vào bổ sung.

Các baseline dựa trên cây trực tiếp tạo ra một cây được phân tích (ví dụ: cây cú pháp trừu tượng) của mã nguồn. Cây được tạo ra sau đó được chuyển đổi thành mã nguồn.

• Seq2Tree [31] là một công việc tiên phong dựa trên cây đề xuất một mô hình tạo mã được tăng cường attention.
• TRANX [1] là một mô hình tạo mã dựa trên cây đại diện có thể ánh xạ một mô tả NL thành một cây sử dụng một chuỗi các hành động xây dựng cây.
• ASN [32] sử dụng một decoder được xác định động để tạo ra một cây một cách hiệu quả.
• TreeGen [2] tích hợp các quy tắc ngữ pháp và cấu trúc cây vào Transformer. Nó vượt trội đáng kể so với các mô hình tạo mã dựa trên RNN trước đây.
• ReCode [5] là một biến thể của TRANX, có thể sao chép các hành động n-gram từ cây của một chương trình tương tự.

Các baseline được tiền huấn luyện đầu tiên được tiền huấn luyện với một kho dữ liệu mã quy mô lớn và sau đó được tinh chỉnh với các bộ dữ liệu tạo mã. Ngày nay, các mô hình tạo mã được tiền huấn luyện đã đạt được kết quả SOTA trên nhiều bộ dữ liệu tạo mã.

• CodeBERT [33] và GraphCodeBERT [34] là hai mô hình được tiền huấn luyện chỉ có encoder. Chúng chủ yếu áp dụng các kỹ thuật tiền huấn luyện cho ngôn ngữ tự nhiên vào mã nguồn. Chúng tôi thêm một decoder transformer sáu lớp cùng với hai mô hình, để hỗ trợ tạo mã. Cả hai mô hình đều chứa 175 triệu tham số.
• CodeGPT [35] và CodeParrot [27] là hai mô hình được tiền huấn luyện chỉ có decoder. Chúng được phát triển từ GPT-2 [36] và được tiền huấn luyện liên tục với mã. Cả hai mô hình đều chứa 124 triệu tham số.
• PyCodeGPT [26] và GPT-CC [28] là hai mô hình được tiền huấn luyện chỉ có decoder. Chúng được khởi tạo với GPT-Neo [37] và được tiền huấn luyện liên tục với một kho dữ liệu mã quy mô lớn bằng Python. Cả hai mô hình đều chứa 110 triệu tham số.
• CERT-PyCodeGPT [26] là một biến thể của PyCodeGPT. Nó đầu tiên dự đoán một phác thảo dựa trên mô tả NL và tiếp tục tạo ra mã hoàn chỉnh dựa trên phác thảo. Chúng tôi tuân theo hướng dẫn trong bài báo gốc và huấn luyện một CERT-PyCodeGPT (220M) trong các bộ dữ liệu thí nghiệm của chúng tôi.
• CodeGen [38] là một mô hình được tiền huấn luyện chỉ có decoder. Nó coi việc tạo mã như một cuộc trò chuyện nhiều lượt giữa người dùng và hệ thống. Trong bài báo này, chúng tôi sử dụng phiên bản CodeGen-Mono-350M.
• REDCODER [7] là một mô hình được tiền huấn luyện encoder-decoder. Nó cung cấp nhiều đoạn mã tương tự như một bổ sung cho một mô hình tạo mã được tiền huấn luyện. Chúng tôi sử dụng GraphCodeBERT để khởi tạo bộ truy xuất và sử dụng PLBART-base [39] để khởi tạo bộ tạo. REDCODER đầy đủ chứa 315 triệu tham số.
• CodeT5-small và CodeT5-base [3] là hai mô hình được tiền huấn luyện encoder-decoder. Chúng đề xuất một tác vụ tiền huấn luyện nhận biết định danh và đã đạt được kết quả SOTA trên nhiều bộ dữ liệu tạo mã. CodeT5-small chứa 60 triệu tham số và CodeT5-base bao gồm 220 triệu tham số.

E. Chi tiết triển khai

Chi tiết triển khai của SKCODER như sau:

• Bộ truy xuất. Chúng tôi sử dụng công cụ tìm kiếm mã nguồn mở - Lucene [20] để xây dựng bộ truy xuất. Chỉ số truy xuất là điểm BM25. Đối với HearthStone và Magic, kho dữ liệu truy xuất là dữ liệu huấn luyện của nó. Lưu ý rằng chúng tôi loại trừ ground truth từ các đầu ra của bộ truy xuất.
• Bộ phác thảo. Chúng tôi triển khai bộ phác thảo với một encoder Transformer 12 lớp. Kiến trúc mạng của nó tuân theo các nghiên cứu trước đây [33], [34]. Chúng tôi khởi tạo bộ phác thảo sử dụng trọng số được tiền huấn luyện của GraphCodeBERT [34].
• Bộ chỉnh sửa. Bộ chỉnh sửa là một Transformer encoder-decoder, và cả encoder và decoder đều chứa 12 lớp Transformer. Bộ chỉnh sửa tuân theo kiến trúc mạng trong

--- TRANG 7 ---

BẢNG II
KẾT QUẢ TRÊN BỘ DỮ LIỆU HEARTHSTONE (PYTHON). "*" ĐẠI DIỆN CHO CÁC BASELINE DỰA TRÊN SAO CHÉP.

Loại | Phương pháp | EM | BLEU | CodeBLEU
---|---|---|---|---
 | Module truy xuất | 0 | 57.56 | 56.58
Dựa trên chuỗi | LPN | 6.10 | 67.10 | –
 | RNN | 3.03 | 64.53 | 58.56
 | Transformer | 3.03 | 62.46 | 51.63
 | ReEdit * | 9.10 | 70.00 | –
Dựa trên cây | Seq2Tree | 1.50 | 53.40 | –
 | TRANX | 16.20 | 75.80 | –
 | ASN | 18.20 | 77.60 | –
 | ReCode * | 19.60 | 78.40 | –
 | TreeGen | 25.80 | 79.30 | –
Được tiền huấn luyện | CodeBERT | 3.03 | 66.50 | 59.39
 | GraphCodeBERT | 3.03 | 66.32 | 58.87
 | CodeGPT | 15.15 | 80.90 | 66.69
 | GPT-CC | 15.15 | 74.58 | 63.95
 | CodeParrot | 19.70 | 76.99 | 65.40
 | PyCodeGPT | 24.24 | 81.03 | 68.70
 | CERT-PyCodeGPT | 16.67 | 78.91 | 67.73
 | CodeGen | 24.24 | 78.80 | 67.43
 | REDCODER * | 21.21 | 80.08 | 67.31
 | CodeT5-small | 21.20 | 77.91 | 64.60
 | CodeT5-base | 25.84 | 81.28 | 68.42
 | SKCODER | 30.30 (↑17.26%) | 83.12 (↑2.26%) | 70.97 (↑3.73%)

BẢNG III
KẾT QUẢ TRÊN BỘ DỮ LIỆU MAGIC (JAVA). CHÚNG TÔI BỎ QUA MỘT SỐ BASELINE VÌ CHÚNG KHÔNG THỂ ÁP DỤNG CHO NGÔN NGỮ JAVA.

Loại | Phương pháp | EM | BLEU | CodeBLEU
---|---|---|---|---
 | Module truy xuất | 0 | 53.64 | 64.23
Dựa trên chuỗi | LPN | 4.80 | 61.40 | –
 | RNN | 16.26 | 71.96 | 61.83
 | Transformer | 12.20 | 73.10 | 66.61
Được tiền huấn luyện | CodeBERT | 19.42 | 78.69 | 71.73
 | GraphCodeBERT | 27.41 | 82.33 | 74.76
 | CodeGPT | 27.40 | 78.68 | 70.04
 | REDCODER * | 9.79 | 58.81 | 50.38
 | CodeT5-small | 26.95 | 78.38 | 71.11
 | CodeT5-base | 28.91 | 80.46 | 73.11
 | SKCODER | 35.39 (↑22.41%) | 85.39 (↑6.13%) | 82.42 (↑10.27%)

công việc [3] và được khởi tạo với trọng số được tiền huấn luyện của CodeT5-base [3].

• Huấn luyện & Kiểm tra. Chúng tôi huấn luyện SKCODER với hai GPU NVIDIA A100. Kích thước batch được đặt là 32. Trong quá trình huấn luyện, chúng tôi sử dụng Top-5 đoạn mã tương tự để xây dựng dữ liệu huấn luyện của bộ phác thảo và bộ chỉnh sửa. Trong quá trình suy luận, chúng tôi chỉ sử dụng mã tương tự Top-1, sử dụng tìm kiếm beam, và đặt kích thước beam là 10.

Lưu ý rằng việc khởi tạo sử dụng trọng số được tiền huấn luyện là phổ biến trong các nghiên cứu trước đây [34], [7], [26], [27], [28] và có thể cải thiện hiệu quả hiệu suất của các mô hình. Để so sánh công bằng, chúng tôi cũng tái sử dụng trọng số được tiền huấn luyện trong thí nghiệm của mình.

V. KẾT QUẢ VÀ PHÂN TÍCH

Trong câu hỏi nghiên cứu đầu tiên, chúng tôi đánh giá hiệu suất của SKCODER so với các phương pháp tạo mã trước đây.

RQ1: SKCODER hoạt động như thế nào so với các baseline SOTA?

Thiết lập. Chúng tôi đánh giá các baseline (Phần IV-D) và SKCODER trên ba bộ dữ liệu tạo mã (Phần IV-B). Các chỉ số đánh giá được mô tả trong Phần IV-C, tức là EM, BLEU, CodeBLEU, Pass@1, và AvgPassRatio. Đối với tất cả các chỉ số, điểm số cao hơn đại diện cho hiệu suất tốt hơn.

Kết quả. Bảng II, Bảng III và Bảng IV hiển thị kết quả thí nghiệm trên ba bộ dữ liệu, tương ứng. "–" biểu thị

BẢNG IV
KẾT QUẢ TRÊN BỘ DỮ LIỆU AIXBENCH-L (JAVA). CHÚNG TÔI BỎ QUA MỘT SỐ BASELINE VÌ CHÚNG KHÔNG THỂ ÁP DỤNG CHO NGÔN NGỮ JAVA.

Loại | Phương pháp | Pass@1 | AvgPassRatio
---|---|---|---
 | Module truy xuất | 2.86 | 7.93
Dựa trên chuỗi | RNN | 4.00 | 13.33
 | Transformer | 6.29 | 12.43
Được tiền huấn luyện | CodeBERT | 9.14 | 23.35
 | GraphCodeBERT | 10.86 | 24.99
 | CodeGPT | 17.71 | 35.67
 | REDCODER * | 16.00 | 33.14
 | CodeT5-small | 12.57 | 25.11
 | CodeT5-base | 15.43 | 24.53
 | SKCODER | 20.00 (↑12.9%) | 38.70 (↑8.49%)

rằng các mô hình không được đánh giá sử dụng chỉ số này, theo hiểu biết tốt nhất của chúng tôi. "*" đại diện cho các baseline dựa trên sao chép, cũng sử dụng mã tương tự được truy xuất. Tỷ lệ phần trăm trong ngoặc đơn là các cải thiện tương đối so với các baseline mạnh nhất. Trên các bộ dữ liệu Magic và AixBench-L, chúng tôi bỏ qua một số baseline vì chúng được thiết kế cho các ngôn ngữ cụ thể và không thể hoạt động trong bộ dữ liệu Java.

Phân tích. (1) SKCODER đạt được kết quả tốt nhất trong tất cả các baseline. SKCODER có thể tạo ra nhiều chương trình đúng hơn. So với mô hình SOTA - CodeT5-base, SKCODER vượt trội hơn nó lên đến 22.41% trong EM và 29.62% trong Pass@1. Lưu ý rằng EM và Pass@1 là các chỉ số rất nghiêm ngặt và khó được cải thiện. Các cải thiện đáng kể chứng minh tính ưu việt của SKCODER trong việc tạo mã tự động. (2) Mã được truy xuất có lợi cho việc tạo mã. Module truy xuất của chúng tôi hoạt động tốt trong BLEU và CodeBLEU, nhưng nó kém trong EM và Pass@1. Điều này xác thực động lực của chúng tôi rằng mã tương tự chứa nhiều nội dung có thể tái sử dụng và các phần không liên quan. Bằng cách giới thiệu mã được truy xuất, các mô hình tạo mã có thể được cải thiện thêm. Ví dụ, trên bộ dữ liệu HearthStone, ReEdit cải thiện mô hình cơ sở của nó (tức là RNN) lên đến 200%, và ReCode cải thiện mô hình cơ sở của nó (tức là TRANX) lên đến 20.99%. (3) SKCODER vượt trội hơn các baseline dựa trên sao chép SOTA. Baseline dựa trên sao chép SOTA là REDCODER, sử dụng nhiều đoạn mã tương tự để tăng cường các mô hình tạo mã. Trong khi SKCODER chỉ sử dụng mã tương tự Top-1. So với REDCODER, SKCODER cải thiện nó 42.86% trong EM, 25% trong Pass@1, và 16.78% trong AvPassRatio. Điều này là do REDCODER có khả năng lặp lại mã tương tự mà không có sửa đổi cần thiết. Trong khi SKCODER sử dụng một bộ phác thảo để trích xuất nội dung liên quan như một phác thảo, bỏ qua các phần không liên quan. Phác thảo sau đó được chỉnh sửa dựa trên mô tả đầu vào. Do đó, SKCODER gần gũi hơn với hành vi tái sử dụng mã của các nhà phát triển và có thể tạo ra nhiều chương trình đúng hơn.

Trên các bộ dữ liệu HearthStone và Magic, chúng tôi nhận thấy rằng các cải thiện về EM cao hơn so với các chỉ số khác. Chúng tôi cẩn thận so sánh đầu ra của các mô hình khác nhau và thấy rằng các baseline và SKCODER đều có thể tạo ra đúng thân của chương trình. Nhưng các baseline thường sai ở một số chi tiết, chẳng hạn như tham số. Do đó, SKCODER có thể

--- TRANG 8 ---

BẢNG V
KẾT QUẢ CỦA NGHIÊN CỨU ABLATION.

Bộ chỉnh sửa | Bộ truy xuất | Bộ phác thảo | HearthStone | Magic | AixBench-L
---|---|---|---|---|---
| | | EM | BLEU | CodeBLEU | EM | BLEU | CodeBLEU | Pass@1 | AvgPassRate
RNN | | | 3.03 | 64.53 | 57.56 | 16.26 | 71.96 | 61.83 | 4.00 | 13.33
| ✓ | | 3.03 (↑0%) | 68.39 | 59.12 | 16.51 (↑1.54%) | 72.79 | 63.82 | 5.14 (↑28.5%) | 10.61
| ✓ | ✓ | 4.54 (↑49.83%) | 71.50 | 61.76 | 17.91 (↑10.15%) | 73.72 | 65.04 | 8.57 (↑114.3%) | 13.42 (↑2.7%)
CodeT5-small | | | 21.20 | 77.91 | 64.60 | 26.95 | 78.38 | 71.11 | 12.57 | 25.11
| ✓ | | 27.86 (↑31.42%) | 79.84 | 68.76 | 31.73 (↑17.74%) | 80.85 | 77.10 | 14.29 (↑13.68%) | 26.06 (↑3.78%)
| ✓ | ✓ | 30.30 (↑42.90%) | 83.08 | 69.35 | 33.89 (↑25.75%) | 85.15 | 80.08 | 18.29 (↑45.51%) | 34.05 (↑35.6%)
CodeT5-base | | | 25.24 | 81.28 | 68.42 | 28.91 | 80.46 | 73.11 | 15.43 | 24.52
| ✓ | | 27.81 (↑10.18%) | 82.06 | 69.35 | 32.43 (↑12.18%) | 83.11 | 78.97 | 17.71 (↑14.78%) | 34.75 (↑41.72%)
| ✓ | ✓ | 30.30 (↑20.05%) | 83.12 | 70.97 | 35.39 (↑22.41%) | 85.39 | 80.62 | 20.00 (↑29.62%) | 38.70 (↑57.83%)

tạo ra nhiều chương trình chính xác hoàn toàn hơn, và đạt được các cải thiện thấp hơn trên các chỉ số tương tự n-gram (tức là BLEU và CodeBLEU). Kết quả cũng xác minh rằng so với việc tạo ra mã từ đầu, việc chỉnh sửa một phác thảo được hình thành tốt dễ dàng hơn để tạo ra mã đúng.

Trả lời cho RQ1: SKCODER đạt được kết quả tốt nhất trong tất cả các baseline. Đặc biệt, SKCODER tạo ra 30.30%, 35.39%, và 20% chương trình đúng trên ba bộ dữ liệu, vượt trội hơn các mô hình tạo mã SOTA lần lượt 17.26%, 22.41%, và 12.9%. Các cải thiện đáng kể chứng minh phương pháp dựa trên phác thảo của chúng tôi triển vọng hơn trong việc tạo mã tự động.

Trong RQ2, chúng tôi nhằm tìm ra đóng góp của các module khác nhau trong SKCODER. Ngoài ra, chúng tôi dự định khảo sát tính hiệu quả của phương pháp chúng tôi trên các mô hình tạo mã khác nhau.

RQ2: Đóng góp của các module khác nhau trong phương pháp chúng tôi là gì?

Thiết lập. Trong RQ này, chúng tôi chọn ba mô hình tạo mã làm bộ chỉnh sửa cơ sở, bao gồm RNN, CodeT5-small, và CodeT5-base. Chúng bao gồm các kiến trúc mạng chính thống, tức là RNN, Transformer, và các mô hình được tiền huấn luyện. Đối với mỗi bộ chỉnh sửa, chúng tôi thực hiện nghiên cứu ablation bằng cách dần dần thêm bộ truy xuất và bộ phác thảo.

Kết quả. Kết quả thí nghiệm được hiển thị trong Bảng V. ✓ và ✗ đại diện cho việc thêm và loại bỏ các module tương ứng. Một bộ chỉnh sửa riêng lẻ chỉ là một mô hình tạo mã vanilla ánh xạ một mô tả NL thành mã nguồn. Sau khi thêm một bộ truy xuất, mô hình lấy mã được truy xuất làm đầu vào bổ sung. Sau khi tiếp tục giới thiệu một bộ phác thảo, mô hình là phương pháp dựa trên phác thảo của chúng tôi.

Phân tích. (1) Cả ba module đều cần thiết để hoạt động tốt nhất. Sau khi thêm một bộ truy xuất, hiệu suất của tất cả các mô hình được cải thiện. Ví dụ, trên HearthStone, bộ truy xuất mang lại cải thiện 10.18% trong EM cho CodeT5-base. Điều này xác thực rằng mã được truy xuất chứa nhiều thông tin có giá trị có lợi cho các mô hình tạo mã. Sau khi giới thiệu một bộ phác thảo, tất cả các mô hình đạt được kết quả tốt hơn. Ví dụ, trên HearthStone, CodeT5-base được cải thiện 20.05% trong EM. Điều này chứng minh rằng so với việc sao chép từ mã được truy xuất, phương pháp tạo mã dựa trên phác thảo của chúng tôi có thể khai thác tốt hơn kiến thức trong mã được truy xuất.

BẢNG VI
HIỆU SUẤT CỦA CÁC BỘ PHÁC THẢO KHÁC NHAU.

Phương pháp | HearthStone | Magic
---|---|---
| EM | BLEU | CodeBLEU | EM | BLEU | CodeBLEU
Không có bộ phác thảo | 27.81 | 82.06 | 69.35 | 32.43 | 82.01 | 78.87
Bộ phác thảo-1 | 27.93 (↑0.43%) | 82.39 | 70.81 | 33.06 (↑1.94%) | 83.04 | 80.15
Bộ phác thảo-2 | 29.03 (↑4.39%) | 82.77 | 70.27 | 34.46 (↑5.95%) | 83.91 | 80.19
Bộ phác thảo của chúng tôi | 30.30 (↑9.13%) | 83.12 | 70.97 | 35.39 (↑9.13%) | 85.39 | 80.62

Mô tả NL đầu vào: check if all elements in list var_0 are identical
Ground truth: all(x == var_0[0] for x in var_0)
Mã tương tự được truy xuất: all(isinstance(x, int) for x in var_0)
Bộ phác thảo-1 (ẩn danh hóa các thuật ngữ do người dùng định nghĩa): all(isinstance(v_1, int) for v_1 in v_2)
Bộ phác thảo-2 (giữ lại các token chồng lấp): all((x) for x in var_0)
Bộ phác thảo của chúng tôi (dãy con chung dài nhất): all(<pad> for x in var_0)

Hình 5. Ví dụ về ba phác thảo.

(2) Phương pháp của chúng tôi hiệu quả với nhiều mô hình tạo mã. Như được hiển thị trong Bảng V, phương pháp của chúng tôi hỗ trợ các mô hình tạo mã khác nhau và mang lại các cải thiện rõ ràng. Cụ thể, về mặt Pass@1, phương pháp của chúng tôi cải thiện RNN lên đến 114.3%, CodeT5-small 45.31%, và CodeT5-base 29.62%. Trong tương lai, phương pháp của chúng tôi có thể được sử dụng để tăng cường các mô hình tạo mã mạnh mẽ hơn.

Trả lời cho RQ2: Cả ba module đều thiết yếu cho hiệu suất của phương pháp chúng tôi. Ngoài ra, phương pháp của chúng tôi hiệu quả với các mô hình tạo mã khác nhau và cải thiện chúng 114.3%, 45.31%, và 29.62% trong Pass@1.

Phác thảo mã không được định nghĩa rõ ràng trong các bộ dữ liệu hiện có và cách xây dựng một phác thảo là một câu hỏi mở. Do đó, chúng tôi thiết kế một số lựa chọn thiết kế khả thi cho bộ phác thảo và khảo sát cái nào tốt hơn.

RQ3: Lựa chọn thiết kế tốt hơn cho phác thảo mã là gì?

Thiết lập. Trong RQ này, chúng tôi cung cấp ba bộ phác thảo (tức là bộ phác thảo-1, bộ phác thảo-2, và bộ phác thảo của chúng tôi). Bộ phác thảo-1 sử dụng một parser để ẩn danh hóa các thuật ngữ do người dùng định nghĩa trong mã tương tự (tức là chuỗi, hằng số, biến) và có được một phác thảo mã. Bộ phác thảo-2 huấn luyện một mạng neural để dự đoán các token chồng lấp giữa mã tương tự và ground truth. Các token chồng lấp được thu thập để xây dựng một phác thảo. Bộ phác thảo của chúng tôi

--- TRANG 9 ---

huấn luyện một mạng neural để dự đoán dãy con chung dài nhất (LCS) giữa mã tương tự và ground-truth. LCS được dự đoán được xem như một phác thảo. Chúng tôi trình bày một số ví dụ về các bộ phác thảo khác nhau trong Hình 5.

Kết quả. Kết quả thí nghiệm được hiển thị trong Bảng VI. Chúng tôi trình bày kết quả của SKCODER với các bộ phác thảo khác nhau và kết quả không có bộ phác thảo.

Phân tích. (1) Việc giới thiệu một bộ phác thảo có thể sử dụng tốt hơn mã được truy xuất. So với mô hình không có bộ phác thảo, các mô hình có bộ phác thảo hoạt động tốt hơn. Điều này cho thấy rằng bộ phác thảo có thể khai thác tốt hơn kiến thức từ mã được truy xuất và phương pháp dựa trên phác thảo của chúng tôi triển vọng hơn so với các phương pháp dựa trên sao chép. (2) Bộ phác thảo của chúng tôi hoạt động tốt nhất trong tất cả các baseline. Trên cả hai bộ dữ liệu, bộ phác thảo của chúng tôi mang lại cải thiện gấp 2 lần (ví dụ: 9.13% so với 0.43%) so với các bộ phác thảo khác. Điều này là do bộ phác thảo của chúng tôi có thể trích xuất chính xác nội dung liên quan và để lại các chi tiết không liên quan, trong khi các bộ phác thảo khác không thể. Như được hiển thị trong Hình 5, phác thảo-1 xuất ra một phác thảo bằng cách ẩn danh hóa các thuật ngữ do người dùng định nghĩa. Nhưng mã được ẩn danh hóa vẫn chứa các phần không liên quan (ví dụ: isinstance) và thậm chí mất một số token có thể tái sử dụng (ví dụ: var_0). Phác thảo-2 chỉ giữ lại các token có thể xuất hiện trong ground truth. Nó bỏ qua tính tuần tự của các token, và phác thảo được tạo ra có thể bị rối loạn và gây nhầm lẫn (ví dụ: (x)). Ngược lại, phác thảo được tạo ra bởi bộ phác thảo của chúng tôi được hình thành tốt và cung cấp một cấu trúc mã rõ ràng.

Trả lời cho RQ3: Phác thảo mã có lợi cho việc tái sử dụng kiến thức trong mã được truy xuất. Trong số nhiều bộ phác thảo khả thi, bộ phác thảo của chúng tôi hoạt động tốt nhất và mang lại cải thiện tối đa 9.13% trong EM.

VI. ĐÁNH GIÁ CON NGƯỜI

Mục tiêu cuối cùng của các mô hình tạo mã là hỗ trợ các nhà phát triển trong việc viết mã nguồn. Do đó, trong phần này, chúng tôi thực hiện một đánh giá con người để đánh giá SKCODER.

Thiết lập. Theo công việc trước đây [24], chúng tôi đánh giá thủ công mã được tạo ra bởi các mô hình khác nhau trong ba khía cạnh, bao gồm tính đúng đắn (liệu mã có thỏa mãn yêu cầu đã cho không), chất lượng mã (liệu mã có chứa mùi mã xấu không) và khả năng bảo trì (liệu việc triển khai có được chuẩn hóa và có tính đọc tốt không). Đối với mỗi khía cạnh, điểm số là số nguyên, từ 0 đến 2 (từ xấu đến tốt). Chúng tôi chọn ngẫu nhiên 50 mẫu thử nghiệm và thu thập các chương trình được tạo ra bởi 10 mô hình trên các mẫu này. Cuối cùng, chúng tôi có được 500 chương trình (50*10) để đánh giá. Các đánh giá viên là sinh viên tiến sĩ khoa học máy tính và không phải là đồng tác giả. Họ đều có kinh nghiệm lập trình từ 3+ năm. 500 đoạn mã được chia thành 5 nhóm, với mỗi bảng câu hỏi chứa một nhóm. Chúng tôi liệt kê ngẫu nhiên mã và mô tả đầu vào tương ứng trên bảng câu hỏi. Mỗi nhóm được đánh giá ẩn danh bởi hai đánh giá viên, và điểm số cuối cùng là trung bình của điểm số của hai đánh giá viên. Các đánh giá viên được phép tìm kiếm trên Internet cho các khái niệm không quen thuộc.

Kết quả và Phân tích. Kết quả của đánh giá con người được hiển thị trong Bảng VII. SKCODER tốt hơn tất cả

BẢNG VII
KẾT QUẢ CỦA ĐÁNH GIÁ CON NGƯỜI. TẤT CẢ CÁC GIÁ TRỊ P ĐỀU NHỎ HƠN ĐÁNG KỂ SO VỚI 0.005.

Phương pháp | Tính đúng đắn | Chất lượng mã | Khả năng bảo trì
---|---|---|---
GraphCodeBERT | 0.9277 | 0.9872 | 1.3049
CodeGPT | 0.9798 | 1.0229 | 1.3306
REDCODER * | 1.0177 | 1.2038 | 1.5796
CodeGen | 1.1250 | 1.3610 | 1.5573
PyCodeGPT | 1.1098 | 1.3661 | 1.5442
CodeParrot | 0.9704 | 1.0814 | 1.3668
GPT-Code-Clippy | 0.9646 | 1.0585 | 1.3672
CERT-PyCodeGPT | 0.9629 | 1.0439 | 1.3882
CodeT5-base | 1.1719 | 1.3908 | 1.5848
SKCODER | 1.3705 (↑16.95%) | 1.5639 (↑12.45%) | 1.7764 (↑12.09%)

các baseline trong ba khía cạnh. Cụ thể, SKCODER vượt trội hơn mô hình SOTA - CodeT5-base 16.95% về tính đúng đắn, 12.45% về chất lượng mã, và 12.09% về khả năng bảo trì. Tất cả các giá trị p đều nhỏ hơn đáng kể so với 0.005, cho thấy các cải thiện có ý nghĩa thống kê. Các cải thiện chứng minh tính ưu việt của SKCODER trong việc hỗ trợ các nhà phát triển lập trình. Ngoài ra, chúng tôi nhận thấy rằng mô hình dựa trên sao chép - REDCODER hoạt động tốt về khả năng bảo trì nhưng kém về tính đúng đắn và chất lượng mã. Điều này là do REDCODER có thể tạo ra các chương trình tự nhiên bằng cách sao chép từ mã được truy xuất. Nhưng một số nội dung được sao chép không liên quan và dẫn đến mã không chính xác.

VII. THẢO LUẬN

A. Nghiên cứu trường hợp

Hình 6 trình bày một số đoạn mã được tạo ra bởi các mô hình khác nhau trên bộ dữ liệu HearthStone. Từ các ví dụ, chúng tôi có được những phát hiện sau. (1) Mã tương tự được truy xuất cung cấp một cấu trúc mã được hình thành tốt và chứa một số chi tiết không liên quan (ví dụ: ImpGangBoss). (2) Như một phương pháp dựa trên sao chép, REDCODER sai lầm lặp lại câu lệnh không phù hợp (tức là effects=[Effect(...), ActionTag(...)]) mà không có sửa đổi. Điều này khiến mã được tạo ra không nhất quán với mô tả đầu vào. (3) Bộ phác thảo của chúng tôi chính xác giữ lại nội dung liên quan và thay thế các chi tiết không liên quan bằng placeholder. Phác thảo được trích xuất cung cấp một điểm khởi đầu rõ ràng cho việc chỉnh sửa. (4) Dựa trên mô tả đầu vào, SKCODER tiếp tục chỉnh sửa phác thảo thành mã mong muốn. Ví dụ, mô tả đầu vào chỉ định hiệu ứng của thẻ (tức là whenever you hero takes damage on your turn, gain +2/+2). SKCODER sửa đổi các lời gọi Damaged() và ActionTag() trong phác thảo và thêm nhiều chi tiết hơn (ví dụ: And(IsHero(), OwersTurn()). Ngoài ra, bộ chỉnh sửa thêm một số thành phần không có trong phác thảo, chẳng hạn như Character.

B. Các mối đe dọa đến tính hợp lệ

Có ba mối đe dọa chính đến tính hợp lệ của công việc chúng tôi.

Tính tổng quát của kết quả thí nghiệm của chúng tôi. Để giảm thiểu mối đe dọa này, chúng tôi thiết kế cẩn thận các bộ dữ liệu thí nghiệm, chỉ số, và baseline. Đối với các bộ dữ liệu, chúng tôi tuân theo các nghiên cứu trước đây [1], [5], [2] và chọn ba bộ dữ liệu tạo mã đại diện. Ba bộ dữ liệu được thu thập từ các dự án và cộng đồng phần mềm thực và bao gồm hai

--- TRANG 10 ---

Mô tả đầu vào: NAME:Floating Watcher ATK:4DEF:4COST:5DUR:-1 TYPE:Minion PLAYER:Warlock RACE:Demon RARITY:Common DESCRIPTION:Whenever your hero takes damage on your turn, gain +2/+2.

Bộ truy xuất (mã tương tự):
class ImpGangBoss(MinionCard):
    def __init__(self):
        super().__init__("Imp Gang Boss", 3, CHARACTER_CLASS.WARLOCK, CARD_RARITY.COMMON, minion_type=MINION_TYPE.DEMON)
    def create_minion(self, player):
        return Minion(2, 4, effects=[Effect(Damaged(), ActionTag(Summon(Imp()), PlayerSelector()))])

REDCODER:
class FloatingWatcher(MinionCard):
    def __init__(self):
        super().__init__("Floating Watcher", 5, CHARACTER_CLASS.WARLOCK, CARD_RARITY.COMMON, minion_type=MINION_TYPE.DEMON)
    def create_minion(self, player):
        return Minion(4, 4, effects=[Effect(Damaged(), ActionTag(Summon(Imp()), PlayerSelector()))])

Bộ phác thảo (phác thảo mã từ mã tương tự):
class <pad>(MinionCard):
    def __init__(self):
        super().__init__(<pad>, <pad>, CHARACTER_CLASS.WARLOCK, CARD_RARITY.COMMON, minion_type=MINION_TYPE.DEMON)
    def create_minion(self, player):
        return Minion(2, 4, effects=[Effect(Damaged(), ActionTag(<pad>, <pad>))])

SkCoder (chỉnh sửa phác thảo) & Ground-truth:
class FloatingWatcher(MinionCard):
    def __init__(self):
        super().__init__("Floating Watcher", 5, CHARACTER_CLASS.WARLOCK, CARD_RARITY.COMMON, minion_type=MINION_TYPE.DEMON)
    def create_minion(self, player):
        return Minion(4, 4, effects=[Effect(CharacterDamaged(And(IsHero(), OwnersTurn())), ActionTag(Give([Buff(ChangeAttack(2)), Buff(ChangeHealth(2))]), SelfSelector()))])

Hình 6. Ví dụ về các đoạn mã được tạo ra bởi các mô hình khác nhau. Chúng tôi làm nổi bật các phần mà SKCODER sửa đổi trên phác thảo.

ngôn ngữ lập trình phổ biến (tức là Java và Python). Đối với các chỉ số, chúng tôi chọn năm chỉ số được sử dụng rộng rãi, bao gồm EM, BLEU, CodeBLEU, Pass@1, và AvgPassRatio. Công việc hiện có [40] đã chứng minh độ tin cậy của các chỉ số này. Để xác minh tính ưu việt của phương pháp chúng tôi, chúng tôi chọn 20 mô hình tạo mã làm baseline để so sánh. Chúng bao gồm hầu hết các công việc đại diện trong sáu năm qua. Ngoài ra, chúng tôi chạy mỗi phương pháp ba lần và báo cáo kết quả trung bình.

Việc triển khai các mô hình. Được biết rộng rãi rằng các mô hình học sâu nhạy cảm với các chi tiết triển khai, bao gồm các siêu tham số và kiến trúc mạng. Trong công việc này, chúng tôi cần triển khai các baseline và phương pháp của chúng tôi. Đối với các baseline, chúng tôi sử dụng mã nguồn được cung cấp bởi các bài báo gốc của chúng và đảm bảo rằng hiệu suất của mô hình có thể so sánh với kết quả được báo cáo của chúng. Đối với phương pháp của chúng tôi, chúng tôi triển khai một phiên bản sử dụng các mạng neural chính thống (chi tiết trong Phần IV-E). Do chi phí huấn luyện cao, chúng tôi thực hiện tìm kiếm lưới phạm vi nhỏ trên một số siêu tham số (tức là tỷ lệ học và kích thước batch), để các siêu tham số khác giống như trong các nghiên cứu trước đây [18], [34], [3]. Do đó, có thể có chỗ để điều chỉnh thêm các siêu tham số và kiến trúc mạng của phương pháp chúng tôi để có thêm cải thiện.

Tác động của mã được truy xuất. Mã được truy xuất là một yếu tố quan trọng trong phương pháp của chúng tôi. Theo trực giác, khi mã được truy xuất ít tương tự với mã mục tiêu, hiệu suất của mô hình chúng tôi có thể bị ảnh hưởng. Để giải quyết mối đe dọa này, chúng tôi có hai suy nghĩ. (1) Một nghiên cứu quy mô lớn trên 13.2 triệu tệp mã thực đã tìm thấy tỷ lệ mã được tái sử dụng lên đến 80% [8]. Do đó, chúng tôi tin rằng rất có thể truy xuất được mã tương tự trong các kịch bản phát triển thực tế. (2) Ngay cả khi mã được truy xuất không tương tự với mã mục tiêu, SKCODER có thể tập trung có chọn lọc vào mã được truy xuất dựa trên yêu cầu hiện tại. Để chứng minh điểm này, chúng tôi chọn ngẫu nhiên các đoạn mã từ kho dữ liệu truy xuất làm mã được truy xuất và huấn luyện một biến thể có tên SKCODER-random. Kết quả được hiển thị trong Bảng VIII. SKCODER-random có sự giảm so với SKCODER nhưng vẫn vượt trội đáng kể so với CodeT5-base. Điều này chứng minh rằng SKCODER có thể trích xuất thích ứng nội dung có giá trị từ mã được truy xuất và có tính mạnh mẽ cao.

BẢNG VIII
HIỆU SUẤT CỦA SKCODER-RANDOM.

Phương pháp | EM | BLEU | CodeBLEU
---|---|---|---
CodeT5-base | 28.91 | 80.46 | 73.11
SKCODER-random | 33.48 (↑15.81%) | 82.07 | 79.08
SKCODER | 35.39 (↑22.41%) | 85.39 | 80.62

VIII. CÔNG VIỆC LIÊN QUAN

Tạo mã nhằm mục đích tạo ra mã nguồn thỏa mãn một mô tả hoặc yêu cầu ngôn ngữ tự nhiên đã cho. Công việc hiện có có thể được chia thành ba loại: mô hình dựa trên chuỗi, mô hình dựa trên cây, và mô hình được tiền huấn luyện.

Mô hình dựa trên chuỗi. Các mô hình dựa trên chuỗi coi mã nguồn như một chuỗi token và sử dụng mạng neural để tạo ra mã nguồn từng token một dựa trên mô tả đầu vào. Ling et al. [12] tạo ra mã nguồn với một cơ chế attention có cấu trúc để xử lý đầu vào bán cấu trúc. Hashimoto et al. [6] huấn luyện một bộ truy xuất phụ thuộc tác vụ để truy xuất mã tương tự, và sau đó sử dụng mã tương tự như một đầu vào bổ sung cho bộ tạo. Wei et al. [41] đề xuất một mô hình tạo mã dựa trên học kép, hoạt động tốt hơn với sự giúp đỡ của tóm tắt mã.

Mô hình dựa trên cây. Chương trình có cấu trúc nghiêm ngặt, và có thể được phân tích thành một cây, ví dụ: Cây cú pháp trừu tượng (AST). Các mô hình dựa trên cây tạo ra một cây phân tích của chương trình dựa trên mô tả NL và sau đó chuyển đổi cây phân tích thành mã tương ứng. Dong et al. [31] tạo ra AST bằng cách mở rộng mọi không-terminal với một mô hình LSTM. Rabinovich et al. [32] tạo ra AST với một decoder có cấu trúc modular được xác định động song song với cấu trúc của AST đầu ra. Yin et al. [1] tạo ra chuỗi hành động xây dựng cây với một mô hình LSTM, và xây dựng AST từ chuỗi hành động. Sun et al. [2] mã hóa ngôn ngữ tự nhiên và các quy tắc ngữ pháp đã được tạo ra với các khối Transformer được thiết kế đặc biệt, và dự đoán quy tắc ngữ pháp tiếp theo tương ứng.

Mô hình được tiền huấn luyện. Những năm gần đây đã chứng kiến sự xuất hiện của các mô hình được tiền huấn luyện [42], [43], [44]. Các mô hình này được tiền huấn luyện trên dữ liệu mã nguồn khổng lồ và sau đó được tinh chỉnh trên tác vụ tạo mã. Các mô hình được tiền huấn luyện có thể được chia thành ba loại.

--- TRANG 11 ---

(1) Các mô hình được tiền huấn luyện chỉ có encoder chỉ chứa một encoder và chủ yếu được sử dụng trong biểu diễn mã. Chúng thường được tiền huấn luyện với các tác vụ hiểu ngôn ngữ, ví dụ: mô hình hóa ngôn ngữ có mask hoặc phát hiện token được thay thế. Các mô hình được tiền huấn luyện chỉ có encoder được đề xuất gần đây bao gồm CodeBERT [33], GraphCodeBERT [34], v.v. (2) Các mô hình được tiền huấn luyện chỉ có decoder được tiền huấn luyện để dự đoán token tiếp theo dựa trên ngữ cảnh đầu vào. Chuỗi GPT [45] là các mô hình chỉ có decoder xuất sắc cho xử lý ngôn ngữ tự nhiên, và có nhiều nỗ lực để điều chỉnh các ý tưởng tương tự vào mã. Lu et al. [35] điều chỉnh mô hình GPT-2 [36] trên mã nguồn, tạo ra CodeGPT. Chen et al. [46] tinh chỉnh mô hình GPT-3 [47] trên mã để tạo ra CodeX và GitHub Copilot [48]. Cả CodeX và GitHub Copilot đều không mở mã nguồn, dẫn đến một số nỗ lực để sao chép CodeX trong ngành và học thuật, tạo ra CodeParrot [27], GPT-CC [28], PyCodeGPT [26], và CodeGen [38]. CodeParrot và CodeGen được huấn luyện từ đầu. PyCodeGPT và GPT-CC được tinh chỉnh từ GPT-Neo[37]. Zan et al. [26] đề xuất một biến thể của PyCodeGPT. Họ đầu tiên tạo ra một phác thảo ẩn danh hóa các hằng số do người dùng định nghĩa, và sau đó tạo ra chương trình hoàn chỉnh từ NL và phác thảo. (3) Các mô hình được tiền huấn luyện encoder-decoder bao gồm một encoder và một decoder. Chúng có thể hỗ trợ cả tác vụ biểu diễn mã và tạo mã. Các kiến trúc encoder-decoder thành công khác nhau trong xử lý ngôn ngữ tự nhiên đã được chuyển giao vào mã nguồn, tạo ra các mô hình mạnh mẽ, ví dụ: CodeT5 [3] và PLBART [39].

Lấy cảm hứng từ việc tái sử dụng mã, một số nghiên cứu giới thiệu mã tương tự để tăng cường các mô hình tạo mã. Hayati et al. [5] truy xuất mã tương tự với đầu vào, và sao chép các hành động n-gram từ mã tương tự trong quá trình giải mã. Hashimoto et al. [6] và Parvez et al. [7] truy xuất các đoạn mã tương tự và đưa chúng cùng với mô tả đầu vào cho một bộ tạo. Họ huấn luyện bộ tạo để học cách sao chép một số nội dung có thể tái sử dụng từ mã tương tự. Chúng tôi gọi những nghiên cứu này là các phương pháp hướng sao chép. Khác với các phương pháp hướng sao chép, SKCODER hướng phác thảo của chúng tôi bắt chước hành vi tái sử dụng mã của các nhà phát triển, trích xuất nội dung có liên quan đến yêu cầu đầu vào và bỏ qua các phần không liên quan trong mã tương tự. Nội dung được trích xuất được xem như một phác thảo mã và tiếp tục được chỉnh sửa thành mã mục tiêu với sự hướng dẫn của yêu cầu đầu vào.

IX. KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Trong quá trình phát triển phần mềm, các nhà phát triển con người thường tái sử dụng các đoạn mã tương tự. Trong bài báo này, chúng tôi đề xuất một phương pháp tạo mã dựa trên phác thảo mới có tên SKCODER để bắt chước hành vi tái sử dụng mã của các nhà phát triển. Khác với các phương pháp dựa trên sao chép trước đây, SKCODER có thể trích xuất nội dung liên quan từ mã tương tự được truy xuất và xây dựng một phác thảo mã. Phác thảo sau đó được chỉnh sửa bằng cách thêm nhiều chi tiết cụ thể theo yêu cầu. Chúng tôi thực hiện thí nghiệm trên hai bộ dữ liệu tạo mã công khai và một bộ dữ liệu Java mới được thu thập bởi công việc này. Bộ dữ liệu mới chứa 200k cặp NL-mã và mỗi mẫu thử nghiệm được trang bị một tập hợp các bài kiểm tra đơn vị. Kết quả thí nghiệm cho thấy SKCODER vượt trội đáng kể so với các baseline state-of-the-art. Nghiên cứu ablation chứng minh tính hiệu quả của phác thảo mã và phương pháp của chúng tôi hiệu quả với các mạng neural khác nhau. Trong tương lai, chúng tôi sẽ khám phá các bộ phác thảo hiệu quả hơn và áp dụng ý tưởng dựa trên phác thảo của chúng tôi cho các mô hình được tiền huấn luyện quy mô lớn.

LỜI CẢM ơN

Nghiên cứu này được hỗ trợ bởi Chương trình R&D Chính quốc gia dưới Grant No. 2021ZD0110303, Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc dưới Grant Nos. 62192731, 61751210, 62072007, 62192733, 61832009, và 62192730.

TÀI LIỆU THAM KHẢO

[1] P. Yin và G. Neubig, "Tranx: A transition-based neural abstract syntax parser for semantic parsing and code generation," trong Proceedings of the Conference on Empirical Methods in Natural Language Processing (Demo Track), 2018.

[2] Z. Sun, Q. Zhu, Y. Xiong, Y. Sun, L. Mou, và L. Zhang, "Treegen: A tree-based transformer architecture for code generation," trong Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 05, 2020, pp. 8984–8991.

[3] Y. Wang, W. Wang, S. Joty, và S. C. Hoi, "Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation," trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 2021, pp. 8696–8708.

[4] S. Haefliger, G. Von Krogh, và S. Spaeth, "Code reuse in open source software," Management science, vol. 54, no. 1, pp. 180–193, 2008.

[5] S. A. Hayati, R. Olivier, P. Avvaru, P. Yin, A. Tomasic, và G. Neubig, "Retrieval-based neural code generation," trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018.

[6] T. B. Hashimoto, K. Guu, Y. Oren, và P. S. Liang, "A retrieve-and-edit framework for predicting structured outputs," Advances in Neural Information Processing Systems, vol. 31, 2018.

[7] M. R. Parvez, W. Ahmad, S. Chakraborty, B. Ray, và K.-W. Chang, "Retrieval augmented code generation and summarization," trong Findings of the Association for Computational Linguistics: EMNLP 2021, 2021, pp. 2719–2734.

[8] A. Mockus, "Large-scale code reuse in open source software," trong First International Workshop on Emerging Trends in FLOSS Research and Development (FLOSS'07: ICSE Workshops 2007). IEEE, 2007, pp. 7–7.

[9] [Trực tuyến]. Có sẵn: https://stackoverflow.com/

[10] J. Wang, Y. Dang, H. Zhang, K. Chen, T. Xie, và D. Zhang, "Mining succinct and high-coverage api usage patterns from source code," trong 2013 10th Working Conference on Mining Software Repositories (MSR). IEEE, 2013, pp. 319–328.

[11] H. Niu, I. Keivanloo, và Y. Zou, "Api usage pattern recommendation for software development," Journal of Systems and Software, vol. 129, pp. 127–139, 2017.

[12] W. Ling, P. Blunsom, E. Grefenstette, K. M. Hermann, T. Kočiský, F. Wang, và A. Senior, "Latent predictor networks for code generation," trong Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2016, pp. 599–609.

[13] K. Papineni, S. Roukos, T. Ward, và W.-J. Zhu, "Bleu: a method for automatic evaluation of machine translation," trong Proceedings of the 40th annual meeting of the Association for Computational Linguistics, 2002, pp. 311–318.

[14] S. Ren, D. Guo, S. Lu, L. Zhou, S. Liu, D. Tang, N. Sundaresan, M. Zhou, A. Blanco, và S. Ma, "Codebleu: a method for automatic evaluation of code synthesis," arXiv preprint arXiv:2009.10297, 2020.

[15] [Trực tuyến]. Có sẵn: https://github.com/LJ2lijia/SkCoder

[16] S. Robertson, H. Zaragoza et al., "The probabilistic relevance framework: Bm25 and beyond," Foundations and Trends® in Information Retrieval, vol. 3, no. 4, pp. 333–389, 2009.

[17] B. Wei, Y. Li, G. Li, X. Xia, và Z. Jin, "Retrieve and refine: exemplar-based neural comment generation," trong 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2020, pp. 349–360.

--- TRANG 12 ---

[18] J. Li, Y. Li, G. Li, X. Hu, X. Xia, và Z. Jin, "Editsum: A retrieve-and-edit framework for source code summarization," trong 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2021, pp. 155–166.

[19] S. Lu, N. Duan, H. Han, D. Guo, S.-w. Hwang, và A. Svyatkovskiy, "Reacc: A retrieval-augmented code completion framework," trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 6227–6240.

[20] [Trực tuyến]. Có sẵn: https://lucene.apache.org

[21] X. Gu, H. Zhang, và S. Kim, "Deep code search," trong 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE, 2018, pp. 933–944.

[22] J. Cambronero, H. Li, S. Kim, K. Sen, và S. Chandra, "When deep learning met code search," trong Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2019, pp. 964–974.

[23] R. A. Wagner và M. J. Fischer, "The string-to-string correction problem," Journal of the ACM (JACM), vol. 21, no. 1, pp. 168–173, 1974.

[24] Y. Hao, G. Li, Y. Liu, X. Miao, H. Zong, S. Jiang, Y. Liu, và H. Wei, "Aixbench: A code generation benchmark dataset," arXiv preprint arXiv:2206.13179, 2022.

[25] [Trực tuyến]. Có sẵn: https://github.com/

[26] D. Zan, B. Chen, D. Yang, Z. Lin, M. Kim, B. Guan, Y. Wang, W. Chen, và J.-G. Lou, "Cert: Continual pre-training on sketches for library-oriented code generation," trong Proceedings of the 31-th International Joint Conference on Artificial Intelligence (IJCAI 2022).

[27] [Trực tuyến]. Có sẵn: https://huggingface.co/codeparrot/codeparrot

[28] [Trực tuyến]. Có sẵn: https://github.com/CodedotAl/gpt-code-clippy

[29] W. Zaremba, I. Sutskever, và O. Vinyals, "Recurrent neural network regularization," arXiv preprint arXiv:1409.2329, 2014.

[30] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, và I. Polosukhin, "Attention is all you need," Advances in neural information processing systems, vol. 30, 2017.

[31] L. Dong và M. Lapata, "Language to logical form with neural attention," trong 54th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics (ACL), 2016, pp. 33–43.

[32] M. Rabinovich, M. Stern, và D. Klein, "Abstract syntax networks for code generation and semantic parsing," trong Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2017, pp. 1139–1149.

[33] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang et al., "Codebert: A pre-trained model for programming and natural languages," trong Findings of the Association for Computational Linguistics: EMNLP 2020, 2020, pp. 1536–1547.

[34] D. Guo, S. Ren, S. Lu, Z. Feng, D. Tang, L. Shujie, L. Zhou, N. Duan, A. Svyatkovskiy, S. Fu et al., "Graphcodebert: Pre-training code representations with data flow," trong International Conference on Learning Representations, 2020.

[35] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy, A. Blanco, C. Clement, D. Drain, D. Jiang, D. Tang et al., "Codexglue: A machine learning benchmark dataset for code understanding and generation," trong Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1), 2021.

[36] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al., "Language models are unsupervised multitask learners," OpenAI blog, vol. 1, no. 8, p. 9, 2019.

[37] S. Black, L. Gao, P. Wang, C. Leahy, và S. Biderman, "Gpt-neo: Large scale autoregressive language modeling with mesh-tensorflow, march 2021," URL https://doi.org/10.5281/zenodo, vol. 5297715.

[38] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese, và C. Xiong, "A conversational paradigm for program synthesis," arXiv preprint arXiv:2203.13474, 2022.

[39] W. U. Ahmad, S. Chakraborty, B. Ray, và K.-W. Chang, "Unified pre-training for program understanding and generation," arXiv preprint arXiv:2103.06333, 2021.

[40] M. Evtikhiev, E. Bogomolov, Y. Sokolov, và T. Bryksin, "Out of the bleu: how should we assess quality of the code generation models?" arXiv preprint arXiv:2208.03133, 2022.

[41] B. Wei, G. Li, X. Xia, Z. Fu, và Z. Jin, "Code generation as a dual task of code summarization," Advances in neural information processing systems, vol. 32, 2019.

[42] J. Li, G. Li, Z. Li, Z. Jin, X. Hu, K. Zhang, và Z. Fu, "Codeeditor: Learning to edit source code with pre-trained models," arXiv preprint arXiv:2210.17040, 2022.

[43] J. Li, Y. Zhao, Y. Li, G. Li, và Z. Jin, "Towards enhancing in-context learning for code generation," arXiv preprint arXiv:2303.17780, 2023.

[44] J. Li, G. Li, Y. Li, và Z. Jin, "Enabling programming thinking in large language models toward code generation," arXiv preprint arXiv:2305.06599, 2023.

[45] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever et al., "Improving language understanding by generative pre-training," 2018.

[46] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman et al., "Evaluating large language models trained on code," arXiv preprint arXiv:2107.03374, 2021.

[47] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., "Language models are few-shot learners," Advances in neural information processing systems, vol. 33, pp. 1877–1901, 2020.

[48] [Trực tuyến]. Có sẵn: https://github.com/features/copilot

PYInfer: Suy luận kiểu ngữ nghĩa học sâu cho các biến Python

Siwei Cui
Đại học Texas A&M
College Station, Texas
siweicui@tamu.edu

Luochao Wang
Đại học Texas A&M
College Station, Texas
wangluochao@tamu.edu

Gang Zhao
Đại học Texas A&M
College Station, Texas
zhaogang92@tamu.edu

Ruihong Huang
Đại học Texas A&M
College Station, Texas
huangrh@cse.tamu.edu

Zeyu Dai
Đại học Texas A&M
College Station, Texas
jzdaizeyu@tamu.edu

Jeff Huang
Đại học Texas A&M
College Station, Texas
jeffhuang@tamu.edu

Tóm tắt — Suy luận kiểu Python là một thách thức trong thực tế. Do tính chất động và sự phụ thuộc rộng rãi vào các thư viện bên thứ ba không có chú thích kiểu, hiệu suất của các kỹ thuật phân tích tĩnh truyền thống bị hạn chế. Mặc dù ngữ nghĩa trong mã nguồn có thể giúp thể hiện cách sử dụng dự định cho các biến (do đó giúp suy luận kiểu), chúng thường bị bỏ qua bởi các công cụ hiện có. Trong bài báo này, chúng tôi đề xuất PYInfer, một công cụ suy luận kiểu từ đầu đến cuối dựa trên học máy tự động tạo chú thích kiểu cho các biến Python. Ý tưởng chính là ngữ nghĩa mã ngữ cảnh rất quan trọng trong việc suy luận kiểu cho một biến. Đối với mỗi cách sử dụng của một biến, chúng tôi thu thập một vài token trong phạm vi ngữ cảnh của nó và thiết kế một mạng nơ-ron để dự đoán kiểu của nó. Một thách thức là rất khó để thu thập một tập dữ liệu huấn luyện được gán nhãn bởi con người chất lượng cao cho mục đích này. Để giải quyết vấn đề này, chúng tôi áp dụng một bộ phân tích tĩnh hiện có để tạo ra sự thật cơ sở cho các biến trong mã nguồn.

Đóng góp chính của chúng tôi là một phương pháp mới để suy luận kiểu biến tĩnh một cách hiệu quả và hiệu suất. Xây dựng suy luận kiểu như một bài toán phân loại, chúng tôi có thể xử lý các kiểu do người dùng định nghĩa và dự đoán xác suất kiểu cho từng biến. Mô hình của chúng tôi đạt được độ chính xác 91.2% khi phân loại 11 kiểu cơ bản trong Python và độ chính xác 81.2% khi phân loại 500 kiểu phổ biến nhất. Kết quả của chúng tôi vượt trội đáng kể so với các công cụ chú thích kiểu tốt nhất hiện tại. Hơn nữa, PYInfer đạt được độ bao phủ mã nhiều hơn 5.2 lần và nhanh hơn 187 lần so với một công cụ dựa trên học máy tốt nhất hiện tại. Với thời gian tiêu thụ tương tự, mô hình của chúng tôi chú thích nhiều biến hơn 5 lần so với một công cụ phân tích tĩnh tốt nhất hiện tại (PySonar2). Mô hình của chúng tôi cũng vượt trội hơn một công cụ chú thích cấp hàm dựa trên học máy (TypeWriter) trong việc chú thích kiểu cho các biến và tham số hàm. Tất cả các công cụ và tập dữ liệu của chúng tôi đều được công khai để tạo điều kiện cho nghiên cứu tương lai theo hướng này.

Từ khóa chỉ mục — Suy luận kiểu Python, Ngữ nghĩa mã ngữ cảnh, Học sâu.

I. GIỚI THIỆU

Python được sử dụng rộng rãi do tính linh hoạt và sự phong phú của các thư viện bên thứ ba (ví dụ: các framework web và học máy). Tuy nhiên, tính linh hoạt mang đến những thách thức cho việc tối ưu hóa mã và cũng làm cho nó dễ xảy ra lỗi. Sự không nhất quán kiểu biến là một lỗi phổ biến trong các ngôn ngữ động. Do tính chất động của Python, trình thông dịch không thể kiểm tra sự không nhất quán kiểu như một trình biên dịch ngôn ngữ lập trình tĩnh (ví dụ: Go hoặc Rust). Các công cụ kiểm tra kiểu Python [1, 2, 3, 4] tận dụng các chú thích để phát hiện sự không nhất quán kiểu. Những công cụ này chủ yếu dựa vào các chú thích kiểu được viết thủ công bởi các nhà phát triển, điều này tốn kém để cung cấp.

Để tạo điều kiện thuận lợi cho việc lập trình của người dùng và kiểm tra lỗi kiểu, suy luận kiểu biến là một bước cần thiết. Học sâu đã được áp dụng để suy luận kiểu cho JavaScript [5, 6, 7, 8] bằng cách tận dụng TypeScript [9] để tạo ra corpus lớn với các chú thích chính xác. Tuy nhiên, tồn tại ít giải pháp tốt cho Python do phạm vi rộng của các tính năng động và sự phụ thuộc rộng rãi vào các thư viện bên thứ ba, điều này để lại cho chúng ta nhiều cơ hội trong phạm vi này. Chất lượng của tập dữ liệu tự nó mang lại một khoảng cách lớn giữa việc chú thích Python và JavaScript.

Các công cụ suy luận kiểu áp dụng phân tích tĩnh hoặc phân tích động [10, 11, 12] không yêu cầu chú thích được gán nhãn cho suy luận kiểu. Tuy nhiên, chúng không chính xác và bỏ qua ngữ nghĩa ngôn ngữ tự nhiên phong phú trong mã nguồn. Xu và cộng sự [13] đề xuất sử dụng một mô hình xác suất để suy luận kiểu biến bằng cách tận dụng các gợi ý kiểu từ luồng dữ liệu, thuộc tính, kiểu con và tên biến. Tuy nhiên, việc này mất thời gian đáng kể để phân tích mã nguồn và giải quyết các ràng buộc xác suất. Không có một tập dữ liệu đủ lớn để cung cấp đủ tín hiệu, hiệu suất của mô hình xác suất cũng bị hạn chế.

Các chú thích kiểu được gán nhãn bởi con người hiện có trong mypy [1] và typeshed [14] chỉ bao gồm một vài chú thích cho tham số hàm và kiểu trả về. Tập dữ liệu không chứa chú thích biến và không đủ để suy luận kiểu biến Python. TypeWriter [15] cũng nhắm đến suy luận kiểu cho Python, nhưng nó giải quyết vấn đề suy luận tham số hàm và kiểu trả về. Thí nghiệm cho thấy TypeWriter không đủ cho dự đoán kiểu biến. Các chú thích cấp hàm (tham số hàm và kiểu trả về) hữu ích để phục vụ như một hợp đồng API cho IDE, trong khi các chú thích cấp biến có thể được sử dụng để cung cấp kiểm tra kiểu cho từng biến.

Trong bài báo này, chúng tôi trình bày PYInfer, một phương pháp dựa trên học sâu để tạo chú thích kiểu cho Python. Một cái nhìn tổng quan cấp cao về PYInfer được mô tả trong Hình 1. Vì tập dữ liệu được gán nhãn bởi con người cho các biến không có sẵn, đầu tiên chúng tôi sử dụng một bộ phân tích tĩnh, PySonar2 [16], để tự động tạo các chú thích ban đầu từ các dự án Python GitHub hàng đầu. Sau đó chúng tôi áp dụng một loạt các kỹ thuật làm sạch dữ liệu để tinh chỉnh chất lượng của tập dữ liệu. Chúng tôi tiếp tục đưa các chú thích và thông tin ngữ cảnh vào để huấn luyện một mạng nơ-ron sâu, mạng này xếp hạng từng kiểu với xác suất một cách hiệu quả.

Chúng tôi nhấn mạnh rằng việc kết hợp học sâu với phân tích tĩnh để suy luận chú thích kiểu là đầy hứa hẹn. Bằng cách kết hợp học sâu với phân tích tĩnh từ đầu đến cuối, phương pháp của chúng tôi có khả năng phân tích ngữ nghĩa mã với các kỹ thuật xử lý ngôn ngữ tự nhiên (NLP) được phát triển tốt. Hiệu quả của PYInfer được hưởng lợi từ việc giải quyết các thách thức sau:

Thu thập tập dữ liệu chú thích. Phân tích ngữ nghĩa mã nguồn ngữ cảnh cho kiểu biến đòi hỏi một tập dữ liệu chú thích lớn. Tuy nhiên, không tồn tại tập dữ liệu lớn được công nhận rộng rãi với các chú thích. Chúng tôi tạo ra tập dữ liệu chú thích của mình với dữ liệu được làm giàu dựa trên kết quả suy luận từ PySonar2 và thực hiện làm sạch dữ liệu để nâng cao chất lượng, điều này tự nó là một đóng góp đáng kể, bởi vì dữ liệu được gán nhãn chất lượng cao là quan trọng cho học sâu. Tập dữ liệu của chúng tôi được thu thập từ 4,577 dự án Python phổ biến trên GitHub với 54,928,617 Dòng mã (LoC) từ 320,402 tệp nguồn. Nó chứa 77,089,946 chú thích, đủ lớn cho hầu hết nghiên cứu kiểu Python.

Kiểu do người dùng định nghĩa. Do tính linh hoạt của Python, các kiểu có thể được người dùng định nghĩa và thay đổi trong thời gian chạy. Chúng tôi khung suy luận kiểu Python như một nhiệm vụ phân loại để bao phủ các kiểu do người dùng định nghĩa trong 500 kiểu phổ biến nhất của chúng tôi. Chúng tôi điều tra hiệu suất của 11 kiểu cơ bản so với 500 kiểu. Mô hình của chúng tôi đạt được độ chính xác 91.187% khi phân loại 11 kiểu cơ bản và 81.195% khi dự đoán 500 kiểu. Đây là một tiến bộ đáng kể so với công việc trước đây [13] về vấn đề này. Như một nhiệm vụ phân loại, mô hình của chúng tôi cung cấp mức độ tin cậy cho từng kiểu. Nó đạt được độ chính xác 97.677% với ngưỡng 0.9 trên mức độ tin cậy.

Nhúng mã nguồn. Mã nguồn chứa thông tin ngữ nghĩa phong phú và gợi ý kiểu trong tên biến và cách sử dụng, điều này hữu ích cho suy luận kiểu. Công việc trước đây [6, 13, 15] đã áp dụng nhúng từ cho suy luận kiểu. Tuy nhiên, chúng tôi cho thấy rằng những nhúng này không hoạt động tốt do vấn đề Ngoài từ vựng (OOV) gây ra bởi số lượng lớn các tính năng động và kiểu do người dùng định nghĩa trong Python. Để giải quyết vấn đề này, chúng tôi sử dụng thuật toán Mã hóa cặp byte (BPE) [17]. Nó cung cấp đủ tín hiệu để phân tích ngữ nghĩa trong tên biến và dữ liệu ngữ cảnh. So với nhúng dựa trên đồ thị trong LambdaNet [8], nhúng BPE nhẹ và có thể dễ dàng mở rộng để phân tích các ngôn ngữ khác. Chúng tôi chứng minh rằng BPE hiệu quả trong việc suy luận kiểu biến. Mô hình của chúng tôi cải thiện độ chính xác 27.1% với nhúng BPE so với nhúng GloVe [18].

Ngữ nghĩa mã ngữ cảnh. Một ý tưởng chính trong phương pháp của chúng tôi là tận dụng ngữ nghĩa mã ngữ cảnh để suy luận kiểu biến. Chúng tôi giả định rằng ngữ cảnh trong một biên độ nhất định truyền đạt thông tin ngữ nghĩa có liên quan để đặc trưng cho biến. Được truyền cảm hứng bởi phân tích tĩnh liên thủ tục [10, 11, 12], phương pháp của chúng tôi có khả năng phân tích ngữ nghĩa của các biến cùng với thông tin cú pháp và ngữ pháp cấu trúc. Việc thiết lập siêu tham số biên độ được minh họa trong Hình 2. Đối với mỗi biến, chúng tôi thu thập các token mã nguồn trong phạm vi ngữ cảnh của nó. Chúng tôi áp dụng Đơn vị Tái phát có cổng (GRU) [19] với cơ chế chú ý [20] để phân tích ngữ nghĩa ngữ cảnh. Thử nghiệm loại bỏ của chúng tôi về thông tin ngữ cảnh cho thấy cải thiện 41.0% về độ chính xác. Đánh giá của chúng tôi trên tập dữ liệu typeshed [14] được gán nhãn bởi con người chứng minh cùng một kết quả. Thông tin ngữ cảnh cung cấp ngữ nghĩa cục bộ cho các biến, và nó hữu ích để rút ra các chú thích biến.

Kết hợp tất cả những đóng góp này lại với nhau, chúng tôi phát triển một framework từ đầu đến cuối, hiệu quả cao và hiệu suất để suy luận kiểu biến cho Python một cách tĩnh. Tập dữ liệu của chúng tôi đủ lớn cho hầu hết nghiên cứu dưới kiểu Python, điều này tự nó là một đóng góp mới. Chúng tôi đạt được độ chính xác 91.187% trên 11 kiểu cơ bản và 81.195% trên 500 kiểu phổ biến nhất. PYInfer chứng minh ưu thế về cả độ bao phủ và hiệu quả thời gian trên các dự án lớn so với công việc hiện có [13]. Thay vì gán trọng số cho nhiều yếu tố cho suy luận xác suất [13], PYInfer đạt được độ bao phủ nhiều hơn 5.2 lần và nhanh hơn 187.4 lần. Mô hình của chúng tôi chú thích một biến trung bình trong 1 mili giây. So với PySonar2, công cụ của chúng tôi mất thời gian tương tự để phân tích nhưng tạo ra nhiều chú thích hơn 5 lần. Một ví dụ thúc đẩy so sánh PYInfer và PySonar2 được cung cấp trong Phần V. Mặc dù được huấn luyện trên các chú thích được tạo bởi PySonar2, PYInfer có thể xử lý các trường hợp phức tạp sử dụng ngữ nghĩa mã ngữ cảnh, như được hiển thị trong Hình 5. PYInfer cũng có thể được mở rộng để thực hiện suy luận tham số hàm. Nó cho thấy ưu thế so với TypeWriter trong việc suy luận kiểu biến và tham số hàm.

Chúng tôi đã phát hành mô hình PYInfer, mã nguồn và tập dữ liệu để tạo điều kiện cho nghiên cứu tiếp theo¹. Các công cụ kiểm tra kiểu hiện có có thể được hưởng lợi từ các chú thích kiểu được tạo bởi PYInfer để phát hiện sự không nhất quán kiểu. Chúng tôi cung cấp một quy trình làm việc về việc tích hợp PYInfer với pyre để phát hiện sự không nhất quán biến trong các kho lưu trữ Python. Như một công cụ chú thích kiểu tĩnh từ đầu đến cuối, ¹Liên kết sẽ được cung cấp sau quá trình đánh giá kép mù.

PYInfer cung cấp các chú thích với xác suất trong 1 ms cho một biến. Nó cung cấp chú thích kiểu cho các lập trình viên một cách liền mạch trong khi họ đang lập trình. Framework của chúng tôi cũng có thể được sử dụng để suy luận kiểu tham số. Vì phương pháp của chúng tôi dựa vào ngữ nghĩa cấp cao hơn là cấu trúc đồ thị, nó có thể dễ dàng được mở rộng để chú thích các biến và phát hiện lỗi ngữ nghĩa trong các ngôn ngữ gõ động khác.

II. FRAMEWORK PYINFER

Hình 3 trình bày một cái nhìn tổng quan kỹ thuật về mô hình PYInfer. Ý tưởng cơ bản là xây dựng suy luận kiểu như một bài toán phân loại. Chúng tôi kiểm tra top 500 kiểu dựa trên tần suất xuất hiện và phân tích ngữ nghĩa ngữ cảnh trong một biên độ nhất định. Thuật toán BPE được áp dụng để rút ra biểu diễn vector như nhúng. Chúng tôi tiếp tục đưa những nhúng này vào một mạng GRU với cơ chế chú ý để trích xuất ngữ nghĩa mã từ ngữ cảnh. Sau đó chúng tôi sử dụng một lớp softmax để phân loại từng kiểu với xác suất. PYInfer bao gồm bốn thành phần sau: thu thập và tạo dữ liệu, nhúng mã nguồn, xây dựng mô hình và huấn luyện mô hình.

A. Thu thập và tạo dữ liệu

Để phân loại kiểu biến, chúng tôi cần một tập dữ liệu chú thích đủ lớn. Vì tập dữ liệu chú thích biến được gán nhãn bởi con người không có sẵn, chúng tôi áp dụng PySonar2 để tạo các chú thích ban đầu. Vì PySonar2 thực hiện phân tích bảo thủ, chúng tôi bỏ qua tất cả các biến mà nó không thể suy luận kiểu và giả định kết quả cho các biến còn lại là sự thật cơ sở (mặc dù các kiểu có thể được xấp xỉ quá mức). Chúng tôi cũng phân tích typeshed [14], probPY [13] và tập dữ liệu TypeWriter [15]. Tập dữ liệu của chúng tôi được tóm tắt trong Bảng I. Gốc và Hợp lệ thể hiện số lượng chú thích trước và sau khi làm sạch dữ liệu và khử trùng lặp. typePY là tập dữ liệu mã nguồn của chúng tôi được thu thập từ 4,577 kho lưu trữ GitHub hàng đầu. probPY đại diện cho tập dữ liệu được xuất bản trong Xu và cộng sự [13], và typeshed là một tập dữ liệu được gán nhãn bởi con người chỉ chứa các chú thích cho tham số hàm và giá trị trả về [14].

Chúng tôi thu thập tập dữ liệu typePY bằng cách chú thích mã nguồn Python trong các kho lưu trữ GitHub hàng đầu. Đối với mỗi biến, chúng tôi lưu trữ liên kết đến kho lưu trữ, tên tệp, tên biến, vị trí token bắt đầu và kết thúc, chú thích kiểu và mã nguồn tương ứng. Để có được chú thích kiểu, chúng tôi áp dụng PySonar2, một bộ chỉ mục ngữ nghĩa tiên tiến cho Python [16], để suy luận kiểu cho từng biến. Chúng tôi có được 77,089,946 chú thích từ 320,402 tệp mã nguồn Python. Vì PySonar2 chỉ có 49.47% độ bao phủ trên các chú thích [13], chúng tôi cũng tinh chỉnh tập dữ liệu của mình với một loạt các kỹ thuật làm sạch dữ liệu. Chúng tôi loại bỏ tất cả các kiểu vô nghĩa, chẳng hạn như "dấu hỏi" và kiểu "None", và thực hiện khử trùng lặp. Cuối cùng, chúng tôi có được 42,560,876 chú thích hợp lệ. Theo hiểu biết tốt nhất của chúng tôi, đây là tập dữ liệu chú thích Python lớn nhất. Chúng tôi phát hành tập dữ liệu này để tạo điều kiện cho nghiên cứu về chủ đề này.

BẢNG I: Siêu dữ liệu cho tập dữ liệu typePY, probPY và typeshed.

Tập dữ liệu | Tệp Python | LoC | Gốc | Hợp lệ
typePY | 320,402 | 54,928,617 | 77,089,946 | 42,560,876
Tập dữ liệu probPY | 716 | 146,019 | 106,808 | 64,831
typeshed stdlib | 545 | 34,854 | 38,536 | 14,685
bên thứ ba | 564 | 23,877 | 17,632 | 8,957

Đối với tập dữ liệu probPY [13], chúng tôi khai thác dữ liệu được hợp nhất kết hợp kết quả của PySonar2 và phân tích động. Tập dữ liệu probPY cung cấp tên biến, chú thích và mã nguồn để tạo thông tin ngữ cảnh cho mô hình của chúng tôi. Chúng tôi có thể so sánh thời gian tiêu thụ và độ bao phủ giữa PYInfer, PySonar2 và mô hình probPY.

Tập dữ liệu typeshed chứa các chú thích kiểu được gán nhãn bởi con người cho các thư viện tiêu chuẩn Python và gói bên thứ ba, làm cho nó đáng tin cậy hơn. Tuy nhiên, tập dữ liệu typeshed chỉ bao gồm các chú thích cho tham số hàm và kiểu trả về, và không có thông tin ngữ cảnh do cập nhật mã thường xuyên. Chúng tôi trích xuất các chú thích tham số để đánh giá mô hình của chúng tôi về tầm quan trọng của ngữ nghĩa mã ngữ cảnh. Sau khi hợp nhất các chú thích trong thư viện bên thứ ba với thư viện tiêu chuẩn, chúng tôi khử trùng lặp các chú thích trên các cặp [tên biến, chú thích kiểu]. Cuối cùng chúng tôi có được 3,379 kiểu khác nhau với 16,537 chú thích trong tập dữ liệu này. Những bản sao trùng lặp hơn 30.1% cho thấy các lập trình viên có khả năng áp dụng tên tương tự trên các biến với chức năng tương tự.

B. Nhúng mã nguồn

Phương pháp nhúng thông thường xây dựng một từ điển trên các token được sử dụng thường xuyên và tạo nhúng cho mỗi token trong từ vựng. Phương pháp này đảm bảo rằng mỗi token giữ nguyên vẹn khi đưa vào mô hình. Nhiều phương pháp hiện có, chẳng hạn như Word2Vec [21] và Vectors Toàn cầu cho biểu diễn từ (GloVe) [18], lấy biểu diễn vector hóa của mỗi token. Tuy nhiên, các phương pháp nhúng từ không phù hợp cho mã nguồn. Với rất nhiều tên biến và tên hàm do người dùng định nghĩa, những phương pháp này thường gặp phải OOV vì các từ hiếm không được quan sát trong dữ liệu huấn luyện. OOV làm cho mô hình không thể hấp thụ bất kỳ thông tin nào từ các token không có trong từ vựng. Một giải pháp tầm thường là sử dụng <UNK> để đại diện cho các từ không xác định, điều này không phù hợp do mất ý nghĩa ngữ nghĩa.

Để nắm bắt những ngữ nghĩa đó trong tên biến và hàm, chúng tôi áp dụng thuật toán BPE [17] để tạo nhúng cho mã nguồn. Thuật toán BPE lần đầu tiên được biết đến như một thuật toán nén [22, 23] và hiệu quả trong nhiều tác vụ phân tích chương trình với mạng nơ-ron [17, 24, 25, 26, 27]. Thuật toán này giảm thiểu OOV bằng cách hợp nhất một cặp byte thường xuyên nhất thành một byte mới. Bắt đầu với một ký tự riêng lẻ, chúng tôi đặc trưng cho các token do người dùng định nghĩa bằng cách chia chúng thành các mảnh nhỏ hơn trong từ điển của chúng tôi. Chúng tôi áp dụng phương pháp phân cụm từ dưới lên và ban đầu tạo unigram cho tất cả các ký tự. Sau đó, chúng tôi lặp lại tính toán tần suất của n-gram và sử dụng xấp xỉ tham lam để tối đa hóa log-likelihood của mô hình ngôn ngữ để tạo n-gram mới cho các cặp n-gram thường xuyên nhất [28].

Chúng tôi huấn luyện mô hình BPE của mình trên corpus mã nguồn và có được 19,995 từ cơ sở khác nhau để tạo nhúng. So với các phương pháp nhúng thông thường, nhúng BPE tận dụng tối đa ngữ nghĩa mã ngữ cảnh bằng cách giải quyết OOV. Chúng tôi chứng minh rằng BPE hiệu quả trong việc nhúng mã nguồn Python cho chú thích biến. Tên biến sử dụng snake case (ví dụ: network address) hoặc camel case có thể được nhúng hiệu quả bằng BPE.

C. Xây dựng mô hình

Một trong những ý tưởng chính là chúng tôi mang thông tin ngữ cảnh vào mô hình của mình. Các ngữ cảnh trong mã nguồn không chỉ mang kiến thức ngữ nghĩa có ý nghĩa mà còn cung cấp các manh mối và hiểu biết về chức năng biến. Chúng tôi thiết lập biên độ m để chỉ ra bao nhiêu thông tin ngữ cảnh sẽ được xem xét. Việc thiết lập biên độ được minh họa trong Hình 2. Đối với mỗi biến vi, i ∈ [1::n], chúng tôi xử lý dòng hiện tại sở hữu biến hiện tại, được chú thích là dc_i, m token trước dòng hiện tại, như được chú thích với de_i, m token sau dòng hiện tại, được biểu diễn là da_i, và tên của biến hiện tại dn_i. Thông tin ngữ cảnh cung cấp ngữ nghĩa cục bộ cho các biến, đủ để rút ra các chú thích biến. Để thuật toán BPE là B(), và chúng tôi có thể hoàn thiện nhúng Xi của chúng tôi cho biến vi như:

Xi = B(de_i) + B(dc_i) + B(da_i) + B(dn_i);

trong đó "+" đại diện cho phép nối trên hai vector nhúng. Chúng tôi cố ý gán các nhúng của tên biến trong phần sau của nhúng. Thiết lập này cho phép chúng tôi có được biểu diễn ngữ nghĩa bằng cách trích xuất mẫu trong lớp cuối cùng trong mô hình GRU của chúng tôi.

Để đặc trưng cho các tính năng nhúng một cách toàn diện, chúng tôi áp dụng Đơn vị Tái phát có cổng (GRU) [19], một mạng nơ-ron tái phát (RNN) [29] có hiệu suất tương tự so với mạng nơ-ron tái phát hai chiều [29] nhưng với độ phức tạp tính toán thấp hơn. GRU được sử dụng để phân tích và đặc trưng cho nhúng mã nguồn của chúng tôi theo cách vượt trội. Đối với mỗi biến, GRU được áp dụng để phân tích đặc trưng của thông tin ngữ cảnh kết hợp với tên biến. Nó có khả năng xử lý một chuỗi vector bằng cách áp dụng công thức tái phát tại mỗi bước thời gian t. Ban đầu, chúng ta có vector đầu ra h0 = 0 khi t = 0. Giả sử số lượng token sau khi nhúng là si cho biến vi. Đối với mỗi token mã nguồn đầu vào xt, trong đó t ∈ [1::si] trong nhúng Xi, chúng ta có:

zt = σ(Wzxt + Uzht-1 + bz);
rt = σ(Wrxt + Urht-1 + bz);
ht = ztht-1 + (1-zt) ⊙ tanh(Whxt + Uh(rt ⊙ ht-1) + bh);

trong đó xt là nhúng đầu vào của chúng tôi với thông tin ngữ cảnh, ht là vector đầu ra của chúng tôi cho biến vi này, zt là cổng cập nhật và rt là cổng đặt lại, và W, U và b là các tham số trong mô hình của chúng tôi. σ đại diện cho hàm sigmoid, và tanh biểu thị tiếp tuyến hyperbolic. Cơ chế chú ý [20] cũng được thêm vào mô hình của chúng tôi để có hiệu suất đáng tin cậy hơn. Vì tên biến được thêm vào vị trí cuối cùng của vector nhúng, chúng tôi có thể trích xuất lớp cuối cùng trong vector đầu ra hsi để đặc trưng cho biến Xi. Một lớp dropout được gắn vào mô hình GRU để giải quyết vấn đề overfitting một cách thích hợp. Cuối cùng, chúng tôi gắn một lớp kết nối đầy đủ vào đầu ra của mô hình GRU để cung cấp cho mô hình của chúng tôi tính linh hoạt hơn trong việc học ngữ nghĩa mã ngữ cảnh.

Chúng tôi coi suy luận kiểu Python như một phân loại kiểu để giải quyết các kiểu do người dùng định nghĩa. Để có được xác suất của mỗi kiểu, chúng tôi áp dụng hồi quy softmax (còn được gọi là hồi quy logistic đa thức [30]) trên tính năng được trích xuất từ đầu ra của mô hình GRU. Đối với đầu ra của mạng GRU hsi, chúng ta có:

yi = argmax (P(hsi)) = argmax (e^hsi / Σ_{i=0}^n e^hsi);

trong đó argmax là một hàm trả về vị trí với xác suất tối đa, và P(hsi) là một danh sách xác suất cho mỗi kiểu có thể có của biến vi. Hàm này được sử dụng để xấp xỉ một số nguyên mục tiêu yi ∈ [1, C], trong đó C đại diện cho số lượng lớp. Hàm softmax P() tạo ra một đầu ra vô hướng P(hsi) ∈ R, với xác suất cho mỗi kiểu P(hsi)j ∈ [0, 1].

Với sự giúp đỡ của lớp softmax, chúng tôi có thể tạo ra các chú thích kiểu cho mỗi biến với phân phối trên xác suất P(hsi). PYInfer chú thích biến dựa trên kiểu với xác suất tối đa, trả về yi. Chúng tôi có thể thêm một ngưỡng trên mức độ tin cậy, tức là xác suất. Độ chính xác mô hình của chúng tôi tăng với sự tăng của mức độ tin cậy (Bảng IX), điều này chứng minh hiệu quả của mô hình của chúng tôi về phân loại kiểu.

D. Huấn luyện mô hình

Trong mô hình của chúng tôi, chúng tôi áp dụng cross-entropy làm hàm mất mát. Cụ thể, chúng tôi áp dụng một softmax theo sau bởi một logarit để rút ra sự tin cậy cho suy luận kiểu và thêm mất mát log-likelihood âm (NLLLoss) vào kết quả softmax. Đối với hàm mất mát, chúng ta có:

L = Σ_{i=1}^n Σ_{j=1}^C g_{ij} log(P(hsi)j);

trong đó L đại diện cho hàm mất mát cho mô hình của chúng tôi, được tính bằng cách tổng mất mát cho mỗi chú thích. Hằng số n là tổng số chú thích chúng tôi có, và C đại diện cho số lượng lớp. Kiểu sự thật cơ sở cho biến vi được biểu diễn bởi g_{ij}. Chúng tôi đặt g_{ij} = 1 nếu chú thích cho biến vi là j, và g_{ij} = 0 ngược lại. P(hsi)j định nghĩa kết quả log softmax của lớp j trên biến vi.

Chúng tôi tiếp tục đưa kết quả tính toán vào một optimizer, nhằm mục đích giảm thiểu giá trị của hàm mất mát L. Thí nghiệm rộng rãi được tiến hành, và Adam Optimizer [31] hóa ra là phù hợp nhất cho hiện tượng này.

III. ĐÁNH GIÁ

Trong phần này, chúng tôi đánh giá PYInfer bằng cách trả lời các câu hỏi nghiên cứu sau:

RQ 1: PYInfer hiệu quả như thế nào trong việc rút ra các chú thích kiểu chính xác?
RQ 2: Số lượng lớp được xem xét cho phân loại có tác động đáng kể đến PYInfer không?
RQ 3: Ngưỡng ảnh hưởng như thế nào đến mô hình PYInfer của chúng tôi?

A. RQ 1: Hiệu quả mô hình và so sánh cơ sở

1) Tập dữ liệu và thiết lập thí nghiệm: Trong RQ này, chúng tôi phân tích hiệu suất của mô hình ngữ cảnh với 500 kiểu phổ biến nhất trong tập dữ liệu typePY. Bên cạnh tất cả các kiểu tích hợp trong Python, chúng tôi cũng xem xét một lượng lớn các kiểu do người dùng định nghĩa. Sau khi phân tích corpus mã nguồn, chúng tôi thấy rằng có sự trùng lặp trong tập dữ liệu của chúng tôi. Lý do chính là một số kho lưu trữ GitHub tái sử dụng cùng một mã từ những kho khác. Chúng tôi thực hiện khử trùng lặp trên tập dữ liệu của mình và rút ra 3,499,933 chú thích để đánh giá. Chúng tôi cũng kiểm tra một số phân phối kiểu, như được hiển thị trong Bảng II. Phân phối không đều này phản ánh sự khác biệt trong việc sử dụng biến thế giới thực trên các kiểu khác nhau. Toàn bộ corpus dữ liệu của chúng tôi được chia ngẫu nhiên thành dữ liệu huấn luyện, xác thực và kiểm tra với tỷ lệ 60%:20%:20%. Chúng tôi chạy tất cả thí nghiệm trên một máy đơn với CPU Intel i7-9700k, RAM 32GB và một GPU NVIDIA RTX 2070 Super đơn.

BẢNG II: RQ 1: Phân phối chú thích kiểu của 500 kiểu phổ biến nhất trong tập dữ liệu typePY.

Kiểu | Số chú thích | Kiểu | Số chú thích
str | 921,471 | DataFrame | 16,764
int | 628,552 | Series | 13,429
dict | 336,374 | [float] | 11,376
bool | 241,804 | tuple | 11,110
float | 126,005 | (int, int) | 9,738
[str] | 121,669 | {dict dict} | 8,608
list | 48,400 | object | 6,110

2) Chi tiết triển khai và kết quả: Chúng tôi huấn luyện mô hình PYInfer với các tham số trong Bảng III và báo cáo kết quả kiểm tra. Để phân tích ngữ nghĩa mã ngữ cảnh, chúng tôi tạo các nhúng bằng cách phân tích ngữ nghĩa ngữ cảnh trong mã nguồn với một bộ phân tách giữa mỗi phần trong thiết lập biên độ của chúng tôi. Chúng tôi có được các biểu diễn vector bằng cách trích xuất lớp cuối cùng trong mạng nơ-ron GRU vì tên biến ở phần sau trong nhúng.

Chúng tôi thêm một lớp dropout để giải quyết vấn đề overfitting, làm cho mô hình của chúng tôi có thể tổng quát hóa hơn và nâng cao hiệu suất cho các trường hợp thế giới thực. Các tham số MODEL SIZE và SEQ LEN đặc trưng cho kích thước của lớp ẩn trong mạng GRU. Chúng tôi thiết lập siêu tham số TENSOR LEN để loại bỏ một số nhúng cực kỳ dài, thường là trường hợp mà một đoạn mã nguồn chứa vô số token chưa thấy. Chúng tôi đã thu thập phân phối về độ dài nhúng, và độ dài nhúng trong vòng 1,000 bao gồm 99.9% chú thích trong tập dữ liệu của chúng tôi. Do đó, chúng tôi có thể an toàn áp dụng các chú thích trong ràng buộc độ dài này để huấn luyện mô hình của chúng tôi. Với tất cả các thiết lập trên, chúng tôi tinh chỉnh các tham số và sử dụng độ chính xác làm một trong những ma trận đánh giá của mô hình. Độ chính xác được tính như:

A_{Xi} = |D(Xi) ∩ C(Xi)| / |D(Xi)|;

trong đó Xi đại diện cho nhúng hiện tại đang được xử lý, D(Xi) đại diện cho kiểu sự thật cơ sở cho biến vi, và C(Xi) trả về chú thích kiểu Top-1 được xếp hạng dựa trên xác suất. Mô hình của chúng tôi cuối cùng đạt được độ chính xác 81.195% trên dữ liệu kiểm tra.

BẢNG III: Siêu tham số cho mô hình PYInfer, số lượng chú thích và kết quả kiểm tra.

Optimizer | Margin | Loss | Dropout
Adam | 128 | CrossEntropy | 0.1

Learning Rate | MODEL SIZE | SEQ LEN | TENSOR LEN
512 | 1,000 | 0.0001 | 512

Training Samples | Validation Samples | Testing Samples
2,099,739 | 699,913 | 699,914

Kết quả kiểm tra mô hình PYInfer
Accuracy | Precision | Recall | F-1 Score
81.195% | 79.318% | 81.195% | 80.246%

Vì phân phối cho mỗi kiểu không đều, chúng tôi cũng đánh giá mô hình của mình bằng precision và recall có trọng số và tính điểm f-1 dựa trên chúng. Như một phân loại đa lớp, chúng tôi tính trung bình của mỗi ma trận đánh giá có trọng số bởi support, tức là số lượng chú thích chính xác cho mỗi kiểu. PYInfer đạt được 79.318% về precision, 81.195% về recall và 80.246% về điểm f-1.

3) Phân tích cơ sở và hiểu biết: Để phân tích cơ sở, chúng tôi so sánh framework PYInfer của chúng tôi với mô hình probPY [13] và PySonar2. Đầu tiên, chúng tôi thực hiện thí nghiệm cơ sở sử dụng dữ liệu được hợp nhất trong tập dữ liệu probPY.

Ma trận đánh giá trong probPY tận dụng recall và precision. Precision trong probPY được tính dựa trên đầu vào khả thi. Tuy nhiên, do thiếu sự thật cơ sở, họ cung cấp ước tính dựa trên các mẫu được chọn ngẫu nhiên. Do đó, chúng tôi áp dụng recall để đánh giá chính xác. Tương tự như probPY, chúng tôi tính recall như:

R_{Xi} = |D(Xi) ∩ C(Xi, TOP k)| / |D(Xi)|

Xi là nhúng của biến vi đang được xử lý. D(Xi) đại diện cho kiểu sự thật cơ sở cho biến vi, và C(Xi, TOP k) trả về TOP k chú thích kiểu được xếp hạng dựa trên xác suất cho mỗi kiểu có thể.

BẢNG IV: Kết quả đánh giá về recall sử dụng tập dữ liệu probPY.

Framework | Top-1 | Top-3 | Top-5 | Top-7
PYInfer | 63.034% | 77.931% | 83.774% | 88.865%
probPY | 58.155% | 75.930% | 79.090% | 80.310%

Trong bảng IV, chúng tôi trình bày recall kiểm tra của PYInfer so với mô hình probPY. Chúng tôi đánh giá PYInfer trên recall kiểm tra Top-k, trong đó k ∈ {1, 3, 5, 7}. PYInfer trên Top-k trả về k chú thích với xác suất cao nhất. Vì chúng tôi có sự thật cơ sở cho chú thích, |D(Xi)| luôn là một chú thích kiểu duy nhất. R_{Xi} tăng nếu sự thật cơ sở được bao gồm trong k kết quả suy luận đầu tiên TOP k được xếp hạng theo xác suất. Vì chỉ có chú thích biến Top-1 được cung cấp cho phía người dùng, nó quan trọng nhất trong các tình huống thế giới thực. Chúng tôi cũng thu thập precision Top-1 sử dụng probPY với thiết lập ngưỡng xác suất HIGH 0.95 và ngưỡng xác suất quy ước đặt tên = 0.7, như được minh họa trong bài báo của họ [13]. Chúng tôi sử dụng mô hình PYInfer được huấn luyện với tập dữ liệu typePY phân loại 500 kiểu và đánh giá trên tập dữ liệu probPY. Vì chúng tôi không huấn luyện lại hoặc tinh chỉnh mô hình của mình trong tập dữ liệu probPY, hiệu suất ít cạnh tranh hơn so với kết quả kiểm tra của chúng tôi. Tuy nhiên, mô hình của chúng tôi vẫn vượt trội hơn mô hình probPY trên tất cả các recall Top-k. Ưu thế này là do chúng tôi có một tập dữ liệu đủ lớn để PYInfer phân tích ngữ nghĩa ngữ cảnh. Phương pháp nhúng của chúng tôi tiên tiến hơn trong việc giải quyết OOV so với nhúng từ.

Thay vì gán trọng số cho nhiều yếu tố, framework PYInfer của chúng tôi hiệu quả hơn so với mô hình probPY với sự giúp đỡ của bản chất có thể song song hóa. PYInfer cũng vượt trội hơn probPY về độ bao phủ chú thích. Công cụ trong probPY chạy 68 phút trên CPU tám lõi và tạo ra 22,354 chú thích. Mô hình PYInfer của chúng tôi có thể tận dụng GPU để chạy song song. Nó mất 113 giây để rút ra 115,535 chú thích trong cùng tập dữ liệu, và nó đạt được nhanh hơn 187.4 lần so với probPY với độ bao phủ 5.2 lần.

BẢNG V: So sánh thời gian và độ bao phủ giữa PYInfer, PySonar2 và mô hình probPY.

| PYInfer | PySonar2 | probPY
Chú thích hợp lệ | 115,535 | 23,107 | 22,354
Thời gian tiêu thụ (s) | 112.575 | 40 | 4,080
Thời gian mỗi chú thích (ms) | 0.974 | 1.731 | 182.518

Mô hình của chúng tôi cũng thành thạo với độ bao phủ cao hơn so với PySonar2. Pysonar2 cung cấp 102,361 chú thích ban đầu cho tập dữ liệu probPY. Tuy nhiên, nhiều chú thích kiểu là dấu hỏi hoặc không hợp lệ. Trong số 102,361 chú thích, có 38,137 chú thích dấu hỏi, 9,454 được chú thích là "None", và 40,400 không có chữ cái (ví dụ: "[[?]]"). Trong số tất cả các chú thích dấu hỏi, 35,882 chú thích có thể được dự đoán bởi PYInfer, PYInfer cũng có thể suy luận 9,352 chú thích hợp lệ cho "None Type" và 38,019 chú thích cho "No Letter". Cuối cùng chúng tôi có được 23,107 chú thích sau khi khử trùng lặp và loại bỏ kiểu None và không hợp lệ. Nhìn chung, mô hình của chúng tôi đạt được độ bao phủ chú thích tốt nhất trong số ba công cụ này. Chúng tôi tiết lộ các so sánh chi tiết trong Bảng V.

4) So sánh với TypeWriter: TypeWriter [15] hiệu quả tận dụng mạng nơ-ron để suy luận kiểu cấp hàm, tức là kiểu tham số và kiểu trả về, từ các cơ sở mã được chú thích một phần. Nó sử dụng LSTM trên gợi ý kiểu từ token mã nguồn trong tên tham số, cách sử dụng và bình luận cấp hàm. Đối với tập dữ liệu, TypeWriter sử dụng một cơ sở mã nội bộ cũng như các phụ thuộc mypy trên GitHub. Nó xử lý 1,137 kho lưu trữ GitHub và dự đoán 16,492 chú thích cho kiểu trả về và 21,215 chú thích cho tham số.

So với TypeWriter, chúng tôi nhắm đến các vấn đề hơi khác nhau và áp dụng các framework khác nhau. TypeWriter suy luận tham số hàm và kiểu trả về, trong khi PYInfer chú thích các biến Python. Ở cấp độ phương pháp, TypeWriter áp dụng nhúng Word2Vec theo token truyền thống, trong khi PYInfer áp dụng nhúng BPE để nắm bắt ngữ nghĩa mã ngữ cảnh. Đối với thiết kế mạng nơ-ron, TypeWriter sử dụng mô hình LSTM trên token mã nguồn và bình luận hàm, trong khi PYInfer khai thác mạng GRU với cơ chế chú ý để giải quyết ngữ nghĩa cục bộ.

Chúng tôi so sánh mô hình PYInfer của chúng tôi với TypeWriter trong bộ kiểm tra của TypeWriter về tạo chú thích cho ba vấn đề khác nhau: biến, tham số hàm và kiểu trả về, như được hiển thị trong Bảng VI.

BẢNG VI: So sánh giữa TypeWriter và PYInfer.

Top-1 | PYInfer | TypeWriter
Precision | 79% | 59%
Chú thích biến Recall | 81% | 47%
F-1 Score | 80% | 52%
Precision | 72% | 58%
Tham số hàm Recall | 75% | 50%
F-1 Score | 73% | 54%
Precision | 59% | 69%
Trả về hàm Recall | 60% | 61%
F-1 Score | 59% | 65%

Chú thích biến. Chúng tôi đánh giá TypeWriter trên tập dữ liệu chú thích biến của chúng tôi, typePY. Chúng tôi đặt các chú thích biến như chú thích tham số hàm trong mô hình TypeWriter. Chúng tôi huấn luyện lại TypeWriter và có được 59% về precision, tương tự như hiệu suất suy luận kiểu tham số trong bài báo TypeWriter.

Kiểu tham số hàm. Chúng tôi đánh giá PYInfer trên tập dữ liệu mã nguồn mở trong TypeWriter. Chúng tôi đặt tên tham số như tên biến trong mô hình của chúng tôi. Không huấn luyện lại hoặc tinh chỉnh, mô hình của chúng tôi đạt được 72% về precision.

Kiểu trả về hàm. Chúng tôi đánh giá PYInfer trên tập dữ liệu mã nguồn mở trong TypeWriter. Chúng tôi coi dòng mã nơi trả về hàm được định nghĩa như tên biến trong mô hình của chúng tôi. Chúng tôi đạt được precision 59% mà không huấn luyện lại hoặc tinh chỉnh mô hình PYInfer.

Từ đánh giá trên, công việc của chúng tôi bổ sung cho TypeWriter. TypeWriter sử dụng các tính năng cấp hàm toàn cục, tức là mã nguồn hàm, bình luận và cách sử dụng tham số để suy luận kiểu trả về và tham số. Những tính năng toàn cục đó cung cấp một cái nhìn toàn diện về toàn bộ hàm, làm cho nó tiên tiến hơn để suy luận kiểu cấp hàm. TypeWriter cho thấy hiệu suất tăng cường so với NL2Type [6] và DeepTyper [5] trong dự đoán tham số. Tuy nhiên, TypeWriter gặp khó khăn trong việc chú thích các biến trong thân hàm, nơi thông tin cấp biến hiệu quả hơn. PYInfer chú thích các biến sử dụng ngữ nghĩa mã nguồn trong một biên độ nhất định, làm cho nó cạnh tranh hơn trong việc cung cấp chú thích cấp biến. Lý do chính là mô hình PYInfer khai thác các tính năng cấp biến cục bộ, tức là tên biến và ngữ nghĩa ngữ cảnh trong một biên độ nhất định. Để suy luận kiểu của các biến và tham số, các tính năng cục bộ quan trọng hơn vì chúng đặc trưng cho cách một biến được định nghĩa và sử dụng.

B. RQ 2: Kiểu cơ bản hay nhiều kiểu hơn

Chúng tôi điều tra hiệu suất mô hình của việc chỉ phân loại các kiểu cơ bản trong Python. Cụ thể, chúng tôi kiểm tra các kiểu tích hợp sau: [str, int, dict, bool, float, list, tuple, object, complex, set, type]. Chúng tôi phân tích phân phối của các kiểu khác nhau, như được hiển thị trong Bảng VII.

BẢNG VII: Phân phối chú thích trên các kiểu cơ bản với dữ liệu ngữ cảnh trong tập dữ liệu typePY.

Kiểu | Số lượng | Khử trùng lặp | Kiểu | Số lượng | Khử trùng lặp
str | 6,553,418 | 921,471 | tuple | 78,947 | 11,110
int | 4,028,405 | 628,552 | object | 27,251 | 6,110
dict | 1,810,145 | 336,374 | complex | 11,177 | 2,295
bool | 4,429,648 | 241,804 | set | 483 | 11
float | 765,077 | 126,005 | type | 168 | 3
list | 363,832 | 48,400

Để phân tích hiệu suất của PYInfer trên các kiểu cơ bản, chúng tôi có được 2,322,135 chú thích sau khi khử trùng lặp. Kết quả so sánh giữa các kiểu cơ bản và 500 kiểu phổ biến nhất có thể được tìm thấy trong Bảng VIII. Hiệu suất của mô hình kiểu cơ bản vượt qua mô hình 500 kiểu 9.9% về độ chính xác kiểm tra. Phân loại 11 kiểu sẽ dễ quản lý hơn nhiều và chính xác hơn 500 kiểu. Tuy nhiên, một số lượng lớn các kiểu do người dùng định nghĩa không thể được dự đoán với 11 kiểu. Một mô hình xem xét 500 kiểu bao phủ nhiều kiểu do người dùng định nghĩa hơn, làm cho nó có thể tổng quát hóa cho các tình huống thế giới thực.

BẢNG VIII: So sánh giữa các kiểu cơ bản và 500 kiểu phổ biến nhất sử dụng PYInfer.

Kiểu | Huấn luyện | Xác thực | Kiểm tra | Precision | Recall | F-1 Score
Kiểu cơ bản | 91.440% | 91.280% | 91.187% | 95.366% | 91.638% | 93.465%
500 kiểu | 81.165% | 81.153% | 81.195% | 79.318% | 81.195% | 80.246%

C. RQ 3: Ngưỡng

Vì mô hình cung cấp chú thích kiểu với một xác suất, chúng tôi kiểm tra các ngưỡng khác nhau trên mức độ tin cậy. Từ 0.1 đến 0.9, chúng tôi cung cấp kết quả về số lượng chú thích với precision, recall và điểm f-1 trong Bảng IX được đánh giá trên corpus xác thực của chúng tôi trong typePY. Các chú thích trong Bảng IX chỉ ra số lượng biến được dự đoán với một kiểu. Với sự tăng của ngưỡng, mô hình của chúng tôi đưa ra ít chú thích hơn, trong khi precision tăng. Với ngưỡng cao hơn, ít chú thích hơn được đưa ra. Ngưỡng ở 0.9 cung cấp precision 97.677%, cũng bỏ qua 42.151% dữ liệu xác thực của chúng tôi.

Ngưỡng là một phản ánh thực sự về kết quả của mô hình trên xác suất, cho biết mô hình của chúng tôi tin tưởng như thế nào để cung cấp một chú thích kiểu. Chúng tôi có thể đặt ngưỡng ở một giá trị hợp lý để đạt được sự cân bằng giữa số lượng chú thích chúng tôi muốn có được và một tiêu chuẩn độ chính xác tuyệt đối chúng tôi muốn có.

BẢNG IX: Kết quả đánh giá trên PYInfer sử dụng tập dữ liệu xác thực typePY với các thiết lập ngưỡng khác nhau.

Ngưỡng | Chú thích | Precision | Recall | F-1 Score
0.0 | 699,913 | 79.510% | 81.275% | 80.383%
0.1 | 689,916 | 80.339% | 81.185% | 80.760%
0.2 | 677,457 | 81.556% | 80.880% | 81.217%
0.3 | 653,684 | 83.596% | 79.944% | 81.729%
0.4 | 617,740 | 86.631% | 78.029% | 82.105%
0.5 | 578,565 | 89.663% | 75.340% | 81.880%
0.6 | 540,766 | 92.146% | 72.208% | 80.968%
0.7 | 502,896 | 94.118% | 68.508% | 79.296%
0.8 | 460,553 | 95.985% | 63.809% | 76.657%
0.9 | 404,896 | 97.677% | 56.881% | 71.895%

IV. PHÂN TÍCH

Trong phần này, chúng tôi tập trung vào việc trả lời hai câu hỏi nghiên cứu sau:

RQ 4: Thông tin ngữ cảnh ảnh hưởng như thế nào đến hiệu suất của PYInfer?
RQ 5: Nhúng BPE có vượt trội hơn các nhúng mã dựa trên học tập khác không?

A. RQ 4: Phân tích loại bỏ của ngữ nghĩa ngữ cảnh

Chúng tôi cũng quan tâm đến hiệu quả của ngữ nghĩa ngữ cảnh. Do đó, chúng tôi tiến hành phân tích loại bỏ về dữ liệu ngữ cảnh và phân tích PYInfer không có ngữ nghĩa ngữ cảnh. Chúng tôi thu thập kết quả trong Bảng X. Không có các yếu tố ngữ cảnh, mô hình của chúng tôi chỉ có thể tận dụng tên biến, bỏ qua cách sử dụng biến và các mối quan hệ logic trong một biên độ nhất định trong ngữ cảnh. Thông tin ngữ cảnh đóng vai trò then chốt trong việc đặc trưng cho ngữ nghĩa mã nguồn. Sự khan hiếm của ngữ nghĩa ngữ cảnh tàn phá hiệu quả của mô hình chúng tôi. Chúng tôi quan sát được mức tăng 41% về độ chính xác kiểm tra với sự hỗ trợ của ngữ nghĩa ngữ cảnh.

BẢNG X: Kết quả đánh giá cho thí nghiệm loại bỏ dữ liệu ngữ cảnh của PYInfer.

Mô hình | Huấn luyện | Xác thực | Kiểm tra | Precision | Recall | F-1 Score
Ngữ cảnh | 81.165% | 81.153% | 81.195% | 79.318% | 81.195% | 80.246%
Không ngữ cảnh | 40.823% | 39.918% | 40.195% | 33.106% | 40.775% | 36.542%

Sự suy giảm hiệu suất cũng có thể được giải thích một phần do việc giảm chú thích. Đối với mô hình với dữ liệu ngữ cảnh, chúng tôi có 3,499,933 chú thích xem xét 500 kiểu. Không có thông tin ngữ cảnh, chúng tôi có một số lượng áp đảo các bản sao vì hầu hết các biến có tên tương tự với cùng kiểu. Chúng tôi chỉ có được 841,521 chú thích sau khi khử trùng lặp. Vì chúng tôi bỏ qua dữ liệu ngữ cảnh và khử trùng lặp các chú thích, chúng tôi gặp phải sự thiếu hụt nghiêm trọng các chú thích kiểu. Sự không đủ này về chú thích cũng làm suy giảm hiệu suất của mô hình.

Để điều tra thêm về tầm quan trọng của ngữ nghĩa ngữ cảnh, chúng tôi tiến hành thí nghiệm với tập dữ liệu typeshed được gán nhãn bởi con người. Nó chứa các chú thích kiểu theo định dạng của một tệp pyi theo các định dạng cụ thể [32, 33], được sử dụng rộng rãi để kiểm tra kiểu và suy luận kiểu.

Trong Hình 4, chúng tôi trình bày một mẫu tệp pyi trong kho lưu trữ GitHub typeshed. Một tệp pyi chứa các chú thích về tham số và giá trị trả về cho các hàm. Lưu ý rằng đối với biến safe trong Hình 4, chúng tôi được cung cấp cả chú thích Str và AnyStr dưới các ngữ cảnh khác nhau. Vì mã nguồn không có sẵn cho tập dữ liệu này, chúng tôi không thể tách hai biến này với các chú thích tương ứng.

Hình 4: Một mẫu tệp pyi trong tập dữ liệu typeshed.

Số lượng chú thích trong tập dữ liệu typeshed cực kỳ hạn chế. Sẽ có sự thiếu hụt dữ liệu to lớn cho mỗi kiểu khi xem xét 500 kiểu. Như một biện pháp giảm thiểu, chúng tôi dành tâm huyết để điều tra top-50 kiểu. Chúng tôi huấn luyện lại PYInfer của chúng tôi trên typeshed và so sánh với mô hình được huấn luyện trên tập dữ liệu typePY. PYInfer được huấn luyện trên typeshed đạt được độ chính xác kiểm tra 41.747%, precision 53.126%, 43.748% và điểm f-1 47.983%. So với kết quả trong Bảng X, chúng tôi thấy một xu hướng tương tự ở phía kiểm tra, điều này chỉ ra rằng thông tin ngữ cảnh quan trọng đối với dự đoán kiểu biến.

B. RQ 5: Ưu điểm của nhúng mã nguồn

Bên cạnh dữ liệu ngữ cảnh và kiểu, mô hình của chúng tôi cũng vượt trội trong việc áp dụng nhúng BPE. Mã nguồn phong phú với các biến và tên hàm do người dùng định nghĩa. Chúng tôi thường gặp phải vấn đề OOV trong việc đặc trưng cho ngữ nghĩa mã nguồn. Chúng tôi áp dụng phương pháp BPE để giải quyết vấn đề này, cho phép chúng tôi tận dụng tối đa ngữ nghĩa mã ngữ cảnh.

Trong RQ này, chúng tôi chủ yếu điều tra hiệu quả của nhúng BPE so với nhúng GloVe dựa trên học tập, một phương pháp nhúng từ nổi bật cho các tệp văn bản. Chúng tôi huấn luyện lại nhúng GloVe của chúng tôi trên tập dữ liệu typePY và rút ra một vector 50 chiều cho mỗi token. Mỗi token ngữ cảnh trong một biên độ nhất định được ánh xạ đến một vector GloVe 50 chiều. Sau đó chúng tôi nối các vector nhúng cho các token trước và sau biến hiện tại trong một biên độ nhất định và tên của biến hiện tại. Vector được nối được đưa qua mạng GRU để huấn luyện mô hình. Chúng tôi thu thập và tập hợp kết quả trong Bảng XI. Kết quả thí nghiệm của chúng tôi tiết lộ rằng nhúng BPE vượt trội hơn nhúng GloVe một cách đáng kể. Chúng tôi chứng minh rằng BPE hiệu quả hơn nhúng GloVe cho gõ biến.

BẢNG XI: So sánh giữa nhúng BPE và nhúng GloVe với PYInfer trên tập dữ liệu typePY.

Nhúng | Huấn luyện | Xác thực | Kiểm tra | Precision | Recall | F-1 Score
BPE | 81.165% | 81.153% | 81.195% | 79.318% | 81.195% | 80.246%
GloVe | 51.916% | 54.168% | 54.077% | 50.470% | 54.132% | 52.237%

V. THẢO LUẬN

A. Điểm mạnh và điểm yếu của PYInfer

Lý do chính tại sao PYInfer vượt trội hơn các công cụ suy luận kiểu khác là chúng tôi có một tập dữ liệu chú thích đủ lớn và mã hóa ngữ nghĩa ngữ cảnh của một biến vào mô hình học sâu. Như được minh họa trong Hình 2, chúng tôi thiết lập một biên độ để xác định phạm vi ngữ cảnh, áp dụng nhúng BPE để giải quyết OOV và sử dụng mạng GRU với cơ chế chú ý để trích xuất ngữ nghĩa. Thiết lập biên độ ảnh hưởng đến hiệu suất của PYInfer. Chúng tôi tiến hành thí nghiệm để kiểm tra ảnh hưởng của thiết lập biên độ dựa trên tập dữ liệu probPY, và kết quả đánh giá có thể được tìm thấy ở Bảng XII. Các thí nghiệm được thực hiện trên tập dữ liệu probPY được hợp nhất đánh giá Top-k (k ∈ {1, 3, 5, 7}) không có ngưỡng. Khi biên độ tăng, độ chính xác tăng trước rồi giảm, có thể được giải thích theo những cách sau:

Thiết lập biên độ ở 32 và 64 thiếu ngữ nghĩa cục bộ ngữ cảnh đầy đủ cho biến hiện tại. Thiết lập biên độ của 256 và 512 cung cấp nhiều ngữ nghĩa ngữ cảnh không liên quan hơn. Chúng tôi rút ra hiểu biết sau rằng một thiết lập thích hợp của biên độ chắc chắn có ảnh hưởng đến hiệu suất tổng thể của mô hình chúng tôi.

BẢNG XII: Các thiết lập biên độ khác nhau với PYInfer trên tập dữ liệu probPY.

Biên độ | 32 | 64 | 128 | 256 | 512
Độ chính xác | 54.751% | 60.055% | 61.635% | 60.933% | 59.265%
Precision | 69.446% | 69.016% | 68.554% | 67.862% | 65.972%
Recall | 54.751% | 60.055% | 61.635% | 60.933% | 59.265%
F-1 Score | 61.229% | 64.224% | 64.911% | 64.211% | 62.439%

Có một số hạn chế của PYInfer. Mặc dù PYInfer đủ tiêu chuẩn để xử lý các kiểu do người dùng định nghĩa, một số chú thích không chính xác do dữ liệu huấn luyện hạn chế về các kiểu do người dùng định nghĩa so với các kiểu tích hợp. Chúng tôi đã hiển thị phân phối của các chú thích khác nhau trong Bảng II, và số lượng mẫu về các kiểu do người dùng định nghĩa bị áp đảo bởi số lượng kiểu tích hợp. Ngoài ra, như nhiều bộ phân tích tĩnh, PYInfer đòi hỏi quyền truy cập vào mã nguồn, có thể không thực tế do các vấn đề bảo mật.

B. Ưu thế so với PySonar2

Chúng tôi phải nhấn mạnh rằng mặc dù được huấn luyện bằng các chú thích được tạo bởi PySonar2, mô hình của chúng tôi cho thấy độ bao phủ cao hơn đáng kể so với Pysonar2 trong suy luận kiểu biến. Phân tích cùng một đoạn mã², chúng tôi so sánh kết quả chú thích của PySonar2 và PYInfer được huấn luyện với 500 kiểu phổ biến nhất trên tập dữ liệu typePY, như được hiển thị trong Hình 5. PySonar2 và PYInfer đều báo cáo một số dương tính giả. PySonar2 sử dụng phân tích liên thủ tục có nhận thức về luồng điều khiển, bỏ qua kiến thức ngữ nghĩa trong mã nguồn. Nó chú thích một nửa số biến bằng dấu hỏi (7 trong số 14 chú thích). PYInfer nắm bắt ngữ nghĩa mã bằng cách xem xét ngữ nghĩa ngữ cảnh trong một biên độ cụ thể, đưa ra các chú thích cụ thể khi các ngữ cảnh khác nhau. Nó có thể xử lý các tình huống đòi hỏi nơi PySonar2 phát ra dấu hỏi và chú thích chính xác 21 biến trong tất cả 29 chú thích. Mặc dù PYInfer không hoàn hảo, nó đạt được độ chính xác kiểm tra hợp lý (91.187% trên 11 kiểu cơ bản và 81.195% trên 500 kiểu phổ biến nhất).

² Được truy cập từ https://github.com/pyeve/eve/blob/master/eve/endpoints.py.

Hình 5: Chúng tôi so sánh các chú thích kiểu được cung cấp bởi PySonar2 (trái) và PYInfer (phải). PYInfer không chỉ tạo ra nhiều chú thích hơn cho các tình huống phức tạp mà còn cung cấp xác suất cho mỗi kiểu.

VI. CÔNG VIỆC LIÊN QUAN

A. Suy luận kiểu cho Python

Các tiêu chuẩn, chẳng hạn như PEP 484 [32], PEP 3107 [33], được đề xuất để tạo điều kiện cho gợi ý kiểu và chú thích. Các công cụ kiểm tra kiểu, chẳng hạn như mypy [1], pyre-check [2], pytype [3] và pyright [4], tận dụng các chú thích để phát hiện sự không nhất quán kiểu. Không có các chú thích kiểu, sẽ vô ích cho các công cụ kiểm tra kiểu để phát hiện sự không nhất quán kiểu cho các dự án Python. Các công cụ kiểm tra kiểu hiện có chủ yếu dựa vào các chú thích kiểu được viết thủ công từ các nhà phát triển, điều này tốn kém để cung cấp.

Công việc suy luận kiểu trước đây thường bỏ qua các yếu tố ngôn ngữ tự nhiên trong mã nguồn. Một số công cụ chú thích kiểu hiện có áp dụng phân tích động. PyAnnotate [34], ví dụ, là một công cụ suy luận kiểu động được phát triển bởi Dropbox. Sử dụng phân tích động để có được chú thích kiểu trong thời gian chạy làm cho việc suy luận chính xác cho đầu vào cụ thể. Tuy nhiên, nó đòi hỏi một môi trường thời gian chạy cụ thể, điều này không thực tế trong một số hoàn cảnh thế giới thực. Ngoài ra, nó nhạy cảm với đầu vào, dẫn đến độ bao phủ hạn chế. Các framework được đề xuất bởi Cannon [10], Salib [11], Vitousek và cộng sự [12] tạo ra các chú thích kiểu dựa trên phân tích tĩnh. Salib [11] trình bày một suy luận kiểu tĩnh và trình biên dịch cho Python với Thuật toán tích Cartesian đã sửa đổi [35]. Công cụ này chuyển đổi mã nguồn Python thành mã C++ tương đương, làm cho nó thành thạo trong việc phân tích mã bằng ngôn ngữ nước ngoài. Tuy nhiên, công cụ này không hoàn chỉnh và các hướng dẫn có thể được xử lý bị hạn chế. Vitousek và cộng sự [12] phát triển gõ dần dần cho Python sử dụng một hệ thống kiểu dựa trên tính toán đối tượng bậc nhất [36] được tăng cường với các kiểu động. Luo và cộng sự [37] phân tích docstring Python và xây dựng một bộ phân loại cây quyết định. Phương pháp này chỉ xem xét chín kiểu tích hợp và sẽ vô ích nếu docstring không có sẵn. PySonar2[16], một công cụ suy luận kiểu tĩnh cho Python, có thể tạo ra gợi ý kiểu tĩnh cho các biến. Mặc dù nó chỉ bao gồm 48.91% chú thích dựa trên thí nghiệm của chúng tôi, các kết quả chính xác phù hợp với nghiên cứu của chúng tôi với sự thật cơ sở cho việc gán nhãn.

Một số công việc liên quan khai thác ngữ nghĩa trong mã nguồn sử dụng mạng nơ-ron. Pradel và cộng sự [15] dự đoán các kiểu tham số và trả về cho các hàm với các yếu tố ngôn ngữ tự nhiên trong mã nguồn và bình luận. Nó hiệu quả hơn trong suy luận cấp hàm so với dự đoán cấp biến. Xu và cộng sự [13] áp dụng suy luận xác suất để rút ra các chú thích kiểu cho Python. Xem xét các yếu tố xác suất khác nhau làm cho công cụ tốn thời gian và khó mở rộng.

B. Suy luận kiểu trên các ngôn ngữ gõ động

Các công cụ suy luận kiểu dựa trên học tập hiện có chủ yếu tập trung vào JavaScript, nơi các chú thích kiểu có thể được lấy bằng TypeScript [9]. LambdaNet [8] sử dụng mạng nơ-ron đồ thị để dự đoán kiểu với gợi ý ngữ cảnh liên quan đến đặt tên và sử dụng biến. Nó định nghĩa đồ thị phụ thuộc kiểu và truyền thông tin kiểu trên một mạng nơ-ron đồ thị. LambdaNet khám phá tiềm năng sử dụng nhúng đồ thị trong suy luận kiểu. So với nhúng dựa trên đồ thị, việc tạo nhúng mã nguồn dựa trên token hiệu quả hơn. Nó có thể khai thác ngữ nghĩa mã nguồn và dễ tiếp cận hơn để áp dụng cho các ngôn ngữ khác. NL2Type [6] đề xuất một phương pháp dựa trên học tập để dự đoán chữ ký kiểu cho các hàm với hỗ trợ ngôn ngữ tự nhiên. Hellendoorn và cộng sự [5] sử dụng một mô hình học sâu với nhúng từ 300 chiều để tạo ra các chú thích kiểu cho JavaScript.

C. Phân tích mã nguồn dựa trên học tập

Học máy đã được áp dụng rộng rãi trong phân tích chương trình. Godefroid và cộng sự [38] đề xuất một kỹ thuật học máy thống kê để tự động tạo ra đầu vào phù hợp với ngữ pháp cho fuzzing. DeepFix [39] sử dụng một mạng nơ-ron chuỗi-đến-chuỗi với chú ý để phát hiện và sửa lỗi trong các chương trình C. Raychev và cộng sự [40] tập trung vào hoàn thành mã với API sử dụng một mô hình ngôn ngữ. Deepsim [41] đo sự tương tự mã sử dụng một mô hình học sâu với ma trận luồng điều khiển và luồng dữ liệu. Raychev và cộng sự [42] xây dựng JSNice để dự đoán tên của các định danh và chú thích kiểu của các biến cho JavaScript. Pradel và Sen [7] đề xuất một phương pháp dựa trên học tập để phát hiện ba loại lỗi dựa trên tên khác nhau. Họ tạo ra các mẫu âm sử dụng biến đổi mã dựa trên các mẫu lỗi cụ thể. Trích xuất các mẫu lỗi và gieo lỗi vào mã nguồn theo mẫu đòi hỏi nỗ lực con người lớn.

D. Nhúng mã nguồn dựa trên học tập

Nhúng từ dựa trên học tập đã được áp dụng rộng rãi trong xử lý ngôn ngữ tự nhiên, chẳng hạn như word2vec [43] và doc2vec [21]. Nguyen và cộng sự [44] tận dụng word2vec để phân tích các mối quan hệ ngữ nghĩa về cách sử dụng API. Ye và cộng sự [45] huấn luyện nhúng từ trên các tài liệu API, hướng dẫn và tài liệu tham khảo để ước tính sự tương tự ngữ nghĩa. Những phương pháp này phụ thuộc rất nhiều vào dữ liệu huấn luyện, và các token không được quan sát trong đầu vào huấn luyện không được giải quyết tốt. OOV là một vấn đề nghiêm trọng, đặc biệt trong nhúng mã nguồn, vì một lập trình viên có thể linh hoạt định nghĩa tên hàm và biến. Thuật toán BPE [17] giải quyết vấn đề OOV bằng cách mã hóa các từ hiếm và không xác định như các chuỗi đơn vị từ con. Nó hiệu quả trong nhiều tác vụ phân tích chương trình [24, 26, 27].

Bên cạnh nhúng mã nguồn dựa trên token, cũng có nhúng dựa trên đồ thị. Code2Vec [46] phân tách mã nguồn thành một tập hợp các đường dẫn trong cây cú pháp trừu tượng (AST) của nó và học biểu diễn nguyên tử của mỗi đường dẫn. Alon và cộng sự [47] đề xuất một biểu diễn dựa trên đường dẫn để học từ các chương trình sử dụng AST. LambdaNet [8] đề xuất đồ thị phụ thuộc kiểu, liên kết các biến kiểu với các ràng buộc logic cũng như thông tin tên và sử dụng. Những nhúng này chủ yếu xem xét cấu trúc trong mã nguồn. Chúng tôi điều tra ngữ nghĩa mã nguồn trong tên biến và thông tin ngữ cảnh, khác với cấu trúc mã dựa trên đồ thị với AST và mạng nơ-ron đồ thị.

VII. KẾT LUẬN

Chúng tôi đã trình bày PYInfer, một phương pháp dựa trên học tập để tự động tạo ra các chú thích kiểu cho Python. Đóng góp chính của chúng tôi là framework PYInfer từ đầu đến cuối để suy luận kiểu biến cho Python một cách tĩnh. Nghiên cứu của chúng tôi kết hợp các phương pháp biểu tượng và xác suất để tạo ra các chú thích kiểu cho các biến, hóa ra là rất hiệu quả và hiệu suất. Một trong những hiểu biết chính của chúng tôi là xem xét thông tin ngữ cảnh cho các biến, điều này tăng cường mô hình bằng cách mã hóa ngữ nghĩa mã bổ sung. PYInfer có khả năng xử lý các kiểu do người dùng định nghĩa bằng cách xây dựng suy luận kiểu như một bài toán phân loại. Nó đạt được nhiều hơn 5.2 lần về độ bao phủ mã và nhanh hơn 187 lần so với một kỹ thuật tốt nhất hiện tại để suy luận kiểu Python, và bao phủ nhiều biến hơn 5 lần so với PySonar2. Nó vượt trội hơn TypeWriter trong việc suy luận kiểu cho các biến và tham số hàm. Cuối cùng, chúng tôi đề xuất một phương pháp thu thập dữ liệu và đóng góp một tập dữ liệu lớn bao gồm 77,089,946 chú thích kiểu từ 4,577 dự án Python phổ biến. Chúng tôi làm cho công cụ và tập dữ liệu của chúng tôi có sẵn công khai để tạo điều kiện cho nghiên cứu tiếp theo.

TÀI LIỆU THAM KHẢO

[1] J. Lehtosalo, G. van Rossum, I. Levkivskyi, M. J. Sullivan, D. Fisher, G. Price và cộng sự. (2014) mypy - gõ tĩnh tùy chọn cho python. [Trực tuyến]. Có sẵn: http://www.mypy-lang.org/

[2] J. DiLorenzo, Z. Hu, R. van Tonder, Łukasz Langa, J. Fried, C. Meyer và cộng sự. (2018) Pyre một bộ kiểm tra kiểu hiệu suất cho python 3. [Trực tuyến]. Có sẵn: https://pyre-check.org/

[3] M. Kramm, R. Chen, T. Sudol, M. Demello, A. Caceres, D. Baum và cộng sự. (2015) pytype một bộ phân tích kiểu tĩnh cho mã python. [Trực tuyến]. Có sẵn: https://google.github.io/pytype/

[4] Microsoft. (2019) Pyright - bộ kiểm tra kiểu tĩnh cho python. [Trực tuyến]. Có sẵn: https://github.com/microsoft/pyright

[5] V. J. Hellendoorn, C. Bird, E. T. Barr, và M. Allamanis, "Deep learning type inference," trong Proceedings of the 2018 26th acm joint meeting on european software engineering conference and symposium on the foundations of software engineering, 2018, pp. 152–162.

[6] R. S. Malik, J. Patra, và M. Pradel, "Nl2type: inferring javascript function types from natural language information," trong 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 2019, pp. 304–315.

[7] M. Pradel và K. Sen, "Deepbugs: A learning approach to name-based bug detection," Proceedings of the ACM on Programming Languages, vol. 2, no. OOPSLA, pp. 1–25, 2018.

[8] J. Wei, M. Goyal, G. Durrett, và I. Dillig, "Lambdanet: Probabilistic type inference using graph neural networks," arXiv preprint arXiv:2005.02161, 2020.

[9] G. Bierman, M. Abadi, và M. Torgersen, "Understanding typescript," trong European Conference on Object-Oriented Programming. Springer, 2014, pp. 257–281.

[10] B. Cannon, "Localized type inference of atomic types in python," Ph.D. dissertation, Citeseer, 2005.

[11] M. Salib, "Starkiller: A static type inferencer and compiler for python," Ph.D. dissertation, Massachusetts Institute of Technology, 2004.

[12] M. M. Vitousek, A. M. Kent, J. G. Siek, và J. Baker, "Design and evaluation of gradual typing for python," trong ACM SIGPLAN Notices, vol. 50, no. 2. ACM, 2014, pp. 45–56.

[13] Z. Xu, X. Zhang, L. Chen, K. Pei, và B. Xu, "Python probabilistic type inference with natural language support," trong Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 2016, pp. 607–618.

[14] D. Fisher, Łukasz Langa, J. Lehtosalo, I. Levkivskyi, M. Kramm, G. Price và cộng sự. (2015) Collection of library stubs for python, with static types. [Trực tuyến]. Có sẵn: https://github.com/python/typeshed/

[15] M. Pradel, G. Gousios, J. Liu, và S. Chandra, "Typewriter: Neural type prediction with search-based validation," arXiv preprint arXiv:1912.03768, 2019.

[16] Y. Wang. (2013) Pysonar2: an advanced semantic indexer for python. [Trực tuyến]. Có sẵn: https://github.com/yinwang0/pysonar2/

[17] R. Sennrich, B. Haddow, và A. Birch, "Neural machine translation of rare words with subword units," arXiv preprint arXiv:1508.07909, 2015.

[18] J. Pennington, R. Socher, và C. Manning, "Glove: Global vectors for word representation," trong Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), 2014, pp. 1532–1543.

[19] K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, và Y. Bengio, "Learning phrase representations using rnn encoder-decoder for statistical machine translation," arXiv preprint arXiv:1406.1078, 2014.

[20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, và I. Polosukhin, "Attention is all you need," trong Advances in neural information processing systems, 2017, pp. 5998–6008.

[21] Q. Le và T. Mikolov, "Distributed representations of sentences and documents," trong International conference on machine learning, 2014, pp. 1188–1196.

[22] P. Gage, "A new algorithm for data compression," The C Users Journal, vol. 12, no. 2, pp. 23–38, 1994.

[23] Y. Shibata, T. Kida, S. Fukamachi, M. Takeda, A. Shinohara, T. Shinohara, và S. Arikawa, "Byte pair encoding: A text compression scheme that accelerates pattern matching," Technical Report DOI-TR-161, Department of Informatics, Kyushu University, Tech. Rep., 1999.

[24] H. Babii, A. Janes, và R. Robbes, "Modeling vocabulary for big code machine learning," arXiv preprint arXiv:1904.01873, 2019.

[25] J. Devlin, M.-W. Chang, K. Lee, và K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," arXiv preprint arXiv:1810.04805, 2018.

[26] R.-M. Karampatsis và C. Sutton, "Maybe deep neural networks are the best choice for modeling source code," arXiv preprint arXiv:1903.05734, 2019.

[27] R.-M. Karampatsis, H. Babii, R. Robbes, C. Sutton, và A. Janes, "Big code!= big vocabulary: Open-vocabulary models for source code," arXiv preprint arXiv:2003.07914, 2020.

[28] T. Kudo và J. Richardson, "Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing," arXiv preprint arXiv:1808.06226, 2018.

[29] M. Schuster và K. K. Paliwal, "Bidirectional recurrent neural networks," IEEE Transactions on Signal Processing, vol. 45, no. 11, pp. 2673–2681, 1997.

[30] D. Böhning, "Multinomial logistic regression algorithm," Annals of the institute of Statistical Mathematics, vol. 44, no. 1, pp. 197–200, 1992.

[31] D. P. Kingma và J. Ba, "Adam: A method for stochastic optimization," arXiv preprint arXiv:1412.6980, 2014.

[32] G. van Rossum, J. Lehtosalo, và Łukasz Langa. (2014) Pep 484 – type hints. [Trực tuyến]. Có sẵn: https://www.python.org/dev/peps/pep-0484/

[33] C. Winter và T. Lownds. (2006) Pep 3107 – function annotations. [Trực tuyến]. Có sẵn: https://www.python.org/dev/peps/pep-3107/

[34] T. Grue, S. Vorobev, J. Lehtosalo, và G. van Rossum. (2017) Pyannotate: Auto-generate pep-484 annotations. [Trực tuyến]. Có sẵn: https://github.com/dropbox/pyannotate/

[35] O. Agesen, "The cartesian product algorithm," trong European Conference on Object-Oriented Programming. Springer, 1995, pp. 2–26.

[36] M. Abadi và L. Cardelli, "A theory of objects," 1996.

[37] Y. Luo, W. Ma, Y. Li, Z. Chen, và L. Chen, "Recognizing potential runtime types from python docstrings," trong International Conference on Software Analysis, Testing, and Evolution. Springer, 2018, pp. 68–84.

[38] P. Godefroid, H. Peleg, và R. Singh, "Learn&fuzz: Machine learning for input fuzzing," trong 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2017, pp. 50–59.

[39] R. Gupta, S. Pal, A. Kanade, và S. Shevade, "Deepfix: Fixing common c language errors by deep learning," trong Thirty-First AAAI Conference on Artificial Intelligence, 2017.

[40] V. Raychev, M. Vechev, và E. Yahav, "Code completion with statistical language models," trong Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, 2014, pp. 419–428.

[41] G. Zhao và J. Huang, "Deepsim: deep learning code functional similarity," trong Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2018, pp. 141–151.

[42] V. Raychev, M. Vechev, và A. Krause, "Predicting program properties from" big code"," ACM SIGPLAN Notices, vol. 50, no. 1, pp. 111–124, 2015.

[43] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, và J. Dean, "Distributed representations of words and phrases and their compositionality," trong Advances in neural information processing systems, 2013, pp. 3111–3119.

[44] T. D. Nguyen, A. T. Nguyen, H. D. Phan, và T. N. Nguyen, "Exploring api embedding for api usages and applications," trong 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). IEEE, 2017, pp. 438–449.

[45] X. Ye, H. Shen, X. Ma, R. Bunescu, và C. Liu, "From word embeddings to document similarities for improved information retrieval in software engineering," trong Proceedings of the 38th international conference on software engineering, 2016, pp. 404–415.

[46] U. Alon, M. Zilberstein, O. Levy, và E. Yahav, "code2vec: Learning distributed representations of code," Proceedings of the ACM on Programming Languages, vol. 3, no. POPL, pp. 1–29, 2019.

[47] U. Alon, M. Zilberstein, O. Levy, và E. Yahav, "A general path-based representation for predicting program properties," ACM SIGPLAN Notices, vol. 53, no. 4, pp. 404–419, 2018.

# 2302.04662.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2302.04662.pdf
# Kích thước tệp: 770959 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Tạo Phản Hồi Độ Chính Xác Cao cho Lỗi Cú Pháp Lập Trình
sử dụng Các Mô Hình Ngôn Ngữ Lớn
Tung Phung1
MPI-SWS
mphung@mpi-sws.orgJosé Cambronero2
Microsoft
jcambronero@microsoft.comSumit Gulwani2
Microsoft
sumitg@microsoft.com
Tobias Kohn2
TU Wien
tobias.kohn@tuwien.ac.atRupak Majumdar2
MPI-SWS
rupak@mpi-sws.org
Adish Singla2
MPI-SWS
adishs@mpi-sws.orgGustavo Soares2
Microsoft
gsoares@microsoft.com
TÓM TẮT
Các mô hình ngôn ngữ lớn (LLM), như Codex, có tiềm năng lớn trong việc nâng cao giáo dục lập trình bằng cách tự động tạo phản hồi cho sinh viên. Chúng tôi nghiên cứu việc sử dụng LLM để tạo phản hồi cho việc sửa lỗi cú pháp trong chương trình Python, một kịch bản chính trong lập trình nhập môn. Cụ thể hơn, cho chương trình có lỗi của sinh viên, mục tiêu của chúng tôi là tạo phản hồi bao gồm một chương trình đã được sửa cùng với giải thích bằng ngôn ngữ tự nhiên mô tả các lỗi/sửa chữa, lấy cảm hứng từ cách mà một gia sư con người sẽ đưa ra phản hồi. Mặc dù việc sử dụng LLM là đầy hứa hẹn, thách thức quan trọng là đảm bảo độ chính xác cao trong phản hồi được tạo ra, điều này rất quan trọng trước khi triển khai công nghệ như vậy trong lớp học. Câu hỏi nghiên cứu chính mà chúng tôi nghiên cứu là: Liệu chúng ta có thể phát triển các kỹ thuật tạo phản hồi dựa trên LLM với tham số độ chính xác có thể điều chỉnh, cho phép các nhà giáo dục kiểm soát chất lượng phản hồi mà sinh viên nhận được? Để đạt được điều này, chúng tôi giới thiệu PyFiXV, kỹ thuật của chúng tôi để tạo phản hồi độ chính xác cao được hỗ trợ bởi Codex. Ý tưởng chính đằng sau PyFiXV là sử dụng cơ chế xác thực thời gian chạy mới để quyết định liệu phản hồi được tạo có phù hợp để chia sẻ với sinh viên hay không; đáng chú ý, cơ chế xác thực này cũng cung cấp một núm điều chỉnh độ chính xác cho các nhà giáo dục. Chúng tôi thực hiện đánh giá mở rộng sử dụng hai bộ dữ liệu thực tế của các chương trình Python có lỗi cú pháp và cho thấy hiệu quả của PyFiXV trong việc tạo phản hồi độ chính xác cao.

Từ khóa
Giáo dục lập trình, chương trình Python, lỗi cú pháp, tạo phản hồi, mô hình ngôn ngữ lớn

∗1: Tác giả liên hệ.
2: Được liệt kê theo thứ tự bảng chữ cái.

1. GIỚI THIỆU
Các mô hình ngôn ngữ lớn (LLM) được đào tạo trên văn bản và mã có tiềm năng thúc đẩy các công nghệ giáo dục thế hệ tiếp theo được điều khiển bởi AI và cải thiện đáng kể bối cảnh của giáo dục máy tính. Một trong những LLM phổ biến như vậy là Codex của OpenAI [1], một biến thể của mô hình 175 tỷ tham số GPT-3 [2], được đào tạo bằng cách tinh chỉnh GPT-3 trên mã từ hơn 50 triệu kho lưu trữ GitHub. Một nghiên cứu gần đây đã xếp hạng Codex ở tứ phân vị hàng đầu so với sinh viên trong một khóa học lập trình nhập môn lớn [3]. Sau đó, các nghiên cứu gần đây đã cho thấy kết quả đầy hứa hẹn trong việc sử dụng Codex cho các kịch bản giáo dục lập trình khác nhau, bao gồm tạo bài tập lập trình mới [4], cung cấp giải thích mã [5], và cải thiện thông báo lỗi lập trình [6].

Chúng tôi nghiên cứu việc sử dụng LLM để tạo phản hồi cho lỗi cú pháp lập trình, một kịch bản chính trong giáo dục lập trình nhập môn. Mặc dù những lỗi như vậy thường chỉ yêu cầu những sửa chữa nhỏ và dễ giải thích bởi các gia sư con người, chúng có thể tạo ra một trở ngại lớn trong học tập cho sinh viên mới bắt đầu [7]. Hơn nữa, các thông báo lỗi lập trình được cung cấp bởi môi trường lập trình mặc định thường khó hiểu và không thể cung cấp phản hồi có thể giải thích được cho sinh viên [8–10]. Lý tưởng nhất, một gia sư con người sẽ giúp một sinh viên mới bắt đầu bằng cách cung cấp phản hồi chi tiết mô tả các lỗi và các sửa chữa cần thiết cho chương trình có lỗi; tuy nhiên, việc cung cấp phản hồi quy mô lớn là cực kỳ tẻ nhạt/thách thức do số lượng đăng ký ngày càng tăng trong các khóa học lập trình nhập môn [11, 12]. Để đạt được điều này, mục tiêu của chúng tôi là tự động hóa quá trình tạo phản hồi bằng các kỹ thuật dựa trên LLM.

Cụ thể hơn, cho chương trình có lỗi của sinh viên, chúng tôi muốn tạo phản hồi bao gồm một chương trình đã được sửa và giải thích bằng ngôn ngữ tự nhiên mô tả các lỗi/sửa chữa, lấy cảm hứng từ cách mà một gia sư con người sẽ đưa ra phản hồi. Mặc dù các mô hình như Codex, được đào tạo trên cả văn bản và mã, là phù hợp tự nhiên cho điều này, thách thức quan trọng là đảm bảo độ chính xác cao trong phản hồi được tạo ra. Độ chính xác cao là rất quan trọng trong việc xây dựng lòng tin của các nhà giáo dục trước khi triển khai công nghệ được điều khiển bởi AI như vậy trong lớp học. Một nghiên cứu gần đây đã điều tra việc cải thiện các thông báo lỗi lập trình mặc định sử dụng Codex [6]; một trong những điểm rút ra, được trích từ bài báo của họ, là "Các ý nghĩa chính của nghiên cứu này là các giải thích thông báo lỗi lập trình và các sửa chữa được đề xuất được tạo ra bởi LLM chưa sẵn sàng để sử dụng trong sản xuất trong các lớp học lập trình nhập môn...". Các thí nghiệm ban đầu của chúng tôi (Phần 4) cũng nêu bật các vấn đề trong việc tạo phản hồi độ chính xác cao. Để đạt được điều này, câu hỏi nghiên cứu chính là:

Liệu chúng ta có thể phát triển các kỹ thuật tạo phản hồi dựa trên LLM với tham số độ chính xác có thể điều chỉnh, cho phép các nhà giáo dục kiểm soát chất lượng phản hồi mà sinh viên nhận được?

1.1 Phương Pháp Tiếp Cận và Đóng Góp của Chúng Tôi
Trong bài báo này, chúng tôi phát triển PyFiXV, kỹ thuật của chúng tôi để tạo phản hồi độ chính xác cao được hỗ trợ bởi Codex. Cho chương trình có lỗi của sinh viên làm đầu vào, PyFiXV phân tách toàn bộ quá trình thành (i) tạo phản hồi (tức là, một chương trình đã được sửa và giải thích bằng ngôn ngữ tự nhiên cho các lỗi/sửa chữa); và (ii) xác thực phản hồi (tức là, quyết định liệu phản hồi được tạo có phù hợp để chia sẻ với sinh viên hay không).

Một trong những ý tưởng chính trong PyFiXV là sử dụng cơ chế xác thực phản hồi thời gian chạy để quyết định liệu phản hồi được tạo có chất lượng tốt hay không. Cơ chế xác thực này sử dụng Codex như một mô hình sinh viên mô phỏng – trực giác là giải thích chất lượng tốt, khi được cung cấp như hướng dẫn prompt của Codex, sẽ tăng thành công của Codex trong việc chuyển đổi chương trình có lỗi thành chương trình đã được sửa. Đáng chú ý, việc xác thực này cũng cung cấp một núm độ chính xác có thể điều chỉnh cho các nhà giáo dục để kiểm soát sự đánh đổi giữa độ chính xác và độ bao phủ.

Các ví dụ minh họa trong Hình 1, 2, và 3 trình bày PyFiXV trên ba chương trình có lỗi khác nhau của sinh viên. Các đóng góp chính của chúng tôi là:

(I) Chúng tôi chính thức hóa bài toán tạo phản hồi độ chính xác cao cho lỗi cú pháp lập trình sử dụng LLM, trong đó phản hồi bao gồm một chương trình đã được sửa và giải thích bằng ngôn ngữ tự nhiên. (Phần 2)

(II) Chúng tôi phát triển một kỹ thuật mới, PyFiXV, tạo phản hồi sử dụng Codex và có cơ chế xác thực phản hồi thời gian chạy để quyết định liệu phản hồi được tạo có phù hợp để chia sẻ hay không. (Phần 3)

(III) Chúng tôi thực hiện đánh giá mở rộng sử dụng hai bộ dữ liệu thực tế của các chương trình Python có lỗi cú pháp và trình bày hiệu quả của PyFiXV. Chúng tôi công khai phát hành việc triển khai PyFiXV. (Phần 4)1

1Github: https://github.com/machine-teaching-group/edm2023_PyFiXV

--- TRANG 2 ---
1print "x"
2a = input ("xxx")
3print "Xx x"a
4b = input ("xxx xxx?")
5print " xxxxxx " a + b
(a) Chương trình có lỗi của sinh viên

1print "x"
2a = input ("xxx")
3print "Xx x"+a
4b = input ("xxx xxx?")
5print " xxxxxx " +a + b
(b) Chương trình đã sửa được tạo ra

Sinh viên quên nối chuỗi ký tự với biến. Chúng ta có thể sửa lỗi bằng cách thêm dấu cộng giữa chuỗi ký tự và biến.
(c) Giải thích được tạo ra

✓ (d) Xác thực

Hình 1: Ví dụ minh họa trình bày PyFiXV trên chương trình Python 2 có lỗi từ TigerJython [9]. (a) Chương trình có lỗi (với các chuỗi ký tự được ẩn danh thành chuỗi 'x' trong bộ dữ liệu của chúng tôi). (b, c) Chương trình đã sửa và giải thích được tạo bởi PyFiXV. (d) Cơ chế xác thực của PyFiXV đã chấp nhận thành công phản hồi được tạo là phù hợp để chia sẻ.

1for i in range (int ( input ()):
2 l1 =[]
3 for i in range (int ( input ())):
4 if i ==0:
5 if i ==0:
6 l1. appned (n)
7 elif (i==(n -1) ):
8 l1. append (1)
9 else :
10 l1. append (i)
11 print (l1)
(a) Chương trình có lỗi của sinh viên

1for i in range (int ( input ())):
2 l1 =[]
3 for i in range (int ( input ())):
4 if i ==0:
5 if i ==0:
6 l1. append (n)
7 elif (i==(n -1) ):
8 l1. append (1)
9 else :
10 l1. append (i)
11 print (l1)
(b) Chương trình đã sửa được tạo ra

Ở dòng 1, thiếu dấu ngoặc đóng khi gọi hàm 'range'. Chúng ta nên thêm dấu ngoặc đóng ở cuối dòng 1, trước dấu hai chấm, để sửa lỗi này. Ở dòng 6, hàm 'append' bị viết sai chính tả. Chúng ta nên thay thế 'appned' bằng 'append' để sửa lỗi này.
(c) Giải thích được tạo ra

✓ (d) Xác thực

Hình 2: Tương tự như Hình 1, ví dụ này trình bày PyFiXV trên chương trình Python 3 có lỗi từ Codeforces [13]. Mặc dù việc viết sai chính tả 'append' thành 'appned' không phải là lỗi cú pháp (gây ra AttributeError tại thời gian chạy thay vào đó), PyFiXV thường sửa những lỗi như vậy, cho thấy giá trị tổng quát trong kỹ thuật được hỗ trợ bởi LLM.

1import math
2
3def binary (num):
4 x=int ( math . log2 (num))+1
5 for i in range (x):
6 num =( num ^^(1 < <i))
7 print ( num )
8for i in range (int , input ()):
9 n=int ( input ())
10 binary (n)
(a) Chương trình có lỗi của sinh viên

1import math
2
3def binary (num):
4 x=int ( math . log2 (num))+1
5 for i in range (x):
6 num =( num ^ (1<<i))
7 print ( num )
8for i in range (int ( input ())):
9 n=int ( input ())
10 binary (n)
(b) Chương trình đã sửa được tạo ra

Ở dòng 6, toán tử '^^' không phải là toán tử hợp lệ trong Python 3. Chúng ta nên thay thế nó bằng '^' để sửa lỗi này. Ở dòng 8, thiếu dấu ngoặc đóng khi gọi hàm 'range'. Chúng ta nên thêm dấu ngoặc đóng ở cuối dòng 8, trước dấu hai chấm, để sửa lỗi này.
(c) Giải thích được tạo ra

✗ (d) Xác thực

Hình 3: Tương tự như Hình 2, ví dụ này trình bày PyFiXV trên chương trình Python 3 có lỗi từ Codeforces [13]. Cơ chế xác thực của PyFiXV đã từ chối thành công phản hồi được tạo ra (chúng tôi đánh dấu văn bản trong (c) để làm nổi bật các vấn đề với giải thích).

báo lỗi lập trình và các sửa chữa được đề xuất được tạo ra bởi LLM chưa sẵn sàng để sử dụng trong sản xuất trong các lớp học lập trình nhập môn...". Các thí nghiệm ban đầu của chúng tôi (Phần 4) cũng nêu bật các vấn đề trong việc tạo phản hồi độ chính xác cao. Để đạt được điều này, câu hỏi nghiên cứu chính là:

Liệu chúng ta có thể phát triển các kỹ thuật tạo phản hồi dựa trên LLM với tham số độ chính xác có thể điều chỉnh, cho phép các nhà giáo dục kiểm soát chất lượng phản hồi mà sinh viên nhận được?

1.1 Phương Pháp Tiếp Cận và Đóng Góp của Chúng Tôi

Trong bài báo này, chúng tôi phát triển PyFiXV, kỹ thuật của chúng tôi để tạo phản hồi độ chính xác cao được hỗ trợ bởi Codex. Cho chương trình có lỗi của sinh viên làm đầu vào, PyFiXV phân tách toàn bộ quá trình thành (i) tạo phản hồi (tức là, một chương trình đã được sửa và giải thích bằng ngôn ngữ tự nhiên cho các lỗi/sửa chữa); và (ii) xác thực phản hồi (tức là, quyết định liệu phản hồi được tạo có phù hợp để chia sẻ với sinh viên hay không).

Một trong những ý tưởng chính trong PyFiXV là sử dụng cơ chế xác thực phản hồi thời gian chạy để quyết định liệu phản hồi được tạo có chất lượng tốt hay không. Cơ chế xác thực này sử dụng Codex như một mô hình sinh viên mô phỏng – trực giác là giải thích chất lượng tốt, khi được cung cấp như hướng dẫn prompt của Codex, sẽ tăng thành công của Codex trong việc chuyển đổi chương trình có lỗi thành chương trình đã được sửa. Đáng chú ý, việc xác thực này cũng cung cấp một núm độ chính xác có thể điều chỉnh cho các nhà giáo dục để kiểm soát sự đánh đổi giữa độ chính xác và độ bao phủ.

Các ví dụ minh họa trong Hình 1, 2, và 3 trình bày PyFiXV trên ba chương trình có lỗi khác nhau của sinh viên. Các đóng góp chính của chúng tôi là:

(I) Chúng tôi chính thức hóa bài toán tạo phản hồi độ chính xác cao cho lỗi cú pháp lập trình sử dụng LLM, trong đó phản hồi bao gồm một chương trình đã được sửa và giải thích bằng ngôn ngữ tự nhiên. (Phần 2)

(II) Chúng tôi phát triển một kỹ thuật mới, PyFiXV, tạo phản hồi sử dụng Codex và có cơ chế xác thực phản hồi thời gian chạy để quyết định liệu phản hồi được tạo có phù hợp để chia sẻ hay không. (Phần 3)

(III) Chúng tôi thực hiện đánh giá mở rộng sử dụng hai bộ dữ liệu thực tế của các chương trình Python có lỗi cú pháp và trình bày hiệu quả của PyFiXV. Chúng tôi công khai phát hành việc triển khai PyFiXV. (Phần 4)1

1Github: https://github.com/machine-teaching-group/edm2023_PyFiXV

--- TRANG 3 ---
1.2 Nghiên Cứu Liên Quan

Tạo phản hồi cho lỗi lập trình. Đã có nhiều nghiên cứu mở rộng về tạo phản hồi cho lỗi cú pháp/ngữ nghĩa lập trình [14–18]; tuy nhiên, những nghiên cứu này đã tập trung vào việc sửa/khắc phục chương trình có lỗi mà không cung cấp giải thích. Nghiên cứu trong [11] đã đề xuất một kỹ thuật để tạo giải thích; tuy nhiên, nó yêu cầu các quy tắc được xác định trước ánh xạ lỗi thành giải thích. Một hướng nghiên cứu khác, bổ sung cho nghiên cứu của chúng tôi, đã khám phá các phương pháp tiếp cận huy động đám đông để có được giải thích được cung cấp bởi các sinh viên/gia sư khác [19, 20]. Cũng đã có nhiều nghiên cứu mở rộng về việc cải thiện thông báo lỗi lập trình bằng cách thiết kế các môi trường tùy chỉnh [9, 10]. Như đã thảo luận trước đó, một nghiên cứu gần đây đã sử dụng Codex để cải thiện những thông báo lỗi này [6]; tuy nhiên, nghiên cứu của chúng tôi khác biệt vì chúng tôi tập trung vào việc tạo phản hồi độ chính xác cao với núm độ chính xác có thể điều chỉnh.

Xác thực nội dung được tạo ra. Trong nghiên cứu gần đây, [21] đã phát triển một kỹ thuật để xác thực đầu ra của LLM trong bối cảnh tổng hợp chương trình. Mặc dù tương tự về tinh thần, cơ chế xác thực của họ khác biệt và hoạt động bằng cách yêu cầu LLM tạo ra các vị từ để kiểm tra các chương trình được tổng hợp. Một phương pháp tiếp cận khả thi khác là sử dụng các mô hình dịch ngược để xác thực nội dung được tạo ra [22, 23]; tuy nhiên, một mô hình dịch ngược như vậy (tạo ra chương trình có lỗi từ giải thích) không sẵn có cho bối cảnh của chúng tôi. Một phương pháp tiếp cận khác, bổ sung cho nghiên cứu của chúng tôi, là sử dụng con người trong vòng lặp để xác thực các đầu ra có độ tin cậy thấp [24].

2. THIẾT LẬP BÀI TOÁN

Tiếp theo, chúng tôi giới thiệu các định nghĩa và chính thức hóa mục tiêu của chúng tôi.

2.1 Kiến Thức Cơ Bản

Chương trình có lỗi của sinh viên. Xét một sinh viên đang làm bài tập lập trình đã viết một chương trình có lỗi với lỗi cú pháp, như được hiển thị trong Hình 1a, 2a, và 3a. Chính thức, những lỗi cú pháp này được định nghĩa bởi trình phân tích cú pháp cơ bản của ngôn ngữ lập trình [14]; chúng tôi sẽ sử dụng ngôn ngữ lập trình Python trong đánh giá của chúng tôi. Từ đây, chúng tôi ký hiệu chương trình có lỗi như vậy là Pb, được cung cấp làm đầu vào cho các kỹ thuật tạo phản hồi.

Phong cách phản hồi. Cho Pb, chúng tôi tìm cách tạo phản hồi bao gồm một chương trình đã được sửa cùng với giải thích bằng ngôn ngữ tự nhiên mô tả các lỗi và sửa chữa. Phong cách phản hồi này được lấy cảm hứng từ cách mà một gia sư con người sẽ đưa ra phản hồi cho sinh viên mới bắt đầu trong giáo dục lập trình nhập môn [5, 9]. Chúng tôi ký hiệu chương trình đã được sửa được tạo ra là Pf, giải thích được tạo ra là X, và phản hồi được tạo ra là một bộ (Pf, X).

Chất lượng phản hồi. Chúng tôi đánh giá chất lượng phản hồi được tạo ra (Pf, X) đối với Pb theo các thuộc tính nhị phân sau:
(i) Pf có cú pháp đúng và được có được bằng cách thực hiện một số lượng nhỏ chỉnh sửa để sửa Pb; (ii) X hoàn chỉnh, tức là, chứa thông tin về tất cả lỗi và sửa chữa cần thiết; (iii) X đúng, tức là, thông tin được cung cấp giải thích chính xác các lỗi và sửa chữa cần thiết; (iv) X dễ hiểu, tức là, dễ hiểu, được trình bày theo định dạng có thể đọc được, và không chứa thông tin dư thừa. Những thuộc tính này được lấy cảm hứng từ các rubric đánh giá được sử dụng trong tài liệu [6, 25–27].

Trong đánh giá của chúng tôi, chất lượng phản hồi được đánh giá thông qua xếp hạng của các chuyên gia theo bốn thuộc tính này. Chúng tôi đo chất lượng phản hồi như nhị phân bằng cách gán giá trị 1 (chất lượng tốt) nếu nó thỏa mãn tất cả bốn thuộc tính chất lượng và ngược lại 0 (chất lượng xấu).2

2.2 Các Chỉ Số Hiệu Suất và Mục Tiêu

Các chỉ số hiệu suất. Tiếp theo, chúng tôi mô tả các chỉ số hiệu suất tổng thể được sử dụng để đánh giá kỹ thuật tạo phản hồi. Đối với chương trình có lỗi Pb làm đầu vào, chúng tôi tìm cách thiết kế các kỹ thuật tạo phản hồi (Pf, X) và cũng quyết định liệu phản hồi được tạo có phù hợp để chia sẻ với sinh viên hay không. Chúng tôi đo hiệu suất của một kỹ thuật bằng hai chỉ số: (i) Độ bao phủ đo phần trăm số lần phản hồi được tạo ra và cung cấp cho sinh viên; (ii) Độ chính xác đo phần trăm số lần phản hồi được cung cấp có chất lượng tốt đối với tiêu chí chất lượng phản hồi nhị phân được giới thiệu ở trên. Trong các thí nghiệm của chúng tôi, chúng tôi sẽ tính toán những chỉ số này trên bộ dữ liệu Dtest = {Pb} bao gồm một tập hợp các chương trình có lỗi của sinh viên.3

Mục tiêu. Mục tiêu của chúng tôi là thiết kế các kỹ thuật tạo phản hồi với độ chính xác cao, điều này rất quan trọng trước khi triển khai những kỹ thuật như vậy trong lớp học. Đặc biệt, chúng tôi muốn phát triển các kỹ thuật với tham số độ chính xác có thể điều chỉnh có thể cung cấp một núm cho các nhà giáo dục để kiểm soát sự đánh đổi giữa độ chính xác và độ bao phủ.

3. KỸ THUẬT CỦA CHÚNG TÔI PYFIXV

Trong phần này, chúng tôi trình bày PyFiXV, kỹ thuật của chúng tôi để tạo phản hồi độ chính xác cao sử dụng LLM. PyFiXV sử dụng Codex của OpenAPI làm LLM [1] – Codex đã cho thấy hiệu suất cạnh tranh trên nhiều benchmark lập trình khác nhau [1, 3, 17, 18], và đặc biệt phù hợp cho PyFiXV vì chúng tôi tìm cách tạo ra cả chương trình đã được sửa và giải thích bằng ngôn ngữ tự nhiên. Cụ thể hơn, PyFiXV sử dụng hai điểm truy cập của Codex được cung cấp bởi OpenAI thông qua API công khai: Codex-Edit [28] và Codex-Complete [29]. Như được minh họa trong Hình 4, PyFiXV có ba thành phần/giai đoạn sau: (1) tạo chương trình đã được sửa Pf bằng cách chỉnh sửa Pb sử dụng Codex-Edit; (2) tạo giải thích bằng ngôn ngữ tự nhiên X sử dụng Codex-Complete; (3) xác thực phản hồi (Pf, X) sử dụng Codex-Edit để quyết định liệu phản hồi được tạo có phù hợp để chia sẻ hay không. Pipeline tổng thể của PyFiXV là mô-đun và chúng tôi sẽ đánh giá tính hữu ích của các thành phần khác nhau trong Phần 4. Tiếp theo, chúng tôi cung cấp chi tiết cho từng giai đoạn này.

2Chúng tôi lưu ý rằng bốn thuộc tính là độc lập. Đặc biệt, thuộc tính "hoàn chỉnh" nắm bắt liệu giải thích có chứa thông tin về tất cả lỗi/sửa chữa hay không (mặc dù thông tin có thể sai), và thuộc tính "đúng" nắm bắt tính đúng đắn của thông tin được cung cấp.

3Khi một kỹ thuật không thể tạo phản hồi cho chương trình đầu vào Pb (ví dụ, kỹ thuật không thể tìm thấy chương trình đã được sửa), thì chúng tôi sử dụng quy ước tự nhiên là không có phản hồi nào được cung cấp cho sinh viên—quy ước này làm giảm chỉ số độ bao phủ nhưng không ảnh hưởng trực tiếp đến chỉ số độ chính xác.

--- TRANG 4 ---
Chương trình Đầu vào cho Codex-Edit
1for i in range (int ( input ()):
2 l1 =[]
3 for i in range (int ( input ())):
4 if i ==0:
5 if i ==0:
6 l1. appned (n)
7 elif (i==(n -1)):
8 l1. append (1)
9 else :
10 l1. append (i)
11 print (l1)

Hướng dẫn cho Codex-Edit
Sửa lỗi cú pháp trong mã Python 3 này
(a) Prompt Giai đoạn-1 để tạo Pf

Prompt cho Codex-Complete
1# Python 3
2# Đưa ra phản hồi cho việc sửa lỗi cú pháp dưới đây:
3
4...... < ví dụ few-shot 1 >......
5...... < ví dụ few-shot 2 >......
6...... < ví dụ few-shot 3 >......
7
8# [ PYTHON 3 CÓ LỖI ]
9for i in range ( int ( input ()):
10 l1 =[]
11 for i in range (int ( input ())):
12 if i ==0:
13 if i ==0:
14 l1. appned (n)
15 elif (i==(n -1) ):
16 l1. append (1)
17 else :
18 l1. append (i)
19 print (l1)
20
21
22# [ SỬA CHỮA ]
231c1
24< for i in range ( int ( input ()):
25 ---
26> for i in range ( int ( input ())):
276c6
28< l1. appned (n)
29 ---
30> l1. append (n)
31
32
33# [ PHẢN HỒI ] Lỗi cú pháp trong mã Python 3 này là:
(b) Prompt Giai đoạn-2 để tạo X

Chương trình Đầu vào cho Codex-Edit
1for i in range ( int ( input ()):
2 l1 =[]
3 for i in range (int ( input ())):
4 if i ==0:
5 if i ==0:
6 l1. appned (n)
7 elif (i==(n -1) ):
8 l1. append (1)
9 else :
10 l1. append (i)
11 print (l1)

Hướng dẫn cho Codex-Edit
Lỗi cú pháp trong mã Python 3 này là: Ở dòng 1, thiếu dấu ngoặc đóng khi gọi hàm 'range'. Chúng ta nên thêm dấu ngoặc đóng ở cuối dòng 1, trước dấu hai chấm, để sửa lỗi này. Ở dòng 6, hàm 'append' bị viết sai chính tả. Chúng ta nên thay thế 'appned' bằng 'append' để sửa lỗi này.
(c) Prompt Giai đoạn-3 để xác thực (Pf, X)

Hình 5: Minh họa các prompt được sử dụng bởi các giai đoạn khác nhau của PyFiXV cho chương trình Python 3 có lỗi trong Hình 2. Đặc biệt, "Hướng dẫn cho Codex-Edit" trong (c) được tạo ra bằng cách nối dòng 33 của (b) và X được tạo ra hiển thị trong Hình 2c.

3.1 Giai đoạn-1: Tạo Chương trình Đã Sửa

Cho chương trình có lỗi Pb của sinh viên làm đầu vào, Giai đoạn-1 của PyFiXV tạo ra chương trình đã được sửa Pf. Chúng tôi sử dụng Codex-Edit để sửa/khắc phục chương trình có lỗi trong giai đoạn này vì nó đã cho thấy hiệu suất cạnh tranh trong các benchmark sửa chữa chương trình trong các nghiên cứu gần đây [30]. Hình 5a cho thấy một prompt mẫu được sử dụng bởi PyFiXV để truy vấn Codex-Edit cho chương trình Python 3 có lỗi trong Hình 2a. Quá trình tạo Pf được xác định bởi hai siêu tham số: (i) t1 ∈ [0.0, 1.0] là giá trị nhiệt độ được chỉ định khi truy vấn Codex-Edit và kiểm soát tính ngẫu nhiên/đa dạng trong các chương trình được tạo ra; (ii) n1 kiểm soát số lượng truy vấn được thực hiện đến Codex-Edit.

Cụ thể hơn, PyFiXV bắt đầu bằng cách thực hiện n1 truy vấn đến Codex-Edit với nhiệt độ t1. Sau đó, trong số n1 chương trình được tạo ra, PyFiXV chọn Pf là chương trình có cú pháp đúng và có khoảng cách chỉnh sửa nhỏ nhất đến Pb. Ở đây, khoảng cách chỉnh sửa giữa hai chương trình được đo bằng cách đầu tiên tokenize các chương trình sử dụng thư viện Pygments [31] và sau đó tính toán khoảng cách chỉnh sửa Levenshtein trên các chuỗi token.4 Nếu Giai đoạn-1 không thể tạo ra chương trình đã được sửa, quá trình dừng lại mà không tạo ra phản hồi nào; xem Chú thích 3. Trong các thí nghiệm của chúng tôi, chúng tôi đặt (t1 = 0.5, n1 = 10) và có được tỷ lệ thành công cao trong việc tạo ra chương trình đã được sửa Pf với số lượng chỉnh sửa nhỏ đối với Pb.

3.2 Giai đoạn-2: Tạo Giải thích

Cho Pb và Pf làm đầu vào, Giai đoạn-2 của PyFiXV tạo ra giải thích bằng ngôn ngữ tự nhiên X mô tả các lỗi/sửa chữa. Chúng tôi sử dụng Codex-Complete trong giai đoạn này vì nó phù hợp tự nhiên để tạo văn bản bằng cách hoàn thành một prompt [1, 5, 6]. Một thành phần quan trọng của Giai đoạn-2 là bộ dữ liệu chú thích Dshot được sử dụng để chọn các ví dụ few-shot khi truy vấn Codex-Complete (xem Hình 4). Hình 5b cho thấy một prompt mẫu được sử dụng bởi PyFiXV để truy vấn Codex-Complete cho kịch bản trong Hình 2. Trong Hình 5b, dòng 4–dòng 6 chỉ ra ba ví dụ few-shot (không hiển thị để tiết kiệm), dòng 9–dòng 19 cung cấp Pb, dòng 23–dòng 30 cung cấp Pf dưới dạng line-diff đối với Pb, và dòng 33 là hướng dẫn được hoàn thành bởi Codex-Complete. Cho một prompt, quá trình tạo X được xác định bởi hai siêu tham số: (i) giá trị nhiệt độ t2 (= 0) và (ii) số lượng truy vấn n2 (= 1). Tiếp theo, chúng tôi thảo luận về vai trò của Dshot trong việc chọn ví dụ few-shot.

Khi truy vấn Codex-Complete, chúng tôi sử dụng ba ví dụ few-shot được chọn từ Dshot, một bộ dữ liệu chú thích gồm các ví dụ bao gồm các chương trình có lỗi và phản hồi mong muốn thu được bởi chú thích chuyên gia (xem Phần 4.2). Những ví dụ chú thích này về cơ bản cung cấp ngữ cảnh cho LLM và đã được chứng minh đóng vai trò quan trọng trong việc tối ưu hóa đầu ra được tạo ra (ví dụ, xem [1, 2, 17, 18, 32]). Trong trường hợp của chúng tôi, Dshot cung cấp dữ liệu huấn luyện theo ngữ cảnh, nắm bắt định dạng của cách các chuyên gia/gia sư đưa ra giải thích. Cho Pb và Pf, chúng tôi sử dụng hai tiêu chí chính để chọn ví dụ few-shot. Tiêu chí chính là chọn các ví dụ mà loại lỗi của chương trình có lỗi trong ví dụ giống với của Pb—trình phân tích cú pháp/biên dịch cơ bản cung cấp các loại lỗi (ví dụ, 'InvalidSyntax', 'UnexpectedIndent'). Tiêu chí phụ (được sử dụng để phá vỡ mối quan hệ trong quá trình lựa chọn) dựa trên khoảng cách chỉnh sửa giữa diff của chương trình có lỗi/đã sửa trong ví dụ và diff của Pb/Pf. Trong Phần 4, chúng tôi tiến hành ablation để cho thấy tầm quan trọng của việc chọn few-shot.

3.3 Giai đoạn-3: Xác thực Phản hồi

Cho Pb và (Pf, X) làm đầu vào, Giai đoạn-3 của PyFiXV xác thực chất lượng phản hồi và đưa ra quyết định nhị phân về việc

4Lưu ý rằng các chương trình có lỗi không thể phân tích cú pháp thành biểu diễn Abstract Syntax Tree (AST) và khoảng cách dựa trên chuỗi thường được sử dụng trong những bối cảnh như vậy (ví dụ, xem [17]).

--- TRANG 5 ---
Kỹ thuật TigerJython Codeforces
Độ chính xác Độ bao phủ Độ chính xác Độ bao phủ
PyFi-PEM 05.0 (1.0) 92.5 (1.6) 35.0 (2.4) 98.8 (0.8)
PyFiX shot: None 00.9 (0.5) 92.5 (1.6) 03.0 (0.4) 98.8 (0.8)
PyFiX shot: Rand 21.6 (1.7) 92.5 (1.6) 48.5 (2.6) 98.8 (0.8)
PyFiX shot: Sel 38.9 (3.5) 92.5 (1.6) 55.2 (3.9) 98.8 (0.8)
PyFi ||X shot: Sel 15.8 (1.8) 92.5 (1.6) 15.6 (2.8) 98.8 (0.8)
PyFiX-Rule P70 48.6 (4.4) 30.8 (12.5) 61.6 (9.0) 38.3 (10.5)
PyFiXV P70 76.0 (4.0) 31.2 (4.0) 72.4 (6.2) 64.2 (6.3)
PyFiX-Opt PVP70 76.1 (0.4) 47.1 (3.4) 72.8 (0.1) 75.0 (5.7)

(a) Kết quả cho các kỹ thuật khác nhau, báo cáo dưới dạng trung bình (stderr)

[Biểu đồ 6b: TigerJython trade-off curve]
[Biểu đồ 6c: Codeforces trade-off curve]

Hình 6: Kết quả thí nghiệm trên hai bộ dữ liệu thực tế của các chương trình Python, cụ thể là TigerJython [9] và Codeforces [13].

"chấp nhận" (phản hồi phù hợp để chia sẻ) hoặc "từ chối" (phản hồi bị loại bỏ). PyFiXV sử dụng cơ chế xác thực phản hồi thời gian chạy mới sử dụng Codex-Edit để quyết định liệu phản hồi (Pf, X) đối với Pb có chất lượng tốt hay không. Ở đây, Codex-Edit được sử dụng trong vai trò đảo ngược của một mô hình sinh viên mô phỏng – trực giác là giải thích chất lượng tốt X, khi được cung cấp trong hướng dẫn prompt của Codex-Edit, sẽ tăng thành công của Codex-Edit trong việc chuyển đổi Pb thành Pf. Hình 5c cho thấy một prompt mẫu được sử dụng bởi PyFiXV để truy vấn Codex-Edit cho kịch bản trong Hình 2—xem chú thích về cách "Hướng dẫn cho Codex-Edit" trong Hình 5c được tạo ra.5

Cơ chế xác thực có ba siêu tham số: (i) t3 ∈ [0.0, 1.0] là giá trị nhiệt độ được chỉ định khi truy vấn Codex-Edit; (ii) n3 kiểm soát số lượng truy vấn được thực hiện đến Codex-Edit; (iii) h3 ∈ [1, n3] là ngưỡng được sử dụng cho quyết định chấp nhận. Cụ thể hơn, PyFiXV bắt đầu bằng cách thực hiện n3 truy vấn đến Codex-Edit với nhiệt độ t3. Sau đó, trong số n3 chương trình được tạo ra, PyFiXV đếm số lượng chương trình không có lỗi cú pháp và có khớp chính xác với Pf. Ở đây, khớp chính xác được kiểm tra bằng cách chuyển đổi các chương trình thành biểu diễn chuẩn hóa dựa trên Abstract Syntax Tree (AST) của chúng.6 Cuối cùng, cơ chế xác thực chấp nhận phản hồi nếu số lượng khớp chính xác ít nhất là h3. Những siêu tham số này (t3, n3, h3) cũng cung cấp một núm độ chính xác và được chọn để đạt được mức độ chính xác mong muốn, như được thảo luận tiếp theo.

3.4 Đánh Đổi Độ Chính Xác và Độ Bao Phủ

Cơ chế xác thực của PyFiXV cung cấp một núm độ chính xác để kiểm soát sự đánh đổi giữa độ chính xác và độ bao phủ (xem các chỉ số hiệu suất trong Phần 2.2). Gọi P là mức độ chính xác mong muốn mà chúng tôi muốn đạt được cho PyFiXV. Ý tưởng là chọn các siêu tham số Giai đoạn-3 (t3, n3, h3) để đạt được mức độ chính xác P. Cho mục đích này, chúng tôi sử dụng bộ dữ liệu hiệu chuẩn Dcal để

5 Trong các thí nghiệm ban đầu của chúng tôi, chúng tôi đã thử sử dụng các tín hiệu thay thế cho xác thực, chẳng hạn như (a) xác suất của Codex-Complete liên quan đến X được tạo ra; (b) chấm điểm tự động của X đối với giải thích trong few-shot sử dụng điểm BLEU [33]; (c) lọc dựa trên độ dài của X. Phần 4 báo cáo kết quả cho (c) vì nó có hiệu suất cao nhất trong số các phương án thay thế này.

6 Chúng tôi kiểm tra khớp chính xác dựa trên AST thay vì kiểm tra khoảng cách chỉnh sửa Levenshtein trên chuỗi token bằng 0 (xem Phần 3.1). Khớp chính xác dựa trên AST thoải mái hơn so với khoảng cách chỉnh sửa bằng 0 – biểu diễn dựa trên AST bỏ qua một số khác biệt nhất định giữa các mã, ví dụ, dựa trên khoảng trắng và chú thích thêm. Chúng tôi đã sử dụng khớp chính xác dựa trên AST trong cơ chế xác thực vì nó mạnh mẽ hơn đối với những khác biệt như vậy.

chọn các siêu tham số. Cụ thể hơn, trong các thí nghiệm của chúng tôi, PyFiXV đầu tiên tính toán các chỉ số hiệu suất trên Dcal cho phạm vi giá trị sau: (i) t3 ∈ {0.3, 0.5, 0.8}; (ii) n3 ∈ {10}; (iii) h3 ∈ {1, 2, ..., 10}. Sau đó, nó chọn (t3, n3, h3) có ít nhất mức độ chính xác P và tối đa hóa độ bao phủ; khi việc đạt được P mong muốn không thể thực hiện được, thì mức độ chính xác thấp hơn tiếp theo có thể được xem xét. Các giá trị được chọn của siêu tham số sau đó được sử dụng trong cơ chế xác thực Giai đoạn-3 của PyFiXV. Chúng tôi gọi PyFiXV Px là phiên bản PyFiXV được hiệu chuẩn với P = x.

4. ĐÁNH GIÁ THỰC NGHIỆM

Chúng tôi thực hiện đánh giá sử dụng hai bộ dữ liệu lập trình Python thực tế, cụ thể là TigerJython [9] và Codeforces [13]. Chúng tôi chọn Python vì sự phổ biến ngày càng tăng của nó như một ngôn ngữ lập trình nhập môn; đáng chú ý, PyFiXV có thể được sử dụng với các ngôn ngữ khác bằng cách thay đổi thích hợp các prompt và tokenizer được sử dụng. Chúng tôi sử dụng API công khai của OpenAI cho Codex-Edit [28] (model=code-davinci-edit-001) và Codex-Complete [29] (model=code-davinci-002). Chúng tôi bắt đầu bằng cách mô tả các kỹ thuật khác nhau được sử dụng trong đánh giá.

4.1 Baseline và Các Biến Thể của PYFIXV

Thông báo lỗi lập trình mặc định không có xác thực. Là baseline đầu tiên của chúng tôi, PyFi-PEM sử dụng Giai đoạn-1 của PyFiXV để tạo Pf và sử dụng thông báo lỗi lập trình được cung cấp bởi môi trường lập trình làm X. PyFi-PEM sử dụng thông báo lỗi được cung cấp bởi môi trường Python 2.7 cho TigerJython và môi trường Python 3.12 cho Codeforces. Baseline này không có xác thực (tức là, phản hồi được tạo ra luôn được chấp nhận).

Các biến thể của PyFiXV không có xác thực. PyFiX shot: Sel là biến thể của PyFiXV không có cơ chế xác thực (tức là, chỉ sử dụng Giai đoạn-1 và Giai đoạn-2). PyFiX shot: Rand là biến thể của PyFiX shot: Sel trong đó các ví dụ few-shot trong Giai đoạn-2 được chọn ngẫu nhiên từ Dshot. PyFiX shot: None là biến thể của PyFiX shot: Sel không sử dụng ví dụ few-shot trong Giai đoạn-2. PyFi ||X shot: Sel là biến thể của PyFiX shot: Sel chạy Giai đoạn-1 và Giai đoạn-2 song song; do đó, prompt của Giai đoạn-2 không sử dụng Pf. Tất cả những biến thể này không có xác thực (tức là, phản hồi được tạo ra luôn được chấp nhận).

Kỹ thuật với cơ chế xác thực thay thế. Chúng tôi xem xét hai biến thể của PyFiXV, cụ thể là PyFiX-Rule và PyFiX-Opt, sử dụng các cơ chế xác thực khác nhau (tức là, thay thế Giai đoạn-3 của PyFiXV bằng xác thực thay thế).

--- TRANG 6 ---
1import time
2
3def cd( seconds ):
4 while seconds > 0:
5 rem_m = seconds // 60
6 rem_s = seconds % 60
7 remaining_time = str ( rem_m ) + " minutes " + str ( rem_s ) + " seconds "
8 print ( remaining_time , end ='\r')
9 seconds = seconds - 1
10 time . sleep (1)
11
12 print (" Xxxxx xxxxX ")
13
14cd (60)
(a) Chương trình có lỗi Pb của sinh viên

1from __future__ import print_function
2import time
3
4def cd( seconds ):
5 while seconds > 0:
6 rem_m = seconds // 60
7 rem_s = seconds % 60
8 remaining_time = str ( rem_m ) + " minutes " + str ( rem_s ) + " seconds "
9 print ( remaining_time , end ='\r')
10 seconds = seconds - 1
11 time . sleep (1)
12
13 print (" Xxxxx xxxxX ")
14
15cd (60)
(b) Pf được tạo ra

Sinh viên muốn sử dụng hàm print từ Python 3. Để làm được điều này, cách đúng là thêm dòng 'from __future__ import print_function' ở đầu mã.
(c) X được tạo ra

✓ (d) Xác thực

Hình 7: Tương tự như Hình 1, ví dụ minh họa này trình bày PyFiXV trên chương trình Python 2 có lỗi từ TigerJython [9].

1name = input (" Xxx xx?")
2num = input ("Xxx xx xxxxxxx ?")
3print (" Xxxx " + name + " Xxx ")*,num
(a) Chương trình có lỗi Pb của sinh viên

1name = input ("Xxx xx?")
2num = input ("Xxx xx xxxxxxx ?")
3print (" Xxxx " + name + " Xxx ")*num
(b) Pf được tạo ra

Sinh viên quên đặt chuỗi ký tự trong dấu ngoặc kép. Chúng ta có thể sửa lỗi bằng cách đặt chuỗi ký tự ở dòng 3 trong một cặp dấu ngoặc kép.
(c) X được tạo ra

✗ (d) Xác thực

Hình 8: Tương tự như Hình 3, ví dụ này trình bày PyFiXV trên chương trình Python 2 có lỗi từ TigerJython [9]. Cơ chế xác thực của PyFiXV đã từ chối thành công phản hồi được tạo ra (chúng tôi đánh dấu văn bản trong (c) để làm nổi bật các vấn đề với giải thích).

PyFiX-Rule xác thực (Pf, X) dựa trên độ dài của X, như đã lưu ý trong Chú thích 5. Cho siêu tham số hr, (Pf, X) được chấp nhận nếu số lượng token trong X tối đa là hr, trong đó tokenization được thực hiện bằng cách tách trên khoảng trắng/dấu chấm câu. hr của PyFiX-Rule được chọn từ tập hợp {30, 40, 50, ..., 200} dựa trên mức độ chính xác mong muốn P, bằng cách tuân theo quá trình hiệu chuẩn trong Phần 3.4. PyFiX-Opt sử dụng xác thực oracle có quyền truy cập vào xếp hạng của chuyên gia cho phản hồi được tạo ra (Pf, X). Sau đó, đối với P mong muốn, PyFiX-Opt thực hiện xác thực tối ưu và làm nổi bật độ bao phủ tối đa có thể đạt được trên Dtest cho phản hồi được tạo ra.

4.2 Bộ Dữ Liệu và Quy Trình Đánh Giá

Bộ dữ liệu và chú thích cho ví dụ few-shot. Là bộ dữ liệu đầu tiên của chúng tôi, cụ thể là TigerJython, chúng tôi có 240 chương trình Python 2 riêng biệt được viết bởi sinh viên trong môi trường lập trình giáo dục TigerJython [9]. Chúng tôi có được phiên bản riêng tư và ẩn danh của bộ dữ liệu được sử dụng trong [34], với các chuỗi ký tự trong chương trình được thay thế bằng chuỗi 'x' (ví dụ, xem Hình 1). Là bộ dữ liệu thứ hai của chúng tôi, cụ thể là Codeforces, chúng tôi đã tuyển chọn 240 chương trình Python 3 riêng biệt từ trang web Codeforces sử dụng API công khai của họ [13], lấy cảm hứng từ các nghiên cứu tương tự tuyển chọn bộ dữ liệu Codeforces [35, 36]. Các chương trình trong cả hai bộ dữ liệu đều có lỗi cú pháp và có độ dài token tối đa 500 (xem Phần 3.1 về tokenization chương trình).

Đối với bộ dữ liệu Codeforces, chúng tôi chỉ bao gồm các chương trình được gửi đến các cuộc thi được tổ chức từ tháng 7 năm 2021 trở đi (sau ngày cắt dữ liệu huấn luyện của Codex [1]). Vì một phần của những bộ dữ liệu này sẽ được sử dụng cho ví dụ few-shot (như Dshot trong Giai đoạn-2 của PyFiXV), chúng tôi đã yêu cầu các chuyên gia chú thích 480 chương trình này với phản hồi (tức là, một chương trình đã được sửa cùng với giải thích). Ba chuyên gia, với kinh nghiệm rộng rãi trong lập trình Python và dạy học, đã cung cấp chú thích.

Quy trình đánh giá và xếp hạng phản hồi. Cho bộ dữ liệu D với 240 chương trình có lỗi, chúng tôi có thể đánh giá một kỹ thuật bằng cách chia D như sau: (a) Dtest (25%) để báo cáo các chỉ số hiệu suất độ chính xác và độ bao phủ; (b) Dshot (50%) cho ví dụ few-shot; (c) Dcal (25%) để hiệu chuẩn cơ chế xác thực. Để báo cáo hiệu suất tổng thể cho các kỹ thuật, chúng tôi thực hiện quy trình cross-validation với bốn vòng đánh giá trong khi đảm bảo rằng Dtest qua bốn vòng không chồng chéo. Sau đó chúng tôi báo cáo kết quả tổng hợp qua các vòng này dưới dạng trung bình (stderr). Như đã thảo luận trong Phần 2.1 và 2.2, việc đánh giá những chỉ số hiệu suất này đòi hỏi xếp hạng phản hồi bởi các chuyên gia để đánh giá chất lượng phản hồi được tạo ra bởi mỗi kỹ thuật.7 Ví dụ, việc đánh giá các chỉ số trên bộ dữ liệu TigerJython cho PyFiXV đòi hỏi 480 xếp hạng phản hồi (4 × 60 cho Dtest và 4 × 60 cho Dcal). Để bắt đầu, chúng tôi đã thực hiện một cuộc điều tra quy mô nhỏ hơn để thiết lập tiêu chí xếp hạng, trong đó hai chuyên gia đã xếp hạng 100 phiên bản phản hồi được tạo ra; chúng tôi có được giá trị độ tin cậy kappa của Cohen là 0.72 cho thấy sự đồng ý đáng kể giữa các chuyên gia [37]. Sau đó, một chuyên gia (với kinh nghiệm dạy các lớp lập trình Python) đã thực hiện những xếp hạng phản hồi này cho kết quả đánh giá.8

4.3 Kết Quả

So sánh các kỹ thuật khác nhau. Hình 6a cung cấp so sánh các kỹ thuật khác nhau trên hai bộ dữ liệu. Tất cả các kỹ thuật ở đây sử dụng Giai đoạn-1 của PyFiXV để có được Pf. Các con số độ bao phủ 92.5 và 98.8 được báo cáo trong Hình 6a tương ứng với tỷ lệ thành công của việc có được Pf trên những bộ dữ liệu này (khoảng cách chỉnh sửa trung bình giữa Pb và Pf là khoảng 10.4 và 7.5 token trên những bộ dữ liệu này, tương ứng). Đối với baseline PyFi-PEM của chúng tôi, chúng tôi thấy sự tăng lớn về độ chính xác từ 5.0 cho TigerJython (Python 2) lên 35.0 cho Codeforces (Python 3), do thông báo lỗi được cải thiện trong các phiên bản Python gần đây [38–40]. Kết quả cho PyFiXV P70 so với kết quả cho PyFiX shot: Sel, PyFiX shot: Rand, PyFiX shot: None, và PyFi ||X shot: Sel cho thấy tính hữu ích của các thành phần khác nhau được sử dụng trong pipeline của PyFiXV. So sánh PyFiXV P70 với PyFiX-Rule P70 cho thấy xác thực của PyFiXV vượt trội đáng kể so với xác thực của PyFiX-Rule.9 Cuối cùng, kết quả cho PyFiX-Opt PVP70 được có được bằng cách đặt mức độ chính xác mong muốn cho PyFiX-Opt khớp với của PyFiXV P70 trên Dtest – các con số độ bao phủ (47.1 cho TigerJython và 75.0 cho Codeforces) cho thấy độ bao phủ tối đa có thể đạt được. Đáng chú ý, PyFiXV P70 đạt được độ bao phủ cạnh tranh 64.2 trên Codeforces.10

Đường cong đánh đổi độ chính xác và độ bao phủ. Các đường cong trong Hình 6b và 6c được có được bằng cách chọn các mức độ chính xác mong muốn P khác nhau và sau đó tính toán các giá trị độ chính xác/độ bao phủ trên Dtest đối với P. Các đường cong cho PyFiX-Opt cho thấy độ bao phủ tối đa có thể đạt được trên Dtest cho các mức độ chính xác P khác nhau sử dụng phản hồi được tạo ra của chúng tôi. Để có được những đường cong này cho PyFiXV và PyFiX-Rule, chúng tôi đã thực hiện hiệu chuẩn trực tiếp trên Dtest thay vì Dcal (tức là, thực hiện hiệu chuẩn lý tưởng cho cơ chế xác thực của chúng khi so sánh với đường cong của PyFiX-Opt). Những đường cong này làm nổi bật sự đánh đổi giữa độ chính xác và độ bao phủ được cung cấp bởi PyFiXV so với xác thực dựa trên quy tắc đơn giản và xác thực oracle.

Phân tích định tính. Chúng tôi đã cung cấp một số ví dụ minh họa để chứng minh kỹ thuật PyFiXV của chúng tôi. Hình 1, 2, và 7 cho thấy các ví dụ trong đó Giai đoạn-1 và Giai đoạn-2 của PyFiXV tạo ra phản hồi chất lượng tốt và Giai đoạn-3 chấp nhận thành công phản hồi. Hình 3 và 8 cho thấy các ví dụ trong đó Giai đoạn-1 và Giai đoạn-2 của PyFiXV tạo ra phản hồi chất lượng xấu và Giai đoạn-3 từ chối thành công phản hồi. Hình 7 làm nổi bật rằng PyFiXV có thể thực hiện sửa chữa không tầm thường trong chương trình có lỗi và giải thích chúng một cách chính xác theo cách dễ hiểu. Hình 3 cho thấy một ví dụ trong đó phản hồi tổng thể có chất lượng xấu và được từ chối thành công, mặc dù các phần của giải thích được tạo ra là đúng; điều này có thể hữu ích cho các gia sư trong phương pháp tiếp cận có con người trong vòng lặp.

5. THẢO LUẬN KẾT LUẬN

Chúng tôi đã nghiên cứu việc sử dụng LLM để tạo phản hồi cho việc sửa lỗi cú pháp lập trình. Đặc biệt, chúng tôi đã xem xét phản hồi dưới dạng chương trình đã được sửa cùng với giải thích bằng ngôn ngữ tự nhiên. Chúng tôi tập trung vào thách thức tạo phản hồi độ chính xác cao, điều này rất quan trọng trước khi triển khai công nghệ như vậy trong lớp học. Kỹ thuật được đề xuất của chúng tôi, PyFiXV, đảm bảo độ chính xác cao thông qua cơ chế xác thực thời gian chạy mới và cũng cung cấp núm độ chính xác cho các nhà giáo dục. Chúng tôi đã thực hiện đánh giá mở rộng để

7 Chúng tôi lưu ý rằng các chỉ số hiệu suất độ chính xác và độ bao phủ cho các kỹ thuật khác nhau được báo cáo cho quá trình đầu cuối được liên kết với mỗi kỹ thuật, chứ không chỉ cho cơ chế xác thực. Ngoài ra, ngay cả khi một kỹ thuật không sử dụng bất kỳ cơ chế xác thực nào, độ bao phủ có thể ít hơn 100.0 như đã thảo luận trong Chú thích 3.

8 Chúng tôi lưu ý rằng các chuyên gia được che giấu điều kiện (kỹ thuật) liên quan đến mỗi phiên bản phản hồi khi cung cấp xếp hạng. Hơn nữa, những phiên bản phản hồi được tạo ra này được cung cấp cho các chuyên gia theo thứ tự ngẫu nhiên qua các điều kiện thay vì nhóm chúng theo điều kiện.

--- TRANG 7 ---
cho thấy hiệu quả của PyFiXV trên hai bộ dữ liệu lập trình Python thực tế. Có một số hướng nghiên cứu thú vị cho công việc tương lai, bao gồm (a) cải thiện các thành phần của PyFiXV để có được sự đánh đổi độ chính xác/độ bao phủ tốt hơn, ví dụ, bằng cách điều chỉnh kỹ thuật của chúng tôi để sử dụng các LLM gần đây như ChatGPT [42] và GPT-4 [43] thay vì Codex; (b) mở rộng PyFiXV vượt ra ngoài lỗi cú pháp để cung cấp phản hồi cho các chương trình có lỗi ngữ nghĩa hoặc chương trình một phần; (c) kết hợp các tín hiệu bổ sung trong cơ chế xác thực của PyFiXV; (d) tiến hành các nghiên cứu thực tế trong lớp học.

6. LỜI CẢM ÒN

Được tài trợ/Đồng tài trợ bởi Liên minh Châu Âu (ERC, TOPS, 101039090). Tuy nhiên, quan điểm và ý kiến được bày tỏ chỉ thuộc về (các) tác giả và không nhất thiết phản ánh quan điểm của Liên minh Châu Âu hoặc Hội đồng Nghiên cứu Châu Âu. Liên minh Châu Âu và cơ quan cấp tài trợ đều không thể chịu trách nhiệm về chúng.

Tài Liệu Tham Khảo

[1] Mark Chen và cộng sự. Evaluating Large Language Models Trained on Code. CoRR, abs/2107.03374, 2021.

[2] Tom B. Brown và cộng sự. Language Models are Few-Shot Learners. Trong NeurIPS, 2020.

[3] James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, và James Prather. The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming. Trong ACE, 2022.

[4] Sami Sarsa, Paul Denny, Arto Hellas, và Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. Trong ICER, 2022.

[5] Stephen MacNeil, Andrew Tran, Arto Hellas, Joanne Kim, Sami Sarsa, Paul Denny, Seth Bernstein, và Juho Leinonen. Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book. Trong SIGCSE, 2023.

[6] Juho Leinonen, Arto Hellas, Sami Sarsa, Brent N. Reeves, Paul Denny, James Prather, và Brett A. Becker. Using Large Language Models to Enhance Programming Error Messages. Trong SIGCSE, 2023.

[7] James Prather, Raymond Pettit, Kayla Holcomb McMurry, Alani L. Peters, John Homer, Nevan Simone, và Maxine S. Cohen. On Novices' Interaction with Compiler Error Messages: A Human Factors Approach. Trong ICER, 2017.

[8] Brett A. Becker. An Effective Approach to Enhancing Compiler Error Messages. Trong SIGCSE, 2016.

[9] Tobias Kohn và Bill Z. Manaris. Tell Me What's Wrong: A Python IDE with Error Messages. Trong SIGCSE, 2020.

[10] Brett A. Becker. What Does Saying That 'Programming is Hard' Really Say, and About Whom? Communications of ACM, 64(8):27–29, 2021.

[11] Rishabh Singh, Sumit Gulwani, và Armando Solar-Lezama. Automated Feedback Generation for Introductory Programming Assignments. Trong PLDI, 2013.

[12] Samim Mirhosseini, Austin Z. Henley, và Chris Parnin. What is Your Biggest Pain Point? An Investigation of CS Instructor Obstacles, Workarounds, and Desires. Trong SIGCSE, 2023.

[13] Mikhail Mirzayanov. Codeforces. https://codeforces.com/.

[14] Sumit Gulwani, Ivan Radicek, và Florian Zuleger. Automated Clustering and Program Repair for Introductory Programming Assignments. Trong PLDI, 2018.

[15] Sahil Bhatia, Pushmeet Kohli, và Rishabh Singh. Neuro-Symbolic Program Corrector for Introductory Programming Assignments. Trong ICSE, 2018.

[16] Rahul Gupta, Aditya Kanade, và Shirish K. Shevade. Deep Reinforcement Learning for Syntactic Error Repair in Student Programs. Trong AAAI, 2019.

[17] Jialu Zhang, José Cambronero, Sumit Gulwani, Vu Le, Ruzica Piskac, Gustavo Soares, và Gust Verbruggen. Repairing Bugs in Python Assignments Using Large Language Models. CoRR, abs/2209.14876, 2022.

[18] Harshit Joshi, José Pablo Cambronero Sánchez, Sumit Gulwani, Vu Le, Ivan Radicek, và Gust Verbruggen. Repair is Nearly Generation: Multilingual Program Repair with LLMs. Trong AAAI, 2023.

[19] Björn Hartmann, Daniel MacDougall, Joel Brandt, và Scott R. Klemmer. What Would Other Programmers Do: Suggesting Solutions to Error Messages. Trong CHI, 2010.

[20] Andrew Head, Elena L. Glassman, Gustavo Soares, Ryo Suzuki, Lucas Figueredo, Loris D'Antoni, và Björn Hartmann. Writing Reusable Code Feedback at Scale with Mixed-Initiative Program Synthesis. Trong Learning @ Scale, 2017.

[21] Darren Key, Wen-Ding Li, và Kevin Ellis. I Speak, You Verify: Toward Trustworthy Neural Program Synthesis. CoRR, abs/2210.00848, 2022.

[22] Sergey Edunov, Myle Ott, Michael Auli, và David Grangier. Understanding Back-Translation at Scale. Trong EMNLP, 2018.

[23] Yewen Pu, Kevin Ellis, Marta Kryven, Josh Tenenbaum, và Armando Solar-Lezama. Program Synthesis with Pragmatic Communication. Trong NeurIPS, 2020.

[24] Hiroaki Funayama, Tasuku Sato, Yuichiroh Matsubayashi, Tomoya Mizumoto, Jun Suzuki, và Kentaro Inui. Balancing Cost and Quality: An Exploration of Human-in-the-Loop Frameworks for Automated Short Answer Scoring. Trong AIED, 2022.

[25] Rui Zhi, Samiha Marwan, Yihuan Dong, Nicholas Lytle, Thomas W. Price, và Tiffany Barnes. Toward Data-Driven Example Feedback for Novice Programming. Trong EDM, 2019.

[26] Ahana Ghosh, Sebastian Tschiatschek, Sam Devlin, và Adish Singla. Adaptive Scaffolding in Block-Based Programming via Synthesizing New Tasks as Pop Quizzes. Trong AIED, 2022.

[27] Anaïs Tack và Chris Piech. The AI Teacher Test: Measuring the Pedagogical Ability of Blender and GPT-3 in Educational Dialogues. Trong EDM, 2023.

[28] OpenAI. Codex-Edit. https://beta.openai.com/playground?mode=edit&model=code-davinci-edit-001.

[29] OpenAI. Codex-Complete. https://beta.openai.com/playground?mode=complete&model=code-davinci-002.

[30] Zhiyu Fan, Xiang Gao, Abhik Roychoudhury, và Shin Hwei Tan. Automated Repair of Programs from Large Language Models. Trong ICSE, 2022.

[31] Georg Brandl, Matthäus Chajdas, và Jean Abou-Samra. Pygments. https://pygments.org/.

[32] Rohan Bavishi, Harshit Joshi, José Cambronero, Anna Fariha, Sumit Gulwani, Vu Le, Ivan Radicek, và Ashish Tiwari. Neurosymbolic Repair for Low-Code Formula Languages. Proceedings ACM Programming Languages, 6(OOPSLA2), 2022.

[33] Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. BLEU: A Method for Automatic Evaluation of Machine Translation. Trong ACL, 2002.

[34] Tobias Kohn. The Error Behind The Message: Finding the Cause of Error Messages in Python. Trong SIGCSE, 2019.

[35] Ethan Caballero và Ilya Sutskever. Description2Code Dataset. https://github.com/ethancaballero/description2code, 2016.

[36] Yujia Li và cộng sự. Competition-Level Code Generation with AlphaCode. 2022.

[37] Matthijs J Warrens. Five Ways to Look at Cohen's Kappa. Journal of Psychology & Psychotherapy, 5(4):1, 2015.

[38] The Python Software Foundation. What's New In Python 3.10. https://docs.python.org/3/whatsnew/3.10.html.

[39] The Python Software Foundation. What's New In Python 3.11. https://docs.python.org/3/whatsnew/3.11.html.

[40] The Python Software Foundation. What's New In Python 3.12. https://docs.python.org/3.12/whatsnew/3.12.html.

[41] William G Cochran. The χ2 Test of Goodness of Fit. The Annals of Mathematical Statistics, 1952.

[42] OpenAI. ChatGPT. https://openai.com/blog/chatgpt, 2023.

[43] OpenAI. GPT-4 Technical Report. CoRR, abs/2303.08774, 2023.

--- TRANG 8 ---
3), do thông báo lỗi được cải thiện trong các phiên bản Python gần đây [38–40]. Kết quả cho PyFiXV P70 so sánh với kết quả cho PyFiX shot: Sel, PyFiX shot: Rand, PyFiX shot: None, và PyFi ||X shot: Sel cho thấy tính hữu ích của các thành phần khác nhau được sử dụng trong pipeline của PyFiXV. So sánh PyFiXV P70 với PyFiX-Rule P70 cho thấy xác thực của PyFiXV vượt trội đáng kể so với xác thực của PyFiX-Rule.9 Cuối cùng, kết quả cho PyFiX-Opt PVP70 được có được bằng cách đặt mức độ chính xác mong muốn cho PyFiX-Opt khớp với của PyFiXV P70 trên Dtest – các con số độ bao phủ (47.1 cho TigerJython và 75.0 cho Codeforces) cho thấy độ bao phủ tối đa có thể đạt được. Đáng chú ý, PyFiXV P70 đạt được độ bao phủ cạnh tranh 64.2 trên Codeforces.10

Đường cong đánh đổi độ chính xác và độ bao phủ. Các đường cong trong Hình 6b và 6c được có được bằng cách chọn các mức độ chính xác mong muốn P khác nhau và sau đó tính toán các giá trị độ chính xác/độ bao phủ trên Dtest đối với P. Các đường cong cho PyFiX-Opt cho thấy độ bao phủ tối đa có thể đạt được trên Dtest cho các mức độ chính xác P khác nhau sử dụng phản hồi được tạo ra của chúng tôi. Để có được những đường cong này cho PyFiXV và PyFiX-Rule, chúng tôi đã thực hiện hiệu chuẩn trực tiếp trên Dtest thay vì Dcal (tức là, thực hiện hiệu chuẩn lý tưởng cho cơ chế xác thực của chúng khi so sánh với đường cong của PyFiX-Opt). Những đường cong này làm nổi bật sự đánh đổi giữa độ chính xác và độ bao phủ được cung cấp bởi PyFiXV so với xác thực dựa trên quy tắc đơn giản và xác thực oracle.

Phân tích định tính. Chúng tôi đã cung cấp một số ví dụ minh họa để chứng minh kỹ thuật PyFiXV của chúng tôi. Hình 1, 2, và 7 cho thấy các ví dụ trong đó Giai đoạn-1 và Giai đoạn-2 của PyFiXV tạo ra phản hồi chất lượng tốt và Giai đoạn-3 chấp nhận thành công phản hồi. Hình 3 và 8 cho thấy các ví dụ trong đó Giai đoạn-1 và Giai đoạn-2 của PyFiXV tạo ra phản hồi chất lượng xấu và Giai đoạn-3 từ chối thành công phản hồi. Hình 7 làm nổi bật rằng PyFiXV có thể thực hiện sửa chữa không tầm thường trong chương trình có lỗi và giải thích chúng một cách chính xác theo cách dễ hiểu. Hình 3 cho thấy một ví dụ trong đó phản hồi tổng thể có chất lượng xấu và được từ chối thành công, mặc dù các phần của giải thích được tạo ra là đúng; điều này có thể hữu ích cho các gia sư trong phương pháp tiếp cận có con người trong vòng lặp.

5. THẢO LUẬN KẾT LUẬN

Chúng tôi đã nghiên cứu việc sử dụng LLM để tạo phản hồi cho việc sửa lỗi cú pháp lập trình. Đặc biệt, chúng tôi đã xem xét phản hồi dưới dạng chương trình đã được sửa cùng với giải thích bằng ngôn ngữ tự nhiên. Chúng tôi tập trung vào thách thức tạo phản hồi độ chính xác cao, điều này rất quan trọng trước khi triển khai công nghệ như vậy trong lớp học. Kỹ thuật được đề xuất của chúng tôi, PyFiXV, đảm bảo độ chính xác cao thông qua cơ chế xác thực thời gian chạy mới và cũng cung cấp núm độ chính xác cho các nhà giáo dục. Chúng tôi đã thực hiện đánh giá mở rộng để cho thấy hiệu quả của PyFiXV trên hai bộ dữ liệu lập trình Python thực tế. Có một số hướng nghiên cứu thú vị cho công việc tương lai, bao gồm (a) cải thiện các thành phần của PyFiXV để có được sự đánh đổi độ chính xác/độ bao phủ tốt hơn, ví dụ, bằng cách điều chỉnh kỹ thuật của chúng tôi để sử dụng các LLM gần đây như ChatGPT [42] và GPT-4 [43] thay vì Codex; (b) mở rộng PyFiXV vượt ra ngoài lỗi cú pháp để cung cấp phản hồi cho các chương trình có lỗi ngữ nghĩa hoặc chương trình một phần; (c) kết hợp các tín hiệu bổ sung trong cơ chế xác thực của PyFiXV; (d) tiến hành các nghiên cứu thực tế trong lớp học.

6. LỜI CẢM ƠN

Được tài trợ/Đồng tài trợ bởi Liên minh Châu Âu (ERC, TOPS, 101039090). Tuy nhiên, quan điểm và ý kiến được bày tỏ chỉ thuộc về (các) tác giả và không nhất thiết phản ánh quan điểm của Liên minh Châu Âu hoặc Hội đồng Nghiên cứu Châu Âu. Liên minh Châu Âu và cơ quan cấp tài trợ đều không thể chịu trách nhiệm về chúng.

Tài Liệu Tham Khảo

[1] Mark Chen và cộng sự. Evaluating Large Language Models Trained on Code. CoRR, abs/2107.03374, 2021.

[2] Tom B. Brown và cộng sự. Language Models are Few-Shot Learners. Trong NeurIPS, 2020.

[3] James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, và James Prather. The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming. Trong ACE, 2022.

[4] Sami Sarsa, Paul Denny, Arto Hellas, và Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. Trong ICER, 2022.

[5] Stephen MacNeil, Andrew Tran, Arto Hellas, Joanne Kim, Sami Sarsa, Paul Denny, Seth Bernstein, và Juho Leinonen. Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book. Trong SIGCSE, 2023.

[6] Juho Leinonen, Arto Hellas, Sami Sarsa, Brent N. Reeves, Paul Denny, James Prather, và Brett A. Becker. Using Large Language Models to Enhance Programming Error Messages. Trong SIGCSE, 2023.

[7] James Prather, Raymond Pettit, Kayla Holcomb McMurry, Alani L. Peters, John Homer, Nevan Simone, và Maxine S. Cohen. On Novices' Interaction with Compiler Error Messages: A Human Factors Approach. Trong ICER, 2017.

[8] Brett A. Becker. An Effective Approach to Enhancing Compiler Error Messages. Trong SIGCSE, 2016.

[9] Tobias Kohn và Bill Z. Manaris. Tell Me What's Wrong: A Python IDE with Error Messages. Trong SIGCSE, 2020.

[10] Brett A. Becker. What Does Saying That 'Programming is Hard' Really Say, and About Whom? Communications of ACM, 64(8):27–29, 2021.

[11] Rishabh Singh, Sumit Gulwani, và Armando Solar-Lezama. Automated Feedback Generation for Introductory Programming Assignments. Trong PLDI, 2013.

[12] Samim Mirhosseini, Austin Z. Henley, và Chris Parnin. What is Your Biggest Pain Point? An Investigation of CS Instructor Obstacles, Workarounds, and Desires. Trong SIGCSE, 2023.

[13] Mikhail Mirzayanov. Codeforces. https://codeforces.com/.

[14] Sumit Gulwani, Ivan Radicek, và Florian Zuleger. Automated Clustering and Program Repair for Introductory Programming Assignments. Trong PLDI, 2018.

[15] Sahil Bhatia, Pushmeet Kohli, và Rishabh Singh. Neuro-Symbolic Program Corrector for Introductory Programming Assignments. Trong ICSE, 2018.

[16] Rahul Gupta, Aditya Kanade, và Shirish K. Shevade. Deep Reinforcement Learning for Syntactic Error Repair in Student Programs. Trong AAAI, 2019.

[17] Jialu Zhang, José Cambronero, Sumit Gulwani, Vu Le, Ruzica Piskac, Gustavo Soares, và Gust Verbruggen. Repairing Bugs in Python Assignments Using Large Language Models. CoRR, abs/2209.14876, 2022.

[18] Harshit Joshi, José Pablo Cambronero Sánchez, Sumit Gulwani, Vu Le, Ivan Radicek, và Gust Verbruggen. Repair is Nearly Generation: Multilingual Program Repair with LLMs. Trong AAAI, 2023.

[19] Björn Hartmann, Daniel MacDougall, Joel Brandt, và Scott R. Klemmer. What Would Other Programmers Do: Suggesting Solutions to Error Messages. Trong CHI, 2010.

[20] Andrew Head, Elena L. Glassman, Gustavo Soares, Ryo Suzuki, Lucas Figueredo, Loris D'Antoni, và Björn Hartmann. Writing Reusable Code Feedback at Scale with Mixed-Initiative Program Synthesis. Trong Learning @ Scale, 2017.

[21] Darren Key, Wen-Ding Li, và Kevin Ellis. I Speak, You Verify: Toward Trustworthy Neural Program Synthesis. CoRR, abs/2210.00848, 2022.

[22] Sergey Edunov, Myle Ott, Michael Auli, và David Grangier. Understanding Back-Translation at Scale. Trong EMNLP, 2018.

[23] Yewen Pu, Kevin Ellis, Marta Kryven, Josh Tenenbaum, và Armando Solar-Lezama. Program Synthesis with Pragmatic Communication. Trong NeurIPS, 2020.

[24] Hiroaki Funayama, Tasuku Sato, Yuichiroh Matsubayashi, Tomoya Mizumoto, Jun Suzuki, và Kentaro Inui. Balancing Cost and Quality: An Exploration of Human-in-the-Loop Frameworks for Automated Short Answer Scoring. Trong AIED, 2022.

[25] Rui Zhi, Samiha Marwan, Yihuan Dong, Nicholas Lytle, Thomas W. Price, và Tiffany Barnes. Toward Data-Driven Example Feedback for Novice Programming. Trong EDM, 2019.

[26] Ahana Ghosh, Sebastian Tschiatschek, Sam Devlin, và Adish Singla. Adaptive Scaffolding in Block-Based Programming via Synthesizing New Tasks as Pop Quizzes. Trong AIED, 2022.

[27] Anaïs Tack và Chris Piech. The AI Teacher Test: Measuring the Pedagogical Ability of Blender and GPT-3 in Educational Dialogues. Trong EDM, 2023.

[28] OpenAI. Codex-Edit. https://beta.openai.com/playground?mode=edit&model=code-davinci-edit-001.

[29] OpenAI. Codex-Complete. https://beta.openai.com/playground?mode=complete&model=code-davinci-002.

[30] Zhiyu Fan, Xiang Gao, Abhik Roychoudhury, và Shin Hwei Tan. Automated Repair of Programs from Large Language Models. Trong ICSE, 2022.

[31] Georg Brandl, Matthäus Chajdas, và Jean Abou-Samra. Pygments. https://pygments.org/.

[32] Rohan Bavishi, Harshit Joshi, José Cambronero, Anna Fariha, Sumit Gulwani, Vu Le, Ivan Radicek, và Ashish Tiwari. Neurosymbolic Repair for Low-Code Formula Languages. Proceedings ACM Programming Languages, 6(OOPSLA2), 2022.

[33] Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. BLEU: A Method for Automatic Evaluation of Machine Translation. Trong ACL, 2002.

[34] Tobias Kohn. The Error Behind The Message: Finding the Cause of Error Messages in Python. Trong SIGCSE, 2019.

[35] Ethan Caballero và Ilya Sutskever. Description2Code Dataset. https://github.com/ethancaballero/description2code, 2016.

[36] Yujia Li và cộng sự. Competition-Level Code Generation with AlphaCode. 2022.

[37] Matthijs J Warrens. Five Ways to Look at Cohen's Kappa. Journal of Psychology & Psychotherapy, 5(4):1, 2015.

[38] The Python Software Foundation. What's New In Python 3.10. https://docs.python.org/3/whatsnew/3.10.html.

[39] The Python Software Foundation. What's New In Python 3.11. https://docs.python.org/3/whatsnew/3.11.html.

[40] The Python Software Foundation. What's New In Python 3.12. https://docs.python.org/3.12/whatsnew/3.12.html.

[41] William G Cochran. The χ2 Test of Goodness of Fit. The Annals of Mathematical Statistics, 1952.

[42] OpenAI. ChatGPT. https://openai.com/blog/chatgpt, 2023.

[43] OpenAI. GPT-4 Technical Report. CoRR, abs/2303.08774, 2023.

# Đánh giá và Giải thích các Mô hình Ngôn ngữ Lớn cho Mã nguồn bằng cách sử dụng Cấu trúc Cú pháp

# 2308.03873.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2308.03873.pdf
# Kích thước tệp: 4327458 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Đánh giá và Giải thích các Mô hình Ngôn ngữ Lớn
cho Mã nguồn bằng cách sử dụng Cấu trúc Cú pháp
1stDavid N. Palacio
Khoa Khoa học Máy tính
William & Mary
Williamsburg, V A
danaderpalacio@wm.edu2ndAlejandro Velasco
Khoa Khoa học Máy tính
William & Mary
Williamsburg, V A
svelascodimate@wm.edu3rdDaniel Rodriguez-Cardenas
Khoa Khoa học Máy tính
William & Mary
Williamsburg, V A
dhrodriguezcar@wm.edu
4thKevin Moran
Khoa Khoa học Máy tính
Đại học Central Florida
Orlando, FL
kpmoran@ucf.edu5thDenys Poshyvanyk
Khoa Khoa học Máy tính
William & Mary
Williamsburg, V A
dposhyvanyk@wm.edu

Tóm tắt —Các Mô hình Ngôn ngữ Lớn (LLM) cho mã nguồn là một
họ các mạng nơ-ron transformer có tham số cao được
tiền huấn luyện trên các tập dữ liệu khổng lồ của cả ngôn ngữ tự nhiên và ngôn ngữ
lập trình. Các mô hình này đang nhanh chóng được sử dụng trong
các công cụ phát triển AI thương mại, chẳng hạn như GitHub CoPi-
lot. Tuy nhiên, việc đo lường và giải thích hiệu quả của chúng trong
các tác vụ lập trình là một đề xuất đầy thách thức, xét đến
kích thước và độ phức tạp của chúng. Các phương pháp đánh giá và giải thích
LLM cho mã nguồn có mối liên hệ không thể tách rời với nhau. Nghĩa là, để
giải thích dự đoán của một mô hình, chúng phải được ánh xạ một cách đáng tin cậy
với các khái niệm chi tiết, dễ hiểu. Khi việc ánh xạ này
được thực hiện, các phương pháp mới cho đánh giá mô hình chi tiết là
có thể. Tuy nhiên, hầu hết các kỹ thuật giải thích và
benchmark đánh giá hiện tại tập trung vào tính mạnh mẽ của mô hình hoặc hiệu suất
tác vụ cá nhân, trái ngược với việc diễn giải dự đoán của mô hình.
Để đạt được mục tiêu này, bài báo này giới thiệu AST xplainer , một phương pháp giải
thích cụ thể cho LLM dành cho mã nguồn cho phép cả các phương pháp mới
cho đánh giá LLM và trực quan hóa dự đoán LLM
hỗ trợ người dùng cuối hiểu dự đoán của mô hình. Tại
cốt lõi, AST xplainer cung cấp một phương pháp tự động để căn chỉnh
dự đoán token với các nút AST, bằng cách trích xuất và tổng hợp
các logit mô hình được chuẩn hóa trong cấu trúc AST. Để chứng minh
lợi ích thực tế của AST xplainer , chúng tôi minh họa những hiểu biết
mà framework của chúng tôi có thể cung cấp bằng cách thực hiện đánh giá thực nghiệm
trên 12 LLM phổ biến cho mã nguồn sử dụng một tập dữ liệu được tuyển chọn
của các dự án GitHub phổ biến nhất. Ngoài ra, chúng tôi thực hiện
một nghiên cứu người dùng kiểm tra tính hữu ích của trực quan hóa
dự đoán mô hình dẫn xuất từ AST xplainer nhằm cho phép người dùng mô hình
giải thích dự đoán. Kết quả của các nghiên cứu này minh họa
tiềm năng của AST xplainer để cung cấp hiểu biết về hiệu quả LLM,
và hỗ trợ người dùng cuối hiểu dự đoán.
Thuật ngữ chỉ mục —khả năng giải thích, khả năng diễn giải, mô hình ngôn ngữ lớn,
dl4se

I. GIỚI THIỆU
Sự xuất hiện và phổ biến của các kho mã nguồn mở trực tuyến
và những tiến bộ nhanh chóng trong các mô hình ngôn ngữ lớn (LLM) dựa trên transformer đã phục vụ như một chất xúc tác
cho sự tiến bộ của các công cụ Kỹ thuật Phần mềm (SE) tự động
với hiệu quả tiến bộ nhanh chóng. LLM cho mã nguồn
đã chứng minh khả năng đáng kể trên một mảng đa dạng các tác vụ SE tạo sinh, bao gồm, nhưng không giới hạn
ở, hoàn thành mã nguồn [1], [2], sửa chữa chương trình [3], [4], và
tạo test case [5]. Hơn nữa, những tiến bộ này đang
nhanh chóng được đưa vào các công cụ phát triển thương mại như
GitHub CoPilot [6] và Ghostwriter của Replit [7].

Tuy nhiên, độ phức tạp và kích thước khổng lồ cho phép
hiệu quả thường đáng ngạc nhiên của LLM cho mã nguồn là một con dao hai lưỡi. Nghĩa là, trong khi những thuộc tính này cho phép LLM nắm bắt
các mẫu quan trọng trong mã nguồn cho phép chúng được áp dụng
cho một loạt các tác vụ lập trình, việc giải thích và
đánh giá hiệu quả khả năng của các mô hình này là một
đề xuất đầy thách thức — chúng hoạt động hiệu quả như "hộp đen" mà
rút ra dự đoán từ cơ chế mô hình nội bộ cực kỳ phức tạp. Nghiên cứu hiện tại trong cả việc thiết kế LLM cho mã nguồn
và trong việc áp dụng chúng cho các tác vụ lập trình thường sử dụng
các benchmark hiện có ( ví dụ, CodeSearchNet [8], hoặc Hu-
manEval [9]) và các metric đã được điều chỉnh từ lĩnh vực
xử lý ngôn ngữ tự nhiên (NLP) như độ chính xác, BLEU,
METEOR, và ROUGE, cũng như các metric gần đây hơn được
điều chỉnh thêm cho mã nguồn như CodeBLEU [10]. Tuy nhiên, công trình gần đây đã minh họa các hạn chế của các benchmark như
HumanEval [11], và đã có sự chỉ trích ngày càng tăng về các
metric tự động trong cộng đồng NLP [12]–[15]. Những thiếu sót này chủ yếu bắt nguồn từ thực tế là các benchmark
và metric như vậy thường được nhắm mục tiêu đánh giá tính đúng đắn chức năng hoặc
cú pháp của mã nguồn được tạo ra hoặc hiệu suất tác vụ,
nhưng không thể giải thích dự đoán hoặc khả năng của mô hình
theo cách có thể diễn giải được.

Các phương pháp đánh giá và giải thích LLM cho mã nguồn có
mối liên hệ không thể tách rời với nhau. Một đánh giá có thông tin
đòi hỏi một mức độ khả năng giải thích nào đó của dự đoán mô hình,
sao cho hành vi mô hình có thể được hiểu ở mức độ chi tiết. Tuy nhiên, thách thức cơ bản trong việc đạt được khả năng giải thích của LLM cho mã nguồn nằm ở việc thiết lập một
cơ chế ánh xạ đáng tin cậy có thể thu hẹp khoảng cách giữa dự đoán của một mô hình cho trước và các khái niệm ngôn ngữ lập trình (PL) có thể hiểu được bởi con người mà có thể hỗ trợ trong việc giải thích quyết định của mô hình. Do đó, việc thiết kế cả đánh giá hiệu quả và
kỹ thuật khả năng diễn giải cho LLM của mã nguồn đòi hỏi một
người trước tiên phải thiết lập ánh xạ khái niệm này.

Để vượt qua những thách thức trong việc giải thích và đánh giá
LLM cho mã nguồn, chúng tôi đề xuất một phương pháp mới để cho phép
ánh xạ khái niệm đáng tin cậy của dự đoán LLM với các khái niệm PL,
được gọi là AST xplainer , thu thập và tổng hợp
dự đoán token LLM thành một cấu trúc mà chúng tôi gọi là Abstract
Syntax Concepts ( AsC), bắt nguồn từ Abstract Syntax Trees
(AST). Bằng cách ánh xạ rõ ràng dự đoán mô hình với cấu trúc mã nguồn, AST xplainer cung cấp một phương pháp luận chi tiết
để kiểm tra cách các mô hình hoạt động so với các khái niệm ngôn ngữ lập trình, và có thể giúp người dùng cuối mô hình suy luận về
lý do tại sao một LLM có thể đã đưa ra một tập hợp dự đoán nhất định.
Việc ánh xạ dự đoán mô hình với AsC của AST xplainer cho phép
hai loại đánh giá mới cho LLM của mã nguồn, và một kỹ thuật khả năng diễn giải mới trực quan hóa AsC mô hình để hỗ trợ người dùng cuối ( tức là, các nhà phát triển sử dụng LLM để tự động hoàn thành mã nguồn) trong
việc hiểu dự đoán LLM. Hình 1 minh họa ba
thành phần chính này của AST xplainer .

Kỹ thuật đánh giá đầu tiên, được gọi là AsC -Eval có thể
ước tính hiệu suất cấu trúc của một phần tử cú pháp được dự đoán
để đo lường độ bất định của quá trình tạo mã nguồn downstream
(ví dụ, cho hoàn thành mã nguồn). Kỹ thuật đánh giá thứ hai được gọi là AsC -Causal , có khả năng
tạo ra giải thích nhân quả liên kết các giá trị hiệu suất cấu trúc này
với hiệu suất mô hình tiêu chuẩn (tức là,
Cross-Entropy Loss). Cuối cùng, AsC -Viz thực hiện một
kỹ thuật khả năng diễn giải thực tế bằng cách trực quan hóa độ bất định dự đoán mô hình LLM, được tổ chức thành cấu trúc AST, hỗ trợ người dùng cuối hiểu độ tin cậy của dự đoán mô hình trong
thực tế. Chúng tôi đánh giá AsC -Eval và AsC -Causal thông qua một
nghiên cứu thực nghiệm quy mô lớn, toàn diện đánh giá 12
LLM phổ biến trên một tập dữ liệu mới của ≈10 triệu token
độc quyền với dữ liệu huấn luyện của mô hình. Hơn nữa,
để đánh giá hiệu quả của AsC -Viz, chúng tôi tiến hành một nghiên cứu người dùng kiểm tra tính hữu ích của nhiều trực quan hóa trong việc hỗ trợ
các nhà phát triển hiểu và giải thích dự đoán mô hình.
Kết quả của nghiên cứu thực nghiệm của chúng tôi dẫn đến những hiểu biết mới
về hiệu suất của LLM cho mã nguồn, và nghiên cứu người dùng
minh họa tính hữu ích đầy hứa hẹn của AsC -Viz.

Những đóng góp của bài báo này như sau:
• Một metric đánh giá dựa trên Abstract Syntax Concepts
và Next-token Predictions (AsC -Eval ).
• Một phương pháp khả năng giải thích (AsC -Causal ) liên kết các
đánh giá tiêu chuẩn với Abstract Syntax Concepts của chúng tôi để
cung cấp hiểu biết về lý do tại sao cross-entropy loss đang bị
ảnh hưởng bởi các phần tử cấu trúc của dữ liệu mã nguồn.
• Một nghiên cứu người dùng cho thấy cách trực quan hóa AST (AsC -
Viz) giúp hiểu mã nguồn được tạo ra.
• Một benchmark để đánh giá Abstract Syntax Concepts trong
LLM, bao gồm một tập dữ liệu được tuyển chọn ( Galeras ) gồm 50K
mẫu python.
• Dữ liệu thực nghiệm, tập dữ liệu được tuyển chọn, mã nguồn, và
phân tích thống kê bổ sung được sử dụng trong nghiên cứu này được công bố trong một kho lưu trữ mã nguồn mở,
có sẵn tại https://github.com/WM-SEMERU/
CodeSyntaxConcept.

II. NỀN TẢNG & CÔNG TRÌNH LIÊN QUAN

AST xplainer là một phương pháp đánh giá và khả năng giải thích
để định lượng độ bất định dự đoán của LLM cho mã nguồn.
LLM là kết quả của việc mở rộng quy mô hàng tỷ tham số cho
các biểu diễn từ nhận biết ngữ cảnh từ các mô hình tiền huấn luyện
[16]. Phần này định nghĩa và hình thức hóa các yếu tố cơ bản
của phương pháp của chúng tôi. Chúng tôi cung cấp định nghĩa của LLM và cách
đánh giá chúng, định nghĩa của Abstract Syntax Trees (AST)
và cách chúng được sử dụng để thăm dò, và cuối cùng, các
phương pháp khả năng giải thích cho LLM.

A. Mô hình Ngôn ngữ Lớn cho Mã nguồn

Nghiên cứu của chúng tôi tập trung vào LLM vì hiệu suất xuất sắc của chúng
trên các tác vụ tạo sinh dựa trên mã nguồn. Trong khi các
biểu diễn khác tồn tại, chẳng hạn như các mô hình dựa trên đồ thị [17], [18],
chúng tôi tập trung thảo luận của mình vào các biểu diễn dựa trên chuỗi để
đơn giản. Mục tiêu của các mô hình dựa trên chuỗi là thống kê
học một biểu diễn của một artifact phần mềm ( ví dụ, đoạn mã,
comment, hoặc test case). Chúng tôi gọi dữ liệu dựa trên chuỗi cụ thể của SE là một corpus phần mềm S. Cho tính chất tuần tự
của S, chúng tôi có thể phân tách S thành độ chi tiết mong muốn của token,
từ, hoặc sub-word [19] bằng cách sử dụng một hàm biến đổi
Γ(S) = w1, ..., w I(tức là, tokenizer ). Hàm biến đổi này
là một phương pháp token hóa để chuyển đổi một corpus phần mềm
thành một chuỗi các đối tượng rời rạc wi cho 1⩽i⩽I.
Lưu ý rằng wi∈V, trong đó từ vựng V là một tập hợp hữu hạn.

Cho định nghĩa này, một mô hình ngôn ngữ thống kê là một
phân phối xác suất P trên một độ chi tiết cố định của các chuỗi
corpus phần mềm S. Chúng ta có thể phân tích phân phối kết hợp
trên chiều i− như: P(S) = P(w1, ..., w I) =QI
i=1P(wi|w<i). Do tính chất rời rạc của dữ liệu,
biểu thức P(wi|w<i) có thể được ước tính bằng một classifier.
Classifier, trong trường hợp cụ thể của chúng tôi, là một LLM [20]. Do đó,
thay vì sử dụng n-gram hoặc Markov Models để xấp xỉ
P(wi|w<i)[21], việc sử dụng một mô hình tiềm ẩn là thuận tiện
P(wi|w<i)≈P(wi|hi), trong đó hi được biết đến như một trạng thái ẩn
nhúng thông tin chuỗi từ các quan sát quá khứ
đến thời điểm i.

Tùy thuộc vào cách chuỗi được xử lý, trạng thái ẩn hi có thể được tính toán bằng cách sử dụng kiến trúc Encoder-Only ,
Encoder-Decoder , hoặc Decoder-Only theo
các lớp transformer [22]. Một hàm mục tiêu hai chiều phổ biến được sử dụng rộng rãi trong học biểu diễn là
mô hình hóa ngôn ngữ có mặt nạ [23]. Hàm này nhằm dự đoán
các mảnh văn bản bị che dựa trên ngữ cảnh xung quanh. Code-
BERT [24], CuBERT (345M) [25] CodeRoBERTa [26], và
GraphCodeBERT [27] là các ví dụ của mô hình Encoder-Only
cho mã nguồn. Trong các ngữ cảnh lập trình, những phương pháp này cung cấp
các biểu diễn hữu ích của chuỗi mã nguồn cho các tác vụ downstream
như phân loại mã nguồn, phát hiện bản sao và lỗi. CodeT5
[28] và PLBART [4] là các ví dụ của mô hình Encoder-Decoder. Những mô hình này mã hóa một chuỗi đầu vào và, sau đó,
chuỗi được mã hóa này được giải mã với một kiến trúc khác. Các mô hình Encoder-Decoder được huấn luyện với mục tiêu
tái tạo các chuỗi đầu vào bị che [29]. Ngoài ra, chúng
đã được sử dụng cho các tác vụ SE như tóm tắt mã nguồn,
và tạo mã nguồn sử dụng mặt nạ [28]. Cuối cùng, các mô hình Decoder-Only
dự đoán xác suất của một token cho trước một chuỗi đi trước. CodeGPT [30], CodeParrot [31], GPT-Neo [32],
GPT-J [33], Codex [34], GPT-NeoX [35], và các mô hình ngôn ngữ Transformer decoder-only từ trái sang phải của Google [22], [36]
là các ví dụ của mô hình Decoder-Only cho mã nguồn.

Mặc dù phương pháp đề xuất của chúng tôi AST xplainer được thiết kế
để tương thích với cả hai loại LLM, bài báo này tập trung vào các mô hình Decoder-Only do sự phổ biến của chúng
cho các tác vụ tạo sinh dựa trên mã nguồn [37]. Những mô hình này chia sẻ một
tính chất chung: khả năng kết nối thông tin được xử lý trước đó
với một tác vụ hiện tại, chẳng hạn như sử dụng một chuỗi ban đầu
của các token để dự đoán các token mã nguồn mới . Chuỗi tự động hoàn thành kết quả nên nhất quán với ngữ cảnh của chuỗi ban đầu. Tính chất này được biết đến như
khả năng mô hình hóa các phụ thuộc tầm xa [38].

Định nghĩa 1: Decoder-Only Transformers. Các mô hình Decoder-Only
cập nhật trạng thái ẩn hi=f(hi−1, w<i) sử dụng các
đầu vào quá khứ w<i và một trạng thái ẩn trước đó hi−1. Nói cách khác,
những mô hình này hoạt động theo cách feed-forward dự đoán
các giá trị tương lai từ các giá trị lịch sử trực tiếp. LLM được huấn luyện trên
mã nguồn có khả năng tạo ra token hoặc sub-word
cho trước một lịch sử. Do đó, các mô hình decoder-only được sử dụng như
các mô hình tạo sinh ˆwi∽P(wi|w<i) =σ(y)i=eywi
Σjeyj.

Trong xấp xỉ trước đó, token được dự đoán wi được
điều kiện bởi thông tin trước đó. Thuật ngữ yj đại diện cho
các log-probabilities không được chuẩn hóa cho mỗi token đầu ra j.
Chúng tôi đã trích xuất và chuẩn hóa những log-probabilities này từ
lớp cuối cùng của LLM để ước tính Next-token Predictions
(NtP) trong AST xplainer (xem Sec.III). Ước tính này dựa vào
hàm softmax. Softmax σi trả về một phân phối
trên các lớp đầu ra được dự đoán, trong trường hợp này, các lớp là mỗi
token trong từ vựng V được giới thiệu trước đó. Dự kiến rằng
các dự đoán chứa trong σi bị ảnh hưởng bởi các đầu vào trước đó
của chuỗi w<i.

B. Phương pháp Thăm dò AST

Thăm dó là một phân tích có giám sát để xác định loại
tham số nào ( ví dụ, đoạn mã nguồn đầu vào, quá trình token hóa,
số lớp ẩn, và kích thước mô hình) ảnh hưởng đến quá trình học
trong các mô hình machine learning [39]. Mục đích của thăm dò là đánh giá liệu các biểu diễn ẩn của các mô hình machine learning ( tức là, LLM) có mã hóa các tính chất ngôn ngữ cụ thể
như cấu trúc cú pháp của ngôn ngữ lập trình hay không.
Ví dụ, Lopez et al. [40] đã huấn luyện một classifier tuyến tính để
cho thấy rằng cấu trúc cú pháp mã nguồn được mã hóa trong các mô hình tiền huấn luyện
dưới dạng Abstract Syntax Trees (AST). Phương pháp của Lopez
et al. chứng minh rằng các lớp giữa của các mô hình tiền huấn luyện chứa thông tin AST [40].

Tuy nhiên, thay vì đề xuất một probe cú pháp khác, phương pháp của chúng tôi AST xplainer điều chỉnh thông tin AST để đánh giá và
giải thích LLM (xem Sec. III). AST được định nghĩa như một
biểu diễn chính thức của cấu trúc cú pháp được xây dựng dựa trên các yếu tố ngôn ngữ của PL. AST được hình thành theo các quy tắc sản xuất
được định nghĩa trong Context Free Grammar (CFG). Chính xác hơn, các quy tắc sản xuất là các hàm kết hợp
các nút terminal và non-terminal thành các câu lệnh. Các nút terminal là
các ký hiệu trong mã nguồn ( ví dụ, token trong vùng 3 của
Hình 5), trong khi các nút non-terminal đóng gói nhiều hơn một
nút terminal để định nghĩa cấu trúc của một câu lệnh ( ví dụ, các nút
chứa con trong vùng 2 của Hình 5).

Khi thiết kế phương pháp AST xplainer của chúng tôi (xem Sec.III),
chúng tôi đã tận dụng thông tin có ý nghĩa và có thể diễn giải được định nghĩa
trong Context-Free Grammars ( CFG ). CFG là một tập hợp các quy tắc
chứa thông tin cú pháp và cấu trúc của một ngôn ngữ
[41]. Cuối cùng CFG định nghĩa các hướng dẫn chỉ định cách
các token khác nhau ( tức là, Lexeme) được đặt lại với nhau để tạo thành các câu lệnh hợp lệ trong mọi ngôn ngữ lập trình.

Định nghĩa 2: Context Free Grammars. CFG G được
biểu diễn như G= (α, λ, ω, β ) trong đó α biểu thị tập hợp hữu hạn
của các ký hiệu non-terminal, λ tập hợp hữu hạn của các ký hiệu terminal, ω tập hợp hữu hạn của các quy tắc sản xuất và β ký hiệu bắt đầu.
Tập hợp các quy tắc sản xuất ω cho bất kỳ loại câu lệnh nào ( ví dụ,
điều kiện, gán, toán tử) được biểu diễn theo các ký hiệu
terminal và non-terminal.

C. Khả năng Giải thích cho Tạo Mã nguồn

LLM cho mã nguồn có thể được coi là một hộp đen vì
hành vi không chắc chắn của chúng khi dự đoán token. Để ước tính
độ bất định như vậy, chúng ta có thể sử dụng các phương pháp khả năng giải thích
trên LLM. Khả năng giải thích nhằm hiểu cách một mô hình
hoạt động và đưa ra quyết định bằng cách khám phá các lớp bên trong
hoặc thực hiện phân tích nhiễu loạn trên các đầu vào của mô hình [42], [43]. Ví dụ, Gholizadeh et al. [44] đề xuất
một kỹ thuật khả năng giải thích cục bộ, cụ thể là layer-wise relevant
propagation (LRP), tính toán tầm quan trọng của một
n-gram có thể diễn giải trong việc phân loại một chuỗi văn bản. LRP tính toán
một điểm số với tổng của các trọng số được kích hoạt trong quá trình lan truyền ngược để xác định các n-gram có ảnh hưởng nhất. Điểm số này được sử dụng để giải thích tầm quan trọng của một
n-gram cho trước cho một mô hình tiêu chuẩn ( tức là, SVM) và một mô hình neural( tức là,
CNN). Các tác giả đã chứng minh rằng LRP vượt trội hơn các
kỹ thuật khả năng giải thích chỉ dựa trên gradient và chỉ dựa trên hoán vị [44]. Điều quan trọng cần làm rõ là, trong nghiên cứu của chúng tôi,
khả năng giải thích và khả năng diễn giải được sử dụng thay thế cho nhau.

Trong bối cảnh các mô hình tiền huấn luyện cho mã nguồn, Liu et al.
đã thử nghiệm với các mô hình Encoder-Decoder cho code2code
và comment2code task ( ví dụ, T5, CodeText, và CodeTrans).
Nghiên cứu của họ nhằm giải thích tại sao các mô hình neural tạo ra
chuỗi mã nguồn một cách đáng tin cậy bằng cách xác định các token đóng góp
nhiều nhất cho dự đoán chuỗi [15]. Hơn nữa, Vasconcelos
et al. đề xuất một kỹ thuật làm nổi bật mã nguồn được tạo ra bằng cách sử dụng
một ngưỡng độ bất định. Phương pháp của họ chỉ ra các đoạn
của chuỗi nơi các nhà phát triển có thể can thiệp dựa trên
ngưỡng độ bất định [45]. Mặt khác, chúng ta có thể giải thích
các mô hình tiền huấn luyện cho mã nguồn bằng cách sử dụng thông tin cấu trúc. Ví dụ, Wan et al. đã tiến hành phân tích khả năng diễn giải
trên các mô hình Encoder-only ( ví dụ, CodeBert và GraphCodeBert)
tập trung vào ba khía cạnh: 1) cách các trọng số self-attention
căn chỉnh với cấu trúc cú pháp, 2) liệu cấu trúc cú pháp có
được mã hóa trong các lớp ẩn hay không, và 3) cách các mô hình tiền huấn luyện
tạo ra cấu trúc cú pháp [14].

Mặc dù nghiên cứu trước đó đã giới thiệu các kỹ thuật khả năng giải thích
để phân tích các mô hình tiền huấn luyện với thông tin cấu trúc,
những kỹ thuật đó đã được thử nghiệm và thiết kế cho các mô hình Encoder-Only kích thước khiêm tốn ( tức là, ít hơn 1B).
Ngược lại, nghiên cứu AST xplainer của chúng tôi đề xuất không chỉ một
kỹ thuật khả năng giải thích mà ngữ cảnh hóa các metric tiêu chuẩn
(tức là, cross-entropy loss) dựa trên suy luận nhân quả (xem Hình 4)
mà còn một metric đánh giá (AsC -Eval ) cho các
LLM Decoder-only dự đoán các nút terminal và non-terminal của AST.
Quan trọng hơn, chúng tôi giới thiệu và kiểm soát một tập hợp các
yếu tố gây nhiễu dựa trên các đặc tính mã nguồn ( ví dụ, AST-levels, AST-nodes,
và số lượng token) để ước tính đúng đắn mối quan hệ
giữa AsC -Eval và các metric tiêu chuẩn (xem Tab. II).

Kim et al. [13] giới thiệu một cấu trúc toán học chính thức
được biết đến như một hàm cho khả năng giải thích (φ). Chúng tôi sử dụng
định nghĩa này để mô tả chính thức những gì tạo nên một phương pháp có thể giải thích được trong SE. Hầu hết LLM cho mã nguồn hoạt động bằng cách dự đoán
token P(wi|di) mà không vốn dĩ khớp với các khái niệm cấp cao
mà con người có thể dễ dàng hiểu. Kim et al. khẳng định rằng
khó khăn như vậy có thể được biểu diễn toán học như đại diện cho
trạng thái của LLM như một không gian vector ( ⃗ m). Ngược lại, con người hoặc,
trong nghiên cứu của chúng tôi, các nhà phát triển hoạt động trong một không gian vector khác ⃗h,
tương ứng với một tập hợp khái niệm có thể diễn giải bởi con người (h) chưa biết. Do đó, thách thức chính của chúng tôi là ánh xạ ⃗ m→⃗h
thu hẹp khoảng cách này giữa các không gian vector khác biệt. Hiểu biết chính của AST xplainer là việc chính thức hóa một hàm khả năng giải thích φ cho LLM của mã nguồn.

Định nghĩa 3: Hàm Khả năng Diễn giải cho Next Token
Predictions. Xem xét φ:⃗ m→⃗h. Trong công thức này, ⃗ m
đại diện cho một xấp xỉ của không gian vector của mô hình như được đo lường thông qua hiệu suất dự đoán token ở các mức độ chi tiết khác nhau ( tức là, log-probabilities được chuẩn hóa). Xấp xỉ không gian vector này sau đó được ánh xạ với các khái niệm có thể hiểu được bởi con người ⃗h đại diện cho các khái niệm cú pháp ngôn ngữ lập trình ( tức là, các nút terminal và non-terminal).

III. THÀNH PHẦN AsC-Eval

Trong khi LLM đã chứng kiến những tiến bộ đáng kinh ngạc về
tạo mã nguồn và các tác vụ SE downstream khác [46], [47],
các nhà nghiên cứu vẫn không thể đánh giá những khía cạnh nào của
mã nguồn thực sự được học thống kê bởi các mô hình này. Trong phần này, chúng tôi đề xuất một metric mới, AsC -Eval , để thể hiện
hành vi thống kê của các phần tử cú pháp được tạo ra bởi
LLM. AsC -Eval được đề xuất của chúng tôi bao gồm các đơn vị cơ bản cho
khả năng giải thích (xem Hình 2) như Abstract Syntax Concepts ( AsC),
một hàm căn chỉnh δ liên kết token với AST, và một
hàm tổng hợp θ ước tính hiệu suất dự đoán
của các nút terminal và non-terminal. Chúng tôi đề xuất một
hàm khả năng giải thích φ dựa vào hàm căn chỉnh
δ và hàm tổng hợp θ để thực hiện ánh xạ
từ log-probabilites ( tức là, NtP ) đến các khái niệm có thể hiểu được bởi nhà phát triển ( tức là, AsC ).

A. Abstract Syntax Concepts (AsC)

AsC-Eval có thể được định nghĩa chính thức (xem Def. 3) như một
hàm khả năng giải thích φ của dự đoán token của LLM sử dụng
Context Free Grammars. Chúng tôi giới thiệu thuật ngữ Abstract
Syntax Concepts (AsC) để đại diện cho các ký hiệu terminal và non-terminal trong một Context Free Grammar (xem Def .2).
Cụ thể, để xấp xỉ không gian vector của LLM, trong ⃗ m, chúng tôi
trích xuất lớp cuối cùng để tính toán NtP, mà thực tế là một
thước đo hiệu suất tạo sinh. Sau đó trong ⃗h, chúng tôi ánh xạ
hiệu suất dự đoán của mô hình ở mức token ( NtP) với
AsC (mà chúng tôi định nghĩa một tập hợp các danh mục H), để làm cho
việc diễn giải những khía cạnh nào của LLM hiệu quả hoặc
sai sót trong dự đoán trở nên dễ dàng hơn.

Trong PL, các nút terminal và non-terminal giữ các
ý nghĩa ngữ nghĩa khác nhau. Ví dụ, các nút 'identifier' và
'string' tương ứng với một danh mục khái niệm Ngôn ngữ Tự nhiên chung. Do đó, chúng ta có thể nhóm các nút n thành các
danh mục có ý nghĩa ngữ nghĩa H. Hình 3 mô tả một số
danh mục được đề xuất của chúng tôi cho Python. Những danh mục này sẽ
cho phép AsC -Eval gán ý nghĩa ngữ nghĩa cho AsC được dự đoán.
AsC là các đơn vị toán học cơ bản để cho phép
đánh giá và khả năng giải thích của LLM. Hình 3 mô tả
một số khái niệm được sử dụng để đánh giá LLM với AsC -Eval .
Các khái niệm n∈N là các loại ký hiệu được định nghĩa bởi
CFG của tree-sitter [48]. Tóm lại, Mỗi token trong một chuỗi s
có thể được gán cho một danh mục h∈ H . Với các danh mục
H của chúng tôi, các nhà nghiên cứu và nhà phát triển có thể dễ dàng liên kết hiệu suất LLM với các thuộc tính mã nguồn cấu trúc cụ thể. Do đó,
AsC-Eval cho phép Next-token Predictions của LLM được
giải thích theo cách tập trung vào nhà phát triển.

Hình 2-A mô tả biểu diễn AST của một đoạn mã Python
của một triển khai ngây thơ của hàm countCharts . Hàm này
đếm và trả về số lần xuất hiện của một
ký tự cho trước cho một chuỗi đầu vào. Trong biểu diễn AST,
các nút lá tương ứng với các token terminal được sử dụng trong
đoạn mã, trong khi các nút trung gian tương ứng với non-
terminal. Phương pháp của chúng tôi dựa vào thư viện tree-sitter [48]
để xây dựng các biểu diễn AST của các đoạn mã. Khi
AST đã được phân tích, chúng ta có thể truy cập thông tin cho
tất cả các nút và lấy các thuộc tính hữu ích như loại,
con, và vị trí của chúng.

--- TRANG 5 ---
Hình 2: Các Thành phần AsC -Eval. Trái: Các nút được sử dụng như "khái niệm". Giữa: Mỗi token được căn chỉnh với các nút cuối của AST với một hàm offset. Phải: Xác suất nút được ước tính với một hàm tổng hợp.

B. Hàm căn chỉnh AST ( δ)

Hình 2-B minh họa quá trình căn chỉnh các nút terminal và non-terminal trong biểu diễn AST với các
token tương ứng của chúng. Trước quá trình căn chỉnh này, chúng tôi chia
đoạn mã countCharts s thành các token sử dụng tokenizer mô hình
Γ(s) = ( w1, ..., w i). Vì tokenizer có thể tạo ra một
chuỗi token trong đó mỗi token không nhất thiết
phải khớp với một nút terminal duy nhất, một nút đơn lẻ trong
AST có thể chứa nhiều hơn một token liên kết. Thực tế,
các nút trung gian được căn chỉnh với một chuỗi con của
đoạn mã gốc thay vì một token duy nhất. Chúng tôi định nghĩa cho mục đích này hàm căn chỉnh δ:N→s<=i trong đó s<=i
tương ứng với một chuỗi con của một đoạn mã và N là tập hợp
của các nút terminal và non-terminal. Chúng tôi tận dụng thuộc tính offset của mỗi nút AST để tiến hành quá trình này, nói cách khác, chúng tôi tìm kiếm tất cả các token trong s nằm trong
phạm vi offset của mỗi nút. Để minh họa cách hàm δ
hoạt động, hãy xem xét ví dụ trong Hình 2-B, trong cây con
nút terminal '(' được căn chỉnh với token ( trong khi
nút anh em 'identifier' được căn chỉnh với token str
ing. Nút cha 'parameters' sẽ do đó
được căn chỉnh với (str ing ,char acter ).

C. Hàm tổng hợp AST ( θ)

Chúng tôi thiết kế một hàm tổng hợp θ tính toán metric được đề xuất của chúng tôi AsC -Eval , đại diện cho mức độ tự tin
một nút terminal hoặc non-terminal n được dự đoán bởi một LLM.
Bằng cách liên kết những dự đoán nút này với một ký hiệu nút thực tế,
chúng ta có được hiểu biết về mức độ tốt của một mô hình được nghiên cứu đang
tạo ra mã nguồn . Những giá trị hiệu suất AsC -Eval này cũng có thể
khám phá các tương tác tầm xa cụ thể và ánh xạ chúng vào một
cấu trúc visual AST (xem Sec. V). AsC -Eval hoạt động ở hai
mức độ chi tiết tùy thuộc vào phạm vi của corpus được phân tích S. Chúng tôi gọi
độ chi tiết như vậy là tổng hợp cục bộ và toàn cục. Các tổng hợp cục bộ hoạt động cho một đoạn mã, trong khi các tổng hợp toàn cục hoạt động cho một corpus. Mặc dù tổng hợp cục bộ có thể cung cấp một giá trị AsC -Eval cho một đoạn mã duy nhất,
tổng hợp này cho phép tính toán trung bình của các giá trị tổng hợp
ở độ chi tiết đoạn mã.

Hình 2-C cho thấy hàm tổng hợp được sử dụng để tính toán
xác suất dự đoán cho mỗi nút. Khi các token được
căn chỉnh với các nút tương ứng của chúng sử dụng δ, chúng tôi duyệt
toàn bộ AST và tổng hợp các xác suất NtP của các
token liên kết của chúng. Hàm tổng hợp θ có thể nhận
dạng của một trung bình thống kê, median hoặc giá trị max tùy thuộc
vào cấu hình người dùng. Trong nghiên cứu của chúng tôi, chúng tôi đặt tổng hợp
θ:N→median (δ(N)) cho một tập con của token s<=i.

Ví dụ, như minh họa trong Hình 2-C, nút cha
'parameters' có một giá trị trung bình liên kết là 0.23.
Giá trị trung bình nút cha này được tổng hợp với các giá trị terminal của nó: '(' với 0.07,'identifier' với 0.4,',' với
0.5,'identifier' với 0.1, và ')' với 0.1.

IV. THÀNH PHẦN AsC-Causal

Trong phần này, chúng tôi cho thấy cách thành phần AsC -Causal có thể được
sử dụng để giải thích và ngữ cảnh hóa các metric tiêu chuẩn khác như
cross-entropy loss. Để đạt được điều đó, chúng tôi đề xuất một kỹ thuật suy luận nhân quả để ước tính tác động của Abstract Syntax
Concepts ( AsC) dự đoán trên hiệu suất LLM tổng thể.

LLM dễ hiểu hơn khi chúng phản ánh kiến thức con người
[13]. Một cách để xác định liệu một LLM
cho mã nguồn có phản ánh kiến thức con người hay không là thử nghiệm để xem
nó có hoạt động tương tự như cách một nhà phát triển sẽ ước tính
dự đoán của một chuỗi hay không [49]. Ví dụ, xem xét
tình huống mà một nhà phát triển chèn một 'for statement'
trong một đoạn mã. Vốn dĩ, một nhà phát triển hợp lý hóa tinh thần
nhiều thứ như khái niệm của Iteration . Nếu một LLM
có thể đưa ra dự đoán tương tự, nó gợi ý cho chúng ta rằng
nó đã học thống kê một số hiểu biết về cấu trúc cú pháp
của một chu kỳ lập trình. Chúng ta có thể xem xét rằng hành vi thống kê này tác động đến cross-entropy loss. Tác động này cho thấy rằng Abstract Syntax Concepts ( AsC) đang ảnh hưởng đến
chất lượng của một LLM (xem Def. 4). Để ước tính ảnh hưởng như vậy, chúng tôi đề xuất một kỹ thuật suy luận nhân quả dựa trên
phân tích do-calculus [50]–[52]. Ví dụ, trong Eq. 1, chúng tôi
tính toán một hiệu ứng nhân quả (Eq. 1a) và tương quan (Eq. 1a) cho
khái niệm treatment 'for_statement' tác động đến cross-
entropy loss của một LLM cho trước.

p(Y|do(t=forState. )) =X
z∈codeFeat.p(Y|z, t)p(t) (1a)
p(Y|t=forState. ) =X
z∈codeFeat.p(Y|z, t)p(t|z)(1b)

Chúng ta có thể giải thích hiệu suất dự đoán của LLM sử dụng các giá trị AsC -Eval như các hiệu ứng treatment. Những hiệu ứng này được
tính toán từ một Structural Causal Model (SCM), đại diện cho các giả định của chúng tôi về quá trình nhân quả cơ bản. Trong nghiên cứu của chúng tôi, những giả định này có dạng của
hiệu suất của mỗi AsC (treatment T), đặc tính mã nguồn (con-
founder Z), và hiệu suất tiêu chuẩn LLM (kết quả
Y). Thông tin mối quan hệ hoặc hướng của các
biến nhân quả này được nêu rõ ràng trong SCM (xem Hình 4).
Mục tiêu của phân tích nhân quả là xác định Average
Treatment Effect (ATE) mà một treatment có trên kết quả
sau khi kiểm soát các biến gây nhiễu. Nói cách khác,
chúng ta muốn ước tính xác suất p(Y|do(T))(xem Eq. 1a)
để xác định các trường hợp tương quan giả mạo (tức là, liên kết không phải là nguyên nhân) [53]. Lưu ý rằng xác suất p(Y|do(T)) khác
với p(Y|T) trong Eq. 1b. Chúng tôi tuyên bố rằng xác suất
p(Y|T) đại diện cho tương quan giữa các biến Y và
T mà không kiểm soát bất kỳ hiệu ứng confounder nào trên treatment
hoặc kết quả. Trong nghiên cứu của chúng tôi, chúng tôi tính toán tương quan Pearson
ρ=p(Y|T). Ngược lại, hiệu ứng treatment p(Y|do(T)) được
ước tính với một hồi quy tuyến tính sau khi áp dụng tiêu chí back-
door để kiểm soát confounder [53].

Định nghĩa 4: Hiệu ứng Treatment Nhân quả AsC. Cho một
Structural Causal Model trong đó một tập hợp các biến PA biểu thị
các cha ( tức là, đặc tính mã nguồn) của T, hiệu ứng treatment của T
(tức là, AsC ) trên Y ( tức là, cross-entropy loss) được cho bởi

p(Y=y|do(T=t)) = (2a)
Σzp(Y=y|T=t, PA =z)p(PA=z) = (2b)
Σzp(T=t, Y=y, PA =z)/p(T=t|PA=z) (2c)

Dựa trên định nghĩa suy luận nhân quả của Pearl et al. [50],
chúng tôi đề xuất một hiệu ứng treatment cụ thể cho Abstract Syntax
Concept AsC của chúng tôi. Def. 2 mô tả sự cận biên hóa thống kê của
confounder. Nói đơn giản, Average Treatment Effect bao gồm tác động thuần túy của treatment trong kết quả mà không có
ảnh hưởng của các biến gây nhiễu. Những hiệu ứng này
đại diện cho độ dốc của mô hình tuyến tính thu được giữa
treatment và đầu ra sau khi kiểm soát nhiễu loạn. Trong
nghiên cứu của chúng tôi, chúng tôi đã kiểm soát cho các confounder như kích thước chuỗi,
số lượng nút ,số mức cây , và độ phức tạp cyclomatic .

V. THÀNH PHẦN AsC-Viz

Thành phần trực quan hóa AsC -Viz là một kỹ thuật khả năng giải thích đồ họa hiển thị các giá trị hiệu suất AsC -Eval của các nút terminal và non-terminal cho một
đánh giá cục bộ duy nhất. Chúng tôi tận dụng cấu trúc phân cấp
của PL để trực quan chứa các giá trị AsC -Eval thu được
trong AsC -Eval vào AST. Hình 5 minh họa cách chúng tôi chứa các giá trị AsC -Eval cho một tác vụ tạo mã nguồn
sử dụng mô hình gpt-3 [1.3B] được phân tích của chúng tôi. Vùng 1 cho thấy
một hộp với một prompt với một đoạn mã không hoàn chỉnh theo sau
bởi một hộp thứ hai với các token được tạo ra màu xanh. Sau đó, trong
vùng 2, đoạn mã tự động hoàn thành kết quả được xử lý
với AsC -Eval và được biểu diễn như một AST. Mỗi nút có
thông tin về hiệu suất AsC -Eval sau khi áp dụng
tổng hợp cục bộ θ. Các nút được mã hóa màu. Các giá trị tổng hợp cao nhất ( tức là, dự đoán tốt nhất) được hiển thị màu
xanh. Ngược lại, các nút có giá trị nhỏ nhất
(tức là, dự đoán tệ nhất) được hiển thị màu đỏ. Các nút,

--- TRANG 7 ---
trong vùng 2, đóng gói các token mã nguồn được tạo ra bởi
LLM như được trình bày trong vùng 3. Chúng tôi gọi các token được tổ chức tuyến tính là biểu diễn chuỗi .

VI. THIẾT KẾ THỰC NGHIỆM

Để minh họa những hiểu biết mà AST xplainer có thể
cho phép, chúng tôi trình bày một đánh giá thực nghiệm trên 12 LLM, cho thấy cách LLM hoạt động cho mỗi Abstract Syntax Concept,
và một nghiên cứu người dùng, đánh giá khả năng sử dụng của phương pháp của chúng tôi.
Phần này chi tiết các bước phương pháp mà chúng tôi đã tuân theo để
cấu hình, đánh giá, và giải thích các LLM được chọn của chúng tôi.

RQ1 AsC-Eval :Ở mức độ nào các Mô hình Ngôn ngữ Lớn
cho mã nguồn dự đoán cấu trúc cú pháp?

RQ2 AsC-Causal :Làm thế nào Abstract Syntax Concepts tác động
đến hiệu suất dự đoán tiêu chuẩn của LLM?

RQ3 AsC-Viz:Phương pháp đánh giá AST của chúng tôi hữu ích như thế nào cho
các nhà phát triển trong một kịch bản thực tế?

A. Thiết lập Nghiên cứu

Thu thập Dữ liệu. Các LLM được chọn của chúng tôi được huấn luyện trên Big-
Query [54], BigPython [55], và the Pile [56]. Những tập dữ liệu này
bao gồm các kho lưu trữ và tệp từ GitHub được tạo ra trước năm 2021.
Tuy nhiên, để đánh giá đúng đắn AsC -Eval , chúng tôi phải
tránh ô nhiễm dữ liệu. Nghĩa là, chúng tôi cần tránh sử dụng
các mẫu trong đánh giá mà LLM đã được sử dụng
để huấn luyện. Vì lý do tương tự, chúng tôi không thể đánh giá phương pháp của mình sử dụng các tập dữ liệu mã nguồn phổ biến như CodesearchNet
[8] hoặc CodeXglue [57]. Để giải quyết vấn đề ô nhiễm dữ liệu này,
chúng tôi đã thu thập 50k đoạn mã Python duy nhất và tạo ra một
tập dữ liệu mã nguồn hoàn toàn mới, được gọi là Galeras . Galeras chỉ chứa các
commit gần đây được thực hiện từ ngày 1 tháng 1 năm 2022 đến ngày 1 tháng 1
năm 2023. Chúng tôi đã thu thập các kho lưu trữ Python từ Github có
hơn một trăm sao và trích xuất các đoạn mã từ các phương thức Python mới và được cập nhật. Chúng tôi đã làm sạch các
bản sao mẫu sử dụng lịch sử commit. Ngoài ra, Galeras
bao gồm thông tin về thông điệp commit, comment
trên phương thức, toàn bộ cấu trúc dữ liệu AST của phương thức,
số lượng nút, mức AST, lỗi AST, khoảng trắng, dòng
mã nguồn, độ phức tạp cyclomatic, và số lượng token.

Thu thập Mô hình. Chúng tôi đã đánh giá và giải thích tổng cộng
12 LLM Decoder-Only mở được lọc theo độ phổ biến. Mô hình lớn nhất của chúng tôi có 2.7B tham số. Bảng I cho thấy các LLM
được nhóm thành bốn danh mục khác nhau tương ứng với
chiến lược fine-tuning được sử dụng. Danh mục đầu tiên bao gồm
các mô hình dựa trên GPT-3 được huấn luyện chủ yếu trên ngôn ngữ tự nhiên ( tức là,
Pile [56]). Danh mục thứ hai bao gồm các mô hình được huấn luyện trên
ngôn ngữ tự nhiên nhưng được xây dựng dựa trên kiến trúc codegen [58].
Danh mục thứ ba bao gồm các mô hình được huấn luyện trên nhiều
ngôn ngữ lập trình sử dụng BigQuery [54] trên cả kiến trúc gpt-2
và codegen. Danh mục cuối cùng tương ứng với
cả các mô hình Multi-Language-Type được fine-tuned trên BigPython
[58], mà chúng tôi gọi là Mono-Language-Type , và các mô hình gpt-2
( tức là, codeparrot [31]).

Cấu hình Máy. Chúng tôi đã thực hiện các thử nghiệm sử dụng Ubuntu 20.04 với AMD EPYC 7532 32-Core CPU,
A100 NVIDA GPU với 40GB VRAM, và 1TB RAM. Cho quá trình suy luận mô hình, chúng tôi đã sử dụng HugginFace và Pytorch
[59], [60]. Tất cả các mô hình đều được tải vào GPU của máy để tăng tốc thời gian suy luận.

B. RQ1 Phương pháp Thực nghiệm AsC-Eval

Để trả lời RQ1, chúng tôi đã tạo ra các log-
probabilities được chuẩn hóa (xem Sec.II) hoặc Next Token Predictions ( NtP) cho
mỗi đoạn mã trong S=Galeras . Những log-probabilities này được
trích xuất tại thời điểm suy luận cho mỗi vị trí token cho 12
LLM. Các phân phối log-probabilities có kích thước vector của
|V| cho mỗi vị trí token trong s∈ S. Những phân phối này được
xử lý để có được log-probability thực sự khớp với
token mong đợi tại vị trí i. Do đó, mỗi vị trí token
có một giá trị dự đoán liên kết mà chúng tôi lưu để
tạo ra chuỗi NtP. Chuỗi Next-token Prediction như vậy là đầu vào cho hàm tổng hợp θ tạo ra các giá trị AsC -Eval tương ứng (xem Sec. III).

Ngoài ra, chúng tôi đã tính toán cross-entropy loss của mỗi
đoạn mã s trong tập dữ liệu của chúng tôi. Để có được giá trị AsC -Eval Global
trong Tab. I và Hình 6, chúng tôi đã tổng hợp các giá trị hiệu suất AsC -Eval ( tức là, tất cả AsC có sẵn) theo LLM. Các giá trị mỗi mô hình được bootstrap với median (kích thước 500 lần lấy mẫu)
để cho phép so sánh công bằng giữa các mô hình. Tương tự, để
có được AsC -Eval cho mỗi Abstract Syntax Concept Category
(ví dụ, Data Str, Decision, hoặc Scope), chúng tôi đã tổng hợp toàn cục
các giá trị hiệu suất của token dưới những danh mục này. Chúng tôi cũng
khám phá với các tổng hợp Type Model (xem Bảng. I).

C. RQ2 Phương pháp Thực nghiệm AsC-Causal

Để trả lời RQ2, chúng tôi tính toán cả các giá trị tương quan Pearson ρ
và hiệu ứng treatment nhân quả (xem Def .4) cho một tập con
của 14 khái niệm cú pháp (xem Hình 4). Cụ thể, chúng tôi đề xuất
các treatment ( T) Scope , Exceptions , Operator , Decision ,
Data Structures , Functional Programming , Natural Language ,
Iterative , Types , và Testing . Mỗi AsC được tương quan với
4 biến gây nhiễu ( tức là, Cyclo, AST Levels, #AST
Nodes, và Sequence Size) và cross-entropy loss của
gpt-3 [125M] và mono-lang [2B] . Chúng tôi quyết định khám phá
chỉ các LLM trường hợp cực đoan ( tức là, các mô hình tốt nhất và tệ nhất theo
hiệu suất AsC-Eval) vì chúng tôi phát hiện ra rằng các giá trị tương quan
rất tương tự giữa các LLM. Mặt khác, chúng tôi
ước tính xác suất của hiệu ứng treatment p(Y|do(T)
cho mỗi AsC và cross-entropy loss bằng cách kiểm soát 4
confounder được đề cập trước đó. Hàm xác suất này được
ước tính sử dụng công cụ doWhy [53]. Bảng II tóm tắt
các hiệu ứng treatment và tương quan giữa các giá trị AsC -Eval
được tổng hợp cục bộ (xem Sec. III) và cross-entropy
loss được nhóm theo danh mục khái niệm ( H).

D. RQ3 Phương pháp Nghiên cứu Người dùng Định tính

Để trả lời RQ3, chúng tôi đã thiết kế bốn khảo sát để hiểu nhận thức của các thực hành viên phần mềm về khả năng sử dụng của
AsC-Eval và AsC -Viz. Mục tiêu của chúng tôi là đánh giá hiệu quả
của các phương pháp AsC -Eval và AsC -Viz của chúng tôi để giải thích tại sao và
cách các token mã nguồn nhất định được dự đoán bởi LLM được huấn luyện
trên mã nguồn. Tận dụng các kỹ thuật khả năng diễn giải để giải thích

--- TRANG 8 ---
Hình 5: Đánh giá Cục bộ cho Hoàn thành Mã nguồn (AsC -Viz).

BẢNG I: Đặc tính của Mô hình Ngôn ngữ Lớn và hiệu suất AsC -Eval liên kết của chúng. Các giá trị AsC -Eval lỗi màu đỏ. Các giá trị AsC -Eval tự tin màu xanh. AsC -Eval toàn cục tốt nhất được gạch chân.

Mô hình Ngôn ngữ Lớn (LLM) Hiệu suất AsC-Eval (median bootstrap)
Loại Tên Kiến trúc Kích thước Toàn cục Data Str. Decision Except. F. Prog. Iter. NL Oper. Scope Testing Types
gpt-neo-125m [32] gpt-3 125M 0.48 0.50 0.52 0.43 0.49 0.74 0.32 0.48 0.51 0.59 0.33
gpt-neo-1.3B [32] gpt-3 1.3B 0.59 0.60 0.61 0.53 0.62 0.79 0.43 0.57 0.68 0.68 0.44Natural L.
gpt-3gpt-neo-2.7B [32] gpt-3 2.7B 0.62 0.62 0.63 0.56 0.66 0.81 0.46 0.60 0.74 0.70 0.47
codegen-350M-nl [61] codegen 350M 0.55 0.56 0.57 0.45 0.57 0.77 0.39 0.54 0.64 0.64 0.40 Natural L.
codegen codegen-2B-nl [61] codegen 2B 0.65 0.65 0.65 0.58 0.68 0.82 0.48 0.61 0.78 0.72 0.50
codeparrot-small-multi [31] gpt-2 110M 0.57 0.54 0.55 0.64 0.60 0.60 0.40 0.54 0.71 0.67 0.42
codegen-350M-multi [61] codegen-350M-nl 350M 0.68 0.63 0.72 0.75 0.70 0.69 0.51 0.62 0.83 0.73 0.51Multi-
Languagecodegen-2B-multi [61] codegen-2B-nl 2B 0.79 0.74 0.79 0.83 0.81 0.77 0.65 0.74 0.91 0.80 0.71
codeparrot-small [31] gpt-2 110M 0.61 0.58 0.58 0.68 0.66 0.63 0.46 0.57 0.73 0.69 0.47
codeparrot [31] gpt-2 1.5B 0.71 0.67 0.67 0.80 0.76 0.70 0.59 0.66 0.82 0.74 0.64
codegen-350M-mono [61] codegen-350M-multi 350M 0.73 0.68 0.76 0.78 0.76 0.73 0.57 0.68 0.86 0.77 0.58Mono-
Language
codegen-2B-mono [61] codegen-2B-multi 2B 0.84 0.79 0.84 0.90 0.85 0.81 0.73 0.82 0.94 0.85 0.83

quyết định của các mô hình như vậy có thể mang lại cho các thực hành viên phần mềm
hiểu biết về hành vi và chất lượng của các dự đoán.
Chúng tôi đã giới thiệu một tập hợp các mẫu mã nguồn với giải thích AsC -Viz tương ứng của chúng. Chúng tôi yêu cầu các người tham gia
đánh giá các giải thích cho bốn mẫu Python được phân phối
qua các treatment. Chúng tôi sử dụng thiết kế within-subjects hoặc thiết kế đo lường lặp lại, trong đó mỗi cá nhân nhận từng
treatment thực nghiệm liên tiếp. Bảng III chứa một
tóm tắt với mô tả của mỗi khảo sát. Mỗi khảo sát cá nhân
có hai phần. Phần đầu tiên của mỗi khảo sát
nhằm đánh giá năng lực của người tham gia sử dụng Python
và sự quen thuộc của họ với các mô hình ngôn ngữ cho các tác vụ tạo mã nguồn. Người tham gia cũng được hỏi về kiến thức của họ về
biểu diễn của thuật toán (AST) và các vấn đề chính
mà họ đã gặp phải khi sử dụng LLM cho tạo mã nguồn.

Trong phần thứ hai, chúng tôi cung cấp bốn prompt Python
với một phương thức không hoàn chỉnh cùng với dự đoán của các
dòng bị thiếu được đưa ra bởi một LLM. Vì mục tiêu của chúng tôi là đánh giá
khả năng sử dụng của AST xplainer thay vì nhận thức của
người tham gia về hiệu suất mô hình, chúng tôi bỏ qua chi tiết về mô hình được sử dụng cho dự đoán ( gpt-3 [1.3B] ).
Mỗi prompt được kèm theo một trực quan hóa ( tức là, AST-
partial, AST-complete, và sequence) cho thấy các giá trị AsC -Eval
và NtP cho các token được dự đoán. Sau đó chúng tôi yêu cầu
người tham gia đánh giá trực quan hóa và đánh giá tính hữu ích của nó.
Các trực quan hóa được tách thành các khảo sát khác nhau.

Hình 5 đặt ra một ví dụ về đánh giá cục bộ của một tác vụ hoàn thành mã nguồn
được trình bày cho người tham gia. Khảo sát yêu cầu đánh giá bốn mẫu khác nhau được xử lý với
AsC-Eval . Một số mẫu có lỗi cú pháp. Mỗi
khảo sát bao gồm một phương thức Python không hoàn chỉnh ( tức là, prompt)
và một phương thức hoàn chỉnh với phần được làm nổi bật của mã nguồn được tạo ra (vùng 1 trong Hình 5). Cho mỗi mẫu trong các
khảo sát, chúng tôi đã trình bày một trực quan hóa cụ thể. Ví dụ,
các khảo sát ( S2) và ( S3) chứa một biểu diễn dựa trên AST
tương tự như trong Hình 5. Trực quan hóa AST-complete
S3 cho thấy các nút terminal và non-terminal (vùng 2 trong
Hình 5). Tuy nhiên, trực quan hóa AST-partial ( S2) chỉ
cho thấy các nút non-terminal. Cuối cùng, một trực quan hóa dựa trên chuỗi của các logit được tạo ra cho mỗi token được trình bày
cho người tham gia trong khảo sát ( S1) (vùng 3 trong Hình 5).

--- TRANG 9 ---
VII. KẾT QUẢ & THẢO LUẬN

A. RQ1 Đánh giá Hiệu suất AsC Thực nghiệm

Trong RQ này, chúng tôi cung cấp một giá trị thực nghiệm (các cột median bootstrap trong Tab. I) của dự đoán Abstract Syntax
Concepts cho 12 LLM. Chúng tôi đặt ngưỡng 0.6 như một
tỷ lệ tin cậy dự đoán chấp nhận được cho metric AsC -
Eval của chúng tôi. Hình 3, ví dụ, cho thấy LLM tốt nhất và tệ nhất của chúng tôi, mono-lang [2B] và gpt-3 [125M] tương ứng, tại
mọi Abstract Syntax Concept được đề xuất. Chúng tôi quan sát rằng, nói chung, việc mở rộng quy mô các tham số của LLM đóng một vai trò cơ bản trong dự đoán AsC. Các hộp màu xanh lục gạch ngang cho thấy các
gia tăng hiệu suất AsC -Eval lớn nhất từ khái niệm tệ nhất đến
tốt nhất. Đặc biệt, Exceptions , Natural Language ,
Operators , Types , và Decisions thể hiện những bước nhảy lớn nhất trong
hiệu suất AsC -Eval cú pháp.

Đánh giá thực nghiệm của chúng tôi cho thấy rằng các danh mục AsC
đạt ngưỡng 0.6 cho 12 LLM là Scope với
hiệu suất AsC -Eval cao nhất 0.94 cho các mô hình Mono-
Language-Type, Iterations với 0.82 cho codegen-nl
[2B] , và Testing với 0.85 cho mono-lang [2B] (xem Bảng.I).
Ngược lại, chúng tôi đã tìm thấy một số danh mục khái niệm gặp khó khăn với
hiệu suất AsC-Eval. Chúng tôi gọi những danh mục này là
lỗi vì chúng dưới 0.5. Những danh mục đó chủ yếu là
danh mục Natural Language với median trung bình lớn nhất là
0.46 và Data Types với median trung bình lớn nhất là 0.47
cho NL GPT-3 .

0.2 0.4 0.6 0.8 1.0
Hiệu suất AsC Eval gpt-3 [125M]
gpt-3 [1.3B]
gpt-3 [2.7B]
codegen-nl [350M]
codegen-nl [2B]
multi-lang [110M]
multi-lang [350M]
multi-lang [2B]
mono-lang [110M]
mono-lang [1.5B]
mono-lang [350M]
mono-lang [2B]LLMs

Hình 6: Hiệu suất AsC -Eval được nhóm theo LLM cụ thể và
mật độ AsC-Eval theo Loại Mô hình.

Chúng tôi tin rằng các mô hình hoạt động kém với hiệu suất AsC -
Eval thấp vì các khái niệm danh mục như Natural
Language và Data Types đòi hỏi nhiều ngữ cảnh hơn để được dự đoán
chính xác. Ví dụ, khái niệm 'string' đòi hỏi
một cửa sổ ngữ cảnh lớn hơn trước khi được dự đoán đúng đắn.
Tương tự, danh mục Data Types dễ bị lỗi
vì chúng có thể xuất hiện thường xuyên hơn ở đầu
đoạn mã so với các danh mục khác. Ngoài ra, hãy nhớ rằng
Data Types là các khái niệm ít thường xuyên hơn do
kiểu động cho Python. Nói chung, không có kiến trúc nào được đánh giá
hoạt động tốt trong việc dự đoán Data Types chính xác ngoại trừ
mono-lang [2B] , được huấn luyện với một số lượng lớn
mẫu mã nguồn.

Bảng I mô tả rằng danh mục Iteration chủ yếu vượt qua
ngưỡng cho tất cả các mô hình của chúng tôi ngoại trừ codeparrot-small-multi
với median trung bình AsC -Eval là 0.6. Từ các mô hình nhỏ hơn của chúng tôi ( tức là, trong khoảng hàng triệu tham số), median trung bình thấp nhất thu được cho gpt-3 [125M] là 0.74, cũng
vượt qua ngưỡng. Hành vi xuất sắc này của các mô hình NL GPT-
3 có thể được giải thích là các từ dành riêng Python cho
lặp như for và while cũng xuất hiện trong ngôn ngữ tự nhiên
với ngữ nghĩa tương tự.

Hình 6 cho thấy rằng các mô hình được huấn luyện trên ngôn ngữ tự nhiên
có nhiều biến thiên median hơn các mô hình được fine-tuned trên
tập dữ liệu mã nguồn. Ví dụ, NL GPT-3 và NL Codegen báo cáo
các giá trị trong khoảng từ 0.2 đến 0.9. Ngược lại, các mô hình fine-tuned
với mã nguồn như Mono-Language-Type có biến thiên thấp hơn
so với các danh mục NL GPT-3 và NL Codegen. Ví dụ, mono-lang [2B] có median trung bình toàn cục AsC -
Eval là 0.84 và một khoảng biến thiên giữa 0.7 và 1.0,
vượt trội hơn ngưỡng 0.6. Hơn nữa, mono-lang [2B]
là mô hình tốt nhất của chúng tôi với AsC -Eval toàn cục trung bình là 0.84.
Một mặt, điều này gợi ý rằng các mô hình fine-tuned trên mã nguồn đang
dự đoán AsC với độ tin cậy cao hơn các mô hình chỉ ngôn ngữ tự nhiên. Mặt khác, mặc dù các mô hình Multi-Language-
Type thể hiện biến thiên cao (từ 0.5 đến 0.9), median trung bình AsC -Eval của chúng ( tức là, 0.68 cho multi-lang [110M] )
thậm chí còn tốt hơn các mô hình ngôn ngữ tự nhiên ( tức là, 0.48 với
biến thiên từ 0.2 đến 0.8 cho gpt-3 [125M] ).

RQ1 AsC-Eval: Dự đoán cấu trúc cú pháp phụ thuộc rất nhiều
vào kích thước tham số LLM và chiến lược fine-tuning.
Cụ thể hơn, mô hình lớn nhất được đánh giá của chúng tôi mono-lang
[2B] , được fine-tuned với các tập dữ liệu BigPython và BigQuery,
đạt được Hiệu suất AsC toàn cục cao nhất là 0.84 với biến thiên thấp nhất.

B. RQ2 Đánh giá Nhân quả Thực nghiệm

Trong câu hỏi nghiên cứu này, chúng tôi muốn chứng minh định lượng rằng cross-entropy loss của LLM có xu hướng bị tác động tiêu cực bởi các giá trị AsC -Eval ở độ chi tiết đoạn mã. Do đó,
chúng ta có thể giải thích ở độ chi tiết thấp hơn những phần nào của
mã nguồn LLM hoạt động kém (xem các hộp đỏ trong Tab. I). Chúng tôi
thể hiện bằng chứng thực nghiệm rằng tuyên bố trước đó đúng
cho cả giá trị tương quan ρ và hiệu ứng nhân quả p(y|do(t)). Ví dụ, Bảng II cho thấy rằng, nói chung, tất cả Abstract Syntax
Concept Categories ( tức là, Global Avg. AsC -Eval ) ảnh hưởng đến
cross-entropy loss cho mô hình tốt nhất ( tức là, mono-lang [2B] ) và tệ nhất của chúng tôi (tức là, gpt-3 [125M] ), với hiệu ứng treatment trung bình
là 1.78 và −1.60 tương ứng.

Phát hiện nổi bật nhất là danh mục Natural Language
có tác động lớn nhất đến cross-entropy loss. Ví dụ, khái niệm AsC 'identifier' có hiệu ứng nhân quả
là −1.78 cho gpt-3 [125M] và −2.89 cho mono-lang [2B] .
Ngược lại, các danh mục Functional Programming thể hiện
tác động thấp nhất đến cross-entropy loss với hiệu ứng nhân quả 'lambda' dương tinh tế là 0.2 cho gpt-3 [125M] . Hiệu ứng dương tinh tế này được mong đợi vì các LLM dựa trên NL chưa được
fine-tuned trên corpus mã nguồn với biểu thức 'lambda'. Ngoài ra, chúng tôi muốn làm nổi bật giá trị tương quan Pearson vừa phải giữa khái niệm 'if statement' và
độ phức tạp cyclomatic cho các mô hình tốt nhất và tệ nhất của chúng tôi với
cùng giá trị ρ= 0.58. Quan sát này phù hợp với
định nghĩa của metric độ phức tạp cyclomatic vì metric này
tính đến các luồng điều khiển được tạo ra bởi
cấu trúc điều kiện.

RQ2 AsC-Causal: Chúng ta có thể quan sát rằng cross-entropy loss
của LLM có xu hướng bị tác động tiêu cực bởi các giá trị AsC -Eval
ở độ chi tiết đoạn mã. Ví dụ, identifier ảnh hưởng đến
cả gpt-3 [2.7B] và mono-lang [2B] cross-entropy loss với
Average Treatment Effects là −1.78 và −2.89 tương ứng.

C. RQ3 Kết quả Nghiên cứu Người dùng về Trực quan hóa AsC

Trong RQ này, chúng tôi đánh giá AsC -Eval và AsC -Viz của chúng tôi trong
một kịch bản thực tế. Chúng tôi đã đánh giá mức độ hữu ích của trực quan hóa AST cho các thực hành viên sau khi thu thập tổng cộng 40
phản hồi (với độ tin cậy lấy mẫu 90% và biên
lỗi 15%). Mỗi người tham gia được phân công ngẫu nhiên và đồng đều
cho nhóm điều khiển hoặc một trong các nhóm khảo sát.
Nghiên cứu người dùng của chúng tôi (xem Tab. III) tiết lộ rằng trực quan hóa AST một phần ( tức là, AST chỉ với các nút non-terminal) được
ưa thích hơn biểu diễn AST hoàn chỉnh ( S3) và
trực quan hóa chuỗi ( S1). Hơn nữa, trực quan hóa AST một phần ( S2) được thấy là đặc biệt ít phức tạp hơn bởi
người tham gia với tỷ lệ 43% trong khảo sát so với
điều khiển C. Tuy nhiên, trực quan hóa AST hoàn chỉnh ( S3)
được nhận thức là phức tạp hơn bởi người tham gia với
tỷ lệ 67% so với điều khiển. Tuy nhiên, chúng tôi quan sát thấy rằng 43% người tham gia muốn sử dụng trực quan hóa tuần tự thay vì không có bất kỳ trợ giúp visual nào
(tức là, nhóm điều khiển C) và chỉ 29% người tham gia coi
trực quan hóa tuần tự dễ đọc và sử dụng. Đáng ngạc nhiên,
57% người tham gia thấy trực quan hóa chuỗi rất
hữu ích trong việc giải thích hành vi của mô hình. Sở thích này
có thể được giải thích bằng cách xem xét thực tế rằng chỉ
42% người tham gia có giáo dục chính thức về ML.

Trong tất cả các khảo sát, người tham gia đồng ý rằng việc trực quan hóa các
nút Error trong AsC -Viz với giá trị AsC -Eval tương ứng của chúng
rất hữu ích để hiểu các phụ thuộc tầm xa của
quá trình tạo sinh. Người tham gia làm nổi bật thực tế rằng
AsC-Viz hữu ích để giải thích tại sao LLM tạo ra một
dự đoán lỗi. Cụ thể hơn, người tham gia đề cập rằng mã màu cho các giá trị AsC -Eval giúp họ
phân biệt giữa các xác suất được dự đoán. Người tham gia
cũng chỉ ra rằng họ muốn các trực quan hóa bao gồm
thông tin về luồng làm việc của chương trình.

RQ3 Khả năng sử dụng của AsC-Eval: Chúng tôi thấy rằng trực quan hóa một phần
của AST là biểu diễn có thể đọc được nhất để
thể hiện các dự đoán được tổng hợp cục bộ với 57% đồng ý.
Mặc dù trực quan hóa AST một phần có ý kiến trái chiều về
tính hữu ích của nó với tỷ lệ đồng ý là 29%, trực quan hóa AST hoàn chỉnh có tỷ lệ đồng ý là 50%.

VIII. KẾT LUẬN & CÔNG VIỆC TƯƠNG LAI

Nghiên cứu của chúng tôi đề xuất một phương pháp Abstract Syntax Concept
để đánh giá và giải thích hiệu suất của Mô hình Ngôn ngữ Lớn cho mã nguồn. Chúng tôi đã tiến hành đánh giá thực nghiệm nghiêm ngặt
trên 12 LLM phổ biến sử dụng một tập dữ liệu được tuyển chọn
đã khám phá ra những chất lượng hiệu suất mới của LLM cho mã nguồn. Đánh giá thực nghiệm của chúng tôi tiết lộ rằng mono-language vượt trội hơn
multi-language LLM trong việc dự đoán tất cả các loại khái niệm cú pháp. Điều này gợi ý tầm quan trọng của các chiến lược fine-tuning
hơn kích thước mô hình. Ngoài ra, chúng tôi đã chứng minh rằng Abstract
Syntax Concepts ảnh hưởng đến cross-entropy loss của LLM
sau khi kiểm soát các confounder mã nguồn. Thực tế, ảnh hưởng này
tồn tại qua các mô hình ở các kích thước tham số khác nhau và
chiến lược fine-tuning. Ngoài ra, chúng tôi đã minh họa tính hữu ích của
các trực quan hóa được xây dựng dựa trên Abstract Syntax
Concepts đã định nghĩa của chúng tôi trong một nghiên cứu người dùng. Chúng tôi tin rằng những kết quả này minh họa
lời hứa của việc kết hợp các kỹ thuật khả năng giải thích và đánh giá
cho LLM của mã nguồn, và báo hiệu tiềm năng cho công việc tương lai
để tích hợp thêm các kỹ thuật khả năng giải thích vào các
benchmark LLM tương lai.

TÀI LIỆU THAM KHẢO
[1] V . Raychev, M. T. Vechev, và E. Yahav, "Code completion with
statistical language models," Proceedings of the 35th ACM SIGPLAN
Conference on Programming Language Design and Implementation ,
2014.
[2] M. Ciniselli, N. Cooper, L. Pascarella et al. , "An empirical study
on the usage of BERT models for code completion," CoRR , vol.
abs/2103.07115, 2021. [Online]. Available: https://arxiv.org/abs/2103.
07115
[3] Z. Chen, S. J. Kommrusch, M. Tufano et al. , "Sequencer: Sequence-
to-sequence learning for end-to-end program repair," IEEE Transactions
on Software Engineering , pp. 1–1, 2019.
[4] W. U. Ahmad, S. Chakraborty, B. Ray, và K.-W. Chang, "Unified
pre-training for program understanding and generation." [Online].
Available: http://arxiv.org/abs/2103.06333
[5] C. Watson, M. Tufano, K. Moran et al. , "On learning meaningful
assert statements for unit test cases," in Proceedings of the ACM/IEEE
42nd International Conference on Software Engineering , ser. ICSE '20.
New York, NY , USA: Association for Computing Machinery, 2020,
p. 1398–1409. [Online]. Available: https://doi.org/10.1145/3377811.
3380429
[6] GitHub, "Github copilot · your ai pair programmer." [Online]. Available:
https://copilot.github.com/
[7] Replit, "Replit Ghostwriter," https://replit.com/site/ghostwriter, May
2023.
[8] H. Husain, H.-H. Wu, T. Gazit et al. , "CodeSearchNet chal-
lenge: Evaluating the state of semantic code search," arXiv preprint
arXiv:1909.09436 , 2019.
[9] M. Chen, J. Tworek, H. Jun et al. , "Evaluating Large Language
Models Trained on Code," Jul. 2021, arXiv:2107.03374 [cs]. [Online].
Available: http://arxiv.org/abs/2107.03374
[10] S. Ren, D. Guo, S. Lu et al. , "CodeBLEU: a Method for Automatic
Evaluation of Code Synthesis," vol. 1949, no. Weaver 1955, 2020,
arXiv: 2009.10297. [Online]. Available: http://arxiv.org/abs/2009.10297
[11] J. Liu, C. S. Xia, Y . Wang, và L. Zhang, "Is your code generated by
chatgpt really correct? rigorous evaluation of large language models for
code generation," 2023.
[12] C. Molnar, Interpretable Machine Learning , 2019, https://christophm.
github.io/interpretable-ml-book/.
[13] B. Kim, M. Wattenberg, J. Gilmer et al. , "Interpretability beyond
feature attribution: Quantitative Testing with Concept Activation Vectors
(TCA V)," 35th International Conference on Machine Learning, ICML
2018 , vol. 6, pp. 4186–4195, 2018.

--- TRANG 11 ---
BẢNG II: AsC -Causal : Tương quan và Hiệu ứng Nhân quả.

Biến Độ phức tạp Cyclo Mức AST # Nút AST Kích thước Chuỗi Cross-Entropy Loss
LLMs gpt-125 mono-2B gpt-125 mono-2B gpt-125 mono-2B gpt-125 mono-2B gpt-125 mono-2B
Danh mục H AsC ρ=p(Y|T) ρ Hiệu ứng Nhân quả ρ Hiệu ứng Nhân quả
Global Avg. AsC-Eval 0.61 0.60 0.41 0.45 0.51 0.47 0.53 0.48 -0.38 -1.60 -0.38 -1.78
forstatement 0.32 0.32 0.30 0.30 0.18 0.19 0.23 0.19 -0.16 -0.10 -0.07 -0.01Iterativewhile statement 0.13 0.13 0.08 0.07 0.05 0.05 0.07 0.05 -0.05 -0.11 -0.03 -0.08
identifier 0.10 0.12 0.10 0.20 0.51 0.46 0.49 0.49 -0.56 -1.78 -0.80 -2.89 Natural
Language string 0.02 0.04 0.20 0.24 0.36 0.30 0.36 0.30 -0.31 -0.36 -0.43 -0.55
] 0.16 0.14 0.21 0.28 0.35 0.36 0.29 0.32 -0.16 -0.04 -0.22 -0.10 Scope
) 0.09 0.03 0.07 0.12 0.37 0.23 0.31 0.23 -0.37 -0.85 -0.54 -1.49
Decision ifstatement 0.58 0.58 0.29 0.28 0.20 0.21 0.27 0.23 -0.22 -0.21 -0.11 -0.11
comparison operator 0.34 0.38 0.18 0.20 0.30 0.30 0.30 0.32 -0.13 0.02 -0.11 0.00Operatorboolean operator 0.53 0.54 0.20 0.21 0.17 0.18 0.22 0.20 -0.10 0.01 -0.08 -0.09
forinclause 0.28 0.29 0.18 0.18 0.15 0.14 0.13 0.13 -0.03 0.09 -0.03 0.04
ifclause 0.20 0.22 0.10 0.10 0.06 0.06 0.07 0.06 -0.01 0.19 0.01 0.13Functional
Programminglambda -0.01 -0.01 0.12 0.12 0.18 0.18 0.16 0.16 -0.04 0.20 -0.05 0.06

BẢNG III: Kết quả nghiên cứu người dùng trực quan hóa

ID Nhóm Trực quan hóa Kết quả nghiên cứu người dùng trực quan hóa
C Điều khiểnPrompt
token được dự đoán.Đồng ý%
hữu ích%
có thể đọc được%
phức tạp
S1ChuỗiPrompt
token được dự đoán
NTP.Rất đồng ý 14 0 0
Đồng ý 43 29 43
Trung lập 29 29 29
Không đồng ý 14 43 29
S2AST
một phầnPrompt
token được dự đoán
AST một phần
NTP.Rất đồng ý 14 14 0
Đồng ý 29 43 14
Trung lập 29 29 43
Không đồng ý 29 14* 43
S3AST
hoàn chỉnhPrompt
token được dự đoán
AST hoàn chỉnh
NTP.Rất đồng ý 0 0 17
Đồng ý 50 17 50
Trung lập 33 33 17
Không đồng ý 17 50 17

* mô tả "Rất không đồng ý" duy nhất được báo cáo trong khảo sát

[14] Y . Wan, W. Zhao, H. Zhang et al. , "What Do They Capture?
– A Structural Analysis of Pre-Trained Language Models for
Source Code," Feb. 2022, arXiv:2202.06840 [cs]. [Online]. Available:
http://arxiv.org/abs/2202.06840
[15] Y . Liu, C. Tantithamthavorn, Y . Liu, và L. Li, "On the Reliability
and Explainability of Automated Code Generation Approaches," Feb.
2023, arXiv:2302.09587 [cs]. [Online]. Available: http://arxiv.org/abs/
2302.09587
[16] W. X. Zhao, K. Zhou, J. Li et al. , "A Survey of Large Language
Models," Apr. 2023, arXiv:2303.18223 [cs]. [Online]. Available:
http://arxiv.org/abs/2303.18223
[17] M. Allamanis, M. Brockschmidt, và M. Khademi, "Learning
to represent programs with graphs," in International Conference
on Learning Representations , 2018. [Online]. Available: https:
//openreview.net/forum?id=BJOFETxR-
[18] M. Allamanis, "The adverse effects of code duplication in machine
learning models of code," in Onward! OOPLSA 2019 , 2019, pp.
143–153. [Online]. Available: https://doi.org/10.1145/3359591.3359735
[19] R. M. Karampatsis và C. Sutton, "Maybe deep neural networks are the
best choice for modeling source code," arXiv , no. Lm, 2019.
[20] Y . Bengio, R. Ducharme, và P. Vincent, "A neural probabilistic
language model," Advances in Neural Information Processing Systems ,
vol. 3, pp. 1137–1155, 2003.
[21] R. M. Karampatsis, H. Babii, R. Robbes et al. , "Open-V ocabulary
Models for Source Code (Extended Abstract)," Proceedings - 2020
ACM/IEEE 42nd International Conference on Software Engineering:
Companion, ICSE-Companion 2020 , pp. 294–295, 2020.
[22] A. Vaswani, N. Shazeer, N. Parmar et al. , "Attention is all you need," in
Proceedings of the 31st International Conference on Neural Information
Processing Systems , ser. NeurIPs'17. Red Hook, NY , USA: Curran
Associates Inc., 2017, p. 6000–6010.

[23] J. Devlin, M.-W. Chang, K. Lee, và K. Toutanova, "BERT: Pre-
training of deep bidirectional transformers for language understanding."
[Online]. Available: http://arxiv.org/abs/1810.04805
[24] Z. Feng, D. Guo, D. Tang et al. , "CodeBERT: A pre-trained
model for programming and natural languages." [Online]. Available:
http://arxiv.org/abs/2002.08155
[25] A. Kanade, P. Maniatis, G. Balakrishnan, và K. Shi, "Learning and
evaluating contextual embedding of source code." [Online]. Available:
http://arxiv.org/abs/2001.00059
[26] Z. Lin, G. Li, J. Zhang et al. , "Xcode: Towards cross-language code
representation with large-scale pre-training," vol. 31, no. 3, pp. 1–44.
[Online]. Available: https://dl.acm.org/doi/10.1145/3506696
[27] D. Guo, S. Ren, S. Lu et al. , "GraphCodeBERT: Pre-training
code representations with data flow." [Online]. Available: http:
//arxiv.org/abs/2009.08366
[28] Y . Wang, W. Wang, S. Joty, và S. C. H. Hoi, "CodeT5: Identifier-aware
unified pre-trained encoder-decoder models for code understanding and
generation." [Online]. Available: http://arxiv.org/abs/2109.00859
[29] M. Lewis, Y . Liu, N. Goyal et al. , "BART: Denoising sequence-to-
sequence pre-training for natural language generation, translation, and
comprehension." [Online]. Available: http://arxiv.org/abs/1910.13461
[30] S. Lu, D. Guo, S. Ren et al. , "CodeXGLUE: A machine learning
benchmark dataset for code understanding and generation." [Online].
Available: http://arxiv.org/abs/2102.04664
[31] L. Gao, S. Biderman, S. Black et al. , "Codeparrot," 2021.
[Online]. Available: https://github.com/huggingface/blog/blob/main/
codeparrot.md
[32] S. Black, G. Leo, P. Wang et al. , "GPT-Neo: Large Scale
Autoregressive Language Modeling with Mesh-Tensorflow," Mar. 2021.
[Online]. Available: https://doi.org/10.5281/zenodo.5297715
[33] B. Wang và A. Komatsuzaki, "GPT-J-6B: A 6 Billion Param-
eter Autoregressive Language Model," https://github.com/kingoflolz/
mesh-transformer-jax, May 2021.
[34] W. Zaremba, G. Brockman, và OpenAI, "Openai codex," Aug 2021.
[Online]. Available: https://openai.com/blog/openai-codex/
[35] S. Black, S. Biderman, E. Hallahan et al. , "Gpt-neox-20b: An
open-source autoregressive language model," 2022. [Online]. Available:
https://arxiv.org/abs/2204.06745
[36] J. Austin, A. Odena, M. Nye et al. , "Program synthesis with large
language models," 2021.
[37] F. F. Xu, U. Alon, G. Neubig, và V . J. Hellendoorn, "A
Systematic Evaluation of Large Language Models of Code," May 2022,
arXiv:2202.13169 [cs]. [Online]. Available: http://arxiv.org/abs/2202.
13169
[38] A. Karpathy, J. Johnson, và F. Li, "Visualizing and understanding
recurrent networks," CoRR , vol. abs/1506.02078, 2015. [Online].
Available: http://arxiv.org/abs/1506.02078
[39] S. Troshin và N. Chirkova, "Probing Pretrained Models of
Source Code," Nov. 2022, arXiv:2202.08975 [cs]. [Online]. Available:
http://arxiv.org/abs/2202.08975
[40] J. A. H. L ´opez, M. Weyssow, J. S. Cuadrado, và H. Sahraoui, "AST-
Probe: Recovering abstract syntax trees from hidden representations
of pre-trained language models," Sep. 2022, arXiv:2206.11719 [cs].
[Online]. Available: http://arxiv.org/abs/2206.11719
[41] J. E. Hopcroft, R. Motwani, và J. D. Ullman, Introduction to Automata
Theory, Languages, and Computation (3rd Edition) . USA: Addison-
Wesley Longman Publishing Co., Inc., 2006.
[42] V . Belle và I. Papantonis, "Principles and Practice of Explainable
Machine Learning," 2020, arXiv: 2009.11698. [Online]. Available:
http://arxiv.org/abs/2009.11698
[43] C. Molnar, G. Casalicchio, và B. Bischl, "Interpretable Machine
Learning – A Brief History, State-of-the-Art and Challenges,"
no. 01, pp. 1–15, 2020, arXiv: 2010.09337. [Online]. Available:
http://arxiv.org/abs/2010.09337
[44] S. Gholizadeh và N. Zhou, "Model Explainability in Deep Learning
Based Natural Language Processing," Jun. 2021, arXiv:2106.07410
[cs]. [Online]. Available: http://arxiv.org/abs/2106.07410
[45] H. Vasconcelos, G. Bansal, A. Fourney et al. , "Generation Probabilities
Are Not Enough: Exploring the Effectiveness of Uncertainty Highlight-
ing in AI-Powered Code Completions," Feb. 2023, arXiv:2302.07248
[cs]. [Online]. Available: http://arxiv.org/abs/2302.07248
[46] M. Chen, J. Tworek, H. Jun et al. , "Evaluating Large Language Models
Trained on Code," 2021. [Online]. Available: http://arxiv.org/abs/2107.
03374
[47] C. Watson, N. Cooper, D. Nader-Palacio et al. , "A systematic
literature review on the use of deep learning in software engineering
research," CoRR , vol. abs/2009.06520, 2020. [Online]. Available:
https://arxiv.org/abs/2009.06520
[48] M. Brunsfeld, A. Hlynskyi, P. Thomson et al. , "tree-sitter/tree-sitter:
v0.20.8," Apr. 2023. [Online]. Available: https://doi.org/10.5281/zenodo.
7798573
[49] D. N. Palacio, N. Cooper, A. Rodriguez et al. , "Toward a theory of
causation for interpreting neural code models," 2023.
[50] J. Pearl, M. Glymour, và N. P.Jewell, Causal Inference in Statistics, A
Primer , 2016.
[51] J. Pearl, Causality: models, reasoning, and inference , 2009.
[52] J. Pearl và D. Mackenzie, The book of why: The New Science of Cause
and Effect , 2018.
[53] A. Sharma, V . Syrgkanis, C. Zhang, và E. Kıcıman, "DoWhy : Ad-
dressing Challenges in Expressing and Validating Causal Assumptions,"
2021.
[54] "Bigquery dataset." [Online]. Available: https://cloud.google.com/
bigquery
[55] Anonymous, "Interpretingcodegeneration," https://anonymous.4open.
science/r/InterpretingCodeGeneration-75E4/, 2022.
[56] L. Gao, S. Biderman, S. Black et al. , "The pile: An 800gb dataset of
diverse text for language modeling," 2020.
[57] S. Lu, D. Guo, S. Ren et al. , "Codexglue: A machine learning
benchmark dataset for code understanding and generation," CoRR , vol.
abs/2102.04664, 2021.
[58] E. Nijkamp, B. Pang, H. Hayashi et al. , "Codegen: An open large
language model for code with multi-turn program synthesis," 2023.
[59] T. Wolf, L. Debut, V . Sanh et al. , "Transformers: State-of-the-
art natural language processing," in Proceedings of the 2020
Conference on Empirical Methods in Natural Language Processing:
System Demonstrations . Online: Association for Computational
Linguistics, Oct. 2020, pp. 38–45. [Online]. Available: https:
//www.aclweb.org/anthology/2020.emnlp-demos.6
[60] A. Paszke, S. Gross, F. Massa et al. , "Pytorch: An imperative style,
high-performance deep learning library," in Advances in Neural
Information Processing Systems 32 , H. Wallach, H. Larochelle,
A. Beygelzimer et al. , Eds. Curran Associates, Inc., 2019,
pp. 8024–8035. [Online]. Available: http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.
pdf
[61] E. Nijkamp, B. Pang, H. Hayashi et al. , "A conversational paradigm for
program synthesis," arXiv preprint , 2022.
12

# T5APR: TĂNG CƯỜNG SỬA CHỮA CHƯƠNG TRÌNH TỰ ĐỘNG TRÊN NHIỀU NGÔN NGỮ THÔNG QUA ENSEMBLE CHECKPOINT

Reza Gharibi, Mohammad Hadi Sadreddini,
 Seyed Mostafa Fakhrahmad∗
Khoa Khoa học Máy tính và Kỹ thuật và CNTT
Trường Kỹ thuật Điện và Máy tính
Đại học Shiraz, Shiraz, Iran
gharibi@cse.shirazu.ac.ir, sadredin@shirazu.ac.ir, fakhrahmad@shirazu.ac.ir

TÓM TẮT
Sửa chữa chương trình tự động (APR) sử dụng các kỹ thuật học sâu đã trở thành một lĩnh vực nghiên cứu quan trọng trong những năm gần đây, nhằm tự động tạo ra các bản vá sửa lỗi có thể cải thiện độ tin cậy và khả năng bảo trì của phần mềm. Tuy nhiên, hầu hết các phương pháp hiện tại hoặc chỉ nhắm đến một ngôn ngữ duy nhất hoặc yêu cầu tài nguyên tính toán cao để huấn luyện các mô hình đa ngôn ngữ. Trong bài báo này, chúng tôi đề xuất T5APR, một phương pháp sửa chữa chương trình neural mới cung cấp giải pháp thống nhất cho việc sửa lỗi trên nhiều ngôn ngữ lập trình. T5APR tận dụng CodeT5, một mô hình transformer text-to-text được huấn luyện trước mạnh mẽ, và áp dụng chiến lược ensemble checkpoint để cải thiện việc đề xuất bản vá. Chúng tôi tiến hành đánh giá toàn diện trên sáu benchmark nổi tiếng với bốn ngôn ngữ lập trình (Java, Python, C, JavaScript), chứng minh tính cạnh tranh của T5APR so với các kỹ thuật hiện đại. T5APR sửa chính xác 1,985 lỗi, bao gồm 1,442 lỗi mà không có kỹ thuật nào được so sánh đã sửa được. Chúng tôi tiếp tục hỗ trợ hiệu quả của phương pháp bằng cách tiến hành các phân tích chi tiết, chẳng hạn như so sánh xếp hạng bản vá đúng giữa các kỹ thuật khác nhau. Các phát hiện của nghiên cứu này chứng minh tiềm năng của T5APR để sử dụng trong các ứng dụng thực tế và làm nổi bật tầm quan trọng của các phương pháp đa ngôn ngữ trong lĩnh vực APR.

Từ khóa Sửa chữa chương trình tự động · Sửa chữa chương trình neural · Học sâu · Transformer

1 Giới thiệu
Lỗi phần mềm là điều không thể tránh khỏi trong phát triển phần mềm và có thể dẫn đến vi phạm bảo mật, lỗi hệ thống và sự không hài lòng của người dùng, khiến việc phát hiện và sửa chúng một cách hiệu quả trở nên cực kỳ quan trọng. Tuy nhiên, việc debug thủ công tốn thời gian, đặc biệt khi xử lý các hệ thống phần mềm lớn và phức tạp. Nhu cầu ngày càng tăng về phần mềm chất lượng cao và đáng tin cậy, cùng với sự phức tạp ngày càng tăng của các hệ thống phần mềm, đã dẫn đến sự quan tâm gia tăng đối với sửa chữa chương trình tự động (APR). APR là một lĩnh vực nghiên cứu đang phát triển tự động sửa lỗi phần mềm để tăng cường độ tin cậy và khả năng bảo trì phần mềm. APR có thể tiết kiệm thời gian và công sức cho các nhà phát triển, cải thiện chất lượng và bảo trì phần mềm, và cho phép phát hành phần mềm nhanh hơn và thường xuyên hơn (Le Goues et al., 2019).

Những tiến bộ gần đây trong học máy đã cho thấy triển vọng trong việc cải thiện APR bằng cách áp dụng các kỹ thuật học sâu, chẳng hạn như các mô hình sequence-to-sequence, dịch máy neural (NMT), và graph-to-sequence, để tự động tạo ra các bản vá đúng cho mã nguồn có lỗi (Zhang et al., 2023; Zhong et al., 2022). Các kỹ thuật này có thể học các mẫu từ các kho mã lớn và tạo ra các bản vá sửa lỗi với hiệu suất hiện đại. Các công cụ APR sử dụng những kỹ thuật này được gọi là các công cụ sửa chữa chương trình neural. Sửa chữa chương trình neural chủ yếu được triển khai với học có giám sát trên các commit sửa lỗi trong quá khứ để tạo ra các bản vá dưới dạng chuỗi token hoặc chỉnh sửa, với mã có lỗi và ngữ cảnh của nó (Chakraborty et al., 2022; Chen et al., 2019; Ding et al., 2020; Jiang et al., 2021; Li et al., 2020; Lutellier et al., 2020; Ye et al., 2022; Zhu et al., 2021).

Tuy nhiên, hầu hết các phương pháp APR hiện tại bị giới hạn bởi tính đặc thù ngôn ngữ và chi phí tính toán cao. Chúng hoặc đắt đỏ để huấn luyện cho nhiều ngôn ngữ lập trình (Lutellier et al., 2020) hoặc tập trung vào một lĩnh vực ngôn ngữ duy nhất. Mặc dù chúng có thể tổng quát hóa cho các ngôn ngữ khác, chúng hiếm khi được triển khai và đánh giá cho các ngôn ngữ khác. Điều này hạn chế khả năng áp dụng và mở rộng của chúng trên các ngôn ngữ và lĩnh vực mã khác nhau. Ví dụ, CoCoNuT (Lutellier et al., 2020) và CIRCLE (Yuan et al., 2022) là hai trong số ít phương pháp được đánh giá trên nhiều ngôn ngữ lập trình. Để đạt được sửa chữa đa ngôn ngữ, CoCoNuT huấn luyện các mô hình riêng biệt cho từng ngôn ngữ lập trình, điều này yêu cầu lượng tài nguyên lớn. CIRCLE sử dụng học liên tục trên một mô hình duy nhất nhưng vẫn cần các biện pháp để ngăn chặn việc quên thảm khốc của mô hình và cũng là chiến lược hậu xử lý re-repairing để cung cấp các bản vá cho các ngôn ngữ khác nhau.

Để giải quyết những hạn chế này, bài báo này đề xuất T5APR, một phương pháp sửa chữa neural đa ngôn ngữ mới tận dụng sức mạnh của các mô hình transformer sequence-to-sequence (Vaswani et al., 2017). T5APR dựa trên CodeT5 (Wang et al., 2021), một mô hình được huấn luyện trước cho việc tạo và hiểu mã. T5APR tinh chỉnh CodeT5 theo kiểu học đa nhiệm trên tập dữ liệu các đoạn mã có lỗi và đã được sửa và sử dụng ensemble checkpoint (Chen et al., 2017) từ các bước huấn luyện khác nhau để tạo ra các bản vá ứng viên. Như được hiển thị trong Hình 1, chúng tôi huấn luyện một mô hình thống nhất để sửa lỗi từ nhiều ngôn ngữ lập trình khác nhau và sử dụng mã điều khiển ngôn ngữ trong prompt đầu vào để phân biệt giữa các ngôn ngữ khác nhau. Phương pháp này cho phép chúng tôi đạt được việc huấn luyện hiệu quả và có thể mở rộng với mức tiêu thụ tài nguyên thấp. T5APR sau đó xếp hạng và xác nhận các bản vá ứng viên được tạo ra bằng cách sử dụng bộ test của dự án để chọn bản vá phù hợp nhất.

Chúng tôi đánh giá phương pháp của mình trên sáu benchmark bao gồm Defects4J (Just et al., 2014), Bears (Madeiral et al., 2019), QuixBugs (Lin et al., 2017), Codelfaws (Tan et al., 2017), ManyBugs (Le Goues et al., 2015), và BugAID (Hanam et al., 2016), và so sánh hiệu suất của nó với 11 phương pháp APR hiện có. Kết quả cho thấy T5APR có thể tạo ra các bản vá đúng cho nhiều loại lỗi khác nhau trong các ngôn ngữ khác nhau và đạt được hiệu suất hiện đại về cả hiệu quả sửa chữa (tức là sửa chữa đúng) và hiệu suất (tức là xếp hạng sửa chữa). Trên tất cả các benchmark và từ 5,257 lỗi, T5APR sửa được 1,985 trong số đó, có nghĩa là bản vá khả thi đầu tiên mà nó tạo ra có ngữ nghĩa tương đương với bản vá của nhà phát triển.

Các đóng góp chính của bài báo này như sau:
• Chúng tôi giới thiệu T5APR, một phương pháp sửa chữa neural đa ngôn ngữ mới cung cấp giải pháp cho việc sửa lỗi trên nhiều ngôn ngữ lập trình khác nhau (Phần 2).
• Chúng tôi giải quyết thách thức về hiệu quả tài nguyên trong huấn luyện mà không giới thiệu các mô hình bổ sung cho từng ngôn ngữ bằng cách mô hình hóa APR đa ngôn ngữ với học đa nhiệm (Phần 2.6).
• Chúng tôi đề xuất chiến lược ensemble checkpoint, tăng cường hiệu quả của các bản vá được tạo ra (Phần 2.7).
• Chúng tôi đánh giá T5APR trên sáu benchmark và so sánh hiệu suất của nó với 11 phương pháp APR hiện đại, đạt được hiệu suất cạnh tranh (Phần 3 và 4).
• Chúng tôi cung cấp triển khai mã nguồn mở của T5APR, và kết quả của chúng tôi được công khai để thúc đẩy nghiên cứu và ứng dụng thực tế thêm: https://github.com/h4iku/T5APR .

Chúng tôi thảo luận về các công trình liên quan trong Phần 5, và Phần 6 kết luận bài báo và đề xuất các hướng tương lai.

2 Phương pháp

2.1 Tổng quan
Hình 2 cho thấy tổng quan về cấu trúc của T5APR. T5APR tận dụng CodeT5 làm mô hình cơ sở và kết hợp đầu ra của nhiều checkpoint để đạt được hiệu suất cải thiện trong sửa chữa chương trình tự động (APR). T5APR bao gồm hai giai đoạn: huấn luyện và suy luận. Trong giai đoạn huấn luyện, mô hình CodeT5 được tinh chỉnh trên tập dữ liệu đa ngôn ngữ quy mô lớn của các đoạn mã có lỗi và đã được sửa. Trong giai đoạn suy luận, nhiều checkpoint được sử dụng để tạo ra các bản vá ứng viên cho mã có lỗi và ngữ cảnh của nó. Các checkpoint được chọn từ các bước khác nhau của quá trình tinh chỉnh. Cuối cùng, chúng tôi xếp hạng các bản vá ứng viên dựa trên sự kết hợp của thứ hạng của chúng trong mỗi checkpoint và điểm xác suất của chúng, và xác nhận chúng bằng cách sử dụng bộ test của dự án để chọn bản vá phù hợp nhất. Các công cụ APR thường trả về bản vá được xếp hạng cao nhất có thể biên dịch và vượt qua các test case, được gọi là bản vá khả thi đầu tiên. Các phần sau sẽ mô tả chi tiết quá trình này.

2.2 Trích xuất dữ liệu
Quá trình huấn luyện T5APR bao gồm việc trích xuất lượng lớn dữ liệu bao gồm các dòng có lỗi (nguồn), ngữ cảnh xung quanh chúng để tăng cường sự hiểu biết của mô hình về mã có lỗi, và các phiên bản đã được sửa tương ứng (đích). Dữ liệu huấn luyện được thu thập từ nhiều dự án mã nguồn mở trong các ngôn ngữ lập trình khác nhau, đảm bảo đại diện rộng rãi cho các tình huống mã thực tế.

Đối với ngữ cảnh có lỗi, chúng tôi áp dụng "ngữ cảnh có lỗi ngay lập tức", tham chiếu đến hàm hoặc phương thức chứa các dòng có lỗi. Mặc dù các lựa chọn ngữ cảnh khác, chẳng hạn như toàn bộ nội dung tệp hoặc ngữ cảnh thu được thông qua phân tích luồng dữ liệu hoặc cắt chương trình là có thể, ngữ cảnh có lỗi ngay lập tức thường ngắn và có thể dễ dàng thu được cho một mô hình đa ngôn ngữ. Ngữ cảnh càng lớn, càng có khả năng có các thành phần cần thiết để sửa lỗi (Yang et al., 2021), nhưng chúng ta phải đưa cho mô hình một chuỗi dài hơn, điều này làm tăng thời gian tính toán và tài nguyên. Do đó, chúng tôi nhằm tạo ra một môi trường huấn luyện cân bằng hiệu quả nắm bắt thông tin thiết yếu cho APR mà không hy sinh tài nguyên tính toán. Tính độc lập ngữ cảnh của mô hình cho phép việc kết hợp các loại ngữ cảnh khác nhau trong tương lai để có thể cải thiện hiệu suất (Chen et al., 2019).

Trong các thí nghiệm của chúng tôi, chúng tôi huấn luyện mô hình T5APR trên tập dữ liệu được thu thập bởi CoCoNuT (Lutellier et al., 2020). Tập dữ liệu này tuân theo các tiêu chí tương tự được vẽ ở trên và bao gồm các bộ ba của các đoạn mã có lỗi, ngữ cảnh và đã được sửa được trích xuất từ lịch sử commit của các dự án mã nguồn mở khác nhau. Một hunk là một tập hợp các dòng mã thay đổi liên tiếp được trích xuất từ lịch sử commit. Ví dụ, trong Hình 3a, các dòng bắt đầu bằng (-) là các dòng có lỗi, các dòng bắt đầu bằng (+) là các dòng đã được sửa, và toàn bộ hàm flatten với các dòng có lỗi là ngữ cảnh. Điều tương tự áp dụng cho Hình 3b, ngoại trừ việc hunk đã được sửa có nhiều hơn một dòng ở đây.

CoCoNuT sử dụng heuristic dựa trên từ khóa để xác định các commit sửa lỗi từ thông điệp commit của chúng (Mockus và Votta, 2000). Họ đã kiểm tra thủ công các commit ngẫu nhiên và xác nhận hiệu quả của quá trình lọc này. Tuy nhiên, chúng tôi tiếp tục làm sạch dữ liệu trong quá trình tiền xử lý để đảm bảo các instance huấn luyện chất lượng cao.

2.3 Tiền xử lý
Phần này mô tả các bước được thực hiện để chuẩn bị dữ liệu huấn luyện đầu vào cho mô hình T5APR. Trước khi đưa dữ liệu vào mô hình, chúng tôi áp dụng một số bước tiền xử lý để tăng cường chất lượng dữ liệu và giảm yêu cầu tài nguyên tính toán (Raffel et al., 2020):

• Loại bỏ comment: Comments được loại bỏ khỏi cả nguồn và đích. Bước này đảm bảo mô hình chỉ tập trung vào các khía cạnh chức năng của mã.
• Loại bỏ trùng lặp: Chúng tôi loại bỏ trùng lặp dữ liệu huấn luyện trên nguồn, ngữ cảnh và đích dựa trên biểu diễn chuỗi của chúng, bỏ qua các ký tự khoảng trắng. Điều này loại bỏ các instance trùng lặp có cùng chức năng chỉ khác nhau về ký tự khoảng trắng, giảm đáng kể kích thước tập dữ liệu mà không làm tổn hại đến sự đa dạng của các đoạn mã.
• Loại bỏ nguồn và đích giống hệt: Các instance có nguồn và đích giống hệt nhau bị loại bỏ. Điều này cũng bao gồm các instance có cả nguồn và đích trống và các instance mà nguồn và đích của chúng chỉ khác nhau ở comments. Những instance như vậy không đại diện cho việc sửa lỗi thực tế, và chúng không cung cấp thông tin có ý nghĩa cho việc học.
• Lọc đích trống: Các instance có đích trống được loại bỏ khỏi dữ liệu huấn luyện. Mặc dù điều này có thể ảnh hưởng tiêu cực đến khả năng tạo ra các bản vá toán tử xóa của mô hình, chúng tôi chứng minh rằng mô hình vẫn có thể tạo ra các bản vá trống hiệu quả. Trong trường hợp mô hình không tạo ra bản vá trống, vì đó là một toán tử duy nhất, chúng tôi thêm thủ công một bản vá trống vào đầu danh sách bản vá.
• Lọc độ dài nguồn: Chúng tôi lọc các instance dựa trên độ dài sau tokenization của nguồn chúng (không bao gồm ngữ cảnh). Bước này đảm bảo rằng các đoạn mã tương thích với các ràng buộc độ dài đầu vào của mô hình và chỉ các bản vá hoàn chỉnh được sử dụng.

2.4 Biểu diễn mã và tokenization
Chúng tôi biểu diễn các dòng có lỗi và ngữ cảnh liên quan của chúng trong một định dạng thống nhất sử dụng token phân cách đặc biệt (:) cho quá trình tokenization:

input = prefix buggy_lines : context

trong đó prefix là mã điều khiển đặc thù ngôn ngữ phân biệt các ngôn ngữ lập trình khác nhau và được thêm vào đầu mỗi ví dụ, theo các công trình trước đây sử dụng các mô hình dựa trên T5 (Berabi et al., 2021; Raffel et al., 2020; Wang et al., 2021). Trong trường hợp lỗi nhiều dòng, chúng tôi nối các dòng bằng khoảng trắng và đặt chúng ngay sau nhau. Đầu vào này sau đó được tokenize và cắt bớt nếu cần thiết để đảm bảo kích thước của nó vẫn dưới giới hạn tối đa của mô hình. Chúng tôi chỉ sử dụng các instance mà độ dài prefix + buggy_lines và target_lines sau tokenization nhỏ hơn hoặc bằng kích thước đầu vào và đầu ra tối đa của mô hình. Do đó, việc cắt bớt chỉ ảnh hưởng đến phần ngữ cảnh của mỗi instance, nếu cần thiết.

Chúng tôi cũng tokenize đích theo cách tương tự nhưng độc lập và không thêm prefix hoặc ngữ cảnh. Để tokenize đầu vào và đích, chúng tôi sử dụng tokenizer subword dựa trên RoBERTa được huấn luyện trước, sử dụng byte-level byte-pair-encoding (BPE) (Sennrich et al., 2016). Chúng tôi sử dụng tokenizer đi kèm với CodeT5 và được huấn luyện để hiệu quả trong việc tokenize mã nguồn. Bằng cách sử dụng tokenizer được huấn luyện đặc biệt trên mã, chúng tôi có thể giảm số lượng token được tạo ra, điều này lần lượt cải thiện hiệu suất huấn luyện và tạo đầu ra của mô hình.

Các thuật toán tokenization subword chia các từ hiếm thành các phần nhỏ hơn, có ý nghĩa trong khi để nguyên các từ phổ biến. Tokenizer BPE cho phép chúng tôi bao gồm các token đặc thù dự án hiếm trong từ vựng của chúng tôi bằng cách chia chúng thành các phần nhỏ hơn (Jiang et al., 2021). Tokenization subword cung cấp cho mô hình kích thước từ vựng hợp lý trong khi cố gắng giảm thiểu vấn đề out-of-vocabulary (OOV) (Karampatsis et al., 2020).

Đầu ra cuối cùng bao gồm các cặp nguồn-ngữ cảnh được tokenize và các nhãn đích được tokenize. Chúng tôi biểu diễn đầu vào được mã hóa trong định dạng sau:

<s>prefix b1b2...bn:c1c2...cm</s>

trong đó n và m biểu thị số lượng token có lỗi và ngữ cảnh, tương ứng. Các token <s> và </s> đánh dấu điểm bắt đầu và kết thúc của một chuỗi. Hình 4 minh họa một ví dụ về cách, cho nguồn và ngữ cảnh, đầu vào được mã hóa cho các ngôn ngữ lập trình được xem xét.

Token ˙G được sử dụng để biểu diễn ký tự khoảng cách vì tokenizer này đã được huấn luyện để xem xét khoảng cách như một phần của các token.

Sau khi tokenize và chuẩn bị dữ liệu cho mỗi ngôn ngữ lập trình, chúng tôi nối dữ liệu từ các ngôn ngữ lập trình khác nhau thành một tập dữ liệu duy nhất.

2.5 Kiến trúc mô hình
Mô hình cơ sở của chúng tôi là CodeT5, một mô hình transformer hiện đại có thể xử lý cả ngôn ngữ tự nhiên và mã nguồn. CodeT5 sử dụng cùng kiến trúc encoder-decoder như T5 (Raffel et al., 2020) nhưng được huấn luyện trước trên tập dữ liệu quy mô lớn các đoạn mã và mô tả ngôn ngữ tự nhiên từ nhiều ngôn ngữ lập trình khác nhau. Các tác giả đã sử dụng tập dữ liệu CodeSearchNet (Husain et al., 2020) và một tập dữ liệu khác mà họ thu thập từ BigQuery, chứa các đoạn mã từ tám ngôn ngữ lập trình (Ruby, JavaScript, Go, Python, Java, PHP, C, và C#) và các mô tả ngôn ngữ tự nhiên tương ứng được trích xuất từ các kho mã công cộng.

Kiến trúc của CodeT5 bao gồm khung encoder-decoder với nhiều lớp cơ chế self-attention. Encoder tạo ra các biểu diễn ẩn của chuỗi đầu vào, trong khi decoder sử dụng chúng để tạo ra chuỗi đầu ra. Cơ chế self-attention cho phép mô hình tập trung vào các phần khác nhau của chuỗi đầu vào và nắm bắt các mối quan hệ phức tạp giữa các phần khác nhau của mã nguồn (Wang et al., 2021).

Chúng tôi chọn CodeT5 làm mô hình cơ sở vì một số lý do. Đầu tiên, đó là một mô hình transformer mã nguồn mở, được huấn luyện trước trên nhiều ngôn ngữ lập trình có sẵn để sử dụng và thích ứng. Thứ hai, nó có kiến trúc encoder-decoder mạnh mẽ và linh hoạt có thể xử lý các định dạng và độ dài đầu vào và đầu ra khác nhau. Thứ ba, nó có phiên bản nhỏ chỉ với 60M tham số, hiệu quả hơn về mặt tính toán so với các mô hình lớn khác nhưng vẫn đạt được kết quả tương đương (Wang et al., 2021).

CodeT5 đã được chứng minh đạt được hiệu suất hiện đại trên một số nhiệm vụ liên quan đến mã, bao gồm tạo mã, tóm tắt mã, tinh chỉnh mã và hoàn thành mã. Điều này có nghĩa là CodeT5 có nền tảng vững chắc để xử lý các nhiệm vụ liên quan đến mã và có thể học được cách thực hiện sửa chữa chương trình hiệu quả (Jiang et al., 2021).

CodeT5 trải qua bốn nhiệm vụ huấn luyện trước để có được khả năng nhận biết mã:
1. Dự đoán span bị che khuất ngẫu nhiên chọn các span có độ dài tùy ý để che khuất và sau đó sử dụng decoder để dự đoán các span bị che khuất này được đánh dấu bằng một số token sentinel.
2. Gắn thẻ định danh huấn luyện mô hình hiểu liệu một token mã có phải là định danh hay không.
3. Dự đoán định danh bị che khuất che khuất tất cả các định danh trong mã và sử dụng token mask duy nhất cho tất cả các lần xuất hiện của một định danh cụ thể.
4. Tạo song phương xem xét việc tạo văn bản tự nhiên từ mã nguồn và mã nguồn từ văn bản tự nhiên (NL ↔ PL).

Tất cả các nhiệm vụ này được công thức hóa như một nhiệm vụ sequence-to-sequence. Các nhiệm vụ 1, 2 và 3 là một phần của huấn luyện trước denoising nhận biết định danh tăng cường sự hiểu biết của mô hình về cú pháp, cấu trúc và ngữ nghĩa mã. Nhiệm vụ 4 hiệu quả cho việc chuyển đổi giữa văn bản và mã, như tạo comments cho mã hoặc tạo đoạn mã dựa trên mô tả như GitHub Copilot.

2.6 Tinh chỉnh CodeT5
Tinh chỉnh là quá trình thích ứng một mô hình được huấn luyện trước cho một nhiệm vụ cụ thể sử dụng dữ liệu đặc thù nhiệm vụ. Trong phương pháp của chúng tôi, chúng tôi tinh chỉnh mô hình CodeT5 cho APR đa ngôn ngữ. Điều này bao gồm việc huấn luyện một mô hình thống nhất trên tập dữ liệu đa ngôn ngữ bao gồm nhiều ngôn ngữ lập trình; trong trường hợp của chúng tôi là Java, Python, C và JavaScript. Dữ liệu huấn luyện của chúng tôi chứa ba cột: hunk có lỗi (nguồn), hàm ngữ cảnh có lỗi xung quanh, và hunk đã được sửa tương ứng (đích).

Quá trình tinh chỉnh điều chỉnh các tham số của mô hình CodeT5 được huấn luyện trước để phù hợp hơn với nhiệm vụ cụ thể của APR bằng cách giảm thiểu hàm mất mát cross-entropy đo lường sự khác biệt giữa dự đoán của mô hình và các bản sửa đích thực tế. Khi mô hình gặp dữ liệu đặc thù nhiệm vụ, nó tiếp tục học và cập nhật các tham số của mình để cải thiện hiệu suất trên nhiệm vụ sửa chữa. Chúng tôi tinh chỉnh tất cả các ngôn ngữ đồng thời trong các batch chứa mẫu từ tất cả các ngôn ngữ lập trình trong khi sử dụng prefix để xác định mỗi ngôn ngữ. Phương pháp này tận dụng học đa nhiệm (tức là xem xét việc sửa chữa mỗi ngôn ngữ như một nhiệm vụ riêng biệt), mở rộng tập dữ liệu, và cho phép chuyển giao kiến thức giữa các nhiệm vụ sửa lỗi trong các ngôn ngữ khác nhau. Bằng cách sử dụng mô hình cơ sở đa ngôn ngữ và tinh chỉnh nó với dữ liệu kết hợp từ các ngôn ngữ khác nhau (Phần 2.4), chúng tôi tạo điều kiện cho việc học đa ngôn ngữ, nơi mô hình học từ lỗi và bản sửa trên nhiều ngôn ngữ lập trình khác nhau. Đáng chú ý, chiến lược này chứng minh đặc biệt hiệu quả cho việc xử lý các lỗi phổ biến trên tất cả các ngôn ngữ (Berabi et al., 2021).

Chúng tôi tinh chỉnh mô hình cho một số epoch được chỉ định biểu thị bằng i trong khi lưu một checkpoint mỗi j bước, dẫn đến k checkpoint như được hiển thị trong Hình 2.

2.7 Ensemble checkpoint
Do tính chất đa dạng của lỗi và bản sửa, một mô hình duy nhất với các tham số tối ưu có thể không tổng quát hóa tốt (Lutellier et al., 2020). Học ensemble đã là một kỹ thuật phổ biến trong học máy để tăng cường hiệu suất và độ mạnh mẽ của mô hình (Dietterich, 2000). Trong ngữ cảnh của các mô hình transformer, học ensemble bao gồm việc huấn luyện nhiều instance của cùng một mô hình với khởi tạo hoặc siêu tham số khác nhau và sau đó kết hợp kết quả của chúng để có được đầu ra cuối cùng.

Các phương pháp trước đây trong APR đã sử dụng các mô hình ensemble, kết hợp nhiều mô hình riêng biệt để tạo ra các bản vá sửa lỗi (Jiang et al., 2021, 2023b; Lutellier et al., 2020). Mặc dù phương pháp này đã cho thấy hiệu quả trong việc sửa nhiều lỗi hơn, nó thường đòi hỏi chi phí tính toán đáng kể do huấn luyện nhiều mô hình chuyên biệt với các đầu vào, siêu tham số khác nhau, và trong một số trường hợp, thậm chí các kiến trúc riêng biệt.

Ngược lại, chúng tôi áp dụng phương pháp ensemble checkpoint cho T5APR, không chỉ cải thiện hiệu suất mà còn giảm chi phí huấn luyện (Chen et al., 2017). Thay vì huấn luyện các mô hình riêng biệt, chúng tôi khai thác khả năng đa dạng của mô hình ở các bước huấn luyện khác nhau bằng cách lưu và sử dụng nhiều checkpoint. Chúng tôi lưu k checkpoint trong quá trình huấn luyện mô hình, trong đó k đại diện cho số lượng checkpoint được sử dụng trong ensemble. Các checkpoint được lưu có khả năng bổ sung để tạo ra các bản vá cho các loại lỗi khác nhau và đóng góp vào chất lượng xếp hạng bản vá.

2.8 Tạo và xếp hạng bản vá
Sau khi có được k checkpoint từ mô hình được huấn luyện, chúng tôi tiến hành tạo ra các bản vá cho mỗi lỗi. Chúng tôi áp dụng các bước chuẩn bị dữ liệu và tokenization tương tự cho hunk có lỗi được định vị và ngữ cảnh của nó như được mô tả trong Phần 2.4, với sự khác biệt duy nhất là chúng tôi cắt bớt tất cả các instance dài để phù hợp với kích thước mô hình mà không loại bỏ bất kỳ instance nào.

Trong một số trường hợp, hunk có lỗi không nằm trong một hàm. Mặc dù dữ liệu huấn luyện của chúng tôi luôn chứa các hàm, chúng tôi không loại bỏ những lỗi này. Thay vào đó, chúng tôi để ngữ cảnh trống và cố gắng tạo ra các bản vá chỉ sử dụng các dòng có lỗi.

Tiếp theo, chúng tôi tạo ra các bản vá ứng viên cho một ví dụ đã cho bằng cách sử dụng mô hình. Để đạt được điều này, chúng tôi sử dụng beam search với kích thước beam cụ thể t trên mỗi checkpoint, dẫn đến việc tạo ra t bản vá tốt nhất từ mỗi checkpoint dựa trên điểm ước lượng khả năng tối đa của mỗi chuỗi. Tổng cộng, chúng tôi có được k×t bản vá thông qua ensemble checkpoint như được hiển thị trong Hình 2.

Để hợp nhất các bản vá được tạo ra từ các checkpoint khác nhau, chúng tôi kết hợp, loại bỏ trùng lặp và xếp hạng lại các bản vá bằng cách áp dụng các bước sau:
1. Chúng tôi chuẩn hóa các ký tự khoảng trắng trong các bản vá được tạo ra để đảm bảo tính nhất quán.
2. Chúng tôi hợp nhất và sắp xếp các bản vá cho mỗi hunk theo thứ hạng checkpoint của chúng, phá vỡ sự ngang bằng bằng cách sử dụng điểm chuỗi (tức là điểm khả năng của mỗi chuỗi được tạo ra bởi mỗi checkpoint).
3. Chúng tôi loại bỏ các bản vá giống hệt với nguồn có lỗi, vì chúng không đóng góp vào quá trình sửa chữa.
4. Chúng tôi loại bỏ trùng lặp các bản vá, chỉ giữ lại những cái duy nhất, và giữ lại bản vá đầu tiên trong danh sách trong trường hợp trùng lặp.
5. Cuối cùng, để tính đến khả năng loại bỏ các dòng có lỗi, chúng tôi thêm một bản vá trống vào đầu danh sách cho bất kỳ lỗi nào thiếu một bản vá.

Đối với các lỗi single-hunk, danh sách được tạo ra đã sẵn sàng để xác nhận. Tuy nhiên, đối với các lỗi multi-hunk (lỗi yêu cầu thay đổi ở nhiều hơn một vị trí mã), chúng tôi thực hiện xử lý bổ sung để giảm không gian tìm kiếm của các bản vá (Saha et al., 2019). Cụ thể, chúng tôi tập trung vào các bản vá multi-hunk thể hiện các thay đổi tương tự trên tất cả các hunk (Madeiral và Durieux, 2021). Chúng tôi xác định các bản vá giống hệt nhau trong số những bản được tạo ra cho tất cả các hunk của một lỗi và chỉ giữ lại những bản vá có mặt trong tất cả các hunk. Các bản vá sau đó được sắp xếp dựa trên điểm chuỗi tối đa giữa các bản vá của mỗi hunk. Do đó, chúng tôi có được một danh sách các bản vá có thể được áp dụng cho tất cả các hunk, giảm đáng kể số lượng bản vá cần xác nhận.

Những bản vá ứng viên cuối cùng này trải qua xác nhận thêm để chọn ra các bản sửa đúng.

2.9 Xác nhận bản vá
APR dựa trên bộ test sử dụng bộ test như đặc tả tính đúng đắn của chương trình. Trong giai đoạn này, chúng tôi xác nhận các bản vá ứng viên có được từ giai đoạn trước bằng cách áp dụng chúng vào mã nguồn gốc, biên dịch mã đã được vá, và chạy bộ test do nhà phát triển viết. Mục tiêu là lọc ra các bản vá không biên dịch được hoặc không vượt qua các test case trong bộ test của dự án.

Để xác nhận các bản vá ứng viên, chúng tôi làm theo các bước sau: Chúng tôi áp dụng mỗi bản vá vào vị trí có lỗi của mã nguồn bằng cách thay thế các dòng có lỗi bằng các dòng đã được sửa tương ứng từ bản vá được tạo ra. Sau đó chúng tôi biên dịch mã đã được vá và chạy bộ test. Để làm cho quá trình này nhanh hơn, nếu có thể, chúng tôi trước tiên chạy các test case kích hoạt lỗi, và nếu tất cả chúng đều vượt qua, chúng tôi tiến hành chạy phần còn lại của các test case làm cho phiên bản có lỗi vượt qua để tránh hồi quy. Chúng tôi đảm bảo loại bỏ các test không ổn định khỏi quá trình này. Chương trình đã được vá được coi là hợp lệ nếu nó vượt qua tất cả các test case mà dự án có lỗi đã vượt qua và vượt qua các test case kích hoạt mà trước đây đã thất bại trên dự án có lỗi. Phương pháp xác nhận này phù hợp với các thực hành phổ biến trong nhiều nghiên cứu APR (Lutellier et al., 2020).

Các bản vá kết quả vượt qua quá trình xác nhận được gọi là các bản vá khả thi. Một bản vá khả thi là một bản vá thỏa mãn bộ test nhưng có thể không nhất thiết sửa được lỗi cơ bản. Tuy nhiên, điều cần thiết là so sánh các bản vá khả thi này với thực tế cơ bản (tức là các bản vá do nhà phát triển viết) để đánh giá liệu chúng có sửa đúng lỗi hay chỉ overfitting với các test case (Qi et al., 2015; Smith et al., 2015). Một bản vá là đúng nếu nó vượt qua bộ test và có ngữ nghĩa tương tự hoặc tương đương với bản vá của nhà phát triển.

3 Thiết lập thí nghiệm

3.1 Câu hỏi nghiên cứu
Các câu hỏi nghiên cứu mà chúng tôi nhằm trả lời trong bài báo này là:
• RQ1 (Hiệu quả và khả năng tổng quát hóa): T5APR so sánh như thế nào với các phương pháp APR hiện đại về hiệu quả sửa chữa và khả năng tổng quát hóa?
• RQ2 (Nhiều bản vá khả thi): Việc xem xét nhiều bản vá khả thi cải thiện hiệu quả sửa chữa của T5APR như thế nào?
• RQ3 (Nghiên cứu ablation): Tác động của ensemble checkpoint đối với hiệu suất của T5APR là gì?
• RQ4 (Đa ngôn ngữ và đơn ngôn ngữ): Hiệu quả của mô hình đa ngôn ngữ của T5APR so sánh như thế nào với các mô hình đơn ngôn ngữ cho mỗi ngôn ngữ lập trình?

3.2 Tập dữ liệu
Dữ liệu huấn luyện Chúng tôi sử dụng cùng tập dữ liệu được cung cấp bởi CoCoNuT (Lutellier et al., 2020) trên GitHub¹ để huấn luyện mô hình T5APR. Tập dữ liệu bao gồm các bộ ba của các hunk mã có lỗi, ngữ cảnh và đã được sửa từ lịch sử commit của các dự án mã nguồn mở khác nhau được lưu trữ trên các nền tảng như GitHub, GitLab và BitBucket. Tập dữ liệu bao phủ nhiều ngôn ngữ lập trình, bao gồm Java, Python, C và JavaScript, làm cho nó lý tưởng để huấn luyện một mô hình APR đa ngôn ngữ. Chúng tôi chọn những ngôn ngữ này vì chúng được sử dụng rộng rãi trong ngành công nghiệp phần mềm và bao phủ các paradigm và cú pháp khác nhau. Hơn nữa, chúng có độ phổ biến cao và tính khả dụng của dữ liệu huấn luyện và benchmark đánh giá cho sửa chữa chương trình. Bảng 1 cung cấp tóm tắt thống kê tập dữ liệu, bao gồm năm cutoff của dữ liệu được thu thập, số lượng dự án, instance trước tiền xử lý, và số lượng instance sau tiền xử lý và tokenization cho mỗi ngôn ngữ lập trình.

CoCoNuT tìm ngày của lỗi sớm nhất trong mỗi benchmark đánh giá và thu thập các commit được thực hiện trước ngày đó, và loại bỏ các instance được commit sau đó để tránh chồng chéo dữ liệu huấn luyện và đánh giá. Năm cutoff trong Bảng 1 là năm mà dữ liệu được thu thập cho đến năm đó. Các công trình khác cũng đã sử dụng dữ liệu này (Jiang et al., 2021, 2023b; Ye et al., 2022; Yuan et al., 2022).

Trong thí nghiệm của chúng tôi, chúng tôi sử dụng 512 token làm độ dài đầu vào tối đa của phương pháp chúng tôi, giống với độ dài đầu vào tối đa của CodeT5. Độ dài đầu ra tối đa được đặt là 256 token để cân bằng chi phí tính toán và hiệu suất của mô hình. CodeT5 cũng sử dụng 256 token làm độ dài đầu ra tối đa cho huấn luyện trước và một số nhiệm vụ downstream của nó. Hình 5 cho thấy phân phối nguồn và đích của các instance dữ liệu huấn luyện dựa trên số lượng token của chúng sau tiền xử lý nhưng trước khi lọc kích thước. Trục x chỉ ra phạm vi độ dài token, trong khi trục y đại diện cho số lượng instance. Các instance có độ dài token ngắn hơn thì nhiều hơn, và khi độ dài token tăng, số lượng instance giảm dần. Hình này chứng minh rằng lựa chọn độ dài đầu vào và đầu ra tối đa của chúng tôi là hợp lý và bao phủ hầu hết dữ liệu huấn luyện. Bảng 1 cho thấy từ tổng cộng 2,644,305 instance sau tiền xử lý, chúng tôi giữ lại 2,324,030 instance sau lọc kích thước, chiếm 87.89% dữ liệu.

Benchmark lỗi Chúng tôi đánh giá hiệu suất của T5APR trên một tập hợp đa dạng các benchmark, trải rộng nhiều ngôn ngữ lập trình và bao gồm nhiều loại lỗi khác nhau. Chúng tôi sử dụng các benchmark sau trong đánh giá của mình: Defects4J (Java) (Just et al., 2014), Bears (Java) (Madeiral et al., 2019), QuixBugs (Java và Python) (Lin et al., 2017), Codeflaws (C) (Tan et al., 2017), ManyBugs (C) (Le Goues et al., 2015), và BugAID (JavaScript) (Hanam et al., 2016). Những benchmark này cùng nhau bao phủ một phạm vi rộng các khuyết điểm phần mềm thực tế và thách thức lập trình (Sobreira et al., 2018; Ye et al., 2021a).

Defects4J là một cơ sở dữ liệu và framework của các lỗi thực tế từ 17 dự án Java mã nguồn mở nổi tiếng. Chúng tôi làm theo công trình trước đây (Jiang et al., 2023b; Ye et al., 2022; Zhu et al., 2021) và tách Defects4J thành hai phiên bản: Defects4J (v1.2) và Defects4J (v2.0). Defects4J (v1.2) chứa 395 lỗi, và Defects4J (v2.0) chứa 444 lỗi bổ sung chỉ có sẵn trong phiên bản v2.0. Benchmark Bears là một bộ sưu tập các lỗi từ 72 dự án Java được lưu trữ trên GitHub và được trích xuất bằng cách sử dụng lịch sử trạng thái tích hợp liên tục của chúng. QuixBugs chứa 40 lỗi từ các bài toán Quixey Challenge trong cả Java và Python. Các chương trình là các thuật toán cổ điển nhỏ trong một tệp duy nhất. Codeflaws là một tập hợp các lỗi từ cuộc thi lập trình Codeforces trong C nơi mỗi chương trình là một tệp duy nhất. ManyBugs chứa các lỗi từ các dự án C mã nguồn mở lớn phổ biến. Benchmark BugAID bao gồm 12 ví dụ về các mẫu lỗi phổ biến trong JavaScript được mô tả trong Hanam et al. (2016).

Bảng 2 cung cấp thống kê chi tiết cho mỗi benchmark. Bảng bao gồm số lượng lỗi có mặt trong mỗi benchmark, số lượng lỗi được loại bỏ khỏi xem xét vì chúng là bản sao của các lỗi khác hoặc phiên bản có lỗi và đã được sửa của chúng không có thay đổi, số lượng lỗi còn lại đủ điều kiện để đánh giá, và tổng số lỗi mà chúng tôi cố gắng sửa chữa. Những thống kê này cung cấp thông tin chi tiết về quy mô của mỗi benchmark và phạm vi đánh giá thí nghiệm của chúng tôi.

3.3 Chi tiết triển khai và tham số
Triển khai Chúng tôi triển khai T5APR bằng Python và sử dụng thư viện Hugging Face Transformers (Wolf et al., 2020) với backend PyTorch (Paszke et al., 2019) để huấn luyện mô hình. Chuẩn bị và tiền xử lý dữ liệu được thực hiện bằng thư viện Hugging Face Datasets (Lhoest et al., 2021), dựa trên Apache Arrow để xử lý dữ liệu hiệu quả.

Chúng tôi sử dụng checkpoint CodeT5 được huấn luyện bằng mục tiêu huấn luyện trước denoising nhận biết định danh trong 100 epoch. CodeT5 có nhiều biến thể với kích thước và số lượng tham số khác nhau. Chúng tôi tinh chỉnh mô hình nhỏ (CodeT5-small) có tổng cộng 60M tham số. Mặc dù các mô hình lớn hơn có xu hướng hoạt động tốt hơn, đã được chứng minh rằng mô hình nhỏ cũng tương đối có khả năng (Wang et al., 2021). Chúng tôi để việc sử dụng các kích thước mô hình khác của CodeT5 cho công việc tương lai do hạn chế tài nguyên.

Kích thước từ vựng của tokenizer CodeT5 là 32,100, trong đó 32,000 token được lấy từ tập dữ liệu huấn luyện trước với các ký tự không in được và token tần suất thấp (xuất hiện ít hơn ba lần) được lọc và 100 token đặc biệt cho padding (<pad>), masking (<mask>), đánh dấu đầu và cuối của chuỗi (<s>, </s>), và đại diện cho token không xác định (<unk>).

Việc lựa chọn siêu tham số, chẳng hạn như tốc độ học, kích thước batch, hoặc số epoch huấn luyện có thể có tác động đáng kể đến hiệu suất của mô hình được tinh chỉnh. Những siêu tham số này thường được điều chỉnh bằng cách sử dụng một tập validation riêng biệt, được tách ra từ dữ liệu huấn luyện và được sử dụng để đánh giá hiệu suất của mô hình trên các ví dụ chưa thấy.

Chúng tôi sử dụng framework tối ưu hóa Optuna (Akiba et al., 2019) và sử dụng optimizer AdamW (Loshchilov và Hutter, 2018) để tiến hành tìm kiếm siêu tham số. Chúng tôi chia ngẫu nhiên tập dữ liệu huấn luyện Python của chúng tôi thành một tập huấn luyện và một tập validation, với 5,000 instance trong tập validation và phần còn lại trong tập huấn luyện. Sự phân tách này chỉ dành cho việc điều chỉnh siêu tham số, và sau đó để huấn luyện, chúng tôi sử dụng toàn bộ tập dữ liệu Python.

Các tiêu chí đánh giá cho việc điều chỉnh siêu tham số là exact match và điểm BLEU (Papineni et al., 2002). Exact match là tỷ lệ các instance mà chuỗi dự đoán khớp chính xác với chuỗi thực tế. Điểm BLEU xem xét có bao nhiêu n-gram trong đầu ra của mô hình khớp với n-gram trong chuỗi thực tế và là một thước đo độ tương tự giữa đầu ra mô hình và chuỗi thực tế, mà chúng tôi tính toán bằng thư viện sacreBLEU (Post, 2018). Chúng tôi định nghĩa metric mục tiêu cho tối ưu hóa siêu tham số là tổng exact match và điểm BLEU như sau:

objective metric = exact match × 100 + BLEU score (1)

Điểm BLEU từ sacreBLEU dao động từ 0 đến 100, với 100 là điểm tốt nhất có thể. Do đó, chúng tôi nhân exact match với 100 để có cùng phạm vi giá trị cho cả hai metric.

Chúng tôi định nghĩa không gian tìm kiếm siêu tham số dựa trên các giá trị hợp lý thường được sử dụng cho tinh chỉnh transformer trong công trình liên quan như sau: Tốc độ học dao động từ 1e−5 đến 1e−3, epoch huấn luyện dao động từ 1 đến 5 epoch, kích thước batch huấn luyện có phạm vi tìm kiếm từ 4 đến 16, kích thước beam đến 5, và loại scheduler tốc độ học bao gồm constant, cosine, linear, và polynomial.

Sau điều chỉnh siêu tham số, chúng tôi đặt các siêu tham số cuối cùng như sau: kích thước batch huấn luyện được đặt thành 8, epoch huấn luyện thành 1, tốc độ học thành 1e−4, và loại scheduler tốc độ học thành constant. Chúng tôi cũng sử dụng mixed precision FP16 để huấn luyện nhanh hơn. Trong quá trình huấn luyện, chúng tôi đặt k = 5 và lưu năm checkpoint. Mỗi checkpoint được lưu ở mỗi 20% bước của epoch huấn luyện.

Trong quyết định sử dụng năm checkpoint, chúng tôi lấy cảm hứng từ các phương pháp thành công trước đây của CoCoNuT (Lutellier et al., 2020), CURE (Jiang et al., 2021), và KNOD (Jiang et al., 2023b), cũng sử dụng từ năm đến mười mô hình trong ensemble của họ. Số lượng này đã được chứng minh hiệu quả trong công trình liên quan, và chúng tôi áp dụng nó như một điểm khởi đầu hợp lý cho ensemble của chúng tôi. Chúng tôi cho thấy rằng nhiều checkpoint hơn dẫn đến nhiều bản sửa lỗi hơn, như cũng được chỉ ra bởi CoCoNuT và CURE.

Để suy luận cuối cùng và tạo bản vá của các benchmark, chúng tôi đặt kích thước beam thành 100 để tạo ra 100 bản vá từ mỗi checkpoint. Kích thước beam lớn hơn sẽ cải thiện kết quả (Tufano et al., 2019a), nhưng do hạn chế tài nguyên, chúng tôi chọn kích thước beam là 100.

Để phân tích các tệp nguồn và trích xuất ngữ cảnh có lỗi, chúng tôi sử dụng thư viện phân tích Tree-sitter² và các lexer có sẵn trong Pygments³. Những thư viện này có thể tokenize và phân tích nhiều ngôn ngữ lập trình, làm cho chúng phù hợp cho phương pháp đa ngôn ngữ của chúng tôi. Chúng tôi cũng sử dụng Unidiff⁴ để phân tích diff của mã có lỗi và đã được sửa để trích xuất vị trí của các hunk có lỗi.

Hạ tầng Chúng tôi huấn luyện mô hình của chúng tôi trên một máy chủ với 4 lõi CPU Intel Xeon Platinum 8259CL, 16 GB RAM, và GPU NVIDIA T4 với 16 GB VRAM. Để đánh giá, chúng tôi sử dụng một hệ thống khác với CPU Intel Core i7-8750H 6 lõi, 16 GB RAM, và GPU NVIDIA GeForce GTX 1060 với 6 GB VRAM.

3.4 Đánh giá bản vá
Các bản vá có thể được biên dịch và vượt qua bộ test của dự án được gọi là khả thi. Tuy nhiên, một bản vá khả thi có thể không sửa được lỗi nếu bộ test yếu và không bao phủ tất cả các trường hợp (Qi et al., 2015). Điều này được gọi là vấn đề overfitting, nơi bản vá chỉ hoạt động cho các test case chứ không phải cho vấn đề (Smith et al., 2015). Do đó, chúng tôi sử dụng các tiêu chí sau để xác định xem một bản vá khả thi có đúng không (Ye và Monperrus, 2024):

• Nó giống hệt với bản vá do nhà phát triển cung cấp.
• Nó giống hệt với các bản vá đúng được tạo ra bởi các kỹ thuật hiện có đã trải qua đánh giá công khai bởi cộng đồng trong các kho mã nguồn mở.
• Chúng tôi đánh giá nó tương đương về mặt ngữ nghĩa với bản vá do nhà phát triển cung cấp bằng cách sử dụng các quy tắc được mô tả bởi Liu et al. (2020).

Để tuân thủ những tiêu chí này, một tác giả đã kiểm tra xem các bản vá có giống hệt với những bản được tạo ra bởi nhà phát triển hoặc các kỹ thuật hiện có khác không. Đối với các bản vá còn lại yêu cầu kiểm tra tương đương ngữ nghĩa, tác giả đã tham khảo ý kiến với tác giả khác trong trường hợp không chắc chắn. Để giảm khả năng xảy ra lỗi trong quá trình này, chúng tôi đã công khai tất cả các bản vá được tạo ra để cộng đồng đánh giá và xem xét.⁵

3.5 Quy trình phân tích
Chúng tôi so sánh T5APR với các công cụ dựa trên học tập hiện đại gần đây và các công cụ từ các danh mục khác, chẳng hạn như sửa chữa dựa trên template và dựa trên ngữ nghĩa được đánh giá trên các benchmark đã chọn của chúng tôi và báo cáo kết quả của chúng dưới thiết lập định vị lỗi hoàn hảo. Các kỹ thuật sử dụng định vị lỗi hoàn hảo được cung cấp vị trí chính xác của lỗi. Chúng tôi xác định vị trí của mỗi lỗi với sự trợ giúp của các bản vá do con người viết và diff của chúng. Một số phương pháp sử dụng các thuật toán hoặc triển khai định vị lỗi khác nhau để tìm vị trí có lỗi, điều này khiến việc chỉ so sánh khả năng sửa chữa của mỗi phương pháp trở nên khó khăn. Các nghiên cứu gần đây cho rằng định vị lỗi hoàn hảo là cách ưa thích để đánh giá các phương pháp APR, vì nó cho phép so sánh công bằng các kỹ thuật APR mà không phụ thuộc vào phương pháp định vị lỗi (Liu et al., 2019a, 2020).

Chúng tôi so sánh T5APR với 11 công cụ hiện đại, bao gồm bảy công cụ APR Java: SequenceR (Chen et al., 2019), TBar (Liu et al., 2019b), DLFix (Li et al., 2020), CURE (Jiang et al., 2021), Recoder (Zhu et al., 2021), RewardRepair (Ye et al., 2022), và KNOD (Jiang et al., 2023b). Một công cụ C: SOSRepair (Afzal et al., 2019). Hai công cụ sử dụng các mô hình ngôn ngữ lớn: Codex (Prenner et al., 2022) và ChatGPT (Sobania et al., 2023). Cuối cùng, CoCoNuT (Lutellier et al., 2020), được đánh giá trên tất cả bốn ngôn ngữ lập trình.

Chúng tôi không bao gồm CIRCLE (Yuan et al., 2022) trong đánh giá vì họ chưa xác nhận các bản vá ứng viên của mình bằng bộ test của benchmark và chỉ báo cáo kết quả exact match trên các bản vá được tạo ra của họ.

Để so sánh với các phương pháp này, chúng tôi làm theo các công trình trước đây và chỉ xem xét bản vá khả thi đầu tiên được tạo ra bởi T5APR thành công biên dịch và vượt qua bộ test (Durieux et al., 2019; Liu et al., 2019b; Lutellier et al., 2020). Có thể có các bản vá đúng xa hơn trong danh sách bản vá khả thi, nhưng chúng tôi phân tích những cái đó trong một phần khác.

Chúng tôi lấy kết quả từ bài báo hoặc kho của mỗi công cụ. Kết quả kho, khi có sẵn, thường mới hơn và có thể chứa các sửa chữa từ các phiên bản bài báo. Đối với các công cụ không báo cáo kết quả với định vị hoàn hảo hoặc cho một số benchmark, chúng tôi sử dụng kết quả từ các ấn phẩm khác đánh giá những công cụ này dưới thiết lập định vị hoàn hảo (Liu et al., 2020; Zhong et al., 2023).

Để tính toán xếp hạng bản vá, tỷ lệ bản vá có thể biên dịch, và lỗi duy nhất mà T5APR có thể sửa so với các phương pháp khác, chúng tôi lấy danh sách các bản vá ứng viên và lỗi đã được sửa cho mỗi phương pháp trên mỗi benchmark từ các kho tương ứng của chúng (Những cái cung cấp nó).

4 Kết quả và thảo luận

4.1 RQ1: Hiệu quả và khả năng tổng quát hóa
Bảng 3 trình bày kết quả đánh giá hiệu suất của T5APR trên nhiều benchmark và so với một lựa chọn các công cụ APR hiện đại. Bảng hiển thị tên và tổng số lỗi được xem xét cho mỗi benchmark bên dưới tên của nó. Kết quả được hiển thị dưới dạng c/p trong đó c là số lượng bản vá đúng được xếp hạng đầu tiên như bản vá khả thi đầu tiên bởi một kỹ thuật APR, và p là tổng số bản vá khả thi. Chúng tôi cũng hiển thị, trong ngoặc đơn, số lượng lỗi có bản vá giống hệt với bản vá do nhà phát triển viết. Dấu gạch ngang (-) chỉ ra rằng công cụ chưa được đánh giá trên benchmark hoặc không hỗ trợ ngôn ngữ lập trình của benchmark theo hiểu biết tốt nhất của chúng tôi. Đối với các benchmark ManyBugs và BugAID, chúng tôi không thể xác nhận các bản vá của chúng; do đó, chúng tôi không thể hiển thị số lượng bản vá khả thi và chỉ báo cáo số lượng bản vá đúng mà chúng tôi xác định thủ công.

Chúng tôi làm nổi bật hiệu suất của T5APR trên những benchmark này như sau. Nhìn chung, T5APR sửa 1,985 lỗi trên tất cả các benchmark, với 1,413 trong số chúng được vá giống hệt với bản vá của nhà phát triển. Kết quả cho thấy T5APR vượt trội hoặc bằng tất cả các phương pháp khác trên tất cả các benchmark được đánh giá ngoại trừ Defects4J (v1.2) và ManyBugs.

Đối với Defects4J, chúng tôi quan sát thấy T5APR đạt được kết quả cạnh tranh, đặc biệt là trong Defects4J (v2.0) nơi nó tạo ra các bản sửa đúng cho 56 lỗi và vượt trội tất cả các phương pháp khác. Trong Defects4J (v1.2), KNOD hoạt động tốt hơn T5APR bằng cách sửa 71 lỗi, trong khi T5APR sửa 67 lỗi. Cần lưu ý rằng CoCoNuT, CURE, và KNOD sử dụng kích thước beam lớn hơn đáng kể là 1000 so với 100 mà T5APR sử dụng, và đã được chỉ ra rằng sử dụng kích thước beam lớn hơn dẫn đến nhiều bản vá đúng hơn (Tufano et al., 2019a). Lưu ý rằng nếu chúng tôi xem xét tất cả các bản vá khả thi được tạo ra (Bảng 8), T5APR đạt 72 lỗi đúng. Điều này cho thấy nhu cầu về chiến lược xếp hạng bản vá tốt hơn trong các nghiên cứu tương lai (Kang và Yoo, 2022).

Trong trường hợp Bears, T5APR chứng minh tiềm năng của mình bằng cách sửa chữa đúng 24 lỗi, vượt trội tất cả các công cụ được so sánh. Kết quả trong hai benchmark này chỉ ra khả năng của T5APR trong việc giải quyết các lỗi thực tế trong các chương trình Java.

Trong benchmark QuixBugs, bao gồm cả chương trình Java và Python, T5APR cho thấy hiệu suất mạnh mẽ, sửa chữa 25 lỗi Java và đạt được sửa chữa đúng cho 29 lỗi Python. Tỷ lệ bản vá đúng trên khả thi cho cả hai phiên bản là khoảng 96%, nơi chỉ có một trong các bản vá khả thi được tạo ra là không đúng. Trong phiên bản QuixBugs (Java), T5APR thất bại trong việc sửa lỗi SQRT, và trong phiên bản QuixBugs (Python), nó thất bại trong việc sửa lỗi DEPTH_FIRST_SEARCH nơi nó được sửa đúng xa hơn trong danh sách bản vá.

Tương tự, trong Codeflaws, một benchmark ngôn ngữ lập trình C, T5APR thể hiện tính mạnh mẽ của mình bằng cách đạt được sửa chữa đáng kể 1,764 lỗi, vượt trội đối thủ duy nhất khác của nó, CoCoNuT. Chuyển sang benchmark ManyBugs, hiệu suất T5APR vẫn cạnh tranh bằng cách sửa chữa 15 lỗi, định vị mình trong số các công cụ hoạt động tốt nhất nhưng bị vượt trội bởi SOSRepair. Trong benchmark BugAID, T5APR đạt được tỷ lệ sửa chữa cao nhất, thành công sửa 5 trong số 12 lỗi, chứng minh năng lực của nó trong việc giải quyết các lỗi JavaScript.

Trong số các lỗi được T5APR sửa cho các benchmark Defects4J (v1.2), Defects4J (v2.0), Bears, Codeflaws, và ManyBugs, tương ứng 10, 4, 4, 36, và 2 trong số chúng là multi-hunk. Những cái này được sửa bằng chiến lược được mô tả trong Phần 2.8. Các benchmark còn lại hoặc không chứa lỗi multi-hunk hoặc không được T5APR sửa thành công.

So sánh T5APR với các phương pháp hiện đại hiện có, chúng tôi liên tục quan sát hiệu suất cạnh tranh hoặc vượt trội trên các benchmark khác nhau. Kết quả tổng thể cho thấy hiệu quả của T5APR trong việc sửa chữa một phạm vi rộng các khuyết điểm phần mềm và hiệu quả của nó trong việc xử lý các lỗi từ các ngôn ngữ lập trình khác nhau.

Xếp hạng bản vá Để cung cấp sự hiểu biết toàn diện về hiệu quả của chiến lược xếp hạng bản vá của T5APR, chúng tôi phân tích vị trí xếp hạng của các bản vá đúng được tạo ra bởi mỗi phương pháp. Chúng tôi trích xuất vị trí xếp hạng của các bản vá đúng cho mỗi lỗi từ danh sách các bản vá được tạo ra của mỗi phương pháp được cung cấp trong các kho phần mềm của họ. Sau đó, chúng tôi tính toán số lượng lỗi được sửa đúng ở các ngưỡng khác nhau. Hình 6 trình bày phân phối thông tin vị trí xếp hạng bản vá đúng ở các ngưỡng khác nhau. Mỗi đường trong biểu đồ tương ứng với một phương pháp khác nhau, bao gồm T5APR, CURE, RewardRepair, và KNOD. Trục x đại diện cho các ngưỡng xếp hạng, trong khi trục y chỉ ra số lượng lỗi được sửa đúng trong mỗi ngưỡng. Chúng tôi chỉ xem xét các công cụ mà chúng tôi có quyền truy cập vào thông tin xếp hạng bản vá và các bản vá ứng viên được tạo ra của chúng.

T5APR vượt trội tất cả các phương pháp khác trong xếp hạng bản vá đúng ngoại trừ top-200 trên QuixBugs (Java), nơi CURE hoạt động tốt hơn. Chúng ta cũng có thể thấy rằng mặc dù KNOD đạt kết quả tốt hơn T5APR cho Defects4J (v1.2) (71 so với 67 lỗi trong Bảng 3), T5APR sửa nhiều lỗi hơn lên đến top-500 bản vá ứng viên được tạo ra. KNOD tạo ra các bản sửa cho phần còn lại của các lỗi ở thứ hạng cao hơn 500 do sử dụng kích thước beam lớn hơn. Nhìn chung, 310 trong số các bản vá đúng được tạo ra bởi T5APR được xếp hạng đầu tiên trong danh sách bản vá ứng viên.

Bản sửa lỗi duy nhất Hình 7 trình bày số lượng lỗi duy nhất và chồng chéo được sửa chữa bởi các phương pháp riêng lẻ từ Bảng 3 cho tất cả các benchmark. Đối với các benchmark có nhiều hơn bốn công cụ, chúng tôi chọn ba công cụ tốt nhất cho benchmark đó và kết hợp các lỗi đã được sửa của các công cụ còn lại dưới "Others". Trên tất cả các benchmark, T5APR sửa 1,442 lỗi mà các công cụ khác không sửa được. Trên benchmark Defects4J, T5APR và KNOD bổ sung cho nhau bằng cách sửa tương ứng 21 và 25 lỗi duy nhất cho v1.2 và v2.0. Trên benchmark ManyBugs, T5APR có chất lượng bổ sung tốt và cùng với SOSRepair sửa 20 lỗi duy nhất. Nhìn chung, kết quả cho thấy T5APR bổ sung cho các công trình hiện có được so sánh trên tất cả các benchmark được đánh giá.

Chúng tôi cung cấp một vài ví dụ về các lỗi mà T5APR có thể sửa. Hình 8 cho thấy bản sửa được tạo ra bởi T5APR và bản vá thực tế cho lỗi Codec 5 từ benchmark Defects4J (v2.0) mà các công cụ khác không sửa được. Để sửa lỗi này, T5APR nhận thấy rằng header của phương thức ngữ cảnh có throws ParseException, điều này thúc đẩy T5APR tổng hợp một câu lệnh throw exception. Sự khác biệt duy nhất giữa T5APR và bản vá của nhà phát triển là thông điệp exception, nơi T5APR sử dụng tham số chuỗi của phương thức trong khi nhà phát triển viết một thông điệp tùy chỉnh.

Hình 9 đưa ra bản vá T5APR cho Bears-32, chỉ được T5APR sửa. Đối với lỗi này, T5APR thêm một kiểm tra null cho giá trị trả về của getStep(), đây là một mẫu phổ biến trong Java. Bản vá của nhà phát triển cho lỗi này được hiển thị trong Hình 3b. Bản vá của T5APR tương đương về mặt ngữ nghĩa với bản vá của nhà phát triển. Hình 10 cho thấy một lỗi Bears khác

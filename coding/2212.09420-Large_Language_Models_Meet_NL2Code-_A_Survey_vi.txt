# Khảo sát về Mô hình Ngôn ngữ Lớn gặp NL2Code

Daoguang Zan1;2, Bei Chen3, Fengji Zhang3, Dianjie Lu4, Bingchao Wu1,
Bei Guan5, Yongji Wang5, Jian-Guang Lou3
1Trung tâm Đổi mới Hợp tác, Viện Phần mềm, Viện Hàn lâm Khoa học Trung Quốc
2Đại học Viện Hàn lâm Khoa học Trung Quốc;3Microsoft Research Asia;4Đại học Sư phạm Shandong
5Trung tâm Đổi mới Tích hợp, Viện Phần mềm, Viện Hàn lâm Khoa học Trung Quốc

## Tóm tắt

Nhiệm vụ tạo mã từ mô tả ngôn ngữ tự nhiên, hay NL2Code, được coi là một thách thức cấp bách và quan trọng trong trí tuệ mã. Nhờ vào sự phát triển nhanh chóng của các kỹ thuật tiền huấn luyện, các mô hình ngôn ngữ lớn đang được đề xuất cho mã, thúc đẩy những tiến bộ trong NL2Code. Để hỗ trợ nghiên cứu và ứng dụng sâu hơn trong lĩnh vực này, trong bài báo này, chúng tôi trình bày một khảo sát toàn diện về 27 mô hình ngôn ngữ lớn hiện có cho NL2Code, và cũng xem xét các điểm chuẩn và số liệu. Chúng tôi cung cấp một so sánh trực quan của tất cả các mô hình hiện có trên điểm chuẩn HumanEval. Thông qua quan sát và phân tích sâu sắc, chúng tôi cung cấp một số hiểu biết và kết luận rằng các yếu tố chính góp phần vào thành công của các mô hình ngôn ngữ lớn cho NL2Code là "Kích thước Lớn, Dữ liệu Cao cấp, Điều chỉnh Chuyên gia". Ngoài ra, chúng tôi thảo luận về các thách thức và cơ hội liên quan đến khoảng cách giữa mô hình và con người. Chúng tôi cũng tạo ra một trang web https://nl2code.github.io để theo dõi tiến độ mới nhất thông qua đóng góp cộng đồng. Theo hiểu biết tốt nhất của chúng tôi, đây là khảo sát đầu tiên về các mô hình ngôn ngữ lớn cho NL2Code, và chúng tôi tin rằng nó sẽ đóng góp vào sự phát triển liên tục của lĩnh vực này.

## 1 Giới thiệu

Liệu có thể cho các lập trình viên mới bắt đầu, thậm chí những người không có kinh nghiệm lập trình nào, tạo ra phần mềm chỉ bằng cách mô tả yêu cầu của họ bằng ngôn ngữ tự nhiên? Đây là một câu hỏi hấp dẫn lâu đời, đặt ra thách thức cho các lĩnh vực nghiên cứu như kỹ thuật phần mềm, ngôn ngữ lập trình và trí tuệ nhân tạo. Việc hiện thực hóa kịch bản này sẽ có tác động chưa từng có đến cuộc sống, giáo dục, kinh tế và thị trường lao động của chúng ta, vì nó sẽ thay đổi mô hình phát triển và vận hành phần mềm tập trung. Do tương lai đầy hứa hẹn và hấp dẫn của nó, natural-language-to-code (NL2Code) đã được đề xuất như một nhiệm vụ nghiên cứu thu hút sự quan tâm rộng rãi trong cả học thuật và công nghiệp, với mục tiêu tạo ra mã từ các mô tả ngôn ngữ tự nhiên.

Các nghiên cứu ban đầu về NL2Code chủ yếu dựa trên các quy tắc phỏng đoán hoặc hệ thống chuyên gia, chẳng hạn như các phương pháp dựa trên ngữ pháp xác suất (Joshi và Rambow, 2003; Cohn et al., 2010; Allamanis và Sutton, 2014) và những phương pháp tập trung vào các ngôn ngữ chuyên dụng (de Moura và Bjørner, 2008; Gulwani, 2010; Jha et al., 2010), vốn không linh hoạt và không thể mở rộng. Các nghiên cứu khác sử dụng các mô hình ngôn ngữ tĩnh, như n-gram (Nguyen et al., 2013; Raychev et al., 2014; Devanbu, 2012) và Hidden Markov (Sutskever et al., 2008), có các biểu diễn vector thưa thớt và không thể mô hình hóa các phụ thuộc dài hạn. Sau đó, các mạng neural, bao gồm CNN (Liu et al., 2016; Sun et al., 2018), RNN (Iyer et al., 2016; Wan et al., 2018), và LSTM (Eriguchi et al., 2016; Yin và Neubig, 2017), được sử dụng để mô hình hóa mối quan hệ giữa NL và mã. Năm 2017, mô hình Transformer (Vaswani et al., 2017) được giới thiệu cho dịch máy và sau đó được áp dụng cho nhiệm vụ NL2Code (Mastropaolo et al., 2021; Shah et al., 2021). Tuy nhiên, các mô hình học sâu này yêu cầu một lượng đáng kể các cặp được gán nhãn của NL và mã để huấn luyện, và có khả năng hạn chế cho nhiệm vụ NL2Code.

Gần đây, một số lượng ngày càng tăng các mô hình ngôn ngữ lớn (LLMs) với kiến trúc Transformer đã được huấn luyện trên kho ngữ liệu mã không gán nhãn quy mô lớn. Các mô hình này có khả năng tạo mã theo cách zero-shot và đã đạt được kết quả ấn tượng trong nhiệm vụ NL2Code. Như một cột mốc quan trọng, Codex (Chen et al., 2021) đã chỉ ra rằng một LLM với 12 tỷ tham số có thể giải quyết 72.31% các bài toán lập trình Python thách thức được tạo ra bởi con người. Đáng khích lệ hơn, Codex đã được sử dụng để cung cấp năng lượng cho một sản phẩm thương mại và cải thiện hiệu quả lập trình trong thực tế (Sobania et al., 2022a; Barke et al., 2023).

Theo thành công của Codex, nhiều LLMs khác nhau cho nhiệm vụ NL2Code đã xuất hiện, với kích thước mô hình từ hàng triệu đến hàng tỷ tham số. Các ví dụ bao gồm AlphaCode (Li et al., 2022b), nhằm giải quyết các bài toán lập trình cấp độ cạnh tranh, và InCoder (Fried et al., 2023), hỗ trợ điền mã ở các vị trí tùy ý sử dụng ngữ cảnh hai chiều. Các mô hình khác như CodeGen (Nijkamp et al., 2023), PaLM-Coder (Chowdhery et al., 2022), PanGu-Coder (Christopoulou et al., 2022), CodeGeeX (Zheng et al., 2023), và SantaCoder (Allal et al., 2023) cũng đã thu hút sự chú ý lớn. Khi kích thước mô hình tăng lên, LLMs đã được chứng minh là thể hiện một số khả năng xuất hiện như lập trình và gỡ lỗi giống con người (Zhang et al., 2022; Saunders et al., 2022; Kang et al., 2023).

Các mô hình ngôn ngữ lớn đã thắp lên hy vọng cho nhiệm vụ NL2Code do sức mạnh ấn tượng và giá trị tiềm năng của chúng. Mặc dù có tiến bộ đáng kể, vẫn còn nhiều thách thức và cơ hội, đòi hỏi công việc tương lai tiên tiến và sáng tạo hơn. Hiện tại, xem xét sự đa dạng của các kỹ thuật và ứng dụng, ngày càng có nhu cầu về một khảo sát toàn diện để cung cấp một cái nhìn tổng quan có hệ thống về lĩnh vực này và xác định các thách thức quan trọng. Vì mục đích này, trong bài báo này, chúng tôi điều tra cẩn thận 27 LLMs tiên tiến cho NL2Code (§2), và cũng xem xét các điểm chuẩn và số liệu (§4). Chúng tôi tiến hành so sánh trực quan của tất cả các LLMs hiện có trên điểm chuẩn HumanEval, thực hiện phân tích kỹ lưỡng, và cuối cùng quy kết thành công của các LLMs này cho "Kích thước Lớn, Dữ liệu Cao cấp, Điều chỉnh Chuyên gia" (§3). Điều này có nghĩa là kích thước mô hình và dữ liệu lớn, dữ liệu huấn luyện chất lượng cao và điều chỉnh siêu tham số chuyên gia. Chúng tôi cũng thảo luận về các thách thức và cơ hội liên quan đến khoảng cách khả năng giữa LLMs và Con người (§5). Ngoài ra, chúng tôi đã xây dựng một trang web https://nl2code.github.io để theo dõi tiến độ mới nhất và hỗ trợ cập nhật crowdsourcing. Theo hiểu biết tốt nhất của chúng tôi, đây là khảo sát đầu tiên về LLMs cho NL2Code, và chúng tôi hy vọng nó sẽ đóng góp vào sự phát triển liên tục của lĩnh vực thú vị này.

## 2 Mô hình Ngôn ngữ Lớn cho NL2Code

Cho một mô tả bài toán ngôn ngữ tự nhiên, nhiệm vụ NL2Code nhằm tự động tạo ra mã được yêu cầu. Để minh họa nhiệm vụ này một cách trực quan, chúng tôi cung cấp một bài toán lập trình Python làm ví dụ trong Hình 1, trong khi các điểm chuẩn NL2Code khác nhau có thể khác nhau về ngôn ngữ hoặc miền bài toán. Các mô hình ngôn ngữ lớn hiện có cho nhiệm vụ NL2Code thường dựa trên Transformer (Vaswani et al., 2017) và được huấn luyện trên kho ngữ liệu không gán nhãn liên quan đến mã quy mô lớn. Để có hiệu suất tạo mã tốt hơn, hầu hết các LLMs, dù là mô hình encoder-decoder hay decoder-only, đều sử dụng mục tiêu mô hình hóa ngôn ngữ nhân quả để huấn luyện, tức là dự đoán token tiếp theo sau một chuỗi token. Trong quá trình suy luận, một LLM có thể giải quyết các bài toán NL2Code theo cách zero-shot mà không cần điều chỉnh tham số. Cũng có các nghiên cứu sử dụng few-shot (Austin et al., 2021) hoặc học trong ngữ cảnh (Nijkamp et al., 2023) để tăng cường hiệu suất hơn nữa.

Chúng tôi tiến hành một cuộc điều tra toàn diện về 27 LLMs đại diện cho nhiệm vụ NL2Code. Chi tiết của từng mô hình được tóm tắt trong Bảng 1, nơi các mô hình khác nhau về kiến trúc, kích thước và khả năng tiếp cận. Để trực quan hóa tốt hơn, chúng tôi trình bày các mô hình này theo thứ tự thời gian trong Hình 2, vẽ các kích thước mô hình lớn nhất. Một xu hướng được quan sát là các mô hình ngôn ngữ lớn này liên tục tăng về kích thước khi lĩnh vực nghiên cứu tiến bộ. Ngoài ra, kiến trúc decoder-only được ưa chuộng cho các mô hình được tiền huấn luyện với kích thước lớn hơn.

Các công trình ban đầu, như GPT-C (Svyatkovskiy et al., 2020), PyMT5 (Clement et al., 2020), và PLBART (Ahmad et al., 2021), có số lượng tham số tương đối nhỏ và không thể hiện khả năng mạnh mẽ trong tạo mã zero-shot. Ngược lại, các mô hình quy mô lớn như GPT-Neo (Black et al., 2021) và GPT-J (Wang và Komatsuzaki, 2021), mặc dù có thang tham số tỷ, đã được phát hiện có sức mạnh hạn chế trong nhiệm vụ NL2Code do lượng mã nhỏ trong kho ngữ liệu huấn luyện của chúng. Gần đây, một số LLMs mạnh mẽ đã được đề xuất cho NL2Code, như Codex (Chen et al., 2021), AlphaCode (Li et al., 2022b), và PaLM-Coder (Chowdhery et al., 2022), sở hữu thang tham số khổng lồ và kho ngữ liệu huấn luyện chất lượng cao với mã. Trong khi chúng cho thấy hiệu suất tốt đáng ngạc nhiên trên NL2Code, hầu hết chúng không dễ dàng tiếp cận. Hiện tại, một số mô hình mã nguồn mở xuất sắc cũng đã được đề xuất, bao gồm CodeParrot (Huggingface, 2021), PolyCoder (Xu et al., 2022), GPT-NeoX (Black et al., 2022), và SantaCoder (Allal et al., 2023), góp phần vào sự thịnh vượng của LLMs cho NL2Code. Bên cạnh đó, các nghiên cứu gần đây đã đề xuất nhiều cách tiếp cận khác nhau để giải quyết các kịch bản NL2Code cụ thể. Ví dụ, JuPyT5 (Chandel et al., 2022a) được thiết kế để làm việc trong Jupyter Notebooks, trong khi ERNIE-Code (Chai et al., 2022), CodeGeeX (Zheng et al., 2023), và BLOOM (Scao et al., 2022) được huấn luyện để hỗ trợ nhiều ngôn ngữ tự nhiên hoặc lập trình. Ngoài ra, InCoder (Fried et al., 2023), FIM (Bavarian et al., 2022), và SantaCoder (Allal et al., 2023) không chỉ hỗ trợ dự đoán mã từ trái sang phải, mà còn cho phép điền vào các vùng mã tùy ý. Khi LLMs cho NL2Code đang phát triển nhanh chóng, chúng tôi đã tạo ra một trang web để theo kịp với những tiến bộ mới nhất thông qua crowdsourcing. Chi tiết về trang web có thể được tìm thấy trong Phụ lục B.

Các mô hình này không chỉ hấp dẫn trong học thuật (Chen et al., 2021; Nijkamp et al., 2023; Li et al., 2022b), mà còn được áp dụng trong các sản phẩm thực tế để cải thiện hiệu quả lập trình (Sobania et al., 2022a; Barke et al., 2023). Một ví dụ là GitHub và Copilot của OpenAI, một công cụ hỗ trợ lập trình sử dụng Codex để cung cấp gợi ý mã thời gian thực. Các sản phẩm đáng chú ý khác bao gồm CodeGeeX và CodeWhisperer. Tóm tắt về 10 sản phẩm có thể được tìm thấy trong Phụ lục Bảng 5. Các nghiên cứu gần đây (Sobania et al., 2022b; Pearce et al., 2022; Nguyen và Nadi, 2022) đã chỉ ra rằng các sản phẩm này có thể cung cấp các khuyến nghị hữu ích, trong khi chúng cũng giới thiệu các lỗi nhỏ có thể gây ra vấn đề cho người dùng. Vẫn còn chỗ để cải thiện trước khi LLMs có thể hoàn toàn thực tế và có khả năng lập trình như con người.

## 3 Điều gì làm cho LLMs thành công?

Chúng tôi đã tóm tắt các mô hình ngôn ngữ lớn hiện có cho NL2Code. Các LLMs này khác nhau về kiến trúc, kích thước và các đặc tính khác, khiến việc thiết lập một so sánh hoàn toàn công bằng trở nên khó khăn. Chúng tôi đánh giá các LLMs này trên điểm chuẩn HumanEval (Chen et al., 2021) theo cách zero-shot để cung cấp một so sánh trực quan. HumanEval, được đề xuất cùng với Codex, là một trong những điểm chuẩn phổ biến nhất cho nhiệm vụ NL2Code và bao gồm 164 bài toán lập trình Python được viết tay. Các trường hợp thử nghiệm được cung cấp cho mỗi bài toán lập trình để đánh giá tính đúng đắn của mã được tạo ra. pass@k được sử dụng làm số liệu đánh giá, tính toán tỷ lệ các bài toán có thể được trả lời đúng với k lần thử. Bảng 2 cho thấy kết quả của các LLMs khác nhau được tổ chức theo kích thước mô hình. Chi tiết triển khai và đánh giá trên điểm chuẩn MBPP (Austin et al., 2021) có thể được tìm thấy trong Phụ lục C.2.

Có thể quan sát từ Bảng 2 rằng hiệu suất của các LLMs hiện có khác nhau rộng rãi trên HumanEval, ngay cả đối với những mô hình có kích thước tương tự. Cụ thể, Codex (Chen et al., 2021) giữ vị trí dẫn đầu trong các kích thước mô hình khác nhau, trong khi một mô hình tương đối nhỏ, PyCodeGPT 110M (Zan et al., 2022b), đạt được kết quả tương đương với Codex 85M. Các mô hình lớn hơn khác như AlphaCode (Li et al., 2022b), CodeGen-Mono (Nijkamp et al., 2023), và PanGu-Coder (Christopoulou et al., 2022) cũng thể hiện hiệu suất ấn tượng. Đáng chú ý, InCoder (Fried et al., 2023) và SantaCoder (Allal et al., 2023), sử dụng phương pháp huấn luyện FIM (Bavarian et al., 2022), cũng đạt được kết quả đáng kể trong thiết lập tạo từ trái sang phải. Sự biến đổi đáng kể trong hiệu suất dẫn chúng tôi đến câu hỏi: Điều gì làm cho LLMs thành công trong NL2Code? Cho sự đa dạng của các mô hình này về các lựa chọn thiết kế, chúng tôi thực hiện một phân tích kỹ lưỡng và kết luận câu trả lời: Kích thước Lớn, Dữ liệu Cao cấp, Điều chỉnh Chuyên gia. Tức là, kích thước mô hình và dữ liệu lớn, dữ liệu chất lượng cao và điều chỉnh siêu tham số chuyên gia là các yếu tố chính cho thành công của LLMs trong nhiệm vụ NL2Code. Trong phần này, chúng tôi chi tiết các quan sát và hiểu biết của mình từ các góc độ mô hình, dữ liệu và điều chỉnh.

### 3.1 Kích thước Mô hình Lớn

Như được hiển thị trong Hình 2 và Bảng 2, các LLMs gần đây cho NL2Code thể hiện kích thước lớn hơn và hiệu suất vượt trội. Điều này phù hợp với các phát hiện trước đây rằng việc tăng số lượng tham số mô hình có thể nâng cao khả năng mô hình (Radford et al., 2019; Thoppilan et al., 2022; Chowdhery et al., 2022). Chúng tôi tiếp tục chứng minh mối tương quan giữa kích thước mô hình và hiệu suất trong Hình 3a, so sánh kết quả pass@1 của 10 mô hình đại diện trên điểm chuẩn HumanEval. Rõ ràng là các mô hình lớn hơn thường dẫn đến hiệu suất tốt hơn. Hơn nữa, chúng tôi cũng thấy rằng các mô hình hiện tại, bất kể kích thước, vẫn có tiềm năng cải thiện thông qua việc tăng kích thước thêm nữa. Kết quả bổ sung trên các điểm chuẩn HumanEval và MBPP có thể được tìm thấy trong Phụ lục Hình 7, cũng hỗ trợ kết luận này.

Ngoài ra, chúng tôi tiến hành một thí nghiệm trên điểm chuẩn HumanEval để kiểm tra tỷ lệ lỗi cú pháp của mã được tạo ra bởi các mô hình khác nhau với kích thước khác nhau. Cụ thể, chúng tôi làm cho các mô hình dự đoán 10 mẫu mã cho mỗi bài toán lập trình, sau đó tính toán tỷ lệ phần trăm các mẫu mã có lỗi cú pháp. Như được hiển thị trong Hình 3b, kết quả chỉ ra rằng các mô hình lớn hơn có xu hướng có tỷ lệ lỗi cú pháp thấp hơn. Đáng chú ý là phiên bản lớn nhất của mô hình CodeGen-Mono thể hiện tỷ lệ lỗi cú pháp thấp đáng kể, tức là 6%. Tuy nhiên, như được chứng minh bởi Hình 3a và Bảng 2, mô hình CodeGen-Mono với 16 tỷ tham số vẫn có hiệu suất không thỏa mãn về pass@k, ví dụ, pass@1 là 29%. Điều này nhấn mạnh thực tế rằng hạn chế hiện tại đối với các mô hình được tiền huấn luyện lớn là việc tạo ra mã đúng về mặt ngữ nghĩa.

### 3.2 Dữ liệu Lớn và Cao cấp

Khi kích thước của LLMs tăng lên trong lĩnh vực NL2Code, quy mô của kho ngữ liệu được sử dụng để huấn luyện cũng tăng lên. Điều này nhấn mạnh tầm quan trọng của việc lựa chọn và tiền xử lý dữ liệu chất lượng cao. Trong phần này, chúng tôi sẽ thảo luận về các nguồn dữ liệu và chiến lược tiền xử lý được sử dụng phổ biến khác nhau mà rất cần thiết để huấn luyện LLMs.

Các mô hình ban đầu được huấn luyện bằng cách sử dụng các cặp dữ liệu được chú thích thủ công của NL và mã, và các nguồn dữ liệu bao gồm CodeSearchNet (Husain et al., 2019), CoST (Zhu et al., 2022b), và XL-CoST (Zhu et al., 2022a). Tuy nhiên, chú thích thủ công tốn nhiều lao động và thời gian. Cũng có các mô hình như GPT-3 (Brown et al., 2020), GPT-Neo (Black et al., 2021), và GPT-J (Wang và Komatsuzaki, 2021) được huấn luyện trên Pile (Gao et al., 2020), một tập dữ liệu không giám sát quy mô lớn. Tuy nhiên, các mô hình này chưa chứng minh khả năng tạo mã ngoại lệ do số lượng hạn chế các tệp mã trong kho ngữ liệu huấn luyện. Gần đây hơn, với sự xuất hiện của các LLMs mạnh mẽ hơn cho NL2Code, các tập dữ liệu mã không gán nhãn quy mô lớn hơn đã được đề xuất, bao gồm BigQuery (Google, 2016), kho ngữ liệu của CodeParrot (HuggingFace, 2021a), GitHub-Code (HuggingFace, 2021b), và Stack (HuggingFace, 2022), được thu thập từ các trang web mã nguồn mở miền chung như GitHub và Stack Overflow. Hơn nữa, cũng có các tập dữ liệu chuyên biệt được đề xuất cho các kịch bản khác nhau, ví dụ, sử dụng Jupyter Notebooks hoặc các bài toán lập trình cạnh tranh làm kho ngữ liệu huấn luyện. Các tập dữ liệu được phát hành bao gồm Jupyter (HuggingFace, 2021c), JuICe (Agashe et al., 2019), APPS (Hendrycks et al., 2021), và CodeNet (IBM, 2021).

Để đảm bảo chất lượng của kho ngữ liệu huấn luyện, thông thường các LLMs thực hiện tiền xử lý dữ liệu trên lượng mã đáng kể trong dữ liệu được thu thập. Chúng tôi xem xét cẩn thận các phương pháp tiền xử lý dữ liệu của năm LLMs mạnh mẽ, bao gồm Codex (Chen et al., 2021), AlphaCode (Li et al., 2022b), CodeGen (Nijkamp et al., 2023), InCoder (Fried et al., 2023), và PyCodeGPT (Zan et al., 2022b), và xác định một số điểm chung. Một là việc loại bỏ các tệp mã có khả năng được tự động tạo ra hoặc chưa hoàn thành, vì chúng được coi là vô nghĩa. Ngoài ra, các quy tắc cụ thể được sử dụng để lọc ra các tệp mã không phổ biến. Các quy tắc này bao gồm các yếu tố như xếp hạng sao của kho lưu trữ, kích thước tệp, độ dài dòng và tỷ lệ chữ và số. Tóm lại, mục tiêu của các chiến lược tiền xử lý này là đạt được một kho ngữ liệu mã không trùng lặp, hoàn chỉnh, đúng đắn, sạch sẽ và có tính chất chung.

### 3.3 Điều chỉnh Chuyên gia

Huấn luyện một mô hình xuất sắc đòi hỏi xem xét cẩn thận các lựa chọn thiết kế và siêu tham số khác nhau. Sau khi xem xét 27 LLMs hiện có (tóm tắt trong Phụ lục Bảng 6), chúng tôi có những phát hiện sau. Đầu tiên, các LLMs này chia sẻ một số thiết lập chung. Ví dụ, chúng tôi quan sát thấy rằng bộ tối ưu hóa của các mô hình hiện tại hầu như đều là Adam (Kingma và Ba, 2014) hoặc các biến thể của nó (Loshchilov và Hutter, 2017). Chúng tôi cũng thấy rằng việc khởi tạo với các mô hình ngôn ngữ tự nhiên khác không mang lại lợi ích đáng chú ý so với huấn luyện từ đầu, ngoại trừ việc tăng tốc độ hội tụ (Chen et al., 2021). Hơn nữa, có một số siêu tham số cần điều chỉnh chuyên gia, như tỷ lệ học, kích thước batch, kích thước cửa sổ, các bước khởi động, các bước tích lũy gradient và nhiệt độ lấy mẫu. Đối với tỷ lệ học, chúng tôi phân tích mối tương quan của nó với kích thước mô hình bằng cách sử dụng sáu LLMs mạnh mẽ, như được hiển thị trong Hình 4. Chúng tôi quan sát thấy rằng tỷ lệ học trở nên nhỏ hơn khi mô hình lớn hơn. Để khám phá hiệu ứng của nhiệt độ, trong Hình 5, chúng tôi báo cáo hiệu suất của hai mô hình sử dụng nhiều nhiệt độ trên HumanEval. Một quan sát là nhiệt độ cao hơn dẫn đến pass@1 thấp hơn và pass@100 cao hơn, điều này cho thấy rằng nhiệt độ cao hơn làm cho LLMs tạo ra dự đoán đa dạng hơn và ngược lại. Bên cạnh đó, một số nghiên cứu (erman Arsenovich Arutyunov và Avdoshin, 2022) đã chỉ ra rằng kích thước cửa sổ là một yếu tố chính. Một phát hiện thú vị là mô hình nhỏ với kích thước cửa sổ lớn đôi khi vượt trội hơn mô hình lớn với kích thước cửa sổ nhỏ (chi tiết trong Phụ lục D). Ngoài ra, các LLMs mạnh mẽ thường huấn luyện một tokenizer mới trên kho ngữ liệu mã chủ yếu sử dụng hai kỹ thuật: Byte-level Byte-Pair-Encoding (Radford et al., 2019) và SentencePiece (Kudo và Richardson, 2018). Một tokenizer mới có thể hiệu quả và chính xác hơn trong việc tách nội dung mã thành các token. Các kỹ thuật điều chỉnh đã được chứng minh này sẽ phục vụ như các tài liệu tham khảo có giá trị để huấn luyện các LLMs mạnh mẽ hơn.

## 4 Điểm chuẩn và Số liệu

Để đánh giá nhiệm vụ NL2Code, các điểm chuẩn chất lượng cao và số liệu đáng tin cậy là cơ bản và thiết yếu. Trong phần này, chúng tôi cung cấp một cái nhìn tổng quan ngắn gọn về các điểm chuẩn và số liệu hiện tại, cũng như các quan sát của chúng tôi và các thách thức mở.

Chúng tôi tóm tắt 17 điểm chuẩn NL2Code được nghiên cứu kỹ trong Bảng 3, nơi chúng ta có thể thấy rằng mỗi điểm chuẩn này có đặc tính riêng về kích thước, ngôn ngữ, độ phức tạp và kịch bản. Chúng tôi quan sát thấy rằng hầu hết các điểm chuẩn chứa số lượng hạn chế các thực thể. Ví dụ, HumanEval và MBPP được sử dụng rộng rãi có 164 và 974 thực thể, tương ứng. Điều này là do các điểm chuẩn này thường được viết tay để đảm bảo rằng LLMs chưa thấy chúng trong quá trình huấn luyện. Trong kỷ nguyên của các mô hình ngôn ngữ lớn, việc tránh rò rỉ dữ liệu khi tạo các điểm chuẩn mới là quan trọng. Ngoài ra, hầu hết các điểm chuẩn hiện tại có mô tả bài toán bằng tiếng Anh và giải pháp mã bằng Python. Gần đây, một số điểm chuẩn đa ngôn ngữ đã được đề xuất, như MBXP (Athiwaratkun et al., 2022), HumanEvalX (Zheng et al., 2023), và MultiPL (Cassano et al., 2022), bao phủ nhiều ngôn ngữ lập trình, và ODEX (Wang et al., 2022c), bao phủ nhiều ngôn ngữ tự nhiên. Chi tiết của các điểm chuẩn đa ngôn ngữ được liệt kê trong Phụ lục Bảng 7. Hơn nữa, các điểm chuẩn đã được đề xuất cho các kịch bản thực tế khác, như khoa học dữ liệu (Lai et al., 2022), thư viện công cộng (Zan et al., 2022b), thư viện riêng tư (Zan et al., 2022a), tổng hợp chương trình đa lượt (Nijkamp et al., 2023), và bảo mật mã (Siddiq và msiddiq, 2022). Đối với các điểm chuẩn dựa trên thực thi, các trường hợp thử nghiệm toàn diện với phạm vi bao phủ hoàn chỉnh của chương trình được tạo ra có thể đảm bảo độ tin cậy của kết quả đánh giá. Làm tham khảo, số lượng trung bình các trường hợp thử nghiệm cho mỗi điểm chuẩn, cũng như thống kê độ dài của mô tả bài toán và giải pháp cũng được cung cấp trong Bảng 3.

Việc đánh giá thủ công mã được tạo ra là không thực tế, điều này đòi hỏi nhu cầu về các số liệu tự động. Các điểm chuẩn được đề cập ở trên đều cung cấp các trường hợp thử nghiệm để đánh giá dựa trên thực thi, nơi các số liệu như pass@k (Chen et al., 2021), n@k (Li et al., 2022b), trung bình trường hợp thử nghiệm (Hendrycks et al., 2021), và độ chính xác thực thi (Rajkumar et al., 2022) có thể được sử dụng. Tuy nhiên, cách tiếp cận này có yêu cầu nghiêm ngặt về chất lượng của các trường hợp thử nghiệm và chỉ có thể đánh giá mã có thể thực thi. Đối với mã không thể thực thi, các số liệu như BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), và CodeBLEU (Ren et al., 2020) được sử dụng, trong khi chúng không thể đánh giá chính xác tính đúng đắn của mã. Cho đến nay, có nhiều thách thức mở trong việc thiết kế số liệu để đánh giá các khía cạnh khác nhau của mã, như lỗ hổng, khả năng bảo trì, độ rõ ràng, độ phức tạp thực thi và tính ổn định.

## 5 Thách thức và Cơ hội

Các cuộc điều tra của chúng tôi đã tiết lộ rằng những tiến bộ trong LLMs cho NL2Code có tác động đáng kể đến cả học thuật và công nghiệp. Mặc dù có tiến bộ này, vẫn còn nhiều thách thức cần được giải quyết, mang lại nhiều cơ hội cho nghiên cứu và ứng dụng sâu hơn. Trong phần này, chúng tôi khám phá các thách thức và cơ hội về khoảng cách khả năng giữa LLMs và con người.

**Khả năng Hiểu biết** Tính linh hoạt vốn có của ngôn ngữ tự nhiên cho phép nhiều biểu đạt khác nhau để truyền đạt các yêu cầu chức năng. Con người có thể hiểu các mô tả khác nhau ở các cấp độ trừu tượng khác nhau. Ngược lại, các LLMs hiện tại có xu hướng nhạy cảm với ngữ cảnh được đưa ra, điều này có thể gây ra sự suy giảm hiệu suất không mong muốn (Wang et al., 2022a). Ngoài ra, LLMs có thể gặp khó khăn khi đối mặt với các bài toán phức tạp có nhiều điều kiện và yêu cầu (Barke et al., 2022; Imai, 2022). Chúng tôi tin rằng việc khám phá khả năng hiểu biết của LLMs là một hướng nghiên cứu quan trọng. Một giải pháp tiềm năng là chia nhỏ các bài toán phức tạp thành nhiều bước, như thường được thực hiện trong các nhiệm vụ lý luận (Wei et al., 2022).

**Khả năng Phán đoán** Con người có khả năng xác định liệu họ có thể giải quyết một bài toán lập trình hay không. Trong khi các mô hình hiện tại sẽ luôn trả về một giải pháp ngay cả khi không có câu trả lời cho bài toán, do thực tế là chúng được huấn luyện bằng mục tiêu mô hình hóa ngôn ngữ nhân quả không giám sát. Điều này có thể gây ra vấn đề trong các ứng dụng thực tế. Để cải thiện khả năng phán đoán của LLMs, các nhà nghiên cứu đã sử dụng học tăng cường để tận dụng phản hồi của người dùng, như được thấy trong các mô hình như InstructGPT (Ouyang et al., 2022) và ChatGPT. Tuy nhiên, việc thu thập phản hồi chất lượng cao cho mã là tốn kém và thách thức. Cũng có các nghiên cứu đang tiến hành (Chen et al., 2023; Key et al., 2022) khám phá khả năng tự xác thực cho LLMs, đây cũng là một hướng nghiên cứu đầy hứa hẹn.

**Khả năng Giải thích** Được thừa nhận rộng rãi rằng các nhà phát triển con người sở hữu khả năng diễn giải ý nghĩa của mã họ viết, điều này rất quan trọng cho mục đích giáo dục và bảo trì phần mềm. Các nghiên cứu gần đây cho thấy rằng LLMs có tiềm năng tự động tạo ra các lời giải thích mã. MacNeil et al. (2022a) đề xuất sử dụng LLMs để tạo ra các lời giải thích mã cho sinh viên trong quá trình học của họ, và MacNeil et al. (2022b) đề xuất giải thích nhiều khía cạnh của một đoạn mã được cho sẵn bằng cách sử dụng Copilot. Nghiên cứu và khám phá sâu hơn là cần thiết để hoàn toàn nhận ra tiềm năng của LLMs trong khía cạnh này.

**Khả năng Học thích ứng** Một sự khác biệt cơ bản giữa các mô hình ngôn ngữ lớn hiện tại và con người là khả năng thích ứng với kiến thức mới và được cập nhật. Các nhà phát triển con người sở hữu khả năng độc đáo để nhanh chóng tìm kiếm và học các tài liệu mới, như tài liệu lập trình, và thích ứng với các thay đổi trong APIs với sự dễ dàng tương đối. Tuy nhiên, việc huấn luyện lại hoặc điều chỉnh tinh LLMs đòi hỏi nỗ lực và tài nguyên đáng kể. Vấn đề này đã truyền cảm hứng cho một số nghiên cứu gần đây, như DocCoder (Zhou et al., 2023) và APICoder (Zan et al., 2022a), sử dụng các phương pháp dựa trên truy xuất để cung cấp kiến thức bổ sung hoặc được cập nhật trong quá trình suy luận mô hình. Mặc dù có những tiến bộ này, việc trao cho LLMs khả năng học mạnh mẽ mà con người sở hữu vẫn là một thách thức mở.

**Khả năng Đa nhiệm** Các mô hình ngôn ngữ lớn đã được áp dụng cho nhiều nhiệm vụ liên quan đến mã, như sửa chữa mã (Joshi et al., 2022; Prenner và Robbes, 2021), tìm kiếm mã (Neelakantan et al., 2022), và xem xét mã (Li et al., 2022c) cũng như các nhiệm vụ không phải mã có thể được định dạng theo cách giống mã, như toán học (Drori và Verma, 2021; Drori et al., 2021) và hóa học (Krenn et al., 2022; Hocky và White, 2022). Tuy nhiên, có sự khác biệt giữa LLMs và khả năng của con người về đa nhiệm. Con người có thể chuyển đổi liền mạch giữa các nhiệm vụ, trong khi LLMs có thể yêu cầu kỹ thuật prompt phức tạp (Liu et al., 2023). Một bằng chứng khác là LLMs thiếu khả năng nhanh chóng thành thạo nhiều ngôn ngữ lập trình (Zheng et al., 2023) như con người. Những hạn chế này làm nổi bật các lĩnh vực cho nghiên cứu tương lai.

## 6 Kết luận

Trong bài báo này, chúng tôi khảo sát 27 mô hình ngôn ngữ lớn hiện có cho NL2Code, và đưa ra một phân tích kỹ lưỡng về các lý do cơ bản cho thành công của chúng. Chúng tôi cũng cung cấp một đánh giá chi tiết về các điểm chuẩn và số liệu. Liên quan đến khoảng cách giữa mô hình và con người, chúng tôi trình bày các thách thức và cơ hội đang diễn ra. Ngoài ra, chúng tôi đã phát triển một trang web để theo dõi những phát hiện mới nhất trong lĩnh vực này. Chúng tôi hy vọng khảo sát này có thể đóng góp vào một cái nhìn tổng quan toàn diện về lĩnh vực và thúc đẩy sự phát triển thịnh vượng của nó.

## Hạn chế

Trong bài báo này, chúng tôi điều tra kỹ lưỡng các mô hình ngôn ngữ lớn hiện có cho NL2Code, và tóm tắt chúng từ các góc độ đa dạng với suy nghĩ riêng của chúng tôi. Tuy nhiên, vì lĩnh vực này đang phát triển rất nhanh, có thể có những khía cạnh mà chúng tôi đã bỏ qua, hoặc một số công trình mới mà chúng tôi chưa đề cập. Để giảm thiểu vấn đề này, chúng tôi đã tạo ra một trang web để theo dõi tiến độ mới nhất thông qua crowdsourcing, hy vọng rằng nó sẽ liên tục đóng góp vào sự phát triển của lĩnh vực. Bên cạnh đó, các LLMs hiện có sở hữu đặc tính riêng về kích thước mô hình, kiến trúc, kho ngữ liệu, tiền xử lý, tokenizer, siêu tham số và nền tảng huấn luyện. Ngoài ra, một số trong số chúng hiện tại không có sẵn công khai, như AlphaCode (Li et al., 2022b) và PaLM-Coder (Chowdhery et al., 2022). Do đó, việc tiến hành một so sánh hoàn toàn công bằng là gần như không thực tế. Chúng tôi đã cố gắng hết sức để cho thấy một loại so sánh trên các điểm chuẩn HumanEval và MBPP phổ biến, hy vọng rằng nó có thể cung cấp manh mối về sự khác biệt trong hiệu suất của các LLMs khác nhau. Ngoài ra, việc đánh giá LLMs có chi phí cao về tài nguyên tính toán. Do đó chúng tôi đã làm cho tất cả các tệp được tạo ra bởi LLMs có sẵn công khai trên https://nl2code.github.io.

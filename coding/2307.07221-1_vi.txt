# Kiểm thử phần mềm với các mô hình ngôn ngữ lớn:
Khảo sát, Bối cảnh và Tầm nhìn
Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang

Tóm tắt —Các mô hình ngôn ngữ lớn được đào tạo trước (LLM) gần đây đã nổi lên như một công nghệ đột phá trong xử lý ngôn ngữ tự nhiên và trí tuệ nhân tạo, với khả năng xử lý các tập dữ liệu quy mô lớn và thể hiện hiệu suất đáng kể trên nhiều loại tác vụ khác nhau. Trong khi đó, kiểm thử phần mềm là một hoạt động quan trọng đóng vai trò như nền tảng để đảm bảo chất lượng và độ tin cậy của các sản phẩm phần mềm. Khi phạm vi và độ phức tạp của các hệ thống phần mềm tiếp tục tăng lên, nhu cầu về các kỹ thuật kiểm thử phần mềm hiệu quả hơn trở nên ngày càng cấp thiết, khiến đây trở thành một lĩnh vực chín muồi cho các cách tiếp cận sáng tạo như việc sử dụng LLM. Bài báo này cung cấp một đánh giá toàn diện về việc sử dụng LLM trong kiểm thử phần mềm. Nó phân tích 102 nghiên cứu liên quan đã sử dụng LLM cho kiểm thử phần mềm, từ cả góc độ kiểm thử phần mềm và LLM. Bài báo trình bày một thảo luận chi tiết về các tác vụ kiểm thử phần mềm mà LLM thường được sử dụng, trong đó chuẩn bị test case và sửa lỗi chương trình là những tác vụ đại diện nhất. Nó cũng phân tích các LLM thường được sử dụng, các loại kỹ thuật prompt engineering được áp dụng, cũng như các kỹ thuật đi kèm với những LLM này. Nó cũng tóm tắt các thách thức chính và cơ hội tiềm năng trong hướng này. Công trình này có thể phục vụ như một lộ trình cho nghiên cứu tương lai trong lĩnh vực này, làm nổi bật các hướng tiềm năng để khám phá, và xác định những khoảng trống trong hiểu biết hiện tại của chúng ta về việc sử dụng LLM trong kiểm thử phần mềm.

Từ khóa chỉ mục —Mô hình ngôn ngữ lớn được đào tạo trước, Kiểm thử phần mềm, LLM, GPT

1 GIỚI THIỆU

Kiểm thử phần mềm là một hoạt động quan trọng đóng vai trò như nền tảng để đảm bảo chất lượng và độ tin cậy của các sản phẩm phần mềm. Nếu không có quy trình kiểm thử phần mềm nghiêm ngặt, các doanh nghiệp phần mềm sẽ miễn cưỡng phát hành sản phẩm của họ ra thị trường, biết rõ hậu quả tiềm tàng của việc cung cấp phần mềm có lỗi cho người dùng cuối. Bằng cách thực hiện các quy trình kiểm thử kỹ lưỡng và tỉ mỉ, các doanh nghiệp phần mềm có thể giảm thiểu sự xuất hiện của các lỗi phần mềm nghiêm trọng, vấn đề về khả năng sử dụng, hoặc vi phạm bảo mật có thể dẫn đến tổn thất tài chính hoặc làm tổn hại niềm tin của người dùng. Ngoài ra, kiểm thử phần mềm giúp giảm chi phí bảo trì bằng cách xác định và giải quyết các vấn đề sớm trong vòng đời phát triển, ngăn chặn những phức tạp lớn hơn về sau.

Tầm quan trọng của kiểm thử phần mềm đã thu hút sự chú ý đáng kể trong cộng đồng nghiên cứu và công nghiệp. Trong lĩnh vực kỹ nghệ phần mềm, nó đứng vững như một lĩnh vực nghiên cứu vô cùng phổ biến và sôi động. Có thể quan sát thấy tầm quan trọng không thể phủ nhận của kiểm thử phần mềm bằng cách đơn giản là xem xét bối cảnh của các hội nghị và hội thảo tập trung vào kỹ nghệ phần mềm. Trong số các sự kiện này, các chủ đề liên quan đến kiểm thử phần mềm liên tục chiếm ưu thế về số lượng bài nộp và thường xuyên được chọn để xuất bản.

Mặc dù lĩnh vực kiểm thử phần mềm đã đạt được sự phổ biến đáng kể, vẫn còn hàng chục thách thức chưa được giải quyết hiệu quả. Ví dụ, một thách thức như vậy là tạo test case đơn vị tự động. Mặc dù có nhiều cách tiếp cận khác nhau, bao gồm các kỹ thuật dựa trên tìm kiếm, dựa trên ràng buộc hoặc dựa trên ngẫu nhiên để tạo ra một bộ unit test, độ bao phủ và tính có ý nghĩa của các test được tạo ra vẫn còn xa mới đạt mức thỏa đáng. Tương tự, khi đến với kiểm thử GUI di động, các nghiên cứu hiện tại với các phương pháp dựa trên ngẫu nhiên/quy tắc, phương pháp dựa trên mô hình, và phương pháp dựa trên học máy không thể hiểu thông tin ngữ nghĩa của trang GUI và thường không đạt được độ bao phủ toàn diện. Xem xét những hạn chế này, nhiều nỗ lực nghiên cứu hiện đang được tiến hành để khám phá các kỹ thuật sáng tạo có thể nâng cao hiệu quả của các tác vụ kiểm thử phần mềm, trong đó các mô hình ngôn ngữ lớn là những kỹ thuật đầy hứa hẹn nhất.

Các mô hình ngôn ngữ lớn (LLM) như T5 và GPT-3 đã cách mạng hóa lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) và trí tuệ nhân tạo (AI). Những mô hình này, ban đầu được đào tạo trước trên các kho ngữ liệu rộng lớn, đã thể hiện hiệu suất đáng kể trên nhiều tác vụ NLP bao gồm hỏi đáp, dịch máy, và tạo văn bản. Trong những năm gần đây, đã có sự tiến bộ đáng kể trong LLM với sự xuất hiện của các mô hình có khả năng xử lý thậm chí các tập dữ liệu quy mô lớn hơn. Sự mở rộng về kích thước mô hình này không chỉ dẫn đến hiệu suất được cải thiện mà còn mở ra những khả năng mới để áp dụng LLM như Trí tuệ Nhân tạo Tổng quát. Trong số những LLM tiên tiến này, các mô hình như ChatGPT và LLaMA có hàng tỷ tham số. Những mô hình như vậy có tiềm năng to lớn để giải quyết các tác vụ thực tế phức tạp trong các lĩnh vực như tạo mã và sáng tạo nghệ thuật. Với khả năng mở rộng và năng lực nâng cao, LLM đã trở thành những yếu tố thay đổi cuộc chơi trong NLP và AI, và đang thúc đẩy những tiến bộ trong các lĩnh vực khác như lập trình và kiểm thử phần mềm.

LLM đã được sử dụng cho nhiều tác vụ liên quan đến lập trình bao gồm tạo mã và đề xuất mã. Một mặt, trong kiểm thử phần mềm, có nhiều tác vụ liên quan đến tạo mã, chẳng hạn như tạo unit test, nơi việc sử dụng LLM được kỳ vọng sẽ mang lại hiệu suất tốt. Mặt khác, kiểm thử phần mềm có những đặc điểm độc đáo phân biệt nó với tạo mã. Ví dụ, tạo mã chủ yếu tập trung vào việc tạo ra một đoạn mã đúng duy nhất, trong khi kiểm thử phần mềm thường yêu cầu tạo ra các đầu vào test đa dạng để đảm bảo độ bao phủ tốt hơn của phần mềm được kiểm thử. Sự tồn tại của những khác biệt này đưa ra những thách thức và cơ hội mới khi sử dụng LLM cho kiểm thử phần mềm. Hơn nữa, mọi người đã được hưởng lợi từ hiệu suất xuất sắc của LLM trong các tác vụ tạo sinh và suy luận, dẫn đến sự xuất hiện của hàng chục thực hành mới sử dụng LLM cho kiểm thử phần mềm.

Bài báo này trình bày một đánh giá toàn diện về việc sử dụng LLM trong kiểm thử phần mềm. Chúng tôi thu thập 102 bài báo liên quan và tiến hành phân tích kỹ lưỡng từ cả góc độ kiểm thử phần mềm và LLM, như được tóm tắt đại khái trong Hình 1.

Từ quan điểm kiểm thử phần mềm, phân tích của chúng tôi bao gồm việc kiểm tra các tác vụ kiểm thử phần mềm cụ thể mà LLM được sử dụng. Kết quả cho thấy LLM thường được sử dụng cho chuẩn bị test case (bao gồm tạo unit test case, tạo test oracle, và tạo đầu vào test hệ thống), gỡ lỗi chương trình, và sửa lỗi, trong khi chúng tôi không tìm thấy các thực hành áp dụng LLM trong các tác vụ của vòng đời kiểm thử sớm (như yêu cầu test, kế hoạch test, v.v.). Đối với mỗi tác vụ test, chúng tôi sẽ cung cấp các minh họa chi tiết trình bày việc sử dụng LLM trong việc giải quyết tác vụ, làm nổi bật các thực hành thường được sử dụng, theo dõi xu hướng tiến hóa công nghệ, và tóm tắt hiệu suất đạt được, nhằm tạo điều kiện cho người đọc hiểu toàn diện về cách LLM được sử dụng trong các tác vụ kiểm thử khác nhau.

Từ quan điểm LLM, phân tích của chúng tôi bao gồm các LLM thường được sử dụng trong những nghiên cứu này, các loại kỹ thuật prompt engineering, đầu vào của LLM, cũng như các kỹ thuật đi kèm với những LLM này. Kết quả cho thấy khoảng một phần ba các nghiên cứu sử dụng LLM thông qua lược đồ đào tạo trước hoặc fine-tuning, trong khi những nghiên cứu khác sử dụng kỹ thuật prompt engineering để giao tiếp với LLM nhằm điều hướng hành vi của chúng để đạt được kết quả mong muốn. Đối với prompt engineering, các chiến lược zero-shot learning và few-shot learning được sử dụng phổ biến nhất, trong khi các tiến bộ khác như chain-of-thought promoting và self-consistency hiếm khi được sử dụng. Kết quả cũng cho thấy các kỹ thuật kiểm thử truyền thống như differential testing và mutation testing thường được kết hợp với LLM để giúp tạo ra các test đa dạng hơn.

Hơn nữa, chúng tôi tóm tắt các thách thức chính và cơ hội tiềm năng trong hướng này. Mặc dù kiểm thử phần mềm với LLM đã trải qua sự tăng trưởng đáng kể trong hai năm qua, vẫn còn những thách thức trong việc đạt được độ bao phủ cao của kiểm thử, vấn đề test oracle, đánh giá nghiêm ngặt, và ứng dụng thực tế của LLM trong kiểm thử phần mềm. Vì đây là một lĩnh vực mới nổi, có nhiều cơ hội nghiên cứu, bao gồm khám phá LLM trong giai đoạn đầu của kiểm thử, khám phá LLM cho nhiều loại phần mềm hơn và kiểm thử phi chức năng, khám phá kỹ thuật prompt engineering tiên tiến, cũng như kết hợp LLM với các kỹ thuật truyền thống.

Bài báo này đóng góp những điều sau:
• Chúng tôi phân tích kỹ lưỡng 102 nghiên cứu liên quan đã sử dụng LLM cho kiểm thử phần mềm, về xu hướng xuất bản, phân bố của các địa điểm xuất bản, v.v.
• Chúng tôi tiến hành phân tích toàn diện từ góc độ kiểm thử phần mềm để hiểu phân bố các tác vụ kiểm thử phần mềm với LLM và trình bày thảo luận kỹ lưỡng về cách những tác vụ này được giải quyết với LLM.
• Chúng tôi tiến hành phân tích toàn diện từ góc độ LLM, và khám phá các LLM thường được sử dụng, các loại kỹ thuật prompt engineering, đầu vào của LLM, cũng như các kỹ thuật đi kèm với những LLM này.
• Chúng tôi làm nổi bật những thách thức trong các nghiên cứu hiện tại và trình bày những cơ hội tiềm năng cho các nghiên cứu sâu hơn.

Chúng tôi tin rằng công trình này sẽ có giá trị đối với cả các nhà nghiên cứu và người thực hành trong lĩnh vực kỹ nghệ phần mềm, vì nó cung cấp một cái nhìn tổng quan toàn diện về tình trạng hiện tại và tầm nhìn tương lai của việc sử dụng LLM cho kiểm thử phần mềm. Đối với các nhà nghiên cứu, công trình này có thể phục vụ như một lộ trình cho nghiên cứu tương lai trong lĩnh vực này, làm nổi bật các hướng tiềm năng để khám phá và xác định những khoảng trống trong hiểu biết hiện tại của chúng ta về việc sử dụng LLM trong kiểm thử phần mềm. Đối với những người thực hành, công trình này có thể cung cấp cái nhìn sâu sắc về lợi ích tiềm năng và hạn chế của việc sử dụng LLM cho kiểm thử phần mềm, cũng như hướng dẫn thực tế về cách tích hợp hiệu quả chúng vào các quy trình kiểm thử hiện có. Bằng cách cung cấp một bối cảnh chi tiết về tình trạng hiện tại và tầm nhìn tương lai của việc sử dụng LLM cho kiểm thử phần mềm, công trình này có thể giúp tăng tốc việc áp dụng công nghệ này trong cộng đồng kỹ nghệ phần mềm và cuối cùng góp phần cải thiện chất lượng và độ tin cậy của các hệ thống phần mềm.

2 BỐI CẢNH

2.1 Mô hình Ngôn ngữ Lớn (LLM)

Gần đây, các mô hình ngôn ngữ được đào tạo trước (PLM) đã được đề xuất bằng cách đào tạo trước các mô hình dựa trên Transformer trên các kho ngữ liệu quy mô lớn, thể hiện khả năng mạnh mẽ trong việc giải quyết các tác vụ xử lý ngôn ngữ tự nhiên (NLP) khác nhau. Các nghiên cứu đã chỉ ra rằng việc mở rộng mô hình có thể dẫn đến cải thiện khả năng mô hình, thúc đẩy các nhà nghiên cứu điều tra hiệu ứng mở rộng thông qua việc tăng thêm kích thước tham số. Thú vị là, khi quy mô tham số vượt quá một ngưỡng nhất định, những mô hình ngôn ngữ lớn hơn này không chỉ thể hiện những cải thiện hiệu suất đáng kể mà còn có những khả năng đặc biệt như in-context learning, mà những mô hình nhỏ hơn như BERT không có.

Để phân biệt các mô hình ngôn ngữ ở các quy mô tham số khác nhau, cộng đồng nghiên cứu đã đặt ra thuật ngữ mô hình ngôn ngữ lớn (LLM) cho các PLM có kích thước đáng kể. LLM thường đề cập đến các mô hình ngôn ngữ có hàng trăm tỷ (hoặc nhiều hơn) tham số và được đào tạo trên dữ liệu văn bản khổng lồ như GPT-3, PaLM, Codex, và LLaMA. LLM được xây dựng bằng kiến trúc Transformer, xếp chồng các lớp attention đa đầu trong một mạng neural rất sâu. Các LLM hiện tại áp dụng kiến trúc mô hình tương tự (Transformer) và mục tiêu đào tạo trước (language modeling) như các mô hình ngôn ngữ nhỏ, nhưng phần lớn mở rộng kích thước mô hình, dữ liệu đào tạo trước, và tổng sức mạnh tính toán. Điều này cho phép LLM hiểu ngôn ngữ tự nhiên tốt hơn và tạo ra văn bản chất lượng cao dựa trên ngữ cảnh hoặc prompt đã cho.

Lưu ý rằng, trong tài liệu hiện tại, không có sự đồng thuận chính thức về quy mô tham số tối thiểu cho LLM, vì khả năng mô hình cũng liên quan đến kích thước dữ liệu và tổng sức mạnh tính toán. Trong một khảo sát gần đây về LLM, các tác giả tập trung thảo luận về các mô hình ngôn ngữ có kích thước mô hình lớn hơn 10B. Theo tiêu chí của họ, LLM đầu tiên là T5 được phát hành bởi Google vào năm 2019, tiếp theo là GPT-3 được phát hành bởi OpenAI vào năm 2020, và có hơn ba mươi LLM được phát hành giữa năm 2021 và 2023 cho thấy tính phổ biến của nó. Trong một khảo sát khác về việc thống nhất LLM và đồ thị tri thức, các tác giả phân loại LLM thành ba loại: kiến trúc mạng chỉ encoder (ví dụ: BERT), encoder-decoder (ví dụ: T5), và chỉ decoder (ví dụ: GPT-3). Trong đánh giá của chúng tôi, chúng tôi tính đến tiêu chí phân loại của hai khảo sát và chỉ xem xét kiến trúc mạng encoder-decoder và chỉ decoder của các mô hình ngôn ngữ đào tạo trước, vì cả hai đều có thể hỗ trợ các tác vụ tạo sinh. Chúng tôi không xem xét kiến trúc mạng chỉ encoder vì chúng không thể xử lý các tác vụ tạo sinh, được đề xuất tương đối sớm (ví dụ: BERT vào năm 2018), và hầu như không có mô hình nào sử dụng kiến trúc này sau năm 2021. Nói cách khác, các LLM được thảo luận trong bài báo này không chỉ bao gồm các mô hình có tham số trên 10B (như đã đề cập trong) mà còn bao gồm các mô hình khác sử dụng kiến trúc mạng encoder-decoder và chỉ decoder (như đã đề cập trong), chẳng hạn như BART với 140M tham số và GPT-2 với kích thước tham số từ 117M đến 1,5B. Điều này cũng nhằm có thể bao gồm nhiều nghiên cứu hơn để thể hiện bối cảnh của chủ đề này.

2.2 Kiểm thử Phần mềm

Kiểm thử phần mềm là một quy trình quan trọng trong phát triển phần mềm bao gồm việc đánh giá chất lượng của một sản phẩm phần mềm. Mục tiêu chính của kiểm thử phần mềm là xác định các khuyết tật hoặc lỗi trong hệ thống phần mềm có thể dẫn đến hành vi không đúng hoặc không mong muốn. Toàn bộ vòng đời của kiểm thử phần mềm thường bao gồm các tác vụ sau (được thể hiện trong Hình 4):

• Phân tích Yêu cầu: phân tích các yêu cầu phần mềm và xác định mục tiêu kiểm thử, phạm vi, và tiêu chí.
• Kế hoạch Kiểm thử: phát triển kế hoạch kiểm thử nêu ra chiến lược kiểm thử, mục tiêu kiểm thử, và lịch trình.
• Thiết kế và Đánh giá Kiểm thử: phát triển và đánh giá các test case và bộ test phù hợp với kế hoạch kiểm thử và các yêu cầu của ứng dụng phần mềm.
• Chuẩn bị Test Case: các test case thực tế được chuẩn bị dựa trên các thiết kế được tạo trong giai đoạn trước.
• Thực thi Kiểm thử: thực hiện các test được thiết kế trong giai đoạn trước. Hệ thống phần mềm được thực thi với các test case và kết quả được ghi lại.
• Báo cáo Kiểm thử: phân tích kết quả của các test và tạo báo cáo tóm tắt quy trình kiểm thử và xác định bất kỳ khuyết tật hoặc vấn đề nào được phát hiện.
• Sửa lỗi và Kiểm thử Hồi quy: các khuyết tật hoặc vấn đề được xác định trong quá trình kiểm thử được báo cáo cho nhóm phát triển để sửa chữa. Khi các khuyết tật được sửa chữa, kiểm thử hồi quy được thực hiện để đảm bảo rằng các thay đổi không tạo ra khuyết tật hoặc vấn đề mới.
• Phát hành Phần mềm: khi hệ thống phần mềm đã vượt qua tất cả các giai đoạn kiểm thử và các khuyết tật đã được sửa chữa, phần mềm có thể được phát hành cho khách hàng hoặc người dùng cuối.

Quy trình kiểm thử là lặp lại và có thể bao gồm nhiều chu kỳ của các giai đoạn trên, tùy thuộc vào độ phức tạp của hệ thống phần mềm và các yêu cầu kiểm thử.

Trong giai đoạn kiểm thử, nhiều loại test khác nhau có thể được thực hiện, bao gồm unit test, integration test, system test, và acceptance test.

• Unit Testing bao gồm kiểm thử các đơn vị hoặc thành phần riêng lẻ của ứng dụng phần mềm để đảm bảo rằng chúng hoạt động đúng.
• Integration Testing bao gồm kiểm thử các mô-đun hoặc thành phần khác nhau của ứng dụng phần mềm cùng nhau để đảm bảo rằng chúng hoạt động đúng như một hệ thống.
• System Testing bao gồm kiểm thử toàn bộ hệ thống phần mềm như một tổng thể, bao gồm tất cả các thành phần tích hợp và các phụ thuộc bên ngoài.
• Acceptance Testing bao gồm kiểm thử ứng dụng phần mềm để đảm bảo rằng nó đáp ứng các yêu cầu kinh doanh và sẵn sàng để triển khai.

Ngoài ra, có thể có kiểm thử chức năng, kiểm thử hiệu suất, unit testing, kiểm thử bảo mật, kiểm thử khả năng tiếp cận, v.v., khám phá các khía cạnh khác nhau của phần mềm được kiểm thử.

3 LỰA CHỌN BÀI BÁO VÀ LƯỢC ĐỒ ĐÁNH GIÁ

3.1 Phương pháp Thu thập Bài báo

Hình 2 cho thấy quy trình tìm kiếm và lựa chọn bài báo của chúng tôi. Để thu thập càng nhiều tài liệu liên quan càng tốt, chúng tôi sử dụng cả tìm kiếm tự động (từ cơ sở dữ liệu kho bài báo) và tìm kiếm thủ công (từ các địa điểm kỹ nghệ phần mềm và trí tuệ nhân tạo chính). Chúng tôi tìm kiếm các bài báo từ tháng 1 năm 2019 đến tháng 6 năm 2023 và tiếp tục tiến hành vòng tìm kiếm thứ hai để bao gồm các bài báo từ tháng 7 năm 2023 đến tháng 10 năm 2023.

3.1.1 Tìm kiếm Tự động

Để đảm bảo rằng chúng tôi thu thập các bài báo từ các lĩnh vực nghiên cứu đa dạng, chúng tôi tiến hành tìm kiếm mở rộng sử dụng bốn cơ sở dữ liệu khoa học phổ biến: thư viện kỹ thuật số ACM, thư viện kỹ thuật số IEEE Xplore, arXiv, và DBLP.

Chúng tôi tìm kiếm các bài báo có tiêu đề chứa từ khóa liên quan đến các tác vụ kiểm thử phần mềm và kỹ thuật kiểm thử (như được hiển thị bên dưới) trong ba cơ sở dữ liệu đầu tiên. Trong trường hợp DBLP, chúng tôi sử dụng thêm từ khóa liên quan đến LLM (như được hiển thị bên dưới) để lọc ra các nghiên cứu không liên quan, vì chỉ dựa vào từ khóa liên quan đến kiểm thử sẽ dẫn đến một số lượng lớn các nghiên cứu ứng viên. Mặc dù việc sử dụng hai bộ từ khóa cho DBLP có thể dẫn đến việc bỏ sót một số nghiên cứu liên quan, chúng tôi tin rằng đây vẫn là một chiến lược khả thi. Điều này là do một số lượng đáng kể các nghiên cứu có trong cơ sở dữ liệu này đã có thể được tìm thấy trong ba cơ sở dữ liệu đầu tiên, và cơ sở dữ liệu thứ tư chỉ phục vụ như một nguồn bổ sung để thu thập thêm các bài báo.

• Từ khóa liên quan đến các tác vụ và kỹ thuật kiểm thử phần mềm: test OR bug OR issue OR defect OR fault OR error OR failure OR crash OR debug OR debugger OR repair OR fix OR assert OR verification OR validation OR fuzz OR fuzzer OR mutation.
• Từ khóa liên quan đến LLM: LLM OR language model OR generative model OR large model OR GPT-3 OR ChatGPT OR GPT-4 OR LLaMA OR PaLM2 OR CodeT5 OR CodeX OR CodeGen OR Bard OR InstructGPT. Lưu ý rằng, chúng tôi chỉ liệt kê mười LLM phổ biến nhất (dựa trên tìm kiếm Google), vì chúng là từ khóa tìm kiếm để khớp tiêu đề bài báo, thay vì khớp nội dung bài báo.

Chiến lược tìm kiếm trên dựa trên tiêu đề bài báo có thể thu hồi một số lượng lớn bài báo, và chúng tôi tiếp tục tiến hành lọc tự động dựa trên nội dung bài báo. Cụ thể, chúng tôi lọc các bài báo có nội dung chứa "LLM" hoặc "language model" hoặc "generative model" hoặc "large model" hoặc tên của các LLM (sử dụng các LLM trong ngoại trừ những cái trong tiêu chí loại trừ của chúng tôi). Điều này có thể giúp loại bỏ các bài báo không liên quan đến các mô hình neural.

3.1.2 Tìm kiếm Thủ công

Để bù đắp cho những thiếu sót tiềm tàng có thể xuất phát từ tìm kiếm tự động, chúng tôi cũng tiến hành tìm kiếm thủ công. Để đảm bảo rằng chúng tôi thu thập các bài báo có liên quan cao, chúng tôi tiến hành tìm kiếm thủ công trong các kỷ yếu hội nghị và bài báo tạp chí từ các địa điểm kỹ nghệ phần mềm hàng đầu (được liệt kê trong Bảng 2).

Ngoài ra, do tính chất liên ngành của công trình này, chúng tôi cũng bao gồm các kỷ yếu hội nghị của lĩnh vực trí tuệ nhân tạo. Chúng tôi chọn mười địa điểm hàng đầu dựa trên chỉ số h5 từ Google Scholar, và loại trừ ba địa điểm thị giác máy tính, tức là CVPR, ICCV, ECCV, như được liệt kê trong Bảng 2.

3.1.3 Tiêu chí Bao gồm và Loại trừ

Việc tìm kiếm được tiến hành trên các cơ sở dữ liệu và địa điểm, theo thiết kế, rất bao trùm. Điều này cho phép chúng tôi thu thập càng nhiều bài báo càng tốt trong nhóm của mình. Tuy nhiên, tính bao trùm hào phóng này dẫn đến việc có các bài báo không liên quan trực tiếp đến phạm vi của khảo sát này. Theo đó, chúng tôi xác định một bộ tiêu chí bao gồm và loại trừ cụ thể và sau đó áp dụng chúng cho từng bài báo trong nhóm và loại bỏ các bài báo không đáp ứng tiêu chí. Điều này đảm bảo rằng mỗi bài báo được thu thập phù hợp với phạm vi và câu hỏi nghiên cứu của chúng tôi.

Tiêu chí Bao gồm. Chúng tôi xác định các tiêu chí sau để bao gồm các bài báo:
• Bài báo đề xuất hoặc cải thiện một cách tiếp cận, nghiên cứu, hoặc công cụ/khung nhắm đến kiểm thử phần mềm hoặc hệ thống cụ thể với LLM.
• Bài báo áp dụng LLM vào thực hành kiểm thử phần mềm, bao gồm tất cả các tác vụ trong vòng đời kiểm thử phần mềm như được thể hiện trong Phần 2.2.
• Bài báo trình bày một nghiên cứu thực nghiệm hoặc thử nghiệm về việc sử dụng LLM trong thực hành kiểm thử phần mềm.
• Bài báo liên quan đến các kỹ thuật kiểm thử cụ thể (ví dụ: fuzz testing) sử dụng LLM.

Nếu một bài báo thỏa mãn bất kỳ tiêu chí nào sau đây, chúng tôi sẽ bao gồm nó.

Tiêu chí Loại trừ. Các nghiên cứu sau sẽ bị loại trừ trong quá trình lựa chọn nghiên cứu:
• Bài báo không liên quan đến các tác vụ kiểm thử phần mềm, ví dụ: tạo comment mã.
• Bài báo không sử dụng LLM, ví dụ: sử dụng mạng neural hồi quy.
• Bài báo chỉ đề cập đến LLM trong công việc tương lai hoặc thảo luận thay vì sử dụng LLM trong cách tiếp cận.
• Bài báo sử dụng các mô hình ngôn ngữ với kiến trúc chỉ encoder, ví dụ: BERT, không thể được sử dụng trực tiếp cho các tác vụ tạo sinh (như được thể hiện trong Phần 2.1).
• Bài báo tập trung vào kiểm thử hiệu suất của LLM, chẳng hạn như công bằng, ổn định, bảo mật, v.v.
• Bài báo tập trung vào đánh giá hiệu suất của các công cụ hỗ trợ LLM, ví dụ: đánh giá chất lượng mã của công cụ tạo mã Copilot.

Đối với các bài báo được thu thập thông qua tìm kiếm tự động và tìm kiếm thủ công, chúng tôi tiến hành kiểm tra thủ công để xem liệu chúng có thỏa mãn tiêu chí bao gồm của chúng tôi hay không và lọc những cái theo tiêu chí loại trừ của chúng tôi. Cụ thể, hai tác giả đầu đọc từng bài báo để cẩn thận xác định liệu nó có nên được bao gồm dựa trên tiêu chí bao gồm và tiêu chí loại trừ hay không, và bất kỳ bài báo nào có quyết định khác nhau sẽ được chuyển cho tác giả thứ ba để đưa ra quyết định cuối cùng.

3.1.4 Đánh giá Chất lượng

Ngoài ra, chúng tôi thiết lập tiêu chí đánh giá chất lượng để loại trừ các nghiên cứu chất lượng thấp như được hiển thị bên dưới. Đối với mỗi câu hỏi, chất lượng của nghiên cứu được đánh giá là "có", "một phần" hoặc "không" được gán giá trị lần lượt là 1, 0,5 và 0. Các bài báo có điểm số dưới tám sẽ bị loại trừ khỏi nghiên cứu của chúng tôi.

• Có một mục tiêu nghiên cứu được nêu rõ ràng liên quan đến kiểm thử phần mềm không?
• Có một kỹ thuật được xác định và có thể lặp lại không?
• Có đóng góp rõ ràng nào cho kiểm thử phần mềm không?
• Có mô tả rõ ràng về LLM nào được sử dụng không?
• Có giải thích rõ ràng về cách LLM được sử dụng không?
• Có phương pháp rõ ràng để xác thực kỹ thuật không?
• Các dự án chủ đề được chọn để xác thực có phù hợp với mục tiêu nghiên cứu không?
• Có các kỹ thuật kiểm soát hoặc đường cơ sở để chứng minh hiệu quả của kỹ thuật được đề xuất không?
• Các thước đo đánh giá có liên quan (ví dụ: đánh giá hiệu quả của kỹ thuật được đề xuất) đến mục tiêu nghiên cứu không?
• Các kết quả được trình bày trong nghiên cứu có phù hợp với mục tiêu nghiên cứu và được trình bày một cách rõ ràng và liên quan không?

3.1.5 Snowballing

Cuối quá trình tìm kiếm kho cơ sở dữ liệu và kỷ yếu và tạp chí hội nghị, và áp dụng tiêu chí bao gồm/loại trừ và đánh giá chất lượng, chúng tôi có được bộ bài báo ban đầu. Tiếp theo, để giảm thiểu rủi ro bỏ sót tài liệu liên quan từ khảo sát này, chúng tôi cũng thực hiện snowballing ngược bằng cách kiểm tra các tài liệu tham khảo được trích dẫn bởi các bài báo đã thu thập cho đến nay. Lưu ý rằng, quy trình này không bao gồm các nghiên cứu mới, có thể là do chủ đề được khảo sát khá mới và các nghiên cứu tham khảo có xu hướng được xuất bản trước đó, và chúng tôi đã bao gồm một tìm kiếm tự động và thủ công tương đối toàn diện.

3.2 Kết quả Thu thập

Như được hiển thị trong Hình 2, quá trình thu thập bắt đầu với tổng cộng 14.623 bài báo được truy xuất từ bốn cơ sở dữ liệu học thuật sử dụng tìm kiếm từ khóa. Sau đó, sau khi lọc tự động, tìm kiếm thủ công, áp dụng tiêu chí bao gồm/loại trừ, và đánh giá chất lượng, cuối cùng chúng tôi đã thu thập tổng cộng 102 bài báo liên quan đến kiểm thử phần mềm với LLM. Bảng 1 cho thấy chi tiết của các bài báo được thu thập. Bên cạnh đó, chúng tôi cũng sử dụng Bảng 5 (ở cuối bài báo) để cung cấp một cái nhìn tổng quan toàn diện hơn về những bài báo này về các đặc điểm cụ thể sẽ được minh họa trong Phần 4 và Phần 5.

Lưu ý rằng, có hai nghiên cứu lần lượt là phần mở rộng của một bài báo đã xuất bản trước đó của cùng tác giả (và, và), và chúng tôi chỉ giữ phiên bản mở rộng để tránh trùng lặp.

3.3 Tổng quan Chung về Bài báo Đã thu thập

Trong số các bài báo, 47% bài báo được xuất bản tại các địa điểm kỹ nghệ phần mềm, trong đó 19 bài báo từ ICSE, 5 bài báo từ FSE, 5 bài báo từ ASE, và 3 bài báo từ ISSTA. 2% bài báo được xuất bản tại các địa điểm trí tuệ nhân tạo như EMNLP và ICLR, và 5% bài báo được xuất bản tại các địa điểm phân tích chương trình hoặc bảo mật như PLDI và S&P. Bên cạnh đó, 46% số bài báo chưa được xuất bản qua các địa điểm được đánh giá ngang hàng, tức là chúng được tiết lộ trên arXiv. Điều này có thể hiểu được vì lĩnh vực này đang nổi lên và nhiều công trình vừa hoàn thành và đang trong quá trình nộp bài. Mặc dù những bài báo này không trải qua đánh giá ngang hàng, chúng tôi có quy trình đánh giá chất lượng loại bỏ các bài báo chất lượng thấp, điều này có thể đảm bảo chất lượng của khảo sát này.

Hình 3 thể hiện xu hướng của các bài báo được thu thập của chúng tôi theo năm. Chúng ta có thể thấy rằng theo năm tháng, số lượng bài báo trong lĩnh vực này tăng trưởng gần như theo cấp số nhân. Vào năm 2020 và 2021, chỉ có 1 và 2 bài báo tương ứng. Vào năm 2022, có 19 bài báo, và vào năm 2023, đã có 82 bài báo. Có thể dự đoán rằng sẽ có nhiều bài báo hơn nữa trong tương lai, điều này cho thấy sự phổ biến và sự chú ý mà lĩnh vực này đang nhận được.

4 PHÂN TÍCH TỪ GÓC ĐỘ KIỂM THỬ PHẦN MỀM

Phần này trình bày phân tích của chúng tôi từ quan điểm kiểm thử phần mềm và tổ chức các nghiên cứu được thu thập theo các tác vụ kiểm thử. Hình 4 liệt kê phân bố của từng tác vụ kiểm thử liên quan, phù hợp với vòng đời kiểm thử phần mềm. Chúng tôi đầu tiên cung cấp một cái nhìn tổng quan chung về phân bố, tiếp theo là phân tích sâu hơn cho từng tác vụ. Lưu ý rằng, đối với mỗi phần tiếp theo, tổng tích lũy của các tiểu mục có thể không luôn khớp với tổng số bài báo vì một bài báo có thể thuộc về nhiều tiểu mục.

Chúng ta có thể thấy rằng LLM đã được sử dụng hiệu quả trong cả giai đoạn giữa đến cuối của vòng đời kiểm thử phần mềm. Trong giai đoạn chuẩn bị test case, LLM đã được sử dụng cho các tác vụ như tạo unit test case, tạo test oracle, và tạo đầu vào test hệ thống. Những tác vụ này rất quan trọng trong giai đoạn giữa của kiểm thử phần mềm để giúp phát hiện các vấn đề và ngăn chặn phát triển thêm cho đến khi các vấn đề được giải quyết. Hơn nữa, trong các giai đoạn sau như giai đoạn báo cáo test/báo cáo lỗi và giai đoạn sửa lỗi, LLM đã được sử dụng cho các tác vụ như phân tích lỗi, gỡ lỗi, và sửa chữa. Những tác vụ này rất quan trọng đối với cuối giai đoạn kiểm thử khi các lỗi phần mềm cần được giải quyết để chuẩn bị cho việc phát hành sản phẩm.

4.1 Tạo Unit Test Case

Tạo unit test case bao gồm việc viết các unit test case để kiểm tra các đơn vị/thành phần riêng lẻ của phần mềm một cách độc lập và đảm bảo rằng chúng hoạt động đúng. Đối với một phương thức được kiểm thử (tức là thường được gọi là phương thức tiêu điểm), unit test tương ứng của nó bao gồm một test prefix và một test oracle. Cụ thể, test prefix thường là một loạt các câu lệnh gọi phương thức hoặc câu lệnh gán, nhằm mục đích điều khiển phương thức tiêu điểm đến trạng thái có thể kiểm thử được; và sau đó test oracle phục vụ như đặc tả để kiểm tra xem hành vi hiện tại của phương thức tiêu điểm có thỏa mãn hành vi mong đợi hay không, ví dụ: test assertion.

Để giảm bớt nỗ lực thủ công trong việc viết unit test, các nhà nghiên cứu đã đề xuất nhiều kỹ thuật khác nhau để tạo điều kiện cho việc tạo unit test tự động. Các kỹ thuật tạo unit test truyền thống tận dụng các chiến lược dựa trên tìm kiếm, dựa trên ràng buộc hoặc dựa trên ngẫu nhiên để tạo ra một bộ unit test với mục tiêu chính là tối đa hóa độ bao phủ trong phần mềm được kiểm thử. Tuy nhiên, độ bao phủ và tính có ý nghĩa của các test được tạo ra vẫn còn xa mới đạt mức thỏa đáng.

Vì LLM đã thể hiện kết quả đầy hứa hẹn trong các tác vụ như tạo mã, và cho rằng cả tạo mã và tạo unit test case đều bao gồm việc tạo mã nguồn, nghiên cứu gần đây đã mở rộng lĩnh vực tạo mã để bao gồm tạo unit test case. Mặc dù có thành công ban đầu, có những sắc thái phân biệt tạo unit test case với tạo mã chung, báo hiệu nhu cầu về các cách tiếp cận được điều chỉnh phù hợp hơn.

Đào tạo trước hoặc fine-tuning LLM cho tạo unit test case. Do những hạn chế của LLM trong giai đoạn đầu, phần lớn các nghiên cứu được xuất bản sớm hơn áp dụng lược đồ đào tạo trước hoặc fine-tuning này. Hơn nữa, trong một số nghiên cứu gần đây, lược đồ này tiếp tục được sử dụng để tăng cường sự quen thuộc của LLM với kiến thức lĩnh vực. Alagarsamy và cộng sự đầu tiên đào tạo trước LLM với phương thức tiêu điểm và các câu lệnh khẳng định để cho phép LLM có kiến thức nền tảng mạnh hơn về các khẳng định, sau đó fine-tune LLM cho tác vụ tạo test case nơi mục tiêu là học mối quan hệ giữa phương thức tiêu điểm và test case tương ứng. Tufano và cộng sự sử dụng một lược đồ tương tự bằng cách đào tạo trước LLM trên một kho ngữ liệu Java không giám sát lớn, và fine-tuning có giám sát một tác vụ dịch hạ nguồn để tạo unit test. Hashtroudi và cộng sự tận dụng các test do developer viết hiện có cho mỗi dự án để tạo ra một tập dữ liệu cụ thể cho dự án để thích ứng miền khi fine-tuning LLM, điều này có thể tạo điều kiện cho việc tạo ra các unit test có thể đọc được bởi con người. Rao và cộng sự đào tạo một mô hình ngôn ngữ kiểu GPT bằng cách sử dụng một tín hiệu đào tạo trước rõ ràng xem xét ánh xạ giữa các tệp mã và test. Steenhoek và cộng sự sử dụng học tăng cường để tối ưu hóa các mô hình bằng cách cung cấp phần thưởng dựa trên các thước đo chất lượng tĩnh có thể được tính toán tự động cho các unit test case được tạo ra.

Thiết kế prompt hiệu quả cho tạo unit test case. Sự tiến bộ của LLM đã cho phép chúng xuất sắc trong các tác vụ được nhắm mục tiêu mà không cần đào tạo trước hoặc fine-tuning. Do đó, hầu hết các nghiên cứu sau này thường tập trung vào cách thiết kế prompt, để làm cho LLM hiểu ngữ cảnh và các sắc thái của tác vụ này tốt hơn. Xie và cộng sự tạo ra các unit test case bằng cách phân tích dự án, trích xuất thông tin thiết yếu, và tạo ra một ngữ cảnh tiêu điểm thích ứng bao gồm một phương thức tiêu điểm và các phụ thuộc của nó trong giới hạn token prompt tối đa được xác định trước của LLM, và kết hợp những ngữ cảnh này vào một prompt để truy vấn LLM. Dakhel và cộng sự giới thiệu MuTAP để cải thiện hiệu quả của các test case được tạo ra bởi LLM về mặt tiết lộ lỗi bằng cách tận dụng mutation testing. Họ bổ sung prompt với các mutant sống sót, vì những mutant đó làm nổi bật những hạn chế của test case trong việc phát hiện lỗi. Zhang và cộng sự tạo ra các test bảo mật với các phụ thuộc dễ bị tổn thương với LLM.

Yuan và cộng sự đầu tiên thực hiện một nghiên cứu thực nghiệm để đánh giá khả năng tạo unit test của ChatGPT với cả phân tích định lượng và nghiên cứu người dùng về tính đúng đắn, đầy đủ, dễ đọc, và khả năng sử dụng. Và kết quả cho thấy các test được tạo ra vẫn gặp phải các vấn đề về tính đúng đắn, bao gồm các lỗi biên dịch đa dạng và lỗi thực thi. Họ tiếp tục đề xuất một cách tiếp cận tận dụng chính ChatGPT để cải thiện chất lượng của các test được tạo ra với một bộ tạo test ban đầu và một bộ tinh chỉnh test lặp đi lặp lại. Cụ thể, bộ tinh chỉnh test lặp đi lặp lại sửa chữa lặp đi lặp lại các lỗi biên dịch trong các test được tạo ra bởi bộ tạo test ban đầu, theo một mô hình xác thực và sửa chữa để nhắc LLM dựa trên các thông báo lỗi biên dịch và ngữ cảnh mã bổ sung. Guilherme và cộng sự và Li và cộng sự tương ứng đánh giá chất lượng của các unit test được tạo ra bởi LLM sử dụng các thước đo và prompt khác nhau.

Tạo test với tài liệu bổ sung. Vikram và cộng sự đã đi xa hơn bằng cách điều tra tiềm năng sử dụng LLM để tạo ra các test dựa trên thuộc tính khi được cung cấp tài liệu API. Họ tin rằng tài liệu của một phương thức API có thể hỗ trợ LLM trong việc tạo ra logic để tạo đầu vào ngẫu nhiên cho phương thức đó và rút ra các thuộc tính có ý nghĩa của kết quả để kiểm tra. Thay vì tạo unit test từ mã nguồn, Plein và cộng sự tạo ra các test dựa trên báo cáo lỗi do người dùng viết.

LLM và phương pháp dựa trên tìm kiếm cho tạo unit test. Các nghiên cứu đã đề cập sử dụng LLM cho toàn bộ tác vụ tạo unit test case, trong khi Lemieux và cộng sự tập trung vào một hướng khác, tức là đầu tiên để các kỹ thuật kiểm thử phần mềm dựa trên tìm kiếm truyền thống (ví dụ: Pynguin) tạo ra unit test case cho đến khi cải thiện độ bao phủ của nó ngừng lại, sau đó yêu cầu LLM cung cấp các test case ví dụ cho các hàm được bao phủ dưới mức. Những ví dụ này có thể giúp việc tạo test ban đầu chuyển hướng tìm kiếm của nó đến các khu vực hữu ích hơn của không gian tìm kiếm.

Tang và cộng sự tiến hành so sánh có hệ thống các bộ test được tạo ra bởi LLM và công cụ kiểm thử phần mềm dựa trên tìm kiếm hiện đại EvoSuite, bằng cách xem xét tính đúng đắn, dễ đọc, độ bao phủ mã, và khả năng phát hiện lỗi. Tương tự, Bhatia điều tra thực nghiệm chất lượng của các unit test được tạo ra bởi LLM so với một bộ tạo test thường được sử dụng Pynguin.

Hiệu suất của tạo unit test case. Vì các nghiên cứu đã đề cập về tạo unit test case dựa trên các tập dữ liệu khác nhau, khó có thể rút ra một so sánh công bằng và chúng tôi trình bày chi tiết trong Bảng 3 để người đọc có cái nhìn tổng quan. Chúng ta có thể thấy rằng trong benchmark SF110, cả ba LLM được đánh giá đều có hiệu suất khá thấp, tức là độ bao phủ 2%. SF110 là một benchmark Evosuite (một kỹ thuật tạo unit test case dựa trên tìm kiếm) bao gồm 111 dự án Java mã nguồn mở được truy xuất từ SourceForge, chứa 23.886 lớp, hơn 800.000 nhánh cấp bytecode, và 6,6 triệu dòng mã. Các tác giả không trình bày lý do chi tiết cho hiệu suất thấp có thể được khám phá thêm trong tương lai.

4.2 Tạo Test Oracle

Test oracle là một nguồn thông tin về việc liệu đầu ra của một hệ thống phần mềm (hoặc chương trình hoặc hàm hoặc phương thức) có đúng hay không. Hầu hết các nghiên cứu được thu thập trong danh mục này nhắm đến việc tạo test assertion, nằm bên trong một unit test case. Tuy nhiên, chúng tôi chọn coi những nghiên cứu này như các phần riêng biệt để tạo điều kiện cho phân tích kỹ lưỡng hơn.

Test assertion, được sử dụng để chỉ ra các vấn đề tiềm ẩn trong mã được kiểm thử, là một khía cạnh quan trọng có thể phân biệt các unit test case với mã thông thường. Đây là lý do tại sao một số nghiên cứu tập trung cụ thể vào việc tạo ra các test assertion hiệu quả. Thực tế, trước khi sử dụng LLM, các nhà nghiên cứu đã đề xuất các cách tiếp cận dựa trên RNN nhằm học từ hàng nghìn phương thức unit test để tạo ra các câu lệnh assert có ý nghĩa, tuy nhiên chỉ 17% các assert được tạo ra có thể khớp chính xác với các assert chuẩn. Tiếp theo, để cải thiện hiệu suất, một số nhà nghiên cứu đã sử dụng LLM cho tác vụ này.

Mastropaolo và cộng sự đào tạo trước một mô hình T5 trên một tập dữ liệu bao gồm văn bản tiếng Anh ngôn ngữ tự nhiên và mã nguồn. Sau đó, nó fine-tune mô hình như vậy bằng cách tái sử dụng các tập dữ liệu được sử dụng trong bốn công trình trước đây đã sử dụng các kỹ thuật deep learning (như RNN như đã đề cập trước đó) bao gồm tạo test assertion và sửa chữa chương trình, v.v. Kết quả cho thấy tỷ lệ khớp chính xác của test assertion được tạo ra là 57%. Tufano và cộng sự đề xuất một cách tiếp cận tương tự riêng biệt đào tạo trước LLM với kho ngữ liệu tiếng Anh và kho ngữ liệu mã, và sau đó fine-tune nó trên tập dữ liệu assert (với các phương thức test, phương thức tiêu điểm, và assert). Điều này tiếp tục cải thiện hiệu suất lên 62% tỷ lệ khớp chính xác. Bên cạnh dữ liệu cấp cú pháp như các nghiên cứu trước, Nie và cộng sự fine-tune LLM với sáu loại dữ liệu ngữ nghĩa mã, bao gồm kết quả thực thi (ví dụ: loại của các biến cục bộ) và ngữ cảnh thực thi (ví dụ: phương thức được gọi cuối cùng trong phương thức test), cho phép LLM học hiểu thông tin thực thi mã. Tỷ lệ khớp chính xác là 17% (lưu ý rằng bài báo này dựa trên một tập dữ liệu khác với tất cả các nghiên cứu khác được đề cập dưới chủ đề này).

Các nghiên cứu đã đề cập sử dụng lược đồ đào tạo trước và fine-tuning khi sử dụng LLM, và với khả năng ngày càng mạnh mẽ của LLM, chúng có thể hoạt động tốt trên các tác vụ cụ thể mà không cần những tập dữ liệu đào tạo trước hoặc fine-tuning chuyên biệt này. Tiếp theo, Nashid và cộng sự sử dụng kỹ thuật prompt engineering cho tác vụ này, và đề xuất một kỹ thuật tạo prompt tự động truy xuất các minh chứng mã tương tự với tác vụ, dựa trên phân tích embedding hoặc tần suất. Họ cũng trình bày các đánh giá về few-shot learning với các số lượng khác nhau (ví dụ: zero-shot, one-shot, hoặc n-shot) và hình thức (ví dụ: ngẫu nhiên so với có hệ thống, hoặc có so với không có mô tả ngôn ngữ tự nhiên) của các prompt, để điều tra tính khả thi của nó trong tạo test assertion. Chỉ với một vài minh chứng mã liên quan, cách tiếp cận này có thể đạt được độ chính xác 76% cho khớp chính xác trong tạo test assertion, đây là hiệu suất hiện đại cho tác vụ này.

4.3 Tạo Đầu vào Test Hệ thống

Danh mục này bao gồm các nghiên cứu liên quan đến việc tạo đầu vào test của kiểm thử hệ thống để cho phép tự động hóa thực thi test. Chúng tôi sử dụng ba phần để trình bày phân tích từ ba quan điểm trực giao khác nhau, và mỗi nghiên cứu được thu thập có thể được phân tích trong một hoặc nhiều phần này.

Phần đầu tiên là tạo đầu vào theo loại phần mềm. Việc tạo đầu vào test cấp hệ thống cho kiểm thử phần mềm khác nhau đối với các loại phần mềm cụ thể được kiểm thử. Ví dụ, đối với ứng dụng di động, việc tạo đầu vào test yêu cầu cung cấp một loạt các đầu vào văn bản đa dạng hoặc kết hợp thao tác (ví dụ: nhấp nút, nhấn giữ danh sách), đây là chìa khóa để kiểm thử chức năng và giao diện người dùng của ứng dụng; trong khi đối với các thư viện Deep Learning (DL), đầu vào test là một chương trình bao phủ các API DL đa dạng. Phần này sẽ thể hiện cách LLM được sử dụng để tạo đầu vào cho các loại phần mềm khác nhau.

Phần thứ hai là tạo đầu vào theo kỹ thuật kiểm thử. Chúng tôi đã quan sát thấy rằng một số cách tiếp cận phục vụ như các loại kỹ thuật kiểm thử cụ thể. Ví dụ, hàng chục nghiên cứu được thu thập của chúng tôi tập trung cụ thể vào việc sử dụng LLM cho fuzz testing. Do đó, phần này sẽ cung cấp phân tích các nghiên cứu được thu thập theo các kỹ thuật kiểm thử, thể hiện cách LLM được sử dụng để nâng cao các kỹ thuật kiểm thử truyền thống.

Phần thứ ba là tạo đầu vào theo đầu vào và đầu ra. Trong khi hầu hết các nghiên cứu được thu thập lấy mã nguồn hoặc chính phần mềm làm đầu vào và trực tiếp đầu ra đầu vào test của phần mềm, có những nghiên cứu sử dụng các hình thức đầu vào và đầu ra thay thế. Phần này sẽ cung cấp phân tích các nghiên cứu như vậy, làm nổi bật các cách tiếp cận khác nhau và đặc điểm đầu vào-đầu ra của chúng.

4.3.1 Tạo Đầu vào theo Loại Phần mềm

Hình 5 thể hiện các loại phần mềm được kiểm thử trong các nghiên cứu được thu thập của chúng tôi. Rõ ràng là danh mục nổi bật nhất là ứng dụng di động, với năm nghiên cứu sử dụng LLM để kiểm thử, có thể do tính phổ biến và tầm quan trọng của chúng trong kinh doanh và đời sống hàng ngày hiện tại. Ngoài ra, có tương ứng hai nghiên cứu tập trung vào kiểm thử thư viện deep learning, compiler, và SMT solver. Hơn nữa, các kỹ thuật kiểm thử dựa trên LLM cũng đã được áp dụng cho các lĩnh vực như hệ thống cyber-physical, nền tảng tính toán lượng tử, và nhiều hơn nữa. Việc áp dụng rộng rãi LLM này chứng minh hiệu quả của chúng trong việc xử lý các đầu vào test đa dạng và nâng cao các hoạt động kiểm thử trên nhiều lĩnh vực phần mềm khác nhau. Một phân tích chi tiết được cung cấp bên dưới.

Tạo đầu vào test cho ứng dụng di động. Đối với kiểm thử ứng dụng di động, một khó khăn là tạo ra các đầu vào văn bản phù hợp để tiến đến trang tiếp theo, điều này vẫn là một trở ngại nổi bật đối với độ bao phủ kiểm thử. Xem xét tính đa dạng và yêu cầu ngữ nghĩa của các đầu vào hợp lệ (ví dụ: điểm khởi hành chuyến bay, tên phim), các kỹ thuật truyền thống với kỹ thuật dựa trên heuristic hoặc dựa trên ràng buộc còn xa mới tạo ra đầu vào văn bản có ý nghĩa. Liu và cộng sự sử dụng LLM để tạo ra văn bản đầu vào ngữ nghĩa một cách thông minh theo ngữ cảnh GUI. Chi tiết, QTypist được đề xuất của họ tự động trích xuất thông tin thành phần liên quan đến EditText để tạo các prompt, và sau đó nhập các prompt vào LLM để tạo văn bản đầu vào.

Bên cạnh đầu vào văn bản, có các hình thức đầu vào khác cho ứng dụng di động, tức là các thao tác như 'nhấp nút' và 'chọn danh sách'. Để kiểm thử đầy đủ một ứng dụng, cần phải bao phủ nhiều trang GUI hơn và tiến hành các dấu vết khám phá có ý nghĩa hơn thông qua các thao tác GUI, tuy nhiên các nghiên cứu hiện tại với các phương pháp dựa trên ngẫu nhiên/quy tắc, phương pháp dựa trên mô hình, và phương pháp dựa trên học máy không thể hiểu thông tin ngữ nghĩa của trang GUI do đó không thể tiến hành lập kế hoạch dấu vết hiệu quả. Liu và cộng sự hình thành vấn đề tạo đầu vào test của kiểm thử GUI di động như một tác vụ Q&A, yêu cầu LLM trò chuyện với các ứng dụng di động bằng cách chuyển thông tin trang GUI cho LLM để tạo ra các script kiểm thử (tức là thao tác GUI), và thực thi chúng để tiếp tục chuyển phản hồi ứng dụng cho LLM, lặp lại toàn bộ quá trình. GPTDroid được đề xuất trích xuất ngữ cảnh tĩnh của trang GUI và ngữ cảnh động của quá trình kiểm thử lặp đi lặp lại, và thiết kế các prompt để nhập thông tin này vào LLM cho phép LLM hiểu trang GUI tốt hơn cũng như toàn bộ quá trình kiểm thử. Nó cũng giới thiệu một cơ chế nhắc nhở bộ nhớ nhận thức chức năng trang bị cho LLM khả năng giữ lại kiến thức kiểm thử của toàn bộ quá trình và tiến hành lý luận dài hạn, dựa trên chức năng để hướng dẫn khám phá. Tương tự, Zimmermann và cộng sự sử dụng LLM để diễn giải các test case ngôn ngữ tự nhiên và điều hướng theo chương trình thông qua ứng dụng được kiểm thử.

Yu và cộng sự điều tra khả năng của LLM trong tác vụ tạo và di chuyển script test ứng dụng di động, bao gồm tạo test dựa trên kịch bản, và di chuyển test đa nền tảng/ứng dụng.

Tạo đầu vào test cho thư viện DL. Đầu vào để kiểm thử thư viện DL là các chương trình DL, và khó khăn trong việc tạo ra các chương trình DL đầu vào đa dạng là chúng cần thỏa mãn cả cú pháp/ngữ nghĩa ngôn ngữ đầu vào (ví dụ: Python) và các ràng buộc đầu vào/hình dạng API cho tính toán tensor. Các kỹ thuật truyền thống với fuzzing cấp API hoặc fuzzing cấp mô hình gặp phải những hạn chế sau: 1) thiếu chuỗi API đa dạng do đó không thể tiết lộ lỗi do chuỗi API móc nối gây ra; 2) không thể tạo mã tùy ý do đó không thể khám phá không gian tìm kiếm khổng lồ tồn tại khi sử dụng các thư viện DL. Vì LLM có thể bao gồm nhiều đoạn mã gọi API thư viện DL trong kho ngữ liệu đào tạo của chúng, chúng có thể học ngầm cả cú pháp/ngữ nghĩa ngôn ngữ và các ràng buộc API phức tạp cho việc tạo chương trình DL hợp lệ. Theo nghĩa này, Deng và cộng sự sử dụng cả LLM tạo sinh và infilling để tạo ra và đột biến các chương trình DL đầu vào hợp lệ/đa dạng để fuzzing thư viện DL. Chi tiết, đầu tiên nó sử dụng LLM tạo sinh (CodeX) để tạo ra một tập các chương trình seed (tức là đoạn mã sử dụng API DL mục tiêu). Sau đó nó thay thế một phần của chương trình seed bằng các token được che với các toán tử đột biến khác nhau và tận dụng khả năng của LLM infilling (InCoder) để thực hiện code infilling để tạo ra mã mới thay thế các token được che. Nghiên cứu tiếp theo của họ đi xa hơn để priming LLM tổng hợp các chương trình bất thường cho fuzzing thư viện DL. Nó được xây dựng trên giả thuyết nổi tiếng rằng các chương trình kích hoạt lỗi lịch sử có thể bao gồm các thành phần mã hiếm/có giá trị quan trọng cho việc tìm lỗi và thể hiện hiệu suất phát hiện lỗi được cải thiện.

Tạo đầu vào test cho các loại phần mềm khác. Cũng có hàng chục nghiên cứu giải quyết các tác vụ kiểm thử trong nhiều lĩnh vực khác, do hạn chế về không gian, chúng tôi sẽ trình bày một lựa chọn các nghiên cứu đại diện trong những lĩnh vực này.

Tìm lỗi trong một công cụ phát triển hệ thống cyber-physical (CPS) thương mại như Simulink thậm chí còn thách thức hơn. Cho sự phức tạp của ngôn ngữ Simulink, việc tạo ra các tệp mô hình Simulink hợp lệ để kiểm thử là một tác vụ đầy tham vọng đối với các kỹ thuật machine learning hoặc deep learning truyền thống. Shrestha và cộng sự sử dụng một tập nhỏ dữ liệu đào tạo cụ thể cho Simulink để fine-tune LLM để tạo ra các mô hình Simulink. Kết quả cho thấy nó có thể tạo ra các mô hình Simulink khá tương tự với các mô hình mã nguồn mở, và có thể tìm thấy một tập con của các lỗi mà các cách tiếp cận fuzzing truyền thống tìm thấy.

Sun và cộng sự sử dụng LLM để tạo các công thức test cho fuzzing SMT solver. Nó đào tạo lại LLM trên một kho ngữ liệu lớn các công thức SMT để cho phép chúng có được kiến thức lĩnh vực cụ thể SMT. Sau đó nó tiếp tục fine-tune LLM trên các công thức kích hoạt lỗi lịch sử, được biết là liên quan đến các cấu trúc có nhiều khả năng kích hoạt lỗi và hành vi cụ thể của solver. LLM-based compiler fuzzer được đề xuất bởi Yang và cộng sự áp dụng một khung dual-model: (1) một LLM phân tích kiểm tra mã nguồn tối ưu hóa cấp thấp và tạo ra các yêu cầu trên các chương trình test cấp cao có thể kích hoạt tối ưu hóa; (2) một LLM tạo sinh tạo ra các chương trình test dựa trên các yêu cầu được tóm tắt. Ye và cộng sự sử dụng LLM để tạo ra các chương trình JavaScript và sau đó sử dụng các đặc tả ECMAScript có cấu trúc tốt để tự động tạo dữ liệu test cùng với các chương trình test, sau đó họ áp dụng differential testing để phơi bày lỗi.

4.3.2 Tạo Đầu vào theo Kỹ thuật Kiểm thử

Bằng cách sử dụng đầu vào test hệ thống được tạo ra bởi LLM, các nghiên cứu được thu thập nhằm mục đích nâng cao các kỹ thuật kiểm thử truyền thống và làm cho chúng hiệu quả hơn. Trong số những kỹ thuật này, fuzz testing là kỹ thuật được liên quan đến nhiều nhất. Fuzz testing, như một khái niệm chung, xoay quanh việc tạo ra dữ liệu không hợp lệ, bất ngờ, hoặc ngẫu nhiên làm đầu vào để đánh giá hành vi của phần mềm. LLM đóng vai trò quan trọng trong việc cải thiện fuzz testing truyền thống bằng cách tạo điều kiện cho việc tạo ra dữ liệu đầu vào đa dạng và thực tế. Điều này cho phép fuzz testing khám phá các lỗi tiềm ẩn trong phần mềm bằng cách đặt nó trong một loạt các kịch bản đầu vào rộng. Ngoài fuzz testing, LLM cũng góp phần nâng cao các kỹ thuật kiểm thử khác, sẽ được thảo luận chi tiết sau này.

Khung fuzzing toàn cầu. Xia và cộng sự trình bày Fuzz4All có thể nhắm đến nhiều ngôn ngữ đầu vào khác nhau và nhiều tính năng khác nhau của những ngôn ngữ này. Ý tưởng chính đằng sau nó là tận dụng LLM như một engine tạo đầu vào và đột biến, cho phép cách tiếp cận tạo ra các đầu vào đa dạng và thực tế cho bất kỳ ngôn ngữ liên quan thực tế nào. Để thực hiện tiềm năng này, họ trình bày một kỹ thuật auto-prompting mới, tạo ra các prompt LLM phù hợp cho fuzzing, và một vòng lặp fuzzing được hỗ trợ bởi LLM mới, cập nhật lặp đi lặp lại prompt để tạo ra các đầu vào fuzzing mới. Họ thử nghiệm với sáu ngôn ngữ khác nhau (C, C++, Go, SMT2, Java và Python) làm đầu vào và chứng minh độ bao phủ cao hơn các fuzzer cụ thể cho ngôn ngữ hiện có. Hu và cộng sự đề xuất một greybox fuzzer được tăng cường bởi LLM, chọn một seed trong pool seed của fuzzer và nhắc LLM tạo ra các seed đột biến có thể kích hoạt một vùng mã mới của phần mềm. Họ thử nghiệm với ba danh mục định dạng đầu vào, tức là các tệp dữ liệu được định dạng (ví dụ: json, xml), mã nguồn trong các ngôn ngữ lập trình khác nhau (ví dụ: JS, SQL, C), văn bản không có quy tắc cú pháp rõ ràng (ví dụ: HTTP response, md5 checksum). Ngoài ra, fuzzing hiệu quả dựa vào fuzz driver hiệu quả, và Zhang và cộng sự sử dụng LLM trong việc tạo fuzz driver, trong đó năm chiến lược truy vấn được thiết kế và phân tích từ cơ bản đến nâng cao.

Kỹ thuật fuzzing cho phần mềm cụ thể. Có những nghiên cứu tập trung vào các kỹ thuật fuzzing được điều chỉnh cho phần mềm cụ thể, ví dụ: thư viện deep learning, compiler, SMT solver, input widget của ứng dụng di động, hệ thống cyber-physical, v.v. Một trọng tâm chính của những kỹ thuật fuzzing này là tạo ra các đầu vào test đa dạng để đạt được độ bao phủ cao hơn. Điều này thường được đạt được bằng cách kết hợp kỹ thuật đột biến với việc tạo sinh dựa trên LLM, trong đó cái trước tạo ra các ứng viên khác nhau trong khi cái sau chịu trách nhiệm tạo ra các đầu vào test có thể thực thi. Một trọng tâm khác của những kỹ thuật fuzzing này là tạo ra các đầu vào test rủi ro có thể kích hoạt lỗi sớm hơn. Để đạt được điều này, một thực hành phổ biến là thu thập các chương trình kích hoạt lỗi lịch sử để fine-tune LLM hoặc coi chúng như các minh chứng khi truy vấn LLM.

Các kỹ thuật kiểm thử khác. Có những nghiên cứu sử dụng LLM để nâng cao kiểm thử GUI để tạo ra đầu vào văn bản có ý nghĩa và dấu vết khám phá định hướng chức năng, đã được giới thiệu trong phần Tạo đầu vào test cho ứng dụng di động của Phần 4.3.1.

Bên cạnh đó, Deng và cộng sự tận dụng LLM để thực hiện các tác vụ penetration testing tự động. Nó liên quan đến việc đặt một mục tiêu penetration testing cho LLM, yêu cầu nó thực hiện thao tác phù hợp để thực thi, triển khai nó trong môi trường kiểm thử, và cung cấp đầu ra test trở lại cho LLM để lý luận bước tiếp theo.

4.3.3 Tạo Đầu vào theo Đầu vào và Đầu ra

Định dạng đầu ra khác của tạo test. Mặc dù hầu hết các công trình sử dụng LLM để tạo ra test case trực tiếp, cũng có một số công trình tạo ra các đầu vào gián tiếp như mã kiểm thử, kịch bản test, mối quan hệ metamorphic, v.v. Liu và cộng sự đề xuất InputBlaster tận dụng LLM để tự động tạo ra các đầu vào văn bản bất thường để fuzzing các widget đầu vào văn bản trong ứng dụng di động. Nó hình thành vấn đề tạo đầu vào bất thường như một tác vụ tạo ra một tập các bộ tạo test, mỗi cái có thể tạo ra một lô đầu vào văn bản bất thường dưới cùng một quy tắc đột biến. Chi tiết, InputBlaster tận dụng LLM để tạo ra các bộ tạo test cùng với các quy tắc đột biến phục vụ như chuỗi lý luận và sử dụng lược đồ in-context learning để chứng minh cho LLM với các ví dụ để tăng cường hiệu suất. Deng và cộng sự sử dụng LLM để trích xuất thông tin chính liên quan đến kịch bản test từ một quy tắc giao thông, và biểu diễn thông tin được trích xuất trong một lược đồ kịch bản test, sau đó tổng hợp các script kịch bản tương ứng để xây dựng kịch bản test. Luu và cộng sự kiểm tra hiệu quả của LLM trong việc tạo ra các mối quan hệ metamorphic (MR) cho metamorphic testing. Kết quả của họ cho thấy ChatGPT có thể được sử dụng để thúc đẩy trí thông minh kiểm thử phần mềm bằng cách đề xuất các ứng viên MR có thể được điều chỉnh sau này để triển khai các test, nhưng trí thông minh con người vẫn phải tham gia không thể tránh khỏi để biện minh và chỉnh sửa tính đúng đắn của chúng.

Định dạng đầu vào khác của tạo test. Các nghiên cứu đã đề cập chủ yếu lấy mã nguồn hoặc phần mềm làm đầu vào của LLM, tuy nhiên cũng có những nghiên cứu lấy mô tả ngôn ngữ tự nhiên làm đầu vào cho việc tạo test. Mathur và cộng sự đề xuất tạo ra test case từ các yêu cầu được mô tả bằng ngôn ngữ tự nhiên. Ackerman và cộng sự tạo ra các thể hiện từ các yêu cầu được mô tả bằng ngôn ngữ tự nhiên một cách đệ quy để phục vụ như các ví dụ seed cho một mutation fuzzer.

4.4 Phân tích Lỗi

Danh mục này liên quan đến việc phân tích và phân loại các lỗi phần mềm được xác định để nâng cao hiểu biết về lỗi, và tạo điều kiện cho việc gỡ lỗi và sửa lỗi tiếp theo. Mukherjee và cộng sự tạo ra các câu trả lời liên quan cho các câu hỏi tiếp theo đối với các báo cáo lỗi thiếu sót để tạo điều kiện cho bug triage. Su và cộng sự chuyển đổi bug-component triaging thành một tác vụ đa phân loại và một tác vụ tạo sinh với LLM, sau đó tổng hợp kết quả dự đoán từ chúng để cải thiện hiệu suất của bug-component triaging thêm nữa. Zhang và cộng sự đầu tiên tận dụng LLM dưới thiết lập zero-shot để có được thông tin thiết yếu về báo cáo lỗi, sau đó sử dụng thông tin thiết yếu làm đầu vào để phát hiện báo cáo lỗi trùng lặp. Mahbub và cộng sự đề xuất giải thích lỗi phần mềm với LLM, tạo ra các giải thích ngôn ngữ tự nhiên cho lỗi phần mềm bằng cách học từ một kho ngữ liệu lớn các commit sửa lỗi. Zhang và cộng sự nhắm đến việc tự động tạo tiêu đề lỗi từ các mô tả của lỗi, nhằm mục đích giúp các developer viết tiêu đề issue và tạo điều kiện cho bug triaging và quy trình sửa chữa tiếp theo.

4.5 Gỡ lỗi

Danh mục này đề cập đến quá trình xác định và định vị nguyên nhân của một vấn đề phần mềm (tức là lỗi). Nó bao gồm việc phân tích mã, theo dõi dòng thực thi, thu thập thông tin lỗi để hiểu nguyên nhân gốc của vấn đề, và sửa chữa vấn đề. Một số nghiên cứu tập trung vào quá trình gỡ lỗi toàn diện, trong khi những nghiên cứu khác đi sâu vào các hoạt động phụ cụ thể trong quá trình.

Khung gỡ lỗi tổng thể. Bui và cộng sự đề xuất một khung Detect-Localize-Repair thống nhất dựa trên LLM để gỡ lỗi, đầu tiên xác định xem một đoạn mã nhất định có lỗi hay không, sau đó xác định các dòng lỗi, và dịch mã lỗi thành phiên bản đã sửa. Kang và cộng sự đề xuất automated scientific debugging, một kỹ thuật cho trước mã lỗi và một test tiết lộ lỗi, nhắc LLM tự động tạo ra các giả thuyết, sử dụng debugger để tương tác tích cực với mã lỗi, và do đó tự động đạt được kết luận trước khi tạo patch. Chen và cộng sự chứng minh rằng self-debugging có thể dạy LLM thực hiện rubber duck debugging; tức là, không có bất kỳ phản hồi nào từ con người về tính đúng đắn của mã hoặc thông báo lỗi, mô hình có thể xác định các lỗi của nó bằng cách điều tra kết quả thực thi và giải thích mã được tạo ra bằng ngôn ngữ tự nhiên. Cao và cộng sự tiến hành một nghiên cứu về khả năng gỡ lỗi của LLM cho các chương trình deep learning, bao gồm phát hiện lỗi, định vị lỗi và sửa chữa chương trình.

Định vị lỗi. Wu và cộng sự so sánh hai LLM (ChatGPT và GPT-4) với các kỹ thuật định vị lỗi hiện có, và điều tra tính nhất quán của LLM trong định vị lỗi, cũng như cách prompt engineering và độ dài của ngữ cảnh mã ảnh hưởng đến kết quả. Kang và cộng sự đề xuất AutoFL, một kỹ thuật định vị lỗi tự động chỉ yêu cầu một test thất bại duy nhất, và trong quá trình định vị lỗi của nó, nó cũng tạo ra một giải thích về lý do tại sao test nhất định thất bại. Yang và cộng sự đề xuất LLMAO để vượt qua bản chất từ trái sang phải của LLM bằng cách fine-tuning một tập nhỏ các lớp adapter hai chiều trên đầu các biểu diễn được học bởi LLM, có thể định vị các dòng mã lỗi mà không có bất kỳ thông tin độ bao phủ test nào. Tu và cộng sự đề xuất LLM4CBI để tận dụng LLM tạo ra các chương trình test hiệu quả để tìm các tệp đáng ngờ.

Tái tạo lỗi. Cũng có những nghiên cứu tập trung vào một giai đoạn phụ của quá trình gỡ lỗi. Ví dụ, Kang và cộng sự và Plein và cộng sự tương ứng đề xuất khung để khai thác LLM để tái tạo lỗi, và đề xuất các test case tái tạo lỗi cho developer để tạo điều kiện cho việc gỡ lỗi. Li và cộng sự tập trung vào một khía cạnh tương tự của việc tìm các test case gây ra lỗi có đầu vào test có thể kích hoạt lỗi của phần mềm. Nó kết hợp một cách hiệp lực LLM và differential testing để làm điều đó.

Cũng có những nghiên cứu tập trung vào việc tái tạo lỗi của ứng dụng di động để tạo ra script replay. Feng và cộng sự đề xuất AdbGPT, một cách tiếp cận nhẹ mới để tự động tái tạo lỗi từ báo cáo lỗi thông qua prompt engineering, không có bất kỳ nỗ lực đào tạo và hard-coding nào. Nó tận dụng few-shot learning và chain-of-thought reasoning để tạo ra kiến thức con người và lý luận logic từ LLM để hoàn thành bug replay theo cách tương tự như một developer. Huang và cộng sự đề xuất CrashTranslator để tự động tái tạo lỗi trực tiếp từ stack trace. Nó hoàn thành điều này bằng cách tận dụng LLM để dự đoán các bước khám phá để kích hoạt crash, và thiết kế một kỹ thuật dựa trên học tăng cường để giảm thiểu dự đoán không chính xác và hướng dẫn tìm kiếm một cách tổng thể. Taeb và cộng sự chuyển đổi các hướng dẫn test accessibility thủ công thành các video có thể replay, có thể điều hướng bằng cách sử dụng LLM và các mô hình phát hiện phần tử UI, cũng có thể giúp tiết lộ các vấn đề accessibility.

Giải thích lỗi. Taylor và cộng sự tích hợp LLM vào Debugging C Compiler để tạo ra các giải thích độc đáo, tập trung vào người mới bắt đầu được điều chỉnh cho từng lỗi. Widjojo và cộng sự nghiên cứu hiệu quả của Stack Overflow và LLM trong việc giải thích lỗi compiler.

4.6 Sửa chữa Chương trình

Danh mục này biểu thị tác vụ sửa chữa các lỗi phần mềm được xác định. Tần suất cao của các nghiên cứu liên quan đến sửa chữa có thể được quy cho mối quan hệ chặt chẽ giữa tác vụ này và mã nguồn. Với khả năng xử lý ngôn ngữ tự nhiên và hiểu biết tiên tiến, LLM được trang bị tốt để xử lý và phân tích mã nguồn, làm cho chúng trở thành công cụ lý tưởng để thực hiện các tác vụ liên quan đến mã như sửa lỗi.

Đã có các kỹ thuật sửa chữa chương trình tự động dựa trên template, dựa trên heuristic, và dựa trên ràng buộc. Và với sự phát triển của các kỹ thuật deep learning trong vài năm qua, đã có một số nghiên cứu sử dụng các kỹ thuật deep learning cho sửa chữa chương trình. Chúng thường áp dụng các mô hình deep learning để lấy một chương trình phần mềm lỗi làm đầu vào và tạo ra một chương trình đã được vá. Dựa trên dữ liệu đào tạo, chúng sẽ xây dựng một mô hình mạng neural học các mối quan hệ giữa mã lỗi và mã đã sửa tương ứng. Tuy nhiên, những kỹ thuật này vẫn thất bại trong việc sửa một phần lớn lỗi, và chúng thường phải tạo ra hàng trăm đến hàng nghìn patch ứng viên và mất hàng giờ để xác thực những patch này để sửa đủ lỗi. Hơn nữa, các mô hình sửa chữa chương trình dựa trên deep learning cần được đào tạo với lượng lớn dữ liệu đào tạo có nhãn (thường là các cặp mã lỗi và đã sửa), điều này tốn thời gian và công sức để thu thập tập dữ liệu chất lượng cao. Tiếp theo, với sự phổ biến và khả năng được chứng minh của LLM, các nhà nghiên cứu bắt đầu khám phá LLM cho sửa chữa chương trình.

Patch lỗi đơn dòng. Trong thời đại đầu của sửa chữa chương trình, trọng tâm chủ yếu là giải quyết các khuyết tật liên quan đến lỗi mã đơn dòng, tương đối đơn giản và không yêu cầu sửa chữa logic chương trình phức tạp. Lajkó và cộng sự đề xuất fine-tune LLM với các đoạn mã JavaScript để phục vụ mục đích sửa chữa chương trình JavaScript. Zhang và cộng sự sử dụng program slicing để trích xuất thông tin ngữ cảnh liên quan trực tiếp đến câu lệnh lỗi nhất định làm thành phần sửa chữa từ program dependence graph tương ứng, làm cho fine-tuning tập trung hơn vào mã lỗi. Zhang và cộng sự đề xuất một khung theo giai đoạn STEAM để patch lỗi đơn dòng, mô phỏng hành vi tương tác của nhiều programmer tham gia quản lý lỗi, ví dụ: báo cáo lỗi, chẩn đoán lỗi, tạo patch, và xác thực patch.

Vì hầu hết lỗi thực tế sẽ liên quan đến nhiều dòng mã, và các nghiên cứu sau này khám phá những tình huống phức tạp hơn này (mặc dù một số trong số chúng cũng có thể patch lỗi đơn dòng).

Patch lỗi nhiều dòng. Các nghiên cứu trong danh mục này sẽ nhập một hàm lỗi vào LLM, và mục tiêu là đầu ra hàm đã được patch, có thể liên quan đến hiểu biết ngữ nghĩa phức tạp, sửa đổi hunk mã, cũng như tái cấu trúc chương trình. Các nghiên cứu sớm hơn thường sử dụng chiến lược fine-tuning để cho phép LLM hiểu ngữ nghĩa mã tốt hơn. Fu và cộng sự fine-tune LLM bằng cách sử dụng tokenization BPE để xử lý các vấn đề Out-Of-Vocabulary (OOV) làm cho cách tiếp cận tạo ra các token mới không bao giờ xuất hiện trong hàm đào tạo nhưng được giới thiệu mới trong việc sửa chữa. Wang và cộng sự đào tạo LLM dựa trên cả đầu vào lỗi và các ví dụ sửa lỗi được truy xuất được truy xuất theo độ tương tự từ vựng và ngữ nghĩa. Các nghiên cứu đã đề cập (bao gồm những cái trong patching lỗi đơn dòng) sẽ dự đoán các chương trình đã sửa trực tiếp, và Hu và cộng sự sử dụng một thiết lập khác dự đoán các script có thể sửa lỗi khi được thực thi với ngữ pháp delete và insert. Ví dụ, nó dự đoán xem một dòng mã ban đầu có nên được xóa hay không, và nội dung gì nên được chèn vào.

Tuy nhiên, fine-tuning có thể gặp phải những hạn chế về việc dựa vào dữ liệu có nhãn chất lượng cao dồi dào, tài nguyên tính toán đáng kể, và khả năng overfitting. Để tiếp cận vấn đề sửa chữa chương trình hiệu quả hơn, các nghiên cứu sau này tập trung vào cách thiết kế một prompt hiệu quả cho sửa chữa chương trình. Một số nghiên cứu điều tra thực nghiệm hiệu quả của các biến thể prompt của LLM mới nhất cho sửa chữa chương trình dưới các thiết lập sửa chữa khác nhau và các benchmark thường được sử dụng (sẽ được khám phá sâu sau này), trong khi các nghiên cứu khác tập trung vào đề xuất các kỹ thuật mới. Ribeiro và cộng sự tận dụng LLM để thực hiện code completion trong một dòng lỗi để tạo patch, và trình bày chi tiết về cách vượt qua bản chất mở của tạo mã để phù hợp một cách thích hợp mã mới trong chương trình ban đầu. Xia và cộng sự đề xuất cách tiếp cận sửa chữa chương trình điều khiển bằng hội thoại xen kẽ việc tạo patch với phản hồi tức thì để thực hiện sửa chữa theo kiểu hội thoại. Họ đầu tiên cung cấp cho LLM thông tin thất bại test liên quan để bắt đầu, và sau đó học từ cả thất bại và thành công của các nỗ lực patching sớm hơn của cùng một lỗi để sửa chữa mạnh mẽ hơn. Đối với các patch sớm hơn thất bại trong việc vượt qua tất cả các test, họ kết hợp các patch không đúng với thông tin thất bại test liên quan tương ứng của chúng để xây dựng một prompt mới cho LLM để tạo ra patch tiếp theo, nhằm tránh làm những lỗi tương tự. Đối với các patch sớm hơn vượt qua tất cả các test (tức là các patch hợp lý), họ tiếp tục yêu cầu LLM tạo ra các biến thể thay thế của các patch hợp lý ban đầu. Điều này có thể tiếp tục xây dựng và học từ các thành công sớm hơn để tạo ra nhiều patch hợp lý hơn để tăng cơ hội có các patch đúng. Zhang và cộng sự đề xuất một thiết kế cách tiếp cận tương tự bằng cách tận dụng prompt đa phương thức (ví dụ: mô tả ngôn ngữ tự nhiên, thông báo lỗi, test case dựa trên input-output), truy vấn lặp đi lặp lại, lựa chọn few-shot dựa trên test-case để tạo ra sửa chữa. Moon và cộng sự đề xuất để sửa lỗi với phản hồi. Nó bao gồm một mô hình critic để tạo phản hồi, một editor để chỉnh sửa mã dựa trên phản hồi, và một feedback selector để chọn phản hồi tốt nhất có thể từ critic.

Wei và cộng sự đề xuất Repilot để copilot các "copilot" AI (tức là LLM) bằng cách tổng hợp nhiều patch hợp lệ hơn trong quá trình sửa chữa. Cái nhìn sâu sắc chính của nó là nhiều LLM tạo ra đầu ra autoregressive (tức là token by token), và bằng cách giống như con người viết chương trình, việc sửa chữa có thể được tăng cường đáng kể và được hướng dẫn thông qua một completion engine. Brownlee và cộng sự đề xuất sử dụng LLM như các toán tử đột biến cho các kỹ thuật dựa trên tìm kiếm của sửa chữa chương trình.

Sửa chữa với static code analyzer. Hầu hết các nghiên cứu sửa chữa chương trình sẽ giả định lỗi đã được phát hiện, trong khi Jin và cộng sự đề xuất một khung sửa chữa chương trình được kết hợp với một static analyzer để đầu tiên phát hiện lỗi, và sau đó sửa chúng. Chi tiết, static analyzer đầu tiên phát hiện một lỗi (ví dụ: null pointer dereference) và thông tin ngữ cảnh được cung cấp bởi static analyzer sẽ được gửi vào LLM để truy vấn patch cho lỗi cụ thể này. Wadhwa và cộng sự tập trung vào một tác vụ tương tự, và bổ sung sử dụng một LLM như ranker để đánh giá khả năng chấp nhận của các patch được tạo ra có thể hiệu quả bắt được các bản sửa hợp lý nhưng không đúng và giảm gánh nặng cho developer.

Sửa chữa cho lỗi cụ thể. Các nghiên cứu đã đề cập đều xem xét mã lỗi làm đầu vào cho sửa chữa chương trình tự động, trong khi các nghiên cứu khác tiến hành sửa chữa chương trình theo các loại mô tả lỗi khác, các loại lỗi cụ thể, v.v. Fakhoury và cộng sự tập trung vào sửa chữa chương trình từ mô tả issue ngôn ngữ tự nhiên, tức là tạo ra patch với thông tin liên quan đến lỗi và sửa chữa được mô tả trong báo cáo issue. Garg và cộng sự nhằm mục đích sửa chữa các vấn đề hiệu suất, trong đó họ đầu tiên truy xuất một hướng dẫn prompt từ một knowledge-base được xây dựng trước của các bản sửa lỗi hiệu suất trước đó và sau đó tạo ra một prompt sửa chữa sử dụng hướng dẫn được truy xuất. Có những nghiên cứu tập trung vào việc sửa lỗi của các chương trình Rust hoặc các chương trình OCaml (một ngôn ngữ lập trình công nghiệp mạnh mẽ).

Nghiên cứu thực nghiệm về sửa chữa chương trình. Có một số nghiên cứu liên quan đến đánh giá thực nghiệm hoặc thử nghiệm của nhiều LLM khác nhau về sửa chữa chương trình, và chúng tôi tóm tắt hiệu suất trong Bảng 4. Jiang và cộng sự, Xia và cộng sự, và Zhang và cộng sự tương ứng tiến hành đánh giá thực nghiệm toàn diện với nhiều LLM khác nhau và trên các benchmark sửa chữa chương trình tự động khác nhau, trong khi các nhà nghiên cứu khác tập trung vào một LLM cụ thể và trên một tập dữ liệu, ví dụ: QuixBugs. Ngoài ra, Gao và cộng sự điều tra thực nghiệm tác động của các minh chứng in-context cho sửa lỗi, bao gồm lựa chọn, thứ tự, và số lượng ví dụ minh chứng. Prenner và cộng sự nghiên cứu thực nghiệm cách ngữ cảnh cục bộ (tức là mã đến trước hoặc sau vị trí lỗi) ảnh hưởng đến hiệu suất sửa chữa. Horváth và cộng sự nghiên cứu thực nghiệm tác động của biểu diễn chương trình và kiến trúc mô hình đến hiệu suất sửa chữa.

Có hai thiết lập sửa chữa thường được sử dụng khi sử dụng LLM để tạo patch: 1) tạo hàm hoàn chỉnh (tức là tạo ra toàn bộ hàm patch), 2) code infilling đúng (tức là điền vào một đoạn mã cho trước prefix và suffix), và các nghiên cứu khác nhau có thể sử dụng các thiết lập khác nhau được đánh dấu trong Bảng 4. Các tập dữ liệu thường được sử dụng là QuixBugs, Defects4J, v.v. Những tập dữ liệu này chỉ liên quan đến các chức năng cơ bản như thuật toán sắp xếp, số dòng trung bình của mỗi chương trình từ 13 đến 22, triển khai một chức năng, và liên quan đến ít phụ thuộc. Để giải quyết điều này, Cao và cộng sự tiến hành một nghiên cứu thực nghiệm trên một tập dữ liệu phức tạp hơn với các chương trình DL được thu thập từ StackOverflow. Mỗi chương trình chứa khoảng 46 dòng mã trung bình, triển khai một số chức năng bao gồm tiền xử lý dữ liệu, xây dựng mô hình DL, đào tạo mô hình, và đánh giá. Và tập dữ liệu liên quan đến hơn 6 phụ thuộc cho mỗi chương trình, bao gồm TensorFlow, Keras, và Pytorch. Kết quả của họ chứng minh tỷ lệ patch đúng thấp hơn nhiều so với các tập dữ liệu khác, điều này một lần nữa tiết lộ khó khăn tiềm tàng của tác vụ này. Tương tự, Haque và cộng sự giới thiệu một tập dữ liệu bao gồm các bài nộp mã lỗi và các bản sửa tương ứng của chúng được thu thập từ các nền tảng online judge, trong đó nó cung cấp một bộ sưu tập mở rộng các unit test để cho phép đánh giá về tính đúng đắn của các bản sửa và thông tin thêm về thời gian, ràng buộc bộ nhớ, và sự chấp nhận dựa trên một verdict.

5 PHÂN TÍCH TỪ GÓC ĐỘ LLM

Phần này thảo luận về phân tích dựa trên quan điểm của LLM, cụ thể, nó được triển khai từ quan điểm của các LLM được sử dụng, các loại kỹ thuật prompt engineering, đầu vào của LLM, cũng như các kỹ thuật đi kèm khi sử dụng LLM.

5.1 Các Mô hình LLM

Như được hiển thị trong Hình 6, LLM được sử dụng phổ biến nhất trong các tác vụ kiểm thử phần mềm là ChatGPT, được phát hành vào tháng 11 năm 2022 bởi OpenAI. Nó được đào tạo trên một kho ngữ liệu lớn dữ liệu văn bản ngôn ngữ tự nhiên, và chủ yếu được thiết kế cho xử lý ngôn ngữ tự nhiên và hội thoại. ChatGPT là LLM được công nhận rộng rãi và phổ biến nhất cho đến nay, được biết đến với hiệu suất đặc biệt trên nhiều tác vụ khác nhau. Do đó, không có gì ngạc nhiên khi nó xếp hạng đầu về các nghiên cứu được thu thập của chúng tôi.

Codex, một LLM dựa trên GPT-3, là LLM được sử dụng phổ biến thứ hai trong các nghiên cứu được thu thập của chúng tôi. Nó được đào tạo trên một kho ngữ liệu mã khổng lồ chứa các ví dụ từ nhiều ngôn ngữ lập trình như JavaScript, Python, C/C++, và Java. Codex được phát hành vào tháng 9 năm 2021 bởi OpenAI và cung cấp năng lượng cho GitHub Copilot– một AI pair programmer tạo ra toàn bộ đoạn mã, cho trước một mô tả ngôn ngữ tự nhiên làm prompt. Vì một phần lớn các nghiên cứu được thu thập của chúng tôi liên quan đến mã nguồn (ví dụ: sửa chữa, tạo unit test case), không có gì ngạc nhiên khi các nhà nghiên cứu chọn Codex làm LLM trong việc hỗ trợ họ hoàn thành các tác vụ liên quan đến lập trình.

LLM xếp hạng thứ ba là CodeT5, một LLM mã nguồn mở được phát triển bởi salesforce. Nhờ mã nguồn mở của nó, các nhà nghiên cứu có thể dễ dàng tiến hành đào tạo trước và fine-tuning với dữ liệu cụ thể cho lĩnh vực để đạt được hiệu suất tốt hơn. Tương tự, CodeGen cũng là mã nguồn mở và xếp hạng tương đối cao hơn. Bên cạnh đó, đối với CodeT5 và CodeGen, có hơn một nửa các nghiên cứu liên quan liên quan đến các đánh giá thực nghiệm (sử dụng nhiều LLM), ví dụ: sửa chữa chương trình, tạo unit test case.

Đã có 14 nghiên cứu sử dụng GPT-4, xếp hạng thứ tư, được ra mắt vào tháng 3 năm 2023. Một số nghiên cứu trực tiếp sử dụng LLM hiện đại này của OpenAI, vì nó thể hiện hiệu suất xuất sắc trên một loạt các tác vụ tạo sinh và lý luận. Ví dụ, Xie và cộng sự sử dụng GPT-4 để tạo đầu vào fuzzing, trong khi Vikram và cộng sự sử dụng nó để tạo property-based test với sự hỗ trợ của tài liệu API. Ngoài ra, một số nghiên cứu tiến hành thử nghiệm sử dụng cả GPT-4 và ChatGPT hoặc các LLM khác để cung cấp đánh giá toàn diện hơn về hiệu suất của những mô hình này. Trong kỹ thuật penetration testing tự động được hỗ trợ bởi LLM được đề xuất của họ, Deng và cộng sự thấy rằng GPT-4 vượt trội so với ChatGPT và LaMDA từ Google. Tương tự, Zhang và cộng sự thấy rằng GPT-4 thể hiện ưu thế hiệu suất so với ChatGPT khi tạo các fuzz driver với cả các chiến lược truy vấn cơ bản và nâng cao. Hơn nữa, GPT-4, như một LLM đa phương thức, tự phân biệt với các LLM khác đã đề cập bằng cách thể hiện các khả năng bổ sung như tạo ra các câu chuyện hình ảnh và trả lời các câu hỏi dựa trên hình ảnh. Tuy nhiên chúng tôi chưa gặp bất kỳ nghiên cứu nào khám phá việc sử dụng các tính năng liên quan đến hình ảnh của GPT-4 (ví dụ: ảnh chụp màn hình UI, screencast lập trình) trong các tác vụ kiểm thử phần mềm.

5.2 Các Loại Kỹ thuật Prompt Engineering

Như được hiển thị trong Hình 7, trong số các nghiên cứu được thu thập của chúng tôi, 38 nghiên cứu sử dụng LLM thông qua lược đồ đào tạo trước hoặc fine-tuning, trong khi 64 nghiên cứu sử dụng kỹ thuật prompt engineering để giao tiếp với LLM nhằm điều hướng hành vi của nó để đạt được kết quả mong muốn mà không cập nhật trọng số mô hình. Khi sử dụng các LLM sớm, hiệu suất của chúng có thể không ấn tượng lắm, vì vậy các nhà nghiên cứu thường sử dụng các kỹ thuật đào tạo trước hoặc fine-tuning để điều chỉnh các mô hình cho các lĩnh vực và tác vụ cụ thể nhằm cải thiện hiệu suất của chúng. Sau đó với việc nâng cấp công nghệ LLM, đặc biệt với việc giới thiệu GPT-3 và các LLM sau này, kiến thức chứa trong các mô hình và khả năng hiểu biết/suy luận của chúng đã tăng lên đáng kể. Do đó, các nhà nghiên cứu thường sẽ dựa vào kỹ thuật prompt engineering để xem xét cách thiết kế các prompt phù hợp để kích thích kiến thức của mô hình.

Trong số 64 nghiên cứu với kỹ thuật prompt engineering, 51 nghiên cứu liên quan đến zero-shot learning, và 25 nghiên cứu liên quan đến few-shot learning (một nghiên cứu có thể liên quan đến nhiều loại). Cũng có những nghiên cứu liên quan đến chain-of-thought (7 nghiên cứu), self-consistency (1 nghiên cứu), và automatic prompt (1 nghiên cứu).

Zero-shot learning là đơn giản cung cấp văn bản tác vụ cho mô hình và yêu cầu kết quả. Nhiều nghiên cứu được thu thập sử dụng Codex, CodeT5, và CodeGen (như được hiển thị trong Phần 5.1), đã được đào tạo trên mã nguồn. Do đó, đối với các tác vụ xử lý mã nguồn như tạo unit test case và sửa chữa chương trình như đã thể hiện trong các phần trước, việc truy vấn LLM trực tiếp với prompt là thực hành phổ biến. Có hai loại cách thức zero-shot learning chung, tức là có và không có hướng dẫn. Ví dụ, Xie và cộng sự sẽ cung cấp cho LLM các hướng dẫn như "xin hãy giúp tôi tạo ra một JUnit test cho một phương thức Java cụ thể ..." để tạo điều kiện cho việc tạo unit test case. Ngược lại, Siddiq và cộng sự chỉ cung cấp header mã của unit test case (ví dụ: "class ${className}${suffix}Test {"), và LLM sẽ thực hiện việc tạo unit test case tự động. Nói chung, các prompt với hướng dẫn rõ ràng sẽ mang lại kết quả chính xác hơn, trong khi các prompt không có hướng dẫn thường phù hợp cho các tình huống rất cụ thể.

Few-shot learning trình bày một tập các minh chứng chất lượng cao, mỗi cái bao gồm cả đầu vào và đầu ra mong muốn, trên tác vụ mục tiêu. Khi mô hình đầu tiên nhìn thấy các ví dụ, nó có thể hiểu ý định con người và tiêu chí cho những loại câu trả lời được mong muốn tốt hơn, điều này đặc biệt quan trọng đối với các tác vụ không quá đơn giản hoặc trực quan đối với LLM. Ví dụ, khi tiến hành tạo test tự động từ báo cáo lỗi chung, Kang và cộng sự cung cấp các ví dụ về báo cáo lỗi (câu hỏi) và các test tái tạo lỗi tương ứng (câu trả lời) cho LLM, và kết quả của họ cho thấy hai ví dụ có thể đạt được hiệu suất cao nhất so với không có ví dụ hoặc số lượng ví dụ khác. Một ví dụ khác về tạo test assertion, Nashid và cộng sự cung cấp các minh chứng về phương thức tiêu điểm, phương thức test chứa một <AssertPlaceholder>, và assertion mong đợi, cho phép LLM hiểu tác vụ tốt hơn.

Chain-of-thought (CoT) prompting tạo ra một chuỗi các câu ngắn để mô tả logic lý luận từng bước (còn được gọi là chuỗi lý luận hoặc lý lẽ) cho LLM để tạo ra câu trả lời cuối cùng. Ví dụ, đối với sửa chữa chương trình từ mô tả issue ngôn ngữ tự nhiên, cho trước mã lỗi và báo cáo issue, các tác giả đầu tiên yêu cầu LLM định vị lỗi, và sau đó họ yêu cầu nó giải thích tại sao các dòng được định vị lại lỗi, cuối cùng, họ yêu cầu LLM sửa lỗi. Một ví dụ khác là để tạo ra các chương trình bất thường cho fuzzing thư viện deep learning, Deng và cộng sự đầu tiên tạo ra một "lỗi" có thể (mô tả lỗi) trước khi tạo ra đoạn mã "kích hoạt lỗi" thực tế gọi API mục tiêu. Mô tả lỗi được dự đoán cung cấp một gợi ý bổ sung cho LLM, chỉ ra rằng mã được tạo ra nên cố gắng bao phủ hành vi lỗi tiềm ẩn cụ thể.

Self-consistency liên quan đến việc đánh giá tính nhất quán và nhất quán của các phản hồi của LLM trên cùng đầu vào trong các ngữ cảnh khác nhau. Có một nghiên cứu với loại prompt này, và nó liên quan đến gỡ lỗi. Kang và cộng sự sử dụng một vòng lặp hypothesize-observe-conclude, đầu tiên tạo ra một giả thuyết về lỗi là gì và xây dựng một thí nghiệm để xác minh, sử dụng một LLM, sau đó quyết định xem giả thuyết có đúng dựa trên kết quả thí nghiệm hay không (với một debugger hoặc thực thi mã) sử dụng một LLM, sau đó, tùy thuộc vào kết luận, nó hoặc bắt đầu với một giả thuyết mới hoặc chọn chấm dứt quá trình gỡ lỗi và tạo ra một bản sửa.

Automatic prompt nhằm mục đích tự động tạo ra và lựa chọn hướng dẫn phù hợp cho LLM, thay vì yêu cầu người dùng kỹ thuật prompt thủ công. Xia và cộng sự giới thiệu một bước auto-prompting tự động chưng cất tất cả đầu vào do người dùng cung cấp thành một prompt ngắn gọn và hiệu quả cho fuzzing. Cụ thể, họ đầu tiên tạo ra một danh sách các prompt ứng viên bằng cách kết hợp các đầu vào của người dùng và hướng dẫn auto prompting trong khi đặt LLM ở nhiệt độ cao, sau đó một thí nghiệm fuzzing quy mô nhỏ được tiến hành để đánh giá từng prompt ứng viên, và cái tốt nhất được chọn.

Lưu ý rằng có mười bốn nghiên cứu áp dụng thiết kế prompt lặp đi lặp lại khi sử dụng zero-shot hoặc few-shot learning, trong đó cách tiếp cận liên tục tinh chỉnh các prompt với thông tin chạy của tác vụ kiểm thử, ví dụ: thông tin thất bại test. Ví dụ, đối với sửa chữa chương trình, Xia và cộng sự xen kẽ việc tạo patch với phản hồi xác thực test để nhắc tạo sinh tương lai lặp đi lặp lại. Chi tiết, họ kết hợp thông tin khác nhau từ một test thất bại bao gồm tên của nó, (các) dòng mã liên quan kích hoạt thất bại test, và thông báo lỗi được tạo ra trong vòng nhắc tiếp theo có thể giúp mô hình hiểu lý do thất bại và cung cấp hướng dẫn hướng tới việc tạo ra bản sửa đúng. Một ví dụ khác là cho kiểm thử GUI di động, Liu và cộng sự lặp đi lặp lại truy vấn LLM về thao tác (ví dụ: nhấp nút, nhập văn bản) được tiến hành trong ứng dụng di động, và tại mỗi lần lặp, họ sẽ cung cấp cho LLM thông tin ngữ cảnh hiện tại như trang GUI và widget nào vừa được khám phá.

Ánh xạ giữa các tác vụ kiểm thử và cách LLM được sử dụng. Hình 8 thể hiện ánh xạ giữa các tác vụ kiểm thử (được đề cập trong Phần 4) và cách LLM được sử dụng (như được giới thiệu trong phần này). Tạo unit test case và sửa chữa chương trình chia sẻ các mẫu tương tự của việc giao tiếp với LLM, vì cả hai tác vụ đều liên quan chặt chẽ đến mã nguồn. Thông thường, các nhà nghiên cứu sử dụng các phương pháp đào tạo trước và/hoặc fine-tuning và zero-shot learning cho hai tác vụ này. Zero-shot learning phù hợp vì những tác vụ này tương đối đơn giản và có thể được LLM hiểu dễ dàng. Hơn nữa, vì dữ liệu đào tạo cho hai tác vụ này có thể được thu thập tự động từ các kho mã nguồn, các phương pháp đào tạo trước và/hoặc fine-tuning được sử dụng rộng rãi cho hai tác vụ này, có thể nâng cao hiểu biết của LLM về kiến thức cụ thể cho lĩnh vực.

So sánh với đó, đối với tạo đầu vào test hệ thống, các phương pháp zero-shot learning và few-shot learning thường được sử dụng. Điều này có thể là do tác vụ này thường liên quan đến việc tạo ra các loại đầu vào cụ thể, và các minh chứng trong few-shot learning có thể hỗ trợ LLM hiểu tốt hơn những gì nên được tạo ra. Bên cạnh đó, đối với tác vụ này, việc sử dụng các phương pháp đào tạo trước và/hoặc fine-tuning không phổ biến như trong tạo unit test case và sửa chữa chương trình. Điều này có thể được quy cho thực tế rằng dữ liệu đào tạo cho kiểm thử hệ thống khác nhau trên các phần mềm khác nhau và tương đối thách thức để thu thập tự động.

5.3 Đầu vào của LLM

Chúng tôi cũng thấy rằng các tác vụ kiểm thử khác nhau hoặc phần mềm được kiểm thử có thể liên quan đến đầu vào đa dạng khi truy vấn LLM, như được thể hiện trong Hình 9.

Đầu vào được sử dụng phổ biến nhất là mã nguồn vì một phần lớn các nghiên cứu được thu thập liên quan đến sửa chữa chương trình hoặc tạo unit test case có đầu vào là mã nguồn. Đối với tạo unit test case, thông tin liên quan đến mã điển hình sẽ là (i) phương thức tiêu điểm hoàn chỉnh, bao gồm chữ ký và thân; (ii) tên của lớp tiêu điểm (tức là lớp mà phương thức tiêu điểm thuộc về); (iii) trường trong lớp tiêu điểm; và (iv) chữ ký của tất cả các phương thức được định nghĩa trong lớp tiêu điểm. Đối với sửa chữa chương trình, có thể có các thiết lập khác nhau và liên quan đến các đầu vào khác nhau, bao gồm (i) nhập một hàm lỗi với mục tiêu đầu ra hàm đã được patch, (ii) nhập vị trí lỗi với mục tiêu tạo ra mã thay thế đúng (có thể là thay đổi một dòng) cho trước prefix và suffix của hàm lỗi. Bên cạnh đó, có thể có các biến thể cho đầu vào vị trí lỗi, tức là (i) không chứa các dòng lỗi (nhưng vị trí lỗi vẫn được biết), (ii) đưa các dòng lỗi như các dòng comment.

Cũng có 12 nghiên cứu lấy mô tả lỗi làm đầu vào cho LLM. Ví dụ, Kang và cộng sự lấy mô tả lỗi làm đầu vào khi truy vấn LLM và để LLM tạo ra các test case tái tạo lỗi. Fakhoury và cộng sự nhập mô tả ngôn ngữ tự nhiên của lỗi vào LLM, và tạo ra các bản sửa mã đúng.

Có 7 nghiên cứu sẽ cung cấp thông tin lỗi trung gian, ví dụ: thông tin thất bại test, cho LLM, và sẽ tiến hành prompt lặp đi lặp lại (như được mô tả trong Phần 5.2) để làm phong phú ngữ cảnh được cung cấp cho LLM. Những nghiên cứu này liên quan đến tạo unit test case và sửa chữa chương trình, vì trong những kịch bản này, thông tin chạy có thể được thu thập dễ dàng.

Khi kiểm thử ứng dụng di động, vì LLM được sử dụng không thể hiểu hình ảnh của trang GUI, tệp view hierarchy biểu diễn chi tiết của trang GUI thường hoạt động như đầu vào cho LLM. Tuy nhiên, với sự xuất hiện của GPT-4 là một mô hình đa phương thức và chấp nhận cả đầu vào hình ảnh và văn bản cho đầu vào mô hình, ảnh chụp màn hình GUI có thể được sử dụng trực tiếp cho đầu vào của LLM.

5.4 Kết hợp Các Kỹ thuật Khác với LLM

Có những ý kiến chia rẽ về việc liệu LLM đã đạt đến trạng thái toàn năng không yêu cầu kỹ thuật nào khác. Như được hiển thị trong Hình 10, trong số các nghiên cứu được thu thập của chúng tôi, 67 trong số họ sử dụng LLM để giải quyết toàn bộ tác vụ kiểm thử, trong khi 35 nghiên cứu kết hợp các kỹ thuật bổ sung. Những kỹ thuật này bao gồm mutation testing, differential testing, kiểm tra cú pháp, phân tích chương trình, phân tích thống kê, v.v.

Lý do tại sao các nhà nghiên cứu vẫn chọn kết hợp LLM với các kỹ thuật khác có thể là vì, mặc dù thể hiện tiềm năng to lớn trong nhiều tác vụ khác nhau, LLM vẫn có những hạn chế như hiểu ngữ nghĩa mã và xử lý các cấu trúc chương trình phức tạp. Do đó, việc kết hợp LLM với các kỹ thuật khác tối ưu hóa điểm mạnh và điểm yếu của chúng để đạt được kết quả tốt hơn trong các kịch bản cụ thể. Ngoài ra, điều quan trọng cần lưu ý là trong khi LLM có khả năng tạo ra mã đúng, chúng có thể không nhất thiết tạo ra đủ test case để kiểm tra các trường hợp biên hoặc kịch bản hiếm. Đây là nơi mutation và các kỹ thuật kiểm thử khác phát huy tác dụng, vì chúng cho phép tạo ra mã đa dạng và phức tạp hơn có thể mô phỏng tốt hơn các kịch bản thực tế. Theo nghĩa này, một cách tiếp cận kiểm thử có thể kết hợp một sự kết hợp của các kỹ thuật khác nhau, bao gồm cả LLM và các chiến lược kiểm thử khác, để đảm bảo độ bao phủ và hiệu quả toàn diện.

LLM + phân tích thống kê. Vì LLM thường có thể tạo ra vô số đầu ra, việc sàng lọc thủ công và xác định đầu ra đúng có thể quá sức lao động. Do đó, các nhà nghiên cứu đã chuyển sang các kỹ thuật phân tích thống kê như xếp hạng và phân cụm để lọc hiệu quả qua đầu ra của LLM và cuối cùng có được kết quả chính xác hơn.

LLM + phân tích chương trình. Khi sử dụng LLM để hoàn thành các tác vụ như tạo unit test case và sửa chữa mã phần mềm, điều quan trọng cần xem xét là mã phần mềm vốn dĩ sở hữu thông tin cấu trúc, có thể không được LLM hiểu đầy đủ. Do đó, các nhà nghiên cứu thường sử dụng các kỹ thuật phân tích chương trình, bao gồm cây cú pháp trừu tượng mã (AST), để biểu diễn cấu trúc của mã hiệu quả hơn và tăng khả năng hiểu mã chính xác của LLM. Các nhà nghiên cứu cũng thực hiện việc phân tập dòng mã dựa trên cấu trúc để thu hẹp trọng tâm cho LLM, hoặc trích xuất ngữ cảnh mã bổ sung từ các tệp mã khác, để cho phép các mô hình tập trung vào thông tin liên quan nhất đến tác vụ trong codebase và dẫn đến các dự đoán chính xác hơn.

LLM + mutation testing. Nó chủ yếu nhắm đến việc tạo ra các đầu vào test đa dạng hơn. Ví dụ, Deng và cộng sự đầu tiên sử dụng LLM để tạo ra các chương trình seed (ví dụ: đoạn mã sử dụng API DL mục tiêu) cho fuzzing thư viện deep learning. Để làm phong phú pool của những chương trình test này, họ thay thế các phần của chương trình seed bằng các token được che sử dụng các toán tử đột biến (ví dụ: thay thế các đối số gọi API bằng span token) để tạo ra các đầu vào được che, và một lần nữa sử dụng LLM để thực hiện code infilling để tạo ra mã mới thay thế các token được che.

LLM + kiểm tra cú pháp. Mặc dù LLM đã thể hiện hiệu suất đáng kể trong nhiều tác vụ xử lý ngôn ngữ tự nhiên khác nhau, mã được tạo ra từ những mô hình này đôi khi có thể không đúng cú pháp, dẫn đến lỗi tiềm ẩn và giảm khả năng sử dụng. Do đó, các nhà nghiên cứu đã đề xuất tận dụng kiểm tra cú pháp để xác định và sửa lỗi trong mã được tạo ra. Ví dụ, trong công trình của họ về tạo unit test case, Alagarsamy và cộng sự bổ sung giới thiệu một phương pháp xác minh để kiểm tra và sửa chữa tính nhất quán đặt tên (tức là sửa tên phương thức test để nhất quán với tên phương thức tiêu điểm) và chữ ký test (tức là thêm từ khóa thiếu như public, void, hoặc chú thích @test). Xie và cộng sự cũng xác thực unit test case được tạo ra và sử dụng sửa chữa dựa trên quy tắc để sửa lỗi cú pháp và lỗi biên dịch đơn giản.

LLM + differential testing. Differential testing rất phù hợp để tìm lỗi ngữ nghĩa hoặc logic không thể hiện hành vi sai rõ ràng như crash hoặc thất bại assertion. Trong danh mục này của các nghiên cứu được thu thập của chúng tôi, LLM chủ yếu chịu trách nhiệm tạo ra các đầu vào hợp lệ và đa dạng, trong khi differential testing giúp xác định xem có lỗi được kích hoạt dựa trên đầu ra của phần mềm hay không. Ví dụ, Ye và cộng sự đầu tiên sử dụng LLM để tạo ra các chương trình JavaScript ngẫu nhiên, và tận dụng tài liệu đặc tả ngôn ngữ để tạo dữ liệu test, sau đó tiến hành differential testing trên các JavaScript engine như JavaScriptCore, ChakraCore, SpiderMonkey, QuickJS, v.v. Cũng có những nghiên cứu sử dụng LLM để tạo ra đầu vào test và sau đó tiến hành differential testing để fuzzing thư viện DL và SAT solver. Li và cộng sự sử dụng LLM trong việc tìm các test case gây ra lỗi. Chi tiết, cho trước một chương trình được kiểm thử, họ đầu tiên yêu cầu LLM suy luận ý định của chương trình, sau đó yêu cầu LLM tạo ra các chương trình có cùng ý định, là các triển khai thay thế của chương trình, và có khả năng không có lỗi của chương trình. Sau đó họ thực hiện differential testing với chương trình được kiểm thử và các chương trình được tạo ra để tìm các test case gây ra lỗi.

6 THÁCH THỨC VÀ CƠ HỘI

Dựa trên phân tích trên từ quan điểm kiểm thử phần mềm và LLM, chúng tôi tóm tắt các thách thức và cơ hội khi tiến hành kiểm thử phần mềm với LLM.

6.1 Thách thức

Như được chỉ ra bởi khảo sát này, kiểm thử phần mềm với LLM đã trải qua sự tăng trưởng đáng kể trong hai năm qua. Tuy nhiên, nó vẫn đang trong giai đoạn đầu phát triển, và nhiều thách thức và câu hỏi mở cần được giải quyết.

6.1.1 Thách thức để Đạt được Độ bao phủ Cao

Khám phá các hành vi đa dạng của phần mềm được kiểm thử để đạt được độ bao phủ cao luôn là một mối quan tâm đáng kể trong kiểm thử phần mềm. Trong bối cảnh này, tạo test khác với tạo mã, vì tạo mã chủ yếu tập trung vào việc tạo ra một đoạn mã đúng duy nhất, trong khi kiểm thử phần mềm yêu cầu tạo ra các đầu vào test đa dạng để đảm bảo độ bao phủ tốt hơn của phần mềm. Mặc dù đặt nhiệt độ cao có thể tạo điều kiện cho LLM tạo ra các đầu ra khác nhau, vẫn thách thức đối với LLM để trực tiếp đạt được sự đa dạng cần thiết. Ví dụ, đối với tạo unit test case, trong tập dữ liệu SF110, độ bao phủ dòng chỉ là 2% và độ bao phủ nhánh chỉ là 1%. Đối với tạo đầu vào test hệ thống, về mặt fuzzing thư viện DL, độ bao phủ API cho TensorFlow được báo cáo là 66% (2215/3316).

Từ các nghiên cứu được thu thập của chúng tôi, chúng tôi quan sát thấy rằng các nhà nghiên cứu thường sử dụng mutation testing cùng với LLM để tạo ra các đầu ra đa dạng hơn. Ví dụ, khi fuzzing một thư viện DL, thay vì tạo ra đoạn mã trực tiếp với LLM, Deng và cộng sự thay thế các phần của seed đã chọn (mã được tạo ra bởi LLM) bằng các token được che sử dụng các toán tử đột biến khác nhau để tạo ra các đầu vào được che. Sau đó họ tận dụng LLM để thực hiện code infilling để tạo ra mã mới thay thế các token được che, có thể tăng đáng kể sự đa dạng của các test được tạo ra. Liu và cộng sự tận dụng LLM để tạo ra các bộ tạo test (mỗi cái có thể tạo ra một lô đầu vào văn bản bất thường dưới cùng quy tắc đột biến) cùng với các quy tắc đột biến cho fuzzing định hướng văn bản, giảm nỗ lực con người cần thiết để thiết kế các quy tắc đột biến.

Một hướng nghiên cứu tiềm năng có thể liên quan đến việc sử dụng dữ liệu cụ thể cho kiểm thử để đào tạo hoặc fine-tune một LLM chuyên biệt được thiết kế đặc biệt để hiểu bản chất của kiểm thử. Bằng cách làm như vậy, LLM có thể vốn dĩ thừa nhận các yêu cầu của kiểm thử và tự động tạo ra các đầu ra đa dạng.

6.1.2 Thách thức trong Vấn đề Test Oracle

Vấn đề oracle đã là một thách thức lâu dài trong nhiều ứng dụng kiểm thử khác nhau, ví dụ: kiểm thử hệ thống machine learning và kiểm thử thư viện deep learning. Để giảm nhẹ vấn đề oracle đối với các hoạt động kiểm thử tổng thể, một thực hành phổ biến trong các nghiên cứu được thu thập của chúng tôi là chuyển đổi nó thành một hình thức dễ rút ra hơn, thường bằng cách sử dụng differential testing hoặc chỉ tập trung vào việc xác định lỗi crash.

Có những ứng dụng thành công của differential testing với LLM, như được hiển thị trong Hình 10. Chẳng hạn, khi kiểm thử SMT solver, Sun và cộng sự áp dụng differential testing bao gồm việc so sánh kết quả của nhiều SMT solver (tức là Z3, cvc5, và Bitwuzla) trên cùng các công thức test được tạo ra bởi LLM. Tuy nhiên, cách tiếp cận này bị hạn chế đối với các hệ thống nơi phần mềm đối tác hoặc môi trường chạy có thể dễ dàng được tìm thấy, có thể hạn chế khả năng áp dụng của nó. Hơn nữa, để giảm nhẹ vấn đề oracle, các nghiên cứu khác chỉ tập trung vào các lỗi crash dễ quan sát tự động. Điều này đặc biệt là trường hợp đối với kiểm thử ứng dụng di động, trong đó LLM hướng dẫn kiểm thử trong việc khám phá nhiều trang đa dạng hơn, tiến hành các hành động vận hành phức tạp hơn, và bao phủ các chuỗi vận hành có ý nghĩa hơn. Tuy nhiên, điều này hạn chế đáng kể tiềm năng của việc sử dụng LLM để khám phá nhiều loại lỗi phần mềm khác nhau.

Khám phá việc sử dụng LLM để rút ra các loại test oracle khác đại diện cho một hướng nghiên cứu thú vị và có giá trị. Cụ thể, metamorphic testing cũng được sử dụng rộng rãi trong thực hành kiểm thử phần mềm để giúp giảm nhẹ vấn đề oracle, tuy nhiên trong hầu hết các trường hợp, việc định nghĩa các mối quan hệ metamorphic dựa vào sự khéo léo của con người. Luu và cộng sự đã kiểm tra hiệu quả của LLM trong việc tạo ra các mối quan hệ metamorphic, tuy nhiên họ chỉ thử nghiệm với các prompt đơn giản bằng cách truy vấn ChatGPT trực tiếp. Khám phá sâu hơn, có thể kết hợp tương tác người-máy tính hoặc kiến thức lĩnh vực, được khuyến khích cao. Một hướng đầy hứa hẹn khác là khám phá khả năng của LLM để tự động tạo ra các test case dựa trên các mối quan hệ metamorphic, bao phủ một loạt đầu vào rộng.

Sự tiến bộ của các LLM đa mô hình như GPT-4 có thể mở ra khả năng khám phá khả năng của chúng để phát hiện lỗi trong giao diện người dùng phần mềm và hỗ trợ rút ra các test oracle. Bằng cách tận dụng khả năng hiểu hình ảnh và lý luận của những mô hình này, có thể điều tra tiềm năng của chúng để tự động xác định sự không nhất quán, lỗi, hoặc vấn đề khả năng sử dụng trong giao diện người dùng.

6.1.3 Thách thức cho Đánh giá Nghiêm ngặt

Việc thiếu các tập dữ liệu benchmark và các vấn đề rò rỉ dữ liệu tiềm ẩn liên quan đến các kỹ thuật dựa trên LLM đặt ra những thách thức trong việc tiến hành đánh giá nghiêm ngặt và so sánh toàn diện các phương pháp được đề xuất.

Đối với sửa chữa chương trình, chỉ có hai benchmark nổi tiếng và thường được sử dụng, tức là Defect4J và QuixBugs, như được thể hiện trong Bảng 4. Hơn nữa, những tập dữ liệu này không được thiết kế đặc biệt để kiểm thử LLM. Ví dụ, như được báo cáo bởi Xia và cộng sự, 39 trong số 40 lỗi Python trong tập dữ liệu QuixBugs có thể được sửa bởi Codex, tuy nhiên trong thực hành thực tế, tỷ lệ sửa thành công có thể không đạt mức cao như vậy. Đối với tạo unit test case, không có benchmark được công nhận rộng rãi, và các nghiên cứu khác nhau sẽ sử dụng các tập dữ liệu khác nhau để đánh giá hiệu suất, như được thể hiện trong Bảng 3. Điều này chỉ ra nhu cầu xây dựng các benchmark chuyên biệt và đa dạng hơn.

Hơn nữa, LLM có thể đã thấy các benchmark được sử dụng rộng rãi trong dữ liệu đào tạo trước của chúng, tức là các vấn đề rò rỉ dữ liệu. Jiang và cộng sự kiểm tra CodeSearchNet và BigQuery, là các nguồn dữ liệu của các LLM phổ biến, và kết quả cho thấy bốn kho được sử dụng bởi benchmark Defect4J cũng có trong CodeSearchNet, và toàn bộ kho Defects4J được bao gồm bởi BigQuery. Do đó, rất có khả năng các benchmark sửa chữa chương trình hiện tại được LLM nhìn thấy trong quá trình đào tạo trước. Vấn đề rò rỉ dữ liệu này cũng đã được điều tra trong các nghiên cứu liên quan đến machine learning. Ví dụ, Tu và cộng sự tập trung vào rò rỉ dữ liệu trong dữ liệu theo dõi issue, và kết quả cho thấy thông tin bị rò rỉ từ "tương lai" làm cho các mô hình dự đoán lạc quan một cách gây hiểu lầm. Điều này nhắc nhở chúng ta rằng hiệu suất của LLM trên các tác vụ kiểm thử phần mềm có thể không tốt như được báo cáo trong các nghiên cứu trước. Nó cũng gợi ý rằng chúng ta cần các tập dữ liệu chuyên biệt hơn mà LLM chưa nhìn thấy để phục vụ như benchmark. Một cách là thu thập nó từ các nguồn chuyên biệt, ví dụ: nội dung do người dùng tạo ra từ các cộng đồng trực tuyến thích hợp.

6.1.4 Thách thức trong Ứng dụng Thực tế của LLM trong Kiểm thử Phần mềm

Như chúng tôi đã đề cập trong Phần 5.2, trong những ngày đầu sử dụng LLM, đào tạo trước và fine-tuning là thực hành thường được sử dụng, xem xét các tham số mô hình tương đối ít dẫn đến khả năng mô hình yếu hơn (ví dụ: T5). Theo thời gian, số lượng tham số mô hình tăng lên đáng kể, dẫn đến sự xuất hiện của các mô hình với khả năng lớn hơn (ví dụ: ChatGPT). Và trong các nghiên cứu gần đây, kỹ thuật prompt engineering đã trở thành một cách tiếp cận phổ biến. Tuy nhiên, do lo ngại về quyền riêng tư dữ liệu, khi xem xét thực hành thực tế, hầu hết các tổ chức phần mềm có xu hướng tránh sử dụng các LLM thương mại và sẽ thích áp dụng những LLM mã nguồn mở với đào tạo hoặc fine-tuning sử dụng dữ liệu cụ thể cho tổ chức. Hơn nữa, một số công ty cũng xem xét những hạn chế hiện tại về sức mạnh tính toán hoặc chú ý chặt chẽ đến tiêu thụ năng lượng, họ có xu hướng fine-tune các mô hình cỡ trung bình. Khá thách thức đối với những mô hình này để đạt được hiệu suất tương tự như những gì các bài báo được thu thập của chúng tôi đã báo cáo. Chẳng hạn, trong tập dữ liệu QuixBugs được sử dụng rộng rãi, đã được báo cáo rằng 39 trong số 40 lỗi Python và 34 trong số 40 lỗi Java có thể được sửa tự động. Tuy nhiên, khi đến với các chương trình DL được thu thập từ Stack Overflow, đại diện cho thực hành lập trình thực tế, chỉ 16 trong số 72 lỗi Python có thể được sửa tự động.

Nghiên cứu gần đây đã làm nổi bật tầm quan trọng của dữ liệu đào tạo chất lượng cao trong việc cải thiện hiệu suất của các mô hình cho các tác vụ liên quan đến mã, tuy nhiên việc xây dựng thủ công các tập dữ liệu chất lượng cao cụ thể cho tổ chức để đào tạo hoặc fine-tuning tốn thời gian và lao động. Để giải quyết điều này, người ta được khuyến khích sử dụng các kỹ thuật tự động của khai thác kho phần mềm để xây dựng các tập dữ liệu, ví dụ: các kỹ thuật trích xuất thông tin chính từ Stack Overflow cung cấp các giải pháp tiềm năng để tự động thu thập dữ liệu liên quan.

Ngoài ra, khám phá phương pháp để fine-tune LLM tốt hơn với dữ liệu cụ thể cho phần mềm đáng để xem xét vì dữ liệu cụ thể cho phần mềm khác với dữ liệu ngôn ngữ tự nhiên vì nó chứa nhiều thông tin cấu trúc hơn, chẳng hạn như data flow và control flow. Nghiên cứu trước đây về biểu diễn mã đã chỉ ra lợi ích của việc kết hợp data flow, bắt giữ cấu trúc cấp ngữ nghĩa của mã và biểu diễn mối quan hệ giữa các biến về mặt "whether-value-comes-from". Những cái nhìn sâu sắc này có thể cung cấp hướng dẫn có giá trị để fine-tune LLM hiệu quả với dữ liệu cụ thể cho phần mềm.

6.2 Cơ hội

Cũng có nhiều cơ hội nghiên cứu trong kiểm thử phần mềm với LLM, có thể mang lại lợi ích lớn cho các developer, người dùng, và cộng đồng nghiên cứu. Mặc dù không nhất thiết là thách thức, những cơ hội này góp phần vào những tiến bộ trong kiểm thử phần mềm, mang lại lợi ích cho những người thực hành và cộng đồng nghiên cứu rộng lớn hơn.

6.2.1 Khám phá LLM trong Giai đoạn Đầu của Kiểm thử

Như được hiển thị trong Hình 4, LLM chưa được sử dụng trong giai đoạn đầu của kiểm thử, ví dụ: yêu cầu test, và lập kế hoạch test. Có thể có hai lý do chính đằng sau điều đó. Lý do đầu tiên là tính chủ quan trong các tác vụ kiểm thử giai đoạn đầu. Nhiều tác vụ trong giai đoạn đầu của kiểm thử, chẳng hạn như thu thập yêu cầu, tạo kế hoạch test, và đánh giá thiết kế, có thể liên quan đến các đánh giá chủ quan yêu cầu đầu vào đáng kể từ các chuyên gia con người. Điều này có thể làm cho nó ít phù hợp cho LLM dựa nhiều vào các cách tiếp cận dựa trên dữ liệu. Lý do thứ hai có thể là thiếu dữ liệu mã nguồn mở trong giai đoạn đầu. Khác với giai đoạn sau của kiểm thử, có thể có dữ liệu hạn chế có sẵn trực tuyến trong các hoạt động giai đoạn đầu. Điều này có thể có nghĩa là LLM có thể chưa nhìn thấy nhiều loại dữ liệu này, và do đó có thể không hoạt động tốt trên những tác vụ này.

Áp dụng lược đồ tương tác người-máy tính để giải quyết các tác vụ kiểm thử giai đoạn đầu sẽ khai thác kiến thức cụ thể cho lĩnh vực của các developer con người và tận dụng kiến thức chung được nhúng trong LLM. Ngoài ra, các công ty phát triển phần mềm được khuyến khích cao ghi lại và cung cấp quyền truy cập vào dữ liệu kiểm thử giai đoạn đầu, cho phép cải thiện đào tạo và hiệu suất của LLM trong những hoạt động kiểm thử quan trọng này.

6.2.2 Khám phá LLM trong Các Giai đoạn Kiểm thử Khác

Chúng tôi đã phân tích phân bố các giai đoạn kiểm thử cho các nghiên cứu được thu thập. Như được hiển thị trong Hình 11, chúng ta có thể quan sát thấy rằng LLM được sử dụng phổ biến nhất trong unit testing, tiếp theo là system testing. Tuy nhiên, vẫn chưa có nghiên cứu nào về việc sử dụng LLM trong integration testing và acceptance testing.

Đối với integration testing, nó liên quan đến việc kiểm thử các giao diện giữa các mô-đun phần mềm khác nhau. Trong một số tổ chức phần mềm, integration testing có thể được hợp nhất với unit testing, có thể là một lý do có thể tại sao LLM hiếm khi được sử dụng trong integration testing. Một lý do khác có thể là kích thước và độ phức tạp của dữ liệu đầu vào trong trường hợp này có thể vượt quá khả năng của LLM để xử lý và phân tích (ví dụ: mã nguồn của tất cả các mô-đun phần mềm liên quan), có thể dẫn đến lỗi hoặc kết quả không đáng tin cậy. Để giải quyết điều này, một tham khảo tiềm năng có thể được tìm thấy trong Phần 4.1, nơi Xie và cộng sự thiết kế một phương pháp để tổ chức thông tin cần thiết vào giới hạn token prompt tối đa được xác định trước của LLM. Hơn nữa, integration testing yêu cầu dữ liệu đa dạng được tạo ra để kiểm thử đầy đủ giao diện giữa nhiều mô-đun. Như đã đề cập trong Phần 4.3, công trình trước đây đã chứng minh khả năng của LLM trong việc tạo ra đầu vào test đa dạng cho system testing, kết hợp với các kỹ thuật mutation testing. Và những điều này có thể cung cấp cái nhìn sâu sắc về việc tạo ra dữ liệu giao diện đa dạng cho integration testing.

Acceptance testing thường được thực hiện bởi các nhà phân tích kinh doanh hoặc người dùng cuối để xác thực chức năng và khả năng sử dụng của hệ thống, yêu cầu nhiều ngôn ngữ phi kỹ thuật hơn và kiến thức cụ thể cho lĩnh vực, do đó làm cho việc áp dụng LLM hiệu quả trở nên thách thức. Vì acceptance testing liên quan đến con người, nó rất phù hợp cho việc sử dụng lược đồ human-in-the-loop với LLM. Điều này đã được nghiên cứu trong machine learning truyền thống, nhưng chưa được khám phá với LLM. Cụ thể, LLM có thể chịu trách nhiệm tự động tạo ra test case, đánh giá độ bao phủ test, v.v., trong khi các tester con người chịu trách nhiệm kiểm tra hành vi của chương trình và xác minh test oracle.

6.2.3 Khám phá LLM cho Nhiều Loại Phần mềm Hơn

Chúng tôi phân tích những loại phần mềm nào đã được khám phá trong các nghiên cứu được thu thập, như được hiển thị trong Hình 5. Lưu ý rằng, vì một phần lớn các nghiên cứu tập trung vào unit testing hoặc sửa chữa chương trình, chúng được tiến hành trên các tập dữ liệu có sẵn công khai và không liên quan đến các loại phần mềm cụ thể.

Từ phân tích trong Phần 4.3, LLM có thể tạo ra không chỉ mã nguồn để kiểm thử thư viện DL mà còn đầu vào văn bản để kiểm thử ứng dụng di động, thậm chí các mô hình để kiểm thử CPS. Nhìn chung, LLM cung cấp một khung linh hoạt và mạnh mẽ để tạo ra đầu vào test cho một loạt ứng dụng rộng. Tính linh hoạt của nó sẽ làm cho nó hữu ích để kiểm thử phần mềm trong các lĩnh vực khác.

Từ một quan điểm, một số kỹ thuật được đề xuất có thể được áp dụng cho các loại phần mềm khác. Ví dụ, trong bài báo được đề xuất để kiểm thử thư viện deep learning, vì nó đề xuất các kỹ thuật để tạo ra các chương trình DL đa dạng, phức tạp, và giống con người, các tác giả nói rằng cách tiếp cận có thể dễ dàng được mở rộng để kiểm thử các hệ thống phần mềm từ các lĩnh vực ứng dụng khác, ví dụ: interpreter, hệ thống cơ sở dữ liệu, và các thư viện phổ biến khác. Hơn thế nữa, đã có những nghiên cứu tập trung vào các kỹ thuật fuzzing toàn cầu được thiết kế để có thể thích ứng và áp dụng cho các loại đầu vào test và phần mềm khác nhau.

Từ quan điểm khác, các loại phần mềm khác cũng có thể được hưởng lợi từ khả năng của LLM để thiết kế các kỹ thuật kiểm thử phù hợp tốt hơn với lĩnh vực và đặc điểm cụ thể của chúng. Chẳng hạn, metaverse, với các môi trường ảo nhập vai và tương tác phức tạp, đặt ra những thách thức độc đáo cho kiểm thử phần mềm. LLM có thể được tận dụng để tạo ra các đầu vào đa dạng và thực tế mô phỏng hành vi và tương tác của người dùng trong metaverse, chưa bao giờ được khám phá.

6.2.4 Khám phá LLM cho Kiểm thử Phi chức năng

Trong các nghiên cứu được thu thập của chúng tôi, LLM chủ yếu được sử dụng cho kiểm thử chức năng, và không có thực hành nào trong kiểm thử hiệu suất, kiểm thử khả năng sử dụng hoặc khác. Một lý do có thể cho sự phổ biến của các giải pháp dựa trên LLM trong kiểm thử chức năng là chúng có thể chuyển đổi các vấn đề kiểm thử chức năng thành các vấn đề tạo mã hoặc tạo ngôn ngữ tự nhiên, mà LLM đặc biệt giỏi trong việc giải quyết.

Mặt khác, kiểm thử hiệu suất và kiểm thử khả năng sử dụng có thể yêu cầu các mô hình chuyên biệt hơn được thiết kế để phát hiện và phân tích các loại dữ liệu cụ thể, xử lý các phân tích thống kê phức tạp, hoặc xác định tiêu chí lỗi. Hơn nữa, đã có hàng chục công cụ kiểm thử hiệu suất (ví dụ: LoadRunner) có thể tạo ra một workload mô phỏng các kịch bản sử dụng thực tế và đạt được hiệu suất tương đối thỏa đáng.

Các cơ hội tiềm năng có thể để LLM tích hợp các công cụ kiểm thử hiệu suất và hoạt động như LangChain, để mô phỏng tốt hơn các loại workload khác nhau dựa trên hành vi người dùng thực. Hơn nữa, LLM có thể xác định các kết hợp và giá trị tham số có tiềm năng cao nhất để kích hoạt các vấn đề hiệu suất. Bản chất, đây là một cách để xếp hạng và ưu tiên các thiết lập tham số khác nhau dựa trên tác động của chúng đến hiệu suất và cải thiện hiệu quả của kiểm thử hiệu suất.

6.2.5 Khám phá Kỹ thuật Prompt Engineering Tiên tiến

Có tổng cộng 11 kỹ thuật prompt engineering thường được sử dụng như được liệt kê trong một hướng dẫn prompt engineering phổ biến, như được hiển thị trong Hình 12. Hiện tại, trong các nghiên cứu được thu thập của chúng tôi, chỉ có năm kỹ thuật đầu tiên đang được sử dụng. Các kỹ thuật tiên tiến hơn chưa được sử dụng, và có thể được khám phá trong tương lai để thiết kế prompt.

Chẳng hạn, multimodal chain of thought prompting liên quan đến việc sử dụng các tín hiệu cảm quan và nhận thức đa dạng để kích thích tư duy và sự sáng tạo trong LLM. Bằng cách cung cấp hình ảnh (ví dụ: ảnh chụp màn hình GUI) hoặc ghi âm liên quan đến phần mềm được kiểm thử có thể giúp LLM hiểu ngữ cảnh và các vấn đề tiềm ẩn của phần mềm tốt hơn. Bên cạnh đó, cố gắng nhắc LLM tưởng tượng bản thân trong các vai trò khác nhau, chẳng hạn như developer, người dùng, hoặc chuyên gia đảm bảo chất lượng. Bài tập chuyển đổi góc nhìn này cho phép LLM tiếp cận kiểm thử phần mềm từ nhiều quan điểm và khám phá các khía cạnh khác nhau có thể yêu cầu sự chú ý hoặc điều tra.

Graph prompting liên quan đến việc biểu diễn thông tin sử dụng đồ thị hoặc cấu trúc hình ảnh để tạo điều kiện cho hiểu biết và giải quyết vấn đề. Graph prompting có thể là một sự kết hợp tự nhiên với kỹ nghệ phần mềm, xem xét nó liên quan đến nhiều phụ thuộc khác nhau, control flow, data flow, chuyển đổi trạng thái, hoặc cấu trúc đồ thị liên quan khác. Graph prompting có thể có lợi trong việc phân tích thông tin cấu trúc này, và cho phép LLM hiểu phần mềm được kiểm thử hiệu quả. Chẳng hạn, các tester có thể sử dụng graph prompt để hình dung độ bao phủ test, xác định các khu vực hoặc đường dẫn chưa được kiểm thử, và đảm bảo thực thi test đầy đủ.

6.2.6 Kết hợp LLM với Các Kỹ thuật Truyền thống

Hiện tại không có sự đồng thuận rõ ràng về mức độ mà LLM có thể giải quyết các vấn đề kiểm thử phần mềm. Từ phân tích trong Phần 5.4, chúng ta đã thấy một số kết quả đầy hứa hẹn từ các nghiên cứu đã kết hợp LLM với các kỹ thuật kiểm thử phần mềm truyền thống. Điều này ngụ ý rằng LLM không phải là giải pháp toàn diện duy nhất cho kiểm thử phần mềm. Xem xét sự sẵn có của nhiều kỹ thuật và công cụ kiểm thử phần mềm trưởng thành, và khả năng hạn chế của LLM, cần thiết phải khám phá các cách khác tốt hơn để kết hợp LLM với các kỹ thuật kiểm thử truyền thống hoặc phân tích chương trình và công cụ để kiểm thử phần mềm tốt hơn.

Dựa trên các nghiên cứu được thu thập, LLM đã được sử dụng thành công cùng với nhiều kỹ thuật khác nhau như differential testing (ví dụ:), mutation testing (ví dụ:), phân tích chương trình (ví dụ:), như được hiển thị trong Hình 10. Từ một góc độ, các nghiên cứu tương lai có thể khám phá việc tích hợp cải tiến của những kỹ thuật truyền thống này với LLM. Lấy mutation testing làm ví dụ, các thực hành hiện tại chủ yếu dựa vào các quy tắc đột biến được thiết kế bởi con người để đột biến các test ứng viên, và để LLM tái tạo các test mới, trong khi Liu và cộng sự trực tiếp sử dụng LLM để tạo ra các quy tắc đột biến cùng với các test đã đột biến. Các khám phá sâu hơn trong hướng này rất được quan tâm.

Từ quan điểm khác, nhiều kỹ thuật truyền thống hơn có thể được kết hợp trong LLM cho kiểm thử phần mềm. Chẳng hạn, bên cạnh các kỹ thuật truyền thống đã đề cập, LLM đã được kết hợp với xác minh chính thức cho phát hiện phần mềm tự chữa lành trong lĩnh vực bảo mật phần mềm. Nhiều nỗ lực hơn được khuyến khích. Hơn nữa, xem xét sự tồn tại của nhiều công cụ kiểm thử phần mềm trưởng thành, có thể khám phá việc tích hợp LLM với những công cụ này, cho phép chúng hoạt động như một "LangChain" để khám phá tốt hơn tiềm năng của những công cụ này.

7 CÔNG TRÌNH LIÊN QUAN

Đánh giá tài liệu có hệ thống là một cách quan trọng để có cái nhìn sâu sắc về xu hướng hiện tại và hướng tương lai trong một lĩnh vực cụ thể. Nó cho phép chúng ta hiểu và cập nhật những phát triển trong lĩnh vực đó.

Wang và cộng sự khảo sát các kỹ thuật machine learning và deep learning cho kỹ nghệ phần mềm. Yang và cộng sự và Watson và cộng sự tương ứng thực hiện các khảo sát về việc sử dụng deep learning trong lĩnh vực kỹ nghệ phần mềm. Bajammal và cộng sự khảo sát việc sử dụng các kỹ thuật thị giác máy tính để cải thiện các tác vụ kỹ nghệ phần mềm. Zhang và cộng sự cung cấp một khảo sát về các kỹ thuật kiểm thử hệ thống machine learning.

Với những tiến bộ của trí tuệ nhân tạo và LLM, các nhà nghiên cứu cũng tiến hành các đánh giá tài liệu có hệ thống về LLM, và ứng dụng của chúng trong nhiều lĩnh vực khác nhau (ví dụ: kỹ nghệ phần mềm). Zhao và cộng sự đánh giá những tiến bộ gần đây trong LLM bằng cách cung cấp một cái nhìn tổng quan về bối cảnh, những phát hiện chính, và các kỹ thuật chính của chúng. Họ tập trung vào bốn khía cạnh chính của LLM, cụ thể là đào tạo trước, điều chỉnh thích ứng, sử dụng, và đánh giá khả năng. Ngoài ra, họ tóm tắt các tài nguyên có sẵn để phát triển LLM và thảo luận các vấn đề còn lại cho hướng tương lai. Hou và cộng sự tiến hành một đánh giá tài liệu có hệ thống về việc sử dụng LLM cho kỹ nghệ phần mềm, với trọng tâm cụ thể là hiểu cách LLM có thể được khai thác để tối ưu hóa các quy trình và kết quả. Fan và cộng sự tiến hành một khảo sát về LLM cho kỹ nghệ phần mềm, và đặt ra những thách thức nghiên cứu mở cho việc áp dụng LLM vào các vấn đề kỹ thuật mà các kỹ sư phần mềm đối mặt. Zan và cộng sự tiến hành một khảo sát về các LLM hiện có cho tác vụ NL2Code (tức là tạo mã từ mô tả ngôn ngữ tự nhiên), và đánh giá các benchmark và thước đo.

Mặc dù những nghiên cứu này hoặc nhắm đến lĩnh vực kỹ nghệ phần mềm rộng hơn (với trọng tâm hạn chế vào các tác vụ kiểm thử phần mềm) hoặc tập trung vào các tác vụ phát triển phần mềm khác (loại trừ kiểm thử phần mềm), bài báo này tập trung cụ thể vào việc sử dụng LLM cho kiểm thử phần mềm. Nó khảo sát các nghiên cứu liên quan, tóm tắt các thách thức chính và cơ hội tiềm năng, và phục vụ như một lộ trình cho nghiên cứu tương lai trong lĩnh vực này.

8 KẾT LUẬN

Bài báo này cung cấp một đánh giá toàn diện về việc sử dụng LLM trong kiểm thử phần mềm. Chúng tôi đã phân tích các nghiên cứu liên quan đã sử dụng LLM trong kiểm thử phần mềm từ cả góc độ kiểm thử phần mềm và LLM. Bài báo này cũng làm nổi bật các thách thức và cơ hội tiềm năng trong hướng này. Kết quả của đánh giá này chứng minh rằng LLM đã được áp dụng thành công trong một loạt các tác vụ kiểm thử rộng, bao gồm tạo unit test case, tạo test oracle, tạo đầu vào test hệ thống, gỡ lỗi chương trình, và sửa chữa chương trình. Tuy nhiên, vẫn tồn tại các thách thức trong việc đạt được độ bao phủ kiểm thử cao, giải quyết vấn đề test oracle, tiến hành đánh giá nghiêm ngặt, và áp dụng LLM trong các kịch bản thực tế. Ngoài ra, quan sát được rằng LLM thường chỉ được sử dụng trong một phần của toàn bộ vòng đời kiểm thử, ví dụ: chúng chủ yếu được sử dụng trong giai đoạn giữa và cuối của kiểm thử, chỉ phục vụ các giai đoạn unit và system testing, và chỉ cho kiểm thử chức năng. Điều này làm nổi bật các cơ hội nghiên cứu để khám phá các khu vực chưa được bao phủ. Về cách LLM được sử dụng, chúng tôi thấy rằng nhiều phương pháp đào tạo trước/fine-tuning và prompt engineering khác nhau đã được phát triển để nâng cao khả năng của LLM trong việc giải quyết các tác vụ kiểm thử. Tuy nhiên, các kỹ thuật tiên tiến hơn trong thiết kế prompt chưa được khám phá và có thể là một hướng cho nghiên cứu tương lai.

Nó có thể phục vụ như một lộ trình cho nghiên cứu tương lai trong lĩnh vực này, xác định những khoảng trống trong hiểu biết hiện tại của chúng ta về việc sử dụng LLM trong kiểm thử phần mềm và làm nổi bật các hướng tiềm năng để khám phá. Chúng tôi tin rằng những cái nhìn sâu sắc được cung cấp trong bài báo này sẽ có giá trị đối với cả các nhà nghiên cứu và những người thực hành trong lĩnh vực kỹ nghệ phần mềm, hỗ trợ họ trong việc tận dụng LLM để cải thiện thực hành kiểm thử phần mềm và cuối cùng nâng cao chất lượng và độ tin cậy của các hệ thống phần mềm.

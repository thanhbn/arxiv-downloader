# 2401.00812.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/coding/2401.00812.pdf
# File size: 11878506 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
If LLM Is the Wizard, Then Code Is the Wand: A Survey on How
Code Empowers Large Language Models to Serve as Intelligent Agents
Ke Yang∗,Jiateng Liu∗,John Wu ,Chaoqi Yang ,Yi R. Fung ,Sha Li ,
Zixuan Huang ,Xu Cao ,Xingyao Wang ,Yiquan Wang ,Heng Ji ,Chengxiang Zhai
University of Illinois Urbana-Champaign
{key4, jiateng5, johnwu3, chaoqiy2, yifung2, shal2,
zixuan3, xucao2, xingyao6, yiquan2, hengji, czhai}@illinois.edu
Abstract
The prominent large language models (LLMs)
of today differ from past language models not
only in size, but also in the fact that they are
trained on a combination of natural language
and formal language (code). As a medium be-
tween humans and computers, code translates
high-level goals into executable steps, featuring
standard syntax, logical consistency, abstrac-
tion, and modularity. In this survey, we present
an overview of the various benefits of integrat-
ing code into LLMs’ training data. Specifically,
beyond enhancing LLMs in code generation,
we observe that these unique properties of code
help i)unlock the reasoning ability of LLMs,
enabling their applications to a range of more
complex natural language tasks; ii)steer LLMs
to produce structured and precise intermediate
steps, which can then be connected to external
execution ends through function calls; and iii)
take advantage of code compilation and execu-
tion environment, which also provides diverse
feedback for model improvement. In addition,
we trace how these profound capabilities of
LLMs, brought by code, have led to their emer-
gence as intelligent agents (IAs) in situations
where the ability to understand instructions, de-
compose goals, plan and execute actions, and
refine from feedback are crucial to their suc-
cess on downstream tasks. Finally, we present
several key challenges and future directions of
empowering LLMs and IAs with code.
1 Introduction
Code has become an integral component in the
training data of large language models (LLMs), in-
cluding well-known models such as Llama2, GPT-
3.5 series and GPT-4 (Touvron et al., 2023; Ye et al.,
2023a; OpenAI, 2023). Training LLMs on code
has gained popularity not only because the acquired
programming skills enable commercial applica-
tions, such as Github Copilot1, but also because it
∗*Equal contribution
1https://github.com/features/copilot.improves the models’ previously lacking reasoning
abilities (Liang et al., 2023b). Consequently, LLMs
rapidly emerge as a primary decision-making hub
for intelligent agents (IAs) (Zhao et al., 2023),
demonstrating an exponential growth in capabil-
ities from code training and the advancement of
tool learning (Qin et al., 2023). These LLM-based
IAs are poised to handle a wider range of more
complex tasks, including downstream applications
in multi-agent environment simulation (Wu et al.,
2023c) and AI for science (Boiko et al., 2023).
As depicted in Figure 1, this survey aims to
explain the widespread adoption of code-specific
training in the general LLM training paradigm and
how code enhances LLMs to act as IAs. Unlike
previous code-LLM surveys that concentrate on
either evaluating and comparing code generation
abilities (Zan et al., 2023; Xu et al., 2022), or list-
ing IA tasks (Wang et al., 2023d; Xi et al., 2023;
Zhao et al., 2023) in IA surveys, we aim to provide
a comprehensive understanding of how code assists
LLMs and where code benefits LLMs as IAs, based
on the taxonomy of relevant papers (see Figure 2).
We first provide our definition of code and
present typical methods for LLM code training (§2).
Compared to natural language (refer to the case
study in A.1), code is more structured, featuring
logical, step-by-step executable processes derived
from procedural programming, as well as explic-
itly defined, modularized functions, which com-
pose graphically representable abstractions. Addi-
tionally, code is typically accompanied by a self-
contained compilation and execution environment.
With insights from these characteristics of code,
our comprehensive literature review reveals that in-
tegrating code into LLM training i)enhances their
programming and reasoning capabilities (§3); ii)
enables the models to directly generate executable,
fine-grained steps during decision-making, thereby
facilitating their scalability in incorporating various
tool modules through function calls (§4); and iii)arXiv:2401.00812v2  [cs.CL]  8 Jan 2024

--- PAGE 2 ---
Figure 1: An illustration of how code empowers large language models (LLMs) and enhances their downstream
applications as intelligent agents (IAs). While traditional LLMs excel in conventional natural language tasks like
document classification and question answering, further pre-training or fine-tuning LLMs with human-interpretable
and machine-executable code serves as an additional power-up — akin to equipping wizards with mana-boosting
wands. This significantly boosts their performance as IAs through intricately woven operational steps.
situates the LLMs within a code execution envi-
ronment, allowing them to receive automated feed-
back from integrated evaluation modules and self-
improve (§5).
In addition, as LLMs are becoming key decision-
makers for IAs in complex real-world tasks, our sur-
vey also explores how these advantages facilitate
their functioning along this capacity (§6), in terms
ofi)enhancing IAs’ decision-making in percep-
tion and planning skills (§6.1), ii)facilitating their
execution through direct action primitive ground-
ing and modular memory organization (§6.2), and
iii)providing an interactive environment for self-
correction and self-improvement (§6.3). Finally,
we discuss several open challenges and promising
future directions (§7).
2 Preliminaries
2.1 Our Definition of Code
We consider code as any formal language that is
both machine-executable and human-interpretable.
For instance, human-readable programming lan-
guages fall within the scope of our discussion,
whereas low-level languages, such as machine lan-
guage based on binary instructions, are excluded
due to their lack of human interpretability. Ad-
ditionally, pre-defined formal languages, such as
function sets employed in WebGPT (Nakano et al.,
2021), are included as they can be parsed and exe-
cuted in a rule-based manner.LLMs trained with expressions formulated
within a defined set of symbols and rules (e.g.,
pre-defined function sets, mathematical deduction
formula, etc.), i.e., formal languages, exhibit ad-
vantages akin to those trained with programming
languages. Therefore, we expand our definition of
code to incorporate these homogeneous training
corpora, enhancing the comprehensiveness of this
survey to align with current research needs.
2.2 LLM Code Training Methods
LLMs undergo code training by following the
standard language modeling objective, applied to
code corpora. Given that code possesses natural
language-like sequential readability, this parallels
the approach to instruct LLMs in understanding
and generating free-form natural language.
Specifically, for an LLM MΘwith parameters Θ
and a code corpus T={t1, ..., t n}, the language
modeling loss for optimization is:
L(T) =X
ilogP(ti|ti−k, ..., t i−1; Θ)
When employing programming language (e.g.,
Python, C, etc.) as the corpus (Chen et al., 2021;
Li et al., 2022; Nijkamp et al., 2022), training data
is typically sourced from publicly accessible code
repositories, such as GitHub. This process yields
a corpus with a volume comparable to that of nat-
ural language pre-training, and thus we call train-
ing with such an abundance of code as code pre-
training . The training strategy entails either train-

--- PAGE 3 ---
How Code Empowers LLMs to Serve as IAsHow Code
Assists LLMsBoost LLMs’
Performance (§3)Strengthen LLMs’
Programming Skills
(§3.1)LLM as a Strong CoderAlphaCode (Li et al., 2022), SantaCoder (Allal et al., 2023), PolyCoder (Xu et al., 2022),
CodeX (Chen et al., 2021), CodeGen (Nijkamp et al., 2022)
LLM as a SOTA Code
EvaluatorAutoFill (Kang et al., 2023a), GPT-3.5Eval (Zhuo, 2023), PentestGPT (Deng et al., 2023a),
SkipAnalyzer (Mohajer et al., 2023), LIBRO (Kang et al., 2023b)
Collaboration Coding
Solves Complex TasksMetaGPT (Hong et al., 2023), ChatDev (Qian et al., 2023a), DyLAN (Liu et al., 2023g),
Autogen (Wu et al., 2023b), Self-planning (Jiang et al., 2023)
Empower LLMs’
Complex Reasoning
(§3.2)Enhancing Task Deco-
mposition with Chain
of ThoughtCode Training Improves LLM CoT (Fu and Khot, 2022), When to Train LLM On Code
(Ma et al., 2023a)
Program-of-ThoughtLM Decomposers (Ye et al., 2023b), PoT (Chen et al., 2023b), Pal (Gao et al., 2023)
LM Theorem Proving (Polu and Sutskever, 2020), LM Math Solving (Drori et al., 2022) ,
Binding LMs (Cheng et al., 2023), SelfzCoT (Lei and Deng, 2023)
Enhances LLMs in
Capturing Structured
Knowledge (§3.3)Commonsense Reason-
ing GraphCOCOGEN (Madaan et al., 2022), CODE4STRUCT (Wang et al., 2023f),
ViStruct (Chen et al., 2023d)
Visually Situated Natu-
ral LanguageWebGUM (Furuta et al., 2023), Pix2Struct (Lee et al., 2023), MATCHA (Liu et al., 2023a)
Connect LLMs to
Other Functional
Ends (§4)Relate LLMs to
Digital Ends (§4.1)Text-based ToolsTALM (Parisi et al., 2022a), Toolformer (Schick et al., 2023), ToolAlpaca (Tang et al., 2023),
Gorilla (Patil et al., 2023), RestGPT (Song et al., 2023), ToolkenGPT (Hao et al., 2023)
Multimodality ToolsHuggingGPT (Shen et al., 2023), VISPROG (Gupta and Kembhavi, 2023),
ViperGPT (Surís et al., 2023), TaskMatrix.AI (Liang et al., 2023d), VPGEN (Cho et al., 2023)
Relate LLMs to
Physical Ends (§4.2)ProgPrompt (Singh et al., 2022), Code-as-Policies (Liang et al., 2023a), V oxPoser (Huang et al., 2023a),
ChatGPT4Robotics (Vemprala et al., 2023), LaMPilot (Ma et al., 2023b), RRR (Cui et al., 2023a)
Provide LLM with
an Executable Envi-
ronment for Automa-
ted Feedback (§5)Feedbacks from
Code Execution
(§5.1)Ds-1000 (Lai et al., 2023), CodeRL (Le et al., 2022), Self-debugging(Chen et al., 2023c), Leti (Wang et al., 2023g)
Methods for Enhan-
cing LLM’s Perform-
ance with Feedback
(§5.2)Selection-based Meth. CODET (Chen et al., 2022), SRank (To et al., 2023), Lever (Ni et al., 2023)
Prompting-based Meth. Mint (Wang et al., 2023h), Self-Debugging (Chen et al., 2023c)
Finetuning-based Meth.Leti (Wang et al., 2023g), CodeRL (Le et al., 2022), CompCoder (Wang et al., 2022),
Self-edit (Zhang et al., 2023a), CodeScore (Dong et al., 2023a), ILF (Chen et al., 2023a)
How Code-
LLMs benefit
IAs (§6)Decision-making
(§6.1)Environment
PerceptionWebshopping (Yao et al., 2022a), Mind2Web (Deng et al., 2023b), Progprompt (Singh et al., 2022),
Planning Code as Policies (Liang et al., 2023a), ProgPrompt (Singh et al., 2022), Experimental assistants (Boiko et al., 2023)
Execution (§6.2)Action Grounding AgentBench (Liu et al., 2023f), V oyager (Wang et al., 2023b), Mint (Wang et al., 2023h), Progprompt (Singh et al., 2022)
Memory
OrganizationToolmaker (Cai et al., 2023), CRAFT (Yuan et al., 2023), Creator (Qian et al., 2023b), V oyager (Wang et al., 2023b)
Self-improvement
(§6.3)V oyager (Wang et al., 2023b), Chameleon (Lu et al., 2023), Agents for Science problems (Bran et al., 2023; Swan et al., 2023; Wu et al., 2023b)
Figure 2: The organization of our paper, with a curated list of the most representative works. The complete work
list is provided in Appendix D.
ing code on a pre-trained natural language LLM, as
exemplified by Codex (Chen et al., 2021), or train-
ing a LLM from scratch with a blend of natural
language and code, as demonstrated by CodeLLM
(Ma et al., 2023a).
Conversely, when utilizing other pre-defined for-
mal language for training, the objective shifts to
acquainting the model with the application of spe-
cific functions (Schick et al., 2023), mathematical
proof formulas (Wu et al., 2022), SQL (Sun et al.,
2023b), and similar constructs. As the dataset for
this is smaller compared to the pre-trained natural
language corpus, we refer to such training process
ascode fine-tuning . Researchers apply the lan-
guage modeling loss to optimize LLMs during this
process, similarly.
3 Code Pre-Training Boosts LLMs’
Performance
The pre-training of LLMs on code, exemplified
by OpenAI’s GPT Codex (Chen et al., 2021), has
broadened the LLMs’ scope of tasks beyond nat-ural language. Such models enable diverse appli-
cations, including generating code for mathemati-
cal theory (Wu et al., 2022), general programming
tasks (Chen et al., 2021), and data retrieval (Sun
et al., 2023b; Cheng et al., 2023). Code necessitates
producing logically coherent, ordered sequences
of steps essential for valid execution. Moreover,
the executability of each step within code allows
for step-by-step logic verification. Leveraging
and embedding both these properties of code in
pre-training has improved LLM chain-of-thought
(CoT) performance across many conventional nat-
ural language downstream tasks (Lyu et al., 2023;
Zhou et al., 2023a; Fu and Khot, 2022), indicat-
ing improved complex reasoning skills. Implicitly
learning from code’s structured format, code LLMs
demonstrate further improved performance on com-
monsense structured reasoning tasks, such as those
related to markup, HTML, and chart understanding
(Furuta et al., 2023; Liu et al., 2023a).
In the following sections, our objective is to elu-
cidate why training LLMs on code and employing

--- PAGE 4 ---
(a) Strengthen LLMs’ programming
and code evaluation skills (§3.1).
(b) Empower LLMs’ complex reason-
ing, decoupling computation from lan-
guage understanding (§3.2).
(c) Enable LLM to better capture struc-
tured knowledge and better understand
complex multimedia data (§3.3).
Figure 3: How code pre-training boosts LLMs’ performance.
code-based prompts enhance their performance on
complex downstream tasks. Specifically, we high-
light three key areas where pre-training on code
have benefited LLMs: i)enhancing programming
proficiency in §3.1, ii)empowering complex rea-
soning capabilities in §3.2, and iii)facilitating the
capture of structured commonsense knowledge in
§3.3, as shown in Figure 3.
3.1 Strengthen LLMs’ Programming Skills
LLM as a strong coder. Earlier language mod-
els only generate domain-specific programs (Ellis
et al., 2019) or restrict to one of the generic pro-
gramming languages, such as Java or C# (Alon
et al., 2020). Empowered by the increasing num-
ber of parameters and computing resources, recent
LLM-based code generation models (such as Al-
phaCode (Li et al., 2022), CodeGen (Nijkamp et al.,
2022), SantaCoder (Allal et al., 2023), PolyCoder
(Xu et al., 2022)) could master more than 10 lan-
guages within the same model and show unprece-
dented success. A well-known work is CodeX
(Chen et al., 2021), with 12 billion parameters
that reads the entire GitHub database and is able
to solve 72.31% of challenging Python program-
ming problems created by humans. Recent studies
(Zan et al., 2023; Xu et al., 2022; Du et al., 2023;
Vaithilingam et al., 2022; Wong et al., 2023; Fan
et al., 2023) have provided systematic surveys and
evaluations of existing code-LLMs.
With its strong code generation ability, LLMs
benefit various applications that rely on code, such
as database administration (Zhou et al., 2023b),
embedded control (Liang et al., 2023a), game de-
sign (Roberts et al.), spreadsheet data analysis (Liu
et al., 2023c), and website generation (Calò and
De Russis, 2023).
LLM as a state-of-the-art code evaluator. On theother hand, LLMs themselves could be state-of-the-
art evaluators (i.e., analyze and score) for human
or machine-generated codes. Kang et al. (2023a)
leverage LLM-based models for code fault localiza-
tion, while Zhuo (2023) uses GPT-3.5 to evaluate
the functional correctness and human preferences
of code generation. In addition, Deng et al. (2023a)
design a LLM-based penetration testing tool and
find that LLMs demonstrate proficiency in using
testing tools, interpreting outputs, and proposing
subsequent actions. Two recent efforts (Li et al.,
2023a; Mohajer et al., 2023) also utilize LLM for
examining and analyzing source code without ex-
ecuting it. Furthermore, LLMs are used for auto-
matic bug reproduction in Kang et al. (2023b) and
vulnerable software evaluation in Noever (2023).
Multi-LLM collaboration solves complex cod-
ing problems. Though code LLMs, like GitHub
Copilot, have shown unprecedented success, one
LLM agent alone could fail in complicated sce-
narios requiring multiple steps. Luckily, collab-
orative coding among several role-specific LLM
agents exhibits more accurate and robust perfor-
mance towards complex tasks. Hong et al. (2023)
incorporates human programming workflows as
guides to coordinate different agents. Dong et al.
(2023b) assigned three roles: analyst, coder, and
tester to three distinct “GPT-3.5”s, which surpasses
GPT-4 in code generation. Meanwhile, Qian et al.
(2023a) designs a chat-powered software devel-
opment process, assigning more than three roles
to separate LLM agents. Other similar methods
(Liu et al., 2023g; Talebirad and Nadiri, 2023; Wu
et al., 2023b; Jiang et al., 2023) all employ mul-
tiple code-LLM agents or different phases of the
same agent for code generation, software develop-
ments or leveraging generated intermediate codes
for other general purpose tasks.

--- PAGE 5 ---
3.2 Empower LLMs’ Complex Reasoning
Code pre-training improves chain-of-thought
performance. Logically, many complex tasks
can be divided into smaller easier tasks for solving.
CoT prompting, where prompt inputs are designed
with chains of reasoning, allows the LLM to condi-
tion its generation with further steps of reasoning,
providing a direct approach to task decomposition
(Wei et al., 2023). CoT has seen success in the
decomposition of many tasks, such as planning
(Huang et al., 2022b) and evidence-based question
answering (Dua et al., 2022; Ye et al., 2023b).
While LLM CoT ability was originally mainly
attributed to dramatically increased model sizes
(Wei et al., 2022b), recent evidence compiled by
Fu and Khot (2022) suggests that much of the per-
formance improvements from CoT stems from its
pre-training on code. For instance, when compar-
ing different versions of GPT-3 (i.e., v1 vs. v5),
LLMs not trained on code, such as GPT-3’s text-
davinci-001, see a small but substantial accuracy
improvement of 6.4 % to 12.4 % with CoT on the
mathematical reasoning task GSM8k (Cobbe et al.,
2021). In contrast, LLMs pre-trained on code, such
as GPT-3’s text-davinci-002 and Codex (Chen et al.,
2021), see a dramatic performance improvement
arising from CoT, with a remarkable accuracy in-
crease of 15.6% to 46.9% and 19.7% to 63.1%
respectively. Supporting this hypothesis proposed
by Fu and Khot (2022), Ma et al. (2023a) show that
pre-training on code in small-sized LLMs (2.6B)
(Zeng et al., 2021) enhances performance when
using CoT, and even more remarkably that smaller
code-pretrained LLMs outperform their larger non-
code counterparts across many different tasks. Fur-
thermore, their study indicates that incorporating
a greater volume of code during the initial phases
of LLM training significantly enhances its efficacy
in reasoning tasks. Nevertheless, tempering expec-
tations, it is possible that the discrepancy in CoT
performance between LLMs with and without code
pre-training diminishes as the size of the models
decreases, as the accuracy gap between the small
LLMs in Ma et al. (2023a) was less than 3% when
evaluating CoT. Notably, both Fu and Khot (2022)
and Ma et al. (2023a) show that pre-training on
code improves LLM performance in both standard
and CoT prompting scenarios across downstream
tasks.
Program-of-thought outperforms chain-of-
thought. Furthermore, in comparison to vanillaCoT methods, LLMs that first translate and
decompose a natural language task into code
(Chen et al., 2023b; Gao et al., 2023), typically
termed program-of-thought (PoT) prompting
or program-aided language model, see sizable
gains in tasks that require disambiguation in
both language and explicit longitudinal structure.
This approach is especially effective in complex
areas such as theoretical mathematics (Polu and
Sutskever, 2020), undergraduate mathematics
(Drori et al., 2022), and question answering with
data retrieval (Sun et al., 2023b; Cheng et al.,
2023).
PoT enhances performance due to the precision
and verifiability inherent in code as a machine-
executable language. Within task decomposition,
it is not uncommon for the LLM to hallucinate
incorrect subtasks and questions through CoT (Ji
et al., 2023). PoT implementations from Chen et al.
(2023b), Gao et al. (2023), and Ye et al. (2023b)
show that by directly executing code and verify-
ing outcomes post translation by LLMs, one can
effectively mitigate the effects of incorrect reason-
ing in CoT. This is because the reasoning process
must adhere to the logic and constraints explicitly
specified by the program, thereby ensuring a more
accurate and reliable outcome.
However, such improvements seen in the usage
of code are not limited to purely executable coding
languages such as Python or SQL, nor are they lim-
ited to tasks that are specifically rigid in structure
such as mathematics (Drori et al., 2022) and data
retrieval (Rajkumar et al., 2022). Enhancements
also extend to the realm where even translating
into pseudo-code to decompose a task can improve
zero-shot performance (Lei and Deng, 2023) in
word problems containing numbers, and general
reasoning tasks such as StrategyQA (Geva et al.,
2021).
3.3 Enable LLMs to Capture Structured
Knowledge
Code generation unveils superior structural
commonsense reasoning. Given that code pos-
sesses the graph structure of symbolic representa-
tions, translating textual graphs, tables, and images
into code empowers a code-driven LLM to logi-
cally process such information according to code
reasoning and generation principles.
Consequently, previous work (Madaan et al.,
2022; Wang et al., 2023f) shows that LLMs under-

--- PAGE 6 ---
going extra pre-training on code may rival, or even
exceed, their fine-tuned natural language counter-
parts in tasks involving structural commonsense
reasoning, even with limited or no training data.
COCOGEN (Madaan et al., 2022) first reframed
the commonsense reasoning graph completion task
as a code generation task and demonstrated im-
proved few-shot performance in reasoning graphs,
table entity state tracking, and explanation graph
generation.
Building on this perspective, CODE4STRUCT
(Wang et al., 2023f) applied code-LLMs to seman-
tic structures, focusing on the event argument ex-
traction task. By leveraging code’s features such as
comments and type annotation, it achieved compet-
itive performance with minimal training instances.
Moreover, it surpassed baselines in zero-shot sce-
narios, benefiting from the inheritance feature and
sibling event-type samples. ViStruct (Chen et al.,
2023d) extended this approach further to multi-
modal tasks, leveraging programming language for
representing visual structural information and cur-
riculum learning for enhancing the model’s under-
standing of visual structures.
Markup code mastery evolves visually situ-
ated natural language understanding. Another
stream of research focuses on utilizing markup
code such as HTML and CSS to delineate and
derender structured graphical information in graph-
ical user interfaces (GUIs) or visualizations such
as plots and charts in documents. This markup
code not only specifies content but also governs the
layout of a web page, aiding large vision-language
models (LVLMs) in capturing visually situated nat-
ural language (VSNL) information.
For LVLMs’ markup code understanding,
WebGUM (Furuta et al., 2023) exemplified au-
tonomous web navigation. It employed a pre-
training approach using webpage screenshots and
the corresponding HTML as input, and navigation
action as output. Outperforming SOTA, human,
and other LLM-based agents, WebGUM show-
cased the effectiveness of pre-training model with
markup code augmentation in webpage understand-
ing.
For markup code generation, pix2code (Bel-
tramelli, 2017) and sketch2code (Robinson, 2019)
pioneered machine learning methods to generate
rendering code for GUIs or website mockups, in
the pre-LLM era. Pix2Struct (Lee et al., 2023)
achieved SOTA at that time in VSNL understanding
Figure 4: The code-centric tool-calling paradigm serves
as a unified interface between LLMs and a large variety
of functional ends, thus enabling many cross-modality
and cross-domain tasks.
by pre-training an image-to-text model on masked
website screenshots, and further training with OCR,
language modeling, and image captioning objec-
tives. Building on this, MATCHA (Liu et al.,
2023a) introduced additional pre-training objec-
tives based on chart derendering, layout compre-
hension, and mathematical reasoning, surpassing
SOTA on VSNL understanding tasks.
4 Code Connects LLMs to Other
Function Ends
Recent studies show that connecting LLMs to other
functional ends (i.e., augmenting LLMs with ex-
ternal tools and execution modules) helps LLMs
to perform tasks more accurately and reliably (Mi-
alon et al., 2023; Parisi et al., 2022b; Peng et al.,
2023; Gou et al., 2023). These functional ends
empower LLMs to access external knowledge, en-
gage with diverse modalities, and interact effec-
tively with various environments. As indicated
in Table 1, we observe a prevalent trend where
LLMs generate programming languages or utilize
pre-defined functions to establish connections with
other functional ends—a phenomenon we refer to
as the code-centric paradigm .
In contrast to the rigid practice of strictly hard-
coding tool calls within the LLMs’ inference mech-
anism, the code-centric paradigm allows LLMs
to dynamically generate tokens that invoke exe-
cution modules with adaptable parameters. This
paradigm enables a simple and unambiguous way
for LLMs to interact with other functional ends,
enhancing the flexibility and scalability of their ap-
plication. Importantly, as depicted in Figure 4, it
allows LLMs to engage with numerous functional
ends spanning diverse modalities and domains. By
expanding both the quantity and variety of func-
tional ends accessible, LLMs can handle more com-
plicated tasks.

--- PAGE 7 ---
Table 1: Representative work connecting LLMs to different function ends for performing non-trivial tasks. Initial
efforts embed tool calls rigidly within the LLMs’ inference mechanism (indicated by “ ∗”), resulting in diminished
flexibility and constrained tool accessibility. More recently, the code-centric paradigm establishes connections
between LLMs and function ends through programming languages or pre-defined functions (indicated by “ †”). This
approach enhances the scalability of LLMs’ function end invocation across diverse tools and execution modules.
Major Type of Function Ends Representative Work Connecting Paradigm Learning Method Objectives or Problems to Solve
Single ToolRetriever in REALM (Guu et al., 2020) Hardcoded in Inference Mechanism* Example Fine-tuningAugment LLMs with ToolsVerifier in GSM8K (Cobbe et al., 2021) Hardcoded in Inference Mechanism* Example Fine-tuning
Limited Text-based ToolsBlenderbot3 (Shuster et al., 2022) Hardcoded in Inference Mechanism* Example Fine-tuningOpen-domain ConversationLamDA (Thoppilan et al., 2022) Generate Pre-defined Functions†Example Fine-tuning
Text-based ToolsTALM (Parisi et al., 2022a) Generate Pre-defined Functions†Iterative Self-playEfficient and Generalizable Tool UsingToolFormer (Schick et al., 2023) Generate Pre-defined Functions†Self-supervised Training
Multi-modal ModulesMM-React (Yang et al., 2023) Generate Pre-defined Functions†Zero-shot Prompting
Multi-modal Reasoning TasksCodeVQA (Subramanian et al., 2023) Generate Python Functions†Zero-shot & Few shot
VISPROG (Gupta and Kembhavi, 2023) Generate Python Functions†Zero-shot Prompting
ViperGPT (Surís et al., 2023) Generate Python Functions†Zero-shot Prompting
Real-World APIsCode as Policies (Liang et al., 2023a) Generate Python Functions†Few-shot Prompting
Better Robot Control Progprompt (Singh et al., 2022) Generate Python Functions†Zero-shot Prompting
SayCan (Ahn et al., 2022) Generate Pre-defined Functions†Zero-shot Prompting
RRR (Cui et al., 2023a) Generate Pre-defined Functions†Zero-shot Prompting
Autonomous Driving Ecosystems Agent-Driver (Mao et al., 2023) Generate Pre-defined Functions†Few-shot Prompting
LaMPilot (Ma et al., 2023b) Generate Python Functions†Zero-shot & Few-shot
In §4.1, we examine (digital) textual and multi-
modal tools connected to LLMs, while §4.2 focuses
on physical-world functional ends, including robots
and autonomous driving, showcasing the versatil-
ity of LLMs in tackling problems across various
modalities and domains.
4.1 Relate LLMs to Digital Ends
Text-Based Tools. The code-centric framework
has enhanced precision and clarity to LLMs’ tool
invocation, initially driving progress in text-based
tools. Prior to the popularity of this code-centric
paradigm, research on augmenting LMs with single
tools like information retrivers (Guu et al., 2020;
Lewis et al., 2020; Izacard et al., 2022; Borgeaud
et al., 2022; Yasunaga et al., 2022) required a
hardcoded-in-inference-mechanism (e.g. always
calling a retriever before the generation starts),
which was less flexible and harder to scale. TALM
(Parisi et al., 2022a) first incorporates multiple
text-based tools by invoking API calls with a pre-
defined delimiter, enabling unambiguous calls to
any text-based tools at any position of generation.
Following their work, Toolformer (Schick et al.,
2023) marks API calls with “<API> </API>” along
with their enclosed contents. Later, diverse tool-
learning approaches were introduced to facilitate
the integration of numerous text-based tools across
various foundational models (Song et al., 2023;
Hao et al., 2023; Tang et al., 2023).
The code-centric framework facilitates the in-
vocation of a diverse range of external text mod-
ules. These include calculators, calendars, machine
translation systems, web navigation tools, as well
as APIs from HuggingFace and TorchHub (Thop-pilan et al., 2022; Yao et al., 2022c; Shuster et al.,
2022; Jin et al., 2023; Yao et al., 2022b; Liu et al.,
2023e; Jin et al., 2023; Patil et al., 2023).
Multimodal Tools. The high scalability of the
code-centric LLM paradigm enables the extension
of tool-learning to modalities other than text. Early
work (Gupta and Kembhavi, 2023; Surís et al.,
2023; Subramanian et al., 2023) use the code-
centric paradigm to tackle the visual question an-
swering task. For instance, VISPROG (Gupta and
Kembhavi, 2023) curates various pretrained com-
puter vision models and functions from existing im-
age processing libraries (e.g. Pillow and OpenCV)
as a set of APIs. The API calls can then be chained
together as a program for question-targeted image
understanding, where the program is generated via
in-context learning with LLMs. Containing arith-
metic in its API code language, the program is
capable of performing simple arithmetic tasks, thus
enabling VISPROG to answer concrete questions
such as object counting. Similar work includes
ViperGPT (Surís et al., 2023) and CodeVQA (Sub-
ramanian et al., 2023). Compared to VISPROG,
they directly generate more flexible Python code
using Codex. This enables them to potentially gen-
erate programs of more complex control flows us-
ing the pre-trained knowledge embedded in Codex.
In addition to visual reasoning, code has also been
used to connect LLMs with multi-modal generative
tools in image generation tasks (Cho et al., 2023;
Feng et al., 2023; Wu et al., 2023a), where code’s
unambiguous nature is leveraged in generating im-
ages that better match their text prompts.
Beyond the image-based tools, other modalities

--- PAGE 8 ---
have been considered and used in a collaborative
fashion by recent work (Shen et al., 2023; Yang
et al., 2023; Liang et al., 2023d). For example, MM-
REACT (Yang et al., 2023) considers video recog-
nition models in their API, and Chameleon (Lu
et al., 2023) includes tools such as visual text
detector or web search. In HuggingGPT (Shen
et al., 2023), the authors connect LLMs to vari-
ous Hugging Face models and treat each model as
an available API call. As a result, HuggingGPT
is capable of performing an even wider range of
tasks, such as audio-related tasks, that were previ-
ously unexplored. Pushing the API diversity fur-
ther, TaskMatrix.AI (Liang et al., 2023d) uses a
magnitude higher number of APIs, spanning from
visual & figure APIs to music and game APIs. The
flexibility of code facilitates LLMs to jointly use
different multimodal tools. This makes LLMs more
versatile and capable of acting as general-purpose
multimodal problem solvers that can scale to many
tasks.
4.2 Relate LLMs to Physical Ends
While the physical world offers a more immer-
sive, contextually rich, and engaging interactive
environment compared to the digital realm, the
connection between LLMs and the physical world
has been constrained until the advent of the code-
centric paradigm. This paradigm allows for adapt-
able calls to tools and execution modules in the
physical world, first sparking a wave of research
exploring the integration of LLMs with robotics
and autonomous driving.
One of the most successful approaches to em-
ploying LLMs to generate policy codes for real-
world robotic tasks is PaLM-SayCan (Ahn et al.,
2022), where LLMs comprehend high-level in-
structions and then call corresponding APIs for
robotic control. Following SayCan, recent devel-
opments have shown that LLMs can serve as the
brain for robotics planning and control through
their powerful code generation capabilities. Prog-
Prompt (Singh et al., 2022), for instance, pioneered
program-like specifications for robot task planning,
while other researchers like Huang et al. (2023a),
Liang et al. (2023a), and Vemprala et al. (2023)
have extended this approach to a range of other
tasks, including human-robot interaction and drone
control.
Through code generation and tool learning,
LLMs also show great potential in more compli-
Figure 5: LLMs can be embedded into a code execution
environment, where they collect faithful, automatic, and
customizable feedback for self-improvement.
cated tasks such as human-vehicle interactions and
autonomous driving (Cui et al., 2023b; Huang et al.,
2023b; Li et al., 2023d). A prime tool learning
example from the industry is Wayve’s LINGO-
1 (Wayve, 2023), which uses an open-loop vision,
language, and action LLM to improve the explain-
ability of driving models. Using instruction tuning,
LLMs have advanced to the point where they can
understand complex driving, navigation, and enter-
tainment commands (Wang et al., 2023e), generate
actionable codes (Ma et al., 2023b), and execute
them by calling low-level vehicle planning and con-
trol APIs (Cui et al., 2023a; Sha et al., 2023; Mao
et al., 2023).
Overall, despite challenges such as latency, accu-
racy issues, and the absence of adequate simulation
environments, datasets, and benchmarks (Kannan
et al., 2023; Chen and Huang, 2023; Cui et al.,
2023b), LLMs show promise in understanding
high-level instructions and executing code-related
APIs in intricate domains like robotics and au-
tonomous driving. Looking ahead, there’s consider-
able potential for LLMs to bridge the gap between
physical worlds and AI, influencing areas like trans-
portation and smart manufacturing (Panchal and
Wang, 2023; Zeng et al., 2023a).
5Code Provides LLM with an Executable
Environment for Automated Feedback
LLMs demonstrate performance beyond the param-
eters of their training, in part due to their ability
to intake feedback, especially in real-world appli-
cations where environments are rarely static (Liu
et al., 2023f; Wang et al., 2023d). However, feed-
back must be chosen carefully as noisy prompts
can hinder LMs’ performance on downstream tasks
(Zheng and Saparov, 2023). Furthermore, as hu-
man effort is expensive, it is crucial that feedback
can be automatically collected while staying faith-
ful. Embedding LLMs into a code execution envi-

--- PAGE 9 ---
ronment enables automated feedback that fulfills all
of these criteria, as shown in Figure 5. As the code
execution is largely deterministic, LLMs that intake
feedback from the results of executed code remain
faithful to the task at hand (Chen et al., 2023a;
Fernandes et al., 2023; Scheurer et al., 2022). Fur-
thermore, code interpreters provide an automatic
pathway for LLMs to query internal feedback, elim-
inating the need for costly human annotations as
seen when leveraging LLMs to debug or optimize
faulty code (Chen et al., 2023a; Fernandes et al.,
2023; Scheurer et al., 2022). In addition, code
environments allow LLMs to incorporate diverse
and comprehensive forms of external feedback,
such as critic on binary correctness (Wang et al.,
2023g), natural language explanations on results
(Chen et al., 2023c), and ranking with reward val-
ues (Inala et al., 2022), enabling highly customiz-
able methods to enhance performance.
We introduce the various types of feedback de-
rived from code execution that can be jointly uti-
lized to benefit LLMs in §5.1, and discuss com-
mon methods for utilizing this feedback to improve
LLMs in §5.2.
5.1 Various Feedback from Code Execution
The code execution process enables assessing
LLM-generated content with more comprehensive
evaluation metrics derived from deterministic exe-
cution results, as opposed to relying solely on often
ambiguous sequence-based metrics like BLEU (Pa-
pineni et al., 2002; Ren et al., 2020) and Rouge
(Lin, 2004).
Straightforward methods for evaluating program
execution outcomes and generating feedback in-
clude the creation of unit tests (Chen et al., 2021;
Hendrycks et al., 2021; Austin et al., 2021; Li et al.,
2022; Huang et al., 2022a; Lai et al., 2023) and
the application of exact result matching techniques
(Dong and Lapata, 2016; Zhong et al., 2017; Huang
et al., 2022a). From these, feedback can be pro-
vided in two primary forms: simple correctness
feedback and textual feedback. Simple feedback,
indicating whether a program is correct or not, can
be generated through critic models or rule-based
methods (Wang et al., 2023g; Chen et al., 2023c).
For more detailed textual feedback, language
models can be employed to produce explanations
either about the program itself (Chen et al., 2023c),
or to summarize comments on the program and its
execution (Wang et al., 2023g; Chen et al., 2023c;Zhang et al., 2023a). Execution results can also be
translated into reward functions using predefined
rules. The rules map execution results into scalar
values based on the severity of different error types,
thus making the feedback format suitable for re-
inforcement learning approaches (Le et al., 2022).
Moreover, additional feedback can be extracted
by performing static analysis using software en-
gineering tools. For instance, Wang et al. (2017)
and Gupta et al. (2017) obtain extra information
from the execution trace, including variable or state
traces. Lai et al. (2023) demonstrates an effective
way to extract extra feedback using surface-form
constraints on function calls.
5.2 Methods for Enhancing LLM’s
Performance with Feedback
The feedback derived from code execution and
external evaluation modules can enhance LLMs
through three major approaches.
Selection Based Method. Selection-based meth-
ods, such as majority voting and re-ranking
schemes, have proven effective in enhancing LLM
performance in tasks such as code generation.
These methods, originally developed for simple
program synthesis, leverage code execution out-
comes like the number of passed unit tests to
choose the best-performing code snippet. Studies
like Chen et al. (2018); Li et al. (2022) demon-
strate the efficacy of majority voting, while Zhang
et al. (2023b); Yin and Neubig (2019); Zeng et al.
(2023b) showcase the advantages of re-ranking
schemes. Building on this success, similar ap-
proaches have been adapted for more challenging
tasks where code-LLMs are integrated in interac-
tive environments, as shown in the work of Shi
et al. (2022); Chen et al. (2022) for similar voting
methods, and Ni et al. (2023); Inala et al. (2022);
To et al. (2023) for re-ranking strategies. However,
these approaches, while simple and effective, cause
inefficiencies, as they necessitate multiple rounds
of generation and the employment of additional
re-ranking models to identify the optimal solution.
Prompting Based Method. Modern LLMs are
equipped with the capability to reason in-context
and directly integrate feedback from task descrip-
tions into prompts, to certain extents. Improving
LLM “self-debugging” with in-context learning
prompts typically requires feedback presented as
natural language explanations (Wang et al., 2023h;
Chen et al., 2023c) or error messages derived from

--- PAGE 10 ---
execution results, as these formats are more com-
prehensible for the LLM. This method is favored
by most LLM-based agents (see §6) due to its au-
tomatic nature, computational efficiency, and lack
of requirement for additional fine-tuning. However,
the effectiveness of this approach heavily depends
on the LLM’s in-context learning capabilities.
Finetuning Based Method. In the aforemen-
tioned methods, neither the selection-based method
nor the prompting-based method promises steady
improvement over the task, as the LLMs’ param-
eters remain unchanged. They require repeating
the tuning process even when faced with similar
problems. Finetuning approaches, on the other
hand, fundamentally improve the LLMs by updat-
ing their parameterized knowledge. Typical fine-
tuning strategies include direct optimization, lever-
aging an external model for optimization, and train-
ing the model in a reinforcement learning paradigm.
Wang et al. (2023g) exemplifies the direct optimiza-
tion approach, where the original language model
is fine-tuned with a feedback-conditioned objec-
tive. Haluptzok et al. (2022) presents a unique
method where language models generate synthetic
unit tests to identify and retain only correctly gen-
erated examples, which are then composed into
correct question-answer pairs and employed to
further fine-tune the models. CodeScore (Dong
et al., 2023a) designs its loss function based on
executability and the pass rate on the unit tests.
For self-edit (Zhang et al., 2023a), it first wraps
up execution results into textual comments, then
trains an editor to further refine the program by ac-
cepting both the problematic program and the com-
ments. Chen et al. (2023a) train a “refine model”
which accepts the feedback and generated program
first, then use the refined generated example to fine-
tune the generation model, illustrating a layered
approach to fine-tuning. CodeRL (Le et al., 2022)
and Wang et al. (2022) apply reinforcement learn-
ing to improve the original language model. While
Wang et al. (2022) aims at employing compiler
feedback to obtain erroneous code, CodeRL (Le
et al., 2022) empirically defines fixed reward val-
ues for different execution result types based on
unit tests. Despite the discussed advantages, re-
fining LLMs through finetuning typically involves
a resource-intensive data collection process. Ad-
ditionally, assessing predefined reward values, as
exemplified in CodeRL (Le et al., 2022), poses
certain challenges.6 Application: Code-empowered LLMs
Facilitate Intelligent Agents
In the preceding sections, our discussion high-
lighted the various ways in which code integration
enhances LLMs. Going beyond, we discern that the
benefits of code-empowered LLMs are especially
pronounced in one key area: the development of
IAs (Xu et al., 2023). In this section, we underscore
the unique capabilities bestowed upon these agents
by code-empowered LLMs.
Figure 6 helps to illustrate a standard operational
pipeline of an IA, specifically serving as an em-
bodied general daily assistant. We observe that
the improvements brought about by code training
in LLMs are firmly rooted in their practical oper-
ational steps when serving as IAs. These steps
include (i) enhancing the IA’s decision-making
in terms of environment perception and planning
(§6.1), (ii) streamlining execution by grounding
actions in modular and explicit action primitives
and efficiently organizing memory (§6.2), and (iii)
optimizing performance through feedback automat-
ically derived from the code execution environment
(§6.3). Detailed explanations of each aspect will
follow in the subsequent sections.
6.1 Decision Making
Environment Perception As depicted in Fig-
ure 6 at step (0-10), the IA continuously perceives
the world, engaging in interactions with humans
and the environment, responding to relevant stim-
uli (e.g., human instructions for meal preparation),
and planning and executing actions based on the ob-
served environmental conditions (e.g., the kitchen
layout). Utilizing LLMs as decision centers for
IAs requires translating environmental observa-
tions into text, such as tasks based in the virtual
household or Minecraft (Shridhar et al., 2020; Côté
et al., 2018; Wang et al., 2023b; Zhu et al., 2023).
The perceived information needs to be organized
in a highly structured format, ensuring that stim-
uli occurring at the same moment (e.g., coexisting
multimodality stimuli) influence the IA’s percep-
tion and decision simultaneously without temporal
differences, a requirement that contrasts with the
sequential nature of free-form text. Through pre-
training on code, LLMs acquire the ability to better
comprehend and generate structured representa-
tions resembling class definitions in code. This
structured format, where class attributes and func-
tions are permutation invariant, facilitates agents in

--- PAGE 11 ---
Figure 6: This figure illustrates the complete working pipeline of a LLM-based intelligent agent, mapping code-
LLM abilities to specific phases: code-based planning in step (2), modular action parsing and tool creation in step
(3), and automated feedback collection for enhanced agent self-improvement in step (5). Collectively, steps 0-10 in
the entire loop benefit from code-LLMs’ improved structured information understanding and perception.
perceiving structured environmental observations
during task execution.
One such intuitive example is web-page-based
environments which are highly structured around
HTML code. In agent tasks like web shopping (Yao
et al., 2022a), web browsing (Deng et al., 2023b),
and web-based QA (Nakano et al., 2021; Liu et al.,
2023d), it is preferred to translate the web-based
environment into HTML code rather than natural
language, directly encompassing its structural in-
formation and thereby improving the LLM agent’s
overall perception. Moreover, in robotics research
by Singh et al. (2022) and Liang et al. (2023a), the
IAs are prompted with program-like specifications
for objects in the environment, enabling the LLM
to generate situated task plans based on the virtual
objects they perceived.
Planning As illustrated in Figure 6 at step (2),
IAs must break down intricate tasks into finer, man-
ageable steps. Leveraging the synergized planning
abilities of code-LLMs, IAs can generate organized
reasoning steps using modular and unambiguous
code alongside expressive natural language. As
discussed in §2.2, when code-LLMs are employed
for planning agent tasks, they exhibit enhanced rea-
soning capabilities. In addition, they generate the
sub-tasks as executable programs when necessary,
yielding more robust intermediate results, which
the IA conditions on and refines its planning with
greater precision. Furthermore, the IA seamlesslyintegrates performant tool APIs into planning, ad-
dressing the limitations such as poor mathematical
reasoning and outdated information updates faced
by vanilla LLMs during planning.
Typical examples that utilize code for planning
are in two main categories. Progprompt (Singh
et al., 2022) and Code as Policies (Liang et al.,
2023a) represent the work utilizing code for bet-
ter robot control. Both work highlight the bene-
fits brought by code-based planning as they not
only enable direct expressions of feedback loops,
functions, and primitive APIs, but also facilitate di-
rect access to third-party libraries. Another stream
of work is concerned with the scenario when the
agents’ programming and mathematical reasoning
abilities are crucial, like solving maths-related prob-
lems (Gao et al., 2023; Wang et al., 2023h) or doing
experiments in the scientific domain (Boiko et al.,
2023; Liffiton et al., 2023).
6.2 Execution
Action Grounding As depicted in Figure 6 at
step (3), when the IA interfaces with external func-
tion ends according to the planning, it must in-
voke action primitives from a pre-defined set of
actions (i.e., functions). Given that modern LLMs
are trained in formal language and can generate
highly formalized primitives, the IA’s generation
can be directly parsed and executed, eliminating the
necessity for additional action primitive grounding
modules.

--- PAGE 12 ---
Connecting the IA with other function ends re-
quires grounding actions into formalized function-
like primitives. For instance, in a benchmark evalu-
ating LLMs as agents in real-world scenarios (Liu
et al., 2023f), seven out of eight scenarios involve
code as the action space.
Previous work generating agent plans with pure
natural language necessitate an additional step-to-
primitive module to ground those planning steps
into code (Wang et al., 2023c; Yin et al., 2023). In
contrast, IAs that plan with code-LLMs generate
atomic action programs (Yao et al., 2022d; Wang
et al., 2023h; Liang et al., 2023a; Singh et al., 2022),
and can have their generation quickly parsed for
execution.
Memory Organization As depicted in Figure 6
at step (3) and the component labeled “Function
Ends for Updating State,” the IA typically necessi-
tates an external memory organization module to
manage exposed information (Wang et al., 2023d),
including original planning, task progress, execu-
tion history, available tool set, acquired skills, aug-
mented knowledge, and users’ early feedback. In
this context, Code-LLM aids the IA’s memory orga-
nization by employing highly abstract and modular
code to record, organize, and access memory, es-
pecially for expanding the available tool set and
manage acquired skills.
Typically, agent-written code snippets can serve
as parts of the toolset, integrated into the memory
organization of agents. This stream of research is
known as tool creation approaches. TALM (Cai
et al., 2023) proposes to use stronger agents (e.g.
GPT-4 based agents) to write code as part of mem-
ory for weaker agents (e.g. GPT-3.5 based agents).
In Creator (Qian et al., 2023b), agents themselves
are highlighted as not only users of the tools but
also their creators. They proposed a four-stage tool-
creation framework that enables agents to write
code as part of their executable tool set. Going
further, Craft (Yuan et al., 2023) focuses on ensur-
ing the created tools are indeed executable, making
the framework more robust. Another work sharing
this idea is V oyager (Wang et al., 2023b), in which
the agent store learned skills in code format and
execute them in the future when faced with similar
tasks.
6.3 Self-improvement
As illustrated in Figure 6 at step (5), when the
IA’s decision center, i.e., the LLM, operates withina code execution environment, the environment
can integrate various evaluation modules to of-
fer automated feedback (e.g., correctness, ranking,
detailed comments). This significantly enhances
the IA’s early error correction and facilitates self-
improvement.
V oyager (Wang et al., 2023b) is a good exam-
ple for agents that use feedback from the simu-
lated environment. The agent learns from failure
task cases and further horn its skills in Minecraft.
Chameleon (Lu et al., 2023) receives feedback
from a program verifier to decide whether it should
regenerate an appropriate program. Mint (Wang
et al., 2023h) can receive feedback from proxies,
and the agent can thus self-improve in a multi-turn
interactive setting. Importantly, this ability to self-
improve from execution feedback is fundamental
for agents’ success at solving scientific problems
(Bran et al., 2023; Swan et al., 2023; Wu et al.,
2023b).
7 Challenges
We identify several intriguing and promising av-
enues for future research.
7.1 The Causality between Code Pre-training
and LLMs’ Reasoning Enhancement
Although we have categorized the most pertinent
work in §3.2, a noticeable gap persists in providing
explicit experimental evidence that directly indi-
cates the enhancement of LLMs’ reasoning abilities
through the acquisition of specific code properties.
While we intuitively acknowledge that certain code
properties likely contribute to LLMs’ reasoning ca-
pabilities, the precise extent of their influence on
enhancing reasoning skills remains ambiguous. In
the future research endeavors, it is important to in-
vestigate whether reinforcing these code properties
within training data could indeed augment the rea-
soning capabilities of trained LLMs. If it is indeed
the case, that pre-training on specific properties of
code directly improves LLMs’ reasoning abilities,
understanding this phenomenon will be key to fur-
ther improving the complex reasoning capabilities
of current models.
7.2 Acquisition of Reasoning Beyond Code
Despite the enhancement in reasoning achieved
by pre-training on code, foundational models still
lack the human-like reasoning abilities expected
from a truly generalized artificial intelligence. Im-

--- PAGE 13 ---
portantly, beyond code, a wealth of other textual
data sources holds the potential to bolster LLM rea-
soning abilities, where the intrinsic characteristics
of code, such as its lack of ambiguity, executabil-
ity, and logical sequential structure, offer guiding
principles for the collection or creation of these
datasets. However, if we stick to the paradigm of
training language models on large corpora with the
language modeling objective, it’s hard to envision
a sequentially readable language that is more ab-
stract, highly structured, and closely aligned with
symbolic language than formal languages, exem-
plified by code, which are prevalent in a substantial
digital context. We envision that exploring alter-
native data modalities, diverse training objectives,
and novel architectures would present additional
opportunities to further enhance the reasoning ca-
pabilities of these models.
7.3 Challenges of Applying Code-centric
Paradigm
The primary challenge in LLMs using code to con-
nect to different function ends is learning the cor-
rect invocation of numerous functions, including
selecting the right function end and passing the
correct parameters at an appropriate time. Even
for simple tasks like simplified web navigation
with a limited set of action primitives like mouse
movements, clicks, and page scrolls, few shot ex-
amples together with a strong underlying LLM
are often required for the LLM to precisely grasp
the usage of these primitives (Sridhar et al., 2023).
For more complex tasks in data-intensive fields
like chemistry (Bran et al., 2023), biology, and as-
tronomy, which involve domain-specific Python
libraries with diverse functions and intricate calls,
enhancing LLMs’ capability of learning the correct
invocation of these functions is a prospective direc-
tion, empowering LLMs to act as IAs performing
expert-level tasks in fine-grained domains.
7.4 Learning from multi-turn interactions
and feedback
LLMs often require multiple interactions with the
user and the environment, continuously correcting
themselves to improve intricate task completion
(Li et al., 2023c). While code execution offers reli-
able and customizable feedback, a perfect method
to fully leverage this feedback has yet to be estab-
lished. As discussed in § 5.2, we observed that
selection-based methods, though useful, do not
guarantee improved performance and can be inef-ficient. Prompting-based methods heavily depend
on the in-context learning abilities of the LLM,
which might limit their applicability. Fine-tuning
methods show consistent improvement, but data
collection and fine-tuning are resource-intensive
and thus prohibitive. We hypothesize that reinforce-
ment learning could be a more effective approach
for utilizing feedback and improving LLMs. This
method can potentially address the limitations of
current techniques by providing a dynamic way to
adapt to feedback through well-designed reward
functions. However, significant research is still
needed to understand how reward functions should
be designed and how reinforcement learning can be
optimally integrated with LLMs for complex task
completion.
8 Conclusion
In this survey, we compile literature that elucidates
how code empowers LLMs, as well as where code
assists LLMs to serve as IAs. To begin with, code
possesses natural language’s sequential readability
while also embodying the abstraction and graph
structure of symbolic representations, rendering it
a conduit for knowledge perception and reasoning
as an integral part of the LLMs’ training corpus
based on the mere language modeling objective.
Through a comprehensive literature review, we ob-
serve that after code training, LLMs i)improve
their programming skills and reasoning, ii)could
generate highly formalized functions, enabling flex-
ible connections to diverse functional ends across
modalities and domains, and iii)engage in inter-
action with evaluation modules integrated in the
code execution environment for automated self-
improvement. Moreover, we find that the LLMs’
capability enhancement brought by code training
benefits their downstream application as IAs, mani-
festing in the specific operational steps of the IAs’
workflow regarding decision-making, execution,
and self-improvement. Beyond reviewing prior
research, we put forth several challenges in this
field to serve as guiding factors for potential future
directions.
References
Rajas Agashe, Srini Iyer, and Luke Zettlemoyer. 2019.
Juice: A large scale distantly supervised dataset
for open domain context-based code generation.
InConference onEmpirical Methods inNatural
Language Processing.

--- PAGE 14 ---
Michael Ahn, Anthony Brohan, Noah Brown, Yev-
gen Chebotar, Omar Cortes, Byron David, Chelsea
Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol
Hausman, Alex Herzog, Daniel Ho, Jasmine Hsu,
Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang,
Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jes-
month, Nikhil J Joshi, Ryan Julian, Dmitry Kalash-
nikov, Yuheng Kuang, Kuang-Huei Lee, Sergey
Levine, Yao Lu, Linda Luu, Carolina Parada, Pe-
ter Pastor, Jornell Quiambao, Kanishka Rao, Jarek
Rettinghouse, Diego Reyes, Pierre Sermanet, Nico-
las Sievers, Clayton Tan, Alexander Toshev, Vincent
Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu,
Mengyuan Yan, and Andy Zeng. 2022. Do as i can,
not as i say: Grounding language in robotic affor-
dances.
Loubna Ben Allal, Raymond Li, Denis Kocetkov,
Chenghao Mou, Christopher Akiki, Carlos Munoz
Ferrandis, Niklas Muennighoff, Mayank Mishra,
Alex Gu, Manan Dey, Logesh Kumar Umapathi,
Carolyn Jane Anderson, Yangtian Zi, Joel Lamy
Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry
Abulkhanov, Manuel Romero, Michael Lappert,
Francesco De Toni, Bernardo García del Río, Qian
Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue
Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab
Mangrulkar, David Lansky, Huu Nguyen, Danish
Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau,
Yacine Jernite, Sean Hughes, Daniel Fried, Arjun
Guha, Harm de Vries, and Leandro von Werra. 2023.
Santacoder: don’t reach for the stars!
Uri Alon, Roy Sadaka, Omer Levy, and Eran Yahav.
2020. Structural language models of code.
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten
Bosma, Henryk Michalewski, David Dohan, Ellen
Jiang, Carrie Cai, Michael Terry, Quoc Le, and
Charles Sutton. 2021. Program synthesis with large
language models.
Tony Beltramelli. 2017. pix2code: Generating code
from a graphical user interface screenshot.
Daniil A. Boiko, Robert MacKnight, and Gabe Gomes.
2023. Emergent autonomous scientific research
capabilities of large language models. ArXiv ,
abs/2304.05332.
Sebastian Borgeaud, Arthur Mensch, Jordan Hoff-
mann, Trevor Cai, Eliza Rutherford, Katie Milli-
can, George Bm Van Den Driessche, Jean-Baptiste
Lespiau, Bogdan Damoc, Aidan Clark, Diego
De Las Casas, Aurelia Guy, Jacob Menick, Ro-
man Ring, Tom Hennigan, Saffron Huang, Loren
Maggiore, Chris Jones, Albin Cassirer, Andy Brock,
Michela Paganini, Geoffrey Irving, Oriol Vinyals, Si-
mon Osindero, Karen Simonyan, Jack Rae, Erich
Elsen, and Laurent Sifre. 2022. Improving lan-
guage models by retrieving from trillions of tokens.
InProceedings ofthe39th International Conference
onMachine Learning , volume 162 of Proceedings
ofMachine Learning Research , pages 2206–2240.
PMLR.Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldas-
sari, Andrew D White, and Philippe Schwaller. 2023.
Chemcrow: Augmenting large-language models with
chemistry tools.
Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen,
and Denny Zhou. 2023. Large language models as
tool makers. ArXiv, abs/2305.17126.
Tommaso Calò and Luigi De Russis. 2023. Leverag-
ing large language models for end-user website gen-
eration. In International Symposium onEnd User
Development, pages 52–61. Springer.
Angelica Chen, Jérémy Scheurer, Tomasz Korbak,
Jon Ander Campos, Jun Shern Chan, Samuel R. Bow-
man, Kyunghyun Cho, and Ethan Perez. 2023a. Im-
proving code generation by training with natural lan-
guage feedback.
Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan,
Zeqi Lin, Jian-Guang Lou, and Weizhu Chen. 2022.
Codet: Code generation with generated tests.
Juo-Tung Chen and Chien-Ming Huang. 2023. For-
getful large language models: Lessons learned from
using llms in robot programming.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming
Yuan, Henrique Ponde de Oliveira Pinto, Jared Ka-
plan, Harri Edwards, Yuri Burda, Nicholas Joseph,
Greg Brockman, Alex Ray, Raul Puri, Gretchen
Krueger, Michael Petrov, Heidy Khlaaf, Girish Sas-
try, Pamela Mishkin, Brooke Chan, Scott Gray,
Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz
Kaiser, Mohammad Bavarian, Clemens Winter,
Philippe Tillet, Felipe Petroski Such, Dave Cum-
mings, Matthias Plappert, Fotios Chantzis, Eliza-
beth Barnes, Ariel Herbert-V oss, William Hebgen
Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie
Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,
William Saunders, Christopher Hesse, Andrew N.
Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan
Morikawa, Alec Radford, Matthew Knight, Miles
Brundage, Mira Murati, Katie Mayer, Peter Welinder,
Bob McGrew, Dario Amodei, Sam McCandlish, Ilya
Sutskever, and Wojciech Zaremba. 2021. Evaluating
large language models trained on code.
Wenhu Chen, Xueguang Ma, Xinyi Wang, and
William W. Cohen. 2023b. Program of thoughts
prompting: Disentangling computation from reason-
ing for numerical reasoning tasks.
Xinyun Chen, Maxwell Lin, Nathanael Schärli, and
Denny Zhou. 2023c. Teaching large language models
to self-debug.
Xinyun Chen, Chang Liu, and Dawn Song.
2018. Execution-guided neural program syn-
thesis. In International Conference onLearning
Representations.
Yangyi Chen, Xingyao Wang, Manling Li, Derek
Hoiem, and Heng Ji. 2023d. Vistruct: Visual struc-
tural knowledge extraction via curriculum guided
code-vision representation.

--- PAGE 15 ---
Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu
Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong,
Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer,
Noah A. Smith, and Tao Yu. 2023. Binding language
models in symbolic languages.
Jaemin Cho, Abhay Zala, and Mohit Bansal. 2023. Vi-
sual programming for text-to-image generation and
evaluation.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, Christopher Hesse, and John Schulman.
2021. Training verifiers to solve math word prob-
lems.
Marc-Alexandre Côté, Ákos Kádár, Xingdi Yuan,
Ben A. Kybartas, Tavian Barnes, Emery Fine, James
Moore, Matthew J. Hausknecht, Layla El Asri, Mah-
moud Adada, Wendy Tay, and Adam Trischler. 2018.
Textworld: A learning environment for text-based
games. ArXiv, abs/1806.11532.
Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, and Ziran
Wang. 2023a. Receive, reason, and react: Drive as
you say with large language models in autonomous
vehicles.
Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Yang
Zhou, Kaizhao Liang, Jintai Chen, Juanwu Lu, Zi-
chong Yang, Kuei-Da Liao, Tianren Gao, Erlong Li,
Kun Tang, Zhipeng Cao, Tong Zhou, Ao Liu, Xin-
rui Yan, Shuqi Mei, Jianguo Cao, Ziran Wang, and
Chao Zheng. 2023b. A survey on multimodal large
language models for autonomous driving.
Gelei Deng, Yi Liu, Víctor Mayoral-Vilches, Peng Liu,
Yuekang Li, Yuan Xu, Tianwei Zhang, Yang Liu,
Martin Pinzger, and Stefan Rass. 2023a. Pentest-
gpt: An llm-empowered automatic penetration test-
ing tool.
Xiang Deng, Yu Gu, Bo Zheng, Shijie Chen, Samuel
Stevens, Boshi Wang, Huan Sun, and Yu Su. 2023b.
Mind2web: Towards a generalist agent for the web.
ArXiv, abs/2306.06070.
Li Dong and Mirella Lapata. 2016. Language to logical
form with neural attention.
Yihong Dong, Ji Ding, Xue Jiang, Zhuo Li, Ge Li,
and Zhi Jin. 2023a. Codescore: Evaluating code
generation by learning code execution. ArXiv ,
abs/2301.09043.
Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. 2023b.
Self-collaboration code generation via chatgpt.
Iddo Drori, Sarah Zhang, Reece Shuttleworth, Leonard
Tang, Albert Lu, Elizabeth Ke, Kevin Liu, Linda
Chen, Sunny Tran, Newman Cheng, Roman Wang,
Nikhil Singh, Taylor L. Patti, Jayson Lynch, Avi Sh-
porer, Nakul Verma, Eugene Wu, and Gilbert Strang.
2022. A neural network solves, explains, and gener-
ates university math problems by program synthesisand few-shot learning at human level. Proceedings
oftheNational Academy ofSciences, 119(32).
Xueying Du, Mingwei Liu, Kaixin Wang, Hanlin Wang,
Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng
Sha, Xin Peng, and Yiling Lou. 2023. Classeval:
A manually-crafted benchmark for evaluating llms
on class-level code generation.
Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt
Gardner. 2022. Successive prompting for decompos-
ing complex questions.
Kevin Ellis, Maxwell Nye, Yewen Pu, Felix Sosa,
Josh Tenenbaum, and Armando Solar-Lezama. 2019.
Write, execute, assess: Program synthesis with a
repl. Advances inNeural Information Processing
Systems, 32.
Angela Fan, Beliz Gokkaya, Mark Harman, Mitya
Lyubarskiy, Shubho Sengupta, Shin Yoo, and Jie M.
Zhang. 2023. Large language models for software
engineering: Survey and open problems.
Weixi Feng, Wanrong Zhu, Tsu-jui Fu, Varun Jampani,
Arjun Akula, Xuehai He, Sugato Basu, Xin Eric
Wang, and William Yang Wang. 2023. Layout-
gpt: Compositional visual planning and genera-
tion with large language models. arXiv preprint
arXiv:2305.15393.
Patrick Fernandes, Aman Madaan, Emmy Liu, António
Farinhas, Pedro Henrique Martins, Amanda Bertsch,
José GC de Souza, Shuyan Zhou, Tongshuang Wu,
Graham Neubig, et al. 2023. Bridging the gap: A sur-
vey on integrating (human) feedback for natural lan-
guage generation. arXiv preprint arXiv:2305.00955.
Hao Fu, Yao; Peng and Tushar Khot. 2022. How does
gpt obtain its ability? tracing emergent abilities of
language models to their sources. YaoFu’s Notion.
Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and
Tushar Khot. 2023. Complexity-based prompting for
multi-step reasoning.
Hiroki Furuta, Kuang-Huei Lee, Ofir Nachum, Yutaka
Matsuo, Aleksandra Faust, Shixiang Shane Gu, and
Izzeddin Gur. 2023. Multimodal web navigation with
instruction-finetuned foundation models.
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,
Pengfei Liu, Yiming Yang, Jamie Callan, and Gra-
ham Neubig. 2023. Pal: Program-aided language
models. In International Conference onMachine
Learning, pages 10764–10799. PMLR.
Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,
Dan Roth, and Jonathan Berant. 2021. Did aristotle
use a laptop? a question answering benchmark with
implicit reasoning strategies. Transactions ofthe
Association forComputational Linguistics , 9:346–
361.

--- PAGE 16 ---
Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen,
Yujiu Yang, Nan Duan, and Weizhu Chen. 2023.
CRITIC: Large language models can self-correct
with tool-interactive critiquing.
Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish
Shevade. 2017. Deepfix: Fixing common c language
errors by deep learning. In Proceedings oftheaaai
conference onartificial intelligence, volume 31.
Tanmay Gupta and Aniruddha Kembhavi. 2023. Vi-
sual programming: Compositional visual reason-
ing without training. In Proceedings ofthe
IEEE/CVF Conference onComputer Vision and
Pattern Recognition, pages 14953–14962.
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-
pat, and Mingwei Chang. 2020. Retrieval augmented
language model pre-training. In Proceedings ofthe
37th International Conference onMachine Learning ,
volume 119 of Proceedings ofMachine Learning
Research, pages 3929–3938. PMLR.
Patrick Haluptzok, Matthew Bowers, and Adam Tauman
Kalai. 2022. Language models can teach themselves
to program better. arXiv preprint arXiv:2207.14502.
Shibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu.
2023. ToolkenGPT: Augmenting frozen language
models with massive tools via tool embeddings.
Dan Hendrycks, Steven Basart, Saurav Kadavath, Man-
tas Mazeika, Akul Arora, Ethan Guo, Collin Burns,
Samir Puranik, Horace He, Dawn Song, et al. 2021.
Measuring coding challenge competence with apps.
arXiv preprint arXiv:2105.09938.
Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng
Cheng, Ceyao Zhang, Zili Wang, Steven Ka Shing
Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al.
2023. Metagpt: Meta programming for multi-
agent collaborative framework. arXiv preprint
arXiv:2308.00352.
Junjie Huang, Chenglong Wang, Jipeng Zhang, Cong
Yan, Haotian Cui, Jeevana Priya Inala, Colin Clement,
Nan Duan, and Jianfeng Gao. 2022a. Execution-
based evaluation for data science code generation
models. arXiv preprint arXiv:2211.09374.
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and
Igor Mordatch. 2022b. Language models as zero-
shot planners: Extracting actionable knowledge for
embodied agents. In International Conference on
Machine Learning, pages 9118–9147. PMLR.
Wenlong Huang, Chen Wang, Ruohan Zhang, Yun-
zhu Li, Jiajun Wu, and Li Fei-Fei. 2023a. V ox-
poser: Composable 3d value maps for robotic ma-
nipulation with language models. arXiv preprint
arXiv:2307.05973.
Yu Huang, Yue Chen, and Zhu Li. 2023b. Applications
of large scale foundation models for autonomous
driving. arXiv preprint arXiv:2311.12144.Drew A Hudson and Christopher D Manning. 2019.
Gqa: A new dataset for real-world visual rea-
soning and compositional question answering.
InProceedings oftheIEEE/CVF conference on
computer vision andpattern recognition , pages 6700–
6709.
Jeevana Priya Inala, Chenglong Wang, Mei Yang, An-
dres Codas, Mark Encarnación, Shuvendu Lahiri,
Madanlal Musuvathi, and Jianfeng Gao. 2022. Fault-
aware neural code rankers. Advances inNeural
Information Processing Systems, 35:13419–13432.
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas
Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-
Yu, Armand Joulin, Sebastian Riedel, and Edouard
Grave. 2022. Atlas: Few-shot learning with retrieval
augmented language models.
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan
Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea
Madotto, and Pascale Fung. 2023. Survey of hal-
lucination in natural language generation. ACM
Computing Surveys, 55(12):1–38.
Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei
Shang, and Ge Li. 2023. Self-planning code gen-
eration with large language model. arXiv preprint
arXiv:2303.06689.
Qiao Jin, Yifan Yang, Qingyu Chen, and Zhiyong Lu.
2023. GeneGPT: Augmenting large language models
with domain tools for improved access to biomedical
information.
Sungmin Kang, Gabin An, and Shin Yoo. 2023a. A
preliminary evaluation of llm-based fault localization.
arXiv preprint arXiv:2308.05487.
Sungmin Kang, Juyeon Yoon, and Shin Yoo. 2023b.
Large language models are few-shot testers: Ex-
ploring llm-based general bug reproduction. In
2023 IEEE/ACM 45th International Conference on
Software Engineering (ICSE) , pages 2312–2323.
IEEE.
Shyam Sundar Kannan, Vishnunandan LN Venkatesh,
and Byung-Cheol Min. 2023. Smart-llm: Smart
multi-agent robot task planning using large language
models. arXiv preprint arXiv:2309.10062.
Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang,
Ruiqi Zhong, Luke Zettlemoyer, Wen-tau Yih, Daniel
Fried, Sida Wang, and Tao Yu. 2023. Ds-1000: A
natural and reliable benchmark for data science code
generation. In International Conference onMachine
Learning, pages 18319–18345. PMLR.
Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio
Savarese, and Steven Chu Hong Hoi. 2022. Coderl:
Mastering code generation through pretrained mod-
els and deep reinforcement learning. Advances in
Neural Information Processing Systems , 35:21314–
21328.

--- PAGE 17 ---
Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu,
Fangyu Liu, Julian Eisenschlos, Urvashi Khandel-
wal, Peter Shaw, Ming-Wei Chang, and Kristina
Toutanova. 2023. Pix2struct: Screenshot parsing
as pretraining for visual language understanding.
Ioktong Lei and Zhidong Deng. 2023. Selfzcot: a self-
prompt zero-shot cot from semantic-level to code-
level for a better utilization of llms.
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio
Petroni, Vladimir Karpukhin, Naman Goyal, Hein-
rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-
täschel, Sebastian Riedel, and Douwe Kiela. 2020.
Retrieval-augmented generation for knowledge-
intensive nlp tasks. In Advances inNeural
Information Processing Systems , volume 33, pages
9459–9474. Curran Associates, Inc.
Haonan Li, Yu Hao, Yizhuo Zhai, and Zhiyun Qian.
2023a. The hitchhiker’s guide to program analysis: A
journey with large language models. arXiv preprint
arXiv:2308.00245.
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
2023b. Blip-2: Bootstrapping language-image pre-
training with frozen image encoders and large lan-
guage models. arXiv preprint arXiv:2301.12597.
Sha Li, Chi Han, Pengfei Yu, Carl Edwards, Manling Li,
Xingyao Wang, Yi Fung, Charles Yu, Joel Tetreault,
Eduard Hovy, and Heng Ji. 2023c. Defining a new
NLP playground. In Findings oftheAssociation
forComputational Linguistics: EMNLP 2023 , pages
11932–11951, Singapore. Association for Computa-
tional Linguistics.
Xin Li, Yeqi Bai, Pinlong Cai, Licheng Wen,
Daocheng Fu, Bo Zhang, Xuemeng Yang, Xinyu
Cai, Tao Ma, Jianfei Guo, et al. 2023d. To-
wards knowledge-driven autonomous driving. arXiv
preprint arXiv:2312.04316.
Yujia Li, David Choi, Junyoung Chung, Nate Kushman,
Julian Schrittwieser, Rémi Leblond, Tom Eccles,
James Keeling, Felix Gimeno, Agustin Dal Lago,
et al. 2022. Competition-level code generation with
alphacode. Science, 378(6624):1092–1097.
Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu,
Karol Hausman, Brian Ichter, Pete Florence, and
Andy Zeng. 2023a. Code as policies: Language
model programs for embodied control. In 2023
IEEE International Conference onRobotics and
Automation (ICRA), pages 9493–9500. IEEE.
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris
Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian
Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-
mar, Benjamin Newman, Binhang Yuan, Bobby Yan,
Ce Zhang, Christian Cosgrove, Christopher D. Man-
ning, Christopher R’e, Diana Acosta-Navas, Drew A.
Hudson, E. Zelikman, Esin Durmus, Faisal Ladhak,
Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang,
Keshav Santhanam, Laurel J. Orr, Lucia Zheng, MertYuksekgonul, Mirac Suzgun, Nathan S. Kim, Neel
Guha, Niladri S. Chatterji, Omar Khattab, Peter
Henderson, Qian Huang, Ryan Chi, Sang Michael
Xie, Shibani Santurkar, Surya Ganguli, Tatsunori
Hashimoto, Thomas F. Icard, Tianyi Zhang, Vishrav
Chaudhary, William Wang, Xuechen Li, Yifan Mai,
Yuhui Zhang, and Yuta Koreeda. 2023b. Holistic
evaluation of language models. Annals oftheNew
York Academy ofSciences, 1525:140 – 146.
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris
Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian
Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-
mar, Benjamin Newman, Binhang Yuan, Bobby Yan,
Ce Zhang, Christian Cosgrove, Christopher D. Man-
ning, Christopher Ré, Diana Acosta-Navas, Drew A.
Hudson, Eric Zelikman, Esin Durmus, Faisal Lad-
hak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue
Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng,
Mert Yuksekgonul, Mirac Suzgun, Nathan Kim,
Neel Guha, Niladri Chatterji, Omar Khattab, Peter
Henderson, Qian Huang, Ryan Chi, Sang Michael
Xie, Shibani Santurkar, Surya Ganguli, Tatsunori
Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav
Chaudhary, William Wang, Xuechen Li, Yifan Mai,
Yuhui Zhang, and Yuta Koreeda. 2023c. Holistic
evaluation of language models.
Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu,
Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji,
Shaoguang Mao, et al. 2023d. Taskmatrix. ai: Com-
pleting tasks by connecting foundation models with
millions of apis. arXiv preprint arXiv:2303.16434.
Mark H. Liffiton, Brad E. Sheese, Jaromir Savelka, and
Paul Denny. 2023. Codehelp: Using large language
models with guardrails for scalable support in pro-
gramming classes. ArXiv, abs/2308.06921.
Chin-Yew Lin. 2004. Rouge: A package for automatic
evaluation of summaries. In Text summarization
branches out, pages 74–81.
Jiawei Lin, Jiaqi Guo, Shizhao Sun, Weijiang Xu, Ting
Liu, Jian-Guang Lou, and Dongmei Zhang. 2023.
A parse-then-place approach for generating graphic
layouts from textual descriptions.
Fangyu Liu, Francesco Piccinno, Syrine Krichene,
Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin
Altun, Nigel Collier, and Julian Martin Eisenschlos.
2023a. Matcha: Enhancing visual language pretrain-
ing with math reasoning and chart derendering.
Jiateng Liu, Sha Li, Zhenhailong Wang, Manling Li, and
Heng Ji. 2023b. A language-first approach for pro-
cedure planning. In Findings oftheAssociation for
Computational Linguistics: ACL 2023, pages 1941–
1954.
Michael Xieyang Liu, Advait Sarkar, Carina Negreanu,
Benjamin Zorn, Jack Williams, Neil Toronto, and
Andrew D Gordon. 2023c. “what it wants me to say”:

--- PAGE 18 ---
Bridging the abstraction gap between end-user pro-
grammers and code-generating large language mod-
els. In Proceedings ofthe2023 CHI Conference on
Human Factors inComputing Systems, pages 1–31.
Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng,
Zhengxiao Du, P. Zhang, Yuxiao Dong, and Jie Tang.
2023d. Webglm: Towards an efficient web-enhanced
question answering system with human preferences.
Proceedings ofthe29th ACM SIGKDD Conference
onKnowledge Discovery andData Mining.
Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng,
Zhengxiao Du, Peng Zhang, Yuxiao Dong, and Jie
Tang. 2023e. WebGLM: Towards an efficient web-
enhanced question answering system with human
preferences.
Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xu-
anyu Lei, Hanyu Lai, Yu Gu, Yuxian Gu, Hangliang
Ding, Kai Men, Kejuan Yang, Shudan Zhang, Xiang
Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang,
Shengqi Shen, Tianjun Zhang, Yu Su, Huan Sun,
Minlie Huang, Yuxiao Dong, and Jie Tang. 2023f.
Agentbench: Evaluating llms as agents. ArXiv ,
abs/2308.03688.
Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi
Yang. 2023g. Dynamic llm-agent network: An llm-
agent collaboration framework with agent team opti-
mization. arXiv preprint arXiv:2310.02170.
Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-
Wei Chang, Ying Nian Wu, Song-Chun Zhu, and Jian-
feng Gao. 2023. Chameleon: Plug-and-play compo-
sitional reasoning with large language models. arXiv
preprint arXiv:2304.09842.
Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey
Svyatkovskiy, Ambrosio Blanco, Colin Clement,
Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li, Lidong
Zhou, Linjun Shou, Long Zhou, Michele Tufano,
Ming Gong, Ming Zhou, Nan Duan, Neel Sundare-
san, Shao Kun Deng, Shengyu Fu, and Shujie Liu.
2021. Codexglue: A machine learning benchmark
dataset for code understanding and generation.
Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang,
Delip Rao, Eric Wong, Marianna Apidianaki,
and Chris Callison-Burch. 2023. Faithful
chain-of-thought reasoning. arXiv preprint
arXiv:2301.13379.
Yingwei Ma, Yue Liu, Yue Yu, Yuanliang Zhang,
Yu Jiang, Changjian Wang, and Shanshan Li. 2023a.
At which training stage does code data help llms
reasoning?
Yunsheng Ma, Can Cui, Xu Cao, Wenqian Ye, Peiran
Liu, Juanwu Lu, Amr Abdelraouf, Rohit Gupta,
Kyungtae Han, Aniket Bera, et al. 2023b. Lampi-
lot: An open benchmark dataset for autonomous driv-
ing with language model programs. arXiv preprint
arXiv:2312.04372.Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang,
and Graham Neubig. 2022. Language models of
code are few-shot commonsense learners.
Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, and
Yue Wang. 2023. A language agent for autonomous
driving. arXiv preprint arXiv:2311.10813.
Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christo-
foros Nalmpantis, Ramakanth Pasunuru, Roberta
Raileanu, Baptiste Rozière, Timo Schick, Jane
Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann
LeCun, and Thomas Scialom. 2023. Augmented
language models: a survey. ArXiv, abs/2302.07842.
Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard
Tang, Sean Welleck, Chitta Baral, Tanmay Rajpuro-
hit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark,
and Ashwin Kalyan. 2023. Lila: A unified bench-
mark for mathematical reasoning.
Mohammad Mahdi Mohajer, Reem Aleithan,
Nima Shiri Harzevili, Moshi Wei, Alvine Boaye
Belle, Hung Viet Pham, and Song Wang. 2023.
Skipanalyzer: An embodied agent for code anal-
ysis with large language models. arXiv preprint
arXiv:2310.18532.
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
Long Ouyang, Christina Kim, Christopher Hesse,
Shantanu Jain, Vineet Kosaraju, William Saunders,
et al. 2021. Webgpt: Browser-assisted question-
answering with human feedback. arXiv preprint
arXiv:2112.09332.
Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoy-
anov, Wen-tau Yih, Sida Wang, and Xi Victoria
Lin. 2023. Lever: Learning to verify language-to-
code generation with execution. In International
Conference onMachine Learning , pages 26106–
26128. PMLR.
Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan
Wang, Yingbo Zhou, Silvio Savarese, and Caiming
Xiong. 2022. Codegen: An open large language
model for code with multi-turn program synthesis.
arXiv preprint arXiv:2203.13474.
David Noever. 2023. Can large language models
find and fix vulnerable software? arXiv preprint
arXiv:2308.10345.
OpenAI. 2023. Gpt-4 technical report.
Jitesh H Panchal and Ziran Wang. 2023. Design of
next-generation automotive systems: Challenges and
research opportunities. Journal ofComputing and
Information Science inEngineering, 23(6).
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings
ofthe40th annual meeting oftheAssociation for
Computational Linguistics, pages 311–318.

--- PAGE 19 ---
Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022a.
Talm: Tool augmented language models. ArXiv ,
abs/2205.12255.
Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022b.
TALM: Tool augmented language models.
Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E
Gonzalez. 2023. Gorilla: Large language model
connected with massive APIs.
Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng,
Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou
Yu, Weizhu Chen, and Jianfeng Gao. 2023. Check
your facts and try again: Improving large language
models with external knowledge and automated feed-
back.
Stanislas Polu and Ilya Sutskever. 2020. Generative
language modeling for automated theorem proving.
Chen Qian, Xin Cong, Cheng Yang, Weize Chen,
Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong
Sun. 2023a. Communicative agents for software de-
velopment. arXiv preprint arXiv:2307.07924.
Cheng Qian, Chi Han, Yi Ren Fung, Yujia Qin, Zhiyuan
Liu, and Heng Ji. 2023b. Creator: Tool creation
for disentangling abstract and concrete reasoning of
large language models.
Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen,
Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang,
Chaojun Xiao, Chi Han, et al. 2023. Tool
learning with foundation models. arXiv preprint
arXiv:2304.08354.
Nitarshan Rajkumar, Raymond Li, and Dzmitry Bah-
danau. 2022. Evaluating the text-to-sql capabilities
of large language models.
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,
Amnon Shashua, Kevin Leyton-Brown, and Yoav
Shoham. 2023. In-Context retrieval-augmented lan-
guage models.
Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie Liu,
Duyu Tang, Neel Sundaresan, Ming Zhou, Ambrosio
Blanco, and Shuai Ma. 2020. Codebleu: a method
for automatic evaluation of code synthesis. arXiv
preprint arXiv:2009.10297.
Jasmine Roberts, Andrzej Banburski-Fahey, Microsoft
Jaron, and Lanier Microsoft. Surreal vr pong: Llm
approach to game design.
Alex Robinson. 2019. Sketch2code: Generating a web-
site from a paper mockup.
Jérémy Scheurer, Jon Ander Campos, Jun Shern Chan,
Angelica Chen, Kyunghyun Cho, and Ethan Perez.
2022. Training language models with natural lan-
guage feedback. arXiv preprint arXiv:2204.14146 ,
8.Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta
Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola
Cancedda, and Thomas Scialom. 2023. Toolformer:
Language models can teach themselves to use tools.
Hao Sha, Yao Mu, Yuxuan Jiang, Li Chen, Chenfeng Xu,
Ping Luo, Shengbo Eben Li, Masayoshi Tomizuka,
Wei Zhan, and Mingyu Ding. 2023. Languagempc:
Large language models as decision makers for au-
tonomous driving. arXiv preprint arXiv:2310.03026 .
Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li,
Weiming Lu, and Yueting Zhuang. 2023. Hugging-
gpt: Solving ai tasks with chatgpt and its friends in
huggingface. arXiv preprint arXiv:2303.17580.
Freda Shi, Daniel Fried, Marjan Ghazvininejad, Luke
Zettlemoyer, and Sida I Wang. 2022. Natural lan-
guage to code translation with execution. arXiv
preprint arXiv:2204.11454.
Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté,
Yonatan Bisk, Adam Trischler, and Matthew J.
Hausknecht. 2020. Alfworld: Aligning text and em-
bodied environments for interactive learning. ArXiv ,
abs/2010.03768.
Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju,
Eric Michael Smith, Stephen Roller, Megan Ung,
Moya Chen, Kushal Arora, Joshua Lane, Morteza
Behrooz, William Ngan, Spencer Poff, Naman Goyal,
Arthur Szlam, Y-Lan Boureau, Melanie Kambadur,
and Jason Weston. 2022. BlenderBot 3: a deployed
conversational agent that continually learns to respon-
sibly engage.
Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit
Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox,
Jesse Thomason, and Animesh Garg. 2022. Prog-
prompt: Generating situated robot task plans using
large language models.
Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu,
Han Qian, Mingbo Song, Hailiang Huang, Cheng Li,
Ke Wang, Rong Yao, Ye Tian, and Sujian Li. 2023.
RestGPT: Connecting large language models with
real-world RESTful APIs.
Davit Soselia, Khalid Saifullah, and Tianyi Zhou. 2023.
Learning ui-to-code reverse generator using visual
critic without rendering.
Abishek Sridhar, Robert Lo, Frank F. Xu, Hao Zhu, and
Shuyan Zhou. 2023. Hierarchical prompting assists
large language model on web navigation.
Sanjay Subramanian, Medhini Narasimhan, Kushal
Khangaonkar, Kevin Yang, Arsha Nagrani, Cordelia
Schmid, Andy Zeng, Trevor Darrell, and Dan Klein.
2023. Modular visual question answering via code
generation. arXiv preprint arXiv:2306.05392.
Chunyi Sun, Junlin Han, Weijian Deng, Xinlong Wang,
Zishan Qin, and Stephen Gould. 2023a. 3d-gpt: Pro-
cedural 3d modeling with large language models.
arXiv preprint arXiv:2310.12945.

--- PAGE 20 ---
Ruoxi Sun, Sercan O. Arik, Hootan Nakhost, Hanjun
Dai, Rajarishi Sinha, Pengcheng Yin, and Tomas
Pfister. 2023b. Sql-palm: Improved large language
model adaptation for text-to-sql.
Dídac Surís, Sachit Menon, and Carl V ondrick. 2023.
Vipergpt: Visual inference via python execution for
reasoning. arXiv preprint arXiv:2303.08128.
Melanie Swan, Takashi Kido, Eric Roland, and Renato P.
dos Santos. 2023. Math agents: Computational in-
frastructure, mathematical embedding, and genomics.
ArXiv, abs/2307.02502.
Yashar Talebirad and Amirhossein Nadiri. 2023. Multi-
agent collaboration: Harnessing the power of intelli-
gent llm agents. arXiv preprint arXiv:2306.03314.
Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han,
Qiao Liang, Boxi Cao, and Le Sun. 2023. ToolAl-
paca: Generalized tool learning for language models
with 3000 simulated cases.
Romal Thoppilan, Daniel De Freitas, Jamie Hall,
Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze
Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,
Yaguang Li, Hongrae Lee, Huaixiu Steven Zheng,
Amin Ghafouri, Marcelo Menegali, Yanping Huang,
Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao
Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts,
Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-
Ching Chang, Igor Krivokon, Will Rusch, Marc
Pickett, Pranesh Srinivasan, Laichee Man, Kathleen
Meier-Hellstern, Meredith Ringel Morris, Tulsee
Doshi, Renelito Delos Santos, Toju Duke, Johnny So-
raker, Ben Zevenbergen, Vinodkumar Prabhakaran,
Mark Diaz, Ben Hutchinson, Kristen Olson, Ale-
jandra Molina, Erin Hoffman-John, Josh Lee, Lora
Aroyo, Ravi Rajakumar, Alena Butryna, Matthew
Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Co-
hen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-
Arcas, Claire Cui, Marian Croak, Ed Chi, and Quoc
Le. 2022. LaMDA: Language models for dialog ap-
plications.
Hung Quoc To, Minh Nguyen, and Nghi D. Q. Bui.
2023. Neural rankers for code generation via inter-
cluster modeling.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton
Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,
Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-
thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura,
Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-
tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023. Llama 2: Open foundation and fine-
tuned chat models.
Priyan Vaithilingam, Tianyi Zhang, and Elena L Glass-
man. 2022. Expectation vs. experience: Evalu-
ating the usability of code generation tools pow-
ered by large language models. In Chiconference
onhuman factors incomputing systems extended
abstracts, pages 1–7.
Sai Vemprala, Rogerio Bonatti, Arthur Bucker, and
Ashish Kapoor. 2023. Chatgpt for robotics: De-
sign principles and model abilities. Microsoft Auton.
Syst. Robot. Res, 2:20.
Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen,
You Wu, Luke Zettlemoyer, and Huan Sun. 2023a.
Towards understanding chain-of-thought prompting:
An empirical study of what matters.
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Man-
dlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and An-
ima Anandkumar. 2023b. V oyager: An open-ended
embodied agent with large language models. arXiv
preprint arXiv:2305.16291.
Huaxiaoyue Wang, Gonzalo Gonzalez-Pumariega,
Yash Sharma, and Sanjiban Choudhury. 2023c.
Demo2code: From summarizing demonstrations to
synthesizing code via extended chain-of-thought.
arXiv preprint arXiv:2305.16744.
Ke Wang, Rishabh Singh, and Zhendong Su. 2017. Dy-
namic neural program embedding for program repair.
arXiv preprint arXiv:1711.07163.
Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao
Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang,
Xu Chen, Yankai Lin, et al. 2023d. A survey on large
language model based autonomous agents. arXiv
preprint arXiv:2308.11432.
Shiyi Wang, Yuxuan Zhu, Zhiheng Li, Yutong Wang,
Li Li, and Zhengbing He. 2023e. Chatgpt as your ve-
hicle co-pilot: An initial attempt. IEEE Transactions
onIntelligent Vehicles.
Xin Wang, Yasheng Wang, Yao Wan, Fei Mi, Yi-
tong Li, Pingyi Zhou, Jin Liu, Hao Wu, Xin Jiang,
and Qun Liu. 2022. Compilable neural code gen-
eration with compiler feedback. arXiv preprint
arXiv:2203.05132.
Xingyao Wang, Sha Li, and Heng Ji. 2023f.
Code4struct: Code generation for few-shot event
structure prediction.
Xingyao Wang, Hao Peng, Reyhaneh Jabbarvand, and
Heng Ji. 2023g. Leti: Learning to generate from tex-
tual interactions. arXiv preprint arXiv:2305.10314.

--- PAGE 21 ---
Xingyao Wang, Zihan Wang, Jiateng Liu, Yangyi
Chen, Lifan Yuan, Hao Peng, and Heng Ji. 2023h.
Mint: Evaluating llms in multi-turn interaction
with tools and language feedback. arXiv preprint
arXiv:2309.10691.
Wayve. 2023. LINGO-1: Exploring Natural Language
for Autonomous Driving.
Colin Wei, Sang Michael Xie, and Tengyu Ma. 2022a.
Why do pretrained language models help in down-
stream tasks? an analysis of head and prompt tuning.
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,
Barret Zoph, Sebastian Borgeaud, Dani Yogatama,
Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.
Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy
Liang, Jeff Dean, and William Fedus. 2022b. Emer-
gent abilities of large language models.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and
Denny Zhou. 2023. Chain-of-thought prompting elic-
its reasoning in large language models.
Man-Fai Wong, Shangxin Guo, Ching-Nam Hang, Siu-
Wai Ho, and Chee-Wei Tan. 2023. Natural lan-
guage generation and understanding of big code
for AI-assisted programming: A review. Entropy ,
25(6):888.
Chenfei Wu, Shengming Yin, Weizhen Qi, Xi-
aodong Wang, Zecheng Tang, and Nan Duan.
2023a. Visual chatgpt: Talking, drawing and edit-
ing with visual foundation models. arXiv preprint
arXiv:2303.04671.
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu,
Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang,
Xiaoyun Zhang, and Chi Wang. 2023b. Auto-
gen: Enabling next-gen llm applications via multi-
agent conversation framework. arXiv preprint
arXiv:2308.08155.
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu,
Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang,
Xiaoyun Zhang, and Chi Wang. 2023c. Autogen:
Enabling next-gen llm applications via multi-agent
conversation framework. ArXiv, abs/2308.08155.
Yuhuai Wu, Albert Q. Jiang, Wenda Li, Markus N.
Rabe, Charles Staats, Mateja Jamnik, and Christian
Szegedy. 2022. Autoformalization with large lan-
guage models.
Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen
Ding, Boyang Hong, Ming Zhang, Junzhe Wang,
Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan,
Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran
Wang, Changhao Jiang, Yicheng Zou, Xiangyang
Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng,
Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan
Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui.
2023. The rise and potential of large language model
based agents: A survey.Frank F Xu, Uri Alon, Graham Neubig, and Vincent Jo-
sua Hellendoorn. 2022. A systematic evaluation of
large language models of code. In Proceedings of
the6thACM SIGPLAN International Symposium
onMachine Programming, pages 1–10.
Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian
Liu, Weijia Shi, Binyuan Hui, Fan Zhou, Yitao Liu,
Tianbao Xie, Zhoujun Cheng, Siheng Zhao, Ling-
peng Kong, Bailin Wang, Caiming Xiong, and Tao
Yu. 2023. Lemur: Harmonizing natural language and
code for language agents.
Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin
Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu,
Ce Liu, Michael Zeng, and Lijuan Wang. 2023. Mm-
react: Prompting chatgpt for multimodal reasoning
and action. arXiv preprint arXiv:2303.11381.
Shunyu Yao, Howard Chen, John Yang, and Karthik
Narasimhan. 2022a. Webshop: Towards scalable
real-world web interaction with grounded language
agents. ArXiv, abs/2207.01206.
Shunyu Yao, Howard Chen, John Yang, and Karthik
Narasimhan. 2022b. Webshop: Towards scal-
able real-world web interaction with grounded lan-
guage agents. In Advances inNeural Information
Processing Systems , volume 35, pages 20744–20757.
Curran Associates, Inc.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran, Karthik Narasimhan, and Yuan Cao. 2022c.
ReAct: Synergizing reasoning and acting in language
models.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran, Karthik Narasimhan, and Yuan Cao. 2022d.
React: Synergizing reasoning and acting in language
models. ArXiv, abs/2210.03629.
Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi,
Rich James, Jure Leskovec, Percy Liang, Mike
Lewis, Luke Zettlemoyer, and Wen-Tau Yih. 2022.
Retrieval-augmented multimodal language modeling.
Junjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai Shao,
Shichun Liu, Yuhan Cui, Zeyang Zhou, Chao Gong,
Yang Shen, et al. 2023a. A comprehensive capability
analysis of gpt-3 and gpt-3.5 series models. arXiv
preprint arXiv:2303.10420.
Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei
Huang, and Yongbin Li. 2023b. Large language mod-
els are versatile decomposers: Decompose evidence
and questions for table-based reasoning.
Da Yin, Faeze Brahman, Abhilasha Ravichander, Khy-
athi Chandu, Kai-Wei Chang, Yejin Choi, and
Bill Yuchen Lin. 2023. Lumos: Towards language
agents that are unified, modular, and open source.
Pengcheng Yin and Graham Neubig. 2019. Rerank-
ing for neural semantic parsing. In Proceedings
ofthe57th Annual Meeting oftheAssociation for
Computational Linguistics.

--- PAGE 22 ---
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,
Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingn-
ing Yao, Shanelle Roman, Zilin Zhang, and Dragomir
Radev. 2019. Spider: A large-scale human-labeled
dataset for complex and cross-domain semantic pars-
ing and text-to-sql task.
Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi Ren Fung,
Hao Peng, and Heng Ji. 2023. Craft: Customiz-
ing llms by creating and retrieving from specialized
toolsets. ArXiv, abs/2309.17428.
Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie
Lu, Bingchao Wu, Bei Guan, Wang Yongji, and
Jian-Guang Lou. 2023. Large language mod-
els meet nl2code: A survey. In Proceedings
ofthe61st Annual Meeting oftheAssociation
forComputational Linguistics (V olume 1:Long
Papers), pages 7443–7464.
Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning
Liu, and Philip S Yu. 2023a. Large language
models for robotics: A survey. arXiv preprint
arXiv:2311.07226.
Lu Zeng, Sree Hari Krishnan Parthasarathi, and Dilek
Hakkani-Tur. 2023b. N-best hypotheses rerank-
ing for text-to-sql systems. In 2022 IEEE Spoken
Language Technology Workshop (SLT) , pages 663–
670. IEEE.
Wei Zeng, Xiaozhe Ren, Teng Su, Hui Wang, Yi Liao,
Zhiwei Wang, Xin Jiang, ZhenZhang Yang, Kaisheng
Wang, Xiaoda Zhang, Chen Li, Ziyan Gong, Yi-
fan Yao, Xinjing Huang, Jun Wang, Jianfeng Yu,
Qi Guo, Yue Yu, Yan Zhang, Jin Wang, Hengtao
Tao, Dasen Yan, Zexuan Yi, Fang Peng, Fangqing
Jiang, Han Zhang, Lingfeng Deng, Yehong Zhang,
Zhe Lin, Chao Zhang, Shaojie Zhang, Mingyue Guo,
Shanzhi Gu, Gaojun Fan, Yaowei Wang, Xuefeng
Jin, Qun Liu, and Yonghong Tian. 2021. Pangu-
α: Large-scale autoregressive pretrained chinese lan-
guage models with auto-parallel computation.
Kechi Zhang, Zhuo Li, Jia Li, Ge Li, and Zhi Jin. 2023a.
Self-edit: Fault-aware code editor for code genera-
tion. arXiv preprint arXiv:2305.04087.
Tianyi Zhang, Tao Yu, Tatsunori Hashimoto, Mike
Lewis, Wen-tau Yih, Daniel Fried, and Sida Wang.
2023b. Coder reviewer reranking for code generation.
InInternational Conference onMachine Learning ,
pages 41832–41846. PMLR.
Pengyu Zhao, Zijian Jin, and Ning Cheng. 2023. An in-
depth survey of large language model-based artificial
intelligence agents.
Hongyi Zheng and Abulhair Saparov. 2023. Noisy ex-
emplars make large language models more robust: A
domain-agnostic behavioral analysis.
Victor Zhong, Caiming Xiong, and Richard Socher.
2017. Seq2sql: Generating structured queries from
natural language using reinforcement learning. arXiv
preprint arXiv:1709.00103.Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun
Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi
Song, Mingjie Zhan, et al. 2023a. Solving chal-
lenging math word problems using gpt-4 code in-
terpreter with code-based self-verification. arXiv
preprint arXiv:2308.07921.
Xuanhe Zhou, Guoliang Li, and Zhiyuan Liu. 2023b.
Llm as dba. arXiv preprint arXiv:2308.05481.
Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Wei-
jie Su, Chenyuan Yang, Gao Huang, Bin Li, Lewei
Lu, Xiaogang Wang, Y . Qiao, Zhaoxiang Zhang, and
Jifeng Dai. 2023. Ghost in the minecraft: Gener-
ally capable agents for open-world environments via
large language models with text-based knowledge
and memory. ArXiv, abs/2305.17144.
Terry Yue Zhuo. 2023. Large language models are
state-of-the-art evaluators of code generation. arXiv
preprint arXiv:2304.14317.
A Discussion
A.1 Intrinsic Qualities of Code that
Contribute to LLM Empowerment
Reflecting on our definition of code in the introduc-
tion section (§1) as formal languages that are both
human-interpretable and machine-executable, we
highlight that while some features are shared by
all code, programming language, as the most well-
known and most established type of code, enjoy
some unique advantages. In Figure 7, we provide a
case study comparing code and natural language.
First, we talk about the core feature shared by
all code within the range of our definition. The
inherent nature of code is that they are explicit and
have clear definitions for every single line, while
natural language is generally in free form and can
be very ambiguous. Consequently, code is sig-
nificantly better at expressing detailed commands,
signifying a specific step, and transmitting control
signals. This generally led to the improvement in
§4, the improvement for more controlled planning
(cf. planning part in §6.1), and also helped with
action execution (§6.2).
Programming languages, a critical component
of the code family, are specifically designed for
machine communication. Their advantages ex-
tend beyond mere explicitness and clarity. One
overwhelming feature of programming languages
(though some formal languages also define logical
commands and loops) is that they contain structural
definitions. Some well-known features are logical
operands (If & Else), loops (For & While), nest-
ing (within Functions), and even class definition

--- PAGE 23 ---
Figure 7: We generate pseudo-code for the “IntelligentAgent” class and employ ChatGPT to compile its docstring.
By contrasting the self-explanatory code with its natural language docstring, we observe that code exhibits greater
structure, expressiveness, and logical coherence, underscoring certain advantages of code over natural language.
and class inheritance (Object Oriented Program-
ming). This feature makes them super suitable
for expressing nesting and complicated structures
(cf. §3.3 and the perception part in §6.1). Another
feature is that programming languages are often
paired with a very powerful execution environment.
This executable feature benefits much as it natu-
rally delegates some harder tasks to lower level,
like arithmetic computing or interacting with a sim-
ulated environment when connecting to a Database,
Minecraft, and so on, also facilitating reasoning
discussed in §3.2. What’s more, the execution of-
ten includes feedback mechanisms, which can be
valuable for further refining the generator (§5 and
§6.3).
A.2 Breadth by Code Delegation or Depth by
Multimodality Joint Learning
LLMs can swiftly and cost-effectively address
tasks involving more data modalities by utilizing
code to invoke tools. Simultaneously, joint fine-
tuning on multimodal data enhances the model’s
precision and robustness in perceiving each modal-ity, resulting in superior task performance. For
instance, on the VQA dataset GQA (Hudson and
Manning, 2019), ViperGPT (Surís et al., 2023),
a typical code-centric paradigm, marginally sur-
passes the multimodal model BLIP-2 (Li et al.,
2023b) in the zero-shot scenario after learning
visual model API usages. However, its accu-
racy remains significantly lower than other su-
pervised multimodal models. It is also still un-
certain whether this approach will surpass the
state-of-the-art models on multi-modal procedu-
ral planning (Liu et al., 2023b). One reason
is that the code-centric paradigm’s effectiveness
hinges on the central decision model and individ-
ual task execution components. This makes code-
delegation approaches susceptible to error accumu-
lation across steps and highly influenced by the
worst-performing sub-modules or tools. Neverthe-
less, code delegation remains essential, as certain
tools’ advantages, such as the precision of calcu-
lators and the flexibility of search engines, cannot
be learned by training multimodality models alone.
The high extensibility of the code-centric paradigm

--- PAGE 24 ---
to various tools and modalities also makes it a per-
fect fit for domains where training data is hard to
collect at scale. We anticipate that the central de-
cision model, utilizing code to invoke tools, will
evolve from text-only LLMs to multimodality mod-
els capable of comprehensively understanding and
processing multimodal data.
A.3 The Potential of Using Code-centric
Framework for Intelligent Agent
Construction
We observed a rising trend in leveraging code in
the construction of LLM-based intelligent agents.
As shown in §6, we showed three major scenar-
ios where agents can effectively benefit from code
usage. We also identified that this trend mainly
originated from the increasing need to evaluate
agents in a real-world scenario, where executive
environments and interactions are everywhere. A
natural question arises: Does code have the poten-
tial to substitute natural language and become the
dominant media in the construction of agents?
A lot of work has begun to adopt this approach,
like V oyager (Wang et al., 2023b) in a simulated
Minecraft environment. They used code for high-
level planning, low-level control sequence, and
execution to interact with the environment. Ac-
quired skills are also organized in the format of
code snippets. With the code-centric paradigm,
the framework is highly automatic and efficient.
However, it’s also true that many framework today
are still using natural language for planning, proba-
bly because they provide more human-interpretable
reasoning steps. Human feedback in natural lan-
guage is also widely used to harvest strong reward
models that reflect real human preferences. We hy-
pothesize that the integration of code will continue
gaining popularity on our path to AGI, especially
for facilitating interactions between agents and the
real world. Nevertheless, natural language could
hardly be replaced regarding the interaction be-
tween agents and humans.(Drori et al., 2022; Chen
et al., 2023b; Lei and Deng, 2023). Leveraging this
understanding, we aim to explore novel research av-
enues in LLM reasoning inspired by the utilization
of “code”.
B Paper Statistics from Arxiv
We write a Python script that serves as a web
scraper to extract paper details from the ArXiv
preprint server, specifically focusing on the field
2017 2018 2019 2020 2021 2022 2023
Year020040060080010001200T otal Number of LLM Papers(left axis) LLM T otal
(right axis) Code in LLM
(right axis) LLM in IA
0510152025
Paper Percentage [%]
Figure 8: Paper statistics from Arxiv. We identified a
significant and growing trend in recent research focused
on code-based large language models (LLMs) and LLM-
based intelligent agents (IAs). Code usage contributes
much to the success of these cutting-edge models and
systems.
of computer science. The web scraper gathers
information about papers related to specific top-
ics, including code, LLM, and IA. The script navi-
gates through the ArXiv website, fetching essential
details such as paper title, abstract, authors, and
subject categories. We analyze and visualize data
related to these papers in Figure 8, intending to
provide insights into the trends and relationships
between LLMs, code-related topics, and IAs in the
past few years.
C Benchmarks for Evaluating Complex
Reasoning with Code:
While there exist many benchmarks used to eval-
uate the abilities of LLMs (Liang et al., 2023c)
across many disciplines, the benchmarks that most
directly evaluate LLMs pre-trained on code in com-
plex reasoning tasks are programming benchmarks
such as CodeBLEU (Ren et al., 2020), where met-
rics that better match a human’s evaluation of what
is good logical, interpretable, and syntactically con-
cise code was created, and CodeXGLUE (Lu et al.,
2021) where multiple programming tasks such as
code repair and code defect detection were accumu-
lated into one dataset. Other suitable benchmarks
include math datasets such as many of MIT’s un-
dergraduate math courses such as calculus and lin-
ear algebra, (Drori et al., 2022), LILA, a compila-
tion of 23 tasks that test for mathematical abilities,
language format, language diversity, and external
knowledge abilities of LLMs (Mishra et al., 2023),

--- PAGE 25 ---
How Code Empowers LLMs to Serve as IAsHow Code
Assits LLMsBoost LLMs’
Performance (§3)Strengthen LLMs’
Prgramming Skills
(§3.1)LLM as a Strong CoderAlphaCode (Li et al., 2022), SantaCoder (Allal et al., 2023), PolyCoder (Xu et al., 2022),
CodeX (Chen et al., 2021), CodeGen (Nijkamp et al., 2022)
LLM as a SOTA Code
EvaluatorAutoFill (Kang et al., 2023a), GPT-3.5Eval (Zhuo, 2023), PentestGPT (Deng et al., 2023a),
SkipAnalyzer (Mohajer et al., 2023), LIBRO (Kang et al., 2023b)
Collaboration Coding
Solves Complex TasksMetaGPT (Hong et al., 2023), ChatDev (Qian et al., 2023a), DyLAN (Liu et al., 2023g),
Autogen (Wu et al., 2023b), Self-planning (Jiang et al., 2023)
Empower LLMs’
Complex Reasoning
(§3.2)Enhancing Task Deco-
mposition for Chain of
ThoughtLM Decomposers (Ye et al., 2023b), PoT (Chen et al., 2023b),
LM Theorem Proving (Polu and Sutskever, 2020), LM Math Solving (Drori et al., 2022) ,
Binding LMs (Cheng et al., 2023), SelfzCoT (Lei and Deng, 2023)
Serving As an Improv-
ed Latent SpaceUnderstanding CoT (Wang et al., 2023a), Head & Prompt Tuning Analysis (Wei et al., 2022a),
Complexity-based Prompting (Fu et al., 2023)
Enable LLMs to
Capture Structured
Knowledge (§3.3)Commonsense Reason-
ing GraphCOCOGEN (Madaan et al., 2022), CODE4STRUCT (Wang et al., 2023f),
ViStruct (Chen et al., 2023d), PROGPROMPT (Singh et al., 2022)
Visually Situated Natu-
ral LanguageWebGUM (Furuta et al., 2023), pix2code (Beltramelli, 2017), sketch2code (Robinson, 2019),
Pix2Struct (Lee et al., 2023), MATCHA (Liu et al., 2023a), RL-UI-to-Code
n (Soselia et al., 2023), parse-then-place (Lin et al., 2023)
Connect LLMs to
Other Function Ends
(§4)Relate LLMs to
Digital Ends (§4.1)Text-Based ToolsTALM (Parisi et al., 2022a), Toolformer (Schick et al., 2023), ToolAlpaca (Tang et al., 2023),
Gorilla (Patil et al., 2023), RestGPT (Song et al., 2023), ToolkenGPT (Hao et al., 2023)
In-context RALM (Ram et al., 2023), LaMDA (Thoppilan et al., 2022),
Webshop (Yao et al., 2022a), BlenderBot3 (Shuster et al., 2022), GeneGPT (Jin et al., 2023),
WebGLM (Liu et al., 2023e), React (Yao et al., 2022d), AlfWorld (Shridhar et al., 2020)
Multimodality ToolsHuggingGPT (Shen et al., 2023), VisualChatGPT (Wu et al., 2023a),
ViperGPT (Surís et al., 2023), MM-REACT (Yang et al., 2023), Chameleon (Lu et al., 2023),
TaskMatrix.AI (Liang et al., 2023d), VISPROG (Gupta and Kembhavi, 2023),
CodeVQA (Subramanian et al., 2023), VPGEN (Cho et al., 2023), 3D-GPT (Sun et al., 2023a),
LayoutGPT (Feng et al., 2023)
Relate LLMs to
Physical Ends (§4.2)ProgPrompt (Singh et al., 2022), Code-as-Policies (Liang et al., 2023a), V oxPoser (Huang et al., 2023a),
ChatGPT4Robotics (Vemprala et al., 2023), LaMPilot (Ma et al., 2023b), RRR (Cui et al., 2023a)
Provide LLM with
an Executable
Environment for
Feedback (§5)Various Feedback
from Code Execution
(§5.1)Ds-1000 (Lai et al., 2023), CodeRL (Le et al., 2022), Self-debugging(Chen et al., 2023c), Leti (Wang et al., 2023g),
Codebleu (Ren et al., 2020), JuIce (Agashe et al., 2019)
Methods for Enhan-
cing LLM’s Perform-
ance with Feedback
(§5.2)Selection Based Meth.CODET (Chen et al., 2022), SRank (To et al., 2023), Lever (Ni et al., 2023),
MBR-EXEC (Shi et al., 2022), Code-Ranker (Inala et al., 2022)
Prompting Based Meth. Mint (Wang et al., 2023h), Self-Debugging (Chen et al., 2023c)
Finetuning Based Meth.Leti (Wang et al., 2023g), CodeRL (Le et al., 2022), CompCoder (Wang et al., 2022),
Self-edit (Zhang et al., 2023a), CodeScore (Dong et al., 2023a), ILF (Chen et al., 2023a),
LM-teach (Haluptzok et al., 2022)
How Code-
LLMs benefit
IAs (§6)Decision-making
(§6.1)Environment
perceptionWebshopping (Yao et al., 2022a), Mind2Web (Deng et al., 2023b), Progprompt (Singh et al., 2022),
Code as Policies (Liang et al., 2023a)
PlanningCode as Policies (Liang et al., 2023a), ProgPrompt (Singh et al., 2022), Pal (Gao et al., 2023), Mint (Wang et al., 2023h),
Experimental assistants (Boiko et al., 2023; Liffiton et al., 2023)
Execution (§6.2)Action GroundingAgentBench (Liu et al., 2023f), V oyager (Wang et al., 2023b), Mint (Wang et al., 2023h), Progprompt (Singh et al., 2022)
Lumos (Yin et al., 2023), React (Yao et al., 2022d), Code as policies (Liang et al., 2023a),
Memory
OrganizationToolmaker (Cai et al., 2023), CRAFT (Yuan et al., 2023), Creator (Qian et al., 2023b), V oyager (Wang et al., 2023b)
Self-improvement
(§6.3)V oyager (Wang et al., 2023b), Chameleon (Lu et al., 2023), Agents for Science problems (Bran et al., 2023; Swan et al., 2023; Wu et al., 2023b)
Figure 9: We hereby provide a complete list of the papers included in our survey.
and theorem proving from the metamath theorem
code language (Polu and Sutskever, 2020). Oth-
ers include question-answering tasks that require
complex abilities to perform data retrieval in SQL
databases (Ye et al., 2023b), such as those seen by
the Spider dataset (Yu et al., 2019; Rajkumar et al.,
2022).
D The Comprehensive Paper List
To complement the core paper list presented in Fig-
ure 2, we have included a comprehensive list of
papers in Figure 9. It is important to note that this
list excludes papers used for performance compar-
isons between code and natural language. Instead,
it focuses on papers that have utilized code to aug-
ment the capabilities of Large Language Models
and intelligent agents.E Mappings of Sections to Core Code
features
In each section, we identify key code features that
contribute to the success of enhancing Large Lan-
guage Models and Intelligent Agents. The corre-
lation between each section and its core features
is detailed in Table 2. We have classified code
features into three main categories: Machine Ex-
ecutable, Structured and Expressive, and Explicit
and Unambiguous. Various aspects of these core
features play a pivotal role in the effective use of
code. Detailed explanations of these aspects are
provided in the right column of the table. Addi-
tionally, further information can be found in the
preamble of each respective section.

--- PAGE 26 ---
Major Functionalities Facilitated Key Features of Code
Strengthen LLMs’ Programming Skills
Correspond to §3.1 and Figure 3 (a)Machine Executable: Pretraining with Code, the
LLM is able to write code, evaluate code, and utilize
collaborative coding to solve complex tasks.
Empower LLMs’ Complex Reasoning
Correspond to §3.2 and Figure 3 (b)Structured and Expressive: The step-by-step
nature of code benefits CoT. Machine Executable:
LLMs can utilize code to help with certain
capabilities like mathematical reasoning.
Enhance LLMs’ Structured Knowledge
Correspond to §3.3 and Figure 3 (c)Structured and Expressive: Code can be used to
express complex structures, some programming
language features like logical expressions and class
inheritance will be especially useful.
Connect LLMs to Other Functional Ends
Correspond to §4 and Figure 4Explicit and Unambiguous : Code is more explicit
and clear than natural language, thus can better
express clear instructions of connecting to any other
functional ends.
Provide LLMs w/ Environmental Feedback
Correspond to §5 and Figure 5Machine Executable : Code execution result can be
treated as feedback to finetune the LLMs further and
make their performance more desirable
Help with IAs’ Decision-Making
Correspond to §6.1 and Figure 6Structured and Expressive : Code pretraining
Enhances agents’ ability to precept structural
knowledge, step by step feature improves CoT
planning, logical expressions and nesting help with
better control flow. Machine Executable : Help with
solving mathematical tasks.
Help with IAs’ Action Execution
Correspond to §6.2 and Figure 6Explicit and Unambiguous: Unambiguous
function calling help with action grounding.
Machine Executable: Agents can write reusable
code snippets as its memory
Help with IAs’ Self-improving
Correspond to §6.3 and Figure 6Machine Executable: Agent code execution results
reflect potential environment change and can be
utilized for self-improving
Table 2: We conclude the three major key features of code and correspond them to the major functionalities of LLMs
and IAs they facilitated. The three key features are namely Structured and Expressive ,Machine Executable and
Explicit and Unambiguous . More details of how these features assist LLMs and IAs can be found in the preamble
of each section.

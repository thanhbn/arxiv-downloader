# 2401.00812.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2401.00812.pdf
# Kích thước tệp: 11878506 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Nếu LLM là Phù Thủy, Thì Code là Cây Đũa Phép: Một Khảo Sát về Cách Code Trao Quyền cho Các Mô Hình Ngôn Ngữ Lớn để Phục Vụ như Các Tác Nhân Thông Minh
Ke Yang∗,Jiateng Liu∗,John Wu ,Chaoqi Yang ,Yi R. Fung ,Sha Li ,
Zixuan Huang ,Xu Cao ,Xingyao Wang ,Yiquan Wang ,Heng Ji ,Chengxiang Zhai
University of Illinois Urbana-Champaign
{key4, jiateng5, johnwu3, chaoqiy2, yifung2, shal2,
zixuan3, xucao2, xingyao6, yiquan2, hengji, czhai}@illinois.edu
Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) nổi bật ngày nay khác với các mô hình ngôn ngữ trước đây không chỉ về kích thước, mà còn ở chỗ chúng được huấn luyện trên sự kết hợp của ngôn ngữ tự nhiên và ngôn ngữ hình thức (code). Như một phương tiện trung gian giữa con người và máy tính, code dịch các mục tiêu cấp cao thành các bước thực thi, có cú pháp chuẩn, tính nhất quán logic, trừu tượng hóa và tính mô-đun. Trong khảo sát này, chúng tôi trình bày một cái nhìn tổng quan về các lợi ích khác nhau của việc tích hợp code vào dữ liệu huấn luyện của LLM. Cụ thể, ngoài việc tăng cường LLM trong việc tạo code, chúng tôi quan sát thấy rằng những đặc tính độc đáo của code giúp i) mở khóa khả năng lý luận của LLM, cho phép ứng dụng chúng vào một loạt các tác vụ ngôn ngữ tự nhiên phức tạp hơn; ii) điều khiển LLM tạo ra các bước trung gian có cấu trúc và chính xác, sau đó có thể được kết nối với các đầu thực thi bên ngoài thông qua lời gọi hàm; và iii) tận dụng môi trường biên dịch và thực thi code, cũng cung cấp phản hồi đa dạng để cải thiện mô hình. Ngoài ra, chúng tôi theo dấu cách những khả năng sâu sắc này của LLM, được mang lại bởi code, đã dẫn đến sự xuất hiện của chúng như các tác nhân thông minh (IA) trong các tình huống mà khả năng hiểu hướng dẫn, phân tách mục tiêu, lập kế hoạch và thực hiện hành động, và tinh chỉnh từ phản hồi là rất quan trọng cho thành công của chúng trong các tác vụ hạ lưu. Cuối cùng, chúng tôi trình bày một số thách thức chính và hướng phát triển tương lai của việc trao quyền cho LLM và IA bằng code.

1 Giới thiệu
Code đã trở thành một thành phần không thể thiếu trong dữ liệu huấn luyện của các mô hình ngôn ngữ lớn (LLM), bao gồm các mô hình nổi tiếng như Llama2, GPT-3.5 series và GPT-4 (Touvron et al., 2023; Ye et al., 2023a; OpenAI, 2023). Việc huấn luyện LLM trên code đã trở nên phổ biến không chỉ vì các kỹ năng lập trình thu được cho phép ứng dụng thương mại, như Github Copilot1, mà còn vì nó cải thiện các khả năng lý luận mà các mô hình trước đây thiếu (Liang et al., 2023b). Do đó, LLM nhanh chóng xuất hiện như một trung tâm ra quyết định chính cho các tác nhân thông minh (IA) (Zhao et al., 2023), thể hiện sự tăng trưởng theo cấp số nhân trong các khả năng từ việc huấn luyện code và sự tiến bộ của việc học công cụ (Qin et al., 2023). Những IA dựa trên LLM này đã sẵn sàng xử lý một loạt rộng hơn các tác vụ phức tạp hơn, bao gồm các ứng dụng hạ lưu trong mô phỏng môi trường đa tác nhân (Wu et al., 2023c) và AI cho khoa học (Boiko et al., 2023).

Như được mô tả trong Hình 1, khảo sát này nhằm giải thích việc áp dụng rộng rãi của việc huấn luyện đặc biệt cho code trong mô hình huấn luyện LLM tổng quát và cách code tăng cường LLM để hoạt động như IA. Không giống như các khảo sát code-LLM trước đây tập trung vào việc đánh giá và so sánh các khả năng tạo code (Zan et al., 2023; Xu et al., 2022), hoặc liệt kê các tác vụ IA (Wang et al., 2023d; Xi et al., 2023; Zhao et al., 2023) trong các khảo sát IA, chúng tôi nhằm cung cấp một hiểu biết toàn diện về cách code hỗ trợ LLM và nơi code có lợi cho LLM như IA, dựa trên phân loại các bài báo liên quan (xem Hình 2).

Đầu tiên chúng tôi cung cấp định nghĩa về code và trình bày các phương pháp điển hình cho việc huấn luyện code LLM (§2). So với ngôn ngữ tự nhiên (tham khảo nghiên cứu trường hợp trong A.1), code có cấu trúc hơn, có các quy trình thực thi logic, từng bước được rút ra từ lập trình thủ tục, cũng như các hàm được định nghĩa rõ ràng, mô-đun hóa, tạo thành các trừu tượng có thể biểu diễn bằng đồ thị. Ngoài ra, code thường đi kèm với môi trường biên dịch và thực thi tự chứa.

Với những hiểu biết từ các đặc tính này của code, đánh giá tài liệu toàn diện của chúng tôi tiết lộ rằng việc tích hợp code vào huấn luyện LLM i) tăng cường khả năng lập trình và lý luận của chúng (§3); ii) cho phép các mô hình trực tiếp tạo ra các bước thực thi được, chi tiết trong quá trình ra quyết định, từ đó tạo điều kiện cho khả năng mở rộng của chúng trong việc kết hợp các mô-đun công cụ khác nhau thông qua lời gọi hàm (§4); và iii) đặt LLM trong môi trường thực thi code, cho phép chúng nhận phản hồi tự động từ các mô-đun đánh giá tích hợp và tự cải thiện (§5).

--- TRANG 2 ---
Hình 1: Minh họa về cách code trao quyền cho các mô hình ngôn ngữ lớn (LLM) và tăng cường ứng dụng hạ lưu của chúng như các tác nhân thông minh (IA). Trong khi LLM truyền thống xuất sắc trong các tác vụ ngôn ngữ tự nhiên thông thường như phân loại tài liệu và trả lời câu hỏi, việc tiếp tục tiền huấn luyện hoặc tinh chỉnh LLM với code có thể hiểu được bởi con người và thực thi được bởi máy phục vụ như một sức mạnh bổ sung — giống như việc trang bị cho phù thủy những cây đũa phép tăng cường mana. Điều này làm tăng đáng kể hiệu suất của chúng như IA thông qua các bước hoạt động được dệt nên phức tạp.

Ngoài ra, khi LLM đang trở thành những người ra quyết định chính cho IA trong các tác vụ thế giới thực phức tạp, khảo sát của chúng tôi cũng khám phá cách những lợi thế này tạo điều kiện cho việc hoạt động của chúng theo khả năng này (§6), về mặt i) tăng cường khả năng ra quyết định của IA trong các kỹ năng nhận thức và lập kế hoạch (§6.1), ii) tạo điều kiện cho việc thực hiện của chúng thông qua việc gắn kết nguyên tắc hành động trực tiếp và tổ chức bộ nhớ mô-đun (§6.2), và iii) cung cấp môi trường tương tác để tự sửa chữa và tự cải thiện (§6.3). Cuối cùng, chúng tôi thảo luận về một số thách thức mở và hướng phát triển tương lai đầy hứa hẹn (§7).

2 Kiến thức cơ bản
2.1 Định nghĩa về Code của chúng tôi
Chúng tôi coi code như bất kỳ ngôn ngữ hình thức nào vừa có thể thực thi bởi máy vừa có thể hiểu được bởi con người. Ví dụ, các ngôn ngữ lập trình có thể đọc được bởi con người nằm trong phạm vi thảo luận của chúng tôi, trong khi các ngôn ngữ cấp thấp, như ngôn ngữ máy dựa trên chỉ dẫn nhị phân, bị loại trừ do thiếu khả năng hiểu được của con người. Ngoài ra, các ngôn ngữ hình thức được định nghĩa trước, như các tập hàm được sử dụng trong WebGPT (Nakano et al., 2021), được bao gồm vì chúng có thể được phân tích và thực thi theo cách dựa trên quy tắc.

LLM được huấn luyện với các biểu thức được công thức hóa trong một tập ký hiệu và quy tắc được định nghĩa (ví dụ: tập hàm được định nghĩa trước, công thức suy luận toán học, v.v.), tức là các ngôn ngữ hình thức, thể hiện những lợi thế tương tự như những mô hình được huấn luyện với các ngôn ngữ lập trình. Do đó, chúng tôi mở rộng định nghĩa về code để kết hợp những corpus huấn luyện đồng nhất này, tăng cường tính toàn diện của khảo sát này để phù hợp với nhu cầu nghiên cứu hiện tại.

2.2 Phương pháp Huấn luyện Code LLM
LLM trải qua quá trình huấn luyện code bằng cách tuân theo mục tiêu mô hình hóa ngôn ngữ chuẩn, được áp dụng cho corpus code. Với việc code có khả năng đọc tuần tự giống như ngôn ngữ tự nhiên, điều này tương tự với cách tiếp cận để hướng dẫn LLM hiểu và tạo ra ngôn ngữ tự nhiên tự do.

Cụ thể, đối với một LLM MΘ với các tham số Θ và một corpus code T={t1, ..., tn}, hàm mất mát mô hình hóa ngôn ngữ để tối ưu hóa là:
L(T) = Σi logP(ti|ti−k, ..., ti−1; Θ)

Khi sử dụng ngôn ngữ lập trình (ví dụ: Python, C, v.v.) làm corpus (Chen et al., 2021; Li et al., 2022; Nijkamp et al., 2022), dữ liệu huấn luyện thường được lấy từ các kho code có thể truy cập công khai, như GitHub. Quá trình này tạo ra một corpus với khối lượng có thể so sánh với việc tiền huấn luyện ngôn ngữ tự nhiên, và do đó chúng tôi gọi việc huấn luyện với một lượng code dồi dào như vậy là tiền huấn luyện code. Chiến lược huấn luyện bao gồm việc huấn luyện

--- TRANG 3 ---
Cách Code Trao Quyền cho LLM để Phục Vụ như IACách Code
Hỗ trợ LLMTăng cường Hiệu suất
LLM (§3)Củng cố Kỹ năng Lập
trình của LLM (§3.1)LLM như một Lập trình viên MạnhAlphaCode (Li et al., 2022), SantaCoder (Allal et al., 2023), PolyCoder (Xu et al., 2022),
CodeX (Chen et al., 2021), CodeGen (Nijkamp et al., 2022)

LLM như một Đánh giá
viên Code SOTALM Decomposers (Ye et al., 2023b), PoT (Chen et al., 2023b), Pal (Gao et al., 2023)
LM Theorem Proving (Polu and Sutskever, 2020), LM Math Solving (Drori et al., 2022) ,
Binding LMs (Cheng et al., 2023), SelfzCoT (Lei and Deng, 2023)

Cộng tác Lập trình Giải
quyết Tác vụ Phức tạpMetaGPT (Hong et al., 2023), ChatDev (Qian et al., 2023a), DyLAN (Liu et al., 2023g),
Autogen (Wu et al., 2023b), Self-planning (Jiang et al., 2023)

Trao quyền cho Lý luận
Phức tạp của LLM (§3.2)Tăng cường Phân tách Tác vụ
với Chuỗi Suy nghĩCode Training Improves LLM CoT (Fu and Khot, 2022), When to Train LLM On Code
(Ma et al., 2023a)

Chương trình Suy nghĩLM Decomposers (Ye et al., 2023b), PoT (Chen et al., 2023b), Pal (Gao et al., 2023)
LM Theorem Proving (Polu and Sutskever, 2020), LM Math Solving (Drori et al., 2022) ,
Binding LMs (Cheng et al., 2023), SelfzCoT (Lei and Deng, 2023)

Tăng cường LLM trong
việc Nắm bắt Kiến thức
Có cấu trúc (§3.3)Đồ thị Lý luận Thường
thứcCOCOGEN (Madaan et al., 2022), CODE4STRUCT (Wang et al., 2023f),
ViStruct (Chen et al., 2023d)

Ngôn ngữ Tự nhiên Có
định vị TrựcquanWebGUM (Furuta et al., 2023), Pix2Struct (Lee et al., 2023), MATCHA (Liu et al., 2023a)

Kết nối LLM với Các
Đầu Chức năng Khác
(§4)Liên quan LLM với Các
Đầu Kỹ thuật số (§4.1)Công cụ Dựa trên VănbảnTALM (Parisi et al., 2022a), Toolformer (Schick et al., 2023), ToolAlpaca (Tang et al., 2023),
Gorilla (Patil et al., 2023), RestGPT (Song et al., 2023), ToolkenGPT (Hao et al., 2023)

Công cụ Đa phương thứcHuggingGPT (Shen et al., 2023), VISPROG (Gupta and Kembhavi, 2023),
ViperGPT (Surís et al., 2023), TaskMatrix.AI (Liang et al., 2023d), VPGEN (Cho et al., 2023)

Liên quan LLM với Các
Đầu Vật lý (§4.2)ProgPrompt (Singh et al., 2022), Code-as-Policies (Liang et al., 2023a), VoxPoser (Huang et al., 2023a),
ChatGPT4Robotics (Vemprala et al., 2023), LaMPilot (Ma et al., 2023b), RRR (Cui et al., 2023a)

Cung cấp cho LLM một
Môi trường Thực thi để
Phản hồi Tự động (§5)Phản hồi từ Thực thi
Code (§5.1)Ds-1000 (Lai et al., 2023), CodeRL (Le et al., 2022), Self-debugging(Chen et al., 2023c), Leti (Wang et al., 2023g)

Phương pháp Tăng cường
Hiệu suất LLM với Phản
hồi (§5.2)Phương pháp Dựa trên LựachọnCODET (Chen et al., 2022), SRank (To et al., 2023), Lever (Ni et al., 2023)

Phương pháp Dựa trên PrompingMint (Wang et al., 2023h), Self-Debugging (Chen et al., 2023c)

Phương pháp Dựa trên FintuningLeti (Wang et al., 2023g), CodeRL (Le et al., 2022), CompCoder (Wang et al., 2022),
Self-edit (Zhang et al., 2023a), CodeScore (Dong et al., 2023a), ILF (Chen et al., 2023a)

Cách Code-LLM có lợi
cho IA (§6)Ra quyết định (§6.1)Nhận thức Môi trường
Webshopping (Yao et al., 2022a), Mind2Web (Deng et al., 2023b), Progprompt (Singh et al., 2022),

Lập kế hoạchCode as Policies (Liang et al., 2023a), ProgPrompt (Singh et al., 2022), Experimental assistants (Boiko et al., 2023)

Thực hiện (§6.2)Gắn kết Hành độngAgentBench (Liu et al., 2023f), Voyager (Wang et al., 2023b), Mint (Wang et al., 2023h), Progprompt (Singh et al., 2022)

Tổ chức Bộ nhớToolmaker (Cai et al., 2023), CRAFT (Yuan et al., 2023), Creator (Qian et al., 2023b), Voyager (Wang et al., 2023b)

Tự cải thiện (§6.3)Voyager (Wang et al., 2023b), Chameleon (Lu et al., 2023), Agents for Science problems (Bran et al., 2023; Swan et al., 2023; Wu et al., 2023b)

Hình 2: Tổ chức bài báo của chúng tôi, với danh sách được tuyển chọn của các công trình đại diện nhất. Danh sách công trình đầy đủ được cung cấp trong Phụ lục D.

code trên một LLM ngôn ngữ tự nhiên đã được tiền huấn luyện, như được minh họa bởi Codex (Chen et al., 2021), hoặc huấn luyện một LLM từ đầu với sự pha trộn của ngôn ngữ tự nhiên và code, như được thể hiện bởi CodeLLM (Ma et al., 2023a).

Ngược lại, khi sử dụng ngôn ngữ hình thức được định nghĩa trước khác để huấn luyện, mục tiêu chuyển sang làm quen mô hình với việc ứng dụng các hàm cụ thể (Schick et al., 2023), công thức chứng minh toán học (Wu et al., 2022), SQL (Sun et al., 2023b), và các cấu trúc tương tự. Vì tập dữ liệu cho điều này nhỏ hơn so với corpus ngôn ngữ tự nhiên đã được tiền huấn luyện, chúng tôi gọi quá trình huấn luyện như vậy là tinh chỉnh code. Các nhà nghiên cứu áp dụng hàm mất mát mô hình hóa ngôn ngữ để tối ưu hóa LLM trong quá trình này, tương tự.

3 Tiền huấn luyện Code Tăng cường Hiệu suất LLM
Việc tiền huấn luyện LLM trên code, được minh họa bởi GPT Codex của OpenAI (Chen et al., 2021), đã mở rộng phạm vi tác vụ của LLM vượt ra ngoài ngôn ngữ tự nhiên. Các mô hình như vậy cho phép ứng dụng đa dạng, bao gồm tạo code cho lý thuyết toán học (Wu et al., 2022), các tác vụ lập trình tổng quát (Chen et al., 2021), và truy xuất dữ liệu (Sun et al., 2023b; Cheng et al., 2023). Code đòi hỏi phải tạo ra các chuỗi bước logic nhất quán, có thứ tự cần thiết cho việc thực thi hợp lệ. Hơn nữa, khả năng thực thi của mỗi bước trong code cho phép xác minh logic từng bước. Việc tận dụng và nhúng cả hai đặc tính này của code trong tiền huấn luyện đã cải thiện hiệu suất chuỗi suy nghĩ (CoT) của LLM trên nhiều tác vụ ngôn ngữ tự nhiên hạ lưu thông thường (Lyu et al., 2023; Zhou et al., 2023a; Fu and Khot, 2022), cho thấy kỹ năng lý luận phức tạp được cải thiện. Học một cách ngầm định từ định dạng có cấu trúc của code, các LLM code thể hiện hiệu suất được cải thiện hơn nữa trên các tác vụ lý luận có cấu trúc thường thức, như những tác vụ liên quan đến markup, HTML, và hiểu biểu đồ (Furuta et al., 2023; Liu et al., 2023a).

Trong các phần sau, mục tiêu của chúng tôi là làm rõ tại sao việc huấn luyện LLM trên code và sử dụng

--- TRANG 4 ---
(a) Củng cố kỹ năng lập trình và đánh giá code của LLM (§3.1).
(b) Trao quyền cho lý luận phức tạp của LLM, tách biệt tính toán khỏi hiểu ngôn ngữ (§3.2).
(c) Cho phép LLM nắm bắt tốt hơn kiến thức có cấu trúc và hiểu tốt hơn dữ liệu đa phương tiện phức tạp (§3.3).

Hình 3: Cách tiền huấn luyện code tăng cường hiệu suất LLM.

prompts dựa trên code tăng cường hiệu suất của chúng trên các tác vụ hạ lưu phức tạp. Cụ thể, chúng tôi làm nổi bật ba lĩnh vực chính nơi tiền huấn luyện trên code đã có lợi cho LLM: i) tăng cường thành thạo lập trình trong §3.1, ii) trao quyền cho khả năng lý luận phức tạp trong §3.2, và iii) tạo điều kiện cho việc nắm bắt kiến thức thường thức có cấu trúc trong §3.3, như được thể hiện trong Hình 3.

3.1 Củng cố Kỹ năng Lập trình của LLM

LLM như một lập trình viên mạnh mẽ. Các mô hình ngôn ngữ trước đây chỉ tạo ra các chương trình dành riêng cho lĩnh vực (Ellis et al., 2019) hoặc hạn chế trong một trong các ngôn ngữ lập trình chung, như Java hoặc C# (Alon et al., 2020). Được trao quyền bởi số lượng tham số và tài nguyên tính toán tăng lên, các mô hình tạo code dựa trên LLM gần đây (như AlphaCode (Li et al., 2022), CodeGen (Nijkamp et al., 2022), SantaCoder (Allal et al., 2023), PolyCoder (Xu et al., 2022)) có thể làm chủ hơn 10 ngôn ngữ trong cùng một mô hình và thể hiện thành công chưa từng có. Một công trình nổi tiếng là CodeX (Chen et al., 2021), với 12 tỷ tham số đọc toàn bộ cơ sở dữ liệu GitHub và có thể giải quyết 72.31% các bài toán lập trình Python thách thức được tạo ra bởi con người. Các nghiên cứu gần đây (Zan et al., 2023; Xu et al., 2022; Du et al., 2023; Vaithilingam et al., 2022; Wong et al., 2023; Fan et al., 2023) đã cung cấp các khảo sát và đánh giá hệ thống về các code-LLM hiện có.

Với khả năng tạo code mạnh mẽ, LLM mang lại lợi ích cho các ứng dụng khác nhau dựa vào code, như quản trị cơ sở dữ liệu (Zhou et al., 2023b), điều khiển nhúng (Liang et al., 2023a), thiết kế game (Roberts et al.), phân tích dữ liệu bảng tính (Liu et al., 2023c), và tạo website (Calò và De Russis, 2023).

LLM như một đánh giá viên code tiên tiến nhất. Mặt khác, chính LLM có thể là những đánh giá viên tiên tiến nhất (tức là phân tích và chấm điểm) cho code được tạo ra bởi con người hoặc máy. Kang et al. (2023a) tận dụng các mô hình dựa trên LLM để định vị lỗi code, trong khi Zhuo (2023) sử dụng GPT-3.5 để đánh giá tính đúng đắn chức năng và sở thích của con người trong việc tạo code. Ngoài ra, Deng et al. (2023a) thiết kế một công cụ kiểm thử xâm nhập dựa trên LLM và phát hiện rằng LLM thể hiện thành thạo trong việc sử dụng công cụ kiểm thử, diễn giải đầu ra, và đề xuất các hành động tiếp theo. Hai nỗ lực gần đây (Li et al., 2023a; Mohajer et al., 2023) cũng sử dụng LLM để kiểm tra và phân tích mã nguồn mà không thực thi nó. Hơn nữa, LLM được sử dụng để tái tạo lỗi tự động trong Kang et al. (2023b) và đánh giá phần mềm dễ bị tổn thương trong Noever (2023).

Cộng tác đa LLM giải quyết các vấn đề lập trình phức tạp. Mặc dù các LLM code, như GitHub Copilot, đã thể hiện thành công chưa từng có, một tác nhân LLM đơn lẻ có thể thất bại trong các kịch bản phức tạp đòi hỏi nhiều bước. May mắn thay, việc lập trình cộng tác giữa một số tác nhân LLM đặc thù vai trò thể hiện hiệu suất chính xác và bền vững hơn đối với các tác vụ phức tạp. Hong et al. (2023) kết hợp quy trình lập trình của con người làm hướng dẫn để điều phối các tác nhân khác nhau. Dong et al. (2023b) giao ba vai trò: nhà phân tích, lập trình viên, và kiểm thử viên cho ba "GPT-3.5" riêng biệt, vượt qua GPT-4 trong việc tạo code. Trong khi đó, Qian et al. (2023a) thiết kế một quy trình phát triển phần mềm hỗ trợ chat, giao hơn ba vai trò cho các tác nhân LLM riêng biệt. Các phương pháp tương tự khác (Liu et al., 2023g; Talebirad và Nadiri, 2023; Wu et al., 2023b; Jiang et al., 2023) đều sử dụng nhiều tác nhân code-LLM hoặc các giai đoạn khác nhau của cùng một tác nhân để tạo code, phát triển phần mềm hoặc tận dụng code trung gian được tạo ra cho các tác vụ mục đích chung khác.

--- TRANG 5 ---
3.2 Trao quyền cho Lý luận Phức tạp của LLM

Tiền huấn luyện code cải thiện hiệu suất chuỗi suy nghĩ. Về mặt logic, nhiều tác vụ phức tạp có thể được chia thành các tác vụ nhỏ hơn dễ dàng hơn để giải quyết. Prompting CoT, nơi các đầu vào prompt được thiết kế với các chuỗi lý luận, cho phép LLM điều kiện hóa việc tạo ra của nó với các bước lý luận xa hơn, cung cấp một cách tiếp cận trực tiếp cho việc phân tách tác vụ (Wei et al., 2023). CoT đã thấy thành công trong việc phân tách nhiều tác vụ, như lập kế hoạch (Huang et al., 2022b) và trả lời câu hỏi dựa trên bằng chứng (Dua et al., 2022; Ye et al., 2023b).

Trong khi khả năng CoT của LLM ban đầu chủ yếu được quy cho việc tăng kích thước mô hình đáng kể (Wei et al., 2022b), bằng chứng gần đây được tổng hợp bởi Fu và Khot (2022) cho thấy rằng phần lớn cải thiện hiệu suất từ CoT bắt nguồn từ việc tiền huấn luyện trên code. Ví dụ, khi so sánh các phiên bản khác nhau của GPT-3 (tức là v1 so với v5), các LLM không được huấn luyện trên code, như text-davinci-001 của GPT-3, thấy sự cải thiện độ chính xác nhỏ nhưng đáng kể từ 6.4% đến 12.4% với CoT trên tác vụ lý luận toán học GSM8k (Cobbe et al., 2021). Ngược lại, các LLM được tiền huấn luyện trên code, như text-davinci-002 và Codex của GPT-3 (Chen et al., 2021), thấy sự cải thiện hiệu suất đáng kể phát sinh từ CoT, với sự tăng độ chính xác đáng chú ý từ 15.6% đến 46.9% và 19.7% đến 63.1% tương ứng. Hỗ trợ giả thuyết này được đề xuất bởi Fu và Khot (2022), Ma et al. (2023a) cho thấy rằng tiền huấn luyện trên code trong các LLM kích thước nhỏ (2.6B) (Zeng et al., 2021) tăng cường hiệu suất khi sử dụng CoT, và thậm chí đáng chú ý hơn là các LLM được tiền huấn luyện code nhỏ hơn vượt trội hơn các đối tác không có code lớn hơn trên nhiều tác vụ khác nhau. Hơn nữa, nghiên cứu của họ chỉ ra rằng việc kết hợp khối lượng code lớn hơn trong các giai đoạn đầu của việc huấn luyện LLM làm tăng đáng kể hiệu quả của nó trong các tác vụ lý luận. Tuy nhiên, để điều chỉnh kỳ vọng, có thể sự khác biệt trong hiệu suất CoT giữa các LLM có và không có tiền huấn luyện code giảm đi khi kích thước của các mô hình giảm, vì khoảng cách độ chính xác giữa các LLM nhỏ trong Ma et al. (2023a) ít hơn 3% khi đánh giá CoT. Đáng chú ý, cả Fu và Khot (2022) và Ma et al. (2023a) đều cho thấy rằng tiền huấn luyện trên code cải thiện hiệu suất LLM trong cả kịch bản prompting chuẩn và CoT trên các tác vụ hạ lưu.

Chương trình suy nghĩ vượt trội hơn chuỗi suy nghĩ. Hơn nữa, so với các phương pháp CoT thuần túy, các LLM đầu tiên dịch và phân tách một tác vụ ngôn ngữ tự nhiên thành code (Chen et al., 2023b; Gao et al., 2023), thường được gọi là prompting chương trình suy nghĩ (PoT) hoặc mô hình ngôn ngữ hỗ trợ chương trình, thấy những cải thiện đáng kể trong các tác vụ đòi hỏi sự phân biệt trong cả ngôn ngữ và cấu trúc theo chiều dọc rõ ràng. Cách tiếp cận này đặc biệt hiệu quả trong các lĩnh vực phức tạp như toán học lý thuyết (Polu và Sutskever, 2020), toán học đại học (Drori et al., 2022), và trả lời câu hỏi với truy xuất dữ liệu (Sun et al., 2023b; Cheng et al., 2023).

PoT tăng cường hiệu suất do tính chính xác và khả năng xác minh vốn có trong code như một ngôn ngữ có thể thực thi bởi máy. Trong việc phân tách tác vụ, không hiếm khi LLM tạo ra các tác vụ con và câu hỏi không chính xác thông qua CoT (Ji et al., 2023). Các triển khai PoT từ Chen et al. (2023b), Gao et al. (2023), và Ye et al. (2023b) cho thấy rằng bằng cách thực thi code trực tiếp và xác minh kết quả sau khi dịch bởi LLM, người ta có thể giảm thiểu hiệu quả các tác động của lý luận không chính xác trong CoT. Điều này là do quá trình lý luận phải tuân thủ logic và ràng buộc được chỉ định rõ ràng bởi chương trình, từ đó đảm bảo kết quả chính xác và đáng tin cậy hơn.

Tuy nhiên, những cải thiện như vậy được thấy trong việc sử dụng code không chỉ giới hạn ở các ngôn ngữ lập trình có thể thực thi thuần túy như Python hoặc SQL, cũng không chỉ giới hạn ở các tác vụ đặc biệt cứng nhắc về cấu trúc như toán học (Drori et al., 2022) và truy xuất dữ liệu (Rajkumar et al., 2022). Các cải thiện cũng mở rộng đến lĩnh vực mà thậm chí việc dịch thành pseudo-code để phân tách một tác vụ có thể cải thiện hiệu suất zero-shot (Lei và Deng, 2023) trong các bài toán từ có chứa số, và các tác vụ lý luận tổng quát như StrategyQA (Geva et al., 2021).

3.3 Cho phép LLM Nắm bắt Kiến thức Có cấu trúc

Tạo code tiết lộ lý luận thường thức có cấu trúc vượt trội. Với việc code có cấu trúc đồ thị của các biểu diễn ký hiệu, việc dịch các đồ thị văn bản, bảng, và hình ảnh thành code trao quyền cho LLM điều khiển bởi code để xử lý thông tin như vậy một cách logic theo các nguyên tắc lý luận và tạo code.

Do đó, công trình trước đây (Madaan et al., 2022; Wang et al., 2023f) cho thấy rằng các LLM trải qua tiền huấn luyện bổ sung trên code có thể sánh ngang, hoặc thậm chí vượt qua, các đối tác ngôn ngữ tự nhiên được tinh chỉnh của chúng trong các tác vụ liên quan đến lý luận thường thức có cấu trúc, ngay cả với dữ liệu huấn luyện hạn chế hoặc không có. COCOGEN (Madaan et al., 2022) đầu tiên đã tái định nghĩa tác vụ hoàn thiện đồ thị lý luận thường thức như một tác vụ tạo code và thể hiện hiệu suất few-shot được cải thiện trong đồ thị lý luận, theo dõi trạng thái thực thể bảng, và tạo đồ thị giải thích.

Dựa trên quan điểm này, CODE4STRUCT (Wang et al., 2023f) áp dụng code-LLM cho các cấu trúc ngữ nghĩa, tập trung vào tác vụ trích xuất đối số sự kiện. Bằng cách tận dụng các tính năng của code như comment và chú thích kiểu, nó đạt được hiệu suất cạnh tranh với số lượng trường hợp huấn luyện tối thiểu. Hơn nữa, nó vượt qua các baseline trong kịch bản zero-shot, hưởng lợi từ tính năng kế thừa và các mẫu kiểu sự kiện anh chị em. ViStruct (Chen et al., 2023d) mở rộng cách tiếp cận này hơn nữa cho các tác vụ đa phương tiện, tận dụng ngôn ngữ lập trình để biểu diễn thông tin cấu trúc thị giác và học curriculum để tăng cường hiểu biết của mô hình về các cấu trúc thị giác.

Thành thạo markup code phát triển hiểu ngôn ngữ tự nhiên có định vị thị giác. Một dòng nghiên cứu khác tập trung vào việc sử dụng markup code như HTML và CSS để phân định và de-render thông tin đồ họa có cấu trúc trong các giao diện người dùng đồ họa (GUI) hoặc các hình ảnh như biểu đồ và đồ thị trong tài liệu. Markup code này không chỉ chỉ định nội dung mà còn điều chỉnh bố cục của một trang web, hỗ trợ các mô hình ngôn ngữ thị giác lớn (LVLM) trong việc nắm bắt thông tin ngôn ngữ tự nhiên có định vị thị giác (VSNL).

Đối với hiểu markup code của LVLM, WebGUM (Furuta et al., 2023) minh họa điều hướng web tự động. Nó sử dụng một cách tiếp cận tiền huấn luyện sử dụng ảnh chụp màn hình trang web và HTML tương ứng làm đầu vào, và hành động điều hướng làm đầu ra. Vượt trội hơn SOTA, con người, và các tác nhân dựa trên LLM khác, WebGUM thể hiện hiệu quả của việc tiền huấn luyện mô hình với tăng cường markup code trong hiểu trang web.

Đối với tạo markup code, pix2code (Beltramelli, 2017) và sketch2code (Robinson, 2019) đi tiên phong trong các phương pháp học máy để tạo code rendering cho GUI hoặc mockup website, trong thời đại trước LLM. Pix2Struct (Lee et al., 2023) đạt SOTA vào thời điểm đó trong hiểu VSNL

--- TRANG 6 ---
Hình 4: Mô hình gọi công cụ tập trung vào code phục vụ như giao diện thống nhất giữa LLM và một loạt lớn các đầu chức năng, do đó cho phép nhiều tác vụ đa phương tiện và đa lĩnh vực.

bằng cách tiền huấn luyện một mô hình hình ảnh-sang-văn bản trên các ảnh chụp màn hình website bị che, và tiếp tục huấn luyện với các mục tiêu OCR, mô hình hóa ngôn ngữ, và chú thích hình ảnh. Dựa trên điều này, MATCHA (Liu et al., 2023a) giới thiệu các mục tiêu tiền huấn luyện bổ sung dựa trên de-rendering biểu đồ, hiểu bố cục, và lý luận toán học, vượt qua SOTA trong các tác vụ hiểu VSNL.

4 Code Kết nối LLM với Các Đầu Chức năng Khác

Các nghiên cứu gần đây cho thấy rằng việc kết nối LLM với các đầu chức năng khác (tức là tăng cường LLM với các công cụ và mô-đun thực thi bên ngoài) giúp LLM thực hiện các tác vụ chính xác và đáng tin cậy hơn (Mialon et al., 2023; Parisi et al., 2022b; Peng et al., 2023; Gou et al., 2023). Các đầu chức năng này trao quyền cho LLM để truy cập kiến thức bên ngoài, tham gia với các phương tiện đa dạng, và tương tác hiệu quả với các môi trường khác nhau. Như được chỉ ra trong Bảng 1, chúng tôi quan sát một xu hướng phổ biến nơi LLM tạo ra các ngôn ngữ lập trình hoặc sử dụng các hàm được định nghĩa trước để thiết lập kết nối với các đầu chức năng khác—một hiện tượng mà chúng tôi gọi là mô hình tập trung vào code.

Trái ngược với thực hành cứng nhắc của việc mã hóa cứng nghiêm ngặt các lời gọi công cụ trong cơ chế suy luận của LLM, mô hình tập trung vào code cho phép LLM tạo ra động các token gọi các mô-đun thực thi với các tham số có thể thích ứng. Mô hình này cho phép một cách đơn giản và rõ ràng để LLM tương tác với các đầu chức năng khác, tăng cường tính linh hoạt và khả năng mở rộng của ứng dụng của chúng. Quan trọng, như được mô tả trong Hình 4, nó cho phép LLM tham gia với nhiều đầu chức năng trải dài trên các phương tiện và lĩnh vực đa dạng. Bằng cách mở rộng cả số lượng và đa dạng của các đầu chức năng có thể truy cập, LLM có thể xử lý các tác vụ phức tạp hơn.

--- TRANG 7 ---
Bảng 1: Công trình đại diện kết nối LLM với các đầu chức năng khác nhau để thực hiện các tác vụ không tầm thường. Các nỗ lực ban đầu nhúng các lời gọi công cụ một cách cứng nhắc trong cơ chế suy luận của LLM (được chỉ ra bởi "*"), dẫn đến tính linh hoạt giảm và khả năng truy cập công cụ bị hạn chế. Gần đây hơn, mô hình tập trung vào code thiết lập kết nối giữa LLM và các đầu chức năng thông qua ngôn ngữ lập trình hoặc hàm được định nghĩa trước (được chỉ ra bởi "†"). Cách tiếp cận này tăng cường khả năng mở rộng của việc gọi đầu chức năng của LLM trên các công cụ và mô-đun thực thi đa dạng.

[Bảng với các thông tin về Loại Chính của Đầu Chức năng, Công trình Đại diện, Mô hình Kết nối, Phương pháp Học, và Mục tiêu hoặc Vấn đề để Giải quyết]

Trong §4.1, chúng tôi kiểm tra các công cụ văn bản và đa phương tiện (kỹ thuật số) được kết nối với LLM, trong khi §4.2 tập trung vào các đầu chức năng thế giới vật lý, bao gồm robot và lái xe tự động, thể hiện tính linh hoạt của LLM trong việc giải quyết các vấn đề trên các phương tiện và lĩnh vực khác nhau.

4.1 Liên quan LLM với Các Đầu Kỹ thuật số

Công cụ Dựa trên Văn bản. Khung tập trung vào code đã tăng cường độ chính xác và rõ ràng cho việc gọi công cụ của LLM, ban đầu thúc đẩy tiến bộ trong các công cụ dựa trên văn bản. Trước khi mô hình tập trung vào code này trở nên phổ biến, nghiên cứu về việc tăng cường LM với các công cụ đơn lẻ như trình truy xuất thông tin (Guu et al., 2020; Lewis et al., 2020; Izacard et al., 2022; Borgeaud et al., 2022; Yasunaga et al., 2022) đòi hỏi một cơ chế mã hóa cứng trong suy luận (ví dụ: luôn gọi một trình truy xuất trước khi bắt đầu tạo), điều này ít linh hoạt và khó mở rộng hơn. TALM (Parisi et al., 2022a) đầu tiên kết hợp nhiều công cụ dựa trên văn bản bằng cách gọi lời gọi API với một dấu phân cách được định nghĩa trước, cho phép lời gọi rõ ràng đến bất kỳ công cụ dựa trên văn bản nào tại bất kỳ vị trí nào của việc tạo ra. Tiếp theo công trình của họ, Toolformer (Schick et al., 2023) đánh dấu các lời gọi API với "<API> </API>" cùng với nội dung được bao bọc của chúng. Sau đó, các cách tiếp cận học công cụ đa dạng được giới thiệu để tạo điều kiện cho việc tích hợp nhiều công cụ dựa trên văn bản trên các mô hình nền tảng khác nhau (Song et al., 2023; Hao et al., 2023; Tang et al., 2023).

Khung tập trung vào code tạo điều kiện cho việc gọi một loạt đa dạng các mô-đun văn bản bên ngoài. Chúng bao gồm máy tính, lịch, hệ thống dịch máy, công cụ điều hướng web, cũng như API từ HuggingFace và TorchHub (Thoppilan et al., 2022; Yao et al., 2022c; Shuster et al., 2022; Jin et al., 2023; Yao et al., 2022b; Liu et al., 2023e; Jin et al., 2023; Patil et al., 2023).

Công cụ Đa phương tiện. Khả năng mở rộng cao của mô hình LLM tập trung vào code cho phép mở rộng việc học công cụ sang các phương tiện khác ngoài văn bản. Công trình đầu (Gupta và Kembhavi, 2023; Surís et al., 2023; Subramanian et al., 2023) sử dụng mô hình tập trung vào code để giải quyết tác vụ trả lời câu hỏi thị giác. Ví dụ, VISPROG (Gupta và Kembhavi, 2023) tuyển chọn các mô hình thị giác máy tính được tiền huấn luyện đa dạng và các hàm từ các thư viện xử lý hình ảnh hiện có (ví dụ: Pillow và OpenCV) như một tập API. Các lời gọi API sau đó có thể được xâu chuỗi lại với nhau như một chương trình để hiểu hình ảnh có mục tiêu câu hỏi, nơi chương trình được tạo ra thông qua học trong ngữ cảnh với LLM. Chứa số học trong ngôn ngữ API code của nó, chương trình có khả năng thực hiện các tác vụ số học đơn giản, do đó cho phép VISPROG trả lời các câu hỏi cụ thể như đếm đối tượng. Công trình tương tự bao gồm ViperGPT (Surís et al., 2023) và CodeVQA (Subramanian et al., 2023). So với VISPROG, chúng trực tiếp tạo ra code Python linh hoạt hơn bằng cách sử dụng Codex. Điều này cho phép chúng có khả năng tạo ra các chương trình của các luồng điều khiển phức tạp hơn bằng cách sử dụng kiến thức được tiền huấn luyện nhúng trong Codex.

Ngoài lý luận thị giác, code cũng đã được sử dụng để kết nối LLM với các công cụ tạo đa phương tiện trong các tác vụ tạo hình ảnh (Cho et al., 2023; Feng et al., 2023; Wu et al., 2023a), nơi tính chất rõ ràng của code được tận dụng trong việc tạo ra những hình ảnh phù hợp tốt hơn với prompts văn bản của chúng.

Ngoài các công cụ dựa trên hình ảnh, các phương tiện khác

--- TRANG 8 ---
đã được xem xét và sử dụng theo cách cộng tác bởi công trình gần đây (Shen et al., 2023; Yang et al., 2023; Liang et al., 2023d). Ví dụ, MM-REACT (Yang et al., 2023) xem xét các mô hình nhận dạng video trong API của họ, và Chameleon (Lu et al., 2023) bao gồm các công cụ như detector văn bản thị giác hoặc tìm kiếm web. Trong HuggingGPT (Shen et al., 2023), các tác giả kết nối LLM với các mô hình Hugging Face khác nhau và coi mỗi mô hình như một lời gọi API có sẵn. Kết quả là, HuggingGPT có khả năng thực hiện một loạt tác vụ thậm chí rộng hơn, như các tác vụ liên quan đến âm thanh, mà trước đây chưa được khám phá. Đẩy đa dạng API xa hơn, TaskMatrix.AI (Liang et al., 2023d) sử dụng một số lượng API cao hơn một bậc độ lớn, trải dài từ API thị giác & hình ảnh đến API âm nhạc và game. Tính linh hoạt của code tạo điều kiện cho LLM sử dụng chung các công cụ đa phương tiện khác nhau. Điều này làm cho LLM linh hoạt hơn và có khả năng hoạt động như những người giải quyết vấn đề đa phương tiện mục đích chung có thể mở rộng cho nhiều tác vụ.

4.2 Liên quan LLM với Các Đầu Vật lý

Trong khi thế giới vật lý cung cấp một môi trường tương tác chìm đắm, phong phú về bối cảnh và hấp dẫn hơn so với lĩnh vực kỹ thuật số, việc kết nối giữa LLM và thế giới vật lý đã bị hạn chế cho đến khi xuất hiện mô hình tập trung vào code. Mô hình này cho phép các lời gọi có thể thích ứng đến các công cụ và mô-đun thực thi trong thế giới vật lý, đầu tiên tạo ra một làn sóng nghiên cứu khám phá việc tích hợp LLM với robotics và lái xe tự động.

Một trong những cách tiếp cận thành công nhất để sử dụng LLM tạo ra code chính sách cho các tác vụ robot thế giới thực là PaLM-SayCan (Ahn et al., 2022), nơi LLM hiểu các hướng dẫn cấp cao và sau đó gọi các API tương ứng để điều khiển robot. Tiếp theo SayCan, các phát triển gần đây đã cho thấy rằng LLM có thể phục vụ như bộ não cho việc lập kế hoạch và điều khiển robotics thông qua khả năng tạo code mạnh mẽ của chúng. ProgPrompt (Singh et al., 2022), chẳng hạn, đi tiên phong trong các đặc tả giống chương trình cho việc lập kế hoạch tác vụ robot, trong khi các nhà nghiên cứu khác như Huang et al. (2023a), Liang et al. (2023a), và Vemprala et al. (2023) đã mở rộng cách tiếp cận này cho một loạt các tác vụ khác, bao gồm tương tác người-robot và điều khiển drone.

Thông qua tạo code và học công cụ, LLM cũng cho thấy tiềm năng lớn trong các tác vụ phức tạp hơn như tương tác người-xe và lái xe tự động (Cui et al., 2023b; Huang et al., 2023b; Li et al., 2023d). Một ví dụ học công cụ hàng đầu từ ngành công nghiệp là LINGO-1 của Wayve (Wayve, 2023), sử dụng một LLM thị giác, ngôn ngữ và hành động open-loop để cải thiện khả năng giải thích của các mô hình lái xe. Sử dụng instruction tuning, LLM đã tiến bộ đến mức chúng có thể hiểu các lệnh lái xe, điều hướng và giải trí phức tạp (Wang et al., 2023e), tạo ra code có thể thực hiện (Ma et al., 2023b), và thực thi chúng bằng cách gọi các API lập kế hoạch và điều khiển xe cấp thấp (Cui et al., 2023a; Sha et al., 2023; Mao et al., 2023).

Nhìn chung, mặc dù có những thách thức như độ trễ, vấn đề độ chính xác, và việc thiếu các môi trường mô phỏng, tập dữ liệu và benchmark phù hợp (Kannan et al., 2023; Chen và Huang, 2023; Cui et al., 2023b), LLM cho thấy triển vọng trong việc hiểu các hướng dẫn cấp cao và thực thi các API liên quan đến code trong các lĩnh vực phức tạp như robotics và lái xe tự động. Nhìn về phía trước, có tiềm năng đáng kể cho LLM để thu hẹp khoảng cách giữa thế giới vật lý và AI, ảnh hưởng đến các lĩnh vực như giao thông và sản xuất thông minh (Panchal và Wang, 2023; Zeng et al., 2023a).

5 Code Cung cấp cho LLM một Môi trường Thực thi để Phản hồi Tự động

LLM thể hiện hiệu suất vượt ra ngoài các tham số của việc huấn luyện của chúng, một phần do khả năng tiếp nhận phản hồi, đặc biệt trong các ứng dụng thế giới thực nơi môi trường hiếm khi tĩnh (Liu et al., 2023f; Wang et al., 2023d). Tuy nhiên, phản hồi phải được chọn cẩn thận vì các prompt nhiễu có thể cản trở hiệu suất của LM trên các tác vụ hạ lưu (Zheng và Saparov, 2023). Hơn nữa, vì nỗ lực của con người tốn kém, điều quan trọng là phản hồi có thể được thu thập tự động trong khi vẫn trung thực. Việc nhúng LLM vào một môi trường thực thi code cho phép phản hồi tự động đáp ứng tất cả các tiêu chí này, như được thể hiện trong Hình 5. Vì việc thực thi code phần lớn là xác định, các LLM tiếp nhận phản hồi từ kết quả của code được thực thi vẫn trung thực với tác vụ trong tầm tay (Chen et al., 2023a; Fernandes et al., 2023; Scheurer et al., 2022). Hơn nữa, các trình thông dịch code cung cấp một con đường tự động cho LLM để truy vấn phản hồi nội bộ, loại bỏ nhu cầu cho các chú thích của con người tốn kém như đã thấy khi tận dụng LLM để debug hoặc tối ưu hóa code có lỗi (Chen et al., 2023a; Fernandes et al., 2023; Scheurer et al., 2022). Ngoài ra, môi trường code cho phép LLM kết hợp các hình thức phản hồi bên ngoài đa dạng và toàn diện, như phê bình về tính đúng đắn nhị phân (Wang et al., 2023g), giải thích ngôn ngữ tự nhiên về kết quả (Chen et al., 2023c), và xếp hạng với giá trị phần thưởng (Inala et al., 2022), cho phép các phương pháp có thể tùy chỉnh cao để tăng cường hiệu suất.

Chúng tôi giới thiệu các loại phản hồi khác nhau được rút ra từ việc thực thi code có thể được sử dụng chung để có lợi cho LLM trong §5.1, và thảo luận về các phương pháp phổ biến để sử dụng phản hồi này để cải thiện LLM trong §5.2.

--- TRANG 9 ---
Hình 5: LLM có thể được nhúng vào một môi trường thực thi code, nơi chúng thu thập phản hồi trung thực, tự động và có thể tùy chỉnh để tự cải thiện.

5.1 Phản hồi Đa dạng từ Thực thi Code

Quá trình thực thi code cho phép đánh giá nội dung được tạo ra bởi LLM với các metric đánh giá toàn diện hơn được rút ra từ kết quả thực thi xác định, trái ngược với việc chỉ dựa vào các metric dựa trên chuỗi thường mơ hồ như BLEU (Papineni et al., 2002; Ren et al., 2020) và Rouge (Lin, 2004).

Các phương pháp đơn giản để đánh giá kết quả thực thi chương trình và tạo phản hồi bao gồm việc tạo unit test (Chen et al., 2021; Hendrycks et al., 2021; Austin et al., 2021; Li et al., 2022; Huang et al., 2022a; Lai et al., 2023) và áp dụng các kỹ thuật khớp kết quả chính xác (Dong và Lapata, 2016; Zhong et al., 2017; Huang et al., 2022a). Từ đó, phản hồi có thể được cung cấp dưới hai hình thức chính: phản hồi tính đúng đắn đơn giản và phản hồi văn bản. Phản hồi đơn giản, chỉ ra liệu một chương trình có đúng hay không, có thể được tạo ra thông qua các mô hình phê bình hoặc phương pháp dựa trên quy tắc (Wang et al., 2023g; Chen et al., 2023c).

Đối với phản hồi văn bản chi tiết hơn, các mô hình ngôn ngữ có thể được sử dụng để tạo ra giải thích về chính chương trình (Chen et al., 2023c), hoặc để tóm tắt comment về chương trình và việc thực thi của nó (Wang et al., 2023g; Chen et al., 2023c; Zhang et al., 2023a). Kết quả thực thi cũng có thể được dịch thành các hàm phần thưởng bằng cách sử dụng các quy tắc được định nghĩa trước. Các quy tắc ánh xạ kết quả thực thi thành các giá trị vô hướng dựa trên mức độ nghiêm trọng của các loại lỗi khác nhau, do đó làm cho định dạng phản hồi phù hợp cho các cách tiếp cận học tăng cường (Le et al., 2022).

Hơn nữa, phản hồi bổ sung có thể được trích xuất bằng cách thực hiện phân tích tĩnh sử dụng các công cụ kỹ thuật phần mềm. Ví dụ, Wang et al. (2017) và Gupta et al. (2017) thu được thông tin bổ sung từ trace thực thi, bao gồm trace biến hoặc trạng thái. Lai et al. (2023) thể hiện một cách hiệu quả để trích xuất phản hồi bổ sung bằng cách sử dụng các ràng buộc hình thức bề mặt trên các lời gọi hàm.

5.2 Phương pháp Tăng cường Hiệu suất LLM với Phản hồi

Phản hồi được rút ra từ việc thực thi code và các mô-đun đánh giá bên ngoài có thể tăng cường LLM thông qua ba cách tiếp cận chính.

Phương pháp Dựa trên Lựa chọn. Các phương pháp dựa trên lựa chọn, như bỏ phiếu đa số và các sơ đồ xếp hạng lại, đã chứng minh hiệu quả trong việc tăng cường hiệu suất LLM trong các tác vụ như tạo code. Các phương pháp này, ban đầu được phát triển cho tổng hợp chương trình đơn giản, tận dụng kết quả thực thi code như số lượng unit test được vượt qua để chọn đoạn code có hiệu suất tốt nhất. Các nghiên cứu như Chen et al. (2018); Li et al. (2022) thể hiện hiệu quả của bỏ phiếu đa số, trong khi Zhang et al. (2023b); Yin và Neubig (2019); Zeng et al. (2023b) thể hiện những lợi thế của các sơ đồ xếp hạng lại. Dựa trên thành công này, các cách tiếp cận tương tự đã được điều chỉnh cho các tác vụ thách thức hơn nơi code-LLM được tích hợp trong các môi trường tương tác, như được thể hiện trong công trình của Shi et al. (2022); Chen et al. (2022) cho các phương pháp bỏ phiếu tương tự, và Ni et al. (2023); Inala et al. (2022); To et al. (2023) cho các chiến lược xếp hạng lại. Tuy nhiên, những cách tiếp cận này, mặc dù đơn giản và hiệu quả, gây ra sự không hiệu quả, vì chúng đòi hỏi nhiều vòng tạo ra và sử dụng các mô hình xếp hạng lại bổ sung để xác định giải pháp tối ưu.

Phương pháp Dựa trên Prompting. Các LLM hiện đại được trang bị khả năng lý luận trong ngữ cảnh và tích hợp trực tiếp phản hồi từ mô tả tác vụ vào prompts, đến mức độ nhất định. Cải thiện "tự debug" của LLM với prompts học trong ngữ cảnh thường đòi hỏi phản hồi được trình bày dưới dạng giải thích ngôn ngữ tự nhiên (Wang et al., 2023h; Chen et al., 2023c) hoặc thông báo lỗi được rút ra từ kết quả thực thi, vì những định dạng này dễ hiểu hơn cho LLM. Phương pháp này được ưa chuộng bởi hầu hết các tác nhân dựa trên LLM (xem §6) do tính tự động, hiệu quả tính toán, và không đòi hỏi tinh chỉnh bổ sung. Tuy nhiên, hiệu quả của cách tiếp cận này phụ thuộc rất nhiều vào khả năng học trong ngữ cảnh của LLM.

Phương pháp Dựa trên Finetuning. Trong các phương pháp nói trên, cả phương pháp dựa trên lựa chọn và phương pháp dựa trên prompting đều không hứa hẹn cải thiện ổn định về tác vụ, vì các tham số của LLM vẫn không thay đổi. Chúng đòi hỏi lặp lại quá trình tuning ngay cả khi đối mặt với các vấn đề tương tự. Các cách tiếp cận finetuning, mặt khác, cải thiện cơ bản LLM bằng cách cập nhật kiến thức được tham số hóa của chúng. Các chiến lược finetuning điển hình bao gồm tối ưu hóa trực tiếp, tận dụng một mô hình bên ngoài để tối ưu hóa, và huấn luyện mô hình trong một mô hình học tăng cường.

Wang et al. (2023g) minh họa cách tiếp cận tối ưu hóa trực tiếp, nơi mô hình ngôn ngữ gốc được tinh chỉnh với một mục tiêu có điều kiện phản hồi. Haluptzok et al. (2022) trình bày một phương pháp độc đáo nơi các mô hình ngôn ngữ tạo ra unit test tổng hợp để xác định và chỉ giữ lại các ví dụ được tạo ra đúng, sau đó được kết hợp thành các cặp câu hỏi-trả lời đúng và được sử dụng để tinh chỉnh thêm các mô hình. CodeScore (Dong et al., 2023a) thiết kế hàm mất mát của nó dựa trên khả năng thực thi và tỷ lệ vượt qua trên các unit test. Đối với self-edit (Zhang et al., 2023a), nó đầu tiên gói kết quả thực thi thành comment văn bản, sau đó huấn luyện một trình chỉnh sửa để tinh chỉnh thêm chương trình bằng cách chấp nhận cả chương trình có vấn đề và các comment. Chen et al. (2023a) huấn luyện một "mô hình tinh chỉnh" chấp nhận phản hồi và chương trình được tạo ra trước, sau đó sử dụng ví dụ được tạo ra đã được tinh chỉnh để tinh chỉnh mô hình tạo ra, minh họa một cách tiếp cận phân lớp cho finetuning. CodeRL (Le et al., 2022) và Wang et al. (2022) áp dụng học tăng cường để cải thiện mô hình ngôn ngữ gốc. Trong khi Wang et al. (2022) nhằm sử dụng phản hồi compiler để thu được code lỗi, CodeRL (Le et al., 2022) định nghĩa thực nghiệm các giá trị phần thưởng cố định cho các loại kết quả thực thi khác nhau dựa trên unit test. Mặc dù có những lợi thế được thảo luận, việc tinh chỉnh LLM thông qua finetuning thường liên quan đến một quá trình thu thập dữ liệu tốn nhiều tài nguyên. Ngoài ra, việc đánh giá các giá trị phần thưởng được định nghĩa trước, như được minh họa trong CodeRL (Le et al., 2022), đặt ra những thách thức nhất định.

--- TRANG 10 ---
6 Ứng dụng: LLM được trao quyền bởi Code Tạo điều kiện cho Tác nhân Thông minh

Trong các phần trước, cuộc thảo luận của chúng tôi làm nổi bật các cách khác nhau mà việc tích hợp code tăng cường LLM. Đi xa hơn, chúng tôi nhận thấy rằng những lợi ích của LLM được trao quyền bởi code đặc biệt rõ ràng trong một lĩnh vực chính: phát triển IA (Xu et al., 2023). Trong phần này, chúng tôi nhấn mạnh những khả năng độc đáo được trao cho những tác nhân này bởi LLM được trao quyền bởi code.

Hình 6 giúp minh họa một quy trình hoạt động chuẩn của một IA, đặc biệt phục vụ như một trợ lý hàng ngày tổng quát được hiện thân. Chúng tôi quan sát thấy rằng những cải thiện mang lại bởi việc huấn luyện code trong LLM được gắn chặt trong các bước hoạt động thực tế của chúng khi phục vụ như IA. Những bước này bao gồm (i) tăng cường khả năng ra quyết định của IA về nhận thức môi trường và lập kế hoạch (§6.1), (ii) tinh gọn việc thực hiện bằng cách gắn kết hành động trong các nguyên tắc hành động mô-đun và rõ ràng và tổ chức bộ nhớ hiệu quả (§6.2), và (iii) tối ưu hóa hiệu suất thông qua phản hồi được rút ra tự động từ môi trường thực thi code (§6.3). Giải thích chi tiết về mỗi khía cạnh sẽ theo sau trong các phần tiếp theo.

6.1 Ra quyết định

Nhận thức Môi trường Như được mô tả trong Hình 6 ở bước (0-10), IA liên tục nhận thức thế giới, tham gia vào các tương tác với con người và môi trường, phản ứng với các kích thích liên quan (ví dụ: hướng dẫn của con người để chuẩn bị bữa ăn), và lập kế hoạch và thực hiện hành động dựa trên các điều kiện môi trường quan sát được (ví dụ: bố cục nhà bếp). Việc sử dụng LLM làm trung tâm quyết định cho IA đòi hỏi việc dịch các quan sát môi trường thành văn bản, như các tác vụ dựa trên hộ gia đình ảo hoặc Minecraft (Shridhar et al., 2020; Côté et al., 2018; Wang et al., 2023b; Zhu et al., 2023). Thông tin được nhận thức cần được tổ chức trong một định dạng có cấu trúc cao, đảm bảo rằng các kích thích xảy ra cùng một lúc (ví dụ: kích thích đa phương tiện cùng tồn tại) ảnh hưởng đến nhận thức và quyết định của IA cùng lúc mà không có sự khác biệt về thời gian, một yêu cầu tương phản với tính chất tuần tự của văn bản tự do. Thông qua tiền huấn luyện trên code, LLM có được khả năng hiểu và tạo ra tốt hơn các biểu diễn có cấu trúc giống như định nghĩa lớp trong code. Định dạng có cấu trúc này, nơi các thuộc tính và hàm của lớp là bất biến hoán vị, tạo điều kiện cho các tác nhân trong việc nhận thức các quan sát môi trường có cấu trúc trong quá trình thực hiện tác vụ.

Một ví dụ trực quan như vậy là các môi trường dựa trên trang web có cấu trúc cao xung quanh code HTML. Trong các tác vụ tác nhân như mua sắm web (Yao et al., 2022a), duyệt web (Deng et al., 2023b), và QA dựa trên web (Nakano et al., 2021; Liu et al., 2023d), việc dịch môi trường dựa trên web thành code HTML được ưa chuộng hơn là ngôn ngữ tự nhiên, trực tiếp bao gồm thông tin cấu trúc của nó và do đó cải thiện nhận thức tổng thể của tác nhân LLM. Hơn nữa, trong nghiên cứu robotics bởi Singh et al. (2022) và Liang et al. (2023a), các IA được prompted với các đặc tả giống chương trình cho các đối tượng trong môi trường, cho phép LLM tạo ra các kế hoạch tác vụ có tình huống dựa trên các đối tượng ảo mà chúng nhận thức.

Lập kế hoạch Như được minh họa trong Hình 6 ở bước (2), IA phải chia nhỏ các tác vụ phức tạp thành các bước nhỏ hơn, có thể quản lý được. Tận dụng khả năng lập kế hoạch được kết hợp của code-LLM, IA có thể tạo ra các bước lý luận có tổ chức bằng cách sử dụng code mô-đun và rõ ràng cùng với ngôn ngữ tự nhiên biểu cảm. Như đã thảo luận trong §2.2, khi code-LLM được sử dụng cho việc lập kế hoạch các tác vụ tác nhân, chúng thể hiện khả năng lý luận được tăng cường. Ngoài ra, chúng tạo ra các tác vụ con như các chương trình có thể thực thi khi cần thiết, tạo ra các kết quả trung gian mạnh mẽ hơn, mà IA điều kiện hóa và tinh chỉnh việc lập kế hoạch của nó với độ chính xác cao hơn. Hơn nữa, IA tích hợp một cách liền mạch các API công cụ hiệu quả vào việc lập kế hoạch, giải quyết các hạn chế như lý luận toán học kém và cập nhật thông tin lỗi thời mà các LLM thuần túy gặp phải trong quá trình lập kế hoạch.

Các ví dụ điển hình sử dụng code để lập kế hoạch có hai danh mục chính. Progprompt (Singh et al., 2022) và Code as Policies (Liang et al., 2023a) đại diện cho công trình sử dụng code để điều khiển robot tốt hơn. Cả hai công trình đều làm nổi bật những lợi ích mang lại bởi việc lập kế hoạch dựa trên code vì chúng không chỉ cho phép biểu đạt trực tiếp các vòng lặp phản hồi, hàm, và API nguyên tắc, mà còn tạo điều kiện truy cập trực tiếp đến các thư viện bên thứ ba. Một dòng công trình khác quan tâm đến kịch bản khi khả năng lập trình và lý luận toán học của các tác nhân là quan trọng, như giải quyết các vấn đề liên quan đến toán học (Gao et al., 2023; Wang et al., 2023h) hoặc thực hiện thí nghiệm trong lĩnh vực khoa học (Boiko et al., 2023; Liffiton et al., 2023).

6.2 Thực hiện

Gắn kết Hành động Như được mô tả trong Hình 6 ở bước (3), khi IA giao tiếp với các đầu chức năng bên ngoài theo kế hoạch, nó phải gọi các nguyên tắc hành động từ một tập hành động được định nghĩa trước (tức là các hàm). Với việc các LLM hiện đại được huấn luyện trong ngôn ngữ hình thức và có thể tạo ra các nguyên tắc được hình thức hóa cao, việc tạo ra của IA có thể được phân tích và thực thi trực tiếp, loại bỏ sự cần thiết cho các mô-đun gắn kết nguyên tắc hành động bổ sung.

--- TRANG 11 ---
Hình 6: Hình này minh họa quy trình làm việc hoàn chỉnh của một tác nhân thông minh dựa trên LLM, ánh xạ các khả năng code-LLM đến các giai đoạn cụ thể: lập kế hoạch dựa trên code ở bước (2), phân tích hành động mô-đun và tạo công cụ ở bước (3), và thu thập phản hồi tự động để tăng cường tự cải thiện tác nhân ở bước (5). Tổng hợp, các bước 0-10 trong toàn bộ vòng lặp được hưởng lợi từ khả năng hiểu thông tin có cấu trúc và nhận thức được cải thiện của code-LLM.

Việc kết nối IA với các đầu chức năng khác đòi hỏi gắn kết các hành động thành các nguyên tắc giống hàm được hình thức hóa. Ví dụ, trong một benchmark đánh giá LLM như các tác nhân trong các kịch bản thế giới thực (Liu et al., 2023f), bảy trong tám kịch bản liên quan đến code như không gian hành động.

Công trình trước đây tạo ra các kế hoạch tác nhân với ngôn ngữ tự nhiên thuần túy đòi hỏi một mô-đun bước-đến-nguyên tắc bổ sung để gắn kết những bước lập kế hoạch đó thành code (Wang et al., 2023c; Yin et al., 2023). Ngược lại, các IA lập kế hoạch với code-LLM tạo ra các chương trình hành động nguyên tử (Yao et al., 2022d; Wang et al., 2023h; Liang et al., 2023a; Singh et al., 2022), và có thể được phân tích nhanh chóng để thực thi.

Tổ chức Bộ nhớ Như được mô tả trong Hình 6 ở bước (3) và thành phần được gắn nhãn "Đầu Chức năng để Cập nhật Trạng thái," IA thường đòi hỏi một mô-đun tổ chức bộ nhớ bên ngoài để quản lý thông tin được tiết lộ (Wang et al., 2023d), bao gồm kế hoạch gốc, tiến độ tác vụ, lịch sử thực hiện, tập công cụ có sẵn, kỹ năng đã có được, kiến thức được tăng cường, và phản hồi sớm của người dùng. Trong bối cảnh này, Code-LLM hỗ trợ tổ chức bộ nhớ của IA bằng cách sử dụng code trừu tượng và mô-đun cao để ghi lại, tổ chức, và truy cập bộ nhớ, đặc biệt để mở rộng tập công cụ có sẵn và quản lý các kỹ năng đã có được.

Thông thường, các đoạn code được viết bởi tác nhân có thể phục vụ như các phần của bộ công cụ, được tích hợp vào tổ chức bộ nhớ của các tác nhân. Dòng nghiên cứu này được biết đến như các cách tiếp cận tạo công cụ. TALM (Cai et al., 2023) đề xuất sử dụng các tác nhân mạnh hơn (ví dụ: tác nhân dựa trên GPT-4) để viết code như một phần bộ nhớ cho các tác nhân yếu hơn (ví dụ: tác nhân dựa trên GPT-3.5). Trong Creator (Qian et al., 2023b), các tác nhân bản thân được làm nổi bật không chỉ như người dùng của các công cụ mà còn là những người tạo ra chúng. Họ đề xuất một khung tạo công cụ bốn giai đoạn cho phép các tác nhân viết code như một phần của bộ công cụ có thể thực thi của chúng. Đi xa hơn, Craft (Yuan et al., 2023) tập trung vào việc đảm bảo các công cụ được tạo ra thực sự có thể thực thi, làm cho khung này mạnh mẽ hơn. Một công trình khác chia sẻ ý tưởng này là Voyager (Wang et al., 2023b), trong đó tác nhân lưu trữ các kỹ năng đã học trong định dạng code và thực thi chúng trong tương lai khi đối mặt với các tác vụ tương tự.

6.3 Tự cải thiện

Như được minh họa trong Hình 6 ở bước (5), khi trung tâm quyết định của IA, tức là LLM, hoạt động trong một môi trường thực thi code, môi trường có thể tích hợp các mô-đun đánh giá khác nhau để cung cấp phản hồi tự động (ví dụ: tính đúng đắn, xếp hạng, comment chi tiết). Điều này làm tăng đáng kể khả năng sửa chữa lỗi sớm của IA và tạo điều kiện cho tự cải thiện.

Voyager (Wang et al., 2023b) là một ví dụ tốt cho các tác nhân sử dụng phản hồi từ môi trường mô phỏng. Tác nhân học từ các trường hợp tác vụ thất bại và tiếp tục mài giũa kỹ năng của nó trong Minecraft. Chameleon (Lu et al., 2023) nhận phản hồi từ một trình xác minh chương trình để quyết định liệu nó có nên tái tạo một chương trình phù hợp hay không. Mint (Wang et al., 2023h) có thể nhận phản hồi từ các proxy, và tác nhân do đó có thể tự cải thiện trong một cài đặt tương tác đa lượt. Quan trọng, khả năng tự cải thiện từ phản hồi thực thi này là cơ bản cho thành công của các tác nhân trong việc giải quyết các vấn đề khoa học (Bran et al., 2023; Swan et al., 2023; Wu et al., 2023b).

7 Thách thức

Chúng tôi xác định một số hướng nghiên cứu thú vị và đầy hứa hẹn cho tương lai.

7.1 Mối quan hệ Nhân quả giữa Tiền huấn luyện Code và Tăng cường Lý luận của LLM

Mặc dù chúng tôi đã phân loại công trình liên quan nhất trong §3.2, một khoảng cách đáng chú ý vẫn tồn tại trong việc cung cấp bằng chứng thực nghiệm rõ ràng cho thấy trực tiếp việc tăng cường khả năng lý luận của LLM thông qua việc có được các đặc tính code cụ thể. Trong khi chúng ta trực giác thừa nhận rằng một số đặc tính code có thể đóng góp vào khả năng lý luận của LLM, mức độ chính xác của ảnh hưởng của chúng đến việc tăng cường kỹ năng lý luận vẫn mơ hồ. Trong các nỗ lực nghiên cứu tương lai, điều quan trọng là điều tra liệu việc củng cố những đặc tính code này trong dữ liệu huấn luyện có thể thực sự tăng cường khả năng lý luận của các LLM được huấn luyện hay không. Nếu thực sự là trường hợp, việc tiền huấn luyện trên các đặc tính cụ thể của code trực tiếp cải thiện khả năng lý luận của LLM, việc hiểu hiện tượng này sẽ là chìa khóa để tiếp tục cải thiện khả năng lý luận phức tạp của các mô hình hiện tại.

7.2 Có được Lý luận Ngoài Code

Mặc dù có sự tăng cường trong lý luận đạt được bằng việc tiền huấn luyện trên code, các mô hình nền tảng vẫn thiếu khả năng lý luận giống con người được mong đợi từ một trí tuệ nhân tạo thực sự tổng quát. Quan trọng, ngoài code, một lượng lớn các nguồn dữ liệu văn bản khác có tiềm năng củng cố khả năng lý luận LLM, nơi các đặc tính vốn có của code, như thiếu sự mơ hồ, khả năng thực thi, và cấu trúc tuần tự logic, cung cấp các nguyên tắc hướng dẫn cho việc thu thập hoặc tạo ra những tập dữ liệu này. Tuy nhiên, nếu chúng ta gắn bó với mô hình huấn luyện các mô hình ngôn ngữ trên corpus lớn với mục tiêu mô hình hóa ngôn ngữ, thật khó để hình dung một ngôn ngữ có thể đọc tuần tự trừu tượng hơn, có cấu trúc cao, và phù hợp chặt chẽ với ngôn ngữ ký hiệu hơn các ngôn ngữ hình thức, được minh họa bởi code, phổ biến trong một bối cảnh kỹ thuật số đáng kể. Chúng tôi hình dung rằng việc khám phá các phương tiện dữ liệu thay thế, các mục tiêu huấn luyện đa dạng, và các kiến trúc mới sẽ mang lại những cơ hội bổ sung để tiếp tục tăng cường khả năng lý luận của những mô hình này.

7.3 Thách thức của việc Áp dụng Mô hình Tập trung vào Code

Thách thức chính trong việc LLM sử dụng code để kết nối với các đầu chức năng khác nhau là học cách gọi đúng nhiều hàm, bao gồm việc chọn đúng đầu chức năng và truyền các tham số đúng vào thời điểm thích hợp. Ngay cả đối với các tác vụ đơn giản như điều hướng web đơn giản hóa với một tập hành động nguyên tắc hạn chế như di chuyển chuột, nhấp chuột, và cuộn trang, các ví dụ few shot cùng với một LLM cơ bản mạnh thường được yêu cầu để LLM nắm bắt chính xác việc sử dụng những nguyên tắc này (Sridhar et al., 2023). Đối với các tác vụ phức tạp hơn trong các lĩnh vực sử dụng nhiều dữ liệu như hóa học (Bran et al., 2023), sinh học, và thiên văn học, liên quan đến các thư viện Python đặc thù lĩnh vực với các hàm đa dạng và lời gọi phức tạp, việc tăng cường khả năng của LLM trong việc học cách gọi đúng những hàm này là một hướng triển vọng, trao quyền cho LLM hoạt động như IA thực hiện các tác vụ cấp chuyên gia trong các lĩnh vực chi tiết.

7.4 Học từ các tương tác và phản hồi đa lượt

LLM thường đòi hỏi nhiều tương tác với người dùng và môi trường, liên tục tự sửa chữa để cải thiện việc hoàn thành tác vụ phức tạp (Li et al., 2023c). Trong khi việc thực thi code cung cấp phản hồi đáng tin cậy và có thể tùy chỉnh, một phương pháp hoàn hảo để tận dụng đầy đủ phản hồi này vẫn chưa được thiết lập. Như đã thảo luận trong §5.2, chúng tôi quan sát thấy rằng các phương pháp dựa trên lựa chọn, mặc dù hữu ích, không đảm bảo hiệu suất được cải thiện và có thể không hiệu quả. Các phương pháp dựa trên prompting phụ thuộc rất nhiều vào khả năng học trong ngữ cảnh của LLM, điều này có thể hạn chế khả năng áp dụng của chúng. Các phương pháp fine-tuning cho thấy cải thiện nhất quán, nhưng việc thu thập dữ liệu và fine-tuning tốn nhiều tài nguyên và do đó có tính cấm đoán. Chúng tôi giả thuyết rằng học tăng cường có thể là một cách tiếp cận hiệu quả hơn để sử dụng phản hồi và cải thiện LLM. Phương pháp này có thể giải quyết những hạn chế của các kỹ thuật hiện tại bằng cách cung cấp một cách động để thích ứng với phản hồi thông qua các hàm phần thưởng được thiết kế tốt. Tuy nhiên, vẫn cần nghiên cứu đáng kể để hiểu cách các hàm phần thưởng nên được thiết kế và cách học tăng cường có thể được tích hợp tối ưu với LLM để hoàn thành tác vụ phức tạp.

8 Kết luận

Trong khảo sát này, chúng tôi biên soạn tài liệu làm rõ cách code trao quyền cho LLM, cũng như nơi code hỗ trợ LLM phục vụ như IA. Để bắt đầu, code có khả năng đọc tuần tự của ngôn ngữ tự nhiên trong khi cũng thể hiện sự trừu tượng và cấu trúc đồ thị của các biểu diễn ký hiệu, khiến nó trở thành một kênh cho nhận thức kiến thức và lý luận như một phần không thể thiếu của corpus huấn luyện LLM dựa trên mục tiêu mô hình hóa ngôn ngữ đơn thuần. Thông qua một đánh giá tài liệu toàn diện, chúng tôi quan sát thấy rằng sau khi huấn luyện code, LLM i) cải thiện kỹ năng lập trình và lý luận của chúng, ii) có thể tạo ra các hàm được hình thức hóa cao, cho phép kết nối linh hoạt với các đầu chức năng đa dạng trên các phương tiện và lĩnh vực, và iii) tham gia vào tương tác với các mô-đun đánh giá được tích hợp trong môi trường thực thi code để tự cải thiện tự động. Hơn nữa, chúng tôi phát hiện rằng việc tăng cường khả năng của LLM mang lại bởi việc huấn luyện code có lợi cho ứng dụng hạ lưu của chúng như IA, biểu hiện trong các bước hoạt động cụ thể của quy trình làm việc IA về ra quyết định, thực hiện, và tự cải thiện. Ngoài việc đánh giá nghiên cứu trước đây, chúng tôi đưa ra một số thách thức trong lĩnh vực này để phục vụ như các yếu tố hướng dẫn cho các hướng tiềm năng trong tương lai.

[Phần tham khảo được bỏ qua do độ dài]
